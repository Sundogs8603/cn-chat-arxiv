<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#24320;&#21457;&#30340;&#22810;&#35821;&#35328;&#20064;&#35821;&#30693;&#35782;&#24211;&#65288;IdiomKB&#65289;&#65292;&#36890;&#36807;&#26816;&#32034;&#20064;&#35821;&#30340;&#27604;&#21947;&#24847;&#20041;&#65292;&#23454;&#29616;&#23545;&#20064;&#35821;&#30340;&#26356;&#22909;&#32763;&#35793;&#12290;</title><link>http://arxiv.org/abs/2308.13961</link><description>&lt;p&gt;
&#32763;&#35793;&#21547;&#20041;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#35789;&#35821;&#65306;IdiomKB&#22312;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#20248;&#21270;&#20064;&#35821;&#32763;&#35793;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models. (arXiv:2308.13961v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#24320;&#21457;&#30340;&#22810;&#35821;&#35328;&#20064;&#35821;&#30693;&#35782;&#24211;&#65288;IdiomKB&#65289;&#65292;&#36890;&#36807;&#26816;&#32034;&#20064;&#35821;&#30340;&#27604;&#21947;&#24847;&#20041;&#65292;&#23454;&#29616;&#23545;&#20064;&#35821;&#30340;&#26356;&#22909;&#32763;&#35793;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36827;&#34892;&#33391;&#22909;&#30340;&#32763;&#35793;&#65292;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#21644;&#36890;&#29992;&#35821;&#35328;&#27169;&#22411;&#38656;&#35201;&#23545;&#28304;&#35821;&#35328;&#21644;&#30446;&#26631;&#35821;&#35328;&#20197;&#21450;&#25991;&#21270;&#26377;&#28145;&#20837;&#30340;&#29702;&#35299;&#12290;&#22240;&#27492;&#65292;&#30001;&#20110;&#20854;&#38750;&#32452;&#21512;&#24615;&#30340;&#29305;&#24615;&#65292;&#20064;&#35821;&#23545;&#22522;&#20110;Transformer&#30340;&#31995;&#32479;&#25552;&#20986;&#20102;&#29305;&#27530;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#30452;&#35793;&#24448;&#24448;&#20250;&#24573;&#30053;&#24847;&#22270;&#12290;&#20256;&#32479;&#26041;&#27861;&#20351;&#29992;&#29616;&#26377;&#30340;&#30693;&#35782;&#24211;&#65288;KB&#65289;&#26367;&#25442;&#20064;&#35821;&#65292;&#24448;&#24448;&#32570;&#20047;&#35268;&#27169;&#21644;&#19978;&#19979;&#25991;&#24847;&#35782;&#12290;&#38024;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20808;&#32771;&#34385;&#19978;&#19979;&#25991;&#24847;&#35782;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#20801;&#35768;&#22312;&#21487;&#31649;&#29702;&#30340;KB&#22823;&#23567;&#30340;&#31163;&#32447;&#23384;&#20648;&#20013;&#23384;&#20648;&#20064;&#35821;&#12290;&#36825;&#30830;&#20445;&#20102;&#26356;&#39640;&#25928;&#30340;&#23567;&#22411;&#27169;&#22411;&#26381;&#21153;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20064;&#35821;&#34920;&#36798;&#30340;&#26356;&#20840;&#38754;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24320;&#21457;&#30340;&#22810;&#35821;&#35328;&#20064;&#35821;KB&#65288;IdiomKB&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#26816;&#32034;&#20064;&#35821;&#30340;&#27604;&#21947;&#24847;&#20041;&#65292;&#35813;KB&#21487;&#20197;&#24110;&#21161;&#23567;&#22411;&#27169;&#22411;&#65288;&#22914;BLOOMZ&#65288;7.1B&#65289;&#65292;Alpaca&#65288;7B&#65289;&#21644;InstructGPT&#65288;6.7B&#65289;&#65289;&#23454;&#29616;&#26356;&#22909;&#30340;&#32763;&#35793;&#12290;
&lt;/p&gt;
&lt;p&gt;
To translate well, machine translation (MT) systems and general-purposed language models (LMs) need a deep understanding of both source and target languages and cultures. Therefore, idioms, with their non-compositional nature, pose particular challenges for Transformer-based systems, as literal translations often miss the intended meaning. Traditional methods, which replace idioms using existing knowledge bases (KBs), often lack scale and context awareness. Addressing these challenges, our approach prioritizes context awareness and scalability, allowing for offline storage of idioms in a manageable KB size. This ensures efficient serving with smaller models and provides a more comprehensive understanding of idiomatic expressions. We introduce a multilingual idiom KB (IdiomKB) developed using large LMs to address this. This KB facilitates better translation by smaller models, such as BLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms' figurative meanings. We presen
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25913;&#36827;BERT&#27169;&#22411;&#30340;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#19981;&#21516;&#30340;&#25439;&#22833;&#20989;&#25968;&#12289;&#26144;&#23556;&#26041;&#27861;&#21644;&#26435;&#37325;&#35843;&#25972;&#65292;&#25552;&#39640;&#30693;&#35782;&#33976;&#39311;&#30340;&#25928;&#29575;&#21644;&#31934;&#24230;&#65292;&#20174;&#32780;&#21387;&#32553;&#22823;&#22411;Transformer&#27169;&#22411;&#65292;&#20351;&#20854;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#26356;&#21152;&#39640;&#25928;&#12290;</title><link>http://arxiv.org/abs/2308.13958</link><description>&lt;p&gt;
&#25913;&#36827;BERT&#27169;&#22411;&#30340;&#30693;&#35782;&#33976;&#39311;&#65306;&#25439;&#22833;&#20989;&#25968;&#12289;&#26144;&#23556;&#26041;&#27861;&#21644;&#26435;&#37325;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Improving Knowledge Distillation for BERT Models: Loss Functions, Mapping Methods, and Weight Tuning. (arXiv:2308.13958v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25913;&#36827;BERT&#27169;&#22411;&#30340;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#39564;&#19981;&#21516;&#30340;&#25439;&#22833;&#20989;&#25968;&#12289;&#26144;&#23556;&#26041;&#27861;&#21644;&#26435;&#37325;&#35843;&#25972;&#65292;&#25552;&#39640;&#30693;&#35782;&#33976;&#39311;&#30340;&#25928;&#29575;&#21644;&#31934;&#24230;&#65292;&#20174;&#32780;&#21387;&#32553;&#22823;&#22411;Transformer&#27169;&#22411;&#65292;&#20351;&#20854;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#26356;&#21152;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#65292;&#22914;BERT&#12289;GPT&#21644;T5&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#38656;&#35201;&#37319;&#29992;&#27169;&#22411;&#21387;&#32553;&#25216;&#26415;&#26469;&#20943;&#23567;&#20854;&#22823;&#23567;&#21644;&#22797;&#26434;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#20934;&#30830;&#24615;&#12290;&#26412;&#39033;&#30446;&#30740;&#31350;&#24182;&#24212;&#29992;&#30693;&#35782;&#33976;&#39311;&#29992;&#20110;BERT&#27169;&#22411;&#21387;&#32553;&#65292;&#29305;&#21035;&#20851;&#27880;TinyBERT&#23398;&#29983;&#27169;&#22411;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#22810;&#31181;&#25216;&#26415;&#26469;&#25913;&#36827;&#30693;&#35782;&#33976;&#39311;&#65292;&#21253;&#25324;&#23454;&#39564;&#19981;&#21516;&#30340;&#25439;&#22833;&#20989;&#25968;&#12289;Transformer&#23618;&#26144;&#23556;&#26041;&#27861;&#21644;&#35843;&#25972;&#27880;&#24847;&#21147;&#21644;&#34920;&#31034;&#25439;&#22833;&#30340;&#26435;&#37325;&#65292;&#24182;&#22312;GLUE&#22522;&#20934;&#27979;&#35797;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#25216;&#26415;&#22312;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;&#26412;&#24037;&#20316;&#30340;&#30446;&#26631;&#26159;&#25913;&#36827;&#30693;&#35782;&#33976;&#39311;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#65292;&#20174;&#32780;&#20026;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#24320;&#21457;&#25552;&#20379;&#26356;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The use of large transformer-based models such as BERT, GPT, and T5 has led to significant advancements in natural language processing. However, these models are computationally expensive, necessitating model compression techniques that reduce their size and complexity while maintaining accuracy. This project investigates and applies knowledge distillation for BERT model compression, specifically focusing on the TinyBERT student model. We explore various techniques to improve knowledge distillation, including experimentation with loss functions, transformer layer mapping methods, and tuning the weights of attention and representation loss and evaluate our proposed techniques on a selection of downstream tasks from the GLUE benchmark. The goal of this work is to improve the efficiency and effectiveness of knowledge distillation, enabling the development of more efficient and accurate models for a range of natural language processing tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65288;&#30693;&#35782;&#22270;&#35889;LLM&#65289;&#65292;&#20197;&#25552;&#39640;&#19977;&#20803;&#32452;&#20998;&#31867;&#21644;&#20851;&#31995;&#39044;&#27979;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.13916</link><description>&lt;p&gt;
&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Exploring Large Language Models for Knowledge Graph Completion. (arXiv:2308.13916v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65288;&#30693;&#35782;&#22270;&#35889;LLM&#65289;&#65292;&#20197;&#25552;&#39640;&#19977;&#20803;&#32452;&#20998;&#31867;&#21644;&#20851;&#31995;&#39044;&#27979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#22312;&#20247;&#22810;&#20154;&#24037;&#26234;&#33021;&#20219;&#21153;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#20294;&#32463;&#24120;&#38754;&#20020;&#19981;&#23436;&#25972;&#24615;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#19977;&#20803;&#32452;&#35270;&#20026;&#25991;&#26412;&#24207;&#21015;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#30693;&#35782;&#22270;&#35889;LLM&#65288;KG-LLM&#65289;&#65292;&#26469;&#23545;&#36825;&#20123;&#19977;&#20803;&#32452;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#21033;&#29992;&#19977;&#20803;&#32452;&#30340;&#23454;&#20307;&#21644;&#20851;&#31995;&#25551;&#36848;&#20316;&#20026;&#25552;&#31034;&#65292;&#24182;&#21033;&#29992;&#21709;&#24212;&#36827;&#34892;&#39044;&#27979;&#12290;&#23545;&#21508;&#31181;&#22522;&#20934;&#30693;&#35782;&#22270;&#35889;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19977;&#20803;&#32452;&#20998;&#31867;&#21644;&#20851;&#31995;&#39044;&#27979;&#31561;&#20219;&#21153;&#20013;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#24494;&#35843;&#30456;&#23545;&#36739;&#23567;&#30340;&#27169;&#22411;&#65288;&#20363;&#22914;LLaMA-7B&#65292;ChatGLM-6B&#65289;&#20248;&#20110;&#26368;&#26032;&#30340;ChatGPT&#21644;GPT-4&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24191;&#27867;&#30740;&#31350;&#20102;ChatGPT&#27169;&#22411;&#22312;13&#20010;&#24773;&#24863;&#35745;&#31639;&#38382;&#39064;&#19978;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#35780;&#20272;ChatGPT&#27169;&#22411;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2308.13911</link><description>&lt;p&gt;
ChatGPT&#22312;&#24773;&#24863;&#35745;&#31639;&#20219;&#21153;&#19978;&#30340;&#24191;&#27867;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A Wide Evaluation of ChatGPT on Affective Computing Tasks. (arXiv:2308.13911v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24191;&#27867;&#30740;&#31350;&#20102;ChatGPT&#27169;&#22411;&#22312;13&#20010;&#24773;&#24863;&#35745;&#31639;&#38382;&#39064;&#19978;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#35780;&#20272;ChatGPT&#27169;&#22411;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22522;&#30784;&#27169;&#22411;&#30340;&#23835;&#36215;&#65292;&#19968;&#20010;&#26032;&#30340;&#20154;&#24037;&#26234;&#33021;&#33539;&#24335;&#20986;&#29616;&#20102;&#65292;&#21363;&#36890;&#36807;&#20351;&#29992;&#36890;&#29992;&#30446;&#30340;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#31034;&#26469;&#35299;&#20915;&#38382;&#39064;&#65292;&#32780;&#19981;&#26159;&#20026;&#27599;&#20010;&#38382;&#39064;&#35757;&#32451;&#21333;&#29420;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#24050;&#32463;&#26174;&#31034;&#20986;&#35299;&#20915;&#19968;&#20123;&#26368;&#21021;&#26410;&#32463;&#35757;&#32451;&#30340;&#38382;&#39064;&#30340;&#26032;&#24615;&#36136;&#12290;&#23545;&#20110;&#36825;&#31867;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#30340;&#30740;&#31350;&#36824;&#30456;&#24403;&#26377;&#38480;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24191;&#27867;&#30740;&#31350;&#20102;ChatGPT&#27169;&#22411;&#65288;&#21363;GPT-4&#21644;GPT-3.5&#65289;&#22312;13&#20010;&#24773;&#24863;&#35745;&#31639;&#38382;&#39064;&#19978;&#30340;&#33021;&#21147;&#65292;&#21253;&#25324;&#26041;&#38754;&#25552;&#21462;&#12289;&#26041;&#38754;&#26497;&#24615;&#20998;&#31867;&#12289;&#24847;&#35265;&#25552;&#21462;&#12289;&#24773;&#24863;&#20998;&#26512;&#12289;&#24773;&#24863;&#24378;&#24230;&#25490;&#24207;&#12289;&#24773;&#32490;&#24378;&#24230;&#25490;&#24207;&#12289;&#33258;&#26432;&#20542;&#21521;&#26816;&#27979;&#12289;&#27602;&#24615;&#26816;&#27979;&#12289;&#31119;&#31049;&#35780;&#20272;&#12289;&#21442;&#19982;&#24230;&#27979;&#37327;&#12289;&#20154;&#26684;&#35780;&#20272;&#12289;&#35773;&#21050;&#26816;&#27979;&#21644;&#20027;&#35266;&#24615;&#26816;&#27979;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#35780;&#20272;ChatGPT&#27169;&#22411;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#26694;&#26550;&#65292;&#27604;&#22914;&#24378;&#24230;&#25490;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rise of foundation models, a new artificial intelligence paradigm has emerged, by simply using general purpose foundation models with prompting to solve problems instead of training a separate machine learning model for each problem. Such models have been shown to have emergent properties of solving problems that they were not initially trained on. The studies for the effectiveness of such models are still quite limited. In this work, we widely study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13 affective computing problems, namely aspect extraction, aspect polarity classification, opinion extraction, sentiment analysis, sentiment intensity ranking, emotions intensity ranking, suicide tendency detection, toxicity detection, well-being assessment, engagement measurement, personality assessment, sarcasm detection, and subjectivity detection. We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking p
&lt;/p&gt;</description></item><item><title>LMSanitator&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#28040;&#38500;Transformer&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#19981;&#21487;&#30693;&#21518;&#38376;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;LMSanitator&#36890;&#36807;&#36870;&#36716;&#39044;&#23450;&#20041;&#30340;&#25915;&#20987;&#21521;&#37327;&#32780;&#19981;&#26159;&#35302;&#21457;&#22120;&#65292;&#23454;&#29616;&#26356;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#21644;&#21518;&#38376;&#26816;&#27979;&#31934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.13904</link><description>&lt;p&gt;
LMSanitator: &#38024;&#23545;&#20219;&#21153;&#19981;&#21487;&#30693;&#21518;&#38376;&#30340;Prompt-Tuning&#38450;&#24481;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors. (arXiv:2308.13904v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13904
&lt;/p&gt;
&lt;p&gt;
LMSanitator&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#28040;&#38500;Transformer&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#19981;&#21487;&#30693;&#21518;&#38376;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;LMSanitator&#36890;&#36807;&#36870;&#36716;&#39044;&#23450;&#20041;&#30340;&#25915;&#20987;&#21521;&#37327;&#32780;&#19981;&#26159;&#35302;&#21457;&#22120;&#65292;&#23454;&#29616;&#26356;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#21644;&#21518;&#38376;&#26816;&#27979;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Prompt-Tuning&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24341;&#20154;&#27880;&#30446;&#30340;&#33539;&#24335;&#65292;&#29992;&#20110;&#37096;&#32626;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#24378;&#22823;&#30340;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#21644;&#39640;&#25928;&#30340;&#22810;&#20219;&#21153;&#26381;&#21153;&#33021;&#21147;&#12290;&#23613;&#31649;&#23427;&#34987;&#24191;&#27867;&#37319;&#29992;&#65292;&#25105;&#20204;&#23454;&#35777;&#34920;&#26126;&#65292;Prompt-Tuning&#23481;&#26131;&#21463;&#21040;&#20219;&#21153;&#19981;&#21487;&#30693;&#21518;&#38376;&#30340;&#25915;&#20987;&#65292;&#36825;&#20123;&#21518;&#38376;&#23384;&#22312;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#65292;&#21487;&#20197;&#24433;&#21709;&#20219;&#24847;&#30340;&#19979;&#28216;&#20219;&#21153;&#12290;&#30446;&#21069;&#30340;&#21518;&#38376;&#26816;&#27979;&#26041;&#27861;&#26080;&#27861;&#38450;&#24481;&#20219;&#21153;&#19981;&#21487;&#30693;&#21518;&#38376;&#65292;&#22240;&#20026;&#23427;&#20204;&#24456;&#38590;&#22312;&#36870;&#36716;&#21518;&#38376;&#35302;&#21457;&#22120;&#26041;&#38754;&#25910;&#25947;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LMSanitator&#65292;&#19968;&#31181;&#22312;Transformer&#27169;&#22411;&#19978;&#26816;&#27979;&#21644;&#21435;&#38500;&#20219;&#21153;&#19981;&#21487;&#30693;&#21518;&#38376;&#30340;&#26032;&#26041;&#27861;&#12290;LMSanitator&#19981;&#30452;&#25509;&#36870;&#36716;&#35302;&#21457;&#22120;&#65292;&#32780;&#26159;&#36870;&#36716;&#39044;&#23450;&#20041;&#30340;&#25915;&#20987;&#21521;&#37327;&#65288;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#36755;&#20837;&#23884;&#20837;&#35302;&#21457;&#22120;&#26102;&#30340;&#36755;&#20986;&#65289;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#21644;&#21518;&#38376;&#26816;&#27979;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prompt-tuning has emerged as an attractive paradigm for deploying large-scale language models due to its strong downstream task performance and efficient multitask serving ability. Despite its wide adoption, we empirically show that prompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside in the pretrained models and can affect arbitrary downstream tasks. The state-of-the-art backdoor detection approaches cannot defend against task-agnostic backdoors since they hardly converge in reversing the backdoor triggers. To address this issue, we propose LMSanitator, a novel approach for detecting and removing task-agnostic backdoors on Transformer models. Instead of directly inversing the triggers, LMSanitator aims to inverse the predefined attack vectors (pretrained models' output when the input is embedded with triggers) of the task-agnostic backdoors, which achieves much better convergence performance and backdoor detection accuracy. LMSanitator further leverages prom
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#38382;&#39064;&#31867;&#22411;&#20998;&#31867;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;&#65292;&#36890;&#36807;&#38598;&#25104;&#22810;&#31181;&#26041;&#27861;&#26469;&#25552;&#39640;&#35299;&#20915;&#33021;&#21147;&#65292;&#24182;&#19988;&#21033;&#29992;&#38598;&#25104;&#25216;&#26415;&#25552;&#39640;&#22522;&#20110;&#26641;&#30340;&#27714;&#35299;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.13844</link><description>&lt;p&gt;
&#20351;&#29992;&#38382;&#39064;&#31867;&#22411;&#20998;&#31867;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Math Word Problem with Problem Type Classification. (arXiv:2308.13844v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13844
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#38382;&#39064;&#31867;&#22411;&#20998;&#31867;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;&#65292;&#36890;&#36807;&#38598;&#25104;&#22810;&#31181;&#26041;&#27861;&#26469;&#25552;&#39640;&#35299;&#20915;&#33021;&#21147;&#65292;&#24182;&#19988;&#21033;&#29992;&#38598;&#25104;&#25216;&#26415;&#25552;&#39640;&#22522;&#20110;&#26641;&#30340;&#27714;&#35299;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23398;&#24212;&#29992;&#39064;&#38656;&#35201;&#20998;&#26512;&#25991;&#26412;&#25551;&#36848;&#24182;&#29983;&#25104;&#25968;&#23398;&#26041;&#31243;&#26469;&#25512;&#23548;&#35299;&#20915;&#26041;&#26696;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#36890;&#36807;&#22522;&#20110;&#26641;&#30340;&#27714;&#35299;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24635;&#26159;&#36890;&#36807;&#21333;&#19968;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;&#65292;&#20250;&#24102;&#26469;&#20197;&#19979;&#38382;&#39064;&#65306;(1) &#21333;&#19968;&#31867;&#22411;&#30340;&#27714;&#35299;&#22120;&#38590;&#20197;&#24456;&#22909;&#22320;&#35299;&#20915;&#25152;&#26377;&#31867;&#22411;&#30340;&#25968;&#23398;&#24212;&#29992;&#39064;&#12290; (2) &#21333;&#19968;&#27714;&#35299;&#22120;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#65292;&#24615;&#33021;&#19981;&#20339;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#21033;&#29992;&#22810;&#31181;&#38598;&#25104;&#26041;&#27861;&#26469;&#25552;&#39640;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;&#30340;&#33021;&#21147;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#31867;&#22411;&#20998;&#31867;&#22120;&#65292;&#32467;&#21512;&#20102;&#22522;&#20110;&#26641;&#30340;&#27714;&#35299;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27714;&#35299;&#22120;&#30340;&#20248;&#21183;&#12290;&#36825;&#31181;&#38598;&#25104;&#26041;&#27861;&#21033;&#29992;&#23427;&#20204;&#21508;&#33258;&#30340;&#20248;&#28857;&#65292;&#25193;&#22823;&#20102;&#21487;&#20197;&#35299;&#20915;&#30340;&#25968;&#23398;&#24212;&#29992;&#39064;&#30340;&#33539;&#22260;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#38598;&#25104;&#25216;&#26415;&#24212;&#29992;&#20110;&#22522;&#20110;&#26641;&#30340;&#27714;&#35299;&#22120;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27714;&#35299;&#22120;&#65292;&#20197;&#25552;&#39640;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Math word problems (MWPs) require analyzing text descriptions and generating mathematical equations to derive solutions. Existing works focus on solving MWPs with two types of solvers: tree-based solver and large language model (LLM) solver. However, these approaches always solve MWPs by a single solver, which will bring the following problems: (1) Single type of solver is hard to solve all types of MWPs well. (2) A single solver will result in poor performance due to over-fitting. To address these challenges, this paper utilizes multiple ensemble approaches to improve MWP-solving ability. Firstly, We propose a problem type classifier that combines the strengths of the tree-based solver and the LLM solver. This ensemble approach leverages their respective advantages and broadens the range of MWPs that can be solved. Furthermore, we also apply ensemble techniques to both tree-based solver and LLM solver to improve their performance. For the tree-based solver, we propose an ensemble lear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36923;&#36753;&#22270;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;Logical-GLM&#65292;&#29992;&#20110;&#25351;&#23548;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20855;&#26377;&#27491;&#30830;&#36923;&#36753;&#30340;&#25991;&#26412;&#65292;&#24182;&#20197;&#25552;&#39640;&#25991;&#26412;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Logical-GLM&#22312;&#20351;&#29992;&#36739;&#23569;&#25968;&#25454;&#21644;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#21644;&#39640;&#25928;&#12290;</title><link>http://arxiv.org/abs/2308.13782</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#36923;&#36753;&#22270;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25351;&#20196;&#29983;&#25104;&#30340;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Planning with Logical Graph-based Language Model for Instruction Generation. (arXiv:2308.13782v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36923;&#36753;&#22270;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;Logical-GLM&#65292;&#29992;&#20110;&#25351;&#23548;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20855;&#26377;&#27491;&#30830;&#36923;&#36753;&#30340;&#25991;&#26412;&#65292;&#24182;&#20197;&#25552;&#39640;&#25991;&#26412;&#29983;&#25104;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Logical-GLM&#22312;&#20351;&#29992;&#36739;&#23569;&#25968;&#25454;&#21644;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#21644;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#33258;&#28982;&#35821;&#35328;&#25991;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#20294;&#30001;&#20110;&#31070;&#32463;&#27169;&#22411;&#38590;&#20197;&#20174;&#33258;&#30001;&#24418;&#24335;&#30340;&#25991;&#26412;&#20013;&#25429;&#25417;&#21040;&#38544;&#21547;&#30340;&#35268;&#21017;&#65292;&#22240;&#27492;&#24456;&#38590;&#29983;&#25104;&#20855;&#26377;&#27491;&#30830;&#36923;&#36753;&#30340;&#25991;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22270;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;Logical-GLM&#65292;&#23558;&#36923;&#36753;&#27880;&#20837;&#35821;&#35328;&#27169;&#22411;&#20197;&#36827;&#34892;&#26356;&#26377;&#25928;&#30340;&#25991;&#26412;&#29983;&#25104;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#20174;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#20013;&#25552;&#21462;&#20449;&#24687;&#24182;&#26500;&#24314;&#36890;&#24120;&#25551;&#36848;&#39046;&#22495;&#30340;&#36923;&#36753;&#36125;&#21494;&#26031;&#22270;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#29983;&#25104;&#36923;&#36753;&#39592;&#26550;&#20197;&#25351;&#23548;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#65292;&#23558;&#39046;&#22495;&#30693;&#35782;&#27880;&#20837;&#35821;&#35328;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20132;&#26367;&#20248;&#21270;&#22270;&#30340;&#25628;&#32034;&#31574;&#30053;&#21644;&#35821;&#35328;&#27169;&#22411;&#65292;&#30452;&#33267;&#25910;&#25947;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Logical-GLM&#19982;&#20256;&#32479;&#35821;&#35328;&#27169;&#22411;&#30456;&#27604;&#65292;&#23613;&#31649;&#20351;&#29992;&#35268;&#27169;&#36739;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#36739;&#23569;&#30340;&#21442;&#25968;&#65292;&#20173;&#28982;&#20855;&#26377;&#26377;&#25928;&#21644;&#39640;&#25928;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#26377;&#25928;&#30340;&#25351;&#20196;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the superior performance of large language models to generate natural language texts, it is hard to generate texts with correct logic according to a given task, due to the difficulties for neural models to capture implied rules from free-form texts. In this paper, we propose a novel graph-based language model, Logical-GLM, to infuse logic into language models for more valid text generation and interpretability. Specifically, we first capture information from natural language instructions and construct logical bayes graphs that generally describe domains. Next, we generate logical skeletons to guide language model training, infusing domain knowledge into language models. Finally, we alternately optimize the searching policy of graphs and language models until convergence. The experimental results show that Logical-GLM is both effective and efficient compared with traditional language models, despite using smaller-scale training data and fewer parameters. Our approach can generat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26816;&#32034;&#21644;&#32534;&#36753;&#30340;&#28304;&#20195;&#30721;&#25688;&#35201;&#26694;&#26550;(EditSum)&#65292;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#32467;&#26500;&#21270;&#12289;&#20449;&#24687;&#20016;&#23500;&#30340;&#20195;&#30721;&#25688;&#35201;&#12290;</title><link>http://arxiv.org/abs/2308.13775</link><description>&lt;p&gt;
EditSum: &#19968;&#31181;&#22522;&#20110;&#26816;&#32034;&#21644;&#32534;&#36753;&#30340;&#28304;&#20195;&#30721;&#25688;&#35201;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
EditSum: A Retrieve-and-Edit Framework for Source Code Summarization. (arXiv:2308.13775v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26816;&#32034;&#21644;&#32534;&#36753;&#30340;&#28304;&#20195;&#30721;&#25688;&#35201;&#26694;&#26550;(EditSum)&#65292;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#32467;&#26500;&#21270;&#12289;&#20449;&#24687;&#20016;&#23500;&#30340;&#20195;&#30721;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#20195;&#30721;&#25688;&#35201;&#26377;&#21161;&#20110;&#24320;&#21457;&#20154;&#21592;&#29702;&#35299;&#21644;&#32500;&#25252;&#28304;&#20195;&#30721;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36719;&#20214;&#39033;&#30446;&#20013;&#32463;&#24120;&#32570;&#20047;&#25110;&#36807;&#26102;&#30340;&#25688;&#35201;&#12290;&#20195;&#30721;&#25688;&#35201;&#26088;&#22312;&#33258;&#21160;&#29983;&#25104;&#28304;&#20195;&#30721;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#12290;&#20195;&#30721;&#25688;&#35201;&#38750;&#24120;&#32467;&#26500;&#21270;&#65292;&#24182;&#20855;&#26377;&#37325;&#22797;&#30340;&#27169;&#24335;&#12290;&#38500;&#20102;&#27169;&#24335;&#21270;&#30340;&#21333;&#35789;&#22806;&#65292;&#20195;&#30721;&#25688;&#35201;&#36824;&#21253;&#21547;&#37325;&#35201;&#30340;&#20851;&#38190;&#35789;&#65292;&#36825;&#20123;&#20851;&#38190;&#35789;&#26159;&#21453;&#26144;&#20195;&#30721;&#21151;&#33021;&#30340;&#20851;&#38190;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#25216;&#26415;&#22312;&#39044;&#27979;&#20851;&#38190;&#35789;&#26041;&#38754;&#34920;&#29616;&#36739;&#24046;&#65292;&#23548;&#33268;&#29983;&#25104;&#30340;&#25688;&#35201;&#20449;&#24687;&#20007;&#22833;&#20102;&#20449;&#24687;&#37327;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EditSum&#30340;&#26032;&#22411;&#26816;&#32034;&#21644;&#32534;&#36753;&#26041;&#27861;&#29992;&#20110;&#20195;&#30721;&#25688;&#35201;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;EditSum&#39318;&#20808;&#20174;&#39044;&#23450;&#20041;&#30340;&#35821;&#26009;&#24211;&#20013;&#26816;&#32034;&#19968;&#20010;&#30456;&#20284;&#30340;&#20195;&#30721;&#29255;&#27573;&#65292;&#24182;&#23558;&#20854;&#25688;&#35201;&#35270;&#20026;&#21407;&#22411;&#25688;&#35201;&#20197;&#23398;&#20064;&#27169;&#24335;&#12290;&#28982;&#21518;&#65292;EditSum&#33258;&#21160;&#32534;&#36753;&#21407;&#22411;&#25688;&#35201;&#65292;&#20197;&#32467;&#21512;&#20854;&#20013;&#30340;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing studies show that code summaries help developers understand and maintain source code. Unfortunately, these summaries are often missing or outdated in software projects. Code summarization aims to generate natural language descriptions automatically for source code. Code summaries are highly structured and have repetitive patterns. Besides the patternized words, a code summary also contains important keywords, which are the key to reflecting the functionality of the code. However, the state-of-the-art approaches perform poorly on predicting the keywords, which leads to the generated summaries suffering a loss in informativeness. To alleviate this problem, this paper proposes a novel retrieve-and-edit approach named EditSum for code summarization. Specifically, EditSum first retrieves a similar code snippet from a pre-defined corpus and treats its summary as a prototype summary to learn the pattern. Then, EditSum edits the prototype automatically to combine the pattern in the pr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#38454;&#27573;&#20248;&#21270;&#25216;&#26415;&#65292;&#20351;&#29992;&#23545;&#25239;&#24615;&#24494;&#35843;&#26469;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24847;&#22806;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#36845;&#20195;&#30340;&#25552;&#31034;&#21644;&#24494;&#35843;&#65292;&#23454;&#29616;&#20102;&#25345;&#32493;&#30340;&#25913;&#36827;&#21644;&#24615;&#33021;&#25552;&#21319;&#65292;&#24182;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#20998;&#31867;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2308.13768</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25932;&#23545;&#24494;&#35843;&#65306;&#38024;&#23545;&#38382;&#39064;&#20869;&#23481;&#29983;&#25104;&#21644;&#26816;&#27979;&#30340;&#36845;&#20195;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content. (arXiv:2308.13768v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#38454;&#27573;&#20248;&#21270;&#25216;&#26415;&#65292;&#20351;&#29992;&#23545;&#25239;&#24615;&#24494;&#35843;&#26469;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24847;&#22806;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#36845;&#20195;&#30340;&#25552;&#31034;&#21644;&#24494;&#35843;&#65292;&#23454;&#29616;&#20102;&#25345;&#32493;&#30340;&#25913;&#36827;&#21644;&#24615;&#33021;&#25552;&#21319;&#65292;&#24182;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#20998;&#31867;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37319;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#38454;&#27573;&#20248;&#21270;&#25216;&#26415;&#65292;&#20351;&#29992;&#23545;&#25239;&#24615;&#24494;&#35843;&#26469;&#24212;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#24847;&#22806;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#23545;&#25239;&#27169;&#22411;&#21644;&#21028;&#21035;&#27169;&#22411;&#20004;&#20010;&#38454;&#27573;&#65292;&#23545;&#25239;&#27169;&#22411;&#34987;&#24494;&#35843;&#29992;&#20110;&#29983;&#25104;&#28508;&#22312;&#26377;&#23475;&#25552;&#31034;&#65292;&#32780;&#21028;&#21035;&#27169;&#22411;&#21017;&#36890;&#36807;&#36845;&#20195;&#20248;&#21270;&#26469;&#35782;&#21035;&#36825;&#20123;&#25552;&#31034;&#12290;&#36890;&#36807;&#23545;&#25239;&#24490;&#29615;&#65292;&#20004;&#20010;&#27169;&#22411;&#22312;&#25552;&#31034;&#38454;&#27573;&#20105;&#30456;&#36229;&#36234;&#23545;&#26041;&#65292;&#29983;&#25104;&#21253;&#21547;&#20016;&#23500;&#31034;&#20363;&#30340;&#25968;&#25454;&#38598;&#65292;&#28982;&#21518;&#29992;&#20110;&#24494;&#35843;&#12290;&#36825;&#31181;&#36845;&#20195;&#24212;&#29992;&#25552;&#31034;&#21644;&#24494;&#35843;&#30340;&#26041;&#27861;&#20351;&#24471;&#25345;&#32493;&#30340;&#25913;&#36827;&#21644;&#24615;&#33021;&#25552;&#21319;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#19968;&#20010;&#21253;&#21547;GPT-4&#26410;&#26816;&#27979;&#21040;&#30340;&#38382;&#39064;&#25552;&#31034;&#21644;&#19968;&#20123;&#26377;&#20105;&#35758;&#20294;&#26080;&#38382;&#39064;&#30340;&#25552;&#31034;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20998;&#31867;&#20934;&#30830;&#24230;&#30340;&#35780;&#20272;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#26174;&#31034;&#22312;&#36825;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#19978;&#65292;&#21028;&#21035;&#27169;&#22411;&#30340;&#20998;&#31867;&#20934;&#30830;&#24230;&#26377;&#20102;&#26174;&#33879;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we tackle the emerging challenge of unintended harmful content generation in Large Language Models (LLMs) with a novel dual-stage optimisation technique using adversarial fine-tuning. Our two-pronged approach employs an adversarial model, fine-tuned to generate potentially harmful prompts, and a judge model, iteratively optimised to discern these prompts. In this adversarial cycle, the two models seek to outperform each other in the prompting phase, generating a dataset of rich examples which are then used for fine-tuning. This iterative application of prompting and fine-tuning allows continuous refinement and improved performance. The performance of our approach is evaluated through classification accuracy on a dataset consisting of problematic prompts not detected by GPT-4, as well as a selection of contentious but unproblematic prompts. We show considerable increase in classification accuracy of the judge model on this challenging dataset as it undergoes the optimisat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22914;&#20309;&#23558;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#20449;&#24687;&#19982;&#25991;&#26723;&#23545;&#35805;&#31995;&#32479;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#27573;&#33853;&#26816;&#32034;&#20219;&#21153;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26377;&#25928;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#26032;&#39062;&#26041;&#27861;PCAS&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;PCAS&#19981;&#20165;&#22312;&#26816;&#32034;&#26368;&#30456;&#20851;&#30340;&#27573;&#33853;&#26041;&#38754;&#20248;&#20110;&#22522;&#20934;&#31995;&#32479;&#65292;&#32780;&#19988;&#22312;&#30830;&#23450;&#30456;&#20851;&#19978;&#19979;&#25991;&#26041;&#38754;&#20063;&#34920;&#29616;&#20986;&#33394;&#12290;&#36825;&#23558;&#28608;&#21457;&#26410;&#26469;&#30740;&#31350;&#30340;&#20852;&#36259;&#12290;</title><link>http://arxiv.org/abs/2308.13760</link><description>&lt;p&gt;
&#22914;&#20309;&#21033;&#29992;&#19978;&#19979;&#25991;&#24110;&#21161;&#65311;&#25506;&#32034;&#27573;&#33853;&#21644;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#30340;&#32852;&#21512;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context. (arXiv:2308.13760v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13760
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22914;&#20309;&#23558;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#20449;&#24687;&#19982;&#25991;&#26723;&#23545;&#35805;&#31995;&#32479;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#27573;&#33853;&#26816;&#32034;&#20219;&#21153;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26377;&#25928;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#26032;&#39062;&#26041;&#27861;PCAS&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;PCAS&#19981;&#20165;&#22312;&#26816;&#32034;&#26368;&#30456;&#20851;&#30340;&#27573;&#33853;&#26041;&#38754;&#20248;&#20110;&#22522;&#20934;&#31995;&#32479;&#65292;&#32780;&#19988;&#22312;&#30830;&#23450;&#30456;&#20851;&#19978;&#19979;&#25991;&#26041;&#38754;&#20063;&#34920;&#29616;&#20986;&#33394;&#12290;&#36825;&#23558;&#28608;&#21457;&#26410;&#26469;&#30740;&#31350;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22806;&#37096;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#20449;&#24687;&#25972;&#21512;&#21040;&#20197;&#25991;&#26723;&#20026;&#22522;&#30784;&#30340;&#23545;&#35805;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#30340;&#21830;&#19994;&#20215;&#20540;&#65292;&#20294;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#36824;&#19981;&#22815;&#28145;&#20837;&#12290;&#21463;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#24863;&#30693;&#25991;&#26723;&#23545;&#35805;&#31995;&#32479;&#30340;&#27010;&#24565;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#27573;&#33853;&#26816;&#32034;&#20219;&#21153;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#19987;&#38376;&#20026;&#27492;&#30446;&#30340;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22810;&#20010;&#22522;&#20934;&#31995;&#32479;&#26469;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21363;&#20010;&#24615;&#21270;&#19978;&#19979;&#25991;&#24863;&#30693;&#25628;&#32034;(Personalized Context-Aware Search&#65292;PCAS)&#65292;&#23427;&#22312;&#27573;&#33853;&#26816;&#32034;&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#22312;&#22810;&#20010;&#27969;&#34892;&#30340;&#31264;&#23494;&#26816;&#32034;&#31995;&#32479;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#22312;&#26816;&#32034;&#26368;&#30456;&#20851;&#30340;&#27573;&#33853;&#26041;&#38754;&#20248;&#20110;&#22522;&#20934;&#31995;&#32479;&#65292;&#32780;&#19988;&#22312;&#30830;&#23450;&#25152;&#26377;&#21487;&#29992;&#19978;&#19979;&#25991;&#20013;&#30340;&#30456;&#20851;&#19978;&#19979;&#25991;&#26041;&#38754;&#20063;&#34920;&#29616;&#20986;&#33394;&#12290;&#25105;&#20204;&#39044;&#35745;&#25105;&#20204;&#30340;&#36129;&#29486;&#23558;&#25104;&#20026;&#28608;&#21169;&#26410;&#26469;&#30740;&#31350;&#30340;&#20652;&#21270;&#21058;&#12290;
&lt;/p&gt;
&lt;p&gt;
The integration of external personalized context information into document-grounded conversational systems has significant potential business value, but has not been well-studied. Motivated by the concept of personalized context-aware document-grounded conversational systems, we introduce the task of context-aware passage retrieval. We also construct a dataset specifically curated for this purpose. We describe multiple baseline systems to address this task, and propose a novel approach, Personalized Context-Aware Search (PCAS), that effectively harnesses contextual information during passage retrieval. Experimental evaluations conducted on multiple popular dense retrieval systems demonstrate that our proposed approach not only outperforms the baselines in retrieving the most relevant passage but also excels at identifying the pertinent context among all the available contexts. We envision that our contributions will serve as a catalyst for inspiring future research endeavors in this pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ZC3&#30340;&#36328;&#35821;&#35328;&#38646;&#26679;&#26412;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#35774;&#35745;&#20102;&#23545;&#27604;&#20195;&#30721;&#29255;&#27573;&#39044;&#27979;&#65292;&#24418;&#25104;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#21516;&#26500;&#34920;&#31034;&#31354;&#38388;&#65292;&#24182;&#21033;&#29992;&#39046;&#22495;&#24863;&#30693;&#23398;&#20064;&#21644;&#24490;&#29615;&#19968;&#33268;&#24615;&#23398;&#20064;&#26469;&#36827;&#19968;&#27493;&#32422;&#26463;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.13754</link><description>&lt;p&gt;
ZC3: &#36328;&#35821;&#35328;&#38646;&#26679;&#26412;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
ZC3: Zero-Shot Cross-Language Code Clone Detection. (arXiv:2308.13754v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13754
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ZC3&#30340;&#36328;&#35821;&#35328;&#38646;&#26679;&#26412;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#35774;&#35745;&#20102;&#23545;&#27604;&#20195;&#30721;&#29255;&#27573;&#39044;&#27979;&#65292;&#24418;&#25104;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#21516;&#26500;&#34920;&#31034;&#31354;&#38388;&#65292;&#24182;&#21033;&#29992;&#39046;&#22495;&#24863;&#30693;&#23398;&#20064;&#21644;&#24490;&#29615;&#19968;&#33268;&#24615;&#23398;&#20064;&#26469;&#36827;&#19968;&#27493;&#32422;&#26463;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20154;&#21592;&#24341;&#20837;&#20195;&#30721;&#20811;&#38534;&#20197;&#25552;&#39640;&#32534;&#31243;&#25928;&#29575;&#12290;&#35768;&#22810;&#29616;&#26377;&#30740;&#31350;&#22312;&#21333;&#35821;&#35328;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#24320;&#21457;&#20154;&#21592;&#20351;&#29992;&#19981;&#21516;&#30340;&#35821;&#35328;&#32534;&#20889;&#35821;&#20041;&#19978;&#31561;&#20215;&#30340;&#31243;&#24207;&#65292;&#20197;&#25903;&#25345;&#19981;&#21516;&#30340;&#24179;&#21488;&#65292;&#24182;&#24110;&#21161;&#24320;&#21457;&#20154;&#21592;&#20174;&#19968;&#31181;&#35821;&#35328;&#32763;&#35793;&#39033;&#30446;&#21040;&#21478;&#19968;&#31181;&#35821;&#35328;&#12290;&#32771;&#34385;&#21040;&#25910;&#38598;&#36328;&#35821;&#35328;&#24182;&#34892;&#25968;&#25454;&#65288;&#23588;&#20854;&#26159;&#20302;&#36164;&#28304;&#35821;&#35328;&#65289;&#30340;&#25104;&#26412;&#39640;&#26114;&#19988;&#32791;&#26102;&#65292;&#35774;&#35745;&#19968;&#31181;&#19981;&#20381;&#36182;&#20219;&#20309;&#24182;&#34892;&#25968;&#25454;&#30340;&#26377;&#25928;&#36328;&#35821;&#35328;&#27169;&#22411;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ZC3&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#20195;&#30721;&#20811;&#38534;&#26816;&#27979;&#12290;ZC3&#36890;&#36807;&#35774;&#35745;&#23545;&#27604;&#20195;&#30721;&#29255;&#27573;&#39044;&#27979;&#26469;&#24418;&#25104;&#19981;&#21516;&#32534;&#31243;&#35821;&#35328;&#20043;&#38388;&#30340;&#21516;&#26500;&#34920;&#31034;&#31354;&#38388;&#12290;&#22522;&#20110;&#27492;&#65292;ZC3&#21033;&#29992;&#39046;&#22495;&#24863;&#30693;&#23398;&#20064;&#21644;&#24490;&#29615;&#19968;&#33268;&#24615;&#23398;&#20064;&#36827;&#19968;&#27493;&#32422;&#26463;&#27169;&#22411;&#20197;&#29983;&#25104;&#34920;&#36798;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developers introduce code clones to improve programming productivity. Many existing studies have achieved impressive performance in monolingual code clone detection. However, during software development, more and more developers write semantically equivalent programs with different languages to support different platforms and help developers translate projects from one language to another. Considering that collecting cross-language parallel data, especially for low-resource languages, is expensive and time-consuming, how designing an effective cross-language model that does not rely on any parallel data is a significant problem. In this paper, we propose a novel method named ZC3 for Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive snippet prediction to form an isomorphic representation space among different programming languages. Based on this, ZC3 exploits domain-aware learning and cycle consistency learning to further constrain the model to generate represen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#21746;&#23398;&#12289;&#24515;&#29702;&#23398;&#19982;&#25968;&#23398;&#30456;&#32467;&#21512;&#30340;Philomatics&#21644;Psychomatics&#27010;&#24565;&#65292;&#24182;&#35299;&#37322;&#20102;&#22235;&#20010;&#21160;&#26426;&#65306;&#28385;&#36275;&#20998;&#26512;&#21746;&#23398;&#30340;&#38656;&#27714;&#12289;&#25552;&#20986;&#21746;&#23398;&#31185;&#23398;&#12289;&#29992;&#21746;&#23398;&#26469;&#35777;&#26126;&#25968;&#23398;&#31639;&#27861;&#20197;&#21450;&#21746;&#23398;&#21644;&#25968;&#23398;&#30340;&#25277;&#35937;&#12290;&#24182;&#21015;&#20030;&#20102;&#22810;&#20010;&#31034;&#20363;&#65292;&#21253;&#25324;&#25968;&#23398;&#20013;&#27880;&#24847;&#26426;&#21046;&#21644;&#19978;&#19979;&#25991;&#21407;&#21017;&#12289;&#24418;&#24335;&#29702;&#35770;&#19982;&#20840;&#24687;&#21407;&#29702;&#30340;&#20851;&#31995;&#31561;&#12290;&#26412;&#25991;&#20026;&#23558;&#21746;&#23398;&#21644;&#24515;&#29702;&#23398;&#19982;&#25968;&#23398;&#30456;&#32467;&#21512;&#30340;&#30740;&#31350;&#24320;&#36767;&#20102;&#30740;&#31350;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2308.13738</link><description>&lt;p&gt;
&#20851;&#20110;&#23558;&#21746;&#23398;&#12289;&#24515;&#29702;&#23398;&#19982;&#25968;&#23398;&#30456;&#32467;&#21512;&#30340;Philomatics&#21644;Psychomatics&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Philomatics and Psychomatics for Combining Philosophy and Psychology with Mathematics. (arXiv:2308.13738v1 [math.HO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#21746;&#23398;&#12289;&#24515;&#29702;&#23398;&#19982;&#25968;&#23398;&#30456;&#32467;&#21512;&#30340;Philomatics&#21644;Psychomatics&#27010;&#24565;&#65292;&#24182;&#35299;&#37322;&#20102;&#22235;&#20010;&#21160;&#26426;&#65306;&#28385;&#36275;&#20998;&#26512;&#21746;&#23398;&#30340;&#38656;&#27714;&#12289;&#25552;&#20986;&#21746;&#23398;&#31185;&#23398;&#12289;&#29992;&#21746;&#23398;&#26469;&#35777;&#26126;&#25968;&#23398;&#31639;&#27861;&#20197;&#21450;&#21746;&#23398;&#21644;&#25968;&#23398;&#30340;&#25277;&#35937;&#12290;&#24182;&#21015;&#20030;&#20102;&#22810;&#20010;&#31034;&#20363;&#65292;&#21253;&#25324;&#25968;&#23398;&#20013;&#27880;&#24847;&#26426;&#21046;&#21644;&#19978;&#19979;&#25991;&#21407;&#21017;&#12289;&#24418;&#24335;&#29702;&#35770;&#19982;&#20840;&#24687;&#21407;&#29702;&#30340;&#20851;&#31995;&#31561;&#12290;&#26412;&#25991;&#20026;&#23558;&#21746;&#23398;&#21644;&#24515;&#29702;&#23398;&#19982;&#25968;&#23398;&#30456;&#32467;&#21512;&#30340;&#30740;&#31350;&#24320;&#36767;&#20102;&#30740;&#31350;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#23558;&#21746;&#23398;&#12289;&#24515;&#29702;&#23398;&#19982;&#25968;&#23398;&#30456;&#32467;&#21512;&#30340;Philomatics&#21644;Psychomatics&#27010;&#24565;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#36825;&#31181;&#32467;&#21512;&#30340;&#22235;&#20010;&#21160;&#26426;&#65292;&#21253;&#25324;&#28385;&#36275;&#20998;&#26512;&#21746;&#23398;&#30340;&#38656;&#27714;&#12289;&#25552;&#20986;&#21746;&#23398;&#31185;&#23398;&#12289;&#29992;&#21746;&#23398;&#26469;&#35777;&#26126;&#25968;&#23398;&#31639;&#27861;&#20197;&#21450;&#21746;&#23398;&#21644;&#25968;&#23398;&#30340;&#25277;&#35937;&#12290;&#25105;&#20204;&#21015;&#20030;&#20102;&#21508;&#31181;Philomatics&#21644;Psychomatics&#30340;&#31034;&#20363;&#65292;&#20854;&#20013;&#19968;&#20123;&#22312;&#26356;&#28145;&#20837;&#22320;&#35299;&#37322;&#12290;&#31532;&#19968;&#20010;&#31034;&#20363;&#26159;&#20851;&#20110;&#25968;&#23398;&#20013;&#27880;&#24847;&#26426;&#21046;&#19982;&#19978;&#19979;&#25991;&#21407;&#21017;&#12289;&#35821;&#20041;&#25972;&#20307;&#20027;&#20041;&#21644;&#20351;&#29992;&#29702;&#35770;&#30340;&#20851;&#31995;&#20998;&#26512;&#12290;&#21478;&#19968;&#20010;&#31034;&#20363;&#26159;&#20851;&#20110;&#21746;&#23398;&#20013;&#26575;&#25289;&#22270;&#30340;&#24418;&#24335;&#29702;&#35770;&#19982;&#24358;&#29702;&#35770;&#20013;&#30340;&#20840;&#24687;&#21407;&#29702;&#12289;&#38754;&#21521;&#23545;&#35937;&#32534;&#31243;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#20851;&#31995;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#32500;&#29305;&#26681;&#26031;&#22374;&#30340;&#23478;&#26063;&#30456;&#20284;&#24615;&#19982;&#25968;&#23398;&#20013;&#30340;&#32858;&#31867;&#30340;&#20851;&#31995;&#12290;&#26412;&#25991;&#20026;&#23558;&#21746;&#23398;&#21644;&#24515;&#29702;&#23398;&#19982;&#25968;&#23398;&#30456;&#32467;&#21512;&#30340;&#30740;&#31350;&#25171;&#24320;&#20102;&#22823;&#38376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose the concepts of philomatics and psychomatics as hybrid combinations of philosophy and psychology with mathematics. We explain four motivations for this combination which are fulfilling the desire of analytical philosophy, proposing science of philosophy, justifying mathematical algorithms by philosophy, and abstraction in both philosophy and mathematics. We enumerate various examples for philomatics and psychomatics, some of which are explained in more depth. The first example is the analysis of relation between the context principle, semantic holism, and the usage theory of meaning with the attention mechanism in mathematics. The other example is on the relations of Plato's theory of forms in philosophy with the holographic principle in string theory, object-oriented programming, and machine learning. Finally, the relation between Wittgenstein's family resemblance and clustering in mathematics is explained. This paper opens the door of research for combining philosophy and 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#37327;&#21270;&#35780;&#20272;&#21487;&#21809;&#27468;&#35789;&#32763;&#35793;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#32771;&#37327;&#38899;&#20048;&#12289;&#35821;&#35328;&#21644;&#25991;&#21270;&#32500;&#24230;&#65292;&#30740;&#31350;&#27468;&#35789;&#30340;&#38899;&#33410;&#12289;&#38899;&#32032;&#12289;&#38899;&#20048;&#32467;&#26500;&#21644;&#35821;&#20041;&#31561;&#26041;&#38754;&#30340;&#30456;&#20284;&#24615;&#25351;&#26631;&#65292;&#25581;&#31034;&#20102;&#26500;&#25104;&#21487;&#21809;&#27468;&#35789;&#32763;&#35793;&#30340;&#20851;&#38190;&#35201;&#32032;&#12290;</title><link>http://arxiv.org/abs/2308.13715</link><description>&lt;p&gt;
&#12298;&#19968;&#31181;&#29992;&#20110;&#21487;&#21809;&#27468;&#35789;&#32763;&#35793;&#30340;&#35745;&#31639;&#35780;&#20272;&#26694;&#26550;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Computational Evaluation Framework for Singable Lyric Translation. (arXiv:2308.13715v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13715
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#37327;&#21270;&#35780;&#20272;&#21487;&#21809;&#27468;&#35789;&#32763;&#35793;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#32771;&#37327;&#38899;&#20048;&#12289;&#35821;&#35328;&#21644;&#25991;&#21270;&#32500;&#24230;&#65292;&#30740;&#31350;&#27468;&#35789;&#30340;&#38899;&#33410;&#12289;&#38899;&#32032;&#12289;&#38899;&#20048;&#32467;&#26500;&#21644;&#35821;&#20041;&#31561;&#26041;&#38754;&#30340;&#30456;&#20284;&#24615;&#25351;&#26631;&#65292;&#25581;&#31034;&#20102;&#26500;&#25104;&#21487;&#21809;&#27468;&#35789;&#32763;&#35793;&#30340;&#20851;&#38190;&#35201;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27468;&#35789;&#32763;&#35793;&#22312;&#25918;&#22823;&#38899;&#20048;&#30340;&#20840;&#29699;&#20849;&#40483;&#12289;&#24357;&#21512;&#25991;&#21270;&#20998;&#27495;&#21644;&#20419;&#36827;&#26222;&#36941;&#32852;&#31995;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#19982;&#20256;&#32479;&#30340;&#32763;&#35793;&#20219;&#21153;&#19981;&#21516;&#65292;&#27468;&#35789;&#32763;&#35793;&#38656;&#35201;&#22312;&#21487;&#21809;&#24615;&#21644;&#35821;&#20041;&#20043;&#38388;&#20445;&#25345;&#24494;&#22937;&#30340;&#24179;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#37327;&#21270;&#35780;&#20272;&#21487;&#21809;&#27468;&#35789;&#32763;&#35793;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#23558;&#27468;&#35789;&#30340;&#38899;&#20048;&#12289;&#35821;&#35328;&#21644;&#25991;&#21270;&#32500;&#24230;&#26080;&#32541;&#38598;&#25104;&#12290;&#25105;&#20204;&#30340;&#32508;&#21512;&#26694;&#26550;&#21253;&#25324;&#22235;&#20010;&#25351;&#26631;&#65292;&#20998;&#21035;&#34913;&#37327;&#38899;&#33410;&#25968;&#30446;&#36317;&#31163;&#12289;&#38899;&#32032;&#37325;&#22797;&#30456;&#20284;&#24615;&#12289;&#38899;&#20048;&#32467;&#26500;&#36317;&#31163;&#21644;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#20026;&#20102;&#23454;&#35777;&#25105;&#20204;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#22312;&#33521;&#25991;&#12289;&#26085;&#25991;&#21644;&#38889;&#25991;&#30340;&#27468;&#35789;&#19978;&#65292;&#25105;&#20204;&#37319;&#38598;&#20102;&#19968;&#20010;&#21487;&#21809;&#27468;&#35789;&#25968;&#25454;&#38598;&#65292;&#24182;&#23545;&#21487;&#21809;&#21644;&#19981;&#21487;&#21809;&#27468;&#35789;&#36827;&#34892;&#20102;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#36328;&#23398;&#31185;&#26041;&#27861;&#25581;&#31034;&#20102;&#26500;&#25104;&#21487;&#21809;&#27468;&#35789;&#32763;&#35793;&#30340;&#20851;&#38190;&#35201;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lyric translation plays a pivotal role in amplifying the global resonance of music, bridging cultural divides, and fostering universal connections. Translating lyrics, unlike conventional translation tasks, requires a delicate balance between singability and semantics. In this paper, we present a computational framework for the quantitative evaluation of singable lyric translation, which seamlessly integrates musical, linguistic, and cultural dimensions of lyrics. Our comprehensive framework consists of four metrics that measure syllable count distance, phoneme repetition similarity, musical structure distance, and semantic similarity. To substantiate the efficacy of our framework, we collected a singable lyrics dataset, which precisely aligns English, Japanese, and Korean lyrics on a line-by-line and section-by-section basis, and conducted a comparative analysis between singable and non-singable lyrics. Our multidisciplinary approach provides insights into the key components that unde
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;Reddit&#20869;&#23481;&#20013;&#35782;&#21035;&#20581;&#24247;&#32500;&#24230;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#22797;&#26434;&#30340;&#31934;&#31070;&#20581;&#24247;&#20998;&#26512;&#12290;&#20182;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;WELLXPLAIN&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#21046;&#23450;&#20102;&#19968;&#20010;&#27880;&#37322;&#26694;&#26550;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#35782;&#21035;&#28508;&#22312;&#30340;&#31934;&#31070;&#38382;&#39064;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2308.13710</link><description>&lt;p&gt;
WellXplain: Reddit&#24086;&#23376;&#20013;&#30340;&#20581;&#24247;&#27010;&#24565;&#25552;&#21462;&#21644;&#20998;&#31867;&#65292;&#29992;&#20110;&#31934;&#31070;&#20581;&#24247;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
WellXplain: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health Analysis. (arXiv:2308.13710v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;Reddit&#20869;&#23481;&#20013;&#35782;&#21035;&#20581;&#24247;&#32500;&#24230;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#22797;&#26434;&#30340;&#31934;&#31070;&#20581;&#24247;&#20998;&#26512;&#12290;&#20182;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;WELLXPLAIN&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#21046;&#23450;&#20102;&#19968;&#20010;&#27880;&#37322;&#26694;&#26550;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#35782;&#21035;&#28508;&#22312;&#30340;&#31934;&#31070;&#38382;&#39064;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#21069;&#30340;&#31934;&#31070;&#20581;&#24247;&#21361;&#26426;&#20013;&#65292;&#20174;&#31038;&#20132;&#23186;&#20307;&#20869;&#23481;&#20013;&#35782;&#21035;&#28508;&#22312;&#30340;&#31934;&#31070;&#38382;&#39064;&#25351;&#26631;&#30340;&#37325;&#35201;&#24615;&#26377;&#25152;&#22686;&#21152;&#12290;&#24573;&#35270;&#31934;&#31070;&#21644;&#31038;&#20250;&#24184;&#31119;&#30340;&#22810;&#38754;&#24615;&#21487;&#33021;&#23545;&#19968;&#20010;&#20154;&#30340;&#31934;&#31070;&#29366;&#24577;&#20135;&#29983;&#26377;&#23475;&#24433;&#21709;&#12290;&#22312;&#20256;&#32479;&#30340;&#27835;&#30103;&#36807;&#31243;&#20013;&#65292;&#19987;&#19994;&#20154;&#21592;&#38656;&#35201;&#25163;&#21160;&#30830;&#23450;&#28508;&#22312;&#31934;&#31070;&#25361;&#25112;&#30340;&#36215;&#28304;&#21644;&#32467;&#26524;&#65292;&#36825;&#26159;&#19968;&#20010;&#35814;&#32454;&#32780;&#32791;&#26102;&#30340;&#36807;&#31243;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;Reddit&#20869;&#23481;&#20013;&#30340;&#20581;&#24247;&#32500;&#24230;&#35782;&#21035;&#20026;&#20581;&#24247;&#27010;&#24565;&#25552;&#21462;&#21644;&#20998;&#31867;&#30340;&#25361;&#25112;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#22797;&#26434;&#30340;&#31934;&#31070;&#20581;&#24247;&#20998;&#26512;&#26041;&#27861;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#21517;&#20026;WELLXPLAIN&#30340;&#29420;&#29305;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;3,092&#20010;&#26465;&#30446;&#65292;&#24635;&#35745;72,813&#20010;&#21333;&#35789;&#12290;&#22522;&#20110;&#21704;&#23572;&#20271;&#29305;&#183;L&#183;&#37011;&#24681;&#30340;&#33879;&#21517;&#20581;&#24247;&#29702;&#35770;&#65292;&#25105;&#20204;&#30340;&#22242;&#38431;&#21046;&#23450;&#20102;&#19968;&#20010;&#27880;&#37322;&#26694;&#26550;&#21644;&#25351;&#21335;&#12290;&#35813;&#25968;&#25454;&#38598;&#36824;&#21253;&#25324;&#20154;&#24037;&#26631;&#35760;&#30340;&#25991;&#26412;&#29255;&#27573;&#65292;&#28165;&#26970;&#35299;&#37322;&#20102;&#20581;&#24247;&#27010;&#24565;&#20998;&#31867;&#20915;&#31574;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
During the current mental health crisis, the importance of identifying potential indicators of mental issues from social media content has surged. Overlooking the multifaceted nature of mental and social well-being can have detrimental effects on one's mental state. In traditional therapy sessions, professionals manually pinpoint the origins and outcomes of underlying mental challenges, a process both detailed and time-intensive. We introduce an approach to this intricate mental health analysis by framing the identification of wellness dimensions in Reddit content as a wellness concept extraction and categorization challenge. We've curated a unique dataset named WELLXPLAIN, comprising 3,092 entries and totaling 72,813 words. Drawing from Halbert L. Dunn's well-regarded wellness theory, our team formulated an annotation framework along with guidelines. This dataset also includes human-marked textual segments, offering clear reasoning for decisions made in the wellness concept categoriza
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26463;&#25628;&#32034;&#21644;&#31351;&#20030;&#25628;&#32034;&#20043;&#38388;&#19968;&#31995;&#21015;&#19981;&#21516;&#30340;&#25628;&#32034;&#28145;&#24230;&#65292;&#25552;&#20986;&#20102;&#21069;&#30651;&#26463;&#25628;&#32034;&#65288;LBS&#65289;&#31639;&#27861;&#36827;&#34892;&#20248;&#21270;&#12290;&#23613;&#31649;&#26463;&#25628;&#32034;&#30340;&#25628;&#32034;&#35823;&#24046;&#36739;&#39640;&#65292;&#20294;&#22312;&#35745;&#31639;&#25104;&#26412;&#21644;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#31351;&#20030;&#25628;&#32034;&#12290;</title><link>http://arxiv.org/abs/2308.13696</link><description>&lt;p&gt;
&#20851;&#20110;&#25991;&#26412;&#29983;&#25104;&#20013;&#30340;&#26463;&#25628;&#32034;&#21644;&#31351;&#20030;&#25628;&#32034;&#30340;&#28145;&#24230;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Depth between Beam Search and Exhaustive Search for Text Generation. (arXiv:2308.13696v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13696
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#26463;&#25628;&#32034;&#21644;&#31351;&#20030;&#25628;&#32034;&#20043;&#38388;&#19968;&#31995;&#21015;&#19981;&#21516;&#30340;&#25628;&#32034;&#28145;&#24230;&#65292;&#25552;&#20986;&#20102;&#21069;&#30651;&#26463;&#25628;&#32034;&#65288;LBS&#65289;&#31639;&#27861;&#36827;&#34892;&#20248;&#21270;&#12290;&#23613;&#31649;&#26463;&#25628;&#32034;&#30340;&#25628;&#32034;&#35823;&#24046;&#36739;&#39640;&#65292;&#20294;&#22312;&#35745;&#31639;&#25104;&#26412;&#21644;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#31351;&#20030;&#25628;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26463;&#25628;&#32034;&#21644;&#31351;&#20030;&#25628;&#32034;&#26159;&#25991;&#26412;&#35299;&#30721;&#31639;&#27861;&#20013;&#28145;&#24230;&#25628;&#32034;&#30340;&#20004;&#20010;&#26497;&#31471;&#12290;&#26463;&#25628;&#32034;&#22312;&#25628;&#32034;&#23485;&#24230;&#21644;&#28145;&#24230;&#19978;&#37117;&#26377;&#38480;&#21046;&#65292;&#32780;&#31351;&#20030;&#25628;&#32034;&#26159;&#20840;&#23616;&#25628;&#32034;&#65292;&#27809;&#26377;&#36825;&#20123;&#38480;&#21046;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23613;&#31649;&#26463;&#25628;&#32034;&#30340;&#25628;&#32034;&#35823;&#24046;&#36739;&#39640;&#65292;&#20294;&#23427;&#19981;&#20165;&#35745;&#31639;&#25104;&#26412;&#26356;&#20302;&#65292;&#32780;&#19988;&#34920;&#29616;&#26356;&#22909;&#12290;&#35768;&#22810;&#30740;&#31350;&#23545;&#19968;&#31995;&#21015;&#19981;&#21516;&#30340;&#26463;&#23485;&#24230;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#24182;&#25253;&#21578;&#31216;&#26082;&#19981;&#22826;&#22823;&#20063;&#19981;&#22826;&#23567;&#30340;&#26463;&#23485;&#24230;&#26159;&#29702;&#24819;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#25628;&#32034;&#28145;&#24230;&#26041;&#38754;&#65292;&#21482;&#26377;&#26463;&#25628;&#32034;&#21644;&#31351;&#20030;&#25628;&#32034;&#36825;&#20004;&#20010;&#26497;&#31471;&#24471;&#21040;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20171;&#20110;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#30340;&#19968;&#31995;&#21015;&#25628;&#32034;&#28145;&#24230;&#65292;&#20197;&#21457;&#29616;&#29702;&#24819;&#30340;&#25628;&#32034;&#28145;&#24230;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21069;&#30651;&#26463;&#25628;&#32034;&#65288;LBS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22810;&#27493;&#21069;&#30651;&#25628;&#32034;&#65292;&#36890;&#36807;&#32771;&#34385;&#26410;&#26469;&#22266;&#23450;&#27493;&#25968;&#26469;&#20248;&#21270;&#30446;&#26631;&#12290;&#26463;&#25628;&#32034;&#21644;&#31351;&#20030;&#25628;&#32034;&#26159;&#29305;&#27530;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Beam search and exhaustive search are two extreme ends of text decoding algorithms with respect to the search depth. Beam search is limited in both search width and depth, whereas exhaustive search is a global search that has no such limitations. Surprisingly, beam search is not only computationally cheaper but also performs better than exhaustive search despite its higher search error. Plenty of research has investigated a range of beam widths, from small to large, and reported that a beam width that is neither too large nor too small is desirable. However, in terms of search depth, only the two extreme ends, beam search and exhaustive search are studied intensively. In this paper, we examine a range of search depths between the two extremes to discover the desirable search depth. To this end, we introduce Lookahead Beam Search (LBS), a multi-step lookahead search that optimizes the objective considering a fixed number of future steps. Beam search and exhaustive search are special cas
&lt;/p&gt;</description></item><item><title>&#32842;&#22825;&#26426;&#22120;&#20154;&#29983;&#25104;&#20102;150&#19975;&#20010;&#26448;&#26009;&#21465;&#36848;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#20998;&#23545;&#27604;&#65292;&#21457;&#29616;&#20154;&#31867;&#35780;&#20998;&#20013;&#30340;&#20869;&#23481;&#28145;&#24230;&#30456;&#23545;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2308.13687</link><description>&lt;p&gt;
&#32842;&#22825;&#26426;&#22120;&#20154;&#29983;&#25104;&#20102;150&#19975;&#20010;&#26448;&#26009;&#21465;&#36848;
&lt;/p&gt;
&lt;p&gt;
1.5 million materials narratives generated by chatbots. (arXiv:2308.13687v1 [cond-mat.mtrl-sci])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13687
&lt;/p&gt;
&lt;p&gt;
&#32842;&#22825;&#26426;&#22120;&#20154;&#29983;&#25104;&#20102;150&#19975;&#20010;&#26448;&#26009;&#21465;&#36848;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#35780;&#20998;&#23545;&#27604;&#65292;&#21457;&#29616;&#20154;&#31867;&#35780;&#20998;&#20013;&#30340;&#20869;&#23481;&#28145;&#24230;&#30456;&#23545;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30340;&#20986;&#29616;&#20351;&#24471;&#26448;&#26009;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#20840;&#38754;&#30340;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#24448;&#24448;&#20248;&#20808;&#36873;&#25321;&#22312;&#31185;&#23398;&#25991;&#29486;&#20013;&#32463;&#24120;&#36935;&#21040;&#30340;&#26448;&#26009;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#22522;&#20110;&#29289;&#29702;&#21644;&#21270;&#23398;&#29305;&#24615;&#36873;&#25321;&#36866;&#24403;&#20505;&#36873;&#26448;&#26009;&#30340;&#33539;&#22260;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;OQMD&#12289;Materials Project&#12289;JARVIS&#12289;COD&#21644;AFLOW2&#25968;&#25454;&#24211;&#29983;&#25104;&#20102;&#19968;&#20010;&#30001;1494017&#20010;&#33258;&#28982;&#35821;&#35328;-&#26448;&#26009;&#27573;&#33853;&#32452;&#25104;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21344;&#20027;&#23548;&#22320;&#20301;&#30340;&#26159;&#20174;&#22836;&#35745;&#31639;&#65292;&#24182;&#22312;&#21608;&#26399;&#34920;&#19978;&#30340;&#20998;&#24067;&#26356;&#21152;&#22343;&#21248;&#12290;&#29983;&#25104;&#30340;&#25991;&#26412;&#21465;&#36848;&#38543;&#21518;&#30001;&#20154;&#31867;&#19987;&#23478;&#21644;ChatGPT-4&#36827;&#34892;&#25237;&#31080;&#21644;&#35780;&#20998;&#65292;&#35780;&#20998;&#26631;&#20934;&#21253;&#25324;&#25216;&#26415;&#20934;&#30830;&#24615;&#12289;&#35821;&#35328;&#21644;&#32467;&#26500;&#12289;&#20869;&#23481;&#30340;&#30456;&#20851;&#24615;&#21644;&#28145;&#24230;&#65292;&#32467;&#26524;&#26174;&#31034;&#20004;&#32773;&#24471;&#20998;&#30456;&#20284;&#65292;&#20294;&#20154;&#31867;&#35780;&#20998;&#20013;&#30340;&#20869;&#23481;&#28145;&#24230;&#30456;&#23545;&#36739;&#20302;&#12290;&#22810;&#27169;&#24577;&#25968;&#25454;&#28304;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21512;&#24182;&#20855;&#26377;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of artificial intelligence (AI) has enabled a comprehensive exploration of materials for various applications. However, AI models often prioritize frequently encountered materials in the scientific literature, limiting the selection of suitable candidates based on inherent physical and chemical properties. To address this imbalance, we have generated a dataset of 1,494,017 natural language-material paragraphs based on combined OQMD, Materials Project, JARVIS, COD and AFLOW2 databases, which are dominated by ab initio calculations and tend to be much more evenly distributed on the periodic table. The generated text narratives were then polled and scored by both human experts and ChatGPT-4, based on three rubrics: technical accuracy, language and structure, and relevance and depth of content, showing similar scores but with human-scored depth of content being the most lagging. The merger of multi-modality data sources and large language model (LLM) holds immense potential for 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#19981;&#21516;&#22823;&#23567;&#21644;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#23427;&#20204;&#33021;&#21542;&#28085;&#30422;&#30693;&#35782;&#22270;&#35889;&#30340;&#22797;&#26434;&#25299;&#25169;&#21644;&#35821;&#20041;&#23646;&#24615;&#65292;&#36825;&#23545;&#20110;&#25512;&#29702;&#36807;&#31243;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2308.13676</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#31526;&#21495;&#30693;&#35782;&#22270;&#35889;
&lt;/p&gt;
&lt;p&gt;
Rethinking Language Models as Symbolic Knowledge Graphs. (arXiv:2308.13676v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13676
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#19981;&#21516;&#22823;&#23567;&#21644;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;&#23427;&#20204;&#33021;&#21542;&#28085;&#30422;&#30693;&#35782;&#22270;&#35889;&#30340;&#22797;&#26434;&#25299;&#25169;&#21644;&#35821;&#20041;&#23646;&#24615;&#65292;&#36825;&#23545;&#20110;&#25512;&#29702;&#36807;&#31243;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21495;&#30693;&#35782;&#22270;&#35889;&#22312;&#25628;&#32034;&#12289;&#38382;&#31572;&#21644;&#25512;&#33616;&#31561;&#20197;&#30693;&#35782;&#20026;&#20013;&#24515;&#30340;&#24212;&#29992;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#38543;&#30528;&#24403;&#20195;&#22522;&#20110;&#22823;&#37327;&#25991;&#26412;&#25968;&#25454;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#22686;&#21152;&#65292;&#30740;&#31350;&#20154;&#21592;&#24191;&#27867;&#25506;&#35752;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#21270;&#30693;&#35782;&#26159;&#21542;&#33021;&#22815;&#19982;&#30693;&#35782;&#22270;&#35889;&#20013;&#30340;&#30693;&#35782;&#30456;&#21305;&#37197;&#12290;&#21508;&#31181;&#26041;&#27861;&#34920;&#26126;&#65292;&#22686;&#21152;&#27169;&#22411;&#22823;&#23567;&#25110;&#35757;&#32451;&#25968;&#25454;&#37327;&#21487;&#20197;&#22686;&#24378;&#20854;&#26816;&#32034;&#31526;&#21495;&#30693;&#35782;&#30340;&#33021;&#21147;&#65292;&#36890;&#24120;&#20960;&#20046;&#19981;&#38656;&#35201;&#20154;&#24037;&#30417;&#30563;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#25105;&#20204;&#23545;&#20110;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#28085;&#30422;&#30693;&#35782;&#22270;&#35889;&#30340;&#22797;&#26434;&#25299;&#25169;&#21644;&#35821;&#20041;&#23646;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#36825;&#20123;&#23646;&#24615;&#23545;&#20110;&#25512;&#29702;&#36807;&#31243;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#19981;&#21516;&#22823;&#23567;&#21644;&#33021;&#21147;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#35814;&#23613;&#30340;&#35780;&#20272;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20061;&#20010;&#23450;&#24615;&#22522;&#20934;&#65292;&#28085;&#30422;&#20102;&#19968;&#31995;&#21015;&#23646;&#24615;&#65292;&#21253;&#25324;&#23545;&#31216;&#24615;&#12289;&#19981;&#23545;&#31216;&#24615;&#12289;
&lt;/p&gt;
&lt;p&gt;
Symbolic knowledge graphs (KGs) play a pivotal role in knowledge-centric applications such as search, question answering and recommendation. As contemporary language models (LMs) trained on extensive textual data have gained prominence, researchers have extensively explored whether the parametric knowledge within these models can match up to that present in knowledge graphs. Various methodologies have indicated that enhancing the size of the model or the volume of training data enhances its capacity to retrieve symbolic knowledge, often with minimal or no human supervision. Despite these advancements, there is a void in comprehensively evaluating whether LMs can encompass the intricate topological and semantic attributes of KGs, attributes crucial for reasoning processes. In this work, we provide an exhaustive evaluation of language models of varying sizes and capabilities. We construct nine qualitative benchmarks that encompass a spectrum of attributes including symmetry, asymmetry, h
&lt;/p&gt;</description></item><item><title>GRASP&#26159;&#19968;&#31181;&#26032;&#30340;&#26679;&#26412;&#36873;&#25321;&#31574;&#30053;&#65292;&#26681;&#25454;&#26679;&#26412;&#30340;&#20195;&#34920;&#24615;&#36873;&#25321;&#26368;&#36866;&#21512;&#23398;&#20064;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22312;&#32447;&#28176;&#36827;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.13646</link><description>&lt;p&gt;
GRASP: &#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#28176;&#36827;&#24335;&#23398;&#20064;&#30340;&#37325;&#28436;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
GRASP: A Rehearsal Policy for Efficient Online Continual Learning. (arXiv:2308.13646v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13646
&lt;/p&gt;
&lt;p&gt;
GRASP&#26159;&#19968;&#31181;&#26032;&#30340;&#26679;&#26412;&#36873;&#25321;&#31574;&#30053;&#65292;&#26681;&#25454;&#26679;&#26412;&#30340;&#20195;&#34920;&#24615;&#36873;&#25321;&#26368;&#36866;&#21512;&#23398;&#20064;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22312;&#32447;&#28176;&#36827;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28176;&#36827;&#23398;&#20064;&#28041;&#21450;&#20174;&#19981;&#26029;&#22686;&#38271;&#30340;&#25968;&#25454;&#27969;&#20013;&#36880;&#27493;&#32047;&#31215;&#30693;&#35782;&#12290;&#28176;&#36827;&#23398;&#20064;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#38750;&#24179;&#31283;&#30340;&#25968;&#25454;&#27969;&#20250;&#23548;&#33268;&#20043;&#21069;&#23398;&#21040;&#30340;&#33021;&#21147;&#36973;&#21463;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#37325;&#28436;&#26159;&#19968;&#31181;&#24120;&#29992;&#19988;&#26377;&#25928;&#30340;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#23558;&#36807;&#21435;&#30340;&#35266;&#27979;&#32467;&#26524;&#23384;&#20648;&#22312;&#32531;&#20914;&#21306;&#20013;&#65292;&#24182;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#23558;&#23427;&#20204;&#19982;&#26032;&#30340;&#35266;&#27979;&#32467;&#26524;&#28151;&#21512;&#12290;&#36825;&#24102;&#26469;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#24212;&#35813;&#36873;&#25321;&#21738;&#20123;&#23384;&#20648;&#26679;&#26412;&#36827;&#34892;&#37325;&#28436;&#65311;&#36873;&#25321;&#26368;&#36866;&#21512;&#23398;&#20064;&#30340;&#26679;&#26412;&#32780;&#19981;&#26159;&#38543;&#26426;&#36873;&#25321;&#26679;&#26412;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#23398;&#20064;&#36895;&#24230;&#26174;&#33879;&#21152;&#24555;&#12290;&#23545;&#20110;&#31867;&#22686;&#37327;&#23398;&#20064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#31616;&#21333;&#30340;&#31867;&#22343;&#34913;&#38543;&#26426;&#36873;&#25321;&#31574;&#30053;&#20248;&#20110;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#25506;&#32034;&#19968;&#31181;&#26032;&#30340;&#26679;&#26412;&#36873;&#25321;&#31574;&#30053;GRASP&#37325;&#26032;&#24605;&#32771;&#36825;&#20010;&#38382;&#39064;&#12290;GRASP&#39318;&#20808;&#36873;&#25321;&#26368;&#20855;&#20195;&#34920;&#24615;&#30340;&#26679;&#26412;&#65292;&#28982;&#21518;&#36880;&#28176;&#36873;&#25321;&#36739;&#19981;&#20855;&#20195;&#34920;&#24615;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Continual learning (CL) in deep neural networks (DNNs) involves incrementally accumulating knowledge in a DNN from a growing data stream. A major challenge in CL is that non-stationary data streams cause catastrophic forgetting of previously learned abilities. Rehearsal is a popular and effective way to mitigate this problem, which is storing past observations in a buffer and mixing them with new observations during learning. This leads to a question: Which stored samples should be selected for rehearsal? Choosing samples that are best for learning, rather than simply selecting them at random, could lead to significantly faster learning. For class incremental learning, prior work has shown that a simple class balanced random selection policy outperforms more sophisticated methods. Here, we revisit this question by exploring a new sample selection policy called GRASP. GRASP selects the most prototypical (class representative) samples first and then gradually selects less prototypical (h
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;LSTM&#27169;&#22411;&#30340;&#24773;&#24863;&#20998;&#26512;&#21644;Net&#21697;&#29260;&#22768;&#35465;&#31639;&#27861;&#35780;&#20272;&#24494;&#26381;&#21153;&#30340;&#22768;&#35465;&#20998;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19968;&#32452;&#19982;Amazon Web&#24494;&#26381;&#21153;&#30456;&#20851;&#30340;&#36229;&#36807;10,000&#26465;&#35780;&#35770;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2308.13590</link><description>&lt;p&gt;
&#22522;&#20110;LSTM&#30340;Web&#24494;&#26381;&#21153;&#21475;&#30865;&#35780;&#20998;&#30340;QoE&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
LSTM-based QoE Evaluation for Web Microservices' Reputation Scoring. (arXiv:2308.13590v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;LSTM&#27169;&#22411;&#30340;&#24773;&#24863;&#20998;&#26512;&#21644;Net&#21697;&#29260;&#22768;&#35465;&#31639;&#27861;&#35780;&#20272;&#24494;&#26381;&#21153;&#30340;&#22768;&#35465;&#20998;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19968;&#32452;&#19982;Amazon Web&#24494;&#26381;&#21153;&#30456;&#20851;&#30340;&#36229;&#36807;10,000&#26465;&#35780;&#35770;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#24863;&#20998;&#26512;&#26159;&#25366;&#25496;&#20316;&#32773;&#23545;&#29305;&#23450;&#23454;&#20307;&#30340;&#24847;&#35265;&#30340;&#20219;&#21153;&#12290;&#23427;&#20801;&#35768;&#32452;&#32455;&#23454;&#26102;&#30417;&#25511;&#19981;&#21516;&#30340;&#26381;&#21153;&#24182;&#37319;&#21462;&#30456;&#24212;&#30340;&#34892;&#21160;&#12290;&#22768;&#35465;&#26159;&#20154;&#20204;&#25110;&#20107;&#29289;&#36890;&#24120;&#35828;&#21040;&#25110;&#30456;&#20449;&#30340;&#19996;&#35199;&#12290;&#38750;&#27491;&#24335;&#22320;&#35828;&#65292;&#22768;&#35465;&#32508;&#21512;&#20102;&#20174;&#29992;&#25143;&#37027;&#37324;&#24471;&#21040;&#30340;&#21453;&#39304;&#12289;&#35780;&#35770;&#21644;&#35780;&#32423;&#25152;&#21453;&#26144;&#30340;&#21487;&#38752;&#24230;&#24230;&#37327;&#65292;&#36825;&#20123;&#21453;&#26144;&#20102;&#20182;&#20204;&#30340;&#20307;&#39564;&#36136;&#37327;(QoE)&#65292;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#25439;&#23475;&#25152;&#25552;&#20379;&#26381;&#21153;&#30340;&#22768;&#35465;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#23545;Web&#24494;&#26381;&#21153;&#35780;&#20215;&#25351;&#26631;&#30340;&#24773;&#24863;&#20998;&#26512;&#65292;&#20197;&#21033;&#29992;&#25552;&#20379;&#30340;&#20449;&#24687;&#26469;&#35780;&#20272;&#21644;&#35780;&#20998;&#24494;&#26381;&#21153;&#30340;&#22768;&#35465;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#29992;&#20102;&#38271;&#30701;&#26399;&#35760;&#24518;(LSTM)&#27169;&#22411;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#65292;&#24182;&#20351;&#29992;&#32593;&#32476;&#21697;&#29260;&#22768;&#35465;(NBR)&#31639;&#27861;&#35780;&#20272;&#24494;&#26381;&#21153;&#30340;&#22768;&#35465;&#20998;&#25968;&#12290;&#35813;&#26041;&#27861;&#22312;&#19982;15&#20010;Amazon Web&#24494;&#26381;&#21153;&#30456;&#20851;&#30340;10000&#22810;&#26465;&#35780;&#35770;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
Sentiment analysis is the task of mining the authors' opinions about specific entities. It allows organizations to monitor different services in real time and act accordingly. Reputation is what is generally said or believed about people or things. Informally, reputation combines the measure of reliability derived from feedback, reviews, and ratings gathered from users, which reflect their quality of experience (QoE) and can either increase or harm the reputation of the provided services. In this study, we propose to perform sentiment analysis on web microservices reviews to exploit the provided information to assess and score the microservices' reputation. Our proposed approach uses the Long Short-Term Memory (LSTM) model to perform sentiment analysis and the Net Brand Reputation (NBR) algorithm to assess reputation scores for microservices. This approach is tested on a set of more than 10,000 reviews related to 15 Amazon Web microservices, and the experimental results have shown that
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26377;&#28508;&#21147;&#25104;&#20026;&#20154;&#24037;&#35780;&#20272;&#21644;&#20854;&#20182;&#33258;&#21160;&#21270;&#35780;&#20215;&#25351;&#26631;&#30340;&#21487;&#34892;&#26367;&#20195;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2308.13577</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25991;&#26412;&#39118;&#26684;&#36716;&#25442;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Text Style Transfer Evaluation Using Large Language Models. (arXiv:2308.13577v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13577
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26377;&#28508;&#21147;&#25104;&#20026;&#20154;&#24037;&#35780;&#20272;&#21644;&#20854;&#20182;&#33258;&#21160;&#21270;&#35780;&#20215;&#25351;&#26631;&#30340;&#21487;&#34892;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#39118;&#26684;&#36716;&#25442;&#65288;TST&#65289;&#30340;&#35780;&#20272;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#29983;&#25104;&#25991;&#26412;&#30340;&#36136;&#37327;&#34920;&#29616;&#22312;&#22810;&#20010;&#26041;&#38754;&#65292;&#27599;&#20010;&#26041;&#38754;&#37117;&#24456;&#38590;&#21333;&#29420;&#34913;&#37327;&#65306;&#39118;&#26684;&#36716;&#25442;&#20934;&#30830;&#24615;&#12289;&#20869;&#23481;&#20445;&#30041;&#21644;&#25972;&#20307;&#27969;&#30021;&#24615;&#12290;&#20154;&#24037;&#35780;&#20272;&#26159;TST&#35780;&#20272;&#30340;&#40644;&#37329;&#26631;&#20934;&#65292;&#28982;&#32780;&#65292;&#23427;&#36153;&#26102;&#36153;&#21147;&#65292;&#24182;&#19988;&#32467;&#26524;&#38590;&#20197;&#37325;&#22797;&#12290;&#35768;&#22810;&#33258;&#21160;&#21270;&#25351;&#26631;&#34987;&#29992;&#20110;&#35780;&#20272;&#36825;&#20123;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20316;&#20026;&#20154;&#24037;&#35780;&#20272;&#30340;&#26367;&#20195;&#21697;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#33258;&#21160;&#21270;&#25351;&#26631;&#19982;&#20154;&#24037;&#35780;&#20272;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20173;&#28982;&#19981;&#28165;&#26970;&#65292;&#23545;&#23427;&#20204;&#20316;&#20026;&#21487;&#38752;&#22522;&#20934;&#30340;&#25928;&#26524;&#20135;&#29983;&#20102;&#24576;&#30097;&#12290;&#26368;&#36817;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#23637;&#24050;&#32463;&#35777;&#26126;&#20102;&#23427;&#20204;&#19981;&#20165;&#33021;&#22815;&#21305;&#37197;&#65292;&#32780;&#19988;&#22312;&#21508;&#31181;&#26410;&#35265;&#20219;&#21153;&#20013;&#36824;&#33021;&#36229;&#36807;&#24179;&#22343;&#20154;&#31867;&#34920;&#29616;&#12290;&#36825;&#34920;&#26126;LLMs&#26377;&#28508;&#21147;&#25104;&#20026;&#20154;&#24037;&#35780;&#20272;&#21644;&#20854;&#20182;&#33258;&#21160;&#21270;&#25351;&#26631;&#30340;&#21487;&#34892;&#26367;&#20195;&#26041;&#26696;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Text Style Transfer (TST) is challenging to evaluate because the quality of the generated text manifests itself in multiple aspects, each of which is hard to measure individually: style transfer accuracy, content preservation, and overall fluency of the text. Human evaluation is the gold standard in TST evaluation; however, it is expensive, and the results are difficult to reproduce. Numerous automated metrics are employed to assess performance in these aspects, serving as substitutes for human evaluation. However, the correlation between many of these automated metrics and human evaluations remains unclear, raising doubts about their effectiveness as reliable benchmarks. Recent advancements in Large Language Models (LLMs) have demonstrated their ability to not only match but also surpass the average human performance across a wide range of unseen tasks. This suggests that LLMs have the potential to serve as a viable alternative to human evaluation and other automated metrics. We asses
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12289;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#21644;&#23383;&#31526;&#32423;&#27169;&#22411;&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#21477;&#23376;/&#21333;&#35789;&#33258;&#21160;&#34917;&#20840;&#24314;&#35758;&#65292;&#24182;&#22312;&#20005;&#26684;&#30340;&#24310;&#36831;&#32422;&#26463;&#19979;&#23454;&#29616;&#39640;&#25928;&#20934;&#30830;&#30340;&#20889;&#20316;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2308.13576</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#23454;&#26102;&#39044;&#27979;&#20889;&#20316;&#30340;&#38598;&#25104;&#26041;&#27861;&#23545;&#20110;&#19987;&#23478;
&lt;/p&gt;
&lt;p&gt;
An Ensemble Approach to Personalized Real Time Predictive Writing for Experts. (arXiv:2308.13576v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12289;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#21644;&#23383;&#31526;&#32423;&#27169;&#22411;&#65292;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#21477;&#23376;/&#21333;&#35789;&#33258;&#21160;&#34917;&#20840;&#24314;&#35758;&#65292;&#24182;&#22312;&#20005;&#26684;&#30340;&#24310;&#36831;&#32422;&#26463;&#19979;&#23454;&#29616;&#39640;&#25928;&#20934;&#30830;&#30340;&#20889;&#20316;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19982;&#29992;&#25143;&#36827;&#34892;&#31508;&#35760;&#25110;&#23454;&#26102;&#32842;&#22825;&#26102;&#65292;&#23545;&#20110;Intuit&#37329;&#34701;&#19987;&#23478;&#26469;&#35828;&#65292;&#22312;&#36755;&#20837;&#19968;&#20123;&#21333;&#35789;/&#23383;&#31526;&#21518;&#34917;&#20840;&#19968;&#20010;&#21477;&#23376;&#12289;&#30701;&#35821;&#25110;&#21333;&#35789;&#23545;&#20110;&#20182;&#20204;&#38750;&#24120;&#26377;&#24110;&#21161;&#65292;&#22240;&#20026;&#20182;&#20204;&#38656;&#35201;&#22312;&#19968;&#22825;&#20013;&#22810;&#27425;&#39640;&#25928;&#20934;&#30830;&#22320;&#20889;&#20837;&#22797;&#26434;&#30340;&#37329;&#34701;&#27010;&#24565;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12289;&#20256;&#32479;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#21644;&#23383;&#31526;&#32423;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#21019;&#24314;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#31995;&#32479;&#65292;&#20197;&#22312;&#20005;&#26684;&#30340;&#24310;&#36831;&#32422;&#26463;&#19979;&#20026;&#19987;&#23478;&#25552;&#20379;&#20010;&#24615;&#21270;&#30340;&#21477;&#23376;/&#21333;&#35789;&#33258;&#21160;&#34917;&#20840;&#24314;&#35758;&#12290;&#25152;&#25552;&#20986;&#30340;&#31995;&#32479;&#21487;&#20197;&#22312;&#20070;&#20889;&#26102;&#33258;&#21160;&#34917;&#20840;&#21477;&#23376;&#12289;&#30701;&#35821;&#25110;&#21333;&#35789;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#24456;&#23569;&#30340;&#25968;&#25454;&#21644;&#36164;&#28304;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31995;&#32479;&#19981;&#20165;&#39640;&#25928;&#21644;&#20010;&#24615;&#21270;&#65292;&#32780;&#19988;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22240;&#20026;&#23427;&#21033;&#29992;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#21450;&#22522;&#20110;&#36716;&#31227;&#23398;&#20064;&#30340;&#26041;&#27861;&#36890;&#36807;Intuit&#29305;&#23450;&#25968;&#25454;&#24494;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#36825;&#30830;&#20445;&#21363;&#20351;&#22312;&#32597;&#35265;&#25110;&#19981;&#23547;&#24120;&#30340;&#30701;&#35821;&#24773;&#20917;&#19979;&#20063;&#33021;&#26377;&#25928;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Completing a sentence, phrase or word after typing few words / characters is very helpful for Intuit financial experts, while taking notes or having a live chat with users, since they need to write complex financial concepts more efficiently and accurately many times in a day. In this paper, we tie together different approaches like large language models, traditional Markov Models and char level models to create an end-to-end system to provide personalised sentence/word auto-complete suggestions to experts, under strict latency constraints. Proposed system can auto-complete sentences, phrases or words while writing with personalisation and can be trained with very less data and resources with good efficiency. Our proposed system is not only efficient and personalized but also robust as it leverages multiple machine learning techniques along with transfer learning approach to fine tune large language model with Intuit specific data. This ensures that even in cases of rare or unusual phr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#22823;&#37327;&#24515;&#29702;&#20581;&#24247;&#30740;&#31350;&#35770;&#25991;&#65292;&#37319;&#29992;&#33258;&#23450;&#20041;&#23884;&#20837;&#27169;&#22411;&#65292;&#35782;&#21035;&#20986;&#35813;&#39046;&#22495;&#30340;&#19968;&#33324;&#36235;&#21183;&#21644;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.13569</link><description>&lt;p&gt;
&#29992;&#20027;&#39064;&#24314;&#27169;&#21457;&#29616;&#24515;&#29702;&#20581;&#24247;&#30740;&#31350;&#35838;&#39064;
&lt;/p&gt;
&lt;p&gt;
Discovering Mental Health Research Topics with Topic Modeling. (arXiv:2308.13569v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#22823;&#37327;&#24515;&#29702;&#20581;&#24247;&#30740;&#31350;&#35770;&#25991;&#65292;&#37319;&#29992;&#33258;&#23450;&#20041;&#23884;&#20837;&#27169;&#22411;&#65292;&#35782;&#21035;&#20986;&#35813;&#39046;&#22495;&#30340;&#19968;&#33324;&#36235;&#21183;&#21644;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24515;&#29702;&#20581;&#24247;&#26174;&#33879;&#24433;&#21709;&#25105;&#20204;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#20854;&#37325;&#35201;&#24615;&#22312;&#30740;&#31350;&#30028;&#21644;&#22823;&#20247;&#20013;&#36234;&#26469;&#36234;&#21463;&#21040;&#35748;&#21487;&#65292;&#29305;&#21035;&#26159;&#22312;COVID-19&#22823;&#27969;&#34892;&#20043;&#21518;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#24515;&#29702;&#20581;&#24247;&#39046;&#22495;&#30340;&#20986;&#29256;&#29289;&#25968;&#37327;&#19981;&#26029;&#22686;&#38271;&#65292;&#36825;&#31181;&#27987;&#21402;&#30340;&#20852;&#36259;&#20063;&#20307;&#29616;&#22312;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#35770;&#25991;&#20013;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#20998;&#26512;&#22823;&#22411;&#24515;&#29702;&#20581;&#24247;&#30740;&#31350;&#35770;&#25991;&#25968;&#25454;&#38598;&#65292;&#35782;&#21035;&#35813;&#39046;&#22495;&#30340;&#19968;&#33324;&#36235;&#21183;&#65292;&#24182;&#25214;&#20986;&#20855;&#26377;&#39640;&#24433;&#21709;&#21147;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#20174;&#21508;&#20010;&#25968;&#25454;&#24211;&#25910;&#38598;&#20102;&#25688;&#35201;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;BERTopic&#26694;&#26550;&#30340;&#33258;&#23450;&#20041;Sentence-BERT&#23884;&#20837;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#21253;&#21547;96,676&#31687;&#19982;&#24515;&#29702;&#20581;&#24247;&#30456;&#20851;&#30340;&#30740;&#31350;&#35770;&#25991;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#23427;&#20204;&#30340;&#25688;&#35201;&#26469;&#30740;&#31350;&#19981;&#21516;&#20027;&#39064;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20026;&#20102;&#35780;&#20272;&#27169;&#22411;&#30340;&#25928;&#26524;&#65292;&#25105;&#20204;&#23558;&#20854;&#19982;&#21478;&#22806;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#23545;&#27604;&#65306;Top2Vec&#27169;&#22411;&#21644;LDA-BERT&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mental health significantly influences various aspects of our daily lives, and its importance has been increasingly recognized by the research community and the general public, particularly in the wake of the COVID-19 pandemic. This heightened interest is evident in the growing number of publications dedicated to mental health in the past decade. In this study, our goal is to identify general trends in the field and pinpoint high-impact research topics by analyzing a large dataset of mental health research papers. To accomplish this, we collected abstracts from various databases and trained a customized Sentence-BERT based embedding model leveraging the BERTopic framework. Our dataset comprises 96,676 research papers pertaining to mental health, enabling us to examine the relationships between different topics using their abstracts. To evaluate the effectiveness of the model, we compared it against two other state-of-the-art methods: Top2Vec model and LDA-BERT model. The model demonstr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MLLM-DataEngine&#30340;&#36845;&#20195;&#25913;&#36827;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20998;&#26512;&#27169;&#22411;&#24369;&#28857;&#65292;&#29983;&#25104;&#36866;&#24403;&#30340;&#22686;&#37327;&#25968;&#25454;&#38598;&#24182;&#36845;&#20195;&#22320;&#22686;&#24378;&#27169;&#22411;&#33021;&#21147;&#12290;&#19982;&#20197;&#24448;&#26041;&#27861;&#30456;&#27604;&#65292;MLLM-DataEngine&#29983;&#25104;&#30340;&#25968;&#25454;&#22312;&#23450;&#20301;&#12289;&#36136;&#37327;&#21644;&#27491;&#30830;&#24615;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2308.13566</link><description>&lt;p&gt;
MLLM-DataEngine&#65306;&#19968;&#31181;MLLM&#30340;&#36845;&#20195;&#25913;&#36827;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
MLLM-DataEngine: An Iterative Refinement Approach for MLLM. (arXiv:2308.13566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MLLM-DataEngine&#30340;&#36845;&#20195;&#25913;&#36827;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20998;&#26512;&#27169;&#22411;&#24369;&#28857;&#65292;&#29983;&#25104;&#36866;&#24403;&#30340;&#22686;&#37327;&#25968;&#25454;&#38598;&#24182;&#36845;&#20195;&#22320;&#22686;&#24378;&#27169;&#22411;&#33021;&#21147;&#12290;&#19982;&#20197;&#24448;&#26041;&#27861;&#30456;&#27604;&#65292;MLLM-DataEngine&#29983;&#25104;&#30340;&#25968;&#25454;&#22312;&#23450;&#20301;&#12289;&#36136;&#37327;&#21644;&#27491;&#30830;&#24615;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#25351;&#23548;&#25968;&#25454;&#38598;&#26500;&#24314;&#21644;&#22522;&#20934;&#27979;&#35797;&#26041;&#38754;&#65292;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLM&#65289;&#21462;&#24471;&#20102;&#24456;&#22823;&#30340;&#36827;&#23637;&#65292;&#20294;&#35757;&#32451;&#21644;&#35780;&#20272;&#30340;&#29420;&#31435;&#24615;&#20351;&#24471;&#24403;&#21069;&#30340;MLLM&#24456;&#38590;&#22312;&#30456;&#23545;&#36739;&#20302;&#30340;&#20154;&#21147;&#25104;&#26412;&#19979;&#36827;&#19968;&#27493;&#25552;&#39640;&#20854;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23553;&#38381;&#24490;&#29615;&#31995;&#32479;MLLM-DataEngine&#65292;&#23427;&#36830;&#25509;&#20102;&#25968;&#25454;&#29983;&#25104;&#12289;&#27169;&#22411;&#35757;&#32451;&#21644;&#35780;&#20272;&#12290;&#22312;&#27599;&#20010;&#24490;&#29615;&#36845;&#20195;&#20013;&#65292;MLLM-DataEngine&#39318;&#20808;&#26681;&#25454;&#35780;&#20272;&#32467;&#26524;&#20998;&#26512;&#27169;&#22411;&#30340;&#24369;&#28857;&#65292;&#28982;&#21518;&#29983;&#25104;&#21512;&#36866;&#30340;&#22686;&#37327;&#25968;&#25454;&#38598;&#29992;&#20110;&#19979;&#19968;&#27425;&#35757;&#32451;&#36845;&#20195;&#65292;&#24182;&#36845;&#20195;&#22320;&#22686;&#24378;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#19982;&#20808;&#21069;&#19982;&#22522;&#20934;&#27979;&#35797;&#20998;&#31163;&#30340;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#30456;&#27604;&#65292;MLLM-DataEngine&#29983;&#25104;&#30340;&#25968;&#25454;&#22312;&#23450;&#20301;&#12289;&#36136;&#37327;&#21644;&#27491;&#30830;&#24615;&#26041;&#38754;&#37117;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental datas
&lt;/p&gt;</description></item><item><title>DARWIN&#31995;&#21015;&#26159;&#20026;&#33258;&#28982;&#31185;&#23398;&#39046;&#22495;&#24320;&#21457;&#30340;&#23450;&#21046;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#31185;&#23398;&#25351;&#20196;&#29983;&#25104;&#27169;&#22411;&#21644;&#22823;&#37327;&#25968;&#25454;&#24494;&#35843;&#65292;&#21152;&#36895;&#20102;&#33258;&#21160;&#21270;&#21457;&#29616;&#36807;&#31243;&#30340;&#36827;&#34892;&#12290;</title><link>http://arxiv.org/abs/2308.13565</link><description>&lt;p&gt;
DARWIN&#31995;&#21015;&#65306;&#38754;&#21521;&#33258;&#28982;&#31185;&#23398;&#30340;&#39046;&#22495;&#29305;&#23450;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DARWIN Series: Domain Specific Large Language Models for Natural Science. (arXiv:2308.13565v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13565
&lt;/p&gt;
&lt;p&gt;
DARWIN&#31995;&#21015;&#26159;&#20026;&#33258;&#28982;&#31185;&#23398;&#39046;&#22495;&#24320;&#21457;&#30340;&#23450;&#21046;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#31185;&#23398;&#25351;&#20196;&#29983;&#25104;&#27169;&#22411;&#21644;&#22823;&#37327;&#25968;&#25454;&#24494;&#35843;&#65292;&#21152;&#36895;&#20102;&#33258;&#21160;&#21270;&#21457;&#29616;&#36807;&#31243;&#30340;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#20852;&#30340;&#24037;&#20855;&#24102;&#26469;&#20102;&#26032;&#30340;&#24037;&#20316;&#26041;&#27861;&#65292;&#33258;&#28982;&#31185;&#23398;&#39046;&#22495;&#20063;&#19981;&#20363;&#22806;&#12290;&#22312;&#33258;&#28982;&#31185;&#23398;&#20013;&#65292;&#20256;&#32479;&#30340;&#25163;&#24037;&#12289;&#20018;&#34892;&#21644;&#21171;&#21160;&#23494;&#38598;&#22411;&#24037;&#20316;&#27491;&#34987;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#23454;&#39564;&#33258;&#21160;&#21270;&#21644;&#26356;&#22810;&#30340;&#33258;&#21160;&#21270;&#12289;&#24182;&#34892;&#21644;&#36845;&#20195;&#36807;&#31243;&#25152;&#21462;&#20195;&#12290;&#20026;&#20102;&#22312;&#33258;&#28982;&#31185;&#23398;&#20013;&#22686;&#21152;&#26032;&#30340;&#33021;&#21147;&#65292;&#21152;&#36895;&#21644;&#20016;&#23500;&#21457;&#29616;&#36807;&#31243;&#30340;&#33258;&#21160;&#21270;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DARWIN&#65292;&#19968;&#20010;&#38754;&#21521;&#33258;&#28982;&#31185;&#23398;&#30340;&#31995;&#21015;&#23450;&#21046;LLM&#65292;&#20027;&#35201;&#24212;&#29992;&#22312;&#29289;&#29702;&#23398;&#12289;&#21270;&#23398;&#21644;&#26448;&#26009;&#31185;&#23398;&#31561;&#39046;&#22495;&#12290;&#35813;&#31995;&#21015;&#20381;&#36182;&#20110;&#24320;&#28304;LLM&#65292;&#23558;&#20844;&#20849;&#25968;&#25454;&#38598;&#21644;&#25991;&#29486;&#20013;&#30340;&#32467;&#26500;&#21270;&#21644;&#38750;&#32467;&#26500;&#21270;&#31185;&#23398;&#30693;&#35782;&#25972;&#21512;&#36827;&#26469;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#36229;&#36807;60,000&#20010;&#25351;&#20196;&#25968;&#25454;&#28857;&#23545;&#27169;&#22411;&#36827;&#34892;&#20102;&#24494;&#35843;&#65292;&#24378;&#35843;&#20107;&#23454;&#30340;&#27491;&#30830;&#24615;&#12290;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31185;&#23398;&#25351;&#20196;&#29983;&#25104;&#65288;SIG&#65289;&#27169;&#22411;&#65292;&#20174;&#31185;&#23398;&#25991;&#26412;&#20013;&#33258;&#21160;&#29983;&#25104;&#25351;&#20196;&#12290;&#36825;&#28040;&#38500;&#20102;&#25163;&#21160;&#25552;&#21462;&#25110;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In natural science, traditional manual, serial, and labour-intensive work is being augmented by automated, parallel, and iterative processes driven by artificial intelligence-based experimental automation and more. To add new capabilities in natural science, enabling the acceleration and enrichment of automation of the discovery process, we present DARWIN, a series of tailored LLMs for natural science, mainly in physics, chemistry, and material science. This series relies on open-source LLM, incorporating structured and unstructured scientific knowledge from public datasets and literature. We fine-tuned the models using over 60,000 instruction data points, emphasizing factual correctness. During the fine-tuning, we introduce the Scientific Instruction Generation (SIG) model, automating instruction generation from scientific texts. This eliminates the need for manual extraction or doma
&lt;/p&gt;</description></item><item><title>&#19977;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25509;&#21475;(ChatGPT, BARD&#21644;GPT4)&#22312;&#20998;&#26512;&#20107;&#25925;&#21465;&#36848;&#20013;&#30340;&#25928;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#20204;&#22312;&#25552;&#21462;&#20107;&#25925;&#30456;&#20851;&#20449;&#24687;&#21644;&#22238;&#31572;&#30456;&#20851;&#38382;&#39064;&#26041;&#38754;&#37117;&#20855;&#26377;&#19968;&#23450;&#30340;&#26377;&#25928;&#24615;&#65292;&#20294;&#20063;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2308.13563</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20998;&#26512;&#20107;&#25925;&#21465;&#36848;&#20013;&#30340;&#24212;&#29992;&#8212;&#8212;ChatGPT&#12289;BARD&#21644;GPT-4&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4. (arXiv:2308.13563v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13563
&lt;/p&gt;
&lt;p&gt;
&#19977;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25509;&#21475;(ChatGPT, BARD&#21644;GPT4)&#22312;&#20998;&#26512;&#20107;&#25925;&#21465;&#36848;&#20013;&#30340;&#25928;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#20204;&#22312;&#25552;&#21462;&#20107;&#25925;&#30456;&#20851;&#20449;&#24687;&#21644;&#22238;&#31572;&#30456;&#20851;&#38382;&#39064;&#26041;&#38754;&#37117;&#20855;&#26377;&#19968;&#23450;&#30340;&#26377;&#25928;&#24615;&#65292;&#20294;&#20063;&#23384;&#22312;&#19968;&#20123;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20132;&#36890;&#23433;&#20840;&#30740;&#31350;&#20013;&#65292;&#20351;&#29992;&#25991;&#26412;&#20998;&#26512;&#20174;&#20107;&#25925;&#21465;&#36848;&#20013;&#25552;&#21462;&#20449;&#24687;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#20570;&#27861;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#20102;&#35299;&#27969;&#34892;&#30340;LLM&#25509;&#21475;&#22312;&#20998;&#31867;&#25110;&#20174;&#20107;&#25925;&#21465;&#36848;&#20013;&#25552;&#21462;&#20449;&#24687;&#26041;&#38754;&#30340;&#34920;&#29616;&#23558;&#38750;&#24120;&#26377;&#29992;&#12290;&#20026;&#20102;&#25506;&#32034;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20351;&#29992;&#20102;&#30446;&#21069;&#26368;&#27969;&#34892;&#30340;&#19977;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;LLM&#25509;&#21475;&#8212;&#8212;ChatGPT&#12289;BARD&#21644;GPT4&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#23427;&#20204;&#22312;&#25552;&#21462;&#20449;&#24687;&#21644;&#22238;&#31572;&#19982;&#20107;&#25925;&#26377;&#20851;&#30340;&#26597;&#35810;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#21644;&#38480;&#21046;&#12290;&#30740;&#31350;&#20174;&#29233;&#33655;&#21326;&#24030;&#21644;&#22570;&#33832;&#26031;&#24030;&#30340;100&#20010;&#20107;&#25925;&#21465;&#36848;&#20013;&#25552;&#21462;&#20449;&#24687;&#65292;&#24182;&#23545;&#23427;&#20204;&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#27604;&#36739;&#20102;&#23427;&#20204;&#23545;&#26597;&#35810;&#30340;&#21709;&#24212;&#12290;&#20116;&#20010;&#19982;&#21465;&#36848;&#30456;&#20851;&#30340;&#38382;&#39064;&#34987;&#25552;&#20986;&#65306;1&#65289;&#35841;&#26159;&#36131;&#20219;&#26041;&#65311;2&#65289;&#30896;&#25758;&#26041;&#24335;&#26159;&#20160;&#20040;&#65311;3&#65289;&#20107;&#25925;&#21457;&#29983;&#22312;&#24037;&#20316;&#21306;&#21527;&#65311;4&#65289;&#20107;&#25925;&#28041;&#21450;&#34892;&#20154;&#21527;&#65311;5&#65289;&#20107;&#25925;&#20013;&#26377;&#23475;&#20107;&#20214;&#30340;&#39034;&#24207;&#26159;&#20160;&#20040;&#65311;&#23545;&#20110;&#31532;1&#21040;&#31532;4&#20010;&#38382;&#39064;&#65292;&#19977;&#20010;LLM&#25509;&#21475;&#30340;&#22238;&#31572;&#37117;&#32463;&#36807;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
In traffic safety research, extracting information from crash narratives using text analysis is a common practice. With recent advancements of large language models (LLM), it would be useful to know how the popular LLM interfaces perform in classifying or extracting information from crash narratives. To explore this, our study has used the three most popular publicly available LLM interfaces- ChatGPT, BARD and GPT4. This study investigated their usefulness and boundaries in extracting information and answering queries related to accidents from 100 crash narratives from Iowa and Kansas. During the investigation, their capabilities and limitations were assessed and their responses to the queries were compared. Five questions were asked related to the narratives: 1) Who is at-fault? 2) What is the manner of collision? 3) Has the crash occurred in a work-zone? 4) Did the crash involve pedestrians? and 5) What are the sequence of harmful events in the crash? For questions 1 through 4, the o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#23391;&#21152;&#25289;&#25991;&#26412;&#20998;&#31867;&#20013;&#36827;&#34892;&#29305;&#24449;&#25552;&#21462;&#30340;&#26041;&#27861;&#65292;&#24182;&#25910;&#38598;&#12289;&#27880;&#37322;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25968;&#25454;&#38598;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#29305;&#24449;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2308.13545</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#23391;&#21152;&#25289;&#25991;&#26412;&#20998;&#31867;&#30340;&#29305;&#24449;&#25552;&#21462;&#65288;arXiv:2308.13545v1 [cs.IR]&#65289;
&lt;/p&gt;
&lt;p&gt;
Feature Extraction Using Deep Generative Models for Bangla Text Classification on a New Comprehensive Dataset. (arXiv:2308.13545v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#23391;&#21152;&#25289;&#25991;&#26412;&#20998;&#31867;&#20013;&#36827;&#34892;&#29305;&#24449;&#25552;&#21462;&#30340;&#26041;&#27861;&#65292;&#24182;&#25910;&#38598;&#12289;&#27880;&#37322;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#25968;&#25454;&#38598;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#29305;&#24449;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#20998;&#31867;&#20013;&#30340;&#29305;&#24449;&#36873;&#25321;&#26159;&#25991;&#26412;&#25366;&#25496;&#21644;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;&#22522;&#30784;&#20219;&#21153;&#12290;&#23613;&#31649;&#23391;&#21152;&#25289;&#35821;&#26159;&#19990;&#30028;&#19978;&#20351;&#29992;&#26368;&#24191;&#27867;&#30340;&#31532;&#20845;&#22823;&#35821;&#35328;&#65292;&#20294;&#30001;&#20110;&#25991;&#26412;&#25968;&#25454;&#38598;&#30340;&#31232;&#32570;&#24615;&#65292;&#23427;&#19968;&#30452;&#21463;&#21040;&#36739;&#23569;&#20851;&#27880;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25910;&#38598;&#12289;&#27880;&#37322;&#21644;&#20934;&#22791;&#20102;&#19968;&#20010;&#21253;&#21547;212,184&#20010;&#23391;&#21152;&#25289;&#25991;&#26723;&#30340;&#20840;&#38754;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20102;&#19971;&#20010;&#19981;&#21516;&#30340;&#31867;&#21035;&#65292;&#24182;&#23558;&#20854;&#20844;&#24320;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19977;&#20010;&#28145;&#24230;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#65306;LSTM&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;LSTM VAE&#65289;&#12289;&#36741;&#21161;&#20998;&#31867;&#22120;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;AC-GAN&#65289;&#21644;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;&#65288;AAE&#65289;&#26469;&#25552;&#21462;&#25991;&#26412;&#29305;&#24449;&#65292;&#23613;&#31649;&#23427;&#20204;&#30340;&#24212;&#29992;&#26368;&#21021;&#26159;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#21457;&#29616;&#30340;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#35757;&#32451;&#20102;&#36825;&#19977;&#20010;&#27169;&#22411;&#65292;&#24182;&#22312;&#25991;&#26723;&#20998;&#31867;&#20219;&#21153;&#20013;&#20351;&#29992;&#20102;&#24471;&#21040;&#30340;&#29305;&#24449;&#31354;&#38388;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#21457;&#29616;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#29305;&#24449;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
The selection of features for text classification is a fundamental task in text mining and information retrieval. Despite being the sixth most widely spoken language in the world, Bangla has received little attention due to the scarcity of text datasets. In this research, we collected, annotated, and prepared a comprehensive dataset of 212,184 Bangla documents in seven different categories and made it publicly accessible. We implemented three deep learning generative models: LSTM variational autoencoder (LSTM VAE), auxiliary classifier generative adversarial network (AC-GAN), and adversarial autoencoder (AAE) to extract text features, although their applications are initially found in the field of computer vision. We utilized our dataset to train these three models and used the feature space obtained in the document classification task. We evaluated the performance of the classifiers and found that the adversarial autoencoder model produced the best feature space.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#28216;&#25103;&#29305;&#24449;&#24314;&#35758;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#20351;&#29992;&#25991;&#26412;&#25552;&#31034;&#65292;&#25552;&#21462;&#20027;&#39064;&#30456;&#20284;&#30340;&#28216;&#25103;&#29305;&#24449;&#24182;&#29983;&#25104;&#26032;&#29305;&#24449;&#12290;&#32463;&#36807;&#29992;&#25143;&#30740;&#31350;&#27604;&#36739;&#65292;&#35813;&#31995;&#32479;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#26576;&#20123;&#28216;&#25103;&#20013;&#30340;&#34920;&#29616;&#36229;&#36807;&#20102;&#20154;&#24037;&#24314;&#35758;&#12290;&#35813;&#31995;&#32479;&#26159;&#19968;&#20010;&#19982;&#29992;&#25143;&#22312;&#27010;&#24565;&#23618;&#38754;&#19978;&#36827;&#34892;&#21327;&#20316;&#30340;&#28216;&#25103;&#35774;&#35745;&#21161;&#25163;&#24037;&#20855;&#30340;&#19968;&#37096;&#20998;&#12290;</title><link>http://arxiv.org/abs/2308.13538</link><description>&lt;p&gt;
&#19968;&#20010;&#27010;&#24565;&#28216;&#25103;&#29305;&#24449;&#29983;&#25104;&#19982;&#25512;&#33616;&#31995;&#32479;&#30340;&#21021;&#27493;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System. (arXiv:2308.13538v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13538
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#28216;&#25103;&#29305;&#24449;&#24314;&#35758;&#30340;&#31995;&#32479;&#65292;&#36890;&#36807;&#20351;&#29992;&#25991;&#26412;&#25552;&#31034;&#65292;&#25552;&#21462;&#20027;&#39064;&#30456;&#20284;&#30340;&#28216;&#25103;&#29305;&#24449;&#24182;&#29983;&#25104;&#26032;&#29305;&#24449;&#12290;&#32463;&#36807;&#29992;&#25143;&#30740;&#31350;&#27604;&#36739;&#65292;&#35813;&#31995;&#32479;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#26576;&#20123;&#28216;&#25103;&#20013;&#30340;&#34920;&#29616;&#36229;&#36807;&#20102;&#20154;&#24037;&#24314;&#35758;&#12290;&#35813;&#31995;&#32479;&#26159;&#19968;&#20010;&#19982;&#29992;&#25143;&#22312;&#27010;&#24565;&#23618;&#38754;&#19978;&#36827;&#34892;&#21327;&#20316;&#30340;&#28216;&#25103;&#35774;&#35745;&#21161;&#25163;&#24037;&#20855;&#30340;&#19968;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#25991;&#26412;&#25552;&#31034;&#29983;&#25104;&#28216;&#25103;&#29305;&#24449;&#24314;&#35758;&#30340;&#31995;&#32479;&#12290;&#35813;&#31995;&#32479;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#30340;GLoVe&#27169;&#22411;&#30340;&#35789;&#23884;&#20837;&#26469;&#25552;&#21462;&#20027;&#39064;&#30456;&#20284;&#30340;&#28216;&#25103;&#20013;&#30340;&#29305;&#24449;&#21644;&#23454;&#20307;&#65292;&#24182;&#23558;&#20854;&#36890;&#36807;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#20256;&#36882;&#65292;&#29992;&#20110;&#29983;&#25104;&#29992;&#25143;&#25552;&#31034;&#30340;&#26032;&#29305;&#24449;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#30701;&#26399;&#29992;&#25143;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#26469;&#33258;&#19968;&#20010;&#32463;&#36807;&#24494;&#35843;&#30340;GPT-2&#27169;&#22411;&#12289;&#20351;&#29992;ConceptNet&#30340;&#27169;&#22411;&#20197;&#21450;&#20154;&#24037;&#32534;&#20889;&#30340;&#28216;&#25103;&#29305;&#24449;&#29983;&#25104;&#30340;&#29305;&#24449;&#12290;&#34429;&#28982;&#20154;&#24037;&#24314;&#35758;&#33719;&#24471;&#20102;&#32477;&#22823;&#22810;&#25968;&#30340;&#25237;&#31080;&#65292;&#20294;&#22312;&#26576;&#20123;&#28216;&#25103;&#20013;&#65292;GPT-2&#27169;&#22411;&#30340;&#34920;&#29616;&#36229;&#36807;&#20102;&#20154;&#24037;&#24314;&#35758;&#12290;&#35813;&#31995;&#32479;&#26159;&#19968;&#20010;&#26356;&#22823;&#30340;&#28216;&#25103;&#35774;&#35745;&#21161;&#25163;&#24037;&#20855;&#30340;&#19968;&#37096;&#20998;&#65292;&#33021;&#22815;&#22312;&#27010;&#24565;&#23618;&#38754;&#19978;&#19982;&#29992;&#25143;&#36827;&#34892;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a system used to generate game feature suggestions based on a text prompt. Trained on the game descriptions of almost 60k games, it uses the word embeddings of a small GLoVe model to extract features and entities found in thematically similar games which are then passed through a generator model to generate new features for a user's prompt. We perform a short user study comparing the features generated from a fine-tuned GPT-2 model, a model using the ConceptNet, and human-authored game features. Although human suggestions won the overall majority of votes, the GPT-2 model outperformed the human suggestions in certain games. This system is part of a larger game design assistant tool that is able to collaborate with users at a conceptual level.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#36848;&#21644;&#35299;&#20915;&#26041;&#26696;&#26550;&#26500;&#65292;&#29992;&#20110;&#26500;&#24314;&#21487;&#35299;&#37322;&#30340;&#12289;&#38544;&#31169;&#24863;&#30693;&#30340;&#23545;&#35805;&#22411;AI&#31995;&#32479;&#12290;&#39318;&#20808;&#20171;&#32461;&#20102;LLM&#27169;&#22411;&#30340;&#32508;&#21512;&#24037;&#20855;LLMXplorer&#65292;&#24182;&#38416;&#26126;&#20102;&#20854;&#23545;&#31038;&#20250;&#12289;&#20262;&#29702;&#21644;&#30417;&#31649;&#31561;&#26041;&#38754;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#25552;&#20986;&#20102;&#23558;&#30693;&#35782;&#22270;&#35889;&#30340;&#32467;&#26500;&#21160;&#24577;&#19982;LLM&#30340;&#35821;&#35328;&#33021;&#21147;&#26080;&#32541;&#38598;&#25104;&#30340;&#26550;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;AI&#26032;&#38395;&#25968;&#25454;&#36827;&#34892;&#39564;&#35777;&#65292;&#35813;&#26550;&#26500;&#25104;&#21151;&#22320;&#34701;&#21512;&#20102;&#35821;&#35328;&#30340;&#22797;&#26434;&#24615;&#19982;&#20107;&#23454;&#30340;&#20005;&#35880;&#24615;&#65292;&#24182;&#22686;&#24378;&#20102;&#25968;&#25454;&#23433;&#20840;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13534</link><description>&lt;p&gt;
&#24314;&#31435;&#23545;&#35805;&#22411;AI&#20013;&#30340;&#20449;&#20219;&#65306;&#20351;&#29992;LLMs&#21644;&#30693;&#35782;&#22270;&#35889;&#26500;&#24314;&#21487;&#35299;&#37322;&#30340;&#12289;&#38544;&#31169;&#24863;&#30693;&#30340;&#31995;&#32479;&#30340;&#32508;&#36848;&#21644;&#35299;&#20915;&#26041;&#26696;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph. (arXiv:2308.13534v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#36848;&#21644;&#35299;&#20915;&#26041;&#26696;&#26550;&#26500;&#65292;&#29992;&#20110;&#26500;&#24314;&#21487;&#35299;&#37322;&#30340;&#12289;&#38544;&#31169;&#24863;&#30693;&#30340;&#23545;&#35805;&#22411;AI&#31995;&#32479;&#12290;&#39318;&#20808;&#20171;&#32461;&#20102;LLM&#27169;&#22411;&#30340;&#32508;&#21512;&#24037;&#20855;LLMXplorer&#65292;&#24182;&#38416;&#26126;&#20102;&#20854;&#23545;&#31038;&#20250;&#12289;&#20262;&#29702;&#21644;&#30417;&#31649;&#31561;&#26041;&#38754;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#25552;&#20986;&#20102;&#23558;&#30693;&#35782;&#22270;&#35889;&#30340;&#32467;&#26500;&#21160;&#24577;&#19982;LLM&#30340;&#35821;&#35328;&#33021;&#21147;&#26080;&#32541;&#38598;&#25104;&#30340;&#26550;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;AI&#26032;&#38395;&#25968;&#25454;&#36827;&#34892;&#39564;&#35777;&#65292;&#35813;&#26550;&#26500;&#25104;&#21151;&#22320;&#34701;&#21512;&#20102;&#35821;&#35328;&#30340;&#22797;&#26434;&#24615;&#19982;&#20107;&#23454;&#30340;&#20005;&#35880;&#24615;&#65292;&#24182;&#22686;&#24378;&#20102;&#25968;&#25454;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#22411;AI&#31995;&#32479;&#24050;&#25104;&#20026;&#21508;&#20010;&#39046;&#22495;&#23454;&#29616;&#31867;&#20284;&#20110;&#20154;&#31867;&#20132;&#20114;&#30340;&#20851;&#38190;&#39537;&#21160;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#35821;&#35328;&#32454;&#24494;&#24046;&#21035;&#21644;&#20107;&#23454;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#24179;&#34913;&#19968;&#30452;&#38590;&#20197;&#25226;&#25569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;LLMXplorer&#65292;&#36825;&#26159;&#19968;&#20010;&#20840;&#38754;&#30340;&#24037;&#20855;&#65292;&#35814;&#32454;&#23457;&#35270;&#20102;150&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#38416;&#26126;&#20102;&#23427;&#20204;&#20174;&#31038;&#20250;&#12289;&#20262;&#29702;&#21040;&#30417;&#31649;&#30340;&#21508;&#31181;&#24433;&#21709;&#65292;&#20197;&#21450;&#23427;&#20204;&#22312;&#21508;&#34892;&#21508;&#19994;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21151;&#33021;&#26550;&#26500;&#65292;&#23558;&#30693;&#35782;&#22270;&#35889;&#30340;&#32467;&#26500;&#21160;&#24577;&#19982;LLMs&#30340;&#35821;&#35328;&#33021;&#21147;&#26080;&#32541;&#38598;&#25104;&#12290;&#36890;&#36807;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;AI&#26032;&#38395;&#25968;&#25454;&#36827;&#34892;&#39564;&#35777;&#65292;&#25105;&#20204;&#30340;&#26550;&#26500;&#24039;&#22937;&#22320;&#34701;&#21512;&#20102;&#35821;&#35328;&#30340;&#22797;&#26434;&#24615;&#19982;&#20107;&#23454;&#30340;&#20005;&#35880;&#24615;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#35282;&#33394;&#30340;&#35775;&#38382;&#25511;&#21046;&#36827;&#19968;&#27493;&#21152;&#24378;&#20102;&#25968;&#25454;&#23433;&#20840;&#24615;&#12290;&#26412;&#30740;&#31350;&#20026;&#23545;&#35805;&#22411;AI&#21457;&#23637;&#30340;&#21464;&#21270;&#26223;&#35266;&#25552;&#20379;&#20102;&#28145;&#20837;&#35265;&#35299;&#65292;&#24378;&#35843;&#20102;&#39640;&#25928;&#12289;&#36879;&#26126;&#30340;&#31995;&#32479;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational AI systems have emerged as key enablers of human-like interactions across diverse sectors. Nevertheless, the balance between linguistic nuance and factual accuracy has proven elusive. In this paper, we first introduce LLMXplorer, a comprehensive tool that provides an in-depth review of over 150 Large Language Models (LLMs), elucidating their myriad implications ranging from social and ethical to regulatory, as well as their applicability across industries. Building on this foundation, we propose a novel functional architecture that seamlessly integrates the structured dynamics of Knowledge Graphs with the linguistic capabilities of LLMs. Validated using real-world AI news data, our architecture adeptly blends linguistic sophistication with factual rigour and further strengthens data security through Role-Based Access Control. This research provides insights into the evolving landscape of conversational AI, emphasizing the imperative for systems that are efficient, transp
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26426;&#22120;&#32763;&#35793;&#20013;&#65292;&#22914;&#20309;&#22312;&#27573;&#33853;&#32423;&#21035;&#35780;&#20272;&#32763;&#35793;&#36136;&#37327;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#21477;&#23376;&#32423;&#21035;&#30340;&#35780;&#20272;&#25351;&#26631;&#26469;&#35780;&#20998;&#25972;&#20010;&#27573;&#33853;&#19982;&#20351;&#29992;&#27573;&#33853;&#32423;&#21035;&#30340;&#25351;&#26631;&#19968;&#26679;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2308.13506</link><description>&lt;p&gt;
&#22312;&#27573;&#33853;&#32423;&#21035;&#19978;&#35757;&#32451;&#21644;&#20803;&#35780;&#20272;&#26426;&#22120;&#32763;&#35793;&#35780;&#20272;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level. (arXiv:2308.13506v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13506
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26426;&#22120;&#32763;&#35793;&#20013;&#65292;&#22914;&#20309;&#22312;&#27573;&#33853;&#32423;&#21035;&#35780;&#20272;&#32763;&#35793;&#36136;&#37327;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#21477;&#23376;&#32423;&#21035;&#30340;&#35780;&#20272;&#25351;&#26631;&#26469;&#35780;&#20998;&#25972;&#20010;&#27573;&#33853;&#19982;&#20351;&#29992;&#27573;&#33853;&#32423;&#21035;&#30340;&#25351;&#26631;&#19968;&#26679;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#32763;&#35793;&#30740;&#31350;&#30340;&#21457;&#23637;&#65292;&#23558;&#25991;&#26412;&#32763;&#35793;&#21040;&#21477;&#23376;&#20197;&#19978;&#30340;&#32423;&#21035;&#65292;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#22312;&#35780;&#20998;&#26356;&#38271;&#30340;&#32763;&#35793;&#19978;&#30340;&#26377;&#25928;&#24615;&#20173;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#29616;&#26377;&#30340;&#21477;&#23376;&#32423;&#21035;&#25968;&#25454;&#21019;&#24314;&#27573;&#33853;&#32423;&#21035;&#30340;&#25968;&#25454;&#65292;&#29992;&#20110;&#35757;&#32451;&#21644;&#20803;&#35780;&#20272;&#25351;&#26631;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#26032;&#25968;&#25454;&#38598;&#26469;&#35780;&#20272;&#29616;&#26377;&#30340;&#21477;&#23376;&#32423;&#21035;&#25351;&#26631;&#65292;&#24182;&#22312;&#27573;&#33853;&#32423;&#21035;&#19978;&#35757;&#32451;&#23398;&#20064;&#25351;&#26631;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#21477;&#23376;&#32423;&#21035;&#30340;&#25351;&#26631;&#26469;&#35780;&#20998;&#25972;&#20010;&#27573;&#33853;&#19982;&#20351;&#29992;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#27573;&#33853;&#32423;&#21035;&#24037;&#20316;&#30340;&#25351;&#26631;&#19968;&#26679;&#26377;&#25928;&#12290;&#25105;&#20204;&#25512;&#27979;&#36825;&#20010;&#32467;&#26524;&#21487;&#33021;&#24402;&#22240;&#20110;&#21442;&#32771;&#35780;&#20272;&#20219;&#21153;&#30340;&#29305;&#24615;&#20197;&#21450;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#22312;&#25429;&#25417;&#27573;&#33853;&#32423;&#21035;&#32763;&#35793;&#20013;&#20986;&#29616;&#30340;&#25152;&#26377;&#31867;&#22411;&#29616;&#35937;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As research on machine translation moves to translating text beyond the sentence level, it remains unclear how effective automatic evaluation metrics are at scoring longer translations. In this work, we first propose a method for creating paragraph-level data for training and meta-evaluating metrics from existing sentence-level data. Then, we use these new datasets to benchmark existing sentence-level metrics as well as train learned metrics at the paragraph level. Interestingly, our experimental results demonstrate that using sentence-level metrics to score entire paragraphs is equally as effective as using a metric designed to work at the paragraph level. We speculate this result can be attributed to properties of the task of reference-based evaluation as well as limitations of our datasets with respect to capturing all types of phenomena that occur in paragraph-level translations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27169;&#22411;&#25237;&#31080;&#25552;&#31034;(MVP)&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;(FSL)&#29615;&#22659;&#19979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#26597;&#35810;&#24615;&#33021;&#12290;MVP&#36890;&#36807;&#25552;&#31034;&#22810;&#20010;LLMs&#25191;&#34892;&#30456;&#21516;&#30340;&#20219;&#21153;&#65292;&#24182;&#23545;&#29983;&#25104;&#30340;&#36755;&#20986;&#36827;&#34892;&#22810;&#25968;&#25237;&#31080;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#32597;&#35265;&#30149;&#30340;&#35782;&#21035;&#21644;&#20998;&#31867;&#20219;&#21153;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.12890</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25237;&#31080;&#65306;&#29992;&#20110;&#32597;&#35265;&#30149;&#35782;&#21035;&#30340;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27169;&#22411;&#25237;&#31080;&#25552;&#31034;(MVP)&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;(FSL)&#29615;&#22659;&#19979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#26597;&#35810;&#24615;&#33021;&#12290;MVP&#36890;&#36807;&#25552;&#31034;&#22810;&#20010;LLMs&#25191;&#34892;&#30456;&#21516;&#30340;&#20219;&#21153;&#65292;&#24182;&#23545;&#29983;&#25104;&#30340;&#36755;&#20986;&#36827;&#34892;&#22810;&#25968;&#25237;&#31080;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#32597;&#35265;&#30149;&#30340;&#35782;&#21035;&#21644;&#20998;&#31867;&#20219;&#21153;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#30340;&#20986;&#29616;&#24378;&#35843;&#20102;&#20934;&#30830;&#21644;&#39640;&#25928;&#30340;&#25552;&#31034;&#26041;&#27861;&#30340;&#38656;&#27714;&#12290;LLMs&#32463;&#24120;&#24212;&#29992;&#20110;&#23569;&#26679;&#26412;&#23398;&#20064;(FSL)&#30340;&#24773;&#22659;&#20013;&#65292;&#36825;&#37324;&#20219;&#21153;&#21482;&#20351;&#29992;&#24456;&#23569;&#30340;&#35757;&#32451;&#25968;&#25454;&#25191;&#34892;&#12290;FSL&#22312;&#35768;&#22810;&#20154;&#24037;&#26234;&#33021;(AI)&#23376;&#39046;&#22495;&#20013;&#21464;&#24471;&#27969;&#34892;&#65292;&#21253;&#25324;&#29992;&#20110;&#20581;&#24247;&#30340;AI&#12290;&#32597;&#35265;&#30149;&#24433;&#21709;&#20154;&#21475;&#30340;&#19968;&#23567;&#37096;&#20998;&#65292;&#22312;&#25968;&#25454;&#21487;&#29992;&#24615;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979; inherently &#38656;&#35201;FSL&#25216;&#26415;&#65292;&#23613;&#31649;&#20154;&#24037;&#25968;&#25454;&#25910;&#38598;&#21644;&#26631;&#27880;&#36153;&#26102;&#36153;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27169;&#22411;&#25237;&#31080;&#25552;&#31034;(MVP)&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;FSL&#29615;&#22659;&#20013;LLM&#26597;&#35810;&#24615;&#33021;&#30340;&#28789;&#27963;&#25552;&#31034;&#26041;&#27861;&#12290;MVP&#36890;&#36807;&#25552;&#31034;&#22810;&#20010;LLMs&#25191;&#34892;&#30456;&#21516;&#30340;&#20219;&#21153;&#65292;&#28982;&#21518;&#23545;&#29983;&#25104;&#30340;&#36755;&#20986;&#36827;&#34892;&#22810;&#25968;&#25237;&#31080;&#26469;&#23454;&#29616;&#12290;&#35813;&#26041;&#27861;&#22312;&#21333;&#27425;&#32597;&#35265;&#30149;&#35782;&#21035;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#30456;&#23545;&#20110;&#20219;&#20309;&#21333;&#20010;&#27169;&#22411;&#22312;&#38598;&#25104;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#32597;&#35265;&#30149;&#25968;&#25454;&#38598;&#29992;&#20110;FSL&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FS
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24212;&#29992;&#20110;&#32593;&#32476;&#23433;&#20840;&#29615;&#22659;&#65292;&#20316;&#20026;&#25915;&#20987;&#20195;&#29702;&#20154;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#12290;&#35813;&#35774;&#35745;&#34920;&#26126;LLMs&#22312;&#39640;&#25928;&#24212;&#23545;&#22797;&#26434;&#20915;&#31574;&#26041;&#38754;&#20855;&#26377;&#28508;&#21147;&#65292;&#24182;&#19988;&#22312;&#22823;&#22810;&#25968;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#26368;&#20808;&#36827;&#20195;&#29702;&#30456;&#20284;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12086</link><description>&lt;p&gt;
&#36208;&#20986;&#31548;&#23376;&#65306;&#38543;&#26426;&#40550;&#40521;&#22312;&#32593;&#32476;&#23433;&#20840;&#29615;&#22659;&#20013;&#30340;&#32988;&#21033;
&lt;/p&gt;
&lt;p&gt;
Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments. (arXiv:2308.12086v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24212;&#29992;&#20110;&#32593;&#32476;&#23433;&#20840;&#29615;&#22659;&#65292;&#20316;&#20026;&#25915;&#20987;&#20195;&#29702;&#20154;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#12290;&#35813;&#35774;&#35745;&#34920;&#26126;LLMs&#22312;&#39640;&#25928;&#24212;&#23545;&#22797;&#26434;&#20915;&#31574;&#26041;&#38754;&#20855;&#26377;&#28508;&#21147;&#65292;&#24182;&#19988;&#22312;&#22823;&#22810;&#25968;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#19982;&#32463;&#36807;&#35757;&#32451;&#30340;&#26368;&#20808;&#36827;&#20195;&#29702;&#30456;&#20284;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#28041;&#21450;&#25991;&#26412;&#29983;&#25104;&#12289;&#25688;&#35201;&#21644;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#19981;&#21516;&#39046;&#22495;&#20013;&#24191;&#21463;&#27426;&#36814;&#12290;&#23613;&#31649;&#23384;&#22312;&#22266;&#26377;&#30340;&#23616;&#38480;&#24615;&#65292;&#22522;&#20110;LLM&#30340;&#35774;&#35745;&#22312;&#35268;&#21010;&#21644;&#23548;&#33322;&#24320;&#25918;&#19990;&#30028;&#22330;&#26223;&#26041;&#38754;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#23558;&#39044;&#35757;&#32451;&#30340;LLMs&#29992;&#20316;&#32593;&#32476;&#23433;&#20840;&#29615;&#22659;&#20013;&#30340;&#20195;&#29702;&#20154;&#30340;&#26032;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#23427;&#20204;&#22312;&#39034;&#24207;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#20316;&#20026;&#20004;&#20010;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#25915;&#20987;&#20195;&#29702;&#12290;&#22312;&#22823;&#22810;&#25968;&#22330;&#26223;&#21644;&#37197;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#20195;&#29702;&#22312;&#34920;&#29616;&#19978;&#19982;&#32463;&#36807;&#25968;&#21315;&#27425;&#35757;&#32451;&#30340;&#26368;&#20808;&#36827;&#20195;&#29702;&#30456;&#20284;&#25110;&#26356;&#22909;&#12290;&#27492;&#22806;&#65292;&#26368;&#20339;LLM&#20195;&#29702;&#22312;&#27809;&#26377;&#20219;&#20309;&#39069;&#22806;&#35757;&#32451;&#36807;&#31243;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#19982;&#29615;&#22659;&#30340;&#20154;&#31867;&#27979;&#35797;&#32773;&#31867;&#20284;&#12290;&#36825;&#31181;&#35774;&#35745;&#31361;&#26174;&#20102;LLMs&#22312;&#39640;&#25928;&#24212;&#23545;&#22797;&#26434;&#20915;&#31574;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have gained widespread popularity across diverse domains involving text generation, summarization, and various natural language processing tasks. Despite their inherent limitations, LLM-based designs have shown promising capabilities in planning and navigating open-world scenarios. This paper introduces a novel application of pre-trained LLMs as agents within cybersecurity network environments, focusing on their utility for sequential decision-making processes.  We present an approach wherein pre-trained LLMs are leveraged as attacking agents in two reinforcement learning environments. Our proposed agents demonstrate similar or better performance against state-of-the-art agents trained for thousands of episodes in most scenarios and configurations. In addition, the best LLM agents perform similarly to human testers of the environment without any additional training process. This design highlights the potential of LLMs to efficiently address complex decision
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#34920;&#26684;&#24207;&#21015;&#21270;&#27169;&#22359;&#21644;&#32416;&#27491;&#26426;&#21046;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#25216;&#26415;&#20173;&#26377;&#24046;&#36317;&#65292;&#20294;&#35813;&#26041;&#27861;&#22312;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#23450;&#30340;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2308.11891</link><description>&lt;p&gt;
&#32447;&#24615;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#20998;&#26512;&#34920;&#26684;&#25968;&#25454;&#30340;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Bridging the Gap: Deciphering Tabular Data Using Large Language Model. (arXiv:2308.11891v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11891
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#34920;&#26684;&#24207;&#21015;&#21270;&#27169;&#22359;&#21644;&#32416;&#27491;&#26426;&#21046;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#25216;&#26415;&#20173;&#26377;&#24046;&#36317;&#65292;&#20294;&#35813;&#26041;&#27861;&#22312;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#19968;&#23450;&#30340;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#65292;&#23545;&#34920;&#26684;&#25968;&#25454;&#30340;&#29702;&#35299;&#19968;&#30452;&#26159;&#23398;&#26415;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#38543;&#30528;&#35832;&#22914;ChatGPT&#20043;&#31867;&#30340;&#24222;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#22987;&#25506;&#32034;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#26469;&#22788;&#29702;&#19982;&#34920;&#26684;&#30456;&#20851;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26088;&#22312;&#25506;&#32034;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#34920;&#26684;&#32467;&#26500;&#21644;&#20869;&#23481;&#19978;&#30340;&#33021;&#21147;&#65292;&#20197;&#20415;&#26356;&#22909;&#22320;&#22238;&#31572;&#30456;&#20851;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;&#23558;&#34920;&#26684;&#24207;&#21015;&#21270;&#30340;&#27169;&#22359;&#65292;&#24182;&#22312;&#27169;&#22411;&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#32416;&#27491;&#26426;&#21046;&#26469;&#20462;&#27491;&#28508;&#22312;&#30340;&#38169;&#35823;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#23613;&#31649;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#25216;&#26415;&#20173;&#26377;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the realm of natural language processing, the understanding of tabular data has perpetually stood as a focal point of scholarly inquiry. The emergence of expansive language models, exemplified by the likes of ChatGPT, has ushered in a wave of endeavors wherein researchers aim to harness these models for tasks related to table-based question answering. Central to our investigative pursuits is the elucidation of methodologies that amplify the aptitude of such large language models in discerning both the structural intricacies and inherent content of tables, ultimately facilitating their capacity to provide informed responses to pertinent queries. To this end, we have architected a distinctive module dedicated to the serialization of tables for seamless integration with expansive language models. Additionally, we've instituted a corrective mechanism within the model to rectify potential inaccuracies. Experimental results indicate that, although our proposed method trails the SOTA by ap
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#22312;&#30495;&#23454;&#30340;&#36719;&#20214;&#24320;&#21457;&#20013;&#21487;&#25191;&#34892;&#30340;&#20195;&#30721;&#24182;&#19981;&#33021;&#20445;&#35777;&#21487;&#38752;&#21644;&#40065;&#26834;&#65292;&#28389;&#29992;API&#21487;&#33021;&#23548;&#33268;&#20005;&#37325;&#38382;&#39064;&#12290;&#36825;&#23545;&#21021;&#32423;&#24320;&#21457;&#32773;&#26469;&#35828;&#23588;&#20854;&#21361;&#38505;&#65292;&#22240;&#20026;&#20182;&#20204;&#24456;&#38590;&#23519;&#35273;&#21040;&#20195;&#30721;&#20013;&#30340;API&#28389;&#29992;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.10335</link><description>&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20195;&#30721;&#29983;&#25104;&#30340;&#40065;&#26834;&#24615;&#21644;&#21487;&#38752;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#22312;&#30495;&#23454;&#30340;&#36719;&#20214;&#24320;&#21457;&#20013;&#21487;&#25191;&#34892;&#30340;&#20195;&#30721;&#24182;&#19981;&#33021;&#20445;&#35777;&#21487;&#38752;&#21644;&#40065;&#26834;&#65292;&#28389;&#29992;API&#21487;&#33021;&#23548;&#33268;&#20005;&#37325;&#38382;&#39064;&#12290;&#36825;&#23545;&#21021;&#32423;&#24320;&#21457;&#32773;&#26469;&#35828;&#23588;&#20854;&#21361;&#38505;&#65292;&#22240;&#20026;&#20182;&#20204;&#24456;&#38590;&#23519;&#35273;&#21040;&#20195;&#30721;&#20013;&#30340;API&#28389;&#29992;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#29702;&#35299;&#33258;&#28982;&#35821;&#35328;&#21644;&#29983;&#25104;&#32534;&#31243;&#20195;&#30721;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#38750;&#20961;&#33021;&#21147;&#12290;&#24403;&#36935;&#21040;&#32534;&#30721;&#38382;&#39064;&#26102;&#65292;&#36719;&#20214;&#24037;&#31243;&#24072;&#24120;&#24120;&#20250;&#21672;&#35810;LLMs&#12290;&#23613;&#31649;&#24050;&#32463;&#20570;&#20986;&#20102;&#19968;&#20123;&#21162;&#21147;&#26469;&#36991;&#20813;&#35821;&#27861;&#38169;&#35823;&#24182;&#20351;&#20195;&#30721;&#19982;&#39044;&#26399;&#30340;&#35821;&#20041;&#23545;&#40784;&#65292;&#20294;LLMs&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#23578;&#26410;&#34987;&#28145;&#20837;&#30740;&#31350;&#12290;&#22312;&#30495;&#23454;&#30340;&#36719;&#20214;&#24320;&#21457;&#29615;&#22659;&#20013;&#65292;&#21487;&#25191;&#34892;&#30340;&#20195;&#30721;&#24182;&#19981;&#31561;&#21516;&#20110;&#21487;&#38752;&#21644;&#40065;&#26834;&#30340;&#20195;&#30721;&#12290;&#22312;&#29983;&#25104;&#30340;&#20195;&#30721;&#20013;&#28389;&#29992;API&#21487;&#33021;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#38382;&#39064;&#65292;&#22914;&#36164;&#28304;&#27844;&#28431;&#12289;&#31243;&#24207;&#23849;&#28291;&#12290;&#26356;&#31967;&#31957;&#30340;&#26159;&#65292;LLM&#20195;&#30721;&#29983;&#25104;&#26381;&#21153;&#30340;&#29992;&#25143;&#23454;&#38469;&#19978;&#26159;&#26368;&#23481;&#26131;&#21463;&#21040;&#36825;&#20123;&#30475;&#20284;&#27491;&#30830;&#30340;&#20195;&#30721;&#24433;&#21709;&#30340;&#24320;&#21457;&#32773;&#8212;&#8212;&#20182;&#20204;&#36890;&#24120;&#26159;&#19981;&#29087;&#24713;LLMs&#20026;&#20182;&#20204;&#29983;&#25104;&#20195;&#30721;&#30340;API&#30340;&#21021;&#32423;&#24320;&#21457;&#32773;&#12290;&#22240;&#27492;&#65292;&#20182;&#20204;&#24456;&#38590;&#23519;&#35273;&#21040;API&#30340;&#28389;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the large language models (LLMs) have shown extraordinary ability in understanding natural language and generating programming code. It has been a common practice of software engineers to consult LLMs when encountering coding questions. Although efforts have been made to avoid syntax errors and align the code with the intended semantics, the reliability and robustness of the code generationfrom LLMs have not yet been thoroughly studied. The executable code is not equivalent to the reliable and robust code, especially in the context of real-world software development. The misuse of APIs in the generated code could lead to severe problem, such as resource leaks, program crashes. To make things worse, the users of LLM code generation services are actually the developers that are most vulnerable to these code that seems right -- They are always novice developers that are not familiar with the APIs that LLMs generate code for them. Therefore, they could hardly tell the misuse in t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#26469;&#28608;&#21457;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#25972;&#21512;&#26032;&#30693;&#35782;&#12289;&#20135;&#29983;&#24187;&#35273;&#21644;&#20915;&#31574;&#36807;&#31243;&#19981;&#36879;&#26126;&#31561;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#24605;&#32500;&#23548;&#22270;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#25512;&#29702;&#36335;&#24452;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#21462;&#24471;&#26174;&#33879;&#30340;&#23454;&#35777;&#22686;&#30410;&#12290;</title><link>http://arxiv.org/abs/2308.09729</link><description>&lt;p&gt;
MindMap&#65306;&#30693;&#35782;&#22270;&#35889;&#28608;&#21457;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24605;&#32500;&#22270;&#24605;&#32771;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#26469;&#28608;&#21457;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#25972;&#21512;&#26032;&#30693;&#35782;&#12289;&#20135;&#29983;&#24187;&#35273;&#21644;&#20915;&#31574;&#36807;&#31243;&#19981;&#36879;&#26126;&#31561;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#24605;&#32500;&#23548;&#22270;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#25512;&#29702;&#36335;&#24452;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#21462;&#24471;&#26174;&#33879;&#30340;&#23454;&#35777;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#24120;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#26080;&#27861;&#25972;&#21512;&#26032;&#30693;&#35782;&#12289;&#20135;&#29983;&#24187;&#35273;&#21644;&#20915;&#31574;&#36807;&#31243;&#19981;&#36879;&#26126;&#31561;&#38480;&#21046;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#30693;&#35782;&#22270;&#35889;&#65288;KG&#65289;&#26469;&#28608;&#21457;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#25972;&#21512;&#26368;&#26032;&#30693;&#35782;&#21644;&#24341;&#21457;&#27169;&#22411;&#24605;&#32500;&#36335;&#24452;&#30340;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#25552;&#31034;&#31649;&#36947;&#65292;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#29702;&#35299;KG&#36755;&#20837;&#24182;&#21033;&#29992;&#38544;&#21547;&#30693;&#35782;&#21644;&#26816;&#32034;&#21040;&#30340;&#22806;&#37096;&#30693;&#35782;&#36827;&#34892;&#25512;&#29702;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24341;&#21457;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25191;&#34892;&#25512;&#29702;&#21644;&#29983;&#25104;&#31572;&#26696;&#30340;&#24605;&#32500;&#23548;&#22270;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#29983;&#25104;&#30340;&#24605;&#32500;&#23548;&#22270;&#22522;&#20110;&#30693;&#35782;&#30340;&#26412;&#20307;&#35770;&#65292;&#23637;&#31034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#36335;&#24452;&#65292;&#20174;&#32780;&#20026;&#29983;&#20135;&#29615;&#22659;&#20013;&#30340;&#25512;&#29702;&#25552;&#20379;&#20102;&#25506;&#32034;&#21644;&#35780;&#20272;&#30340;&#21487;&#33021;&#24615;&#12290;&#23545;&#19977;&#20010;&#38382;&#31572;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;MindMap&#25552;&#31034;&#26041;&#27861;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#23454;&#35777;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question &amp; answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;Meituan&#25628;&#32034;&#20013;&#36827;&#34892;&#30456;&#20851;&#24615;&#24314;&#27169;&#30340;&#26032;&#39062;&#20004;&#38454;&#27573;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2308.07711</link><description>&lt;p&gt;
SPM: Meituan&#25628;&#32034;&#20013;&#29992;&#20110;&#30456;&#20851;&#24615;&#24314;&#27169;&#30340;&#32467;&#26500;&#21270;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;Meituan&#25628;&#32034;&#20013;&#36827;&#34892;&#30456;&#20851;&#24615;&#24314;&#27169;&#30340;&#26032;&#39062;&#20004;&#38454;&#27573;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#21830;&#25628;&#32034;&#20013;&#65292;&#26597;&#35810;&#21644;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26159;&#28385;&#36275;&#29992;&#25143;&#20307;&#39564;&#30340;&#22522;&#26412;&#35201;&#27714;&#12290;&#19982;&#20256;&#32479;&#30340;&#30005;&#21830;&#24179;&#21488;&#19981;&#21516;&#65292;&#29992;&#25143;&#22312;&#32654;&#22242;&#31561;&#29983;&#27963;&#26381;&#21153;&#24179;&#21488;&#19978;&#36827;&#34892;&#25628;&#32034;&#20027;&#35201;&#26159;&#20026;&#20102;&#20135;&#21697;&#20379;&#24212;&#21830;&#65292;&#36825;&#20123;&#20379;&#24212;&#21830;&#36890;&#24120;&#25317;&#26377;&#20016;&#23500;&#30340;&#32467;&#26500;&#21270;&#20449;&#24687;&#65292;&#20363;&#22914;&#21517;&#31216;&#12289;&#22320;&#22336;&#12289;&#31867;&#21035;&#12289;&#25104;&#21315;&#19978;&#19975;&#30340;&#20135;&#21697;&#12290;&#20351;&#29992;&#36825;&#20123;&#20016;&#23500;&#30340;&#32467;&#26500;&#21270;&#20869;&#23481;&#36827;&#34892;&#25628;&#32034;&#30456;&#20851;&#24615;&#24314;&#27169;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20027;&#35201;&#23384;&#22312;&#20197;&#19979;&#38382;&#39064;&#65306;&#65288;1&#65289;&#19981;&#21516;&#23383;&#27573;&#30340;&#32467;&#26500;&#21270;&#25991;&#26723;&#23384;&#22312;&#35821;&#35328;&#20998;&#24067;&#24046;&#24322;&#65292;&#26080;&#27861;&#30452;&#25509;&#37319;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#65288;&#22914;BERT&#65289;&#12290;&#65288;2&#65289;&#19981;&#21516;&#23383;&#27573;&#36890;&#24120;&#20855;&#26377;&#19981;&#21516;&#30340;&#37325;&#35201;&#24615;&#65292;&#19988;&#38271;&#24230;&#24046;&#24322;&#24456;&#22823;&#65292;&#24456;&#38590;&#25552;&#21462;&#23545;&#30456;&#20851;&#24615;&#21305;&#37197;&#26377;&#24110;&#21161;&#30340;&#25991;&#26723;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#38454;&#27573;&#39044;&#35757;&#32451;&#21644;&#21305;&#37197;&#26550;&#26500;&#65292;&#29992;&#20110;&#20016;&#23500;&#32467;&#26500;&#30340;&#30456;&#20851;&#24615;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching.  To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structure
&lt;/p&gt;</description></item><item><title>EcomGPT&#26159;&#38024;&#23545;&#30005;&#23376;&#21830;&#21153;&#39046;&#22495;&#30340;&#20219;&#21153;&#38142;&#35843;&#33410;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#21407;&#23376;&#20219;&#21153;&#38142;&#24182;&#20351;&#29992;EcomInstruct&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;&#20855;&#26377;&#36739;&#24378;&#30340;&#36890;&#29992;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.06966</link><description>&lt;p&gt;
EcomGPT: &#20351;&#29992;&#20219;&#21153;&#38142;&#35843;&#33410;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20197;&#36866;&#24212;&#30005;&#23376;&#21830;&#21153;&#39046;&#22495;
&lt;/p&gt;
&lt;p&gt;
EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce. (arXiv:2308.06966v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06966
&lt;/p&gt;
&lt;p&gt;
EcomGPT&#26159;&#38024;&#23545;&#30005;&#23376;&#21830;&#21153;&#39046;&#22495;&#30340;&#20219;&#21153;&#38142;&#35843;&#33410;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#21407;&#23376;&#20219;&#21153;&#38142;&#24182;&#20351;&#29992;EcomInstruct&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;&#20855;&#26377;&#36739;&#24378;&#30340;&#36890;&#29992;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25351;&#20196;&#36319;&#38543;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#20363;&#22914;ChatGPT&#65292;&#22312;&#36890;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#23637;&#29616;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30005;&#23376;&#21830;&#21153;&#25968;&#25454;&#30340;&#29420;&#29305;&#29305;&#28857;&#23545;&#20110;&#36890;&#29992;LLM&#26469;&#35828;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#38024;&#23545;&#30005;&#23376;&#21830;&#21153;&#22330;&#26223;&#30340;LLM&#65292;&#21517;&#20026;EcomGPT&#12290;&#36890;&#36807;&#26500;&#24314;&#20197;&#30005;&#23376;&#21830;&#21153;&#22522;&#26412;&#25968;&#25454;&#31867;&#22411;&#65288;&#20363;&#22914;&#20135;&#21697;&#20449;&#24687;&#12289;&#29992;&#25143;&#35780;&#20215;&#65289;&#20026;&#22522;&#30784;&#30340;&#21407;&#23376;&#20219;&#21153;&#65292;EcomInstruct&#25968;&#25454;&#38598;&#25193;&#22823;&#20102;&#25968;&#25454;&#35268;&#27169;&#21644;&#20219;&#21153;&#22810;&#26679;&#24615;&#12290;&#21407;&#23376;&#20219;&#21153;&#26159;&#38544;&#21547;&#22312;&#35299;&#20915;&#26368;&#32456;&#20219;&#21153;&#20013;&#30340;&#20013;&#38388;&#20219;&#21153;&#65292;&#25105;&#20204;&#20063;&#31216;&#20043;&#20026;&#20219;&#21153;&#38142;&#20219;&#21153;&#12290;&#36890;&#36807;&#20351;&#29992;EcomInstruct&#35757;&#32451;&#39592;&#24178;&#27169;&#22411;BLOOMZ&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20855;&#26377;&#19981;&#21516;&#21442;&#25968;&#35268;&#27169;&#30340;EcomGPT&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, instruction-following Large Language Models (LLMs) , represented by ChatGPT, have exhibited exceptional performance in general Natural Language Processing (NLP) tasks. However, the unique characteristics of E-commerce data pose significant challenges to general LLMs. An LLM tailored specifically for E-commerce scenarios, possessing robust cross-dataset/task generalization capabilities, is a pressing necessity. To solve this issue, in this work, we proposed the first e-commerce instruction dataset EcomInstruct, with a total of 2.5 million instruction data. EcomInstruct scales up the data size and task diversity by constructing atomic tasks with E-commerce basic data types, such as product information, user reviews. Atomic tasks are defined as intermediate tasks implicitly involved in solving a final task, which we also call Chain-of-Task tasks. We developed EcomGPT with different parameter scales by training the backbone model BLOOMZ with the EcomInstruct. Benefiting from the 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;Electra Transformer&#12289;GloVe&#21644;LSTM&#27169;&#22411;&#30340;&#21019;&#26032;&#38382;&#39064;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;TREC&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20005;&#26684;&#27979;&#35797;&#65292;&#35777;&#26126;&#20102;&#34701;&#21512;&#19981;&#21516;&#25216;&#26415;&#21487;&#20197;&#33719;&#24471;&#26356;&#20248;&#36234;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.06828</link><description>&lt;p&gt;
&#38382;&#39064;&#20998;&#31867;&#30340;&#38598;&#25104;&#26041;&#27861;&#65306;&#34701;&#21512;Electra Transformer&#12289;GloVe&#21644;LSTM
&lt;/p&gt;
&lt;p&gt;
An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM. (arXiv:2308.06828v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;Electra Transformer&#12289;GloVe&#21644;LSTM&#27169;&#22411;&#30340;&#21019;&#26032;&#38382;&#39064;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;TREC&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20005;&#26684;&#27979;&#35797;&#65292;&#35777;&#26126;&#20102;&#34701;&#21512;&#19981;&#21516;&#25216;&#26415;&#21487;&#20197;&#33719;&#24471;&#26356;&#20248;&#36234;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24050;&#32463;&#25104;&#20026;&#29702;&#35299;&#21644;&#29983;&#25104;&#20154;&#31867;&#35821;&#35328;&#30340;&#20851;&#38190;&#25216;&#26415;&#65292;&#23427;&#22312;&#26426;&#22120;&#32763;&#35793;&#12289;&#24773;&#24863;&#20998;&#26512;&#31561;&#20219;&#21153;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#65292;&#23588;&#20854;&#26159;&#22312;&#38382;&#39064;&#20998;&#31867;&#26041;&#38754;&#12290;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#23376;&#39046;&#22495;&#65292;&#38382;&#39064;&#20998;&#31867;&#19987;&#27880;&#20110;&#30830;&#23450;&#25152;&#38656;&#20449;&#24687;&#30340;&#31867;&#22411;&#65292;&#36825;&#26159;&#38382;&#39064;&#22238;&#31572;&#31995;&#32479;&#31561;&#19979;&#28216;&#24212;&#29992;&#30340;&#22522;&#26412;&#27493;&#39588;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#38382;&#39064;&#20998;&#31867;&#38598;&#25104;&#26041;&#27861;&#65292;&#23558;Electra&#12289;GloVe&#21644;LSTM&#27169;&#22411;&#30340;&#20248;&#21183;&#30456;&#32467;&#21512;&#12290;&#35813;&#27169;&#22411;&#22312;&#33879;&#21517;&#30340;TREC&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#25972;&#21512;&#36825;&#20123;&#19981;&#21516;&#25216;&#26415;&#21487;&#20197;&#24471;&#21040;&#26356;&#20248;&#36234;&#30340;&#32467;&#26524;&#12290;Electra&#25552;&#20379;&#20102;&#22522;&#20110;transformer&#30340;&#22797;&#26434;&#35821;&#35328;&#29702;&#35299;&#33021;&#21147;&#65292;GloVe&#25552;&#20379;&#20102;&#20840;&#23616;&#21521;&#37327;&#34920;&#31034;&#20197;&#25429;&#25417;&#35789;&#32423;&#35821;&#20041;&#65292;LSTM&#21017;&#36129;&#29486;&#20102;&#24207;&#21015;&#23398;&#20064;&#33021;&#21147;&#20197;&#24314;&#27169;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural Language Processing (NLP) has emerged as a crucial technology for understanding and generating human language, playing an essential role in tasks such as machine translation, sentiment analysis, and more pertinently, question classification. As a subfield within NLP, question classification focuses on determining the type of information being sought, a fundamental step for downstream applications like question answering systems. This study presents an innovative ensemble approach for question classification, combining the strengths of Electra, GloVe, and LSTM models. Rigorously tested on the well-regarded TREC dataset, the model demonstrates how the integration of these disparate technologies can lead to superior results. Electra brings in its transformer-based capabilities for complex language understanding, GloVe offers global vector representations for capturing word-level semantics, and LSTM contributes its sequence learning abilities to model long-term dependencies. By fus
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#20174;&#22806;&#37096;&#23384;&#20648;&#24211;&#20013;&#36873;&#25321;&#24615;&#22320;&#38598;&#25104;&#30693;&#35782;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22806;&#37096;&#25512;&#29702;&#30340;&#26032;&#26041;&#27861;&#65292;&#20363;&#23376;&#26159;ChatPDF&#12290;</title><link>http://arxiv.org/abs/2307.12057</link><description>&lt;p&gt;
&#22806;&#37096;&#25512;&#29702;&#65306;&#26397;&#30528;&#22810;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20114;&#25442;&#36741;&#21161;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#26041;&#21521;&#21069;&#36827;
&lt;/p&gt;
&lt;p&gt;
External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback. (arXiv:2307.12057v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12057
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#20174;&#22806;&#37096;&#23384;&#20648;&#24211;&#20013;&#36873;&#25321;&#24615;&#22320;&#38598;&#25104;&#30693;&#35782;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22806;&#37096;&#25512;&#29702;&#30340;&#26032;&#26041;&#27861;&#65292;&#20363;&#23376;&#26159;ChatPDF&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35760;&#24518;&#34987;&#35748;&#20026;&#26159;&#20351;&#28023;&#39532;&#20307;&#21644;&#33041;&#31070;&#32463;&#20803;&#20869;&#20445;&#25345;&#35270;&#35273;&#21644;&#35821;&#35328;&#20449;&#24687;&#12289;&#38543;&#21518;&#29992;&#20110;&#35299;&#20915;&#36890;&#36807;&#23398;&#20064;&#19968;&#29983;&#20013;&#36935;&#21040;&#30340;&#29616;&#23454;&#25361;&#25112;&#30340;&#20851;&#38190;&#20154;&#31867;&#33021;&#21147;&#12290;&#36890;&#36807;&#24212;&#29992;&#24050;&#33719;&#24471;&#30340;&#30693;&#35782;&#35299;&#20915;&#22797;&#26434;&#30340;&#20154;&#24037;&#26234;&#33021;&#20219;&#21153;&#26159;&#23454;&#29616;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#30340;&#19968;&#22823;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20687;GPT-3.5&#21644;GPT-4&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35821;&#35328;&#29702;&#35299;&#12289;&#29983;&#25104;&#12289;&#20132;&#20114;&#21644;&#25512;&#29702;&#26041;&#38754;&#26174;&#31034;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#30001;&#20110;&#19978;&#19979;&#25991;&#38271;&#24230;&#30340;&#38480;&#21046;&#65292;&#23427;&#20204;&#26080;&#27861;&#22788;&#29702;&#24191;&#27867;&#12289;&#19981;&#26029;&#28436;&#21464;&#30340;&#30693;&#35782;&#24211;&#12290;&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#20174;&#22806;&#37096;&#23384;&#20648;&#24211;&#20013;&#36873;&#25321;&#24615;&#22320;&#38598;&#25104;&#30693;&#35782;&#26469;&#22686;&#24378;LLMs&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#22806;&#37096;&#25512;&#29702;&#30340;&#26032;&#26041;&#27861;&#65292;&#20363;&#23376;&#26159;ChatPDF&#12290;
&lt;/p&gt;
&lt;p&gt;
Memory is identified as a crucial human faculty that allows for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise through a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4 , which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#65292;&#24378;&#35843;&#20102;&#24179;&#34913;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#24341;&#20837;&#21547;&#26377;&#24694;&#24847;&#25351;&#20196;&#30340;&#28508;&#22312;&#36234;&#29425;&#25552;&#31034;&#25968;&#25454;&#38598;&#65292;&#24182;&#35774;&#35745;&#20998;&#23618;&#27880;&#37322;&#26694;&#26550;&#65292;&#20840;&#38754;&#30740;&#31350;&#20102;&#25991;&#26412;&#23433;&#20840;&#24615;&#21644;&#36755;&#20986;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.08487</link><description>&lt;p&gt;
&#28508;&#22312;&#36234;&#29425;&#65306;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#23433;&#20840;&#24615;&#21644;&#36755;&#20986;&#40065;&#26834;&#24615;&#30340;&#27979;&#35797;&#22871;&#20214;
&lt;/p&gt;
&lt;p&gt;
Latent Jailbreak: A Test Suite for Evaluating Both Text Safety and Output Robustness of Large Language Models. (arXiv:2307.08487v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08487
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;&#22871;&#20214;&#65292;&#24378;&#35843;&#20102;&#24179;&#34913;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#24341;&#20837;&#21547;&#26377;&#24694;&#24847;&#25351;&#20196;&#30340;&#28508;&#22312;&#36234;&#29425;&#25552;&#31034;&#25968;&#25454;&#38598;&#65292;&#24182;&#35774;&#35745;&#20998;&#23618;&#27880;&#37322;&#26694;&#26550;&#65292;&#20840;&#38754;&#30740;&#31350;&#20102;&#25991;&#26412;&#23433;&#20840;&#24615;&#21644;&#36755;&#20986;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#26377;&#22823;&#37327;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#30830;&#20445;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#30456;&#19968;&#33268;&#24182;&#29983;&#25104;&#23433;&#20840;&#25991;&#26412;&#12290;&#28982;&#32780;&#65292;&#23545;&#26576;&#20123;&#20027;&#39064;&#30340;&#36807;&#24230;&#20851;&#27880;&#21487;&#33021;&#20250;&#25439;&#23475;&#27169;&#22411;&#22312;&#36981;&#24490;&#25351;&#20196;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#20174;&#32780;&#24433;&#21709;&#20854;&#22312;&#23436;&#25104;&#20219;&#21153;&#26041;&#38754;&#30340;&#25972;&#20307;&#34920;&#29616;&#12290;&#20197;&#24448;&#29992;&#20110;&#36234;&#29425;LLMs&#30340;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#35780;&#20272;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#65292;&#32780;&#27809;&#26377;&#32771;&#34385;&#20854;&#40065;&#26834;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;LLMs&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#22522;&#20934;&#65292;&#24378;&#35843;&#38656;&#35201;&#19968;&#20010;&#24179;&#34913;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#20840;&#38754;&#30740;&#31350;&#25991;&#26412;&#23433;&#20840;&#24615;&#21644;&#36755;&#20986;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#28508;&#22312;&#36234;&#29425;&#25552;&#31034;&#25968;&#25454;&#38598;&#65292;&#27599;&#20010;&#25968;&#25454;&#38598;&#20013;&#37117;&#21253;&#21547;&#24694;&#24847;&#25351;&#20196;&#23884;&#20837;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25351;&#23548;&#27169;&#22411;&#23436;&#25104;&#24120;&#35268;&#20219;&#21153;&#65292;&#20363;&#22914;&#32763;&#35793;&#65292;&#20854;&#20013;&#24453;&#32763;&#35793;&#30340;&#25991;&#26412;&#21253;&#21547;&#24694;&#24847;&#25351;&#20196;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#20998;&#26512;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20998;&#23618;&#27880;&#37322;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Considerable research efforts have been devoted to ensuring that large language models (LLMs) align with human values and generate safe text. However, an excessive focus on sensitivity to certain topics can compromise the model's robustness in following instructions, thereby impacting its overall performance in completing tasks. Previous benchmarks for jailbreaking LLMs have primarily focused on evaluating the safety of the models without considering their robustness. In this paper, we propose a benchmark that assesses both the safety and robustness of LLMs, emphasizing the need for a balanced approach. To comprehensively study text safety and output robustness, we introduce a latent jailbreak prompt dataset, each involving malicious instruction embedding. Specifically, we instruct the model to complete a regular task, such as translation, with the text to be translated containing malicious instructions. To further analyze safety and robustness, we design a hierarchical annotation fram
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#36719;&#20214;&#24320;&#21457;&#33539;&#24335;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25972;&#20010;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#23454;&#29616;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#65292;&#28040;&#38500;&#20102;&#27599;&#20010;&#38454;&#27573;&#38656;&#35201;&#19987;&#38376;&#27169;&#22411;&#30340;&#38656;&#27714;&#12290;&#35813;&#33539;&#24335;&#20351;&#29992;ChatDev&#20316;&#20026;&#19968;&#20010;&#34394;&#25311;&#32842;&#22825;&#39537;&#21160;&#30340;&#36719;&#20214;&#24320;&#21457;&#20844;&#21496;&#65292;&#36890;&#36807;&#35774;&#35745;&#12289;&#32534;&#30721;&#12289;&#27979;&#35797;&#21644;&#25991;&#26723;&#21270;&#22235;&#20010;&#38454;&#27573;&#30340;&#20195;&#29702;&#20154;&#22242;&#38431;&#20419;&#36827;&#21327;&#20316;&#12290;</title><link>http://arxiv.org/abs/2307.07924</link><description>&lt;p&gt;
&#36719;&#20214;&#24320;&#21457;&#20013;&#30340;&#20132;&#27969;&#22411;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Communicative Agents for Software Development. (arXiv:2307.07924v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#36719;&#20214;&#24320;&#21457;&#33539;&#24335;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25972;&#20010;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#23454;&#29616;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#65292;&#28040;&#38500;&#20102;&#27599;&#20010;&#38454;&#27573;&#38656;&#35201;&#19987;&#38376;&#27169;&#22411;&#30340;&#38656;&#27714;&#12290;&#35813;&#33539;&#24335;&#20351;&#29992;ChatDev&#20316;&#20026;&#19968;&#20010;&#34394;&#25311;&#32842;&#22825;&#39537;&#21160;&#30340;&#36719;&#20214;&#24320;&#21457;&#20844;&#21496;&#65292;&#36890;&#36807;&#35774;&#35745;&#12289;&#32534;&#30721;&#12289;&#27979;&#35797;&#21644;&#25991;&#26723;&#21270;&#22235;&#20010;&#38454;&#27573;&#30340;&#20195;&#29702;&#20154;&#22242;&#38431;&#20419;&#36827;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#24037;&#31243;&#26159;&#19968;&#20010;&#20197;&#24494;&#22937;&#30340;&#30452;&#35273;&#21644;&#21672;&#35810;&#20026;&#29305;&#24449;&#30340;&#39046;&#22495;&#65292;&#20915;&#31574;&#36807;&#31243;&#22797;&#26434;&#12290;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#24320;&#22987;&#36890;&#36807;&#22312;&#36719;&#20214;&#24320;&#21457;&#30340;&#21508;&#20010;&#38454;&#27573;&#23454;&#26045;&#31934;&#24515;&#35774;&#35745;&#26469;&#38761;&#26032;&#36719;&#20214;&#24037;&#31243;&#23454;&#36341;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#33539;&#24335;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#65292;&#22312;&#25972;&#20010;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20851;&#38190;&#27969;&#31243;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#22312;&#27599;&#20010;&#38454;&#27573;&#38656;&#35201;&#19987;&#38376;&#30340;&#27169;&#22411;&#30340;&#38656;&#35201;&#12290;&#36825;&#20010;&#33539;&#24335;&#30340;&#26680;&#24515;&#26159;ChatDev&#65292;&#19968;&#20010;&#34394;&#25311;&#30340;&#32842;&#22825;&#39537;&#21160;&#36719;&#20214;&#24320;&#21457;&#20844;&#21496;&#65292;&#23427;&#27169;&#20223;&#20102;&#24050;&#32463;&#24314;&#31435;&#30340;&#28689;&#24067;&#27169;&#22411;&#65292;&#23558;&#24320;&#21457;&#36807;&#31243;&#32454;&#20998;&#20026;&#22235;&#20010;&#19981;&#21516;&#30340;&#26102;&#38388;&#38454;&#27573;&#65306;&#35774;&#35745;&#12289;&#32534;&#30721;&#12289;&#27979;&#35797;&#21644;&#25991;&#26723;&#21270;&#12290;&#27599;&#20010;&#38454;&#27573;&#37117;&#28041;&#21450;&#19968;&#20010;&#22242;&#38431;&#30340;&#20195;&#29702;&#20154;&#65292;&#22914;&#31243;&#24207;&#21592;&#12289;&#20195;&#30721;&#23457;&#26597;&#20154;&#21592;&#21644;&#27979;&#35797;&#24037;&#31243;&#24072;&#65292;&#20419;&#36827;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Software engineering is a domain characterized by intricate decision-making processes, often relying on nuanced intuition and consultation. Recent advancements in deep learning have started to revolutionize software engineering practices through elaborate designs implemented at various stages of software development. In this paper, we present an innovative paradigm that leverages large language models (LLMs) throughout the entire software development process, streamlining and unifying key processes through natural language communication, thereby eliminating the need for specialized models at each phase. At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting. Each stage engages a team of agents, such as programmers, code reviewers, and test engineers, fostering collaborativ
&lt;/p&gt;</description></item><item><title>AspectCSE&#26159;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21644;&#32467;&#26500;&#21270;&#30693;&#35782;&#36827;&#34892;&#22522;&#20110;&#26041;&#38754;&#30340;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#30340;&#21477;&#23376;&#23884;&#20837;&#26041;&#27861;&#65292;&#23427;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30456;&#27604;&#20043;&#21069;&#30340;&#26368;&#22909;&#32467;&#26524;&#24179;&#22343;&#25552;&#39640;&#20102;3.97%&#65292;&#36890;&#36807;&#21516;&#26102;&#32771;&#34385;&#22810;&#20010;&#29305;&#23450;&#26041;&#38754;&#30340;&#23884;&#20837;&#27169;&#22411;&#20248;&#20110;&#21333;&#26041;&#38754;&#23884;&#20837;&#12290;</title><link>http://arxiv.org/abs/2307.07851</link><description>&lt;p&gt;
AspectCSE: &#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21644;&#32467;&#26500;&#21270;&#30693;&#35782;&#36827;&#34892;&#22522;&#20110;&#26041;&#38754;&#30340;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#30340;&#21477;&#23376;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07851
&lt;/p&gt;
&lt;p&gt;
AspectCSE&#26159;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#21644;&#32467;&#26500;&#21270;&#30693;&#35782;&#36827;&#34892;&#22522;&#20110;&#26041;&#38754;&#30340;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#30340;&#21477;&#23376;&#23884;&#20837;&#26041;&#27861;&#65292;&#23427;&#22312;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#30456;&#27604;&#20043;&#21069;&#30340;&#26368;&#22909;&#32467;&#26524;&#24179;&#22343;&#25552;&#39640;&#20102;3.97%&#65292;&#36890;&#36807;&#21516;&#26102;&#32771;&#34385;&#22810;&#20010;&#29305;&#23450;&#26041;&#38754;&#30340;&#23884;&#20837;&#27169;&#22411;&#20248;&#20110;&#21333;&#26041;&#38754;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#29992;&#30340;&#21477;&#23376;&#23884;&#20837;&#25552;&#20379;&#20102;&#23545;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#30340;&#31895;&#30053;&#36817;&#20284;&#65292;&#20294;&#24573;&#30053;&#20102;&#20351;&#25991;&#26412;&#30456;&#20284;&#30340;&#29305;&#23450;&#26041;&#38754;&#12290;&#30456;&#21453;&#65292;&#22522;&#20110;&#26041;&#38754;&#30340;&#21477;&#23376;&#23884;&#20837;&#25552;&#20379;&#20102;&#22522;&#20110;&#39044;&#23450;&#20041;&#26041;&#38754;&#30340;&#25991;&#26412;&#30456;&#20284;&#24615;&#12290;&#22240;&#27492;&#65292;&#25991;&#26412;&#30340;&#30456;&#20284;&#24615;&#39044;&#27979;&#26356;&#21152;&#38024;&#23545;&#29305;&#23450;&#35201;&#27714;&#65292;&#24182;&#19988;&#26356;&#23481;&#26131;&#35299;&#37322;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AspectCSE&#65292;&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;&#26041;&#38754;&#30340;&#23545;&#27604;&#23398;&#20064;&#21477;&#23376;&#23884;&#20837;&#30340;&#26041;&#27861;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20043;&#21069;&#26368;&#22909;&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;AspectCSE&#22312;&#22810;&#20010;&#26041;&#38754;&#30340;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#24179;&#22343;&#25913;&#21892;3.97%&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20351;&#29992;Wikidata&#30693;&#35782;&#22270;&#23646;&#24615;&#26469;&#35757;&#32451;&#22810;&#26041;&#38754;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#20854;&#20013;&#22312;&#30456;&#20284;&#24615;&#39044;&#27979;&#36807;&#31243;&#20013;&#21516;&#26102;&#32771;&#34385;&#22810;&#20010;&#29305;&#23450;&#26041;&#38754;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22810;&#26041;&#38754;&#23884;&#20837;&#22312;&#29305;&#23450;&#26041;&#38754;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#19978;&#20248;&#20110;&#21333;&#26041;&#38754;&#23884;&#20837;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23884;&#20837;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#25552;&#20986;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#26469;&#25913;&#36827;&#23884;&#20837;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#20851;&#27880;&#19977;&#20010;&#20851;&#38190;&#32500;&#24230;&#65306;&#35780;&#20272;&#20160;&#20040;&#12289;&#22312;&#21738;&#37324;&#35780;&#20272;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#12290;&#35780;&#20272;&#20219;&#21153;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#25512;&#29702;&#12289;&#21307;&#23398;&#24212;&#29992;&#12289;&#20262;&#29702;&#23398;&#12289;&#25945;&#32946;&#12289;&#33258;&#28982;&#21644;&#31038;&#20250;&#31185;&#23398;&#12289;&#20195;&#29702;&#24212;&#29992;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#26412;&#25991;&#20026;&#31038;&#20250;&#23618;&#38754;&#23545;LLMs&#28508;&#22312;&#39118;&#38505;&#30340;&#29702;&#35299;&#25552;&#20379;&#20102;&#37325;&#35201;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2307.03109</link><description>&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#20851;&#27880;&#19977;&#20010;&#20851;&#38190;&#32500;&#24230;&#65306;&#35780;&#20272;&#20160;&#20040;&#12289;&#22312;&#21738;&#37324;&#35780;&#20272;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#12290;&#35780;&#20272;&#20219;&#21153;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#25512;&#29702;&#12289;&#21307;&#23398;&#24212;&#29992;&#12289;&#20262;&#29702;&#23398;&#12289;&#25945;&#32946;&#12289;&#33258;&#28982;&#21644;&#31038;&#20250;&#31185;&#23398;&#12289;&#20195;&#29702;&#24212;&#29992;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#26412;&#25991;&#20026;&#31038;&#20250;&#23618;&#38754;&#23545;LLMs&#28508;&#22312;&#39118;&#38505;&#30340;&#29702;&#35299;&#25552;&#20379;&#20102;&#37325;&#35201;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30001;&#20110;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#30340;&#21069;&#25152;&#26410;&#26377;&#30340;&#24615;&#33021;&#32780;&#22312;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#38543;&#30528;LLMs&#22312;&#30740;&#31350;&#21644;&#26085;&#24120;&#20351;&#29992;&#20013;&#32487;&#32493;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#23427;&#20204;&#30340;&#35780;&#20272;&#21464;&#24471;&#36234;&#26469;&#36234;&#20851;&#38190;&#65292;&#19981;&#20165;&#22312;&#20219;&#21153;&#27700;&#24179;&#19978;&#65292;&#32780;&#19988;&#22312;&#31038;&#20250;&#23618;&#38754;&#19978;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#23427;&#20204;&#30340;&#28508;&#22312;&#39118;&#38505;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#37324;&#65292;&#24050;&#32463;&#20570;&#20986;&#20102;&#30456;&#24403;&#22823;&#30340;&#21162;&#21147;&#26469;&#20174;&#19981;&#21516;&#30340;&#35282;&#24230;&#26469;&#30740;&#31350;LLMs&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;LLMs&#30340;&#36825;&#20123;&#35780;&#20272;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#19977;&#20010;&#20851;&#38190;&#32500;&#24230;&#65306;&#35780;&#20272;&#20160;&#20040;&#12289;&#22312;&#21738;&#37324;&#35780;&#20272;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20174;&#35780;&#20272;&#20219;&#21153;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#19968;&#20010;&#27010;&#36848;&#65292;&#28085;&#30422;&#20102;&#19968;&#33324;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#12289;&#25512;&#29702;&#12289;&#21307;&#23398;&#24212;&#29992;&#12289;&#20262;&#29702;&#23398;&#12289;&#25945;&#32946;&#12289;&#33258;&#28982;&#31185;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#12289;&#20195;&#29702;&#24212;&#29992;&#21644;&#20854;&#20182;&#39046;&#22495;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36890;&#36807;&#28145;&#20837;&#25506;&#35752;&#35780;&#20272;&#26041;&#27861;&#21644;&#22522;&#20934;&#31572;&#26696;&#26469;&#22238;&#31572;&#8220;&#22312;&#21738;&#37324;&#8221;&#21644;&#8220;&#22914;&#20309;&#8221;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#36731;&#37327;&#32423;&#36866;&#37197;&#22120;&#26469;&#39640;&#25928;&#22495;&#33258;&#36866;&#24212;&#21477;&#23376;&#23884;&#20837;&#30340;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#24494;&#35843;&#25972;&#20010;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#30340;&#36164;&#28304;&#28040;&#32791;&#12290;&#36890;&#36807;&#35757;&#32451;&#29305;&#23450;&#39046;&#22495;&#30340;&#36866;&#37197;&#22120;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#20351;&#29992;&#21516;&#19968;&#27169;&#22411;&#33719;&#24471;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.03104</link><description>&lt;p&gt;
&#20351;&#29992;&#36866;&#37197;&#22120;&#39640;&#25928;&#22495;&#33258;&#36866;&#24212;&#21477;&#23376;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03104
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#36731;&#37327;&#32423;&#36866;&#37197;&#22120;&#26469;&#39640;&#25928;&#22495;&#33258;&#36866;&#24212;&#21477;&#23376;&#23884;&#20837;&#30340;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#24494;&#35843;&#25972;&#20010;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#30340;&#36164;&#28304;&#28040;&#32791;&#12290;&#36890;&#36807;&#35757;&#32451;&#29305;&#23450;&#39046;&#22495;&#30340;&#36866;&#37197;&#22120;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#20351;&#29992;&#21516;&#19968;&#27169;&#22411;&#33719;&#24471;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21477;&#23376;&#23884;&#20837;&#20351;&#25105;&#20204;&#33021;&#22815;&#25429;&#25417;&#30701;&#25991;&#26412;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#22823;&#22810;&#25968;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#26159;&#38024;&#23545;&#19968;&#33324;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#65288;STS&#65289;&#20219;&#21153;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#22240;&#27492;&#65292;&#35201;&#22312;&#29305;&#23450;&#39046;&#22495;&#20013;&#20351;&#29992;&#21477;&#23376;&#23884;&#20837;&#65292;&#24517;&#39035;&#23558;&#27169;&#22411;&#36866;&#24212;&#20110;&#35813;&#39046;&#22495;&#20197;&#33719;&#24471;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;&#36890;&#24120;&#65292;&#36825;&#26159;&#36890;&#36807;&#23545;&#24863;&#20852;&#36259;&#30340;&#22495;&#23545;&#25972;&#20010;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#26469;&#23454;&#29616;&#30340;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#20135;&#29983;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#20294;&#22312;&#24494;&#35843;&#36807;&#31243;&#20013;&#26356;&#26032;&#20102;&#25152;&#26377;&#27169;&#22411;&#30340;&#26435;&#37325;&#65292;&#20351;&#35813;&#26041;&#27861;&#22312;&#36164;&#28304;&#19978;&#35201;&#27714;&#36739;&#39640;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35757;&#32451;&#36731;&#37327;&#32423;&#36866;&#37197;&#22120;&#30340;&#26041;&#27861;&#65292;&#32780;&#19981;&#26159;&#21333;&#29420;&#20026;&#27599;&#20010;&#30446;&#26631;&#39046;&#22495;&#24494;&#35843;&#25972;&#20010;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#12290;&#36825;&#20123;&#29305;&#23450;&#39046;&#22495;&#30340;&#36866;&#37197;&#22120;&#19981;&#38656;&#35201;&#24494;&#35843;&#25152;&#26377;&#24213;&#23618;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#21482;&#35757;&#32451;&#23569;&#37327;&#30340;&#39069;&#22806;&#21442;&#25968;&#65292;&#21516;&#26102;&#20445;&#25345;&#24213;&#23618;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#30340;&#26435;&#37325;&#19981;&#21464;&#12290;&#35757;&#32451;&#29305;&#23450;&#39046;&#22495;&#30340;&#36866;&#37197;&#22120;&#21487;&#20197;&#22987;&#32456;&#20351;&#29992;&#21516;&#19968;&#27169;&#22411;&#24182;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#33719;&#24471;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;Reddit&#19978;&#20998;&#26512;&#20102;&#20004;&#26041;&#23545;&#35805;&#20027;&#39064;&#30340;&#22823;&#37327;&#35821;&#26009;&#24211;&#65292;&#30740;&#31350;&#20102;LSM&#22312;&#23545;&#35805;&#20013;&#30340;&#24046;&#24322;&#20197;&#21450;&#19982;&#31038;&#21306;&#25351;&#26631;&#30340;&#20851;&#31995;&#65292;&#25581;&#31034;&#20102;&#29702;&#35299;&#31038;&#21306;&#21160;&#24577;&#26102;&#23545;&#35805;&#21442;&#19982;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02758</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#31038;&#21306;&#20013;&#25506;&#32034;&#35821;&#35328;&#39118;&#26684;&#21305;&#37197;&#65306;&#31038;&#20250;&#32972;&#26223;&#21644;&#23545;&#35805;&#21160;&#24577;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Exploring Linguistic Style Matching in Online Communities: The Role of Social Context and Conversation Dynamics. (arXiv:2307.02758v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;Reddit&#19978;&#20998;&#26512;&#20102;&#20004;&#26041;&#23545;&#35805;&#20027;&#39064;&#30340;&#22823;&#37327;&#35821;&#26009;&#24211;&#65292;&#30740;&#31350;&#20102;LSM&#22312;&#23545;&#35805;&#20013;&#30340;&#24046;&#24322;&#20197;&#21450;&#19982;&#31038;&#21306;&#25351;&#26631;&#30340;&#20851;&#31995;&#65292;&#25581;&#31034;&#20102;&#29702;&#35299;&#31038;&#21306;&#21160;&#24577;&#26102;&#23545;&#35805;&#21442;&#19982;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#35805;&#20013;&#30340;&#35821;&#35328;&#39118;&#26684;&#21305;&#37197;&#21487;&#20197;&#21453;&#26144;&#20986;&#31038;&#20250;&#24433;&#21709;&#30340;&#22810;&#20010;&#26041;&#38754;&#65292;&#22914;&#26435;&#21147;&#25110;&#35828;&#26381;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#31867;&#20284;Reddit&#31561;&#24179;&#21488;&#19978;&#65292;LSM&#19982;&#22312;&#32447;&#27807;&#36890;&#32467;&#26524;&#30340;&#20851;&#31995;&#23578;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;Reddit&#20013;&#20004;&#26041;&#23545;&#35805;&#20027;&#39064;&#30340;&#22823;&#37327;&#35821;&#26009;&#24211;&#65292;&#24182;&#20351;&#29992;&#20004;&#31181;&#31867;&#22411;&#30340;&#39118;&#26684;&#65306;&#21151;&#33021;&#35789;&#30340;&#20351;&#29992;&#21644;&#24418;&#24335;&#21270;&#12290;&#20351;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#31038;&#20132;&#22240;&#32032;&#22312;Reddit&#23545;&#35805;&#20013;LSM&#27700;&#24179;&#30340;&#24046;&#24322;&#65306;&#24086;&#23376;&#21644;&#23376;&#31038;&#21306;&#29305;&#24449;&#12289;&#23545;&#35805;&#28145;&#24230;&#12289;&#29992;&#25143;&#36164;&#21382;&#21644;&#35780;&#35770;&#30340;&#20105;&#35758;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27979;&#37327;&#20102;&#31038;&#21306;&#31105;&#20196;&#21518;&#22833;&#21435;&#22320;&#20301;&#21518;LSM&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20102;LSM&#22312;Reddit&#23545;&#35805;&#20013;&#19982;&#20960;&#20010;&#31038;&#21306;&#25351;&#26631;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#26263;&#31034;&#20102;&#22312;&#20102;&#35299;&#31038;&#21306;&#21160;&#24577;&#26102;&#29702;&#35299;&#23545;&#35805;&#21442;&#19982;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linguistic style matching (LSM) in conversations can be reflective of several aspects of social influence such as power or persuasion. However, how LSM relates to the outcomes of online communication on platforms such as Reddit is an unknown question. In this study, we analyze a large corpus of two-party conversation threads in Reddit where we identify all occurrences of LSM using two types of style: the use of function words and formality. Using this framework, we examine how levels of LSM differ in conversations depending on several social factors within Reddit: post and subreddit features, conversation depth, user tenure, and the controversiality of a comment. Finally, we measure the change of LSM following loss of status after community banning. Our findings reveal the interplay of LSM in Reddit conversations with several community metrics, suggesting the importance of understanding conversation engagement when understanding community dynamics.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#65292;&#22312;&#22823;&#22411;&#35821;&#26009;&#24211;&#19978;&#24494;&#35843;BERT&#27169;&#22411;&#20197;&#39044;&#27979;&#32473;&#23450;&#25991;&#26412;&#30340;&#34920;&#24773;&#31526;&#21495;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#20934;&#30830;&#29575;&#19978;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#31038;&#20132;&#23186;&#20307;&#33829;&#38144;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.02054</link><description>&lt;p&gt;
&#20351;&#29992;Transformer&#27169;&#22411;&#39044;&#27979;&#34920;&#24773;&#31526;&#21495;
&lt;/p&gt;
&lt;p&gt;
Emoji Prediction using Transformer Models. (arXiv:2307.02054v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02054
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#65292;&#22312;&#22823;&#22411;&#35821;&#26009;&#24211;&#19978;&#24494;&#35843;BERT&#27169;&#22411;&#20197;&#39044;&#27979;&#32473;&#23450;&#25991;&#26412;&#30340;&#34920;&#24773;&#31526;&#21495;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#20934;&#30830;&#29575;&#19978;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#31038;&#20132;&#23186;&#20307;&#33829;&#38144;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31038;&#20132;&#23186;&#20307;&#20013;&#20351;&#29992;&#34920;&#24773;&#31526;&#21495;&#30340;&#39057;&#29575;&#22823;&#24133;&#22686;&#21152;&#65292;&#20351;&#24471;&#23427;&#20204;&#25104;&#20026;&#20102;&#29702;&#35299;&#22312;&#32447;&#27807;&#36890;&#30340;&#37325;&#35201;&#20803;&#32032;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#21547;&#31946;&#30340;&#29305;&#24615;&#65292;&#39044;&#27979;&#32473;&#23450;&#25991;&#26412;&#20013;&#34920;&#24773;&#31526;&#21495;&#30340;&#21547;&#20041;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#26469;&#20351;&#29992;BERT&#36827;&#34892;&#34920;&#24773;&#31526;&#21495;&#39044;&#27979;&#65292;BERT&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21253;&#21547;&#25991;&#26412;&#21644;&#34920;&#24773;&#31526;&#21495;&#30340;&#22823;&#22411;&#35821;&#26009;&#24211;&#19978;&#23545;BERT&#36827;&#34892;&#24494;&#35843;&#65292;&#20197;&#39044;&#27979;&#32473;&#23450;&#25991;&#26412;&#30340;&#26368;&#21512;&#36866;&#30340;&#34920;&#24773;&#31526;&#21495;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#39044;&#27979;&#34920;&#24773;&#31526;&#21495;&#26041;&#38754;&#30340;&#20934;&#30830;&#29575;&#36229;&#36807;&#20102;75&#65285;&#65292;&#20248;&#20110;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;&#35813;&#30740;&#31350;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#24773;&#24863;&#20998;&#26512;&#21644;&#31038;&#20132;&#23186;&#20307;&#33829;&#38144;&#26041;&#38754;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, the use of emojis in social media has increased dramatically, making them an important element in understanding online communication. However, predicting the meaning of emojis in a given text is a challenging task due to their ambiguous nature. In this study, we propose a transformer-based approach for emoji prediction using BERT, a widely-used pre-trained language model. We fine-tuned BERT on a large corpus of text containing both text and emojis to predict the most appropriate emoji for a given text. Our experimental results demonstrate that our approach outperforms several state-of-the-art models in predicting emojis with an accuracy of over 75 percent. This work has potential applications in natural language processing, sentiment analysis, and social media marketing.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23481;&#26131;&#34987;&#35823;&#23548;&#65292;&#20986;&#29616;&#22266;&#23450;&#25928;&#24212;&#21644;Einstellung&#33539;&#24335;&#12290;</title><link>http://arxiv.org/abs/2306.11167</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#35823;&#23548;&#65306;&#20351;&#29992;Only Connect Wall&#25968;&#25454;&#38598;&#25506;&#32034;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#21644;Einstellung&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11167
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23481;&#26131;&#34987;&#35823;&#23548;&#65292;&#20986;&#29616;&#22266;&#23450;&#25928;&#24212;&#21644;Einstellung&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#20154;&#24037;&#26234;&#33021;&#35806;&#29983;&#20197;&#26469;&#65292;&#23545;&#20154;&#31867;&#20223;&#30495;&#26234;&#33021;&#30340;&#36861;&#27714;&#19968;&#30452;&#26159;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#30340;&#25345;&#20037;&#35805;&#39064;&#12290;&#26368;&#26032;&#19968;&#20195;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#25216;&#26415;&#28436;&#36827;&#21644;&#26032;&#20852;&#33021;&#21147;&#23558;&#36825;&#20010;&#20027;&#39064;&#20174;&#23398;&#26415;&#30028;&#24102;&#21040;&#20102;&#25991;&#21270;&#26102;&#20195;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;NLP&#35780;&#20272;&#22522;&#20934;&#20219;&#21153;&#27979;&#35797;&#20102;&#20154;&#31867;&#20223;&#30495;&#34892;&#20026;&#30340;&#19968;&#20123;&#26041;&#38754;&#65288;&#20363;&#22914;BIG-bench&#30340;&#8220;&#31867;&#20154;&#34892;&#20026;&#8221;&#20219;&#21153;&#65289;&#65292;&#20294;&#20960;&#20046;&#27809;&#26377;&#19968;&#20010;&#20219;&#21153;&#32771;&#23519;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;&#20154;&#31867;&#30340;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#26159;&#35748;&#30693;&#31070;&#32463;&#31185;&#23398;&#20013;&#30740;&#31350;&#36739;&#20026;&#28145;&#20837;&#30340;&#20027;&#39064;&#65292;&#26631;&#20934;&#21270;&#27979;&#35797;&#20027;&#35201;&#20351;&#29992;&#23558;&#32447;&#32034;&#35789;&#20043;&#38388;&#30340;&#65288;&#24322;&#26500;&#65289;&#36830;&#25509;&#33021;&#21147;&#20316;&#20026;&#21019;&#36896;&#24615;&#30340;&#24230;&#37327;&#12290;&#22312;&#36825;&#26679;&#30340;&#20219;&#21153;&#20013;&#65292;&#26263;&#31034;&#24615;&#30340;&#35823;&#23548;&#24615;&#21050;&#28608;-&#34987;&#31216;&#20026;&#8220;&#35825;&#23548;&#35823;&#35299;&#8221;&#30340;&#24178;&#25200;&#22240;&#32032;-&#36890;&#36807;&#22266;&#23450;&#25928;&#24212;&#21644;Einstellung&#33539;&#24335;&#38459;&#30861;&#20102;&#20154;&#31867;&#30340;&#34920;&#29616;&#12290;&#22312;&#35748;&#30693;&#31070;&#32463;&#31185;&#23398;&#30340;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20107;&#20808;&#35753;&#21442;&#19982;&#32773;&#25509;&#35302;&#21040;&#26377;&#30456;&#20284;&#25340;&#20889;&#30340;&#38169;&#35823;&#22240;&#32032;&#26469;&#23454;&#39564;&#24615;&#22320;&#35825;&#23548;&#36825;&#26679;&#30340;&#22266;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quest for human imitative AI has been an enduring topic in AI research since its inception. The technical evolution and emerging capabilities of the latest cohort of large language models (LLMs) have reinvigorated the subject beyond academia to the cultural zeitgeist. While recent NLP evaluation benchmark tasks test some aspects of human-imitative behaviour (e.g., BIG-bench's 'human-like behavior' tasks), few, if not none, examine creative problem solving abilities. Creative problem solving in humans is a well-studied topic in cognitive neuroscience with standardized tests that predominantly use the ability to associate (heterogeneous) connections among clue words as a metric for creativity. Exposure to misleading stimuli - distractors dubbed red herrings - impede human performance in such tasks via the fixation effect and Einstellung paradigm. In cognitive neuroscience studies, such fixations are experimentally induced by pre-exposing participants to orthographically similar incor
&lt;/p&gt;</description></item><item><title>RestGPT&#36890;&#36807;&#36830;&#25509;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;RESTful API&#65292;&#25552;&#20986;&#20102;RestGPT&#20197;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#22797;&#26434;&#25351;&#20196;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;API&#25191;&#34892;&#22120;&#12290;</title><link>http://arxiv.org/abs/2306.06624</link><description>&lt;p&gt;
RestGPT&#65306;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#29616;&#23454;&#19990;&#30028;&#30340;RESTful API&#36830;&#25509;&#36215;&#26469;
&lt;/p&gt;
&lt;p&gt;
RestGPT: Connecting Large Language Models with Real-World RESTful APIs. (arXiv:2306.06624v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06624
&lt;/p&gt;
&lt;p&gt;
RestGPT&#36890;&#36807;&#36830;&#25509;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;RESTful API&#65292;&#25552;&#20986;&#20102;RestGPT&#20197;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#22797;&#26434;&#25351;&#20196;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;API&#25191;&#34892;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#20855;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#24191;&#27867;&#20219;&#21153;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#23616;&#38480;&#20110;&#29305;&#23450;&#35774;&#35745;&#30340;&#24037;&#20855;&#65292;&#26080;&#27861;&#28385;&#36275;&#22797;&#26434;&#25351;&#20196;&#65292;&#22312;&#38754;&#23545;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#26102;&#23384;&#22312;&#24456;&#22823;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#31526;&#21512;&#24191;&#27867;&#37319;&#29992;&#30340;REST&#36719;&#20214;&#26550;&#26500;&#39118;&#26684;&#30340;RESTful API&#36830;&#25509;&#36215;&#26469;&#65292;&#25506;&#32034;&#20102;&#26356;&#21152;&#30495;&#23454;&#30340;&#22330;&#26223;&#12290;&#20026;&#20102;&#35299;&#20915;&#22788;&#29702;&#22797;&#26434;&#25351;&#20196;&#30340;&#23454;&#38469;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RestGPT&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#24182;&#37319;&#29992;&#31895;&#21040;&#31934;&#30340;&#22312;&#32447;&#35268;&#21010;&#26426;&#21046;&#65292;&#20197;&#22686;&#24378;&#20219;&#21153;&#20998;&#35299;&#21644;API&#36873;&#25321;&#30340;&#33021;&#21147;&#12290;RestGPT&#36824;&#21253;&#25324;&#19968;&#20010;&#19987;&#38376;&#29992;&#20110;&#35843;&#29992;RESTful API&#30340;API&#25191;&#34892;&#22120;&#65292;&#21487;&#20197;&#31934;&#30830;&#22320;&#21046;&#23450;&#21442;&#25968;&#21644;&#35299;&#26512;API&#21709;&#24212;&#12290;&#20026;&#20102;&#20840;&#38754;&#35780;&#20272;RestGPT&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RestBench&#65292;&#36825;&#26159;&#19968;&#20010;&#30001;&#20004;&#20010;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#32452;&#25104;&#30340;&#39640;&#36136;&#37327;&#22522;&#20934;&#27979;&#35797;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tool-augmented large language models (LLMs) have achieved remarkable progress in tackling a broad range of tasks. However, existing methods are mainly restricted to specifically designed tools and fail to fulfill complex instructions, having great limitations when confronted with real-world scenarios. In this paper, we explore a more realistic scenario by connecting LLMs with RESTful APIs, which adhere to the widely adopted REST software architectural style for web service development. To address the practical challenges of tackling complex instructions, we propose RestGPT, which exploits the power of LLMs and conducts a coarse-to-fine online planning mechanism to enhance the abilities of task decomposition and API selection. RestGPT also contains an API executor tailored for calling RESTful APIs, which can meticulously formulate parameters and parse API responses. To fully evaluate the performance of RestGPT, we propose RestBench, a high-quality benchmark which consists of two real-wo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#30340;&#26500;&#24314;&#27969;&#31243;&#12289;&#20851;&#38190;&#25216;&#26415;&#21644;&#21033;&#29992;&#26041;&#27861;&#20197;&#21450;&#29616;&#26377;&#36164;&#28304;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.04802</link><description>&lt;p&gt;
&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;&#32508;&#36848;&#65306;&#36164;&#28304;&#12289;&#24212;&#29992;&#21644;&#21069;&#26223;
&lt;/p&gt;
&lt;p&gt;
A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#36848;&#20102;&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#30340;&#26500;&#24314;&#27969;&#31243;&#12289;&#20851;&#38190;&#25216;&#26415;&#21644;&#21033;&#29992;&#26041;&#27861;&#20197;&#21450;&#29616;&#26377;&#36164;&#28304;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#30103;&#30693;&#35782;&#22270;&#35889;(HKGs)&#24050;&#25104;&#20026;&#32452;&#32455;&#21307;&#23398;&#30693;&#35782;&#30340;&#26377;&#32467;&#26500;&#19988;&#21487;&#35299;&#37322;&#30340;&#26377;&#20026;&#24037;&#20855;&#65292;&#25552;&#20379;&#20102;&#21307;&#23398;&#27010;&#24565;&#21450;&#20854;&#20851;&#31995;&#30340;&#20840;&#38754;&#35270;&#22270;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#35206;&#30422;&#33539;&#22260;&#26377;&#38480;&#31561;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#65292;&#24378;&#35843;&#20102;&#22312;HKG&#39046;&#22495;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24517;&#35201;&#24615;&#12290;&#26412;&#32508;&#36848;&#26159;HKG&#30340;&#31532;&#19968;&#20221;&#32508;&#21512;&#27010;&#36848;&#12290;&#25105;&#20204;&#24635;&#32467;&#20102;HKG&#26500;&#24314;&#30340;&#27969;&#31243;&#21644;&#20851;&#38190;&#25216;&#26415;&#65288;&#21363;&#20174;&#22836;&#24320;&#22987;&#21644;&#36890;&#36807;&#38598;&#25104;&#65289;&#65292;&#20197;&#21450;&#24120;&#35265;&#30340;&#21033;&#29992;&#26041;&#27861;&#65288;&#21363;&#22522;&#20110;&#27169;&#22411;&#21644;&#38750;&#22522;&#20110;&#27169;&#22411;&#65289;&#12290;&#20026;&#20102;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#65292;&#25105;&#20204;&#26681;&#25454;&#23427;&#20204;&#25429;&#33719;&#30340;&#25968;&#25454;&#31867;&#22411;&#21644;&#24212;&#29992;&#39046;&#22495;&#65288;&#35813;&#36164;&#28304;&#23384;&#20648;&#20110;https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase&#65289;&#32452;&#32455;&#20102;&#29616;&#26377;&#30340;HKG&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#22312;&#24212;&#29992;&#37096;&#20998;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;HKG&#22312;&#21508;&#31181;&#21307;&#30103;&#39046;&#22495;&#30340;&#21464;&#38761;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39046;&#22495;&#19987;&#38376;&#21270;&#65292;&#21253;&#25324;&#21160;&#26426;&#12289;&#25361;&#25112;&#12289;&#26041;&#27861;&#35770;&#21644;&#35780;&#20272;&#25351;&#26631;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#39046;&#22495;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#30340;&#20998;&#31867;&#27861;&#65292;&#23545;&#29616;&#26377;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#23450;&#21046;&#25216;&#26415;&#36827;&#34892;&#20102;&#35814;&#32454;&#27604;&#36739;&#65292;&#24182;&#24191;&#27867;&#35752;&#35770;&#20102;&#36825;&#19968;&#39046;&#22495;&#20013;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2305.18703</link><description>&lt;p&gt;
&#36229;&#36234;&#19968;&#20010;&#27169;&#22411;&#36866;&#29992;&#20110;&#25152;&#26377;&#39046;&#22495;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39046;&#22495;&#19987;&#38376;&#21270;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. (arXiv:2305.18703v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39046;&#22495;&#19987;&#38376;&#21270;&#65292;&#21253;&#25324;&#21160;&#26426;&#12289;&#25361;&#25112;&#12289;&#26041;&#27861;&#35770;&#21644;&#35780;&#20272;&#25351;&#26631;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#39046;&#22495;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#30340;&#20998;&#31867;&#27861;&#65292;&#23545;&#29616;&#26377;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#23450;&#21046;&#25216;&#26415;&#36827;&#34892;&#20102;&#35814;&#32454;&#27604;&#36739;&#65292;&#24182;&#24191;&#27867;&#35752;&#35770;&#20102;&#36825;&#19968;&#39046;&#22495;&#20013;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#32463;&#22823;&#22823;&#25512;&#21160;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#20026;&#24191;&#27867;&#24212;&#29992;&#25552;&#20379;&#20102;&#39640;&#24230;&#23454;&#29992;&#12289;&#20219;&#21153;&#26080;&#20851;&#30340;&#22522;&#30784;&#12290;LLMs &#20316;&#20026;&#36890;&#29992;&#20219;&#21153;&#27714;&#35299;&#22120;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#20419;&#20351;&#20154;&#20204;&#23558;&#20854;&#29992;&#20110;&#29305;&#23450;&#39046;&#22495;&#65292;&#22914;&#21307;&#30103;&#20445;&#20581;&#12289;&#37329;&#34701;&#21644;&#25945;&#32946;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#21161;&#25163;&#29978;&#33267;&#26367;&#20195;&#29305;&#23450;&#39046;&#22495;&#30340;&#19987;&#23478;&#21644;&#24037;&#20855;&#12290;&#20294;&#26159;&#65292;&#23558;LLMs&#30452;&#25509;&#24212;&#29992;&#20110;&#29305;&#23450;&#39046;&#22495;&#20013;&#30340;&#22797;&#26434;&#38382;&#39064;&#20250;&#36935;&#21040;&#35768;&#22810;&#22256;&#38590;&#65292;&#21253;&#25324;&#39046;&#22495;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#12289;&#39046;&#22495;&#30693;&#35782;&#30340;&#22797;&#26434;&#24615;&#12289;&#39046;&#22495;&#30446;&#26631;&#30340;&#29420;&#29305;&#24615;&#20197;&#21450;&#32422;&#26463;&#30340;&#22810;&#26679;&#24615;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#31181;&#24046;&#36317;&#65292;&#26368;&#36817;&#20960;&#24180;&#36827;&#34892;&#20102;&#24613;&#21095;&#22686;&#21152;&#30340;&#30740;&#31350;&#21644;&#23454;&#36341;&#33268;&#21147;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39046;&#22495;&#19987;&#38376;&#21270;&#65292;&#28982;&#32780;&#36825;&#26041;&#38754;&#30340;&#30740;&#31350;&#23578;&#26410;&#34987;&#31995;&#32479;&#22320;&#24635;&#32467;&#12290;&#22312;&#36825;&#31687;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#23545;LLMs&#30340;&#39046;&#22495;&#19987;&#38376;&#21270;&#36827;&#34892;&#20102;&#20840;&#38754;&#27010;&#36848;&#65292;&#21253;&#25324;&#21160;&#26426;&#12289;&#25361;&#25112;&#12289;&#26041;&#27861;&#35770;&#21644;&#35780;&#20272;&#25351;&#26631;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#39046;&#22495;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#30340;&#20998;&#31867;&#27861;&#65292;&#23545;&#29616;&#26377;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#23450;&#21046;&#25216;&#26415;&#36827;&#34892;&#20102;&#35814;&#32454;&#27604;&#36739;&#65292;&#24182;&#24191;&#27867;&#35752;&#35770;&#20102;&#36825;&#19968;&#39046;&#22495;&#20013;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. The great promise of LLMs as general task solvers motivated people to extend their functionality largely beyond just a ``chatbot'', and use it as an assistant or even replacement for domain experts and tools in specific domains such as healthcare, finance, and education. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). To fill such a gap, explosively-increase research, and practices have been conducted in very recent years on the domain specialization of LLMs, which, howe
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#25512;&#29305;&#25968;&#25454;&#30740;&#31350;&#20102;&#26085;&#26412;&#21069;&#39318;&#30456;&#38463;&#36125;&#30340;&#26263;&#26432;&#20107;&#20214;&#23545;2022&#24180;&#26085;&#26412;&#21442;&#35758;&#38498;&#36873;&#20030;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#26263;&#26432;&#20107;&#20214;&#30701;&#26399;&#20869;&#23545;&#25512;&#29305;&#24773;&#32490;&#20135;&#29983;&#20102;&#36127;&#38754;&#24433;&#21709;&#65292;&#24182;&#19988;&#31038;&#20132;&#23186;&#20307;&#30340;&#20851;&#27880;&#26102;&#38388;&#20063;&#21464;&#24471;&#26356;&#30701;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#38463;&#36125;&#20043;&#27515;&#23545;&#36873;&#20030;&#32467;&#26524;&#20135;&#29983;&#20102;&#24433;&#21709;&#65292;&#20294;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;&#20197;&#24471;&#20986;&#30830;&#20999;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2305.18004</link><description>&lt;p&gt;
&#25919;&#27835;&#27529;&#36947;&#23545;&#36873;&#20030;&#32467;&#26524;&#30340;&#24433;&#21709;&#65306;&#38463;&#36125;&#36935;&#21050;&#20107;&#20214;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Effects of Political Martyrdom on Election Results: The Assassination of Abe. (arXiv:2305.18004v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18004
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#25512;&#29305;&#25968;&#25454;&#30740;&#31350;&#20102;&#26085;&#26412;&#21069;&#39318;&#30456;&#38463;&#36125;&#30340;&#26263;&#26432;&#20107;&#20214;&#23545;2022&#24180;&#26085;&#26412;&#21442;&#35758;&#38498;&#36873;&#20030;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#26263;&#26432;&#20107;&#20214;&#30701;&#26399;&#20869;&#23545;&#25512;&#29305;&#24773;&#32490;&#20135;&#29983;&#20102;&#36127;&#38754;&#24433;&#21709;&#65292;&#24182;&#19988;&#31038;&#20132;&#23186;&#20307;&#30340;&#20851;&#27880;&#26102;&#38388;&#20063;&#21464;&#24471;&#26356;&#30701;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#38463;&#36125;&#20043;&#27515;&#23545;&#36873;&#20030;&#32467;&#26524;&#20135;&#29983;&#20102;&#24433;&#21709;&#65292;&#20294;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;&#20197;&#24471;&#20986;&#30830;&#20999;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21457;&#36798;&#22269;&#23478;&#65292;&#26263;&#26432;&#34892;&#20026;&#24456;&#23569;&#65292;&#22240;&#27492;&#23545;&#27492;&#31867;&#34892;&#20026;&#23545;&#36873;&#20030;&#21644;&#25919;&#27835;&#26684;&#23616;&#30340;&#24433;&#21709;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#25512;&#29305;&#25968;&#25454;&#65292;&#30740;&#31350;&#26085;&#26412;&#21069;&#39318;&#30456;&#38463;&#36125;&#30340;&#26263;&#26432;&#20107;&#20214;&#23545;2022&#24180;&#26085;&#26412;&#21442;&#35758;&#38498;&#36873;&#20030;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#23545;200&#19975;&#26465;&#25512;&#25991;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#12289;&#24773;&#32490;&#26816;&#27979;&#21644;&#20027;&#39064;&#24314;&#27169;&#65292;&#24182;&#19982;&#21069;&#20960;&#27425;&#36873;&#20030;&#21608;&#26399;&#30340;&#25512;&#25991;&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#26263;&#26432;&#20107;&#20214;&#30701;&#26399;&#20869;&#23545;&#25512;&#29305;&#24773;&#32490;&#20135;&#29983;&#20102;&#36127;&#38754;&#24433;&#21709;&#65292;&#21516;&#26102;&#31038;&#20132;&#23186;&#20307;&#30340;&#20851;&#27880;&#26102;&#38388;&#20063;&#21464;&#24471;&#26356;&#30701;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#8220;&#27515;&#20129;&#25919;&#27835;&#8221;&#22914;&#20309;&#24433;&#21709;&#36873;&#20030;&#32467;&#26524;&#65292;&#34920;&#26126;&#38463;&#36125;&#20043;&#27515;&#20284;&#20046;&#23545;&#36873;&#20030;&#32467;&#26524;&#20135;&#29983;&#20102;&#24433;&#21709;&#65292;&#20294;&#30740;&#31350;&#32467;&#26524;&#36824;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;&#20197;&#24471;&#20986;&#30830;&#20999;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In developed nations assassinations are rare and thus the impact of such acts on the electoral and political landscape is understudied. In this paper, we focus on Twitter data to examine the effects of Japan's former Primer Minister Abe's assassination on the Japanese House of Councillors elections in 2022. We utilize sentiment analysis and emotion detection together with topic modeling on over 2 million tweets and compare them against tweets during previous election cycles. Our findings indicate that Twitter sentiments were negatively impacted by the event in the short term and that social media attention span has shortened. We also discuss how "necropolitics" affected the outcome of the elections in favor of the deceased's party meaning that there seems to have been an effect of Abe's death on the election outcome though the findings warrant further investigation for conclusive results.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#35780;&#20272;&#24320;&#25918;&#24335;&#38382;&#31572;&#65288;Open-QA&#65289;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20219;&#21153;QA-Eval&#21644;&#25968;&#25454;&#38598;EVOUNA&#65292;&#36890;&#36807;&#20154;&#24037;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;AI&#29983;&#25104;&#30340;&#31572;&#26696;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#19982;&#20154;&#24037;&#35780;&#20272;&#30456;&#20851;&#30340;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#32570;&#38519;&#21644;&#25913;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#30456;&#20449;&#36825;&#23545;&#20110;&#26410;&#26469;&#30340;&#33258;&#21160;&#35780;&#20272;&#24037;&#20855;&#21457;&#23637;&#21644;&#30740;&#31350;&#20855;&#26377;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.12421</link><description>&lt;p&gt;
&#35780;&#20272;&#24320;&#25918;&#24335;&#38382;&#31572;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Evaluating Open-QA Evaluation. (arXiv:2305.12421v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#35780;&#20272;&#24320;&#25918;&#24335;&#38382;&#31572;&#65288;Open-QA&#65289;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20219;&#21153;QA-Eval&#21644;&#25968;&#25454;&#38598;EVOUNA&#65292;&#36890;&#36807;&#20154;&#24037;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;AI&#29983;&#25104;&#30340;&#31572;&#26696;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;&#19982;&#20154;&#24037;&#35780;&#20272;&#30456;&#20851;&#30340;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#32570;&#38519;&#21644;&#25913;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#30456;&#20449;&#36825;&#23545;&#20110;&#26410;&#26469;&#30340;&#33258;&#21160;&#35780;&#20272;&#24037;&#20855;&#21457;&#23637;&#21644;&#30740;&#31350;&#20855;&#26377;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#23545;&#24320;&#25918;&#24335;&#38382;&#31572;&#65288;Open-QA&#65289;&#20219;&#21153;&#30340;&#35780;&#20272;&#65292;&#35813;&#20219;&#21153;&#21487;&#20197;&#30452;&#25509;&#20272;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20107;&#23454;&#24615;&#12290;&#30446;&#21069;&#30340;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#24050;&#26174;&#31034;&#20986;&#19968;&#23450;&#30340;&#23616;&#38480;&#24615;&#65292;&#34920;&#26126;&#20154;&#24037;&#35780;&#20272;&#20173;&#28982;&#26159;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#35780;&#20272;QA&#35780;&#20272;&#65288;QA-Eval&#65289;&#20197;&#21450;&#30456;&#24212;&#30340;&#25968;&#25454;&#38598;EVOUNA&#65292;&#26088;&#22312;&#35780;&#20272;AI&#29983;&#25104;&#30340;&#31572;&#26696;&#19982;Open-QA&#20013;&#30340;&#26631;&#20934;&#31572;&#26696;&#20043;&#38388;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#20154;&#24037;&#26631;&#27880;&#30340;&#32467;&#26524;&#26469;&#35780;&#20272;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#37027;&#20123;&#19982;&#20154;&#24037;&#35780;&#20272;&#20855;&#26377;&#39640;&#24230;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#65292;&#35748;&#20026;&#23427;&#20204;&#26356;&#21487;&#38752;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#24403;&#21069;&#26041;&#27861;&#30340;&#32570;&#38519;&#20197;&#21450;&#25913;&#36827;&#22522;&#20110;LLM&#30340;&#35780;&#20272;&#22120;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30456;&#20449;&#65292;&#36825;&#20010;&#26032;&#30340;QA-Eval&#20219;&#21153;&#21644;&#30456;&#24212;&#30340;&#25968;&#25454;&#38598;EVOUNA&#23558;&#20419;&#36827;&#26356;&#26377;&#25928;&#30340;&#33258;&#21160;&#35780;&#20272;&#24037;&#20855;&#30340;&#24320;&#21457;&#65292;&#24182;&#23545;&#26410;&#26469;&#30340;&#30740;&#31350;&#20855;&#26377;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study focuses on the evaluation of the Open Question Answering (Open-QA) task, which can directly estimate the factuality of large language models (LLMs). Current automatic evaluation methods have shown limitations, indicating that human evaluation still remains the most reliable approach. We introduce a new task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset EVOUNA, designed to assess the accuracy of AI-generated answers in relation to standard answers within Open-QA. Our evaluation of these methods utilizes human-annotated results to measure their performance. Specifically, the work investigates methods that show high correlation with human evaluations, deeming them more reliable. We also discuss the pitfalls of current methods and methods to improve LLM-based evaluators. We believe this new QA-Eval task and corresponding dataset EVOUNA will facilitate the development of more effective automatic evaluation tools and prove valuable for future research in this a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;X-adapter&#25554;&#25300;&#24335;&#27169;&#22359;&#65292;&#21033;&#29992;&#22810;&#27169;&#24577;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65292;&#39640;&#25928;&#22320;&#21521;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#27880;&#20837;&#35270;&#35273;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2305.07358</link><description>&lt;p&gt;
&#21033;&#29992;&#36328;&#27169;&#24577;&#36866;&#37197;&#22120;&#21521;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#27880;&#20837;&#22810;&#21151;&#33021;&#39640;&#25928;&#30340;&#35270;&#35273;&#30693;&#35782;
&lt;/p&gt;
&lt;p&gt;
Towards Versatile and Efficient Visual Knowledge Injection into Pre-trained Language Models with Cross-Modal Adapters. (arXiv:2305.07358v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07358
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;X-adapter&#25554;&#25300;&#24335;&#27169;&#22359;&#65292;&#21033;&#29992;&#22810;&#27169;&#24577;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65292;&#39640;&#25928;&#22320;&#21521;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#27880;&#20837;&#35270;&#35273;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#36890;&#36807;&#22810;&#27169;&#24577;&#30693;&#35782;&#23398;&#20064;&#35821;&#35328;&#65292;&#28982;&#32780;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#20165;&#25903;&#25345;&#25991;&#26412;&#39044;&#35757;&#32451;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#25554;&#25300;&#24335;&#27169;&#22359;X-adapter&#65292;&#23427;&#33021;&#22815;&#26681;&#25454;&#22810;&#27169;&#24577;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#30340;&#23545;&#40784;&#35270;&#35273;&#21644;&#25991;&#26412;&#30693;&#35782;&#65292;&#28789;&#27963;&#39640;&#25928;&#22320;&#21521;PLMs&#27880;&#20837;&#35270;&#35273;&#30693;&#35782;&#12290; X-adapter&#21253;&#21547;&#20004;&#20010;&#23376;&#27169;&#22359;V-expert&#21644;T-expert&#65292;&#21487;&#20197;&#26681;&#25454;&#19979;&#28216;&#20219;&#21153;&#28608;&#27963;&#19981;&#21516;&#30340;&#23376;&#27169;&#22359;&#65292;&#26469;&#34701;&#21512;VLMs&#30340;&#22270;&#20687;&#21644;&#25991;&#26412;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Humans learn language via multi-modal knowledge. However, due to the text-only pre-training scheme, most existing pre-trained language models (PLMs) are hindered from the multi-modal information.  To inject visual knowledge into PLMs, existing methods incorporate either the text or image encoder of vision-language models (VLMs) to encode the visual information and update all the original parameters of PLMs for knowledge fusion.  In this paper, we propose a new plug-and-play module, X-adapter, to flexibly leverage the aligned visual and textual knowledge learned in pre-trained VLMs and efficiently inject them into PLMs.  Specifically, we insert X-adapters into PLMs, and only the added parameters are updated during adaptation.  To fully exploit the potential in VLMs, X-adapters consist of two sub-modules, V-expert and T-expert, to fuse VLMs' image and text representations, respectively.  We can opt for activating different sub-modules depending on the downstream tasks.  Experimental resu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35270;&#35273;&#21464;&#21387;&#22120;&#30340;&#23545;&#27604;&#22270;&#20687;-&#25991;&#26412;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#38024;&#23545;&#24320;&#25918;&#35789;&#27719;&#30340;&#29289;&#20307;&#26816;&#27979;&#20219;&#21153;&#65292;&#37319;&#29992;&#21306;&#22495;&#24863;&#30693;&#39044;&#35757;&#32451;&#12289;&#32858;&#28966;&#25439;&#22833;&#21644;&#26032;&#39062;&#29289;&#20307;&#25552;&#26696;&#31561;&#25216;&#26415;&#65292;&#22312;LVIS&#19978;&#21462;&#24471;&#20102;32.1$AP_r$&#30340;&#26368;&#20339;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.07011</link><description>&lt;p&gt;
&#21306;&#22495;&#24863;&#30693;&#39044;&#35757;&#32451;&#65306;&#35270;&#35273;&#21464;&#21387;&#22120;&#19979;&#30340;&#24320;&#25918;&#35789;&#27719;&#29289;&#20307;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07011
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35270;&#35273;&#21464;&#21387;&#22120;&#30340;&#23545;&#27604;&#22270;&#20687;-&#25991;&#26412;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#38024;&#23545;&#24320;&#25918;&#35789;&#27719;&#30340;&#29289;&#20307;&#26816;&#27979;&#20219;&#21153;&#65292;&#37319;&#29992;&#21306;&#22495;&#24863;&#30693;&#39044;&#35757;&#32451;&#12289;&#32858;&#28966;&#25439;&#22833;&#21644;&#26032;&#39062;&#29289;&#20307;&#25552;&#26696;&#31561;&#25216;&#26415;&#65292;&#22312;LVIS&#19978;&#21462;&#24471;&#20102;32.1$AP_r$&#30340;&#26368;&#20339;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21306;&#22495;&#24863;&#30693;&#24320;&#25918;&#35789;&#27719;&#35270;&#35273;&#21464;&#21387;&#22120;&#65288;RO-ViT&#65289;&#65292;&#19968;&#31181;&#23545;&#27604;&#22270;&#20687;-&#25991;&#26412;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#26088;&#22312;&#22635;&#34917;&#22270;&#20687;&#32423;&#39044;&#35757;&#32451;&#21644;&#24320;&#25918;&#35789;&#27719;&#29289;&#20307;&#26816;&#27979;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#24314;&#35758;&#38543;&#26426;&#35009;&#21098;&#24182;&#35843;&#25972;&#20301;&#32622;&#23884;&#20837;&#30340;&#21306;&#22495;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#25972;&#20010;&#22270;&#20687;&#20301;&#32622;&#23884;&#20837;&#12290;&#36825;&#26356;&#22909;&#22320;&#21305;&#37197;&#20102;&#26816;&#27979;&#24494;&#35843;&#38454;&#27573;&#20013;&#21306;&#22495;&#32423;&#21035;&#19978;&#20351;&#29992;&#20301;&#32622;&#23884;&#20837;&#30340;&#26041;&#24335;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#29992;&#32858;&#28966;&#25439;&#22833;&#26367;&#25442;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;softmax&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#20197;&#26356;&#22909;&#22320;&#23398;&#20064;&#37027;&#20123;&#26377;&#20449;&#24687;&#37327;&#20294;&#38590;&#20197;&#25429;&#25417;&#30340;&#20363;&#23376;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#26368;&#36817;&#22312;&#26032;&#39062;&#29289;&#20307;&#25552;&#26696;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#20197;&#25913;&#36827;&#24320;&#25918;&#35789;&#27719;&#26816;&#27979;&#30340;&#24494;&#35843;&#12290;&#25105;&#20204;&#22312;LVIS&#21644;COCO&#24320;&#25918;&#35789;&#27719;&#26816;&#27979;&#22522;&#20934;&#19978;&#35780;&#20272;&#20102;&#23436;&#25972;&#27169;&#22411;&#21644;&#38646;-shot&#36716;&#31227;&#24615;&#33021;&#12290;RO-ViT&#22312;LVIS&#19978;&#23454;&#29616;&#20102;32.1$AP_r$&#30340;&#26368;&#20339;&#25928;&#26524;&#65292;&#36229;&#36807;&#29616;&#26377;&#26368;&#20339;&#26041;&#27861;5.8&#20010;&#30334;&#20998;&#28857;&#65292;&#21516;&#26102;&#36824;&#20855;&#26377;&#31454;&#20105;&#24615;&#30340;&#38646;-shot&#36716;&#31227;&#26816;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of positional embeddings at region-level in the detection finetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to better learn the informative yet difficult examples. Finally, we leverage recent advances in novel object proposals to improve open-vocabulary detection finetuning. We evaluate our full model on the LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 32.1 $AP_r$ on LVIS, surpassing the best existing approach by +5.8 points in addition to competitive zero-shot transfer detec
&lt;/p&gt;</description></item><item><title>&#23545;&#35805;&#31995;&#32479;&#30340;&#20010;&#24615;&#21270;&#38656;&#35201;&#20010;&#20154;&#36164;&#26009;&#20449;&#24687;&#65292;&#32780;&#20174;&#23545;&#35805;&#20013;&#25552;&#21462;/&#29983;&#25104;&#20010;&#20154;&#36164;&#26009;&#20449;&#24687;&#26159;&#19968;&#39033;&#22522;&#26412;&#38656;&#27714;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26723;&#26696;&#29983;&#25104;&#20219;&#21153;&#65288;PGTask&#65289;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#35813;&#20219;&#21153;&#20351;&#24471;&#30740;&#31350;&#32773;&#21487;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#26723;&#26696;&#29983;&#25104;&#20219;&#21153;&#30340;&#25361;&#25112;&#21644;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.06634</link><description>&lt;p&gt;
PGTask&#65306;&#20171;&#32461;&#20174;&#23545;&#35805;&#20013;&#29983;&#25104;&#26723;&#26696;&#30340;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
PGTask: Introducing the Task of Profile Generation from Dialogues. (arXiv:2304.06634v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06634
&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#31995;&#32479;&#30340;&#20010;&#24615;&#21270;&#38656;&#35201;&#20010;&#20154;&#36164;&#26009;&#20449;&#24687;&#65292;&#32780;&#20174;&#23545;&#35805;&#20013;&#25552;&#21462;/&#29983;&#25104;&#20010;&#20154;&#36164;&#26009;&#20449;&#24687;&#26159;&#19968;&#39033;&#22522;&#26412;&#38656;&#27714;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26723;&#26696;&#29983;&#25104;&#20219;&#21153;&#65288;PGTask&#65289;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;&#65292;&#35813;&#20219;&#21153;&#20351;&#24471;&#30740;&#31350;&#32773;&#21487;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#26723;&#26696;&#29983;&#25104;&#20219;&#21153;&#30340;&#25361;&#25112;&#21644;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#23581;&#35797;&#36890;&#36807;&#23558;&#20010;&#20154;&#36164;&#26009;&#20449;&#24687;&#34701;&#20837;&#27169;&#22411;&#26469;&#20010;&#24615;&#21270;&#23545;&#35805;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#30693;&#35782;&#20449;&#24687;&#31232;&#23569;&#19988;&#38590;&#20197;&#33719;&#21462;&#65292;&#36825;&#20351;&#24471;&#20174;&#23545;&#35805;&#20013;&#25552;&#21462;/&#29983;&#25104;&#20010;&#20154;&#36164;&#26009;&#20449;&#24687;&#25104;&#20026;&#19968;&#39033;&#22522;&#26412;&#38656;&#27714;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26723;&#26696;&#29983;&#25104;&#20219;&#21153;&#65288;PGTask&#65289;&#12290;&#25105;&#20204;&#20026;&#27492;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#19982;&#30456;&#20851;&#35805;&#35821;&#23545;&#40784;&#30340;&#26723;&#26696;&#21477;&#23376;&#65292;&#20174;&#23545;&#35805;&#35821;&#26009;&#24211;&#20013;&#25552;&#21462;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20026;&#36825;&#20010;&#26032;&#25968;&#25454;&#38598;&#25552;&#20379;&#20102;&#19968;&#20010;&#26723;&#26696;&#29983;&#25104;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#26723;&#26696;&#29983;&#25104;&#30340;&#25361;&#25112;&#65292;&#24182;&#24076;&#26395;&#36825;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#20154;&#31867;&#21512;&#20316;&#26159;&#21542;&#22686;&#24378;&#20102;&#35782;&#21035;LLM&#29983;&#25104;&#30340;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#20934;&#30830;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21512;&#20316;&#21487;&#20197;&#28508;&#22312;&#22320;&#25552;&#39640;&#20004;&#32452;&#20154;&#23545;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.01002</link><description>&lt;p&gt;
&#20154;&#31867;&#21512;&#20316;&#26159;&#21542;&#22686;&#24378;&#20102;&#35782;&#21035;LLM&#29983;&#25104;&#30340;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#20934;&#30830;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?. (arXiv:2304.01002v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01002
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#20154;&#31867;&#21512;&#20316;&#26159;&#21542;&#22686;&#24378;&#20102;&#35782;&#21035;LLM&#29983;&#25104;&#30340;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#20934;&#30830;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21512;&#20316;&#21487;&#20197;&#28508;&#22312;&#22320;&#25552;&#39640;&#20004;&#32452;&#20154;&#23545;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT-4&#12289;LLaMA&#65289;&#30340;&#36827;&#23637;&#25913;&#21892;&#20102;&#22823;&#35268;&#27169;&#29983;&#25104;&#31867;&#20284;&#20154;&#31867;&#20889;&#20316;&#30340;&#36830;&#36143;&#21477;&#23376;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#25152;&#35859;&#30340;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#36827;&#23637;&#24341;&#21457;&#20102;&#23433;&#20840;&#21644;&#38544;&#31169;&#30340;&#25285;&#24551;&#65292;&#38656;&#35201;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#26469;&#21306;&#20998;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#21644;&#20154;&#31867;&#20070;&#20889;&#25991;&#26412;&#12290;&#23613;&#31649;&#20197;&#21069;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#20154;&#31867;&#26816;&#27979;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#20294;&#27809;&#26377;&#30740;&#31350;&#8220;&#21512;&#20316;&#8221;&#26159;&#21542;&#33021;&#25552;&#39640;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#26816;&#27979;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#20026;&#20102;&#22635;&#34917;&#23545;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#29702;&#35299;&#30340;&#31354;&#30333;&#65292;&#25105;&#20204;&#23545;&#20004;&#32452;&#20154;&#36827;&#34892;&#20102;&#23454;&#39564;&#65306;&#65288;1&#65289;&#26469;&#33258;AMT&#24179;&#21488;&#30340;&#38750;&#19987;&#23478;&#32676;&#20307;&#21644;&#65288;2&#65289;&#26469;&#33258;Upwork&#24179;&#21488;&#30340;&#20889;&#20316;&#19987;&#23478;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20154;&#31867;&#20043;&#38388;&#30340;&#21512;&#20316;&#21487;&#33021;&#20250;&#25552;&#39640;&#20004;&#32452;&#23545;&#28145;&#24230;&#20266;&#36896;&#25991;&#26412;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#65292;&#38750;&#19987;&#23478;&#32452;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#25552;&#39640;&#20102;6.36%&#65292;&#19987;&#23478;&#32452;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#25552;&#39640;&#20102;12.76%&#12290;
&lt;/p&gt;
&lt;p&gt;
Advances in Large Language Models (e.g., GPT-4, LLaMA) have improved the generation of coherent sentences resembling human writing on a large scale, resulting in the creation of so-called deepfake texts. However, this progress poses security and privacy concerns, necessitating effective solutions for distinguishing deepfake texts from human-written ones. Although prior works studied humans' ability to detect deepfake texts, none has examined whether "collaboration" among humans improves the detection of deepfake texts. In this study, to address this gap of understanding on deepfake texts, we conducted experiments with two groups: (1) nonexpert individuals from the AMT platform and (2) writing experts from the Upwork platform. The results demonstrate that collaboration among humans can potentially improve the detection of deepfake texts for both groups, increasing detection accuracies by 6.36% for non-experts and 12.76% for experts, respectively, compared to individuals' detection accur
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#22312;&#25277;&#35937;&#27010;&#25324;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#33258;&#21160;&#21270;&#25351;&#26631;&#21644;&#30450;&#23457;&#20154;&#21592;&#35780;&#20272;&#26174;&#31034;ChatGPT&#29983;&#25104;&#30340;&#25688;&#35201;&#22312;&#20154;&#31867;&#35270;&#35282;&#19979;&#38590;&#20197;&#20998;&#36776;&#30495;&#20551;&#12290;</title><link>http://arxiv.org/abs/2303.17650</link><description>&lt;p&gt;
&#36890;&#36807;&#30450;&#23457;&#35780;&#20272;&#21644;&#25991;&#26412;&#20998;&#31867;&#31639;&#27861;&#27604;&#36739;ChatGPT&#29983;&#25104;&#30340;&#25277;&#35937;&#25688;&#35201;&#21644;&#30495;&#23454;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
Comparing Abstractive Summaries Generated by ChatGPT to Real Summaries Through Blinded Reviewers and Text Classification Algorithms. (arXiv:2303.17650v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;ChatGPT&#22312;&#25277;&#35937;&#27010;&#25324;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#33258;&#21160;&#21270;&#25351;&#26631;&#21644;&#30450;&#23457;&#20154;&#21592;&#35780;&#20272;&#26174;&#31034;ChatGPT&#29983;&#25104;&#30340;&#25688;&#35201;&#22312;&#20154;&#31867;&#35270;&#35282;&#19979;&#38590;&#20197;&#20998;&#36776;&#30495;&#20551;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22240;&#20854;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#20986;&#33394;&#34920;&#29616;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;OpenAI&#24320;&#21457;&#30340;ChatGPT&#26159;&#35821;&#35328;&#27169;&#22411;&#23478;&#26063;&#30340;&#26368;&#26032;&#25104;&#21592;&#65292;&#30001;&#20110;&#20854;&#31867;&#20154;&#30340;&#25991;&#26412;&#29983;&#25104;&#33021;&#21147;&#65292;&#34987;&#19968;&#20123;&#20154;&#31216;&#20026;&#19968;&#39033;&#39072;&#35206;&#24615;&#25216;&#26415;&#12290;&#23613;&#31649;&#32593;&#32476;&#19978;&#26377;&#35768;&#22810;ChatGPT&#30340;&#20363;&#23376;&#26469;&#35780;&#20272;&#20854;&#24378;&#24369;&#20043;&#22788;&#65292;&#20294;&#21482;&#26377;&#23569;&#25968;&#31995;&#32479;&#24615;&#30340;&#30740;&#31350;&#23384;&#22312;&#12290;&#20026;&#20102;&#20026;ChatGPT&#30340;&#31995;&#32479;&#24615;&#30740;&#31350;&#20570;&#20986;&#36129;&#29486;&#65292;&#25105;&#20204;&#36890;&#36807;&#33258;&#21160;&#21270;&#25351;&#26631;&#21644;&#30450;&#23457;&#20154;&#21592;&#35780;&#20272;&#20102;ChatGPT&#22312;&#25277;&#35937;&#27010;&#25324;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#36824;&#26500;&#24314;&#20102;&#33258;&#21160;&#25991;&#26412;&#20998;&#31867;&#22120;&#26469;&#26816;&#27979;ChatGPT&#29983;&#25104;&#30340;&#25688;&#35201;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#25991;&#26412;&#20998;&#31867;&#31639;&#27861;&#21487;&#20197;&#21306;&#20998;&#30495;&#23454;&#21644;&#29983;&#25104;&#30340;&#25688;&#35201;&#65292;&#20294;&#20154;&#31867;&#26080;&#27861;&#21306;&#20998;&#30495;&#23454;&#25688;&#35201;&#21644;ChatGPT&#29983;&#25104;&#30340;&#25688;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have gathered significant attention due to their impressive performance on a variety of tasks. ChatGPT, developed by OpenAI, is a recent addition to the family of language models and is being called a disruptive technology by a few, owing to its human-like text-generation capabilities. Although, many anecdotal examples across the internet have evaluated ChatGPT's strength and weakness, only a few systematic research studies exist. To contribute to the body of literature of systematic research on ChatGPT, we evaluate the performance of ChatGPT on Abstractive Summarization by the means of automated metrics and blinded human reviewers. We also build automatic text classifiers to detect ChatGPT generated summaries. We found that while text classification algorithms can distinguish between real and generated summaries, humans are unable to distinguish between real summaries and those produced by ChatGPT.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24635;&#32467;&#20102;250&#22810;&#20010;&#20851;&#20110;&#33521;&#25991;&#35821;&#35328;&#27169;&#22411;&#34892;&#20026;&#30340;&#26368;&#36817;&#30740;&#31350;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#22522;&#26412;&#30340;&#21477;&#27861;&#12289;&#35821;&#20041;&#12289;&#35821;&#29992;&#12289;&#19990;&#30028;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#23481;&#26131;&#20986;&#29616;&#19981;&#23454;&#22238;&#31572;&#12289;&#24120;&#35782;&#38169;&#35823;&#12289;&#35760;&#24518;&#21270;&#25991;&#26412;&#21644;&#31038;&#20250;&#20559;&#35265;&#31561;&#24369;&#28857;&#12290;</title><link>http://arxiv.org/abs/2303.11504</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#34892;&#20026;&#65306;&#19968;&#39033;&#20840;&#38754;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Language Model Behavior: A Comprehensive Survey. (arXiv:2303.11504v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11504
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24635;&#32467;&#20102;250&#22810;&#20010;&#20851;&#20110;&#33521;&#25991;&#35821;&#35328;&#27169;&#22411;&#34892;&#20026;&#30340;&#26368;&#36817;&#30740;&#31350;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#22522;&#26412;&#30340;&#21477;&#27861;&#12289;&#35821;&#20041;&#12289;&#35821;&#29992;&#12289;&#19990;&#30028;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#23481;&#26131;&#20986;&#29616;&#19981;&#23454;&#22238;&#31572;&#12289;&#24120;&#35782;&#38169;&#35823;&#12289;&#35760;&#24518;&#21270;&#25991;&#26412;&#21644;&#31038;&#20250;&#20559;&#35265;&#31561;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer &#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#65292;&#28982;&#32780;&#23427;&#20204;&#29983;&#25104;&#30340;&#25991;&#26412;&#21363;&#20351;&#23545;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20154;&#21592;&#26469;&#35828;&#20063;&#24120;&#24120;&#20196;&#20154;&#24778;&#35766;&#12290;&#22312;&#26412;&#27425;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;250&#22810;&#20010;&#20851;&#20110;&#33521;&#35821;&#35821;&#35328;&#27169;&#22411;&#34892;&#20026;&#30340;&#26368;&#36817;&#30740;&#31350;&#65292;&#36825;&#20123;&#30740;&#31350;&#22312;&#20219;&#21153;&#29305;&#23450;&#30340;&#24494;&#35843;&#20043;&#21069;&#36827;&#34892;&#12290;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#22522;&#26412;&#30340;&#21477;&#27861;&#12289;&#35821;&#20041;&#12289;&#35821;&#29992;&#12289;&#19990;&#30028;&#30693;&#35782;&#21644;&#25512;&#29702;&#33021;&#21147;&#65292;&#20294;&#36825;&#20123;&#33021;&#21147;&#23545;&#29305;&#23450;&#30340;&#36755;&#20837;&#21644;&#34920;&#38754;&#29305;&#24449;&#24456;&#25935;&#24863;&#12290;&#23613;&#31649;&#27169;&#22411;&#38543;&#30528;&#21442;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#29983;&#25104;&#30340;&#25991;&#26412;&#36136;&#37327;&#26174;&#33879;&#25552;&#39640;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#23481;&#26131;&#20986;&#29616;&#19981;&#23454;&#22238;&#31572;&#12289;&#24120;&#35782;&#38169;&#35823;&#12289;&#35760;&#24518;&#21270;&#25991;&#26412;&#21644;&#31038;&#20250;&#20559;&#35265;&#12290;&#20854;&#20013;&#35768;&#22810;&#24369;&#28857;&#21487;&#20197;&#34987;&#25551;&#36848;&#20026;&#23545;&#25991;&#26412;&#20013;&#25152;&#23398;&#27169;&#24335;&#30340;&#36807;&#24230;&#25512;&#24191;&#25110;&#36807;&#24230;&#27867;&#21270;&#12290;&#25105;&#20204;&#32508;&#21512;&#20102;&#26368;&#36817;&#30340;&#32467;&#26524;&#65292;&#31361;&#20986;&#20102;&#30446;&#21069;&#24050;&#30693;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#20570;&#20160;&#20040;&#21644;&#19981;&#33021;&#20570;&#20160;&#20040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer language models have received widespread public attention, yet their generated text is often surprising even to NLP researchers. In this survey, we discuss over 250 recent studies of English language model behavior before task-specific fine-tuning. Language models possess basic capabilities in syntax, semantics, pragmatics, world knowledge, and reasoning, but these capabilities are sensitive to specific inputs and surface features. Despite dramatic increases in generated text quality as models scale to hundreds of billions of parameters, the models are still prone to unfactual responses, commonsense errors, memorized text, and social biases. Many of these weaknesses can be framed as over-generalizations or under-generalizations of learned patterns in text. We synthesize recent results to highlight what is currently known about what large language models can and cannot do.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20381;&#36182;&#24615;&#24314;&#27169;&#26041;&#27861;&#65292;&#30001;&#24773;&#24863;&#24815;&#24615;&#21644;&#24863;&#26579;&#39537;&#21160;&#65288;EmotionIC&#65289;&#65292;&#29992;&#20110;&#22312;&#29305;&#24449;&#25552;&#21462;&#21644;&#20998;&#31867;&#32423;&#21035;&#19978;&#36827;&#34892;&#20250;&#35805;&#24773;&#24863;&#35782;&#21035;&#12290;&#35774;&#35745;&#20102;&#22810;&#39033;&#20855;&#20307;&#26041;&#27861;&#65292;&#21253;&#25324;&#36523;&#20221;&#25513;&#30721;&#22810;&#22836;&#27880;&#24847;&#65288;IM-MHA&#65289;&#21644;&#22522;&#20110;&#23545;&#35805;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;(DialogGRU)&#65292;&#20197;&#25235;&#21462;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.11117</link><description>&lt;p&gt;
EmotionIC&#65306;&#22522;&#20110;&#24773;&#24863;&#24815;&#24615;&#21644;&#24863;&#26579;&#30340;&#20381;&#36182;&#24314;&#27169;&#21487;&#29992;&#20110;&#23545;&#35805;&#20013;&#30340;&#24773;&#24863;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
EmotionIC: Emotional Inertia and Contagion-driven Dependency Modelling for Emotion Recognition in Conversation. (arXiv:2303.11117v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11117
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20381;&#36182;&#24615;&#24314;&#27169;&#26041;&#27861;&#65292;&#30001;&#24773;&#24863;&#24815;&#24615;&#21644;&#24863;&#26579;&#39537;&#21160;&#65288;EmotionIC&#65289;&#65292;&#29992;&#20110;&#22312;&#29305;&#24449;&#25552;&#21462;&#21644;&#20998;&#31867;&#32423;&#21035;&#19978;&#36827;&#34892;&#20250;&#35805;&#24773;&#24863;&#35782;&#21035;&#12290;&#35774;&#35745;&#20102;&#22810;&#39033;&#20855;&#20307;&#26041;&#27861;&#65292;&#21253;&#25324;&#36523;&#20221;&#25513;&#30721;&#22810;&#22836;&#27880;&#24847;&#65288;IM-MHA&#65289;&#21644;&#22522;&#20110;&#23545;&#35805;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;(DialogGRU)&#65292;&#20197;&#25235;&#21462;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38543;&#30528;&#20154;&#26426;&#30028;&#38754;&#25216;&#26415;&#30340;&#36827;&#27493;&#21644;&#23454;&#26045;&#65292;&#23545;&#35805;&#20013;&#30340;&#24773;&#24863;&#35782;&#21035;&#65288;ERC&#65289;&#21560;&#24341;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#24314;&#27169;&#26041;&#27861;&#22312;&#20840;&#23616;&#21644;&#23616;&#37096;&#19978;&#19979;&#25991;&#20381;&#36182;&#26041;&#38754;&#20002;&#22833;&#20102;&#20381;&#36182;&#20449;&#24687;&#30340;&#22810;&#26679;&#24615;&#65292;&#24182;&#19988;&#22312;&#20998;&#31867;&#32423;&#21035;&#19981;&#32771;&#34385;&#19978;&#19979;&#25991;&#20381;&#36182;&#20851;&#31995;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20381;&#36182;&#24615;&#24314;&#27169;&#26041;&#27861;&#65292;&#30001;&#24773;&#24863;&#24815;&#24615;&#21644;&#24863;&#26579;&#39537;&#21160;&#65288;EmotionIC&#65289;&#65292;&#29992;&#20110;&#22312;&#29305;&#24449;&#25552;&#21462;&#21644;&#20998;&#31867;&#32423;&#21035;&#19978;&#36827;&#34892;&#20250;&#35805;&#24773;&#24863;&#35782;&#21035;&#12290;&#22312;&#29305;&#24449;&#25552;&#21462;&#32423;&#21035;&#65292;&#25105;&#20204;&#35774;&#35745;&#30340;&#36523;&#20221;&#25513;&#30721;&#22810;&#22836;&#27880;&#24847;&#65288;IM-MHA&#65289;&#25429;&#25417;&#23545;&#35805;&#20013;&#22522;&#20110;&#36523;&#20221;&#30340;&#38271;&#36317;&#31163;&#19978;&#19979;&#25991;&#65292;&#20197;&#21253;&#21547;&#19981;&#21516;&#21442;&#19982;&#32773;&#30340;&#19981;&#21516;&#24433;&#21709;&#26500;&#24314;&#20840;&#23616;&#24773;&#24863;&#27675;&#22260;&#65292;&#32780;&#35774;&#35745;&#30340;&#22522;&#20110;&#23545;&#35805;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;(DialogGRU)&#21017;&#32858;&#21512;&#20102;&#20108;&#20803;&#23545;&#35805;&#30340;&#24773;&#24863;&#20542;&#21521;&#65292;&#24182;&#24212;&#29992;&#20110;&#20998;&#31867;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emotion Recognition in Conversation (ERC) has attracted growing attention in recent years as a result of the advancement and implementation of human-computer interface technologies. However, previous approaches to modeling global and local context dependencies lost the diversity of dependency information and do not take the context dependency into account at the classification level. In this paper, we propose a novel approach to dependency modeling driven by Emotional Inertia and Contagion (EmotionIC) for conversational emotion recognition at the feature extraction and classification levels. At the feature extraction level, our designed Identity Masked Multi-head Attention (IM-MHA) captures the identity-based long-distant context in the dialogue to contain the diverse influence of different participants and construct the global emotional atmosphere, while the devised Dialogue-based Gate Recurrent Unit (DialogGRU) that aggregates the emotional tendencies of dyadic dialogue is applied to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#26631;&#31614;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#25163;&#21160;&#26631;&#35760;&#30340;&#25968;&#25454;&#20013;&#23384;&#22312;&#22122;&#22768;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27169;&#22411;&#39044;&#27979;&#26469;&#36741;&#21161;&#20154;&#31867;&#26631;&#35760;&#22122;&#22768;&#25968;&#25454;&#12290;&#23454;&#39564;&#35777;&#26126;&#27492;&#26041;&#27861;&#36866;&#29992;&#20110;&#22810;&#31867;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2302.04391</link><description>&lt;p&gt;
&#25968;&#25454;&#20013;&#24515;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#26032;&#26631;&#31614;&#27861;
&lt;/p&gt;
&lt;p&gt;
The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#26631;&#31614;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#25163;&#21160;&#26631;&#35760;&#30340;&#25968;&#25454;&#20013;&#23384;&#22312;&#22122;&#22768;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27169;&#22411;&#39044;&#27979;&#26469;&#36741;&#21161;&#20154;&#31867;&#26631;&#35760;&#22122;&#22768;&#25968;&#25454;&#12290;&#23454;&#39564;&#35777;&#26126;&#27492;&#26041;&#27861;&#36866;&#29992;&#20110;&#22810;&#31867;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25163;&#21160;&#26631;&#35760;&#30340;&#25968;&#25454;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#23384;&#22312;&#22122;&#22768;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#22312;&#24320;&#21457;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;90&#20998;&#20197;&#19978;&#30340;&#25104;&#32489;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#25214;&#20986;&#22122;&#22768;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#37319;&#29992;&#27169;&#22411;&#39044;&#27979;&#20316;&#20026;&#20154;&#31867;&#26631;&#35760;&#30340;&#21442;&#32771;&#26469;&#37325;&#26032;&#26631;&#35760;&#22122;&#22768;&#25968;&#25454;&#12290;&#26412;&#25991;&#38416;&#36848;&#20102;&#25105;&#20204;&#22312;&#24191;&#27867;&#30340;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24819;&#27861;&#65292;&#21253;&#25324;&#20998;&#31867;&#12289;&#24207;&#21015;&#26631;&#35760;&#12289;&#29289;&#20307;&#26816;&#27979;&#12289;&#24207;&#21015;&#29983;&#25104;&#12289;&#28857;&#20987;&#29575;&#39044;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#21644;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#24819;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; GINSEW &#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#31192;&#23494;&#20449;&#21495;&#27880;&#20837;&#21040;&#27599;&#20010;&#30446;&#26631;&#26631;&#35760;&#30340;&#35299;&#30721;&#27493;&#39588;&#30340;&#27010;&#29575;&#21521;&#37327;&#20013;&#65292;&#20445;&#25252;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#65292;&#26377;&#25928;&#35782;&#21035;&#20986;&#20405;&#26435;&#34892;&#20026;&#65292;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#24456;&#23567;&#12290;</title><link>http://arxiv.org/abs/2302.03162</link><description>&lt;p&gt;
&#36890;&#36807;&#38544;&#24418;&#27700;&#21360;&#20445;&#25252;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Protecting Language Generation Models via Invisible Watermarking. (arXiv:2302.03162v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03162
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; GINSEW &#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#31192;&#23494;&#20449;&#21495;&#27880;&#20837;&#21040;&#27599;&#20010;&#30446;&#26631;&#26631;&#35760;&#30340;&#35299;&#30721;&#27493;&#39588;&#30340;&#27010;&#29575;&#21521;&#37327;&#20013;&#65292;&#20445;&#25252;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#65292;&#26377;&#25928;&#35782;&#21035;&#20986;&#20405;&#26435;&#34892;&#20026;&#65292;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#26159;&#35768;&#22810;&#24212;&#29992;&#30340;&#26377;&#21147;&#25903;&#25345;&#32773;&#12290;&#35768;&#22810;&#36825;&#26679;&#30340;&#27169;&#22411;&#25552;&#20379;&#20813;&#36153;&#25110;&#32463;&#27982;&#23454;&#24800;&#30340; API &#35775;&#38382;&#65292;&#36825;&#20351;&#23427;&#20204;&#21487;&#33021;&#21463;&#21040;&#27169;&#22411;&#25277;&#21462;&#25915;&#20987;&#30340;&#23041;&#32961;&#12290;&#20026;&#20102;&#20445;&#25252;&#30693;&#35782;&#20135;&#26435;&#24182;&#30830;&#20445;&#36825;&#20123;&#27169;&#22411;&#30340;&#20844;&#27491;&#20351;&#29992;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#25216;&#26415;&#65292;&#20363;&#22914;&#35789;&#27719;&#27700;&#21360;&#21644;&#21516;&#20041;&#35789;&#26367;&#25442;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#33021;&#20250;&#34987;&#26126;&#26174;&#30340;&#23545;&#31574;&#22914;&#8220;&#21516;&#20041;&#35789;&#38543;&#26426;&#21270;&#8221;&#31561;&#25152;&#25269;&#28040;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; GINSEW&#65292;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#33976;&#39311;&#20445;&#25252;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#31192;&#23494;&#20449;&#21495;&#27880;&#20837;&#21040;&#27599;&#20010;&#30446;&#26631;&#26631;&#35760;&#30340;&#35299;&#30721;&#27493;&#39588;&#30340;&#27010;&#29575;&#21521;&#37327;&#20013;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#25506;&#27979;&#23244;&#30097;&#30340;&#27169;&#22411;&#26469;&#26816;&#27979;&#31192;&#23494;&#28040;&#24687;&#26159;&#21542;&#30001;&#21463;&#20445;&#25252;&#30340;&#27169;&#22411;&#33976;&#39311;&#32780;&#26469;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;GINSEW &#21487;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#20405;&#26435;&#34892;&#20026;&#65292;&#23545;&#29983;&#25104;&#27169;&#22411;&#30340;&#24433;&#21709;&#26497;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language generation models have been an increasingly powerful enabler for many applications. Many such models offer free or affordable API access, which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and ensure fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as "synonym randomization". To address this issue, we propose GINSEW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the ge
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25317;&#26377;&#20016;&#23500;&#30340;&#20107;&#20214;&#30693;&#35782;&#65292;&#20960;&#20046;&#24635;&#26159;&#23558;&#21487;&#33021;&#20107;&#20214;&#30340;&#25551;&#36848;&#27604;&#19981;&#21487;&#33021;&#20107;&#20214;&#30340;&#25551;&#36848;&#36171;&#20104;&#26356;&#39640;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.01488</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20107;&#20214;&#30693;&#35782;&#65306;&#19981;&#21487;&#33021;&#24615;&#21644;&#19981;&#22826;&#21487;&#33021;&#24615;&#20043;&#38388;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Event knowledge in large language models: the gap between the impossible and the unlikely. (arXiv:2212.01488v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.01488
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25317;&#26377;&#20016;&#23500;&#30340;&#20107;&#20214;&#30693;&#35782;&#65292;&#20960;&#20046;&#24635;&#26159;&#23558;&#21487;&#33021;&#20107;&#20214;&#30340;&#25551;&#36848;&#27604;&#19981;&#21487;&#33021;&#20107;&#20214;&#30340;&#25551;&#36848;&#36171;&#20104;&#26356;&#39640;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#35821;&#26009;&#24211;&#20013;&#30340;&#35789;&#20849;&#29616;&#27169;&#24335;&#21253;&#21547;&#30528;&#24847;&#24819;&#19981;&#21040;&#30340;&#27010;&#24565;&#30693;&#35782;&#12290;&#36890;&#36807;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#26469;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#35789;&#35821;&#65292;&#36825;&#20123;&#27169;&#22411;&#33021;&#22815;&#21033;&#29992;&#36825;&#20123;&#27169;&#24335;&#65292;&#22312;&#38656;&#35201;&#19990;&#30028;&#30693;&#35782;&#30340;&#21508;&#31181;&#35821;&#20041;&#20219;&#21153;&#19978;&#21462;&#24471;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#12290;&#20851;&#20110;LLMs&#30340;&#35821;&#20041;&#33021;&#21147;&#30340;&#37325;&#35201;&#20294;&#40092;&#20026;&#30740;&#31350;&#30340;&#38382;&#39064;&#26159;&#23427;&#20204;&#26159;&#21542;&#33719;&#24471;&#20102;&#24120;&#35265;&#20107;&#20214;&#30340;&#19968;&#33324;&#21270;&#30693;&#35782;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#27979;&#35797;&#20102;&#20116;&#20010;&#39044;&#35757;&#32451;&#30340;LLMs&#65288;&#20174;2018&#24180;&#30340;BERT&#21040;2023&#24180;&#30340;MPT&#65289;&#26159;&#21542;&#27604;&#21516;&#19968;&#20107;&#20214;&#30340;&#19981;&#22826;&#21487;&#33021;&#30340;&#29256;&#26412;&#26356;&#21487;&#33021;&#22320;&#20998;&#37197;&#32473;&#21512;&#29702;&#30340;&#20195;&#29702;-&#24739;&#32773;&#30456;&#20114;&#20316;&#29992;&#12290;&#20351;&#29992;&#19977;&#20010;&#31934;&#24515;&#31574;&#21010;&#30340;&#26368;&#23567;&#21477;&#23545;&#38598;&#21512;&#65288;&#24635;&#25968;n=1,215&#65289;&#65292;&#25105;&#20204;&#21457;&#29616;&#39044;&#35757;&#32451;&#30340;LLMs&#25317;&#26377;&#30456;&#24403;&#22823;&#30340;&#20107;&#20214;&#30693;&#35782;&#65292;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#20998;&#24067;&#24335;&#35821;&#35328;&#27169;&#22411;&#12290;&#29305;&#21035;&#26159;&#65292;&#23427;&#20204;&#20960;&#20046;&#24635;&#26159;&#23558;&#21487;&#33021;&#20107;&#20214;&#19982;&#19981;&#21487;&#33021;&#20107;&#20214;&#30456;&#27604;&#36171;&#20104;&#26356;&#39640;&#30340;&#21487;&#33021;&#24615;&#65288;&#25945;&#24072;&#20080;&#20102;&#31508;&#35760;&#26412;&#30005;&#33041;&#30456;&#23545;&#20110;&#31508;&#35760;&#26412;&#30005;&#33041;&#20080;&#20102;&#25945;&#24072;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Word co-occurrence patterns in language corpora contain a surprising amount of conceptual knowledge. Large language models (LLMs), trained to predict words in context, leverage these patterns to achieve impressive performance on diverse semantic tasks requiring world knowledge. An important but understudied question about LLMs' semantic abilities is whether they acquire generalized knowledge of common events. Here, we test whether five pre-trained LLMs (from 2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions of agent-patient interactions than to minimally different implausible versions of the same event. Using three curated sets of minimal sentence pairs (total n=1,215), we found that pre-trained LLMs possess substantial event knowledge, outperforming other distributional language models. In particular, they almost always assign higher likelihood to possible vs. impossible events (The teacher bought the laptop vs. The laptop bought the teacher). However, LLMs
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#35270;&#35282;&#19968;&#33268;&#30340;&#23545;&#27604;&#23398;&#20064;&#26469;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#38382;&#39064;&#65292;&#36890;&#36807;&#21516;&#26102;&#32771;&#34385;&#33258;&#19978;&#32780;&#19979;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#25512;&#29702;&#35270;&#35282;&#65292;&#20197;&#21450;&#22810;&#31181;&#31561;&#20215;&#30340;&#26041;&#31243;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#26356;&#23436;&#25972;&#30340;&#35821;&#20041;&#21040;&#26041;&#31243;&#30340;&#26144;&#23556;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#12290;</title><link>http://arxiv.org/abs/2210.11694</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#25512;&#29702;&#65306;&#19968;&#33268;&#30340;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#25968;&#23398;&#24212;&#29992;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem. (arXiv:2210.11694v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11694
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#35270;&#35282;&#19968;&#33268;&#30340;&#23545;&#27604;&#23398;&#20064;&#26469;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#38382;&#39064;&#65292;&#36890;&#36807;&#21516;&#26102;&#32771;&#34385;&#33258;&#19978;&#32780;&#19979;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#25512;&#29702;&#35270;&#35282;&#65292;&#20197;&#21450;&#22810;&#31181;&#31561;&#20215;&#30340;&#26041;&#31243;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#26356;&#23436;&#25972;&#30340;&#35821;&#20041;&#21040;&#26041;&#31243;&#30340;&#26144;&#23556;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23398;&#24212;&#29992;&#38382;&#39064;&#27714;&#35299;&#22120;&#38656;&#35201;&#23545;&#25991;&#26412;&#20013;&#30340;&#25968;&#37327;&#36827;&#34892;&#31934;&#30830;&#30340;&#20851;&#31995;&#25512;&#29702;&#21644;&#21487;&#38752;&#30340;&#26041;&#31243;&#29983;&#25104;&#12290;&#24403;&#21069;&#30340;&#24207;&#21015;&#21040;&#26641;&#25110;&#20851;&#31995;&#25277;&#21462;&#26041;&#27861;&#21482;&#20174;&#19968;&#20010;&#22266;&#23450;&#35270;&#35282;&#30475;&#24453;&#36825;&#20010;&#38382;&#39064;&#65292;&#24456;&#38590;&#21516;&#26102;&#22788;&#29702;&#22797;&#26434;&#30340;&#35821;&#20041;&#21644;&#22810;&#26679;&#30340;&#26041;&#31243;&#12290;&#28982;&#32780;&#65292;&#20154;&#31867;&#35299;&#39064;&#33258;&#28982;&#22320;&#28041;&#21450;&#20004;&#31181;&#19968;&#33268;&#30340;&#25512;&#29702;&#35270;&#35282;&#65306;&#33258;&#19978;&#32780;&#19979;&#21644;&#33258;&#19979;&#32780;&#19978;&#65292;&#23601;&#20687;&#25968;&#23398;&#26041;&#31243;&#20063;&#21487;&#20197;&#29992;&#22810;&#31181;&#31561;&#20215;&#24418;&#24335;&#34920;&#31034;&#65306;&#21069;&#24207;&#21644;&#21518;&#24207;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#35282;&#19968;&#33268;&#30340;&#23545;&#27604;&#23398;&#20064;&#65292;&#29992;&#20110;&#26356;&#23436;&#25972;&#30340;&#35821;&#20041;&#21040;&#26041;&#31243;&#30340;&#26144;&#23556;&#12290;&#25972;&#20010;&#36807;&#31243;&#34987;&#20998;&#35299;&#20026;&#20004;&#20010;&#29420;&#31435;&#20294;&#19968;&#33268;&#30340;&#35270;&#35282;&#65306;&#33258;&#19978;&#32780;&#19979;&#30340;&#20998;&#35299;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#26500;&#24314;&#65292;&#24182;&#19988;&#20004;&#31181;&#25512;&#29702;&#35270;&#35282;&#22312;&#22810;&#31890;&#24230;&#19978;&#23545;&#40784;&#20197;&#20445;&#25345;&#19968;&#33268;&#24615;&#65292;&#22686;&#24378;&#20840;&#23616;&#29983;&#25104;&#21644;&#31934;&#30830;&#25512;&#29702;&#12290;&#22312;&#20004;&#31181;&#35821;&#35328;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Math word problem solver requires both precise relation reasoning about quantities in the text and reliable generation for the diverse equation. Current sequence-to-tree or relation extraction methods regard this only from a fixed view, struggling to simultaneously handle complex semantics and diverse equations. However, human solving naturally involves two consistent reasoning views: top-down and bottom-up, just as math equations also can be expressed in multiple equivalent forms: pre-order and post-order. We propose a multi-view consistent contrastive learning for a more complete semantics-to-equation mapping. The entire process is decoupled into two independent but consistent views: top-down decomposition and bottom-up construction, and the two reasoning views are aligned in multi-granularity for consistency, enhancing global generation and precise reasoning. Experiments on multiple datasets across two languages show our approach significantly outperforms the existing baselines, esp
&lt;/p&gt;</description></item><item><title>TwHIN-BERT&#26159;&#19968;&#20010;&#22312;Twitter&#19978;&#35757;&#32451;&#30340;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#25991;&#26412;&#30340;&#33258;&#30417;&#30563;&#21644;&#22522;&#20110;&#20016;&#23500;&#31038;&#20132;&#21442;&#19982;&#23545;&#35937;&#30340;&#31038;&#20132;&#30446;&#26631;&#35757;&#32451;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#31034;&#30701;&#12289;&#22024;&#26434;&#30340;&#29992;&#25143;&#29983;&#25104;&#25991;&#26412;&#12290;&#22312;&#21508;&#31181;&#22810;&#35821;&#35328;&#31038;&#20132;&#25512;&#33616;&#21644;&#35821;&#20041;&#29702;&#35299;&#20219;&#21153;&#20013;&#65292;TwHIN-BERT&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#25351;&#26631;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2209.07562</link><description>&lt;p&gt;
TwHIN-BERT&#65306;&#19968;&#31181;&#29992;&#20110;Twitter&#22810;&#35821;&#35328;&#25512;&#29305;&#34920;&#31034;&#30340;&#31038;&#20132;&#22686;&#24378;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter. (arXiv:2209.07562v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07562
&lt;/p&gt;
&lt;p&gt;
TwHIN-BERT&#26159;&#19968;&#20010;&#22312;Twitter&#19978;&#35757;&#32451;&#30340;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#25991;&#26412;&#30340;&#33258;&#30417;&#30563;&#21644;&#22522;&#20110;&#20016;&#23500;&#31038;&#20132;&#21442;&#19982;&#23545;&#35937;&#30340;&#31038;&#20132;&#30446;&#26631;&#35757;&#32451;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#31034;&#30701;&#12289;&#22024;&#26434;&#30340;&#29992;&#25143;&#29983;&#25104;&#25991;&#26412;&#12290;&#22312;&#21508;&#31181;&#22810;&#35821;&#35328;&#31038;&#20132;&#25512;&#33616;&#21644;&#35821;&#20041;&#29702;&#35299;&#20219;&#21153;&#20013;&#65292;TwHIN-BERT&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#25351;&#26631;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#23545;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;PLMs&#24182;&#19981;&#38024;&#23545;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#22024;&#26434;&#29992;&#25143;&#29983;&#25104;&#25991;&#26412;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#19988;&#39044;&#35757;&#32451;&#36807;&#31243;&#20013;&#27809;&#26377;&#32771;&#34385;&#31038;&#20132;&#32593;&#32476;&#20013;&#21487;&#29992;&#30340;&#26377;&#20215;&#20540;&#30340;&#31038;&#20132;&#21442;&#19982;&#26085;&#24535;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;TwHIN-BERT&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;Twitter&#19978;&#29983;&#20135;&#21270;&#30340;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#65292;&#35757;&#32451;&#25968;&#25454;&#26469;&#33258;&#27969;&#34892;&#30340;&#31038;&#20132;&#32593;&#32476;&#12290;&#19982;&#20808;&#21069;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#19981;&#21516;&#65292;TwHIN-BERT&#19981;&#20165;&#36890;&#36807;&#22522;&#20110;&#25991;&#26412;&#30340;&#33258;&#30417;&#30563;&#36827;&#34892;&#35757;&#32451;&#65292;&#36824;&#21033;&#29992;Twitter&#24322;&#26500;&#20449;&#24687;&#32593;&#32476;&#65288;TwHIN&#65289;&#20013;&#20016;&#23500;&#30340;&#31038;&#20132;&#21442;&#19982;&#23545;&#35937;&#36827;&#34892;&#31038;&#20132;&#30446;&#26631;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#35757;&#32451;&#25968;&#25454;&#28085;&#30422;&#20102;&#36229;&#36807;100&#31181;&#19981;&#21516;&#35821;&#35328;&#30340;70&#20159;&#26465;&#25512;&#25991;&#65292;&#20026;&#24314;&#27169;&#30701;&#12289;&#22024;&#26434;&#12289;&#29992;&#25143;&#29983;&#25104;&#30340;&#25991;&#26412;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#22810;&#35821;&#35328;&#31038;&#20132;&#25512;&#33616;&#21644;&#35821;&#20041;&#29702;&#35299;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#24050;&#24314;&#31435;&#27169;&#22411;&#30456;&#27604;&#30340;&#26174;&#33879;&#25351;&#26631;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained language models (PLMs) are fundamental for natural language processing applications. Most existing PLMs are not tailored to the noisy user-generated text on social media, and the pre-training does not factor in the valuable social engagement logs available in a social network. We present TwHIN-BERT, a multilingual language model productionized at Twitter, trained on in-domain data from the popular social network. TwHIN-BERT differs from prior pre-trained language models as it is trained with not only text-based self-supervision, but also with a social objective based on the rich social engagements within a Twitter heterogeneous information network (TwHIN). Our model is trained on 7 billion tweets covering over 100 distinct languages, providing a valuable representation to model short, noisy, user-generated text. We evaluate our model on various multilingual social recommendation and semantic understanding tasks and demonstrate significant metric improvement over established
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#31574;&#30053;LAFT-URIEL&#65292;&#29992;&#20110;&#40065;&#26834;&#24615;&#25345;&#32493;&#22810;&#35821;&#35328;&#23398;&#20064;&#65292;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#30693;&#35782;&#24179;&#34913;&#36807;&#25311;&#21512;&#21644;&#30693;&#35782;&#20849;&#20139;&#65292;&#20351;&#27169;&#22411;&#22312;&#26356;&#26032;&#21518;&#22312;&#26356;&#22810;&#35821;&#31181;&#19978;&#34920;&#29616;&#20986;&#25913;&#36827;&#65292;&#21516;&#26102;&#20943;&#23567;&#20102;&#21097;&#20313;&#35821;&#31181;&#30340;&#24615;&#33021;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2209.06767</link><description>&lt;p&gt;
&#40065;&#26834;&#24615;&#25345;&#32493;&#22810;&#35821;&#35328;&#23398;&#20064;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Parameter-Efficient Finetuning for Robust Continual Multilingual Learning. (arXiv:2209.06767v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.06767
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#31574;&#30053;LAFT-URIEL&#65292;&#29992;&#20110;&#40065;&#26834;&#24615;&#25345;&#32493;&#22810;&#35821;&#35328;&#23398;&#20064;&#65292;&#36890;&#36807;&#21033;&#29992;&#35821;&#35328;&#30693;&#35782;&#24179;&#34913;&#36807;&#25311;&#21512;&#21644;&#30693;&#35782;&#20849;&#20139;&#65292;&#20351;&#27169;&#22411;&#22312;&#26356;&#26032;&#21518;&#22312;&#26356;&#22810;&#35821;&#31181;&#19978;&#34920;&#29616;&#20986;&#25913;&#36827;&#65292;&#21516;&#26102;&#20943;&#23567;&#20102;&#21097;&#20313;&#35821;&#31181;&#30340;&#24615;&#33021;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#40065;&#26834;&#24615;&#25345;&#32493;&#22810;&#35821;&#35328;&#23398;&#20064;&#65288;CML&#65289;&#30340;&#38382;&#39064;&#65292;&#21363;&#21608;&#26399;&#24615;&#20351;&#29992;&#26032;&#21040;&#36798;&#30340;&#25968;&#25454;&#23545;&#20808;&#21069;&#35757;&#32451;&#30340;&#22810;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26356;&#26032;&#12290;&#22914;&#26524;&#26032;&#25968;&#25454;&#20165;&#23384;&#22312;&#20110;&#35821;&#31181;&#30340;&#23376;&#38598;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#20165;&#22312;&#26368;&#26032;&#26356;&#26032;&#20013;&#21253;&#25324;&#30340;&#35821;&#31181;&#65288;&#21644;&#19968;&#20123;&#32039;&#23494;&#30456;&#20851;&#30340;&#35821;&#31181;&#65289;&#19978;&#34920;&#29616;&#20986;&#25913;&#36827;&#65292;&#32780;&#20854;&#22312;&#25152;&#26377;&#21097;&#20313;&#35821;&#31181;&#19978;&#30340;&#24615;&#33021;&#21017;&#26174;&#33879;&#19979;&#38477;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;LAFT-URIEL&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#36825;&#26159;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#31574;&#30053;&#65292;&#26088;&#22312;&#22686;&#21152;&#27169;&#22411;&#26356;&#26032;&#21518;&#22312;&#35821;&#31181;&#19978;&#30340;&#24615;&#33021;&#25913;&#36827;&#25968;&#37327;&#65292;&#21516;&#26102;&#20943;&#23569;&#21097;&#20313;&#35821;&#31181;&#24615;&#33021;&#19979;&#38477;&#30340;&#31243;&#24230;&#12290;LAFT-URIEL&#21033;&#29992;&#35821;&#35328;&#30693;&#35782;&#22312;&#35821;&#31181;&#20043;&#38388;&#23454;&#29616;&#36807;&#25311;&#21512;&#21644;&#30693;&#35782;&#20849;&#20139;&#30340;&#24179;&#34913;&#65292;&#20351;&#24471;&#39069;&#22806;&#30340;25%&#20219;&#21153;&#35821;&#31181;&#22312;&#26356;&#26032;&#21518;&#30475;&#21040;&#24615;&#33021;&#25913;&#36827;&#65292;&#21516;&#26102;&#20943;&#23567;&#20102;&#21097;&#20313;&#35821;&#31181;&#30340;&#24179;&#22343;&#24615;&#33021;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce and study the problem of Continual Multilingual Learning (CML) where a previously trained multilingual model is periodically updated using new data arriving in stages. If the new data is present only in a subset of languages, we find that the resulting model shows improved performance only on the languages included in the latest update (and a few closely related languages) while its performance on all the remaining languages degrade significantly. We address this challenge by proposing LAFT-URIEL, a parameter-efficient finetuning strategy which aims to increase the number of languages on which the model improves after an update, while reducing the magnitude of loss in performance for the remaining languages. LAFT-URIEL uses linguistic knowledge to balance overfitting and knowledge sharing across languages, allowing for an additional 25% of task languages to see an improvement in performance after an update, while also reducing the average magnitude of losses on the remaini
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#34701;&#20837;&#21040;&#19968;&#20010;&#23545;&#35805;&#20195;&#29702;&#20013;&#65292;&#35774;&#35745;&#20855;&#26377;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#32452;&#20214;&#30340;&#26631;&#20934;&#27169;&#22411;&#12290;&#36890;&#36807;&#25193;&#23637;XAI&#38382;&#39064;&#24211;&#24182;&#25552;&#20379;&#35299;&#37322;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#30495;&#27491;&#33258;&#28982;&#23545;&#35805;&#12290;</title><link>http://arxiv.org/abs/2209.02552</link><description>&lt;p&gt;
&#33258;&#28982;&#23545;&#35805;&#20013;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65306;&#36208;&#21521;&#23545;&#35805;&#24335;XAI&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent. (arXiv:2209.02552v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#34701;&#20837;&#21040;&#19968;&#20010;&#23545;&#35805;&#20195;&#29702;&#20013;&#65292;&#35774;&#35745;&#20855;&#26377;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#32452;&#20214;&#30340;&#26631;&#20934;&#27169;&#22411;&#12290;&#36890;&#36807;&#25193;&#23637;XAI&#38382;&#39064;&#24211;&#24182;&#25552;&#20379;&#35299;&#37322;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#30495;&#27491;&#33258;&#28982;&#23545;&#35805;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#26041;&#27861;&#26469;&#25581;&#31034;&#40657;&#30418;&#27169;&#22411;&#65288;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#20197;&#20415;&#21521;&#20154;&#31867;&#35299;&#37322;&#12290;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#25351;&#20986;&#65292;&#36825;&#26679;&#30340;&#35299;&#37322;&#24212;&#35813;&#26159;&#23545;&#35805;&#24335;&#30340;&#65292;&#31867;&#20284;&#20110;&#20154;&#19982;&#20154;&#20043;&#38388;&#30340;&#35299;&#37322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;XAI&#34701;&#20837;&#21040;&#19968;&#20010;&#23545;&#35805;&#20195;&#29702;&#20013;&#65292;&#20351;&#29992;&#20102;&#19968;&#20010;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#32452;&#20214;&#30340;&#26631;&#20934;&#35774;&#35745;&#12290;&#25105;&#20204;&#26681;&#25454;&#36136;&#25511;&#30340;&#37322;&#20041;&#37325;&#36848;&#25193;&#23637;&#20102;&#19968;&#20010;XAI&#38382;&#39064;&#24211;&#65292;&#20197;&#29702;&#35299;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#31995;&#32479;&#22320;&#35843;&#26597;&#20102;&#36866;&#21512;&#25552;&#20379;&#31572;&#26696;&#20449;&#24687;&#30340;&#35299;&#37322;&#26041;&#27861;&#30340;&#25991;&#29486;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#24314;&#35758;&#21015;&#34920;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#23454;&#29616;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#30495;&#27491;&#33258;&#28982;&#23545;&#35805;&#30340;&#31532;&#19968;&#27493;&#65292;&#19982;&#19968;&#20010;&#35299;&#37322;&#20195;&#29702;&#26377;&#20851;&#30340;&#20840;&#38754;&#30340;XAI&#38382;&#39064;&#21015;&#34920;&#21644;&#30456;&#24212;&#30340;&#35299;&#37322;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of Explainable AI (XAI) is to design methods to provide insights into the reasoning process of black-box models, such as deep neural networks, in order to explain them to humans. Social science research states that such explanations should be conversational, similar to human-to-human explanations. In this work, we show how to incorporate XAI in a conversational agent, using a standard design for the agent comprising natural language understanding and generation components. We build upon an XAI question bank which we extend by quality-controlled paraphrases to understand the user's information needs. We further systematically survey the literature for suitable explanation methods that provide the information to answer those questions, and present a comprehensive list of suggestions. Our work is the first step towards truly natural conversations about machine learning models with an explanation agent. The comprehensive list of XAI questions and the corresponding explanation meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#38024;&#23545;&#31359;&#26797;&#24335;&#31163;&#23376;&#38449;&#37327;&#23376;&#22788;&#29702;&#22120;&#30340;&#37327;&#23376;&#30005;&#36335;&#32534;&#35793;&#22120;&#65292;&#33021;&#22815;&#23558;&#37327;&#23376;&#30005;&#36335;&#36716;&#25442;&#21644;&#20248;&#21270;&#20026;&#29305;&#23450;&#30340;&#26412;&#22320;&#38376;&#24207;&#21015;&#65292;&#19982;&#26631;&#20934;&#32534;&#35793;&#26041;&#27861;&#30456;&#27604;&#65292;&#21487;&#20197;&#23558;&#38376;&#35745;&#25968;&#20943;&#23569;&#21040;5.1&#20493;&#12290;</title><link>http://arxiv.org/abs/2207.01964</link><description>&lt;p&gt;
&#29992;&#20110;&#22522;&#20110;&#31359;&#26797;&#24335;&#31163;&#23376;&#38449;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#37327;&#23376;&#30005;&#36335;&#32534;&#35793;&#22120;
&lt;/p&gt;
&lt;p&gt;
Quantum Circuit Compiler for a Shuttling-Based Trapped-Ion Quantum Computer. (arXiv:2207.01964v3 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.01964
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#38024;&#23545;&#31359;&#26797;&#24335;&#31163;&#23376;&#38449;&#37327;&#23376;&#22788;&#29702;&#22120;&#30340;&#37327;&#23376;&#30005;&#36335;&#32534;&#35793;&#22120;&#65292;&#33021;&#22815;&#23558;&#37327;&#23376;&#30005;&#36335;&#36716;&#25442;&#21644;&#20248;&#21270;&#20026;&#29305;&#23450;&#30340;&#26412;&#22320;&#38376;&#24207;&#21015;&#65292;&#19982;&#26631;&#20934;&#32534;&#35793;&#26041;&#27861;&#30456;&#27604;&#65292;&#21487;&#20197;&#23558;&#38376;&#35745;&#25968;&#20943;&#23569;&#21040;5.1&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#37327;&#23376;&#35745;&#31639;&#30828;&#20214;&#33021;&#21147;&#30340;&#22686;&#24378;&#21644;&#23454;&#29616;&#28145;&#24230;&#37327;&#23376;&#30005;&#36335;&#30340;&#25361;&#25112;&#65292;&#38656;&#35201;&#23436;&#20840;&#33258;&#21160;&#21270;&#21644;&#39640;&#25928;&#30340;&#24037;&#20855;&#26469;&#32534;&#35793;&#37327;&#23376;&#30005;&#36335;&#12290;&#20026;&#20102;&#22312;&#29305;&#23450;&#20110;&#37327;&#23376;&#35745;&#31639;&#26426;&#26550;&#26500;&#30340;&#26412;&#22320;&#38376;&#24207;&#21015;&#20013;&#34920;&#31034;&#20219;&#24847;&#30005;&#36335;&#65292;&#38656;&#35201;&#20351;&#31639;&#27861;&#22312;&#37327;&#23376;&#30828;&#20214;&#20379;&#24212;&#21830;&#30340;&#33539;&#22260;&#20869;&#21487;&#31227;&#26893;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32534;&#35793;&#22120;&#65292;&#21487;&#20197;&#23558;&#37327;&#23376;&#30005;&#36335;&#36716;&#25442;&#21644;&#20248;&#21270;&#20026;&#38024;&#23545;&#31359;&#26797;&#24335;&#31163;&#23376;&#38449;&#37327;&#23376;&#22788;&#29702;&#22120;&#30340;&#30446;&#26631;&#30005;&#36335;&#12290;&#23427;&#30001;&#22522;&#20110;&#37327;&#23376;&#30005;&#36335;&#26694;&#26550;Pytket&#30340;&#23450;&#21046;&#31639;&#27861;&#32452;&#25104;&#12290;&#23545;&#24191;&#27867;&#30340;&#37327;&#23376;&#30005;&#36335;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#26631;&#20934;Pytket&#30456;&#27604;&#65292;&#38376;&#35745;&#25968;&#21487;&#20197;&#20943;&#23569;&#22810;&#36798;5.1&#20493;&#65292;&#19982;&#26631;&#20934;Qiskit&#32534;&#35793;&#30456;&#27604;&#21487;&#20197;&#20943;&#23569;&#22810;&#36798;2.2&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing capabilities of quantum computing hardware and the challenge of realizing deep quantum circuits require fully automated and efficient tools for compiling quantum circuits. To express arbitrary circuits in a sequence of native gates specific to the quantum computer architecture, it is necessary to make algorithms portable across the landscape of quantum hardware providers. In this work, we present a compiler capable of transforming and optimizing a quantum circuit targeting a shuttling-based trapped-ion quantum processor. It consists of custom algorithms set on top of the quantum circuit framework Pytket. The performance was evaluated for a wide range of quantum circuits and the results show that the gate counts can be reduced by factors up to 5.1 compared to standard Pytket and up to 2.2 compared to standard Qiskit compilation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#38454;&#32447;&#24615;&#36923;&#36753;&#19982;&#25193;&#23637;&#24352;&#37327;&#31867;&#22411;&#28436;&#31639;&#30340;&#20851;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22266;&#26377;&#30340;&#28436;&#32462;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2206.08955</link><description>&lt;p&gt;
&#35753;&#19968;&#38454;&#32447;&#24615;&#36923;&#36753;&#25104;&#20026;&#29983;&#25104;&#35821;&#27861;
&lt;/p&gt;
&lt;p&gt;
Making first order linear logic a generating grammar. (arXiv:2206.08955v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#38454;&#32447;&#24615;&#36923;&#36753;&#19982;&#25193;&#23637;&#24352;&#37327;&#31867;&#22411;&#28436;&#31639;&#30340;&#20851;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22266;&#26377;&#30340;&#28436;&#32462;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#19981;&#21516;&#30340;&#33539;&#30068;&#35821;&#27861;&#22312;&#19968;&#38454;&#20056;&#27861;&#32447;&#24615;&#36923;&#36753;&#30340;&#19968;&#20010;&#29255;&#27573;&#20013;&#20855;&#26377;&#34920;&#38754;&#34920;&#31034;&#12290; &#25105;&#20204;&#34920;&#26126;&#65292;&#35813;&#29255;&#27573;&#31561;&#20215;&#20110;&#26368;&#36817;&#24341;&#20837;&#30340;&#25193;&#23637;&#24352;&#37327;&#31867;&#22411;&#28436;&#31639;&#12290; &#36825;&#19981;&#20165;&#20026;&#21069;&#32773;&#25552;&#20379;&#20102;&#19968;&#20123;&#26367;&#20195;&#30340;&#35821;&#27861;&#21644;&#30452;&#35266;&#30340;&#20960;&#20309;&#34920;&#31034;&#65292;&#32780;&#19988;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#22266;&#26377;&#30340;&#28436;&#32462;&#31995;&#32479;&#65292;&#36825;&#26159;&#20197;&#21069;&#32570;&#23569;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is known that different categorial grammars have surface representation in a fragment of first order multiplicative linear logic. We show that the fragment of interest is equivalent to the recently introduced {\it extended tensor type calculus}. This provides the former not only with some alternative syntax and intuitive geometric representation, but also with an intrinsic deductive system, which has been absent.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#37325;&#26032;&#25490;&#24207;&#20505;&#36873;&#39033;&#26469;&#25552;&#39640;&#31070;&#32463;&#23545;&#35805;&#27169;&#22411;&#20013;&#30340;&#33258;&#25105;&#25259;&#38706;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#31070;&#32463;&#23545;&#35805;&#27169;&#22411;&#20013;&#23384;&#22312;&#30340;&#22238;&#22797;&#36880;&#28176;&#21464;&#24471;&#29712;&#30862;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2109.05090</link><description>&lt;p&gt;
&#36890;&#36807;&#20505;&#36873;&#39033;&#37325;&#26032;&#25490;&#24207;&#22686;&#24378;&#31070;&#32463;&#23545;&#35805;&#27169;&#22411;&#20013;&#30340;&#33258;&#25105;&#25259;&#38706;
&lt;/p&gt;
&lt;p&gt;
Enhancing Self-Disclosure In Neural Dialog Models By Candidate Re-ranking. (arXiv:2109.05090v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.05090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#37325;&#26032;&#25490;&#24207;&#20505;&#36873;&#39033;&#26469;&#25552;&#39640;&#31070;&#32463;&#23545;&#35805;&#27169;&#22411;&#20013;&#30340;&#33258;&#25105;&#25259;&#38706;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#31070;&#32463;&#23545;&#35805;&#27169;&#22411;&#20013;&#23384;&#22312;&#30340;&#22238;&#22797;&#36880;&#28176;&#21464;&#24471;&#29712;&#30862;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#35821;&#35328;&#24314;&#27169;&#22312;&#19981;&#21516;&#30340;&#19979;&#28216;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#36827;&#27493;&#12290;&#20854;&#20013;&#19968;&#20010;&#39046;&#22495;&#26159;&#24320;&#25918;&#22495;&#23545;&#35805;&#24314;&#27169;&#65292;&#22522;&#20110;GPT-2&#30340;&#31070;&#32463;&#23545;&#35805;&#27169;&#22411;&#65288;&#20363;&#22914;DialoGPT&#65289;&#22312;&#21333;&#22238;&#21512;&#23545;&#35805;&#20013;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#65288;&#31070;&#32463;&#65289;&#23545;&#35805;&#27169;&#22411;&#22240;&#20026;&#29983;&#25104;&#30340;&#22238;&#22797;&#34429;&#28982;&#21487;&#33021;&#19982;&#21069;&#19968;&#20010;&#20154;&#30340;&#22238;&#24212;&#26377;&#30456;&#20851;&#24615;&#65292;&#20294;&#24456;&#24555;&#20250;&#20351;&#20154;&#22833;&#21435;&#20852;&#36259;&#24182;&#38519;&#20837;&#29712;&#30862;&#30340;&#23545;&#35805;&#65292;&#22240;&#27492;&#21463;&#21040;&#20102;&#25209;&#35780;&#12290;&#36896;&#25104;&#36825;&#31181;&#24615;&#33021;&#30340;&#21407;&#22240;&#20043;&#19968;&#26159;&#22312;&#20154;&#26426;&#23545;&#35805;&#20013;&#32570;&#20047;&#26126;&#30830;&#30340;&#23545;&#35805;&#31574;&#30053;&#12290;&#20154;&#20204;&#22312;&#23545;&#35805;&#20013;&#20351;&#29992;&#21508;&#31181;&#23545;&#35805;&#31574;&#30053;&#65292;&#20854;&#20013;&#19968;&#20010;&#20851;&#38190;&#30340;&#31038;&#20132;&#31574;&#30053;&#26159;&#33258;&#25105;&#25259;&#38706;&#65288;SD&#65289;&#65292;&#21363;&#21521;&#20182;&#20154;&#23637;&#31034;&#33258;&#24049;&#30340;&#20449;&#24687;&#12290;&#31038;&#20250;&#28183;&#36879;&#29702;&#35770;&#65288;SPT&#65289;&#25552;&#20986;&#65292;&#20004;&#20010;&#20154;&#20043;&#38388;&#30340;&#20132;&#27969;&#20250;&#38543;&#30528;&#20851;&#31995;&#30340;&#36827;&#23637;&#20174;&#34920;&#38754;&#23618;&#27425;&#36880;&#28176;&#28145;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural language modelling has progressed the state-of-the-art in different downstream Natural Language Processing (NLP) tasks. One such area is of open-domain dialog modelling, neural dialog models based on GPT-2 such as DialoGPT have shown promising performance in single-turn conversation. However, such (neural) dialog models have been criticized for generating responses which although may have relevance to the previous human response, tend to quickly dissipate human interest and descend into trivial conversation. One reason for such performance is the lack of explicit conversation strategy being employed in human-machine conversation. Humans employ a range of conversation strategies while engaging in a conversation, one such key social strategies is Self-disclosure(SD). A phenomenon of revealing information about one-self to others. Social penetration theory (SPT) proposes that communication between two people moves from shallow to deeper levels as the relationship progresses primari
&lt;/p&gt;</description></item><item><title>CoPaSul&#24037;&#20855;&#21253;&#25552;&#20379;&#20102;&#33258;&#21160;&#30340;&#38901;&#24459;&#26631;&#27880;&#21644;&#29305;&#24449;&#25552;&#21462;&#21151;&#33021;&#65292;&#20351;&#29992;&#20102;&#22522;&#20110;&#36718;&#24275;&#30340;&#21442;&#25968;&#21270;&#21644;&#21472;&#21152;&#38901;&#24459;&#39118;&#26684;&#21270;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#35813;&#24037;&#20855;&#21253;&#21487;&#20197;&#24471;&#21040;&#19982;&#38901;&#24459;&#36793;&#30028;&#21644;&#31361;&#20986;&#24615;&#30456;&#20851;&#30340;&#29305;&#24449;&#65292;&#24182;&#21487;&#20197;&#36890;&#36807;&#31995;&#25968;&#32858;&#31867;&#24471;&#21040;&#38901;&#24459;&#36718;&#24275;&#31867;&#21035;&#12290;</title><link>http://arxiv.org/abs/1612.04765</link><description>&lt;p&gt;
CoPaSul&#25163;&#20876;--&#22522;&#20110;&#36718;&#24275;&#30340;&#21442;&#25968;&#21270;&#21644;&#21472;&#21152;&#38901;&#24459;&#39118;&#26684;&#21270;
&lt;/p&gt;
&lt;p&gt;
CoPaSul Manual -- Contour-based parametric and superpositional intonation stylization. (arXiv:1612.04765v11 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1612.04765
&lt;/p&gt;
&lt;p&gt;
CoPaSul&#24037;&#20855;&#21253;&#25552;&#20379;&#20102;&#33258;&#21160;&#30340;&#38901;&#24459;&#26631;&#27880;&#21644;&#29305;&#24449;&#25552;&#21462;&#21151;&#33021;&#65292;&#20351;&#29992;&#20102;&#22522;&#20110;&#36718;&#24275;&#30340;&#21442;&#25968;&#21270;&#21644;&#21472;&#21152;&#38901;&#24459;&#39118;&#26684;&#21270;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#35813;&#24037;&#20855;&#21253;&#21487;&#20197;&#24471;&#21040;&#19982;&#38901;&#24459;&#36793;&#30028;&#21644;&#31361;&#20986;&#24615;&#30456;&#20851;&#30340;&#29305;&#24449;&#65292;&#24182;&#21487;&#20197;&#36890;&#36807;&#31995;&#25968;&#32858;&#31867;&#24471;&#21040;&#38901;&#24459;&#36718;&#24275;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
CoPaSul&#24037;&#20855;&#21253;&#30340;&#30446;&#30340;&#26159;&#33258;&#21160;&#30340;&#38901;&#24459;&#26631;&#27880;&#21644;&#20174;&#38899;&#33410;&#21040;&#35821;&#21477;&#32423;&#21035;&#30340;&#38901;&#24459;&#29305;&#24449;&#25552;&#21462;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#38901;&#24459;&#34987;&#34920;&#31034;&#20026;&#20840;&#23616;&#21644;&#23616;&#37096;&#36718;&#24275;&#30340;&#21472;&#21152;&#65292;&#36825;&#20123;&#36718;&#24275;&#22312;&#22810;&#39033;&#24335;&#31995;&#25968;&#30340;&#21442;&#25968;&#21270;&#25551;&#36848;&#19979;&#12290;&#22312;&#20840;&#23616;&#23618;&#38754;&#19978;&#65288;&#36890;&#24120;&#19982;&#20294;&#19981;&#19968;&#23450;&#38480;&#20110;&#35821;&#35843;&#30701;&#35821;&#30456;&#20851;&#65289;&#65292;&#39118;&#26684;&#21270;&#29992;&#20110;&#20197;&#26102;&#38388;&#21464;&#21270;&#30340;F0&#27700;&#24179;&#21644;&#33539;&#22260;&#26469;&#34920;&#31034;&#38899;&#35843;&#12290;&#22312;&#23616;&#37096;&#23618;&#38754;&#19978;&#65288;&#20363;&#22914;&#65292;&#37325;&#38899;&#32452;&#65289;&#65292;&#25551;&#36848;&#23616;&#37096;&#36718;&#24275;&#24418;&#29366;&#12290;&#36890;&#36807;&#36825;&#31181;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#20960;&#20010;&#19982;&#38901;&#24459;&#36793;&#30028;&#21644;&#31361;&#20986;&#24615;&#30456;&#20851;&#30340;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#31995;&#25968;&#32858;&#31867;&#65292;&#21487;&#20197;&#20197;&#33258;&#19979;&#32780;&#19978;&#30340;&#26041;&#24335;&#33719;&#24471;&#38901;&#24459;&#36718;&#24275;&#31867;&#21035;&#12290;&#38500;&#20102;&#22522;&#20110;&#39118;&#26684;&#21270;&#30340;&#29305;&#24449;&#25552;&#21462;&#22806;&#65292;&#36824;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#30340;F0&#21644;&#33021;&#37327;&#27979;&#37327;&#65288;&#20363;&#22914;&#65292;&#24179;&#22343;&#20540;&#21644;&#26041;&#24046;&#65289;&#20197;&#21450;&#38901;&#24459;&#26041;&#38754;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
The purposes of the CoPaSul toolkit are (1) automatic prosodic annotation and (2) prosodic feature extraction from syllable to utterance level. CoPaSul stands for contour-based, parametric, superpositional intonation stylization. In this framework intonation is represented as a superposition of global and local contours that are described parametrically in terms of polynomial coefficients. On the global level (usually associated but not necessarily restricted to intonation phrases) the stylization serves to represent register in terms of time-varying F0 level and range. On the local level (e.g. accent groups), local contour shapes are described. From this parameterization several features related to prosodic boundaries and prominence can be derived. Furthermore, by coefficient clustering prosodic contour classes can be obtained in a bottom-up way. Next to the stylization-based feature extraction also standard F0 and energy measures (e.g. mean and variance) as well as rhythmic aspects c
&lt;/p&gt;</description></item></channel></rss>