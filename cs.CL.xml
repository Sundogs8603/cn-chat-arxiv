<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20351;&#29992;&#20154;&#35774;&#26469;&#24314;&#27169;&#30495;&#23454;&#24615;&#30340;&#21487;&#33021;&#24615;&#12290;&#36890;&#36807;&#24314;&#27169;&#30495;&#23454;&#20154;&#35774;&#65292;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#23558;&#30495;&#23454;&#24615;&#25512;&#24191;&#21040;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#29305;&#24449;&#21028;&#26029;&#20010;&#20307;&#20135;&#29983;&#25991;&#26412;&#30340;&#30495;&#23454;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.18168</link><description>&lt;p&gt;
&#20351;&#29992;&#20154;&#35774;&#26469;&#24314;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#30495;&#23454;&#24615;
&lt;/p&gt;
&lt;p&gt;
Personas as a Way to Model Truthfulness in Language Models. (arXiv:2310.18168v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20351;&#29992;&#20154;&#35774;&#26469;&#24314;&#27169;&#30495;&#23454;&#24615;&#30340;&#21487;&#33021;&#24615;&#12290;&#36890;&#36807;&#24314;&#27169;&#30495;&#23454;&#20154;&#35774;&#65292;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#23558;&#30495;&#23454;&#24615;&#25512;&#24191;&#21040;&#19981;&#21516;&#19978;&#19979;&#25991;&#20013;&#65292;&#24182;&#36890;&#36807;&#30456;&#20851;&#29305;&#24449;&#21028;&#26029;&#20010;&#20307;&#20135;&#29983;&#25991;&#26412;&#30340;&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20351;&#29992;&#20114;&#32852;&#32593;&#19978;&#30340;&#22823;&#37327;&#25991;&#26412;&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#20123;&#25991;&#26412;&#20013;&#26082;&#21253;&#21547;&#20102;&#20107;&#23454;&#65292;&#20063;&#21253;&#21547;&#20102;&#35823;&#23548;&#24615;&#30340;&#20449;&#24687;&#12290;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#20174;&#36825;&#20123;&#30456;&#20114;&#30683;&#30462;&#30340;&#25968;&#25454;&#20013;&#36776;&#21035;&#30495;&#23454;&#19982;&#34394;&#20551;&#21527;&#65311;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#24314;&#27169;&#19981;&#21516;&#20135;&#29983;&#25991;&#26412;&#30340;&#20010;&#20307;&#36825;&#19968;&#35266;&#28857;&#65292;&#25105;&#20204;&#20551;&#35774;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#24314;&#27169;&#30495;&#23454;&#20154;&#35774;&#26469;&#32858;&#31867;&#30495;&#23454;&#25991;&#26412;&#65306;&#19968;&#32676;&#24456;&#21487;&#33021;&#20135;&#29983;&#30495;&#23454;&#25991;&#26412;&#24182;&#20855;&#26377;&#30456;&#20284;&#29305;&#24449;&#30340;&#20010;&#20307;&#12290;&#20363;&#22914;&#65292;&#21487;&#20449;&#28304;&#22914;&#32500;&#22522;&#30334;&#31185;&#21644;&#31185;&#23398;&#26399;&#21002;&#36890;&#24120;&#20351;&#29992;&#27491;&#24335;&#30340;&#20889;&#20316;&#39118;&#26684;&#24182;&#25552;&#20986;&#19968;&#33268;&#30340;&#20027;&#24352;&#12290;&#36890;&#36807;&#24314;&#27169;&#36825;&#19968;&#20154;&#35774;&#65292;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#23558;&#30495;&#23454;&#24615;&#25512;&#24191;&#21040;&#27599;&#20010;&#20010;&#20307;&#29983;&#25104;&#35757;&#32451;&#25991;&#26412;&#30340;&#29305;&#23450;&#19978;&#19979;&#25991;&#20043;&#22806;&#12290;&#20363;&#22914;&#65292;&#27169;&#22411;&#21487;&#20197;&#25512;&#26029;&#20986;&#8220;&#32500;&#22522;&#30334;&#31185;&#8221;&#36825;&#20010;&#20010;&#20307;&#22312;&#8220;&#31185;&#23398;&#8221;&#29983;&#25104;&#30340;&#20027;&#39064;&#19978;&#20250;&#34920;&#29616;&#20986;&#30495;&#23454;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#20849;&#20139;&#19968;&#20010;&#20154;&#35774;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#20004;&#20010;&#35266;&#23519;&#32467;&#26524;&#20026;&#20154;&#35774;&#20551;&#35774;&#25552;&#20379;&#20102;&#35777;&#25454;&#65306;&#65288;1&#65289;&#25105;&#20204;&#21487;&#20197;&#25506;&#27979;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#21028;&#26029;&#30495;&#23454;&#24615;&#30340;&#33021;&#21147;&#65307;&#65288;2&#65289;&#27169;&#22411;&#21487;&#20197;&#20174;&#30456;&#20851;&#29305;&#24449;&#20013;&#25512;&#27979;&#20010;&#20307;&#20135;&#29983;&#25991;&#26412;&#30340;&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are trained on vast amounts of text from the internet, which contains both factual and misleading information about the world. Can language models discern truth from falsehood in this contradicting data? Expanding on the view that LLMs can model different agents producing the corpora, we hypothesize that they can cluster truthful text by modeling a truthful persona: a group of agents that are likely to produce truthful text and share similar features. For example, trustworthy sources like Wikipedia and Science usually use formal writing styles and make consistent claims. By modeling this persona, LLMs can generalize truthfulness beyond the specific contexts in which each agent generated the training text. For example, the model can infer that the agent "Wikipedia" will behave truthfully on topics that were only generated by "Science" because they share a persona. We first show evidence for the persona hypothesis via two observations: (1) we can probe whether a mod
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#25968;&#20540;&#25512;&#29702;&#30340;&#22823;&#35268;&#27169;KBQA&#25968;&#25454;&#38598;MarkQA&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;NR-KBQA&#65292;&#35813;&#20219;&#21153;&#35201;&#27714;&#36827;&#34892;&#22810;&#36339;&#25512;&#29702;&#21644;&#25968;&#20540;&#25512;&#29702;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;KBQA&#20013;&#30340;&#22797;&#26434;&#25968;&#20540;&#25512;&#29702;&#38754;&#20020;&#24040;&#22823;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.15517</link><description>&lt;p&gt;
MarkQA: &#19968;&#20010;&#21253;&#21547;&#25968;&#20540;&#25512;&#29702;&#30340;&#22823;&#35268;&#27169;KBQA&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
MarkQA: A large scale KBQA dataset with numerical reasoning. (arXiv:2310.15517v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15517
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#25968;&#20540;&#25512;&#29702;&#30340;&#22823;&#35268;&#27169;KBQA&#25968;&#25454;&#38598;MarkQA&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;NR-KBQA&#65292;&#35813;&#20219;&#21153;&#35201;&#27714;&#36827;&#34892;&#22810;&#36339;&#25512;&#29702;&#21644;&#25968;&#20540;&#25512;&#29702;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;KBQA&#20013;&#30340;&#22797;&#26434;&#25968;&#20540;&#25512;&#29702;&#38754;&#20020;&#24040;&#22823;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#30693;&#35782;&#24211;&#38382;&#31572;&#65288;KBQA&#65289;&#22312;&#35299;&#20915;&#20107;&#23454;&#22411;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#26159;&#28041;&#21450;&#25968;&#20540;&#25512;&#29702;&#30340;KBQA&#30456;&#23545;&#36739;&#23569;&#30740;&#31350;&#12290;&#26412;&#25991;&#38024;&#23545;KBQA&#20013;&#22797;&#26434;&#30340;&#25968;&#20540;&#25512;&#29702;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20219;&#21153;&#65292;NR-KBQA&#65292;&#23427;&#38656;&#35201;&#36827;&#34892;&#22810;&#36339;&#25512;&#29702;&#21644;&#25968;&#20540;&#25512;&#29702;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#20197;Python&#26684;&#24335;&#30340;&#36923;&#36753;&#24418;&#24335;PyQL&#26469;&#34920;&#31034;&#25968;&#20540;&#25512;&#29702;&#38382;&#39064;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20026;&#20102;&#20415;&#20110;NR-KBQA&#30340;&#24320;&#21457;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#21517;&#20026;MarkQA&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#20174;&#19968;&#23567;&#32452;&#31181;&#23376;&#33258;&#21160;&#26500;&#24314;&#30340;&#12290;MarkQA&#20013;&#30340;&#27599;&#20010;&#38382;&#39064;&#37117;&#37197;&#22791;&#20102;&#19982;&#20043;&#23545;&#24212;&#30340;SPARQL&#26597;&#35810;&#65292;&#20197;&#21450;&#20197;QDMR&#26684;&#24335;&#21644;PyQL&#31243;&#24207;&#34920;&#31034;&#30340;&#36880;&#27493;&#25512;&#29702;&#36807;&#31243;&#12290;&#19968;&#20123;&#26368;&#20808;&#36827;&#30340;QA&#26041;&#27861;&#22312;MarkQA&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;KBQA&#20013;&#30340;&#22797;&#26434;&#25968;&#20540;&#25512;&#29702;&#38754;&#20020;&#30528;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
While question answering over knowledge bases (KBQA) has shown progress in addressing factoid questions, KBQA with numerical reasoning remains relatively unexplored. In this paper, we focus on the complex numerical reasoning in KBQA and propose a new task, NR-KBQA, which necessitates the ability to perform both multi-hop reasoning and numerical reasoning. We design a logic form in Python format called PyQL to represent the reasoning process of numerical reasoning questions. To facilitate the development of NR-KBQA, we present a large dataset called MarkQA, which is automatically constructed from a small set of seeds. Each question in MarkQA is equipped with its corresponding SPARQL query, alongside the step-by-step reasoning process in the QDMR format and PyQL program. Experimental results of some state-of-the-art QA methods on the MarkQA show that complex numerical reasoning in KBQA faces great challenges.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38646;&#26679;&#26412;&#24544;&#23454;&#24615;&#35780;&#20272;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;FFLM&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;FFLM&#22312;&#19981;&#19968;&#33268;&#24615;&#26816;&#27979;&#21644;&#24544;&#23454;&#24615;&#35780;&#32423;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#24182;&#19988;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569;&#20102;24&#20493;&#12290;</title><link>http://arxiv.org/abs/2310.11648</link><description>&lt;p&gt;
&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38646;&#26679;&#26412;&#24544;&#23454;&#24615;&#35780;&#20272;&#30340;&#25991;&#26412;&#25688;&#35201;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model. (arXiv:2310.11648v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11648
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38646;&#26679;&#26412;&#24544;&#23454;&#24615;&#35780;&#20272;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;FFLM&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;FFLM&#22312;&#19981;&#19968;&#33268;&#24615;&#26816;&#27979;&#21644;&#24544;&#23454;&#24615;&#35780;&#32423;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#65292;&#24182;&#19988;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569;&#20102;24&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#27493;&#65292;&#20294;&#25688;&#35201;&#27169;&#22411;&#20173;&#28982;&#23384;&#22312;&#24544;&#23454;&#24615;&#38382;&#39064;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#35201;&#20040;&#20351;&#29992;&#22312;&#20854;&#20182;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#25110;&#39046;&#22495;&#20869;&#30340;&#21512;&#25104;&#25968;&#25454;&#26469;&#35780;&#20272;&#24544;&#23454;&#24615;&#65292;&#35201;&#20040;&#20351;&#29992;&#31867;&#20284;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#19968;&#20010;&#20013;&#31561;&#22823;&#23567;&#30340;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38646;&#26679;&#26412;&#24544;&#23454;&#24615;&#35780;&#20272;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;FFLM&#65292;&#23427;&#26159;&#22522;&#20110;&#27010;&#29575;&#21464;&#21270;&#30340;&#32452;&#21512;&#65292;&#36825;&#31181;&#32452;&#21512;&#26159;&#22522;&#20110;&#19968;&#20010;&#35266;&#28857;&#65306;&#22312;&#36755;&#20986;&#30340;&#25991;&#26412;&#21069;&#21152;&#19978;&#19982;&#36755;&#20986;&#19968;&#33268;&#30340;&#19968;&#27573;&#25991;&#26412;&#23558;&#22686;&#21152;&#39044;&#27979;&#36755;&#20986;&#30340;&#27010;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;FFLM&#22312;&#19981;&#19968;&#33268;&#24615;&#26816;&#27979;&#21644;&#24544;&#23454;&#24615;&#35780;&#32423;&#19978;&#19982;ChatGPT&#30456;&#27604;&#34920;&#29616;&#20986;&#33394;&#65292;&#19988;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569;24&#20493;&#12290;FFLM&#36824;&#22312;&#20854;&#20182;&#24378;&#22522;&#20934;&#19978;&#21462;&#24471;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite tremendous improvements in natural language generation, summarization models still suffer from the unfaithfulness issue. Previous work evaluates faithfulness either using models trained on the other tasks or in-domain synthetic data, or prompting a large model such as ChatGPT. This paper proposes to do zero-shot faithfulness evaluation simply with a moderately-sized foundation language model. We introduce a new metric FFLM, which is a combination of probability changes based on the intuition that prefixing a piece of text that is consistent with the output will increase the probability of predicting the output. Experiments show that FFLM performs competitively with or even outperforms ChatGPT on both inconsistency detection and faithfulness rating with 24x fewer parameters. FFLM also achieves improvements over other strong baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25506;&#32034;&#20102;&#26367;&#25442;&#26631;&#35782;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19979;&#28216;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#28151;&#28102;&#35821;&#26009;&#24211;&#35757;&#32451;&#30340;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.08628</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38544;&#31169;&#20445;&#25252;&#25513;&#30721;&#30340;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08628
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25506;&#32034;&#20102;&#26367;&#25442;&#26631;&#35782;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19979;&#28216;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#28151;&#28102;&#35821;&#26009;&#24211;&#35757;&#32451;&#30340;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#36866;&#24212;&#23545;&#20110;&#22788;&#29702;&#20195;&#29702;&#35757;&#32451;&#25968;&#25454;&#21644;&#23454;&#38469;&#29992;&#25143;&#25968;&#25454;&#20043;&#38388;&#30340;&#24046;&#24322;&#38750;&#24120;&#37325;&#35201;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#36827;&#34892;&#36866;&#24212;&#65292;&#29992;&#25143;&#30340;&#25991;&#26412;&#25968;&#25454;&#36890;&#24120;&#23384;&#20648;&#22312;&#26381;&#21153;&#22120;&#25110;&#26412;&#22320;&#35774;&#22791;&#19978;&#65292;&#19979;&#28216;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#36825;&#20123;&#39046;&#22495;&#20869;&#30340;&#25968;&#25454;&#36827;&#34892;&#30452;&#25509;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#36825;&#21487;&#33021;&#20250;&#24341;&#36215;&#38544;&#31169;&#21644;&#23433;&#20840;&#38382;&#39064;&#65292;&#22240;&#20026;&#23384;&#22312;&#21521;&#23545;&#25163;&#27844;&#38706;&#29992;&#25143;&#20449;&#24687;&#30340;&#39069;&#22806;&#39118;&#38505;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#24320;&#22987;&#25506;&#32034;&#20351;&#29992;&#36890;&#29992;&#26631;&#35760;&#26367;&#25442;&#25991;&#26412;&#20013;&#30340;&#26631;&#35782;&#20449;&#24687;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#24314;&#35758;&#26367;&#25442;&#25513;&#30721;&#26631;&#35760;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19979;&#28216;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#19978;&#35780;&#20272;&#20854;&#25928;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#31181;&#22522;&#20110;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#30340;LLM&#26041;&#27861;&#65292;&#24182;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#20197;&#27604;&#36739;&#36825;&#20123;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#28151;&#28102;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#33021;&#22815;&#36798;&#21040;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model adaptation is crucial to handle the discrepancy between proxy training data and actual users data received. To effectively perform adaptation, textual data of users is typically stored on servers or their local devices, where downstream natural language processing (NLP) models can be directly trained using such in-domain data. However, this might raise privacy and security concerns due to the extra risks of exposing user information to adversaries. Replacing identifying information in textual data with a generic marker has been recently explored. In this work, we leverage large language models (LLMs) to suggest substitutes of masked tokens and have their effectiveness evaluated on downstream language modeling tasks. Specifically, we propose multiple pre-trained and fine-tuned LLM-based approaches and perform empirical studies on various datasets for the comparison of these methods. Experimental results show that models trained on the obfuscation corpora are able to achieve compar
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#30340;&#38170;&#23450;&#23398;&#20064;&#26041;&#27861;&#65292;&#21363;CIFAL&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#38170;&#23450;&#23398;&#20064;&#20174;&#19981;&#21516;&#24341;&#25991;&#26679;&#24335;&#30340;&#25968;&#25454;&#20013;&#25429;&#25417;&#24341;&#25991;&#27169;&#24335;&#65292;&#25552;&#39640;&#20102;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#24615;&#33021;&#65292;&#21462;&#24471;&#20102;2.83%&#30340;&#23383;&#27573;&#32423;F1&#20998;&#25968;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2309.03559</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#30340;&#38170;&#23450;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Anchor Learning Approach for Citation Field Learning. (arXiv:2309.03559v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03559
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#30340;&#38170;&#23450;&#23398;&#20064;&#26041;&#27861;&#65292;&#21363;CIFAL&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#38170;&#23450;&#23398;&#20064;&#20174;&#19981;&#21516;&#24341;&#25991;&#26679;&#24335;&#30340;&#25968;&#25454;&#20013;&#25429;&#25417;&#24341;&#25991;&#27169;&#24335;&#65292;&#25552;&#39640;&#20102;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#24615;&#33021;&#65292;&#21462;&#24471;&#20102;2.83%&#30340;&#23383;&#27573;&#32423;F1&#20998;&#25968;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#26159;&#23558;&#24341;&#25991;&#23383;&#31526;&#20018;&#20998;&#21106;&#20026;&#24863;&#20852;&#36259;&#30340;&#23383;&#27573;&#65292;&#22914;&#20316;&#32773;&#12289;&#26631;&#39064;&#21644;&#22330;&#25152;&#12290;&#20174;&#24341;&#25991;&#20013;&#25552;&#21462;&#36825;&#20123;&#23383;&#27573;&#23545;&#20110;&#24341;&#25991;&#32034;&#24341;&#12289;&#30740;&#31350;&#32773;&#20010;&#20154;&#36164;&#26009;&#20998;&#26512;&#31561;&#38750;&#24120;&#37325;&#35201;&#12290;&#29992;&#25143;&#29983;&#25104;&#30340;&#36164;&#28304;&#65292;&#22914;&#23398;&#26415;&#20027;&#39029;&#21644;&#20010;&#20154;&#31616;&#21382;&#65292;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#24341;&#25991;&#23383;&#27573;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#24341;&#25991;&#26679;&#24335;&#19981;&#19968;&#33268;&#12289;&#21477;&#27861;&#19981;&#23436;&#25972;&#21644;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#65292;&#20174;&#36825;&#20123;&#36164;&#28304;&#20013;&#25552;&#21462;&#23383;&#27573;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;CIFAL&#65288;&#36890;&#36807;&#38170;&#23450;&#23398;&#20064;&#36827;&#34892;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#65289;&#65292;&#20197;&#25552;&#39640;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#24615;&#33021;&#12290;CIFAL&#21033;&#29992;&#38170;&#23450;&#23398;&#20064;&#65292;&#23427;&#23545;&#20110;&#20219;&#20309;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#37117;&#26159;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#65292;&#24110;&#21161;&#25429;&#25417;&#19981;&#21516;&#24341;&#25991;&#26679;&#24335;&#30340;&#24341;&#25991;&#27169;&#24335;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;CIFAL&#22312;&#24341;&#25991;&#23383;&#27573;&#23398;&#20064;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#22312;&#23383;&#27573;&#32423;F1&#20998;&#25968;&#19978;&#21462;&#24471;&#20102;2.83%&#30340;&#25552;&#21319;&#12290;&#22823;&#37327;&#30340;
&lt;/p&gt;
&lt;p&gt;
Citation field learning is to segment a citation string into fields of interest such as author, title, and venue. Extracting such fields from citations is crucial for citation indexing, researcher profile analysis, etc. User-generated resources like academic homepages and Curriculum Vitae, provide rich citation field information. However, extracting fields from these resources is challenging due to inconsistent citation styles, incomplete sentence syntax, and insufficient training data. To address these challenges, we propose a novel algorithm, CIFAL (citation field learning by anchor learning), to boost the citation field learning performance. CIFAL leverages the anchor learning, which is model-agnostic for any Pre-trained Language Model, to help capture citation patterns from the data of different citation styles. The experiments demonstrate that CIFAL outperforms state-of-the-art methods in citation field learning, achieving a 2.83% improvement in field-level F1-scores. Extensive an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;ZYN&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#26159;&#38750;&#38382;&#39064;&#20316;&#20026;&#22870;&#21169;&#27169;&#22411;&#30340;&#25552;&#31034;&#65292;&#20197;&#21450;&#22686;&#24378;&#23398;&#20064;&#26469;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#65292;&#20351;&#20854;&#29983;&#25104;&#30340;&#25991;&#26412;&#19982;&#20154;&#31867;&#25805;&#20316;&#32773;&#30340;&#20559;&#22909;&#23545;&#40784;&#12290;&#23454;&#39564;&#35777;&#25454;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#65292;&#21253;&#25324;&#35299;&#27602;&#12289;&#24773;&#24863;&#20248;&#21270;&#21644;&#20010;&#24615;&#21270;&#25552;&#31034;&#29983;&#25104;&#22120;&#31561;&#12290;</title><link>http://arxiv.org/abs/2308.06385</link><description>&lt;p&gt;
ZYN&#65306;&#38646;&#24335;&#22870;&#21169;&#27169;&#22411;&#19982;&#26159;&#38750;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
ZYN: Zero-Shot Reward Models with Yes-No Questions. (arXiv:2308.06385v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06385
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;ZYN&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#26159;&#38750;&#38382;&#39064;&#20316;&#20026;&#22870;&#21169;&#27169;&#22411;&#30340;&#25552;&#31034;&#65292;&#20197;&#21450;&#22686;&#24378;&#23398;&#20064;&#26469;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#65292;&#20351;&#20854;&#29983;&#25104;&#30340;&#25991;&#26412;&#19982;&#20154;&#31867;&#25805;&#20316;&#32773;&#30340;&#20559;&#22909;&#23545;&#40784;&#12290;&#23454;&#39564;&#35777;&#25454;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#65292;&#21253;&#25324;&#35299;&#27602;&#12289;&#24773;&#24863;&#20248;&#21270;&#21644;&#20010;&#24615;&#21270;&#25552;&#31034;&#29983;&#25104;&#22120;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#23558;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#29983;&#25104;&#23450;&#21521;&#20110;&#26399;&#26395;&#34892;&#20026;&#30340;&#38382;&#39064;&#65292;&#23558;&#29983;&#25104;&#30340;&#25991;&#26412;&#19982;&#20154;&#31867;&#25805;&#20316;&#32773;&#30340;&#20559;&#22909;&#23545;&#40784;&#12290;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#21478;&#19968;&#20010;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#25209;&#35780;&#32773;&#65292;&#36890;&#36807;&#19968;&#20010;&#34920;&#31034;&#29992;&#25143;&#20559;&#22909;&#30340;&#26159;&#38750;&#38382;&#39064;&#30340;&#25552;&#31034;&#65292;&#20197;&#38646;&#24335;&#26041;&#24335;&#20316;&#20026;&#22870;&#21169;&#27169;&#22411;&#65292;&#32780;&#19981;&#38656;&#35201;&#36827;&#19968;&#27493;&#26631;&#35760;&#25968;&#25454;&#12290;&#36825;&#31181;&#38646;&#24335;&#22870;&#21169;&#27169;&#22411;&#20026;&#36827;&#19968;&#27493;&#24494;&#35843;&#22522;&#26412;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#20102;&#23398;&#20064;&#20449;&#21495;&#65292;&#20351;&#29992;&#22686;&#24378;&#23398;&#20064;&#65292;&#23601;&#20687;&#22312;RLAIF&#20013;&#19968;&#26679;&#65307;&#28982;&#32780;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20854;&#20182;&#19978;&#19979;&#25991;&#20013;&#20063;&#26159;&#20860;&#23481;&#30340;&#65292;&#20363;&#22914;&#36136;&#37327;&#22810;&#26679;&#24615;&#25628;&#32034;&#12290;&#36890;&#36807;&#22312;&#19982;&#25991;&#26412;&#29983;&#25104;&#30456;&#20851;&#30340;&#19981;&#21516;&#39046;&#22495;&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;&#35299;&#27602;&#12289;&#20248;&#21270;&#30005;&#24433;&#35780;&#35770;&#30340;&#24773;&#24863;&#25110;&#20219;&#20309;&#20854;&#20182;&#23646;&#24615;&#12289;&#24341;&#23548;&#27169;&#22411;&#21487;&#33021;&#20855;&#26377;&#30340;&#20851;&#20110;&#29305;&#23450;&#20027;&#39064;&#30340;&#35266;&#28857;&#65292;&#20197;&#21450;&#20010;&#24615;&#21270;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#20219;&#21153;&#30340;&#25552;&#31034;&#29983;&#25104;&#22120;&#65292;&#25552;&#20379;&#20102;&#23545;&#25152;&#25552;&#20986;&#30340;ZYN&#26694;&#26550;&#33021;&#21147;&#30340;&#22823;&#37327;&#35777;&#25454;&#12290;&#20195;&#30721;&#23558;&#22312;\url&#22788;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we address the problem of directing the text generations of a LLM towards a desired behavior, aligning the generated text with the preferences of the human operator. We propose using another language model as a critic, reward model in a zero-shot way thanks to the prompt of a Yes-No question that represents the user preferences, without requiring further labeled data. This zero-shot reward model provides the learning signal to further fine-tune the base LLM using reinforcement learning, as in RLAIF; yet our approach is also compatible in other contexts such as quality-diversity search. Extensive evidence of the capabilities of the proposed ZYN framework is provided through experiments in different domains related to text generation, including detoxification; optimizing sentiment of movie reviews, or any other attribute; steering the opinion about a particular topic the model may have; and personalizing prompt generators for text-to-image tasks. Code to be released at \url
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#35758;&#23558;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;&#37325;&#26500;&#20026;&#30001;&#20363;&#23376;&#24341;&#23548;&#30340;&#31890;&#24230;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#65292;&#20197;&#26368;&#23567;&#21270;&#26381;&#21153;&#20043;&#38388;&#30340;&#20219;&#21153;&#36716;&#31227;&#65292;&#33719;&#24471;&#25345;&#32493;&#30340;&#23398;&#20064;&#25928;&#30410;&#12290;&#36890;&#36807;&#32467;&#21512;&#31616;&#21333;&#30340;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#65292;&#21487;&#20197;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.13721</link><description>&lt;p&gt;
&#22522;&#20110;&#31034;&#20363;&#24341;&#23548;&#38382;&#31572;&#30340;&#25345;&#32493;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;
&lt;/p&gt;
&lt;p&gt;
Continual Dialogue State Tracking via Example-Guided Question Answering. (arXiv:2305.13721v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#35758;&#23558;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;&#37325;&#26500;&#20026;&#30001;&#20363;&#23376;&#24341;&#23548;&#30340;&#31890;&#24230;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#65292;&#20197;&#26368;&#23567;&#21270;&#26381;&#21153;&#20043;&#38388;&#30340;&#20219;&#21153;&#36716;&#31227;&#65292;&#33719;&#24471;&#25345;&#32493;&#30340;&#23398;&#20064;&#25928;&#30410;&#12290;&#36890;&#36807;&#32467;&#21512;&#31616;&#21333;&#30340;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#65292;&#21487;&#20197;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35805;&#31995;&#32479;&#38656;&#35201;&#19981;&#26029;&#26356;&#26032;&#20197;&#36866;&#24212;&#26032;&#26381;&#21153;&#65292;&#20294;&#26159;&#31616;&#21333;&#22320;&#20351;&#29992;&#26032;&#26381;&#21153;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#20250;&#38477;&#20302;&#20808;&#21069;&#23398;&#20064;&#30340;&#26381;&#21153;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#21457;&#29616;&#65292;&#23545;&#35805;&#29366;&#24577;&#36319;&#36394;(DST)&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#20854;&#37325;&#26500;&#20026;&#19968;&#32452;&#30001;&#20363;&#23376;&#24341;&#23548;&#30340;&#31890;&#24230;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#65292;&#20197;&#26368;&#23567;&#21270;&#26381;&#21153;&#20043;&#38388;&#30340;&#20219;&#21153;&#36716;&#31227;&#65292;&#20174;&#32780;&#33719;&#24471;&#25345;&#32493;&#30340;&#23398;&#20064;&#25928;&#30410;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20943;&#36731;&#29305;&#23450;&#26381;&#21153;&#30340;&#35760;&#24518;&#36127;&#25285;&#65292;&#24182;&#25945;&#20250;&#27169;&#22411;&#23558;&#25152;&#32473;&#38382;&#39064;&#21644;&#31034;&#20363;&#29992;&#20110;&#20174;&#23545;&#35805;&#20013;&#25552;&#21462;&#24517;&#35201;&#20449;&#24687;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#19968;&#20010;&#21482;&#26377;6000&#19975;&#20010;&#21442;&#25968;&#30340;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#20174;&#26816;&#32034;&#22120;&#33719;&#21462;&#30340;&#19978;&#19979;&#25991;&#31034;&#20363;&#33719;&#24471;&#24040;&#22823;&#30340;&#25552;&#21319;&#12290;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#31616;&#21333;&#30340;&#25345;&#32493;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dialogue systems are frequently updated to accommodate new services, but naively updating them by continually training with data for new services in diminishing performance on previously learnt services. Motivated by the insight that dialogue state tracking (DST), a crucial component of dialogue systems that estimates the user's goal as a conversation proceeds, is a simple natural language understanding task, we propose reformulating it as a bundle of granular example-guided question answering tasks to minimize the task shift between services and thus benefit continual learning. Our approach alleviates service-specific memorization and teaches a model to contextualize the given question and example to extract the necessary information from the conversation. We find that a model with just 60M parameters can achieve a significant boost by learning to learn from in-context examples retrieved by a retriever trained to identify turns with similar dialogue state changes. Combining our method
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25581;&#31034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#35821;&#26469;&#26377;&#25928;&#35268;&#36991;&#29616;&#26377;&#30340;&#25991;&#26412;&#26816;&#27979;&#31995;&#32479;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26816;&#27979;&#22120;&#30340;&#33030;&#24369;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.10847</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#34987;&#24341;&#23548;&#26469;&#35268;&#36991;AI&#29983;&#25104;&#30340;&#25991;&#26412;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10847
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#35821;&#26469;&#26377;&#25928;&#35268;&#36991;&#29616;&#26377;&#30340;&#25991;&#26412;&#26816;&#27979;&#31995;&#32479;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26816;&#27979;&#22120;&#30340;&#33030;&#24369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21253;&#25324;&#35770;&#25991;&#20889;&#20316;&#21644;&#38382;&#31572;&#31561;&#22810;&#20010;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#20986;&#33394;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;&#24517;&#39035;&#35299;&#20915;&#36825;&#20123;&#27169;&#22411;&#28508;&#22312;&#30340;&#35823;&#29992;&#38382;&#39064;&#65292;&#21542;&#21017;&#21487;&#33021;&#23548;&#33268;&#25220;&#34989;&#21644;&#22403;&#22334;&#20449;&#24687;&#31561;&#19981;&#33391;&#21518;&#26524;&#12290;&#26412;&#30740;&#31350;&#25581;&#31034;&#65292;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#35821;&#65292;LLMs&#21487;&#20197;&#26377;&#25928;&#22320;&#35268;&#36991;&#26816;&#27979;&#31995;&#32479;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26367;&#25442;&#30340;&#19978;&#19979;&#25991;&#31034;&#20363;&#20248;&#21270;&#26041;&#27861;&#65288;SICO&#65289;&#65292;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#36825;&#31181;&#25552;&#31034;&#35821;&#12290;&#22312;&#19977;&#20010;&#29616;&#23454;&#20219;&#21153;&#20013;&#65292;LLMs&#21487;&#33021;&#34987;&#35823;&#29992;&#65292;&#22312;SICO&#30340;&#24110;&#21161;&#19979;&#65292;ChatGPT&#25104;&#21151;&#22320;&#35268;&#36991;&#20102;&#20845;&#39033;&#29616;&#26377;&#30340;&#26816;&#27979;&#22120;&#65292;&#24179;&#22343;&#23548;&#33268;0.54&#30340;AUC&#19979;&#38477;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#26816;&#27979;&#22120;&#30340;&#34920;&#29616;&#29978;&#33267;&#27604;&#38543;&#26426;&#20998;&#31867;&#22120;&#36824;&#35201;&#24046;&#12290;&#36825;&#20123;&#32467;&#26524;&#22362;&#23450;&#22320;&#25581;&#31034;&#20102;&#29616;&#26377;&#26816;&#27979;&#22120;&#30340;&#33030;&#24369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated exceptional performance in a variety of tasks, including essay writing and question answering. However, it is crucial to address the potential misuse of these models, which can lead to detrimental outcomes such as plagiarism and spamming. Recently, several detectors have been proposed, including fine-tuned classifiers and various statistical methods. In this study, we reveal that with the aid of carefully crafted prompts, LLMs can effectively evade these detection systems. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically generate such prompts. On three real-world tasks where LLMs can be misused, SICO successfully enables ChatGPT to evade six existing detectors, causing a significant 0.54 AUC drop on average. Surprisingly, in most cases these detectors perform even worse than random classifiers. These results firmly reveal the vulnerability of existing detectors. Finally, the strong perfor
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07235</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#35299;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21333;&#23618;Transformer&#23545;&#24191;&#20041;Potts&#27169;&#22411;&#36827;&#34892;&#26368;&#20248;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Optimal inference of a generalised Potts model by single-layer transformers with factored attention. (arXiv:2304.07235v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07235
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer &#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#34507;&#30333;&#36136;&#31185;&#23398;&#26041;&#38754;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#12290;&#23427;&#20204;&#30340;&#20851;&#38190;&#26500;&#24314;&#22359;&#26159;&#19968;&#20010;&#21483;&#20570;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26426;&#21046;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;&#39044;&#27979;&#21477;&#23376;&#20013;&#32570;&#22833;&#30340;&#35789;&#12290;&#23613;&#31649;Transformer&#22312;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#65292;&#20294;&#26159;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#31350;&#31455;&#20174;&#25968;&#25454;&#20013;&#23398;&#21040;&#20102;&#20160;&#20040;&#20197;&#21450;&#23427;&#26159;&#24590;&#20040;&#20570;&#21040;&#30340;&#36824;&#19981;&#26159;&#24456;&#28165;&#26970;&#12290;&#26412;&#25991;&#38024;&#23545;&#20174;&#20855;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#20301;&#32622;&#21644; Potts &#39068;&#33394;&#20013;&#25552;&#21462;&#30340;&#25968;&#25454;&#22312;&#35757;&#32451;&#30340;Transformer&#19978;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#21644;&#25968;&#20540;&#21051;&#30011;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#34429;&#28982;&#19968;&#33324;&#30340;transformer&#38656;&#35201;&#22810;&#23618;&#23398;&#20064;&#25165;&#33021;&#20934;&#30830;&#23398;&#20064;&#36825;&#20010;&#20998;&#24067;&#65292;&#20294;&#26159;&#32463;&#36807;&#23567;&#25913;&#36827;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#26080;&#38480;&#37319;&#26679;&#30340;&#26497;&#38480;&#19979;&#21487;&#20197;&#23436;&#32654;&#22320;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#35745;&#31639;&#20102;&#36825;&#20010;&#20462;&#25913;&#21518;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#25152;&#35859;&#8220;&#20998;&#35299;&#8221;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#25968;&#20540;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#37322;Transformer&#30340;&#20869;&#22312;&#24037;&#20316;&#21407;&#29702;&#20197;&#21450;&#25552;&#39640;&#20854;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers are the type of neural networks that has revolutionised natural language processing and protein science. Their key building block is a mechanism called self-attention which is trained to predict missing words in sentences. Despite the practical success of transformers in applications it remains unclear what self-attention learns from data, and how. Here, we give a precise analytical and numerical characterisation of transformers trained on data drawn from a generalised Potts model with interactions between sites and Potts colours. While an off-the-shelf transformer requires several layers to learn this distribution, we show analytically that a single layer of self-attention with a small modification can learn the Potts model exactly in the limit of infinite sampling. We show that this modified self-attention, that we call ``factored'', has the same functional form as the conditional probability of a Potts spin given the other spins, compute its generalisation error using t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Prophet&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#31572;&#26696;&#21551;&#21457;&#24335;&#26041;&#24335;&#20419;&#20351;GPT-3&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;&#12290;&#22312;&#29305;&#23450;&#30340;&#30693;&#35782;&#22411;VQA&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#19968;&#20010;&#32431;VQA&#27169;&#22411;&#65292;&#24182;&#20174;&#20013;&#25552;&#21462;&#20986;&#31572;&#26696;&#21551;&#21457;&#24335;&#65292;&#21487;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.01903</link><description>&lt;p&gt;
&#29992;&#31572;&#26696;&#21551;&#21457;&#24335;&#26041;&#24335;&#20419;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering. (arXiv:2303.01903v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Prophet&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#31572;&#26696;&#21551;&#21457;&#24335;&#26041;&#24335;&#20419;&#20351;GPT-3&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38382;&#39064;&#12290;&#22312;&#29305;&#23450;&#30340;&#30693;&#35782;&#22411;VQA&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#19968;&#20010;&#32431;VQA&#27169;&#22411;&#65292;&#24182;&#20174;&#20013;&#25552;&#21462;&#20986;&#31572;&#26696;&#21551;&#21457;&#24335;&#65292;&#21487;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;&#38656;&#35201;&#36229;&#20986;&#22270;&#20687;&#33539;&#22260;&#30340;&#22806;&#37096;&#30693;&#35782;&#26469;&#22238;&#31572;&#38382;&#39064;&#12290;&#26089;&#26399;&#30340;&#30740;&#31350;&#20174;&#26174;&#24335;&#30693;&#35782;&#24211;&#65288;KBs&#65289;&#26816;&#32034;&#25152;&#38656;&#30340;&#30693;&#35782;&#65292;&#36825;&#32463;&#24120;&#20250;&#24341;&#20837;&#19982;&#38382;&#39064;&#26080;&#20851;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#35797;&#22270;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#21363;GPT-3&#65289;&#20316;&#20026;&#38544;&#21547;&#24335;&#30693;&#35782;&#24341;&#25806;&#26469;&#33719;&#21462;&#22238;&#31572;&#25152;&#38656;&#30340;&#24517;&#35201;&#30693;&#35782;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#21462;&#24471;&#20102;&#20196;&#20154;&#40723;&#33310;&#30340;&#32467;&#26524;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;&#23427;&#20204;&#36824;&#27809;&#26377;&#20805;&#20998;&#21457;&#25381;GPT-3&#30340;&#33021;&#21147;&#65292;&#22240;&#20026;&#25552;&#20379;&#30340;&#36755;&#20837;&#20449;&#24687;&#20173;&#28982;&#19981;&#36275;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Prophet&#8212;&#8212;&#19968;&#20010;&#27010;&#24565;&#19978;&#31616;&#21333;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#22238;&#31572;&#21551;&#21457;&#24335;&#26041;&#24335;&#65292;&#20419;&#20351;GPT-3&#35299;&#20915;&#22522;&#20110;&#30693;&#35782;&#30340;VQA&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#22312;&#29305;&#23450;&#30340;&#22522;&#20110;&#30693;&#35782;&#30340;VQA&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#19968;&#20010;&#32431;VQA&#27169;&#22411;&#65292;&#32780;&#19981;&#20351;&#29992;&#22806;&#37096;&#30693;&#35782;&#12290;&#20043;&#21518;&#65292;&#25105;&#20204;&#20174;&#27169;&#22411;&#20013;&#25552;&#21462;&#20102;&#20004;&#31181;&#20114;&#34917;&#30340;&#31572;&#26696;&#21551;&#21457;&#24335;&#65306;&#31572;&#26696;&#20505;&#36873;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge-based visual question answering (VQA) requires external knowledge beyond the image to answer the question. Early studies retrieve required knowledge from explicit knowledge bases (KBs), which often introduces irrelevant information to the question, hence restricting the performance of their models. Recent works have sought to use a large language model (i.e., GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for answering. Despite the encouraging results achieved by these methods, we argue that they have not fully activated the capacity of GPT-3 as the provided input information is insufficient. In this paper, we present Prophet -- a conceptually simple framework designed to prompt GPT-3 with answer heuristics for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge. After that, we extract two types of complementary answer heuristics from the model: answer candidates 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21452;&#25490;&#21015;&#31561;&#21464;&#24615;&#30340;KG&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#31070;&#32463;&#32593;&#32476;&#22312;KG&#20013;&#25191;&#34892;&#22797;&#26434;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#65292;&#24182;&#22312;&#22810;&#20010;&#24402;&#32435;KG&#23436;&#25104;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;Hits@10&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;&#21452;&#25490;&#21015;&#31561;&#21464;&#24615;&#22312;KG&#20013;&#24320;&#36767;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2302.01313</link><description>&lt;p&gt;
&#21452;&#25490;&#21015;&#31561;&#21464;&#24615;&#22312;&#30693;&#35782;&#22270;&#35889;&#34917;&#20840;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#21452;&#25490;&#21015;&#31561;&#21464;&#24615;&#30340;KG&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#31070;&#32463;&#32593;&#32476;&#22312;KG&#20013;&#25191;&#34892;&#22797;&#26434;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#65292;&#24182;&#22312;&#22810;&#20010;&#24402;&#32435;KG&#23436;&#25104;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;Hits@10&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;&#21452;&#25490;&#21015;&#31561;&#21464;&#24615;&#22312;KG&#20013;&#24320;&#36767;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#30693;&#35782;&#22270;&#35889;(KGs)&#24418;&#24335;&#21270;&#20026;&#19968;&#31181;&#26032;&#22411;&#30340;&#22270;&#65292;&#24182;&#31216;&#20043;&#20026;&#21452;&#20132;&#25442;&#23646;&#24615;&#22270;&#65292;&#20854;&#20013;&#33410;&#28857;&#21644;&#20108;&#20803;&#65288;&#20004;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#65289;&#34920;&#31034;&#24517;&#39035;&#23545;&#33410;&#28857;&#21495;&#21644;&#36793;&#65288;&#21450;&#33410;&#28857;&#65289;&#23646;&#24615;&#65288;&#20851;&#31995;&#21644;&#33410;&#28857;&#29305;&#24449;&#65289;&#30340;&#25490;&#21015;&#31561;&#21464;&#12290;&#21452;&#37325;&#25490;&#21015;&#31561;&#21464;&#30340;KG&#34920;&#31034;&#22312;KG&#20013;&#24320;&#36767;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#31561;&#21464;&#24615;&#23545;&#20851;&#31995;&#30340;&#32467;&#26500;&#34920;&#31034;&#20135;&#29983;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#20351;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#22312;KG&#20013;&#25191;&#34892;&#22797;&#26434;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#31561;&#21464;&#34920;&#31034;&#34013;&#22270;&#65292;&#24182;&#27979;&#35797;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#22522;&#20110;GNN&#30340;&#21452;&#25490;&#21015;&#31561;&#21464;&#31070;&#32463;&#32467;&#26500;&#65292;&#22312;WN18RR&#12289;FB237&#21644;NELL995&#24402;&#32435;KG&#23436;&#25104;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;Hits@10&#27979;&#35797;&#20934;&#30830;&#29575;&#65292;&#24182;&#33021;&#22815;&#20934;&#30830;&#25191;&#34892;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#25191;&#34892;&#30340;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (&amp; node) attributes (relations &amp; node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20107;&#23454;&#26680;&#26597;&#25968;&#25454;&#38598;AmbiFC&#65292;&#29992;&#20110;&#22788;&#29702;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#21547;&#31946;&#24615;&#22768;&#26126;&#26680;&#26597;&#38382;&#39064;&#65292;&#36890;&#36807;&#32454;&#31890;&#24230;&#30340;&#35777;&#25454;&#27880;&#37322;&#21644;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21547;&#31946;&#24615;&#22768;&#26126;&#30340;&#36719;&#26631;&#31614;&#35777;&#25454;&#26680;&#26597;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27880;&#37322;&#20154;&#21592;&#20105;&#35758;&#20998;&#26512;&#20013;&#21457;&#29616;&#20102;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2104.00640</link><description>&lt;p&gt;
AmbiFC: &#29992;&#35777;&#25454;&#26816;&#39564;&#21547;&#31946;&#24615;&#22768;&#26126;&#30340;&#30495;&#23454;&#24615;
&lt;/p&gt;
&lt;p&gt;
AmbiFC: Fact-Checking Ambiguous Claims with Evidence. (arXiv:2104.00640v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.00640
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20107;&#23454;&#26680;&#26597;&#25968;&#25454;&#38598;AmbiFC&#65292;&#29992;&#20110;&#22788;&#29702;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#21547;&#31946;&#24615;&#22768;&#26126;&#26680;&#26597;&#38382;&#39064;&#65292;&#36890;&#36807;&#32454;&#31890;&#24230;&#30340;&#35777;&#25454;&#27880;&#37322;&#21644;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21547;&#31946;&#24615;&#22768;&#26126;&#30340;&#36719;&#26631;&#31614;&#35777;&#25454;&#26680;&#26597;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27880;&#37322;&#20154;&#21592;&#20105;&#35758;&#20998;&#26512;&#20013;&#21457;&#29616;&#20102;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#33258;&#21160;&#21270;&#20107;&#23454;&#26680;&#26597;&#31995;&#32479;&#24517;&#39035;&#23558;&#22768;&#26126;&#19982;&#26816;&#32034;&#21040;&#30340;&#35777;&#25454;&#36827;&#34892;&#27604;&#36739;&#20197;&#39044;&#27979;&#30495;&#23454;&#24615;&#12290;&#26816;&#32034;&#21040;&#30340;&#35777;&#25454;&#21487;&#33021;&#26080;&#27861;&#26126;&#30830;&#25903;&#25345;&#25110;&#21453;&#39539;&#22768;&#26126;&#65292;&#24182;&#20135;&#29983;&#21508;&#31181;&#26377;&#25928;&#35299;&#37322;&#12290;&#29616;&#26377;&#30340;&#20107;&#23454;&#26680;&#26597;&#25968;&#25454;&#38598;&#38656;&#35201;&#27169;&#22411;&#20026;&#27599;&#20010;&#22768;&#26126;&#39044;&#27979;&#21333;&#20010;&#30495;&#23454;&#24615;&#26631;&#31614;&#65292;&#24182;&#19988;&#32570;&#20047;&#31649;&#29702;&#27492;&#31867;&#27169;&#31946;&#24615;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20107;&#23454;&#26680;&#26597;&#25968;&#25454;&#38598;AmbiFC&#65292;&#20854;&#20013;&#21253;&#21547;&#20174;&#23436;&#25972;&#32500;&#22522;&#30334;&#31185;&#39029;&#38754;&#20013;&#33719;&#21462;&#30340;&#32463;&#36807;&#32454;&#31890;&#24230;&#35777;&#25454;&#27880;&#37322;&#30340;&#20449;&#24687;&#38656;&#27714;&#30340;&#29616;&#23454;&#22768;&#26126;&#12290;&#25105;&#20204;&#24443;&#24213;&#20998;&#26512;&#20102;AmbiFC&#20013;&#28041;&#21450;&#21547;&#31946;&#22768;&#26126;&#24341;&#36215;&#30340;&#20105;&#35758;&#65292;&#35266;&#23519;&#21040;&#19982;&#27880;&#37322;&#20154;&#21592;&#30340;&#33258;&#25105;&#35780;&#20272;&#21644;&#19987;&#23478;&#27880;&#37322;&#30340;&#35821;&#35328;&#29616;&#35937;&#24378;&#28872;&#30456;&#20851;&#30340;&#27880;&#37322;&#20154;&#21592;&#20105;&#35758;&#12290;&#25105;&#20204;&#24341;&#20837;&#22522;&#20110;&#35777;&#25454;&#30340;&#21547;&#31946;&#22768;&#26126;&#30340;&#30495;&#23454;&#24615;&#26680;&#26597;&#20219;&#21153;&#65292;&#27604;&#36739;&#20102;&#19977;&#31181;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#21547;&#27880;&#37322;&#20449;&#21495;&#21644;&#21333;&#26631;&#31614;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated fact-checking systems in real-world scenarios must compare claims with retrieved evidence to predict the veracity. The retrieved evidence may not unambiguously support or refute the claim and yield diverse valid interpretations. Existing fact-checking datasets necessitate that models predict a single veracity label for each claim and lack the ability to manage such ambiguity. We present AmbiFC, a large-scale fact-checking dataset with realistic claims derived from real-world information needs. Our dataset contains fine-grained evidence annotations of passages from complete Wikipedia pages. We thoroughly analyze disagreements arising from ambiguous claims in AmbiFC, observing a strong correlation of annotator disagreement with their self-assessment and expert-annotated linguistic phenomena. We introduce the task of evidence-based fact-checking for ambiguous claims with soft labels, and compare three methodologies incorporating annotation signals with a single-label classificat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20154;&#31867;&#30699;&#27491;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#26631;&#27880;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#25968;&#25454;&#65292;&#25910;&#38598;&#32416;&#38169;&#20449;&#24687;&#65292;&#24182;&#23558;&#20854;&#27880;&#20837;&#33267;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#65292;&#25104;&#21151;&#23558;&#25991;&#26412;&#20998;&#31867;&#20934;&#30830;&#24230;&#25552;&#21319;&#20102;1.7&#20010;&#30334;&#20998;&#28857;&#12290;</title><link>http://arxiv.org/abs/2102.00225</link><description>&lt;p&gt;
&#20174;&#20154;&#31867;&#30340;&#32416;&#38169;&#20013;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning From How Humans Correct. (arXiv:2102.00225v14 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.00225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20154;&#31867;&#30699;&#27491;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#26631;&#27880;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#25968;&#25454;&#65292;&#25910;&#38598;&#32416;&#38169;&#20449;&#24687;&#65292;&#24182;&#23558;&#20854;&#27880;&#20837;&#33267;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#65292;&#25104;&#21151;&#23558;&#25991;&#26412;&#20998;&#31867;&#20934;&#30830;&#24230;&#25552;&#21319;&#20102;1.7&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#19994;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#25163;&#21160;&#26631;&#27880;&#30340;&#25968;&#25454;&#20013;&#23384;&#22312;&#19968;&#23450;&#25968;&#37327;&#30340;&#22122;&#22768;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#25214;&#21040;&#22122;&#22768;&#25968;&#25454;&#24182;&#25163;&#21160;&#37325;&#26032;&#26631;&#27880;&#23427;&#20204;&#65292;&#21516;&#26102;&#25910;&#38598;&#32416;&#38169;&#20449;&#24687;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#20154;&#31867;&#32416;&#38169;&#20449;&#24687;&#34701;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#20154;&#31867;&#30693;&#36947;&#22914;&#20309;&#32416;&#27491;&#22122;&#22768;&#25968;&#25454;&#65292;&#22240;&#27492;&#32416;&#38169;&#20449;&#24687;&#21487;&#20197;&#27880;&#20837;&#21040;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#22312;&#33258;&#24049;&#30340;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#25163;&#21160;&#26631;&#27880;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#37325;&#26032;&#26631;&#27880;&#20102;&#25105;&#20204;&#25968;&#25454;&#38598;&#20013;&#30340;&#22122;&#22768;&#25968;&#25454;&#65292;&#20197;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#24037;&#19994;&#24212;&#29992;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#20998;&#31867;&#20934;&#30830;&#24230;&#20174;91.7%&#25552;&#21319;&#21040;92.5%&#12290;91.7%&#30340;&#20934;&#30830;&#24230;&#26159;&#22312;&#20462;&#27491;&#21518;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#65292;&#23427;&#23558;&#22522;&#32447;&#20934;&#30830;&#24230;&#20174;83.3%&#25552;&#21319;&#21040;91.7%&#12290;
&lt;/p&gt;
&lt;p&gt;
In industry NLP application, our manually labeled data has a certain number of noisy data. We present a simple method to find the noisy data and re-label them manually, meanwhile we collect the correction information. Then we present novel method to incorporate the human correction information into deep learning model. Human know how to correct noisy data. So the correction information can be inject into deep learning model. We do the experiment on our own text classification dataset, which is manually labeled, because we re-label the noisy data in our dataset for our industry application. The experiment result shows that our method improve the classification accuracy from 91.7% to 92.5%. The 91.7% accuracy is trained on the corrected dataset, which improve the baseline from 83.3% to 91.7%.
&lt;/p&gt;</description></item></channel></rss>