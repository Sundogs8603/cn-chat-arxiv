<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;32&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#65292;&#22635;&#34917;&#20102;&#25918;&#23556;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#35780;&#20272;&#31354;&#30333;&#12290;&#35780;&#20272;&#32467;&#26524;&#20026;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#12289;&#20248;&#21183;&#21644;&#24369;&#28857;&#25552;&#20379;&#20102;&#20851;&#38190;&#35265;&#35299;&#65292;&#20026;&#23427;&#20204;&#22312;&#21307;&#23398;&#39046;&#22495;&#30340;&#23454;&#38469;&#24212;&#29992;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2307.13693</link><description>&lt;p&gt;
&#35780;&#20272;&#29992;&#20110;&#25918;&#23556;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Evaluating Large Language Models for Radiology Natural Language Processing. (arXiv:2307.13693v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;32&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#65292;&#22635;&#34917;&#20102;&#25918;&#23556;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#35780;&#20272;&#31354;&#30333;&#12290;&#35780;&#20272;&#32467;&#26524;&#20026;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#12289;&#20248;&#21183;&#21644;&#24369;&#28857;&#25552;&#20379;&#20102;&#20851;&#38190;&#35265;&#35299;&#65292;&#20026;&#23427;&#20204;&#22312;&#21307;&#23398;&#39046;&#22495;&#30340;&#23454;&#38469;&#24212;&#29992;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#23835;&#36215;&#26631;&#24535;&#30528;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#39046;&#22495;&#30340;&#37325;&#22823;&#36716;&#21464;&#12290;LLMs&#24050;&#32463;&#22312;&#35768;&#22810;&#39046;&#22495;&#24341;&#36215;&#20102;&#38761;&#21629;&#24615;&#30340;&#21464;&#21270;&#65292;&#24182;&#22312;&#21307;&#23398;&#39046;&#22495;&#20135;&#29983;&#20102;&#37325;&#35201;&#24433;&#21709;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27604;&#20197;&#24448;&#20219;&#20309;&#26102;&#20505;&#37117;&#26356;&#20016;&#23500;&#65292;&#24182;&#19988;&#20854;&#20013;&#35768;&#22810;&#27169;&#22411;&#20855;&#26377;&#21452;&#35821;&#33021;&#21147;&#65292;&#21487;&#20197;&#29087;&#32451;&#22788;&#29702;&#33521;&#25991;&#21644;&#20013;&#25991;&#12290;&#28982;&#32780;&#65292;&#23545;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#20173;&#26377;&#24453;&#24320;&#23637;&#12290;&#22312;&#25918;&#23556;&#23398;NLP&#30340;&#32972;&#26223;&#19979;&#65292;&#23588;&#20854;&#26126;&#26174;&#32570;&#20047;&#36825;&#31181;&#35780;&#20272;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#23545;32&#20010;LLMs&#22312;&#35299;&#37322;&#25918;&#23556;&#23398;&#25253;&#21578;&#26041;&#38754;&#36827;&#34892;&#25209;&#21028;&#24615;&#35780;&#20272;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20855;&#20307;&#35780;&#20272;&#20102;&#20174;&#24433;&#20687;&#23398;&#21457;&#29616;&#20013;&#24471;&#20986;&#21360;&#35937;&#30340;&#33021;&#21147;&#12290;&#36825;&#20010;&#35780;&#20272;&#30340;&#32467;&#26524;&#20026;&#36825;&#20123;LLMs&#30340;&#24615;&#33021;&#12289;&#20248;&#21183;&#21644;&#24369;&#28857;&#25552;&#20379;&#20102;&#20851;&#38190;&#35265;&#35299;&#65292;&#24182;&#20026;&#23427;&#20204;&#22312;&#21307;&#23398;&#39046;&#22495;&#30340;&#23454;&#38469;&#24212;&#29992;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP). LLMs have revolutionized a multitude of domains, and they have made a significant impact in the medical field. Large language models are now more abundant than ever, and many of these models exhibit bilingual capabilities, proficient in both English and Chinese. However, a comprehensive evaluation of these models remains to be conducted. This lack of assessment is especially apparent within the context of radiology NLP. This study seeks to bridge this gap by critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP. Specifically, the ability to derive impressions from radiologic findings is assessed. The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain.
&lt;/p&gt;</description></item><item><title>ARB&#26159;&#19968;&#20010;&#26032;&#22411;&#22522;&#20934;&#65292;&#21253;&#21547;&#20102;&#25968;&#23398;&#12289;&#29289;&#29702;&#12289;&#29983;&#29289;&#12289;&#21270;&#23398;&#21644;&#27861;&#24459;&#39046;&#22495;&#30340;&#39640;&#32423;&#25512;&#29702;&#38382;&#39064;&#12290;&#30446;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#36825;&#20123;&#20219;&#21153;&#19978;&#24471;&#20998;&#36828;&#20302;&#20110;50%&#65292;&#20026;&#20102;&#25552;&#39640;&#35780;&#20272;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.13692</link><description>&lt;p&gt;
ARB&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39640;&#32423;&#25512;&#29702;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
ARB: Advanced Reasoning Benchmark for Large Language Models. (arXiv:2307.13692v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13692
&lt;/p&gt;
&lt;p&gt;
ARB&#26159;&#19968;&#20010;&#26032;&#22411;&#22522;&#20934;&#65292;&#21253;&#21547;&#20102;&#25968;&#23398;&#12289;&#29289;&#29702;&#12289;&#29983;&#29289;&#12289;&#21270;&#23398;&#21644;&#27861;&#24459;&#39046;&#22495;&#30340;&#39640;&#32423;&#25512;&#29702;&#38382;&#39064;&#12290;&#30446;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#36825;&#20123;&#20219;&#21153;&#19978;&#24471;&#20998;&#36828;&#20302;&#20110;50%&#65292;&#20026;&#20102;&#25552;&#39640;&#35780;&#20272;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#23450;&#37327;&#25512;&#29702;&#21644;&#30693;&#35782;&#22522;&#20934;&#19978;&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#36824;&#27809;&#26377;&#36798;&#21040;&#19987;&#23478;&#27700;&#24179;&#65292;&#20294;&#35768;&#22810;&#36825;&#20123;&#22522;&#20934;&#38543;&#30528;LLMs&#33719;&#24471;&#36234;&#26469;&#36234;&#39640;&#30340;&#20998;&#25968;&#32780;&#22833;&#21435;&#20102;&#25928;&#29992;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;ARB&#65292;&#19968;&#20010;&#30001;&#22810;&#20010;&#39046;&#22495;&#30340;&#39640;&#32423;&#25512;&#29702;&#38382;&#39064;&#32452;&#25104;&#30340;&#26032;&#22411;&#22522;&#20934;&#12290;ARB&#25552;&#20379;&#27604;&#20197;&#21069;&#30340;&#22522;&#20934;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#27979;&#35797;&#65292;&#21253;&#25324;&#25968;&#23398;&#12289;&#29289;&#29702;&#12289;&#29983;&#29289;&#12289;&#21270;&#23398;&#21644;&#27861;&#24459;&#39046;&#22495;&#30340;&#38382;&#39064;&#12290;&#20316;&#20026;ARB&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#32452;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#21644;&#29289;&#29702;&#38382;&#39064;&#65292;&#38656;&#35201;&#39640;&#32423;&#31526;&#21495;&#25512;&#29702;&#21644;&#39046;&#22495;&#30693;&#35782;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#26368;&#36817;&#30340;&#27169;&#22411;&#65292;&#22914;GPT-4&#21644;Claude&#22312;ARB&#19978;&#30340;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#24403;&#21069;&#27169;&#22411;&#22312;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#24471;&#20998;&#36828;&#20302;&#20110;50%&#12290;&#20026;&#20102;&#25913;&#36827;&#33258;&#21160;&#21644;&#36741;&#21161;&#35780;&#20272;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#35780;&#20998;&#26631;&#20934;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#20801;&#35768;GPT-4&#23545;&#20854;&#33258;&#36523;&#30340;&#20013;&#38388;&#25512;&#29702;&#27493;&#39588;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;&#39046;&#22495;&#36827;&#34892;&#20102;&#32508;&#21512;&#35780;&#20272;&#19982;&#20998;&#26512;&#65292;&#21457;&#29616;&#21512;&#29702;&#34701;&#21512;&#35821;&#38899;&#21644;&#22270;&#24418;&#20449;&#24687;&#21487;&#20197;&#25552;&#39640;&#26816;&#26597;&#25928;&#26524;&#65292;&#27169;&#22411;&#23545;&#27979;&#35797;&#38598;&#30340;&#38169;&#35823;&#20998;&#24067;&#25935;&#24863;&#65292;&#20808;&#21069;&#32463;&#39564;&#23545;&#27169;&#22411;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24120;&#29992;&#30340;&#22522;&#20934;&#27979;&#35797;&#38598;&#26080;&#27861;&#21487;&#38752;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.13655</link><description>&lt;p&gt;
&#23545;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;&#30340;&#32508;&#21512;&#35780;&#20272;&#19982;&#20998;&#26512;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check. (arXiv:2307.13655v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;&#39046;&#22495;&#36827;&#34892;&#20102;&#32508;&#21512;&#35780;&#20272;&#19982;&#20998;&#26512;&#65292;&#21457;&#29616;&#21512;&#29702;&#34701;&#21512;&#35821;&#38899;&#21644;&#22270;&#24418;&#20449;&#24687;&#21487;&#20197;&#25552;&#39640;&#26816;&#26597;&#25928;&#26524;&#65292;&#27169;&#22411;&#23545;&#27979;&#35797;&#38598;&#30340;&#38169;&#35823;&#20998;&#24067;&#25935;&#24863;&#65292;&#20808;&#21069;&#32463;&#39564;&#23545;&#27169;&#22411;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24120;&#29992;&#30340;&#22522;&#20934;&#27979;&#35797;&#38598;&#26080;&#27861;&#21487;&#38752;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#21457;&#23637;&#21644;&#35821;&#38899;&#21644;&#22270;&#24418;&#20449;&#24687;&#30340;&#34701;&#21512;&#65292;&#31070;&#32463;&#27169;&#22411;&#22312;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;&#26041;&#38754;&#21462;&#24471;&#20102;&#39640;&#20998;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#27979;&#35797;&#38598;&#30340;&#38480;&#21046;&#65292;&#23427;&#24182;&#27809;&#26377;&#20840;&#38754;&#21453;&#26144;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#21462;&#20102;&#20195;&#34920;&#24615;&#30340;&#27169;&#22411;&#33539;&#20363;&#65292;&#29992;&#20061;&#31181;&#32467;&#26500;&#23454;&#29616;&#65292;&#24182;&#22312;&#25105;&#20204;&#26500;&#24314;&#30340;&#19981;&#21516;&#30446;&#30340;&#30340;&#32508;&#21512;&#27979;&#35797;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#25105;&#20204;&#23545;&#32467;&#26524;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#21457;&#29616;&#65306;1&#65289;&#21512;&#29702;&#22320;&#34701;&#21512;&#35821;&#38899;&#21644;&#22270;&#24418;&#20449;&#24687;&#23545;&#25340;&#20889;&#26816;&#26597;&#26159;&#26377;&#25928;&#30340;&#12290;2&#65289;&#27169;&#22411;&#23545;&#20110;&#27979;&#35797;&#38598;&#30340;&#38169;&#35823;&#20998;&#24067;&#25935;&#24863;&#65292;&#36825;&#21453;&#26144;&#20102;&#27169;&#22411;&#30340;&#32570;&#28857;&#24182;&#25581;&#31034;&#20102;&#25105;&#20204;&#24212;&#35813;&#21162;&#21147;&#30340;&#26041;&#21521;&#12290;3&#65289;&#38169;&#35823;&#21644;&#19978;&#19979;&#25991;&#30340;&#20808;&#21069;&#32463;&#39564;&#23545;&#27169;&#22411;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;4&#65289;&#24120;&#29992;&#30340;&#22522;&#20934;&#27979;&#35797;&#38598;SIGHAN&#26080;&#27861;&#21487;&#38752;&#35780;&#20272;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the development of pre-trained models and the incorporation of phonetic and graphic information, neural models have achieved high scores in Chinese Spelling Check (CSC). However, it does not provide a comprehensive reflection of the models' capability due to the limited test sets. In this study, we abstract the representative model paradigm, implement it with nine structures and experiment them on comprehensive test sets we constructed with different purposes. We perform a detailed analysis of the results and find that: 1) Fusing phonetic and graphic information reasonably is effective for CSC. 2) Models are sensitive to the error distribution of the test set, which reflects the shortcomings of models and reveals the direction we should work on. 3) Whether or not the errors and contexts have been seen has a significant impact on models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate models' performance.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#20013;&#38382;&#39064;&#22238;&#31572;&#31995;&#32479;&#30340;&#25913;&#36827;&#26041;&#27861;&#65292;&#21253;&#25324;&#38382;&#39064;&#31867;&#22411;&#20998;&#31867;&#21644;&#31572;&#26696;&#25552;&#21462;&#26041;&#27861;&#30340;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.13631</link><description>&lt;p&gt;
&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#20013;&#36129;&#29486;&#20110;&#38382;&#39064;&#22238;&#31572;&#31995;&#32479;&#30340;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Contributions to the Improvement of Question Answering Systems in the Biomedical Domain. (arXiv:2307.13631v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13631
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#20013;&#38382;&#39064;&#22238;&#31572;&#31995;&#32479;&#30340;&#25913;&#36827;&#26041;&#27861;&#65292;&#21253;&#25324;&#38382;&#39064;&#31867;&#22411;&#20998;&#31867;&#21644;&#31572;&#26696;&#25552;&#21462;&#26041;&#27861;&#30340;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#24037;&#20316;&#28041;&#21450;&#21040;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#20013;&#30340;&#38382;&#39064;&#22238;&#31572;(QA)&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#28041;&#21450;&#21040;&#20102;&#20960;&#20010;&#20855;&#20307;&#30340;&#25361;&#25112;&#65292;&#22914;&#19987;&#19994;&#30340;&#35789;&#24211;&#21644;&#26415;&#35821;&#12289;&#22788;&#29702;&#30340;&#38382;&#39064;&#31867;&#22411;&#20197;&#21450;&#30446;&#26631;&#25991;&#26723;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#20110;&#30740;&#31350;&#21644;&#25913;&#36827;&#37027;&#20123;&#26088;&#22312;&#20174;&#22823;&#37327;&#30340;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#25991;&#26723;&#20013;&#25214;&#21040;&#20934;&#30830;&#21644;&#31616;&#30701;&#31572;&#26696;&#30340;&#26041;&#27861;&#12290;QA&#30340;&#30446;&#26631;&#26159;&#20026;&#25552;&#38382;&#32773;&#25552;&#20379;&#30452;&#25509;&#12289;&#31616;&#30701;&#21644;&#20934;&#30830;&#30340;&#22238;&#31572;&#12290;&#22312;&#36825;&#31687;&#21338;&#22763;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#36129;&#29486;&#65292;&#20197;&#25913;&#36827;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#20013;QA&#30340;&#24615;&#33021;&#12290;&#22312;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#29992;&#20110;&#38382;&#39064;&#31867;&#22411;&#20998;&#31867;&#65292;&#20197;&#30830;&#23450;&#32473;&#23450;&#38382;&#39064;&#30340;&#31867;&#22411;&#65292;&#20174;&#32780;&#20351;&#29983;&#29289;&#21307;&#23398;QA&#31995;&#32479;&#33021;&#22815;&#20351;&#29992;&#36866;&#24403;&#30340;&#31572;&#26696;&#25552;&#21462;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21478;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;a...
&lt;/p&gt;
&lt;p&gt;
This thesis work falls within the framework of question answering (QA) in the biomedical domain where several specific challenges are addressed, such as specialized lexicons and terminologies, the types of treated questions, and the characteristics of targeted documents. We are particularly interested in studying and improving methods that aim at finding accurate and short answers to biomedical natural language questions from a large scale of biomedical textual documents in English. QA aims at providing inquirers with direct, short and precise answers to their natural language questions. In this Ph.D. thesis, we propose four contributions to improve the performance of QA in the biomedical domain. In our first contribution, we propose a machine learning-based method for question type classification to determine the types of given questions which enable to a biomedical QA system to use the appropriate answer extraction method. We also propose an another machine learning-based method to a
&lt;/p&gt;</description></item><item><title>GPT-3&#27169;&#22411;&#22312;&#37329;&#34701;&#39046;&#22495;&#30340;&#23569;&#26679;&#26412;&#25512;&#29702;&#34920;&#29616;&#26377;&#38480;&#65292;&#38656;&#35201;&#20351;&#29992;&#29420;&#31435;&#30340;&#26816;&#32034;&#27169;&#22411;&#21644;&#36923;&#36753;&#24341;&#25806;&#26469;&#33719;&#24471;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.13617</link><description>&lt;p&gt;
GPT-3&#27169;&#22411;&#26159;&#23569;&#26679;&#26412;&#37329;&#34701;&#25512;&#29702;&#22120;
&lt;/p&gt;
&lt;p&gt;
GPT-3 Models are Few-Shot Financial Reasoners. (arXiv:2307.13617v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13617
&lt;/p&gt;
&lt;p&gt;
GPT-3&#27169;&#22411;&#22312;&#37329;&#34701;&#39046;&#22495;&#30340;&#23569;&#26679;&#26412;&#25512;&#29702;&#34920;&#29616;&#26377;&#38480;&#65292;&#38656;&#35201;&#20351;&#29992;&#29420;&#31435;&#30340;&#26816;&#32034;&#27169;&#22411;&#21644;&#36923;&#36753;&#24341;&#25806;&#26469;&#33719;&#24471;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37329;&#34701;&#20998;&#26512;&#26159;&#35780;&#20272;&#20844;&#21496;&#19994;&#32489;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#20174;&#19994;&#32773;&#36890;&#36807;&#28145;&#20837;&#30340;&#37327;&#21270;&#20998;&#26512;&#22238;&#31572;&#37329;&#34701;&#38382;&#39064;&#65292;&#20174;&#32780;&#20570;&#20986;&#26377;&#21033;&#21487;&#22270;&#30340;&#25237;&#36164;&#20915;&#31574;&#12290;&#22240;&#27492;&#65292;&#37329;&#34701;&#38382;&#31572;&#26159;&#19968;&#20010;&#38656;&#35201;&#23545;&#25968;&#23383;&#36827;&#34892;&#28145;&#20837;&#25512;&#29702;&#30340;&#38382;&#39064;&#22238;&#31572;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#22312;&#37329;&#34701;&#39046;&#22495;&#30340;&#25512;&#29702;&#33021;&#21147;&#22914;&#20309;&#12290;&#30446;&#21069;&#30340;&#26368;&#26032;&#25216;&#26415;&#38656;&#35201;&#19968;&#20010;&#26816;&#32034;&#27169;&#22411;&#20174;&#25991;&#26412;&#20013;&#25910;&#38598;&#19982;&#37329;&#34701;&#38382;&#39064;&#30456;&#20851;&#30340;&#20107;&#23454;&#65292;&#24182;&#20351;&#29992;&#19968;&#20010;&#29983;&#25104;&#22120;&#26469;&#29983;&#25104;&#26377;&#25928;&#30340;&#37329;&#34701;&#31243;&#24207;&#21644;&#26368;&#32456;&#31572;&#26696;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;GPT-3&#20165;&#20165;&#36890;&#36807;&#23569;&#37327;&#31034;&#20363;&#23601;&#23454;&#29616;&#20102;&#24191;&#27867;&#20219;&#21153;&#30340;&#26368;&#26032;&#24615;&#33021;&#12290;&#25105;&#20204;&#23545;GPT-3&#36827;&#34892;&#20102;&#22810;&#20010;&#23454;&#39564;&#65292;&#21457;&#29616;&#29420;&#31435;&#30340;&#26816;&#32034;&#27169;&#22411;&#21644;&#36923;&#36753;&#24341;&#25806;&#20173;&#28982;&#26159;&#23454;&#29616;&#36825;&#19968;&#20219;&#21153;&#30340;&#20851;&#38190;&#32452;&#20214;&#65292;&#23588;&#20854;&#26159;&#30001;&#20110;&#37329;&#34701;&#39046;&#22495;&#30340;&#31934;&#30830;&#24615;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Financial analysis is an important tool for evaluating company performance. Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so. As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers. Furthermore, it is unknown how well pre-trained language models can reason in the financial domain. The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer. However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples. We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of finan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;XDLM&#65292;&#19968;&#31181;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#30340;&#36328;&#35821;&#35328;&#25193;&#25955;&#35821;&#35328;&#27169;&#22411;&#12290;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#38454;&#27573;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#25552;&#39640;&#20102;&#22312;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#30340;&#32763;&#35793;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#21644;Transformer&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.13560</link><description>&lt;p&gt;
XDLM: &#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#30340;&#36328;&#35821;&#35328;&#25193;&#25955;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
XDLM: Cross-lingual Diffusion Language Model for Machine Translation. (arXiv:2307.13560v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;XDLM&#65292;&#19968;&#31181;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#30340;&#36328;&#35821;&#35328;&#25193;&#25955;&#35821;&#35328;&#27169;&#22411;&#12290;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#38454;&#27573;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#25552;&#39640;&#20102;&#22312;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#30340;&#32763;&#35793;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#21644;Transformer&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#22312;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#24050;&#32463;&#24212;&#29992;&#20110;&#31070;&#32463;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#30340;&#21487;&#25511;&#25991;&#26412;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#25193;&#25955;&#27169;&#22411;&#22312;&#36328;&#35821;&#35328;&#29615;&#22659;&#20013;&#30340;&#24212;&#29992;&#30456;&#23545;&#36739;&#23569;&#12290;&#27492;&#22806;&#65292;&#23613;&#31649;&#24050;&#32463;&#30740;&#31350;&#20102;&#22312;&#21333;&#19968;&#35821;&#35328;&#20013;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#20294;&#36328;&#35821;&#35328;&#39044;&#35757;&#32451;&#30340;&#28508;&#21147;&#20173;&#26410;&#34987;&#28145;&#20837;&#30740;&#31350;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20123;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;XDLM&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#30340;&#36328;&#35821;&#35328;&#25193;&#25955;&#27169;&#22411;&#65292;&#21253;&#25324;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#38454;&#27573;&#12290;&#22312;&#39044;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TLDM&#65292;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#29992;&#20110;&#25484;&#25569;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#65307;&#22312;&#24494;&#35843;&#38454;&#27573;&#65292;&#25105;&#20204;&#22522;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#26500;&#24314;&#20102;&#32763;&#35793;&#31995;&#32479;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#26426;&#22120;&#32763;&#35793;&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#36229;&#36807;&#20102;&#25193;&#25955;&#21644;Transformer&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, diffusion models have excelled in image generation tasks and have also been applied to neural language processing (NLP) for controllable text generation. However, the application of diffusion models in a cross-lingual setting is less unexplored. Additionally, while pretraining with diffusion models has been studied within a single language, the potential of cross-lingual pretraining remains understudied. To address these gaps, we propose XDLM, a novel Cross-lingual diffusion model for machine translation, consisting of pretraining and fine-tuning stages. In the pretraining stage, we propose TLDM, a new training objective for mastering the mapping between different languages; in the fine-tuning stage, we build up the translation system based on the pretrained model. We evaluate the result on several machine translation benchmarks and outperformed both diffusion and Transformer baselines.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;FacTool&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;ChatGPT&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#30340;&#20107;&#23454;&#38169;&#35823;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30693;&#35782;&#22411;&#38382;&#31572;&#12289;&#20195;&#30721;&#29983;&#25104;&#12289;&#25968;&#23398;&#25512;&#29702;&#21644;&#31185;&#23398;&#25991;&#29486;&#32508;&#36848;&#31561;&#22235;&#20010;&#20219;&#21153;&#20013;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.13528</link><description>&lt;p&gt;
FacTool&#65306;&#29983;&#25104;AI&#20013;&#30340;&#20107;&#23454;&#24615;&#26816;&#27979; &#8212;&#8212; &#19968;&#31181;&#20026;&#22810;&#20219;&#21153;&#21644;&#22810;&#39046;&#22495;&#22330;&#26223;&#21152;&#24378;&#30340;&#24037;&#20855;&#22686;&#24378;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios. (arXiv:2307.13528v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13528
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;FacTool&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;ChatGPT&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#30340;&#20107;&#23454;&#38169;&#35823;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30693;&#35782;&#22411;&#38382;&#31572;&#12289;&#20195;&#30721;&#29983;&#25104;&#12289;&#25968;&#23398;&#25512;&#29702;&#21644;&#31185;&#23398;&#25991;&#29486;&#32508;&#36848;&#31561;&#22235;&#20010;&#20219;&#21153;&#20013;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#20986;&#29616;&#26041;&#20415;&#20102;&#39640;&#36136;&#37327;&#25991;&#26412;&#30340;&#21512;&#25104;&#65292;&#20294;&#20063;&#22312;&#35782;&#21035;&#29983;&#25104;&#25991;&#26412;&#20013;&#30340;&#20107;&#23454;&#38169;&#35823;&#26041;&#38754;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#38024;&#23545;&#20197;&#19979;&#38382;&#39064;&#25552;&#20986;&#20102;FacTool&#26694;&#26550;&#65306;&#65288;1&#65289;&#36234;&#26469;&#36234;&#22810;&#30340;&#20219;&#21153;&#30001;&#29983;&#25104;&#27169;&#22411;&#22788;&#29702;&#26102;&#65292;&#23384;&#22312;&#30528;&#21253;&#21547;&#20107;&#23454;&#38169;&#35823;&#30340;&#39118;&#38505;&#65307;&#65288;2&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#24448;&#24448;&#24456;&#38271;&#65292;&#32570;&#20047;&#28165;&#26224;&#23450;&#20041;&#30340;&#32454;&#31890;&#24230;&#20010;&#20307;&#20107;&#23454;&#65307;&#65288;3&#65289;&#22312;&#20107;&#23454;&#26816;&#26597;&#36807;&#31243;&#20013;&#32570;&#20047;&#26126;&#30830;&#30340;&#35777;&#25454;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#19978;&#36827;&#34892;&#23454;&#39564;&#65288;&#22522;&#20110;&#30693;&#35782;&#30340;&#38382;&#31572;&#12289;&#20195;&#30721;&#29983;&#25104;&#12289;&#25968;&#23398;&#25512;&#29702;&#21644;&#31185;&#23398;&#25991;&#29486;&#32508;&#36848;&#65289;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.
&lt;/p&gt;</description></item><item><title>Zshot&#26159;&#19968;&#20010;&#24320;&#28304;&#26694;&#26550;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#21644;&#20851;&#31995;&#25277;&#21462;&#65292;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#30340;&#26368;&#26032;ZSL&#26041;&#27861;&#65292;&#25903;&#25345;&#30740;&#31350;&#20154;&#21592;&#21644;&#24037;&#19994;&#30028;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2307.13497</link><description>&lt;p&gt;
Zshot&#65306;&#19968;&#20010;&#29992;&#20110;&#38646;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#21644;&#20851;&#31995;&#25277;&#21462;&#30340;&#24320;&#28304;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction. (arXiv:2307.13497v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13497
&lt;/p&gt;
&lt;p&gt;
Zshot&#26159;&#19968;&#20010;&#24320;&#28304;&#26694;&#26550;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#21644;&#20851;&#31995;&#25277;&#21462;&#65292;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#30340;&#26368;&#26032;ZSL&#26041;&#27861;&#65292;&#25903;&#25345;&#30740;&#31350;&#20154;&#21592;&#21644;&#24037;&#19994;&#30028;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38646;&#26679;&#26412;&#23398;&#20064;&#65288;ZSL&#65289;&#20219;&#21153;&#28041;&#21450;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26410;&#35265;&#36807;&#30340;&#25991;&#26412;&#20013;&#35782;&#21035;&#23454;&#20307;&#25110;&#20851;&#31995;&#12290;&#30001;&#20110;&#29305;&#23450;&#39046;&#22495;&#20013;&#26631;&#27880;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#65292;ZSL&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#24182;&#19988;&#22312;&#36817;&#24180;&#26469;&#24212;&#29992;&#33539;&#22260;&#24050;&#22823;&#24133;&#22686;&#38271;&#12290;&#38543;&#30528;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#25552;&#20986;&#20102;&#35768;&#22810;&#26032;&#30340;&#26041;&#27861;&#65292;ZSL&#24615;&#33021;&#26174;&#33879;&#25552;&#21319;&#12290;&#30740;&#31350;&#30028;&#21644;&#24037;&#19994;&#30028;&#23545;&#19968;&#20010;&#20840;&#38754;&#25903;&#25345;&#26368;&#26032;&#26041;&#27861;&#21644;&#39044;&#35757;&#32451;&#27169;&#22411;&#24320;&#21457;&#21644;&#21487;&#35775;&#38382;&#24615;&#30340;ZSL&#26694;&#26550;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Zshot&#30340;&#21019;&#26032;ZSL&#26694;&#26550;&#65292;&#26088;&#22312;&#35299;&#20915;&#19978;&#36848;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#25552;&#20379;&#19968;&#20010;&#24179;&#21488;&#65292;&#20801;&#35768;&#30740;&#31350;&#20154;&#21592;&#20351;&#29992;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#27604;&#36739;&#19981;&#21516;&#30340;&#26368;&#26032;ZSL&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#25903;&#25345;&#24037;&#19994;&#30028;&#30340;&#26694;&#26550;&#65292;&#20855;&#22791;&#26131;&#29992;&#24615;&#12289;&#28789;&#27963;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Zero-Shot Learning (ZSL) task pertains to the identification of entities or relations in texts that were not seen during training. ZSL has emerged as a critical research area due to the scarcity of labeled data in specific domains, and its applications have grown significantly in recent years. With the advent of large pretrained language models, several novel methods have been proposed, resulting in substantial improvements in ZSL performance. There is a growing demand, both in the research community and industry, for a comprehensive ZSL framework that facilitates the development and accessibility of the latest methods and pretrained models.In this study, we propose a novel ZSL framework called Zshot that aims to address the aforementioned challenges. Our primary objective is to provide a platform that allows researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets. Additionally, we have designed our framework to support the industry with readi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#25506;&#32034;&#20102;&#36890;&#29992;&#20998;&#35299;&#35821;&#20041;&#35299;&#26512;&#65292;&#36890;&#36807;&#24341;&#20837;&#32423;&#32852;&#27169;&#22411;&#21644;&#20248;&#21270;&#26550;&#26500;&#65292;&#20943;&#23569;&#25512;&#29702;&#26102;&#38388;&#24182;&#25552;&#39640;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#19981;&#21516;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#36827;&#19968;&#27493;&#25913;&#36827;&#20102;&#35299;&#26512;&#32467;&#26524;&#12290;&#30740;&#31350;&#21457;&#29616;ChatGPT&#22312;&#23646;&#24615;&#35299;&#26512;&#26041;&#38754;&#34920;&#29616;&#22909;&#65292;&#20294;&#22312;&#20851;&#31995;&#35299;&#26512;&#19978;&#23384;&#22312;&#22256;&#38590;&#65292;&#20351;&#29992;ChatGPT&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#25928;&#26524;&#19981;&#20339;&#12290;</title><link>http://arxiv.org/abs/2307.13424</link><description>&lt;p&gt;
&#20840;&#38754;&#25506;&#32034;&#36890;&#29992;&#20998;&#35299;&#35821;&#20041;&#35299;&#26512;&#65306;&#26550;&#26500;&#12289;&#25968;&#25454;&#22686;&#24378;&#21644;LLM&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm. (arXiv:2307.13424v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#25506;&#32034;&#20102;&#36890;&#29992;&#20998;&#35299;&#35821;&#20041;&#35299;&#26512;&#65292;&#36890;&#36807;&#24341;&#20837;&#32423;&#32852;&#27169;&#22411;&#21644;&#20248;&#21270;&#26550;&#26500;&#65292;&#20943;&#23569;&#25512;&#29702;&#26102;&#38388;&#24182;&#25552;&#39640;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#19981;&#21516;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#36827;&#19968;&#27493;&#25913;&#36827;&#20102;&#35299;&#26512;&#32467;&#26524;&#12290;&#30740;&#31350;&#21457;&#29616;ChatGPT&#22312;&#23646;&#24615;&#35299;&#26512;&#26041;&#38754;&#34920;&#29616;&#22909;&#65292;&#20294;&#22312;&#20851;&#31995;&#35299;&#26512;&#19978;&#23384;&#22312;&#22256;&#38590;&#65292;&#20351;&#29992;ChatGPT&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#25928;&#26524;&#19981;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#36890;&#29992;&#20998;&#35299;&#35821;&#20041;&#35299;&#26512;&#36827;&#34892;&#20102;&#20840;&#38754;&#25506;&#32034;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#32423;&#32852;&#27169;&#22411;&#65292;&#23558;&#22797;&#26434;&#30340;&#35299;&#26512;&#20219;&#21153;&#20998;&#35299;&#20026;&#35821;&#20041;&#19978;&#21512;&#36866;&#30340;&#23376;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20943;&#23569;&#25512;&#29702;&#26102;&#38388;&#30340;&#21516;&#26102;&#65292;&#20248;&#20110;&#20043;&#21069;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#32467;&#21512;&#20102;&#21477;&#27861;&#20449;&#24687;&#24182;&#36827;&#19968;&#27493;&#20248;&#21270;&#20102;&#26550;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#36890;&#29992;&#20998;&#35299;&#35821;&#20041;&#35299;&#26512;&#30340;&#25928;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35843;&#30740;&#20102;ChatGPT&#22312;&#22788;&#29702;&#36890;&#29992;&#20998;&#35299;&#35821;&#20041;&#35299;&#26512;&#20219;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#21457;&#29616;&#23427;&#22312;&#23646;&#24615;&#35299;&#26512;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#20851;&#31995;&#35299;&#26512;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#20351;&#29992;ChatGPT&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#30340;&#25928;&#26524;&#19981;&#22815;&#29702;&#24819;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/hexuandeng/HExp4UDS&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we conduct a holistic exploration of the Universal Decompositional Semantic (UDS) Parsing. We first introduce a cascade model for UDS parsing that decomposes the complex parsing task into semantically appropriate subtasks. Our approach outperforms the prior models, while significantly reducing inference time. We also incorporate syntactic information and further optimized the architecture. Besides, different ways for data augmentation are explored, which further improve the UDS Parsing. Lastly, we conduct experiments to investigate the efficacy of ChatGPT in handling the UDS task, revealing that it excels in attribute parsing but struggles in relation parsing, and using ChatGPT for data augmentation yields suboptimal results. Our code is available at https://github.com/hexuandeng/HExp4UDS.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#24212;&#29992;DBSCAN&#32858;&#31867;&#31639;&#27861;&#26469;&#35782;&#21035;&#21644;&#35780;&#20272;&#20855;&#26377;&#27495;&#20041;&#30340;&#21333;&#35789;&#65292;&#20174;&#32780;&#35299;&#20915;&#35789;&#20041;&#27495;&#20041;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.13417</link><description>&lt;p&gt;
&#29992;&#35789;&#21521;&#37327;&#35299;&#20915;&#35789;&#20041;&#27495;&#20041;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Towards Resolving Word Ambiguity with Word Embeddings. (arXiv:2307.13417v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#24212;&#29992;DBSCAN&#32858;&#31867;&#31639;&#27861;&#26469;&#35782;&#21035;&#21644;&#35780;&#20272;&#20855;&#26377;&#27495;&#20041;&#30340;&#21333;&#35789;&#65292;&#20174;&#32780;&#35299;&#20915;&#35789;&#20041;&#27495;&#20041;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#20013;&#65292;&#27495;&#20041;&#24615;&#26222;&#36941;&#23384;&#22312;&#12290;&#35299;&#20915;&#27495;&#20041;&#24847;&#20041;&#23545;&#20110;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#23588;&#20026;&#37325;&#35201;&#12290;&#23613;&#31649;&#35789;&#21521;&#37327;&#25658;&#24102;&#35821;&#20041;&#20449;&#24687;&#65292;&#20294;&#23427;&#20204;&#23545;&#20110;&#22788;&#29702;&#27495;&#20041;&#24615;&#24182;&#19981;&#25797;&#38271;&#12290;Transformer&#27169;&#22411;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#22788;&#29702;&#22797;&#26434;&#26597;&#35810;&#20013;&#30340;&#35789;&#20041;&#27495;&#20041;&#65292;&#20294;&#26080;&#27861;&#29992;&#20110;&#35782;&#21035;&#26377;&#27495;&#20041;&#30340;&#21333;&#35789;&#65292;&#20363;&#22914;&#29992;&#20110;&#19968;&#20010;&#21333;&#35789;&#30340;&#26597;&#35810;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#22312;&#26102;&#38388;&#12289;&#30828;&#20214;&#36164;&#28304;&#21644;&#35757;&#32451;&#25968;&#25454;&#26041;&#38754;&#25104;&#26412;&#39640;&#26114;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#20855;&#26377;&#25935;&#24863;&#25968;&#25454;&#30340;&#19987;&#38376;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#12290;&#35789;&#21521;&#37327;&#21487;&#20197;&#20351;&#29992;&#36866;&#20013;&#30340;&#30828;&#20214;&#36164;&#28304;&#36827;&#34892;&#35757;&#32451;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;DBSCAN&#32858;&#31867;&#24212;&#29992;&#20110;&#28508;&#31354;&#38388;&#65292;&#21487;&#20197;&#35782;&#21035;&#20986;&#26377;&#27495;&#20041;&#30340;&#21333;&#35789;&#24182;&#35780;&#20272;&#20854;&#27495;&#20041;&#31243;&#24230;&#12290;&#33258;&#21160;DBSCAN&#21442;&#25968;&#36873;&#25321;&#33021;&#22815;&#24471;&#21040;&#39640;&#36136;&#37327;&#30340;&#32858;&#31867;&#65292;&#36825;&#20123;&#32858;&#31867;&#22312;&#35821;&#20041;&#19978;&#26159;&#36830;&#36143;&#30340;&#65292;&#24182;&#19982;&#32473;&#23450;&#21333;&#35789;&#30340;&#24863;&#30693;&#24847;&#20041;&#30456;&#23545;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is especially important in information retrieval tasks. While word embeddings carry semantic information, they fail to handle ambiguity well. Transformer models have been shown to handle word ambiguity for complex queries, but they cannot be used to identify ambiguous words, e.g. for a 1-word query. Furthermore, training these models is costly in terms of time, hardware resources, and training data, prohibiting their use in specialized environments with sensitive data. Word embeddings can be trained using moderate hardware resources. This paper shows that applying DBSCAN clustering to the latent space can identify ambiguous words and evaluate their level of ambiguity. An automatic DBSCAN parameter selection leads to high-quality clusters, which are semantically coherent and correspond well to the perceived meanings of a given word.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#25506;&#35752;&#8220;&#35821;&#35328;&#20559;&#35265;&#8221;&#29616;&#35937;&#65292;&#21363;&#22810;&#35821;&#35328;&#22788;&#29702;&#31995;&#32479;&#23384;&#22312;&#23545;&#26576;&#20123;&#35821;&#35328;&#30340;&#30828;&#32534;&#30721;&#20542;&#21521;&#65292;&#24573;&#35270;&#20102;&#35821;&#35328;&#22797;&#26434;&#24615;&#21644;&#35821;&#35328;&#31038;&#21306;&#30340;&#38656;&#27714;&#65292;&#38459;&#30861;&#20102;AI&#25216;&#26415;&#35206;&#30422;&#21040;&#8220;&#36164;&#28304;&#26377;&#38480;&#30340;&#35821;&#35328;&#8221;&#12290;</title><link>http://arxiv.org/abs/2307.13405</link><description>&lt;p&gt;
&#36208;&#21521;&#32553;&#23567;&#25968;&#23383;&#35821;&#35328;&#40511;&#27807;&#30340;&#21162;&#21147;
&lt;/p&gt;
&lt;p&gt;
Towards Bridging the Digital Language Divide. (arXiv:2307.13405v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13405
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#25506;&#35752;&#8220;&#35821;&#35328;&#20559;&#35265;&#8221;&#29616;&#35937;&#65292;&#21363;&#22810;&#35821;&#35328;&#22788;&#29702;&#31995;&#32479;&#23384;&#22312;&#23545;&#26576;&#20123;&#35821;&#35328;&#30340;&#30828;&#32534;&#30721;&#20542;&#21521;&#65292;&#24573;&#35270;&#20102;&#35821;&#35328;&#22797;&#26434;&#24615;&#21644;&#35821;&#35328;&#31038;&#21306;&#30340;&#38656;&#27714;&#65292;&#38459;&#30861;&#20102;AI&#25216;&#26415;&#35206;&#30422;&#21040;&#8220;&#36164;&#28304;&#26377;&#38480;&#30340;&#35821;&#35328;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#24403;&#21069;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#35821;&#35328;&#25216;&#26415;&#65292;&#22914;&#35821;&#35328;&#27169;&#22411;&#12289;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#12289;&#22810;&#35821;&#35328;&#23383;&#20856;&#21644;&#35821;&#26009;&#24211;&#65292;&#20027;&#35201;&#20851;&#27880;&#20840;&#29699;2-3%&#30340;&#26368;&#24120;&#29992;&#35821;&#35328;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21162;&#21147;&#33268;&#21147;&#20110;&#23558;AI&#25216;&#26415;&#25193;&#22823;&#21040;&#8220;&#36164;&#28304;&#26377;&#38480;&#30340;&#35821;&#35328;&#8221;&#12290;&#25105;&#20204;&#35770;&#25991;&#30340;&#30446;&#26631;&#26159;&#24341;&#36215;&#20154;&#20204;&#23545;&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#35821;&#35328;&#20559;&#35265;&#8221;&#30340;&#29616;&#35937;&#30340;&#20851;&#27880;&#65306;&#22810;&#35821;&#35328;&#35821;&#35328;&#22788;&#29702;&#31995;&#32479;&#24448;&#24448;&#34920;&#29616;&#20986;&#23545;&#26576;&#20123;&#35821;&#35328;&#30340;&#30828;&#32534;&#30721;&#20542;&#21521;&#65292;&#36825;&#24448;&#24448;&#26159;&#26080;&#24847;&#35782;&#21644;&#38544;&#34255;&#30340;&#12290;&#21363;&#20351;&#22312;&#31867;&#20284;&#30340;&#27979;&#35797;&#26465;&#20214;&#19979;&#65292;&#35821;&#35328;&#20559;&#35265;&#20063;&#20250;&#23548;&#33268;&#19981;&#21516;&#35821;&#35328;&#30340;&#24615;&#33021;&#19981;&#22343;&#34913;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20855;&#26377;&#20559;&#35265;&#30340;&#25216;&#26415;&#24448;&#24448;&#26159;&#30001;&#20110;&#30740;&#21457;&#26041;&#27861;&#35770;&#27809;&#26377;&#23545;&#25152;&#34920;&#31034;&#30340;&#35821;&#35328;&#22797;&#26434;&#24615;&#36827;&#34892;&#24688;&#24403;&#22788;&#29702;&#32780;&#20135;&#29983;&#30340;&#65292;&#29978;&#33267;&#20250;&#22240;&#24573;&#35270;&#22810;&#26679;&#24615;&#23453;&#36149;&#30340;&#26041;&#38754;&#20197;&#21450;&#35821;&#35328;&#31038;&#21306;&#30340;&#38656;&#27714;&#32780;&#24341;&#36215;&#20262;&#29702;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is a well-known fact that current AI-based language technology -- language models, machine translation systems, multilingual dictionaries and corpora -focuses on the world's 2-3% most widely spoken languages. Recent research efforts have attempted to expand the coverage of AI technology to `under-resourced languages.' The goal of our paper is to bring attention to a phenomenon that we call linguistic bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages. Linguistic bias is manifested in uneven per-language performance even in the case of similar test conditions. We show that biased technology is often the result of research and development methodologies that do not do justice to the complexity of the languages being represented, and that can even become ethically problematic as they disregard valuable aspects of diversity as well as the needs of the language communities the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22312;&#31185;&#23398;&#35770;&#25991;&#33268;&#35874;&#25991;&#26412;&#20013;&#33258;&#21160;&#25552;&#21462;&#21644;&#20998;&#31867;&#34987;&#33268;&#35874;&#23454;&#20307;&#30340;&#19981;&#21516;&#23884;&#20837;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#20351;&#29992;Flair NLP&#26694;&#26550;&#36827;&#34892;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#30340;&#35757;&#32451;&#20013;&#65292;Flair Embeddings&#27169;&#22411;&#22312;&#20013;&#31561;&#35268;&#27169;&#35821;&#26009;&#24211;&#19978;&#36798;&#21040;&#20102;&#26368;&#20339;&#20934;&#30830;&#24230;&#65288;0.79&#65289;&#12290;&#21516;&#26102;&#65292;&#25193;&#22823;&#35757;&#32451;&#35821;&#26009;&#24211;&#30340;&#35268;&#27169;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#25152;&#26377;&#35757;&#32451;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.13377</link><description>&lt;p&gt;
&#20351;&#29992;&#23884;&#20837;&#27169;&#22411;&#36827;&#34892;&#31185;&#23398;&#33268;&#35874;&#20013;&#21629;&#21517;&#23454;&#20307;&#30340;&#33258;&#21160;&#25552;&#21462;&#21644;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements. (arXiv:2307.13377v1 [cs.DL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13377
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22312;&#31185;&#23398;&#35770;&#25991;&#33268;&#35874;&#25991;&#26412;&#20013;&#33258;&#21160;&#25552;&#21462;&#21644;&#20998;&#31867;&#34987;&#33268;&#35874;&#23454;&#20307;&#30340;&#19981;&#21516;&#23884;&#20837;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#20351;&#29992;Flair NLP&#26694;&#26550;&#36827;&#34892;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20219;&#21153;&#30340;&#35757;&#32451;&#20013;&#65292;Flair Embeddings&#27169;&#22411;&#22312;&#20013;&#31561;&#35268;&#27169;&#35821;&#26009;&#24211;&#19978;&#36798;&#21040;&#20102;&#26368;&#20339;&#20934;&#30830;&#24230;&#65288;0.79&#65289;&#12290;&#21516;&#26102;&#65292;&#25193;&#22823;&#35757;&#32451;&#35821;&#26009;&#24211;&#30340;&#35268;&#27169;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#25152;&#26377;&#35757;&#32451;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#35770;&#25991;&#20013;&#30340;&#33268;&#35874;&#37096;&#20998;&#21487;&#33021;&#25581;&#31034;&#31185;&#23398;&#31038;&#21306;&#30340;&#26576;&#20123;&#26041;&#38754;&#65292;&#27604;&#22914;&#22870;&#21169;&#20307;&#31995;&#12289;&#21512;&#20316;&#27169;&#24335;&#21644;&#38544;&#34255;&#30340;&#30740;&#31350;&#36235;&#21183;&#12290;&#35813;&#35770;&#25991;&#26088;&#22312;&#35780;&#20272;&#19981;&#21516;&#23884;&#20837;&#27169;&#22411;&#22312;&#31185;&#23398;&#35770;&#25991;&#33268;&#35874;&#25991;&#26412;&#20013;&#33258;&#21160;&#25552;&#21462;&#21644;&#20998;&#31867;&#34987;&#33268;&#35874;&#23454;&#20307;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20351;&#29992;Flair NLP&#26694;&#26550;&#36827;&#34892;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#20219;&#21153;&#30340;&#35757;&#32451;&#21644;&#23454;&#29616;&#12290;&#35757;&#32451;&#20351;&#29992;&#20102;&#19977;&#20010;&#40664;&#35748;&#30340;Flair NER&#27169;&#22411;&#65292;&#20351;&#29992;&#22235;&#20010;&#19981;&#21516;&#22823;&#23567;&#30340;&#35821;&#26009;&#24211;&#21644;&#19981;&#21516;&#29256;&#26412;&#30340;Flair NLP&#26694;&#26550;&#36827;&#34892;&#12290;&#22312;&#26368;&#26032;&#30340;FLAIR&#29256;&#26412;&#19978;&#65292;&#20351;&#29992;&#20013;&#31561;&#35268;&#27169;&#30340;&#35821;&#26009;&#24211;&#35757;&#32451;&#30340;Flair&#23884;&#20837;&#27169;&#22411;&#26174;&#31034;&#20986;&#20102;&#26368;&#22909;&#30340;&#20934;&#30830;&#24615;&#65292;&#20026;0.79&#12290;&#23558;&#35757;&#32451;&#35821;&#26009;&#24211;&#30340;&#35268;&#27169;&#20174;&#38750;&#24120;&#23567;&#30340;&#25193;&#23637;&#21040;&#20013;&#31561;&#35268;&#27169;&#22823;&#22823;&#25552;&#39640;&#20102;&#25152;&#26377;&#35757;&#32451;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#36827;&#19968;&#27493;&#25193;&#22823;&#35757;&#32451;&#35821;&#26009;&#24211;&#24182;&#27809;&#26377;&#24102;&#26469;&#36827;&#19968;&#27493;&#30340;&#25913;&#21892;&#12290;&#27492;&#22806;&#65292;&#23884;&#20837;&#27169;&#22411;&#30340;&#24615;&#33021;&#22312;&#20854;&#20182;Embeddings&#36873;&#39033;&#19978;&#27809;&#26377;&#26174;&#33879;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends. The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers. We trained and implemented a named entity recognition (NER) task using the Flair NLP framework. The training was conducted using three default Flair NER models with four differently-sized corpora and different versions of the Flair NLP framework. The Flair Embeddings model trained on the medium corpus with the latest FLAIR version showed the best accuracy of 0.79. Expanding the size of a training corpus from very small to medium size massively increased the accuracy of all training algorithms, but further expansion of the training corpus did not bring further improvement. Moreover, the performance of the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20869;&#30340;&#20449;&#24687;&#20256;&#36882;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27880;&#24847;&#21147;&#36716;&#31227;&#30340;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#33021;&#22815;&#20351;&#27169;&#22411;&#22312;&#19981;&#22686;&#21152;&#35757;&#32451;&#25110;&#23545;&#29983;&#25104;&#27969;&#30021;&#24615;&#30340;&#24433;&#21709;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26356;&#38271;&#26356;&#22909;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.13365</link><description>&lt;p&gt;
&#29992;&#26356;&#38271;&#26356;&#22909;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#23558;&#27169;&#22411;&#36171;&#33021;
&lt;/p&gt;
&lt;p&gt;
Empower Your Model with Longer and Better Context Comprehension. (arXiv:2307.13365v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20869;&#30340;&#20449;&#24687;&#20256;&#36882;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27880;&#24847;&#21147;&#36716;&#31227;&#30340;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#33021;&#22815;&#20351;&#27169;&#22411;&#22312;&#19981;&#22686;&#21152;&#35757;&#32451;&#25110;&#23545;&#29983;&#25104;&#27969;&#30021;&#24615;&#30340;&#24433;&#21709;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26356;&#38271;&#26356;&#22909;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38543;&#30528;&#22823;&#37327;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#65292;&#20154;&#24037;&#26234;&#33021;&#30340;&#23454;&#29616;&#36827;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#26102;&#20195;&#12290;&#26080;&#35770;&#36825;&#20123;&#27169;&#22411;&#33258;&#36523;&#30340;&#23481;&#37327;&#21644;&#32467;&#26500;&#22914;&#20309;&#65292;&#37117;&#23384;&#22312;&#23545;LLMs&#20855;&#26377;&#26356;&#38271;&#26356;&#22797;&#26434;&#19978;&#19979;&#25991;&#30340;&#22686;&#24378;&#29702;&#35299;&#30340;&#38656;&#27714;&#65292;&#32780;&#27169;&#22411;&#36890;&#24120;&#22312;&#22788;&#29702;&#36229;&#20986;&#20854;&#29702;&#35299;&#33021;&#21147;&#33539;&#22260;&#30340;&#21477;&#23376;&#24207;&#21015;&#26102;&#20250;&#36935;&#21040;&#19978;&#38480;&#65292;&#23548;&#33268;&#20135;&#29983;&#31163;&#39064;&#25110;&#28151;&#20081;&#30340;&#22238;&#31572;&#12290;&#34429;&#28982;&#26368;&#36817;&#26377;&#20960;&#39033;&#24037;&#20316;&#35797;&#22270;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#24456;&#23569;&#20851;&#27880;&#8220;&#20026;&#20160;&#20040;&#27169;&#22411;&#26080;&#27861;&#33258;&#34892;&#24357;&#34917;&#25110;&#22686;&#24378;&#33258;&#24049;&#30340;&#33021;&#21147;&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;LLMs&#20869;&#30340;&#20449;&#24687;&#20256;&#36882;&#24615;&#36136;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27880;&#24847;&#21147;&#36716;&#31227;&#30340;&#26032;&#25216;&#26415;&#12290;&#36825;&#31181;&#25216;&#26415;&#33021;&#22815;&#20351;&#27169;&#22411;&#22312;&#26368;&#23567;&#21270;&#39069;&#22806;&#35757;&#32451;&#25110;&#23545;&#29983;&#25104;&#27969;&#21033;&#24615;&#30340;&#24433;&#21709;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26356;&#38271;&#26356;&#22909;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, with the emergence of numerous Large Language Models (LLMs), the implementation of AI has entered a new era. Irrespective of these models' own capacity and structure, there is a growing demand for LLMs to possess enhanced comprehension of longer and more complex contexts with relatively smaller sizes. Models often encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses. While several recent works attempt to address this issue in various ways, they rarely focus on "why models are unable to compensate or strengthen their capabilities on their own". In this paper, we thoroughly investigate the nature of information transfer within LLMs and propose a novel technique called Attention Transition. This technique empowers models to achieve longer and better context comprehension with minimal additional training or impact on generation fluency. Our experiments are conducted in XSu
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#26799;&#24230;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#30740;&#31350;&#21457;&#29616;&#24605;&#32500;&#38142;&#21551;&#21457;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24182;&#27809;&#26377;&#22686;&#21152;&#19982;&#35821;&#20041;&#30456;&#20851;&#26631;&#35760;&#30340;&#37325;&#35201;&#24615;&#65292;&#20294;&#25552;&#39640;&#20102;&#19982;&#38382;&#39064;&#30456;&#20851;&#26631;&#35760;&#30340;&#37325;&#35201;&#24615;&#20998;&#25968;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.13339</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#26799;&#24230;&#30340;&#29305;&#24449;&#24402;&#22240;&#20998;&#26512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24605;&#32500;&#38142;&#21551;&#21457;
&lt;/p&gt;
&lt;p&gt;
Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions. (arXiv:2307.13339v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13339
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#26799;&#24230;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#30740;&#31350;&#21457;&#29616;&#24605;&#32500;&#38142;&#21551;&#21457;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24182;&#27809;&#26377;&#22686;&#21152;&#19982;&#35821;&#20041;&#30456;&#20851;&#26631;&#35760;&#30340;&#37325;&#35201;&#24615;&#65292;&#20294;&#25552;&#39640;&#20102;&#19982;&#38382;&#39064;&#30456;&#20851;&#26631;&#35760;&#30340;&#37325;&#35201;&#24615;&#20998;&#25968;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#38382;&#31572;&#20219;&#21153;&#20013;&#65292;&#24050;&#32463;&#35777;&#26126;&#24605;&#32500;&#38142;&#21551;&#21457;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#26041;&#38754;&#26377;&#23454;&#38469;&#30340;&#25913;&#21892;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#30830;&#20445;&#36825;&#31181;&#29616;&#35937;&#26159;&#26399;&#26395;&#30340;&#27169;&#22411;&#34892;&#20026;&#30340;&#32467;&#26524;&#65292;&#29702;&#35299;&#20026;&#20309;&#24605;&#32500;&#38142;&#21551;&#21457;&#26377;&#25928;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#26159;&#30446;&#21069;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#20102;&#34913;&#37327;&#36755;&#20837;&#26631;&#35760;&#23545;&#27169;&#22411;&#36755;&#20986;&#24433;&#21709;&#30340;&#37325;&#35201;&#24615;&#20998;&#25968;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#20960;&#20010;&#24320;&#28304;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#30740;&#31350;&#24605;&#32500;&#38142;&#21551;&#21457;&#26159;&#21542;&#20250;&#24433;&#21709;&#23427;&#20204;&#20998;&#37197;&#32473;&#29305;&#23450;&#36755;&#20837;&#26631;&#35760;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#26631;&#20934;&#30340;&#23569;&#26679;&#26412;&#21551;&#21457;&#30456;&#27604;&#65292;&#24605;&#32500;&#38142;&#21551;&#21457;&#24182;&#26410;&#22686;&#21152;&#20998;&#37197;&#32473;&#35821;&#20041;&#30456;&#20851;&#26631;&#35760;&#30340;&#37325;&#35201;&#24615;&#20998;&#25968;&#30340;&#22823;&#23567;&#65292;&#20294;&#23427;&#25552;&#39640;&#20102;&#20998;&#37197;&#32473;&#38382;&#39064;&#30456;&#20851;&#26631;&#35760;&#30340;&#37325;&#35201;&#24615;&#20998;&#25968;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks. While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment. We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output. Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens. Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to quest
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27861;&#24459;&#26696;&#20214;&#26816;&#32034;&#30340;&#24847;&#22270;&#20998;&#31867;&#27861;&#65292;&#22312;&#26126;&#30830;&#20102;&#27861;&#24459;&#26816;&#32034;&#29992;&#25143;&#30340;&#28508;&#22312;&#25628;&#32034;&#24847;&#22270;&#26356;&#21152;&#22797;&#26434;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20116;&#31181;&#24847;&#22270;&#31867;&#22411;&#36827;&#34892;&#20998;&#31867;&#12290;&#35813;&#20998;&#31867;&#27861;&#32463;&#36807;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#25581;&#31034;&#20102;&#29992;&#25143;&#34892;&#20026;&#21644;&#28385;&#24847;&#24230;&#26041;&#38754;&#30340;&#26174;&#33879;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2307.13298</link><description>&lt;p&gt;
&#27861;&#24459;&#26696;&#20214;&#26816;&#32034;&#30340;&#24847;&#22270;&#20998;&#31867;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Intent Taxonomy of Legal Case Retrieval. (arXiv:2307.13298v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27861;&#24459;&#26696;&#20214;&#26816;&#32034;&#30340;&#24847;&#22270;&#20998;&#31867;&#27861;&#65292;&#22312;&#26126;&#30830;&#20102;&#27861;&#24459;&#26816;&#32034;&#29992;&#25143;&#30340;&#28508;&#22312;&#25628;&#32034;&#24847;&#22270;&#26356;&#21152;&#22797;&#26434;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20116;&#31181;&#24847;&#22270;&#31867;&#22411;&#36827;&#34892;&#20998;&#31867;&#12290;&#35813;&#20998;&#31867;&#27861;&#32463;&#36807;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#25581;&#31034;&#20102;&#29992;&#25143;&#34892;&#20026;&#21644;&#28385;&#24847;&#24230;&#26041;&#38754;&#30340;&#26174;&#33879;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27861;&#24459;&#26696;&#20214;&#26816;&#32034;&#26159;&#19968;&#39033;&#29305;&#27530;&#30340;&#20449;&#24687;&#26816;&#32034;&#20219;&#21153;&#65292;&#20851;&#27880;&#30340;&#26159;&#27861;&#24459;&#26696;&#20214;&#25991;&#20214;&#12290;&#26681;&#25454;&#26816;&#32034;&#21040;&#30340;&#26696;&#20214;&#25991;&#20214;&#30340;&#19979;&#28216;&#20219;&#21153;&#21644;&#29992;&#25143;&#30340;&#20449;&#24687;&#38656;&#27714;&#65292;&#27861;&#24459;&#26696;&#20214;&#26816;&#32034;&#20013;&#30340;&#20449;&#24687;&#38656;&#27714;&#19982;&#32593;&#32476;&#25628;&#32034;&#21644;&#20256;&#32479;&#30340;&#33258;&#36866;&#24212;&#26816;&#32034;&#20219;&#21153;&#21487;&#33021;&#20250;&#26377;&#26174;&#33879;&#30340;&#21306;&#21035;&#12290;&#34429;&#28982;&#26377;&#20960;&#39033;&#30740;&#31350;&#26681;&#25454;&#25991;&#26412;&#30456;&#20284;&#24615;&#26469;&#26816;&#32034;&#27861;&#24459;&#26696;&#20214;&#65292;&#20294;&#20316;&#20026;&#26412;&#25991;&#25152;&#31034;&#65292;&#27861;&#24459;&#26816;&#32034;&#29992;&#25143;&#30340;&#28508;&#22312;&#25628;&#32034;&#24847;&#22270;&#26356;&#21152;&#22797;&#26434;&#65292;&#20294;&#22823;&#37096;&#20998;&#23578;&#26410;&#25506;&#32034;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27861;&#24459;&#26696;&#20214;&#26816;&#32034;&#30340;&#24847;&#22270;&#20998;&#31867;&#27861;&#12290;&#23427;&#30001;&#20116;&#31181;&#24847;&#22270;&#31867;&#22411;&#32452;&#25104;&#65292;&#26681;&#25454;&#19977;&#20010;&#26631;&#20934;&#36827;&#34892;&#20998;&#31867;&#65292;&#21363;&#25628;&#32034;&#29305;&#23450;&#26696;&#20363;&#65292;&#29305;&#24449;&#25551;&#36848;&#65292;&#22788;&#32602;&#65292;&#31243;&#24207;&#21644;&#21033;&#30410;&#12290;&#35813;&#20998;&#31867;&#27861;&#36890;&#36807;&#36879;&#26126;&#30340;&#26500;&#24314;&#21644;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#21253;&#25324;&#35775;&#35848;&#12289;&#32534;&#36753;&#29992;&#25143;&#30740;&#31350;&#21644;&#26597;&#35810;&#26085;&#24535;&#20998;&#26512;&#12290;&#36890;&#36807;&#23454;&#39564;&#23460;&#29992;&#25143;&#30740;&#31350;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#29992;&#25143;&#34892;&#20026;&#21644;&#28385;&#24847;&#24230;&#26041;&#38754;&#30340;&#26174;&#33879;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Legal case retrieval is a special Information Retrieval~(IR) task focusing on legal case documents. Depending on the downstream tasks of the retrieved case documents, users' information needs in legal case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks. While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of legal case retrieval. It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest. The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis. Through a laboratory user study, we reveal significant differences in user behavior and sati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;LoRA&#32452;&#21512;&#22312;&#36328;&#20219;&#21153;&#36890;&#29992;&#24615;&#19978;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;LoraHub&#26694;&#26550;&#65292;&#33021;&#22815;&#36890;&#36807;&#32452;&#21512;&#19981;&#21516;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;LoRA&#27169;&#22359;&#65292;&#23454;&#29616;&#23545;&#26410;&#35265;&#20219;&#21153;&#30340;&#21487;&#36866;&#24212;&#24615;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;LoraHub&#22312;&#23569;&#26679;&#26412;&#22330;&#26223;&#20013;&#33021;&#22815;&#26377;&#25928;&#27169;&#25311;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#19978;&#19979;&#25991;&#31034;&#20363;&#12290;</title><link>http://arxiv.org/abs/2307.13269</link><description>&lt;p&gt;
LoraHub: &#36890;&#36807;&#21160;&#24577;LoRA&#32452;&#21512;&#23454;&#29616;&#39640;&#25928;&#30340;&#20219;&#21153;&#36890;&#29992;&#24615;
&lt;/p&gt;
&lt;p&gt;
LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition. (arXiv:2307.13269v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;LoRA&#32452;&#21512;&#22312;&#36328;&#20219;&#21153;&#36890;&#29992;&#24615;&#19978;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;LoraHub&#26694;&#26550;&#65292;&#33021;&#22815;&#36890;&#36807;&#32452;&#21512;&#19981;&#21516;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;LoRA&#27169;&#22359;&#65292;&#23454;&#29616;&#23545;&#26410;&#35265;&#20219;&#21153;&#30340;&#21487;&#36866;&#24212;&#24615;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;LoraHub&#22312;&#23569;&#26679;&#26412;&#22330;&#26223;&#20013;&#33021;&#22815;&#26377;&#25928;&#27169;&#25311;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#19978;&#19979;&#25991;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#24120;&#24120;&#34987;&#29992;&#20110;&#23545;&#26032;&#20219;&#21153;&#36827;&#34892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#24494;&#35843;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;LoRA&#32452;&#21512;&#22312;&#36328;&#20219;&#21153;&#36890;&#29992;&#24615;&#19978;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#20171;&#32461;&#20102;LoraHub&#65292;&#36825;&#26159;&#19968;&#20010;&#20026;&#30446;&#30340;&#24615;&#32452;&#35013;&#22312;&#19981;&#21516;&#32473;&#23450;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;LoRA&#27169;&#22359;&#30340;&#25112;&#30053;&#26694;&#26550;&#65292;&#26088;&#22312;&#23454;&#29616;&#23545;&#26410;&#35265;&#20219;&#21153;&#30340;&#21487;&#36866;&#24212;&#24615;&#24615;&#33021;&#12290;&#20165;&#20973;&#20511;&#26469;&#33258;&#26032;&#20219;&#21153;&#30340;&#20960;&#20010;&#31034;&#20363;&#65292;LoraHub&#21487;&#20197;&#28789;&#27963;&#22320;&#32452;&#21512;&#22810;&#20010;LoRA&#27169;&#22359;&#65292;&#28040;&#38500;&#20102;&#23545;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#30340;&#38656;&#27714;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#31181;&#32452;&#21512;&#26082;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#27169;&#22411;&#21442;&#25968;&#65292;&#20063;&#19981;&#38656;&#35201;&#26799;&#24230;&#12290;&#25105;&#20204;&#20174;Big-Bench Hard&#65288;BBH&#65289;&#22522;&#20934;&#27979;&#35797;&#20013;&#24471;&#20986;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;LoraHub&#22312;&#23569;&#26679;&#26412;&#22330;&#26223;&#20013;&#21487;&#20197;&#26377;&#25928;&#22320;&#27169;&#25311;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#22312;&#27599;&#20010;&#25512;&#29702;&#36755;&#20837;&#26049;&#36793;&#19981;&#38656;&#35201;&#19978;&#19979;&#25991;&#31034;&#20363;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#30340;&#19968;&#20010;&#37325;&#35201;&#36129;&#29486;&#26159;&#22521;&#32946;&#19968;&#20010;LoRA&#31038;&#21306;&#65292;&#29992;&#25143;&#21487;&#20197;&#22312;&#20854;&#20013;&#20998;&#20139;&#20182;&#20204;&#35757;&#32451;&#30340;LoRA&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks. This paper investigates LoRA composability for cross-task generalization and introduces LoraHub, a strategic framework devised for the purposive assembly of LoRA modules trained on diverse given tasks, with the objective of achieving adaptable performance on unseen tasks. With just a few examples from a novel task, LoraHub enables the fluid combination of multiple LoRA modules, eradicating the need for human expertise. Notably, the composition requires neither additional model parameters nor gradients. Our empirical results, derived from the Big-Bench Hard (BBH) benchmark, suggest that LoraHub can effectively mimic the performance of in-context learning in few-shot scenarios, excluding the necessity of in-context examples alongside each inference input. A significant contribution of our research is the fostering of a community for LoRA, where users can share their trained LoRA module
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#25968;&#25454;&#20013;&#29983;&#25104;&#21487;&#25191;&#34892;&#30340;&#27934;&#23519;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#30340;&#21453;&#39304;&#23545;&#27934;&#23519;&#36827;&#34892;&#25490;&#24207;&#65292;&#23637;&#31034;&#20102;&#20854;&#36866;&#24212;&#21453;&#39304;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.13176</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#24335;&#30340;&#34892;&#21160;&#27934;&#23519;&#29983;&#25104;&#21644;&#26234;&#33021;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Schema-Driven Actionable Insight Generation and Smart Recommendation. (arXiv:2307.13176v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#25968;&#25454;&#20013;&#29983;&#25104;&#21487;&#25191;&#34892;&#30340;&#27934;&#23519;&#65292;&#24182;&#26681;&#25454;&#29992;&#25143;&#30340;&#21453;&#39304;&#23545;&#27934;&#23519;&#36827;&#34892;&#25490;&#24207;&#65292;&#23637;&#31034;&#20102;&#20854;&#36866;&#24212;&#21453;&#39304;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#65288;NLG&#65289;&#20013;&#65292;&#27934;&#23519;&#25366;&#25496;&#34987;&#35270;&#20026;&#19968;&#31181;&#23558;&#25968;&#25454;&#36716;&#21270;&#20026;&#25991;&#26412;&#30340;&#20219;&#21153;&#65292;&#20854;&#20013;&#25968;&#25454;&#34987;&#25366;&#25496;&#20197;&#23547;&#25214;&#26377;&#36259;&#30340;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#21475;&#22836;&#21270;&#36716;&#21270;&#20026;&#8220;&#27934;&#23519;&#8221;&#38472;&#36848;&#12290;&#19968;&#20010;&#8220;&#36807;&#37327;&#29983;&#25104;&#21644;&#25490;&#24207;&#8221;&#30340;&#33539;&#24335;&#34987;&#30452;&#35266;&#22320;&#29992;&#20110;&#29983;&#25104;&#36825;&#20123;&#27934;&#23519;&#12290;&#36825;&#20010;&#36807;&#31243;&#30340;&#22810;&#32500;&#24230;&#21644;&#20027;&#35266;&#24615;&#20351;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#30340;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#20174;&#25968;&#25454;&#21040;&#25512;&#21160;&#22686;&#38271;&#21644;&#21464;&#38761;&#30340;&#21487;&#25191;&#34892;&#27934;&#23519;&#12290;&#23427;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#36890;&#36807;&#29992;&#25143;&#21453;&#39304;&#26469;&#19982;&#29992;&#25143;&#20852;&#36259;&#20445;&#25345;&#19968;&#33268;&#30340;&#25490;&#24207;&#27934;&#23519;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#25105;&#20204;&#30340;&#25216;&#26415;&#29983;&#25104;&#30340;&#27934;&#23519;&#30340;&#21021;&#27493;&#23450;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#36866;&#24212;&#21453;&#39304;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In natural language generation (NLG), insight mining is seen as a data-to-text task, where data is mined for interesting patterns and verbalised into 'insight' statements. An 'over-generate and rank' paradigm is intuitively used to generate such insights. The multidimensionality and subjectivity of this process make it challenging. This paper introduces a schema-driven method to generate actionable insights from data to drive growth and change. It also introduces a technique to rank the insights to align with user interests based on their feedback. We show preliminary qualitative results of the insights generated using our technique and demonstrate its ability to adapt to feedback.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32463;&#36807;&#35843;&#25972;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35266;&#28857;&#25366;&#25496;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#29305;&#23450;&#25968;&#25454;&#30340;&#24494;&#35843;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23398;&#20064;&#21644;&#36716;&#31227;&#35266;&#28857;&#65292;&#24182;&#20445;&#25345;&#26497;&#24615;&#30340;&#27604;&#20363;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25366;&#25496;&#30495;&#23454;&#25991;&#26412;&#20013;&#30340;&#35266;&#28857;&#27934;&#23519;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.13173</link><description>&lt;p&gt;
&#20351;&#29992;&#32463;&#36807;&#20154;&#32676;&#35843;&#25972;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35266;&#28857;&#25366;&#25496;
&lt;/p&gt;
&lt;p&gt;
Opinion Mining Using Population-tuned Generative Language Models. (arXiv:2307.13173v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32463;&#36807;&#35843;&#25972;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35266;&#28857;&#25366;&#25496;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#29305;&#23450;&#25968;&#25454;&#30340;&#24494;&#35843;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23398;&#20064;&#21644;&#36716;&#31227;&#35266;&#28857;&#65292;&#24182;&#20445;&#25345;&#26497;&#24615;&#30340;&#27604;&#20363;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25366;&#25496;&#30495;&#23454;&#25991;&#26412;&#20013;&#30340;&#35266;&#28857;&#27934;&#23519;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#35757;&#32451;&#20110;&#19981;&#21516;&#20154;&#32676;&#25968;&#25454;&#19978;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#20174;&#25991;&#26412;&#38598;&#21512;&#20013;&#25366;&#25496;&#35266;&#28857;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22522;&#26412;&#23450;&#20041;&#12289;&#26041;&#27861;&#35770;&#21644;&#35266;&#28857;&#27934;&#23519;&#25366;&#25496;&#30340;&#36890;&#29992;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65306;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#29983;&#25104;&#24335;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#29305;&#23450;&#30340;&#23450;&#21046;&#20869;&#23481;&#21644;&#23436;&#20840;&#26631;&#27880;&#30340;&#35266;&#28857;&#23545;&#20854;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23398;&#20064;&#21644;&#36716;&#31227;&#35266;&#28857;&#21040;&#35821;&#20041;&#31867;&#21035;&#65292;&#24182;&#20445;&#25345;&#26497;&#24615;&#30340;&#27604;&#20363;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#27934;&#23519;&#25366;&#25496;&#31995;&#32479;&#22312;&#23454;&#38469;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#21457;&#29616;&#35266;&#28857;&#27934;&#23519;&#30340;&#25193;&#23637;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel method for mining opinions from text collections using generative language models trained on data collected from different populations. We describe the basic definitions, methodology and a generic algorithm for opinion insight mining. We demonstrate the performance of our method in an experiment where a pre-trained generative model is fine-tuned using specifically tailored content with unnatural and fully annotated opinions. We show that our approach can learn and transfer the opinions to the semantic classes while maintaining the proportion of polarisation. Finally, we demonstrate the usage of an insight mining system to scale up the discovery of opinion insights from a real text corpus.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#21160;&#21270;&#25968;&#23398;&#35789;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#24037;&#20316;&#21407;&#29702;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#27714;&#35299;&#22120;&#21487;&#33021;&#20381;&#36182;&#20110;&#34920;&#38754;&#27169;&#24335;&#32780;&#19981;&#26159;&#25968;&#23398;&#35821;&#20041;&#36923;&#36753;&#26469;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.13128</link><description>&lt;p&gt;
&#35299;&#37322;&#25968;&#23398;&#35789;&#38382;&#39064;&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
Explaining Math Word Problem Solvers. (arXiv:2307.13128v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13128
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#21160;&#21270;&#25968;&#23398;&#35789;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#24037;&#20316;&#21407;&#29702;&#65292;&#24182;&#21457;&#29616;&#36825;&#20123;&#27714;&#35299;&#22120;&#21487;&#33021;&#20381;&#36182;&#20110;&#34920;&#38754;&#27169;&#24335;&#32780;&#19981;&#26159;&#25968;&#23398;&#35821;&#20041;&#36923;&#36753;&#26469;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#21160;&#21270;&#25968;&#23398;&#35789;&#38382;&#39064;&#27714;&#35299;&#22120;&#24050;&#25104;&#21151;&#22320;&#22312;&#35299;&#20915;&#31639;&#26415;&#35789;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102;70-80&#65285;&#30340;&#20934;&#30830;&#29575;&#12290;&#28982;&#32780;&#65292;&#30740;&#31350;&#34920;&#26126;&#36825;&#20123;&#27714;&#35299;&#22120;&#21487;&#33021;&#20381;&#36182;&#20110;&#34920;&#38754;&#27169;&#24335;&#26469;&#33719;&#24471;&#23427;&#20204;&#30340;&#26041;&#31243;&#24335;&#12290;&#20026;&#20102;&#30830;&#23450;&#25968;&#23398;&#35789;&#38382;&#39064;&#27714;&#35299;&#22120;&#20351;&#29992;&#21738;&#20123;&#20449;&#24687;&#26469;&#29983;&#25104;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#21435;&#38500;&#36755;&#20837;&#30340;&#37096;&#20998;&#20869;&#23481;&#65292;&#24182;&#27979;&#37327;&#27169;&#22411;&#22312;&#25200;&#21160;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#27169;&#22411;&#23545;&#20110;&#20174;&#36755;&#20837;&#20013;&#21435;&#38500;&#35768;&#22810;&#21333;&#35789;&#24182;&#20173;&#28982;&#33021;&#22815;&#22312;&#32473;&#20986;&#26080;&#24847;&#20041;&#38382;&#39064;&#26102;&#25214;&#21040;&#27491;&#30830;&#31572;&#26696;&#24182;&#19981;&#25935;&#24863;&#12290;&#36825;&#34920;&#26126;&#33258;&#21160;&#21270;&#27714;&#35299;&#22120;&#24182;&#26410;&#36981;&#24490;&#25968;&#23398;&#35789;&#38382;&#39064;&#30340;&#35821;&#20041;&#36923;&#36753;&#65292;&#24182;&#19988;&#21487;&#33021;&#36807;&#24230;&#25311;&#21512;&#29305;&#23450;&#21333;&#35789;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated math word problem solvers based on neural networks have successfully managed to obtain 70-80\% accuracy in solving arithmetic word problems. However, it has been shown that these solvers may rely on superficial patterns to obtain their equations. In order to determine what information math word problem solvers use to generate solutions, we remove parts of the input and measure the model's performance on the perturbed dataset. Our results show that the model is not sensitive to the removal of many words from the input and can still manage to find a correct answer when given a nonsense question. This indicates that automatic solvers do not follow the semantic logic of math word problems, and may be overfitting to the presence of specific words.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#20351;&#29992;LLMs&#36827;&#34892;&#25991;&#26412;&#20998;&#26512;&#65292;LLMs&#20316;&#20026;&#19968;&#31181;&#38750;&#24120;&#22810;&#21151;&#33021;&#30340;&#25991;&#26412;&#20998;&#26512;&#26041;&#27861;&#22312;&#31038;&#20250;&#31185;&#23398;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;&#20351;&#29992;LLMs&#21487;&#20197;&#23454;&#29616;&#20174;&#25991;&#26412;&#26631;&#27880;&#21644;&#20998;&#31867;&#21040;&#24773;&#24863;&#20998;&#26512;&#21644;&#25209;&#21028;&#24615;&#35805;&#35821;&#20998;&#26512;&#31561;&#22810;&#31181;&#20219;&#21153;&#65292;&#24182;&#19988;&#26131;&#20110;&#20351;&#29992;&#19988;&#36895;&#24230;&#24555;&#12290;&#36825;&#23545;&#20110;&#20855;&#26377;&#26377;&#38480;&#32534;&#31243;&#32463;&#39564;&#30340;&#23398;&#29983;&#21644;&#30740;&#31350;&#32773;&#26469;&#35828;&#23588;&#20854;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.13106</link><description>&lt;p&gt;
&#22914;&#20309;&#20351;&#29992;LLMs&#36827;&#34892;&#25991;&#26412;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
How to use LLMs for Text Analysis. (arXiv:2307.13106v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13106
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#20351;&#29992;LLMs&#36827;&#34892;&#25991;&#26412;&#20998;&#26512;&#65292;LLMs&#20316;&#20026;&#19968;&#31181;&#38750;&#24120;&#22810;&#21151;&#33021;&#30340;&#25991;&#26412;&#20998;&#26512;&#26041;&#27861;&#22312;&#31038;&#20250;&#31185;&#23398;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;&#20351;&#29992;LLMs&#21487;&#20197;&#23454;&#29616;&#20174;&#25991;&#26412;&#26631;&#27880;&#21644;&#20998;&#31867;&#21040;&#24773;&#24863;&#20998;&#26512;&#21644;&#25209;&#21028;&#24615;&#35805;&#35821;&#20998;&#26512;&#31561;&#22810;&#31181;&#20219;&#21153;&#65292;&#24182;&#19988;&#26131;&#20110;&#20351;&#29992;&#19988;&#36895;&#24230;&#24555;&#12290;&#36825;&#23545;&#20110;&#20855;&#26377;&#26377;&#38480;&#32534;&#31243;&#32463;&#39564;&#30340;&#23398;&#29983;&#21644;&#30740;&#31350;&#32773;&#26469;&#35828;&#23588;&#20854;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25351;&#21335;&#20171;&#32461;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20316;&#20026;&#31038;&#20250;&#31185;&#23398;&#20013;&#19968;&#31181;&#38750;&#24120;&#22810;&#21151;&#33021;&#30340;&#25991;&#26412;&#20998;&#26512;&#26041;&#27861;&#12290;&#30001;&#20110;LLMs&#26131;&#20110;&#20351;&#29992;&#12289;&#25104;&#26412;&#20302;&#12289;&#36895;&#24230;&#24555;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25991;&#26412;&#20998;&#26512;&#20219;&#21153;&#65292;&#20174;&#25991;&#26412;&#26631;&#27880;&#21644;&#20998;&#31867;&#21040;&#24773;&#24863;&#20998;&#26512;&#21644;&#25209;&#21028;&#24615;&#35805;&#35821;&#20998;&#26512;&#65292;&#35768;&#22810;&#23398;&#32773;&#35748;&#20026;LLMs&#23558;&#25913;&#21464;&#25105;&#20204;&#36827;&#34892;&#25991;&#26412;&#20998;&#26512;&#30340;&#26041;&#24335;&#12290;&#26412;&#25351;&#21335;&#38754;&#21521;&#20855;&#26377;&#26377;&#38480;&#32534;&#31243;&#32463;&#39564;&#30340;&#23398;&#29983;&#21644;&#30740;&#31350;&#32773;&#65292;&#24182;&#25552;&#20379;&#20102;&#22914;&#20309;&#22312;&#33258;&#24049;&#30340;&#30740;&#31350;&#39033;&#30446;&#20013;&#20351;&#29992;LLMs&#36827;&#34892;&#25991;&#26412;&#20998;&#26512;&#30340;&#31616;&#21333;&#20171;&#32461;&#65292;&#20197;&#21450;&#26368;&#20339;&#23454;&#36341;&#24314;&#35758;&#12290;&#25105;&#20204;&#23558;&#20351;&#29992;Python&#28436;&#31034;&#20351;&#29992;LLMs&#20998;&#26512;&#25991;&#26412;&#25968;&#25454;&#30340;&#27599;&#20010;&#27493;&#39588;&#65306;&#23433;&#35013;&#36719;&#20214;&#65292;&#35774;&#32622;API&#65292;&#21152;&#36733;&#25968;&#25454;&#65292;&#24320;&#21457;&#20998;&#26512;&#25552;&#31034;&#65292;&#20998;&#26512;&#25991;&#26412;&#21644;&#39564;&#35777;&#32467;&#26524;&#12290;&#20316;&#20026;&#19968;&#20010;&#35828;&#26126;&#24615;&#20363;&#23376;&#65292;&#25105;&#20204;&#23558;&#20351;&#29992;&#22312;&#25919;&#27835;&#25991;&#26412;&#20013;&#35782;&#21035;&#27665;&#31929;&#20027;&#20041;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;LLMs&#22914;&#20309;&#36229;&#36234;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This guide introduces Large Language Models (LLM) as a highly versatile text analysis method within the social sciences. As LLMs are easy-to-use, cheap, fast, and applicable on a broad range of text analysis tasks, ranging from text annotation and classification to sentiment analysis and critical discourse analysis, many scholars believe that LLMs will transform how we do text analysis. This how-to guide is aimed at students and researchers with limited programming experience, and offers a simple introduction to how LLMs can be used for text analysis in your own research project, as well as advice on best practices. We will go through each of the steps of analyzing textual data with LLMs using Python: installing the software, setting up the API, loading the data, developing an analysis prompt, analyzing the text, and validating the results. As an illustrative example, we will use the challenging task of identifying populism in political texts, and show how LLMs move beyond the existing
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAIRMetaText&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#31243;&#24207;&#65292;&#29992;&#20110;&#27604;&#36739;&#20803;&#25968;&#25454;&#12290;&#35813;&#24212;&#29992;&#31243;&#24207;&#20998;&#26512;&#20803;&#25968;&#25454;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#65292;&#24182;&#25552;&#20379;&#25968;&#23398;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#21487;&#29992;&#20110;&#20998;&#26512;&#21644;&#35782;&#21035;&#21487;&#26367;&#20195;&#26415;&#35821;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23569;&#20154;&#21147;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2307.13085</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20351;&#20803;&#25968;&#25454;&#26356;&#21152;FAIR
&lt;/p&gt;
&lt;p&gt;
Making Metadata More FAIR Using Large Language Models. (arXiv:2307.13085v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAIRMetaText&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#31243;&#24207;&#65292;&#29992;&#20110;&#27604;&#36739;&#20803;&#25968;&#25454;&#12290;&#35813;&#24212;&#29992;&#31243;&#24207;&#20998;&#26512;&#20803;&#25968;&#25454;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#65292;&#24182;&#25552;&#20379;&#25968;&#23398;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#21487;&#29992;&#20110;&#20998;&#26512;&#21644;&#35782;&#21035;&#21487;&#26367;&#20195;&#26415;&#35821;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23569;&#20154;&#21147;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20840;&#29699;&#23454;&#39564;&#25968;&#25454;&#36164;&#26009;&#30340;&#22686;&#21152;&#65292;&#32479;&#19968;&#21033;&#29992;&#36825;&#20123;&#36164;&#26009;&#30340;&#19968;&#20010;&#20027;&#35201;&#38556;&#30861;&#26159;&#31967;&#31957;&#30340;&#20803;&#25968;&#25454;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FAIRMetaText&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24212;&#29992;&#31243;&#24207;&#65292;&#29992;&#20110;&#27604;&#36739;&#20803;&#25968;&#25454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;FAIRMetaText&#20998;&#26512;&#20803;&#25968;&#25454;&#30340;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#65292;&#24182;&#25552;&#20379;&#20004;&#20010;&#26415;&#35821;&#20043;&#38388;&#30340;&#25968;&#23398;&#30456;&#20284;&#24230;&#24230;&#37327;&#12290;&#36825;&#20010;&#24230;&#37327;&#21487;&#20197;&#29992;&#20110;&#20998;&#26512;&#19981;&#21516;&#30340;&#20803;&#25968;&#25454;&#65292;&#36890;&#36807;&#24314;&#35758;&#31526;&#21512;&#24615;&#26415;&#35821;&#25110;&#20998;&#32452;&#30456;&#20284;&#26415;&#35821;&#26469;&#35782;&#21035;&#21487;&#26367;&#20195;&#26415;&#35821;&#12290;&#36890;&#36807;&#22312;&#20844;&#24320;&#30340;&#30740;&#31350;&#36164;&#26009;&#19978;&#36827;&#34892;&#28145;&#20837;&#30740;&#31350;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21508;&#31181;&#20803;&#25968;&#25454;&#30456;&#20851;&#20219;&#21153;&#19978;&#23450;&#24615;&#21644;&#23450;&#37327;&#22320;&#23637;&#31034;&#20102;&#35813;&#31639;&#27861;&#30340;&#25928;&#26524;&#12290;&#36825;&#20010;&#36719;&#20214;&#21487;&#20197;&#26497;&#22823;&#22320;&#20943;&#23569;&#20154;&#21147;&#25104;&#26412;&#65292;&#21516;&#26102;&#21033;&#29992;&#22810;&#31181;&#23454;&#39564;&#25968;&#25454;&#36807;&#31243;&#20013;&#31579;&#36873;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#20803;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the global increase in experimental data artifacts, harnessing them in a unified fashion leads to a major stumbling block - bad metadata. To bridge this gap, this work presents a Natural Language Processing (NLP) informed application, called FAIRMetaText, that compares metadata. Specifically, FAIRMetaText analyzes the natural language descriptions of metadata and provides a mathematical similarity measure between two terms. This measure can then be utilized for analyzing varied metadata, by suggesting terms for compliance or grouping similar terms for identification of replaceable terms. The efficacy of the algorithm is presented qualitatively and quantitatively on publicly available research artifacts and demonstrates large gains across metadata related tasks through an in-depth study of a wide variety of Large Language Models (LLMs). This software can drastically reduce the human effort in sifting through various natural language metadata while employing several experimental dat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;LLM&#36827;&#34892;&#20302;&#36164;&#28304;&#21644;&#39046;&#22495;&#29305;&#23450;&#32534;&#31243;&#35821;&#35328;&#32534;&#30721;&#30340;&#21487;&#34892;&#24615;&#65292;&#21457;&#29616;LLM&#21487;&#20197;&#29992;&#20110;&#25913;&#36827;gretl&#20195;&#30721;&#65292;&#24182;&#29983;&#25104;&#25551;&#36848;&#24615;&#30340;&#25991;&#26723;&#23383;&#31526;&#20018;&#21644;&#31934;&#30830;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;LLM&#22312;&#26576;&#20123;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#22914;&#26080;&#27861;&#25913;&#21892;&#26576;&#20123;&#20195;&#30721;&#27573;&#21644;&#32534;&#20889;&#20934;&#30830;&#30340;&#21333;&#20803;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2307.13018</link><description>&lt;p&gt;
LLM&#22312;&#20302;&#36164;&#28304;&#21644;&#39046;&#22495;&#29305;&#23450;&#32534;&#31243;&#35821;&#35328;&#32534;&#30721;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
The potential of LLMs for coding with low-resource and domain-specific programming languages. (arXiv:2307.13018v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;LLM&#36827;&#34892;&#20302;&#36164;&#28304;&#21644;&#39046;&#22495;&#29305;&#23450;&#32534;&#31243;&#35821;&#35328;&#32534;&#30721;&#30340;&#21487;&#34892;&#24615;&#65292;&#21457;&#29616;LLM&#21487;&#20197;&#29992;&#20110;&#25913;&#36827;gretl&#20195;&#30721;&#65292;&#24182;&#29983;&#25104;&#25551;&#36848;&#24615;&#30340;&#25991;&#26723;&#23383;&#31526;&#20018;&#21644;&#31934;&#30830;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;LLM&#22312;&#26576;&#20123;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#22914;&#26080;&#27861;&#25913;&#21892;&#26576;&#20123;&#20195;&#30721;&#27573;&#21644;&#32534;&#20889;&#20934;&#30830;&#30340;&#21333;&#20803;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#20302;&#36164;&#28304;&#21644;&#39046;&#22495;&#29305;&#23450;&#30340;&#32534;&#31243;&#35821;&#35328;&#20013;&#36827;&#34892;&#32534;&#30721;&#30340;&#21487;&#34892;&#24615;&#12290;&#36825;&#20123;&#32534;&#31243;&#35821;&#35328;&#36890;&#24120;&#32570;&#20047;&#26377;&#25928;&#30340;LLM&#22788;&#29702;&#25216;&#26415;&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#12290;&#26412;&#30740;&#31350;&#19987;&#27880;&#20110;&#24320;&#28304;&#36719;&#20214;gretl&#30340;&#35745;&#37327;&#33050;&#26412;&#35821;&#35328;hansl&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;GPT-3.5&#30340;&#19987;&#26377;LLM&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;LLM&#21487;&#20197;&#25104;&#20026;&#32534;&#20889;&#12289;&#29702;&#35299;&#12289;&#25913;&#36827;&#21644;&#25991;&#26723;&#21270;gretl&#20195;&#30721;&#30340;&#26377;&#29992;&#24037;&#20855;&#65292;&#20854;&#20013;&#21253;&#25324;&#20026;&#20989;&#25968;&#29983;&#25104;&#25551;&#36848;&#24615;&#30340;&#25991;&#26723;&#23383;&#31526;&#20018;&#65292;&#24182;&#20026;&#25277;&#35937;&#21644;&#25991;&#26723;&#19981;&#23436;&#22791;&#30340;&#35745;&#37327;&#20195;&#30721;&#25552;&#20379;&#31934;&#30830;&#30340;&#35299;&#37322;&#12290;&#23613;&#31649;LLM&#23637;&#31034;&#20102;&#23383;&#31526;&#20018;&#21040;&#20195;&#30721;&#32763;&#35793;&#33021;&#21147;&#65292;&#20294;&#25105;&#20204;&#20063;&#21457;&#29616;&#20102;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;LLM&#26080;&#27861;&#25913;&#21892;&#26576;&#20123;&#20195;&#30721;&#27573;&#24182;&#32534;&#20889;&#20934;&#30830;&#30340;&#21333;&#20803;&#27979;&#35797;&#12290;&#36825;&#39033;&#30740;&#31350;&#26159;&#21033;&#29992;LLM&#30340;&#33021;&#21147;&#20419;&#36827;&#20302;&#36164;&#28304;&#32534;&#31243;&#35821;&#35328;&#36719;&#20214;&#24320;&#21457;&#30340;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a study on the feasibility of using large language models (LLM) for coding with low-resource and domain-specific programming languages that typically lack the amount of data required for effective LLM processing techniques. This study focuses on the econometric scripting language named hansl of the open-source software gretl and employs a proprietary LLM based on GPT-3.5. Our findings suggest that LLMs can be a useful tool for writing, understanding, improving, and documenting gretl code, which includes generating descriptive docstrings for functions and providing precise explanations for abstract and poorly documented econometric code. While the LLM showcased promoting docstring-to-code translation capability, we also identify some limitations, such as its inability to improve certain sections of code and to write accurate unit tests. This study is a step towards leveraging the power of LLMs to facilitate software development in low-resource programming languages a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#20174;&#33258;&#28982;&#35821;&#35328;&#20013;&#25552;&#21462;&#20998;&#23376;&#23646;&#24615;&#20449;&#24687;&#65292;&#36890;&#36807;&#25913;&#36827;&#25991;&#26412;&#26816;&#32034;&#21644;&#24341;&#20837;&#20998;&#23376;&#22270;&#25193;&#22686;&#31574;&#30053;&#31561;&#26041;&#27861;&#25552;&#39640;&#20102;&#23646;&#24615;&#39044;&#27979;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#30456;&#23545;&#20110;&#20165;&#22312;&#22270;&#27169;&#24577;&#19978;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;+4.26%&#30340;AUROC&#22686;&#30410;&#21644;+1.54%&#30340;&#22686;&#30410;&#12290;</title><link>http://arxiv.org/abs/2307.12996</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#20174;&#33258;&#28982;&#35821;&#35328;&#20013;&#25552;&#21462;&#20998;&#23376;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
Extracting Molecular Properties from Natural Language with Multimodal Contrastive Learning. (arXiv:2307.12996v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12996
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#22810;&#27169;&#24577;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#20174;&#33258;&#28982;&#35821;&#35328;&#20013;&#25552;&#21462;&#20998;&#23376;&#23646;&#24615;&#20449;&#24687;&#65292;&#36890;&#36807;&#25913;&#36827;&#25991;&#26412;&#26816;&#32034;&#21644;&#24341;&#20837;&#20998;&#23376;&#22270;&#25193;&#22686;&#31574;&#30053;&#31561;&#26041;&#27861;&#25552;&#39640;&#20102;&#23646;&#24615;&#39044;&#27979;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#30456;&#23545;&#20110;&#20165;&#22312;&#22270;&#27169;&#24577;&#19978;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;+4.26%&#30340;AUROC&#22686;&#30410;&#21644;+1.54%&#30340;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#29983;&#29289;&#21270;&#23398;&#20013;&#65292;&#28145;&#24230;&#23398;&#20064;&#20256;&#32479;&#19978;&#19987;&#27880;&#20110;&#20998;&#23376;&#22270;&#31070;&#32463;&#34920;&#24449;&#65307;&#28982;&#32780;&#65292;&#26368;&#36817;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#23637;&#31361;&#26174;&#20102;&#25991;&#26412;&#20013;&#25152;&#32534;&#30721;&#30340;&#31185;&#23398;&#30693;&#35782;&#37327;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#20004;&#31181;&#27169;&#24577;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#23558;&#20998;&#23376;&#23646;&#24615;&#20449;&#24687;&#20174;&#33258;&#28982;&#35821;&#35328;&#36716;&#21270;&#20026;&#22270;&#34920;&#24449;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#23558;&#31070;&#32463;&#22270;&#34920;&#24449;&#19982;&#20854;&#29305;&#24449;&#30340;&#25991;&#26412;&#25551;&#36848;&#34920;&#24449;&#23545;&#40784;&#21518;&#65292;&#23646;&#24615;&#39044;&#27979;&#24615;&#33021;&#30340;&#25552;&#21319;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#31070;&#32463;&#30456;&#20851;&#24615;&#35780;&#20998;&#31574;&#30053;&#20197;&#25913;&#36827;&#25991;&#26412;&#26816;&#32034;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#21463;&#26377;&#26426;&#21453;&#24212;&#21551;&#21457;&#30340;&#26032;&#39062;&#21512;&#27861;&#20998;&#23376;&#22270;&#25193;&#22686;&#31574;&#30053;&#65292;&#24182;&#22312;&#19979;&#28216;&#30340;MoleculeNet&#23646;&#24615;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#24615;&#33021;&#30340;&#25913;&#21892;&#12290;&#19982;&#20165;&#22312;&#22270;&#27169;&#24577;&#19978;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;+4.26%&#30340;AUROC&#22686;&#30410;&#65292;&#24182;&#19982;&#26368;&#36817;&#25552;&#20986;&#30340;&#20998;&#23376;&#22270;/&#25991;&#26412;&#23545;&#27604;&#27169;&#22411;&#30456;&#27604;&#65292;&#21462;&#24471;&#20102;+1.54%&#30340;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning in computational biochemistry has traditionally focused on molecular graphs neural representations; however, recent advances in language models highlight how much scientific knowledge is encoded in text. To bridge these two modalities, we investigate how molecular property information can be transferred from natural language to graph representations. We study property prediction performance gains after using contrastive learning to align neural graph representations with representations of textual descriptions of their characteristics. We implement neural relevance scoring strategies to improve text retrieval, introduce a novel chemically-valid molecular graph augmentation strategy inspired by organic reactions, and demonstrate improved performance on downstream MoleculeNet property classification tasks. We achieve a +4.26% AUROC gain versus models pre-trained on the graph modality alone, and a +1.54% gain compared to recently proposed molecular graph/text contrastively t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30340;&#21019;&#26032;&#26159;&#22522;&#20110;Hapax Rate&#27169;&#22411;&#24341;&#20837;&#20102;&#23545;Zipf&#21644;Heaps&#23450;&#24459;&#30340;&#20462;&#27491;&#65292;&#24182;&#21457;&#29616;&#36923;&#36753;&#27169;&#22411;&#25311;&#21512;&#25928;&#26524;&#26368;&#20248;&#12290;</title><link>http://arxiv.org/abs/2307.12896</link><description>&lt;p&gt;
&#20174;Hapax Rate&#27169;&#22411;&#23548;&#20986;&#30340;Zipf&#21644;Heaps&#23450;&#24459;&#30340;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models. (arXiv:2307.12896v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12896
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30340;&#21019;&#26032;&#26159;&#22522;&#20110;Hapax Rate&#27169;&#22411;&#24341;&#20837;&#20102;&#23545;Zipf&#21644;Heaps&#23450;&#24459;&#30340;&#20462;&#27491;&#65292;&#24182;&#21457;&#29616;&#36923;&#36753;&#27169;&#22411;&#25311;&#21512;&#25928;&#26524;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;Hapax Rate&#27169;&#22411;&#24341;&#20837;&#20102;&#23545;Zipf&#21644;Heaps&#23450;&#24459;&#30340;&#20462;&#27491;&#12290;&#25512;&#23548;&#22522;&#20110;&#20004;&#20010;&#20551;&#35774;&#65306;&#31532;&#19968;&#20010;&#20551;&#35774;&#26159;&#26631;&#20934;&#30340;&#29934;&#27169;&#22411;&#65292;&#39044;&#27979;&#36739;&#30701;&#25991;&#26412;&#30340;&#36793;&#38469;&#35789;&#39057;&#20998;&#24067;&#30475;&#36215;&#26469;&#23601;&#20687;&#26159;&#20174;&#19968;&#20010;&#32473;&#23450;&#30340;&#36739;&#38271;&#25991;&#26412;&#20013;&#30450;&#30446;&#37319;&#26679;&#35789;&#20803;&#12290;&#31532;&#20108;&#20010;&#20551;&#35774;&#20551;&#23450;Hapax&#30340;&#39057;&#29575;&#26159;&#25991;&#26412;&#22823;&#23567;&#30340;&#31616;&#21333;&#20989;&#25968;&#12290;&#35752;&#35770;&#20102;&#22235;&#20010;&#36825;&#26679;&#30340;&#20989;&#25968;&#65306;&#24120;&#25968;&#27169;&#22411;&#12289;Davis&#27169;&#22411;&#12289;&#32447;&#24615;&#27169;&#22411;&#21644;&#36923;&#36753;&#27169;&#22411;&#12290;&#32467;&#26524;&#26174;&#31034;&#36923;&#36753;&#27169;&#22411;&#25311;&#21512;&#25928;&#26524;&#26368;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
The article introduces corrections to Zipf's and Heaps' laws based on systematic models of the hapax rate. The derivation rests on two assumptions: The first one is the standard urn model which predicts that marginal frequency distributions for shorter texts look as if word tokens were sampled blindly from a given longer text. The second assumption posits that the rate of hapaxes is a simple function of the text size. Four such functions are discussed: the constant model, the Davis model, the linear model, and the logistic model. It is shown that the logistic model yields the best fit.
&lt;/p&gt;</description></item><item><title>RRAML&#26159;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#29992;&#25143;&#25552;&#20379;&#30340;&#24222;&#22823;&#25968;&#25454;&#24211;&#20013;&#30340;&#25903;&#25345;&#20449;&#24687;&#30456;&#32467;&#21512;&#12290;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#36827;&#23637;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#35299;&#20915;&#20102;&#20960;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.12798</link><description>&lt;p&gt;
RRAML: &#24378;&#21270;&#26816;&#32034;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
RRAML: Reinforced Retrieval Augmented Machine Learning. (arXiv:2307.12798v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12798
&lt;/p&gt;
&lt;p&gt;
RRAML&#26159;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#29992;&#25143;&#25552;&#20379;&#30340;&#24222;&#22823;&#25968;&#25454;&#24211;&#20013;&#30340;&#25903;&#25345;&#20449;&#24687;&#30456;&#32467;&#21512;&#12290;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#36827;&#23637;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#35299;&#20915;&#20102;&#20960;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#24443;&#24213;&#25913;&#21464;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#30456;&#20851;&#39046;&#22495;&#65292;&#22312;&#29702;&#35299;&#12289;&#29983;&#25104;&#21644;&#25805;&#20316;&#20154;&#31867;&#35821;&#35328;&#26041;&#38754;&#23637;&#31034;&#20102;&#26174;&#33879;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#22522;&#20110;API&#30340;&#25991;&#26412;&#25552;&#31034;&#25552;&#20132;&#26469;&#20351;&#29992;&#23427;&#20204;&#20250;&#23384;&#22312;&#19968;&#23450;&#30340;&#38480;&#21046;&#65292;&#21253;&#25324;&#19978;&#19979;&#25991;&#32422;&#26463;&#21644;&#22806;&#37096;&#36164;&#28304;&#30340;&#21487;&#29992;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#24378;&#21270;&#26816;&#32034;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;RRAML&#65289;&#12290;RRAML&#23558;LLMs&#30340;&#25512;&#29702;&#33021;&#21147;&#19982;&#30001;&#19987;&#29992;&#26816;&#32034;&#22120;&#20174;&#29992;&#25143;&#25552;&#20379;&#30340;&#24222;&#22823;&#25968;&#25454;&#24211;&#20013;&#26816;&#32034;&#21040;&#30340;&#25903;&#25345;&#20449;&#24687;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20960;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#23427;&#32469;&#36807;&#20102;&#35775;&#38382;LLM&#26799;&#24230;&#30340;&#38656;&#27714;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20943;&#36731;&#20102;&#38024;&#23545;&#29305;&#23450;&#20219;&#21153;&#37325;&#26032;&#35757;&#32451;LLMs&#30340;&#36127;&#25285;&#65292;&#22240;&#20026;&#30001;&#20110;&#23545;&#27169;&#22411;&#21644;&#21512;&#20316;&#30340;&#35775;&#38382;&#21463;&#38480;&#65292;&#36825;&#24448;&#24448;&#26159;&#19981;&#21487;&#34892;&#25110;&#19981;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of large language models (LLMs) has revolutionized machine learning and related fields, showcasing remarkable abilities in comprehending, generating, and manipulating human language. However, their conventional usage through API-based text prompt submissions imposes certain limitations in terms of context constraints and external source availability. To address these challenges, we propose a novel framework called Reinforced Retrieval Augmented Machine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs with supporting information retrieved by a purpose-built retriever from a vast user-provided database. By leveraging recent advancements in reinforcement learning, our method effectively addresses several critical challenges. Firstly, it circumvents the need for accessing LLM gradients. Secondly, our method alleviates the burden of retraining LLMs for specific tasks, as it is often impractical or impossible due to restricted access to the model and the co
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#23376;&#38382;&#39064;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.11768</link><description>&lt;p&gt;
&#38382;&#39064;&#20998;&#35299;&#25552;&#39640;&#20102;&#27169;&#22411;&#29983;&#25104;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;
&lt;/p&gt;
&lt;p&gt;
Question Decomposition Improves the Faithfulness of Model-Generated Reasoning. (arXiv:2307.11768v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11768
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#23376;&#38382;&#39064;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25191;&#34892;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#20219;&#21153;&#65292;&#39564;&#35777;&#20854;&#34892;&#20026;&#30340;&#27491;&#30830;&#24615;&#21644;&#23433;&#20840;&#24615;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#12290;&#20854;&#20013;&#19968;&#31181;&#35299;&#20915;&#26041;&#27861;&#26159;&#35201;&#27714;LLM&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#20197;&#36880;&#27493;&#25512;&#29702;&#30340;&#26041;&#24335;&#22806;&#21270;&#20854;&#25512;&#29702;&#36807;&#31243;&#65288;&#24605;&#32500;&#38142;&#65307;CoT&#65289;&#12290;&#25512;&#29702;&#36807;&#31243;&#21487;&#20197;&#35753;&#25105;&#20204;&#26816;&#26597;&#27169;&#22411;&#25191;&#34892;&#20219;&#21153;&#30340;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#20381;&#36182;&#20110;&#25152;&#38472;&#36848;&#30340;&#25512;&#29702;&#33021;&#22815;&#24544;&#23454;&#22320;&#21453;&#26144;&#27169;&#22411;&#30340;&#23454;&#38469;&#25512;&#29702;&#65292;&#32780;&#36825;&#24182;&#38750;&#24635;&#26159;&#22914;&#27492;&#12290;&#20026;&#20102;&#25552;&#39640;CoT&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#38382;&#39064;&#20998;&#35299;&#20026;&#23376;&#38382;&#39064;&#26469;&#29983;&#25104;&#25512;&#29702;&#12290;&#22522;&#20110;&#20998;&#35299;&#30340;&#26041;&#27861;&#22312;&#38382;&#31572;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#26377;&#26102;&#25509;&#36817;CoT&#65292;&#24182;&#22312;&#20960;&#20010;&#26368;&#36817;&#25552;&#20986;&#30340;&#24230;&#37327;&#26631;&#20934;&#20013;&#25552;&#39640;&#20102;&#27169;&#22411;&#25152;&#38472;&#36848;&#25512;&#29702;&#30340;&#24544;&#23454;&#24230;&#12290;&#36890;&#36807;&#24378;&#21046;&#27169;&#22411;&#22312;&#21333;&#29420;&#30340;&#19978;&#19979;&#25991;&#20013;&#22238;&#31572;&#31616;&#21333;&#30340;&#23376;&#38382;&#39064;&#65292;&#25105;&#20204;&#22823;&#22823;&#22686;&#21152;&#20102;&#27169;&#22411;&#30340;&#24544;&#23454;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models (LLMs) perform more difficult tasks, it becomes harder to verify the correctness and safety of their behavior. One approach to help with this issue is to prompt LLMs to externalize their reasoning, e.g., by having them generate step-by-step reasoning as they answer a question (Chain-of-Thought; CoT). The reasoning may enable us to check the process that models use to perform tasks. However, this approach relies on the stated reasoning faithfully reflecting the model's actual reasoning, which is not always the case. To improve over the faithfulness of CoT reasoning, we have models generate reasoning by decomposing questions into subquestions. Decomposition-based methods achieve strong performance on question-answering tasks, sometimes approaching that of CoT while improving the faithfulness of the model's stated reasoning on several recently-proposed metrics. By forcing the model to answer simpler subquestions in separate contexts, we greatly increase the faithf
&lt;/p&gt;</description></item><item><title>EmotionPrompt&#26159;&#19968;&#20010;&#22522;&#20110;&#24515;&#29702;&#23398;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#24773;&#24863;&#21050;&#28608;&#34701;&#20837;&#21040;&#25552;&#31034;&#20013;&#65292;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#39033;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21516;&#26102;&#25913;&#21892;&#20102;&#20854;&#30495;&#23454;&#24615;&#21644;&#20449;&#24687;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.11760</link><description>&lt;p&gt;
EmotionPrompt: &#36890;&#36807;&#24773;&#24863;&#21050;&#28608;&#25552;&#21319;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20851;&#38190;&#24515;&#29702;&#23398;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11760
&lt;/p&gt;
&lt;p&gt;
EmotionPrompt&#26159;&#19968;&#20010;&#22522;&#20110;&#24515;&#29702;&#23398;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#24773;&#24863;&#21050;&#28608;&#34701;&#20837;&#21040;&#25552;&#31034;&#20013;&#65292;&#25552;&#21319;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#39033;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21516;&#26102;&#25913;&#21892;&#20102;&#20854;&#30495;&#23454;&#24615;&#21644;&#20449;&#24687;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25512;&#29702;&#12289;&#35821;&#35328;&#29702;&#35299;&#21644;&#25968;&#23398;&#38382;&#39064;&#35299;&#20915;&#31561;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#65292;&#24182;&#34987;&#35270;&#20026;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#65288;AGI&#65289;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#28982;&#32780;&#65292;LLMs&#23545;&#25552;&#31034;&#30340;&#25935;&#24863;&#24615;&#20173;&#28982;&#26159;&#20854;&#26085;&#24120;&#24212;&#29992;&#30340;&#20027;&#35201;&#29942;&#39048;&#12290;&#26412;&#25991;&#20174;&#24515;&#29702;&#23398;&#20013;&#27762;&#21462;&#28789;&#24863;&#65292;&#25552;&#20986;&#20102;EmotionPrompt&#26469;&#25506;&#32034;&#24773;&#24863;&#26234;&#33021;&#20197;&#25552;&#21319;LLMs&#30340;&#24615;&#33021;&#12290;EmotionPrompt&#22522;&#20110;&#19968;&#20010;&#38750;&#24120;&#31616;&#21333;&#26126;&#20102;&#30340;&#21407;&#21017;&#65306;&#23558;&#24773;&#24863;&#21050;&#28608;&#34701;&#20837;&#21040;&#25552;&#31034;&#20013;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#30456;&#21516;&#30340;&#21333;&#19968;&#25552;&#31034;&#27169;&#26495;&#19978;&#65292;&#19982;&#21407;&#22987;&#30340;&#38646;&#26679;&#26412;&#25552;&#31034;&#21644;Zero-shot-CoT&#30456;&#27604;&#65292;&#22312;8&#20010;&#20219;&#21153;&#19978;&#37117;&#26174;&#33879;&#20248;&#20110;&#22810;&#31181;&#27169;&#22411;&#65306;ChatGPT&#12289;Vicuna-13b&#12289;Bloom&#21644;T5&#12290;&#27492;&#22806;&#65292;&#35266;&#23519;&#21040;EmotionPrompt&#33021;&#22815;&#25552;&#39640;&#30495;&#23454;&#24615;&#21644;&#20449;&#24687;&#37327;&#12290;&#25105;&#20204;&#30456;&#20449;EmotionPrompt&#20026;&#25506;&#32034;&#36328;&#23398;&#31185;&#30693;&#35782;&#24320;&#36767;&#20102;&#19968;&#26465;&#26032;&#30340;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have achieved significant performance in many fields such as reasoning, language understanding, and math problem-solving, and are regarded as a crucial step to artificial general intelligence (AGI). However, the sensitivity of LLMs to prompts remains a major bottleneck for their daily adoption. In this paper, we take inspiration from psychology and propose EmotionPrompt to explore emotional intelligence to enhance the performance of LLMs. EmotionPrompt operates on a remarkably straightforward principle: the incorporation of emotional stimulus into prompts. Experimental results demonstrate that our \method, using the same single prompt templates, significantly outperforms original zero-shot prompt and Zero-shot-CoT on 8 tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and T5. Further, EmotionPrompt was observed to improve both truthfulness and informativeness. We believe that EmotionPrompt heralds a novel avenue for exploring interdisciplinary knowledg
&lt;/p&gt;</description></item><item><title>Retentive Network&#65288;RetNet&#65289;&#20316;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#30784;&#26550;&#26500;&#65292;&#23454;&#29616;&#20102;&#35757;&#32451;&#24182;&#34892;&#12289;&#20302;&#25104;&#26412;&#25512;&#29702;&#21644;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#24182;&#34892;&#12289;&#24490;&#29615;&#21644;&#20998;&#22359;&#24490;&#29615;&#19977;&#31181;&#35745;&#31639;&#33539;&#24335;&#65292;RetNet&#20855;&#26377;&#35757;&#32451;&#24182;&#34892;&#21270;&#12289;&#20302;&#25104;&#26412;&#25512;&#29702;&#21644;&#39640;&#25928;&#30340;&#38271;&#24207;&#21015;&#24314;&#27169;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.08621</link><description>&lt;p&gt;
Retentive Network: &#20316;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;Transformer&#30340;&#32487;&#20219;&#32773;
&lt;/p&gt;
&lt;p&gt;
Retentive Network: A Successor to Transformer for Large Language Models. (arXiv:2307.08621v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08621
&lt;/p&gt;
&lt;p&gt;
Retentive Network&#65288;RetNet&#65289;&#20316;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#30784;&#26550;&#26500;&#65292;&#23454;&#29616;&#20102;&#35757;&#32451;&#24182;&#34892;&#12289;&#20302;&#25104;&#26412;&#25512;&#29702;&#21644;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#24182;&#34892;&#12289;&#24490;&#29615;&#21644;&#20998;&#22359;&#24490;&#29615;&#19977;&#31181;&#35745;&#31639;&#33539;&#24335;&#65292;RetNet&#20855;&#26377;&#35757;&#32451;&#24182;&#34892;&#21270;&#12289;&#20302;&#25104;&#26412;&#25512;&#29702;&#21644;&#39640;&#25928;&#30340;&#38271;&#24207;&#21015;&#24314;&#27169;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Retentive Network (RetNet)&#20316;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#30784;&#26550;&#26500;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#35757;&#32451;&#24182;&#34892;&#12289;&#20302;&#25104;&#26412;&#25512;&#29702;&#21644;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#25512;&#23548;&#20986;&#20102;&#24490;&#29615;&#21644;&#27880;&#24847;&#21147;&#20043;&#38388;&#30340;&#36830;&#25509;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24207;&#21015;&#24314;&#27169;&#30340;&#20445;&#30041;&#26426;&#21046;&#65292;&#25903;&#25345;&#19977;&#31181;&#35745;&#31639;&#33539;&#24335;&#65292;&#21363;&#24182;&#34892;&#12289;&#24490;&#29615;&#21644;&#20998;&#22359;&#24490;&#29615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24182;&#34892;&#34920;&#31034;&#20801;&#35768;&#36827;&#34892;&#35757;&#32451;&#24182;&#34892;&#21270;&#12290;&#24490;&#29615;&#34920;&#31034;&#33021;&#22815;&#23454;&#29616;&#20302;&#25104;&#26412;&#30340;$O(1)$&#25512;&#29702;&#65292;&#20174;&#32780;&#25552;&#39640;&#35299;&#30721;&#21534;&#21520;&#37327;&#12289;&#24310;&#36831;&#21644;GPU&#20869;&#23384;&#65292;&#21516;&#26102;&#19981;&#25439;&#22833;&#24615;&#33021;&#12290;&#20998;&#22359;&#24490;&#29615;&#34920;&#31034;&#20415;&#20110;&#20351;&#29992;&#32447;&#24615;&#22797;&#26434;&#24230;&#36827;&#34892;&#39640;&#25928;&#30340;&#38271;&#24207;&#21015;&#24314;&#27169;&#65292;&#20854;&#20013;&#27599;&#20010;&#22359;&#21487;&#20197;&#24182;&#34892;&#32534;&#30721;&#65292;&#21516;&#26102;&#36827;&#34892;&#24490;&#29615;&#25688;&#35201;&#12290;&#35821;&#35328;&#24314;&#27169;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;RetNet&#23454;&#29616;&#20102;&#33391;&#22909;&#30340;&#25193;&#23637;&#32467;&#26524;&#12289;&#24182;&#34892;&#35757;&#32451;&#12289;&#20302;&#25104;&#26412;&#37096;&#32626;&#21644;&#39640;&#25928;&#30340;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost $O(1)$ inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#26469;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#26041;&#27861;&#65288;SPTAR&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#29983;&#25104;&#24369;&#26597;&#35810;&#65292;&#21487;&#20197;&#25552;&#39640;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.08303</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#36719;&#25552;&#31034;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#26469;&#22686;&#24378;&#23494;&#38598;&#26816;&#32034;&#30340;&#26041;&#27861;&#65288;SPTAR&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#24182;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#29983;&#25104;&#24369;&#26597;&#35810;&#65292;&#21487;&#20197;&#25552;&#39640;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#26816;&#32034;&#65288;DR&#65289;&#23558;&#26597;&#35810;&#21644;&#25991;&#26723;&#36716;&#21270;&#20026;&#23494;&#38598;&#21521;&#37327;&#34920;&#31034;&#65292;&#24182;&#22312;&#21521;&#37327;&#31354;&#38388;&#20013;&#27979;&#37327;&#26597;&#35810;&#19982;&#25991;&#26723;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;DR&#30340;&#19968;&#20010;&#25361;&#25112;&#26159;&#32570;&#20047;&#39046;&#22495;&#29305;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#34429;&#28982;DR&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#36801;&#31227;&#23398;&#20064;&#20174;&#22823;&#35268;&#27169;&#20844;&#20849;&#25968;&#25454;&#38598;&#65288;&#22914;MS MARCO&#65289;&#20013;&#23398;&#20064;&#65292;&#20294;&#35777;&#25454;&#34920;&#26126;&#65292;&#24182;&#38750;&#25152;&#26377;DR&#27169;&#22411;&#21644;&#39046;&#22495;&#37117;&#33021;&#21516;&#31561;&#21463;&#30410;&#20110;&#36801;&#31227;&#23398;&#20064;&#12290;&#26368;&#36817;&#65292;&#19968;&#20123;&#30740;&#31350;&#20154;&#21592;&#36716;&#21521;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#25913;&#36827;&#38646;&#26679;&#26412;&#21644;&#23569;&#26679;&#26412;&#30340;DR&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20013;&#37319;&#29992;&#30340;&#30828;&#25552;&#31034;&#25110;&#20154;&#24037;&#32534;&#20889;&#30340;&#25552;&#31034;&#26080;&#27861;&#20445;&#35777;&#29983;&#25104;&#30340;&#24369;&#26597;&#35810;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#22686;&#24378;DR&#30340;&#36719;&#25552;&#31034;&#35843;&#20248;&#65288;SPTAR&#65289;&#65306;&#23545;&#20110;&#27599;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#21033;&#29992;&#36719;&#25552;&#31034;&#35843;&#20248;&#22312;&#26377;&#38480;&#30340;&#30495;&#23454;&#25968;&#25454;&#19978;&#20248;&#21270;&#20219;&#21153;&#29305;&#23450;&#30340;&#36719;&#25552;&#31034;&#65292;&#28982;&#21518;&#29992;&#36825;&#20123;&#25552;&#31034;&#24341;&#23548;LLMs&#20026;&#26410;&#26631;&#35760;&#30340;&#25991;&#26723;&#26631;&#35760;&#24369;&#26597;&#35810;&#65292;&#20174;&#32780;&#24471;&#21040;&#36275;&#22815;&#30340;&#24369;&#25991;&#26723;-&#26597;&#35810;&#23545;&#26469;&#35757;&#32451;&#20219;&#21153;&#29305;&#23450;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24320;&#21457;&#39046;&#22495;&#29305;&#23450;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#20013;&#25972;&#21512;&#29983;&#25104;&#24335;&#29992;&#25143;&#20307;&#39564;&#30740;&#31350;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#23558;&#39046;&#22495;&#29992;&#25143;&#32435;&#20837;&#21407;&#22411;&#24320;&#21457;&#30340;&#19981;&#21516;&#38454;&#27573;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#29992;&#25143;&#38656;&#27714;&#21644;&#35780;&#20272;&#29992;&#25143;&#20215;&#20540;&#30340;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.16143</link><description>&lt;p&gt;
&#20026;&#24320;&#21457;&#39046;&#22495;&#29305;&#23450;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#32780;&#36827;&#34892;&#30340;&#29983;&#25104;&#24335;&#29992;&#25143;&#20307;&#39564;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications. (arXiv:2306.16143v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24320;&#21457;&#39046;&#22495;&#29305;&#23450;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#20013;&#25972;&#21512;&#29983;&#25104;&#24335;&#29992;&#25143;&#20307;&#39564;&#30740;&#31350;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#23558;&#39046;&#22495;&#29992;&#25143;&#32435;&#20837;&#21407;&#22411;&#24320;&#21457;&#30340;&#19981;&#21516;&#38454;&#27573;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#29992;&#25143;&#38656;&#27714;&#21644;&#35780;&#20272;&#29992;&#25143;&#20215;&#20540;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#25143;&#20307;&#39564;&#65288;UX&#65289;&#26159;&#20154;&#26426;&#20132;&#20114;&#65288;HCI&#65289;&#30740;&#31350;&#30340;&#19968;&#37096;&#20998;&#65292;&#19987;&#27880;&#20110;&#25552;&#39640;&#31995;&#32479;&#29992;&#25143;&#30340;&#30452;&#35266;&#24615;&#12289;&#36879;&#26126;&#24230;&#12289;&#31616;&#27905;&#24615;&#21644;&#20449;&#20219;&#24230;&#12290;&#22823;&#22810;&#25968;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#25110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;UX&#30740;&#31350;&#37117;&#37319;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#21363;&#27809;&#26377;&#20851;&#27880;&#29992;&#25143;&#38656;&#27714;&#65292;&#24182;&#20165;&#20165;&#23558;&#39046;&#22495;&#29992;&#25143;&#29992;&#20110;&#21487;&#29992;&#24615;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#26356;&#20856;&#22411;&#30340;UX&#26041;&#27861;&#26159;&#20808;&#38024;&#23545;&#29992;&#25143;&#30340;&#21487;&#29992;&#24615;&#36827;&#34892;&#23450;&#21046;&#65292;&#32780;&#19981;&#26159;&#39318;&#20808;&#20102;&#35299;&#29992;&#25143;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#29983;&#25104;&#24335;UX&#30740;&#31350;&#25972;&#21512;&#21040;&#24320;&#21457;&#39046;&#22495;NLP&#24212;&#29992;&#20013;&#30340;&#26041;&#27861;&#12290;&#29983;&#25104;&#24335;UX&#30740;&#31350;&#23558;&#39046;&#22495;&#29992;&#25143;&#32435;&#20837;&#21407;&#22411;&#24320;&#21457;&#30340;&#21021;&#22987;&#38454;&#27573;&#65292;&#21363;&#26500;&#24605;&#21644;&#27010;&#24565;&#35780;&#20272;&#38454;&#27573;&#65292;&#20197;&#21450;&#26368;&#21518;&#19968;&#38454;&#27573;&#35780;&#20272;&#29992;&#25143;&#20215;&#20540;&#30340;&#21464;&#21270;&#12290;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25253;&#36947;&#20102;&#19968;&#20010;&#38024;&#23545;&#36807;&#31243;&#24037;&#19994;&#20013;&#26085;&#24120;&#25805;&#20316;&#30340;&#39046;&#22495;&#29305;&#23450;&#35821;&#20041;&#25628;&#32034;&#30340;&#23436;&#25972;&#21407;&#22411;&#24320;&#21457;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
User experience (UX) is a part of human-computer interaction (HCI) research and focuses on increasing intuitiveness, transparency, simplicity, and trust for system users. Most of the UX research for machine learning (ML) or natural language processing (NLP) focuses on a data-driven methodology, i.e., it fails to focus on users' requirements, and engages domain users mainly for usability evaluation. Moreover, more typical UX methods tailor the systems towards user usability, unlike learning about the user needs first. The paper proposes a methodology for integrating generative UX research into developing domain NLP applications. Generative UX research employs domain users at the initial stages of prototype development, i.e., ideation and concept evaluation, and the last stage for evaluating the change in user value. In the case study, we report the full-cycle prototype development of a domain-specific semantic search for daily operations in the process industry. Our case study shows tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#32467;&#21512;&#31526;&#21495;&#34920;&#31034;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#36870;&#21521;&#24037;&#31243;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#30495;&#27491;&#35821;&#35328;&#29702;&#35299;&#19978;&#30340;&#23616;&#38480;&#24615;&#65292;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#12289;&#35821;&#35328;&#26080;&#20851;&#30340;LLMs&#12290;</title><link>http://arxiv.org/abs/2306.00017</link><description>&lt;p&gt;
&#21521;&#21487;&#35299;&#37322;&#30340;&#12289;&#35821;&#35328;&#26080;&#20851;&#30340;LLMs&#36808;&#36827;&#65306;&#22823;&#35268;&#27169;&#35821;&#35328;&#31526;&#21495;&#36870;&#21521;&#24037;&#31243;
&lt;/p&gt;
&lt;p&gt;
Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00017
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#32467;&#21512;&#31526;&#21495;&#34920;&#31034;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#36870;&#21521;&#24037;&#31243;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#30495;&#27491;&#35821;&#35328;&#29702;&#35299;&#19978;&#30340;&#23616;&#38480;&#24615;&#65292;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#12289;&#35821;&#35328;&#26080;&#20851;&#30340;LLMs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21462;&#24471;&#20102;&#19968;&#20010;&#37324;&#31243;&#30865;&#65292;&#26080;&#21487;&#21542;&#35748;&#22320;&#25913;&#21464;&#20102;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#20013;&#35768;&#22810;&#20449;&#20208;&#12290;&#28982;&#32780;&#65292;&#24403;&#28041;&#21450;&#30495;&#27491;&#30340;&#35821;&#35328;&#29702;&#35299;&#26102;&#65292;&#36825;&#20123;LLM&#30340;&#35768;&#22810;&#38480;&#21046;&#20173;&#28982;&#23384;&#22312;&#65292;&#36825;&#20123;&#38480;&#21046;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24213;&#23618;&#26550;&#26500;&#30340;&#21103;&#20135;&#21697;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#23427;&#20204;&#30340;&#20122;&#31526;&#21495;&#24615;&#36136;&#65292;&#36825;&#20123;&#27169;&#22411;&#33719;&#24471;&#26377;&#20851;&#35821;&#35328;&#22914;&#20309;&#36816;&#20316;&#30340;&#20219;&#20309;&#30693;&#35782;&#37117;&#23558;&#34987;&#22475;&#22312;&#25968;&#21313;&#20159;&#20010;&#24494;&#29305;&#24449;&#65288;&#26435;&#37325;&#65289;&#20013;&#65292;&#20854;&#20013;&#27809;&#26377;&#19968;&#20010;&#21333;&#29420;&#30340;&#29305;&#24449;&#26377;&#24847;&#20041;&#65292;&#20351;&#24471;&#36825;&#20123;&#27169;&#22411;&#26080;&#27861;&#35299;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#31526;&#21495;&#34920;&#31034;&#30340;&#24378;&#24230;&#19982;&#25105;&#20204;&#35748;&#20026;&#26159;LLMs&#25104;&#21151;&#30340;&#20851;&#38190;&#32467;&#21512;&#36215;&#26469;&#65292;&#21363;&#22312;&#35268;&#27169;&#19978;&#25104;&#21151;&#22320;&#36827;&#34892;&#33258;&#19979;&#32780;&#19978;&#30340;&#35821;&#35328;&#36870;&#21521;&#24037;&#31243;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20027;&#24352;&#22312;&#31526;&#21495;&#35774;&#32622;&#19979;&#23545;&#35821;&#35328;&#36827;&#34892;&#33258;&#19979;&#32780;&#19978;&#30340;&#36870;&#21521;&#24037;&#31243;&#12290;&#19968;&#20123;&#20316;&#32773;&#25552;&#20986;&#20102;&#36825;&#20010;&#39033;&#30446;&#30340;&#25552;&#31034;&#65292;&#25105;&#20204;&#23558;&#36827;&#34892;&#35814;&#32454;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have achieved a milestone that undenia-bly changed many held beliefs in artificial intelligence (AI). However, there remains many limitations of these LLMs when it comes to true language understanding, limitations that are a byproduct of the under-lying architecture of deep neural networks. Moreover, and due to their subsymbolic nature, whatever knowledge these models acquire about how language works will always be buried in billions of microfeatures (weights), none of which is meaningful on its own, making such models hopelessly unexplainable. To address these limitations, we suggest com-bining the strength of symbolic representations with what we believe to be the key to the success of LLMs, namely a successful bottom-up re-verse engineering of language at scale. As such we argue for a bottom-up reverse engineering of language in a symbolic setting. Hints on what this project amounts to have been suggested by several authors, and we discuss in some detail
&lt;/p&gt;</description></item><item><title>NormBank&#26159;&#19968;&#31181;&#24773;&#22659;&#31038;&#20250;&#35268;&#33539;&#30340;&#30693;&#35782;&#24211;&#65292;&#36890;&#36807;&#22810;&#20803;&#21270;&#30340;&#31038;&#20250;&#25991;&#21270;&#26694;&#26550;&#20026;&#20132;&#20114;&#24335;&#12289;&#36741;&#21161;&#21644;&#21327;&#20316;&#26234;&#33021;&#31995;&#32479;&#25552;&#20379;&#28789;&#27963;&#30340;&#35268;&#33539;&#25512;&#29702;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2305.17008</link><description>&lt;p&gt;
NormBank&#65306;&#19968;&#31181;&#24773;&#22659;&#31038;&#20250;&#35268;&#33539;&#30340;&#30693;&#35782;&#24211;
&lt;/p&gt;
&lt;p&gt;
NormBank: A Knowledge Bank of Situational Social Norms. (arXiv:2305.17008v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17008
&lt;/p&gt;
&lt;p&gt;
NormBank&#26159;&#19968;&#31181;&#24773;&#22659;&#31038;&#20250;&#35268;&#33539;&#30340;&#30693;&#35782;&#24211;&#65292;&#36890;&#36807;&#22810;&#20803;&#21270;&#30340;&#31038;&#20250;&#25991;&#21270;&#26694;&#26550;&#20026;&#20132;&#20114;&#24335;&#12289;&#36741;&#21161;&#21644;&#21327;&#20316;&#26234;&#33021;&#31995;&#32479;&#25552;&#20379;&#28789;&#27963;&#30340;&#35268;&#33539;&#25512;&#29702;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;NormBank&#65292;&#19968;&#20010;&#21253;&#21547;155k&#20010;&#24773;&#22659;&#35268;&#33539;&#30340;&#30693;&#35782;&#24211;&#12290;&#35813;&#36164;&#28304;&#26088;&#22312;&#20026;&#20132;&#20114;&#24335;&#12289;&#36741;&#21161;&#21644;&#21327;&#20316;&#26234;&#33021;&#31995;&#32479;&#25552;&#20379;&#28789;&#27963;&#30340;&#35268;&#33539;&#25512;&#29702;&#25903;&#25345;&#12290;&#19982;&#20808;&#21069;&#30340;&#24120;&#35782;&#36164;&#28304;&#19981;&#21516;&#65292;NormBank&#23558;&#27599;&#20010;&#25512;&#29702;&#23884;&#20837;&#21040;&#22810;&#20803;&#21270;&#30340;&#31038;&#20250;&#25991;&#21270;&#26694;&#26550;&#20013;&#65292;&#21253;&#25324;&#22330;&#26223;&#65288;&#20363;&#22914;&#65292;&#39184;&#21381;&#65289;&#12289;&#21442;&#19982;&#32773;&#30340;&#35282;&#33394;&#65288;&#26381;&#21153;&#21592;&#12289;&#39038;&#23458;&#65289;&#12289;&#20182;&#20204;&#30340;&#23646;&#24615;&#65288;&#24180;&#40836;&#12289;&#24615;&#21035;&#65289;&#20197;&#21450;&#20854;&#20182;&#29289;&#29702;&#12289;&#31038;&#20250;&#21644;&#25991;&#21270;&#32422;&#26463;&#65288;&#20363;&#22914;&#65292;&#28201;&#24230;&#25110;&#36816;&#33829;&#22269;&#23478;&#65289;&#12290;NormBank&#24635;&#20849;&#21253;&#21547;&#20102;&#26469;&#33258;&#25105;&#20204;&#24341;&#20837;&#21644;&#36845;&#20195;&#23436;&#21892;&#30340;&#20998;&#31867;&#27861;&#30340;63k&#20010;&#29420;&#29305;&#32422;&#26463;&#12290;&#36825;&#20123;&#32422;&#26463;&#20197;&#19981;&#21516;&#30340;&#32452;&#21512;&#24212;&#29992;&#20110;&#26500;&#24314;&#31038;&#20250;&#35268;&#33539;&#12290;&#32463;&#36807;&#36825;&#20123;&#25805;&#20316;&#65292;&#35268;&#33539;&#26159;&#38750;&#21333;&#35843;&#30340;-&#21363;&#20351;&#31245;&#24494;&#26356;&#26032;&#20854;&#26694;&#26550;&#20063;&#21487;&#20197;&#21462;&#28040;&#25512;&#29702;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#21457;&#29616;&#31070;&#32463;&#27169;&#22411;&#21487;&#20197;&#21487;&#38752;&#22320;&#25193;&#23637;NormBank&#30340;&#33539;&#22260;&#21644;&#35206;&#30422;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#19968;&#20010;&#31034;&#20363;&#23637;&#31034;&#20102;&#36825;&#20010;&#36164;&#28304;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present NormBank, a knowledge bank of 155k situational norms. This resource is designed to ground flexible normative reasoning for interactive, assistive, and collaborative AI systems. Unlike prior commonsense resources, NormBank grounds each inference within a multivalent sociocultural frame, which includes the setting (e.g., restaurant), the agents' contingent roles (waiter, customer), their attributes (age, gender), and other physical, social, and cultural constraints (e.g., the temperature or the country of operation). In total, NormBank contains 63k unique constraints from a taxonomy that we introduce and iteratively refine here. Constraints then apply in different combinations to frame social norms. Under these manipulations, norms are non-monotonic - one can cancel an inference by updating its frame even slightly. Still, we find evidence that neural models can help reliably extend the scope and coverage of NormBank. We further demonstrate the utility of this resource with a s
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#33258;&#28982;&#35821;&#35328;&#23450;&#20041;&#20316;&#20026;&#35789;&#20041;&#34920;&#31034;&#65292;&#21487;&#20197;&#20351;&#35821;&#20041;&#21464;&#21270;&#20998;&#26512;&#26356;&#20855;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20801;&#35768;&#29992;&#25143;&#30452;&#35266;&#35299;&#37322;&#35789;&#20041;&#30340;&#21382;&#26102;&#36712;&#36857;&#12290;&#27492;&#22806;&#65292;&#19978;&#19979;&#25991;&#21270;&#30340;&#23450;&#20041;&#22312;&#19978;&#19979;&#25991;&#20013;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#19978;&#20063;&#20248;&#20110;&#20196;&#29260;&#25110;&#20351;&#29992;&#21477;&#23884;&#20837;&#12290;</title><link>http://arxiv.org/abs/2305.11993</link><description>&lt;p&gt;
&#36890;&#36807;&#23450;&#20041;&#29983;&#25104;&#23454;&#29616;&#21487;&#35299;&#37322;&#30340;&#35789;&#20041;&#34920;&#31034;&#65306;&#20197;&#35821;&#20041;&#21464;&#21270;&#20998;&#26512;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis. (arXiv:2305.11993v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11993
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#33258;&#28982;&#35821;&#35328;&#23450;&#20041;&#20316;&#20026;&#35789;&#20041;&#34920;&#31034;&#65292;&#21487;&#20197;&#20351;&#35821;&#20041;&#21464;&#21270;&#20998;&#26512;&#26356;&#20855;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20801;&#35768;&#29992;&#25143;&#30452;&#35266;&#35299;&#37322;&#35789;&#20041;&#30340;&#21382;&#26102;&#36712;&#36857;&#12290;&#27492;&#22806;&#65292;&#19978;&#19979;&#25991;&#21270;&#30340;&#23450;&#20041;&#22312;&#19978;&#19979;&#25991;&#20013;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#19978;&#20063;&#20248;&#20110;&#20196;&#29260;&#25110;&#20351;&#29992;&#21477;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#33258;&#28982;&#35821;&#35328;&#23450;&#20041;&#26469;&#34920;&#31034;&#21487;&#35299;&#37322;&#30340;&#35789;&#21644;&#35789;&#20041;&#12290;&#32473;&#23450;&#19968;&#20010;&#30446;&#26631;&#35789;&#30340;&#20351;&#29992;&#31034;&#20363;&#38598;&#21512;&#21644;&#30456;&#24212;&#30340;&#25968;&#25454;&#39537;&#21160;&#20351;&#29992;&#32858;&#31867;&#65288;&#21363;&#35789;&#20041;&#65289;&#65292;&#20351;&#29992;&#19987;&#38376;&#30340;Flan-T5&#35821;&#35328;&#27169;&#22411;&#20026;&#27599;&#20010;&#29992;&#27861;&#29983;&#25104;&#23450;&#20041;&#65292;&#24182;&#36873;&#25321;&#20351;&#29992;&#32858;&#31867;&#20013;&#26368;&#20855;&#20195;&#34920;&#24615;&#30340;&#23450;&#20041;&#20316;&#20026;&#35813;&#35789;&#20041;&#26631;&#31614;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#29983;&#25104;&#30340;&#35789;&#20041;&#26631;&#31614;&#20351;&#29616;&#26377;&#30340;&#35821;&#20041;&#21464;&#21270;&#20998;&#26512;&#26041;&#27861;&#26356;&#20855;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#21450;&#22914;&#20309;&#20801;&#35768;&#29992;&#25143; - &#21382;&#21490;&#35821;&#35328;&#23398;&#23478;&#12289;&#35789;&#20856;&#32534;&#32386;&#32773;&#25110;&#31038;&#20250;&#31185;&#23398;&#23478; - &#25506;&#32034;&#24182;&#30452;&#35266;&#22320;&#35299;&#37322;&#35789;&#20041;&#30340;&#21382;&#26102;&#36712;&#36857;&#12290;&#35821;&#20041;&#21464;&#21270;&#20998;&#26512;&#20165;&#26159;&#8220;&#23450;&#20041;&#20316;&#20026;&#34920;&#31034;&#8221;&#30340;&#27169;&#24335;&#30340;&#20247;&#22810;&#21487;&#33021;&#24212;&#29992;&#20043;&#19968;&#12290;&#38500;&#20102;&#20154;&#31867;&#21487;&#35835;&#22806;&#65292;&#19978;&#19979;&#25991;&#21270;&#30340;&#23450;&#20041;&#22312;&#19978;&#19979;&#25991;&#20013;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#19978;&#20063;&#20248;&#20110;&#20196;&#29260;&#25110;&#20351;&#29992;&#21477;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose using automatically generated natural language definitions of contextualised word usages as interpretable word and word sense representations. Given a collection of usage examples for a target word, and the corresponding data-driven usage clusters (i.e., word senses), a definition is generated for each usage with a specialised Flan-T5 language model, and the most prototypical definition in a usage cluster is chosen as the sense label.  We demonstrate how the resulting sense labels can make existing approaches to semantic change analysis more interpretable, and how they can allow users -historical linguists, lexicographers, or social scientists -- to explore and intuitively explain diachronic trajectories of word meaning. Semantic change analysis is only one of many possible applications of the `definitions as representations' paradigm. Beyond being human-readable, contextualised definitions also outperform token or usage sentence embeddings in word-in-context semantic simi
&lt;/p&gt;</description></item><item><title>DataComp&#26159;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#65292;&#26088;&#22312;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#35757;&#32451;&#38598;&#26469;&#35299;&#20915;&#25968;&#25454;&#38598;&#22312;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#32570;&#38519;&#12290;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#35268;&#27169;&#35774;&#35745;&#30340;&#23454;&#39564;&#27979;&#35797;&#24179;&#21488;&#65292;&#20351;&#29992;12.8B&#20010;&#22270;&#20687;-&#25991;&#26412;&#23545;&#30340;&#26032;&#20505;&#36873;&#27744;&#65292;&#35753;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#36807;&#28388;&#25216;&#26415;&#25110;&#31574;&#21010;&#26032;&#30340;&#25968;&#25454;&#28304;&#24182;&#35780;&#20272;&#23427;&#20204;&#30340;&#26032;&#25968;&#25454;&#38598;&#26469;&#36827;&#34892;&#21019;&#26032;&#12290;</title><link>http://arxiv.org/abs/2304.14108</link><description>&lt;p&gt;
DataComp&#65306;&#23547;&#25214;&#19979;&#19968;&#20195;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
DataComp: In search of the next generation of multimodal datasets. (arXiv:2304.14108v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14108
&lt;/p&gt;
&lt;p&gt;
DataComp&#26159;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#65292;&#26088;&#22312;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#35757;&#32451;&#38598;&#26469;&#35299;&#20915;&#25968;&#25454;&#38598;&#22312;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#32570;&#38519;&#12290;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#35268;&#27169;&#35774;&#35745;&#30340;&#23454;&#39564;&#27979;&#35797;&#24179;&#21488;&#65292;&#20351;&#29992;12.8B&#20010;&#22270;&#20687;-&#25991;&#26412;&#23545;&#30340;&#26032;&#20505;&#36873;&#27744;&#65292;&#35753;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#36807;&#28388;&#25216;&#26415;&#25110;&#31574;&#21010;&#26032;&#30340;&#25968;&#25454;&#28304;&#24182;&#35780;&#20272;&#23427;&#20204;&#30340;&#26032;&#25968;&#25454;&#38598;&#26469;&#36827;&#34892;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#22312;&#36817;&#26399;&#30340;&#31361;&#30772;&#20013;&#36215;&#21040;&#20102;&#20851;&#38190;&#20316;&#29992;&#65292;&#27604;&#22914;CLIP&#12289;Stable Diffusion&#21644;GPT-4&#31561;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25968;&#25454;&#38598;&#24456;&#23569;&#24471;&#21040;&#19982;&#27169;&#22411;&#26550;&#26500;&#25110;&#35757;&#32451;&#31639;&#27861;&#21516;&#31561;&#30340;&#30740;&#31350;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#22312;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#32570;&#38519;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;DataComp&#65292;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#35757;&#32451;&#20195;&#30721;&#26159;&#22266;&#23450;&#30340;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#35757;&#32451;&#38598;&#26469;&#36827;&#34892;&#21019;&#26032;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;Common Crawl&#30340;&#26032;&#20505;&#36873;&#27744;&#65292;&#20854;&#20013;&#21253;&#21547;12.8B&#20010;&#22270;&#20687;-&#25991;&#26412;&#23545;&#30340;&#25968;&#25454;&#38598;&#23454;&#39564;&#27979;&#35797;&#24179;&#21488;&#12290;&#21442;&#21152;&#25105;&#20204;&#22522;&#20934;&#27979;&#35797;&#30340;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#35774;&#35745;&#26032;&#30340;&#36807;&#28388;&#25216;&#26415;&#25110;&#31574;&#21010;&#26032;&#30340;&#25968;&#25454;&#28304;&#65292;&#24182;&#36890;&#36807;&#36816;&#34892;&#25105;&#20204;&#26631;&#20934;&#21270;&#30340;CLIP&#35757;&#32451;&#20195;&#30721;&#24182;&#22312;38&#20010;&#19979;&#28216;&#27979;&#35797;&#38598;&#19978;&#36827;&#34892;&#27979;&#35797;&#26469;&#35780;&#20272;&#20182;&#20204;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#21253;&#21547;&#22810;&#20010;&#35268;&#27169;&#65292;&#22235;&#20010;&#20505;&#36873;&#27744;&#22823;&#23567;&#21644;&#30456;&#24212;&#30340;&#35745;&#31639;&#39044;&#31639;&#65292;&#22312;&#35757;&#32451;&#26399;&#38388;&#28085;&#30422;&#20102;&#20174;12.8M&#21040;12.8B&#20010;&#26679;&#26412;&#12290;&#36825;&#31181;&#22810;&#35268;&#27169;&#35774;&#35745;&#26377;&#21161;&#20110;&#30740;&#31350;&#35268;&#27169;&#36235;&#21183;&#65292;&#24182;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#36873;&#25321;&#20313;&#22320;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large multimodal datasets have been instrumental in recent breakthroughs such as CLIP, Stable Diffusion, and GPT-4. At the same time, datasets rarely receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DataComp, a benchmark where the training code is fixed and researchers innovate by proposing new training sets. We provide a testbed for dataset experiments centered around a new candidate pool of 12.8B image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing on 38 downstream test sets. Our benchmark consists of multiple scales, with four candidate pool sizes and associated compute budgets ranging from 12.8M to 12.8B samples seen during training. This multi-scale design facilitates the study of scaling trends and makes the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;$\sigma$Reparam&#65292;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2303.06296</link><description>&lt;p&gt;
&#38450;&#27490;&#27880;&#24847;&#21147;&#29109;&#23849;&#28291;&#30340;Transformer&#35757;&#32451;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Transformer Training by Preventing Attention Entropy Collapse. (arXiv:2303.06296v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06296
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;$\sigma$Reparam&#65292;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the training dynamics of Transformers and proposes a simple and efficient solution, $\sigma$Reparam, to prevent entropy collapse in the attention layers, promoting more stable training.
&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#31283;&#23450;&#24615;&#23545;&#20110;Transformer&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27880;&#24847;&#21147;&#23618;&#30340;&#28436;&#21464;&#26469;&#25506;&#31350;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36319;&#36394;&#27599;&#20010;&#27880;&#24847;&#21147;&#22836;&#30340;&#27880;&#24847;&#21147;&#29109;&#65292;&#36825;&#26159;&#27169;&#22411;&#38160;&#24230;&#30340;&#20195;&#29702;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19981;&#21516;&#30340;&#26550;&#26500;&#21644;&#20219;&#21153;&#20013;&#23384;&#22312;&#19968;&#31181;&#24120;&#35265;&#27169;&#24335;&#65292;&#21363;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#37319;&#21462;&#25391;&#33633;&#25439;&#22833;&#25110;&#21457;&#25955;&#30340;&#24418;&#24335;&#12290;&#25105;&#20204;&#23558;&#30149;&#24577;&#20302;&#27880;&#24847;&#21147;&#29109;&#65292;&#23545;&#24212;&#39640;&#24230;&#38598;&#20013;&#30340;&#27880;&#24847;&#21147;&#20998;&#25968;&#65292;&#31216;&#20026;$\textit{&#29109;&#23849;&#28291;}$&#12290;&#20316;&#20026;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\sigma$Reparam&#65292;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#35889;&#24402;&#19968;&#21270;&#21644;&#39069;&#22806;&#30340;&#23398;&#20064;&#26631;&#37327;&#37325;&#26032;&#21442;&#25968;&#21270;&#25152;&#26377;&#32447;&#24615;&#23618;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
Training stability is of great importance to Transformers. In this work, we investigate the training dynamics of Transformers by examining the evolution of the attention layers. In particular, we track the attention entropy for each attention head during the course of training, which is a proxy for model sharpness. We identify a common pattern across different architectures and tasks, where low attention entropy is accompanied by high training instability, which can take the form of oscillating loss or divergence. We denote the pathologically low attention entropy, corresponding to highly concentrated attention scores, as $\textit{entropy collapse}$. As a remedy, we propose $\sigma$Reparam, a simple and efficient solution where we reparametrize all linear layers with spectral normalization and an additional learned scalar. We demonstrate that the proposed reparameterization successfully prevents entropy collapse in the attention layers, promoting more stable training. Additionally, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2302.03693</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#30340;&#27010;&#24565;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#24341;&#23548;&#29983;&#25104;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#37325;&#28857;&#20851;&#27880;&#22522;&#20110;&#20998;&#25968;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#26576;&#31181;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#65288;&#25110;&#26041;&#21521;&#65289;&#30340;&#24605;&#24819;&#65292;&#24182;&#24320;&#21457;&#20102;&#36825;&#20010;&#24605;&#24819;&#30340;&#25968;&#23398;&#24418;&#24335;&#21270;&#12290;&#21033;&#29992;&#36825;&#20010;&#24418;&#24335;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26377;&#19968;&#20010;&#33258;&#28982;&#30340;&#34920;&#31034;&#36873;&#25321;&#20855;&#26377;&#36825;&#31181;&#24615;&#36136;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#19982;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#23545;&#34920;&#31034;&#30340;&#20195;&#25968;&#25805;&#20316;&#26469;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#20351;&#29992;&#31283;&#23450;&#25193;&#25955;&#22312;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#29983;&#25104;&#30340;&#31034;&#20363;&#20013;&#28436;&#31034;&#20102;&#36825;&#20010;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. Here, we focus on the idea that concepts are encoded as subspaces (or directions) of some representation space. We develop a mathematical formalization of this idea.Using this formalism, we show there's a natural choice of representation with this property, and we develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples text-guided image generation, using Stable Diffusion.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20462;&#35746;Transformer&#65288;RiT&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#24403;&#21069;Transformer&#35821;&#35328;&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#25463;&#24452;&#23398;&#20064;&#21644;&#20559;&#35265;&#38382;&#39064;&#65292;&#20197;&#20415;&#26356;&#26041;&#20415;&#22320;&#36827;&#34892;&#27169;&#22411;&#26356;&#26032;&#12290;RiT&#37319;&#29992;&#20102;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#21644;&#28165;&#26224;&#32467;&#26500;&#30340;&#20462;&#35746;&#24341;&#25806;&#30340;&#32452;&#21512;&#65292;&#36890;&#36807;&#23569;&#37327;&#30340;&#21162;&#21147;&#21644;&#29992;&#25143;&#20114;&#21160;&#65292;&#21487;&#20197;&#36731;&#26494;&#26356;&#26032;&#27169;&#22411;&#30340;&#30693;&#35782;&#12290;&#22312;&#36947;&#24503;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;RiT&#22312;&#27169;&#22411;&#20462;&#35746;&#26041;&#38754;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.10332</link><description>&lt;p&gt;
&#20462;&#35746;Transformer&#65306;&#25351;&#23548;&#35821;&#35328;&#27169;&#22411;&#25913;&#21464;&#20854;&#20215;&#20540;&#35266;
&lt;/p&gt;
&lt;p&gt;
Revision Transformers: Instructing Language Models to Change their Values. (arXiv:2210.10332v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20462;&#35746;Transformer&#65288;RiT&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#24403;&#21069;Transformer&#35821;&#35328;&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#25463;&#24452;&#23398;&#20064;&#21644;&#20559;&#35265;&#38382;&#39064;&#65292;&#20197;&#20415;&#26356;&#26041;&#20415;&#22320;&#36827;&#34892;&#27169;&#22411;&#26356;&#26032;&#12290;RiT&#37319;&#29992;&#20102;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#21644;&#28165;&#26224;&#32467;&#26500;&#30340;&#20462;&#35746;&#24341;&#25806;&#30340;&#32452;&#21512;&#65292;&#36890;&#36807;&#23569;&#37327;&#30340;&#21162;&#21147;&#21644;&#29992;&#25143;&#20114;&#21160;&#65292;&#21487;&#20197;&#36731;&#26494;&#26356;&#26032;&#27169;&#22411;&#30340;&#30693;&#35782;&#12290;&#22312;&#36947;&#24503;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;RiT&#22312;&#27169;&#22411;&#20462;&#35746;&#26041;&#38754;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;Transformer&#35821;&#35328;&#27169;&#22411;&#26159;&#20855;&#26377;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#30340;&#22823;&#35268;&#27169;&#27169;&#22411;&#12290;&#23427;&#20204;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#23481;&#26131;&#20986;&#29616;&#25463;&#24452;&#23398;&#20064;&#21644;&#20559;&#35265;&#12290;&#36890;&#36807;&#21442;&#25968;&#35843;&#25972;&#26469;&#35299;&#20915;&#36825;&#31867;&#19981;&#27491;&#30830;&#30340;&#27169;&#22411;&#34892;&#20026;&#38750;&#24120;&#26114;&#36149;&#12290;&#23545;&#20110;&#26356;&#26032;&#25991;&#21270;&#25110;&#20010;&#20154;&#20043;&#38388;&#21464;&#21270;&#30340;&#36947;&#24503;&#20215;&#20540;&#31561;&#21160;&#24577;&#27010;&#24565;&#23588;&#20854;&#26840;&#25163;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#23558;&#25152;&#26377;&#20449;&#24687;&#23384;&#20648;&#22312;&#27169;&#22411;&#21442;&#25968;&#20013;&#30340;&#24403;&#21069;&#24120;&#35265;&#20570;&#27861;&#25552;&#20986;&#36136;&#30097;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#35746;Transformer&#65288;RiT&#65289;&#26469;&#20419;&#36827;&#27169;&#22411;&#30340;&#36731;&#26494;&#26356;&#26032;&#12290;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#19982;&#28165;&#26224;&#32467;&#26500;&#30340;&#20462;&#35746;&#24341;&#25806;&#30340;&#29305;&#23450;&#32452;&#21512;&#20351;&#24471;&#22312;&#23569;&#37327;&#30340;&#21162;&#21147;&#21644;&#29992;&#25143;&#20114;&#21160;&#30340;&#24110;&#21161;&#19979;&#26356;&#26032;&#27169;&#22411;&#30340;&#30693;&#35782;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#36947;&#24503;&#25968;&#25454;&#38598;&#19978;&#31034;&#33539;&#20102;RiT&#65292;&#24182;&#27169;&#25311;&#20102;&#29992;&#25143;&#21453;&#39304;&#65292;&#23637;&#31034;&#20102;&#27169;&#22411;&#20462;&#35746;&#30340;&#24378;&#22823;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current transformer language models (LM) are large-scale models with billions of parameters. They have been shown to provide high performances on a variety of tasks but are also prone to shortcut learning and bias. Addressing such incorrect model behavior via parameter adjustments is very costly. This is particularly problematic for updating dynamic concepts, such as moral values, which vary culturally or interpersonally. In this work, we question the current common practice of storing all information in the model parameters and propose the Revision Transformer (RiT) to facilitate easy model updating. The specific combination of a large-scale pre-trained LM that inherently but also diffusely encodes world knowledge with a clear-structured revision engine makes it possible to update the model's knowledge with little effort and the help of user interaction. We exemplify RiT on a moral dataset and simulate user feedback demonstrating strong performance in model revision even with small da
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#20803;&#21453;&#28216;&#25103;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#32452;&#21512;&#23398;&#20064;&#34892;&#20026;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#35299;&#20915;&#32465;&#23450;&#38382;&#39064;&#26469;&#25903;&#25345;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#23637;&#31034;&#32452;&#21512;&#23398;&#20064;&#34892;&#20026;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2207.08012</link><description>&lt;p&gt;
&#20803;&#20803;&#21453;&#28216;&#25103;&#23398;&#20064;&#32452;&#21512;&#23398;&#20064;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Meta-Referential Games to Learn Compositional Learning Behaviours. (arXiv:2207.08012v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#20803;&#21453;&#28216;&#25103;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#32452;&#21512;&#23398;&#20064;&#34892;&#20026;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#35299;&#20915;&#32465;&#23450;&#38382;&#39064;&#26469;&#25903;&#25345;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#23637;&#31034;&#32452;&#21512;&#23398;&#20064;&#34892;&#20026;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#21033;&#29992;&#32452;&#21512;&#24615;&#20174;&#36807;&#21435;&#30340;&#32463;&#39564;&#20013;&#25512;&#24191;&#21040;&#26032;&#39062;&#30340;&#32463;&#39564;&#12290;&#25105;&#20204;&#20551;&#35774;&#25105;&#20204;&#30340;&#32463;&#39564;&#21487;&#20197;&#20998;&#35299;&#20026;&#22522;&#26412;&#30340;&#21407;&#23376;&#32452;&#20214;&#65292;&#36825;&#20123;&#32452;&#20214;&#21487;&#20197;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#37325;&#26032;&#32452;&#21512;&#65292;&#20197;&#25903;&#25345;&#25105;&#20204;&#21442;&#19982;&#26032;&#39062;&#32463;&#39564;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23558;&#36825;&#35270;&#20026;&#23398;&#20064;&#20197;&#32452;&#21512;&#26041;&#24335;&#27867;&#21270;&#30340;&#33021;&#21147;&#65292;&#24182;&#23558;&#21033;&#29992;&#36825;&#31181;&#33021;&#21147;&#30340;&#34892;&#20026;&#31216;&#20026;&#32452;&#21512;&#23398;&#20064;&#34892;&#20026;&#65288;CLBs&#65289;&#12290;&#23398;&#20064;CLBs&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#35299;&#20915;&#32465;&#23450;&#38382;&#39064;&#65288;BP&#65289;&#12290;&#23613;&#31649;&#36825;&#26159;&#20154;&#31867;&#36731;&#26494;&#23436;&#25104;&#30340;&#26234;&#33021;&#22766;&#20030;&#65292;&#20294;&#23545;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#26469;&#35828;&#24182;&#38750;&#22914;&#27492;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#26500;&#24314;&#33021;&#22815;&#19982;&#20154;&#31867;&#21512;&#20316;&#30340;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#65292;&#25105;&#20204;&#24314;&#35758;&#24320;&#21457;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#26469;&#30740;&#31350;&#20195;&#29702;&#21830;&#36890;&#36807;&#35299;&#20915;BP&#30340;&#39046;&#22495;&#26080;&#20851;&#29256;&#26412;&#26469;&#23637;&#31034;CLBs&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#21463;&#21040;&#25351;&#20195;&#28216;&#25103;&#30340;&#35821;&#35328;&#28044;&#29616;&#21644;&#22522;&#30784;&#26550;&#26500;&#26694;&#26550;&#30340;&#21551;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20803;&#23398;&#20064;&#25193;&#23637;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Human beings use compositionality to generalise from past experiences to novel experiences. We assume a separation of our experiences into fundamental atomic components that can be recombined in novel ways to support our ability to engage with novel experiences. We frame this as the ability to learn to generalise compositionally, and we will refer to behaviours making use of this ability as compositional learning behaviours (CLBs). A central problem to learning CLBs is the resolution of a binding problem (BP). While it is another feat of intelligence that human beings perform with ease, it is not the case for state-of-the-art artificial agents. Thus, in order to build artificial agents able to collaborate with human beings, we propose to develop a novel benchmark to investigate agents' abilities to exhibit CLBs by solving a domain-agnostic version of the BP. We take inspiration from the language emergence and grounding framework of referential games and propose a meta-learning extensio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#20247;&#21253;&#21333;&#26631;&#31614;&#24773;&#24863;&#20998;&#26512;&#20013;&#35299;&#20915;&#27880;&#37322;&#32773;&#20559;&#24046;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#30340;&#20559;&#24046;&#24314;&#27169;&#21644;&#30495;&#23454;&#20540;&#20272;&#35745;&#26469;&#25913;&#21892;&#20934;&#30830;&#24615;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;&#26679;&#26412;&#21482;&#30001;&#21333;&#20010;&#27880;&#37322;&#32773;&#26631;&#27880;&#30340;&#24773;&#20917;&#19979;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2111.02326</link><description>&lt;p&gt;
&#19968;&#31181;&#22312;&#20247;&#21253;&#21333;&#26631;&#31614;&#24773;&#24863;&#20998;&#26512;&#20013;&#31471;&#21040;&#31471;&#30340;&#27880;&#37322;&#32773;&#20559;&#24046;&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
End-to-End Annotator Bias Approximation on Crowdsourced Single-Label Sentiment Analysis. (arXiv:2111.02326v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.02326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#20247;&#21253;&#21333;&#26631;&#31614;&#24773;&#24863;&#20998;&#26512;&#20013;&#35299;&#20915;&#27880;&#37322;&#32773;&#20559;&#24046;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#30340;&#20559;&#24046;&#24314;&#27169;&#21644;&#30495;&#23454;&#20540;&#20272;&#35745;&#26469;&#25913;&#21892;&#20934;&#30830;&#24615;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;&#26679;&#26412;&#21482;&#30001;&#21333;&#20010;&#27880;&#37322;&#32773;&#26631;&#27880;&#30340;&#24773;&#20917;&#19979;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#24863;&#20998;&#26512;&#36890;&#24120;&#26159;&#19968;&#20010;&#23481;&#26131;&#21463;&#21040;&#20247;&#22810;&#27880;&#37322;&#32773;&#20027;&#35266;&#26631;&#31614;&#24433;&#21709;&#30340;&#20247;&#21253;&#20219;&#21153;&#12290;&#30446;&#21069;&#23578;&#19981;&#23436;&#20840;&#20102;&#35299;&#22914;&#20309;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#27491;&#30830;&#22320;&#24314;&#27169;&#27599;&#20010;&#27880;&#37322;&#32773;&#30340;&#27880;&#37322;&#20559;&#24046;&#12290;&#28982;&#32780;&#65292;&#20934;&#30830;&#21487;&#38752;&#22320;&#35299;&#20915;&#27880;&#37322;&#32773;&#20559;&#24046;&#26159;&#29702;&#35299;&#27880;&#37322;&#32773;&#26631;&#27880;&#34892;&#20026;&#24182;&#25104;&#21151;&#35299;&#20915;&#30456;&#24212;&#30340;&#20010;&#20307;&#35823;&#35299;&#21644;&#38169;&#35823;&#30340;&#20851;&#38190;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#23545;&#31934;&#30830;&#30340;&#31471;&#21040;&#31471;&#20559;&#24046;&#24314;&#27169;&#21644;&#30495;&#23454;&#20540;&#20272;&#35745;&#36827;&#34892;&#35299;&#37322;&#21644;&#25913;&#36827;&#65292;&#20174;&#32780;&#20943;&#23569;&#29616;&#26377;&#20808;&#36827;&#26041;&#27861;&#20013;&#28041;&#21450;&#30340;&#19981;&#24076;&#26395;&#20986;&#29616;&#30340;&#19981;&#21305;&#37197;&#38382;&#39064;&#12290;&#20998;&#31867;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#26377;&#28508;&#21147;&#25552;&#39640;&#20165;&#30001;&#21333;&#20010;&#27880;&#37322;&#32773;&#26631;&#27880;&#30340;&#26679;&#26412;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20844;&#24320;&#25552;&#20379;&#25972;&#20010;&#28304;&#20195;&#30721;&#65292;&#24182;&#21457;&#24067;&#19968;&#20010;&#21253;&#21547;&#35752;&#35770;&#26377;&#26426;&#39135;&#21697;&#20135;&#21697;&#30340;10,000&#20010;&#21477;&#23376;&#30340;&#39046;&#22495;&#29305;&#23450;&#24773;&#24863;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#21477;&#23376;&#26159;&#20174;&#31038;&#20132;&#23186;&#20307;&#25235;&#21462;&#32780;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sentiment analysis is often a crowdsourcing task prone to subjective labels given by many annotators. It is not yet fully understood how the annotation bias of each annotator can be modeled correctly with state-of-the-art methods. However, resolving annotator bias precisely and reliably is the key to understand annotators' labeling behavior and to successfully resolve corresponding individual misconceptions and wrongdoings regarding the annotation task. Our contribution is an explanation and improvement for precise neural end-to-end bias modeling and ground truth estimation, which reduces an undesired mismatch in that regard of the existing state-of-the-art. Classification experiments show that it has potential to improve accuracy in cases where each sample is annotated only by one single annotator. We provide the whole source code publicly and release an own domain-specific sentiment dataset containing 10,000 sentences discussing organic food products. These are crawled from social me
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#29616;&#20195;&#21644;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#22810;&#31181;&#35821;&#35328;&#65292;&#26500;&#24314;&#19968;&#20010;&#21333;&#19968;&#20027;&#39064;&#27169;&#22411;&#65292;&#24182;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#23558;&#35813;&#27169;&#22411;&#24212;&#29992;&#20110;&#26377;&#26426;&#39135;&#21697;&#30340;&#25253;&#32440;&#25991;&#31456;&#21644;&#29992;&#25143;&#35780;&#35770;&#65292;&#25105;&#20204;&#21457;&#29616;&#20027;&#39064;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#21305;&#37197;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#27604;&#20363;&#30340;&#31283;&#23450;&#19988;&#19982;&#39046;&#22495;&#30456;&#20851;&#30340;&#20027;&#39064;&#12290;</title><link>http://arxiv.org/abs/2111.02259</link><description>&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#30340;&#36328;&#35821;&#35328;&#35266;&#28857;&#25366;&#25496;&#30340;&#26696;&#20363;&#30740;&#31350;&#21644;&#36136;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Case Study and Qualitative Analysis of Simple Cross-Lingual Opinion Mining. (arXiv:2111.02259v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.02259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#29616;&#20195;&#21644;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#22810;&#31181;&#35821;&#35328;&#65292;&#26500;&#24314;&#19968;&#20010;&#21333;&#19968;&#20027;&#39064;&#27169;&#22411;&#65292;&#24182;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24773;&#24863;&#20998;&#26512;&#12290;&#36890;&#36807;&#23558;&#35813;&#27169;&#22411;&#24212;&#29992;&#20110;&#26377;&#26426;&#39135;&#21697;&#30340;&#25253;&#32440;&#25991;&#31456;&#21644;&#29992;&#25143;&#35780;&#35770;&#65292;&#25105;&#20204;&#21457;&#29616;&#20027;&#39064;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#21305;&#37197;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#27604;&#20363;&#30340;&#31283;&#23450;&#19988;&#19982;&#39046;&#22495;&#30456;&#20851;&#30340;&#20027;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#29992;&#25143;&#29983;&#25104;&#20869;&#23481;&#28041;&#21450;&#22810;&#31181;&#35821;&#35328;&#65292;&#36825;&#22312;&#25216;&#26415;&#19978;&#20351;&#24471;&#36328;&#19981;&#21516;&#25991;&#21270;&#21644;&#22320;&#21306;&#27604;&#36739;&#35752;&#35770;&#20027;&#39064;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#23545;&#20110;&#20840;&#29699;&#21270;&#19990;&#30028;&#20013;&#30340;&#39046;&#22495;&#65292;&#22914;&#24066;&#22330;&#30740;&#31350;&#65292;&#20154;&#20204;&#21487;&#33021;&#23545;&#20135;&#21697;&#26377;&#19981;&#21516;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#29616;&#20195;&#21644;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#33021;&#22815;&#21516;&#26102;&#35206;&#30422;&#22810;&#31181;&#35821;&#35328;&#30340;&#21333;&#19968;&#20027;&#39064;&#27169;&#22411;&#65292;&#24182;&#22522;&#20110;&#19968;&#20010;&#39044;&#35757;&#32451;&#30340;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#24773;&#24863;&#20998;&#26512;&#12290;&#20026;&#20102;&#35777;&#26126;&#20854;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#23558;&#35813;&#27169;&#22411;&#24212;&#29992;&#20110;&#29305;&#23450;&#39046;&#22495;&#30340;&#25253;&#32440;&#25991;&#31456;&#21644;&#29992;&#25143;&#35780;&#35770;&#65292;&#21363;&#26377;&#26426;&#39135;&#21697;&#20135;&#21697;&#21644;&#30456;&#20851;&#28040;&#36153;&#34892;&#20026;&#12290;&#20027;&#39064;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#39640;&#27604;&#20363;&#30340;&#31283;&#23450;&#19988;&#30456;&#20851;&#39046;&#22495;&#30340;&#20027;&#39064;&#65292;&#20027;&#39064;&#19982;&#20854;&#30456;&#24212;&#25991;&#26412;&#20869;&#23481;&#20043;&#38388;&#23384;&#22312;&#26377;&#24847;&#20041;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#19968;&#20123;&#26032;&#39062;&#30340;
&lt;/p&gt;
&lt;p&gt;
User-generated content from social media is produced in many languages, making it technically challenging to compare the discussed themes from one domain across different cultures and regions. It is relevant for domains in a globalized world, such as market research, where people from two nations and markets might have different requirements for a product. We propose a simple, modern, and effective method for building a single topic model with sentiment analysis capable of covering multiple languages simultanteously, based on a pre-trained state-of-the-art deep neural network for natural language understanding. To demonstrate its feasibility, we apply the model to newspaper articles and user comments of a specific domain, i.e., organic food products and related consumption behavior. The themes match across languages. Additionally, we obtain an high proportion of stable and domain-relevant topics, a meaningful relation between topics and their respective textual contents, and an interpr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#24341;&#20837;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#21069;&#21518;&#22810;&#20010;&#22823;&#35268;&#27169;&#35745;&#31639;&#26426;&#31185;&#23398;&#22522;&#30784;&#35838;&#31243;&#30340;&#35780;&#20272;&#32467;&#26524;&#65292;&#25506;&#35752;&#20102;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#23545;&#23398;&#29983;&#23545;&#32534;&#31243;&#35838;&#31243;&#21644;&#25945;&#23398;&#24863;&#30693;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2110.15134</link><description>&lt;p&gt;
&#24341;&#20837;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#21069;&#21518;&#32534;&#31243;&#35838;&#31243;&#35780;&#20272;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Programming Course Evaluations Before and After the Introduction of an Autograder. (arXiv:2110.15134v2 [cs.HC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.15134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#24341;&#20837;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#21069;&#21518;&#22810;&#20010;&#22823;&#35268;&#27169;&#35745;&#31639;&#26426;&#31185;&#23398;&#22522;&#30784;&#35838;&#31243;&#30340;&#35780;&#20272;&#32467;&#26524;&#65292;&#25506;&#35752;&#20102;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#23545;&#23398;&#29983;&#23545;&#32534;&#31243;&#35838;&#31243;&#21644;&#25945;&#23398;&#24863;&#30693;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#31561;&#25945;&#32946;&#26426;&#26500;&#20013;&#65292;&#24120;&#35265;&#30340;&#20837;&#38376;&#32534;&#31243;&#35838;&#31243;&#26377;&#25968;&#30334;&#21517;&#21442;&#19982;&#23398;&#29983;&#28212;&#26395;&#23398;&#20064;&#32534;&#31243;&#12290;&#20154;&#24037;&#35780;&#23457;&#25552;&#20132;&#30340;&#28304;&#20195;&#30721;&#21644;&#25552;&#20379;&#21453;&#39304;&#30340;&#24037;&#20316;&#37327;&#24050;&#32463;&#26080;&#27861;&#31649;&#29702;&#12290;&#25163;&#21160;&#35780;&#23457;&#25552;&#20132;&#30340;&#20316;&#19994;&#21487;&#33021;&#23384;&#22312;&#20027;&#35266;&#21644;&#19981;&#20844;&#24179;&#30340;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#22914;&#26524;&#26377;&#22810;&#20010;&#21161;&#25945;&#36127;&#36131;&#35780;&#20998;&#12290;&#19981;&#21516;&#30340;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#21487;&#20197;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#24110;&#21161;&#65307;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20110;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#22914;&#20309;&#24433;&#21709;&#23398;&#29983;&#23545;&#32534;&#31243;&#35838;&#31243;&#21644;&#25945;&#23398;&#30340;&#25972;&#20307;&#24863;&#30693;&#32570;&#20047;&#20102;&#35299;&#12290;&#36825;&#23545;&#20110;&#35838;&#31243;&#32452;&#32455;&#32773;&#21644;&#26426;&#26500;&#22312;&#24212;&#23545;&#19981;&#26029;&#22686;&#21152;&#30340;&#23398;&#29983;&#25968;&#37327;&#26102;&#20445;&#25345;&#32534;&#31243;&#35838;&#31243;&#30340;&#21560;&#24341;&#21147;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#36817;&#24341;&#20837;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#30340;&#22810;&#20010;&#22823;&#35268;&#27169;&#22522;&#30784;&#35745;&#31639;&#26426;&#31185;&#23398;&#35838;&#31243;&#30340;&#26631;&#20934;&#21270;&#22823;&#23398;&#35780;&#20272;&#38382;&#21367;&#30340;&#22238;&#31572;&#12290;&#20998;&#26512;&#20102;&#20171;&#20837;&#21069;&#21518;&#30340;&#24046;&#24322;&#12290;&#36890;&#36807;&#32435;&#20837;&#20854;&#20182;&#35266;&#23519;&#35282;&#24230;&#65292;&#25506;&#35752;&#20102;&#33258;&#21160;&#35780;&#20998;&#31995;&#32479;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Commonly, introductory programming courses in higher education institutions have hundreds of participating students eager to learn to program. The manual effort for reviewing the submitted source code and for providing feedback can no longer be managed. Manually reviewing the submitted homework can be subjective and unfair, particularly if many tutors are responsible for grading. Different autograders can help in this situation; however, there is a lack of knowledge about how autograders can impact students' overall perception of programming classes and teaching. This is relevant for course organizers and institutions to keep their programming courses attractive while coping with increasing students.  This paper studies the answers to the standardized university evaluation questionnaires of multiple large-scale foundational computer science courses which recently introduced autograding. The differences before and after this intervention are analyzed. By incorporating additional observa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#22522;&#20110;&#35789;&#23884;&#20837;&#30340;&#20027;&#39064;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#21253;SocialVisTUM&#20013;&#26174;&#31034;&#30456;&#20851;&#20027;&#39064;&#27169;&#22411;&#12290;&#35813;&#24037;&#20855;&#21253;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#21151;&#33021;&#21644;&#32454;&#33410;&#65292;&#25903;&#25345;&#23545;&#22823;&#25991;&#26412;&#38598;&#21512;&#30340;&#25506;&#32034;&#12290;&#20174;&#19968;&#20010;&#20851;&#20110;&#26377;&#26426;&#39135;&#21697;&#28040;&#36153;&#30340;&#33521;&#35821;&#31038;&#20132;&#23186;&#20307;&#35752;&#35770;&#25968;&#25454;&#30340;&#23454;&#20363;&#20013;&#65292;&#21487;&#35270;&#21270;&#32467;&#26524;&#35777;&#23454;&#20102;&#19968;&#39033;&#28040;&#36153;&#32773;&#30740;&#31350;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2110.10575</link><description>&lt;p&gt;
SocialVisTUM&#65306;&#38754;&#21521;&#31038;&#20132;&#23186;&#20307;&#35266;&#28857;&#25366;&#25496;&#30340;&#30456;&#20851;&#31070;&#32463;&#20027;&#39064;&#27169;&#22411;&#30340;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#21253;
&lt;/p&gt;
&lt;p&gt;
SocialVisTUM: An Interactive Visualization Toolkit for Correlated Neural Topic Models on Social Media Opinion Mining. (arXiv:2110.10575v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.10575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#22522;&#20110;&#35789;&#23884;&#20837;&#30340;&#20027;&#39064;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#21253;SocialVisTUM&#20013;&#26174;&#31034;&#30456;&#20851;&#20027;&#39064;&#27169;&#22411;&#12290;&#35813;&#24037;&#20855;&#21253;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#21151;&#33021;&#21644;&#32454;&#33410;&#65292;&#25903;&#25345;&#23545;&#22823;&#25991;&#26412;&#38598;&#21512;&#30340;&#25506;&#32034;&#12290;&#20174;&#19968;&#20010;&#20851;&#20110;&#26377;&#26426;&#39135;&#21697;&#28040;&#36153;&#30340;&#33521;&#35821;&#31038;&#20132;&#23186;&#20307;&#35752;&#35770;&#25968;&#25454;&#30340;&#23454;&#20363;&#20013;&#65292;&#21487;&#35270;&#21270;&#32467;&#26524;&#35777;&#23454;&#20102;&#19968;&#39033;&#28040;&#36153;&#32773;&#30740;&#31350;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#35266;&#28857;&#25366;&#25496;&#26041;&#38754;&#30340;&#30740;&#31350;&#20013;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#35789;&#23884;&#20837;&#30340;&#20027;&#39064;&#24314;&#27169;&#26041;&#27861;&#65292;&#19982;&#20256;&#32479;&#20027;&#39064;&#24314;&#27169;&#30456;&#27604;&#65292;&#36825;&#20123;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#65292;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#20132;&#20114;&#24335;&#21487;&#35270;&#21270;&#24037;&#20855;&#21253;SocialVisTUM&#20013;&#65292;&#26174;&#31034;&#31038;&#20132;&#23186;&#20307;&#25991;&#26412;&#19978;&#30340;&#30456;&#20851;&#20027;&#39064;&#27169;&#22411;&#12290;&#23427;&#26174;&#31034;&#20102;&#19968;&#20010;&#22270;&#65292;&#20027;&#39064;&#20316;&#20026;&#33410;&#28857;&#65292;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#20316;&#20026;&#36793;&#12290;&#36827;&#19968;&#27493;&#30340;&#32454;&#33410;&#20197;&#20132;&#20114;&#26041;&#24335;&#26174;&#31034;&#65292;&#20197;&#25903;&#25345;&#22823;&#25991;&#26412;&#38598;&#21512;&#30340;&#25506;&#32034;&#65292;&#20363;&#22914;&#20027;&#39064;&#30340;&#20195;&#34920;&#24615;&#35789;&#35821;&#21644;&#21477;&#23376;&#12289;&#20027;&#39064;&#21644;&#24773;&#24863;&#20998;&#24067;&#12289;&#20998;&#23618;&#20027;&#39064;&#32858;&#31867;&#21644;&#21487;&#23450;&#21046;&#30340;&#39044;&#23450;&#20041;&#20027;&#39064;&#26631;&#31614;&#12290;&#35813;&#24037;&#20855;&#21253;&#21487;&#20197;&#33258;&#21160;&#20248;&#21270;&#33258;&#23450;&#20041;&#25968;&#25454;&#65292;&#20197;&#33719;&#24471;&#26368;&#20339;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24037;&#20855;&#21253;&#22312;&#20174;&#33521;&#35821;&#31038;&#20132;&#23186;&#20307;&#35752;&#35770;&#20013;&#29228;&#21462;&#30340;&#26377;&#26426;&#39135;&#21697;&#28040;&#36153;&#25968;&#25454;&#19978;&#30340;&#24037;&#20316;&#23454;&#20363;&#12290;&#35813;&#21487;&#35270;&#21270;&#32467;&#26524;&#35777;&#23454;&#20102;&#19968;&#39033;&#23450;&#24615;&#28040;&#36153;&#32773;&#30740;&#31350;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research in opinion mining proposed word embedding-based topic modeling methods that provide superior coherence compared to traditional topic modeling. In this paper, we demonstrate how these methods can be used to display correlated topic models on social media texts using SocialVisTUM, our proposed interactive visualization toolkit. It displays a graph with topics as nodes and their correlations as edges. Further details are displayed interactively to support the exploration of large text collections, e.g., representative words and sentences of topics, topic and sentiment distributions, hierarchical topic clustering, and customizable, predefined topic labels. The toolkit optimizes automatically on custom data for optimal coherence. We show a working instance of the toolkit on data crawled from English social media discussions about organic food consumption. The visualization confirms findings of a qualitative consumer research study. SocialVisTUM and its training procedures ar
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22797;&#26434;&#30340;&#19987;&#23478;&#27880;&#35299;&#22312;&#31038;&#20132;&#23186;&#20307;&#20013;&#36827;&#34892;&#28040;&#36153;&#32773;&#20449;&#24565;&#38472;&#36848;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#27604;&#36739;&#20102;&#32454;&#31890;&#24230;&#21644;&#25277;&#35937;&#31867;&#21035;&#30340;&#26631;&#31614;&#65292;&#24182;&#35828;&#26126;&#22797;&#26434;&#19987;&#23478;&#27880;&#35299;&#22312;&#39640;&#24230;&#29305;&#23450;&#30340;&#24847;&#35265;&#25366;&#25496;&#20013;&#30340;&#28508;&#22312;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2106.15498</link><description>&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#20013;&#28040;&#36153;&#32773;&#20449;&#24565;&#38472;&#36848;&#30340;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Classification of Consumer Belief Statements From Social Media. (arXiv:2106.15498v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.15498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22797;&#26434;&#30340;&#19987;&#23478;&#27880;&#35299;&#22312;&#31038;&#20132;&#23186;&#20307;&#20013;&#36827;&#34892;&#28040;&#36153;&#32773;&#20449;&#24565;&#38472;&#36848;&#20998;&#31867;&#30340;&#20934;&#30830;&#24615;&#65292;&#27604;&#36739;&#20102;&#32454;&#31890;&#24230;&#21644;&#25277;&#35937;&#31867;&#21035;&#30340;&#26631;&#31614;&#65292;&#24182;&#35828;&#26126;&#22797;&#26434;&#19987;&#23478;&#27880;&#35299;&#22312;&#39640;&#24230;&#29305;&#23450;&#30340;&#24847;&#35265;&#25366;&#25496;&#20013;&#30340;&#28508;&#22312;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#25552;&#20379;&#20102;&#22823;&#37327;&#20449;&#24687;&#65292;&#21487;&#20197;&#36827;&#34892;&#24066;&#22330;&#35843;&#30740;&#65292;&#20197;&#28385;&#36275;&#23458;&#25143;&#30340;&#38656;&#27714;&#12290;&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#36890;&#36807;&#25910;&#38598;&#21644;&#20998;&#31867;&#29992;&#25143;&#29983;&#25104;&#30340;&#20869;&#23481;&#65292;&#26500;&#24314;&#22797;&#26434;&#32454;&#31890;&#24230;&#30340;&#31867;&#21035;&#32467;&#26500;&#26469;&#36827;&#34892;&#24066;&#22330;&#35843;&#30740;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25968;&#25454;&#37327;&#36739;&#23569;&#19988;&#27880;&#35299;&#22797;&#26434;&#12290;&#22914;&#20309;&#25104;&#21151;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#20173;&#19981;&#23436;&#20840;&#28165;&#26970;&#12290;&#26412;&#30740;&#31350;&#32771;&#23519;&#20102;&#24403;&#19987;&#23478;&#27880;&#35299;&#34987;&#24212;&#29992;&#20110;a) &#35768;&#22810;&#32454;&#31890;&#24230;&#31867;&#21035;&#21644;b) &#23569;&#25968;&#25277;&#35937;&#31867;&#21035;&#26102;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;&#23545;&#20110;&#22330;&#26223;b)&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#39046;&#22495;&#19987;&#23478;&#32473;&#20986;&#30340;&#25277;&#35937;&#31867;&#21035;&#26631;&#31614;&#65288;&#22522;&#20934;&#65289;&#21644;&#33258;&#21160;&#20998;&#23618;&#32858;&#31867;&#32473;&#20986;&#30340;&#25277;&#35937;&#31867;&#21035;&#26631;&#31614;&#12290;&#25105;&#20204;&#23558;&#20854;&#19982;&#21478;&#19968;&#22522;&#20934;&#36827;&#34892;&#27604;&#36739;&#65292;&#35813;&#22522;&#20934;&#20351;&#29992;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#32858;&#31867;&#26041;&#27861;&#32473;&#20986;&#25972;&#20010;&#31867;&#21035;&#32467;&#26500;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#35813;&#30740;&#31350;&#21487;&#20197;&#20316;&#20026;&#22797;&#26434;&#19987;&#23478;&#27880;&#35299;&#22914;&#20309;&#22312;&#39640;&#24230;&#29305;&#23450;&#30340;&#24847;&#35265;&#25366;&#25496;&#20013;&#21457;&#25381;&#28508;&#22312;&#20248;&#21183;&#65292;&#24182;&#20197;&#26368;&#20248;&#21270;&#30340;&#26041;&#24335;&#21033;&#29992;&#30340;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Social media offer plenty of information to perform market research in order to meet the requirements of customers. One way how this research is conducted is that a domain expert gathers and categorizes user-generated content into a complex and fine-grained class structure. In many of such cases, little data meets complex annotations. It is not yet fully understood how this can be leveraged successfully for classification. We examine the classification accuracy of expert labels when used with a) many fine-grained classes and b) few abstract classes. For scenario b) we compare abstract class labels given by the domain expert as baseline and by automatic hierarchical clustering. We compare this to another baseline where the entire class structure is given by a completely unsupervised clustering approach. By doing so, this work can serve as an example of how complex expert annotations are potentially beneficial and can be utilized in the most optimal way for opinion mining in highly speci
&lt;/p&gt;</description></item></channel></rss>