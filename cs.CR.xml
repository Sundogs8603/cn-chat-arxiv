<rss version="2.0"><channel><title>Chat Arxiv cs.CR</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CR</description><item><title>&#26412;&#25991;&#20351;&#29992;&#22686;&#24378;&#22411;&#38543;&#26426;&#26862;&#26519;&#20998;&#31867;&#22120;&#21644;&#21512;&#25104;&#23569;&#25968;&#31867;&#36807;&#37319;&#26679;&#25216;&#26415;&#26469;&#35299;&#20915;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;&#20013;&#30340;&#19981;&#24179;&#34913;&#25968;&#25454;&#38382;&#39064;&#65292;&#33719;&#24471;&#20102;98%&#30340;&#20934;&#30830;&#24230;&#21644;F1&#20998;&#25968;&#20540;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2303.06514</link><description>&lt;p&gt;
&#20351;&#29992;&#22686;&#24378;&#22411;&#38543;&#26426;&#26862;&#26519;&#20998;&#31867;&#22120;&#26816;&#27979;&#19981;&#24179;&#34913;&#25968;&#25454;&#20013;&#30340;&#20449;&#29992;&#21345;&#27450;&#35784;
&lt;/p&gt;
&lt;p&gt;
Credit Card Fraud Detection Using Enhanced Random Forest Classifier for Imbalanced Data. (arXiv:2303.06514v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06514
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#22686;&#24378;&#22411;&#38543;&#26426;&#26862;&#26519;&#20998;&#31867;&#22120;&#21644;&#21512;&#25104;&#23569;&#25968;&#31867;&#36807;&#37319;&#26679;&#25216;&#26415;&#26469;&#35299;&#20915;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;&#20013;&#30340;&#19981;&#24179;&#34913;&#25968;&#25454;&#38382;&#39064;&#65292;&#33719;&#24471;&#20102;98%&#30340;&#20934;&#30830;&#24230;&#21644;F1&#20998;&#25968;&#20540;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an enhanced random forest classifier and synthetic minority over-sampling technique to address the issue of imbalanced data in credit card fraud detection, achieving an accuracy of 98% and F1-score value of about 98%, with potential practical applications.
&lt;/p&gt;
&lt;p&gt;
&#20449;&#29992;&#21345;&#24050;&#25104;&#20026;&#22312;&#32447;&#21644;&#31163;&#32447;&#20132;&#26131;&#20013;&#26368;&#27969;&#34892;&#30340;&#25903;&#20184;&#26041;&#24335;&#12290;&#38543;&#30528;&#25216;&#26415;&#30340;&#21457;&#23637;&#21644;&#27450;&#35784;&#26696;&#20214;&#30340;&#22686;&#21152;&#65292;&#21019;&#24314;&#27450;&#35784;&#26816;&#27979;&#31639;&#27861;&#20197;&#31934;&#30830;&#35782;&#21035;&#21644;&#20572;&#27490;&#27450;&#35784;&#27963;&#21160;&#30340;&#24517;&#35201;&#24615;&#20063;&#38543;&#20043;&#20135;&#29983;&#12290;&#26412;&#25991;&#23454;&#29616;&#20102;&#38543;&#26426;&#26862;&#26519;&#65288;RF&#65289;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#20102;&#19968;&#32452;&#20449;&#29992;&#21345;&#20132;&#26131;&#25968;&#25454;&#38598;&#12290;&#22312;&#22788;&#29702;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;&#26102;&#30340;&#20027;&#35201;&#38382;&#39064;&#26159;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#20132;&#26131;&#37117;&#26159;&#38750;&#27450;&#35784;&#20132;&#26131;&#12290;&#20026;&#20102;&#20811;&#26381;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#65292;&#20351;&#29992;&#20102;&#21512;&#25104;&#23569;&#25968;&#31867;&#36807;&#37319;&#26679;&#25216;&#26415;&#65288;SMOTE&#65289;&#12290;&#23454;&#29616;&#36229;&#21442;&#25968;&#25216;&#26415;&#20197;&#22686;&#24378;&#38543;&#26426;&#26862;&#26519;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;RF&#20998;&#31867;&#22120;&#33719;&#24471;&#20102;98&#65285;&#30340;&#20934;&#30830;&#24230;&#21644;&#32422;98&#65285;&#30340;F1&#20998;&#25968;&#20540;&#65292;&#36825;&#26159;&#20196;&#20154;&#20852;&#22859;&#30340;&#12290;&#25105;&#20204;&#36824;&#30456;&#20449;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#30456;&#23545;&#23481;&#26131;&#24212;&#29992;&#65292;&#24182;&#19988;&#21487;&#20197;&#20811;&#26381;&#20449;&#29992;&#21345;&#27450;&#35784;&#26816;&#27979;&#20013;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
The credit card has become the most popular payment method for both online and offline transactions. The necessity to create a fraud detection algorithm to precisely identify and stop fraudulent activity arises as a result of both the development of technology and the rise in fraud cases. This paper implements the random forest (RF) algorithm to solve the issue in the hand. A dataset of credit card transactions was used in this study. The main problem when dealing with credit card fraud detection is the imbalanced dataset in which most of the transaction are non-fraud ones. To overcome the problem of the imbalanced dataset, the synthetic minority over-sampling technique (SMOTE) was used. Implementing the hyperparameters technique to enhance the performance of the random forest classifier. The results showed that the RF classifier gained an accuracy of 98% and about 98% of F1-score value, which is promising. We also believe that our model is relatively easy to apply and can overcome the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#36719;&#20214;&#23450;&#20041;&#32593;&#32476;&#65288;SDN&#65289;&#29615;&#22659;&#20013;&#26816;&#27979;&#20998;&#24067;&#24335;&#25298;&#32477;&#26381;&#21153;&#65288;DDoS&#65289;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#65292;&#36890;&#36807;&#27979;&#35797;&#22235;&#31181;&#31639;&#27861;&#65292;&#20854;&#20013;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#12290;</title><link>http://arxiv.org/abs/2303.06513</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26816;&#27979;&#36719;&#20214;&#23450;&#20041;&#32593;&#32476;&#20013;&#30340;DDoS&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Detection of DDoS Attacks in Software Defined Networking Using Machine Learning Models. (arXiv:2303.06513v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#36719;&#20214;&#23450;&#20041;&#32593;&#32476;&#65288;SDN&#65289;&#29615;&#22659;&#20013;&#26816;&#27979;&#20998;&#24067;&#24335;&#25298;&#32477;&#26381;&#21153;&#65288;DDoS&#65289;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#65292;&#36890;&#36807;&#27979;&#35797;&#22235;&#31181;&#31639;&#27861;&#65292;&#20854;&#20013;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the effectiveness of using machine learning algorithms to detect distributed denial-of-service (DDoS) attacks in software-defined networking (SDN) environments, and tests four algorithms on the CICDDoS2019 dataset, with Random Forest performing the best.
&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#23450;&#20041;&#32593;&#32476;&#65288;SDN&#65289;&#30340;&#27010;&#24565;&#20195;&#34920;&#20102;&#19968;&#31181;&#29616;&#20195;&#30340;&#32593;&#32476;&#26041;&#27861;&#65292;&#36890;&#36807;&#32593;&#32476;&#25277;&#35937;&#23558;&#25511;&#21046;&#24179;&#38754;&#19982;&#25968;&#25454;&#24179;&#38754;&#20998;&#31163;&#65292;&#20174;&#32780;&#23454;&#29616;&#19982;&#20256;&#32479;&#32593;&#32476;&#30456;&#27604;&#26356;&#28789;&#27963;&#12289;&#21487;&#32534;&#31243;&#21644;&#21160;&#24577;&#30340;&#26550;&#26500;&#12290;&#25511;&#21046;&#24179;&#38754;&#21644;&#25968;&#25454;&#24179;&#38754;&#30340;&#20998;&#31163;&#23548;&#33268;&#20102;&#39640;&#24230;&#30340;&#32593;&#32476;&#24377;&#24615;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26032;&#30340;&#23433;&#20840;&#39118;&#38505;&#65292;&#21253;&#25324;&#20998;&#24067;&#24335;&#25298;&#32477;&#26381;&#21153;&#65288;DDoS&#65289;&#25915;&#20987;&#30340;&#23041;&#32961;&#65292;&#36825;&#22312;SDN&#29615;&#22659;&#20013;&#26500;&#25104;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#36719;&#20214;&#23450;&#20041;&#32593;&#32476;&#65288;SDN&#65289;&#29615;&#22659;&#20013;&#26816;&#27979;&#20998;&#24067;&#24335;&#25298;&#32477;&#26381;&#21153;&#65288;DDoS&#65289;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;CICDDoS2019&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#22235;&#31181;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#12289;&#20915;&#31574;&#26641;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;XGBoost&#65292;&#20854;&#20013;&#26102;&#38388;&#25139;&#29305;&#24449;&#34987;&#21024;&#38500;&#31561;&#12290;&#36890;&#36807;&#20934;&#30830;&#29575;&#12289;&#21484;&#22238;&#29575;&#12289;&#20934;&#30830;&#29575;&#21644;F1&#20998;&#25968;&#31561;&#25351;&#26631;&#35780;&#20272;&#20102;&#24615;&#33021;&#65292;&#20854;&#20013;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;
The concept of Software Defined Networking (SDN) represents a modern approach to networking that separates the control plane from the data plane through network abstraction, resulting in a flexible, programmable and dynamic architecture compared to traditional networks. The separation of control and data planes has led to a high degree of network resilience, but has also given rise to new security risks, including the threat of distributed denial-of-service (DDoS) attacks, which pose a new challenge in the SDN environment. In this paper, the effectiveness of using machine learning algorithms to detect distributed denial-of-service (DDoS) attacks in software-defined networking (SDN) environments is investigated. Four algorithms, including Random Forest, Decision Tree, Support Vector Machine, and XGBoost, were tested on the CICDDoS2019 dataset, with the timestamp feature dropped among others. Performance was assessed by measures of accuracy, recall, accuracy, and F1 score, with the Rando
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21306;&#22359;&#38142;&#30340;&#21435;&#20013;&#24515;&#21270;&#25237;&#31080;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#36523;&#20221;&#35782;&#21035;&#26041;&#24335;&#65292;&#20351;&#24471;&#27599;&#20010;&#20154;&#37117;&#33021;&#36861;&#36394;&#25237;&#31080;&#27450;&#35784;&#65292;&#31995;&#32479;&#38750;&#24120;&#23433;&#20840;&#12290;</title><link>http://arxiv.org/abs/2303.06306</link><description>&lt;p&gt;
&#22522;&#20110;&#21306;&#22359;&#38142;&#30340;&#21435;&#20013;&#24515;&#21270;&#25237;&#31080;&#31995;&#32479;&#23433;&#20840;&#35270;&#35282;&#65306;&#25968;&#23383;&#25237;&#31080;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#21644;&#20445;&#38556;
&lt;/p&gt;
&lt;p&gt;
Blockchain-based decentralized voting system security Perspective: Safe and secure for digital voting system. (arXiv:2303.06306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21306;&#22359;&#38142;&#30340;&#21435;&#20013;&#24515;&#21270;&#25237;&#31080;&#31995;&#32479;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#36523;&#20221;&#35782;&#21035;&#26041;&#24335;&#65292;&#20351;&#24471;&#27599;&#20010;&#20154;&#37117;&#33021;&#36861;&#36394;&#25237;&#31080;&#27450;&#35784;&#65292;&#31995;&#32479;&#38750;&#24120;&#23433;&#20840;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the blockchain-based decentralized voting system and proposes a unique identification method that enables everyone to trace vote fraud, making the system incredibly safe.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#22522;&#20110;&#21306;&#22359;&#38142;&#30340;&#25237;&#31080;&#31995;&#32479;&#65292;&#20026;&#36873;&#27665;&#12289;&#20505;&#36873;&#20154;&#21644;&#23448;&#21592;&#21442;&#19982;&#21644;&#31649;&#29702;&#25237;&#31080;&#25552;&#20379;&#20415;&#21033;&#12290;&#30001;&#20110;&#25105;&#20204;&#22312;&#21518;&#31471;&#20351;&#29992;&#20102;&#21306;&#22359;&#38142;&#65292;&#20351;&#24471;&#27599;&#20010;&#20154;&#37117;&#33021;&#36861;&#36394;&#25237;&#31080;&#27450;&#35784;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#31995;&#32479;&#38750;&#24120;&#23433;&#20840;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#36523;&#20221;&#35782;&#21035;&#26041;&#24335;&#65292;&#21363;&#20351;&#29992;Aadhar&#21345;&#21495;&#25110;OTP&#29983;&#25104;&#65292;&#28982;&#21518;&#29992;&#25143;&#21487;&#20197;&#21033;&#29992;&#25237;&#31080;&#31995;&#32479;&#25237;&#31080;&#12290;&#25552;&#20986;&#20102;&#27604;&#29305;&#24065;&#30340;&#24314;&#35758;&#65292;&#27604;&#29305;&#24065;&#26159;&#19968;&#31181;&#34394;&#25311;&#36135;&#24065;&#31995;&#32479;&#65292;&#30001;&#20013;&#22830;&#26426;&#26500;&#20915;&#23450;&#29983;&#20135;&#36135;&#24065;&#12289;&#36716;&#31227;&#25152;&#26377;&#26435;&#21644;&#39564;&#35777;&#20132;&#26131;&#65292;&#21253;&#25324;&#28857;&#23545;&#28857;&#32593;&#32476;&#22312;&#21306;&#22359;&#38142;&#31995;&#32479;&#20013;&#65292;&#36134;&#26412;&#22312;&#22810;&#20010;&#30456;&#21516;&#30340;&#25968;&#25454;&#24211;&#20013;&#22797;&#21046;&#65292;&#30001;&#19981;&#21516;&#30340;&#36827;&#31243;&#25176;&#31649;&#21644;&#26356;&#26032;&#65292;&#22914;&#26524;&#23545;&#19968;&#20010;&#33410;&#28857;&#36827;&#34892;&#26356;&#25913;&#24182;&#21457;&#29983;&#20132;&#26131;&#65292;&#21017;&#25152;&#26377;&#20854;&#20182;&#33410;&#28857;&#20250;&#21516;&#26102;&#26356;&#26032;&#65292;&#20215;&#20540;&#21644;&#36164;&#20135;&#30340;&#35760;&#24405;&#23558;&#27704;&#20037;&#20132;&#25442;&#65292;&#21482;&#26377;&#29992;&#25143;&#21644;&#31995;&#32479;&#38656;&#35201;&#36827;&#34892;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research study focuses primarily on Block-Chain-based voting systems, which facilitate participation in and administration of voting for voters, candidates, and officials. Because we used Block-Chain in the backend, which enables everyone to trace vote fraud, our system is incredibly safe. This paper approach any unique identification the Aadhar Card number or an OTP will be generated then user can utilise the voting system to cast his/her vote. A proposal for Bit-coin, a virtual currency system that is decided by a central authority for producing money, transferring ownership, and validating transactions, included the peer-to-peer network in a Block-Chain system, the ledger is duplicated across several, identical databases which is hosted and updated by a different process and all other nodes are updated concurrently if changes made to one node and a transaction occurs, the records of the values and assets are permanently exchanged, Only the user and the system need to be verifie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#26377;&#29366;&#24577;&#38450;&#24481;&#40657;&#30418;&#23545;&#25239;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26377;&#29366;&#24577;&#38450;&#24481;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;CIFAR10&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;82.2&#65285;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;ImageNet&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;76.5&#65285;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.06280</link><description>&lt;p&gt;
&#25506;&#31350;&#26377;&#29366;&#24577;&#38450;&#24481;&#40657;&#30418;&#23545;&#25239;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Investigating Stateful Defenses Against Black-Box Adversarial Examples. (arXiv:2303.06280v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#26377;&#29366;&#24577;&#38450;&#24481;&#40657;&#30418;&#23545;&#25239;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26377;&#29366;&#24577;&#38450;&#24481;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;CIFAR10&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;82.2&#65285;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;ImageNet&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;76.5&#65285;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates stateful defenses against black-box adversarial examples and proposes a new stateful defense model that achieves 82.2% accuracy on the CIFAR10 dataset and 76.5% accuracy on the ImageNet dataset.
&lt;/p&gt;
&lt;p&gt;
&#38450;&#24481;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#20813;&#21463;&#30333;&#30418;&#23545;&#25239;&#25915;&#20987;&#24050;&#34987;&#35777;&#26126;&#26497;&#20026;&#22256;&#38590;&#12290;&#30456;&#21453;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#26377;&#29366;&#24577;&#38450;&#24481;&#65292;&#35797;&#22270;&#38450;&#24481;&#26356;&#21463;&#38480;&#21046;&#30340;&#40657;&#30418;&#25915;&#20987;&#32773;&#12290;&#36825;&#20123;&#38450;&#24481;&#36890;&#36807;&#36319;&#36394;&#20256;&#20837;&#27169;&#22411;&#26597;&#35810;&#30340;&#21382;&#21490;&#35760;&#24405;&#65292;&#24182;&#25298;&#32477;&#37027;&#20123;&#21487;&#30097;&#22320;&#30456;&#20284;&#30340;&#26597;&#35810;&#26469;&#25805;&#20316;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26377;&#29366;&#24577;&#38450;&#24481;Blacklight&#26159;&#22312;USENIX Security '22&#19978;&#25552;&#20986;&#30340;&#65292;&#22768;&#31216;&#21487;&#20197;&#38450;&#27490;&#20960;&#20046;100&#65285;&#30340;CIFAR10&#21644;ImageNet&#25968;&#25454;&#38598;&#19978;&#30340;&#25915;&#20987;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#35843;&#25972;&#29616;&#26377;&#40657;&#30418;&#25915;&#20987;&#30340;&#21442;&#25968;&#65292;&#26174;&#33879;&#38477;&#20302;&#21463;Blacklight&#20445;&#25252;&#30340;&#20998;&#31867;&#22120;&#30340;&#20934;&#30830;&#24615;&#65288;&#20363;&#22914;&#65292;&#22312;CIFAR10&#19978;&#20174;82.2&#65285;&#38477;&#33267;6.4&#65285;&#65289;&#12290;&#21463;&#21040;&#36825;&#19968;&#24778;&#20154;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#29366;&#24577;&#38450;&#24481;&#30340;&#31995;&#32479;&#21270;&#65292;&#20197;&#20102;&#35299;&#20026;&#20160;&#20040;&#29616;&#26377;&#30340;&#26377;&#29366;&#24577;&#38450;&#24481;&#27169;&#22411;&#20250;&#22833;&#36133;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26377;&#29366;&#24577;&#38450;&#24481;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;CIFAR10&#25968;&#25454;&#38598;&#19978;&#30340;&#20934;&#30830;&#24615;&#20026;82.2&#65285;&#65292;&#22312;ImageNet&#25968;&#25454;&#38598;&#19978;&#30340;&#20934;&#30830;&#24615;&#20026;76.5&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
Defending machine-learning (ML) models against white-box adversarial attacks has proven to be extremely difficult. Instead, recent work has proposed stateful defenses in an attempt to defend against a more restricted black-box attacker. These defenses operate by tracking a history of incoming model queries, and rejecting those that are suspiciously similar. The current state-of-the-art stateful defense Blacklight was proposed at USENIX Security '22 and claims to prevent nearly 100% of attacks on both the CIFAR10 and ImageNet datasets. In this paper, we observe that an attacker can significantly reduce the accuracy of a Blacklight-protected classifier (e.g., from 82.2% to 6.4% on CIFAR10) by simply adjusting the parameters of an existing black-box attack. Motivated by this surprising observation, since existing attacks were evaluated by the Blacklight authors, we provide a systematization of stateful defenses to understand why existing stateful defense models fail. Finally, we propose a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#23454;&#29992;&#30340;&#26631;&#31614;&#19981;&#21487;&#30693;&#35774;&#32622;&#65292;&#20197;&#29983;&#25104;&#19981;&#21487;&#23398;&#20064;&#30340;&#26679;&#26412;&#65292;&#38450;&#27490;&#26410;&#32463;&#25480;&#26435;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2301.01217</link><description>&lt;p&gt;
&#19981;&#21487;&#23398;&#20064;&#30340;&#32858;&#31867;&#65306;&#38754;&#21521;&#26631;&#31614;&#19981;&#21487;&#30693;&#30340;&#19981;&#21487;&#23398;&#20064;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples. (arXiv:2301.01217v3 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.01217
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#23454;&#29992;&#30340;&#26631;&#31614;&#19981;&#21487;&#30693;&#35774;&#32622;&#65292;&#20197;&#29983;&#25104;&#19981;&#21487;&#23398;&#20064;&#30340;&#26679;&#26412;&#65292;&#38450;&#27490;&#26410;&#32463;&#25480;&#26435;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a more practical label-agnostic setting to generate unlearnable examples, which can prevent unauthorized training of machine learning models.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20114;&#32852;&#32593;&#19978;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#23545;&#24320;&#21457;&#19981;&#21487;&#23398;&#20064;&#30340;&#31034;&#20363;&#65288;UEs&#65289;&#26469;&#38450;&#27490;&#35270;&#35273;&#38544;&#31169;&#27844;&#38706;&#24863;&#20852;&#36259;&#12290;UEs&#26159;&#28155;&#21152;&#20102;&#19981;&#21487;&#35265;&#20294;&#19981;&#21487;&#23398;&#20064;&#22122;&#22768;&#30340;&#35757;&#32451;&#26679;&#26412;&#65292;&#24050;&#32463;&#21457;&#29616;&#21487;&#20197;&#38450;&#27490;&#26410;&#32463;&#25480;&#26435;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12290;UEs&#36890;&#24120;&#26159;&#36890;&#36807;&#19968;&#20010;&#21452;&#23618;&#20248;&#21270;&#26694;&#26550;&#21644;&#19968;&#20010;&#26367;&#20195;&#27169;&#22411;&#29983;&#25104;&#30340;&#65292;&#20197;&#20174;&#21407;&#22987;&#26679;&#26412;&#20013;&#21435;&#38500;&#65288;&#26368;&#23567;&#21270;&#65289;&#38169;&#35823;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#20445;&#25252;&#25968;&#25454;&#20813;&#21463;&#26410;&#30693;&#30446;&#26631;&#27169;&#22411;&#30340;&#25915;&#20987;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;UE&#29983;&#25104;&#26041;&#27861;&#37117;&#20381;&#36182;&#20110;&#19968;&#20010;&#29702;&#24819;&#30340;&#20551;&#35774;&#65292;&#31216;&#20026;&#26631;&#31614;&#19968;&#33268;&#24615;&#65292;&#21363;&#20551;&#23450;&#40657;&#23458;&#21644;&#20445;&#25252;&#32773;&#23545;&#20110;&#32473;&#23450;&#30340;&#26679;&#26412;&#25345;&#26377;&#30456;&#21516;&#30340;&#26631;&#31614;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#25512;&#24191;&#20102;&#19968;&#20010;&#26356;&#23454;&#29992;&#30340;&#26631;&#31614;&#19981;&#21487;&#30693;&#35774;&#32622;&#65292;&#20854;&#20013;&#40657;&#23458;&#21487;&#33021;&#20250;&#20197;&#19982;&#20445;&#25252;&#32773;&#23436;&#20840;&#19981;&#21516;&#30340;&#26041;&#24335;&#21033;&#29992;&#21463;&#20445;&#25252;&#30340;&#25968;&#25454;&#12290;&#20363;&#22914;&#65292;&#30001;&#20445;&#25252;&#32773;&#25345;&#26377;&#30340;m&#31867;&#19981;&#21487;&#23398;&#20064;&#25968;&#25454;&#38598;&#21487;&#33021;&#34987;&#40657;&#23458;&#20316;&#20026;n&#31867;&#25968;&#25454;&#38598;&#21033;&#29992;&#12290;&#29616;&#26377;&#30340;UE&#29983;&#25104;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#22833;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in developing unlearnable examples (UEs) against visual privacy leaks on the Internet. UEs are training samples added with invisible but unlearnable noise, which have been found can prevent unauthorized training of machine learning models. UEs typically are generated via a bilevel optimization framework with a surrogate model to remove (minimize) errors from the original samples, and then applied to protect the data against unknown target models. However, existing UE generation methods all rely on an ideal assumption called label-consistency, where the hackers and protectors are assumed to hold the same label for a given sample. In this work, we propose and promote a more practical label-agnostic setting, where the hackers may exploit the protected data quite differently from the protectors. E.g., a m-class unlearnable dataset held by the protector may be exploited by the hacker as a n-class dataset. Existing UE generation methods are rendered ineffective in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25554;&#20540;MVU&#26426;&#21046;&#65292;&#36890;&#36807;&#25968;&#20540;&#26426;&#21046;&#35774;&#35745;&#23454;&#29616;&#38754;&#21521;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#21387;&#32553;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#38544;&#31169;&#25928;&#29992;&#26435;&#34913;&#21644;&#26356;&#39640;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#25552;&#20379;&#20102;&#36890;&#20449;&#39640;&#25928;&#30340;&#31169;&#26377;FL&#30340;SOTA&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.03942</link><description>&lt;p&gt;
&#38754;&#21521;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#21387;&#32553;&#65306;&#36890;&#36807;&#25968;&#20540;&#26426;&#21046;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design. (arXiv:2211.03942v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.03942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25554;&#20540;MVU&#26426;&#21046;&#65292;&#36890;&#36807;&#25968;&#20540;&#26426;&#21046;&#35774;&#35745;&#23454;&#29616;&#38754;&#21521;&#38544;&#31169;&#30340;&#32852;&#37030;&#23398;&#20064;&#21387;&#32553;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#38544;&#31169;&#25928;&#29992;&#26435;&#34913;&#21644;&#26356;&#39640;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#25552;&#20379;&#20102;&#36890;&#20449;&#39640;&#25928;&#30340;&#31169;&#26377;FL&#30340;SOTA&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new Interpolated MVU mechanism for privacy-aware compression in federated learning, which achieves a better privacy-utility trade-off and scalability through numerical mechanism design, and provides SOTA results on communication-efficient private FL on a variety of datasets.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#65292;&#26381;&#21153;&#22120;&#32858;&#21512;&#26469;&#33258;&#22823;&#37327;&#23458;&#25143;&#31471;&#30340;&#24046;&#20998;&#38544;&#31169;&#26356;&#26032;&#65292;&#20197;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22312;&#38544;&#31169;&#21644;&#23398;&#20064;&#27169;&#22411;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#20197;&#21450;&#23458;&#25143;&#31471;&#21644;&#26381;&#21153;&#22120;&#20043;&#38388;&#36890;&#20449;&#30340;&#20301;&#25968;&#20043;&#38388;&#24179;&#34913;&#38544;&#31169;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#38544;&#31169;&#24863;&#30693;&#21387;&#32553;&#26426;&#21046;&#65288;&#31216;&#20026;&#26368;&#23567;&#26041;&#24046;&#26080;&#20559;&#65288;MVU&#65289;&#26426;&#21046;&#65289;&#26469;&#23454;&#29616;&#33391;&#22909;&#30340;&#26435;&#34913;&#65292;&#35813;&#26426;&#21046;&#36890;&#36807;&#25968;&#20540;&#27714;&#35299;&#20248;&#21270;&#38382;&#39064;&#26469;&#30830;&#23450;&#26426;&#21046;&#30340;&#21442;&#25968;&#12290;&#26412;&#25991;&#22312;&#27492;&#22522;&#30784;&#19978;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25554;&#20540;&#36807;&#31243;&#65292;&#29992;&#20110;&#25968;&#20540;&#35774;&#35745;&#36807;&#31243;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#38544;&#31169;&#20998;&#26512;&#12290;&#32467;&#26524;&#26159;&#26032;&#30340;&#25554;&#20540;MVU&#26426;&#21046;&#65292;&#23427;&#26356;&#20855;&#21487;&#25193;&#23637;&#24615;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#38544;&#31169;&#25928;&#29992;&#26435;&#34913;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#25552;&#20379;&#20102;&#36890;&#20449;&#39640;&#25928;&#30340;&#31169;&#26377;FL&#30340;SOTA&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In private federated learning (FL), a server aggregates differentially private updates from a large number of clients in order to train a machine learning model. The main challenge in this setting is balancing privacy with both classification accuracy of the learnt model as well as the number of bits communicated between the clients and server. Prior work has achieved a good trade-off by designing a privacy-aware compression mechanism, called the minimum variance unbiased (MVU) mechanism, that numerically solves an optimization problem to determine the parameters of the mechanism. This paper builds upon it by introducing a new interpolation procedure in the numerical design process that allows for a far more efficient privacy analysis. The result is the new Interpolated MVU mechanism that is more scalable, has a better privacy-utility trade-off, and provides SOTA results on communication-efficient private FL on a variety of datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#35774;&#35745;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#36807;&#28388;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27169;&#24577;&#34701;&#21512;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#22522;&#20110;&#25991;&#26412;&#25110;&#22522;&#20110;&#22270;&#20687;&#30340;&#36807;&#28388;&#22120;&#26080;&#27861;&#26816;&#27979;&#21040;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2210.14616</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#26816;&#27979;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#30340;&#22810;&#27169;&#24577;&#34701;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Late Multi-Modal Fusion Model for Detecting Hybrid Spam E-mail. (arXiv:2210.14616v3 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#35774;&#35745;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#36807;&#28388;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27169;&#24577;&#34701;&#21512;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#22522;&#20110;&#25991;&#26412;&#25110;&#22522;&#20110;&#22270;&#20687;&#30340;&#36807;&#28388;&#22120;&#26080;&#27861;&#26816;&#27979;&#21040;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study aims to design an effective approach filtering out hybrid spam e-mails and proposes a late multi-modal fusion model to solve the problem of traditional text-based or image-based filters failing to detect hybrid spam e-mails.
&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22403;&#22334;&#37038;&#20214;&#21457;&#36865;&#32773;&#24320;&#22987;&#36890;&#36807;&#24341;&#20837;&#22270;&#20687;&#21644;&#25991;&#26412;&#37096;&#20998;&#30340;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#26469;&#28151;&#28102;&#20854;&#24847;&#22270;&#65292;&#36825;&#27604;&#20165;&#21253;&#21547;&#25991;&#26412;&#25110;&#22270;&#20687;&#30340;&#30005;&#23376;&#37038;&#20214;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#26412;&#30740;&#31350;&#30340;&#21160;&#26426;&#26159;&#35774;&#35745;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#36807;&#28388;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#65292;&#20197;&#36991;&#20813;&#20256;&#32479;&#30340;&#22522;&#20110;&#25991;&#26412;&#25110;&#22522;&#20110;&#22270;&#20687;&#30340;&#36807;&#28388;&#22120;&#26080;&#27861;&#26816;&#27979;&#21040;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#30340;&#24773;&#20917;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#21482;&#26377;&#23569;&#25968;&#30740;&#31350;&#26088;&#22312;&#26816;&#27979;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#12290;&#36890;&#24120;&#65292;&#20809;&#23398;&#23383;&#31526;&#35782;&#21035;&#65288;OCR&#65289;&#25216;&#26415;&#29992;&#20110;&#36890;&#36807;&#23558;&#22270;&#20687;&#36716;&#25442;&#20026;&#25991;&#26412;&#26469;&#28040;&#38500;&#22403;&#22334;&#37038;&#20214;&#30340;&#22270;&#20687;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#30740;&#31350;&#38382;&#39064;&#26159;&#65292;&#23613;&#31649;OCR&#25195;&#25551;&#26159;&#22788;&#29702;&#25991;&#26412;&#21644;&#22270;&#20687;&#28151;&#21512;&#22403;&#22334;&#37038;&#20214;&#30340;&#38750;&#24120;&#25104;&#21151;&#30340;&#25216;&#26415;&#65292;&#20294;&#30001;&#20110;&#25152;&#38656;&#30340;CPU&#21151;&#29575;&#21644;&#25195;&#25551;&#30005;&#23376;&#37038;&#20214;&#25991;&#20214;&#25152;&#38656;&#30340;&#25191;&#34892;&#26102;&#38388;&#65292;&#23427;&#19981;&#26159;&#22788;&#29702;&#22823;&#37327;&#22403;&#22334;&#37038;&#20214;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, spammers are now trying to obfuscate their intents by introducing hybrid spam e-mail combining both image and text parts, which is more challenging to detect in comparison to e-mails containing text or image only. The motivation behind this research is to design an effective approach filtering out hybrid spam e-mails to avoid situations where traditional text-based or image-baesd only filters fail to detect hybrid spam e-mails. To the best of our knowledge, a few studies have been conducted with the goal of detecting hybrid spam e-mails. Ordinarily, Optical Character Recognition (OCR) technology is used to eliminate the image parts of spam by transforming images into text. However, the research questions are that although OCR scanning is a very successful technique in processing text-and-image hybrid spam, it is not an effective solution for dealing with huge quantities due to the CPU power required and the execution time it takes to scan e-mail files. And the OCR tech
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#31216;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#32763;&#36716;&#25110;&#27700;&#24179;&#32763;&#36716;&#23545;&#31216;&#23545;&#25239;&#26679;&#26412;&#26469;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#20351;&#29992;&#23376;&#32676;&#23545;&#31216;&#24615;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2210.04087</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;CNN&#25200;&#21160;&#25915;&#20987;&#30340;&#23545;&#31216;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Symmetry Defense Against CNN Adversarial Perturbation Attacks. (arXiv:2210.04087v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#31216;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#32763;&#36716;&#25110;&#27700;&#24179;&#32763;&#36716;&#23545;&#31216;&#23545;&#25239;&#26679;&#26412;&#26469;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#20351;&#29992;&#23376;&#32676;&#23545;&#31216;&#24615;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a symmetry defense method to improve adversarial robustness by flipping or horizontally flipping symmetric adversarial samples, and uses subgroup symmetries for classification.
&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#65288;CNN&#65289;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#36825;&#20123;&#25915;&#20987;&#20250;&#25200;&#21160;&#21407;&#22987;&#26679;&#26412;&#20197;&#27450;&#39575;&#20998;&#31867;&#22120;&#65292;&#20363;&#22914;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#30340;&#36947;&#36335;&#26631;&#24535;&#22270;&#20687;&#20998;&#31867;&#22120;&#12290;CNN&#22312;&#23545;&#31216;&#26679;&#26412;&#30340;&#20998;&#31867;&#20013;&#20063;&#32570;&#20047;&#19981;&#21464;&#24615;&#65292;&#22240;&#20026;CNN&#21487;&#20197;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#23545;&#31216;&#26679;&#26412;&#36827;&#34892;&#20998;&#31867;&#12290;&#32771;&#34385;&#21040;CNN&#32570;&#20047;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#21644;CNN&#32570;&#20047;&#19981;&#21464;&#24615;&#65292;&#23545;&#31216;&#23545;&#25239;&#26679;&#26412;&#30340;&#20998;&#31867;&#21487;&#33021;&#19982;&#20854;&#38169;&#35823;&#20998;&#31867;&#19981;&#21516;&#12290;&#26412;&#25991;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#23545;&#31216;&#38450;&#24481;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#23545;&#25239;&#32773;&#19981;&#30693;&#36947;&#38450;&#24481;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#23545;&#31216;&#23545;&#25239;&#26679;&#26412;&#32763;&#36716;&#25110;&#27700;&#24179;&#32763;&#36716;&#21518;&#20877;&#36827;&#34892;&#20998;&#31867;&#12290;&#23545;&#20110;&#30693;&#36947;&#38450;&#24481;&#30340;&#23545;&#25163;&#65292;&#38450;&#24481;&#35774;&#35745;&#20102;&#19968;&#20010;Klein&#22235;&#20010;&#23545;&#31216;&#23376;&#32676;&#65292;&#20854;&#20013;&#21253;&#25324;&#27700;&#24179;&#32763;&#36716;&#21644;&#20687;&#32032;&#21453;&#36716;&#23545;&#31216;&#24615;&#12290;&#23545;&#31216;&#38450;&#24481;&#20351;&#29992;&#23376;&#32676;&#23545;&#31216;&#24615;&#36827;&#34892;&#20998;&#31867;&#65292;&#20197;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolutional neural network classifiers (CNNs) are susceptible to adversarial attacks that perturb original samples to fool classifiers such as an autonomous vehicle's road sign image classifier. CNNs also lack invariance in the classification of symmetric samples because CNNs can classify symmetric samples differently. Considered together, the CNN lack of adversarial robustness and the CNN lack of invariance mean that the classification of symmetric adversarial samples can differ from their incorrect classification. Could symmetric adversarial samples revert to their correct classification? This paper answers this question by designing a symmetry defense that inverts or horizontally flips adversarial samples before classification against adversaries unaware of the defense. Against adversaries aware of the defense, the defense devises a Klein four symmetry subgroup that includes the horizontal flip and pixel inversion symmetries. The symmetry defense uses the subgroup symmetries in ac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;XG-BoT&#30340;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#26816;&#27979;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#30340;&#24694;&#24847;&#20725;&#23608;&#32593;&#32476;&#33410;&#28857;&#65292;&#24182;&#36890;&#36807;&#31361;&#20986;&#26174;&#31034;&#21487;&#30097;&#30340;&#32593;&#32476;&#27969;&#21644;&#30456;&#20851;&#30340;&#20725;&#23608;&#32593;&#32476;&#33410;&#28857;&#26469;&#25191;&#34892;&#33258;&#21160;&#32593;&#32476;&#21462;&#35777;&#12290;&#35813;&#27169;&#22411;&#22312;&#20851;&#38190;&#35780;&#20272;&#25351;&#26631;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2207.09088</link><description>&lt;p&gt;
XG-BoT&#65306;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#20725;&#23608;&#32593;&#32476;&#26816;&#27979;&#21644;&#21462;&#35777;
&lt;/p&gt;
&lt;p&gt;
XG-BoT: An Explainable Deep Graph Neural Network for Botnet Detection and Forensics. (arXiv:2207.09088v5 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;XG-BoT&#30340;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#26816;&#27979;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#30340;&#24694;&#24847;&#20725;&#23608;&#32593;&#32476;&#33410;&#28857;&#65292;&#24182;&#36890;&#36807;&#31361;&#20986;&#26174;&#31034;&#21487;&#30097;&#30340;&#32593;&#32476;&#27969;&#21644;&#30456;&#20851;&#30340;&#20725;&#23608;&#32593;&#32476;&#33410;&#28857;&#26469;&#25191;&#34892;&#33258;&#21160;&#32593;&#32476;&#21462;&#35777;&#12290;&#35813;&#27169;&#22411;&#22312;&#20851;&#38190;&#35780;&#20272;&#25351;&#26631;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an explainable deep graph neural network model called XG-BoT for detecting malicious botnet nodes in large-scale networks and performing automatic network forensics by highlighting suspicious network flows and related botnet nodes. The model outperforms state-of-the-art approaches in terms of key evaluation metrics.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;XG-BoT&#30340;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#26816;&#27979;&#20725;&#23608;&#32593;&#32476;&#33410;&#28857;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#19968;&#20010;&#20725;&#23608;&#32593;&#32476;&#26816;&#27979;&#22120;&#21644;&#19968;&#20010;&#33258;&#21160;&#21462;&#35777;&#30340;&#35299;&#37322;&#22120;&#12290;XG-BoT&#26816;&#27979;&#22120;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#30340;&#24694;&#24847;&#20725;&#23608;&#32593;&#32476;&#33410;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#21033;&#29992;&#20998;&#32452;&#21487;&#36870;&#27531;&#24046;&#36830;&#25509;&#21644;&#22270;&#21516;&#26500;&#32593;&#32476;&#20174;&#20725;&#23608;&#32593;&#32476;&#36890;&#20449;&#22270;&#20013;&#23398;&#20064;&#34920;&#36798;&#24615;&#33410;&#28857;&#34920;&#31034;&#12290;&#22522;&#20110;GNNExplainer&#21644;XG-BoT&#20013;&#30340;&#26174;&#33879;&#24615;&#22270;&#65292;&#35299;&#37322;&#22120;&#21487;&#20197;&#36890;&#36807;&#31361;&#20986;&#26174;&#31034;&#21487;&#30097;&#30340;&#32593;&#32476;&#27969;&#21644;&#30456;&#20851;&#30340;&#20725;&#23608;&#32593;&#32476;&#33410;&#28857;&#26469;&#25191;&#34892;&#33258;&#21160;&#32593;&#32476;&#21462;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#30340;&#22823;&#35268;&#27169;&#20725;&#23608;&#32593;&#32476;&#22270;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;XG-BoT&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;XG-BoT&#22312;&#20851;&#38190;&#35780;&#20272;&#25351;&#26631;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;XG-BoT&#35299;&#37322;&#22120;&#21487;&#20197;&#20026;&#33258;&#21160;&#32593;&#32476;&#21462;&#35777;&#29983;&#25104;&#26377;&#29992;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose XG-BoT, an explainable deep graph neural network model for botnet node detection. The proposed model comprises a botnet detector and an explainer for automatic forensics. The XG-BoT detector can effectively detect malicious botnet nodes in large-scale networks. Specifically, it utilizes a grouped reversible residual connection with a graph isomorphism network to learn expressive node representations from botnet communication graphs. The explainer, based on the GNNExplainer and saliency map in XG-BoT, can perform automatic network forensics by highlighting suspicious network flows and related botnet nodes. We evaluated XG-BoT using real-world, large-scale botnet network graph datasets. Overall, XG-BoT outperforms state-of-the-art approaches in terms of key evaluation metrics. Additionally, we demonstrate that the XG-BoT explainers can generate useful explanations for automatic network forensics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20221;&#20851;&#20110;&#21516;&#34892;&#35780;&#23457;&#20013;&#24694;&#24847;&#25237;&#26631;&#30340;&#25968;&#25454;&#38598;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#32570;&#20047;&#20844;&#24320;&#25968;&#25454;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2207.02303</link><description>&lt;p&gt;
&#19968;&#20221;&#20851;&#20110;&#21516;&#34892;&#35780;&#23457;&#20013;&#24694;&#24847;&#25237;&#26631;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
A Dataset on Malicious Paper Bidding in Peer Review. (arXiv:2207.02303v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.02303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20221;&#20851;&#20110;&#21516;&#34892;&#35780;&#23457;&#20013;&#24694;&#24847;&#25237;&#26631;&#30340;&#25968;&#25454;&#38598;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#32570;&#20047;&#20844;&#24320;&#25968;&#25454;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provides a dataset on malicious paper bidding in peer review, filling the gap of lack of publicly-available data in this field.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20250;&#35758;&#21516;&#34892;&#35780;&#23457;&#20013;&#65292;&#35780;&#23457;&#20154;&#36890;&#24120;&#34987;&#35201;&#27714;&#23545;&#27599;&#31687;&#25552;&#20132;&#30340;&#35770;&#25991;&#25552;&#20379;&#8220;&#25237;&#26631;&#8221;&#65292;&#20197;&#34920;&#36798;&#20182;&#20204;&#23545;&#23457;&#26597;&#35813;&#35770;&#25991;&#30340;&#20852;&#36259;&#12290;&#28982;&#21518;&#65292;&#19968;&#31181;&#35770;&#25991;&#20998;&#37197;&#31639;&#27861;&#20351;&#29992;&#36825;&#20123;&#25237;&#26631;&#65288;&#20197;&#21450;&#20854;&#20182;&#25968;&#25454;&#65289;&#26469;&#35745;&#31639;&#35780;&#23457;&#20154;&#23545;&#35770;&#25991;&#30340;&#39640;&#36136;&#37327;&#20998;&#37197;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#36807;&#31243;&#24050;&#32463;&#34987;&#24694;&#24847;&#35780;&#23457;&#20154;&#21033;&#29992;&#65292;&#20182;&#20204;&#20250;&#26377;&#31574;&#30053;&#22320;&#25237;&#26631;&#65292;&#20197;&#38750;&#36947;&#24503;&#30340;&#26041;&#24335;&#25805;&#32437;&#35770;&#25991;&#20998;&#37197;&#65292;&#20174;&#32780;&#20005;&#37325;&#30772;&#22351;&#21516;&#34892;&#35780;&#23457;&#36807;&#31243;&#12290;&#20363;&#22914;&#65292;&#36825;&#20123;&#35780;&#23457;&#20154;&#21487;&#33021;&#20250;&#35797;&#22270;&#34987;&#20998;&#37197;&#21040;&#26379;&#21451;&#30340;&#35770;&#25991;&#20013;&#65292;&#20316;&#20026;&#19968;&#31181;&#20132;&#25442;&#26465;&#20214;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#20851;&#38190;&#38556;&#30861;&#26159;&#32570;&#20047;&#20219;&#20309;&#20844;&#24320;&#21487;&#29992;&#30340;&#20851;&#20110;&#24694;&#24847;&#25237;&#26631;&#30340;&#25968;&#25454;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25910;&#38598;&#24182;&#20844;&#24320;&#21457;&#24067;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#20197;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#20174;&#19968;&#20010;&#27169;&#25311;&#20250;&#35758;&#27963;&#21160;&#20013;&#25910;&#38598;&#30340;&#65292;&#21442;&#19982;&#32773;&#34987;&#35201;&#27714;&#35802;&#23454;&#25110;&#24694;&#24847;&#22320;&#25237;&#26631;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#23545;&#25237;&#26631;&#34892;&#20026;&#30340;&#25551;&#36848;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
In conference peer review, reviewers are often asked to provide "bids" on each submitted paper that express their interest in reviewing that paper. A paper assignment algorithm then uses these bids (along with other data) to compute a high-quality assignment of reviewers to papers. However, this process has been exploited by malicious reviewers who strategically bid in order to unethically manipulate the paper assignment, crucially undermining the peer review process. For example, these reviewers may aim to get assigned to a friend's paper as part of a quid-pro-quo deal. A critical impediment towards creating and evaluating methods to mitigate this issue is the lack of any publicly-available data on malicious paper bidding. In this work, we collect and publicly release a novel dataset to fill this gap, collected from a mock conference activity where participants were instructed to bid either honestly or maliciously. We further provide a descriptive analysis of the bidding behavior, inc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#19979;&#65292;&#36890;&#36807;&#26799;&#24230;&#27844;&#28431;&#25915;&#20987;&#25512;&#26029;&#29992;&#25143;&#20301;&#32622;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#25252;&#20301;&#32622;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2112.03452</link><description>&lt;p&gt;
&#32852;&#37030;&#20449;&#21495;&#22320;&#22270;&#20013;&#30340;&#20301;&#32622;&#27844;&#38706;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Location Leakage in Federated Signal Maps. (arXiv:2112.03452v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.03452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#19979;&#65292;&#36890;&#36807;&#26799;&#24230;&#27844;&#28431;&#25915;&#20987;&#25512;&#26029;&#29992;&#25143;&#20301;&#32622;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#25252;&#20301;&#32622;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the problem of inferring user location through gradient leakage attacks in the federated learning framework, and proposes a method to protect location privacy.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20174;&#22810;&#20010;&#31227;&#21160;&#35774;&#22791;&#25910;&#38598;&#30340;&#27979;&#37327;&#25968;&#25454;&#20013;&#39044;&#27979;&#34562;&#31389;&#32593;&#32476;&#24615;&#33021;&#65288;&#20449;&#21495;&#22320;&#22270;&#65289;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#20869;&#21046;&#23450;&#20102;&#38382;&#39064;&#65306;&#65288;i&#65289;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20351;&#29992;&#25143;&#33021;&#22815;&#21327;&#20316;&#35757;&#32451;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#35757;&#32451;&#25968;&#25454;&#22312;&#20854;&#35774;&#22791;&#19978;&#65307;&#65288;ii&#65289;&#27979;&#37327;&#25968;&#25454;&#26159;&#38543;&#30528;&#29992;&#25143;&#38543;&#26102;&#38388;&#31227;&#21160;&#32780;&#25910;&#38598;&#30340;&#65292;&#24182;&#20197;&#22312;&#32447;&#26041;&#24335;&#29992;&#20110;&#26412;&#22320;&#35757;&#32451;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#35802;&#23454;&#20294;&#22909;&#22855;&#30340;&#26381;&#21153;&#22120;&#65292;&#35266;&#23519;&#21442;&#19982;FL&#30340;&#30446;&#26631;&#29992;&#25143;&#30340;&#26356;&#26032;&#24182;&#20351;&#29992;&#26799;&#24230;&#27844;&#28431;&#65288;DLG&#65289;&#31867;&#22411;&#30340;&#25915;&#20987;&#25512;&#26029;&#20182;&#20204;&#30340;&#20301;&#32622;&#65292;&#35813;&#25915;&#20987;&#26368;&#21021;&#26159;&#20026;&#37325;&#26500;DNN&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#25968;&#25454;&#32780;&#24320;&#21457;&#30340;&#12290;&#25105;&#20204;&#20570;&#20986;&#20102;&#20851;&#38190;&#35266;&#23519;&#65292;&#21363;DLG&#25915;&#20987;&#24212;&#29992;&#20110;&#25105;&#20204;&#30340;&#35774;&#32622;&#65292;&#21487;&#20197;&#25512;&#26029;&#20986;&#26412;&#22320;&#25968;&#25454;&#25209;&#27425;&#30340;&#24179;&#22343;&#20301;&#32622;&#65292;&#24182;&#22240;&#27492;&#21487;&#20197;&#29992;&#20110;&#22312;&#31895;&#30053;&#31890;&#24230;&#19978;&#37325;&#26500;&#30446;&#26631;&#29992;&#25143;&#30340;&#36712;&#36857;&#12290;&#25105;&#20204;&#22522;&#20110;&#36825;&#20010;&#35266;&#23519;&#26469;&#20445;&#25252;&#20301;&#32622;&#38544;&#31169;&#65292;&#22312;&#25105;&#20204;&#30340;s&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of predicting cellular network performance (signal maps) from measurements collected by several mobile devices. We formulate the problem within the online federated learning framework: (i) federated learning (FL) enables users to collaboratively train a model, while keeping their training data on their devices; (ii) measurements are collected as users move around over time and are used for local training in an online fashion. We consider an honest-but-curious server, who observes the updates from target users participating in FL and infers their location using a deep leakage from gradients (DLG) type of attack, originally developed to reconstruct training data of DNN image classifiers. We make the key observation that a DLG attack, applied to our setting, infers the average location of a batch of local data, and can thus be used to reconstruct the target users' trajectory at a coarse granularity. We build on this observation to protect location privacy, in our s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#38544;&#31169;&#20445;&#25252;&#19979;&#22810;&#28304;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20004;&#31181;&#20027;&#27969;&#35299;&#20915;&#26041;&#26696;&#65306;&#23433;&#20840;&#22810;&#26041;&#23398;&#20064;&#21644;&#32852;&#37030;&#23398;&#20064;&#65292;&#24182;&#23545;&#23427;&#20204;&#30340;&#23433;&#20840;&#24615;&#12289;&#25928;&#29575;&#12289;&#25968;&#25454;&#20998;&#24067;&#12289;&#35757;&#32451;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#24212;&#29992;&#22330;&#26223;&#36827;&#34892;&#20102;&#27604;&#36739;&#21644;&#35752;&#35770;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2012.03386</link><description>&lt;p&gt;
SoK: &#38544;&#31169;&#20445;&#25252;&#19979;&#22810;&#28304;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SoK: Training Machine Learning Models over Multiple Sources with Privacy Preservation. (arXiv:2012.03386v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.03386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#38544;&#31169;&#20445;&#25252;&#19979;&#22810;&#28304;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20004;&#31181;&#20027;&#27969;&#35299;&#20915;&#26041;&#26696;&#65306;&#23433;&#20840;&#22810;&#26041;&#23398;&#20064;&#21644;&#32852;&#37030;&#23398;&#20064;&#65292;&#24182;&#23545;&#23427;&#20204;&#30340;&#23433;&#20840;&#24615;&#12289;&#25928;&#29575;&#12289;&#25968;&#25454;&#20998;&#24067;&#12289;&#35757;&#32451;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#24212;&#29992;&#22330;&#26223;&#36827;&#34892;&#20102;&#27604;&#36739;&#21644;&#35752;&#35770;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper reviews two mainstream solutions for training machine learning models over multiple sources with privacy preservation: Secure Multi-party Learning (MPL) and Federated Learning (FL). The security, efficiency, data distribution, accuracy of trained models, and application scenarios of these two solutions are compared and discussed, and future research directions are explored.
&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#20174;&#22810;&#20010;&#25968;&#25454;&#28304;&#20013;&#25910;&#38598;&#39640;&#36136;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#24182;&#20445;&#25252;&#38544;&#31169;&#26159;&#35757;&#32451;&#39640;&#24615;&#33021;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#25171;&#30772;&#23396;&#31435;&#25968;&#25454;&#35821;&#26009;&#24211;&#20043;&#38388;&#30340;&#38556;&#30861;&#65292;&#20174;&#32780;&#25193;&#22823;&#21487;&#29992;&#20110;&#22788;&#29702;&#30340;&#25968;&#25454;&#33539;&#22260;&#12290;&#20026;&#27492;&#65292;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#21644;&#24037;&#19994;&#20379;&#24212;&#21830;&#26368;&#36817;&#24378;&#28872;&#21160;&#21147;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20027;&#27969;&#35299;&#20915;&#26041;&#26696;&#65292;&#20027;&#35201;&#22522;&#20110;&#36719;&#20214;&#26500;&#36896;&#65306;1&#65289;&#23433;&#20840;&#22810;&#26041;&#23398;&#20064;&#65288;MPL&#65289;&#65307;&#21644;2&#65289;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#12290;&#24403;&#25105;&#20204;&#26681;&#25454;&#20197;&#19979;&#20116;&#20010;&#26631;&#20934;&#35780;&#20272;&#23427;&#20204;&#26102;&#65292;&#19978;&#36848;&#20004;&#20010;&#25216;&#26415;&#25991;&#20214;&#22841;&#37117;&#26377;&#20854;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#65306;&#23433;&#20840;&#24615;&#65292;&#25928;&#29575;&#65292;&#25968;&#25454;&#20998;&#24067;&#65292;&#35757;&#32451;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#24212;&#29992;&#22330;&#26223;&#12290;&#20026;&#20102;&#23637;&#31034;&#30740;&#31350;&#36827;&#23637;&#24182;&#35752;&#35770;&#26410;&#26469;&#26041;&#21521;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#24443;&#24213;&#35843;&#26597;&#20102;&#36825;&#20123;&#21327;&#35758;&#21644;MPL&#21644;FL&#30340;&#26694;&#26550;&#65292;&#24182;&#24635;&#32467;&#20102;&#35813;&#39046;&#22495;&#30340;&#26368;&#26032;&#30740;&#31350;&#36827;&#23637;&#12290;&#25105;&#20204;&#36824;&#23545;&#36825;&#20004;&#20010;&#25216;&#26415;&#25991;&#20214;&#22841;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#65292;&#24182;&#35752;&#35770;&#20102;&#24320;&#25918;&#30340;&#25361;&#25112;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays, gathering high-quality training data from multiple data sources with privacy preservation is a crucial challenge to training high-performance machine learning models. The potential solutions could break the barriers among isolated data corpus, and consequently enlarge the range of data available for processing. To this end, both academic researchers and industrial vendors are recently strongly motivated to propose two main-stream folders of solutions mainly based on software constructions: 1) Secure Multi-party Learning (MPL for short); and 2) Federated Learning (FL for short). The above two technical folders have their advantages and limitations when we evaluate them according to the following five criteria: security, efficiency, data distribution, the accuracy of trained models, and application scenarios.  Motivated to demonstrate the research progress and discuss the insights on the future directions, we thoroughly investigate these protocols and frameworks of both MPL and
&lt;/p&gt;</description></item></channel></rss>