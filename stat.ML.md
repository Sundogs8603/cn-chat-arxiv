# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions.](http://arxiv.org/abs/2310.05921) | 符合决策理论是一种框架，可以通过不完美的机器学习预测产生安全的自主决策。该理论的创新之处在于可以在没有对世界模型做出任何假设的情况下提供具有低风险的统计保证的决策。 |
| [^2] | [Grokking as Compression: A Nonlinear Complexity Perspective.](http://arxiv.org/abs/2310.05918) | 本研究将"grokking"现象归因于压缩，并提出线性映射数（LMN）作为衡量神经网络复杂度的方法。LMN能够更好地描述网络的压缩过程，并展现XOR网络在通用化解决方案间切换的有趣现象。 |
| [^3] | [Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts.](http://arxiv.org/abs/2310.05898) | Lion是通过程序搜索发现的新优化器，在训练大型AI模型方面表现出有希望的结果，具有更高的内存效率。尽管其理论基础不明确，但基于连续时间和离散时间分析，我们证明Lion是一种理论上新颖且有原则的方法，可在最小化一般损失函数的同时强制执行边界约束。 |
| [^4] | [A Generalization Bound of Deep Neural Networks for Dependent Data.](http://arxiv.org/abs/2310.05892) | 该研究在非平稳相关数据上建立了前馈神经网络的泛化界限。 |
| [^5] | [Coarse-Graining Hamiltonian Systems Using WSINDy.](http://arxiv.org/abs/2310.05879) | 本论文研究了使用WSINDy进行粗粒化哈密顿系统的问题，扩展了WSINDy在相互作用粒子系统中的粗粒化能力。通过识别近似对称性和处理外部扰动，WSINDy成功地识别出降维的哈密顿系统，从而有效地捕捉了相关自由度的动力学。 |
| [^6] | [Robust Angular Synchronization via Directed Graph Neural Networks.](http://arxiv.org/abs/2310.05842) | 本论文提出了一个名为GNNSync的基于有向图神经网络的鲁棒角度同步解决方案，解决了角度同步问题在高噪声环境下的挑战，并提出了新的损失函数以更好地编码同步约束。 |
| [^7] | [A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models.](http://arxiv.org/abs/2310.05833) | 该论文首次引入了生成模型的核评分的偏差-方差-协方差分解，并提出了相应的量的无偏和一致估计器。通过应用在扩散模型上发现少数群体的模式坍缩是一种与过拟合相反的现象，并证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。 |
| [^8] | [Provably Convergent Data-Driven Convex-Nonconvex Regularization.](http://arxiv.org/abs/2310.05812) | 本研究展示了在凸非凸框架中，通过从数据中学习正则化器，可以实现收敛正则化；引入了一种新颖的弱凸输入神经网络构建，解决了之前对抗性方法的数值问题。 |
| [^9] | [Boosted Control Functions.](http://arxiv.org/abs/2310.05805) | 本研究通过建立同时方程模型和控制函数与分布概括的新连接，解决了在存在未观察到的混淆情况下，针对不同训练和测试分布的预测问题。 |
| [^10] | [Estimating Shape Distances on Neural Representations with Limited Samples.](http://arxiv.org/abs/2310.05742) | 本论文研究了在数据有限情况下，对高维神经表示进行形状距离估计的问题。通过推导出对形状距离标准估计器最坏情况下的收敛上下界，我们揭示了这个问题的挑战性质。为了克服挑战，我们引入了一种新的矩法估计器，并展示了其在高维设置下相对于标准估计器的优越性能。 |
| [^11] | [Post-hoc Bias Scoring Is Optimal For Fair Classification.](http://arxiv.org/abs/2310.05725) | 本研究提出了一种后验偏差评分的方法，在满足公平性约束的情况下保持高准确性，并给出了基于偏差分数的修改规则。该方法适用于各种类型的公平性约束问题。 |
| [^12] | [Transformer Fusion with Optimal Transport.](http://arxiv.org/abs/2310.05719) | 本文介绍了一种使用最优输运来融合基于Transformer的网络的方法，可以对齐各种架构组件并允许不同大小的模型的融合，提供了一种新的高效压缩Transformer的方式。 |
| [^13] | [Multi-timestep models for Model-based Reinforcement Learning.](http://arxiv.org/abs/2310.05672) | 多步模型的基于模型的强化学习算法通过使用多步目标来训练一步模型，解决了轨迹长度增长时一步预测误差的累积问题，并在噪声数据上表现出显著的性能提升。 |
| [^14] | [Causal structure learning with momentum: Sampling distributions over Markov Equivalence Classes of DAGs.](http://arxiv.org/abs/2310.05655) | 本文提出了一种非可逆连续时间马尔科夫链，即“因果Zig-Zag采样器”，用于推断贝叶斯网络结构。通过使用动量变量，该采样器可以显著改善混合性能。 |
| [^15] | [A New Transformation Approach for Uplift Modeling with Binary Outcome.](http://arxiv.org/abs/2310.05549) | 本论文提出了一种新的二元结果提升建模转换方法，利用了零结果样本的信息并且易于使用。 (arXiv:2310.05549v1 [stat.ML]) |
| [^16] | [Projecting infinite time series graphs to finite marginal graphs using number theory.](http://arxiv.org/abs/2310.05526) | 本研究提出了一种将具有重复边的无限时间序列图投射到有限边际图上的方法，从而解决了以往无法处理的$m$-分离查询任务，并为时间序列的因果发现和因果效果估计提供了有用的工具。 |
| [^17] | [A Neural Tangent Kernel View on Federated Averaging for Deep Linear Neural Network.](http://arxiv.org/abs/2310.05495) | 本论文介绍了一种基于神经切向核视角的联邦平均方法在深度线性神经网络上的应用，并探讨了该方法面临的挑战。 |
| [^18] | [Integration-free Training for Spatio-temporal Multimodal Covariate Deep Kernel Point Processes.](http://arxiv.org/abs/2310.05485) | 本研究提出了一种无积分训练的时空多模态协变深度内核点过程模型，利用分数匹配方法和去噪分数匹配方法解决了训练困难，实验结果表明该模型优于基线模型。 |
| [^19] | [ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest.](http://arxiv.org/abs/2310.05468) | 本研究介绍了EIF+和ExIFFI两种改进了扩展孤立森林的方法，分别增强了模型的推广能力和解释性能，实验结果表明其在异常检测任务中具有优势。 |
| [^20] | [Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels.](http://arxiv.org/abs/2310.05387) | 该论文提出了一种基于核学习和贝叶斯Spike-and-Slab先验的方程式发现方法，通过核回归和贝叶斯稀疏分布，能够有效处理数据稀疏性和噪声问题，并进行不确定性量化和高效的后验推断和函数估计。 |
| [^21] | [Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Methods.](http://arxiv.org/abs/2310.05309) | 本文提出了一种新颖的理论框架，为深度神经网络和增强学习方法在解决组合问题方面的有效性提供了肯定的答案。这个框架对于解决包括最大割和最小割、最大$k$约束问题、最大权重二分图匹配和旅行商问题在内的广泛的组合问题有重要的意义。 |
| [^22] | [Adversarial Attacks on Combinatorial Multi-Armed Bandits.](http://arxiv.org/abs/2310.05308) | 本文研究了对组合多臂老虎机的奖励污染攻击，并给出了攻击可能性的条件。与以往对多臂老虎机的理解相反，我们发现特定CMAB实例的攻击可能性还取决于发哥实例是否被对手知晓。这表明在实践中对CMAB进行对抗攻击是困难的，因为对手大部分情况下无法了解环境的情况。 |
| [^23] | [Clustering Three-Way Data with Outliers.](http://arxiv.org/abs/2310.05288) | 这项研究提出了一种用于聚类矩阵形式数据的方法，可以处理其中的异常值。 |
| [^24] | [Simplifying GNN Performance with Low Rank Kernel Models.](http://arxiv.org/abs/2310.05250) | 本文提出了一种用于简化GNN性能的低秩内核模型，通过应用传统的非参数估计方法在谱域中取代过于复杂的GNN架构，并在多个图类型的半监督节点分类基准测试中取得了最先进的性能。 |
| [^25] | [In-Context Convergence of Transformers.](http://arxiv.org/abs/2310.05249) | 本研究通过对Transformers内部学习动力学的分析，研究了一层Transformer使用梯度下降进行上下文学习的能力，对于具有平衡特征的数据，建立了有限时间收敛保证，且预测误差接近零。 |
| [^26] | [Orlicz regrets to consistently bound statistics of random variables with an application to environmental indicators.](http://arxiv.org/abs/2310.05168) | 本文提出了一种新型的Orlicz后悔方法，用于一致地界定随机变量的统计量上下界，通过灵活评估随机变量的尾行为。与传统方法不同，此方法采用了一致性评估，并得到了将其与发散风险度量等效的充分条件。 |
| [^27] | [A Corrected Expected Improvement Acquisition Function Under Noisy Observations.](http://arxiv.org/abs/2310.05166) | 这个论文提出了一个修正的期望改善采集函数，在贝叶斯优化中解决了对于有噪声观测的情况下忽略候选解不确定性的问题。 |
| [^28] | [Compressed online Sinkhorn.](http://arxiv.org/abs/2310.05019) | 这篇论文介绍了压缩在线Sinkhorn算法，在机器学习和数据科学领域中，它提出了处理连续数据流的随机版本，收敛速度更快。 |
| [^29] | [Model-adapted Fourier sampling for generative compressed sensing.](http://arxiv.org/abs/2310.04984) | 这篇论文提出了一种模型适应的采样策略，用于生成式压缩感知中的信号恢复，通过优化采样分布和新的理论恢复保证技术，能够显著减少所需测量的数量。 |
| [^30] | [Robust matrix completion via Novel M-estimator Functions.](http://arxiv.org/abs/2310.04953) | 本文针对鲁棒矩阵补全问题，提出了一种利用新型M估计函数的方法。通过生成一类非凸函数，用于减弱受异常值污染的观测值，得到了相应的鲁棒损失函数。在算法设计和收敛性分析上取得了较好的结果，并且数值实验结果表明，该方法在恢复准确性和运行时间方面优于其他竞争方法。 |
| [^31] | [Statistical Guarantees for Variational Autoencoders using PAC-Bayesian Theory.](http://arxiv.org/abs/2310.04935) | 这项工作利用PAC-Bayesian理论为变分自动编码器提供了统计保证，包括对后验分布、重构损失和输入与生成分布之间距离的上界。 |
| [^32] | [DISCOVER: Making Vision Networks Interpretable via Competition and Dissection.](http://arxiv.org/abs/2310.04929) | 该论文的创新是通过竞争和剖析的方法，使得视觉网络更容易解释，从而克服了深度网络复杂且难以解释的问题。 |
| [^33] | [The Conditional Prediction Function: A Novel Technique to Control False Discovery Rate for Complex Models.](http://arxiv.org/abs/2310.04919) | 引入了一种基于条件预测函数的Knockoff统计方法，可以在复杂模型中对误发现率进行控制，并且能够捕捉到预测变量和结果之间的非线性关系。 |
| [^34] | [Randomized Sparse Neural Galerkin Schemes for Solving Evolution Equations with Deep Networks.](http://arxiv.org/abs/2310.04867) | 该论文介绍了一种用于演化方程解决的神经Galerkin方案，通过随机化稀疏网络参数的更新来避免在时间上过拟合并降低计算成本。 |
| [^35] | [Uncovering hidden geometry in Transformers via disentangling position and context.](http://arxiv.org/abs/2310.04861) | 本文通过分解transformer的隐藏状态，揭示了其在语义理解中的隐含几何结构。 |
| [^36] | [Universal Graph Random Features.](http://arxiv.org/abs/2310.04859) | 本文提出了一种新的准蒙特卡罗机制，称为排斥随机游走，通过改进图的采样，提高了统计估计器的集中度。该机制在估计图内核、PageRank向量和图形浓度等方面展示了有效性。 |
| [^37] | [Repelling Random Walks.](http://arxiv.org/abs/2310.04854) | 抵制随机游走是一种新的准蒙特卡罗机制，通过在图上的行走者之间引入相关性，能够更高效地探索图并提高统计估计的集中度，同时保持其无偏性。此机制在估计图核、PageRank向量和图元浓度等多个领域都展示了其有效性，并提供了详细的实验评估和理论保证。 |
| [^38] | [Subspace Identification for Multi-Source Domain Adaptation.](http://arxiv.org/abs/2310.04723) | 该论文提出了一个基于子空间识别理论的多源域自适应方法，通过最小化域之间的偏移对不变变量的影响，实现了源域的知识转移到目标域。该方法相对于现有方法更加灵活，不需要满足严格的假设条件。 |
| [^39] | [Robust Transfer Learning with Unreliable Source Data.](http://arxiv.org/abs/2310.04606) | 本文提出了一个新的鲁棒性迁移学习方法TAB模型，通过衡量目标与源回归函数之间的模糊度水平来改善分类任务，并避免负迁移。通过实验验证，TAB模型在非参数分类和逻辑回归任务上表现出了优越的性能。 |
| [^40] | [TNDDR: Efficient and doubly robust estimation of COVID-19 vaccine effectiveness under the test-negative design.](http://arxiv.org/abs/2310.04578) | 我们提出了一种高效且双重鲁棒的估计器TNDDR，用于在阴性测试设计下估计COVID-19疫苗的有效性，可有效解决选择偏差问题，并结合机器学习技术进行辅助函数估计。 |
| [^41] | [Risk factor aggregation and stress testing.](http://arxiv.org/abs/2310.04511) | 本论文介绍了一种在压力测试中应用无监督学习的降维技术的方法，通过主成分分析和自编码器扩展了风险因素的范围，并提供了潜在因子的解释。这种方法对于其他需要降维和可解释性的领域也有用处。 |
| [^42] | [Simultaneous Dimensionality Reduction: A Data Efficient Approach for Multimodal Representations Learning.](http://arxiv.org/abs/2310.04458) | 该论文介绍了一种数据高效的多模态表示学习方法，探索了独立降维和同时降维两种方法，并通过生成线性模型评估了其相对准确性和数据集大小要求。 |
| [^43] | [Diffusion Random Feature Model.](http://arxiv.org/abs/2310.04417) | 本研究提出了一种以扩散模型为灵感的深度随机特征模型，它具有可解释性并可在数量相同的可训练参数下与全连接神经网络提供可比较的数值结果。通过推导得分匹配的属性，我们扩展了现有随机特征结果，并得出了样本数据分布与真实分布之间的泛化边界。 |
| [^44] | [A Marketplace Price Anomaly Detection System at Scale.](http://arxiv.org/abs/2310.04367) | MoatPlus是一个可扩展的价格异常检测框架，通过利用无监督统计特征和历史价格趋势生成上限价格边界，以解决在线市场中的数据质量和错误价格发布的问题。 |
| [^45] | [Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization.](http://arxiv.org/abs/2310.04015) | 本文提出了一种名为“类似样本聚类”的技术，通过替换个体的敏感特征为聚类的平均值来增强隐私。通过对使用匿名聚类中心训练模型的精确分析，我们揭示了不同模型组成部分对泛化误差的影响，并证明在某些高维情况下，使用匿名聚类中心进行训练可以取得更好的效果。 |
| [^46] | [Provable benefits of annealing for estimating normalizing constants: Importance Sampling, Noise-Contrastive Estimation, and beyond.](http://arxiv.org/abs/2310.03902) | 这篇论文研究了使用退火方法估计归一化常数的蒙特卡洛方法。通过评估不同设计选择对估计误差的影响，结果表明使用退火噪声对比估计器更有效，并且使用几何路径可以降低估计误差。 |
| [^47] | [A Unified Framework for Uniform Signal Recovery in Nonlinear Generative Compressed Sensing.](http://arxiv.org/abs/2310.03758) | 该论文提出了一个统一的框架，用于在非线性生成式压缩感知中实现统一的信号恢复。该框架适用于非线性和可能非连续或未知的观测模型，并且可以恢复生成模型中所有可能的信号。 |
| [^48] | [Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance.](http://arxiv.org/abs/2310.03722) | 本文提出了两种新的“e-process”和置信序列方法，分别通过替换Lai的混合方法，并分析了所得结果的宽度。 |
| [^49] | [Multi-Domain Causal Representation Learning via Weak Distributional Invariances.](http://arxiv.org/abs/2310.02854) | 本文提出了一种通过弱分布不变性进行多领域因果表示学习的方法，证明了融入这种不变性的自编码器能够可靠地识别出稳定的变量集合。 |
| [^50] | [How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization.](http://arxiv.org/abs/2310.01769) | 该论文研究了过参数化如何影响矩阵感知问题中梯度下降的收敛行为，在对称和非对称设置下给出了不同的收敛速度。 |
| [^51] | [Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior.](http://arxiv.org/abs/2310.00097) | 本文研究了稀疏变分高斯过程回归中点估计和不确定性量化的方法，通过使用布朗运动先验和特征向量引导变量，推导了频率派可信区间的理论保证和限制，并在足够多的引导变量的情况下精确定义了渐近频率派覆盖，从而推断出这个变分方法的可信区间何时保守，何时过于自信/误导。数值实验证明了这些结果的适用性，并讨论了与其他常见高斯过程先验的相关性。 |
| [^52] | [Water quality prediction using machine learning and neural network approaches.](http://arxiv.org/abs/2309.16951) | 本研究通过比较线性回归、随机森林、XGBoost、LightGBM和MLP神经网络五种模型在佐治亚州预测水质pH值方面的效果，发现LightGBM表现最好。基于树的模型在回归问题中优势显著，而MLP神经网络对特征缩放敏感。同时，本研究还探讨了与原研究相比，机器学习模型能够取得更好性能的原因。 |
| [^53] | [TomOpt: Differential optimisation for task- and constraint-aware design of particle detectors in the context of muon tomography.](http://arxiv.org/abs/2309.14027) | TomOpt是一个软件包，用于优化宇宙射线μ子断层扫描设计中的微粒探测器的几何布局和规格。它利用可微分编程模拟μ子与探测器和扫描体积的相互作用，并通过损失最小化的优化循环进行推断感知优化。 |
| [^54] | [Action-State Dependent Dynamic Model Selection.](http://arxiv.org/abs/2307.04754) | 本文提出了一种动态模型选择的方法，该方法能够根据不同的状态选择最优的模型，并通过强化学习算法对动态规划问题进行近似和估计。实验结果表明，在重新平衡成本下切换投资组合模型时，使用宏观经济信息的性能优于事后选择最佳投资组合模型。 |
| [^55] | [Variational Imbalanced Regression.](http://arxiv.org/abs/2306.06599) | 本文提出的变分不平衡回归（VIR）模型通过引入Probabilistic Reweighting方法，可以在不平衡回归方面表现良好，并自然产生合理的不确定性估计。 |
| [^56] | [Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models.](http://arxiv.org/abs/2305.19187) | 本研究提出应对大型语言模型可信度问题的方法，研究黑盒模型中置信度与不确定性量化，并将其应用于选择性自然语言生成。 |
| [^57] | [Robust Lipschitz Bandits to Adversarial Corruptions.](http://arxiv.org/abs/2305.18543) | 本文提出的强健Lipschitz赌徒算法，能够在对抗性攻击的情况下实现次线性遗憾，并在强敌手情况下最优。 |
| [^58] | [Let the Flows Tell: Solving Graph Combinatorial Optimization Problems with GFlowNets.](http://arxiv.org/abs/2305.17010) | 本文提出了一种名为GFlowNets的机器，可以有效地解决组合优化问题，同时在训练方面进行了优化，结果表明其可以高效地找到高质量的解决方案。 |
| [^59] | [Kernel Methods are Competitive for Operator Learning.](http://arxiv.org/abs/2304.13202) | 本文提出了一个核方法算子学习框架，在对多组数据进行全面比较后，结果表明该方法在多种设置下都是一种具有竞争力的算子学习方法。 |
| [^60] | [Synergistic Graph Fusion via Encoder Embedding.](http://arxiv.org/abs/2303.18051) | 本文提出了一种协同图融合的新方法，该方法处理具有共同顶点集的多个图，有着非常理想的“协同效应”，即顶点分类准确度总是受益于额外的图，并在实验中证实了其卓越性能。 |
| [^61] | [Non-Asymptotic Lower Bounds For Training Data Reconstruction.](http://arxiv.org/abs/2303.16372) | 本文通过研究差分隐私和度量隐私学习器在对抗者重构错误方面的鲁棒性，得出了非渐进性下界，覆盖了高维情况，且扩展了深度学习算法的隐私分析 |
| [^62] | [Statistical Learning under Heterogenous Distribution Shift.](http://arxiv.org/abs/2302.13934) | 本文研究了异质分布偏移下的统计学习问题，通过研究经验风险最小化(ERM)在不同类别的复杂性下的表现，我们发现当类别$F$相比类别$G$更“简单”时，我们的预测器对于协变量偏移具有更强的鲁棒性，尤其在$\textbf{y}$的偏移远小于$\textbf{x}$的情况下。同时，我们发现ERM的行为与正交机器学习具有类似的特性。 |
| [^63] | [Causally Disentangled Generative Variational AutoEncoder.](http://arxiv.org/abs/2302.11737) | 本研究提出了一种名为CDG的方法，通过对变分自动编码器进行监督学习，实现了同时学习因果解缠表示和生成因果解缠结果。通过探索特定模型下实现CDG的必要和充分条件，我们发现仅在编码器中加入监督正则化是不够的。此外，我们引入了一个通用度量来评估生成模型的因果解缠程度，并通过实证结果验证了我们的发现。 |
| [^64] | [Quantized Low-Rank Multivariate Regression with Random Dithering.](http://arxiv.org/abs/2302.11197) | 本文研究了量子化的低秩多元回归，通过采用均匀量化与随机抖动的方法，提出了约束Lasso和正则化Lasso估计器，实现了最小最优率的估计，同时量化仅对乘法因子略有影响。 |
| [^65] | [Towards Inferential Reproducibility of Machine Learning Research.](http://arxiv.org/abs/2302.04054) | 本研究提出利用线性混合效应模型（LMEM）来分析机器学习性能评估分数，并考虑多个方差来源及其与数据特性相互作用，从而评估可靠性和可复制性，促进对机器学习算法行为的更全面理解。 |
| [^66] | [Simplex Random Features.](http://arxiv.org/abs/2301.13856) | Simplex随机特征（SimRFs）是一种新的随机特征机制，通过几何相关性来无偏估计softmax和高斯核。在权重无关的几何相关正随机特征机制类中，SimRFs提供了最小可能的均方误差，并且在没有额外成本的情况下明显优于先前最准确的正交随机特征。在实证研究中，SimRFs在多个领域中表现出一致的收益。 |
| [^67] | [Robust convex biclustering with a tuning-free method.](http://arxiv.org/abs/2212.03122) | 本文提出了一个鲁棒的凸二聚类算法，使用了无需调参的方法，该算法在面对重尾数据时表现出更好的性能。 |
| [^68] | [Estimating the minimizer and the minimum value of a regression function under passive design.](http://arxiv.org/abs/2211.16457) | 本论文提出了一种方法，可以在带有随机噪声的观测中估计回归函数的极小值点和最小值。方法基于投影梯度下降和非参数过程，通过推导上界和建立最小化下界证明了方法的渐进最优性。 |
| [^69] | [FaiREE: Fair Classification with Finite-Sample and Distribution-Free Guarantee.](http://arxiv.org/abs/2211.15072) | 本研究提出了FaiREE算法，它是一种可满足群体公平性约束的公平分类算法，并且具有有限样本和无分布理论保证。在实验中表现优异。 |
| [^70] | [Probability-Dependent Gradient Decay in Large Margin Softmax.](http://arxiv.org/abs/2210.17145) | 本文研究了在神经网络中的Softmax组件中引入梯度衰减超参数的作用，并发现泛化性能与梯度衰减率显著相关。此外，采用较小的梯度衰减的优化方法类似于课程学习序列，使得困难样本在易样本确信之后得到关注。大边际Softmax会影响局部Lipschitz约束。 |
| [^71] | [Self-supervised debiasing using low rank regularization.](http://arxiv.org/abs/2210.05248) | 本研究通过对潜在表示的谱分析发现，虚假相关属性会导致深度神经网络偏向编码较低有效秩的表示。在此基础上，提出了一种自监督的去偏框架，通过秩正则化预训练有偏编码器来学习虚假相关属性。 |
| [^72] | [Design of the topology for contrastive visual-textual alignment.](http://arxiv.org/abs/2209.02127) | 对比视觉-文本对齐学习中，我们讨论了softmax温度参数的作用，并提出了一种新的嵌入对齐拓扑设计。采用这种设计可以显著提高零-shot学习的性能。 |
| [^73] | [On Transfer of Adversarial Robustness from Pretraining to Downstream Tasks.](http://arxiv.org/abs/2208.03835) | 本研究证明了无论预训练采用何种协议，线性预测器在下游任务中的鲁棒性受其基础表示鲁棒性的限制。我们提出了损失上界和鲁棒分类准则，并在实际应用中验证了这些理论结果。 |
| [^74] | [A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting.](http://arxiv.org/abs/2207.14219) | 本文介绍了一种名为AEnbMIMOCQR的新颖算法，通过自适应集成的方式，在不需要数据拆分的情况下，以分布无关的方式生成多步鲍型预测区间。该方法考虑了异方差性，并对分布转变具有鲁棒性，在实验中表现优于其他竞争方法。 |
| [^75] | [Randomly Initialized One-Layer Neural Networks Make Data Linearly Separable.](http://arxiv.org/abs/2205.11716) | 随机初始化的单层神经网络可以将两个集合转化为线性可分的集合，而无需训练，具有计算效率高的优点。 |
| [^76] | [Finding Safe Zones of policies Markov Decision Processes.](http://arxiv.org/abs/2202.11593) | 这篇论文研究了寻找策略的马尔可夫决策过程的安全区域的复杂性，提出了一个双准则逼近学习算法，可以近似计算出逃逸概率和安全区域大小。 |
| [^77] | [Confidence intervals for the Cox model test error from cross-validation.](http://arxiv.org/abs/2201.10770) | 本文研究了交叉验证中Cox模型测试误差的置信区间问题，发现传统方法可能低估置信区间，并提出使用嵌套交叉验证方法解决这个问题，实现更准确的置信区间估计。 |
| [^78] | [Modern Non-Linear Function-on-Function Regression.](http://arxiv.org/abs/2107.14151) | 本研究提出一种利用神经网络分析功能数据的新型非线性函数回归模型，通过连续隐藏层实现对功能响应建模，并提供了两种模型拟合策略（FDNN和FBNN），并通过正则化技术得到更加简明的结果。 |
| [^79] | [Unlabeled Principal Component Analysis and Matrix Completion.](http://arxiv.org/abs/2101.09446) | 本文引入了一种称为未标记主成分分析（UPCA）的方法，通过代数几何证明了其是一个良定义的代数问题，并提出了一个两阶段算法流程来应对被置换的数据，同时解决了无标记矩阵补全问题。 |
| [^80] | [CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity.](http://arxiv.org/abs/1902.05605) | CrossQ是一种轻量级算法，通过巧妙运用批归一化和删除目标网络的方式，提高了深度强化学习的样本效率，减少了计算成本，并且实施简单。 |

# 详细

[^1]: 符合决策理论: 通过不完美的预测产生安全的自主决策

    Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. (arXiv:2310.05921v1 [stat.ML])

    [http://arxiv.org/abs/2310.05921](http://arxiv.org/abs/2310.05921)

    符合决策理论是一种框架，可以通过不完美的机器学习预测产生安全的自主决策。该理论的创新之处在于可以在没有对世界模型做出任何假设的情况下提供具有低风险的统计保证的决策。

    

    我们介绍了一种符合决策理论的框架，可以在机器学习预测不完美的情况下产生安全的自主决策。这种决策的例子是普遍存在的，从依赖于行人预测的机器人规划算法，到校准自动化制造以实现高吞吐量和低错误率，再到在运行时选择信任名义策略还是切换到安全备份策略。我们算法产生的决策在统计保证的情况下是安全的，无需对世界模型作出任何假设；观测数据可以不满足独立同分布(I.I.D.)的条件，甚至可能是对抗性的。该理论将符合预测的结果扩展到直接校准决策，而不需要构建预测集合。实验证明了我们方法在围绕人类进行机器人运动规划、自动股票交易和机器人制造方面的实用性。

    We introduce Conformal Decision Theory, a framework for producing safe autonomous decisions despite imperfect machine learning predictions. Examples of such decisions are ubiquitous, from robot planning algorithms that rely on pedestrian predictions, to calibrating autonomous manufacturing to exhibit high throughput and low error, to the choice of trusting a nominal policy versus switching to a safe backup policy at run-time. The decisions produced by our algorithms are safe in the sense that they come with provable statistical guarantees of having low risk without any assumptions on the world model whatsoever; the observations need not be I.I.D. and can even be adversarial. The theory extends results from conformal prediction to calibrate decisions directly, without requiring the construction of prediction sets. Experiments demonstrate the utility of our approach in robot motion planning around humans, automated stock trading, and robot manufacturin
    
[^2]: Grokking作为压缩：一种非线性复杂性的视角

    Grokking as Compression: A Nonlinear Complexity Perspective. (arXiv:2310.05918v1 [cs.LG])

    [http://arxiv.org/abs/2310.05918](http://arxiv.org/abs/2310.05918)

    本研究将"grokking"现象归因于压缩，并提出线性映射数（LMN）作为衡量神经网络复杂度的方法。LMN能够更好地描述网络的压缩过程，并展现XOR网络在通用化解决方案间切换的有趣现象。

    

    我们将迟缓通用化（generalization）的现象“grokking”归因于压缩。为了这样做，我们定义了线性映射数（LMN）来测量网络复杂度，这是ReLU网络线性区域数的广义版本。LMN可以很好地表征网络在通用化之前的压缩过程。虽然$L_2$范数一直是描述模型复杂度的常用选择，但我们提出了几个理由支持使用LMN：（1）LMN能够自然地解释为信息/计算，而$L_2$则不能。（2）在压缩阶段，LMN与测试误差具有线性关系，而$L_2$则以一种复杂的非线性方式与测试误差相关。（3）LMN还揭示了XOR网络在两种通用化解决方案之间切换的有趣现象，而$L_2$则没有。除了解释“grokking”现象外，我们还认为LMN是Kolmogorov复杂度的神经网络版本的一个有前途的候选者，因为它显式地考虑了计算量。

    We attribute grokking, the phenomenon where generalization is much delayed after memorization, to compression. To do so, we define linear mapping number (LMN) to measure network complexity, which is a generalized version of linear region number for ReLU networks. LMN can nicely characterize neural network compression before generalization. Although the $L_2$ norm has been a popular choice for characterizing model complexity, we argue in favor of LMN for a number of reasons: (1) LMN can be naturally interpreted as information/computation, while $L_2$ cannot. (2) In the compression phase, LMN has linear relations with test losses, while $L_2$ is correlated with test losses in a complicated nonlinear way. (3) LMN also reveals an intriguing phenomenon of the XOR network switching between two generalization solutions, while $L_2$ does not. Besides explaining grokking, we argue that LMN is a promising candidate as the neural network version of the Kolmogorov complexity since it explicitly co
    
[^3]: 狮子秘密地解决受限制优化问题：正如李雅普诺夫所预测的。

    Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v1 [cs.LG])

    [http://arxiv.org/abs/2310.05898](http://arxiv.org/abs/2310.05898)

    Lion是通过程序搜索发现的新优化器，在训练大型AI模型方面表现出有希望的结果，具有更高的内存效率。尽管其理论基础不明确，但基于连续时间和离散时间分析，我们证明Lion是一种理论上新颖且有原则的方法，可在最小化一般损失函数的同时强制执行边界约束。

    

    通过程序搜索发现的新优化器Lion（进化的符号动量）在训练大型AI模型方面显示出有希望的结果。它在训练效果上与AdamW相当或更好，并具有更高的内存效率。正如我们可以从随机搜索程序的结果中期待的，Lion集成了几个现有算法的元素，包括符号动量、独立的权重衰减、Polak和Nesterov动量，但又不属于任何现有的理论基础优化器类别。因此，尽管Lion作为广泛任务的通用优化器表现良好，但其理论基础仍然不明确。这种缺乏理论的明确性限制了进一步增强和扩展Lion的可能性。本文旨在揭开Lion的神秘面纱。基于连续时间和离散时间分析，我们证明Lion是一种理论上新颖且有原则的方法，可在最小化一般损失函数$f(x)$的同时强制执行边界约束。

    Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It performs comparably or favorably to AdamW but with greater memory efficiency. As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.  This work aims to demystify Lion. Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint 
    
[^4]: 深度神经网络对相关数据的泛化界限

    A Generalization Bound of Deep Neural Networks for Dependent Data. (arXiv:2310.05892v1 [stat.ML])

    [http://arxiv.org/abs/2310.05892](http://arxiv.org/abs/2310.05892)

    该研究在非平稳相关数据上建立了前馈神经网络的泛化界限。

    

    现有的深度神经网络泛化界限要求数据是独立同分布的，而在现实应用中，如进化生物学、传染病流行病学和股价预测中，这个假设可能不成立。本研究建立了前馈神经网络在非平稳 $\phi$-混合数据上的泛化界限。

    Existing generalization bounds for deep neural networks require data to be independent and identically distributed (iid). This assumption may not hold in real-life applications such as evolutionary biology, infectious disease epidemiology, and stock price prediction. This work establishes a generalization bound of feed-forward neural networks for non-stationary $\phi$-mixing data.
    
[^5]: 使用WSINDy进行粗粒化哈密顿系统

    Coarse-Graining Hamiltonian Systems Using WSINDy. (arXiv:2310.05879v1 [physics.comp-ph])

    [http://arxiv.org/abs/2310.05879](http://arxiv.org/abs/2310.05879)

    本论文研究了使用WSINDy进行粗粒化哈密顿系统的问题，扩展了WSINDy在相互作用粒子系统中的粗粒化能力。通过识别近似对称性和处理外部扰动，WSINDy成功地识别出降维的哈密顿系统，从而有效地捕捉了相关自由度的动力学。

    

    在相互作用粒子系统的背景下，已经证明了弱形态稀疏识别非线性动力学算法(WSINDy)具有粗粒化能力。在本工作中，我们将这种能力扩展到具有近似对称性的哈密顿动力学的粗粒化问题上。这种近似对称性通常导致存在一个降维的哈密顿系统，可以有效地捕捉相关自由度的动力学。导出这样的降维系统，或者通过数值方法对其进行近似，是一个持续的挑战。我们证明了WSINDy可以成功地在对称不精确性和外部噪声的影响下识别出这个降维的哈密顿系统。这在一部分是因为这样的系统如何被解析地导出是非平凡的。WSINDy自然地保留了哈密顿结构。

    The Weak-form Sparse Identification of Nonlinear Dynamics algorithm (WSINDy) has been demonstrated to offer coarse-graining capabilities in the context of interacting particle systems ( https://doi.org/10.1016/j.physd.2022.133406 ). In this work we extend this capability to the problem of coarse-graining Hamiltonian dynamics which possess approximate symmetries. Such approximate symmetries often lead to the existence of a Hamiltonian system of reduced dimension that may be used to efficiently capture the dynamics of the relevant degrees of freedom. Deriving such reduced systems, or approximating them numerically, is an ongoing challenge. We demonstrate that WSINDy can successfully identify this reduced Hamiltonian system in the presence of large perturbations imparted from both the inexact nature of the symmetry and extrinsic noise. This is significant in part due to the nontrivial means by which such systems are derived analytically. WSINDy naturally preserves the Hamiltonian structur
    
[^6]: 鲁棒的角度同步问题的有向图神经网络解决方案

    Robust Angular Synchronization via Directed Graph Neural Networks. (arXiv:2310.05842v1 [cs.LG])

    [http://arxiv.org/abs/2310.05842](http://arxiv.org/abs/2310.05842)

    本论文提出了一个名为GNNSync的基于有向图神经网络的鲁棒角度同步解决方案，解决了角度同步问题在高噪声环境下的挑战，并提出了新的损失函数以更好地编码同步约束。

    

    角度同步问题旨在通过$m$个偏移量$\theta_i-\theta_j \;\mbox{mod} \; 2\pi$的噪声测量准确估计（最多一个常数相位偏移）一组未知角度$\theta_1, \dots, \theta_n\in[0, 2\pi)$. 应用包括传感器网络定位、相位恢复和分布式时钟同步。该问题的异构扩展（称为$k$-同步）是同时估计$k$组角度，给定每个组的未知组分配的噪声观察值。现有的角度同步方法在高噪声环境下通常表现不佳，而这在应用中很常见。在本文中，我们利用神经网络解决角度同步问题及其异构扩展，提出了GNNSync，这是一个理论支撑的端到端可训练框架，使用有向图神经网络。此外，我们设计了新的损失函数来编码角度同步的约束。

    The angular synchronization problem aims to accurately estimate (up to a constant additive phase) a set of unknown angles $\theta_1, \dots, \theta_n\in[0, 2\pi)$ from $m$ noisy measurements of their offsets $\theta_i-\theta_j \;\mbox{mod} \; 2\pi.$ Applications include, for example, sensor network localization, phase retrieval, and distributed clock synchronization. An extension of the problem to the heterogeneous setting (dubbed $k$-synchronization) is to estimate $k$ groups of angles simultaneously, given noisy observations (with unknown group assignment) from each group. Existing methods for angular synchronization usually perform poorly in high-noise regimes, which are common in applications. In this paper, we leverage neural networks for the angular synchronization problem, and its heterogeneous extension, by proposing GNNSync, a theoretically-grounded end-to-end trainable framework using directed graph neural networks. In addition, new loss functions are devised to encode synchro
    
[^7]: 生成模型的核评分的偏差-方差-协方差分解

    A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models. (arXiv:2310.05833v1 [cs.LG])

    [http://arxiv.org/abs/2310.05833](http://arxiv.org/abs/2310.05833)

    该论文首次引入了生成模型的核评分的偏差-方差-协方差分解，并提出了相应的量的无偏和一致估计器。通过应用在扩散模型上发现少数群体的模式坍缩是一种与过拟合相反的现象，并证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。

    

    生成模型在我们日常生活中变得越来越重要，然而，尚不存在一个理论框架来评估它们的泛化行为和不确定性。特别是，不确定性估计问题通常以一种特定任务的临时解决方案来解决。例如，自然语言方法不能应用于图像生成。在本文中，我们首次引入了用于核评分及其相关熵的偏差-方差-协方差分解。我们提出了每个量的无偏和一致估计器，只需要生成样本而不需要底层模型本身。作为应用，我们提供了扩散模型的泛化评估，并发现少数群体的模式坍缩是一种与过拟合相反的现象。此外，我们证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。具体来说，我们的方法使得可以通过样本生成评估生成模型的泛化性能，并且发现了不同模型类型下的不确定性现象。

    Generative models, like large language models, are becoming increasingly relevant in our daily lives, yet a theoretical framework to assess their generalization behavior and uncertainty does not exist. Particularly, the problem of uncertainty estimation is commonly solved in an ad-hoc manner and task dependent. For example, natural language approaches cannot be transferred to image generation. In this paper we introduce the first bias-variance-covariance decomposition for kernel scores and their associated entropy. We propose unbiased and consistent estimators for each quantity which only require generated samples but not the underlying model itself. As an application, we offer a generalization evaluation of diffusion models and discover how mode collapse of minority groups is a contrary phenomenon to overfitting. Further, we demonstrate that variance and predictive kernel entropy are viable measures of uncertainty for image, audio, and language generation. Specifically, our approach f
    
[^8]: 可证收敛的数据驱动凸非凸正则化

    Provably Convergent Data-Driven Convex-Nonconvex Regularization. (arXiv:2310.05812v1 [cs.LG])

    [http://arxiv.org/abs/2310.05812](http://arxiv.org/abs/2310.05812)

    本研究展示了在凸非凸框架中，通过从数据中学习正则化器，可以实现收敛正则化；引入了一种新颖的弱凸输入神经网络构建，解决了之前对抗性方法的数值问题。

    

    通过使用深度学习从数据中学习正则化器是解决逆问题的新兴范式。这导致了高质量的结果，但往往无法提供可证明的保证。在这项工作中，我们展示了在凸非凸（CNC）框架中出现了良定义性和收敛性正则化的原因。我们引入了一种新颖的弱凸输入神经网络（IWCNN）构建，将学习对抗性正则化方法适应到CNC框架中。从实验证明，我们的方法克服了之前对抗性方法的数值问题。

    An emerging new paradigm for solving inverse problems is via the use of deep learning to learn a regularizer from data. This leads to high-quality results, but often at the cost of provable guarantees. In this work, we show how well-posedness and convergent regularization arises within the convex-nonconvex (CNC) framework for inverse problems. We introduce a novel input weakly convex neural network (IWCNN) construction to adapt the method of learned adversarial regularization to the CNC framework. Empirically we show that our method overcomes numerical issues of previous adversarial methods.
    
[^9]: 提升控制函数

    Boosted Control Functions. (arXiv:2310.05805v1 [stat.ML])

    [http://arxiv.org/abs/2310.05805](http://arxiv.org/abs/2310.05805)

    本研究通过建立同时方程模型和控制函数与分布概括的新连接，解决了在存在未观察到的混淆情况下，针对不同训练和测试分布的预测问题。

    

    现代机器学习方法和大规模数据的可用性为从大量的协变量中准确预测目标数量打开了大门。然而，现有的预测方法在训练和测试数据不同的情况下表现不佳，尤其是在存在隐藏混淆的情况下。虽然对因果效应估计（例如仪器变量）已经对隐藏混淆进行了深入研究，但对于预测任务来说并非如此。本研究旨在填补这一空白，解决在存在未观察到的混淆的情况下，针对不同训练和测试分布的预测问题。具体而言，我们在机器学习的分布概括领域，以及计量经济学中的同时方程模型和控制函数之间建立了一种新的联系。我们的贡献的核心是描述在一组分布转变下的数据生成过程的分布概括同时方程模型（SIMDGs）。

    Modern machine learning methods and the availability of large-scale data opened the door to accurately predict target quantities from large sets of covariates. However, existing prediction methods can perform poorly when the training and testing data are different, especially in the presence of hidden confounding. While hidden confounding is well studied for causal effect estimation (e.g., instrumental variables), this is not the case for prediction tasks. This work aims to bridge this gap by addressing predictions under different training and testing distributions in the presence of unobserved confounding. In particular, we establish a novel connection between the field of distribution generalization from machine learning, and simultaneous equation models and control function from econometrics. Central to our contribution are simultaneous equation models for distribution generalization (SIMDGs) which describe the data-generating process under a set of distributional shifts. Within thi
    
[^10]: 有限采样下神经表示的形状距离估计

    Estimating Shape Distances on Neural Representations with Limited Samples. (arXiv:2310.05742v1 [stat.ML])

    [http://arxiv.org/abs/2310.05742](http://arxiv.org/abs/2310.05742)

    本论文研究了在数据有限情况下，对高维神经表示进行形状距离估计的问题。通过推导出对形状距离标准估计器最坏情况下的收敛上下界，我们揭示了这个问题的挑战性质。为了克服挑战，我们引入了一种新的矩法估计器，并展示了其在高维设置下相对于标准估计器的优越性能。

    

    在神经科学和深度学习领域，衡量高维网络表示之间的几何相似性一直是一个长期的研究兴趣。尽管已经提出了许多方法，但只有少数工作对它们的统计效率进行了严格分析，或者对数据有限情况下的估计器不确定性进行了量化。在这里，我们推导出了标准形状距离估计器（由Williams et al. (2021)提出）的最坏情况收敛上下界。这些界限揭示了在高维特征空间中这个问题的挑战性质。为了克服这些挑战，我们引入了一种新的矩法估计器，具有可调的偏差-方差权衡。我们展示了这个估计器在模拟和神经数据上相对于标准估计器在高维设置下实现了更好的性能。因此，我们为高维形状分析奠定了严格的统计理论基础。

    Measuring geometric similarity between high-dimensional network representations is a topic of longstanding interest to neuroscience and deep learning. Although many methods have been proposed, only a few works have rigorously analyzed their statistical efficiency or quantified estimator uncertainty in data-limited regimes. Here, we derive upper and lower bounds on the worst-case convergence of standard estimators of shape distance$\unicode{x2014}$a measure of representational dissimilarity proposed by Williams et al. (2021). These bounds reveal the challenging nature of the problem in high-dimensional feature spaces. To overcome these challenges, we introduce a new method-of-moments estimator with a tunable bias-variance tradeoff. We show that this estimator achieves superior performance to standard estimators in simulation and on neural data, particularly in high-dimensional settings. Thus, we lay the foundation for a rigorous statistical theory for high-dimensional shape analysis, an
    
[^11]: 后验偏差评分对公平分类最优

    Post-hoc Bias Scoring Is Optimal For Fair Classification. (arXiv:2310.05725v1 [stat.ML])

    [http://arxiv.org/abs/2310.05725](http://arxiv.org/abs/2310.05725)

    本研究提出了一种后验偏差评分的方法，在满足公平性约束的情况下保持高准确性，并给出了基于偏差分数的修改规则。该方法适用于各种类型的公平性约束问题。

    

    我们考虑了一个在群体公平性约束下的二元分类问题，该问题可以是人口统计学公平性（DP），机会均等（EOp）或等概率（EO）之一。我们提出了在公平性约束下贝叶斯最优分类器的明确特征化，结果是不受约束分类器的简单修改规则。即，我们引入了一种新的实例级别的偏差度量，称为偏差分数，而修改规则则是在有限量的偏差分数之上的简单线性规则。基于这个特征化，我们开发了一种后验方法，使我们能够适应公平性约束同时保持较高的准确性。在DP和EOp约束的情况下，修改规则是基于单个偏差分数的阈值选择，而在EO约束的情况下，我们需要调整具有2个参数的线性修改规则。该方法还可以用于包含多个敏感属性的复合群体公平性标准的情况。

    We consider a binary classification problem under group fairness constraints, which can be one of Demographic Parity (DP), Equalized Opportunity (EOp), or Equalized Odds (EO). We propose an explicit characterization of Bayes optimal classifier under the fairness constraints, which turns out to be a simple modification rule of the unconstrained classifier. Namely, we introduce a novel instance-level measure of bias, which we call bias score, and the modification rule is a simple linear rule on top of the finite amount of bias scores. Based on this characterization, we develop a post-hoc approach that allows us to adapt to fairness constraints while maintaining high accuracy. In the case of DP and EOp constraints, the modification rule is thresholding a single bias score, while in the case of EO constraints we are required to fit a linear modification rule with 2 parameters. The method can also be applied for composite group-fairness criteria, such as ones involving several sensitive att
    
[^12]: 使用最优输运器合并Transformer

    Transformer Fusion with Optimal Transport. (arXiv:2310.05719v1 [cs.LG])

    [http://arxiv.org/abs/2310.05719](http://arxiv.org/abs/2310.05719)

    本文介绍了一种使用最优输运来融合基于Transformer的网络的方法，可以对齐各种架构组件并允许不同大小的模型的融合，提供了一种新的高效压缩Transformer的方式。

    

    融合是一种将多个独立训练的神经网络合并以结合它们的能力的技术。过去的尝试仅限于全连接、卷积和残差网络的情况。本文提出了一种系统的方法，利用最优输运来融合两个或多个基于Transformer的网络，以（软）对齐各种架构组件。我们详细描述了一种层对齐的抽象方法，可以推广到任意架构，例如多头自注意力、层归一化和残差连接。我们通过各种消融研究讨论了如何处理这些架构组件。此外，我们的方法允许不同大小的模型进行融合（异构融合），为Transformer的压缩提供了一种新的高效方法。我们通过Vision Transformer进行图像分类任务以及自然语言

    Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities. Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks. In this paper, we present a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components. We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies. Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way for compression of Transformers. The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language
    
[^13]: 多步模型的基于模型的强化学习

    Multi-timestep models for Model-based Reinforcement Learning. (arXiv:2310.05672v1 [cs.LG])

    [http://arxiv.org/abs/2310.05672](http://arxiv.org/abs/2310.05672)

    多步模型的基于模型的强化学习算法通过使用多步目标来训练一步模型，解决了轨迹长度增长时一步预测误差的累积问题，并在噪声数据上表现出显著的性能提升。

    

    在基于模型的强化学习中，大多数算法依赖于从数据中学习到的一步动力学模型来模拟轨迹。这种方法的一个关键挑战是随着轨迹长度的增长，一步预测误差的累积。本文通过使用多步目标来训练一步模型来解决这个问题。我们的目标是在各种未来时间段上的一个损失函数（例如，负对数似然）的加权和。我们探索和测试了一系列权重方案。我们发现指数衰减权重导致模型在长时间段的R2得分显著提高。当模型在噪声数据上进行评估时，这种改进尤为明显。最后，我们在纯批量强化学习（RL）和迭代批量RL场景中使用软件演员-评论家（SAC）代理，发现我们的多步模型优于或与标准的一步模型相匹配。这在考虑环境的噪声变体中尤为明显。

    In model-based reinforcement learning (MBRL), most algorithms rely on simulating trajectories from one-step dynamics models learned on data. A critical challenge of this approach is the compounding of one-step prediction errors as length of the trajectory grows. In this paper we tackle this issue by using a multi-timestep objective to train one-step models. Our objective is a weighted sum of a loss function (e.g., negative log-likelihood) at various future horizons. We explore and test a range of weights profiles. We find that exponentially decaying weights lead to models that significantly improve the long-horizon R2 score. This improvement is particularly noticeable when the models were evaluated on noisy data. Finally, using a soft actor-critic (SAC) agent in pure batch reinforcement learning (RL) and iterated batch RL scenarios, we found that our multi-timestep models outperform or match standard one-step models. This was especially evident in a noisy variant of the considered envi
    
[^14]: 使用动量进行因果结构学习：在DAG的Markov等价类上采样分布

    Causal structure learning with momentum: Sampling distributions over Markov Equivalence Classes of DAGs. (arXiv:2310.05655v1 [stat.ML])

    [http://arxiv.org/abs/2310.05655](http://arxiv.org/abs/2310.05655)

    本文提出了一种非可逆连续时间马尔科夫链，即“因果Zig-Zag采样器”，用于推断贝叶斯网络结构。通过使用动量变量，该采样器可以显著改善混合性能。

    

    在推断贝叶斯网络结构（有向无环图，DAG）的背景下，我们设计了一种非可逆连续时间马尔科夫链，即“因果Zig-Zag采样器”，该采样器针对一类观测等价（Markov等价）DAG的概率分布。这些类别以完成的部分有向无环图（CPDAG）表示。非可逆马尔科夫链依赖于Chickering的贪婪等价搜索（GES）中使用的操作符，并且具有一个动量变量，经实验证明可以显著改善混合性能。可能的目标分布包括基于DAG先验和Markov等价似然的后验分布。我们提供了一个高效的实现，其中我们开发了新的算法来列举、计数、均匀采样和应用GES操作符的可能移动，所有这些算法都显著改进了现有技术。

    In the context of inferring a Bayesian network structure (directed acyclic graph, DAG for short), we devise a non-reversible continuous time Markov chain, the "Causal Zig-Zag sampler", that targets a probability distribution over classes of observationally equivalent (Markov equivalent) DAGs. The classes are represented as completed partially directed acyclic graphs (CPDAGs). The non-reversible Markov chain relies on the operators used in Chickering's Greedy Equivalence Search (GES) and is endowed with a momentum variable, which improves mixing significantly as we show empirically. The possible target distributions include posterior distributions based on a prior over DAGs and a Markov equivalent likelihood. We offer an efficient implementation wherein we develop new algorithms for listing, counting, uniformly sampling, and applying possible moves of the GES operators, all of which significantly improve upon the state-of-the-art.
    
[^15]: 一个新的二元结果提升建模转换方法

    A New Transformation Approach for Uplift Modeling with Binary Outcome. (arXiv:2310.05549v1 [stat.ML])

    [http://arxiv.org/abs/2310.05549](http://arxiv.org/abs/2310.05549)

    本论文提出了一种新的二元结果提升建模转换方法，利用了零结果样本的信息并且易于使用。 (arXiv:2310.05549v1 [stat.ML])

    

    提升建模在市场营销和客户保留等领域中得到了有效应用，用于针对那些由于活动或治疗更有可能产生反应的客户。本文设计了一种新颖的二元结果转换方法，解锁了零结果样本的全部价值。

    Uplift modeling has been used effectively in fields such as marketing and customer retention, to target those customers who are more likely to respond due to the campaign or treatment. Essentially, it is a machine learning technique that predicts the gain from performing some action with respect to not taking it. A popular class of uplift models is the transformation approach that redefines the target variable with the original treatment indicator. These transformation approaches only need to train and predict the difference in outcomes directly. The main drawback of these approaches is that in general it does not use the information in the treatment indicator beyond the construction of the transformed outcome and usually is not efficient. In this paper, we design a novel transformed outcome for the case of the binary target variable and unlock the full value of the samples with zero outcome. From a practical perspective, our new approach is flexible and easy to use. Experimental resul
    
[^16]: 使用数论将无限时间序列图投射到有限边际图

    Projecting infinite time series graphs to finite marginal graphs using number theory. (arXiv:2310.05526v1 [math.ST])

    [http://arxiv.org/abs/2310.05526](http://arxiv.org/abs/2310.05526)

    本研究提出了一种将具有重复边的无限时间序列图投射到有限边际图上的方法，从而解决了以往无法处理的$m$-分离查询任务，并为时间序列的因果发现和因果效果估计提供了有用的工具。

    

    近年来，越来越多的方法和应用工作将因果图模型框架应用于时间序列数据。其中很多工作使用了时间分辨的因果图，这些图在过去和未来都延展到无限远，并且边在时间上是重复的，体现了稳态因果关系的假设。然而，因果图模型框架的大多数结果和算法并不适用于无限图。在这项工作中，我们开发了一种方法，将具有重复边的无限时间序列图投射到有限时间窗口上的边际图模型。这些有限边际图对于与无限图相关的$m$-分离查询提供了答案，这是以前无法解决的任务。此外，我们认为这些边际图对于时间序列的因果发现和因果效果估计是有用的，可以将为有限图开发的结果应用到无限图上。

    In recent years, a growing number of method and application works have adapted and applied the causal-graphical-model framework to time series data. Many of these works employ time-resolved causal graphs that extend infinitely into the past and future and whose edges are repetitive in time, thereby reflecting the assumption of stationary causal relationships. However, most results and algorithms from the causal-graphical-model framework are not designed for infinite graphs. In this work, we develop a method for projecting infinite time series graphs with repetitive edges to marginal graphical models on a finite time window. These finite marginal graphs provide the answers to $m$-separation queries with respect to the infinite graph, a task that was previously unresolved. Moreover, we argue that these marginal graphs are useful for causal discovery and causal effect estimation in time series, effectively enabling to apply results developed for finite graphs to the infinite graphs. The p
    
[^17]: 基于神经切向核的联邦平均在深度线性神经网络上的视角

    A Neural Tangent Kernel View on Federated Averaging for Deep Linear Neural Network. (arXiv:2310.05495v1 [cs.LG])

    [http://arxiv.org/abs/2310.05495](http://arxiv.org/abs/2310.05495)

    本论文介绍了一种基于神经切向核视角的联邦平均方法在深度线性神经网络上的应用，并探讨了该方法面临的挑战。

    

    联邦平均（FedAvg）是一种广泛使用的范式，用于在不共享数据的情况下协同训练来自分布式客户端的模型。如今，由于其卓越性能，神经网络取得了显著的成功，这使得它成为FedAvg中的首选模型。然而，神经网络的优化问题通常是非凸的甚至是非光滑的。此外，FedAvg总是涉及多个客户端和本地更新，导致不准确的更新方向。这些属性给分析FedAvg在训练神经网络中的收敛性带来了困难。最近，神经切向核（NTK）理论已被提出，用于理解解决神经网络非凸问题中的一阶方法的收敛性。深度线性神经网络是理论学科中的经典模型，由于其简单的公式。然而，在训练深度线性神经网络上，对于FedAvg的收敛性目前还没有理论结果。

    Federated averaging (FedAvg) is a widely employed paradigm for collaboratively training models from distributed clients without sharing data. Nowadays, the neural network has achieved remarkable success due to its extraordinary performance, which makes it a preferred choice as the model in FedAvg. However, the optimization problem of the neural network is often non-convex even non-smooth. Furthermore, FedAvg always involves multiple clients and local updates, which results in an inaccurate updating direction. These properties bring difficulties in analyzing the convergence of FedAvg in training neural networks. Recently, neural tangent kernel (NTK) theory has been proposed towards understanding the convergence of first-order methods in tackling the non-convex problem of neural networks. The deep linear neural network is a classical model in theoretical subject due to its simple formulation. Nevertheless, there exists no theoretical result for the convergence of FedAvg in training the d
    
[^18]: 无积分训练的时空多模态协变深度内核点过程

    Integration-free Training for Spatio-temporal Multimodal Covariate Deep Kernel Point Processes. (arXiv:2310.05485v1 [cs.LG])

    [http://arxiv.org/abs/2310.05485](http://arxiv.org/abs/2310.05485)

    本研究提出了一种无积分训练的时空多模态协变深度内核点过程模型，利用分数匹配方法和去噪分数匹配方法解决了训练困难，实验结果表明该模型优于基线模型。

    

    在本研究中，我们提出了一种新颖的深度时空点过程模型，Deep Kernel Mixture Point Processes (DKMPP)，它融合了多模态协变信息。DKMPP是Deep Mixture Point Processes (DMPP)的改进版本，使用更灵活的深度内核建模事件和协变数据之间的复杂关系，提高了模型的表达能力。为了解决DKMPP的非可积深度内核造成的训练困难，我们采用了基于分数匹配的无积分方法，并进一步通过采用可扩展的去噪分数匹配方法提高了效率。我们的实验结果表明，DKMPP及其相应的基于分数的估计器优于基线模型，展示了融合协变信息、利用深度内核和采用基于分数的估计器的优势。

    In this study, we propose a novel deep spatio-temporal point process model, Deep Kernel Mixture Point Processes (DKMPP), that incorporates multimodal covariate information. DKMPP is an enhanced version of Deep Mixture Point Processes (DMPP), which uses a more flexible deep kernel to model complex relationships between events and covariate data, improving the model's expressiveness. To address the intractable training procedure of DKMPP due to the non-integrable deep kernel, we utilize an integration-free method based on score matching, and further improve efficiency by adopting a scalable denoising score matching method. Our experiments demonstrate that DKMPP and its corresponding score-based estimators outperform baseline models, showcasing the advantages of incorporating covariate information, utilizing a deep kernel, and employing score-based estimators.
    
[^19]: ExIFFI和EIF+：解释性和增强的推广能力以扩展扩展孤立森林

    ExIFFI and EIF+: Interpretability and Enhanced Generalizability to Extend the Extended Isolation Forest. (arXiv:2310.05468v1 [stat.ML])

    [http://arxiv.org/abs/2310.05468](http://arxiv.org/abs/2310.05468)

    本研究介绍了EIF+和ExIFFI两种改进了扩展孤立森林的方法，分别增强了模型的推广能力和解释性能，实验结果表明其在异常检测任务中具有优势。

    

    异常检测是一种重要的无监督机器学习任务，涉及在复杂数据集和系统中识别异常行为。虽然机器学习算法和决策支持系统（DSS）提供了有效的解决方案，但仅仅定位异常往往在实际应用中不足。这些系统的用户通常需要了解预测背后的原因，以便进行根本原因分析并增强对模型的信任。然而，由于异常检测的无监督性质，创建可解释的工具是具有挑战性的。本文介绍了EIF+，这是扩展孤立森林（EIF）的增强变体，旨在增强泛化能力。此外，我们提出了ExIFFI，一种将扩展孤立森林与解释性功能（特征排名）相结合的新方法。实验结果提供了以孤立基于方法进行异常检测的综合比较分析。

    Anomaly detection, an essential unsupervised machine learning task, involves identifying unusual behaviors within complex datasets and systems. While Machine Learning algorithms and decision support systems (DSSs) offer effective solutions for this task, simply pinpointing anomalies often falls short in real-world applications. Users of these systems often require insight into the underlying reasons behind predictions to facilitate Root Cause Analysis and foster trust in the model. However, due to the unsupervised nature of anomaly detection, creating interpretable tools is challenging. This work introduces EIF+, an enhanced variant of Extended Isolation Forest (EIF), designed to enhance generalization capabilities. Additionally, we present ExIFFI, a novel approach that equips Extended Isolation Forest with interpretability features, specifically feature rankings. Experimental results provide a comprehensive comparative analysis of Isolation-based approaches for Anomaly Detection, incl
    
[^20]: 基于贝叶斯Spike-and-Slab先验和高效核函数的方程式发现方法

    Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels. (arXiv:2310.05387v1 [cs.LG])

    [http://arxiv.org/abs/2310.05387](http://arxiv.org/abs/2310.05387)

    该论文提出了一种基于核学习和贝叶斯Spike-and-Slab先验的方程式发现方法，通过核回归和贝叶斯稀疏分布，能够有效处理数据稀疏性和噪声问题，并进行不确定性量化和高效的后验推断和函数估计。

    

    从数据中发现控制方程对于许多科学和工程应用非常重要。然而，尽管有一些有希望的成功案例，现有方法仍然面临着数据稀疏性和噪声问题的挑战，这在实践中随处可见。此外，最先进的方法缺乏不确定性量化和/或训练成本高昂。为了克服这些局限性，我们提出了一种基于核学习和贝叶斯Spike-and-Slab先验（KBASS）的新型方程式发现方法。我们使用核回归来估计目标函数，这种方法具有灵活性、表达力，并且对于数据稀疏性和噪声更加稳健。我们将其与贝叶斯Spike-and-Slab先验结合使用，后者是一种理想的贝叶斯稀疏分布，用于有效的算子选择和不确定性量化。我们开发了一种基于期望传播期望最大化（EP-EM）算法的有效后验推断和函数估计方法。为了克服核回归的计算挑战，我们使用了一种快速方法。

    Discovering governing equations from data is important to many scientific and engineering applications. Despite promising successes, existing methods are still challenged by data sparsity as well as noise issues, both of which are ubiquitous in practice. Moreover, state-of-the-art methods lack uncertainty quantification and/or are costly in training. To overcome these limitations, we propose a novel equation discovery method based on Kernel learning and BAyesian Spike-and-Slab priors (KBASS). We use kernel regression to estimate the target function, which is flexible, expressive, and more robust to data sparsity and noises. We combine it with a Bayesian spike-and-slab prior -- an ideal Bayesian sparse distribution -- for effective operator selection and uncertainty quantification. We develop an expectation propagation expectation-maximization (EP-EM) algorithm for efficient posterior inference and function estimation. To overcome the computational challenge of kernel regression, we pla
    
[^21]: 优化组合问题的解采样器：策略梯度方法的梯度方向

    Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Methods. (arXiv:2310.05309v1 [cs.LG])

    [http://arxiv.org/abs/2310.05309](http://arxiv.org/abs/2310.05309)

    本文提出了一种新颖的理论框架，为深度神经网络和增强学习方法在解决组合问题方面的有效性提供了肯定的答案。这个框架对于解决包括最大割和最小割、最大$k$约束问题、最大权重二分图匹配和旅行商问题在内的广泛的组合问题有重要的意义。

    

    深度神经网络和增强学习方法在解决复杂的组合问题方面具有很高的实用价值。在这些方法中，深度神经网络被用作解决方案生成器，然后通过梯度下降等方法进行训练，以逐步获得更好的解决方案分布。在这项工作中，我们引入了一种新颖的理论框架来分析这些方法的有效性。我们的主要贡献是对这个问题的积极回答。我们的结果适用于包括最大割和最小割、最大$k$约束问题、最大权重二分图匹配和旅行商问题在内的广泛的组合问题。

    Deep Neural Networks and Reinforcement Learning methods have empirically shown great promise in tackling challenging combinatorial problems. In those methods a deep neural network is used as a solution generator which is then trained by gradient-based methods (e.g., policy gradient) to successively obtain better solution distributions. In this work we introduce a novel theoretical framework for analyzing the effectiveness of such methods. We ask whether there exist generative models that (i) are expressive enough to generate approximately optimal solutions; (ii) have a tractable, i.e, polynomial in the size of the input, number of parameters; (iii) their optimization landscape is benign in the sense that it does not contain sub-optimal stationary points. Our main contribution is a positive answer to this question. Our result holds for a broad class of combinatorial problems including Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and the Traveling Salesman Problem. A
    
[^22]: 对组合多臂老虎机的对抗攻击

    Adversarial Attacks on Combinatorial Multi-Armed Bandits. (arXiv:2310.05308v1 [cs.LG])

    [http://arxiv.org/abs/2310.05308](http://arxiv.org/abs/2310.05308)

    本文研究了对组合多臂老虎机的奖励污染攻击，并给出了攻击可能性的条件。与以往对多臂老虎机的理解相反，我们发现特定CMAB实例的攻击可能性还取决于发哥实例是否被对手知晓。这表明在实践中对CMAB进行对抗攻击是困难的，因为对手大部分情况下无法了解环境的情况。

    

    本文研究了对组合多臂老虎机（CMAB）的奖励污染攻击。我们首先给出了CMAB攻击可能性的充分必要条件，该条件取决于相应CMAB实例的内在特性，如超臂的奖励分布和基本臂的结果分布。此外，我们设计了适用于可攻击CMAB实例的攻击算法。与以往对多臂老虎机的理解相反，我们的研究揭示了一个令人惊讶的事实，即特定CMAB实例的攻击可能性还取决于发哥实例是否被对手知晓。这一发现表明，CMAB的对抗攻击在实践中很困难，并且不存在适用于任何CMAB实例的通用攻击策略，因为环境对于对手来说大部分是未知的。我们通过对实际CMAB应用（包括概率最大覆盖问题、在线最小生成树问题）的大量实验验证了我们的理论发现。

    We study reward poisoning attacks on Combinatorial Multi-armed Bandits (CMAB). We first provide a sufficient and necessary condition for the attackability of CMAB, which depends on the intrinsic properties of the corresponding CMAB instance such as the reward distributions of super arms and outcome distributions of base arms. Additionally, we devise an attack algorithm for attackable CMAB instances. Contrary to prior understanding of multi-armed bandits, our work reveals a surprising fact that the attackability of a specific CMAB instance also depends on whether the bandit instance is known or unknown to the adversary. This finding indicates that adversarial attacks on CMAB are difficult in practice and a general attack strategy for any CMAB instance does not exist since the environment is mostly unknown to the adversary. We validate our theoretical findings via extensive experiments on real-world CMAB applications including probabilistic maximum covering problem, online minimum spanni
    
[^23]: 带有异常值的三元数据聚类

    Clustering Three-Way Data with Outliers. (arXiv:2310.05288v1 [stat.ML])

    [http://arxiv.org/abs/2310.05288](http://arxiv.org/abs/2310.05288)

    这项研究提出了一种用于聚类矩阵形式数据的方法，可以处理其中的异常值。

    

    矩阵变量分布是模型聚类领域的最新添加，从而可以分析具有复杂结构（如图像和时间序列）的矩阵形式数据。由于其最近的出现，关于矩阵变量数据的文献有限，对于处理这些模型中的异常值的文献更少。本文讨论了一种用于聚类矩阵变量正态数据的方法。该方法使用子集对数似然的分布，将OCLUST算法扩展到矩阵变量正态数据，并使用迭代方法检测和剪裁异常值。

    Matrix-variate distributions are a recent addition to the model-based clustering field, thereby making it possible to analyze data in matrix form with complex structure such as images and time series. Due to its recent appearance, there is limited literature on matrix-variate data, with even less on dealing with outliers in these models. An approach for clustering matrix-variate normal data with outliers is discussed. The approach, which uses the distribution of subset log-likelihoods, extends the OCLUST algorithm to matrix-variate normal data and uses an iterative approach to detect and trim outliers.
    
[^24]: 用低秩内核模型简化GNN性能

    Simplifying GNN Performance with Low Rank Kernel Models. (arXiv:2310.05250v1 [cs.LG])

    [http://arxiv.org/abs/2310.05250](http://arxiv.org/abs/2310.05250)

    本文提出了一种用于简化GNN性能的低秩内核模型，通过应用传统的非参数估计方法在谱域中取代过于复杂的GNN架构，并在多个图类型的半监督节点分类基准测试中取得了最先进的性能。

    

    我们重新审视了最近的谱GNN方法对半监督节点分类（SSNC）的应用。我们认为许多当前的GNN架构可能过于精细设计。相反，简单的非参数估计传统方法，在谱域中应用，可以取代许多受深度学习启发的GNN设计。这些传统技术似乎非常适合各种图类型，在许多常见的SSNC基准测试中达到了最先进的性能。此外，我们还展示了最近在GNN方法方面的性能改进可能部分归因于评估惯例的变化。最后，我们对与GNN谱过滤技术相关的各种超参数进行了消融研究。

    We revisit recent spectral GNN approaches to semi-supervised node classification (SSNC). We posit that many of the current GNN architectures may be over-engineered. Instead, simpler, traditional methods from nonparametric estimation, applied in the spectral domain, could replace many deep-learning inspired GNN designs. These conventional techniques appear to be well suited for a variety of graph types reaching state-of-the-art performance on many of the common SSNC benchmarks. Additionally, we show that recent performance improvements in GNN approaches may be partially attributed to shifts in evaluation conventions. Lastly, an ablative study is conducted on the various hyperparameters associated with GNN spectral filtering techniques. Code available at: https://github.com/lucianoAvinas/lowrank-gnn-kernels
    
[^25]: Transformers内部的收敛性研究

    In-Context Convergence of Transformers. (arXiv:2310.05249v1 [cs.LG])

    [http://arxiv.org/abs/2310.05249](http://arxiv.org/abs/2310.05249)

    本研究通过对Transformers内部学习动力学的分析，研究了一层Transformer使用梯度下降进行上下文学习的能力，对于具有平衡特征的数据，建立了有限时间收敛保证，且预测误差接近零。

    

    近期，Transformers在现代机器学习的许多领域中取得了巨大的革命性进展，其中一个显著的发现是它们在上下文学习方面的出色能力，通过利用特定任务的提示而无需参数微调，模型可以解决从未见过的任务。这也启发了最近的理论研究，目标是理解Transformers在上下文学习中的机制，然而这些研究仅关注线性Transformer。本文通过梯度下降训练一层Transformer的softmax attention机制，首次在上下文学习线性函数类方面研究学习动力学。我们考虑了一个结构化数据模型，其中每个标记从一组平衡或不平衡的特征向量中随机采样。对于具有平衡特征的数据，我们通过在训练动力学的两个阶段上进行分析，建立了有限时间收敛保证，且预测误差接近零。

    Transformers have recently revolutionized many domains in modern machine learning and one salient discovery is their remarkable in-context learning capability, where models can solve an unseen task by utilizing task-specific prompts without further parameters fine-tuning. This also inspired recent theoretical studies aiming to understand the in-context learning mechanism of transformers, which however focused only on linear transformers. In this work, we take the first step toward studying the learning dynamics of a one-layer transformer with softmax attention trained via gradient descent in order to in-context learn linear function classes. We consider a structured data model, where each token is randomly sampled from a set of feature vectors in either balanced or imbalanced fashion. For data with balanced features, we establish the finite-time convergence guarantee with near-zero prediction error by navigating our analysis over two phases of the training dynamics of the attention map
    
[^26]: Orlicz后悔统一边界随机变量统计的方法及其在环境指标中的应用

    Orlicz regrets to consistently bound statistics of random variables with an application to environmental indicators. (arXiv:2310.05168v1 [math.ST])

    [http://arxiv.org/abs/2310.05168](http://arxiv.org/abs/2310.05168)

    本文提出了一种新型的Orlicz后悔方法，用于一致地界定随机变量的统计量上下界，通过灵活评估随机变量的尾行为。与传统方法不同，此方法采用了一致性评估，并得到了将其与发散风险度量等效的充分条件。

    

    针对随机变量的统计评估是设计更好的环境管理和恢复方案的主要议题。对于水质指标、洪涝和干旱水位等这些变量的上下界估计都很重要，应当在一个统一的数学框架中进行一致的评估。我们提出了一种新型的Orlicz后悔方法，用于一致地界定随机变量的统计量上下界。这里的一致性指的是上界和下界使用相同的系数和参数值进行评估，与迄今为止提出的某些风险度量不同。Orlicz后悔能够根据随机变量的尾行为灵活地评估其统计量。我们通过明确地将Orlicz后悔与发散风险度量联系起来，以更好地理解它们。我们得到了将Orlicz后悔和发散风险度量等效的充分条件。

    Evaluating environmental variables that vary stochastically is the principal topic for designing better environmental management and restoration schemes. Both the upper and lower estimates of these variables, such as water quality indices and flood and drought water levels, are important and should be consistently evaluated within a unified mathematical framework. We propose a novel pair of Orlicz regrets to consistently bound the statistics of random variables both from below and above. Here, consistency indicates that the upper and lower bounds are evaluated with common coefficients and parameter values being different from some of the risk measures proposed thus far. Orlicz regrets can flexibly evaluate the statistics of random variables based on their tail behavior. The explicit linkage between Orlicz regrets and divergence risk measures was exploited to better comprehend them. We obtain sufficient conditions to pose the Orlicz regrets as well as divergence risk measures, and furth
    
[^27]: 一个在有噪声观测下修正的期望改善采集函数

    A Corrected Expected Improvement Acquisition Function Under Noisy Observations. (arXiv:2310.05166v1 [cs.LG])

    [http://arxiv.org/abs/2310.05166](http://arxiv.org/abs/2310.05166)

    这个论文提出了一个修正的期望改善采集函数，在贝叶斯优化中解决了对于有噪声观测的情况下忽略候选解不确定性的问题。

    

    序列最大化期望改善(EI)是贝叶斯优化中最常用的策略之一，因其简单性和处理噪声观测的能力而广泛应用。特别是，在噪声环境中，改善函数通常使用最佳后验均值作为最佳候选解。然而，在许多解析的EI类型方法中，常常忽略与候选解相关的不确定性：在无噪声的情况下导出了一个闭合形式的采集函数，然后应用于有噪声观测的情况。为了解决这个限制，我们提出了一种修正EI的方法，将高斯过程(GP)模型提供的协方差信息纳入其闭合形式表达式中。这个采集函数与经典的无噪声结果相吻合，我们认为它应该取代贝叶斯优化软件包、教程和教材中的那个公式。这个改进的采集函数为有噪声和无噪声的解提供了良好的适用性。

    Sequential maximization of expected improvement (EI) is one of the most widely used policies in Bayesian optimization because of its simplicity and ability to handle noisy observations. In particular, the improvement function often uses the best posterior mean as the best incumbent in noisy settings. However, the uncertainty associated with the incumbent solution is often neglected in many analytic EI-type methods: a closed-form acquisition function is derived in the noise-free setting, but then applied to the setting with noisy observations. To address this limitation, we propose a modification of EI that corrects its closed-form expression by incorporating the covariance information provided by the Gaussian Process (GP) model. This acquisition function specializes to the classical noise-free result, and we argue should replace that formula in Bayesian optimization software packages, tutorials, and textbooks. This enhanced acquisition provides good generality for noisy and noiseless s
    
[^28]: 压缩在线Sinkhorn算法

    Compressed online Sinkhorn. (arXiv:2310.05019v1 [cs.LG])

    [http://arxiv.org/abs/2310.05019](http://arxiv.org/abs/2310.05019)

    这篇论文介绍了压缩在线Sinkhorn算法，在机器学习和数据科学领域中，它提出了处理连续数据流的随机版本，收敛速度更快。

    

    在机器学习和数据科学的许多领域中，最优传输（OT）距离的使用，特别是熵正则化OT距离，成为越来越受欢迎的评估指标。它们的使用主要是由于Sinkhorn算法等高效算法的可用性。Sinkhorn算法在大规模数据处理中的一个缺点是它是一个两阶段的方法，首先从概率分布中抽取大量数据，然后将Sinkhorn算法应用于离散概率测度。最近，已经有一些研究开发了直接处理连续数据流的Sinkhorn的随机版本。在这项工作中，我们重新审视了[Mensch和Peyr\'e, 2020]最近引入的在线Sinkhorn算法。我们的贡献有两个方面：我们改进了在线Sinkhorn算法的收敛分析，新得到的收敛速度在某些参数下比先前的速度更快。

    The use of optimal transport (OT) distances, and in particular entropic-regularised OT distances, is an increasingly popular evaluation metric in many areas of machine learning and data science. Their use has largely been driven by the availability of efficient algorithms such as the Sinkhorn algorithm. One of the drawbacks of the Sinkhorn algorithm for large-scale data processing is that it is a two-phase method, where one first draws a large stream of data from the probability distributions, before applying the Sinkhorn algorithm to the discrete probability measures. More recently, there have been several works developing stochastic versions of Sinkhorn that directly handle continuous streams of data. In this work, we revisit the recently introduced online Sinkhorn algorithm of [Mensch and Peyr\'e, 2020]. Our contributions are twofold: We improve the convergence analysis for the online Sinkhorn algorithm, the new rate that we obtain is faster than the previous rate under certain para
    
[^29]: 模型适应的傅立叶采样用于生成式压缩感知

    Model-adapted Fourier sampling for generative compressed sensing. (arXiv:2310.04984v1 [cs.IT])

    [http://arxiv.org/abs/2310.04984](http://arxiv.org/abs/2310.04984)

    这篇论文提出了一种模型适应的采样策略，用于生成式压缩感知中的信号恢复，通过优化采样分布和新的理论恢复保证技术，能够显著减少所需测量的数量。

    

    我们研究了当测量矩阵是从一个酉矩阵中随机子采样得到时的生成式压缩感知问题（离散傅立叶变换是重要的特殊情况）。最近的研究表明，当每个傅立叶向量与神经网络的取值范围对齐时，只需要$O(kdn\|\boldsymbol{\alpha}\|_{\infty}^{2})$个均匀随机傅立叶测量就足以恢复输出信号。我们构建了一个模型适应的采样策略，其样本复杂度得到了改进，只需要$O(kd\|\boldsymbol{\alpha}\|_{2}^{2})$个测量。这是通过以下步骤实现的：（1）我们开发了适用于非均匀随机采样分布  的新的理论恢复保证，然后（2）优化采样分布以最小化这些保证所需的测量数量。这种技术发展提供了适用的样本复杂度。

    We study generative compressed sensing when the measurement matrix is randomly subsampled from a unitary matrix (with the DFT as an important special case). It was recently shown that $\textit{O}(kdn\| \boldsymbol{\alpha}\|_{\infty}^{2})$ uniformly random Fourier measurements are sufficient to recover signals in the range of a neural network $G:\mathbb{R}^k \to \mathbb{R}^n$ of depth $d$, where each component of the so-called local coherence vector $\boldsymbol{\alpha}$ quantifies the alignment of a corresponding Fourier vector with the range of $G$. We construct a model-adapted sampling strategy with an improved sample complexity of $\textit{O}(kd\| \boldsymbol{\alpha}\|_{2}^{2})$ measurements. This is enabled by: (1) new theoretical recovery guarantees that we develop for nonuniformly random sampling distributions and then (2) optimizing the sampling distribution to minimize the number of measurements needed for these guarantees. This development offers a sample complexity applicable
    
[^30]: 鲁棒矩阵补全的新型M估计函数

    Robust matrix completion via Novel M-estimator Functions. (arXiv:2310.04953v1 [stat.ML])

    [http://arxiv.org/abs/2310.04953](http://arxiv.org/abs/2310.04953)

    本文针对鲁棒矩阵补全问题，提出了一种利用新型M估计函数的方法。通过生成一类非凸函数，用于减弱受异常值污染的观测值，得到了相应的鲁棒损失函数。在算法设计和收敛性分析上取得了较好的结果，并且数值实验结果表明，该方法在恢复准确性和运行时间方面优于其他竞争方法。

    

    Welsch和Cauchy等M估计器已被广泛应用于对抗异常值的鲁棒性，但它们也会减弱未受污染的数据。为了解决这个问题，我们设计了一个生成一类非凸函数的框架，这些函数只会减弱受异常值污染的观测值。然后，我们将该框架应用于Welsch，Cauchy和$\ell_p$-norm函数，生成相应的鲁棒损失函数。我们针对鲁棒矩阵补全应用了基于这些函数的高效算法，并对其收敛性进行了分析。最后，大量的数值实验结果表明，所提出的方法在恢复准确性和运行时间方面优于竞争对手。

    M-estmators including the Welsch and Cauchy have been widely adopted for robustness against outliers, but they also down-weigh the uncontaminated data. To address this issue, we devise a framework to generate a class of nonconvex functions which only down-weigh outlier-corrupted observations. Our framework is then applied to the Welsch, Cauchy and $\ell_p$-norm functions to produce the corresponding robust loss functions. Targeting on the application of robust matrix completion, efficient algorithms based on these functions are developed and their convergence is analyzed. Finally, extensive numerical results demonstrate that the proposed methods are superior to the competitors in terms of recovery accuracy and runtime.
    
[^31]: 使用PAC-Bayesian理论给变分自动编码器提供统计保证

    Statistical Guarantees for Variational Autoencoders using PAC-Bayesian Theory. (arXiv:2310.04935v1 [cs.LG])

    [http://arxiv.org/abs/2310.04935](http://arxiv.org/abs/2310.04935)

    这项工作利用PAC-Bayesian理论为变分自动编码器提供了统计保证，包括对后验分布、重构损失和输入与生成分布之间距离的上界。

    

    自从它们的问世以来，变分自动编码器（VAEs）在机器学习中变得非常重要。尽管它们被广泛使用，关于它们的理论性质仍存在许多问题。本文利用PAC-Bayesian理论为VAEs提供统计保证。首先，我们推导出了基于独立样本的后验分布的首个PAC-Bayesian界限。然后，利用这一结果为VAE的重构损失提供了泛化保证，同时提供了输入分布与VAE生成模型定义的分布之间距离的上界。更重要的是，我们提供了输入分布与VAE生成模型定义的分布之间Wasserstein距离的上界。

    Since their inception, Variational Autoencoders (VAEs) have become central in machine learning. Despite their widespread use, numerous questions regarding their theoretical properties remain open. Using PAC-Bayesian theory, this work develops statistical guarantees for VAEs. First, we derive the first PAC-Bayesian bound for posterior distributions conditioned on individual samples from the data-generating distribution. Then, we utilize this result to develop generalization guarantees for the VAE's reconstruction loss, as well as upper bounds on the distance between the input and the regenerated distributions. More importantly, we provide upper bounds on the Wasserstein distance between the input distribution and the distribution defined by the VAE's generative model.
    
[^32]: DISCOVER: 通过竞争和剖析使视觉网络可解释

    DISCOVER: Making Vision Networks Interpretable via Competition and Dissection. (arXiv:2310.04929v1 [cs.CV])

    [http://arxiv.org/abs/2310.04929](http://arxiv.org/abs/2310.04929)

    该论文的创新是通过竞争和剖析的方法，使得视觉网络更容易解释，从而克服了深度网络复杂且难以解释的问题。

    

    现代深度网络非常复杂，其推理结果很难解释。这对于透明地将其部署在安全关键或偏见感知应用中是一个严重的障碍。本研究对后期可解释性特别是网络剖析做出了贡献。我们的目标是提出一个框架，使得在训练于视觉任务的网络中，发现每个神经元的个体功能更容易；通过生成文本描述进行发现。为了实现这个目标，我们利用了以下两个方面：(i)最新的多模态视觉-文本模型的进展和(ii)基于线性单元之间的新概念-随机局部竞争的网络层。在这种设置下，对于给定的输入只有一小部分层神经元被激活，导致极高的激活稀疏性（仅约为4%）。至关重要的是，我们提出的方法推断出了（稀疏的）神经元激活模式，使得神经元能够激活/专门化为...

    Modern deep networks are highly complex and their inferential outcome very hard to interpret. This is a serious obstacle to their transparent deployment in safety-critical or bias-aware applications. This work contributes to post-hoc interpretability, and specifically Network Dissection. Our goal is to present a framework that makes it easier to discover the individual functionality of each neuron in a network trained on a vision task; discovery is performed in terms of textual description generation. To achieve this objective, we leverage: (i) recent advances in multimodal vision-text models and (ii) network layers founded upon the novel concept of stochastic local competition between linear units. In this setting, only a small subset of layer neurons are activated for a given input, leading to extremely high activation sparsity (as low as only $\approx 4\%$). Crucially, our proposed method infers (sparse) neuron activation patterns that enables the neurons to activate/specialize to i
    
[^33]: 条件预测函数：一种用于复杂模型的控制误发现率的新技术

    The Conditional Prediction Function: A Novel Technique to Control False Discovery Rate for Complex Models. (arXiv:2310.04919v1 [stat.ME])

    [http://arxiv.org/abs/2310.04919](http://arxiv.org/abs/2310.04919)

    引入了一种基于条件预测函数的Knockoff统计方法，可以在复杂模型中对误发现率进行控制，并且能够捕捉到预测变量和结果之间的非线性关系。

    

    在现代科学研究中，目标通常是在大量可能的预测因素中确定与结果相关的变量。这个目标可以通过以控制误发现率（FDR）的方式来选择变量来实现，即在所选择的变量中，无关的预测因素的比例。Knockoff滤波是一种先进的变量选择方法，可以提供FDR控制。现有的Knockoff统计方法经常使用线性模型来评估特征和响应之间的关系，但是在线性模型在现实世界应用中常常被违反。这可能导致对真正预测变量的检测能力较差。我们引入了一种基于条件预测函数（CPF）的Knockoff统计方法，它可以与最先进的机器学习预测模型（如深度神经网络）配对使用。CPF统计方法可以捕捉预测变量和结果之间的非线性关系，同时还考虑了相关性。

    In modern scientific research, the objective is often to identify which variables are associated with an outcome among a large class of potential predictors. This goal can be achieved by selecting variables in a manner that controls the the false discovery rate (FDR), the proportion of irrelevant predictors among the selections. Knockoff filtering is a cutting-edge approach to variable selection that provides FDR control. Existing knockoff statistics frequently employ linear models to assess relationships between features and the response, but the linearity assumption is often violated in real world applications. This may result in poor power to detect truly prognostic variables. We introduce a knockoff statistic based on the conditional prediction function (CPF), which can pair with state-of-art machine learning predictive models, such as deep neural networks. The CPF statistics can capture the nonlinear relationships between predictors and outcomes while also accounting for correlati
    
[^34]: 针对随机稀疏神经Galerkin方案用于求解含有深度网络的演化方程

    Randomized Sparse Neural Galerkin Schemes for Solving Evolution Equations with Deep Networks. (arXiv:2310.04867v1 [cs.LG])

    [http://arxiv.org/abs/2310.04867](http://arxiv.org/abs/2310.04867)

    该论文介绍了一种用于演化方程解决的神经Galerkin方案，通过随机化稀疏网络参数的更新来避免在时间上过拟合并降低计算成本。

    

    在时间上顺序地训练神经网络来近似解决含有时间依赖的偏微分方程可以帮助保持因果性和其他物理属性；然而，时间上的顺序训练在数值上具有挑战性，因为训练误差会随着时间快速积累和放大。本研究引入了神经Galerkin方案，该方案在每个时间步骤上更新随机稀疏的网络参数子集。随机化避免了在时间上过度拟合，并帮助防止误差在时间上的快速累积，这受到dropout的启发，dropout解决了由于神经元协同适应而导致的过拟合问题。更新的稀疏性降低了训练的计算成本，并且不会丧失表达能力，因为在每个时间步骤上许多网络参数是多余的。在广泛的演化方程的数值实验中，采用了随机稀疏方案。

    Training neural networks sequentially in time to approximate solution fields of time-dependent partial differential equations can be beneficial for preserving causality and other physics properties; however, the sequential-in-time training is numerically challenging because training errors quickly accumulate and amplify over time. This work introduces Neural Galerkin schemes that update randomized sparse subsets of network parameters at each time step. The randomization avoids overfitting locally in time and so helps prevent the error from accumulating quickly over the sequential-in-time training, which is motivated by dropout that addresses a similar issue of overfitting due to neuron co-adaptation. The sparsity of the update reduces the computational costs of training without losing expressiveness because many of the network parameters are redundant locally at each time step. In numerical experiments with a wide range of evolution equations, the proposed scheme with randomized sparse
    
[^35]: 通过区分位置和上下文来揭示Transformers中的隐藏几何

    Uncovering hidden geometry in Transformers via disentangling position and context. (arXiv:2310.04861v1 [cs.LG])

    [http://arxiv.org/abs/2310.04861](http://arxiv.org/abs/2310.04861)

    本文通过分解transformer的隐藏状态，揭示了其在语义理解中的隐含几何结构。

    

    Transformers广泛用于从输入令牌中提取复杂的语义意义，然而它们通常作为黑盒模型运行。本文提出了一种简单而信息丰富的方法，将训练好的transformer的隐藏状态（或嵌入）分解为可解释的组件。对于任何层，输入序列样本的嵌入向量由一个张量表示 $\boldsymbol{h} \in \mathbb{R}^{C \times T \times d}$。给定在序列（或上下文） $c \le C$ 的位置 $t \le T$ 处的嵌入向量 $\boldsymbol{h}_{c,t} \in \mathbb{R}^d$，提取均值效果得到分解形式 \[ \boldsymbol{h}_{c,t} = \boldsymbol{\mu} + \mathbf{pos}_t + \mathbf{ctx}_c + \mathbf{resid}_{c,t} \] 其中 $\boldsymbol{\mu}$ 是全局均值向量，$\mathbf{pos}_t$ 和 $\mathbf{ctx}_c$ 分别是跨上下文和跨位置的均值向量，$\mathbf{resid}_{c,t}$ 是残余向量。针对流行的transformer架构和多样的文本数据集，经验结果表明...

    Transformers are widely used to extract complex semantic meanings from input tokens, yet they usually operate as black-box models. In this paper, we present a simple yet informative decomposition of hidden states (or embeddings) of trained transformers into interpretable components. For any layer, embedding vectors of input sequence samples are represented by a tensor $\boldsymbol{h} \in \mathbb{R}^{C \times T \times d}$. Given embedding vector $\boldsymbol{h}_{c,t} \in \mathbb{R}^d$ at sequence position $t \le T$ in a sequence (or context) $c \le C$, extracting the mean effects yields the decomposition \[ \boldsymbol{h}_{c,t} = \boldsymbol{\mu} + \mathbf{pos}_t + \mathbf{ctx}_c + \mathbf{resid}_{c,t} \] where $\boldsymbol{\mu}$ is the global mean vector, $\mathbf{pos}_t$ and $\mathbf{ctx}_c$ are the mean vectors across contexts and across positions respectively, and $\mathbf{resid}_{c,t}$ is the residual vector. For popular transformer architectures and diverse text datasets, empirica
    
[^36]: 通用图随机特征

    Universal Graph Random Features. (arXiv:2310.04859v1 [stat.ML])

    [http://arxiv.org/abs/2310.04859](http://arxiv.org/abs/2310.04859)

    本文提出了一种新的准蒙特卡罗机制，称为排斥随机游走，通过改进图的采样，提高了统计估计器的集中度。该机制在估计图内核、PageRank向量和图形浓度等方面展示了有效性。

    

    我们提出了一种新颖的准蒙特卡罗机制，称为排斥随机游走，以改进基于图的采样。通过在相互作用集合的轨迹之间引入相关性，使它们的边际转移概率保持不变，我们能够更高效地探索图形，提高统计估计器的集中度，同时保持它们的无偏性。该机制可以轻松地实现。我们展示了在估计图内核、PageRank向量和图形浓度等各种情况下，排斥随机游走的有效性。我们提供了详细的实验评估和鲁棒的理论保证。据我们所知，排斥随机游走是第一个在图上相关步行者方向进行严格研究的准蒙特卡罗方案，为这个令人兴奋的新兴领域带来了新的研究。

    We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain.
    
[^37]: 抵制随机游走

    Repelling Random Walks. (arXiv:2310.04854v1 [stat.ML])

    [http://arxiv.org/abs/2310.04854](http://arxiv.org/abs/2310.04854)

    抵制随机游走是一种新的准蒙特卡罗机制，通过在图上的行走者之间引入相关性，能够更高效地探索图并提高统计估计的集中度，同时保持其无偏性。此机制在估计图核、PageRank向量和图元浓度等多个领域都展示了其有效性，并提供了详细的实验评估和理论保证。

    

    我们提出了一种新的准蒙特卡罗机制来改进基于图的抽样，称为抵制随机游走。通过在一个相互作用的集合中的轨迹之间引入相关性，使它们的边际转移概率保持不变，我们能够更有效地探索图，提高统计估计器的集中度，同时保持其无偏性。这个机制有一个简单的插入实现方式。我们展示了抵制随机游走在一系列设置中的有效性，包括图核的估计、PageRank向量和图元浓度。我们提供了详细的实验评估和稳健的理论保证。据我们所知，抵制随机游走是首个在图上相关行走方向的准蒙特卡罗方案进行了严谨研究，为这个令人兴奋的新兴领域开展新的研究提供了契机。

    We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain.
    
[^38]: 多源域自适应的子空间识别

    Subspace Identification for Multi-Source Domain Adaptation. (arXiv:2310.04723v1 [cs.LG])

    [http://arxiv.org/abs/2310.04723](http://arxiv.org/abs/2310.04723)

    该论文提出了一个基于子空间识别理论的多源域自适应方法，通过最小化域之间的偏移对不变变量的影响，实现了源域的知识转移到目标域。该方法相对于现有方法更加灵活，不需要满足严格的假设条件。

    

    多源域自适应（MSDA）方法旨在将多个有标签的源域的知识转移到一个无标签的目标域中。尽管当前的方法通过在域之间施加最小的变化来实现目标联合分布的可辨识性，但它们通常需要严格的条件，如足够数量的域、潜在变量的单调变换和不变的标签分布。这些要求在实际应用中很难满足。为了减轻对这些严格假设的需求，我们提出了一个子空间识别理论，它在关于域数量和变换特性方面具有较宽松的约束条件，从而通过最小化域之间的偏移对不变变量的影响来促进域自适应。基于这个理论，我们开发了一个利用变分推断的子空间识别保证（SIG）模型。

    Multi-source domain adaptation (MSDA) methods aim to transfer knowledge from multiple labeled source domains to an unlabeled target domain. Although current methods achieve target joint distribution identifiability by enforcing minimal changes across domains, they often necessitate stringent conditions, such as an adequate number of domains, monotonic transformation of latent variables, and invariant label distributions. These requirements are challenging to satisfy in real-world applications. To mitigate the need for these strict assumptions, we propose a subspace identification theory that guarantees the disentanglement of domain-invariant and domain-specific variables under less restrictive constraints regarding domain numbers and transformation properties, thereby facilitating domain adaptation by minimizing the impact of domain shifts on invariant variables. Based on this theory, we develop a Subspace Identification Guarantee (SIG) model that leverages variational inference. Furth
    
[^39]: 具有不可靠源数据的鲁棒性迁移学习

    Robust Transfer Learning with Unreliable Source Data. (arXiv:2310.04606v1 [stat.ML])

    [http://arxiv.org/abs/2310.04606](http://arxiv.org/abs/2310.04606)

    本文提出了一个新的鲁棒性迁移学习方法TAB模型，通过衡量目标与源回归函数之间的模糊度水平来改善分类任务，并避免负迁移。通过实验验证，TAB模型在非参数分类和逻辑回归任务上表现出了优越的性能。

    

    本文针对鲁棒性迁移学习中的贝叶斯分类器的模糊性和目标与源分布之间的弱可转移信号所带来的挑战进行了研究。我们引入了一种新的量，称为“模糊度水平”，用于衡量目标与源回归函数之间的差异，并提出了一种简单的迁移学习方法，并建立了一个一般定理，说明了这个新量与学习的迁移性在风险改善方面的关系。我们提出的“边界周围转移”(Transfer Around Boundary, TAB)模型通过在目标数据和源数据性能之间进行平衡的阈值，既高效又鲁棒，能够改善分类并避免负迁移。此外，我们还展示了TAB模型在非参数分类和逻辑回归任务上的有效性，达到了最优的上界，只有对数因子的差距。通过仿真研究进一步支持了TAB的有效性。

    This paper addresses challenges in robust transfer learning stemming from ambiguity in Bayes classifiers and weak transferable signals between the target and source distribution. We introduce a novel quantity called the ''ambiguity level'' that measures the discrepancy between the target and source regression functions, propose a simple transfer learning procedure, and establish a general theorem that shows how this new quantity is related to the transferability of learning in terms of risk improvements. Our proposed ''Transfer Around Boundary'' (TAB) model, with a threshold balancing the performance of target and source data, is shown to be both efficient and robust, improving classification while avoiding negative transfer. Moreover, we demonstrate the effectiveness of the TAB model on non-parametric classification and logistic regression tasks, achieving upper bounds which are optimal up to logarithmic factors. Simulation studies lend further support to the effectiveness of TAB. We 
    
[^40]: TNDDR: 高效且双重鲁棒的COVID-19疫苗有效性估计在阴性测试设计下

    TNDDR: Efficient and doubly robust estimation of COVID-19 vaccine effectiveness under the test-negative design. (arXiv:2310.04578v1 [stat.ME])

    [http://arxiv.org/abs/2310.04578](http://arxiv.org/abs/2310.04578)

    我们提出了一种高效且双重鲁棒的估计器TNDDR，用于在阴性测试设计下估计COVID-19疫苗的有效性，可有效解决选择偏差问题，并结合机器学习技术进行辅助函数估计。

    

    尽管阴性测试设计（TND）常用于监测季节性流感疫苗有效性（VE），但最近已成为COVID-19疫苗监测的重要组成部分，但由于结果相关抽样，它容易受到选择偏差的影响。一些研究已经解决了TND下因果参数的可鉴别性和估计问题，但尚未研究非参数估计器在无混杂性假设下的效率边界。我们提出了一种称为TNDDR（TND双重鲁棒）的一步双重鲁棒和局部高效估计器,它利用样本分割，并可以结合机器学习技术来估计辅助函数。我们推导了结果边际期望的高效影响函数（EIF），探索了von Mises展开，并建立了TNDDR的n的平方根一致性、渐近正态性和双重鲁棒性的条件。

    While the test-negative design (TND), which is routinely used for monitoring seasonal flu vaccine effectiveness (VE), has recently become integral to COVID-19 vaccine surveillance, it is susceptible to selection bias due to outcome-dependent sampling. Some studies have addressed the identifiability and estimation of causal parameters under the TND, but efficiency bounds for nonparametric estimators of the target parameter under the unconfoundedness assumption have not yet been investigated. We propose a one-step doubly robust and locally efficient estimator called TNDDR (TND doubly robust), which utilizes sample splitting and can incorporate machine learning techniques to estimate the nuisance functions. We derive the efficient influence function (EIF) for the marginal expectation of the outcome under a vaccination intervention, explore the von Mises expansion, and establish the conditions for $\sqrt{n}-$consistency, asymptotic normality and double robustness of TNDDR. The proposed TND
    
[^41]: 风险因素聚合和压力测试

    Risk factor aggregation and stress testing. (arXiv:2310.04511v1 [q-fin.RM])

    [http://arxiv.org/abs/2310.04511](http://arxiv.org/abs/2310.04511)

    本论文介绍了一种在压力测试中应用无监督学习的降维技术的方法，通过主成分分析和自编码器扩展了风险因素的范围，并提供了潜在因子的解释。这种方法对于其他需要降维和可解释性的领域也有用处。

    

    压力测试是将不利的金融或宏观经济情景应用于投资组合。为此，通过因子模型通常将金融或宏观经济风险因素与资产收益相关联。我们通过从无监督学习中采用降维技术，即主成分分析和自编码器，扩展了风险因素的范围。这导致了聚合的风险因素，包括全球因子、代表广泛地理区域的因子以及代表周期性和防御性行业的因子。由于适应的主成分分析和自编码器对潜在因子进行了解释，因此该方法在其他需要降维和可解释性的领域也具有价值。

    Stress testing refers to the application of adverse financial or macroeconomic scenarios to a portfolio. For this purpose, financial or macroeconomic risk factors are linked with asset returns, typically via a factor model. We expand the range of risk factors by adapting dimension-reduction techniques from unsupervised learning, namely PCA and autoencoders. This results in aggregated risk factors, encompassing a global factor, factors representing broad geographical regions, and factors specific to cyclical and defensive industries. As the adapted PCA and autoencoders provide an interpretation of the latent factors, this methodology is also valuable in other areas where dimension-reduction and explainability are crucial.
    
[^42]: 同时降维：一种数据高效的多模态表示学习方法

    Simultaneous Dimensionality Reduction: A Data Efficient Approach for Multimodal Representations Learning. (arXiv:2310.04458v1 [stat.ML])

    [http://arxiv.org/abs/2310.04458](http://arxiv.org/abs/2310.04458)

    该论文介绍了一种数据高效的多模态表示学习方法，探索了独立降维和同时降维两种方法，并通过生成线性模型评估了其相对准确性和数据集大小要求。

    

    本文探索了两种主要的降维方法：独立降维(IDR)和同时降维(SDR)。在IDR方法中，每个模态都被独立压缩，力图保留每个模态内的尽可能多的变化。相反，在SDR中，同时压缩模态以最大化减少描述之间的协变性，同时对保留单个变化的程度不太关注。典型的例子包括偏最小二乘法和典型相关分析。虽然这些降维方法是统计学的主要方法，但它们的相对精度和数据集大小要求尚不清楚。我们引入了一个生成线性模型来合成具有已知方差和协方差结构的多模态数据，以研究这些问题。我们评估了协方差的重构准确性。

    We explore two primary classes of approaches to dimensionality reduction (DR): Independent Dimensionality Reduction (IDR) and Simultaneous Dimensionality Reduction (SDR). In IDR methods, of which Principal Components Analysis is a paradigmatic example, each modality is compressed independently, striving to retain as much variation within each modality as possible. In contrast, in SDR, one simultaneously compresses the modalities to maximize the covariation between the reduced descriptions while paying less attention to how much individual variation is preserved. Paradigmatic examples include Partial Least Squares and Canonical Correlations Analysis. Even though these DR methods are a staple of statistics, their relative accuracy and data set size requirements are poorly understood. We introduce a generative linear model to synthesize multimodal data with known variance and covariance structures to examine these questions. We assess the accuracy of the reconstruction of the covariance s
    
[^43]: 扩散随机特征模型

    Diffusion Random Feature Model. (arXiv:2310.04417v1 [stat.ML])

    [http://arxiv.org/abs/2310.04417](http://arxiv.org/abs/2310.04417)

    本研究提出了一种以扩散模型为灵感的深度随机特征模型，它具有可解释性并可在数量相同的可训练参数下与全连接神经网络提供可比较的数值结果。通过推导得分匹配的属性，我们扩展了现有随机特征结果，并得出了样本数据分布与真实分布之间的泛化边界。

    

    扩散概率模型已成功用于生成从噪声中产生的数据。然而，大多数扩散模型计算成本高昂，难以解释，缺乏理论依据。另一方面，由于其可解释性，随机特征模型变得越来越受欢迎，但其在复杂机器学习任务中的应用仍然有限。在本工作中，我们提出了一种受扩散模型启发的深度随机特征模型，它既具有可解释性，又能给出与具有相同可训练参数数量的全连接神经网络相当的数值结果。具体而言，我们扩展了现有的随机特征结果，利用得分匹配的属性导出了样本数据分布与真实分布之间的泛化边界。我们通过在时尚MNIST数据集和乐器音频数据上生成样本来验证我们的发现。

    Diffusion probabilistic models have been successfully used to generate data from noise. However, most diffusion models are computationally expensive and difficult to interpret with a lack of theoretical justification. Random feature models on the other hand have gained popularity due to their interpretability but their application to complex machine learning tasks remains limited. In this work, we present a diffusion model-inspired deep random feature model that is interpretable and gives comparable numerical results to a fully connected neural network having the same number of trainable parameters. Specifically, we extend existing results for random features and derive generalization bounds between the distribution of sampled data and the true distribution using properties of score matching. We validate our findings by generating samples on the fashion MNIST dataset and instrumental audio data.
    
[^44]: 一个大规模市场价格异常检测系统

    A Marketplace Price Anomaly Detection System at Scale. (arXiv:2310.04367v1 [stat.ML])

    [http://arxiv.org/abs/2310.04367](http://arxiv.org/abs/2310.04367)

    MoatPlus是一个可扩展的价格异常检测框架，通过利用无监督统计特征和历史价格趋势生成上限价格边界，以解决在线市场中的数据质量和错误价格发布的问题。

    

    在线市场每天在平台上执行大量的价格更新，这些更新由个体市场卖家发起。这种价格民主化随着数据质量的挑战而增加。相对于传统的在线零售商，缺乏集中的防护措施会导致更高的错误价格在网站上发布，从而给顾客体验带来差评和潜在的收入损失。我们提出了MoatPlus（使用树、基于邻近度的标签以及无监督统计特征的蒙面最优锚点），这是一个用于不断增长的市场平台的可扩展价格异常检测框架。目标是利用邻近度和历史价格趋势的无监督统计特征来生成上限价格边界。我们构建了一个模型集合来检测基于价格的特征中的异常情况，排除异常特征，并使用优化的加权方案来构建实时定价管道中可靠的价格边界。

    Online marketplaces execute large volume of price updates that are initiated by individual marketplace sellers each day on the platform. This price democratization comes with increasing challenges with data quality. Lack of centralized guardrails that are available for a traditional online retailer causes a higher likelihood for inaccurate prices to get published on the website, leading to poor customer experience and potential for revenue loss. We present MoatPlus (Masked Optimal Anchors using Trees, Proximity-based Labeling and Unsupervised Statistical-features), a scalable price anomaly detection framework for a growing marketplace platform. The goal is to leverage proximity and historical price trends from unsupervised statistical features to generate an upper price bound. We build an ensemble of models to detect irregularities in price-based features, exclude irregular features and use optimized weighting scheme to build a reliable price bound in real-time pricing pipeline. We obs
    
[^45]: 通过类似样本聚类学习：对模型泛化的精确分析

    Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization. (arXiv:2310.04015v1 [cs.LG])

    [http://arxiv.org/abs/2310.04015](http://arxiv.org/abs/2310.04015)

    本文提出了一种名为“类似样本聚类”的技术，通过替换个体的敏感特征为聚类的平均值来增强隐私。通过对使用匿名聚类中心训练模型的精确分析，我们揭示了不同模型组成部分对泛化误差的影响，并证明在某些高维情况下，使用匿名聚类中心进行训练可以取得更好的效果。

    

    尽管个性化推荐系统变得越来越流行，但确保用户数据的保护仍然是这些学习系统开发中的一个重要关注点。增强隐私的常见方法是使用匿名数据而不是个体数据来训练模型。在本文中，我们探索了一种名为“类似样本聚类”的自然技术，它涉及将个体的敏感特征替换为聚类的平均值。我们对使用匿名聚类中心训练模型如何影响其泛化能力进行了精确的分析。我们关注一个渐近情况，即训练集的大小与特征维度成比例增长。我们的分析基于凸高斯极小化极大定理（Convex Gaussian Minimax Theorem，CGMT），使我们能够在理论上理解不同模型组成部分对泛化误差的作用。此外，我们证明在某些高维情况下，通过匿名聚类中心进行训练能够取得更好的效果。

    While personalized recommendations systems have become increasingly popular, ensuring user data protection remains a paramount concern in the development of these learning systems. A common approach to enhancing privacy involves training models using anonymous data rather than individual data. In this paper, we explore a natural technique called \emph{look-alike clustering}, which involves replacing sensitive features of individuals with the cluster's average values. We provide a precise analysis of how training models using anonymous cluster centers affects their generalization capabilities. We focus on an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT) and allows us to theoretically understand the role of different model components on the generalization error. In addition, we demonstrate that in certain high-dimensional regimes, training over anonymous cluster cente
    
[^46]: 通过退火来估计归一化常数的可证明的益处：重要性抽样，噪声对比估计，以及更多

    Provable benefits of annealing for estimating normalizing constants: Importance Sampling, Noise-Contrastive Estimation, and beyond. (arXiv:2310.03902v1 [stat.ML])

    [http://arxiv.org/abs/2310.03902](http://arxiv.org/abs/2310.03902)

    这篇论文研究了使用退火方法估计归一化常数的蒙特卡洛方法。通过评估不同设计选择对估计误差的影响，结果表明使用退火噪声对比估计器更有效，并且使用几何路径可以降低估计误差。

    

    最近的研究发展了几种蒙特卡洛方法来估计归一化常数（配分函数），这些方法基于退火的思想。即从可计算的“提议”分布和未归一化的“目标”分布之间的路径逐步采样。这些家族中的重要估计器包括退火重要性抽样和退火噪声对比估计（NCE）。这样的方法依赖于许多设计选择：使用哪个估计器、使用哪个分布路径以及是否使用分布路径；到目前为止，对于哪些选择是有效的还没有明确的理论。在这里，我们通过产生的渐近估计误差来评估每个设计选择。首先，我们证明了使用NCE比重要性抽样估计器更有效，但在无限小的路径步长的极限下，差异消失了。第二，我们发现使用几何路径将估计误差从指数级降低到...

    Recent research has developed several Monte Carlo methods for estimating the normalization constant (partition function) based on the idea of annealing. This means sampling successively from a path of distributions that interpolate between a tractable "proposal" distribution and the unnormalized "target" distribution. Prominent estimators in this family include annealed importance sampling and annealed noise-contrastive estimation (NCE). Such methods hinge on a number of design choices: which estimator to use, which path of distributions to use and whether to use a path at all; so far, there is no definitive theory on which choices are efficient. Here, we evaluate each design choice by the asymptotic estimation error it produces. First, we show that using NCE is more efficient than the importance sampling estimator, but in the limit of infinitesimal path steps, the difference vanishes. Second, we find that using the geometric path brings down the estimation error from an exponential to
    
[^47]: 非线性生成式压缩感知中统一信号恢复框架

    A Unified Framework for Uniform Signal Recovery in Nonlinear Generative Compressed Sensing. (arXiv:2310.03758v1 [eess.SP])

    [http://arxiv.org/abs/2310.03758](http://arxiv.org/abs/2310.03758)

    该论文提出了一个统一的框架，用于在非线性生成式压缩感知中实现统一的信号恢复。该框架适用于非线性和可能非连续或未知的观测模型，并且可以恢复生成模型中所有可能的信号。

    

    在生成式压缩感知中，我们希望使用生成先验从m个测量中（m≪n）恢复一个信号x∗∈Rn，其中G通常是一个L-Lipschitz连续的生成模型，B2k(r)表示Rk中的半径为r的ℓ2球。在非线性测量下，大多数先前的结果是非均匀的，即它们对于固定的x∗具有高概率，而不是对于所有的x∗同时成立。本文建立了一个统一的框架来推导非线性生成式压缩感知中的均匀恢复保证，并且适用于非线性和可能非连续或未知的观测模型。我们的框架包括了1位/均匀量化观测和单索引模型作为规范示例。具体来说，使用感知集合的单个实现和广义Lasso，所有的x∗∈G(B2k(r))可以恢复到一个el

    In generative compressed sensing (GCS), we want to recover a signal $\mathbf{x}^* \in \mathbb{R}^n$ from $m$ measurements ($m\ll n$) using a generative prior $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$, where $G$ is typically an $L$-Lipschitz continuous generative model and $\mathbb{B}_2^k(r)$ represents the radius-$r$ $\ell_2$-ball in $\mathbb{R}^k$. Under nonlinear measurements, most prior results are non-uniform, i.e., they hold with high probability for a fixed $\mathbf{x}^*$ rather than for all $\mathbf{x}^*$ simultaneously. In this paper, we build a unified framework to derive uniform recovery guarantees for nonlinear GCS where the observation model is nonlinear and possibly discontinuous or unknown. Our framework accommodates GCS with 1-bit/uniformly quantized observations and single index models as canonical examples. Specifically, using a single realization of the sensing ensemble and generalized Lasso, {\em all} $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$ can be recovered up to an $\el
    
[^48]: 未知方差下的高斯均值的任意有效T检验和置信序列

    Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])

    [http://arxiv.org/abs/2310.03722](http://arxiv.org/abs/2310.03722)

    本文提出了两种新的“e-process”和置信序列方法，分别通过替换Lai的混合方法，并分析了所得结果的宽度。

    

    在1976年，Lai构造了一个非平凡的均值$\mu$的高斯分布的置信序列，该分布的方差$\sigma$是未知的。他使用了关于$\sigma$的不适当（右Haar）混合和关于$\mu$的不适当（平坦）混合。在本文中，我们详细说明了他构建的细节，其中使用了广义的不可积分鞅和扩展的维尔不等式。尽管这确实产生了一个顺序T检验，但由于他的鞅不可积分，它并没有产生一个“e-process”。在本文中，我们为相同的设置开发了两个新的“e-process”和置信序列：一个是在缩减滤波器中的测试鞅，另一个是在规范数据滤波器中的“e-process”。这些分别是通过将Lai的平坦混合替换为高斯混合，并将对$\sigma$的右Haar混合替换为在零空间下的最大似然估计，就像在通用推断中一样。我们还分析了所得结果的宽度。

    In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an ``e-process'' (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting 
    
[^49]: 通过弱分布不变性实现多领域因果表示学习

    Multi-Domain Causal Representation Learning via Weak Distributional Invariances. (arXiv:2310.02854v1 [cs.LG])

    [http://arxiv.org/abs/2310.02854](http://arxiv.org/abs/2310.02854)

    本文提出了一种通过弱分布不变性进行多领域因果表示学习的方法，证明了融入这种不变性的自编码器能够可靠地识别出稳定的变量集合。

    

    因果表示学习已成为因果机器学习研究的核心。特别是，多领域数据集为展示因果表示学习相对于标准无监督表示学习的优势提供了自然机会。虽然最近的研究在学习因果表示方面取得了重要进展，但由于过于简化数据的假设，它们往往不能适用于多领域数据集；例如，每个领域都来自不同的单节点完美干预。在本文中，我们放宽了这些假设，并利用以下观察结果：在多领域数据中，往往存在一部分潜变量的某些分布属性（例如支持度、方差）在不同领域之间保持稳定；当每个领域来自多节点不完美干预时，这个属性成立。利用这个观察结果，我们证明了融入这种不变性的自编码器能够可靠地识别出稳定的变量集合。

    Causal representation learning has emerged as the center of action in causal machine learning research. In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning. While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention. In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention. Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set o
    
[^50]: 过参数化如何减缓矩阵感知中的梯度下降：对称性和初始化的问题。

    How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization. (arXiv:2310.01769v1 [cs.LG])

    [http://arxiv.org/abs/2310.01769](http://arxiv.org/abs/2310.01769)

    该论文研究了过参数化如何影响矩阵感知问题中梯度下降的收敛行为，在对称和非对称设置下给出了不同的收敛速度。

    

    本文详细阐述了过参数化如何改变梯度下降在矩阵感知问题中的收敛行为。在对称设置中，通过对称参数化学习未知的半正定矩阵，我们给出了过参数化情况下（$k>r$）随机初始化梯度下降的新型$\Omega (1/T^2)$下界，与精确参数化情况（$k=r$）的收敛速度$\exp (-\Omega (T))$形成鲜明对比。接下来，我们研究了不对称设置，其中$M^* \in \mathbb{R}^{n_1 \times n_2}$是未知矩阵，采用非对称参数化学习。

    This paper rigorously shows how over-parameterization changes the convergence behaviors of gradient descent (GD) for the matrix sensing problem, where the goal is to recover an unknown low-rank ground-truth matrix from near-isotropic linear measurements. First, we consider the symmetric setting with the symmetric parameterization where $M^* \in \mathbb{R}^{n \times n}$ is a positive semi-definite unknown matrix of rank $r \ll n$, and one uses a symmetric parameterization $XX^\top$ to learn $M^*$. Here $X \in \mathbb{R}^{n \times k}$ with $k > r$ is the factor matrix. We give a novel $\Omega (1/T^2)$ lower bound of randomly initialized GD for the over-parameterized case ($k >r$) where $T$ is the number of iterations. This is in stark contrast to the exact-parameterization scenario ($k=r$) where the convergence rate is $\exp (-\Omega (T))$. Next, we study asymmetric setting where $M^* \in \mathbb{R}^{n_1 \times n_2}$ is the unknown matrix of rank $r \ll \min\{n_1,n_2\}$, and one uses an 
    
[^51]: 稀疏变分高斯过程回归的点估计和不确定性量化与布朗运动先验的研究

    Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior. (arXiv:2310.00097v1 [math.ST])

    [http://arxiv.org/abs/2310.00097](http://arxiv.org/abs/2310.00097)

    本文研究了稀疏变分高斯过程回归中点估计和不确定性量化的方法，通过使用布朗运动先验和特征向量引导变量，推导了频率派可信区间的理论保证和限制，并在足够多的引导变量的情况下精确定义了渐近频率派覆盖，从而推断出这个变分方法的可信区间何时保守，何时过于自信/误导。数值实验证明了这些结果的适用性，并讨论了与其他常见高斯过程先验的相关性。

    

    本文研究了使用特征向量引导变量的稀疏变分高斯过程方法的点估计和不确定性量化。对于具有重标定布朗运动先验的情况，我们推导了点化可信区间的频率派大小和覆盖的理论保证和限制。通过充分的引导变量，我们精确地描述了渐近频率派覆盖，推断了这个变分方法的可信区间何时保守，何时过于自信/误导。我们通过数值实验说明了我们的结果的适用性，并讨论了与其他常见高斯过程先验的联系。

    We study pointwise estimation and uncertainty quantification for a sparse variational Gaussian process method with eigenvector inducing variables. For a rescaled Brownian motion prior, we derive theoretical guarantees and limitations for the frequentist size and coverage of pointwise credible sets. For sufficiently many inducing variables, we precisely characterize the asymptotic frequentist coverage, deducing when credible sets from this variational method are conservative and when overconfident/misleading. We numerically illustrate the applicability of our results and discuss connections with other common Gaussian process priors.
    
[^52]: 机器学习和神经网络方法在水质预测中的应用

    Water quality prediction using machine learning and neural network approaches. (arXiv:2309.16951v1 [stat.ML])

    [http://arxiv.org/abs/2309.16951](http://arxiv.org/abs/2309.16951)

    本研究通过比较线性回归、随机森林、XGBoost、LightGBM和MLP神经网络五种模型在佐治亚州预测水质pH值方面的效果，发现LightGBM表现最好。基于树的模型在回归问题中优势显著，而MLP神经网络对特征缩放敏感。同时，本研究还探讨了与原研究相比，机器学习模型能够取得更好性能的原因。

    

    水资源是人类生计和经济进步的基础，与公共健康和环境福祉有着内在的联系。准确预测水质是改善水资源管理和对抗污染的关键因素。本研究采用多种性能指标，评估了五种不同模型（线性回归，随机森林，XGBoost，LightGBM和MLP神经网络）在美国佐治亚州预测pH值方面的效果。同时，LightGBM在所有模型中取得了最高的平均精度。基于树的模型凸显了它们在处理回归问题中的优势。此外，MLP神经网络的性能对特征缩放具有敏感性。我们还详细阐述并分析了机器学习模型在时间依赖性和空间考虑因素方面与原研究相比所取得的优越性能的原因。

    Water resources serve as the cornerstone of human livelihoods and economic progress, with intrinsic links to both public health and environmental well-being. The accurate prediction of water quality stands as a pivotal factor in enhancing water resource management and combating pollution. This research, employing diverse performance metrics, assesses the efficacy of five distinct models, namely, linear regression, Random Forest, XGBoost, LightGBM, and MLP neural network, in forecasting pH values within Georgia, USA. Concurrently, LightGBM attains the highest average precision among all models examined. Tree-based models underscore their supremacy in addressing regression challenges. Furthermore, the performance of MLP neural network is sensitive to feature scaling. Additionally, we expound upon and dissect the reasons behind the superior precision of the machine learning models when they are compared to the original study, which factors in time dependencies and spatial considerations. 
    
[^53]: TomOpt：在宇宙射线μ子断层扫描中面向任务和约束感知设计的微粒探测器的差分优化

    TomOpt: Differential optimisation for task- and constraint-aware design of particle detectors in the context of muon tomography. (arXiv:2309.14027v1 [physics.ins-det])

    [http://arxiv.org/abs/2309.14027](http://arxiv.org/abs/2309.14027)

    TomOpt是一个软件包，用于优化宇宙射线μ子断层扫描设计中的微粒探测器的几何布局和规格。它利用可微分编程模拟μ子与探测器和扫描体积的相互作用，并通过损失最小化的优化循环进行推断感知优化。

    

    我们描述了一个名为TomOpt的软件包，用于优化几何布局和探测器规格，以进行宇宙射线μ子的散射断层扫描设计。该软件利用可微分编程来模拟μ子与探测器和扫描体积的相互作用，推断体积属性，并进行损失最小化的优化循环。通过这样做，我们首次演示了粒子物理仪器的端到端可微分和推断感知优化。我们研究了该软件在相关基准场景上的性能，并讨论了其潜在应用。

    We describe a software package, TomOpt, developed to optimise the geometrical layout and specifications of detectors designed for tomography by scattering of cosmic-ray muons. The software exploits differentiable programming for the modeling of muon interactions with detectors and scanned volumes, the inference of volume properties, and the optimisation cycle performing the loss minimisation. In doing so, we provide the first demonstration of end-to-end-differentiable and inference-aware optimisation of particle physics instruments. We study the performance of the software on a relevant benchmark scenarios and discuss its potential applications.
    
[^54]: 动作状态相关的动态模型选择

    Action-State Dependent Dynamic Model Selection. (arXiv:2307.04754v1 [cs.LG])

    [http://arxiv.org/abs/2307.04754](http://arxiv.org/abs/2307.04754)

    本文提出了一种动态模型选择的方法，该方法能够根据不同的状态选择最优的模型，并通过强化学习算法对动态规划问题进行近似和估计。实验结果表明，在重新平衡成本下切换投资组合模型时，使用宏观经济信息的性能优于事后选择最佳投资组合模型。

    

    在世界的某些状态下，多个模型中的一个可能只在其中某些状态下表现最佳。而在模型之间的切换也可能代价高昂。在这种情况下，寻找一种能够动态选择模型的过程需要解决一个复杂的估计问题和动态规划问题。本文使用强化学习算法来从数据中近似和估计这个动态规划问题的最优解。实验结果表明，该算法能够一致地估计出根据一组协变量选择不同模型的最优策略。具体应用方面，例如在重新平衡成本下切换不同投资组合模型，使用宏观经济信息进行决策。通过一组宏观经济变量和价格数据，经验应用于上述投资组合问题表现出比事后选择最佳投资组合模型更优的性能。

    A model among many may only be best under certain states of the world. Switching from a model to another can also be costly. Finding a procedure to dynamically choose a model in these circumstances requires to solve a complex estimation procedure and a dynamic programming problem. A Reinforcement learning algorithm is used to approximate and estimate from the data the optimal solution to this dynamic programming problem. The algorithm is shown to consistently estimate the optimal policy that may choose different models based on a set of covariates. A typical example is the one of switching between different portfolio models under rebalancing costs, using macroeconomic information. Using a set of macroeconomic variables and price data, an empirical application to the aforementioned portfolio problem shows superior performance to choosing the best portfolio model with hindsight.
    
[^55]: 变分不平衡回归(Variational Imbalanced Regression)

    Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])

    [http://arxiv.org/abs/2306.06599](http://arxiv.org/abs/2306.06599)

    本文提出的变分不平衡回归（VIR）模型通过引入Probabilistic Reweighting方法，可以在不平衡回归方面表现良好，并自然产生合理的不确定性估计。

    

    当标签分布不平衡时，现有的回归模型往往在准确性和不确定性估计方面表现不佳。本文提出了一种概率深度学习模型——变分不平衡回归（VIR），它不仅在不平衡回归方面表现出色，而且自然地产生合理的不确定性估计。与典型的变分自编码器假设I.I.D.表示（数据点的表示不直接受其他数据点的影响）不同，我们的VIR借用具有类似回归标签的数据来计算潜在表示的变分分布；此外，不同于产生点估计的确定性回归模型， VIR预测整个正态反-伽玛分布并调节相关联的共轭分布，对不平衡数据施加概率重新加权，从而提供更好的不确定性估计。在几个真实世界的数据集上进行了实验。

    Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
    
[^56]: 生成可信的文本：大型语言模型的不确定性量化

    Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models. (arXiv:2305.19187v1 [cs.CL])

    [http://arxiv.org/abs/2305.19187](http://arxiv.org/abs/2305.19187)

    本研究提出应对大型语言模型可信度问题的方法，研究黑盒模型中置信度与不确定性量化，并将其应用于选择性自然语言生成。

    

    近期，专门用于自然语言生成的大型语言模型(LLMs)在各个领域表现出了很好的能力，但是评估LLMs生成的结果的可信度仍然是一个挑战，关于自然语言生成的不确定性量化的研究也较少。此外，现有的文献通常假定对语言模型的白盒访问，这要么是由于最新的LLMs的封闭源代码的性质，要么是由于计算限制。本文研究了黑盒LLMs的不确定性量化问题。我们首先区分了两种密切相关的概念: 只与输入有关的“不确定性”和还与生成的回复有关的“置信度”。然后我们提出并比较了几个置信度/不确定度指标，将它们应用于“选择性自然语言生成”，其中不可靠的结果可以被忽略或者移交给进一步的分析。

    Large language models (LLMs) specializing in natural language generation (NLG) have recently started exhibiting promising capabilities across a variety of domains. However, gauging the trustworthiness of responses generated by LLMs remains an open challenge, with limited research on uncertainty quantification for NLG. Furthermore, existing literature typically assumes white-box access to language models, which is becoming unrealistic either due to the closed-source nature of the latest LLMs or due to computational constraints. In this work, we investigate uncertainty quantification in NLG for $\textit{black-box}$ LLMs. We first differentiate two closely-related notions: $\textit{uncertainty}$, which depends only on the input, and $\textit{confidence}$, which additionally depends on the generated response. We then propose and compare several confidence/uncertainty metrics, applying them to $\textit{selective NLG}$, where unreliable results could either be ignored or yielded for further 
    
[^57]: 针对对抗性攻击的强健Lipschitz赌徒算法

    Robust Lipschitz Bandits to Adversarial Corruptions. (arXiv:2305.18543v1 [cs.LG])

    [http://arxiv.org/abs/2305.18543](http://arxiv.org/abs/2305.18543)

    本文提出的强健Lipschitz赌徒算法，能够在对抗性攻击的情况下实现次线性遗憾，并在强敌手情况下最优。

    

    Lipschitz赌徒算法是一种处理定义在度量空间上的连续臂集的随机赌徒算法的变体，其中奖励函数受到Lipschitz约束。本文介绍了一种新的Lipschitz赌徒问题，即在对抗性破坏存在的情况下，自适应敌手将随机奖励损坏到总预算 $C$。 预算通过时间跨度 $T$ 中的破坏水平之和来衡量。 我们考虑弱和强敌手，其中弱敌手在攻击之前不知道当前的行动，而强敌手可以观察行动。我们的工作提出了第一行强健Lipschitz赌徒算法，在两种类型的敌手下，甚至在损坏总预算 $C$ 未向代理披露的情况下，均能实现次线性遗憾。我们在每种类型的敌手下提供下限，并证明了我们的算法在强类型下是最优的。最后，我们进行实验以说明该算法的有效性。

    Lipschitz bandit is a variant of stochastic bandits that deals with a continuous arm set defined on a metric space, where the reward function is subject to a Lipschitz constraint. In this paper, we introduce a new problem of Lipschitz bandits in the presence of adversarial corruptions where an adaptive adversary corrupts the stochastic rewards up to a total budget $C$. The budget is measured by the sum of corruption levels across the time horizon $T$. We consider both weak and strong adversaries, where the weak adversary is unaware of the current action before the attack, while the strong one can observe it. Our work presents the first line of robust Lipschitz bandit algorithms that can achieve sub-linear regret under both types of adversary, even when the total budget of corruption $C$ is unrevealed to the agent. We provide a lower bound under each type of adversary, and show that our algorithm is optimal under the strong case. Finally, we conduct experiments to illustrate the effecti
    
[^58]: 利用GFlowNets解决图形组合优化问题

    Let the Flows Tell: Solving Graph Combinatorial Optimization Problems with GFlowNets. (arXiv:2305.17010v1 [cs.LG])

    [http://arxiv.org/abs/2305.17010](http://arxiv.org/abs/2305.17010)

    本文提出了一种名为GFlowNets的机器，可以有效地解决组合优化问题，同时在训练方面进行了优化，结果表明其可以高效地找到高质量的解决方案。

    

    组合优化问题通常是NP难题，因此不适用于精确算法，这使它们成为应用机器学习方法的理想领域。这些问题中高度结构化的限制可能会直接阻碍优化或采样解决方案的空间。另一方面，GFlowNets最近被发现是一种强大的机器，可以顺序地从复合非规范化密度中有效地采样，并具有在CO中分摊此类解决方案搜索过程以及生成不同的解决方案候选项的潜力。在本文中，我们设计了适用于不同组合问题的马尔科夫决策过程（MDP），并提出训练有条件的GFlowNets从解空间中采样的策略。还开发了高效的训练技术来受益于远程信用分配。通过对各种使用合成和实际数据的不同CO任务的广泛实验，我们证明了GFlowNet策略可以有效地找到高质量的解。

    Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space. On the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates. In this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. Efficient training techniques are also developed to benefit long-range credit assignment. Through extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quali
    
[^59]: 核方法在算子学习中表现竞争力

    Kernel Methods are Competitive for Operator Learning. (arXiv:2304.13202v1 [stat.ML])

    [http://arxiv.org/abs/2304.13202](http://arxiv.org/abs/2304.13202)

    本文提出了一个核方法算子学习框架，在对多组数据进行全面比较后，结果表明该方法在多种设置下都是一种具有竞争力的算子学习方法。

    

    我们提出了一个基于核的算子学习框架，并提供了先验误差分析和与流行的神经网络方法（如Deep Operator Net（DeepONet）[Lu et al.]和Fourier神经算子（FNO）[Li et al.]）的全面数字比较。我们考虑目标算子$\mathcal{G}^\dagger:\mathcal{U}\to\mathcal{V}$的输入/输出空间是再生核希尔伯特空间（RKHS）的情况，数据以输入/输出函数的部分观测$\varphi(v_i),\phi(u_i)$的形式出现，其中$v_i=\mathcal{G}^\dagger(u_i)$（$i=1,\ldots,N$），测量算子$\varphi:\mathcal{V}\to\mathbb{R}^m$和$\phi:\mathcal{U}\to\mathbb{R}^n$是线性的。在写$\psi:\mathbb{R}^n\to\mathcal{U}$和$\chi:\mathbb{R}^m\to\mathcal{V}$作为与$\phi$和$\varphi$相关的最佳恢复映射时，我们使用$\bar{f}$ 核映射 $L^2(\mathcal{U},\mathbb{R}^n)$ 定义一个$k$ 类型的最小二乘模型， 然后用 $\bar{\mathcal{G}}=\chi\circ\bar{f}\circ\psi$ 来近似$\mathcal{G}^\dagger$。 我们的分析涉及多个例子，包括常见的偏微分方程的算子近似，结果表明在多种设置下核方法都是一种具有竞争力的算子学习方法。

    We present a general kernel-based framework for learning operators between Banach spaces along with a priori error analysis and comprehensive numerical comparisons with popular neural net (NN) approaches such as Deep Operator Net (DeepONet) [Lu et al.] and Fourier Neural Operator (FNO) [Li et al.]. We consider the setting where the input/output spaces of target operator $\mathcal{G}^\dagger\,:\, \mathcal{U}\to \mathcal{V}$ are reproducing kernel Hilbert spaces (RKHS), the data comes in the form of partial observations $\phi(u_i), \varphi(v_i)$ of input/output functions $v_i=\mathcal{G}^\dagger(u_i)$ ($i=1,\ldots,N$), and the measurement operators $\phi\,:\, \mathcal{U}\to \mathbb{R}^n$ and $\varphi\,:\, \mathcal{V} \to \mathbb{R}^m$ are linear. Writing $\psi\,:\, \mathbb{R}^n \to \mathcal{U}$ and $\chi\,:\, \mathbb{R}^m \to \mathcal{V}$ for the optimal recovery maps associated with $\phi$ and $\varphi$, we approximate $\mathcal{G}^\dagger$ with $\bar{\mathcal{G}}=\chi \circ \bar{f} \ci
    
[^60]: 基于编码器嵌入的协同图融合

    Synergistic Graph Fusion via Encoder Embedding. (arXiv:2303.18051v1 [cs.SI])

    [http://arxiv.org/abs/2303.18051](http://arxiv.org/abs/2303.18051)

    本文提出了一种协同图融合的新方法，该方法处理具有共同顶点集的多个图，有着非常理想的“协同效应”，即顶点分类准确度总是受益于额外的图，并在实验中证实了其卓越性能。

    

    本文提出了一种称为图融合编码器嵌入的多图嵌入新方法，该方法旨在处理具有共同顶点集的多个图。在监督学习设置下，我们证明了该方法展现出了令人惊叹但非常理想的“协同效应”：对于足够大的顶点数，分类准确度总是受益于额外的图。我们在随机块模型下提供了这种效应的数学证明，并确定了渐近完美分类的必要条件和充分条件。模拟和真实数据实验证实了所提出的方法的卓越性能，该方法在分类中始终优于最近的基准方法。

    In this paper, we introduce a novel approach to multi-graph embedding called graph fusion encoder embedding. The method is designed to work with multiple graphs that share a common vertex set. Under the supervised learning setting, we show that the resulting embedding exhibits a surprising yet highly desirable "synergistic effect": for sufficiently large vertex size, the vertex classification accuracy always benefits from additional graphs. We provide a mathematical proof of this effect under the stochastic block model, and identify the necessary and sufficient condition for asymptotically perfect classification. The simulations and real data experiments confirm the superiority of the proposed method, which consistently outperforms recent benchmark methods in classification.
    
[^61]: 训练数据重构的非渐进性下界

    Non-Asymptotic Lower Bounds For Training Data Reconstruction. (arXiv:2303.16372v1 [cs.LG])

    [http://arxiv.org/abs/2303.16372](http://arxiv.org/abs/2303.16372)

    本文通过研究差分隐私和度量隐私学习器在对抗者重构错误方面的鲁棒性，得出了非渐进性下界，覆盖了高维情况，且扩展了深度学习算法的隐私分析

    

    本文研究了专业对手进行训练数据重构攻击时私有学习算法的语义保证强度。我们通过导出非渐进量级下界来研究了满足差分隐私（DP）和度量隐私（mDP）的学习器对抗者重构错误的鲁棒性。此外，我们还证明了我们对mDP的分析覆盖了高维情况。本文进一步对流行的深度学习算法，如DP-SGD和Projected Noisy SGD进行了度量差分隐私的扩展隐私分析。

    We investigate semantic guarantees of private learning algorithms for their resilience to training Data Reconstruction Attacks (DRAs) by informed adversaries. To this end, we derive non-asymptotic minimax lower bounds on the adversary's reconstruction error against learners that satisfy differential privacy (DP) and metric differential privacy (mDP). Furthermore, we demonstrate that our lower bound analysis for the latter also covers the high dimensional regime, wherein, the input data dimensionality may be larger than the adversary's query budget. Motivated by the theoretical improvements conferred by metric DP, we extend the privacy analysis of popular deep learning algorithms such as DP-SGD and Projected Noisy SGD to cover the broader notion of metric differential privacy.
    
[^62]: 异质分布偏移下的统计学习

    Statistical Learning under Heterogenous Distribution Shift. (arXiv:2302.13934v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13934](http://arxiv.org/abs/2302.13934)

    本文研究了异质分布偏移下的统计学习问题，通过研究经验风险最小化(ERM)在不同类别的复杂性下的表现，我们发现当类别$F$相比类别$G$更“简单”时，我们的预测器对于协变量偏移具有更强的鲁棒性，尤其在$\textbf{y}$的偏移远小于$\textbf{x}$的情况下。同时，我们发现ERM的行为与正交机器学习具有类似的特性。

    

    本文研究了从随机变量对$(\mathbf{x},\mathbf{y})$中预测目标$\mathbf{z}$, 其中真实的预测器是加法的$\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$。我们研究了在给定训练分布上拟合的函数$f+g$, $f \in F$和$g \in G$上的经验风险最小化(ERM)在表现上的差异，但在测试分布上得到评估时会显示出协变量偏移。我们的研究表明，当类别$F$比$G$更“简单”（例如，以度量熵为衡量标准）时，我们的预测器对于协变量偏移的抗干扰能力更强，其中$\textbf{y}$的偏移要远小于$\textbf{x}$的偏移。我们的分析表明，ERM的行为与正交机器学习$\textbf{ qualitatively similarly}$：ERM恢复预测器中的$f$成分的速率仅对于类别$G$的复杂性具有较低阶的依赖性，调整后...

    This paper studies the prediction of a target $\mathbf{z}$ from a pair of random variables $(\mathbf{x},\mathbf{y})$, where the ground-truth predictor is additive $\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$. We study the performance of empirical risk minimization (ERM) over functions $f+g$, $f \in F$ and $g \in G$, fit on a given training distribution, but evaluated on a test distribution which exhibits covariate shift. We show that, when the class $F$ is "simpler" than $G$ (measured, e.g., in terms of its metric entropy), our predictor is more resilient to $\textbf{heterogenous covariate shifts}$ in which the shift in $\mathbf{x}$ is much greater than that in $\mathbf{y}$. Our analysis proceeds by demonstrating that ERM behaves $\textbf{qualitatively similarly to orthogonal machine learning}$: the rate at which ERM recovers the $f$-component of the predictor has only a lower-order dependence on the complexity of the class $G$, adjus
    
[^63]: 因果解缠的生成变分自动编码器

    Causally Disentangled Generative Variational AutoEncoder. (arXiv:2302.11737v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.11737](http://arxiv.org/abs/2302.11737)

    本研究提出了一种名为CDG的方法，通过对变分自动编码器进行监督学习，实现了同时学习因果解缠表示和生成因果解缠结果。通过探索特定模型下实现CDG的必要和充分条件，我们发现仅在编码器中加入监督正则化是不够的。此外，我们引入了一个通用度量来评估生成模型的因果解缠程度，并通过实证结果验证了我们的发现。

    

    我们提出了一种新的监督学习技术，用于变分自动编码器（VAE），使其能够同时学习因果解缠表示和生成因果解缠结果。我们将这种方法称为因果解缠生成（CDG）。CDG是一个生成模型，它可以根据因果解缠表示准确地解码输出。我们的研究表明，仅仅在编码器中加入监督正则化是无法实现具有CDG的生成模型的，即使对于一个简单的任务也是如此。因此，我们探讨了在特定模型中实现CDG所需的必要条件和充分条件。此外，我们引入了一个用于评估生成模型因果解缠程度的通用度量。来自图像和表格数据集的实证结果支持了我们的发现。

    We present a new supervised learning technique for the Variational AutoEncoder (VAE) that allows it to learn a causally disentangled representation and generate causally disentangled outcomes simultaneously. We call this approach Causally Disentangled Generation (CDG). CDG is a generative model that accurately decodes an output based on a causally disentangled representation. Our research demonstrates that adding supervised regularization to the encoder alone is insufficient for achieving a generative model with CDG, even for a simple task. Therefore, we explore the necessary and sufficient conditions for achieving CDG within a specific model. Additionally, we introduce a universal metric for evaluating the causal disentanglement of a generative model. Empirical results from both image and tabular datasets support our findings.
    
[^64]: 量子化的低秩多元回归与随机抖动

    Quantized Low-Rank Multivariate Regression with Random Dithering. (arXiv:2302.11197v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.11197](http://arxiv.org/abs/2302.11197)

    本文研究了量子化的低秩多元回归，通过采用均匀量化与随机抖动的方法，提出了约束Lasso和正则化Lasso估计器，实现了最小最优率的估计，同时量化仅对乘法因子略有影响。

    

    低秩多元回归（LRMR）是一种重要的统计学习模型，将高度相关的任务作为具有低秩先验的多响应回归问题进行组合。本文研究了量子化的LRMR，这是一种实际的设置，其中响应和/或协变量被离散化为有限的精度。我们专注于估计基础系数矩阵。为了使能够实现任意小误差的一致估计器成为可能，我们采用了均匀量化与随机抖动，即在量化之前向数据添加适当的随机噪声。具体而言，响应使用均匀抖动，协变量使用三角抖动。基于量化数据，我们提出了约束Lasso和正则化Lasso估计器，并推导了非渐近性误差界。通过抖动的帮助，估计器实现了最小最优率，而量化仅略微恶化了乘法因子。

    Low-rank multivariate regression (LRMR) is an important statistical learning model that combines highly correlated tasks as a multiresponse regression problem with low-rank priori on the coefficient matrix. In this paper, we study quantized LRMR, a practical setting where the responses and/or the covariates are discretized to finite precision. We focus on the estimation of the underlying coefficient matrix. To make consistent estimator that could achieve arbitrarily small error possible, we employ uniform quantization with random dithering, i.e., we add appropriate random noise to the data before quantization. Specifically, uniform dither and triangular dither are used for responses and covariates, respectively. Based on the quantized data, we propose the constrained Lasso and regularized Lasso estimators, and derive the non-asymptotic error bounds. With the aid of dithering, the estimators achieve minimax optimal rate, while quantization only slightly worsens the multiplicative factor
    
[^65]: 追求机器学习研究的推理复现性

    Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04054](http://arxiv.org/abs/2302.04054)

    本研究提出利用线性混合效应模型（LMEM）来分析机器学习性能评估分数，并考虑多个方差来源及其与数据特性相互作用，从而评估可靠性和可复制性，促进对机器学习算法行为的更全面理解。

    

    机器学习评估的可靠性——即在复制的模型训练运行中观察到的评估分数的一致性——受到几种非确定性来源的影响，可以被视为测量噪声。目前的趋势是去除噪声，以强制研究结果的可复制性，忽略了实现层面固有的非确定性以及算法噪声因素和数据特性之间的关键相互作用效应。这限制了从这些实验中可以得出的结论范围。我们提出的方法是将几个方差来源，包括它们与数据特性的相互作用，纳入机器学习评估的显著性和可靠性分析中，以期从训练模型的特定实例得出推理结论, 而非去除噪声。我们展示如何使用线性混合效应模型（LMEM）来分析性能评估分数，并用广义似然比检验进行统计推断。我们的方法提供了一种系统的方式来考虑算法和数据相关的噪声来源，并使我们能够量化各个方差来源对机器学习实验的可靠性和可复制性的影响。我们在一系列合成和真实数据集上演示了我们方法的实用性，并说明了我们的方法如何促进对机器学习算法行为的更全面理解。

    Reliability of machine learning evaluation -- the consistency of observed evaluation scores across replicated model training runs -- is affected by several sources of nondeterminism which can be regarded as measurement noise. Current tendencies to remove noise in order to enforce reproducibility of research results neglect inherent nondeterminism at the implementation level and disregard crucial interaction effects between algorithmic noise factors and data properties. This limits the scope of conclusions that can be drawn from such experiments. Instead of removing noise, we propose to incorporate several sources of variance, including their interaction with data properties, into an analysis of significance and reliability of machine learning evaluation, with the aim to draw inferences beyond particular instances of trained models. We show how to use linear mixed effects models (LMEMs) to analyze performance evaluation scores, and to conduct statistical inference with a generalized lik
    
[^66]: Simplex随机特征

    Simplex Random Features. (arXiv:2301.13856v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.13856](http://arxiv.org/abs/2301.13856)

    Simplex随机特征（SimRFs）是一种新的随机特征机制，通过几何相关性来无偏估计softmax和高斯核。在权重无关的几何相关正随机特征机制类中，SimRFs提供了最小可能的均方误差，并且在没有额外成本的情况下明显优于先前最准确的正交随机特征。在实证研究中，SimRFs在多个领域中表现出一致的收益。

    

    我们提出了Simplex随机特征（SimRFs），一种通过随机投影向量的几何相关性来无偏估计softmax和高斯核的新随机特征（RF）机制。我们证明了在无偏估计这些核的权重无关的几何相关正随机特征（PRF）机制类中，SimRFs提供了最小可能的均方误差（MSE），在没有观察到额外成本的情况下明显优于先前最准确的正交随机特征。我们提出了一个计算成本更高的SimRFs+变种，我们证明在更广泛的权重相关几何耦合方案族中（允许随机向量方向和范数之间的相关性），它是渐近优化的。在广泛的实证研究中，我们展示了SimRFs在包括逐点核估计、非参数分类和可扩展的Transformer中提供的一致收益。

    We present Simplex Random Features (SimRFs), a new random feature (RF) mechanism for unbiased approximation of the softmax and Gaussian kernels by geometrical correlation of random projection vectors. We prove that SimRFs provide the smallest possible mean square error (MSE) on unbiased estimates of these kernels among the class of weight-independent geometrically-coupled positive random feature (PRF) mechanisms, substantially outperforming the previously most accurate Orthogonal Random Features at no observable extra cost. We present a more computationally expensive SimRFs+ variant, which we prove is asymptotically optimal in the broader family of weight-dependent geometrical coupling schemes (which permit correlations between random vector directions and norms). In extensive empirical studies, we show consistent gains provided by SimRFs in settings including pointwise kernel estimation, nonparametric classification and scalable Transformers.
    
[^67]: 鲁棒的凸二聚类方法中使用了无需调参的方法

    Robust convex biclustering with a tuning-free method. (arXiv:2212.03122v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2212.03122](http://arxiv.org/abs/2212.03122)

    本文提出了一个鲁棒的凸二聚类算法，使用了无需调参的方法，该算法在面对重尾数据时表现出更好的性能。

    

    二聚类广泛应用于基因信息分析、文本挖掘和推荐系统等领域，通过有效地发现样本和特征之间的局部相关性。然而，许多二聚类算法在面对重尾数据时容易崩溃。本文提出了一个鲁棒的凸二聚类算法，使用了Huber损失函数。然而，新引入的鲁棒化参数会增加选择最佳参数的额外负担。因此，我们提出了一种无需调参的方法，实现自动选择最佳的鲁棒化参数，并具有高效性。模拟研究表明，我们提出的方法在面对重尾噪声时比传统的二聚类方法表现更好。同时，还提供了一个真实生物医学应用示例。R包RcvxBiclustr可在https://github.com/YifanChen3/RcvxBiclustr 上获取。

    Biclustering is widely used in different kinds of fields including gene information analysis, text mining, and recommendation system by effectively discovering the local correlation between samples and features. However, many biclustering algorithms will collapse when facing heavy-tailed data. In this paper, we propose a robust version of convex biclustering algorithm with Huber loss. Yet, the newly introduced robustification parameter brings an extra burden to selecting the optimal parameters. Therefore, we propose a tuning-free method for automatically selecting the optimal robustification parameter with high efficiency. The simulation study demonstrates the more fabulous performance of our proposed method than traditional biclustering methods when encountering heavy-tailed noise. A real-life biomedical application is also presented. The R package RcvxBiclustr is available at https://github.com/YifanChen3/RcvxBiclustr.
    
[^68]: 估计在被动设计下回归函数的极小值点和最小值

    Estimating the minimizer and the minimum value of a regression function under passive design. (arXiv:2211.16457v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2211.16457](http://arxiv.org/abs/2211.16457)

    本论文提出了一种方法，可以在带有随机噪声的观测中估计回归函数的极小值点和最小值。方法基于投影梯度下降和非参数过程，通过推导上界和建立最小化下界证明了方法的渐进最优性。

    

    我们提出了一种新的方法，用于从带有随机噪声的观测中估计一个平滑且强凸的回归函数$f$的极小值点$x^*$和最小值$f^*$。我们的估计器$z_n$基于一个投影梯度下降的版本，并使用通过正则化局部多项式算法估计的梯度。接下来，我们提出了一个两阶段的估计过程，用于估计回归函数$f$的最小值$f^*$。在第一阶段，我们构建了一个足够准确的$x^*$的估计器，可以是$z_n$。在第二阶段，我们使用一个速率最优的非参数过程来估计在第一阶段得到的点的函数值。我们推导了$z_n$的二次风险和优化误差的非渐进上界，以及估计$f^*$的风险的非渐进上界。我们建立了最小化下界，证明在某些选择下，这些上界是渐进最优的。

    We propose a new method for estimating the minimizer $\boldsymbol{x}^*$ and the minimum value $f^*$ of a smooth and strongly convex regression function $f$ from the observations contaminated by random noise. Our estimator $\boldsymbol{z}_n$ of the minimizer $\boldsymbol{x}^*$ is based on a version of the projected gradient descent with the gradient estimated by a regularized local polynomial algorithm. Next, we propose a two-stage procedure for estimation of the minimum value $f^*$ of regression function $f$. At the first stage, we construct an accurate enough estimator of $\boldsymbol{x}^*$, which can be, for example, $\boldsymbol{z}_n$. At the second stage, we estimate the function value at the point obtained in the first stage using a rate optimal nonparametric procedure. We derive non-asymptotic upper bounds for the quadratic risk and optimization error of $\boldsymbol{z}_n$, and for the risk of estimating $f^*$. We establish minimax lower bounds showing that, under certain choice 
    
[^69]: FaiREE：具有有限样本和无分布保证的公平分类算法

    FaiREE: Fair Classification with Finite-Sample and Distribution-Free Guarantee. (arXiv:2211.15072v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.15072](http://arxiv.org/abs/2211.15072)

    本研究提出了FaiREE算法，它是一种可满足群体公平性约束的公平分类算法，并且具有有限样本和无分布理论保证。在实验中表现优异。

    

    算法公平性在机器学习研究中发挥着越来越重要的作用。已经提出了几种群体公平性概念和算法。然而，现有公平分类方法的公平保证主要依赖于特定的数据分布假设，通常需要大样本量，并且在样本量较小的情况下可能会违反公平性，而这在实践中经常发生。本文提出了FaiREE算法，它是一种公平分类算法，可以在有限样本和无分布理论保证下满足群体公平性约束。FaiREE可以适应各种群体公平性概念（例如，机会平等，平衡几率，人口统计学平衡等）并实现最佳准确性。这些理论保证进一步得到了对合成和实际数据的实验支持。FaiREE表现出比最先进的算法更好的性能。

    Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depends on specific data distributional assumptions, often requiring large sample sizes, and fairness could be violated when there is a modest number of samples, which is often the case in practice. In this paper, we propose FaiREE, a fair classification algorithm that can satisfy group fairness constraints with finite-sample and distribution-free theoretical guarantees. FaiREE can be adapted to satisfy various group fairness notions (e.g., Equality of Opportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal accuracy. These theoretical guarantees are further supported by experiments on both synthetic and real data. FaiREE is shown to have favorable performance over state-of-the-art algorithms.
    
[^70]: 大边际Softmax中的概率相关梯度衰减

    Probability-Dependent Gradient Decay in Large Margin Softmax. (arXiv:2210.17145v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.17145](http://arxiv.org/abs/2210.17145)

    本文研究了在神经网络中的Softmax组件中引入梯度衰减超参数的作用，并发现泛化性能与梯度衰减率显著相关。此外，采用较小的梯度衰减的优化方法类似于课程学习序列，使得困难样本在易样本确信之后得到关注。大边际Softmax会影响局部Lipschitz约束。

    

    在过去的几年中，Softmax已经成为神经网络框架中常见的组件。本文在Softmax中引入了一个梯度衰减超参数，以控制训练过程中的概率相关梯度衰减率。通过对基于MNIST、CIFAR-10/100和SVHN的各种模型架构进行理论分析和实证结果的研究，我们发现泛化性能与梯度衰减率显著相关，即随着置信概率的上升，梯度会呈凸函数或凹函数递减。此外，采用较小的梯度衰减的优化方法类似于课程学习序列，即在易样本足够确信之后，才会关注困难样本，并且对于样本之间的类内距离较大的情况会获得更高的梯度以减小距离。根据分析结果，我们可以提供证据证明大边际Softmax将影响局部Lipschitz约束。

    In the past few years, Softmax has become a common component in neural network frameworks. In this paper, a gradient decay hyperparameter is introduced in Softmax to control the probability-dependent gradient decay rate during training. By following the theoretical analysis and empirical results of a variety of model architectures trained on MNIST, CIFAR-10/100 and SVHN, we find that the generalization performance depends significantly on the gradient decay rate as the confidence probability rises, i.e., the gradient decreases convexly or concavely as the sample probability increases. Moreover, optimization with the small gradient decay shows a similar curriculum learning sequence where hard samples are in the spotlight only after easy samples are convinced sufficiently, and well-separated samples gain a higher gradient to reduce intra-class distance. Based on the analysis results, we can provide evidence that the large margin Softmax will affect the local Lipschitz constraint of the l
    
[^71]: 自监督的低秩正则化去偏方法

    Self-supervised debiasing using low rank regularization. (arXiv:2210.05248v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05248](http://arxiv.org/abs/2210.05248)

    本研究通过对潜在表示的谱分析发现，虚假相关属性会导致深度神经网络偏向编码较低有效秩的表示。在此基础上，提出了一种自监督的去偏框架，通过秩正则化预训练有偏编码器来学习虚假相关属性。

    

    虚假相关性可能导致深度神经网络中的强偏见，影响其泛化能力。虽然大多数现有的去偏方法要求对虚假属性或目标标签进行完全监督，但如何仅通过有限的注释数据训练一个去偏模型仍然是一个开放问题。为了解决这个问题，我们通过对潜在表示进行谱分析研究了一个有趣的现象：虚假相关属性使神经网络归纳地偏向编码较低有效秩表示。我们还展示了秩正则化可以放大这种偏差，以鼓励高度相关的特征。基于这些发现，我们提出了一个自监督的去偏框架，可能与无标签样本兼容。具体而言，我们首先通过秩正则化以自监督的方式预训练一个有偏编码器，作为语义瓶颈来强制编码器学习虚假相关属性。

    Spurious correlations can cause strong biases in deep neural networks, impairing generalization ability. While most existing debiasing methods require full supervision on either spurious attributes or target labels, training a debiased model from a limited amount of both annotations is still an open question. To address this issue, we investigate an interesting phenomenon using the spectral analysis of latent representations: spuriously correlated attributes make neural networks inductively biased towards encoding lower effective rank representations. We also show that a rank regularization can amplify this bias in a way that encourages highly correlated features. Leveraging these findings, we propose a self-supervised debiasing framework potentially compatible with unlabeled samples. Specifically, we first pretrain a biased encoder in a self-supervised manner with the rank regularization, serving as a semantic bottleneck to enforce the encoder to learn the spuriously correlated attrib
    
[^72]: 对比视觉-文本对齐拓扑设计

    Design of the topology for contrastive visual-textual alignment. (arXiv:2209.02127v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.02127](http://arxiv.org/abs/2209.02127)

    对比视觉-文本对齐学习中，我们讨论了softmax温度参数的作用，并提出了一种新的嵌入对齐拓扑设计。采用这种设计可以显著提高零-shot学习的性能。

    

    余弦相似度是对比视觉-文本对齐学习中测量特征表示之间距离的常见选择。然而，实验证明，在学习大规模嘈杂训练数据时，需要一个可学习的softmax温度参数。在这项工作中，我们首先讨论了softmax温度在嵌入空间拓扑属性中的作用。我们认为softmax温度是对嘈杂训练数据进行对比学习的关键机制。它作为距离范围的缩放因子（例如，余弦相似度的范围是[-1, 1]），其学到的值表明训练数据中的噪音水平。然后，我们提出了一种嵌入对齐拓扑的替代设计。我们利用Transformer架构中的多个类标记，将特征表示映射到具有负内积作为距离函数的斜面流形上。通过这种配置，我们大大提高了零-shot

    Cosine similarity is the common choice for measuring the distance between the feature representations in contrastive visual-textual alignment learning. However, empirically a learnable softmax temperature parameter is required when learning on large-scale noisy training data. In this work, we first discuss the role of softmax temperature from the embedding space's topological properties. We argue that the softmax temperature is the key mechanism for contrastive learning on noisy training data. It acts as a scaling factor of the distance range (e.g. [-1, 1] for the cosine similarity), and its learned value indicates the level of noise in the training data. Then, we propose an alternative design of the topology for the embedding alignment. We make use of multiple class tokens in the transformer architecture; then map the feature representations onto an oblique manifold endowed with the negative inner product as the distance function. With this configuration, we largely improve the zero-s
    
[^73]: 关于从预训练到下游任务的对抗鲁棒性转移

    On Transfer of Adversarial Robustness from Pretraining to Downstream Tasks. (arXiv:2208.03835v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.03835](http://arxiv.org/abs/2208.03835)

    本研究证明了无论预训练采用何种协议，线性预测器在下游任务中的鲁棒性受其基础表示鲁棒性的限制。我们提出了损失上界和鲁棒分类准则，并在实际应用中验证了这些理论结果。

    

    随着大规模训练方案的流行，预训练模型在机器学习中的下游任务中被广泛使用。虽然实践中已经证明预训练可以提高模型的性能，但是从预训练到下游任务的鲁棒性属性的转移仍然不够理解。在本研究中，我们证明了线性预测器在下游任务中的鲁棒性可以由其基础表示的鲁棒性限制，而不管预训练使用的协议如何。我们证明了(i)一个在任何下游任务中都成立的损失上界，以及(ii)特定于鲁棒分类的准则。我们在实际应用中验证了我们的理论结果，展示了我们的结果如何用于校准下游鲁棒性的期望，以及我们的结果在最优迁移学习中的用途。综合起来，我们的结果为表征要求进行了初步的步骤。

    As large-scale training regimes have gained popularity, the use of pretrained models for downstream tasks has become common practice in machine learning. While pretraining has been shown to enhance the performance of models in practice, the transfer of robustness properties from pretraining to downstream tasks remains poorly understood. In this study, we demonstrate that the robustness of a linear predictor on downstream tasks can be constrained by the robustness of its underlying representation, regardless of the protocol used for pretraining. We prove (i) a bound on the loss that holds independent of any downstream task, as well as (ii) a criterion for robust classification in particular. We validate our theoretical results in practical applications, show how our results can be used for calibrating expectations of downstream robustness, and when our results are useful for optimal transfer learning. Taken together, our results offer an initial step towards characterizing the requireme
    
[^74]: 一种用于多步鲍型自适应异方差时间序列预测的通用框架

    A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v7 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.14219](http://arxiv.org/abs/2207.14219)

    本文介绍了一种名为AEnbMIMOCQR的新颖算法，通过自适应集成的方式，在不需要数据拆分的情况下，以分布无关的方式生成多步鲍型预测区间。该方法考虑了异方差性，并对分布转变具有鲁棒性，在实验中表现优于其他竞争方法。

    

    本文介绍了一种新颖的模型无关算法，名为自适应集成批量多输入多输出鲍型分位数回归（AEnbMIMOCQR），使得预测者能够以分布无关的方式生成固定预设失配率的多步鲍型预测区间。我们的方法基于鲍型预测原理，但不需要数据拆分，并且即使在数据不可互换的情况下也能提供接近精确的覆盖率。此外，所得到的预测区间在预测时间范围内经验证明有效，并且考虑了异方差性。AEnbMIMOCQR被设计成对分布转变具有鲁棒性，这意味着其预测区间在无限的时间范围内保持可靠，而无需重新训练或对数据生成过程进行不切实际的严格假设。通过系统实验，我们证明了我们的方法在鲍型预测中优于其他竞争方法。

    This paper introduces a novel model-agnostic algorithm called adaptive ensemble batch multi-input multi-output conformalized quantile regression (AEnbMIMOCQR} that enables forecasters to generate multi-step ahead prediction intervals for a fixed pre-specified miscoverage rate in a distribution-free manner. Our method is grounded on conformal prediction principles, however, it does not require data splitting and provides close to exact coverage even when the data is not exchangeable. Moreover, the resulting prediction intervals, besides being empirically valid along the forecast horizon, do not neglect heteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution shifts, which means that its prediction intervals remain reliable over an unlimited period of time, without entailing retraining or imposing unrealistic strict assumptions on the data-generating process. Through methodically experimentation, we demonstrate that our approach outperforms other competitive methods on bo
    
[^75]: 随机初始化的单层神经网络能够使数据线性可分

    Randomly Initialized One-Layer Neural Networks Make Data Linearly Separable. (arXiv:2205.11716v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11716](http://arxiv.org/abs/2205.11716)

    随机初始化的单层神经网络可以将两个集合转化为线性可分的集合，而无需训练，具有计算效率高的优点。

    

    最近，神经网络在将两个任意集合映射为两个线性可分集合方面展示出了显著的能力。相比完全训练的网络，随机初始化的神经网络具有计算效率上的吸引力。本文的贡献在于建立了在足够宽度的情况下，随机初始化的单层神经网络有很高的概率能够将两个集合转化为线性可分的集合，而无需任何训练。此外，我们给出了神经网络必要宽度的精确界限。我们的初始界限在输入维度上呈指数依赖关系，同时在其他参数上呈多项式依赖关系。相反，我们的第二个界限与输入维度无关，有效地克服了维度灾难。我们证明中使用的主要工具在很大程度上依赖于几何原理和随机集中性。

    Recently, neural networks have demonstrated remarkable capabilities in mapping two arbitrary sets to two linearly separable sets. The prospect of achieving this with randomly initialized neural networks is particularly appealing due to the computational efficiency compared to fully trained networks. This paper contributes by establishing that, given sufficient width, a randomly initialized one-layer neural network can, with high probability, transform two sets into two linearly separable sets without any training. Moreover, we furnish precise bounds on the necessary width of the neural network for this phenomenon to occur. Our initial bound exhibits exponential dependence on the input dimension while maintaining polynomial dependence on all other parameters. In contrast, our second bound is independent of input dimension, effectively surmounting the curse of dimensionality. The main tools used in our proof heavily relies on a fusion of geometric principles and concentration of random m
    
[^76]: 寻找策略的马尔可夫决策过程的安全区域

    Finding Safe Zones of policies Markov Decision Processes. (arXiv:2202.11593v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.11593](http://arxiv.org/abs/2202.11593)

    这篇论文研究了寻找策略的马尔可夫决策过程的安全区域的复杂性，提出了一个双准则逼近学习算法，可以近似计算出逃逸概率和安全区域大小。

    

    针对马尔可夫决策过程的策略，我们定义了安全区域，即状态的一个子集，大多数策略的轨迹都被限制在该子集内。安全区域的质量由状态数和逃逸概率参数化，即随机轨迹离开子集的概率。当安全区域具有少量的状态和较低的逃逸概率时，尤其有趣。我们研究了寻找最优安全区域的复杂性，并证明了一般情况下该问题计算上是困难的。我们的主要结果是一个双准则逼近学习算法，准确度近似为$2$倍，同时考虑到逃逸概率和安全区域大小，并且使用多项式大小的样本复杂度。

    Given a policy of a Markov Decision Process, we define a SafeZone as a subset of states, such that most of the policy's trajectories are confined to this subset. The quality of a SafeZone is parameterized by the number of states and the escape probability, i.e., the probability that a random trajectory will leave the subset. SafeZones are especially interesting when they have a small number of states and low escape probability. We study the complexity of finding optimal SafeZones, and show that in general, the problem is computationally hard. Our main result is a bi-criteria approximation learning algorithm with a factor of almost $2$ approximation for both the escape probability and SafeZone size, using a polynomial size sample complexity.
    
[^77]: 交叉验证中Cox模型测试误差的置信区间

    Confidence intervals for the Cox model test error from cross-validation. (arXiv:2201.10770v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2201.10770](http://arxiv.org/abs/2201.10770)

    本文研究了交叉验证中Cox模型测试误差的置信区间问题，发现传统方法可能低估置信区间，并提出使用嵌套交叉验证方法解决这个问题，实现更准确的置信区间估计。

    

    交叉验证是统计学习中用于估计模型测试误差的最常用技术之一，但其行为仍未完全理解。研究表明，使用交叉验证估计得到的标准测试误差的置信区间可能低于名义水平。这种现象是因为在交叉验证过程中，每个样本都同时用于训练和测试，导致估计的误差之间存在相关性。如果不考虑这种相关性，估计的方差会小于应有的值。解决这个问题的一种方法是使用嵌套交叉验证来估计预测误差的均方误差。研究表明，与使用标准交叉验证得到的置信区间相比，这种方法能够实现更好的覆盖率。本研究将嵌套交叉验证思想推广到Cox比例风险模型，并探索了该设置下的各种测试误差选择。

    Cross-validation (CV) is one of the most widely used techniques in statistical learning for estimating the test error of a model, but its behavior is not yet fully understood. It has been shown that standard confidence intervals for test error using estimates from CV may have coverage below nominal levels. This phenomenon occurs because each sample is used in both the training and testing procedures during CV and as a result, the CV estimates of the errors become correlated. Without accounting for this correlation, the estimate of the variance is smaller than it should be. One way to mitigate this issue is by estimating the mean squared error of the prediction error instead using nested CV. This approach has been shown to achieve superior coverage compared to intervals derived from standard CV. In this work, we generalize the nested CV idea to the Cox proportional hazards model and explore various choices of test error for this setting.
    
[^78]: 现代非线性函数回归模型：使用神经网络分析功能数据

    Modern Non-Linear Function-on-Function Regression. (arXiv:2107.14151v1 [stat.ME] CROSS LISTED)

    [http://arxiv.org/abs/2107.14151](http://arxiv.org/abs/2107.14151)

    本研究提出一种利用神经网络分析功能数据的新型非线性函数回归模型，通过连续隐藏层实现对功能响应建模，并提供了两种模型拟合策略（FDNN和FBNN），并通过正则化技术得到更加简明的结果。

    

    本论文引入了一种新的非线性函数回归模型类，使用神经网络分析功能数据。我们提出了一个框架，使用由连续神经元组成的隐藏层，称为连续隐藏层，用于功能响应建模，并提供了两种模型拟合策略：功能直接神经网络（FDNN）和功能基础神经网络（FBNN）。这两种方法都是专门设计来利用功能数据固有的结构，并捕捉功能预测变量和功能响应变量之间存在的复杂关系。我们通过求解函数梯度并实施正则化技术进行模型拟合，得到更简明的结果。我们通过广泛的模拟研究和实际数据示例展示了我们提出的方法在处理复杂功能模型方面的强大灵活性。

    We introduce a new class of non-linear function-on-function regression models for functional data using neural networks. We propose a framework using a hidden layer consisting of continuous neurons, called a continuous hidden layer, for functional response modeling and give two model fitting strategies, Functional Direct Neural Network (FDNN) and Functional Basis Neural Network (FBNN). Both are designed explicitly to exploit the structure inherent in functional data and capture the complex relations existing between the functional predictors and the functional response. We fit these models by deriving functional gradients and implement regularization techniques for more parsimonious results. We demonstrate the power and flexibility of our proposed method in handling complex functional models through extensive simulation studies as well as real data examples.
    
[^79]: 未标记的主成分分析和矩阵补全

    Unlabeled Principal Component Analysis and Matrix Completion. (arXiv:2101.09446v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2101.09446](http://arxiv.org/abs/2101.09446)

    本文引入了一种称为未标记主成分分析（UPCA）的方法，通过代数几何证明了其是一个良定义的代数问题，并提出了一个两阶段算法流程来应对被置换的数据，同时解决了无标记矩阵补全问题。

    

    我们引入了一种称为未标记主成分分析（UPCA）的方法，用于从被置换损坏的数据矩阵中提取鲁棒的主成分。利用代数几何，我们证明了UPCA是一个良定义的代数问题，即与给定数据相一致的最小秩矩阵只有作为多项式方程组的唯一解的实际矩阵的行置换。此外，我们提出了一个适用于实际相关情况的高效两阶段算法流程用于UPCA，其中只有一部分数据被置换。阶段I利用鲁棒的异常值主成分分析方法来估计实际矩阵的列空间。在具备列空间的情况下，阶段II应用最近的无标记感知方法来恢复被置换的数据。在UPCA的基础上允许出现缺失条目和置换导致了无标记矩阵补全问题，我们为此推导了理论和算法。

    We introduce robust principal component analysis from a data matrix in which the entries of its columns have been corrupted by permutations, termed Unlabeled Principal Component Analysis (UPCA). Using algebraic geometry, we establish that UPCA is a well-defined algebraic problem in the sense that the only matrices of minimal rank that agree with the given data are row-permutations of the ground-truth matrix, arising as the unique solutions of a polynomial system of equations. Further, we propose an efficient two-stage algorithmic pipeline for UPCA suitable for the practically relevant case where only a fraction of the data have been permuted. Stage-I employs outlier-robust PCA methods to estimate the ground-truth column-space. Equipped with the column-space, Stage-II applies recent methods for unlabeled sensing to restore the permuted data. Allowing for missing entries on top of permutations in UPCA leads to the problem of unlabeled matrix completion, for which we derive theory and alg
    
[^80]: CrossQ: 用于提高深度强化学习样本效率和简洁性的批归一化方法

    CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity. (arXiv:1902.05605v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1902.05605](http://arxiv.org/abs/1902.05605)

    CrossQ是一种轻量级算法，通过巧妙运用批归一化和删除目标网络的方式，提高了深度强化学习的样本效率，减少了计算成本，并且实施简单。

    

    在深度强化学习中，样本效率是一个关键问题。最近的算法，如REDQ和DroQ，通过将批次标准化的更新数据（UTD）比率增加到每个环境样本上的20个梯度更新步骤，改善了样本效率。然而，这样做会带来大幅增加的计算成本。为了减少这种计算负担，我们引入了CrossQ：一种轻量级算法，它巧妙地运用批归一化，并去除了目标网络，以在保持低UTD比率为1的同时超越目前的最新样本效率。值得注意的是，CrossQ不依赖于当前方法中使用的高级偏差缩减方案。CrossQ的贡献有三个方面：（1）最先进的样本效率，（2）与REDQ和DroQ相比大幅减少计算成本，（3）实施简单，仅需要在SAC之上添加几行代码。

    Sample efficiency is a crucial problem in deep reinforcement learning. Recent algorithms, such as REDQ and DroQ, found a way to improve the sample efficiency by increasing the update-to-data (UTD) ratio to 20 gradient update steps on the critic per environment sample. However, this comes at the expense of a greatly increased computational cost. To reduce this computational burden, we introduce Cross$Q$: a lightweight algorithm that makes careful use of Batch Normalization and removes target networks to surpass the state-of-the-art in sample efficiency while maintaining a low UTD ratio of $1$. Notably, Cross$Q$ does not rely on advanced bias-reduction schemes used in current methods. Cross$Q$'s contributions are thus threefold: (1) state-of-the-art sample efficiency, (2) substantial reduction in computational cost compared to REDQ and DroQ, and (3) ease of implementation, requiring just a few lines of code on top of SAC.
    

