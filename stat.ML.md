# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation.](http://arxiv.org/abs/2308.07896) | SciRE-Solver是一种高效的采样器，通过引入得分积分求解器和递归导数估计方法，它解决了扩散概率模型采样过程缓慢的挑战，并实现了最先进的采样性能。 |
| [^2] | [On regularized Radon-Nikodym differentiation.](http://arxiv.org/abs/2308.07887) | 本文讨论了估计Radon-Nikodym导数的问题，并提出了基于正则化方案的解决方法。通过考虑导数的平滑度和估计空间的容量，建立了相应算法的收敛速度。数值模拟进一步验证了理论结果。 |
| [^3] | [Dyadic Reinforcement Learning.](http://arxiv.org/abs/2308.07843) | 该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。 |
| [^4] | [A Review of Adversarial Attacks in Computer Vision.](http://arxiv.org/abs/2308.07673) | 这项综述研究深度神经网络面临的对抗性攻击，探讨了攻击类型、攻击者目的以及黑白盒攻击的区别，并强调了对抗样本的传递性和现实应用的可行性。 |
| [^5] | [Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem.](http://arxiv.org/abs/2308.07536) | 本文研究了一类随机简单双层优化问题，并引入了一种新颖的无投影方法，该方法通过随机割平面近似解决方案集，然后使用方差缩减技术进行条件梯度更新来控制误差。在上层为凸函数的情况下，该方法能够在$\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\})$个查询中获得$\epsilon_f$-最优的上层解和$\epsilon_g$-最优的下层解，这一保证改进了先前已知的复杂性。 |
| [^6] | [Potential of Deep Operator Networks in Digital Twin-enabling Technology for Nuclear System.](http://arxiv.org/abs/2308.07523) | 深层操作符网络（DeepONet）作为一种强大的替代建模方法，在核系统数字孪生技术中展示出了显著的预测精度和计算效率。然而，挑战仍然存在，包括最佳传感器放置和模型评估。 |
| [^7] | [Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning.](http://arxiv.org/abs/2308.07520) | 这篇论文研究了非线性、反馈和因果结构学习中的一致性问题，并提出了一个弱于强可靠性的k-Triangle Faithfulness的替代定义。 |
| [^8] | [Addressing Distribution Shift in RTB Markets via Exponential Tilting.](http://arxiv.org/abs/2308.07424) | 本文介绍了一种名为ExTRA的算法，用于解决机器学习模型中的分布偏移问题。通过确定源数据上的重要性权重，该方法能够最小化加权源数据和目标数据集之间的KL散度。通过实验验证，证明了这种方法的适用性。 |
| [^9] | [Locally Adaptive and Differentiable Regression.](http://arxiv.org/abs/2308.07418) | 本文提出了一种本地自适应可微回归模型，通过对局部学习模型进行加权平均，在不同本地区域处理数据时具有竞争力，并在理论上实现更快的统计收敛以及在实际应用中改善了性能。 |
| [^10] | [A Time-aware tensor decomposition for tracking evolving patterns.](http://arxiv.org/abs/2308.07126) | 提出了一种适用于跟踪演变模式的时空张量分解方法tPARAFAC2，通过时间正则化器从时间数据中提取逐渐演变的模式。 |
| [^11] | [Fr\'echet Statistics Based Change Point Detection in Multivariate Hawkes Process.](http://arxiv.org/abs/2308.06769) | 本文提出了一种基于Frechet统计的方法，用于在多变量Hawkes过程中检测变点。通过将点过程分成窗口，并利用核矩阵来重构有符号的拉普拉斯矩阵，我们的方法能够准确地检测和描述多变量Hawkes过程因果结构中的变化，具有潜在的金融和神经科学等领域应用价值。 |
| [^12] | [Private Distribution Learning with Public Data: The View from Sample Compression.](http://arxiv.org/abs/2308.06239) | 本论文研究了在具有公共数据的情况下的私有分布学习问题，通过压缩样本和列表学习的方式，我们对高斯分布以及高斯混合分布进行了学习上限的分析，并提出了对不可知学习和分布变化抵抗学习的新结果。 |
| [^13] | [Diffusion Model in Causal Inference with Unmeasured Confounders.](http://arxiv.org/abs/2308.03669) | 本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。 |
| [^14] | [An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines.](http://arxiv.org/abs/2307.06542) | 本研究提出了一种通过受限玻尔兹曼机（RBMs）的二值图像去噪框架，该框架使用二次无约束二值优化（QUBO）形式的去噪目标，并且适用于量子退火。通过平衡训练的RBMs学习到的分布和噪声图像偏离的惩罚项，实现了去噪目标。通过进行实验，研究发现该方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。 |
| [^15] | [Likelihood-free neural Bayes estimators for censored peaks-over-threshold models.](http://arxiv.org/abs/2306.15642) | 该论文提出了一种基于神经网络的无似然贝叶斯估计方法，用于构建高效的截尾超阈值模型估计器。该方法挑战了传统的基于截尾似然的空间极值推理，并在计算和统计效率上取得了显著的提升。 |
| [^16] | [Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics.](http://arxiv.org/abs/2306.10656) | 本论文提出了一种名为VHGM的深度生成模型，基于掩码建模的方法来学习健康属性、生活方式和人格之间的关系。通过使用异构表格数据集，VHGM有效地学习了超过1,800个属性。该模型具有潜在的应用前景，例如用于医疗属性的虚拟测量和生活方式的假设验证。 |
| [^17] | [Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals.](http://arxiv.org/abs/2306.07071) | 这篇论文提出了一种名为ω-UCB的新上置信区间抽样策略，使用不对称置信区间以更准确、更紧密地估计奖励成本比，解决了现有预算多臂老虎机问题策略存在的问题，并在合成和真实环境中表现出色。 |
| [^18] | [Disentanglement via Latent Quantization.](http://arxiv.org/abs/2305.18378) | 本文通过潜在量化的方式实现了解缠表示学习，并通过严格的交流瓶颈和强大的模型规范化成功将数据进行了组合编码和解码，最终在多个基准数据集上实现了最先进的解缠性能，并提高了标准VAE模型学习表征的可解释性。 |
| [^19] | [Mixed Regression via Approximate Message Passing.](http://arxiv.org/abs/2304.02229) | 本文提出了一种新的近似消息传递算法来解决在广义线性模型中的回归问题，该算法适用于混合线性回归、最大仿射回归和专家混合模型等问题。 |
| [^20] | [Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches.](http://arxiv.org/abs/2303.11582) | 本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。 |
| [^21] | [A Recipe for Well-behaved Graph Neural Approximations of Complex Dynamics.](http://arxiv.org/abs/2301.04900) | 本文介绍了一种行为良好的图神经网络近似复杂动力学的方法，包括必要的偏置和适当的神经网络结构，并提出了评估泛化能力和推断时预测置信度的方法。 |
| [^22] | [Birth-death dynamics for sampling: Global convergence, approximations and their asymptotics.](http://arxiv.org/abs/2211.00450) | 本文研究了一种连续的出生死亡动态，并提出了弱假设。通过这种动态控制的概率密度指数级地快速收敛到吉布斯平衡测度，同时提出了一种实用的基于纯出生死亡动态的数值采样器，并对其逼近品质进行了定量评估。 |
| [^23] | [Nesterov Meets Optimism: Rate-Optimal Separable Minimax Optimization.](http://arxiv.org/abs/2210.17550) | 我们提出了一种新的一阶优化算法AG-OG，用于可分离的凸-凹极小极大优化问题。通过精细地利用问题结构，我们实现了最优收敛速率，可以适用于多种设置，包括双线性耦合的强凸-强凹、凸-强凹极小极大优化和双线性博弈。该算法还在随机设置下达到了最优收敛速率。这是第一个在双线性耦合的极小极大优化问题中在确定性和随机设置下都具有最优收敛速率的单次调用算法。 |
| [^24] | [Bayesian Hyperbolic Multidimensional Scaling.](http://arxiv.org/abs/2210.15081) | 这是一篇关于提出了一种贝叶斯双曲多维标度方法的论文，通过在双曲空间中表示低维图形来处理高维相关数据，从而适用于具有树状结构的数据，并且提供了有效的后验采样方法，降低了计算复杂性。 |
| [^25] | [Rigorous dynamical mean field theory for stochastic gradient descent methods.](http://arxiv.org/abs/2210.06591) | 本研究通过证明的闭式方程，描述了一类基于梯度的方法在高维情况下的精确渐进性能，为随机梯度下降等算法提供了理论支持，并提供了数值实现。 |
| [^26] | [Random Forests for Change Point Detection.](http://arxiv.org/abs/2205.04997) | 这个论文提出了一种利用分类器的新颖多变量非参数多变点检测方法，该方法以随机森林为核心，具有较好的经验性能。 |
| [^27] | [Multi-task Representation Learning with Stochastic Linear Bandits.](http://arxiv.org/abs/2202.10066) | 本研究通过跨任务共享低维线性表示，提出了一种基于迹范数正则化的高效贪婪策略，在多任务学习中学习低维表示，无需知道潜在矩阵的秩。实验结果表明，该策略相比基线在多任务遗憾上有明显的优势。 |
| [^28] | [Variational Gibbs Inference for Statistical Model Estimation from Incomplete Data.](http://arxiv.org/abs/2111.13180) | 这项研究提出了一种名为变分吉布斯推断（VGI）的方法，用于解决使用不完全数据进行统计模型估计时的挑战。与标准的潜变量模型不同，VGI能够处理估计指数多个缺失变量的条件分布，从而为实际的数据集提供了更准确的模型估计。 |
| [^29] | [Clustering and Structural Robustness in Causal Diagrams.](http://arxiv.org/abs/2111.04513) | 本研究提出了一种聚类方法，通过定义过渡聚类并应用完备的算法，可以简化因果图中的变量关系，并保留因果效应的可辨识性属性。 |
| [^30] | [Non-stationary Online Learning with Memory and Non-stochastic Control.](http://arxiv.org/abs/2102.03758) | 本文研究了具有记忆的非平稳在线凸优化问题，引入了动态策略遗憾作为性能度量，并提出了一种算法，通过新颖的切换成本感知在线合奏方法解决了切换成本的关键技术挑战。 |
| [^31] | [Fair Densities via Boosting the Sufficient Statistics of Exponential Families.](http://arxiv.org/abs/2012.00188) | 本文介绍了一种利用增强算法来实现公平密度的方法，该方法通过学习指数族的充分统计量，以改善数据拟合，并确保最小的公平性保证。实验证明了该方法在真实数据上的有效性。 |

# 详细

[^1]: SciRE-Solver: 用得分积分求解器和递归导数估计快速采样扩散概率模型

    SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation. (arXiv:2308.07896v1 [stat.ML])

    [http://arxiv.org/abs/2308.07896](http://arxiv.org/abs/2308.07896)

    SciRE-Solver是一种高效的采样器，通过引入得分积分求解器和递归导数估计方法，它解决了扩散概率模型采样过程缓慢的挑战，并实现了最先进的采样性能。

    

    扩散概率模型(DPMs)是一类强大的生成模型，以其生成高保真图像样本的能力而闻名。DPMs的实现面临的主要挑战是采样过程缓慢。在这项工作中，我们提出了一种高效的DPMs采样器。具体而言，我们针对与DPMs采样过程对应的扩散ODE提出了一个基于得分的精确解决方案范式，该范式为求解扩散ODE的数值算法开发提供了新的视角。为了实现高效的采样器，我们提出了一种递归导数估计(RDE)方法来减小估计误差。通过我们提出的解决方案范式和RDE方法，我们提出了具有收敛顺序保证的得分积分求解器(SciRE-Solver)来解决扩散ODEs。SciRE-Solver在离散时间和连续时间DPMs上获得了最先进的采样性能，并且仅需有限数量的得分函数评估(NFE)。

    Diffusion probabilistic models (DPMs) are a powerful class of generative models known for their ability to generate high-fidelity image samples. A major challenge in the implementation of DPMs is the slow sampling process. In this work, we bring a high-efficiency sampler for DPMs. Specifically, we propose a score-based exact solution paradigm for the diffusion ODEs corresponding to the sampling process of DPMs, which introduces a new perspective on developing numerical algorithms for solving diffusion ODEs. To achieve an efficient sampler, we propose a recursive derivative estimation (RDE) method to reduce the estimation error. With our proposed solution paradigm and RDE method, we propose the score-integrand solver with the convergence order guarantee as efficient solver (SciRE-Solver) for solving diffusion ODEs. The SciRE-Solver attains state-of-the-art (SOTA) sampling performance with a limited number of score function evaluations (NFE) on both discrete-time and continuous-time DPMs
    
[^2]: 关于正则化的Radon-Nikodym导数

    On regularized Radon-Nikodym differentiation. (arXiv:2308.07887v1 [math.ST])

    [http://arxiv.org/abs/2308.07887](http://arxiv.org/abs/2308.07887)

    本文讨论了估计Radon-Nikodym导数的问题，并提出了基于正则化方案的解决方法。通过考虑导数的平滑度和估计空间的容量，建立了相应算法的收敛速度。数值模拟进一步验证了理论结果。

    

    本文讨论了估计Radon-Nikodym导数的问题。这个问题在各种应用中出现，比如协变量偏移适应、似然比检验、互信息估计和条件概率估计。为了解决上述问题，我们采用再生核希尔伯特空间中的一般正则化方案。通过考虑导数的平滑度和估计它的空间的容量，建立了相应正则化算法的收敛速度。这是以一般源条件和正则化的Christoffel函数为基础的。我们还发现，在任何特定点上重建Radon-Nikodym导数可以具有高精度。我们的理论结果通过数值模拟进行了说明。

    We discuss the problem of estimating Radon-Nikodym derivatives. This problem appears in various applications, such as covariate shift adaptation, likelihood-ratio testing, mutual information estimation, and conditional probability estimation. To address the above problem, we employ the general regularization scheme in reproducing kernel Hilbert spaces. The convergence rate of the corresponding regularized algorithm is established by taking into account both the smoothness of the derivative and the capacity of the space in which it is estimated. This is done in terms of general source conditions and the regularized Christoffel functions. We also find that the reconstruction of Radon-Nikodym derivatives at any particular point can be done with high order of accuracy. Our theoretical results are illustrated by numerical simulations.
    
[^3]: Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) 该论文标题已翻译：二元强化学习。

    Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])

    [http://arxiv.org/abs/2308.07843](http://arxiv.org/abs/2308.07843)

    该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。

    

    移动医疗旨在通过在个人日常生活中提供干预来提高健康结果。照顾伴侣和社会支持网络的参与经常在帮助个人管理繁重的医疗条件方面起着关键作用。这为移动医疗提供了机会，设计针对二元关系——目标人和其照顾伴侣之间关系——以提高社会支持的干预措施。在本文中，我们开发了二元强化学习（Dyadic RL），这是一种基于环境因素和目标人及其照顾伴侣的过去反馈个性化干预措施的在线强化学习算法。在这里，多组干预措施影响着二元关系在多个时间间隔内。开发的二元强化学习是贝叶斯和层次的。我们正式介绍了问题设定，开发了二元强化学习并确定了遗憾边界。通过模拟，我们展示了二元强化学习的实证效果。

    Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
    
[^4]: 计算机视觉中对抗性攻击的综述

    A Review of Adversarial Attacks in Computer Vision. (arXiv:2308.07673v1 [cs.CV])

    [http://arxiv.org/abs/2308.07673](http://arxiv.org/abs/2308.07673)

    这项综述研究深度神经网络面临的对抗性攻击，探讨了攻击类型、攻击者目的以及黑白盒攻击的区别，并强调了对抗样本的传递性和现实应用的可行性。

    

    深度神经网络在各种下游任务中被广泛应用，特别是在像自动驾驶这样的安全关键场景中，但深度网络经常受到对抗样本的威胁。这种对抗性攻击对人眼来说是看不见的，但却会导致深度神经网络误分类，并且在深度学习和机器学习模型以及现实环境中具有传递性。对抗性攻击可以分为白盒攻击，攻击者知道模型的参数和梯度；以及黑盒攻击，攻击者只能获取模型的输入和输出。根据攻击者的目的，可以分为有目标攻击和非目标攻击，前者是指攻击者希望模型将原始样本错误分类为指定的类，这更实际；而非目标攻击只需让模型将样本错误分类即可。黑盒设置是一种情况。

    Deep neural networks have been widely used in various downstream tasks, especially those safety-critical scenario such as autonomous driving, but deep networks are often threatened by adversarial samples. Such adversarial attacks can be invisible to human eyes, but can lead to DNN misclassification, and often exhibits transferability between deep learning and machine learning models and real-world achievability. Adversarial attacks can be divided into white-box attacks, for which the attacker knows the parameters and gradient of the model, and black-box attacks, for the latter, the attacker can only obtain the input and output of the model. In terms of the attacker's purpose, it can be divided into targeted attacks and non-targeted attacks, which means that the attacker wants the model to misclassify the original sample into the specified class, which is more practical, while the non-targeted attack just needs to make the model misclassify the sample. The black box setting is a scenari
    
[^5]: 无投影方法求解具有凸下层问题的随机简单双层优化问题

    Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem. (arXiv:2308.07536v1 [math.OC])

    [http://arxiv.org/abs/2308.07536](http://arxiv.org/abs/2308.07536)

    本文研究了一类随机简单双层优化问题，并引入了一种新颖的无投影方法，该方法通过随机割平面近似解决方案集，然后使用方差缩减技术进行条件梯度更新来控制误差。在上层为凸函数的情况下，该方法能够在$\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\})$个查询中获得$\epsilon_f$-最优的上层解和$\epsilon_g$-最优的下层解，这一保证改进了先前已知的复杂性。

    

    本文研究了一类随机双层优化问题，也称为随机简单双层优化，在这类问题中，我们最小化另一个随机凸优化问题的最优解集上的一个光滑随机目标函数。我们介绍了一种新颖的随机双层优化方法，该方法通过随机割平面局部近似下层问题的解集，并使用方差缩减技术进行条件梯度更新以控制由于使用随机梯度而引入的误差。当上层函数为凸函数时，我们的方法需要$\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\})$个随机预言机查询才能获得上层为$\epsilon_f$最优，下层为$\epsilon_g$最优的解。这个保证改进了先前最好已知复杂性$\mathcal{O}(\max\{1/\epsilon_f^{4},1/\epsilon_g^{4}\})$。此外，对于上层为凸函数的情况，我们的方法中的论文具有多个创新和贡献。

    In this paper, we study a class of stochastic bilevel optimization problems, also known as stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function over the optimal solution set of another stochastic convex optimization problem. We introduce novel stochastic bilevel optimization methods that locally approximate the solution set of the lower-level problem via a stochastic cutting plane, and then run a conditional gradient update with variance reduction techniques to control the error induced by using stochastic gradients. For the case that the upper-level function is convex, our method requires $\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\}) $ stochastic oracle queries to obtain a solution that is $\epsilon_f$-optimal for the upper-level and $\epsilon_g$-optimal for the lower-level. This guarantee improves the previous best-known complexity of $\mathcal{O}(\max\{1/\epsilon_f^{4},1/\epsilon_g^{4}\})$. Moreover, for the case that the
    
[^6]: 深层操作符网络在核系统数字孪生技术中的潜力

    Potential of Deep Operator Networks in Digital Twin-enabling Technology for Nuclear System. (arXiv:2308.07523v1 [stat.ML])

    [http://arxiv.org/abs/2308.07523](http://arxiv.org/abs/2308.07523)

    深层操作符网络（DeepONet）作为一种强大的替代建模方法，在核系统数字孪生技术中展示出了显著的预测精度和计算效率。然而，挑战仍然存在，包括最佳传感器放置和模型评估。

    

    本研究在核工程的数字孪生系统中引入了深层操作符网络（DeepONet）作为一种强大的替代建模方法。随着核能作为一种碳中和解决方案的重要性不断增加，采用数字孪生技术对于提高核工程应用中的运营效率、安全性和预测能力变得至关重要。DeepONet具有显著的预测精度，优于传统的机器学习方法。通过广泛的基准测试和评估，本研究展示了DeepONet在解决复杂粒子传输问题中的可扩展性和计算效率。通过将函数作为输入数据并使用训练数据构建操作符G，DeepONet能够有效处理多样化和复杂的场景。然而，DeepONet的应用也揭示了与最佳传感器放置和模型评估相关的挑战，这是实际实施中的关键问题。

    This research introduces the Deep Operator Network (DeepONet) as a robust surrogate modeling method within the context of digital twin (DT) systems for nuclear engineering. With the increasing importance of nuclear energy as a carbon-neutral solution, adopting DT technology has become crucial to enhancing operational efficiencies, safety, and predictive capabilities in nuclear engineering applications. DeepONet exhibits remarkable prediction accuracy, outperforming traditional ML methods. Through extensive benchmarking and evaluation, this study showcases the scalability and computational efficiency of DeepONet in solving a challenging particle transport problem. By taking functions as input data and constructing the operator $G$ from training data, DeepONet can handle diverse and complex scenarios effectively. However, the application of DeepONet also reveals challenges related to optimal sensor placement and model evaluation, critical aspects of real-world implementation. Addressing 
    
[^7]: 非线性、反馈和因果结构学习中的一致性问题研究

    Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning. (arXiv:2308.07520v1 [stat.ML])

    [http://arxiv.org/abs/2308.07520](http://arxiv.org/abs/2308.07520)

    这篇论文研究了非线性、反馈和因果结构学习中的一致性问题，并提出了一个弱于强可靠性的k-Triangle Faithfulness的替代定义。

    

    因果发现的目标是从观测数据中找到学习因果结构的自动化搜索方法。有些情况下，感兴趣的因果机制的所有变量都已经被测量，任务是预测一个变量对另一个变量的影响。相反，有时主要关注的变量并非直接可观察，而是通过它们在数据中的表现来推理出来的。这些被称为潜在变量。一个广泛被知道的例子是心理构造的智商，因为无法直接测量，所以研究人员尝试通过各种指标如智商测试来评估。在这种情况下，因果发现算法可以揭示潜在变量之间和潜在变量与观察变量之间的因果连接，从而发现潜在的模式和结构。这篇论文主要研究因果发现中的两个问题：提供了一个弱于强可靠性的k-Triangle Faithfulness的替代定义，并提出了对统计一致性的新要求。

    The goal of Causal Discovery is to find automated search methods for learning causal structures from observational data. In some cases all variables of the interested causal mechanism are measured, and the task is to predict the effects one measured variable has on another. In contrast, sometimes the variables of primary interest are not directly observable but instead inferred from their manifestations in the data. These are referred to as latent variables. One commonly known example is the psychological construct of intelligence, which cannot directly measured so researchers try to assess through various indicators such as IQ tests. In this case, casual discovery algorithms can uncover underlying patterns and structures to reveal the causal connections between the latent variables and between the latent and observed variables. This thesis focuses on two questions in causal discovery: providing an alternative definition of k-Triangle Faithfulness that (i) is weaker than strong faithfu
    
[^8]: 通过指数倾斜解决RTB市场中的分布偏移问题

    Addressing Distribution Shift in RTB Markets via Exponential Tilting. (arXiv:2308.07424v1 [stat.ML])

    [http://arxiv.org/abs/2308.07424](http://arxiv.org/abs/2308.07424)

    本文介绍了一种名为ExTRA的算法，用于解决机器学习模型中的分布偏移问题。通过确定源数据上的重要性权重，该方法能够最小化加权源数据和目标数据集之间的KL散度。通过实验验证，证明了这种方法的适用性。

    

    机器学习模型中的分布偏移可能是性能下降的主要原因。本文深入探讨了这些偏移的特性，主要针对实时竞价（RTB）市场模型的特点。我们强调了类别不平衡和样本选择偏差所带来的挑战，这两者均是分布偏移的强有力诱因。本文介绍了一种名为ExTRA（Exponential Tilt Reweighting Alignment）的算法，该算法由Marty等人（2023）提出，用于解决数据中的分布偏移问题。ExTRA方法旨在确定源数据上的重要性权重，以最小化加权源数据和目标数据集之间的KL散度。该方法的一个显著优点是它能够使用有标签的源数据和无标签的目标数据进行操作。通过模拟真实世界数据，我们研究了分布偏移的性质，并评估了所提出模型的适用性。

    Distribution shift in machine learning models can be a primary cause of performance degradation. This paper delves into the characteristics of these shifts, primarily motivated by Real-Time Bidding (RTB) market models. We emphasize the challenges posed by class imbalance and sample selection bias, both potent instigators of distribution shifts. This paper introduces the Exponential Tilt Reweighting Alignment (ExTRA) algorithm, as proposed by Marty et al. (2023), to address distribution shifts in data. The ExTRA method is designed to determine the importance weights on the source data, aiming to minimize the KL divergence between the weighted source and target datasets. A notable advantage of this method is its ability to operate using labeled source data and unlabeled target data. Through simulated real-world data, we investigate the nature of distribution shift and evaluate the applicacy of the proposed model.
    
[^9]: 本地自适应可微回归

    Locally Adaptive and Differentiable Regression. (arXiv:2308.07418v1 [cs.LG])

    [http://arxiv.org/abs/2308.07418](http://arxiv.org/abs/2308.07418)

    本文提出了一种本地自适应可微回归模型，通过对局部学习模型进行加权平均，在不同本地区域处理数据时具有竞争力，并在理论上实现更快的统计收敛以及在实际应用中改善了性能。

    

    过度参数化模型，如深度神经网络和随机森林，在机器学习中变得非常受欢迎。然而，在现代超参数化的本地自适应模型中，常见的连续性和可微性目标往往被忽视。我们提出了一个通用框架，通过在对应的本地区域中对局部学习模型进行加权平均来构建全局连续可微模型。该模型在处理具有不同密度或不同本地区域中的函数值尺度的数据时具有竞争力。我们证明，当我们在本地模型中混合使用核岭和多项式回归项，并对它们进行连续拼接时，在理论上实现更快的统计收敛，并在各种实际环境中实现改进的性能。

    Over-parameterized models like deep nets and random forests have become very popular in machine learning. However, the natural goals of continuity and differentiability, common in regression models, are now often ignored in modern overparametrized, locally-adaptive models. We propose a general framework to construct a global continuous and differentiable model based on a weighted average of locally learned models in corresponding local regions. This model is competitive in dealing with data with different densities or scales of function values in different local regions. We demonstrate that when we mix kernel ridge and polynomial regression terms in the local models, and stitch them together continuously, we achieve faster statistical convergence in theory and improved performance in various practical settings.
    
[^10]: 一种适用于跟踪演变模式的时空张量分解方法

    A Time-aware tensor decomposition for tracking evolving patterns. (arXiv:2308.07126v1 [cs.LG])

    [http://arxiv.org/abs/2308.07126](http://arxiv.org/abs/2308.07126)

    提出了一种适用于跟踪演变模式的时空张量分解方法tPARAFAC2，通过时间正则化器从时间数据中提取逐渐演变的模式。

    

    时间演变的数据集通常可以组织成一个高阶张量，其中的一个模式是时间模式。虽然张量分解已经成功地用于捕捉这类高阶数据集中的潜在模式，但往往忽略了时间的因素，允许时间点的重新排序。在最近的研究中，引入了时间正则化器来解决这个问题。然而，现有方法仍然不允许潜在模式在时间上发生变化（例如，大脑中的空间变化，主题中的上下文变化）。本文中，我们提出了一种基于PARAFAC2的时空张量分解方法tPARAFAC2，通过时间正则化器从时间数据中提取逐渐演变的模式。通过对合成数据的大量实验，我们证明了tPARAFAC2能够准确地捕捉到演变中的潜在模式，表现优于PARAFAC2和带有时间平滑正则化的耦合矩阵分解方法。

    Time-evolving data sets can often be arranged as a higher-order tensor with one of the modes being the time mode. While tensor factorizations have been successfully used to capture the underlying patterns in such higher-order data sets, the temporal aspect is often ignored, allowing for the reordering of time points. In recent studies, temporal regularizers are incorporated in the time mode to tackle this issue. Nevertheless, existing approaches still do not allow underlying patterns to change in time (e.g., spatial changes in the brain, contextual changes in topics). In this paper, we propose temporal PARAFAC2 (tPARAFAC2): a PARAFAC2-based tensor factorization method with temporal regularization to extract gradually evolving patterns from temporal data. Through extensive experiments on synthetic data, we demonstrate that tPARAFAC2 can capture the underlying evolving patterns accurately performing better than PARAFAC2 and coupled matrix factorization with temporal smoothness regulariza
    
[^11]: 基于Frechet统计的多变量Hawkes过程中的变点检测

    Fr\'echet Statistics Based Change Point Detection in Multivariate Hawkes Process. (arXiv:2308.06769v1 [stat.ML])

    [http://arxiv.org/abs/2308.06769](http://arxiv.org/abs/2308.06769)

    本文提出了一种基于Frechet统计的方法，用于在多变量Hawkes过程中检测变点。通过将点过程分成窗口，并利用核矩阵来重构有符号的拉普拉斯矩阵，我们的方法能够准确地检测和描述多变量Hawkes过程因果结构中的变化，具有潜在的金融和神经科学等领域应用价值。

    

    本文提出了一种使用Frechet统计方法对多变量Hawkes过程中的因果网络进行变点检测的新方法。我们的方法将点过程分成重叠的窗口，在每个窗口中估计核矩阵，并通过将核矩阵视为因果网络的邻接矩阵来重构有符号的拉普拉斯矩阵。通过在模拟和真实加密货币数据集上进行实验，我们证明了我们的方法的有效性。我们的结果显示，我们的方法能够准确地检测和描述多变量Hawkes过程因果结构中的变化，并在金融和神经科学等领域具有潜在的应用价值。所提出的方法是对点过程设置中Frechet统计之前工作的扩展，并对多变量点过程的变点检测领域做出了重要贡献。

    This paper proposes a new approach for change point detection in causal networks of multivariate Hawkes processes using Frechet statistics. Our method splits the point process into overlapping windows, estimates kernel matrices in each window, and reconstructs the signed Laplacians by treating the kernel matrices as the adjacency matrices of the causal network. We demonstrate the effectiveness of our method through experiments on both simulated and real-world cryptocurrency datasets. Our results show that our method is capable of accurately detecting and characterizing changes in the causal structure of multivariate Hawkes processes, and may have potential applications in fields such as finance and neuroscience. The proposed method is an extension of previous work on Frechet statistics in point process settings and represents an important contribution to the field of change point detection in multivariate point processes.
    
[^12]: 具有公共数据的私有分布学习：基于样本压缩的视角

    Private Distribution Learning with Public Data: The View from Sample Compression. (arXiv:2308.06239v1 [cs.LG])

    [http://arxiv.org/abs/2308.06239](http://arxiv.org/abs/2308.06239)

    本论文研究了在具有公共数据的情况下的私有分布学习问题，通过压缩样本和列表学习的方式，我们对高斯分布以及高斯混合分布进行了学习上限的分析，并提出了对不可知学习和分布变化抵抗学习的新结果。

    

    我们研究了在可以访问公共数据的情况下的私有分布学习问题。在这个设置中，我们称之为公私学习，学习器被给予来自未知分布p的属于类$\mathcal Q$的公共样本和私有样本，目标是输出一个对p的估计，同时遵守与私有样本相关的隐私约束（这里是纯差分隐私）。我们展示了类$\mathcal Q$的公私可学习性与$\mathcal Q$的样本压缩方案以及中间概念——列表学习的存在性有关。利用这个联系：（1）近似恢复了关于$\mathbb R^d$上高斯分布的先前结果；（2）得出了新的结果，包括对任意$k$-高斯混合分布在$\mathbb R^d$上的样本复杂度上界，以及对不可知和分布变化抵抗学习器的结果，以及公私可学习性的闭包性质。

    We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.  We show that the public-private learnability of a class $\mathcal Q$ is connected to the existence of a sample compression scheme for $\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability
    
[^13]: 无法测量混淆因素下因果推断中的扩散模型

    Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])

    [http://arxiv.org/abs/2308.03669](http://arxiv.org/abs/2308.03669)

    本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。

    

    我们研究了如何在无法测量的混淆因素存在的情况下，扩展扩散模型的使用，以从观测数据中回答因果问题。在Pearl的使用有向无环图（DAG）捕捉因果干预的框架中，提出了一种基于扩散模型的因果模型（DCM），可以更准确地回答因果问题，假设所有混淆因素都是可以观察到的。然而，实际中存在无法测量的混淆因素，这使得DCM无法应用。为了缓解DCM的这一局限性，我们提出了一个扩展模型，称为基于反门准则的DCM（BDCM），其思想根植于在DAG中找到要包括在扩散模型解码过程中的变量的反门准则，这样我们可以将DCM扩展到存在无法测量的混淆因素的情况。合成数据实验表明，我们提出的模型在无法测量混淆因素的情况下更精确地捕捉到了反事实分布。

    We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
    
[^14]: 量子退火中适合的图像去噪框架：QUBO和受限玻尔兹曼机

    An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines. (arXiv:2307.06542v1 [quant-ph])

    [http://arxiv.org/abs/2307.06542](http://arxiv.org/abs/2307.06542)

    本研究提出了一种通过受限玻尔兹曼机（RBMs）的二值图像去噪框架，该框架使用二次无约束二值优化（QUBO）形式的去噪目标，并且适用于量子退火。通过平衡训练的RBMs学习到的分布和噪声图像偏离的惩罚项，实现了去噪目标。通过进行实验，研究发现该方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。

    

    我们研究了一种通过受限玻尔兹曼机（RBMs）实现的二值图像去噪框架，该框架引入了一个二次无约束二值优化（QUBO）形式的去噪目标，并且非常适合量子退火。通过在训练的RBMs上学习到的分布与噪声图像偏离的惩罚项的平衡，实现了去噪目标。我们推导了在目标分布被良好近似的情况下，惩罚参数的统计最优选择，并进一步建议了一种经过经验证支持的修改方法，使该方法对于理想化假设具有鲁棒性。我们还在额外的假设下展示了，我们方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。虽然我们将该模型构建为图像去噪模型，但它可以应用于任何二值数据。由于QUBO公式非常适合在量子退火器上实现，我们在一个数据集上对该模型进行了测试。

    We investigate a framework for binary image denoising via restricted Boltzmann machines (RBMs) that introduces a denoising objective in quadratic unconstrained binary optimization (QUBO) form and is well-suited for quantum annealing. The denoising objective is attained by balancing the distribution learned by a trained RBM with a penalty term for derivations from the noisy image. We derive the statistically optimal choice of the penalty parameter assuming the target distribution has been well-approximated, and further suggest an empirically supported modification to make the method robust to that idealistic assumption. We also show under additional assumptions that the denoised images attained by our method are, in expectation, strictly closer to the noise-free images than the noisy images are. While we frame the model as an image denoising model, it can be applied to any binary data. As the QUBO formulation is well-suited for implementation on quantum annealers, we test the model on a
    
[^15]: 无似然神经贝叶斯估计的截尾超阈值模型

    Likelihood-free neural Bayes estimators for censored peaks-over-threshold models. (arXiv:2306.15642v1 [stat.ME])

    [http://arxiv.org/abs/2306.15642](http://arxiv.org/abs/2306.15642)

    该论文提出了一种基于神经网络的无似然贝叶斯估计方法，用于构建高效的截尾超阈值模型估计器。该方法挑战了传统的基于截尾似然的空间极值推理，并在计算和统计效率上取得了显著的提升。

    

    在高维度下，对于空间极值依赖模型的推理往往因其依赖于难以处理的或截尾的似然函数而造成计算负担。利用最近在无似然推理方面的进展，我们通过在神经网络架构中编码截尾信息，为截尾超阈值模型构建了高效的估计器。我们的新方法对于传统的基于截尾似然的空间极值推理提出了挑战。我们的模拟研究表明，在推断流行的极值依赖模型（如最大稳定模型、r-帕累托模型和随机比例混合过程）时，相对于竞争的基于似然的方法，我们的新估计器在计算和统计效率方面提供了显著的提升。

    Inference for spatial extremal dependence models can be computationally burdensome in moderate-to-high dimensions due to their reliance on intractable and/or censored likelihoods. Exploiting recent advances in likelihood-free inference with neural Bayes estimators (that is, neural estimators that target Bayes estimators), we develop a novel approach to construct highly efficient estimators for censored peaks-over-threshold models by encoding censoring information in the neural network architecture. Our new method provides a paradigm shift that challenges traditional censored likelihood-based inference for spatial extremes. Our simulation studies highlight significant gains in both computational and statistical efficiency, relative to competing likelihood-based approaches, when applying our novel estimators for inference of popular extremal dependence models, such as max-stable, $r$-Pareto, and random scale mixture processes. We also illustrate that it is possible to train a single esti
    
[^16]: 虚拟人类生成模型：基于掩码建模的方法来学习人类特征

    Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])

    [http://arxiv.org/abs/2306.10656](http://arxiv.org/abs/2306.10656)

    本论文提出了一种名为VHGM的深度生成模型，基于掩码建模的方法来学习健康属性、生活方式和人格之间的关系。通过使用异构表格数据集，VHGM有效地学习了超过1,800个属性。该模型具有潜在的应用前景，例如用于医疗属性的虚拟测量和生活方式的假设验证。

    

    识别医疗属性、生活方式和人格之间的关系对于理解和改善身体和精神状况至关重要。本文提出了一种名为虚拟人类生成模型（VHGM）的机器学习模型，用于估计有关医疗保健、生活方式和个性的属性。VHGM是一个深度生成模型，使用掩码建模训练，在已知属性的条件下学习属性的联合分布。利用异构表格数据集，VHGM高效地学习了超过1,800个属性。我们数值评估了VHGM及其训练技术的性能。作为VHGM的概念验证，我们提出了几个应用程序，演示了用户情境，例如医疗属性的虚拟测量和生活方式的假设验证。

    Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
    
[^17]: 具有不对称置信区间的有限预算多臂老虎机问题

    Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals. (arXiv:2306.07071v1 [cs.LG])

    [http://arxiv.org/abs/2306.07071](http://arxiv.org/abs/2306.07071)

    这篇论文提出了一种名为ω-UCB的新上置信区间抽样策略，使用不对称置信区间以更准确、更紧密地估计奖励成本比，解决了现有预算多臂老虎机问题策略存在的问题，并在合成和真实环境中表现出色。

    

    我们研究了随机预算多臂老虎机（MAB）问题，其中玩家选择具有未知期望奖励和成本的K个臂。目标是在预算约束下最大化总奖励。因此，玩家试图尽可能经常地选择具有最高奖励成本比的臂。当前针对此问题的最先进策略存在一些问题，我们予以说明。为了克服这些问题，我们提出了一种新的上置信区间（UCB）抽样策略，称为ω-UCB，并使用不对称置信区间。这些区间尺度随着样本均值和随机变量边界之间的距离而变化，相对于我们的竞争对手，可以更准确、更紧密地估计奖励成本比。我们证明了我们的方法具有对数后悔，并在合成和真实环境中始终优于现有策略。

    We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a player chooses from $K$ arms with unknown expected rewards and costs. The goal is to maximize the total reward under a budget constraint. A player thus seeks to choose the arm with the highest reward-cost ratio as often as possible. Current state-of-the-art policies for this problem have several issues, which we illustrate. To overcome them, we propose a new upper confidence bound (UCB) sampling policy, $\omega$-UCB, that uses asymmetric confidence intervals. These intervals scale with the distance between the sample mean and the bounds of a random variable, yielding a more accurate and tight estimation of the reward-cost ratio compared to our competitors. We show that our approach has logarithmic regret and consistently outperforms existing policies in synthetic and real settings.
    
[^18]: 通过潜在量化进行解缠

    Disentanglement via Latent Quantization. (arXiv:2305.18378v1 [cs.LG])

    [http://arxiv.org/abs/2305.18378](http://arxiv.org/abs/2305.18378)

    本文通过潜在量化的方式实现了解缠表示学习，并通过严格的交流瓶颈和强大的模型规范化成功将数据进行了组合编码和解码，最终在多个基准数据集上实现了最先进的解缠性能，并提高了标准VAE模型学习表征的可解释性。

    

    在解缠表示学习中，模型需要将数据集的基础变化因素分开并独立地表示出来，而模型并没有提供有关这些因素的真实信息，归纳偏见在实现解缠方面发挥着重要作用。在本文中，我们通过施加严格的交流瓶颈和强大的模型规范化，构建了一种朝着组合编码和解码数据的归纳偏见。具体来说，我们对潜在维度进行可学习的离散编码，并为每个维度应用一个单独的标量码书。潜在量化迫使编码器在许多数据点上使用少量潜在值，从而使解码器能够为每个值分配一致的含义。规范化有助于将模型引向这种简明策略。我们在多个基准数据集上展示了该方法的广泛应用性，并且展示了我们的方法显著提高了一系列标准VAE模型学习的表征的可解释性。

    In disentangled representation learning, a model is asked to tease apart a dataset's underlying sources of variation and represent them independently of one another. Since the model is provided with no ground truth information about these sources, inductive biases take a paramount role in enabling disentanglement. In this work, we construct an inductive bias towards compositionally encoding and decoding data by enforcing a harsh communication bottleneck. Concretely, we do this by (i) quantizing the latent space into learnable discrete codes with a separate scalar codebook per dimension and (ii) applying strong model regularization via an unusually high weight decay. Intuitively, the quantization forces the encoder to use a small number of latent values across many datapoints, which in turn enables the decoder to assign a consistent meaning to each value. Regularization then serves to drive the model towards this parsimonious strategy. We demonstrate the broad applicability of this appr
    
[^19]: 通过近似消息传递的混合回归（Mixed Regression via Approximate Message Passing）

    Mixed Regression via Approximate Message Passing. (arXiv:2304.02229v1 [stat.ML])

    [http://arxiv.org/abs/2304.02229](http://arxiv.org/abs/2304.02229)

    本文提出了一种新的近似消息传递算法来解决在广义线性模型中的回归问题，该算法适用于混合线性回归、最大仿射回归和专家混合模型等问题。

    

    本文研究了广义线性模型（GLM）中具有多个信号和潜变量的回归问题。该模型被称为矩阵GLM，涵盖了许多在统计学习中广泛研究的问题，包括混合线性回归、最大仿射回归和专家混合模型等。我们提出了一种新的近似消息传递（AMP）算法来估计矩阵GLM中的信号和潜变量，并在高维极限中对其性能进行了严格的表征。该表征是通过状态演化递归来计算的，从而可以精确计算渐近性能度量，例如信噪比下降阈值（threshold）。

    We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic 
    
[^20]: 大规模适应性实验：灵活批处理的贝叶斯算法

    Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])

    [http://arxiv.org/abs/2303.11582](http://arxiv.org/abs/2303.11582)

    本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。

    

    标准的贝叶斯算法假定持续重新分配测量工作，这在实现过程中存在延迟反馈和基础设施/组织难题等挑战。本文针对仅有少数重新分配阶段的实际情况，其中测量结果是以批处理形式测量的，提出了一种新的适应性实验框架，可灵活处理任何批处理大小。我们的主要观察是，在统计推断中普遍使用的正态近似也可以指导可扩展自适应设计。通过推导渐进顺序实验，我们制定了一种动态规划，可以利用平均回报的先验信息。动态规划的状态转移相对于采样分配是可微的，允许使用基于梯度的方法进行规划和策略优化。我们提出了一种简单的迭代规划方法，即残余时限优化，通过优化平衡探索和利用的规划目标来选择采样分配。在合成和真实世界基准测试问题上的实验结果表明，我们的框架实现了最先进的性能，同时具有模块化和易用性。

    Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
    
[^21]: 一种行为良好的图神经近似复杂动力学的方法

    A Recipe for Well-behaved Graph Neural Approximations of Complex Dynamics. (arXiv:2301.04900v2 [cond-mat.stat-mech] UPDATED)

    [http://arxiv.org/abs/2301.04900](http://arxiv.org/abs/2301.04900)

    本文介绍了一种行为良好的图神经网络近似复杂动力学的方法，包括必要的偏置和适当的神经网络结构，并提出了评估泛化能力和推断时预测置信度的方法。

    

    数据驱动的常微分方程近似提供了一种有前景的方法来发现动力系统模型，特别是对于缺乏明确原理的复杂系统。本文着重研究了一类由网络邻接矩阵耦合的常微分方程系统描述的复杂系统。许多现实世界中的系统，包括金融、社交和神经系统，属于这类动力学模型。我们提出了使用神经网络近似这种动力系统的关键要素，包括必要的偏置和适当的神经网络结构。强调与静态监督学习的区别，我们提倡在统计学习理论的经典假设之外评估泛化能力。为了在推断时估计预测的置信度，我们引入了一个专用的空模型。通过研究各种复杂网络动力学，我们展示了神经网络的能力。

    Data-driven approximations of ordinary differential equations offer a promising alternative to classical methods in discovering a dynamical system model, particularly in complex systems lacking explicit first principles. This paper focuses on a complex system whose dynamics is described with a system of ordinary differential equations, coupled via a network adjacency matrix. Numerous real-world systems, including financial, social, and neural systems, belong to this class of dynamical models. We propose essential elements for approximating such dynamical systems using neural networks, including necessary biases and an appropriate neural architecture. Emphasizing the differences from static supervised learning, we advocate for evaluating generalization beyond classical assumptions of statistical learning theory. To estimate confidence in prediction during inference time, we introduce a dedicated null model. By studying various complex network dynamics, we demonstrate the neural network'
    
[^22]: 采样的出生死亡动态：全局收敛，逼近及其渐近性质研究

    Birth-death dynamics for sampling: Global convergence, approximations and their asymptotics. (arXiv:2211.00450v2 [math.AP] UPDATED)

    [http://arxiv.org/abs/2211.00450](http://arxiv.org/abs/2211.00450)

    本文研究了一种连续的出生死亡动态，并提出了弱假设。通过这种动态控制的概率密度指数级地快速收敛到吉布斯平衡测度，同时提出了一种实用的基于纯出生死亡动态的数值采样器，并对其逼近品质进行了定量评估。

    

    本文以采样非凸位势吉布斯测度为挑战，研究了一种连续出生死亡动态。我们提出了一种弱假设，改进了先前[51,57]的结果，证明了由Kullback-Leibler散度或$\chi^2$散度控制的出生死亡概率密度会指数级快速地收敛到吉布斯平衡测度，其普适速率独立于势垒。为了构建基于纯出生死亡动态的实用数值采样器，我们考虑了一个交互粒子系统，它灵感来自于梯度流结构和经典的Fokker-Planck方程，并依赖于测量的基于核的逼近。通过梯度流的$\Gamma$-收敛技术，证明在环上，核化动态的光滑有界正解在有限时间间隔内，当核带宽收缩到零时，收敛于纯出生死亡动态。此外，我们使用了伽马收敛的技术对纯出生死亡过程的逼近品质进行了定量评估。

    Motivated by the challenge of sampling Gibbs measures with nonconvex potentials, we study a continuum birth-death dynamics. We improve results in previous works [51,57] and provide weaker hypotheses under which the probability density of the birth-death governed by Kullback-Leibler divergence or by $\chi^2$ divergence converge exponentially fast to the Gibbs equilibrium measure, with a universal rate that is independent of the potential barrier. To build a practical numerical sampler based on the pure birth-death dynamics, we consider an interacting particle system, which is inspired by the gradient flow structure and the classical Fokker-Planck equation and relies on kernel-based approximations of the measure. Using the technique of $\Gamma$-convergence of gradient flows, we show that on the torus, smooth and bounded positive solutions of the kernelized dynamics converge on finite time intervals, to the pure birth-death dynamics as the kernel bandwidth shrinks to zero. Moreover we pro
    
[^23]: Nesterov遇见乐观主义：速率最优的可分离极小极大优化

    Nesterov Meets Optimism: Rate-Optimal Separable Minimax Optimization. (arXiv:2210.17550v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.17550](http://arxiv.org/abs/2210.17550)

    我们提出了一种新的一阶优化算法AG-OG，用于可分离的凸-凹极小极大优化问题。通过精细地利用问题结构，我们实现了最优收敛速率，可以适用于多种设置，包括双线性耦合的强凸-强凹、凸-强凹极小极大优化和双线性博弈。该算法还在随机设置下达到了最优收敛速率。这是第一个在双线性耦合的极小极大优化问题中在确定性和随机设置下都具有最优收敛速率的单次调用算法。

    

    我们提出了一种新的一阶优化算法 - 加速梯度-乐观梯度（AG-OG）下降上升法，用于可分离的凸-凹极小极大优化问题。我们算法的主要思想是精细地利用极小极大问题的结构，在个体组件上进行Nesterov加速，并在耦合组件上进行乐观梯度。我们展示了AG-OG在各种设置下（包括双线性耦合的强凸-强凹极小极大优化，双线性耦合的凸-强凹极小极大优化和双线性博弈）实现了最优收敛速率（常数因子之内）。我们还将我们的算法扩展到随机设置，并在双线性耦合的强凸-强凹和凸-强凹设置下达到最优收敛速率。AG-OG是第一个在双线性耦合的极小极大优化问题的确定性和随机设置下都具有最优收敛速率的单次调用算法。

    We propose a new first-order optimization algorithm -AcceleratedGradient-OptimisticGradient (AG-OG) Descent Ascent -- for separable convex-concave minimax optimization. The main idea of our algorithm is to carefully leverage the structure of the minimax problem, performing Nesterov acceleration on the individual component and optimistic gradient on the coupling component. Equipped with proper restarting, we show that AG-OG achieves the optimal convergence rate (up to a constant) for a variety of settings, including bilinearly coupled strongly convex-strongly concave minimax optimization (bi-SC-SC), bilinearly coupled convex-strongly concave minimax optimization (bi-C-SC), and bilinear games. We also extend our algorithm to the stochastic setting and achieve the optimal convergence rate in both bi-SC-SC and bi-C-SC settings. AG-OG is the first single-call algorithm with optimal convergence rates in both deterministic and stochastic settings for bilinearly coupled minimax optimization 
    
[^24]: Bayesian双曲多维标度

    Bayesian Hyperbolic Multidimensional Scaling. (arXiv:2210.15081v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2210.15081](http://arxiv.org/abs/2210.15081)

    这是一篇关于提出了一种贝叶斯双曲多维标度方法的论文，通过在双曲空间中表示低维图形来处理高维相关数据，从而适用于具有树状结构的数据，并且提供了有效的后验采样方法，降低了计算复杂性。

    

    多维标度（MDS）是一种广泛应用于表示高维、相关数据的方法。MDS通过为每个观测分配一个低维几何图形上的位置来工作，图形上的距离表示相似性。我们提出了一种贝叶斯方法来处理低维图形为双曲线的多维标度。使用双曲空间有助于表示许多场景中常见的树状结构（例如具有层次结构的文本或遗传数据）。贝叶斯方法提供了对观测数据中测量误差的最小化影响和不确定性评估的正则化。我们还提出了一种情况对照似然估计近似值，允许在更大的数据设置中从后验分布中高效采样，将计算复杂性从近似$O(n^2)$降低到$O(n)$。我们使用模拟、经典参考数据集、印度vil进行了对所提出的方法与业界最先进的方法进行了评估

    Multidimensional scaling (MDS) is a widely used approach to representing high-dimensional, dependent data. MDS works by assigning each observation a location on a low-dimensional geometric manifold, with distance on the manifold representing similarity. We propose a Bayesian approach to multidimensional scaling when the low-dimensional manifold is hyperbolic. Using hyperbolic space facilitates representing tree-like structures common in many settings (e.g. text or genetic data with hierarchical structure). A Bayesian approach provides regularization that minimizes the impact of measurement error in the observed data and assesses uncertainty. We also propose a case-control likelihood approximation that allows for efficient sampling from the posterior distribution in larger data settings, reducing computational complexity from approximately $O(n^2)$ to $O(n)$. We evaluate the proposed method against state-of-the-art alternatives using simulations, canonical reference datasets, Indian vil
    
[^25]: 严格的动力学均场理论用于随机梯度下降方法

    Rigorous dynamical mean field theory for stochastic gradient descent methods. (arXiv:2210.06591v2 [math-ph] UPDATED)

    [http://arxiv.org/abs/2210.06591](http://arxiv.org/abs/2210.06591)

    本研究通过证明的闭式方程，描述了一类基于梯度的方法在高维情况下的精确渐进性能，为随机梯度下降等算法提供了理论支持，并提供了数值实现。

    

    我们证明了一类基于梯度的方法在高维情况下的精确渐进性能闭式方程，该方法从高斯数据的经验风险最小化学习估计器（例如M-估计器，浅层神经网络...）。这包括了广泛使用的算法，如随机梯度下降（SGD）或Nesterov加速。得到的方程与将动力学均场理论（DMFT）方程离散化后应用于梯度流时产生的方程相匹配。我们的证明方法允许我们明确描述记忆核在有效动力学中如何构建，并且包括非可分离的更新函数，允许具有非单位协方差矩阵的数据集。最后，我们提供了具有通用批处理大小和恒定学习率的SGD方程的数值实现。

    We prove closed-form equations for the exact high-dimensional asymptotics of a family of first order gradient-based methods, learning an estimator (e.g. M-estimator, shallow neural network, ...) from observations on Gaussian data with empirical risk minimization. This includes widely used algorithms such as stochastic gradient descent (SGD) or Nesterov acceleration. The obtained equations match those resulting from the discretization of dynamical mean-field theory (DMFT) equations from statistical physics when applied to gradient flow. Our proof method allows us to give an explicit description of how memory kernels build up in the effective dynamics, and to include non-separable update functions, allowing datasets with non-identity covariance matrices. Finally, we provide numerical implementations of the equations for SGD with generic extensive batch-size and with constant learning rates.
    
[^26]: 随机森林用于变点检测

    Random Forests for Change Point Detection. (arXiv:2205.04997v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2205.04997](http://arxiv.org/abs/2205.04997)

    这个论文提出了一种利用分类器的新颖多变量非参数多变点检测方法，该方法以随机森林为核心，具有较好的经验性能。

    

    我们提出了一种新颖的多变量非参数多变点检测方法，使用分类器。我们构建了一个分类器对数似然比，利用类概率预测来比较不同的变点配置。我们提出了一种计算可行的搜索方法，特别适用于随机森林，称为changeforest。然而，该方法可以与任何产生类概率预测的分类器配对使用，我们通过使用k最近邻分类器来说明。我们证明了当与一致的分类器配对时，在单变点设置中，它能够一致地定位变点。在广泛的模拟研究中，我们的方法changeforest相较于现有的多变量非参数变点检测方法实现了改进的经验性能。我们为R，Python和Rust用户提供了changeforest软件包的高效实现。

    We propose a novel multivariate nonparametric multiple change point detection method using classifiers. We construct a classifier log-likelihood ratio that uses class probability predictions to compare different change point configurations. We propose a computationally feasible search method that is particularly well suited for random forests, denoted by changeforest. However, the method can be paired with any classifier that yields class probability predictions, which we illustrate by also using a k-nearest neighbor classifier. We prove that it consistently locates change points in single change point settings when paired with a consistent classifier. Our proposed method changeforest achieves improved empirical performance in an extensive simulation study compared to existing multivariate nonparametric change point detection methods. An efficient implementation of our method is made available for R, Python, and Rust users in the changeforest software package.
    
[^27]: 多任务表示学习与随机线性赌博机

    Multi-task Representation Learning with Stochastic Linear Bandits. (arXiv:2202.10066v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.10066](http://arxiv.org/abs/2202.10066)

    本研究通过跨任务共享低维线性表示，提出了一种基于迹范数正则化的高效贪婪策略，在多任务学习中学习低维表示，无需知道潜在矩阵的秩。实验结果表明，该策略相比基线在多任务遗憾上有明显的优势。

    

    我们研究了在随机线性赌博机任务中的迁移学习问题。我们考虑跨任务共享低维线性表示，并研究在多任务学习中学习这种表示的益处。根据最新的随机赌博机策略设计结果，我们提出了一种基于迹范数正则化的高效贪婪策略。它通过鼓励任务回归向量形成的矩阵具有低秩来隐式地学习低维表示。与文献中的先前工作不同，我们的策略不需要知道潜在矩阵的秩。我们导出了我们策略的多任务遗憾的上界，该上界在对数因子上是$O(\sqrt{NdT(T+d)r})$，其中$T$是任务数，$r$是秩，$d$是变量数，$N$是每个任务的回合数。我们展示了与基线$Td\sqrt{N}$相比，我们策略的益处。

    We study the problem of transfer-learning in the setting of stochastic linear bandit tasks. We consider that a low dimensional linear representation is shared across the tasks, and study the benefit of learning this representation in the multi-task learning setting. Following recent results to design stochastic bandit policies, we propose an efficient greedy policy based on trace norm regularization. It implicitly learns a low dimensional representation by encouraging the matrix formed by the task regression vectors to be of low rank. Unlike previous work in the literature, our policy does not need to know the rank of the underlying matrix. We derive an upper bound on the multi-task regret of our policy, which is, up to logarithmic factors, of order $\sqrt{NdT(T+d)r}$, where $T$ is the number of tasks, $r$ the rank, $d$ the number of variables and $N$ the number of rounds per task. We show the benefit of our strategy compared to the baseline $Td\sqrt{N}$ obtained by solving each task i
    
[^28]: 不完全数据统计模型估计的变分吉布斯推断

    Variational Gibbs Inference for Statistical Model Estimation from Incomplete Data. (arXiv:2111.13180v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.13180](http://arxiv.org/abs/2111.13180)

    这项研究提出了一种名为变分吉布斯推断（VGI）的方法，用于解决使用不完全数据进行统计模型估计时的挑战。与标准的潜变量模型不同，VGI能够处理估计指数多个缺失变量的条件分布，从而为实际的数据集提供了更准确的模型估计。

    

    统计模型在机器学习中具有广泛的适用性，可用于各种下游任务。这些模型由自由参数控制，通常通过最大似然估计或其近似方法从数据中估计。然而，当面对真实世界的数据集时，许多模型都会遇到一个关键问题：它们是以完全观测的数据为基础的，而实际上数据集中存在缺失数据。从不完全数据中进行统计模型估计的理论在概念上类似于潜变量模型的估计，其中存在诸如变分推断（VI）之类的强大工具。然而，与标准的潜变量模型不同，使用不完全数据的参数估计通常需要估计指数多个缺失变量的条件分布，因此使得标准的VI方法难以处理。我们通过引入变分吉布斯推断（VGI），一种新的通用方法，来填补这一差距。

    Statistical models are central to machine learning with broad applicability across a range of downstream tasks. The models are controlled by free parameters that are typically estimated from data by maximum-likelihood estimation or approximations thereof. However, when faced with real-world data sets many of the models run into a critical issue: they are formulated in terms of fully-observed data, whereas in practice the data sets are plagued with missing data. The theory of statistical model estimation from incomplete data is conceptually similar to the estimation of latent-variable models, where powerful tools such as variational inference (VI) exist. However, in contrast to standard latent-variable models, parameter estimation with incomplete data often requires estimating exponentially-many conditional distributions of the missing variables, hence making standard VI methods intractable. We address this gap by introducing variational Gibbs inference (VGI), a new general-purpose meth
    
[^29]: 聚类和因果图中的结构稳健性

    Clustering and Structural Robustness in Causal Diagrams. (arXiv:2111.04513v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.04513](http://arxiv.org/abs/2111.04513)

    本研究提出了一种聚类方法，通过定义过渡聚类并应用完备的算法，可以简化因果图中的变量关系，并保留因果效应的可辨识性属性。

    

    图表常用于表示和可视化因果关系。对于少量变量，这种方法提供了一个简洁清晰的场景视图。但是随着研究变量数量的增加，图表方法可能变得不可行，并且表示的清晰度丧失。变量聚类是减小因果图大小的一种自然方式，但如果随意实施，可能会错误地改变因果关系的重要属性。我们定义了一种特定类型的聚类，称为过渡聚类，在某些条件下保证保留因果效应的可辨识性属性。我们提供了一个完备的算法来寻找给定图表中的所有过渡聚类，并展示了聚类如何简化因果效应的识别。我们还研究了反向问题，即我们从一个聚类图表开始，寻找满足因果效应可辨识性属性的扩展图表。

    Graphs are commonly used to represent and visualize causal relations. For a small number of variables, this approach provides a succinct and clear view of the scenario at hand. As the number of variables under study increases, the graphical approach may become impractical, and the clarity of the representation is lost. Clustering of variables is a natural way to reduce the size of the causal diagram, but it may erroneously change the essential properties of the causal relations if implemented arbitrarily. We define a specific type of cluster, called transit cluster, that is guaranteed to preserve the identifiability properties of causal effects under certain conditions. We provide a sound and complete algorithm for finding all transit clusters in a given graph and demonstrate how clustering can simplify the identification of causal effects. We also study the inverse problem, where one starts with a clustered graph and looks for extended graphs where the identifiability properties of ca
    
[^30]: 非平稳在线学习中的记忆与非随机控制问题

    Non-stationary Online Learning with Memory and Non-stochastic Control. (arXiv:2102.03758v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.03758](http://arxiv.org/abs/2102.03758)

    本文研究了具有记忆的非平稳在线凸优化问题，引入了动态策略遗憾作为性能度量，并提出了一种算法，通过新颖的切换成本感知在线合奏方法解决了切换成本的关键技术挑战。

    

    本文研究了具有记忆的在线凸优化问题（OCO），其中损失函数可以依赖于过去的决策，从而捕捉到学习问题的时间效应。我们引入了动态策略遗憾作为性能度量，以设计在非平稳环境下鲁棒的算法，该算法将算法的决策与一系列变化的比较器进行竞争。我们提出了一种新的OCO记忆算法，它在时间跨度、非平稳度量和记忆长度方面保证了最佳的动态策略遗憾。关键技术挑战是如何控制切换成本，即参与者决策的累积移动量，这个问题通过一种新颖的切换成本感知在线合奏方法得到了巧妙解决，该方法采用了动态策略遗憾的新的元基分解和一个精心设计的元学习器和基学习器，以显式地规范化切换成本。

    We study the problem of Online Convex Optimization (OCO) with memory, which allows loss functions to depend on past decisions and thus captures temporal effects of learning problems. In this paper, we introduce dynamic policy regret as the performance measure to design algorithms robust to non-stationary environments, which competes algorithms' decisions with a sequence of changing comparators. We propose a novel algorithm for OCO with memory that provably enjoys an optimal dynamic policy regret in terms of time horizon, non-stationarity measure, and memory length. The key technical challenge is how to control the switching cost, the cumulative movements of player's decisions, which is neatly addressed by a novel switching-cost-aware online ensemble approach equipped with a new meta-base decomposition of dynamic policy regret and a careful design of meta-learner and base-learner that explicitly regularizes the switching cost. The results are further applied to tackle non-stationarity i
    
[^31]: 通过增强指数族的充分统计量来实现公平密度。

    Fair Densities via Boosting the Sufficient Statistics of Exponential Families. (arXiv:2012.00188v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2012.00188](http://arxiv.org/abs/2012.00188)

    本文介绍了一种利用增强算法来实现公平密度的方法，该方法通过学习指数族的充分统计量，以改善数据拟合，并确保最小的公平性保证。实验证明了该方法在真实数据上的有效性。

    

    我们介绍了一种利用增强算法对数据进行公平预处理的方法。从一个初始的公平但不准确的分布开始，我们的方法在确保最小公平性保证的同时朝着更好的数据拟合方向进行转移。为此，它学习了一个具有增强收敛性的指数族的充分统计量。重要的是，我们能够从理论上证明学习的分布将具有表示率和统计率的数据公平性保证。与最近的基于优化的预处理方法不同，我们的方法可以轻松适应连续域特征。此外，当弱学习者被指定为决策树时，可以检查学习分布的充分统计量，以提供（不）公平性的来源线索。通过实证结果展示了在真实数据上的结果质量。

    We introduce a boosting algorithm to pre-process data for fairness. Starting from an initial fair but inaccurate distribution, our approach shifts towards better data fitting while still ensuring a minimal fairness guarantee. To do so, it learns the sufficient statistics of an exponential family with boosting-compliant convergence. Importantly, we are able to theoretically prove that the learned distribution will have a representation rate and statistical rate data fairness guarantee. Unlike recent optimization based pre-processing methods, our approach can be easily adapted for continuous domain features. Furthermore, when the weak learners are specified to be decision trees, the sufficient statistics of the learned distribution can be examined to provide clues on sources of (un)fairness. Empirical results are present to display the quality of result on real-world data.
    

