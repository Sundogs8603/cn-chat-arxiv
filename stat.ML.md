# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Neural Network Driven, Interactive Design for Nonlinear Optical Molecules Based on Group Contribution Method.](http://arxiv.org/abs/2309.08570) | 本研究提出了一种基于神经网络的交互式设计方法，结合群组贡献方法和机器学习技术，能够准确快速地设计非线性光学分子。该方法不仅能够准确预测不同分子的光学性质，还可以实现有效的结构搜索。 |
| [^2] | [Towards Word-Level End-to-End Neural Speaker Diarization with Auxiliary Network.](http://arxiv.org/abs/2309.08489) | 本文提出了一种名为WEEND的词级端到端神经网络方法，通过使用辅助网络，实现了同时进行自动语音识别和发言人分离，并在2个发言人的短片场景中取得了优于基线系统的性能。 |
| [^3] | [Deep Multi-Agent Reinforcement Learning for Decentralized Active Hypothesis Testing.](http://arxiv.org/abs/2309.08477) | 这个论文提出了一个分布式主动假设测试（AHT）问题的解决方法，通过多智能体强化学习，设计一个策略来在有限通信通道上合作完成任务，将贝叶斯风险最小化。 |
| [^4] | [On the limitations of data-driven weather forecasting models.](http://arxiv.org/abs/2309.08473) | 数据驱动的机器学习天气预报模型不具备传统基于物理的模型的准确性和物理一致性，它们在预测技能上的优势很大程度上可以归因于这些特殊性。 |
| [^5] | [Chunked Attention-based Encoder-Decoder Model for Streaming Speech Recognition.](http://arxiv.org/abs/2309.08436) | 本研究提出了一种基于分块注意力编码器-解码器模型的流式语音识别方法，通过在预定义的固定大小窗口上操作，实现了模型的流式运行。实验结果表明，该模型相比非流式变种具有相当的性能，并且在长篇演讲中具有很好的泛化能力。 |
| [^6] | [IHT-Inspired Neural Network for Single-Snapshot DOA Estimation with Sparse Linear Arrays.](http://arxiv.org/abs/2309.08429) | 本文提出了一种基于IHT的神经网络方法，用于在汽车环境中利用稀疏线性阵列进行单快照DOA估计。该方法通过循环神经网络结构对IHT算法进行参数化，并通过浅层自编码器替代t-SVD来降低计算成本。 |
| [^7] | [Constraint-Free Structure Learning with Smooth Acyclic Orientations.](http://arxiv.org/abs/2309.08406) | 本文提出了一种无约束的连续优化方案COSMO，用于非环结构学习。通过定义一个可微近似的方向矩阵，并使用单一优先向量进行参数化，我们可以得到一个平滑的方向矩阵和相应的非环邻接矩阵，而无需在任何步骤中评估非环性。尽管没有显式约束，但我们证明COSMO始终收敛到一个非环解。这种方法不仅渐近快速，而且比其他有约束方法具有更小的误差。 |
| [^8] | [Heteroskedastic conformal regression.](http://arxiv.org/abs/2309.08313) | 本文研究了使用标准化和Mondrian符合规范的方法如何构建自适应的预测区间，以解决回归问题中的异方差噪声。 |
| [^9] | [Sampling-Free Probabilistic Deep State-Space Models.](http://arxiv.org/abs/2309.08256) | 本文提出了一种无需采样的概率深度状态空间模型，通过使用第一个确定性推断算法，实现了高效的训练和测试近似。 |
| [^10] | [Deep Nonnegative Matrix Factorization with Beta Divergences.](http://arxiv.org/abs/2309.08249) | 本文提出了一种使用Beta散度的深度非负矩阵分解方法，应用于面部特征提取、文档主题识别和高光谱图像材料识别。 |
| [^11] | [Topological Node2vec: Enhanced Graph Embedding via Persistent Homology.](http://arxiv.org/abs/2309.08241) | 通过引入拓扑损失项和适应持续同调度量的熵正则化，我们改进了Node2vec方法，使其能够更好地还原输入图的拓扑结构。 |
| [^12] | [How many Neurons do we need? A refined Analysis for Shallow Networks trained with Gradient Descent.](http://arxiv.org/abs/2309.08044) | 本论文在神经切向核（NTK）范式下，通过分析用梯度下降训练的两层神经网络的泛化性质，改进了现有结果，并得出了快速收敛的速度。此外，我们证明了训练过程中权重保持在初始位置附近，半径与回归函数的平滑度和NTK的积分算子的特征值衰减程度有关。 |
| [^13] | [Uncertainty quantification for learned ISTA.](http://arxiv.org/abs/2309.07982) | 本文提出了一种严谨的方法来获得LISTA估计量的置信区间，为模型-based深度学习解决方案中的不确定性提供了理论支持。 |
| [^14] | [Masked Generative Modeling with Enhanced Sampling Scheme.](http://arxiv.org/abs/2309.07945) | 本文提出了一种增强的采样方案 (ESS)，用于掩码非自回归生成建模。该方案能够确保样本的多样性和保真度，并由三个阶段组成：简单迭代解码、关键反向采样和关键重采样。简单迭代解码用于采样标记集，关键反向采样和关键重采样用于掩盖不真实的标记并重建被掩盖的标记，以提高采样的保真度。 |
| [^15] | [Policy Gradient Optimal Correlation Search for Variance Reduction in Monte Carlo simulation and Maximum Optimal Transport.](http://arxiv.org/abs/2307.12703) | 该论文提出了一种新的算法，通过引入相关路径来降低蒙特卡洛模拟中的方差，从而估计随机微分方程解的函数。通过政策梯度和强化学习技术，使用深度神经网络近似最优相关函数并进行校准。这与最大最优传输问题有关。 |
| [^16] | [Engression: Extrapolation for Nonlinear Regression?.](http://arxiv.org/abs/2307.00835) | Engression是一种非线性回归方法，通过使用分布回归技术和预加性噪声模型，在训练样本范围边界外也能可靠地进行外推。 |
| [^17] | [Optimal scheduling of entropy regulariser for continuous-time linear-quadratic reinforcement learning.](http://arxiv.org/abs/2208.04466) | 本研究利用熵正则化的松弛随机控制视角设计了连续时间线性二次强化学习算法，并通过探索性控制方法和近端策略更新方法实现了探索和利用的权衡，以解决有限时间线性二次强化学习问题。 |
| [^18] | [GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes.](http://arxiv.org/abs/2204.02112) | GP-BART是一种使用高斯过程的新型贝叶斯加法回归树方法，相比标准BART模型，它具有更好的平滑性和明确的协方差结构假设，在多种情境下显示出超越传统建模方法的性能。 |
| [^19] | [Efficient Multidimensional Functional Data Analysis Using Marginal Product Basis Systems.](http://arxiv.org/abs/2107.14728) | 本文提出了一个用于高效处理多维函数数据的方法，通过使用一组优化适应数据的可分离基函数构建连续表示。利用观测数据的降维转换和张量分解，可以有效解决估计问题。同时，引入基于粗糙度的正则化以应对维度灾难。 |

# 详细

[^1]: 基于群组贡献方法的非线性光学分子的神经网络驱动的交互式设计

    Neural Network Driven, Interactive Design for Nonlinear Optical Molecules Based on Group Contribution Method. (arXiv:2309.08570v1 [stat.ML])

    [http://arxiv.org/abs/2309.08570](http://arxiv.org/abs/2309.08570)

    本研究提出了一种基于神经网络的交互式设计方法，结合群组贡献方法和机器学习技术，能够准确快速地设计非线性光学分子。该方法不仅能够准确预测不同分子的光学性质，还可以实现有效的结构搜索。

    

    本文报道了一种基于Lewis模型群组贡献方法（LGC）- 多阶段贝叶斯神经网络（msBNN）- 进化算法（EA）框架，用于合理设计D-Pi-A型有机小分子非线性光学材料。通过结合msBNN和校正的Lewis模型群组贡献方法（cLGC），可以准确高效地获得分子的不同光学性质 - 仅使用小型数据集进行训练。此外，通过使用专为LGC设计的EA模型，可以实现良好的结构搜索。详细讨论了该框架表现良好的逻辑原因。考虑到这种理论引导的机器学习框架结合了化学原理和数据驱动工具，很可能被证明在更广泛的领域中解决分子设计相关问题时有效。

    A Lewis-mode group contribution method (LGC) -- multi-stage Bayesian neural network (msBNN) -- evolutionary algorithm (EA) framework is reported for rational design of D-Pi-A type organic small-molecule nonlinear optical materials is presented. Upon combination of msBNN and corrected Lewis-mode group contribution method (cLGC), different optical properties of molecules are afforded accurately and efficiently - by using only a small data set for training. Moreover, by employing the EA model designed specifically for LGC, structural search is well achievable. The logical origins of the well performance of the framework are discussed in detail. Considering that such a theory guided, machine learning framework combines chemical principles and data-driven tools, most likely, it will be proven efficient to solve molecular design related problems in wider fields.
    
[^2]: 朝向词级端到端神经发言人分离与辅助网络

    Towards Word-Level End-to-End Neural Speaker Diarization with Auxiliary Network. (arXiv:2309.08489v1 [eess.AS])

    [http://arxiv.org/abs/2309.08489](http://arxiv.org/abs/2309.08489)

    本文提出了一种名为WEEND的词级端到端神经网络方法，通过使用辅助网络，实现了同时进行自动语音识别和发言人分离，并在2个发言人的短片场景中取得了优于基线系统的性能。

    

    尽管标准的发言人分离试图回答“谁在什么时候说了什么”，但现实中大多数相关应用更关心确定“谁说了什么”。无论是传统的模块化方法还是最近的端到端神经分离（EEND），都需要一个额外的自动语音识别（ASR）模型和一个协调算法来将说话者标签与识别的单词关联起来。在本文中，我们提出了一种带有辅助网络的词级端到端神经分离（WEEND），这是一种多任务学习算法，它在相同的神经架构中执行端到端ASR和发言人分离。也就是说，当语音被识别时，同时为每个识别的单词预测说话者标签。实验结果表明，WEEND在所有两个发言人的短片场景上优于基线系统，并且能够推广到5分钟的音频长度。尽管在3个或更多发言人的情况下，相对于基线系统，不能达到最佳性能。

    While standard speaker diarization attempts to answer the question "who spoken when", most of relevant applications in reality are more interested in determining "who spoken what". Whether it is the conventional modularized approach or the more recent end-to-end neural diarization (EEND), an additional automatic speech recognition (ASR) model and an orchestration algorithm are required to associate the speaker labels with recognized words. In this paper, we propose Word-level End-to-End Neural Diarization (WEEND) with auxiliary network, a multi-task learning algorithm that performs end-to-end ASR and speaker diarization in the same neural architecture. That is, while speech is being recognized, speaker labels are predicted simultaneously for each recognized word. Experimental results demonstrate that WEEND outperforms the turn-based diarization baseline system on all 2-speaker short-form scenarios and has the capability to generalize to audio lengths of 5 minutes. Although 3+speaker co
    
[^3]: 分布式主动假设测试的深度多智能体强化学习

    Deep Multi-Agent Reinforcement Learning for Decentralized Active Hypothesis Testing. (arXiv:2309.08477v1 [stat.ML])

    [http://arxiv.org/abs/2309.08477](http://arxiv.org/abs/2309.08477)

    这个论文提出了一个分布式主动假设测试（AHT）问题的解决方法，通过多智能体强化学习，设计一个策略来在有限通信通道上合作完成任务，将贝叶斯风险最小化。

    

    我们考虑了分布式主动假设测试（AHT）问题的一个分布式形式，在这个问题中，多个智能体从环境中收集到带噪声的观测数据，目的是识别出正确的假设。在每个时间步骤中，智能体可以选择一个采样动作，这些不同的动作会导致从不同分布中抽取观测数据，每个分布与一个特定的假设相关联。智能体通过在有限速率的通信通道上进行消息交换来合作完成任务。目标是设计一个多智能体策略，将贝叶斯风险最小化。这种风险包括采样成本和智能体在声明假设时产生的联合终端成本。在AHT问题中推导出最优的结构化策略通常在数学上是难以处理的，即使是在单个智能体的背景下也是如此。因此，最近的研究工作转向深度学习方法来解决这些问题，这些方法包括...

    We consider a decentralized formulation of the active hypothesis testing (AHT) problem, where multiple agents gather noisy observations from the environment with the purpose of identifying the correct hypothesis. At each time step, agents have the option to select a sampling action. These different actions result in observations drawn from various distributions, each associated with a specific hypothesis. The agents collaborate to accomplish the task, where message exchanges between agents are allowed over a rate-limited communications channel. The objective is to devise a multi-agent policy that minimizes the Bayes risk. This risk comprises both the cost of sampling and the joint terminal cost incurred by the agents upon making a hypothesis declaration. Deriving optimal structured policies for AHT problems is generally mathematically intractable, even in the context of a single agent. As a result, recent efforts have turned to deep learning methodologies to address these problems, whi
    
[^4]: 数据驱动天气预报模型的局限性研究

    On the limitations of data-driven weather forecasting models. (arXiv:2309.08473v1 [stat.ML])

    [http://arxiv.org/abs/2309.08473](http://arxiv.org/abs/2309.08473)

    数据驱动的机器学习天气预报模型不具备传统基于物理的模型的准确性和物理一致性，它们在预测技能上的优势很大程度上可以归因于这些特殊性。

    

    机器学习在天气和气候预测领域产生了深远影响。最近的发展是数据驱动的机器学习预测模型的出现，它们通常声称比传统的基于物理的模型具有更高的性能。在这项工作中，我们研究了当前一代机器学习模型之一Pangu-Weather的预测方面的一些问题，重点关注预测的准确性和物理一致性以及这些特征与感知预测性能之间的关系。主要结论是Pangu-Weather的预测，以及类似的机器学习模型，不具备基于物理的模型的准确性和物理一致性，而它们在传统的确定性预测技能指标上的优势很大程度上可以归因于这些特殊性。与其他当前的后处理技术类似。

    As in many other areas of engineering and applied science, Machine Learning (ML) is having a profound impact in the domain of Weather and Climate Prediction. A very recent development in this area has been the emergence of fully data-driven ML prediction models which routinely claim superior performance to that of traditional physics-based models. In this work, we examine some aspects of the forecasts produced by an exemplar of the current generation of ML models, Pangu-Weather, with a focus on the fidelity and physical consistency of those forecasts and how these characteristics relate to perceived forecast performance. The main conclusion is that Pangu-Weather forecasts, and by extension those of similar ML models, do not have the fidelity and physical consistency of physics-based models and their advantage in accuracy on traditional deterministic metrics of forecast skill can be attributed, to a large extent, to these peculiarities. Similarly to other current post-processing technol
    
[^5]: 基于分块注意力编码器-解码器模型的流式语音识别研究

    Chunked Attention-based Encoder-Decoder Model for Streaming Speech Recognition. (arXiv:2309.08436v1 [eess.AS])

    [http://arxiv.org/abs/2309.08436](http://arxiv.org/abs/2309.08436)

    本研究提出了一种基于分块注意力编码器-解码器模型的流式语音识别方法，通过在预定义的固定大小窗口上操作，实现了模型的流式运行。实验结果表明，该模型相比非流式变种具有相当的性能，并且在长篇演讲中具有很好的泛化能力。

    

    我们研究了一种可流式运行的基于注意力的编码器-解码器模型，其中解码器或编码器和解码器都可以在预定义的固定大小的窗口（称为块）上操作。一种特殊的块结束符（EOC）符号从一个块进入到下一个块，有效地替代了传统的序列结束符。这个修改将我们的模型置于一个操作块而不是帧的转换模型，其中EOC对应空白符号。我们进一步探索了标准转换器模型和我们模型之间的其他差异。此外，我们还研究了长篇演讲的泛化能力、束搜索大小和长度规范化等相关方面。通过在Librispeech和TED-LIUM-v2上的实验，并通过连接连续的序列进行长篇试验，我们发现我们的流式模型相比于非流式变种具有竞争性的性能，并且对于长篇演讲非常泛化。

    We study a streamable attention-based encoder-decoder model in which either the decoder, or both the encoder and decoder, operate on pre-defined, fixed-size windows called chunks. A special end-of-chunk (EOC) symbol advances from one chunk to the next chunk, effectively replacing the conventional end-of-sequence symbol. This modification, while minor, situates our model as equivalent to a transducer model that operates on chunks instead of frames, where EOC corresponds to the blank symbol. We further explore the remaining differences between a standard transducer and our model. Additionally, we examine relevant aspects such as long-form speech generalization, beam size, and length normalization. Through experiments on Librispeech and TED-LIUM-v2, and by concatenating consecutive sequences for long-form trials, we find that our streamable model maintains competitive performance compared to the non-streamable variant and generalizes very well to long-form speech.
    
[^6]: 基于IHT的神经网络用于稀疏线性阵列的单快照DOA估计

    IHT-Inspired Neural Network for Single-Snapshot DOA Estimation with Sparse Linear Arrays. (arXiv:2309.08429v1 [eess.SP])

    [http://arxiv.org/abs/2309.08429](http://arxiv.org/abs/2309.08429)

    本文提出了一种基于IHT的神经网络方法，用于在汽车环境中利用稀疏线性阵列进行单快照DOA估计。该方法通过循环神经网络结构对IHT算法进行参数化，并通过浅层自编码器替代t-SVD来降低计算成本。

    

    在汽车MIMO雷达领域，使用稀疏线性阵列(SLAs)进行单快照方向到达(DOA)估计引起了重要关注。这是因为在汽车环境中，多个快照往往无法获取，并且减少硬件成本非常重要。现有的方法利用低秩Hankel矩阵完成来插值SLAs中的丢失元素。然而，矩阵完成的求解器，例如迭代硬阈值(IHT)，在超参数调整方面非常依赖专业知识，并且缺乏任务特异性。此外，IHT涉及截断奇异值分解(t-SVD)，在每次迭代中计算成本很高。本文提出了一种基于IHT的神经网络，用于SLAs的单快照DOA估计，称为IHT-Net。我们利用循环神经网络结构对IHT算法进行参数化。此外，我们还集成了浅层自编码器来替代t-SVD，从而降低了计算成本。

    Single-snapshot direction-of-arrival (DOA) estimation using sparse linear arrays (SLAs) has gained significant attention in the field of automotive MIMO radars. This is due to the dynamic nature of automotive settings, where multiple snapshots aren't accessible, and the importance of minimizing hardware costs. Low-rank Hankel matrix completion has been proposed to interpolate the missing elements in SLAs. However, the solvers of matrix completion, such as iterative hard thresholding (IHT), heavily rely on expert knowledge of hyperparameter tuning and lack task-specificity. Besides, IHT involves truncated-singular value decomposition (t-SVD), which has high computational cost in each iteration. In this paper, we propose an IHT-inspired neural network for single-snapshot DOA estimation with SLAs, termed IHT-Net. We utilize a recurrent neural network structure to parameterize the IHT algorithm. Additionally, we integrate shallow-layer autoencoders to replace t-SVD, reducing computational 
    
[^7]: 不受限的平滑有向无环图结构学习

    Constraint-Free Structure Learning with Smooth Acyclic Orientations. (arXiv:2309.08406v1 [cs.LG])

    [http://arxiv.org/abs/2309.08406](http://arxiv.org/abs/2309.08406)

    本文提出了一种无约束的连续优化方案COSMO，用于非环结构学习。通过定义一个可微近似的方向矩阵，并使用单一优先向量进行参数化，我们可以得到一个平滑的方向矩阵和相应的非环邻接矩阵，而无需在任何步骤中评估非环性。尽管没有显式约束，但我们证明COSMO始终收敛到一个非环解。这种方法不仅渐近快速，而且比其他有约束方法具有更小的误差。

    

    结构学习问题是将由有向无环图（DAG）生成的数据正确地重构其弧的问题。在这种情况下，可微化方法使用连续松弛的非环性质对优化问题进行约束或规范化。评估图的非环性的计算成本与节点数量呈三次方关系，严重影响可扩展性。本文介绍了COSMO，一种无约束连续优化方案，用于非环结构学习。在我们的方法的核心，我们定义了一个可微近似的方向矩阵，其由一个优先向量参数化。与以前的工作不同，我们的参数化得到了一个平滑的方向矩阵和相应的非环邻接矩阵，而不需要在任何步骤中评估非环性。尽管没有显式约束，我们证明COSMO始终收敛到一个非环解。除了渐近快速外，我们的经验分析还表明COSMO与其他有约束方法相比具有更小的误差。

    The structure learning problem consists of fitting data generated by a Directed Acyclic Graph (DAG) to correctly reconstruct its arcs. In this context, differentiable approaches constrain or regularize the optimization problem using a continuous relaxation of the acyclicity property. The computational cost of evaluating graph acyclicity is cubic on the number of nodes and significantly affects scalability. In this paper we introduce COSMO, a constraint-free continuous optimization scheme for acyclic structure learning. At the core of our method, we define a differentiable approximation of an orientation matrix parameterized by a single priority vector. Differently from previous work, our parameterization fits a smooth orientation matrix and the resulting acyclic adjacency matrix without evaluating acyclicity at any step. Despite the absence of explicit constraints, we prove that COSMO always converges to an acyclic solution. In addition to being asymptotically faster, our empirical ana
    
[^8]: 异方差拟合置信回归

    Heteroskedastic conformal regression. (arXiv:2309.08313v1 [stat.ML])

    [http://arxiv.org/abs/2309.08313](http://arxiv.org/abs/2309.08313)

    本文研究了使用标准化和Mondrian符合规范的方法如何构建自适应的预测区间，以解决回归问题中的异方差噪声。

    

    符合规范的预测以及特定的拆分符合规范的预测提供了一种无分布的方法来估计具有统计保证的预测区间。最近的研究表明，当专注于边际覆盖时，即在校准数据集上，该方法产生的预测区间平均包含预定义覆盖水平的真实值，拆分符合规范的预测可以产生最先进的预测区间。然而，这样的区间通常不是自适应的，这对于具有异方差噪声的回归问题可能是有问题的。本文试图阐明如何使用标准化和Mondrian符合规范的方法来构建自适应的预测区间。我们以系统的方式提出理论和实验结果来研究这些方法。

    Conformal prediction, and split conformal prediction as a specific implementation, offer a distribution-free approach to estimating prediction intervals with statistical guarantees. Recent work has shown that split conformal prediction can produce state-of-the-art prediction intervals when focusing on marginal coverage, i.e., on a calibration dataset the method produces on average prediction intervals that contain the ground truth with a predefined coverage level. However, such intervals are often not adaptive, which can be problematic for regression problems with heteroskedastic noise. This paper tries to shed new light on how adaptive prediction intervals can be constructed using methods such as normalized and Mondrian conformal prediction. We present theoretical and experimental results in which these methods are investigated in a systematic way.
    
[^9]: 无需采样的概率深度状态空间模型

    Sampling-Free Probabilistic Deep State-Space Models. (arXiv:2309.08256v1 [cs.LG])

    [http://arxiv.org/abs/2309.08256](http://arxiv.org/abs/2309.08256)

    本文提出了一种无需采样的概率深度状态空间模型，通过使用第一个确定性推断算法，实现了高效的训练和测试近似。

    

    很多现实世界中的动态系统可以用状态空间模型（SSM）来描述。在这种表述中，每个观察值都由一个潜在状态发射，该状态遵循一阶马尔可夫动力学。概率深度状态空间模型（ProDSSM）将这一框架推广到未知参数形式的动态系统中，其中过渡模型和发射模型由具有不确定权重的神经网络描述。本文提出了针对这类模型的第一个确定性推断算法。我们的框架可以进行高效的训练和测试近似。在实验中，我们证明我们的新方法可以用于各种任务，并在预测性能和计算预算之间取得了卓越的平衡。

    Many real-world dynamical systems can be described as State-Space Models (SSMs). In this formulation, each observation is emitted by a latent state, which follows first-order Markovian dynamics. A Probabilistic Deep SSM (ProDSSM) generalizes this framework to dynamical systems of unknown parametric form, where the transition and emission models are described by neural networks with uncertain weights. In this work, we propose the first deterministic inference algorithm for models of this type. Our framework allows efficient approximations for training and testing. We demonstrate in our experiments that our new method can be employed for a variety of tasks and enjoys a superior balance between predictive performance and computational budget.
    
[^10]: 带有Beta散度的深度非负矩阵分解

    Deep Nonnegative Matrix Factorization with Beta Divergences. (arXiv:2309.08249v1 [cs.LG])

    [http://arxiv.org/abs/2309.08249](http://arxiv.org/abs/2309.08249)

    本文提出了一种使用Beta散度的深度非负矩阵分解方法，应用于面部特征提取、文档主题识别和高光谱图像材料识别。

    

    深度非负矩阵分解（deep NMF）最近成为一种有价值的技术，用于在不同尺度上提取多层特征。然而，所有现有的深度NMF模型和算法主要都以最小二乘误差为评估标准，这可能不是评估多样化数据集近似质量的最合适指标。例如，当处理音频信号和文档等数据类型时，广泛认可的是$\beta$-divergences提供了更适合的替代方案。本文基于$\beta$-divergences开发了新的深度NMF模型和算法，并将这些技术应用于面部特征提取、文档集合中的主题识别以及高光谱图像中材料的识别。

    Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a valuable technique for extracting multiple layers of features across different scales. However, all existing deep NMF models and algorithms have primarily centered their evaluation on the least squares error, which may not be the most appropriate metric for assessing the quality of approximations on diverse datasets. For instance, when dealing with data types such as audio signals and documents, it is widely acknowledged that $\beta$-divergences offer a more suitable alternative. In this paper, we develop new models and algorithms for deep NMF using $\beta$-divergences. Subsequently, we apply these techniques to the extraction of facial features, the identification of topics within document collections, and the identification of materials within hyperspectral images.
    
[^11]: 基于持续同调的拓扑Node2vec：增强图嵌入方法

    Topological Node2vec: Enhanced Graph Embedding via Persistent Homology. (arXiv:2309.08241v1 [stat.ML])

    [http://arxiv.org/abs/2309.08241](http://arxiv.org/abs/2309.08241)

    通过引入拓扑损失项和适应持续同调度量的熵正则化，我们改进了Node2vec方法，使其能够更好地还原输入图的拓扑结构。

    

    Node2vec是一种图嵌入方法，它学习了加权图每个节点的向量表示，同时尽力保持节点之间的相对距离和全局结构。数值实验表明，Node2vec难以再现输入图的拓扑结构。为了解决这个问题，我们在Node2vec的训练损失中引入了一个拓扑损失项，该损失项试图将生成的嵌入的持续同调图与输入图的持续同调图尽可能地对齐。我们根据计算优化传输中的结果，精心调整了熵正则化的持续同调度量，使我们能够以可微分的方式衡量持续同调图之间的差异。通过梯度下降最小化我们修改后的损失函数，可以重建输入图的几何和拓扑结构。我们使用一些示例合成图展示了这种方法的好处。

    Node2vec is a graph embedding method that learns a vector representation for each node of a weighted graph while seeking to preserve relative proximity and global structure. Numerical experiments suggest Node2vec struggles to recreate the topology of the input graph. To resolve this we introduce a topological loss term to be added to the training loss of Node2vec which tries to align the persistence diagram (PD) of the resulting embedding as closely as possible to that of the input graph. Following results in computational optimal transport, we carefully adapt entropic regularization to PD metrics, allowing us to measure the discrepancy between PDs in a differentiable way. Our modified loss function can then be minimized through gradient descent to reconstruct both the geometry and the topology of the input graph. We showcase the benefits of this approach using demonstrative synthetic examples.
    
[^12]: 我们需要多少个神经元？用梯度下降训练的浅层网络的精细分析

    How many Neurons do we need? A refined Analysis for Shallow Networks trained with Gradient Descent. (arXiv:2309.08044v1 [stat.ML])

    [http://arxiv.org/abs/2309.08044](http://arxiv.org/abs/2309.08044)

    本论文在神经切向核（NTK）范式下，通过分析用梯度下降训练的两层神经网络的泛化性质，改进了现有结果，并得出了快速收敛的速度。此外，我们证明了训练过程中权重保持在初始位置附近，半径与回归函数的平滑度和NTK的积分算子的特征值衰减程度有关。

    

    我们在神经切向核（NTK）范式下，分析了用梯度下降（GD）训练的两层神经网络的泛化性质。对于早停的GD，我们导出了快速收敛的速度，这在非参数回归和再生核希尔伯特空间的框架中已知是最小值的最优解。在这过程中，我们精确地追踪了泛化所需的隐藏层神经元数量，并改进了现有结果。我们进一步展示了训练过程中权重保持在初始位置附近的情况，其半径取决于回归函数的平滑度和与NTK相关联的积分算子的特征值衰减程度。

    We analyze the generalization properties of two-layer neural networks in the neural tangent kernel (NTK) regime, trained with gradient descent (GD). For early stopped GD we derive fast rates of convergence that are known to be minimax optimal in the framework of non-parametric regression in reproducing kernel Hilbert spaces. On our way, we precisely keep track of the number of hidden neurons required for generalization and improve over existing results. We further show that the weights during training remain in a vicinity around initialization, the radius being dependent on structural assumptions such as degree of smoothness of the regression function and eigenvalue decay of the integral operator associated to the NTK.
    
[^13]: 为学习的ISTA进行不确定性量化

    Uncertainty quantification for learned ISTA. (arXiv:2309.07982v1 [stat.ML])

    [http://arxiv.org/abs/2309.07982](http://arxiv.org/abs/2309.07982)

    本文提出了一种严谨的方法来获得LISTA估计量的置信区间，为模型-based深度学习解决方案中的不确定性提供了理论支持。

    

    近年来，基于模型的深度学习方法在逆问题中已经引起越来越多的关注，因为它们在数值性能和解释性方面都处于最前沿。此外，结合先验领域知识可以使训练更加高效，因为较少的参数数量允许使用较小的数据集进行训练。在这些基于模型的学习技术中，算法展开方案脱颖而出。尽管它们的快速发展与传统的高维统计方法密切相关，但它们缺乏确定性估计，对于不确定性量化的理论仍然存在困难。本文提出了一种严谨的方法来获得LISTA估计量的置信区间，从而为填补这一空白迈出了一步。

    Model-based deep learning solutions to inverse problems have attracted increasing attention in recent years as they bridge state-of-the-art numerical performance with interpretability. In addition, the incorporated prior domain knowledge can make the training more efficient as the smaller number of parameters allows the training step to be executed with smaller datasets. Algorithm unrolling schemes stand out among these model-based learning techniques. Despite their rapid advancement and their close connection to traditional high-dimensional statistical methods, they lack certainty estimates and a theory for uncertainty quantification is still elusive. This work provides a step towards closing this gap proposing a rigorous way to obtain confidence intervals for the LISTA estimator.
    
[^14]: 增强采样方案的掩码非自回归生成建模

    Masked Generative Modeling with Enhanced Sampling Scheme. (arXiv:2309.07945v1 [cs.LG])

    [http://arxiv.org/abs/2309.07945](http://arxiv.org/abs/2309.07945)

    本文提出了一种增强的采样方案 (ESS)，用于掩码非自回归生成建模。该方案能够确保样本的多样性和保真度，并由三个阶段组成：简单迭代解码、关键反向采样和关键重采样。简单迭代解码用于采样标记集，关键反向采样和关键重采样用于掩盖不真实的标记并重建被掩盖的标记，以提高采样的保真度。

    

    本文提出了一种用于掩码非自回归生成建模的新型采样方案。我们分析了TimeVQVAE、MaskGIT和Token-Critic在采样过程中的局限性，并提出了增强采样方案 (ESS) 来克服这些限制。ESS明确确保了样本的多样性和保真度，由三个阶段组成：简单迭代解码、关键反向采样和关键重采样。ESS首先使用MaskGIT中提出的简单迭代解码来采样一个标记集，以确保样本的多样性。然后，标记集经过关键反向采样，掩盖导致不真实样本的标记。在此之后，关键重采样重建被掩盖的标记，直到达到最终采样步骤以确保高度保真度。关键重采样使用来自自我Token-Critic获得的置信度分数更好地衡量采样标记的真实性，而关键反向采样使用量化潜变量空间的结构。

    This paper presents a novel sampling scheme for masked non-autoregressive generative modeling. We identify the limitations of TimeVQVAE, MaskGIT, and Token-Critic in their sampling processes, and propose Enhanced Sampling Scheme (ESS) to overcome these limitations. ESS explicitly ensures both sample diversity and fidelity, and consists of three stages: Naive Iterative Decoding, Critical Reverse Sampling, and Critical Resampling. ESS starts by sampling a token set using the naive iterative decoding as proposed in MaskGIT, ensuring sample diversity. Then, the token set undergoes the critical reverse sampling, masking tokens leading to unrealistic samples. After that, critical resampling reconstructs masked tokens until the final sampling step is reached to ensure high fidelity. Critical resampling uses confidence scores obtained from a self-Token-Critic to better measure the realism of sampled tokens, while critical reverse sampling uses the structure of the quantized latent vector space
    
[^15]: 政策梯度最优相关搜索用于蒙特卡洛模拟和最大最优传输中的方差降低

    Policy Gradient Optimal Correlation Search for Variance Reduction in Monte Carlo simulation and Maximum Optimal Transport. (arXiv:2307.12703v1 [stat.ML])

    [http://arxiv.org/abs/2307.12703](http://arxiv.org/abs/2307.12703)

    该论文提出了一种新的算法，通过引入相关路径来降低蒙特卡洛模拟中的方差，从而估计随机微分方程解的函数。通过政策梯度和强化学习技术，使用深度神经网络近似最优相关函数并进行校准。这与最大最优传输问题有关。

    

    我们提出了一种用于估计$f(X_T)$的方差降低算法，其中$X$是某个随机微分方程的解，$f$是一个测试函数。新的估计器是$(f(X^1_T) + f(X^2_T))/2$，其中$X^1$和$X^2$具有与$X$相同的边际分布，但路径上存在相关性，以降低方差。最优相关函数$\rho$由深度神经网络近似，并通过政策梯度和强化学习技术在$(X^1, X^2)$的轨迹上进行校准。在给定边际分布的情况下找到最优耦合与最大最优传输有关联。

    We propose a new algorithm for variance reduction when estimating $f(X_T)$ where $X$ is the solution to some stochastic differential equation and $f$ is a test function. The new estimator is $(f(X^1_T) + f(X^2_T))/2$, where $X^1$ and $X^2$ have same marginal law as $X$ but are pathwise correlated so that to reduce the variance. The optimal correlation function $\rho$ is approximated by a deep neural network and is calibrated along the trajectories of $(X^1, X^2)$ by policy gradient and reinforcement learning techniques. Finding an optimal coupling given marginal laws has links with maximum optimal transport.
    
[^16]: Engression: 非线性回归的外推方法

    Engression: Extrapolation for Nonlinear Regression?. (arXiv:2307.00835v1 [stat.ME])

    [http://arxiv.org/abs/2307.00835](http://arxiv.org/abs/2307.00835)

    Engression是一种非线性回归方法，通过使用分布回归技术和预加性噪声模型，在训练样本范围边界外也能可靠地进行外推。

    

    外推对于许多统计学和机器学习应用至关重要，因为常常会遇到超出训练样本范围的测试数据。然而，对于非线性模型来说，外推是一个巨大的挑战。传统模型在这方面通常遇到困难：树集成模型在支持范围外提供连续的预测，而神经网络的预测往往变得不可控。这项工作旨在提供一种非线性回归方法，其可靠性在训练样本范围边界不会立即崩溃。我们的主要贡献是一种名为“engression”的新方法，它是一种预加性噪声模型的分布回归技术，其中噪声添加到协变量上并应用非线性转换。我们的实验结果表明，该模型通常适用于许多真实数据集。我们展示engression可以在一些假设下成功进行外推，例如严格限制噪声大小。

    Extrapolation is crucial in many statistical and machine learning applications, as it is common to encounter test data outside the training support. However, extrapolation is a considerable challenge for nonlinear models. Conventional models typically struggle in this regard: while tree ensembles provide a constant prediction beyond the support, neural network predictions tend to become uncontrollable. This work aims at providing a nonlinear regression methodology whose reliability does not break down immediately at the boundary of the training support. Our primary contribution is a new method called `engression' which, at its core, is a distributional regression technique for pre-additive noise models, where the noise is added to the covariates before applying a nonlinear transformation. Our experimental results indicate that this model is typically suitable for many real data sets. We show that engression can successfully perform extrapolation under some assumptions such as a strictl
    
[^17]: 连续时间线性二次强化学习中熵正则化的最优调度

    Optimal scheduling of entropy regulariser for continuous-time linear-quadratic reinforcement learning. (arXiv:2208.04466v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.04466](http://arxiv.org/abs/2208.04466)

    本研究利用熵正则化的松弛随机控制视角设计了连续时间线性二次强化学习算法，并通过探索性控制方法和近端策略更新方法实现了探索和利用的权衡，以解决有限时间线性二次强化学习问题。

    

    本研究使用熵正则化的松弛随机控制视角作为设计强化学习算法的基础框架。在这里，Agent通过生成符合最优松弛策略的噪声控制与环境进行交互。噪声策略一方面可以探索空间并促进学习，但另一方面也会引入偏差，将正概率分配给非最优动作。这种探索与利用的权衡由熵正则化的强度来确定。我们研究了两种熵正则化形式得到的算法：探索性控制方法，在成本目标中添加熵；近端策略更新方法，在连续的Episode之间对策略差异进行熵惩罚。我们重点研究了有限时间连续时间线性二次强化学习问题，其中具有未知漂移系数的线性动力学受到四次方约束的控制。

    This work uses the entropy-regularised relaxed stochastic control perspective as a principled framework for designing reinforcement learning (RL) algorithms. Herein agent interacts with the environment by generating noisy controls distributed according to the optimal relaxed policy. The noisy policies on the one hand, explore the space and hence facilitate learning but, on the other hand, introduce bias by assigning a positive probability to non-optimal actions. This exploration-exploitation trade-off is determined by the strength of entropy regularisation. We study algorithms resulting from two entropy regularisation formulations: the exploratory control approach, where entropy is added to the cost objective, and the proximal policy update approach, where entropy penalises policy divergence between consecutive episodes. We focus on the finite horizon continuous-time linear-quadratic (LQ) RL problem, where a linear dynamics with unknown drift coefficients is controlled subject to quadr
    
[^18]: GP-BART: 一种使用高斯过程的新型贝叶斯加法回归树方法

    GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes. (arXiv:2204.02112v4 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2204.02112](http://arxiv.org/abs/2204.02112)

    GP-BART是一种使用高斯过程的新型贝叶斯加法回归树方法，相比标准BART模型，它具有更好的平滑性和明确的协方差结构假设，在多种情境下显示出超越传统建模方法的性能。

    

    贝叶斯加法回归树 (BART) 模型是一种集成方法，由于其始终强大的预测性能和量化不确定性的能力，在回归任务中广泛且成功地使用。BART通过一组缩减先验将“弱”树模型组合起来，其中每个树解释了数据中的一小部分变异性。然而，标准BART模型中缺乏平滑性并且对观测值之间的协方差结构没有明确假设，这在需要这些假设的情况下可能导致性能较差。高斯过程贝叶斯加法回归树 (GP-BART) 模型是对BART的扩展，它通过假设每个终端节点的预测服从高斯过程先验来解决这一限制。通过对模拟和实际数据的应用来证明了模型的有效性，在各种情境下超越了传统建模方法的性能。

    The Bayesian additive regression trees (BART) model is an ensemble method extensively and successfully used in regression tasks due to its consistently strong predictive performance and its ability to quantify uncertainty. BART combines "weak" tree models through a set of shrinkage priors, whereby each tree explains a small portion of the variability in the data. However, the lack of smoothness and the absence of an explicit covariance structure over the observations in standard BART can yield poor performance in cases where such assumptions would be necessary. The Gaussian processes Bayesian additive regression trees (GP-BART) model is an extension of BART which addresses this limitation by assuming Gaussian process (GP) priors for the predictions of each terminal node among all trees. The model's effectiveness is demonstrated through applications to simulated and real-world data, surpassing the performance of traditional modeling approaches in various scenarios.
    
[^19]: 使用边际积分基系统的高效多维函数数据分析

    Efficient Multidimensional Functional Data Analysis Using Marginal Product Basis Systems. (arXiv:2107.14728v4 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2107.14728](http://arxiv.org/abs/2107.14728)

    本文提出了一个用于高效处理多维函数数据的方法，通过使用一组优化适应数据的可分离基函数构建连续表示。利用观测数据的降维转换和张量分解，可以有效解决估计问题。同时，引入基于粗糙度的正则化以应对维度灾难。

    

    许多现代数据集，如神经影像学和地理统计学，是张量值数据的随机样本，可以理解为平滑多维随机函数的噪声观测。大多数传统的函数数据分析技术受到维度灾难的困扰，随着域的维度增加，很快变得难以处理。本文提出了一个框架，用于从多维函数数据样本中学习连续表示，这个框架对维度灾难的几种表现具有免疫性。这些表示使用一组可分离的基函数构建，这些基函数被定义为对数据最佳适应。我们通过观测数据的精心定义的降维转换的张量分解来高效解决所得到的估计问题。基于粗糙度的正则化使用一类基于微分算子的惩罚引入。

    Many modern datasets, from areas such as neuroimaging and geostatistics, come in the form of a random sample of tensor-valued data which can be understood as noisy observations of a smooth multidimensional random function. Most of the traditional techniques from functional data analysis are plagued by the curse of dimensionality and quickly become intractable as the dimension of the domain increases. In this paper, we propose a framework for learning continuous representations from a sample of multidimensional functional data that is immune to several manifestations of the curse. These representations are constructed using a set of separable basis functions that are defined to be optimally adapted to the data. We show that the resulting estimation problem can be solved efficiently by the tensor decomposition of a carefully defined reduction transformation of the observed data. Roughness-based regularization is incorporated using a class of differential operator-based penalties. Relevan
    

