# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Karhunen-Lo\`eve Data Imputation in High Contrast Imaging.](http://arxiv.org/abs/2308.16912) | 本论文提出了一种用于高对比度成像中的数据插值方法，通过修改标准Karhunen-Lo\`eve图像投影方法，实现了散斑去除并得到了高质量的成像结果。 |
| [^2] | [Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs.](http://arxiv.org/abs/2308.16859) | 本文研究了学习动态有向无环图（DDAG）的信息理论最优样本复杂度，提出了一种基于观测时间序列的功率谱密度矩阵的度量和算法来重建DDAG。 |
| [^3] | [Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness.](http://arxiv.org/abs/2308.16681) | 通过多元宇宙分析评估模型设计决策对算法公平性的影响，可以揭示算法决策系统中设计决策的关键作用。 |
| [^4] | [Branches of a Tree: Taking Derivatives of Programs with Discrete and Branching Randomness in High Energy Physics.](http://arxiv.org/abs/2308.16680) | 该论文提出了应用多种梯度估计技术实现对具有离散和分支随机性的程序进行求导的方法，并发展了首个完全可微分的分支程序，这项工作的贡献在于为高能物理中的梯度优化提供了新的可能性。 |
| [^5] | [Learning Channel Importance for High Content Imaging with Interpretable Deep Input Channel Mixing.](http://arxiv.org/abs/2308.16637) | 该论文提出了一种利用多光谱信息解释高内容成像中细胞生物学的新方法，通过对任意数量的通道进行图像合成和处理，解决了深度学习方法缺乏通道重要性信息的问题。 |
| [^6] | [Forecasting Emergency Department Crowding with Advanced Machine Learning Models and Multivariable Input.](http://arxiv.org/abs/2308.16544) | 本研究使用高级机器学习模型和多变量输入来预测急诊室拥挤，发现N-BEATS和LightGBM相较于基准模型分别提供了11%和9%的性能改进。 |
| [^7] | [Least Squares Maximum and Weighted Generalization-Memorization Machines.](http://arxiv.org/abs/2308.16456) | 本文提出了一种记忆影响机制用于最小二乘支持向量机，能够准确划分训练集并避免过拟合，提出的最大记忆影响模型和加权记忆影响模型在泛化性能和时间成本方面具有优势。 |
| [^8] | [On the Equivalence between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint.](http://arxiv.org/abs/2308.16425) | 本文研究了高维隐式神经网络，提供了共轭核和神经切向核的高维等价表达，并在高维空间建立了隐式网络和显式网络的等价性。 |
| [^9] | [A stochastic block model for community detection in attributed networks.](http://arxiv.org/abs/2308.16382) | 本文提出了一种基于属性网络的社区检测方法，使用了集成节点介数中心度和聚类系数的随机块模型。与其他方法不同的是，该模型还考虑了社区之间的概率，可以检测多方结构和混合结构。 |
| [^10] | [Multiple Augmented Reduced Rank Regression for Pan-Cancer Analysis.](http://arxiv.org/abs/2308.16333) | 多增强缩减秩回归（maRRR）是一种灵活的矩阵回归和分解方法，用于同时学习协变驱动和辅助结构化变异。通过组合多个数据集，maRRR在全癌症分析中实现了显著的功率增益。 |
| [^11] | [Calibrated Explanations for Regression.](http://arxiv.org/abs/2308.16245) | 本文介绍了一种针对回归问题的特征重要性解释方法的扩展，可以量化特征重要性的不确定性。 |
| [^12] | [High Dimensional Time Series Regression Models: Applications to Statistical Learning Methods.](http://arxiv.org/abs/2308.16192) | 这篇论文概述了高维时间序列回归模型的方法和最新发展，包括相关数据的极限理论结果、与许多协变量的时间序列回归模型相关的渐近理论和统计学习方法的多种应用。 |
| [^13] | [Temporal-spatial model via Trend Filtering.](http://arxiv.org/abs/2308.16172) | 本研究通过趋势滤波方法对具有时空依赖性的数据进行了非参数回归函数的估计，研究了该方法在单变量和多变量情况下的应用，并验证了其极小化性。研究发现了以往未曾探索的独特相变现象，并通过仿真和实际数据应用验证了方法的优越性能。 |
| [^14] | [Multi-Response Heteroscedastic Gaussian Process Models and Their Inference.](http://arxiv.org/abs/2308.15370) | 本文介绍了多响应异方差高斯过程模型，将其应用于回归、分类和状态空间模型，并提出了一种利用变分推断来近似后验的方法，解决了高斯过程模型在捕捉函数平滑性的突变和适应异方差错误方面的局限性。 |
| [^15] | [Biclustering Methods via Sparse Penalty.](http://arxiv.org/abs/2308.14388) | 本文提出了一种基于稀疏惩罚的双聚类方法，主要关注了SSVD方法，并尝试了一种新的稀疏惩罚方法。模拟研究结果表明混合的Prenet惩罚对于非重叠数据非常有效。 |
| [^16] | [Hypergraph Structure Inference From Data Under Smoothness Prior.](http://arxiv.org/abs/2308.14172) | 本文提出了一种光滑性先验方法，用于从节点特征中推断超图的结构，并捕捉数据内在的关系。该方法不需要标记数据作为监督，能够推断出每个潜在超边的概率。 |
| [^17] | [Generative Sliced MMD Flows with Riesz Kernels.](http://arxiv.org/abs/2305.11463) | 本文使用Riesz核展示了生成式分割MMD流的高效计算方法，实现了在大规模应用中通过神经网络训练生成模型。 |
| [^18] | [A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks.](http://arxiv.org/abs/2304.14994) | 本文提出了一种用神经网络求解初值偏微分方程的稳定可扩展方法，解决了在全局最小化神经网络参数中的 PDE 残差中遇到的灾难性遗忘和 ODE 方法中随着数量呈立方级别扩展等问题。 |
| [^19] | [StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space.](http://arxiv.org/abs/2303.05102) | StyleDiff是一种在潜在解缠空间中比较未标记数据集属性差异的方法，可以帮助开发人员了解两个数据集的差异，并以易于理解的方式提供分析。方法具有高效性能和准确性。 |
| [^20] | [On-Demand Communication for Asynchronous Multi-Agent Bandits.](http://arxiv.org/abs/2302.07446) | 本文研究了一种协作多智能体多臂赌博问题，提出了一种按需通信协议ODC，可以根据智能体的经验拉动时间调整每对智能体间的通信，同时将ODC集成到UCB和AAE算法的自然扩展中，提出了两种通信效率高的协作算法，分析表明这两个算法在遗憾方面都接近最优。 |
| [^21] | [Invertible normalizing flow neural networks by JKO scheme.](http://arxiv.org/abs/2212.14424) | 本文提出了一种基于JKO方案的可逆归一化流神经网络，通过按块进行残差块的训练，减少了内存负载和深度流网络训练的难度。并且通过自适应时间重新参数化的流网络，在概率空间中逐步细化轨迹，从而提高了模型的训练效率和准确性。 |
| [^22] | [GRASP: A Goodness-of-Fit Test for Classification Learning.](http://arxiv.org/abs/2209.02064) | 本文提出了一种适合度检验方法GRASP，用于评估通用二分类器对给定特征向量的标签的条件概率分布的拟合程度。 |
| [^23] | [Leveraging Image-based Generative Adversarial Networks for Time Series Generation.](http://arxiv.org/abs/2112.08060) | 本文提出了一种基于图像的生成对抗网络用于时间序列生成的方法，通过引入拓展的时间序列间隔回报图（XIRP）作为二维图像表示，能够以尺度不变和可逆的方式捕捉时间序列的动态特性，从而在降低训练时间和提高样本质量方面取得显著优势。通过与其他图像表示方法和模型的比较，验证了该方法在预测能力方面的优越性。同时，引入了改进的随机反演方法以改善时间序列的重建效果。 |
| [^24] | [Approximate Bayesian inference from noisy likelihoods with Gaussian process emulated MCMC.](http://arxiv.org/abs/2104.03942) | 我们提出了一种使用高斯过程来模拟具有噪声似然的近似贝叶斯推断的方法。通过选择具有信息量的对数似然评估位置，我们能够准确地模拟出精确的Metropolis-Hastings采样器的路径，从而实现了计算效率高且对GP建模假设违反更鲁棒的近似采样器。 |

# 详细

[^1]: Karhunen-Lo\`eve高对比度成像中的数据插值

    Karhunen-Lo\`eve Data Imputation in High Contrast Imaging. (arXiv:2308.16912v1 [astro-ph.IM])

    [http://arxiv.org/abs/2308.16912](http://arxiv.org/abs/2308.16912)

    本论文提出了一种用于高对比度成像中的数据插值方法，通过修改标准Karhunen-Lo\`eve图像投影方法，实现了散斑去除并得到了高质量的成像结果。

    

    在高对比度成像中，检测和表征扩展结构是一个至关重要的目标。然而，这些结构在数据降噪方面面临挑战，导致了从散斑和自相减的过度减法以及大多数现有方法的光注入。迭代后处理方法提供了有希望的结果，但它们的集成到现有的流程中受到选择性算法、高计算成本和算法正则化的阻碍。为了解决这个问题，在参考差分成像（RDI）中，我们提出了以Karhunen-Lo\`eve变换（DIKL）为基础的数据插值概念，通过修改标准Karhunen-Lo\`eve图像投影（KLIP）方法中的两个步骤。具体而言，我们将图像分割为两个矩阵：一个锚定矩阵，仅关注散斑以获得DIKL系数，以及一个船型矩阵，专注于天体物理兴趣区域，使用DIKL成分进行散斑去除。作为一种分析方法，DIKL取得了高质量的结果，具有显著的效果。

    Detection and characterization of extended structures is a crucial goal in high contrast imaging. However, these structures face challenges in data reduction, leading to over-subtraction from speckles and self-subtraction with most existing methods. Iterative post-processing methods offer promising results, but their integration into existing pipelines is hindered by selective algorithms, high computational cost, and algorithmic regularization. To address this for reference differential imaging (RDI), here we propose the data imputation concept to Karhunen-Lo\`eve transform (DIKL) by modifying two steps in the standard Karhunen-Lo\`eve image projection (KLIP) method. Specifically, we partition an image to two matrices: an anchor matrix which focuses only on the speckles to obtain the DIKL coefficients, and a boat matrix which focuses on the regions of astrophysical interest for speckle removal using DIKL components. As an analytical approach, DIKL achieves high-quality results with sig
    
[^2]: 学习动态有向无环图的信息理论最优样本复杂度

    Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs. (arXiv:2308.16859v1 [stat.ML])

    [http://arxiv.org/abs/2308.16859](http://arxiv.org/abs/2308.16859)

    本文研究了学习动态有向无环图（DDAG）的信息理论最优样本复杂度，提出了一种基于观测时间序列的功率谱密度矩阵的度量和算法来重建DDAG。

    

    本文研究了学习线性动态系统（LDS）在有向无环图（DAG）上的底层相互作用/依赖关系的最优样本复杂度。学习DAG结构的样本复杂度在静态系统中已经得到了很好的研究，其中节点状态的样本是独立同分布的（i.i.d.）。然而，在具有动态系统的DAG中，这样的研究较少。我们将这样的DAG称为\emph{动态}DAG（DDAG）。具体来说，我们考虑了一个DDAG，其中节点动力学由未观测的外生噪声源驱动，这些噪声源在时间上是宽幅平稳的（WSS），但彼此之间是不相关的，并且具有相同的功率谱密度（PSD）。受静态设置的启发，我们提出了一种基于观测时间序列的PSD矩阵的度量和算法来重建DDAG。噪声PSD相等的假设可以放宽，以使其可识别。

    In this article, the optimal sample complexity of learning the underlying interaction/dependencies of a Linear Dynamical System (LDS) over a Directed Acyclic Graph (DAG) is studied. The sample complexity of learning a DAG's structure is well-studied for static systems, where the samples of nodal states are independent and identically distributed (i.i.d.). However, such a study is less explored for DAGs with dynamical systems, where the nodal states are temporally correlated. We call such a DAG underlying an LDS as \emph{dynamical} DAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are driven by unobserved exogenous noise sources that are wide-sense stationary (WSS) in time but are mutually uncorrelated, and have the same {power spectral density (PSD)}. Inspired by the static settings, a metric and an algorithm based on the PSD matrix of the observed time series are proposed to reconstruct the DDAG. The equal noise PSD assumption can be relaxed such that identifiabil
    
[^3]: 通过多元宇宙分析评估模型设计决策对算法公平性的影响：一切，无处不在，全方位评估

    Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness. (arXiv:2308.16681v1 [stat.ML])

    [http://arxiv.org/abs/2308.16681](http://arxiv.org/abs/2308.16681)

    通过多元宇宙分析评估模型设计决策对算法公平性的影响，可以揭示算法决策系统中设计决策的关键作用。

    

    全球范围内的许多系统都利用算法决策来（部分）自动化以前由人类进行的决策。当设计良好时，这些系统承诺更客观的决策，同时节省大量资源，节约人力。然而，当算法决策系统设计不良时，可能会导致对社会群体进行歧视的不公平决策。算法决策系统的下游效应在很大程度上取决于系统设计和实施过程中的决策，因为数据中的偏见可能会在建模过程中缓解或加强。许多这些设计决策是隐含进行的，不知道它们确切地如何影响最终系统。因此，明确算法决策系统设计中的决策并了解这些决策如何影响结果系统的公平性非常重要。为了研究这个问题，我们借鉴了心理学领域的见解，并引入了多元宇宙分析方法。

    A vast number of systems across the world use algorithmic decision making (ADM) to (partially) automate decisions that have previously been made by humans. When designed well, these systems promise more objective decisions while saving large amounts of resources and freeing up human time. However, when ADM systems are not designed well, they can lead to unfair decisions which discriminate against societal groups. The downstream effects of ADMs critically depend on the decisions made during the systems' design and implementation, as biases in data can be mitigated or reinforced along the modeling pipeline. Many of these design decisions are made implicitly, without knowing exactly how they will influence the final system. It is therefore important to make explicit the decisions made during the design of ADM systems and understand how these decisions affect the fairness of the resulting system.  To study this issue, we draw on insights from the field of psychology and introduce the metho
    
[^4]: 树的分支：在高能物理中对具有离散和分支随机性的程序进行求导

    Branches of a Tree: Taking Derivatives of Programs with Discrete and Branching Randomness in High Energy Physics. (arXiv:2308.16680v1 [stat.ML])

    [http://arxiv.org/abs/2308.16680](http://arxiv.org/abs/2308.16680)

    该论文提出了应用多种梯度估计技术实现对具有离散和分支随机性的程序进行求导的方法，并发展了首个完全可微分的分支程序，这项工作的贡献在于为高能物理中的梯度优化提供了新的可能性。

    

    我们提出应用多种梯度估计技术来实现对在高能物理中具有离散随机性的程序进行求导。由于存在分支过程和基于聚类的分析，此类程序在高能物理中很常见。因此，对这类程序进行求导可以为梯度优化在探测器设计优化、模拟器调整或数据分析和重构优化等方面开辟道路。我们讨论了几种可能的梯度估计策略，包括最近的随机自动微分（Stochastic AD）方法，并在简化的探测器设计实验中进行了比较。在这样做的过程中，我们开发了迄今为止首个完全可微分的分支程序。

    We propose to apply several gradient estimation techniques to enable the differentiation of programs with discrete randomness in High Energy Physics. Such programs are common in High Energy Physics due to the presence of branching processes and clustering-based analysis. Thus differentiating such programs can open the way for gradient based optimization in the context of detector design optimization, simulator tuning, or data analysis and reconstruction optimization. We discuss several possible gradient estimation strategies, including the recent Stochastic AD method, and compare them in simplified detector design experiments. In doing so we develop, to the best of our knowledge, the first fully differentiable branching program.
    
[^5]: 利用可解释的深度输入通道混合学习高内容成像中的通道重要性

    Learning Channel Importance for High Content Imaging with Interpretable Deep Input Channel Mixing. (arXiv:2308.16637v1 [cs.CV])

    [http://arxiv.org/abs/2308.16637](http://arxiv.org/abs/2308.16637)

    该论文提出了一种利用多光谱信息解释高内容成像中细胞生物学的新方法，通过对任意数量的通道进行图像合成和处理，解决了深度学习方法缺乏通道重要性信息的问题。

    

    发现治疗复杂疾病的新药候选物仍然是早期发现研究中最具挑战性的任务之一。为了解决这个挑战，生物医药研究建立了一个标准化的高内容成像协议，对每个图像通道进行不同的细胞区域标记。为了评判实验结果，科学家需要了解与某种表型相关的通道重要性，以解码潜在的生物学。与传统的图像分析方法相比，这种实验现在更倾向于使用基于深度学习的方法进行分析，然而，这些方法缺乏关于通道重要性的关键信息。为了克服这个局限性，我们提出了一种新方法，利用高内容图像的多光谱信息来解释细胞生物学的某个方面。为此，我们基于图像混合概念和alpha混合方法，对任意数量的通道进行处理。

    Uncovering novel drug candidates for treating complex diseases remain one of the most challenging tasks in early discovery research. To tackle this challenge, biopharma research established a standardized high content imaging protocol that tags different cellular compartments per image channel. In order to judge the experimental outcome, the scientist requires knowledge about the channel importance with respect to a certain phenotype for decoding the underlying biology. In contrast to traditional image analysis approaches, such experiments are nowadays preferably analyzed by deep learning based approaches which, however, lack crucial information about the channel importance. To overcome this limitation, we present a novel approach which utilizes multi-spectral information of high content images to interpret a certain aspect of cellular biology. To this end, we base our method on image blending concepts with alpha compositing for an arbitrary number of channels. More specifically, we in
    
[^6]: 使用高级机器学习模型和多变量输入预测急诊室拥挤

    Forecasting Emergency Department Crowding with Advanced Machine Learning Models and Multivariable Input. (arXiv:2308.16544v1 [cs.LG])

    [http://arxiv.org/abs/2308.16544](http://arxiv.org/abs/2308.16544)

    本研究使用高级机器学习模型和多变量输入来预测急诊室拥挤，发现N-BEATS和LightGBM相较于基准模型分别提供了11%和9%的性能改进。

    

    急诊室拥挤对患者的安全构成重大威胁，并且与增加的死亡率有关。预测未来的服务需求有潜在的患者结果。尽管对这个主题进行了积极的研究，但仍存在几个差距：1）由于快速增加的高级机器学习模型（ML），所提出的预测模型变得过时，2）多变量输入数据的量有限，3）很少报告具体的性能指标。在这项研究中，我们记录了一组先进的ML模型在预测24小时前的急诊室占用率方面的性能。我们使用一个大型综合急诊室的电子健康记录数据和一系列解释变量，包括救治区域医院的床位可用性，来自当地观测站的交通数据，天气变量等。我们展示了N-BEATS和LightGBM在11％和9％的改进中超越了基准，并且DeepAR可以预测第二天的人员状况。

    Emergency department (ED) crowding is a significant threat to patient safety and it has been repeatedly associated with increased mortality. Forecasting future service demand has the potential patient outcomes. Despite active research on the subject, several gaps remain: 1) proposed forecasting models have become outdated due to quick influx of advanced machine learning models (ML), 2) amount of multivariable input data has been limited and 3) discrete performance metrics have been rarely reported. In this study, we document the performance of a set of advanced ML models in forecasting ED occupancy 24 hours ahead. We use electronic health record data from a large, combined ED with an extensive set of explanatory variables, including the availability of beds in catchment area hospitals, traffic data from local observation stations, weather variables, etc. We show that N-BEATS and LightGBM outpeform benchmarks with 11 % and 9 % respective improvements and that DeepAR predicts next day cr
    
[^7]: 最小二乘法最大化和加权泛化记忆机

    Least Squares Maximum and Weighted Generalization-Memorization Machines. (arXiv:2308.16456v1 [stat.ML])

    [http://arxiv.org/abs/2308.16456](http://arxiv.org/abs/2308.16456)

    本文提出了一种记忆影响机制用于最小二乘支持向量机，能够准确划分训练集并避免过拟合，提出的最大记忆影响模型和加权记忆影响模型在泛化性能和时间成本方面具有优势。

    

    本文提出了一种用于最小二乘支持向量机（LSSVM）的记忆影响机制，实现记忆的新方法。在不改变原始LSSVM方程约束的情况下，该机制能够准确地对训练集进行划分，避免过拟合。然后提出了最大记忆影响模型（MIMM）和加权记忆影响模型（WIMM）。实验证明这些模型可以退化为LSSVM。此外，我们还为MIMM和WIMM提出了一些不同的记忆影响函数。实验结果表明，相比于LSSVM，我们的MIMM和WIMM在泛化性能上有更好的表现，并且在时间成本上比其他记忆模型具有明显优势。

    In this paper, we propose a new way of remembering by introducing a memory influence mechanism for the least squares support vector machine (LSSVM). Without changing the equation constraints of the original LSSVM, this mechanism, allows an accurate partitioning of the training set without overfitting. The maximum memory impact model (MIMM) and the weighted impact memory model (WIMM) are then proposed. It is demonstrated that these models can be degraded to the LSSVM. Furthermore, we propose some different memory impact functions for the MIMM and WIMM. The experimental results show that that our MIMM and WIMM have better generalization performance compared to the LSSVM and significant advantage in time cost compared to other memory models.
    
[^8]: 隐式神经网络与显式神经网络的等价性：高维视角

    On the Equivalence between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint. (arXiv:2308.16425v1 [cs.LG])

    [http://arxiv.org/abs/2308.16425](http://arxiv.org/abs/2308.16425)

    本文研究了高维隐式神经网络，提供了共轭核和神经切向核的高维等价表达，并在高维空间建立了隐式网络和显式网络的等价性。

    

    隐式神经网络在各种任务中取得了显著的成功。然而，对于隐式网络和显式网络之间的连接和差异缺乏理论分析。本文研究了高维隐式神经网络，并为对应的共轭核和神经切向核提供了高维等价表达。基于此，我们在高维空间建立了隐式网络和显式网络的等价性。

    Implicit neural networks have demonstrated remarkable success in various tasks. However, there is a lack of theoretical analysis of the connections and differences between implicit and explicit networks. In this paper, we study high-dimensional implicit neural networks and provide the high dimensional equivalents for the corresponding conjugate kernels and neural tangent kernels. Built upon this, we establish the equivalence between implicit and explicit networks in high dimensions.
    
[^9]: 基于属性网络的社区检测的随机块模型

    A stochastic block model for community detection in attributed networks. (arXiv:2308.16382v1 [cs.SI])

    [http://arxiv.org/abs/2308.16382](http://arxiv.org/abs/2308.16382)

    本文提出了一种基于属性网络的社区检测方法，使用了集成节点介数中心度和聚类系数的随机块模型。与其他方法不同的是，该模型还考虑了社区之间的概率，可以检测多方结构和混合结构。

    

    社区检测是复杂网络分析中的重要内容。现有的基于属性网络的社区检测方法大多仅关注网络结构，而集成节点属性的方法主要用于传统的社区结构，无法检测网络中的多方结构和混合结构。此外，目前针对属性网络提出的基于模型的社区检测方法并没有充分考虑节点的独特拓扑信息，例如介数中心度和聚类系数。因此，本文提出了一种集成节点介数中心度和聚类系数的随机块模型用于属性网络的社区检测，称为BCSBM模型。与其他属性网络生成模型不同，BCSBM模型中链接和属性的生成过程遵循泊松分布，并考虑了社区之间的概率。

    Community detection is an important content in complex network analysis. The existing community detection methods in attributed networks mostly focus on only using network structure, while the methods of integrating node attributes is mainly for the traditional community structures, and cannot detect multipartite structures and mixture structures in network. In addition, the model-based community detection methods currently proposed for attributed networks do not fully consider unique topology information of nodes, such as betweenness centrality and clustering coefficient. Therefore, a stochastic block model that integrates betweenness centrality and clustering coefficient of nodes for community detection in attributed networks, named BCSBM, is proposed in this paper. Different from other generative models for attributed networks, the generation process of links and attributes in BCSBM model follows the Poisson distribution, and the probability between community is considered based on 
    
[^10]: 多增强缩减秩回归用于全癌症分析

    Multiple Augmented Reduced Rank Regression for Pan-Cancer Analysis. (arXiv:2308.16333v1 [stat.ME])

    [http://arxiv.org/abs/2308.16333](http://arxiv.org/abs/2308.16333)

    多增强缩减秩回归（maRRR）是一种灵活的矩阵回归和分解方法，用于同时学习协变驱动和辅助结构化变异。通过组合多个数据集，maRRR在全癌症分析中实现了显著的功率增益。

    

    成功结合多个数据集的统计方法比单独分析更强大、高效和科学信息丰富。为了正确和全面地处理高维数据在多个样本集（即队列）中的变化结构，我们提出了多增强缩减秩回归（maRRR），一种灵活的矩阵回归和分解方法，同时学习协变驱动和辅助结构化变异。我们考虑了受随机矩阵理论启发的结构核范数目标，其中回归或分解项可以是共享的，也可以特定于任意数量的队列。我们的框架包含了减少秩回归和无监督多矩阵分解方法等多种现有方法，并将单个数据集（aRRR）的回归和分解作为特例进行了有希望的创新性探索。模拟实验表明，通过组合多个数据集可以获得显著的功率增益。

    Statistical approaches that successfully combine multiple datasets are more powerful, efficient, and scientifically informative than separate analyses. To address variation architectures correctly and comprehensively for high-dimensional data across multiple sample sets (i.e., cohorts), we propose multiple augmented reduced rank regression (maRRR), a flexible matrix regression and factorization method to concurrently learn both covariate-driven and auxiliary structured variation. We consider a structured nuclear norm objective that is motivated by random matrix theory, in which the regression or factorization terms may be shared or specific to any number of cohorts. Our framework subsumes several existing methods, such as reduced rank regression and unsupervised multi-matrix factorization approaches, and includes a promising novel approach to regression and factorization of a single dataset (aRRR) as a special case. Simulations demonstrate substantial gains in power from combining mult
    
[^11]: 回归问题的校准解释

    Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])

    [http://arxiv.org/abs/2308.16245](http://arxiv.org/abs/2308.16245)

    本文介绍了一种针对回归问题的特征重要性解释方法的扩展，可以量化特征重要性的不确定性。

    

    人工智能（AI）通常是现代决策支持系统（DSS）的一部分。在基于AI的DSS中使用的最佳预测模型缺乏透明度。可解释的人工智能（XAI）旨在创建能够向人类用户解释其理由的AI系统。XAI中的局部解释可以提供关于个别预测的原因的信息，即特征重要性。然而，现有局部解释方法的一个关键缺点是无法量化与特征重要性相关的不确定性。本文介绍了特征重要性解释方法Calibrated Explanations（CE）的扩展，之前只支持分类，现在支持标准回归和概率回归，即目标超过任意阈值的概率。回归问题的扩展保留了CE的所有优点，例如将底层模型的预测与置信度校准。

    Artificial Intelligence (AI) is often an integral part of modern decision support systems (DSSs). The best-performing predictive models used in AI-based DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance. However, a critical drawback of existing local explanation methods is their inability to quantify the uncertainty associated with a feature's importance. This paper introduces an extension of a feature importance explanation method, Calibrated Explanations (CE), previously only supporting classification, with support for standard regression and probabilistic regression, i.e., the probability that the target is above an arbitrary threshold. The extension for regression keeps all the benefits of CE, such as calibration of the prediction from the underlying model with confidenc
    
[^12]: 高维时间序列回归模型：应用于统计学习方法的研究

    High Dimensional Time Series Regression Models: Applications to Statistical Learning Methods. (arXiv:2308.16192v1 [econ.EM])

    [http://arxiv.org/abs/2308.16192](http://arxiv.org/abs/2308.16192)

    这篇论文概述了高维时间序列回归模型的方法和最新发展，包括相关数据的极限理论结果、与许多协变量的时间序列回归模型相关的渐近理论和统计学习方法的多种应用。

    

    这些讲稿概述了高维时间序列回归模型的现有方法和最新发展，包括高维相关数据的主要极限理论结果、与许多协变量的时间序列回归模型相关的渐近理论主要方面以及统计学习方法在时间序列分析中的各种应用。

    These lecture notes provide an overview of existing methodologies and recent developments for estimation and inference with high dimensional time series regression models. First, we present main limit theory results for high dimensional dependent data which is relevant to covariance matrix structures as well as to dependent time series sequences. Second, we present main aspects of the asymptotic theory related to time series regression models with many covariates. Third, we discuss various applications of statistical learning methodologies for time series analysis purposes.
    
[^13]: 通过趋势滤波进行时空模型建模

    Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v1 [stat.ME])

    [http://arxiv.org/abs/2308.16172](http://arxiv.org/abs/2308.16172)

    本研究通过趋势滤波方法对具有时空依赖性的数据进行了非参数回归函数的估计，研究了该方法在单变量和多变量情况下的应用，并验证了其极小化性。研究发现了以往未曾探索的独特相变现象，并通过仿真和实际数据应用验证了方法的优越性能。

    

    本研究侧重于对具有同时时间和空间依赖性的数据进行非参数回归函数的估计。在这种情况下，我们研究了趋势滤波，这是一种非参数估计方法，由Mammen和Rudin提出。在单变量设置中，我们考虑的信号假设具有有界总变异度的k次弱导数，允许一定程度的平滑性。在多变量情况下，我们研究了Padilla等人的K最近邻融合套索估计器，采用适用于具有有界变异度且符合分段利普希茨连续性准则的信号的ADMM算法。通过与下界对齐，我们验证了我们估计器的极小化性。通过分析，我们发现了以往趋势滤波研究中未曾探索过的独特相变现象。仿真研究和实际数据应用都突出了我们方法的出色性能。

    This research focuses on the estimation of a non-parametric regression function designed for data with simultaneous time and space dependencies. In such a context, we study the Trend Filtering, a nonparametric estimator introduced by \cite{mammen1997locally} and \cite{rudin1992nonlinear}. For univariate settings, the signals we consider are assumed to have a kth weak derivative with bounded total variation, allowing for a general degree of smoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused lasso estimator as in \cite{padilla2018adaptive}, employing an ADMM algorithm, suitable for signals with bounded variation that adhere to a piecewise Lipschitz continuity criterion. By aligning with lower bounds, the minimax optimality of our estimators is validated. A unique phase transition phenomenon, previously uncharted in Trend Filtering studies, emerges through our analysis. Both Simulation studies and real data applications underscore the superior performance of o
    
[^14]: 多响应异方差高斯过程模型及其推断

    Multi-Response Heteroscedastic Gaussian Process Models and Their Inference. (arXiv:2308.15370v1 [stat.ML])

    [http://arxiv.org/abs/2308.15370](http://arxiv.org/abs/2308.15370)

    本文介绍了多响应异方差高斯过程模型，将其应用于回归、分类和状态空间模型，并提出了一种利用变分推断来近似后验的方法，解决了高斯过程模型在捕捉函数平滑性的突变和适应异方差错误方面的局限性。

    

    尽管高斯过程模型被广泛用于灵活的非参数建模，但它们在有效捕捉函数平滑性的突变和适应异方差错误方面存在局限性。为了解决这些问题，异方差高斯过程（HeGP）回归旨在通过承认回归模型中协变量间残差方差的可变性来引入灵活性。本文将HeGP概念扩展到分类和状态空间模型，并提出了一种新的框架，将高斯过程与协变量诱导的精度矩阵过程相结合，采用混合形式。这种方法使得可以对协变量之间的异方差协方差函数进行建模。为了解决采样带来的计算挑战，我们采用变分推断来近似后验并便利计算。

    Despite the widespread utilization of Gaussian process models for versatile nonparametric modeling, they exhibit limitations in effectively capturing abrupt changes in function smoothness and accommodating relationships with heteroscedastic errors. Addressing these shortcomings, the heteroscedastic Gaussian process (HeGP) regression seeks to introduce flexibility by acknowledging the variability of residual variances across covariates in the regression model. In this work, we extend the HeGP concept, expanding its scope beyond regression tasks to encompass classification and state-space models. To achieve this, we propose a novel framework where the Gaussian process is coupled with a covariate-induced precision matrix process, adopting a mixture formulation. This approach enables the modeling of heteroscedastic covariance functions across covariates. To mitigate the computational challenges posed by sampling, we employ variational inference to approximate the posterior and facilitate p
    
[^15]: 通过稀疏惩罚进行的双聚类方法

    Biclustering Methods via Sparse Penalty. (arXiv:2308.14388v1 [stat.ML])

    [http://arxiv.org/abs/2308.14388](http://arxiv.org/abs/2308.14388)

    本文提出了一种基于稀疏惩罚的双聚类方法，主要关注了SSVD方法，并尝试了一种新的稀疏惩罚方法。模拟研究结果表明混合的Prenet惩罚对于非重叠数据非常有效。

    

    本文首先回顾了几种用于识别基因表达数据中最显著聚类的双聚类方法。我们主要关注了SSVD（稀疏SVD）方法，并尝试了一种仅用于因子分析的新的稀疏惩罚方法，称为"Prenet惩罚"。然后在模拟研究中，我们尝试了不同类型的生成数据集（具有不同的稀疏性和维度），并尝试了一层逼近和k层逼近，结果表明混合的Prenet惩罚对于非重叠数据非常有效。最后，我们使用了一些真实的基因表达数据来展示我们方法的行为。

    In this paper, we first reviewed several biclustering methods that are used to identify the most significant clusters in gene expression data. Here we mainly focused on the SSVD(sparse SVD) method and tried a new sparse penalty named "Prenet penalty" which has been used only in factor analysis to gain sparsity. Then in the simulation study, we tried different types of generated datasets (with different sparsity and dimension) and tried 1-layer approximation then for k-layers which shows the mixed Prenet penalty is very effective for non-overlapped data. Finally, we used some real gene expression data to show the behavior of our methods.
    
[^16]: 从数据中基于光滑性先验推断超图结构

    Hypergraph Structure Inference From Data Under Smoothness Prior. (arXiv:2308.14172v1 [cs.LG])

    [http://arxiv.org/abs/2308.14172](http://arxiv.org/abs/2308.14172)

    本文提出了一种光滑性先验方法，用于从节点特征中推断超图的结构，并捕捉数据内在的关系。该方法不需要标记数据作为监督，能够推断出每个潜在超边的概率。

    

    超图在处理涉及多个实体的高阶关系数据中非常重要。在没有明确超图可用的情况下，希望能够从节点特征中推断出有意义的超图结构，以捕捉数据内在的关系。然而，现有的方法要么采用简单预定义的规则，不能精确捕捉潜在超图结构的分布，要么学习超图结构和节点特征之间的映射，但需要大量标记数据（即预先存在的超图结构）进行训练。这两种方法都局限于实际情景中的应用。为了填补这一空白，我们提出了一种新的光滑性先验，使我们能够设计一种方法，在没有标记数据作为监督的情况下推断出每个潜在超边的概率。所提出的先验表示超边中的节点特征与包含该超边的超边的特征高度相关。

    Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing th
    
[^17]: 利用Riesz核的生成式分割MMD流

    Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v1 [cs.LG])

    [http://arxiv.org/abs/2305.11463](http://arxiv.org/abs/2305.11463)

    本文使用Riesz核展示了生成式分割MMD流的高效计算方法，实现了在大规模应用中通过神经网络训练生成模型。

    

    在大规模计算中，最大平均差异度(MMD)流的计算成本很高。在本文中，我们展示了使用Riesz核$K(x,y)=-\|x-y\|^r$，$r \in (0,2)$的MMD流具有杰出的性质，可允许其进行高效计算。首先，Riesz核的MMD与其分割版本的MMD重合。因此，可以在一维设置中进行MMD梯度的计算。在此处，对于$r=1$，可以应用简单的排序算法将两个经验度量的复杂度从$O(MN+N^2)$降低到$O((M+N)\log(M+N))$，其中$M$和$N$是支持点。对于实现，我们通过仅使用有限数量的$P$个切片来近似分割MMD的梯度。我们展示了由此产生的误差具有$O(\sqrt{d/P})$的复杂度，其中$d$是数据维度。这些结果使我们能够通过神经网络近似MMD梯度流来训练生成模型，甚至用于大规模应用。

    Maximum mean discrepancy (MMD) flows suffer from high computational costs in large scale computations. In this paper, we show that MMD flows with Riesz kernels $K(x,y) = - \|x-y\|^r$, $r \in (0,2)$ have exceptional properties which allow for their efficient computation. First, the MMD of Riesz kernels coincides with the MMD of their sliced version. As a consequence, the computation of gradients of MMDs can be performed in the one-dimensional setting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce the complexity from $O(MN+N^2)$ to $O((M+N)\log(M+N))$ for two empirical measures with $M$ and $N$ support points. For the implementations we approximate the gradient of the sliced MMD by using only a finite number $P$ of slices. We show that the resulting error has complexity $O(\sqrt{d/P})$, where $d$ is the data dimension. These results enable us to train generative models by approximating MMD gradient flows by neural networks even for large scale applications. We demo
    
[^18]: 用神经网络求解初值偏微分方程的稳定可扩展方法

    A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks. (arXiv:2304.14994v1 [cs.LG])

    [http://arxiv.org/abs/2304.14994](http://arxiv.org/abs/2304.14994)

    本文提出了一种用神经网络求解初值偏微分方程的稳定可扩展方法，解决了在全局最小化神经网络参数中的 PDE 残差中遇到的灾难性遗忘和 ODE 方法中随着数量呈立方级别扩展等问题。

    

    与传统的网格和基于网格的方法不同，神经网络有可能打破维数灾难，在使用经典求解器困难或不可能的问题中提供近似解。全局最小化神经网络参数中的 PDE 残差对于边界值问题效果良好，但是灾难性忘却损害了这种方法对于初值问题的适用性。在替代的局部时间方法中，可以将优化问题转化为网络参数上的常微分方程（ODE），并将解向前传播。然而，我们证明了目前基于这种方法的方法存在两个关键问题。首先，遵循 ODE 会导致问题条件增长无法控制，最终导致不可接受的大数值误差。其次，随着 ODE 方法随着 m 的数量呈立方级别扩展。

    Unlike conventional grid and mesh based methods for solving partial differential equations (PDEs), neural networks have the potential to break the curse of dimensionality, providing approximate solutions to problems where using classical solvers is difficult or impossible. While global minimization of the PDE residual over the network parameters works well for boundary value problems, catastrophic forgetting impairs the applicability of this approach to initial value problems (IVPs). In an alternative local-in-time approach, the optimization problem can be converted into an ordinary differential equation (ODE) on the network parameters and the solution propagated forward in time; however, we demonstrate that current methods based on this approach suffer from two key issues. First, following the ODE produces an uncontrolled growth in the conditioning of the problem, ultimately leading to unacceptably large numerical errors. Second, as the ODE methods scale cubically with the number of m
    
[^19]: StyleDiff: 在潜在解缠空间中比较未标记数据集的属性差异

    StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space. (arXiv:2303.05102v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.05102](http://arxiv.org/abs/2303.05102)

    StyleDiff是一种在潜在解缠空间中比较未标记数据集属性差异的方法，可以帮助开发人员了解两个数据集的差异，并以易于理解的方式提供分析。方法具有高效性能和准确性。

    

    机器学习应用中的一个主要挑战是解决开发中使用的数据集与实际应用中获取的数据集之间的不匹配。这些不匹配可能导致预测不准确和错误，进而影响产品质量和系统的可靠性。本研究提出了StyleDiff，以便开发人员了解两个数据集之间的差异，以实现机器学习系统的稳定发展。使用最近提出的生成模型获得的解缠图像空间，StyleDiff通过关注图像中的属性来比较两个数据集，并提供易于理解的差异分析。所提出的StyleDiff的性能为$O(dN\log N)$，其中$N$是数据集的大小，$d$是属性的数量，可以应用于大型数据集。我们证明StyleDiff能准确检测数据集之间的差异，并以易于理解的格式呈现。

    One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for 
    
[^20]: 异步多智能体赌博机的按需通信

    On-Demand Communication for Asynchronous Multi-Agent Bandits. (arXiv:2302.07446v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07446](http://arxiv.org/abs/2302.07446)

    本文研究了一种协作多智能体多臂赌博问题，提出了一种按需通信协议ODC，可以根据智能体的经验拉动时间调整每对智能体间的通信，同时将ODC集成到UCB和AAE算法的自然扩展中，提出了两种通信效率高的协作算法，分析表明这两个算法在遗憾方面都接近最优。

    

    本文研究了一种协作多智能体多臂赌博问题，其中智能体的操作是异步的 - 智能体的拉动时间和速率是未知的、不规则的和异构的 - 并且面对相同的K臂赌博问题的实例。智能体可以共享奖励信息以加快学习过程，但需要额外的通信成本。我们提出了一种按需通信协议ODC，根据智能体的经验拉动时间调整每对智能体间的通信。当智能体的拉动时间高度不均匀时，ODC具有高效性，并且其通信复杂性取决于智能体的经验拉动时间。ODC是一个通用的协议，可以集成到大多数协作赌博算法中而不降低其性能。然后，我们将ODC集成到UCB和AAE算法的自然扩展中，并提出了两种通信效率高的协作算法。我们的分析表明，这两个算法在遗憾方面都接近最优。

    This paper studies a cooperative multi-agent multi-armed stochastic bandit problem where agents operate asynchronously -- agent pull times and rates are unknown, irregular, and heterogeneous -- and face the same instance of a K-armed bandit problem. Agents can share reward information to speed up the learning process at additional communication costs. We propose ODC, an on-demand communication protocol that tailors the communication of each pair of agents based on their empirical pull times. ODC is efficient when the pull times of agents are highly heterogeneous, and its communication complexity depends on the empirical pull times of agents. ODC is a generic protocol that can be integrated into most cooperative bandit algorithms without degrading their performance. We then incorporate ODC into the natural extensions of UCB and AAE algorithms and propose two communication-efficient cooperative algorithms. Our analysis shows that both algorithms are near-optimal in regret.
    
[^21]: 基于JKO方案的可逆归一化流神经网络

    Invertible normalizing flow neural networks by JKO scheme. (arXiv:2212.14424v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.14424](http://arxiv.org/abs/2212.14424)

    本文提出了一种基于JKO方案的可逆归一化流神经网络，通过按块进行残差块的训练，减少了内存负载和深度流网络训练的难度。并且通过自适应时间重新参数化的流网络，在概率空间中逐步细化轨迹，从而提高了模型的训练效率和准确性。

    

    归一化流是一类用于高效采样和密度估计的深度生成模型。实际中，流通常表示为一系列可逆的神经网络模块链; 为了便于训练，现有的工作对流轨迹进行了正则化，并设计了特殊的网络架构。本文提出了受Jordan-Kinderleherer-Otto (JKO)方案启发的神经ODE流网络，它允许有效地按块进行残差块的训练，无需采样SDE轨迹或分数匹配或变分学习的内循环。由于JKO方案展开了梯度流的动态，所提出的模型自然地逐个堆叠残差网络块，降低了内存负载和进行端到端深度流网络训练的难度。我们还开发了自适应时间重新参数化的流网络，通过在概率空间中逐步细化轨迹，提高了模型的训练效率和准确性。

    Normalizing flow is a class of deep generative models for efficient sampling and density estimation. In practice, the flow often appears as a chain of invertible neural network blocks; to facilitate training, existing works have regularized flow trajectories and designed special network architectures. The current paper develops a neural ODE flow network inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which allows efficient block-wise training of the residual blocks without sampling SDE trajectories or inner loops of score matching or variational learning. As the JKO scheme unfolds the dynamic of gradient flow, the proposed model naturally stacks residual network blocks one by one, reducing the memory load and difficulty in performing end-to-end deep flow network training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the trajectory in probability space, which improves the model training efficiency and accuracy in practice.
    
[^22]: GRASP: 一种用于分类学习的适合度检验方法

    GRASP: A Goodness-of-Fit Test for Classification Learning. (arXiv:2209.02064v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2209.02064](http://arxiv.org/abs/2209.02064)

    本文提出了一种适合度检验方法GRASP，用于评估通用二分类器对给定特征向量的标签的条件概率分布的拟合程度。

    

    分类器的性能通常以测试数据的平均准确率衡量。尽管平均准确率是一种标准的衡量方法，但它在描述模型对给定特征向量的标签的条件概率分布的拟合程度方面存在缺陷，例如模型错误规范化、过拟合和高维度等。在本文中，我们考虑了评估通用二分类器拟合程度的基本问题。我们的框架不对条件概率分布$Y|X$进行任何参数假设，并将其视为黑盒子模型，只能通过查询访问。我们将适合度评估问题表述为容忍度假设检验的形式\[ H_0: \mathbb{E}\Big[D_f\Big({\sf Bern}(\eta(X))\|{\sf Bern}(\hat{\eta}(X))\Big)\Big]\leq \tau\,, \]其中$D_f$表示一个$f$-散度函数，$\eta(x)$和$\hat{\eta}(x)$分别表示特征向量$x$的真实和估计的似然度。

    Performance of classifiers is often measured in terms of average accuracy on test data. Despite being a standard measure, average accuracy fails in characterizing the fit of the model to the underlying conditional law of labels given the features vector ($Y|X$), e.g. due to model misspecification, over fitting, and high-dimensionality. In this paper, we consider the fundamental problem of assessing the goodness-of-fit for a general binary classifier. Our framework does not make any parametric assumption on the conditional law $Y|X$, and treats that as a black box oracle model which can be accessed only through queries. We formulate the goodness-of-fit assessment problem as a tolerance hypothesis testing of the form \[ H_0: \mathbb{E}\Big[D_f\Big({\sf Bern}(\eta(X))\|{\sf Bern}(\hat{\eta}(X))\Big)\Big]\leq \tau\,, \] where $D_f$ represents an $f$-divergence function, and $\eta(x)$, $\hat{\eta}(x)$ respectively denote the true and an estimate likelihood for a feature vector $x$ admitting
    
[^23]: 利用基于图像的生成对抗网络进行时间序列生成

    Leveraging Image-based Generative Adversarial Networks for Time Series Generation. (arXiv:2112.08060v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.08060](http://arxiv.org/abs/2112.08060)

    本文提出了一种基于图像的生成对抗网络用于时间序列生成的方法，通过引入拓展的时间序列间隔回报图（XIRP）作为二维图像表示，能够以尺度不变和可逆的方式捕捉时间序列的动态特性，从而在降低训练时间和提高样本质量方面取得显著优势。通过与其他图像表示方法和模型的比较，验证了该方法在预测能力方面的优越性。同时，引入了改进的随机反演方法以改善时间序列的重建效果。

    

    由于生成模型能够从复杂的数据分布中生成逼真的样本，因此在计算机视觉和自然语言处理领域中，基于图像的生成模型引起了广泛关注。为了利用基于图像的生成模型在时间序列领域的进展，我们提出了一种二维图像表示方法，即拓展的时间序列间隔回报图（Extended Intertemporal Return Plot，XIRP）。我们的方法以尺度不变和可逆的方式捕捉了时间序列的动态特性，降低了训练时间并提高了样本质量。我们使用带有梯度惩罚的Wasserstein生成对抗网络（WGAN-GP）对合成的XIRP进行了基准测试，与其他图像表示方法和模型进行了相似性和预测能力指标的比较。我们的创新性、经过验证的时间序列图像表示方法在预测能力方面始终显著优于最先进的基于RNN的生成模型。此外，我们引入了改进的随机反演方法使得重建时间序列的效果更好。

    Generative models for images have gained significant attention in computer vision and natural language processing due to their ability to generate realistic samples from complex data distributions. To leverage the advances of image-based generative models for the time series domain, we propose a two-dimensional image representation for time series, the Extended Intertemporal Return Plot (XIRP). Our approach captures the intertemporal time series dynamics in a scale-invariant and invertible way, reducing training time and improving sample quality. We benchmark synthetic XIRPs obtained by an off-the-shelf Wasserstein GAN with gradient penalty (WGAN-GP) to other image representations and models regarding similarity and predictive ability metrics. Our novel, validated image representation for time series consistently and significantly outperforms a state-of-the-art RNN-based generative model regarding predictive ability. Further, we introduce an improved stochastic inversion to substantial
    
[^24]: 通过高斯过程模拟的MCMC近似贝叶斯推断中的含有噪声似然的近似方法

    Approximate Bayesian inference from noisy likelihoods with Gaussian process emulated MCMC. (arXiv:2104.03942v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2104.03942](http://arxiv.org/abs/2104.03942)

    我们提出了一种使用高斯过程来模拟具有噪声似然的近似贝叶斯推断的方法。通过选择具有信息量的对数似然评估位置，我们能够准确地模拟出精确的Metropolis-Hastings采样器的路径，从而实现了计算效率高且对GP建模假设违反更鲁棒的近似采样器。

    

    我们提出了一种近似贝叶斯推断的框架，当由于计算限制而只能获得有限数量的含有噪声的对数似然评估时，这在复杂模型的应用中越来越常见。我们使用高斯过程（GP）对对数似然函数进行建模，主要的方法创新是将该模型应用于模拟精确的Metropolis-Hastings（MH）采样器如果适用的话将会采取的路径。使用顺序实验设计策略选择具有信息量的对数似然评估位置，直到根据GP模型准确地完成MH接受/拒绝决策。得到的近似采样器在概念上简单且样本效率高。与早期相关的“类贝叶斯优化”方法相比，它对GP建模假设的违反更具鲁棒性，该方法专为贝叶斯推断而设计。我们讨论了一些理论方面和各种结果的解释。

    We present a framework for approximate Bayesian inference when only a limited number of noisy log-likelihood evaluations can be obtained due to computational constraints, which is becoming increasingly common for applications of complex models. We model the log-likelihood function using a Gaussian process (GP) and the main methodological innovation is to apply this model to emulate the progression that an exact Metropolis-Hastings (MH) sampler would take if it was applicable. Informative log-likelihood evaluation locations are selected using a sequential experimental design strategy until the MH accept/reject decision is done accurately enough according to the GP model. The resulting approximate sampler is conceptually simple and sample-efficient. It is also more robust to violations of GP modelling assumptions compared with earlier, related "Bayesian optimisation-like" methods tailored for Bayesian inference. We discuss some theoretical aspects and various interpretations of the resul
    

