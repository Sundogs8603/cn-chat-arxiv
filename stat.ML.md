# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [IW-GAE: Importance weighted group accuracy estimation for improved calibration and model selection in unsupervised domain adaptation.](http://arxiv.org/abs/2310.10611) | 本文提出了一种名为IW-GAE的方法，通过开发一种新颖的加权群准确率估计器来解决非监督领域适应中的校准和模型选择问题。经过理论分析和实验验证，该方法在处理数据分布偏移方面表现出有效性。 |
| [^2] | [Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems.](http://arxiv.org/abs/2310.10603) | 本研究发现图神经网络（MPNNs）可以模拟标准内点法来解决线性优化问题，并且在解决时间上表现出色，超过了传统求解器和竞争方法。 |
| [^3] | [Causal Dynamic Variational Autoencoder for Counterfactual Regression in Longitudinal Data.](http://arxiv.org/abs/2310.10559) | 本论文提出了一种因果动态变分自编码器（CDVAE）来解决纵向数据中的反事实回归问题。该方法假设存在未观察到的调整变量，并通过结合动态变分自编码器（DVAE）框架和使用倾向得分的加权策略来估计反事实响应。 |
| [^4] | [Sample Complexity of Preference-Based Nonparametric Off-Policy Evaluation with Deep Networks.](http://arxiv.org/abs/2310.10556) | 本文研究了在深度网络中使用人类偏好进行非参数离策略评估的样本复杂性，并建立了统计保证。 |
| [^5] | [TacticAI: an AI assistant for football tactics.](http://arxiv.org/abs/2310.10553) | 提出了TacticAI，一种与利物浦足球俱乐部的领域专家密切合作开发和评价的AI足球战术助手。TacticAI能够通过预测和生成的方式帮助教练们分析角球情况，并为每个角球惯例选择成功可能性最高的球员配置。 |
| [^6] | [Optimal vintage factor analysis with deflation varimax.](http://arxiv.org/abs/2310.10545) | 本文提出了一种采用通货紧缩变量旋转的拟合因子分析方法，在每一行上逐步求解正交矩阵，相比于传统方法具有更好的计算性能和灵活性，并且在更广泛的背景下提供了理论保证。 |
| [^7] | [Comparing Comparators in Generalization Bounds.](http://arxiv.org/abs/2310.10534) | 本文推导了涉及任意凸比较函数的通用信息理论和PAC-Bayesian泛化界限，证明了最紧界限是由凸共轭的累积生成函数(CGF)构成的，使得这些界限广泛适用于不同结构的泛化界限。 |
| [^8] | [A Geometric Insight into Equivariant Message Passing Neural Networks on Riemannian Manifolds.](http://arxiv.org/abs/2310.10448) | 本研究提出了一种在黎曼流形上的等变消息传递的几何洞察，通过优化度量来实现对黎曼流形上的数值特征的消息传递，并通过扩散过程进行离散化，提出了一种高阶等变扩散过程。 |
| [^9] | [Efficiently matching random inhomogeneous graphs via degree profiles.](http://arxiv.org/abs/2310.10441) | 本文提出了一种通过度特征匹配算法高效匹配随机不均匀图的方法，要求最小平均度和最小相关性达到一定阈值。 |
| [^10] | [Equivariant Matrix Function Neural Networks.](http://arxiv.org/abs/2310.10434) | 矩阵函数神经网络（MFNs）是一种通过解析矩阵等变函数来参数化非局部相互作用的新型架构，能够在各种应用中实现最先进的性能。 |
| [^11] | [Towards Fair and Calibrated Models.](http://arxiv.org/abs/2310.10399) | 该论文研究了构建同时具备公平性和校准性的机器学习模型的问题，并提出了一种与经典定义不同的公平性概念，展示了先前的负面结果在这一新定义下不再成立。 |
| [^12] | [Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification.](http://arxiv.org/abs/2310.10379) | 本文重新审视和重新设计了逻辑-softmax似然，通过温度参数控制先验置信水平，从而改善了贝叶斯元学习中的少样本分类问题。同时证明softmax是逻辑-softmax的一种特殊情况，逻辑-softmax能够引导更大的数据分布家族。 |
| [^13] | [GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers.](http://arxiv.org/abs/2310.10375) | 提出了一种面向几何的注意力机制（GTA），用于将几何结构编码为相对变换，从而改进了多视图Transformer的学习效率和性能。 |
| [^14] | [Assessing univariate and bivariate risks of late-frost and drought using vine copulas: A historical study for Bavaria.](http://arxiv.org/abs/2310.10324) | 本文通过使用藤蔓可汀模型，评估了巴伐利亚地区自1952年至2020年期间的一元干旱和晚霜的风险，并进行了联合风险分析。研究结果发现了一些"风险区域"，强调了气候变化对森林适应的必要性。 |
| [^15] | [Mask wearing object detection algorithm based on improved YOLOv5.](http://arxiv.org/abs/2310.10245) | 本文提出了一种基于改进的YOLOv5的口罩佩戴物体检测算法。该算法通过引入多头注意力自卷积和Swin Transformer Block来提高模型的检测精度和适应能力，最终在MASK数据集上实现1.1%的mAP(0.5)提升和1.3%的改善。 |
| [^16] | [The Mixtures and the Neural Critics: On the Pointwise Mutual Information Profiles of Fine Distributions.](http://arxiv.org/abs/2310.10240) | 本文研究了点间互信息的特征，引入了细分布家族来解决现有互信息估计器的局限性，并探究了神经批评家在变分估计器中的行为，以及实验异常值对互信息估计的影响。此外，还介绍了基于模型的贝叶斯估计的方法，适用于具有领域专业知识且需要不确定性量化的问题。 |
| [^17] | [Structural transfer learning of non-Gaussian DAG.](http://arxiv.org/abs/2310.10239) | 本文提出了一种用于非高斯有向无环图的结构迁移学习方法，通过引入新颖的DAG结构相似度度量并利用不同相似性水平的辅助DAG的信息，能够显著提高目标研究中的DAG重构效果。 |
| [^18] | [On permutation symmetries in Bayesian neural network posteriors: a variational perspective.](http://arxiv.org/abs/2310.10171) | 本文研究了贝叶斯神经网络后验中的置换对称性，揭示了在梯度下降的局部解之间基本上不存在损失阻碍。通过使用置换矩阵对齐两个贝叶斯解决方案的分布，提出了一种寻找线性相连解的匹配算法。 |
| [^19] | [An Empirical Study of Simplicial Representation Learning with Wasserstein Distance.](http://arxiv.org/abs/2310.10143) | 本文研究了在树结构上利用Wasserstein距离进行简化表示学习的问题，并提出了一种基于SimCLR和负TWD的自监督学习方法来估计简化表示，通过实证研究找到了稳定的训练策略。 |
| [^20] | [Empowering SMPC: Bridging the Gap Between Scalability, Memory Efficiency and Privacy in Neural Network Inference.](http://arxiv.org/abs/2310.10133) | 本文提出了一个高效的开源SMPC仓库，解决了在资源有限的机器上实现SMPC协议的实际和可扩展性问题，并通过优化内存使用、减少执行时间和提高效率的方法，在保护数据隐私的同时完成了MNIST数据集推断任务。 |
| [^21] | [From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond.](http://arxiv.org/abs/2310.10121) | 本综述系统全面地回顾了利用连续动力学框架的图神经网络，以帮助从根本上理解和改进GNN的能力和缺陷。 |
| [^22] | [Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs.](http://arxiv.org/abs/2310.10107) | 本文分析了后验采样学习算法在序列化POMDPs中的遗憾性能，并在一定条件下提供了改进的多项式贝叶斯遗憾界。 |
| [^23] | [PAC Learning Linear Thresholds from Label Proportions.](http://arxiv.org/abs/2310.10098) | 本文探讨了从标签比例中学习线性阈值函数的计算可学习性，提出了一种使用LTFs有效学习LTFs的方法。 |
| [^24] | [LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions.](http://arxiv.org/abs/2310.10096) | 本文提出了一个大规模表格LLP基准，填补了表格LLP领域的研究空白。在该基准中，我们可以创建特征bags，其中所有实例具有相同的特征值，从而更好地模拟实际应用场景。 |
| [^25] | [Label Differential Privacy via Aggregation.](http://arxiv.org/abs/2310.10092) | 以前研究表明朴素的LBA和LLP不能提供标签差分隐私。但本研究显示，使用具有随机抽样的加权LBA可以提供标签差分隐私。 |
| [^26] | [Riemannian Residual Neural Networks.](http://arxiv.org/abs/2310.10013) | 本论文研究了黎曼残差神经网络的扩展，将其应用于通用黎曼流形，提供了解决消失梯度问题的几何原理方法，并展示了其在机器学习中的优异表现。 |
| [^27] | [Implicit regularization via soft ascent-descent.](http://arxiv.org/abs/2310.10006) | 本研究提出了一种通过软化的逐点机制（SoftAD）来实现正则化的方法，该方法具有更好的鲁棒性，可以减少超参数的影响，并保留上升-下降效应。 |
| [^28] | [Conformal Contextual Robust Optimization.](http://arxiv.org/abs/2310.10003) | 提出了一种Conformal-Predict-Then-Optimize（CPO）框架，利用高维非凸拟合预测区域，在数据驱动的预测-优化决策问题中减轻了安全关键环境中不确定性区域建模错误的风险，并通过提供语义可理解的可视化总结来解释最优决策。 |
| [^29] | [Outlier Detection Using Generative Models with Theoretical Performance Guarantees.](http://arxiv.org/abs/2310.09999) | 本文提出了一种利用生成模型进行异常值检测的方法，建立了在受稀疏异常值下使用生成模型重建信号的理论保证，给出了下界，并提出了两个算法解决异常值检测问题。 |
| [^30] | [Pseudo-Bayesian Optimization.](http://arxiv.org/abs/2310.09766) | 本文提出了伪贝叶斯优化，并通过研究最小要求的公理框架，构建了能确保黑盒优化收敛性的算法。 |
| [^31] | [Inference with Mondrian Random Forests.](http://arxiv.org/abs/2310.09702) | 本文在回归设置下给出了Mondrian随机森林的估计中心极限定理和去偏过程，使其能够进行统计推断和实现最小极大估计速率。 |
| [^32] | [DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization.](http://arxiv.org/abs/2310.09639) | 该论文提出了DPZero算法，这是一种与维度无关且具有差分隐私的零阶优化算法，用于解决在细调大型语言模型时面临的内存和隐私挑战。 |
| [^33] | [Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural ODEs via Homotopy Continuation.](http://arxiv.org/abs/2310.09583) | 通过同伦延续，我们建立了深度平衡模型（DEQs）和神经常微分方程（Neural ODEs）之间的连接，并提出了一种新的隐式模型HomoODE，它继承了DEQs的高精度性能和Neural ODEs的稳定性。 |
| [^34] | [ARTree: A Deep Autoregressive Model for Phylogenetic Inference.](http://arxiv.org/abs/2310.09553) | ARTree是一种用于系统发育推断的深度自回归模型，通过使用图神经网络对树形拓扑结构的条件分布进行建模，能够提供整个树形拓扑空间的丰富分布，并具有简单的采样算法和密度估计过程。 |
| [^35] | [A Semiparametric Instrumented Difference-in-Differences Approach to Policy Learning.](http://arxiv.org/abs/2310.09545) | 提出了一种半参数的工具变差分方法，用于学习最优治疗政策，并构建了一些估计器来解决平行趋势假设不成立的问题。 |
| [^36] | [Efficient Link Prediction via GNN Layers Induced by Negative Sampling.](http://arxiv.org/abs/2310.09516) | 本研究提出了一种新颖的GNN架构，通过负采样诱导了正边和负边的正向传递，以更加灵活而稳定地进行链接预测。 |
| [^37] | [Learning In-between Imagery Dynamics via Physical Latent Spaces.](http://arxiv.org/abs/2310.09495) | 本文提出了一个学习图像动态的框架，通过潜在动态估计图像演变的中间阶段，从而实现解释性，并保留与图像的空间相关性。该方法通过使用遵循物理模型的潜在变量，确保了学习模型的可解释性，并在地球科学图像数据上展示了其鲁棒性和有效性。 |
| [^38] | [ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning.](http://arxiv.org/abs/2310.09488) | 本研究提出了ARM，一种多变量的时间-上下文自适应学习方法，用于优化长期时间序列预测。ARM通过采用自适应单变量效应学习、随机丢弃训练策略和多核局部平滑，能更好地处理时间模式和学习系列之间的依赖关系。在多个基准测试中，ARM展示了卓越的性能，而计算成本相对较低。 |
| [^39] | [Signal reconstruction using determinantal sampling.](http://arxiv.org/abs/2310.09437) | 本研究提出了使用行列式抽样进行信号重建的方法，在有限数量的随机节点评估中近似表示方可积函数，实现了快速收敛和更高的适应性正则性。 |
| [^40] | [Offline Reinforcement Learning for Optimizing Production Bidding Policies.](http://arxiv.org/abs/2310.09426) | 该论文介绍了一种使用离线强化学习方法来优化生产环境中竞标策略的通用方法，该方法可以优化任何可微分的基础策略，只需要使用基础策略生成的数据。论文提出了一种混合代理架构，将基础策略与强化学习模块相结合。 |
| [^41] | [Statistical guarantees for stochastic Metropolis-Hastings.](http://arxiv.org/abs/2310.09335) | 该论文研究了针对随机Metropolis-Hastings算法的统计保证。通过引入简单的修正项，该方法可以避免计算成本上的损失，并通过分析非参数回归情景和深度神经网络回归的数值实例来证明了其在采样和可信区间方面的优势。 |
| [^42] | [Generative Entropic Neural Optimal Transport To Map Within and Across Spaces.](http://arxiv.org/abs/2310.09254) | 该论文介绍了生成熵神经最优传输在测度到测度映射中的应用，解决了处理非平方欧氏距离成本、确定性蒙格映射、映射跨不可比较空间和质量守恒约束等实际挑战。 |
| [^43] | [Computing Marginal and Conditional Divergences between Decomposable Models with Applications.](http://arxiv.org/abs/2310.09129) | 提出了一种计算可分解模型之间边际和条件差异的方法，能够在高维分布中精确计算差异，具有广泛的应用价值。 |
| [^44] | [Transformer Fusion with Optimal Transport.](http://arxiv.org/abs/2310.05719) | 本文介绍了一种使用最优输运来融合基于Transformer的网络的方法，可以对齐各种架构组件并允许不同大小的模型的融合，提供了一种新的高效压缩Transformer的方式。 |
| [^45] | [The Blessings of Multiple Treatments and Outcomes in Treatment Effect Estimation.](http://arxiv.org/abs/2309.17283) | 多重治疗和多个结果的并行研究在治疗效果估计中可以互相协助实现因果识别。 |
| [^46] | [Generalization error bounds for iterative learning algorithms with bounded updates.](http://arxiv.org/abs/2309.05077) | 本文研究了具有有界更新的迭代学习算法在非凸损失函数上的泛化特性，提出了一种新颖的泛化误差界限，利用了信息论技术。研究表明，在模型维度和训练数据样本数量相等的情况下，界限得到了改善。 |
| [^47] | [A correlation-based fuzzy cluster validity index with secondary options detector.](http://arxiv.org/abs/2308.14785) | 本研究提出了一种基于相关性的模糊聚类有效性指标，该指标考虑了在聚类数量选择时可能存在的多个选项，并通过评估在多种数据集上的性能，与现有指标进行比较。 |
| [^48] | [Path convergence of Markov chains on large graphs.](http://arxiv.org/abs/2308.09214) | 本文研究了大图上的马尔可夫链收敛性。通过研究欧几里德随机优化算法和Metropolis MCMC算法的改进版本在图上的表现，我们得出了随着图大小趋近于无穷大，随机过程的轨迹会收敛到确定性极限的结论。这些极限是测度值图上的曲线，通过引入新的度量，在这个空间中提供了自然的收敛概念。 |
| [^49] | [Med-HALT: Medical Domain Hallucination Test for Large Language Models.](http://arxiv.org/abs/2307.15343) | Med-HALT是一个新的基准和数据集，用于评估和减少大规模语言模型中医疗领域的幻觉问题。这个数据集包括多种创新的测试模式，并评估了领先的LLMs在性能上的差异。 |
| [^50] | [Beyond Normal: On the Evaluation of Mutual Information Estimators.](http://arxiv.org/abs/2306.11078) | 本文提出了一种语言无关的互信息估计基准平台，并讨论了经典和神经估计器在处理高维数据、长尾分布和高互信息时的普适性和局限性。 |
| [^51] | [On Certified Generalization in Structured Prediction.](http://arxiv.org/abs/2306.09112) | 该论文提出了一种新的结构化预测PAC-Bayesian风险界限，它可以随着结构化示例的数量和大小的变化而进行泛化，为使用生成模型建立结构化预测的泛化界限迈出了第一步。 |
| [^52] | [Going Deeper with Spectral Embeddings.](http://arxiv.org/abs/2306.00742) | 本文提出两种新的谱嵌入方法，一种基于函数分析原理和核方法，另一种基于深度网络优化损失，提供理论保证和实际有效的算法，并提供新的采样算法。 |
| [^53] | [ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding.](http://arxiv.org/abs/2305.14196) | ZeroSCROLLS是一个用于长文本自然语言理解的零Shot基准测试，包括六个任务和四个数据集，能够评估大型语言模型的性能。当前，GPT-4的平均得分最高，但在聚合任务等多个挑战上，仍有改进的空间。 |
| [^54] | [Statistical Guarantees of Group-Invariant GANs.](http://arxiv.org/abs/2305.13517) | 本研究提出了群不变GAN的统计保证，发现当学习群不变分布时，群不变GAN所需样本数会按群体大小的幂比例减少。 |
| [^55] | [The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors.](http://arxiv.org/abs/2305.12883) | 该论文研究了基于一般回归误差假设的无噪声回归最小二乘估计值的均方误差，并发现包含大量不重要的参数可以有效地降低估计器的均方误差。 |
| [^56] | [Relabel Minimal Training Subset to Flip a Prediction.](http://arxiv.org/abs/2305.12809) | 本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。 |
| [^57] | [Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability.](http://arxiv.org/abs/2305.11788) | 本文研究了逻辑回归常数步长梯度下降在稳定性边缘的收敛性和隐式偏差，证明了逻辑损失可以通过任何常数步长的梯度下降进行最小化，同时也发现了指数损失下的发散性问题，强调了稳定性边缘下梯度下降的不稳定性。 |
| [^58] | [Beyond Exponential Graph: Communication-Efficient Topologies for Decentralized Learning via Finite-time Convergence.](http://arxiv.org/abs/2305.11420) | 本文介绍了一种新型拓扑——基础$(k+1)$图，其中节点在有限的迭代次数后能达到确切的共识，具有快速共识率和小的最大度数，从而可以用于分散式SGD。 |
| [^59] | [On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation.](http://arxiv.org/abs/2305.11283) | 本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。 |
| [^60] | [Unbounded Differentially Private Quantile and Maximum Estimation.](http://arxiv.org/abs/2305.01177) | 本文研究了如何对无上限数据进行差分隐私分位数和最大值的计算。调用基本的稀疏向量技术中的$\texttt{AboveThreshold}$子程序可以实现这个目标，可以提供更准确和稳健的最高分位数估计，从而应用于对于差分隐私求和和均值估计至关重要的数据剪切，该技术的隐私保障可以通过方法改进。 |
| [^61] | [Energy-Based Sliced Wasserstein Distance.](http://arxiv.org/abs/2304.13586) | 本文提出了一种能量为基础的切片Wasserstein距离，并将其参数化，以克服传统方法中的固定先验分布缺乏信息和优化最佳分布昂贵不稳定的局限。 |
| [^62] | [NF-ULA: Langevin Monte Carlo with Normalizing Flow Prior for Imaging Inverse Problems.](http://arxiv.org/abs/2304.08342) | 本文提出了一种NF-ULA算法，其中包括学习正则化流作为先验，用于解决成像逆问题的贝叶斯推断采样算法，且有效性得到了在三个成像逆问题上的证明。 |
| [^63] | [Operator learning with PCA-Net: upper and lower complexity bounds.](http://arxiv.org/abs/2303.16317) | 本文发展了PCA-Net的近似理论，得出了通用逼近结果，并识别出了使用PCA-Net进行高效操作学习的潜在障碍：输出分布的复杂性和算子空间的内在复杂性。 |
| [^64] | [Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference.](http://arxiv.org/abs/2302.11944) | 我们提出了一种反事实场景测试框架，通过比较数据集中类似的保护和非保护实例来检测分类器中的歧视，通过比较组间决策结果差异，来发现个人歧视。该框架可以更好地对「给定差异的公平原则」进行操作，以揭示在公平原则下的歧视差异。 |
| [^65] | [Extragradient-Type Methods with $\mathcal{O} (1/k)$ Last-Iterate Convergence Rates for Co-Hypomonotone Inclusions.](http://arxiv.org/abs/2302.04099) | 本文提出了两种"Nesterov's加速"的外推算法来逼近共超单调包含关系的解，分别为内斯特罗夫加速的Tseng前-后-前分裂法和过去FBFS法，两种算法都达到了$\mathcal{O}(1/k)$的最终迭代收敛速度。 |
| [^66] | [Sketched Ridgeless Linear Regression: The Role of Downsampling.](http://arxiv.org/abs/2302.01088) | 本文研究了描绘无岗位最小二乘估计器在比例区域下的样本外预测风险，挑战了传统观念，并发现下采样在某些情况下可以改善泛化，我们确定了最佳缩略图大小并提出了实际实施方法。 |
| [^67] | [Neural networks learn to magnify areas near decision boundaries.](http://arxiv.org/abs/2301.11375) | 神经网络训练能够放大决策边界附近的局部区域，改善整个系统的泛化能力。 |
| [^68] | [Markovian Sliced Wasserstein Distances: Beyond Independent Projections.](http://arxiv.org/abs/2301.03749) | 马尔可夫切片Wasserstein（MSW）距离是一种新的SW距离家族，通过在投影方向上施加一阶马尔可夫结构，解决了切片Wasserstein（SW）距离中独立投影导致的冗余投影的问题，并且具有较低的计算复杂度。（found in translation） |
| [^69] | [Data-driven multinomial random forest: A new random forest variant with strong consistency.](http://arxiv.org/abs/2211.15154) | 本研究改进了先前弱一致性随机森林变体的证明方法，提出了一种数据驱动的多项式随机森林（DMRF），并表明DMRF在分类和回归问题中具有更好的性能，并且实现了概率1的强一致性。 |
| [^70] | [Efficient Estimation for Longitudinal Network via Adaptive Merging.](http://arxiv.org/abs/2211.07866) | 本文提出了一个有效的纵向网络估计框架，利用自适应合并、张量分解和点过程等方法来减少估计偏差和方差。 |
| [^71] | [Concentration inequalities for leave-one-out cross validation.](http://arxiv.org/abs/2211.02478) | 本文证明了估计器的稳定性足以说明留一法交叉验证是可靠的，并通过提供集中界限超出Lipschitz连续性假设的损失函数或估计器，为我们提供了一个相对丰富的分布类。 |
| [^72] | [Optimal AdaBoost Converges.](http://arxiv.org/abs/2210.07808) | 本研究通过形式证明，展示了最优AdaBoost算法的分类器和边缘的收敛性质，结果与几十年的研究相一致。 |
| [^73] | [Optimality Guarantees for Particle Belief Approximation of POMDPs.](http://arxiv.org/abs/2210.05015) | 该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。 |
| [^74] | [Signed Network Embedding with Application to Simultaneous Detection of Communities and Anomalies.](http://arxiv.org/abs/2207.09324) | 本文开发了一个统一的嵌入模型，用于解决签名网络中的平衡结构和异常效应，并在社区检测、异常检测和网络推断等任务中取得了良好表现。 |
| [^75] | [Diagnostic Tool for Out-of-Sample Model Evaluation.](http://arxiv.org/abs/2206.10982) | 本文提出了一种用于外样本模型评估的诊断工具，可以通过有限的校准数据集来表征模型在未来外样本上的损失，并提供了简单易用且易于解释的方法。该工具可以量化分布转变的影响，促进回归分析，帮助实现模型选择和超参数调优。 |
| [^76] | [Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation.](http://arxiv.org/abs/2203.11740) | 该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。 |
| [^77] | [Inference of time-ordered multibody interactions.](http://arxiv.org/abs/2111.14611) | 本文介绍了时序多体相互作用的推断方法，该方法可以描述表现出时间依赖性和多体依赖性的复杂系统。通过将多元马尔可夫链的动力学分解为时序多体相互作用的集合，我们提出了一种从数据中提取这些相互作用的算法，并验证了算法的稳健性和效率。 |
| [^78] | [Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting.](http://arxiv.org/abs/2110.03135) | 该论文发现了对抗训练中存在的标签噪声，并解释了其对鲁棒过度拟合的普遍存在以及扰动半径和数据质量的依赖性。通过该论文提出的方法，可以自动校准标签以应对标签噪声和鲁棒过度拟合。 |
| [^79] | [BEAUTY Powered BEAST.](http://arxiv.org/abs/2103.00674) | 本文研究了使用BEAUTY方法进行分布无关的拟合优度检验。该方法通过二进制展开逼近特征函数，并将许多重要的独立性检验统一起来。使用数据自适应权重的BEAST检验提供了稳健的功效，同时提出了一个可行功效的参考。 |
| [^80] | [Ansor: Generating High-Performance Tensor Programs for Deep Learning.](http://arxiv.org/abs/2006.06762) | Ansor是一个针对深度学习应用的张量程序生成框架，通过采样程序和使用进化搜索和学习的成本模型进行微调，能够高效地找到高性能的张量程序。 |

# 详细

[^1]: IW-GAE: 用于提高非监督领域适应中的校准和模型选择的加权群准确率估计

    IW-GAE: Importance weighted group accuracy estimation for improved calibration and model selection in unsupervised domain adaptation. (arXiv:2310.10611v1 [cs.LG])

    [http://arxiv.org/abs/2310.10611](http://arxiv.org/abs/2310.10611)

    本文提出了一种名为IW-GAE的方法，通过开发一种新颖的加权群准确率估计器来解决非监督领域适应中的校准和模型选择问题。经过理论分析和实验验证，该方法在处理数据分布偏移方面表现出有效性。

    

    计算模型在测试样本上的准确率并从中推断其置信度是机器学习中的一个核心问题，与不确定性表示、模型选择和探索等重要应用密切相关。虽然这些连接在独立同分布设置中已经被广泛研究，但数据分布的偏移给传统方法带来了重大挑战。因此，在非监督领域适应问题中，模型校准和模型选择仍然具有挑战性，这是一种在没有标签的情况下在数据分布发生偏移的领域中表现良好的场景。在本文中，我们通过开发一种新颖的加权群准确率估计器来解决由于数据分布的偏移而带来的困难。具体而言，我们制定了一个优化问题，找到导致在数据分布偏移的领域中准确估计群准确率的重要权重，并进行了理论分析。大量实验结果表明了群准确率估计在模型上的有效性。

    Reasoning about a model's accuracy on a test sample from its confidence is a central problem in machine learning, being connected to important applications such as uncertainty representation, model selection, and exploration. While these connections have been well-studied in the i.i.d. settings, distribution shifts pose significant challenges to the traditional methods. Therefore, model calibration and model selection remain challenging in the unsupervised domain adaptation problem--a scenario where the goal is to perform well in a distribution shifted domain without labels. In this work, we tackle difficulties coming from distribution shifts by developing a novel importance weighted group accuracy estimator. Specifically, we formulate an optimization problem for finding an importance weight that leads to an accurate group accuracy estimation in the distribution shifted domain with theoretical analyses. Extensive experiments show the effectiveness of group accuracy estimation on model 
    
[^2]: 探索图神经网络在解决线性优化问题中的威力

    Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems. (arXiv:2310.10603v1 [cs.LG])

    [http://arxiv.org/abs/2310.10603](http://arxiv.org/abs/2310.10603)

    本研究发现图神经网络（MPNNs）可以模拟标准内点法来解决线性优化问题，并且在解决时间上表现出色，超过了传统求解器和竞争方法。

    

    最近，机器学习特别是消息传递图神经网络（MPNNs）在增强精确优化算法方面已经引起了关注。例如，MPNNs通过模拟计算密集型启发式方法如强支分支加速解决混合整数优化问题，这需要解决多个线性优化问题（LPs）。尽管有实证成功，但MPNNs在模拟线性优化方面的有效性的原因仍然不清楚。在这里，我们展示了MPNNs可以模拟LPs的标准内点法，解释了它们在实践中的成功。此外，我们强调了MPNNs如何作为解决LPs的轻量级代理，适应给定的问题实例分布。实证结果表明，MPNNs在接近最优性上解决了标准组合优化问题的LP松弛，通常在解决时间上超过了传统求解器和竞争方法。

    Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.
    
[^3]: 因果动态变分自编码器用于纵向数据中的反事实回归

    Causal Dynamic Variational Autoencoder for Counterfactual Regression in Longitudinal Data. (arXiv:2310.10559v1 [stat.ML])

    [http://arxiv.org/abs/2310.10559](http://arxiv.org/abs/2310.10559)

    本论文提出了一种因果动态变分自编码器（CDVAE）来解决纵向数据中的反事实回归问题。该方法假设存在未观察到的调整变量，并通过结合动态变分自编码器（DVAE）框架和使用倾向得分的加权策略来估计反事实响应。

    

    在很多实际应用中，如精准医学、流行病学、经济和市场营销中，估计随时间变化的治疗效果是相关的。许多最先进的方法要么假设了所有混杂变量的观测结果，要么试图推断未观察到的混杂变量。我们采取了不同的观点，假设存在未观察到的风险因素，即仅影响结果序列的调整变量。在无混杂性的情况下，我们以未观测到的风险因素导致的治疗反应中的未知异质性为目标，估计个体治疗效果（ITE）。我们应对了时变效应和未观察到的调整变量所带来的挑战。在学习到的调整变量的有效性和治疗效果的一般化界限的理论结果指导下，我们设计了因果DVAE（CDVAE）。该模型将动态变分自编码器（DVAE）框架与使用倾向得分的加权策略相结合，用于估计反事实响应。

    Estimating treatment effects over time is relevant in many real-world applications, such as precision medicine, epidemiology, economy, and marketing. Many state-of-the-art methods either assume the observations of all confounders or seek to infer the unobserved ones. We take a different perspective by assuming unobserved risk factors, i.e., adjustment variables that affect only the sequence of outcomes. Under unconfoundedness, we target the Individual Treatment Effect (ITE) estimation with unobserved heterogeneity in the treatment response due to missing risk factors. We address the challenges posed by time-varying effects and unobserved adjustment variables. Led by theoretical results over the validity of the learned adjustment variables and generalization bounds over the treatment effect, we devise Causal DVAE (CDVAE). This model combines a Dynamic Variational Autoencoder (DVAE) framework with a weighting strategy using propensity scores to estimate counterfactual responses. The CDVA
    
[^4]: 基于人类偏好的非参数离策略评估在深度网络中的样本复杂性

    Sample Complexity of Preference-Based Nonparametric Off-Policy Evaluation with Deep Networks. (arXiv:2310.10556v1 [cs.LG])

    [http://arxiv.org/abs/2310.10556](http://arxiv.org/abs/2310.10556)

    本文研究了在深度网络中使用人类偏好进行非参数离策略评估的样本复杂性，并建立了统计保证。

    

    最近流行的解决强化学习问题的方法是使用人类偏好数据。事实上，人类偏好数据现在与经典的强化学习算法（如演员-评论家方法）一起使用，在从人类偏好数据中学习的奖励上评估中间策略，即离策略评估（OPE）。该算法包括（i）从人类偏好数据集中学习奖励函数，以及（ii）学习目标策略的累积奖励。尽管有巨大的经验成功，但现有的使用偏好数据的OPE方法通常缺乏理论理解，并且严重依赖于启发式方法。在本文中，我们研究了基于人类偏好的OPE的样本效率，并为其建立了统计保证。具体而言，我们通过使用深度神经网络进行拟合Q评估来处理OPE。通过适当选择ReLU网络的大小，我们表明可以利用任何lo

    A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understanding and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE by learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any lo
    
[^5]: TacticAI:一种足球战术的人工智能助手

    TacticAI: an AI assistant for football tactics. (arXiv:2310.10553v1 [cs.LG])

    [http://arxiv.org/abs/2310.10553](http://arxiv.org/abs/2310.10553)

    提出了TacticAI，一种与利物浦足球俱乐部的领域专家密切合作开发和评价的AI足球战术助手。TacticAI能够通过预测和生成的方式帮助教练们分析角球情况，并为每个角球惯例选择成功可能性最高的球员配置。

    

    辨别对手团队实施的战术关键模式并开发有效的应对方法是现代足球的核心问题。然而，以算法的方式来解决这个问题仍是一个未解决的研究挑战。为了解决这个需求，我们提出了TacticAI，一种与利物浦足球俱乐部的领域专家密切合作开发和评价的AI足球战术助手。我们专注于分析角球，因为它们给教练们提供了直接的干预和改进机会。TacticAI包含了一个预测和生成的组件，使教练能够有效地采样和探索每个角球惯例的替代球员配置，并选择那些预测成功可能性最高的。我们通过一些相关的基准任务对TacticAI进行了验证：预测接收球员和射门尝试以及推荐球员位置调整。TacticAI的实用性通过与利物浦足球领域专家进行的定性研究得到了验证。

    Identifying key patterns of tactics implemented by rival teams, and developing effective responses, lies at the heart of modern football. However, doing so algorithmically remains an open research challenge. To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC. We focus on analysing corner kicks, as they offer coaches the most direct opportunities for interventions and improvements. TacticAI incorporates both a predictive and a generative component, allowing the coaches to effectively sample and explore alternative player setups for each corner kick routine and to select those with the highest predicted likelihood of success. We validate TacticAI on a number of relevant benchmark tasks: predicting receivers and shot attempts and recommending player position adjustments. The utility of TacticAI is validated by a qualitative study conducted with football domain experts at Liv
    
[^6]: 优化拟合因子分析与通货紧缩变量旋转

    Optimal vintage factor analysis with deflation varimax. (arXiv:2310.10545v1 [stat.ML])

    [http://arxiv.org/abs/2310.10545](http://arxiv.org/abs/2310.10545)

    本文提出了一种采用通货紧缩变量旋转的拟合因子分析方法，在每一行上逐步求解正交矩阵，相比于传统方法具有更好的计算性能和灵活性，并且在更广泛的背景下提供了理论保证。

    

    通货紧缩变量旋转是一种重要的因子分析方法，旨在首先找到原始数据的低维表示，然后寻求旋转，使旋转后的低维表示具有科学意义。尽管Principal Component Analysis (PCA) followed by the varimax rotation被广泛应用于拟合因子分析，但由于varimax rotation需要在正交矩阵集合上解非凸优化问题，因此很难提供理论保证。本文提出了一种逐行求解正交矩阵的通货紧缩变量旋转过程。除了在计算上的优势和灵活性之外，我们还能在广泛的背景下对所提出的过程进行完全的理论保证。在PCA之后采用这种新的varimax方法作为第二步，我们进一步分析了这个两步过程在一个更一般的因子模型的情况下。

    Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. Perhaps the most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.  In this paper, we propose a deflation varimax procedure that solves each row of an orthogonal matrix sequentially. In addition to its net computational gain and flexibility, we are able to fully establish theoretical guarantees for the proposed procedure in a broad context.  Adopting this new varimax approach as the second step after PCA, we further analyze this two step procedure under a general class of factor models. Our resul
    
[^7]: 对比分类器在泛化界限中的比较

    Comparing Comparators in Generalization Bounds. (arXiv:2310.10534v1 [cs.LG])

    [http://arxiv.org/abs/2310.10534](http://arxiv.org/abs/2310.10534)

    本文推导了涉及任意凸比较函数的通用信息理论和PAC-Bayesian泛化界限，证明了最紧界限是由凸共轭的累积生成函数(CGF)构成的，使得这些界限广泛适用于不同结构的泛化界限。

    

    我们推导了涉及任意凸比较函数的通用信息理论和PAC-Bayesian泛化界限，该函数测量训练误差和样本误差之间的差异。该界限在比较函数的累积生成函数(CG), 被界定在一族限制分布函数的CGF上限的假设下成立。我们证明了当比较函数是CGF的凸共轭，也被称为Cram\'er函数时，得到的界限是最紧的。这个结论更广泛地适用于具有类似结构的泛化界限。这证实了已知界限在有界和次高斯损失情况下的近最优性，并且在其他限制分布下得到了新的界限。

    We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training and population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cram\'er function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions.
    
[^8]: 一种在黎曼流形上的等变消息传递神经网络的几何洞察

    A Geometric Insight into Equivariant Message Passing Neural Networks on Riemannian Manifolds. (arXiv:2310.10448v1 [stat.ML])

    [http://arxiv.org/abs/2310.10448](http://arxiv.org/abs/2310.10448)

    本研究提出了一种在黎曼流形上的等变消息传递的几何洞察，通过优化度量来实现对黎曼流形上的数值特征的消息传递，并通过扩散过程进行离散化，提出了一种高阶等变扩散过程。

    

    本文提出了一种在黎曼流形上进行等变消息传递的几何洞察。如先前提出的，黎曼流形上的数值特征被表示为流形上的无坐标特征场。对于流形上的任何无坐标特征场，都附带有一个主丛到数值特征空间的等变嵌入。我们认为这个嵌入诱导的度量应该最优地保留主丛原始的度量。这个最优性标准导致了对该嵌入的图的Polyakov作用的扭曲形式的最小化，从而得到了关联向量丛上的等变扩散过程。通过对扩散方程流进行离散化，我们得到了一个在流形上的消息传递方案。我们提出了一个高阶等变扩散过程，它等价于在基本流形的笛卡尔乘积上进行扩散。

    This work proposes a geometric insight into equivariant message passing on Riemannian manifolds. As previously proposed, numerical features on Riemannian manifolds are represented as coordinate-independent feature fields on the manifold. To any coordinate-independent feature field on a manifold comes attached an equivariant embedding of the principal bundle to the space of numerical features. We argue that the metric this embedding induces on the numerical feature space should optimally preserve the principal bundle's original metric. This optimality criterion leads to the minimization of a twisted form of the Polyakov action with respect to the graph of this embedding, yielding an equivariant diffusion process on the associated vector bundle. We obtain a message passing scheme on the manifold by discretizing the diffusion equation flow for a fixed time step. We propose a higher-order equivariant diffusion process equivalent to diffusion on the cartesian product of the base manifold. T
    
[^9]: 通过度特征高效匹配随机不均匀图

    Efficiently matching random inhomogeneous graphs via degree profiles. (arXiv:2310.10441v1 [cs.DS])

    [http://arxiv.org/abs/2310.10441](http://arxiv.org/abs/2310.10441)

    本文提出了一种通过度特征匹配算法高效匹配随机不均匀图的方法，要求最小平均度和最小相关性达到一定阈值。

    

    本文研究了恢复两个相关的随机图之间潜在顶点对应关系的问题，这两个图具有极不均匀且未知的不同顶点对之间的边概率。在Ding、Ma、Wu和Xu(2021)提出的度特征匹配算法的基础上，我们扩展出了一种高效的匹配算法，只要最小平均度至少为$\Omega(\log^{2} n)$，最小相关性至少为$1 - O(\log^{-2} n)$。

    In this paper, we study the problem of recovering the latent vertex correspondence between two correlated random graphs with vastly inhomogeneous and unknown edge probabilities between different pairs of vertices. Inspired by and extending the matching algorithm via degree profiles by Ding, Ma, Wu and Xu (2021), we obtain an efficient matching algorithm as long as the minimal average degree is at least $\Omega(\log^{2} n)$ and the minimal correlation is at least $1 - O(\log^{-2} n)$.
    
[^10]: 等变矩阵函数神经网络

    Equivariant Matrix Function Neural Networks. (arXiv:2310.10434v1 [stat.ML])

    [http://arxiv.org/abs/2310.10434](http://arxiv.org/abs/2310.10434)

    矩阵函数神经网络（MFNs）是一种通过解析矩阵等变函数来参数化非局部相互作用的新型架构，能够在各种应用中实现最先进的性能。

    

    图神经网络（GNNs），尤其是消息传递神经网络（MPNNs），已经成为在各种应用中学习图形的强大架构。然而，当建模非局部相互作用时，MPNNs在大共轭分子，金属或非晶态材料等系统中面临挑战。尽管谱GNN和传统的神经网络（例如循环神经网络和Transformer）可以缓解这些挑战，但它们常常缺乏扩展性，适应性，泛化能力，计算效率，或者不能捕捉数据中的详细结构关系或对称性。为了解决这些问题，我们引入了矩阵函数神经网络（MFNs），一种通过解析矩阵等变函数来参数化非局部相互作用的新型架构。采用解析矩阵展开提供了一种直接的实现方法，并具有随系统大小线性扩展的潜力。该MFN架构在标准任务中实现了最先进的性能。

    Graph Neural Networks (GNNs), especially message-passing neural networks (MPNNs), have emerged as powerful architectures for learning on graphs in diverse applications. However, MPNNs face challenges when modeling non-local interactions in systems such as large conjugated molecules, metals, or amorphous materials. Although Spectral GNNs and traditional neural networks such as recurrent neural networks and transformers mitigate these challenges, they often lack extensivity, adaptability, generalizability, computational efficiency, or fail to capture detailed structural relationships or symmetries in the data. To address these concerns, we introduce Matrix Function Neural Networks (MFNs), a novel architecture that parameterizes non-local interactions through analytic matrix equivariant functions. Employing resolvent expansions offers a straightforward implementation and the potential for linear scaling with system size. The MFN architecture achieves state-of-the-art performance in standa
    
[^11]: 朝着公平和校准模型的方向

    Towards Fair and Calibrated Models. (arXiv:2310.10399v1 [cs.LG])

    [http://arxiv.org/abs/2310.10399](http://arxiv.org/abs/2310.10399)

    该论文研究了构建同时具备公平性和校准性的机器学习模型的问题，并提出了一种与经典定义不同的公平性概念，展示了先前的负面结果在这一新定义下不再成立。

    

    最近的文献注重于构建具有特定属性的机器学习模型，如公平性（即对于给定的一组属性，不偏袒任何一方）、校准性（即模型信心与预测准确性一致）、可解释性（即能够被人理解的能力）。虽然已经有关于每个方面的研究工作，但研究人员迄今为止还没有同时解决这些维度中超过一个的问题。在这项工作中，我们解决了构建既公平又校准的模型的问题。我们采用了与[Biswas et. al. 2019]非常接近的公平性定义，并且在我们的定义下，贝叶斯最优分类器具有最大可能的公平性。我们证明了一个现有的关于实现公平和校准模型的负面结果[Kleinberg et. al. 2017]在我们的公平性定义下不成立。此外，我们证明了确保群体智能的方法。

    Recent literature has seen a significant focus on building machine learning models with specific properties such as fairness, i.e., being non-biased with respect to a given set of attributes, calibration i.e., model confidence being aligned with its predictive accuracy, and explainability, i.e., ability to be understandable to humans. While there has been work focusing on each of these aspects individually, researchers have shied away from simultaneously addressing more than one of these dimensions. In this work, we address the problem of building models which are both fair and calibrated. We work with a specific definition of fairness, which closely matches [Biswas et. al. 2019], and has the nice property that Bayes optimal classifier has the maximum possible fairness under our definition. We show that an existing negative result towards achieving a fair and calibrated model [Kleinberg et. al. 2017] does not hold for our definition of fairness. Further, we show that ensuring group-wis
    
[^12]: 重新审视贝叶斯元学习中逻辑-softmax似然用于少样本分类

    Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification. (arXiv:2310.10379v1 [cs.LG])

    [http://arxiv.org/abs/2310.10379](http://arxiv.org/abs/2310.10379)

    本文重新审视和重新设计了逻辑-softmax似然，通过温度参数控制先验置信水平，从而改善了贝叶斯元学习中的少样本分类问题。同时证明softmax是逻辑-softmax的一种特殊情况，逻辑-softmax能够引导更大的数据分布家族。

    

    元学习通过学习使用先前的知识解决新问题，在少样本分类中取得了有希望的结果。贝叶斯方法能够有效地表征少样本分类中的不确定性，这在高风险领域至关重要。然而，在多类别高斯过程分类中，逻辑-softmax似然一直被用作softmax似然的替代方法，因为其具有条件共轭性质。然而，逻辑-softmax的理论特性不清楚，以前的研究表明逻辑-softmax的固有不确定性导致了次优的性能。为了解决这些问题，我们重新审视和重新设计了逻辑-softmax似然，通过一个温度参数实现对先验置信水平的控制。此外，我们从理论和实践的角度证明了softmax可以被视为逻辑-softmax的一种特殊情况，并且逻辑-softmax引导了比softmax更大的数据分布家族。

    Meta-learning has demonstrated promising results in few-shot classification (FSC) by learning to solve new problems using prior knowledge. Bayesian methods are effective at characterizing uncertainty in FSC, which is crucial in high-risk fields. In this context, the logistic-softmax likelihood is often employed as an alternative to the softmax likelihood in multi-class Gaussian process classification due to its conditional conjugacy property. However, the theoretical property of logistic-softmax is not clear and previous research indicated that the inherent uncertainty of logistic-softmax leads to suboptimal performance. To mitigate these issues, we revisit and redesign the logistic-softmax likelihood, which enables control of the \textit{a priori} confidence level through a temperature parameter. Furthermore, we theoretically and empirically show that softmax can be viewed as a special case of logistic-softmax and logistic-softmax induces a larger family of data distribution than soft
    
[^13]: GTA：一种面向几何的多视图Transformer的注意力机制

    GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers. (arXiv:2310.10375v1 [cs.CV])

    [http://arxiv.org/abs/2310.10375](http://arxiv.org/abs/2310.10375)

    提出了一种面向几何的注意力机制（GTA），用于将几何结构编码为相对变换，从而改进了多视图Transformer的学习效率和性能。

    

    随着transformers对输入标记的排列具有等变性，对标记的位置信息进行编码对许多任务是必要的。然而，由于现有的位置编码方案最初是为自然语言处理任务设计的，对于通常在其数据中表现出不同结构特性的视觉任务来说，它们的适用性值得怀疑。我们认为现有的位置编码方案对于3D视觉任务来说是次优的，因为它们不尊重其底层的3D几何结构。基于这个假设，我们提出了一种面向几何的注意力机制，它将标记的几何结构编码为由查询和键值对之间的几何关系所确定的相对变换。通过在稀疏宽基线多视图设置中评估多个新颖视图合成（NVS）数据集，我们展示了我们的注意力机制——几何变换注意力（GTA）如何提高了最先进的Transformer的学习效率和性能。

    As transformers are equivariant to the permutation of input tokens, encoding the positional information of tokens is necessary for many tasks. However, since existing positional encoding schemes have been initially designed for NLP tasks, their suitability for vision tasks, which typically exhibit different structural properties in their data, is questionable. We argue that existing positional encoding schemes are suboptimal for 3D vision tasks, as they do not respect their underlying 3D geometric structure. Based on this hypothesis, we propose a geometry-aware attention mechanism that encodes the geometric structure of tokens as relative transformation determined by the geometric relationship between queries and key-value pairs. By evaluating on multiple novel view synthesis (NVS) datasets in the sparse wide-baseline multi-view setting, we show that our attention, called Geometric Transform Attention (GTA), improves learning efficiency and performance of state-of-the-art transformer-b
    
[^14]: 使用藤蔓可汀模型评估慕尼黑的晚霜和干旱的一元和二元风险：一项历史研究

    Assessing univariate and bivariate risks of late-frost and drought using vine copulas: A historical study for Bavaria. (arXiv:2310.10324v1 [stat.AP])

    [http://arxiv.org/abs/2310.10324](http://arxiv.org/abs/2310.10324)

    本文通过使用藤蔓可汀模型，评估了巴伐利亚地区自1952年至2020年期间的一元干旱和晚霜的风险，并进行了联合风险分析。研究结果发现了一些"风险区域"，强调了气候变化对森林适应的必要性。

    

    鉴于气候变化对森林的影响，包括极端干旱和晚霜，导致植被减退和局部森林衰退，我们评估了巴伐利亚从1952年到2020年的一元干旱和晚霜风险，并进行了联合风险分析。利用包含26个生物气候和地形变量的庞大数据集，由于数据的非高斯和不对称性依赖性，我们采用藤蔓可汀模型。我们使用D-vine回归进行一元分析，使用Y-vine回归进行二元分析，并提出相应的一元和二元条件概率风险度量。我们确定了"风险区域"，强调了由于气候变化而需要森林适应的重要性。

    In light of climate change's impacts on forests, including extreme drought and late-frost, leading to vitality decline and regional forest die-back, we assess univariate drought and late-frost risks and perform a joint risk analysis in Bavaria, Germany, from 1952 to 2020. Utilizing a vast dataset with 26 bioclimatic and topographic variables, we employ vine copula models due to the data's non-Gaussian and asymmetric dependencies. We use D-vine regression for univariate and Y-vine regression for bivariate analysis, and propose corresponding univariate and bivariate conditional probability risk measures. We identify "at-risk" regions, emphasizing the need for forest adaptation due to climate change.
    
[^15]: 基于改进的YOLOv5的口罩佩戴物体检测算法

    Mask wearing object detection algorithm based on improved YOLOv5. (arXiv:2310.10245v1 [cs.CV])

    [http://arxiv.org/abs/2310.10245](http://arxiv.org/abs/2310.10245)

    本文提出了一种基于改进的YOLOv5的口罩佩戴物体检测算法。该算法通过引入多头注意力自卷积和Swin Transformer Block来提高模型的检测精度和适应能力，最终在MASK数据集上实现1.1%的mAP(0.5)提升和1.3%的改善。

    

    戴口罩是预防传染病的重要措施之一，然而在人流量较大的公共场所很难检测到人们佩戴口罩的情况。为了解决这个问题，本文提出了一种基于YOLOv5l的口罩佩戴人脸检测模型。首先，引入了多头注意力自卷积，不仅提高了模型的收敛速度，还增强了模型的检测精度。其次，引入了Swin Transformer Block，能够提取更多有用的特征信息，增强对小目标的检测能力，提高模型的整体精度。我们设计的I-CBAM模块可以提高目标检测的准确性。此外，采用增强的特征融合使得模型能够更好地适应不同尺度的目标检测任务。在MASK数据集上的实验结果表明，本文提出的模型在mAP(0.5)上取得了1.1%的提升和1.3%的改善。

    Wearing a mask is one of the important measures to prevent infectious diseases. However, it is difficult to detect people's mask-wearing situation in public places with high traffic flow. To address the above problem, this paper proposes a mask-wearing face detection model based on YOLOv5l. Firstly, Multi-Head Attentional Self-Convolution not only improves the convergence speed of the model but also enhances the accuracy of the model detection. Secondly, the introduction of Swin Transformer Block is able to extract more useful feature information, enhance the detection ability of small targets, and improve the overall accuracy of the model. Our designed I-CBAM module can improve target detection accuracy. In addition, using enhanced feature fusion enables the model to better adapt to object detection tasks of different scales. In the experimentation on the MASK dataset, the results show that the model proposed in this paper achieved a 1.1% improvement in mAP(0.5) and a 1.3% improvement
    
[^16]: 混合物与神经批评家：关于精细分布的点间互信息的研究

    The Mixtures and the Neural Critics: On the Pointwise Mutual Information Profiles of Fine Distributions. (arXiv:2310.10240v1 [stat.ML])

    [http://arxiv.org/abs/2310.10240](http://arxiv.org/abs/2310.10240)

    本文研究了点间互信息的特征，引入了细分布家族来解决现有互信息估计器的局限性，并探究了神经批评家在变分估计器中的行为，以及实验异常值对互信息估计的影响。此外，还介绍了基于模型的贝叶斯估计的方法，适用于具有领域专业知识且需要不确定性量化的问题。

    

    互信息量化了两个随机变量之间的依赖关系，并且在微分同胚下保持不变。在本文中，我们探讨了点间互信息的特征，这是互信息的推广形式，保持了这种不变性。我们在解析上描述了多元正态分布的特征，并引入了细分布家族，通过蒙特卡洛方法可以准确地逼近这种特征。然后，我们展示了如何利用细分布来研究现有互信息估计器的局限性，调查在变分估计器中使用的神经批评家的行为，并了解实验异常值对互信息估计的影响。最后，我们展示了如何利用细分布来获得基于模型的贝叶斯估计的互信息，适用于具有可用领域专业知识且需要不确定性量化的问题。

    Mutual information quantifies the dependence between two random variables and remains invariant under diffeomorphisms. In this paper, we explore the pointwise mutual information profile, an extension of mutual information that maintains this invariance. We analytically describe the profiles of multivariate normal distributions and introduce the family of fine distributions, for which the profile can be accurately approximated using Monte Carlo methods. We then show how fine distributions can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how fine distributions can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary.
    
[^17]: 非高斯有向无环图的结构迁移学习

    Structural transfer learning of non-Gaussian DAG. (arXiv:2310.10239v1 [stat.ML])

    [http://arxiv.org/abs/2310.10239](http://arxiv.org/abs/2310.10239)

    本文提出了一种用于非高斯有向无环图的结构迁移学习方法，通过引入新颖的DAG结构相似度度量并利用不同相似性水平的辅助DAG的信息，能够显著提高目标研究中的DAG重构效果。

    

    有向无环图(DAG)被广泛用于表示一组收集到的节点之间的方向关系。然而，一次单独研究中可用的数据往往有限，不足以准确地重构DAG，而异构数据可能会从多个相关研究中收集到。如何将异构数据汇集到目标研究中以更好地重构DAG结构仍然是一个未解决的问题。在本文中，我们首先引入了一套新颖的DAG结构相似度度量，然后提出了一个传输DAG学习框架，通过有效地利用不同相似性水平的辅助DAG的信息来提高目标研究中的DAG重构效果。我们的理论分析表明，在目标DAG没有整体与辅助DAG相似的情况下，我们的方法也能在DAG重构方面实现显著的改进，这与大多数现有的传输学习方法形成鲜明对比。我们的实验结果也支持了所提出的传输DAG学习的优势。

    Directed acyclic graph (DAG) has been widely employed to represent directional relationships among a set of collected nodes. Yet, the available data in one single study is often limited for accurate DAG reconstruction, whereas heterogeneous data may be collected from multiple relevant studies. It remains an open question how to pool the heterogeneous data together for better DAG structure reconstruction in the target study. In this paper, we first introduce a novel set of structural similarity measures for DAG and then present a transfer DAG learning framework by effectively leveraging information from auxiliary DAGs of different levels of similarities. Our theoretical analysis shows substantial improvement in terms of DAG reconstruction in the target study, even when no auxiliary DAG is overall similar to the target DAG, which is in sharp contrast to most existing transfer learning methods. The advantage of the proposed transfer DAG learning is also supported by extensive numerical ex
    
[^18]: 关于贝叶斯神经网络后验中置换对称性的研究: 一个变分角度

    On permutation symmetries in Bayesian neural network posteriors: a variational perspective. (arXiv:2310.10171v1 [stat.ML])

    [http://arxiv.org/abs/2310.10171](http://arxiv.org/abs/2310.10171)

    本文研究了贝叶斯神经网络后验中的置换对称性，揭示了在梯度下降的局部解之间基本上不存在损失阻碍。通过使用置换矩阵对齐两个贝叶斯解决方案的分布，提出了一种寻找线性相连解的匹配算法。

    

    神经网络中基于梯度的优化的难以捉摸的性质与其损失函数的几何形态有关，而这个几何形态目前还不太被理解。然而，最近的研究已经提供了坚实的证据，证明在梯度下降的局部解之间基本上不存在损失阻碍，只要考虑到保持网络计算不变的权重置换。这引发了对贝叶斯神经网络（BNNs）中近似推断的问题，我们关心的是在损失函数空间中对多个点进行边缘化。在这项工作中，我们首先将边缘化的损失阻碍和解插值的形式主义扩展到BNNs中，然后提出了一种匹配算法来寻找线性相连的解决方案。这是通过将两个独立的近似贝叶斯解决方案的分布与置换矩阵对齐来实现的。我们基于Ainsworth等人（2023）的结果，将问题重新框架为一个组合优化问题，并使用一种近似方法。

    The elusive nature of gradient-based optimization in neural networks is tied to their loss landscape geometry, which is poorly understood. However recent work has brought solid evidence that there is essentially no loss barrier between the local solutions of gradient descent, once accounting for weight-permutations that leave the network's computation unchanged. This raises questions for approximate inference in Bayesian neural networks (BNNs), where we are interested in marginalizing over multiple points in the loss landscape. In this work, we first extend the formalism of marginalized loss barrier and solution interpolation to BNNs, before proposing a matching algorithm to search for linearly connected solutions. This is achieved by aligning the distributions of two independent approximate Bayesian solutions with respect to permutation matrices. We build on the results of Ainsworth et al. (2023), reframing the problem as a combinatorial optimization one, using an approximation to the
    
[^19]: 用Wasserstein距离进行简化表示学习的实证研究

    An Empirical Study of Simplicial Representation Learning with Wasserstein Distance. (arXiv:2310.10143v1 [stat.ML])

    [http://arxiv.org/abs/2310.10143](http://arxiv.org/abs/2310.10143)

    本文研究了在树结构上利用Wasserstein距离进行简化表示学习的问题，并提出了一种基于SimCLR和负TWD的自监督学习方法来估计简化表示，通过实证研究找到了稳定的训练策略。

    

    本文探讨了在树结构上利用1-Wasserstein距离进行简化表示学习的问题，其中树- Wasserstein距离(TWD)定义为两个树嵌入向量之间的L1距离。具体而言，我们考虑了一种基于SimCLR和负TWD作为相似度度量的自监督学习方法来估计简化表示。在SimCLR中，通常使用与实向量嵌入的余弦相似度，但是尚未对利用L1距离与简化嵌入进行深入研究。一个关键挑战是训练L1距离在数值上具有挑战性，并且往往会产生不令人满意的结果，概率模型的选择也有很多。因此，本研究从实证角度探究了用TWD优化自监督学习的策略，并找到了稳定的训练过程。更具体地说，我们评估了两种类型TWD的组合（总 ...

    In this paper, we delve into the problem of simplicial representation learning utilizing the 1-Wasserstein distance on a tree structure (a.k.a., Tree-Wasserstein distance (TWD)), where TWD is defined as the L1 distance between two tree-embedded vectors. Specifically, we consider a framework for simplicial representation estimation employing a self-supervised learning approach based on SimCLR with a negative TWD as a similarity measure. In SimCLR, the cosine similarity with real-vector embeddings is often utilized; however, it has not been well studied utilizing L1-based measures with simplicial embeddings. A key challenge is that training the L1 distance is numerically challenging and often yields unsatisfactory outcomes, and there are numerous choices for probability models. Thus, this study empirically investigates a strategy for optimizing self-supervised learning with TWD and find a stable training procedure. More specifically, we evaluate the combination of two types of TWD (total
    
[^20]: 提升SMPC: 在神经网络推断中跨越可扩展性、内存效率和隐私之间的差距

    Empowering SMPC: Bridging the Gap Between Scalability, Memory Efficiency and Privacy in Neural Network Inference. (arXiv:2310.10133v1 [cs.CR])

    [http://arxiv.org/abs/2310.10133](http://arxiv.org/abs/2310.10133)

    本文提出了一个高效的开源SMPC仓库，解决了在资源有限的机器上实现SMPC协议的实际和可扩展性问题，并通过优化内存使用、减少执行时间和提高效率的方法，在保护数据隐私的同时完成了MNIST数据集推断任务。

    

    本文旨在开发一个高效的开源Secure Multi-Party Computation（SMPC）仓库，解决了在中等计算资源的机器上实现SMPC协议的实际和可扩展性问题，并旨在减少执行时间。我们实现了ABY2.0协议，为开发人员提供了在ABY 2.0协议上构建应用程序的有效工具。文章解决了基于C++的MOTION2NX框架的限制，包括内存限制和操作兼容性问题。我们的改进包括优化内存使用、利用第三方Helper节点减少执行时间，并在保护数据隐私的同时提高效率。这些优化使得MNIST数据集的推断只需32秒，仅需0.2GB的RAM用于5层神经网络。相比之下，之前的基准实现需要8.03GB的RAM和200秒的执行时间。

    This paper aims to develop an efficient open-source Secure Multi-Party Computation (SMPC) repository, that addresses the issue of practical and scalable implementation of SMPC protocol on machines with moderate computational resources, while aiming to reduce the execution time. We implement the ABY2.0 protocol for SMPC, providing developers with effective tools for building applications on the ABY 2.0 protocol. This article addresses the limitations of the C++ based MOTION2NX framework for secure neural network inference, including memory constraints and operation compatibility issues. Our enhancements include optimizing the memory usage, reducing execution time using a third-party Helper node, and enhancing efficiency while still preserving data privacy. These optimizations enable MNIST dataset inference in just 32 seconds with only 0.2 GB of RAM for a 5-layer neural network. In contrast, the previous baseline implementation required 8.03 GB of RAM and 200 seconds of execution time.
    
[^21]: 从连续动力学到图神经网络：神经扩散与更多

    From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond. (arXiv:2310.10121v1 [cs.LG])

    [http://arxiv.org/abs/2310.10121](http://arxiv.org/abs/2310.10121)

    本综述系统全面地回顾了利用连续动力学框架的图神经网络，以帮助从根本上理解和改进GNN的能力和缺陷。

    

    图神经网络（GNN）在建模关系数据方面表现出显著的潜力，并在各个领域得到广泛应用。GNN背后的关键机制是所谓的消息传递，它通过从邻居节点中集中地聚合信息来进行迭代。这种方案与称为热传导的物理过程密切相关，其中GNN的传播自然对应于热密度的演化。将消息传递过程类比为热动力学可以从根本上理解GNN的能力和缺陷，从而有助于更好地设计模型。最近出现了大量旨在减轻GNN已知限制（如过度平滑和过度压缩）的GNN提出作品，这些作品受到连续动力学的启发。在本综述中，我们首次系统全面地回顾了利用连续动力学框架的研究。

    Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuou
    
[^22]: 后验采样学习算法在序列化POMDPs中的遗憾分析

    Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs. (arXiv:2310.10107v1 [cs.LG])

    [http://arxiv.org/abs/2310.10107](http://arxiv.org/abs/2310.10107)

    本文分析了后验采样学习算法在序列化POMDPs中的遗憾性能，并在一定条件下提供了改进的多项式贝叶斯遗憾界。

    

    相比于马尔科夫决策过程（MDPs），部分可观察马尔科夫决策过程（POMDPs）的学习由于观察数据难以解读而变得更加困难。在本文中，我们考虑了具有未知转移和观测模型的POMDPs中的序列化学习问题。我们考虑了基于后验采样的强化学习算法（PSRL）在POMDPs中的应用，并证明其贝叶斯遗憾随着序列的数量的平方根而缩小。一般来说，遗憾随着时间长度$H$呈指数级增长，并通过提供一个下界证明了这一点。然而，在POMDP是欠完备且弱可识别的条件下，我们建立了一个多项式贝叶斯遗憾界，相比于arXiv:2204.08967的最新结果，改进了遗憾界约$\Omega(H^2\sqrt{SA})$倍。

    Compared to Markov Decision Processes (MDPs), learning in Partially Observable Markov Decision Processes (POMDPs) can be significantly harder due to the difficulty of interpreting observations. In this paper, we consider episodic learning problems in POMDPs with unknown transition and observation models. We consider the Posterior Sampling-based Reinforcement Learning (PSRL) algorithm for POMDPs and show that its Bayesian regret scales as the square root of the number of episodes. In general, the regret scales exponentially with the horizon length $H$, and we show that this is inevitable by providing a lower bound. However, under the condition that the POMDP is undercomplete and weakly revealing, we establish a polynomial Bayesian regret bound that improves the regret bound by a factor of $\Omega(H^2\sqrt{SA})$ over the recent result by arXiv:2204.08967.
    
[^23]: 从标签比例中学习线性阈值（标题翻译）

    PAC Learning Linear Thresholds from Label Proportions. (arXiv:2310.10098v1 [cs.LG])

    [http://arxiv.org/abs/2310.10098](http://arxiv.org/abs/2310.10098)

    本文探讨了从标签比例中学习线性阈值函数的计算可学习性，提出了一种使用LTFs有效学习LTFs的方法。

    

    标签比例学习（LLP）是一种监督学习的泛化形式，其中训练数据以特征向量（实例）的集合或包的形式给出，同时还提供了每个包的平均实例标签。其目标是训练一个良好的实例分类器。尽管之前的LLP研究主要集中在该训练数据上训练模型，但最近的工作[Saket'21, Saket'22]探索了LLP的计算可学习性，展示了从标签比例中准确学习线性阈值函数（LTFs）的最坏情况复杂性。然而，他们的工作没有排除在自然分布下该问题的高效算法。在本文中，我们展示了通过使用LTFs从某个标签比例的随机包获取的条件下标签独立地从高斯分布$N(\mathbf{\mu}, \mathbf{\Sigma})$中采样的特征向量，可以有效地学习LTFs。我们的工作表明，通过某种矩阵的形式-

    Learning from label proportions (LLP) is a generalization of supervised learning in which the training data is available as sets or bags of feature-vectors (instances) along with the average instance-label of each bag. The goal is to train a good instance classifier. While most previous works on LLP have focused on training models on such training data, computational learnability of LLP was only recently explored by [Saket'21, Saket'22] who showed worst case intractability of properly learning linear threshold functions (LTFs) from label proportions. However, their work did not rule out efficient algorithms for this problem on natural distributions.  In this work we show that it is indeed possible to efficiently learn LTFs using LTFs when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution $N(\mathbf{\mu}, \mathbf{\Sigma})$. Our work shows that a certain matrix -- formed using
    
[^24]: LLP-Bench：一种用于从标签比例中学习的大规模表格基准

    LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions. (arXiv:2310.10096v1 [cs.LG])

    [http://arxiv.org/abs/2310.10096](http://arxiv.org/abs/2310.10096)

    本文提出了一个大规模表格LLP基准，填补了表格LLP领域的研究空白。在该基准中，我们可以创建特征bags，其中所有实例具有相同的特征值，从而更好地模拟实际应用场景。

    

    在学习从标签比例中学习（LLP）任务中，模型通过对实例组（称为bags）和相应的标签比例进行训练，以预测个体实例的标签。LLP主要应用于图像和表格两种数据集。在图像LLP中，通过从底层数据集中随机抽样实例来创建固定大小的bags。通过这种方法创建的bags称为随机bags。对图像LLP的实验主要集中在CIFAR-*和MNIST数据集的随机bags上。尽管表格LLP在隐私敏感应用中非常重要，但尚缺乏一个开放的、大规模的表格LLP基准。表格LLP的一个独特特性是能够创建特征bags，其中bag中的所有实例对于给定的特征具有相同的值。先前的研究表明，特征bags在实际的现实应用中非常常见。在本文中，我们解决了表格LLP的研究空白，提出了一个用于大规模表格LLP的基准。

    In the task of Learning from Label Proportions (LLP), a model is trained on groups (a.k.a bags) of instances and their corresponding label proportions to predict labels for individual instances. LLP has been applied pre-dominantly on two types of datasets - image and tabular. In image LLP, bags of fixed size are created by randomly sampling instances from an underlying dataset. Bags created via this methodology are called random bags. Experimentation on Image LLP has been mostly on random bags on CIFAR-* and MNIST datasets. Despite being a very crucial task in privacy sensitive applications, tabular LLP does not yet have a open, large scale LLP benchmark. One of the unique properties of tabular LLP is the ability to create feature bags where all the instances in a bag have the same value for a given feature. It has been shown in prior research that feature bags are very common in practical, real world applications [Chen et. al '23, Saket et. al. '22].  In this paper, we address the lac
    
[^25]: 通过聚合实现标签差分隐私

    Label Differential Privacy via Aggregation. (arXiv:2310.10092v1 [cs.LG])

    [http://arxiv.org/abs/2310.10092](http://arxiv.org/abs/2310.10092)

    以前研究表明朴素的LBA和LLP不能提供标签差分隐私。但本研究显示，使用具有随机抽样的加权LBA可以提供标签差分隐私。

    

    在许多现实应用中，特别是由于隐私领域的最新发展，训练数据可以进行聚合，以保护敏感训练标签的隐私。在标签比例学习(LLP)框架中，数据集被划分为特征向量的包，只能获得每个包中标签的总和。进一步限制的限制学习(LBA)是只能获得包的特征向量的总和（可能是加权的）。我们研究这种聚合技术是否能够在标签差分隐私(label-DP)的概念下提供隐私保证，该概念之前在[Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22]中进行了研究。很容易看出，朴素的LBA和LLP不能提供标签差分隐私。然而，我们的主要结果表明，使用具有$m$个随机抽样的不相交$k$-大小包的加权LBA实际上是$(\varepsilon,

    In many real-world applications, in particular due to recent developments in the privacy landscape, training data may be aggregated to preserve the privacy of sensitive training labels. In the learning from label proportions (LLP) framework, the dataset is partitioned into bags of feature-vectors which are available only with the sum of the labels per bag. A further restriction, which we call learning from bag aggregates (LBA) is where instead of individual feature-vectors, only the (possibly weighted) sum of the feature-vectors per bag is available. We study whether such aggregation techniques can provide privacy guarantees under the notion of label differential privacy (label-DP) previously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22].  It is easily seen that naive LBA and LLP do not provide label-DP. Our main result however, shows that weighted LBA using iid Gaussian weights with $m$ randomly sampled disjoint $k$-sized bags is in fact $(\varepsilon, 
    
[^26]: 黎曼残差神经网络

    Riemannian Residual Neural Networks. (arXiv:2310.10013v1 [stat.ML])

    [http://arxiv.org/abs/2310.10013](http://arxiv.org/abs/2310.10013)

    本论文研究了黎曼残差神经网络的扩展，将其应用于通用黎曼流形，提供了解决消失梯度问题的几何原理方法，并展示了其在机器学习中的优异表现。

    

    近年来，在几何深度学习中，引入了各种神经网络来处理处于黎曼流形上的数据。这样的网络通常用于在具有分层结构的图形上学习，或者用于在自然科学中遇到的流形值数据上学习。这些网络常常受到标准欧几里得神经网络的启发，并直接推广。然而，扩展欧几里得网络是困难的，并且只适用于少数几个流形。在这项工作中，我们研究了残差神经网络（ResNet）并展示了如何以几何原理的方式将其扩展到通用黎曼流形上。ResNet最初被引入来帮助解决消失梯度问题，由于其良好的学习性质、优异的实验结果和易于构建不同神经网络的特点，这种网络已经广泛应用于机器学习。

    Recent methods in geometric deep learning have introduced various neural networks to operate over data that lie on Riemannian manifolds. Such networks are often necessary to learn well over graphs with a hierarchical structure or to learn over manifold-valued data encountered in the natural sciences. These networks are often inspired by and directly generalize standard Euclidean neural networks. However, extending Euclidean networks is difficult and has only been done for a select few manifolds. In this work, we examine the residual neural network (ResNet) and show how to extend this construction to general Riemannian manifolds in a geometrically principled manner. Originally introduced to help solve the vanishing gradient problem, ResNets have become ubiquitous in machine learning due to their beneficial learning properties, excellent empirical results, and easy-to-incorporate nature when building varied neural networks. We find that our Riemannian ResNets mirror these desirable prope
    
[^27]: 通过软上升-下降实现隐式正则化

    Implicit regularization via soft ascent-descent. (arXiv:2310.10006v1 [stat.ML])

    [http://arxiv.org/abs/2310.10006](http://arxiv.org/abs/2310.10006)

    本研究提出了一种通过软化的逐点机制（SoftAD）来实现正则化的方法，该方法具有更好的鲁棒性，可以减少超参数的影响，并保留上升-下降效应。

    

    随着模型变得越来越大和复杂，通过最小的试错来实现更好的离线泛化对机器学习工作流程的可靠性和经济性至关重要。作为寻求“平坦”局部最小值的众所周知的启发式方法的代理，梯度正则化是一条自然的途径，一阶近似方法如Floding和Sharpness-Aware Minimization (SAM) 已经受到了相当大的关注，但它们的性能严重依赖于超参数（洪水阈值和邻域半径），这些超参数不容易事先确定。为了开发一个对错误超参数更具韧性的过程，受Flooding中使用的硬阈值“上升-下降”开关装置的启发，我们提出了一种软化的逐点机制，称为SoftAD，它对边界上的点进行降权，限制异常值的影响，并保留上升-下降效应。我们将形式的平稳性保证与Flooding进行对比。

    As models grow larger and more complex, achieving better off-sample generalization with minimal trial-and-error is critical to the reliability and economy of machine learning workflows. As a proxy for the well-studied heuristic of seeking "flat" local minima, gradient regularization is a natural avenue, and first-order approximations such as Flooding and sharpness-aware minimization (SAM) have received significant attention, but their performance depends critically on hyperparameters (flood threshold and neighborhood radius, respectively) that are non-trivial to specify in advance. In order to develop a procedure which is more resilient to misspecified hyperparameters, with the hard-threshold "ascent-descent" switching device used in Flooding as motivation, we propose a softened, pointwise mechanism called SoftAD that downweights points on the borderline, limits the effects of outliers, and retains the ascent-descent effect. We contrast formal stationarity guarantees with those for Flo
    
[^28]: 《一种符合环境的鲁棒性优化方法》

    Conformal Contextual Robust Optimization. (arXiv:2310.10003v1 [stat.ME])

    [http://arxiv.org/abs/2310.10003](http://arxiv.org/abs/2310.10003)

    提出了一种Conformal-Predict-Then-Optimize（CPO）框架，利用高维非凸拟合预测区域，在数据驱动的预测-优化决策问题中减轻了安全关键环境中不确定性区域建模错误的风险，并通过提供语义可理解的可视化总结来解释最优决策。

    

    数据驱动的预测-优化决策问题的方法旨在减轻安全关键环境中不确定性区域建模错误的风险。然而，目前的方法往往考虑过于保守的不确定性区域，导致次优的决策结果。为此，我们提出了一种名为Conformal-Predict-Then-Optimize (CPO)的框架，该框架利用基于条件生成模型的高维非凸拟合预测区域，具有期望的无分布性保证。尽管能够保证鲁棒性，但仅仅使用这种黑盒优化过程会带来很少的置信度，因为无法解释为何某个决策被认为是最优的。因此，我们还增加了CPO的功能，可以提供对不确定性区域的语义可理解的可视化总结，以便直观地理解最优决策。我们通过展示来突出CPO框架的重要性。

    Data-driven approaches to predict-then-optimize decision-making problems seek to mitigate the risk of uncertainty region misspecification in safety-critical settings. Current approaches, however, suffer from considering overly conservative uncertainty regions, often resulting in suboptimal decisionmaking. To this end, we propose Conformal-Predict-Then-Optimize (CPO), a framework for leveraging highly informative, nonconvex conformal prediction regions over high-dimensional spaces based on conditional generative models, which have the desired distribution-free coverage guarantees. Despite guaranteeing robustness, such black-box optimization procedures alone inspire little confidence owing to the lack of explanation of why a particular decision was found to be optimal. We, therefore, augment CPO to additionally provide semantically meaningful visual summaries of the uncertainty regions to give qualitative intuition for the optimal decision. We highlight the CPO framework by demonstrating
    
[^29]: 使用具有理论性能保证的生成模型进行异常值检测

    Outlier Detection Using Generative Models with Theoretical Performance Guarantees. (arXiv:2310.09999v1 [stat.ML])

    [http://arxiv.org/abs/2310.09999](http://arxiv.org/abs/2310.09999)

    本文提出了一种利用生成模型进行异常值检测的方法，建立了在受稀疏异常值下使用生成模型重建信号的理论保证，给出了下界，并提出了两个算法解决异常值检测问题。

    

    本文考虑了利用生成模型从受稀疏异常值污染的线性测量中恢复信号的问题。我们提出了一种用于在受稀疏异常值下重建由生成模型建模的真实信号的异常值检测方法。我们在存在异常值的情况下建立了使用生成模型重建信号的理论恢复保证，并给出了可纠正异常值数量的下界。我们的结果适用于具有任意层数的线性生成器神经网络和非线性生成器神经网络。我们提出了一种用于通过$\ell_1$范数最小化解决异常值检测问题的迭代交替方向乘子法（ADMM）算法，以及一种用于通过平方$\ell_1$范数最小化解决异常值检测问题的梯度下降算法。我们使用变分自编码器和深度卷积生成对抗网络进行了广泛实验。

    This paper considers the problem of recovering signals modeled by generative models from linear measurements contaminated with sparse outliers. We propose an outlier detection approach for reconstructing the ground-truth signals modeled by generative models under sparse outliers. We establish theoretical recovery guarantees for reconstruction of signals using generative models in the presence of outliers, giving lower bounds on the number of correctable outliers. Our results are applicable to both linear generator neural networks and the nonlinear generator neural networks with an arbitrary number of layers. We propose an iterative alternating direction method of multipliers (ADMM) algorithm for solving the outlier detection problem via $\ell_1$ norm minimization, and a gradient descent algorithm for solving the outlier detection problem via squared $\ell_1$ norm minimization. We conduct extensive experiments using variational auto-encoder and deep convolutional generative adversarial 
    
[^30]: 伪贝叶斯优化

    Pseudo-Bayesian Optimization. (arXiv:2310.09766v1 [stat.ML])

    [http://arxiv.org/abs/2310.09766](http://arxiv.org/abs/2310.09766)

    本文提出了伪贝叶斯优化，并通过研究最小要求的公理框架，构建了能确保黑盒优化收敛性的算法。

    

    贝叶斯优化是一种优化昂贵黑盒函数的流行方法。其关键思想是使用一个替代模型来近似目标，并且重要的是量化相关的不确定性，从而实现探索和开发之间的平衡的顺序搜索。高斯过程(GP)一直是替代模型的首选，因为它具有贝叶斯的不确定性量化能力和建模灵活性。然而，它的挑战也引发了一系列收敛性更显得不明显的备选方案。在本文中，我们通过研究引出最小要求的公理框架来确保黑盒优化的收敛性，以应用于除了GP相关方法之外的情况。此外，我们利用我们的框架中的设计自由，我们称之为伪贝叶斯优化，来构建经验上更优的算法。特别地，我们展示了如何使用简单的局部回归和一个适应问题特性的代理模型来实现这一目标。

    Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-related methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a sui
    
[^31]: 带有Mondrian随机森林的推理

    Inference with Mondrian Random Forests. (arXiv:2310.09702v1 [math.ST])

    [http://arxiv.org/abs/2310.09702](http://arxiv.org/abs/2310.09702)

    本文在回归设置下给出了Mondrian随机森林的估计中心极限定理和去偏过程，使其能够进行统计推断和实现最小极大估计速率。

    

    随机森林是一种常用的分类和回归方法，在最近几年中提出了许多不同的变体。一个有趣的例子是Mondrian随机森林，其中底层树是根据Mondrian过程构建的。在本文中，我们给出了Mondrian随机森林在回归设置下的估计的中心极限定理。当与偏差表征和一致方差估计器相结合时，这允许进行渐近有效的统计推断，如构建置信区间，对未知的回归函数进行推断。我们还提供了一种去偏过程，用于Mondrian随机森林，使其能够在适当的参数调整下实现$\beta$-H\"older回归函数的最小极大估计速率，对于所有的$\beta$和任意维度。

    Random forests are popular methods for classification and regression, and many different variants have been proposed in recent years. One interesting example is the Mondrian random forest, in which the underlying trees are constructed according to a Mondrian process. In this paper we give a central limit theorem for the estimates made by a Mondrian random forest in the regression setting. When combined with a bias characterization and a consistent variance estimator, this allows one to perform asymptotically valid statistical inference, such as constructing confidence intervals, on the unknown regression function. We also provide a debiasing procedure for Mondrian random forests which allows them to achieve minimax-optimal estimation rates with $\beta$-H\"older regression functions, for all $\beta$ and in arbitrary dimension, assuming appropriate parameter tuning.
    
[^32]: DPZero：与维度无关且具有差分隐私的零阶优化算法

    DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization. (arXiv:2310.09639v1 [cs.LG])

    [http://arxiv.org/abs/2310.09639](http://arxiv.org/abs/2310.09639)

    该论文提出了DPZero算法，这是一种与维度无关且具有差分隐私的零阶优化算法，用于解决在细调大型语言模型时面临的内存和隐私挑战。

    

    在细调预训练的大型语言模型（LLM）以适应特定领域数据的广泛实践中，面临着内存和隐私两个主要挑战。首先，随着LLM的规模不断增长，达到数十亿个参数，基于梯度的反向传播训练方法所需的内存消耗变得难以承受。其次，考虑到LLM倾向于记忆和泄露敏感的训练数据，必须保护细调数据的隐私。为此，我们探索了将零阶方法与差分隐私优化相结合用于LLM的细调的潜力。零阶方法仅依赖前向传递，大大减少了训练过程中的内存消耗。然而，直接将它们与标准的差分隐私机制结合在一起会导致维度相关的复杂性。为了弥合这一差距，我们引入了DPZero，一种具有近乎维度无关率的新型差分隐私零阶算法。我们的理论分析揭示出了

    The widespread practice of fine-tuning pretrained large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continue to grow, encompassing billions of parameters, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize and disclose sensitive training data, the privacy of fine-tuning data must be respected. To this end, we explore the potential of zeroth-order methods in differentially private optimization for fine-tuning LLMs. Zeroth-order methods, which rely solely on forward passes, substantially reduce memory consumption during training. However, directly combining them with standard differential privacy mechanism poses dimension-dependent complexity. To bridge the gap, we introduce DPZero, a novel differentially private zeroth-order algorithm with nearly dimension-independent rates. Our theoretical analysis reveals that 
    
[^33]: 两枚硬币的两面：通过同伦延续连接深度平衡模型和神经常微分方程

    Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural ODEs via Homotopy Continuation. (arXiv:2310.09583v1 [cs.LG])

    [http://arxiv.org/abs/2310.09583](http://arxiv.org/abs/2310.09583)

    通过同伦延续，我们建立了深度平衡模型（DEQs）和神经常微分方程（Neural ODEs）之间的连接，并提出了一种新的隐式模型HomoODE，它继承了DEQs的高精度性能和Neural ODEs的稳定性。

    

    深度平衡模型（DEQs）和神经常微分方程（Neural ODEs）是两种隐式模型的分支，以其卓越的性能和低内存消耗成就了显著的成功。虽然两者都是隐式模型，但DEQs和Neural ODEs是从不同的数学形式导出的。受同伦延续的启发，我们建立了这两种模型之间的联系，并表明它们实际上是同一个硬币的两面。同伦延续是一种基于对应ODE的解非线性方程组的经典方法。给定这种联系，我们提出了一种新的隐式模型称为HomoODE，它继承了DEQs的高精度性质和Neural ODEs的稳定性。与DEQs不同，HomoODE通过同伦延续使用修改后的神经常微分方程隐式地解决平衡点找寻问题。

    Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations (Neural ODEs) are two branches of implicit models that have achieved remarkable success owing to their superior performance and low memory consumption. While both are implicit models, DEQs and Neural ODEs are derived from different mathematical formulations. Inspired by homotopy continuation, we establish a connection between these two models and illustrate that they are actually two sides of the same coin. Homotopy continuation is a classical method of solving nonlinear equations based on a corresponding ODE. Given this connection, we proposed a new implicit model called HomoODE that inherits the property of high accuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs, which explicitly solve an equilibrium-point-finding problem via Newton's methods in the forward pass, HomoODE solves the equilibrium-point-finding problem implicitly using a modified Neural ODE via homotopy continuation. Fur
    
[^34]: ARTree: 一种用于系统发育推断的深度自回归模型

    ARTree: A Deep Autoregressive Model for Phylogenetic Inference. (arXiv:2310.09553v1 [q-bio.PE])

    [http://arxiv.org/abs/2310.09553](http://arxiv.org/abs/2310.09553)

    ARTree是一种用于系统发育推断的深度自回归模型，通过使用图神经网络对树形拓扑结构的条件分布进行建模，能够提供整个树形拓扑空间的丰富分布，并具有简单的采样算法和密度估计过程。

    

    设计灵活的概率模型来建立树形拓扑结构对于开发高效的系统发育推断方法至关重要。为了做到这一点，之前的工作往往利用树形拓扑结构的相似性，通过手工设计的启发式特征来实现，这需要预先采样树形拓扑结构，并且可能受限于近似能力有限。在本文中，我们提出了一种基于图神经网络(GNNs)的深度自回归模型用于系统发育推断，称为ARTree。通过将树形拓扑结构分解为一系列叶节点添加操作，并利用可学习的拓扑特征通过GNNs对所涉及的条件分布进行建模，ARTree可以提供一个丰富的分布族，覆盖整个树形拓扑空间，并具有简单的采样算法和密度估计过程，而无需使用启发式特征。我们在具有挑战性的真实数据树形拓扑密度估计和变分推断基准上展示了我们方法的效果和效率。

    Designing flexible probabilistic models over tree topologies is important for developing efficient phylogenetic inference methods. To do that, previous works often leverage the similarity of tree topologies via hand-engineered heuristic features which would require pre-sampled tree topologies and may suffer from limited approximation capability. In this paper, we propose a deep autoregressive model for phylogenetic inference based on graph neural networks (GNNs), called ARTree. By decomposing a tree topology into a sequence of leaf node addition operations and modeling the involved conditional distributions based on learnable topological features via GNNs, ARTree can provide a rich family of distributions over the entire tree topology space that have simple sampling algorithms and density estimation procedures, without using heuristic features. We demonstrate the effectiveness and efficiency of our method on a benchmark of challenging real data tree topology density estimation and vari
    
[^35]: 一种半参数的工具变差分方法用于政策学习

    A Semiparametric Instrumented Difference-in-Differences Approach to Policy Learning. (arXiv:2310.09545v1 [stat.ME])

    [http://arxiv.org/abs/2310.09545](http://arxiv.org/abs/2310.09545)

    提出了一种半参数的工具变差分方法，用于学习最优治疗政策，并构建了一些估计器来解决平行趋势假设不成立的问题。

    

    最近，针对差异对差异（DiD）方法进行因果效应评估的方法学发展有所增加。文献中的标准方法依赖于平行趋势假设来识别对待处理的平均处理效应。然而，在存在未测定混淆的情况下，平行趋势假设可能会被违反，并且对待处理的平均处理效应可能对整个人群的治疗分配政策学习没有用处。在本文中，我们提出了一种通用的工具变差分方法来学习最优的治疗政策。具体来说，我们建立了一个二进制工具变量（IV）的识别结果，当平行趋势假设不成立时。此外，我们构建了瓦尔德估计器、新颖的反概率加权估计器（IPW）和一类半参数有效且多重鲁棒估计器，具有一致性和渐近正态性的理论保证，

    Recently, there has been a surge in methodological development for the difference-in-differences (DiD) approach to evaluate causal effects. Standard methods in the literature rely on the parallel trends assumption to identify the average treatment effect on the treated. However, the parallel trends assumption may be violated in the presence of unmeasured confounding, and the average treatment effect on the treated may not be useful in learning a treatment assignment policy for the entire population. In this article, we propose a general instrumented DiD approach for learning the optimal treatment policy. Specifically, we establish identification results using a binary instrumental variable (IV) when the parallel trends assumption fails to hold. Additionally, we construct a Wald estimator, novel inverse probability weighting (IPW) estimators, and a class of semiparametric efficient and multiply robust estimators, with theoretical guarantees on consistency and asymptotic normality, even 
    
[^36]: 通过负采样诱导的GNN层进行高效的链接预测

    Efficient Link Prediction via GNN Layers Induced by Negative Sampling. (arXiv:2310.09516v1 [cs.LG])

    [http://arxiv.org/abs/2310.09516](http://arxiv.org/abs/2310.09516)

    本研究提出了一种新颖的GNN架构，通过负采样诱导了正边和负边的正向传递，以更加灵活而稳定地进行链接预测。

    

    链接预测中的图神经网络(GNN)可以大致分为两大类。第一类是基于节点的结构，为每个节点预先计算个体嵌入，并通过简单的解码器进行组合以进行预测。尽管在推理时非常高效（因为节点嵌入只计算一次并反复重用），但模型表达能力有限，导致无法区分对候选边有贡献的同构节点，从而影响准确性。与之相反，第二类方法则依赖于形成针对每个边的子图嵌入，以丰富两两关系的表示，从而消除同构节点，提高准确性，但代价是增加了模型复杂度。为了更好地权衡这个取舍，我们提出了一种新颖的GNN架构，其中的正向传递明确依赖于正边（通常情况下）和负边（我们方法的独特之处），以提供更灵活但仍稳定的信号。

    Graph neural networks (GNNs) for link prediction can loosely be divided into two broad categories. First, \emph{node-wise} architectures pre-compute individual embeddings for each node that are later combined by a simple decoder to make predictions. While extremely efficient at inference time (since node embeddings are only computed once and repeatedly reused), model expressiveness is limited such that isomorphic nodes contributing to candidate edges may not be distinguishable, compromising accuracy. In contrast, \emph{edge-wise} methods rely on the formation of edge-specific subgraph embeddings to enrich the representation of pair-wise relationships, disambiguating isomorphic nodes to improve accuracy, but with the cost of increased model complexity. To better navigate this trade-off, we propose a novel GNN architecture whereby the \emph{forward pass} explicitly depends on \emph{both} positive (as is typical) and negative (unique to our approach) edges to inform more flexible, yet sti
    
[^37]: 通过物理潜在空间学习图像动态

    Learning In-between Imagery Dynamics via Physical Latent Spaces. (arXiv:2310.09495v1 [cs.LG])

    [http://arxiv.org/abs/2310.09495](http://arxiv.org/abs/2310.09495)

    本文提出了一个学习图像动态的框架，通过潜在动态估计图像演变的中间阶段，从而实现解释性，并保留与图像的空间相关性。该方法通过使用遵循物理模型的潜在变量，确保了学习模型的可解释性，并在地球科学图像数据上展示了其鲁棒性和有效性。

    

    我们提出了一个框架，旨在学习在连续时间步骤中观察到的两个图像之间的底层动态。图像数据的复杂性和缺乏时间信息导致在捕捉独特的演变模式时存在重大挑战。我们提出的方法专注于估计图像演变的中间阶段，通过潜在动态实现可解释性，同时保留与图像的空间相关性。通过将遵循偏微分方程（PDEs）的物理模型表达的潜在变量纳入我们的方法中，我们的方法确保了学习模型的可解释性，并提供了对应的图像动态的洞察力。我们通过一系列使用地球科学图像数据的数值测试证明了我们学习框架的稳健性和有效性。

    We present a framework designed to learn the underlying dynamics between two images observed at consecutive time steps. The complex nature of image data and the lack of temporal information pose significant challenges in capturing the unique evolving patterns. Our proposed method focuses on estimating the intermediary stages of image evolution, allowing for interpretability through latent dynamics while preserving spatial correlations with the image. By incorporating a latent variable that follows a physical model expressed in partial differential equations (PDEs), our approach ensures the interpretability of the learned model and provides insight into corresponding image dynamics. We demonstrate the robustness and effectiveness of our learning framework through a series of numerical tests using geoscientific imagery data.
    
[^38]: 使用自适应时间-上下文学习优化多变量预测

    ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning. (arXiv:2310.09488v1 [stat.ML])

    [http://arxiv.org/abs/2310.09488](http://arxiv.org/abs/2310.09488)

    本研究提出了ARM，一种多变量的时间-上下文自适应学习方法，用于优化长期时间序列预测。ARM通过采用自适应单变量效应学习、随机丢弃训练策略和多核局部平滑，能更好地处理时间模式和学习系列之间的依赖关系。在多个基准测试中，ARM展示了卓越的性能，而计算成本相对较低。

    

    长期时间序列预测（LTSF）在各个领域中都很重要，但在处理复杂的时间-上下文关系方面面临挑战。由于多变量输入模型表现不如最近的一些单变量模型，我们认为问题在于现有的多变量LTSF变压器模型无法高效地建模系列之间的关系：往往不能正确地捕捉到系列之间的特征差异。为了解决这个问题，我们引入了ARM：一种多变量的时间-上下文自适应学习方法，它是专门为多变量LTSF建模而设计的增强型架构。ARM采用自适应单变量效应学习（AUEL）、随机丢弃（RD）训练策略和多核局部平滑（MKLS）来更好地处理单个系列的时间模式并正确学习系列之间的依赖关系。ARM在多个基准测试上展示了卓越的性能，而与现有方法相比并没有显著增加计算成本。

    Long-term time series forecasting (LTSF) is important for various domains but is confronted by challenges in handling the complex temporal-contextual relationships. As multivariate input models underperforming some recent univariate counterparts, we posit that the issue lies in the inefficiency of existing multivariate LTSF Transformers to model series-wise relationships: the characteristic differences between series are often captured incorrectly. To address this, we introduce ARM: a multivariate temporal-contextual adaptive learning method, which is an enhanced architecture specifically designed for multivariate LTSF modelling. ARM employs Adaptive Univariate Effect Learning (AUEL), Random Dropping (RD) training strategy, and Multi-kernel Local Smoothing (MKLS), to better handle individual series temporal patterns and correctly learn inter-series dependencies. ARM demonstrates superior performance on multiple benchmarks without significantly increasing computational costs compared to
    
[^39]: 使用行列式抽样进行信号重建

    Signal reconstruction using determinantal sampling. (arXiv:2310.09437v1 [stat.ML])

    [http://arxiv.org/abs/2310.09437](http://arxiv.org/abs/2310.09437)

    本研究提出了使用行列式抽样进行信号重建的方法，在有限数量的随机节点评估中近似表示方可积函数，实现了快速收敛和更高的适应性正则性。

    

    我们研究了从随机节点的有限数量评估中近似表示一个方可积函数的问题，其中随机节点的选择依据是一个精心选择的分布。当函数被假设属于再生核希尔伯特空间（RKHS）时，这尤为相关。本研究提出了将基于两种可能的节点概率分布的几个自然有限维逼近方法相结合。这些概率分布与行列式点过程相关，并利用RKHS的核函数来优化在随机设计中的RKHS适应性正则性。虽然先前的行列式抽样工作依赖于RKHS范数，我们证明了在$L^2$范数下的均方保证。我们表明，行列式点过程及其混合体可以产生快速收敛速度。我们的结果还揭示了当假设更多的平滑性时收敛速度如何变化，这种现象被称为超收敛。此外，行列式抽样推广了从Christoffel函数进行i.i.d.抽样的方法。

    We study the approximation of a square-integrable function from a finite number of evaluations on a random set of nodes according to a well-chosen distribution. This is particularly relevant when the function is assumed to belong to a reproducing kernel Hilbert space (RKHS). This work proposes to combine several natural finite-dimensional approximations based two possible probability distributions of nodes. These distributions are related to determinantal point processes, and use the kernel of the RKHS to favor RKHS-adapted regularity in the random design. While previous work on determinantal sampling relied on the RKHS norm, we prove mean-square guarantees in $L^2$ norm. We show that determinantal point processes and mixtures thereof can yield fast convergence rates. Our results also shed light on how the rate changes as more smoothness is assumed, a phenomenon known as superconvergence. Besides, determinantal sampling generalizes i.i.d. sampling from the Christoffel function which is
    
[^40]: 线下强化学习用于优化生产竞标策略

    Offline Reinforcement Learning for Optimizing Production Bidding Policies. (arXiv:2310.09426v1 [cs.LG])

    [http://arxiv.org/abs/2310.09426](http://arxiv.org/abs/2310.09426)

    该论文介绍了一种使用离线强化学习方法来优化生产环境中竞标策略的通用方法，该方法可以优化任何可微分的基础策略，只需要使用基础策略生成的数据。论文提出了一种混合代理架构，将基础策略与强化学习模块相结合。

    

    在线广告市场每秒进行数千次拍卖，对于希望在预算限制下优化支出的广告商来说，这是一个艰巨的挑战。因此，广告平台通常为他们的客户提供自动化代理人，代表他们实时大规模竞标。由于这些代理人由平台拥有但使用广告商的资金进行操作，因此在平衡代理人的可靠性和可解释性与优化性能方面存在着强烈的实际需求。我们提出了一种通过离线强化学习从真实数据中学习的方法，以优化生产环境中的竞标策略。这种方法可以用于优化任何可微分的基础策略（实际上是基于广告商能够轻松理解的原则的启发式策略），并且只需要由基础策略本身生成的数据。我们使用混合代理架构，将任意基础策略与强化学习模块相结合。

    The online advertising market, with its thousands of auctions run per second, presents a daunting challenge for advertisers who wish to optimize their spend under a budget constraint. Thus, advertising platforms typically provide automated agents to their customers, which act on their behalf to bid for impression opportunities in real time at scale. Because these proxy agents are owned by the platform but use advertiser funds to operate, there is a strong practical need to balance reliability and explainability of the agent with optimizing power. We propose a generalizable approach to optimizing bidding policies in production environments by learning from real data using offline reinforcement learning. This approach can be used to optimize any differentiable base policy (practically, a heuristic policy based on principles which the advertiser can easily understand), and only requires data generated by the base policy itself. We use a hybrid agent architecture that combines arbitrary ba
    
[^41]: 针对随机Metropolis-Hastings算法的统计保证

    Statistical guarantees for stochastic Metropolis-Hastings. (arXiv:2310.09335v1 [stat.ML])

    [http://arxiv.org/abs/2310.09335](http://arxiv.org/abs/2310.09335)

    该论文研究了针对随机Metropolis-Hastings算法的统计保证。通过引入简单的修正项，该方法可以避免计算成本上的损失，并通过分析非参数回归情景和深度神经网络回归的数值实例来证明了其在采样和可信区间方面的优势。

    

    Metropolis-Hastings步骤被广泛应用于基于梯度的马尔可夫链蒙特卡洛方法中的不确定性量化中。通过对批次计算接受概率，随机Metropolis-Hastings步骤节省了计算成本，但降低了有效样本量。我们展示了通过简单的修正项可以避免这个障碍。我们研究了如果在非参数回归设置中应用改进的随机Metropolis-Hastings方法从Gibbs后验分布中采样，则链的结果稳态分布的统计属性。针对深度神经网络回归，我们证明了PAC-Bayes预言不等式，它提供了最优的收缩速率，并分析了结果可信区间的直径和高置信概率。通过在高维参数空间中的数值实例，我们说明了随机Metropolis-Hastings算法的可信区间和收缩速率确实表现出类似的行为。

    A Metropolis-Hastings step is widely used for gradient-based Markov chain Monte Carlo methods in uncertainty quantification. By calculating acceptance probabilities on batches, a stochastic Metropolis-Hastings step saves computational costs, but reduces the effective sample size. We show that this obstacle can be avoided by a simple correction term. We study statistical properties of the resulting stationary distribution of the chain if the corrected stochastic Metropolis-Hastings approach is applied to sample from a Gibbs posterior distribution in a nonparametric regression setting. Focusing on deep neural network regression, we prove a PAC-Bayes oracle inequality which yields optimal contraction rates and we analyze the diameter and show high coverage probability of the resulting credible sets. With a numerical example in a high-dimensional parameter space, we illustrate that credible sets and contraction rates of the stochastic Metropolis-Hastings algorithm indeed behave similar to 
    
[^42]: 生成熵神经最优传输在空间内外映射中的应用

    Generative Entropic Neural Optimal Transport To Map Within and Across Spaces. (arXiv:2310.09254v1 [stat.ML])

    [http://arxiv.org/abs/2310.09254](http://arxiv.org/abs/2310.09254)

    该论文介绍了生成熵神经最优传输在测度到测度映射中的应用，解决了处理非平方欧氏距离成本、确定性蒙格映射、映射跨不可比较空间和质量守恒约束等实际挑战。

    

    学习测度到测度的映射是机器学习中的一个关键任务，尤其在生成建模中占据重要地位。近年来，受最优传输理论启发的技术不断涌现。结合神经网络模型，这些方法统称为"神经最优传输"，将最优传输作为归纳偏好：这些映射应该针对给定的成本函数是最优的，能以节约的方式（通过最小化位移）在空间内或空间间移动点。这一原则在直观上是合理的，但往往面临几个实际挑战，需要调整最优传输工具箱：处理其他非平方欧氏距离成本的挑战，确定性状况下的蒙格映射公式会限制灵活性，映射在不可比较的空间中会带来多个挑战，最优传输固有的质量守恒约束可能对异常数据给予过多的重视。

    Learning measure-to-measure mappings is a crucial task in machine learning, featured prominently in generative modeling. Recent years have witnessed a surge of techniques that draw inspiration from optimal transport (OT) theory. Combined with neural network models, these methods collectively known as \textit{Neural OT} use optimal transport as an inductive bias: such mappings should be optimal w.r.t. a given cost function, in the sense that they are able to move points in a thrifty way, within (by minimizing displacements) or across spaces (by being isometric). This principle, while intuitive, is often confronted with several practical challenges that require adapting the OT toolbox: cost functions other than the squared-Euclidean cost can be challenging to handle, the deterministic formulation of Monge maps leaves little flexibility, mapping across incomparable spaces raises multiple challenges, while the mass conservation constraint inherent to OT can provide too much credit to outli
    
[^43]: 计算可分解模型之间的边际和条件差异及其应用

    Computing Marginal and Conditional Divergences between Decomposable Models with Applications. (arXiv:2310.09129v1 [cs.LG])

    [http://arxiv.org/abs/2310.09129](http://arxiv.org/abs/2310.09129)

    提出了一种计算可分解模型之间边际和条件差异的方法，能够在高维分布中精确计算差异，具有广泛的应用价值。

    

    在许多应用中，计算两个高维分布之间的精确差异是有用的，但直接计算是不可行的。对于两个可分解模型（即弦图马尔可夫网络）的联合分布计算α-β差异（包括Kullback-Leibler差异和Hellinger距离）可以在指数时间内成为这些模型的树宽度。然而，将两个高维对象之间的不相似性减少为单个标量值可能是不具有信息性的。此外，在诸如监督学习的应用中，对于条件分布的差异可能更有兴趣。因此，我们提出了一种方法来计算两个可分解模型的任何边际或条件分布之间的精确α-β差异。以可行的方式进行此计算是非平凡的，因为我们需要对这些分布之间的差异进行分解，因此需要对条件分布进行分解。

    The ability to compute the exact divergence between two high-dimensional distributions is useful in many applications but doing so naively is intractable. Computing the alpha-beta divergence -- a family of divergences that includes the Kullback-Leibler divergence and Hellinger distance -- between the joint distribution of two decomposable models, i.e chordal Markov networks, can be done in time exponential in the treewidth of these models. However, reducing the dissimilarity between two high-dimensional objects to a single scalar value can be uninformative. Furthermore, in applications such as supervised learning, the divergence over a conditional distribution might be of more interest. Therefore, we propose an approach to compute the exact alpha-beta divergence between any marginal or conditional distribution of two decomposable models. Doing so tractably is non-trivial as we need to decompose the divergence between these distributions and therefore, require a decomposition over the m
    
[^44]: 使用最优输运器合并Transformer

    Transformer Fusion with Optimal Transport. (arXiv:2310.05719v1 [cs.LG])

    [http://arxiv.org/abs/2310.05719](http://arxiv.org/abs/2310.05719)

    本文介绍了一种使用最优输运来融合基于Transformer的网络的方法，可以对齐各种架构组件并允许不同大小的模型的融合，提供了一种新的高效压缩Transformer的方式。

    

    融合是一种将多个独立训练的神经网络合并以结合它们的能力的技术。过去的尝试仅限于全连接、卷积和残差网络的情况。本文提出了一种系统的方法，利用最优输运来融合两个或多个基于Transformer的网络，以（软）对齐各种架构组件。我们详细描述了一种层对齐的抽象方法，可以推广到任意架构，例如多头自注意力、层归一化和残差连接。我们通过各种消融研究讨论了如何处理这些架构组件。此外，我们的方法允许不同大小的模型进行融合（异构融合），为Transformer的压缩提供了一种新的高效方法。我们通过Vision Transformer进行图像分类任务以及自然语言

    Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities. Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks. In this paper, we present a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components. We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies. Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way for compression of Transformers. The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language
    
[^45]: 多重治疗和多个结果在治疗效果估计中的益处

    The Blessings of Multiple Treatments and Outcomes in Treatment Effect Estimation. (arXiv:2309.17283v1 [stat.ME])

    [http://arxiv.org/abs/2309.17283](http://arxiv.org/abs/2309.17283)

    多重治疗和多个结果的并行研究在治疗效果估计中可以互相协助实现因果识别。

    

    在存在未观测混杂的情况下评估因果效应是一个具有挑战性的问题。现有研究利用代理变量或多重治疗来调整混杂偏差。尤其是后一种方法将单一结果的影响归因于多重治疗，可以估计混杂控制的潜在变量。然而，这些方法主要关注单一结果，而在许多实际场景中，更感兴趣的是研究对多个结果的影响。此外，这些结果通常与多个治疗相关。例如，重症监护病房（ICU）中，医疗提供者评估治疗对多个健康指标的有效性。为了适应这些场景，我们考虑了一个新的设置，即多重治疗和多个结果。然后我们证明，在这种设置中涉及多个结果的并行研究可以互相协助实现因果识别，即

    Assessing causal effects in the presence of unobserved confounding is a challenging problem. Existing studies leveraged proxy variables or multiple treatments to adjust for the confounding bias. In particular, the latter approach attributes the impact on a single outcome to multiple treatments, allowing estimating latent variables for confounding control. Nevertheless, these methods primarily focus on a single outcome, whereas in many real-world scenarios, there is greater interest in studying the effects on multiple outcomes. Besides, these outcomes are often coupled with multiple treatments. Examples include the intensive care unit (ICU), where health providers evaluate the effectiveness of therapies on multiple health indicators. To accommodate these scenarios, we consider a new setting dubbed as multiple treatments and multiple outcomes. We then show that parallel studies of multiple outcomes involved in this setting can assist each other in causal identification, in the sense that
    
[^46]: 具有有界更新的迭代学习算法的泛化误差界限

    Generalization error bounds for iterative learning algorithms with bounded updates. (arXiv:2309.05077v1 [cs.LG])

    [http://arxiv.org/abs/2309.05077](http://arxiv.org/abs/2309.05077)

    本文研究了具有有界更新的迭代学习算法在非凸损失函数上的泛化特性，提出了一种新颖的泛化误差界限，利用了信息论技术。研究表明，在模型维度和训练数据样本数量相等的情况下，界限得到了改善。

    

    本文探讨了具有有界更新的迭代学习算法在非凸损失函数上的泛化特性，采用了信息论技术。我们的主要贡献是针对具有有界更新的算法提出了一种新颖的泛化误差界限，超出了以前只关注随机梯度下降（SGD）的范围。我们的方法引入了两个主要的创新之处：1）我们将互信息重新定义为更新的不确定性，提供了一种新的视角；2）我们不使用互信息的链式法则，而是采用方差分解技术来将信息分解到迭代中，从而允许简化的代理过程。我们在各种设置下分析了我们的泛化界限，并在模型维度以与训练数据样本数量相同的速率增加时展示了改进的界限。为了弥合理论与实践之间的差距，我们还研究了先前观察到的情况。

    This paper explores the generalization characteristics of iterative learning algorithms with bounded updates for non-convex loss functions, employing information-theoretic techniques. Our key contribution is a novel bound for the generalization error of these algorithms with bounded updates, extending beyond the scope of previous works that only focused on Stochastic Gradient Descent (SGD). Our approach introduces two main novelties: 1) we reformulate the mutual information as the uncertainty of updates, providing a new perspective, and 2) instead of using the chaining rule of mutual information, we employ a variance decomposition technique to decompose information across iterations, allowing for a simpler surrogate process. We analyze our generalization bound under various settings and demonstrate improved bounds when the model dimension increases at the same rate as the number of training data samples. To bridge the gap between theory and practice, we also examine the previously obse
    
[^47]: 基于相关性的模糊聚类有效性指标与次要选项检测器

    A correlation-based fuzzy cluster validity index with secondary options detector. (arXiv:2308.14785v1 [stat.ML])

    [http://arxiv.org/abs/2308.14785](http://arxiv.org/abs/2308.14785)

    本研究提出了一种基于相关性的模糊聚类有效性指标，该指标考虑了在聚类数量选择时可能存在的多个选项，并通过评估在多种数据集上的性能，与现有指标进行比较。

    

    应用聚类分析时，最佳聚类数量是主要关注点之一。已经引入了多个聚类有效性指标来解决这个问题。然而，在某些情况下，有多个选项可以作为最终的聚类数量。大多数现有工作在这个领域忽视了这一方面。在本研究中，我们引入了一种基于相关性的模糊聚类有效性指标，称为Wiroonsri-Preedasawakul（WP）指标。该指标根据一对数据点的实际距离与相应对的调整质心之间的距离之间的相关性来定义。我们评估并比较了我们的指标与Xie-Beni，Pakhira-Bandyopadhyay-Maulik，Tang，Wu-Li，广义C和Kwon2等几个现有指标的性能。我们在四种类型的数据集上进行了评估：人工数据集，现实世界数据集，带有等级的模拟数据集和图像数据集，使用模糊c-mea算法。

    The optimal number of clusters is one of the main concerns when applying cluster analysis. Several cluster validity indexes have been introduced to address this problem. However, in some situations, there is more than one option that can be chosen as the final number of clusters. This aspect has been overlooked by most of the existing works in this area. In this study, we introduce a correlation-based fuzzy cluster validity index known as the Wiroonsri-Preedasawakul (WP) index. This index is defined based on the correlation between the actual distance between a pair of data points and the distance between adjusted centroids with respect to that pair. We evaluate and compare the performance of our index with several existing indexes, including Xie-Beni, Pakhira-Bandyopadhyay-Maulik, Tang, Wu-Li, generalized C, and Kwon2. We conduct this evaluation on four types of datasets: artificial datasets, real-world datasets, simulated datasets with ranks, and image datasets, using the fuzzy c-mea
    
[^48]: 大图上马尔可夫链的路径收敛性

    Path convergence of Markov chains on large graphs. (arXiv:2308.09214v1 [math.PR])

    [http://arxiv.org/abs/2308.09214](http://arxiv.org/abs/2308.09214)

    本文研究了大图上的马尔可夫链收敛性。通过研究欧几里德随机优化算法和Metropolis MCMC算法的改进版本在图上的表现，我们得出了随着图大小趋近于无穷大，随机过程的轨迹会收敛到确定性极限的结论。这些极限是测度值图上的曲线，通过引入新的度量，在这个空间中提供了自然的收敛概念。

    

    我们研究了有限无标度图上的两类自然随机过程。这些过程包括在加权图的邻接矩阵上的欧几里德随机优化算法以及在无权图上的Metropolis MCMC算法的改进版本。在这两种情况下，我们证明随着图的规模趋近于无穷大，随机过程的随机轨迹收敛于确定性极限。这些确定性极限是测度值图上的曲线。由Lov\'{a}sz和Szegedy引入的测度值图是图构架概念的细化，能够区分使得相同图构架极限的两个无穷可交换数组。我们在这个空间上引入了新的度量，为我们的极限定理提供了自然的收敛概念。这个概念等价于无穷可交换数组的收敛。在适当的时间缩放下，Metropolis链具有扩散属性。

    We consider two classes of natural stochastic processes on finite unlabeled graphs. These are Euclidean stochastic optimization algorithms on the adjacency matrix of weighted graphs and a modified version of the Metropolis MCMC algorithm on stochastic block models over unweighted graphs. In both cases we show that, as the size of the graph goes to infinity, the random trajectories of the stochastic processes converge to deterministic limits. These deterministic limits are curves on the space of measure-valued graphons. Measure-valued graphons, introduced by Lov\'{a}sz and Szegedy, are a refinement of the concept of graphons that can distinguish between two infinite exchangeable arrays that give rise to the same graphon limit. We introduce new metrics on this space which provide us with a natural notion of convergence for our limit theorems. This notion is equivalent to the convergence of infinite-exchangeable arrays. Under a suitable time-scaling, the Metropolis chain admits a diffusio
    
[^49]: Med-HALT:大规模语言模型中医疗领域幻觉测试

    Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v1 [cs.CL])

    [http://arxiv.org/abs/2307.15343](http://arxiv.org/abs/2307.15343)

    Med-HALT是一个新的基准和数据集，用于评估和减少大规模语言模型中医疗领域的幻觉问题。这个数据集包括多种创新的测试模式，并评估了领先的LLMs在性能上的差异。

    

    本研究论文关注大规模语言模型（LLMs）中幻觉问题的挑战，特别是在医疗领域的背景下。幻觉指这些模型生成了合理但未经验证或错误的信息，这可能对医疗应用产生严重影响。我们提出了一个新的基准和数据集，Med-HALT（医疗领域幻觉测试），专门设计用于评估和减少幻觉。Med-HALT提供了一个多元化的跨国数据集，这些数据集来自不同国家的医疗检查，包括多种创新的测试模式。Med-HALT包括两类测试：推理和基于记忆的幻觉测试，旨在评估LLMs的问题解决和信息检索能力。我们的研究评估了文本Davinci，GPT-3.5，LlaMa-2，MPT和Falcon等领先的LLMs，揭示了它们在性能上的显著差异。这篇论文提供了有关数据集的详细见解，促进了进一步的研究和发展。

    This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities.  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting
    
[^50]: 超越正常：关于互信息估计的评估

    Beyond Normal: On the Evaluation of Mutual Information Estimators. (arXiv:2306.11078v1 [stat.ML])

    [http://arxiv.org/abs/2306.11078](http://arxiv.org/abs/2306.11078)

    本文提出了一种语言无关的互信息估计基准平台，并讨论了经典和神经估计器在处理高维数据、长尾分布和高互信息时的普适性和局限性。

    

    互信息是一种常用的统计相关度量，已在表示学习、因果性、域泛化和计算生物学等领域得到应用。然而，互信息估计通常只在简单的概率分布族类（即多元正态分布和具有一维随机变量的选择分布）上进行评估。在本文中，我们展示了如何构建具有已知基准互信息的各种分布族，并提出了一种语言无关的互信息估计基准平台。我们讨论了经典和神经网络估计器在涉及高维度、稀疏相互作用、长尾分布和高互信息的情境中的普适性和局限性。最后，我们为从业人员提供了选择适当的估计器以适应所考虑问题难度和应用估计互信息时需要考虑的问题的指南。

    Mutual information is a general statistical dependency measure which has found applications in representation learning, causality, domain generalization and computational biology. However, mutual information estimators are typically evaluated on simple families of probability distributions, namely multivariate normal distribution and selected distributions with one-dimensional random variables. In this paper, we show how to construct a diverse family of distributions with known ground-truth mutual information and propose a language-independent benchmarking platform for mutual information estimators. We discuss the general applicability and limitations of classical and neural estimators in settings involving high dimensions, sparse interactions, long-tailed distributions, and high mutual information. Finally, we provide guidelines for practitioners on how to select appropriate estimator adapted to the difficulty of problem considered and issues one needs to consider when applying an est
    
[^51]: 关于结构预测中的认证泛化

    On Certified Generalization in Structured Prediction. (arXiv:2306.09112v1 [stat.ML])

    [http://arxiv.org/abs/2306.09112](http://arxiv.org/abs/2306.09112)

    该论文提出了一种新的结构化预测PAC-Bayesian风险界限，它可以随着结构化示例的数量和大小的变化而进行泛化，为使用生成模型建立结构化预测的泛化界限迈出了第一步。

    

    在结构预测中，目标对象具有丰富的内部结构，这种结构无法分解为独立的组件，并违反了常见的独立同分布假设。这一挑战在应用程序中表现为指数级的输出空间，如图像分割或场景图生成。我们提出了一种新的结构化预测PAC-Bayesian风险界限，其中泛化速率不仅随着结构化示例的数量而且还随着它们的大小而变化。基本假设符合生成模型上的最新研究，即数据由分解参考度量的Knothe-Rosenblatt重新排列生成。这使得我们可以将随机输出变量之间的结构显式地提取到Wasserstein依赖矩阵中。我们的工作为利用强大的生成模型在结构预测这种具有挑战性的情况下建立判别式下游任务的泛化界限迈出了初步的一步。

    In structured prediction, target objects have rich internal structure which does not factorize into independent components and violates common i.i.d. assumptions. This challenge becomes apparent through the exponentially large output space in applications such as image segmentation or scene graph generation. We present a novel PAC-Bayesian risk bound for structured prediction wherein the rate of generalization scales not only with the number of structured examples but also with their size. The underlying assumption, conforming to ongoing research on generative models, is that data are generated by the Knothe-Rosenblatt rearrangement of a factorizing reference measure. This allows to explicitly distill the structure between random output variables into a Wasserstein dependency matrix. Our work makes a preliminary step towards leveraging powerful generative models to establish generalization bounds for discriminative downstream tasks in the challenging setting of structured prediction.
    
[^52]: 基于谱嵌入的深度学习研究

    Going Deeper with Spectral Embeddings. (arXiv:2306.00742v1 [cs.LG])

    [http://arxiv.org/abs/2306.00742](http://arxiv.org/abs/2306.00742)

    本文提出两种新的谱嵌入方法，一种基于函数分析原理和核方法，另一种基于深度网络优化损失，提供理论保证和实际有效的算法，并提供新的采样算法。

    

    为了有效地处理海量的数据，从而更好地对其进行表征，科学家们采用表示学习。最近，这些方法与一些底层运算的谱分解之间展现出明显的联系。在历史上，是通过在数据的顶部构建图形来建立明确的谱嵌入，而我们提出了两种新的方法：一种基于函数分析原理和核方法构建的，这将导致具有理论保证的算法，另一种基于深度网络训练以优化基本变分损失的算法，它们产生了实际有效的算法。此外，我们提供了一种新的采样算法，利用学习到的表征来在一步中生成新的样本。

    To make sense of millions of raw data and represent them efficiently, practitioners rely on representation learning. Recently, deep connections have been shown between these approaches and the spectral decompositions of some underlying operators. Historically, explicit spectral embeddings were built from graphs constructed on top of the data. In contrast, we propose two new methods to build spectral embeddings: one based on functional analysis principles and kernel methods, which leads to algorithms with theoretical guarantees, and the other based on deep networks trained to optimize principled variational losses, which yield practically efficient algorithms. Furthermore, we provide a new sampling algorithm that leverages learned representations to generate new samples in a single step.
    
[^53]: ZeroSCROLLS：一个用于长文本理解的零Shot基准测试

    ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding. (arXiv:2305.14196v1 [cs.CL])

    [http://arxiv.org/abs/2305.14196](http://arxiv.org/abs/2305.14196)

    ZeroSCROLLS是一个用于长文本自然语言理解的零Shot基准测试，包括六个任务和四个数据集，能够评估大型语言模型的性能。当前，GPT-4的平均得分最高，但在聚合任务等多个挑战上，仍有改进的空间。

    

    我们介绍了 ZeroSCROLLS，这是一个用于长文本自然语言理解的零Shot基准测试，仅包含测试集而没有训练或开发数据。我们从SCROLLS基准测试中适应了六个任务，并添加了四个新数据集，包括两个新的信息融合任务，例如聚合正面评价的百分比。使用ZeroSCROLLS，我们对开源和闭源大型语言模型进行了全面评估，发现Claude优于ChatGPT，并且GPT-4获得了最高的平均分数。然而，在ZeroSCROLLS的多个开放挑战方面（例如，聚合任务），还有改进的空间，因为模型很难通过朴素的基准测试。由于最先进的技术还在不断更新，我们邀请研究人员在实时的ZeroSCROLLS排行榜上评估他们的想法。

    We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test sets, without training or development data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard
    
[^54]: Group-Invariant GAN的统计保证

    Statistical Guarantees of Group-Invariant GANs. (arXiv:2305.13517v1 [stat.ML])

    [http://arxiv.org/abs/2305.13517](http://arxiv.org/abs/2305.13517)

    本研究提出了群不变GAN的统计保证，发现当学习群不变分布时，群不变GAN所需样本数会按群体大小的幂比例减少。

    

    Group-Invariant生成对抗网络(GAN)是一种GAN，其中生成器和判别器具有硬性集团对称性。实证研究表明，这些网络能够学习具有显着改进数据效率的集团不变分布。在本研究中，我们旨在通过分析群不变GAN的样本复杂度减少来严格量化这种改进。我们的研究发现，在学习群不变分布时，群不变GAN所需样本数按照群体大小的幂比例减少，这个幂取决于分布支持的本质维度。据我们所知，这项工作是首个为群不变生成模型，特别是GAN提供统计估计的工作，并可以为其他群不变生成模型的研究提供借鉴。

    Group-invariant generative adversarial networks (GANs) are a type of GANs in which the generators and discriminators are hardwired with group symmetries. Empirical studies have shown that these networks are capable of learning group-invariant distributions with significantly improved data efficiency. In this study, we aim to rigorously quantify this improvement by analyzing the reduction in sample complexity for group-invariant GANs. Our findings indicate that when learning group-invariant distributions, the number of samples required for group-invariant GANs decreases proportionally with a power of the group size, and this power depends on the intrinsic dimension of the distribution's support. To our knowledge, this work presents the first statistical estimation for group-invariant generative models, specifically for GANs, and it may shed light on the study of other group-invariant generative models.
    
[^55]: 基于一般回归误差假设来研究无噪声回归最小二乘估计值的均方误差

    The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors. (arXiv:2305.12883v1 [math.ST])

    [http://arxiv.org/abs/2305.12883](http://arxiv.org/abs/2305.12883)

    该论文研究了基于一般回归误差假设的无噪声回归最小二乘估计值的均方误差，并发现包含大量不重要的参数可以有效地降低估计器的均方误差。

    

    近年来，最小$\ell_2$范数（无岭）插值最小二乘估计器的研究方兴未艾。然而，大多数分析都局限于简单的回归误差结构，假设误差是独立同分布的，具有零均值和相同的方差，与特征向量无关。此外，这些理论分析的主要重点是样本外预测风险。本文通过检查无岭插值最小二乘估计器的均方误差，允许更一般的回归误差假设，打破了现有文献的局限性。具体而言，我们研究过度参数化的潜在好处，通过描绘有限样本中的均方误差来表征均方误差。我们的研究结果表明，相对于样本量，包含大量不重要的参数可以有效地降低估计器的均方误差。

    In recent years, there has been a significant growth in research focusing on minimum $\ell_2$ norm (ridgeless) interpolation least squares estimators. However, the majority of these analyses have been limited to a simple regression error structure, assuming independent and identically distributed errors with zero mean and common variance, independent of the feature vectors. Additionally, the main focus of these theoretical analyses has been on the out-of-sample prediction risk. This paper breaks away from the existing literature by examining the mean squared error of the ridgeless interpolation least squares estimator, allowing for more general assumptions about the regression errors. Specifically, we investigate the potential benefits of overparameterization by characterizing the mean squared error in a finite sample. Our findings reveal that including a large number of unimportant parameters relative to the sample size can effectively reduce the mean squared error of the estimator. N
    
[^56]: 通过重新标记最小训练子集来翻转预测

    Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])

    [http://arxiv.org/abs/2305.12809](http://arxiv.org/abs/2305.12809)

    本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。

    

    Yang等人发现，仅删除1%的训练数据就可能导致预测结果翻转。鉴于机器学习模型中存在噪声数据的普遍性，本文提出了一个问题：在模型训练之前通过重新标记一个小的训练数据子集可否导致测试结果翻转？本文利用扩展影响函数提出了一种有效的识别和重新标记这种子集的方法，并证明了其始终能够产生成功的结果。这种机制有多重作用：（1）提供了一种补充方法，可以通过恢复可能错误标记的训练数据来挑战模型预测；（2）评估模型的鲁棒性，因为本文发现子集的大小与训练集中噪声数据的比例之间存在显著关系；（3）提供了洞察训练集偏差的见解。据我们所知，这项工作代表了对识别最小训练子集问题的第一次研究。

    Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
    
[^57]: 稳定性边缘处的逻辑回归梯度下降的隐式偏差

    Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability. (arXiv:2305.11788v1 [cs.LG])

    [http://arxiv.org/abs/2305.11788](http://arxiv.org/abs/2305.11788)

    本文研究了逻辑回归常数步长梯度下降在稳定性边缘的收敛性和隐式偏差，证明了逻辑损失可以通过任何常数步长的梯度下降进行最小化，同时也发现了指数损失下的发散性问题，强调了稳定性边缘下梯度下降的不稳定性。

    

    最近的研究表明，在机器学习优化中，梯度下降 (GD) 经常在稳定性边缘 (EoS) [Cohen 等，2021] 运行，其中步长被设置为大，导致由 GD 迭代引起的非单调损失。本文研究在 EoS 区域内使用常数步长 GD 进行逻辑回归的收敛性和隐式偏差，对于线性可分的数据。尽管存在局部振荡，我们证明逻辑损失可以通过任何常数步长的 GD 在长时间尺度上进行最小化。此外，我们证明，在任何常数步长下，当投影到最大边际方向 (硬边 SVM 方向) 时，GD 迭代趋向于无穷大，并在投影到最大边缘的正交补空间时，收敛于最小化强凸势能的固定向量。相反，我们也表明，在 EoS 区域，GD 迭代可能在指数损失下发生灾难性发散，突显了 EoS 区域中 GD 的不稳定性。

    Recent research has observed that in machine learning optimization, gradient descent (GD) often operates at the edge of stability (EoS) [Cohen, et al., 2021], where the stepsizes are set to be large, resulting in non-monotonic losses induced by the GD iterates. This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime. Despite the presence of local oscillations, we prove that the logistic loss can be minimized by GD with any constant stepsize over a long time scale. Furthermore, we prove that with any constant stepsize, the GD iterates tend to infinity when projected to a max-margin direction (the hard-margin SVM direction) and converge to a fixed vector that minimizes a strongly convex potential when projected to the orthogonal complement of the max-margin direction. In contrast, we also show that in the EoS regime, GD iterates may diverge catastrophically under the exponential loss, highlighting t
    
[^58]: 超越指数图：有限时间收敛的通信效率拓扑用于分散学习

    Beyond Exponential Graph: Communication-Efficient Topologies for Decentralized Learning via Finite-time Convergence. (arXiv:2305.11420v1 [cs.LG])

    [http://arxiv.org/abs/2305.11420](http://arxiv.org/abs/2305.11420)

    本文介绍了一种新型拓扑——基础$(k+1)$图，其中节点在有限的迭代次数后能达到确切的共识，具有快速共识率和小的最大度数，从而可以用于分散式SGD。

    

    近年来越来越多的研究关注于分散式学习在并行计算和隐私保护中的应用。许多最近的研究指出，具有更快共识率（即谱间隙）的底层网络拓扑可导致分散式学习的更好收敛速度和准确性。然而，具有快速共识率的拓扑，如指数图，通常具有较大的最大度数，这会导致重要的通信成本。因此，寻求既具有快速共识率又具有小的最大度数的拓扑是重要的。在本研究中，我们提出了一种结合快速共识率和小最大度的新型拓扑，称为基础$(k+1)$ 图。与现有的拓扑不同，基础$(k+1)$ 图使所有节点在有限的迭代次数后都能达到确切的共识，对于任何节点数和最大度k都适用。得益于这个有利的属性，基础$(k+1)$ 图赋予了分散式SGD

    Decentralized learning has recently been attracting increasing attention for its applications in parallel computation and privacy preservation. Many recent studies stated that the underlying network topology with a faster consensus rate (a.k.a. spectral gap) leads to a better convergence rate and accuracy for decentralized learning. However, a topology with a fast consensus rate, e.g., the exponential graph, generally has a large maximum degree, which incurs significant communication costs. Thus, seeking topologies with both a fast consensus rate and small maximum degree is important. In this study, we propose a novel topology combining both a fast consensus rate and small maximum degree called the Base-$(k + 1)$ Graph. Unlike the existing topologies, the Base-$(k + 1)$ Graph enables all nodes to reach the exact consensus after a finite number of iterations for any number of nodes and maximum degree k. Thanks to this favorable property, the Base-$(k + 1)$ Graph endows Decentralized SGD
    
[^59]: 关于一般函数逼近下的均场强化学习的统计效率

    On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])

    [http://arxiv.org/abs/2305.11283](http://arxiv.org/abs/2305.11283)

    本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。

    

    本文研究了一般函数逼近下的均场控制（MFC）和均场博弈（MFG）中强化学习的统计效率。引入了一种称为Mean-Field Model-Based Eluder Dimension (MBED)的新概念，包含了一系列丰富的均场强化学习问题。此外，我们提出了基于乐观最大似然估计的算法，可以返回一个$\epsilon$优的策略，适用于MFC或$\epsilon$纳什均衡策略适用于MFG，样本复杂度多项式与相关参数无关，与状态、动作和代理数量无关。值得注意的是，我们的结果仅对转移动力学具有Lipschitz连续性的假设，避免了以前的强结构假设。最后，在tabular设置下，假设有一个生成模型，我们建立了一个指数级的下界支持MFC设置，同时提供了一种新颖的样本高效的模型消除算法以逼近最优策略。

    In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
    
[^60]: 无界差分隐私分位数和最大值估算

    Unbounded Differentially Private Quantile and Maximum Estimation. (arXiv:2305.01177v1 [cs.DS])

    [http://arxiv.org/abs/2305.01177](http://arxiv.org/abs/2305.01177)

    本文研究了如何对无上限数据进行差分隐私分位数和最大值的计算。调用基本的稀疏向量技术中的$\texttt{AboveThreshold}$子程序可以实现这个目标，可以提供更准确和稳健的最高分位数估计，从而应用于对于差分隐私求和和均值估计至关重要的数据剪切，该技术的隐私保障可以通过方法改进。

    

    本文考虑在数据的分位数计算中，尤其是最高分位数（如最大值），如何实现对无界数据的差分隐私计算。我们通过简单调用迭代调用基本的稀疏向量技术中的$\texttt{AboveThreshold}$子程序，即可高效地实现此目标，即使数据没有上限。特别地，我们展示出此过程可提供更准确和稳健的最高分位数估计，从而应用于对于差分隐私求和和均值估计至关重要的数据剪切。此外，我们展示了两个调用如何处理完全无界的数据设置。在我们的研究中，我们展示了改进$\texttt{AboveThreshold}$的分析方法可以提高广泛使用的稀疏向量技术的隐私保障（这是独立于本文的内容）。我们给出了更普遍的$\texttt{AboveThreshold}$隐私损失特征，并展示了差分隐私的标准组合规则可能会高估总体隐私损失。

    In this work we consider the problem of differentially private computation of quantiles for the data, especially the highest quantiles such as maximum, but with an unbounded range for the dataset. We show that this can be done efficiently through a simple invocation of $\texttt{AboveThreshold}$, a subroutine that is iteratively called in the fundamental Sparse Vector Technique, even when there is no upper bound on the data. In particular, we show that this procedure can give more accurate and robust estimates on the highest quantiles with applications towards clipping that is essential for differentially private sum and mean estimation. In addition, we show how two invocations can handle the fully unbounded data setting. Within our study, we show that an improved analysis of $\texttt{AboveThreshold}$ can improve the privacy guarantees for the widely used Sparse Vector Technique that is of independent interest. We give a more general characterization of privacy loss for $\texttt{AboveTh
    
[^61]: 能量为基础的切片Wasserstein距离

    Energy-Based Sliced Wasserstein Distance. (arXiv:2304.13586v1 [stat.ML])

    [http://arxiv.org/abs/2304.13586](http://arxiv.org/abs/2304.13586)

    本文提出了一种能量为基础的切片Wasserstein距离，并将其参数化，以克服传统方法中的固定先验分布缺乏信息和优化最佳分布昂贵不稳定的局限。

    

    切片Wasserstein（SW）距离被广泛认为是两个概率测度之间的一种统计有效且计算高效的度量。SW距离的一个关键部分是切片分布。目前有两种方法来选择这个分布。第一种方法是使用固定的先验分布。第二种是优化归属于参数分布族的最佳分布，并且可以最大化期望的距离。然而，这两种方法都有局限性。固定的先验分布在突出能够区分两个常规概率测度的投影方向方面缺乏信息。而优化最佳分布通常是昂贵和不稳定的。此外，设计候选分布的参数分布族可能会很容易被错误指定。为了解决这些问题，我们提出将切片分布设计为基于能量的分布，并将其参数化，从而使其更加通用而稳健。

    The sliced Wasserstein (SW) distance has been widely recognized as a statistically effective and computationally efficient metric between two probability measures. A key component of the SW distance is the slicing distribution. There are two existing approaches for choosing this distribution. The first approach is using a fixed prior distribution. The second approach is optimizing for the best distribution which belongs to a parametric family of distributions and can maximize the expected distance. However, both approaches have their limitations. A fixed prior distribution is non-informative in terms of highlighting projecting directions that can discriminate two general probability measures. Doing optimization for the best distribution is often expensive and unstable. Moreover, designing the parametric family of the candidate distribution could be easily misspecified. To address the issues, we propose to design the slicing distribution as an energy-based distribution that is parameter
    
[^62]: 带有正则化流先验的Langevin Monte Carlo用于成像逆问题

    NF-ULA: Langevin Monte Carlo with Normalizing Flow Prior for Imaging Inverse Problems. (arXiv:2304.08342v1 [math.NA])

    [http://arxiv.org/abs/2304.08342](http://arxiv.org/abs/2304.08342)

    本文提出了一种NF-ULA算法，其中包括学习正则化流作为先验，用于解决成像逆问题的贝叶斯推断采样算法，且有效性得到了在三个成像逆问题上的证明。

    

    贝叶斯方法是解决逆问题的一种强大替代方案，因为贝叶斯方法提供了问题的概率描述并能够量化解决方案中的不确定性。本文尝试将数据驱动模型并入基于Langevin的贝叶斯推断采样算法中。我们引入了NF-ULA（通过正则化流的未调整Langevin算法），其中包括学习正则化流作为先验。我们通过调查贝叶斯解的良好性和NF-ULA算法的非渐进收敛性进行理论分析。我们在三个成像逆问题上进行的实验展示了我们所提出的方法的有效性：图像去模糊，超分辨率和计算机断层扫描（CT）重建。

    Bayesian methods for solving inverse problems are a powerful alternative to classical methods since the Bayesian approach gives a probabilistic description of the problems and offers the ability to quantify the uncertainty in the solution. Meanwhile, solving inverse problems by data-driven techniques also proves to be successful, due to the increasing representation ability of data-based models. In this work, we try to incorporate the data-based models into a class of Langevin-based sampling algorithms in Bayesian inference. Loosely speaking, we introduce NF-ULA (Unadjusted Langevin algorithms by Normalizing Flows), which involves learning a normalizing flow as the prior. In particular, our algorithm only requires a pre-trained normalizing flow, which is independent of the considered inverse problem and the forward operator. We perform theoretical analysis by investigating the well-posedness of the Bayesian solution and the non-asymptotic convergence of the NF-ULA algorithm. The effica
    
[^63]: PCA-Net：操作学习的复杂性上下界

    Operator learning with PCA-Net: upper and lower complexity bounds. (arXiv:2303.16317v1 [cs.LG])

    [http://arxiv.org/abs/2303.16317](http://arxiv.org/abs/2303.16317)

    本文发展了PCA-Net的近似理论，得出了通用逼近结果，并识别出了使用PCA-Net进行高效操作学习的潜在障碍：输出分布的复杂性和算子空间的内在复杂性。

    

    神经算子在计算科学和工程中备受关注。PCA-Net是一种最近提出的神经算子架构，它将主成分分析(PCA)与神经网络相结合，以逼近潜在的算子。本文对这种方法进行了近似理论的发展，改进并显着扩展了此方向的以前的工作。在定性界限方面，本文得出了新颖的通用逼近结果，在对潜在算子和数据生成分布的最小假设的前提下。在定量限制方面，本文识别了使用PCA-Net进行高效操作学习的两个潜在障碍，通过导出下界进行了严格证明，第一个障碍与输出分布的复杂性有关，由PCA特征值的缓慢衰减来衡量；另一个障碍涉及无限维输入和输出空间之间的算子空间的内在复杂性。

    Neural operators are gaining attention in computational science and engineering. PCA-Net is a recently proposed neural operator architecture which combines principal component analysis (PCA) with neural networks to approximate an underlying operator. The present work develops approximation theory for this approach, improving and significantly extending previous work in this direction. In terms of qualitative bounds, this paper derives a novel universal approximation result, under minimal assumptions on the underlying operator and the data-generating distribution. In terms of quantitative bounds, two potential obstacles to efficient operator learning with PCA-Net are identified, and made rigorous through the derivation of lower complexity bounds; the first relates to the complexity of the output distribution, measured by a slow decay of the PCA eigenvalues. The other obstacle relates the inherent complexity of the space of operators between infinite-dimensional input and output spaces, 
    
[^64]: 测试反事实场景：揭示在公平原则下的歧视差异 (arXiv:2302.11944v2 [stat.ML] UPDATED)

    Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference. (arXiv:2302.11944v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.11944](http://arxiv.org/abs/2302.11944)

    我们提出了一种反事实场景测试框架，通过比较数据集中类似的保护和非保护实例来检测分类器中的歧视，通过比较组间决策结果差异，来发现个人歧视。该框架可以更好地对「给定差异的公平原则」进行操作，以揭示在公平原则下的歧视差异。

    

    我们提出了一种被称为反事实场景测试(CST)的因果数据挖掘框架来检测分类器中的歧视情况。CST旨在以可操作且有意义的方式回答一种直观问题：“如果个人或投诉人所属的受保护身份不同，模型的结果将会是什么？”它通过反事实推理来对法律基础的情景测试进行扩展，以操作“给定差异的公平原则”的概念。对于任何投诉人，我们在分类器使用的数据集中找到并比较相似的受保护和非受保护实例，构造控制组和测试组，两组的决策结果差异意味着潜在的个人歧视。与情境测试不同，情境测试是围绕投诉人构建两组，我们根据因果知识在投诉人的反事实生成测试组。反事实旨在反映受保护属性对结果的影响。

    We present counterfactual situation testing (CST), a causal data mining framework for detecting discrimination in classifiers. CST aims to answer in an actionable and meaningful way the intuitive question "what would have been the model outcome had the individual, or complainant, been of a different protected status?" It extends the legally-grounded situation testing of Thanh et al. (2011) by operationalizing the notion of fairness given the difference using counterfactual reasoning. For any complainant, we find and compare similar protected and non-protected instances in the dataset used by the classifier to construct a control and test group, where a difference between the decision outcomes of the two groups implies potential individual discrimination. Unlike situation testing, which builds both groups around the complainant, we build the test group on the complainant's counterfactual generated using causal knowledge. The counterfactual is intended to reflect how the protected attrib
    
[^65]: 具有$\mathcal{O} (1/k)$最终迭代收敛速度的对偶亚极单调递推方法，用于共超单调包含关系

    Extragradient-Type Methods with $\mathcal{O} (1/k)$ Last-Iterate Convergence Rates for Co-Hypomonotone Inclusions. (arXiv:2302.04099v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2302.04099](http://arxiv.org/abs/2302.04099)

    本文提出了两种"Nesterov's加速"的外推算法来逼近共超单调包含关系的解，分别为内斯特罗夫加速的Tseng前-后-前分裂法和过去FBFS法，两种算法都达到了$\mathcal{O}(1/k)$的最终迭代收敛速度。

    

    我们开发了两种"内斯特罗夫加速"的变种外推法来逼近由两个算子之和构成的共超单调包含关系的解，其中一个是Lipschitz连续的，另一个可能是多值的。第一种方案可以看作是曾's前-后-前分裂算法的加速变种，而第二种方案是"Nesterov's加速变种的"过去FBFS方案，该方案只需要对Lipschitz算子进行一次评估和多值映射进行一次解算。在参数适当的条件下，我们在理论上证明了这两种算法在剩余范数上实现了$\mathcal{O}(1/k)$的最终迭代收敛速度，其中$k$是迭代计数器。我们的结果可以看作是用于根查找问题的最近一类Halpern型方法的替代方案。为了比较，我们还提供了两种最近的额外锚定梯度型方法的新收敛分析。

    We develop two "Nesterov's accelerated" variants of the well-known extragradient method to approximate a solution of a co-hypomonotone inclusion constituted by the sum of two operators, where one is Lipschitz continuous and the other is possibly multivalued. The first scheme can be viewed as an accelerated variant of Tseng's forward-backward-forward splitting (FBFS) method, while the second one is a Nesterov's accelerated variant of the "past" FBFS scheme, which requires only one evaluation of the Lipschitz operator and one resolvent of the multivalued mapping. Under appropriate conditions on the parameters, we theoretically prove that both algorithms achieve $\mathcal{O}(1/k)$ last-iterate convergence rates on the residual norm, where $k$ is the iteration counter. Our results can be viewed as alternatives of a recent class of Halpern-type methods for root-finding problems. For comparison, we also provide a new convergence analysis of the two recent extra-anchored gradient-type methods
    
[^66]: 通过下采样，描绘无岗位线性回归：下采样的作用

    Sketched Ridgeless Linear Regression: The Role of Downsampling. (arXiv:2302.01088v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2302.01088](http://arxiv.org/abs/2302.01088)

    本文研究了描绘无岗位最小二乘估计器在比例区域下的样本外预测风险，挑战了传统观念，并发现下采样在某些情况下可以改善泛化，我们确定了最佳缩略图大小并提出了实际实施方法。

    

    过度参数化通常有助于提高泛化性能。本文提出了过度参数化的双重视角，并认为下采样也可以帮助泛化。我们针对比例区域$m\asymp n \asymp p$进行了研究，其中$m$表示缩略图大小，$n$是样本大小，$p$是特征维度，研究了描绘无岗位最小二乘估计器的两个样本外预测风险。我们的发现挑战了传统观念，表明下采样不总是对泛化有害，而在某些情况下实际上可以改善泛化。我们确定了最小化样本外预测风险的最佳缩略图大小，并证明了最优缩略图估计器显示出更稳定的风险曲线，消除了完全样本估计器的峰值。为了便于实际实施，我们提出了一种确定最佳缩略图大小的经验方法。最后，我们扩展了我们的分析，涵盖了中心极限定理。

    Overparametrization often helps improve the generalization performance. This paper presents a dual view of overparametrization suggesting that downsampling may also help generalize. Focusing on the proportional regime $m\asymp n \asymp p$, where $m$ represents the sketching size, $n$ is the sample size, and $p$ is the feature dimensionality, we investigate two out-of-sample prediction risks of the sketched ridgeless least square estimator. Our findings challenge conventional beliefs by showing that downsampling does not always harm generalization but can actually improve it in certain cases. We identify the optimal sketching size that minimizes out-of-sample prediction risks and demonstrate that the optimally sketched estimator exhibits stabler risk curves, eliminating the peaks of those for the full-sample estimator. To facilitate practical implementation, we propose an empirical procedure to determine the optimal sketching size. Finally, we extend our analysis to cover central limit 
    
[^67]: 神经网络学习放大决策边界附近的区域

    Neural networks learn to magnify areas near decision boundaries. (arXiv:2301.11375v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11375](http://arxiv.org/abs/2301.11375)

    神经网络训练能够放大决策边界附近的局部区域，改善整个系统的泛化能力。

    

    我们研究了训练如何塑造神经网络特征图诱导的黎曼几何。在宽度为无限的情况下，具有随机参数的神经网络在输入空间上引导高度对称的度量。训练分类任务的网络中的特征学习放大了沿决策边界的局部区域。这些变化与先前提出的用于手动调整核方法以改善泛化的几何方法一致。

    We study how training molds the Riemannian geometry induced by neural network feature maps. At infinite width, neural networks with random parameters induce highly symmetric metrics on input space. Feature learning in networks trained to perform classification tasks magnifies local areas along decision boundaries. These changes are consistent with previously proposed geometric approaches for hand-tuning of kernel methods to improve generalization.
    
[^68]: 马尔可夫切片Wasserstein距离：超越独立投影

    Markovian Sliced Wasserstein Distances: Beyond Independent Projections. (arXiv:2301.03749v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.03749](http://arxiv.org/abs/2301.03749)

    马尔可夫切片Wasserstein（MSW）距离是一种新的SW距离家族，通过在投影方向上施加一阶马尔可夫结构，解决了切片Wasserstein（SW）距离中独立投影导致的冗余投影的问题，并且具有较低的计算复杂度。（found in translation）

    

    切片Wasserstein（SW）距离由于独立的均匀随机投影方向而导致冗余投影。为了部分克服这个问题，最大K切片Wasserstein（Max-K-SW）距离（$K\geq1$）寻求最佳的区分正交投影方向。尽管能够减少投影数量，但Max-K-SW的度量性在实践中不能保证，原因是优化的非最优性。此外，正交约束也在计算上是昂贵的，可能不太有效。为了解决这个问题，我们引入了一种新的SW距离家族，称为马尔可夫切片Wasserstein（MSW）距离，它在投影方向上施加了一阶马尔可夫结构。我们通过指定马尔可夫结构，包括先验分布、转移分布以及燃烧和稀疏化技术，讨论了MSW的各种成员。此外，我们还研究了MSW的理论性质，包括拓扑性质（found in translation）

    Sliced Wasserstein (SW) distance suffers from redundant projections due to independent uniform random projecting directions. To partially overcome the issue, max K sliced Wasserstein (Max-K-SW) distance ($K\geq 1$), seeks the best discriminative orthogonal projecting directions. Despite being able to reduce the number of projections, the metricity of Max-K-SW cannot be guaranteed in practice due to the non-optimality of the optimization. Moreover, the orthogonality constraint is also computationally expensive and might not be effective. To address the problem, we introduce a new family of SW distances, named Markovian sliced Wasserstein (MSW) distance, which imposes a first-order Markov structure on projecting directions. We discuss various members of MSW by specifying the Markov structure including the prior distribution, the transition distribution, and the burning and thinning technique. Moreover, we investigate the theoretical properties of MSW including topological properties (met
    
[^69]: 数据驱动的多项式随机森林: 一种具有强一致性的新随机森林变体

    Data-driven multinomial random forest: A new random forest variant with strong consistency. (arXiv:2211.15154v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15154](http://arxiv.org/abs/2211.15154)

    本研究改进了先前弱一致性随机森林变体的证明方法，提出了一种数据驱动的多项式随机森林（DMRF），并表明DMRF在分类和回归问题中具有更好的性能，并且实现了概率1的强一致性。

    

    本文将一些先前弱一致性随机森林变体的证明方法修改为强一致性证明方法，并改进了这些变体的数据利用，以获得更好的理论性质和实验性能。此外，我们提出了一种数据驱动的多项式随机森林（DMRF），其与BreimanRF（由Breiman提出）具有相同的复杂度，同时以概率1满足强一致性。在分类和回归问题上，它比先前仅满足弱一致性的RF变体具有更好的性能，并且在大多数情况下甚至超过了BreimanRF在分类任务上的表现。据我们所知，DMRF是当前实现了概率1的强一致性的低复杂性和高性能随机森林的一种变体。

    In this paper, we modify the proof methods of some previously weakly consistent variants of random forests into strongly consistent proof methods, and improve the data utilization of these variants in order to obtain better theoretical properties and experimental performance. In addition, we propose a data-driven multinomial random forest (DMRF), which has the same complexity with BreimanRF (proposed by Breiman) while satisfying strong consistency with probability 1. It has better performance in classification and regression problems than previous RF variants that only satisfy weak consistency, and in most cases even surpasses BreimanRF in classification tasks. To the best of our knowledge, DMRF is currently a low-complexity and high-performing variation of random forests that achieves strong consistency with probability 1.
    
[^70]: 自适应合并下的纵向网络有效估计

    Efficient Estimation for Longitudinal Network via Adaptive Merging. (arXiv:2211.07866v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.07866](http://arxiv.org/abs/2211.07866)

    本文提出了一个有效的纵向网络估计框架，利用自适应合并、张量分解和点过程等方法来减少估计偏差和方差。

    

    纵向网络由多个节点之间的时间边序列组成，其中时间边在实时中被观察到。随着在线社交平台和电子商务的兴起，它已经变得普遍，但在文献中往往被忽略。本文提出了一个有效的纵向网络估计框架，利用自适应网络合并、张量分解和点过程的优势。它合并相邻的稀疏网络，以扩大观测边的数量并减少估计方差，同时通过利用本地时间结构进行自适应网络邻域控制引入的估计偏差。提出了一个投影梯度下降算法来促进估计，其中每次迭代的估计错误上界被建立。进行了彻底的分析，以量化所提出方法的渐近行为，结果表明它可以显着减少估计偏差。

    Longitudinal network consists of a sequence of temporal edges among multiple nodes, where the temporal edges are observed in real time. It has become ubiquitous with the rise of online social platform and e-commerce, but largely under-investigated in literature. In this paper, we propose an efficient estimation framework for longitudinal network, leveraging strengths of adaptive network merging, tensor decomposition and point process. It merges neighboring sparse networks so as to enlarge the number of observed edges and reduce estimation variance, whereas the estimation bias introduced by network merging is controlled by exploiting local temporal structures for adaptive network neighborhood. A projected gradient descent algorithm is proposed to facilitate estimation, where the upper bound of the estimation error in each iteration is established. A thorough analysis is conducted to quantify the asymptotic behavior of the proposed method, which shows that it can significantly reduce the
    
[^71]: 用于留一法交叉验证的集中不等式

    Concentration inequalities for leave-one-out cross validation. (arXiv:2211.02478v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2211.02478](http://arxiv.org/abs/2211.02478)

    本文证明了估计器的稳定性足以说明留一法交叉验证是可靠的，并通过提供集中界限超出Lipschitz连续性假设的损失函数或估计器，为我们提供了一个相对丰富的分布类。

    

    在本文中，我们证明了估计器的稳定性足以说明留一法交叉验证是一个可靠的过程，通过在一个通用的框架中提供集中界限。特别是，我们在损失函数或估计器上提供了超过Lipschitz连续性假设的集中界限。我们通过依赖具有满足对数Sobolev不等式的分布的随机变量来获得我们的结果，这为我们提供了一个相对丰富的分布类。我们通过考虑几个有趣的例子来说明我们的方法，包括线性回归，核密度估计以及稳定/截断估计器，例如稳定的核回归。

    In this article we prove that estimator stability is enough to show that leave-one-out cross validation is a sound procedure, by providing concentration bounds in a general framework. In particular, we provide concentration bounds beyond Lipschitz continuity assumptions on the loss or on the estimator. We obtain our results by relying on random variables with distribution satisfying the logarithmic Sobolev inequality, providing us a relatively rich class of distributions. We illustrate our method by considering several interesting examples, including linear regression, kernel density estimation, and stabilized/truncated estimators such as stabilized kernel regression.
    
[^72]: 最优AdaBoost算法的收敛性

    Optimal AdaBoost Converges. (arXiv:2210.07808v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.07808](http://arxiv.org/abs/2210.07808)

    本研究通过形式证明，展示了最优AdaBoost算法的分类器和边缘的收敛性质，结果与几十年的研究相一致。

    

    本研究是关于AdaBoost机器学习算法分类器和边缘的收敛性性质的形式证明的预印本集合。针对这些收敛性性质的猜想和特殊情况已经编写了各种数学和计算机科学论文。此外，AdaBoost的边缘在围绕该算法的研究中占据重要地位。在本文的顶点，我们展示了AdaBoost的分类器和边缘如何收敛到与几十年的研究相一致的值。在此之后，我们展示了与组合分类器相关的各种数量是如何收敛的。

    The following work is a preprint collection of formal proofs regarding the convergence properties of the AdaBoost machine learning algorithm's classifier and margins. Various math and computer science papers have been written regarding conjectures and special cases of these convergence properties. Furthermore, the margins of AdaBoost feature prominently in the research surrounding the algorithm. At the zenith of this paper we present how AdaBoost's classifier and margins converge on a value that agrees with decades of research. After this, we show how various quantities associated with the combined classifier converge.
    
[^73]: 粒子信念近似POMDP的最优性保证

    Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.05015](http://arxiv.org/abs/2210.05015)

    该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。

    

    部分可观察马尔可夫决策过程(POMDP)提供了现实决策和控制问题的灵活表示。然而，POMDP的求解非常困难，特别是当状态和观测空间是连续或混合的时候，这在物理系统中经常发生。尽管最近使用观测似然权重策划的在线采样POMDP算法表现出了实用的有效性，但先前并没有提出一般理论来刻画这些算法使用的粒子滤波技术的逼近误差。我们的主要贡献是限定任何POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差。这种PB-MDP和POMDP之间的基础桥梁使得我们能够通过解决相应的粒子信念MDP将任何采样MDP算法适应到POMDP中，从而将MDP算法的收敛保证扩展到POMDP中。在实践中，这可以提高在解决具有大的或连续状态空间的POMDP时的性能和鲁棒性。

    Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, thi
    
[^74]: 带有同时检测社区和异常的签名网络嵌入及应用

    Signed Network Embedding with Application to Simultaneous Detection of Communities and Anomalies. (arXiv:2207.09324v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2207.09324](http://arxiv.org/abs/2207.09324)

    本文开发了一个统一的嵌入模型，用于解决签名网络中的平衡结构和异常效应，并在社区检测、异常检测和网络推断等任务中取得了良好表现。

    

    在现实生活中，我们经常观察到带有附加符号信息的网络，然而这些信息在现有的网络模型中被大部分忽视了。本文针对签名网络开发了一个统一的嵌入模型，以解开错综复杂的平衡结构和异常效应，从而可以极大地促进下游分析，包括社区检测、异常检测和网络推断。所提出的模型通过低秩加稀疏矩阵分解捕捉平衡结构和异常效应，并通过正则化方法联合估计二者。在网络嵌入、社区检测和异常检测方面，它的理论保证是建立在渐近一致性和有限样本概率边界的基础上。所提出的嵌入模型的优势还通过对合成网络和国际关系网络进行广泛的数值实验得到了证明。

    Signed networks are frequently observed in real life with additional sign information associated with each edge, yet such information has been largely ignored in existing network models. This paper develops a unified embedding model for signed networks to disentangle the intertwined balance structure and anomaly effect, which can greatly facilitate the downstream analysis, including community detection, anomaly detection, and network inference. The proposed model captures both balance structure and anomaly effect through a low rank plus sparse matrix decomposition, which are jointly estimated via a regularized formulation. Its theoretical guarantees are established in terms of asymptotic consistency and finite-sample probability bounds for network embedding, community detection and anomaly detection. The advantage of the proposed embedding model is also demonstrated through extensive numerical experiments on both synthetic networks and an international relation network.
    
[^75]: 用于外样本模型评估的诊断工具

    Diagnostic Tool for Out-of-Sample Model Evaluation. (arXiv:2206.10982v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.10982](http://arxiv.org/abs/2206.10982)

    本文提出了一种用于外样本模型评估的诊断工具，可以通过有限的校准数据集来表征模型在未来外样本上的损失，并提供了简单易用且易于解释的方法。该工具可以量化分布转变的影响，促进回归分析，帮助实现模型选择和超参数调优。

    

    模型适配性评估是机器学习的关键部分。标准范式是通过对训练数据上的选择损失函数进行平均，以实现在未来数据上获得小的损失。在本文中，我们考虑使用有限的校准数据集来表征模型在未来外样本上的损失。我们提出了一个简单的模型诊断工具，在弱假设下提供有限样本的保证。该工具简单易用且易于解释。通过展示几个数值实验，我们展示了提出的方法如何量化分布转变的影响，促进回归分析，以及实现模型选择和超参数调优。

    Assessment of model fitness is a key part of machine learning. The standard paradigm is to learn models by minimizing a chosen loss function averaged over training data, with the aim of achieving small losses on future data. In this paper, we consider the use of a finite calibration data set to characterize the future, out-of-sample losses of a model. We propose a simple model diagnostic tool that provides finite-sample guarantees under weak assumptions. The tool is simple to compute and to interpret. Several numerical experiments are presented to show how the proposed method quantifies the impact of distribution shifts, aids the analysis of regression, and enables model selection as well as hyper-parameter tuning.
    
[^76]: 基于星形细胞对关键期的神经可塑性神经网络，通过现有和记忆性的大脑可塑性和突触形成实现突触竞争和强度平衡。（arXiv: 2203.11740v12 [cs.NE] UPDATED）

    Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2203.11740](http://arxiv.org/abs/2203.11740)

    该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。

    

    除了突触共享连接权重之外，PNN还包括突触有效范围的权重[14-25]。PNN考虑突触强度平衡在突触吞噬的动态和长度常数之和的静态中[14]，并包含了鱼群行为的先导行为。突触形成在实验和模拟中会抑制树突生成[15]。类似于Spring Boot中的强制韧性，反向回路的记忆持久度梯度也存在。相对较好和较差的梯度信息存储在类似于脑褶的记忆痕迹细胞中，在反向回路的突触形成中。争议认为人类海马神经元的再生能力是否持续到老年，并可能在后期迭代中形成新的更长的回路[17,18]。关闭关键期会导致神经紊乱在实验和模拟中[19]。考虑到负面和正面记忆的持久性，有助于更好地激活突触。

    In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
    
[^77]: 时序多体相互作用的推断

    Inference of time-ordered multibody interactions. (arXiv:2111.14611v2 [physics.soc-ph] UPDATED)

    [http://arxiv.org/abs/2111.14611](http://arxiv.org/abs/2111.14611)

    本文介绍了时序多体相互作用的推断方法，该方法可以描述表现出时间依赖性和多体依赖性的复杂系统。通过将多元马尔可夫链的动力学分解为时序多体相互作用的集合，我们提出了一种从数据中提取这些相互作用的算法，并验证了算法的稳健性和效率。

    

    我们引入时序多体相互作用来描述表现出时间依赖性和多体依赖性的复杂系统。首先，我们展示了如何将多元马尔可夫链的动力学分解为时序多体相互作用的集合。然后，我们提出了一种从捕获节点状态系统级动力学的数据中提取这些相互作用的算法，以及一种用于表征相互作用集合复杂性的度量方法。最后，我们在统计误差下验证了我们的算法的稳健性，并证明了其推断简洁的相互作用集合的效率。

    We introduce time-ordered multibody interactions to describe complex systems manifesting temporal as well as multibody dependencies. First, we show how the dynamics of multivariate Markov chains can be decomposed in ensembles of time-ordered multibody interactions. Then, we present an algorithm to extract those interactions from data capturing the system-level dynamics of node states and a measure to characterize the complexity of interaction ensembles. Finally, we experimentally validate the robustness of our algorithm against statistical errors and its efficiency at inferring parsimonious interaction ensembles.
    
[^78]: 对抗训练中的标签噪声：研究鲁棒过度拟合的新视角

    Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting. (arXiv:2110.03135v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03135](http://arxiv.org/abs/2110.03135)

    该论文发现了对抗训练中存在的标签噪声，并解释了其对鲁棒过度拟合的普遍存在以及扰动半径和数据质量的依赖性。通过该论文提出的方法，可以自动校准标签以应对标签噪声和鲁棒过度拟合。

    

    我们展示了在对抗训练中存在标签噪声。这种标签噪声是由于对抗样本的真实标签分布与从干净样本继承的标签之间的不匹配造成的 - 真实标签分布被对抗扰动扭曲，但从干净样本继承标签的常见做法却忽略了这一点。认识到标签噪声有助于洞察对抗训练中鲁棒过度拟合的普遍存在，并解释了其对扰动半径和数据质量的奇特依赖性。此外，我们的标签噪声视角与我们对对抗训练中纪元双下降现象的观察相吻合。在我们的分析指导下，我们提出了一种方法来自动校准标签以应对标签噪声和鲁棒过度拟合。我们的方法在各种模型和数据集上实现了一致的性能提升，而不引入新的超参数或额外的调整。

    We show that label noise exists in adversarial training. Such label noise is due to the mismatch between the true label distribution of adversarial examples and the label inherited from clean examples - the true label distribution is distorted by the adversarial perturbation, but is neglected by the common practice that inherits labels from clean examples. Recognizing label noise sheds insights on the prevalence of robust overfitting in adversarial training, and explains its intriguing dependence on perturbation radius and data quality. Also, our label noise perspective aligns well with our observations of the epoch-wise double descent in adversarial training. Guided by our analyses, we proposed a method to automatically calibrate the label to address the label noise and robust overfitting. Our method achieves consistent performance improvements across various models and datasets without introducing new hyper-parameters or additional tuning.
    
[^79]: BEAUTY动力的BEAST

    BEAUTY Powered BEAST. (arXiv:2103.00674v5 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2103.00674](http://arxiv.org/abs/2103.00674)

    本文研究了使用BEAUTY方法进行分布无关的拟合优度检验。该方法通过二进制展开逼近特征函数，并将许多重要的独立性检验统一起来。使用数据自适应权重的BEAST检验提供了稳健的功效，同时提出了一个可行功效的参考。

    

    我们研究了使用提出的二进制展开近似均匀性（BEAUTY）方法的无分布拟合优度检验。该方法推广了著名的欧拉公式，并通过期望的二进制交互的线性组合来逼近任何联合分布函数的特征函数。这个新颖的理论通过特定的二次对称统计的逼近，将许多重要的独立性检验统一起来，其中确定性权重矩阵表征每个检验的功效性质。为了获得稳健的功效，我们使用数据自适应权重来检验检验统计量，称为二进制展开自适应对称性检验（BEAST）。利用二进制展开过程的性质，我们证明了均匀性的Neyman-Pearson检验可以通过oracle加权和的对称性统计量来近似。具有这个oracle的BEAST提供了可行功效的参考。

    We study distribution-free goodness-of-fit tests with the proposed Binary Expansion Approximation of UniformiTY (BEAUTY) approach. This method generalizes the renowned Euler's formula, and approximates the characteristic function of any copula through a linear combination of expectations of binary interactions from marginal binary expansions. This novel theory enables a unification of many important tests of independence via approximations from specific quadratic forms of symmetry statistics, where the deterministic weight matrix characterizes the power properties of each test. To achieve a robust power, we examine test statistics with data-adaptive weights, referred to as the Binary Expansion Adaptive Symmetry Test (BEAST). Using properties of the binary expansion filtration, we demonstrate that the Neyman-Pearson test of uniformity can be approximated by an oracle weighted sum of symmetry statistics. The BEAST with this oracle provides a useful benchmark of feasible power. To approac
    
[^80]: Ansor: 生成用于深度学习的高性能张量程序

    Ansor: Generating High-Performance Tensor Programs for Deep Learning. (arXiv:2006.06762v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.06762](http://arxiv.org/abs/2006.06762)

    Ansor是一个针对深度学习应用的张量程序生成框架，通过采样程序和使用进化搜索和学习的成本模型进行微调，能够高效地找到高性能的张量程序。

    

    高性能的张量程序对于保证深度神经网络的高效执行至关重要。然而，为不同的运算符在各种硬件平台上获得高性能张量程序是非常具有挑战性的。目前，深度学习系统依赖于供应商提供的内核库或各种搜索策略来获取高性能的张量程序。这些方法要么需要大量的工程工作来开发特定于平台的优化代码，要么由于受限的搜索空间和无效的探索策略而无法找到高性能的程序。我们提出了一种名为Ansor的张量程序生成框架，用于深度学习应用。与现有的搜索策略相比，Ansor通过从搜索空间的分层表示中采样程序来探索更多的优化组合。然后，Ansor使用进化搜索和学习的成本模型来对采样出的程序进行微调，以找到最佳程序。

    High-performance tensor programs are crucial to guarantee efficient execution of deep neural networks. However, obtaining performant tensor programs for different operators on various hardware platforms is notoriously challenging. Currently, deep learning systems rely on vendor-provided kernel libraries or various search strategies to get performant tensor programs. These approaches either require significant engineering effort to develop platform-specific optimization code or fall short of finding high-performance programs due to restricted search space and ineffective exploration strategy.  We present Ansor, a tensor program generation framework for deep learning applications. Compared with existing search strategies, Ansor explores many more optimization combinations by sampling programs from a hierarchical representation of the search space. Ansor then fine-tunes the sampled programs with evolutionary search and a learned cost model to identify the best programs. Ansor can find hig
    

