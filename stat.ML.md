# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Low coordinate degree algorithms I: Universality of computational thresholds for hypothesis testing](https://arxiv.org/abs/2403.07862) | 该研究探讨了低坐标度函数在高维概率测度假设检验中的普遍性，提出了一种新的分解方法来使其更广泛适用，证明了其在通过噪声信道进行随机信号存在检测中的成功性能。 |
| [^2] | [FairRR: Pre-Processing for Group Fairness through Randomized Response](https://arxiv.org/abs/2403.07780) | 本文提出了一种名为FairRR的预处理算法，通过在随机响应框架中修改响应变量的最优设计矩阵，直接控制群体公平性的度量，从而产生出色的下游模型效用和公平性。 |
| [^3] | [Probabilistic Easy Variational Causal Effect](https://arxiv.org/abs/2403.07745) | 论文提出了一种称为Probabilistic Easy Variational Causal Effect (PEACE)的函数，可以测量X对Y的直接因果效应，适用于连续和离散情况，通过管理概率密度值强度$d\ge 0$来实现干预。 |
| [^4] | [The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels](https://arxiv.org/abs/2403.07735) | HSIC估计的极小化率对平移不变核的独立性度量具有重要意义 |
| [^5] | [CAS: A General Algorithm for Online Selective Conformal Prediction with FCR Control](https://arxiv.org/abs/2403.07728) | CAS框架允许在在线选择性预测中控制FCR，通过自适应选择和校准集构造输出符合预测区间 |
| [^6] | [Balancing Fairness and Accuracy in Data-Restricted Binary Classification](https://arxiv.org/abs/2403.07724) | 研究提出了一个框架，直接分析最优贝叶斯分类器在数据限制的情况下的行为，以平衡准确性和公平性。 |
| [^7] | [On the Last-Iterate Convergence of Shuffling Gradient Methods](https://arxiv.org/abs/2403.07723) | 该论文证明了针对目标函数的洗牌梯度方法最后迭代的收敛速率，弥合了在不同设置中最后迭代的良好性能与现有理论之间的差距。 |
| [^8] | [Tuning diagonal scale matrices for HMC](https://arxiv.org/abs/2403.07495) | ISG方法相对于基准方法在许多情况下提高了采样效率，特别是在具有强相关性或非线性依赖性的情况下。 |
| [^9] | [On the nonconvexity of some push-forward constraints and its consequences in machine learning](https://arxiv.org/abs/2403.07471) | 本文提供了关于推进约束的非凸性的理论见解，并展示了这对相关学习问题的影响。 |
| [^10] | [On Ranking-based Tests of Independence](https://arxiv.org/abs/2403.07464) | 本文提出了一种基于排名的新的非参数框架来测试两个随机变量的独立性，该方法利用ROC分析和二部排名，具有超越竞争对手的理论性质。 |
| [^11] | [A tutorial on multi-view autoencoders using the multi-view-AE library](https://arxiv.org/abs/2403.07456) | 提出了一个统一的多视图自编码器数学框架，整合了各种公式，并拓展了 \texttt{multi-view-AE} 库的文档和功能。 |
| [^12] | [Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings](https://arxiv.org/abs/2403.07454) | 使用结构混合概率分布提供了准确的后验推断，同时具有更小的计算占用量，相较于现有的基于神经网络的SBI方法。 |
| [^13] | [Proxy Methods for Domain Adaptation](https://arxiv.org/abs/2403.07442) | 该论文研究了针对域自适应问题的代理方法，利用近端因果学习技术估计因果效应，在不恢复或建模潜在变量的情况下通过代理变量实现了对分布转移的适应。 |
| [^14] | [Knowledge Transfer across Multiple Principal Component Analysis Studies](https://arxiv.org/abs/2403.07431) | 提出了一种跨多个主成分分析研究的知识转移算法，通过整合多个研究中共享的子空间信息来增强目标PCA任务的估计准确性。 |
| [^15] | [Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends](https://arxiv.org/abs/2403.07379) | 分析神经网络和LLMs中优化轨迹的复杂性，揭示了优化过程中的关键特征，包括方向探索和方向正则化。 |
| [^16] | [How does promoting the minority fraction affect generalization? A theoretical study of the one-hidden-layer neural network on group imbalance](https://arxiv.org/abs/2403.07310) | 本文通过高斯混合模型量化了群体不平衡对样本复杂性、收敛速率和平均以及群体级测试性能的影响，首次提供了ERM在群体级泛化的理论分析。 |
| [^17] | [Near-Interpolators: Rapid Norm Growth and the Trade-Off between Interpolation and Generalization](https://arxiv.org/abs/2403.07264) | 研究了几乎插值线性回归器的泛化能力，证明了范数增长迅速且插值与泛化之间存在明确的权衡关系。 |
| [^18] | [Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction](https://arxiv.org/abs/2403.07263) | 通过两步形式预测方法，本文实现了自适应边界框不确定性的量化，保证了对象边界框不确定性区间的覆盖率，包括了错误分类的对象，同时确保边界框区间能够适应物体大小，实现更平衡的覆盖率。 |
| [^19] | [Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits](https://arxiv.org/abs/2403.07213) | 该论文提出了一种具有收敛意识的增量时间臂在线模型选择方法，用于在选择最佳模型时平衡任务奖励和探索成本。 |
| [^20] | [Tracking Dynamic Gaussian Density with a Theoretically Optimal Sliding Window Approach](https://arxiv.org/abs/2403.07207) | 通过理论上对滑动窗口高斯核密度估计器进行研究，提供了选择最优权重序列的原则指南，通过实证证据表明该加权方案相比启发式方法具有更好的跟踪性能 |
| [^21] | [Uncertainty in Graph Neural Networks: A Survey](https://arxiv.org/abs/2403.07185) | 本调查旨在全面概述图神经网络中的不确定性，并提出了关于如何识别、量化和利用不确定性来增强模型性能和 GNN 预测可靠性的观点。 |
| [^22] | [Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities](https://arxiv.org/abs/2403.07148) | 该论文针对三类变分不等式问题提出了具有随机重排的随机外推法（SEG-RR），并证明其在单调情况下实现了比均匀替换采样SEG更快的收敛速度。 |
| [^23] | [On the Limited Representational Power of Value Functions and its Links to Statistical (In)Efficiency](https://arxiv.org/abs/2403.07136) | 研究发现基于值函数的表征能力有限，导致在某些情况下基于值函数的方法在统计上低效率，这揭示了价值函数和统计效率之间的关联。 |
| [^24] | [The Cram Method for Efficient Simultaneous Learning and Evaluation](https://arxiv.org/abs/2403.07031) | Cram方法是一种同时学习和评估的高效方法，利用整个样本进行训练和测试，比传统的样本分割策略更高效。 |
| [^25] | [Convergence of Some Convex Message Passing Algorithms to a Fixed Point](https://arxiv.org/abs/2403.07004) | 这项研究证明了一些凸消息传递算法会收敛到固定点，并在一定迭代次数内达到特定精度。 |
| [^26] | [Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods](https://arxiv.org/abs/2312.08531) | 研究了随机梯度方法的最终迭代收敛性，并提出了不需要限制性假设的最优收敛速率问题。 |
| [^27] | [Quantum Inception Score](https://arxiv.org/abs/2311.12163) | 通过量子启蒙分数，我们提出了一个用于评估量子生成模型质量的新指标，证明量子生成模型在质量上优于经典生成模型，并利用量子波动定理揭示了其物理限制。 |
| [^28] | [Efficient Compression of Overparameterized Deep Models through Low-Dimensional Learning Dynamics](https://arxiv.org/abs/2311.05061) | 通过研究深度模型的学习动态，提出了一种压缩超参数化模型的新方法，通过在低维不变子空间内更新权重矩阵来压缩深度线性网络，并在矩阵恢复问题上进行了有效性评估 |
| [^29] | [TAP: The Attention Patch for Cross-Modal Knowledge Transfer from Unlabeled Modality](https://arxiv.org/abs/2302.02224) | 通过引入The Attention Patch（TAP）神经网络附加组件，本文提出了一种简单且有效的方法，允许从未标记的次要模态实现跨模态的数据级知识传递。 |
| [^30] | [An alternative approach to train neural networks using monotone variational inequality](https://arxiv.org/abs/2202.08876) | 通过单调变分不等式，提出了一种高效的神经网络训练方法，可以快速收敛并在特定情况下提供保证。 |
| [^31] | [Learning and Decision-Making with Data: Optimal Formulations and Phase Transitions](https://arxiv.org/abs/2109.06911) | 本论文提出了一种新的方法，通过首先定义一个衡量基于数据公式质量的标尺，然后寻找最优公式，使其在保证样本外性能的同时，更加接近真实成本。 |
| [^32] | [A local approach to parameter space reduction for regression and classification tasks](https://arxiv.org/abs/2107.10867) | 本文提出一种名为局部主动子空间（LAS）的新方法，通过探索主动子空间与监督聚类技术的结合，实现了更有效的参数空间维度缩减，尤其在高维参数化系统中具有重要意义。 |
| [^33] | [Epoch-evolving Gaussian Process Guided Learning](https://arxiv.org/abs/2006.14347) | 提出了一种名为GPGL的epoch-evolving Gaussian Process Guided Learning学习方案，通过上下文标签和地面真实标签指导模型参数更新，进一步推广并应用于当前深度模型，在主流数据集上表现显著优于现有基于批次的最先进模型 |
| [^34] | [lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap.](http://arxiv.org/abs/2401.15879) | 本文提出了一种名为lil'HDoC的算法，用于解决小阈值间隙下的好臂识别问题。实验证明该算法在样本效率上优于现有算法。 |
| [^35] | [Beyond Regrets: Geometric Metrics for Bayesian Optimization.](http://arxiv.org/abs/2401.01981) | 本论文提出了四个新的几何度量，可以比较贝叶斯优化算法在考虑查询点和全局最优解的几何特性时的性能。 |
| [^36] | [Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers.](http://arxiv.org/abs/2310.12553) | 提出一种插入/删除指标感知的基于解释的优化(ID-ExpO)方法，通过优化可区分的预测器来提高解释的插入和删除得分，并保持预测准确性。实验结果表明，ID-ExpO能够使流行的事后解释器产生更忠实的解释。 |
| [^37] | [Dynamic Prediction using Time-Dependent Cox Survival Neural Network.](http://arxiv.org/abs/2307.05881) | 该论文通过使用time-dependent Cox模型和神经网络，提出了一种动态预测模型来预测进行性眼部疾病年龄相关性黄斑变性（AMD）的进展。通过使用纵向眼底图像作为输入，该模型可以建立一个个体化的风险预测模型，并且在实证研究中表现出良好的效果。 |
| [^38] | [Integrating Uncertainty Awareness into Conformalized Quantile Regression.](http://arxiv.org/abs/2306.08693) | 新提出的方法 UACQR 将条件分位估计和整合推断结合，以区分随机不确定性和认识性不确定性，并相应地构造预测区间，可以在量子回归器在特征空间的不同子集上优于现有的 CQR 方法。 |
| [^39] | [Alignment of Density Maps in Wasserstein Distance.](http://arxiv.org/abs/2305.12310) | 本文提出了一种使用Wasserstein距离对三维物体进行对齐的算法，并通过贝叶斯优化实现计算。在对齐真实蛋白质分子方面，该算法表现出更好的准确性和效率，并阐明了对新距离函数的需求。 |
| [^40] | [Utility Theory of Synthetic Data Generation.](http://arxiv.org/abs/2305.10015) | 本文从统计学角度建立效用理论，旨在基于一般性指标定量评估合成算法的效用，效用指标的分析界限揭示了指标收敛的关键条件，令人惊讶的是，只要下游学习任务中的模型规范是正确的，合成特征分布不一定与原始特征分布相同，效用指标会收敛。 |
| [^41] | [An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response.](http://arxiv.org/abs/2303.17823) | 本文提出了一种基于可解释神经网络的非比例赔率模型 (N$^3$POM) 用于有序回归，可以对连续变量进行预测，同时保留了可解释性，具有灵活性。 |

# 详细

[^1]: 低坐标度算法 I：假设检验的计算门限的普适性

    Low coordinate degree algorithms I: Universality of computational thresholds for hypothesis testing

    [https://arxiv.org/abs/2403.07862](https://arxiv.org/abs/2403.07862)

    该研究探讨了低坐标度函数在高维概率测度假设检验中的普遍性，提出了一种新的分解方法来使其更广泛适用，证明了其在通过噪声信道进行随机信号存在检测中的成功性能。

    

    我们研究了低坐标度函数（LCDF）何时可以在高维概率测度之间进行假设检验 -- LCDF是依赖于向量的一个小子集的函数的线性组合，这是对低次多项式（LDP）的一个推 generalization，LDP是最近文献中广泛用于作为所有统计学和优化任务中有效算法的代理的一个类。我们的LCDF分析不同于LDP计算中使用的正交多项式分解，而是基于Efron-Stein或ANOVA分解，使其适用范围更广泛。作为示例，我们证明了通道普适性，指出LCDF在通过噪声信道进行充分“稀疏”随机信号存在假设检验时的成功：LCDF的功效仅仅取决于通道，对于包括

    arXiv:2403.07862v1 Announce Type: cross  Abstract: We study when low coordinate degree functions (LCDF) -- linear combinations of functions depending on small subsets of entries of a vector -- can hypothesis test between high-dimensional probability measures. These functions are a generalization, proposed in Hopkins' 2018 thesis but seldom studied since, of low degree polynomials (LDP), a class widely used in recent literature as a proxy for all efficient algorithms for tasks in statistics and optimization. Instead of the orthogonal polynomial decompositions used in LDP calculations, our analysis of LCDF is based on the Efron-Stein or ANOVA decomposition, making it much more broadly applicable. By way of illustration, we prove channel universality for the success of LCDF in testing for the presence of sufficiently "dilute" random signals through noisy channels: the efficacy of LCDF depends on the channel only through the scalar Fisher information for a class of channels including nearl
    
[^2]: 公平RR：通过随机响应实现群体公平的预处理

    FairRR: Pre-Processing for Group Fairness through Randomized Response

    [https://arxiv.org/abs/2403.07780](https://arxiv.org/abs/2403.07780)

    本文提出了一种名为FairRR的预处理算法，通过在随机响应框架中修改响应变量的最优设计矩阵，直接控制群体公平性的度量，从而产生出色的下游模型效用和公平性。

    

    机器学习模型在重要决策过程中的使用日益增多，这促使人们开始研究这些系统的公平性。虽然在处理过程和后处理设置中已经进行了大量工作来研究群体公平性，但很少有研究能够从理论上将这些结果与预处理领域连接起来。本文提出，实现下游模型中的群体公平性可以被形式化为在随机响应框架中修改响应变量的最优设计矩阵。我们展示了群体公平性的度量可以通过最优模型效用直接控制，提出了一种称为FairRR的预处理算法，该算法产生出色的下游模型效用和公平性。

    arXiv:2403.07780v1 Announce Type: cross  Abstract: The increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. While significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. This paper proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a Randomized Response framework. We show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called FairRR that yields excellent downstream model utility and fairness.
    
[^3]: 概率易变量因果效应研究

    Probabilistic Easy Variational Causal Effect

    [https://arxiv.org/abs/2403.07745](https://arxiv.org/abs/2403.07745)

    论文提出了一种称为Probabilistic Easy Variational Causal Effect (PEACE)的函数，可以测量X对Y的直接因果效应，适用于连续和离散情况，通过管理概率密度值强度$d\ge 0$来实现干预。

    

    论文研究随机向量$X$和$Z$，以及$Y=g(X,Z)$的情况。一方面，对于连续的$X$和$Z$，通过使用总变差和$g$的通量的思想，我们发展了一个在因果推断中能够处理广泛因果问题领域的视角。我们关注一个称为Probabilistic Easy Variational Causal Effect (PEACE)的函数，它可以测量$X$对$Y$的直接因果效应，而同时改变$X$的值，但保持$Z$的值不变。PEACE是关于$d\ge 0$的一个函数，管理着概率密度值$f(x|z)$的强度。另一方面，我们将上述思想推广到离散情况，并展示其与连续情况的兼容性。此外，我们使用测度论概念研究了PEACE的一些性质。此外，我们提供了一些可辨识性标准。

    arXiv:2403.07745v1 Announce Type: cross  Abstract: Let $X$ and $Z$ be random vectors, and $Y=g(X,Z)$. In this paper, on the one hand, for the case that $X$ and $Z$ are continuous, by using the ideas from the total variation and the flux of $g$, we develop a point of view in causal inference capable of dealing with a broad domain of causal problems. Indeed, we focus on a function, called Probabilistic Easy Variational Causal Effect (PEACE), which can measure the direct causal effect of $X$ on $Y$ with respect to continuously and interventionally changing the values of $X$ while keeping the value of $Z$ constant. PEACE is a function of $d\ge 0$, which is a degree managing the strengths of probability density values $f(x|z)$. On the other hand, we generalize the above idea for the discrete case and show its compatibility with the continuous case. Further, we investigate some properties of PEACE using measure theoretical concepts. Furthermore, we provide some identifiability criteria and s
    
[^4]: HSIC估计的极小化率对平移不变核

    The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels

    [https://arxiv.org/abs/2403.07735](https://arxiv.org/abs/2403.07735)

    HSIC估计的极小化率对平移不变核的独立性度量具有重要意义

    

    Kernel技术是数据科学和统计学中最有影响力的方法之一。在温和条件下，与核相关的再生核希尔伯特空间能够编码$M\ge 2$个随机变量的独立性。在核上依赖的最普遍的独立性度量可能是所谓的Hilbert-Schmidt独立性准则(HSIC; 在统计文献中也称为距离协方差)。尽管自近二十年前引入以来已经有各种现有的设计的HSIC估计量，HSIC可以被估计的速度的基本问题仍然是开放的。在这项工作中，我们证明了对于包含具有连续有界平移不变特征核的高斯Borel测度在$\mathbb R^d$上的HSIC估计的极小化最优速率是$\mathcal O\!\left(n^{-1/2}\right)$。具体地，我们的结果意味着许多方面在极小化意义上的最优性

    arXiv:2403.07735v1 Announce Type: cross  Abstract: Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the optimality in the minimax sense of many 
    
[^5]: CAS: 一种具有FCR控制的在线选择性符合预测的通用算法

    CAS: A General Algorithm for Online Selective Conformal Prediction with FCR Control

    [https://arxiv.org/abs/2403.07728](https://arxiv.org/abs/2403.07728)

    CAS框架允许在在线选择性预测中控制FCR，通过自适应选择和校准集构造输出符合预测区间

    

    我们研究了在线方式下后选择预测推断的问题。为了避免将资源耗费在不重要的单位上，在报告其预测区间之前对当前个体进行初步选择在在线预测任务中是常见且有意义的。由于在线选择导致所选预测区间中存在时间多重性，因此控制实时误覆盖陈述率（FCR）来测量平均误覆盖误差是重要的。我们开发了一个名为CAS（适应性选择后校准）的通用框架，可以包裹任何预测模型和在线选择规则，以输出后选择的预测区间。如果选择了当前个体，我们首先对历史数据进行自适应选择来构建校准集，然后为未观察到的标签输出符合预测区间。我们为校准集提供了可行的构造方式

    arXiv:2403.07728v1 Announce Type: cross  Abstract: We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) to measure the averaged miscoverage error. We develop a general framework named CAS (Calibration after Adaptive Selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. If the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. We provide tractable constructions for the calibration set for 
    
[^6]: 在数据限制的二分类中平衡公平性和准确性

    Balancing Fairness and Accuracy in Data-Restricted Binary Classification

    [https://arxiv.org/abs/2403.07724](https://arxiv.org/abs/2403.07724)

    研究提出了一个框架，直接分析最优贝叶斯分类器在数据限制的情况下的行为，以平衡准确性和公平性。

    

    处理敏感信息的应用可能对机器学习（ML）分类器可用数据设置限制。本文提出一个框架，模拟准确性和公平性之间的权衡，在四种实际情景下探讨可用于分析的数据类型。与先前研究通过分析经训练以隐式学习数据集的特征向量、类别标签和敏感属性的潜在分布的评分函数的输出来考虑这种权衡不同，我们的框架直接通过从数据集本身构建的离散近似来分析最优贝叶斯分类器在这个潜在分布上的行为。这种方法使我们能够制定多个凸优化问题，以更好地平衡准确性和公平性。

    arXiv:2403.07724v1 Announce Type: cross  Abstract: Applications that deal with sensitive information may have restrictions placed on the data available to a machine learning (ML) classifier. For example, in some applications, a classifier may not have direct access to sensitive attributes, affecting its ability to produce accurate and fair decisions. This paper proposes a framework that models the trade-off between accuracy and fairness under four practical scenarios that dictate the type of data available for analysis. Prior works examine this trade-off by analyzing the outputs of a scoring function that has been trained to implicitly learn the underlying distribution of the feature vector, class label, and sensitive attribute of a dataset. In contrast, our framework directly analyzes the behavior of the optimal Bayesian classifier on this underlying distribution by constructing a discrete approximation it from the dataset itself. This approach enables us to formulate multiple convex 
    
[^7]: 关于洗牌梯度方法的最后迭代收敛性

    On the Last-Iterate Convergence of Shuffling Gradient Methods

    [https://arxiv.org/abs/2403.07723](https://arxiv.org/abs/2403.07723)

    该论文证明了针对目标函数的洗牌梯度方法最后迭代的收敛速率，弥合了在不同设置中最后迭代的良好性能与现有理论之间的差距。

    

    洗牌梯度方法，也被称为无替换的随机梯度下降（SGD），在实践中被广泛应用，特别包括三种流行算法：Random Reshuffle（RR）、Shuffle Once（SO）和Incremental Gradient（IG）。与经验成功相比，长期以来对于洗牌梯度方法的理论保证并不充分了解。最近，只为凸函数的平均迭代和强凸问题的最后迭代（以平方距离为度量）建立了收敛速率。然而，当将函数值差作为收敛准则时，现有理论无法解释在不同设置中（例如受约束的优化）最后迭代的良好性能。为了弥合这种实践与理论之间的差距，我们针对目标函数证明了洗牌梯度方法最后迭代的收敛速率。

    arXiv:2403.07723v1 Announce Type: new  Abstract: Shuffling gradient methods, which are also known as stochastic gradient descent (SGD) without replacement, are widely implemented in practice, particularly including three popular algorithms: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understanding for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove last-iterate convergence rates for shuffling gradient methods with respect to the objectiv
    
[^8]: 为HMC调整对角比例矩阵

    Tuning diagonal scale matrices for HMC

    [https://arxiv.org/abs/2403.07495](https://arxiv.org/abs/2403.07495)

    ISG方法相对于基准方法在许多情况下提高了采样效率，特别是在具有强相关性或非线性依赖性的情况下。

    

    讨论并比较了三种自适应调整HMC对角比例矩阵的方法。将根据估计边际标准差进行缩放的常见做法作为基准。根据平均对数目标梯度（ISG）进行缩放，以及一个旨在使底层哈密顿动力学穿越各自中位数的频率在维度上均匀的缩放方法被视为替代方案。数值研究表明，ISG方法在许多情况下比基准方法更有效，特别是在存在强相关性或非线性依赖性的情况下。ISG方法也易于实现，计算成本低，相对简单地包含在自动调整代码中作为基准做法的替代方案。

    arXiv:2403.07495v1 Announce Type: cross  Abstract: Three approaches for adaptively tuning diagonal scale matrices for HMC are discussed and compared. The common practice of scaling according to estimated marginal standard deviations is taken as a benchmark. Scaling according to the mean log-target gradient (ISG), and a scaling method targeting that the frequency of when the underlying Hamiltonian dynamics crosses the respective medians should be uniform across dimensions, are taken as alternatives. Numerical studies suggest that the ISG method leads in many cases to more efficient sampling than the benchmark, in particular in cases with strong correlations or non-linear dependencies. The ISG method is also easy to implement, computationally cheap and would be relatively simple to include in automatically tuned codes as an alternative to the benchmark practice.
    
[^9]: 有关某些推进约束的非凸性及其在机器学习中的影响

    On the nonconvexity of some push-forward constraints and its consequences in machine learning

    [https://arxiv.org/abs/2403.07471](https://arxiv.org/abs/2403.07471)

    本文提供了关于推进约束的非凸性的理论见解，并展示了这对相关学习问题的影响。

    

    push-forward操作使人能够通过确定性映射重新分配概率测度。它在统计和优化中起着关键作用：许多学习问题（特别是来自最优输运、生成建模和算法公平性的问题）包括作为模型上的推进条件或处罚的约束。然而，文献缺乏关于这些约束的（非）凸性及其对相关学习问题的影响的一般理论见解。本文旨在填补这一空白。在第一部分中，我们提供了两组函数（将一个概率测度传输到另一个的映射；诱导不同概率测度之间相等输出分布的映射）的（非）凸性的一系列充分必要条件。这突出了对于大多数概率测度而言，这些推进约束是非凸的。在接下来，我们展示了这一结果如何暗示

    arXiv:2403.07471v1 Announce Type: cross  Abstract: The push-forward operation enables one to redistribute a probability measure through a deterministic map. It plays a key role in statistics and optimization: many learning problems (notably from optimal transport, generative modeling, and algorithmic fairness) include constraints or penalties framed as push-forward conditions on the model. However, the literature lacks general theoretical insights on the (non)convexity of such constraints and its consequences on the associated learning problems. This paper aims at filling this gap. In a first part, we provide a range of sufficient and necessary conditions for the (non)convexity of two sets of functions: the maps transporting one probability measure to another; the maps inducing equal output distributions across distinct probability measures. This highlights that for most probability measures, these push-forward constraints are not convex. In a second time, we show how this result impli
    
[^10]: 基于排名的独立性检验

    On Ranking-based Tests of Independence

    [https://arxiv.org/abs/2403.07464](https://arxiv.org/abs/2403.07464)

    本文提出了一种基于排名的新的非参数框架来测试两个随机变量的独立性，该方法利用ROC分析和二部排名，具有超越竞争对手的理论性质。

    

    在本文中，我们提出了一种新的非参数框架，用于基于“接收器操作特性”（ROC）分析和二部排名来测试具有未知边际分布H(dx)和G(dy)以及联合分布F(dx dy)的两个随机变量X和Y的独立性。我们的方法的基本原理在于，独立性假设H_0在从二部排名算法得到的与分布对(H ⊗ G，F)相关联的最佳评分函数具有偏离单位正方形主对角线的ROC曲线时必然不成立。我们考虑了一类广泛的秩统计量，涵盖了在ROC空间中偏离对角线的许多方式，以构建独立性检验。除了其极大的灵活性外，这种新方法具有远超其竞争对手的理论特性。我们还得到了在非渐近情况下的两个t

    arXiv:2403.07464v1 Announce Type: cross  Abstract: In this paper we develop a novel nonparametric framework to test the independence of two random variables $\mathbf{X}$ and $\mathbf{Y}$ with unknown respective marginals $H(dx)$ and $G(dy)$ and joint distribution $F(dx dy)$, based on {\it Receiver Operating Characteristic} (ROC) analysis and bipartite ranking. The rationale behind our approach relies on the fact that, the independence hypothesis $\mathcal{H}\_0$ is necessarily false as soon as the optimal scoring function related to the pair of distributions $(H\otimes G,\; F)$, obtained from a bipartite ranking algorithm, has a ROC curve that deviates from the main diagonal of the unit square.We consider a wide class of rank statistics encompassing many ways of deviating from the diagonal in the ROC space to build tests of independence. Beyond its great flexibility, this new method has theoretical properties that far surpass those of its competitors. Nonasymptotic bounds for the two t
    
[^11]: 使用 multi-view-AE 库的多视图自编码器教程

    A tutorial on multi-view autoencoders using the multi-view-AE library

    [https://arxiv.org/abs/2403.07456](https://arxiv.org/abs/2403.07456)

    提出了一个统一的多视图自编码器数学框架，整合了各种公式，并拓展了 \texttt{multi-view-AE} 库的文档和功能。

    

    近年来，对建模数据的多个模态（或视图）以便理解模态之间的关系或生成缺失数据引起了越来越多的关注。多视图自编码器因其能够适应和灵活建模多模态数据的能力而备受关注，表明其具有根据手头数据特征调整方法的能力。然而，大多数多视图自编码器存在一致性符号标注不一的问题，并且通常使用不同的编码框架实现。为解决这个问题，我们提出了一个统一的多视图自编码器数学框架，整合了它们的公式。此外，我们提供了对每个模型动机和理论优势的见解。为了方便访问和实际使用，我们扩展了先前介绍的 multi-view-AE 库的文档和功能。该库提供了 Python 实现。

    arXiv:2403.07456v1 Announce Type: new  Abstract: There has been a growing interest in recent years in modelling multiple modalities (or views) of data to for example, understand the relationship between modalities or to generate missing data. Multi-view autoencoders have gained significant traction for their adaptability and versatility in modelling multi-modal data, demonstrating an ability to tailor their approach to suit the characteristics of the data at hand. However, most multi-view autoencoders have inconsistent notation and are often implemented using different coding frameworks. To address this, we present a unified mathematical framework for multi-view autoencoders, consolidating their formulations. Moreover, we offer insights into the motivation and theoretical advantages of each model. To facilitate accessibility and practical use, we extend the documentation and functionality of the previously introduced \texttt{multi-view-AE} library. This library offers Python implementa
    
[^12]: 使用高斯局部线性映射进行快速、准确和轻量级的顺序仿真推断

    Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings

    [https://arxiv.org/abs/2403.07454](https://arxiv.org/abs/2403.07454)

    使用结构混合概率分布提供了准确的后验推断，同时具有更小的计算占用量，相较于现有的基于神经网络的SBI方法。

    

    arXiv:2403.07454v1 公告类型: 跨领域 摘要: 针对具有难以处理的似然函数的复杂模型的贝叶斯推断可以使用多次调用计算模拟器的算法来解决。 这些方法被统称为“基于仿真的推断”（SBI）。 最近的SBI方法利用神经网络（NN）提供近似但表达丰富的构造，用于不可用的似然函数和后验分布。 然而，它们通常无法实现准确性和计算需求之间的最佳折衷。 在这项工作中，我们提出了一种提供似然函数和后验分布近似的替代方法，使用结构化的概率分布混合物。 相对于最先进的基于NN的SBI方法，我们的方法在产生准确的后验推断的同时，具有更小的计算占用量。 我们在SBI文献中的几个基准模型上展示了我们的结果。

    arXiv:2403.07454v1 Announce Type: cross  Abstract: Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as "simulation-based inference" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, they do not generally achieve an optimal trade-off between accuracy and computational demand. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature.
    
[^13]: 针对域自适应的代理方法

    Proxy Methods for Domain Adaptation

    [https://arxiv.org/abs/2403.07442](https://arxiv.org/abs/2403.07442)

    该论文研究了针对域自适应问题的代理方法，利用近端因果学习技术估计因果效应，在不恢复或建模潜在变量的情况下通过代理变量实现了对分布转移的适应。

    

    我们研究了在分布转移下的域自适应问题，这种转移是由于未观察到的潜在变量分布发生改变，导致协变量和标签都被混淆。在这种情况下，既不适用协变量转移也不适用标签转移的假设。我们的自适应方法采用了近端因果学习，一种在可获得未观察混淆变量代理的设置中估计因果效应的技术。我们展示了代理变量允许适应分布转移，而无需显式恢复或建模潜在变量。我们考虑了两种情况，(i) 概念瓶颈：观察到一个额外的“概念”变量，它在协变量和标签之间起到中介作用；(ii) 多领域：可用来自多个源领域的训练数据，其中每个源领域展示了对潜在混杂变量的不同分布。我们开发了一个两阶段的 k

    arXiv:2403.07442v1 Announce Type: new  Abstract: We study the problem of domain adaptation under distribution shift, where the shift is due to a change in the distribution of an unobserved, latent variable that confounds both the covariates and the labels. In this setting, neither the covariate shift nor the label shift assumptions apply. Our approach to adaptation employs proximal causal learning, a technique for estimating causal effects in settings where proxies of unobserved confounders are available. We demonstrate that proxy variables allow for adaptation to distribution shift without explicitly recovering or modeling latent variables. We consider two settings, (i) Concept Bottleneck: an additional ''concept'' variable is observed that mediates the relationship between the covariates and labels; (ii) Multi-domain: training data from multiple source domains is available, where each source domain exhibits a different distribution over the latent confounder. We develop a two-stage k
    
[^14]: 跨多个主成分分析研究的知识转移

    Knowledge Transfer across Multiple Principal Component Analysis Studies

    [https://arxiv.org/abs/2403.07431](https://arxiv.org/abs/2403.07431)

    提出了一种跨多个主成分分析研究的知识转移算法，通过整合多个研究中共享的子空间信息来增强目标PCA任务的估计准确性。

    

    Transfer learning在统计领域引起了极大兴趣。本文关注于无监督学习任务的知识转移，与文献中的监督学习任务相对比。在给定可转移的源人口的情况下，我们提出了一个两步的转移学习算法，从多个源主成分分析（PCA）研究中提取有用信息，从而增强目标PCA任务的估计准确性。第一步中，我们通过一种名为Grassmannian barycenter的方法，整合跨多个研究共享的子空间信息，而不是直接在汇总数据集上执行PCA。提出的Grassmannian barycenter方法在更一般的情况下具有鲁棒性和计算优势。然后，第一步得到的共享子空间的估计器进一步用于估计第二步中的目标私有子空间。

    arXiv:2403.07431v1 Announce Type: cross  Abstract: Transfer learning has aroused great interest in the statistical community. In this article, we focus on knowledge transfer for unsupervised learning tasks in contrast to the supervised learning tasks in the literature. Given the transferable source populations, we propose a two-step transfer learning algorithm to extract useful information from multiple source principal component analysis (PCA) studies, thereby enhancing estimation accuracy for the target PCA task. In the first step, we integrate the shared subspace information across multiple studies by a proposed method named as Grassmannian barycenter, instead of directly performing PCA on the pooled dataset. The proposed Grassmannian barycenter method enjoys robustness and computational advantages in more general cases. Then the resulting estimator for the shared subspace from the first step is further utilized to estimate the target private subspace in the second step. Our theoret
    
[^15]: 神经网络和LLMs中优化轨迹的特征：长度、拐点和死胡同

    Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends

    [https://arxiv.org/abs/2403.07379](https://arxiv.org/abs/2403.07379)

    分析神经网络和LLMs中优化轨迹的复杂性，揭示了优化过程中的关键特征，包括方向探索和方向正则化。

    

    我们提出了一种全新的方法来理解神经网络的机制，通过分析其优化轨迹中包含的丰富参数结构。为此，我们引入了一些关于优化轨迹复杂性的自然概念，既定性又定量地揭示了各种优化选择（如动量、权重衰减和批大小）之间所涉及的内在微妙和相互作用。我们利用这些概念来提供关于深度神经网络优化本质的关键特征：何时顺利进行，何时陷入死胡同。此外，基于我们的轨迹视角，我们揭示了动量和权重衰减之间促进方向探索的交织行为，以及其他一些行为的方向正则化行为。我们在大规模视觉和语言设置中进行实验，包括具有最多120亿个参数的大型语言模型（LLMs）。

    arXiv:2403.07379v1 Announce Type: cross  Abstract: We propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. Towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. We use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. Further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. We perform experiments over large-scale vision and language settings, including large language models (LLMs) with up to 12 billio
    
[^16]: 推动少数群体份额如何影响泛化？关于一层隐藏层神经网络在群体不平衡上的理论研究

    How does promoting the minority fraction affect generalization? A theoretical study of the one-hidden-layer neural network on group imbalance

    [https://arxiv.org/abs/2403.07310](https://arxiv.org/abs/2403.07310)

    本文通过高斯混合模型量化了群体不平衡对样本复杂性、收敛速率和平均以及群体级测试性能的影响，首次提供了ERM在群体级泛化的理论分析。

    

    群体不平衡一直是经验风险最小化（ERM）中已知的问题，其中取得的高平均准确率伴随着少数群体的低准确率。尽管有算法努力改善少数群体的准确性，但关于ERM在各个群体上的理论泛化分析仍然难以实现。通过用高斯混合模型表达群体不平衡问题，本文量化了各个群体对样本复杂性、收敛速率以及平均和群体级测试性能的影响。虽然我们的理论框架集中在使用一层隐藏层神经网络进行二分类，但据我们所知，我们首次提供了ERM在群体级泛化的理论分析，除了通常研究的平均泛化性能。我们的理论结果的一些见解包括当所有群体级协方差都在...

    arXiv:2403.07310v1 Announce Type: cross  Abstract: Group imbalance has been a known problem in empirical risk minimization (ERM), where the achieved high average accuracy is accompanied by low accuracy in a minority group. Despite algorithmic efforts to improve the minority group accuracy, a theoretical generalization analysis of ERM on individual groups remains elusive. By formulating the group imbalance problem with the Gaussian Mixture Model, this paper quantifies the impact of individual groups on the sample complexity, the convergence rate, and the average and group-level testing performance. Although our theoretical framework is centered on binary classification using a one-hidden-layer neural network, to the best of our knowledge, we provide the first theoretical analysis of the group-level generalization of ERM in addition to the commonly studied average generalization performance. Sample insights of our theoretical results include that when all group-level co-variance is in th
    
[^17]: 近插值器：快速范数增长与插值与泛化之间的权衡

    Near-Interpolators: Rapid Norm Growth and the Trade-Off between Interpolation and Generalization

    [https://arxiv.org/abs/2403.07264](https://arxiv.org/abs/2403.07264)

    研究了几乎插值线性回归器的泛化能力，证明了范数增长迅速且插值与泛化之间存在明确的权衡关系。

    

    我们研究了几乎插值线性回归器的泛化能力：其训练误差τ为正但很小，即低于噪声水平。在对数据分布进行随机矩阵理论假设和对数据协方差矩阵Σ进行特征衰减假设的情况下，我们证明了任何近插值器都表现出快速的范数增长：对于固定的τ，β的平方∥β∥2 的增长率为Ω(n^α)，其中n为样本数量，α>1是特征衰减的指数，即λ_i(Σ)∼i^(-α)。这意味着现有的独立于数据的范数界限必定松弛。另一方面，在相同的区间内，我们精确地刻画了插值和泛化之间的渐近权衡。我们的表征揭示出了大多数现有范数界限是宽松的。

    arXiv:2403.07264v1 Announce Type: cross  Abstract: We study the generalization capability of nearly-interpolating linear regressors: $\boldsymbol{\beta}$'s whose training error $\tau$ is positive but small, i.e., below the noise floor. Under a random matrix theoretic assumption on the data distribution and an eigendecay assumption on the data covariance matrix $\boldsymbol{\Sigma}$, we demonstrate that any near-interpolator exhibits rapid norm growth: for $\tau$ fixed, $\boldsymbol{\beta}$ has squared $\ell_2$-norm $\mathbb{E}[\|{\boldsymbol{\beta}}\|_{2}^{2}] = \Omega(n^{\alpha})$ where $n$ is the number of samples and $\alpha >1$ is the exponent of the eigendecay, i.e., $\lambda_i(\boldsymbol{\Sigma}) \sim i^{-\alpha}$. This implies that existing data-independent norm-based bounds are necessarily loose. On the other hand, in the same regime we precisely characterize the asymptotic trade-off between interpolation and generalization. Our characterization reveals that larger norm scalin
    
[^18]: 通过两步形式预测实现自适应边界框不确定性

    Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction

    [https://arxiv.org/abs/2403.07263](https://arxiv.org/abs/2403.07263)

    通过两步形式预测方法，本文实现了自适应边界框不确定性的量化，保证了对象边界框不确定性区间的覆盖率，包括了错误分类的对象，同时确保边界框区间能够适应物体大小，实现更平衡的覆盖率。

    

    量化模型的预测不确定性对于像自动驾驶这样的安全关键应用至关重要。我们考虑为多物体检测量化这种不确定性。具体来说，我们利用形式预测来获得具有保证覆盖率的物体边界框不确定性区间。这样做的一个挑战是边界框的预测取决于物体的类别标签。因此，我们开发了一种新颖的两步形式方法，将对预测类别标签的不确定性传播到边界框的不确定性区间中。这样，我们的形式覆盖保证的有效性更广泛，包括了被错误分类的物体，确保它们在需要最大安全保证时的实用性。此外，我们研究了新颖的集成和分位数回归形式，以确保边界框区间能够适应物体大小，从而实现更平衡的覆盖率。

    arXiv:2403.07263v1 Announce Type: cross  Abstract: Quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. We consider quantifying such uncertainty for multi-object detection. In particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. One challenge in doing so is that bounding box predictions are conditioned on the object's class label. Thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals for the bounding boxes. This broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, ensuring their usefulness when maximal safety assurances are required. Moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage across
    
[^19]: 选择哪个LLM？具有收敛意识的增量时间臂的在线模型选择

    Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits

    [https://arxiv.org/abs/2403.07213](https://arxiv.org/abs/2403.07213)

    该论文提出了一种具有收敛意识的增量时间臂在线模型选择方法，用于在选择最佳模型时平衡任务奖励和探索成本。

    

    Web-based应用，如聊天机器人、搜索引擎和新闻推荐，随着LLMs的日益普及，在规模和复杂性上继续增长。在线模型选择因需要在平衡任务奖励和探索成本的同时选择最佳模型而引起了越来越多的关注。传统的选择方法通常在选择一个模型之前评估每个候选模型，随着训练和微调LLMs成本的上升，这些方法变得不切实际。此外，分配过多资源去探索表现不佳的模型是不可取的。尽管一些最新的工作利用在线臂算法来管理模型选择中的这种探索-开发权衡，但它们往往忽视了增长然后收敛趋势。

    arXiv:2403.07213v1 Announce Type: new  Abstract: Web-based applications such as chatbots, search engines and news recommendations continue to grow in scale and complexity with the recent surge in the adoption of LLMs. Online model selection has thus garnered increasing attention due to the need to choose the best model among a diverse set while balancing task reward and exploration cost. Organizations faces decisions like whether to employ a costly API-based LLM or a locally finetuned small LLM, weighing cost against performance. Traditional selection methods often evaluate every candidate model before choosing one, which are becoming impractical given the rising costs of training and finetuning LLMs. Moreover, it is undesirable to allocate excessive resources towards exploring poor-performing models. While some recent works leverage online bandit algorithm to manage such exploration-exploitation trade-off in model selection, they tend to overlook the increasing-then-converging trend i
    
[^20]: 使用理论上最优的滑动窗口方法跟踪动态高斯密度

    Tracking Dynamic Gaussian Density with a Theoretically Optimal Sliding Window Approach

    [https://arxiv.org/abs/2403.07207](https://arxiv.org/abs/2403.07207)

    通过理论上对滑动窗口高斯核密度估计器进行研究，提供了选择最优权重序列的原则指南，通过实证证据表明该加权方案相比启发式方法具有更好的跟踪性能

    

    动态密度估计在许多应用中是普遍存在的，包括计算机视觉和信号处理。解决这一问题的一种流行方法是“滑动窗口”核密度估计器。该方法存在多种不同的实现，这些实现使用启发式定义的加权序列用于观测数据。但是，权重序列是影响估计器跟踪性能的关键因素。在这项工作中，我们研究了针对不断演变的高斯密度的“滑动窗口”高斯核密度估计器的精确均方集成误差（MISE）。我们通过理论上表征准确MISE的方式提供了选择最优权重序列的原则指南，它可以被构建为受限二次规划。我们通过合成数据集提供实证证据，表明我们的加权方案确实提高了跟踪性能，与启发式方法相比有显著改进。

    arXiv:2403.07207v1 Announce Type: cross  Abstract: Dynamic density estimation is ubiquitous in many applications, including computer vision and signal processing. One popular method to tackle this problem is the "sliding window" kernel density estimator. There exist various implementations of this method that use heuristically defined weight sequences for the observed data. The weight sequence, however, is a key aspect of the estimator affecting the tracking performance significantly. In this work, we study the exact mean integrated squared error (MISE) of "sliding window" Gaussian Kernel Density Estimators for evolving Gaussian densities. We provide a principled guide for choosing the optimal weight sequence by theoretically characterizing the exact MISE, which can be formulated as constrained quadratic programming. We present empirical evidence with synthetic datasets to show that our weighting scheme indeed improves the tracking performance compared to heuristic approaches.
    
[^21]: 图神经网络中的不确定性：一项调查

    Uncertainty in Graph Neural Networks: A Survey

    [https://arxiv.org/abs/2403.07185](https://arxiv.org/abs/2403.07185)

    本调查旨在全面概述图神经网络中的不确定性，并提出了关于如何识别、量化和利用不确定性来增强模型性能和 GNN 预测可靠性的观点。

    

    图神经网络（GNNs）已被广泛应用于各种现实世界的应用中。然而，GNNs的预测不确定性源自数据中的固有随机性和模型训练误差等多种因素，可能导致不稳定和错误的预测。因此，识别、量化和利用不确定性对于增强模型性能和GNN预测的可靠性是至关重要的。本调查旨在从不确定性的角度全面概述GNNs，并强调其在图学习中的整合。我们比较和总结了现有的图不确定性理论和方法，以及相应的下游任务。通过这种方式，我们弥合了理论与实践之间的差距，同时连接不同的GNN社区。此外，我们的工作为这一领域的未来方向提供了宝贵的见解。

    arXiv:2403.07185v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have been extensively used in various real-world applications. However, the predictive uncertainty of GNNs stemming from diverse sources such as inherent randomness in data and model training errors can lead to unstable and erroneous predictions. Therefore, identifying, quantifying, and utilizing uncertainty are essential to enhance the performance of the model for the downstream tasks as well as the reliability of the GNN predictions. This survey aims to provide a comprehensive overview of the GNNs from the perspective of uncertainty with an emphasis on its integration in graph learning. We compare and summarize existing graph uncertainty theory and methods, alongside the corresponding downstream tasks. Thereby, we bridge the gap between theory and practice, meanwhile connecting different GNN communities. Moreover, our work provides valuable insights into promising directions in this field.
    
[^22]: 具有随机重排的随机外推法：改进变分不等式的收敛性

    Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities

    [https://arxiv.org/abs/2403.07148](https://arxiv.org/abs/2403.07148)

    该论文针对三类变分不等式问题提出了具有随机重排的随机外推法（SEG-RR），并证明其在单调情况下实现了比均匀替换采样SEG更快的收敛速度。

    

    随机外推法（SEG）方法是解决出现在各种机器学习任务中的有限求和极小-极大优化和变分不等式问题（VIPs）的最流行算法之一。然而，现有的SEG收敛分析专注于其带替换变体，而方法的实际实现会随机重新排列分量并按顺序使用它们。与广为研究的带替换变体不同，具有随机重排的SEG（SEG-RR）缺乏已建立的理论保证。在本工作中，我们针对三类VIPs（i）强单调，（ii）仿射和（iii）单调提供了SEG-RR的收敛性分析。我们推导了SEG-RR实现比均匀带替换采样SEG具有更快收敛速度的条件。在单调设置中，我们的SEG-RR分析保证了收敛到任意精度而无需大批量大小，这是对大批量大小而言的强要求。

    arXiv:2403.07148v1 Announce Type: cross  Abstract: The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in 
    
[^23]: 价值函数的有限表征能力及其与统计(不)效率的关联

    On the Limited Representational Power of Value Functions and its Links to Statistical (In)Efficiency

    [https://arxiv.org/abs/2403.07136](https://arxiv.org/abs/2403.07136)

    研究发现基于值函数的表征能力有限，导致在某些情况下基于值函数的方法在统计上低效率，这揭示了价值函数和统计效率之间的关联。

    

    在强化学习中，识别基于模型和无模型方法之间的权衡是一个核心问题。 基于值的方法提供了重要的计算优势，并且有时在统计上和基于模型的方法一样有效。 然而，当关注策略评估的核心问题时，我们发现关于转移动态的信息可能无法在价值函数空间中表示。 我们通过一系列着重于许多重要问题中出现的结构的案例研究来探究这一点。 在其中几种情况中，没有信息丢失，基于值的方法与基于模型的方法在统计效率上相当。 在其他相关示例中，信息丢失严重，基于值的方法性能严重不及基于模型的方法。 更深入的研究指出了表征能力的限制作为低效性的驱动因素，而非算法设计上的失误。

    arXiv:2403.07136v1 Announce Type: cross  Abstract: Identifying the trade-offs between model-based and model-free methods is a central question in reinforcement learning. Value-based methods offer substantial computational advantages and are sometimes just as statistically efficient as model-based methods. However, focusing on the core problem of policy evaluation, we show information about the transition dynamics may be impossible to represent in the space of value functions. We explore this through a series of case studies focused on structures that arises in many important problems. In several, there is no information loss and value-based methods are as statistically efficient as model based ones. In other closely-related examples, information loss is severe and value-based methods are severely outperformed. A deeper investigation points to the limitations of the representational power as the driver of the inefficiency, as opposed to failure in algorithm design.
    
[^24]: 用于高效同时学习和评估的Cram方法

    The Cram Method for Efficient Simultaneous Learning and Evaluation

    [https://arxiv.org/abs/2403.07031](https://arxiv.org/abs/2403.07031)

    Cram方法是一种同时学习和评估的高效方法，利用整个样本进行训练和测试，比传统的样本分割策略更高效。

    

    我们介绍了“Cram”方法，这是一种通用且高效的方法，使用通用的机器学习（ML）算法进行同时学习和评估。在批处理数据的单次传递中，该方法反复训练ML算法并测试其经验性能。由于它同时利用了整个样本进行学习和评估，所以Cram方法比样本分割要高效得多。Cram方法还自然地适用于在线学习算法，使其实施具有计算效率。为了展示Cram方法的强大之处，我们考虑了标准策略学习设置，其中将Cram应用于相同数据以开发个性化治疗规则（ITR）并估计如果学习的ITR被部署将会产生的平均结果。我们展示了在最小一组假设下，由此产生的Cram评估估计器是一致且渐近的。

    arXiv:2403.07031v1 Announce Type: new  Abstract: We introduce the "cram" method, a general and efficient approach to simultaneous learning and evaluation using a generic machine learning (ML) algorithm. In a single pass of batched data, the proposed method repeatedly trains an ML algorithm and tests its empirical performance. Because it utilizes the entire sample for both learning and evaluation, cramming is significantly more data-efficient than sample-splitting. The cram method also naturally accommodates online learning algorithms, making its implementation computationally efficient. To demonstrate the power of the cram method, we consider the standard policy learning setting where cramming is applied to the same data to both develop an individualized treatment rule (ITR) and estimate the average outcome that would result if the learned ITR were to be deployed. We show that under a minimal set of assumptions, the resulting crammed evaluation estimator is consistent and asymptoticall
    
[^25]: 一些凸消息传递算法收敛到固定点

    Convergence of Some Convex Message Passing Algorithms to a Fixed Point

    [https://arxiv.org/abs/2403.07004](https://arxiv.org/abs/2403.07004)

    这项研究证明了一些凸消息传递算法会收敛到固定点，并在一定迭代次数内达到特定精度。

    

    在图模型中解决MAP推断问题的一种流行方法是通过（块状）坐标下降最小化从对偶线性规划或Lagrange松弛中获得的一个上界。这样的算法包括最大和扩散以及顺序树重新加权消息传递。这些方法的收敛性质目前尚未完全理解。它们已被证明会收敛到由活跃约束的局部一致性所表征的集合，但收敛速度未知；然而，尚不清楚迭代是否会收敛（到任何一个单一点）。我们证明了一个更强的结果（之前有猜想但从未证明过）：迭代会收敛到算法的一个固定点。此外，我们还展示它们在$\mathcal{O}(1/\varepsilon)$次迭代中达到了精度$\varepsilon>0$。

    arXiv:2403.07004v1 Announce Type: new  Abstract: A popular approach to the MAP inference problem in graphical models is to minimize an upper bound obtained from a dual linear programming or Lagrangian relaxation by (block-)coordinate descent. Examples of such algorithms are max-sum diffusion and sequential tree-reweighted message passing. Convergence properties of these methods are currently not fully understood. They have been proved to converge to the set characterized by local consistency of active constraints, with unknown convergence rate; however, it was not clear if the iterates converge at all (to any single point). We prove a stronger result (which was conjectured before but never proved): the iterates converge to a fixed point of the algorithm. Moreover, we show that they achieve precision $\varepsilon>0$ in $\mathcal{O}(1/\varepsilon)$ iterations.   We first prove this for a version of coordinate descent applied to a general piecewise-affine convex objective, using a novel p
    
[^26]: 重新审视随机梯度方法的最终迭代收敛性

    Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods

    [https://arxiv.org/abs/2312.08531](https://arxiv.org/abs/2312.08531)

    研究了随机梯度方法的最终迭代收敛性，并提出了不需要限制性假设的最优收敛速率问题。

    

    在过去几年里，随机梯度下降（SGD）算法的最终迭代收敛引起了人们的兴趣，因为它在实践中表现良好但缺乏理论理解。对于Lipschitz凸函数，不同的研究建立了最佳的$O(\log(1/\delta)\log T/\sqrt{T})$或$O(\sqrt{\log(1/\delta)/T})$最终迭代的高概率收敛速率，其中$T$是时间跨度，$\delta$是失败概率。然而，为了证明这些界限，所有现有的工作要么局限于紧致域，要么需要几乎肯定有界的噪声。很自然地会问，不需要这两个限制性假设的情况下，SGD的最终迭代是否仍然可以保证最佳的收敛速率。除了这个重要问题外，还有很多理论问题仍然没有答案。

    arXiv:2312.08531v2 Announce Type: replace  Abstract: In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal $O(\log(1/\delta)\log T/\sqrt{T})$ or $O(\sqrt{\log(1/\delta)/T})$ high-probability convergence rates for the final iterate, where $T$ is the time horizon and $\delta$ is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smoot
    
[^27]: 量子启蒙分数

    Quantum Inception Score

    [https://arxiv.org/abs/2311.12163](https://arxiv.org/abs/2311.12163)

    通过量子启蒙分数，我们提出了一个用于评估量子生成模型质量的新指标，证明量子生成模型在质量上优于经典生成模型，并利用量子波动定理揭示了其物理限制。

    

    受到经典生成模型在机器学习中取得巨大成功的启发，近期开始了对它们量子版本的热切探索。为了开始这一探索之旅，开发一个相关的度量标准来评估量子生成模型的质量是很重要的；在经典情况下，一个这样的例子便是启蒙分数。在本文中，我们提出了量子启蒙分数，它将质量与用于对给定数据集进行分类的量子通道的Holevo信息联系起来。我们证明，在这个提出的度量标准下，量子生成模型提供比它们的经典对应物更好的质量，因为存在着由不对称性的资源理论和纠缠所表征的量子相干性。此外，我们利用量子波动定理来表征限制量子生成模型质量的物理限制。最后，我们应用量子启蒙分数来

    arXiv:2311.12163v2 Announce Type: replace-cross  Abstract: Motivated by the great success of classical generative models in machine learning, enthusiastic exploration of their quantum version has recently started. To depart on this journey, it is important to develop a relevant metric to evaluate the quality of quantum generative models; in the classical case, one such example is the inception score. In this paper, we propose the quantum inception score, which relates the quality to the Holevo information of the quantum channel that classifies a given dataset. We prove that, under this proposed measure, the quantum generative models provide better quality than their classical counterparts because of the presence of quantum coherence, characterized by the resource theory of asymmetry, and entanglement. Furthermore, we harness the quantum fluctuation theorem to characterize the physical limitation of the quality of quantum generative models. Finally, we apply the quantum inception score 
    
[^28]: 通过低维学习动态实现超参数化深度模型的高效压缩

    Efficient Compression of Overparameterized Deep Models through Low-Dimensional Learning Dynamics

    [https://arxiv.org/abs/2311.05061](https://arxiv.org/abs/2311.05061)

    通过研究深度模型的学习动态，提出了一种压缩超参数化模型的新方法，通过在低维不变子空间内更新权重矩阵来压缩深度线性网络，并在矩阵恢复问题上进行了有效性评估

    

    超参数化模型已被证明是解决各种机器学习任务的强大工具。然而，过度参数化往往导致计算和内存成本大幅增加，进而需要大量资源来训练。在这项工作中，我们提出了一种新颖的方法来压缩超参数化模型，通过研究它们的学习动态来实现。我们观察到对于许多深度模型，权重矩阵的更新发生在低维不变子空间内。对于深度线性模型，我们展示了它们的主要成分在一个小子空间内逐渐适配，并利用这些见解提出了一种针对深度线性网络的压缩算法，其中包括减小其中间层的宽度。我们从实验角度评估了我们的压缩技术在矩阵恢复问题上的有效性。

    arXiv:2311.05061v2 Announce Type: replace  Abstract: Overparameterized models have proven to be powerful tools for solving various machine learning tasks. However, overparameterization often leads to a substantial increase in computational and memory costs, which in turn requires extensive resources to train. In this work, we present a novel approach for compressing overparameterized models, developed through studying their learning dynamics. We observe that for many deep models, updates to the weight matrices occur within a low-dimensional invariant subspace. For deep linear models, we demonstrate that their principal components are fitted incrementally within a small subspace, and use these insights to propose a compression algorithm for deep linear networks that involve decreasing the width of their intermediate layers. We empirically evaluate the effectiveness of our compression technique on matrix recovery problems. Remarkably, by using an initialization that exploits the structur
    
[^29]: TAP: 跨模态知识传递中的注意力补丁

    TAP: The Attention Patch for Cross-Modal Knowledge Transfer from Unlabeled Modality

    [https://arxiv.org/abs/2302.02224](https://arxiv.org/abs/2302.02224)

    通过引入The Attention Patch（TAP）神经网络附加组件，本文提出了一种简单且有效的方法，允许从未标记的次要模态实现跨模态的数据级知识传递。

    

    本文解决了跨模态学习框架，其目标是通过未标记、不配对的次要模态，增强主要模态中监督学习的性能。采用概率方法进行缺失信息估计，我们表明次要模态中包含的额外信息可以通过Nadaraya-Watson（NW）核回归进行估计，其可以进一步表示为经过线性变换的核交叉注意力模块。我们的结果为引入The Attention Patch（TAP）奠定了基础，这是一个简单的神经网络附加组件，允许从未标记的模态进行数据级知识传递。我们使用四个真实世界数据集进行了大量数值模拟，结果表明TAP能够显著提高跨不同领域和不同神经网络架构的泛化能力，利用看似无用的未标记信息。

    arXiv:2302.02224v2 Announce Type: replace  Abstract: This paper addresses a cross-modal learning framework, where the objective is to enhance the performance of supervised learning in the primary modality using an unlabeled, unpaired secondary modality. Taking a probabilistic approach for missing information estimation, we show that the extra information contained in the secondary modality can be estimated via Nadaraya-Watson (NW) kernel regression, which can further be expressed as a kernelized cross-attention module (under linear transformation). Our results lay the foundations for introducing The Attention Patch (TAP), a simple neural network add-on that allows data-level knowledge transfer from the unlabeled modality. We provide extensive numerical simulations using four real-world datasets to show that TAP can provide statistically significant improvement in generalization across different domains and different neural network architectures, making use of seemingly unusable unlabel
    
[^30]: 使用单调变分不等式训练神经网络的另一种方法

    An alternative approach to train neural networks using monotone variational inequality

    [https://arxiv.org/abs/2202.08876](https://arxiv.org/abs/2202.08876)

    通过单调变分不等式，提出了一种高效的神经网络训练方法，可以快速收敛并在特定情况下提供保证。

    

    我们提出了一种使用单调矢量场的替代方法来训练神经网络，这个想法受到Juditsky和Nemirovski的开创性工作的启发，最初是为了解决广义线性模型（GLM）的参数估计问题，通过将原始非凸问题简化为解决单调变分不等式（VI）的凸问题。我们的方法导致了计算效率高且在某些特殊情况下收敛快速并提供了保证，例如训练单层神经网络或微调预训练模型的最后一层。我们的方法可以用于更高效地微调预训练模型的同时冻结底层，这是部署许多机器学习模型（如大型语言模型LLM）的重要步骤。我们证明了它在训练全连接（FC）神经网络、图神经网络方面的适用性。

    arXiv:2202.08876v4 Announce Type: replace-cross  Abstract: We propose an alternative approach to neural network training using the monotone vector field, an idea inspired by the seminal work of Juditsky and Nemirovski [Juditsky & Nemirovsky, 2019] developed originally to solve parameter estimation problems for generalized linear models (GLM) by reducing the original non-convex problem to a convex problem of solving a monotone variational inequality (VI). Our approach leads to computationally efficient procedures that converge fast and offer guarantee in some special cases, such as training a single-layer neural network or fine-tuning the last layer of the pre-trained model. Our approach can be used for more efficient fine-tuning of a pre-trained model while freezing the bottom layers, an essential step for deploying many machine learning models such as large language models (LLM). We demonstrate its applicability in training fully-connected (FC) neural networks, graph neural networks (
    
[^31]: 使用数据进行学习和决策：最优公式与相变

    Learning and Decision-Making with Data: Optimal Formulations and Phase Transitions

    [https://arxiv.org/abs/2109.06911](https://arxiv.org/abs/2109.06911)

    本论文提出了一种新的方法，通过首先定义一个衡量基于数据公式质量的标尺，然后寻找最优公式，使其在保证样本外性能的同时，更加接近真实成本。

    

    我们研究了当只有历史数据可用时设计最优学习和决策公式的问题。之前的工作通常会致力于某一类基于数据的公式，然后试图建立样本外性能保证。我们这里采取了相反的方法。我们首先定义一个合理的标尺来衡量任何基于数据的公式的质量，然后寻求找到一个最优的这样的公式。不正式地说，任何基于数据的公式可以被视为在保证样本外性能水平的同时平衡估计成本与实际成本的接近度的度量。在给定一个可接受的样本外性能水平后，我们显式构造了一个基于数据的公式，该公式在与同样具有样本外性能的其他公式相比是统一更接近真实成本的。我们展示了三种不同的样本外执行

    arXiv:2109.06911v3 Announce Type: replace-cross  Abstract: We study the problem of designing optimal learning and decision-making formulations when only historical data is available. Prior work typically commits to a particular class of data-driven formulation and subsequently tries to establish out-of-sample performance guarantees. We take here the opposite approach. We define first a sensible yard stick with which to measure the quality of any data-driven formulation and subsequently seek to find an optimal such formulation. Informally, any data-driven formulation can be seen to balance a measure of proximity of the estimated cost to the actual cost while guaranteeing a level of out-of-sample performance. Given an acceptable level of out-of-sample performance, we construct explicitly a data-driven formulation that is uniformly closer to the true cost than any other formulation enjoying the same out-of-sample performance. We show the existence of three distinct out-of-sample performan
    
[^32]: 一种用于回归和分类任务的参数空间缩减的本地方法

    A local approach to parameter space reduction for regression and classification tasks

    [https://arxiv.org/abs/2107.10867](https://arxiv.org/abs/2107.10867)

    本文提出一种名为局部主动子空间（LAS）的新方法，通过探索主动子空间与监督聚类技术的结合，实现了更有效的参数空间维度缩减，尤其在高维参数化系统中具有重要意义。

    

    参数空间缩减已被证明是加速许多数值任务执行的关键工具，例如优化、逆问题、敏感性分析和代理模型设计，特别是在存在高维参数化系统时。在这项工作中，我们提出了一种名为局部主动子空间（LAS）的新方法，它探索了主动子空间与监督聚类技术的协同作用，以在参数空间中进行更有效的维度缩减。通过引入由全局主动子空间引起的距离度量，聚类是在不丢失输入输出关系的情况下执行的。我们提出了两种可能的聚类算法：K-medoids和一种自上而下的层次方法，该方法能够施加一系列特别为参数空间缩减任务量身定制的细分准则。这种方法对于从事代理模型设计工作的社区特别有用。

    arXiv:2107.10867v3 Announce Type: replace  Abstract: Parameter space reduction has been proved to be a crucial tool to speed-up the execution of many numerical tasks such as optimization, inverse problems, sensitivity analysis, and surrogate models' design, especially when in presence of high-dimensional parametrized systems. In this work we propose a new method called local active subspaces (LAS), which explores the synergies of active subspaces with supervised clustering techniques in order to carry out a more efficient dimension reduction in the parameter space. The clustering is performed without losing the input-output relations by introducing a distance metric induced by the global active subspace. We present two possible clustering algorithms: K-medoids and a hierarchical top-down approach, which is able to impose a variety of subdivision criteria specifically tailored for parameter space reduction tasks. This method is particularly useful for the community working on surrogate 
    
[^33]: 不断演变的高斯过程引导学习

    Epoch-evolving Gaussian Process Guided Learning

    [https://arxiv.org/abs/2006.14347](https://arxiv.org/abs/2006.14347)

    提出了一种名为GPGL的epoch-evolving Gaussian Process Guided Learning学习方案，通过上下文标签和地面真实标签指导模型参数更新，进一步推广并应用于当前深度模型，在主流数据集上表现显著优于现有基于批次的最先进模型

    

    在这篇论文中，我们提出了一种名为不断演变的高斯过程引导学习（GPGL）的新颖学习方案，旨在描述批级分布与全局数据分布之间的相关信息。这种相关信息被编码为上下文标签，需要每个时期进行更新。在上下文标签和地面真实标签的指导下，GPGL方案通过使用三角一致性损失来更新模型参数，从而提供更高效的优化。此外，我们的GPGL方案可以进一步推广并自然应用于当前的深度模型，在主流数据集（CIFAR-10、CIFAR-100和Tiny-ImageNet）上显著优于现有基于批次的最先进模型。

    arXiv:2006.14347v2 Announce Type: replace  Abstract: In this paper, we propose a novel learning scheme called epoch-evolving Gaussian Process Guided Learning (GPGL), which aims at characterizing the correlation information between the batch-level distribution and the global data distribution. Such correlation information is encoded as context labels and needs renewal every epoch. With the guidance of the context label and ground truth label, GPGL scheme provides a more efficient optimization through updating the model parameters with a triangle consistency loss. Furthermore, our GPGL scheme can be further generalized and naturally applied to the current deep models, outperforming the existing batch-based state-of-the-art models on mainstream datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) remarkably.
    
[^34]: 小阈值间隙下的好臂识别算法: lil'HDoC

    lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap. (arXiv:2401.15879v1 [cs.LG])

    [http://arxiv.org/abs/2401.15879](http://arxiv.org/abs/2401.15879)

    本文提出了一种名为lil'HDoC的算法，用于解决小阈值间隙下的好臂识别问题。实验证明该算法在样本效率上优于现有算法。

    

    好臂识别（GAI）是一个纯探索性的赌博机问题，在这个问题中，一个单独的学习器会在确定一个臂是好臂时立即输出该臂。好臂被定义为期望回报大于等于给定阈值的臂。本文聚焦于小阈值间隙下的GAI问题，该间隙指的是臂的期望回报与给定阈值之间的距离。我们提出了一种名为lil'HDoC的新算法，显著改善了HDoC算法的总样本复杂度。我们证明了在小阈值间隙下，lil'HDoC算法输出的第一个λ臂的样本复杂度与原始HDoC算法相比仅有微小的差异。大量实验证明我们的算法在合成数据集和真实世界数据集上表现优于最先进的算法。

    Good arm identification (GAI) is a pure-exploration bandit problem in which a single learner outputs an arm as soon as it is identified as a good arm. A good arm is defined as an arm with an expected reward greater than or equal to a given threshold. This paper focuses on the GAI problem under a small threshold gap, which refers to the distance between the expected rewards of arms and the given threshold. We propose a new algorithm called lil'HDoC to significantly improve the total sample complexity of the HDoC algorithm. We demonstrate that the sample complexity of the first $\lambda$ output arm in lil'HDoC is bounded by the original HDoC algorithm, except for one negligible term, when the distance between the expected reward and threshold is small. Extensive experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both synthetic and real-world datasets.
    
[^35]: 超越遗憾：贝叶斯优化的几何度量

    Beyond Regrets: Geometric Metrics for Bayesian Optimization. (arXiv:2401.01981v1 [cs.LG])

    [http://arxiv.org/abs/2401.01981](http://arxiv.org/abs/2401.01981)

    本论文提出了四个新的几何度量，可以比较贝叶斯优化算法在考虑查询点和全局最优解的几何特性时的性能。

    

    贝叶斯优化是一种针对黑盒子目标函数的原则性优化策略。它在科学发现和实验设计等各种实际应用中的效果得到了证明。通常，贝叶斯优化的性能是通过基于遗憾的度量来评估的，如瞬时遗憾、简单遗憾和累积遗憾。这些度量仅依赖于函数评估，因此它们不考虑查询点和全局解之间的几何关系，也不考虑查询点本身。值得注意的是，它们不能区分是否成功找到了多个全局解。此外，它们也不能评估贝叶斯优化在给定搜索空间中利用和探索的能力。为了解决这些问题，我们提出了四个新的几何度量，即精确度、召回率、平均度和平均距离。这些度量使我们能够比较考虑查询点和全局最优解的几何特性的贝叶斯优化算法。

    Bayesian optimization is a principled optimization strategy for a black-box objective function. It shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. In general, the performance of Bayesian optimization is assessed by regret-based metrics such as instantaneous, simple, and cumulative regrets. These metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. Notably, they cannot discriminate if multiple global solutions are successfully found. Moreover, they do not evaluate Bayesian optimization's abilities to exploit and explore a search space given. To tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. These metrics allow us to compare Bayesian optimization algorithms considering the geometry of both query points and global optima, or que
    
[^36]: 利用可区分插入/删除指标感知正则化进行解释性训练

    Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])

    [http://arxiv.org/abs/2310.12553](http://arxiv.org/abs/2310.12553)

    提出一种插入/删除指标感知的基于解释的优化(ID-ExpO)方法，通过优化可区分的预测器来提高解释的插入和删除得分，并保持预测准确性。实验结果表明，ID-ExpO能够使流行的事后解释器产生更忠实的解释。

    

    复杂机器学习预测器的解释质量通常使用插入和删除指标进行衡量，这些指标评估解释的忠实度，即解释正确地反映了预测器的行为程度。为了提高忠实度，我们提出了插入/删除指标感知的基于解释的优化（ID-ExpO），该优化能够改善解释的插入和删除得分，同时保持其预测准确性。由于原始的插入和删除指标对于解释来说是不可区分的，并且无法直接进行基于梯度的优化，我们扩展了这些指标以使其可区分，并将其用于形式化插入和删除指标的正则化。在图像和表格数据集上的实验结果表明，使用ID-ExpO进行微调的基于深度神经网络的预测器能够使流行的事后解释器产生更忠实的解释。

    The quality of explanations for the predictions of complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how correctly the explanations reflect the predictor's behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both insertion and deletion scores of the explanations while keeping their predictive accuracy. Since the original insertion and deletion metrics are indifferentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics to be differentiable and use them to formalize insertion and deletion metric-based regularizers. The experimental results on image and tabular datasets show that the deep neural networks-based predictors fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful
    
[^37]: 动态预测使用时变Cox生存神经网络

    Dynamic Prediction using Time-Dependent Cox Survival Neural Network. (arXiv:2307.05881v1 [stat.ML])

    [http://arxiv.org/abs/2307.05881](http://arxiv.org/abs/2307.05881)

    该论文通过使用time-dependent Cox模型和神经网络，提出了一种动态预测模型来预测进行性眼部疾病年龄相关性黄斑变性（AMD）的进展。通过使用纵向眼底图像作为输入，该模型可以建立一个个体化的风险预测模型，并且在实证研究中表现出良好的效果。

    

    动态预测的目标是在不断更新的新数据可用时提供个体化的风险预测。受到建立一个针对进行性眼部疾病，年龄相关性黄斑变性（AMD），我们提出了一种基于时变Cox模型的生存神经网络（tdCoxSNN）来预测其在持续时间尺度上的进展，使用纵向眼底图像。tdCoxSNN通过利用神经网络来模拟时变协变量对生存结果的非线性影响扩展了时变Cox模型。此外，通过结合卷积神经网络（CNN），tdCoxSNN可以以纵向原始图像作为输入。我们通过全面的模拟，使用两个时变精度度量标准，Brier分数和动态AUC比较和评估我们提出的方法与联合建模和里程碑方法。我们将所提出的方法应用于两个真实数据集。一个是一个大型AMD数据集。

    The target of dynamic prediction is to provide individualized risk predictions over time which can be updated as new data become available. Motivated by establishing a dynamic prediction model for the progressive eye disease, age-related macular degeneration (AMD), we proposed a time-dependent Cox model-based survival neural network (tdCoxSNN) to predict its progression on a continuous time scale using longitudinal fundus images. tdCoxSNN extends the time-dependent Cox model by utilizing a neural network to model the non-linear effect of the time-dependent covariates on the survival outcome. Additionally, by incorporating the convolutional neural network (CNN), tdCoxSNN can take the longitudinal raw images as input. We evaluate and compare our proposed method with joint modeling and landmarking approaches through comprehensive simulations using two time-dependent accuracy metrics, the Brier Score and dynamic AUC. We applied the proposed approach to two real datasets. One is a large AMD
    
[^38]: 将不确定性意识整合到 Conformalized Quantile Regression 中

    Integrating Uncertainty Awareness into Conformalized Quantile Regression. (arXiv:2306.08693v1 [stat.ME])

    [http://arxiv.org/abs/2306.08693](http://arxiv.org/abs/2306.08693)

    新提出的方法 UACQR 将条件分位估计和整合推断结合，以区分随机不确定性和认识性不确定性，并相应地构造预测区间，可以在量子回归器在特征空间的不同子集上优于现有的 CQR 方法。

    

    Conformalized Quantile Regression (CQR) 是一种最近提出的方法，用于在不做分布假设的情况下构建给定协变量 X 的响应 Y 的预测区间。现有的 CQR 构造方法在量子回归器在特征空间的某些部分表现更好的问题上可能无效。其原因在于 CQR 的预测区间不区分两种不确定性形式：第一种是给定 X 的条件分布的变异性（即，随机不确定性），第二种是我们估计这种条件分布的不确定性（即，认识性不确定性）。这可能导致不均匀的覆盖范围，在认识性不确定性低（或高）的区域中过度宽（或过度窄）的区间。为了解决这个问题，我们提出了 Conformalized Quantile Regression 的新变体，即 Uncertainty-Aware CQR (UACQR)，该方法明确地分离这两种不确定性来源，并相应地构造预测区间。UACQR 方法使用整合推断来量化估计给定 X 的 Y 的条件分布的不确定性，同时还将有界的条件分位估计并入其中，以捕捉该分布的变异性。我们的实验结果表明，UACQR 在量子回归器在特征空间的子集上表现不同的设置中可以优于现有的 CQR 方法。

    Conformalized Quantile Regression (CQR) is a recently proposed method for constructing prediction intervals for a response $Y$ given covariates $X$, without making distributional assumptions. However, as we demonstrate empirically, existing constructions of CQR can be ineffective for problems where the quantile regressors perform better in certain parts of the feature space than others. The reason is that the prediction intervals of CQR do not distinguish between two forms of uncertainty: first, the variability of the conditional distribution of $Y$ given $X$ (i.e., aleatoric uncertainty), and second, our uncertainty in estimating this conditional distribution (i.e., epistemic uncertainty). This can lead to uneven coverage, with intervals that are overly wide (or overly narrow) in regions where epistemic uncertainty is low (or high). To address this, we propose a new variant of the CQR methodology, Uncertainty-Aware CQR (UACQR), that explicitly separates these two sources of uncertaint
    
[^39]: 使用Wasserstein距离对密度地图进行对齐

    Alignment of Density Maps in Wasserstein Distance. (arXiv:2305.12310v1 [eess.IV])

    [http://arxiv.org/abs/2305.12310](http://arxiv.org/abs/2305.12310)

    本文提出了一种使用Wasserstein距离对三维物体进行对齐的算法，并通过贝叶斯优化实现计算。在对齐真实蛋白质分子方面，该算法表现出更好的准确性和效率，并阐明了对新距离函数的需求。

    

    本文提出一种算法，用于将三维物体表示为密度地图并进行对齐，该算法的动机是在冷冻电子显微镜中的应用。该算法基于在刚性变换后密度地图之间最小化1-Wasserstein距离。引入的损失函数比欧几里得距离场具有更好的特性，并使用贝叶斯优化进行计算。数值实验表明，在真实蛋白质分子的对齐方面，该算法的准确性和效率优于现有算法。在对齐异质对的情况下，我们阐明了新距离函数的潜在需求。

    In this paper we propose an algorithm for aligning three-dimensional objects when represented as density maps, motivated by applications in cryogenic electron microscopy. The algorithm is based on minimizing the 1-Wasserstein distance between the density maps after a rigid transformation. The induced loss function enjoys a more benign landscape than its Euclidean counterpart and Bayesian optimization is employed for computation. Numerical experiments show improved accuracy and efficiency over existing algorithms on the alignment of real protein molecules. In the context of aligning heterogeneous pairs, we illustrate a potential need for new distance functions.
    
[^40]: 合成数据生成的效用理论

    Utility Theory of Synthetic Data Generation. (arXiv:2305.10015v1 [stat.ML])

    [http://arxiv.org/abs/2305.10015](http://arxiv.org/abs/2305.10015)

    本文从统计学角度建立效用理论，旨在基于一般性指标定量评估合成算法的效用，效用指标的分析界限揭示了指标收敛的关键条件，令人惊讶的是，只要下游学习任务中的模型规范是正确的，合成特征分布不一定与原始特征分布相同，效用指标会收敛。

    

    评估合成数据的效用对于衡量合成算法的有效性和效率至关重要。现有的结果侧重于对合成数据效用的经验评估，而针对合成数据算法如何影响效用的理论理解仍然未被充分探索。本文从统计学角度建立效用理论，旨在基于一般性指标定量评估合成算法的效用。该指标定义为在合成和原始数据集上训练的模型之间泛化的绝对差异。我们建立了该效用指标的分析界限来研究指标收敛的关键条件。一个有趣的结果是，只要下游学习任务中的模型规范是正确的，合成特征分布不一定与原始特征分布相同，则该效用指标会收敛。另一个重要的效用指标基于合成和原始数据之间潜在的因果机制一致性。该理论使用几种合成算法进行说明，并分析了它们的效用属性。

    Evaluating the utility of synthetic data is critical for measuring the effectiveness and efficiency of synthetic algorithms. Existing results focus on empirical evaluations of the utility of synthetic data, whereas the theoretical understanding of how utility is affected by synthetic data algorithms remains largely unexplored. This paper establishes utility theory from a statistical perspective, aiming to quantitatively assess the utility of synthetic algorithms based on a general metric. The metric is defined as the absolute difference in generalization between models trained on synthetic and original datasets. We establish analytical bounds for this utility metric to investigate critical conditions for the metric to converge. An intriguing result is that the synthetic feature distribution is not necessarily identical to the original one for the convergence of the utility metric as long as the model specification in downstream learning tasks is correct. Another important utility metri
    
[^41]: 一种基于可解释神经网络的连续回应有序回归非比例赔率模型

    An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response. (arXiv:2303.17823v1 [stat.ME])

    [http://arxiv.org/abs/2303.17823](http://arxiv.org/abs/2303.17823)

    本文提出了一种基于可解释神经网络的非比例赔率模型 (N$^3$POM) 用于有序回归，可以对连续变量进行预测，同时保留了可解释性，具有灵活性。

    

    本文提出了一种基于可解释神经网络的非比例赔率模型（N$^3$POM) 用于有序回归，其中反应变量不仅可以取离散值，也可以取连续值，而回归系数根据预测顺序反应也不同。与传统方法直接从离散反应估计线性系数不同，我们训练了一个非线性的神经网络，通过以反应为输入产生线性系数。由于神经网络的优势，N$^3$POM可以在保留传统有序回归的可解释性的同时具有灵活性。我们给出了充分的条件，使得在指定的用户区域内，预测的条件累积概率（CCP）满足局部单调性约束。我们还提供了一种保持单调性的随机（MPS）算法来充分训练神经网络。

    This paper proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression, where the response variable can take not only discrete but also continuous values, and the regression coefficients vary depending on the predicting ordinal response. In contrast to conventional approaches estimating the linear coefficients of regression directly from the discrete response, we train a non-linear neural network that outputs the linear coefficients by taking the response as its input. By virtue of the neural network, N$^3$POM may have flexibility while preserving the interpretability of the conventional ordinal regression. We show a sufficient condition so that the predicted conditional cumulative probability~(CCP) satisfies the monotonicity constraint locally over a user-specified region in the covariate space; we also provide a monotonicity-preserving stochastic (MPS) algorithm for training the neural network adequately.
    

