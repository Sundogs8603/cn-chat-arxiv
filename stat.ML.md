# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective.](http://arxiv.org/abs/2401.14343) | 本研究提出了一种名称为CAP的方法，通过生成类别特定的学习策略来更好地适应异质性数据，并在损失函数设计和标签不平衡问题方面取得了显著改进。 |
| [^2] | [Estimation of partially known Gaussian graphical models with score-based structural priors.](http://arxiv.org/abs/2401.14340) | 本论文提出了一种基于得分结构先验的算法，用于估计部分已知高斯图模型。通过使用图神经网络来估计图的得分函数，我们可以在生成样本时利用退火朗格维能扩散，从而更准确地估计后验分布。数值实验表明，我们的方法具有明显的优势。 |
| [^3] | [Information Leakage Detection through Approximate Bayes-optimal Prediction.](http://arxiv.org/abs/2401.14283) | 本论文通过建立一个理论框架，利用统计学习理论和信息论来准确量化和检测信息泄漏，通过近似贝叶斯预测的对数损失和准确性来准确估计互信息。 |
| [^4] | [At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition.](http://arxiv.org/abs/2401.14210) | 该论文通过使用深度学习和极值理论驱动的模型，开发了一个统一的方法来估计滑坡灾害。这种方法将滑坡位置的空间信息、威胁程度和频率结合起来，填补了目前在处理大范围地区时仅考虑两个元素的不足之处。 |
| [^5] | [Adapting tree-based multiple imputation methods for multi-level data? A simulation study.](http://arxiv.org/abs/2401.14161) | 该研究通过模拟实验比较了传统的多重插补与基于树的方法在多层数据上的性能，发现MICE在准确的拒绝率方面优于其他方法，而极限梯度提升在减少偏差方面表现较好。 |
| [^6] | [Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations.](http://arxiv.org/abs/2401.14142) | 基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。 |
| [^7] | [A New Paradigm for Counterfactual Reasoning in Fairness and Recourse.](http://arxiv.org/abs/2401.13935) | 本研究探索了一种新的反事实推理范式，基于回溯反事实，通过回溯已有路径，而不是想象在法律保护特征上进行的可干预的假设干预。 |
| [^8] | [Reinforcement Learning with Hidden Markov Models for Discovering Decision-Making Dynamics.](http://arxiv.org/abs/2401.13929) | 本论文针对重性抑郁障碍(MDD)中的奖励处理异常，使用强化学习模型和隐马尔可夫模型结合，探索决策制定过程中的学习策略动态对个体奖励学习能力的影响。 |
| [^9] | [Spectral Clustering for Discrete Distributions.](http://arxiv.org/abs/2401.13913) | 本文提出了一种基于谱聚类和分布相似度度量的框架来解决离散分布聚类问题。通过使用线性最优传输构建相似度矩阵，我们在聚类准确性和计算效率方面取得了显著的改进。 |
| [^10] | [Constant Stepsize Q-learning: Distributional Convergence, Bias and Extrapolation.](http://arxiv.org/abs/2401.13884) | 本文研究了常数步长异步Q-learning算法，并通过分析其与马尔可夫链的关联，展示了其迭代在分布上的收敛性和指数收敛速度。同时，研究者还建立了该算法迭代的中心极限定理，并对其渐近偏差进行了精确的展开。通过这些分析，我们可以深入理解这种算法的优化效果和偏差特性。 |
| [^11] | [Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?.](http://arxiv.org/abs/2401.13875) | 本文研究了温度对Softmax高斯混合专家的采样效率的影响，证明了由于温度和其他模型参数之间的相互作用，参数估计的收敛速度较慢，并且可能很慢。 |
| [^12] | [A V2X-based Privacy Preserving Federated Measuring and Learning System.](http://arxiv.org/abs/2401.13848) | 本文介绍了一种基于V2X的隐私保护联合测量和学习系统，通过V2V通信向其他车辆提供实时数据，同时通过V2N链路上的FL方案创建交通网络的预测模型。 |
| [^13] | [A Systematic Approach to Robustness Modelling for Deep Convolutional Neural Networks.](http://arxiv.org/abs/2401.13751) | 本论文提出一种系统化方法，用于针对深度卷积神经网络进行鲁棒性建模。研究发现隐藏层数量对模型的推广性能有影响，同时还测试了模型大小、浮点精度、训练数据和模型输出的噪声水平等参数。为了改进模型的预测能力和计算成本，提出了一种使用诱发故障来建模故障概率的方法。 |
| [^14] | [Conformal Prediction Sets Improve Human Decision Making.](http://arxiv.org/abs/2401.13744) | 该研究表明，通过规范预测量化模型的不确定性，可以提高人类决策的准确性和效果，对人机协同决策具有实用价值。 |
| [^15] | [Accelerating hyperbolic t-SNE.](http://arxiv.org/abs/2401.13708) | 本文提出了加速双曲线t-SNE算法，通过引入极坐标四叉树的加速结构，解决了现有方法在处理大规模输入数据时的效率问题。 |
| [^16] | [The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness.](http://arxiv.org/abs/2401.12236) | 这项研究证明了即使机器学习模型在训练过程中对噪声数据拟合得很好，对敌对示例具有鲁棒性，但当面临敌对操纵的数据时，过度拟合的模型可能会给系统带来意外的危害。 |
| [^17] | [On the Nystrom Approximation for Preconditioning in Kernel Machines.](http://arxiv.org/abs/2312.03311) | 本文分析了核机器预处理中使用Nystrom逼近的权衡。研究表明，使用对数大小的样本能够让Nystrom逼近的预处理器几乎与梯度下降同样有效地加速。 |
| [^18] | [A powerful rank-based correction to multiple testing under positive dependency.](http://arxiv.org/abs/2311.10900) | 我们提出了一种基于秩的多重检验修正方法，能够有效利用正相关的统计假设检验之间的依赖关系，并在存在正相关依赖情况下优于Bonferroni修正。我们的方法尤其适用于并行置换检验，在保证FWER控制的同时保持高统计功效。 |
| [^19] | [Online Infinite-Dimensional Regression: Learning Linear Operators.](http://arxiv.org/abs/2309.06548) | 在这篇论文中，我们研究了在线设置下学习无限维线性算子的问题。我们证明了在一定的条件下，线性算子是可以在线学习的，而在另一些条件下则不可以。我们还证明了在线均一收敛和学习能力之间的分离，并在PAC设置下得到了相同的结果。 |
| [^20] | [Adversarial Resilience in Sequential Prediction via Abstention.](http://arxiv.org/abs/2306.13119) | 本文提出了一种处理顺序预测的模型，允许在不对对抗性样例进行预测的情况下提高算法抗对抗攻击的能力。 |
| [^21] | [Lipschitz-bounded 1D convolutional neural networks using the Cayley transform and the controllability Gramian.](http://arxiv.org/abs/2303.11835) | 本文提出了一个逐层参数化方法，用于实现内置鲁棒性保证的1D卷积神经网络。该方法基于CNN特征的Lipschitz常数作为鲁棒性度量，并使用Cayley变换和可控性Gram矩来实现CNN的Lipschitz连续性和无约束训练，最后在心律失常数据分类任务中取得了改进的鲁棒性。 |
| [^22] | [Correlation Clustering with Active Learning of Pairwise Similarities.](http://arxiv.org/abs/2302.10295) | 本文研究了相关聚类中成对相似性不事先给出的情况，并开发了一个通用的主动学习框架，适应各种相关聚类算法和查询策略，同时具有适应性灵活、噪声鲁棒性等优势。 |
| [^23] | [When Can We Track Significant Preference Shifts in Dueling Bandits?.](http://arxiv.org/abs/2302.06595) | 这个论文研究了具有分布转变的决斗对抗问题，并探讨了设计自适应算法以解决动态遗憾的问题，结果发现取决于底层偏好分布的属性。达到$O(\sqrt{K\tilde{L}T})$的动态遗憾是不可能的；对于$\text{SST} \cap \text{STI}$情况，存在一种算法实现动态遗憾为$O(\sqrt{K\tilde{L}T})$。 |
| [^24] | [RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion.](http://arxiv.org/abs/2302.01757) | 本文提出了一种适应于离散序列分类器的随机删除（RS-Del）平滑机制，提供针对编辑距离受限对抗性的鲁棒性证明。 |
| [^25] | [Transfer Learning for Contextual Multi-armed Bandits.](http://arxiv.org/abs/2211.12612) | 本文研究了上下文多臂赌博机问题中的转移学习，提出了一种新的算法来最小化遗憾，并量化了源领域数据对目标领域学习的贡献。 |
| [^26] | [Bridging Distributional and Risk-sensitive Reinforcement Learning with Provable Regret Bounds.](http://arxiv.org/abs/2210.14051) | 本论文证明了使用分布式强化学习方法可以实现风险敏感强化学习的遗憾保证问题，并提出了两种新颖算法，其遗憾上界与先前方法相匹配。 |
| [^27] | [MCCE: Monte Carlo sampling of realistic counterfactual explanations.](http://arxiv.org/abs/2111.09790) | MCCE是一个新颖的反事实解释方法，通过模拟可变特征和决策的联合分布，生成处于流形上、可行并且有效的反事实。与其他方法相比，MCCE可以处理任何类型的预测模型和具有多个级别的分类特征。 |
| [^28] | [Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems.](http://arxiv.org/abs/2108.00473) | 本文提出针对非凸-凹极小极大问题的无导数交替投影算法，包括光滑问题的交替随机梯度投影算法（ZO-AGP），以及块状非光滑问题的分块交替随机近端梯度算法（ZO-BAPG）。这些算法具有较少的函数值估计和较高的迭代复杂度。 |
| [^29] | [Rates of convergence for density estimation with generative adversarial networks.](http://arxiv.org/abs/2102.00199) | 本文针对基本生成对抗网络（GANs）进行了详细研究，证明了在非参数密度估计应用中，GAN估计与真实密度之间的JS散度收敛速度达到了极小极限最优速率。 |

# 详细

[^1]: 类属性先验：将优化方法应用于异质性和公平目标

    Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective. (arXiv:2401.14343v1 [cs.LG])

    [http://arxiv.org/abs/2401.14343](http://arxiv.org/abs/2401.14343)

    本研究提出了一种名称为CAP的方法，通过生成类别特定的学习策略来更好地适应异质性数据，并在损失函数设计和标签不平衡问题方面取得了显著改进。

    

    现代分类问题在各个类别之间存在异质性：每个类别可能具有独特的属性，例如样本大小，标签质量或可预测性（易 vs 难），以及在测试时的变量重要性。如果不注意处理，这些异质性会阻碍学习过程，尤其是在优化公平目标时。在高斯混合模型设定下，我们证明了为了达到平衡准确度，最优的支持向量机分类器需要适应类别属性。这激发了我们提出了CAP：一种基于类别属性生成类别特定学习策略（例如超参数）的有效和通用方法。通过这种方式，优化过程更好地适应异质性。CAP相比于将不同的超参数分配给每个类别的朴素方法有显著改进。我们将CAP实例化为损失函数设计和事后对数调整，重点关注标签不平衡问题。

    Modern classification problems exhibit heterogeneities across individual classes: Each class may have unique attributes, such as sample size, label quality, or predictability (easy vs difficult), and variable importance at test-time. Without care, these heterogeneities impede the learning process, most notably, when optimizing fairness objectives. Confirming this, under a gaussian mixture setting, we show that the optimal SVM classifier for balanced accuracy needs to be adaptive to the class attributes. This motivates us to propose CAP: An effective and general method that generates a class-specific learning strategy (e.g. hyperparameter) based on the attributes of that class. This way, optimization process better adapts to heterogeneities. CAP leads to substantial improvements over the naive approach of assigning separate hyperparameters to each class. We instantiate CAP for loss function design and post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show that CA
    
[^2]: 基于得分结构先验的部分已知高斯图模型估计

    Estimation of partially known Gaussian graphical models with score-based structural priors. (arXiv:2401.14340v1 [stat.ML])

    [http://arxiv.org/abs/2401.14340](http://arxiv.org/abs/2401.14340)

    本论文提出了一种基于得分结构先验的算法，用于估计部分已知高斯图模型。通过使用图神经网络来估计图的得分函数，我们可以在生成样本时利用退火朗格维能扩散，从而更准确地估计后验分布。数值实验表明，我们的方法具有明显的优势。

    

    我们提出了一种新的算法，用于支持估计部分已知的高斯图模型，并且结合了关于底层图的先验信息。与传统方法相比，传统方法使用点估计方法基于最大似然或最大后验准则，并使用（简单的）精度矩阵先验来提供点估计。我们考虑对图进行先验，并依赖退火朗格维能扩散从后验分布中生成样本。由于朗格维能采样器需要访问底层图先验的得分函数，因此我们使用图神经网络来有效地从图数据集（事先可用或从已知分布生成）估计得分。数值实验证明了我们方法的优势。

    We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or a maximum a posteriori criterion using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments demonstrate the benefits of our approach.
    
[^3]: 通过近似贝叶斯最优预测检测信息泄漏

    Information Leakage Detection through Approximate Bayes-optimal Prediction. (arXiv:2401.14283v1 [stat.ML])

    [http://arxiv.org/abs/2401.14283](http://arxiv.org/abs/2401.14283)

    本论文通过建立一个理论框架，利用统计学习理论和信息论来准确量化和检测信息泄漏，通过近似贝叶斯预测的对数损失和准确性来准确估计互信息。

    

    在今天的以数据驱动的世界中，公开可获得的信息的增加加剧了信息泄漏（IL）的挑战，引发了安全问题。IL涉及通过系统的可观察信息无意地将秘密（敏感）信息暴露给未经授权的方，传统的统计方法通过估计可观察信息和秘密信息之间的互信息（MI）来检测IL，面临维度灾难、收敛、计算复杂度和MI估计错误等挑战。此外，虽然新兴的监督机器学习（ML）方法在二进制系统敏感信息的检测上有效，但缺乏一个全面的理论框架。为了解决这些限制，我们使用统计学习理论和信息论建立了一个理论框架来准确量化和检测IL。我们证明了可以通过近似贝叶斯预测的对数损失和准确性来准确估计MI。

    In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predict
    
[^4]: 在深度学习与极值统计之间：对滑坡灾害定义的形式化

    At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition. (arXiv:2401.14210v1 [cs.LG])

    [http://arxiv.org/abs/2401.14210](http://arxiv.org/abs/2401.14210)

    该论文通过使用深度学习和极值理论驱动的模型，开发了一个统一的方法来估计滑坡灾害。这种方法将滑坡位置的空间信息、威胁程度和频率结合起来，填补了目前在处理大范围地区时仅考虑两个元素的不足之处。

    

    滑坡灾害的最常用定义结合了滑坡位置的空间信息（易发性）、威胁程度（强度）和频率（重现期）。在处理大范围地区时，通常只考虑和估计前两个元素。即便如此，分离的模型仍是标准，对频率的研究很少。频率和强度相互交织并相互依赖，因为更大规模的事件发生的频率较低，反之亦然。然而，由于缺乏多时期清单和联合统计模型，通过统一的灾害模型对这些属性进行建模一直是具有挑战性的，尚未尝试过。在这里，我们开发了一个统一模型，以单元坡度水平估计滑坡灾害，以解决这些差距。我们采用深度学习结合极值理论驱动的模型，分析了尼泊尔30年土壤降雨引发滑坡的清单，并评估了多个地区的滑坡灾害。

    The most adopted definition of landslide hazard combines spatial information about landslide location (susceptibility), threat (intensity), and frequency (return period). Only the first two elements are usually considered and estimated when working over vast areas. Even then, separate models constitute the standard, with frequency being rarely investigated. Frequency and intensity are intertwined and depend on each other because larger events occur less frequently and vice versa. However, due to the lack of multi-temporal inventories and joint statistical models, modelling such properties via a unified hazard model has always been challenging and has yet to be attempted. Here, we develop a unified model to estimate landslide hazard at the slope unit level to address such gaps. We employed deep learning, combined with a model motivated by extreme-value theory to analyse an inventory of 30 years of observed rainfall-triggered landslides in Nepal and assess landslide hazard for multiple r
    
[^5]: 适应多层数据的基于树的多重插补方法的研究

    Adapting tree-based multiple imputation methods for multi-level data? A simulation study. (arXiv:2401.14161v1 [stat.AP])

    [http://arxiv.org/abs/2401.14161](http://arxiv.org/abs/2401.14161)

    该研究通过模拟实验比较了传统的多重插补与基于树的方法在多层数据上的性能，发现MICE在准确的拒绝率方面优于其他方法，而极限梯度提升在减少偏差方面表现较好。

    

    本模拟研究评估了针对多层数据的多重插补(MI)技术的有效性。它比较了传统的以链式方程为基础的多重插补(MICE)与基于树的方法（如链式随机森林与预测均值匹配和极限梯度提升）的性能。还对基于树的方法包括了包括集群成员的虚拟变量的改进版本进行了评估。该研究使用具有不同集群大小(25和50)和不完整程度(10\%和50\%)的模拟分层数据对系数估计偏差、统计功效和类型I错误率进行评估。系数是使用随机截距和随机斜率模型进行估计的。结果表明，虽然MICE更适合准确的拒绝率，但极限梯度提升有助于减少偏差。此外，研究发现，不同集群大小的偏差水平相似，但拒绝率在少数缺失情况下较不理想。

    This simulation study evaluates the effectiveness of multiple imputation (MI) techniques for multilevel data. It compares the performance of traditional Multiple Imputation by Chained Equations (MICE) with tree-based methods such as Chained Random Forests with Predictive Mean Matching and Extreme Gradient Boosting. Adapted versions that include dummy variables for cluster membership are also included for the tree-based methods. Methods are evaluated for coefficient estimation bias, statistical power, and type I error rates on simulated hierarchical data with different cluster sizes (25 and 50) and levels of missingness (10\% and 50\%). Coefficients are estimated using random intercept and random slope models. The results show that while MICE is preferred for accurate rejection rates, Extreme Gradient Boosting is advantageous for reducing bias. Furthermore, the study finds that bias levels are similar across different cluster sizes, but rejection rates tend to be less favorable with few
    
[^6]: 基于能量的概念瓶颈模型：统一预测、概念干预和条件解释

    Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations. (arXiv:2401.14142v1 [cs.CV])

    [http://arxiv.org/abs/2401.14142](http://arxiv.org/abs/2401.14142)

    基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。

    

    现有方法，如概念瓶颈模型 (CBM)，在为黑盒深度学习模型提供基于概念的解释方面取得了成功。它们通常通过在给定输入的情况下预测概念，然后在给定预测的概念的情况下预测最终的类别标签。然而，它们经常无法捕捉到概念之间的高阶非线性相互作用，例如纠正一个预测的概念（例如“黄色胸部”）无法帮助纠正高度相关的概念（例如“黄色腹部”），导致最终准确率不理想；它们无法自然地量化不同概念和类别标签之间的复杂条件依赖关系（例如对于一个带有类别标签“Kentucky Warbler”和概念“黑色嘴巴”的图像，模型能够正确预测另一个概念“黑色冠”的概率是多少），因此无法提供关于黑盒模型工作原理更深层次的洞察。针对这些限制，我们提出了基于能量的概念瓶颈模型（Energy-based Concept Bottleneck Models）。

    Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final class label given the predicted concepts. However, (1) they often fail to capture the high-order, nonlinear interaction between concepts, e.g., correcting a predicted concept (e.g., "yellow breast") does not help correct highly correlated concepts (e.g., "yellow belly"), leading to suboptimal final accuracy; (2) they cannot naturally quantify the complex conditional dependencies between different concepts and class labels (e.g., for an image with the class label "Kentucky Warbler" and a concept "black bill", what is the probability that the model correctly predicts another concept "black crown"), therefore failing to provide deeper insight into how a black-box model works. In response to these limitations, we propose Energy-based Concept Bot
    
[^7]: 公平性和救济中反事实推理的新范式

    A New Paradigm for Counterfactual Reasoning in Fairness and Recourse. (arXiv:2401.13935v1 [cs.AI])

    [http://arxiv.org/abs/2401.13935](http://arxiv.org/abs/2401.13935)

    本研究探索了一种新的反事实推理范式，基于回溯反事实，通过回溯已有路径，而不是想象在法律保护特征上进行的可干预的假设干预。

    

    反事实和反事实推理是审计和理解人工智能系统的许多技术的基础。在这一领域中，反事实推理的传统范式是干预反事实，即想象和模拟假设性干预。因此，关于人工智能中的法律保护和人口统计数据的因果推理的出发点是对法律保护特征（如种族、性别、残疾、年龄等）进行假设干预。我们问的问题是，如果你的种族不同，会发生什么情况？这个范式的一个固有限制是，一些人口统计干预（比如种族干预）可能无法转化为干预反事实的形式主义。在这项研究中，我们探索了一种基于回溯反事实的新范式，与想象在法律保护特征上进行的假设干预不同，我们想象可以沿着已有的路径进行回溯的反事实。

    Counterfactuals and counterfactual reasoning underpin numerous techniques for auditing and understanding artificial intelligence (AI) systems. The traditional paradigm for counterfactual reasoning in this literature is the interventional counterfactual, where hypothetical interventions are imagined and simulated. For this reason, the starting point for causal reasoning about legal protections and demographic data in AI is an imagined intervention on a legally-protected characteristic, such as ethnicity, race, gender, disability, age, etc. We ask, for example, what would have happened had your race been different? An inherent limitation of this paradigm is that some demographic interventions -- like interventions on race -- may not translate into the formalisms of interventional counterfactuals. In this work, we explore a new paradigm based instead on the backtracking counterfactual, where rather than imagine hypothetical interventions on legally-protected characteristics, we imagine al
    
[^8]: 使用隐马尔可夫模型的强化学习来发现决策动态

    Reinforcement Learning with Hidden Markov Models for Discovering Decision-Making Dynamics. (arXiv:2401.13929v1 [cs.LG])

    [http://arxiv.org/abs/2401.13929](http://arxiv.org/abs/2401.13929)

    本论文针对重性抑郁障碍(MDD)中的奖励处理异常，使用强化学习模型和隐马尔可夫模型结合，探索决策制定过程中的学习策略动态对个体奖励学习能力的影响。

    

    由于其复杂和异质性，重性抑郁障碍(MDD)在诊断和治疗方面存在挑战。新的证据表明奖励处理异常可能作为MDD的行为标记。为了衡量奖励处理，患者执行涉及做出选择或对与不同结果相关联的刺激作出反应的基于计算机的行为任务。强化学习(RL)模型被拟合以提取衡量奖励处理各个方面的参数，以表征患者在行为任务中的决策方式。最近的研究发现，仅基于单个RL模型的奖励学习表征不足; 相反，决策过程中可能存在多种策略之间的切换。一个重要的科学问题是决策制定中学习策略的动态如何影响MDD患者的奖励学习能力。由概率奖励任务(PRT)所启发

    Major depressive disorder (MDD) presents challenges in diagnosis and treatment due to its complex and heterogeneous nature. Emerging evidence indicates that reward processing abnormalities may serve as a behavioral marker for MDD. To measure reward processing, patients perform computer-based behavioral tasks that involve making choices or responding to stimulants that are associated with different outcomes. Reinforcement learning (RL) models are fitted to extract parameters that measure various aspects of reward processing to characterize how patients make decisions in behavioral tasks. Recent findings suggest the inadequacy of characterizing reward learning solely based on a single RL model; instead, there may be a switching of decision-making processes between multiple strategies. An important scientific question is how the dynamics of learning strategies in decision-making affect the reward learning ability of individuals with MDD. Motivated by the probabilistic reward task (PRT) wi
    
[^9]: 离散分布的谱聚类

    Spectral Clustering for Discrete Distributions. (arXiv:2401.13913v1 [cs.LG])

    [http://arxiv.org/abs/2401.13913](http://arxiv.org/abs/2401.13913)

    本文提出了一种基于谱聚类和分布相似度度量的框架来解决离散分布聚类问题。通过使用线性最优传输构建相似度矩阵，我们在聚类准确性和计算效率方面取得了显著的改进。

    

    离散分布聚类（D2C）通常通过Wasserstein质心方法来解决。这些方法在一个共同的假设下工作，即聚类可以通过质心很好地表示，但在许多实际应用中可能不成立。在本文中，我们提出了一个简单而有效的基于谱聚类和分布相似度度量（例如最大均值差异和Wasserstein距离）的框架来解决D2C问题。为了提高可扩展性，我们提出使用线性最优传输在大型数据集上高效地构建相似度矩阵。我们提供了理论保证，保证了所提方法在聚类分布方面的成功。在合成数据和真实数据上的实验证明，我们的方法在聚类准确性和计算效率方面大大优于基准方法。

    Discrete distribution clustering (D2C) was often solved by Wasserstein barycenter methods. These methods are under a common assumption that clusters can be well represented by barycenters, which may not hold in many real applications. In this work, we propose a simple yet effective framework based on spectral clustering and distribution affinity measures (e.g., maximum mean discrepancy and Wasserstein distance) for D2C. To improve the scalability, we propose to use linear optimal transport to construct affinity matrices efficiently on large datasets. We provide theoretical guarantees for the success of the proposed methods in clustering distributions. Experiments on synthetic and real data show that our methods outperform the baselines largely in terms of both clustering accuracy and computational efficiency.
    
[^10]: Constant Stepsize Q-learning: 分布收敛性、偏差和外推

    Constant Stepsize Q-learning: Distributional Convergence, Bias and Extrapolation. (arXiv:2401.13884v1 [stat.ML])

    [http://arxiv.org/abs/2401.13884](http://arxiv.org/abs/2401.13884)

    本文研究了常数步长异步Q-learning算法，并通过分析其与马尔可夫链的关联，展示了其迭代在分布上的收敛性和指数收敛速度。同时，研究者还建立了该算法迭代的中心极限定理，并对其渐近偏差进行了精确的展开。通过这些分析，我们可以深入理解这种算法的优化效果和偏差特性。

    

    随机逼近（SA）是一种广泛应用于各个领域的算法方法，包括优化和强化学习（RL）。在RL算法中，由于其经验成功，Q-learning特别受欢迎。在本文中，我们研究了常数步长异步Q-learning，这在实践中通常用于快速收敛。通过将常数步长Q-learning与时间均匀的马尔可夫链相关联，我们展示了迭代在Wasserstein距离下的分布收敛性，并建立了其指数收敛速度。我们还为Q-learning迭代建立了中心极限定理，证明了平均迭代的渐近正态性。此外，我们提供了平均迭代步骤的渐近偏差的明确展开。具体而言，偏差与步长成正比，直到高阶项，并为线性系数提供了明确的表达式。这种对偏差的精确描述可以使得我们可以探索出对于这种偏差的更深入理解。

    Stochastic Approximation (SA) is a widely used algorithmic approach in various fields, including optimization and reinforcement learning (RL). Among RL algorithms, Q-learning is particularly popular due to its empirical success. In this paper, we study asynchronous Q-learning with constant stepsize, which is commonly used in practice for its fast convergence. By connecting the constant stepsize Q-learning to a time-homogeneous Markov chain, we show the distributional convergence of the iterates in Wasserstein distance and establish its exponential convergence rate. We also establish a Central Limit Theory for Q-learning iterates, demonstrating the asymptotic normality of the averaged iterates. Moreover, we provide an explicit expansion of the asymptotic bias of the averaged iterate in stepsize. Specifically, the bias is proportional to the stepsize up to higher-order terms and we provide an explicit expression for the linear coefficient. This precise characterization of the bias allows
    
[^11]: 温度对Softmax高斯混合专家是否具有采样效率？

    Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?. (arXiv:2401.13875v1 [stat.ML])

    [http://arxiv.org/abs/2401.13875](http://arxiv.org/abs/2401.13875)

    本文研究了温度对Softmax高斯混合专家的采样效率的影响，证明了由于温度和其他模型参数之间的相互作用，参数估计的收敛速度较慢，并且可能很慢。

    

    最近，密集-稀疏门控专家混合模型（MoE）已成为广为使用的稀疏MoE的有效替代方案。与后者模型中固定激活的专家数量不同，前者模型利用温度来控制softmax权重分布和MoE的稀疏性，在训练过程中稳定专家的专业化。然而，尽管以前有尝试从理论上理解稀疏MoE的方法，对于密集到稀疏门控MoE的全面分析仍然困难重重。因此，本文旨在探讨密集到稀疏门控对Gaussian MoE下的最大似然估计的影响。我们证明由于温度和其他模型参数之间通过一些偏微分方程的相互作用，参数估计的收敛速度比任何多项式速率都要慢，并且可能慢到$\mathcal{

    Dense-to-sparse gating mixture of experts (MoE) has recently become an effective alternative to a well-known sparse MoE. Rather than fixing the number of activated experts as in the latter model, which could limit the investigation of potential experts, the former model utilizes the temperature to control the softmax weight distribution and the sparsity of the MoE during training in order to stabilize the expert specialization. Nevertheless, while there are previous attempts to theoretically comprehend the sparse MoE, a comprehensive analysis of the dense-to-sparse gating MoE has remained elusive. Therefore, we aim to explore the impacts of the dense-to-sparse gate on the maximum likelihood estimation under the Gaussian MoE in this paper. We demonstrate that due to interactions between the temperature and other model parameters via some partial differential equations, the convergence rates of parameter estimations are slower than any polynomial rates, and could be as slow as $\mathcal{
    
[^12]: 一种基于V2X的隐私保护联合测量和学习系统

    A V2X-based Privacy Preserving Federated Measuring and Learning System. (arXiv:2401.13848v1 [cs.LG])

    [http://arxiv.org/abs/2401.13848](http://arxiv.org/abs/2401.13848)

    本文介绍了一种基于V2X的隐私保护联合测量和学习系统，通过V2V通信向其他车辆提供实时数据，同时通过V2N链路上的FL方案创建交通网络的预测模型。

    

    未来的自动驾驶车辆将使用各种传感器生成大量数据。这些数据不仅可以用于自动驾驶算法，还可以帮助其他车辆或基础设施进行实时决策。因此，车辆需要通过车辆到一切(V2X)技术来交换测量数据。此外，预测道路网络的状态可能也会有益处。通过这种预测，我们可以减轻道路拥堵、平衡停车场使用情况或优化交通流动。这将降低运输成本，减少环境影响。在本文中，我们提出了一种联合测量和学习系统，通过车辆到车辆(V2V)通信向其他车辆提供实时数据，同时通过车辆到网络(V2N)链路上的联合学习(FL)方案创建交通网络的预测模型。由于尚无真实世界的自动驾驶数据，我们模拟了数据，

    Future autonomous vehicles (AVs) will use a variety of sensors that generate a vast amount of data. Naturally, this data not only serves self-driving algorithms; but can also assist other vehicles or the infrastructure in real-time decision-making. Consequently, vehicles shall exchange their measurement data over Vehicle-to-Everything (V2X) technologies. Moreover, predicting the state of the road network might be beneficial too. With such a prediction, we might mitigate road congestion, balance parking lot usage, or optimize the traffic flow. That would decrease transportation costs as well as reduce its environmental impact.  In this paper, we propose a federated measurement and learning system that provides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V) communication while also operating a federated learning (FL) scheme over the Vehicle-to-Network (V2N) link to create a predictive model of the transportation network. As we are yet to have real-world AV data, we model
    
[^13]: 一种针对深度卷积神经网络的鲁棒性建模的系统化方法

    A Systematic Approach to Robustness Modelling for Deep Convolutional Neural Networks. (arXiv:2401.13751v1 [cs.LG])

    [http://arxiv.org/abs/2401.13751](http://arxiv.org/abs/2401.13751)

    本论文提出一种系统化方法，用于针对深度卷积神经网络进行鲁棒性建模。研究发现隐藏层数量对模型的推广性能有影响，同时还测试了模型大小、浮点精度、训练数据和模型输出的噪声水平等参数。为了改进模型的预测能力和计算成本，提出了一种使用诱发故障来建模故障概率的方法。

    

    当有大量标记数据可用时，卷积神经网络已经被证明在许多领域都可以广泛应用。最近的趋势是使用具有越来越多可调参数的模型，以提高模型准确性，降低模型损失或创建更具对抗鲁棒性的模型，而这些目标通常相互矛盾。特别是，最近的理论研究提出了对更大模型能否推广到受控的训练和测试集之外的数据的疑问。因此，我们研究了ResNet模型中隐藏层的数量在MNIST、CIFAR10和CIFAR100数据集上的作用。我们测试了各种参数，包括模型的大小、浮点精度，以及训练数据和模型输出的噪声水平。为了改进模型的预测能力和计算成本，我们提供了一种使用诱发故障来建模故障概率的方法。

    Convolutional neural networks have shown to be widely applicable to a large number of fields when large amounts of labelled data are available. The recent trend has been to use models with increasingly larger sets of tunable parameters to increase model accuracy, reduce model loss, or create more adversarially robust models -- goals that are often at odds with one another. In particular, recent theoretical work raises questions about the ability for even larger models to generalize to data outside of the controlled train and test sets. As such, we examine the role of the number of hidden layers in the ResNet model, demonstrated on the MNIST, CIFAR10, CIFAR100 datasets. We test a variety of parameters including the size of the model, the floating point precision, and the noise level of both the training data and the model output. To encapsulate the model's predictive power and computational cost, we provide a method that uses induced failures to model the probability of failure as a fun
    
[^14]: 《规范预测集提升人类决策能力》

    Conformal Prediction Sets Improve Human Decision Making. (arXiv:2401.13744v1 [cs.LG])

    [http://arxiv.org/abs/2401.13744](http://arxiv.org/abs/2401.13744)

    该研究表明，通过规范预测量化模型的不确定性，可以提高人类决策的准确性和效果，对人机协同决策具有实用价值。

    

    作为对日常查询的回应，人类明确地表达不确定性，并在不确定的情况下提供替代答案。通过规范预测输出校准的预测集，模仿了人类的这种行为；更大的预测集表示更大的不确定性，同时提供了替代方案。在这项工作中，我们通过实施预注册的随机对照试验，并给人类受试者提供规范预测集，研究了规范预测集对人类决策的实用性。通过统计学显著性，我们发现当人类获得规范预测集时，他们在任务上的准确性比使用相同覆盖保证的固定尺寸预测集时有所提高。结果表明，用规范预测量化模型的不确定性有助于人机协同决策和人工智能团队的决策。

    In response to everyday queries, humans explicitly signal uncertainty and offer alternative answers when they are unsure. Machine learning models that output calibrated prediction sets through conformal prediction mimic this human behaviour; larger sets signal greater uncertainty while providing alternatives. In this work, we study the usefulness of conformal prediction sets as an aid for human decision making by conducting a pre-registered randomized controlled trial with conformal prediction sets provided to human subjects. With statistical significance, we find that when humans are given conformal prediction sets their accuracy on tasks improves compared to fixed-size prediction sets with the same coverage guarantee. The results show that quantifying model uncertainty with conformal prediction is helpful for human-in-the-loop decision making and human-AI teams.
    
[^15]: 加速双曲线t-SNE算法

    Accelerating hyperbolic t-SNE. (arXiv:2401.13708v1 [cs.HC])

    [http://arxiv.org/abs/2401.13708](http://arxiv.org/abs/2401.13708)

    本文提出了加速双曲线t-SNE算法，通过引入极坐标四叉树的加速结构，解决了现有方法在处理大规模输入数据时的效率问题。

    

    在各个领域中，理解层次化或高维数据的结构是必要的。双曲空间已经被证明是一种重要的嵌入计算和分析工具，因为它们的非线性特性很适合处理树状或图形数据。因此，它们也被用于高维数据的可视化，其中它们表现出更好的嵌入性能。然而，现有的嵌入到双曲空间的降维方法都不能很好地处理输入数据的规模扩展问题。这是因为嵌入是通过迭代优化方案计算的，而每次迭代的计算成本与输入规模的平方成正比。此外，由于双曲空间的非线性特性，欧几里德加速结构不能直接转化为双曲设置。本文介绍了第一个用于双曲嵌入加速的结构，基于极坐标四叉树。我们将其应用于t-SNE算法，提出了加速双曲线t-SNE算法。

    The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, Euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This paper introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We com
    
[^16]: 无害过度拟合对敌对鲁棒性的意外危害

    The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness. (arXiv:2401.12236v1 [cs.LG])

    [http://arxiv.org/abs/2401.12236](http://arxiv.org/abs/2401.12236)

    这项研究证明了即使机器学习模型在训练过程中对噪声数据拟合得很好，对敌对示例具有鲁棒性，但当面临敌对操纵的数据时，过度拟合的模型可能会给系统带来意外的危害。

    

    最近的实证和理论研究已经证明了大规模机器学习模型对训练噪声数据的泛化能力。在本文中，我们证明了一个令人惊讶的结果：即使真正的数据本身对敌对示例具有鲁棒性，而且过度拟合的模型在“标准”的样本外风险目标上是无害的，但在样本外数据受到敌对操纵时，这种无害的过度拟合过程可能是有害的。具体而言，我们的主要结果包含两个部分：（i）在过度参数化线性模型中，最小范数估计总是在“无害过度拟合”设置中导致敌对易受攻击；（ii）我们验证了每个岭回归估计器的标准风险和“敌对”风险之间的渐进权衡结果，这意味着在适当的条件下，这两个项目不能同时通过任何单个岭正则化参数的选择来保持很小。

    Recent empirical and theoretical studies have established the generalization capabilities of large machine learning models that are trained to (approximately or exactly) fit noisy data. In this work, we prove a surprising result that even if the ground truth itself is robust to adversarial examples, and the benignly overfitted model is benign in terms of the ``standard'' out-of-sample risk objective, this benign overfitting process can be harmful when out-of-sample data are subject to adversarial manipulation. More specifically, our main results contain two parts: (i) the min-norm estimator in overparameterized linear model always leads to adversarial vulnerability in the ``benign overfitting'' setting; (ii) we verify an asymptotic trade-off result between the standard risk and the ``adversarial'' risk of every ridge regression estimator, implying that under suitable conditions these two items cannot both be small at the same time by any single choice of the ridge regularization parame
    
[^17]: 对于核机器在预处理中的Nystrom逼近

    On the Nystrom Approximation for Preconditioning in Kernel Machines. (arXiv:2312.03311v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2312.03311](http://arxiv.org/abs/2312.03311)

    本文分析了核机器预处理中使用Nystrom逼近的权衡。研究表明，使用对数大小的样本能够让Nystrom逼近的预处理器几乎与梯度下降同样有效地加速。

    

    核方法是机器学习中一类流行的非线性预测模型。学习核模型的可扩展算法需要具有迭代性质，但由于糟糕的条件，收敛可能很慢。谱预处理是加快训练核模型迭代算法收敛速度的重要工具。然而，计算和存储谱预处理器可能代价高昂，会导致大量的计算和存储开销，限制了核方法在大型数据集问题上的应用。Nystrom逼近的谱预处理器通常更便宜和更容易计算和存储，并在实际应用中取得了成功。本文分析了使用这种逼近预处理器的权衡。具体来说，我们表明与数据集大小相关的对数样本数量能够让基于Nystrom逼近的预处理器几乎与梯度下降同样有效地加速。

    Kernel methods are a popular class of nonlinear predictive models in machine learning. Scalable algorithms for learning kernel models need to be iterative in nature, but convergence can be slow due to poor conditioning. Spectral preconditioning is an important tool to speed-up the convergence of such iterative algorithms for training kernel models. However computing and storing a spectral preconditioner can be expensive which can lead to large computational and storage overheads, precluding the application of kernel methods to problems with large datasets. A Nystrom approximation of the spectral preconditioner is often cheaper to compute and store, and has demonstrated success in practical applications. In this paper we analyze the trade-offs of using such an approximated preconditioner. Specifically, we show that a sample of logarithmic size (as a function of the size of the dataset) enables the Nystrom-based approximated preconditioner to accelerate gradient descent nearly as well as
    
[^18]: 一种基于秩的多重检验正相关依赖的强大修正方法

    A powerful rank-based correction to multiple testing under positive dependency. (arXiv:2311.10900v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2311.10900](http://arxiv.org/abs/2311.10900)

    我们提出了一种基于秩的多重检验修正方法，能够有效利用正相关的统计假设检验之间的依赖关系，并在存在正相关依赖情况下优于Bonferroni修正。我们的方法尤其适用于并行置换检验，在保证FWER控制的同时保持高统计功效。

    

    我们开发了一种能够高效利用可能相关的统计假设检验之间正相关性的家族误差率(FWER)控制的新型多重假设检验修正算法$\texttt{max-rank}$。我们的方法概念上很直观，依赖于在计算的统计检验的秩域使用$\max$算子。通过理论和经验的比较，我们证明了在存在正相关依赖的情况下，我们的方法优于经常使用的Bonferroni修正，而在不存在正相关依赖的情况下等效。我们的优势随着测试数量的增加而增加，同时在保证FWER控制的情况下保持高统计功效。我们特别将我们的算法应用于并行置换检验的背景中，这是在我们主要应用的一种复杂预测场景中产生的情况下。

    We develop a novel multiple hypothesis testing correction with family-wise error rate (FWER) control that efficiently exploits positive dependencies between potentially correlated statistical hypothesis tests. Our proposed algorithm $\texttt{max-rank}$ is conceptually straight-forward, relying on the use of a $\max$-operator in the rank domain of computed test statistics. We compare our approach to the frequently employed Bonferroni correction, theoretically and empirically demonstrating its superiority over Bonferroni in the case of existing positive dependency, and its equivalence otherwise. Our advantage over Bonferroni increases as the number of tests rises, and we maintain high statistical power whilst ensuring FWER control. We specifically frame our algorithm in the context of parallel permutation testing, a scenario that arises in our primary application of conformal prediction, a recently popularized approach for quantifying uncertainty in complex predictive settings.
    
[^19]: 在在线设置下学习线性算子的无限维回归

    Online Infinite-Dimensional Regression: Learning Linear Operators. (arXiv:2309.06548v1 [stat.ML])

    [http://arxiv.org/abs/2309.06548](http://arxiv.org/abs/2309.06548)

    在这篇论文中，我们研究了在线设置下学习无限维线性算子的问题。我们证明了在一定的条件下，线性算子是可以在线学习的，而在另一些条件下则不可以。我们还证明了在线均一收敛和学习能力之间的分离，并在PAC设置下得到了相同的结果。

    

    我们考虑在线设置下学习两个无限维希尔伯特空间之间的线性算子问题，通过最小二乘损失函数进行学习。我们证明了在$p \in [1, \infty)$范围内，具有均匀有界$p$-Schatten范数的线性算子类是可以在线学习的。另一方面，我们证明了具有均匀有界算子范数的线性算子类\textit{不}是可以在线学习的。此外，我们通过找到一类有界线性算子，证明了在线均一收敛和学习能力之间的分离。最后，我们证明了不可能性结果和均一收敛与学习能力之间的分离在PAC设置下同样成立。

    We consider the problem of learning linear operators under squared loss between two infinite-dimensional Hilbert spaces in the online setting. We show that the class of linear operators with uniformly bounded $p$-Schatten norm is online learnable for any $p \in [1, \infty)$. On the other hand, we prove an impossibility result by showing that the class of uniformly bounded linear operators with respect to the operator norm is \textit{not} online learnable. Moreover, we show a separation between online uniform convergence and online learnability by identifying a class of bounded linear operators that is online learnable but uniform convergence does not hold. Finally, we prove that the impossibility result and the separation between uniform convergence and learnability also hold in the agnostic PAC setting.
    
[^20]: 通过弃权实现顺序预测中的对抗鲁棒性

    Adversarial Resilience in Sequential Prediction via Abstention. (arXiv:2306.13119v1 [cs.LG])

    [http://arxiv.org/abs/2306.13119](http://arxiv.org/abs/2306.13119)

    本文提出了一种处理顺序预测的模型，允许在不对对抗性样例进行预测的情况下提高算法抗对抗攻击的能力。

    

    本文研究了在带有允许注入干净标签对抗性（或超出分布）示例的对抗者的情况下，在随机设置下的顺序预测问题。针对纯随机数据的算法在存在此类对抗性示例的情况下往往失败，从而导致错误的预测。这在许多高风险应用中是不可取的，例如医学建议，这里弃权不进行对抗性示例的预测优于误分类。另一方面，假设完全对抗性数据导致非常悲观的界限，在实践中往往是空洞的。为了实现这一目标，我们提出了一种新的顺序预测模型，它位于纯随机和完全对抗性设置之间，通过允许学习器在对抗样例上无代价地放弃进行预测来实现。假设访问非对抗样例的边际分布，我们设计了一个学习器，其误差随着VC维的变化而变化。

    We study the problem of sequential prediction in the stochastic setting with an adversary that is allowed to inject clean-label adversarial (or out-of-distribution) examples. Algorithms designed to handle purely stochastic data tend to fail in the presence of such adversarial examples, often leading to erroneous predictions. This is undesirable in many high-stakes applications such as medical recommendations, where abstaining from predictions on adversarial examples is preferable to misclassification. On the other hand, assuming fully adversarial data leads to very pessimistic bounds that are often vacuous in practice.  To capture this motivation, we propose a new model of sequential prediction that sits between the purely stochastic and fully adversarial settings by allowing the learner to abstain from making a prediction at no cost on adversarial examples. Assuming access to the marginal distribution on the non-adversarial examples, we design a learner whose error scales with the VC 
    
[^21]: 利用Cayley变换和可控性Gram矩的Lipschitz-bounded 1D卷积神经网络(arXiv:2303.11835v1 [cs.LG])

    Lipschitz-bounded 1D convolutional neural networks using the Cayley transform and the controllability Gramian. (arXiv:2303.11835v1 [cs.LG])

    [http://arxiv.org/abs/2303.11835](http://arxiv.org/abs/2303.11835)

    本文提出了一个逐层参数化方法，用于实现内置鲁棒性保证的1D卷积神经网络。该方法基于CNN特征的Lipschitz常数作为鲁棒性度量，并使用Cayley变换和可控性Gram矩来实现CNN的Lipschitz连续性和无约束训练，最后在心律失常数据分类任务中取得了改进的鲁棒性。

    

    我们建立了一种用于1D卷积神经网络（CNN）的逐层参数化，具有内置的端到端鲁棒性保证。我们使用CNN特征的Lipschitz常数作为鲁棒性度量。我们基于Cayley变换对正交矩阵进行参数化以及对卷积层的状态空间表征的可控性Gram矩进行参数化。所提出的参数化设计满足线性矩阵不等式，从而实现CNN的Lipschitz连续性，进一步实现Lipschitz-bounded 1D CNNs的无约束训练。最后，我们对心律失常数据进行Lipschitz-bounded 1D CNNs的分类训练，并展示了其改进的鲁棒性。

    We establish a layer-wise parameterization for 1D convolutional neural networks (CNNs) with built-in end-to-end robustness guarantees. Herein, we use the Lipschitz constant of the input-output mapping characterized by a CNN as a robustness measure. We base our parameterization on the Cayley transform that parameterizes orthogonal matrices and the controllability Gramian for the state space representation of the convolutional layers. The proposed parameterization by design fulfills linear matrix inequalities that are sufficient for Lipschitz continuity of the CNN, which further enables unconstrained training of Lipschitz-bounded 1D CNNs. Finally, we train Lipschitz-bounded 1D CNNs for the classification of heart arrythmia data and show their improved robustness.
    
[^22]: 使用主动学习方法的相关聚类

    Correlation Clustering with Active Learning of Pairwise Similarities. (arXiv:2302.10295v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10295](http://arxiv.org/abs/2302.10295)

    本文研究了相关聚类中成对相似性不事先给出的情况，并开发了一个通用的主动学习框架，适应各种相关聚类算法和查询策略，同时具有适应性灵活、噪声鲁棒性等优势。

    

    相关聚类是一个众所周知的无监督学习设置，处理正负相似性对。在本文中，我们研究了一种情况，即成对相似性不事先给出，必须以高效的方式查询。为此，我们开发了一个通用的主动学习框架，针对这个任务具有多种优势，例如，用户/注释者可以提供各种反馈类型、适应任何相关聚类算法和查询策略以及对噪声具有鲁棒性。此外，我们还提出和分析了一些适合这种设置的新的查询策略。通过几个实验研究，我们展示了我们框架和所提出的查询策略的有效性。

    Correlation clustering is a well-known unsupervised learning setting that deals with positive and negative pairwise similarities. In this paper, we study the case where the pairwise similarities are not given in advance and must be queried in a cost-efficient way. Thereby, we develop a generic active learning framework for this task that benefits from several advantages, e.g., flexibility in the type of feedback that a user/annotator can provide, adaptation to any correlation clustering algorithm and query strategy, and robustness to noise. In addition, we propose and analyze a number of novel query strategies suited to this setting. We demonstrate the effectiveness of our framework and the proposed query strategies via several experimental studies.
    
[^23]: 何时可以追踪到决斗对抗中的显著偏好转变？

    When Can We Track Significant Preference Shifts in Dueling Bandits?. (arXiv:2302.06595v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06595](http://arxiv.org/abs/2302.06595)

    这个论文研究了具有分布转变的决斗对抗问题，并探讨了设计自适应算法以解决动态遗憾的问题，结果发现取决于底层偏好分布的属性。达到$O(\sqrt{K\tilde{L}T})$的动态遗憾是不可能的；对于$\text{SST} \cap \text{STI}$情况，存在一种算法实现动态遗憾为$O(\sqrt{K\tilde{L}T})$。

    

    在信息检索、推荐系统等领域应用广泛的$K$臂决斗对抗问题中，反馈以有噪声的成对偏好形式给出，因此得到了广泛研究。考虑到用户的偏好/口味可能随时间演变，我们研究了具有分布转变的决斗对抗问题。具体来说，我们研究了最近提出的显著转变概念（Suk和Kpotufe，2022），并提出是否可以设计一种自适应算法来解决具有$O(\sqrt{K\tilde{L}T})$动态遗憾（regret）的决斗问题，其中$\tilde{L}$是偏好中显著转变的（未知）数量。我们表明，这个问题的答案取决于底层偏好分布的属性。首先，我们给出了一个不可能的结果，排除了在广受研究的Condorcet和SST偏好分布类下具有$O(\sqrt{K\tilde{L}T})$动态遗憾的任何算法。其次，我们表明$\text{SST} \cap \text{STI}$是大规模的情况。

    The $K$-armed dueling bandits problem, where the feedback is in the form of noisy pairwise preferences, has been widely studied due its applications in information retrieval, recommendation systems, etc. Motivated by concerns that user preferences/tastes can evolve over time, we consider the problem of dueling bandits with distribution shifts. Specifically, we study the recent notion of significant shifts (Suk and Kpotufe, 2022), and ask whether one can design an adaptive algorithm for the dueling problem with $O(\sqrt{K\tilde{L}T})$ dynamic regret, where $\tilde{L}$ is the (unknown) number of significant shifts in preferences. We show that the answer to this question depends on the properties of underlying preference distributions.  Firstly, we give an impossibility result that rules out any algorithm with $O(\sqrt{K\tilde{L}T})$ dynamic regret under the well-studied Condorcet and SST classes of preference distributions. Secondly, we show that $\text{SST} \cap \text{STI}$ is the large
    
[^24]: RS-Del: 随机删除对序列分类器的编辑距离鲁棒性证明

    RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion. (arXiv:2302.01757v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.01757](http://arxiv.org/abs/2302.01757)

    本文提出了一种适应于离散序列分类器的随机删除（RS-Del）平滑机制，提供针对编辑距离受限对抗性的鲁棒性证明。

    

    随机平滑是构建具有认证鲁棒性的分类器的主要方法。现有的随机平滑方法主要针对具有连续输入（如图像）的分类器，其中常常研究$\ell_p$范数受限的对抗性示例。然而，对于具有离散或可变大小输入（例如源代码）的分类器的研究较少，这些分类器需要不同的威胁模型和平滑机制。在本研究中，我们修改了随机平滑方法，以适用于离散序列分类器，以提供针对编辑距离受限的对抗性的可证明的鲁棒性。我们提出的平滑机制随机删除（RS-Del）应用了随机删除编辑，这种方式（也许令人惊讶地）足以提供针对对抗性删除、插入和替换编辑的鲁棒性。我们的认证证明不同于传统的Neyman-Pearson方法，在我们的情况下无法计算，而是围绕着另一种方式进行组织。

    Randomized smoothing is a leading approach for constructing classifiers that are certifiably robust against adversarial examples. Existing work on randomized smoothing has focused on classifiers with continuous inputs, such as images, where $\ell_p$-norm bounded adversaries are commonly studied. However, there has been limited work for classifiers with discrete or variable-size inputs, such as for source code, which require different threat models and smoothing mechanisms. In this work, we adapt randomized smoothing for discrete sequence classifiers to provide certified robustness against edit distance-bounded adversaries. Our proposed smoothing mechanism randomized deletion (RS-Del) applies random deletion edits, which are (perhaps surprisingly) sufficient to confer robustness against adversarial deletion, insertion and substitution edits. Our proof of certification deviates from the established Neyman-Pearson approach, which is intractable in our setting, and is instead organized aro
    
[^25]: 转移学习用于上下文多臂赌博机问题

    Transfer Learning for Contextual Multi-armed Bandits. (arXiv:2211.12612v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.12612](http://arxiv.org/abs/2211.12612)

    本文研究了上下文多臂赌博机问题中的转移学习，提出了一种新的算法来最小化遗憾，并量化了源领域数据对目标领域学习的贡献。

    

    在面对一系列应用的驱动下，本文研究了在协变量转移模型下非参数上下文多臂赌博机的转移学习问题，其中在目标赌博机开始学习之前，我们已经收集到了源赌博机的数据。本文建立了累积遗憾的最小化速率收敛性，并提出了一种新颖的转移学习算法，它达到了最小化遗憾的极限。结果量化了源领域数据在上下文非参数多臂赌博机学习中对目标领域学习的贡献。鉴于对未知平滑性的一般不可能性，我们开发了一种数据驱动算法，它在额外的自相似性假设下在大量参数空间中自动适应未知参数，并实现了接近最优的统计保证（除以对数因子）。通过模拟实验说明了转移学习在上下文多臂赌博机问题中的好处。

    Motivated by a range of applications, we study in this paper the problem of transfer learning for nonparametric contextual multi-armed bandits under the covariate shift model, where we have data collected on source bandits before the start of the target bandit learning. The minimax rate of convergence for the cumulative regret is established and a novel transfer learning algorithm that attains the minimax regret is proposed. The results quantify the contribution of the data from the source domains for learning in the target domain in the context of nonparametric contextual multi-armed bandits.  In view of the general impossibility of adaptation to unknown smoothness, we develop a data-driven algorithm that achieves near-optimal statistical guarantees (up to a logarithmic factor) while automatically adapting to the unknown parameters over a large collection of parameter spaces under an additional self-similarity assumption. A simulation study is carried out to illustrate the benefits of
    
[^26]: 证明了分布式风险敏感强化学习与风险敏感强化学习之间的可证明遗憾上界

    Bridging Distributional and Risk-sensitive Reinforcement Learning with Provable Regret Bounds. (arXiv:2210.14051v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14051](http://arxiv.org/abs/2210.14051)

    本论文证明了使用分布式强化学习方法可以实现风险敏感强化学习的遗憾保证问题，并提出了两种新颖算法，其遗憾上界与先前方法相匹配。

    

    本论文研究了使用分布式强化学习方法对风险敏感强化学习（RSRL）的遗憾保证问题。具体而言，我们考虑了目标为回报的熵风险测度（EntRM）的有限情节马尔可夫决策过程。通过利用EntRM的一个关键属性，独立性属性，我们建立了风险敏感分布式动态规划框架。然后，我们提出了两种新颖的分布式强化学习算法，通过两种不同的方案实现了乐观性，包括基于模型和无模型的方法。我们证明了这两种算法都达到了$\tilde{\mathcal{O}}(\frac{\exp(|\beta| H)-1}{|\beta|}H\sqrt{S^2AK})$的遗憾上界，其中$S$，$A$，$K$和$H$分别表示状态的数量，动作的数量，情节的数量和时间的长度。这与\cite{fei2021exponential}中提出的RSVI2相一致，并进行了新颖的分布式分析。据我们所知，这是第一个以样本复杂度方向将分布式强化学习和风险敏感强化学习联系起来的遗憾分析。

    We study the regret guarantee for risk-sensitive reinforcement learning (RSRL) via distributional reinforcement learning (DRL) methods. In particular, we consider finite episodic Markov decision processes whose objective is the entropic risk measure (EntRM) of return. By leveraging a key property of the EntRM, the independence property, we establish the risk-sensitive distributional dynamic programming framework. We then propose two novel DRL algorithms that implement optimism through two different schemes, including a model-free one and a model-based one.  We prove that they both attain $\tilde{\mathcal{O}}(\frac{\exp(|\beta| H)-1}{|\beta|}H\sqrt{S^2AK})$ regret upper bound, where $S$, $A$, $K$, and $H$ represent the number of states, actions, episodes, and the time horizon, respectively. It matches RSVI2 proposed in \cite{fei2021exponential}, with novel distributional analysis. To the best of our knowledge, this is the first regret analysis that bridges DRL and RSRL in terms of sampl
    
[^27]: MCCE：蒙特卡洛采样的现实反事实解释

    MCCE: Monte Carlo sampling of realistic counterfactual explanations. (arXiv:2111.09790v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.09790](http://arxiv.org/abs/2111.09790)

    MCCE是一个新颖的反事实解释方法，通过模拟可变特征和决策的联合分布，生成处于流形上、可行并且有效的反事实。与其他方法相比，MCCE可以处理任何类型的预测模型和具有多个级别的分类特征。

    

    我们引入了MCCE: Monte Carlo采样的有效和现实的表格数据反事实解释，这是一种新颖的反事实解释方法，通过对给定不可变特征和决策的可变特征的联合分布进行建模，生成处于流形上、可行并且有效的反事实。与其他依赖变分自动编码器和具有严格预测模型和数据要求的流形方法不同，MCCE可以处理任何类型的预测模型和具有两个以上级别的分类特征。MCCE首先使用自回归生成模型对特征和决策的联合分布进行建模，其中条件概率使用决策树进行估计。然后，它从该模型中采样一大组观测值，最后删除不符合特定条件的样本。我们使用四个知名数据集将MCCE与一系列最先进的流形反事实方法进行比较，并展示了MCCE的优越性。

    We introduce MCCE: Monte Carlo sampling of valid and realistic Counterfactual Explanations for tabular data, a novel counterfactual explanation method that generates on-manifold, actionable and valid counterfactuals by modeling the joint distribution of the mutable features given the immutable features and the decision. Unlike other on-manifold methods that tend to rely on variational autoencoders and have strict prediction model and data requirements, MCCE handles any type of prediction model and categorical features with more than two levels. MCCE first models the joint distribution of the features and the decision with an autoregressive generative model where the conditionals are estimated using decision trees. Then, it samples a large set of observations from this model, and finally, it removes the samples that do not obey certain criteria. We compare MCCE with a range of state-of-the-art on-manifold counterfactual methods using four well-known data sets and show that MCCE outperfo
    
[^28]: 针对非凸-凹极小极大问题的无导数交替投影算法

    Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems. (arXiv:2108.00473v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2108.00473](http://arxiv.org/abs/2108.00473)

    本文提出针对非凸-凹极小极大问题的无导数交替投影算法，包括光滑问题的交替随机梯度投影算法（ZO-AGP），以及块状非光滑问题的分块交替随机近端梯度算法（ZO-BAPG）。这些算法具有较少的函数值估计和较高的迭代复杂度。

    

    本文研究了非凸-凹极小极大问题的零阶算法，这类问题近年在机器学习、信号处理等领域引起了广泛关注。我们提出了一种零阶交替随机梯度投影（ZO-AGP）算法来解决光滑的非凸-凹极小极大问题，其迭代复杂度为 $\mathcal{O}(\varepsilon^{-4})$，每次迭代的函数值估计次数为 $\mathcal{O}(d_{x}+d_{y})$。此外，我们还提出了一种零阶分块交替随机近端梯度算法（ZO-BAPG）来解决块状非光滑的非凸-凹极小极大优化问题，其迭代复杂度为 $\mathcal{O}(\varepsilon^{-4})$，每次迭代的函数值估计次数为 $\mathcal{O}(K d_{x}+d_{y})$。据我们所知，这是首次提出这些算法。

    In this paper, we study zeroth-order algorithms for nonconvex-concave minimax problems, which have attracted widely attention in machine learning, signal processing and many other fields in recent years. We propose a zeroth-order alternating randomized gradient projection (ZO-AGP) algorithm for smooth nonconvex-concave minimax problems, and its iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$, and the number of function value estimation is bounded by $\mathcal{O}(d_{x}+d_{y})$ per iteration. Moreover, we propose a zeroth-order block alternating randomized proximal gradient algorithm (ZO-BAPG) for solving block-wise nonsmooth nonconvex-concave minimax optimization problems, and the iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$ and the number of function value estimation per iteration is bounded by $\mathcal{O}(K d_{x}+d_{y})$. To the best of our knowledge, this 
    
[^29]: 使用生成对抗网络进行密度估计的收敛速度

    Rates of convergence for density estimation with generative adversarial networks. (arXiv:2102.00199v4 [math.ST] UPDATED)

    [http://arxiv.org/abs/2102.00199](http://arxiv.org/abs/2102.00199)

    本文针对基本生成对抗网络（GANs）进行了详细研究，证明了在非参数密度估计应用中，GAN估计与真实密度之间的JS散度收敛速度达到了极小极限最优速率。

    

    在本研究中，我们对基本生成对抗网络（GANs）的非渐近特性进行了全面研究。我们证明了对于基本密度$\mathsf{p}^*$和GAN估计之间的Jensen-Shannon（JS）散度，存在一个正则化不等式，其统计误差项相较于先前已知的结果显著改进。我们的界限的优势在于非参数密度估计的应用中变得明显。我们展示了GAN估计与$\mathsf{p}^*$之间的JS散度的收敛速度与样本量$n$的速率为$(\log{n}/n)^{2\beta/(2\beta + d)}$，其中$n$为样本大小，$\beta$决定了$\mathsf{p}^*$的平滑程度。这种收敛速度（除了对数因子）与所考虑的密度类的极小极限最优速率一致。

    In this work we undertake a thorough study of the non-asymptotic properties of the vanilla generative adversarial networks (GANs). We prove an oracle inequality for the Jensen-Shannon (JS) divergence between the underlying density $\mathsf{p}^*$ and the GAN estimate with a significantly better statistical error term compared to the previously known results. The advantage of our bound becomes clear in application to nonparametric density estimation. We show that the JS-divergence between the GAN estimate and $\mathsf{p}^*$ decays as fast as $(\log{n}/n)^{2\beta/(2\beta + d)}$, where $n$ is the sample size and $\beta$ determines the smoothness of $\mathsf{p}^*$. This rate of convergence coincides (up to logarithmic factors) with minimax optimal for the considered class of densities.
    

