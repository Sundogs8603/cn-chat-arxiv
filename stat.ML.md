# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks.](http://arxiv.org/abs/2305.06986) | 本文研究了三层神经网络的特征学习能力，相比之下，它具有比两层网络更丰富的可证的特征学习能力，并提出了一个通用定理，限制了目标结构的样本复杂度和宽度，以实现低测试误差。 |
| [^2] | [Convergence of Alternating Gradient Descent for Matrix Factorization.](http://arxiv.org/abs/2305.06927) | 本文提出一种交替梯度下降算法，能够高概率地从非典型随机初始化达到一个$\epsilon$-最优矩阵分解，实验表明该初始化不仅在理论上有益，而且在实践中显著提高了梯度下降的收敛性。 |
| [^3] | [Reinterpreting causal discovery as the task of predicting unobserved joint statistics.](http://arxiv.org/abs/2305.06894) | 研究者提出将因果发现视为预测未观察到联合统计量的任务，这样可以更好地推断未观察到集合的属性。 |
| [^4] | [Risk-limiting Financial Audits via Weighted Sampling without Replacement.](http://arxiv.org/abs/2305.06884) | 本文介绍了一种通过构建新的加权抽样信心序列，对N个未知值的加权平均值进行估计的风险限制财务审计（RLFA）。该方法可以通过合并未知值的附加信息提高生成序列的质量，从而提高估计的准确性和置信度。 |
| [^5] | [A General Framework for Visualizing Embedding Spaces of Neural Survival Analysis Models Based on Angular Information.](http://arxiv.org/abs/2305.06862) | 本文提出了一种通用框架，可以可视化任何神经生存分析模型所使用的中间嵌入表示。该框架基于嵌入空间中的锚定方向，可用于表格数据和原始输入（例如图像）。本文说明了在一个基于角度信息的嵌入空间中存在的信息丢失问题，并提供了减少信息丢失的实用方法。 |
| [^6] | [Policy Gradient Algorithms Implicitly Optimize by Continuation.](http://arxiv.org/abs/2305.06851) | 本文提供了政策梯度算法的新理论解释和证明，即政策梯度算法可以通过连续方式隐式优化确定性策略，并指出政策梯度算法探索的实质是计算当前策略收益的连续函数，策略的方差应该是历史依赖性函数。 |
| [^7] | [Information Design in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2305.06807) | 本文探究了多智能体强化学习中的信息设计问题及其挑战，提出了“马尔科夫信令博弈”的概念。 |
| [^8] | [Integrating nearest neighbors on neural network models for treatment effect estimation.](http://arxiv.org/abs/2305.06789) | 本论文提出了一种新的方法NNCI，用于将最近邻居信息集成到神经网络模型中，以更准确地估计治疗效果。 |
| [^9] | [Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits.](http://arxiv.org/abs/2305.06743) | 本文提出了一种针对奖励分布重尾的MAB问题的隐式规范化预测器，证明该方法在线性和非线性重尾随机MAB问题上是最优的。 |
| [^10] | [NUBO: A Transparent Python Package for Bayesian Optimisation.](http://arxiv.org/abs/2305.06709) | NUBO是一个透明的Python包，用于优化昂贵的黑盒函数，它利用高斯过程做代理模型以及获取函数来指导选择候选点，专注于透明度和用户体验。 |
| [^11] | [Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models.](http://arxiv.org/abs/2305.06704) | 该论文提出了一种基于聚类的鲁棒检测滞后多因子模型中的领先滞后关系方法，并使用各种聚类技术和相似度度量方法实现了对领先滞后估计的聚合，从而强化了对原始宇宙中的一致关系的识别。 |
| [^12] | [Neural Fine-Gray: Monotonic neural networks for competing risks.](http://arxiv.org/abs/2305.06703) | 本文提出了一种使用单调约束神经网络模拟每种竞争生存率分布的方法，从而确保可以在计算成本下实现精确的最大似然值最优化，该方法可以用于生存分析领域。 |
| [^13] | [Generalization bounds for neural ordinary differential equations and deep residual networks.](http://arxiv.org/abs/2305.06648) | 本研究提出了神经常微分方程及其变体的泛化界限，涵盖了深度残差网络，其泛化界限与连续权重差异大小有关。 |
| [^14] | [Dropout Regularization in Extended Generalized Linear Models based on Double Exponential Families.](http://arxiv.org/abs/2305.06625) | 本论文研究了基于双指数族的扩展广义线性模型中的dropout正则化，dropout正则化偏好罕见但重要的特征，在均值和离散度方面都具有普适性。 |
| [^15] | [Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation.](http://arxiv.org/abs/2305.06563) | 本文提出了一种基于流形正则化Tucker分解的时空交通数据填充方法，该方法利用稀疏正则化项改善了Tucker核的稀疏性，并引入流形正则化和时间约束项来优化张量的填充性能。 |
| [^16] | [Structures of Neural Network Effective Theories.](http://arxiv.org/abs/2305.02334) | 该论文提出了一种简化深度神经网络有效场论计算的图解方法，并指出单一条件决定了所有神经元预激活的关联函数的临界性，这可能有助于推动深度学习和场论模拟的进展。 |
| [^17] | [Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization.](http://arxiv.org/abs/2304.13761) | 通过独热编码和正则化提高梯度提升决策树的鲁棒性，研究表明对带有$L_1$或$L_2$正则化的线性回归形式进行拟合可提高GBDT模型的鲁棒性。 |
| [^18] | [More Communication Does Not Result in Smaller Generalization Error in Federated Learning.](http://arxiv.org/abs/2304.12216) | 我们研究了联邦学习环境下的统计学习模型泛化误差，表明更频繁地与参数服务器通信会负面影响此类学习算法的泛化性能。 |
| [^19] | [Using VAEs to Learn Latent Variables: Observations on Applications in cryo-EM.](http://arxiv.org/abs/2303.07487) | 本研究通过定性分析，发现VAE在生物应用中摊销潜在变量的特性与传统显式表示方法相似。 |
| [^20] | [Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference.](http://arxiv.org/abs/2302.11944) | 我们提出了一种反事实场景测试框架，通过比较数据集中类似的保护和非保护实例来检测分类器中的歧视，通过比较组间决策结果差异，来发现个人歧视。该框架可以更好地对「给定差异的公平原则」进行操作，以揭示在公平原则下的歧视差异。 |
| [^21] | [Imprecise Bayesian Neural Networks.](http://arxiv.org/abs/2302.09656) | 在机器学习和人工智能领域，该论文提出了一种新的算法——不精确的贝叶斯神经网络(IBNNs)。这种算法使用可信区间先验分布集合和似然分布集合进行训练，相比标准的BNNs，可以区分先验和后验的不确定性并量化。此外，IBNNs在贝叶斯灵敏度分析方面具有更强的鲁棒性，并且对分布变化也更加鲁棒。 |
| [^22] | [Reverse Ordering Techniques for Attention-Based Channel Prediction.](http://arxiv.org/abs/2302.00341) | 本文提出了基于Seq2Seq-attn和Transformer的信道预测模型，并引入了反向技术以提高模型鲁棒性，仿真结果表明比现有方法更好。 |
| [^23] | [Forecasting the 2016-2017 Central Apennines Earthquake Sequence with a Neural Point Process.](http://arxiv.org/abs/2301.09948) | 本文利用神经点过程模型对2016-2017年阿彭宁地震序列进行了预测，结果表明神经模型优于传统ETAS模型，可以应用于短期地震预报。 |
| [^24] | [Kernel Subspace and Feature Extraction.](http://arxiv.org/abs/2301.01410) | 本文研究了机器学习中的核方法，建立了特征子空间和核之间的一一对应关系，并提出了一个信息熵度量方法用于核的比较。特别地，构建了一个极大相关核，并证明其在信息熵度量方面的最优性。最后，把Fisher核解释为一种特殊的极大相关核，并建立了它的最优性。 |
| [^25] | [From Denoising Diffusions to Denoising Markov Models.](http://arxiv.org/abs/2211.03595) | 本论文提出了一个统一的框架，将去噪扩散模型推广到广泛的空间中，并导致分数匹配的原始扩展，适用于各种应用程序。 |
| [^26] | [$2 \times 2$ Zero-Sum Games with Commitments and Noisy Observations.](http://arxiv.org/abs/2211.01703) | 本文研究了带承诺和噪声观测的$2\times 2$零和博弈，发现平衡点总是存在的；领导者的动作观测结果对于追随者来说要么是有益的，要么是无关紧要的；该博弈的收益在均衡点上被上界限制为纯策略下的SE的收益，下界为混合策略下的纳什均衡的收益。 |
| [^27] | [Continuous-in-time Limit for Bayesian Bandits.](http://arxiv.org/abs/2210.07513) | 本文提出了一种适用于解决大时间长度下的贝叶斯赌博机问题的近似贝叶斯最优策略，并且其计算成本不包括依赖于时间长度的项。 |
| [^28] | [Covariance regression with random forests.](http://arxiv.org/abs/2209.08173) | 基于随机森林框架的协方差回归分析(Covariance Regression with Random Forests, CovRegRF)被提出，可以用于估算在给定协变量情况下多元响应的协方差矩阵，并且提供了一个有关某些协变量偏效应的显著性检验方法。 |
| [^29] | [Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning.](http://arxiv.org/abs/2208.08831) | 本研究利用现成的图像生成和字幕生成技术，自动发现视觉模型中的错误。通过生成大量合成但逼真的输入，聚类和描述，评估和发现分类器的失败和虚假相关性。这为未来构建实用的框架提供了一个有前途的思路。 |
| [^30] | [Computationally Efficient and Statistically Optimal Robust Low-rank Matrix and Tensor Estimation.](http://arxiv.org/abs/2203.00953) | 提出了一种新的计算高效且统计最优的鲁棒低秩矩阵和张量估计算法，可以在重尾噪声下实现准确估计，实验结果证明其优于现有方法。 |
| [^31] | [Learning to Rank under Multinomial Logit Choice.](http://arxiv.org/abs/2009.03207) | 该论文提出了一个基于多项Logit选择模型的学习排序框架，能够更准确地捕捉用户在整个项目列表中的选择行为，为网站设计提供了更好的排序方案。 |
| [^32] | [Efficient Discovery of Heterogeneous Quantile Treatment Effects in Randomized Experiments via Anomalous Pattern Detection.](http://arxiv.org/abs/1803.09159) | 提出了一种名为TESS的新方法，通过将该挑战作为一种模式检测问题来解决，可以高效地从随机实验数据中找到受治疗影响最大的子群体，同时假设最少且具有正确性保证。 |

# 详细

[^1]: 三层神经网络中非线性特征学习的可证保证

    Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks. (arXiv:2305.06986v1 [cs.LG])

    [http://arxiv.org/abs/2305.06986](http://arxiv.org/abs/2305.06986)

    本文研究了三层神经网络的特征学习能力，相比之下，它具有比两层网络更丰富的可证的特征学习能力，并提出了一个通用定理，限制了目标结构的样本复杂度和宽度，以实现低测试误差。

    

    深度学习理论中的一个核心问题是理解神经网络如何学习分层特征。深度网络提取显著特征的能力对其卓越的泛化能力和现代深度学习范式的预训练和微调至关重要。然而，从理论角度来看，这种特征学习过程仍然不够清晰，现有的分析主要局限于两层网络。在本文中，我们展示了三层神经网络具有证明的比两层网络更丰富的特征学习能力。我们分析了通过逐层梯度下降训练的三层网络学习的特征，并提出了一个通用定理，它上界了目标具有特定层次结构时实现低测试错误所需的样本复杂度和宽度。我们将我们的框架实例化到特定的统计学学习设置中——单指数模型和二次函数。

    One of the central questions in the theory of deep learning is to understand how neural networks learn hierarchical features. The ability of deep networks to extract salient features is crucial to both their outstanding generalization ability and the modern deep learning paradigm of pretraining and finetuneing. However, this feature learning process remains poorly understood from a theoretical perspective, with existing analyses largely restricted to two-layer networks. In this work we show that three-layer neural networks have provably richer feature learning capabilities than two-layer networks. We analyze the features learned by a three-layer network trained with layer-wise gradient descent, and present a general purpose theorem which upper bounds the sample complexity and width needed to achieve low test error when the target has specific hierarchical structure. We instantiate our framework in specific statistical learning settings -- single-index models and functions of quadratic 
    
[^2]: 矩阵分解中交替梯度下降的收敛性分析

    Convergence of Alternating Gradient Descent for Matrix Factorization. (arXiv:2305.06927v1 [cs.LG])

    [http://arxiv.org/abs/2305.06927](http://arxiv.org/abs/2305.06927)

    本文提出一种交替梯度下降算法，能够高概率地从非典型随机初始化达到一个$\epsilon$-最优矩阵分解，实验表明该初始化不仅在理论上有益，而且在实践中显著提高了梯度下降的收敛性。

    

    本文考虑了应用于不对称矩阵分解目标的具有固定步长$\eta>0$的交替梯度下降（AGD）。我们证明了，对于秩为$r$的矩阵$\mathbf {A}\in \mathbb {R} ^ {m \times n}$，$T=\left(\left(\frac{\sigma_1(\mathbf{A})}{\sigma_r(\mathbf{A})}\right)^2\log(1/\epsilon)\right)$次交替梯度下降即可从非典型随机初始化高概率地达到$\epsilon$-最优分解$\|\mathbf {A}\mathbf {X}_T^{\vphantom{\intercal}}\mathbf {Y}_T^{\intercal}\|_{\rm F}^2\le\epsilon\|\mathbf {A}\|_{\rm F}^2$。分解中因子的秩为$d>r$，因此$\mathbf{X}_T\in\mathbb{R}^{m \times d}$且$\mathbf{Y}_T\in\mathbb{R}^{n \times d}$。实验表明，我们提出的初始化不仅在理论上有益，而且在实践中显著提高了梯度下降的收敛性。我们的证明概念上很简单：一致的PL不等式和一致的Lipschitz平滑性。

    We consider alternating gradient descent (AGD) with fixed step size $\eta > 0$, applied to the asymmetric matrix factorization objective. We show that, for a rank-$r$ matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$, $T = \left( \left(\frac{\sigma_1(\mathbf{A})}{\sigma_r(\mathbf{A})}\right)^2 \log(1/\epsilon)\right)$ iterations of alternating gradient descent suffice to reach an $\epsilon$-optimal factorization $\| \mathbf{A} \mathbf{X}_T^{\vphantom{\intercal}} \mathbf{Y}_T^{\intercal} \|_{\rm F}^2 \leq \epsilon \| \mathbf{A} \|_{\rm F}^2$ with high probability starting from an atypical random initialization. The factors have rank $d>r$ so that $\mathbf{X}_T\in\mathbb{R}^{m \times d}$ and $\mathbf{Y}_T \in\mathbb{R}^{n \times d}$. Experiments suggest that our proposed initialization is not merely of theoretical benefit, but rather significantly improves convergence of gradient descent in practice. Our proof is conceptually simple: a uniform PL-inequality and uniform Lipschitz smoothne
    
[^3]: 将因果发现重新解释为预测未观察到的联合统计量的任务

    Reinterpreting causal discovery as the task of predicting unobserved joint statistics. (arXiv:2305.06894v1 [stat.ML])

    [http://arxiv.org/abs/2305.06894](http://arxiv.org/abs/2305.06894)

    研究者提出将因果发现视为预测未观察到联合统计量的任务，这样可以更好地推断未观察到集合的属性。

    

    如果$X,Y,Z$表示随机变量集，不同的数据源可以包含$P_{X,Y}$和$P_{Y,Z}$的样本。我们认为因果发现可以帮助推断“未观察到的联合分布”$P_{X,Y,Z}$或$P_{X,Z}$的性质。这些性质可以是条件独立性（如“整合因果推理”中那样），也可以是关于依赖性的定量说明。更一般地，我们定义了一个学习场景，其中输入是变量的子集，标签是该子集的某些统计属性。共同观测变量集定义了训练点，而未观察到的集合是可能的测试点。为了解决这个学习任务，我们从观察结果中推断出一个因果模型，这个因果模型可以得到未观察到集合的属性。因此，我们可以定义一个因果模型类的VC维，并为预测推导出泛化界限。因此，因果发现变得更加谦逊和易于访问。

    If $X,Y,Z$ denote sets of random variables, two different data sources may contain samples from $P_{X,Y}$ and $P_{Y,Z}$, respectively. We argue that causal discovery can help inferring properties of the `unobserved joint distributions' $P_{X,Y,Z}$ or $P_{X,Z}$. The properties may be conditional independences (as in `integrative causal inference') or also quantitative statements about dependences.  More generally, we define a learning scenario where the input is a subset of variables and the label is some statistical property of that subset. Sets of jointly observed variables define the training points, while unobserved sets are possible test points. To solve this learning task, we infer, as an intermediate step, a causal model from the observations that then entails properties of unobserved sets. Accordingly, we can define the VC dimension of a class of causal models and derive generalization bounds for the predictions.  Here, causal discovery becomes more modest and better accessible 
    
[^4]: 通过无替换加权抽样进行风险限制财务审计

    Risk-limiting Financial Audits via Weighted Sampling without Replacement. (arXiv:2305.06884v1 [stat.ME])

    [http://arxiv.org/abs/2305.06884](http://arxiv.org/abs/2305.06884)

    本文介绍了一种通过构建新的加权抽样信心序列，对N个未知值的加权平均值进行估计的风险限制财务审计（RLFA）。该方法可以通过合并未知值的附加信息提高生成序列的质量，从而提高估计的准确性和置信度。

    

    我们介绍了风险限制财务审计（RLFA）的概念：在给定误差$\epsilon$和置信度$1-\delta$的情况下，通过构建新的加权抽样信心序列（CSs），对$N$个未知值的加权平均值进行估计。我们利用重要权重的想法构建测试鞅，首先开发了一个框架，以构建任意抽样策略的CSs。接下来，我们开发了一些方法来通过合并与每个项目关联的未知值的附加信息来提高CSs的质量。当附加信息足够具有预测性时，我们表明它可以直接驱动抽样。对于精度未知的情况，我们引入一种通过控制变量使用附加信息的方法。关键的是，我们的构建是自适应的。

    We introduce the notion of a risk-limiting financial auditing (RLFA): given $N$ transactions, the goal is to estimate the total misstated monetary fraction~($m^*$) to a given accuracy $\epsilon$, with confidence $1-\delta$. We do this by constructing new confidence sequences (CSs) for the weighted average of $N$ unknown values, based on samples drawn without replacement according to a (randomized) weighted sampling scheme. Using the idea of importance weighting to construct test martingales, we first develop a framework to construct CSs for arbitrary sampling strategies. Next, we develop methods to improve the quality of CSs by incorporating side information about the unknown values associated with each item. We show that when the side information is sufficiently predictive, it can directly drive the sampling. Addressing the case where the accuracy is unknown a priori, we introduce a method that incorporates side information via control variates. Crucially, our construction is adaptive
    
[^5]: 基于角度信息的神经生存分析模型嵌入空间可视化的通用框架

    A General Framework for Visualizing Embedding Spaces of Neural Survival Analysis Models Based on Angular Information. (arXiv:2305.06862v1 [stat.ML])

    [http://arxiv.org/abs/2305.06862](http://arxiv.org/abs/2305.06862)

    本文提出了一种通用框架，可以可视化任何神经生存分析模型所使用的中间嵌入表示。该框架基于嵌入空间中的锚定方向，可用于表格数据和原始输入（例如图像）。本文说明了在一个基于角度信息的嵌入空间中存在的信息丢失问题，并提供了减少信息丢失的实用方法。

    

    我们提出了一个通用框架，用于可视化神经生存分析模型所使用的任何中间嵌入表示。我们的框架基于嵌入空间中的所谓锚定方向。我们展示了如何使用聚类或用户提供的“概念”来定义原始输入（例如，来自女性患者的特征向量可以编码“女性”概念）来估计这些锚定方向。对于表格数据，我们提供了可视化策略，以显示锚定方向与原始临床特征和生存时间分布之间的关系。然后，我们展示了这些可视化思想如何扩展到处理图像等原始输入。我们的框架是基于查看嵌入空间中向量之间的角度建立的，由于忽略了幅度信息而可能存在“信息丢失”，我们展示了在实践中如何减少这种信息丢失导致的“聚集”伪影。

    We propose a general framework for visualizing any intermediate embedding representation used by any neural survival analysis model. Our framework is based on so-called anchor directions in an embedding space. We show how to estimate these anchor directions using clustering or, alternatively, using user-supplied "concepts" defined by collections of raw inputs (e.g., feature vectors all from female patients could encode the concept "female"). For tabular data, we present visualization strategies that reveal how anchor directions relate to raw clinical features and to survival time distributions. We then show how these visualization ideas extend to handling raw inputs that are images. Our framework is built on looking at angles between vectors in an embedding space, where there could be "information loss" by ignoring magnitude information. We show how this loss results in a "clumping" artifact that appears in our visualizations, and how to reduce this information loss in practice.
    
[^6]: 通过连续方式隐式优化的政策梯度算法

    Policy Gradient Algorithms Implicitly Optimize by Continuation. (arXiv:2305.06851v1 [cs.LG])

    [http://arxiv.org/abs/2305.06851](http://arxiv.org/abs/2305.06851)

    本文提供了政策梯度算法的新理论解释和证明，即政策梯度算法可以通过连续方式隐式优化确定性策略，并指出政策梯度算法探索的实质是计算当前策略收益的连续函数，策略的方差应该是历史依赖性函数。

    

    强化学习中的直接策略优化通常通过政策梯度算法解决，该算法通过随机梯度上升优化策略参数。本文提供了一种新的理论解释和证明这些算法的方法。首先，我们将直接策略优化问题建立在优化连续框架下。后者是一种用于优化非凸函数的框架，其中以连续的替代目标函数序列为基础。其次，我们证明了优化仿射高斯策略并执行熵正则化可以解释为通过连续隐式地优化确定性策略。基于这些理论结果，我们认为政策梯度算法中的探索包括计算当前的策略收益的连续函数，策略的方差应该是历史依赖性函数，以避免局部最值而不是仅仅最大化政策的收益。

    Direct policy optimization in reinforcement learning is usually solved with policy-gradient algorithms, which optimize policy parameters via stochastic gradient ascent. This paper provides a new theoretical interpretation and justification of these algorithms. First, we formulate direct policy optimization in the optimization by continuation framework. The latter is a framework for optimizing nonconvex functions where a sequence of surrogate objective functions, called continuations, are locally optimized. Second, we show that optimizing affine Gaussian policies and performing entropy regularization can be interpreted as implicitly optimizing deterministic policies by continuation. Based on these theoretical results, we argue that exploration in policy-gradient algorithms consists in computing a continuation of the return of the policy at hand, and that the variance of policies should be history-dependent functions adapted to avoid local extrema rather than to maximize the return of th
    
[^7]: 多智能体强化学习中的信息设计

    Information Design in Multi-Agent Reinforcement Learning. (arXiv:2305.06807v1 [cs.GT])

    [http://arxiv.org/abs/2305.06807](http://arxiv.org/abs/2305.06807)

    本文探究了多智能体强化学习中的信息设计问题及其挑战，提出了“马尔科夫信令博弈”的概念。

    

    强化学习（RL）模仿人类和动物与环境交互的方式。然而实际环境中存在其他有自己目标的智能体，它们会适应地与自己相互作用。因此，为了在这些环境中成功，自主智能体需要影响其他智能体以使它们的行为更有益。信息设计是影响其他智能体行为的一种方法。本文探讨了针对一组RL代理的信息设计问题，并提出了“马尔科夫信令博弈”的概念。

    Reinforcement learning (RL) mimics how humans and animals interact with the environment. The setting is somewhat idealized because, in actual tasks, other agents in the environment have their own goals and behave adaptively to the ego agent. To thrive in those environments, the agent needs to influence other agents so their actions become more helpful and less harmful. Research in computational economics distills two ways to influence others directly: by providing tangible goods (mechanism design) and by providing information (information design). This work investigates information design problems for a group of RL agents. The main challenges are two-fold. One is the information provided will immediately affect the transition of the agent trajectories, which introduces additional non-stationarity. The other is the information can be ignored, so the sender must provide information that the receivers are willing to respect. We formulate the Markov signaling game, and develop the notions 
    
[^8]: 在神经网络模型中集成最近邻居以估计治疗效果

    Integrating nearest neighbors on neural network models for treatment effect estimation. (arXiv:2305.06789v1 [stat.ML])

    [http://arxiv.org/abs/2305.06789](http://arxiv.org/abs/2305.06789)

    本论文提出了一种新的方法NNCI，用于将最近邻居信息集成到神经网络模型中，以更准确地估计治疗效果。

    

    治疗效果估计对于许多科学和工业领域的研究人员和从业者来说具有高度重要性。观察数据的丰富性使它们越来越受到研究人员用于因果效应的估计。然而，这些数据存在偏差和其他弱点，导致如果不正确处理，估计因果效应会不准确。因此，提出了几种机器学习技术，其中大部分都专注于利用神经网络模型的预测能力，以达到更精确的因果效应估计。在本文中，我们提出了一种名为最近邻居信息用于因果推断（NNCI）的新方法，用于将有价值的最近邻居信息集成到基于神经网络的模型中，以估计治疗效果。提出的NNCI方法被应用于一些最广泛使用的基于神经网络的治疗效果估计模型，其使用观察数据。

    Treatment effect estimation is of high-importance for both researchers and practitioners across many scientific and industrial domains. The abundance of observational data makes them increasingly used by researchers for the estimation of causal effects. However, these data suffer from biases, from several weaknesses, leading to inaccurate causal effect estimations, if not handled properly. Therefore, several machine learning techniques have been proposed, most of them focusing on leveraging the predictive power of neural network models to attain more precise estimation of causal effects. In this work, we propose a new methodology, named Nearest Neighboring Information for Causal Inference (NNCI), for integrating valuable nearest neighboring information on neural network-based models for estimating treatment effects. The proposed NNCI methodology is applied to some of the most well established neural network-based models for treatment effect estimation with the use of observational data
    
[^9]: 针对线性和非线性重尾多臂老虎机的隐式范数预测器的修剪

    Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits. (arXiv:2305.06743v1 [cs.LG])

    [http://arxiv.org/abs/2305.06743](http://arxiv.org/abs/2305.06743)

    本文提出了一种针对奖励分布重尾的MAB问题的隐式规范化预测器，证明该方法在线性和非线性重尾随机MAB问题上是最优的。

    

    已知隐式范数预测器（在线镜像下降，以Tsallis熵作为prox函数）是对抗性多臂老虎机问题（MAB）的最佳算法。但是，大多数复杂性结果都依赖于有界奖励或其他限制性假设。最近有关最佳二者结合算法的研究已经针对对手性和随机重尾MAB设置进行了探讨。这个算法在这两种情况下都是最优的，但不能充分利用数据。在本文中，我们针对奖励分布重尾的MAB问题提出了带剪辑的隐式规范化预测器。我们在奖励分布上提出渐进收敛性结果，并证明所提出的方法对于线性和非线性重尾随机MAB问题是最优的。我们还证明了与最好的二者结合算法相比，该算法通常表现更好。

    Implicitly Normalized Forecaster (online mirror descent with Tsallis entropy as prox-function) is known to be an optimal algorithm for adversarial multi-armed problems (MAB). However, most of the complexity results rely on bounded rewards or other restrictive assumptions. Recently closely related best-of-both-worlds algorithm were proposed for both adversarial and stochastic heavy-tailed MAB settings. This algorithm is known to be optimal in both settings, but fails to exploit data fully. In this paper, we propose Implicitly Normalized Forecaster with clipping for MAB problems with heavy-tailed distribution on rewards. We derive convergence results under mild assumptions on rewards distribution and show that the proposed method is optimal for both linear and non-linear heavy-tailed stochastic MAB problems. Also we show that algorithm usually performs better compared to best-of-two-worlds algorithm.
    
[^10]: NUBO：一个透明的 Python 包用于贝叶斯优化

    NUBO: A Transparent Python Package for Bayesian Optimisation. (arXiv:2305.06709v1 [cs.LG])

    [http://arxiv.org/abs/2305.06709](http://arxiv.org/abs/2305.06709)

    NUBO是一个透明的Python包，用于优化昂贵的黑盒函数，它利用高斯过程做代理模型以及获取函数来指导选择候选点，专注于透明度和用户体验。

    

    NUBO（Newcastle University Bayesian Optimisation）是一个贝叶斯优化框架，用于优化昂贵的黑盒函数，比如物理实验和计算机模拟器。它利用高斯过程做代理模型、并通过获取函数来选择用于全局最优化的候选点。NUBO专注于透明度和用户体验，以便让不同领域的研究人员更容易使用贝叶斯优化。

    NUBO, short for Newcastle University Bayesian Optimisation, is a Bayesian optimisation framework for the optimisation of expensive-to-evaluate black-box functions, such as physical experiments and computer simulators. Bayesian optimisation is a cost-efficient optimisation strategy that uses surrogate modelling via Gaussian processes to represent an objective function and acquisition functions to guide the selection of candidate points to approximate the global optimum of the objective function. NUBO itself focuses on transparency and user experience to make Bayesian optimisation easily accessible to researchers from all disciplines. Clean and understandable code, precise references, and thorough documentation ensure transparency, while user experience is ensured by a modular and flexible design, easy-to-write syntax, and careful selection of Bayesian optimisation algorithms. NUBO allows users to tailor Bayesian optimisation to their specific problem by writing the optimisation loop the
    
[^11]: 滞后多因子模型中领先滞后关系的鲁棒检测

    Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models. (arXiv:2305.06704v1 [stat.ML])

    [http://arxiv.org/abs/2305.06704](http://arxiv.org/abs/2305.06704)

    该论文提出了一种基于聚类的鲁棒检测滞后多因子模型中的领先滞后关系方法，并使用各种聚类技术和相似度度量方法实现了对领先滞后估计的聚合，从而强化了对原始宇宙中的一致关系的识别。

    

    在多元时间序列系统中，通过发现数据中固有的领先滞后关系，可以获得关键信息，这指的是两个相对时间互移的时间序列之间的依赖关系，可以用于控制、预测或聚类。我们开发了一种基于聚类的方法，用于鲁棒检测滞后多因子模型中的领先滞后关系。在我们的框架中，所设想的管道接收一组时间序列作为输入，并使用滑动窗口方法从每个输入时间序列中提取一组子序列时间序列。然后，我们应用各种聚类技术（例如K-means++和谱聚类），采用各种成对相似性度量，包括非线性的相似性度量。一旦聚类被提取出来，跨聚类的领先滞后估计被聚合起来，以增强对原始宇宙中一致关系的识别。由于多

    In multivariate time series systems, key insights can be obtained by discovering lead-lag relationships inherent in the data, which refer to the dependence between two time series shifted in time relative to one another, and which can be leveraged for the purposes of control, forecasting or clustering. We develop a clustering-driven methodology for the robust detection of lead-lag relationships in lagged multi-factor models. Within our framework, the envisioned pipeline takes as input a set of time series, and creates an enlarged universe of extracted subsequence time series from each input time series, by using a sliding window approach. We then apply various clustering techniques (e.g, K-means++ and spectral clustering), employing a variety of pairwise similarity measures, including nonlinear ones. Once the clusters have been extracted, lead-lag estimates across clusters are aggregated to enhance the identification of the consistent relationships in the original universe. Since multi
    
[^12]: 竞争风险的单调神经网络：用于生存分析的模型

    Neural Fine-Gray: Monotonic neural networks for competing risks. (arXiv:2305.06703v1 [cs.LG])

    [http://arxiv.org/abs/2305.06703](http://arxiv.org/abs/2305.06703)

    本文提出了一种使用单调约束神经网络模拟每种竞争生存率分布的方法，从而确保可以在计算成本下实现精确的最大似然值最优化，该方法可以用于生存分析领域。

    

    生存分析是一种处理患者因未经历感兴趣事件而出现的“censoring”的时间至事件模型。机器学习算法在此类问题中表现突出，但往往忽略了竞争风险对感兴趣事件的影响，从而导致生存率估计存在偏差。本文提出了一种使用单调约束神经网络模拟每种竞争生存率分布的方法，确保采用自动微分方法能够在计算成本下实现精确的最大似然值最优化。通过效果实验对比完成了一个合成数据和三个医学数据集的生存数据分析。最后讨论了在开发医疗实践风险评估指标时考虑竞争风险的意义。

    Time-to-event modelling, known as survival analysis, differs from standard regression as it addresses censoring in patients who do not experience the event of interest. Despite competitive performances in tackling this problem, machine learning methods often ignore other competing risks that preclude the event of interest. This practice biases the survival estimation. Extensions to address this challenge often rely on parametric assumptions or numerical estimations leading to sub-optimal survival approximations. This paper leverages constrained monotonic neural networks to model each competing survival distribution. This modelling choice ensures the exact likelihood maximisation at a reduced computational cost by using automatic differentiation. The effectiveness of the solution is demonstrated on one synthetic and three medical datasets. Finally, we discuss the implications of considering competing risks when developing risk scores for medical practice.
    
[^13]: 神经常微分方程与深度残差网络的泛化界限

    Generalization bounds for neural ordinary differential equations and deep residual networks. (arXiv:2305.06648v1 [stat.ML])

    [http://arxiv.org/abs/2305.06648](http://arxiv.org/abs/2305.06648)

    本研究提出了神经常微分方程及其变体的泛化界限，涵盖了深度残差网络，其泛化界限与连续权重差异大小有关。

    

    神经常微分方程（Neural ODEs）是一类流行的连续深度深度学习模型。本文考虑了一个由连续时间参数化的ODE及时变的神经ODE组成的大类。我们通过Lipschitz方法推导了这个类别的泛化界限。通过利用神经ODE和深度残差网络之间的类比，我们的方法得到了一个深度残差网络的泛化界限。这个界限与连续权重之间的差异的大小有关。我们通过数值结果演示了这个量是如何影响神经网络的泛化能力的。

    Neural ordinary differential equations (neural ODEs) are a popular family of continuous-depth deep learning models. In this work, we consider a large family of parameterized ODEs with continuous-in-time parameters, which include time-dependent neural ODEs. We derive a generalization bound for this class by a Lipschitz-based argument. By leveraging the analogy between neural ODEs and deep residual networks, our approach yields in particular a generalization bound for a class of deep residual networks. The bound involves the magnitude of the difference between successive weight matrices. We illustrate numerically how this quantity affects the generalization capability of neural networks.
    
[^14]: 基于双指数族的扩展广义线性模型中的Dropout正则化

    Dropout Regularization in Extended Generalized Linear Models based on Double Exponential Families. (arXiv:2305.06625v1 [stat.ML])

    [http://arxiv.org/abs/2305.06625](http://arxiv.org/abs/2305.06625)

    本论文研究了基于双指数族的扩展广义线性模型中的dropout正则化，dropout正则化偏好罕见但重要的特征，在均值和离散度方面都具有普适性。

    

    尽管dropout是一种流行的正则化技术，但其理论性质尚未被充分理解。本文研究了基于双指数族的扩展广义线性模型中的dropout正则化，其中离散参数可以随特征变化。理论分析表明，dropout正则化偏好罕见但重要的特征，在均值和离散度方面都具有普适性，这扩展了之前针对传统广义线性模型的结果 。采用自适应学习率的随机梯度下降进行训练。为了说明这一点，我们将dropout应用于自适应B样条平滑，其中均值和离散度参数都被灵活地建模。重要的B样条基础函数可以被认为是罕见的特征，我们在实验中证实，dropout是一种改善了罚最大似然方法的显式平滑性的均值和离散度参数的有效正则化形式。

    Even though dropout is a popular regularization technique, its theoretical properties are not fully understood. In this paper we study dropout regularization in extended generalized linear models based on double exponential families, for which the dispersion parameter can vary with the features. A theoretical analysis shows that dropout regularization prefers rare but important features in both the mean and dispersion, generalizing an earlier result for conventional generalized linear models. Training is performed using stochastic gradient descent with adaptive learning rate. To illustrate, we apply dropout to adaptive smoothing with B-splines, where both the mean and dispersion parameters are modelled flexibly. The important B-spline basis functions can be thought of as rare features, and we confirm in experiments that dropout is an effective form of regularization for mean and dispersion parameters that improves on a penalized maximum likelihood approach with an explicit smoothness p
    
[^15]: 基于流形正则化 Tucker 分解的时空交通数据填充方法

    Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation. (arXiv:2305.06563v1 [stat.ML])

    [http://arxiv.org/abs/2305.06563](http://arxiv.org/abs/2305.06563)

    本文提出了一种基于流形正则化Tucker分解的时空交通数据填充方法，该方法利用稀疏正则化项改善了Tucker核的稀疏性，并引入流形正则化和时间约束项来优化张量的填充性能。

    

    时空交通数据填充(STDI)是数据驱动智能交通系统中不可避免和具有挑战性的任务，在部分观测到的交通数据中估计丢失数据。由于交通数据具有多维和时空性质，我们将丢失数据填充视为张量完成问题。过去十年中，许多关于基于张量分解的 STDI 的研究已经展开。然而，如何利用时空相关性和核张量稀疏性来改善填充性能仍然需要解决。本文重新构造了3/4阶汉克尔张量，并提出了一种创新的流形正则化 Tucker 分解(maniRTD)模型用于STDI。明确地，我们通过引入多维延迟嵌入变换将传感交通状态数据表示为3/4阶张量。然后，ManiRTD使用稀疏正则化项改善了Tucker核的稀疏性，并使用流形正则化和时间约束项来优化张量的填充性能。

    Spatiotemporal traffic data imputation (STDI), estimating the missing data from partially observed traffic data, is an inevitable and challenging task in data-driven intelligent transportation systems (ITS). Due to traffic data's multidimensional and spatiotemporal properties, we treat the missing data imputation as a tensor completion problem. Many studies have been on STDI based on tensor decomposition in the past decade. However, how to use spatiotemporal correlations and core tensor sparsity to improve the imputation performance still needs to be solved. This paper reshapes a 3rd/4th order Hankel tensor and proposes an innovative manifold regularized Tucker decomposition (ManiRTD) model for STDI. Expressly, we represent the sensory traffic state data as the 3rd/4th tensors by introducing Multiway Delay Embedding Transforms. Then, ManiRTD improves the sparsity of the Tucker core using a sparse regularization term and employs manifold regularization and temporal constraint terms of f
    
[^16]: 神经网络有效理论的结构

    Structures of Neural Network Effective Theories. (arXiv:2305.02334v1 [hep-th])

    [http://arxiv.org/abs/2305.02334](http://arxiv.org/abs/2305.02334)

    该论文提出了一种简化深度神经网络有效场论计算的图解方法，并指出单一条件决定了所有神经元预激活的关联函数的临界性，这可能有助于推动深度学习和场论模拟的进展。

    

    我们提出了一种图解方法，用于研究深度神经网络初始状态下的有效场论（EFT），这种方法可以极大地简化计算有限宽度修正神经元统计量的过程。EFT计算的结构使得所有神经元预激活的关联函数的临界性都受到单一条件的控制。理解这样的EFT可能有助于进展深度学习和场论模拟。

    We develop a diagrammatic approach to effective field theories (EFTs) corresponding to deep neural networks at initialization, which dramatically simplifies computations of finite-width corrections to neuron statistics. The structures of EFT calculations make it transparent that a single condition governs criticality of all connected correlators of neuron preactivations. Understanding of such EFTs may facilitate progress in both deep learning and field theory simulations.
    
[^17]: 通过独热编码和正则化提高梯度提升决策树的鲁棒性

    Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization. (arXiv:2304.13761v1 [stat.ML])

    [http://arxiv.org/abs/2304.13761](http://arxiv.org/abs/2304.13761)

    通过独热编码和正则化提高梯度提升决策树的鲁棒性，研究表明对带有$L_1$或$L_2$正则化的线性回归形式进行拟合可提高GBDT模型的鲁棒性。

    

    梯度提升决策树(GBDT)是一种广泛应用的高效机器学习方法，用于表格数据建模。然而，它们复杂的结构可能导致模型对未见数据中的小协变量扰动的鲁棒性较低。本研究应用独热编码将GBDT模型转换为线性框架，通过将每个树叶编码为一个虚拟变量。这允许使用线性回归技术，以及一种新颖的风险分解方法来评估GBDT模型对协变量扰动的鲁棒性。我们建议通过重新拟合其带有$L_1$或$L_2$正则化的线性回归形式，提高GBDT模型的鲁棒性。理论结果表明了正则化对模型性能和鲁棒性的影响。在数值实验中，证明了所提出的正则化方法可以提高独热编码GBDT模型的鲁棒性。

    Gradient-boosted decision trees (GBDT) are widely used and highly effective machine learning approach for tabular data modeling. However, their complex structure may lead to low robustness against small covariate perturbation in unseen data. In this study, we apply one-hot encoding to convert a GBDT model into a linear framework, through encoding of each tree leaf to one dummy variable. This allows for the use of linear regression techniques, plus a novel risk decomposition for assessing the robustness of a GBDT model against covariate perturbations. We propose to enhance the robustness of GBDT models by refitting their linear regression forms with $L_1$ or $L_2$ regularization. Theoretical results are obtained about the effect of regularization on the model performance and robustness. It is demonstrated through numerical experiments that the proposed regularization approach can enhance the robustness of the one-hot-encoded GBDT models.
    
[^18]: 更多通信不会使联邦学习中的泛化误差变小。

    More Communication Does Not Result in Smaller Generalization Error in Federated Learning. (arXiv:2304.12216v1 [stat.ML])

    [http://arxiv.org/abs/2304.12216](http://arxiv.org/abs/2304.12216)

    我们研究了联邦学习环境下的统计学习模型泛化误差，表明更频繁地与参数服务器通信会负面影响此类学习算法的泛化性能。

    

    我们研究了联邦学习（FL）环境下统计学习模型的泛化误差。具体而言，有$K$个设备或客户端，每个设备持有一个大小为$n$的独立数据集。通过随机梯度下降本地学习的个体模型通过一个中央服务器进行聚合（平均），然后发送回设备。我们考虑多次（比如说$R\in \mathbb{N}^*$）模型聚合并研究$R$对最终聚合模型的泛化误差的影响。我们建立了一个上界，明确考虑了$R$（除了参与设备的数量$K$和数据集大小$n$）的影响。观察到对于固定的$(n,K)$，上界随$R$的增加而增加，这表明更频繁地与参数服务器通信会负面影响此类学习算法的泛化性能。与此同时，由于经验风险通常只随着$n$的增加而减少，因此我们的理论证明了为了在FL中实现良好的泛化性能，需要权衡本地学习和全局聚合之间的权衡。

    We study the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, there are $K$ devices or clients, each holding an independent own dataset of size $n$. Individual models, learned locally via Stochastic Gradient Descent, are aggregated (averaged) by a central server into a global model and then sent back to the devices. We consider multiple (say $R \in \mathbb N^*$) rounds of model aggregation and study the effect of $R$ on the generalization error of the final aggregated model. We establish an upper bound on the generalization error that accounts explicitly for the effect of $R$ (in addition to the number of participating devices $K$ and dataset size $n$). It is observed that, for fixed $(n, K)$, the bound increases with $R$, suggesting that the generalization of such learning algorithms is negatively affected by more frequent communication with the parameter server. Combined with the fact that the empirical risk, however, generally d
    
[^19]: 使用VAE学习潜在变量：在cryo-EM中的应用观察（arXiv:2303.07487v1 [stat.ML]）

    Using VAEs to Learn Latent Variables: Observations on Applications in cryo-EM. (arXiv:2303.07487v1 [stat.ML])

    [http://arxiv.org/abs/2303.07487](http://arxiv.org/abs/2303.07487)

    本研究通过定性分析，发现VAE在生物应用中摊销潜在变量的特性与传统显式表示方法相似。

    

    变分自编码器（VAEs）是一种流行的生成模型，用于近似分布。VAE的编码器部分用于认证学习潜在变量，为数据样本生成潜在表示。最近，VAEs已用于表征物理和生物系统。在这个案例研究中，我们定性地研究了VAE在生物应用中的摊销特性。我们发现，在这种应用中，编码器与更传统的显式潜在变量表示具有定性相似性。

    Variational autoencoders (VAEs) are a popular generative model used to approximate distributions. The encoder part of the VAE is used in amortized learning of latent variables, producing a latent representation for data samples. Recently, VAEs have been used to characterize physical and biological systems. In this case study, we qualitatively examine the amortization properties of a VAE used in biological applications. We find that in this application the encoder bears a qualitative resemblance to more traditional explicit representation of latent variables.
    
[^20]: 测试反事实场景：揭示在公平原则下的歧视差异 (arXiv:2302.11944v2 [stat.ML] UPDATED)

    Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference. (arXiv:2302.11944v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.11944](http://arxiv.org/abs/2302.11944)

    我们提出了一种反事实场景测试框架，通过比较数据集中类似的保护和非保护实例来检测分类器中的歧视，通过比较组间决策结果差异，来发现个人歧视。该框架可以更好地对「给定差异的公平原则」进行操作，以揭示在公平原则下的歧视差异。

    

    我们提出了一种被称为反事实场景测试(CST)的因果数据挖掘框架来检测分类器中的歧视情况。CST旨在以可操作且有意义的方式回答一种直观问题：“如果个人或投诉人所属的受保护身份不同，模型的结果将会是什么？”它通过反事实推理来对法律基础的情景测试进行扩展，以操作“给定差异的公平原则”的概念。对于任何投诉人，我们在分类器使用的数据集中找到并比较相似的受保护和非受保护实例，构造控制组和测试组，两组的决策结果差异意味着潜在的个人歧视。与情境测试不同，情境测试是围绕投诉人构建两组，我们根据因果知识在投诉人的反事实生成测试组。反事实旨在反映受保护属性对结果的影响。

    We present counterfactual situation testing (CST), a causal data mining framework for detecting discrimination in classifiers. CST aims to answer in an actionable and meaningful way the intuitive question "what would have been the model outcome had the individual, or complainant, been of a different protected status?" It extends the legally-grounded situation testing of Thanh et al. (2011) by operationalizing the notion of fairness given the difference using counterfactual reasoning. For any complainant, we find and compare similar protected and non-protected instances in the dataset used by the classifier to construct a control and test group, where a difference between the decision outcomes of the two groups implies potential individual discrimination. Unlike situation testing, which builds both groups around the complainant, we build the test group on the complainant's counterfactual generated using causal knowledge. The counterfactual is intended to reflect how the protected attrib
    
[^21]: 不精确的贝叶斯神经网络

    Imprecise Bayesian Neural Networks. (arXiv:2302.09656v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09656](http://arxiv.org/abs/2302.09656)

    在机器学习和人工智能领域，该论文提出了一种新的算法——不精确的贝叶斯神经网络(IBNNs)。这种算法使用可信区间先验分布集合和似然分布集合进行训练，相比标准的BNNs，可以区分先验和后验的不确定性并量化。此外，IBNNs在贝叶斯灵敏度分析方面具有更强的鲁棒性，并且对分布变化也更加鲁棒。

    

    在机器学习和人工智能中, 确定不确定性和鲁棒性是重要的目标。虽然贝叶斯神经网络使得预测中的不确定性能够被评估，不同来源的不确定性是无法区分的。我们提出了不精确的贝叶斯神经网络（IBNNs），它们可以概括和克服标准BNNs的某些缺点。标准BNNs使用单一的先验分布和似然分布进行训练，而IBNNs使用可信区间先验分布和似然分布进行训练。它们允许区分先验和后验不确定性，并对其进行量化。此外，IBNNs在贝叶斯灵敏度分析方面具有鲁棒性，并且对分布变化比标准BNNs更加鲁棒。它们还可以用于计算具有PAC样本复杂性的结果集。我们将IBNNs应用于两个案例研究：一个是为了人工胰腺控制模拟血糖和胰岛素动力学，另一个是运动规划。

    Uncertainty quantification and robustness to distribution shifts are important goals in machine learning and artificial intelligence. Although Bayesian neural networks (BNNs) allow for uncertainty in the predictions to be assessed, different sources of uncertainty are indistinguishable. We present imprecise Bayesian neural networks (IBNNs); they generalize and overcome some of the drawbacks of standard BNNs. These latter are trained using a single prior and likelihood distributions, whereas IBNNs are trained using credal prior and likelihood sets. They allow to distinguish between aleatoric and epistemic uncertainties, and to quantify them. In addition, IBNNs are robust in the sense of Bayesian sensitivity analysis, and are more robust than BNNs to distribution shift. They can also be used to compute sets of outcomes that enjoy PAC-like properties. We apply IBNNs to two case studies. One, to model blood glucose and insulin dynamics for artificial pancreas control, and two, for motion p
    
[^22]: 基于注意力及反向技术的信道预测方法

    Reverse Ordering Techniques for Attention-Based Channel Prediction. (arXiv:2302.00341v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00341](http://arxiv.org/abs/2302.00341)

    本文提出了基于Seq2Seq-attn和Transformer的信道预测模型，并引入了反向技术以提高模型鲁棒性，仿真结果表明比现有方法更好。

    

    本文旨在利用序列到序列模型（Seq2Seq-attn）和Transformer模型，基于噪声观测来预测无线通信系统中的信道。两种模型都是从自然语言处理中改编而来，以应对信道预测的复杂挑战。此外，还引入了一种称为“反向位置编码”的新技术以提高Transformer模型在不同序列长度下的鲁棒性。类似地，在应用注意力之前，Seq2Seq-attn模型的编码器输出也会被翻转。仿真结果表明，所提出的反向技术使模型能够更好地捕捉序列中信道瞬间之间的关系，无论序列长度如何，与现有方法相比有更好的效果。

    This work aims to predict channels in wireless communication systems based on noisy observations, utilizing sequence-to-sequence models with attention (Seq2Seq-attn) and transformer models. Both models are adapted from natural language processing to tackle the complex challenge of channel prediction. Additionally, a new technique called reverse positional encoding is introduced in the transformer model to improve the robustness of the model against varying sequence lengths. Similarly, the encoder outputs of the Seq2Seq-attn model are reversed before applying attention. Simulation results demonstrate that the proposed ordering techniques allow the models to better capture the relationships between the channel snapshots within the sequence, irrespective of the sequence length, as opposed to existing methods.
    
[^23]: 用神经点过程预测2016-2017年中央阿彭宁地震序列

    Forecasting the 2016-2017 Central Apennines Earthquake Sequence with a Neural Point Process. (arXiv:2301.09948v2 [physics.geo-ph] UPDATED)

    [http://arxiv.org/abs/2301.09948](http://arxiv.org/abs/2301.09948)

    本文利用神经点过程模型对2016-2017年阿彭宁地震序列进行了预测，结果表明神经模型优于传统ETAS模型，可以应用于短期地震预报。

    

    近几十年来，点过程一直是地震活动演化建模领域的主流方法，其中Epidemic Type Aftershock Sequence (ETAS)模型最为流行。近年来，机器学习的不断发展利用神经网络构建高度灵活的点过程模型以改进现有的参数模型。本文通过将现有的时间神经模型扩展到震级领域，探究这些灵活的点过程模型是否可以应用于短期地震预报，并展示此模型如何预测高于目标震级阈值的地震。本文首先证明了神经模型可以拟合ETAS合成数据，且需要较少的计算时间，因为它不依赖于整个序列的完整历史。通过在合成数据集中模拟短期余震不完整性，我们发现神经模型的表现优于ETAS。利用2016-2017年中央阿彭宁地震序列的新增强目录，我们预测了未来的地震活动。

    Point processes have been dominant in modeling the evolution of seismicity for decades, with the Epidemic Type Aftershock Sequence (ETAS) model being most popular. Recent advances in machine learning have constructed highly flexible point process models using neural networks to improve upon existing parametric models. We investigate whether these flexible point process models can be applied to short-term seismicity forecasting by extending an existing temporal neural model to the magnitude domain and we show how this model can forecast earthquakes above a target magnitude threshold. We first demonstrate that the neural model can fit synthetic ETAS data, however, requiring less computational time because it is not dependent on the full history of the sequence. By artificially emulating short-term aftershock incompleteness in the synthetic dataset, we find that the neural model outperforms ETAS. Using a new enhanced catalog from the 2016-2017 Central Apennines earthquake sequence, we inv
    
[^24]: 核子空间和特征提取

    Kernel Subspace and Feature Extraction. (arXiv:2301.01410v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01410](http://arxiv.org/abs/2301.01410)

    本文研究了机器学习中的核方法，建立了特征子空间和核之间的一一对应关系，并提出了一个信息熵度量方法用于核的比较。特别地，构建了一个极大相关核，并证明其在信息熵度量方面的最优性。最后，把Fisher核解释为一种特殊的极大相关核，并建立了它的最优性。

    

    本文从特征子空间的角度研究了机器学习中的核方法，建立了特征子空间和核之间的一一对应关系，并提出了一个信息熵度量方法用于核的比较。特别地，我们构建了一个由Hirschfeld-Gebelein-R\'{e}nyi极大相关函数构成的核，称之为极大相关核，并展示了它在信息熵度量方面的最优性。我们以支持向量机(SVM)为例，将核方法与特征提取方法联系起来，并表明在极大相关核上的核SVM具有最小预测误差。最后，我们把Fisher核解释为一种特殊的极大相关核，并建立了它的最优性。

    We study kernel methods in machine learning from the perspective of feature subspace. We establish a one-to-one correspondence between feature subspaces and kernels and propose an information-theoretic measure for kernels. In particular, we construct a kernel from Hirschfeld--Gebelein--R\'{e}nyi maximal correlation functions, coined the maximal correlation kernel, and demonstrate its information-theoretic optimality. We use the support vector machine (SVM) as an example to illustrate a connection between kernel methods and feature extraction approaches. We show that the kernel SVM on maximal correlation kernel achieves minimum prediction error. Finally, we interpret the Fisher kernel as a special maximal correlation kernel and establish its optimality.
    
[^25]: 从去噪扩散到去噪马尔科夫模型

    From Denoising Diffusions to Denoising Markov Models. (arXiv:2211.03595v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.03595](http://arxiv.org/abs/2211.03595)

    本论文提出了一个统一的框架，将去噪扩散模型推广到广泛的空间中，并导致分数匹配的原始扩展，适用于各种应用程序。

    

    去噪扩散是展现出卓越实验性能的最先进的生成模型。他们通过将数据分布扩散到高斯分布，然后学习逆转这个噪声过程以获取合成数据点。去噪扩散依赖于使用分数匹配对噪声数据密度的对数导数的逼近。当只能从先验分布和似然函数中进行抽样时，这种模型也可用于执行近似后验模拟。我们提出了一个统一框架，将此方法推广到一类广泛的空间，并导致分数匹配的原始扩展。我们通过各种应用程序说明了所得模型。

    Denoising diffusions are state-of-the-art generative models exhibiting remarkable empirical performance. They work by diffusing the data distribution into a Gaussian distribution and then learning to reverse this noising process to obtain synthetic datapoints. The denoising diffusion relies on approximations of the logarithmic derivatives of the noised data densities using score matching. Such models can also be used to perform approximate posterior simulation when one can only sample from the prior and likelihood. We propose a unifying framework generalising this approach to a wide class of spaces and leading to an original extension of score matching. We illustrate the resulting models on various applications.
    
[^26]: 带承诺和噪声观测的$2\times 2$零和博弈研究

    $2 \times 2$ Zero-Sum Games with Commitments and Noisy Observations. (arXiv:2211.01703v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2211.01703](http://arxiv.org/abs/2211.01703)

    本文研究了带承诺和噪声观测的$2\times 2$零和博弈，发现平衡点总是存在的；领导者的动作观测结果对于追随者来说要么是有益的，要么是无关紧要的；该博弈的收益在均衡点上被上界限制为纯策略下的SE的收益，下界为混合策略下的纳什均衡的收益。

    

    本文研究了在以下假设下的$2\times 2$零和博弈：$(1)$其中一位玩家（领导者）承诺通过采样给定的概率分布（策略）来选择他的动作;$(2)$领导者宣布他的动作，这个动作通过二进制信道被对手（追随者）观察到;$(3)$追随者基于领导者的策略和领导者动作的噪声观测来选择她的策略。在这些条件下，平衡点被证明总是存在的。有趣的是，即使受到噪声的影响，观察领导者的行动对追随者来说实质上要么是有益的，要么是无关紧要的。具体而言，在这个博弈的均衡点上，收益被上界限制为纯策略下SE的收益；并且下界为纳什均衡的收益，这等价于混合策略下的SE。最后，我们提供了必要和充分的条件来观察均衡点的收益。

    In this paper, $2\times2$ zero-sum games are studied under the following assumptions: $(1)$ One of the players (the leader) commits to choose its actions by sampling a given probability measure (strategy); $(2)$ The leader announces its action, which is observed by its opponent (the follower) through a binary channel; and $(3)$ the follower chooses its strategy based on the knowledge of the leader's strategy and the noisy observation of the leader's action. Under these conditions, the equilibrium is shown to always exist. Interestingly, even subject to noise, observing the actions of the leader is shown to be either beneficial or immaterial for the follower. More specifically, the payoff at the equilibrium of this game is upper bounded by the payoff at the Stackelberg equilibrium (SE) in pure strategies; and lower bounded by the payoff at the Nash equilibrium, which is equivalent to the SE in mixed strategies.Finally, necessary and sufficient conditions for observing the payoff at equi
    
[^27]: 贝叶斯赌博机问题的连续时间极限

    Continuous-in-time Limit for Bayesian Bandits. (arXiv:2210.07513v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.07513](http://arxiv.org/abs/2210.07513)

    本文提出了一种适用于解决大时间长度下的贝叶斯赌博机问题的近似贝叶斯最优策略，并且其计算成本不包括依赖于时间长度的项。

    

    本文重新审视了贝叶斯设置下的赌博机问题。贝叶斯方法将赌博机问题制定为一个优化问题，旨在寻找最优策略以最小化贝叶斯遗憾。面对的主要挑战之一是，当问题的时间长度或臂数较大时，计算最优策略通常是不可行的。我们首先展示了在适当的重缩放下，贝叶斯赌博机问题收敛于一个连续的哈密尔顿 - 雅各比 - 贝尔曼（HJB）方程。对于常见的一些赌博机问题，可以明确获得极限HJB方程的最优策略，并且在无法明确解决方案的情况下，我们提供了解决HJB方程的数字方法。基于这些结果，我们提出了一种适用于解决大时间长度下的贝叶斯赌博机问题的近似贝叶斯最优策略。我们的方法的计算成本不包括依赖于时间长度的项，这与现有方法不同。数值模拟表明了我们方法的有效性。

    This paper revisits the bandit problem in the Bayesian setting. The Bayesian approach formulates the bandit problem as an optimization problem, and the goal is to find the optimal policy which minimizes the Bayesian regret. One of the main challenges facing the Bayesian approach is that computation of the optimal policy is often intractable, especially when the length of the problem horizon or the number of arms is large. In this paper, we first show that under a suitable rescaling, the Bayesian bandit problem converges toward a continuous Hamilton-Jacobi-Bellman (HJB) equation. The optimal policy for the limiting HJB equation can be explicitly obtained for several common bandit problems, and we give numerical methods to solve the HJB equation when an explicit solution is not available. Based on these results, we propose an approximate Bayes-optimal policy for solving Bayesian bandit problems with large horizons. Our method has the added benefit that its computational cost does not inc
    
[^28]: 随机森林进行协方差回归分析

    Covariance regression with random forests. (arXiv:2209.08173v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2209.08173](http://arxiv.org/abs/2209.08173)

    基于随机森林框架的协方差回归分析(Covariance Regression with Random Forests, CovRegRF)被提出，可以用于估算在给定协变量情况下多元响应的协方差矩阵，并且提供了一个有关某些协变量偏效应的显著性检验方法。

    

    在包括神经科学、流行病学、生物医学等多个领域，基于协变量捕获多元响应矢量的条件协方差或相关性是非常重要的。我们提出一种新方法——基于随机森林框架的协方差回归分析(Covariance Regression with Random Forests, CovRegRF)，用于估算在给定协变量情况下多元响应的协方差矩阵。随机森林树的分割规则是专门设计的，以最大化子节点的样本协方差矩阵估计之间的差异。此外，我们还提出了一个有关某些协变量偏效应的显著性检验方法。通过模拟研究评估了所提出方法和显著性检验的性能，结果显示CovRegRF方法提供了准确的协方差矩阵估计，并且Type-1误差得到了良好控制。该方法在甲状腺疾病数据上的应用也被提出。CovRegRF已经实现在R包"CovRegRF"中。

    Capturing the conditional covariances or correlations among the elements of a multivariate response vector based on covariates is important to various fields including neuroscience, epidemiology and biomedicine. We propose a new method called Covariance Regression with Random Forests (CovRegRF) to estimate the covariance matrix of a multivariate response given a set of covariates, using a random forest framework. Random forest trees are built with a splitting rule specially designed to maximize the difference between the sample covariance matrix estimates of the child nodes. We also propose a significance test for the partial effect of a subset of covariates. We evaluate the performance of the proposed method and significance test through a simulation study which shows that the proposed method provides accurate covariance matrix estimates and that the Type-1 error is well controlled. An application of the proposed method to thyroid disease data is also presented. CovRegRF is implemente
    
[^29]: 利用现成的图像生成和字幕生成技术发现视觉模型中的错误

    Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning. (arXiv:2208.08831v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.08831](http://arxiv.org/abs/2208.08831)

    本研究利用现成的图像生成和字幕生成技术，自动发现视觉模型中的错误。通过生成大量合成但逼真的输入，聚类和描述，评估和发现分类器的失败和虚假相关性。这为未来构建实用的框架提供了一个有前途的思路。

    

    在真实世界的情境下自动发现视觉模型的失败仍然是一个开放的挑战。本研究展示了如何利用大量数据训练的现成大型图像到文本和文本到图像模型来自动发现这些失败。本研究将条件文本到图像生成模型用于生成大量合成但逼真的输入。分类错误的输入将被聚类并使用字幕生成模型来描述每个聚类。每个聚类的描述依次用于生成更多输入并评估是否特定聚类引起的失败超出了预期。我们利用此流程演示了我们可以有效地调查在ImageNet上训练的分类器，找到特定失败案例并发现虚假相关性。我们还展示了我们可以扩展此方法，生成针对特定分类器架构的对抗数据集。本研究作为一个实用的框架的概念验证，用于发现视觉模型中的失误。

    Automatically discovering failures in vision models under real-world settings remains an open challenge. This work demonstrates how off-the-shelf, large-scale, image-to-text and text-to-image models, trained on vast amounts of data, can be leveraged to automatically find such failures. In essence, a conditional text-to-image generative model is used to generate large amounts of synthetic, yet realistic, inputs given a ground-truth label. Misclassified inputs are clustered and a captioning model is used to describe each cluster. Each cluster's description is used in turn to generate more inputs and assess whether specific clusters induce more failures than expected. We use this pipeline to demonstrate that we can effectively interrogate classifiers trained on ImageNet to find specific failure cases and discover spurious correlations. We also show that we can scale the approach to generate adversarial datasets targeting specific classifier architectures. This work serves as a proof-of-co
    
[^30]: 计算高效且统计最优的鲁棒低秩矩阵和张量估计

    Computationally Efficient and Statistically Optimal Robust Low-rank Matrix and Tensor Estimation. (arXiv:2203.00953v4 [math.ST] UPDATED)

    [http://arxiv.org/abs/2203.00953](http://arxiv.org/abs/2203.00953)

    提出了一种新的计算高效且统计最优的鲁棒低秩矩阵和张量估计算法，可以在重尾噪声下实现准确估计，实验结果证明其优于现有方法。

    

    在重尾噪声下进行低秩矩阵估计既具有计算复杂性又具有统计挑战。凸方法已被证明在统计学上是最优的，但由于鲁棒损失函数通常是非光滑的，因此遭受高计算成本的困扰。最近，通过次梯度下降提出了计算快速的非凸方法，但不幸的是，即使在次高斯噪声下，也无法提供统计一致的估计。在本文中，我们介绍了一种新的变曲率次梯度算法（RsGrad），它不仅计算高效，而且收敛线性，并且在噪声为高斯或重尾分布时也具有统计优良性。我们建立了一个通用框架和具体的应用于绝对损失、Huber损失和分位损失的收敛理论，并对比现有非凸方法，我们发现它的对双相收敛的现象进行了惊人的揭示。在阶段一中，RsGrad的行为类似于典型的非凸方法，而在阶段二中，它实现了类凸收敛，并且具有快速的收敛速率和稳健性。我们的数值实验表明，在多种设置下，RsGrad优于现有方法，适用于矩阵和张量估计问题。

    Low-rank matrix estimation under heavy-tailed noise is challenging, both computationally and statistically. Convex approaches have been proven statistically optimal but suffer from high computational costs, especially since robust loss functions are usually non-smooth. More recently, computationally fast non-convex approaches via sub-gradient descent are proposed, which, unfortunately, fail to deliver a statistically consistent estimator even under sub-Gaussian noise. In this paper, we introduce a novel Riemannian sub-gradient (RsGrad) algorithm which is not only computationally efficient with linear convergence but also is statistically optimal, be the noise Gaussian or heavy-tailed. Convergence theory is established for a general framework and specific applications to absolute loss, Huber loss, and quantile loss are investigated. Compared with existing non-convex methods, ours reveals a surprising phenomenon of dual-phase convergence. In phase one, RsGrad behaves as in a typical non-
    
[^31]: 学习在多项Logit选择下进行排序

    Learning to Rank under Multinomial Logit Choice. (arXiv:2009.03207v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2009.03207](http://arxiv.org/abs/2009.03207)

    该论文提出了一个基于多项Logit选择模型的学习排序框架，能够更准确地捕捉用户在整个项目列表中的选择行为，为网站设计提供了更好的排序方案。

    

    在网站设计中，学习最佳内容排序是一个重要的挑战。学习排序（LTR）框架将这个问题建模为选择内容列表并观察用户决定点击的顺序问题。大多数以前的LTR工作假设用户在列表中独立考虑每个项目，并对每个项目进行二选一的选择。我们引入了多项式Logit（MNL）选择模型到LTR框架中，它捕捉到用户将有序的项目列表作为一个整体，从所有项目和没有点击选项中做出一个选择的行为。在MNL模型下，用户更喜欢本质上更有吸引力的项目，或者处于列表中更可取的位置的项目。我们提出了上置信界（UCB）算法，以在已知和未知的位置依赖参数的两种设置中最小化遗憾。我们提出了理论分析，导致了对问题的$\Omega（\sqrt{JT}）$下限。

    Learning the optimal ordering of content is an important challenge in website design. The learning to rank (LTR) framework models this problem as a sequential problem of selecting lists of content and observing where users decide to click. Most previous work on LTR assumes that the user considers each item in the list in isolation, and makes binary choices to click or not on each. We introduce a multinomial logit (MNL) choice model to the LTR framework, which captures the behaviour of users who consider the ordered list of items as a whole and make a single choice among all the items and a no-click option. Under the MNL model, the user favours items which are either inherently more attractive, or placed in a preferable position within the list. We propose upper confidence bound (UCB) algorithms to minimise regret in two settings where the position dependent parameters are known, and unknown. We present theoretical analysis leading to an $\Omega(\sqrt{JT})$ lower bound for the problem
    
[^32]: 异质量化处理效应的高效发现：基于异常模式检测的随机实验方法

    Efficient Discovery of Heterogeneous Quantile Treatment Effects in Randomized Experiments via Anomalous Pattern Detection. (arXiv:1803.09159v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/1803.09159](http://arxiv.org/abs/1803.09159)

    提出了一种名为TESS的新方法，通过将该挑战作为一种模式检测问题来解决，可以高效地从随机实验数据中找到受治疗影响最大的子群体，同时假设最少且具有正确性保证。

    

    在对估计异质性处理效应的方法进行文献综述时，每种提出的方法都会对干预效应及要明确估计的亚群体做出一系列具有限制性的假设。此外，大部分文献没有提供确定哪些亚群体受影响最大的机制——除了手动检查——并且在确定受影响最大的亚群体时也很少能提供正确性保证。因此，我们提出了Treatment Effect Subset Scan (TESS)，一种新方法，用于发现在随机实验中哪些亚群体最明显地受到处理影响。我们将其作为一个模式检测问题来提出，通过有效地对亚群体进行非参数扫描统计量（条件量化处理效应的一种度量）的最大化来实现。此外，我们还确定了受干预影响最大的分布变化最大的亚群体，同时对于干预效应的影响也做出最小的假设。

    In the recent literature on estimating heterogeneous treatment effects, each proposed method makes its own set of restrictive assumptions about the intervention's effects and which subpopulations to explicitly estimate. Moreover, the majority of the literature provides no mechanism to identify which subpopulations are the most affected--beyond manual inspection--and provides little guarantee on the correctness of the identified subpopulations. Therefore, we propose Treatment Effect Subset Scan (TESS), a new method for discovering which subpopulation in a randomized experiment is most significantly affected by a treatment. We frame this challenge as a pattern detection problem where we efficiently maximize a nonparametric scan statistic (a measure of the conditional quantile treatment effect) over subpopulations. Furthermore, we identify the subpopulation which experiences the largest distributional change as a result of the intervention, while making minimal assumptions about the inter
    

