# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Restart Sampling for Improving Generative Processes.](http://arxiv.org/abs/2306.14878) | 本文提出了一种名为“重启”的新型采样算法，以更好地平衡离散化误差和收缩，可以优化生成过程中的采样速度和样本质量。 |
| [^2] | [Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits.](http://arxiv.org/abs/2306.14872) | 本文提出了一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为线性赌博机算法建立实例相关的频率后悔界，并实现了平衡算法性能与理论保证的效果。 |
| [^3] | [Leveraging Task Structures for Improved Identifiability in Neural Network Representations.](http://arxiv.org/abs/2306.14861) | 本文提出一种基于任务结构的可识别性理论，拓展了先前仅限于单任务分类的工作。任务分布的存在定义了一个潜在变量的条件先验，将可识别性的等价类降低到排列和缩放。在假设任务之间存在因果关系时，该方法可以实现简单的最大边际似然优化，并在因果表示学习方面具有下游应用的可行性。 |
| [^4] | [Effective Minkowski Dimension of Deep Nonparametric Regression: Function Approximation and Statistical Theories.](http://arxiv.org/abs/2306.14859) | 本文提出了深度非参数回归的有效闵可夫斯基维数表示方法，证明了深度非参数回归的样本复杂度仅取决于数据集周围的子集的有效闵可夫斯基维数。 |
| [^5] | [Black holes and the loss landscape in machine learning.](http://arxiv.org/abs/2306.14817) | 本论文指出，黑洞自然产生指数级别的许多局部极小值的损失景观，为机器学习领域提供了重要的见解。 |
| [^6] | [The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory.](http://arxiv.org/abs/2306.14753) | 本文介绍了如何从多项式混沌扩展的角度分析DANN的神经信号处理，为深度神经网络提供了更多的数据驱动的方法和策略。 |
| [^7] | [Leveraging Locality and Robustness to Achieve Massively Scalable Gaussian Process Regression.](http://arxiv.org/abs/2306.14731) | 该研究提出了一种新的思路，通过探索 GPnn 的鲁棒性和极限行为实现大规模高斯过程回归，即使在出现重大小错误的情况下只需要花费少量的工作进行参数估计即可实现高 MSE 准确性。同时，该研究成功解决了加性噪声方差带来的不确定度校准和 NLL 准确性问题。 |
| [^8] | [Conformal link prediction to control the error rate.](http://arxiv.org/abs/2306.14693) | 本研究提出了一种基于一致性推断思想的新方法，可在控制虚假发现率的前提下，识别一组真实的边。 |
| [^9] | [PWSHAP: A Path-Wise Explanation Model for Targeted Variables.](http://arxiv.org/abs/2306.14672) | PWSHAP是一种用于敏感领域中评估特定二进制变量目标效应的框架，使用用户定义的DAG和on-manifold Shapley值识别因果路径中的效应，同时对对抗性攻击保持稳健性，具有良好的准确性和可解释性。 |
| [^10] | [Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition.](http://arxiv.org/abs/2306.14670) | 本文研究了机器学习模型在竞争环境下的行为，发现提高数据表示质量可能会导致供应商整体预测准确性降低，从而降低社会福利。 |
| [^11] | [CST-YOLO: A Novel Method for Blood Cell Detection Based on Improved YOLOv7 and CNN-Swin Transformer.](http://arxiv.org/abs/2306.14590) | 本论文提出了一种CST-YOLO算法，基于改进的YOLOv7和CNN-Swin Transformer，引入了几个有用的模型，有效提高了血细胞检测精度，实验结果显示其在三个血细胞数据集上均优于现有最先进算法。 |
| [^12] | [Multi-output Ensembles for Multi-step Forecasting.](http://arxiv.org/abs/2306.14563) | 本文探究了多输出模型组成的动态集成在多步预测中的应用，并发现基于仲裁和时间窗口的动态集成表现最佳。随着预测时间的增加，大多数方法难以胜过静态集成。 |
| [^13] | [Enhanced multi-fidelity modelling for digital twin and uncertainty quantification.](http://arxiv.org/abs/2306.14430) | 该研究提出了一个称为H-PCFE的新的框架，通过将多项式相关函数扩展（PCFE）和高斯过程（GP）集成起来，开发了一个强大的多保真度代理模型，以跟踪数字孪生系统。 |
| [^14] | [Anomaly Detection with Score Distribution Discrimination.](http://arxiv.org/abs/2306.14403) | 本文提出了一种基于分数分布区分的异常检测方法，使用Overlap Loss损失函数最小化正常和异常样本的分数分布重叠区域，无需人工预定义的分数目标，能更好地适应不同数据场景，并在多个基准数据集上表现出更好的性能。 |
| [^15] | [Comparing Causal Frameworks: Potential Outcomes, Structural Models, Graphs, and Abstractions.](http://arxiv.org/abs/2306.14351) | 本文比较了因果框架中的潜在结果模型(RCM)和结构因果模型(SCM)，并阐明了RCM成为SCM可表达的条件，以及每个RCM作为某些可表达的RCM的抽象。作者介绍了SCM原则在RCM经典应用中的重要作用，并提出了由图表示的代数约束的特征，有助于进一步比较两个框架。 |
| [^16] | [TCE: A Test-Based Approach to Measuring Calibration Error.](http://arxiv.org/abs/2306.14343) | 本文提出基于测试的校准误差 （TCE）指标，使用了一种新颖的基于统计检验的损失函数来衡量模型预测与数据预估概率之间的差异，相对标准校准误差表示，具有解释清晰、一致刻度和增强视觉表示等优点。 |
| [^17] | [Near Optimal Heteroscedastic Regression with Symbiotic Learning.](http://arxiv.org/abs/2306.14288) | 本研究提出了一种基于共生学习的异方差回归的近似最优算法，可以在统计学、计量经济学、时间序列分析等领域，以及在不同来源数据质量不一的机器学习中应用。 |
| [^18] | [Towards Trustworthy Explanation: On Causal Rationalization.](http://arxiv.org/abs/2306.14115) | 该论文介绍了一种新的因果关系解释方法，通过在解释中引入非虚假性和效率，从因果推断的角度定义了因果概率，从而建立了必要和充分解释的主要组成部分，相比现有的基于关联的解释方法，这种方法有更加优越的性能表现。 |
| [^19] | [Is RLHF More Difficult than Standard RL?.](http://arxiv.org/abs/2306.14111) | 本文证明了对于广泛的偏好模型，我们可以使用现有的算法和技术直接解决基于偏好的RL问题，而几乎不需要额外的成本。 |
| [^20] | [Private Aggregation in Wireless Federated Learning with Heterogeneous Clusters.](http://arxiv.org/abs/2306.14088) | 本文探讨了在一个无线系统中，考虑到信息论隐私的条件下，通过基站连接到联合器的客户端，如何解决联邦学习中的隐私数据聚合问题。 |
| [^21] | [Smoothed $f$-Divergence Distributionally Robust Optimization: Exponential Rate Efficiency and Complexity-Free Calibration.](http://arxiv.org/abs/2306.14041) | 分布鲁棒优化在实现统计保证界限时存在限制和保守性问题，但平滑的$f$-散度分布鲁棒优化可在指数衰减率方面实现最紧密的统计保证。 |
| [^22] | [Zero-Concentrated Private Distributed Learning for Nonsmooth Objective Functions.](http://arxiv.org/abs/2306.14012) | 本文提出了一种用于解决非平滑优化问题的完全分布式的差分隐私学习算法，保证零集中度差分隐私，具有更好的准确性和更强的保证，并且处理非平滑和非必须强凸问题。 |
| [^23] | [Learned Mappings for Targeted Free Energy Perturbation between Peptide Conformations.](http://arxiv.org/abs/2306.14010) | 本文研究了将机器学习用于映射自由能扰动中的Boltzmann分布，以求得Deca-Alanine分子的自由能差异。当弹簧中心相隔较近时，该方法可以得到准确的结果，但当弹簧中心相隔较远时，该方法无法得到代表目标状态的结构和正确的结果。 |
| [^24] | [Robust Classification of High-Dimensional Data using Data-Adaptive Energy Distance.](http://arxiv.org/abs/2306.13985) | 该论文提出了一种用于高维低样本量数据分类的稳健的数据自适应能量距离分类器，该分类器无需调参且在一定条件下可以实现完美分类，已在模拟研究和实际数据分析中得到证明比其他方法表现更优。 |
| [^25] | [Regularized Multivariate Functional Principal Component Analysis.](http://arxiv.org/abs/2306.13980) | 本文提出了一种称为规则化MFPCA的新方法，用于平滑和增强多元函数PC的可解释性，为分析和发现复杂的多元函数数据中的关系开辟了新的途径。 |
| [^26] | [Tuning structure learning algorithms with out-of-sample and resampling strategies.](http://arxiv.org/abs/2306.13932) | 本文提出了一种新的超参数调整方法 OTSL，它采用外样本和重抽样策略来估算给定输入数据集和结构学习算法的最佳超参数配置。实验表明，该方法优于现有技术，可提高结构学习算法的图形准确性。 |
| [^27] | [G-TRACER: Expected Sharpness Optimization.](http://arxiv.org/abs/2306.13914) | G-TRACER是一种正则化深度学习结构优化方案，重点解决低信噪比问题，能有效促进泛化并获得了竞争性能。 |
| [^28] | [Selective inference using randomized group lasso estimators for general models.](http://arxiv.org/abs/2306.13829) | 研究了一种使用随机分组套索估计器进行广义模型的选择性推断方法，可以考虑分类或分组协变量以及连续协变量，并且有证据表明其具有适当性和准确性。 |
| [^29] | [Tensor Dirichlet Process Multinomial Mixture Model for Passenger Trajectory Clustering.](http://arxiv.org/abs/2306.13794) | 提出了一种基于张量的狄利克雷过程多项式混合模型（Tensor-DPMM），通过张量保留了多维行程信息的多模式和分层结构，并以统一的一步方式进行乘客轨迹聚类，在自动确定聚类数方面具有优越性。 |
| [^30] | [A new approach to generalisation error of machine learning algorithms: Estimates and convergence.](http://arxiv.org/abs/2306.13784) | 本文提出了一种新的机器学习算法泛化误差的估计方法和收敛性分析，可以在不需要神经网络的任何假设下对误差进行估计，并只要求神经网络具有适当的逼近能力就可以将近似转化为目标函数f。 |
| [^31] | [Valid inference after prediction.](http://arxiv.org/abs/2306.13746) | 最近的研究聚焦于基于预测的推断，并提出了修正步骤以实现对未观测到响应和协变量之间关系的有效推断，Angelopoulos等人（2023）的方法成功控制了第一类错误率，并提供了正确命名覆盖的置信区间，但在某些情况下，其存在低功率问题。 |
| [^32] | [Estimating the Value of Evidence-Based Decision Making.](http://arxiv.org/abs/2306.13681) | 本文提出了一个实证框架，用于估算证据决策的价值和统计精度投资回报。 |
| [^33] | [Taming the Exponential Action Set: Sublinear Regret and Fast Convergence to Nash Equilibrium in Online Congestion Games.](http://arxiv.org/abs/2306.13673) | 本文提出了一种名为CongestEXP的分散算法，可以线性缩放设施数量，实现在线拥塞博弈的次线性遗憾上界，并以与已知最佳下界相匹配的速度快速收敛到纳什均衡。 |
| [^34] | [Communication-Efficient Federated Learning through Importance Sampling.](http://arxiv.org/abs/2306.12625) | 本文提出了一种通过重要性抽样实现有效通信的联邦学习方法，大大降低了发送模型更新的高通信成本，利用服务器端客户端分布和附加信息的接近关系，只需要较少的通信量即可实现。 |
| [^35] | [Structure-Aware Robustness Certificates for Graph Classification.](http://arxiv.org/abs/2306.11915) | 该论文提出了一种新的随机平滑方法，可以根据图的不同预定义结构生成对应的鲁棒性证书，从而在多个基准图分类任务中取得领先的对抗性攻击下鲁棒性结果。 |
| [^36] | [Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations.](http://arxiv.org/abs/2306.11839) | 本文提出了针对于异质种群有害实验的早期停止方法CLASH，使用因果机器学习可以有效提前停止临床试验和A/B测试。 |
| [^37] | [Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima.](http://arxiv.org/abs/2306.09850) | 该研究揭示了实用的锐度感知优化算法在某些情况下不能够全程向最优点收敛。 |
| [^38] | [Kernel Debiased Plug-in Estimation.](http://arxiv.org/abs/2306.08598) | 本文提出了一种高效、不需要实现影响函数且可计算的去偏插值估计方法。 |
| [^39] | [Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach.](http://arxiv.org/abs/2306.07566) | 本文提出了一种处理选择性标记数据的学习问题的方法。通过利用历史决策由一组异质决策者做出的事实，我们建立了一种有原理的工具变量框架，并提出了一种加权学习方法，用于学习预测规则。 |
| [^40] | [On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling.](http://arxiv.org/abs/2306.07252) | 研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性 |
| [^41] | [Hyperparameter Learning under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization.](http://arxiv.org/abs/2306.01613) | 本文提出了一种考虑攻击对超参数影响的最优攻击公式，将攻击建模为多目标双层优化问题，可以更准确地评估算法鲁棒性和学习超参数，在多个数据集上的评估证明了这种方法的优势。 |
| [^42] | [Balanced Training of Energy-Based Models with Adaptive Flow Sampling.](http://arxiv.org/abs/2306.00684) | 本文研究了能量基模型的训练算法，使用归一化流进行采样，提高了模型的统计精度和生成性能。 |
| [^43] | [Low-rank extended Kalman filtering for online learning of neural networks from streaming data.](http://arxiv.org/abs/2305.19535) | 本文提出一种基于低秩扩展卡尔曼滤波的高效在线学习算法，其能够估计非线性函数的参数，具有更快的适应性和更快的奖励积累。 |
| [^44] | [Compression with Bayesian Implicit Neural Representations.](http://arxiv.org/abs/2305.19185) | 该论文提出了一种用Bayesian隐式神经表示来压缩数据的方法，通过最小化 $\beta$-ELBO 直接优化码-失真性能，并通过调整 $\beta$ 来针对给定的网络结构实现不同的码-失真平衡。 |
| [^45] | [PFNs Are Flexible Models for Real-World Bayesian Optimization.](http://arxiv.org/abs/2305.17535) | 本文使用灵活的PFN作为BO代理建模，该模型能够允许进一步信息纳入以进行非远视BO。在三种不同的问题上得到了很好的结果。 |
| [^46] | [Representation Transfer Learning via Multiple Pre-trained models for Linear Regression.](http://arxiv.org/abs/2305.16440) | 本文提出了一种基于表示迁移的学习方法，在给定很少数样本的情况下，通过提供一组在可能不同的数据领域上训练的预训练回归模型，来构建目标模型，使用这种方法可以提高模型的样本复杂度。 |
| [^47] | [Online Platt Scaling with Calibeating.](http://arxiv.org/abs/2305.00070) | 本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。 |
| [^48] | [Fault Detection via Occupation Kernel Principal Component Analysis.](http://arxiv.org/abs/2303.11138) | 本文提出了一种使用占据核PCA方法进行故障检测的新方法，并且通过数值模拟验证了其有效性。 |
| [^49] | [Finite-Sample Analysis of Learning High-Dimensional Single ReLU Neuron.](http://arxiv.org/abs/2303.02255) | 本文研究了高维单个ReLU神经元的有限样本学习问题，并提供了感知器算法GLM-tron的风险上下界，其中包括特殊情况，为高维ReLU回归问题提供了清晰的刻画。此外，对于对称伯努利数据的ReLU回归，随机梯度下降的过多风险不如GLM-tron。 |
| [^50] | [Online Instrumental Variable Regression: Regret Analysis and Bandit Feedback.](http://arxiv.org/abs/2302.09357) | 该论文研究了在线学习中内生性问题的解决方法，提出了使用Two-Stage Least Squares方法的在线变体O2SLS来处理内生性，取得了较好的识别率和预测遗憾率。 |
| [^51] | [Approximately Bayes-Optimal Pseudo Label Selection.](http://arxiv.org/abs/2302.08883) | 本文介绍了BPLS，一种用于PLS的贝叶斯框架，通过解析逼近选择标签实例的标准，以避免由过度自信但错误预测的实例选择而导致的确认偏差问题。 |
| [^52] | [On Heterogeneous Treatment Effects in Heterogeneous Causal Graphs.](http://arxiv.org/abs/2301.12383) | 本文通过推广因果图模型，描述了异质性因果图，提出了一种方法来研究不同调节因素对治疗效果和潜在中介变量的影响，解决了现实生活中高维度场景的挑战，并在真实数据应用中发现了新的异质性治疗效应。 |
| [^53] | [Inverse Solvability and Security with Applications to Federated Learning.](http://arxiv.org/abs/2211.14115) | 介绍了逆可解性和安全性的概念，以及其在联邦学习中的应用。论文提供了模型示例，展示了如何通过增加用户数量来增加可解性和安全性。 |
| [^54] | [Hyperbolic Sliced-Wasserstein via Geodesic and Horospherical Projections.](http://arxiv.org/abs/2211.10066) | 本文提出了一种基于测地线和水平面投影的双曲切片Wasserstein距离，可用于比较具有基础分层结构的数据中定义的概率分布。 |
| [^55] | [A mixed-categorical correlation kernel for Gaussian process.](http://arxiv.org/abs/2211.08262) | 提出一种新的混合类别相关核的高斯过程代理，相较于其他现有模型在分析和工程问题上表现更好。 |
| [^56] | [Training Debiased Subnetworks with Contrastive Weight Pruning.](http://arxiv.org/abs/2210.05247) | 本文探讨了在存在强假相关的偏置网络中提取最优无偏子网络的问题，并提出了使用对比剪枝权重训练实现去偏置子网络的算法 DCWP，在多个应用中都有良好的效果。 |
| [^57] | [Exceedance Probability Forecasting via Regression for Significant Wave Height Prediction.](http://arxiv.org/abs/2206.09821) | 本论文提出了一种基于回归的超标概率预测方法，用于预测显著波高，通过利用预测来估计超标概率，取得了更好的效果。 |
| [^58] | [Bounding and Approximating Intersectional Fairness through Marginal Fairness.](http://arxiv.org/abs/2206.05828) | 本文旨在通过统计分析了解边际公平性和交集公平性之间的关系，在一定条件下取得精确关系。在高概率下,通过边际公平性和其他有意义的统计量可以计算出交集公平性的界限。 |
| [^59] | [Semi-Supervised Clustering of Sparse Graphs: Crossing the Information-Theoretic Threshold.](http://arxiv.org/abs/2205.11677) | 该论文提出了两种有效的算法来将标签信息与稀疏图结构相结合，解决了基于网络拓扑的聚类在稀疏图上的问题。 |
| [^60] | [Neural Q-learning for solving PDEs.](http://arxiv.org/abs/2203.17128) | 本文提出了一种新的利用神经Q-学习算法解决椭圆型PDE数值方法，该算法无网格且具有克服维度灾难的潜力。本文证明了这种方法的有效性，并在单调PDE的情况下得到了极限神经网络收敛于PDE解的证明。 |
| [^61] | [Optimal Learning.](http://arxiv.org/abs/2203.15994) | 本文证明，通过解决一个带有惩罚项的离散过度参数化优化问题，可以找到近乎最优的 $\hat f$。 |
| [^62] | [Interpretable Off-Policy Learning via Hyperbox Search.](http://arxiv.org/abs/2203.02473) | 本文提出了一个基于超立方体搜索的可解释离线策略学习算法，可以用合取范式表示，可以灵活逼近任何可测函数。在临床实践中具有重要意义。 |
| [^63] | [Accelerating Non-Negative and Bounded-Variable Linear Regression Algorithms with Safe Screening.](http://arxiv.org/abs/2202.07258) | 本文提出了一种通过识别饱和坐标加速解决非负和有界变量线性回归问题的技术，实验结果表明其具有令人信服的加速效果。 |
| [^64] | [Concentration of measure and generalized product of random vectors with an application to Hanson-Wright-like inequalities.](http://arxiv.org/abs/2102.08020) | 本文介绍了函数浓度表达式，并给出了浓度集中与 Hanson-Wright不等式的广义推广，研究了随机矩阵XDX^(t)及其解析式Q。 |
| [^65] | [Representation Ensembling for Synergistic Lifelong Learning with Quasilinear Complexity.](http://arxiv.org/abs/2004.12908) | 本文提出了一种名为RELL的方法，利用知识蒸馏和知识保持正则化方法，以协同集成在不同任务上独立学习的表示，在准线性复杂度下实现了前向和后向传递。实验结果表明，在各种基准数据集上，RELL的表现优于现有的最先进方法，尤其是在存在灾难性遗忘的情况下，能够显着改善反向传递。 |

# 详细

[^1]: 重启采样以提高生成过程

    Restart Sampling for Improving Generative Processes. (arXiv:2306.14878v1 [cs.LG])

    [http://arxiv.org/abs/2306.14878](http://arxiv.org/abs/2306.14878)

    本文提出了一种名为“重启”的新型采样算法，以更好地平衡离散化误差和收缩，可以优化生成过程中的采样速度和样本质量。

    

    生成过程中解决微分方程的过程，如扩散模型，需要平衡速度和质量。基于ODE的采样器速度快但性能平稳，而基于SDE的采样器提供更高的样本质量但需要更长的采样时间。我们将这种差异归因于采样误差：ODE采样器涉及更小的离散化误差，而SDE的随机性会使累积误差缩小。基于这些发现，我们提出了一种名为重启的新型采样算法，以更好地平衡离散化误差和收缩。该采样方法在额外前向步骤中交替添加大量噪声和严格遵循后向ODE。经验证，重启采样器在速度和准确性方面均优于先前的SDE和ODE采样器。在CIFAR-10/ImageNet $64 \times 64$上，重启不仅优于先前的最佳SDE结果，而且加快了采样速度，分别为10倍/2倍。此外，它在进行图像生成时还提供了更好的样本质量。

    Generative processes that involve solving differential equations, such as diffusion models, frequently necessitate balancing speed and quality. ODE-based samplers are fast but plateau in performance while SDE-based samplers deliver higher sample quality at the cost of increased sampling time. We attribute this difference to sampling errors: ODE-samplers involve smaller discretization errors while stochasticity in SDE contracts accumulated errors. Based on these findings, we propose a novel sampling algorithm called Restart in order to better balance discretization errors and contraction. The sampling method alternates between adding substantial noise in additional forward steps and strictly following a backward ODE. Empirically, Restart sampler surpasses previous SDE and ODE samplers in both speed and accuracy. Restart not only outperforms the previous best SDE results, but also accelerates the sampling speed by 10-fold / 2-fold on CIFAR-10 / ImageNet $64 \times 64$. In addition, it at
    
[^2]: 线性赌博机中平衡性能与理论保证的几何感知方法

    Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])

    [http://arxiv.org/abs/2306.14872](http://arxiv.org/abs/2306.14872)

    本文提出了一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为线性赌博机算法建立实例相关的频率后悔界，并实现了平衡算法性能与理论保证的效果。

    

    本文受线性赌博机算法表现良好的实证性能与悲观理论后悔界之间的不一致性启发，提出一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为包括贪心、OFUL和汤普森抽样算法在内的广泛算法类建立实例相关的频率后悔界，在保留基本算法大部分优良特性的同时“校正”基本算法在某些实例中表现差的问题，实现了渐近最优后悔界。我们通过仿真实验验证了该方法的有效性。

    This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
    
[^3]: 利用任务结构提高神经网络表示的可识别性

    Leveraging Task Structures for Improved Identifiability in Neural Network Representations. (arXiv:2306.14861v1 [stat.ML])

    [http://arxiv.org/abs/2306.14861](http://arxiv.org/abs/2306.14861)

    本文提出一种基于任务结构的可识别性理论，拓展了先前仅限于单任务分类的工作。任务分布的存在定义了一个潜在变量的条件先验，将可识别性的等价类降低到排列和缩放。在假设任务之间存在因果关系时，该方法可以实现简单的最大边际似然优化，并在因果表示学习方面具有下游应用的可行性。

    

    本文扩展了监督学习中可辨别性的理论，考虑了在拥有任务分布的情况下的后果。在这种情况下，我们展示了即使在回归的情况下也可以实现可识别性，扩展了先前仅限于单任务分类情况的工作。此外，我们展示了任务分布的存在定义了一个潜在变量的条件先验，将可识别性的等价类降低到排列和缩放，这是一个更强大和更有用的结果。当我们进一步假设这些任务之间存在因果关系时，我们的方法可以实现简单的最大边际似然优化，并在因果表示学习方面具有下游应用的可行性。在经验上，我们验证了我们的模型在恢复合成和现实世界数据的规范表示方面优于更一般的无监督模型。

    This work extends the theory of identifiability in supervised learning by considering the consequences of having access to a distribution of tasks. In such cases, we show that identifiability is achievable even in the case of regression, extending prior work restricted to the single-task classification case. Furthermore, we show that the existence of a task distribution which defines a conditional prior over latent variables reduces the equivalence class for identifiability to permutations and scaling, a much stronger and more useful result. When we further assume a causal structure over these tasks, our approach enables simple maximum marginal likelihood optimization together with downstream applicability to causal representation learning. Empirically, we validate that our model outperforms more general unsupervised models in recovering canonical representations for synthetic and real-world data.
    
[^4]: 深度非参数回归的有效闵可夫斯基维数：函数逼近和统计理论

    Effective Minkowski Dimension of Deep Nonparametric Regression: Function Approximation and Statistical Theories. (arXiv:2306.14859v1 [cs.LG])

    [http://arxiv.org/abs/2306.14859](http://arxiv.org/abs/2306.14859)

    本文提出了深度非参数回归的有效闵可夫斯基维数表示方法，证明了深度非参数回归的样本复杂度仅取决于数据集周围的子集的有效闵可夫斯基维数。

    

    现有的关于深度非参数回归的理论表明，当输入数据位于低维流形上时，深度神经网络可以适应固有的数据结构。在实际应用中，数据恰好位于低维流形上的假设是苛刻的。本文引入了一个更宽松的假设，即输入数据集中在$\mathbb{R}^d$的一个子集$\mathcal{S}$周围，并且$\mathcal{S}$的内在维数可以用新的复杂度表示——有效闵可夫斯基维数进行刻画。我们证明，深度非参数回归的样本复杂度仅取决于$\mathcal{S}$的有效闵可夫斯基维数$p$。此外，我们通过考虑具有各向异性高斯随机设计$ N(0，\Sigma)$的非参数回归，进一步说明了我们的理论发现，其中$ \Sigma $具有全秩。当$ \Sigma $的特征值有指数或多项式衰减时，子集$ \mathcal {S }$的有效闵可夫斯基维数被证明等于各向异性高斯流形的内在维数。

    Existing theories on deep nonparametric regression have shown that when the input data lie on a low-dimensional manifold, deep neural networks can adapt to the intrinsic data structures. In real world applications, such an assumption of data lying exactly on a low dimensional manifold is stringent. This paper introduces a relaxed assumption that the input data are concentrated around a subset of $\mathbb{R}^d$ denoted by $\mathcal{S}$, and the intrinsic dimension of $\mathcal{S}$ can be characterized by a new complexity notation -- effective Minkowski dimension. We prove that, the sample complexity of deep nonparametric regression only depends on the effective Minkowski dimension of $\mathcal{S}$ denoted by $p$. We further illustrate our theoretical findings by considering nonparametric regression with an anisotropic Gaussian random design $N(0,\Sigma)$, where $\Sigma$ is full rank. When the eigenvalues of $\Sigma$ have an exponential or polynomial decay, the effective Minkowski dimens
    
[^5]: 机器学习中的黑洞和损失景观

    Black holes and the loss landscape in machine learning. (arXiv:2306.14817v1 [hep-th])

    [http://arxiv.org/abs/2306.14817](http://arxiv.org/abs/2306.14817)

    本论文指出，黑洞自然产生指数级别的许多局部极小值的损失景观，为机器学习领域提供了重要的见解。

    

    理解损失景观是机器学习中的一个重要问题。许多神经网络结构共同具有的一个关键特征是存在指数级别的许多局部极小值。具有类似能量景观的物理系统可以提供有用的见解。在这项工作中，我们指出，由于存在黑洞熵，黑洞自然产生这样的景观。为了明确起见，我们考虑$\mathcal{N}=8$ 弦理论中的1/8 BPS黑洞。这些提供了一系列潜在的景观，这些景观在相应的黑洞微观描述中出现。极小值的计数相当于黑洞微观态计数。此外，这些景观的最小值的确切数量是先验已知的，来自于弦理论的对偶性。其中一些最小值通过低损失值的路径相连，类似于模式连接。我们估计需要多少次运行才能找到所有的解。

    Understanding the loss landscape is an important problem in machine learning. One key feature of the loss function, common to many neural network architectures, is the presence of exponentially many low lying local minima. Physical systems with similar energy landscapes may provide useful insights. In this work, we point out that black holes naturally give rise to such landscapes, owing to the existence of black hole entropy. For definiteness, we consider 1/8 BPS black holes in $\mathcal{N} = 8$ string theory. These provide an infinite family of potential landscapes arising in the microscopic descriptions of corresponding black holes. The counting of minima amounts to black hole microstate counting. Moreover, the exact numbers of the minima for these landscapes are a priori known from dualities in string theory. Some of the minima are connected by paths of low loss values, resembling mode connectivity. We estimate the number of runs needed to find all the solutions. Initial exploration
    
[^6]: 深度任意多项式混沌神经网络 - 深度神经网络如何受益于数据驱动的同态混沌理论

    The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory. (arXiv:2306.14753v1 [cs.NE])

    [http://arxiv.org/abs/2306.14753](http://arxiv.org/abs/2306.14753)

    本文介绍了如何从多项式混沌扩展的角度分析DANN的神经信号处理，为深度神经网络提供了更多的数据驱动的方法和策略。

    

    人工智能和机器学习在数学计算、物理建模、计算科学、通讯科学和随机分析等领域得到了广泛应用。基于深度人工神经网络（DANN）的方法在当今非常流行。但对于大多数基于DANN的深度学习方法，神经信号处理的核心结构仍然是相同的，在这种结构下，节点响应被编码为神经活动的线性叠加，而非线性则是由激活函数触发。在本文中，我们建议从同态混沌理论（如多项式混沌扩展）的角度分析DANN的神经信号处理。从PCE的角度看，DANN的每个节点的（线性）响应可以看作是一个同态混沌过程，并且可以通过将活性函数替换为非线性的泛函来计算。

    Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions. In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen a
    
[^7]: 利用本地性和鲁棒性实现大规模高斯过程回归

    Leveraging Locality and Robustness to Achieve Massively Scalable Gaussian Process Regression. (arXiv:2306.14731v1 [stat.ML])

    [http://arxiv.org/abs/2306.14731](http://arxiv.org/abs/2306.14731)

    该研究提出了一种新的思路，通过探索 GPnn 的鲁棒性和极限行为实现大规模高斯过程回归，即使在出现重大小错误的情况下只需要花费少量的工作进行参数估计即可实现高 MSE 准确性。同时，该研究成功解决了加性噪声方差带来的不确定度校准和 NLL 准确性问题。

    

    高斯过程回归所提供的精确预测和原则性不确定性测量会产生 O(n^3) 的成本，这对于现代大规模应用来说是难以承受的。因此，出现了大量关于计算效率的研究。我们通过探索 GP 最近邻预测(GPnn) 的鲁棒性和极限行为引入了一种新的视角。我们通过理论和模拟证明，随着数据量 n 的增加，估计参数和 GP 模型假设的准确性对 GPnn 预测准确性的影响逐渐减小。因此，为了实现高 MSE 准确性，即使在出现重大错误的情况下, 只需要花费少量的工作进行参数估计即可。相比之下，随着 n 趋近于无穷大，我们发现不确定度校准和 NLL 仍对一个参数敏感，即加性噪声方差；但我们证明可以纠正这种不准确性，并实现良好的不确定度校准和 NLL。

    The accurate predictions and principled uncertainty measures provided by GP regression incur O(n^3) cost which is prohibitive for modern-day large-scale applications. This has motivated extensive work on computationally efficient approximations. We introduce a new perspective by exploring robustness properties and limiting behaviour of GP nearest-neighbour (GPnn) prediction. We demonstrate through theory and simulation that as the data-size n increases, accuracy of estimated parameters and GP model assumptions become increasingly irrelevant to GPnn predictive accuracy. Consequently, it is sufficient to spend small amounts of work on parameter estimation in order to achieve high MSE accuracy, even in the presence of gross misspecification. In contrast, as n tends to infinity, uncertainty calibration and NLL are shown to remain sensitive to just one parameter, the additive noise-variance; but we show that this source of inaccuracy can be corrected for, thereby achieving both well-calibra
    
[^8]: 控制误差率的一致性链路预测方法

    Conformal link prediction to control the error rate. (arXiv:2306.14693v1 [stat.ME])

    [http://arxiv.org/abs/2306.14693](http://arxiv.org/abs/2306.14693)

    本研究提出了一种基于一致性推断思想的新方法，可在控制虚假发现率的前提下，识别一组真实的边。

    

    大多数链路预测方法返回图中缺失边的连接概率的估计值。这种输出可用于按可能性大小对缺失边进行排序，但并未直接提供真实和不存在的分类。本研究考虑在控制虚假发现率的前提下，识别一组真实的边的问题。我们提出了一种基于一致性推断文献中高级思想的新方法。图形结构引入了数据中的复杂依赖关系，我们仔细考虑了这一点，因为这使得设置不同于一般的一致性推断设置，那里假定了交换性。在模拟和真实数据中，我们证明了FDR的控制。

    Most link prediction methods return estimates of the connection probability of missing edges in a graph. Such output can be used to rank the missing edges, from most to least likely to be a true edge, but it does not directly provide a classification into true and non-existent. In this work, we consider the problem of identifying a set of true edges with a control of the false discovery rate (FDR). We propose a novel method based on high-level ideas from the literature on conformal inference. The graph structure induces intricate dependence in the data, which we carefully take into account, as this makes the setup different from the usual setup in conformal inference, where exchangeability is assumed. The FDR control is empirically demonstrated for both simulated and real data.
    
[^9]: PWSHAP：一种针对目标变量的路径解释模型

    PWSHAP: A Path-Wise Explanation Model for Targeted Variables. (arXiv:2306.14672v1 [stat.ML])

    [http://arxiv.org/abs/2306.14672](http://arxiv.org/abs/2306.14672)

    PWSHAP是一种用于敏感领域中评估特定二进制变量目标效应的框架，使用用户定义的DAG和on-manifold Shapley值识别因果路径中的效应，同时对对抗性攻击保持稳健性，具有良好的准确性和可解释性。

    

    预测性黑盒模型可能表现出很高的准确性，但它们的不透明性阻碍了它们在安全关键的计算环境中的应用。解释方法（XAI）可以通过增加透明度来提高决策的信心。然而，现有的XAI方法并不是针对敏感领域中对于特定预测变量的解释，例如临床模型中的治疗效果或政策模型中的种族。我们引入了Path-Wise Shapley Effects (PWSHAP)，这是一种框架，用于评估复杂结果模型的二进制（例如治疗）变量的目标效应。我们的方法利用用户定义的有向无环图（DAG）来扩充预测模型。该方法与on-manifold Shapley值一起使用图形来识别沿因果路径的效应，同时保持对对抗性攻击的稳健性。我们确定了识别的路径Shapley效应和Shapley值的误差界限。我们展示了PWSHAP可以执行局部双...

    Predictive black-box models can exhibit high accuracy but their opaque nature hinders their uptake in safety-critical deployment environments. Explanation methods (XAI) can provide confidence for decision-making through increased transparency. However, existing XAI methods are not tailored towards models in sensitive domains where one predictor is of special interest, such as a treatment effect in a clinical model, or ethnicity in policy models. We introduce Path-Wise Shapley effects (PWSHAP), a framework for assessing the targeted effect of a binary (e.g.~treatment) variable from a complex outcome model. Our approach augments the predictive model with a user-defined directed acyclic graph (DAG). The method then uses the graph alongside on-manifold Shapley values to identify effects along causal pathways whilst maintaining robustness to adversarial attacks. We establish error bounds for the identified path-wise Shapley effects and for Shapley values. We show PWSHAP can perform local bi
    
[^10]: 竞争环境下贝叶斯风险的提高可能导致社会福利的降低

    Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition. (arXiv:2306.14670v1 [cs.GT])

    [http://arxiv.org/abs/2306.14670](http://arxiv.org/abs/2306.14670)

    本文研究了机器学习模型在竞争环境下的行为，发现提高数据表示质量可能会导致供应商整体预测准确性降低，从而降低社会福利。

    

    随着机器学习模型规模的增长，缩放定律等趋势预计会导致预测准确性的持续改进。然而，这些趋势只考虑了单个模型供应商的视角，而实际上供应商之间常常竞争用户。本文证明了竞争可以从根本上改变这些缩放趋势的行为，甚至可能造成整体预测准确性随着规模的增大而非单调或降低。我们定义了一个分类任务的竞争模型，并使用数据表示作为研究规模增加的影响的镜头。我们发现在一家市场上，改善数据表示质量（按贝叶斯风险计量）可能会降低竞争模型供应商的整体预测准确性（即社会福利）。我们的例子涵盖了简单设置中的封闭式公式到预训练的 CIFAR-10 模拟。

    As the scale of machine learning models increases, trends such as scaling laws anticipate consistent downstream improvements in predictive accuracy. However, these trends take the perspective of a single model-provider in isolation, while in reality providers often compete with each other for users. In this work, we demonstrate that competition can fundamentally alter the behavior of these scaling trends, even causing overall predictive accuracy across users to be non-monotonic or decreasing with scale. We define a model of competition for classification tasks, and use data representations as a lens for studying the impact of increases in scale. We find many settings where improving data representation quality (as measured by Bayes risk) decreases the overall predictive accuracy across users (i.e., social welfare) for a marketplace of competing model-providers. Our examples range from closed-form formulas in simple settings to simulations with pretrained representations on CIFAR-10. At
    
[^11]: CST-YOLO: 一种基于改进的YOLOv7和CNN-Swin Transformer的血细胞检测新方法

    CST-YOLO: A Novel Method for Blood Cell Detection Based on Improved YOLOv7 and CNN-Swin Transformer. (arXiv:2306.14590v1 [cs.CV])

    [http://arxiv.org/abs/2306.14590](http://arxiv.org/abs/2306.14590)

    本论文提出了一种CST-YOLO算法，基于改进的YOLOv7和CNN-Swin Transformer，引入了几个有用的模型，有效提高了血细胞检测精度，实验结果显示其在三个血细胞数据集上均优于现有最先进算法。

    

    血细胞检测是计算机视觉中典型的小物体检测问题。本文提出了一种CST-YOLO模型，基于YOLOv7结构并使用CNN-Swin Transformer（CST）进行增强，这是一种CNN-Transformer融合的新尝试。同时，我们还引入了三个有用的模型：加权高效层聚合网络（W-ELAN）、多尺度通道分割（MCS）和级联卷积层（CatConv），以提高小物体检测精度。实验结果表明，我们提出的CST-YOLO在三个血细胞数据集上分别达到了92.7、95.6和91.1 mAP@0.5，优于最先进的物体检测器，如YOLOv5和YOLOv7。我们的代码可在https://github.com/mkang315/CST-YOLO上找到。

    Blood cell detection is a typical small-scale object detection problem in computer vision. In this paper, we propose a CST-YOLO model for blood cell detection based on YOLOv7 architecture and enhance it with the CNN-Swin Transformer (CST), which is a new attempt at CNN-Transformer fusion. We also introduce three other useful modules: Weighted Efficient Layer Aggregation Networks (W-ELAN), Multiscale Channel Split (MCS), and Concatenate Convolutional Layers (CatConv) in our CST-YOLO to improve small-scale object detection precision. Experimental results show that the proposed CST-YOLO achieves 92.7, 95.6, and 91.1 mAP@0.5 respectively on three blood cell datasets, outperforming state-of-the-art object detectors, e.g., YOLOv5 and YOLOv7. Our code is available at https://github.com/mkang315/CST-YOLO.
    
[^12]: 多步预测的多输出集成

    Multi-output Ensembles for Multi-step Forecasting. (arXiv:2306.14563v1 [stat.ML])

    [http://arxiv.org/abs/2306.14563](http://arxiv.org/abs/2306.14563)

    本文探究了多输出模型组成的动态集成在多步预测中的应用，并发现基于仲裁和时间窗口的动态集成表现最佳。随着预测时间的增加，大多数方法难以胜过静态集成。

    

    本文研究了由多输出模型组成的集成在多步预测问题中的应用。动态集成通常用于预测，但是这些方法通常只适用于一步预测任务。与此相对，动态集成在多步预测中的应用文献很少，且不清楚组合规则如何应用于整个预测时段。我们进行了大量实验，以分析动态集成在多步预测中的应用。我们进行了一个实例研究，包含3568个时间序列和一个由30个多输出模型组成的集成。我们发现，基于仲裁和时间窗口的动态集成在平均排名上表现最佳。此外，随着预测时间逐步增加，大多数方法都难以胜过将所有模型分配相等权重的静态集成方法。实验代码已公开在一个代码库中。

    This paper studies the application of ensembles composed of multi-output models for multi-step ahead forecasting problems. Dynamic ensembles have been commonly used for forecasting. However, these are typically designed for one-step-ahead tasks. On the other hand, the literature regarding the application of dynamic ensembles for multi-step ahead forecasting is scarce. Moreover, it is not clear how the combination rule is applied across the forecasting horizon. We carried out extensive experiments to analyze the application of dynamic ensembles for multi-step forecasting. We resorted to a case study with 3568 time series and an ensemble of 30 multi-output models. We discovered that dynamic ensembles based on arbitrating and windowing present the best performance according to average rank. Moreover, as the horizon increases, most approaches struggle to outperform a static ensemble that assigns equal weights to all models. The experiments are publicly available in a repository.
    
[^13]: 增强的多保真度建模用于数字孪生和不确定性量化

    Enhanced multi-fidelity modelling for digital twin and uncertainty quantification. (arXiv:2306.14430v1 [cs.LG])

    [http://arxiv.org/abs/2306.14430](http://arxiv.org/abs/2306.14430)

    该研究提出了一个称为H-PCFE的新的框架，通过将多项式相关函数扩展（PCFE）和高斯过程（GP）集成起来，开发了一个强大的多保真度代理模型，以跟踪数字孪生系统。

    

    数字孪生技术在航空航天、基础设施和汽车等工程和工业领域的重要意义不容忽视。然而，缺乏详细的应用特定信息对其在实际系统中的无缝实施构成了挑战。数据驱动模型在数字孪生中发挥着关键作用，通过利用数据和计算模型实现实时更新和预测。然而，可用数据的保真度和准确传感器数据的缺乏常常阻碍了代理模型的高效学习，而这些模型是物理系统和数字孪生模型之间的连接。为了解决这一挑战，我们提出了一个新的框架，从开发一个强大的多保真度代理模型开始，随后应用于跟踪数字孪生系统。我们的框架将多项式相关函数扩展（PCFE）与高斯过程（GP）集成起来，创建出一个有效的代理模型称为H-PCFE。

    The increasing significance of digital twin technology across engineering and industrial domains, such as aerospace, infrastructure, and automotive, is undeniable. However, the lack of detailed application-specific information poses challenges to its seamless implementation in practical systems. Data-driven models play a crucial role in digital twins, enabling real-time updates and predictions by leveraging data and computational models. Nonetheless, the fidelity of available data and the scarcity of accurate sensor data often hinder the efficient learning of surrogate models, which serve as the connection between physical systems and digital twin models. To address this challenge, we propose a novel framework that begins by developing a robust multi-fidelity surrogate model, subsequently applied for tracking digital twin systems. Our framework integrates polynomial correlated function expansion (PCFE) with the Gaussian process (GP) to create an effective surrogate model called H-PCFE.
    
[^14]: 基于分数分布区分的异常检测方法

    Anomaly Detection with Score Distribution Discrimination. (arXiv:2306.14403v1 [cs.LG])

    [http://arxiv.org/abs/2306.14403](http://arxiv.org/abs/2306.14403)

    本文提出了一种基于分数分布区分的异常检测方法，使用Overlap Loss损失函数最小化正常和异常样本的分数分布重叠区域，无需人工预定义的分数目标，能更好地适应不同数据场景，并在多个基准数据集上表现出更好的性能。

    

    近年来，对于能够利用少量标注异常数据与大量未标注数据的异常检测方法受到越来越多的关注。现有的基于异常信息的异常检测方法依赖于人工预定义的分数目标，例如先前的常量或边距超参数，以实现对正常和异常数据之间的异常分数区分。然而，这种方法容易受到未标注数据中异常污染的影响，并且缺乏对不同数据场景的适应性。本文提出了一种基于分数分布优化的异常评分函数，从而更好地保留输入数据的多样性和更细粒度的信息，特别是当未标注数据包含更实际的异常噪声时。我们设计了一种称为Overlap Loss的新型损失函数，它最小化正常和异常样本的分数分布重叠区域，不再依赖于先前的异常信息或预定义的目标。在几个基准数据集上的实验证明，我们提出的方法优于现有的基于异常信息的异常检测方法。

    Recent studies give more attention to the anomaly detection (AD) methods that can leverage a handful of labeled anomalies along with abundant unlabeled data. These existing anomaly-informed AD methods rely on manually predefined score target(s), e.g., prior constant or margin hyperparameter(s), to realize discrimination in anomaly scores between normal and abnormal data. However, such methods would be vulnerable to the existence of anomaly contamination in the unlabeled data, and also lack adaptation to different data scenarios. In this paper, we propose to optimize the anomaly scoring function from the view of score distribution, thus better retaining the diversity and more fine-grained information of input data, especially when the unlabeled data contains anomaly noises in more practical AD scenarios. We design a novel loss function called Overlap loss that minimizes the overlap area between the score distributions of normal and abnormal samples, which no longer depends on prior anom
    
[^15]: 比较因果框架：潜在结果、结构模型、图和抽象

    Comparing Causal Frameworks: Potential Outcomes, Structural Models, Graphs, and Abstractions. (arXiv:2306.14351v1 [stat.ME])

    [http://arxiv.org/abs/2306.14351](http://arxiv.org/abs/2306.14351)

    本文比较了因果框架中的潜在结果模型(RCM)和结构因果模型(SCM)，并阐明了RCM成为SCM可表达的条件，以及每个RCM作为某些可表达的RCM的抽象。作者介绍了SCM原则在RCM经典应用中的重要作用，并提出了由图表示的代数约束的特征，有助于进一步比较两个框架。

    

    本文旨在阐明潜在结果模型（RCM）与结构因果模型（SCM）框架在因果推断中的关系。采用中立的逻辑视角，借鉴以前的研究成果，我们展示了RCM成为SCM可表达的条件。一个关键结果显示，每个RCM -- 包括那些违反SCM框架中暗示的代数原则的RCM -- 作为某些可表达的RCM的抽象而出现。最后，我们通过准确定位SCM原则在RCM经典应用中的重要作用，阐明了这种改进性视角的优势；反之，我们提供了由图表示的代数约束的特征，有助于进一步比较两个框架。

    The aim of this paper is to make clear and precise the relationship between the Rubin causal model (RCM) and structural causal model (SCM) frameworks for causal inference. Adopting a neutral logical perspective, and drawing on previous work, we show what is required for an RCM to be representable by an SCM. A key result then shows that every RCM -- including those that violate algebraic principles implied by the SCM framework -- emerges as an abstraction of some representable RCM. Finally, we illustrate the power of this ameliorative perspective by pinpointing an important role for SCM principles in classic applications of RCMs; conversely, we offer a characterization of the algebraic constraints implied by a graph, helping to substantiate further comparisons between the two frameworks.
    
[^16]: 一种基于测试的方法来测量校准误差

    TCE: A Test-Based Approach to Measuring Calibration Error. (arXiv:2306.14343v1 [stat.ML])

    [http://arxiv.org/abs/2306.14343](http://arxiv.org/abs/2306.14343)

    本文提出基于测试的校准误差 （TCE）指标，使用了一种新颖的基于统计检验的损失函数来衡量模型预测与数据预估概率之间的差异，相对标准校准误差表示，具有解释清晰、一致刻度和增强视觉表示等优点。

    

    本文提出了一种用于测量概率二元分类器的校准误差的新指标，称为基于测试的校准误差 (TCE)。TCE采用一种基于统计测试的损失函数来检查模型预测与从数据估计的概率之间的差异程度。它提供了清晰的解释、一个不受类别不平衡影响的一致刻度以及相对于标准可靠性图的增强视觉表示。此外，我们还引入了一个基于经验概率最小估计误差的校准误差分箱程序的最优性准则，提供了一个新的针对限制箱子大小的最优箱子的计算算法。我们通过多个真实世界的不平衡数据集和ImageNet 1000等验证了TCE的特性。

    This paper proposes a new metric to measure the calibration error of probabilistic binary classifiers, called test-based calibration error (TCE). TCE incorporates a novel loss function based on a statistical test to examine the extent to which model predictions differ from probabilities estimated from data. It offers (i) a clear interpretation, (ii) a consistent scale that is unaffected by class imbalance, and (iii) an enhanced visual representation with repect to the standard reliability diagram. In addition, we introduce an optimality criterion for the binning procedure of calibration error metrics based on a minimal estimation error of the empirical probabilities. We provide a novel computational algorithm for optimal bins under bin-size constraints. We demonstrate properties of TCE through a range of experiments, including multiple real-world imbalanced datasets and ImageNet 1000.
    
[^17]: 基于共生学习的异方差回归的近似最优算法研究

    Near Optimal Heteroscedastic Regression with Symbiotic Learning. (arXiv:2306.14288v1 [stat.ML])

    [http://arxiv.org/abs/2306.14288](http://arxiv.org/abs/2306.14288)

    本研究提出了一种基于共生学习的异方差回归的近似最优算法，可以在统计学、计量经济学、时间序列分析等领域，以及在不同来源数据质量不一的机器学习中应用。

    

    本研究针对经典的异方差线性回归问题展开讨论。假设我们有n个样本 $(\mathbf{x}_i, y_i) \in \mathbb{R}^d \times \mathbb{R}$，其中 $y_i = \langle \mathbf{w}^{*}, \mathbf{x}_i \rangle + \epsilon_i \cdot \langle \mathbf{f}^{*}, \mathbf{x}_i \rangle$， $\mathbf{x}_i \sim N(0,\mathbf{I})$，$\epsilon_i \sim N(0,1)$，我们的目标是估计 $\mathbf{w}^{*}$。在统计学、计量经济学、时间序列分析等领域，异方差模型具有广泛的应用，同时，在机器学习中如果数据来源不同，而不同来源的数据质量也不一，则异方差模型也显得特别相关。本研究表明，我们可以估计出$\mathbf{w}^{*}$的平方范数，误差为$\tilde{O}\left(\|\mathbf{f}^{*}\|^2 \cdot \left(\frac{1}{n} + \left(\frac{d}{n}\right)^2\right)\right)$，并证明了一个匹配的下限（上界存在对数因子）。本研究的结果显著改进了异方差回归问题的近似最优算法。

    We consider the classical problem of heteroscedastic linear regression, where we are given $n$ samples $(\mathbf{x}_i, y_i) \in \mathbb{R}^d \times \mathbb{R}$ obtained from $y_i = \langle \mathbf{w}^{*}, \mathbf{x}_i \rangle + \epsilon_i \cdot \langle \mathbf{f}^{*}, \mathbf{x}_i \rangle$, where $\mathbf{x}_i \sim N(0,\mathbf{I})$, $\epsilon_i \sim N(0,1)$, and our task is to estimate $\mathbf{w}^{*}$. In addition to the classical applications of heteroscedastic models in fields such as statistics, econometrics, time series analysis etc., it is also particularly relevant in machine learning when data is collected from multiple sources of varying but apriori unknown quality, e.g., large model training. Our work shows that we can estimate $\mathbf{w}^{*}$ in squared norm up to an error of $\tilde{O}\left(\|\mathbf{f}^{*}\|^2 \cdot \left(\frac{1}{n} + \left(\frac{d}{n}\right)^2\right)\right)$ and prove a matching lower bound (up to logarithmic factors). Our result substantially improves 
    
[^18]: 朝着可信的解释：因果关系解释论文研究

    Towards Trustworthy Explanation: On Causal Rationalization. (arXiv:2306.14115v1 [cs.LG])

    [http://arxiv.org/abs/2306.14115](http://arxiv.org/abs/2306.14115)

    该论文介绍了一种新的因果关系解释方法，通过在解释中引入非虚假性和效率，从因果推断的角度定义了因果概率，从而建立了必要和充分解释的主要组成部分，相比现有的基于关联的解释方法，这种方法有更加优越的性能表现。

    

    随着自然语言处理的最新进展，解释成为了通过选择输入文本的子集来解释黑盒模型中主要变化的一个基本的自我解释图。然而，现有的基于关联的解释方法在两个或多个片段高度互相关联时无法识别真正的解释，因此对预测准确性提供类似的贡献，所谓的虚假性。为了解决这一限制，我们从因果推断的角度新颖地将两个因果期望值（非虚假性和效率）引入了解释中。我们根据一种新提出的解释结构因果模型定义了一系列的因果概率，通过其理论鉴定，建立了必要和充分解释的主要组成部分。我们在真实世界的评论和医疗数据集上证明了所提出的因果关系解释的优越性能。

    With recent advances in natural language processing, rationalization becomes an essential self-explaining diagram to disentangle the black box by selecting a subset of input texts to account for the major variation in prediction. Yet, existing association-based approaches on rationalization cannot identify true rationales when two or more snippets are highly inter-correlated and thus provide a similar contribution to prediction accuracy, so-called spuriousness. To address this limitation, we novelly leverage two causal desiderata, non-spuriousness and efficiency, into rationalization from the causal inference perspective. We formally define a series of probabilities of causation based on a newly proposed structural causal model of rationalization, with its theoretical identification established as the main component of learning necessary and sufficient rationales. The superior performance of the proposed causal rationalization is demonstrated on real-world review and medical datasets w
    
[^19]: RLHF是否比标准RL更困难？

    Is RLHF More Difficult than Standard RL?. (arXiv:2306.14111v1 [cs.LG])

    [http://arxiv.org/abs/2306.14111](http://arxiv.org/abs/2306.14111)

    本文证明了对于广泛的偏好模型，我们可以使用现有的算法和技术直接解决基于偏好的RL问题，而几乎不需要额外的成本。

    

    从人类反馈学习的强化学习（RLHF）是从偏好信号学习，而标准强化学习（RL）则直接从奖励信号学习。偏好信号可能包含的信息比奖励信号少，这使得基于偏好的RL似乎更加困难。本文理论上证明，对于广泛的偏好模型，我们可以使用现有的算法和技术直接解决基于偏好的RL问题，而几乎不需要额外的成本。具体而言，我们将问题分为两类：（1）基于奖励概率模型的偏好，此时可以将问题简化为容忍奖励小误差的鲁棒奖励RL问题；（2）对于一般的任意偏好且目标是找到von Neumann获胜者的情况，我们将问题简化为多智能体奖励RL问题，该问题可以在一组受限制的策略下找到马尔可夫博弈的因子纳什平衡解。后一种情况可以进一步降低成对关系的MDP。

    Reinforcement learning from Human Feedback (RLHF) learns from preference signals, while standard Reinforcement Learning (RL) directly learns from reward signals. Preferences arguably contain less information than rewards, which makes preference-based RL seemingly more difficult. This paper theoretically proves that, for a wide range of preference models, we can solve preference-based RL directly using existing algorithms and techniques for reward-based RL, with small or no extra costs. Specifically, (1) for preferences that are drawn from reward-based probabilistic models, we reduce the problem to robust reward-based RL that can tolerate small errors in rewards; (2) for general arbitrary preferences where the objective is to find the von Neumann winner, we reduce the problem to multiagent reward-based RL which finds Nash equilibria for factored Markov games under a restricted set of policies. The latter case can be further reduce to adversarial MDP when preferences only depend on the f
    
[^20]: 非同质化集群下的无线联邦学习中的私有数据聚合

    Private Aggregation in Wireless Federated Learning with Heterogeneous Clusters. (arXiv:2306.14088v1 [cs.LG])

    [http://arxiv.org/abs/2306.14088](http://arxiv.org/abs/2306.14088)

    本文探讨了在一个无线系统中，考虑到信息论隐私的条件下，通过基站连接到联合器的客户端，如何解决联邦学习中的隐私数据聚合问题。

    

    联邦学习是通过多个参与客户端私有数据的协同训练神经网络的方法。在训练神经网络的过程中，使用一种著名并广泛使用的迭代优化算法——梯度下降算法。每个客户端使用本地数据计算局部梯度并将其发送给联合器以进行聚合。客户端数据的隐私是一个主要问题。实际上，观察到局部梯度就足以泄露客户端的数据。已研究了用于应对联邦学习中隐私问题的私有聚合方案，其中所有用户都彼此连接并与联合器连接。本文考虑了一个无线系统架构，其中客户端仅通过基站连接到联合器。当需要信息论隐私时，我们推导出通信成本的基本极限，并引入和分析了一种针对这种情况量身定制的私有聚合方案。

    Federated learning collaboratively trains a neural network on privately owned data held by several participating clients. The gradient descent algorithm, a well-known and popular iterative optimization procedure, is run to train the neural network. Every client uses its local data to compute partial gradients and sends it to the federator which aggregates the results. Privacy of the clients' data is a major concern. In fact, observing the partial gradients can be enough to reveal the clients' data. Private aggregation schemes have been investigated to tackle the privacy problem in federated learning where all the users are connected to each other and to the federator. In this paper, we consider a wireless system architecture where clients are only connected to the federator via base stations. We derive fundamental limits on the communication cost when information-theoretic privacy is required, and introduce and analyze a private aggregation scheme tailored for this setting.
    
[^21]: 平滑的$f$-散度分布鲁棒优化：指数率效率和不带复杂性的校准。

    Smoothed $f$-Divergence Distributionally Robust Optimization: Exponential Rate Efficiency and Complexity-Free Calibration. (arXiv:2306.14041v1 [math.OC])

    [http://arxiv.org/abs/2306.14041](http://arxiv.org/abs/2306.14041)

    分布鲁棒优化在实现统计保证界限时存在限制和保守性问题，但平滑的$f$-散度分布鲁棒优化可在指数衰减率方面实现最紧密的统计保证。

    

    在数据驱动的优化中，样本平均逼近已知存在一个所谓的优化者诅咒，会导致在评估解决方案性能时产生乐观偏差。可以通过在估计的目标值中增加“保证空间”或通过分布鲁棒优化（DRO）来解决这个问题，后者是一种快速增长的方法，基于最坏情况分析，为获得的目标价值提供了保护界限。然而，在所有这些现有方法中，对真实解决方案性能的统计保证界限要么需要对目标函数复杂性有限制性条件和知识，要么会表现出取决于分布维度的过于保守的速率。我们认为，在这些挑战方面，一种特殊类型的DRO在理论上提供了强大的优势：对于一大类目标函数，它获得了对真实解的解决方案性能的统计界限，这在指数衰减率方面是可能的，就其紧缩程度而言，要紧密得多。

    In data-driven optimization, sample average approximation is known to suffer from the so-called optimizer's curse that causes optimistic bias in evaluating the solution performance. This can be tackled by adding a "margin" to the estimated objective value, or via distributionally robust optimization (DRO), a fast-growing approach based on worst-case analysis, which gives a protective bound on the attained objective value. However, in all these existing approaches, a statistically guaranteed bound on the true solution performance either requires restrictive conditions and knowledge on the objective function complexity, or otherwise exhibits an over-conservative rate that depends on the distribution dimension. We argue that a special type of DRO offers strong theoretical advantages in regard to these challenges: It attains a statistical bound on the true solution performance that is the tightest possible in terms of exponential decay rate, for a wide class of objective functions that not
    
[^22]: 用于非平滑目标函数的零集中度私有分布式学习

    Zero-Concentrated Private Distributed Learning for Nonsmooth Objective Functions. (arXiv:2306.14012v1 [math.OC])

    [http://arxiv.org/abs/2306.14012](http://arxiv.org/abs/2306.14012)

    本文提出了一种用于解决非平滑优化问题的完全分布式的差分隐私学习算法，保证零集中度差分隐私，具有更好的准确性和更强的保证，并且处理非平滑和非必须强凸问题。

    

    本文开发了一种完全分布式的差分隐私学习算法来解决非平滑优化问题。我们将交替方向乘子法（ADMM）分布到分布式设置中，并采用增广拉格朗日近似来处理非平滑目标函数。此外，我们通过在每个代理处用方差递减的高斯噪声扰动计算结果来确保零集中差分隐私（zCDP）。这种隐私保护方法允许比传统的$(\epsilon，\delta)$-DP更好的准确性，比最近的Rényi-DP提供更强的保证。开发的完全分布式算法具有竞争性的隐私准确性平衡，并处理非平滑和非必须强凸问题。我们提供了隐私保证和算法收敛到精确解的完整理论证明。我们还证明，在其他假设下，该算法的收敛速度比集中式非私有算法更快。

    This paper develops a fully distributed differentially-private learning algorithm to solve nonsmooth optimization problems. We distribute the Alternating Direction Method of Multipliers (ADMM) to comply with the distributed setting and employ an approximation of the augmented Lagrangian to handle nonsmooth objective functions. Furthermore, we ensure zero-concentrated differential privacy (zCDP) by perturbing the outcome of the computation at each agent with a variance-decreasing Gaussian noise. This privacy-preserving method allows for better accuracy than the conventional $(\epsilon, \delta)$-DP and stronger guarantees than the more recent R\'enyi-DP. The developed fully distributed algorithm has a competitive privacy accuracy trade-off and handles nonsmooth and non-necessarily strongly convex problems. We provide complete theoretical proof for the privacy guarantees and the convergence of the algorithm to the exact solution. We also prove under additional assumptions that the algorit
    
[^23]: 学习映射用于肽构象间的有针对性自由能扰动

    Learned Mappings for Targeted Free Energy Perturbation between Peptide Conformations. (arXiv:2306.14010v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2306.14010](http://arxiv.org/abs/2306.14010)

    本文研究了将机器学习用于映射自由能扰动中的Boltzmann分布，以求得Deca-Alanine分子的自由能差异。当弹簧中心相隔较近时，该方法可以得到准确的结果，但当弹簧中心相隔较远时，该方法无法得到代表目标状态的结构和正确的结果。

    

    有针对性自由能扰动利用可逆映射来促进构象空间的重叠和自由能估计的收敛。然而，开发合适的映射可能具有挑战性。Wirnsberger等人（2020）展示了使用机器学习来训练深度神经网络，将不同热力学状态的Boltzmann分布之间进行映射。在本文中，我们将他们的方法应用到具有不同弹簧中心的弹性键合分子Deca-Alanine的自由能差异上。当神经网络训练到“提前停止”-即测试集的损失值增加时-我们可以计算出弹簧中心相隔1Å和有时2Å的热力学状态之间的准确自由能差异。对于更远的热力学状态，该映射不会产生代表目标状态的结构，该方法也无法复现参考计算。

    Targeted free energy perturbation uses an invertible mapping to promote configuration space overlap and the convergence of free energy estimates. However, developing suitable mappings can be challenging. Wirnsberger et al. (2020) demonstrated the use of machine learning to train deep neural networks that map between Boltzmann distributions for different thermodynamic states. Here, we adapt their approach to free energy differences of a flexible bonded molecule, deca-alanine, with harmonic biases with different spring centers. When the neural network is trained until ``early stopping'' - when the loss value of the test set increases - we calculate accurate free energy differences between thermodynamic states with spring centers separated by 1 \r{A} and sometimes 2 \r{A}. For more distant thermodynamic states, the mapping does not produce structures representative of the target state and the method does not reproduce reference calculations.
    
[^24]: 使用数据自适应能量距离的高维数据稳健分类

    Robust Classification of High-Dimensional Data using Data-Adaptive Energy Distance. (arXiv:2306.13985v1 [stat.ML])

    [http://arxiv.org/abs/2306.13985](http://arxiv.org/abs/2306.13985)

    该论文提出了一种用于高维低样本量数据分类的稳健的数据自适应能量距离分类器，该分类器无需调参且在一定条件下可以实现完美分类，已在模拟研究和实际数据分析中得到证明比其他方法表现更优。

    

    在真实世界中，高维低样本量（HDLSS）数据的分类面临挑战，例如基因表达研究、癌症研究和医学成像等领域。本文提出了一些专门为HDLSS数据设计的分类器的开发和分析。这些分类器没有调节参数，并且是稳健的，因为它们不受底层数据分布的任何矩条件的影响。研究表明，在一些相当普遍的条件下，它们在HDLSS渐近区域内可以实现完美分类。还比较了所提出分类器的性能。我们的理论结果得到了广泛的模拟研究和实际数据分析的支持，证明了所提出分类技术优于几种广泛认可的方法的有希望优势。

    Classification of high-dimensional low sample size (HDLSS) data poses a challenge in a variety of real-world situations, such as gene expression studies, cancer research, and medical imaging. This article presents the development and analysis of some classifiers that are specifically designed for HDLSS data. These classifiers are free of tuning parameters and are robust, in the sense that they are devoid of any moment conditions of the underlying data distributions. It is shown that they yield perfect classification in the HDLSS asymptotic regime, under some fairly general conditions. The comparative performance of the proposed classifiers is also investigated. Our theoretical results are supported by extensive simulation studies and real data analysis, which demonstrate promising advantages of the proposed classification techniques over several widely recognized methods.
    
[^25]: 规则化的多元函数主成分分析

    Regularized Multivariate Functional Principal Component Analysis. (arXiv:2306.13980v1 [stat.ME])

    [http://arxiv.org/abs/2306.13980](http://arxiv.org/abs/2306.13980)

    本文提出了一种称为规则化MFPCA的新方法，用于平滑和增强多元函数PC的可解释性，为分析和发现复杂的多元函数数据中的关系开辟了新的途径。

    

    多元函数主成分分析（MFPCA）是探索多元函数数据关系和识别共享变化模式的有价值工具。然而，控制提取的主成分的平滑度可能会具有挑战性。本文引入了一种称为规则化MFPCA（ReMFPCA）的新方法来解决这个问题，并增强多元函数PC的平滑度和可解释性。ReMFPCA在惩罚框架内使用参数向量来调节每个函数变量的平滑度，内含一个粗糙度惩罚项。该方法生成平滑的多元函数PC，提供了数据的简明和可解释的表示。广泛的模拟和实际数据示例证明了ReMFPCA的有效性和优越性。所提出的方法为分析和发现复杂的多元函数数据中的关系开辟了新的途径。

    Multivariate Functional Principal Component Analysis (MFPCA) is a valuable tool for exploring relationships and identifying shared patterns of variation in multivariate functional data. However, controlling the roughness of the extracted Principal Components (PCs) can be challenging. This paper introduces a novel approach called regularized MFPCA (ReMFPCA) to address this issue and enhance the smoothness and interpretability of the multivariate functional PCs. ReMFPCA incorporates a roughness penalty within a penalized framework, using a parameter vector to regulate the smoothness of each functional variable. The proposed method generates smoothed multivariate functional PCs, providing a concise and interpretable representation of the data. Extensive simulations and real data examples demonstrate the effectiveness of ReMFPCA and its superiority over alternative methods. The proposed approach opens new avenues for analyzing and uncovering relationships in complex multivariate functional
    
[^26]: 利用外样本和重抽样策略优化结构学习算法的超参数调整方法

    Tuning structure learning algorithms with out-of-sample and resampling strategies. (arXiv:2306.13932v1 [cs.LG])

    [http://arxiv.org/abs/2306.13932](http://arxiv.org/abs/2306.13932)

    本文提出了一种新的超参数调整方法 OTSL，它采用外样本和重抽样策略来估算给定输入数据集和结构学习算法的最佳超参数配置。实验表明，该方法优于现有技术，可提高结构学习算法的图形准确性。

    

    当实践者将结构学习算法应用于其数据时，面临的挑战之一是确定一组超参数；否则，假定一组超参数默认值。最佳超参数配置常常取决于多种因素，包括通常未知的真实底层图的大小和密度、输入数据的样本大小和结构学习算法等。我们提出了一种新的超参数调整方法，名为Out-of-sample Tuning for Structure Learning（OTSL），它采用外样本和重抽样策略来估算给定输入数据集和结构学习算法的最佳超参数配置。合成实验表明，使用OTSL作为混合和基于分数的结构学习算法的超参数调整手段，相对于现有技术，能够提高图形准确性。我们还演示了该方法在几个真实数据集中的适用性。

    One of the challenges practitioners face when applying structure learning algorithms to their data involves determining a set of hyperparameters; otherwise, a set of hyperparameter defaults is assumed. The optimal hyperparameter configuration often depends on multiple factors, including the size and density of the usually unknown underlying true graph, the sample size of the input data, and the structure learning algorithm. We propose a novel hyperparameter tuning method, called the Out-of-sample Tuning for Structure Learning (OTSL), that employs out-of-sample and resampling strategies to estimate the optimal hyperparameter configuration for structure learning, given the input data set and structure learning algorithm. Synthetic experiments show that employing OTSL as a means to tune the hyperparameters of hybrid and score-based structure learning algorithms leads to improvements in graphical accuracy compared to the state-of-the-art. We also illustrate the applicability of this approa
    
[^27]: G-TRACER: 预期清晰度优化

    G-TRACER: Expected Sharpness Optimization. (arXiv:2306.13914v1 [stat.ML])

    [http://arxiv.org/abs/2306.13914](http://arxiv.org/abs/2306.13914)

    G-TRACER是一种正则化深度学习结构优化方案，重点解决低信噪比问题，能有效促进泛化并获得了竞争性能。

    

    我们提出了一种新的深度学习结构优化正则化方案，G-TRACER（"Geometric TRACE Ratio"），通过寻求平坦最小值促进泛化，并具有以广义Bayes目标的自然梯度下降为基础的理论基础。通过使用TRACER增加损失函数，曲率正则化优化器（例如SGD-TRACER和Adam-TRACER）可以作为现有优化器的修改简单地实现，不需要进行广泛的调整。我们展示了该方法收敛于未正则化目标的局部最小值附近（取决于正则化强度的邻域范围），并在许多基准计算机视觉和NLP数据集上展示了竞争性能，特别关注挑战性的低信噪比问题。

    We propose a new regularization scheme for the optimization of deep learning architectures, G-TRACER ("Geometric TRACE Ratio"), which promotes generalization by seeking flat minima, and has a sound theoretical basis as an approximation to a natural-gradient descent based optimization of a generalized Bayes objective. By augmenting the loss function with a TRACER, curvature-regularized optimizers (eg SGD-TRACER and Adam-TRACER) are simple to implement as modifications to existing optimizers and don't require extensive tuning. We show that the method converges to a neighborhood (depending on the regularization strength) of a local minimum of the unregularized objective, and demonstrate competitive performance on a number of benchmark computer vision and NLP datasets, with a particular focus on challenging low signal-to-noise ratio problems.
    
[^28]: 使用随机分组套索估计器进行广义模型的选择性推断。

    Selective inference using randomized group lasso estimators for general models. (arXiv:2306.13829v1 [stat.ME])

    [http://arxiv.org/abs/2306.13829](http://arxiv.org/abs/2306.13829)

    研究了一种使用随机分组套索估计器进行广义模型的选择性推断方法，可以考虑分类或分组协变量以及连续协变量，并且有证据表明其具有适当性和准确性。

    

    为了与广泛的分布和损失函数一起使用，开发了选择性推理方法，用于组套索估计器。该方法包括使用指数家族分布，以及像过度离散计数数据的拟然模型等，允许分类或分组协变量以及连续协变量。研究了一种随机的组正则化优化问题。添加的随机化使我们可以构建后选择似然，我们证明在条件选择分组协变量的事件上适用于选择性推断。这个似然也提供了一个选择性点估计，通过组套索考虑了选择。选择的模型中回归参数的置信区间采用沃尔德类型的区间，并证明具有有界体积。以美国国家健康和营养调查的数据为例展示了组套索的选择性推理方法。

    Selective inference methods are developed for group lasso estimators for use with a wide class of distributions and loss functions. The method includes the use of exponential family distributions, as well as quasi-likelihood modeling for overdispersed count data, for example, and allows for categorical or grouped covariates as well as continuous covariates. A randomized group-regularized optimization problem is studied. The added randomization allows us to construct a post-selection likelihood which we show to be adequate for selective inference when conditioning on the event of the selection of the grouped covariates. This likelihood also provides a selective point estimator, accounting for the selection by the group lasso. Confidence regions for the regression parameters in the selected model take the form of Wald-type regions and are shown to have bounded volume. The selective inference method for grouped lasso is illustrated on data from the national health and nutrition examinatio
    
[^29]: 乘客轨迹聚类的张量狄利克雷过程多项式混合模型

    Tensor Dirichlet Process Multinomial Mixture Model for Passenger Trajectory Clustering. (arXiv:2306.13794v1 [stat.ML])

    [http://arxiv.org/abs/2306.13794](http://arxiv.org/abs/2306.13794)

    提出了一种基于张量的狄利克雷过程多项式混合模型（Tensor-DPMM），通过张量保留了多维行程信息的多模式和分层结构，并以统一的一步方式进行乘客轨迹聚类，在自动确定聚类数方面具有优越性。

    

    基于出行记录的乘客聚类对于运输运营商至关重要。然而，现有方法由于乘客行程信息的分层结构而难以轻松进行乘客聚类，即：每个乘客有多次出行，每次出行包含多维多模式信息。此外，现有方法依赖于精确指定聚类数量开始，而每天有数百万通勤者使用交通系统时这是困难的。本文提出了一种新颖的基于张量的狄利克雷过程多项式混合模型（Tensor-DPMM），通过张量保留了多维行程信息的多模式和分层结构，并以统一的一步方式对它们进行聚类。该模型还通过使用狄利克雷过程决定乘客分配至现有聚类还是形成新聚类的概率，自动确定聚类数的能力。在真实的交通运输数据集上的实验表明，我们提出的Tensor-DPMM模型在乘客轨迹聚类方面具有优越性。

    Passenger clustering based on travel records is essential for transportation operators. However, existing methods cannot easily cluster the passengers due to the hierarchical structure of the passenger trip information, namely: each passenger has multiple trips, and each trip contains multi-dimensional multi-mode information. Furthermore, existing approaches rely on an accurate specification of the clustering number to start, which is difficult when millions of commuters are using the transport systems on a daily basis. In this paper, we propose a novel Tensor Dirichlet Process Multinomial Mixture model (Tensor-DPMM), which is designed to preserve the multi-mode and hierarchical structure of the multi-dimensional trip information via tensor, and cluster them in a unified one-step manner. The model also has the ability to determine the number of clusters automatically by using the Dirichlet Process to decide the probabilities for a passenger to be either assigned in an existing cluster 
    
[^30]: 机器学习算法泛化误差的新方法：估计和收敛性

    A new approach to generalisation error of machine learning algorithms: Estimates and convergence. (arXiv:2306.13784v1 [stat.ML])

    [http://arxiv.org/abs/2306.13784](http://arxiv.org/abs/2306.13784)

    本文提出了一种新的机器学习算法泛化误差的估计方法和收敛性分析，可以在不需要神经网络的任何假设下对误差进行估计，并只要求神经网络具有适当的逼近能力就可以将近似转化为目标函数f。

    

    本文考虑了深度神经学习的一个模型问题，即在有限的点集上已知一个函数的点值，学习该函数。通过典型的机器学习算法，包括给定的DNN体系结构和一个被认为可以完全解决的优化步骤，得到了深度神经网络插值器，该插值器是f的近似。在本文中，我们引入了一种估计（泛化）误差和收敛性的新方法。我们的结果包括：（i）在神经网络没有任何结构性假设的情况下，并在学习函数f的温和正则性假设下估计误差，（ii）只要神经网络空间具有适当的逼近能力，就可以将近似转化为目标函数f。

    In this work we consider a model problem of deep neural learning, namely the learning of a given function when it is assumed that we have access to its point values on a finite set of points. The deep neural network interpolant is the the resulting approximation of f, which is obtained by a typical machine learning algorithm involving a given DNN architecture and an optimisation step, which is assumed to be solved exactly. These are among the simplest regression algorithms based on neural networks. In this work we introduce a new approach to the estimation of the (generalisation) error and to convergence. Our results include (i) estimates of the error without any structural assumption on the neural networks and under mild regularity assumptions on the learning function f (ii) convergence of the approximations to the target function f by only requiring that the neural network spaces have appropriate approximation capability.
    
[^31]: 在预测之后的有效推断

    Valid inference after prediction. (arXiv:2306.13746v1 [stat.ML])

    [http://arxiv.org/abs/2306.13746](http://arxiv.org/abs/2306.13746)

    最近的研究聚焦于基于预测的推断，并提出了修正步骤以实现对未观测到响应和协变量之间关系的有效推断，Angelopoulos等人（2023）的方法成功控制了第一类错误率，并提供了正确命名覆盖的置信区间，但在某些情况下，其存在低功率问题。

    

    近期的研究聚焦于基于预测的推断，即使用预先训练好的机器学习模型预测未观测到的响应变量，然后对该预测响应与某些协变量之间的关系进行推断。然而，将标准推断方法应用于该过程并不能准确量化未观测到（而非预测到）响应与协变量之间的关系。最近，Wang等人（2020）和Angelopoulos等人（2023）提出了修正（ii）步骤的方法，以实现对未观测到响应和协变量之间关系的有效推断。本文表明，Angelopoulos等人（2023）提出的方法成功地控制了第一类错误率，并提供了具有正确命名覆盖的置信区间，无论预先训练的机器学习模型用于预测未观测到的响应的质量如何。然而，我们也发现在某些情况下，所提出的方法具有低功率。

    Recent work has focused on the very common practice of prediction-based inference: that is, (i) using a pre-trained machine learning model to predict an unobserved response variable, and then (ii) conducting inference on the association between that predicted response and some covariates. As pointed out by Wang et al. [2020], applying a standard inferential approach in (ii) does not accurately quantify the association between the unobserved (as opposed to the predicted) response and the covariates. In recent work, Wang et al. [2020] and Angelopoulos et al. [2023] propose corrections to step (ii) in order to enable valid inference on the association between the unobserved response and the covariates. Here, we show that the method proposed by Angelopoulos et al. [2023] successfully controls the type 1 error rate and provides confidence intervals with correct nominal coverage, regardless of the quality of the pre-trained machine learning model used to predict the unobserved response. Howe
    
[^32]: 估算基于证据决策的价值

    Estimating the Value of Evidence-Based Decision Making. (arXiv:2306.13681v1 [stat.ME])

    [http://arxiv.org/abs/2306.13681](http://arxiv.org/abs/2306.13681)

    本文提出了一个实证框架，用于估算证据决策的价值和统计精度投资回报。

    

    商业/政策决策通常基于随机实验和观察性研究的证据。本文提出了一个实证框架来估算基于证据的决策（EBDM）的价值和统计精度投资回报。

    Business/policy decisions are often based on evidence from randomized experiments and observational studies. In this article we propose an empirical framework to estimate the value of evidence-based decision making (EBDM) and the return on the investment in statistical precision.
    
[^33]: 驾驭指数级的动作集：在线拥塞博弈中次线性遗憾和快速收敛到纳什均衡

    Taming the Exponential Action Set: Sublinear Regret and Fast Convergence to Nash Equilibrium in Online Congestion Games. (arXiv:2306.13673v1 [cs.GT])

    [http://arxiv.org/abs/2306.13673](http://arxiv.org/abs/2306.13673)

    本文提出了一种名为CongestEXP的分散算法，可以线性缩放设施数量，实现在线拥塞博弈的次线性遗憾上界，并以与已知最佳下界相匹配的速度快速收敛到纳什均衡。

    

    拥塞博弈是一种强大的模型，涵盖了交通网络和资源分配等一系列工程系统。本文研究拥塞博弈的在线形式，其中代理重复参与博弈，并观察到带有随机性的反馈。我们提出了一种名为CongestEXP的分散算法，应用于经典的指数权重方法，通过在设施级别上保持权重，避免了传统算法对可能设施集大小的指数依赖，即$\binom{F}{k}\approx F^k$，并且仅与$F$线性缩放。具体地，我们证明了对于每个单独的玩家，CongestEXP可以实现$O(kF\sqrt{T})$的遗憾上界，其中$T$是时间周期。另一方面，利用权重的指数增长使CongestEXP能够实现快速收敛到纳什均衡，其收敛速度为$O(\ln F/\sqrt{T})$，这与已知的最佳下界相符，仅相差对数因子。我们的分析也适用于更广泛的游戏类别，包括那些具有连续分布权重和那些具有任意玩家行动的游戏。最后，我们在合成数据集和实际数据集上证明了CongestEXP的有效性。

    The congestion game is a powerful model that encompasses a range of engineering systems such as traffic networks and resource allocation. It describes the behavior of a group of agents who share a common set of $F$ facilities and take actions as subsets with $k$ facilities. In this work, we study the online formulation of congestion games, where agents participate in the game repeatedly and observe feedback with randomness. We propose CongestEXP, a decentralized algorithm that applies the classic exponential weights method. By maintaining weights on the facility level, the regret bound of CongestEXP avoids the exponential dependence on the size of possible facility sets, i.e., $\binom{F}{k} \approx F^k$, and scales only linearly with $F$. Specifically, we show that CongestEXP attains a regret upper bound of $O(kF\sqrt{T})$ for every individual player, where $T$ is the time horizon. On the other hand, exploiting the exponential growth of weights enables CongestEXP to achieve a fast conv
    
[^34]: 通过重要性抽样实现有效通信的联邦学习

    Communication-Efficient Federated Learning through Importance Sampling. (arXiv:2306.12625v1 [cs.LG])

    [http://arxiv.org/abs/2306.12625](http://arxiv.org/abs/2306.12625)

    本文提出了一种通过重要性抽样实现有效通信的联邦学习方法，大大降低了发送模型更新的高通信成本，利用服务器端客户端分布和附加信息的接近关系，只需要较少的通信量即可实现。

    

    客户端向服务器发送模型更新的高通信成本是可扩展联邦学习（FL）的重要瓶颈。现有方法中，使用随机压缩方法实现了最先进的比特率-准确性折衷——其中客户端n发送来自仅为该客户端的概率分布qφ（n）的样本，服务器使用这些样本估计客户端分布的平均值。然而，这种方法没有充分利用FL的设置，其中服务器在整个训练过程中具有预数据分布pθ的附加信息，该分布与客户端分布qφ（n）在Kullback-Leibler（KL）发散方面接近。在本文中，我们利用服务器端客户端分布qφ（n)与附加信息pθ之间的这种接近关系，并提出了一种框架，该框架需要大约Dkl（qφ（n）|| pθ）位的通信量。

    The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods -- in which the client $n$ sends a sample from a client-only probability distribution $q_{\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a pre-data distribution $p_{\theta}$ that is close to the client's distribution $q_{\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this closeness between the clients' distributions $q_{\phi^{(n)}}$'s and the side information $p_{\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\phi^{(n)}}|| p_{\theta})$ bits of com
    
[^35]: 图分类问题中结构感知的鲁棒性认证

    Structure-Aware Robustness Certificates for Graph Classification. (arXiv:2306.11915v1 [cs.LG])

    [http://arxiv.org/abs/2306.11915](http://arxiv.org/abs/2306.11915)

    该论文提出了一种新的随机平滑方法，可以根据图的不同预定义结构生成对应的鲁棒性证书，从而在多个基准图分类任务中取得领先的对抗性攻击下鲁棒性结果。

    

    对于基于图的机器学习模型进行鲁棒性认证是保证安全性的一个至关重要的挑战。目前用于图分类器的鲁棒性证明保证与节点对翻转（添加或删除边缘）的总数有关，这相当于以邻接矩阵为中心的l0球。尽管从理论上看很有吸引力，但这种各向同性的结构噪声在实际场景中可能过于严格，因为有些节点对于确定分类器的输出更为关键。在这种情况下，证书给出了对图模型鲁棒性的悲观描述。为了解决这个问题，我们开发了一种基于随机平滑的方法，将非各向同性的噪声分布添加到输入图结构中。我们展示了我们的过程为分类器生成了结构感知的证书，因此鲁棒性证书的大小可以在图的不同预定义结构之间变化。我们在几个基准图分类任务上展示了我们方法的优势，在对抗性攻击的鲁棒性方面取得了最先进的结果。

    Certifying the robustness of a graph-based machine learning model poses a critical challenge for safety. Current robustness certificates for graph classifiers guarantee output invariance with respect to the total number of node pair flips (edge addition or edge deletion), which amounts to an $l_{0}$ ball centred on the adjacency matrix. Although theoretically attractive, this type of isotropic structural noise can be too restrictive in practical scenarios where some node pairs are more critical than others in determining the classifier's output. The certificate, in this case, gives a pessimistic depiction of the robustness of the graph model. To tackle this issue, we develop a randomised smoothing method based on adding an anisotropic noise distribution to the input graph structure. We show that our process generates structural-aware certificates for our classifiers, whereby the magnitude of robustness certificates can vary across different pre-defined structures of the graph. We demon
    
[^36]: 是否应该停止：具有异质种群的早期停止方法

    Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations. (arXiv:2306.11839v1 [stat.ME])

    [http://arxiv.org/abs/2306.11839](http://arxiv.org/abs/2306.11839)

    本文提出了针对于异质种群有害实验的早期停止方法CLASH，使用因果机器学习可以有效提前停止临床试验和A/B测试。

    

    随机实验由于治疗造成意外的有害影响，因此往往需要提前停止。目前确定何时提前终止实验的现有方法通常适用于总体数据，不考虑治疗效应的异质性。本文研究了针对异质种群有害实验的早期停止方法。我们首先确定现有方法在治疗对少数参与者造成伤害时往往无法停止实验。然后使用因果机器学习开发了CLASH，这是首个广泛适用于异质早期停止的方法。我们在模拟和实际数据上展示了CLASH的表现，并证明它在临床试验和A/B测试中都能有效提前停止。

    Randomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests.
    
[^37]: 实用的锐度感知优化算法不能全程向最优点收敛

    Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima. (arXiv:2306.09850v1 [cs.LG])

    [http://arxiv.org/abs/2306.09850](http://arxiv.org/abs/2306.09850)

    该研究揭示了实用的锐度感知优化算法在某些情况下不能够全程向最优点收敛。

    

    锐度感知优化(SAM)是一种优化器，它基于当前点$x_t$的梯度，在扰动$y_t=x_t+\rho\frac{\nabla f(x_t)}{\lVert\nabla f(x_t)\rVert}$处进行下降。现有研究证明了SAM对于平滑函数的收敛性，但是它们假设扰动的大小$\rho$逐渐衰减和/或在$y_t$中没有梯度归一化，这与实践不符。为了弥补这一差距，我们研究了具有实用配置（即常数$\rho$和$y_t$中的梯度归一化）的确定性/随机版本的SAM，并探讨了它们在具有（非）凸性假设的平滑函数上的收敛性质。令人惊讶的是，在许多情况下，我们发现SAM在收敛到全局最小值或稳定点方面具有有限的能力。对于平滑强凸函数，我们展示了确定性SAM具有严格的全局收敛率为$\tilde\Theta(\frac{1}{T^2})$，而随机SAM的收敛界则受到噪声水平降低的影响，这表明了平面目标表面的尖锐度和平缓性之间平衡的挑战。

    Sharpness-Aware Minimization (SAM) is an optimizer that takes a descent step based on the gradient at a perturbation $y_t = x_t + \rho \frac{\nabla f(x_t)}{\lVert \nabla f(x_t) \rVert}$ of the current point $x_t$. Existing studies prove convergence of SAM for smooth functions, but they do so by assuming decaying perturbation size $\rho$ and/or no gradient normalization in $y_t$, which is detached from practice. To address this gap, we study deterministic/stochastic versions of SAM with practical configurations (i.e., constant $\rho$ and gradient normalization in $y_t$) and explore their convergence properties on smooth functions with (non)convexity assumptions. Perhaps surprisingly, in many scenarios, we find out that SAM has limited capability to converge to global minima or stationary points. For smooth strongly convex functions, we show that while deterministic SAM enjoys tight global convergence rates of $\tilde \Theta(\frac{1}{T^2})$, the convergence bound of stochastic SAM suffer
    
[^38]: 核去偏插值估计

    Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])

    [http://arxiv.org/abs/2306.08598](http://arxiv.org/abs/2306.08598)

    本文提出了一种高效、不需要实现影响函数且可计算的去偏插值估计方法。

    

    本文考虑在干扰参数存在的情况下估计标量目标参数的问题。采用非参数估计器（例如机器学习（ML）模型）替换未知干扰参数是方便的，但因存在较大偏差而效率低下。为了避免偏差-方差权衡的次优选择，现代方法会进行插值预估的去偏差操作，如有目标最小损失估计（TMLE）和双机器学习（DML）等。现有的去偏方法需要将目标参数的影响函数（IF）作为输入，然而，IF的推导需要专业知识，从而阻碍了这些方法的适应性。我们提出了一种新的去偏插入估计器的方法，它（i）高效、（ii）不需要实现IF、（iii）可计算。

    We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
    
[^39]: 学习选择标签下的异质决策者：一种工具变量方法

    Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach. (arXiv:2306.07566v1 [stat.ML])

    [http://arxiv.org/abs/2306.07566](http://arxiv.org/abs/2306.07566)

    本文提出了一种处理选择性标记数据的学习问题的方法。通过利用历史决策由一组异质决策者做出的事实，我们建立了一种有原理的工具变量框架，并提出了一种加权学习方法，用于学习预测规则。

    

    我们研究了在选择性标记数据下的学习问题。这种问题在历史决策导致结果仅部分标记时出现。标记数据分布可能与整体人群有显著差异，特别是当历史决策和目标结果可以同时受某些未观察到的因素影响时。因此，仅基于标记数据进行学习可能会导致在整体人群中的严重偏差。我们的论文通过利用许多应用中历史决策由一组异质决策者做出的事实来解决此挑战。具体而言，我们在一个有原理的工具变量框架下分析了这种设置。我们建立了满足观察到的数据时任何给定预测规则的全体风险的点识别条件，并在点识别失败时提供了尖锐的风险界限。我们进一步提出了一种加权学习方法，用于学习预测规则。

    We study the problem of learning with selectively labeled data, which arises when outcomes are only partially labeled due to historical decision-making. The labeled data distribution may substantially differ from the full population, especially when the historical decisions and the target outcome can be simultaneously affected by some unobserved factors. Consequently, learning with only the labeled data may lead to severely biased results when deployed to the full population. Our paper tackles this challenge by exploiting the fact that in many applications the historical decisions were made by a set of heterogeneous decision-makers. In particular, we analyze this setup in a principled instrumental variable (IV) framework. We establish conditions for the full-population risk of any given prediction rule to be point-identified from the observed data and provide sharp risk bounds when the point identification fails. We further propose a weighted learning approach that learns prediction ru
    
[^40]: 非均匀抽样下网络数据中符合性预测的有效性研究

    On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])

    [http://arxiv.org/abs/2306.07252](http://arxiv.org/abs/2306.07252)

    研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性

    

    我们研究了针对常见非代表性节点采样机制下的网络数据符合性预测的性质。我们将这些采样机制解释为应用于超总体的选择规则，并在适当的选择事件条件下研究符合性预测的有效性。我们证明了，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则采样子阵列在选择事件条件下是可交换的。我们的结果意味着对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性。我们还表明，当数据通过图上的随机游走来采样时，加权符合性预测的变体可以对人口独立选择节点的预测集进行渐近有效的预测。

    We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
    
[^41]: 数据污染下的超参数学习：基于多目标二层优化的正则化影响分析

    Hyperparameter Learning under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization. (arXiv:2306.01613v1 [cs.LG])

    [http://arxiv.org/abs/2306.01613](http://arxiv.org/abs/2306.01613)

    本文提出了一种考虑攻击对超参数影响的最优攻击公式，将攻击建模为多目标双层优化问题，可以更准确地评估算法鲁棒性和学习超参数，在多个数据集上的评估证明了这种方法的优势。

    

    机器学习算法容易遭受数据污染攻击，即通过操纵部分训练数据来有意破坏算法的性能。最优攻击可以被制定为双层优化问题，并有助于在最坏情况下评估算法的强健性。我们发现当前的方法通常假定超参数保持不变，这导致了对算法鲁棒性和正则化影响的过于悲观的观点。因此我们提出了一种新的最优攻击公式，考虑攻击对超参数的影响，并将攻击建模为多目标双层优化问题。这允许制定最优攻击、学习超参数并在最坏情况下评估鲁棒性。我们将此攻击公式应用于使用$L_2$和$L_1$正则化的多个机器学习分类器上。我们对多个数据集的评估确认了先前策略的限制，并证明了我们提出的方法具有更精确的鲁棒性评估和在存在数据污染攻击时更有效地学习超参数的优点。

    Machine Learning (ML) algorithms are vulnerable to poisoning attacks, where a fraction of the training data is manipulated to deliberately degrade the algorithms' performance. Optimal attacks can be formulated as bilevel optimization problems and help to assess their robustness in worst-case scenarios. We show that current approaches, which typically assume that hyperparameters remain constant, lead to an overly pessimistic view of the algorithms' robustness and of the impact of regularization. We propose a novel optimal attack formulation that considers the effect of the attack on the hyperparameters and models the attack as a multiobjective bilevel optimization problem. This allows to formulate optimal attacks, learn hyperparameters and evaluate robustness under worst-case conditions. We apply this attack formulation to several ML classifiers using $L_2$ and $L_1$ regularization. Our evaluation on multiple datasets confirms the limitations of previous strategies and evidences the ben
    
[^42]: 使用自适应流采样平衡训练能量基模型

    Balanced Training of Energy-Based Models with Adaptive Flow Sampling. (arXiv:2306.00684v1 [cs.LG])

    [http://arxiv.org/abs/2306.00684](http://arxiv.org/abs/2306.00684)

    本文研究了能量基模型的训练算法，使用归一化流进行采样，提高了模型的统计精度和生成性能。

    

    能量基模型 (EBM) 是一种直接参数化未标准化对数密度的多功能密度估计模型。EBM 非常灵活，但缺乏模型的规范化常量，使模型的似然函数计算不可行。近年来，已经提出了许多近似采样器和变分推理技术来估计似然函数梯度进行训练。这些技术在生成样本方面表现出色，但对于估计密度的统计精度，例如确定数据集中不同类的相对重要性，却付出了很少的关注。在本文中，我们提出了一种新的最大似然训练算法，使用一种不同类型的生成模型，归一化流 (NF)，这种模型最近被提出以便于采样。我们的方法在训练过程中将 NF 拟合到 EBM 上，以便 NF 辅助下的采样方案能够始终为 EBM 提供准确的梯度，最终提高模型的统计精度。实验结果表明，与传统 EBM 训练技术相比，我们的方法产生了更高质量的样本和更好的生成性能。

    Energy-based models (EBMs) are versatile density estimation models that directly parameterize an unnormalized log density. Although very flexible, EBMs lack a specified normalization constant of the model, making the likelihood of the model computationally intractable. Several approximate samplers and variational inference techniques have been proposed to estimate the likelihood gradients for training. These techniques have shown promising results in generating samples, but little attention has been paid to the statistical accuracy of the estimated density, such as determining the relative importance of different classes in a dataset. In this work, we propose a new maximum likelihood training algorithm for EBMs that uses a different type of generative model, normalizing flows (NF), which have recently been proposed to facilitate sampling. Our method fits an NF to an EBM during training so that an NF-assisted sampling scheme provides an accurate gradient for the EBMs at all times, ultim
    
[^43]: 基于流数据的神经网络在线学习的低秩扩展卡尔曼滤波算法

    Low-rank extended Kalman filtering for online learning of neural networks from streaming data. (arXiv:2305.19535v1 [stat.ML])

    [http://arxiv.org/abs/2305.19535](http://arxiv.org/abs/2305.19535)

    本文提出一种基于低秩扩展卡尔曼滤波的高效在线学习算法，其能够估计非线性函数的参数，具有更快的适应性和更快的奖励积累。

    

    本文提出了一种高效的在线近似贝叶斯推理算法，用于从可能非平稳的数据流中估计非线性函数的参数。该方法基于扩展卡尔曼滤波器（EKF），但使用了一种新颖的低秩加对角线的后验精度矩阵分解，其每步的成本与模型参数数量成线性关系。与基于随机变分推理的方法不同，我们的方法是完全确定的，并且不需要步长调整。我们通过实验证明，这导致更快（更高效）的学习，从而在用作上下文赌博算法的一部分时实现更快速的适应性和更快的奖励积累。

    We propose an efficient online approximate Bayesian inference algorithm for estimating the parameters of a nonlinear function from a potentially non-stationary data stream. The method is based on the extended Kalman filter (EKF), but uses a novel low-rank plus diagonal decomposition of the posterior precision matrix, which gives a cost per step which is linear in the number of model parameters. In contrast to methods based on stochastic variational inference, our method is fully deterministic, and does not require step-size tuning. We show experimentally that this results in much faster (more sample efficient) learning, which results in more rapid adaptation to changing distributions, and faster accumulation of reward when used as part of a contextual bandit algorithm.
    
[^44]: Bayesian隐式神经表示下的压缩

    Compression with Bayesian Implicit Neural Representations. (arXiv:2305.19185v1 [cs.LG])

    [http://arxiv.org/abs/2305.19185](http://arxiv.org/abs/2305.19185)

    该论文提出了一种用Bayesian隐式神经表示来压缩数据的方法，通过最小化 $\beta$-ELBO 直接优化码-失真性能，并通过调整 $\beta$ 来针对给定的网络结构实现不同的码-失真平衡。

    

    许多常见类型的数据可以表示为将坐标映射到信号值的函数，例如图像中的像素位置到RGB值。基于这个观点，可以通过对数据的功能表示进行超拟合，然后编码网络权重来压缩数据。然而，大多数当前的解决方案都效率低下，因为将精度量化到低比特会大幅降低重构质量。为解决这个问题，我们提出了过度拟合变分贝叶斯神经网络来压缩近似后验权重样本，而不是量化和熵编码它。该策略通过最小化 $\beta$-ELBO 直接优化码-失真性能，并通过调整 $\beta$ 来针对给定的网络结构实现不同的码-失真平衡。此外，我们引入了一种学习先验权重分布的迭代算法，并采用主动尺寸调整来进一步提高效率。

    Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a pro
    
[^45]: PFN是适用于实际贝叶斯优化的灵活模型。

    PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])

    [http://arxiv.org/abs/2305.17535](http://arxiv.org/abs/2305.17535)

    本文使用灵活的PFN作为BO代理建模，该模型能够允许进一步信息纳入以进行非远视BO。在三种不同的问题上得到了很好的结果。

    

    本文使用先验数据拟合网络(PFNs)作为贝叶斯优化(BO)的灵活代理。PFN是一种神经过程，被训练用于近似后验预测分布(PPD)，适用于任何可有效采样的先验分布。我们描述了如何利用这种灵活性来进行BO的代理建模。我们使用PFN来模拟一个朴素高斯过程(GP)，一个先进的GP和一个贝叶斯神经网络(BNN)。此外，我们展示了如何将进一步的信息纳入先验，例如允许有关最优位置的提示(用户先验)，忽略不相关的维度，并通过学习获取函数来执行非远视BO。这些扩展的灵活性为使用PFN进行BO开辟了广阔的可能性。我们在人工高斯过程样本和三个不同的超参数优化测试平台上展示了PFN对BO的有用性：HPO-B、Bayesmark和PD1。

    In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
    
[^46]: 多个预训练模型的表示迁移学习在线性回归中的研究

    Representation Transfer Learning via Multiple Pre-trained models for Linear Regression. (arXiv:2305.16440v1 [cs.LG])

    [http://arxiv.org/abs/2305.16440](http://arxiv.org/abs/2305.16440)

    本文提出了一种基于表示迁移的学习方法，在给定很少数样本的情况下，通过提供一组在可能不同的数据领域上训练的预训练回归模型，来构建目标模型，使用这种方法可以提高模型的样本复杂度。

    

    本文研究了在给定很少数样本的情况下，如何在感兴趣的数据领域（目标）上学习线性回归模型。我们提出了一种基于表示迁移的学习方法，通过提供一组在可能不同的数据领域（来源）上训练的预训练回归模型，来构建目标模型。该方法由两个阶段组成：（i）利用不同的源表示来构造适应目标数据的表示，（ii）将所得到的模型作为初始值，通过微调程序，在目标数据上重新训练整个（超参数）回归模型。对于训练方法的每个阶段，我们提供了学习模型与真实数据生成目标模型之间的超额风险限制。导出的限制显示了样本复杂度的提高。

    In this paper, we consider the problem of learning a linear regression model on a data domain of interest (target) given few samples. To aid learning, we are provided with a set of pre-trained regression models that are trained on potentially different data domains (sources). Assuming a representation structure for the data generating linear models at the sources and the target domains, we propose a representation transfer based learning method for constructing the target model. The proposed scheme is comprised of two phases: (i) utilizing the different source representations to construct a representation that is adapted to the target data, and (ii) using the obtained model as an initialization to a fine-tuning procedure that re-trains the entire (over-parameterized) regression model on the target data. For each phase of the training method, we provide excess risk bounds for the learned model compared to the true data generating target model. The derived bounds show a gain in sample co
    
[^47]: 在线Platt缩放及其校准方法

    Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])

    [http://arxiv.org/abs/2305.00070](http://arxiv.org/abs/2305.00070)

    本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。

    

    我们提出了一种在线后校准方法，称为在线Platt缩放(OPS)，它将Platt缩放技术与在线逻辑回归相结合。我们展示了OPS如何在分布漂移的i.i.d.和非i.i.d.情况下平稳适应。此外，当最佳的Platt缩放模型本身被错误校准时，我们使用一种最近开发的称为calibeating的技术来增强OPS，使其更加鲁棒。理论上，我们得到的OPS+calibeating方法对于对抗性结果序列是保证校准的。在实验上，它在一系列合成和真实数据集上均表现出卓越的性能，无需超参数调整。最后，我们将所有OPS思想扩展到beta缩放方法。

    We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.
    
[^48]: 基于占据核主成分分析的故障检测

    Fault Detection via Occupation Kernel Principal Component Analysis. (arXiv:2303.11138v1 [stat.ML])

    [http://arxiv.org/abs/2303.11138](http://arxiv.org/abs/2303.11138)

    本文提出了一种使用占据核PCA方法进行故障检测的新方法，并且通过数值模拟验证了其有效性。

    

    自动系统的可靠操作很大程度上依赖于检测基础动态系统中的故障。虽然传统的基于模型的方法已被广泛用于故障检测，但基于数据的方法因其易于部署和对专家知识需求最小的特点而受到越来越多的关注。本文提出了一种使用占据核进行主成分分析（PCA）的新方法。占据核产生的特征映射适用于测量数据，由于使用积分具有内在的噪声鲁棒性，并且可以利用长度可变的不规则采样系统轨迹进行PCA。占据核PCA方法被用于开发一种重构误差方法进行故障检测，并且通过数值模拟验证了其有效性。

    The reliable operation of automatic systems is heavily dependent on the ability to detect faults in the underlying dynamical system. While traditional model-based methods have been widely used for fault detection, data-driven approaches have garnered increasing attention due to their ease of deployment and minimal need for expert knowledge. In this paper, we present a novel principal component analysis (PCA) method that uses occupation kernels. Occupation kernels result in feature maps that are tailored to the measured data, have inherent noise-robustness due to the use of integration, and can utilize irregularly sampled system trajectories of variable lengths for PCA. The occupation kernel PCA method is used to develop a reconstruction error approach to fault detection and its efficacy is validated using numerical simulations.
    
[^49]: 高维单个ReLU神经元的有限样本学习分析

    Finite-Sample Analysis of Learning High-Dimensional Single ReLU Neuron. (arXiv:2303.02255v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02255](http://arxiv.org/abs/2303.02255)

    本文研究了高维单个ReLU神经元的有限样本学习问题，并提供了感知器算法GLM-tron的风险上下界，其中包括特殊情况，为高维ReLU回归问题提供了清晰的刻画。此外，对于对称伯努利数据的ReLU回归，随机梯度下降的过多风险不如GLM-tron。

    

    本文研究了在过参数化的情况下（即输入维度可能超出样本数），学习具有平方损失的单个ReLU神经元的问题。我们分析了称为GLM-tron（Kakade等人，2011）的感知器算法，并提供了其维度无关的风险上界，用于高维ReLU回归的良好规定和规定错误设置。我们的风险上界恢复了几个现有结果作为特例。此外，在良好规定的情况下，我们为GLM-tron提供了一个实例匹配风险下界。我们的上下风险界提供了对可以通过GLM-tron学习的高维ReLU回归问题的清晰刻画。另一方面，我们针对对称伯努利数据的ReLU回归提供了一些随机梯度下降（SGD）的负面结果：如果模型规定良好，则SGD的过多风险可证明不比无视常数因素的GLM-tron的过多风险好。

    This paper considers the problem of learning a single ReLU neuron with squared loss (a.k.a., ReLU regression) in the overparameterized regime, where the input dimension can exceed the number of samples. We analyze a Perceptron-type algorithm called GLM-tron (Kakade et al., 2011) and provide its dimension-free risk upper bounds for high-dimensional ReLU regression in both well-specified and misspecified settings. Our risk bounds recover several existing results as special cases. Moreover, in the well-specified setting, we provide an instance-wise matching risk lower bound for GLM-tron. Our upper and lower risk bounds provide a sharp characterization of the high-dimensional ReLU regression problems that can be learned via GLM-tron. On the other hand, we provide some negative results for stochastic gradient descent (SGD) for ReLU regression with symmetric Bernoulli data: if the model is well-specified, the excess risk of SGD is provably no better than that of GLM-tron ignoring constant fa
    
[^50]: 在线工具变量回归: 遗憾分析和Bandit反馈

    Online Instrumental Variable Regression: Regret Analysis and Bandit Feedback. (arXiv:2302.09357v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09357](http://arxiv.org/abs/2302.09357)

    该论文研究了在线学习中内生性问题的解决方法，提出了使用Two-Stage Least Squares方法的在线变体O2SLS来处理内生性，取得了较好的识别率和预测遗憾率。

    

    内生性是实际数据中常见的现象，因为遗漏变量、战略行为、测量误差等原因导致噪声和协变量之间的依赖性。与之相反，现有的无界噪声和线性Bandit随机在线线性回归分析严重依赖外生性，即噪声和协变量之间的独立性。鉴于这一差距，我们研究了工具变量（IV）回归在随机在线学习中的超识别和恰好识别情况。我们提出使用Two-Stage Least Squares方法的在线变体（即O2SLS）来处理内生性。我们的分析表明，O2SLS实现了$ \mathcal{O} \left(d_x d_z \log ^ 2 T \right)$的识别率和$ \tilde {\mathcal {O}} \left(\gamma \sqrt {d_x T} \right)$的预测遗憾率。

    Endogeneity, i.e. the dependence between noise and covariates, is a common phenomenon in real data due to omitted variables, strategic behaviours, measurement errors etc. In contrast, the existing analyses of stochastic online linear regression with unbounded noise and linear bandits depend heavily on exogeneity, i.e. the independence between noise and covariates. Motivated by this gap, we study the over-and just-identified Instrumental Variable (IV) regression for stochastic online learning. IV regression and the Two-Stage Least Squares approach to it are widely deployed in economics and causal inference to identify the underlying model from an endogenous dataset. Thus, we propose to use an online variant of Two-Stage Least Squares approach, namely O2SLS, to tackle endogeneity in stochastic online learning. Our analysis shows that O2SLS achieves $\mathcal{O}\left(d_x d_z \log ^2 T\right)$ identification and $\tilde{\mathcal{O}}\left(\gamma \sqrt{d_x T}\right)$ oracle regret after $T$ 
    
[^51]: 近乎贝叶斯最优的伪标签选择

    Approximately Bayes-Optimal Pseudo Label Selection. (arXiv:2302.08883v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.08883](http://arxiv.org/abs/2302.08883)

    本文介绍了BPLS，一种用于PLS的贝叶斯框架，通过解析逼近选择标签实例的标准，以避免由过度自信但错误预测的实例选择而导致的确认偏差问题。

    

    自训练的半监督学习严重依赖于伪标签选择（PLS）。选择通常取决于初始模型拟合标记数据的程度。过早的过拟合可能通过选择具有过度自信但错误的预测的实例（通常称为确认偏差）而传播到最终模型。本文介绍了BPLS，这是一种用于PLS的贝叶斯框架，旨在减轻这个问题。其核心是选择标签实例的标准：伪样本的后验预测的分析近似。我们通过证明伪样本的后验预测的贝叶斯最优性获得了这种选择标准。我们进一步通过解析逼近克服计算难题。它与边际似然的关系使我们能够提出基于拉普拉斯方法和高斯积分的逼近。我们针对参数广义线性和非参数广义加性模型对BPLS进行了实证评估。

    Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). The selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace's method and the Gaussian integral. We empirically assess BPLS for parametric generalized linear and non-parametric generalized additive models
    
[^52]: 关于异质性因果图中的异质性治疗效应

    On Heterogeneous Treatment Effects in Heterogeneous Causal Graphs. (arXiv:2301.12383v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2301.12383](http://arxiv.org/abs/2301.12383)

    本文通过推广因果图模型，描述了异质性因果图，提出了一种方法来研究不同调节因素对治疗效果和潜在中介变量的影响，解决了现实生活中高维度场景的挑战，并在真实数据应用中发现了新的异质性治疗效应。

    

    异质性和共病是许多医疗困境的两大挑战，阻碍了针对有效治疗的研究以及对潜在神经生物机制的理解。本文首先通过推广因果图模型与混杂变量交互和多个中介变量的概念，把异质性因果图（HCGs）进行了概括描述，这些与治疗交互作用的混杂变量被称为调节因素，这使我们能够灵活地产生HCGs，给出不同的调节因素，明确描述治疗或潜在中介变量对结果的HCEs。我们在线性和非线性模型中建立了HCE的理论形式，并在个体层面上推导了其特性。为了处理高维度场景，我们开发了一种交互式结构学习，通过将双重机器学习策略纳入估计调节因素中，来解决问题。我们通过模拟和对HIV阳性患者戒烟干预的真实数据应用示例来演示我们提出的方法和发现出先前未记录的新的HCE。该方法在各个医疗领域中为理解异质性治疗效应和改善个性化医学提供了潜在应用。

    Heterogeneity and comorbidity are two interwoven challenges associated with various healthcare problems that greatly hampered research on developing effective treatment and understanding of the underlying neurobiological mechanism. Very few studies have been conducted to investigate heterogeneous causal effects (HCEs) in graphical contexts due to the lack of statistical methods. To characterize this heterogeneity, we first conceptualize heterogeneous causal graphs (HCGs) by generalizing the causal graphical model with confounder-based interactions and multiple mediators. Such confounders with an interaction with the treatment are known as moderators. This allows us to flexibly produce HCGs given different moderators and explicitly characterize HCEs from the treatment or potential mediators on the outcome. We establish the theoretical forms of HCEs and derive their properties at the individual level in both linear and nonlinear models. An interactive structural learning is developed to 
    
[^53]: 逆可解性和安全性及其在联邦学习中的应用

    Inverse Solvability and Security with Applications to Federated Learning. (arXiv:2211.14115v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.14115](http://arxiv.org/abs/2211.14115)

    介绍了逆可解性和安全性的概念，以及其在联邦学习中的应用。论文提供了模型示例，展示了如何通过增加用户数量来增加可解性和安全性。

    

    我们介绍了逆可解性和安全性的概念，适用于一般线性前向模型，并展示了如何将其应用于联邦学习中使用的模型。我们提供了这样的模型的示例，其逆可解性和安全性在本文中得到定义。我们还展示了如何利用参与给定迭代的大量用户来增加可解性和安全性。最后，我们讨论了所提出概念的可能扩展，包括非线性情况。

    We introduce the concepts of inverse solvability and security for a generic linear forward model and demonstrate how they can be applied to models used in federated learning. We provide examples of such models which differ in the resulting inverse solvability and security as defined in this paper. We also show how the large number of users participating in a given iteration of federated learning can be leveraged to increase both solvability and security. Finally, we discuss possible extensions of the presented concepts including the nonlinear case.
    
[^54]: 基于测地线和水平面投影的双曲切片Wasserstein

    Hyperbolic Sliced-Wasserstein via Geodesic and Horospherical Projections. (arXiv:2211.10066v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.10066](http://arxiv.org/abs/2211.10066)

    本文提出了一种基于测地线和水平面投影的双曲切片Wasserstein距离，可用于比较具有基础分层结构的数据中定义的概率分布。

    

    研究表明，对于许多具有基础分层结构的数据，将其嵌入双曲空间是有益的。因此，许多机器学习工具被扩展到这些空间，但只有很少对于这些空间中定义的概率分布进行比较的不一致性存在。在双曲空间上，最优输运距离在这样的黎曼流形上是明确定义的，并具有强大的理论性质，但计算成本较高。在欧几里得空间上，切片Wasserstein距离是更具计算效率的方法，它利用一维Wasserstein距离的闭合形式，但在双曲空间上不易获得。在本文中，我们提出了新的双曲切片Wasserstein不一致性构造。这些构造使用基本测地线上的水平面或测地线的投影。我们在不同的任务中研究和比较它们，其中双曲表示是相关的。

    It has been shown beneficial for many types of data which present an underlying hierarchical structure to be embedded in hyperbolic spaces. Consequently, many tools of machine learning were extended to such spaces, but only few discrepancies to compare probability distributions defined over those spaces exist. Among the possible candidates, optimal transport distances are well defined on such Riemannian manifolds and enjoy strong theoretical properties, but suffer from high computational cost. On Euclidean spaces, sliced-Wasserstein distances, which leverage a closed-form of the Wasserstein distance in one dimension, are more computationally efficient, but are not readily available on hyperbolic spaces. In this work, we propose to derive novel hyperbolic sliced-Wasserstein discrepancies. These constructions use projections on the underlying geodesics either along horospheres or geodesics. We study and compare them on different tasks where hyperbolic representations are relevant, such a
    
[^55]: 一种混合类别相关核的高斯过程

    A mixed-categorical correlation kernel for Gaussian process. (arXiv:2211.08262v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2211.08262](http://arxiv.org/abs/2211.08262)

    提出一种新的混合类别相关核的高斯过程代理，相较于其他现有模型在分析和工程问题上表现更好。

    

    近年来，基于高斯过程代理的混合类别元模型引起了越来越多的关注。在这种情况下，一些现有的方法使用不同的策略，通过使用连续核（例如，连续松弛和Gower距离基于高斯过程）或通过直接估计相关矩阵。在本文中，我们提出了一种基于核的方法，将连续指数核扩展为处理混合类别变量。所提出的核引导到了一个新的高斯代理，它概括了连续松弛和Gower距离基于高斯过程模型。我们在分析和工程问题上证明了，我们的提出的高斯过程模型比其他基于核的现有模型具有更高的可能性和更小的残差误差。我们的方法可使用开源软件SMT。

    Recently, there has been a growing interest for mixed-categorical meta-models based on Gaussian process (GP) surrogates. In this setting, several existing approaches use different strategies either by using continuous kernels (e.g., continuous relaxation and Gower distance based GP) or by using a direct estimation of the correlation matrix. In this paper, we present a kernel-based approach that extends continuous exponential kernels to handle mixed-categorical variables. The proposed kernel leads to a new GP surrogate that generalizes both the continuous relaxation and the Gower distance based GP models. We demonstrate, on both analytical and engineering problems, that our proposed GP model gives a higher likelihood and a smaller residual error than the other kernel-based state-of-the-art models. Our method is available in the open-source software SMT.
    
[^56]: 使用对比剪枝权重训练去偏置子网络

    Training Debiased Subnetworks with Contrastive Weight Pruning. (arXiv:2210.05247v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05247](http://arxiv.org/abs/2210.05247)

    本文探讨了在存在强假相关的偏置网络中提取最优无偏子网络的问题，并提出了使用对比剪枝权重训练实现去偏置子网络的算法 DCWP，在多个应用中都有良好的效果。

    

    神经网络通常存在偏置性，导致提供具有误导性的统计证据，不能很好地推广。因此，提出了在偏置网络中提取最优无偏功能子网络的问题。本文首先提出了现有算法在探索具有强假相关性的无偏子网络存在限制的理论洞见，然后进一步阐明了偏差冲突样本对结构学习的重要性，并基于学习的（伪）无偏样本和选择性偏差冲突样本，提出了去偏置对比剪枝（DCWP）算法。在图像分类、语言模型和强化学习等各种应用中验证了 DCWP 的有效性。

    Neural networks are often biased to spuriously correlated features that provide misleading statistical evidence that does not generalize. This raises an interesting question: ``Does an optimal unbiased functional subnetwork exist in a severely biased network? If so, how to extract such subnetwork?" While empirical evidence has been accumulated about the existence of such unbiased subnetworks, these observations are mainly based on the guidance of ground-truth unbiased samples. Thus, it is unexplored how to discover the optimal subnetworks with biased training datasets in practice. To address this, here we first present our theoretical insight that alerts potential limitations of existing algorithms in exploring unbiased subnetworks in the presence of strong spurious correlations. We then further elucidate the importance of bias-conflicting samples on structure learning. Motivated by these observations, we propose a Debiased Contrastive Weight Pruning (DCWP) algorithm, which probes unbi
    
[^57]: 基于回归的超标概率预测方法用于显著波高预测

    Exceedance Probability Forecasting via Regression for Significant Wave Height Prediction. (arXiv:2206.09821v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.09821](http://arxiv.org/abs/2206.09821)

    本论文提出了一种基于回归的超标概率预测方法，用于预测显著波高，通过利用预测来估计超标概率，取得了更好的效果。

    

    显著波高预测是海洋数据分析中的一个关键问题。预测显著波高对于估计波能产生是至关重要的。此外，及时预测大浪的到来对于确保航海作业的安全很重要。我们将预测显著波高的极端值作为超标概率预测问题。因此，我们旨在估计显著波高将超过预定义阈值的概率。通常使用概率二分类模型来解决这个任务。相反，我们提出了一种基于预测模型的新方法。该方法利用未来观测的预测来根据累积分布函数估计超标概率。我们使用来自加拿大哈利法克斯海岸的浮标数据进行了实验。结果表明，所提出的方法更好。

    Significant wave height forecasting is a key problem in ocean data analytics. Predicting the significant wave height is crucial for estimating the energy production from waves. Moreover, the timely prediction of large waves is important to ensure the safety of maritime operations, e.g. passage of vessels. We frame the task of predicting extreme values of significant wave height as an exceedance probability forecasting problem. Accordingly, we aim at estimating the probability that the significant wave height will exceed a predefined threshold. This task is usually solved using a probabilistic binary classification model. Instead, we propose a novel approach based on a forecasting model. The method leverages the forecasts for the upcoming observations to estimate the exceedance probability according to the cumulative distribution function. We carried out experiments using data from a buoy placed in the coast of Halifax, Canada. The results suggest that the proposed methodology is better
    
[^58]: 通过边际公平性来界定和逼近交集公平性

    Bounding and Approximating Intersectional Fairness through Marginal Fairness. (arXiv:2206.05828v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.05828](http://arxiv.org/abs/2206.05828)

    本文旨在通过统计分析了解边际公平性和交集公平性之间的关系，在一定条件下取得精确关系。在高概率下,通过边际公平性和其他有意义的统计量可以计算出交集公平性的界限。

    

    机器学习中的歧视通常涉及多个维度（即保护属性）；因此，确保“交集公平性”，即不歧视任何子组，是理想的。众所周知，仅独立地保证每个维度的“边际公平性”通常是不足够的。然而，由于子组的指数数量，直接从数据中度量交集公平性是不可能的。在本文中，我们的主要目标是通过统计分析详细了解边际公平性和交集公平性之间的关系。我们首先确定了一组足够的条件，可以在其中获得精确关系。然后，我们证明了在一般情况下，在高概率下通过边际公平性和其他有意义的统计量可以计算出交集公平性的界限。除了它们的描述价值外，我们还展示了这些理论界限可以利用到一种启发式的提高方法中。

    Discrimination in machine learning often arises along multiple dimensions (a.k.a. protected attributes); it is then desirable to ensure \emph{intersectional fairness} -- i.e., that no subgroup is discriminated against. It is known that ensuring \emph{marginal fairness} for every dimension independently is not sufficient in general. Due to the exponential number of subgroups, however, directly measuring intersectional fairness from data is impossible. In this paper, our primary goal is to understand in detail the relationship between marginal and intersectional fairness through statistical analysis. We first identify a set of sufficient conditions under which an exact relationship can be obtained. Then, we prove bounds (easily computable through marginal fairness and other meaningful statistical quantities) in high-probability on intersectional fairness in the general case. Beyond their descriptive value, we show that these theoretical bounds can be leveraged to derive a heuristic impro
    
[^59]: 稀疏图的半监督聚类：跨越了信息理论门槛

    Semi-Supervised Clustering of Sparse Graphs: Crossing the Information-Theoretic Threshold. (arXiv:2205.11677v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.11677](http://arxiv.org/abs/2205.11677)

    该论文提出了两种有效的算法来将标签信息与稀疏图结构相结合，解决了基于网络拓扑的聚类在稀疏图上的问题。

    

    随机块模型是一种用于网络结构数据聚类和社区检测的基本随机图模型。数十年来对该问题的广泛研究已经建立了许多深刻的结果，其中Kesten-Stigum门槛处的相变现象特别有趣，从数学和应用角度都具有重要意义。它表明，如果模型参数在某个门槛以下，基于网络拓扑的任何估计器在稀疏图上都不能比随机猜测更好。然而，如果我们稍微扩展视野到普遍存在的半监督设置，这样的基本限制将完全消失。我们证明，通过揭示出任意一部分标记，可以在整个参数域内对检测问题进行处理。此外，我们引入了两种有效的算法，一种是基于组合的，一种是基于优化的，用于将标签信息与图结构相结合。我们的工作为随机块模型和半监督学习带来了全新的视角，标志着稀疏图聚类领域的重大突破。

    The stochastic block model is a canonical random graph model for clustering and community detection on network-structured data. Decades of extensive study on the problem have established many profound results, among which the phase transition at the Kesten-Stigum threshold is particularly interesting both from a mathematical and an applied standpoint. It states that no estimator based on the network topology can perform substantially better than chance on sparse graphs if the model parameter is below certain threshold. Nevertheless, if we slightly extend the horizon to the ubiquitous semi-supervised setting, such a fundamental limitation will disappear completely. We prove that with arbitrary fraction of the labels revealed, the detection problem is feasible throughout the parameter domain. Moreover, we introduce two efficient algorithms, one combinatorial and one based on optimization, to integrate label information with graph structures. Our work brings a new perspective to stochasti
    
[^60]: 利用神经Q-学习解决偏微分方程

    Neural Q-learning for solving PDEs. (arXiv:2203.17128v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2203.17128](http://arxiv.org/abs/2203.17128)

    本文提出了一种新的利用神经Q-学习算法解决椭圆型PDE数值方法，该算法无网格且具有克服维度灾难的潜力。本文证明了这种方法的有效性，并在单调PDE的情况下得到了极限神经网络收敛于PDE解的证明。

    

    解决高维偏微分方程是科学计算中的一个主要挑战。本文通过改进强化学习中的Q-学习算法开发了一种新的解决椭圆型PDE的数值方法。我们的“Q-PDE”算法是无网格的，因此具有克服维度灾难的潜力。我们使用神经切向核（NTK）方法证明，使用Q-PDE算法训练的PDE解的神经网络逼近器，随着隐藏层单元数的增加，收敛于无穷维常微分方程（ODE）的轨迹。对于单调PDE（即由单调算符给出的可能是非线性的PDE），尽管NTK中缺乏谱间隙，我们证明了满足无穷维ODE的极限神经网络会随着训练时间的增加收敛于$L^2$中的PDE解。更一般地说，我们可以证明wi的任何不动点都是该无穷维ODE的解。

    Solving high-dimensional partial differential equations (PDEs) is a major challenge in scientific computing. We develop a new numerical method for solving elliptic-type PDEs by adapting the Q-learning algorithm in reinforcement learning. Our "Q-PDE" algorithm is mesh-free and therefore has the potential to overcome the curse of dimensionality. Using a neural tangent kernel (NTK) approach, we prove that the neural network approximator for the PDE solution, trained with the Q-PDE algorithm, converges to the trajectory of an infinite-dimensional ordinary differential equation (ODE) as the number of hidden units $\rightarrow \infty$. For monotone PDE (i.e. those given by monotone operators, which may be nonlinear), despite the lack of a spectral gap in the NTK, we then prove that the limit neural network, which satisfies the infinite-dimensional ODE, converges in $L^2$ to the PDE solution as the training time $\rightarrow \infty$. More generally, we can prove that any fixed point of the wi
    
[^61]: 最优学习

    Optimal Learning. (arXiv:2203.15994v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.15994](http://arxiv.org/abs/2203.15994)

    本文证明，通过解决一个带有惩罚项的离散过度参数化优化问题，可以找到近乎最优的 $\hat f$。

    

    本文研究了从关于 $f$ 的给定数据学习未知函数 $f$ 的问题。学习问题是给出一个近似值 $ \hat f $，用于预测数据外的 $f$ 值。这个学习问题的准确性取决于：（i）我们对 $f$ 有什么额外的信息（称为模型类假设），（ii）我们如何度量 $\hat f$ 的预测准确性，（iii）数据和数据站点的情况，（iv）数据观察是否受到噪声污染。在存在模型类假设的情况下，已知最优恢复性能的数学描述。在标准模型类假设下，本文证明，通过解决一个带有惩罚项的离散过度参数化优化问题，可以找到近乎最优的 $\hat f$。最优指的是误差受到固定倍数的限制。

    This paper studies the problem of learning an unknown function $f$ from given data about $f$. The learning problem is to give an approximation $\hat f$ to $f$ that predicts the values of $f$ away from the data. There are numerous settings for this learning problem depending on (i) what additional information we have about $f$ (known as a model class assumption), (ii) how we measure the accuracy of how well $\hat f$ predicts $f$, (iii) what is known about the data and data sites, (iv) whether the data observations are polluted by noise. A mathematical description of the optimal performance possible (the smallest possible error of recovery) is known in the presence of a model class assumption. Under standard model class assumptions, it is shown in this paper that a near optimal $\hat f$ can be found by solving a certain discrete over-parameterized optimization problem with a penalty term. Here, near optimal means that the error is bounded by a fixed constant times the optimal error. This
    
[^62]: 可解释的离线策略学习：基于超立方体搜索的方法

    Interpretable Off-Policy Learning via Hyperbox Search. (arXiv:2203.02473v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.02473](http://arxiv.org/abs/2203.02473)

    本文提出了一个基于超立方体搜索的可解释离线策略学习算法，可以用合取范式表示，可以灵活逼近任何可测函数。在临床实践中具有重要意义。

    

    个性化治疗决策已成为现代医学的重要组成部分。因此，目标是根据个体患者的特征进行治疗决策。已经开发了许多方法从观测数据中学习这样的策略，以实现在特定策略类别下获得最佳结果。但是，这些方法很少具有可解释性。然而，可解释性通常是临床实践中策略学习的前提条件。在本文中，我们提出了一种基于超立方体搜索的可解释离线策略学习算法。特别地，我们的策略可以用合取范式表示（即AND的OR），因此是容易理解的。我们证明了一个通用逼近定理，证明了我们的策略类可以灵活地逼近任何可测函数。为了优化，我们在分支定界框架内开发了一个定制的列生成过程。通过模拟研究，我们证明了我们的算法优于其他方法。

    Personalized treatment decisions have become an integral part of modern medicine. Thereby, the aim is to make treatment decisions based on individual patient characteristics. Numerous methods have been developed for learning such policies from observational data that achieve the best outcome across a certain policy class. Yet these methods are rarely interpretable. However, interpretability is often a prerequisite for policy learning in clinical practice. In this paper, we propose an algorithm for interpretable off-policy learning via hyperbox search. In particular, our policies can be represented in disjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove a universal approximation theorem that shows that our policy class is flexible enough to approximate any measurable function arbitrarily well. For optimization, we develop a tailored column generation procedure within a branch-and-bound framework. Using a simulation study, we demonstrate that our algorithm outpe
    
[^63]: 使用安全筛选加速非负和有界变量线性回归算法

    Accelerating Non-Negative and Bounded-Variable Linear Regression Algorithms with Safe Screening. (arXiv:2202.07258v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.07258](http://arxiv.org/abs/2202.07258)

    本文提出了一种通过识别饱和坐标加速解决非负和有界变量线性回归问题的技术，实验结果表明其具有令人信服的加速效果。

    

    非负和有界变量线性回归问题在机器学习和信号处理的各种应用中都有所涉及。本文提出了一种技术，通过在迭代过程中识别饱和坐标，加速现有解决器来解决这些问题。这类似于先前针对稀疏正则化回归问题提出的安全筛选技术。所提出的策略是经过证明是安全的，因为它提供了理论保证，表明所识别的坐标确实在最优解中是饱和的。对合成数据和实际数据的实验结果都表明，对于非负和有界变量问题都具有令人信服的加速效果。

    Non-negative and bounded-variable linear regression problems arise in a variety of applications in machine learning and signal processing. In this paper, we propose a technique to accelerate existing solvers for these problems by identifying saturated coordinates in the course of iterations. This is akin to safe screening techniques previously proposed for sparsity-regularized regression problems. The proposed strategy is provably safe as it provides theoretical guarantees that the identified coordinates are indeed saturated in the optimal solution. Experimental results on synthetic and real data show compelling accelerations for both non-negative and bounded-variable problems.
    
[^64]: 测度集中和随机向量的广义积及其在 Hanson-Wright 不等式中的应用。

    Concentration of measure and generalized product of random vectors with an application to Hanson-Wright-like inequalities. (arXiv:2102.08020v5 [math.PR] UPDATED)

    [http://arxiv.org/abs/2102.08020](http://arxiv.org/abs/2102.08020)

    本文介绍了函数浓度表达式，并给出了浓度集中与 Hanson-Wright不等式的广义推广，研究了随机矩阵XDX^(t)及其解析式Q。

    

    本文从 $m$ 个随机向量 $Z_1, \ldots, Z_m$ 矩阵的测度集中假设出发，给出了函数 $\phi(Z_1, \ldots, Z_m)$ 的浓度表达式。其中，$\phi$ 在每个变量上的变化取决于其他变量的范数（或半范数）的积（就像 $\phi$ 本身就是一个积）。我们通过各种 Hanson-Wright浓度不等式的泛化举例说明了这个结果的重要性，以及在统计机器学习应用中具有基本意义的随机矩阵 $XDX^T$ 及其解析式 $Q=(I_p−\frac{1}{n}XDX^T)^{-1}$ 的研究。

    Starting from concentration of measure hypotheses on $m$ random vectors $Z_1,\ldots, Z_m$, this article provides an expression of the concentration of functionals $\phi(Z_1,\ldots, Z_m)$ where the variations of $\phi$ on each variable depend on the product of the norms (or semi-norms) of the other variables (as if $\phi$ were a product). We illustrate the importance of this result through various generalizations of the Hanson-Wright concentration inequality as well as through a study of the random matrix $XDX^T$ and its resolvent $Q = (I_p - \frac{1}{n}XDX^T)^{-1}$, where $X$ and $D$ are random, which have fundamental interest in statistical machine learning applications.
    
[^65]: 代表性集成在准线性复杂度下实现协同生命周期学习

    Representation Ensembling for Synergistic Lifelong Learning with Quasilinear Complexity. (arXiv:2004.12908v16 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2004.12908](http://arxiv.org/abs/2004.12908)

    本文提出了一种名为RELL的方法，利用知识蒸馏和知识保持正则化方法，以协同集成在不同任务上独立学习的表示，在准线性复杂度下实现了前向和后向传递。实验结果表明，在各种基准数据集上，RELL的表现优于现有的最先进方法，尤其是在存在灾难性遗忘的情况下，能够显着改善反向传递。

    

    在终身学习中，数据不仅可以用于改进当前任务的性能，还可以用于之前和尚未遇到的任务。传统的机器学习则从空白状态开始，仅针对单个任务使用数据。虽然传统迁移学习算法可以提高未来任务的性能，但在学习新任务后对旧任务的性能下降（称为遗忘）。近期针对连续或终身学习的许多方法都试图在给定新任务的情况下保持对旧任务的性能。但是，仅努力避免忘记将目标定得过低。终身学习的目标不仅应该是提高未来任务（前向传递）的性能，而且还应该是用任何新数据提高过去任务（反向传递）的性能。我们的关键见解是，我们可以协同集成分别在不同任务上独立学习的表示，以实现准线性复杂度下的前向和后向传递。本文提出了一种新方法，称为“终身学习中的表示集成（RELL）”，它集成了知识蒸馏和知识保持正则化方法，以利用不同表示中包含的互补信息。我们的实验表明，RELL在各种基准数据集上都优于现有最先进方法，尤其是在存在灾难性遗忘的情况下实现了显着更好的反向传递。

    In lifelong learning, data are used to improve performance not only on the current task, but also on previously encountered, and as yet unencountered tasks. In contrast, classical machine learning, which we define as, starts from a blank slate, or tabula rasa and uses data only for the single task at hand. While typical transfer learning algorithms can improve performance on future tasks, their performance on prior tasks degrades upon learning new tasks (called forgetting). Many recent approaches for continual or lifelong learning have attempted to maintain performance on old tasks given new tasks. But striving to avoid forgetting sets the goal unnecessarily low. The goal of lifelong learning should be not only to improve performance on future tasks (forward transfer) but also on past tasks (backward transfer) with any new data. Our key insight is that we can synergistically ensemble representations -- that were learned independently on disparate tasks -- to enable both forward and bac
    

