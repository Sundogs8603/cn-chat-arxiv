# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Ordinal time series analysis with the R package otsfeatures.](http://arxiv.org/abs/2304.12251) | otsfeatures是一个R包，提供了一组函数用于分析序时间序列数据，其中包含提取统计特征和执行推断任务，以及聚类、分类或异常检测等常规机器学习任务。此外，该软件包还包含两个金融时间序列数据集和三个合成数据库。 |
| [^2] | [Fuzzy clustering of ordinal time series based on two novel distances with economic applications.](http://arxiv.org/abs/2304.12249) | 本文研究了离散响应的序列模糊聚类问题，提出了两种新的距离度量，其中的算法具有高效性和准确性，并可在经济学领域获得应用。 |
| [^3] | [A Transfer Principle: Universal Approximators Between Metric Spaces From Euclidean Universal Approximators.](http://arxiv.org/abs/2304.12231) | 本论文提出使用欧几里得空间通用逼近器为构建块，构建了在任意波兰度量空间 $\mathcal{X}$ 和 $\mathcal{Y}$ 之间的通用逼近器，并通过随机化输出离散概率测度来克服某些限制。在适当的结构下提供了概率和定量保证。 |
| [^4] | [More Communication Does Not Result in Smaller Generalization Error in Federated Learning.](http://arxiv.org/abs/2304.12216) | 我们研究了联邦学习环境下的统计学习模型泛化误差，表明更频繁地与参数服务器通信会负面影响此类学习算法的泛化性能。 |
| [^5] | [Variational Diffusion Auto-encoder: Deep Latent Variable Model with Unconditional Diffusion Prior.](http://arxiv.org/abs/2304.12141) | 本文提出了一种基于扩散模型对条件数据分布进行建模的变分扩散自编码器方法，它避免了对参数形式做出强烈假设，可以显著提高生成图像的质量。 |
| [^6] | [Estimation of sparse linear regression coefficients under $L$-subexponential covariates.](http://arxiv.org/abs/2304.11958) | 本文提出了一种方法，在不需要更强条件的情况下，即使在协变量来自 $L$-亚指数随机向量的情况下，使用$\ell_1$ -帕伯回归进行线性回归，可以得到与高斯随机向量相同（在常数因子下）的误差界限。 |
| [^7] | [Recurrent neural network based parameter estimation of Hawkes model on high-frequency financial data.](http://arxiv.org/abs/2304.11883) | 本研究利用循环神经网络对高频金融数据的Hawkes模型参数进行估计，并通过实时波动率测量进行应用。相较于传统方法，本方法具有更快的计算性能和可比较的准确性。 |
| [^8] | [Silent Abandonment in Contact Centers: Estimating Customer Patience from Uncertain Data.](http://arxiv.org/abs/2304.11754) | 该研究探究了客户在联系中心无声放弃的现象，通过不确定数据估计客户等待的耐心，揭示了这种现象对代理人时间和能力的浪费。 |
| [^9] | [Robust and differentially private stochastic linear bandits.](http://arxiv.org/abs/2304.11741) | 本文提出了一种在差分隐私和对抗性强健性条件下的随机线性赌博机算法，是首次提供这两个保护条件的算法。 |
| [^10] | [Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features.](http://arxiv.org/abs/2304.11737) | 本论文介绍了两种新的随机FW有限和最小化算法变体，适用于凸函数和非凸函数，且具有最佳收敛保证。同时两种方法不需要永久收集大批数据和全确定性梯度。 |
| [^11] | [Quantile Extreme Gradient Boosting for Uncertainty Quantification.](http://arxiv.org/abs/2304.11732) | 本论文提出了QXGBoost，它是对极端梯度提升（XGBoost）的增强，采用修改后的分位数回归方法估计不确定性。 |
| [^12] | [Stochastic Cell Transmission Models of Traffic Networks.](http://arxiv.org/abs/2304.11654) | 本文介绍了一个适用于交通网络的随机单元传输模型，通过偏好函数和可接受设计来评估交通系统的性能。数值实现结合了模拟、高斯过程回归和随机探索过程。 |
| [^13] | [Meaningful Causal Aggregation and Paradoxical Confounding.](http://arxiv.org/abs/2304.11625) | 聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。 |
| [^14] | [Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces.](http://arxiv.org/abs/2304.11468) | 该论文提出了一种自适应贝叶斯优化方法BAxUS，通过利用嵌套子空间来避免高维贝叶斯优化中的风险并确保高性能，相对于现有最先进方法在广泛应用中取得更好结果。 |
| [^15] | [Towards Understanding Feature Learning in Out-of-Distribution Generalization.](http://arxiv.org/abs/2304.11327) | 研究发现，ERM本质上同时学习了具有误导性的特征和不变特征，在ERM预训练期间学习到的特征质量影响了最终的OOD性能，未能捕获所有潜在的有用特征将限制最终的OOD性能。 |
| [^16] | [Machine Learning and the Future of Bayesian Computation.](http://arxiv.org/abs/2304.11251) | 本文讨论了利用机器学习的思想来改进贝叶斯计算的潜力，并探讨了几个具体的未来方向。 |
| [^17] | [Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions.](http://arxiv.org/abs/2304.11059) | 本文介绍了一种新的通用算法，利用尺度敏感的Vapnik维度来学习$[0,1]$值函数类，并获得了关于期望绝对误差的一般上限。文中证明该上限不能在一般情况下进一步改善一个常数因子。这篇论文对无偏学习样本复杂度的提高具有重要的意义。 |
| [^18] | [Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling.](http://arxiv.org/abs/2304.05365) | 本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。 |
| [^19] | [Partial Identification of Causal Effects Using Proxy Variables.](http://arxiv.org/abs/2304.04374) | 这篇论文提出了一种无需完备性的部分识别方法，它为我们提供了一组界限，用于在未能控制混淆因素的情形下，评估治疗对结果变量因果效应。 |
| [^20] | [Operator learning with PCA-Net: upper and lower complexity bounds.](http://arxiv.org/abs/2303.16317) | 本文发展了PCA-Net的近似理论，得出了通用逼近结果，并识别出了使用PCA-Net进行高效操作学习的潜在障碍：输出分布的复杂性和算子空间的内在复杂性。 |
| [^21] | [FuNVol: A Multi-Asset Implied Volatility Market Simulator using Functional Principal Components and Neural SDEs.](http://arxiv.org/abs/2303.00859) | FuNVol是一个多资产隐含波动率市场模拟器，使用函数主成分和神经SDE生成真实历史价格的IV表面序列，并在无静态套利的表面次流形内产生一致的市场情景。同时，使用模拟表面进行对冲可以生成与实现P＆L一致的损益分布。 |
| [^22] | [Bagging Provides Assumption-free Stability.](http://arxiv.org/abs/2301.12600) | 本文证明了Bagging技术可提供无偏差稳定性，适用于各种数据分布和算法，具有良好的实证效果。 |
| [^23] | [MMD-B-Fair: Learning Fair Representations with Statistical Testing.](http://arxiv.org/abs/2211.07907) | 提出了一种基于统计检验的 MMD-B-Fair 方法，用于学习公平的数据表示，并在各种数据集上得到了验证。 |
| [^24] | [PAC-Bayes Generalisation Bounds for Heavy-Tailed Losses through Supermartingales.](http://arxiv.org/abs/2210.00928) | 本文为重尾损失情况下的PAC-Bayes提供了泛化界，扩展了先前的研究，并通过马尔科夫不等式的扩展为不同的PAC-Bayesian框架提供了界限。 |
| [^25] | [Upper bounds on the Natarajan dimensions of some function classes.](http://arxiv.org/abs/2209.07015) | 本研究建立了一些函数类的Natarajan维度上界，这些结果可以用于描述某些多类学习算法的性能。 |
| [^26] | [Neural Point Estimation for Fast Optimal Likelihood-Free Inference.](http://arxiv.org/abs/2208.12942) | 本文介绍了一种快速、无需似然函数、易于进行基于自举的不确定性量化的推断工具——神经点估计器，并通过模拟研究和实际案例分析证明其可以在弱识别和高参数化模型中进行快速且最优的参数估计。 |
| [^27] | [Conformal Risk Control.](http://arxiv.org/abs/2208.02814) | 该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。 |
| [^28] | [Beyond neural scaling laws: beating power law scaling via data pruning.](http://arxiv.org/abs/2206.14486) | 本研究通过数据修剪算法突破神经网络训练集大小与模型误差幂律的尺度界限，并在多个数据集实验中验证了有效性，同时进行了首次大规模数据修剪算法基准测试研究。 |
| [^29] | [A Conditional Gradient-based Method for Simple Bilevel Optimization with Convex Lower-level Problem.](http://arxiv.org/abs/2206.08868) | 本文提出了一种新的双层优化方法，该方法通过局部逼近下层问题的解集，然后运行条件梯度更新来减少上层目标函数，并且收敛性保证较好。 |
| [^30] | [Robust PAC$^m$: Training Ensemble Models Under Model Misspecification and Outliers.](http://arxiv.org/abs/2203.01859) | 对于存在模型规格不准确和异常值情况下的集成学习，本文提出了一个新的鲁棒自由能量准则，通过将广义对数得分函数与PAC$^m$结合，实现了更好的模型性能。 |
| [^31] | [Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Streaming Data.](http://arxiv.org/abs/2109.07117) | 该论文介绍了流数据随机逼近算法的非渐近收敛速度，包括随机梯度下降、小批量SG和时间变化的小批量SG算法以及它们的迭代平均值，同时展示了加速收敛的方法和同时提供方差减少和加速收敛的优势。 |
| [^32] | [A theory of representation learning in deep neural networks gives a deep generalisation of kernel methods.](http://arxiv.org/abs/2108.13097) | 本文提出了一种新的无限宽度限制——贝叶斯表示学习限制，旨在解决标准无限宽度限制消除表示学习的问题。该方法可以实现类似于有限宽度模型中的表示学习效果，并保留标准无限宽度限制的简单性。 |
| [^33] | [MRCpy: A Library for Minimax Risk Classifiers.](http://arxiv.org/abs/2108.01952) | MRCpy是一种用于实现最小化风险分类器的Python库，它基于鲁棒风险最小化技术，可以利用0-1损失并提供了多种分类方法，其中一些提供了紧密的期望损失界限。 |
| [^34] | [Robust Model Selection and Nearly-Proper Learning for GMMs.](http://arxiv.org/abs/2106.02774) | 本文研究了一元高斯混合模型（GMMs）鲁棒模型选择的问题，提出了一个鲁棒算法，可以在对抗性扰动下近似正确地学习GMMs，实现了最佳样本复杂度，能够近似确定拟合分布所需的最少组件数。 |
| [^35] | [Conformalized Survival Analysis.](http://arxiv.org/abs/2103.09763) | 本文提出了一种基于拟合预测思想的推论方法，可以产生校准、基于协变量的生存时间的下界预测，不依赖强大的建模假设，可有效避免模型错误。 |
| [^36] | [IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters.](http://arxiv.org/abs/1903.12141) | 本文提出IMAE模型用于畸形训练数据的鲁棒深度学习，通过实践证实平均绝对误差（MAE）在处理示例时存在欠拟合问题，利用加权方差调整提高了拟合能力，同时保持了鲁棒性。 |
| [^37] | [The Simulator: Understanding Adaptive Sampling in the Moderate-Confidence Regime.](http://arxiv.org/abs/1702.05186) | 提出一种名为模拟器的新技术用于分析自适应采样。将重点放在了区分好的采样策略和坏采样策略的难度上。在纯探索场景的结构化多臂赌博问题中应用了该技术，展示了有中等置信度的样本复杂度和文献中在 $\delta \to 0$ 时得到的渐近复杂度之间存在着实质性差异，并且还证明了作为顶部-k问题的第一个基于实例的下界。 |

# 详细

[^1]: R包otsfeatures中的序时间序列分析

    Ordinal time series analysis with the R package otsfeatures. (arXiv:2304.12251v1 [stat.ML])

    [http://arxiv.org/abs/2304.12251](http://arxiv.org/abs/2304.12251)

    otsfeatures是一个R包，提供了一组函数用于分析序时间序列数据，其中包含提取统计特征和执行推断任务，以及聚类、分类或异常检测等常规机器学习任务。此外，该软件包还包含两个金融时间序列数据集和三个合成数据库。

    

    21世纪见证了对时间序列数据分析的不断兴趣。虽然大部分文献都处理了实值时间序列的问题，但序时间序列通常受到的关注较少。然而，对后者的特定分析工具的发展近年来已经显著增加。 R包otsfeatures旨在提供一组简单的函数，用于分析序时间序列。特别地，提供了几个命令，允许用户提取一些已知的统计特征和执行推断任务。几个函数的输出可以用于执行传统的机器学习任务，包括聚类，分类或异常检测。otsfeatures还包含了两个金融时间序列数据集，这些数据集在文献中用于聚类目的，以及三个有趣的合成数据库。描述了该软件包的主要属性。

    The 21st century has witnessed a growing interest in the analysis of time series data. Whereas most of the literature on the topic deals with real-valued time series, ordinal time series have typically received much less attention. However, the development of specific analytical tools for the latter objects has substantially increased in recent years. The R package otsfeatures attempts to provide a set of simple functions for analyzing ordinal time series. In particular, several commands allowing the extraction of well-known statistical features and the execution of inferential tasks are available for the user. The output of several functions can be employed to perform traditional machine learning tasks including clustering, classification or outlier detection. otsfeatures also incorporates two datasets of financial time series which were used in the literature for clustering purposes, as well as three interesting synthetic databases. The main properties of the package are described an
    
[^2]: 基于两个新距离的序列模糊聚类及其在经济学中的应用

    Fuzzy clustering of ordinal time series based on two novel distances with economic applications. (arXiv:2304.12249v1 [stat.ML])

    [http://arxiv.org/abs/2304.12249](http://arxiv.org/abs/2304.12249)

    本文研究了离散响应的序列模糊聚类问题，提出了两种新的距离度量，其中的算法具有高效性和准确性，并可在经济学领域获得应用。

    

    时间序列聚类是一项有广泛应用的机器学习任务。然而绝大部分方法聚焦于连续型时间序列，只有极少数研究离散响应的序列。本文研究了序列模糊聚类问题，引入了两个新的序列距离度量，并用其构建模糊聚类算法。这两个距离度量均是估算的累积概率函数，从而自动利用了序列范围的排序优势。算法具有高效性，并能够准确将来自各种模型的相似随机过程序列分组。由于序列动态可能随时间变化，本文采用了模糊方法，使得算法可以在不同成员度数的几个类别中定位每个序列。本文还提供了大量的仿真实验以及在经济学中运用的案例。

    Time series clustering is a central machine learning task with applications in many fields. While the majority of the methods focus on real-valued time series, very few works consider series with discrete response. In this paper, the problem of clustering ordinal time series is addressed. To this aim, two novel distances between ordinal time series are introduced and used to construct fuzzy clustering procedures. Both metrics are functions of the estimated cumulative probabilities, thus automatically taking advantage of the ordering inherent to the series' range. The resulting clustering algorithms are computationally efficient and able to group series generated from similar stochastic processes, reaching accurate results even though the series come from a wide variety of models. Since the dynamic of the series may vary over the time, we adopt a fuzzy approach, thus enabling the procedures to locate each series into several clusters with different membership degrees. An extensive simul
    
[^3]: 一种转移原理：从欧几里得通用逼近器到度量空间之间的通用逼近器

    A Transfer Principle: Universal Approximators Between Metric Spaces From Euclidean Universal Approximators. (arXiv:2304.12231v1 [cs.LG])

    [http://arxiv.org/abs/2304.12231](http://arxiv.org/abs/2304.12231)

    本论文提出使用欧几里得空间通用逼近器为构建块，构建了在任意波兰度量空间 $\mathcal{X}$ 和 $\mathcal{Y}$ 之间的通用逼近器，并通过随机化输出离散概率测度来克服某些限制。在适当的结构下提供了概率和定量保证。

    

    我们使用欧几里得空间通用逼近器作为构建块，构建了连续映射的度量空间之间的通用逼近器。早期结果假定输出空间 $\mathcal{Y}$ 是拓扑向量空间。我们通过“随机化”来克服这种限制：我们的逼近器输出 $\mathcal{Y}$ 上的离散概率测度。当 $\mathcal{X}$ 和 $\mathcal{Y}$ 没有附加结构时，我们证明了非常通用的定性保证；当它们具有适当的组合结构时，我们证明了 H\"older 类映射的定量保证，包括有限图之间的映射，在某些 Carnot 群之间的粗微分方程的解算子以及反问题中出现的 Banach 空间之间的连续非线性算子。特别地，我们展示了所需的 Dirac 测度数量由 $\mathcal{X}$ 和 $\mathcal{Y}$ 的组合结构决定。

    We build universal approximators of continuous maps between arbitrary Polish metric spaces $\mathcal{X}$ and $\mathcal{Y}$ using universal approximators between Euclidean spaces as building blocks. Earlier results assume that the output space $\mathcal{Y}$ is a topological vector space. We overcome this limitation by "randomization": our approximators output discrete probability measures over $\mathcal{Y}$. When $\mathcal{X}$ and $\mathcal{Y}$ are Polish without additional structure, we prove very general qualitative guarantees; when they have suitable combinatorial structure, we prove quantitative guarantees for H\"older-like maps, including maps between finite graphs, solution operators to rough differential equations between certain Carnot groups, and continuous non-linear operators between Banach spaces arising in inverse problems. In particular, we show that the required number of Dirac measures is determined by the combinatorial structure of $\mathcal{X}$ and $\mathcal{Y}$. For b
    
[^4]: 更多通信不会使联邦学习中的泛化误差变小。

    More Communication Does Not Result in Smaller Generalization Error in Federated Learning. (arXiv:2304.12216v1 [stat.ML])

    [http://arxiv.org/abs/2304.12216](http://arxiv.org/abs/2304.12216)

    我们研究了联邦学习环境下的统计学习模型泛化误差，表明更频繁地与参数服务器通信会负面影响此类学习算法的泛化性能。

    

    我们研究了联邦学习（FL）环境下统计学习模型的泛化误差。具体而言，有$K$个设备或客户端，每个设备持有一个大小为$n$的独立数据集。通过随机梯度下降本地学习的个体模型通过一个中央服务器进行聚合（平均），然后发送回设备。我们考虑多次（比如说$R\in \mathbb{N}^*$）模型聚合并研究$R$对最终聚合模型的泛化误差的影响。我们建立了一个上界，明确考虑了$R$（除了参与设备的数量$K$和数据集大小$n$）的影响。观察到对于固定的$(n,K)$，上界随$R$的增加而增加，这表明更频繁地与参数服务器通信会负面影响此类学习算法的泛化性能。与此同时，由于经验风险通常只随着$n$的增加而减少，因此我们的理论证明了为了在FL中实现良好的泛化性能，需要权衡本地学习和全局聚合之间的权衡。

    We study the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, there are $K$ devices or clients, each holding an independent own dataset of size $n$. Individual models, learned locally via Stochastic Gradient Descent, are aggregated (averaged) by a central server into a global model and then sent back to the devices. We consider multiple (say $R \in \mathbb N^*$) rounds of model aggregation and study the effect of $R$ on the generalization error of the final aggregated model. We establish an upper bound on the generalization error that accounts explicitly for the effect of $R$ (in addition to the number of participating devices $K$ and dataset size $n$). It is observed that, for fixed $(n, K)$, the bound increases with $R$, suggesting that the generalization of such learning algorithms is negatively affected by more frequent communication with the parameter server. Combined with the fact that the empirical risk, however, generally d
    
[^5]: 变分扩散自编码器：具有无条件扩散先验的深层潜变量模型

    Variational Diffusion Auto-encoder: Deep Latent Variable Model with Unconditional Diffusion Prior. (arXiv:2304.12141v1 [cs.LG])

    [http://arxiv.org/abs/2304.12141](http://arxiv.org/abs/2304.12141)

    本文提出了一种基于扩散模型对条件数据分布进行建模的变分扩散自编码器方法，它避免了对参数形式做出强烈假设，可以显著提高生成图像的质量。

    

    变分自编码器是深度生成建模的一种最流行的方法。尽管取得了成功，但因为高度不现实的建模假设，即条件数据分布p(x|z)可以近似为各向同性高斯分布，所以由变分自编码器生成的图像是模糊的。在本文中，我们引入了一种基于扩散模型对条件数据分布p(x|z)进行建模的原则性方法。我们证明了可以创建类似变分自编码器的深潜变量模型，而无需对p(x|z)做高斯假设，甚至不需要训练解码器网络。通过Bayes'规则，可以将经过训练的编码器和无条件扩散模型组合到一起，以获得一个表达丰富的p(x|z)模型。我们的方法避免了对参数形式p(x|z)做出强烈假设，因此可以显著提高生成图像的质量。

    Variational auto-encoders (VAEs) are one of the most popular approaches to deep generative modeling. Despite their success, images generated by VAEs are known to suffer from blurriness, due to a highly unrealistic modeling assumption that the conditional data distribution $ p(\textbf{x} | \textbf{z})$ can be approximated as an isotropic Gaussian. In this work we introduce a principled approach to modeling the conditional data distribution $p(\textbf{x} | \textbf{z})$ by incorporating a diffusion model. We show that it is possible to create a VAE-like deep latent variable model without making the Gaussian assumption on $ p(\textbf{x} | \textbf{z}) $ or even training a decoder network. A trained encoder and an unconditional diffusion model can be combined via Bayes' rule for score functions to obtain an expressive model for $ p(\textbf{x} | \textbf{z}) $. Our approach avoids making strong assumptions on the parametric form of $ p(\textbf{x} | \textbf{z}) $, and thus allows to significant
    
[^6]: 在 $L$-亚指数协变量下的稀疏线性回归系数估计

    Estimation of sparse linear regression coefficients under $L$-subexponential covariates. (arXiv:2304.11958v1 [math.ST])

    [http://arxiv.org/abs/2304.11958](http://arxiv.org/abs/2304.11958)

    本文提出了一种方法，在不需要更强条件的情况下，即使在协变量来自 $L$-亚指数随机向量的情况下，使用$\ell_1$ -帕伯回归进行线性回归，可以得到与高斯随机向量相同（在常数因子下）的误差界限。

    

    当协变量来自 $L$-亚指数随机向量时，我们解决了在线性回归中估计稀疏系数的任务，该随机向量属于一类具有比高斯随机向量更重的尾巴的分布。以前的工作通过假设协变量来自 $L$-亚指数随机向量来解决这个问题，并建立了类似于对高斯随机向量导出的误差界限。然而，这些以前的方法要求更强的条件，以导出与高斯随机向量相同的误差界限。在本文中，我们在不需要更强的条件的情况下提出了与高斯随机向量相同（在常数因子下），甚至当协变量来自 $L$-亚指数随机向量时的误差界限。有趣的是，我们利用了 $\ell_1$-帕伯回归，该回归因其对重尾随机噪声的鲁棒性而被认为是重要的，而不是协变量。我们相信...

    We address a task of estimating sparse coefficients in linear regression when the covariates are drawn from an $L$-subexponential random vector, which belongs to a class of distributions having heavier tails than a Gaussian random vector. Prior works have tackled this issue by assuming that the covariates are drawn from an $L$-subexponential random vector and have established error bounds that resemble those derived for Gaussian random vectors. However, these previous methods require stronger conditions to derive error bounds than those employed for Gaussian random vectors. In the present paper, we present an error bound identical to that obtained for Gaussian random vectors, up to constant factors, without requiring stronger conditions, even when the covariates are drawn from an $L$-subexponential random vector. Somewhat interestingly, we utilize an $\ell_1$-penalized Huber regression, that is recognized for its robustness to heavy-tailed random noises, not covariates. We believe that
    
[^7]: 基于循环神经网络的高频金融数据Hawkes模型参数估计

    Recurrent neural network based parameter estimation of Hawkes model on high-frequency financial data. (arXiv:2304.11883v1 [q-fin.ST])

    [http://arxiv.org/abs/2304.11883](http://arxiv.org/abs/2304.11883)

    本研究利用循环神经网络对高频金融数据的Hawkes模型参数进行估计，并通过实时波动率测量进行应用。相较于传统方法，本方法具有更快的计算性能和可比较的准确性。

    

    本研究探讨了利用循环神经网络对基于高频金融数据的Hawkes模型参数进行估计，并通过计算波动性来进行分析。神经网络在各个领域都展现出了良好的效果，在金融领域中的应用也正在增长。与传统最大似然估计方法相比，我们的方法在模拟和实证研究中表现出了可比较的准确性，同时具有显着更快的计算性能。此外，我们演示了该方法在实时波动率测量中的应用，可以持续地估计金融波动性，随着市场上出现新的价格数据。

    This study examines the use of a recurrent neural network for estimating the parameters of a Hawkes model based on high-frequency financial data, and subsequently, for computing volatility. Neural networks have shown promising results in various fields, and interest in finance is also growing. Our approach demonstrates significantly faster computational performance compared to traditional maximum likelihood estimation methods while yielding comparable accuracy in both simulation and empirical studies. Furthermore, we demonstrate the application of this method for real-time volatility measurement, enabling the continuous estimation of financial volatility as new price data keeps coming from the market.
    
[^8]: 无声放弃：如何从不确定数据中估计客户等待的耐心

    Silent Abandonment in Contact Centers: Estimating Customer Patience from Uncertain Data. (arXiv:2304.11754v1 [cs.SI])

    [http://arxiv.org/abs/2304.11754](http://arxiv.org/abs/2304.11754)

    该研究探究了客户在联系中心无声放弃的现象，通过不确定数据估计客户等待的耐心，揭示了这种现象对代理人时间和能力的浪费。

    

    为了提高服务质量，公司为客户提供与代理人进行交互的机会，其中大部分交流是基于文本的。这已成为近年来客户与公司交流的最受欢迎的渠道之一。然而，联系中心面临运营挑战，因为客户体验的常见代理，例如是否知道客户已放弃排队和他们等待服务的意愿（耐心），受到信息不确定性的影响。我们的研究聚焦于主要不确定性来源的影响：客户的无声放弃。这些客户在等待回答他们的查询时离开系统，但没有给出任何指示，例如关闭互动的移动应用程序。因此，系统不知道他们已经离开，并浪费代理人的时间和能力，直到意识到这一事实。本文表明，放弃客户中的30％-67％放弃时会采取无声放弃策略。

    In the quest to improve services, companies offer customers the opportunity to interact with agents through contact centers, where the communication is mainly text-based. This has become one of the favorite channels of communication with companies in recent years. However, contact centers face operational challenges, since the measurement of common proxies for customer experience, such as knowledge of whether customers have abandoned the queue and their willingness to wait for service (patience), are subject to information uncertainty. We focus this research on the impact of a main source of such uncertainty: silent abandonment by customers. These customers leave the system while waiting for a reply to their inquiry, but give no indication of doing so, such as closing the mobile app of the interaction. As a result, the system is unaware that they have left and waste agent time and capacity until this fact is realized. In this paper, we show that 30%-67% of the abandoning customers aban
    
[^9]: 强健且具有差分隐私保护的随机线性赌博机

    Robust and differentially private stochastic linear bandits. (arXiv:2304.11741v1 [cs.LG])

    [http://arxiv.org/abs/2304.11741](http://arxiv.org/abs/2304.11741)

    本文提出了一种在差分隐私和对抗性强健性条件下的随机线性赌博机算法，是首次提供这两个保护条件的算法。

    

    本文研究了在差分隐私、强健性和批量观察这些附加条件下的随机线性赌博机问题。特别地，我们假设在每个批次中，对于观测到的奖励，对手会随机选择其中的一个固定部分，并用任意数字替换。我们以对数批量查询为基础，分别在两种隐私模型下提出了有差分隐私保护和强健的臂消除算法变体，并在两种情况下提供了遗憾界。在第一个模型中，每一轮中的每个奖励都由可能不同的客户报告，这归结为标准的本地差分隐私。在第二个模型中，每个动作由不同的客户“拥有”，这些客户可能会汇总多个查询的奖励，并将聚合响应私有化。据我们所知，我们的算法是在随机线性赌博机问题中，首次同时提供差分隐私和对抗性强健性的算法。

    In this paper, we study the stochastic linear bandit problem under the additional requirements of differential privacy, robustness and batched observations. In particular, we assume an adversary randomly chooses a constant fraction of the observed rewards in each batch, replacing them with arbitrary numbers. We present differentially private and robust variants of the arm elimination algorithm using logarithmic batch queries under two privacy models and provide regret bounds in both settings. In the first model, every reward in each round is reported by a potentially different client, which reduces to standard local differential privacy (LDP). In the second model, every action is "owned" by a different client, who may aggregate the rewards over multiple queries and privatize the aggregate response instead. To the best of our knowledge, our algorithms are the first simultaneously providing differential privacy and adversarial robustness in the stochastic linear bandits problem.
    
[^10]: Sarah Frank-Wolfe：具有最佳速率和实用特点的约束优化方法

    Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features. (arXiv:2304.11737v1 [math.OC])

    [http://arxiv.org/abs/2304.11737](http://arxiv.org/abs/2304.11737)

    本论文介绍了两种新的随机FW有限和最小化算法变体，适用于凸函数和非凸函数，且具有最佳收敛保证。同时两种方法不需要永久收集大批数据和全确定性梯度。

    

    Frank-Wolfe（FW）方法是解决机器学习应用中出现的结构化约束优化问题的流行方法。近年来，受到大数据集的启发，FW的随机版本变得更加流行，因为计算全梯度代价过高。本文介绍了两种新的FW随机有限和最小化算法变体。我们的算法既适用于凸函数又适用于非凸函数。我们的方法不存在永久收集大批数据的问题，这是许多投影无约束随机方法的共同问题。此外，我们的第二种方法既不需要大批量的数据也不需要全确定性梯度，这是许多有限和问题技术的典型弱点。我们方法的更快收敛速度在实践中得到了验证。

    The Frank-Wolfe (FW) method is a popular approach for solving optimization problems with structured constraints that arise in machine learning applications. In recent years, stochastic versions of FW have gained popularity, motivated by large datasets for which the computation of the full gradient is prohibitively expensive. In this paper, we present two new variants of the FW algorithms for stochastic finite-sum minimization. Our algorithms have the best convergence guarantees of existing stochastic FW approaches for both convex and non-convex objective functions. Our methods do not have the issue of permanently collecting large batches, which is common to many stochastic projection-free approaches. Moreover, our second approach does not require either large batches or full deterministic gradients, which is a typical weakness of many techniques for finite-sum problems. The faster theoretical rates of our approaches are confirmed experimentally.
    
[^11]: 分位数极端梯度提升用于不确定性量化

    Quantile Extreme Gradient Boosting for Uncertainty Quantification. (arXiv:2304.11732v1 [stat.ML])

    [http://arxiv.org/abs/2304.11732](http://arxiv.org/abs/2304.11732)

    本论文提出了QXGBoost，它是对极端梯度提升（XGBoost）的增强，采用修改后的分位数回归方法估计不确定性。

    

    近年来，随着数据的可用性、规模和复杂性的增加，机器学习（ML）技术已经成为建模的热门方法。将ML模型应用于预测的结果经常被用于推理、决策和下游应用。然而，ML模型的不确定性量化是一个至关重要但常常被忽视的方面，它能够显著影响模型预测的使用和解释。极端梯度提升（XGBoost）是最受欢迎的ML方法之一，因为它的实现简单、计算速度快、序列学习等原因，其预测相对于其他方法来说更为准确。然而，对于如XGBoost这样的ML模型的不确定性确定技术，其在不同应用场景中仍然存在争议。我们提出了对XGBoost的增强措施，采用修改后的分位数回归作为目标函数来估计不确定性（QXGBoost）。具体而言，我们在分位数回归中引入了Huber范数。

    As the availability, size and complexity of data have increased in recent years, machine learning (ML) techniques have become popular for modeling. Predictions resulting from applying ML models are often used for inference, decision-making, and downstream applications. A crucial yet often overlooked aspect of ML is uncertainty quantification, which can significantly impact how predictions from models are used and interpreted.  Extreme Gradient Boosting (XGBoost) is one of the most popular ML methods given its simple implementation, fast computation, and sequential learning, which make its predictions highly accurate compared to other methods. However, techniques for uncertainty determination in ML models such as XGBoost have not yet been universally agreed among its varying applications. We propose enhancements to XGBoost whereby a modified quantile regression is used as the objective function to estimate uncertainty (QXGBoost). Specifically, we included the Huber norm in the quantile 
    
[^12]: 交通网络的随机单元传输模型

    Stochastic Cell Transmission Models of Traffic Networks. (arXiv:2304.11654v1 [cs.LG])

    [http://arxiv.org/abs/2304.11654](http://arxiv.org/abs/2304.11654)

    本文介绍了一个适用于交通网络的随机单元传输模型，通过偏好函数和可接受设计来评估交通系统的性能。数值实现结合了模拟、高斯过程回归和随机探索过程。

    

    我们为一般交通网络引入了随机单元传输模型的严格框架。通过偏好函数和可接受设计评估交通系统的性能。数值实现结合了模拟、高斯过程回归和随机探索过程。该方法在两个案例研究中得到了说明。

    We introduce a rigorous framework for stochastic cell transmission models for general traffic networks. The performance of traffic systems is evaluated based on preference functionals and acceptable designs. The numerical implementation combines simulation, Gaussian process regression, and a stochastic exploration procedure. The approach is illustrated in two case studies.
    
[^13]: 有意义的因果聚合和悖论性混淆

    Meaningful Causal Aggregation and Paradoxical Confounding. (arXiv:2304.11625v1 [cs.AI])

    [http://arxiv.org/abs/2304.11625](http://arxiv.org/abs/2304.11625)

    聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。

    

    在聚合变量中，干预的影响通常是不确定的，因为相同的宏观干预的不同微观实现可能会导致下游宏观变量的不同变化。我们表明，对于聚合变量，因果性的不确定性可以使得原本不混淆的因果关系变得混淆，并且反之亦然，这一点取决于相应的微观实现。我们认为，只有在聚合因果系统没有这种不确定性的情况下，我们才可以实际应用这种方法。否则，我们需要接受一点，就是宏观因果关系通常只与微观状态相关。在积极方面，我们表明当宏观干预的分布与观测分布中微观状态的分布相同时，因果关系可以进行聚合，并讨论了此观察的概括。

    In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation.
    
[^14]: 学习时扩大范围：嵌套子空间中的自适应贝叶斯优化

    Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces. (arXiv:2304.11468v1 [cs.LG])

    [http://arxiv.org/abs/2304.11468](http://arxiv.org/abs/2304.11468)

    该论文提出了一种自适应贝叶斯优化方法BAxUS，通过利用嵌套子空间来避免高维贝叶斯优化中的风险并确保高性能，相对于现有最先进方法在广泛应用中取得更好结果。

    

    最近的进展将贝叶斯优化（BO）的范围扩展到了具有几十个维度的昂贵黑盒函数，并渴望在生命科学、神经架构搜索和机器人等领域实现重大应用。然而，对高维贝叶斯优化（HDBO）的现有方法的更深入研究表明，随着维度数量的增加，性能会降低，甚至有失败风险，如果不满足某些无法验证的假设。该论文提出了BAxUS，它利用一族新颖的嵌套随机子空间来使其优化的空间适应问题。这确保了高性能，同时通过理论保证消除了失败的风险。全面评估表明，对于广泛的应用，BAxUS比现有的最先进方法取得了更好的结果。

    Recent advances have extended the scope of Bayesian optimization (BO) to expensive-to-evaluate black-box functions with dozens of dimensions, aspiring to unlock impactful applications, for example, in the life sciences, neural architecture search, and robotics. However, a closer examination reveals that the state-of-the-art methods for high-dimensional Bayesian optimization (HDBO) suffer from degrading performance as the number of dimensions increases or even risk failure if certain unverifiable assumptions are not met. This paper proposes BAxUS that leverages a novel family of nested random subspaces to adapt the space it optimizes over to the problem. This ensures high performance while removing the risk of failure, which we assert via theoretical guarantees. A comprehensive evaluation demonstrates that BAxUS achieves better results than the state-of-the-art methods for a broad set of applications.
    
[^15]: 探索外部分布广义化中的特征学习

    Towards Understanding Feature Learning in Out-of-Distribution Generalization. (arXiv:2304.11327v1 [cs.LG])

    [http://arxiv.org/abs/2304.11327](http://arxiv.org/abs/2304.11327)

    研究发现，ERM本质上同时学习了具有误导性的特征和不变特征，在ERM预训练期间学习到的特征质量影响了最终的OOD性能，未能捕获所有潜在的有用特征将限制最终的OOD性能。

    

    对于外部分布（OOD）广义化的失败，常见的解释是使用经验风险最小化（ERM）模型学习到具有误导性的特征而不是期望的不变特征。然而，最近的几项研究挑战了这种解释，发现深度网络可能已经学到了足够好的特征进行OOD广义化。这场辩论扩展到了许多OOD广义化任务的训练或微调神经网络的内部组织和OOD性能相关性中。为了理解这些似乎相互矛盾的现象，我们进行了理论研究，发现ERM本质上同时学习了具有误导性的特征和不变特征。另一方面，在ERM预训练期间学习到的特征质量显著影响了最终的OOD性能，因为OOD对象很少学习到新功能。未能在预训练期间捕获所有潜在的有用特征将进一步限制最终的OOD性能。

    A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of the desired invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. The debate extends to the in-distribution and OOD performance correlations along with training or fine-tuning neural nets across a variety of OOD generalization tasks. To understand these seemingly contradicting phenomena, we conduct a theoretical investigation and find that ERM essentially learns both spurious features and invariant features. On the other hand, the quality of learned features during ERM pre-training significantly affects the final OOD performance, as OOD objectives rarely learn new features. Failing to capture all the underlying useful features during pre-training will further limit the final OOD
    
[^16]: 机器学习与贝叶斯计算的未来

    Machine Learning and the Future of Bayesian Computation. (arXiv:2304.11251v1 [stat.ML])

    [http://arxiv.org/abs/2304.11251](http://arxiv.org/abs/2304.11251)

    本文讨论了利用机器学习的思想来改进贝叶斯计算的潜力，并探讨了几个具体的未来方向。

    

    贝叶斯模型是研究复杂数据的强大工具，允许分析人员编码丰富的层次依赖关系并利用先验信息。最重要的是，它们通过后验分布促进了对不确定性的完整表征。实用的后验计算通常通过MCMC进行，但对于具有许多观测值的高维模型而言，这可能计算上不可行。在本文中，我们讨论利用机器学习思想来改进后验计算的潜力。具体的未来方向在正态流、贝叶斯核心集、分布式贝叶斯推断和变分推断的vignettes中得到探讨。

    Bayesian models are a powerful tool for studying complex data, allowing the analyst to encode rich hierarchical dependencies and leverage prior information. Most importantly, they facilitate a complete characterization of uncertainty through the posterior distribution. Practical posterior computation is commonly performed via MCMC, which can be computationally infeasible for high dimensional models with many observations. In this article we discuss the potential to improve posterior computation using ideas from machine learning. Concrete future directions are explored in vignettes on normalizing flows, Bayesian coresets, distributed Bayesian inference, and variational inference.
    
[^17]: 预测、学习、一致收敛和尺度敏感维度

    Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions. (arXiv:2304.11059v1 [cs.LG])

    [http://arxiv.org/abs/2304.11059](http://arxiv.org/abs/2304.11059)

    本文介绍了一种新的通用算法，利用尺度敏感的Vapnik维度来学习$[0,1]$值函数类，并获得了关于期望绝对误差的一般上限。文中证明该上限不能在一般情况下进一步改善一个常数因子。这篇论文对无偏学习样本复杂度的提高具有重要的意义。

    

    我们提出了一种新的通用算法，用于在预测模型的推广中学习$[0,1]$值函数类，并证明了一般性的上限，该上限反映了由Alon、Ben-David、Cesa-Bianchi和Haussler提出的尺度敏感的Vapnik维度的推广。我们给出了下限，这表明我们的上限不能在一般情况下进一步改善一个常数因子。我们应用此结果和Haussler以及Benedek和Itai的技术，以利用这种尺度敏感的维度概念获得新的填充数上限。我们利用不同的技术，利用Kearns和Schapire的fat-shattering函数得到了新的填充数上限。我们展示了如何应用这两种填充上限来获得对无偏学习样本复杂度的改进一般性上限。对于每个$\epsilon > 0$，我们建立了一个类的足够条件和必要条件。

    We present a new general-purpose algorithm for learning classes of $[0,1]$-valued functions in a generalization of the prediction model, and prove a general upper bound on the expected absolute error of this algorithm in terms of a scale-sensitive generalization of the Vapnik dimension proposed by Alon, Ben-David, Cesa-Bianchi and Haussler. We give lower bounds implying that our upper bounds cannot be improved by more than a constant factor in general. We apply this result, together with techniques due to Haussler and to Benedek and Itai, to obtain new upper bounds on packing numbers in terms of this scale-sensitive notion of dimension. Using a different technique, we obtain new bounds on packing numbers in terms of Kearns and Schapire's fat-shattering function. We show how to apply both packing bounds to obtain improved general bounds on the sample complexity of agnostic learning. For each $\epsilon > 0$, we establish weaker sufficient and stronger necessary conditions for a class of 
    
[^18]: 我们实现了个性化治疗吗？使用重复采样的在线强化学习算法进行个性化评估

    Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])

    [http://arxiv.org/abs/2304.05365](http://arxiv.org/abs/2304.05365)

    本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。

    

    在数字健康中，使用强化学习（RL）个性化治疗序列以支持用户采取更健康的行为越来越受到关注。这种连续决策问题涉及到基于用户的上下文（例如，先前的活动水平、位置等）在何时治疗以及如何治疗的决定。在线RL算法是这个问题的一个有前途的数据驱动方法，因为它基于每个用户的历史反馈进行学习，并利用这些知识个性化这些决策。然而，要决定是否应在实际部署的“优化”干预中包含RL算法，我们必须评估数据证据，表明RL算法实际上正在将治疗个性化适应其用户。由于RL算法中的随机性，人们可能会对其在某些状态下的学习并使用此学习来提供特定治疗的能力产生误解。我们使用工作定义的个性化，并介绍了一种重复采样政策评估方法来评估在线RL算法实现的个性化水平。我们使用模拟评估了我们提出的方法，并展示了我们的方法可以准确地识别个性化的策略。我们提出的方法在优化数字健康的个性化干预方面具有潜在应用。

    There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
    
[^19]: 利用代理变量进行因果效应部分识别

    Partial Identification of Causal Effects Using Proxy Variables. (arXiv:2304.04374v1 [stat.ME])

    [http://arxiv.org/abs/2304.04374](http://arxiv.org/abs/2304.04374)

    这篇论文提出了一种无需完备性的部分识别方法，它为我们提供了一组界限，用于在未能控制混淆因素的情形下，评估治疗对结果变量因果效应。

    

    近年来，近端因果推断被提出为一种在未能控制混淆因素的情形下评估治疗对结果变量因果效应的框架。其中利用未被观测到的混淆因素的代理变量进行点估计，前提是这样的代理变量对混淆因素相当有关，然而这种完备性却是经验不可检验的。本文提出了一种不要求完备性的部分识别方法，并为感兴趣的因果效应提供了一组界限。该方法建立在敏感性分析的基础上，并且比现有的基于代理变量的方法要求更弱。这项工作在模拟数据和现实数据上进行了展示。

    Proximal causal inference is a recently proposed framework for evaluating the causal effect of a treatment on an outcome variable in the presence of unmeasured confounding (Miao et al., 2018a; Tchetgen Tchetgen et al., 2020). For nonparametric point identification, the framework leverages proxy variables of unobserved confounders, provided that such proxies are sufficiently relevant for the latter, a requirement that has previously been formalized as a completeness condition. Completeness is key to connecting the observed proxy data to hidden factors via a so-called confounding bridge function, identification of which is an important step towards proxy-based point identification of causal effects. However, completeness is well-known not to be empirically testable, therefore potentially restricting the application of the proximal causal framework. In this paper, we propose partial identification methods that do not require completeness and obviate the need for identification of a bridge
    
[^20]: PCA-Net：操作学习的复杂性上下界

    Operator learning with PCA-Net: upper and lower complexity bounds. (arXiv:2303.16317v1 [cs.LG])

    [http://arxiv.org/abs/2303.16317](http://arxiv.org/abs/2303.16317)

    本文发展了PCA-Net的近似理论，得出了通用逼近结果，并识别出了使用PCA-Net进行高效操作学习的潜在障碍：输出分布的复杂性和算子空间的内在复杂性。

    

    神经算子在计算科学和工程中备受关注。PCA-Net是一种最近提出的神经算子架构，它将主成分分析(PCA)与神经网络相结合，以逼近潜在的算子。本文对这种方法进行了近似理论的发展，改进并显着扩展了此方向的以前的工作。在定性界限方面，本文得出了新颖的通用逼近结果，在对潜在算子和数据生成分布的最小假设的前提下。在定量限制方面，本文识别了使用PCA-Net进行高效操作学习的两个潜在障碍，通过导出下界进行了严格证明，第一个障碍与输出分布的复杂性有关，由PCA特征值的缓慢衰减来衡量；另一个障碍涉及无限维输入和输出空间之间的算子空间的内在复杂性。

    Neural operators are gaining attention in computational science and engineering. PCA-Net is a recently proposed neural operator architecture which combines principal component analysis (PCA) with neural networks to approximate an underlying operator. The present work develops approximation theory for this approach, improving and significantly extending previous work in this direction. In terms of qualitative bounds, this paper derives a novel universal approximation result, under minimal assumptions on the underlying operator and the data-generating distribution. In terms of quantitative bounds, two potential obstacles to efficient operator learning with PCA-Net are identified, and made rigorous through the derivation of lower complexity bounds; the first relates to the complexity of the output distribution, measured by a slow decay of the PCA eigenvalues. The other obstacle relates the inherent complexity of the space of operators between infinite-dimensional input and output spaces, 
    
[^21]: FuNVol：使用函数主成分和神经SDE的多资产隐含波动率市场模拟器

    FuNVol: A Multi-Asset Implied Volatility Market Simulator using Functional Principal Components and Neural SDEs. (arXiv:2303.00859v2 [q-fin.CP] UPDATED)

    [http://arxiv.org/abs/2303.00859](http://arxiv.org/abs/2303.00859)

    FuNVol是一个多资产隐含波动率市场模拟器，使用函数主成分和神经SDE生成真实历史价格的IV表面序列，并在无静态套利的表面次流形内产生一致的市场情景。同时，使用模拟表面进行对冲可以生成与实现P＆L一致的损益分布。

    

    我们介绍了一种新的方法，使用函数数据分析和神经随机微分方程，结合概率积分变换惩罚来生成多个资产的隐含波动率表面序列，该方法忠实于历史价格。我们证明了学习IV表面和价格的联合动态产生的市场情景与历史特征一致，并且在没有静态套利的表面次流形内。最后，我们证明使用模拟表面进行对冲会生成与实现P＆L一致的损益分布。

    Here, we introduce a new approach for generating sequences of implied volatility (IV) surfaces across multiple assets that is faithful to historical prices. We do so using a combination of functional data analysis and neural stochastic differential equations (SDEs) combined with a probability integral transform penalty to reduce model misspecification. We demonstrate that learning the joint dynamics of IV surfaces and prices produces market scenarios that are consistent with historical features and lie within the sub-manifold of surfaces that are essentially free of static arbitrage. Finally, we demonstrate that delta hedging using the simulated surfaces generates profit and loss (P&L) distributions that are consistent with realised P&Ls.
    
[^22]: Bagging提供无偏差稳定性。

    Bagging Provides Assumption-free Stability. (arXiv:2301.12600v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.12600](http://arxiv.org/abs/2301.12600)

    本文证明了Bagging技术可提供无偏差稳定性，适用于各种数据分布和算法，具有良好的实证效果。

    

    Bagging是稳定机器学习模型的一个重要技术。在本文中，我们针对任何模型的稳定性推导了一个有限样本保证。我们的结果不对数据分布、基本算法的属性或协变量的维数进行任何假设。我们的保证适用于多种变体的Bagging，并且是最优的常数。实证结果验证了我们的发现，表明Bagging成功稳定了即使是高度不稳定的基本算法。

    Bagging is an important technique for stabilizing machine learning models. In this paper, we derive a finite-sample guarantee on the stability of bagging for any model. Our result places no assumptions on the distribution of the data, on the properties of the base algorithm, or on the dimensionality of the covariates. Our guarantee applies to many variants of bagging and is optimal up to a constant. Empirical results validate our findings, showing that bagging successfully stabilizes even highly unstable base algorithms.
    
[^23]: 基于统计检验的MMD-B-Fair：学习公平的表示

    MMD-B-Fair: Learning Fair Representations with Statistical Testing. (arXiv:2211.07907v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.07907](http://arxiv.org/abs/2211.07907)

    提出了一种基于统计检验的 MMD-B-Fair 方法，用于学习公平的数据表示，并在各种数据集上得到了验证。

    

    我们提出了一种通过核双样本测试学习数据公平表示的方法MMD-B-Fair。我们找到了数据的神经特征，其中最大平均偏差（MMD）测试无法区分不同敏感组的表示，同时保留有关目标属性的信息。我们的方法利用块测试方案的简单渐近性能够有效地找到公平表示，而不需要使用现有公平表示学习方法中广泛使用的复杂对抗性优化或生成建模方案。我们在各种数据集上评估了我们的方法，显示其能够“隐藏”有关敏感属性的信息，并在下游传输任务中的有效性。

    We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between representations of different sensitive groups, while preserving information about the target attributes. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold's complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to ``hide'' information about sensitive attributes, and its effectiveness in downstream transfer tasks.
    
[^24]: 通过超马氏过程推导重尾损失的PAC-Bayes泛化界

    PAC-Bayes Generalisation Bounds for Heavy-Tailed Losses through Supermartingales. (arXiv:2210.00928v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.00928](http://arxiv.org/abs/2210.00928)

    本文为重尾损失情况下的PAC-Bayes提供了泛化界，扩展了先前的研究，并通过马尔科夫不等式的扩展为不同的PAC-Bayesian框架提供了界限。

    

    尽管PAC-Bayes已经成为一种用于轻尾损失（例如亚高斯或亚指数）的学习框架，但其在重尾损失情况下的推广仍然未得到广泛研究，近年来受到越来越多的关注。本文在假定损失函数有界方差的情况下，为重尾损失提供了PAC-Bayes泛化界。在该假设下，我们扩展了\citet{kuzborskij2019efron}的先前结果。我们的关键技术贡献在于利用超马氏过程的马尔科夫不等式的扩展。我们的证明技术通过为无界鞅提供界限，以及为重尾损失的批处理和在线学习提供界限，统一和扩展了不同的PAC-Bayesian框架。

    While PAC-Bayes is now an established learning framework for light-tailed losses (\emph{e.g.}, subgaussian or subexponential), its extension to the case of heavy-tailed losses remains largely uncharted and has attracted a growing interest in recent years. We contribute PAC-Bayes generalisation bounds for heavy-tailed losses under the sole assumption of bounded variance of the loss function. Under that assumption, we extend previous results from \citet{kuzborskij2019efron}. Our key technical contribution is exploiting an extention of Markov's inequality for supermartingales. Our proof technique unifies and extends different PAC-Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for batch and online learning with heavy-tailed losses.
    
[^25]: 某些函数类的Natarajan维数的上界

    Upper bounds on the Natarajan dimensions of some function classes. (arXiv:2209.07015v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.07015](http://arxiv.org/abs/2209.07015)

    本研究建立了一些函数类的Natarajan维度上界，这些结果可以用于描述某些多类学习算法的性能。

    

    Natarajan维度是表征多类PAC可学习性的基本工具，将Vapnik-Chervonenkis（VC）维从二进制分类问题推广到多类分类问题。本研究建立了一些函数类的Natarajan维度上界，包括（i）多类决策树和随机森林，以及（ii）二进制、线性和ReLU激活的多类神经网络。这些结果可能对描述某些多类学习算法的性能有相关性。

    The Natarajan dimension is a fundamental tool for characterizing multi-class PAC learnability, generalizing the Vapnik-Chervonenkis (VC) dimension from binary to multi-class classification problems. This work establishes upper bounds on Natarajan dimensions for certain function classes, including (i) multi-class decision tree and random forests, and (ii) multi-class neural networks with binary, linear and ReLU activations. These results may be relevant for describing the performance of certain multi-class learning algorithms.
    
[^26]: 快速最优无似然推断的神经点估计

    Neural Point Estimation for Fast Optimal Likelihood-Free Inference. (arXiv:2208.12942v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2208.12942](http://arxiv.org/abs/2208.12942)

    本文介绍了一种快速、无需似然函数、易于进行基于自举的不确定性量化的推断工具——神经点估计器，并通过模拟研究和实际案例分析证明其可以在弱识别和高参数化模型中进行快速且最优的参数估计。

    

    神经点估计器是一种将数据映射到参数点估计的神经网络。它们快速、无需似然函数，并且由于它们的平均特性，易于进行基于自举的不确定性量化。本文旨在提高统计学家对于这种相对较新的推断工具的认识，并通过提供用户友好的开源软件来促进其采用。我们还关注了从重复数据进行推断的广泛问题，在神经设置中使用排列不变神经网络来解决这个问题。通过广泛的模拟研究，我们展示了这些神经点估计器可以快速且最优地（从贝叶斯意义上）在弱识别和高参数化模型中进行估计，并且相对容易。我们通过对红海极端海表温度分析来证明它们的适用性，在训练之后，我们获得了参数估计和基于自举的置信区间。

    Neural point estimators are neural networks that map data to parameter point estimates. They are fast, likelihood free and, due to their amortised nature, amenable to fast bootstrap-based uncertainty quantification. In this paper, we aim to increase the awareness of statisticians to this relatively new inferential tool, and to facilitate its adoption by providing user-friendly open-source software. We also give attention to the ubiquitous problem of making inference from replicated data, which we address in the neural setting using permutation-invariant neural networks. Through extensive simulation studies we show that these neural point estimators can quickly and optimally (in a Bayes sense) estimate parameters in weakly-identified and highly-parameterised models with relative ease. We demonstrate their applicability through an analysis of extreme sea-surface temperature in the Red Sea where, after training, we obtain parameter estimates and bootstrap-based confidence intervals from h
    
[^27]: 一种符合保序的风险控制方法

    Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2208.02814](http://arxiv.org/abs/2208.02814)

    该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。

    

    我们将符合性预测推广至控制任何单调损失函数的期望值。该算法将分裂符合性预测及其覆盖保证进行了泛化。类似于符合性预测，符合保序的风险控制方法在$\mathcal{O}(1/n)$因子内保持紧密性。计算机视觉和自然语言处理领域的示例证明了我们算法在控制误报率、图形距离和令牌级F1得分方面的应用。

    We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
    
[^28]: 超越神经尺度定律：通过数据修剪打败幂律尺度

    Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14486](http://arxiv.org/abs/2206.14486)

    本研究通过数据修剪算法突破神经网络训练集大小与模型误差幂律的尺度界限，并在多个数据集实验中验证了有效性，同时进行了首次大规模数据修剪算法基准测试研究。

    

    普遍存在的神经尺度定律以训练集大小、模型规模或两者的幂为模型误差下降的驱动力，为深度学习带来了显著的性能提升。但是，仅通过尺度来实现这些改进需要巨大的计算和能源成本。本文着重研究数据集大小与误差比例的尺度，并展示理论上我们如何突破幂律尺度，并在pruning算法条件下潜在地甚至能将其降至指数尺度。我们接着在CIFAR-10、SVHN和ImageNet的ResNet上进行了实验验证，并观察到实践中优于幂律尺度的表现。此外，鉴于寻找优质pruning算法的重要性，我们对ImageNet上的十种不同的数据修剪算法进行了首次大规模基准测试研究。

    Widely observed neural scaling laws, in which error falls off as a power of the training set size, model size, or both, have driven substantial performance improvements in deep learning. However, these improvements through scaling alone require considerable costs in compute and energy. Here we focus on the scaling of error with dataset size and show how in theory we can break beyond power law scaling and potentially even reduce it to exponential scaling instead if we have access to a high-quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size. We then test this improved scaling prediction with pruned dataset size empirically, and indeed observe better than power law scaling in practice on ResNets trained on CIFAR-10, SVHN, and ImageNet. Next, given the importance of finding high-quality pruning metrics, we perform the first large-scale benchmarking study of ten different data pruning metrics on ImageNet. We fin
    
[^29]: 带约束下凸下层问题的简单双层优化条件梯度方法

    A Conditional Gradient-based Method for Simple Bilevel Optimization with Convex Lower-level Problem. (arXiv:2206.08868v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2206.08868](http://arxiv.org/abs/2206.08868)

    本文提出了一种新的双层优化方法，该方法通过局部逼近下层问题的解集，然后运行条件梯度更新来减少上层目标函数，并且收敛性保证较好。

    

    本文研究一类双层优化问题——简单双层优化，其中我们在另一个凸约束优化问题的最优解集上最小化平滑的目标函数。已经发展出了几种迭代方法来处理这类问题，但它们的收敛性保证要么是上层目标的渐近性，要么是收敛速率缓慢且亚优。为了解决这个问题，本文提出了一种新的双层优化方法，该方法通过切割平面局部逼近下层问题的解集，然后运行条件梯度更新来减少上层目标函数。当上层目标函数为凸函数时，我们证明了我们的方法需要${\mathcal{O}}(\max\{1/\epsilon_f,1/\epsilon_g\})$次迭代才能找到一个对于上层 和下层目标函数同时$\epsilon_f$和$\epsilon_g$最优的解。

    In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane, and then runs a conditional gradient update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${\mathcal{O}}(\max\{1/\epsilon_f,1/\epsilon_g\})$ iterations to find a solution that is $\epsilon_f$-optimal for the upper-level objective and $\epsilon_g$-optimal for the lower-level objective. Moreover,
    
[^30]: 鲁棒PAC$^m$: 在模型规格不准确和存在异常值情况下训练集成模型

    Robust PAC$^m$: Training Ensemble Models Under Model Misspecification and Outliers. (arXiv:2203.01859v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.01859](http://arxiv.org/abs/2203.01859)

    对于存在模型规格不准确和异常值情况下的集成学习，本文提出了一个新的鲁棒自由能量准则，通过将广义对数得分函数与PAC$^m$结合，实现了更好的模型性能。

    

    传统的贝叶斯学习在模型规格不准确和存在异常值的情况下已知存在泛化能力的不足。PAC-Bayes理论证明了贝叶斯学习所最小化的自由能量准则是在假设未被异常值污染的采样分布下，对Gibbs预测器（即从后验随机抽取的单个模型）的泛化误差的一个上界。该观点提供了贝叶斯学习在模型规格不准确且需要集成，以及数据受到异常值影响时的局限性的证明。最近的工作中，推导出了PAC-Bayes上界 - 称为PAC$^m$ - 引入了自由能量度量，可考虑集合预测器的性能，从而获得在模型不准确的情况下提高模型性能。本文提出了一种新的鲁棒自由能量准则，将广义对数得分函数与PAC$^m$集成上界相结合。建议的自由能量训练...（摘要未完，详情请查看原文）

    Standard Bayesian learning is known to have suboptimal generalization capabilities under model misspecification and in the presence of outliers. PAC-Bayes theory demonstrates that the free energy criterion minimized by Bayesian learning is a bound on the generalization error for Gibbs predictors (i.e., for single models drawn at random from the posterior) under the assumption of sampling distributions uncontaminated by outliers. This viewpoint provides a justification for the limitations of Bayesian learning when the model is misspecified, requiring ensembling, and when data is affected by outliers. In recent work, PAC-Bayes bounds - referred to as PAC$^m$ - were derived to introduce free energy metrics that account for the performance of ensemble predictors, obtaining enhanced performance under misspecification. This work presents a novel robust free energy criterion that combines the generalized logarithm score function with PAC$^m$ ensemble bounds. The proposed free energy training 
    
[^31]: 流数据随机逼近算法的非渐进分析

    Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Streaming Data. (arXiv:2109.07117v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.07117](http://arxiv.org/abs/2109.07117)

    该论文介绍了流数据随机逼近算法的非渐近收敛速度，包括随机梯度下降、小批量SG和时间变化的小批量SG算法以及它们的迭代平均值，同时展示了加速收敛的方法和同时提供方差减少和加速收敛的优势。

    

    我们引入了一个流式框架来分析随机逼近/优化问题。这个流式框架类似于使用逐步到达的时间变化的小批次来解决优化问题。我们提供了各种基于梯度的算法的非渐近收敛速度；这包括著名的随机梯度下降（SG）算法（也称为Robbins-Monro算法），小批量SG和时间变化的小批量SG算法，以及它们的迭代平均值（也称为Polyak-Ruppert平均）。我们展示了：i）如何通过根据时间变化的小批次来选择学习速率来加速收敛；ii）Polyak-Ruppert平均值在达到Cramer-Rao下界方面实现了最优收敛；iii）时间变化的小批次与Polyak-Ruppert平均值结合使用可以同时提供方差减少和加速收敛，这对于许多学习问题（如在线，顺序和大规模）都是有利的。

    We introduce a streaming framework for analyzing stochastic approximation/optimization problems. This streaming framework is analogous to solving optimization problems using time-varying mini-batches that arrive sequentially. We provide non-asymptotic convergence rates of various gradient-based algorithms; this includes the famous Stochastic Gradient (SG) descent (a.k.a. Robbins-Monro algorithm), mini-batch SG and time-varying mini-batch SG algorithms, as well as their iterated averages (a.k.a. Polyak-Ruppert averaging). We show i) how to accelerate convergence by choosing the learning rate according to the time-varying mini-batches, ii) that Polyak-Ruppert averaging achieves optimal convergence in terms of attaining the Cramer-Rao lower bound, and iii) how time-varying mini-batches together with Polyak-Ruppert averaging can provide variance reduction and accelerate convergence simultaneously, which is advantageous for many learning problems, such as online, sequential, and large-scale
    
[^32]: 一种深度神经网络中表示学习的理论给出了核方法的深度泛化。

    A theory of representation learning in deep neural networks gives a deep generalisation of kernel methods. (arXiv:2108.13097v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2108.13097](http://arxiv.org/abs/2108.13097)

    本文提出了一种新的无限宽度限制——贝叶斯表示学习限制，旨在解决标准无限宽度限制消除表示学习的问题。该方法可以实现类似于有限宽度模型中的表示学习效果，并保留标准无限宽度限制的简单性。

    

    现代深度机器学习方法的成功基于它们跨多个层次对输入进行变换以建立良好的高级表示能力。因此，理解这种表示学习过程至关重要。然而，常规的理论方法（正式为NNGPs）涉及无限宽限制消除了表示学习。因此，我们开发了一种新的无限宽限制——贝叶斯表示学习限制，它展现了在有限宽度模型中镜像表示学习的效果，同时保留了一些标准无限宽度限制的简单性。特别地，我们表明在贝叶斯表示学习极限下的深层高斯过程（DGPs）具有确切的多元高斯后验分布，后验协方差可以通过优化一种可解释目标得到，该目标结合了增强性能的对数似然和一系列的KL-散度，使得后验分布接近先验分布。

    The successes of modern deep machine learning methods are founded on their ability to transform inputs across multiple layers to build good high-level representations. It is therefore critical to understand this process of representation learning. However, standard theoretical approaches (formally NNGPs) involving infinite width limits eliminate representation learning. We therefore develop a new infinite width limit, the Bayesian representation learning limit, that exhibits representation learning mirroring that in finite-width models, yet at the same time, retains some of the simplicity of standard infinite-width limits. In particular, we show that Deep Gaussian processes (DGPs) in the Bayesian representation learning limit have exactly multivariate Gaussian posteriors, and the posterior covariances can be obtained by optimizing an interpretable objective combining a log-likelihood to improve performance with a series of KL-divergences which keep the posteriors close to the prior. We
    
[^33]: MRCpy：一种用于最小化风险分类器的库

    MRCpy: A Library for Minimax Risk Classifiers. (arXiv:2108.01952v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2108.01952](http://arxiv.org/abs/2108.01952)

    MRCpy是一种用于实现最小化风险分类器的Python库，它基于鲁棒风险最小化技术，可以利用0-1损失并提供了多种分类方法，其中一些提供了紧密的期望损失界限。

    

    目前现有的监督分类库都是基于经验风险最小化和使用代理损失技术的。本文介绍MRCpy库，该库实现了基于鲁棒风险最小化的最小化风险分类器（MRC），并可利用0-1损失。这种技术产生了许多分类方法，可以提供紧密的期望损失界限。MRCpy为不同变量的MRC提供了统一的接口，并遵循流行Python库的标准。此外，MRCpy还提供了实现一些流行技术的功能，这些技术可以看作是MRC，例如L1正则化逻辑回归，0-1对抗性和最大熵机。此外，MRCpy还实现了最近的特征映射，如傅里叶，ReLU和阈值特征。该库采用面向对象的方法设计，方便协作者和用户。

    Existing libraries for supervised classification implement techniques that are based on empirical risk minimization and utilize surrogate losses. We present MRCpy library that implements minimax risk classifiers (MRCs) that are based on robust risk minimization and can utilize 0-1-loss. Such techniques give rise to a manifold of classification methods that can provide tight bounds on the expected loss. MRCpy provides a unified interface for different variants of MRCs and follows the standards of popular Python libraries. The presented library also provides implementation for popular techniques that can be seen as MRCs such as L1-regularized logistic regression, zero-one adversarial, and maximum entropy machines. In addition, MRCpy implements recent feature mappings such as Fourier, ReLU, and threshold features. The library is designed with an object-oriented approach that facilitates collaborators and users.
    
[^34]: GMM的鲁棒模型选择和近似正确学习

    Robust Model Selection and Nearly-Proper Learning for GMMs. (arXiv:2106.02774v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2106.02774](http://arxiv.org/abs/2106.02774)

    本文研究了一元高斯混合模型（GMMs）鲁棒模型选择的问题，提出了一个鲁棒算法，可以在对抗性扰动下近似正确地学习GMMs，实现了最佳样本复杂度，能够近似确定拟合分布所需的最少组件数。

    

    在学习理论中，通常假定数据是从有限混合模型生成的。但是如果事先不知道组分数会发生什么呢？估计组分数的问题，在本身上是很重要的，但实际上就算是没有有效算法，更不用说能容忍对抗性扰动了。本文研究了一元高斯混合模型（GMMs）鲁棒模型选择的问题。我们会从一个与$k$个组分的GMM $\epsilon$ -close的分布中产生$\textsf{poly}(k / \epsilon)$个样本，用$\textsf{poly}(k / \epsilon)$时间构建一个有$\widetilde{O}(k)$个组件的GMM，可在$\widetilde {O} (\epsilon)$内近似表示分布。因此，我们能够近似确定拟合分布所需的最少组件数。在本研究之前，唯一已知的有效算法需要至少 $O(k \log \log n)$ 个组件才能完成此任务，这已近乎达到了极限。此外，我们还证明了我们的算法几乎是正确的，即，其具有最优的样本复杂度，仅具有对数因子。最后，我们证明了我们的结果使得我们能够在对抗扰动下鲁棒地学习GMMs。

    In learning theory, a standard assumption is that the data is generated from a finite mixture model. But what happens when the number of components is not known in advance? The problem of estimating the number of components, also called model selection, is important in its own right but there are essentially no known efficient algorithms with provable guarantees let alone ones that can tolerate adversarial corruptions. In this work, we study the problem of robust model selection for univariate Gaussian mixture models (GMMs). Given $\textsf{poly}(k/\epsilon)$ samples from a distribution that is $\epsilon$-close in TV distance to a GMM with $k$ components, we can construct a GMM with $\widetilde{O}(k)$ components that approximates the distribution to within $\widetilde{O}(\epsilon)$ in $\textsf{poly}(k/\epsilon)$ time. Thus we are able to approximately determine the minimum number of components needed to fit the distribution within a logarithmic factor. Prior to our work, the only known 
    
[^35]: 拟合的生存分析

    Conformalized Survival Analysis. (arXiv:2103.09763v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2103.09763](http://arxiv.org/abs/2103.09763)

    本文提出了一种基于拟合预测思想的推论方法，可以产生校准、基于协变量的生存时间的下界预测，不依赖强大的建模假设，可有效避免模型错误。

    

    现有的生存分析技术往往依赖于强大的建模假设，因此容易出现模型错误。本文提出了一种基于拟合预测思想的推论方法，该方法可以包裹任何生存预测算法，产生校准、基于协变量的生存时间的下界预测。在类型I右截尾设定下，当剪除时间是完全外生的时，这些下界预测在有限样本中具有保证的覆盖率，除了独立同分布的数据点这一假设外，无需任何其他假设。在更一般的条件独立剪除假设下，如果剪除机制或条件生存函数估计良好，则边际覆盖率将近乎保证。此外，我们证明当生存预测算法被错误地规定时，这些下界预测仍然有效且信息丰富。通过模拟实验和医学真实数据集的分析，我们证明了这种方法的实用性。

    Existing survival analysis techniques heavily rely on strong modelling assumptions and are, therefore, prone to model misspecification errors. In this paper, we develop an inferential method based on ideas from conformal prediction, which can wrap around any survival prediction algorithm to produce calibrated, covariate-dependent lower predictive bounds on survival times. In the Type I right-censoring setting, when the censoring times are completely exogenous, the lower predictive bounds have guaranteed coverage in finite samples without any assumptions other than that of operating on independent and identically distributed data points. Under a more general conditionally independent censoring assumption, the bounds satisfy a doubly robust property which states the following: marginal coverage is approximately guaranteed if either the censoring mechanism or the conditional survival function is estimated well. Further, we demonstrate that the lower predictive bounds remain valid and info
    
[^36]: IMAE用于噪声鲁棒学习：绝对值误差不平等对待示例，梯度大小的方差很重要。

    IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters. (arXiv:1903.12141v10 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1903.12141](http://arxiv.org/abs/1903.12141)

    本文提出IMAE模型用于畸形训练数据的鲁棒深度学习，通过实践证实平均绝对误差（MAE）在处理示例时存在欠拟合问题，利用加权方差调整提高了拟合能力，同时保持了鲁棒性。

    

    本文研究了从示例加权角度，即与对数的梯度大小来看待畸形训练数据的鲁棒深度学习。我们有两个关键发现：（1）平均绝对误差（MAE）不平等地处理示例。我们针对MAE进行了新的观察和深入分析，理论证明其鲁棒性。首先，我们揭示了其在实践中的欠拟合问题。其次，我们分析了MAE的鲁棒性是通过强调不确定示例而不是像前人研究中所声称的那样对待训练样本来实现的。（2）梯度大小的方差很重要。我们提出了一种有效而简单的解决方案，以增强MAE的拟合能力，同时保持其鲁棒性。在不改变MAE的整体加权方案（即哪些示例获得更高的权重）的情况下，我们仅通过非线性地改变其加权方差来实现这一点。

    In this work, we study robust deep learning against abnormal training data from the perspective of example weighting built in empirical loss functions, i.e., gradient magnitude with respect to logits, an angle that is not thoroughly studied so far. Consequently, we have two key findings: (1) Mean Absolute Error (MAE) Does Not Treat Examples Equally. We present new observations and insightful analysis about MAE, which is theoretically proved to be noise-robust. First, we reveal its underfitting problem in practice. Second, we analyse that MAE's noise-robustness is from emphasising on uncertain examples instead of treating training samples equally, as claimed in prior work. (2) The Variance of Gradient Magnitude Matters. We propose an effective and simple solution to enhance MAE's fitting ability while preserving its noise-robustness. Without changing MAE's overall weighting scheme, i.e., what examples get higher weights, we simply change its weighting variance non-linearly so that the i
    
[^37]: 模拟器：理解在中等置信度条件下的自适应采样

    The Simulator: Understanding Adaptive Sampling in the Moderate-Confidence Regime. (arXiv:1702.05186v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1702.05186](http://arxiv.org/abs/1702.05186)

    提出一种名为模拟器的新技术用于分析自适应采样。将重点放在了区分好的采样策略和坏采样策略的难度上。在纯探索场景的结构化多臂赌博问题中应用了该技术，展示了有中等置信度的样本复杂度和文献中在 $\delta \to 0$ 时得到的渐近复杂度之间存在着实质性差异，并且还证明了作为顶部-k问题的第一个基于实例的下界。

    

    我们提出了一种新的技术，称为“模拟器”，用于分析自适应采样。我们的方法与现有方法不同，它不考虑任何固定采样策略可以收集多少信息，而是考虑在给定的有限数据收集时间内，区分好的采样策略和坏的采样策略有多难。这种视角的改变使我们能够匹配Fano和变量测量技术的优点，而不会陷入任何一种方法的局限性中。为了具体说明，我们将我们的技术应用到了一个固定置信水平的纯探索场景中的结构化多臂赌博问题，我们展示了在均值限制下，有中等置信度的样本复杂度和文献中在 $\delta \to 0$ 时得到的渐近复杂度之间存在着实质性差异。我们还证明了作为顶部-k问题的第一个基于实例的下界，其包括适当的对数因子。

    We propose a novel technique for analyzing adaptive sampling called the {\em Simulator}. Our approach differs from the existing methods by considering not how much information could be gathered by any fixed sampling strategy, but how difficult it is to distinguish a good sampling strategy from a bad one given the limited amount of data collected up to any given time. This change of perspective allows us to match the strength of both Fano and change-of-measure techniques, without succumbing to the limitations of either method. For concreteness, we apply our techniques to a structured multi-arm bandit problem in the fixed-confidence pure exploration setting, where we show that the constraints on the means imply a substantial gap between the moderate-confidence sample complexity, and the asymptotic sample complexity as $\delta \to 0$ found in the literature. We also prove the first instance-based lower bounds for the top-k problem which incorporate the appropriate log-factors. Moreover, o
    

