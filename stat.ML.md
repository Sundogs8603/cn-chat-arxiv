# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Combining predictive distributions of electricity prices: Does minimizing the CRPS lead to optimal decisions in day-ahead bidding?.](http://arxiv.org/abs/2308.15443) | 这篇论文研究了在电力交易中使用概率价格预测和结合预测分布的技术。通过实证研究发现，增加集合的多样性可以提高准确性，但使用最小化CRPS的权重技术并不能带来更高的利润。 |
| [^2] | [Random feature approximation for general spectral methods.](http://arxiv.org/abs/2308.15434) | 本论文研究了随机特征逼近在一般谱方法中的应用，分析了与随机特征相结合的谱正则化方法的泛化性质，并获得了在不同正则性类别中的最佳学习速率。 |
| [^3] | [Multi-Response Heteroscedastic Gaussian Process Models and Their Inference.](http://arxiv.org/abs/2308.15370) | 本文介绍了多响应异方差高斯过程模型，将其应用于回归、分类和状态空间模型，并提出了一种利用变分推断来近似后验的方法，解决了高斯过程模型在捕捉函数平滑性的突变和适应异方差错误方面的局限性。 |
| [^4] | [Heterogeneous Multi-Task Gaussian Cox Processes.](http://arxiv.org/abs/2308.15364) | 本文提出了一种用于联合建模多个异构相关任务的扩展方法，通过多输出高斯过程（MOGP）促进任务之间的信息共享和非参数参数估计，并应用数据增广技术来解决非共轭贝叶斯推断问题。 |
| [^5] | [Towards quantitative precision for ECG analysis: Leveraging state space models, self-supervision and patient metadata.](http://arxiv.org/abs/2308.15291) | 这项研究利用状态空间模型(SSMs)和自监督学习来改善深度学习模型在自动心电图分析中的定量准确性。结果表明，使用SSMs可以捕捉时间序列数据中的长期依赖关系，并且在标准诊断任务中，较高的采样率和扩大输入尺寸并没有明显的改进效果。 |
| [^6] | [Small Area Estimation with Random Forests and the LASSO.](http://arxiv.org/abs/2308.15180) | 本论文研究了基于随机森林和LASSO的小区域估计方法，在只有部分区域有采样数据的情况下利用辅助变量对结果进行预测。通过比较不同方法的效果，并提出了一种修改的拆分合规程序，放宽了数据分布的假设。该研究以加纳的数据为例，估计了家庭消费的均值。 |
| [^7] | [Group-Conditional Conformal Prediction via Quantile Regression Calibration for Crop and Weed Classification.](http://arxiv.org/abs/2308.15094) | 通过分位数回归校准实现基于群体条件的符合预测框架，解决了深度学习预测模型的不确定性问题，并应用于实际农业计算机视觉中的作物与杂草分类问题。 |
| [^8] | [Inferences on Mixing Probabilities and Ranking in Mixed-Membership Models.](http://arxiv.org/abs/2308.14988) | 本文利用度校正混合成员模型(DCMM)来建模网络，推导了成员混合概率的有限样本扩展，填补了关于成员配置的不确定性量化方面的重要空白。同时，还开发了一个基于成员混合概率的顶点排名方案。 |
| [^9] | [Noise-Free Sampling Algorithms via Regularized Wasserstein Proximals.](http://arxiv.org/abs/2308.14945) | 本文通过正则化Wasserstein Proximal方法提出了一种无噪声的抽样算法，通过给定的潜势函数确定性地进行粒子演化，并提供了优于传统方法的维度依赖性和速度收敛性能。 |
| [^10] | [BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition.](http://arxiv.org/abs/2308.14906) | BayOTIDE是一种基于贝叶斯方法的在线多元时间序列插补与函数分解模型，通过将多元时间序列视为低秩时序因子组的加权组合来进行插补，同时解决了全局趋势和周期性模式的忽略以及不规则采样时间序列的处理问题。 |
| [^11] | [NAS-X: Neural Adaptive Smoothing via Twisting.](http://arxiv.org/abs/2308.14864) | NAS-X是一种基于扭曲的神经自适应平滑方法，通过重新加权的唤醒-睡眠算法来学习和推断顺序潜变量模型，并在离散和连续任务中取得了优于先前方法的推断和参数恢复效果。 |
| [^12] | [A correlation-based fuzzy cluster validity index with secondary options detector.](http://arxiv.org/abs/2308.14785) | 本研究提出了一种基于相关性的模糊聚类有效性指标，该指标考虑了在聚类数量选择时可能存在的多个选项，并通过评估在多种数据集上的性能，与现有指标进行比较。 |
| [^13] | [Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering.](http://arxiv.org/abs/2308.06399) | 本研究介绍了一种将混合效应模型和层次聚类应用于贝叶斯网络学习的新方法，在农学研究中广泛应用。通过整合随机效应，该方法可以提高贝叶斯网络的结构学习能力，实现因果关系网络的发现。 |
| [^14] | [Trajectory Poisson multi-Bernoulli mixture filter for traffic monitoring using a drone.](http://arxiv.org/abs/2306.16890) | 本文提出了一种使用无人机进行交通监测的多目标跟踪算法。该算法利用光学和热感摄像头获取图像上的物体检测，并使用轨迹泊松多伯努利混合滤波器来估计车辆的轨迹。实验证明，该算法在合成和实验数据集中具有较高的准确性。 |
| [^15] | [On Optimal Caching and Model Multiplexing for Large Model Inference.](http://arxiv.org/abs/2306.02003) | 本文提出了最优缓存与模型复用两种方法来缓解大型模型推理中资源消耗和延迟挑战，经过实证模拟发现这种组合大大提高了传统模型推理方法的性能。 |
| [^16] | [Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting.](http://arxiv.org/abs/2305.15786) | 本文研究了学习集合策略在时间序列预测中的应用，证明了在有限或有限维叠加泛化模型中选择基于交叉验证性能的最优叠加泛化与最优解性能相近。 |
| [^17] | [Generalized partitioned local depth.](http://arxiv.org/abs/2303.10167) | 本文提出了一个广义的凝聚概念，构建在分区局部深度的技术基础上，扩展了早期结果并应用于具有不确定性的数据的社区发现中。 |
| [^18] | [Cyclic and Randomized Stepsizes Invoke Heavier Tails in SGD than Constant Stepsize.](http://arxiv.org/abs/2302.05516) | 本文研究了深度学习中的随机步长和循环步长相对于常数步长的优势，通过考虑尾部指数如何随步长调度的变化而变化来推动理论研究，进一步揭示了它们对于泛化性能的改善机制。 |
| [^19] | [Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio.](http://arxiv.org/abs/2209.04512) | 本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的方法不仅适用于金融市场典型的低信噪比环境，还与弱因子兼容，并且通过理论分析建立了统一的界限，同时提供了基于数据的一致误差协方差估计方法。模拟和实证结果显示我们的模型具有卓越的准确性。 |
| [^20] | [On the Existence of the Adversarial Bayes Classifier (Extended Version).](http://arxiv.org/abs/2112.01694) | 本篇论文研究了对抗训练健壮性下Bayes最优分类器的存在性问题，提出了一般性的充分条件，并可以为研究对抗性代理损失和其一致性属性提供有用的工具。 |
| [^21] | [Combinatorial Pure Exploration with Full-bandit Feedback and Beyond: Solving Combinatorial Optimization under Uncertainty with Limited Observation.](http://arxiv.org/abs/2012.15584) | 该论文研究了在组合优化问题中，当输入参数不确定或最初未知时，通过全带回馈的组合纯探索（CPE）来解决该不确定性的问题。以往的研究主要关注半赌博机反馈或假设每个边的结果始终可以访问，而这篇论文考虑了强反馈信息不一定可用的实际约束。 |
| [^22] | [Bayesian Feature Selection in Joint Quantile Time Series Analysis.](http://arxiv.org/abs/2010.01654) | 本文提出了一种贝叶斯特征选择方法，用于高维联合分位数时间序列分析。模型具有灵活性，可以根据每个时间序列的需要进行特征的选择，并且允许进行即时预测。 |
| [^23] | [Second-order Conditional Gradient Sliding.](http://arxiv.org/abs/2002.08907) | 提出了一种二阶条件梯度滑动（SOCGS）算法，可以高效解决约束二次凸优化问题，并在有限次线性收敛迭代后二次收敛于原始间隙。 |
| [^24] | [Semi-supervised Vector-valued Learning: Improved Bounds and Algorithms.](http://arxiv.org/abs/1909.04883) | 该论文提出了一种针对半监督矢量值学习的改进算法，通过利用局部Rademacher复杂度和无标签数据，得出了更精确的超出风险界限。实验结果表明，该算法在多个领域中明显优于其他方法。 |

# 详细

[^1]: 结合电价的预测分布：最小化CRPS是否在提前竞标中导致最佳决策？

    Combining predictive distributions of electricity prices: Does minimizing the CRPS lead to optimal decisions in day-ahead bidding?. (arXiv:2308.15443v1 [q-fin.ST])

    [http://arxiv.org/abs/2308.15443](http://arxiv.org/abs/2308.15443)

    这篇论文研究了在电力交易中使用概率价格预测和结合预测分布的技术。通过实证研究发现，增加集合的多样性可以提高准确性，但使用最小化CRPS的权重技术并不能带来更高的利润。

    

    近年来，基于概率的价格预测在电力交易中引起了关注，因为基于这种预测的决策可以比仅仅基于点预测获得显著更高的利润。与此同时，正在开发方法来结合预测分布，因为没有一个模型是完美的，平均通常可以改善预测性能。在本文中，我们探讨了使用CRPS学习的权重技术（最小化连续排名概率评分）是否在提前竞标中导致最佳决策。为此，我们进行了一项实证研究，使用了来自德国EPEX市场的小时级提前电力价格。我们发现，增加集合的多样性可以对准确性产生积极影响。与此同时，与等权重聚合分布相比，使用CRPS学习的较高计算成本不能通过更高的利润来抵消，尽管预测更准确。

    Probabilistic price forecasting has recently gained attention in power trading because decisions based on such predictions can yield significantly higher profits than those made with point forecasts alone. At the same time, methods are being developed to combine predictive distributions, since no model is perfect and averaging generally improves forecasting performance. In this article we address the question of whether using CRPS learning, a novel weighting technique minimizing the continuous ranked probability score (CRPS), leads to optimal decisions in day-ahead bidding. To this end, we conduct an empirical study using hourly day-ahead electricity prices from the German EPEX market. We find that increasing the diversity of an ensemble can have a positive impact on accuracy. At the same time, the higher computational cost of using CRPS learning compared to an equal-weighted aggregation of distributions is not offset by higher profits, despite significantly more accurate predictions.
    
[^2]: 针对一般谱方法的随机特征逼近

    Random feature approximation for general spectral methods. (arXiv:2308.15434v1 [cs.LG])

    [http://arxiv.org/abs/2308.15434](http://arxiv.org/abs/2308.15434)

    本论文研究了随机特征逼近在一般谱方法中的应用，分析了与随机特征相结合的谱正则化方法的泛化性质，并获得了在不同正则性类别中的最佳学习速率。

    

    随机特征逼近被认为是在大规模算法中加速核方法的最流行技术之一，并且为深度神经网络的分析提供了一种理论方法。我们分析了与随机特征相结合的一大类谱正则化方法的泛化性质，其中包括使用隐式正则化（如梯度下降）或显式方法（如Tikhonov正则化）的核方法。对于我们的估计器，我们在适当的源条件下定义了正则性类别，从而获得了最佳的学习速率。这改进或完善了以前在特定核算法相关设置中获得的结果。

    Random feature approximation is arguably one of the most popular techniques to speed up kernel methods in large scale algorithms and provides a theoretical approach to the analysis of deep neural networks. We analyze generalization properties for a large class of spectral regularization methods combined with random features, containing kernel methods with implicit regularization such as gradient descent or explicit methods like Tikhonov regularization. For our estimators we obtain optimal learning rates over regularity classes (even for classes that are not included in the reproducing kernel Hilbert space), which are defined through appropriate source conditions. This improves or completes previous results obtained in related settings for specific kernel algorithms.
    
[^3]: 多响应异方差高斯过程模型及其推断

    Multi-Response Heteroscedastic Gaussian Process Models and Their Inference. (arXiv:2308.15370v1 [stat.ML])

    [http://arxiv.org/abs/2308.15370](http://arxiv.org/abs/2308.15370)

    本文介绍了多响应异方差高斯过程模型，将其应用于回归、分类和状态空间模型，并提出了一种利用变分推断来近似后验的方法，解决了高斯过程模型在捕捉函数平滑性的突变和适应异方差错误方面的局限性。

    

    尽管高斯过程模型被广泛用于灵活的非参数建模，但它们在有效捕捉函数平滑性的突变和适应异方差错误方面存在局限性。为了解决这些问题，异方差高斯过程（HeGP）回归旨在通过承认回归模型中协变量间残差方差的可变性来引入灵活性。本文将HeGP概念扩展到分类和状态空间模型，并提出了一种新的框架，将高斯过程与协变量诱导的精度矩阵过程相结合，采用混合形式。这种方法使得可以对协变量之间的异方差协方差函数进行建模。为了解决采样带来的计算挑战，我们采用变分推断来近似后验并便利计算。

    Despite the widespread utilization of Gaussian process models for versatile nonparametric modeling, they exhibit limitations in effectively capturing abrupt changes in function smoothness and accommodating relationships with heteroscedastic errors. Addressing these shortcomings, the heteroscedastic Gaussian process (HeGP) regression seeks to introduce flexibility by acknowledging the variability of residual variances across covariates in the regression model. In this work, we extend the HeGP concept, expanding its scope beyond regression tasks to encompass classification and state-space models. To achieve this, we propose a novel framework where the Gaussian process is coupled with a covariate-induced precision matrix process, adopting a mixture formulation. This approach enables the modeling of heteroscedastic covariance functions across covariates. To mitigate the computational challenges posed by sampling, we employ variational inference to approximate the posterior and facilitate p
    
[^4]: 异构多任务高斯Cox过程

    Heterogeneous Multi-Task Gaussian Cox Processes. (arXiv:2308.15364v1 [cs.LG])

    [http://arxiv.org/abs/2308.15364](http://arxiv.org/abs/2308.15364)

    本文提出了一种用于联合建模多个异构相关任务的扩展方法，通过多输出高斯过程（MOGP）促进任务之间的信息共享和非参数参数估计，并应用数据增广技术来解决非共轭贝叶斯推断问题。

    

    本文提出了一种新颖的多任务高斯Cox过程的扩展，用于联合建模多个异构相关任务，例如分类和回归，通过多输出高斯过程（MOGP）。通过对分类、回归和点过程任务的专用似然参数引入MOGP先验，可以促进异构任务之间的信息共享，同时允许非参数参数估计。为了克服MOGP调制的异构多任务框架中的非共轭贝叶斯推断问题，我们采用数据增广技术，并导出均场近似来实现对模型参数的闭式迭代更新。我们在1D合成数据和温哥华的2D城市数据上展示了性能和推断。

    This paper presents a novel extension of multi-task Gaussian Cox processes for modeling multiple heterogeneous correlated tasks jointly, e.g., classification and regression, via multi-output Gaussian processes (MOGP). A MOGP prior over the parameters of the dedicated likelihoods for classification, regression and point process tasks can facilitate sharing of information between heterogeneous tasks, while allowing for nonparametric parameter estimation. To circumvent the non-conjugate Bayesian inference in the MOGP modulated heterogeneous multi-task framework, we employ the data augmentation technique and derive a mean-field approximation to realize closed-form iterative updates for estimating model parameters. We demonstrate the performance and inference on both 1D synthetic data as well as 2D urban data of Vancouver.
    
[^5]: 迈向心电图分析的定量精确性：利用状态空间模型、自监督学习和患者元数据

    Towards quantitative precision for ECG analysis: Leveraging state space models, self-supervision and patient metadata. (arXiv:2308.15291v1 [eess.SP])

    [http://arxiv.org/abs/2308.15291](http://arxiv.org/abs/2308.15291)

    这项研究利用状态空间模型(SSMs)和自监督学习来改善深度学习模型在自动心电图分析中的定量准确性。结果表明，使用SSMs可以捕捉时间序列数据中的长期依赖关系，并且在标准诊断任务中，较高的采样率和扩大输入尺寸并没有明显的改进效果。

    

    深度学习已成为自动心电图分析的首选建模方法。本研究探讨了三个旨在提高这种系统定量准确性的要素。这些组件始终超越了基于卷积模型的现有最先进技术，并通过利用结构化状态空间模型(SSMs)来提高性能。这些模型在捕捉时间序列数据中的长期依赖方面显示了很大的潜力。通过将SSMs纳入我们的方法中，我们不仅实现了更好的性能，还对该领域的长期相关问题有了更深的理解。具体而言，对于标准诊断任务，我们发现与100Hz相比，使用500Hz等更高采样率没有优势。类似地，将模型的输入尺寸扩大到3秒以上也没有带来显著的改进。其次，我们证明了使用对比预测的自监督学习能够增强模型的性能，这是第二个要素。

    Deep learning has emerged as the preferred modeling approach for automatic ECG analysis. In this study, we investigate three elements aimed at improving the quantitative accuracy of such systems. These components consistently enhance performance beyond the existing state-of-the-art, which is predominantly based on convolutional models. Firstly, we explore more expressive architectures by exploiting structured state space models (SSMs). These models have shown promise in capturing long-term dependencies in time series data. By incorporating SSMs into our approach, we not only achieve better performance, but also gain insights into long-standing questions in the field. Specifically, for standard diagnostic tasks, we find no advantage in using higher sampling rates such as 500Hz compared to 100Hz. Similarly, extending the input size of the model beyond 3 seconds does not lead to significant improvements. Secondly, we demonstrate that self-supervised learning using contrastive predictive c
    
[^6]: 基于随机森林和LASSO的小区域估计

    Small Area Estimation with Random Forests and the LASSO. (arXiv:2308.15180v1 [stat.ME])

    [http://arxiv.org/abs/2308.15180](http://arxiv.org/abs/2308.15180)

    本论文研究了基于随机森林和LASSO的小区域估计方法，在只有部分区域有采样数据的情况下利用辅助变量对结果进行预测。通过比较不同方法的效果，并提出了一种修改的拆分合规程序，放宽了数据分布的假设。该研究以加纳的数据为例，估计了家庭消费的均值。

    

    在需要估计的总区域中，仅有部分区域具有采样数据，我们考虑使用随机森林和LASSO方法进行基于模型的小区域估计。采样区域有大量的辅助信息来自调查，而所有区域都有来自外部来源的辅助信息，并且目标是使用辅助变量来预测感兴趣的结果。我们比较了区域级别的随机森林和LASSO方法与频率主义的前向变量选择方法和贝叶斯收缩方法。此外，为了衡量从随机森林和LASSO获得的估计的不确定性，我们提出了一种修改的拆分合规程序，放宽了数据相同分布的假设。这项工作受到了来自加纳第六次生活标准调查（GLSS）和2010年人口和住房普查的数据的启发。我们使用这两个数据集估计了区域的家庭对数消费的均值。

    We consider random forests and LASSO methods for model-based small area estimation when the number of areas with sampled data is a small fraction of the total areas for which estimates are required. Abundant auxiliary information is available for the sampled areas, from the survey, and for all areas, from an exterior source, and the goal is to use auxiliary variables to predict the outcome of interest. We compare areal-level random forests and LASSO approaches to a frequentist forward variable selection approach and a Bayesian shrinkage method. Further, to measure the uncertainty of estimates obtained from random forests and the LASSO, we propose a modification of the split conformal procedure that relaxes the assumption of identically distributed data. This work is motivated by Ghanaian data available from the sixth Living Standard Survey (GLSS) and the 2010 Population and Housing Census. We estimate the areal mean household log consumption using both datasets. The outcome variable is
    
[^7]: 通过分位数回归校准实现基于群体条件的符合预测，用于作物与杂草分类

    Group-Conditional Conformal Prediction via Quantile Regression Calibration for Crop and Weed Classification. (arXiv:2308.15094v1 [cs.CV])

    [http://arxiv.org/abs/2308.15094](http://arxiv.org/abs/2308.15094)

    通过分位数回归校准实现基于群体条件的符合预测框架，解决了深度学习预测模型的不确定性问题，并应用于实际农业计算机视觉中的作物与杂草分类问题。

    

    随着深度学习预测模型成为精准农业系统中不可或缺的一部分，一个阻碍采用这些自动化解决方案的障碍是用户对这些高度复杂、不透明和不确定的模型缺乏信任。实际上，深度神经网络没有任何明确的保证，可以用来证明系统的性能，在高度变化的以及无法控制的环境中，比如典型的农业计算机视觉中所面临的环境。幸运的是，其他领域开发的某些方法对农业应用非常重要。本文提出了符合预测框架，该框架对任何黑盒子预测机器的预测性能提供有效的统计保证，几乎不需要任何假设，应用于实际条件下的深度可视化杂草和作物分类问题。本文重点介绍了框架的实际方面，并特别注意了细节。

    As deep learning predictive models become an integral part of a large spectrum of precision agricultural systems, a barrier to the adoption of such automated solutions is the lack of user trust in these highly complex, opaque and uncertain models. Indeed, deep neural networks are not equipped with any explicit guarantees that can be used to certify the system's performance, especially in highly varying uncontrolled environments such as the ones typically faced in computer vision for agriculture.Fortunately, certain methods developed in other communities can prove to be important for agricultural applications. This article presents the conformal prediction framework that provides valid statistical guarantees on the predictive performance of any black box prediction machine, with almost no assumptions, applied to the problem of deep visual classification of weeds and crops in real-world conditions. The framework is exposed with a focus on its practical aspects and special attention accor
    
[^8]: 关于混合成员模型中混合概率和排名的推断

    Inferences on Mixing Probabilities and Ranking in Mixed-Membership Models. (arXiv:2308.14988v1 [math.ST])

    [http://arxiv.org/abs/2308.14988](http://arxiv.org/abs/2308.14988)

    本文利用度校正混合成员模型(DCMM)来建模网络，推导了成员混合概率的有限样本扩展，填补了关于成员配置的不确定性量化方面的重要空白。同时，还开发了一个基于成员混合概率的顶点排名方案。

    

    网络数据在许多大数据应用中非常常见，包括经济和健康网络，了解网络的潜在结构非常重要。本文使用度校正混合成员模型(DCMM)来建模网络。在DCMM模型中，对于每个节点$i$，存在一个成员向量$\boldsymbol{\pi}_ i = (\boldsymbol{\pi}_i(1), \boldsymbol{\pi}_i(2),\ldots, \boldsymbol{\pi}_i(K))$，其中$\boldsymbol{\pi}_i(k)$表示节点$i$在社区$k$中的权重。我们推导了关于$\boldsymbol{\pi}_i(k)$的新颖的有限样本扩展，从而使我们能够获得成员混合概率和其他相关总体数量的渐近分布和置信区间。这填补了关于成员配置的不确定性量化方面的重要空白。我们进一步基于特定社区中的成员混合概率开发了一个顶点排名方案，并进行相关统计推断。

    Network data is prevalent in numerous big data applications including economics and health networks where it is of prime importance to understand the latent structure of network. In this paper, we model the network using the Degree-Corrected Mixed Membership (DCMM) model. In DCMM model, for each node $i$, there exists a membership vector $\boldsymbol{\pi}_ i = (\boldsymbol{\pi}_i(1), \boldsymbol{\pi}_i(2),\ldots, \boldsymbol{\pi}_i(K))$, where $\boldsymbol{\pi}_i(k)$ denotes the weight that node $i$ puts in community $k$. We derive novel finite-sample expansion for the $\boldsymbol{\pi}_i(k)$s which allows us to obtain asymptotic distributions and confidence interval of the membership mixing probabilities and other related population quantities. This fills an important gap on uncertainty quantification on the membership profile. We further develop a ranking scheme of the vertices based on the membership mixing probabilities on certain communities and perform relevant statistical infere
    
[^9]: 通过正则化Wasserstein Proximals实现无噪声的抽样算法

    Noise-Free Sampling Algorithms via Regularized Wasserstein Proximals. (arXiv:2308.14945v1 [stat.ML])

    [http://arxiv.org/abs/2308.14945](http://arxiv.org/abs/2308.14945)

    本文通过正则化Wasserstein Proximal方法提出了一种无噪声的抽样算法，通过给定的潜势函数确定性地进行粒子演化，并提供了优于传统方法的维度依赖性和速度收敛性能。

    

    本文考虑由潜势函数控制的分布抽样问题。本文提出了一种显式的基于评分的确定性马尔科夫链蒙特卡洛方法，使得粒子的演化变为确定性的，而不是随机微分方程的演化。评分项由正则化的Wasserstein proximal以闭合形式给出，使用采样来近似核卷积。我们在不同问题上展示了快速收敛，并且与未调整Langevin算法和Metropolis调整Langevin算法相比，显示了高斯分布的混合时间边界的改善维度依赖性。我们还推导了二次潜势函数每次迭代的分布的闭合形式表达式，表征了方差降低。实证结果表明，粒子的行为是有组织的，位于潜势的等值线上。此外，后验均值估计结果显示了该方法的有效性。

    We consider the problem of sampling from a distribution governed by a potential function. This work proposes an explicit score-based MCMC method that is deterministic, resulting in a deterministic evolution for particles rather than a stochastic differential equation evolution. The score term is given in closed form by a regularized Wasserstein proximal, using a kernel convolution that is approximated by sampling. We demonstrate fast convergence on various problems and show improved dimensional dependence of mixing time bounds for the case of Gaussian distributions compared to the unadjusted Langevin algorithm (ULA) and the Metropolis-adjusted Langevin algorithm (MALA). We additionally derive closed form expressions for the distributions at each iterate for quadratic potential functions, characterizing the variance reduction. Empirical results demonstrate that the particles behave in an organized manner, lying on level set contours of the potential. Moreover, the posterior mean estimat
    
[^10]: BayOTIDE: 基于贝叶斯方法的在线多元时间序列插补与函数分解

    BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition. (arXiv:2308.14906v1 [cs.LG])

    [http://arxiv.org/abs/2308.14906](http://arxiv.org/abs/2308.14906)

    BayOTIDE是一种基于贝叶斯方法的在线多元时间序列插补与函数分解模型，通过将多元时间序列视为低秩时序因子组的加权组合来进行插补，同时解决了全局趋势和周期性模式的忽略以及不规则采样时间序列的处理问题。

    

    在真实世界的场景中，如交通和能源，经常观察到具有缺失值和噪声的大规模时间序列数据，甚至是不规则采样。尽管已经提出了许多插补方法，但它们大多数只适用于局部视角，即将长序列拆分为适当大小的批次进行训练。这种局部视角可能使模型忽略全局趋势或周期性模式。更重要的是，几乎所有方法都假设观测值在规则的时间间隔进行采样，并且无法处理来自不同应用的复杂不规则采样时间序列。此外，大多数现有方法都是在离线状态下进行学习的。因此，对于那些有快速到达的流数据的应用来说，它们并不合适。为了克服这些局限性，我们提出了BayOTIDE：基于贝叶斯方法的在线多元时间序列插补与函数分解。

    In real-world scenarios like traffic and energy, massive time-series data with missing values and noises are widely observed, even sampled irregularly. While many imputation methods have been proposed, most of them work with a local horizon, which means models are trained by splitting the long sequence into batches of fit-sized patches. This local horizon can make models ignore global trends or periodic patterns. More importantly, almost all methods assume the observations are sampled at regular time stamps, and fail to handle complex irregular sampled time series arising from different applications. Thirdly, most existing methods are learned in an offline manner. Thus, it is not suitable for many applications with fast-arriving streaming data. To overcome these limitations, we propose \ours: Bayesian Online Multivariate Time series Imputation with functional decomposition. We treat the multivariate time series as the weighted combination of groups of low-rank temporal factors with dif
    
[^11]: NAS-X: 基于扭曲的神经自适应平滑方法

    NAS-X: Neural Adaptive Smoothing via Twisting. (arXiv:2308.14864v1 [cs.LG])

    [http://arxiv.org/abs/2308.14864](http://arxiv.org/abs/2308.14864)

    NAS-X是一种基于扭曲的神经自适应平滑方法，通过重新加权的唤醒-睡眠算法来学习和推断顺序潜变量模型，并在离散和连续任务中取得了优于先前方法的推断和参数恢复效果。

    

    本文提出了一种名为NAS-X的神经自适应平滑方法，该方法基于重新加权的唤醒-睡眠算法进行顺序潜变量模型的学习和推断。NAS-X适用于离散和连续潜变量，并利用平滑SMC方法来拟合比传统的重新加权唤醒-睡眠方法更广泛的模型。我们在离散和连续任务上测试了NAS-X，并发现在推断和参数恢复方面，它明显优于先前的变分和基于重新加权唤醒-睡眠方法。

    We present Neural Adaptive Smoothing via Twisting (NAS-X), a method for learning and inference in sequential latent variable models based on reweighted wake-sleep (RWS). NAS-X works with both discrete and continuous latent variables, and leverages smoothing SMC to fit a broader range of models than traditional RWS methods. We test NAS-X on discrete and continuous tasks and find that it substantially outperforms previous variational and RWS-based methods in inference and parameter recovery.
    
[^12]: 基于相关性的模糊聚类有效性指标与次要选项检测器

    A correlation-based fuzzy cluster validity index with secondary options detector. (arXiv:2308.14785v1 [stat.ML])

    [http://arxiv.org/abs/2308.14785](http://arxiv.org/abs/2308.14785)

    本研究提出了一种基于相关性的模糊聚类有效性指标，该指标考虑了在聚类数量选择时可能存在的多个选项，并通过评估在多种数据集上的性能，与现有指标进行比较。

    

    应用聚类分析时，最佳聚类数量是主要关注点之一。已经引入了多个聚类有效性指标来解决这个问题。然而，在某些情况下，有多个选项可以作为最终的聚类数量。大多数现有工作在这个领域忽视了这一方面。在本研究中，我们引入了一种基于相关性的模糊聚类有效性指标，称为Wiroonsri-Preedasawakul（WP）指标。该指标根据一对数据点的实际距离与相应对的调整质心之间的距离之间的相关性来定义。我们评估并比较了我们的指标与Xie-Beni，Pakhira-Bandyopadhyay-Maulik，Tang，Wu-Li，广义C和Kwon2等几个现有指标的性能。我们在四种类型的数据集上进行了评估：人工数据集，现实世界数据集，带有等级的模拟数据集和图像数据集，使用模糊c-mea算法。

    The optimal number of clusters is one of the main concerns when applying cluster analysis. Several cluster validity indexes have been introduced to address this problem. However, in some situations, there is more than one option that can be chosen as the final number of clusters. This aspect has been overlooked by most of the existing works in this area. In this study, we introduce a correlation-based fuzzy cluster validity index known as the Wiroonsri-Preedasawakul (WP) index. This index is defined based on the correlation between the actual distance between a pair of data points and the distance between adjusted centroids with respect to that pair. We evaluate and compare the performance of our index with several existing indexes, including Xie-Beni, Pakhira-Bandyopadhyay-Maulik, Tang, Wu-Li, generalized C, and Kwon2. We conduct this evaluation on four types of datasets: artificial datasets, real-world datasets, simulated datasets with ranks, and image datasets, using the fuzzy c-mea
    
[^13]: 通过混合效应模型和层次聚类学习具有异构农业数据集的贝叶斯网络

    Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering. (arXiv:2308.06399v1 [stat.ML])

    [http://arxiv.org/abs/2308.06399](http://arxiv.org/abs/2308.06399)

    本研究介绍了一种将混合效应模型和层次聚类应用于贝叶斯网络学习的新方法，在农学研究中广泛应用。通过整合随机效应，该方法可以提高贝叶斯网络的结构学习能力，实现因果关系网络的发现。

    

    在涉及多样但相关数据集的研究中，其中协变量与结果之间的关联可能会有所不同，在包括农学研究在内的各个领域都很普遍。在这种情况下，常常使用层次模型，也被称为多层模型，来融合来自不同数据集的信息，并适应它们的不同特点。然而，它们的结构超出了简单的异质性，因为变量通常形成复杂的因果关系网络。贝叶斯网络（BNs）使用有向无环图来模拟这种关系的强大框架。本研究介绍了一种将随机效应整合到BN学习中的新方法。这种方法基于线性混合效应模型，特别适用于处理层次数据。来自真实农学试验的结果表明，采用这种方法可以增强结构学习，从而实现发现

    Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.  Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery 
    
[^14]: 使用无人机进行交通监测的轨迹泊松多伯努利混合滤波器

    Trajectory Poisson multi-Bernoulli mixture filter for traffic monitoring using a drone. (arXiv:2306.16890v1 [cs.CV])

    [http://arxiv.org/abs/2306.16890](http://arxiv.org/abs/2306.16890)

    本文提出了一种使用无人机进行交通监测的多目标跟踪算法。该算法利用光学和热感摄像头获取图像上的物体检测，并使用轨迹泊松多伯努利混合滤波器来估计车辆的轨迹。实验证明，该算法在合成和实验数据集中具有较高的准确性。

    

    本文提出了一种使用配备有光学和热感摄像头的无人机进行交通监测的多目标跟踪（MOT）算法。图像上的物体检测是使用每种类型摄像头的神经网络获得的。摄像头被建模为到达方向（DOA）传感器。每个DOA检测都遵循von-Mises Fisher分布，其平均方向是通过将车辆位置投影到地面上的摄像机获得的。然后我们使用轨迹泊松多伯努利混合滤波器（TPMBM），这是一种贝叶斯多目标跟踪算法，来最优估计一组车辆轨迹。我们还开发了一种测量模型的参数估计算法。我们在合成和实验数据集中测试了所得到的TPMBM滤波器的准确性。

    This paper proposes a multi-object tracking (MOT) algorithm for traffic monitoring using a drone equipped with optical and thermal cameras. Object detections on the images are obtained using a neural network for each type of camera. The cameras are modelled as direction-of-arrival (DOA) sensors. Each DOA detection follows a von-Mises Fisher distribution, whose mean direction is obtain by projecting a vehicle position on the ground to the camera. We then use the trajectory Poisson multi-Bernoulli mixture filter (TPMBM), which is a Bayesian MOT algorithm, to optimally estimate the set of vehicle trajectories. We have also developed a parameter estimation algorithm for the measurement model. We have tested the accuracy of the resulting TPMBM filter in synthetic and experimental data sets.
    
[^15]: 关于大型模型推理中的最优缓存与模型复用

    On Optimal Caching and Model Multiplexing for Large Model Inference. (arXiv:2306.02003v1 [cs.LG])

    [http://arxiv.org/abs/2306.02003](http://arxiv.org/abs/2306.02003)

    本文提出了最优缓存与模型复用两种方法来缓解大型模型推理中资源消耗和延迟挑战，经过实证模拟发现这种组合大大提高了传统模型推理方法的性能。

    

    大型语言模型和其他大型基础模型已经取得了显著的成功，但其尺寸加剧了现有的资源消耗和延迟挑战。本文研究了两种方法来缓解这些挑战：利用缓存存储先前的查询和学习模型复用器来选择用于查询处理的模型。理论上，我们提供了一种最优算法来联合优化这两种方法，从而减少离线和在线制表环境中的推理成本。通过将缓存算法和模型复用器相结合，我们在离线和在线设置下都实现了最优性能。实证模拟表明，我们的缓存和模型复用算法的组合大大提高了传统模型推理方法的性能。

    Large Language Models (LLMs) and other large foundation models have achieved noteworthy success, but their size exacerbates existing resource consumption and latency challenges. In particular, the large-scale deployment of these models is hindered by the significant resource requirements during inference. In this paper, we study two approaches for mitigating these challenges: employing a cache to store previous queries and learning a model multiplexer to choose from an ensemble of models for query processing.  Theoretically, we provide an optimal algorithm for jointly optimizing both approaches to reduce the inference cost in both offline and online tabular settings. By combining a caching algorithm, namely Greedy Dual Size with Frequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we achieve optimal rates in both offline and online settings. Empirically, simulations show that the combination of our caching and model multiplexing algorithms greatly improves over the 
    
[^16]: 学习集合策略的理论保证及其在时间序列预测中的应用

    Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting. (arXiv:2305.15786v1 [cs.LG])

    [http://arxiv.org/abs/2305.15786](http://arxiv.org/abs/2305.15786)

    本文研究了学习集合策略在时间序列预测中的应用，证明了在有限或有限维叠加泛化模型中选择基于交叉验证性能的最优叠加泛化与最优解性能相近。

    

    集合是机器学习中最常用的工具之一，由于其能够有效地减少方差，从而提高泛化性能。针对黑盒基学习器的大多数集合方法都属于“叠加泛化”范畴，即训练一个接受基学习器推理作为输入的机器学习算法。虽然叠加泛化在实践中广泛应用，但其理论性质仍然不为人所知。本文证明了一个新的结果，表明选择基于交叉验证性能的“有限或有限维”叠加泛化中的最佳叠加泛化并不比最优解表现“差得多”。这一结果加强和大大扩展了Van der Laan等人（2007年）的结果。受到理论分析的启发，我们在概率预测的背景下进一步提出了一系列不同敏感性的叠加泛化模型。

    Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of "stacked generalization," namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform "much worse" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the 
    
[^17]: 广义划分局部深度

    Generalized partitioned local depth. (arXiv:2303.10167v1 [stat.ML])

    [http://arxiv.org/abs/2303.10167](http://arxiv.org/abs/2303.10167)

    本文提出了一个广义的凝聚概念，构建在分区局部深度的技术基础上，扩展了早期结果并应用于具有不确定性的数据的社区发现中。

    

    本文提供了一个最近由Berenhaut、Moore和Melvin [Proccedings of the National Academy of Sciences, 119 (4) (2022)]提出的凝聚概念的概括。所提出的表述基于分区局部深度的技术并提炼了两个关键概率概念：局部相关性和支持分割。早期结果在新的背景下得到扩展，并包括在具有不确定性的数据中揭示社区的应用示例。

    In this paper we provide a generalization of the concept of cohesion as introduced recently by Berenhaut, Moore and Melvin [Proceedings of the National Academy of Sciences, 119 (4) (2022)]. The formulation presented builds on the technique of partitioned local depth by distilling two key probabilistic concepts: local relevance and support division. Earlier results are extended within the new context, and examples of applications to revealing communities in data with uncertainty are included.
    
[^18]: 随机步长和循环步长引发了比常数步长更重的SGD尾部

    Cyclic and Randomized Stepsizes Invoke Heavier Tails in SGD than Constant Stepsize. (arXiv:2302.05516v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.05516](http://arxiv.org/abs/2302.05516)

    本文研究了深度学习中的随机步长和循环步长相对于常数步长的优势，通过考虑尾部指数如何随步长调度的变化而变化来推动理论研究，进一步揭示了它们对于泛化性能的改善机制。

    

    随机步长和循环步长在深度学习实践中被广泛使用，并且通常可以胜过常数步长选择，如SGD中的常数步长。尽管它们在经验上获得成功，但目前对于它们何时以及为什么能在理论上提高泛化性能的了解还不够。我们考虑了一类关于学习的马尔可夫步长，其中包含独立同分布的随机步长、循环步长以及常数步长等特殊情况。受到文献中显示的SGD迭代的尾部（通过所谓的“尾部指数”来衡量）的重尾现象与泛化的相关性，我们研究了尾部指数，并提供了一些理论结果，展示了尾部指数在步长调度上的变化。我们的结果为从尾部行为的角度上讨论循环和随机步长相对于常数步长的好处提供了新的理解。我们通过线性回归实验证明了我们的理论，并展示了结果。

    Cyclic and randomized stepsizes are widely used in the deep learning practice and can often outperform standard stepsize choices such as constant stepsize in SGD. Despite their empirical success, not much is currently known about when and why they can theoretically improve the generalization performance. We consider a general class of Markovian stepsizes for learning, which contain i.i.d. random stepsize, cyclic stepsize as well as the constant stepsize as special cases, and motivated by the literature which shows that heaviness of the tails (measured by the so-called "tail-index") in the SGD iterates is correlated with generalization, we study tail-index and provide a number of theoretical results that demonstrate how the tail-index varies on the stepsize scheduling. Our results bring a new understanding of the benefits of cyclic and randomized stepsizes compared to constant stepsize in terms of the tail behavior. We illustrate our theory on linear regression experiments and show thro
    
[^19]: 基于深度学习的非线性因子模型中的残差：低信噪比下资产回报的精确矩阵估计

    Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio. (arXiv:2209.04512v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.04512](http://arxiv.org/abs/2209.04512)

    本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的方法不仅适用于金融市场典型的低信噪比环境，还与弱因子兼容，并且通过理论分析建立了统一的界限，同时提供了基于数据的一致误差协方差估计方法。模拟和实证结果显示我们的模型具有卓越的准确性。

    

    本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的估计方法即使在金融市场典型的信噪比低的环境中仍然有效，并且与弱因子兼容。我们的理论分析对于不断增加的资产数量，基于深度神经网络的预期估计风险建立了统一的界限。此外，我们提供了深度神经网络中基于数据的一致误差协方差估计方法。我们的模型在广泛的模拟和实证中表现出卓越的准确性。

    This paper introduces a consistent estimator and rate of convergence for the precision matrix of asset returns in large portfolios using a non-linear factor model within the deep learning framework. Our estimator remains valid even in low signal-to-noise ratio environments typical for financial markets and is compatible with weak factors. Our theoretical analysis establishes uniform bounds on expected estimation risk based on deep neural networks for an expanding number of assets. Additionally, we provide a new consistent data-dependent estimator of error covariance in deep neural networks. Our models demonstrate superior accuracy in extensive simulations and the empirics.
    
[^20]: 关于对抗性Bayes分类器存在性的研究（扩展版）

    On the Existence of the Adversarial Bayes Classifier (Extended Version). (arXiv:2112.01694v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.01694](http://arxiv.org/abs/2112.01694)

    本篇论文研究了对抗训练健壮性下Bayes最优分类器的存在性问题，提出了一般性的充分条件，并可以为研究对抗性代理损失和其一致性属性提供有用的工具。

    

    对抗训练健壮性在现代机器学习应用中至关重要。虽然最近已经有多项理论研究，但与对抗训练健壮性相关的许多重要问题仍然未被解决。本文研究了一个关于对抗训练健壮性下Bayes最优分类器存在性的基本问题。我们提出了一般的充分条件，以保证存在对抗训练健壮性下的Bayes最优分类器。我们的结果可以为对后续对抗训练健壮性下代理损失和它们的一致性属性的研究提供有用的工具。本文是“关于对抗性Bayes分类器存在性”的矫正和扩展版本，该稿件已发表在NeurIPS 2021上。原始论文中有两处定理错误，一处是对伪可证健壮性的定义，另一处是针对任意度量空间的$A^\e$可测性。

    Adversarial robustness is a critical property in a variety of modern machine learning applications. While it has been the subject of several recent theoretical studies, many important questions related to adversarial robustness are still open. In this work, we study a fundamental question regarding Bayes optimality for adversarial robustness. We provide general sufficient conditions under which the existence of a Bayes optimal classifier can be guaranteed for adversarial robustness. Our results can provide a useful tool for a subsequent study of surrogate losses in adversarial robustness and their consistency properties. This manuscript is the extended and corrected version of the paper \emph{On the Existence of the Adversarial Bayes Classifier} published in NeurIPS 2021. There were two errors in theorem statements in the original paper -- one in the definition of pseudo-certifiable robustness and the other in the measurability of $A^\e$ for arbitrary metric spaces. In this version we 
    
[^21]: 通过全带回馈解决不确定性下的组合优化问题：组合纯探索和更多扩展

    Combinatorial Pure Exploration with Full-bandit Feedback and Beyond: Solving Combinatorial Optimization under Uncertainty with Limited Observation. (arXiv:2012.15584v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.15584](http://arxiv.org/abs/2012.15584)

    该论文研究了在组合优化问题中，当输入参数不确定或最初未知时，通过全带回馈的组合纯探索（CPE）来解决该不确定性的问题。以往的研究主要关注半赌博机反馈或假设每个边的结果始终可以访问，而这篇论文考虑了强反馈信息不一定可用的实际约束。

    

    组合优化是理论计算机科学和运筹学中广泛研究的基础研究领域之一。在开发组合优化算法时，通常假设输入的参数（例如边权重）是准确已知的。然而，在很多应用程序中，例如推荐系统、众包、通信网络和在线广告，输入参数往往是不确定的或者最初未知的。为了解决这样的不确定性，组合多臂赌博机的纯探索问题（CPE）及其变种引起了越来越多的关注。早期关于CPE的研究主要是研究半赌博机反馈或者假设每个边的结果在每轮中都是可以访问的。然而，由于实际约束（例如预算限制或隐私问题），近期的应用中并不总是有这么强的反馈信息可用。

    Combinatorial optimization is one of the fundamental research fields that has been extensively studied in theoretical computer science and operations research. When developing an algorithm for combinatorial optimization, it is commonly assumed that parameters such as edge weights are exactly known as inputs. However, this assumption may not be fulfilled since input parameters are often uncertain or initially unknown in many applications such as recommender systems, crowdsourcing, communication networks, and online advertisement. To resolve such uncertainty, the problem of combinatorial pure exploration of multi-armed bandits (CPE) and its variants have recieved increasing attention. Earlier work on CPE has studied the semi-bandit feedback or assumed that the outcome from each individual edge is always accessible at all rounds. However, due to practical constraints such as a budget ceiling or privacy concern, such strong feedback is not always available in recent applications. In this a
    
[^22]: 贝叶斯特征选择在联合分位数时间序列分析中的应用

    Bayesian Feature Selection in Joint Quantile Time Series Analysis. (arXiv:2010.01654v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.01654](http://arxiv.org/abs/2010.01654)

    本文提出了一种贝叶斯特征选择方法，用于高维联合分位数时间序列分析。模型具有灵活性，可以根据每个时间序列的需要进行特征的选择，并且允许进行即时预测。

    

    对于相关的多变量时间序列数据进行分位数特征选择一直是一种方法上的挑战和一个未解决的问题。在本文中，我们提出了一种通用的贝叶斯降维方法，用于高维联合分位数时间序列分析中的特征选择，该方法被称为分位数特征选择时间序列（QFSTS）模型。QFSTS模型是一个通用的结构时间序列模型，每个组成部分对时间序列建模产生了可直接解释的加性贡献。其灵活性体现在用户可以为每个时间序列添加/减少组成部分，并且每个时间序列可以具有不同大小的特定值组成部分。特征选择是在分位数回归组件中进行的，每个时间序列都有自己的同时外部预测变量池，允许进行即时预测。基于贝叶斯方法将特征选择扩展到分位数时间序列研究领域。

    Quantile feature selection over correlated multivariate time series data has always been a methodological challenge and is an open problem. In this paper, we propose a general Bayesian dimension reduction methodology for feature selection in high-dimensional joint quantile time series analysis, under the name of the quantile feature selection time series (QFSTS) model. The QFSTS model is a general structural time series model, where each component yields an additive contribution to the time series modeling with direct interpretations. Its flexibility is compound in the sense that users can add/deduct components for each time series and each time series can have its own specific valued components of different sizes. Feature selection is conducted in the quantile regression component, where each time series has its own pool of contemporaneous external predictors allowing nowcasting. Bayesian methodology in extending feature selection to the quantile time series research area is developed
    
[^23]: 二阶条件梯度滑动

    Second-order Conditional Gradient Sliding. (arXiv:2002.08907v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2002.08907](http://arxiv.org/abs/2002.08907)

    提出了一种二阶条件梯度滑动（SOCGS）算法，可以高效解决约束二次凸优化问题，并在有限次线性收敛迭代后二次收敛于原始间隙。

    

    当需要高精度解决问题时，约束二阶凸优化算法是首选，因为它们具有局部二次收敛性。这些算法在每次迭代时需要解决一个约束二次子问题。我们提出了\emph{二阶条件梯度滑动}（SOCGS）算法，它使用一种无投影算法来近似解决约束二次子问题。当可行域是一个多面体时，该算法在有限次线性收敛迭代后二次收敛于原始间隙。进入二次收敛阶段后，SOCGS算法需通过$\mathcal{O}(\log(\log 1/\varepsilon))$次一阶和Hessian正交调用以及$\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$次线性最小化正交调用来实现$\varepsilon$-最优解。当可行域只能通过线性优化正交调用高效访问时，此算法非常有用。

    Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\mathcal{O}(\log(\log 1/\varepsilon))$ first-order and Hessian oracle calls and $\mathcal{O}(\log (1/\varepsilon) \log(\log1/\varepsilon))$ linear minimization oracle calls to achieve an $\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, 
    
[^24]: 半监督矢量值学习：改进的界限与算法

    Semi-supervised Vector-valued Learning: Improved Bounds and Algorithms. (arXiv:1909.04883v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1909.04883](http://arxiv.org/abs/1909.04883)

    该论文提出了一种针对半监督矢量值学习的改进算法，通过利用局部Rademacher复杂度和无标签数据，得出了更精确的超出风险界限。实验结果表明，该算法在多个领域中明显优于其他方法。

    

    矢量值学习是一个重要的问题，其输出空间具有矢量值结构，涵盖了许多重要领域，如多任务学习和迁移学习。我们利用局部Rademacher复杂度和无标签数据，从核函数和线性方法的角度为一般矢量值学习导出了新的半监督超出风险界限。这些界限比现有的界限更精确，收敛速度从标记样本大小的平方根改进为总样本大小的平方根或直接依赖于标记样本大小。在理论分析的基础上，我们提出了一种通用的半监督算法来高效学习矢量值函数，结合了局部Rademacher复杂度和拉普拉斯正则化。大量的实验结果表明，所提出的算法明显优于其他方法，并与我们的理论结果相吻合。

    Vector-valued learning, where the output space admits a vector-valued structure, is an important problem that covers a broad family of important domains, e.g. multi-task learning and transfer learning. Using local Rademacher complexity and unlabeled data, we derive novel semi-supervised excess risk bounds for general vector-valued learning from both kernel perspective and linear perspective. The derived bounds are much sharper than existing ones and the convergence rates are improved from the square root of labeled sample size to the square root of total sample size or directly dependent on labeled sample size. Motivated by our theoretical analysis, we propose a general semi-supervised algorithm for efficiently learning vector-valued functions, incorporating both local Rademacher complexity and Laplacian regularization. Extensive experimental results illustrate the proposed algorithm significantly outperforms the compared methods, which coincides with our theoretical findings.
    

