# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Spectral Algorithm for List-Decodable Covariance Estimation in Relative Frobenius Norm.](http://arxiv.org/abs/2305.00966) | 本研究提出了一个谱算法来解决列可译协方差估计问题，并得到了高斯混合模型鲁棒性部分聚类的有效谱算法。 |
| [^2] | [Variational Inference for Bayesian Neural Networks under Model and Parameter Uncertainty.](http://arxiv.org/abs/2305.00934) | 本文提出了一种新的框架将模型不确定性应用于BNNs中的结构学习中并利用可扩展的变分推断方法纳入了模型空间约束，以在模型和参数的联合空间中进行推断分析。 |
| [^3] | [A comparison of short-term probabilistic forecasts for the incidence of COVID-19 using mechanistic and statistical time series models.](http://arxiv.org/abs/2305.00933) | 本研究比较了机械模型和统计模型的短期COVID-19预测，发现平均而言，基于统计时间序列模型的概率预测至少与机械模型的预测一样准确，同时更好地捕捉波动性。这表明将领域知识整合到机械模型中不能改善疾病发生率的短期预测。 |
| [^4] | [Exactly Tight Information-Theoretic Generalization Error Bound for the Quadratic Gaussian Problem.](http://arxiv.org/abs/2305.00876) | 该论文提出了一种新的信息理论泛化误差紧确界，对于典型的二次高斯均值估计问题，它是完全紧确的。与现有的界不同，这个新界利用了个体样本的方法，并对泛化误差函数进行了测量变换不等式和条件导出。 |
| [^5] | [Estimating the Density Ratio between Distributions with High Discrepancy using Multinomial Logistic Regression.](http://arxiv.org/abs/2305.00869) | 本文介绍了一种使用多类逻辑回归进行密度比估计的方法，不受分布偏移影响，对于密度分离良好的情况表现更好，通过引入辅助密度构造，可以实现更准确的估计。 |
| [^6] | [First- and Second-Order Bounds for Adversarial Linear Contextual Bandits.](http://arxiv.org/abs/2305.00832) | 本文研究了允许$k$个臂的损失函数随时间而自由变化的对抗性线性上下文赌博情境。在假设环境较为温和的情况下，我们获得了一个关于Learner's Losses $V_T$的二阶损失值量级为$\tilde O(K\sqrt{d V_T})$和关于最佳策略$L_T^*$的一阶损失值量级为$\tilde O(K\sqrt{d L_T^*})$的界。 |
| [^7] | [Heterogeneous Social Value Orientation Leads to Meaningful Diversity in Sequential Social Dilemmas.](http://arxiv.org/abs/2305.00768) | 该论文研究表明，在序列社交困境中，异质性SVO导致多样化的策略，并通过学习最佳应答策略实现更好的零样本推广。 |
| [^8] | [Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control.](http://arxiv.org/abs/2305.00700) | 本文考虑了高度过参数化的因果推断模型，探讨了多个控制单元的高维合成控制估计性能，发现增加控制单元可以帮助提高填充性能，甚至超过了预处理拟合完美的点。 |
| [^9] | [On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring.](http://arxiv.org/abs/2305.00684) | 本文研究了多智能体决策制定的样本有效、均衡计算和局部监控问题，提出了复杂度上下界和算法，并发现多智能体情况下可能呈指数级难度。 |
| [^10] | [Reservoir Computing with Error Correction: Long-term Behaviors of Stochastic Dynamical Systems.](http://arxiv.org/abs/2305.00669) | 本文提出了一种数据驱动的框架，将沉积计算和归一化流结合起来以研究随机动力学系统的预测和动力学行为，成功地预测了长期演化并复制了动力学行为。 |
| [^11] | [Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression.](http://arxiv.org/abs/2305.00608) | 该论文介绍了使用RePU激活函数的可微分神经网络，在近似$C^s$平滑函数及其导数的同时建立了下限误差界，并证明了其在降低维度灾难方面的能力，此外还提出了一种使用RePU网络的惩罚保序回归(PDIR)方法。 |
| [^12] | [ISAAC Newton: Input-based Approximate Curvature for Newton's Method.](http://arxiv.org/abs/2305.00604) | ISAAC Newton方法提出了一种使用选择的二阶信息调整梯度的方法，并且在选择批量大小小于神经元数量的情况下，计算开销消失，能够在小批量随机情况下有效训练。 |
| [^13] | [The ART of Transfer Learning: An Adaptive and Robust Pipeline.](http://arxiv.org/abs/2305.00520) | 本文提出了自适应稳健转移学习（ART）管道，使用通用机器学习算法实现转移学习，建立了非渐近学习理论，同时防止负面转移，并演示了它在回归、分类和稀疏学习上的良好性能。 |
| [^14] | [Domain Agnostic Fourier Neural Operators.](http://arxiv.org/abs/2305.00478) | 介绍了一种新的神经算子架构 DAFNO，可以学习带有不规则几何和不断变化的域的代理。通过将平滑化的特征函数纳入 FNOs 的积分层架构中，并利用 FFT 来实现快速计算，以明确的方式将几何信息编码到架构中，DAFNO 相对于基线神经算子模型具有最先进的精度。 |
| [^15] | [Time series clustering based on prediction accuracy of global forecasting models.](http://arxiv.org/abs/2305.00473) | 本论文提出了一种基于预测准确性的时间序列聚类新方法，可以用于选择时间序列数据库中的聚类数，并且比传统方法更好。 |
| [^16] | [New bootstrap tests for categorical time series. A comparative study.](http://arxiv.org/abs/2305.00465) | 本文提出了三种用于测试两个分类时间序列生成过程平等性的自助法。通过分析三种方法的等值性和差异，我们评估了它们在不同复杂度程度的分类模型下的性能表现。 |
| [^17] | [Indexability of Finite State Restless Multi-Armed Bandit and Rollout Policy.](http://arxiv.org/abs/2305.00410) | 本文研究了有限状态不想静止多臂赌博机问题，提出了一种应用rollout策略的算法来解决问题，并且在单臂赌博机模型上展示了结构结果和可索引性。 |
| [^18] | [Optimal tests following sequential experiments.](http://arxiv.org/abs/2305.00403) | 本文分析了基于顺序实验的最优检验方法，重要发现是任何检验的渐近功率函数都可以与一种极限实验中匹配的检验相匹配，这个结果有重要的意义，包括一个强大的充分性结果。 |
| [^19] | [POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained models.](http://arxiv.org/abs/2305.00350) | 本文提出了一种基于提示的无监督微调框架，可以在未标记的目标数据上微调大型预训练模型以适应下游任务，实验结果表明该方法在图像分类、情感分析和自然语言推理等任务中表现更好。 |
| [^20] | [Representing Additive Gaussian Processes by Sparse Matrices.](http://arxiv.org/abs/2305.00324) | 本研究展示了对于加性Matérn高斯过程，通过稀疏矩阵和向量的公式可以有效地计算后验均值、后验方差、对数似然和梯度。 |
| [^21] | [A Coupled Flow Approach to Imitation Learning.](http://arxiv.org/abs/2305.00303) | 本文提出了一种新的模仿学习算法Coupled Flow Imitation Learning（CFIL），使用正则流模型的分布匹配来建模状态分布和状态行为分布。在基准任务中具有单个专家轨迹表现出最先进的性能。 |
| [^22] | [EBLIME: Enhanced Bayesian Local Interpretable Model-agnostic Explanations.](http://arxiv.org/abs/2305.00213) | 本文提出了EBLIME方法，使用贝叶斯岭回归模型从黑盒机器学习模型中解释特征重要性的分布，实验结果表明该方法比现有最先进方法具有更好的解释能力和不确定性量化能力。 |
| [^23] | [Data-Driven Subgroup Identification for Linear Regression.](http://arxiv.org/abs/2305.00195) | 本文提出了一个基于数据驱动方法的DDGroup，可以有效地识别具有特征与标签之间统一线性关系的子群，为医学研究提供了一种新的统计工具。 |
| [^24] | [Limits of Model Selection under Transfer Learning.](http://arxiv.org/abs/2305.00152) | 这篇论文介绍了在转移学习下模型选择存在的限制，其转移距离会影响自适应速率，可能导致速率较慢。 |
| [^25] | [Sequential Predictive Two-Sample and Independence Testing.](http://arxiv.org/abs/2305.00143) | 本文提出了一种基于预测的赌博策略来解决高维或结构化数据下非参数双样本和独立性检验问题。 |
| [^26] | [On the existence of solutions to adversarial training in multiclass classification.](http://arxiv.org/abs/2305.00075) | 本文研究了多类分类中敌对训练的鲁棒解存在性问题，证明了每个模型中存在 Borel 可测的鲁棒分类器，并与最优传输和总变差正则化建立了联系。在二元分类问题中，对不可知分类器的敌对训练问题存在 Borel 可测的解。 |
| [^27] | [Online Platt Scaling with Calibeating.](http://arxiv.org/abs/2305.00070) | 本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。 |
| [^28] | [LAVA: Data Valuation without Pre-Specified Learning Algorithms.](http://arxiv.org/abs/2305.00054) | LAVA是一个学习算法无关的数据价值评估方法，它结合了学习算法的统计特性和训练数据的属性，通过迭代估计数据值来实现。LAVA比现有方法计算速度更快，精度更高，并且可以为不同的应用提供有意义的数据排名。 |
| [^29] | [Robust, randomized preconditioning for kernel ridge regression.](http://arxiv.org/abs/2304.12465) | 针对核岭回归问题，本文引入了两种强健的随机预处理技术，分别解决了全数据KRR问题和限制版KRR问题，克服了以往预处理器的故障模式。 |
| [^30] | [Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation.](http://arxiv.org/abs/2303.04772) | 本文介绍了无限维度得分扩散模型在多个分辨率水平上的离散化方法，并使用多级扩散算法在多个分辨率上高效地学习。实证表明，该模型在相同或更高分辨率下产生比传统基于得分的扩散模型更高质量的样本，并可以生成不同分辨率的图像并处理矩形域。 |
| [^31] | [Bridging the Usability Gap: Theoretical and Methodological Advances for Spectral Learning of Hidden Markov Models.](http://arxiv.org/abs/2302.07437) | 本文研究了隐马尔可夫模型谱学习中存在的问题，并提出了解决方案，包括提供了SHMM似然估计的误差渐近分布、提出投影SHMM算法可以减轻误差传播问题、并开发了SHMM和PSHMM的在线学习变体以适应潜在的非平稳性。研究结果表明PSHMM具有更好的性能表现。 |
| [^32] | [Score-based Causal Representation Learning with Interventions.](http://arxiv.org/abs/2301.08230) | 本文研究了当潜在因果变量通过未知线性转换间接观察时的因果表征学习问题。其充分条件确保了干预效果可以从分数的变化中正确检测出来，并利用最小化分数函数变化的关键特性完美恢复有效变换。 |
| [^33] | [Sample Complexity Bounds for Learning High-dimensional Simplices in Noisy Regimes.](http://arxiv.org/abs/2209.05953) | 本文解决了一个重要的开放性问题，提出了在噪声环境下从样本中学习单纯形的样本复杂度界限，并证明了只要信噪比较高，样本复杂度与无噪声情况具有相同的阶。 |
| [^34] | [Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning.](http://arxiv.org/abs/2208.09894) | 本文研究了中心化剪裁在面对不同恶意代理时的脆弱性，提出了一种称为多引用点剪裁 (MRPC) 的算法来解决这个问题。MRPC 框架利用多个参考点有效地中和专门设计的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。 |
| [^35] | [Conformal Risk Control.](http://arxiv.org/abs/2208.02814) | 该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。 |
| [^36] | [Improving adversarial robustness by putting more regularizations on less robust samples.](http://arxiv.org/abs/2206.03353) | 本文提出了一种新的对抗训练算法，通过在容易受到对抗攻击的数据上施加更多正则化以提高对抗性鲁棒性，得到了在准确性和鲁棒性方面均为最优的表现。 |
| [^37] | [Complex-to-Real Sketches for Tensor Products with Applications to the Polynomial Kernel.](http://arxiv.org/abs/2202.02031) | 本论文提出一种Complex-to-Real草图方法，用于处理复合实张量乘积，取得了在多项式核上最先进的准确性和速度表现。 |
| [^38] | [A Machine Learning Framework for Distributed Functional Compression over Wireless Channels in IoT.](http://arxiv.org/abs/2201.09483) | 本论文开发了一种面向物联网的分布式功能压缩机器学习框架，采用了能够任意计算IoT所需函数压缩任务的Kolmogorov-Arnold表示定理，解决了基于云的方法在传输数据时给网络资源带来的压力问题。 |
| [^39] | [A Sparse Expansion For Deep Gaussian Processes.](http://arxiv.org/abs/2112.05888) | 本文提出了一种基于高斯过程的稀疏展开方法，用于构建深度高斯过程模型。该方法可以提高计算效率，使得模型更加稀疏。 |
| [^40] | [Robustness of Graph Neural Networks at Scale.](http://arxiv.org/abs/2110.14038) | 本文研究了规模下如何攻击和防御图神经网络（GNNs），提出了稀疏感知的一阶优化攻击和鲁棒性聚合函数Soft Median，有效提高了GNNs的可靠性和攻击力。 |
| [^41] | [Redundant representations help generalization in wide neural networks.](http://arxiv.org/abs/2106.03485) | 本文研究了各种卷积神经网络的最后一个隐藏层中的表示，发现如果最后一个隐藏表示足够宽，则其神经元倾向于分成携带相同信息的组，而冗余表示有助于宽神经网络的泛化。 |
| [^42] | [Doubly robust Thompson sampling for linear payoffs.](http://arxiv.org/abs/2102.01229) | 本文提出了一种新型多臂上下文赌博算法双重稳健汤普森抽样（DR Thompson Sampling），通过双重稳健估计器，解决了过去的上下文和奖励对选择依赖性导致的损失分解复杂等问题，得到了简化且改进的损失界限。 |
| [^43] | [Best Principal Submatrix Selection for the Maximum Entropy Sampling Problem: Scalable Algorithms and Performance Guarantees.](http://arxiv.org/abs/2001.08537) | 本文提出了一个新的整数规划方法和连续松弛算法来解决最大熵采样问题，并提供了效率更高的确定性采样算法。同时，我们改进了已有的近似界限，并证明了局部搜索算法的第一个近似界限。 |
| [^44] | [IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters.](http://arxiv.org/abs/1903.12141) | 本文提出IMAE模型用于畸形训练数据的鲁棒深度学习，通过实践证实平均绝对误差（MAE）在处理示例时存在欠拟合问题，利用加权方差调整提高了拟合能力，同时保持了鲁棒性。 |

# 详细

[^1]: 列可译协方差估计的谱算法

    A Spectral Algorithm for List-Decodable Covariance Estimation in Relative Frobenius Norm. (arXiv:2305.00966v1 [cs.DS])

    [http://arxiv.org/abs/2305.00966](http://arxiv.org/abs/2305.00966)

    本研究提出了一个谱算法来解决列可译协方差估计问题，并得到了高斯混合模型鲁棒性部分聚类的有效谱算法。

    

    本文研究了列可译高斯协方差估计问题。给定一个由$n$个位于$\mathbb R^d$中的点组成的多重集$T$，其中$\alpha<1/2$个点是从一个未知的高斯$\mathcal {N}(\mu，\Sigma)$中独立同分布采样得到的，旨在输出一个$O(1/\alpha)$的假设列表，其中至少有一个在相对Frobenius范数下接近$\Sigma$。我们的主要结果是针对这个任务的$\mathrm{poly}(d,1/\alpha)$样本和时间算法，它保证了$\mathrm{poly}(1/\alpha)$的相对Frobenius范数误差。重要的是，我们的算法纯粹依赖于谱技术。作为一个推论，我们得到了高斯混合模型(GMMs)鲁棒性部分聚类的有效谱算法——这是[BMD+22]最新工作中鲁棒性学习任意GMMs的关键组成部分。结合[BMD+22]中的其他组成部分，我们的新方法提供了第一个无和平方项算法来鲁棒地学习GMMs。

    We study the problem of list-decodable Gaussian covariance estimation. Given a multiset $T$ of $n$ points in $\mathbb R^d$ such that an unknown $\alpha<1/2$ fraction of points in $T$ are i.i.d. samples from an unknown Gaussian $\mathcal{N}(\mu, \Sigma)$, the goal is to output a list of $O(1/\alpha)$ hypotheses at least one of which is close to $\Sigma$ in relative Frobenius norm. Our main result is a $\mathrm{poly}(d,1/\alpha)$ sample and time algorithm for this task that guarantees relative Frobenius norm error of $\mathrm{poly}(1/\alpha)$. Importantly, our algorithm relies purely on spectral techniques. As a corollary, we obtain an efficient spectral algorithm for robust partial clustering of Gaussian mixture models (GMMs) -- a key ingredient in the recent work of [BDJ+22] on robustly learning arbitrary GMMs. Combined with the other components of [BDJ+22], our new method yields the first Sum-of-Squares-free algorithm for robustly learning GMMs. At the technical level, we develop a no
    
[^2]: 模型和参数不确定性下的贝叶斯神经网络变分推断研究

    Variational Inference for Bayesian Neural Networks under Model and Parameter Uncertainty. (arXiv:2305.00934v1 [stat.ML])

    [http://arxiv.org/abs/2305.00934](http://arxiv.org/abs/2305.00934)

    本文提出了一种新的框架将模型不确定性应用于BNNs中的结构学习中并利用可扩展的变分推断方法纳入了模型空间约束，以在模型和参数的联合空间中进行推断分析。

    

    由于可扩展的近似贝叶斯推断技术的发展，贝叶斯神经网络（BNNs）最近重新引起深度学习社区的大量关注。使用贝叶斯方法有几个优点：参数和预测的不确定性变得容易获得，从而便于进行严格的统计分析。此外，可以加入先验知识。然而，到目前为止，还没有可扩展的技术能够组合结构和参数不确定性。本文将模型不确定性的概念应用于BNNs中的结构学习框架，并因此在结构/模型和参数的联合空间中进行推断。此外，我们建议采用具有边际包含概率重参数化的可扩展变分推断方法来纳入模型空间约束。在一系列基准数据集上的实验结果表明，我们获得了相当的准确性。

    Bayesian neural networks (BNNs) have recently regained a significant amount of attention in the deep learning community due to the development of scalable approximate Bayesian inference techniques. There are several advantages of using a Bayesian approach: Parameter and prediction uncertainties become easily available, facilitating rigorous statistical analysis. Furthermore, prior knowledge can be incorporated. However, so far, there have been no scalable techniques capable of combining both structural and parameter uncertainty. In this paper, we apply the concept of model uncertainty as a framework for structural learning in BNNs and hence make inference in the joint space of structures/models and parameters. Moreover, we suggest an adaptation of a scalable variational inference approach with reparametrization of marginal inclusion probabilities to incorporate the model space constraints. Experimental results on a range of benchmark datasets show that we obtain comparable accuracy res
    
[^3]: 一种基于机械和统计时间序列模型的COVID-19短期概率预测比较

    A comparison of short-term probabilistic forecasts for the incidence of COVID-19 using mechanistic and statistical time series models. (arXiv:2305.00933v1 [stat.AP])

    [http://arxiv.org/abs/2305.00933](http://arxiv.org/abs/2305.00933)

    本研究比较了机械模型和统计模型的短期COVID-19预测，发现平均而言，基于统计时间序列模型的概率预测至少与机械模型的预测一样准确，同时更好地捕捉波动性。这表明将领域知识整合到机械模型中不能改善疾病发生率的短期预测。

    

    疾病传播的短期预测是风险评估和公共卫生决策中至关重要的组成部分。虽然已经开发了不同的短期预测模型，但其相对性能仍有疑问。本文比较基于更新方程的流行病学机械模型和时间序列统计模型的短期概率预测。我们的经验比较基于美国六个大州在第一年的COVID-19每日发病率数据。我们发现，平均而言，来自统计时间序列模型的概率预测总体上至少与机械模型的预测一样准确。此外，统计时间序列模型更好地捕捉波动性。我们的发现表明，通过对疾病动态做出假设将领域知识整合到机械模型中并不能改善疾病发生率的短期预测。但是，我们指出，预测精度在不同州和时间段中有所变化，表明可能存在机械模型的表现优于统计模型的情况。

    Short-term forecasts of infectious disease spread are a critical component in risk evaluation and public health decision making. While different models for short-term forecasting have been developed, open questions about their relative performance remain. Here, we compare short-term probabilistic forecasts of popular mechanistic models based on the renewal equation with forecasts of statistical time series models. Our empirical comparison is based on data of the daily incidence of COVID-19 across six large US states over the first pandemic year. We find that, on average, probabilistic forecasts from statistical time series models are overall at least as accurate as forecasts from mechanistic models. Moreover, statistical time series models better capture volatility. Our findings suggest that domain knowledge, which is integrated into mechanistic models by making assumptions about disease dynamics, does not improve short-term forecasts of disease incidence. We note, however, that foreca
    
[^4]: 二次高斯问题的信息理论泛化误差的完全紧确界

    Exactly Tight Information-Theoretic Generalization Error Bound for the Quadratic Gaussian Problem. (arXiv:2305.00876v1 [cs.IT])

    [http://arxiv.org/abs/2305.00876](http://arxiv.org/abs/2305.00876)

    该论文提出了一种新的信息理论泛化误差紧确界，对于典型的二次高斯均值估计问题，它是完全紧确的。与现有的界不同，这个新界利用了个体样本的方法，并对泛化误差函数进行了测量变换不等式和条件导出。

    

    我们提供了一种新的信息理论泛化误差紧确界，对于典型的二次高斯均值估计问题，它是完全紧确的（即匹配常数）。尽管在推导信息论泛化误差界方面进行了相当多的努力，但将其应用于使用样本平均作为高斯数据均值估计的简单设置并没有产生令人满意的结果。事实上，在这种情况下，大多数现有的界都是松散的，这引起了人们对于信息理论界在推理机器学习的泛化行为方面的基本能力的关注。提出的新的界采用了Bu等人提出的基于单个样本的方法，但也有几个关键的新组成部分。 首先，我们不是将测量变换不等式应用于损失函数，而是应用于泛化误差函数本身；其次，界是有条件地导出的； 最后，

    We provide a new information-theoretic generalization error bound that is exactly tight (i.e., matching even the constant) for the canonical quadratic Gaussian mean estimation problem. Despite considerable existing efforts in deriving information-theoretic generalization error bounds, applying them to this simple setting where sample average is used as the estimate of the mean value of Gaussian data has not yielded satisfying results. In fact, most existing bounds are order-wise loose in this setting, which has raised concerns about the fundamental capability of information-theoretic bounds in reasoning the generalization behavior for machine learning. The proposed new bound adopts the individual-sample-based approach proposed by Bu et al., but also has several key new ingredients. Firstly, instead of applying the change of measure inequality on the loss function, we apply it to the generalization error function itself; secondly, the bound is derived in a conditional manner; lastly, a 
    
[^5]: 使用多项逻辑回归估算高离差分布的密度比

    Estimating the Density Ratio between Distributions with High Discrepancy using Multinomial Logistic Regression. (arXiv:2305.00869v1 [stat.ML])

    [http://arxiv.org/abs/2305.00869](http://arxiv.org/abs/2305.00869)

    本文介绍了一种使用多类逻辑回归进行密度比估计的方法，不受分布偏移影响，对于密度分离良好的情况表现更好，通过引入辅助密度构造，可以实现更准确的估计。

    

    在机器学习中，密度比$p/q$的函数被广泛用于量化两个分布$p$和$q$之间的离差。对于高维分布，基于二元分类的密度比估计器表现出很大的潜力。然而，当密度分离良好时，使用二元分类器估算密度比是具有挑战性的。本文展示了最新的密度比估计器在密度分离良好的情况下表现差，并证明这是由于训练和评估时发生的分布偏移问题。我们提出了一种另类方法，利用多类分类进行密度比估计，并且不受到分布偏移的影响。该方法使用一组辅助密度$\{m_k\}_{k=1}^K$，并训练一个多类逻辑回归对样本从$p，q$和$\{m_k\}_{k=1}^K$分类成$K+2$类。我们证明，如果这些辅助密度被构造为满足最大密度比值条件，则多类逻辑回归可以一致地估计密度比。

    Functions of the ratio of the densities $p/q$ are widely used in machine learning to quantify the discrepancy between the two distributions $p$ and $q$. For high-dimensional distributions, binary classification-based density ratio estimators have shown great promise. However, when densities are well separated, estimating the density ratio with a binary classifier is challenging. In this work, we show that the state-of-the-art density ratio estimators perform poorly on well-separated cases and demonstrate that this is due to distribution shifts between training and evaluation time. We present an alternative method that leverages multi-class classification for density ratio estimation and does not suffer from distribution shift issues. The method uses a set of auxiliary densities $\{m_k\}_{k=1}^K$ and trains a multi-class logistic regression to classify the samples from $p, q$, and $\{m_k\}_{k=1}^K$ into $K+2$ classes. We show that if these auxiliary densities are constructed such that t
    
[^6]: 对抗性线性上下文赌博的一阶和二阶界限

    First- and Second-Order Bounds for Adversarial Linear Contextual Bandits. (arXiv:2305.00832v1 [cs.LG])

    [http://arxiv.org/abs/2305.00832](http://arxiv.org/abs/2305.00832)

    本文研究了允许$k$个臂的损失函数随时间而自由变化的对抗性线性上下文赌博情境。在假设环境较为温和的情况下，我们获得了一个关于Learner's Losses $V_T$的二阶损失值量级为$\tilde O(K\sqrt{d V_T})$和关于最佳策略$L_T^*$的一阶损失值量级为$\tilde O(K\sqrt{d L_T^*})$的界。

    

    本文研究了对抗性线性上下文赌博的情境，该情境允许与K个臂相关联的损失函数随时间而自由变化。 假设d维上下文从已知分布中绘制，那么在T轮游戏期间最坏情况下的预期遗憾将以$\tilde O(\sqrt{Kd T})$的速度增长。在假设上下文的密度是对数凹的情况下，我们获得了一个二阶界，其在累积损失的二次矩$V_T$方面的量级为$\tilde O(K\sqrt{d V_T})$，以及一个与之密切相关的一阶界，其在最佳策略的累积损失$L_T^*$方面的量级为$\tilde O(K\sqrt{d L_T^*})$。由于$V_T$或$L_T^*$可能明显小于$T$，因此每当环境相对温和时，便会改善最坏情况的遗憾。本文使用概率单纯形上的连续指数权重算法的截断版本来获得结果

    We consider the adversarial linear contextual bandit setting, which allows for the loss functions associated with each of $K$ arms to change over time without restriction. Assuming the $d$-dimensional contexts are drawn from a fixed known distribution, the worst-case expected regret over the course of $T$ rounds is known to scale as $\tilde O(\sqrt{Kd T})$. Under the additional assumption that the density of the contexts is log-concave, we obtain a second-order bound of order $\tilde O(K\sqrt{d V_T})$ in terms of the cumulative second moment of the learner's losses $V_T$, and a closely related first-order bound of order $\tilde O(K\sqrt{d L_T^*})$ in terms of the cumulative loss of the best policy $L_T^*$. Since $V_T$ or $L_T^*$ may be significantly smaller than $T$, these improve over the worst-case regret whenever the environment is relatively benign. Our results are obtained using a truncated version of the continuous exponential weights algorithm over the probability simplex, which
    
[^7]: 异质性社交价值取向在序列社交困境中导致有意义的多样性

    Heterogeneous Social Value Orientation Leads to Meaningful Diversity in Sequential Social Dilemmas. (arXiv:2305.00768v1 [cs.MA])

    [http://arxiv.org/abs/2305.00768](http://arxiv.org/abs/2305.00768)

    该论文研究表明，在序列社交困境中，异质性SVO导致多样化的策略，并通过学习最佳应答策略实现更好的零样本推广。

    

    在社会心理学中，社交价值取向（SVO）描述了个人在自我和他人之间分配资源的倾向性。在强化学习中，SVO被实例化为一种内在动机，根据特定的目标分配组奖励，重新映射代理的奖励。之前的研究表明，具有异质性SVO的代理组在类似囚徒困境的激励结构下学习了多样化的策略。我们的研究扩展了这一结果，并证明了(1)异质性SVO在序列社交困境中通过一系列的奖励结构导致策略的多样性，如任务特定的多样性指标所测量的那样；(2)针对这种策略多样性学习最佳应答在某些情况下可以更好地进行零样本推广。我们展示了这些最佳应答代理学习的策略是以他们的联合玩家为条件的，我们认为这是改进零样本推广的原因。

    In social psychology, Social Value Orientation (SVO) describes an individual's propensity to allocate resources between themself and others. In reinforcement learning, SVO has been instantiated as an intrinsic motivation that remaps an agent's rewards based on particular target distributions of group reward. Prior studies show that groups of agents endowed with heterogeneous SVO learn diverse policies in settings that resemble the incentive structure of Prisoner's dilemma. Our work extends this body of results and demonstrates that (1) heterogeneous SVO leads to meaningfully diverse policies across a range of incentive structures in sequential social dilemmas, as measured by task-specific diversity metrics; and (2) learning a best response to such policy diversity leads to better zero-shot generalization in some situations. We show that these best-response agents learn policies that are conditioned on their co-players, which we posit is the reason for improved zero-shot generalization 
    
[^8]: 因果推断中的双重和单一下降现象，及其在高维合成控制中的应用。

    Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control. (arXiv:2305.00700v1 [econ.EM])

    [http://arxiv.org/abs/2305.00700](http://arxiv.org/abs/2305.00700)

    本文考虑了高度过参数化的因果推断模型，探讨了多个控制单元的高维合成控制估计性能，发现增加控制单元可以帮助提高填充性能，甚至超过了预处理拟合完美的点。

    

    本文针对机器学习中的双重下降现象，考虑了高度过参数化的因果推断模型，包括多个控制单元的合成控制。在这种模型中，可能存在太多的自由参数，以至于模型可以完美地拟合训练数据。本文首先以高维线性回归模型为例，研究薪资数据的填充，发现比简单模型更多的协变量对于模型性能的提升很有效。本文的主要贡献在于探讨了多个控制单元的高维合成控制估计性能，发现增加控制单元可以帮助提高填充性能，甚至超过了预处理拟合完美的点。此外，本文提出一种统一的理论视角来解释这些高维模型的性能，即将更复杂的模型视为对简单模型的模型平均估计。

    Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parametrized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. As a motivating example, we first investigate high-dimensional linear regression for imputing wage data, where we find that models with many more covariates than sample size can outperform simple ones. As our main contribution, we document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We then provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we 
    
[^9]: 关于多智能体决策制定的复杂性：从游戏学习到局部监控。

    On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring. (arXiv:2305.00684v1 [cs.LG])

    [http://arxiv.org/abs/2305.00684](http://arxiv.org/abs/2305.00684)

    本文研究了多智能体决策制定的样本有效、均衡计算和局部监控问题，提出了复杂度上下界和算法，并发现多智能体情况下可能呈指数级难度。

    

    多智能体强化学习（MARL）中的一个核心问题是理解结构条件和算法原则会导致哪些样本有效的学习保证，并且在我们从少数智能体转移到多数智能体时，这些考虑如何发生变化。本文在多智能体互动决策的一般框架下研究了这个问题，包括具有函数逼近的马尔可夫博弈和带有赌徒反馈的正则式博弈。我们关注均衡计算，其中集中式学习算法旨在通过控制与未知环境交互的多个智能体来计算均衡。我们的主要贡献是：1. 我们基于由Foster等人（2021）在单智能体情况下引入的复杂度度量方法—决策-估计系数，为多智能体决策制定了最佳样本复杂度的上界和下界。与单智能体情况下的最佳结果相比，我们表明多智能体情况下的问题在智能体数量方面可能呈指数级难度。2. 我们提出了一种新颖的算法，用于在具有函数逼近的大型马尔可夫博弈中进行高效的均衡计算，该算法基于乐观镜像下降法的原理。我们为我们的方法建立了样本复杂度界限，这些界限改进了先前在带有赌徒反馈的游戏中的工作。3. 我们考虑局部监控，这是一种反馈类型，其中决策制定者只观察智能体动作的摘要信息而不是全部信息。我们开发了我们算法的一个变体，该算法实现了此设置的收敛速度最优，与先前工作建立的下界相比。

    A central problem in the theory of multi-agent reinforcement learning (MARL) is to understand what structural conditions and algorithmic principles lead to sample-efficient learning guarantees, and how these considerations change as we move from few to many agents. We study this question in a general framework for interactive decision making with multiple agents, encompassing Markov games with function approximation and normal-form games with bandit feedback. We focus on equilibrium computation, in which a centralized learning algorithm aims to compute an equilibrium by controlling multiple agents that interact with an unknown environment. Our main contributions are:  - We provide upper and lower bounds on the optimal sample complexity for multi-agent decision making based on a multi-agent generalization of the Decision-Estimation Coefficient, a complexity measure introduced by Foster et al. (2021) in the single-agent counterpart to our setting. Compared to the best results for the sin
    
[^10]: 带误差校正的沉积计算：随机动力学系统的长期行为研究

    Reservoir Computing with Error Correction: Long-term Behaviors of Stochastic Dynamical Systems. (arXiv:2305.00669v1 [math.DS])

    [http://arxiv.org/abs/2305.00669](http://arxiv.org/abs/2305.00669)

    本文提出了一种数据驱动的框架，将沉积计算和归一化流结合起来以研究随机动力学系统的预测和动力学行为，成功地预测了长期演化并复制了动力学行为。

    

    随机动力学系统的预测和动力学行为的捕捉是一个深刻的问题。在本文中，我们提出了一种数据驱动框架，将沉积计算和归一化流结合起来研究这个问题，它模仿误差建模来提高传统沉积计算的性能，并充分利用了两种方法的优点。这种无模型方法成功地预测了随机动力学系统的长期演化，并复制了动力学行为。

    The prediction of stochastic dynamical systems and the capture of dynamical behaviors are profound problems. In this article, we propose a data-driven framework combining Reservoir Computing and Normalizing Flow to study this issue, which mimics error modeling to improve the traditional Reservoir Computing performance and takes advantage of both approaches. This model-free method successfully predicts the long-term evolution of stochastic dynamical systems and replicates dynamical behaviors. With few assumptions about the underlying stochastic dynamical systems, we deal with Markov/non-Markov and stationary/non-stationary stochastic processes defined by linear/nonlinear stochastic differential equations or stochastic delay differential equations. We verify the effectiveness of the proposed framework in five experiments, including the Ornstein-Uhlenbeck process, Double-Well system, El Ni\~no Southern Oscillation simplified model, and stochastic Lorenz system. Additionally, we explore th
    
[^11]: 使用RePU激活函数的可微分神经网络：在得分估计和保序回归中的应用。

    Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression. (arXiv:2305.00608v1 [stat.ML])

    [http://arxiv.org/abs/2305.00608](http://arxiv.org/abs/2305.00608)

    该论文介绍了使用RePU激活函数的可微分神经网络，在近似$C^s$平滑函数及其导数的同时建立了下限误差界，并证明了其在降低维度灾难方面的能力，此外还提出了一种使用RePU网络的惩罚保序回归(PDIR)方法。

    

    我们研究了由修正后的幂单元（RePU）函数激活的可微分神经网络的属性。我们展示了RePU神经网络的偏导数可以由混合激活RePU网络来表示，并推导了导数RePU网络函数类的复杂度的上界。在使用RePU激活的深度神经网络中，我们建立了同时近似$C^s$平滑函数及其导数的误差界。此外，当数据具有近似低维支持时，我们推导出改进的逼近误差界，证明了RePU网络减缓维度灾难的能力。为了说明我们的结果的实用性，我们考虑了深度得分匹配估计器(DSME)，并提出了一种使用RePU网络的惩罚保序回归(PDIR)。我们在假定目标函数属于$C^s$平滑函数类的情况下为DSME和PDIR建立非渐近超额风险界。

    We study the properties of differentiable neural networks activated by rectified power unit (RePU) functions. We show that the partial derivatives of RePU neural networks can be represented by RePUs mixed-activated networks and derive upper bounds for the complexity of the function class of derivatives of RePUs networks. We establish error bounds for simultaneously approximating $C^s$ smooth functions and their derivatives using RePU-activated deep neural networks. Furthermore, we derive improved approximation error bounds when data has an approximate low-dimensional support, demonstrating the ability of RePU networks to mitigate the curse of dimensionality. To illustrate the usefulness of our results, we consider a deep score matching estimator (DSME) and propose a penalized deep isotonic regression (PDIR) using RePU networks. We establish non-asymptotic excess risk bounds for DSME and PDIR under the assumption that the target functions belong to a class of $C^s$ smooth functions. We 
    
[^12]: ISAAC Newton：牛顿法的基于输入的近似曲率

    ISAAC Newton: Input-based Approximate Curvature for Newton's Method. (arXiv:2305.00604v1 [cs.LG])

    [http://arxiv.org/abs/2305.00604](http://arxiv.org/abs/2305.00604)

    ISAAC Newton方法提出了一种使用选择的二阶信息调整梯度的方法，并且在选择批量大小小于神经元数量的情况下，计算开销消失，能够在小批量随机情况下有效训练。

    

    我们提出了ISAAC（Input-baSed ApproximAte Curvature），该方法使用选择的二阶信息来调整梯度，并且在批量大小小于神经元数量的情况下具有渐近消失的计算开销。我们展示了在仅基于相应层的输入而不需要实质性计算开销的情况下，计算出一个良好的调节器是可能的。所提出的方法允许在小批量随机情况下有效训练，这使它与一阶以及二阶方法具有竞争力。

    We present ISAAC (Input-baSed ApproximAte Curvature), a novel method that conditions the gradient using selected second-order information and has an asymptotically vanishing computational overhead, assuming a batch size smaller than the number of neurons. We show that it is possible to compute a good conditioner based on only the input to a respective layer without a substantial computational overhead. The proposed method allows effective training even in small-batch stochastic regimes, which makes it competitive to first-order as well as second-order methods.
    
[^13]: 转移学习艺术：一种自适应和稳健的管道

    The ART of Transfer Learning: An Adaptive and Robust Pipeline. (arXiv:2305.00520v1 [stat.ML])

    [http://arxiv.org/abs/2305.00520](http://arxiv.org/abs/2305.00520)

    本文提出了自适应稳健转移学习（ART）管道，使用通用机器学习算法实现转移学习，建立了非渐近学习理论，同时防止负面转移，并演示了它在回归、分类和稀疏学习上的良好性能。

    

    转移学习是利用辅助数据资源来提高主要任务性能的重要工具。在本文中，我们提出自适应稳健转移学习（ART），一种使用通用机器学习算法进行转移学习的灵活管道。我们建立了ART的非渐近学习理论，为实现自适应转移并防止负面转移提供了可证明的理论保证。此外，我们介绍了一种ART集成聚合机制，用于在考虑多个候选算法时产生单个最终模型。通过回归、分类和稀疏学习的广泛实证研究，我们展示了ART的良好性能。我们进一步提出了一个涉及死亡率研究的真实数据分析。

    Transfer learning is an essential tool for improving the performance of primary tasks by leveraging information from auxiliary data resources. In this work, we propose Adaptive Robust Transfer Learning (ART), a flexible pipeline of performing transfer learning with generic machine learning algorithms. We establish the non-asymptotic learning theory of ART, providing a provable theoretical guarantee for achieving adaptive transfer while preventing negative transfer. Additionally, we introduce an ART-integrated-aggregating machine that produces a single final model when multiple candidate algorithms are considered. We demonstrate the promising performance of ART through extensive empirical studies on regression, classification, and sparse learning. We further present a real-data analysis for a mortality study.
    
[^14]: 域不可知傅里叶神经算子

    Domain Agnostic Fourier Neural Operators. (arXiv:2305.00478v1 [cs.LG])

    [http://arxiv.org/abs/2305.00478](http://arxiv.org/abs/2305.00478)

    介绍了一种新的神经算子架构 DAFNO，可以学习带有不规则几何和不断变化的域的代理。通过将平滑化的特征函数纳入 FNOs 的积分层架构中，并利用 FFT 来实现快速计算，以明确的方式将几何信息编码到架构中，DAFNO 相对于基线神经算子模型具有最先进的精度。

    

    傅里叶神经算子（FNOs）能够学习在函数空间之间高度非线性的映射，最近已成为学习复杂物理系统响应的热门工具。然而，为了实现良好的精度和效率，FNOs 依赖于快速傅里叶变换 (FFT)，该变换仅限于矩形域上的建模问题。为了消除这样的限制，允许 FFT 在不规则几何以及拓扑变化中使用，我们引入了域不可知傅里叶神经算子 (DAFNO)，一种用于学习带有不规则几何和不断变化的域的代理的新的神经算子架构。关键思想是将平滑化的特征函数纳入 FNOs 的积分层架构中，并利用 FFT 来实现快速计算，以便以明确的方式将几何信息编码到架构中。在我们的实证评估中，DAFNO 相对于基线神经算子模型具有最先进的精度。

    Fourier neural operators (FNOs) can learn highly nonlinear mappings between function spaces, and have recently become a popular tool for learning responses of complex physical systems. However, to achieve good accuracy and efficiency, FNOs rely on the Fast Fourier transform (FFT), which is restricted to modeling problems on rectangular domains. To lift such a restriction and permit FFT on irregular geometries as well as topology changes, we introduce domain agnostic Fourier neural operator (DAFNO), a novel neural operator architecture for learning surrogates with irregular geometries and evolving domains. The key idea is to incorporate a smoothed characteristic function in the integral layer architecture of FNOs, and leverage FFT to achieve rapid computations, in such a way that the geometric information is explicitly encoded in the architecture. In our empirical evaluation, DAFNO has achieved state-of-the-art accuracy as compared to baseline neural operator models on two benchmark dat
    
[^15]: 基于全局预测模型预测准确性的时间序列聚类方法

    Time series clustering based on prediction accuracy of global forecasting models. (arXiv:2305.00473v1 [stat.ML])

    [http://arxiv.org/abs/2305.00473](http://arxiv.org/abs/2305.00473)

    本论文提出了一种基于预测准确性的时间序列聚类新方法，可以用于选择时间序列数据库中的聚类数，并且比传统方法更好。

    

    本文提出了一种基于模型的时间序列聚类新方法。该方法依赖于两个迭代步骤：（i）通过考虑每个簇所涉及的时序，并由 pooling（集中）拟合 K 个全局预测模型；（ii）每个序列被分配到产生最佳预测的模型关联的组。与文献中大多数技术不同，该方法将预测准确性作为构建聚类分区的主要元素，其中包含共同最小化总体预测误差的组。因此，该方法导致了一个新的聚类范式，其中聚类解的质量是通过其预测能力来衡量的。此外，该过程还引起了在时间序列数据库中选择聚类数的有效机制，并且可以与任何回归模型类结合使用。广泛的模拟研究表明，该方法是要比传统方法更加好的选择。

    In this paper, a novel method to perform model-based clustering of time series is proposed. The procedure relies on two iterative steps: (i) K global forecasting models are fitted via pooling by considering the series pertaining to each cluster and (ii) each series is assigned to the group associated with the model producing the best forecasts according to a particular criterion. Unlike most techniques proposed in the literature, the method considers the predictive accuracy as the main element for constructing the clustering partition, which contains groups jointly minimizing the overall forecasting error. Thus, the approach leads to a new clustering paradigm where the quality of the clustering solution is measured in terms of its predictive capability. In addition, the procedure gives rise to an effective mechanism for selecting the number of clusters in a time series database and can be used in combination with any class of regression model. An extensive simulation study shows that o
    
[^16]: 一种用于分类时间序列的新自助法检验。一项比较研究。

    New bootstrap tests for categorical time series. A comparative study. (arXiv:2305.00465v1 [stat.ME])

    [http://arxiv.org/abs/2305.00465](http://arxiv.org/abs/2305.00465)

    本文提出了三种用于测试两个分类时间序列生成过程平等性的自助法。通过分析三种方法的等值性和差异，我们评估了它们在不同复杂度程度的分类模型下的性能表现。

    

    本文解决了测试两个分类时间序列生成过程平等性的问题。为了达到这个目的，我们提出了三种基于分类过程之间差异的测试方法。考虑到两个序列的边际分布和序列依赖模式之间的差异，我们构造了特定版本的这些测试方法。构建的测试方法的重要部分是这些差异的适当估计，这些估计是基于自助法的。具体而言，我们考虑了一个假设真是生成模型的参数自助法，以及移动块自助法和静态自助法的扩展。我们在包括具有不同复杂度程度的多种分类模型的广泛模拟研究中评估了这些方法的性能。根据它们在零假设和备择假设下以及功率下的表现，我们适当地讨论了每种方法的优缺点。

    The problem of testing the equality of the generating processes of two categorical time series is addressed in this work. To this aim, we propose three tests relying on a dissimilarity measure between categorical processes. Particular versions of these tests are constructed by considering three specific distances evaluating discrepancy between the marginal distributions and the serial dependence patterns of both processes. Proper estimates of these dissimilarities are an essential element of the constructed tests, which are based on the bootstrap. Specifically, a parametric bootstrap method assuming the true generating models and extensions of the moving blocks bootstrap and the stationary bootstrap are considered. The approaches are assessed in a broad simulation study including several types of categorical models with different degrees of complexity. Advantages and disadvantages of each one of the methods are properly discussed according to their behavior under the null and the alter
    
[^17]: 有限状态不想静止多臂赌博机和Rollout策略的可索引性

    Indexability of Finite State Restless Multi-Armed Bandit and Rollout Policy. (arXiv:2305.00410v1 [cs.LG])

    [http://arxiv.org/abs/2305.00410](http://arxiv.org/abs/2305.00410)

    本文研究了有限状态不想静止多臂赌博机问题，提出了一种应用rollout策略的算法来解决问题，并且在单臂赌博机模型上展示了结构结果和可索引性。

    

    本文研究了有限状态不想静止多臂赌博机问题。决策者可以在每个时间步骤中选择M个臂中的任意一个，臂的播放产生基于动作的状态相关奖励，当臂没有被播放时，它还提供基于状态和动作的奖励。决策者的目标是最大化无限时间长度的折扣奖励。传统的不想静止赌博机方法是使用 Whittle 索引策略。在这种策略中，每个时间步骤播放具有最高指数的M个臂。我们将不想静止赌博机问题分离成分析松弛约束不想静止赌博机问题。然后通过拉格朗日松弛问题，将不想静止赌博机问题分离成N个单臂不想静止赌博机问题。我们分析了单臂不想静止赌博机。为了研究 Whittle 索引策略，我们在单臂赌博机模型上展示了结构结果。我们定义了可索引性，并在特定情况下展示了可索引性。我们提出了一种应用rollout策略的算法来解决问题。

    We consider finite state restless multi-armed bandit problem. The decision maker can act on M bandits out of N bandits in each time step. The play of arm (active arm) yields state dependent rewards based on action and when the arm is not played, it also provides rewards based on the state and action. The objective of the decision maker is to maximize the infinite horizon discounted reward. The classical approach to restless bandits is Whittle index policy. In such policy, the M arms with highest indices are played at each time step. Here, one decouples the restless bandits problem by analyzing relaxed constrained restless bandits problem. Then by Lagrangian relaxation problem, one decouples restless bandits problem into N single-armed restless bandit problems. We analyze the single-armed restless bandit. In order to study the Whittle index policy, we show structural results on the single armed bandit model. We define indexability and show indexability in special cases. We propose an al
    
[^18]: 基于顺序实验的最优检验方法

    Optimal tests following sequential experiments. (arXiv:2305.00403v1 [econ.EM])

    [http://arxiv.org/abs/2305.00403](http://arxiv.org/abs/2305.00403)

    本文分析了基于顺序实验的最优检验方法，重要发现是任何检验的渐近功率函数都可以与一种极限实验中匹配的检验相匹配，这个结果有重要的意义，包括一个强大的充分性结果。

    

    近年来，顺序实验的理论和应用取得了巨大进展。虽然这些实验不一定是为了进行假设检验而设计的，但研究人员仍然可能对实验完成后的检验感兴趣。本文的目的是通过分析它们的渐近性质来帮助发展顺序实验的最优检验方法。我们的关键发现是，任何检验的渐近功率函数都可以与极限实验中匹配的检验相匹配，在这个极限实验中，对于每种处理，观察产生一个高斯过程，并对这些过程的漂移进行推断。这个结果有重要的意义，包括一个强大的充分性结果：任何候选检验方法只需要依赖于一组固定的统计量，而不是顺序实验的类型。这些统计量是每种处理在实验结束时被采样的次数，以及得分的最终值（对于参数模型）

    Recent years have seen tremendous advances in the theory and application of sequential experiments. While these experiments are not always designed with hypothesis testing in mind, researchers may still be interested in performing tests after the experiment is completed. The purpose of this paper is to aid in the development of optimal tests for sequential experiments by analyzing their asymptotic properties. Our key finding is that the asymptotic power function of any test can be matched by a test in a limit experiment where a Gaussian process is observed for each treatment, and inference is made for the drifts of these processes. This result has important implications, including a powerful sufficiency result: any candidate test only needs to rely on a fixed set of statistics, regardless of the type of sequential experiment. These statistics are the number of times each treatment has been sampled by the end of the experiment, along with final value of the score (for parametric models)
    
[^19]: POUF: 面向提示的无监督大型预训练模型微调

    POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained models. (arXiv:2305.00350v1 [cs.LG])

    [http://arxiv.org/abs/2305.00350](http://arxiv.org/abs/2305.00350)

    本文提出了一种基于提示的无监督微调框架，可以在未标记的目标数据上微调大型预训练模型以适应下游任务，实验结果表明该方法在图像分类、情感分析和自然语言推理等任务中表现更好。

    

    通过提示，大规模预训练模型在近年来变得更加表现出色和强大。虽然这些大型模型具有零-shot 能力，但通常仍需要有标签的数据来适应下游任务。为了克服这个关键限制，我们提出了一种无监督微调框架，直接在未标记的目标数据上微调模型或提示。我们演示如何将该方法应用于语言增强的视觉和掩蔽语言模型，通过对齐从提示和目标数据中提取的离散分布来实现。为了验证我们方法的适用性，我们对图像分类、情感分析和自然语言推理任务进行了广泛的实验。在 13 个与图像相关的任务和 15 个与语言相关的任务中，该方法均比基线表现更好。

    Through prompting, large-scale pre-trained models have become more expressive and powerful, gaining significant attention in recent years. Though these big models have zero-shot capabilities, in general, labeled data are still required to adapt them to downstream tasks. To overcome this critical limitation, we propose an unsupervised fine-tuning framework to directly fine-tune the model or prompt on the unlabeled target data. We demonstrate how to apply our method to both language-augmented vision and masked-language models by aligning the discrete distributions extracted from the prompts and target data. To verify our approach's applicability, we conduct extensive experiments on image classification, sentiment analysis, and natural language inference tasks. Across 13 image-related tasks and 15 language-related ones, the proposed approach achieves consistent improvements over the baselines.
    
[^20]: 用稀疏矩阵表示加性高斯过程

    Representing Additive Gaussian Processes by Sparse Matrices. (arXiv:2305.00324v1 [stat.ML])

    [http://arxiv.org/abs/2305.00324](http://arxiv.org/abs/2305.00324)

    本研究展示了对于加性Matérn高斯过程，通过稀疏矩阵和向量的公式可以有效地计算后验均值、后验方差、对数似然和梯度。

    

    在广义相加模型中，加性Matérn高斯过程是最受欢迎的可扩展高维问题之一。由于它们的加性结构和随机微分方程表示，基于回归的算法可以将计算后验均值的时间复杂度从$O（n^3）$减少到$O（nlogn）$时间，其中$n$是数据大小。但是，将这些算法推广到有效计算后验方差和最大对数似然仍然是一个未解决的问题。在本研究中，我们展示了对于加性Matérn高斯过程，不仅后验均值，而且后验方差、对数似然和这三个函数的梯度可以用仅涉及稀疏矩阵和稀疏向量的公式表示。我们展示了如何使用这些稀疏公式来推广回归算法，以有效计算这三个函数的后验均值、后验方差、对数似然和梯度。

    Among generalized additive models, additive Mat\'ern Gaussian Processes (GPs) are one of the most popular for scalable high-dimensional problems. Thanks to their additive structure and stochastic differential equation representation, back-fitting-based algorithms can reduce the time complexity of computing the posterior mean from $O(n^3)$ to $O(n\log n)$ time where $n$ is the data size. However, generalizing these algorithms to efficiently compute the posterior variance and maximum log-likelihood remains an open problem. In this study, we demonstrate that for Additive Mat\'ern GPs, not only the posterior mean, but also the posterior variance, log-likelihood, and gradient of these three functions can be represented by formulas involving only sparse matrices and sparse vectors. We show how to use these sparse formulas to generalize back-fitting-based algorithms to efficiently compute the posterior mean, posterior variance, log-likelihood, and gradient of these three functions for additiv
    
[^21]: 一种耦合流方法用于模仿学习

    A Coupled Flow Approach to Imitation Learning. (arXiv:2305.00303v1 [cs.LG])

    [http://arxiv.org/abs/2305.00303](http://arxiv.org/abs/2305.00303)

    本文提出了一种新的模仿学习算法Coupled Flow Imitation Learning（CFIL），使用正则流模型的分布匹配来建模状态分布和状态行为分布。在基准任务中具有单个专家轨迹表现出最先进的性能。

    

    在强化学习和模仿学习中，策略引起的状态分布是一个非常重要的对象。它在策略梯度定理中起着至关重要的作用，并且与相关的状态行为分布一起被广泛引用。尽管状态分布非常重要，但它大多是间接地和理论上讨论，而不是明确地建模。原因是缺乏适当的密度估计工具。在这项工作中，我们研究了基于正则流模型的上述分布应用。特别是，我们使用通过Donsker-Varadhan表示的Kullback-Leibler（KL）散度的最优点耦合的一对流进行分布匹配的模仿学习。我们的算法Coupled Flow Imitation Learning（CFIL）在具有单个专家轨迹的基准任务上实现了最先进的性能，并且自然地扩展到各种形式的专家演示。

    In reinforcement learning and imitation learning, an object of central importance is the state distribution induced by the policy. It plays a crucial role in the policy gradient theorem, and references to it--along with the related state-action distribution--can be found all across the literature. Despite its importance, the state distribution is mostly discussed indirectly and theoretically, rather than being modeled explicitly. The reason being an absence of appropriate density estimation tools. In this work, we investigate applications of a normalizing flow-based model for the aforementioned distributions. In particular, we use a pair of flows coupled through the optimality point of the Donsker-Varadhan representation of the Kullback-Leibler (KL) divergence, for distribution matching based imitation learning. Our algorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to a varie
    
[^22]: EBLIME: 增强的贝叶斯本地可解释模型无关解释方法

    EBLIME: Enhanced Bayesian Local Interpretable Model-agnostic Explanations. (arXiv:2305.00213v1 [stat.ML])

    [http://arxiv.org/abs/2305.00213](http://arxiv.org/abs/2305.00213)

    本文提出了EBLIME方法，使用贝叶斯岭回归模型从黑盒机器学习模型中解释特征重要性的分布，实验结果表明该方法比现有最先进方法具有更好的解释能力和不确定性量化能力。

    

    本文提出了EBLIME来解释黑盒机器学习模型，并使用贝叶斯岭回归模型获得特征重要性的分布。我们提供了贝叶斯框架的数学表达式和理论结果，包括岭参数的显著性。我们对基准数据集和实际工业应用案例进行了案例研究，涉及定位制造产品内部缺陷。与现有最先进方法相比，EBLIME产生更直观和准确的结果，具有更好的不确定性量化能力，包括生成后验分布、可信区间和特征重要性排名。

    We propose EBLIME to explain black-box machine learning models and obtain the distribution of feature importance using Bayesian ridge regression models. We provide mathematical expressions of the Bayesian framework and theoretical outcomes including the significance of ridge parameter. Case studies were conducted on benchmark datasets and a real-world industrial application of locating internal defects in manufactured products. Compared to the state-of-the-art methods, EBLIME yields more intuitive and accurate results, with better uncertainty quantification in terms of deriving the posterior distribution, credible intervals, and rankings of the feature importance.
    
[^23]: 基于数据驱动的线性回归子群识别

    Data-Driven Subgroup Identification for Linear Regression. (arXiv:2305.00195v1 [cs.LG])

    [http://arxiv.org/abs/2305.00195](http://arxiv.org/abs/2305.00195)

    本文提出了一个基于数据驱动方法的DDGroup，可以有效地识别具有特征与标签之间统一线性关系的子群，为医学研究提供了一种新的统计工具。

    

    医学研究常常需要提取每个协变量与结果之间的关系，并使用统计置信度测量。为此，通常使用简单的参数模型（例如线性回归系数），但通常是在整个数据集上拟合。然而，协变量可能在整个人口中没有统一的影响，因此统一的简单模型可能会漏掉异质信号。在本文中，我们提出了基于数据驱动方法的DDGroup (data-driven group discovery)，以有效识别数据中具有特征与标签之间统一线性关系的子群。DDGroup输出的区域是可以解释的，而且在计算上易于实现，适用于使用。理论上我们证明，如果给定足够大的样本，DDGroup保证可以找到具有统一线性关系的子群。我们还在模拟数据集和真实的医学数据集上证明了DDGroup的有效性。

    Medical studies frequently require to extract the relationship between each covariate and the outcome with statistical confidence measures. To do this, simple parametric models are frequently used (e.g. coefficients of linear regression) but usually fitted on the whole dataset. However, it is common that the covariates may not have a uniform effect over the whole population and thus a unified simple model can miss the heterogeneous signal. For example, a linear model may be able to explain a subset of the data but fail on the rest due to the nonlinearity and heterogeneity in the data. In this paper, we propose DDGroup (data-driven group discovery), a data-driven method to effectively identify subgroups in the data with a uniform linear relationship between the features and the label. DDGroup outputs an interpretable region in which the linear model is expected to hold. It is simple to implement and computationally tractable for use. We show theoretically that, given a large enough samp
    
[^24]: 转移学习下的模型选择限制

    Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v1 [stat.ML])

    [http://arxiv.org/abs/2305.00152](http://arxiv.org/abs/2305.00152)

    这篇论文介绍了在转移学习下模型选择存在的限制，其转移距离会影响自适应速率，可能导致速率较慢。

    

    目前，关于转移学习或领域自适应的理论研究主要关注已知假设类或模型的情况；然而，在实践中，通常涉及一定程度的模型选择，这经常出现在超参数调整的总体范畴下：例如，我们可以考虑调整针对目标任务的正确神经网络架构的问题，同时利用来自相关源任务的数据。除了与模型选择有关的近似与估计误差的通常权衡之外，这个问题还带来了新的复杂度，即源分布与目标分布之间的转移距离，这个距离随着假设类的选择而发生变化。我们首次研究了这个问题，重点关注分类问题。特别的，分析揭示了一些引人注目的现象：自适应速率，即没有分布式信息时可达到的速率，可以任意慢于oracle速率，即在给定知识的情况下。

    Theoretical studies on transfer learning or domain adaptation have so far focused on situations with a known hypothesis class or model; however in practice, some amount of model selection is usually involved, often appearing under the umbrella term of hyperparameter-tuning: for example, one may think of the problem of tuning for the right neural network architecture towards a target task, while leveraging data from a related source task.  Now, in addition to the usual tradeoffs on approximation vs estimation errors involved in model selection, this problem brings in a new complexity term, namely, the transfer distance between source and target distributions, which is known to vary with the choice of hypothesis class.  We present a first study of this problem, focusing on classification; in particular, the analysis reveals some remarkable phenomena: adaptive rates, i.e., those achievable with no distributional information, can be arbitrarily slower than oracle rates, i.e., when given kn
    
[^25]: 顺序预测双样本和独立性检验

    Sequential Predictive Two-Sample and Independence Testing. (arXiv:2305.00143v1 [stat.ML])

    [http://arxiv.org/abs/2305.00143](http://arxiv.org/abs/2305.00143)

    本文提出了一种基于预测的赌博策略来解决高维或结构化数据下非参数双样本和独立性检验问题。

    

    我们研究了顺序非参数双样本和独立性检验的问题。顺序检验在线处理数据，允许使用观察到的数据来决定是否停止并拒绝原假设，或在保持类型I错误控制的同时收集更多数据。我们建立在(非参数)测试赌博原则之上，其中赌徒在未来观察中下注，他们的财富对证据反对原假设进行衡量。最近开发的基于核的赌博策略在简单分布上通常表现良好，但对于高维或结构化数据（如文本和图像）选择合适的核通常是棘手的。为解决这个问题，我们设计了基于预测的赌博策略，依赖于以下事实：如果一个顺序更新的预测器开始一致地确定(a)一个实例从哪个分布中绘制，或者(b)一个实例是从联合分布还是从边缘分布的乘积中绘制的，则分布是不同或相关的。我们的方法灵活，并对基础数据分布和维度不可知，同时保持一定的最优性保证。我们在模拟和实际数据上演示了我们的顺序测试框架的有效性。

    We study the problems of sequential nonparametric two-sample and independence testing. Sequential tests process data online and allow using observed data to decide whether to stop and reject the null hypothesis or to collect more data while maintaining type I error control. We build upon the principle of (nonparametric) testing by betting, where a gambler places bets on future observations and their wealth measures evidence against the null hypothesis. While recently developed kernel-based betting strategies often work well on simple distributions, selecting a suitable kernel for high-dimensional or structured data, such as text and images, is often nontrivial. To address this drawback, we design prediction-based betting strategies that rely on the following fact: if a sequentially updated predictor starts to consistently determine (a) which distribution an instance is drawn from, or (b) whether an instance is drawn from the joint distribution or the product of the marginal distributio
    
[^26]: 多类分类中敌对训练解的存在性研究

    On the existence of solutions to adversarial training in multiclass classification. (arXiv:2305.00075v1 [cs.LG])

    [http://arxiv.org/abs/2305.00075](http://arxiv.org/abs/2305.00075)

    本文研究了多类分类中敌对训练的鲁棒解存在性问题，证明了每个模型中存在 Borel 可测的鲁棒分类器，并与最优传输和总变差正则化建立了联系。在二元分类问题中，对不可知分类器的敌对训练问题存在 Borel 可测的解。

    

    本文研究了敌对训练在多类分类问题中的三种模型，旨在构建对抗扰动下鲁棒的分类器。我们证明了每个模型中存在 Borel 可测的鲁棒分类器，并提供了敌对训练问题的统一视角，拓展了作者之前的最优传输联系，并在多类情况下敌对训练和总变差正则化之间建立了新的联系。作为我们结果的推论，我们证明了在二元分类设置中，对不可知分类器的敌对训练问题存在 Borel 可测的解，这一结果改进了关于敌对训练的文献，文献中仅已知只有在特征空间的扩大通用 $σ$-代数内存在鲁棒的分类器。

    We study three models of the problem of adversarial training in multiclass classification designed to construct robust classifiers against adversarial perturbations of data in the agnostic-classifier setting. We prove the existence of Borel measurable robust classifiers in each model and provide a unified perspective of the adversarial training problem, expanding the connections with optimal transport initiated by the authors in previous work and developing new connections between adversarial training in the multiclass setting and total variation regularization. As a corollary of our results, we prove the existence of Borel measurable solutions to the agnostic adversarial training problem in the binary classification setting, a result that improves results in the literature of adversarial training, where robust classifiers were only known to exist within the enlarged universal $\sigma$-algebra of the feature space.
    
[^27]: 在线Platt缩放及其校准方法

    Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])

    [http://arxiv.org/abs/2305.00070](http://arxiv.org/abs/2305.00070)

    本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。

    

    我们提出了一种在线后校准方法，称为在线Platt缩放(OPS)，它将Platt缩放技术与在线逻辑回归相结合。我们展示了OPS如何在分布漂移的i.i.d.和非i.i.d.情况下平稳适应。此外，当最佳的Platt缩放模型本身被错误校准时，我们使用一种最近开发的称为calibeating的技术来增强OPS，使其更加鲁棒。理论上，我们得到的OPS+calibeating方法对于对抗性结果序列是保证校准的。在实验上，它在一系列合成和真实数据集上均表现出卓越的性能，无需超参数调整。最后，我们将所有OPS思想扩展到beta缩放方法。

    We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.
    
[^28]: LAVA: 无需预定学习算法的数据价值评估

    LAVA: Data Valuation without Pre-Specified Learning Algorithms. (arXiv:2305.00054v1 [cs.LG])

    [http://arxiv.org/abs/2305.00054](http://arxiv.org/abs/2305.00054)

    LAVA是一个学习算法无关的数据价值评估方法，它结合了学习算法的统计特性和训练数据的属性，通过迭代估计数据值来实现。LAVA比现有方法计算速度更快，精度更高，并且可以为不同的应用提供有意义的数据排名。

    

    传统的数据价值评估问题是如何公平地分配学习算法的验证性能，致使计算得到的数据价值依赖于底层学习算法的许多设计选择。本文提出了一种新的框架LAVA，该框架结合了学习算法的统计特性和训练数据的属性，迭代估计数据值，使其无视下游的学习算法。我们展示了LAVA比现有方法计算速度更快，精度更高，并且它可以为不同的应用提供有意义的数据排名。

    Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden.  This work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning
    
[^29]: 强健的随机预处理方法解决核岭回归问题

    Robust, randomized preconditioning for kernel ridge regression. (arXiv:2304.12465v1 [math.NA])

    [http://arxiv.org/abs/2304.12465](http://arxiv.org/abs/2304.12465)

    针对核岭回归问题，本文引入了两种强健的随机预处理技术，分别解决了全数据KRR问题和限制版KRR问题，克服了以往预处理器的故障模式。

    

    本论文介绍了两种随机预处理技术，用于强健地解决具有中大规模数据点（$10^4 \leq N \leq 10^7$）的核岭回归（KRR）问题。第一种方法，RPCholesky预处理，能够在假设核矩阵特征值有足够快速的多项式衰减的情况下，以$O（N ^ 2）$算法操作准确地解决全数据KRR问题。第二种方法，KRILL预处理，以$O（（N + k ^ 2）k \ logk）$的代价，为KRR问题的限制版本提供准确的解决方案，该版本涉及$k \ll N$选择的数据中心。所提出的方法解决了广泛的KRR问题，克服了以前的KRR预处理器的故障模式，使它们成为实际应用的理想选择。

    This paper introduces two randomized preconditioning techniques for robustly solving kernel ridge regression (KRR) problems with a medium to large number of data points ($10^4 \leq N \leq 10^7$). The first method, RPCholesky preconditioning, is capable of accurately solving the full-data KRR problem in $O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of the kernel matrix eigenvalues. The second method, KRILL preconditioning, offers an accurate solution to a restricted version of the KRR problem involving $k \ll N$ selected data centers at a cost of $O((N + k^2) k \log k)$ operations. The proposed methods solve a broad range of KRR problems and overcome the failure modes of previous KRR preconditioners, making them ideal for practical applications.
    
[^30]: 多级扩散：图像生成的无限维度基于得分的扩散模型

    Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation. (arXiv:2303.04772v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04772](http://arxiv.org/abs/2303.04772)

    本文介绍了无限维度得分扩散模型在多个分辨率水平上的离散化方法，并使用多级扩散算法在多个分辨率上高效地学习。实证表明，该模型在相同或更高分辨率下产生比传统基于得分的扩散模型更高质量的样本，并可以生成不同分辨率的图像并处理矩形域。

    

    基于得分的扩散模型是近年来图像生成的最先进方法之一。现有的基于得分的扩散模型通常在有限维度设置中表述，其中图像被视为具有有限尺寸的张量。本文在无限维度设置中开发了基于得分的扩散模型，即我们将训练数据建模为支撑在矩形域上的函数。除了追求在更高分辨率下生成图像之外，我们的主要动机是创建一个良好定义的无限维度学习问题，以便可以在多个分辨率水平上一致地离散化它。我们希望获得能够横跨不同分辨率级别的扩散模型，并提高训练过程的效率。我们展示了如何克服当前基于得分的扩散模型在无限维度设置中存在的两个缺点。首先，我们修改了前向过程以确保在无限维度设置中潜在分布是良好定义的。其次，我们提出了一种多级扩散算法，使我们能够在多个分辨率上高效地学习。我们实证表明，我们的多级模型在相同或更高分辨率下产生比传统基于得分的扩散模型更高质量的样本。此外，我们的方法可以无缝地生成不同分辨率的图像并处理矩形域。

    Score-based diffusion models (SBDM) have recently emerged as state-of-the-art approaches for image generation. Existing SBDMs are typically formulated in a finite-dimensional setting, where images are considered as tensors of a finite size. This papers develops SBDMs in the infinite-dimensional setting, that is, we model the training data as functions supported on a rectangular domain. Besides the quest for generating images at ever higher resolution our primary motivation is to create a well-posed infinite-dimensional learning problem so that we can discretize it consistently on multiple resolution levels. We thereby hope to obtain diffusion models that generalize across different resolution levels and improve the efficiency of the training process. We demonstrate how to overcome two shortcomings of current SBDM approaches in the infinite-dimensional setting. First, we modify the forward process to ensure that the latent distribution is well-defined in the infinite-dimensional setting
    
[^31]: 缩小可用性差距：隐马尔可夫模型谱学习的理论与方法学进展

    Bridging the Usability Gap: Theoretical and Methodological Advances for Spectral Learning of Hidden Markov Models. (arXiv:2302.07437v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.07437](http://arxiv.org/abs/2302.07437)

    本文研究了隐马尔可夫模型谱学习中存在的问题，并提出了解决方案，包括提供了SHMM似然估计的误差渐近分布、提出投影SHMM算法可以减轻误差传播问题、并开发了SHMM和PSHMM的在线学习变体以适应潜在的非平稳性。研究结果表明PSHMM具有更好的性能表现。

    

    Baum-Welch（B-W）算法是推断隐马尔可夫模型(HMM)最广泛接受的方法。 然而，它很容易陷入局部最优，而且对于许多实时应用来说速度太慢。文献中提出了一种基于矩法（MOM）的HMM的谱学习（SHMM），旨在克服这些障碍。尽管有这样的承诺，但SHMM的渐近理论一直很难得到，而SHMM的长期性能可能会由于误差的无限传播而降低。在本文中，我们(1)提供了SHMM似然估计的近似误差的渐近分布，(2)提出了一种新算法称为投影SHMM（PSHMM），它可以减轻误差传播问题，(3)开发了SHMM和PSHMM的在线学习变体，以适应潜在的非平稳性。我们在模拟数据和来自真实世界应用的数据上比较了SHMM、PSHMM和B-W算法的性能。

    The Baum-Welch (B-W) algorithm is the most widely accepted method for inferring hidden Markov models (HMM). However, it is prone to getting stuck in local optima, and can be too slow for many real-time applications. Spectral learning of HMMs (SHMM), based on the method of moments (MOM) has been proposed in the literature to overcome these obstacles. Despite its promises, asymptotic theory for SHMM has been elusive, and the long-run performance of SHMM can degrade due to unchecked propagation of error. In this paper, we (1) provide an asymptotic distribution for the approximate error of the likelihood estimated by SHMM, (2) propose a novel algorithm called projected SHMM (PSHMM) that mitigates the problem of error propagation, and (3) develop online learning variants of both SHMM and PSHMM that accommodate potential nonstationarity. We compare the performance of SHMM with PSHMM and estimation through the B-W algorithm on both simulated data and data from real world applications, and fin
    
[^32]: 带干预的基于分数的因果表征学习

    Score-based Causal Representation Learning with Interventions. (arXiv:2301.08230v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.08230](http://arxiv.org/abs/2301.08230)

    本文研究了当潜在因果变量通过未知线性转换间接观察时的因果表征学习问题。其充分条件确保了干预效果可以从分数的变化中正确检测出来，并利用最小化分数函数变化的关键特性完美恢复有效变换。

    

    本文研究了当潜在因果变量通过未知线性转换间接观察时的因果表征学习问题。建立了DAG重构的充分条件，并表明潜在空间中的大类非线性模型满足这些条件，确保了干预效果可以从分数的变化中正确检测出来。利用最小化分数函数变化的关键特性，可以完美恢复有效变换。

    This paper studies the causal representation learning problem when the latent causal variables are observed indirectly through an unknown linear transformation. The objectives are: (i) recovering the unknown linear transformation (up to scaling) and (ii) determining the directed acyclic graph (DAG) underlying the latent variables. Sufficient conditions for DAG recovery are established, and it is shown that a large class of non-linear models in the latent space (e.g., causal mechanisms parameterized by two-layer neural networks) satisfy these conditions. These sufficient conditions ensure that the effect of an intervention can be detected correctly from changes in the score. Capitalizing on this property, recovering a valid transformation is facilitated by the following key property: any valid transformation renders latent variables' score function to necessarily have the minimal variations across different interventional environments. This property is leveraged for perfect recovery of 
    
[^33]: 学习高维单纯形在噪声环境下的样本复杂度界限

    Sample Complexity Bounds for Learning High-dimensional Simplices in Noisy Regimes. (arXiv:2209.05953v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.05953](http://arxiv.org/abs/2209.05953)

    本文解决了一个重要的开放性问题，提出了在噪声环境下从样本中学习单纯形的样本复杂度界限，并证明了只要信噪比较高，样本复杂度与无噪声情况具有相同的阶。

    

    本文研究了从含有噪声的样本中学习单纯形的样本复杂度。假设给定一个大小为$n$的数据集，其中包含从$\mathbb{R}^K$中的未知单纯形上均匀分布中独立同分布抽样的样本，假设这些样本被一个任意幅度的多元加性高斯噪声所污染。我们证明了存在一种算法，以高概率输出一个与真实单纯形的$\ell_2$距离最大为$\varepsilon$的单纯形（对于任意$\varepsilon>0$）。同时，我们在理论上证明，为了实现这个界限，需要有 $n\ge\left(K^2/\varepsilon^2\right)e^{\Omega\left(K/\mathrm{SNR}^2\right)}$ 个样本，其中 $\mathrm{SNR}$ 代表信噪比。这个结果解决了一个重要的开放性问题，并表明只要 $\mathrm{SNR}\ge\Omega\left(K^{1/2}\right)$，在噪声环境下的样本复杂度与无噪声情况具有相同的阶。本文的证明是各种工具的组合。

    In this paper, we find a sample complexity bound for learning a simplex from noisy samples. Assume a dataset of size $n$ is given which includes i.i.d. samples drawn from a uniform distribution over an unknown simplex in $\mathbb{R}^K$, where samples are assumed to be corrupted by a multi-variate additive Gaussian noise of an arbitrary magnitude. We prove the existence of an algorithm that with high probability outputs a simplex having a $\ell_2$ distance of at most $\varepsilon$ from the true simplex (for any $\varepsilon>0$). Also, we theoretically show that in order to achieve this bound, it is sufficient to have $n\ge\left(K^2/\varepsilon^2\right)e^{\Omega\left(K/\mathrm{SNR}^2\right)}$ samples, where $\mathrm{SNR}$ stands for the signal-to-noise ratio. This result solves an important open problem and shows as long as $\mathrm{SNR}\ge\Omega\left(K^{1/2}\right)$, the sample complexity of the noisy regime has the same order to that of the noiseless case. Our proofs are a combination 
    
[^34]: 拜占庭人也能从历史中学习：联邦学习中心化剪裁的衰落

    Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning. (arXiv:2208.09894v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09894](http://arxiv.org/abs/2208.09894)

    本文研究了中心化剪裁在面对不同恶意代理时的脆弱性，提出了一种称为多引用点剪裁 (MRPC) 的算法来解决这个问题。MRPC 框架利用多个参考点有效地中和专门设计的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。

    

    联邦学习 (FL) 框架由于在广泛的协作学习任务中的成功而越来越受欢迎，但也引起了某些安全问题。其中，拜占庭攻击的风险是特别关注的问题，这指的是恶意客户参与学习过程的可能性。因此，FL 中的一个关键目标是消除 Byzantine attacks 的潜在影响，确保最终模型是可信的。已经观察到，客户端的模型/更新之间的方差越大，隐藏 Byzantine attacks 的空间就越大。因此，通过使用动量，从而减少方差，可以削弱已知 Byzantine attacks 的力量。中心化剪裁 (CC) 框架进一步表明，上一次的动量项除了减少方差外，还可以作为一个参考点更好地消除 Byzantine attacks。在本文中，我们研究了在不同的恶意代理有不同目标时 CC 的脆弱性。我们提出了一种改进的剪裁算法称为多引用点剪裁 (MRPC)，以克服这种脆弱性。MRPC 框架有效地利用多个参考点来消除专门设计以绕过 CC 方法的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。

    The increasing popularity of the federated learning (FL) framework due to its success in a wide range of collaborative learning tasks also induces certain security concerns. Among many vulnerabilities, the risk of Byzantine attacks is of particular concern, which refers to the possibility of malicious clients participating in the learning process. Hence, a crucial objective in FL is to neutralize the potential impact of Byzantine attacks, and to ensure that the final model is trustable. It has been observed that the higher the variance among the clients' models/updates, the more space there is for Byzantine attacks to be hidden. As a consequence, by utilizing momentum, and thus, reducing the variance, it is possible to weaken the strength of known Byzantine attacks. The centered clipping (CC) framework has further shown that, the momentum term from the previous iteration, besides reducing the variance, can be used as a reference point to neutralize Byzantine attacks better. In this wor
    
[^35]: 一种符合保序的风险控制方法

    Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2208.02814](http://arxiv.org/abs/2208.02814)

    该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。

    

    我们将符合性预测推广至控制任何单调损失函数的期望值。该算法将分裂符合性预测及其覆盖保证进行了泛化。类似于符合性预测，符合保序的风险控制方法在$\mathcal{O}(1/n)$因子内保持紧密性。计算机视觉和自然语言处理领域的示例证明了我们算法在控制误报率、图形距离和令牌级F1得分方面的应用。

    We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
    
[^36]: 在不稳健样本上施加更多正则化以提高对抗性鲁棒性

    Improving adversarial robustness by putting more regularizations on less robust samples. (arXiv:2206.03353v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.03353](http://arxiv.org/abs/2206.03353)

    本文提出了一种新的对抗训练算法，通过在容易受到对抗攻击的数据上施加更多正则化以提高对抗性鲁棒性，得到了在准确性和鲁棒性方面均为最优的表现。

    

    对抗性训练是提高对抗攻击鲁棒性的一种方法，在人类视觉无法察觉的数据扰动下，使给定的深度神经网络产生误判。本文提出了一种新的对抗训练算法，它在理论上得到很好的证明，并且在实践中表现优于其他现有的算法。该算法的一个新的特点是：对于容易受到对抗攻击的数据，比其他现有的正则化算法更多地应用正则化。理论上，我们证明了我们的算法可以被理解为一个最小化经验风险的正则化算法，它来自一个新的鲁棒风险上界的动机。数值实验表明，我们提出的算法同时提高了泛化性能(在例子上的准确性)和鲁棒性(在对抗攻击上的准确性)，达到了最先进的性能水平。

    Adversarial training, which is to enhance robustness against adversarial attacks, has received much attention because it is easy to generate human-imperceptible perturbations of data to deceive a given deep neural network. In this paper, we propose a new adversarial training algorithm that is theoretically well motivated and empirically superior to other existing algorithms. A novel feature of the proposed algorithm is to apply more regularization to data vulnerable to adversarial attacks than other existing regularization algorithms do. Theoretically, we show that our algorithm can be understood as an algorithm of minimizing the regularized empirical risk motivated from a newly derived upper bound of the robust risk. Numerical experiments illustrate that our proposed algorithm improves the generalization (accuracy on examples) and robustness (accuracy on adversarial attacks) simultaneously to achieve the state-of-the-art performance.
    
[^37]: 复合实张量乘积的草图及其在多项式核上的应用

    Complex-to-Real Sketches for Tensor Products with Applications to the Polynomial Kernel. (arXiv:2202.02031v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.02031](http://arxiv.org/abs/2202.02031)

    本论文提出一种Complex-to-Real草图方法，用于处理复合实张量乘积，取得了在多项式核上最先进的准确性和速度表现。

    

    针对$p$个向量的张量积的随机草图遵循统计效率和计算加速之间的权衡。通常使用的方法避免显式计算高维张量积，导致在嵌入维度上具有亚最优的$\mathcal{O}(3^p)$依赖关系。我们提出了一个简单的Complex-to-Real (CtR)修改既有的草图，通过用复数替换实数随机投影，在嵌入维度上只需要较低的$\mathcal{O}(2^p)$因子。我们草图的输出是实值的，这使得它们的下游用途变得简单。特别地，我们将我们的草图应用于$p$倍自张量输入，这些输入对应于多项式内核的特征映射。我们展示了我们的方法与文献中其他随机逼近相比，在准确性和速度方面实现了最先进的性能。

    Randomized sketches of a tensor product of $p$ vectors follow a tradeoff between statistical efficiency and computational acceleration. Commonly used approaches avoid computing the high-dimensional tensor product explicitly, resulting in a suboptimal dependence of $\mathcal{O}(3^p)$ in the embedding dimension. We propose a simple Complex-to-Real (CtR) modification of well-known sketches that replaces real random projections by complex ones, incurring a lower $\mathcal{O}(2^p)$ factor in the embedding dimension. The output of our sketches is real-valued, which renders their downstream use straightforward. In particular, we apply our sketches to $p$-fold self-tensored inputs corresponding to the feature maps of the polynomial kernel. We show that our method achieves state-of-the-art performance in terms of accuracy and speed compared to other randomized approximations from the literature.
    
[^38]: 一种面向物联网的分布式功能压缩机器学习框架

    A Machine Learning Framework for Distributed Functional Compression over Wireless Channels in IoT. (arXiv:2201.09483v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.09483](http://arxiv.org/abs/2201.09483)

    本论文开发了一种面向物联网的分布式功能压缩机器学习框架，采用了能够任意计算IoT所需函数压缩任务的Kolmogorov-Arnold表示定理，解决了基于云的方法在传输数据时给网络资源带来的压力问题。

    

    物联网设备产生的海量数据和最新的机器学习技术将共同革新物理系统。在许多不同的领域中，从自动驾驶到增强现实，分布式物联网设备计算特定的目标函数，而这些目标函数并不像障碍物检测、物体识别等具有简单形式。传统的基于云的方法专注于将数据传输到中心位置进行训练或推理，这给网络资源带来了巨大的压力。为了解决这个问题，我们开发了目前为止我们所知道的第一个面向物联网的分布式功能压缩机器学习框架，可以在高斯多路访问信道（GMAC）和正交AWGN信道上进行。由于Kolmogorov-Arnold表示定理，我们的机器学习框架可以通过设计为IoT的所需函数压缩任务计算任意任意函数。重要的是原始感官数据永远不会传输到中心节点进行训练或推理。

    IoT devices generating enormous data and state-of-the-art machine learning techniques together will revolutionize cyber-physical systems. In many diverse fields, from autonomous driving to augmented reality, distributed IoT devices compute specific target functions without simple forms like obstacle detection, object recognition, etc. Traditional cloud-based methods that focus on transferring data to a central location either for training or inference place enormous strain on network resources. To address this, we develop, to the best of our knowledge, the first machine learning framework for distributed functional compression over both the Gaussian Multiple Access Channel (GMAC) and orthogonal AWGN channels. Due to the Kolmogorov-Arnold representation theorem, our machine learning framework can, by design, compute any arbitrary function for the desired functional compression task in IoT. Importantly the raw sensory data are never transferred to a central node for training or inference
    
[^39]: 一种用于深度高斯过程的稀疏展开方法

    A Sparse Expansion For Deep Gaussian Processes. (arXiv:2112.05888v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.05888](http://arxiv.org/abs/2112.05888)

    本文提出了一种基于高斯过程的稀疏展开方法，用于构建深度高斯过程模型。该方法可以提高计算效率，使得模型更加稀疏。

    

    本文针对具有复杂分布的随机过程，采用深度高斯过程（DGP）作为统计替代品。传统的DGP模型推断方法的计算复杂度很高，因为需要使用核矩阵进行大规模的训练和推断。本文提出了一种基于一系列高斯过程（TMGP）的准确推断和高效训练方案。我们构建了一个名为分层展开的TMGP诱导近似。接着，我们将多个TMGP的分层展开组合成一种称为深度TMGP（DTMGP）的模型。该模型具有以下特性：（1）每个激活函数的输出都是确定性的，而权重是从标准高斯分布中独立选择的；（2）在训练或预测中，只有polylog（M）（M个中的一部分）个激活函数具有非零输出，这使得模型变得更加稀疏。

    In this work, we use Deep Gaussian Processes (DGPs) as statistical surrogates for stochastic processes with complex distributions. Conventional inferential methods for DGP models can suffer from high computational complexity as they require large-scale operations with kernel matrices for training and inference. In this work, we propose an efficient scheme for accurate inference and efficient training based on a range of Gaussian Processes, called the Tensor Markov Gaussian Processes (TMGP). We construct an induced approximation of TMGP referred to as the hierarchical expansion. Next, we develop a deep TMGP (DTMGP) model as the composition of multiple hierarchical expansion of TMGPs. The proposed DTMGP model has the following properties: (1) the outputs of each activation function are deterministic while the weights are chosen independently from standard Gaussian distribution; (2) in training or prediction, only polylog(M) (out of M) activation functions have non-zero outputs, which sig
    
[^40]: 规模下图神经网络的鲁棒性

    Robustness of Graph Neural Networks at Scale. (arXiv:2110.14038v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.14038](http://arxiv.org/abs/2110.14038)

    本文研究了规模下如何攻击和防御图神经网络（GNNs），提出了稀疏感知的一阶优化攻击和鲁棒性聚合函数Soft Median，有效提高了GNNs的可靠性和攻击力。

    

    图神经网络（GNNs）由于其广泛的应用和受欢迎程度而变得越来越重要。然而，针对对抗攻击的现有研究只依赖于相对较小的图形。本文填补了这一空白，研究了如何在规模下攻击和防御GNNs。我们提出了两种稀疏感知的一阶优化攻击，尽管优化参数数量与节点数量二次关联，但仍保持高效的表示。我们发现公共代理损失不适合用于全局攻击GNNs，而我们的替代方案可以将攻击力翻倍。此外，为了提高GNNs的可靠性，我们设计了一个鲁棒性聚合函数，Soft Median，得到了在所有规模下的有效防御。我们以标准GNNs为基础，对比以前的研究，评估了我们的攻击和防御方法在100倍以上的图形上的效果。我们甚至通过将我们的技术扩展到可扩展的GNN，将规模进一步扩展了一个数量级。

    Graph Neural Networks (GNNs) are increasingly important given their popularity and the diversity of applications. Yet, existing studies of their vulnerability to adversarial attacks rely on relatively small graphs. We address this gap and study how to attack and defend GNNs at scale. We propose two sparsity-aware first-order optimization attacks that maintain an efficient representation despite optimizing over a number of parameters which is quadratic in the number of nodes. We show that common surrogate losses are not well-suited for global attacks on GNNs. Our alternatives can double the attack strength. Moreover, to improve GNNs' reliability we design a robust aggregation function, Soft Median, resulting in an effective defense at all scales. We evaluate our attacks and defense with standard GNNs on graphs more than 100 times larger compared to previous work. We even scale one order of magnitude further by extending our techniques to a scalable GNN.
    
[^41]: 冗余表示对宽神经网络的泛化有帮助

    Redundant representations help generalization in wide neural networks. (arXiv:2106.03485v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.03485](http://arxiv.org/abs/2106.03485)

    本文研究了各种卷积神经网络的最后一个隐藏层中的表示，发现如果最后一个隐藏表示足够宽，则其神经元倾向于分成携带相同信息的组，而冗余表示有助于宽神经网络的泛化。

    

    深度神经网络（DNN）打破了经典的偏差-方差权衡：为DNN添加参数以插值其训练数据通常会改善其泛化性能。解释在深度网络中“良性过拟合”的机制仍然是一个未解决的挑战。在这里，我们研究了各种最先进的卷积神经网络的最后一个隐藏层表示，并发现如果最后一个隐藏表示足够宽，则其神经元倾向于分成携带相同信息的组，仅由统计独立噪声区分彼此。这种组的数量随层的宽度呈线性增加，但仅在宽度高于临界值时才会增加。我们展示了冗余神经元仅在训练过程达到插值且训练误差为零时出现。

    Deep neural networks (DNNs) defy the classical bias-variance trade-off: adding parameters to a DNN that interpolates its training data will typically improve its generalization performance. Explaining the mechanism behind this ``benign overfitting'' in deep networks remains an outstanding challenge. Here, we study the last hidden layer representations of various state-of-the-art convolutional neural networks and find that if the last hidden representation is wide enough, its neurons tend to split into groups that carry identical information, and differ from each other only by statistically independent noise. The number of such groups increases linearly with the width of the layer, but only if the width is above a critical value. We show that redundant neurons appear only when the training process reaches interpolation and the training error is zero.
    
[^42]: 线性回报的双重稳健汤普森抽样算法

    Doubly robust Thompson sampling for linear payoffs. (arXiv:2102.01229v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2102.01229](http://arxiv.org/abs/2102.01229)

    本文提出了一种新型多臂上下文赌博算法双重稳健汤普森抽样（DR Thompson Sampling），通过双重稳健估计器，解决了过去的上下文和奖励对选择依赖性导致的损失分解复杂等问题，得到了简化且改进的损失界限。

    

    汤普森抽样在多臂上下文赌博问题中的应用面临一些挑战，如何根据过去的上下文和奖励对进行选择的依赖性使得后悔分析的复杂性增加。本文提出了一种名为双重稳健汤普森抽样（DR Thompson Sampling）的新型多臂上下文赌博算法，采用在缺失数据领域中使用的双重稳健估计器用于基于上下文的汤普森抽样（LinTS）。双重稳健汤普森抽样让损失分解更加简单，从而使得改进后的损失界限降到了 $\tilde{O}(\phi^{-2}\sqrt{T})$，其中 $\phi^2$ 是上下文协方差矩阵中的最小特征值。这是 \texttt{LinTS} 第一个不基于上下文维度 $d$，而是使用 $\phi^2$ 的损失界限。

    A challenging aspect of the bandit problem is that a stochastic reward is observed only for the chosen arm and the rewards of other arms remain missing. The dependence of the arm choice on the past context and reward pairs compounds the complexity of regret analysis. We propose a novel multi-armed contextual bandit algorithm called Doubly Robust (DR) Thompson Sampling employing the doubly-robust estimator used in missing data literature to Thompson Sampling with contexts (\texttt{LinTS}). Different from previous works relying on missing data techniques (\citet{dimakopoulou2019balanced}, \citet{kim2019doubly}), the proposed algorithm is designed to allow a novel additive regret decomposition leading to an improved regret bound with the order of $\tilde{O}(\phi^{-2}\sqrt{T})$, where $\phi^2$ is the minimum eigenvalue of the covariance matrix of contexts. This is the first regret bound of \texttt{LinTS} using $\phi^2$ without the dimension of the context, $d$. Applying the relationship be
    
[^43]: 最大熵采样问题的最佳主子矩阵选择：可扩展算法和性能保证。

    Best Principal Submatrix Selection for the Maximum Entropy Sampling Problem: Scalable Algorithms and Performance Guarantees. (arXiv:2001.08537v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2001.08537](http://arxiv.org/abs/2001.08537)

    本文提出了一个新的整数规划方法和连续松弛算法来解决最大熵采样问题，并提供了效率更高的确定性采样算法。同时，我们改进了已有的近似界限，并证明了局部搜索算法的第一个近似界限。

    

    本文研究了一种经典的最大熵采样问题（MESP），它旨在从协方差矩阵中选择最具信息量的主子矩阵。通过研究其拉格朗日对偶和原始特征，我们提出了一种新的MESP整数规划方法，并证明其连续松弛可得近似最优解。我们进一步提供了一种高效的确定性采样算法，并说明其在近似界方面优于已有文献中的最佳界限。通过对奇异矩阵开发新的数学工具和分析所提出的凸整数规划的拉格朗日对偶，我们研究了广泛使用的局部搜索算法，并证明其首个近似界限。

    This paper studies a classic maximum entropy sampling problem (MESP), which aims to select the most informative principal submatrix of a prespecified size from a covariance matrix. MESP has been widely applied to many areas, including healthcare, power system, manufacturing and data science. By investigating its Lagrangian dual and primal characterization, we derive a novel convex integer program for MESP and show that its continuous relaxation yields a near-optimal solution. The results motivate us to study an efficient sampling algorithm and develop its approximation bound for MESP, which improves the best-known bound in literature. We then provide an efficient deterministic implementation of the sampling algorithm with the same approximation bound. By developing new mathematical tools for the singular matrices and analyzing the Lagrangian dual of the proposed convex integer program, we investigate the widely-used local search algorithm and prove its first-known approximation bound f
    
[^44]: IMAE用于噪声鲁棒学习：绝对值误差不平等对待示例，梯度大小的方差很重要。

    IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters. (arXiv:1903.12141v10 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1903.12141](http://arxiv.org/abs/1903.12141)

    本文提出IMAE模型用于畸形训练数据的鲁棒深度学习，通过实践证实平均绝对误差（MAE）在处理示例时存在欠拟合问题，利用加权方差调整提高了拟合能力，同时保持了鲁棒性。

    

    本文研究了从示例加权角度，即与对数的梯度大小来看待畸形训练数据的鲁棒深度学习。我们有两个关键发现：（1）平均绝对误差（MAE）不平等地处理示例。我们针对MAE进行了新的观察和深入分析，理论证明其鲁棒性。首先，我们揭示了其在实践中的欠拟合问题。其次，我们分析了MAE的鲁棒性是通过强调不确定示例而不是像前人研究中所声称的那样对待训练样本来实现的。（2）梯度大小的方差很重要。我们提出了一种有效而简单的解决方案，以增强MAE的拟合能力，同时保持其鲁棒性。在不改变MAE的整体加权方案（即哪些示例获得更高的权重）的情况下，我们仅通过非线性地改变其加权方差来实现这一点。

    In this work, we study robust deep learning against abnormal training data from the perspective of example weighting built in empirical loss functions, i.e., gradient magnitude with respect to logits, an angle that is not thoroughly studied so far. Consequently, we have two key findings: (1) Mean Absolute Error (MAE) Does Not Treat Examples Equally. We present new observations and insightful analysis about MAE, which is theoretically proved to be noise-robust. First, we reveal its underfitting problem in practice. Second, we analyse that MAE's noise-robustness is from emphasising on uncertain examples instead of treating training samples equally, as claimed in prior work. (2) The Variance of Gradient Magnitude Matters. We propose an effective and simple solution to enhance MAE's fitting ability while preserving its noise-robustness. Without changing MAE's overall weighting scheme, i.e., what examples get higher weights, we simply change its weighting variance non-linearly so that the i
    

