# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data.](http://arxiv.org/abs/2308.05665) | 本研究利用深度学习技术分析了NHTS数据，开发了一个能够准确预测人员和车辆出行的模型，并取得了98%的准确率。这对传统交通规划模型的性能来说是一个显著的提升。 |
| [^2] | [Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model.](http://arxiv.org/abs/2308.05658) | 本论文提出了一种使用连接车辆数据和深度学习模型自动提取道路基础设施的新方法。通过将车辆轨迹分段并生成道路段的图像表示，我们利用YOLOv5算法准确分类直线道路段和交叉点。实验结果表明了令人印象深刻的整体准确性。 |
| [^3] | [Normalized Gradients for All.](http://arxiv.org/abs/2308.05621) | 这篇论文提出了一种利用标准化梯度适应 H\"{o}lder 光滑性的方法，并引入了局部 H\"{o}lder 光滑性的新概念。 |
| [^4] | [Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance.](http://arxiv.org/abs/2308.05619) | 提出了一种基于排名的兼容性度量和一种新的损失函数来更新临床机器学习模型，以解决更新模型引入的兼容性问题。在使用MIMIC数据的病死率风险分层案例研究中，该方法相对于现有技术能产生更兼容的模型并保持判别性能。 |
| [^5] | [Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling.](http://arxiv.org/abs/2308.05583) | 本文提出了一种基于扩散模型的信道抽样方法，用于快速合成有限数据的信道实现，相比于现有的基于 GAN 的方法，该方法训练稳定且能够生成多样化和高质量的信道数据。 |
| [^6] | [TSLiNGAM: DirectLiNGAM under heavy tails.](http://arxiv.org/abs/2308.05422) | TSLiNGAM是一种能够在重尾分布下进行因果推断的新方法，通过利用LiNGAM模型中误差项的非高斯性假设，实现了更高效和更稳健的因果结构估计。 |
| [^7] | [Unifying Distributionally Robust Optimization via Optimal Transport Theory.](http://arxiv.org/abs/2308.05414) | 本文通过最优输运理论将分布鲁棒优化的散度方法和Wasserstein方法统一到一个框架中，并且提出了可以同时扰动似然和结果的最优对抗分布。这个统一框架在实际应用中具有较强的可行性和实用性。 |
| [^8] | [SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling.](http://arxiv.org/abs/2308.04365) | SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。 |
| [^9] | [Selective inference using randomized group lasso estimators for general models.](http://arxiv.org/abs/2306.13829) | 研究了一种使用随机分组套索估计器进行广义模型的选择性推断方法，可以考虑分类或分组协变量以及连续协变量，并且有证据表明其具有适当性和准确性。 |
| [^10] | [From Random Search to Bandit Learning in Metric Measure Spaces.](http://arxiv.org/abs/2305.11509) | 本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。 |
| [^11] | [Learning ground states of gapped quantum Hamiltonians with Kernel Methods.](http://arxiv.org/abs/2303.08902) | 本文提出了一种利用 kernel 方法学习具有能隙的量子哈密顿量基态的统计学习方法，理论上需要多项式资源实现，通过数值模拟证明了该方法的有效性，并展示了方法的灵活性。 |
| [^12] | [Simplifying Momentum-based Riemannian Submanifold Optimization.](http://arxiv.org/abs/2302.09738) | 本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。 |
| [^13] | [Width and Depth Limits Commute in Residual Networks.](http://arxiv.org/abs/2302.00453) | 本文研究了深度残差网络中宽度和深度的极限情况，发现当枝干按比例缩放时，得到的协方差结构是相同的。这一发现解释了为什么即使深度和宽度处于相同阶数的网络，标准的宽度无限、然后深度趋向无穷的方法也能提供实际洞见。此外，本文还证明了在这种情况下预激活具有高斯分布，这对贝叶斯深度学习具有直接应用。通过大量模拟实验证明了理论发现的准确性。 |
| [^14] | [Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification.](http://arxiv.org/abs/2301.05869) | 功能性神经网络（FNNs）是一种新的神经网络类别，具有位移不变性和保持数据平滑性的特点。在脑电图分类任务中，FNNs的模型表现优于基准模型并能成功进行分类。 |
| [^15] | [A survey of some recent developments in measures of association.](http://arxiv.org/abs/2211.04702) | 本文综述了与作者引入的一种新的相关系数相关的关联度测量方法的一些最新发展，并提出了一个对标准Borel空间的直接推广。 |
| [^16] | [Inverse Extended Kalman Filter -- Part II: Highly Non-Linear and Uncertain Systems.](http://arxiv.org/abs/2208.06683) | 本文提出了逆扩展 Kalman 滤波器 (I-EKF) 来解决非线性系统中的逆过滤问题，并拓展了该理论以应对高度非线性模型。同时，提出了一种改进方案，解决标准 I-EKF 的局限性。 |
| [^17] | [Selective Inference for Sparse Multitask Regression with Applications in Neuroimaging.](http://arxiv.org/abs/2205.14220) | 本文提出了一种多任务稀疏回归的选择推断框架，在神经影像学中应用，可以提高建模精度和预测性能。 |
| [^18] | [InfoNCE is variational inference in a recognition parameterised model.](http://arxiv.org/abs/2107.02495) | InfoNCE目标在识别参数化模型中等同于ELBO，在学习最优先验时变为互信息，并与自监督学习方法建立了联系。然而，实际的InfoNCE目标是对互信息的松散下界，以避免高度纠缠的表示。 |

# 详细

[^1]: 探索深度学习方法预测人员和车辆出行：对NHTS数据的分析

    Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data. (arXiv:2308.05665v1 [cs.AI])

    [http://arxiv.org/abs/2308.05665](http://arxiv.org/abs/2308.05665)

    本研究利用深度学习技术分析了NHTS数据，开发了一个能够准确预测人员和车辆出行的模型，并取得了98%的准确率。这对传统交通规划模型的性能来说是一个显著的提升。

    

    现代交通规划在准确预测人员和车辆出行方面依赖较多。然而，传统规划模型往往无法考虑出行行为的复杂性和动态性，导致预测准确性不佳。本研究探讨了深度学习技术的潜力，以改变我们对出行预测和交通规划的方法。利用全国家庭出行调查（NHTS）的全面数据集，我们开发和训练了一个用于预测人员和车辆出行的深度学习模型。该模型利用NHTS数据中的大量信息，捕捉以前传统模型忽视的复杂非线性关系。结果，我们的深度学习模型在预测人员出行方面达到了98%的准确率，在车辆出行估计方面达到了96%的准确率。相比传统交通模型的表现，这代表了显著的提升。

    Modern transportation planning relies heavily on accurate predictions of person and vehicle trips. However, traditional planning models often fail to account for the intricacies and dynamics of travel behavior, leading to less-than-optimal accuracy in these predictions. This study explores the potential of deep learning techniques to transform the way we approach trip predictions, and ultimately, transportation planning. Utilizing a comprehensive dataset from the National Household Travel Survey (NHTS), we developed and trained a deep learning model for predicting person and vehicle trips. The proposed model leverages the vast amount of information in the NHTS data, capturing complex, non-linear relationships that were previously overlooked by traditional models. As a result, our deep learning model achieved an impressive accuracy of 98% for person trip prediction and 96% for vehicle trip estimation. This represents a significant improvement over the performances of traditional transpo
    
[^2]: 使用连接车辆数据和深度学习模型自动提取相关道路基础设施

    Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model. (arXiv:2308.05658v1 [cs.AI])

    [http://arxiv.org/abs/2308.05658](http://arxiv.org/abs/2308.05658)

    本论文提出了一种使用连接车辆数据和深度学习模型自动提取道路基础设施的新方法。通过将车辆轨迹分段并生成道路段的图像表示，我们利用YOLOv5算法准确分类直线道路段和交叉点。实验结果表明了令人印象深刻的整体准确性。

    

    在当今快速发展的城市环境中，高效准确地绘制道路基础设施对于优化交通系统、增强道路安全并改善驾驶员和通勤者的整体出行体验至关重要。然而，一个严峻的瓶颈阻碍了进展-繁琐耗时的手动交叉点识别。考虑到需要识别的交叉点数量和每个交叉点所需的工时，自动化解决方案的需求变得不可忽视。为了解决这一挑战，我们提出了一种新颖的方法，利用连接车辆数据和先进的深度学习技术。通过使用地理散列对车辆轨迹进行分段，并生成道路段的图像表示，我们利用YOLOv5（You Only Look Once version 5）算法准确分类了直线道路段和交叉点。实验结果展示了令人印象深刻的整体准确性。

    In today's rapidly evolving urban landscapes, efficient and accurate mapping of road infrastructure is critical for optimizing transportation systems, enhancing road safety, and improving the overall mobility experience for drivers and commuters. Yet, a formidable bottleneck obstructs progress - the laborious and time-intensive manual identification of intersections. Simply considering the shear number of intersections that need to be identified, and the labor hours required per intersection, the need for an automated solution becomes undeniable. To address this challenge, we propose a novel approach that leverages connected vehicle data and cutting-edge deep learning techniques. By employing geohashing to segment vehicle trajectories and then generating image representations of road segments, we utilize the YOLOv5 (You Only Look Once version 5) algorithm for accurate classification of both straight road segments and intersections. Experimental results demonstrate an impressive overall
    
[^3]: 所有情况下的标准化梯度

    Normalized Gradients for All. (arXiv:2308.05621v1 [cs.LG])

    [http://arxiv.org/abs/2308.05621](http://arxiv.org/abs/2308.05621)

    这篇论文提出了一种利用标准化梯度适应 H\"{o}lder 光滑性的方法，并引入了局部 H\"{o}lder 光滑性的新概念。

    

    在这篇简短的论文中，我展示了如何以黑盒的方式利用标准化梯度来适应 H\"{o}lder 光滑性。此外，这个界限将依赖于局部 H\"{o}lder 光滑性的一种新概念。主要思想直接来自于 Levy [2017]。

    In this short note, I show how to adapt to H\"{o}lder smoothness using normalized gradients in a black-box way. Moreover, the bound will depend on a novel notion of local H\"{o}lder smoothness. The main idea directly comes from Levy [2017].
    
[^4]: 使用基于排名的兼容性更新临床风险分层模型：评估和优化临床医生-模型团队性能的方法

    Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance. (arXiv:2308.05619v1 [stat.ML])

    [http://arxiv.org/abs/2308.05619](http://arxiv.org/abs/2308.05619)

    提出了一种基于排名的兼容性度量和一种新的损失函数来更新临床机器学习模型，以解决更新模型引入的兼容性问题。在使用MIMIC数据的病死率风险分层案例研究中，该方法相对于现有技术能产生更兼容的模型并保持判别性能。

    

    随着数据的变化或新数据的出现，更新临床机器学习模型可能是必要的，以保持或提高其性能。然而，更新模型可能会引入兼容性问题，当更新后的模型的行为与用户的期望不一致时，会导致用户-模型团队表现不佳。现有的兼容性度量依赖于模型的决策阈值，限制了它们在基于估计风险的排名生成模型的应用能力。为了解决这个限制，我们提出了一种新颖的基于排名的兼容性度量，$C^R$，以及一个旨在优化判别性能的新损失函数，同时鼓励良好的兼容性。在利用MIMIC数据的病死率风险分层的案例研究中，我们的方法相对于现有的模型选择技术，产生了更兼容的模型，同时保持了判别性能，$C^R$提高了0.019（$95\%$置信区间：...

    As data shift or new data become available, updating clinical machine learning models may be necessary to maintain or improve performance over time. However, updating a model can introduce compatibility issues when the behavior of the updated model does not align with user expectations, resulting in poor user-model team performance. Existing compatibility measures depend on model decision thresholds, limiting their applicability in settings where models are used to generate rankings based on estimated risk. To address this limitation, we propose a novel rank-based compatibility measure, $C^R$, and a new loss function that aims to optimize discriminative performance while encouraging good compatibility. Applied to a case study in mortality risk stratification leveraging data from MIMIC, our approach yields more compatible models while maintaining discriminative performance compared to existing model selection techniques, with an increase in $C^R$ of $0.019$ ($95\%$ confidence interval: 
    
[^5]: 无线电无线信道建模和抽样的生成扩散模型

    Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling. (arXiv:2308.05583v1 [cs.AI])

    [http://arxiv.org/abs/2308.05583](http://arxiv.org/abs/2308.05583)

    本文提出了一种基于扩散模型的信道抽样方法，用于快速合成有限数据的信道实现，相比于现有的基于 GAN 的方法，该方法训练稳定且能够生成多样化和高质量的信道数据。

    

    信道建模对于设计现代无线通信系统至关重要。信道建模的复杂性和收集高质量无线信道数据的成本日益增加，已成为主要挑战。在本文中，我们提出了一种基于扩散模型的信道抽样方法，可以快速合成有限数据的信道实现。我们使用在频率空间域中操作的基于 U Net 的扩散模型。为了评估所提模型在训练数据集中如何准确地重现信道的真实分布，我们使用了两个评估指标：$i)$ 反映天线和频率领域中归一化功率谱的实际分布和生成分布之间的近似 $2$-Wasserstein 距离，和 $ii)$ 分布的精确度和召回率度量。我们证明，与现有的基于 GAN 的方法相比，该扩散模型方法训练稳定且能够生成多样化和高质量的信道数据。

    Channel modelling is essential to designing modern wireless communication systems. The increasing complexity of channel modelling and the cost of collecting high-quality wireless channel data have become major challenges. In this paper, we propose a diffusion model based channel sampling approach for rapidly synthesizing channel realizations from limited data. We use a diffusion model with a U Net based architecture operating in the frequency space domain. To evaluate how well the proposed model reproduces the true distribution of channels in the training dataset, two evaluation metrics are used: $i)$ the approximate $2$-Wasserstein distance between real and generated distributions of the normalized power spectrum in the antenna and frequency domains and $ii)$ precision and recall metric for distributions. We show that, compared to existing GAN based approaches which suffer from mode collapse and unstable training, our diffusion based approach trains stably and generates diverse and hi
    
[^6]: TSLiNGAM: 在重尾分布下的DirectLiNGAM

    TSLiNGAM: DirectLiNGAM under heavy tails. (arXiv:2308.05422v1 [stat.ME])

    [http://arxiv.org/abs/2308.05422](http://arxiv.org/abs/2308.05422)

    TSLiNGAM是一种能够在重尾分布下进行因果推断的新方法，通过利用LiNGAM模型中误差项的非高斯性假设，实现了更高效和更稳健的因果结构估计。

    

    因果推断的一种已建立的方法是将有向无环图(DAGs)与结构性因果模型(SCMs)结合起来，以描述效应对其因果的功能依赖关系。给定数据下SCMs的可能可辨识性取决于对噪声变量和SCM中功能类的假设。例如，在LiNGAM模型中，功能类受限于线性函数，扰动必须是非高斯的。在这项工作中，我们提出了TSLiNGAM，一种基于观测数据识别因果模型DAG的新方法。TSLiNGAM建立在DirectLiNGAM之上，它是一种使用简单的OLS回归来识别变量间因果方向的流行算法。TSLiNGAM利用了LiNGAM模型中误差项的非高斯性假设，从而获得更高效和更稳健的因果结构估计。TSLiNGAM在理论上被证明是合理的，并在广泛的模拟研究中进行了实证研究。

    One of the established approaches to causal discovery consists of combining directed acyclic graphs (DAGs) with structural causal models (SCMs) to describe the functional dependencies of effects on their causes. Possible identifiability of SCMs given data depends on assumptions made on the noise variables and the functional classes in the SCM. For instance, in the LiNGAM model, the functional class is restricted to linear functions and the disturbances have to be non-Gaussian.  In this work, we propose TSLiNGAM, a new method for identifying the DAG of a causal model based on observational data. TSLiNGAM builds on DirectLiNGAM, a popular algorithm which uses simple OLS regression for identifying causal directions between variables. TSLiNGAM leverages the non-Gaussianity assumption of the error terms in the LiNGAM model to obtain more efficient and robust estimation of the causal structure. TSLiNGAM is justified theoretically and is studied empirically in an extensive simulation study. I
    
[^7]: 通过最优输运理论统一分布鲁棒优化

    Unifying Distributionally Robust Optimization via Optimal Transport Theory. (arXiv:2308.05414v1 [math.OC])

    [http://arxiv.org/abs/2308.05414](http://arxiv.org/abs/2308.05414)

    本文通过最优输运理论将分布鲁棒优化的散度方法和Wasserstein方法统一到一个框架中，并且提出了可以同时扰动似然和结果的最优对抗分布。这个统一框架在实际应用中具有较强的可行性和实用性。

    

    在过去几年中，对于分布鲁棒优化 (DRO) 有两种主要方法引起了相当大的关注：基于散度和基于Wasserstein的方法。散度方法使用似然比来建模错配，而后者使用实际结果的距离或成本来建模错配。在这些进展的基础上，本文引入了一种新的方法，将这些方法统一到一个基于最优输运 (OT) 和条件矩约束的框架中。例如，我们提出的方法可以使得最优对抗分布同时扰动似然和结果，并在基线模型和对抗模型之间产生一个最优 (从最优输运意义上) 的耦合。此外，本文还研究了几个对偶结果，并提出了可行的改进，增强了这个统一框架的实际适用性。

    In the past few years, there has been considerable interest in two prominent approaches for Distributionally Robust Optimization (DRO): Divergence-based and Wasserstein-based methods. The divergence approach models misspecification in terms of likelihood ratios, while the latter models it through a measure of distance or cost in actual outcomes. Building upon these advances, this paper introduces a novel approach that unifies these methods into a single framework based on optimal transport (OT) with conditional moment constraints. Our proposed approach, for example, makes it possible for optimal adversarial distributions to simultaneously perturb likelihood and outcomes, while producing an optimal (in an optimal transport sense) coupling between the baseline model and the adversarial model.Additionally, the paper investigates several duality results and presents tractable reformulations that enhance the practical applicability of this unified framework.
    
[^8]: SLEM：机器学习用于路径建模和因果推断的超级学习者方程模型

    SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])

    [http://arxiv.org/abs/2308.04365](http://arxiv.org/abs/2308.04365)

    SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。

    

    因果推断是科学的关键目标，使研究人员能够通过观察数据得出关于对假定干预的预测的有意义的结论。路径模型、结构方程模型(SEMs)以及更一般的有向无环图(DAGs)能够明确地指定关于现象背后的因果结构的假设。与DAGs不同，SEMs假设线性关系，这可能导致函数错误规范，从而阻碍研究人员进行可靠的效果大小估计。相反，我们提出了超级学习者方程模型（SLEM），一种集成了机器学习超级学习者集成的路径建模技术。我们通过实证研究，证明了SLEM能够提供一致且无偏的因果效应估计，在与SEMs进行线性模型比较时表现出竞争力，并且在处理非线性关系时优于SEMs。

    Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
    
[^9]: 使用随机分组套索估计器进行广义模型的选择性推断。

    Selective inference using randomized group lasso estimators for general models. (arXiv:2306.13829v1 [stat.ME])

    [http://arxiv.org/abs/2306.13829](http://arxiv.org/abs/2306.13829)

    研究了一种使用随机分组套索估计器进行广义模型的选择性推断方法，可以考虑分类或分组协变量以及连续协变量，并且有证据表明其具有适当性和准确性。

    

    为了与广泛的分布和损失函数一起使用，开发了选择性推理方法，用于组套索估计器。该方法包括使用指数家族分布，以及像过度离散计数数据的拟然模型等，允许分类或分组协变量以及连续协变量。研究了一种随机的组正则化优化问题。添加的随机化使我们可以构建后选择似然，我们证明在条件选择分组协变量的事件上适用于选择性推断。这个似然也提供了一个选择性点估计，通过组套索考虑了选择。选择的模型中回归参数的置信区间采用沃尔德类型的区间，并证明具有有界体积。以美国国家健康和营养调查的数据为例展示了组套索的选择性推理方法。

    Selective inference methods are developed for group lasso estimators for use with a wide class of distributions and loss functions. The method includes the use of exponential family distributions, as well as quasi-likelihood modeling for overdispersed count data, for example, and allows for categorical or grouped covariates as well as continuous covariates. A randomized group-regularized optimization problem is studied. The added randomization allows us to construct a post-selection likelihood which we show to be adequate for selective inference when conditioning on the event of the selection of the grouped covariates. This likelihood also provides a selective point estimator, accounting for the selection by the group lasso. Confidence regions for the regression parameters in the selected model take the form of Wald-type regions and are shown to have bounded volume. The selective inference method for grouped lasso is illustrated on data from the national health and nutrition examinatio
    
[^10]: 从随机搜索到度量测度空间中的赌博学习

    From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])

    [http://arxiv.org/abs/2305.11509](http://arxiv.org/abs/2305.11509)

    本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。

    

    随机搜索是超参数优化中最常用的方法之一，对于深度学习模型的成功至关重要。尽管其性能令人惊叹，但很少有非启发式的理论用于描述其工作机制。本文给出了关于随机搜索的理论解释。我们引入了“散射维度”的概念，描述了底层函数的状态，并量化了随机搜索的性能。我们表明，当环境没有噪声时，随机搜索的输出以概率收敛到最优值，其速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $，其中$ d_s \ge 0 $是底层函数的散射维度。当观察到的函数值受到有界的独立同分布噪声影响时，随机搜索的输出以概率收敛到最优值，速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $。

    Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
    
[^11]: 用 Kernel 方法学习具有能隙的量子哈密顿量的基态

    Learning ground states of gapped quantum Hamiltonians with Kernel Methods. (arXiv:2303.08902v1 [quant-ph])

    [http://arxiv.org/abs/2303.08902](http://arxiv.org/abs/2303.08902)

    本文提出了一种利用 kernel 方法学习具有能隙的量子哈密顿量基态的统计学习方法，理论上需要多项式资源实现，通过数值模拟证明了该方法的有效性，并展示了方法的灵活性。

    

    近年来，利用神经网络来近似量子哈密顿量基态的方法需要解决高度非线性的优化问题。本文提出了一种利用 kernel 方法来使优化变得简单的统计学习方法。我们的方案是功率法的一种近似实现，其中通过监督学习来学习功率迭代的下一步。我们证明，假设监督学习是有效的，那么可以使用多项式资源实现对任意具有能隙的量子哈密顿量的基态性质的计算。我们使用 kernel ridge 回归，通过对一维和二维的几个典型相互作用多体量子系统进行基态的寻找，提供了基于数值模拟的证据，证明了学习假设的有效性，展示了我们方法的灵活性。

    Neural network approaches to approximate the ground state of quantum hamiltonians require the numerical solution of a highly nonlinear optimization problem. We introduce a statistical learning approach that makes the optimization trivial by using kernel methods. Our scheme is an approximate realization of the power method, where supervised learning is used to learn the next step of the power iteration. We show that the ground state properties of arbitrary gapped quantum hamiltonians can be reached with polynomial resources under the assumption that the supervised learning is efficient. Using kernel ridge regression, we provide numerical evidence that the learning assumption is verified by applying our scheme to find the ground states of several prototypical interacting many-body quantum systems, both in one and two dimensions, showing the flexibility of our approach.
    
[^12]: 简化基于动量的黎曼子流形优化

    Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09738](http://arxiv.org/abs/2302.09738)

    本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。

    

    带有动量的黎曼子流形优化在计算上是具有挑战性的，因为确保迭代保持在子流形上通常需要解决困难的微分方程。本文针对具有仿射不变度量的对称正定矩阵的子流形优化算法进行了简化。我们提出了黎曼正常坐标的广义版本，可以将问题动态地简化为欧几里得无约束问题。我们使用我们的方法来解释和简化现有的结构化协方差方法，并为深度学习开发了高效的二阶优化器，而无需显式矩阵求逆。

    Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
    
[^13]: 深度残差网络中宽度和深度极限的通行

    Width and Depth Limits Commute in Residual Networks. (arXiv:2302.00453v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00453](http://arxiv.org/abs/2302.00453)

    本文研究了深度残差网络中宽度和深度的极限情况，发现当枝干按比例缩放时，得到的协方差结构是相同的。这一发现解释了为什么即使深度和宽度处于相同阶数的网络，标准的宽度无限、然后深度趋向无穷的方法也能提供实际洞见。此外，本文还证明了在这种情况下预激活具有高斯分布，这对贝叶斯深度学习具有直接应用。通过大量模拟实验证明了理论发现的准确性。

    

    本文研究了带有跳跃连接的深度神经网络中，当枝干按比例$1/\sqrt{depth}$缩放时，将宽度和深度趋向无穷得到的协方差结构是相同的。这解释了为什么标准的宽度无限、然后深度趋向无穷的方法对于深度和宽度处于相同阶数的网络也能提供实际洞见。我们还证明了在这种情况下，预激活具有高斯分布，这在贝叶斯深度学习中具有直接应用。我们进行了大量模拟实验，结果与理论发现非常吻合。

    We show that taking the width and depth to infinity in a deep neural network with skip connections, when branches are scaled by $1/\sqrt{depth}$ (the only nontrivial scaling), result in the same covariance structure no matter how that limit is taken. This explains why the standard infinite-width-then-depth approach provides practical insights even for networks with depth of the same order as width. We also demonstrate that the pre-activations, in this case, have Gaussian distributions which has direct applications in Bayesian deep learning. We conduct extensive simulations that show an excellent match with our theoretical findings.
    
[^14]: 功能性神经网络：用于功能数据的位移不变模型及其在脑电图分类中的应用

    Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification. (arXiv:2301.05869v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.05869](http://arxiv.org/abs/2301.05869)

    功能性神经网络（FNNs）是一种新的神经网络类别，具有位移不变性和保持数据平滑性的特点。在脑电图分类任务中，FNNs的模型表现优于基准模型并能成功进行分类。

    

    对于统计模型来说，独立于位置地检测感兴趣的信号是很理想的。如果数据由某个平滑过程生成，那么这种附加结构应该被考虑进去。我们引入了一种新的神经网络类别，它们具有位移不变性并保持数据的平滑性：功能性神经网络（FNNs）。为此，我们使用功能数据分析（FDA）的方法来扩展多层感知器和卷积神经网络以适应功能数据。我们提出了不同的模型架构，证明这些模型在准确性上优于FDA的基准模型，并成功地使用FNNs对脑电图数据进行分类。

    It is desirable for statistical models to detect signals of interest independently of their position. If the data is generated by some smooth process, this additional structure should be taken into account. We introduce a new class of neural networks that are shift invariant and preserve smoothness of the data: functional neural networks (FNNs). For this, we use methods from functional data analysis (FDA) to extend multi-layer perceptrons and convolutional neural networks to functional data. We propose different model architectures, show that the models outperform a benchmark model from FDA in terms of accuracy and successfully use FNNs to classify electroencephalography (EEG) data.
    
[^15]: 关联度测量方法的一些最新发展综述

    A survey of some recent developments in measures of association. (arXiv:2211.04702v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2211.04702](http://arxiv.org/abs/2211.04702)

    本文综述了与作者引入的一种新的相关系数相关的关联度测量方法的一些最新发展，并提出了一个对标准Borel空间的直接推广。

    

    本文综述了与作者引入的一种新的相关系数相关的关联度测量方法的一些最新发展。并在综述的最后提出了一个对标准Borel空间（包括所有波兰空间）的直接推广，这一推广在文献中迄今被忽视。

    This paper surveys some recent developments in measures of association related to a new coefficient of correlation introduced by the author. A straightforward extension of this coefficient to standard Borel spaces (which includes all Polish spaces), overlooked in the literature so far, is proposed at the end of the survey.
    
[^16]: Inverse Extended Kalman Filter -- Part II: Highly Non-Linear and Uncertain Systems.

    Inverse Extended Kalman Filter -- Part II: Highly Non-Linear and Uncertain Systems. (arXiv:2208.06683v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2208.06683](http://arxiv.org/abs/2208.06683)

    本文提出了逆扩展 Kalman 滤波器 (I-EKF) 来解决非线性系统中的逆过滤问题，并拓展了该理论以应对高度非线性模型。同时，提出了一种改进方案，解决标准 I-EKF 的局限性。

    

    近年来，对抗性系统设计问题推动了逆贝叶斯滤波器的发展。例如，最近提出了逆 Kalman 滤波器 (I-KF)，用于估计对手的 Kalman 滤波跟踪估计，从而预测对手的未来步骤。本论文及其伴随论文 (Part I) 的目的是通过提出逆扩展 Kalman 滤波器 (I-EKF) 来解决非线性系统中的逆过滤问题。伴随论文提出了 I-EKF (具有和不具有未知输入) 和 I-KF (具有未知输入) 的理论。在本文中，我们对高度非线性模型的该理论进行了拓展，该模型采用二阶、高斯和抖动前向 EKF。特别地，我们通过有界非线性方法推导了逆二阶 EKF 的理论稳定性保证。为了解决标准 I-EKF 的局限性，即系统模型和前向滤波器对防御者来说是完全已知的，我们提出了一种改进方案。

    Counter-adversarial system design problems have lately motivated the development of inverse Bayesian filters. For example, inverse Kalman filter (I-KF) has been recently formulated to estimate the adversary's Kalman-filter-tracked estimates and hence, predict the adversary's future steps. The purpose of this paper and the companion paper (Part I) is to address the inverse filtering problem in non-linear systems by proposing an inverse extended Kalman filter (I-EKF). The companion paper proposed the theory of I-EKF (with and without unknown inputs) and I-KF (with unknown inputs). In this paper, we develop this theory for highly non-linear models, which employ second-order, Gaussian sum, and dithered forward EKFs. In particular, we derive theoretical stability guarantees for the inverse second-order EKF using the bounded non-linearity approach. To address the limitation of the standard I-EKFs that the system model and forward filter are perfectly known to the defender, we propose reprodu
    
[^17]: 多任务稀疏回归的选择推断及其在神经影像学中的应用

    Selective Inference for Sparse Multitask Regression with Applications in Neuroimaging. (arXiv:2205.14220v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2205.14220](http://arxiv.org/abs/2205.14220)

    本文提出了一种多任务稀疏回归的选择推断框架，在神经影像学中应用，可以提高建模精度和预测性能。

    

    多任务学习被广泛应用于从同一特征集中模拟一组相关响应变量，相比于单独处理每个响应变量的方法，可以提高预测性能和建模精度。但多任务学习在推断不确定性方面的研究还较少。本文通过稀疏性信号加强方法，针对神经影像学中的常见多任务问题，提出了一种选择推断框架，具有灵活性，可以同时识别出每个任务相关的协变量，并建立基于稀疏结构的有效推断模型。

    Multi-task learning is frequently used to model a set of related response variables from the same set of features, improving predictive performance and modeling accuracy relative to methods that handle each response variable separately. Despite the potential of multi-task learning to yield more powerful inference than single-task alternatives, prior work in this area has largely omitted uncertainty quantification. Our focus in this paper is a common multi-task problem in neuroimaging, where the goal is to understand the relationship between multiple cognitive task scores (or other subject-level assessments) and brain connectome data collected from imaging. We propose a framework for selective inference to address this problem, with the flexibility to: (i) jointly identify the relevant covariates for each task through a sparsity-inducing penalty, and (ii) conduct valid inference in a model based on the estimated sparsity structure. Our framework offers a new conditional procedure for in
    
[^18]: InfoNCE是识别参数化模型中的变分推断

    InfoNCE is variational inference in a recognition parameterised model. (arXiv:2107.02495v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2107.02495](http://arxiv.org/abs/2107.02495)

    InfoNCE目标在识别参数化模型中等同于ELBO，在学习最优先验时变为互信息，并与自监督学习方法建立了联系。然而，实际的InfoNCE目标是对互信息的松散下界，以避免高度纠缠的表示。

    

    在这里，我们展示InfoNCE目标等同于一种新型概率生成模型——识别参数化模型（RPM）中的ELBO。当我们学习最优先验时，RPM ELBO变成了互信息（MI；除了一个常数），从而与之前存在的自监督学习方法（如InfoNCE）建立了联系。然而，实际的InfoNCE方法并不使用MI作为目标；MI对于任意可逆变换是不变的，因此使用MI目标可能导致高度纠缠的表示（Tschannen et al.，2019）。相反，实际的InfoNCE目标是对MI的一个简化下界，即使在无限样本极限下也不紧密。因此，一个有效的目标（即实际的InfoNCE目标）似乎是对一个无效的目标（即给出任意纠缠表示的真实MI）的松散下界的动机。我们给出了实际的InfoNCE目标的另一种动机。在目录中

    Here, we show that the InfoNCE objective is equivalent to the ELBO in a new class of probabilistic generative model, the recognition parameterised model (RPM). When we learn the optimal prior, the RPM ELBO becomes equal to the mutual information (MI; up to a constant), establishing a connection to pre-existing self-supervised learning methods such as InfoNCE. However, practical InfoNCE methods do not use the MI as an objective; the MI is invariant to arbitrary invertible transformations, so using an MI objective can lead to highly entangled representations (Tschannen et al., 2019). Instead, the actual InfoNCE objective is a simplified lower bound on the MI which is loose even in the infinite sample limit. Thus, an objective that works (i.e. the actual InfoNCE objective) appears to be motivated as a loose bound on an objective that does not work (i.e. the true MI which gives arbitrarily entangled representations). We give an alternative motivation for the actual InfoNCE objective. In pa
    

