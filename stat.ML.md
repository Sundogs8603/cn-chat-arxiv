# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Long-term Forecasting with TiDE: Time-series Dense Encoder.](http://arxiv.org/abs/2304.08424) | TiDE是一种基于MLP的编码器-解码器模型，用于长期时间序列预测。它既具备线性模型的简单性和速度，又能处理协变量和非线性依赖，相较于最佳的Transformer模型，速度快5-10倍。 |
| [^2] | [NF-ULA: Langevin Monte Carlo with Normalizing Flow Prior for Imaging Inverse Problems.](http://arxiv.org/abs/2304.08342) | 本文提出了一种NF-ULA算法，其中包括学习正则化流作为先验，用于解决成像逆问题的贝叶斯推断采样算法，且有效性得到了在三个成像逆问题上的证明。 |
| [^3] | [Promises and Pitfalls of the Linearized Laplace in Bayesian Optimization.](http://arxiv.org/abs/2304.08309) | 本论文研究了在线性化Laplace逼近(LLA)在Bayesian optimization中的应用。虽然LLA在构建贝叶斯神经网络时已被证明具有效性和高效性，但是在序列决策问题中，需要考虑其可能的局限性。 |
| [^4] | [Compositional Probabilistic and Causal Inference using Tractable Circuit Models.](http://arxiv.org/abs/2304.08278) | 本文提出了一种新的结构化分解PC的表示法md-vtrees，并提出了基于这种表示法的PC架构MDNets，首次推导出了较为高效的基于PC的因果推断算法。 |
| [^5] | [Prediction-Oriented Bayesian Active Learning.](http://arxiv.org/abs/2304.08151) | 本文提出了一种基于预测的贝叶斯主动学习方法，即预期预测信息增益（EPIG），这种方法在预测空间而不是参数空间中测量信息增益，可以有效提高预测性能。 |
| [^6] | [Detection of Dense Subhypergraphs by Low-Degree Polynomials.](http://arxiv.org/abs/2304.08135) | 本文研究在超图中检测密集子超图的存在问题，并确定了易于实现和困难的问题之间的阈值。 |
| [^7] | [Fed-MIWAE: Federated Imputation of Incomplete Data via Deep Generative Models.](http://arxiv.org/abs/2304.08054) | 本论文提出了 Fed-MIWAE，这是基于联邦模型的 MIWAE 缺失数据填补的深度潜变量模型，它能够通过经典联邦聚合器进行简单训练，并具有处理 MAR 数据的能力。 |
| [^8] | [In-Context Operator Learning for Differential Equation Problems.](http://arxiv.org/abs/2304.07993) | 本文提出了一种新的神经网络方法INDEED，它可以同时学习不同微分方程问题的操作符，而无需重新训练，且只需要极少的演示。 |
| [^9] | [Metrics for Bayesian Optimal Experiment Design under Model Misspecification.](http://arxiv.org/abs/2304.07949) | 本文提出了一个拓展的框架，其中的期望一般信息增益和期望鉴别信息作为准则，用来度量模型差异稳健性和实验检测模型差异能力。 |
| [^10] | [Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation.](http://arxiv.org/abs/2304.07918) | 这篇论文提出了一种新的基于概率的 3D 感知 2D 图像生成模型 NeRF-LEBM，它结合 NeRF 和可微分体积渲染实现了 3D 表示并入 2D 成像过程，并通过马尔可夫链蒙特卡罗推断和变分推断方法进行训练。实验验证了该模型能够从 2D 图像中推断出 3D 对象结构，生成具有新视角和对象的 2D 图像，学习不完整的 2D 图像，以及从已知或未知相机姿势的 2D 图像中学习。 |
| [^11] | [Penalized Likelihood Inference with Survey Data.](http://arxiv.org/abs/2304.07855) | 本文将三种Lasso推断方法应用于调查数据的推断，证明在具有调查权重和/或异方差的广义线性模型中的推断程序渐近有效性， 并将这些方法推广到对非线性参数函数进行推断，例如在调查logit模型中的平均边际效应 |
| [^12] | [Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value.](http://arxiv.org/abs/2304.07718) | Data-OOB是一种新的数据价值估计方法，它利用out-of-bag估计，并可以在计算上高效处理大型数据集。 |
| [^13] | [Learning Empirical Bregman Divergence for Uncertain Distance Representation.](http://arxiv.org/abs/2304.07689) | 本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。 |
| [^14] | [Dynamic Exploration-Exploitation Trade-Off in Active Learning Regression with Bayesian Hierarchical Modeling.](http://arxiv.org/abs/2304.07665) | 本文提出了一个新方法，利用贝叶斯分层建模，动态平衡探索-开发权衡，以更好地查询数据点。 |
| [^15] | [Dimensionality Reduction as Probabilistic Inference.](http://arxiv.org/abs/2304.07658) | 该论文提出了ProbDR变分框架，将经典降维算法解释为概率推断算法，通过优化一个证据下界来完成推断操作。该框架不仅可以完成常规降维算法，还支持使用概率编程语言进行降维操作，具有强大的表达能力。 |
| [^16] | [Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis.](http://arxiv.org/abs/2304.07504) | 本文提出了两种新算法SVRS和AccSVRS，针对分布式优化问题，实现了卓越的通信复杂度。其中，AccSVRS算法实现了完全无平滑性，通信复杂度更是优于现有算法。 |
| [^17] | [Efficient Convex Algorithms for Universal Kernel Learning.](http://arxiv.org/abs/2304.07472) | 本文提出了一种基于SVD-QCQP原始对偶算法的高效内核学习实现，用于学习半分离核，大大降低了计算复杂度，并在几个基准数据集上展示了其准确性和速度。 |
| [^18] | [Multivariate regression modeling in integrative analysis via sparse regularization.](http://arxiv.org/abs/2304.07451) | 本研究提出了稀疏正则化在综合分析中的多元回归建模方法，并采用交替方向乘子方法开发了其计算算法。该方法可从多个独立数据集中汇集有用信息并比单个数据集分析提供更好的性能。 |
| [^19] | [Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents.](http://arxiv.org/abs/2304.07407) | 本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。 |
| [^20] | [Bayesian inference on Brain-Computer Interface using the GLASS Model.](http://arxiv.org/abs/2304.07401) | 本文针对P300 BCI问题，开发了一种基于GLASS模型的贝叶斯推断方法，直接解决了脑机接口应用中数据集不平衡问题，具有良好的分类性能和易于解释性。 |
| [^21] | [Exact Subspace Diffusion for Decentralized Multitask Learning.](http://arxiv.org/abs/2304.07358) | 本论文提出了一种新的分布式多任务学习算法，通过精确扩散算法的推广，并在网络中进行子空间约束。相比于现有的基于近似投影的方法，其性能得到了明显提升。 |
| [^22] | [Differential geometry with extreme eigenvalues in the positive semidefinite cone.](http://arxiv.org/abs/2304.07347) | 本文提出了一种基于半定锥中的汤普森几何学的可扩展几何框架，利用极广义特征值有效地分析和处理对称正定矩阵数据。同时，基于此几何方法，定义了一种新型 SPD 矩阵迭代平均算法，证明了其存在性和唯一性。 |
| [^23] | [Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling.](http://arxiv.org/abs/2304.06052) | 本文展示了利用符合性预测框架构建可靠、值得信赖的铁路信号预测器的方法，并引入一种基于符合性风险控制的新方法。研究结果表明符合性预测框架有潜力为实现正式保证的不确定性边界提供实用指导。 |
| [^24] | [Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling.](http://arxiv.org/abs/2304.05365) | 本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。 |
| [^25] | [Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches.](http://arxiv.org/abs/2303.11582) | 本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。 |
| [^26] | [Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap.](http://arxiv.org/abs/2303.06484) | 本文提出了一个广义神经坍塌假设，有效地包含了原始神经坍塌，并将其分解为两个目标：最小化类内变异性和最大化类间可分性。使用超球统一性作为量化这两个目标的统一框架，并提出了一个通用目标——超球统一性差（HUG），它由类间和类内超球统一性之间的差异定义。 |
| [^27] | [A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization.](http://arxiv.org/abs/2302.01539) | BLiE是一种用于超参数优化的算法，只假设目标函数具有Lipschitz连续性。理论和实验证明BLiE优于现有算法，并且可以应用于搜索扩散模型的噪声调度。 |
| [^28] | [Learning Generalized Hybrid Proximity Representation for Image Recognition.](http://arxiv.org/abs/2301.13459) | 该文章提出了一种新的图像识别的监督度量学习方法，能够以混合方法学习更好的距离表示。通过控制几何近邻和概率近邻之间的权衡，从图像数据中学习通用的混合相似特征。 |
| [^29] | [Learning Deformation Trajectories of Boltzmann Densities.](http://arxiv.org/abs/2301.07388) | 本文介绍了一种学习Boltzmann密度变形轨迹的方法，其中通过插值能量函数等实现Boltzmann密度的变形，然后找到一个时间依赖向量场，将样本从一个分布转移到另一个分布，其表现在高斯混合和量子力学粒子的Boltzmann密度上比KL-反散度更具优势。 |
| [^30] | [Sliced Optimal Partial Transport.](http://arxiv.org/abs/2212.08049) | 本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。 |
| [^31] | [Scalable Spectral Clustering with Group Fairness Constraints.](http://arxiv.org/abs/2210.16435) | 本文提出了一个带有组公平约束的可扩展谱聚类算法 s-FairSC，并通过稀疏矩阵向量乘积来充分利用其稀疏性。 |
| [^32] | [Universal Adversarial Directions.](http://arxiv.org/abs/2210.15997) | 研究证明传统的通用对抗干扰 (UAPs) 在深度神经网络分类器之间转移性是次优的，为此本文提出了通用对抗方向 (UADs)，只固定通用方向，以便克服在跨DNN架构上转移的挑战。 |
| [^33] | [Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information.](http://arxiv.org/abs/2210.00116) | 本研究利用基因调控网络信息设计了一种新的因果推断框架，并通过邻接矩阵更新技术预训练图卷积网络以更好地预测细胞在反事实干扰下的基因表达。同时，我们提出了一个鲁棒的估计器来高效估计边缘干扰效应。研究结果展示了该框架的优越性能。 |
| [^34] | [Markov Observation Models.](http://arxiv.org/abs/2208.06368) | 本文针对隐马尔可夫模型扩展为允许马尔可夫链观测，研究了相应的期望最大化算法类比算法，并实现了相应的滤波和Viterbi算法。 |
| [^35] | [Proof-of-Learning is Currently More Broken Than You Think.](http://arxiv.org/abs/2208.03567) | 学习证明机制PoL存在不少问题，由于现有的欺骗策略很容易被打败或无法重现，因此对对手的安全保障不稳健。新的欺骗策略引入可以打破PoL的最新防御方法，但成本较低。 |
| [^36] | [Collaborative Learning in Kernel-based Bandits for Distributed Users.](http://arxiv.org/abs/2207.07948) | 本文研究了分布式用户之间的基于内核的赌博机协同学习，并提出了一种使用代理高斯进程模型的算法，以降低通信开销，获得次优遗憾性能。 |
| [^37] | [Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes.](http://arxiv.org/abs/2205.13589) | 本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。 |
| [^38] | [Causal Inference with Invalid Instruments: Exploring Nonlinear Treatment Models with Machine Learning.](http://arxiv.org/abs/2203.12808) | 提出一种名为TSCI的新方法，使用机器学习探索非线性治疗模型，并调整不同形式的其他工具变量假设违背，用于无效工具变量下的因果推断问题。 |
| [^39] | [Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation.](http://arxiv.org/abs/2203.11740) | 该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。 |
| [^40] | [Dimensionality Reduction and Wasserstein Stability for Kernel Regression.](http://arxiv.org/abs/2203.09347) | 本文研究了在高维回归框架中的降维与Wasserstein稳定性应用，针对在扰动输入数据用于拟合回归函数时出现的误差推导了稳定性结果，并利用主成分分析和核回归文献中的估计，推导了两步法的收敛速度。 |
| [^41] | [Counterfactual inference for sequential experiments.](http://arxiv.org/abs/2202.06891) | 本文针对序列实验的反事实推断问题，提出了一个潜在因子模型，使用非参数方法对反事实均值进行估计，并建立了误差界限。 |
| [^42] | [The Implicit Bias of Benign Overfitting.](http://arxiv.org/abs/2201.11489) | 本文针对善意过拟合现象，提供了非线性回归的最小范数插值预测器在一般情况下偏向于不一致解的证明，从而说明善意过拟合不会发生，同时展示了如何将其扩展到标准线性回归以外。 |
| [^43] | [ML4C: Seeing Causality Through Latent Vicinity.](http://arxiv.org/abs/2110.00637) | 本文提出了一种监督式因果学习方法ML4C，采用了新颖的学习目标，用于分类未屏蔽三元组是否是v-结构，并构建因果关系。 |
| [^44] | [Prescribing net demand for two-stage electricity generation scheduling.](http://arxiv.org/abs/2108.01003) | 本文介绍了一个两阶段发电计划问题中的净需求预测决策规则，并考虑了系统的成本结构和不确定性，经过数值测试证明了方法的有效性。 |
| [^45] | [Context-tree weighting for real-valued time series: Bayesian inference with hierarchical mixture models.](http://arxiv.org/abs/2106.03023) | 本文提出了一个通用的贝叶斯建模框架，用于构建实值时间序列的混合模型。基于上下文树的使用并包含了一组有效算法工具，可以与任何现有模型类一起使用，构建灵活且可解释的混合模型。 |
| [^46] | [Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle.](http://arxiv.org/abs/2105.14559) | 该论文提出了一种新的不确定性测量方法Balanced Entropy Acquisition（BalEntAcq），通过捕捉潜在softmax概率和标签变量的信息平衡，实现了基于平衡熵学习准则的贝叶斯神经网络主动学习，并在多个基准数据集上证明了该方法的有效性和较高的计算效率。 |
| [^47] | [CogDL: A Comprehensive Library for Graph Deep Learning.](http://arxiv.org/abs/2103.00959) | CogDL是一个图深度学习的综合库，针对图数据的稀疏性和复杂任务提供了统一的训练和评估设计和多种训练技术，包括高效和可扩展的实现和实用工具，是进行图深度学习的理想选择。 |
| [^48] | [Flexible Model Aggregation for Quantile Regression.](http://arxiv.org/abs/2103.00083) | 本文研究聚合条件分位数模型的方法，提高分位数回归的准确性和鲁棒性，并提出了能够应用于现代深度学习工具包的多种模型，对许多从业者具有广泛的适用性。 |
| [^49] | [Adversarial Meta-Learning of Gamma-Minimax Estimators That Leverage Prior Knowledge.](http://arxiv.org/abs/2012.05465) | 本文提出对抗元学习方法，用于计算在一组与可用知识相容的先验分布中最小化最坏情况的 Bayes 风险的 Gamma-Minimax 估计器，文中还提出了一种神经网络类用于提供估计器类，以及两个实验环节用于说明该方法的应用。 |
| [^50] | [Local Minima Structures in Gaussian Mixture Models.](http://arxiv.org/abs/2009.13040) | 研究了高斯混合模型中的负对数似然函数的局部极小值结构，发现它们都共享一种常见结构而部分确定了真正的位置混合物的簇中心。这些结果适用于真实混合组分满足某种分离条件的情况，也适用于成分数量过多或过少的情况。 |
| [^51] | [Adaptive, Rate-Optimal Hypothesis Testing in Nonparametric IV Models.](http://arxiv.org/abs/2006.09587) | 我们提出了一种自适应检验方法，用于处理非参数仪器变量模型中的结构函数的不等式和等式限制。该方法可以适应未知的平滑度和工具强度，并达到了最小值率的自适应最优检验率。 |
| [^52] | [Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model.](http://arxiv.org/abs/2005.12900) | 本文提出了两个算法——扰动模型驱动算法和保守模型驱动算法，通过生成模型在较小的样本大小下证明了它们的极小化最大算法优化性能。 |
| [^53] | [Zero-Shot Compositional Policy Learning via Language Grounding.](http://arxiv.org/abs/2004.07200) | 本论文提出了一种通过语言基础实现零样本组合策略学习的算法，该算法将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上，实验证明该算法在零样本组合策略学习任务中表现优于现有的RL/IL算法。 |
| [^54] | [Open-set learning with augmented category by exploiting unlabeled data (Open-LACU).](http://arxiv.org/abs/2002.01368) | Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。 |
| [^55] | [Neighborhood and Graph Constructions using Non-Negative Kernel Regression.](http://arxiv.org/abs/1910.09383) | 本文提出了一种非负核回归的算法来构建更好的邻域和图，并且在各种应用中展示出其优越性和实用性。 |

# 详细

[^1]: 用TiDE进行长期预测：时间序列稠密编码器

    Long-term Forecasting with TiDE: Time-series Dense Encoder. (arXiv:2304.08424v1 [stat.ML])

    [http://arxiv.org/abs/2304.08424](http://arxiv.org/abs/2304.08424)

    TiDE是一种基于MLP的编码器-解码器模型，用于长期时间序列预测。它既具备线性模型的简单性和速度，又能处理协变量和非线性依赖，相较于最佳的Transformer模型，速度快5-10倍。

    

    最近的研究表明，相比于基于Transformer的方法，简单的线性模型在长期时间序列预测中表现更好。鉴于此，我们提出了一种基于多层感知机(MLP)的编码器-解码器模型，即时间序列稠密编码器(TiDE)，用于长期时间序列预测。它既享有线性模型的简单性和速度，又能处理协变量和非线性依赖。从理论上讲，我们证明了我们模型的最简线性类比在一些假设下可以达到线性动态系统(LDS)的近乎最优误差率。实证上，我们表明，我们的方法可以在流行的长期时间序列预测基准测试中匹配或胜过以前的方法，同时比最佳的基于Transformer的模型快5-10倍。

    Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.
    
[^2]: 带有正则化流先验的Langevin Monte Carlo用于成像逆问题

    NF-ULA: Langevin Monte Carlo with Normalizing Flow Prior for Imaging Inverse Problems. (arXiv:2304.08342v1 [math.NA])

    [http://arxiv.org/abs/2304.08342](http://arxiv.org/abs/2304.08342)

    本文提出了一种NF-ULA算法，其中包括学习正则化流作为先验，用于解决成像逆问题的贝叶斯推断采样算法，且有效性得到了在三个成像逆问题上的证明。

    

    贝叶斯方法是解决逆问题的一种强大替代方案，因为贝叶斯方法提供了问题的概率描述并能够量化解决方案中的不确定性。本文尝试将数据驱动模型并入基于Langevin的贝叶斯推断采样算法中。我们引入了NF-ULA（通过正则化流的未调整Langevin算法），其中包括学习正则化流作为先验。我们通过调查贝叶斯解的良好性和NF-ULA算法的非渐进收敛性进行理论分析。我们在三个成像逆问题上进行的实验展示了我们所提出的方法的有效性：图像去模糊，超分辨率和计算机断层扫描（CT）重建。

    Bayesian methods for solving inverse problems are a powerful alternative to classical methods since the Bayesian approach gives a probabilistic description of the problems and offers the ability to quantify the uncertainty in the solution. Meanwhile, solving inverse problems by data-driven techniques also proves to be successful, due to the increasing representation ability of data-based models. In this work, we try to incorporate the data-based models into a class of Langevin-based sampling algorithms in Bayesian inference. Loosely speaking, we introduce NF-ULA (Unadjusted Langevin algorithms by Normalizing Flows), which involves learning a normalizing flow as the prior. In particular, our algorithm only requires a pre-trained normalizing flow, which is independent of the considered inverse problem and the forward operator. We perform theoretical analysis by investigating the well-posedness of the Bayesian solution and the non-asymptotic convergence of the NF-ULA algorithm. The effica
    
[^3]: Bayesian Optimization中线性化Laplace的优势和局限性

    Promises and Pitfalls of the Linearized Laplace in Bayesian Optimization. (arXiv:2304.08309v1 [cs.LG])

    [http://arxiv.org/abs/2304.08309](http://arxiv.org/abs/2304.08309)

    本论文研究了在线性化Laplace逼近(LLA)在Bayesian optimization中的应用。虽然LLA在构建贝叶斯神经网络时已被证明具有效性和高效性，但是在序列决策问题中，需要考虑其可能的局限性。

    

    线性化Laplace逼近(LLA)已被证明在构建贝叶斯神经网络时有效且高效。它在理论上具有吸引力，因为它可以被看作是具有高斯过程后验的最大后验预测函数最大化的神经网络的平均函数，并且由经验神经曲面核诱导的协方差函数。然而，尽管已经研究过其在图像分类等大规模任务中的效果，但在诸如Bayesian optimization这样的序列决策问题中尚未对其进行研究，其中高斯过程是默认的代理模型，具有简单的平均函数和核函数，例如径向基函数。在本文中，我们研究了LLA在Bayesian optimization中的有用性和灵活性，并强调其强大的性能。但是，我们还提出了可能出现的一些问题和一个LLA可能存在的问题，即当搜索空间是无界的时候。

    The linearized-Laplace approximation (LLA) has been shown to be effective and efficient in constructing Bayesian neural networks. It is theoretically compelling since it can be seen as a Gaussian process posterior with the mean function given by the neural network's maximum-a-posteriori predictive function and the covariance function induced by the empirical neural tangent kernel. However, while its efficacy has been studied in large-scale tasks like image classification, it has not been studied in sequential decision-making problems like Bayesian optimization where Gaussian processes -- with simple mean functions and kernels such as the radial basis function -- are the de-facto surrogate models. In this work, we study the usefulness of the LLA in Bayesian optimization and highlight its strong performance and flexibility. However, we also present some pitfalls that might arise and a potential problem with the LLA when the search space is unbounded.
    
[^4]: 使用可处理电路模型进行组合概率和因果推断

    Compositional Probabilistic and Causal Inference using Tractable Circuit Models. (arXiv:2304.08278v1 [cs.AI])

    [http://arxiv.org/abs/2304.08278](http://arxiv.org/abs/2304.08278)

    本文提出了一种新的结构化分解PC的表示法md-vtrees，并提出了基于这种表示法的PC架构MDNets，首次推导出了较为高效的基于PC的因果推断算法。

    

    概率电路 (Probabilistic circuits, PCs) 是一类可处理的概率模型，具有高效的推断例程，取决于它们的结构属性。在本文中，我们介绍了 md-vtrees，这是一种新颖的结构化分解 PC 中（边缘）决定论的表示方法，它推广了先前提出的类别，例如概率符号决策图。关键是，我们展示了如何在合理和可推广的方式中使用 md-vtrees 推导出可处理的条件和高效的算法，用于表示基本概率操作的任意组合，例如边缘化、乘法和倒数等高级推断查询。特别地，我们为基于 PC 的因果推断查询，如反向门控调整 (backdoor adjustment)，推导出了第一个多项式时间算法。作为框架的实际实例，我们提出了 MDNets，这是一种使用 md-vtrees 的新型 PC 架构，并通过实验证明了它们在因果推断中的应用。

    Probabilistic circuits (PCs) are a class of tractable probabilistic models, which admit efficient inference routines depending on their structural properties. In this paper, we introduce md-vtrees, a novel structural formulation of (marginal) determinism in structured decomposable PCs, which generalizes previously proposed classes such as probabilistic sentential decision diagrams. Crucially, we show how mdvtrees can be used to derive tractability conditions and efficient algorithms for advanced inference queries expressed as arbitrary compositions of basic probabilistic operations, such as marginalization, multiplication and reciprocals, in a sound and generalizable manner. In particular, we derive the first polytime algorithms for causal inference queries such as backdoor adjustment on PCs. As a practical instantiation of the framework, we propose MDNets, a novel PC architecture using md-vtrees, and empirically demonstrate their application to causal inference.
    
[^5]: 基于预测的贝叶斯主动学习

    Prediction-Oriented Bayesian Active Learning. (arXiv:2304.08151v1 [cs.LG])

    [http://arxiv.org/abs/2304.08151](http://arxiv.org/abs/2304.08151)

    本文提出了一种基于预测的贝叶斯主动学习方法，即预期预测信息增益（EPIG），这种方法在预测空间而不是参数空间中测量信息增益，可以有效提高预测性能。

    

    信息论方法通常集中于最大化关于模型参数的信息，在优化 BALD 分数方面。我们强调从预测性能的角度来看，这可能是次优的。为了解决这个问题，我们提出了预期预测信息增益（EPIG），一种在预测空间而不是参数空间中测量信息增益的收集函数。我们发现，在各种数据集和模型上使用 EPIG 与 BALD 相比，可以获得更强的预测性能，因此提供了一个有吸引力的替代方案。

    Information-theoretic approaches to active learning have traditionally focused on maximising the information gathered about the model parameters, most commonly by optimising the BALD score. We highlight that this can be suboptimal from the perspective of predictive performance. For example, BALD lacks a notion of an input distribution and so is prone to prioritise data of limited relevance. To address this we propose the expected predictive information gain (EPIG), an acquisition function that measures information gain in the space of predictions rather than parameters. We find that using EPIG leads to stronger predictive performance compared with BALD across a range of datasets and models, and thus provides an appealing drop-in replacement.
    
[^6]: 通过低次多项式检测密集子超图

    Detection of Dense Subhypergraphs by Low-Degree Polynomials. (arXiv:2304.08135v1 [cs.DS])

    [http://arxiv.org/abs/2304.08135](http://arxiv.org/abs/2304.08135)

    本文研究在超图中检测密集子超图的存在问题，并确定了易于实现和困难的问题之间的阈值。

    

    在随机图中探测一个被安置的密集子图是一个基本的统计和计算问题，近年来已经得到了广泛的研究。本文研究了该问题的一个超图版本。我们考虑在一个$G^r(n, n^{-\beta})$的超图中探测一个被安置的$G^r(n^\gamma, n^{-\alpha})$的密集子超图的存在，其中$0<\alpha<\beta<r-1$ and $0<\gamma<1$。我们确定了通过邻接张量的$n^{o(1)}$次多项式的测试易于实现和困难的问题之间的阈值，我们的结果已经是$r=2$的图情形中的新结果。

    Detection of a planted dense subgraph in a random graph is a fundamental statistical and computational problem that has been extensively studied in recent years. We study a hypergraph version of the problem. Let $G^r(n,p)$ denote the $r$-uniform Erd\H{o}s-R\'enyi hypergraph model with $n$ vertices and edge density $p$. We consider detecting the presence of a planted $G^r(n^\gamma, n^{-\alpha})$ subhypergraph in a $G^r(n, n^{-\beta})$ hypergraph, where $0< \alpha < \beta < r-1$ and $0 < \gamma < 1$. Focusing on tests that are degree-$n^{o(1)}$ polynomials of the entries of the adjacency tensor, we determine the threshold between the easy and hard regimes for the detection problem. More precisely, for $0 < \gamma < 1/2$, the threshold is given by $\alpha = \beta \gamma$, and for $1/2 \le \gamma < 1$, the threshold is given by $\alpha = \beta/2 + r(\gamma - 1/2)$.  Our results are already new in the graph case $r=2$, as we consider the subtle log-density regime where hardness based on ave
    
[^7]: Fed-MIWAE: 通过深度生成模型联邦填补未完整数据

    Fed-MIWAE: Federated Imputation of Incomplete Data via Deep Generative Models. (arXiv:2304.08054v1 [stat.ML])

    [http://arxiv.org/abs/2304.08054](http://arxiv.org/abs/2304.08054)

    本论文提出了 Fed-MIWAE，这是基于联邦模型的 MIWAE 缺失数据填补的深度潜变量模型，它能够通过经典联邦聚合器进行简单训练，并具有处理 MAR 数据的能力。

    

    联邦学习允许在不需要明确数据交换的情况下对多个分散的本地数据集进行机器学习模型的训练。然而，数据预处理，包括处理缺失数据的策略，仍然是在实际联邦学习部署中的一个重大瓶颈，并且通常是在本地执行的。本文提出了一种通过联邦模型更一致的方法进行数据标准化的方法。此外，我们提出了 Fed-MIWAE，这是 MIWAE 的联邦版本，它是基于变分自动编码器的缺失数据填补的深度潜变量模型。MIWAE 具有使用经典联邦聚合器进行简单训练的巨大优势。此外，它能够处理 MAR（随机未出现）数据，这是一种更具挑战性的缺失数据机制。

    Federated learning allows for the training of machine learning models on multiple decentralized local datasets without requiring explicit data exchange. However, data pre-processing, including strategies for handling missing data, remains a major bottleneck in real-world federated learning deployment, and is typically performed locally. This approach may be biased, since the subpopulations locally observed at each center may not be representative of the overall one. To address this issue, this paper first proposes a more consistent approach to data standardization through a federated model. Additionally, we propose Fed-MIWAE, a federated version of the state-of-the-art imputation method MIWAE, a deep latent variable model for missing data imputation based on variational autoencoders. MIWAE has the great advantage of being easily trainable with classical federated aggregators. Furthermore, it is able to deal with MAR (Missing At Random) data, a more challenging missing-data mechanism th
    
[^8]: 内在上下文算子学习用于微分方程问题

    In-Context Operator Learning for Differential Equation Problems. (arXiv:2304.07993v1 [cs.LG])

    [http://arxiv.org/abs/2304.07993](http://arxiv.org/abs/2304.07993)

    本文提出了一种新的神经网络方法INDEED，它可以同时学习不同微分方程问题的操作符，而无需重新训练，且只需要极少的演示。

    

    本文介绍了一种新的基于神经网络的方法——IN-context Differential Equation Encoder-Decoder（INDEED），用于从数据中同时学习操作符并在推理阶段将其应用于新问题，而无需进行任何权重更新。现有方法局限于使用神经网络来逼近特定的方程解或特定的操作符，需要重新训练来处理具有不同方程的新问题。通过训练单个神经网络作为操作符学习器，我们不仅可以摆脱为新问题重新训练（甚至微调）神经网络的困扰，还可以利用操作符之间共享的共同点，这样在学习新的操作符时只需要极少的演示即可。我们的数值结果显示了神经网络作为少样本学习器的能力，用于各种不同类型的微分方程问题，包括ODE和PDE的正向和反向问题，同时显示它可以推广学习能力。

    This paper introduces a new neural-network-based approach, namely IN-context Differential Equation Encoder-Decoder (INDEED), to simultaneously learn operators from data and apply it to new questions during the inference stage, without any weight update. Existing methods are limited to using a neural network to approximate a specific equation solution or a specific operator, requiring retraining when switching to a new problem with different equations. By training a single neural network as an operator learner, we can not only get rid of retraining (even fine-tuning) the neural network for new problems, but also leverage the commonalities shared across operators so that only a few demos are needed when learning a new operator. Our numerical results show the neural network's capability as a few-shot operator learner for a diversified type of differential equation problems, including forward and inverse problems of ODEs and PDEs, and also show that it can generalize its learning capabilit
    
[^9]: 模型错误下的贝叶斯最优实验设计度量

    Metrics for Bayesian Optimal Experiment Design under Model Misspecification. (arXiv:2304.07949v1 [stat.ME])

    [http://arxiv.org/abs/2304.07949](http://arxiv.org/abs/2304.07949)

    本文提出了一个拓展的框架，其中的期望一般信息增益和期望鉴别信息作为准则，用来度量模型差异稳健性和实验检测模型差异能力。

    

    贝叶斯决策理论实验设计的传统方法是在可能的实验中搜索，以选择最大化指定效用函数的设计。期望是对所采集数据的统计模型所蕴含的所有未知变量的联合分布。效用函数定义了实验的目标，其中常见的效用函数是信息增益。本文引入了一个扩展的框架，在此过程中，我们超越了传统的期望信息增益准则，并引入了测量模型差异稳健性的期望一般信息增益和量化实验检测模型差异能力的期望鉴别信息作为准则。该框架的功能通过其在涉及线性弹簧质量阻尼系统和F-16模型的情景中的应用进行了展示。

    The conventional approach to Bayesian decision-theoretic experiment design involves searching over possible experiments to select a design that maximizes the expected value of a specified utility function. The expectation is over the joint distribution of all unknown variables implied by the statistical model that will be used to analyze the collected data. The utility function defines the objective of the experiment where a common utility function is the information gain. This article introduces an expanded framework for this process, where we go beyond the traditional Expected Information Gain criteria and introduce the Expected General Information Gain which measures robustness to the model discrepancy and Expected Discriminatory Information as a criterion to quantify how well an experiment can detect model discrepancy. The functionality of the framework is showcased through its application to a scenario involving a linearized spring mass damper system and an F-16 model where the mo
    
[^10]: 基于概率的创新辐射场和具有潜在空间能量模型的 3D 感知解耦图像表示

    Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation. (arXiv:2304.07918v1 [cs.CV])

    [http://arxiv.org/abs/2304.07918](http://arxiv.org/abs/2304.07918)

    这篇论文提出了一种新的基于概率的 3D 感知 2D 图像生成模型 NeRF-LEBM，它结合 NeRF 和可微分体积渲染实现了 3D 表示并入 2D 成像过程，并通过马尔可夫链蒙特卡罗推断和变分推断方法进行训练。实验验证了该模型能够从 2D 图像中推断出 3D 对象结构，生成具有新视角和对象的 2D 图像，学习不完整的 2D 图像，以及从已知或未知相机姿势的 2D 图像中学习。

    

    我们提出了一种 NeRF-LEBM，一种基于概率的自顶向下 3D 感知 2D 图像生成模型，它通过神经辐射场 (NeRF) 和可微分体积渲染将 3D 表示并入 2D 成像过程。该模型将图像表示为从 3D 对象到 2D 图像的渲染过程，条件是一些代表对象特征的潜变量，假设它们遵循信息可训练的基于能量的先验模型。我们提出了两种基于概率的学习框架来训练 NeRF-LEBM：(i)基于马尔可夫链蒙特卡罗推断的最大似然估计和(ii)变分推断和重参数化技巧。我们在已知和未知相机姿势的场景中研究了我们的模型。在几个基准数据集上的实验表明，NeRF-LEBM 可以从 2D 图像中推断出 3D 对象结构，生成具有新视角和对象的 2D 图像，从不完整的 2D 图像中学习，以及从已知或未知相机姿势的 2D 图像中学习。

    We propose the NeRF-LEBM, a likelihood-based top-down 3D-aware 2D image generative model that incorporates 3D representation via Neural Radiance Fields (NeRF) and 2D imaging process via differentiable volume rendering. The model represents an image as a rendering process from 3D object to 2D image and is conditioned on some latent variables that account for object characteristics and are assumed to follow informative trainable energy-based prior models. We propose two likelihood-based learning frameworks to train the NeRF-LEBM: (i) maximum likelihood estimation with Markov chain Monte Carlo-based inference and (ii) variational inference with the reparameterization trick. We study our models in the scenarios with both known and unknown camera poses. Experiments on several benchmark datasets demonstrate that the NeRF-LEBM can infer 3D object structures from 2D images, generate 2D images with novel views and objects, learn from incomplete 2D images, and learn from 2D images with known or 
    
[^11]: 调查数据的惩罚似然推断方法

    Penalized Likelihood Inference with Survey Data. (arXiv:2304.07855v1 [econ.EM])

    [http://arxiv.org/abs/2304.07855](http://arxiv.org/abs/2304.07855)

    本文将三种Lasso推断方法应用于调查数据的推断，证明在具有调查权重和/或异方差的广义线性模型中的推断程序渐近有效性， 并将这些方法推广到对非线性参数函数进行推断，例如在调查logit模型中的平均边际效应

    

    本文将三种Lasso推断方法，Debiased Lasso、$C(\alpha)$和Selective Inference推广到调查数据的环境中。我们证明了在具有调查权重和/或异方差的广义线性模型中推断程序的渐近有效性。此外，我们将这些方法推广到对非线性参数函数进行推断，例如在调查logit模型中的平均边际效应。我们通过模拟数据和加拿大2020年互联网使用调查数据来说明该方法的有效性。

    This paper extends three Lasso inferential methods, Debiased Lasso, $C(\alpha)$ and Selective Inference to a survey environment. We establish the asymptotic validity of the inference procedures in generalized linear models with survey weights and/or heteroskedasticity. Moreover, we generalize the methods to inference on nonlinear parameter functions e.g. the average marginal effect in survey logit models. We illustrate the effectiveness of the approach in simulated data and Canadian Internet Use Survey 2020 data.
    
[^12]: Data-OOB:以无需额外计算的Out-of-bag估计为准的数据价值估计方法

    Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value. (arXiv:2304.07718v1 [cs.LG])

    [http://arxiv.org/abs/2304.07718](http://arxiv.org/abs/2304.07718)

    Data-OOB是一种新的数据价值估计方法，它利用out-of-bag估计，并可以在计算上高效处理大型数据集。

    

    数据评估是一个强大的框架，可以为模型训练提供统计洞察力，以区分哪些数据对于模型训练是有益的，哪些是有害的。纵观各种下游任务，许多以Shapley为基础的数据价值评估方法均显示出了很有前途的结果。然而，由于这需要训练大量的模型，因此众所周知，这是具有挑战性的。因此，将此应用于大型数据集是不可行的。为了解决这个问题，我们提出了Data-OOB，这是一种新的数据价值估计方法，针对bagging模型，它利用了out-of-bag估计。所提出的方法在计算上是高效的，可以通过重复使用训练好的弱学习器来扩展到数百万个数据。具体而言，当评估100个输入维度且存在$10^6$个样本时，Data-OOB仅需要在单个CPU处理器上执行不到2.25个小时。此外，Data-OOB在理论上有坚实的解释，当两个离差值函数相同时，其识别具有相同重要性的数据点。

    Data valuation is a powerful framework for providing statistical insights into which data are beneficial or detrimental to model training. Many Shapley-based data valuation methods have shown promising results in various downstream tasks, however, they are well known to be computationally challenging as it requires training a large number of models. As a result, it has been recognized as infeasible to apply to large datasets. To address this issue, we propose Data-OOB, a new data valuation method for a bagging model that utilizes the out-of-bag estimate. The proposed method is computationally efficient and can scale to millions of data by reusing trained weak learners. Specifically, Data-OOB takes less than 2.25 hours on a single CPU processor when there are $10^6$ samples to evaluate and the input dimension is 100. Furthermore, Data-OOB has solid theoretical interpretations in that it identifies the same important data point as the infinitesimal jackknife influence function when two d
    
[^13]: 学习经验Bregman散度用于不确定距离表示

    Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])

    [http://arxiv.org/abs/2304.07689](http://arxiv.org/abs/2304.07689)

    本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。

    

    深度度量学习技术已应用于各种监督和无监督学习任务，通过深度网络学习样本嵌入来进行视觉表示。然而，经典方法采用固定距离度量作为两个嵌入之间的相似性函数，可能导致捕捉复杂数据分布的亚最优性能。Bregman散度概括了各种距离度量的度量，并在许多深度度量学习领域中产生。本文首先展示了如何从Bregman散度获得深度度量学习损失。然后，我们介绍了一种直接从数据中学习经验Bregman散度的新方法，通过使用深度学习设置对Bregman散度下的凸函数进行参数化。我们进一步实验证明，与其他SOTA深度度量学习方法相比，我们的方法在五个流行公共数据集上表现出色，特别是在模式识别和聚类任务上。

    Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
    
[^14]: 贝叶斯分层建模中主动学习回归中的动态探索-开发权衡

    Dynamic Exploration-Exploitation Trade-Off in Active Learning Regression with Bayesian Hierarchical Modeling. (arXiv:2304.07665v1 [cs.LG])

    [http://arxiv.org/abs/2304.07665](http://arxiv.org/abs/2304.07665)

    本文提出了一个新方法，利用贝叶斯分层建模，动态平衡探索-开发权衡，以更好地查询数据点。

    

    主动学习提供了一种自适应采样最具信息的实验以学习未知的黑盒函数的框架。本文提出了一种贝叶斯分层方法来动态平衡探索-开发权衡，以更好地查询数据点。

    Active learning provides a framework to adaptively sample the most informative experiments towards learning an unknown black-box function. Various approaches of active learning have been proposed in the literature, however, they either focus on exploration or exploitation in the design space. Methods that do consider exploration-exploitation simultaneously employ fixed or ad-hoc measures to control the trade-off that may not be optimal. In this paper, we develop a Bayesian hierarchical approach to dynamically balance the exploration-exploitation trade-off as more data points are queried. We subsequently formulate an approximate Bayesian computation approach based on the linear dependence of data samples in the feature space to sample from the posterior distribution of the trade-off parameter obtained from the Bayesian hierarchical model. Simulated and real-world examples show the proposed approach achieves at least 6% and 11% average improvement when compared to pure exploration and ex
    
[^15]: 作为概率推断的降维方法

    Dimensionality Reduction as Probabilistic Inference. (arXiv:2304.07658v1 [stat.ML])

    [http://arxiv.org/abs/2304.07658](http://arxiv.org/abs/2304.07658)

    该论文提出了ProbDR变分框架，将经典降维算法解释为概率推断算法，通过优化一个证据下界来完成推断操作。该框架不仅可以完成常规降维算法，还支持使用概率编程语言进行降维操作，具有强大的表达能力。

    

    降维算法将高维数据压缩到低维表示中，同时保留数据的重要特征。降维是许多分析流程中的关键步骤，因为它实现了数据的可视化、噪声降低和高效的下游处理。在本文中，我们引入了ProbDR变分框架，将广泛的经典DR算法解释为该框架中的概率推断算法。ProbDR包括PCA、CMDS、LLE、LE、MVU、扩散映射、kPCA、Isomap、(t-)SNE和UMAP。在我们的框架中，一个低维潜变量用于构建协方差、精度或图拉普拉斯矩阵，可以作为数据的生成模型的一部分。推断是通过优化一个证据下界来完成的。我们展示了我们框架的内部一致性，并表明它支持使用概率编程语言（PPL）进行DR。此外，我们证明了该框架可以完成常规DR算法的操作，并赋予了它通过概率变分推断的强大表达力。

    Dimensionality reduction (DR) algorithms compress high-dimensional data into a lower dimensional representation while preserving important features of the data. DR is a critical step in many analysis pipelines as it enables visualisation, noise reduction and efficient downstream processing of the data. In this work, we introduce the ProbDR variational framework, which interprets a wide range of classical DR algorithms as probabilistic inference algorithms in this framework. ProbDR encompasses PCA, CMDS, LLE, LE, MVU, diffusion maps, kPCA, Isomap, (t-)SNE, and UMAP. In our framework, a low-dimensional latent variable is used to construct a covariance, precision, or a graph Laplacian matrix, which can be used as part of a generative model for the data. Inference is done by optimizing an evidence lower bound. We demonstrate the internal consistency of our framework and show that it enables the use of probabilistic programming languages (PPLs) for DR. Additionally, we illustrate that the f
    
[^16]: 基于平均二阶相似性的随机分布式优化：算法与分析

    Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis. (arXiv:2304.07504v1 [cs.LG])

    [http://arxiv.org/abs/2304.07504](http://arxiv.org/abs/2304.07504)

    本文提出了两种新算法SVRS和AccSVRS，针对分布式优化问题，实现了卓越的通信复杂度。其中，AccSVRS算法实现了完全无平滑性，通信复杂度更是优于现有算法。

    

    本文研究了具有$n$个客户端的有限和分布式优化问题，满足流行的$\delta$-相似性条件和$\mu$-强凸性。我们提出了两种新算法：SVRS和AccSVRS，启发自先前的工作。非加速的SVRS方法结合了梯度滑动和方差缩减技术，实现了卓越的通信复杂度$\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$，与现有的非加速算法相比有所提高。应用Katyusha X提出的框架，我们还建立了一个名为AccSVRS的直接加速实际版本，其完全无平滑性，通信复杂度为$\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$，在病态情况下优于现有算法。此外，我们展示了一种接近匹配的下界，以验证我们的AccSVRS方法的紧密程度。

    We study finite-sum distributed optimization problems with $n$-clients under popular $\delta$-similarity condition and $\mu$-strong convexity. We propose two new algorithms: SVRS and AccSVRS motivated by previous works. The non-accelerated SVRS method combines the techniques of gradient-sliding and variance reduction, which achieves superior communication complexity $\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$ compared to existing non-accelerated algorithms. Applying the framework proposed in Katyusha X, we also build a direct accelerated practical version named AccSVRS with totally smoothness-free $\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$ communication complexity that improves upon existing algorithms on ill-conditioning cases. Furthermore, we show a nearly matched lower bound to verify the tightness of our AccSVRS method.
    
[^17]: 通用核学习的高效凸优化算法

    Efficient Convex Algorithms for Universal Kernel Learning. (arXiv:2304.07472v1 [stat.ML])

    [http://arxiv.org/abs/2304.07472](http://arxiv.org/abs/2304.07472)

    本文提出了一种基于SVD-QCQP原始对偶算法的高效内核学习实现，用于学习半分离核，大大降低了计算复杂度，并在几个基准数据集上展示了其准确性和速度。

    

    基于核优化的机器学习算法的准确性和复杂性取决于它们能够优化的核集。理想的核集应该：具有线性参数化（以便于可处理性）；在所有核集中密集（以便于鲁棒性）；是通用的（以便于准确性）。最近，提出了一种框架，使用正定矩阵来参数化一类正半分离核。尽管此类核能够满足所有三个标准，但之前用于优化此类核的算法仅限于分类，并且还依赖于计算复杂的半定规划（SDP）算法。在本文中，我们将学习半分离核的问题作为极小化极大化优化问题，并提出了一种SVD-QCQP原始对偶算法，其与之前基于SDP的方法相比，大大降低了计算复杂度。此外，我们提供了一种高效的内核学习实现，并在几个基准数据集上展示了其准确性和速度。

    The accuracy and complexity of machine learning algorithms based on kernel optimization are determined by the set of kernels over which they are able to optimize. An ideal set of kernels should: admit a linear parameterization (for tractability); be dense in the set of all kernels (for robustness); be universal (for accuracy). Recently, a framework was proposed for using positive matrices to parameterize a class of positive semi-separable kernels. Although this class can be shown to meet all three criteria, previous algorithms for optimization of such kernels were limited to classification and furthermore relied on computationally complex Semidefinite Programming (SDP) algorithms. In this paper, we pose the problem of learning semiseparable kernels as a minimax optimization problem and propose a SVD-QCQP primal-dual algorithm which dramatically reduces the computational complexity as compared with previous SDP-based approaches. Furthermore, we provide an efficient implementation of thi
    
[^18]: 稀疏正则化在综合分析中的多元回归建模

    Multivariate regression modeling in integrative analysis via sparse regularization. (arXiv:2304.07451v1 [stat.ME])

    [http://arxiv.org/abs/2304.07451](http://arxiv.org/abs/2304.07451)

    本研究提出了稀疏正则化在综合分析中的多元回归建模方法，并采用交替方向乘子方法开发了其计算算法。该方法可从多个独立数据集中汇集有用信息并比单个数据集分析提供更好的性能。

    

    多元回归模型基本上提供了对具有多个响应的单个数据集的分析。但是，这种单一数据集分析通常会导致令人不满意的结果。综合分析是一种有效的方法，可从多个独立数据集中汇集有用信息，并比单个数据集分析提供更好的性能。在本研究中，我们提出了一种多元回归建模的综合分析方法。集成是通过稀疏估计实现的，该估计执行变量和组选择。基于交替方向乘子方法的思想，我们开发了其计算算法，可享有收敛性质。该方法的性能通过蒙特卡罗模拟和分析带有微生物测量值的废水处理数据来加以论证。

    The multivariate regression model basically offers the analysis of a single dataset with multiple responses. However, such a single-dataset analysis often leads to unsatisfactory results. Integrative analysis is an effective method to pool useful information from multiple independent datasets and provides better performance than single-dataset analysis. In this study, we propose a multivariate regression modeling in integrative analysis. The integration is achieved by sparse estimation that performs variable and group selection. Based on the idea of alternating direction method of multipliers, we develop its computational algorithm that enjoys the convergence property. The performance of the proposed method is demonstrated through Monte Carlo simulation and analyzing wastewater treatment data with microbe measurements.
    
[^19]: 未观测到代理奖励的重复负责人代理博弈问题研究

    Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents. (arXiv:2304.07407v1 [cs.LG])

    [http://arxiv.org/abs/2304.07407](http://arxiv.org/abs/2304.07407)

    本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    

    本文研究了一个多臂老虎机框架中的重复负责人代理博弈场景，其中代理选择一种老虎机后会获得奖励和激励，但负责人只能观察到代理选择了哪个老虎机以及代理相应的激励，而想要设计一种合适的策略却充满了挑战性。本文提出了一种利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    Motivated by a number of real-world applications from domains like healthcare and sustainable transportation, in this paper we study a scenario of repeated principal-agent games within a multi-armed bandit (MAB) framework, where: the principal gives a different incentive for each bandit arm, the agent picks a bandit arm to maximize its own expected reward plus incentive, and the principal observes which arm is chosen and receives a reward (different than that of the agent) for the chosen arm. Designing policies for the principal is challenging because the principal cannot directly observe the reward that the agent receives for their chosen actions, and so the principal cannot directly learn the expected reward using existing estimation techniques. As a result, the problem of designing policies for this scenario, as well as similar ones, remains mostly unexplored. In this paper, we construct a policy that achieves a low regret (i.e., square-root regret up to a log factor) in this scenar
    
[^20]: 基于GLASS模型的脑机接口贝叶斯推断

    Bayesian inference on Brain-Computer Interface using the GLASS Model. (arXiv:2304.07401v1 [stat.AP])

    [http://arxiv.org/abs/2304.07401](http://arxiv.org/abs/2304.07401)

    本文针对P300 BCI问题，开发了一种基于GLASS模型的贝叶斯推断方法，直接解决了脑机接口应用中数据集不平衡问题，具有良好的分类性能和易于解释性。

    

    脑机接口（BCI）使重度残疾人士与世界进行交流。BCI将实时的脑活动转化为计算机指令，通常被认为是一个分类问题，计算神经科学提供了机遇和挑战。本文集中在使用事件相关电位（ERP）BCI设计的P300 BCI上。我们开发了一种新颖的具有稀疏时变效应的高斯潜在组模型（GLASS），用于在P300 BCI上进行贝叶斯推断。GLASS采用多项式回归框架，直接解决了BCI应用中的数据集不平衡问题。先验规范促进了i）使用软阈值进行特征选择和噪声降低，ii）使用全局收缩对时变效应进行平滑处理，iii）对潜在组进行聚类，以减轻EEG数据的高空间相关性。我们开发了一种有效的图模型算法，用于后验计算和模型选择。所提出的GLASS模型在基准数据集上实现了竞争性的分类性能，并提供了所推断的条件相关时空模式的易于解释性。

    The brain-computer interface (BCI) enables individuals with severe physical impairments to communicate with the world. BCIs offer computational neuroscience opportunities and challenges in converting real-time brain activities to computer commands and are typically framed as a classification problem. This article focuses on the P300 BCI that uses the event-related potential (ERP) BCI design, where the primary challenge is classifying target/non-target stimuli. We develop a novel Gaussian latent group model with sparse time-varying effects (GLASS) for making Bayesian inferences on the P300 BCI. GLASS adopts a multinomial regression framework that directly addresses the dataset imbalance in BCI applications. The prior specifications facilitate i) feature selection and noise reduction using soft-thresholding, ii) smoothing of the time-varying effects using global shrinkage, and iii) clustering of latent groups to alleviate high spatial correlations of EEG data. We develop an efficient gra
    
[^21]: 分布化多任务学习中的精确子空间扩散

    Exact Subspace Diffusion for Decentralized Multitask Learning. (arXiv:2304.07358v1 [cs.LG])

    [http://arxiv.org/abs/2304.07358](http://arxiv.org/abs/2304.07358)

    本论文提出了一种新的分布式多任务学习算法，通过精确扩散算法的推广，并在网络中进行子空间约束。相比于现有的基于近似投影的方法，其性能得到了明显提升。

    

    传统的分布式学习方法，如联邦学习或分散式梯度下降，采用共识机制来强制实现代理之间的同质性。虽然这些策略在独立同分布场景下被证明是有效的，但在代理遵循异构目标或数据时，它们可能导致严重的性能降低。另一方面，多任务学习的分布式策略以更加微妙的方式在代理之间建立关系，并鼓励协作而不是强制共识。我们发展了用于通过网络进行子空间约束的多任务学习的精确扩散算法的推广，并导出了在利用噪声梯度逼近时其均方偏差的准确表达式。我们在数值上验证了预测性能表达式的准确性，以及所提出的方法相对于基于近似投影的其他方法的性能改进。

    Classical paradigms for distributed learning, such as federated or decentralized gradient descent, employ consensus mechanisms to enforce homogeneity among agents. While these strategies have proven effective in i.i.d. scenarios, they can result in significant performance degradation when agents follow heterogeneous objectives or data. Distributed strategies for multitask learning, on the other hand, induce relationships between agents in a more nuanced manner, and encourage collaboration without enforcing consensus. We develop a generalization of the exact diffusion algorithm for subspace constrained multitask learning over networks, and derive an accurate expression for its mean-squared deviation when utilizing noisy gradient approximations. We verify numerically the accuracy of the predicted performance expressions, as well as the improved performance of the proposed approach over alternatives based on approximate projections.
    
[^22]: 正半定矩阵的极值特征值差分几何

    Differential geometry with extreme eigenvalues in the positive semidefinite cone. (arXiv:2304.07347v1 [math.DG])

    [http://arxiv.org/abs/2304.07347](http://arxiv.org/abs/2304.07347)

    本文提出了一种基于半定锥中的汤普森几何学的可扩展几何框架，利用极广义特征值有效地分析和处理对称正定矩阵数据。同时，基于此几何方法，定义了一种新型 SPD 矩阵迭代平均算法，证明了其存在性和唯一性。

    

    对称正定矩阵 (SPD) 数据的微分几何方法已被成功应用于计算机视觉、医学成像和机器学习等多个领域。然而，现有几何范式的谱计算成本高昂，难以在高维度和大规模数据下实现。本文基于半定锥的希尔伯特和汤普森几何学提出了计算极广义特征值的可扩展几何框架，构建了基于汤普森几何学的测地空间结构，并证明了这一结构的多个属性。此外，定义了一个基于该几何方法的新型 SPD 矩阵迭代平均，并证明了在给定有限个 SPD 矩阵的情况下其存在性和唯一性。

    Differential geometric approaches to the analysis and processing of data in the form of symmetric positive definite (SPD) matrices have had notable successful applications to numerous fields including computer vision, medical imaging, and machine learning. The dominant geometric paradigm for such applications has consisted of a few Riemannian geometries associated with spectral computations that are costly at high scale and in high dimensions. We present a route to a scalable geometric framework for the analysis and processing of SPD-valued data based on the efficient computation of extreme generalized eigenvalues through the Hilbert and Thompson geometries of the semidefinite cone. We explore a particular geodesic space structure based on Thompson geometry in detail and establish several properties associated with this structure. Furthermore, we define a novel iterative mean of SPD matrices based on this geometry and prove its existence and uniqueness for a given finite collection of 
    
[^23]: 基于符合性预测和符合性风险控制的有信心物体检测：铁路信号应用研究

    Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling. (arXiv:2304.06052v1 [cs.LG])

    [http://arxiv.org/abs/2304.06052](http://arxiv.org/abs/2304.06052)

    本文展示了利用符合性预测框架构建可靠、值得信赖的铁路信号预测器的方法，并引入一种基于符合性风险控制的新方法。研究结果表明符合性预测框架有潜力为实现正式保证的不确定性边界提供实用指导。

    

    在实际认证系统中使用深度学习模型需要提供能够准确反映不确定性的置信度估计。本文演示了利用符合性预测框架构建可靠的、值得信赖的检测铁路信号的预测器的方法。我们使用包含火车操作员视角下的图像和最先进的物体检测器的新数据集。我们测试了几种符合性方法，并引入了一种基于符合性风险控制的新方法。研究结果表明符合性预测框架评估模型性能和提供正式保证的不确定性边界具有潜力，为实现这一目标提供了实用指导。

    Deploying deep learning models in real-world certified systems requires the ability to provide confidence estimates that accurately reflect their uncertainty. In this paper, we demonstrate the use of the conformal prediction framework to construct reliable and trustworthy predictors for detecting railway signals. Our approach is based on a novel dataset that includes images taken from the perspective of a train operator and state-of-the-art object detectors. We test several conformal approaches and introduce a new method based on conformal risk control. Our findings demonstrate the potential of the conformal prediction framework to evaluate model performance and provide practical guidance for achieving formally guaranteed uncertainty bounds.
    
[^24]: 我们实现了个性化治疗吗？使用重复采样的在线强化学习算法进行个性化评估

    Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])

    [http://arxiv.org/abs/2304.05365](http://arxiv.org/abs/2304.05365)

    本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。

    

    在数字健康中，使用强化学习（RL）个性化治疗序列以支持用户采取更健康的行为越来越受到关注。这种连续决策问题涉及到基于用户的上下文（例如，先前的活动水平、位置等）在何时治疗以及如何治疗的决定。在线RL算法是这个问题的一个有前途的数据驱动方法，因为它基于每个用户的历史反馈进行学习，并利用这些知识个性化这些决策。然而，要决定是否应在实际部署的“优化”干预中包含RL算法，我们必须评估数据证据，表明RL算法实际上正在将治疗个性化适应其用户。由于RL算法中的随机性，人们可能会对其在某些状态下的学习并使用此学习来提供特定治疗的能力产生误解。我们使用工作定义的个性化，并介绍了一种重复采样政策评估方法来评估在线RL算法实现的个性化水平。我们使用模拟评估了我们提出的方法，并展示了我们的方法可以准确地识别个性化的策略。我们提出的方法在优化数字健康的个性化干预方面具有潜在应用。

    There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
    
[^25]: 大规模适应性实验：灵活批处理的贝叶斯算法

    Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])

    [http://arxiv.org/abs/2303.11582](http://arxiv.org/abs/2303.11582)

    本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。

    

    标准的贝叶斯算法假定持续重新分配测量工作，这在实现过程中存在延迟反馈和基础设施/组织难题等挑战。本文针对仅有少数重新分配阶段的实际情况，其中测量结果是以批处理形式测量的，提出了一种新的适应性实验框架，可灵活处理任何批处理大小。我们的主要观察是，在统计推断中普遍使用的正态近似也可以指导可扩展自适应设计。通过推导渐进顺序实验，我们制定了一种动态规划，可以利用平均回报的先验信息。动态规划的状态转移相对于采样分配是可微的，允许使用基于梯度的方法进行规划和策略优化。我们提出了一种简单的迭代规划方法，即残余时限优化，通过优化平衡探索和利用的规划目标来选择采样分配。在合成和真实世界基准测试问题上的实验结果表明，我们的框架实现了最先进的性能，同时具有模块化和易用性。

    Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
    
[^26]: 通过超球统一性差填补神经坍塌的泛化和解耦

    Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap. (arXiv:2303.06484v1 [cs.LG])

    [http://arxiv.org/abs/2303.06484](http://arxiv.org/abs/2303.06484)

    本文提出了一个广义神经坍塌假设，有效地包含了原始神经坍塌，并将其分解为两个目标：最小化类内变异性和最大化类间可分性。使用超球统一性作为量化这两个目标的统一框架，并提出了一个通用目标——超球统一性差（HUG），它由类间和类内超球统一性之间的差异定义。

    This paper proposes a generalized neural collapse hypothesis that effectively subsumes the original neural collapse and decomposes it into two objectives: minimizing intra-class variability and maximizing inter-class separability. The authors use hyperspherical uniformity as a unified framework to quantify these objectives and propose a general objective, hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical uniformity.

    神经坍塌现象描述了深度神经网络的底层几何对称性，其中深度学习的特征和分类器都收敛于一个等角紧框架。已经证明，交叉熵损失和均方误差都可以导致神经坍塌。我们消除了神经坍塌对特征维度和类别数量的关键假设，然后提出了一个广义神经坍塌假设，有效地包含了原始神经坍塌。受神经坍塌描述神经网络训练目标的启发，我们将广义神经坍塌分解为两个目标：最小化类内变异性和最大化类间可分性。然后，我们使用超球统一性（它描述了单位超球上均匀性的程度）作为量化这两个目标的统一框架。最后，我们提出了一个通用目标——超球统一性差（HUG），它由类间和类内超球统一性之间的差异定义。

    The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a simplex equiangular tight frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We remove NC's key assumption on the feature dimension and the number of classes, and then present a generalized neural collapse (GNC) hypothesis that effectively subsumes the original NC. Inspired by how NC characterizes the training target of neural networks, we decouple GNC into two objectives: minimal intra-class variability and maximal inter-class separability. We then use hyperspherical uniformity (which characterizes the degree of uniformity on the unit hypersphere) as a unified framework to quantify these two objectives. Finally, we propose a general objective -- hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical un
    
[^27]: 一种用于连续超参数优化的Lipschitz乐观策略算法

    A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization. (arXiv:2302.01539v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01539](http://arxiv.org/abs/2302.01539)

    BLiE是一种用于超参数优化的算法，只假设目标函数具有Lipschitz连续性。理论和实验证明BLiE优于现有算法，并且可以应用于搜索扩散模型的噪声调度。

    

    在机器学习中，超参数优化（HPO）是最关键的问题之一，因为超参数的选择对最终模型的性能有重要影响。虽然有许多HPO算法，但它们要么没有理论保证，要么需要强的假设。为此，我们介绍了BLiE——一种基于Lipschitz乐观策略的HPO算法，它只假设目标函数具有Lipschitz连续性。BLiE利用目标函数的景观以自适应地搜索超参数空间。理论上，我们证明了$(i)$ BLiE发现具有$O(\frac{1}{\epsilon})^{d_z+\beta}$个总预算的$\epsilon$最优超参数，其中$d_z$和$\beta$是问题内在的；$(ii)$ BLiE具有高度可并行性。实验上，我们证明了BLiE在基准任务上优于现有的HPO算法。我们还应用BLiE搜索扩散模型的噪声调度。与默认调度相比较，BLiE表现出更好的性能。

    One of the most critical problems in machine learning is HyperParameter Optimization (HPO), since choice of hyperparameters has a significant impact on final model performance. Although there are many HPO algorithms, they either have no theoretical guarantees or require strong assumptions. To this end, we introduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes Lipschitz continuity of the objective function. BLiE exploits the landscape of the objective function to adaptively search over the hyperparameter space. Theoretically, we show that $(i)$ BLiE finds an $\epsilon$-optimal hyperparameter with $O \left( \frac{1}{\epsilon} \right)^{d_z + \beta}$ total budgets, where $d_z$ and $\beta$ are problem intrinsic; $(ii)$ BLiE is highly parallelizable. Empirically, we demonstrate that BLiE outperforms the state-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to search for noise schedule of diffusion models. Comparison with the default schedule shows tha
    
[^28]: 学习用于图像识别的广义混合距离表示

    Learning Generalized Hybrid Proximity Representation for Image Recognition. (arXiv:2301.13459v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13459](http://arxiv.org/abs/2301.13459)

    该文章提出了一种新的图像识别的监督度量学习方法，能够以混合方法学习更好的距离表示。通过控制几何近邻和概率近邻之间的权衡，从图像数据中学习通用的混合相似特征。

    

    近年来，深度度量学习技术受到关注，因为学习到的距离表示可用于捕捉样本之间的相似性关系，并进一步提高各种监督或无监督学习任务的性能。我们提出了一种新的监督度量学习方法，可学习几何和概率空间中的距离度量，用于图像识别。与先前的度量学习方法通常侧重于学习欧几里德空间中的距离度量不同，我们提出的方法能够以混合方法学习更好的距离表示。为了实现这一点，我们提出了广义混合度量损失（GHM-Loss）来通过控制几何近邻和概率近邻之间的权衡从图像数据中学习通用的混合相似特征。为了评估我们方法的有效性，我们首先提供了所提出的损失函数的理论推导和证明，然后在几个基准数据集上进行实验，结果表明我们提出的方法优于这些数据集上的现有最先进方法。

    Recently, deep metric learning techniques received attention, as the learned distance representations are useful to capture the similarity relationship among samples and further improve the performance of various of supervised or unsupervised learning tasks. We propose a novel supervised metric learning method that can learn the distance metrics in both geometric and probabilistic space for image recognition. In contrast to the previous metric learning methods which usually focus on learning the distance metrics in Euclidean space, our proposed method is able to learn better distance representation in a hybrid approach. To achieve this, we proposed a Generalized Hybrid Metric Loss (GHM-Loss) to learn the general hybrid proximity features from the image data by controlling the trade-off between geometric proximity and probabilistic proximity. To evaluate the effectiveness of our method, we first provide theoretical derivations and proofs of the proposed loss function, then we perform ex
    
[^29]: 学习Boltzmann密度的变形轨迹

    Learning Deformation Trajectories of Boltzmann Densities. (arXiv:2301.07388v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.07388](http://arxiv.org/abs/2301.07388)

    本文介绍了一种学习Boltzmann密度变形轨迹的方法，其中通过插值能量函数等实现Boltzmann密度的变形，然后找到一个时间依赖向量场，将样本从一个分布转移到另一个分布，其表现在高斯混合和量子力学粒子的Boltzmann密度上比KL-反散度更具优势。

    

    我们提出了一种连续标准化流的训练方法，可以在没有样本但存在能量函数的情况下使用。我们的方法依赖于能量函数$f_1$和广义高斯函数$f_0$之间的预定或学习插值$f_t$。能量函数的插值引起Boltzmann密度$p_t\propto e^{-f_t}$的插值，我们旨在找到一个沿着族$p_t$的时间依赖向量场$V_t$，将样本从一个分布转移到另一个分布。将样本沿着族$p_t$从一个分布转移到另一个分布的条件可以转化为$V_t$和$f_t$之间的PDE，我们优化$V_t$和$f_t$以满足此PDE。我们在高斯混合和双井势的量子力学粒子的Boltzmann密度上实验比较了所提出的训练目标与KL-反散度的差异。

    We introduce a training objective for continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian $f_0(x) = ||x/\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ can be translated to a PDE between $V_t$ and $f_t$ and we optimize $V_t$ and $f_t$ to satisfy this PDE. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential.
    
[^30]: 切片最优偏转运输

    Sliced Optimal Partial Transport. (arXiv:2212.08049v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08049](http://arxiv.org/abs/2212.08049)

    本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。

    

    最优传输（OT）已经在机器学习、数据科学和计算机视觉中变得极其流行。OT问题的核心假设是源和目标测度的总质量相等，这限制了它的应用。最优偏转运输（OPT）是最近提出的解决这个限制的方法。与OT问题类似，OPT的计算依赖于解决线性规划问题（通常在高维度中），这可能会变得计算上困难。在本文中，我们提出了一种计算一维非负测度之间OPT问题的有效算法。接下来，遵循切片OT距离的思想，我们利用切片定义了切片OPT距离。最后，我们展示了切片OPT-based方法在各种数值实验中的计算和精度优势。特别是，我们展示了我们提出的Sliced-OPT在噪声点云配准中的应用。

    Optimal transport (OT) has become exceedingly popular in machine learning, data science, and computer vision. The core assumption in the OT problem is the equal total amount of mass in source and target measures, which limits its application. Optimal Partial Transport (OPT) is a recently proposed solution to this limitation. Similar to the OT problem, the computation of OPT relies on solving a linear programming problem (often in high dimensions), which can become computationally prohibitive. In this paper, we propose an efficient algorithm for calculating the OPT problem between two non-negative measures in one dimension. Next, following the idea of sliced OT distances, we utilize slicing to define the sliced OPT distance. Finally, we demonstrate the computational and accuracy benefits of the sliced OPT-based method in various numerical experiments. In particular, we show an application of our proposed Sliced-OPT in noisy point cloud registration.
    
[^31]: 带有组公平约束的可扩展谱聚类

    Scalable Spectral Clustering with Group Fairness Constraints. (arXiv:2210.16435v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.16435](http://arxiv.org/abs/2210.16435)

    本文提出了一个带有组公平约束的可扩展谱聚类算法 s-FairSC，并通过稀疏矩阵向量乘积来充分利用其稀疏性。

    

    机器学习中建模公平性和纠正算法偏差的研究兴趣和工业实践协同作用。本文提出了一种带有组公平约束的可扩展谱聚类（SC）算法。组公平也被称为统计平等，即在每个簇中，每个受保护的组别以与整体相同的比例表示。我们通过结合零空间投影和霍特林的缩减的新的谱计算方法，提出了一个名为 s-FairSC 的算法，它只涉及稀疏的矩阵向量乘积，能够充分利用公平 SC 模型的稀疏性。

    There are synergies of research interests and industrial efforts in modeling fairness and correcting algorithmic bias in machine learning. In this paper, we present a scalable algorithm for spectral clustering (SC) with group fairness constraints. Group fairness is also known as statistical parity where in each cluster, each protected group is represented with the same proportion as in the entirety. While FairSC algorithm (Kleindessner et al., 2019) is able to find the fairer clustering, it is compromised by high costs due to the kernels of computing nullspaces and the square roots of dense matrices explicitly. We present a new formulation of underlying spectral computation by incorporating nullspace projection and Hotelling's deflation such that the resulting algorithm, called s-FairSC, only involves the sparse matrix-vector products and is able to fully exploit the sparsity of the fair SC model. The experimental results on the modified stochastic block model demonstrate that s-FairSC
    
[^32]: 通用对抗方向

    Universal Adversarial Directions. (arXiv:2210.15997v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.15997](http://arxiv.org/abs/2210.15997)

    研究证明传统的通用对抗干扰 (UAPs) 在深度神经网络分类器之间转移性是次优的，为此本文提出了通用对抗方向 (UADs)，只固定通用方向，以便克服在跨DNN架构上转移的挑战。

    

    尽管深度神经网络在图像识别任务中表现出色，但观察到它们容易受到通用对抗干扰 (UAPs) 的影响，这些干扰使用单个扰动向量干扰所有输入样本。然而，UAPs在跨DNN架构转移时通常很困难并导致挑战性优化问题。本文研究了UAP的可Transfer性，通过分析分类器和UAP对手玩家之间在通用对抗示例博弈中的均衡情况。我们表明，在温和的假设下，通用对抗示例博弈缺乏一个纯纳什均衡，这表明UAPs在DNN分类器之间的转移性是次优的。针对这个问题，我们提出了通用对抗方向 (UADs)，只固定对抗干扰的通用方向，允许跨样本自由选择干扰的幅度。我们证明，UAD对抗示例博弈可以具有纳什均衡且该均衡状态纯。

    Despite their great success in image recognition tasks, deep neural networks (DNNs) have been observed to be susceptible to universal adversarial perturbations (UAPs) which perturb all input samples with a single perturbation vector. However, UAPs often struggle in transferring across DNN architectures and lead to challenging optimization problems. In this work, we study the transferability of UAPs by analyzing equilibrium in the universal adversarial example game between the classifier and UAP adversary players. We show that under mild assumptions the universal adversarial example game lacks a pure Nash equilibrium, indicating UAPs' suboptimal transferability across DNN classifiers. To address this issue, we propose Universal Adversarial Directions (UADs) which only fix a universal direction for adversarial perturbations and allow the perturbations' magnitude to be chosen freely across samples. We prove that the UAD adversarial example game can possess a Nash equilibrium with a pure U
    
[^33]: 利用变分因果推断和精细关系信息预测细胞响应

    Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information. (arXiv:2210.00116v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00116](http://arxiv.org/abs/2210.00116)

    本研究利用基因调控网络信息设计了一种新的因果推断框架，并通过邻接矩阵更新技术预训练图卷积网络以更好地预测细胞在反事实干扰下的基因表达。同时，我们提出了一个鲁棒的估计器来高效估计边缘干扰效应。研究结果展示了该框架的优越性能。

    

    预测细胞在干扰下的响应可能为药物研发和个性化治疗带来重要好处。在本研究中，我们提出了一种新的图形变分贝叶斯因果推断框架，预测细胞在反事实干扰下（即细胞未真实接收的干扰）的基因表达，利用代表生物学知识的基因调控网络（GRN）信息来辅助个性化细胞响应预测。我们还针对数据自适应GRN开发了邻接矩阵更新技术用于图卷积网络的预训练，在模型性能上提供了更多的基因关系洞见。

    Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advanta
    
[^34]: 马尔科夫观测模型

    Markov Observation Models. (arXiv:2208.06368v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.06368](http://arxiv.org/abs/2208.06368)

    本文针对隐马尔可夫模型扩展为允许马尔可夫链观测，研究了相应的期望最大化算法类比算法，并实现了相应的滤波和Viterbi算法。

    

    本文将隐马尔可夫模型扩展为允许马尔可夫链观测。特别地，假设观测值是具有马尔可夫性质的链，其一步转移概率依赖于隐藏的马尔可夫链。针对这种更加普遍的模型，研究了期望最大化算法与Baum-Welch算法的类比算法，以估计隐藏状态和观测序列的转移概率，以及估计初始联合隐藏状态-观测分布的概率。从期望最大化算法的计算中得出了信念状态或滤波性递推来跟踪隐藏的状态。同时，还开发了动态规划类比的Viterbi算法，以估计给定观测序列的最可能的隐藏状态序列。

    Herein, the Hidden Markov Model is expanded to allow for Markov chain observations. In particular, the observations are assumed to be a Markov chain whose one step transition probabilities depend upon the hidden Markov chain. An Expectation-Maximization analog to the Baum-Welch algorithm is developed for this more general model to estimate the transition probabilities for both the hidden state and for the observations as well as to estimate the probabilities for the initial joint hidden-state-observation distribution. A believe state or filter recursion to track the hidden state then arises from the calculations of this Expectation-Maximization algorithm. A dynamic programming analog to the Viterbi algorithm is also developed to estimate the most likely sequence of hidden states given the sequence of observations.
    
[^35]: 学习证明机制目前存在许多问题

    Proof-of-Learning is Currently More Broken Than You Think. (arXiv:2208.03567v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.03567](http://arxiv.org/abs/2208.03567)

    学习证明机制PoL存在不少问题，由于现有的欺骗策略很容易被打败或无法重现，因此对对手的安全保障不稳健。新的欺骗策略引入可以打破PoL的最新防御方法，但成本较低。

    

    学习证明（PoL）提出，模型所有者记录训练检查点，以建立为训练耗费的计算提供证明。 PoL的作者放弃了加密方法，以换取深度学习的可扩展性，从而换取了严格的安全保证。他们通过展示盗用模型的计算证明--计算偷来的模型的证明，和真正地训练模型所需要的证明一样昂贵来实证证明了这种方法的优点。但是，最近的研究提供了一个反例，从而使这个观察失效。在这项工作中，我们首先证明，尽管当前PoL验证对于对手来说不稳健是真实的，但是最近的工作大大低估了这种缺乏稳健性。这是因为现有的欺骗策略要么不可重现，要么针对PoL的削弱形式--这意味着它们很容易被更改验证的超参数来挫败。相反，我们引入了第一批欺骗策略，它们可以打破适用于PoL的最新防御方法，但代价很低。

    Proof-of-Learning (PoL) proposes that a model owner logs training checkpoints to establish a proof of having expended the computation necessary for training. The authors of PoL forego cryptographic approaches and trade rigorous security guarantees for scalability to deep learning. They empirically argued the benefit of this approach by showing how spoofing--computing a proof for a stolen model--is as expensive as obtaining the proof honestly by training the model. However, recent work has provided a counter-example and thus has invalidated this observation.  In this work we demonstrate, first, that while it is true that current PoL verification is not robust to adversaries, recent work has largely underestimated this lack of robustness. This is because existing spoofing strategies are either unreproducible or target weakened instantiations of PoL--meaning they are easily thwarted by changing hyperparameters of the verification. Instead, we introduce the first spoofing strategies that c
    
[^36]: 基于内核的赌博机协同学习

    Collaborative Learning in Kernel-based Bandits for Distributed Users. (arXiv:2207.07948v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.07948](http://arxiv.org/abs/2207.07948)

    本文研究了分布式用户之间的基于内核的赌博机协同学习，并提出了一种使用代理高斯进程模型的算法，以降低通信开销，获得次优遗憾性能。

    

    本文研究了通过中央服务器协调分布式客户端之间的协同学习。每个客户端都希望最大化其个性化目标函数，该函数是其本地目标函数和全局目标函数的加权和。每个客户端直接访问其本地目标函数的随机赌博反馈，但只有对全局目标函数的部分视图，并对其他客户端进行信息交流以进行协同学习。我们采用基于内核的赌博机框架，其中目标函数属于再生核希尔伯特空间。我们提出了一种基于代理高斯进程（GP）模型的算法，并确定了其（多项式对数因子内）的次优遗憾性能。我们还表明，可以采用GP模型的稀疏逼近来减少客户端之间的通信开销。

    We study collaborative learning among distributed clients facilitated by a central server. Each client is interested in maximizing a personalized objective function that is a weighted sum of its local objective and a global objective. Each client has direct access to random bandit feedback on its local objective, but only has a partial view of the global objective and relies on information exchange with other clients for collaborative learning. We adopt the kernel-based bandit framework where the objective functions belong to a reproducing kernel Hilbert space. We propose an algorithm based on surrogate Gaussian process (GP) models and establish its order-optimal regret performance (up to polylogarithmic factors). We also show that the sparse approximations of the GP models can be employed to reduce the communication overhead across clients.
    
[^37]: 面对混淆因素的悲观情绪：部分可观察马尔可夫决策过程的证明有效离线强化学习

    Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes. (arXiv:2205.13589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13589](http://arxiv.org/abs/2205.13589)

    本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。

    

    本文研究了部分可观测马尔可夫决策过程中的离线强化学习。特别地，我们旨在从由行为策略收集的数据集中学习最优策略，该策略可能取决于潜在状态。这样的数据集在混淆意义上同时影响行动和观测值，这对于现有的离线强化学习算法来说是禁止的。为此，我们提出了通过近端因果推断构建的悲观置信区间耦合序列的代理变量悲观策略优化（P3O）算法，该算法在广义函数逼近的上下文中解决了混淆偏差和最优策略与行为策略之间的分布偏移问题。我们证明，在混淆数据集的部分覆盖假设下，P3O可以实现n^{-1/2}的收敛率。

    We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \underline{P}roxy variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization (\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \texttt{P3O} achieves a $n^{-1/2}$-
    
[^38]: 无效工具变量下的因果推断: 探索基于机器学习的非线性治疗模型

    Causal Inference with Invalid Instruments: Exploring Nonlinear Treatment Models with Machine Learning. (arXiv:2203.12808v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2203.12808](http://arxiv.org/abs/2203.12808)

    提出一种名为TSCI的新方法，使用机器学习探索非线性治疗模型，并调整不同形式的其他工具变量假设违背，用于无效工具变量下的因果推断问题。

    

    我们讨论了在可能存在无效工具变量的观测研究中的因果推断问题。我们提出了一种名为“两阶段曲率识别”(TSCI)的新方法，它使用机器学习探索非线性治疗模型，并调整不同形式的其他工具变量假设违背。TSCI的成功需要工具变量对治疗的影响与其违背形式不同。我们实现了一步新颖的偏差校正来消除可能高复杂度机器学习所造成的偏差。我们提出的TSCI估计器即使机器学习算法不能一致地估计治疗模型，也被证明是渐进无偏和正态的。我们设计了一个数据依赖方法来选择几个候选违背形式中的最佳形式。我们应用TSCI研究了教育对收入的影响。

    We discuss causal inference for observational studies with possibly invalid instrumental variables. We propose a novel methodology called two-stage curvature identification (TSCI), which explores the nonlinear treatment model with machine learning and adjusts for different forms of violating the instrumental variable assumptions. The success of TSCI requires the instrumental variable's effect on treatment to differ from its violation form. A novel bias correction step is implemented to remove bias resulting from potentially high complexity of machine learning. Our proposed TSCI estimator is shown to be asymptotically unbiased and normal even if the machine learning algorithm does not consistently estimate the treatment model. We design a data-dependent method to choose the best among several candidate violation forms. We apply TSCI to study the effect of education on earnings.
    
[^39]: 基于星形细胞对关键期的神经可塑性神经网络，通过现有和记忆性的大脑可塑性和突触形成实现突触竞争和强度平衡。（arXiv: 2203.11740v12 [cs.NE] UPDATED）

    Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2203.11740](http://arxiv.org/abs/2203.11740)

    该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。

    

    除了突触共享连接权重之外，PNN还包括突触有效范围的权重[14-25]。PNN考虑突触强度平衡在突触吞噬的动态和长度常数之和的静态中[14]，并包含了鱼群行为的先导行为。突触形成在实验和模拟中会抑制树突生成[15]。类似于Spring Boot中的强制韧性，反向回路的记忆持久度梯度也存在。相对较好和较差的梯度信息存储在类似于脑褶的记忆痕迹细胞中，在反向回路的突触形成中。争议认为人类海马神经元的再生能力是否持续到老年，并可能在后期迭代中形成新的更长的回路[17,18]。关闭关键期会导致神经紊乱在实验和模拟中[19]。考虑到负面和正面记忆的持久性，有助于更好地激活突触。

    In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
    
[^40]: 降维与Wasserstein稳定性在核回归中的应用

    Dimensionality Reduction and Wasserstein Stability for Kernel Regression. (arXiv:2203.09347v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.09347](http://arxiv.org/abs/2203.09347)

    本文研究了在高维回归框架中的降维与Wasserstein稳定性应用，针对在扰动输入数据用于拟合回归函数时出现的误差推导了稳定性结果，并利用主成分分析和核回归文献中的估计，推导了两步法的收敛速度。

    

    在高维回归框架中，我们研究了一个朴素的两步法，首先降低输入变量的维数，再使用核回归来预测输出变量。为了分析由此产生的回归误差，我们推导了一个针对Wasserstein距离的新的核回归稳定性结果。这使我们能够限制当扰动输入数据用于拟合回归函数时出现的误差。我们将通用的稳定性结果应用于主成分分析(PCA)，利用已知的主成分分析和核回归文献中的估计，推导出了两步法的收敛速度。后者在半监督设置中特别有用。

    In a high-dimensional regression framework, we study consequences of the naive two-step procedure where first the dimension of the input variables is reduced and second, the reduced input variables are used to predict the output variable with kernel regression. In order to analyze the resulting regression errors, a novel stability result for kernel regression with respect to the Wasserstein distance is derived. This allows us to bound errors that occur when perturbed input data is used to fit the regression function. We apply the general stability result to principal component analysis (PCA). Exploiting known estimates from the literature on both principal component analysis and kernel regression, we deduce convergence rates for the two-step procedure. The latter turns out to be particularly useful in a semi-supervised setting.
    
[^41]: 序列实验的反事实推断

    Counterfactual inference for sequential experiments. (arXiv:2202.06891v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.06891](http://arxiv.org/abs/2202.06891)

    本文针对序列实验的反事实推断问题，提出了一个潜在因子模型，使用非参数方法对反事实均值进行估计，并建立了误差界限。

    

    我们考虑针对连续设计实验进行的事后统计推断，在此实验中，多个单位在多个时间点上分配治疗，并使用随时间而适应的治疗策略。我们的目标是在对适应性治疗策略做出最少的假设的情况下，为最小可能规模的反事实均值提供推断保证，即在每个单位和每个时间下，针对不同治疗的平均结果。在没有对反事实均值进行任何结构性假设的情况下，这项具有挑战性的任务是不可行的，因为未知变量比观察到的数据点还多。为了取得进展，我们引入了一个潜在因子模型用于反事实均值上，该模型作为非参数形式的非线性混合效应模型和以前工作中考虑的双线性潜在因子模型的推广。我们使用非参数方法进行估计，即最近邻的变体，并为每个单位和每个时间的反事实均值建立了非渐进高概率误差界限。

    We consider after-study statistical inference for sequentially designed experiments wherein multiple units are assigned treatments for multiple time points using treatment policies that adapt over time. Our goal is to provide inference guarantees for the counterfactual mean at the smallest possible scale -- mean outcome under different treatments for each unit and each time -- with minimal assumptions on the adaptive treatment policy. Without any structural assumptions on the counterfactual means, this challenging task is infeasible due to more unknowns than observed data points. To make progress, we introduce a latent factor model over the counterfactual means that serves as a non-parametric generalization of the non-linear mixed effects model and the bilinear latent factor model considered in prior works. For estimation, we use a non-parametric method, namely a variant of nearest neighbors, and establish a non-asymptotic high probability error bound for the counterfactual mean for ea
    
[^42]: 善意过拟合的隐性偏差

    The Implicit Bias of Benign Overfitting. (arXiv:2201.11489v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.11489](http://arxiv.org/abs/2201.11489)

    本文针对善意过拟合现象，提供了非线性回归的最小范数插值预测器在一般情况下偏向于不一致解的证明，从而说明善意过拟合不会发生，同时展示了如何将其扩展到标准线性回归以外。

    

    过拟合现象中的善意过拟合，指的是分类器完美地拟合了带有噪声的训练数据，同时达到接近最优的期望损失。近年来，这一现象受到了广泛关注，但除了线性回归设置外，仍然没有得到充分理解。在本文中，我们针对回归和分类任务，提供了关于何时可以或不能期望善意过拟合发生的若干新结果。我们考虑了一个典型且相当通用的线性分类器善意过拟合数据模型，其中将某个固定维度 $k$ 的任意输入分布与高维分布连接在一起。对于非必须经过良好规定的线性回归，我们证明最小范数插值预测器（标准训练方法所收敛到的）在一般情况下是偏向于不一致的解的，因此通常不会发生善意过拟合。此外，我们展示了如何通过一种方法将其扩展到标准线性回归以外。

    The phenomenon of benign overfitting, where a predictor perfectly fits noisy training data while attaining near-optimal expected loss, has received much attention in recent years, but still remains not fully understood beyond well-specified linear regression setups. In this paper, we provide several new results on when one can or cannot expect benign overfitting to occur, for both regression and classification tasks. We consider a prototypical and rather generic data model for benign overfitting of linear predictors, where an arbitrary input distribution of some fixed dimension $k$ is concatenated with a high-dimensional distribution. For linear regression which is not necessarily well-specified, we show that the minimum-norm interpolating predictor (that standard training methods converge to) is biased towards an inconsistent solution in general, hence benign overfitting will generally not occur. Moreover, we show how this can be extended beyond standard linear regression, by an argum
    
[^43]: ML4C: 通过潜在邻域观察因果关系

    ML4C: Seeing Causality Through Latent Vicinity. (arXiv:2110.00637v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.00637](http://arxiv.org/abs/2110.00637)

    本文提出了一种监督式因果学习方法ML4C，采用了新颖的学习目标，用于分类未屏蔽三元组是否是v-结构，并构建因果关系。

    

    监督式因果学习（SCL）旨在通过访问与地面真实因果关系相关的先前看到的数据集，从观察数据中学习因果关系。本文提出了首次尝试解决一个基本问题：监督的好处是什么，以及如何受益？我们提出了一个面向因果学习的双阶段范例，通过显式考虑结构可识别性来解决SCL问题。按照这个范例，我们针对离散数据的SCL问题提出了ML4C。ML4C的核心是一个二元分类器，其新颖的学习目标是分类未屏蔽三元组（UT）是否是v-结构。具体而言，从提供了相应骨架的输入数据集开始，ML4C在将UT分类为v-结构后对其进行取向。这些v-结构一起用于构建最终输出。为解决基本问题，我们提出了一种学习目标，称为潜在邻域识别，通过对UT进行分类，最终获得因果关系。

    Supervised Causal Learning (SCL) aims to learn causal relations from observational data by accessing previously seen datasets associated with ground truth causal relations. This paper presents a first attempt at addressing a fundamental question: What are the benefits from supervision and how does it benefit? Starting from seeing that SCL is not better than random guessing if the learning target is non-identifiable a priori, we propose a two-phase paradigm for SCL by explicitly considering structure identifiability. Following this paradigm, we tackle the problem of SCL on discrete data and propose ML4C. The core of ML4C is a binary classifier with a novel learning target: it classifies whether an Unshielded Triple (UT) is a v-structure or not. Specifically, starting from an input dataset with the corresponding skeleton provided, ML4C orients each UT once it is classified as a v-structure. These v-structures are together used to construct the final output. To address the fundamental que
    
[^44]: 两阶段电力发电计划的净需求预测问题

    Prescribing net demand for two-stage electricity generation scheduling. (arXiv:2108.01003v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2108.01003](http://arxiv.org/abs/2108.01003)

    本文介绍了一个两阶段发电计划问题中的净需求预测决策规则，并考虑了系统的成本结构和不确定性，经过数值测试证明了方法的有效性。

    

    本论文考虑了由前向派遣和实时重新调度组成的两阶段发电计划问题。前者必须面对包括不可调度电力消费和可再生能源发电在内的不确定净需求。后者通过在系统实际运行期间利用平衡电力应对相对于前向计划的合理偏差。标准工业实践通过用其条件期望的良好估计值（通常称为点预测）替换不确定的净需求来处理前向阶段的不确定净需求，以最小化实时平衡电力的需求。然而，众所周知，电力系统的成本结构高度不对称并且依赖于其运行点，因此最小化电力不平衡量并不一定与最小化操作成本一致。在本论文中，我们提出了一个双层方案来构建一个决策规则，根据系统的不确定性和不对称成本结构，在前向派遣阶段预测净需求。我们通过数值测试证明了我们方法的有效性。

    We consider a two-stage generation scheduling problem comprising a forward dispatch and a real-time re-dispatch. The former must be conducted facing an uncertain net demand that includes non-dispatchable electricity consumption and renewable power generation. The latter copes with the plausible deviations with respect to the forward schedule by making use of balancing power during the actual operation of the system. Standard industry practice deals with the uncertain net demand in the forward stage by replacing it with a good estimate of its conditional expectation (usually referred to as a point forecast), so as to minimize the need for balancing power in real time. However, it is well known that the cost structure of a power system is highly asymmetric and dependent on its operating point, with the result that minimizing the amount of power imbalances is not necessarily aligned with minimizing operating costs. In this paper, we propose a bilevel program to construct, from the availab
    
[^45]: 带层次混合模型的实值时间序列上下文树加权的贝叶斯推断

    Context-tree weighting for real-valued time series: Bayesian inference with hierarchical mixture models. (arXiv:2106.03023v4 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2106.03023](http://arxiv.org/abs/2106.03023)

    本文提出了一个通用的贝叶斯建模框架，用于构建实值时间序列的混合模型。基于上下文树的使用并包含了一组有效算法工具，可以与任何现有模型类一起使用，构建灵活且可解释的混合模型。

    

    实值时间序列在科学和工程中非常普遍。本文开发了一个通用的、层次贝叶斯建模框架，用于构建时间序列的混合模型。该框架基于上下文树的使用，并包括一组有效的学习和推断算法工具。为每个样本提取一个离散上下文（或“状态”），其中包括其之前的一些最新观测的离散化版本。所有相关上下文的集合表示为离散上下文树。在最底层，将不同的实值时间序列模型与每个上下文状态（即树的每个叶子）相关联。这定义了一个非常通用的框架，可与任何现有模型类一起使用，以构建灵活且可解释的混合模型。扩展上下文树加权的想法会导致一些算法，允许在此设置中进行高效、确切的贝叶斯推断。

    Real-valued time series are ubiquitous in the sciences and engineering. In this work, a general, hierarchical Bayesian modelling framework is developed for building mixture models for times series. This development is based, in part, on the use of context trees, and it includes a collection of effective algorithmic tools for learning and inference. A discrete context (or 'state') is extracted for each sample, consisting of a discretised version of some of the most recent observations preceding it. The set of all relevant contexts are represented as a discrete context-tree. At the bottom level, a different real-valued time series model is associated with each context-state, i.e., with each leaf of the tree. This defines a very general framework that can be used in conjunction with any existing model class to build flexible and interpretable mixture models. Extending the idea of context-tree weighting leads to algorithms that allow for efficient, exact Bayesian inference in this setting.
    
[^46]: 基于平衡熵学习准则的贝叶斯神经网络主动学习

    Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle. (arXiv:2105.14559v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.14559](http://arxiv.org/abs/2105.14559)

    该论文提出了一种新的不确定性测量方法Balanced Entropy Acquisition（BalEntAcq），通过捕捉潜在softmax概率和标签变量的信息平衡，实现了基于平衡熵学习准则的贝叶斯神经网络主动学习，并在多个基准数据集上证明了该方法的有效性和较高的计算效率。

    

    在许多具有有限预算的机器学习应用中，获取标记数据是具有挑战性的。主动学习提供了一种选择最具信息量的数据点并通过减少标记成本来提高数据效率的过程。信息最大化学习原则（例如 BALD）最大化相互信息已经在各种主动学习应用中成功地广泛采用。然而，这种特定于池的目标本质上引入了冗余选择，并进一步需要高计算成本进行批处理选择。在本文中，我们设计并提出了一种新的不确定性测量方法Balanced Entropy Acquisition（BalEntAcq），它捕捉了潜在softmax概率和标签变量的不确定性之间的信息平衡。为此，我们通过Beta分布逼近每个边缘分布。Beta逼近使我们能够将BalEntAcq制定为增强熵和边缘联合熵之间的比率。所得到的BalEntAcq的闭式表达式可以高效地计算并与其他最先进的主动学习方法进行比较。我们在包括图像分类，目标检测和语义分割任务在内的几个基准数据集上展示了我们方法的有效性。我们提出的方法在显著降低计算成本的同时，达到了与现有方法相当的性能。

    Acquiring labeled data is challenging in many machine learning applications with limited budgets. Active learning gives a procedure to select the most informative data points and improve data efficiency by reducing the cost of labeling. The info-max learning principle maximizing mutual information such as BALD has been successful and widely adapted in various active learning applications. However, this pool-based specific objective inherently introduces a redundant selection and further requires a high computational cost for batch selection. In this paper, we design and propose a new uncertainty measure, Balanced Entropy Acquisition (BalEntAcq), which captures the information balance between the uncertainty of underlying softmax probability and the label variable. To do this, we approximate each marginal distribution by Beta distribution. Beta approximation enables us to formulate BalEntAcq as a ratio between an augmented entropy and the marginalized joint entropy. The closed-form expr
    
[^47]: CogDL：图深度学习的综合库

    CogDL: A Comprehensive Library for Graph Deep Learning. (arXiv:2103.00959v4 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2103.00959](http://arxiv.org/abs/2103.00959)

    CogDL是一个图深度学习的综合库，针对图数据的稀疏性和复杂任务提供了统一的训练和评估设计和多种训练技术，包括高效和可扩展的实现和实用工具，是进行图深度学习的理想选择。

    

    近年来，图神经网络(GNNs)在图学习社区中引起了极大的关注，并在各个领域的实际应用中被广泛采用，比如社交网络和生物图。然而，图深度学习的研究和应用存在一些新的挑战，包括图数据稀疏性、GNN复杂的训练和图任务的非标准评估。为了解决这些问题，我们提出了CogDL，一个图深度学习的综合库，允许研究人员和实践者轻松高效地进行实验、比较方法和构建应用。在CogDL中，我们提出了对于各种图任务的GNN模型训练和评估的统一设计，使其在现有的图学习库中独树一帜。通过使用这个统一的训练器，CogDL可以优化GNN训练循环，采用混合精度训练等多种训练技术。此外，我们针对各种GNN模型开发了高效且可扩展的实现，包括经典模型和最新的模型。此外，CogDL提供了一系列的实用工具和工具，支持图深度学习的开发，如数据加载器和评估指标。我们还通过在流行图数据集上的广泛实验证明了CogDL的有效性，并为各种图任务提供了全面的基准。

    Graph neural networks (GNNs) have attracted tremendous attention from the graph learning community in recent years. It has been widely adopted in various real-world applications from diverse domains, such as social networks and biological graphs. The research and applications of graph deep learning present new challenges, including the sparse nature of graph data, complicated training of GNNs, and non-standard evaluation of graph tasks. To tackle the issues, we present CogDL, a comprehensive library for graph deep learning that allows researchers and practitioners to conduct experiments, compare methods, and build applications with ease and efficiency. In CogDL, we propose a unified design for the training and evaluation of GNN models for various graph tasks, making it unique among existing graph learning libraries. By utilizing this unified trainer, CogDL can optimize the GNN training loop with several training techniques, such as mixed precision training. Moreover, we develop efficie
    
[^48]: 灵活的模型聚合方法用于分位数回归

    Flexible Model Aggregation for Quantile Regression. (arXiv:2103.00083v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2103.00083](http://arxiv.org/abs/2103.00083)

    本文研究聚合条件分位数模型的方法，提高分位数回归的准确性和鲁棒性，并提出了能够应用于现代深度学习工具包的多种模型，对许多从业者具有广泛的适用性。

    

    分位数回归是一种用于统计学习的基本问题，旨在量化预测的不确定性，或在不过度简化的情况下对多样化人群建模。本文研究聚合任意数量的条件分位数模型的方法，以提高准确性和鲁棒性，并考虑权重集成，权重不仅可以变化于单个模型，还可以变化于分位数水平和特征值。本文所考虑的所有模型均可使用现代深度学习工具包拟合，因此对许多从业者具有广泛的适用性（从实现的角度来看）。

    Quantile regression is a fundamental problem in statistical learning motivated by a need to quantify uncertainty in predictions, or to model a diverse population without being overly reductive. For instance, epidemiological forecasts, cost estimates, and revenue predictions all benefit from being able to quantify the range of possible values accurately. As such, many models have been developed for this problem over many years of research in statistics, machine learning, and related fields. Rather than proposing yet another (new) algorithm for quantile regression we adopt a meta viewpoint: we investigate methods for aggregating any number of conditional quantile models, in order to improve accuracy and robustness. We consider weighted ensembles where weights may vary over not only individual models, but also over quantile levels, and feature values. All of the models we consider in this paper can be fit using modern deep learning toolkits, and hence are widely accessible (from an implem
    
[^49]: 利用先验知识的 Gamma-Minimax 估计器的对抗元学习

    Adversarial Meta-Learning of Gamma-Minimax Estimators That Leverage Prior Knowledge. (arXiv:2012.05465v4 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2012.05465](http://arxiv.org/abs/2012.05465)

    本文提出对抗元学习方法，用于计算在一组与可用知识相容的先验分布中最小化最坏情况的 Bayes 风险的 Gamma-Minimax 估计器，文中还提出了一种神经网络类用于提供估计器类，以及两个实验环节用于说明该方法的应用。

    

    贝叶斯估计提供了一种将能够以单个先验分布的形式表达的先验知识结合起来的方式。然而，当这种知识太模糊，无法用单个先验表示时，就需要另一种方法。Gamma-minimax 估计器提供了这样一种方法。这些估计器将在与可用知识相容的一组先验分布 $\Gamma$ 上最小化最坏情况的 Bayes 风险。传统上，Gamma-minimax 性质是为参数模型定义的。在本文中，我们为一般模型定义 Gamma-minimax 估计器，并提出了利用一般化矩限制的对抗元学习算法来计算它们。我们还提出了一种神经网络类，它提供了一种丰富但有限维度的估计器类，可以从中选择 Gamma-minimax 估计器。我们在两个环节中说明了我们的方法，即估计未知支持分布的样本熵和后分层估计。

    Bayes estimators are well known to provide a means to incorporate prior knowledge that can be expressed in terms of a single prior distribution. However, when this knowledge is too vague to express with a single prior, an alternative approach is needed. Gamma-minimax estimators provide such an approach. These estimators minimize the worst-case Bayes risk over a set $\Gamma$ of prior distributions that are compatible with the available knowledge. Traditionally, Gamma-minimaxity is defined for parametric models. In this work, we define Gamma-minimax estimators for general models and propose adversarial meta-learning algorithms to compute them when the set of prior distributions is constrained by generalized moments. Accompanying convergence guarantees are also provided. We also introduce a neural network class that provides a rich, but finite-dimensional, class of estimators from which a Gamma-minimax estimator can be selected. We illustrate our method in two settings, namely entropy est
    
[^50]: 高斯混合模型中的局部极小结构

    Local Minima Structures in Gaussian Mixture Models. (arXiv:2009.13040v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2009.13040](http://arxiv.org/abs/2009.13040)

    研究了高斯混合模型中的负对数似然函数的局部极小值结构，发现它们都共享一种常见结构而部分确定了真正的位置混合物的簇中心。这些结果适用于真实混合组分满足某种分离条件的情况，也适用于成分数量过多或过少的情况。

    

    我们在人口极限的情况下调查了混合成分模型（GMM）的负对数似然函数的情况，并探讨了具有一般成分数量的GMM的负对数似然函数的局部极小值结构。由于目标函数是非凸的，即使对于分离良好的混合模型，也可能存在不是全局最优的多个局部极小值。我们的研究揭示了所有局部极小值都共享一种常见结构，该结构部分确定了真正的位置混合物（即高斯成分的均值）的簇中心。具体而言，每个局部极小值可以表示为两种类型子配置的非重叠组合：将单个均值估计与多个高斯分量拟合或将多个估计拟合到单个真实分量。这些结果适用于真实混合组分满足某种分离条件的情况，并且在成分数量过多或过少的情况下也是有效的。我们还针对一维高斯混合物的设置提供了更精细的分析，通过结构计数论证导出了这些非全局最小值的精确数量和它们对应的配置。

    We investigate the landscape of the negative log-likelihood function of Gaussian Mixture Models (GMMs) with a general number of components in the population limit. As the objective function is non-convex, there can be multiple local minima that are not globally optimal, even for well-separated mixture models. Our study reveals that all local minima share a common structure that partially identifies the cluster centers (i.e., means of the Gaussian components) of the true location mixture. Specifically, each local minimum can be represented as a non-overlapping combination of two types of sub-configurations: fitting a single mean estimate to multiple Gaussian components or fitting multiple estimates to a single true component. These results apply to settings where the true mixture components satisfy a certain separation condition, and are valid even when the number of components is overor under-specified. We also present a more fine-grained analysis for the setting of one-dimensional G
    
[^51]: 非参数IV模型中的自适应高效假设检验

    Adaptive, Rate-Optimal Hypothesis Testing in Nonparametric IV Models. (arXiv:2006.09587v3 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2006.09587](http://arxiv.org/abs/2006.09587)

    我们提出了一种自适应检验方法，用于处理非参数仪器变量模型中的结构函数的不等式和等式限制。该方法可以适应未知的平滑度和工具强度，并达到了最小值率的自适应最优检验率。

    

    我们提出了一种新的自适应假设检验方法，用于非参数仪器变量（NPIV）模型中结构函数的不等式（如单调性、凸性）和等式（如参数、半参数）限制。我们的检验统计量基于修改版的留一法样本模拟，计算受限和不受限筛子NPIV估计量间的二次距离。我们提供了计算简单、数据驱动的筛子调参和Bonferroni调整卡方临界值的选择。我们的检验适应未知的内生性平滑度和工具强度，达到了$L^2$最小值率的自适应最优检验率。也就是说，在复合零假设下其类型I误差的总体和其类型II误差的总体均不能被任何其他NPIV模型的假设检验所提高。我们还提出了基于数据的置信区间。

    We propose a new adaptive hypothesis test for inequality (e.g., monotonicity, convexity) and equality (e.g., parametric, semiparametric) restrictions on a structural function in a nonparametric instrumental variables (NPIV) model. Our test statistic is based on a modified leave-one-out sample analog of a quadratic distance between the restricted and unrestricted sieve NPIV estimators. We provide computationally simple, data-driven choices of sieve tuning parameters and Bonferroni adjusted chi-squared critical values. Our test adapts to the unknown smoothness of alternative functions in the presence of unknown degree of endogeneity and unknown strength of the instruments. It attains the adaptive minimax rate of testing in $L^2$.  That is, the sum of its type I error uniformly over the composite null and its type II error uniformly over nonparametric alternative models cannot be improved by any other hypothesis test for NPIV models of unknown regularities. Data-driven confidence sets in 
    
[^52]: 用生成模型突破模型驱动强化学习中的样本大小障碍

    Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.12900](http://arxiv.org/abs/2005.12900)

    本文提出了两个算法——扰动模型驱动算法和保守模型驱动算法，通过生成模型在较小的样本大小下证明了它们的极小化最大算法优化性能。

    

    本论文着眼于在有生成模型（或模拟器）的情况下，增强学习的样本效率。首先，考虑带有折扣的无限时间步长马尔科夫决策过程（MDP），其状态空间为$\mathcal{S}$，动作空间为$\mathcal{A}$。尽管有许多先前的研究在解决这个问题，但是在样本复杂度和统计精度之间权衡的完整图景尚未确定。特别是，所有的先前结果都受到严重的样本大小障碍，因为它们声称的统计保证仅在样本大小超过至少$\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$时才成立。本文通过证明两个算法——扰动模型驱动算法和保守模型驱动算法——在样本大小超过$\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$的情况下就能证明它们的极小化最大算法优化性能（几乎符合一些对数因子）。除了无限时间步长M解决方案之外，我们还考虑了有限样本和近似价值迭代问题，以在实践中实现算法的应用。

    This paper is concerned with the sample efficiency of reinforcement learning, assuming access to a generative model (or simulator). We first consider $\gamma$-discounted infinite-horizon Markov decision processes (MDPs) with state space $\mathcal{S}$ and action space $\mathcal{A}$. Despite a number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy is yet to be determined. In particular, all prior results suffer from a severe sample size barrier, in the sense that their claimed statistical guarantees hold only when the sample size exceeds at least $\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$. The current paper overcomes this barrier by certifying the minimax optimality of two algorithms -- a perturbed model-based algorithm and a conservative model-based algorithm -- as soon as the sample size exceeds the order of $\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$ (modulo some log factor). Moving beyond infinite-
    
[^53]: 通过语言基础实现零样本组合策略学习

    Zero-Shot Compositional Policy Learning via Language Grounding. (arXiv:2004.07200v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2004.07200](http://arxiv.org/abs/2004.07200)

    本论文提出了一种通过语言基础实现零样本组合策略学习的算法，该算法将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上，实验证明该算法在零样本组合策略学习任务中表现优于现有的RL/IL算法。

    

    尽管强化学习（RL）和模仿学习（IL）在最近都有了突破，但现有算法无法在训练环境之外进行推广。实际上，人类能够通过利用先前关于世界（如语言描述）的知识来快速适应新任务。为了促进带有领域自适应的语言引导代理的研究，我们提出了一项新的零样本组合策略学习任务，其中环境被描述为不同属性的组合。由于没有公共环境支持这项研究，我们介绍了一个新的研究平台BabyAI++，其中环境的动力学与视觉外观解耦。在每个回合中，BabyAI++提供了各种视觉动力学组合以及相应的描述性文本。为了评估所学代理的自适应能力，一组视觉动力学配对被保留在BabyAI++上进行测试。不出所料，我们发现当前的语言引导RL/IL方法无法解决这个零样本组合策略学习任务。因此，我们提出了一种新的语言引导策略学习算法，通过将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上。为了实现这一目标，我们引入了一种新的语言基础模块，将符号属性表示和自然语言输入集成到策略网络中。我们的实验表明，我们提出的算法在零样本组合策略学习任务上显著优于现有的RL/IL算法。

    Despite recent breakthroughs in reinforcement learning (RL) and imitation learning (IL), existing algorithms fail to generalize beyond the training environments. In reality, humans can adapt to new tasks quickly by leveraging prior knowledge about the world such as language descriptions. To facilitate the research on language-guided agents with domain adaption, we propose a novel zero-shot compositional policy learning task, where the environments are characterized as a composition of different attributes. Since there are no public environments supporting this study, we introduce a new research platform BabyAI++ in which the dynamics of environments are disentangled from visual appearance. At each episode, BabyAI++ provides varied vision-dynamics combinations along with corresponding descriptive texts. To evaluate the adaption capability of learned agents, a set of vision-dynamics pairings are held-out for testing on BabyAI++. Unsurprisingly, we find that current language-guided RL/IL 
    
[^54]: 利用未标记数据扩展类别的开放集学习（Open-LACU）

    Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2002.01368](http://arxiv.org/abs/2002.01368)

    Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。

    

    对于半监督学习（SSL）和开放式识别（OSR），已经进行了许多尝试以合成单个训练策略。然而，每次尝试都违反了开放集定义，因为这些方法在未标记的训练集中包含新颖的类别。本研究提出了一种新的学习策略，其中分类器能够在观察到的和未观察到的新颖类别之间进行推广，从而定义了观察到新颖类别的背景类别和未观察到新颖类别的未知类别。通过分类这两种新颖类别的方式，Open-LACU能够提高训练的成本效益性，并确保在存在未观察到的新颖类别时进行安全分类。

    Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
    
[^55]: 使用非负核回归构建邻域和图

    Neighborhood and Graph Constructions using Non-Negative Kernel Regression. (arXiv:1910.09383v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1910.09383](http://arxiv.org/abs/1910.09383)

    本文提出了一种非负核回归的算法来构建更好的邻域和图，并且在各种应用中展示出其优越性和实用性。

    

    数据驱动的邻域定义和图构建在机器学习和信号处理应用中经常使用。k近邻（kNN）和 $\epsilon$-邻域方法是最常用的邻域选择方法之一，由于其计算简单性。然而，这些方法所涉及的参数选择，如 k 和 $\epsilon$，仍然是临时的。本文有两个主要贡献。首先，我们提出了一种邻域选择的替代方法，其中我们表明邻域构造等同于一个稀疏信号逼近问题。其次，我们提出了一种算法，非负核回归（NNK），用于获得更好的稀疏表示的邻域。NNK与信号表示的正交匹配追踪方法相似，并具有良好的几何和理论性质。实验证明了（i）NNK算法在邻域和图构建中的鲁棒性，（ii）NNK在各种应用中优于其他流行的邻域选择方法，以及（iii）NNK在其他机器学习和信号处理任务中的有用性。

    Data-driven neighborhood definitions and graph constructions are often used in machine learning and signal processing applications. k-nearest neighbor~(kNN) and $\epsilon$-neighborhood methods are among the most common methods used for neighborhood selection, due to their computational simplicity. However, the choice of parameters associated with these methods, such as k and $\epsilon$, is still ad hoc. We make two main contributions in this paper. First, we present an alternative view of neighborhood selection, where we show that neighborhood construction is equivalent to a sparse signal approximation problem. Second, we propose an algorithm, non-negative kernel regression~(NNK), for obtaining neighborhoods that lead to better sparse representation. NNK draws similarities to the orthogonal matching pursuit approach to signal representation and possesses desirable geometric and theoretical properties. Experiments demonstrate (i) the robustness of the NNK algorithm for neighborhood and 
    

