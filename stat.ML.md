# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Grid Monitoring and Protection with Continuous Point-on-Wave Measurements and Generative AI](https://arxiv.org/abs/2403.06942) | 提出了基于连续时序测量和生成人工智能的电网监测和控制系统，通过数据压缩和故障检测，实现了对传统监控系统的进步。 |
| [^2] | [Simplicity Bias of Transformers to Learn Low Sensitivity Functions](https://arxiv.org/abs/2403.06925) | Transformers在不同数据模态上具有低敏感性，这种简单性偏差有助于解释其在视觉和语言任务中的优越性能。 |
| [^3] | [Benign overfitting in leaky ReLU networks with moderate input dimension](https://arxiv.org/abs/2403.06903) | 研究了在泄漏ReLU网络上使用铰链损失进行训练的过程中，信噪比（SNR）条件对于良性和非良性过拟合的影响，并发现高SNR值会导致良性过拟合，低SNR值则会导致有害过拟合。 |
| [^4] | [On the Generalization Ability of Unsupervised Pretraining](https://arxiv.org/abs/2403.06871) | 无监督预训练如何影响模型泛化能力的关键因素的新理论框架 |
| [^5] | [In-context Exploration-Exploitation for Reinforcement Learning](https://arxiv.org/abs/2403.06826) | 引入了In-context Exploration-Exploitation (ICEE)算法，通过在Transformer模型内部进行探索-利用权衡，提高了在-context策略学习的效率。 |
| [^6] | [Efficient first-order algorithms for large-scale, non-smooth maximum entropy models with application to wildfire science](https://arxiv.org/abs/2403.06816) | 提出了一种新颖的优化算法，利用Kullback-Leibler散度训练大规模、非光滑的Maxent模型 |
| [^7] | [Monotone Individual Fairness](https://arxiv.org/abs/2403.06812) | 该论文提出了一个新的在线学习框架，通过单调聚合函数实现了一种个体公平性审计方案，可以有效降低多个审计员对个体公平性的分析复杂度。 |
| [^8] | [Multistep Consistency Models](https://arxiv.org/abs/2403.06807) | 本文提出了多步一致性模型，通过在一致性模型和扩散模型之间插值，实现了采样速度和采样质量的平衡。 |
| [^9] | [On the Approximation of Kernel functions](https://arxiv.org/abs/2403.06731) | 本文提出了一种新的方法，通过考虑径向核函数的泰勒级数逼近，建立了对核函数的较好近似，证实了可以使用比文献中更小的正则化参数来实现更好的结果。 |
| [^10] | [Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains](https://arxiv.org/abs/2403.06672) | 本文研究了在隐私敏感领域中如何设计一种FL协议，既能保证隐私，又能提高模型准确性，并提供了设计出对所有参与者都有益处的协议。 |
| [^11] | [Scalable Online Exploration via Coverability](https://arxiv.org/abs/2403.06571) | 提出了探索目标框架，引入了$L_1$-覆盖度作为新的探索目标，支持内在复杂度控制、高效规划和灵活集成的优点。 |
| [^12] | [Sliced-Wasserstein Distances and Flows on Cartan-Hadamard Manifolds](https://arxiv.org/abs/2403.06560) | 该论文在卡坦-哈达玛德流形上推导了切片-华塞斯坦距离的一般构造，提出了不同应用，并且推导了非参数方案以最小化这些新距离。 |
| [^13] | [Detection of Unobserved Common Causes based on NML Code in Discrete, Mixed, and Continuous Variables](https://arxiv.org/abs/2403.06499) | 提出一种新方法CLOUD，用于仅基于观测数据检测未观测到的共同原因，无需对未观测变量的方程模型形式做任何假设 |
| [^14] | [Bridging Domains with Approximately Shared Features](https://arxiv.org/abs/2403.06424) | 提出了一种统计框架，根据特征与标签的相关性方差来区分特征的效用，并设计了一种学习过程，从源任务学习到大致共享的特征表示，并在目标任务上进行微调，以优化总体风险。 |
| [^15] | [Disentangling shared and private latent factors in multimodal Variational Autoencoders](https://arxiv.org/abs/2403.06338) | 多模态变分自动编码器在解开共享和私有潜在因素方面的能力进行了研究，并提出了改进的方法以增强对特定模态变化的鲁棒性。 |
| [^16] | [How much data do you need? Part 2: Predicting DL class specific training dataset sizes](https://arxiv.org/abs/2403.06311) | 通过考虑每个类别的训练样本数量，而不仅仅是总体训练样本数量，来预测机器学习分类模型性能，并提出了一种基于空间填充设计的算法，可以对 CIFAR10 和 EMNIST 数据集进行应用。 |
| [^17] | [Nonparametric Automatic Differentiation Variational Inference with Spline Approximation](https://arxiv.org/abs/2403.06302) | 提出了一种基于样条的非参数逼近方法，实现了对复杂结构分布的灵活后验逼近，提高了生成模型性能。 |
| [^18] | [Probabilistic Neural Circuits](https://arxiv.org/abs/2403.06235) | PNCs将概率电路和神经网络的特点结合起来，可以解释为深层混合的贝叶斯网络，同时作为强大的函数逼近器。 |
| [^19] | [LinearAPT: An Adaptive Algorithm for the Fixed-Budget Thresholding Linear Bandit Problem](https://arxiv.org/abs/2403.06230) | LinearAPT算法是一种为固定预算设置的阈值线性赌博机问题而设计的新算法，具有适应性、简单性和计算效率，并在优化顺序决策方面表现出色。 |
| [^20] | [An Improved Analysis of Langevin Algorithms with Prior Diffusion for Non-Log-Concave Sampling](https://arxiv.org/abs/2403.06183) | 本文研究了先前扩散技术对满足对数Sobolev不等式的目标分布的作用，扩展了先前仅针对强对数凹分布的相关工作。 |
| [^21] | [The ALL0CORE Tensor Decomposition for Sparse Count Data](https://arxiv.org/abs/2403.06153) | ALL0CORE是一种新的概率非负张量分解方法，它在保持计算可处理性的基础上利用Tucker分解的潜在结构，可以仅使用核的微小部分即达到与完整Tucker分解相同效果。 |
| [^22] | [Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment](https://arxiv.org/abs/2403.06100) | 在众包环境中，我们提出了一种自动优化方法，利用在线学习对配对组合和评估量进行优化，实现基于喜好的主观评估的设计优化。 |
| [^23] | [Grafting: Making Random Forests Consistent](https://arxiv.org/abs/2403.06015) | 本文探讨了将一致化估计器移植到浅层决策树（CART）的适用性，并表明这种方法具有一致性保证并在实证环境中表现良好。 |
| [^24] | [Statistical Efficiency of Distributional Temporal Difference](https://arxiv.org/abs/2403.05811) | 该论文分析了分布式时间差分的统计效率和有限样本性能。 |
| [^25] | [Membership Testing in Markov Equivalence Classes via Independence Query Oracles](https://arxiv.org/abs/2403.05759) | 通过建立在给定的最大无向团大小($s$)方面的下界，我们探讨了通过独立查询预言者在马尔可夫等价类中进行成员测试这一问题。 |
| [^26] | [Spectral Clustering of Categorical and Mixed-type Data via Extra Graph Nodes](https://arxiv.org/abs/2403.05669) | 通过添加额外节点，本文提出了一种新的方法，将数值和分类信息同时纳入谱聚类算法，避免了数据预处理或复杂相似性函数的需求。 |
| [^27] | [Density-Regression: Efficient and Distance-Aware Deep Regressor for Uncertainty Estimation under Distribution Shifts](https://arxiv.org/abs/2403.05600) | 密度回归是一种利用密度函数进行不确定性估计并通过单次前向传递实现快速推断的方法，具有距离感知能力，能够在分布偏移下产生高质量不确定性估计。 |
| [^28] | [What makes an image realistic?](https://arxiv.org/abs/2403.04493) | 论文讨论了如何设计能够可靠区分真实数据和不真实数据的函数，提出了通用评论者的概念作为一个新的解决方案。 |
| [^29] | [Hypothesis Spaces for Deep Learning](https://arxiv.org/abs/2403.03353) | 本文介绍了一种应用深度神经网络的深度学习假设空间，并构建了一个再生核Banach空间，研究了正则化学习和最小插值问题，证明了学习模型的解可以表示为线性组合。 |
| [^30] | [Improving generalisation via anchor multivariate analysis](https://arxiv.org/abs/2403.01865) | 引入因果正则化扩展到锚回归（AR）中，提出了与锚框架相匹配的损失函数确保稳健性，各种多元分析算法均在锚框架内，简单正则化增强了OOD设置中的稳健性，验证了锚正则化的多功能性和对因果推断方法论的推进。 |
| [^31] | [Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive Ratio Analysis and Best-of-Both-Worlds](https://arxiv.org/abs/2403.00715) | 通过引入竞争分析框架，我们提出了调整FTRL学习率的更新规则，使其在常数因子内达到最佳竞争比，并且展示了当惩罚项具有近似单调性时的竞争比特性。 |
| [^32] | [Semi-Supervised U-statistics](https://arxiv.org/abs/2402.18921) | 介绍了一种半监督 U-统计量，利用大量未标记数据，获得了渐近正态分布的性质，并通过有效整合各种强大预测工具实现了明显的效率提升。 |
| [^33] | [MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization](https://arxiv.org/abs/2402.16898) | 引入了MIM-Reasoner，结合强化学习和概率图模型，有效地捕捉了给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。 |
| [^34] | [Spectral invariance and maximality properties of the frequency spectrum of quantum neural networks](https://arxiv.org/abs/2402.14515) | 量子神经网络研究了频谱的极大性质，证明了在一类模型中存在极大结果，以及在一些条件下存在保持频谱的光谱不变性，解释了文献中观察到的结果对称性。 |
| [^35] | [Sparse and Faithful Explanations Without Sparse Models](https://arxiv.org/abs/2402.09702) | 引入了稀疏解释值(SEV)，用于衡量机器学习模型的决策稀疏性。即使模型不是稀疏的，许多机器学习模型在SEV的衡量下仍具有低决策稀疏性。 |
| [^36] | [Fusing Individualized Treatment Rules Using Secondary Outcomes](https://arxiv.org/abs/2402.08828) | 该论文提出了一种新方法，通过融合次要结果来学习个体化治疗规则(ITR)，既最大化主要结果的价值函数，又尽可能接近次要结果的最优规则。 |
| [^37] | [Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models](https://arxiv.org/abs/2402.05210) | 这篇论文提出了一种采用分割引导扩散模型的解剖可控医学图像生成方法，通过随机掩模消融训练算法实现对解剖约束的条件化，同时提高了网络对解剖真实性的学习能力。 |
| [^38] | [Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces](https://arxiv.org/abs/2402.04613) | 本文研究了在再生核希尔伯特空间中使用Moreau包络来对测度f-差异进行正则化的方法，并利用该方法分析了Wasserstein梯度流。 |
| [^39] | [Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels](https://arxiv.org/abs/2402.03838) | 本研究提出了一种带有切片Wasserstein Weisfeiler-Lehman图核的高斯过程回归方法，在处理大规模稀疏图形数据集时具有正定性和显著的复杂度降低。 |
| [^40] | [Active learning with biased non-response to label requests](https://arxiv.org/abs/2312.08150) | 偏倧的非响应对主动学习模型性能有害，我们提出了一种成本-based 修正策略来减轻其影响，并通过实验证明其在许多情况下有效。 |
| [^41] | [Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data](https://arxiv.org/abs/2312.06091) | 在结构因果模型中，通过两阶段方法学习未知干预目标的外生噪声，并将其与相应的内生变量匹配，有效地识别干预目标。 |
| [^42] | [Opening the Black Box: Towards inherently interpretable energy data imputation models using building physics insight](https://arxiv.org/abs/2311.16632) | 提出了利用建筑物理学洞察实现固有可解释的能源数据插补模型PI-DAE，在损失函数中引入物理启发软约束，从而实现更可解释的预测。 |
| [^43] | [Nonparametric consistency for maximum likelihood estimation and clustering based on mixtures of elliptically-symmetric distributions](https://arxiv.org/abs/2311.06108) | 展示了椭圆对称分布混合的最大似然估计的一致性，为基于非参数分布的聚类提供了理论依据。 |
| [^44] | [Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes](https://arxiv.org/abs/2311.05866) | 提出了一种公平受监督学习的方法，利用简单随机采样器处理敏感属性，可以更广泛地适用于实践中，并构建了一个计算效率高的群体级别处理公平感知的训练框架。 |
| [^45] | [Weight-Sharing Regularization](https://arxiv.org/abs/2311.03096) | 提出了一种权重共享正则化方法，通过引入对神经网络权重的惩罚，设计并实现了一个新型并行算法，使网络能够学习卷积样式的滤波器 |
| [^46] | [Bayesian Federated Inference for estimating Statistical Models based on Non-shared Multicenter Data sets](https://arxiv.org/abs/2302.07677) | 本文提出了一种用于估计统计模型的替代性贝叶斯联合推断（BFI）框架，旨在处理数据集较小的情况，并能够获取更大数据集的统计能力。 |
| [^47] | [Is your model predicting the past?](https://arxiv.org/abs/2206.11673) | 提出了区分机器学习模型是预测个体未来还是重复过去模式的方法，通过向后基线测试展示模型是否回溯过去，并在长期面板调研任务中验证了该框架的有效性。 |
| [^48] | [Uncertainty-aware Pseudo-label Selection for Positive-Unlabeled Learning](https://arxiv.org/abs/2201.13192) | 通过不确定性感知的伪标签选择过程，本研究提出了一种解决正负样本学习中不平衡数据集和模型校准问题的方法，实验结果表明在高度不平衡的情况下能显著提高预测性能。 |
| [^49] | [Nested Nonparametric Instrumental Variable Regression: Long Term, Mediated, and Time Varying Treatment Effects](https://arxiv.org/abs/2112.14249) | 该论文提出了嵌套非参数工具变量回归的对抗估计器，并提供了对因果参数进行有效推断的充分条件，具有限制病态性复合技术、多种适应模型和扩展到因果函数等特征。 |
| [^50] | [Upper Counterfactual Confidence Bounds: a New Optimism Principle for Contextual Bandits](https://arxiv.org/abs/2007.07876) | 本文提出的“上限反事实置信区间”（UCCB）是针对一般上下文赌博设计乐观算法的新原则，通过在策略空间中构建置信区间，而非像UCB那样在行动空间中，这使得算法在处理一般函数类和大上下文空间时均具有优越性。 |
| [^51] | [Quantifying intrinsic causal contributions via structure preserving interventions](https://arxiv.org/abs/2007.00714) | 该论文提出一种通过结构保持干预来量化节点对目标节点的固有因果贡献的方法，从而将因果信息与祖先节点信息分离，并提出了对方差和熵的贡献分析。 |
| [^52] | [NeurAll: Towards a Unified Visual Perception Model for Automated Driving](https://arxiv.org/abs/1902.03589) | 本文提出了一种联合多任务网络设计，以实现在自动驾驶中的视觉感知任务中共享计算资源，从而提高计算效率并提供更好的泛化能力。 |
| [^53] | [A Discriminative Latent-Variable Model for Bilingual Lexicon Induction](https://arxiv.org/abs/1808.09334) | 引入判别式潜变量模型，结合先前研究的词典先验和表示法，提出了用于双语词典归纳的新方法，并通过实验证据展示先验可以改善诱导的双语词典。 |
| [^54] | [Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?.](http://arxiv.org/abs/2401.13045) | 该论文提出了通过神经信息学和机器学习来评估女性运动员脑震荡的方法。相比传统的临床方法，在女性运动员中诊断脑震荡存在一些局限性，而这些新技术可以通过数据分析找出与性别相关的生物机制，从而填补这一差距。 |
| [^55] | [Locally Optimal Best Arm Identification with a Fixed Budget.](http://arxiv.org/abs/2310.19788) | 该研究解决了识别具有最高预期效果的治疗方案的问题，并提出了具有固定预算的局部最优算法来降低错误识别的概率。 |
| [^56] | [Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion.](http://arxiv.org/abs/2310.18554) | 本论文通过遗憾到置信集转换方法改进了逻辑回归赌博机的遗憾界限，提出了一个基于在线学习算法的凸置信集，并应用于具有新的鞅集中步骤的遗憾分析。 |
| [^57] | [Boosting Data Analytics With Synthetic Volume Expansion.](http://arxiv.org/abs/2310.17848) | 本文介绍了一种利用合成数据生成框架来提升数据分析的方法，在此方法中，使用先进模型生成高逼真度的合成数据，并采用统计方法进行分析。研究发现，在合成数据上的统计方法错误随着合成数据的增加而减少，但最终可能会增加或停滞。 |
| [^58] | [Large-Scale Gaussian Processes via Alternating Projection.](http://arxiv.org/abs/2310.17137) | 本论文提出了一种通过交替投影的迭代方法来解决高斯过程在大规模数据集上的训练问题，并证明了该方法具有线性收敛性。 |
| [^59] | [Coreset Markov Chain Monte Carlo.](http://arxiv.org/abs/2310.17063) | Coreset MCMC提出了一种新的方法，通过模拟马尔可夫链以更新coreset权重，从而实现在推断过程中降低计算成本的目的。与其他方法相比，Coreset MCMC提供了更高质量的后验近似和更高的采样效率。 |
| [^60] | [DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data.](http://arxiv.org/abs/2310.13349) | DeepFDR是一种基于深度学习的虚警控制方法，通过利用无监督的图像分割技术解决神经影像数据中的多重检验问题，并在实验证明其相对于现有方法具有卓越的性能。 |
| [^61] | [Sampling via Gradient Flows in the Space of Probability Measures.](http://arxiv.org/abs/2310.03597) | 通过梯度流抽样方法的研究方向在计算科学和工程中具有重要意义。本文通过研究概率测度空间中的梯度流的设计组成部分，提出了三个贡献：Kullback-Leibler散度作为能量泛函的独特属性、度量的选择与不变性的关系。 |
| [^62] | [Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization.](http://arxiv.org/abs/2310.02679) | 这项工作介绍了一种名为扩散生成流采样器（DGFS）的采样框架，通过将学习过程分解为短的部分轨迹段，实现从难以处理的高维密度函数中进行采样。它通过利用中间的学习信号和非策略探索能力来改善学习信号的分配问题。 |
| [^63] | [M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning.](http://arxiv.org/abs/2309.16578) | M-OFDFT是一种利用深度学习模型解决分子系统问题的OFDFT方法，通过将非局域性建立在模型中并使用紧凑的密度表示，实现了与Kohn-Sham DFT相近的精确度，并且具有良好的外推能力。 |
| [^64] | [Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?.](http://arxiv.org/abs/2307.14642) | 本文证明了带有控制变量的黑盒变分推断在完美变分族规范下以几何速度收敛，为BBVI提供了收敛性保证，同时提出了对熵梯度估计器的改进，对比了STL估计器，并给出了明确的非渐近复杂度保证。 |
| [^65] | [Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification.](http://arxiv.org/abs/2307.14025) | 本论文提出一种基于拓扑正则化的多实例学习方法，用于罕见贫血疾病的红细胞分类。通过从单个红细胞图像中提取多尺度的拓扑特征来进行模型正则化，以保持数据的特征拓扑属性。实验结果表明，该方法是有效的。 |
| [^66] | [Scaling Laws for Imitation Learning in NetHack.](http://arxiv.org/abs/2307.09423) | 本文研究了在NetHack游戏中的模仿学习，发现通过扩大模型和数据规模可以改进模仿学习的效果，并建立了训练计算最优IL代理人的幂律。 |
| [^67] | [Scalable High-Dimensional Multivariate Linear Regression for Feature-Distributed Data.](http://arxiv.org/abs/2307.03410) | 这篇论文提出了一个适用于特征分布式数据的可扩展高维多变量线性回归算法，具有通信复杂度不依赖于特征维度和快速收敛性的优势，可应用于大规模数据集和具有多变量响应变量的场景。 |
| [^68] | [On the Expected Size of Conformal Prediction Sets.](http://arxiv.org/abs/2306.07254) | 该论文研究了适应性预测集的期望大小问题，提出了一种理论量化方法以及点估计和高概率区间，并在真实数据集上验证了其实用性。 |
| [^69] | [Prediction Error-based Classification for Class-Incremental Learning.](http://arxiv.org/abs/2305.18806) | 本论文提出了一种新的增量学习分类方法——基于预测误差的分类方法（PEC）。对PEC的评估表明，在各种基准测试中，PEC可以与最先进的增量学习方法相竞争，并具有许多实际优势，例如样本效率高、易于调整。 |
| [^70] | [Large Language Models as Tool Makers.](http://arxiv.org/abs/2305.17126) | 本文提出了一个闭环框架，即LLMs作为工具制造者（LATM），使LLMs能够自主地创建用于解决问题的工具，而不需要依赖于现有的外部工具。 |
| [^71] | [Vector-Valued Variation Spaces and Width Bounds for DNNs: Insights on Weight Decay Regularization.](http://arxiv.org/abs/2305.16534) | 该论文提供了关于通过加权衰减训练的多输出ReLU神经网络的函数类型和相应的解决方案的新见解。 |
| [^72] | [The Behavior and Convergence of Local Bayesian Optimization.](http://arxiv.org/abs/2305.15572) | 本文研究了贝叶斯本地优化策略的行为和收敛性，并在高维问题上提供了强大的实证性能。统计数据表明，单个高斯过程样本路径的本地解比全局方法恢复的预期值更好。Müller等人提出的贝叶斯本地优化算法的收敛速率在有噪音和无噪音的情况下都有推导。 |
| [^73] | [Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes.](http://arxiv.org/abs/2304.01294) | 本文提出了一种稀疏Cholesky分解算法，用于高斯过程求解非线性偏微分方程，能够有效处理高维和畸形域的问题。 |
| [^74] | [Near-Optimal Non-Parametric Sequential Tests and Confidence Sequences with Possibly Dependent Observations.](http://arxiv.org/abs/2212.14411) | 本文研究了非参数顺序检验和置信区间，在一般非参数数据生成过程下提供了类型I错误和期望拒绝时间保证，提高了其灵活性和性能。 |
| [^75] | [Adaptive variational Bayes: Optimality, computation and applications.](http://arxiv.org/abs/2109.03204) | 本文提出了一种新颖的自适应变分贝叶斯框架，可以在多个模型上运行。该方法能够自适应地实现最优的收缩速率，并提供了一种技术方法来保持可计算性和自适应最优性。 |
| [^76] | [Local Minima Structures in Gaussian Mixture Models.](http://arxiv.org/abs/2009.13040) | 研究了高斯混合模型中的负对数似然函数的局部极小值结构，发现它们都共享一种常见结构而部分确定了真正的位置混合物的簇中心。这些结果适用于真实混合组分满足某种分离条件的情况，也适用于成分数量过多或过少的情况。 |

# 详细

[^1]: 使用连续时序测量和生成人工智能进行电网监测和保护

    Grid Monitoring and Protection with Continuous Point-on-Wave Measurements and Generative AI

    [https://arxiv.org/abs/2403.06942](https://arxiv.org/abs/2403.06942)

    提出了基于连续时序测量和生成人工智能的电网监测和控制系统，通过数据压缩和故障检测，实现了对传统监控系统的进步。

    

    本文提出了一个下一代电网监测和控制系统的案例，利用生成人工智能（AI）、机器学习和统计推断方面的最新进展。我们提出了一种基于连续时序测量和AI支持的数据压缩和故障检测的监测和控制框架，超越了先前基于SCADA和同步相量技术构建的广域监测系统的发展。

    arXiv:2403.06942v1 Announce Type: cross  Abstract: Purpose This article presents a case for a next-generation grid monitoring and control system, leveraging recent advances in generative artificial intelligence (AI), machine learning, and statistical inference. Advancing beyond earlier generations of wide-area monitoring systems built upon supervisory control and data acquisition (SCADA) and synchrophasor technologies, we argue for a monitoring and control framework based on the streaming of continuous point-on-wave (CPOW) measurements with AI-powered data compression and fault detection.   Methods and Results: The architecture of the proposed design originates from the Wiener-Kallianpur innovation representation of a random process that transforms causally a stationary random process into an innovation sequence with independent and identically distributed random variables. This work presents a generative AI approach that (i) learns an innovation autoencoder that extracts innovation se
    
[^2]: Transformers学习低敏感性函数的简单性偏差

    Simplicity Bias of Transformers to Learn Low Sensitivity Functions

    [https://arxiv.org/abs/2403.06925](https://arxiv.org/abs/2403.06925)

    Transformers在不同数据模态上具有低敏感性，这种简单性偏差有助于解释其在视觉和语言任务中的优越性能。

    

    Transformers在许多任务中取得了最先进的准确性和鲁棒性，但对它们具有的归纳偏差以及这些偏差如何与其他神经网络架构不同的理解仍然难以捉摸。本文中，我们将模型对输入中的随机更改的敏感性概念化为一种简单性偏差的概念，这为解释transformers在不同数据模态上的简单性和谱偏差提供了统一的度量标准。我们展示了transformers在视觉和语言任务中比其他替代架构（如LSTMs、MLPs和CNNs）具有更低的敏感性。我们还展示了低敏感性偏差与改进性能的相关性。

    arXiv:2403.06925v1 Announce Type: cross  Abstract: Transformers achieve state-of-the-art accuracy and robustness across many tasks, but an understanding of the inductive biases that they have and how those biases are different from other neural network architectures remains elusive. Various neural network architectures such as fully connected networks have been found to have a simplicity bias towards simple functions of the data; one version of this simplicity bias is a spectral bias to learn simple functions in the Fourier space. In this work, we identify the notion of sensitivity of the model to random changes in the input as a notion of simplicity bias which provides a unified metric to explain the simplicity and spectral bias of transformers across different data modalities. We show that transformers have lower sensitivity than alternative architectures, such as LSTMs, MLPs and CNNs, across both vision and language tasks. We also show that low-sensitivity bias correlates with impro
    
[^3]: 具有适度输入维度的泄漏ReLU网络中的良性过拟合问题

    Benign overfitting in leaky ReLU networks with moderate input dimension

    [https://arxiv.org/abs/2403.06903](https://arxiv.org/abs/2403.06903)

    研究了在泄漏ReLU网络上使用铰链损失进行训练的过程中，信噪比（SNR）条件对于良性和非良性过拟合的影响，并发现高SNR值会导致良性过拟合，低SNR值则会导致有害过拟合。

    

    良性过拟合问题探讨了一个模型是否能够完美地拟合嘈杂的训练数据，同时又能够很好地泛化。我们研究了在二层泄漏ReLU网络上使用铰链损失进行训练的良性过拟合问题，针对二分类任务。我们考虑输入数据，可以分解为一个共同信号和一个随机噪声成分的总和，这两者相互正交。我们表征了模型参数的信噪比（SNR）条件，导致了良性和非良性（有害）过拟合：特别是，如果SNR很高，则发生良性过拟合，相反，如果SNR很低，则发生有害过拟合。我们将良性和非良性过拟合归因于一个近似边界最大化性质，并展示了在铰链损失下使用梯度下降（GD）训练的泄漏ReLU网络满足这一性质。与以前的工作相比，我们不需要nea

    arXiv:2403.06903v1 Announce Type: new  Abstract: The problem of benign overfitting asks whether it is possible for a model to perfectly fit noisy training data and still generalize well. We study benign overfitting in two-layer leaky ReLU networks trained with the hinge loss on a binary classification task. We consider input data which can be decomposed into the sum of a common signal and a random noise component, which lie on subspaces orthogonal to one another. We characterize conditions on the signal to noise ratio (SNR) of the model parameters giving rise to benign versus non-benign, or harmful, overfitting: in particular, if the SNR is high then benign overfitting occurs, conversely if the SNR is low then harmful overfitting occurs. We attribute both benign and non-benign overfitting to an approximate margin maximization property and show that leaky ReLU networks trained on hinge loss with Gradient Descent (GD) satisfy this property. In contrast to prior work we do not require nea
    
[^4]: 关于无监督预训练的泛化能力

    On the Generalization Ability of Unsupervised Pretraining

    [https://arxiv.org/abs/2403.06871](https://arxiv.org/abs/2403.06871)

    无监督预训练如何影响模型泛化能力的关键因素的新理论框架

    

    无监督学习的最新进展表明，无监督预训练，然后进行微调，可以提高模型的泛化能力。然而，目前对于在未标记数据集上学习的表示函数如何影响微调模型的泛化能力缺乏严格的理解。现有理论研究未能充分考虑预训练和微调阶段的分布和任务的异质性。为填补这一空白，本文引入了一个新颖的理论框架，阐明了影响从无监督预训练获得的知识在随后的微调阶段的可传递性的关键因素，最终影响了微调模型在下游任务上的泛化能力。我们应用我们的理论框架来分析两种不同情景的泛化界限：使用深度神经网络进行上下文编码器预训练和蒙版自编码预

    arXiv:2403.06871v1 Announce Type: new  Abstract: Recent advances in unsupervised learning have shown that unsupervised pre-training, followed by fine-tuning, can improve model generalization. However, a rigorous understanding of how the representation function learned on an unlabeled dataset affects the generalization of the fine-tuned model is lacking. Existing theoretical research does not adequately account for the heterogeneity of the distribution and tasks in pre-training and fine-tuning stage. To bridge this gap, this paper introduces a novel theoretical framework that illuminates the critical factor influencing the transferability of knowledge acquired during unsupervised pre-training to the subsequent fine-tuning phase, ultimately affecting the generalization capabilities of the fine-tuned model on downstream tasks. We apply our theoretical framework to analyze generalization bound of two distinct scenarios: Context Encoder pre-training with deep neural networks and Masked Auto
    
[^5]: 基于上下文的探索-利用用于强化学习

    In-context Exploration-Exploitation for Reinforcement Learning

    [https://arxiv.org/abs/2403.06826](https://arxiv.org/abs/2403.06826)

    引入了In-context Exploration-Exploitation (ICEE)算法，通过在Transformer模型内部进行探索-利用权衡，提高了在-context策略学习的效率。

    

    在-context学习是在线策略学习离线强化学习（RL）方法的一种有前途的方法，可以在推理时间内实现，无需梯度优化。然而，由于需要收集大量训练轨迹集并训练大型Transformer模型，这种方法所带来的显著计算成本。我们通过引入一种基于In-context Exploration-Exploitation（ICEE）的算法来解决这一挑战，该算法旨在优化在-context策略学习的效率。ICEE在推理时间内在Transformer模型中执行探索-利用权衡，不需要显式贝叶斯推断。因此，ICEE可以像高斯过程偏差方法那样有效地解决贝叶斯优化问题，但时间显着较短。通过在网格世界环境中的实验，我们证明ICEE能够学习解决新的R

    arXiv:2403.06826v1 Announce Type: cross  Abstract: In-context learning is a promising approach for online policy learning of offline reinforcement learning (RL) methods, which can be achieved at inference time without gradient optimization. However, this method is hindered by significant computational costs resulting from the gathering of large training trajectory sets and the need to train large Transformer models. We address this challenge by introducing an In-context Exploration-Exploitation (ICEE) algorithm, designed to optimize the efficiency of in-context policy learning. Unlike existing models, ICEE performs an exploration-exploitation trade-off at inference time within a Transformer model, without the need for explicit Bayesian inference. Consequently, ICEE can solve Bayesian optimization problems as efficiently as Gaussian process biased methods do, but in significantly less time. Through experiments in grid world environments, we demonstrate that ICEE can learn to solve new R
    
[^6]: 大规模、非光滑最大熵模型的高效一阶算法及其在野火科学中的应用

    Efficient first-order algorithms for large-scale, non-smooth maximum entropy models with application to wildfire science

    [https://arxiv.org/abs/2403.06816](https://arxiv.org/abs/2403.06816)

    提出了一种新颖的优化算法，利用Kullback-Leibler散度训练大规模、非光滑的Maxent模型

    

    最大熵（Maxent）模型是一类利用最大熵原理从数据中估计概率分布的统计模型。由于现代数据集的规模，Maxent模型需要高效的优化算法来适应大数据应用。本文提出了一种新颖的优化算法，克服了训练大规模、非光滑Maxent模型的现有算法的缺点。我们提出的一阶算法利用Kullback-Leibler散度，可以高效地训练大规模且非光滑的Maxent模型。

    arXiv:2403.06816v1 Announce Type: cross  Abstract: Maximum entropy (Maxent) models are a class of statistical models that use the maximum entropy principle to estimate probability distributions from data. Due to the size of modern data sets, Maxent models need efficient optimization algorithms to scale well for big data applications. State-of-the-art algorithms for Maxent models, however, were not originally designed to handle big data sets; these algorithms either rely on technical devices that may yield unreliable numerical results, scale poorly, or require smoothness assumptions that many practical Maxent models lack. In this paper, we present novel optimization algorithms that overcome the shortcomings of state-of-the-art algorithms for training large-scale, non-smooth Maxent models. Our proposed first-order algorithms leverage the Kullback-Leibler divergence to train large-scale and non-smooth Maxent models efficiently. For Maxent models with discrete probability distribution of $
    
[^7]: 单调个体公平性

    Monotone Individual Fairness

    [https://arxiv.org/abs/2403.06812](https://arxiv.org/abs/2403.06812)

    该论文提出了一个新的在线学习框架，通过单调聚合函数实现了一种个体公平性审计方案，可以有效降低多个审计员对个体公平性的分析复杂度。

    

    我们重新审视了带有个体公平性的在线学习问题，其中在线学习者努力在最大化预测准确性的同时确保相似个体受到类似对待。我们首先扩展了Gillen等人（2018年）；Bechavod等人（2020年）的框架，这些框架依赖于来自人类审计员有关公平性违规的反馈，因为我们考虑了能够聚合任意数量审计员反馈的审计方案，使用了我们称为单调聚合函数的丰富类别。然后，我们证明了这种审计方案的特性，通过实际将多个审计员的个体公平性审计分析简化为（实例特定的）单个审计员的审计。利用我们的广义框架，我们提出了一个实现上界前沿的oracle-efficient算法，分别为遗憾值和公平性违规次数的上界$(\mathcal{O}(T^{1/2+2b}),\mathcal{O}(T^{3/4-b}))$，其中$0\leq b$

    arXiv:2403.06812v1 Announce Type: new  Abstract: We revisit the problem of online learning with individual fairness, where an online learner strives to maximize predictive accuracy while ensuring that similar individuals are treated similarly. We first extend the frameworks of Gillen et al. (2018); Bechavod et al. (2020), which rely on feedback from human auditors regarding fairness violations, as we consider auditing schemes that are capable of aggregating feedback from any number of auditors, using a rich class we term monotone aggregation functions. We then prove a characterization for such auditing schemes, practically reducing the analysis of auditing for individual fairness by multiple auditors to that of auditing by (instance-specific) single auditors. Using our generalized framework, we present an oracle-efficient algorithm achieving an upper bound frontier of $(\mathcal{O}(T^{1/2+2b}),\mathcal{O}(T^{3/4-b}))$ respectively for regret, number of fairness violations, for $0\leq b
    
[^8]: 多步一致性模型

    Multistep Consistency Models

    [https://arxiv.org/abs/2403.06807](https://arxiv.org/abs/2403.06807)

    本文提出了多步一致性模型，通过在一致性模型和扩散模型之间插值，实现了采样速度和采样质量的平衡。

    

    扩散模型相对容易训练，但生成样本需要许多步骤。一致性模型更难训练，但可以在一个步骤中生成样本。本文提出了多步一致性模型：通过一致性模型和TRACT的统一，可以在一致性模型和扩散模型之间进行插值：在采样速度和采样质量之间取得平衡。具体来说，1步一致性模型是传统的一致性模型，而我们展示了$\infty$步一致性模型是扩散模型。多步一致性模型在实践中表现良好。将样本预算从单步增加到2-8步，我们可以更轻松地训练模型，生成更高质量的样本，同时保留大部分采样速度优势。在Imagenet 64上8步达到1.4的FID，在Imagenet128上8步达到2.1的FID。

    arXiv:2403.06807v1 Announce Type: new  Abstract: Diffusion models are relatively easy to train but require many steps to generate samples. Consistency models are far more difficult to train, but generate samples in a single step.   In this paper we propose Multistep Consistency Models: A unification between Consistency Models (Song et al., 2023) and TRACT (Berthelot et al., 2023) that can interpolate between a consistency model and a diffusion model: a trade-off between sampling speed and sampling quality. Specifically, a 1-step consistency model is a conventional consistency model whereas we show that a $\infty$-step consistency model is a diffusion model.   Multistep Consistency Models work really well in practice. By increasing the sample budget from a single step to 2-8 steps, we can train models more easily that generate higher quality samples, while retaining much of the sampling speed benefits. Notable results are 1.4 FID on Imagenet 64 in 8 step and 2.1 FID on Imagenet128 in 8 
    
[^9]: 对核函数的近似方法

    On the Approximation of Kernel functions

    [https://arxiv.org/abs/2403.06731](https://arxiv.org/abs/2403.06731)

    本文提出了一种新的方法，通过考虑径向核函数的泰勒级数逼近，建立了对核函数的较好近似，证实了可以使用比文献中更小的正则化参数来实现更好的结果。

    

    统计学习中的各种方法都建立在再生核希尔伯特空间中考虑的核函数基础之上。在应用中，通常根据问题和数据的特征选择核函数。然后利用这个核函数推断那些没有观测到解释数据的点的响应变量。本文研究的数据位于高维空间中的紧致集合中，并解决了核函数本身的近似问题。新方法考虑了径向核函数的泰勒级数逼近。对于单位立方体上的高斯核函数，本文建立了关联特征函数的上限，这个上限随指数多项式增长。该新方法证明了比文献中考虑的更小的正则化参数，从而整体上实现更好的近似。这一改进证实了低秩逼近方法，如Nystrom方法。

    arXiv:2403.06731v1 Announce Type: cross  Abstract: Various methods in statistical learning build on kernels considered in reproducing kernel Hilbert spaces. In applications, the kernel is often selected based on characteristics of the problem and the data. This kernel is then employed to infer response variables at points, where no explanatory data were observed. The data considered here are located in compact sets in higher dimensions and the paper addresses approximations of the kernel itself. The new approach considers Taylor series approximations of radial kernel functions. For the Gauss kernel on the unit cube, the paper establishes an upper bound of the associated eigenfunctions, which grows only polynomially with respect to the index. The novel approach substantiates smaller regularization parameters than considered in the literature, overall leading to better approximations. This improvement confirms low rank approximation methods such as the Nystr\"om method.
    
[^10]: 在隐私敏感领域中从联邦学习中有可证明的互惠益处

    Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains

    [https://arxiv.org/abs/2403.06672](https://arxiv.org/abs/2403.06672)

    本文研究了在隐私敏感领域中如何设计一种FL协议，既能保证隐私，又能提高模型准确性，并提供了设计出对所有参与者都有益处的协议。

    

    跨领域联邦学习（FL）允许数据所有者通过从彼此的私有数据集中获益来训练准确的机器学习模型。本文研究了在何时以及如何服务器可以设计一种对所有参与者都有利的FL协议的问题。我们提供了在均值估计和凸随机优化背景下存在相互有利协议的必要和充分条件。我们推导出了在对称隐私偏好下，最大化总客户效用的协议。最后，我们设计了最大化最终模型准确性的协议，并在合成实验中展示了它们的好处。

    arXiv:2403.06672v1 Announce Type: cross  Abstract: Cross-silo federated learning (FL) allows data owners to train accurate machine learning models by benefiting from each others private datasets. Unfortunately, the model accuracy benefits of collaboration are often undermined by privacy defenses. Therefore, to incentivize client participation in privacy-sensitive domains, a FL protocol should strike a delicate balance between privacy guarantees and end-model accuracy. In this paper, we study the question of when and how a server could design a FL protocol provably beneficial for all participants. First, we provide necessary and sufficient conditions for the existence of mutually beneficial protocols in the context of mean estimation and convex stochastic optimization. We also derive protocols that maximize the total clients' utility, given symmetric privacy preferences. Finally, we design protocols maximizing end-model accuracy and demonstrate their benefits in synthetic experiments.
    
[^11]: 可扩展的在线探索方法：通过Coverability

    Scalable Online Exploration via Coverability

    [https://arxiv.org/abs/2403.06571](https://arxiv.org/abs/2403.06571)

    提出了探索目标框架，引入了$L_1$-覆盖度作为新的探索目标，支持内在复杂度控制、高效规划和灵活集成的优点。

    

    在强化学习中，探索是一个主要挑战，尤其对于需要函数逼近的高维领域。我们提出了探索目标——作为一个概念框架，能够使任何奖励函数的下游最大化成为可能。在这个框架内，我们引入了一个新的目标，即$L_1$-覆盖度，它泛化了以往的探索方案，并支持三个基本愿望：1.内在复杂度控制。$L_1$-覆盖度与结构参数$L_1$-Coverability相关联，反映了潜在MDP的内在统计困难度，包含Block和Low-Rank MDPs。2.高效规划。对于已知的MDP，优化$L_1$-覆盖度能够有效地降低到标准的策略优化，允许与诸如策略梯度和Q-learning等现成方法灵活集成。3.高效的探索。$L_1$-覆盖度的优化等同于现有强化学习算法的操作，尤其在高维领域中具有很强的泛化性。

    arXiv:2403.06571v1 Announce Type: new  Abstract: Exploration is a major challenge in reinforcement learning, especially for high-dimensional domains that require function approximation. We propose exploration objectives -- policy optimization objectives that enable downstream maximization of any reward function -- as a conceptual framework to systematize the study of exploration. Within this framework, we introduce a new objective, $L_1$-Coverage, which generalizes previous exploration schemes and supports three fundamental desiderata:   1. Intrinsic complexity control. $L_1$-Coverage is associated with a structural parameter, $L_1$-Coverability, which reflects the intrinsic statistical difficulty of the underlying MDP, subsuming Block and Low-Rank MDPs.   2. Efficient planning. For a known MDP, optimizing $L_1$-Coverage efficiently reduces to standard policy optimization, allowing flexible integration with off-the-shelf methods such as policy gradient and Q-learning approaches.   3. E
    
[^12]: 切片-华塞斯坦距离及在卡坦-哈达玛德流形上的应用

    Sliced-Wasserstein Distances and Flows on Cartan-Hadamard Manifolds

    [https://arxiv.org/abs/2403.06560](https://arxiv.org/abs/2403.06560)

    该论文在卡坦-哈达玛德流形上推导了切片-华塞斯坦距离的一般构造，提出了不同应用，并且推导了非参数方案以最小化这些新距离。

    

    尽管许多机器学习方法被开发或移植到黎曼流形上，以应对具有已知非欧几何结构的数据，在这些空间中对最优输运（Optimal Transport, OT）方法却没有得到太多关注。在欧几里得空间中，一种流行的替代方法是切片-华塞斯坦距离，该方法利用了一维华塞斯坦距离的封闭形式解决方案，但在流形上无法直接使用。在这项工作中，我们推导了卡坦-哈达玛德流形上切片-华塞斯坦距离的一般构造，这些流形是具有非正曲率的黎曼流形，其中包括了双曲空间或对称正定矩阵空间等。然后，我们提出了不同的应用。此外，我们推导了非参数方案来最小化这些新距离，通过近似它们的华塞斯坦距离。

    arXiv:2403.06560v1 Announce Type: new  Abstract: While many Machine Learning methods were developed or transposed on Riemannian manifolds to tackle data with known non Euclidean geometry, Optimal Transport (OT) methods on such spaces have not received much attention. The main OT tool on these spaces is the Wasserstein distance which suffers from a heavy computational burden. On Euclidean spaces, a popular alternative is the Sliced-Wasserstein distance, which leverages a closed-form solution of the Wasserstein distance in one dimension, but which is not readily available on manifolds. In this work, we derive general constructions of Sliced-Wasserstein distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive curvature, which include among others Hyperbolic spaces or the space of Symmetric Positive Definite matrices. Then, we propose different applications. Additionally, we derive non-parametric schemes to minimize these new distances by approximating their Wasserste
    
[^13]: 基于NML编码在离散、混合和连续变量中检测未观测到的共同原因

    Detection of Unobserved Common Causes based on NML Code in Discrete, Mixed, and Continuous Variables

    [https://arxiv.org/abs/2403.06499](https://arxiv.org/abs/2403.06499)

    提出一种新方法CLOUD，用于仅基于观测数据检测未观测到的共同原因，无需对未观测变量的方程模型形式做任何假设

    

    仅基于观测数据从因果发现中检测未观测到的共同原因是一个至关重要但具有挑战性的问题。我们将两个随机变量之间所有可能的因果关系归为四个类别，并旨在从观测数据中识别一个：直接因果关系存在的两种情况，变量相互独立的情况，以及变量被潜在混杂因素所混淆的情况。尽管已提出了解决这一问题的现有方法，但它们要求未观测到的变量满足其方程模型形式的假设。在我们之前的研究中（Kobayashi等，2022年），首次提出了一种无需这些假设的离散数据的因果发现方法，命名为CLOUD。使用归一化最大似然（NML）编码，CLOUD从一组候选模型中选择一个生成观测数据最小编码长度的模型。本文将CLOUD扩展到...

    arXiv:2403.06499v1 Announce Type: cross  Abstract: Causal discovery in the presence of unobserved common causes from observational data only is a crucial but challenging problem. We categorize all possible causal relationships between two random variables into the following four categories and aim to identify one from observed data: two cases in which either of the direct causality exists, a case that variables are independent, and a case that variables are confounded by latent confounders. Although existing methods have been proposed to tackle this problem, they require unobserved variables to satisfy assumptions on the form of their equation models. In our previous study (Kobayashi et al., 2022), the first causal discovery method without such assumptions is proposed for discrete data and named CLOUD. Using Normalized Maximum Likelihood (NML) Code, CLOUD selects a model that yields the minimum codelength of the observed data from a set of model candidates. This paper extends CLOUD to 
    
[^14]: 通过大致共享特征来实现领域之间的桥梁

    Bridging Domains with Approximately Shared Features

    [https://arxiv.org/abs/2403.06424](https://arxiv.org/abs/2403.06424)

    提出了一种统计框架，根据特征与标签的相关性方差来区分特征的效用，并设计了一种学习过程，从源任务学习到大致共享的特征表示，并在目标任务上进行微调，以优化总体风险。

    

    多源领域适应旨在在将机器学习模型应用于未知领域时降低性能下降。一个基本挑战是设计特征选择的最佳策略。现有文献在某种程度上存在悖论：有些人主张从源领域学习不变特征，而另一些人则更青睐多样化特征。为了解决这一挑战，我们提出了一个统计框架，根据它们与标签 $y$ 的相关性的方差来区分特征的效用。在我们的框架下，我们设计和分析了一个学习过程，该过程由从源任务学习到的大致共享特征表示，并在目标任务上进行微调。我们的理论分析需要学习大致共享特征的重要性，而不仅仅是严格不变的特征，并且相对于以前关于源领域适应性的结果而言，产生了改进的总体风险。

    arXiv:2403.06424v1 Announce Type: cross  Abstract: Multi-source domain adaptation aims to reduce performance degradation when applying machine learning models to unseen domains. A fundamental challenge is devising the optimal strategy for feature selection. Existing literature is somewhat paradoxical: some advocate for learning invariant features from source domains, while others favor more diverse features. To address the challenge, we propose a statistical framework that distinguishes the utilities of features based on the variance of their correlation to label $y$ across domains. Under our framework, we design and analyze a learning procedure consisting of learning approximately shared feature representation from source tasks and fine-tuning it on the target task. Our theoretical analysis necessitates the importance of learning approximately shared features instead of only the strictly invariant features and yields an improved population risk compared to previous results on both sou
    
[^15]: 在多模式变分自动编码器中解开共享和私有潜在因素

    Disentangling shared and private latent factors in multimodal Variational Autoencoders

    [https://arxiv.org/abs/2403.06338](https://arxiv.org/abs/2403.06338)

    多模态变分自动编码器在解开共享和私有潜在因素方面的能力进行了研究，并提出了改进的方法以增强对特定模态变化的鲁棒性。

    

    多模态数据的生成模型可以确定可能与观测数据异质性的重要决定因素相关联的潜在因素。共享因素可以用于解释跨模态的变化，而其他因素可能是私有的，仅用于解释单个模态。多模态变分自动编码器，如MVAE和MMVAE，是推断这些潜在潜因素并将共享变异与私有变异分离的自然选择。在这项工作中，我们研究它们可靠执行此解缠的能力。特别是，我们强调了一个具有挑战性的问题设置，其中特定于模态的变异支配了共享信号。采用交叉模态预测的视角，我们展示了现有模型的局限性，并提出了一种修改方法，使它们对特定于模态的变异更加稳健。我们的发现得到了实验证明。

    arXiv:2403.06338v1 Announce Type: cross  Abstract: Generative models for multimodal data permit the identification of latent factors that may be associated with important determinants of observed data heterogeneity. Common or shared factors could be important for explaining variation across modalities whereas other factors may be private and important only for the explanation of a single modality. Multimodal Variational Autoencoders, such as MVAE and MMVAE, are a natural choice for inferring those underlying latent factors and separating shared variation from private. In this work, we investigate their capability to reliably perform this disentanglement. In particular, we highlight a challenging problem setting where modality-specific variation dominates the shared signal. Taking a cross-modal prediction perspective, we demonstrate limitations of existing models, and propose a modification how to make them more robust to modality-specific variation. Our findings are supported by experi
    
[^16]: 你需要多少数据？第二部分：预测深度学习类特定训练数据集大小

    How much data do you need? Part 2: Predicting DL class specific training dataset sizes

    [https://arxiv.org/abs/2403.06311](https://arxiv.org/abs/2403.06311)

    通过考虑每个类别的训练样本数量，而不仅仅是总体训练样本数量，来预测机器学习分类模型性能，并提出了一种基于空间填充设计的算法，可以对 CIFAR10 和 EMNIST 数据集进行应用。

    

    本文旨在研究在考虑每个类别的训练样本数量而不仅仅是总体训练样本数量时，预测机器学习分类模型性能的问题。这带来了一个组合问题，即在给定固定总体训练数据集大小的情况下，应考虑哪些每个类的训练样本数量组合。为了解决这个问题，提出了一种算法，该算法受到实验设计中的空间填满设计的特殊情况的启发。生成的数据使用诸如幂律曲线和类似模型、扩展的广义线性模型等模型来进行建模，即通过将总体训练数据集大小替换为给定标签类别的训练样本数量的参数化线性组合。该算法已应用于CIFAR10和EMNIST数据集。

    arXiv:2403.06311v1 Announce Type: new  Abstract: This paper targets the question of predicting machine learning classification model performance, when taking into account the number of training examples per class and not just the overall number of training examples. This leads to the a combinatorial question, which combinations of number of training examples per class should be considered, given a fixed overall training dataset size. In order to solve this question, an algorithm is suggested which is motivated from special cases of space filling design of experiments. The resulting data are modeled using models like powerlaw curves and similar models, extended like generalized linear models i.e. by replacing the overall training dataset size by a parametrized linear combination of the number of training examples per label class. The proposed algorithm has been applied on the CIFAR10 and the EMNIST datasets.
    
[^17]: 非参数自动微分变分推断与样条逼近

    Nonparametric Automatic Differentiation Variational Inference with Spline Approximation

    [https://arxiv.org/abs/2403.06302](https://arxiv.org/abs/2403.06302)

    提出了一种基于样条的非参数逼近方法，实现了对复杂结构分布的灵活后验逼近，提高了生成模型性能。

    

    自动微分变分推断（ADVI）在学习概率模型方面很有效。经典ADVI依赖于参数化方法来逼近后验分布。本文提出了一种基于样条的非参数逼近方法，实现了对具有复杂结构的分布（如偏度、多峰性和有界支持）的灵活后验逼近。与广泛使用的非参数变分推断方法相比，所提出的方法易于实现，并适应各种数据结构。通过采用样条逼近，我们推导出了重要性加权自动编码器的一个下界，并确立了渐近一致性。实验证明了所提出方法在逼近复杂后验分布和改善具有不完全数据的生成模型性能方面的高效性。

    arXiv:2403.06302v1 Announce Type: cross  Abstract: Automatic Differentiation Variational Inference (ADVI) is efficient in learning probabilistic models. Classic ADVI relies on the parametric approach to approximate the posterior. In this paper, we develop a spline-based nonparametric approximation approach that enables flexible posterior approximation for distributions with complicated structures, such as skewness, multimodality, and bounded support. Compared with widely-used nonparametric variational inference methods, the proposed method is easy to implement and adaptive to various data structures. By adopting the spline approximation, we derive a lower bound of the importance weighted autoencoder and establish the asymptotic consistency. Experiments demonstrate the efficiency of the proposed method in approximating complex posterior distributions and improving the performance of generative models with incomplete data.
    
[^18]: 概率神经电路

    Probabilistic Neural Circuits

    [https://arxiv.org/abs/2403.06235](https://arxiv.org/abs/2403.06235)

    PNCs将概率电路和神经网络的特点结合起来，可以解释为深层混合的贝叶斯网络，同时作为强大的函数逼近器。

    

    概率电路（PCs）近年来作为一个灵活的框架，被广泛应用于探讨支持可处理查询且足够表达复杂概率分布的概率模型。然而，可处理性是有代价的：PCs比神经网络表达能力更弱。在本文中，我们介绍了概率神经电路（PNCs），在可处理性和表达能力方面在PCs和神经网络之间取得了平衡。理论上，我们展示了PNCs可以被解释为贝叶斯网络的深度混合。实验上，我们证明了PNCs构成了强大的函数逼近器。

    arXiv:2403.06235v1 Announce Type: cross  Abstract: Probabilistic circuits (PCs) have gained prominence in recent years as a versatile framework for discussing probabilistic models that support tractable queries and are yet expressive enough to model complex probability distributions. Nevertheless, tractability comes at a cost: PCs are less expressive than neural networks. In this paper we introduce probabilistic neural circuits (PNCs), which strike a balance between PCs and neural nets in terms of tractability and expressive power. Theoretically, we show that PNCs can be interpreted as deep mixtures of Bayesian networks. Experimentally, we demonstrate that PNCs constitute powerful function approximators.
    
[^19]: LinearAPT: 一种用于固定预算阈值线性赌博机问题的自适应算法

    LinearAPT: An Adaptive Algorithm for the Fixed-Budget Thresholding Linear Bandit Problem

    [https://arxiv.org/abs/2403.06230](https://arxiv.org/abs/2403.06230)

    LinearAPT算法是一种为固定预算设置的阈值线性赌博机问题而设计的新算法，具有适应性、简单性和计算效率，并在优化顺序决策方面表现出色。

    

    在这项研究中，我们深入探讨了阈值线性赌博机（TLB）问题，这是随机多臂赌博问题中的一个微妙领域，重点是在资源约束下最大化针对线性定义阈值的决策准确性。我们提出了LinearAPT，这是一种为TLB的固定预算设置而设计的新颖算法，为优化顺序决策提供了高效解决方案。该算法不仅为估计损失提供了理论上界，而且在合成和真实数据集上展示了强大的性能。我们的贡献突出了LinearAPT的适应性、简单性和计算效率，使其成为解决复杂顺序决策挑战的有价值工具。

    arXiv:2403.06230v1 Announce Type: new  Abstract: In this study, we delve into the Thresholding Linear Bandit (TLB) problem, a nuanced domain within stochastic Multi-Armed Bandit (MAB) problems, focusing on maximizing decision accuracy against a linearly defined threshold under resource constraints. We present LinearAPT, a novel algorithm designed for the fixed budget setting of TLB, providing an efficient solution to optimize sequential decision-making. This algorithm not only offers a theoretical upper bound for estimated loss but also showcases robust performance on both synthetic and real-world datasets. Our contributions highlight the adaptability, simplicity, and computational efficiency of LinearAPT, making it a valuable addition to the toolkit for addressing complex sequential decision-making challenges.
    
[^20]: 具有先前扩散的兰基文算法在非对数凹抽样中的改进分析

    An Improved Analysis of Langevin Algorithms with Prior Diffusion for Non-Log-Concave Sampling

    [https://arxiv.org/abs/2403.06183](https://arxiv.org/abs/2403.06183)

    本文研究了先前扩散技术对满足对数Sobolev不等式的目标分布的作用，扩展了先前仅针对强对数凹分布的相关工作。

    

    高维抽样问题中的计算复杂度的维度相关性是一个基本问题，无论是从实际还是理论的角度来看。相对于具有无偏稳态分布的抽样器，如Metropolis-adjusted Langevin algorithm (MALA)，具有偏置稳态分布的抽样器，如Underdamped Langevin Dynamics (ULD)，在低准确度情况下表现更好，仅仅因为它们的复杂度对维度的依赖性更低。在此基础上，Freund等人(2022)提出，具有先前扩散的修改兰基文算法能够维度独立地收敛于强对数凹目标分布。然而，对于更一般的情况是否存在这样的性质仍然是一个未解之谜。在本文中，我们研究了对满足对数Sobolev不等式（LSI）的目标分布的先前扩散技术，该技术覆盖了比强对数凹分布更广泛的分布类。

    arXiv:2403.06183v1 Announce Type: new  Abstract: Understanding the dimension dependency of computational complexity in high-dimensional sampling problem is a fundamental problem, both from a practical and theoretical perspective. Compared with samplers with unbiased stationary distribution, e.g., Metropolis-adjusted Langevin algorithm (MALA), biased samplers, e.g., Underdamped Langevin Dynamics (ULD), perform better in low-accuracy cases just because a lower dimension dependency in their complexities. Along this line, Freund et al. (2022) suggest that the modified Langevin algorithm with prior diffusion is able to converge dimension independently for strongly log-concave target distributions. Nonetheless, it remains open whether such property establishes for more general cases. In this paper, we investigate the prior diffusion technique for the target distributions satisfying log-Sobolev inequality (LSI), which covers a much broader class of distributions compared to the strongly log-c
    
[^21]: ALL0CORE张量分解用于稀疏计数数据

    The ALL0CORE Tensor Decomposition for Sparse Count Data

    [https://arxiv.org/abs/2403.06153](https://arxiv.org/abs/2403.06153)

    ALL0CORE是一种新的概率非负张量分解方法，它在保持计算可处理性的基础上利用Tucker分解的潜在结构，可以仅使用核的微小部分即达到与完整Tucker分解相同效果。

    

    本文介绍了ALL0CORE，一种新的概率非负张量分解形式。ALL0CORE是一种Tucker分解，其中核张量的非零元素数量（即L0范数）被限制为远小于核的大小的预设值Q。虽然用户规定了总预算Q，但非零元素的位置和值是潜在变量，在推断过程中分配给核张量的各个部分。ALL0CORE，即分配的L0约束核，因此既具有CP分解的计算可处理性，又具有Tucker的潜在结构，令人满意。在一系列真实数据实验中，我们展示了ALL0CORE通常只需使用核的微小部分（例如～1%）即可以与完整Tucker分解相同的结果，而成本仅相应的一小部分。

    arXiv:2403.06153v1 Announce Type: cross  Abstract: This paper introduces ALL0CORE, a new form of probabilistic non-negative tensor decomposition. ALL0CORE is a Tucker decomposition where the number of non-zero elements (i.e., the L0-norm) of the core tensor is constrained to a preset value Q much smaller than the size of the core. While the user dictates the total budget Q, the locations and values of the non-zero elements are latent variables and allocated across the core tensor during inference. ALL0CORE -- i.e., allocated L0-constrained core -- thus enjoys both the computational tractability of CP decomposition and the qualitatively appealing latent structure of Tucker. In a suite of real-data experiments, we demonstrate that ALL0CORE typically requires only tiny fractions (e.g.,~1%) of the full core to achieve the same results as full Tucker decomposition at only a correspondingly tiny fraction of the cost.
    
[^22]: 在众包环境中利用在线学习进行基于喜好的主观评估设计优化

    Automatic design optimization of preference-based subjective evaluation with online learning in crowdsourcing environment

    [https://arxiv.org/abs/2403.06100](https://arxiv.org/abs/2403.06100)

    在众包环境中，我们提出了一种自动优化方法，利用在线学习对配对组合和评估量进行优化，实现基于喜好的主观评估的设计优化。

    

    基于喜好的主观评估是评价生成式媒体可靠性的关键方法。然而，其庞大的配对组合使得它无法应用于利用众包进行大规模评估。为了解决这个问题，我们提出了一种用于在众包环境中进行基于喜好的主观评估的自动优化方法，该方法涉及对配对组合选择和评估量分配的在线学习。我们使用基于排序算法的基于喜好的在线学习方法来识别具有最小样本量的评估目标的完全顺序。我们的在线学习算法支持在众包所需的固定预算条件下的并行和异步执行。我们对合成语音的基于喜好的主观评估实验证明了我们的方法成功通过将配对组合从351减少到83并分配最优评估。

    arXiv:2403.06100v1 Announce Type: cross  Abstract: A preference-based subjective evaluation is a key method for evaluating generative media reliably. However, its huge combinations of pairs prohibit it from being applied to large-scale evaluation using crowdsourcing. To address this issue, we propose an automatic optimization method for preference-based subjective evaluation in terms of pair combination selections and allocation of evaluation volumes with online learning in a crowdsourcing environment. We use a preference-based online learning method based on a sorting algorithm to identify the total order of evaluation targets with minimum sample volumes. Our online learning algorithm supports parallel and asynchronous execution under fixed-budget conditions required for crowdsourcing. Our experiment on preference-based subjective evaluation of synthetic speech shows that our method successfully optimizes the test by reducing pair combinations from 351 to 83 and allocating optimal eva
    
[^23]: 移植：使随机森林一致化

    Grafting: Making Random Forests Consistent

    [https://arxiv.org/abs/2403.06015](https://arxiv.org/abs/2403.06015)

    本文探讨了将一致化估计器移植到浅层决策树（CART）的适用性，并表明这种方法具有一致性保证并在实证环境中表现良好。

    

    尽管随机森林在性能和广泛应用方面表现出色，但关于其理论知之甚少。一个未解之谜是随机森林算法是否一致化，或何时达到一致化。文献探讨了经典随机森林算法的各种变体，以解决这一问题和已知缺陷。本文为这一文献做出了贡献。具体来说，探讨了将一致化估计器移植到浅层CART的适用性。结果表明，这种方法具有一致化保证并在实证环境中表现良好。

    arXiv:2403.06015v1 Announce Type: cross  Abstract: Despite their performance and widespread use, little is known about the theory of Random Forests. A major unanswered question is whether, or when, the Random Forest algorithm is consistent. The literature explores various variants of the classic Random Forest algorithm to address this question and known short-comings of the method. This paper is a contribution to this literature. Specifically, the suitability of grafting consistent estimators onto a shallow CART is explored. It is shown that this approach has a consistency guarantee and performs well in empirical settings.
    
[^24]: 分布式时间差分的统计效率

    Statistical Efficiency of Distributional Temporal Difference

    [https://arxiv.org/abs/2403.05811](https://arxiv.org/abs/2403.05811)

    该论文分析了分布式时间差分的统计效率和有限样本性能。

    

    分布式强化学习(DRL)关注的是返回的完整分布，而不仅仅是均值，在各个领域取得了经验成功。领域DRL中的核心任务之一是分布式策略评估，涉及估计给定策略pi的返回分布η^pi。相应地提出了分布时间差分(TD)算法，这是经典RL文献中时间差分算法的延伸。在表格案例中，citet{rowland2018analysis}和citet{rowland2023analysis}分别证明了两个分布式TD实例即分类时间差分算法(CTD)和分位数时间差分算法(QTD)的渐近收敛。在这篇论文中，我们进一步分析了分布式TD的有限样本性能。为了促进理论分析，我们提出了一个非参数的 dis

    arXiv:2403.05811v1 Announce Type: cross  Abstract: Distributional reinforcement learning (DRL), which cares about the full distribution of returns instead of just the mean, has achieved empirical success in various domains. One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\eta^\pi$ for a given policy $\pi$. A distributional temporal difference (TD) algorithm has been accordingly proposed, which is an extension of the temporal difference algorithm in the classic RL literature. In the tabular case, \citet{rowland2018analysis} and \citet{rowland2023analysis} proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference algorithm (CTD) and quantile temporal difference algorithm (QTD), respectively. In this paper, we go a step further and analyze the finite-sample performance of distributional TD. To facilitate theoretical analysis, we propose non-parametric dis
    
[^25]: 通过独立查询预言者在马尔可夫等价类中进行成员测试

    Membership Testing in Markov Equivalence Classes via Independence Query Oracles

    [https://arxiv.org/abs/2403.05759](https://arxiv.org/abs/2403.05759)

    通过建立在给定的最大无向团大小($s$)方面的下界，我们探讨了通过独立查询预言者在马尔可夫等价类中进行成员测试这一问题。

    

    变量之间因果关系的理解是许多科学领域中具有广泛影响的基本问题。虽然已经投入了大量研究来从数据中学习因果图，但其补充概念——测试因果关系却基本没有被探索。我们通过建立在给定MEC(Markov等价类)的最大无向团的大小($s$)方面的下界，探讨基于约束的测试方法。在最坏情况下，我们展示了$\exp(\Omega(s))$个独立性测试的下界。

    arXiv:2403.05759v1 Announce Type: cross  Abstract: Understanding causal relationships between variables is a fundamental problem with broad impact in numerous scientific fields. While extensive research has been dedicated to learning causal graphs from data, its complementary concept of testing causal relationships has remained largely unexplored. While learning involves the task of recovering the Markov equivalence class (MEC) of the underlying causal graph from observational data, the testing counterpart addresses the following critical question: Given a specific MEC and observational data from some causal graph, can we determine if the data-generating causal graph belongs to the given MEC?   We explore constraint-based testing methods by establishing bounds on the required number of conditional independence tests. Our bounds are in terms of the size of the maximum undirected clique ($s$) of the given MEC. In the worst case, we show a lower bound of $\exp(\Omega(s))$ independence tes
    
[^26]: 通过额外图节点的方法对分类和混合数据进行谱聚类

    Spectral Clustering of Categorical and Mixed-type Data via Extra Graph Nodes

    [https://arxiv.org/abs/2403.05669](https://arxiv.org/abs/2403.05669)

    通过添加额外节点，本文提出了一种新的方法，将数值和分类信息同时纳入谱聚类算法，避免了数据预处理或复杂相似性函数的需求。

    

    将数据对象聚类成同质群体是数据挖掘中最重要的任务之一。谱聚类是一种理论上坚实且适应多种现实场景的最重要的聚类算法之一。本文探讨了一种更自然的方法，将数值和分类信息同时纳入谱聚类算法，避免了需要对数据进行预处理或使用复杂相似性函数的情况。

    arXiv:2403.05669v1 Announce Type: cross  Abstract: Clustering data objects into homogeneous groups is one of the most important tasks in data mining. Spectral clustering is arguably one of the most important algorithms for clustering, as it is appealing for its theoretical soundness and is adaptable to many real-world data settings. For example, mixed data, where the data is composed of numerical and categorical features, is typically handled via numerical discretization, dummy coding, or similarity computation that takes into account both data types. This paper explores a more natural way to incorporate both numerical and categorical information into the spectral clustering algorithm, avoiding the need for data preprocessing or the use of sophisticated similarity functions. We propose adding extra nodes corresponding to the different categories the data may belong to and show that it leads to an interpretable clustering objective function. Furthermore, we demonstrate that this simple 
    
[^27]: 密度回归：面向分布偏移下不确定性估计的高效且距离感知的深度回归器

    Density-Regression: Efficient and Distance-Aware Deep Regressor for Uncertainty Estimation under Distribution Shifts

    [https://arxiv.org/abs/2403.05600](https://arxiv.org/abs/2403.05600)

    密度回归是一种利用密度函数进行不确定性估计并通过单次前向传递实现快速推断的方法，具有距离感知能力，能够在分布偏移下产生高质量不确定性估计。

    

    现代深度合奏技术通过使用不同模型的多次前向传递实现强大的不确定性估计性能。然而，这样做会占用大量存储空间并且推断（测试）时间较慢。为了解决此问题，我们提出了一种称为密度回归的方法，该方法在不确定性估计中利用密度函数，通过单次前向传递实现快速推断。我们证明它在特征空间上具有距离感知，这是神经网络产生高质量不确定性估计的必要条件。在实证方面，我们在立方体玩具数据集、基准UCI数据集、具有时间序列的天气预测和真实世界偏移应用下的深度估计等回归任务上进行了实验。我们展示了在分布偏移下，密度回归与现代深度回归器相比具有竞争力的不确定性估计性能，同时使用的模式较低。

    arXiv:2403.05600v1 Announce Type: new  Abstract: Morden deep ensembles technique achieves strong uncertainty estimation performance by going through multiple forward passes with different models. This is at the price of a high storage space and a slow speed in the inference (test) time. To address this issue, we propose Density-Regression, a method that leverages the density function in uncertainty estimation and achieves fast inference by a single forward pass. We prove it is distance aware on the feature space, which is a necessary condition for a neural network to produce high-quality uncertainty estimation under distribution shifts. Empirically, we conduct experiments on regression tasks with the cubic toy dataset, benchmark UCI, weather forecast with time series, and depth estimation under real-world shifted applications. We show that Density-Regression has competitive uncertainty estimation performance under distribution shifts with modern deep regressors while using a lower mode
    
[^28]: 使图像真实的因素是什么？

    What makes an image realistic?

    [https://arxiv.org/abs/2403.04493](https://arxiv.org/abs/2403.04493)

    论文讨论了如何设计能够可靠区分真实数据和不真实数据的函数，提出了通用评论者的概念作为一个新的解决方案。

    

    在过去的十年里，我们在生成看起来真实的数据方面取得了巨大进展，无论是图像、文本、音频还是视频。在这里，我们讨论了与之密切相关的问题，即量化现实主义，即设计能够可靠地区分真实数据和不真实数据的函数。从算法信息理论的观点出发，我们讨论了为什么这个问题很具挑战性，为什么一个好的生成模型单独不能解决它，以及一个好的解决方案应该是什么样的。特别是，我们引入了通用评论者的概念，不像对抗性评论者那样需要对抗性训练。尽管通用评论者并不立即实用，但它们既可以作为引导实际实现的北极星，也可以作为一个工具。

    arXiv:2403.04493v1 Announce Type: new  Abstract: The last decade has seen tremendous progress in our ability to generate realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of quantifying realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be significantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufficient to solve it, and what a good solution would look like. In particular, we introduce the notion of a universal critic, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool 
    
[^29]: 深度学习的假设空间

    Hypothesis Spaces for Deep Learning

    [https://arxiv.org/abs/2403.03353](https://arxiv.org/abs/2403.03353)

    本文介绍了一种应用深度神经网络的深度学习假设空间，并构建了一个再生核Banach空间，研究了正则化学习和最小插值问题，证明了学习模型的解可以表示为线性组合。

    

    本文介绍了一种应用深度神经网络（DNNs）的深度学习假设空间。通过将DNN视为两个变量的函数，即物理变量和参数变量，我们考虑了DNNs的原始集合，参数变量位于由DNNs的权重矩阵和偏置决定的一组深度和宽度中。然后在弱*拓扑中完成原始DNN集合的线性跨度，以构建一个物理变量函数的Banach空间。我们证明所构造的Banach空间是一个再生核Banach空间（RKBS），并构造其再生核。通过为学习模型的解建立表达定理，我们研究了两个学习模型，正则化学习和最小插值问题在结果RKBS中。表达定理揭示了这些学习模型的解可以表示为线性组合

    arXiv:2403.03353v1 Announce Type: cross  Abstract: This paper introduces a hypothesis space for deep learning that employs deep neural networks (DNNs). By treating a DNN as a function of two variables, the physical variable and parameter variable, we consider the primitive set of the DNNs for the parameter variable located in a set of the weight matrices and biases determined by a prescribed depth and widths of the DNNs. We then complete the linear span of the primitive DNN set in a weak* topology to construct a Banach space of functions of the physical variable. We prove that the Banach space so constructed is a reproducing kernel Banach space (RKBS) and construct its reproducing kernel. We investigate two learning models, regularized learning and minimum interpolation problem in the resulting RKBS, by establishing representer theorems for solutions of the learning models. The representer theorems unfold that solutions of these learning models can be expressed as linear combination of
    
[^30]: 通过锚多元分析改善泛化能力

    Improving generalisation via anchor multivariate analysis

    [https://arxiv.org/abs/2403.01865](https://arxiv.org/abs/2403.01865)

    引入因果正则化扩展到锚回归（AR）中，提出了与锚框架相匹配的损失函数确保稳健性，各种多元分析算法均在锚框架内，简单正则化增强了OOD设置中的稳健性，验证了锚正则化的多功能性和对因果推断方法论的推进。

    

    我们在锚回归（AR）中引入因果正则化扩展，以改善超出分布（OOD）的泛化能力。我们提出了与锚框架相匹配的损失函数，以确保对分布转移的稳健性。各种多元分析（MVA）算法，如（正交化）PLS、RRR和MLR，均在锚框架内。我们观察到简单的正则化增强了OOD设置中的稳健性。在合成和真实的气候科学问题中，为所选算法提供了估计器，展示了其一致性和有效性。经验验证突显了锚正则化的多功能性，强调其与MVA方法的兼容性，并强调其在增强可复制性的同时抵御分布转移中的作用。扩展的AR框架推进了因果推断方法论，解决了可靠OOD泛化的需求。

    arXiv:2403.01865v1 Announce Type: cross  Abstract: We introduce a causal regularisation extension to anchor regression (AR) for improved out-of-distribution (OOD) generalisation. We present anchor-compatible losses, aligning with the anchor framework to ensure robustness against distribution shifts. Various multivariate analysis (MVA) algorithms, such as (Orthonormalized) PLS, RRR, and MLR, fall within the anchor framework. We observe that simple regularisation enhances robustness in OOD settings. Estimators for selected algorithms are provided, showcasing consistency and efficacy in synthetic and real-world climate science problems. The empirical validation highlights the versatility of anchor regularisation, emphasizing its compatibility with MVA approaches and its role in enhancing replicability while guarding against distribution shifts. The extended AR framework advances causal inference methodologies, addressing the need for reliable OOD generalisation.
    
[^31]: 自适应学习率的FTRL算法的竞争比分析和最佳方案研究

    Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive Ratio Analysis and Best-of-Both-Worlds

    [https://arxiv.org/abs/2403.00715](https://arxiv.org/abs/2403.00715)

    通过引入竞争分析框架，我们提出了调整FTRL学习率的更新规则，使其在常数因子内达到最佳竞争比，并且展示了当惩罚项具有近似单调性时的竞争比特性。

    

    Follow-The-Regularized-Leader (FTRL)被认为是在线学习中一种有效且多功能的方法，其中学习率的恰当选择对于减小后悔是至关重要的。为此，我们将调整FTRL学习率的问题构建为一个顺序决策问题，并引入竞争分析框架。我们建立了竞争比的下界，并提出了学习率的更新规则，使其在一个常数因子内达到下界的上界。具体地，我们说明了最优竞争比是由惩罚项的组成部分的（近似）单调性所决定的，表明如果惩罚项的组成部分形成单调非增序列，则可以实现常数竞争比，并推导出了在惩罚项$\xi$近似单调非增时的紧密竞争比。我们提出的更新规则被称为...

    arXiv:2403.00715v1 Announce Type: new  Abstract: Follow-The-Regularized-Leader (FTRL) is known as an effective and versatile approach in online learning, where appropriate choice of the learning rate is crucial for smaller regret. To this end, we formulate the problem of adjusting FTRL's learning rate as a sequential decision-making problem and introduce the framework of competitive analysis. We establish a lower bound for the competitive ratio and propose update rules for learning rate that achieves an upper bound within a constant factor of this lower bound. Specifically, we illustrate that the optimal competitive ratio is characterized by the (approximate) monotonicity of components of the penalty term, showing that a constant competitive ratio is achievable if the components of the penalty term form a monotonically non-increasing sequence, and derive a tight competitive ratio when penalty terms are $\xi$-approximately monotone non-increasing. Our proposed update rule, referred to a
    
[^32]: 半监督 U-统计量

    Semi-Supervised U-statistics

    [https://arxiv.org/abs/2402.18921](https://arxiv.org/abs/2402.18921)

    介绍了一种半监督 U-统计量，利用大量未标记数据，获得了渐近正态分布的性质，并通过有效整合各种强大预测工具实现了明显的效率提升。

    

    arXiv:2402.18921v1 通报类型: 跨领域  摘要: 半监督数据集在多个领域中普遍存在，其中获得完全标记数据成本高昂或耗时。这类数据集的普遍存在一直推动着对利用未标记数据潜力的新工具和方法的需求。为了满足这种需求，我们介绍了受益于大量未标记数据的半监督 U-统计量，并研究了它们的统计特性。我们展示了所提出的方法渐近地服从正态分布，并且通过有效地将各种强大的预测工具整合到框架中，获得了明显的效率提升，超过了经典 U-统计量。为了理解问题的根本困难，我们在半监督设置中推导了极小极大下界，并展示了在正则条件下我们的过程是半参数有效的。此外，针对双变量核函数，我们提出了一种优化的方法，胜过了经典的 U-统计量。

    arXiv:2402.18921v1 Announce Type: cross  Abstract: Semi-supervised datasets are ubiquitous across diverse domains where obtaining fully labeled data is costly or time-consuming. The prevalence of such datasets has consistently driven the demand for new tools and methods that exploit the potential of unlabeled data. Responding to this demand, we introduce semi-supervised U-statistics enhanced by the abundance of unlabeled data, and investigate their statistical properties. We show that the proposed approach is asymptotically Normal and exhibits notable efficiency gains over classical U-statistics by effectively integrating various powerful prediction tools into the framework. To understand the fundamental difficulty of the problem, we derive minimax lower bounds in semi-supervised settings and showcase that our procedure is semi-parametrically efficient under regularity conditions. Moreover, tailored to bivariate kernels, we propose a refined approach that outperforms the classical U-st
    
[^33]: MIM-Reasoner: 具有理论保证的多重影响最大化学习

    MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization

    [https://arxiv.org/abs/2402.16898](https://arxiv.org/abs/2402.16898)

    引入了MIM-Reasoner，结合强化学习和概率图模型，有效地捕捉了给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。

    

    多重影响最大化（MIM）要求我们识别一组种子用户，以最大化多重网络中受影响用户的预期数量。本文介绍了MIM-Reasoner，将强化学习与概率图模型相结合，有效捕捉给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。

    arXiv:2402.16898v1 Announce Type: cross  Abstract: Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as w
    
[^34]: 量子神经网络频谱的光谱不变性和极大性质

    Spectral invariance and maximality properties of the frequency spectrum of quantum neural networks

    [https://arxiv.org/abs/2402.14515](https://arxiv.org/abs/2402.14515)

    量子神经网络研究了频谱的极大性质，证明了在一类模型中存在极大结果，以及在一些条件下存在保持频谱的光谱不变性，解释了文献中观察到的结果对称性。

    

    量子神经网络（QNNs）是量子机器学习领域的热门方法，由于其与变分量子电路的密切联系，使其成为在噪声中间尺度量子（NISQ）设备上进行实际应用的有前途的候选方法。QNN可以表示为有限傅里叶级数，其中频率集被称为频谱。我们分析了这个频谱并证明，对于一大类模型，存在各种极大性结果。此外，我们证明在一些温和条件下，存在一个保持频谱的具有相同面积$A = RL$的模型类之间的双射，其中$R$表示量子比特数量，$L$表示层数，我们因此称之为面积保持变换下的光谱不变性。通过这个，我们解释了文献中经常观察到的在结果中$R$和$L$的对称性，并展示了最大频谱的依赖性

    arXiv:2402.14515v1 Announce Type: cross  Abstract: Quantum Neural Networks (QNNs) are a popular approach in Quantum Machine Learning due to their close connection to Variational Quantum Circuits, making them a promising candidate for practical applications on Noisy Intermediate-Scale Quantum (NISQ) devices. A QNN can be expressed as a finite Fourier series, where the set of frequencies is called the frequency spectrum. We analyse this frequency spectrum and prove, for a large class of models, various maximality results. Furthermore, we prove that under some mild conditions there exists a bijection between classes of models with the same area $A = RL$ that preserves the frequency spectrum, where $R$ denotes the number of qubits and $L$ the number of layers, which we consequently call spectral invariance under area-preserving transformations. With this we explain the symmetry in $R$ and $L$ in the results often observed in the literature and show that the maximal frequency spectrum depen
    
[^35]: 无需稀疏模型的稀疏且准确的解释

    Sparse and Faithful Explanations Without Sparse Models

    [https://arxiv.org/abs/2402.09702](https://arxiv.org/abs/2402.09702)

    引入了稀疏解释值(SEV)，用于衡量机器学习模型的决策稀疏性。即使模型不是稀疏的，许多机器学习模型在SEV的衡量下仍具有低决策稀疏性。

    

    即使模型不满足全局的稀疏性，决策仍然可以用少量的特征准确地描述。例如，对于某人而言，尽管没有信用历史，但申请大笔贷款可能会被拒绝，这就忽视了与其信用价值相关的任何证据。在本论文中，我们引入了稀疏解释值（SEV），这是一种衡量机器学习模型稀疏性的新方法。在以上贷款拒绝的例子中，SEV为1，因为只需要一个因素来解释为什么贷款被拒绝。SEV是对决策稀疏性的衡量，而不是对整体模型稀疏性的衡量，并且我们能够证明许多机器学习模型——即使它们不是稀疏的——实际上在SEV的衡量下具有低决策稀疏性。SEV使用超立方体上的移动进行定义，使得SEV能够在各种模型类别上一致地定义，其中移动限制反映了模型的性质。

    arXiv:2402.09702v1 Announce Type: new  Abstract: Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models -- even if they are not sparse -- actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflectin
    
[^36]: 使用次要结果融合个体化治疗规则

    Fusing Individualized Treatment Rules Using Secondary Outcomes

    [https://arxiv.org/abs/2402.08828](https://arxiv.org/abs/2402.08828)

    该论文提出了一种新方法，通过融合次要结果来学习个体化治疗规则(ITR)，既最大化主要结果的价值函数，又尽可能接近次要结果的最优规则。

    

    个体化治疗规则(ITR)是根据患者个体特征变量推荐治疗方案的决策规则。在许多实践中，理想的主要结果的ITR还预计对其他次要结果造成最小的危害。因此，我们的目标是学习一种ITR，它不仅最大化主要结果的价值函数，还尽可能地接近次要结果的最优规则。为了实现这个目标，我们引入了融合惩罚，鼓励基于不同结果的ITR产生类似的推荐。我们提出了两种使用替代损失函数估计ITR的算法。我们证明了主要结果的估计ITR与次要结果的最优ITR之间的一致率收敛比没有考虑次要结果时更快。此外，我们推导出了...

    arXiv:2402.08828v1 Announce Type: cross Abstract: An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the
    
[^37]: 采用分割引导扩散模型的解剖可控医学图像生成

    Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models

    [https://arxiv.org/abs/2402.05210](https://arxiv.org/abs/2402.05210)

    这篇论文提出了一种采用分割引导扩散模型的解剖可控医学图像生成方法，通过随机掩模消融训练算法实现对解剖约束的条件化，同时提高了网络对解剖真实性的学习能力。

    

    扩散模型已经实现了非常高质量的医学图像生成，可以通过为小型或不平衡的数据集提供补充，从而帮助减轻获取和注释新图像的费用，同时还可以应用于其他方面。然而，这些模型在生成图像时面临着全局解剖真实性的挑战。因此，我们提出了一种解剖可控的医学图像生成模型。我们的模型在每个采样步骤中遵循多类解剖分割掩模，并采用随机掩模消融训练算法，以实现对所选解剖约束的条件化，同时允许其他解剖区域的灵活性。这也改善了网络在完全无条件（无约束生成）情况下对解剖真实性的学习。通过对乳腺MRI和腹部/颈部到盆腔CT数据集的比较评估，证明了我们模型在解剖真实性和输入掩模保真度方面具有优越性。

    Diffusion models have enabled remarkably high-quality medical image generation, which can help mitigate the expenses of acquiring and annotating new images by supplementing small or imbalanced datasets, along with other applications. However, these are hampered by the challenge of enforcing global anatomical realism in generated images. To this end, we propose a diffusion model for anatomically-controlled medical image generation. Our model follows a multi-class anatomical segmentation mask at each sampling step and incorporates a \textit{random mask ablation} training algorithm, to enable conditioning on a selected combination of anatomical constraints while allowing flexibility in other anatomical areas. This also improves the network's learning of anatomical realism for the completely unconditional (unconstrained generation) case. Comparative evaluation on breast MRI and abdominal/neck-to-pelvis CT datasets demonstrates superior anatomical realism and input mask faithfulness over st
    
[^38]: 在再生核希尔伯特空间中的Moreau包络的f-差异的Wasserstein梯度流

    Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces

    [https://arxiv.org/abs/2402.04613](https://arxiv.org/abs/2402.04613)

    本文研究了在再生核希尔伯特空间中使用Moreau包络来对测度f-差异进行正则化的方法，并利用该方法分析了Wasserstein梯度流。

    

    大多数常用的测度f-差异，例如Kullback-Leibler差异，对于所涉及的测度的支持存在限制。解决办法是通过与特征核K相关的平方最大均值差异(MMD)对f-差异进行正则化。在本文中，我们使用所谓的核均值嵌入来显示相应的正则化可以重写为与K相关的再生核希尔伯特空间中某些函数的Moreau包络。然后，我们利用关于希尔伯特空间中Moreau包络的众所周知的结果来证明MMD正则化的f-差异及其梯度的属性。随后，我们使用我们的研究结果来分析受MMD正则化的f-差异的Wasserstein梯度流。最后，我们考虑从经验测度开始的Wasserstein梯度流，并提供使用Tsallis-$\alpha$差异的概念性数值示例的证明。

    Most commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy consists of regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. In this paper, we use the so-called kernel mean embedding to show that the corresponding regularization can be rewritten as the Moreau envelope of some function in the reproducing kernel Hilbert space associated with $K$. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to prove properties of the MMD-regularized $f$-divergences and, in particular, their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. Finally, we consider Wasserstein gradient flows starting from empirical measures and provide proof-of-the-concept numerical examples with Tsallis-$\alpha$ divergences.
    
[^39]: 带有切片Wasserstein Weisfeiler-Lehman图核的高斯过程回归

    Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels

    [https://arxiv.org/abs/2402.03838](https://arxiv.org/abs/2402.03838)

    本研究提出了一种带有切片Wasserstein Weisfeiler-Lehman图核的高斯过程回归方法，在处理大规模稀疏图形数据集时具有正定性和显著的复杂度降低。

    

    监督学习在计算物理领域引起了广泛关注，因为它能够有效地提取复杂模式，用于解决偏微分方程或预测材料性质等任务。传统上，这类数据集由具有大量节点的网格表示的输入（视为图形）和使用数值求解器获得的相应输出组成。这意味着监督学习模型必须能够处理具有连续节点属性的大规模稀疏图形。在本研究中，我们专注于高斯过程回归，引入了切片Wasserstein Weisfeiler-Lehman（SWWL）图核。与现有的图核相比，所提出的SWWL核具有正定性和显著的复杂度降低，使其能够处理此前不可处理的数据集。新的核首先在分子图分类中进行了验证。

    Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which  makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molec
    
[^40]: 具有偏倧的非响应问题的主动学习

    Active learning with biased non-response to label requests

    [https://arxiv.org/abs/2312.08150](https://arxiv.org/abs/2312.08150)

    偏倧的非响应对主动学习模型性能有害，我们提出了一种成本-based 修正策略来减轻其影响，并通过实验证明其在许多情况下有效。

    

    主动学习可以通过识别获取最具信息量的新标签来提高训练预测模型的效率。然而，在标签请求的非响应情况下，会影响主动学习在实际环境中的有效性。我们通过考虑数据中存在的非响应类型来概念化这种退化，证明偏倧的非响应对模型性能特别有害。我们认为，在标签过程天然依赖用户交互的环境中，偏倧的非响应很可能会出现。为了减轻偏倧的非响应影响，我们提出了一种基于成本的修正采样策略——预期效用的上界置信度（UCB-EU）, 这种方法可以合理地应用于任何主动学习算法。通过实验证明，我们的方法成功地减少了在许多场景中标签非响应造成的伤害。

    arXiv:2312.08150v2 Announce Type: replace  Abstract: Active learning can improve the efficiency of training prediction models by identifying the most informative new labels to acquire. However, non-response to label requests can impact active learning's effectiveness in real-world contexts. We conceptualise this degradation by considering the type of non-response present in the data, demonstrating that biased non-response is particularly detrimental to model performance. We argue that biased non-response is likely in contexts where the labelling process, by nature, relies on user interactions. To mitigate the impact of biased non-response, we propose a cost-based correction to the sampling strategy--the Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly, be applied to any active learning algorithm. Through experiments, we demonstrate that our method successfully reduces the harm from labelling non-response in many settings. However, we also characterise settin
    
[^41]: 从异构数据中学习结构因果模型中的未知干预目标

    Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data

    [https://arxiv.org/abs/2312.06091](https://arxiv.org/abs/2312.06091)

    在结构因果模型中，通过两阶段方法学习未知干预目标的外生噪声，并将其与相应的内生变量匹配，有效地识别干预目标。

    

    我们研究了在结构因果模型中识别未知干预目标的问题，其中我们可以访问从多个环境中收集的异构数据。未知干预目标是一组内生变量，其相应的外生噪声在不同环境中发生变化。我们提出了一个两阶段方法，第一阶段中恢复了跨不同环境发生变化的未知干预目标对应的外生噪声。在第二阶段，恢复的噪声与相应的内生变量进行匹配。对于恢复阶段，我们提供了学习这些外生噪声的充分条件，可达到某种分量方向可逆转换。对于匹配阶段，在因果充分性假设下，我们证明了所提方法可以唯一地识别干预目标。

    arXiv:2312.06091v2 Announce Type: replace-cross  Abstract: We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments. The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments. We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments. In the second phase, the recovered noises are matched with the corresponding endogenous variables. For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation. For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets. In the presence of latent confounders, the interv
    
[^42]: 打开黑匣子：利用建筑物理学洞察实现固有可解释的能源数据插补模型

    Opening the Black Box: Towards inherently interpretable energy data imputation models using building physics insight

    [https://arxiv.org/abs/2311.16632](https://arxiv.org/abs/2311.16632)

    提出了利用建筑物理学洞察实现固有可解释的能源数据插补模型PI-DAE，在损失函数中引入物理启发软约束，从而实现更可解释的预测。

    

    缺失数据经常被建筑能源建模领域的实践者和研究人员观察到。在这方面，通常需要先进的数据驱动解决方案，如深度学习方法，以反映这些异常的非线性行为。作为与深度学习相关的一个持续研究问题，可以通过在网络中引入先验知识来探索模型在有限数据设置下的适用性。这种策略也可以导致更可解释的预测，从而促进方法的现场应用。因此，本文旨在提出物理启发型去噪自动编码器(PI-DAE)用于商业建筑的缺失数据插补。具体而言，所提出的方法将物理启发软约束强加给去噪自动编码器(DAE)的损失函数。为了量化物理组件的好处，进行了一项消融实验。

    arXiv:2311.16632v2 Announce Type: replace-cross  Abstract: Missing data are frequently observed by practitioners and researchers in the building energy modeling community. In this regard, advanced data-driven solutions, such as Deep Learning methods, are typically required to reflect the non-linear behavior of these anomalies. As an ongoing research question related to Deep Learning, a model's applicability to limited data settings can be explored by introducing prior knowledge in the network. This same strategy can also lead to more interpretable predictions, hence facilitating the field application of the approach. For that purpose, the aim of this paper is to propose the use of Physics-informed Denoising Autoencoders (PI-DAE) for missing data imputation in commercial buildings. In particular, the presented method enforces physics-inspired soft constraints to the loss function of a Denoising Autoencoder (DAE). In order to quantify the benefits of the physical component, an ablation s
    
[^43]: 基于椭圆对称分布混合的最大似然估计和聚类的非参数一致性

    Nonparametric consistency for maximum likelihood estimation and clustering based on mixtures of elliptically-symmetric distributions

    [https://arxiv.org/abs/2311.06108](https://arxiv.org/abs/2311.06108)

    展示了椭圆对称分布混合的最大似然估计的一致性，为基于非参数分布的聚类提供了理论依据。

    

    该论文展示了椭圆对称分布混合的最大似然估计器对其总体版本的一致性，其中潜在分布P是非参数的，并不一定属于估计器所基于的混合类别。当P是足够分离但非参数的分布混合时，表明了估计器的总体版本的组分对应于P的良好分离组分。这为在P具有良好分离子总体的情况下使用这样的估计器进行聚类分析提供了一些理论上的理据，即使这些子总体与混合模型所假设的不同。

    arXiv:2311.06108v2 Announce Type: replace-cross  Abstract: The consistency of the maximum likelihood estimator for mixtures of elliptically-symmetric distributions for estimating its population version is shown, where the underlying distribution $P$ is nonparametric and does not necessarily belong to the class of mixtures on which the estimator is based. In a situation where $P$ is a mixture of well enough separated but nonparametric distributions it is shown that the components of the population version of the estimator correspond to the well separated components of $P$. This provides some theoretical justification for the use of such estimators for cluster analysis in case that $P$ has well separated subpopulations even if these subpopulations differ from what the mixture model assumes.
    
[^44]: 公平受监督学习中具有敏感属性的简单随机采样器

    Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes

    [https://arxiv.org/abs/2311.05866](https://arxiv.org/abs/2311.05866)

    提出了一种公平受监督学习的方法，利用简单随机采样器处理敏感属性，可以更广泛地适用于实践中，并构建了一个计算效率高的群体级别处理公平感知的训练框架。

    

    随着数据驱动的决策过程在工业应用中变得主导，各个领域对具有公平意识的机器学习引起了极大关注。本研究提出了利用敏感属性的简单随机采样器学习公平惩罚的神经网络方法，用于非歧视性受监督学习。与许多现有作品基本依赖于敏感属性和响应变量的离散性不同，所提出的惩罚能够处理多种格式的敏感属性，因此在实践中比许多现有算法更具广泛适用性。该惩罚使我们能够构建一个计算效率高的群体级别处理公平感知的训练框架。实证证据表明，我们的框架在流行的基准数据集上比竞争方法具有更好的效用和公平度量。我们还在理论上对估计误差和损失进行了表征。

    arXiv:2311.05866v2 Announce Type: replace-cross  Abstract: As the data-driven decision process becomes dominating for industrial applications, fairness-aware machine learning arouses great attention in various areas. This work proposes fairness penalties learned by neural networks with a simple random sampler of sensitive attributes for non-discriminatory supervised learning. In contrast to many existing works that critically rely on the discreteness of sensitive attributes and response variables, the proposed penalty is able to handle versatile formats of the sensitive attributes, so it is more extensively applicable in practice than many existing algorithms. This penalty enables us to build a computationally efficient group-level in-processing fairness-aware training framework. Empirical evidence shows that our framework enjoys better utility and fairness measures on popular benchmark data sets than competing methods. We also theoretically characterize estimation errors and loss of u
    
[^45]: 权重共享正则化

    Weight-Sharing Regularization

    [https://arxiv.org/abs/2311.03096](https://arxiv.org/abs/2311.03096)

    提出了一种权重共享正则化方法，通过引入对神经网络权重的惩罚，设计并实现了一个新型并行算法，使网络能够学习卷积样式的滤波器

    

    在深度学习中，权重共享是无处不在的。受此启发，我们提出了对神经网络的权重$w \in \mathbb{R}^d$进行“权重共享正则化”惩罚，定义为$\mathcal{R}(w) = \frac{1}{d - 1}\sum_{i > j}^d |w_i - w_j|$。我们研究了$\mathcal{R}$的近端映射，并通过一个物理粒子相互作用的系统对其进行了直观解释。我们还并行化了现有的$\operatorname{prox}_\mathcal{R}$算法（在GPU上运行），并发现其中一种在实践中快速，但对于最坏情况输入较慢（$O(d)$）。利用物理解释，我们设计了一种新颖的并行算法，当有足够的处理器可用时，其运行时间为$O(\log^3 d)$，从而保证了快速训练。我们的实验显示，权重共享正则化使全连接网络能够学习卷积样式的滤波器，即使像素已被打乱，而卷积神经网

    arXiv:2311.03096v2 Announce Type: replace  Abstract: Weight-sharing is ubiquitous in deep learning. Motivated by this, we propose a "weight-sharing regularization" penalty on the weights $w \in \mathbb{R}^d$ of a neural network, defined as $\mathcal{R}(w) = \frac{1}{d - 1}\sum_{i > j}^d |w_i - w_j|$. We study the proximal mapping of $\mathcal{R}$ and provide an intuitive interpretation of it in terms of a physical system of interacting particles. We also parallelize existing algorithms for $\operatorname{prox}_\mathcal{R}$ (to run on GPU) and find that one of them is fast in practice but slow ($O(d)$) for worst-case inputs. Using the physical interpretation, we design a novel parallel algorithm which runs in $O(\log^3 d)$ when sufficient processors are available, thus guaranteeing fast training. Our experiments reveal that weight-sharing regularization enables fully connected networks to learn convolution-like filters even when pixels have been shuffled while convolutional neural netwo
    
[^46]: 基于非共享多中心数据集的贝叶斯联合推断用于估计统计模型

    Bayesian Federated Inference for estimating Statistical Models based on Non-shared Multicenter Data sets

    [https://arxiv.org/abs/2302.07677](https://arxiv.org/abs/2302.07677)

    本文提出了一种用于估计统计模型的替代性贝叶斯联合推断（BFI）框架，旨在处理数据集较小的情况，并能够获取更大数据集的统计能力。

    

    通过多变量分析识别目标结果的预测因素在数据集较小时往往很困难。将来自不同医疗中心的数据合并到一个（更大）数据库中将缓解这个问题，但实际上由于监管和物流问题而具有挑战性。联邦学习（FL）是一种机器学习方法，旨在从不同数据中心的本地推断构建出数据集合并后将会推断出的内容。它旨在获取更大数据集的统计能力，而实际上并未创建它们。FL策略并非总是高效和精确。因此，在本文中，我们完善并实施了一种用于具有相同目的的多中心数据的替代性贝叶斯联合推断（BFI）框架。BFI框架旨在通过在本地推断不仅最佳参数值，还另外一些内容来处理数据集较小的情况。

    arXiv:2302.07677v2 Announce Type: replace-cross  Abstract: Identifying predictive factors for an outcome of interest via a multivariable analysis is often difficult when the data set is small. Combining data from different medical centers into a single (larger) database would alleviate this problem, but is in practice challenging due to regulatory and logistic problems. Federated Learning (FL) is a machine learning approach that aims to construct from local inferences in separate data centers what would have been inferred had the data sets been merged. It seeks to harvest the statistical power of larger data sets without actually creating them. The FL strategy is not always efficient and precise. Therefore, in this paper we refine and implement an alternative Bayesian Federated Inference (BFI) framework for multicenter data with the same aim as FL. The BFI framework is designed to cope with small data sets by inferring locally not only the optimal parameter values, but also additional 
    
[^47]: 您的模型是在预测过去吗？

    Is your model predicting the past?

    [https://arxiv.org/abs/2206.11673](https://arxiv.org/abs/2206.11673)

    提出了区分机器学习模型是预测个体未来还是重复过去模式的方法，通过向后基线测试展示模型是否回溯过去，并在长期面板调研任务中验证了该框架的有效性。

    

    机器学习模型何时预测个体的未来，何时重复预先存在的模式？在这项工作中，我们提出了对这两种预测路径进行区分，这一提议得到了理论、经验和规范性论证的支持。我们提出的核心是一类简单高效的统计测试，称为“向后基线”，可以展示模型是否以及在何种程度上重新讲述了过去。我们的统计理论为解释向后基线提供了指导，并建立了不同基线和熟悉统计概念之间的等价关系。具体而言，我们推导了一个有意义的向后基线，可以对预测系统进行审计，即使只提供了背景变量和系统的预测。在经验上，我们在从纵向面板调查中衍生出的不同预测任务上评估了该框架，展示了将其纳入的便捷性和有效性。

    arXiv:2206.11673v2 Announce Type: replace  Abstract: When does a machine learning model predict the future of individuals and when does it recite patterns that predate the individuals? In this work, we propose a distinction between these two pathways of prediction, supported by theoretical, empirical, and normative arguments. At the center of our proposal is a family of simple and efficient statistical tests, called backward baselines, that demonstrate if, and to what extent, a model recounts the past. Our statistical theory provides guidance for interpreting backward baselines, establishing equivalences between different baselines and familiar statistical concepts. Concretely, we derive a meaningful backward baseline for auditing a prediction system as a black box, given only background variables and the system's predictions. Empirically, we evaluate the framework on different prediction tasks derived from longitudinal panel surveys, demonstrating the ease and effectiveness of incorpo
    
[^48]: 针对正负样本学习的不确定性感知伪标签选择

    Uncertainty-aware Pseudo-label Selection for Positive-Unlabeled Learning

    [https://arxiv.org/abs/2201.13192](https://arxiv.org/abs/2201.13192)

    通过不确定性感知的伪标签选择过程，本研究提出了一种解决正负样本学习中不平衡数据集和模型校准问题的方法，实验结果表明在高度不平衡的情况下能显著提高预测性能。

    

    正负样本学习（PUL）旨在从仅具有正样本和未标记训练数据中学习二元分类器。尽管现实应用通常涉及不平衡数据集，其中大多数示例属于一类，但大多数当代PUL方法并未研究这种情况下的性能，因此严重限制了它们在实践中的适用性。在这项工作中，我们通过一种不确定性感知的伪标签选择过程（PUUPL）来解决不平衡数据集和模型校准问题：通过增强少数类的信号，伪标签从未标记集中扩展了带标签的数据集，而显式的不确定性量化防止了有害的确认偏见的出现，从而提高了预测性能。通过一系列实验，PUUPL在高度不平衡的情况下取得了显著的性能提升。

    arXiv:2201.13192v3 Announce Type: replace-cross  Abstract: Positive-unlabeled learning (PUL) aims at learning a binary classifier from only positive and unlabeled training data. Even though real-world applications often involve imbalanced datasets where the majority of examples belong to one class, most contemporary approaches to PUL do not investigate performance in this setting, thus severely limiting their applicability in practice. In this work, we thus propose to tackle the issues of imbalanced datasets and model calibration in a PUL setting through an uncertainty-aware pseudo-labeling procedure (PUUPL): by boosting the signal from the minority class, pseudo-labeling expands the labeled dataset with new samples from the unlabeled set, while explicit uncertainty quantification prevents the emergence of harmful confirmation bias leading to increased predictive performance. Within a series of experiments, PUUPL yields substantial performance gains in highly imbalanced settings while 
    
[^49]: 嵌套非参数工具变量回归：长期、中介和时变治疗效应

    Nested Nonparametric Instrumental Variable Regression: Long Term, Mediated, and Time Varying Treatment Effects

    [https://arxiv.org/abs/2112.14249](https://arxiv.org/abs/2112.14249)

    该论文提出了嵌套非参数工具变量回归的对抗估计器，并提供了对因果参数进行有效推断的充分条件，具有限制病态性复合技术、多种适应模型和扩展到因果函数等特征。

    

    短面板数据模型中的几个因果参数是称为嵌套非参数工具变量回归（nested NPIV）的函数的标量总结。例如，使用代理变量识别出长期、中介和时变治疗效应。然而，似乎不存在关于嵌套NPIV的先前估计量或保证，这样就无法灵活地估计和推断这些因果参数。一个主要挑战是由于嵌套逆问题而导致的复合病态性。我们分析了嵌套NPIV的对抗估计器，并提供了对因果参数进行有效推断的充分条件。我们的非渐近分析具有三个显著特征：（i）引入限制病态性复合的技术；（ii）适应神经网络、随机森林和再生核希尔伯特空间；（iii）扩展到因果函数，例如长期异质治疗效果。

    arXiv:2112.14249v3 Announce Type: replace-cross  Abstract: Several causal parameters in short panel data models are scalar summaries of a function called a nested nonparametric instrumental variable regression (nested NPIV). Examples include long term, mediated, and time varying treatment effects identified using proxy variables. However, it appears that no prior estimators or guarantees for nested NPIV exist, preventing flexible estimation and inference for these causal parameters. A major challenge is compounding ill posedness due to the nested inverse problems. We analyze adversarial estimators of nested NPIV, and provide sufficient conditions for efficient inference on the causal parameter. Our nonasymptotic analysis has three salient features: (i) introducing techniques that limit how ill posedness compounds; (ii) accommodating neural networks, random forests, and reproducing kernel Hilbert spaces; and (iii) extending to causal functions, e.g. long term heterogeneous treatment eff
    
[^50]: 上限反事实置信区间：一种面向上下文赌博的新乐观原则

    Upper Counterfactual Confidence Bounds: a New Optimism Principle for Contextual Bandits

    [https://arxiv.org/abs/2007.07876](https://arxiv.org/abs/2007.07876)

    本文提出的“上限反事实置信区间”（UCCB）是针对一般上下文赌博设计乐观算法的新原则，通过在策略空间中构建置信区间，而非像UCB那样在行动空间中，这使得算法在处理一般函数类和大上下文空间时均具有优越性。

    

    乐观原则面对不确定性是多臂赌博和强化学习中最广泛使用和成功的理念之一。然而，现有的乐观算法（主要是UCB及其变种）通常无法处理一般的函数类和大的上下文空间。本文研究了具有离线回归预言机的一般上下文赌博，并提出了一种简单的通用原则来设计乐观算法，称为“上限反事实置信区间”（UCCB）。UCCB的关键创新是在策略空间中建立置信区间，而不是像UCB那样在行动空间中。我们证明了这些算法在处理一般函数类和大上下文空间方面既是可证明的最优的，又在计算上是高效的。此外，我们证明了UCCB原则可以轻松地扩展到无限动作的一般上下文赌博，并提供了第一个解决方案。

    arXiv:2007.07876v4 Announce Type: replace  Abstract: The principle of optimism in the face of uncertainty is one of the most widely used and successful ideas in multi-armed bandits and reinforcement learning. However, existing optimistic algorithms (primarily UCB and its variants) often struggle to deal with general function classes and large context spaces. In this paper, we study general contextual bandits with an offline regression oracle and propose a simple, generic principle to design optimistic algorithms, dubbed "Upper Counterfactual Confidence Bounds" (UCCB). The key innovation of UCCB is building confidence bounds in policy space, rather than in action space as is done in UCB. We demonstrate that these algorithms are provably optimal and computationally efficient in handling general function classes and large context spaces. Furthermore, we illustrate that the UCCB principle can be seamlessly extended to infinite-action general contextual bandits, provide the first solutions 
    
[^51]: 通过保持结构的干预来量化固有因果贡献

    Quantifying intrinsic causal contributions via structure preserving interventions

    [https://arxiv.org/abs/2007.00714](https://arxiv.org/abs/2007.00714)

    该论文提出一种通过结构保持干预来量化节点对目标节点的固有因果贡献的方法，从而将因果信息与祖先节点信息分离，并提出了对方差和熵的贡献分析。

    

    我们提出了一种描述有向无环图中一个节点对目标节点的“固有”贡献部分的因果影响概念。通过将每个节点递归地写成上游噪声项的函数，我们将每个节点添加的固有信息与从祖先节点获得的信息分开。为了将固有信息解释为“因果”贡献，我们考虑了“保持结构的干预”，这些干预以一种模拟对父节点的通常依赖关系并且不扰乱观察到的联合分布的方式随机化每个节点。为了获得一个对重新标记节点不变的测量，我们使用基于Shapley的对称化，并且表明在线性情况下，在将目标节点解析为噪声变量后，它化简为简单的ANOVA。我们描述了方差和熵的贡献分析，但其他目标度量的贡献可以类似地定义。代码可在...

    arXiv:2007.00714v4 Announce Type: replace  Abstract: We propose a notion of causal influence that describes the `intrinsic' part of the contribution of a node on a target node in a DAG. By recursively writing each node as a function of the upstream noise terms, we separate the intrinsic information added by each node from the one obtained from its ancestors. To interpret the intrinsic information as a {\it causal} contribution, we consider `structure-preserving interventions' that randomize each node in a way that mimics the usual dependence on the parents and does not perturb the observed joint distribution. To get a measure that is invariant with respect to relabelling nodes we use Shapley based symmetrization and show that it reduces in the linear case to simple ANOVA after resolving the target node into noise variables. We describe our contribution analysis for variance and entropy, but contributions for other target metrics can be defined analogously. The code is available in the 
    
[^52]: NeurAll: 面向自动驾驶的统一视觉感知模型

    NeurAll: Towards a Unified Visual Perception Model for Automated Driving

    [https://arxiv.org/abs/1902.03589](https://arxiv.org/abs/1902.03589)

    本文提出了一种联合多任务网络设计，以实现在自动驾驶中的视觉感知任务中共享计算资源，从而提高计算效率并提供更好的泛化能力。

    

    卷积神经网络（CNNs）被成功应用于重要的汽车视觉感知任务，包括目标识别、运动和深度估计、视觉SLAM等。然而，这些任务通常是独立探索和建模的。本文提出了一种联合多任务网络设计，同时学习多个任务。我们的主要动机是通过在所有任务之间共享昂贵的初始卷积层来实现计算效率。事实上，自动驾驶系统中的主要瓶颈是部署硬件上可用的有限处理能力。还有一些证据表明，对于某些任务来说，在提高准确性方面存在其他好处，并且可以减轻开发工作量。它还提供了可伸缩性，可以通过利用现有特征增加更多任务，并实现更好的泛化。我们调查了自动驾驶中用于视觉感知任务的各种基于CNN的解决方案。

    arXiv:1902.03589v3 Announce Type: replace-cross  Abstract: Convolutional Neural Networks (CNNs) are successfully used for the important automotive visual perception tasks including object recognition, motion and depth estimation, visual SLAM, etc. However, these tasks are typically independently explored and modeled. In this paper, we propose a joint multi-task network design for learning several tasks simultaneously. Our main motivation is the computational efficiency achieved by sharing the expensive initial convolutional layers between all tasks. Indeed, the main bottleneck in automated driving systems is the limited processing power available on deployment hardware. There is also some evidence for other benefits in improving accuracy for some tasks and easing development effort. It also offers scalability to add more tasks leveraging existing features and achieving better generalization. We survey various CNN based solutions for visual perception tasks in automated driving. Then we
    
[^53]: 一种用于双语词典归纳的判别式潜变量模型

    A Discriminative Latent-Variable Model for Bilingual Lexicon Induction

    [https://arxiv.org/abs/1808.09334](https://arxiv.org/abs/1808.09334)

    引入判别式潜变量模型，结合先前研究的词典先验和表示法，提出了用于双语词典归纳的新方法，并通过实验证据展示先验可以改善诱导的双语词典。

    

    我们引入了一种新颖的用于双语词典归纳的判别式潜变量模型。我们的模型将Haghighi等人（2008）的二分匹配词典先验与基于表示的方法（Artetxe等人，2017）相结合。为了训练模型，我们推导出了高效的Viterbi EM算法。我们在两个度量标准下对六种语言对进行了实证结果，并显示先验改善了诱导的双语词典。我们还演示了如何将先前的工作视为类似风格的潜变量模型，尽管有不同的先验。

    arXiv:1808.09334v3 Announce Type: replace  Abstract: We introduce a novel discriminative latent variable model for bilingual lexicon induction. Our model combines the bipartite matching dictionary prior of Haghighi et al. (2008) with a representation-based approach (Artetxe et al., 2017). To train the model, we derive an efficient Viterbi EM algorithm. We provide empirical results on six language pairs under two metrics and show that the prior improves the induced bilingual lexicons. We also demonstrate how previous work may be viewed as a similarly fashioned latent-variable model, albeit with a different prior.
    
[^54]: 评估女性运动员脑震荡：神经信息学的作用？

    Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?. (arXiv:2401.13045v1 [stat.ML])

    [http://arxiv.org/abs/2401.13045](http://arxiv.org/abs/2401.13045)

    该论文提出了通过神经信息学和机器学习来评估女性运动员脑震荡的方法。相比传统的临床方法，在女性运动员中诊断脑震荡存在一些局限性，而这些新技术可以通过数据分析找出与性别相关的生物机制，从而填补这一差距。

    

    在过去的十年中，女性运动员脑震荡的复杂性变得明显。传统的临床诊断脑震荡的方法在应用于女性运动员时存在局限性，往往无法捕捉到脑结构和功能的细微变化。先进的神经信息学技术和机器学习模型在这方面已经成为宝贵的资产。虽然这些技术在理解男性运动员的脑震荡方面已经被广泛应用，但在我们对于它们对女性运动员的有效性的理解上仍存在显著差距。通过利用机器学习的强大数据分析能力，研究人员可以将观察到的表型神经影像数据联系到特定于性别的生物机制，揭示女性运动员脑震荡的奥秘。此外，嵌入机器学习的方法还可以在研究中进行交叉验证，进一步检验性别差异。

    Over the past decade, the intricacies of sports-related concussions among female athletes have become readily apparent. Traditional clinical methods for diagnosing concussions suffer limitations when applied to female athletes, often failing to capture subtle changes in brain structure and function. Advanced neuroinformatics techniques and machine learning models have become invaluable assets in this endeavor. While these technologies have been extensively employed in understanding concussion in male athletes, there remains a significant gap in our comprehension of their effectiveness for female athletes. With its remarkable data analysis capacity, machine learning offers a promising avenue to bridge this deficit. By harnessing the power of machine learning, researchers can link observed phenotypic neuroimaging data to sex-specific biological mechanisms, unraveling the mysteries of concussions in female athletes. Furthermore, embedding methods within machine learning enable examining b
    
[^55]: 具有固定预算的局部最优最佳臂识别算法

    Locally Optimal Best Arm Identification with a Fixed Budget. (arXiv:2310.19788v1 [math.ST])

    [http://arxiv.org/abs/2310.19788](http://arxiv.org/abs/2310.19788)

    该研究解决了识别具有最高预期效果的治疗方案的问题，并提出了具有固定预算的局部最优算法来降低错误识别的概率。

    

    本研究探讨了识别最佳治疗方案的问题，即具有最高预期效果的治疗方案。我们旨在通过降低错误识别的概率来确定最佳治疗方案，这一问题在许多研究领域中已被探索，包括最佳臂识别（Best Arm Identification，BAI）和序列优化。在我们的实验中，治疗分配的轮数是固定的。在每一轮中，决策者将一种治疗方案分配给一个实验单元，并观察相应的结果，该结果遵循不同治疗方案之间方差不同的高斯分布。在实验结束时，我们根据观察结果推荐一种治疗方案作为最佳治疗方案的估计值。决策者的目标是设计一个实验，使错误识别最佳治疗方案的概率最小化。基于这一目标，我们开发了误识别概率的下界。

    This study investigates the problem of identifying the best treatment arm, a treatment arm with the highest expected outcome. We aim to identify the best treatment arm with a lower probability of misidentification, which has been explored under various names across numerous research fields, including \emph{best arm identification} (BAI) and ordinal optimization. In our experiments, the number of treatment-allocation rounds is fixed. In each round, a decision-maker allocates a treatment arm to an experimental unit and observes a corresponding outcome, which follows a Gaussian distribution with a variance different among treatment arms. At the end of the experiment, we recommend one of the treatment arms as an estimate of the best treatment arm based on the observations. The objective of the decision-maker is to design an experiment that minimizes the probability of misidentifying the best treatment arm. With this objective in mind, we develop lower bounds for the probability of misident
    
[^56]: 通过遗憾到置信集转换改进（多项式）逻辑回归赌博机的遗憾界限

    Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion. (arXiv:2310.18554v1 [stat.ML])

    [http://arxiv.org/abs/2310.18554](http://arxiv.org/abs/2310.18554)

    本论文通过遗憾到置信集转换方法改进了逻辑回归赌博机的遗憾界限，提出了一个基于在线学习算法的凸置信集，并应用于具有新的鞅集中步骤的遗憾分析。

    

    逻辑回归赌博机是建模用户选择的普遍框架，例如广告推荐系统中的点击与否。我们观察到先前的工作忽视或忽略了$S \geq \lVert \theta_\star \rVert_2$中的依赖关系，其中$\theta_\star \in \mathbb{R}^d$是未知的参数向量，当$S$较大时，例如$S \geq d$，这会产生问题。在这项工作中，我们通过一种称为“遗憾到置信集转换（R2CS）”的新方法改善了对$S$的依赖关系，该方法允许我们构建一个基于在线学习算法存在性的凸置信集。使用R2CS，我们在逻辑回归赌博机的遗憾界限方面获得了严格的改进，同时保持了计算可行性和对其他因素（如$d$和$T$）的依赖。我们将我们的新置信集应用于具有新的鞅集中步骤的逻辑回归赌博机的遗憾分析，从而避免了额外的因素。

    Logistic bandit is a ubiquitous framework of modeling users' choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \geq \lVert \theta_\star \rVert_2$, where $\theta_\star \in \mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor
    
[^57]: 使用合成数据扩展提升数据分析

    Boosting Data Analytics With Synthetic Volume Expansion. (arXiv:2310.17848v1 [stat.ML])

    [http://arxiv.org/abs/2310.17848](http://arxiv.org/abs/2310.17848)

    本文介绍了一种利用合成数据生成框架来提升数据分析的方法，在此方法中，使用先进模型生成高逼真度的合成数据，并采用统计方法进行分析。研究发现，在合成数据上的统计方法错误随着合成数据的增加而减少，但最终可能会增加或停滞。

    

    合成数据生成作为生成式人工智能的基石，在解决数据稀缺和隐私问题的同时，实现了前所未有的性能。随着合成数据的日益重要，人们开始关注统计方法在合成数据与原始数据上的准确性。在本文中，我们介绍了用于分析的合成数据生成框架。该框架使用高逼真度的合成数据，通过先进模型如表格扩散和生成式预训练转换器模型生成，并结合相关研究洞察进一步增强。在这个框架中的一个重要发现是生成效应：统计方法在合成数据上的错误随着合成数据的增加一开始减少，但最终可能会增加或停滞。这个现象根源于复制原始数据分布的复杂性。

    Synthetic data generation, a cornerstone of Generative Artificial Intelligence, signifies a paradigm shift in data science by addressing data scarcity and privacy while enabling unprecedented performance. As synthetic data gains prominence, questions arise concerning the accuracy of statistical methods when applied to synthetic data compared to raw data. In this article, we introduce the Synthetic Data Generation for Analytics framework. This framework employs statistical methods on high-fidelity synthetic data generated by advanced models such as tabular diffusion and Generative Pre-trained Transformer models. These models, trained on raw data, are further enhanced with insights from pertinent studies. A significant discovery within this framework is the generational effect: the error of a statistical method on synthetic data initially diminishes with added synthetic data but may eventually increase or plateau. This phenomenon, rooted in the complexities of replicating raw data distri
    
[^58]: 大规模高斯过程通过交替投影

    Large-Scale Gaussian Processes via Alternating Projection. (arXiv:2310.17137v1 [cs.LG])

    [http://arxiv.org/abs/2310.17137](http://arxiv.org/abs/2310.17137)

    本论文提出了一种通过交替投影的迭代方法来解决高斯过程在大规模数据集上的训练问题，并证明了该方法具有线性收敛性。

    

    高斯过程（GP）超参数优化需要反复求解具有 nxn 核矩阵的线性系统。为了解决 O(n^3) 的时间复杂性问题，最近的研究采用了快速迭代数值方法，如共轭梯度（CG）。然而，随着数据集规模的增加，相应的核矩阵变得越来越病态，并且在没有分割的情况下仍然需要 O(n^2) 的空间。因此，虽然 CG 增加了可训练 GP 基于的数据集的大小，但现代数据集已经达到超出其适用范围的规模。在这项工作中，我们提出了一种只访问核矩阵的子块的迭代方法，有效地实现了小批量处理。我们的算法基于交替投影，每次迭代的时间和空间复杂度为 O(n)，解决了将 GP 扩展到非常大的数据集时的许多实际挑战。从理论上讲，我们证明了我们的方法具有线性收敛性，从实证的角度来看，我们证明了

    Gaussian process (GP) hyperparameter optimization requires repeatedly solving linear systems with $n \times n$ kernel matrices. To address the prohibitive $\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative numerical methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the corresponding kernel matrices become increasingly ill-conditioned and still require $\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling \emph{mini-batching}. Our algorithm, based on alternating projection, has $\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove our method enjoys linear convergence and empirically we demons
    
[^59]: Coreset马尔可夫链蒙特卡罗

    Coreset Markov Chain Monte Carlo. (arXiv:2310.17063v1 [stat.CO])

    [http://arxiv.org/abs/2310.17063](http://arxiv.org/abs/2310.17063)

    Coreset MCMC提出了一种新的方法，通过模拟马尔可夫链以更新coreset权重，从而实现在推断过程中降低计算成本的目的。与其他方法相比，Coreset MCMC提供了更高质量的后验近似和更高的采样效率。

    

    贝叶斯coreset是一个小而加权的数据子集，用于在推断过程中替代完整数据集以降低计算成本。然而，目前调整coreset权重的最先进方法耗时昂贵，需要复杂的用户输入，并对模型施加约束。在本文中，我们提出了一种新的方法——Coreset MCMC，该方法模拟了一个马尔可夫链，目标是coreset后验分布，同时使用相同的抽样更新coreset权重。Coreset MCMC易于实施和调整，并可与任何现有的MCMC内核一起使用。我们在一个代表性场景中分析了Coreset MCMC，以获得有关该方法收敛行为的关键见解。实证结果表明，与其他coreset构造方法相比，Coreset MCMC能够提供更高质量的后验近似和更低的计算成本。此外，与其他常规子采样MCMC方法相比，我们发现Coreset MCMC具有较高的采样效率。

    A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method -- Coreset MCMC -- that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze Coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that Coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that Coreset MCMC has a higher sampling efficiency with 
    
[^60]: DeepFDR：一种用于神经影像数据的基于深度学习的虚警控制方法

    DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data. (arXiv:2310.13349v1 [stat.ML])

    [http://arxiv.org/abs/2310.13349](http://arxiv.org/abs/2310.13349)

    DeepFDR是一种基于深度学习的虚警控制方法，通过利用无监督的图像分割技术解决神经影像数据中的多重检验问题，并在实验证明其相对于现有方法具有卓越的性能。

    

    基于体素的多重检验在神经影像数据分析中广泛应用。传统的虚警控制方法常常忽视基于体素的检验之间的空间相关性，从而导致测试能力的大幅损失。虽然最近出现了一些空间虚警控制方法，但是当处理复杂的脑空间依赖关系时，它们的有效性和最优性仍存在疑问。与此同时，深度学习方法已经在图像分割方面取得了革命性的进展，而图像分割与基于体素的多重检验密切相关。本文提出了一种名为DeepFDR的新型空间虚警控制方法，利用无监督的基于深度学习的图像分割来解决基于体素的多重检验问题。包括全面的模拟和阿尔茨海默病FDG-PET影像分析在内的数值研究表明DeepFDR相对于现有方法具有优势。DeepFDR不仅在虚警控制方面表现出色，还有效降低了虚假的非发现率。

    Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but als
    
[^61]: 在概率测度空间中通过梯度流进行抽样

    Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])

    [http://arxiv.org/abs/2310.03597](http://arxiv.org/abs/2310.03597)

    通过梯度流抽样方法的研究方向在计算科学和工程中具有重要意义。本文通过研究概率测度空间中的梯度流的设计组成部分，提出了三个贡献：Kullback-Leibler散度作为能量泛函的独特属性、度量的选择与不变性的关系。

    

    在计算科学和工程中，使用未知归一化常数的目标概率分布进行抽样是一项基本的挑战。最近的研究表明，通过考虑概率测度空间中的梯度流派生的算法为算法开发开辟了新的途径。本文通过审查这种梯度流的设计组成部分，对这种抽样方法做出了三个贡献。抽样的任何实例化都需要一个能量泛函和一个度量来确定流动，以及流动的数值近似来推导算法。我们的第一个贡献是展示了Kullback-Leibler散度作为一个能量泛函具有唯一的特征（在所有f-散度中），即由其得到的梯度流不依赖于目标分布的归一化常数。我们的第二个贡献是从不变性的角度研究度量的选择。Fisher-Rao度量被称为t

    Sampling a target probability distribution with an unknown normalization constant is a fundamental challenge in computational science and engineering. Recent work shows that algorithms derived by considering gradient flows in the space of probability measures open up new avenues for algorithm development. This paper makes three contributions to this sampling approach by scrutinizing the design components of such gradient flows. Any instantiation of a gradient flow for sampling needs an energy functional and a metric to determine the flow, as well as numerical approximations of the flow to derive algorithms. Our first contribution is to show that the Kullback-Leibler divergence, as an energy functional, has the unique property (among all f-divergences) that gradient flows resulting from it do not depend on the normalization constant of the target distribution. Our second contribution is to study the choice of metric from the perspective of invariance. The Fisher-Rao metric is known as t
    
[^62]: 扩散生成流采样器：通过部分轨迹优化改善学习信号

    Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization. (arXiv:2310.02679v1 [cs.LG])

    [http://arxiv.org/abs/2310.02679](http://arxiv.org/abs/2310.02679)

    这项工作介绍了一种名为扩散生成流采样器（DGFS）的采样框架，通过将学习过程分解为短的部分轨迹段，实现从难以处理的高维密度函数中进行采样。它通过利用中间的学习信号和非策略探索能力来改善学习信号的分配问题。

    

    我们解决了从难以处理的高维密度函数中进行采样的问题，这是在机器学习和统计中经常出现的基本任务。我们扩展了最近的基于采样的方法，利用控制的随机过程来模拟这些目标密度的近似样本。这些方法的主要缺点是训练目标需要计算完整的轨迹，导致由于使用完整轨迹和只在终端时间存在的学习信号的使用而产生缓慢的信用分配问题。在这项工作中，我们提出了扩散生成流采样器（DGFS），这是一个基于采样的框架，可以将学习过程可行地分解为短的部分轨迹段，通过参数化一个额外的“流函数”。我们的方法借鉴了生成流网络（GFlowNets）的理论，使我们能够利用中间的学习信号，并从非策略探索能力中受益。

    We tackle the problem of sampling from intractable high-dimensional density functions, a fundamental task that often appears in machine learning and statistics. We extend recent sampling-based approaches that leverage controlled stochastic processes to model approximate samples from these target densities. The main drawback of these approaches is that the training objective requires full trajectories to compute, resulting in sluggish credit assignment issues due to use of entire trajectories and a learning signal present only at the terminal time. In this work, we present Diffusion Generative Flow Samplers (DGFS), a sampling-based framework where the learning process can be tractably broken down into short partial trajectory segments, via parameterizing an additional "flow function". Our method takes inspiration from the theory developed for generative flow networks (GFlowNets), allowing us to make use of intermediate learning signals and benefit from off-policy exploration capabilitie
    
[^63]: M-OFDFT：利用深度学习克服分子系统中的无轨道密度泛函理论的障碍

    M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])

    [http://arxiv.org/abs/2309.16578](http://arxiv.org/abs/2309.16578)

    M-OFDFT是一种利用深度学习模型解决分子系统问题的OFDFT方法，通过将非局域性建立在模型中并使用紧凑的密度表示，实现了与Kohn-Sham DFT相近的精确度，并且具有良好的外推能力。

    

    无轨道密度泛函理论（OFDFT）是一种具有较低运算成本的量子化学计算方法，比起常用的Kohn-Sham密度泛函理论更加适用于当代分子研究。然而，OFDFT的精确性受到了动能密度泛函的限制，对于非周期性分子系统的近似求解非常困难。本文提出了名为M-OFDFT的方法，利用深度学习的函数模型解决了分子系统的问题。我们将必要的非局域性建立在这个模型中，通过原子基下的展开系数作为紧凑的密度表示来降低成本。通过解决其中的非传统学习挑战的技术，M-OFDFT在一系列OFDFT无法触及的分子上实现了与Kohn-Sham DFT相当的精确度。更有吸引力的是，M-OFDFT在训练时属于更大的分子中有着良好的外推能力，为研究大分子提供了有吸引力的规模效应。

    Orbital-free density functional theory (OFDFT) is a quantum chemistry formulation that has a lower cost scaling than the prevailing Kohn-Sham DFT, which is increasingly desired for contemporary molecular research. However, its accuracy is limited by the kinetic energy density functional, which is notoriously hard to approximate for non-periodic molecular systems. In this work, we propose M-OFDFT, an OFDFT approach capable of solving molecular systems using a deep-learning functional model. We build the essential nonlocality into the model, which is made affordable by the concise density representation as expansion coefficients under an atomic basis. With techniques to address unconventional learning challenges therein, M-OFDFT achieves a comparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched by OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much larger than those in training, which unleashes the appealing scaling for studying large molecu
    
[^64]: 黑盒变分推断的线性收敛性：我们应该坚持到底吗？

    Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])

    [http://arxiv.org/abs/2307.14642](http://arxiv.org/abs/2307.14642)

    本文证明了带有控制变量的黑盒变分推断在完美变分族规范下以几何速度收敛，为BBVI提供了收敛性保证，同时提出了对熵梯度估计器的改进，对比了STL估计器，并给出了明确的非渐近复杂度保证。

    

    我们证明了带有控制变量的黑盒变分推断（BBVI），特别是着陆稳定（STL）估计器，在完美变分族规范下收敛于几何（传统上称为“线性”）速度。特别地，我们证明了STL估计器的梯度方差的二次界限，该界限包括了误指定的变分族。结合先前关于二次方差条件的工作，这直接暗示了在使用投影随机梯度下降的情况下BBVI的收敛性。我们还改进了现有对于正常封闭形式熵梯度估计器的分析，这使得我们能够将其与STL估计器进行比较，并为两者提供明确的非渐进复杂度保证。

    We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called "linear") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator and provides explicit non-asymptotic complexity guarantees for both.
    
[^65]: 基于拓扑正则化的多实例学习用于红细胞疾病分类

    Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification. (arXiv:2307.14025v1 [cs.LG])

    [http://arxiv.org/abs/2307.14025](http://arxiv.org/abs/2307.14025)

    本论文提出一种基于拓扑正则化的多实例学习方法，用于罕见贫血疾病的红细胞分类。通过从单个红细胞图像中提取多尺度的拓扑特征来进行模型正则化，以保持数据的特征拓扑属性。实验结果表明，该方法是有效的。

    

    使用显微图像诊断罕见的贫血疾病对于熟练的专家和机器学习方法来说都具有挑战性。由于在单个血样中有数千个与疾病相关的细胞，这构成了一个复杂的多实例学习（MIL）问题。虽然红细胞的空间邻域本身并不重要，但整个血样的拓扑结构，即数据的几何性质，包含了有益的特征，以解决典型的MIL问题，如梯度消失和在有限数据上训练时的过拟合。因此，我们开发了一种基于拓扑的方法，从单个红细胞图像的包中提取多尺度的拓扑特征。这些拓扑特征被用来对模型进行正则化，强制保持数据的特征拓扑属性。在包含71个罕见贫血疾病患者的数据集上，包括521张红细胞显微图像，我们的实验表明拓扑正则化是一个有效的方法。

    Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike. Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem. While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data. We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images. The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data. Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effe
    
[^66]: 在NetHack中的模仿学习的规模律

    Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])

    [http://arxiv.org/abs/2307.09423](http://arxiv.org/abs/2307.09423)

    本文研究了在NetHack游戏中的模仿学习，发现通过扩大模型和数据规模可以改进模仿学习的效果，并建立了训练计算最优IL代理人的幂律。

    

    模仿学习 (IL) 是机器学习中最常用的方法之一。然而，虽然强大，但许多研究发现它往往不能完全恢复出潜在的专家行为。然而，这些研究没有深入探究模型和数据规模的扩大在其中的作用。受最近在自然语言处理 (NLP) 领域的工作的启发，在那里“扩大规模”已经导致了越来越有能力的领域特定语言模型 (LLMs)，我们研究了仔细扩大模型和数据规模是否可以在模仿学习的设置中带来类似的改进。为了展示我们的发现，我们将重点放在 NetHack 游戏上，这是一个具有程序生成、随机性、长期依赖性和部分可观测性的具有挑战性的环境。我们发现 IL 的损失和平均回报随着计算预算的变化而平滑变化且强相关，从而在模型大小和样本数量方面为训练计算最优的 IL 代理人的计算预算建立了幂律。我们预测并训练了几个具有 IL 的NetHack代理。

    Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where "scaling up" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL an
    
[^67]: 可扩展高维多变量线性回归用于特征分布式数据翻译标题

    Scalable High-Dimensional Multivariate Linear Regression for Feature-Distributed Data. (arXiv:2307.03410v1 [stat.ML])

    [http://arxiv.org/abs/2307.03410](http://arxiv.org/abs/2307.03410)

    这篇论文提出了一个适用于特征分布式数据的可扩展高维多变量线性回归算法，具有通信复杂度不依赖于特征维度和快速收敛性的优势，可应用于大规模数据集和具有多变量响应变量的场景。

    

    特征分布式数据是指根据特征划分并存储在多个计算节点上的数据，在具有大量特征的应用中越来越常见。本文提出了一个适用于这种数据的两阶段放松贪婪算法 (TSRGA)，用于应用多变量线性回归。TSRGA 的主要优势在于其通信复杂度不依赖于特征维度，使其能够高度扩展到非常大的数据集。此外，对于多变量响应变量，TSRGA 可用于产生低秩系数估计。通过模拟实验证明了TSRGA 的快速收敛性。最后，我们将提出的TSRGA 应用于一种金融应用中，利用来自 10-K 报告的非结构化数据，证明了其在具有许多密集大维矩阵的应用中的实用性。

    Feature-distributed data, referred to data partitioned by features and stored across multiple computing nodes, are increasingly common in applications with a large number of features. This paper proposes a two-stage relaxed greedy algorithm (TSRGA) for applying multivariate linear regression to such data. The main advantage of TSRGA is that its communication complexity does not depend on the feature dimension, making it highly scalable to very large data sets. In addition, for multivariate response variables, TSRGA can be used to yield low-rank coefficient estimates. The fast convergence of TSRGA is validated by simulation experiments. Finally, we apply the proposed TSRGA in a financial application that leverages unstructured data from the 10-K reports, demonstrating its usefulness in applications with many dense large-dimensional matrices.
    
[^68]: 关于适应性预测集期望大小的研究

    On the Expected Size of Conformal Prediction Sets. (arXiv:2306.07254v1 [stat.ML])

    [http://arxiv.org/abs/2306.07254](http://arxiv.org/abs/2306.07254)

    该论文研究了适应性预测集的期望大小问题，提出了一种理论量化方法以及点估计和高概率区间，并在真实数据集上验证了其实用性。

    

    虽然适应性预测器在误差频率方面具有严格的统计保证，但其预测集大小对其实际效用至关重要。不幸的是，目前缺乏有限样本分析和预测集大小的保证。为了解决这个问题，我们在分裂适应性预测框架下理论量化预测集的期望大小。因为这种精确的计算通常无法直接计算，我们进一步推导出可轻松计算的点估计和高概率区间，提供了一种描述测试和校准数据不同可能实现的期望预测集大小的实用方法。此外，我们通过对回归和分类问题的真实世界数据集进行实验证实了我们结果的实用性。

    While conformal predictors reap the benefits of rigorous statistical guarantees for their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction set under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high probability intervals that can be easily computed, providing a practical method for characterizing the expected prediction set size across different possible realizations of the test and calibration data. Additionally, we corroborate the efficacy of our results with experiments on real-world datasets, for both regression and classification problems.
    
[^69]: 基于预测误差的增量学习分类方法

    Prediction Error-based Classification for Class-Incremental Learning. (arXiv:2305.18806v1 [cs.LG])

    [http://arxiv.org/abs/2305.18806](http://arxiv.org/abs/2305.18806)

    本论文提出了一种新的增量学习分类方法——基于预测误差的分类方法（PEC）。对PEC的评估表明，在各种基准测试中，PEC可以与最先进的增量学习方法相竞争，并具有许多实际优势，例如样本效率高、易于调整。

    

    增量学习分类是连续学习中的一个挑战性问题，目标是学习来区分所有类别。现有的方法在处理大量分类时容易出现过度遗忘和分数不均衡。本研究提出了一种新方法，名为预测误差分类（PEC），它与传统的判别和生成分类范式有所不同。PEC通过测量模型在从该类别中学习的数据上复制随机神经网络输出的预测误差来计算类别得分。该方法可以解释为基于高斯过程后验方差的分类规则的近似。PEC具有几个实际优势，包括样本效率高、易于调整以及即使在逐个呈现数据时也很有效。本文的实证结果表明PEC在广泛的基准测试中表现出色，可以与最先进的增量学习方法相竞争。

    Class-incremental learning (CIL) is a particularly challenging variant of continual learning, where the goal is to learn to discriminate between all classes presented in an incremental fashion. Existing approaches often suffer from excessive forgetting and imbalance of the scores assigned to classes that have not been seen together during training. In this study, we introduce a novel approach, Prediction Error-based Classification (PEC), which differs from traditional discriminative and generative classification paradigms. PEC computes a class score by measuring the prediction error of a model trained to replicate the outputs of a frozen random neural network on data from that class. The method can be interpreted as approximating a classification rule based on Gaussian Process posterior variance. PEC offers several practical advantages, including sample efficiency, ease of tuning, and effectiveness even when data are presented one class at a time. Our empirical results show that PEC pe
    
[^70]: 大型语言模型作为工具制造者

    Large Language Models as Tool Makers. (arXiv:2305.17126v1 [cs.LG])

    [http://arxiv.org/abs/2305.17126](http://arxiv.org/abs/2305.17126)

    本文提出了一个闭环框架，即LLMs作为工具制造者（LATM），使LLMs能够自主地创建用于解决问题的工具，而不需要依赖于现有的外部工具。

    

    最近的研究表明，通过使用外部工具，大型语言模型（LLMs）可以增强其问题解决能力的潜力。然而，在这方面的先前工作依赖于现有工具的可用性。在本文中，我们提出了一个闭环框架，称为LLMs As Tool Makers（LATM），以消除这种依赖性，其中LLMs创建自己的可重用工具来解决问题。我们的方法包括两个关键阶段：1）制造工具：LLM作为工具制造者，为给定任务制作工具，其中工具作为Python实用函数实现。2）使用工具：LLM作为工具用户，应用工具制造者构建的工具来解决问题。工具用户可以是与工具制造者相同或不同的LLM。工具制造使LLM能够不断生成可应用于不同请求的工具，以便将来请求在解决问题时能调用相应的API。

    Recent research shows the potential of enhancing the problem-solving ability of large language models (LLMs) through the use of external tools. However, prior work along this line depends on the availability of existing tools. In this work, we take an initial step towards removing this dependency by proposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM), where LLMs create their own reusable tools for problem-solving. Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function. 2) tool using: an LLM acts as the tool user, which applies the tool built by the tool maker for problem-solving. The tool user can be either the same or a different LLM from the tool maker. Tool-making enables an LLM to continually generate tools that can be applied to different requests so that future requests can call the corresponding APIs when beneficial for solving the 
    
[^71]: 向量值变分空间和DNN的宽度界：关于权重衰减正则化的见解。

    Vector-Valued Variation Spaces and Width Bounds for DNNs: Insights on Weight Decay Regularization. (arXiv:2305.16534v1 [stat.ML])

    [http://arxiv.org/abs/2305.16534](http://arxiv.org/abs/2305.16534)

    该论文提供了关于通过加权衰减训练的多输出ReLU神经网络的函数类型和相应的解决方案的新见解。

    

    深度神经网络(DNNs)通过梯度下降最小化损失项和平方权重和相应，对应于训练加权衰减的常见方法。本文提供了有关这种常见学习框架的新见解。我们表征了训练加权衰减以获得多输出(向量值)ReLU神经网络学习的函数类型。这扩展了先前限于单输出(标量值)网络的表征。这种表征需要定义我们称之为向量值变分(VV)空间的新类神经函数空间。我们通过一种新的表征定理证明，神经网络(NNs)是通过VV空间中提出学习问题的最优解。这个新的表征定理表明，这些学习问题的解存在于宽度受训练数据数限制的向量值神经网络中。接下来，通过与多任务lasso问题的新联系，我们导出了

    Deep neural networks (DNNs) trained to minimize a loss term plus the sum of squared weights via gradient descent corresponds to the common approach of training with weight decay. This paper provides new insights into this common learning framework. We characterize the kinds of functions learned by training with weight decay for multi-output (vector-valued) ReLU neural networks. This extends previous characterizations that were limited to single-output (scalar-valued) networks. This characterization requires the definition of a new class of neural function spaces that we call vector-valued variation (VV) spaces. We prove that neural networks (NNs) are optimal solutions to learning problems posed over VV spaces via a novel representer theorem. This new representer theorem shows that solutions to these learning problems exist as vector-valued neural networks with widths bounded in terms of the number of training data. Next, via a novel connection to the multi-task lasso problem, we derive
    
[^72]: 本地贝叶斯优化的行为和收敛性

    The Behavior and Convergence of Local Bayesian Optimization. (arXiv:2305.15572v1 [cs.LG])

    [http://arxiv.org/abs/2305.15572](http://arxiv.org/abs/2305.15572)

    本文研究了贝叶斯本地优化策略的行为和收敛性，并在高维问题上提供了强大的实证性能。统计数据表明，单个高斯过程样本路径的本地解比全局方法恢复的预期值更好。Müller等人提出的贝叶斯本地优化算法的收敛速率在有噪音和无噪音的情况下都有推导。

    

    贝叶斯优化中一项最新的发展是使用本地优化策略，与传统的全局策略相比，可以在高维问题上提供强大的实证性能。文献中的“传统智慧”是，专注于本地优化规避了维度诅咒。然而，对于贝叶斯本地优化例程的预期行为或收敛性了解甚少。我们首先研究了本地方法的行为，并发现高斯过程样本路径单个本地解的统计数据与从全局方法恢复的预期值相比非常好。然后，我们展示了最近由Müller等人提出的基于贝叶斯本地优化算法的第一次严格分析，并在有噪音和无噪音的情况下推导出收敛速率。

    A recent development in Bayesian optimization is the use of local optimization strategies, which can deliver strong empirical performance on high-dimensional problems compared to traditional global strategies. The "folk wisdom" in the literature is that the focus on local optimization sidesteps the curse of dimensionality; however, little is known concretely about the expected behavior or convergence of Bayesian local optimization routines. We first study the behavior of the local approach, and find that the statistics of individual local solutions of Gaussian process sample paths are surprisingly good compared to what we would expect to recover from global methods. We then present the first rigorous analysis of such a Bayesian local optimization algorithm recently proposed by M\"uller et al. (2021), and derive convergence rates in both the noisy and noiseless settings.
    
[^73]: 通过高斯过程求解非线性偏微分方程的稀疏Cholesky分解方法

    Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes. (arXiv:2304.01294v1 [math.NA])

    [http://arxiv.org/abs/2304.01294](http://arxiv.org/abs/2304.01294)

    本文提出了一种稀疏Cholesky分解算法，用于高斯过程求解非线性偏微分方程，能够有效处理高维和畸形域的问题。

    

    本文研究了一个高斯过程框架求解一般非线性偏微分方程的计算可伸缩性。这个框架把求解PDE转化为解非线性约束下的二次优化问题。其复杂度的瓶颈在于利用高斯过程的协方差核及其在拟合点的偏导数进行点对点计算所得到的密集协方差矩阵的计算。我们提出了一种基于Diracs和导数测量的新排列顺序的稀疏Cholesky分解算法用于计算此类协方差矩阵。我们严格地确定了该Cholesky分解的稀疏模式，并量化了相应Vecchia近似的指数收敛精度，在Kullback-Leibler距离度量下达到最优。这使我们能够以$O(N\log^d(N/\epsilon))$的空间复杂度和$O(N\log^{d+2}(N/\epsilon))$的时间复杂度计算$\epsilon$-近似的逆Cholesky因子。其中，$N$表示拟合点的数量，$d$为物理域的维数。我们在几个高维（最高可达到$d=50$）和畸形域的基准问题上展示了这种方法的有效性。

    We study the computational scalability of a Gaussian process (GP) framework for solving general nonlinear partial differential equations (PDEs). This framework transforms solving PDEs to solving quadratic optimization problem with nonlinear constraints. Its complexity bottleneck lies in computing with dense kernel matrices obtained from pointwise evaluations of the covariance kernel of the GP and its partial derivatives at collocation points.  We present a sparse Cholesky factorization algorithm for such kernel matrices based on the near-sparsity of the Cholesky factor under a new ordering of Diracs and derivative measurements. We rigorously identify the sparsity pattern and quantify the exponentially convergent accuracy of the corresponding Vecchia approximation of the GP, which is optimal in the Kullback-Leibler divergence. This enables us to compute $\epsilon$-approximate inverse Cholesky factors of the kernel matrices with complexity $O(N\log^d(N/\epsilon))$ in space and $O(N\log^{
    
[^74]: 近似最优的非参数顺序检验和具有可能相关观测的置信区间

    Near-Optimal Non-Parametric Sequential Tests and Confidence Sequences with Possibly Dependent Observations. (arXiv:2212.14411v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2212.14411](http://arxiv.org/abs/2212.14411)

    本文研究了非参数顺序检验和置信区间，在一般非参数数据生成过程下提供了类型I错误和期望拒绝时间保证，提高了其灵活性和性能。

    

    顺序检验和其隐含的置信区间在任意停止时间下都能提供灵活的统计推断和即时决策。然而，强有力的保证仅适用于在实践中低估或浓度界限为基础的顺序序列，而这些序列具有次优的拒绝时间。在本文中，我们考虑罗宾斯（Robbins）1970年的延迟启动正态混合顺序概率比检验，并在一般非参数数据生成过程下提供了首个渐近类型I错误和期望拒绝时间保证，其中渐近性质由测试的烧入时间确定。类型I错误的结果主要依赖于鞅强不变原理，并证明这些检验（及其隐含的置信区间）具有接近所需α水平的类型I错误率。期望拒绝时间的结果主要利用了一种受伊藤引理启发的恒等式。

    Sequential tests and their implied confidence sequences, which are valid at arbitrary stopping times, promise flexible statistical inference and on-the-fly decision making. However, strong guarantees are limited to parametric sequential tests that under-cover in practice or concentration-bound-based sequences that over-cover and have suboptimal rejection times. In this work, we consider \cite{robbins1970boundary}'s delayed-start normal-mixture sequential probability ratio tests, and we provide the first asymptotic type-I-error and expected-rejection-time guarantees under general non-parametric data generating processes, where the asymptotics are indexed by the test's burn-in time. The type-I-error results primarily leverage a martingale strong invariance principle and establish that these tests (and their implied confidence sequences) have type-I error rates approaching a desired $\alpha$-level. The expected-rejection-time results primarily leverage an identity inspired by It\^o's lemm
    
[^75]: 自适应变分贝叶斯：优化性质，计算和应用

    Adaptive variational Bayes: Optimality, computation and applications. (arXiv:2109.03204v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2109.03204](http://arxiv.org/abs/2109.03204)

    本文提出了一种新颖的自适应变分贝叶斯框架，可以在多个模型上运行。该方法能够自适应地实现最优的收缩速率，并提供了一种技术方法来保持可计算性和自适应最优性。

    

    本文探讨了基于变分贝叶斯的自适应推断。虽然已经进行了一些研究来分析变分后验的收敛性质，但仍然缺乏一种通用且具有计算可行性的自适应变分贝叶斯方法。为填补这一空白，我们提出了一种新颖的自适应变分贝叶斯框架，可以在多个模型上运行。该框架首先分别计算每个单独模型的变分后验，然后将它们与一定的权重结合起来，产生整个模型的变分后验。结果表明，这个组合的变分后验是在预定义的一族近似分布中最接近整个模型的后验的成员。我们证明了在非常普遍的条件下，自适应变分贝叶斯可以自适应地实现最优的收缩速率。我们还提供了一种技术方法来保持可计算性和自适应最优性。

    In this paper, we explore adaptive inference based on variational Bayes. Although several studies have been conducted to analyze the contraction properties of variational posteriors, there is still a lack of a general and computationally tractable variational Bayes method that performs adaptive inference. To fill this gap, we propose a novel adaptive variational Bayes framework, which can operate on a collection of models. The proposed framework first computes a variational posterior over each individual model separately and then combines them with certain weights to produce a variational posterior over the entire model. It turns out that this combined variational posterior is the closest member to the posterior over the entire model in a predefined family of approximating distributions. We show that the adaptive variational Bayes attains optimal contraction rates adaptively under very general conditions. We also provide a methodology to maintain the tractability and adaptive optimalit
    
[^76]: 高斯混合模型中的局部极小结构

    Local Minima Structures in Gaussian Mixture Models. (arXiv:2009.13040v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2009.13040](http://arxiv.org/abs/2009.13040)

    研究了高斯混合模型中的负对数似然函数的局部极小值结构，发现它们都共享一种常见结构而部分确定了真正的位置混合物的簇中心。这些结果适用于真实混合组分满足某种分离条件的情况，也适用于成分数量过多或过少的情况。

    

    我们在人口极限的情况下调查了混合成分模型（GMM）的负对数似然函数的情况，并探讨了具有一般成分数量的GMM的负对数似然函数的局部极小值结构。由于目标函数是非凸的，即使对于分离良好的混合模型，也可能存在不是全局最优的多个局部极小值。我们的研究揭示了所有局部极小值都共享一种常见结构，该结构部分确定了真正的位置混合物（即高斯成分的均值）的簇中心。具体而言，每个局部极小值可以表示为两种类型子配置的非重叠组合：将单个均值估计与多个高斯分量拟合或将多个估计拟合到单个真实分量。这些结果适用于真实混合组分满足某种分离条件的情况，并且在成分数量过多或过少的情况下也是有效的。我们还针对一维高斯混合物的设置提供了更精细的分析，通过结构计数论证导出了这些非全局最小值的精确数量和它们对应的配置。

    We investigate the landscape of the negative log-likelihood function of Gaussian Mixture Models (GMMs) with a general number of components in the population limit. As the objective function is non-convex, there can be multiple local minima that are not globally optimal, even for well-separated mixture models. Our study reveals that all local minima share a common structure that partially identifies the cluster centers (i.e., means of the Gaussian components) of the true location mixture. Specifically, each local minimum can be represented as a non-overlapping combination of two types of sub-configurations: fitting a single mean estimate to multiple Gaussian components or fitting multiple estimates to a single true component. These results apply to settings where the true mixture components satisfy a certain separation condition, and are valid even when the number of components is overor under-specified. We also present a more fine-grained analysis for the setting of one-dimensional G
    

