# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Convergence of Kinetic Langevin Monte Carlo on Lie groups](https://arxiv.org/abs/2403.12012) | 提出了一个基于Lie群的动力学Langevin Monte Carlo采样算法，通过添加噪声和精细离散化实现了Lie群结构的保持，并在W2距离下证明了连续动力学和离散采样器的指数收敛性。 |
| [^2] | [Visualization for Trust in Machine Learning Revisited: The State of the Field in 2023](https://arxiv.org/abs/2403.12005) | 2023年的研究显示，可解释和可信赖的机器学习可视化仍然是一个重要且不断发展的领域，为各种领域提供了趋势、见解和挑战。 |
| [^3] | [Unveil Conditional Diffusion Models with Classifier-free Guidance: A Sharp Statistical Theory](https://arxiv.org/abs/2403.11968) | 本文揭示了无分类器引导的条件扩散模型的尖锐统计理论，提出了适应数据分布平滑度的样本复杂度界限，并展示了新颖的扩散泰勒逼近技术在理论发展中的重要性。 |
| [^4] | [Probabilistic Calibration by Design for Neural Network Regression](https://arxiv.org/abs/2403.11964) | 提出了一种称为Quantile Recalibration Training的新型端到端模型训练过程，将后处理校准直接整合到训练过程中，无需额外参数，展示出在神经网络回归中提高校准性能的方法。 |
| [^5] | [Transfer Learning Beyond Bounded Density Ratios](https://arxiv.org/abs/2403.11963) | 低次多项式估计类上的迁移学习，证明了在非常温和的假设下，对于低次多项式来说非平凡的迁移学习是可能的，超越了$dQ/dP$有界的经典假设 |
| [^6] | [CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation](https://arxiv.org/abs/2403.11960) | CASPER提出了一种因果关系感知的方法来处理时空时间序列数据插补问题，避免过度利用非因果关系，提高数据分析的准确性。 |
| [^7] | [Pessimistic Causal Reinforcement Learning with Mediators for Confounded Offline Data](https://arxiv.org/abs/2403.11841) | 提出了一种新的策略学习算法，PESCAL，利用基于前门标准的中介变量消除混杂偏差，并采用悲观原则处理候选策略引起的分布变化。 |
| [^8] | [A tutorial on learning from preferences and choices with Gaussian Processes](https://arxiv.org/abs/2403.11782) | 提供了一个使用高斯过程进行偏好学习的框架，能够将理性原则融入学习过程，涵盖了多种偏好学习模型。 |
| [^9] | [PARMESAN: Parameter-Free Memory Search and Transduction for Dense Prediction Tasks](https://arxiv.org/abs/2403.11743) | 通过引入转导的概念，提出了PARMESAN，一种用于解决密集预测任务的无参数内存搜索和转导方法，实现了灵活性和无需连续训练的学习。 |
| [^10] | [Generalization error of spectral algorithms](https://arxiv.org/abs/2403.11696) | 本研究考虑了使用光谱算法来训练核，推导出泛化误差函数，提供了完整的损失渐近行为，展示了损失在特定频谱尺度上的局部化。 |
| [^11] | [Nonsmooth Implicit Differentiation: Deterministic and Stochastic Convergence Rates](https://arxiv.org/abs/2403.11687) | 在非光滑设置下，提出了用于计算具有内映射的外映射固定点的隐式导数的新方法NSID，并提供了确定性情况下迭代微分（ITD）和近似隐式微分（AID）的改进线性收敛速率。 |
| [^12] | [The Value of Reward Lookahead in Reinforcement Learning](https://arxiv.org/abs/2403.11637) | 分析了在强化学习中利用部分未来奖励先知的价值，通过竞争性分析得出了最坏情况下奖励期望的精确比率。 |
| [^13] | [Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)](https://arxiv.org/abs/2403.11532) | 本研究提出使用符合预测来评估分布外（OOD）检测中效率的新方法，并定义了新的符合AUROC和符合FRP@TPR95指标，为OOD和异常检测基准提供了概率保守性保证。 |
| [^14] | [State-Separated SARSA: A Practical Sequential Decision-Making Algorithm with Recovering Rewards](https://arxiv.org/abs/2403.11520) | 提出了分离状态SARSA（SS-SARSA）算法，针对恢复老虎机场景设计，通过将轮数视为状态，降低Q-learning/SARSA所需的状态组合数量，实现有效学习，并在温和假设下证明了渐近收敛至最优策略。 |
| [^15] | [Do CLIPs Always Generalize Better than ImageNet Models?](https://arxiv.org/abs/2403.11497) | CLIP模型在面对分布转移时表现出良好的泛化能力，作者设计了CounterAnimal数据集来探究模型对虚假特征的依赖性。 |
| [^16] | [Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs](https://arxiv.org/abs/2403.11477) | 该研究提出了对于弱通信MDPs的样本复杂度界限为 $\tilde{O}(SA\frac{H}{\epsilon^2})$，改进了现有工作，是在所有参数上最小最优的。 |
| [^17] | [Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors](https://arxiv.org/abs/2403.11407) | 通过利用去噪扩散模型先验结构，提出了一种分布式分隔后验采样方法，相比先前的方法具有更低的逼近误差。 |
| [^18] | [An SDP-based Branch-and-Cut Algorithm for Biclustering](https://arxiv.org/abs/2403.11351) | 提出了一个基于SDP的分支定界算法，用于解决$k$-最密不相交双团问题。 |
| [^19] | [COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits](https://arxiv.org/abs/2403.11348) | 通过概率电路，提出了COLEP框架，实现了可证实鲁棒学习推理一致性预测，其特点在于训练统计模型学习不同语义概念，并利用概率电路实现精确高效推理 |
| [^20] | [Federated Transfer Learning with Differential Privacy](https://arxiv.org/abs/2403.11343) | 本文提出了具有差分隐私的联邦迁移学习框架，通过利用多个异构源数据集的信息来增强对目标数据集的学习，同时考虑隐私约束。 |
| [^21] | [Prior-dependent analysis of posterior sampling reinforcement learning with function approximation](https://arxiv.org/abs/2403.11175) | 该研究提出了首个先验依赖性贝叶斯遗憾上界，并对后验抽样强化学习进行了改进分析，提出了一个新的上界结果，实现了对先前基准的方法论提升。 |
| [^22] | [Machine learning-based system reliability analysis with Gaussian Process Regression](https://arxiv.org/abs/2403.11125) | 本文提出了基于高斯过程回归的机器学习系统可靠性分析方法，并通过几个定理探讨了最优学习策略，包括考虑和忽略样本之间的相关性以及顺序多个训练样本增益的理论最优策略。 |
| [^23] | [The Fallacy of Minimizing Local Regret in the Sequential Task Setting](https://arxiv.org/abs/2403.10946) | 研究了强化学习中在序列任务设置下最小化局部遗憾的谬误，揭示了近视地最小化遗憾在实际应用中的复杂性。 |
| [^24] | [Function-space Parameterization of Neural Networks for Sequential Learning](https://arxiv.org/abs/2403.10929) | 提出了一种神经网络的函数空间参数化方法，能够在序列学习中有效整合新数据并保留先前知识，同时在不重新训练的情况下合并新数据。 |
| [^25] | [Interpretable Machine Learning for TabPFN](https://arxiv.org/abs/2403.10923) | TabPFN模型在低数据情况下实现了良好的分类性能，并能够以秒级速度生成后验预测分布，我们提出了几种专为TabPFN设计的可解释性方法的改进，实现了更高效的计算。 |
| [^26] | [DTOR: Decision Tree Outlier Regressor to explain anomalies](https://arxiv.org/abs/2403.10903) | DTOR是一种决策树异常值回归器，通过估计异常检测模型生成的异常分数来产生基于规则的解释，具有鲁棒性，适用于具有大量特征数据集。 |
| [^27] | [List Sample Compression and Uniform Convergence](https://arxiv.org/abs/2403.10889) | 研究在列表学习中均匀收敛和样本压缩原则的适用性，证明了在列表PAC学习中均匀收敛仍然等价于可学习性 |
| [^28] | [Neural-Kernel Conditional Mean Embeddings](https://arxiv.org/abs/2403.10859) | 结合深度学习和CME的神经网络方法，解决了核条件均值嵌入面临的可伸缩性和表现力挑战，并在条件密度估计任务和强化学习中展现出卓越性能。 |
| [^29] | [Incentivized Exploration of Non-Stationary Stochastic Bandits](https://arxiv.org/abs/2403.10819) | 提出了针对非平稳随机赌博机的激励探索算法，实现了随时间的子线性遗憾和补偿 |
| [^30] | [A Probabilistic Approach for Alignment with Human Comparisons](https://arxiv.org/abs/2403.10771) | 通过提出的两阶段“监督微调+人类比较”框架，本文研究了如何有效利用人类比较来改善AI模型的对齐，特别是在面对嘈杂数据和高维模型时。 |
| [^31] | [A Primal-Dual Algorithm for Faster Distributionally Robust Optimization](https://arxiv.org/abs/2403.10763) | 这种原始-对偶算法在分布鲁棒优化问题中实现了最先进的线性收敛速度。 |
| [^32] | [Hessian-Free Laplace in Bayesian Deep Learning](https://arxiv.org/abs/2403.10671) | 提出了一种无Hessian计算和求逆的Hessian-Free Laplace近似框架，通过对数后验和网络预测的曲率来估计后验的方差。 |
| [^33] | [A resource-constrained stochastic scheduling algorithm for homeless street outreach and gleaning edible food](https://arxiv.org/abs/2403.10638) | 该研究针对无家可归者和食品银行的资源受限外展问题，提出了一种基于Thompson抽样与马尔可夫链恢复的算法，显著优于基线算法。 |
| [^34] | [Sequential Monte Carlo for Inclusive KL Minimization in Amortized Variational Inference](https://arxiv.org/abs/2403.10610) | 用顺序蒙特卡洛采样器估计inclusive KL散度梯度，提出了三种梯度估计器，解决了现有方法的偏差梯度和高度集中变分分布问题。 |
| [^35] | [Generative Modelling of Stochastic Rotating Shallow Water Noise](https://arxiv.org/abs/2403.10578) | 本文提出一种用于校准流体动力学随机偏微分方程中噪声的通用方法，使用生成模型技术取代了以往的PCA技术，这能够避免对增量施加额外约束。 |
| [^36] | [A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage](https://arxiv.org/abs/2403.09701) | 混合强化学习算法中，通过将离线数据集包含在在线算法的经验重放缓冲区中进行启动，可以实现类似于基于离线数据分布引导在线探索的可证明收益，即使离线数据集没有单一策略可集中性。 |
| [^37] | [Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings](https://arxiv.org/abs/2403.07454) | 使用结构混合概率分布提供了准确的后验推断，同时具有更小的计算占用量，相较于现有的基于神经网络的SBI方法。 |
| [^38] | [Hierarchy of the echo state property in quantum reservoir computing](https://arxiv.org/abs/2403.02686) | 介绍了在量子储备计算中回声态性质的不同层次，包括非平稳性ESP和子系统具有ESP的子空间/子集ESP。进行了数值演示和记忆容量计算以验证这些定义。 |
| [^39] | [Truly No-Regret Learning in Constrained MDPs](https://arxiv.org/abs/2402.15776) | 本文首次肯定回答了一个开放问题，即是否可以在不允许错误抵消的情况下，通过将一种常见的安全约束模型扩展到具有多个约束的CMDPs，提出了一种可以实现次线性后悔的新方法。 |
| [^40] | [HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments](https://arxiv.org/abs/2402.10228) | HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。 |
| [^41] | [A Novel Gaussian Min-Max Theorem and its Applications](https://arxiv.org/abs/2402.07356) | 本文介绍了一个新的高斯最小最大定理，扩展了经典定理对于独立但非恒定分布的情况。此外，该定理在高维统计学、机器学习、非光滑优化和信号处理等领域有广泛的应用。 |
| [^42] | [The Benefits of Reusing Batches for Gradient Descent in Two-Layer Networks: Breaking the Curse of Information and Leap Exponents](https://arxiv.org/abs/2402.03220) | 该论文研究了在两层神经网络中学习多指数目标函数时，重复使用批次的梯度下降（GD）的训练动态。研究发现，与单次GD相比，多次GD能够克服目标函数的限制，仅需两个时间步骤就能实现网络与目标子空间的重叠，展示了在有限时间内有效学习的广泛函数类。这些结果基于动力平均场理论（DMFT）的分析。 |
| [^43] | [How Free is Parameter-Free Stochastic Optimization?](https://arxiv.org/abs/2402.03126) | 这个论文研究了无参随机优化的问题，提出了一种完全无参的方法，通过简单的超参数搜索技术在非凸和凸设置下都能取得优于先进算法的性能。同时，论文还建立了一个下界，指出完全无参的方法在某些情况下无法实现。 |
| [^44] | [Locally Optimal Fixed-Budget Best Arm Identification in Two-Armed Gaussian Bandits with Unknown Variances](https://arxiv.org/abs/2312.12741) | 提出了一种在双臂高斯赌臂机器人中解决具有未知方差情况下局部最优固定预算最佳臂识别问题的策略。 |
| [^45] | [Language Model Knowledge Distillation for Efficient Question Answering in Spanish](https://arxiv.org/abs/2312.04193) | 通过知识蒸馏，我们开发了SpanishTinyRoBERTa，一个基于RoBERTa的西班牙语压缩语言模型，用于提高西班牙语问答的效率。 |
| [^46] | [Multinomial belief networks](https://arxiv.org/abs/2311.16909) | 提出了一种深度生成模型，用于处理具有多项式计数数据的分析需求，并能够从数据中完全自动提取出生物意义的元签名。 |
| [^47] | [Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning](https://arxiv.org/abs/2311.15487) | 通过几何调整的梯度下降，在深度学习中以均匀指数速率实现全局$\mathcal{L}^2$最小化，这一方法在过参数化情况下具有明确自然的不变几何含义。 |
| [^48] | [Copula-based transferable models for synthetic population generation](https://arxiv.org/abs/2302.09193) | 提出了一种基于Copula的新框架，利用不同人口样本以及相似边际依赖性，引入空间组件并考虑多种信息源，用于生成合成但现实的目标人口表示。 |
| [^49] | [Dimension free ridge regression](https://arxiv.org/abs/2210.08571) | 该论文旨在超越比例渐近情况，重新审视对高维数据进行岭回归，允许特征向量是高维甚至无限维的，为统计学中的自然设置提供了新的研究方向。 |
| [^50] | [A review of predictive uncertainty estimation with machine learning](https://arxiv.org/abs/2209.08307) | 该综述回顾了机器学习中利用概率分布进行预测不确定性估计的主题，为评估概率预测提供了相关度量，从经典统计方法到现代机器学习算法进行了梳理。 |
| [^51] | [Statistical Properties of the log-cosh Loss Function Used in Machine Learning](https://arxiv.org/abs/2208.04564) | 分析log-cosh损失函数的统计特性，比较它与柯西分布的性质，并研究MLE的偏差、方差和置信区间，同时提供了与其他损失函数的鲁棒估计器比较。 |
| [^52] | [Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past](https://arxiv.org/abs/2203.06056) | 本文考虑了在时间序列模型中进行 IV 回归的困难，提出了一种用于构建识别方程的方法，以实现对时间序列数据中因果效应的一致性参数估计。 |
| [^53] | [Nonparametric Bayesian volatility learning under microstructure noise](https://arxiv.org/abs/1805.05606) | 研究在市场微观结构噪声下学习波动率的问题，采用非参数贝叶斯方法，通过先前研究波动率函数和采用前向滤波后向模拟算法等新颖计算方法，在合成数据和EUR/USD汇率数据集上表现良好。 |
| [^54] | [Shift Aggregate Extract Networks](https://arxiv.org/abs/1703.05537) | 通过深层分层分解的架构，提出了一种有效学习大型图表示的方法，能够在大型社交网络数据集上胜过当前最先进的图分类方法，同时在小型化学生物基准数据集上具有竞争力。 |
| [^55] | [Ricci flow-guided autoencoders in learning time-dependent dynamics.](http://arxiv.org/abs/2401.14591) | 利用Ricci流引导的自编码器方法能够学习非线性动力学，尤其是偏微分方程。该方法通过在训练中学习流形，并使用Ricci流使流形潜空间逐步适应动力学的变化，从而获得更好的表示能力。在实验中，我们展示了该方法在具有周期性和随机性的PDE上的应用，并评估了在分布内和外推场景中的误差。 |
| [^56] | [Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis.](http://arxiv.org/abs/2401.10383) | 本文提出了一种解决多智能体图形赌博机问题的算法Multi-G-UCB，并通过数值实验验证了其有效性。 |
| [^57] | [Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs.](http://arxiv.org/abs/2401.07961) | 这项研究将概率Lambert问题与最优质量传输、Schr\"odinger桥和反应-扩散偏微分方程等领域连接起来，从而解决了概率Lambert问题的解的存在和唯一性，并提供了数值求解的方法。 |
| [^58] | [Inside the black box: Neural network-based real-time prediction of US recessions.](http://arxiv.org/abs/2310.17571) | 本研究使用神经网络对美国衰退进行实时预测，发现长短期记忆（LSTM）和门控循环单元（GRU）模型在长期预测任务中表现优于其他模型，并通过SHAP方法对GRU模型进行特征重要性评估。 |
| [^59] | [The Expressive Power of Low-Rank Adaptation.](http://arxiv.org/abs/2310.17513) | 本文分析了低秩适应（LoRA）的表达能力，证明了对于全连接神经网络，当LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度）时，LoRA可以使任何模型f准确表示任何较小的目标模型f。对于Transformer网络，通过rank-（嵌入大小/ 2）的LoRA适配器可以使任何模型适应于相同大小的目标模型。 |
| [^60] | [Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes.](http://arxiv.org/abs/2310.16597) | 本文扩展了之前的研究，将证明的范围从独立同分布权重扩展到了更大的权重分布类别(PSEUDO-IID)，包括低秩和稀疏设置。作者发现使用PSEUDO-IID分布初始化的全连接和卷积网络在方差上都是等效的。这些结果可以帮助我们识别更广泛的神经网络的边界混沌状态，并进行性能调优。 |
| [^61] | [Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients.](http://arxiv.org/abs/2310.01012) | 本论文提出了一个新颖的无约束目标，通过应用随机梯度下降（SGD）到CCA目标，实现了一系列快速算法，包括随机PLS、随机CCA和深度CCA。这些方法在各种基准测试中表现出比先前最先进方法更快的收敛速度和更高的相关性恢复。 |
| [^62] | [Learning to Make Adherence-Aware Advice.](http://arxiv.org/abs/2310.00817) | 本文提出了一种顺序决策模型，考虑了人的依从程度和机器提供建议的时机，并提供了学习算法来学习最佳的建议策略。 |
| [^63] | [The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing.](http://arxiv.org/abs/2309.16883) | 本文提出了一个增强随机平滑的方法，通过研究随机平滑引入的方差与分类器的Lipschitz常数和边界之间的关系，以及采用单纯形投影技术来增加认证鲁棒半径。 |
| [^64] | [From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity.](http://arxiv.org/abs/2309.16512) | 本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。 |
| [^65] | [Geometric structure of shallow neural networks and constructive ${\mathcal L}^2$ cost minimization.](http://arxiv.org/abs/2309.10370) | 本文提供了浅层神经网络的几何结构解释，并通过基于${\mathcal L}^2$代价最小化的构造方法获得了一个具有优越性能的网络。 |
| [^66] | [Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets.](http://arxiv.org/abs/2309.09258) | 本文首次证明了在深度为2的神经网络上，适当正则化的逻辑回归代价函数通过随机梯度下降（SGD）能够收敛到全局极小值，这适用于任意数据和具有充分平滑且有界激活函数。同时，我们还证明了连续时间SGD的指数级快速收敛速度，该结果也适用于光滑无界的激活函数。 |
| [^67] | [Deep Nonnegative Matrix Factorization with Beta Divergences.](http://arxiv.org/abs/2309.08249) | 本文提出了一种使用Beta散度的深度非负矩阵分解方法，应用于面部特征提取、文档主题识别和高光谱图像材料识别。 |
| [^68] | [Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods.](http://arxiv.org/abs/2308.01938) | 本文提出了两种新的在线多任务学习方法，分别基于递归最小二乘和递归核方法。与基于梯度下降或不精确逼近的方法不同，我们的方法在每个实例的代价上具有二次复杂度。我们将这些方法应用于风力短期预测挑战，并与其他竞争者进行了比较。 |
| [^69] | [Online learning in bandits with predicted context.](http://arxiv.org/abs/2307.13916) | 本文研究了一种在预测上下文中的在线学习问题，通过将经典统计学中的测量误差模型推广到在线决策设置中，我们提出了第一个具有次线性后悔的在线算法。 |
| [^70] | [Properties of Discrete Sliced Wasserstein Losses.](http://arxiv.org/abs/2307.10352) | 本文研究了离散切割Wasserstein损失的性质，并探讨了其正则性和优化性质以及通过蒙特卡洛近似的方法。 |
| [^71] | [Differentially Private Latent Diffusion Models.](http://arxiv.org/abs/2305.15759) | 本文提出使用差分隐私训练潜在扩散模型(LDMs)，通过预训练自编码器将高维像素空间转变为低维潜在空间实现更高效快速的DMs训练，并且通过只微调注意力模块减少了可训练参数的数量。 |
| [^72] | [Expressive Losses for Verified Robustness via Convex Combinations.](http://arxiv.org/abs/2305.13991) | 通过基于凸组合的表达性损失，可以提高网络的对抗鲁棒性，最新的算法可以获得最先进的结果；这种方法通过对抗性攻击和IBP边界之间的简单凸组合进行实现。 |
| [^73] | [Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees.](http://arxiv.org/abs/2305.11997) | 本文提出了一种可靠的神经网络反事实解释方法，该方法可以针对自然发生的模型变化提供高概率的鲁棒性。 |
| [^74] | [Energy-guided Entropic Neural Optimal Transport.](http://arxiv.org/abs/2304.06094) | 本论文提出了一种新的方法，将能量基础模型和熵正则化最优输运结合起来，以解决生成建模问题。我们在2D情景和图像到图像翻译问题中验证了该方法的适用性。 |
| [^75] | [Koopman-based generalization bound: New aspect for full-rank weights.](http://arxiv.org/abs/2302.05825) | 我们提出了一种使用Koopman算子对全秩神经网络权重进行泛化的新界限，当权重矩阵的条件数较小时，该界限比现有基于范数的界限更紧。我们的界限不与现有界限相矛盾，而是对现有界限进行的补充。此外，我们的界限可以与现有界限结合以得到更紧的界限。该研究结果为理解全秩权重神经网络的泛化提供了新的视角，同时也为算子理论分析和神经网络泛化之间提供了连接。 |
| [^76] | [Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial Online Convex Optimization.](http://arxiv.org/abs/2302.04552) | 本论文研究了乐观的在线镜像下降算法在Stochastically Extended Adversarial (SEA)模型中的理论保证，对于凸和平滑的函数，其遗憾界限为O(sqrt(σ_{1:T}^2) + sqrt(Σ_{1:T}^2))，对于强凸和平滑的函数，其界限为O(sqrt(σ_{\max}^2) + sqrt(Σ_{\max}^2))。 |
| [^77] | [Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies.](http://arxiv.org/abs/2209.14568) | 本文提出了一种概率框架，为每个观测值提供稀疏的局部反事实规则，并将这些规则聚合成区域反事实规则，以适应不稳定的实现环境，并产生稳健的救济措施。 |

# 详细

[^1]: 基于Lie群的动力学Langevin Monte Carlo算法的收敛性

    Convergence of Kinetic Langevin Monte Carlo on Lie groups

    [https://arxiv.org/abs/2403.12012](https://arxiv.org/abs/2403.12012)

    提出了一个基于Lie群的动力学Langevin Monte Carlo采样算法，通过添加噪声和精细离散化实现了Lie群结构的保持，并在W2距离下证明了连续动力学和离散采样器的指数收敛性。

    

    最近，基于变分优化和左平凡化等技术构建了一个明确的、基于动量的动力学系统，用于优化定义在Lie群上的函数。我们适当地为优化动力学添加可处理的噪声，将其转化为采样动力学，利用动量变量是欧几里得的这一有利特性，尽管潜在函数存在于流形上。然后，我们通过精心离散化导致的动力学采样动力学提出了一个Lie群MCMC采样器。这种离散化完全保持了Lie群结构。在W2距离下，分别对连续动力学和离散采样器证明了指数收敛性，其中只需要Lie群的紧致性和潜在函数的测地L-光滑性。据我们所知，这是对动力学Langevin算法的第一个收敛性结果。

    arXiv:2403.12012v1 Announce Type: cross  Abstract: Explicit, momentum-based dynamics for optimizing functions defined on Lie groups was recently constructed, based on techniques such as variational optimization and left trivialization. We appropriately add tractable noise to the optimization dynamics to turn it into a sampling dynamics, leveraging the advantageous feature that the momentum variable is Euclidean despite that the potential function lives on a manifold. We then propose a Lie-group MCMC sampler, by delicately discretizing the resulting kinetic-Langevin-type sampling dynamics. The Lie group structure is exactly preserved by this discretization. Exponential convergence with explicit convergence rate for both the continuous dynamics and the discrete sampler are then proved under W2 distance. Only compactness of the Lie group and geodesically L-smoothness of the potential function are needed. To the best of our knowledge, this is the first convergence result for kinetic Langev
    
[^2]: 2023年机器学习中信任可视化的最新进展

    Visualization for Trust in Machine Learning Revisited: The State of the Field in 2023

    [https://arxiv.org/abs/2403.12005](https://arxiv.org/abs/2403.12005)

    2023年的研究显示，可解释和可信赖的机器学习可视化仍然是一个重要且不断发展的领域，为各种领域提供了趋势、见解和挑战。

    

    可解释和可信赖的机器学习可视化仍然是信息可视化和视觉分析领域中最重要和深入研究的领域之一，涉及医学、金融和生物信息学等各种应用领域。在我们2020年的最新报告中，包括了200种技术，我们坚持收集同行评审的文章，描述可视化技术，根据先前建立的包含119个类别的分类模式对其进行分类，并在在线调查浏览器中提供了542种技术的结果集。在本调查文章中，我们介绍了截至2023年秋季关于这一数据集的新分析结果，并讨论了在机器学习中使用可视化的趋势、见解和八个开放挑战。我们的结果证实了可视化技术在增加对机器学习模型的信任方面呈快速增长的趋势。

    arXiv:2403.12005v1 Announce Type: cross  Abstract: Visualization for explainable and trustworthy machine learning remains one of the most important and heavily researched fields within information visualization and visual analytics with various application domains, such as medicine, finance, and bioinformatics. After our 2020 state-of-the-art report comprising 200 techniques, we have persistently collected peer-reviewed articles describing visualization techniques, categorized them based on the previously established categorization schema consisting of 119 categories, and provided the resulting collection of 542 techniques in an online survey browser. In this survey article, we present the updated findings of new analyses of this dataset as of fall 2023 and discuss trends, insights, and eight open challenges for using visualizations in machine learning. Our results corroborate the rapidly growing trend of visualization techniques for increasing trust in machine learning models in the p
    
[^3]: 揭示无分类器引导的条件扩散模型：一个尖锐的统计理论

    Unveil Conditional Diffusion Models with Classifier-free Guidance: A Sharp Statistical Theory

    [https://arxiv.org/abs/2403.11968](https://arxiv.org/abs/2403.11968)

    本文揭示了无分类器引导的条件扩散模型的尖锐统计理论，提出了适应数据分布平滑度的样本复杂度界限，并展示了新颖的扩散泰勒逼近技术在理论发展中的重要性。

    

    arXiv:2403.11968v1 公告类型: 新 具有分类条件的扩散模型是现代图像合成的基础，在计算生物学和强化学习等领域得到广泛应用。在这些应用中，条件扩散模型结合各种条件信息，如提示输入，以引导样本生成到所需的属性。尽管经验上取得成功，但条件扩散模型的理论在很大程度上尚不完备。本文通过展示使用条件扩散模型进行分布估计的尖锐统计理论来弥合这一差距。我们的分析得出一个适应数据分布平滑度并匹配极小极值下限的样本复杂度界限。我们理论发展的关键在于条件评分函数的逼近结果，依赖于一种新颖的扩散泰勒逼近技术。此外，我们展示了我们的统计理论在...

    arXiv:2403.11968v1 Announce Type: new  Abstract: Conditional diffusion models serve as the foundation of modern image synthesis and find extensive application in fields like computational biology and reinforcement learning. In these applications, conditional diffusion models incorporate various conditional information, such as prompt input, to guide the sample generation towards desired properties. Despite the empirical success, theory of conditional diffusion models is largely missing. This paper bridges this gap by presenting a sharp statistical theory of distribution estimation using conditional diffusion models. Our analysis yields a sample complexity bound that adapts to the smoothness of the data distribution and matches the minimax lower bound. The key to our theoretical development lies in an approximation result for the conditional score function, which relies on a novel diffused Taylor approximation technique. Moreover, we demonstrate the utility of our statistical theory in 
    
[^4]: 神经网络回归的设计概率校准

    Probabilistic Calibration by Design for Neural Network Regression

    [https://arxiv.org/abs/2403.11964](https://arxiv.org/abs/2403.11964)

    提出了一种称为Quantile Recalibration Training的新型端到端模型训练过程，将后处理校准直接整合到训练过程中，无需额外参数，展示出在神经网络回归中提高校准性能的方法。

    

    为了在许多真实世界应用中进行最佳决策，为回归问题生成经过校准且精确的神经网络预测分布至关重要。为解决神经网络的误校准问题，提出了各种改善校准的方法，包括在训练后调整预测的后处理方法和在训练过程中进行操作的正则化方法。虽然与正则化方法相比，后处理方法在校准方面表现出更好的改进，但后处理步骤与模型训练完全独立。我们引入了一种称为Quantile Recalibration Training的新型端到端模型训练过程，将后处理校准直接整合到训练过程中，无需额外的参数。我们还提出了一个统一的算法，将我们的方法和其他后处理方法以及正则化方法作为特殊情况包含在内。我们展示了我们的方法在一个大规模问题上的性能。

    arXiv:2403.11964v1 Announce Type: new  Abstract: Generating calibrated and sharp neural network predictive distributions for regression problems is essential for optimal decision-making in many real-world applications. To address the miscalibration issue of neural networks, various methods have been proposed to improve calibration, including post-hoc methods that adjust predictions after training and regularization methods that act during training. While post-hoc methods have shown better improvement in calibration compared to regularization methods, the post-hoc step is completely independent of model training. We introduce a novel end-to-end model training procedure called Quantile Recalibration Training, integrating post-hoc calibration directly into the training process without additional parameters. We also present a unified algorithm that includes our method and other post-hoc and regularization methods, as particular cases. We demonstrate the performance of our method in a large
    
[^5]: 超越有界密度比的迁移学习

    Transfer Learning Beyond Bounded Density Ratios

    [https://arxiv.org/abs/2403.11963](https://arxiv.org/abs/2403.11963)

    低次多项式估计类上的迁移学习，证明了在非常温和的假设下，对于低次多项式来说非平凡的迁移学习是可能的，超越了$dQ/dP$有界的经典假设

    

    我们研究了迁移学习的基本问题，即学习算法从某个源分布$P$收集数据，但需要在不同的目标分布$Q$上表现良好。标准的测度变换论证表明，当密度比$dQ/dP$有界时发生迁移学习。然而，Kpotufe和Martinet(2018年COLT)以及Hanneke和Kpotufe(2019年NeurIPS)之前引人深思的作品展示了一些情况，其中比率$dQ/dP$是无界的，但迁移学习是可能的。在这项工作中，我们专注于在低次多项式估计类上进行迁移学习。我们的主要结果是在定义域$\mathbb{R}^n$上的一般迁移不等式，证明了在非常温和的假设下，对于低次多项式来说非平凡的迁移学习是可能的，远远超出了$dQ/dP$被有界的经典假设。例如，如果$Q$是对数凹测度，则始终适用。

    arXiv:2403.11963v1 Announce Type: new  Abstract: We study the fundamental problem of transfer learning where a learning algorithm collects data from some source distribution $P$ but needs to perform well with respect to a different target distribution $Q$. A standard change of measure argument implies that transfer learning happens when the density ratio $dQ/dP$ is bounded. Yet, prior thought-provoking works by Kpotufe and Martinet (COLT, 2018) and Hanneke and Kpotufe (NeurIPS, 2019) demonstrate cases where the ratio $dQ/dP$ is unbounded, but transfer learning is possible.   In this work, we focus on transfer learning over the class of low-degree polynomial estimators. Our main result is a general transfer inequality over the domain $\mathbb{R}^n$, proving that non-trivial transfer learning for low-degree polynomials is possible under very mild assumptions, going well beyond the classical assumption that $dQ/dP$ is bounded. For instance, it always applies if $Q$ is a log-concave measur
    
[^6]: CASPER：因果关系感知时空图神经网络用于时空时间序列插补

    CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation

    [https://arxiv.org/abs/2403.11960](https://arxiv.org/abs/2403.11960)

    CASPER提出了一种因果关系感知的方法来处理时空时间序列数据插补问题，避免过度利用非因果关系，提高数据分析的准确性。

    

    arXiv:2403.11960v1 公告类型：新 提要：时空时间序列是理解人类活动及其影响的基础，通常通过放置在不同位置的监测传感器收集。收集到的数据通常包含由于各种故障而导致的缺失值，这对数据分析有重要影响。为了填补缺失值，已经提出了许多方法。在恢复特定数据点时，大多数现有方法倾向于考虑与该点相关的所有信息，无论它们是否具有因果关系。在数据收集过程中，包括一些未知混杂因素是不可避免的，例如时间序列中的背景噪声和构建的传感器网络中的非因果快捷边。这些混杂因素可能在输入和输出之间开辟反向路径，换句话说，它们建立了输入和输出之间的非因果相关性。

    arXiv:2403.11960v1 Announce Type: new  Abstract: Spatiotemporal time series is the foundation of understanding human activities and their impacts, which is usually collected via monitoring sensors placed at different locations. The collected data usually contains missing values due to various failures, which have significant impact on data analysis. To impute the missing values, a lot of methods have been introduced. When recovering a specific data point, most existing methods tend to take into consideration all the information relevant to that point regardless of whether they have a cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths between the input and output, in other words, they establish non-causal correlations between the input and output. Over-exploiting these non-causa
    
[^7]: 基于中介因素的悲观因果强化学习用于混杂的离线数据

    Pessimistic Causal Reinforcement Learning with Mediators for Confounded Offline Data

    [https://arxiv.org/abs/2403.11841](https://arxiv.org/abs/2403.11841)

    提出了一种新的策略学习算法，PESCAL，利用基于前门标准的中介变量消除混杂偏差，并采用悲观原则处理候选策略引起的分布变化。

    

    在现实场景中，由随机实验收集的数据集往往受到时间和预算限制而规模有限。因此，利用大规模的观测数据集成为实现高质量策略学习更具吸引力的选择。然而，大多数现有的离线强化学习（RL）方法依赖于两个关键假设-- 非混杂性和正性-- 这两个假设在观测数据环境中经常不成立。鉴于这些挑战，我们提出了一种新颖的策略学习算法，称为悲观因果学习（PESCAL）。我们利用基于前门标准的中介变量来消除混杂偏差；此外，我们采用悲观原则来解决由候选策略引起的动作分布与生成观测数据的行为策略之间的分布变化。我们的关键观察是，通过融合辅助变量

    arXiv:2403.11841v1 Announce Type: cross  Abstract: In real-world scenarios, datasets collected from randomized experiments are often constrained by size, due to limitations in time and budget. As a result, leveraging large observational datasets becomes a more attractive option for achieving high-quality policy learning. However, most existing offline reinforcement learning (RL) methods depend on two key assumptions--unconfoundedness and positivity--which frequently do not hold in observational data contexts. Recognizing these challenges, we propose a novel policy learning algorithm, PESsimistic CAusal Learning (PESCAL). We utilize the mediator variable based on front-door criterion to remove the confounding bias; additionally, we adopt the pessimistic principle to address the distributional shift between the action distributions induced by candidate policies, and the behavior policy that generates the observational data. Our key observation is that, by incorporating auxiliary variable
    
[^8]: 使用高斯过程从偏好和选择中学习的教程

    A tutorial on learning from preferences and choices with Gaussian Processes

    [https://arxiv.org/abs/2403.11782](https://arxiv.org/abs/2403.11782)

    提供了一个使用高斯过程进行偏好学习的框架，能够将理性原则融入学习过程，涵盖了多种偏好学习模型。

    

    偏好建模位于经济学、决策理论、机器学习和统计学的交叉点。通过理解个体的偏好及其选择方式，我们可以构建更接近他们期望的产品，为跨领域的更高效、个性化应用铺平道路。此教程的目标是提供一个连贯、全面的偏好学习框架，使用高斯过程演示如何将理性原则（来自经济学和决策理论）无缝地纳入学习过程中。通过合适地定制似然函数，这一框架使得能够构建涵盖随机效用模型、辨识限制和对象和标签偏好的多重冲突效用情景的偏好学习模型。

    arXiv:2403.11782v1 Announce Type: new  Abstract: Preference modelling lies at the intersection of economics, decision theory, machine learning and statistics. By understanding individuals' preferences and how they make choices, we can build products that closely match their expectations, paving the way for more efficient and personalised applications across a wide range of domains. The objective of this tutorial is to present a cohesive and comprehensive framework for preference learning with Gaussian Processes (GPs), demonstrating how to seamlessly incorporate rationality principles (from economics and decision theory) into the learning process. By suitably tailoring the likelihood function, this framework enables the construction of preference learning models that encompass random utility models, limits of discernment, and scenarios with multiple conflicting utilities for both object- and label-preference. This tutorial builds upon established research while simultaneously introducin
    
[^9]: PARMESAN: 用于密集预测任务的无参数内存搜索与转导

    PARMESAN: Parameter-Free Memory Search and Transduction for Dense Prediction Tasks

    [https://arxiv.org/abs/2403.11743](https://arxiv.org/abs/2403.11743)

    通过引入转导的概念，提出了PARMESAN，一种用于解决密集预测任务的无参数内存搜索和转导方法，实现了灵活性和无需连续训练的学习。

    

    在这项工作中，我们通过转导推理来解决深度学习中的灵活性问题。我们提出了PARMESAN（无参数内存搜索与转导），这是一种可扩展的转导方法，利用内存模块来解决密集预测任务。在推断过程中，内存中的隐藏表示被搜索以找到相应的示例。与其他方法不同，PARMESAN通过修改内存内容学习，而无需进行任何连续训练或微调可学习参数。我们的方法与常用的神经结构兼容。

    arXiv:2403.11743v1 Announce Type: new  Abstract: In this work we address flexibility in deep learning by means of transductive reasoning. For adaptation to new tasks or new data, existing methods typically involve tuning of learnable parameters or even complete re-training from scratch, rendering such approaches unflexible in practice. We argue that the notion of separating computation from memory by the means of transduction can act as a stepping stone for solving these issues. We therefore propose PARMESAN (parameter-free memory search and transduction), a scalable transduction method which leverages a memory module for solving dense prediction tasks. At inference, hidden representations in memory are being searched to find corresponding examples. In contrast to other methods, PARMESAN learns without the requirement for any continuous training or fine-tuning of learnable parameters simply by modifying the memory content. Our method is compatible with commonly used neural architecture
    
[^10]: 光谱算法的泛化误差

    Generalization error of spectral algorithms

    [https://arxiv.org/abs/2403.11696](https://arxiv.org/abs/2403.11696)

    本研究考虑了使用光谱算法来训练核，推导出泛化误差函数，提供了完整的损失渐近行为，展示了损失在特定频谱尺度上的局部化。

    

    近期关注核方法泛化的渐近精确估计，源于神经网络及其相关核之间的类比。然而，以往的研究是通过核岭回归（KRR）推导出这些估计值，而神经网络通常是通过梯度下降（GD）进行训练。本研究考虑了使用由配置文件$h(\lambda)$指定的一系列“光谱算法”来训练核，其中包括KRR和GD作为特例。然后，我们推导出关于两种数据模型的学习配置文件$h(\lambda)$的泛化误差函数：高维高斯模型和低维平移不变模型。在对核和目标的频谱进行幂律假设的情况下，我们利用我们的框架来(i)为有噪和无噪观测提供完整的损失渐近行为；(ii)展示损失出现在某些频谱尺度上的局部化，

    arXiv:2403.11696v1 Announce Type: new  Abstract: The asymptotically precise estimation of the generalization of kernel methods has recently received attention due to the parallels between neural networks and their associated kernels. However, prior works derive such estimates for training by kernel ridge regression (KRR), whereas neural networks are typically trained with gradient descent (GD). In the present work, we consider the training of kernels with a family of $\textit{spectral algorithms}$ specified by profile $h(\lambda)$, and including KRR and GD as special cases. Then, we derive the generalization error as a functional of learning profile $h(\lambda)$ for two data models: high-dimensional Gaussian and low-dimensional translation-invariant model. Under power-law assumptions on the spectrum of the kernel and target, we use our framework to (i) give full loss asymptotics for both noisy and noiseless observations (ii) show that the loss localizes on certain spectral scales, givi
    
[^11]: 非光滑隐式微分：确定性和随机收敛速率

    Nonsmooth Implicit Differentiation: Deterministic and Stochastic Convergence Rates

    [https://arxiv.org/abs/2403.11687](https://arxiv.org/abs/2403.11687)

    在非光滑设置下，提出了用于计算具有内映射的外映射固定点的隐式导数的新方法NSID，并提供了确定性情况下迭代微分（ITD）和近似隐式微分（AID）的改进线性收敛速率。

    

    我们研究了有效计算参数化不可微收缩映射固定点导数的问题。这个问题在机器学习中有广泛的应用，包括超参数优化、元学习和数据污染攻击。我们分析了两种流行的方法：迭代微分（ITD）和近似隐式微分（AID）。在非光滑设置中的一个关键挑战是链规则不再成立。在Bolte等人（2022）最近的工作基础上，他们证明了不可微分ITD的线性收敛，我们提供了确定性情况下ITD和AID的改进线性收敛速率。我们进一步介绍了NSID，一种新的方法，用于在固定点被定义为只通过随机无偏估计器访问的外映射和内映射的组合时计算隐式导数。我们建立了该方法的收敛速率。

    arXiv:2403.11687v1 Announce Type: cross  Abstract: We study the problem of efficiently computing the derivative of the fixed-point of a parametric non-differentiable contraction map. This problem has wide applications in machine learning, including hyperparameter optimization, meta-learning and data poisoning attacks. We analyze two popular approaches: iterative differentiation (ITD) and approximate implicit differentiation (AID). A key challenge behind the nonsmooth setting is that the chain rule does not hold anymore. Building upon the recent work by Bolte et al. (2022), who proved the linear convergence of non-differentiable ITD, we provide refined linear convergence rates for both ITD and AID in the deterministic case. We further introduce NSID, a new method to compute the implicit derivative when the fixed point is defined as the composition of an outer map and an inner map which is accessible only through a stochastic unbiased estimator. We establish rates for the convergence of 
    
[^12]: 强化学习中未来奖励先知的价值

    The Value of Reward Lookahead in Reinforcement Learning

    [https://arxiv.org/abs/2403.11637](https://arxiv.org/abs/2403.11637)

    分析了在强化学习中利用部分未来奖励先知的价值，通过竞争性分析得出了最坏情况下奖励期望的精确比率。

    

    在强化学习（RL）中，代理们与不断变化的环境进行顺序交互，旨在最大化获得的奖励。通常情况下，奖励仅在行动后被观察到，因此目标是最大化预期累积奖励。然而，在许多实际场景中，奖励信息是提前观察到的 -- 交易前观察到价格；了解部分附近交通信息；经常在互动之前为代理分配目标。在这项工作中，我们旨在通过竞争性分析的视角，定量分析这种未来奖励信息的价值。特别地，我们测量了标准RL代理的价值与具有部分未来奖励先知的代理之间的比率。我们刻画了最坏情况下的奖励分布，并推导出最坏情况下奖励期望的精确比率。令人惊讶的是，结果比率与离线RL和r中已知的数量有关。

    arXiv:2403.11637v1 Announce Type: new  Abstract: In reinforcement learning (RL), agents sequentially interact with changing environments while aiming to maximize the obtained rewards. Usually, rewards are observed only after acting, and so the goal is to maximize the expected cumulative reward. Yet, in many practical settings, reward information is observed in advance -- prices are observed before performing transactions; nearby traffic information is partially known; and goals are oftentimes given to agents prior to the interaction. In this work, we aim to quantifiably analyze the value of such future reward information through the lens of competitive analysis. In particular, we measure the ratio between the value of standard RL agents and that of agents with partial future-reward lookahead. We characterize the worst-case reward distribution and derive exact ratios for the worst-case reward expectations. Surprisingly, the resulting ratios relate to known quantities in offline RL and r
    
[^13]: 应该使用符合预测进行分布外检测（反之亦然？）

    Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)

    [https://arxiv.org/abs/2403.11532](https://arxiv.org/abs/2403.11532)

    本研究提出使用符合预测来评估分布外（OOD）检测中效率的新方法，并定义了新的符合AUROC和符合FRP@TPR95指标，为OOD和异常检测基准提供了概率保守性保证。

    

    关于分布外（OOD）检测的研究主要集中在构建有效区分OOD数据和分布内（ID）数据的分数上。另一方面，符合预测（CP）使用非一致性分数构建具有概率覆盖保证的预测集。在这项工作中，我们提出使用CP更好地评估OOD分数的效率。具体而言，我们强调在标准OOD基准设置中，由于测试数据集的有限样本大小，评估指标可能过于乐观。基于（Bates等人，2022）的工作，我们定义了新的符合AUROC和符合FRP@TPR95指标，这些修正提供了关于这些指标变异性的概率保守性保证。我们展示了这些修正对两个参考OOD和异常检测基准OpenOOD（Yang等人，2022）和AD-Bench（Han等人，2022）的影响。我们还展示了我们的作用的好处

    arXiv:2403.11532v1 Announce Type: cross  Abstract: Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In this work, we propose to use CP to better assess the efficiency of OOD scores. Specifically, we emphasize that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the finite sample size of the test dataset. Based on the work of (Bates et al., 2022), we define new conformal AUROC and conformal FRP@TPR95 metrics, which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics. We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al., 2022) and ADBench (Han et al., 2022). We also show that the benefits of us
    
[^14]: 分离状态SARSA: 一种具有恢复奖励的实用序贯决策算法

    State-Separated SARSA: A Practical Sequential Decision-Making Algorithm with Recovering Rewards

    [https://arxiv.org/abs/2403.11520](https://arxiv.org/abs/2403.11520)

    提出了分离状态SARSA（SS-SARSA）算法，针对恢复老虎机场景设计，通过将轮数视为状态，降低Q-learning/SARSA所需的状态组合数量，实现有效学习，并在温和假设下证明了渐近收敛至最优策略。

    

    虽然许多多臂老虎机算法假设所有臂的奖励在各轮之间保持不变，但在许多现实场景中，这种假设并不成立。本文考虑了恢复老虎机的设置，其中奖励取决于自上次拉动臂以来经过的轮数。我们提出了一种新的适用于这种情况的强化学习（RL）算法，名为分离状态SARSA（SS-SARSA）算法，其中将各轮视为状态。 SS-SARSA算法通过减少Q-learning/SARSA所需的状态组合数量来实现高效学习，这在大规模RL问题中经常遇到组合问题。此外，它对奖励结构进行最少假设并提供较低的计算复杂度。此外，我们证明在温和假设下渐近收敛至最优策略。模拟研究证明

    arXiv:2403.11520v1 Announce Type: new  Abstract: While many multi-armed bandit algorithms assume that rewards for all arms are constant across rounds, this assumption does not hold in many real-world scenarios. This paper considers the setting of recovering bandits (Pike-Burke & Grunewalder, 2019), where the reward depends on the number of rounds elapsed since the last time an arm was pulled. We propose a new reinforcement learning (RL) algorithm tailored to this setting, named the State-Separate SARSA (SS-SARSA) algorithm, which treats rounds as states. The SS-SARSA algorithm achieves efficient learning by reducing the number of state combinations required for Q-learning/SARSA, which often suffers from combinatorial issues for large-scale RL problems. Additionally, it makes minimal assumptions about the reward structure and offers lower computational complexity. Furthermore, we prove asymptotic convergence to an optimal policy under mild assumptions. Simulation studies demonstrate the
    
[^15]: CLIP总是比ImageNet模型泛化更好吗？

    Do CLIPs Always Generalize Better than ImageNet Models?

    [https://arxiv.org/abs/2403.11497](https://arxiv.org/abs/2403.11497)

    CLIP模型在面对分布转移时表现出良好的泛化能力，作者设计了CounterAnimal数据集来探究模型对虚假特征的依赖性。

    

    大型视觉语言模型，例如CLIP，已经彻底改变了现代机器学习。CLIP展示了在分布转移下的良好泛化能力，得到了越来越多的文献支持。然而，CLIP的评估数据集主要是为ImageNet基准而设计的变种，可能不能完全反映CLIP在LAION等上进行预训练时对虚假相关性的稳健性。为了弥补这一差距，我们收集了一个真实世界数据集，名为CounterAnimal，其中包含动物照片中发现的现实虚假特征。CounterAnimal包括a）常见组：包括常见背景的动物，并且 b) 对照组：包括在不寻常背景下的动物。从常见组到对照组的性能下降量化了模型对虚假特征（即背景）预测动物的依赖性。我们发现，在LAION或OpenAI数据上进行训练的CLIP即没有

    arXiv:2403.11497v1 Announce Type: cross  Abstract: Large vision language models, such as CLIPs, have revolutionized modern machine learning. CLIPs have demonstrated great generalizability under distribution shifts, supported by an increasing body of literature. However, the evaluation datasets for CLIPs are variations primarily designed for ImageNet benchmarks, which may not fully reflect the extent to which CLIPs, e.g., pre-trained on LAION, robust to spurious correlations. To bridge the gap, we collect a real-world dataset called CounterAnimal that contains realistic spurious features found in animal photos. CounterAnimal consists of a) the common group: comprising animals on common backgrounds, and b) the counter group: including animals on unusual backgrounds. The performance drops from the common to counter groups quantify the reliance of models on spurious features (i.e., backgrounds) to predict the animals. We find that CLIPs trained on either LAION or the OpenAI data exhibit no
    
[^16]: 弱通信和一般平均奖赏MDPs的基于跨度的最佳样本复杂度

    Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs

    [https://arxiv.org/abs/2403.11477](https://arxiv.org/abs/2403.11477)

    该研究提出了对于弱通信MDPs的样本复杂度界限为 $\tilde{O}(SA\frac{H}{\epsilon^2})$，改进了现有工作，是在所有参数上最小最优的。

    

    我们研究了在生成模型下学习平均奖赏马尔可夫决策过程（MDP）中$\epsilon$-最佳策略的样本复杂度。对于弱通信MDPs，我们建立了复杂度界限为$\tilde{O}(SA\frac{H}{\epsilon^2})$，其中$H$是最优策略的偏差函数的跨度，$SA$是状态-动作空间的基数。我们的结果是在所有参数$S,A,H$和$\epsilon$上（最多对数因子）最小最优的，改进了现有工作，现有工作要么假设所有策略的混合时间均匀有界，要么对参数有次优的依赖。我们进一步研究一般（非弱通信）平均奖赏MDPs中的样本复杂度。我们认为需要一个新的瞬态时间参数$B$，建立了一个$\tilde{O}(SA\frac{B+H}{\epsilon^2})$的复杂度界限，并证明了匹配的（最多对数因子）最小最优下界。这两个结果都是基于减少

    arXiv:2403.11477v1 Announce Type: new  Abstract: We study the sample complexity of learning an $\epsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. For weakly communicating MDPs, we establish the complexity bound $\tilde{O}(SA\frac{H}{\epsilon^2})$, where $H$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,H$ and $\epsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters. We further investigate sample complexity in general (non-weakly-communicating) average-reward MDPs. We argue a new transient time parameter $B$ is necessary, establish an $\tilde{O}(SA\frac{B+H}{\epsilon^2})$ complexity bound, and prove a matching (up to log factors) minimax lower bound. Both results are based on reducing the
    
[^17]: 分布式分隔后验采样用于去噪扩散先验

    Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors

    [https://arxiv.org/abs/2403.11407](https://arxiv.org/abs/2403.11407)

    通过利用去噪扩散模型先验结构，提出了一种分布式分隔后验采样方法，相比先前的方法具有更低的逼近误差。

    

    近年来，对于使用去噪扩散模型（DDM）作为逆贝叶斯问题求解的先验引起了极大的兴趣。然而，从结果后验分布中抽样是一个挑战。为了解决这个问题，先前的研究提出了近似方法来偏置扩散的漂移项。在本工作中，我们采取了一种不同的方法，并利用DDM先验的特定结构来定义一组中间和更简单的后验抽样问题，相比先前的方法，这些方法具有更低的逼近误差。我们通过使用合成例子和各种图像恢复任务来实证地展示我们方法对于一般线性逆问题的重构能力。

    arXiv:2403.11407v1 Announce Type: cross  Abstract: Interest in the use of Denoising Diffusion Models (DDM) as priors for solving inverse Bayesian problems has recently increased significantly. However, sampling from the resulting posterior distribution poses a challenge. To solve this problem, previous works have proposed approximations to bias the drift term of the diffusion. In this work, we take a different approach and utilize the specific structure of the DDM prior to define a set of intermediate and simpler posterior sampling problems, resulting in a lower approximation error compared to previous methods. We empirically demonstrate the reconstruction capability of our method for general linear inverse problems using synthetic examples and various image restoration tasks.
    
[^18]: 基于SDP的二分图聚类分支定界算法

    An SDP-based Branch-and-Cut Algorithm for Biclustering

    [https://arxiv.org/abs/2403.11351](https://arxiv.org/abs/2403.11351)

    提出了一个基于SDP的分支定界算法，用于解决$k$-最密不相交双团问题。

    

    二分图聚类，也称为共聚类、块聚类或双向聚类，涉及将数据矩阵的行和列同时聚类成不同的组，使得同一组内的行和列显示出相似的模式。作为二分图聚类的模型问题，我们考虑$k$-最密不相交双团问题，其目标是在给定加权完全二分图中识别 $k$ 个不相交的完全二部子图（称为双团），使它们的密度之和最大化。为了解决这个问题，我们提出了一个定制的分支定界算法。对于上界例程，我们考虑半定规划放松并提出了用于加强界限的有效不等式。我们使用一种一阶方法以切平面方式解决这个放松问题。对于下界，我们设计了一个利用解决方案的最大权匹配舍入过程。

    arXiv:2403.11351v1 Announce Type: cross  Abstract: Biclustering, also called co-clustering, block clustering, or two-way clustering, involves the simultaneous clustering of both the rows and columns of a data matrix into distinct groups, such that the rows and columns within a group display similar patterns. As a model problem for biclustering, we consider the $k$-densest-disjoint biclique problem, whose goal is to identify $k$ disjoint complete bipartite subgraphs (called bicliques) of a given weighted complete bipartite graph such that the sum of their densities is maximized. To address this problem, we present a tailored branch-and-cut algorithm. For the upper bound routine, we consider a semidefinite programming relaxation and propose valid inequalities to strengthen the bound. We solve this relaxation in a cutting-plane fashion using a first-order method. For the lower bound, we design a maximum weight matching rounding procedure that exploits the solution of the relaxation solved
    
[^19]: COLEP: 通过概率电路实现可证实鲁棒学习推理一致性预测

    COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits

    [https://arxiv.org/abs/2403.11348](https://arxiv.org/abs/2403.11348)

    通过概率电路，提出了COLEP框架，实现了可证实鲁棒学习推理一致性预测，其特点在于训练统计模型学习不同语义概念，并利用概率电路实现精确高效推理

    

    参考类型：交叉  摘要：一致性预测已经显示出在为任意黑匣子机器学习模型构建统计严谨的预测集方面表现出色，假设数据是可交换的。然而，即使在推理过程中进行微小的对抗性扰动也可能违反可交换性假设，挑战覆盖率保证，并导致后续实证覆盖率的下降。在这项工作中，我们提出了一个通过概率电路实现可证实鲁棒学习推理的一致性预测框架（COLEP），其中包括一个数据驱动的学习组件，用于训练统计模型以学习不同的语义概念，以及一个用于编码知识并表征训练模型之间关系的推理组件。为了实现精确和高效的推理，我们在推理组件内部使用了概率电路（PCs）。在理论上，我们提供了完整的预测认证

    arXiv:2403.11348v1 Announce Type: cross  Abstract: Conformal prediction has shown spurring performance in constructing statistically rigorous prediction sets for arbitrary black-box machine learning models, assuming the data is exchangeable. However, even small adversarial perturbations during the inference can violate the exchangeability assumption, challenge the coverage guarantees, and result in a subsequent decline in empirical coverage. In this work, we propose a certifiably robust learning-reasoning conformal prediction framework (COLEP) via probabilistic circuits, which comprise a data-driven learning component that trains statistical models to learn different semantic concepts, and a reasoning component that encodes knowledge and characterizes the relationships among the trained models for logic reasoning. To achieve exact and efficient reasoning, we employ probabilistic circuits (PCs) within the reasoning component. Theoretically, we provide end-to-end certification of predict
    
[^20]: 具有差分隐私的联邦迁移学习

    Federated Transfer Learning with Differential Privacy

    [https://arxiv.org/abs/2403.11343](https://arxiv.org/abs/2403.11343)

    本文提出了具有差分隐私的联邦迁移学习框架，通过利用多个异构源数据集的信息来增强对目标数据集的学习，同时考虑隐私约束。

    

    联邦学习越来越受到欢迎，数据异构性和隐私性是两个突出的挑战。在本文中，我们在联邦迁移学习框架内解决了这两个问题，旨在通过利用来自多个异构源数据集的信息来增强对目标数据集的学习，同时遵守隐私约束。我们严格制定了\textit{联邦差分隐私}的概念，为每个数据集提供隐私保证，而无需假设有一个受信任的中央服务器。在这个隐私约束下，我们研究了三个经典的统计问题，即单变量均值估计、低维线性回归和高维线性回归。通过研究极小值率并确定这些问题的隐私成本，我们展示了联邦差分隐私是已建立的局部和中央模型之间的一种中间隐私模型。

    arXiv:2403.11343v1 Announce Type: new  Abstract: Federated learning is gaining increasing popularity, with data heterogeneity and privacy being two prominent challenges. In this paper, we address both issues within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of \textit{federated differential privacy}, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy constraint, we study three classical statistical problems, namely univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and identifying the costs of privacy for these problems, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of 
    
[^21]: 先验依赖性分析基于函数逼近的后验抽样强化学习

    Prior-dependent analysis of posterior sampling reinforcement learning with function approximation

    [https://arxiv.org/abs/2403.11175](https://arxiv.org/abs/2403.11175)

    该研究提出了首个先验依赖性贝叶斯遗憾上界，并对后验抽样强化学习进行了改进分析，提出了一个新的上界结果，实现了对先前基准的方法论提升。

    

    这项研究在对线性混合MDPs建模的函数逼近强化学习（RL）中推进了随机探索。我们为具有函数逼近的RL建立了首个先验依赖性贝叶斯遗憾上界；并且改进了用于后验抽样强化学习（PSRL）的贝叶斯遗憾分析，提出了一个上界为${\mathcal{O}}(d\sqrt{H^3 T \log T})$的结果，其中$d$表示转移核的维度，$H$表示规划视野，$T$表示总交互次数。 这表示通过优化$\mathcal{O}(\sqrt{\log T})$因子，我们在之前针对线性混合MDPs的基准（Osband和Van Roy，2014）上取得了方法论上的提升。我们的方法，利用价值定向模型学习的视角，引入了一种解耦论证和方差缩减技术，超越了传统分析依赖于置信区间和集中不等式的限制。

    arXiv:2403.11175v1 Announce Type: cross  Abstract: This work advances randomized exploration in reinforcement learning (RL) with function approximation modeled by linear mixture MDPs. We establish the first prior-dependent Bayesian regret bound for RL with function approximation; and refine the Bayesian regret analysis for posterior sampling reinforcement learning (PSRL), presenting an upper bound of ${\mathcal{O}}(d\sqrt{H^3 T \log T})$, where $d$ represents the dimensionality of the transition kernel, $H$ the planning horizon, and $T$ the total number of interactions. This signifies a methodological enhancement by optimizing the $\mathcal{O}(\sqrt{\log T})$ factor over the previous benchmark (Osband and Van Roy, 2014) specified to linear mixture MDPs. Our approach, leveraging a value-targeted model learning perspective, introduces a decoupling argument and a variance reduction technique, moving beyond traditional analyses reliant on confidence sets and concentration inequalities to f
    
[^22]: 基于高斯过程回归的机器学习系统可靠性分析

    Machine learning-based system reliability analysis with Gaussian Process Regression

    [https://arxiv.org/abs/2403.11125](https://arxiv.org/abs/2403.11125)

    本文提出了基于高斯过程回归的机器学习系统可靠性分析方法，并通过几个定理探讨了最优学习策略，包括考虑和忽略样本之间的相关性以及顺序多个训练样本增益的理论最优策略。

    

    arXiv:2403.11125v1 公告类型: 交叉 摘要: 基于机器学习的可靠性分析方法在计算效率和准确性方面取得了巨大进展。最近，已经提出许多有效的学习策略来增强计算性能。然而，其中很少有人探讨了理论上的最优学习策略。在这篇文章中，我们提出了几个定理来促进这种探索。具体来说，详细阐述了考虑和忽略候选设计样本之间相关性的情况。此外，我们证明了众所周知的 U 学习函数可以重新制定为在忽略 Kriging 相关性的情况下的最优学习函数。此外，还通过带有相应损失函数的贝叶斯估计数学上探讨了顺序多个训练样本增益的理论上最优学习策略。模拟结果表明最优学习策略……

    arXiv:2403.11125v1 Announce Type: cross  Abstract: Machine learning-based reliability analysis methods have shown great advancements for their computational efficiency and accuracy. Recently, many efficient learning strategies have been proposed to enhance the computational performance. However, few of them explores the theoretical optimal learning strategy. In this article, we propose several theorems that facilitates such exploration. Specifically, cases that considering and neglecting the correlations among the candidate design samples are well elaborated. Moreover, we prove that the well-known U learning function can be reformulated to the optimal learning function for the case neglecting the Kriging correlation. In addition, the theoretical optimal learning strategy for sequential multiple training samples enrichment is also mathematically explored through the Bayesian estimate with the corresponding lost functions. Simulation results show that the optimal learning strategy consid
    
[^23]: 在序列任务设置中最小化局部遗憾的谬误

    The Fallacy of Minimizing Local Regret in the Sequential Task Setting

    [https://arxiv.org/abs/2403.10946](https://arxiv.org/abs/2403.10946)

    研究了强化学习中在序列任务设置下最小化局部遗憾的谬误，揭示了近视地最小化遗憾在实际应用中的复杂性。

    

    在强化学习领域，在线强化学习经常被概念化为一个优化问题，其中算法与未知环境交互以最小化累积遗憾。在静态设置中，可以获得强大的理论保证，如次线性（$\sqrt{T}$）遗憾界限，通常意味着收敛到最优策略并停止探索。然而，这些理论设置通常过分简化了真实世界强化学习实现中遇到的复杂性，其中任务按顺序到达，任务之间有重大变化，并且算法可能不允许在某些任务中进行自适应学习。我们研究超出结果分布的变化，涵盖奖励设计（从结果到奖励的映射）和允许的策略空间的变化。我们的结果揭示了在每个任务中近视地最小化遗憾的谬误：获得最优遗憾r

    arXiv:2403.10946v1 Announce Type: cross  Abstract: In the realm of Reinforcement Learning (RL), online RL is often conceptualized as an optimization problem, where an algorithm interacts with an unknown environment to minimize cumulative regret. In a stationary setting, strong theoretical guarantees, like a sublinear ($\sqrt{T}$) regret bound, can be obtained, which typically implies the convergence to an optimal policy and the cessation of exploration. However, these theoretical setups often oversimplify the complexities encountered in real-world RL implementations, where tasks arrive sequentially with substantial changes between tasks and the algorithm may not be allowed to adaptively learn within certain tasks. We study the changes beyond the outcome distributions, encompassing changes in the reward designs (mappings from outcomes to rewards) and the permissible policy spaces. Our results reveal the fallacy of myopically minimizing regret within each task: obtaining optimal regret r
    
[^24]: 神经网络的函数空间参数化用于序列学习

    Function-space Parameterization of Neural Networks for Sequential Learning

    [https://arxiv.org/abs/2403.10929](https://arxiv.org/abs/2403.10929)

    提出了一种神经网络的函数空间参数化方法，能够在序列学习中有效整合新数据并保留先前知识，同时在不重新训练的情况下合并新数据。

    

    由于在梯度下降深度学习中难以整合新数据并保留先前知识，顺序学习范式提出了挑战。虽然高斯过程优雅地解决了这些问题，但在处理诸如图像之类的丰富输入和伸缩性方面存在困难。为了解决这些问题，我们引入了一种将神经网络从权重空间转换到函数空间的技术，即双参数化。我们的参数化提供了：(i) 通过稀疏化将函数空间方法扩展到大数据集的途径，(ii) 在访问过去数据受限的情况下保留先前知识，以及(iii) 在不重新训练的情况下合并新数据的机制。我们的实验表明，我们可以在持续学习中保留知识，并有效地合并新数据。我们进一步展示了其在不确定性量化和引导基于模型的RL中探索的优点。

    arXiv:2403.10929v1 Announce Type: cross  Abstract: Sequential learning paradigms pose challenges for gradient-based deep learning due to difficulties incorporating new data and retaining prior knowledge. While Gaussian processes elegantly tackle these problems, they struggle with scalability and handling rich inputs, such as images. To address these issues, we introduce a technique that converts neural networks from weight space to function space, through a dual parameterization. Our parameterization offers: (i) a way to scale function-space methods to large data sets via sparsification, (ii) retention of prior knowledge when access to past data is limited, and (iii) a mechanism to incorporate new data without retraining. Our experiments demonstrate that we can retain knowledge in continual learning and incorporate new data efficiently. We further show its strengths in uncertainty quantification and guiding exploration in model-based RL. Further information and code is available on the
    
[^25]: TabPFN的可解释机器学习

    Interpretable Machine Learning for TabPFN

    [https://arxiv.org/abs/2403.10923](https://arxiv.org/abs/2403.10923)

    TabPFN模型在低数据情况下实现了良好的分类性能，并能够以秒级速度生成后验预测分布，我们提出了几种专为TabPFN设计的可解释性方法的改进，实现了更高效的计算。

    

    最近开发的Prior-Data Fitted Networks（PFNs）已经显示出在低数据情况下具有非常有希望的应用结果。TabPFN模型是PFN的一种特殊情况，适用于表格数据，在不需要学习参数或超参数调整的情况下，能够在短短几秒钟内实现多种分类任务的最先进性能，并且能够生成后验预测分布。TabPFN因此成为了许多领域应用中非常吸引人的选择。然而，该方法的一个主要缺点是缺乏可解释性。因此，我们提出了几种针对TabPFN专门设计的流行解释性方法的改进。通过利用该模型的独特性质，我们的改进允许比现有实现更高效的计算。特别是，我们展示了通过避免...

    arXiv:2403.10923v1 Announce Type: cross  Abstract: The recently developed Prior-Data Fitted Networks (PFNs) have shown very promising results for applications in low-data regimes. The TabPFN model, a special case of PFNs for tabular data, is able to achieve state-of-the-art performance on a variety of classification tasks while producing posterior predictive distributions in mere seconds by in-context learning without the need for learning parameters or hyperparameter tuning. This makes TabPFN a very attractive option for a wide range of domain applications. However, a major drawback of the method is its lack of interpretability. Therefore, we propose several adaptations of popular interpretability methods that we specifically design for TabPFN. By taking advantage of the unique properties of the model, our adaptations allow for more efficient computations than existing implementations. In particular, we show how in-context learning facilitates the estimation of Shapley values by avoid
    
[^26]: DTOR：决策树异常值回归器用于解释异常

    DTOR: Decision Tree Outlier Regressor to explain anomalies

    [https://arxiv.org/abs/2403.10903](https://arxiv.org/abs/2403.10903)

    DTOR是一种决策树异常值回归器，通过估计异常检测模型生成的异常分数来产生基于规则的解释，具有鲁棒性，适用于具有大量特征数据集。

    

    解释异常值的出现以及其产生机制在各种领域中可能非常重要。故障、欺诈、威胁等问题，除了被正确识别之外，通常需要有效的解释以有效执行可操作的对抗措施。越来越广泛地使用复杂的机器学习方法来识别异常值，使得这样的解释更具挑战性。我们提出了决策树异常值回归器（DTOR），这是一种通过估计异常检测模型生成的异常分数来为单个数据点生成基于规则的解释的技术。这是通过首先应用决策树回归器来计算估计分数，然后提取与数据点分数相关联的相对路径来实现的。我们的结果表明，即使在具有大量特征的数据集中，DTOR的鲁棒性也得到了证实。此外，与其他基于规则的方法相比

    arXiv:2403.10903v1 Announce Type: cross  Abstract: Explaining outliers occurrence and mechanism of their occurrence can be extremely important in a variety of domains. Malfunctions, frauds, threats, in addition to being correctly identified, oftentimes need a valid explanation in order to effectively perform actionable counteracts. The ever more widespread use of sophisticated Machine Learning approach to identify anomalies make such explanations more challenging. We present the Decision Tree Outlier Regressor (DTOR), a technique for producing rule-based explanations for individual data points by estimating anomaly scores generated by an anomaly detection model. This is accomplished by first applying a Decision Tree Regressor, which computes the estimation score, and then extracting the relative path associated with the data point score. Our results demonstrate the robustness of DTOR even in datasets with a large number of features. Additionally, in contrast to other rule-based approac
    
[^27]: 列表样本压缩和均匀收敛

    List Sample Compression and Uniform Convergence

    [https://arxiv.org/abs/2403.10889](https://arxiv.org/abs/2403.10889)

    研究在列表学习中均匀收敛和样本压缩原则的适用性，证明了在列表PAC学习中均匀收敛仍然等价于可学习性

    

    列表学习是监督分类的一个变种，在这种学习中，学习器为每个实例输出多个可能的标签，而不仅仅是一个。我们研究了与列表学习上的泛化相关的经典原则。我们的主要目标是确定在列表PAC学习领域，PAC设置中的经典原则是否保留其适用性。我们重点关注均匀收敛（这是经验风险最小化的基础）和样本压缩（这是Occam's Razor的一个强大体现）。在经典PAC学习中，均匀收敛和样本压缩都满足一种“完备性”形式：每当一个类是可学习的时候，也可以通过遵循这些原则的学习规则来学习它。我们探讨在列表学习环境中是否也存在相同的完备性。我们表明在列表PAC学习环境中，均匀收敛仍然等价于可学习性。

    arXiv:2403.10889v1 Announce Type: new  Abstract: List learning is a variant of supervised classification where the learner outputs multiple plausible labels for each instance rather than just one. We investigate classical principles related to generalization within the context of list learning. Our primary goal is to determine whether classical principles in the PAC setting retain their applicability in the domain of list PAC learning. We focus on uniform convergence (which is the basis of Empirical Risk Minimization) and on sample compression (which is a powerful manifestation of Occam's Razor). In classical PAC learning, both uniform convergence and sample compression satisfy a form of `completeness': whenever a class is learnable, it can also be learned by a learning rule that adheres to these principles. We ask whether the same completeness holds true in the list learning setting.   We show that uniform convergence remains equivalent to learnability in the list PAC learning setting
    
[^28]: 神经核条件均值嵌入

    Neural-Kernel Conditional Mean Embeddings

    [https://arxiv.org/abs/2403.10859](https://arxiv.org/abs/2403.10859)

    结合深度学习和CME的神经网络方法，解决了核条件均值嵌入面临的可伸缩性和表现力挑战，并在条件密度估计任务和强化学习中展现出卓越性能。

    

    核条件均值嵌入（CME）为表示条件分布提供了强大的框架，但通常面临可伸缩性和表现力挑战。在这项工作中，我们提出了一种新方法，有效地结合了深度学习与CME，以解决这些挑战。具体而言，我们的方法利用端到端神经网络（NN）优化框架，使用基于核的目标函数。这种设计避免了当前CME方法所需的计算昂贵的Gram矩阵求逆。为进一步提高性能，我们提供了有效的策略来优化剩余的核超参数。在条件密度估计任务中，我们的NN-CME混合方法实现了竞争性能，并常常超过现有基于深度学习的方法。最后，我们展示了其在无缝集成到强化学习（RL）环境中的卓越多功能性。

    arXiv:2403.10859v1 Announce Type: cross  Abstract: Kernel conditional mean embeddings (CMEs) offer a powerful framework for representing conditional distribution, but they often face scalability and expressiveness challenges. In this work, we propose a new method that effectively combines the strengths of deep learning with CMEs in order to address these challenges. Specifically, our approach leverages the end-to-end neural network (NN) optimization framework using a kernel-based objective. This design circumvents the computationally expensive Gram matrix inversion required by current CME methods. To further enhance performance, we provide efficient strategies to optimize the remaining kernel hyperparameters. In conditional density estimation tasks, our NN-CME hybrid achieves competitive performance and often surpasses existing deep learning-based methods. Lastly, we showcase its remarkable versatility by seamlessly integrating it into reinforcement learning (RL) contexts. Building on 
    
[^29]: 非平稳随机赌博机的激励探索

    Incentivized Exploration of Non-Stationary Stochastic Bandits

    [https://arxiv.org/abs/2403.10819](https://arxiv.org/abs/2403.10819)

    提出了针对非平稳随机赌博机的激励探索算法，实现了随时间的子线性遗憾和补偿

    

    我们研究了多臂赌博机（MAB）问题中的激励探索，其中玩家通过探索除了贪婪选择之外的臂获得补偿，并且可能对奖励提供偏倚反馈。我们考虑了两种不同的非平稳环境：突变和持续变化，并提出了相应的激励探索算法。我们展示了所提出的算法实现了随时间的子线性遗憾和补偿，从而有效地激励了探索，尽管存在非平稳性和偏倚或漂移反馈。

    arXiv:2403.10819v1 Announce Type: cross  Abstract: We study incentivized exploration for the multi-armed bandit (MAB) problem with non-stationary reward distributions, where players receive compensation for exploring arms other than the greedy choice and may provide biased feedback on the reward. We consider two different non-stationary environments: abruptly-changing and continuously-changing, and propose respective incentivized exploration algorithms. We show that the proposed algorithms achieve sublinear regret and compensation over time, thus effectively incentivizing exploration despite the nonstationarity and the biased or drifted feedback.
    
[^30]: 一种基于概率的人类比较对齐方法

    A Probabilistic Approach for Alignment with Human Comparisons

    [https://arxiv.org/abs/2403.10771](https://arxiv.org/abs/2403.10771)

    通过提出的两阶段“监督微调+人类比较”框架，本文研究了如何有效利用人类比较来改善AI模型的对齐，特别是在面对嘈杂数据和高维模型时。

    

    一个增长的趋势是将人类知识整合到学习框架中，利用微妙的人类反馈来完善AI模型。尽管取得了这些进展，但尚未开发出描述人类比较何时改善传统监督微调过程的特定条件的全面理论框架。为弥补这一差距，本文研究了有效利用人类比较来解决由嘈杂数据和高维模型引起的限制。我们提出了一个将机器学习与人类反馈通过概率二分方法联系起来的两阶段“监督微调+人类比较”（SFT+HC）框架。这两阶段框架首先通过SFT过程从带有噪声标记的数据中学习低维表示，然后利用人类比较来改进模型对齐。为了检验对齐阶段的效力，我们引入了一个新概念，称为“标签噪声到一致性”

    arXiv:2403.10771v1 Announce Type: new  Abstract: A growing trend involves integrating human knowledge into learning frameworks, leveraging subtle human feedback to refine AI models. Despite these advances, no comprehensive theoretical framework describing the specific conditions under which human comparisons improve the traditional supervised fine-tuning process has been developed. To bridge this gap, this paper studies the effective use of human comparisons to address limitations arising from noisy data and high-dimensional models. We propose a two-stage "Supervised Fine Tuning+Human Comparison" (SFT+HC) framework connecting machine learning with human feedback through a probabilistic bisection approach. The two-stage framework first learns low-dimensional representations from noisy-labeled data via an SFT procedure, and then uses human comparisons to improve the model alignment. To examine the efficacy of the alignment phase, we introduce a novel concept termed the "label-noise-to-co
    
[^31]: 一种用于更快分布鲁棒优化问题的原始-对偶算法

    A Primal-Dual Algorithm for Faster Distributionally Robust Optimization

    [https://arxiv.org/abs/2403.10763](https://arxiv.org/abs/2403.10763)

    这种原始-对偶算法在分布鲁棒优化问题中实现了最先进的线性收敛速度。

    

    我们考虑带有闭合、凸不确定性集的惩罚分布鲁棒优化（DRO）问题，这个设置包括了实践中使用的$f$-DRO、Wasserstein-DRO和谱/$L$-风险公式。我们提出了Drago，一种随机原始-对偶算法，在强凸-强凹DRO问题上实现了最先进的线性收敛速度。该方法将随机化和循环组件与小批量结合，有效处理了DRO中原始和对偶问题的独特不对称性质。我们通过分类和回归中的数值基准支持我们的理论结果。

    arXiv:2403.10763v1 Announce Type: cross  Abstract: We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses the $f$-DRO, Wasserstein-DRO, and spectral/$L$-risk formulations used in practice. We present Drago, a stochastic primal-dual algorithm that achieves a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems. The method combines both randomized and cyclic components with mini-batching, which effectively handles the unique asymmetric nature of the primal and dual problems in DRO. We support our theoretical results with numerical benchmarks in classification and regression.
    
[^32]: Bayesian深度学习中的无Hessian-Laplace

    Hessian-Free Laplace in Bayesian Deep Learning

    [https://arxiv.org/abs/2403.10671](https://arxiv.org/abs/2403.10671)

    提出了一种无Hessian计算和求逆的Hessian-Free Laplace近似框架，通过对数后验和网络预测的曲率来估计后验的方差。

    

    贝叶斯后验的Laplace近似（LA）是以最大后验估计为中心的高斯分布。它在贝叶斯深度学习中的吸引力源于能够在标准网络参数优化之后量化不确定性（即事后），从近似后验中抽样的便利性以及模型证据的解析形式。然而，LA的一个重要计算瓶颈是必须计算和求逆对数后验的Hessian矩阵。Hessian可以以多种方式近似，质量与网络、数据集和推断任务等多个因素有关。在本文中，我们提出了一个绕过Hessian计算和求逆的替代框架。无Hessian-Laplace（HFL）近似使用对数后验和网络预测的曲率来估计其方差。只需要两个点估计：最大后验估计和等价的曲率方向。

    arXiv:2403.10671v1 Announce Type: cross  Abstract: The Laplace approximation (LA) of the Bayesian posterior is a Gaussian distribution centered at the maximum a posteriori estimate. Its appeal in Bayesian deep learning stems from the ability to quantify uncertainty post-hoc (i.e., after standard network parameter optimization), the ease of sampling from the approximate posterior, and the analytic form of model evidence. However, an important computational bottleneck of LA is the necessary step of calculating and inverting the Hessian matrix of the log posterior. The Hessian may be approximated in a variety of ways, with quality varying with a number of factors including the network, dataset, and inference task. In this paper, we propose an alternative framework that sidesteps Hessian calculation and inversion. The Hessian-free Laplace (HFL) approximation uses curvature of both the log posterior and network prediction to estimate its variance. Only two point estimates are needed: the st
    
[^33]: 一种面向无家可归者街头外展和收集可食食物的资源受限随机调度算法

    A resource-constrained stochastic scheduling algorithm for homeless street outreach and gleaning edible food

    [https://arxiv.org/abs/2403.10638](https://arxiv.org/abs/2403.10638)

    该研究针对无家可归者和食品银行的资源受限外展问题，提出了一种基于Thompson抽样与马尔可夫链恢复的算法，显著优于基线算法。

    

    我们开发了一种通用的算法解决方案，解决了社会变革组织在资源受限外展中遇到的问题，这些组织拥有不同的使命和运营方式：Breaking Ground——一家帮助纽约无家可归者过渡至永久住房的组织和以色列全国食品银行Leket。具体地，我们针对部分观测的周期性不安定赌徒问题在$k$-步转移下开发了一种估计和优化方法。结果表明，我们提出的Thompson抽样与具有马尔可夫链恢复（通过Stein变分梯度下降）的算法在两个组织的问题上明显优于基线。我们以远景方式进行了这项工作，旨在设计一个足够灵活但也足够有用的解决方案，以帮助克服对数据可持续影响缺乏的问题。

    arXiv:2403.10638v1 Announce Type: new  Abstract: We developed a common algorithmic solution addressing the problem of resource-constrained outreach encountered by social change organizations with different missions and operations: Breaking Ground -- an organization that helps individuals experiencing homelessness in New York transition to permanent housing and Leket -- the national food bank of Israel that rescues food from farms and elsewhere to feed the hungry. Specifically, we developed an estimation and optimization approach for partially-observed episodic restless bandits under $k$-step transitions. The results show that our Thompson sampling with Markov chain recovery (via Stein variational gradient descent) algorithm significantly outperforms baselines for the problems of both organizations. We carried out this work in a prospective manner with the express goal of devising a flexible-enough but also useful-enough solution that can help overcome a lack of sustainable impact in da
    
[^34]: 顺序蒙特卡洛在摊销变分推理中包容KL最小化的应用

    Sequential Monte Carlo for Inclusive KL Minimization in Amortized Variational Inference

    [https://arxiv.org/abs/2403.10610](https://arxiv.org/abs/2403.10610)

    用顺序蒙特卡洛采样器估计inclusive KL散度梯度，提出了三种梯度估计器，解决了现有方法的偏差梯度和高度集中变分分布问题。

    

    用来训练编码器网络执行摊销变分推理，从精确后验分布到其近似分布的KL散度，即包容或正向KL，是因其极小化值的区域覆盖性质而成为变分目标的越来越流行选择。然而，最小化这一目标是具有挑战性的。作为一种替代方法，我们提出了SMC-Wake，该过程用于拟合一种摊销变分近似，其使用调节似然的顺序蒙特卡罗采样器来估计包容KL散度的梯度。我们提出了三种梯度估计器，其中对迭代次数是渐近无偏的两种是强一致的。我们的方法交替使用随机梯度

    arXiv:2403.10610v1 Announce Type: new  Abstract: For training an encoder network to perform amortized variational inference, the Kullback-Leibler (KL) divergence from the exact posterior to its approximation, known as the inclusive or forward KL, is an increasingly popular choice of variational objective due to the mass-covering property of its minimizer. However, minimizing this objective is challenging. A popular existing approach, Reweighted Wake-Sleep (RWS), suffers from heavily biased gradients and a circular pathology that results in highly concentrated variational distributions. As an alternative, we propose SMC-Wake, a procedure for fitting an amortized variational approximation that uses likelihood-tempered sequential Monte Carlo samplers to estimate the gradient of the inclusive KL divergence. We propose three gradient estimators, all of which are asymptotically unbiased in the number of iterations and two of which are strongly consistent. Our method interleaves stochastic gr
    
[^35]: 随机旋转浅水噪声的生成建模

    Generative Modelling of Stochastic Rotating Shallow Water Noise

    [https://arxiv.org/abs/2403.10578](https://arxiv.org/abs/2403.10578)

    本文提出一种用于校准流体动力学随机偏微分方程中噪声的通用方法，使用生成模型技术取代了以往的PCA技术，这能够避免对增量施加额外约束。

    

    在最近的工作中，作者们开发了一种用于校准流体动力学随机偏微分方程中噪声的通用方法，其中随机性被引入以参数化次网格尺度过程。子网格尺度过程的随机参数化在天气和气候预测的不确定性估计中是必需的，以表示由子网格尺度波动引起的系统模型误差。以前的方法使用基于随机参数化增量为正态分布的假设的主成分分析（PCA）技术。在本文中，PCA技术被生成模型技术所取代。这使我们能够避免对增量施加额外约束。该方法在具有模型高程变量作为输入数据的随机旋转浅水模型上进行了测试。数值模拟表明

    arXiv:2403.10578v1 Announce Type: cross  Abstract: In recent work, the authors have developed a generic methodology for calibrating the noise in fluid dynamics stochastic partial differential equations where the stochasticity was introduced to parametrize subgrid-scale processes. The stochastic parameterization of sub-grid scale processes is required in the estimation of uncertainty in weather and climate predictions, to represent systematic model errors arising from subgrid-scale fluctuations. The previous methodology used a principal component analysis (PCA) technique based on the ansatz that the increments of the stochastic parametrization are normally distributed.   In this paper, the PCA technique is replaced by a generative model technique. This enables us to avoid imposing additional constraints on the increments. The methodology is tested on a stochastic rotating shallow water model with the elevation variable of the model used as input data. The numerical simulations show that
    
[^36]: 一种对有限覆盖的混合RL在线算法的自然扩展

    A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage

    [https://arxiv.org/abs/2403.09701](https://arxiv.org/abs/2403.09701)

    混合强化学习算法中，通过将离线数据集包含在在线算法的经验重放缓冲区中进行启动，可以实现类似于基于离线数据分布引导在线探索的可证明收益，即使离线数据集没有单一策略可集中性。

    

    混合强化学习（RL）结合在线和离线数据，近年来引起了广泛关注，但关于其可证明益处的研究仍然很少。许多现有的混合RL算法对离线数据集施加覆盖假设，但我们表明这是不必要的。一个设计良好的在线算法应该在离线数据集中“填补空白”，探索行为策略未探索的状态和动作。与先前侧重于估计离线数据分布以引导在线探索的方法不同，我们表明对标准乐观在线算法的一个自然扩展——通过将离线数据集包含在经验重放缓冲区中来启动它们——即使离线数据集没有单一策略可集中性，也可实现混合数据的类似可证明收益。我们完成

    arXiv:2403.09701v1 Announce Type: new  Abstract: Hybrid Reinforcement Learning (RL), leveraging both online and offline data, has garnered recent interest, yet research on its provable benefits remains sparse. Additionally, many existing hybrid RL algorithms (Song et al., 2023; Nakamoto et al., 2023; Amortila et al., 2024) impose coverage assumptions on the offline dataset, but we show that this is unnecessary. A well-designed online algorithm should "fill in the gaps" in the offline dataset, exploring states and actions that the behavior policy did not explore. Unlike previous approaches that focus on estimating the offline data distribution to guide online exploration (Li et al., 2023b), we show that a natural extension to standard optimistic online algorithms -- warm-starting them by including the offline dataset in the experience replay buffer -- achieves similar provable gains from hybrid data even when the offline dataset does not have single-policy concentrability. We accomplish
    
[^37]: 使用高斯局部线性映射进行快速、准确和轻量级的顺序仿真推断

    Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings

    [https://arxiv.org/abs/2403.07454](https://arxiv.org/abs/2403.07454)

    使用结构混合概率分布提供了准确的后验推断，同时具有更小的计算占用量，相较于现有的基于神经网络的SBI方法。

    

    arXiv:2403.07454v1 公告类型: 跨领域 摘要: 针对具有难以处理的似然函数的复杂模型的贝叶斯推断可以使用多次调用计算模拟器的算法来解决。 这些方法被统称为“基于仿真的推断”（SBI）。 最近的SBI方法利用神经网络（NN）提供近似但表达丰富的构造，用于不可用的似然函数和后验分布。 然而，它们通常无法实现准确性和计算需求之间的最佳折衷。 在这项工作中，我们提出了一种提供似然函数和后验分布近似的替代方法，使用结构化的概率分布混合物。 相对于最先进的基于NN的SBI方法，我们的方法在产生准确的后验推断的同时，具有更小的计算占用量。 我们在SBI文献中的几个基准模型上展示了我们的结果。

    arXiv:2403.07454v1 Announce Type: cross  Abstract: Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as "simulation-based inference" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, they do not generally achieve an optimal trade-off between accuracy and computational demand. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature.
    
[^38]: 量子储备计算中的回声态性质等级

    Hierarchy of the echo state property in quantum reservoir computing

    [https://arxiv.org/abs/2403.02686](https://arxiv.org/abs/2403.02686)

    介绍了在量子储备计算中回声态性质的不同层次，包括非平稳性ESP和子系统具有ESP的子空间/子集ESP。进行了数值演示和记忆容量计算以验证这些定义。

    

    回声态性质（ESP）代表了储备计算（RC）框架中的一个基本概念，通过对初始状态和远期输入不加歧视来确保储蓄网络的仅输出训练。然而，传统的ESP定义并未描述可能演变统计属性的非平稳系统。为解决这一问题，我们引入了两类新的ESP：\textit{非平稳ESP}，用于潜在非平稳系统，和\textit{子空间/子集ESP}，适用于具有ESP的子系统的系统。根据这些定义，我们在量子储备计算（QRC）框架中数值演示了非平稳ESP与典型哈密顿动力学和使用非线性自回归移动平均（NARMA）任务的输入编码方法之间的对应关系。我们还通过计算线性/非线性记忆容量来确认这种对应关系，以量化

    arXiv:2403.02686v1 Announce Type: cross  Abstract: The echo state property (ESP) represents a fundamental concept in the reservoir computing (RC) framework that ensures output-only training of reservoir networks by being agnostic to the initial states and far past inputs. However, the traditional definition of ESP does not describe possible non-stationary systems in which statistical properties evolve. To address this issue, we introduce two new categories of ESP: \textit{non-stationary ESP}, designed for potentially non-stationary systems, and \textit{subspace/subset ESP}, designed for systems whose subsystems have ESP. Following the definitions, we numerically demonstrate the correspondence between non-stationary ESP in the quantum reservoir computer (QRC) framework with typical Hamiltonian dynamics and input encoding methods using non-linear autoregressive moving-average (NARMA) tasks. We also confirm the correspondence by computing linear/non-linear memory capacities that quantify 
    
[^39]: 受限制MDP中的真正无悔学习

    Truly No-Regret Learning in Constrained MDPs

    [https://arxiv.org/abs/2402.15776](https://arxiv.org/abs/2402.15776)

    本文首次肯定回答了一个开放问题，即是否可以在不允许错误抵消的情况下，通过将一种常见的安全约束模型扩展到具有多个约束的CMDPs，提出了一种可以实现次线性后悔的新方法。

    

    受约束的马尔可夫决策过程（CMDPs）是在强化学习中建模安全约束的常见方式。目前用于高效解决CMDPs的最先进方法基于原始-对偶算法。对于这些算法，所有当前已知的后悔界都允许错误抵消——可以通过在一个回合中的约束违反来用严格的约束满足在另一个回合中。这使得在线学习过程不安全，因为它仅保证最终（混合）策略的安全性，而在学习过程中不保证安全。正如Efroni等人（2020年）指出的，原始-对偶算法是否可以在不允许错误抵消的情况下可证明地实现次线性后悔是一个开放问题。在本文中，我们给出了第一个肯定的答案。我们首先将关于正则化原始-对偶方案的最后迭代收敛性通用化到具有多个约束的CMDPs上。基于这一见解，我们提出了一种基于模型的原始

    arXiv:2402.15776v1 Announce Type: new  Abstract: Constrained Markov decision processes (CMDPs) are a common way to model safety constraints in reinforcement learning. State-of-the-art methods for efficiently solving CMDPs are based on primal-dual algorithms. For these algorithms, all currently known regret bounds allow for error cancellations -- one can compensate for a constraint violation in one round with a strict constraint satisfaction in another. This makes the online learning process unsafe since it only guarantees safety for the final (mixture) policy but not during learning. As Efroni et al. (2020) pointed out, it is an open question whether primal-dual algorithms can provably achieve sublinear regret if we do not allow error cancellations. In this paper, we give the first affirmative answer. We first generalize a result on last-iterate convergence of regularized primal-dual schemes to CMDPs with multiple constraints. Building upon this insight, we propose a model-based primal
    
[^40]: HyperAgent：一种简单、可扩展、高效且可证明用于复杂环境的强化学习框架

    HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments

    [https://arxiv.org/abs/2402.10228](https://arxiv.org/abs/2402.10228)

    HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    

    为了在资源约束下解决复杂任务，强化学习（RL）代理需要简单、高效、可扩展、具有大状态空间和不断积累的交互数据。我们提出了HyperAgent，这是一个具有超模型、索引抽样方案和增量更新机制的RL框架，可以在一般价值函数逼近中进行计算高效的顺序后验逼近和数据高效的动作选择，超越了共轭性。HyperAgent的实现简单，只需要在DDQN中添加一个模块和一行额外代码。在实践中，HyperAgent在大规模深度RL基准测试中表现出稳健的性能，无论是在数据还是计算方面都获得了显着的效率提升。在理论上，在实际可扩展的算法中，HyperAgent是第一个能够实现可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
    
[^41]: 一个新的高斯最小最大定理及其应用

    A Novel Gaussian Min-Max Theorem and its Applications

    [https://arxiv.org/abs/2402.07356](https://arxiv.org/abs/2402.07356)

    本文介绍了一个新的高斯最小最大定理，扩展了经典定理对于独立但非恒定分布的情况。此外，该定理在高维统计学、机器学习、非光滑优化和信号处理等领域有广泛的应用。

    

    Gordon的一个著名结果允许比较两个高斯过程的最小最大行为，如果满足某些不等式条件。这个结果的结果包括高斯最小最大（GMT）和凸高斯最小最大（CGMT）定理，这些定理在高维统计学、机器学习、非光滑优化和信号处理方面有广泛的应用。目前为止，没有发现满足这些不等式的其他一对高斯过程。在本文中，我们确定了这样一对新的高斯过程。由此得到的定理将经典的GMT定理和CGMT定理从基本过程中的底层高斯矩阵具有iid行的情况扩展到具有独立但非恒定分布的情况。新的CGMT定理应用于多源高斯回归问题，以及属于的二元分类问题。

    A celebrated result by Gordon allows one to compare the min-max behavior of two Gaussian processes if certain inequality conditions are met. The consequences of this result include the Gaussian min-max (GMT) and convex Gaussian min-max (CGMT) theorems which have had far-reaching implications in high-dimensional statistics, machine learning, non-smooth optimization, and signal processing. Both theorems rely on a pair of Gaussian processes, first identified by Slepian, that satisfy Gordon's comparison inequalities. To date, no other pair of Gaussian processes satisfying these inequalities has been discovered. In this paper, we identify such a new pair. The resulting theorems extend the classical GMT and CGMT Theorems from the case where the underlying Gaussian matrix in the primary process has iid rows to where it has independent but non-identically-distributed ones. The new CGMT is applied to the problems of multi-source Gaussian regression, as well as to binary classification of genera
    
[^42]: 重复使用批次在两层网络的梯度下降中的好处：打破信息和跳跃指数的诅咒

    The Benefits of Reusing Batches for Gradient Descent in Two-Layer Networks: Breaking the Curse of Information and Leap Exponents

    [https://arxiv.org/abs/2402.03220](https://arxiv.org/abs/2402.03220)

    该论文研究了在两层神经网络中学习多指数目标函数时，重复使用批次的梯度下降（GD）的训练动态。研究发现，与单次GD相比，多次GD能够克服目标函数的限制，仅需两个时间步骤就能实现网络与目标子空间的重叠，展示了在有限时间内有效学习的广泛函数类。这些结果基于动力平均场理论（DMFT）的分析。

    

    本研究探讨了学习多指数目标函数时，两层神经网络的训练动态。我们关注重复多次使用批次的多次梯度下降（GD），并展示它与单次梯度下降相比，显著改变了对于哪些函数是可学习的的结论。具体而言，我们发现具有有限步长的多次GD能够克服目标函数的信息指数（Ben Arous等人，2021）和跳跃指数（Abbe等人，2023）所给出的梯度流和单次GD的限制。我们发现，通过重复使用批次，网络仅需两个时间步骤就能与目标子空间达成重叠，即使函数不满足阶梯性质（Abbe等人，2021）。我们对能够在有限时间内有效学习的（广泛的）函数类进行了表征。我们的结果证明基于动力平均场理论（DMFT）的分析。我们进一步提供了动态的闭式描述。

    We investigate the training dynamics of two-layer neural networks when learning multi-index target functions. We focus on multi-pass gradient descent (GD) that reuses the batches multiple times and show that it significantly changes the conclusion about which functions are learnable compared to single-pass gradient descent. In particular, multi-pass GD with finite stepsize is found to overcome the limitations of gradient flow and single-pass GD given by the information exponent (Ben Arous et al., 2021) and leap exponent (Abbe et al., 2023) of the target function. We show that upon re-using batches, the network achieves in just two time steps an overlap with the target subspace even for functions not satisfying the staircase property (Abbe et al., 2021). We characterize the (broad) class of functions efficiently learned in finite time. The proof of our results is based on the analysis of the Dynamical Mean-Field Theory (DMFT). We further provide a closed-form description of the dynamica
    
[^43]: 无参随机优化的自由度有多高？

    How Free is Parameter-Free Stochastic Optimization?

    [https://arxiv.org/abs/2402.03126](https://arxiv.org/abs/2402.03126)

    这个论文研究了无参随机优化的问题，提出了一种完全无参的方法，通过简单的超参数搜索技术在非凸和凸设置下都能取得优于先进算法的性能。同时，论文还建立了一个下界，指出完全无参的方法在某些情况下无法实现。

    

    我们研究了无参随机优化的问题，探讨了在什么条件下可以存在完全无参的方法：这些方法可以达到与最优调参方法相竞争的收敛速度，而不需要对真实问题参数有很多知识。现有的无参方法只能被视为“部分”无参，因为它们需要对真实问题参数有一些非平凡的知识，比如随机梯度范数的上界、到最小值的距离的上界等。在非凸设置中，我们证明了一个简单的超参数搜索技术可以得到一个完全无参的方法，在性能上超过了更复杂的先进算法。在具有噪声函数值的凸设置下，在较小的噪声假设下，我们也提供了类似的结果。最后，假设只能访问随机梯度，我们建立了一个下界，使得完全无参的方法无法实现。

    We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free s
    
[^44]: 在具有未知方差的双臂高斯赌臂机器人中局部最优固定预算最佳臂识别问题

    Locally Optimal Fixed-Budget Best Arm Identification in Two-Armed Gaussian Bandits with Unknown Variances

    [https://arxiv.org/abs/2312.12741](https://arxiv.org/abs/2312.12741)

    提出了一种在双臂高斯赌臂机器人中解决具有未知方差情况下局部最优固定预算最佳臂识别问题的策略。

    

    我们解决了双臂高斯赌臂机器人中带有固定预算的最佳臂识别（BAI）问题。 在BAI中，给定多个臂，我们通过自适应实验来找到具有最高期望奖励的最佳臂。 Kaufmann等人（2016年）为误识别最佳臂的概率提出了一个下界。 他们还提出了一种策略，假设奖励的方差已知，并表明随着预算无限接近，这种策略在概念上是最优的，即其误识别概率与下界匹配。 但是，当方差未知时，一种渐近优的策略尚未被发现。 针对这个未解决问题，我们提出了一种在自适应实验中估计方差并以估计标准差比例抽取臂的策略。 我们称此策略为Neyman分配（NA）-增强倒概率加权（AIPW）策略。

    arXiv:2312.12741v2 Announce Type: replace  Abstract: We address the problem of best arm identification (BAI) with a fixed budget for two-armed Gaussian bandits. In BAI, given multiple arms, we aim to find the best arm, an arm with the highest expected reward, through an adaptive experiment. Kaufmann et al. (2016) develops a lower bound for the probability of misidentifying the best arm. They also propose a strategy, assuming that the variances of rewards are known, and show that it is asymptotically optimal in the sense that its probability of misidentification matches the lower bound as the budget approaches infinity. However, an asymptotically optimal strategy is unknown when the variances are unknown. For this open issue, we propose a strategy that estimates variances during an adaptive experiment and draws arms with a ratio of the estimated standard deviations. We refer to this strategy as the Neyman Allocation (NA)-Augmented Inverse Probability weighting (AIPW) strategy. We then d
    
[^45]: 西班牙语问答中的语言模型知识蒸馏

    Language Model Knowledge Distillation for Efficient Question Answering in Spanish

    [https://arxiv.org/abs/2312.04193](https://arxiv.org/abs/2312.04193)

    通过知识蒸馏，我们开发了SpanishTinyRoBERTa，一个基于RoBERTa的西班牙语压缩语言模型，用于提高西班牙语问答的效率。

    

    最近发展的预训练西班牙语言模型的进展在许多自然语言处理(NLP)任务中取得了重大进展，如问答。然而，缺乏高效模型对这些模型在资源受限环境中的采用构成了一道障碍。因此，针对西班牙语的较小的蒸馏模型可能被证明是高度可扩展的，并促进它们在各种任务和场景中的进一步采用。在这项工作中，我们朝着这个方向迈出了一步，通过开发基于RoBERTa的西班牙语高效问答压缩语言模型SpanishTinyRoBERTa。为了实现这一目标，我们从一个大模型向一个更轻的模型进行知识蒸馏，这使得更广泛的实现成为可能，即使在计算资源有限的地区，也能实现可忽略的性能牺牲。我们的实验表明，这种密集的蒸馏模型能够实现限制的计算性能兼容。

    arXiv:2312.04193v2 Announce Type: replace  Abstract: Recent advances in the development of pre-trained Spanish language models has led to significant progress in many Natural Language Processing (NLP) tasks, such as question answering. However, the lack of efficient models imposes a barrier for the adoption of such models in resource-constrained environments. Therefore, smaller distilled models for the Spanish language could be proven to be highly scalable and facilitate their further adoption on a variety of tasks and scenarios. In this work, we take one step in this direction by developing SpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient question answering in Spanish. To achieve this, we employ knowledge distillation from a large model onto a lighter model that allows for a wider implementation, even in areas with limited computational resources, whilst attaining negligible performance sacrifice. Our experiments show that the dense distilled model can st
    
[^46]: 多项式信念网络

    Multinomial belief networks

    [https://arxiv.org/abs/2311.16909](https://arxiv.org/abs/2311.16909)

    提出了一种深度生成模型，用于处理具有多项式计数数据的分析需求，并能够从数据中完全自动提取出生物意义的元签名。

    

    机器学习中的贝叶斯方法在需要量化不确定性、处理缺失观测、样本稀缺或数据稀疏时是具有吸引力的。为了满足这些分析需求，我们提出了一种用于多项式计数数据的深层生成模型，其中网络的权重和隐藏单元均服从狄利克雷分布。我们制定了一个利用一系列增广关系的吉布斯抽样过程，类似于周-丛-陈模型。我们将该模型应用于小规模手写数字和一个大型的DNA突变癌症实验数据集，并展示了该模型如何能够完全数据驱动地提取出生物意义的元签名。

    arXiv:2311.16909v2 Announce Type: replace-cross  Abstract: A Bayesian approach to machine learning is attractive when we need to quantify uncertainty, deal with missing observations, when samples are scarce, or when the data is sparse. All of these commonly apply when analysing healthcare data. To address these analytical requirements, we propose a deep generative model for multinomial count data where both the weights and hidden units of the network are Dirichlet distributed. A Gibbs sampling procedure is formulated that takes advantage of a series of augmentation relations, analogous to the Zhou--Cong--Chen model. We apply the model on small handwritten digits, and a large experimental dataset of DNA mutations in cancer, and we show how the model is able to extract biologically meaningful meta-signatures in a fully data-driven way.
    
[^47]: 深度学习中通过几何调整的梯度下降以均匀指数速率全局$\mathcal{L}^2$最小化

    Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning

    [https://arxiv.org/abs/2311.15487](https://arxiv.org/abs/2311.15487)

    通过几何调整的梯度下降，在深度学习中以均匀指数速率实现全局$\mathcal{L}^2$最小化，这一方法在过参数化情况下具有明确自然的不变几何含义。

    

    我们考虑在深度学习网络中广泛使用的用于最小化$\mathcal{L}^2$代价函数的梯度下降流，并引入两个改进版本；一个适用于过参数化设置，另一个适用于欠参数化设置。这两个版本都具有明确自然的不变几何含义，考虑到在过参数化设置中的拉回向量丛结构和在欠参数化设置中的推前向量丛结构。在过参数化情况下，我们证明，只要满足秩条件，改进的梯度下降的所有轨道将以均匀指数收敛速率将$\mathcal{L}^2$代价驱动到全局最小值；因此，对于任何预先指定的接近全局最小值的近似，我们可以得到先验停止时间。我们指出后者与次Riemann几何的关系。

    arXiv:2311.15487v3 Announce Type: replace-cross  Abstract: We consider the gradient descent flow widely used for the minimization of the $\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two modified versions; one adapted for the overparametrized setting, and the other for the underparametrized setting. Both have a clear and natural invariant geometric meaning, taking into account the pullback vector bundle structure in the overparametrized, and the pushforward vector bundle structure in the underparametrized setting. In the overparametrized case, we prove that, provided that a rank condition holds, all orbits of the modified gradient descent drive the $\mathcal{L}^2$ cost to its global minimum at a uniform exponential convergence rate; one thereby obtains an a priori stopping time for any prescribed proximity to the global minimum. We point out relations of the latter to sub-Riemannian geometry.
    
[^48]: 基于Copula的可转移模型用于合成人口生成

    Copula-based transferable models for synthetic population generation

    [https://arxiv.org/abs/2302.09193](https://arxiv.org/abs/2302.09193)

    提出了一种基于Copula的新框架，利用不同人口样本以及相似边际依赖性，引入空间组件并考虑多种信息源，用于生成合成但现实的目标人口表示。

    

    人口综合涉及生成微观代理目标人口的合成但现实的表示，用于行为建模和模拟。 传统方法通常依赖于目标人口样本，如人口普查数据或旅行调查，由于高成本和较小的样本量，在较小的地理尺度上存在局限性。 我们提出了一种基于Copula的新框架，用于为仅已知经验边际分布的目标人口生成合成数据。 该方法利用来自具有相似边际依赖性的不同人口的样本，将空间组件引入到人口综合中，并考虑各种信息源用于更真实的生成器。 具体而言，该过程涉及将数据标准化并将其视为给定Copula的实现，然后在融入关于

    arXiv:2302.09193v2 Announce Type: replace-cross  Abstract: Population synthesis involves generating synthetic yet realistic representations of a target population of micro-agents for behavioral modeling and simulation. Traditional methods, often reliant on target population samples, such as census data or travel surveys, face limitations due to high costs and small sample sizes, particularly at smaller geographical scales. We propose a novel framework based on copulas to generate synthetic data for target populations where only empirical marginal distributions are known. This method utilizes samples from different populations with similar marginal dependencies, introduces a spatial component into population synthesis, and considers various information sources for more realistic generators. Concretely, the process involves normalizing the data and treat it as realizations of a given copula, and then training a generative model before incorporating the information on the marginals of the
    
[^49]: 无维度岭回归

    Dimension free ridge regression

    [https://arxiv.org/abs/2210.08571](https://arxiv.org/abs/2210.08571)

    该论文旨在超越比例渐近情况，重新审视对高维数据进行岭回归，允许特征向量是高维甚至无限维的，为统计学中的自然设置提供了新的研究方向。

    

    随机矩阵理论已成为高维统计学和理论机器学习中非常有用的工具。然而，随机矩阵理论主要集中在比例渐近情况下，其中列数与数据矩阵的行数成比例增长。这在统计学中并不总是最自然的设置，其中列对应协变量，行对应样本。为了超越比例渐近，我们重新审视了对独立同分布数据$(x_i, y_i)$，$i\le n$进行岭回归（$\ell_2$-惩罚最小二乘），其中$x_i$为特征向量，$y_i = \beta^\top x_i +\epsilon_i \in\mathbb{R}$为响应。我们允许特征向量是高维的，甚至是无限维的，此时它属于可分Hilbert空间，并且假设$z_i := \Sigma^{-1/2}x_i$具有独立同分布的条目，或者满足某种凸集中性质。

    arXiv:2210.08571v2 Announce Type: replace-cross  Abstract: Random matrix theory has become a widely useful tool in high-dimensional statistics and theoretical machine learning. However, random matrix theory is largely focused on the proportional asymptotics in which the number of columns grows proportionally to the number of rows of the data matrix. This is not always the most natural setting in statistics where columns correspond to covariates and rows to samples. With the objective to move beyond the proportional asymptotics, we revisit ridge regression ($\ell_2$-penalized least squares) on i.i.d. data $(x_i, y_i)$, $i\le n$, where $x_i$ is a feature vector and $y_i = \beta^\top x_i +\epsilon_i \in\mathbb{R}$ is a response. We allow the feature vector to be high-dimensional, or even infinite-dimensional, in which case it belongs to a separable Hilbert space, and assume either $z_i := \Sigma^{-1/2}x_i$ to have i.i.d. entries, or to satisfy a certain convex concentration property. With
    
[^50]: 机器学习中预测不确定性估计的综述

    A review of predictive uncertainty estimation with machine learning

    [https://arxiv.org/abs/2209.08307](https://arxiv.org/abs/2209.08307)

    该综述回顾了机器学习中利用概率分布进行预测不确定性估计的主题，为评估概率预测提供了相关度量，从经典统计方法到现代机器学习算法进行了梳理。

    

    预测和机器学习模型的预测应当以概率分布的形式呈现，旨在增加向最终用户传达的信息量。尽管学术界和工业界中利用机器学习模型进行概率预测和预测的应用越来越频繁，但相关概念和方法尚未在整个领域的整体视角下得到形式化和结构化。本文综述了利用机器学习算法进行预测不确定性估计的主题，以及用于评估概率预测的相关度量（一致评分函数和适当评分规则）。该综述涵盖了从早期统计引入（基于贝叶斯统计或分位数回归的线性回归和时间序列模型）到最近的机器学习算法（包括用于位置、规模的广义加性模型）

    arXiv:2209.08307v2 Announce Type: replace-cross  Abstract: Predictions and forecasts of machine learning models should take the form of probability distributions, aiming to increase the quantity of information communicated to end users. Although applications of probabilistic prediction and forecasting with machine learning models in academia and industry are becoming more frequent, related concepts and methods have not been formalized and structured under a holistic view of the entire field. Here, we review the topic of predictive uncertainty estimation with machine learning algorithms, as well as the related metrics (consistent scoring functions and proper scoring rules) for assessing probabilistic predictions. The review covers a time period spanning from the introduction of early statistical (linear regression and time series models, based on Bayesian statistics or quantile regression) to recent machine learning algorithms (including generalized additive models for location, scale a
    
[^51]: 机器学习中使用的log-cosh损失函数的统计特性

    Statistical Properties of the log-cosh Loss Function Used in Machine Learning

    [https://arxiv.org/abs/2208.04564](https://arxiv.org/abs/2208.04564)

    分析log-cosh损失函数的统计特性，比较它与柯西分布的性质，并研究MLE的偏差、方差和置信区间，同时提供了与其他损失函数的鲁棒估计器比较。

    

    这篇论文分析了机器学习中使用的一种常见损失函数，即log-cosh损失函数。已经发表了许多使用这种损失函数的论文，但迄今为止，文献中尚未提出过统计分析。本文介绍了log-cosh损失函数产生的分布函数。我们将其与类似的柯西分布进行比较，并进行多种表征其特性的统计程序。特别地，我们检验了与其相关的概率密度函数、累积分布函数、似然函数和费舍尔信息。我们将柯西和Cosh分布以及MLE的位置参数的渐近偏差、渐近方差和置信区间进行并列考虑。我们还提供了来自其他几种损失函数的鲁棒估计器的比较，包括Huber损失函数和秩分散函数。此外，我们还研究了该损失函数的应用。

    arXiv:2208.04564v4 Announce Type: replace-cross  Abstract: This paper analyzes a popular loss function used in machine learning called the log-cosh loss function. A number of papers have been published using this loss function but, to date, no statistical analysis has been presented in the literature. In this paper, we present the distribution function from which the log-cosh loss arises. We compare it to a similar distribution, called the Cauchy distribution, and carry out various statistical procedures that characterize its properties. In particular, we examine its associated pdf, cdf, likelihood function and Fisher information. Side-by-side we consider the Cauchy and Cosh distributions as well as the MLE of the location parameter with asymptotic bias, asymptotic variance, and confidence intervals. We also provide a comparison of robust estimators from several other loss functions, including the Huber loss function and the rank dispersion function. Further, we examine the use of the 
    
[^52]: 使用工具时间序列识别因果效应：无关 IV 和纠正历史

    Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past

    [https://arxiv.org/abs/2203.06056](https://arxiv.org/abs/2203.06056)

    本文考虑了在时间序列模型中进行 IV 回归的困难，提出了一种用于构建识别方程的方法，以实现对时间序列数据中因果效应的一致性参数估计。

    

    仪器变量（IV）回归依赖于工具来推断观测数据中的因果效应，其中存在未观测的混淆因素。我们考虑在时间序列模型中进行 IV 回归，例如矢量自回归（VAR）过程。直接应用独立同分布技术通常不一致，因为它们不能正确调整过去的依赖关系。本文概述了由于时间结构而引起的困难，并提出了用于构建可用于时间序列数据中因果效应一致参数估计的确认方程的方法。一种方法使用额外的无关协变量来获得可识别性（即使在独立同分布情况下也是有趣的想法）。我们进一步提出了一个图边缘化框架，允许我们以原则性的方式对时间序列应用无关 IV 和其他 IV 方法。我们的方法利用了全局马尔可夫性质的一个版本。

    arXiv:2203.06056v2 Announce Type: replace-cross  Abstract: Instrumental variable (IV) regression relies on instruments to infer causal effects from observational data with unobserved confounding. We consider IV regression in time series models, such as vector auto-regressive (VAR) processes. Direct applications of i.i.d. techniques are generally inconsistent as they do not correctly adjust for dependencies in the past. In this paper, we outline the difficulties that arise due to time structure and propose methodology for constructing identifying equations that can be used for consistent parametric estimation of causal effects in time series data. One method uses extra nuisance covariates to obtain identifiability (an idea that can be of interest even in the i.i.d. case). We further propose a graph marginalization framework that allows us to apply nuisance IV and other IV methods in a principled way to time series. Our methods make use of a version of the global Markov property, which w
    
[^53]: 在微观结构噪声下的非参数贝叶斯波动率学习

    Nonparametric Bayesian volatility learning under microstructure noise

    [https://arxiv.org/abs/1805.05606](https://arxiv.org/abs/1805.05606)

    研究在市场微观结构噪声下学习波动率的问题，采用非参数贝叶斯方法，通过先前研究波动率函数和采用前向滤波后向模拟算法等新颖计算方法，在合成数据和EUR/USD汇率数据集上表现良好。

    

    在这项工作中，我们研究了在市场微观结构噪声下学习波动率的问题。具体地，我们考虑从随机微分方程中获得的带有噪声的离散时间观测，并开发了一种新颖的计算方法来学习该方程的扩散系数。我们采用了非参数贝叶斯方法，其中我们\emph{a priori}将波动率函数建模为分段常数。其先验通过逆Gamma马尔可夫链来指定。通过将前向滤波后向模拟算法纳入Gibbs采样器中来对后验进行抽样。该方法在两个代表性的合成数据示例上表现良好。我们还将该方法应用于EUR/USD汇率数据集。最后，我们给出先验分布的极限结果。

    arXiv:1805.05606v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of learning the volatility under market microstructure noise. Specifically, we consider noisy discrete time observations from a stochastic differential equation and develop a novel computational method to learn the diffusion coefficient of the equation. We take a nonparametric Bayesian approach, where we \emph{a priori} model the volatility function as piecewise constant. Its prior is specified via the inverse Gamma Markov chain. Sampling from the posterior is accomplished by incorporating the Forward Filtering Backward Simulation algorithm in the Gibbs sampler. Good performance of the method is demonstrated on two representative synthetic data examples. We also apply the method on a EUR/USD exchange rate dataset. Finally we present a limit result on the prior distribution.
    
[^54]: 移动聚合提取网络

    Shift Aggregate Extract Networks

    [https://arxiv.org/abs/1703.05537](https://arxiv.org/abs/1703.05537)

    通过深层分层分解的架构，提出了一种有效学习大型图表示的方法，能够在大型社交网络数据集上胜过当前最先进的图分类方法，同时在小型化学生物基准数据集上具有竞争力。

    

    我们介绍了一种基于深层分层分解的架构，用于学习大型图的有效表示。我们的框架扩展了在核方法中使用的经典R-分解，实现了嵌套的部分-部分关系。与直接在输入图上展开模板的递归神经网络不同，我们在分解层次结构上展开神经网络模板，从而能够处理通常表征社交网络图的高度变化。深层次的分层分解也适用于领域压缩，这种技术通过利用对称性来减少空间和时间复杂度。我们在实证上证明，我们的方法在大型社交网络数据集上能够胜过当前最先进的图分类方法，同时在小型化学生物基准数据集上具有竞争力。

    arXiv:1703.05537v2 Announce Type: replace  Abstract: We introduce an architecture based on deep hierarchical decompositions to learn effective representations of large graphs. Our framework extends classic R-decompositions used in kernel methods, enabling nested part-of-part relations. Unlike recursive neural networks, which unroll a template on input graphs directly, we unroll a neural network template over the decomposition hierarchy, allowing us to deal with the high degree variability that typically characterize social network graphs. Deep hierarchical decompositions are also amenable to domain compression, a technique that reduces both space and time complexity by exploiting symmetries. We show empirically that our approach is able to outperform current state-of-the-art graph classification methods on large social network datasets, while at the same time being competitive on small chemobiological benchmark datasets.
    
[^55]: 利用Ricci流引导的自编码器学习时变动力学

    Ricci flow-guided autoencoders in learning time-dependent dynamics. (arXiv:2401.14591v1 [cs.LG])

    [http://arxiv.org/abs/2401.14591](http://arxiv.org/abs/2401.14591)

    利用Ricci流引导的自编码器方法能够学习非线性动力学，尤其是偏微分方程。该方法通过在训练中学习流形，并使用Ricci流使流形潜空间逐步适应动力学的变化，从而获得更好的表示能力。在实验中，我们展示了该方法在具有周期性和随机性的PDE上的应用，并评估了在分布内和外推场景中的误差。

    

    我们提出了一种基于流形的自编码器方法，用于学习时间上的非线性动力学，尤其是偏微分方程（PDE），其中流形潜空间根据Ricci流发展。这可以通过在物理信息设置中模拟Ricci流来实现，并且可以匹配流形量，以便实现Ricci流。使用我们的方法，流形是作为训练过程的一部分学习的，因此可以识别出理想的几何形状，同时演变也能在静态方法上引起更宽容的潜在表示。我们在一系列数值实验中展示了我们的方法，包括具有周期性和随机性等理想特征的PDE，并在分布内和外推场景中进行误差评估。

    We present a manifold-based autoencoder method for learning nonlinear dynamics in time, notably partial differential equations (PDEs), in which the manifold latent space evolves according to Ricci flow. This can be accomplished by simulating Ricci flow in a physics-informed setting, and manifold quantities can be matched so that Ricci flow is empirically achieved. With our methodology, the manifold is learned as part of the training procedure, so ideal geometries may be discerned, while the evolution simultaneously induces a more accommodating latent representation over static methods. We present our method on a range of numerical experiments consisting of PDEs that encompass desirable characteristics such as periodicity and randomness, remarking error on in-distribution and extrapolation scenarios.
    
[^56]: 合作多智能体图形赌博机：UCB算法和遗憾分析

    Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis. (arXiv:2401.10383v1 [cs.LG])

    [http://arxiv.org/abs/2401.10383](http://arxiv.org/abs/2401.10383)

    本文提出了一种解决多智能体图形赌博机问题的算法Multi-G-UCB，并通过数值实验验证了其有效性。

    

    本文将多智能体图形赌博机问题建模为Zhang、Johansson和Li在[CISS 57, 1-6 (2023)]中提出的图形赌博机问题的多智能体扩展。在我们的模型中，N个合作智能体在一个连通的图G上移动，图G有K个节点。抵达每个节点时，智能体观察到从一个与节点相关的概率分布中随机抽取的奖励。系统奖励被建模为智能体观测到的奖励的加权和，其中权重表达了多个智能体同时对同一节点进行采样的边际减少奖励。我们提出了一个基于上限置信区间（UCB）的学习算法，称为Multi-G-UCB，并证明了在T步内其期望遗憾被界定为$O(N\log(T)[\sqrt{KT} + DK])$，其中D是图G的直径。最后，我们通过与其他方法进行比较对算法进行了数值测试。

    In this paper, we formulate the multi-agent graph bandit problem as a multi-agent extension of the graph bandit problem introduced by Zhang, Johansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative agents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each node, agents observe a random reward drawn from a node-dependent probability distribution. The reward of the system is modeled as a weighted sum of the rewards the agents observe, where the weights capture the decreasing marginal reward associated with multiple agents sampling the same node at the same time. We propose an Upper Confidence Bound (UCB)-based learning algorithm, Multi-G-UCB, and prove that its expected regret over $T$ steps is bounded by $O(N\log(T)[\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly, we numerically test our algorithm by comparing it to alternative methods.
    
[^57]: 概率Lambert问题的解决方案：与最优质量传输、Schr\"odinger桥和反应-扩散偏微分方程的连接

    Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs. (arXiv:2401.07961v1 [math.OC])

    [http://arxiv.org/abs/2401.07961](http://arxiv.org/abs/2401.07961)

    这项研究将概率Lambert问题与最优质量传输、Schr\"odinger桥和反应-扩散偏微分方程等领域连接起来，从而解决了概率Lambert问题的解的存在和唯一性，并提供了数值求解的方法。

    

    Lambert问题涉及通过速度控制在规定的飞行时间内将航天器从给定的初始位置转移到给定的终端位置，受到重力力场的限制。我们考虑了Lambert问题的概率变种，其中位置向量的端点约束的知识被它们各自的联合概率密度函数所替代。我们证明了具有端点联合概率密度约束的Lambert问题是一个广义的最优质量传输（OMT）问题，从而将这个经典的天体动力学问题与现代随机控制和随机机器学习的新兴研究领域联系起来。这个新发现的连接使我们能够严格建立概率Lambert问题的解的存在性和唯一性。同样的连接还帮助通过扩散正规化数值求解概率Lambert问题，即通过进一步的连接来利用。

    Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection 
    
[^58]: 黑匣子内部：基于神经网络的实时预测美国衰退的研究

    Inside the black box: Neural network-based real-time prediction of US recessions. (arXiv:2310.17571v1 [econ.EM])

    [http://arxiv.org/abs/2310.17571](http://arxiv.org/abs/2310.17571)

    本研究使用神经网络对美国衰退进行实时预测，发现长短期记忆（LSTM）和门控循环单元（GRU）模型在长期预测任务中表现优于其他模型，并通过SHAP方法对GRU模型进行特征重要性评估。

    

    本研究使用前馈神经网络（FFN）和两种特定类型的循环神经网络，即长短期记忆（LSTM）和门控循环单元（GRU），对1967年至2021年的美国衰退进行建模。然后利用估计的模型对美国的大衰退和Covid-19衰退进行实时预测，将其预测性能与传统线性模型、逻辑回归模型（有和无岭回归惩罚）进行比较。外样本表现表明，LSTM和GRU在衰退预测领域具有应用潜力，特别适用于长期预测任务。相对于不同类型的统计性能指标，在5个预测周期内，它们优于其他类型的模型。而用Shapley增量解释（SHAP）方法评估衡量GRU在不同预测周期内的重要特征，以深入了解特征重要性。

    Feedforward neural network (FFN) and two specific types of recurrent neural network, long short-term memory (LSTM) and gated recurrent unit (GRU), are used for modeling US recessions in the period from 1967 to 2021. The estimated models are then employed to conduct real-time predictions of the Great Recession and the Covid-19 recession in US. Their predictive performances are compared to those of the traditional linear models, the logistic regression model both with and without the ridge penalty. The out-of-sample performance suggests the application of LSTM and GRU in the area of recession forecasting, especially for the long-term forecasting tasks. They outperform other types of models across 5 forecasting horizons with respect to different types of statistical performance metrics. Shapley additive explanations (SHAP) method is applied to the fitted GRUs across different forecasting horizons to gain insight into the feature importance. The evaluation of predictor importance differs b
    
[^59]: 《低秩适应的表达能力》

    The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])

    [http://arxiv.org/abs/2310.17513](http://arxiv.org/abs/2310.17513)

    本文分析了低秩适应（LoRA）的表达能力，证明了对于全连接神经网络，当LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度）时，LoRA可以使任何模型f准确表示任何较小的目标模型f。对于Transformer网络，通过rank-（嵌入大小/ 2）的LoRA适配器可以使任何模型适应于相同大小的目标模型。

    

    低秩适应（LoRA）是一种参数高效的微调方法，利用矩阵的低秩适应性，在微调预训练模型（如大型语言模型和扩散模型）中得到了广泛应用。尽管在实践中取得了巨大成功，但是LoRA的理论基础在很大程度上尚未得到探索。本文通过从理论角度分析LoRA的表达能力，首次尝试弥合这一差距。我们证明了对于全连接神经网络，如果LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度），则LoRA可以使任何模型f准确表示任何较小的目标模型f。当LoRA-rank低于阈值时，我们还量化了逼近误差。对于Transformer网络，我们证明任何模型可以通过rank-（嵌入大小/ 2）的LoRA适配器适应于相同大小的目标模型。

    Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models. Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\overline{f}$ if LoRA-rank $\geq(\text{width of }f) \times \frac{\text{depth of }\overline{f}}{\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold. For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\frac{\text{embedding size}}{2})$ LoRA adapters.
    
[^60]: 超越独立同分布权重：稀疏和低秩深度神经网络也是高斯过程

    Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes. (arXiv:2310.16597v1 [stat.ML])

    [http://arxiv.org/abs/2310.16597](http://arxiv.org/abs/2310.16597)

    本文扩展了之前的研究，将证明的范围从独立同分布权重扩展到了更大的权重分布类别(PSEUDO-IID)，包括低秩和稀疏设置。作者发现使用PSEUDO-IID分布初始化的全连接和卷积网络在方差上都是等效的。这些结果可以帮助我们识别更广泛的神经网络的边界混沌状态，并进行性能调优。

    

    无限宽神经网络已经被证明是一个有用且可管理的数学模型，使得我们能够理解深度学习中出现的许多现象。其中一个例子是随机深层网络收敛到高斯过程，从而能够对激活函数和网络权重选择对训练动态的影响进行严格分析。在本文中，我们将Matthews等人(2018)的开创性证明扩展到更大的初始权重分布类别(我们称之为PSEUDO-IID)，其中包括独立同分布和正交权重的已有情况，以及因其计算加速优势而受到赞誉的新兴低秩和结构稀疏设置。我们证明，使用PSEUDO-IID分布初始化的全连接和卷积网络在方差上都是等效的。利用我们的结果，可以识别更广泛的神经网络的边界混沌状态，并调整它们的临界性，以增强训练性能。

    The infinitely wide neural network has been proven a useful and manageable mathematical model that enables the understanding of many phenomena appearing in deep learning. One example is the convergence of random deep networks to Gaussian processes that allows a rigorous analysis of the way the choice of activation function and network weights impacts the training dynamics. In this paper, we extend the seminal proof of Matthews et al. (2018) to a larger class of initial weight distributions (which we call PSEUDO-IID), including the established cases of IID and orthogonal weights, as well as the emerging low-rank and structured sparse settings celebrated for their computational speed-up benefits. We show that fully-connected and convolutional networks initialized with PSEUDO-IID distributions are all effectively equivalent up to their variance. Using our results, one can identify the Edge-of-Chaos for a broader class of neural networks and tune them at criticality in order to enhance the
    
[^61]: CCA家族的高效算法：无约束目标与无偏梯度

    Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients. (arXiv:2310.01012v1 [cs.LG])

    [http://arxiv.org/abs/2310.01012](http://arxiv.org/abs/2310.01012)

    本论文提出了一个新颖的无约束目标，通过应用随机梯度下降（SGD）到CCA目标，实现了一系列快速算法，包括随机PLS、随机CCA和深度CCA。这些方法在各种基准测试中表现出比先前最先进方法更快的收敛速度和更高的相关性恢复。

    

    典型相关分析（CCA）方法在多视角学习中具有基础性作用。正则化线性CCA方法可以看作是偏最小二乘（PLS）的推广，并与广义特征值问题（GEP）框架统一。然而，这些线性方法的传统算法在大规模数据上计算上是不可行的。深度CCA的扩展显示出很大的潜力，但目前的训练过程缓慢且复杂。我们首先提出了一个描述GEPs的顶级子空间的新颖无约束目标。我们的核心贡献是一系列快速算法，用随机梯度下降（SGD）应用于相应的CCA目标，从而获得随机PLS、随机CCA和深度CCA。这些方法在所有标准CCA和深度CCA基准测试中显示出比先前最先进方法更快的收敛速度和更高的相关性恢复。这样的速度使我们能够首次进行大规模生物数据的PLS分析。

    The Canonical Correlation Analysis (CCA) family of methods is foundational in multi-view learning. Regularised linear CCA methods can be seen to generalise Partial Least Squares (PLS) and unified with a Generalized Eigenvalue Problem (GEP) framework. However, classical algorithms for these linear methods are computationally infeasible for large-scale data. Extensions to Deep CCA show great promise, but current training procedures are slow and complicated. First we propose a novel unconstrained objective that characterizes the top subspace of GEPs. Our core contribution is a family of fast algorithms for stochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying stochastic gradient descent (SGD) to the corresponding CCA objectives. These methods show far faster convergence and recover higher correlations than the previous state-of-the-art on all standard CCA and Deep CCA benchmarks. This speed allows us to perform a first-of-its-kind PLS analysis of an extremely large bio
    
[^62]: 学习如何提供注重依从性的建议

    Learning to Make Adherence-Aware Advice. (arXiv:2310.00817v1 [stat.ML])

    [http://arxiv.org/abs/2310.00817](http://arxiv.org/abs/2310.00817)

    本文提出了一种顺序决策模型，考虑了人的依从程度和机器提供建议的时机，并提供了学习算法来学习最佳的建议策略。

    

    随着人工智能系统在人类决策中扮演越来越重要的角色，人工智能与人类之间的交互存在挑战。由于没有充分考虑到人类忽视人工智能建议和人工智能选择性提供建议的需求，一个挑战就来自于底层人工智能策略的不佳表现。本文提出了一个顺序决策模型，该模型考虑了人类的依从程度（即人类遵循/拒绝机器建议的概率），并引入了一个推迟选项，使得机器在最合适的时候可以暂时不提供建议。我们提供了学习算法，可以学习最佳的建议策略，并仅在关键时刻提供建议。与问题不可知的强化学习算法相比，我们的专门化学习算法不仅具有更好的理论收敛性能，而且在实证性能上表现出色。

    As artificial intelligence (AI) systems play an increasingly prominent role in human decision-making, challenges surface in the realm of human-AI interactions. One challenge arises from the suboptimal AI policies due to the inadequate consideration of humans disregarding AI recommendations, as well as the need for AI to provide advice selectively when it is most pertinent. This paper presents a sequential decision-making model that (i) takes into account the human's adherence level (the probability that the human follows/rejects machine advice) and (ii) incorporates a defer option so that the machine can temporarily refrain from making advice. We provide learning algorithms that learn the optimal advice policy and make advice only at critical time stamps. Compared to problem-agnostic reinforcement learning algorithms, our specialized learning algorithms not only enjoy better theoretical convergence properties but also show strong empirical performance.
    
[^63]: 增强随机平滑的Lipschitz-方差-边界权衡

    The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing. (arXiv:2309.16883v1 [cs.LG])

    [http://arxiv.org/abs/2309.16883](http://arxiv.org/abs/2309.16883)

    本文提出了一个增强随机平滑的方法，通过研究随机平滑引入的方差与分类器的Lipschitz常数和边界之间的关系，以及采用单纯形投影技术来增加认证鲁棒半径。

    

    面对噪声输入和对抗性攻击时，深度神经网络的实际应用受到其不稳定的预测的阻碍。在这种情况下，认证半径是模型鲁棒性的关键指标。然而，如何设计一个具有足够认证半径的高效分类器呢？随机平滑通过在输入中注入噪声来获得平滑且更鲁棒的分类器的框架提供了有希望的解决方案。本文首先展示了随机平滑引入的方差与分类器的另外两个重要属性，即其Lipschitz常数和边界之间的密切关系。更具体地说，我们的工作强调了基分类器的Lipschitz常数对平滑分类器和经验方差的双重影响。此外，为了增加认证鲁棒半径，我们引入了一种不同的单纯形投影技术，以便通过Bernst的方差-边界权衡来利用基分类器。

    Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernst
    
[^64]: 从复杂到清晰：通过Clifford的几何代数和凸优化的分析表达深度神经网络的权重

    From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])

    [http://arxiv.org/abs/2309.16512](http://arxiv.org/abs/2309.16512)

    本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。

    

    本文介绍了一种基于几何（Clifford）代数和凸优化的神经网络分析方法。我们展示了当使用标准正则化损失进行训练时，深度ReLU神经网络的最优权重由训练样本的楔积给出。此外，训练问题可简化为对楔积特征进行凸优化，在其中编码训练数据集的几何结构。该结构以数据向量生成的三角形和平行体的有符号体积表示。凸问题通过$\ell_1$正则化找到样本的一个小子集，以发现仅相关的楔积特征。我们的分析提供了对深度神经网络内部工作机制的新视角，并揭示了隐藏层的作用。

    In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.
    
[^65]: 浅层神经网络的几何结构和基于${\mathcal L}^2$代价最小化的构造方法

    Geometric structure of shallow neural networks and constructive ${\mathcal L}^2$ cost minimization. (arXiv:2309.10370v1 [cs.LG])

    [http://arxiv.org/abs/2309.10370](http://arxiv.org/abs/2309.10370)

    本文提供了浅层神经网络的几何结构解释，并通过基于${\mathcal L}^2$代价最小化的构造方法获得了一个具有优越性能的网络。

    

    本文给出了一个几何解释：浅层神经网络的结构由一个隐藏层、一个斜坡激活函数、一个${\mathcal L}^2$谱范类（或者Hilbert-Schmidt）的代价函数、输入空间${\mathbb R}^M$、输出空间${\mathbb R}^Q$（其中$Q\leq M$），以及训练输入样本数量$N>QM$所特征。我们证明了代价函数的最小值具有$O(\delta_P)$的上界，其中$\delta_P$衡量了训练输入的信噪比。我们使用适应于属于同一输出向量$y_j$的训练输入向量$\overline{x_{0,j}}$的投影来获得近似的优化器，其中$j=1,\dots,Q$。在特殊情况$M=Q$下，我们明确确定了代价函数的一个确切退化局部最小值；这个尖锐的值与对于$Q\leq M$所获得的上界之间有一个相对误差$O(\delta_P^2)$。上界证明的方法提供了一个构造性训练的网络；我们证明它测度了$Q$维空间中的给定输出。

    In this paper, we provide a geometric interpretation of the structure of shallow neural networks characterized by one hidden layer, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, input space ${\mathbb R}^M$, output space ${\mathbb R}^Q$ with $Q\leq M$, and training input sample size $N>QM$. We prove an upper bound on the minimum of the cost function of order $O(\delta_P$ where $\delta_P$ measures the signal to noise ratio of training inputs. We obtain an approximate optimizer using projections adapted to the averages $\overline{x_{0,j}}$ of training input vectors belonging to the same output vector $y_j$, $j=1,\dots,Q$. In the special case $M=Q$, we explicitly determine an exact degenerate local minimum of the cost function; the sharp value differs from the upper bound obtained for $Q\leq M$ by a relative error $O(\delta_P^2)$. The proof of the upper bound yields a constructively trained network; we show that it metrizes the $Q$-dimen
    
[^66]: 两层神经网络上逻辑回归代价函数的全局收敛性

    Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets. (arXiv:2309.09258v1 [cs.LG])

    [http://arxiv.org/abs/2309.09258](http://arxiv.org/abs/2309.09258)

    本文首次证明了在深度为2的神经网络上，适当正则化的逻辑回归代价函数通过随机梯度下降（SGD）能够收敛到全局极小值，这适用于任意数据和具有充分平滑且有界激活函数。同时，我们还证明了连续时间SGD的指数级快速收敛速度，该结果也适用于光滑无界的激活函数。

    

    在本文中，我们首次证明了随机梯度下降（SGD）对于适当正则化的深度为2的神经网络的逻辑回归代价函数能够收敛到全局极小值，对于任意数据和具有充分平滑且有界激活函数（如sigmoid和tanh）。我们还证明了连续时间SGD的指数级快速收敛速度，该结果也适用于光滑无界的激活函数（如SoftPlus）。我们的关键思想是证明了在恒定大小的神经网络上存在Frobenius范数正则化的逻辑回归代价函数，这些函数是"Villani函数"，从而能够构建在最近对于此类目标函数上分析SGD的研究进展上。

    In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates with adequately smooth and bounded activations like sigmoid and tanh. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence of Frobenius norm regularized logistic loss functions on constant-sized neural nets which are "Villani functions" and thus be able to build on recent progress with analyzing SGD on such objectives.
    
[^67]: 带有Beta散度的深度非负矩阵分解

    Deep Nonnegative Matrix Factorization with Beta Divergences. (arXiv:2309.08249v1 [cs.LG])

    [http://arxiv.org/abs/2309.08249](http://arxiv.org/abs/2309.08249)

    本文提出了一种使用Beta散度的深度非负矩阵分解方法，应用于面部特征提取、文档主题识别和高光谱图像材料识别。

    

    深度非负矩阵分解（deep NMF）最近成为一种有价值的技术，用于在不同尺度上提取多层特征。然而，所有现有的深度NMF模型和算法主要都以最小二乘误差为评估标准，这可能不是评估多样化数据集近似质量的最合适指标。例如，当处理音频信号和文档等数据类型时，广泛认可的是$\beta$-divergences提供了更适合的替代方案。本文基于$\beta$-divergences开发了新的深度NMF模型和算法，并将这些技术应用于面部特征提取、文档集合中的主题识别以及高光谱图像中材料的识别。

    Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a valuable technique for extracting multiple layers of features across different scales. However, all existing deep NMF models and algorithms have primarily centered their evaluation on the least squares error, which may not be the most appropriate metric for assessing the quality of approximations on diverse datasets. For instance, when dealing with data types such as audio signals and documents, it is widely acknowledged that $\beta$-divergences offer a more suitable alternative. In this paper, we develop new models and algorithms for deep NMF using $\beta$-divergences. Subsequently, we apply these techniques to the extraction of facial features, the identification of topics within document collections, and the identification of materials within hyperspectral images.
    
[^68]: 在线多任务学习中基于递归最小二乘和递归核方法的应用

    Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods. (arXiv:2308.01938v1 [stat.ML])

    [http://arxiv.org/abs/2308.01938](http://arxiv.org/abs/2308.01938)

    本文提出了两种新的在线多任务学习方法，分别基于递归最小二乘和递归核方法。与基于梯度下降或不精确逼近的方法不同，我们的方法在每个实例的代价上具有二次复杂度。我们将这些方法应用于风力短期预测挑战，并与其他竞争者进行了比较。

    

    本文提出了两种新颖的在线多任务学习（MTL）回归问题的方法。我们采用高性能基于图的MTL公式，基于加权递归最小二乘（WRLS）和在线稀疏最小二乘支持向量回归（OSLSSVR）开发其递归版本。采用任务堆叠转换，我们展示了存在一个单矩阵，它融合了多任务之间的关系，并为MT-WRLS方法的初始化过程和MT-OSLSSVR的多任务核函数提供结构信息。与现有大部分基于在线梯度下降（OGD）或不精确立方逼近方法的文献相比，我们实现了精确和近似递归，其每个实例的代价在输入空间的维度（MT-WRLS）或实例字典的大小上是二次的。我们将我们的在线MTL方法与其他竞争者在实际风短期预测挑战上进行了比较。

    This paper introduces two novel approaches for Online Multi-Task Learning (MTL) Regression Problems. We employ a high performance graph-based MTL formulation and develop its recursive versions based on the Weighted Recursive Least Squares (WRLS) and the Online Sparse Least Squares Support Vector Regression (OSLSSVR). Adopting task-stacking transformations, we demonstrate the existence of a single matrix incorporating the relationship of multiple tasks and providing structural information to be embodied by the MT-WRLS method in its initialization procedure and by the MT-OSLSSVR in its multi-task kernel function. Contrasting the existing literature, which is mostly based on Online Gradient Descent (OGD) or cubic inexact approaches, we achieve exact and approximate recursions with quadratic per-instance cost on the dimension of the input space (MT-WRLS) or on the size of the dictionary of instances (MT-OSLSSVR). We compare our online MTL methods to other contenders in a real-world wind sp
    
[^69]: 在预测上下文中的在线学习问题

    Online learning in bandits with predicted context. (arXiv:2307.13916v1 [stat.ML])

    [http://arxiv.org/abs/2307.13916](http://arxiv.org/abs/2307.13916)

    本文研究了一种在预测上下文中的在线学习问题，通过将经典统计学中的测量误差模型推广到在线决策设置中，我们提出了第一个具有次线性后悔的在线算法。

    

    我们考虑在每个时刻，代理只能访问到上下文的一个带噪声的版本以及误差方差（或者这个方差的一个估计）。这一设置受到了许多应用的启发，在这些应用中，用于决策的真实上下文是不可观测的，而只有一个由可能复杂的机器学习算法预测出的上下文。当上下文误差是非衰减的时候，经典的bandit算法无法达到次线性的后悔。我们提出了在这一设置下，第一个具有次线性后悔的在线算法，并与适当的基准进行了比较。关键的思想是将经典统计学中的测量误差模型推广到在线决策设置中，这是非平凡的，因为策略依赖于有噪声的上下文观察。

    We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-diminishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret compared to the appropriate benchmark. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations.
    
[^70]: 离散切割Wasserstein损失的性质

    Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])

    [http://arxiv.org/abs/2307.10352](http://arxiv.org/abs/2307.10352)

    本文研究了离散切割Wasserstein损失的性质，并探讨了其正则性和优化性质以及通过蒙特卡洛近似的方法。

    

    切割Wasserstein（SW）距离已成为比较概率测度的Wasserstein距离的一种流行替代方法。广泛应用包括图像处理、领域自适应和生成建模，常常需要优化一些参数以最小化SW，该参数充当离散概率测度之间的损失函数（因为具有密度的测度在数值上是无法实现的）。所有这些优化问题都存在相同的子问题，即最小化切割Wasserstein能量。在本文中，我们研究了$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$的属性，即两个具有与一个测度的支撑相同数量的离散均匀测度之间的SW距离作为支撑$Y \in \mathbb{R}^{n \times d}$函数的能量。我们研究了这个能量的正则性和优化性质，以及其通过蒙特卡洛近似$\mathcal{E}_p$（使用SW中的期望估计）。

    The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
    
[^71]: 差分隐私潜在扩散模型

    Differentially Private Latent Diffusion Models. (arXiv:2305.15759v1 [stat.ML])

    [http://arxiv.org/abs/2305.15759](http://arxiv.org/abs/2305.15759)

    本文提出使用差分隐私训练潜在扩散模型(LDMs)，通过预训练自编码器将高维像素空间转变为低维潜在空间实现更高效快速的DMs训练，并且通过只微调注意力模块减少了可训练参数的数量。

    

    扩散模型(DMs)被广泛用于生成高质量图像数据集。然而，由于它们直接在高维像素空间中运行，DMs的优化计算成本高，需要长时间的训练。这导致由于差分隐私的可组合性属性，大量噪音注入到差分隐私学习过程中。为了解决这个挑战，我们提出使用差分隐私训练潜在扩散模型(LDMs)。LDMs使用强大的预训练自编码器将高维像素空间减少到更低维的潜在空间，使训练DMs更加高效和快速。与[Ghalebikesabi等人，2023]预先用公共数据预训练DMs，然后再用隐私数据进行微调不同，我们仅微调LDMs中不同层的注意力模块以获得隐私敏感数据，相对于整个DM微调，可减少大约96%的可训练参数数量。

    Diffusion models (DMs) are widely used for generating high-quality image datasets. However, since they operate directly in the high-dimensional pixel space, optimization of DMs is computationally expensive, requiring long training times. This contributes to large amounts of noise being injected into the differentially private learning process, due to the composability property of differential privacy. To address this challenge, we propose training Latent Diffusion Models (LDMs) with differential privacy. LDMs use powerful pre-trained autoencoders to reduce the high-dimensional pixel space to a much lower-dimensional latent space, making training DMs more efficient and fast. Unlike [Ghalebikesabi et al., 2023] that pre-trains DMs with public data then fine-tunes them with private data, we fine-tune only the attention modules of LDMs at varying layers with privacy-sensitive data, reducing the number of trainable parameters by approximately 96% compared to fine-tuning the entire DM. We te
    
[^72]: 基于凸组合的表达性损失可以提高网络的对抗鲁棒性

    Expressive Losses for Verified Robustness via Convex Combinations. (arXiv:2305.13991v1 [cs.LG])

    [http://arxiv.org/abs/2305.13991](http://arxiv.org/abs/2305.13991)

    通过基于凸组合的表达性损失，可以提高网络的对抗鲁棒性，最新的算法可以获得最先进的结果；这种方法通过对抗性攻击和IBP边界之间的简单凸组合进行实现。

    

    先前的工作通常通过（扰动区域的子集）的最坏情况下限，或在对抗训练之上引入可验证性来训练具有已验证鲁棒性的网络。最先进性能的关键在于所使用的损失函数的表达能力，它应该能够匹配训练后要使用的验证器的紧密度。我们形式化定义了表达力，并表明它可以通过对抗性攻击和IBP边界之间的简单凸组合来满足。然后，我们展示了所得到的算法，命名为CC-IBP和MTL-IBP，在各种设置中均可以产生最先进的结果，尽管其概念上是简单的。特别地，在TinyImageNet和缩小的ImageNet上，对于半径为$ \frac{1} {255} $的$ \ell_ \infty $扰动，MTL-IBP可以将文献中最佳标准和验证准确性从$1.98\%$提高到$3.92\%$，同时仅依赖于单步自适应优化。

    In order to train networks for verified adversarial robustness, previous work typically over-approximates the worst-case loss over (subsets of) perturbation regions or induces verifiability on top of adversarial training. The key to state-of-the-art performance lies in the expressivity of the employed loss function, which should be able to match the tightness of the verifiers to be employed post-training. We formalize a definition of expressivity, and show that it can be satisfied via simple convex combinations between adversarial attacks and IBP bounds. We then show that the resulting algorithms, named CC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity. In particular, for $\ell_\infty$ perturbations of radius $\frac{1}{255}$ on TinyImageNet and downscaled ImageNet, MTL-IBP improves on the best standard and verified accuracies from the literature by from $1.98\%$ to $3.92\%$ points while only relying on single-step ad
    
[^73]: 具有概率保证的神经网络鲁棒的反事实解释

    Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v1 [stat.ML])

    [http://arxiv.org/abs/2305.11997](http://arxiv.org/abs/2305.11997)

    本文提出了一种可靠的神经网络反事实解释方法，该方法可以针对自然发生的模型变化提供高概率的鲁棒性。

    

    针对神经网络发现偏移，通过使用稳定性度量来量化反事实解释对可能的模型变化的鲁棒性。通过在反事实解释优化中引入正则化项来将生成的反事实解释靠近数据流形，从而实现了对自然发生的模型变化的高概率鲁棒性。新的算法在合成和现实世界数据集上进行实验，证明了其有效性。

    There is an emerging interest in generating robust counterfactual explanations that would remain valid if the model is updated or changed even slightly. Towards finding robust counterfactuals, existing literature often assumes that the original model $m$ and the new model $M$ are bounded in the parameter space, i.e., $\|\text{Params}(M){-}\text{Params}(m)\|{<}\Delta$. However, models can often change significantly in the parameter space with little to no change in their predictions or accuracy on the given dataset. In this work, we introduce a mathematical abstraction termed \emph{naturally-occurring} model change, which allows for arbitrary changes in the parameter space such that the change in predictions on points that lie on the data manifold is limited. Next, we propose a measure -- that we call \emph{Stability} -- to quantify the robustness of counterfactuals to potential model changes for differentiable models, e.g., neural networks. Our main contribution is to show that counter
    
[^74]: 能量引导的熵神经最优输运

    Energy-guided Entropic Neural Optimal Transport. (arXiv:2304.06094v1 [cs.LG])

    [http://arxiv.org/abs/2304.06094](http://arxiv.org/abs/2304.06094)

    本论文提出了一种新的方法，将能量基础模型和熵正则化最优输运结合起来，以解决生成建模问题。我们在2D情景和图像到图像翻译问题中验证了该方法的适用性。

    

    能量基础模型（EBMs）在机器学习社区已经有数十年的历史。自两千年代起，一直有很多高效的方法通过能量势（非归一化的似然函数）来解决生成建模问题。相比之下，最优输运（OT）领域，尤其是神经OT求解器，受到的探索要少得多，仅有一些近期的研究（不包括利用OT作为损失函数来解决问题的WGAN方法）。在本研究中，我们弥合了EBMs和熵正则化OT之间的差距，提出了一种新的方法，允许利用前者的最新发展和技术改进来丰富后者。我们在2D情景和标准的图像到图像翻译问题中验证了我们方法的适用性。为简单起见，我们选择了简短和长跑的EBMs。

    Energy-Based Models (EBMs) are known in the Machine Learning community for the decades. Since the seminal works devoted to EBMs dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. We validate the applicability of our method on toy 2D scenarios as well as standard unpaired image-to-image translation problems. For the sake of simplicity, we choose simple short- and long- run EBMs as a 
    
[^75]: 基于Koopman算子的全秩权重的泛化界限：新的观点

    Koopman-based generalization bound: New aspect for full-rank weights. (arXiv:2302.05825v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05825](http://arxiv.org/abs/2302.05825)

    我们提出了一种使用Koopman算子对全秩神经网络权重进行泛化的新界限，当权重矩阵的条件数较小时，该界限比现有基于范数的界限更紧。我们的界限不与现有界限相矛盾，而是对现有界限进行的补充。此外，我们的界限可以与现有界限结合以得到更紧的界限。该研究结果为理解全秩权重神经网络的泛化提供了新的视角，同时也为算子理论分析和神经网络泛化之间提供了连接。

    

    我们提出了一种使用Koopman算子对神经网络进行泛化的新界限。大部分现有研究都集中在低秩权重矩阵上，而我们专注于全秩权重矩阵。当权重矩阵的条件数较小时，我们的界限比现有基于范数的界限更紧。特别地，如果权重矩阵是正交的，我们的界限与网络的宽度完全无关。我们的界限不与现有界限相矛盾，而是对现有界限进行的补充。由几个已有实验证明，低秩性并不是泛化的唯一原因。此外，我们的界限可以与现有界限结合以得到更紧的界限。我们的结果为理解具有全秩权重矩阵的神经网络的泛化提供了新的视角，同时还为算子理论分析和神经网络泛化之间提供了连接。

    We propose a new bound for generalization of neural networks using Koopman operators. Whereas most of existing works focus on low-rank weight matrices, we focus on full-rank weight matrices. Our bound is tighter than existing norm-based bounds when the condition numbers of weight matrices are small. Especially, it is completely independent of the width of the network if the weight matrices are orthogonal. Our bound does not contradict to the existing bounds but is a complement to the existing bounds. As supported by several existing empirical results, low-rankness is not the only reason for generalization. Furthermore, our bound can be combined with the existing bounds to obtain a tighter bound. Our result sheds new light on understanding generalization of neural networks with full-rank weight matrices, and it provides a connection between operator-theoretic analysis and generalization of neural networks.
    
[^76]: 乐观的在线镜像下降算法用于连接随机性和对抗性在线凸优化

    Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial Online Convex Optimization. (arXiv:2302.04552v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04552](http://arxiv.org/abs/2302.04552)

    本论文研究了乐观的在线镜像下降算法在Stochastically Extended Adversarial (SEA)模型中的理论保证，对于凸和平滑的函数，其遗憾界限为O(sqrt(σ_{1:T}^2) + sqrt(Σ_{1:T}^2))，对于强凸和平滑的函数，其界限为O(sqrt(σ_{\max}^2) + sqrt(Σ_{\max}^2))。

    

    Sachs等人介绍了Stochastically Extended Adversarial (SEA)模型，作为随机性和对抗性在线凸优化的插值方法。在光滑条件下，他们证明了乐观的Follow-the-Regularized-Leader (FTRL)算法的期望遗憾依赖于凸函数的累积随机方差和累积对抗变化。对于强凸函数，他们也给出了基于最大随机方差和最大对抗变化的稍弱界限。受到他们的工作的启发，我们研究了乐观的在线镜像下降算法在SEA模型中的理论保证。对于凸且平滑的函数，我们得到了相同的遗憾界限，即O(sqrt(σ_{1:T}^2) + sqrt(Σ_{1:T}^2))，而不需要个别函数的凸性要求。对于强凸且平滑的函数，我们建立了一个O(sqrt(σ_{\max}^2) + sqrt(Σ_{\max}^2))的界限。

    Stochastically Extended Adversarial (SEA) model is introduced by Sachs et al. [2022] as an interpolation between stochastic and adversarial online convex optimization. Under the smoothness condition, they demonstrate that the expected regret of optimistic follow-the-regularized-leader (FTRL) depends on the cumulative stochastic variance $\sigma_{1:T}^2$ and the cumulative adversarial variation $\Sigma_{1:T}^2$ for convex functions. They also provide a slightly weaker bound based on the maximal stochastic variance $\sigma_{\max}^2$ and the maximal adversarial variation $\Sigma_{\max}^2$ for strongly convex functions. Inspired by their work, we investigate the theoretical guarantees of optimistic online mirror descent (OMD) for the SEA model. For convex and smooth functions, we obtain the same $\mathcal{O}(\sqrt{\sigma_{1:T}^2}+\sqrt{\Sigma_{1:T}^2})$ regret bound, without the convexity requirement of individual functions. For strongly convex and smooth functions, we establish an $\mathc
    
[^77]: 重新思考反事实解释：作为局部和区域反事实政策的反事实解释

    Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies. (arXiv:2209.14568v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.14568](http://arxiv.org/abs/2209.14568)

    本文提出了一种概率框架，为每个观测值提供稀疏的局部反事实规则，并将这些规则聚合成区域反事实规则，以适应不稳定的实现环境，并产生稳健的救济措施。

    

    反事实解释（CE）面临着许多未解决的挑战，如确保稳定性、综合多个CE以及提供合理性和稀疏性保证。从更实际的角度来看，最近的研究表明，所规定的反事实救济措施通常不会被个体完全实施，并证明大多数最先进的CE算法在这种嘈杂的环境中很可能失败。为了解决这些问题，我们提出了一个概率框架，为每个观测值提供稀疏的局部反事实规则，提供能够以高概率改变决策的值范围的规则。这些规则作为多样的反事实解释的总结，并产生稳健的救济措施。我们进一步将这些局部规则聚合成区域反事实规则，识别数据子组的共享救济措施。我们的局部和区域规则来自于随机森林算法。

    Counterfactual Explanations (CE) face several unresolved challenges, such as ensuring stability, synthesizing multiple CEs, and providing plausibility and sparsity guarantees. From a more practical point of view, recent studies [Pawelczyk et al., 2022] show that the prescribed counterfactual recourses are often not implemented exactly by individuals and demonstrate that most state-of-the-art CE algorithms are very likely to fail in this noisy environment. To address these issues, we propose a probabilistic framework that gives a sparse local counterfactual rule for each observation, providing rules that give a range of values capable of changing decisions with high probability. These rules serve as a summary of diverse counterfactual explanations and yield robust recourses. We further aggregate these local rules into a regional counterfactual rule, identifying shared recourses for subgroups of the data. Our local and regional rules are derived from the Random Forest algorithm, which of
    

