# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Reinforcement Learning from Human Feedback with Active Queries](https://arxiv.org/abs/2402.09401) | 本文提出了一种基于主动查询的强化学习方法，用于解决与人类反馈的对齐问题。通过在强化学习过程中减少人工标注偏好数据的需求，该方法具有较低的代价，并在实验中表现出较好的性能。 |
| [^2] | [Loss Shaping Constraints for Long-Term Time Series Forecasting](https://arxiv.org/abs/2402.09373) | 该论文提出了一种用于长期时间序列预测的受限学习方法，通过在每个时间步骤上设置损失上限来寻找最佳模型，以解决平均性能优化导致特定时间步骤上误差过大的问题。 |
| [^3] | [Connecting Algorithmic Fairness to Quality Dimensions in Machine Learning in Official Statistics and Survey Production](https://arxiv.org/abs/2402.09328) | 这项研究将算法公平性与机器学习在官方统计和调查生产中的质量维度联系起来，扩展了质量框架，并调查了公平性与其他质量维度的互动。 |
| [^4] | [Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models](https://arxiv.org/abs/2402.09236) | 本研究将因果表示学习和基础模型相结合，研究了如何从数据中学习人类可解释的概念。实验证明了这一统一方法的实用性。 |
| [^5] | [Directional Convergence Near Small Initializations and Saddles in Two-Homogeneous Neural Networks](https://arxiv.org/abs/2402.09226) | 本文研究了两次齐次神经网络在小初值附近的梯度流动，发现权重会在方向上收敛到神经相关函数的KKT点和某些鞍点附近。 |
| [^6] | [Better-than-KL PAC-Bayes Bounds](https://arxiv.org/abs/2402.09201) | 本文提出了一种更好的比KL PAC-Bayes界限方法来估计序列均值，应用于预测器泛化误差的估计。 |
| [^7] | [Mixed-Output Gaussian Process Latent Variable Models](https://arxiv.org/abs/2402.09122) | 本文提出了一种基于高斯过程潜变量模型的贝叶斯非参数方法，可以用于信号分离，并且能够处理包含纯组分信号加权和的情况，适用于光谱学和其他领域的多种应用。 |
| [^8] | [Cross-Temporal Forecast Reconciliation at Digital Platforms with Machine Learning](https://arxiv.org/abs/2402.09033) | 本论文介绍了一种使用机器学习方法在数字平台上进行跨时预测协调的非线性分层预测协调方法，该方法能够直接且自动化地生成跨时预测协调的预测，通过对来自按需交付平台的大规模流式数据集进行实证测试。 |
| [^9] | [Neural Operators Meet Energy-based Theory: Operator Learning for Hamiltonian and Dissipative PDEs](https://arxiv.org/abs/2402.09018) | 本文提出了Energy-consistent Neural Operators (ENOs)框架，用于学习遵循能量守恒或耗散定律的PDE解算子。通过引入受物理学能量理论启发的惩罚函数，并通过另一个DNN模型建模能量函数，可以确保DNN解算子的输出满足能量一致性，而无需显式的PDEs。实验证明ENO在多个物理系统上的表现优于以往方法。 |
| [^10] | [Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path](https://arxiv.org/abs/2402.08998) | 本文研究了具有线性混合转移核函数的随机最短路径问题，并提出了一种无需限制性假设的新算法。该算法基于带有方差感知置信区间的扩展值迭代，并通过高阶矩的递归估计实现了近似最小最大遗憾界。 |
| [^11] | [Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method](https://arxiv.org/abs/2402.08992) | 本文提出了一种通过近端点方法进行随机优化的方法，能够在弱条件下获得低样本复杂度，并实现方差减少的目标。 |
| [^12] | [Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption](https://arxiv.org/abs/2402.08991) | 本研究通过引入对抗性健壮的乐观MLE（CR-OMLE）算法，解决了模型驱动强化学习中对抗性破坏的挑战，实现了对转移模型的健壮估计。 |
| [^13] | [Second Order Methods for Bandit Optimization and Control](https://arxiv.org/abs/2402.08929) | 本文提出了一种简单实用的二阶赌徒凸优化算法，并证明了其对于一类称之为$\kappa$-凸的凸函数实现了最优的后期损失界限。该算法在多个应用中表现出高效性能，包括赌徒逻辑回归。 |
| [^14] | [The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes](https://arxiv.org/abs/2402.08922) | 本文介绍和探讨了镜像影响假设，突出了训练和测试数据之间影响的相互性。具体而言，它指出，评估训练数据对测试预测的影响可以重新表述为一个等效但相反的问题：评估如果模型在特定的测试样本上进行训练，对训练样本的预测将如何改变。通过实证和理论验证，我们演示了这一假设的正确性。 |
| [^15] | [Position Paper: Challenges and Opportunities in Topological Deep Learning](https://arxiv.org/abs/2402.08871) | 拓扑深度学习将拓扑特征引入深度学习模型，可作为图表示学习和几何深度学习的补充，给各种机器学习环境提供了自然选择。本文讨论了拓扑深度学习中的开放问题，并提出了未来的研究机会。 |
| [^16] | [Approximation of relation functions and attention mechanisms](https://arxiv.org/abs/2402.08856) | 研究了多层感知机内积的近似性质，揭示了它们作为通用逼近器的能力。得到了对称和非对称关系函数逼近所需神经元数量的界限。 |
| [^17] | [Space-Time Bridge-Diffusion](https://arxiv.org/abs/2402.08847) | 介绍了一种利用时空混合策略生成独立同分布合成样本的方法，并通过线性和非线性随机过程实现最佳转运，进一步细化通过分数匹配技术训练方法 |
| [^18] | [Fusing Individualized Treatment Rules Using Secondary Outcomes](https://arxiv.org/abs/2402.08828) | 该论文提出了一种新方法，通过融合次要结果来学习个体化治疗规则(ITR)，既最大化主要结果的价值函数，又尽可能接近次要结果的最优规则。 |
| [^19] | [Corridor Geometry in Gradient-Based Optimization](https://arxiv.org/abs/2402.08818) | 本文研究了基于梯度优化中的走廊几何，发现走廊可以提供有关梯度下降优化的洞见，并提出了一种适用于梯度下降的学习率自适应策略CLR，该策略与凸优化中的Polyak步长特例一致。 |
| [^20] | [Depth Separation in Norm-Bounded Infinite-Width Neural Networks](https://arxiv.org/abs/2402.08808) | 本研究探讨了在无限宽度神经网络中的深度分隔问题，并发现在特定条件下，用深度为3的ReLU网络学习比用深度为2的ReLU网络学习要更高效。 |
| [^21] | [Projection-Free Online Convex Optimization with Time-Varying Constraints](https://arxiv.org/abs/2402.08799) | 这个论文介绍了在线凸优化中的投影-free算法，使用线性优化预测访问固定可行集，并满足时变约束。算法在序列上实现了$\tilde{O}(T^{3/4})$的遗憾和$O(T^{7/8})$的约束违反。 |
| [^22] | [Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"](https://arxiv.org/abs/2402.08711) | 修正了《对于数值逼近遍历SDE的分布的Wasserstein距离估计》中的错误局部误差估计，提出了一种方法来分析数值离散遍历SDE的Wasserstein-2距离的非渐近保证，并解决了实践中维度依赖性的问题。 |
| [^23] | [Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings](https://arxiv.org/abs/2402.08543) | 本文在高维环境下，针对非可微惩罚项（如推广的LASSO和核范数），通过研究LOOCV在估计外样本风险时的有限样本上界，解决了这个理论缺失的问题。 |
| [^24] | [Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization](https://arxiv.org/abs/2402.08095) | 本文通过均匀化的方式确切实现了离散扩散模型，研究了其理论性质，并提供了关于采样的总变差距离和KL散度保证。这一方法在建模离散数据方面具有重要的应用价值。 |
| [^25] | [Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions](https://arxiv.org/abs/2402.08082) | 基于分数的生成模型在学习一个子高斯概率分布族中突破了维数灾难，通过分数匹配生成的分布以维度无关的速率逼近目标分布的总变差。 |
| [^26] | [A Bayesian cluster validity index](https://arxiv.org/abs/2402.02162) | 该论文提出了一个基于贝叶斯方法的聚类有效性指数，该指数根据现有的基础指数定义，并用于检测次优聚类数，通过与其他指数进行比较，验证了其有效性。 |
| [^27] | [Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling](https://arxiv.org/abs/2402.00522) | 本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。 |
| [^28] | [Attentional Graph Neural Networks for Robust Massive Network Localization](https://arxiv.org/abs/2311.16856) | 本文通过将图神经网络与注意机制相结合，提出了一种用于网络定位的新方法。该方法具有出色的精确度，甚至在严重非直视视线条件下也能表现出良好的效果。通过提出的关注图神经网络模型，我们进一步改善了现有方法的灵活性和对超参数的敏感性。 |
| [^29] | [On the Statistical Benefits of Temporal Difference Learning](https://arxiv.org/abs/2301.13289) | 时序差异学习方法通过最小化连续时间步骤中的估计时序不一致度来拟合值函数，具有统计优势，可以显著减少值估计的均方误差，并且可以在两个状态的值差估计中获得显著改进。 |
| [^30] | [Optimistically Tempered Online Learning](https://arxiv.org/abs/2301.07530) | 本文提出了一种乐观调节的在线学习框架和适应算法，挑战了对专家的信心假设，并通过动态遗憾界限的理论保证和实验证明了该方法的有效性。 |
| [^31] | [High-Dimensional Undirected Graphical Models for Arbitrary Mixed Data](https://arxiv.org/abs/2211.11700) | 本文提出了在高维非定向图模型中处理任意混合数据的方法，通过在潜变量高斯copula框架中应用经典的多项和多序相关的思想。 |
| [^32] | [Theoretical Guarantees for Permutation-Equivariant Quantum Neural Networks](https://arxiv.org/abs/2210.09974) | 这篇论文主要研究了置换等变量量子神经网络在量子机器学习中的应用。研究发现，这种架构能够解决传统 QNNs 遇到的局部最小值和贫瘠的高原问题，并能够在少量数据上进行良好的泛化。 |
| [^33] | [Dynamic Maintenance of Kernel Density Estimation Data Structure: From Practice to Theory](https://arxiv.org/abs/2208.03915) | 本文研究了具有对抗性查询鲁棒性的动态维护核密度估计数据结构，并提供了一个亚二次空间复杂度和亚线性更新时间的理论框架。 |
| [^34] | [Provably Efficient Representation Selection in Low-rank Markov Decision Processes: From Online to Offline RL](https://arxiv.org/abs/2106.11935) | 本论文研究了在低秩马尔可夫决策过程中表示选择对于提高强化学习效率的影响。提出了ReLEX算法，可以在在线和离线强化学习中实现高效表示学习。实验证明，在线版本ReLEX-UCB总是不比没有表示选择的最先进算法差，并在表示函数类具有“覆盖度”性质时，实现了更好的常数遗憾。对于离线版本ReLEX-LCB，可以找到最优策略。 |
| [^35] | [Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications.](http://arxiv.org/abs/2401.09339) | 本文通过对两时间尺度随机逼近（TTSA）的广义分析，利用中心极限定理（CLT）揭示了TTSA受马尔可夫噪声影响的耦合动力学，从而拓展了传统SGD的高效采样策略在分布式学习中的应用范围，同时研究了具有非线性函数逼近的GTD算法的统计特性。 |
| [^36] | [General Identifiability and Achievability for Causal Representation Learning.](http://arxiv.org/abs/2310.15450) | 本文在通用非参数因果潜变量模型和通用转换模型下，通过非耦合干预建立了因果表达学习的可识别性和可实现性结果。在不知道具体干预对应的节点的情况下，这些结果保证了潜在的因果模型和变量的完美恢复，并设计了一个算法来实现这一目标。 |
| [^37] | [The Fundamental Dilemma of Bayesian Active Meta-learning.](http://arxiv.org/abs/2310.14968) | 在贝叶斯主动元学习中，贪婪追求可转移知识可能会损害对可转移参数的估计，学习者面临任务识别和可转移知识获取之间的困境。 |
| [^38] | [MMD-based Variable Importance for Distributional Random Forest.](http://arxiv.org/abs/2310.12115) | 本文介绍了基于MMD距离和经典的drop and relearn原理的变量重要性算法，可以在分布随机森林中检测影响输出分布的变量，并且在实证性能上超越了竞争对手。 |
| [^39] | [DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization.](http://arxiv.org/abs/2310.09639) | 该论文提出了DPZero算法，这是一种与维度无关且具有差分隐私的零阶优化算法，用于解决在细调大型语言模型时面临的内存和隐私挑战。 |
| [^40] | [Intriguing properties of generative classifiers.](http://arxiv.org/abs/2309.16779) | 生成分类器展示了记录破纪录的人类形状偏好、接近人类级别的超出分布准确性、与人类分类错误的最先进对齐以及理解某些知觉幻象的新兴特性，揭示了零样本生成模型出奇地接近人类物体识别数据。 |
| [^41] | [Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces.](http://arxiv.org/abs/2309.16597) | 本文提出了MPHD方法，通过模型预训练和神经网络在异质搜索空间上实现贝叶斯优化的迁移学习。实验证明了MPHD的有效性和在黑盒函数优化任务中的优越性能。 |
| [^42] | [Implicitly Normalized Explicitly Regularized Density Estimation.](http://arxiv.org/abs/2307.13763) | 我们提出了一种新的非参数密度估计方法，基于正则化密度的 Sobolev 范数，通过适当的初始化和使用自然梯度，可以得到性能良好的解，该方法在 Anomaly Detection benchmark 中排名第二。 |
| [^43] | [Understanding Pathologies of Deep Heteroskedastic Regression.](http://arxiv.org/abs/2306.16717) | 该论文研究了利用异方差神经回归模型对真实世界数据进行建模时的困难，并从统计物理的角度提供了解释。作者证明了这些不稳定性不仅适用于神经网络结构，而且已经在过参数化条件高斯似然模型的场论中存在。数值求解结果与实证模型拟合的定性一致性证明了相变的存在。 |
| [^44] | [Optimal Differentially Private Learning with Public Data.](http://arxiv.org/abs/2306.15056) | 本论文研究了具有公共数据的最优差分隐私学习，并解决了在训练差分隐私模型时如何利用公共数据提高准确性的问题。 |
| [^45] | [More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity.](http://arxiv.org/abs/2306.12214) | 本文提出了一种新的高概率PAC-Bayes界限，在有界和一般尾部行为的损失中均适用。此外，这些界限还能够保持随时有效性。 |
| [^46] | [$\texttt{causalAssembly}$: Generating Realistic Production Data for Benchmarking Causal Discovery.](http://arxiv.org/abs/2306.10816) | 该论文提出了一种生成基于装配线数据的半合成制造数据集的方法，以支持因果发现方法的基准测试。 |
| [^47] | [Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm.](http://arxiv.org/abs/2306.02939) | 本文提出了新的算法稳定性理论来改进分布式SGD算法的泛化性能分析，推翻了现有技术对通信图负面影响的观点，并展示了D-SGD在凸设置中与经典SGD算法泛化界相同。 |
| [^48] | [Evading Black-box Classifiers Without Breaking Eggs.](http://arxiv.org/abs/2306.02895) | 本文提出了一种基于实际代价的黑盒攻击，通过设计新的攻击方式，成功减少了“有害”查询的数量，提高了黑盒攻击效率。 |
| [^49] | [Input gradient diversity for neural network ensembles.](http://arxiv.org/abs/2306.02775) | 本文提出了一阶斥力深度集成 (FoRDE) 算法，它使用输入梯度来增强多样性以提高神经网络集成的表现。 |
| [^50] | [A Uniform Confidence Phenomenon in Deep Learning and its Implications for Calibration.](http://arxiv.org/abs/2306.00740) | 深度神经网络在训练点周围有大的几乎确定的置信邻域，这导致现代模型校准面临重要障碍。 |
| [^51] | [Deep Stochastic Mechanics.](http://arxiv.org/abs/2305.19685) | 本文提出了一种基于深度学习的方法，用于数值模拟时间演化薛定谔方程，利用马尔可夫扩散采样来适应波函数的潜在低维结构，并提出了新的随机量子力学方程，具有线性的计算复杂度。数值模拟显示出显着的优势。 |
| [^52] | [Perturbation-Assisted Sample Synthesis: A Novel Approach for Uncertainty Quantification.](http://arxiv.org/abs/2305.18671) | 本文提出了扰动辅助样本合成（PASS）方法，可从复杂数据中绘制可靠结论，并通过估计数据生成分布和蒙特卡罗实验证明任何统计数据的估计分布。进一步推出扰动辅助推理（PAI）框架，可以提供有效性的统计保证。 |
| [^53] | [Neural Fourier Transform: A General Approach to Equivariant Representation Learning.](http://arxiv.org/abs/2305.18484) | 神经傅里叶变换是一种通用的等变表示学习方法，它可以在不需要显式知识的情况下学习组的潜在线性作用，实现对数据隐藏结构的提取。 |
| [^54] | [Counterfactual Generative Models for Time-Varying Treatments.](http://arxiv.org/abs/2305.15742) | 本文研究了时间变量处理情况下的反事实生成模型，能够捕捉整个反事实分布，并且能够有效推断反事实分布的某些统计量，适用于医疗保健和公共政策制定领域。 |
| [^55] | [Optimal Learning via Moderate Deviations Theory.](http://arxiv.org/abs/2305.14496) | 本文提出了一种能够在广泛模型中进行最优学习的方法，利用中度偏差原理构建高度准确的置信区间，满足指数精度、一致性和最大精度等标准，为该方法提供了理论依据。 |
| [^56] | [Conditional Generative Modeling is All You Need for Marked Temporal Point Processes.](http://arxiv.org/abs/2305.12569) | 本文提出了一种从标记时间点过程中提取其统计直觉的事件生成模型，通过条件生成器以历史观察作为输入，生成可能发生的高质量随后事件。该模型具有高效、灵活和表示能力等方面的优势。 |
| [^57] | [Transfer operators on graphs: Spectral clustering and beyond.](http://arxiv.org/abs/2305.11766) | 本文介绍了在图上定义的转移算子及其谱特性，提出了基于广义转移算子的有向图聚类算法，并证明了算法有效性。 |

# 详细

[^1]: 使用主动查询的人类反馈强化学习

    Reinforcement Learning from Human Feedback with Active Queries

    [https://arxiv.org/abs/2402.09401](https://arxiv.org/abs/2402.09401)

    本文提出了一种基于主动查询的强化学习方法，用于解决与人类反馈的对齐问题。通过在强化学习过程中减少人工标注偏好数据的需求，该方法具有较低的代价，并在实验中表现出较好的性能。

    

    将大型语言模型（LLM）与人类偏好进行对齐，在构建现代生成模型中发挥重要作用，这可以通过从人类反馈中进行强化学习来实现。然而，尽管当前的强化学习方法表现出优越性能，但往往需要大量的人工标注偏好数据，而这种数据收集费时费力。本文受到主动学习的成功启发，通过提出查询效率高的强化学习方法来解决这个问题。我们首先将对齐问题形式化为上下文竞争二臂强盗问题，并设计了基于主动查询的近端策略优化（APPO）算法，具有$\tilde{O}(d^2/\Delta)$的遗憾界和$\tilde{O}(d^2/\Delta^2)$的查询复杂度，其中$d$是特征空间的维度，$\Delta$是所有上下文中的次优差距。然后，我们提出了ADPO，这是我们算法的实际版本，基于直接偏好优化（DPO）并将其应用于...

    arXiv:2402.09401v1 Announce Type: cross Abstract: Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to 
    
[^2]: 长期时间序列预测的损失塑造约束

    Loss Shaping Constraints for Long-Term Time Series Forecasting

    [https://arxiv.org/abs/2402.09373](https://arxiv.org/abs/2402.09373)

    该论文提出了一种用于长期时间序列预测的受限学习方法，通过在每个时间步骤上设置损失上限来寻找最佳模型，以解决平均性能优化导致特定时间步骤上误差过大的问题。

    

    许多时间序列预测应用程序需要预测多个步骤。尽管在这个主题上有大量的文献，但经典和最近的基于深度学习的方法主要集中在最小化预测窗口上的性能平均值。我们观察到，这可能导致在预测步骤之间存在不同的错误分布，尤其是对于在常见预测基准上训练的最近的变换器架构。也就是说，平均性能优化可能导致特定时间步骤上的错误过大。在这项工作中，我们提出了一种长期时间序列预测的受限学习方法，旨在找到在平均性能上最好的模型，并且在每个时间步骤上保持用户定义的损失上限。我们称这种方法为损失塑造约束，因为它对每个时间步骤的损失施加约束，并利用最近的对偶性结果展示了...

    arXiv:2402.09373v1 Announce Type: new Abstract: Several applications in time series forecasting require predicting multiple steps ahead. Despite the vast amount of literature in the topic, both classical and recent deep learning based approaches have mostly focused on minimising performance averaged over the predicted window. We observe that this can lead to disparate distributions of errors across forecasting steps, especially for recent transformer architectures trained on popular forecasting benchmarks. That is, optimising performance on average can lead to undesirably large errors at specific time-steps. In this work, we present a Constrained Learning approach for long-term time series forecasting that aims to find the best model in terms of average performance that respects a user-defined upper bound on the loss at each time-step. We call our approach loss shaping constraints because it imposes constraints on the loss at each time step, and leverage recent duality results to show 
    
[^3]: 将算法公平性与机器学习在官方统计和调查生产中的质量维度联系起来

    Connecting Algorithmic Fairness to Quality Dimensions in Machine Learning in Official Statistics and Survey Production

    [https://arxiv.org/abs/2402.09328](https://arxiv.org/abs/2402.09328)

    这项研究将算法公平性与机器学习在官方统计和调查生产中的质量维度联系起来，扩展了质量框架，并调查了公平性与其他质量维度的互动。

    

    国家统计机构（NSOs）越来越多地利用机器学习（ML）来提高产品的时效性和成本效益性。引入ML解决方案时，NSOs必须确保在统计算法的质量框架（QF4SA; Yung等,2022）中明确规定的健壮性、可重复性和准确性等高标准得到保持。与此同时，越来越多的研究关注公平性作为安全部署ML的前提，以防止实践中不同社会影响的出现。然而，在NSOs应用ML的背景下，公平性尚未明确讨论为质量方面。我们使用Yung等人 (2022)的QF4SA质量框架，并将其质量维度映射到算法公平性。这样，我们在几个方面扩展了QF4SA框架：我们主张公平性作为其独立的质量维度，我们调查了公平性与其他质量维度的互动。

    arXiv:2402.09328v1 Announce Type: cross Abstract: National Statistical Organizations (NSOs) increasingly draw on Machine Learning (ML) to improve the timeliness and cost-effectiveness of their products. When introducing ML solutions, NSOs must ensure that high standards with respect to robustness, reproducibility, and accuracy are upheld as codified, e.g., in the Quality Framework for Statistical Algorithms (QF4SA; Yung et al. 2022). At the same time, a growing body of research focuses on fairness as a pre-condition of a safe deployment of ML to prevent disparate social impacts in practice. However, fairness has not yet been explicitly discussed as a quality aspect in the context of the application of ML at NSOs. We employ Yung et al. (2022)'s QF4SA quality framework and present a mapping of its quality dimensions to algorithmic fairness. We thereby extend the QF4SA framework in several ways: we argue for fairness as its own quality dimension, we investigate the interaction of fairness
    
[^4]: 学习可解释概念：统一因果表示学习与基础模型

    Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models

    [https://arxiv.org/abs/2402.09236](https://arxiv.org/abs/2402.09236)

    本研究将因果表示学习和基础模型相结合，研究了如何从数据中学习人类可解释的概念。实验证明了这一统一方法的实用性。

    

    构建智能机器学习系统有两种广泛的方法。一种方法是构建天生可解释的模型，这是因果表示学习领域的努力方向。另一种方法是构建高性能的基础模型，然后投入努力去理解它们的工作原理。本研究将这两种方法联系起来，研究如何从数据中学习人类可解释的概念。通过结合这两个领域的思想，我们正式定义了概念的概念，并展示了它们可以从多样的数据中被可靠地恢复出来。对于合成数据和大型语言模型的实验证明了我们统一方法的实用性。

    arXiv:2402.09236v1 Announce Type: cross Abstract: To build intelligent machine learning systems, there are two broad approaches. One approach is to build inherently interpretable models, as endeavored by the growing field of causal representation learning. The other approach is to build highly-performant foundation models and then invest efforts into understanding how they work. In this work, we relate these two approaches and study how to learn human-interpretable concepts from data. Weaving together ideas from both fields, we formally define a notion of concepts and show that they can be provably recovered from diverse data. Experiments on synthetic data and large language models show the utility of our unified approach.
    
[^5]: 在两次齐次神经网络的小初值和鞍点附近的方向收敛

    Directional Convergence Near Small Initializations and Saddles in Two-Homogeneous Neural Networks

    [https://arxiv.org/abs/2402.09226](https://arxiv.org/abs/2402.09226)

    本文研究了两次齐次神经网络在小初值附近的梯度流动，发现权重会在方向上收敛到神经相关函数的KKT点和某些鞍点附近。

    

    本文研究了两次齐次神经网络在小初值附近的梯度流动力学，其中所有权重都初始化在原点附近。针对平方误差和逻辑损失，论文证明，对于足够小的初始值，梯度流动动态在原点附近花费足够的时间，使得神经网络的权重可以近似地在方向上收敛到神经相关函数的Karush-Kuhn-Tucker（KKT）点，该函数量化了神经网络输出与训练数据集中相应标签之间的关联性。

    arXiv:2402.09226v1 Announce Type: new Abstract: This paper examines gradient flow dynamics of two-homogeneous neural networks for small initializations, where all weights are initialized near the origin. For both square and logistic losses, it is shown that for sufficiently small initializations, the gradient flow dynamics spend sufficient time in the neighborhood of the origin to allow the weights of the neural network to approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of a neural correlation function that quantifies the correlation between the output of the neural network and corresponding labels in the training data set. For square loss, it has been observed that neural networks undergo saddle-to-saddle dynamics when initialized close to the origin. Motivated by this, this paper also shows a similar directional convergence among weights of small magnitude in the neighborhood of certain saddle points.
    
[^6]: 更好的比KL PAC-Bayes界限

    Better-than-KL PAC-Bayes Bounds

    [https://arxiv.org/abs/2402.09201](https://arxiv.org/abs/2402.09201)

    本文提出了一种更好的比KL PAC-Bayes界限方法来估计序列均值，应用于预测器泛化误差的估计。

    

    让$f(\theta, X_1),$ $ \dots,$ $ f(\theta, X_n)$成为一个随机元素序列，其中$f$是一个固定的标量函数，$X_1, \dots, X_n$是独立的随机变量（数据），而$\theta$是根据一些数据相关的后验分布$P_n$分布的随机参数。本文考虑了证明浓度不等式来估计序列均值的问题。这样一个问题的一个例子是对某些通过随机算法训练的预测器的泛化误差的估计，比如神经网络，其中$f$是一个损失函数。传统上，这个问题是通过PAC-Bayes分析来解决的，在这个分析中，除了后验分布，我们还选择一个能够捕捉到学习问题归纳偏差的先验分布。然后，PAC-Bayes浓度界限中的关键数量是一个能够捕捉到学习问题复杂性的分歧。

    arXiv:2402.09201v1 Announce Type: new Abstract: Let $f(\theta, X_1),$ $ \dots,$ $ f(\theta, X_n)$ be a sequence of random elements, where $f$ is a fixed scalar function, $X_1, \dots, X_n$ are independent random variables (data), and $\theta$ is a random parameter distributed according to some data-dependent posterior distribution $P_n$. In this paper, we consider the problem of proving concentration inequalities to estimate the mean of the sequence. An example of such a problem is the estimation of the generalization error of some predictor trained by a stochastic algorithm, such as a neural network where $f$ is a loss function. Classically, this problem is approached through a PAC-Bayes analysis where, in addition to the posterior, we choose a prior distribution which captures our belief about the inductive bias of the learning problem. Then, the key quantity in PAC-Bayes concentration bounds is a divergence that captures the complexity of the learning problem where the de facto stand
    
[^7]: 混合输出高斯过程潜变量模型

    Mixed-Output Gaussian Process Latent Variable Models

    [https://arxiv.org/abs/2402.09122](https://arxiv.org/abs/2402.09122)

    本文提出了一种基于高斯过程潜变量模型的贝叶斯非参数方法，可以用于信号分离，并且能够处理包含纯组分信号加权和的情况，适用于光谱学和其他领域的多种应用。

    

    本文提出了一种贝叶斯非参数的信号分离方法，其中信号可以根据潜变量变化。我们的主要贡献是增加了高斯过程潜变量模型（GPLVMs），以包括每个数据点由已知数量的纯组分信号的加权和组成的情况，并观察多个输入位置。我们的框架允许使用各种关于每个观测权重的先验。这种灵活性使我们能够表示包括用于估计分数组成的总和为一约束和用于分类的二进制权重的用例。我们的贡献对于光谱学尤其相关，因为改变条件可能导致基础纯组分信号在样本之间变化。为了展示对光谱学和其他领域的适用性，我们考虑了几个应用：一个具有不同温度的近红外光谱数据集。

    arXiv:2402.09122v1 Announce Type: cross Abstract: This work develops a Bayesian non-parametric approach to signal separation where the signals may vary according to latent variables. Our key contribution is to augment Gaussian Process Latent Variable Models (GPLVMs) to incorporate the case where each data point comprises the weighted sum of a known number of pure component signals, observed across several input locations. Our framework allows the use of a range of priors for the weights of each observation. This flexibility enables us to represent use cases including sum-to-one constraints for estimating fractional makeup, and binary weights for classification. Our contributions are particularly relevant to spectroscopy, where changing conditions may cause the underlying pure component signals to vary from sample to sample. To demonstrate the applicability to both spectroscopy and other domains, we consider several applications: a near-infrared spectroscopy data set with varying temper
    
[^8]: 使用机器学习在数字平台上进行跨时预测协调

    Cross-Temporal Forecast Reconciliation at Digital Platforms with Machine Learning

    [https://arxiv.org/abs/2402.09033](https://arxiv.org/abs/2402.09033)

    本论文介绍了一种使用机器学习方法在数字平台上进行跨时预测协调的非线性分层预测协调方法，该方法能够直接且自动化地生成跨时预测协调的预测，通过对来自按需交付平台的大规模流式数据集进行实证测试。

    

    平台业务在数字核心上运作，其决策需要不同层次（例如地理区域）和时间聚合（例如分钟到天）的高维准确预测流。为了确保不同规划单元（如定价、产品、控制和战略）之间的决策一致，也需要在层次结构的所有级别上进行协调预测。鉴于平台数据流具有复杂的特征和相互依赖关系，我们引入了一种非线性分层预测协调方法，通过使用流行的机器学习方法，以直接和自动化的方式生成跨时预测协调的预测。该方法足够快，可以满足平台所需的基于预测的高频决策。我们使用来自领先的按需交付平台的独特大规模流式数据集对我们的框架进行了实证测试。

    arXiv:2402.09033v1 Announce Type: new Abstract: Platform businesses operate on a digital core and their decision making requires high-dimensional accurate forecast streams at different levels of cross-sectional (e.g., geographical regions) and temporal aggregation (e.g., minutes to days). It also necessitates coherent forecasts across all levels of the hierarchy to ensure aligned decision making across different planning units such as pricing, product, controlling and strategy. Given that platform data streams feature complex characteristics and interdependencies, we introduce a non-linear hierarchical forecast reconciliation method that produces cross-temporal reconciled forecasts in a direct and automated way through the use of popular machine learning methods. The method is sufficiently fast to allow forecast-based high-frequency decision making that platforms require. We empirically test our framework on a unique, large-scale streaming dataset from a leading on-demand delivery plat
    
[^9]: 神经算子遇上能量理论: 哈密顿和耗散型偏微分方程的算子学习

    Neural Operators Meet Energy-based Theory: Operator Learning for Hamiltonian and Dissipative PDEs

    [https://arxiv.org/abs/2402.09018](https://arxiv.org/abs/2402.09018)

    本文提出了Energy-consistent Neural Operators (ENOs)框架，用于学习遵循能量守恒或耗散定律的PDE解算子。通过引入受物理学能量理论启发的惩罚函数，并通过另一个DNN模型建模能量函数，可以确保DNN解算子的输出满足能量一致性，而无需显式的PDEs。实验证明ENO在多个物理系统上的表现优于以往方法。

    

    近年来，算子学习引起了广泛关注，旨在学习函数空间之间的映射关系。之前的研究提出了利用深度神经网络(DNNs)学习这种映射的方法，实现对偏微分方程(PDEs)的解算子的学习。然而，这些方法仍然难以学习遵守物理规律的动力学。本文提出了能量一致神经算子(ENOs)，这是一个通用的框架，用于学习遵循能量守恒或耗散定律的PDE解算子。我们引入了一种受物理学能量理论启发的惩罚函数用于训练，其中能量函数由另一个DNN来建模，使得基于DNN的解算子的输出能够保证能量一致性，而不需要显式的PDEs。在多个物理系统上的实验证明ENO的性能明显优于以往方法。

    arXiv:2402.09018v1 Announce Type: cross Abstract: The operator learning has received significant attention in recent years, with the aim of learning a mapping between function spaces. Prior works have proposed deep neural networks (DNNs) for learning such a mapping, enabling the learning of solution operators of partial differential equations (PDEs). However, these works still struggle to learn dynamics that obeys the laws of physics. This paper proposes Energy-consistent Neural Operators (ENOs), a general framework for learning solution operators of PDEs that follows the energy conservation or dissipation law from observed solution trajectories. We introduce a novel penalty function inspired by the energy-based theory of physics for training, in which the energy functional is modeled by another DNN, allowing one to bias the outputs of the DNN-based solution operators to ensure energetic consistency without explicit PDEs. Experiments on multiple physical systems show that ENO outperfor
    
[^10]: 学习线性混合随机最短路径的近似最小最大遗憾

    Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path

    [https://arxiv.org/abs/2402.08998](https://arxiv.org/abs/2402.08998)

    本文研究了具有线性混合转移核函数的随机最短路径问题，并提出了一种无需限制性假设的新算法。该算法基于带有方差感知置信区间的扩展值迭代，并通过高阶矩的递归估计实现了近似最小最大遗憾界。

    

    我们研究了具有线性混合转移核函数的随机最短路径（SSP）问题，其中一个代理重复与随机环境互动，并寻求达到特定目标状态同时最小化累积成本。现有的工作通常假设成本函数具有严格的正下界，或者期望长度的最优策略具有上界。在本文中，我们提出了一种新的算法来消除这些限制性假设。我们的算法基于带有精细化方差感知置信区间的扩展值迭代，其中方差从高阶矩递归估计得到。我们的算法实现了$\tilde{\mathcal O}(dB_*\sqrt{K})$ 的遗憾界，其中$d$ 是线性转移核函数中特征映射的维度，$B_*$ 是最优策略的总累积成本的上界，$K$ 是剧集的数量。我们的遗憾上界与$\Omega(.

    arXiv:2402.08998v1 Announce Type: new Abstract: We study the Stochastic Shortest Path (SSP) problem with a linear mixture transition kernel, where an agent repeatedly interacts with a stochastic environment and seeks to reach certain goal state while minimizing the cumulative cost. Existing works often assume a strictly positive lower bound of the cost function or an upper bound of the expected length for the optimal policy. In this paper, we propose a new algorithm to eliminate these restrictive assumptions. Our algorithm is based on extended value iteration with a fine-grained variance-aware confidence set, where the variance is estimated recursively from high-order moments. Our algorithm achieves an $\tilde{\mathcal O}(dB_*\sqrt{K})$ regret bound, where $d$ is the dimension of the feature mapping in the linear transition kernel, $B_*$ is the upper bound of the total cumulative cost for the optimal policy, and $K$ is the number of episodes. Our regret upper bound matches the $\Omega(
    
[^11]: 通过近端点方法进行随机优化中的方差减少和低样本复杂性

    Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method

    [https://arxiv.org/abs/2402.08992](https://arxiv.org/abs/2402.08992)

    本文提出了一种通过近端点方法进行随机优化的方法，能够在弱条件下获得低样本复杂度，并实现方差减少的目标。

    

    本文提出了一种随机近端点法来解决随机凸复合优化问题。随机优化中的高概率结果通常依赖于对随机梯度噪声的限制性假设，例如子高斯分布。本文只假设了随机梯度的有界方差等弱条件，建立了一种低样本复杂度以获得关于所提方法收敛的高概率保证。此外，本工作的一个显著方面是发展了一个用于解决近端子问题的子程序，它同时也是一种用于减少方差的新技术。

    arXiv:2402.08992v1 Announce Type: cross Abstract: This paper proposes a stochastic proximal point method to solve a stochastic convex composite optimization problem. High probability results in stochastic optimization typically hinge on restrictive assumptions on the stochastic gradient noise, for example, sub-Gaussian distributions. Assuming only weak conditions such as bounded variance of the stochastic gradient, this paper establishes a low sample complexity to obtain a high probability guarantee on the convergence of the proposed method. Additionally, a notable aspect of this work is the development of a subroutine to solve the proximal subproblem, which also serves as a novel technique for variance reduction.
    
[^12]: 面向对抗性破坏的健壮模型驱动强化学习

    Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption

    [https://arxiv.org/abs/2402.08991](https://arxiv.org/abs/2402.08991)

    本研究通过引入对抗性健壮的乐观MLE（CR-OMLE）算法，解决了模型驱动强化学习中对抗性破坏的挑战，实现了对转移模型的健壮估计。

    

    本研究解决了模型驱动强化学习中对抗性破坏的挑战，其中转移动力学可以被对手破坏。现有研究主要集中在模型无关强化学习的情景下，通常采用健壮的最小二乘回归来进行值函数估计。然而，这些技术不能直接应用于模型驱动的强化学习。在本文中，我们专注于模型驱动的强化学习，并采用最大似然估计（MLE）方法来学习转移模型。我们的工作涵盖了在线和离线两种情况。在在线情况下，我们引入了一种名为对抗性健壮的乐观MLE（CR-OMLE）的算法，它利用基于总变差（TV）的信息比率作为MLE的不确定权重。我们证明了CR-OMLE的遗憾度为$ \tilde {\mathcal {O}}（\sqrt {T} + C）$，其中$ C $表示经过$ T $个回合后的累计破坏水平。

    arXiv:2402.08991v1 Announce Type: cross Abstract: This study tackles the challenges of adversarial corruption in model-based reinforcement learning (RL), where the transition dynamics can be corrupted by an adversary. Existing studies on corruption-robust RL mostly focus on the setting of model-free RL, where robust least-square regression is often employed for value function estimation. However, these techniques cannot be directly applied to model-based RL. In this paper, we focus on model-based RL and take the maximum likelihood estimation (MLE) approach to learn transition model. Our work encompasses both online and offline settings. In the online setting, we introduce an algorithm called corruption-robust optimistic MLE (CR-OMLE), which leverages total-variation (TV)-based information ratios as uncertainty weights for MLE. We prove that CR-OMLE achieves a regret of $\tilde{\mathcal{O}}(\sqrt{T} + C)$, where $C$ denotes the cumulative corruption level after $T$ episodes. We also pro
    
[^13]: 二阶方法用于赌徒优化与控制

    Second Order Methods for Bandit Optimization and Control

    [https://arxiv.org/abs/2402.08929](https://arxiv.org/abs/2402.08929)

    本文提出了一种简单实用的二阶赌徒凸优化算法，并证明了其对于一类称之为$\kappa$-凸的凸函数实现了最优的后期损失界限。该算法在多个应用中表现出高效性能，包括赌徒逻辑回归。

    

    Bandit凸优化(BCO)是一种在不确定性下进行在线决策的通用框架。尽管已经建立了一般凸损失的紧束后期界限，但现有算法在高维数据上具有难以忍受的计算成本。在本文中，我们提出了一种受在线牛顿步骤算法启发的简单实用的BCO算法。我们证明了我们的算法对于一类我们称之为$\kappa$-凸的凸函数实现了最优(从层面上讲)的后期界限。这个类包含了一系列实际相关的损失函数，包括线性、二次和广义线性模型。除了最优的后期损失，这种方法也是一些经过深入研究的应用中已知的最高效的算法，包括赌徒逻辑回归。

    arXiv:2402.08929v1 Announce Type: new Abstract: Bandit convex optimization (BCO) is a general framework for online decision making under uncertainty. While tight regret bounds for general convex losses have been established, existing algorithms achieving these bounds have prohibitive computational costs for high dimensional data.   In this paper, we propose a simple and practical BCO algorithm inspired by the online Newton step algorithm. We show that our algorithm achieves optimal (in terms of horizon) regret bounds for a large class of convex functions that we call $\kappa$-convex. This class contains a wide range of practically relevant loss functions including linear, quadratic, and generalized linear models. In addition to optimal regret, this method is the most efficient known algorithm for several well-studied applications including bandit logistic regression.   Furthermore, we investigate the adaptation of our second-order bandit algorithm to online convex optimization with mem
    
[^14]: 镜像影响假设：通过利用前向传递实现高效的数据影响估计

    The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes

    [https://arxiv.org/abs/2402.08922](https://arxiv.org/abs/2402.08922)

    本文介绍和探讨了镜像影响假设，突出了训练和测试数据之间影响的相互性。具体而言，它指出，评估训练数据对测试预测的影响可以重新表述为一个等效但相反的问题：评估如果模型在特定的测试样本上进行训练，对训练样本的预测将如何改变。通过实证和理论验证，我们演示了这一假设的正确性。

    

    大规模黑盒模型已经在许多应用中变得无处不在。了解个别训练数据源对这些模型所做预测的影响对于改善其可信性至关重要。当前的影响评估技术涉及计算每个训练点的梯度或在不同子集上重复训练。当扩展到大规模数据集和模型时，这些方法面临明显的计算挑战。

    arXiv:2402.08922v1 Announce Type: new Abstract: Large-scale black-box models have become ubiquitous across numerous applications. Understanding the influence of individual training data sources on predictions made by these models is crucial for improving their trustworthiness. Current influence estimation techniques involve computing gradients for every training point or repeated training on different subsets. These approaches face obvious computational challenges when scaled up to large datasets and models.   In this paper, we introduce and explore the Mirrored Influence Hypothesis, highlighting a reciprocal nature of influence between training and test data. Specifically, it suggests that evaluating the influence of training data on test predictions can be reformulated as an equivalent, yet inverse problem: assessing how the predictions for training samples would be altered if the model were trained on specific test samples. Through both empirical and theoretical validations, we demo
    
[^15]: 位置论文：拓扑深度学习中的挑战与机遇

    Position Paper: Challenges and Opportunities in Topological Deep Learning

    [https://arxiv.org/abs/2402.08871](https://arxiv.org/abs/2402.08871)

    拓扑深度学习将拓扑特征引入深度学习模型，可作为图表示学习和几何深度学习的补充，给各种机器学习环境提供了自然选择。本文讨论了拓扑深度学习中的开放问题，并提出了未来的研究机会。

    

    拓扑深度学习是一个快速发展的领域，它利用拓扑特征来理解和设计深度学习模型。本文认为，通过融入拓扑概念，拓扑深度学习可以补充图表示学习和几何深度学习，并成为各种机器学习环境下的自然选择。为此，本文讨论了拓扑深度学习中的开放问题，涵盖了从实用益处到理论基础的各个方面。针对每个问题，它概述了潜在的解决方案和未来的研究机会。同时，本文也是对科学界的邀请，希望积极参与拓扑深度学习研究，开发这个新兴领域的潜力。

    arXiv:2402.08871v1 Announce Type: new Abstract: Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.
    
[^16]: 关于关系函数和注意力机制的近似方法

    Approximation of relation functions and attention mechanisms

    [https://arxiv.org/abs/2402.08856](https://arxiv.org/abs/2402.08856)

    研究了多层感知机内积的近似性质，揭示了它们作为通用逼近器的能力。得到了对称和非对称关系函数逼近所需神经元数量的界限。

    

    神经网络特征映射的内积在各种机器学习框架中被用于建模输入之间的关系。本研究探讨了神经网络内积的近似性质。研究结果表明，多层感知机自身的内积是对称正定关系函数的通用逼近器。对于非对称关系函数，不同的多层感知机的内积是一个通用逼近器。在两种情况下，都得到了达到给定逼近精度所需的神经元数量的界限。对称情况下，函数类可以被认为是再生核希尔伯特空间中的核函数，而对称情况下函数类可以被认为是再生核巴拿赫空间中的核函数。最后，这些逼近结果被应用于分析...

    arXiv:2402.08856v1 Announce Type: new Abstract: Inner products of neural network feature maps arises in a wide variety of machine learning frameworks as a method of modeling relations between inputs. This work studies the approximation properties of inner products of neural networks. It is shown that the inner product of a multi-layer perceptron with itself is a universal approximator for symmetric positive-definite relation functions. In the case of asymmetric relation functions, it is shown that the inner product of two different multi-layer perceptrons is a universal approximator. In both cases, a bound is obtained on the number of neurons required to achieve a given accuracy of approximation. In the symmetric case, the function class can be identified with kernels of reproducing kernel Hilbert spaces, whereas in the asymmetric case the function class can be identified with kernels of reproducing kernel Banach spaces. Finally, these approximation results are applied to analyzing the
    
[^17]: 时空桥扩散方法

    Space-Time Bridge-Diffusion

    [https://arxiv.org/abs/2402.08847](https://arxiv.org/abs/2402.08847)

    介绍了一种利用时空混合策略生成独立同分布合成样本的方法，并通过线性和非线性随机过程实现最佳转运，进一步细化通过分数匹配技术训练方法

    

    在这项研究中，我们介绍了一种新的方法，用于从由一组地面真实样本（GT样本）隐式定义的高维实值概率分布中生成独立同分布（i.i.d.）的新合成样本。我们的方法的核心是通过时空混合策略在时间和空间维度上进行扩展。我们的方法基于三个相互关联的随机过程，旨在实现从容易处理的初始概率分布到由GT样本表示的目标分布的最佳转运：（a）包含时空混合的线性过程产生高斯条件概率密度，（b）其桥扩散模拟，条件为初始和最终状态向量，以及（c）通过分数匹配技术进行细化的非线性随机过程。我们训练方法的关键在于精调

    arXiv:2402.08847v1 Announce Type: cross Abstract: In this study, we introduce a novel method for generating new synthetic samples that are independent and identically distributed (i.i.d.) from high-dimensional real-valued probability distributions, as defined implicitly by a set of Ground Truth (GT) samples. Central to our method is the integration of space-time mixing strategies that extend across temporal and spatial dimensions. Our methodology is underpinned by three interrelated stochastic processes designed to enable optimal transport from an easily tractable initial probability distribution to the target distribution represented by the GT samples: (a) linear processes incorporating space-time mixing that yield Gaussian conditional probability densities, (b) their bridge-diffusion analogs that are conditioned to the initial and final state vectors, and (c) nonlinear stochastic processes refined through score-matching techniques. The crux of our training regime involves fine-tuning
    
[^18]: 使用次要结果融合个体化治疗规则

    Fusing Individualized Treatment Rules Using Secondary Outcomes

    [https://arxiv.org/abs/2402.08828](https://arxiv.org/abs/2402.08828)

    该论文提出了一种新方法，通过融合次要结果来学习个体化治疗规则(ITR)，既最大化主要结果的价值函数，又尽可能接近次要结果的最优规则。

    

    个体化治疗规则(ITR)是根据患者个体特征变量推荐治疗方案的决策规则。在许多实践中，理想的主要结果的ITR还预计对其他次要结果造成最小的危害。因此，我们的目标是学习一种ITR，它不仅最大化主要结果的价值函数，还尽可能地接近次要结果的最优规则。为了实现这个目标，我们引入了融合惩罚，鼓励基于不同结果的ITR产生类似的推荐。我们提出了两种使用替代损失函数估计ITR的算法。我们证明了主要结果的估计ITR与次要结果的最优ITR之间的一致率收敛比没有考虑次要结果时更快。此外，我们推导出了...

    arXiv:2402.08828v1 Announce Type: cross Abstract: An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the
    
[^19]: 基于梯度优化中的走廊几何

    Corridor Geometry in Gradient-Based Optimization

    [https://arxiv.org/abs/2402.08818](https://arxiv.org/abs/2402.08818)

    本文研究了基于梯度优化中的走廊几何，发现走廊可以提供有关梯度下降优化的洞见，并提出了一种适用于梯度下降的学习率自适应策略CLR，该策略与凸优化中的Polyak步长特例一致。

    

    本文通过将最陡下降的连续曲线，即梯度流的解，变成直线，将损失曲面的区域划分为走廊。我们表明走廊能够提供关于梯度下降优化的洞见，因为走廊正是梯度下降和梯度流遵循相同轨迹且损失线性下降的区域。因此，在走廊内部，不存在因梯度下降和梯度流之间的漂移而导致的隐式正则化效应或训练不稳定性。基于走廊上损失的线性下降，我们设计了一种适用于梯度下降的学习率自适应策略，我们称之为走廊学习率(CLR)。CLR的形式与凸优化上最近发现的Polyak步长特例一致。Polyak步长近期已被证明具有良好的收敛性质。

    arXiv:2402.08818v1 Announce Type: cross Abstract: We characterize regions of a loss surface as corridors when the continuous curves of steepest descent -- the solutions of the gradient flow -- become straight lines. We show that corridors provide insights into gradient-based optimization, since corridors are exactly the regions where gradient descent and the gradient flow follow the same trajectory, while the loss decreases linearly. As a result, inside corridors there are no implicit regularization effects or training instabilities that have been shown to occur due to the drift between gradient descent and the gradient flow. Using the loss linear decrease on corridors, we devise a learning rate adaptation scheme for gradient descent; we call this scheme Corridor Learning Rate (CLR). The CLR formulation coincides with a special case of Polyak step-size, discovered in the context of convex optimization. The Polyak step-size has been shown recently to have also good convergence propertie
    
[^20]: 在规范有界的无限宽度神经网络中的深度分隔问题

    Depth Separation in Norm-Bounded Infinite-Width Neural Networks

    [https://arxiv.org/abs/2402.08808](https://arxiv.org/abs/2402.08808)

    本研究探讨了在无限宽度神经网络中的深度分隔问题，并发现在特定条件下，用深度为3的ReLU网络学习比用深度为2的ReLU网络学习要更高效。

    

    我们研究了在无限宽度神经网络中的深度分隔问题，其中复杂性由权重的整体二次$\ell_2$范数控制（网络中所有权重的平方和）。之前的深度分隔结果主要关注宽度方面的分隔，这些结果无法说明深度是否决定了在宽度无限制的情况下能否学习出适用于广义上的好泛化性能的网络。在这里，我们研究学习可行性的样本复杂度方面的分隔。具体来说，我们表明有些函数可以通过控制范数的深度3 ReLU网络以多项式复杂度的样本量进行学习，但不能通过控制范数的深度2 ReLU网络（任何范数值）以亚指数复杂度进行学习。同时我们还表明类似的逆向说法是不可能成立的：任何可以通过多项式样本复杂度进行学习的函数，并不能通过亚指数样本复杂度进行学习。

    arXiv:2402.08808v1 Announce Type: new Abstract: We study depth separation in infinite-width neural networks, where complexity is controlled by the overall squared $\ell_2$-norm of the weights (sum of squares of all weights in the network). Whereas previous depth separation results focused on separation in terms of width, such results do not give insight into whether depth determines if it is possible to learn a network that generalizes well even when the network width is unbounded. Here, we study separation in terms of the sample complexity required for learnability. Specifically, we show that there are functions that are learnable with sample complexity polynomial in the input dimension by norm-controlled depth-3 ReLU networks, yet are not learnable with sub-exponential sample complexity by norm-controlled depth-2 ReLU networks (with any value for the norm). We also show that a similar statement in the reverse direction is not possible: any function learnable with polynomial sample co
    
[^21]: 具有时变约束的无投影在线凸优化

    Projection-Free Online Convex Optimization with Time-Varying Constraints

    [https://arxiv.org/abs/2402.08799](https://arxiv.org/abs/2402.08799)

    这个论文介绍了在线凸优化中的投影-free算法，使用线性优化预测访问固定可行集，并满足时变约束。算法在序列上实现了$\tilde{O}(T^{3/4})$的遗憾和$O(T^{7/8})$的约束违反。

    

    我们考虑在线凸优化中的对抗性时变约束设置，其中的操作必须是相对于固定约束集可行的，并且还要平均地满足额外的时变约束。受到固定可行集（硬约束）在投影方面困难的情景的启发，我们考虑只通过线性优化预测（LOO）访问该集合的无投影算法。我们提出了一种算法，在长度为$T$的序列上，并使用总共$T$次LOO调用，保证与损失相关的$\tilde{O}(T^{3/4})$的遗憾和$O(T^{7/8})$的约束违反（忽略所有除$T$之外的量）。特别地，这些界限对于序列的任意区间都成立。我们还提出了一种更高效的算法，它只需要对软约束进行一阶预测访问，并实现了与整个序列相关的类似界限。

    arXiv:2402.08799v1 Announce Type: new Abstract: We consider the setting of online convex optimization with adversarial time-varying constraints in which actions must be feasible w.r.t. a fixed constraint set, and are also required on average to approximately satisfy additional time-varying constraints. Motivated by scenarios in which the fixed feasible set (hard constraint) is difficult to project on, we consider projection-free algorithms that access this set only through a linear optimization oracle (LOO). We present an algorithm that, on a sequence of length $T$ and using overall $T$ calls to the LOO, guarantees $\tilde{O}(T^{3/4})$ regret w.r.t. the losses and $O(T^{7/8})$ constraints violation (ignoring all quantities except for $T$) . In particular, these bounds hold w.r.t. any interval of the sequence. We also present a more efficient algorithm that requires only first-order oracle access to the soft constraints and achieves similar bounds w.r.t. the entire sequence. We extend t
    
[^22]: 《对于数值逼近遍历SDE的分布的Wasserstein距离估计》修正

    Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"

    [https://arxiv.org/abs/2402.08711](https://arxiv.org/abs/2402.08711)

    修正了《对于数值逼近遍历SDE的分布的Wasserstein距离估计》中的错误局部误差估计，提出了一种方法来分析数值离散遍历SDE的Wasserstein-2距离的非渐近保证，并解决了实践中维度依赖性的问题。

    

    本文对San-Serna和Zygalakis的《对于数值逼近遍历SDE的分布的Wasserstein距离估计》中的非渐近保证数值离散分析方法进行了修正。他们分析了UBU积分器，该积分器是二阶强型的，并且每个步骤只需要一次梯度评估，从而得到了理想的非渐近保证，特别是在Wasserstein-2距离中到达离目标分布 $\epsilon > 0$ 的距离仅需 $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ 步。然而，Sanz-Serna和Zygalakis (2021)中的局部误差估计存在错误，在实践中需要更强的假设才能实现这些复杂度估计。本文解决了理论与实践中观察到的许多应用场景中的维度依赖性。

    arXiv:2402.08711v1 Announce Type: cross Abstract: A method for analyzing non-asymptotic guarantees of numerical discretizations of ergodic SDEs in Wasserstein-2 distance is presented by Sanz-Serna and Zygalakis in ``Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations". They analyze the UBU integrator which is strong order two and only requires one gradient evaluation per step, resulting in desirable non-asymptotic guarantees, in particular $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ steps to reach a distance of $\epsilon > 0$ in Wasserstein-2 distance away from the target distribution. However, there is a mistake in the local error estimates in Sanz-Serna and Zygalakis (2021), in particular, a stronger assumption is needed to achieve these complexity estimates. This note reconciles the theory with the dimension dependence observed in practice in many applications of interest.
    
[^23]: 在高维环境下，关于非可微惩罚项的LOOCV的理论分析

    Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings

    [https://arxiv.org/abs/2402.08543](https://arxiv.org/abs/2402.08543)

    本文在高维环境下，针对非可微惩罚项（如推广的LASSO和核范数），通过研究LOOCV在估计外样本风险时的有限样本上界，解决了这个理论缺失的问题。

    

    尽管在高维情况下，关于正则化模型的非样条惩罚项（如推广的LASSO和核范数）的外样本风险估计有大量的重要工作，但对于这个问题的理论理解仍然缺失。在本文中，我们解决了这个挑战。我们在比例高维情况下研究了这个问题，其中样本量n和特征数p都很大，且n/p和信噪比（每个观测）保持有限。我们给出了LOOCV在估计外样本风险时的有限样本上界。本文提出的理论框架为阐明LOOCV的准确性提供了坚实的基础。

    Despite a large and significant body of recent work focused on estimating the out-of-sample risk of regularized models in the high dimensional regime, a theoretical understanding of this problem for non-differentiable penalties such as generalized LASSO and nuclear norm is missing. In this paper we resolve this challenge. We study this problem in the proportional high dimensional regime where both the sample size n and number of features p are large, and n/p and the signal-to-noise ratio (per observation) remain finite. We provide finite sample upper bounds on the expected squared error of leave-one-out cross-validation (LO) in estimating the out-of-sample risk. The theoretical framework presented here provides a solid foundation for elucidating empirical findings that show the accuracy of LO.
    
[^24]: 离散扩散模型的收敛分析：通过均匀化的确切实现

    Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization

    [https://arxiv.org/abs/2402.08095](https://arxiv.org/abs/2402.08095)

    本文通过均匀化的方式确切实现了离散扩散模型，研究了其理论性质，并提供了关于采样的总变差距离和KL散度保证。这一方法在建模离散数据方面具有重要的应用价值。

    

    扩散模型在数据生成任务中取得了巨大的经验成功。最近，一些努力已经被做出来，将扩散模型的框架适应到离散状态空间，为建模本质上是离散数据（如语言和图形）提供了一种更自然的方法。这通过将前向噪声过程和相应的逆过程都构建为连续时间马尔可夫链（CTMC）来实现。在本文中，我们研究了离散扩散模型的理论性质。具体而言，我们介绍了一种利用连续马尔可夫链均匀化的算法，在随机时间点上实现转移。在关于离散得分函数学习的合理假设下，我们得到了从超立方体上的任何分布进行采样所需的总变差距离和KL散度保证。我们的结果与在$\mathbb{R}^d$中的扩散模型的最新成就相一致，并进一步强调了d的优势。

    Diffusion models have achieved huge empirical success in data generation tasks. Recently, some efforts have been made to adapt the framework of diffusion models to discrete state space, providing a more natural approach for modeling intrinsically discrete data, such as language and graphs. This is achieved by formulating both the forward noising process and the corresponding reversed process as Continuous Time Markov Chains (CTMCs). In this paper, we investigate the theoretical properties of the discrete diffusion model. Specifically, we introduce an algorithm leveraging the uniformization of continuous Markov chains, implementing transitions on random time points. Under reasonable assumptions on the learning of the discrete score function, we derive Total Variation distance and KL divergence guarantees for sampling from any distribution on a hypercube. Our results align with state-of-the-art achievements for diffusion models in $\mathbb{R}^d$ and further underscore the advantages of d
    
[^25]: 基于分数的生成模型在学习一个子高斯概率分布族中突破了维数灾难

    Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions

    [https://arxiv.org/abs/2402.08082](https://arxiv.org/abs/2402.08082)

    基于分数的生成模型在学习一个子高斯概率分布族中突破了维数灾难，通过分数匹配生成的分布以维度无关的速率逼近目标分布的总变差。

    

    尽管基于分数的生成模型（SGMs）在巨大的图像生成任务中取得了显著的成功，但它们的数学基础仍然有限。在本文中，我们分析了SGMs在学习一个子高斯概率分布族中的近似和泛化。我们引入了一种关于概率分布复杂性的概念，即相对密度与标准高斯测度的相对密度。我们证明，如果对数相对密度可以通过神经网络进行局部逼近，并且网络参数可以适当地受限，那么通过经验分数匹配生成的分布以维度无关的速率逼近目标分布的总变差。我们通过示例说明了我们的理论，其中包括某些高斯混合分布。我们证明的一个关键点是推导出与正向过程相关的真实得分函数的维度无关的深度神经网络逼近速率。

    While score-based generative models (SGMs) have achieved remarkable success in enormous image generation tasks, their mathematical foundations are still limited. In this paper, we analyze the approximation and generalization of SGMs in learning a family of sub-Gaussian probability distributions. We introduce a notion of complexity for probability distributions in terms of their relative density with respect to the standard Gaussian measure. We prove that if the log-relative density can be locally approximated by a neural network whose parameters can be suitably bounded, then the distribution generated by empirical score matching approximates the target distribution in total variation with a dimension-independent rate. We illustrate our theory through examples, which include certain mixtures of Gaussians. An essential ingredient of our proof is to derive a dimension-free deep neural network approximation rate for the true score function associated with the forward process, which is inte
    
[^26]: 一个贝叶斯聚类有效性指数

    A Bayesian cluster validity index

    [https://arxiv.org/abs/2402.02162](https://arxiv.org/abs/2402.02162)

    该论文提出了一个基于贝叶斯方法的聚类有效性指数，该指数根据现有的基础指数定义，并用于检测次优聚类数，通过与其他指数进行比较，验证了其有效性。

    

    在应用聚类算法时，选择聚类数是关键步骤之一。为了完成这个任务，引入了各种聚类有效性指数（CVIs）。大多数聚类有效性指数都被定义为检测数据集中隐藏的最优聚类数。然而，用户有时并不期望获得最优聚类数，而是更适合他们应用的次优聚类数。这促使我们引入了一种基于现有基础指数的贝叶斯聚类有效性指数（BCVI）。该指数基于狄利克雷或广义狄利克雷先验定义，得到相同的后验分布。然后我们基于Wiroonsri指数（WI）和Wiroonsri-Preedasawakul指数（WP）作为硬聚类和软聚类的基础指数来测试我们的BCVI。我们将它们的结果与原始的基础指数以及一些其他存在的CVIs（包括Davies and Bouldin (DB)，Starczewski (STR)）进行比较。

    Selecting the number of clusters is one of the key processes when applying clustering algorithms. To fulfill this task, various cluster validity indices (CVIs) have been introduced. Most of the cluster validity indices are defined to detect the optimal number of clusters hidden in a dataset. However, users sometimes do not expect to get the optimal number of groups but a secondary one which is more reasonable for their applications. This has motivated us to introduce a Bayesian cluster validity index (BCVI) based on existing underlying indices. This index is defined based on either Dirichlet or Generalized Dirichlet priors which result in the same posterior distribution. Our BCVI is then tested based on the Wiroonsri index (WI), and the Wiroonsri-Preedasawakul index (WP) as underlying indices for hard and soft clustering, respectively. We compare their outcomes with the original underlying indices, as well as a few more existing CVIs including Davies and Bouldin (DB), Starczewski (STR)
    
[^27]: 理解Transformer在序列建模中的表达能力和机制

    Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling

    [https://arxiv.org/abs/2402.00522](https://arxiv.org/abs/2402.00522)

    本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。

    

    我们对Transformer在长、稀疏和复杂记忆的序列建模中的近似性质进行了系统研究。我们调查了Transformer的不同组件（如点积自注意力、位置编码和前馈层）是如何影响其表达能力的机制，并通过建立明确的近似率来研究它们的综合影响。我们的研究揭示了Transformer中关键参数（如层数和注意力头数）的作用，并且这些洞察还为替代架构提供了自然建议。

    We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.
    
[^28]: 关注图神经网络用于稳健的大规模网络定位

    Attentional Graph Neural Networks for Robust Massive Network Localization

    [https://arxiv.org/abs/2311.16856](https://arxiv.org/abs/2311.16856)

    本文通过将图神经网络与注意机制相结合，提出了一种用于网络定位的新方法。该方法具有出色的精确度，甚至在严重非直视视线条件下也能表现出良好的效果。通过提出的关注图神经网络模型，我们进一步改善了现有方法的灵活性和对超参数的敏感性。

    

    近年来，图神经网络(GNNs)已成为机器学习分类任务中的重要工具。然而，它们在回归任务中的应用仍然未被充分探索。为了发掘GNNs在回归中的潜力，本文将GNNs与注意机制相结合，这是一种通过其适应性和鲁棒性彻底改变了序列学习任务的技术，以解决一个具有挑战性的非线性回归问题：网络定位。我们首先介绍了一种基于图卷积网络(GCN)的新型网络定位方法，即使在严重非直视视线(NLOS)条件下也表现出卓越的精度，从而减少了繁琐的离线校准或NLOS识别的需求。我们进一步提出了一种关注图神经网络(AGNN)模型，旨在改善基于GCN方法的有限灵活性和对超参数的高敏感性。

    arXiv:2311.16856v2 Announce Type: replace Abstract: In recent years, Graph neural networks (GNNs) have emerged as a prominent tool for classification tasks in machine learning. However, their application in regression tasks remains underexplored. To tap the potential of GNNs in regression, this paper integrates GNNs with attention mechanism, a technique that revolutionized sequential learning tasks with its adaptability and robustness, to tackle a challenging nonlinear regression problem: network localization. We first introduce a novel network localization method based on graph convolutional network (GCN), which exhibits exceptional precision even under severe non-line-of-sight (NLOS) conditions, thereby diminishing the need for laborious offline calibration or NLOS identification. We further propose an attentional graph neural network (AGNN) model, aimed at improving the limited flexibility and mitigating the high sensitivity to the hyperparameter of the GCN-based method. The AGNN co
    
[^29]: 关于时序差异学习的统计优势

    On the Statistical Benefits of Temporal Difference Learning

    [https://arxiv.org/abs/2301.13289](https://arxiv.org/abs/2301.13289)

    时序差异学习方法通过最小化连续时间步骤中的估计时序不一致度来拟合值函数，具有统计优势，可以显著减少值估计的均方误差，并且可以在两个状态的值差估计中获得显著改进。

    

    给定一个关于动作和长期奖励的数据集，直接估计方法通过将值函数与训练数据的预测误差最小化来拟合。而时序差异学习(TD)方法则通过最小化在连续时间步骤中进行的估计之间的时序不一致程度来拟合值函数。针对有限状态Markov链，我们提供了关于这种方法的统计优势的清晰渐进理论。首先，我们证明了一个直观的逆轨迹汇集系数完全刻画了值估计均方误差的百分比减少。根据问题结构的不同，这种减少可以是巨大的或不存在的。接下来，我们证明了两个状态的值差估计可以有巨大的改进：TD的误差受到问题轨迹交叉时间的界限，而这个界限可能远小于概率。

    arXiv:2301.13289v3 Announce Type: replace Abstract: Given a dataset on actions and resulting long-term rewards, a direct estimation approach fits value functions that minimize prediction error on the training data. Temporal difference learning (TD) methods instead fit value functions by minimizing the degree of temporal inconsistency between estimates made at successive time-steps. Focusing on finite state Markov chains, we provide a crisp asymptotic theory of the statistical advantages of this approach. First, we show that an intuitive inverse trajectory pooling coefficient completely characterizes the percent reduction in mean-squared error of value estimates. Depending on problem structure, the reduction could be enormous or nonexistent. Next, we prove that there can be dramatic improvements in estimates of the difference in value-to-go for two states: TD's errors are bounded in terms of a novel measure - the problem's trajectory crossing time - which can be much smaller than the pr
    
[^30]: 乐观调节的在线学习

    Optimistically Tempered Online Learning

    [https://arxiv.org/abs/2301.07530](https://arxiv.org/abs/2301.07530)

    本文提出了一种乐观调节的在线学习框架和适应算法，挑战了对专家的信心假设，并通过动态遗憾界限的理论保证和实验证明了该方法的有效性。

    

    乐观在线学习算法已经被开发出来，以利用专家意见，假设专家意见总是有用的。然而，我们可以合理地对这些意见与基于梯度的在线算法提供的学习信息的相关性提出质疑。在这项工作中，我们质疑对专家的信心假设，并开发了乐观调节（OT）在线学习框架以及在线算法的OT适应性。我们的算法具有动态遗憾界限的稳固理论保证，并最终验证了OT方法的有用性。

    arXiv:2301.07530v2 Announce Type: replace Abstract: Optimistic Online Learning algorithms have been developed to exploit expert advices, assumed optimistically to be always useful. However, it is legitimate to question the relevance of such advices \emph{w.r.t.} the learning information provided by gradient-based online algorithms. In this work, we challenge the confidence assumption on the expert and develop the \emph{optimistically tempered} (OT) online learning framework as well as OT adaptations of online algorithms. Our algorithms come with sound theoretical guarantees in the form of dynamic regret bounds, and we eventually provide experimental validation of the usefulness of the OT approach.
    
[^31]: 高维非定向图模型中的任意混合数据

    High-Dimensional Undirected Graphical Models for Arbitrary Mixed Data

    [https://arxiv.org/abs/2211.11700](https://arxiv.org/abs/2211.11700)

    本文提出了在高维非定向图模型中处理任意混合数据的方法，通过在潜变量高斯copula框架中应用经典的多项和多序相关的思想。

    

    图模型是探索复杂多变量数据中变量之间关系的重要工具。学习这些图模型的方法在所有变量都是连续或离散的情况下已经很成熟，包括高维情况。然而，在许多应用中，数据涉及不同类型的变量（例如连续、计数、二值、有序等），其联合分析是非平凡的。最近的研究进展已经展示了如何处理二值-连续情况，但是一般的混合变量类型仍然具有挑战性。在这项工作中，我们简单而有用地观察到，关于多项与多序相关的经典思想可以在潜变量高斯copula框架中得到应用。

    arXiv:2211.11700v2 Announce Type: replace-cross Abstract: Graphical models are an important tool in exploring relationships between variables in complex, multivariate data. Methods for learning such graphical models are well developed in the case where all variables are either continuous or discrete, including in high-dimensions. However, in many applications data span variables of different types (e.g. continuous, count, binary, ordinal, etc.), whose principled joint analysis is nontrivial. Latent Gaussian copula models, in which all variables are modeled as transformations of underlying jointly Gaussian variables, represent a useful approach. Recent advances have shown how the binary-continuous case can be tackled, but the general mixed variable type regime remains challenging. In this work, we make the simple yet useful observation that classical ideas concerning polychoric and polyserial correlations can be leveraged in a latent Gaussian copula framework. Building on this observati
    
[^32]: 《置换等变量量子神经网络的理论保证》

    Theoretical Guarantees for Permutation-Equivariant Quantum Neural Networks

    [https://arxiv.org/abs/2210.09974](https://arxiv.org/abs/2210.09974)

    这篇论文主要研究了置换等变量量子神经网络在量子机器学习中的应用。研究发现，这种架构能够解决传统 QNNs 遇到的局部最小值和贫瘠的高原问题，并能够在少量数据上进行良好的泛化。

    

    尽管量子机器学习模型有着巨大的潜力，但在释放其全部潜力之前，我们必须克服一些挑战。例如，基于量子神经网络（QNN）的模型可能在训练过程中遇到过多的局部最小值和贫瘠的高原问题。最近，几何量子机器学习（GQML）这一新兴领域已被提出作为其中一些问题的潜在解决方案。GQML 的关键见解是，我们应该设计编码问题的对称性的架构，例如等变 QNNs。在这里，我们专注于具有置换对称性（即对称群 $S_n$）的问题，并展示了如何构建 $S_n$-equivariant QNNs。我们对它们的性能进行了分析研究，证明它们不会遭遇贫瘠的高原问题，能够快速实现过参数化，并且能够从少量的数据中进行良好的泛化。为了验证我们的结果，我们进行了数值仿真实验。

    arXiv:2210.09974v3 Announce Type: replace-cross Abstract: Despite the great promise of quantum machine learning models, there are several challenges one must overcome before unlocking their full potential. For instance, models based on quantum neural networks (QNNs) can suffer from excessive local minima and barren plateaus in their training landscapes. Recently, the nascent field of geometric quantum machine learning (GQML) has emerged as a potential solution to some of those issues. The key insight of GQML is that one should design architectures, such as equivariant QNNs, encoding the symmetries of the problem at hand. Here, we focus on problems with permutation symmetry (i.e., the group of symmetry $S_n$), and show how to build $S_n$-equivariant QNNs. We provide an analytical study of their performance, proving that they do not suffer from barren plateaus, quickly reach overparametrization, and generalize well from small amounts of data. To verify our results, we perform numerical s
    
[^33]: 动态维护核密度估计数据结构：从实践到理论

    Dynamic Maintenance of Kernel Density Estimation Data Structure: From Practice to Theory

    [https://arxiv.org/abs/2208.03915](https://arxiv.org/abs/2208.03915)

    本文研究了具有对抗性查询鲁棒性的动态维护核密度估计数据结构，并提供了一个亚二次空间复杂度和亚线性更新时间的理论框架。

    

    Kernel density estimation (KDE)在机器学习中是一项具有挑战性的任务。该问题定义如下：给定一个核函数$f(x,y)$和一组点$\{x_1, x_2, \cdots, x_n \} \subset \mathbb{R}^d$，我们希望计算任意查询点$y \in \mathbb{R}^d$的$\frac{1}{n}\sum_{i=1}^{n} f(x_i,y)$。近年来，使用数据结构来高效计算KDE的趋势日益增加。然而，现有的KDE数据结构提供的是静态设置下的解决方案，对于动态变化的数据分布的鲁棒性问题并未得到解决。本文旨在研究具有对抗性查询鲁棒性的动态维护KDE数据结构。特别地，我们提供了一个KDE数据结构的理论框架。在我们的框架中，KDE数据结构只需要亚二次空间复杂度。此外，我们的数据结构支持数据集的动态更新，且更新时间为亚线性时间。

    arXiv:2208.03915v2 Announce Type: replace Abstract: Kernel density estimation (KDE) stands out as a challenging task in machine learning. The problem is defined in the following way: given a kernel function $f(x,y)$ and a set of points $\{x_1, x_2, \cdots, x_n \} \subset \mathbb{R}^d$, we would like to compute $\frac{1}{n}\sum_{i=1}^{n} f(x_i,y)$ for any query point $y \in \mathbb{R}^d$. Recently, there has been a growing trend of using data structures for efficient KDE. However, the proposed KDE data structures focus on static settings. The robustness of KDE data structures over dynamic changing data distributions is not addressed. In this work, we focus on the dynamic maintenance of KDE data structures with robustness to adversarial queries. Especially, we provide a theoretical framework of KDE data structures. In our framework, the KDE data structures only require subquadratic spaces. Moreover, our data structure supports the dynamic update of the dataset in sublinear time. Furtherm
    
[^34]: 低秩马尔可夫决策过程中可证明高效的表示选择：从在线到离线强化学习

    Provably Efficient Representation Selection in Low-rank Markov Decision Processes: From Online to Offline RL

    [https://arxiv.org/abs/2106.11935](https://arxiv.org/abs/2106.11935)

    本论文研究了在低秩马尔可夫决策过程中表示选择对于提高强化学习效率的影响。提出了ReLEX算法，可以在在线和离线强化学习中实现高效表示学习。实验证明，在线版本ReLEX-UCB总是不比没有表示选择的最先进算法差，并在表示函数类具有“覆盖度”性质时，实现了更好的常数遗憾。对于离线版本ReLEX-LCB，可以找到最优策略。

    

    深度强化学习(DRL)的成功在于其学习适合探索和利用任务的表示。为了理解表示选择如何提高强化学习的效率，我们研究了一类低秩马尔可夫决策过程(MDP)，其中转移核能够以双线性形式表示。我们提出了一个称为ReLEX的高效算法，用于在线和离线强化学习中的表示学习。具体来说，我们展示了ReLEX的在线版本ReLEX-UCB总是不比没有表示选择的最先进算法差，并在表示函数类在整个状态-动作空间上具有“覆盖度”性质时，实现了更好的常数遗憾。对于其离线对应物ReLEX-LCB，我们展示了该算法可以找到最优策略，如果表示函数类具有“覆盖度”性质。

    arXiv:2106.11935v2 Announce Type: replace Abstract: The success of deep reinforcement learning (DRL) lies in its ability to learn a representation that is well-suited for the exploration and exploitation task. To understand how the choice of representation can improve the efficiency of reinforcement learning (RL), we study representation selection for a class of low-rank Markov Decision Processes (MDPs) where the transition kernel can be represented in a bilinear form. We propose an efficient algorithm, called ReLEX, for representation learning in both online and offline RL. Specifically, we show that the online version of ReLEX, called ReLEX-UCB, always performs no worse than the state-of-the-art algorithm without representation selection, and achieves a strictly better constant regret if the representation function class has a "coverage" property over the entire state-action space. For the offline counterpart, ReLEX-LCB, we show that the algorithm can find the optimal policy if the r
    
[^35]: 两时间尺度带马尔可夫噪声的随机逼近中心极限定理：理论和应用

    Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications. (arXiv:2401.09339v1 [stat.ML])

    [http://arxiv.org/abs/2401.09339](http://arxiv.org/abs/2401.09339)

    本文通过对两时间尺度随机逼近（TTSA）的广义分析，利用中心极限定理（CLT）揭示了TTSA受马尔可夫噪声影响的耦合动力学，从而拓展了传统SGD的高效采样策略在分布式学习中的应用范围，同时研究了具有非线性函数逼近的GTD算法的统计特性。

    

    两时间尺度随机逼近（TTSA）是最通用的迭代随机算法框架之一。这包括了众所周知的随机优化方法，如SGD变种和用于双层或极小化问题的方法，以及类似梯度-based时序差异（GTD）算法的强化学习方法。本文通过中心极限定理（CLT）对带控制马尔可夫噪声的TTSA进行了深入的渐近分析，揭示了TTSA受底层马尔可夫链影响的耦合动力学，这在以前仅考虑鞅差异噪声的TTSA的CLT结果中没有得到解决。基于我们的CLT，我们将高效采样策略的应用范围从传统SGD扩展到了更广泛的TTSA背景下的分布式学习，从而扩大了胡等人（2022）的研究范围。此外，我们利用我们的CLT结果推导了具有非线性函数逼近的GTD算法的统计特性。

    Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approxi
    
[^36]: 通用因果表达学习的可识别性和可实现性

    General Identifiability and Achievability for Causal Representation Learning. (arXiv:2310.15450v1 [cs.LG])

    [http://arxiv.org/abs/2310.15450](http://arxiv.org/abs/2310.15450)

    本文在通用非参数因果潜变量模型和通用转换模型下，通过非耦合干预建立了因果表达学习的可识别性和可实现性结果。在不知道具体干预对应的节点的情况下，这些结果保证了潜在的因果模型和变量的完美恢复，并设计了一个算法来实现这一目标。

    

    本文关注通用非参数因果潜变量模型和将潜变量数据映射到观测数据的通用转换模型下的因果表达学习。通过在潜在因果图中每个节点进行两个硬性非耦合干预来建立可识别性和可实现性结果。值得注意的是，人们不知道哪个干预环境对应的节点是相同的（因此是非耦合环境）。在可识别性方面，本文确保在非耦合干预下能够完美恢复潜在的因果模型和变量。在可实现性方面，设计了一个算法，利用观测和干预数据，并提供了对该算法的可验证的保证，以恢复潜在的因果模型和变量。该算法利用不同环境中的得分变化来估计转换器的逆和随后的潜变量。该分析还...

    This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes \textbf{identifiability} and \textbf{achievability} results using two hard \textbf{uncoupled} interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, addit
    
[^37]: 贝叶斯主动元学习的基本困境

    The Fundamental Dilemma of Bayesian Active Meta-learning. (arXiv:2310.14968v1 [cs.LG])

    [http://arxiv.org/abs/2310.14968](http://arxiv.org/abs/2310.14968)

    在贝叶斯主动元学习中，贪婪追求可转移知识可能会损害对可转移参数的估计，学习者面临任务识别和可转移知识获取之间的困境。

    

    许多应用需要估计在多个不同但相关的数据稀缺任务环境中推广的参数。贝叶斯主动元学习是一种顺序最优实验设计的形式，为解决这类问题提供了一个框架。主动元学习者的目标是在当前任务的特殊特征（任务特定参数）的情况下获得可转移的知识（估计可转移的参数）。我们证明，在这种情况下，贪婪追求这个目标实际上可能会损害对可转移参数的估计（引起所谓的负迁移）。学习者面临着一个类似但不同于勘探-利用困境的困境：他们应该花费他们的获取预算来追求可转移的知识，还是用来确定当前任务特定的参数？我们理论上证明，一些任务存在不可避免且任意大的负迁移威胁，任务的识别对于重新寻找可迁移参数至关重要。

    Many applications involve estimation of parameters that generalize across multiple diverse, but related, data-scarce task environments. Bayesian active meta-learning, a form of sequential optimal experimental design, provides a framework for solving such problems. The active meta-learner's goal is to gain transferable knowledge (estimate the transferable parameters) in the presence of idiosyncratic characteristics of the current task (task-specific parameters). We show that in such a setting, greedy pursuit of this goal can actually hurt estimation of the transferable parameters (induce so-called negative transfer). The learner faces a dilemma akin to but distinct from the exploration--exploitation dilemma: should they spend their acquisition budget pursuing transferable knowledge, or identifying the current task-specific parameters? We show theoretically that some tasks pose an inevitable and arbitrarily large threat of negative transfer, and that task identification is critical to re
    
[^38]: 基于MMD的分布随机森林的变量重要性

    MMD-based Variable Importance for Distributional Random Forest. (arXiv:2310.12115v1 [stat.ML])

    [http://arxiv.org/abs/2310.12115](http://arxiv.org/abs/2310.12115)

    本文介绍了基于MMD距离和经典的drop and relearn原理的变量重要性算法，可以在分布随机森林中检测影响输出分布的变量，并且在实证性能上超越了竞争对手。

    

    分布随机森林（DRF）是一种灵活的基于森林的方法，用于估计给定输入变量的多元输出的全条件分布。在本文中，我们介绍了一种基于经典的drop and relearn原理和MMD距离的DRF变量重要性算法。传统的重要性度量只能发现对输出均值有影响的变量，而我们的算法可以更普遍地发现影响输出分布的变量。我们展示了引入的重要性度量是一致的，在真实数据和模拟数据上具有较高的实证性能，并且超越了竞争对手。特别地，我们的算法通过递归特征消除高效地选择变量，因此可以提供小型变量集合来构建准确的条件输出分布估计。

    Distributional Random Forest (DRF) is a flexible forest-based method to estimate the full conditional distribution of a multivariate output of interest given input variables. In this article, we introduce a variable importance algorithm for DRFs, based on the well-established drop and relearn principle and MMD distance. While traditional importance measures only detect variables with an influence on the output mean, our algorithm detects variables impacting the output distribution more generally. We show that the introduced importance measure is consistent, exhibits high empirical performance on both real and simulated data, and outperforms competitors. In particular, our algorithm is highly efficient to select variables through recursive feature elimination, and can therefore provide small sets of variables to build accurate estimates of conditional output distributions.
    
[^39]: DPZero：与维度无关且具有差分隐私的零阶优化算法

    DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization. (arXiv:2310.09639v1 [cs.LG])

    [http://arxiv.org/abs/2310.09639](http://arxiv.org/abs/2310.09639)

    该论文提出了DPZero算法，这是一种与维度无关且具有差分隐私的零阶优化算法，用于解决在细调大型语言模型时面临的内存和隐私挑战。

    

    在细调预训练的大型语言模型（LLM）以适应特定领域数据的广泛实践中，面临着内存和隐私两个主要挑战。首先，随着LLM的规模不断增长，达到数十亿个参数，基于梯度的反向传播训练方法所需的内存消耗变得难以承受。其次，考虑到LLM倾向于记忆和泄露敏感的训练数据，必须保护细调数据的隐私。为此，我们探索了将零阶方法与差分隐私优化相结合用于LLM的细调的潜力。零阶方法仅依赖前向传递，大大减少了训练过程中的内存消耗。然而，直接将它们与标准的差分隐私机制结合在一起会导致维度相关的复杂性。为了弥合这一差距，我们引入了DPZero，一种具有近乎维度无关率的新型差分隐私零阶算法。我们的理论分析揭示出了

    The widespread practice of fine-tuning pretrained large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continue to grow, encompassing billions of parameters, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize and disclose sensitive training data, the privacy of fine-tuning data must be respected. To this end, we explore the potential of zeroth-order methods in differentially private optimization for fine-tuning LLMs. Zeroth-order methods, which rely solely on forward passes, substantially reduce memory consumption during training. However, directly combining them with standard differential privacy mechanism poses dimension-dependent complexity. To bridge the gap, we introduce DPZero, a novel differentially private zeroth-order algorithm with nearly dimension-independent rates. Our theoretical analysis reveals that 
    
[^40]: 生成分类器的有趣属性

    Intriguing properties of generative classifiers. (arXiv:2309.16779v1 [cs.CV])

    [http://arxiv.org/abs/2309.16779](http://arxiv.org/abs/2309.16779)

    生成分类器展示了记录破纪录的人类形状偏好、接近人类级别的超出分布准确性、与人类分类错误的最先进对齐以及理解某些知觉幻象的新兴特性，揭示了零样本生成模型出奇地接近人类物体识别数据。

    

    识别对象的最佳范式是判别式推理（快速但潜在容易出现快捷学习）还是使用生成模型（较慢但潜在更稳健）？我们借鉴了最新的生成模型进展，将文本到图像模型转化为分类器。这使得我们能够研究其行为，并将其与判别模型和人类心理物理数据进行比较。我们报道了生成分类器的四个有趣的新兴特性：它们显示出破纪录的人类形状偏好（对于Imagen达到99%），接近人类级别的超出分布准确性，与人类分类错误的最先进对齐以及它们理解某些知觉幻象。我们的结果表明，尽管目前模拟人类物体识别的主导范式是判别式推理，零样本生成模型出奇地接近人类物体识别数据。

    What is the best paradigm to recognize objects -- discriminative inference (fast but potentially prone to shortcut learning) or using a generative model (slow but potentially more robust)? We build on recent advances in generative modeling that turn text-to-image models into classifiers. This allows us to study their behavior and to compare them against discriminative models and human psychophysical data. We report four intriguing emergent properties of generative classifiers: they show a record-breaking human-like shape bias (99% for Imagen), near human-level out-of-distribution accuracy, state-of-the-art alignment with human classification errors, and they understand certain perceptual illusions. Our results indicate that while the current dominant paradigm for modeling human object recognition is discriminative inference, zero-shot generative models approximate human object recognition data surprisingly well.
    
[^41]: 异质搜索空间上的贝叶斯优化的迁移学习

    Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])

    [http://arxiv.org/abs/2309.16597](http://arxiv.org/abs/2309.16597)

    本文提出了MPHD方法，通过模型预训练和神经网络在异质搜索空间上实现贝叶斯优化的迁移学习。实验证明了MPHD的有效性和在黑盒函数优化任务中的优越性能。

    

    贝叶斯优化是一种流行的黑盒函数优化方法，它基于贝叶斯模型（通常是高斯过程）进行顺序决策。为了确保模型的质量，我们开发了迁移学习方法，通过学习来自“训练”函数的观察结果来自动设计高斯过程先验。这些训练函数通常需要与“测试”函数（待优化的黑盒函数）具有相同的定义域。在本文中，我们介绍了一种名为MPHD的模型预训练方法，它使用神经网络将特定于领域的上下文映射到分层高斯过程的规范。MPHD可以与贝叶斯优化无缝集成，实现异质搜索空间的知识迁移。我们的理论和实证结果证明了MPHD的有效性，并展示了它在具有挑战性的黑盒函数优化任务中的优越性能。

    Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on "training" functions. These training functions are typically required to have the same domain as the "test" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks.
    
[^42]: 隐式归一化显式正则化密度估计

    Implicitly Normalized Explicitly Regularized Density Estimation. (arXiv:2307.13763v1 [stat.ML])

    [http://arxiv.org/abs/2307.13763](http://arxiv.org/abs/2307.13763)

    我们提出了一种新的非参数密度估计方法，基于正则化密度的 Sobolev 范数，通过适当的初始化和使用自然梯度，可以得到性能良好的解，该方法在 Anomaly Detection benchmark 中排名第二。

    

    我们提出了一种新的非参数密度估计方法，该方法是基于正则化密度的 Sobolev 范数。这种方法与核密度估计有明显差异，可以清晰解释模型的偏差。虽然我们无法得到相关核函数的闭合解析形式，但我们证明可以通过采样进行近似。决定密度的优化问题是非凸的，标准的梯度方法效果不好。然而，我们证明在适当的初始化和使用自然梯度的情况下，可以得到性能良好的解。最后，虽然该方法提供的是非归一化的密度，无法使用对数似然进行交叉验证，但我们证明可以采用基于 Fisher 散度的分数匹配方法来解决这个问题。我们在最近的异常检测基准套件 ADBench 上评估了得到的方法，并发现它在超过15个算法中排名第二。

    We propose a new approach to non-parametric density estimation, that is based on regularizing a Sobolev norm of the density. This method is provably different from Kernel Density Estimation, and makes the bias of the model clear and interpretable. While there is no closed analytic form for the associated kernel, we show that one can approximate it using sampling. The optimization problem needed to determine the density is non-convex, and standard gradient methods do not perform well. However, we show that with an appropriate initialization and using natural gradients, one can obtain well performing solutions. Finally, while the approach provides unnormalized densities, which prevents the use of log-likelihood for cross validation, we show that one can instead adapt Fisher Divergence based Score Matching methods for this task. We evaluate the resulting method on the comprehensive recent Anomaly Detection benchmark suite, ADBench, and find that it ranks second best, among more than 15 al
    
[^43]: 理解深度异方差回归的病态

    Understanding Pathologies of Deep Heteroskedastic Regression. (arXiv:2306.16717v1 [stat.ML])

    [http://arxiv.org/abs/2306.16717](http://arxiv.org/abs/2306.16717)

    该论文研究了利用异方差神经回归模型对真实世界数据进行建模时的困难，并从统计物理的角度提供了解释。作者证明了这些不稳定性不仅适用于神经网络结构，而且已经在过参数化条件高斯似然模型的场论中存在。数值求解结果与实证模型拟合的定性一致性证明了相变的存在。

    

    近期的研究报告了在使用异方差神经回归模型对真实世界数据建模时出现的负面结果。特别是，对于过参数化模型，均值网络和方差网络足够强大，可以拟合每个数据点（同时将预测的方差收缩到零），或者学习一个恒定的预测，输出方差恰好匹配每个预测残差（即将目标解释为纯噪声）。本文从统计物理的角度研究了这些困难。我们证明了观察到的不稳定性不特定于任何神经网络结构，而是已经存在于过参数化条件高斯似然模型的场论中。在轻微的假设下，我们推导出一个可以通过数值求解的非参数自由能。得到的解与真实世界数据上的实证模型拟合具有良好的定性一致性，并且特别证明了相变的存在。

    Several recent studies have reported negative results when using heteroskedastic neural regression models to model real-world data. In particular, for overparameterized models, the mean and variance networks are powerful enough to either fit every single data point (while shrinking the predicted variances to zero), or to learn a constant prediction with an output variance exactly matching every predicted residual (i.e., explaining the targets as pure noise). This paper studies these difficulties from the perspective of statistical physics. We show that the observed instabilities are not specific to any neural network architecture but are already present in a field theory of an overparameterized conditional Gaussian likelihood model. Under light assumptions, we derive a nonparametric free energy that can be solved numerically. The resulting solutions show excellent qualitative agreement with empirical model fits on real-world data and, in particular, prove the existence of phase transit
    
[^44]: 具有公共数据的最优差分隐私学习

    Optimal Differentially Private Learning with Public Data. (arXiv:2306.15056v1 [cs.LG])

    [http://arxiv.org/abs/2306.15056](http://arxiv.org/abs/2306.15056)

    本论文研究了具有公共数据的最优差分隐私学习，并解决了在训练差分隐私模型时如何利用公共数据提高准确性的问题。

    

    差分隐私能够确保训练机器学习模型不泄漏私密数据。然而，差分隐私的代价是模型的准确性降低或样本复杂度增加。在实践中，我们可能可以访问不涉及隐私问题的辅助公共数据。这促使了最近研究公共数据在提高差分隐私模型准确性方面的作用。在本研究中，我们假设有一定数量的公共数据，并解决以下基本开放问题：1.在有公共数据的情况下，训练基于私有数据集的差分隐私模型的最优（最坏情况）误差是多少？哪些算法是最优的？2.如何利用公共数据在实践中改进差分隐私模型训练？我们在本地模型和中心模型的差分隐私问题下考虑这些问题。为了回答第一个问题，我们证明了对三个基本问题的最优误差率的紧密（最高常数因子）下界和上界。这三个问题是：均值估计，经验风险最小化和凸奇化。

    Differential Privacy (DP) ensures that training a machine learning model does not leak private data. However, the cost of DP is lower model accuracy or higher sample complexity. In practice, we may have access to auxiliary public data that is free of privacy concerns. This has motivated the recent study of what role public data might play in improving the accuracy of DP models. In this work, we assume access to a given amount of public data and settle the following fundamental open questions: 1. What is the optimal (worst-case) error of a DP model trained over a private data set while having access to side public data? What algorithms are optimal? 2. How can we harness public data to improve DP model training in practice? We consider these questions in both the local and central models of DP. To answer the first question, we prove tight (up to constant factors) lower and upper bounds that characterize the optimal error rates of three fundamental problems: mean estimation, empirical ris
    
[^45]: 更多的PAC-Bayes Bounds：从有界损失到具有一般性尾部行为的损失，到任何时间均有效的损失。

    More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity. (arXiv:2306.12214v1 [stat.ML])

    [http://arxiv.org/abs/2306.12214](http://arxiv.org/abs/2306.12214)

    本文提出了一种新的高概率PAC-Bayes界限，在有界和一般尾部行为的损失中均适用。此外，这些界限还能够保持随时有效性。

    

    本文针对不同类型的损失提出了新的高概率PAC-Bayes界限。首先，针对有界范围的损失，我们提出了Catoni界的加强版本，适用于所有参数值的统一界。这导致了新的快速速率和混合速率上限，这些上限可解释性强且比文献中先前界限更紧。其次，针对更一般的尾部行为的损失，我们引入了两个新的无参数上限：当损失的累积生成函数有界时，我们引入了一个PAC-Bayes Chernoff类比，另一个上限是损失的二阶矩有界。这两个上限是利用一种基于可能事件空间的离散化的新技术获得的，“在概率”参数优化问题。最后，我们使用一种适用于任何现有界限的简单技术将所有先前结果扩展到任何时间有效的上限。

    In this paper, we present new high-probability PAC-Bayes bounds for different types of losses. Firstly, for losses with a bounded range, we present a strengthened version of Catoni's bound that holds uniformly for all parameter values. This leads to new fast rate and mixed rate bounds that are interpretable and tighter than previous bounds in the literature. Secondly, for losses with more general tail behaviors, we introduce two new parameter-free bounds: a PAC-Bayes Chernoff analogue when the loss' cumulative generating function is bounded, and a bound when the loss' second moment is bounded. These two bounds are obtained using a new technique based on a discretization of the space of possible events for the "in probability" parameter optimization problem. Finally, we extend all previous results to anytime-valid bounds using a simple technique applicable to any existing bound.
    
[^46]: $\texttt{causalAssembly}$: 用于基准因果发现的生成真实生产数据

    $\texttt{causalAssembly}$: Generating Realistic Production Data for Benchmarking Causal Discovery. (arXiv:2306.10816v1 [stat.ML])

    [http://arxiv.org/abs/2306.10816](http://arxiv.org/abs/2306.10816)

    该论文提出了一种生成基于装配线数据的半合成制造数据集的方法，以支持因果发现方法的基准测试。

    

    因果发现算法近年来取得了快速进展并越来越多地依靠灵活的非参数方法来处理复杂数据。然而，由于大多数真实数据源中真正的因果关系仍不为人所知，因此这些算法需要充分的经验验证。这个问题进一步加剧了环绕合适高质量数据发布的隐私问题。为了解决这些挑战，我们收集了一组复杂数据集，包括制造过程中装配线的测量数据。借助于对物理学的深入研究，这个数据集能够提供地面的因果关系对照。我们使用这个装配线数据和相关的地面真实信息来构建一个系统，生成半合成造数据来支持基准因果发现方法。为了实现这个目标，我们采用了最先进的仿真技术来生成数据集，模仿原始装配线数据集的特征，保留了过程变量之间的因果关系和它们的非线性依赖关系。

    Algorithms for causal discovery have recently undergone rapid advances and increasingly draw on flexible nonparametric methods to process complex data. With these advances comes a need for adequate empirical validation of the causal relationships learned by different algorithms. However, for most real data sources true causal relations remain unknown. This issue is further compounded by privacy concerns surrounding the release of suitable high-quality data. To help address these challenges, we gather a complex dataset comprising measurements from an assembly line in a manufacturing context. This line consists of numerous physical processes for which we are able to provide ground truth causal relationships on the basis of a detailed study of the underlying physics. We use the assembly line data and associated ground truth information to build a system for generation of semisynthetic manufacturing data that supports benchmarking of causal discovery methods. To accomplish this, we employ 
    
[^47]: 分布式SGD算法的稳定性与泛化分析改进

    Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm. (arXiv:2306.02939v1 [cs.LG])

    [http://arxiv.org/abs/2306.02939](http://arxiv.org/abs/2306.02939)

    本文提出了新的算法稳定性理论来改进分布式SGD算法的泛化性能分析，推翻了现有技术对通信图负面影响的观点，并展示了D-SGD在凸设置中与经典SGD算法泛化界相同。

    

    本文基于算法稳定性，提出了分布式随机梯度下降(D-SGD)算法的新的泛化误差分析方法。得到的结果大大改进了现有技术，并推翻了它们关于通信图对泛化的负面影响的观点。例如，在凸设置中，无论图的选择如何，D-SGD具有与经典SGD算法相同的泛化界。我们发现这种反直觉的结果来自于考虑本地参数的平均值，这会隐藏一个与分布式场景不兼容的最终全局平均化步骤。考虑到这一观察结果，我们倡导分析本地参数的上确界，并展示了在这种情况下，图确实对泛化产生影响。与之前的结果不同，我们的分析即使对于非连接图也能产生非平凡边界。

    This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.
    
[^48]: 不破坏黑盒分类器的情况下规避它的分类——基于实际代价的黑盒攻击

    Evading Black-box Classifiers Without Breaking Eggs. (arXiv:2306.02895v1 [cs.CR])

    [http://arxiv.org/abs/2306.02895](http://arxiv.org/abs/2306.02895)

    本文提出了一种基于实际代价的黑盒攻击，通过设计新的攻击方式，成功减少了“有害”查询的数量，提高了黑盒攻击效率。

    

    基于决策的规避攻击是通过不断查询黑盒分类器来生成对抗性样本。本文认为现有的攻击方式在处理对安全性敏感的机器学习系统时有缺陷。因为这些系统主要目的是过滤出有害数据（例如恶意软件、有害内容等），所以查询的代价是不对等的，一旦查询被检测出是有害的，就会触发额外的安全过滤，例如使用限制或账户暂停。然而，现有的基于决策的攻击产生了大量的“有害”查询，导致它们很可能对安全关键系统无效。因此，本文提出新的攻击方式，通过减少“有害”查询的数量（最多可以减少 $1.5$ 倍到 $7.3$ 倍），以实现更加有效的黑盒攻击。但这些攻击的正常查询数量大大增加，因此提出了在实际代价度量下构建更有效的黑盒攻击的开放性问题。

    Decision-based evasion attacks repeatedly query a black-box classifier to generate adversarial examples. Prior work measures the cost of such attacks by the total number of queries made to the classifier. We argue this metric is flawed. Most security-critical machine learning systems aim to weed out "bad" data (e.g., malware, harmful content, etc). Queries to such systems carry a fundamentally asymmetric cost: queries detected as "bad" come at a higher cost because they trigger additional security filters, e.g., usage throttling or account suspension. Yet, we find that existing decision-based attacks issue a large number of "bad" queries, which likely renders them ineffective against security-critical systems. We then design new attacks that reduce the number of bad queries by $1.5$-$7.3\times$, but often at a significant increase in total (non-bad) queries. We thus pose it as an open problem to build black-box attacks that are more effective under realistic cost metrics.
    
[^49]: 神经网络集合的输入梯度多样性

    Input gradient diversity for neural network ensembles. (arXiv:2306.02775v1 [stat.ML])

    [http://arxiv.org/abs/2306.02775](http://arxiv.org/abs/2306.02775)

    本文提出了一阶斥力深度集成 (FoRDE) 算法，它使用输入梯度来增强多样性以提高神经网络集成的表现。

    

    深度集成 (DE) 通过它们的功能多样性在准确性、校准性和抵抗干扰方面表现出比单个神经网络更好的表现。基于粒子的变分推断 (ParVI) 方法通过基于网络相似性内核的排斥项来增强多样性。然而，由于过度参数化，权重空间排斥是低效的，而直接功能空间排斥被发现对 DE 的改进很小。为了避免这些困难，我们提出了基于 ParVI 的一阶斥力深度集成 (FoRDE)，这是一种基于输入梯度的集成学习方法。由于输入梯度唯一地确定了一个函数并且比权重小得多，所以这种方法保证了集合成员在功能上是不同的。直观地说，多样化输入梯度鼓励每个网络学习不同的特征，这有望改善神经网络集成的表现。

    Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improv
    
[^50]: 深度学习中的一致置信现象及其对校准的影响

    A Uniform Confidence Phenomenon in Deep Learning and its Implications for Calibration. (arXiv:2306.00740v1 [cs.LG])

    [http://arxiv.org/abs/2306.00740](http://arxiv.org/abs/2306.00740)

    深度神经网络在训练点周围有大的几乎确定的置信邻域，这导致现代模型校准面临重要障碍。

    

    尽管深度神经网络具有惊人的泛化能力，但它们屡次表现出在预测不确定性方面估计不佳的情况——换句话说，它们在错误时经常过度自信。解决这个问题被称为模型校准，并以修改训练方案和训练后校准程序的形式受到了广泛关注。在本文中，我们提出了一个现代模型校准的重要障碍：深度神经网络在它们的训练点周围有大的几乎确定的置信邻域。我们在实验中证明了这种现象在很多模型和数据集对中都会出现（在图像分类的背景下）。此外，我们证明了当这种现象出现时，在类别之间存在重叠的大类数据分布中，即使在应用校准后也不能获得比随机更好的渐近校准模型（在渐近意义下）。

    Despite the impressive generalization capabilities of deep neural networks, they have been repeatedly shown to poorly estimate their predictive uncertainty - in other words, they are frequently overconfident when they are wrong. Fixing this issue is known as model calibration, and has consequently received much attention in the form of modified training schemes and post-training calibration procedures. In this work, we present a significant hurdle to the calibration of modern models: deep neural networks have large neighborhoods of almost certain confidence around their training points. We demonstrate in our experiments that this phenomenon consistently arises (in the context of image classification) across many model and dataset pairs. Furthermore, we prove that when this phenomenon holds, for a large class of data distributions with overlaps between classes, it is not possible to obtain a model that is asymptotically better than random (with respect to calibration) even after applyin
    
[^51]: 深度随机力学

    Deep Stochastic Mechanics. (arXiv:2305.19685v1 [cs.LG])

    [http://arxiv.org/abs/2305.19685](http://arxiv.org/abs/2305.19685)

    本文提出了一种基于深度学习的方法，用于数值模拟时间演化薛定谔方程，利用马尔可夫扩散采样来适应波函数的潜在低维结构，并提出了新的随机量子力学方程，具有线性的计算复杂度。数值模拟显示出显着的优势。

    

    本文引入了一种基于深度学习的方法，用于数值模拟时间演化薛定谔方程，受随机力学和生成性扩散模型的启发。与现有方法不同的是，我们的方法允许我们通过从马尔可夫扩散中采样来适应波函数潜在的低维结构，因此可以在更高的维度上降低计算复杂度。此外，我们提出了新的随机量子力学方程，结果具有与维数数量线性的计算复杂度。数值模拟验证了我们的理论发现，并显示出我们的方法与其他用于量子力学的基于深度学习的方法相比具有显着优势。

    This paper introduces a novel deep-learning-based approach for numerical simulation of a time-evolving Schr\"odinger equation inspired by stochastic mechanics and generative diffusion models. Unlike existing approaches, which exhibit computational complexity that scales exponentially in the problem dimension, our method allows us to adapt to the latent low-dimensional structure of the wave function by sampling from the Markovian diffusion. Depending on the latent dimension, our method may have far lower computational complexity in higher dimensions. Moreover, we propose novel equations for stochastic quantum mechanics, resulting in linear computational complexity with respect to the number of dimensions. Numerical simulations verify our theoretical findings and show a significant advantage of our method compared to other deep-learning-based approaches used for quantum mechanics.
    
[^52]: 扰动辅助样本合成：一种新的不确定性量化方法

    Perturbation-Assisted Sample Synthesis: A Novel Approach for Uncertainty Quantification. (arXiv:2305.18671v1 [stat.ML])

    [http://arxiv.org/abs/2305.18671](http://arxiv.org/abs/2305.18671)

    本文提出了扰动辅助样本合成（PASS）方法，可从复杂数据中绘制可靠结论，并通过估计数据生成分布和蒙特卡罗实验证明任何统计数据的估计分布。进一步推出扰动辅助推理（PAI）框架，可以提供有效性的统计保证。

    

    本文介绍了一种名为“扰动辅助样本合成（PASS）”的新型生成器，旨在从复杂数据中绘制可靠的结论，特别是在使用深度神经网络等高级建模技术时。 PASS利用扰动生成靠近原始数据分布的合成数据，包括数字和非结构化数据类型，如基因表达、图像和文本。通过估计数据生成分布并利用大型预训练生成模型，PASS提高了估计精度，并通过蒙特卡罗实验证明了任何统计数据的估计分布。基于PASS，我们提出了一种生成推理框架称为“扰动辅助推理（PAI）”，它提供了有效性的统计保证。在关键推理中，PAI使得在不知道引导分布（如模拟中）的情况下能够得出准确的结论，即使只有有限的数据。在非关键情况下，我们训练PASS使用中间变量插补策略来提高准确性。实验结果表明，在各种情况下，包括时间序列预测、图像分类和文本生成，PASS和PAI都优于现有最先进的替代品。

    This paper introduces a novel generator called Perturbation-Assisted Sample Synthesis (PASS), designed for drawing reliable conclusions from complex data, especially when using advanced modeling techniques like deep neural networks. PASS utilizes perturbation to generate synthetic data that closely mirrors the distribution of raw data, encompassing numerical and unstructured data types such as gene expression, images, and text. By estimating the data-generating distribution and leveraging large pre-trained generative models, PASS enhances estimation accuracy, providing an estimated distribution of any statistic through Monte Carlo experiments. Building on PASS, we propose a generative inference framework called Perturbation-Assisted Inference (PAI), which offers a statistical guarantee of validity. In pivotal inference, PAI enables accurate conclusions without knowing a pivotal's distribution as in simulations, even with limited data. In non-pivotal situations, we train PASS using an i
    
[^53]: 神经傅里叶变换：等变表示学习的通用方法

    Neural Fourier Transform: A General Approach to Equivariant Representation Learning. (arXiv:2305.18484v1 [stat.ML])

    [http://arxiv.org/abs/2305.18484](http://arxiv.org/abs/2305.18484)

    神经傅里叶变换是一种通用的等变表示学习方法，它可以在不需要显式知识的情况下学习组的潜在线性作用，实现对数据隐藏结构的提取。

    

    对称学习已被证明是提取数据隐藏结构的有效方法，其中等变关系概念起着中心作用。然而，大多数当前研究都建立在建筑理论和对数据形式的相应假设之上。我们提出了神经傅里叶变换（NFT），这是一种学习组的潜在线性作用的通用框架，而无需假设关于组如何作用于数据的显式知识。我们展示了NFT的理论基础，并表明等变特征的存在，即在等变性学习中普遍假定的，等价于数据空间中存在一组不变核。我们还提供实验结果，演示了在具有不同程度的关于操作组的知识的典型场景中应用NFT的应用。

    Symmetry learning has proven to be an effective approach for extracting the hidden structure of data, with the concept of equivariance relation playing the central role. However, most of the current studies are built on architectural theory and corresponding assumptions on the form of data. We propose Neural Fourier Transform (NFT), a general framework of learning the latent linear action of the group without assuming explicit knowledge of how the group acts on data. We present the theoretical foundations of NFT and show that the existence of a linear equivariant feature, which has been assumed ubiquitously in equivariance learning, is equivalent to the existence of a group invariant kernel on the dataspace. We also provide experimental results to demonstrate the application of NFT in typical scenarios with varying levels of knowledge about the acting group.
    
[^54]: 时间变化处理的反事实生成模型

    Counterfactual Generative Models for Time-Varying Treatments. (arXiv:2305.15742v1 [stat.ML])

    [http://arxiv.org/abs/2305.15742](http://arxiv.org/abs/2305.15742)

    本文研究了时间变量处理情况下的反事实生成模型，能够捕捉整个反事实分布，并且能够有效推断反事实分布的某些统计量，适用于医疗保健和公共政策制定领域。

    

    估计平均因果效应是测试新疗法的常用做法。然而，平均效应会掩盖反事实分布中重要的个体特征，可能会引起安全、公平和道德方面的担忧。这个问题在时间设置中更加严重，因为处理是时序的和时变的，对反事实分布产生了错综复杂的影响。本文提出了一种新的条件生成建模方法，以捕获整个反事实分布，允许对反事实分布的某些统计量进行有效推断。这使得所提出的方法尤其适用于医疗保健和公共政策制定领域。我们的生成建模方法通过边际结构模型谨慎地解决了观察数据和目标反事实分布之间的分布不匹配。在合成和真实数据上，我们的方法优于现有的基线方法。

    Estimating average causal effects is a common practice to test new treatments. However, the average effect ''masks'' important individual characteristics in the counterfactual distribution, which may lead to safety, fairness, and ethical concerns. This issue is exacerbated in the temporal setting, where the treatment is sequential and time-varying, leading to an intricate influence on the counterfactual distribution. In this paper, we propose a novel conditional generative modeling approach to capture the whole counterfactual distribution, allowing efficient inference on certain statistics of the counterfactual distribution. This makes the proposed approach particularly suitable for healthcare and public policy making. Our generative modeling approach carefully tackles the distribution mismatch in the observed data and the targeted counterfactual distribution via a marginal structural model. Our method outperforms state-of-the-art baselines on both synthetic and real data.
    
[^55]: 通过中度偏差理论进行最优学习

    Optimal Learning via Moderate Deviations Theory. (arXiv:2305.14496v1 [stat.ML])

    [http://arxiv.org/abs/2305.14496](http://arxiv.org/abs/2305.14496)

    本文提出了一种能够在广泛模型中进行最优学习的方法，利用中度偏差原理构建高度准确的置信区间，满足指数精度、一致性和最大精度等标准，为该方法提供了理论依据。

    

    本文提出了一种在广泛模型中使用置信区间学习函数值的统计最优方法，包括描述为随机规划问题或各种SDE模型的期望损失的一般非参数估计。更准确地说，我们通过采用基于中度偏差原理的方法系统地构建高度准确的置信区间。研究表明，所提出的置信区间在统计意义上是最优的，因为它们满足以指数精度、最小性、一致性、误判概率以及最终的一致最大精度为标准的要求。该方法提出的置信区间是通过强化优化问题的解来表达的，其中不确定性通过数据生成过程引发的中度偏差率函数来表示。我们演示了对于许多模型，这些优化问题具有易于解的结果。

    This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable r
    
[^56]: 有条件生成模型是标记时间点过程的必备工具。

    Conditional Generative Modeling is All You Need for Marked Temporal Point Processes. (arXiv:2305.12569v1 [stat.ML])

    [http://arxiv.org/abs/2305.12569](http://arxiv.org/abs/2305.12569)

    本文提出了一种从标记时间点过程中提取其统计直觉的事件生成模型，通过条件生成器以历史观察作为输入，生成可能发生的高质量随后事件。该模型具有高效、灵活和表示能力等方面的优势。

    

    近年来，生成建模的进步使得从上下文信息中生成高质量内容成为可能，但一个关键问题仍然存在：如何教模型知道何时生成内容？为了回答这个问题，本研究提出了一种新的事件生成模型，从标记时间点过程中提取其统计直觉，并提供了一个干净、灵活和计算效率高的解决方案，适用于涉及多维标记的各种应用。我们旨在捕捉点过程的分布而不需明确指定条件强度或概率密度。我们使用一个条件生成器，以事件历史为输入并生成在先前观察到的事件下，可能发生的高质量随后事件。所提出的框架提供了一系列利益，包括在学习模型和生成样本方面的异常效率以及相当大的表示能力来捕捉。

    Recent advancements in generative modeling have made it possible to generate high-quality content from context information, but a key question remains: how to teach models to know when to generate content? To answer this question, this study proposes a novel event generative model that draws its statistical intuition from marked temporal point processes, and offers a clean, flexible, and computationally efficient solution for a wide range of applications involving multi-dimensional marks. We aim to capture the distribution of the point process without explicitly specifying the conditional intensity or probability density. Instead, we use a conditional generator that takes the history of events as input and generates the high-quality subsequent event that is likely to occur given the prior observations. The proposed framework offers a host of benefits, including exceptional efficiency in learning the model and generating samples, as well as considerable representational power to capture
    
[^57]: 图上的转移算子：谱聚类及其扩展

    Transfer operators on graphs: Spectral clustering and beyond. (arXiv:2305.11766v1 [stat.ML])

    [http://arxiv.org/abs/2305.11766](http://arxiv.org/abs/2305.11766)

    本文介绍了在图上定义的转移算子及其谱特性，提出了基于广义转移算子的有向图聚类算法，并证明了算法有效性。

    

    图和网络在建模和分析复杂的相关系统中发挥着重要作用，例如交通网络，集成电路，电力网格，引文图以及生物和人工神经网络。本文在图上定义了转移算子，如Koopman算子和Perron-Frobenius算子，研究了它们的谱特性，引入了这些算子的Galerkin投影，并说明了如何从数据中估计降低表示。特别地，我们展示了无向图谱聚类可以被解释为Koopman算子的特征函数，并提出了基于广义转移算子的有向图聚类算法。我们在几个基准问题上证明了所得算法的有效性，并提供了不同聚类的解释。

    Graphs and networks play an important role in modeling and analyzing complex interconnected systems such as transportation networks, integrated circuits, power grids, citation graphs, and biological and artificial neural networks. Graph clustering algorithms can be used to detect groups of strongly connected vertices and to derive coarse-grained models. We define transfer operators such as the Koopman operator and the Perron-Frobenius operator on graphs, study their spectral properties, introduce Galerkin projections of these operators, and illustrate how reduced representations can be estimated from data. In particular, we show that spectral clustering of undirected graphs can be interpreted in terms of eigenfunctions of the Koopman operator and propose novel clustering algorithms for directed graphs based on generalized transfer operators. We demonstrate the efficacy of the resulting algorithms on several benchmark problems and provide different interpretations of clusters.
    

