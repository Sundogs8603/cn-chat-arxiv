# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Sharp-SSL: Selective high-dimensional axis-aligned random projections for semi-supervised learning.](http://arxiv.org/abs/2304.09154) | 本文提出了Sharp-SSL算法，通过对许多轴对齐随机投影的低维过程结果的精心汇集，能够高概率恢复信号坐标。 |
| [^2] | [Finite-Sample Bounds for Adaptive Inverse Reinforcement Learning using Passive Langevin Dynamics.](http://arxiv.org/abs/2304.09123) | 本文提供了有限时间界限，用于被动随机梯度 Langevin 动力学算法，该算法可用于逆强化学习。该算法充当随机采样器，恢复用外部过程优化而来的成本函数。 |
| [^3] | [Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism.](http://arxiv.org/abs/2304.09096) | 本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，采用输出扰动的高斯机制实现差分隐私，通过Rényi差分隐私对整体隐私损失进行特征化，在保护用户隐私的同时实现了推荐系统功能。 |
| [^4] | [Bayes Hilbert Spaces for Posterior Approximation.](http://arxiv.org/abs/2304.09053) | 本论文探讨了使用贝叶斯希尔伯特空间来逼近后验分布的问题，提供了该方法与贝叶斯计算相关的新联系。 |
| [^5] | [Decoding Neural Activity to Assess Individual Latent State in Ecologically Valid Contexts.](http://arxiv.org/abs/2304.09050) | 此研究旨在在更为真实的环境中解码人类神经活动模式，以进一步理解复杂任务期间个体内部潜在状态，该方法能够验证实验室方法并提供有意义的洞察。 |
| [^6] | [Estimating Joint Probability Distribution With Low-Rank Tensor Decomposition, Radon Transforms and Dictionaries.](http://arxiv.org/abs/2304.08740) | 本文提出了一种用低秩张量分解、Radon变换和字典估算联合概率分布的方法，通过使用1-D边际进行重建获得了更好的样本复杂度，并在实验中表现优于以前的基于字典的方法和高斯混合模型（GMM）。 |
| [^7] | [Impossibility of Characterizing Distribution Learning -- a simple solution to a long-standing problem.](http://arxiv.org/abs/2304.08712) | 本文解答了长期存在的问题：没有一种参数可以刻画分布类的PAC可学习性。同时，我们还展示了不存在一种刻画可学习性的性质来满足分布类以及其他学习问题的要求。 |
| [^8] | [Semi-supervised Learning of Pushforwards For Domain Translation & Adaptation.](http://arxiv.org/abs/2304.08673) | 本论文提出一种新颖的半监督推进映射学习算法，利用归一化流来解决现有方法中存在的应用空间、样本外数据点可应用性、对两个空间的概率模型进行建模等问题，可应用于图像到图像和文本到文本转换以及分类模型的领域自适应。 |
| [^9] | [Fast and Straggler-Tolerant Distributed SGD with Reduced Computation Load.](http://arxiv.org/abs/2304.08589) | 本文提出了一种基于模型的分布式SGD算法方案，通过适应算法的运行时间内的工作节点数量和计算负载，优化收敛速度同时降低计算负载。 |
| [^10] | [Learning Empirical Bregman Divergence for Uncertain Distance Representation.](http://arxiv.org/abs/2304.07689) | 本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。 |
| [^11] | [On the strong stability of ergodic iterations.](http://arxiv.org/abs/2304.04657) | 本论文研究了迭代随机函数生成的过程的强稳定性，证明了适用于递归映射的温和条件下的强稳定性，并且提供了多个应用及相关领域的新结果。 |
| [^12] | [Diagnosing Model Performance Under Distribution Shift.](http://arxiv.org/abs/2303.02011) | 本研究提出一种名为 DISDE 的方法，用于分析模型在不同分布情况下的性能变化。该方法将性能下降分解为三个方面：难度更大但更频繁出现的示例增加、特征和结果之间关系的变化和在训练期间不频繁或未见过的示例性能差。 |
| [^13] | [A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization.](http://arxiv.org/abs/2302.08766) | 该论文提出了一种双层经验风险最小化算法，使用的梯度计算次数 $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$，在样本复杂度方面是最优的。 |
| [^14] | [Star-Shaped Denoising Diffusion Probabilistic Models.](http://arxiv.org/abs/2302.05259) | 创新点在于提出了一种非马尔可夫扩散噪声过程的星形降噪扩散概率模型，能够广泛适用于指数族中的多种分布，特别适用于约束流形上的数据。 |
| [^15] | [Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces II: non-compact symmetric spaces.](http://arxiv.org/abs/2301.13088) | 本文开发了构建非欧几里得空间上静止高斯过程的实用技术，能够对定义在这些空间上的先验和后验高斯过程进行实际采样和计算协方差核。 |
| [^16] | [A first-order augmented Lagrangian method for constrained minimax optimization.](http://arxiv.org/abs/2301.02060) | 本文提出了一种一阶增广拉格朗日方法来解决约束极小极大问题，其操作复杂度为 ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$。 |
| [^17] | [Particle-based Variational Inference with Preconditioned Functional Gradient Flow.](http://arxiv.org/abs/2211.13954) | 本文提出了一种新的基于粒子的变分推断算法PFG，通过引入包含RKHS范数的函数正则项实现更大的函数类和更好的适应性，解决了RKHS要求限制函数类和算法灵活性的问题，并在KL散度上提供了可证明的连续时间收敛。 |
| [^18] | [Maximum Likelihood Learning of Unnormalized Models for Simulation-Based Inference.](http://arxiv.org/abs/2210.14756) | 该论文提出了两种用于基于仿真推断的合成似然方法，使用高保真度模拟器生成模拟数据，学习条件能量模型(EBM)的 likelihood，结合先验估计后验分布，可以使用MCMC抽取样本，该方法相较于其他方法更加灵活和准确。 |
| [^19] | [p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images.](http://arxiv.org/abs/2210.10418) | 本文介绍了p$^3$VAE生成模型，它将一个完美的物理模型集成到模型中，并应用于高分辨率高光谱遥感图像的语义分割。模型具有更好的外推能力和可解释性，同时具有高度解缕能力。 |
| [^20] | [Factorized Fusion Shrinkage for Dynamic Relational Data.](http://arxiv.org/abs/2210.00091) | 本文提出了一种动态关系数据的分解融合压缩模型，通过对分解矩阵的行向量的逐次差值施加全局-局部压缩先验获得收缩，并具有许多有利的性质。 |
| [^21] | [Selective Inference for Sparse Multitask Regression with Applications in Neuroimaging.](http://arxiv.org/abs/2205.14220) | 本文提出了一种多任务稀疏回归的选择推断框架，在神经影像学中应用，可以提高建模精度和预测性能。 |
| [^22] | [Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions.](http://arxiv.org/abs/2203.02605) | 本文是关于将强化学习应用于自适应干预中的第一份统一调查，强化学习在动态治疗方案和移动健康中即时自适应干预这两个领域中都具有很大的应用潜力。在这两个领域之间存在相似和不同之处需要考虑，并且这里存在巨大的合作机会。 |
| [^23] | [Estimating Conditional Average Treatment Effects with Missing Treatment Information.](http://arxiv.org/abs/2203.01422) | 本文研究了条件平均处理效应 (CATE) 的估计问题，在缺失治疗信息的情况下，提出了缺失治疗表示网络 (MTRNet)，通过域自适应学习协变量的平衡表示来解决协变量转移问题。 |
| [^24] | [Online Sub-Sampling for Reinforcement Learning with General Function Approximation.](http://arxiv.org/abs/2106.07203) | 本文提出了一种基于在线子采样框架的强化学习算法，利用数据点的信息增益量来指导探索，与现有方法相比更新RL算法的策略次数大大减少，但仍保持较小的近似最优遗憾边界。 |
| [^25] | [Mat\'ern Gaussian processes on Riemannian manifolds.](http://arxiv.org/abs/2006.10160) | 本文提出了一种新的方法，通过谱理论计算Riemannian Matérn高斯过程在紧黎曼流形上的核，使其可以通过标准的可扩展技术进行训练。这将推动Matérn高斯过程在黎曼流形上的应用。 |
| [^26] | [Fast Objective & Duality Gap Convergence for Non-Convex Strongly-Concave Min-Max Problems with PL Condition.](http://arxiv.org/abs/2006.06889) | 该论文探讨了解决深度学习中出现的一类非凸强凸min-max问题的随机方法，并提出了一个基于近端阶段的方法框架，其中嵌入了许多众所周知的随机更新，快速收敛性得到了建立。 |
| [^27] | [Interpretable Learning in Multivariate Big Data Analysis for Network Monitoring.](http://arxiv.org/abs/1907.02677) | 本文扩展了多变量大数据分析（MBDA）方法，提出了一种自动推导特征的解决方案，结合可解释性和交互式模型的优势以及并行处理的能力，应用于网络监测和诊断，最终在UGR'16和Dartmouth'18两个数据集上取得成功。 |

# 详细

[^1]: Sharp-SSL：基于选择性高维轴对齐随机投影的半监督学习

    Sharp-SSL: Selective high-dimensional axis-aligned random projections for semi-supervised learning. (arXiv:2304.09154v1 [stat.ME])

    [http://arxiv.org/abs/2304.09154](http://arxiv.org/abs/2304.09154)

    本文提出了Sharp-SSL算法，通过对许多轴对齐随机投影的低维过程结果的精心汇集，能够高概率恢复信号坐标。

    

    提出了一种新的高维半监督学习方法，基于对许多轴对齐随机投影的低维过程结果的精心汇集。我们的主要目标是确定用于区分类别的重要变量；然后可以应用现有的低维方法进行最终的类别分配。受广义瑞利商的启发，我们根据估计白化后的类间协方差矩阵在投影数据上的痕迹对投影进行评分。这使我们能够为给定投影分配每个变量的重要性权重，并通过聚合这些权重来选择信号变量。我们的理论表明，当我们聚合足够多的随机投影和基础过程估计白化后的类间协方差时，所得到的Sharp-SSL算法能够以高概率恢复信号坐标。

    We propose a new method for high-dimensional semi-supervised learning problems based on the careful aggregation of the results of a low-dimensional procedure applied to many axis-aligned random projections of the data. Our primary goal is to identify important variables for distinguishing between the classes; existing low-dimensional methods can then be applied for final class assignment. Motivated by a generalized Rayleigh quotient, we score projections according to the traces of the estimated whitened between-class covariance matrices on the projected data. This enables us to assign an importance weight to each variable for a given projection, and to select our signal variables by aggregating these weights over high-scoring projections. Our theory shows that the resulting Sharp-SSL algorithm is able to recover the signal coordinates with high probability when we aggregate over sufficiently many random projections and when the base procedure estimates the whitened between-class covari
    
[^2]: 使用被动 Langevin 动力学的自适应逆强化学习的有限样本界限

    Finite-Sample Bounds for Adaptive Inverse Reinforcement Learning using Passive Langevin Dynamics. (arXiv:2304.09123v1 [cs.LG])

    [http://arxiv.org/abs/2304.09123](http://arxiv.org/abs/2304.09123)

    本文提供了有限时间界限，用于被动随机梯度 Langevin 动力学算法，该算法可用于逆强化学习。该算法充当随机采样器，恢复用外部过程优化而来的成本函数。

    

    随机梯度 Langevin 动力学 (SGLD) 是从概率分布采样的有用方法。本文提供了一个被动随机梯度 Langevin 动力学算法 (PSGLD) 的有限样本分析，旨在实现逆强化学习。此处的“被动”是指 PSGLD 算法(逆学习过程)可用的噪声渐变是由外部随机梯度算法(正向学习器)在随机选择的点上评估的。PSGLD 算法因此充当一个随机采样器，可恢复正在被此外部过程优化的成本函数。以前的工作使用随机逼近技术分析了这个被动算法的渐近性能；在本文中，我们分析了它的有限时间性能。具体而言，我们提供了在被动算法和其稳定测度之间的 2-Wasserstein 距离上的有限时间界限，从中可以获得重建的成本函数。

    Stochastic gradient Langevin dynamics (SGLD) are a useful methodology for sampling from probability distributions. This paper provides a finite sample analysis of a passive stochastic gradient Langevin dynamics algorithm (PSGLD) designed to achieve inverse reinforcement learning. By "passive", we mean that the noisy gradients available to the PSGLD algorithm (inverse learning process) are evaluated at randomly chosen points by an external stochastic gradient algorithm (forward learner). The PSGLD algorithm thus acts as a randomized sampler which recovers the cost function being optimized by this external process. Previous work has analyzed the asymptotic performance of this passive algorithm using stochastic approximation techniques; in this work we analyze the non-asymptotic performance. Specifically, we provide finite-time bounds on the 2-Wasserstein distance between the passive algorithm and its stationary measure, from which the reconstructed cost function is obtained.
    
[^3]: 基于高斯机制的保护隐私矩阵分解推荐系统

    Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism. (arXiv:2304.09096v1 [cs.IR])

    [http://arxiv.org/abs/2304.09096](http://arxiv.org/abs/2304.09096)

    本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，采用输出扰动的高斯机制实现差分隐私，通过Rényi差分隐私对整体隐私损失进行特征化，在保护用户隐私的同时实现了推荐系统功能。

    

    建立推荐系统需要分析用户数据，这可能会泄露用户的个人信息。匿名化用户数据通常不足以保护用户隐私。鉴于此，本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，矩阵分解是最流行的推荐系统算法之一。通过差分隐私，即使对手拥有用户的公开信息，也可以防止对手提取敏感用户信息。我们采用输出扰动的高斯机制实现差分隐私并发布满足隐私定义的用户档案。我们使用Rényi差分隐私对整体隐私损失进行了紧密的特征化。我们在实验中进行了广泛的测试。

    Building a recommendation system involves analyzing user data, which can potentially leak sensitive information about users. Anonymizing user data is often not sufficient for preserving user privacy. Motivated by this, we propose a privacy-preserving recommendation system based on the differential privacy framework and matrix factorization, which is one of the most popular algorithms for recommendation systems. As differential privacy is a powerful and robust mathematical framework for designing privacy-preserving machine learning algorithms, it is possible to prevent adversaries from extracting sensitive user information even if the adversary possesses their publicly available (auxiliary) information. We implement differential privacy via the Gaussian mechanism in the form of output perturbation and release user profiles that satisfy privacy definitions. We employ R\'enyi Differential Privacy for a tight characterization of the overall privacy loss. We perform extensive experiments on
    
[^4]: 贝叶斯希尔伯特空间用于后验逼近

    Bayes Hilbert Spaces for Posterior Approximation. (arXiv:2304.09053v1 [math.ST])

    [http://arxiv.org/abs/2304.09053](http://arxiv.org/abs/2304.09053)

    本论文探讨了使用贝叶斯希尔伯特空间来逼近后验分布的问题，提供了该方法与贝叶斯计算相关的新联系。

    

    在贝叶斯模型中进行推理需要采样算法从后验中抽取样本。随着数据集的增大，这变得非常昂贵。构建便宜易于评估的后验逼近是规避这个问题的一种流行方法。这引出一个问题：什么样的空间适合用于逼近贝叶斯后验度量？本文研究了将贝叶斯希尔伯特空间应用于后验逼近问题。贝叶斯希尔伯特空间在函数数据分析中得到了研究，其中观测到的函数是概率密度函数，它们在计算贝叶斯问题中的应用还处于初级阶段。本文概述了贝叶斯希尔伯特空间及其与贝叶斯计算之间的联系，特别是贝叶斯希尔伯特空间、贝叶斯核心集算法和基于核的距离之间的新联系。

    Performing inference in Bayesian models requires sampling algorithms to draw samples from the posterior. This becomes prohibitively expensive as the size of data sets increase. Constructing approximations to the posterior which are cheap to evaluate is a popular approach to circumvent this issue. This begs the question of what is an appropriate space to perform approximation of Bayesian posterior measures. This manuscript studies the application of Bayes Hilbert spaces to the posterior approximation problem. Bayes Hilbert spaces are studied in functional data analysis in the context where observed functions are probability density functions and their application to computational Bayesian problems is in its infancy. This manuscript shall outline Bayes Hilbert spaces and their connection to Bayesian computation, in particular novel connections between Bayes Hilbert spaces, Bayesian coreset algorithms and kernel-based distances.
    
[^5]: 解码神经活动以评估个体在生态有效环境中的潜在状态

    Decoding Neural Activity to Assess Individual Latent State in Ecologically Valid Contexts. (arXiv:2304.09050v1 [q-bio.NC])

    [http://arxiv.org/abs/2304.09050](http://arxiv.org/abs/2304.09050)

    此研究旨在在更为真实的环境中解码人类神经活动模式，以进一步理解复杂任务期间个体内部潜在状态，该方法能够验证实验室方法并提供有意义的洞察。

    

    历史上，仅有少量方法可以在更生态有效的情境下分离认知过程。特别地，目前尚不清楚在此类约束条件下观察到的神经活动模式实际上是否以一种可以用于准确推断个体潜在状态、相关认知过程或近端行为的方式在实验室外显现。改善我们对特定神经活动模式何时以及如何在生态有效情境中显现的理解，会验证在隔离环境下研究类似神经现象的实验室方法，并提供关于复杂任务期间发生的潜在状态的有意义洞察。我们认为，来自脑-计算机界面社区的领域通用方法有潜力解决这一挑战。我们以前使用了这样的方法来解码与视觉目标相关的突发神经反应。

    There exist very few ways to isolate cognitive processes, historically defined via highly controlled laboratory studies, in more ecologically valid contexts. Specifically, it remains unclear as to what extent patterns of neural activity observed under such constraints actually manifest outside the laboratory in a manner that can be used to make an accurate inference about the latent state, associated cognitive process, or proximal behavior of the individual. Improving our understanding of when and how specific patterns of neural activity manifest in ecologically valid scenarios would provide validation for laboratory-based approaches that study similar neural phenomena in isolation and meaningful insight into the latent states that occur during complex tasks. We argue that domain generalization methods from the brain-computer interface community have the potential to address this challenge. We previously used such an approach to decode phasic neural responses associated with visual tar
    
[^6]: 用低秩张量分解、Radon变换和字典估算联合概率分布

    Estimating Joint Probability Distribution With Low-Rank Tensor Decomposition, Radon Transforms and Dictionaries. (arXiv:2304.08740v1 [stat.ML])

    [http://arxiv.org/abs/2304.08740](http://arxiv.org/abs/2304.08740)

    本文提出了一种用低秩张量分解、Radon变换和字典估算联合概率分布的方法，通过使用1-D边际进行重建获得了更好的样本复杂度，并在实验中表现优于以前的基于字典的方法和高斯混合模型（GMM）。

    

    本文提出了一种估计数据样本中联合概率密度的方法，假设底层分布能够分解为几个混合组分的乘积密度。我们结合了两个关键想法：用于表示1-D密度的字典以及用于估算1-D边际的随机投影，探索了先前的方法。相比基于字典的方法，我们的算法通过使用1-D边际进行重建而获得了更好的样本复杂度。我们在估算合成概率密度方面评估了我们方法的性能，并将其与以前的基于字典的方法和高斯混合模型（GMM）进行了比较。在所有实验设置中，我们的算法表现优于这些其他方法。

    In this paper, we describe a method for estimating the joint probability density from data samples by assuming that the underlying distribution can be decomposed as a mixture of product densities with few mixture components. Prior works have used such a decomposition to estimate the joint density from lower-dimensional marginals, which can be estimated more reliably with the same number of samples. We combine two key ideas: dictionaries to represent 1-D densities, and random projections to estimate the joint distribution from 1-D marginals, explored separately in prior work. Our algorithm benefits from improved sample complexity over the previous dictionary-based approach by using 1-D marginals for reconstruction. We evaluate the performance of our method on estimating synthetic probability densities and compare it with the previous dictionary-based approach and Gaussian Mixture Models (GMMs). Our algorithm outperforms these other approaches in all the experimental settings.
    
[^7]: 不可能刻画分布学习--一个长期问题的简单解决方案

    Impossibility of Characterizing Distribution Learning -- a simple solution to a long-standing problem. (arXiv:2304.08712v1 [cs.LG])

    [http://arxiv.org/abs/2304.08712](http://arxiv.org/abs/2304.08712)

    本文解答了长期存在的问题：没有一种参数可以刻画分布类的PAC可学习性。同时，我们还展示了不存在一种刻画可学习性的性质来满足分布类以及其他学习问题的要求。

    

    本文考虑了长期以来存在的一个问题：寻找一类概率分布的参数，以刻画它的PAC可学习性。我们提出了一个相当令人惊讶的答案——没有这样的参数存在。我们的技术使我们能够展示类似结果的几个概念，以及几个学习任务。我们展示了没有任何维度可以刻画学习分布类的样本复杂度。然后，我们考虑了只刻画可学习性（而不是量化样本复杂度函数）的较弱要求。我们提出了一些自然的要求，以便对这样一个刻画进行更好的理解，并进一步展示了不存在一种刻画性质，以满足这些要求，对于分布类的。此外，我们展示了我们的结果适用于各种其他学习问题。特别是，我们展示了没有任何维度可以刻画（或刻画可学习性）的概念，适用于...

    We consider the long-standing question of finding a parameter of a class of probability distributions that characterizes its PAC learnability. We provide a rather surprising answer - no such parameter exists. Our techniques allow us to show similar results for several general notions of characterizing learnability and for several learning tasks. We show that there is no notion of dimension that characterizes the sample complexity of learning distribution classes. We then consider the weaker requirement of only characterizing learnability (rather than the quantitative sample complexity function). We propose some natural requirements for such a characterization and go on to show that there exists no characterization of learnability that satisfies these requirements for classes of distributions. Furthermore, we show that our results hold for various other learning problems. In particular, we show that there is no notion of dimension characterizing (or characterization of learnability) for
    
[^8]: 面向领域转换和自适应的推进学习半监督算法

    Semi-supervised Learning of Pushforwards For Domain Translation & Adaptation. (arXiv:2304.08673v1 [cs.LG])

    [http://arxiv.org/abs/2304.08673](http://arxiv.org/abs/2304.08673)

    本论文提出一种新颖的半监督推进映射学习算法，利用归一化流来解决现有方法中存在的应用空间、样本外数据点可应用性、对两个空间的概率模型进行建模等问题，可应用于图像到图像和文本到文本转换以及分类模型的领域自适应。

    

    本论文提出了一种利用归一化流来参数化映射的新颖推进映射学习算法，通过最小化概率距离和应用特定的正则化项来选择所有可能映射，从而解决了现有方法中存在的广泛应用空间、在样本外数据点上具有可应用性、对两个空间的概率模型进行建模等问题。实验结果表明，该方法在准确性和效率方面具有明显的优势，可应用于图像到图像和文本到文本转换以及分类模型的领域自适应。

    Given two probability densities on related data spaces, we seek a map pushing one density to the other while satisfying application-dependent constraints. For maps to have utility in a broad application space (including domain translation, domain adaptation, and generative modeling), the map must be available to apply on out-of-sample data points and should correspond to a probabilistic model over the two spaces. Unfortunately, existing approaches, which are primarily based on optimal transport, do not address these needs. In this paper, we introduce a novel pushforward map learning algorithm that utilizes normalizing flows to parameterize the map. We first re-formulate the classical optimal transport problem to be map-focused and propose a learning algorithm to select from all possible maps under the constraint that the map minimizes a probability distance and application-specific regularizers; thus, our method can be seen as solving a modified optimal transport problem. Once the map 
    
[^9]: 快速并容错的分布式SGD算法，降低计算负载。

    Fast and Straggler-Tolerant Distributed SGD with Reduced Computation Load. (arXiv:2304.08589v1 [cs.DC])

    [http://arxiv.org/abs/2304.08589](http://arxiv.org/abs/2304.08589)

    本文提出了一种基于模型的分布式SGD算法方案，通过适应算法的运行时间内的工作节点数量和计算负载，优化收敛速度同时降低计算负载。

    

    在分布式机器学习中，一个中心节点将计算密集型的运算外包给外部的工作节点。优化过程的属性，如随机梯度下降（SGD），可以利用以减轻不响应或速度慢的工人（称为迟钝者）的影响，因为这些情况会降低计算外包的收益。这可以通过仅等待每个算法迭代中的一部分工作节点完成其计算来实现。之前的工作提出了适应等待工人数量随算法演化以优化收敛速度的方法。相反，本文构建了一个新的方案，通过使用独立的随机变量对通信和计算时间进行建模，来适应算法的运行时间内的工作节点数量和计算负载。因此，我们提高了分布式SGD的收敛速度，同时显着降低了计算负载。

    In distributed machine learning, a central node outsources computationally expensive calculations to external worker nodes. The properties of optimization procedures like stochastic gradient descent (SGD) can be leveraged to mitigate the effect of unresponsive or slow workers called stragglers, that otherwise degrade the benefit of outsourcing the computation. This can be done by only waiting for a subset of the workers to finish their computation at each iteration of the algorithm. Previous works proposed to adapt the number of workers to wait for as the algorithm evolves to optimize the speed of convergence. In contrast, we model the communication and computation times using independent random variables. Considering this model, we construct a novel scheme that adapts both the number of workers and the computation load throughout the run-time of the algorithm. Consequently, we improve the convergence speed of distributed SGD while significantly reducing the computation load, at the ex
    
[^10]: 学习经验Bregman散度用于不确定距离表示

    Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])

    [http://arxiv.org/abs/2304.07689](http://arxiv.org/abs/2304.07689)

    本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。

    

    深度度量学习技术已应用于各种监督和无监督学习任务，通过深度网络学习样本嵌入来进行视觉表示。然而，经典方法采用固定距离度量作为两个嵌入之间的相似性函数，可能导致捕捉复杂数据分布的亚最优性能。Bregman散度概括了各种距离度量的度量，并在许多深度度量学习领域中产生。本文首先展示了如何从Bregman散度获得深度度量学习损失。然后，我们介绍了一种直接从数据中学习经验Bregman散度的新方法，通过使用深度学习设置对Bregman散度下的凸函数进行参数化。我们进一步实验证明，与其他SOTA深度度量学习方法相比，我们的方法在五个流行公共数据集上表现出色，特别是在模式识别和聚类任务上。

    Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
    
[^11]: 论随机遍历的强稳定性

    On the strong stability of ergodic iterations. (arXiv:2304.04657v1 [math.PR])

    [http://arxiv.org/abs/2304.04657](http://arxiv.org/abs/2304.04657)

    本论文研究了迭代随机函数生成的过程的强稳定性，证明了适用于递归映射的温和条件下的强稳定性，并且提供了多个应用及相关领域的新结果。

    

    我们重新审视了由随机函数迭代生成的过程，这些函数由一个平稳且符合遍历条件的序列驱动。如果存在一个随机初始化使得该过程是稳定和遍历的，并且对于任何其他初始化，两个过程之间的差异几乎肯定收敛于零，那么这样的过程被称为强稳定。在对应递归映射上施加一些温和的条件，而不在驱动序列上施加任何条件下，我们展示了迭代的强稳定性。多个应用被研究，如随机逼近和排队。此外，我们推导出了具有依赖噪声的 Langevin 型迭代和多型分支过程的新结果。

    We revisit processes generated by iterated random functions driven by a stationary and ergodic sequence. Such a process is called strongly stable if a random initialization exists, for which the process is stationary and ergodic, and for any other initialization, the difference of the two processes converges to zero almost surely. Under some mild conditions on the corresponding recursive map, without any condition on the driving sequence, we show the strong stability of iterations. Several applications are surveyed such as stochastic approximation and queuing. Furthermore, new results are deduced for Langevin-type iterations with dependent noise and for multitype branching processes.
    
[^12]: 在分布转移下诊断模型性能

    Diagnosing Model Performance Under Distribution Shift. (arXiv:2303.02011v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.02011](http://arxiv.org/abs/2303.02011)

    本研究提出一种名为 DISDE 的方法，用于分析模型在不同分布情况下的性能变化。该方法将性能下降分解为三个方面：难度更大但更频繁出现的示例增加、特征和结果之间关系的变化和在训练期间不频繁或未见过的示例性能差。

    

    当模型在不同于训练分布的目标分布下运行时，其性能可能会下降。为了理解这些操作失败模式，我们开发了一种方法，称为 DIstribution Shift DEcomposition（DISDE），将性能下降归因于不同类型的分布转移。我们的方法将性能下降分解为以下几个方面：1）来自训练的更难但更频繁的示例增加；2）特征和结果之间关系的变化；3）在训练期间不频繁或未见过的示例性能差。为了实现这一点，我们在固定 $X$ 的分布的同时改变 $Y \mid X$ 的条件分布，或在固定 $Y \mid X$ 的条件分布的同时改变 $X$ 的分布，从而定义了一个关于 $X$ 的假设分布，其中包含训练和目标中共同的值，可以轻松地比较 $Y \mid X$ 并进行预测。

    Prediction models can perform poorly when deployed to target distributions different from the training distribution. To understand these operational failure modes, we develop a method, called DIstribution Shift DEcomposition (DISDE), to attribute a drop in performance to different types of distribution shifts. Our approach decomposes the performance drop into terms for 1) an increase in harder but frequently seen examples from training, 2) changes in the relationship between features and outcomes, and 3) poor performance on examples infrequent or unseen during training. These terms are defined by fixing a distribution on $X$ while varying the conditional distribution of $Y \mid X$ between training and target, or by fixing the conditional distribution of $Y \mid X$ while varying the distribution on $X$. In order to do this, we define a hypothetical distribution on $X$ consisting of values common in both training and target, over which it is easy to compare $Y \mid X$ and thus predictive
    
[^13]: 一种双层经验风险最小化算法的下界和近似最优算法

    A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.08766](http://arxiv.org/abs/2302.08766)

    该论文提出了一种双层经验风险最小化算法，使用的梯度计算次数 $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$，在样本复杂度方面是最优的。

    

    双层最优化问题越来越多地应用于机器学习中。在许多实际情况下，上层和下层目标对应于经验风险最小化问题，并因此具有总和结构。在这个背景下，我们提出了一个著名的SARAH算法的双层扩展。我们证明了该算法需要$\mathcal {O}((n+m)^{\frac{1}{2}}\varepsilon ^{-1})$次梯度计算才能实现$\varepsilon$稳定性，其中$n+m$是样本总数，这比先前所有的双层算法都要好。此外，我们提供了一个下界，用于得到双层问题的目标函数的近似稳定点所需的oracle调用次数。这个下界正是我们的算法所达到的，因此在样本复杂度方面是最优的。

    Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ gradient computations to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.
    
[^14]: 星形降噪扩散概率模型

    Star-Shaped Denoising Diffusion Probabilistic Models. (arXiv:2302.05259v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.05259](http://arxiv.org/abs/2302.05259)

    创新点在于提出了一种非马尔可夫扩散噪声过程的星形降噪扩散概率模型，能够广泛适用于指数族中的多种分布，特别适用于约束流形上的数据。

    

    基于降噪扩散概率模型（DDPM）的方法已经成为生成模型中无处不在的工具。但是，它们大多局限于高斯和离散扩散过程。我们提出了星形降噪扩散概率模型（SS-DDPM），一种具有非马尔可夫扩散噪声过程的模型。在高斯分布的情况下，该模型等效于马尔可夫DDPM。然而，它可以定义和适用于任意噪声分布，并且对于落在指数族中的广泛分布，它采用了高效的训练和采样算法。我们提供了一个简单的配方，用于设计具有Beta，von Mises-Fisher，Dirichlet，Wishart等分布的扩散样式模型，当数据位于约束流形上时特别有用，例如单位球，正半定矩阵的空间，概率单纯形等。我们在不同的设置中评估了该模型，并发现它很有竞争力。

    Methods based on Denoising Diffusion Probabilistic Models (DDPM) became a ubiquitous tool in generative modeling. However, they are mostly limited to Gaussian and discrete diffusion processes. We propose Star-Shaped Denoising Diffusion Probabilistic Models (SS-DDPM), a model with a non-Markovian diffusion-like noising process. In the case of Gaussian distributions, this model is equivalent to Markovian DDPMs. However, it can be defined and applied with arbitrary noising distributions, and admits efficient training and sampling algorithms for a wide range of distributions that lie in the exponential family. We provide a simple recipe for designing diffusion-like models with distributions like Beta, von Mises--Fisher, Dirichlet, Wishart and others, which can be especially useful when data lies on a constrained manifold such as the unit sphere, the space of positive semi-definite matrices, the probabilistic simplex, etc. We evaluate the model in different settings and find it competitive 
    
[^15]: Lie 群和它们的齐次空间上的静止核和高斯过程 II：非紧对称空间

    Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces II: non-compact symmetric spaces. (arXiv:2301.13088v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2301.13088](http://arxiv.org/abs/2301.13088)

    本文开发了构建非欧几里得空间上静止高斯过程的实用技术，能够对定义在这些空间上的先验和后验高斯过程进行实际采样和计算协方差核。

    

    高斯过程是机器学习中最重要的时空模型之一，它可以编码有关建模函数的先验信息，并可用于精确或近似贝叶斯学习。在许多应用中，特别是在物理科学和工程领域，以及地质统计学和神经科学等领域，对对称性的不变性是可以考虑的最基本形式之一。高斯过程协方差对这些对称性的不变性引发了对这些空间的平稳性概念的最自然的推广。在这项工作中，我们开发了建立静止高斯过程的构造性和实用技术，用于在对称性背景下出现的非欧几里得空间的非常大的类。我们的技术使得能够（i）计算协方差核和（ii）从这些空间上定义的先验和后验高斯过程中实际地进行采样。

    Gaussian processes are arguably the most important class of spatiotemporal models within machine learning. They encode prior information about the modeled function and can be used for exact or approximate Bayesian learning. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process' covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is 
    
[^16]: 一种用于约束极小极大优化问题的一阶增广拉格朗日方法

    A first-order augmented Lagrangian method for constrained minimax optimization. (arXiv:2301.02060v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2301.02060](http://arxiv.org/abs/2301.02060)

    本文提出了一种一阶增广拉格朗日方法来解决约束极小极大问题，其操作复杂度为 ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$。

    

    本文研究了一类约束极小极大问题。特别地，我们提出了一种一阶增广拉格朗日方法来解决这些问题，其子问题被发现是一个更简单的结构化极小极大问题，并且可以通过作者在 [26] 中最近开发的一阶方法来适当地解决。在一些适当的假设下，为了找到约束极小极大问题的一个 $\varepsilon$-KKT 解，该方法的操作复杂度为 ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$，该复杂度是由基本操作测量得到的。

    In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method recently developed in [26] by the authors. Under some suitable assumptions, an \emph{operation complexity} of ${\cal O}(\varepsilon^{-4}\log\varepsilon^{-1})$, measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $\varepsilon$-KKT solution of the constrained minimax problems.
    
[^17]: 基于粒子的预处理函数梯度流变分推断

    Particle-based Variational Inference with Preconditioned Functional Gradient Flow. (arXiv:2211.13954v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.13954](http://arxiv.org/abs/2211.13954)

    本文提出了一种新的基于粒子的变分推断算法PFG，通过引入包含RKHS范数的函数正则项实现更大的函数类和更好的适应性，解决了RKHS要求限制函数类和算法灵活性的问题，并在KL散度上提供了可证明的连续时间收敛。

    

    基于粒子的变分推断通过梯度流估计最小化模型样本与目标后验之间的KL散度。随着Stein变分梯度下降（SVGD）的流行，基于粒子的VI算法的重点已经转向在重现核希尔伯特空间（RKHS）中逼近梯度流的函数的特性。然而，RKHS的要求限制了函数类和算法的灵活性。本文通过引入包含了RKHS范数的函数正则化项，提供了这个问题的通用解决方案。这使得我们可以提出一个新的基于粒子的VI算法，叫做预处理函数梯度流（PFG）。与SVGD相比，PFG具有更大的函数类，改进了大量粒子场景的可扩展性，更适应病态分布，并在KL散度上提供了可证明的连续时间收敛。此外，非线性函数规范也可以轻松地并入到所提出的算法中。

    Particle-based variational inference (VI) minimizes the KL divergence between model samples and the target posterior with gradient flow estimates. With the popularity of Stein variational gradient descent (SVGD), the focus of particle-based VI algorithms has been on the properties of functions in Reproducing Kernel Hilbert Space (RKHS) to approximate the gradient flow. However, the requirement of RKHS restricts the function class and algorithmic flexibility. This paper offers a general solution to this problem by introducing a functional regularization term that encompasses the RKHS norm as a special case. This allows us to propose a new particle-based VI algorithm called preconditioned functional gradient flow (PFG). Compared to SVGD, PFG has several advantages. It has a larger function class, improved scalability in large particle-size scenarios, better adaptation to ill-conditioned distributions, and provable continuous-time convergence in KL divergence. Additionally, non-linear fun
    
[^18]: 用于基于仿真推断的非归一化模型的最大似然学习

    Maximum Likelihood Learning of Unnormalized Models for Simulation-Based Inference. (arXiv:2210.14756v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14756](http://arxiv.org/abs/2210.14756)

    该论文提出了两种用于基于仿真推断的合成似然方法，使用高保真度模拟器生成模拟数据，学习条件能量模型(EBM)的 likelihood，结合先验估计后验分布，可以使用MCMC抽取样本，该方法相较于其他方法更加灵活和准确。

    

    我们引入了两种用于基于仿真推断（SBI）的合成似然方法，可以在高保真度模拟器存在时从实验观测中进行分摊或有针对性的推断。两种方法均使用从提议分布中抽取的参数所生成的模拟数据来学习 likelihood 的条件能量模型(EBM)。然后可以将学习到的 likelihood 与任何先验组合以获得后验估计，随后可以使用 MCMC 从中抽取样本。与其他合成似然方法不同，我们的方法独特地结合了灵活的能量模型和 KL 损失的最小化。

    We introduce two synthetic likelihood methods for Simulation-Based Inference (SBI), to conduct either amortized or targeted inference from experimental observations when a high-fidelity simulator is available. Both methods learn a conditional energy-based model (EBM) of the likelihood using synthetic data generated by the simulator, conditioned on parameters drawn from a proposal distribution. The learned likelihood can then be combined with any prior to obtain a posterior estimate, from which samples can be drawn using MCMC. Our methods uniquely combine a flexible Energy-Based Model and the minimization of a KL loss: this is in contrast to other synthetic likelihood methods, which either rely on normalizing flows, or minimize score-based objectives; choices that come with known pitfalls. We demonstrate the properties of both methods on a range of synthetic datasets, and apply them to a neuroscience model of the pyloric network in the crab, where our method outperforms prior art for a 
    
[^19]: p$^3$VAE：一个物理集成的生成模型，应用于光学遥感图像的语义分割

    p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images. (arXiv:2210.10418v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10418](http://arxiv.org/abs/2210.10418)

    本文介绍了p$^3$VAE生成模型，它将一个完美的物理模型集成到模型中，并应用于高分辨率高光谱遥感图像的语义分割。模型具有更好的外推能力和可解释性，同时具有高度解缕能力。

    

    将机器学习模型与物理模型相结合是学习强大数据表示的最新研究方向。本文介绍了p$^3$VAE，这是一个生成模型，它集成了一个完美的物理模型，部分解释了数据中真实的变化因素。为了充分利用我们的混合设计，我们提出了一种半监督优化过程和一种推断方案，同时伴随着有意义的不确定性估计。我们将p$^3$VAE应用于高分辨率高光谱遥感图像的语义分割。我们在一个模拟数据集上的实验表明，与传统的机器学习模型相比，我们的混合模型具有更好的外推能力和可解释性。特别是，我们展示了p$^3$VAE自然具有高度解缕能力。我们的代码和数据已在https://github.com/Romain3Ch216/p3VAE上公开发布。

    The combination of machine learning models with physical models is a recent research path to learn robust data representations. In this paper, we introduce p$^3$VAE, a generative model that integrates a perfect physical model which partially explains the true underlying factors of variation in the data. To fully leverage our hybrid design, we propose a semi-supervised optimization procedure and an inference scheme that comes along meaningful uncertainty estimates. We apply p$^3$VAE to the semantic segmentation of high-resolution hyperspectral remote sensing images. Our experiments on a simulated data set demonstrated the benefits of our hybrid model against conventional machine learning models in terms of extrapolation capabilities and interpretability. In particular, we show that p$^3$VAE naturally has high disentanglement capabilities. Our code and data have been made publicly available at https://github.com/Romain3Ch216/p3VAE.
    
[^20]: 动态关系数据的分解融合压缩模型

    Factorized Fusion Shrinkage for Dynamic Relational Data. (arXiv:2210.00091v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2210.00091](http://arxiv.org/abs/2210.00091)

    本文提出了一种动态关系数据的分解融合压缩模型，通过对分解矩阵的行向量的逐次差值施加全局-局部压缩先验获得收缩，并具有许多有利的性质。

    

    现代数据科学应用经常涉及具有动态结构的复杂关系数据。此类动态关系数据的突变通常出现在由于干预而经历制度变化的系统中。在这种情况下，我们考虑一种分解融合压缩模型，其中所有分解因子都被动态地收缩到组内融合结构，收缩通过对分解矩阵的行向量的逐次差值施加全局-局部压缩先验来获得。所提出的先验在估计的动态潜在因子的比较和聚类方面具有许多有利的性质。比较估计的潜在因子涉及相邻和长期比较，考虑到比较的时间范围作为变量。在某些条件下，我们证明后验分布达到最小化最大风险，直到对数因子。在计算方面，我们提出了一个结构化的均值场变分方法。

    Modern data science applications often involve complex relational data with dynamic structures. An abrupt change in such dynamic relational data is typically observed in systems that undergo regime changes due to interventions. In such a case, we consider a factorized fusion shrinkage model in which all decomposed factors are dynamically shrunk towards group-wise fusion structures, where the shrinkage is obtained by applying global-local shrinkage priors to the successive differences of the row vectors of the factorized matrices. The proposed priors enjoy many favorable properties in comparison and clustering of the estimated dynamic latent factors. Comparing estimated latent factors involves both adjacent and long-term comparisons, with the time range of comparison considered as a variable. Under certain conditions, we demonstrate that the posterior distribution attains the minimax optimal rate up to logarithmic factors. In terms of computation, we present a structured mean-field vari
    
[^21]: 多任务稀疏回归的选择推断及其在神经影像学中的应用

    Selective Inference for Sparse Multitask Regression with Applications in Neuroimaging. (arXiv:2205.14220v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2205.14220](http://arxiv.org/abs/2205.14220)

    本文提出了一种多任务稀疏回归的选择推断框架，在神经影像学中应用，可以提高建模精度和预测性能。

    

    多任务学习被广泛应用于从同一特征集中模拟一组相关响应变量，相比于单独处理每个响应变量的方法，可以提高预测性能和建模精度。但多任务学习在推断不确定性方面的研究还较少。本文通过稀疏性信号加强方法，针对神经影像学中的常见多任务问题，提出了一种选择推断框架，具有灵活性，可以同时识别出每个任务相关的协变量，并建立基于稀疏结构的有效推断模型。

    Multi-task learning is frequently used to model a set of related response variables from the same set of features, improving predictive performance and modeling accuracy relative to methods that handle each response variable separately. Despite the potential of multi-task learning to yield more powerful inference than single-task alternatives, prior work in this area has largely omitted uncertainty quantification. Our focus in this paper is a common multi-task problem in neuroimaging, where the goal is to understand the relationship between multiple cognitive task scores (or other subject-level assessments) and brain connectome data collected from imaging. We propose a framework for selective inference to address this problem, with the flexibility to: (i) jointly identify the relevant covariates for each task through a sparsity-inducing penalty, and (ii) conduct valid inference in a model based on the estimated sparsity structure. Our framework offers a new conditional procedure for in
    
[^22]: 现代生物统计中的强化学习：构建最优自适应干预

    Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions. (arXiv:2203.02605v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.02605](http://arxiv.org/abs/2203.02605)

    本文是关于将强化学习应用于自适应干预中的第一份统一调查，强化学习在动态治疗方案和移动健康中即时自适应干预这两个领域中都具有很大的应用潜力。在这两个领域之间存在相似和不同之处需要考虑，并且这里存在巨大的合作机会。

    

    近年来，强化学习（RL）在与健康相关的序列性决策中占据了重要地位，成为交付自适应干预（AIs）的越来越流行的工具。然而，尽管具有潜在优势，但其现实应用仍然受到限制，部分是由于方法论和应用社区之间的协同不足。在这项工作中，我们提供了关于学习AIs的RL方法的第一份统一调查，利用RL的通用方法论伞来桥接动态治疗方案和移动健康中即时自适应干预这两个AI领域。我们概述了这两个AI领域之间的异同，并讨论了它们对使用RL的影响。最后，我们利用自己在两个领域中设计案例研究的经验，说明了在AIs领域中，统计学、RL和医疗研究人员之间的巨大合作机会。

    In recent years, reinforcement learning (RL) has acquired a prominent position in the space of health-related sequential decision-making, becoming an increasingly popular tool for delivering adaptive interventions (AIs). However, despite potential benefits, its real-life application is still limited, partly due to a poor synergy between the methodological and the applied communities. In this work, we provide the first unified survey on RL methods for learning AIs, using the common methodological umbrella of RL to bridge the two AI areas of dynamic treatment regimes and just-in-time adaptive interventions in mobile health. We outline similarities and differences between these two AI domains and discuss their implications for using RL. Finally, we leverage our experience in designing case studies in both areas to illustrate the tremendous collaboration opportunities between statistical, RL, and healthcare researchers in the space of AIs.
    
[^23]: 缺失治疗信息的条件平均处理效应估计

    Estimating Conditional Average Treatment Effects with Missing Treatment Information. (arXiv:2203.01422v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.01422](http://arxiv.org/abs/2203.01422)

    本文研究了条件平均处理效应 (CATE) 的估计问题，在缺失治疗信息的情况下，提出了缺失治疗表示网络 (MTRNet)，通过域自适应学习协变量的平衡表示来解决协变量转移问题。

    

    估计条件平均处理效应 (CATE) 是具有挑战性的，特别是在治疗信息缺失的情况下。尽管在实践中这是一个普遍存在的问题，但缺失治疗的 CATE 估计却受到了很少关注。在本文中，我们分析了缺失治疗情况下的 CATE 估计，在这种情况下存在独特的挑战，例如协变量偏移。我们认定了我们的情况中存在两种协变量转移：(i) 治疗组和对照组之间的协变量转移，以及(ii) 观察到的治疗组和缺失治疗组之间的协变量转移。我们首先从理论上证明了这些协变量转移的影响，通过为我们的缺失治疗情况下的 CATE 估计导出一个泛化界限。然后，受到我们的界限的启发，我们开发了缺失治疗表示网络 (MTRNet)，这是一种新颖的 CATE 估计算法，它使用域自适应学习协变量的平衡表示。通过使用平衡的表示方法，MTRNet提供了

    Estimating conditional average treatment effects (CATE) is challenging, especially when treatment information is missing. Although this is a widespread problem in practice, CATE estimation with missing treatments has received little attention. In this paper, we analyze CATE estimation in the setting with missing treatments where unique challenges arise in the form of covariate shifts. We identify two covariate shifts in our setting: (i) a covariate shift between the treated and control population; and (ii) a covariate shift between the observed and missing treatment population. We first theoretically show the effect of these covariate shifts by deriving a generalization bound for estimating CATE in our setting with missing treatments. Then, motivated by our bound, we develop the missing treatment representation network (MTRNet), a novel CATE estimation algorithm that learns a balanced representation of covariates using domain adaptation. By using balanced representations, MTRNet provid
    
[^24]: 基于普适函数逼近的强化学习的在线子采样

    Online Sub-Sampling for Reinforcement Learning with General Function Approximation. (arXiv:2106.07203v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.07203](http://arxiv.org/abs/2106.07203)

    本文提出了一种基于在线子采样框架的强化学习算法，利用数据点的信息增益量来指导探索，与现有方法相比更新RL算法的策略次数大大减少，但仍保持较小的近似最优遗憾边界。

    

    现有的大多数强化学习（RL）普适函数逼近（FA）方法都专注于理解统计复杂性或遗憾边界，但这些方法的计算复杂性远未得到理解——事实上，函数类上的简单优化问题可能同样难以处理。本文通过建立一种高效的在线子采样框架来解决这个问题，该框架测量RL算法收集的数据点的信息增益，并使用该测量指导探索。对于基于价值的方法和复杂度有界的函数类，我们证明了策略只需要更新$\propto\operatorname{poly}\log(K)$ 次，就可以运行 $K$ 次RL算法而仍然实现较小的近似最优遗憾边界。与现有方法更新策略至少要 $\Omega(K)$ 次相比，我们的方法大大减少了解决方案中的优化调用次数。

    Most of the existing works for reinforcement learning (RL) with general function approximation (FA) focus on understanding the statistical complexity or regret bounds. However, the computation complexity of such approaches is far from being understood -- indeed, a simple optimization problem over the function class might be as well intractable. In this paper, we tackle this problem by establishing an efficient online sub-sampling framework that measures the information gain of data points collected by an RL algorithm and uses the measurement to guide exploration. For a value-based method with complexity-bounded function class, we show that the policy only needs to be updated for $\propto\operatorname{poly}\log(K)$ times for running the RL algorithm for $K$ episodes while still achieving a small near-optimal regret bound. In contrast to existing approaches that update the policy for at least $\Omega(K)$ times, our approach drastically reduces the number of optimization calls in solving 
    
[^25]: Matern高斯过程在黎曼流形上的应用

    Mat\'ern Gaussian processes on Riemannian manifolds. (arXiv:2006.10160v6 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2006.10160](http://arxiv.org/abs/2006.10160)

    本文提出了一种新的方法，通过谱理论计算Riemannian Matérn高斯过程在紧黎曼流形上的核，使其可以通过标准的可扩展技术进行训练。这将推动Matérn高斯过程在黎曼流形上的应用。

    

    高斯过程是一种有效的模型类，特别是在精确表示预测不确定性很重要的情况下。受物理科学应用的启发，最近将广泛使用的Matérn高斯过程推广到模拟定义在黎曼流形上的函数，通过将这些过程重新表示为随机偏微分方程的解来实现。在本文中，我们提出了通过拉普拉斯-贝尔特拉米算子的谱理论在紧黎曼流形上计算这些过程的核心技术，从而使它们可以通过标准可扩展技术（例如诱导点方法）进行训练。我们还将该推广从Matérn推广到广泛使用的平方指数高斯过程。通过允许使用众所周知的技术对Riemannian Matérn高斯过程进行训练，我们的工作使它们能够得到广泛应用。

    Gaussian processes are an effective model class for learning unknown functions, particularly in settings where accurately representing predictive uncertainty is of key importance. Motivated by applications in the physical sciences, the widely-used Mat\'ern class of Gaussian processes has recently been generalized to model functions whose domains are Riemannian manifolds, by re-expressing said processes as solutions of stochastic partial differential equations. In this work, we propose techniques for computing the kernels of these processes on compact Riemannian manifolds via spectral theory of the Laplace-Beltrami operator in a fully constructive manner, thereby allowing them to be trained via standard scalable techniques such as inducing point methods. We also extend the generalization from the Mat\'ern to the widely-used squared exponential Gaussian process. By allowing Riemannian Mat\'ern Gaussian processes to be trained using well-understood techniques, our work enables their use i
    
[^26]: 快速面向具有PL条件的非凸强凸min-max问题的目标和对偶差收敛(arXiv:2006.06889v8 [cs.LG] UPDATED)

    Fast Objective & Duality Gap Convergence for Non-Convex Strongly-Concave Min-Max Problems with PL Condition. (arXiv:2006.06889v8 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.06889](http://arxiv.org/abs/2006.06889)

    该论文探讨了解决深度学习中出现的一类非凸强凸min-max问题的随机方法，并提出了一个基于近端阶段的方法框架，其中嵌入了许多众所周知的随机更新，快速收敛性得到了建立。

    

    本文着重于解决平滑非凸强凸min-max问题的随机方法，该问题由于其在深度学习中的潜在应用（如深度AUC最大化，分布式鲁棒优化）而受到越来越多的关注。然而，大多数现有算法在实践中较慢，并且它们的分析围绕收敛于接近稳态点展开。我们考虑利用Polyak-Lojasiewicz（PL）条件来设计更快的随机算法，并提供更强的收敛保证。虽然PL条件已经被用于设计许多随机最小化算法，但它们对于非凸极小化最大化优化的应用仍然很少。在本文中，我们提出并分析了一个泛化的基于近端阶段的方法框架，其中嵌入了许多众所周知的随机更新。我们建立了基于原始目标间隙和对偶间隙的快速收敛性。与现有研究相比，（i）我们的分析是...

    This paper focuses on stochastic methods for solving smooth non-convex strongly-concave min-max problems, which have received increasing attention due to their potential applications in deep learning (e.g., deep AUC maximization, distributionally robust optimization). However, most of the existing algorithms are slow in practice, and their analysis revolves around the convergence to a nearly stationary point.We consider leveraging the Polyak-Lojasiewicz (PL) condition to design faster stochastic algorithms with stronger convergence guarantee. Although PL condition has been utilized for designing many stochastic minimization algorithms, their applications for non-convex min-max optimization remain rare. In this paper, we propose and analyze a generic framework of proximal stage-based method with many well-known stochastic updates embeddable. Fast convergence is established in terms of both the primal objective gap and the duality gap. Compared with existing studies, (i) our analysis is 
    
[^27]: 多变量大数据分析中的可解释性学习用于网络监测

    Interpretable Learning in Multivariate Big Data Analysis for Network Monitoring. (arXiv:1907.02677v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/1907.02677](http://arxiv.org/abs/1907.02677)

    本文扩展了多变量大数据分析（MBDA）方法，提出了一种自动推导特征的解决方案，结合可解释性和交互式模型的优势以及并行处理的能力，应用于网络监测和诊断，最终在UGR'16和Dartmouth'18两个数据集上取得成功。

    

    开发新的数据驱动模型以评估通信网络性能越来越受到关注。对于许多应用程序，比如网络监测和故障排除，如果不能被人类操作员解释，数据模型就没多大用处。在本文中，我们提出了多变量大数据分析（MBDA）方法的扩展，这是一种近期提出的可解释性数据分析工具。在这个扩展中，我们提出了自动推导特征的解决方案，这是当数据量庞大时应用MBDA的重要步骤。所得到的网络监测方法允许我们检测和诊断不同的网络异常，采用一种将可解释性和交互式模型的优势与并行处理的能力相结合的数据分析工作流。我们将扩展的MBDA应用于两个案例研究：UGR'16，用于异常检测的基准流量实际数据集，以及Dartmouth'18，最长和最具挑战性的数据集之一。

    There is an increasing interest in the development of new data-driven models useful to assess the performance of communication networks. For many applications, like network monitoring and troubleshooting, a data model is of little use if it cannot be interpreted by a human operator. In this paper, we present an extension of the Multivariate Big Data Analysis (MBDA) methodology, a recently proposed interpretable data analysis tool. In this extension, we propose a solution to the automatic derivation of features, a cornerstone step for the application of MBDA when the amount of data is massive. The resulting network monitoring approach allows us to detect and diagnose disparate network anomalies, with a data-analysis workflow that combines the advantages of interpretable and interactive models with the power of parallel processing. We apply the extended MBDA to two case studies: UGR'16, a benchmark flow-based real-traffic dataset for anomaly detection, and Dartmouth'18, the longest and l
    

