# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Inference on eigenvectors of non-symmetric matrices.](http://arxiv.org/abs/2303.18233) | 本研究探讨了建立渐近推断非对称矩阵特征向量程序的必要条件，并针对完全向量和每个系数假设分别建立了 Wald 和 t 检验的分布理论，是多元统计学中的一种有用工具。 |
| [^2] | [Microcanonical Langevin Monte Carlo.](http://arxiv.org/abs/2303.18221) | 我们提出的微正则 Langevin Monte Carlo 方法能够高效地采样 $\exp[-S(\x)]$ 分布，同时具有无偏性。 |
| [^3] | [Simple Sorting Criteria Help Find the Causal Order in Additive Noise Models.](http://arxiv.org/abs/2303.18211) | 文章探讨了加性噪声模型中找到因果顺序的方法。作者发现除了方差排序外，变量的决定系数$R^2$排序也可用于匹配已有方法的表现，且不受数据缩放的影响。 |
| [^4] | [Constrained Optimization of Rank-One Functions with Indicator Variables.](http://arxiv.org/abs/2303.18158) | 本文提出了一种基于透视重构技术的紧凑扩展公式，用于解决涉及指标变量限制下决策变量支持集合的秩一凸函数的最小化问题。 |
| [^5] | [Large Dimensional Independent Component Analysis: Statistical Optimality and Computational Tractability.](http://arxiv.org/abs/2303.18156) | 本文探讨了独立成分分析的统计最优性和计算可行性，发现维度和样本复杂度成线性关系，但使用样本峭度方法不是最优的。在限制使用低次多项式算法计算的情况下，最优样本复杂度将成为维度的平方。另外，我们开发了具有计算可行性的估计方法，实现了最优样本复杂度和极小化最大风险收敛速率。 |
| [^6] | [BERTino: an Italian DistilBERT model.](http://arxiv.org/abs/2303.18121) | 本文介绍了BERTino，一种轻量级的DistilBERT模型，是用于意大利语的第一个替代BERT体系结构的选择，其在多项任务中F1分数与BERTBASE相当并显著提高了训练和推理速度。 |
| [^7] | [Evaluation Challenges for Geospatial ML.](http://arxiv.org/abs/2303.18087) | 本文论述了地理空间机器学习评估中的独特挑战，提出了改进地理空间模型性能评估的具体方法。 |
| [^8] | [Synergistic Graph Fusion via Encoder Embedding.](http://arxiv.org/abs/2303.18051) | 本文提出了一种协同图融合的新方法，该方法处理具有共同顶点集的多个图，有着非常理想的“协同效应”，即顶点分类准确度总是受益于额外的图，并在实验中证实了其卓越性能。 |
| [^9] | [Differentially Private Stochastic Convex Optimization in (Non)-Euclidean Space Revisited.](http://arxiv.org/abs/2303.18047) | 本文重新探讨了在欧几里得空间和一般的$\ell_p^d$空间中进行差分隐私随机凸优化（DP-SCO）的问题。针对凸损失函数和强凸损失函数，提出了方法，其输出能够实现(预期)过量种群风险，这只取决于约束集合的高斯宽度，对强凸函数，界限是最优的。同时，提出了针对重尾数据进行DP-SCO的算法，并在$1<p<2$和$2≤p≤∞$的两种情况下，提供了第一个理论结果。 |
| [^10] | [The Topology-Overlap Trade-Off in Retinal Arteriole-Venule Segmentation.](http://arxiv.org/abs/2303.18022) | 本文研究了视网膜动静脉分割中的拓扑-重叠折衷问题，提出了引入拓扑保持项和方向评分引导的卷积模块来提高分割的连续性和质量。 |
| [^11] | [Rapid prediction of lab-grown tissue properties using deep learning.](http://arxiv.org/abs/2303.18017) | 该文介绍了使用深度学习技术快速预测实验室培养的细胞/hydrogels的机械特性的理论证明，减少了物理实验成本。 |
| [^12] | [Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States.](http://arxiv.org/abs/2303.17963) | 本文提出了一种面向未知具有潜在状态系统的学习优化控制方法，并给出了概率性能保证，同时提出了一种验证任意控制律性能的方法。 |
| [^13] | [Per-Example Gradient Regularization Improves Learning Signals from Noisy Data.](http://arxiv.org/abs/2303.17940) | 本文研究了每个示例的梯度正则化 (PEGR) 技术，证明其可以有效地学习信号并抑制噪音，从而提高测试误差和抗噪声扰动能力。 |
| [^14] | [An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response.](http://arxiv.org/abs/2303.17823) | 本文提出了一种基于可解释神经网络的非比例赔率模型 (N$^3$POM) 用于有序回归，可以对连续变量进行预测，同时保留了可解释性，具有灵活性。 |
| [^15] | [Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness.](http://arxiv.org/abs/2303.17765) | 本文提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置。 |
| [^16] | [A Note On Nonlinear Regression Under L2 Loss.](http://arxiv.org/abs/2303.17745) | 研究者们发现对于传统的最小二乘问题存在一个可以使用凸非线性回归模型解决的方法，使得设计更复杂的系统和更易于训练的模型成为可能。 |
| [^17] | [$\beta^{4}$-IRT: A New $\beta^{3}$-IRT with Enhanced Discrimination Estimation.](http://arxiv.org/abs/2303.17731) | 本文提出了一种新的名称为β4-IRT的项目反应理论模型，通过使用梯度下降方法估计模型参数来增强判别估计，解决了β3-IRT的对称性问题。 |
| [^18] | [A Characterization of Online Multiclass Learnability.](http://arxiv.org/abs/2303.17716) | 在线多类学习问题中，使用Multiclass Littlestone维度可以刻画标签数目为无界情况下的可学习性。 |
| [^19] | [An ADMM Solver for the MKL-$L_{0/1}$-SVM.](http://arxiv.org/abs/2303.04445) | 该论文提出了一个快速ADMM求解器，能够有效处理带有$(0,1)$-损失函数的支持向量机问题，通过在合成平面数据上的实验，证明了该方法的潜力。 |
| [^20] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^21] | [A unified recipe for deriving (time-uniform) PAC-Bayes bounds.](http://arxiv.org/abs/2302.03421) | 该论文提出了一种用于推导PAC-Bayesian泛化界限的统一框架，不同于传统的固定样本大小方式，该框架适用于所有停止时间。同时，该论文还提出了新的边界方法，也可以应用于非平稳损失函数和非独立同分布的数据。 |
| [^22] | [Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data.](http://arxiv.org/abs/2301.00437) | 研究者证明对于均方误差和交叉熵损失，深度线性网络中出现的全局解在不同数据上都具有神经塌陷的特性，即最后一层特征会崩溃为类均值，而这些类均值是等角紧框架的顶点。 |
| [^23] | [TAP-Vid: A Benchmark for Tracking Any Point in a Video.](http://arxiv.org/abs/2211.03726) | TAP-Vid是一个跟踪任何点在视频中的基准数据集，包含真实世界视频和合成视频，有助于推动解决跟踪任意物理点在视频中的难题。 |
| [^24] | [A Kernel Approach for PDE Discovery and Operator Learning.](http://arxiv.org/abs/2210.08140) | 本文提出了一种使用核方法的三步学习和求解偏微分方程的框架，能够近似解新的PDE，并展示了比其他算法更优的表现。 |
| [^25] | [Bounded Simplex-Structured Matrix Factorization: Algorithms, Identifiability and Applications.](http://arxiv.org/abs/2209.12638) | 提出了一种新的低秩矩阵分解模型BSSMF，它的矩阵W每列的元素属于给定的区间，而H的列是随机的，推广了NMF和SSMF，适用于矩阵元素属于给定区间的情况下，具有易于理解的分解和离散结构，适用于主题建模和社区检测等应用。 |
| [^26] | [Far from Asymptopia.](http://arxiv.org/abs/2205.03343) | 本文研究了有限数据推断中的参数度量问题，证明了Jeffreys先验会在典型科学模型中引入巨大偏差，因此提出了一种基于原则的度量选择以实现对于复杂模型的无偏推断。 |
| [^27] | [Continual Learning of Multi-modal Dynamics with External Memory.](http://arxiv.org/abs/2203.00936) | 本文提出了一种新的连续学习方法，通过在记忆中维护遇到序列模式的描述符来实现，能够有效处理新的行为模式的连续出现。 |
| [^28] | [Near-Optimal Learning of Extensive-Form Games with Imperfect Information.](http://arxiv.org/abs/2202.01752) | 本文提出了一种新的算法系列，可以更快速地在不完美信息广义博弈中找到一个近似最优解。 |
| [^29] | [Factor-augmented tree ensembles.](http://arxiv.org/abs/2111.14000) | 本文提出了一种因子增强的树集合方法，能够处理多种不规则预测变量，为处理宏观金融问题提供一种可靠的方法。 |
| [^30] | [A Method for Evaluating Deep Generative Models of Images via Assessing the Reproduction of High-order Spatial Context.](http://arxiv.org/abs/2111.12577) | 本研究提出了一种评估图像深度生成模型的方法，通过检测经过训练的GAN生成的图像中高阶空间上下文的再现能力，并验证了多个客观测试以评估不同GAN的质量。 |
| [^31] | [Adaptive joint distribution learning.](http://arxiv.org/abs/2110.04829) | 该论文提出了一种自适应联合分布学习的框架，可以从大量数据点中估计低维、归一化和正的Radon-Nikodym导数模型，并在不同学习问题上取得了良好的结果。 |
| [^32] | [Learning Treatment Effects in Panels with General Intervention Patterns.](http://arxiv.org/abs/2106.02780) | 本文提出了一种针对面板数据的因果推断问题的解决方案，利用合成对照的方法进行处理。文章拓展了该框架，使其适用性更加广泛，并在计算实验中展现了它的优越性能。 |
| [^33] | [Time-uniform central limit theory and asymptotic confidence sequences.](http://arxiv.org/abs/2103.06476) | 本论文介绍了时间均匀的渐近置信序列的方法，这些序列在时间上是统一有效的，能够在任意停止时间进行有效推断，并填补了现有文献中非渐近置信序列与渐近置信区间之间的空白。 |
| [^34] | [Optimal training of integer-valued neural networks with mixed integer programming.](http://arxiv.org/abs/2009.03825) | 本文介绍了一种新的混合整数规划方法来训练整数值神经网络，其中包括优化神经元数量的方法和鼓励NN更加稀疏的正则化项方法，可以在不使用GPU或复杂超参数调整的情况下提高训练效率和泛化性能。 |
| [^35] | [Adaptive Estimators Show Information Compression in Deep Neural Networks.](http://arxiv.org/abs/1902.09037) | 本文使用自适应估计技术研究深度网络中的信息压缩，发现相比使用饱和激活函数，非饱和激活函数的网络能实现可比的任务性能水平，但无法显示出信息压缩。 |

# 详细

[^1]: 非对称矩阵特征向量的推断

    Inference on eigenvectors of non-symmetric matrices. (arXiv:2303.18233v1 [math.ST])

    [http://arxiv.org/abs/2303.18233](http://arxiv.org/abs/2303.18233)

    本研究探讨了建立渐近推断非对称矩阵特征向量程序的必要条件，并针对完全向量和每个系数假设分别建立了 Wald 和 t 检验的分布理论，是多元统计学中的一种有用工具。

    

    本文认为，Tyler（1981）的可对称化条件并非建立渐近推断特征向量程序所必需的。 我们为完全向量和每个系数假设分别建立了 Wald 和 t 检验的分布理论。 我们的检验统计量来源于非对称矩阵的特征投影。 通过将投影表示为从基础矩阵到其谱数据的映射，我们通过解析摄动理论找到了导数。 这些结果演示了 Sun（1991）的解析摄动理论是多元统计学中的一种有用工具，并且具有独立的兴趣。作为一种应用，我们为由有向图引发的邻接矩阵估计的 Bonacich 中心性定义置信区间。

    This paper argues that the symmetrisability condition in Tyler(1981) is not necessary to establish asymptotic inference procedures for eigenvectors. We establish distribution theory for a Wald and t-test for full-vector and individual coefficient hypotheses, respectively. Our test statistics originate from eigenprojections of non-symmetric matrices. Representing projections as a mapping from the underlying matrix to its spectral data, we find derivatives through analytic perturbation theory. These results demonstrate how the analytic perturbation theory of Sun(1991) is a useful tool in multivariate statistics and are of independent interest. As an application, we define confidence sets for Bonacich centralities estimated from adjacency matrices induced by directed graphs.
    
[^2]: 微正则 Langevin Monte Carlo

    Microcanonical Langevin Monte Carlo. (arXiv:2303.18221v1 [hep-lat])

    [http://arxiv.org/abs/2303.18221](http://arxiv.org/abs/2303.18221)

    我们提出的微正则 Langevin Monte Carlo 方法能够高效地采样 $\exp[-S(\x)]$ 分布，同时具有无偏性。

    

    我们提出了一种方法，用于以可用渐变 $ \nabla S(\x)$ 的形式采样自一任意分布 $ \exp[-S(\x)]$，该方法被制定为保持能量的随机微分方程（SDE）。我们推导出 Fokker-Planck 方程，并证明确定性漂移和随机扩散分别保持平稳分布。这意味着漂移扩散离散化方案无偏，而标准 Langevin 动力学则不是。我们将该方法应用于 $\phi^4$ 晶格场论，展示了结果与标准采样方法一致，但比当前最先进的采样器效率显著提高。

    We propose a method for sampling from an arbitrary distribution $\exp[-S(\x)]$ with an available gradient $\nabla S(\x)$, formulated as an energy-preserving stochastic differential equation (SDE). We derive the Fokker-Planck equation and show that both the deterministic drift and the stochastic diffusion separately preserve the stationary distribution. This implies that the drift-diffusion discretization schemes are bias-free, in contrast to the standard Langevin dynamics. We apply the method to the $\phi^4$ lattice field theory, showing the results agree with the standard sampling methods but with significantly higher efficiency compared to the current state-of-the-art samplers.
    
[^3]: 简单的排序标准有助于在加性噪声模型中找到因果顺序。

    Simple Sorting Criteria Help Find the Causal Order in Additive Noise Models. (arXiv:2303.18211v1 [stat.ML])

    [http://arxiv.org/abs/2303.18211](http://arxiv.org/abs/2303.18211)

    文章探讨了加性噪声模型中找到因果顺序的方法。作者发现除了方差排序外，变量的决定系数$R^2$排序也可用于匹配已有方法的表现，且不受数据缩放的影响。

    

    加性噪声模型（ANM）是一种常见的功能假设，可以从观测数据中学习因果结构。由于缺乏符合假设的真实世界数据，合成ANM数据经常用于评估因果发现算法。Reisach等人（2021）表明，对于常见的模拟参数，按增大方差的顺序变量排列与因果顺序密切相关，并引入变异性可排序性来量化这种对齐程度。本文还表明，除了方差，还有变量的方差被所有其他变量解释的比例（由决定系数$R^2$捕获）倾向于沿着因果顺序增加。简单的基准算法可以使用$R^2$-sortability来匹配已有方法的性能。由于$R^2$可排序性不受数据缩放的影响，这些算法在标准化或重新缩放的数据上表现同样出色，解决了利用变异性可排序性的算法的一个关键限制。

    Additive Noise Models (ANM) encode a popular functional assumption that enables learning causal structure from observational data. Due to a lack of real-world data meeting the assumptions, synthetic ANM data are often used to evaluate causal discovery algorithms. Reisach et al. (2021) show that, for common simulation parameters, a variable ordering by increasing variance is closely aligned with a causal order and introduce var-sortability to quantify the alignment. Here, we show that not only variance, but also the fraction of a variable's variance explained by all others, as captured by the coefficient of determination $R^2$, tends to increase along the causal order. Simple baseline algorithms can use $R^2$-sortability to match the performance of established methods. Since $R^2$-sortability is invariant under data rescaling, these algorithms perform equally well on standardized or rescaled data, addressing a key limitation of algorithms exploiting var-sortability. We characterize and 
    
[^4]: 指标变量限制下秩一函数的约束优化

    Constrained Optimization of Rank-One Functions with Indicator Variables. (arXiv:2303.18158v1 [math.OC])

    [http://arxiv.org/abs/2303.18158](http://arxiv.org/abs/2303.18158)

    本文提出了一种基于透视重构技术的紧凑扩展公式，用于解决涉及指标变量限制下决策变量支持集合的秩一凸函数的最小化问题。

    

    在各种机器学习应用中，涉及到通过约束来建模决策变量支持集合的秩一凸函数的最小化的优化问题。这些问题通常采用指标变量来识别连续变量的支持。本文通过透视重构技术研究了这些问题的紧凑扩展公式。与大多数先前的研究依赖于支持函数参数和离散规划技术以提供凸包结果不同，我们提出了一种构造方法，利用透视函数引起的隐藏圆锥结构。为此，我们首先针对每个圆锥约束涉及独立连续变量的线性函数和一组二元变量的一般圆锥混合二进制集合建立了一个凸包结果。然后，我们展示了与应对epi相关的集合的扩展表示形式。

    Optimization problems involving minimization of a rank-one convex function over constraints modeling restrictions on the support of the decision variables emerge in various machine learning applications. These problems are often modeled with indicator variables for identifying the support of the continuous variables. In this paper we investigate compact extended formulations for such problems through perspective reformulation techniques. In contrast to the majority of previous work that relies on support function arguments and disjunctive programming techniques to provide convex hull results, we propose a constructive approach that exploits a hidden conic structure induced by perspective functions. To this end, we first establish a convex hull result for a general conic mixed-binary set in which each conic constraint involves a linear function of independent continuous variables and a set of binary variables. We then demonstrate that extended representations of sets associated with epi
    
[^5]: 大维独立成分分析: 统计最优性与计算可行性

    Large Dimensional Independent Component Analysis: Statistical Optimality and Computational Tractability. (arXiv:2303.18156v1 [math.ST])

    [http://arxiv.org/abs/2303.18156](http://arxiv.org/abs/2303.18156)

    本文探讨了独立成分分析的统计最优性和计算可行性，发现维度和样本复杂度成线性关系，但使用样本峭度方法不是最优的。在限制使用低次多项式算法计算的情况下，最优样本复杂度将成为维度的平方。另外，我们开发了具有计算可行性的估计方法，实现了最优样本复杂度和极小化最大风险收敛速率。

    

    本文研究了独立成分分析（ICA）的最优统计性能和计算限制的影响。我们的目标是两方面的。一方面，我们表征了样本复杂度和统计准确度与维度精确的关系，以及计算考虑如何影响它们。特别地，我们展示了最优样本复杂度与维度成线性关系，同时，一些常用的基于样本峭度的方法是不可避免的次优的。然而，如果我们限制只使用能够用低次多项式算法计算的估计，最优样本复杂度将变为维度的平方，称为对数因子。另一方面，我们制定了具有计算可行性的估计方法，实现了最优样本复杂度和极小化最大风险收敛速率。我们研究了所提出的估计的渐近性质，并建立了它们的渐近正态性。

    In this paper, we investigate the optimal statistical performance and the impact of computational constraints for independent component analysis (ICA). Our goal is twofold. On the one hand, we characterize the precise role of dimensionality on sample complexity and statistical accuracy, and how computational consideration may affect them. In particular, we show that the optimal sample complexity is linear in dimensionality, and interestingly, the commonly used sample kurtosis-based approaches are necessarily suboptimal. However, the optimal sample complexity becomes quadratic, up to a logarithmic factor, in the dimension if we restrict ourselves to estimates that can be computed with low-degree polynomial algorithms. On the other hand, we develop computationally tractable estimates that attain both the optimal sample complexity and minimax optimal rates of convergence. We study the asymptotic properties of the proposed estimates and establish their asymptotic normality that can be read
    
[^6]: BERTino：一种意大利DistilBERT模型

    BERTino: an Italian DistilBERT model. (arXiv:2303.18121v1 [cs.CL])

    [http://arxiv.org/abs/2303.18121](http://arxiv.org/abs/2303.18121)

    本文介绍了BERTino，一种轻量级的DistilBERT模型，是用于意大利语的第一个替代BERT体系结构的选择，其在多项任务中F1分数与BERTBASE相当并显著提高了训练和推理速度。

    

    最近引入的Transformer语言表示模型在许多自然语言处理任务中取得了很大的改进。然而，这种体系结构的性能虽然惊人，但由于构成其网络的参数过多，导致计算和存储需求高，限制了它们的可用性。本文介绍了BERTino，一种DistilBERT模型，它是用于意大利语的第一个轻量级替代BERT体系结构的选择。我们对BERTino在意大利ISDT、意大利ParTUT、意大利WikiNER和多类分类任务上进行了评估，在训练和推理速度方面获得了显著提高，并获得了与BERTBASE相当的F1分数。

    The recent introduction of Transformers language representation models allowed great improvements in many natural language processing (NLP) tasks. However, if on one hand the performances achieved by this kind of architectures are surprising, on the other their usability is limited by the high number of parameters which constitute their network, resulting in high computational and memory demands. In this work we present BERTino, a DistilBERT model which proposes to be the first lightweight alternative to the BERT architecture specific for the Italian language. We evaluated BERTino on the Italian ISDT, Italian ParTUT, Italian WikiNER and multiclass classification tasks, obtaining F1 scores comparable to those obtained by a BERTBASE with a remarkable improvement in training and inference speed.
    
[^7]: 地理空间机器学习的评估挑战

    Evaluation Challenges for Geospatial ML. (arXiv:2303.18087v1 [cs.LG])

    [http://arxiv.org/abs/2303.18087](http://arxiv.org/abs/2303.18087)

    本文论述了地理空间机器学习评估中的独特挑战，提出了改进地理空间模型性能评估的具体方法。

    

    随着地理空间机器学习模型和由其预测产生的地图在科学和政策的下游分析中越来越多地被使用，评估其准确性和适用性变得至关重要。地理空间机器学习与其他学习范例有着关键差异，因此，衡量空间机器学习输出性能的正确方法一直是争论的话题。本文阐述了全球或遥感数据下地理空间机器学习模型评估的独特挑战，并总结了改进地理空间模型性能评估的具体方法。

    As geospatial machine learning models and maps derived from their predictions are increasingly used for downstream analyses in science and policy, it is imperative to evaluate their accuracy and applicability. Geospatial machine learning has key distinctions from other learning paradigms, and as such, the correct way to measure performance of spatial machine learning outputs has been a topic of debate. In this paper, I delineate unique challenges of model evaluation for geospatial machine learning with global or remotely sensed datasets, culminating in concrete takeaways to improve evaluations of geospatial model performance.
    
[^8]: 基于编码器嵌入的协同图融合

    Synergistic Graph Fusion via Encoder Embedding. (arXiv:2303.18051v1 [cs.SI])

    [http://arxiv.org/abs/2303.18051](http://arxiv.org/abs/2303.18051)

    本文提出了一种协同图融合的新方法，该方法处理具有共同顶点集的多个图，有着非常理想的“协同效应”，即顶点分类准确度总是受益于额外的图，并在实验中证实了其卓越性能。

    

    本文提出了一种称为图融合编码器嵌入的多图嵌入新方法，该方法旨在处理具有共同顶点集的多个图。在监督学习设置下，我们证明了该方法展现出了令人惊叹但非常理想的“协同效应”：对于足够大的顶点数，分类准确度总是受益于额外的图。我们在随机块模型下提供了这种效应的数学证明，并确定了渐近完美分类的必要条件和充分条件。模拟和真实数据实验证实了所提出的方法的卓越性能，该方法在分类中始终优于最近的基准方法。

    In this paper, we introduce a novel approach to multi-graph embedding called graph fusion encoder embedding. The method is designed to work with multiple graphs that share a common vertex set. Under the supervised learning setting, we show that the resulting embedding exhibits a surprising yet highly desirable "synergistic effect": for sufficiently large vertex size, the vertex classification accuracy always benefits from additional graphs. We provide a mathematical proof of this effect under the stochastic block model, and identify the necessary and sufficient condition for asymptotically perfect classification. The simulations and real data experiments confirm the superiority of the proposed method, which consistently outperforms recent benchmark methods in classification.
    
[^9]: 差分隐私随机凸优化在（非）欧几里得空间中的再探讨

    Differentially Private Stochastic Convex Optimization in (Non)-Euclidean Space Revisited. (arXiv:2303.18047v1 [cs.LG])

    [http://arxiv.org/abs/2303.18047](http://arxiv.org/abs/2303.18047)

    本文重新探讨了在欧几里得空间和一般的$\ell_p^d$空间中进行差分隐私随机凸优化（DP-SCO）的问题。针对凸损失函数和强凸损失函数，提出了方法，其输出能够实现(预期)过量种群风险，这只取决于约束集合的高斯宽度，对强凸函数，界限是最优的。同时，提出了针对重尾数据进行DP-SCO的算法，并在$1<p<2$和$2≤p≤∞$的两种情况下，提供了第一个理论结果。

    

    本文重新探讨了在欧几里得空间和一般的$\ell_p^d$空间中进行差分隐私随机凸优化（DP-SCO）的问题。具体来说，我们关注三个仍未被充分理解的设置: (1) 在欧几里得空间限制且有界的（凸）集合上进行DP-SCO; (2) 在$\ell_p^d$空间上无限制的DP-SCO; (3) 在限制且有界的$\ell_p^d$空间中，使用重尾数据进行DP-SCO。对于问题（1），针对凸损失函数和强凸损失函数，我们提出了方法，其输出能够实现(预期)过量种群风险，这只取决于约束集合的高斯宽度，而不是空间维度。此外，我们还展示了对于强凸函数，界限是最优的，最多相差一个对数因子。对于问题（2）和（3），我们提出了几种新算法，并针对$1<p<2$和$2≤p≤∞$的两种情况，提供了第一个理论结果。

    In this paper, we revisit the problem of Differentially Private Stochastic Convex Optimization (DP-SCO) in Euclidean and general $\ell_p^d$ spaces. Specifically, we focus on three settings that are still far from well understood: (1) DP-SCO over a constrained and bounded (convex) set in Euclidean space; (2) unconstrained DP-SCO in $\ell_p^d$ space; (3) DP-SCO with heavy-tailed data over a constrained and bounded set in $\ell_p^d$ space. For problem (1), for both convex and strongly convex loss functions, we propose methods whose outputs could achieve (expected) excess population risks that are only dependent on the Gaussian width of the constraint set rather than the dimension of the space. Moreover, we also show the bound for strongly convex functions is optimal up to a logarithmic factor. For problems (2) and (3), we propose several novel algorithms and provide the first theoretical results for both cases when $1<p<2$ and $2\leq p\leq \infty$.
    
[^10]: 视网膜动静脉分割中的拓扑 - 重叠折衷问题

    The Topology-Overlap Trade-Off in Retinal Arteriole-Venule Segmentation. (arXiv:2303.18022v1 [cs.CV])

    [http://arxiv.org/abs/2303.18022](http://arxiv.org/abs/2303.18022)

    本文研究了视网膜动静脉分割中的拓扑-重叠折衷问题，提出了引入拓扑保持项和方向评分引导的卷积模块来提高分割的连续性和质量。

    

    视网膜底图像可以成为筛查高血压或糖尿病等流行病的宝贵诊断工具。通过自动分割分叉处和交叉处，可以在提高分割重叠度的同时提高管状结构的拓扑正确性。为此，本文考虑在损失函数中引入拓扑保持项，以提高分割的连续性。然而，这样做会导致动脉和静脉之间的误分类和总体重叠度降低。通过引入基于各向异性相似性度量的方向评分引导的卷积模块，我们进一步提高了动静脉细分的质量。

    Retinal fundus images can be an invaluable diagnosis tool for screening epidemic diseases like hypertension or diabetes. And they become especially useful when the arterioles and venules they depict are clearly identified and annotated. However, manual annotation of these vessels is extremely time demanding and taxing, which calls for automatic segmentation. Although convolutional neural networks can achieve high overlap between predictions and expert annotations, they often fail to produce topologically correct predictions of tubular structures. This situation is exacerbated by the bifurcation versus crossing ambiguity which causes classification mistakes. This paper shows that including a topology preserving term in the loss function improves the continuity of the segmented vessels, although at the expense of artery-vein misclassification and overall lower overlap metrics. However, we show that by including an orientation score guided convolutional module, based on the anisotropic si
    
[^11]: 深度学习快速预测实验室培养的组织机械特性

    Rapid prediction of lab-grown tissue properties using deep learning. (arXiv:2303.18017v1 [q-bio.TO])

    [http://arxiv.org/abs/2303.18017](http://arxiv.org/abs/2303.18017)

    该文介绍了使用深度学习技术快速预测实验室培养的细胞/hydrogels的机械特性的理论证明，减少了物理实验成本。

    

    细胞和细胞外基质之间的相互作用是组织自组织的关键。本文介绍了使用机器学习工具预测在固定模具中培养的细胞/hydrogels自组织中机械生物学作用的理论证明。我们通过CONTRACT network dipole orientation(CONDOR)模型在模具中模拟了6500个细胞/基质交互作用，并使用\texttt{pix2pix}深度学习模型中的实现来进行训练，将保留的740个未经训练的案例用于训练和验证。机器学习技术的预测结果与生物物理算法的保留预测之间的比较表明，机器学习模型可以高精度地快速预测细胞/hydrogels的机械特性，减少了耗时和昂贵的物理实验的需求。

    The interactions between cells and the extracellular matrix are vital for the self-organisation of tissues. In this paper we present proof-of-concept to use machine learning tools to predict the role of this mechanobiology in the self-organisation of cell-laden hydrogels grown in tethered moulds. We develop a process for the automated generation of mould designs with and without key symmetries. We create a large training set with $N=6500$ cases by running detailed biophysical simulations of cell-matrix interactions using the contractile network dipole orientation (CONDOR) model for the self-organisation of cellular hydrogels within these moulds. These are used to train an implementation of the \texttt{pix2pix} deep learning model, reserving $740$ cases that were unseen in the training of the neural network for training and validation. Comparison between the predictions of the machine learning technique and the reserved predictions from the biophysical algorithm show that the machine le
    
[^12]: 面向未知具有潜在状态系统的学习优化控制方法

    Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States. (arXiv:2303.17963v1 [eess.SY])

    [http://arxiv.org/abs/2303.17963](http://arxiv.org/abs/2303.17963)

    本文提出了一种面向未知具有潜在状态系统的学习优化控制方法，并给出了概率性能保证，同时提出了一种验证任意控制律性能的方法。

    

    随着控制工程方法应用于越来越复杂的系统，数据驱动的系统辨识方法成为物理建模的有希望的替代方法。然而，许多这些方法依赖于状态测量的可用性，而复杂系统的状态通常不是直接可测量的。因此，可能需要同时估计动力学和潜在状态，从而更加具有挑战性地设计具有性能保证的控制器。本文提出了一种新方法，用于计算具有潜在状态的未知非线性系统的最优输入轨迹。对结果输入轨迹进行了概率性能保证，并提出了一种验证任意控制律性能的方法。本文在数值模拟中展示了所提出方法的有效性。

    As control engineering methods are applied to increasingly complex systems, data-driven approaches for system identification appear as a promising alternative to physics-based modeling. While many of these approaches rely on the availability of state measurements, the states of a complex system are often not directly measurable. It may then be necessary to jointly estimate the dynamics and a latent state, making it considerably more challenging to design controllers with performance guarantees. This paper proposes a novel method for the computation of an optimal input trajectory for unknown nonlinear systems with latent states. Probabilistic performance guarantees are derived for the resulting input trajectory, and an approach to validate the performance of arbitrary control laws is presented. The effectiveness of the proposed method is demonstrated in a numerical simulation.
    
[^13]: 每个示例的梯度正则化改进了从嘈杂数据中学习的信号

    Per-Example Gradient Regularization Improves Learning Signals from Noisy Data. (arXiv:2303.17940v1 [stat.ML])

    [http://arxiv.org/abs/2303.17940](http://arxiv.org/abs/2303.17940)

    本文研究了每个示例的梯度正则化 (PEGR) 技术，证明其可以有效地学习信号并抑制噪音，从而提高测试误差和抗噪声扰动能力。

    

    本文研究了每个示例的梯度正则化 (PEGR) 技术，并通过理论分析证明了其在提高测试误差和抗噪声扰动方面的有效性。具体来说，我们采用了 \citet {cao2022benign} 的信号噪音数据模型，并展示了 PEGR 可以有效地学习信号并抑制噪音。与传统的梯度下降方法不同，PEGR 可以区分信号和噪音，从而提高泛化性能。我们的分析揭示了 PEGR 惩罚模式学习的方差，从而有效地抑制了从训练数据中记忆噪声。

    Gradient regularization, as described in \citet{barrett2021implicit}, is a highly effective technique for promoting flat minima during gradient descent. Empirical evidence suggests that this regularization technique can significantly enhance the robustness of deep learning models against noisy perturbations, while also reducing test error. In this paper, we explore the per-example gradient regularization (PEGR) and present a theoretical analysis that demonstrates its effectiveness in improving both test error and robustness against noise perturbations. Specifically, we adopt a signal-noise data model from \citet{cao2022benign} and show that PEGR can learn signals effectively while suppressing noise. In contrast, standard gradient descent struggles to distinguish the signal from the noise, leading to suboptimal generalization performance. Our analysis reveals that PEGR penalizes the variance of pattern learning, thus effectively suppressing the memorization of noises from the training d
    
[^14]: 一种基于可解释神经网络的连续回应有序回归非比例赔率模型

    An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response. (arXiv:2303.17823v1 [stat.ME])

    [http://arxiv.org/abs/2303.17823](http://arxiv.org/abs/2303.17823)

    本文提出了一种基于可解释神经网络的非比例赔率模型 (N$^3$POM) 用于有序回归，可以对连续变量进行预测，同时保留了可解释性，具有灵活性。

    

    本文提出了一种基于可解释神经网络的非比例赔率模型（N$^3$POM) 用于有序回归，其中反应变量不仅可以取离散值，也可以取连续值，而回归系数根据预测顺序反应也不同。与传统方法直接从离散反应估计线性系数不同，我们训练了一个非线性的神经网络，通过以反应为输入产生线性系数。由于神经网络的优势，N$^3$POM可以在保留传统有序回归的可解释性的同时具有灵活性。我们给出了充分的条件，使得在指定的用户区域内，预测的条件累积概率（CCP）满足局部单调性约束。我们还提供了一种保持单调性的随机（MPS）算法来充分训练神经网络。

    This paper proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression, where the response variable can take not only discrete but also continuous values, and the regression coefficients vary depending on the predicting ordinal response. In contrast to conventional approaches estimating the linear coefficients of regression directly from the discrete response, we train a non-linear neural network that outputs the linear coefficients by taking the response as its input. By virtue of the neural network, N$^3$POM may have flexibility while preserving the interpretability of the conventional ordinal regression. We show a sufficient condition so that the predicted conditional cumulative probability~(CCP) satisfies the monotonicity constraint locally over a user-specified region in the covariate space; we also provide a monotonicity-preserving stochastic (MPS) algorithm for training the neural network adequately.
    
[^15]: 学习相似的线性表示：适应性、极小化、以及稳健性

    Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])

    [http://arxiv.org/abs/2303.17765](http://arxiv.org/abs/2303.17765)

    本文提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置。

    

    表示多任务学习和迁移学习在实践中取得了巨大的成功，然而对这些方法的理论理解仍然欠缺。本文旨在理解从具有相似但并非完全相同的线性表示的任务中学习，同时处理异常值任务。我们提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置，我们的算法在单任务或仅目标学习时表现优异。

    Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
    
[^16]: L2范数下的非线性回归注释

    A Note On Nonlinear Regression Under L2 Loss. (arXiv:2303.17745v1 [cs.LG])

    [http://arxiv.org/abs/2303.17745](http://arxiv.org/abs/2303.17745)

    研究者们发现对于传统的最小二乘问题存在一个可以使用凸非线性回归模型解决的方法，使得设计更复杂的系统和更易于训练的模型成为可能。

    

    我们研究了L2范数（平方损失）函数下的非线性回归问题。传统的非线性回归模型通常导致参数集的非凸优化问题。我们展示了一个针对传统最小二乘问题的凸非线性回归模型，可能有助于设计更复杂的系统和更易于训练的模型。

    We investigate the nonlinear regression problem under L2 loss (square loss) functions. Traditional nonlinear regression models often result in non-convex optimization problems with respect to the parameter set. We show that a convex nonlinear regression model exists for the traditional least squares problem, which can be a promising towards designing more complex systems with easier to train models.
    
[^17]: β4-IRT：一种具有增强判别力估计的新β3-IRT。

    $\beta^{4}$-IRT: A New $\beta^{3}$-IRT with Enhanced Discrimination Estimation. (arXiv:2303.17731v1 [cs.LG])

    [http://arxiv.org/abs/2303.17731](http://arxiv.org/abs/2303.17731)

    本文提出了一种新的名称为β4-IRT的项目反应理论模型，通过使用梯度下降方法估计模型参数来增强判别估计，解决了β3-IRT的对称性问题。

    

    项目反应理论旨在从不同难度等级的项目中推断出受试者未观察到的能力和特征。针对不同类型的任务，如二进制或概率响应、反应时间、多重响应等，已经提出了几种项目反应理论模型。本文提出了一个新版本的β3-IRT，称为β4-IRT，该版本使用梯度下降方法来估计模型参数。在β3-IRT中，能力和难度受到限制，因此我们采用链接函数将β4-IRT转变为无约束的梯度下降过程。原始的β3-IRT存在对称问题，即如果某个项目的判别力值符号错误（例如负值，而实际上是正的），拟合过程可能无法恢复该项目的正确判别力和难度值。

    Item response theory aims to estimate respondent's latent skills from their responses in tests composed of items with different levels of difficulty. Several models of item response theory have been proposed for different types of tasks, such as binary or probabilistic responses, response time, multiple responses, among others. In this paper, we propose a new version of $\beta^3$-IRT, called $\beta^{4}$-IRT, which uses the gradient descent method to estimate the model parameters. In $\beta^3$-IRT, abilities and difficulties are bounded, thus we employ link functions in order to turn $\beta^{4}$-IRT into an unconstrained gradient descent process. The original $\beta^3$-IRT had a symmetry problem, meaning that, if an item was initialised with a discrimination value with the wrong sign, e.g. negative when the actual discrimination should be positive, the fitting process could be unable to recover the correct discrimination and difficulty values for the item. In order to tackle this limita
    
[^18]: 在线多类可学习性的刻画。

    A Characterization of Online Multiclass Learnability. (arXiv:2303.17716v1 [cs.LG])

    [http://arxiv.org/abs/2303.17716](http://arxiv.org/abs/2303.17716)

    在线多类学习问题中，使用Multiclass Littlestone维度可以刻画标签数目为无界情况下的可学习性。

    

    我们考虑当标签数目是无界的时候在线多类学习问题。我们展示了Multiclass Littlestone维度，这个概念首次出现在\cite{DanielyERMprinciple}中，继续刻画了该场景下的在线可学习性。我们的结果补充了最近的工作，\cite{Brukhimetal2022}给出了当标签空间是无界的情况下批处理多类可学习性的刻画。

    We consider the problem of online multiclass learning when the number of labels is unbounded. We show that the Multiclass Littlestone dimension, first introduced in \cite{DanielyERMprinciple}, continues to characterize online learnability in this setting. Our result complements the recent work by \cite{Brukhimetal2022} who give a characterization of batch multiclass learnability when the label space is unbounded.
    
[^19]: 一个ADMM求解MKL-$L_{0/1}$-SVM的方法

    An ADMM Solver for the MKL-$L_{0/1}$-SVM. (arXiv:2303.04445v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.04445](http://arxiv.org/abs/2303.04445)

    该论文提出了一个快速ADMM求解器，能够有效处理带有$(0,1)$-损失函数的支持向量机问题，通过在合成平面数据上的实验，证明了该方法的潜力。

    

    我们针对带有臭名昭著的$(0,1)$-损失函数的支持向量机问题，制定了多核学习(MKL)问题。给出了一些一阶最优性条件，然后利用这些条件来开发一个快速的ADMM求解器，用于处理非凸和非光滑的优化问题。一个简单的数值实验表明，我们的MKL-$L_{0/1}$-SVM框架具有很好的前景。

    We formulate the Multiple Kernel Learning (abbreviated as MKL) problem for the support vector machine with the infamous $(0,1)$-loss function. Some first-order optimality conditions are given and then exploited to develop a fast ADMM solver for the nonconvex and nonsmooth optimization problem. A simple numerical experiment on synthetic planar data shows that our MKL-$L_{0/1}$-SVM framework could be promising.
    
[^20]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^21]: 一种统一的方法推导（时间均匀的）PAC-Bayes界限

    A unified recipe for deriving (time-uniform) PAC-Bayes bounds. (arXiv:2302.03421v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.03421](http://arxiv.org/abs/2302.03421)

    该论文提出了一种用于推导PAC-Bayesian泛化界限的统一框架，不同于传统的固定样本大小方式，该框架适用于所有停止时间。同时，该论文还提出了新的边界方法，也可以应用于非平稳损失函数和非独立同分布的数据。

    

    我们提出了一个框架，用于推导PAC-Bayesian泛化界限。与大多数关于此主题的文献不同，我们的界限是任何时间都有效的（即时间均匀的），这意味着它们适用于所有停止时间，而不仅仅是固定的样本大小。我们的方法按照以下顺序结合了四种工具：（a）非负超马丁格尔或反向亚马逊，（b）混合法，（c）Donsker-Varadhan公式（或其它凸性对偶原理）和（d）Ville不等式。我们的主要成果是一个PAC-Bayes定理，适用于广泛的离散随机过程类。我们展示了这个结果如何推出知名的经典PAC-Bayes界限，例如Seeger、McAllester、Maurer和Catoni的界限，以及许多最新的界限。我们还提出了几个新的界限。我们的框架还使我们能够放松传统的假设；特别地，我们考虑非平稳损失函数和非独立同分布的数据。

    We present a unified framework for deriving PAC-Bayesian generalization bounds. Unlike most previous literature on this topic, our bounds are anytime-valid (i.e., time-uniform), meaning that they hold at all stopping times, not only for a fixed sample size. Our approach combines four tools in the following order: (a) nonnegative supermartingales or reverse submartingales, (b) the method of mixtures, (c) the Donsker-Varadhan formula (or other convex duality principles), and (d) Ville's inequality. Our main result is a PAC-Bayes theorem which holds for a wide class of discrete stochastic processes. We show how this result implies time-uniform versions of well-known classical PAC-Bayes bounds, such as those of Seeger, McAllester, Maurer, and Catoni, in addition to many recent bounds. We also present several novel bounds. Our framework also enables us to relax traditional assumptions; in particular, we consider nonstationary loss functions and non-i.i.d. data. In sum, we unify the derivati
    
[^22]: 深度线性网络中的神经塌陷:从平衡到不平衡的数据

    Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data. (arXiv:2301.00437v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00437](http://arxiv.org/abs/2301.00437)

    研究者证明对于均方误差和交叉熵损失，深度线性网络中出现的全局解在不同数据上都具有神经塌陷的特性，即最后一层特征会崩溃为类均值，而这些类均值是等角紧框架的顶点。

    

    现代深度神经网络在图像分类和自然语言处理等任务中表现出色，但令人惊讶的是，这些具有大量参数的复杂系统在训练到收敛时，它们的最后一层特征和分类器在经典数据集上表现出相同的结构性质。特别地，观察到最后一层特征会崩溃为类均值，并且这些类均值是等角紧框架(simplex Equiangular Tight Frame)的顶点。这种现象被称为神经塌陷(NC)。最近的论文理论上证明了在简化的“无约束特征模型”训练问题的全局最小值中出现了$\mathcal{NC}$。在这个语境下，我们进一步证明了在常用的均方误差(MSE)和交叉熵(CE)损失下，深度线性网络中也会发生$\mathcal{NC}$现象，表明全局解在不同数据上都具有$\mathcal{NC}$的特性。

    Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse ($\mathcal{NC}$). Recent papers have theoretically shown that $\mathcal{NC}$ emerges in the global minimizers of training problems with the simplified ``unconstrained feature model''. In this context, we take a step further and prove the $\mathcal{NC}$ occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit $\mathcal{NC}$ properties across
    
[^23]: TAP-Vid：在视频中跟踪任何点的基准数据集

    TAP-Vid: A Benchmark for Tracking Any Point in a Video. (arXiv:2211.03726v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.03726](http://arxiv.org/abs/2211.03726)

    TAP-Vid是一个跟踪任何点在视频中的基准数据集，包含真实世界视频和合成视频，有助于推动解决跟踪任意物理点在视频中的难题。

    

    从视频中获取普适的运动理解不仅涉及追踪物体，还需要感知它们的表面变形和运动。这些信息对于推断 3D 形状、物理属性和物体交互非常有用。虽然在较长的视频片段中追踪任意物理点的问题已经引起了一些关注，但直到现在还没有可用于评估的数据集或基准。在本文中，我们首先将这个问题形式化，并将其命名为跟踪任意点 (TAP)。我们引入了一个伴随数据集 TAP-Vid，它由具有准确人工标注的点迹的真实世界视频和具有完美地面实况点迹的合成视频组成。我们构建基准的关键是一个新颖的半自动众包流水线，它使用光流估计来弥补摄像机抖动等简单短期运动，让注释者专注于视频的更难部分。我们在合成数据上验证了我们的流水线，并提出了评估指标来衡量在 TAP-Vid 上的跟踪表现。我们的基准包括具有非刚性运动和遮挡的具有挑战性的序列，以及广泛的物体类别和摄像机运动。我们希望 TAP-Vid 能够鼓励研究这个重要而困难的问题，推动更好的算法来跟踪视频中任意物理点。

    Generic motion understanding from video involves not only tracking objects, but also perceiving how their surfaces deform and move. This information is useful to make inferences about 3D shape, physical properties and object interactions. While the problem of tracking arbitrary physical points on surfaces over longer video clips has received some attention, no dataset or benchmark for evaluation existed, until now. In this paper, we first formalize the problem, naming it tracking any point (TAP). We introduce a companion benchmark, TAP-Vid, which is composed of both real-world videos with accurate human annotations of point tracks, and synthetic videos with perfect ground-truth point tracks. Central to the construction of our benchmark is a novel semi-automatic crowdsourced pipeline which uses optical flow estimates to compensate for easier, short-term motion like camera shake, allowing annotators to focus on harder sections of video. We validate our pipeline on synthetic data and prop
    
[^24]: 用核方法探索偏微分方程和算子学习

    A Kernel Approach for PDE Discovery and Operator Learning. (arXiv:2210.08140v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.08140](http://arxiv.org/abs/2210.08140)

    本文提出了一种使用核方法的三步学习和求解偏微分方程的框架，能够近似解新的PDE，并展示了比其他算法更优的表现。

    

    本文介绍了一种使用核方法学习和解决偏微分方程（PDEs）的三步框架。给定一个训练集，包括网格上的噪声PDE解以及源项/边界项的对，利用核平滑技术去噪并近似解的导数。然后利用这些信息在核回归模型中学习PDE的代数形式。学习得到的PDE在基于核的求解器中被用来近似解新的源项/边界项的PDE，从而构成了一个算子学习框架。数值实验将该方法与最先进的算法进行了比较，并展示了其竞争性能。

    This article presents a three-step framework for learning and solving partial differential equations (PDEs) using kernel methods. Given a training set consisting of pairs of noisy PDE solutions and source/boundary terms on a mesh, kernel smoothing is utilized to denoise the data and approximate derivatives of the solution. This information is then used in a kernel regression model to learn the algebraic form of the PDE. The learned PDE is then used within a kernel based solver to approximate the solution of the PDE with a new source/boundary term, thereby constituting an operator learning framework. Numerical experiments compare the method to state-of-the-art algorithms and demonstrate its competitive performance.
    
[^25]: 有界单纯形结构矩阵分解：算法、可识别性和应用

    Bounded Simplex-Structured Matrix Factorization: Algorithms, Identifiability and Applications. (arXiv:2209.12638v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.12638](http://arxiv.org/abs/2209.12638)

    提出了一种新的低秩矩阵分解模型BSSMF，它的矩阵W每列的元素属于给定的区间，而H的列是随机的，推广了NMF和SSMF，适用于矩阵元素属于给定区间的情况下，具有易于理解的分解和离散结构，适用于主题建模和社区检测等应用。

    

    本文提出了一种新的低秩矩阵分解模型，称为有界单纯形结构矩阵分解（BSSMF）。给定一个输入矩阵X和一个分解秩r，BSSMF在矩阵W中寻找具有r列的矩阵和在矩阵H中寻找具有r行的矩阵，使得X≈WH ，其中W的每列中的元素都是有界的，即它们属于给定的区间，而H的列属于概率单纯形，即H是列随机的。BSSMF推广了非负矩阵分解（NMF）和单纯形结构矩阵分解（SSMF）。BSSMF特别适用于输入矩阵X的元素属于给定区间的情况；例如，当X的行表示图像时，或者X是类似Netflix和MovieLens数据集中的评分矩阵时，其中X的元素属于区间[1,5]。单纯形结构矩阵H不仅可以提供易于理解的分解，从而对X的列空间进行软聚类，而且还赋予H的列离散结构，使其非常适合用于如主题建模和社区检测等应用。我们开发了有效的BSSMF优化算法，建立了其可识别性保证，并在合成和实际数据集上展示了BSSMF的有效性。

    In this paper, we propose a new low-rank matrix factorization model dubbed bounded simplex-structured matrix factorization (BSSMF). Given an input matrix $X$ and a factorization rank $r$, BSSMF looks for a matrix $W$ with $r$ columns and a matrix $H$ with $r$ rows such that $X \approx WH$ where the entries in each column of $W$ are bounded, that is, they belong to given intervals, and the columns of $H$ belong to the probability simplex, that is, $H$ is column stochastic. BSSMF generalizes nonnegative matrix factorization (NMF), and simplex-structured matrix factorization (SSMF). BSSMF is particularly well suited when the entries of the input matrix $X$ belong to a given interval; for example when the rows of $X$ represent images, or $X$ is a rating matrix such as in the Netflix and MovieLens datasets where the entries of $X$ belong to the interval $[1,5]$. The simplex-structured matrix $H$ not only leads to an easily understandable decomposition providing a soft clustering of the colu
    
[^26]: 远离渐近理论：有限数据推断中的Jeffreys先验误用问题

    Far from Asymptopia. (arXiv:2205.03343v2 [stat.OT] UPDATED)

    [http://arxiv.org/abs/2205.03343](http://arxiv.org/abs/2205.03343)

    本文研究了有限数据推断中的参数度量问题，证明了Jeffreys先验会在典型科学模型中引入巨大偏差，因此提出了一种基于原则的度量选择以实现对于复杂模型的无偏推断。

    

    在有限数据的推断中，需要一个参数空间上的度量概念，最明确的是贝叶斯框架中的先验。在本文中，我们证明了当应用于典型的科学模型时，最出名的非信息选择，Jeffreys先验，引入了巨大的偏差。这类模型的有效维度显著小于微观参数的数量。因为Jeffreys先验平等地处理所有的微观参数，所以投影到相关参数的子空间上时是均匀的，这是由于无关方向的本地共体积的变化。我们提出了一种基于原则的量度选择，避免了这个问题，在复杂模型中导致无偏推断。这个最优先验取决于要收集的数据数量，并且在渐近极限下趋近于Jeffreys先验。但是，如果没有指数数量级的微观参数，这个极限是无法证明的。

    Inference from limited data requires a notion of measure on parameter space, most explicit in the Bayesian framework as a prior. Here we demonstrate that Jeffreys prior, the best-known uninformative choice, introduces enormous bias when applied to typical scientific models. Such models have a relevant effective dimensionality much smaller than the number of microscopic parameters. Because Jeffreys prior treats all microscopic parameters equally, it is from uniform when projected onto the sub-space of relevant parameters, due to variations in the local co-volume of irrelevant directions. We present results on a principled choice of measure which avoids this issue, leading to unbiased inference in complex models. This optimal prior depends on the quantity of data to be gathered, and approaches Jeffreys prior in the asymptotic limit. However, this limit cannot be justified without an impossibly large amount of data, exponential in the number of microscopic parameters.
    
[^27]: 带外部记忆的多模态动态连续学习

    Continual Learning of Multi-modal Dynamics with External Memory. (arXiv:2203.00936v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.00936](http://arxiv.org/abs/2203.00936)

    本文提出了一种新的连续学习方法，通过在记忆中维护遇到序列模式的描述符来实现，能够有效处理新的行为模式的连续出现。

    

    本文研究了在新的行为模式连续出现时，如何将模型拟合到动态环境中。学习模型能够意识到新的模式出现，但它没有访问单个训练序列的真实模式的信息。目前的连续学习方法无法处理这种情况，因为参数传递受到灾难性干扰的影响，而情节记忆设计需要知道序列的真实模式。我们设计了一种新的连续学习方法，通过在神经情节记忆中维护遇到的序列模式的描述符来克服这两个限制。我们在记忆的注意权重上使用Dirichlet过程先验，以促进模式描述符的有效存储。通过检索先前任务相似模式的描述符，并将此描述符馈入其转移中，我们的方法通过在任务之间传递知识来执行连续学习。

    We study the problem of fitting a model to a dynamical environment when new modes of behavior emerge sequentially. The learning model is aware when a new mode appears, but it does not have access to the true modes of individual training sequences. The state-of-the-art continual learning approaches cannot handle this setup, because parameter transfer suffers from catastrophic interference and episodic memory design requires the knowledge of the ground-truth modes of sequences. We devise a novel continual learning method that overcomes both limitations by maintaining a descriptor of the mode of an encountered sequence in a neural episodic memory. We employ a Dirichlet Process prior on the attention weights of the memory to foster efficient storage of the mode descriptors. Our method performs continual learning by transferring knowledge across tasks by retrieving the descriptors of similar modes of past tasks to the mode of a current sequence and feeding this descriptor into its transitio
    
[^28]: 不完美信息博弈中的近似最优学习

    Near-Optimal Learning of Extensive-Form Games with Imperfect Information. (arXiv:2202.01752v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.01752](http://arxiv.org/abs/2202.01752)

    本文提出了一种新的算法系列，可以更快速地在不完美信息广义博弈中找到一个近似最优解。

    

    本文解决了学习不完美信息广义博弈的近似最优算法设计的开放性问题。我们提出了第一种算法系列，仅需要 $\widetilde{\mathcal{O}}((XA+YB)/\varepsilon^2)$ 局游戏即可在两人零和博弈中找到一个 $\varepsilon$-近似纳什均衡，其中 $X,Y$ 是信息集的数量，$A,B$ 是两名玩家的行动数。这比已知的样本复杂度 $\widetilde{\mathcal{O}}((X^2A+Y^2B)/\varepsilon^2)$ 有着 $\widetilde{\mathcal{O}}(\max\{X, Y\})$ 的巨大改进，并且在对数因子内与信息理论下限一致。我们通过两种新算法实现了这种样本复杂度：平衡在线镜面下降和平衡反事实后悔最小化。这两种算法都依赖于将“平衡探索策略”集成到它们的经典对手中的新方法。此外，我们还将我们的结果扩展到了更广泛的支持不完美信息博弈的二人博弈和多人博弈中。

    This paper resolves the open question of designing near-optimal algorithms for learning imperfect-information extensive-form games from bandit feedback. We present the first line of algorithms that require only $\widetilde{\mathcal{O}}((XA+YB)/\varepsilon^2)$ episodes of play to find an $\varepsilon$-approximate Nash equilibrium in two-player zero-sum games, where $X,Y$ are the number of information sets and $A,B$ are the number of actions for the two players. This improves upon the best known sample complexity of $\widetilde{\mathcal{O}}((X^2A+Y^2B)/\varepsilon^2)$ by a factor of $\widetilde{\mathcal{O}}(\max\{X, Y\})$, and matches the information-theoretic lower bound up to logarithmic factors. We achieve this sample complexity by two new algorithms: Balanced Online Mirror Descent, and Balanced Counterfactual Regret Minimization. Both algorithms rely on novel approaches of integrating \emph{balanced exploration policies} into their classical counterparts. We also extend our results t
    
[^29]: 因子增强的树集合方法

    Factor-augmented tree ensembles. (arXiv:2111.14000v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.14000](http://arxiv.org/abs/2111.14000)

    本文提出了一种因子增强的树集合方法，能够处理多种不规则预测变量，为处理宏观金融问题提供一种可靠的方法。

    

    本文提出了利用状态空间方法提取潜在稳态因子来扩展时间序列回归树信息集的方法。通过这样做，该方法将时间序列回归树的应用扩展到两个方面。第一，它可以处理测量误差、非平稳趋势、季节性和/或缺失观测等不规则的预测变量。第二，它提供了一种明确的利用领域专业理论来指导时间序列回归树的方法。实证结果表明，这些因子增强的树集合方法在宏观金融问题方面提供了一种可靠的方法。本文重点介绍了美国股票波动率与商业周期之间的先导滞后效应。

    This manuscript proposes to extend the information set of time-series regression trees with latent stationary factors extracted via state-space methods. In doing so, this approach generalises time-series regression trees on two dimensions. First, it allows to handle predictors that exhibit measurement error, non-stationary trends, seasonality and/or irregularities such as missing observations. Second, it gives a transparent way for using domain-specific theory to inform time-series regression trees. Empirically, ensembles of these factor-augmented trees provide a reliable approach for macro-finance problems. This article highlights it focussing on the lead-lag effect between equity volatility and the business cycle in the United States.
    
[^30]: 通过评估高阶空间上下文的再现性评估图像深度生成模型的方法

    A Method for Evaluating Deep Generative Models of Images via Assessing the Reproduction of High-order Spatial Context. (arXiv:2111.12577v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2111.12577](http://arxiv.org/abs/2111.12577)

    本研究提出了一种评估图像深度生成模型的方法，通过检测经过训练的GAN生成的图像中高阶空间上下文的再现能力，并验证了多个客观测试以评估不同GAN的质量。

    

    深度生成模型（DGM）可以改变诊断成像领域。生成对抗网络（GAN）是一种广泛使用的DGM。然而，将GAN和其他DGM应用于需要领域专业知识才能使用生成图像的任何应用程序时，普遍存在缺乏评估生成图像领域相关质量的充分或自动化手段的问题。本文展示了针对两种流行GAN架构输出的图像的几个客观测试。我们设计了几个随机上下文模型（SCM）来恢复在经过训练的GAN生成后可以恢复的不同的图像特征。其中一些特征是高阶算法像素排列规则，这些规则不易表达为协方差矩阵。我们设计并验证了统计分类器，以便检测已知排列规则的特定效应。然后，我们测试了两种不同GAN正确复现高阶空间上下文的比率。

    Deep generative models (DGMs) have the potential to revolutionize diagnostic imaging. Generative adversarial networks (GANs) are one kind of DGM which are widely employed. The overarching problem with deploying GANs, and other DGMs, in any application that requires domain expertise in order to actually use the generated images is that there generally is not adequate or automatic means of assessing the domain-relevant quality of generated images. In this work, we demonstrate several objective tests of images output by two popular GAN architectures. We designed several stochastic context models (SCMs) of distinct image features that can be recovered after generation by a trained GAN. Several of these features are high-order, algorithmic pixel-arrangement rules which are not readily expressed in covariance matrices. We designed and validated statistical classifiers to detect specific effects of the known arrangement rules. We then tested the rates at which two different GANs correctly rep
    
[^31]: 自适应联合分布学习

    Adaptive joint distribution learning. (arXiv:2110.04829v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.04829](http://arxiv.org/abs/2110.04829)

    该论文提出了一种自适应联合分布学习的框架，可以从大量数据点中估计低维、归一化和正的Radon-Nikodym导数模型，并在不同学习问题上取得了良好的结果。

    

    我们开发了一个新的框架，用于将联合概率分布嵌入张量积再生核希尔伯特空间（RKHS）中。我们的框架可以容纳一个低维、归一化和正的Radon-Nikodym导数模型，该模型可以从多达数百万个数据点的样本大小中进行估计，减轻了RKHS建模的固有限制。我们的方法自然产生了定义良好的归一化和正的条件分布。嵌入计算速度快且适用于从预测到分类的各种学习问题。我们的理论结果得到了有益的数值结果的支持。

    We develop a new framework for embedding joint probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). Our framework accommodates a low-dimensional, normalized and positive model of a Radon-Nikodym derivative, which we estimate from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and accommodates learning problems ranging from prediction to classification. Our theoretical findings are supplemented by favorable numerical results.
    
[^32]: 学习具有一般干预模式面板数据中的治疗效应

    Learning Treatment Effects in Panels with General Intervention Patterns. (arXiv:2106.02780v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.02780](http://arxiv.org/abs/2106.02780)

    本文提出了一种针对面板数据的因果推断问题的解决方案，利用合成对照的方法进行处理。文章拓展了该框架，使其适用性更加广泛，并在计算实验中展现了它的优越性能。

    

    面板数据中的因果推断问题是一个中心计量经济学问题。本文研究的是一个基本版本的面板数据因果推断问题：设$M^*$为低秩矩阵，$E$为零均值噪声矩阵。对于一个具有$\{0,1\}$值的“治疗”矩阵$Z$，我们观测到矩阵$O$，其中$O_{ij} := M^*_{ij} + E_{ij} + \mathcal{T}_{ij} Z_{ij}$，其中$\mathcal{T}_{ij}$是未知的异质性治疗效应。这个问题需要我们估计平均治疗效应$\tau^*:=\sum_{ij} \mathcal{T}_{ij} Z_{ij} / \sum_{ij} Z_{ij}$。合成对照范例提供了一种估计$\tau^*$的方法，当$Z$仅仅支持单个行时。本文将该框架扩展到允许一般的$Z$的速率最优恢复$\tau^*$，从而广泛扩展了它的适用性。我们的保证是在这个广泛的设置中第一次出现的。合成和真实数据上的计算实验表明，我们的估计器相对于竞争估计器具有重大优势。

    The problem of causal inference with panel data is a central econometric question. The following is a fundamental version of this problem: Let $M^*$ be a low rank matrix and $E$ be a zero-mean noise matrix. For a `treatment' matrix $Z$ with entries in $\{0,1\}$ we observe the matrix $O$ with entries $O_{ij} := M^*_{ij} + E_{ij} + \mathcal{T}_{ij} Z_{ij}$ where $\mathcal{T}_{ij} $ are unknown, heterogenous treatment effects. The problem requires we estimate the average treatment effect $\tau^* := \sum_{ij} \mathcal{T}_{ij} Z_{ij} / \sum_{ij} Z_{ij}$. The synthetic control paradigm provides an approach to estimating $\tau^*$ when $Z$ places support on a single row. This paper extends that framework to allow rate-optimal recovery of $\tau^*$ for general $Z$, thus broadly expanding its applicability. Our guarantees are the first of their type in this general setting. Computational experiments on synthetic and real-world data show a substantial advantage over competing estimators.
    
[^33]: 时间均匀的中心极限定理和渐近置信序列

    Time-uniform central limit theory and asymptotic confidence sequences. (arXiv:2103.06476v7 [math.ST] UPDATED)

    [http://arxiv.org/abs/2103.06476](http://arxiv.org/abs/2103.06476)

    本论文介绍了时间均匀的渐近置信序列的方法，这些序列在时间上是统一有效的，能够在任意停止时间进行有效推断，并填补了现有文献中非渐近置信序列与渐近置信区间之间的空白。

    

    基于中心极限定理（CLT）的置信区间是经典统计学的基石。尽管只是渐近有效的，但它们普遍存在，因为它们允许在非常弱的假设下进行统计推断，并且通常可以应用于即使非渐近推断也不可能的问题。本文介绍了时间均匀的类似于这样的渐近置信区间。具体而言，我们的方法采用置信序列（CS）的形式 - 置信区间的序列，这些区间在时间上是统一有效的。CS可在任意停止时间进行有效推断，而不需要像经典置信区间那样在先固定样本大小的情况下产生“窥视”数据的惩罚。现有文献中的CS都是非渐近的，因此不能享受渐近置信区间的广泛适用性。我们的工作填补了这一空白，给出了“渐近CS”的定义，并推导出一个通用的渐近置信序列。

    Confidence intervals based on the central limit theorem (CLT) are a cornerstone of classical statistics. Despite being only asymptotically valid, they are ubiquitous because they permit statistical inference under very weak assumptions, and can often be applied to problems even when nonasymptotic inference is impossible. This paper introduces time-uniform analogues of such asymptotic confidence intervals. To elaborate, our methods take the form of confidence sequences (CS) -- sequences of confidence intervals that are uniformly valid over time. CSs provide valid inference at arbitrary stopping times, incurring no penalties for "peeking" at the data, unlike classical confidence intervals which require the sample size to be fixed in advance. Existing CSs in the literature are nonasymptotic, and hence do not enjoy the aforementioned broad applicability of asymptotic confidence intervals. Our work bridges the gap by giving a definition for "asymptotic CSs", and deriving a universal asympto
    
[^34]: 混合整数规划优化整数值神经网络的最佳训练方法

    Optimal training of integer-valued neural networks with mixed integer programming. (arXiv:2009.03825v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2009.03825](http://arxiv.org/abs/2009.03825)

    本文介绍了一种新的混合整数规划方法来训练整数值神经网络，其中包括优化神经元数量的方法和鼓励NN更加稀疏的正则化项方法，可以在不使用GPU或复杂超参数调整的情况下提高训练效率和泛化性能。

    

    最近的研究表明，使用混合整数规划求解器可以优化神经网络的某些方面。但是使用混合整数规划求解器进行神经网络训练的方法尚未得到广泛研究。目前的优化神经网络训练的方法通常基于梯度的方法，并需要大量数据、在GPU上进行计算和广泛的超参数调整。相比之下，使用混合整数规划求解器进行训练不需要GPU或繁琐的超参数调整，但目前只能处理少量的数据。本文在最近使用混合整数规划求解器训练二进制神经网络的进展基础上，提出了新的混合整数规划模型，使训练效率得到改善，并可以训练重要的整数值神经网络。我们提供了两种新方法来进一步发挥使用混合整数规划进行神经网络训练的潜在重要性，第一种方法在训练的同时优化NN中神经元的数量，这减少了在训练之前决定网络结构的需要，并可以节省大量的时间和产生更好的结果。第二种方法引入了一个正则化项，鼓励训练的NN更加稀疏，这可以提高泛化性能。

    Recent work has shown potential in using Mixed Integer Programming (MIP) solvers to optimize certain aspects of neural networks (NNs). However the intriguing approach of training NNs with MIP solvers is under-explored. State-of-the-art-methods to train NNs are typically gradient-based and require significant data, computation on GPUs, and extensive hyper-parameter tuning. In contrast, training with MIP solvers does not require GPUs or heavy hyper-parameter tuning, but currently cannot handle anything but small amounts of data. This article builds on recent advances that train binarized NNs using MIP solvers. We go beyond current work by formulating new MIP models which improve training efficiency and which can train the important class of integer-valued neural networks (INNs). We provide two novel methods to further the potential significance of using MIP to train NNs. The first method optimizes the number of neurons in the NN while training. This reduces the need for deciding on netwo
    
[^35]: 深度神经网络中的自适应估计器显示信息压缩

    Adaptive Estimators Show Information Compression in Deep Neural Networks. (arXiv:1902.09037v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1902.09037](http://arxiv.org/abs/1902.09037)

    本文使用自适应估计技术研究深度网络中的信息压缩，发现相比使用饱和激活函数，非饱和激活函数的网络能实现可比的任务性能水平，但无法显示出信息压缩。

    

    为了改善神经网络的功能，理解它们的学习过程至关重要。深度学习的信息瓶颈理论提出，神经网络通过压缩它们的表示来忽略与任务无关的信息，从而实现良好的泛化性能。然而，对于这个理论的经验证据是相互矛盾的，因为只有当网络使用饱和激活函数时才观察到压缩。相反，具有非饱和激活函数的网络实现了可比较的任务性能水平，但没有显示出压缩。在本文中，我们开发了更强大的互信息估计技术，适应于神经网络的隐藏活动，并产生更敏感的从所有函数中激活的测量结果，特别是无界函数。利用这些自适应估计技术，我们研究了带有不同激活函数的网络中的压缩情况。首先，我们使用了两种改进的估计方法，...

    To improve how neural networks function it is crucial to understand their learning process. The information bottleneck theory of deep learning proposes that neural networks achieve good generalization by compressing their representations to disregard information that is not relevant to the task. However, empirical evidence for this theory is conflicting, as compression was only observed when networks used saturating activation functions. In contrast, networks with non-saturating activation functions achieved comparable levels of task performance but did not show compression. In this paper we developed more robust mutual information estimation techniques, that adapt to hidden activity of neural networks and produce more sensitive measurements of activations from all functions, especially unbounded functions. Using these adaptive estimation techniques, we explored compression in networks with a range of different activation functions. With two improved methods of estimation, firstly, we 
    

