# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos.](http://arxiv.org/abs/2311.02076) | 本研究通过分析神经网络训练中的锐度动力学，揭示出早期锐度降低、逐渐增加锐化和稳定边界的机制，并发现增大学习率时，稳定边界流形上发生倍增混沌路径。 |
| [^2] | [Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective.](http://arxiv.org/abs/2311.02043) | 本研究提出了一种基于贝叶斯决策分析的方法，对于任何贝叶斯回归模型，可以得到每个条件分位数的最佳和可解释的线性估计值和不确定性量化。该方法是一种适用于特定分位数子集选择的有效工具。 |
| [^3] | [Reproducible Parameter Inference Using Bagged Posteriors.](http://arxiv.org/abs/2311.02019) | 通过使用袋装方法，提出了一种易于使用且广泛适用的方法来改善在模型错误规范下的可重现性。 |
| [^4] | [High Probability Convergence of Adam Under Unbounded Gradients and Affine Variance Noise.](http://arxiv.org/abs/2311.02000) | Adam算法在非凸平滑随机优化中，经过深入分析，证明了在坐标-wise“仿射”方差噪声下，Adam可以以高概率收敛到稳定点，无需任何有界梯度假设和问题相关的知识。 |
| [^5] | [Obtaining Explainable Classification Models using Distributionally Robust Optimization.](http://arxiv.org/abs/2311.01994) | 本论文介绍了一种利用分布鲁棒优化获取可解释的分类模型的方法，通过构建稀疏的规则集合来同时解决规则集的稀疏性和预测准确性之间的权衡，从而保证泛化性能并降低计算成本。 |
| [^6] | [Latent Diffusion Model for Conditional Reservoir Facies Generation.](http://arxiv.org/abs/2311.01968) | 本研究提出了一种专门用于条件下储层相生成的潜在扩散模型，通过充分保留条件数据，生成了高保真度的储层相。它在性能上明显优于基于GANs的替代方法。 |
| [^7] | [Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization.](http://arxiv.org/abs/2311.01900) | 本研究提出了一种在线非参数似然比估计（OLRE）框架，适用于估计两个概率密度函数之间差异的问题。通过利用核方法和函数最小化技术，我们的方法能够高效地进行在线更新，同时具有对概率密度函数形式无知的优势。 |
| [^8] | [Learning Sparse Codes with Entropy-Based ELBOs.](http://arxiv.org/abs/2311.01888) | 本论文提出了一种基于熵的学习目标，用于稀疏编码参数的学习，通过非平凡的后验逼近和解析的目标函数，实现了标准稀疏编码的学习，在数值实验中证明了其可行性。 |
| [^9] | [Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees.](http://arxiv.org/abs/2311.01806) | 本文提出了一种用于解决较大规模优化问题的快速速写算法，适用于凸或非凸正则化函数的最小二乘问题。相比已有的随机算法，该算法处理通用的Frechet子微分正则化函数并提供了一般的近似误差理论。同时，通过解决速写的稀疏凸或非凸学习问题，我们还得到了稀疏信号估计的极小极大速率。 |
| [^10] | [On the Generalization Properties of Diffusion Models.](http://arxiv.org/abs/2311.01797) | 本文对扩散模型的泛化属性进行了理论研究，建立了基于评分法的扩散模型的训练动态中泛化差距的理论估计，并在停止训练时可以避免维度诅咒。进一步将定量分析扩展到了数据依赖的情景。 |
| [^11] | [Efficient Generalized Low-Rank Tensor Contextual Bandits.](http://arxiv.org/abs/2311.01771) | 本文提出了一种新颖的广义低秩张量情境赌博算法，并引入了G-LowTESTR算法来实现探索和利用之间的权衡。 |
| [^12] | [Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel.](http://arxiv.org/abs/2311.01762) | 本文研究了使用梯度下降法解决非常数核的核岭回归。通过在训练过程中逐渐减小带宽，避免了超参数选择的需求，并提出了一种带宽更新方案，证明了其优于使用常数带宽的方法。 |
| [^13] | [Causal inference with Machine Learning-Based Covariate Representation.](http://arxiv.org/abs/2311.01709) | 本文提出了一种基于机器学习的协变量表示方法，可以在大维度协变量的情况下进行可靠的因果推断，并通过数值实验验证了其效果。 |
| [^14] | [Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling.](http://arxiv.org/abs/2311.01660) | 该论文提出了一种生存分析方法，通过引入重要抽样，消除了调整超参数的需求，如混合分配和箱尺寸，减轻了从业人员的负担。 |
| [^15] | [Should Under-parameterized Student Networks Copy or Average Teacher Weights?.](http://arxiv.org/abs/2311.01644) | 这项研究探讨了在欠参数化情况下，学生网络是否应该复制教师神经元或平均一组教师神经元的权重。研究发现对于特定的网络结构和输入分布，当教师网络的输入向量正交且输出权重为酉时，复制-平均配置将达到优化结果，其中大部分学生神经元复制一个教师神经元，最后一个学生神经元对所有教师神经元取平均值。 |
| [^16] | [Faithful and Robust Local Interpretability for Textual Predictions.](http://arxiv.org/abs/2311.01605) | 提出了一种名为FRED的新颖方法，用于解释文本预测。FRED可以识别文档中的关键词，并且通过与最先进的方法进行的实证评估证明了其在提供对文本模型的深入见解方面的有效性。 |
| [^17] | [Local Bayesian Dirichlet mixing of imperfect models.](http://arxiv.org/abs/2311.01596) | 本文介绍了一种利用狄利克雷分布结合多个不完善模型结果的贝叶斯机器学习框架，该框架在提高复杂计算模型的可预测性方面表现出色，尤其在核质量挖掘中取得了很好的性能。 |
| [^18] | [Variable Selection in Maximum Mean Discrepancy for Interpretable Distribution Comparison.](http://arxiv.org/abs/2311.01537) | 本文研究了数据集比较中的变量选择问题，提出了一种基于最大平均差异的两样本测试方法，通过优化自动相关性检测权重来增强测试的功效，并引入稀疏正则化方法来解决正则化参数选择的问题。 |
| [^19] | [Invariant Causal Imitation Learning for Generalizable Policies.](http://arxiv.org/abs/2311.01489) | 本文提出了不变因果模仿学习（ICIL）的新技术，通过学习一个跨领域不变的特征表示，实现在未知环境中进行模仿策略，并解决转换动态不匹配的问题。 |
| [^20] | [Applications of the Theory of Aggregated Markov Processes in Stochastic Learning Theory.](http://arxiv.org/abs/2311.01476) | 本文描述了聚合马尔可夫过程（AMP）的理论如何应用于随机学习理论中，以降低维度并实现学习特定任务的目标。 |
| [^21] | [Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization.](http://arxiv.org/abs/2310.18860) | 本文提出了一种基于贝叶斯公式的岭回归方法，通过期望最大化来调节正则化超参数，该方法不需要指定候选的λ并且在大样本下可以找到唯一的最优解。 |
| [^22] | [Causal Q-Aggregation for CATE Model Selection.](http://arxiv.org/abs/2310.16945) | 该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率 |
| [^23] | [How a student becomes a teacher: learning and forgetting through Spectral methods.](http://arxiv.org/abs/2310.12612) | 本论文提出了基于谱方法的优化方案，用于解决在非凸性问题下学生网络与教师网络之间存在的不变子网络的识别问题。 |
| [^24] | [Provably Convergent Data-Driven Convex-Nonconvex Regularization.](http://arxiv.org/abs/2310.05812) | 本研究展示了在凸非凸框架中，通过从数据中学习正则化器，可以实现收敛正则化；引入了一种新颖的弱凸输入神经网络构建，解决了之前对抗性方法的数值问题。 |
| [^25] | [On the limitations of data-driven weather forecasting models.](http://arxiv.org/abs/2309.08473) | 数据驱动的机器学习天气预报模型不具备传统基于物理的模型的准确性和物理一致性，它们在预测技能上的优势很大程度上可以归因于这些特殊性。 |
| [^26] | [Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization.](http://arxiv.org/abs/2307.02108) | 这篇论文提出了一种适用于情境赌博设置的新型计算效率高的赌博算法，具有简单和累积遗憾最小化的优势，并可自适应模型错误规范和连续臂设置。该算法利用"一致臂集"（CAS）来提供在每个情境下囊括情境特定的最佳臂的一组臂，跨越情境分布。这篇论文对简单和累积遗憾保证的研究提供了正面结果，同时也揭示了无法实现实例依赖性的简单遗憾保证的消极结果。 |
| [^27] | [Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges.](http://arxiv.org/abs/2307.01050) | 本文研究了最优运输和变分推断之间的联系，并提出了一种基于路径空间散度的采样和生成建模框架。通过开发新颖的基于得分的回火流技术和正则化的迭代比例拟合目标，本文展示了这些方法的潜力。 |
| [^28] | [Adaptive Algorithms for Relaxed Pareto Set Identification.](http://arxiv.org/abs/2307.00424) | 本研究提出了一种自适应算法，用于宽松Pareto集的识别，通过放松策略来减少样本复杂度，并展示了在实际场景中的良好表现。 |
| [^29] | [Allocating Divisible Resources on Arms with Unknown and Random Rewards.](http://arxiv.org/abs/2306.16578) | 本论文研究了在每个周期将一单位可分资源分配到多个臂上的问题，臂上的奖励是未知和随机的，而且与分配的资源成比例，而方差与分配资源的阶数成比例。我们设计了两种算法，实现了不同阶数下的最优有界和无界遗憾，结果表明在阶数为1/2时存在相变现象。 |
| [^30] | [Logarithmic Bayes Regret Bounds.](http://arxiv.org/abs/2306.09136) | 该论文提出了对于贝叶斯赌博机的首个有限时间对数遗憾边界，并用于高斯和线性赌博机，从而阐明了贝叶斯设置中先验价值以及对$\tilde{O}(\sqrt{n})$界限的改善。 |
| [^31] | [Long Sequence Hopfield Memory.](http://arxiv.org/abs/2306.04532) | 这篇论文提出了一种增强Hopfield-like神经网络序列记忆模型的序列容量的方法，通过引入非线性相互作用项，显著优于传统Hopfield网络，同时也引入了一个新的回忆规则以回忆连续的序列。 |
| [^32] | [Learning nonparametric latent causal graphs with unknown interventions.](http://arxiv.org/abs/2306.02899) | 本文提出了一种学习具有未知干预的非参数潜在因果图的方法，通过建立条件确定非参数潜在因果图并从中重构。这种方法不需要参数假设，可用于识别测量模型中潜在结构。 |
| [^33] | [Convex and Non-Convex Optimization under Generalized Smoothness.](http://arxiv.org/abs/2306.01264) | 本文发展了一种新的分析技术，并推广了广义平滑度条件，使凸和非凸优化问题获得更强的结果。在该条件下，获得了（随机）梯度下降和Nesterov加速梯度方法的经典收敛率。 |
| [^34] | [Doubly Robust Self-Training.](http://arxiv.org/abs/2306.00265) | 本文提出了一种双重稳健自我训练算法，可以在伪标签不准确和完全准确时分别采取不同的训练策略，实现有效的半监督学习。实验结果表明，该算法在ImageNet和nuScenes数据集上均比标准自我训练总结更好。 |
| [^35] | [Differentially Private Topological Data Analysis.](http://arxiv.org/abs/2305.03609) | 本文尝试使用差分隐私实现拓扑数据分析并生成接近最优的私有持久图，提出使用 $L^1$-距离计算持久图并采用指数机制保护隐私，成功实现在隐私保护和数据分析之间的平衡。 |
| [^36] | [To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning.](http://arxiv.org/abs/2303.03374) | 该论文研究了在迁移学习中使用单个预训练检查点微调的模型集合，发现通过更好地探索预训练基域可以改进集成模型，但离开基域会导致失去迁移学习的好处，并且降低集成质量。作者提出了一种更有效的修改方法StarSSE，可以产生更强的集成模型和均匀的模型混合。 |
| [^37] | [Multilayer hypergraph clustering using the aggregate similarity matrix.](http://arxiv.org/abs/2301.11657) | 本文提出了一个半定规划方法来解决基于超图的多层聚类问题，同时在同配和非同配情况下保证了精确恢复。 |
| [^38] | [Tracr: Compiled Transformers as a Laboratory for Interpretability.](http://arxiv.org/abs/2301.05062) | Tracr是一个编译器，将可读性强的程序编译成标准的仅解码变压器模型，该编译模型的已知结构可以用于设计实验和评估可解释方法。 |
| [^39] | [Bayesian learning of feature spaces for multitasks problems.](http://arxiv.org/abs/2209.03028) | 本文介绍了一种贝叶斯学习的方法，通过连接核机器和极限学习机，实现了在多任务回归问题中的特征空间的学习。该方法提供了优化RBF核参数、模型复杂度和多输出稀疏性的能力。 |
| [^40] | [Minimax Quasi-Bayesian estimation in sparse canonical correlation analysis via a Rayleigh quotient function.](http://arxiv.org/abs/2010.08627) | 本研究提出了一种利用重新缩放的瑞利商函数作为准对数似然函数并采用贝叶斯框架的方法，通过马尔科夫链蒙特卡罗计算稀疏规范向量的估计值。实验结果表明，该方法在连续和截断数据上表现优于其他方法。 |
| [^41] | [Recurrent Neural-Linear Posterior Sampling for Nonstationary Contextual Bandits.](http://arxiv.org/abs/2007.04750) | 该论文提出了一种递归神经线性后验抽样的方法，用于解决非平稳情境下的情境赌博问题。实验证明该方法能够有效地表示相关情境并做出决策。 |

# 详细

[^1]: 神经网络训练中的普适锐度动力学：固定点分析、稳定边界和混沌路径

    Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos. (arXiv:2311.02076v1 [cs.LG])

    [http://arxiv.org/abs/2311.02076](http://arxiv.org/abs/2311.02076)

    本研究通过分析神经网络训练中的锐度动力学，揭示出早期锐度降低、逐渐增加锐化和稳定边界的机制，并发现增大学习率时，稳定边界流形上发生倍增混沌路径。

    

    在神经网络的梯度下降动力学中，损失函数海森矩阵的最大特征值（锐度）在训练过程中展示出各种稳健的现象。这包括早期时间阶段，在训练的早期阶段锐度可能减小（降低锐度），以及后期行为，如逐渐增加的锐化和稳定边界。我们证明了一个简单的2层线性网络（UV模型），在单个训练样本上训练，展示了在真实场景中观察到的所有关键锐度现象。通过分析函数空间中动力学固定点的结构和函数更新的向量场，我们揭示了这些锐度趋势背后的机制。我们的分析揭示了：(i)早期锐度降低和逐渐增加锐化的机制，(ii)稳定边界所需的条件，以及 (iii)当学习率增加时，稳定边界流形上的倍增混沌路径.

    In gradient descent dynamics of neural networks, the top eigenvalue of the Hessian of the loss (sharpness) displays a variety of robust phenomena throughout training. This includes early time regimes where the sharpness may decrease during early periods of training (sharpness reduction), and later time behavior such as progressive sharpening and edge of stability. We demonstrate that a simple $2$-layer linear network (UV model) trained on a single training example exhibits all of the essential sharpness phenomenology observed in real-world scenarios. By analyzing the structure of dynamical fixed points in function space and the vector field of function updates, we uncover the underlying mechanisms behind these sharpness trends. Our analysis reveals (i) the mechanism behind early sharpness reduction and progressive sharpening, (ii) the required conditions for edge of stability, and (iii) a period-doubling route to chaos on the edge of stability manifold as learning rate is increased. Fi
    
[^2]: 基于子集选择的贝叶斯分位回归：后验总结视角

    Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective. (arXiv:2311.02043v1 [stat.ME])

    [http://arxiv.org/abs/2311.02043](http://arxiv.org/abs/2311.02043)

    本研究提出了一种基于贝叶斯决策分析的方法，对于任何贝叶斯回归模型，可以得到每个条件分位数的最佳和可解释的线性估计值和不确定性量化。该方法是一种适用于特定分位数子集选择的有效工具。

    

    分位回归是一种强大的工具，用于推断协变量如何影响响应分布的特定分位数。现有方法要么分别估计每个感兴趣分位数的条件分位数，要么使用半参数或非参数模型估计整个条件分布。前者经常产生不适合实际数据的模型，并且不在分位数之间共享信息，而后者则以复杂且受限制的模型为特点，难以解释和计算效率低下。此外，这两种方法都不适合于特定分位数的子集选择。相反，我们从贝叶斯决策分析的角度出发，提出了线性分位估计、不确定性量化和子集选择的基本问题。对于任何贝叶斯回归模型，我们为每个基于模型的条件分位数推导出最佳和可解释的线性估计值和不确定性量化。我们的方法引入了一种分位数聚焦的方法。

    Quantile regression is a powerful tool for inferring how covariates affect specific percentiles of the response distribution. Existing methods either estimate conditional quantiles separately for each quantile of interest or estimate the entire conditional distribution using semi- or non-parametric models. The former often produce inadequate models for real data and do not share information across quantiles, while the latter are characterized by complex and constrained models that can be difficult to interpret and computationally inefficient. Further, neither approach is well-suited for quantile-specific subset selection. Instead, we pose the fundamental problems of linear quantile estimation, uncertainty quantification, and subset selection from a Bayesian decision analysis perspective. For any Bayesian regression model, we derive optimal and interpretable linear estimates and uncertainty quantification for each model-based conditional quantile. Our approach introduces a quantile-focu
    
[^3]: 使用袋装后验进行可重现的参数推断

    Reproducible Parameter Inference Using Bagged Posteriors. (arXiv:2311.02019v1 [stat.ME])

    [http://arxiv.org/abs/2311.02019](http://arxiv.org/abs/2311.02019)

    通过使用袋装方法，提出了一种易于使用且广泛适用的方法来改善在模型错误规范下的可重现性。

    

    在模型错误规范下，已知贝叶斯后验通常不能正确量化关于真实或伪真参数的不确定性。更重要的是，错误规范会导致在独立数据集上同一模型产生相互矛盾的后验结果，从而缺乏可重现性。为了定义在错误规范下可重现不确定性量化的标准，我们考虑从独立数据集构建的两个置信区间具有非空交集的概率，并为任何有效置信区间建立了该交集概率的下界。我们证明了标准后验的可信区间在高维设置下（即样本大小增加时的维度）可以严重违反这个下界，表明在错误规范下它不是内部一致的。为了提高易于使用且广泛适用的可重现性，我们建议应用袋装方法。

    Under model misspecification, it is known that Bayesian posteriors often do not properly quantify uncertainty about true or pseudo-true parameters. Even more fundamentally, misspecification leads to a lack of reproducibility in the sense that the same model will yield contradictory posteriors on independent data sets from the true distribution. To define a criterion for reproducible uncertainty quantification under misspecification, we consider the probability that two confidence sets constructed from independent data sets have nonempty overlap, and we establish a lower bound on this overlap probability that holds for any valid confidence sets. We prove that credible sets from the standard posterior can strongly violate this bound, particularly in high-dimensional settings (i.e., with dimension increasing with sample size), indicating that it is not internally coherent under misspecification. To improve reproducibility in an easy-to-use and widely applicable way, we propose to apply ba
    
[^4]: Adam算法在无界梯度和仿射方差噪声下的高概率收敛性研究

    High Probability Convergence of Adam Under Unbounded Gradients and Affine Variance Noise. (arXiv:2311.02000v1 [math.OC])

    [http://arxiv.org/abs/2311.02000](http://arxiv.org/abs/2311.02000)

    Adam算法在非凸平滑随机优化中，经过深入分析，证明了在坐标-wise“仿射”方差噪声下，Adam可以以高概率收敛到稳定点，无需任何有界梯度假设和问题相关的知识。

    

    本文研究了在非凸平滑随机优化中，自适应矩法（Adam）算法的收敛性。尽管在机器学习领域被广泛使用，但其理论性质仍然有限。之前的研究主要从期望角度考虑了Adam的收敛性，常常需要强假设，比如均匀随机有界梯度或者先验的问题相关知识。因此，这些结果在实际的现实场景中的适用性受到了限制。为了克服这些局限，我们进行了深入分析，并证明了在坐标-wise“仿射”方差噪声下，Adam可以以高概率收敛到稳定点，其收敛速率为$\mathcal{O}\left({\rm poly}(\log T)/\sqrt{T}\right)$，不需要任何有界梯度假设和任何问题相关的知识来调整超参数。此外，我们还发现Adam限制了其梯度的...

    In this paper, we study the convergence of the Adaptive Moment Estimation (Adam) algorithm under unconstrained non-convex smooth stochastic optimizations. Despite the widespread usage in machine learning areas, its theoretical properties remain limited. Prior researches primarily investigated Adam's convergence from an expectation view, often necessitating strong assumptions like uniformly stochastic bounded gradients or problem-dependent knowledge in prior. As a result, the applicability of these findings in practical real-world scenarios has been constrained. To overcome these limitations, we provide a deep analysis and show that Adam could converge to the stationary point in high probability with a rate of $\mathcal{O}\left({\rm poly}(\log T)/\sqrt{T}\right)$ under coordinate-wise "affine" variance noise, not requiring any bounded gradient assumption and any problem-dependent knowledge in prior to tune hyper-parameters. Additionally, it is revealed that Adam confines its gradients' 
    
[^5]: 利用分布鲁棒优化获取可解释的分类模型

    Obtaining Explainable Classification Models using Distributionally Robust Optimization. (arXiv:2311.01994v1 [stat.ML])

    [http://arxiv.org/abs/2311.01994](http://arxiv.org/abs/2311.01994)

    本论文介绍了一种利用分布鲁棒优化获取可解释的分类模型的方法，通过构建稀疏的规则集合来同时解决规则集的稀疏性和预测准确性之间的权衡，从而保证泛化性能并降低计算成本。

    

    对于人类用户来说，模型的可解释性对于理解提议分类器如何根据特征值给数据分配标签至关重要。我们研究使用特征值规则集构建的广义线性模型，该模型可以捕捉非线性依赖和交互作用。规则集的稀疏性和预测准确性之间存在固有的权衡。使用现有方法来找到合适的稀疏度选择（例如通过交叉验证）计算成本很高。我们提出了一种新的公式来学习同时解决这些竞争因素的规则集合。通过利用分布鲁棒优化来确保良好的泛化性能，同时保持低计算成本。该公式利用列生成有效地搜索规则集合的空间并构建稀疏的规则集合，与随机森林或Boosting及其变体等技术相比。我们提出了理论结果来推动这一公式的发展。

    Model explainability is crucial for human users to be able to interpret how a proposed classifier assigns labels to data based on its feature values. We study generalized linear models constructed using sets of feature value rules, which can capture nonlinear dependencies and interactions. An inherent trade-off exists between rule set sparsity and its prediction accuracy. It is computationally expensive to find the right choice of sparsity -- e.g., via cross-validation -- with existing methods. We propose a new formulation to learn an ensemble of rule sets that simultaneously addresses these competing factors. Good generalization is ensured while keeping computational costs low by utilizing distributionally robust optimization. The formulation utilizes column generation to efficiently search the space of rule sets and constructs a sparse ensemble of rule sets, in contrast with techniques like random forests or boosting and their variants. We present theoretical results that motivate an
    
[^6]: 条件储层相生成的潜在扩散模型

    Latent Diffusion Model for Conditional Reservoir Facies Generation. (arXiv:2311.01968v1 [physics.geo-ph])

    [http://arxiv.org/abs/2311.01968](http://arxiv.org/abs/2311.01968)

    本研究提出了一种专门用于条件下储层相生成的潜在扩散模型，通过充分保留条件数据，生成了高保真度的储层相。它在性能上明显优于基于GANs的替代方法。

    

    在油气领域的田地开发和储层管理中，基于有限测量数据创建准确且地质真实的储层相至关重要。传统的两点地质统计方法虽然基础，但往往难以捕捉复杂的地质模式。多点统计方法提供了更大的灵活性，但也面临着挑战。随着生成对抗网络（GANs）的兴起和它们在不同领域的成功，人们开始倾向于使用它们进行储层相生成。然而，计算机视觉领域的最新进展显示了扩散模型相较于GANs的卓越性能。受此启发，提出了一种新颖的潜在扩散模型，专门用于条件下的储层相生成。该模型产生了高保真度的储层相，严格保留了条件数据。它明显优于基于GANs的替代方法。

    Creating accurate and geologically realistic reservoir facies based on limited measurements is crucial for field development and reservoir management, especially in the oil and gas sector. Traditional two-point geostatistics, while foundational, often struggle to capture complex geological patterns. Multi-point statistics offers more flexibility, but comes with its own challenges. With the rise of Generative Adversarial Networks (GANs) and their success in various fields, there has been a shift towards using them for facies generation. However, recent advances in the computer vision domain have shown the superiority of diffusion models over GANs. Motivated by this, a novel Latent Diffusion Model is proposed, which is specifically designed for conditional generation of reservoir facies. The proposed model produces high-fidelity facies realizations that rigorously preserve conditioning data. It significantly outperforms a GAN-based alternative.
    
[^7]: 在线非参数似然比估计的皮尔逊散度函数最小化方法

    Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization. (arXiv:2311.01900v1 [stat.ML])

    [http://arxiv.org/abs/2311.01900](http://arxiv.org/abs/2311.01900)

    本研究提出了一种在线非参数似然比估计（OLRE）框架，适用于估计两个概率密度函数之间差异的问题。通过利用核方法和函数最小化技术，我们的方法能够高效地进行在线更新，同时具有对概率密度函数形式无知的优势。

    

    在统计学和机器学习中，使用可用数据量化两个概率密度函数p和q之间的差异是一个基本问题。解决这个问题的一种常见方法是似然比估计（LRE），我们的研究为在线非参数似然比估计（OLRE）引入了一个新的框架，适用于随时间观察到的i.i.d观测值（$x_t \sim p, x'_t \sim q$）。我们的方法的非参数性质具有对$p$和$q$的形式无知的优势。此外，我们利用核方法和函数最小化的最新进展，开发了一个可以进行高效在线更新的估计方法。我们提供了OLRE方法性能的理论保证，并在合成实验中进行了实证验证。

    Quantifying the difference between two probability density functions, $p$ and $q$, using available data, is a fundamental problem in Statistics and Machine Learning. A usual approach for addressing this problem is the likelihood-ratio estimation (LRE) between $p$ and $q$, which -- to our best knowledge -- has been investigated mainly for the offline case. This paper contributes by introducing a new framework for online non-parametric LRE (OLRE) for the setting where pairs of iid observations $(x_t \sim p, x'_t \sim q)$ are observed over time. The non-parametric nature of our approach has the advantage of being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the recent advances in Kernel Methods and functional minimization to develop an estimator that can be efficiently updated online. We provide theoretical guarantees for the performance of the OLRE method along with empirical validation in synthetic experiments.
    
[^8]: 使用基于熵的ELBO学习稀疏编码

    Learning Sparse Codes with Entropy-Based ELBOs. (arXiv:2311.01888v1 [stat.ML])

    [http://arxiv.org/abs/2311.01888](http://arxiv.org/abs/2311.01888)

    本论文提出了一种基于熵的学习目标，用于稀疏编码参数的学习，通过非平凡的后验逼近和解析的目标函数，实现了标准稀疏编码的学习，在数值实验中证明了其可行性。

    

    标准概率稀疏编码假设拉普拉斯先验、从潜在到可观测的线性映射以及高斯可观测分布。我们在这里导出了一个仅基于熵的学习目标，用于标准稀疏编码的参数。这个新的变分目标具有以下特点：（A）与MAP逼近不同，它使用了概率推理的非平凡后验逼近；（B）与以前的非平凡逼近不同，这个新的目标是完全解析的；（C）该目标允许一种新的原则性的退火形式。目标的导出首先通过证明标准ELBO目标收敛到熵的和，这与具有高斯先验的生成模型的最近类似结果相匹配。然后，我们证明了ELBO等于熵的条件具有解析解，从而得到了完全解析的目标。通过数值实验证明了学习逼真性的可行性。

    Standard probabilistic sparse coding assumes a Laplace prior, a linear mapping from latents to observables, and Gaussian observable distributions. We here derive a solely entropy-based learning objective for the parameters of standard sparse coding. The novel variational objective has the following features: (A) unlike MAP approximations, it uses non-trivial posterior approximations for probabilistic inference; (B) unlike for previous non-trivial approximations, the novel objective is fully analytical; and (C) the objective allows for a novel principled form of annealing. The objective is derived by first showing that the standard ELBO objective converges to a sum of entropies, which matches similar recent results for generative models with Gaussian priors. The conditions under which the ELBO becomes equal to entropies are then shown to have analytical solutions, which leads to the fully analytical objective. Numerical experiments are used to demonstrate the feasibility of learning wit
    
[^9]: 利用属性的最小二乘问题的速写算法和锐利保证的凸和非凸正则化。 （arXiv：2311.01806v1 [math.OC]）

    Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees. (arXiv:2311.01806v1 [math.OC])

    [http://arxiv.org/abs/2311.01806](http://arxiv.org/abs/2311.01806)

    本文提出了一种用于解决较大规模优化问题的快速速写算法，适用于凸或非凸正则化函数的最小二乘问题。相比已有的随机算法，该算法处理通用的Frechet子微分正则化函数并提供了一般的近似误差理论。同时，通过解决速写的稀疏凸或非凸学习问题，我们还得到了稀疏信号估计的极小极大速率。

    

    随机算法对于解决大规模优化问题非常重要。在本文中，我们提出了一种快速速写算法，用于通过凸或非凸正则化函数正则化的最小二乘问题，即速写正则化优化（SRO）。我们的SRO算法首先生成原始数据矩阵的速写，然后解决速写问题。与现有的随机算法不同，我们的算法在一个统一的框架中处理通用的Frechet子微分正则化函数。我们为凸或非凸正则化的最小二乘问题的原始问题的优化结果和速写问题之间的近似误差提供了一般的理论结果。对于任意的凸正则化器，证明了相对误差界限的近似误差。重要的是，使用我们的一般极小极大速写稀疏凸或非凸学习问题的解决方案的稀疏信号估计的极小化速率也得到了。

    Randomized algorithms are important for solving large-scale optimization problems. In this paper, we propose a fast sketching algorithm for least square problems regularized by convex or nonconvex regularization functions, Sketching for Regularized Optimization (SRO). Our SRO algorithm first generates a sketch of the original data matrix, then solves the sketched problem. Different from existing randomized algorithms, our algorithm handles general Frechet subdifferentiable regularization functions in an unified framework. We present general theoretical result for the approximation error between the optimization results of the original problem and the sketched problem for regularized least square problems which can be convex or nonconvex. For arbitrary convex regularizer, relative-error bound is proved for the approximation error. Importantly, minimax rates for sparse signal estimation by solving the sketched sparse convex or nonconvex learning problems are also obtained using our gener
    
[^10]: 关于扩散模型的泛化属性

    On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])

    [http://arxiv.org/abs/2311.01797](http://arxiv.org/abs/2311.01797)

    本文对扩散模型的泛化属性进行了理论研究，建立了基于评分法的扩散模型的训练动态中泛化差距的理论估计，并在停止训练时可以避免维度诅咒。进一步将定量分析扩展到了数据依赖的情景。

    

    扩散模型是一类生成模型，用于建立一个随机传输映射，将经验观测到的但未知的目标分布与已知的先验分布联系起来。尽管在实际应用中取得了显著的成功，但对其泛化能力的理论理解仍未充分发展。本文对扩散模型的泛化属性进行了全面的理论研究。我们建立了基于评分法的扩散模型的训练动态中泛化差距的理论估计，表明在样本大小$n$和模型容量$m$上都存在多项式小的泛化误差($O(n^{-2/5}+m^{-4/5})$)，在停止训练时可以避免维度诅咒（即数据维度不呈指数级增长）。此外，我们将定量分析扩展到了一个数据依赖的情景，其中目标分布被描绘为一系列的概率密度函数。

    Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, evading the curse of dimensionality (i.e., not exponentially large in the data dimension) when early-stopped. Furthermore, we extend our quantitative analysis to a data-dependent scenario, wherein target distributions are portrayed as a succession of densities with progr
    
[^11]: 高效的广义低秩张量情境赌博算法

    Efficient Generalized Low-Rank Tensor Contextual Bandits. (arXiv:2311.01771v1 [cs.LG])

    [http://arxiv.org/abs/2311.01771](http://arxiv.org/abs/2311.01771)

    本文提出了一种新颖的广义低秩张量情境赌博算法，并引入了G-LowTESTR算法来实现探索和利用之间的权衡。

    

    本文旨在构建一种新颖的赌博算法，能够充分利用多维数据和奖励函数的固有非线性特性，提供高可用和负责任的决策服务。为此，我们引入了一种广义低秩张量情境赌博模型，其中一个动作由三个特征向量组成，因此可以用张量表示。在这个模型中，奖励是通过将动作的特征张量与一个固定但未知的参数张量的内积应用于广义线性函数来确定的，而这个参数张量具有较低的管状秩。为了实现探索和利用之间的权衡，我们引入了一种名为“广义低秩张量探索子空间然后细化”的新算法（G-LowTESTR）。该算法首先收集原始数据，以探索嵌入在决策情境中的本质低秩张量子空间信息，然后将原始概率转换为可解释的结构化概率。

    In this paper, we aim to build a novel bandits algorithm that is capable of fully harnessing the power of multi-dimensional data and the inherent non-linearity of reward functions to provide high-usable and accountable decision-making services. To this end, we introduce a generalized low-rank tensor contextual bandits model in which an action is formed from three feature vectors, and thus can be represented by a tensor. In this formulation, the reward is determined through a generalized linear function applied to the inner product of the action's feature tensor and a fixed but unknown parameter tensor with a low tubal rank. To effectively achieve the trade-off between exploration and exploitation, we introduce a novel algorithm called "Generalized Low-Rank Tensor Exploration Subspace then Refine" (G-LowTESTR). This algorithm first collects raw data to explore the intrinsic low-rank tensor subspace information embedded in the decision-making scenario, and then converts the original prob
    
[^12]: 使用梯度下降法解决非常数核的核岭回归

    Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])

    [http://arxiv.org/abs/2311.01762](http://arxiv.org/abs/2311.01762)

    本文研究了使用梯度下降法解决非常数核的核岭回归。通过在训练过程中逐渐减小带宽，避免了超参数选择的需求，并提出了一种带宽更新方案，证明了其优于使用常数带宽的方法。

    

    核岭回归（KRR）是线性岭回归的推广，它在数据中是非线性的，但在参数中是线性的。解决方案可以通过闭式解获得，其中包括矩阵求逆，也可以通过梯度下降迭代获得。本文研究了在训练过程中改变核函数的方法。我们从理论上探讨了这对模型复杂性和泛化性能的影响。基于我们的发现，我们提出了一种用于平移不变核的带宽更新方案，其中带宽在训练过程中逐渐减小至零，从而避免了超参数选择的需要。我们在真实和合成数据上展示了在训练过程中逐渐减小带宽的优于使用常数带宽，通过交叉验证和边缘似然最大化选择的带宽。我们还从理论和实证上证明了使用逐渐减小的带宽时，我们能够...

    Kernel ridge regression, KRR, is a generalization of linear ridge regression that is non-linear in the data, but linear in the parameters. The solution can be obtained either as a closed-form solution, which includes a matrix inversion, or iteratively through gradient descent. Using the iterative approach opens up for changing the kernel during training, something that is investigated in this paper. We theoretically address the effects this has on model complexity and generalization. Based on our findings, we propose an update scheme for the bandwidth of translational-invariant kernels, where we let the bandwidth decrease to zero during training, thus circumventing the need for hyper-parameter selection. We demonstrate on real and synthetic data how decreasing the bandwidth during training outperforms using a constant bandwidth, selected by cross-validation and marginal likelihood maximization. We also show theoretically and empirically that using a decreasing bandwidth, we are able to
    
[^13]: 基于机器学习的协变量表示的因果推断

    Causal inference with Machine Learning-Based Covariate Representation. (arXiv:2311.01709v1 [stat.ME])

    [http://arxiv.org/abs/2311.01709](http://arxiv.org/abs/2311.01709)

    本文提出了一种基于机器学习的协变量表示方法，可以在大维度协变量的情况下进行可靠的因果推断，并通过数值实验验证了其效果。

    

    利用协变量信息是提高因果推断效率和准确性的强有力方法，可支持在数据驱动企业上运行的大量随机实验。然而，在协变量维度增加到50时，最先进的方法在实际应用中可能变得不可靠，而大型平台上的实验可能观察到更高维度的协变量。我们提出了一种机器学习辅助的协变量表示方法，可以有效利用在同一平台上运行的历史实验或观测数据，了解哪些低维度可以有效地表示高维协变量。然后，我们提出了设计和估计方法来处理协变量表示。我们为所提出的方法提供了统计可靠性和性能保证。数值实验验证了其实证性能。

    Utilizing covariate information has been a powerful approach to improve the efficiency and accuracy for causal inference, which support massive amount of randomized experiments run on data-driven enterprises. However, state-of-art approaches can become practically unreliable when the dimension of covariate increases to just 50, whereas experiments on large platforms can observe even higher dimension of covariate. We propose a machine-learning-assisted covariate representation approach that can effectively make use of historical experiment or observational data that are run on the same platform to understand which lower dimensions can effectively represent the higher-dimensional covariate. We then propose design and estimation methods with the covariate representation. We prove statistically reliability and performance guarantees for the proposed methods. The empirical performance is demonstrated using numerical experiments.
    
[^14]: 引入重要抽样的柔性生存密度的最大似然估计

    Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling. (arXiv:2311.01660v1 [cs.LG])

    [http://arxiv.org/abs/2311.01660](http://arxiv.org/abs/2311.01660)

    该论文提出了一种生存分析方法，通过引入重要抽样，消除了调整超参数的需求，如混合分配和箱尺寸，减轻了从业人员的负担。

    

    生存分析是一种广泛应用于分析具有截尾的时间至事件数据的技术。最近几年，出现了许多能够适用于大数据集并放松传统假设（如比例风险）的生存分析方法。尽管这些模型表现出色，但对于模型的超参数（如离散模型的箱数和箱尺寸，以及基于混合模型的簇分配数）需要大量调整以实现最佳性能。此外，我们通过实证研究证明了以下事实：（1）最佳箱尺寸可能会因所关注的指标（如一致性和布里尔分数）而大为不同，以及（2）混合模型可能会遭受模式坍塌和数值不稳定的问题。我们提出了一种生存分析方法，消除了调整混合分配和箱尺寸等超参数的需求，从而减轻了从业人员的负担。

    Survival analysis is a widely-used technique for analyzing time-to-event data in the presence of censoring. In recent years, numerous survival analysis methods have emerged which scale to large datasets and relax traditional assumptions such as proportional hazards. These models, while being performant, are very sensitive to model hyperparameters including: (1) number of bins and bin size for discrete models and (2) number of cluster assignments for mixture-based models. Each of these choices requires extensive tuning by practitioners to achieve optimal performance. In addition, we demonstrate in empirical studies that: (1) optimal bin size may drastically differ based on the metric of interest (e.g., concordance vs brier score), and (2) mixture models may suffer from mode collapse and numerical instability. We propose a survival analysis approach which eliminates the need to tune hyperparameters such as mixture assignments and bin sizes, reducing the burden on practitioners. We show t
    
[^15]: 学生网络是否应该复制或平均教师权重？

    Should Under-parameterized Student Networks Copy or Average Teacher Weights?. (arXiv:2311.01644v1 [cs.LG])

    [http://arxiv.org/abs/2311.01644](http://arxiv.org/abs/2311.01644)

    这项研究探讨了在欠参数化情况下，学生网络是否应该复制教师神经元或平均一组教师神经元的权重。研究发现对于特定的网络结构和输入分布，当教师网络的输入向量正交且输出权重为酉时，复制-平均配置将达到优化结果，其中大部分学生神经元复制一个教师神经元，最后一个学生神经元对所有教师神经元取平均值。

    

    任何连续函数 $f^*$ 都可以用足够多的神经元 $k$来近似。我们考虑 $f^*$ 本身是一个具有一个隐藏层和 $k$ 个神经元的神经网络的情况。用具有 $n<k$ 个神经元的神经网络来逼近 $f^*$ 可以看作是将一个欠参数化的“学生”网络与 $k$ 个神经元的“教师”网络进行拟合。由于学生具有较少的神经元，所以不清楚每个 $n$ 个学生神经元应该复制一个教师神经元还是平均一组教师神经元。对于具有 erf 激活函数和标准高斯输入分布的浅层神经网络，我们证明了当教师的输入向量是正交的并且输出权重是酉的时候，“复制-平均”配置是临界点。此外，在这样的配置中，优化结果是当 $n-1$ 个学生神经元分别复制一个教师神经元，并且第 $n$ 个学生神经元是所有教师神经元的平均。

    Any continuous function $f^*$ can be approximated arbitrarily well by a neural network with sufficiently many neurons $k$. We consider the case when $f^*$ itself is a neural network with one hidden layer and $k$ neurons. Approximating $f^*$ with a neural network with $n< k$ neurons can thus be seen as fitting an under-parameterized "student" network with $n$ neurons to a "teacher" network with $k$ neurons. As the student has fewer neurons than the teacher, it is unclear, whether each of the $n$ student neurons should copy one of the teacher neurons or rather average a group of teacher neurons. For shallow neural networks with erf activation function and for the standard Gaussian input distribution, we prove that "copy-average" configurations are critical points if the teacher's incoming vectors are orthonormal and its outgoing weights are unitary. Moreover, the optimum among such configurations is reached when $n-1$ student neurons each copy one teacher neuron and the $n$-th student ne
    
[^16]: 对于文本预测的忠实和稳健的本地可解释性

    Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])

    [http://arxiv.org/abs/2311.01605](http://arxiv.org/abs/2311.01605)

    提出了一种名为FRED的新颖方法，用于解释文本预测。FRED可以识别文档中的关键词，并且通过与最先进的方法进行的实证评估证明了其在提供对文本模型的深入见解方面的有效性。

    

    可解释性对于机器学习模型在关键领域中得到信任和部署是至关重要的。然而，现有的用于解释文本模型的方法通常复杂，并且缺乏坚实的数学基础，它们的性能也不能保证。在本文中，我们提出了一种新颖的方法FRED（Faithful and Robust Explainer for textual Documents），用于解释文本预测。FRED可以识别文档中的关键词，当这些词被移除时对预测结果产生重大影响。我们通过正式的定义和对可解释分类器的理论分析，确立了FRED的可靠性。此外，我们还通过与最先进的方法进行的实证评估，证明了FRED在提供对文本模型的深入见解方面的有效性。

    Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack solid mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED identifies key words in a document that significantly impact the prediction when removed. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models.
    
[^17]: 不完善模型的本地贝叶斯狄利克雷混合方法

    Local Bayesian Dirichlet mixing of imperfect models. (arXiv:2311.01596v1 [stat.ME])

    [http://arxiv.org/abs/2311.01596](http://arxiv.org/abs/2311.01596)

    本文介绍了一种利用狄利克雷分布结合多个不完善模型结果的贝叶斯机器学习框架，该框架在提高复杂计算模型的可预测性方面表现出色，尤其在核质量挖掘中取得了很好的性能。

    

    为了提高在未知领域中复杂计算模型的可预测性，我们提出了一种利用狄利克雷分布结合多个不完善模型结果的贝叶斯统计机器学习框架。这个框架可以看作是贝叶斯堆叠的扩展。为了说明这个方法，我们研究了贝叶斯模型平均和混合技术在挖掘核质量方面的能力。我们展示了全局和局部模型混合在预测精度和不确定性量化方面都达到了非常好的表现，并且比传统的贝叶斯模型平均更可取。此外，我们的统计分析表明，通过混合而不是纠正模型的混合来改善模型预测可以获得更稳健的外推结果。

    To improve the predictability of complex computational models in the experimentally-unknown domains, we propose a Bayesian statistical machine learning framework utilizing the Dirichlet distribution that combines results of several imperfect models. This framework can be viewed as an extension of Bayesian stacking. To illustrate the method, we study the ability of Bayesian model averaging and mixing techniques to mine nuclear masses. We show that the global and local mixtures of models reach excellent performance on both prediction accuracy and uncertainty quantification and are preferable to classical Bayesian model averaging. Additionally, our statistical analysis indicates that improving model predictions through mixing rather than mixing of corrected models leads to more robust extrapolations.
    
[^18]: 在可解释的分布比较中的最大平均差异中的变量选择

    Variable Selection in Maximum Mean Discrepancy for Interpretable Distribution Comparison. (arXiv:2311.01537v1 [stat.ML])

    [http://arxiv.org/abs/2311.01537](http://arxiv.org/abs/2311.01537)

    本文研究了数据集比较中的变量选择问题，提出了一种基于最大平均差异的两样本测试方法，通过优化自动相关性检测权重来增强测试的功效，并引入稀疏正则化方法来解决正则化参数选择的问题。

    

    两样本测试是为了判断两个数据集是否来自同一分布。本文研究了两样本测试中的变量选择问题，即识别造成两个分布差异的变量（或维度）的任务。这个任务与模式分析和机器学习的许多问题相关，如数据集漂移适应、因果推断和模型验证。我们的方法基于基于最大平均差异（MMD）的两样本检验。我们优化针对各个变量定义的自动相关性检测（ARD）权重，以最大化基于MMD的检验的功率。对于这种优化，我们引入了稀疏正则化，并提出了两种方法来解决选择适当正则化参数的问题。一种方法是以数据驱动的方式确定正则化参数，另一种方法是合并不同正则化参数的结果。我们确认了这个方法的有效性。

    Two-sample testing decides whether two datasets are generated from the same distribution. This paper studies variable selection for two-sample testing, the task being to identify the variables (or dimensions) responsible for the discrepancies between the two distributions. This task is relevant to many problems of pattern analysis and machine learning, such as dataset shift adaptation, causal inference and model validation. Our approach is based on a two-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the Automatic Relevance Detection (ARD) weights defined for individual variables to maximise the power of the MMD-based test. For this optimisation, we introduce sparse regularisation and propose two methods for dealing with the issue of selecting an appropriate regularisation parameter. One method determines the regularisation parameter in a data-driven way, and the other aggregates the results of different regularisation parameters. We confirm the validity of the pr
    
[^19]: 通用的不变因果模仿学习的研究

    Invariant Causal Imitation Learning for Generalizable Policies. (arXiv:2311.01489v1 [stat.ML])

    [http://arxiv.org/abs/2311.01489](http://arxiv.org/abs/2311.01489)

    本文提出了不变因果模仿学习（ICIL）的新技术，通过学习一个跨领域不变的特征表示，实现在未知环境中进行模仿策略，并解决转换动态不匹配的问题。

    

    本文考虑基于多个环境中的示范行为学习模仿策略，并且希望能够在未知环境中进行应用。由于每个环境的可观察特征可能不同，直接学习将特征映射到动作的个别策略容易产生错误的相关性，并且可能无法很好地进行泛化。然而，专家策略通常是基于一个在不同环境中都不变的共享潜在结构的函数。通过利用来自多个环境的数据，我们提出了不变因果模仿学习（ICIL）的新技术，在该技术中我们学习一个跨领域不变的特征表示，然后基于此学习与专家行为相匹配的模仿策略。为了解决转换动态不匹配的问题，ICIL学习了一个关于训练环境中的因果特征的共享表示，该表示与噪声变量的特定表示相分离。

    Consider learning an imitation policy on the basis of demonstrated behavior from multiple environments, with an eye towards deployment in an unseen environment. Since the observable features from each setting may be different, directly learning individual policies as mappings from features to actions is prone to spurious correlations -- and may not generalize well. However, the expert's policy is often a function of a shared latent structure underlying those observable features that is invariant across settings. By leveraging data from multiple environments, we propose Invariant Causal Imitation Learning (ICIL), a novel technique in which we learn a feature representation that is invariant across domains, on the basis of which we learn an imitation policy that matches expert behavior. To cope with transition dynamics mismatch, ICIL learns a shared representation of causal features (for all training environments), that is disentangled from the specific representations of noise variables
    
[^20]: 在随机学习理论中应用聚合马尔可夫过程的研究

    Applications of the Theory of Aggregated Markov Processes in Stochastic Learning Theory. (arXiv:2311.01476v1 [stat.ML])

    [http://arxiv.org/abs/2311.01476](http://arxiv.org/abs/2311.01476)

    本文描述了聚合马尔可夫过程（AMP）的理论如何应用于随机学习理论中，以降低维度并实现学习特定任务的目标。

    

    通过将函数与马尔可夫过程组合得到的随机过程被称为聚合马尔可夫过程（AMP）。将马尔可夫过程与函数组合的目的可以是降低维度，例如在特定坐标上进行投影。AMP的理论已经被Dynkin、Cameron、Rogers和Pitman以及Kelly等人广泛研究，他们提供了AMP保持马尔可夫性的充分条件。在另一个方向上，Larget提供了AMP的规范表示，可以用于验证两个AMP的等价性。本文旨在描述如何将AMP的理论应用于随机学习理论中，以实现他们在学习特定任务时的目标。

    A stochastic process that arises by composing a function with a Markov process is called an aggregated Markov process (AMP). The purpose of composing a Markov process with a function can be a reduction of dimensions, e.g., a projection onto certain coordinates. The theory around AMP has been extensively studied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom provided sufficient conditions for an AMP to remain Markov. In another direction, Larget provided a canonical representation for AMP, which can be used to verify the equivalence of two AMPs. The purpose of this paper is to describe how the theory of AMP can be applied to stochastic learning theory as they learn a particular task.
    
[^21]: Bayes战胜交叉验证：通过期望最大化实现高效准确的岭回归

    Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization. (arXiv:2310.18860v1 [stat.ML])

    [http://arxiv.org/abs/2310.18860](http://arxiv.org/abs/2310.18860)

    本文提出了一种基于贝叶斯公式的岭回归方法，通过期望最大化来调节正则化超参数，该方法不需要指定候选的λ并且在大样本下可以找到唯一的最优解。

    

    我们提出了一种新的方法来调节岭回归的正则化超参数λ，该方法的计算速度比留一交叉验证(LOOCV)快，同时在稀疏协变量的情况下可以获得与LOOCV相等或更好的回归参数估计。对于有限的n，LOOCV风险可能受到多个和不好的局部最小值的影响，因此需要指定一组候选的λ，这可能无法提供良好的解决方案。相反，我们证明了所提出的方法在足够大的n下可以找到唯一的最优解，并且不需要指定任何难以确定的超参数。这是基于岭回归的贝叶斯公式，我们证明了对于足够大的n，后验是单峰的，可以同时学习最优的λ和回归系数。

    We present a novel method for tuning the regularization hyper-parameter, $\lambda$, of a ridge regression that is faster to compute than leave-one-out cross-validation (LOOCV) while yielding estimates of the regression parameters of equal, or particularly in the setting of sparse covariates, superior quality to those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from multiple and bad local minima for finite $n$ and thus requires the specification of a set of candidate $\lambda$, which can fail to provide good solutions. In contrast, we show that the proposed method is guaranteed to find a unique optimal solution for large enough $n$, under relatively mild conditions, without requiring the specification of any difficult to determine hyper-parameters. This is based on a Bayesian formulation of ridge regression that we prove to have a unimodal posterior for large enough $n$, allowing for both the optimal $\lambda$ and the regression coefficients to be jointly learned wi
    
[^22]: Causal Q-Aggregation for CATE Model Selection（CATE模型选择中的因果Q集成）

    Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])

    [http://arxiv.org/abs/2310.16945](http://arxiv.org/abs/2310.16945)

    该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率

    

    准确估计条件平均处理效应（CATE）是个性化决策的核心。尽管有大量用于CATE估计的模型，但由于因果推断的基本问题，模型选择是一项非常棘手的任务。最近的实证工作提供了有利于具有双重鲁棒性质的代理损失度量和模型集成的证据。然而，对于这些模型的理论理解还不够。直接应用先前的理论工作会由于模型选择问题的非凸性而导致次优的预测模型选择率。我们提供了现有主要CATE集成方法的遗憾率，并提出了一种基于双重鲁棒损失的Q集成的新的CATE模型集成方法。我们的主要结果表明，因果Q集成在预测模型选择的遗憾率上达到了统计上的最优值为$\frac{\log(M)}{n}$（其中$M$为模型数，$n$为样本数），加上高阶估计误差项

    Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
    
[^23]: 学生如何成为教师：通过谱方法学习和遗忘

    How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v1 [cs.LG])

    [http://arxiv.org/abs/2310.12612](http://arxiv.org/abs/2310.12612)

    本论文提出了基于谱方法的优化方案，用于解决在非凸性问题下学生网络与教师网络之间存在的不变子网络的识别问题。

    

    在理论机器学习中，学生-教师模型常被用作现实生活中教学的有效隐喻。当学生网络相对于教师网络过度参数化时，上述模型尤为相关。在这种操作条件下，很容易推测学生处理给定任务的能力最终可能储存在整个网络的一个子部分中。根据适当的指标，这个子部分应该在一定程度上类似于冻结的教师结构，并且在学生候选网络的不同架构下近似不变。然而，由于所研究问题的固有非凸性程度，最新的传统学习技术无法识别这样一个不变子网络的存在。在这项工作中，我们采取了一个根本不同的优化方案，该方案建立在谱表示的基础上。

    In theoretical ML, the teacher-student paradigm is often employed as an effective metaphor for real-life tuition. The above scheme proves particularly relevant when the student network is overparameterized as compared to the teacher network. Under these operating conditions, it is tempting to speculate that the student ability to handle the given task could be eventually stored in a sub-portion of the whole network. This latter should be to some extent reminiscent of the frozen teacher structure, according to suitable metrics, while being approximately invariant across different architectures of the student candidate network. Unfortunately, state-of-the-art conventional learning techniques could not help in identifying the existence of such an invariant subnetwork, due to the inherent degree of non-convexity that characterizes the examined problem. In this work, we take a leap forward by proposing a radically different optimization scheme which builds on a spectral representation of th
    
[^24]: 可证收敛的数据驱动凸非凸正则化

    Provably Convergent Data-Driven Convex-Nonconvex Regularization. (arXiv:2310.05812v1 [cs.LG])

    [http://arxiv.org/abs/2310.05812](http://arxiv.org/abs/2310.05812)

    本研究展示了在凸非凸框架中，通过从数据中学习正则化器，可以实现收敛正则化；引入了一种新颖的弱凸输入神经网络构建，解决了之前对抗性方法的数值问题。

    

    通过使用深度学习从数据中学习正则化器是解决逆问题的新兴范式。这导致了高质量的结果，但往往无法提供可证明的保证。在这项工作中，我们展示了在凸非凸（CNC）框架中出现了良定义性和收敛性正则化的原因。我们引入了一种新颖的弱凸输入神经网络（IWCNN）构建，将学习对抗性正则化方法适应到CNC框架中。从实验证明，我们的方法克服了之前对抗性方法的数值问题。

    An emerging new paradigm for solving inverse problems is via the use of deep learning to learn a regularizer from data. This leads to high-quality results, but often at the cost of provable guarantees. In this work, we show how well-posedness and convergent regularization arises within the convex-nonconvex (CNC) framework for inverse problems. We introduce a novel input weakly convex neural network (IWCNN) construction to adapt the method of learned adversarial regularization to the CNC framework. Empirically we show that our method overcomes numerical issues of previous adversarial methods.
    
[^25]: 数据驱动天气预报模型的局限性研究

    On the limitations of data-driven weather forecasting models. (arXiv:2309.08473v1 [stat.ML])

    [http://arxiv.org/abs/2309.08473](http://arxiv.org/abs/2309.08473)

    数据驱动的机器学习天气预报模型不具备传统基于物理的模型的准确性和物理一致性，它们在预测技能上的优势很大程度上可以归因于这些特殊性。

    

    机器学习在天气和气候预测领域产生了深远影响。最近的发展是数据驱动的机器学习预测模型的出现，它们通常声称比传统的基于物理的模型具有更高的性能。在这项工作中，我们研究了当前一代机器学习模型之一Pangu-Weather的预测方面的一些问题，重点关注预测的准确性和物理一致性以及这些特征与感知预测性能之间的关系。主要结论是Pangu-Weather的预测，以及类似的机器学习模型，不具备基于物理的模型的准确性和物理一致性，而它们在传统的确定性预测技能指标上的优势很大程度上可以归因于这些特殊性。与其他当前的后处理技术类似。

    As in many other areas of engineering and applied science, Machine Learning (ML) is having a profound impact in the domain of Weather and Climate Prediction. A very recent development in this area has been the emergence of fully data-driven ML prediction models which routinely claim superior performance to that of traditional physics-based models. In this work, we examine some aspects of the forecasts produced by an exemplar of the current generation of ML models, Pangu-Weather, with a focus on the fidelity and physical consistency of those forecasts and how these characteristics relate to perceived forecast performance. The main conclusion is that Pangu-Weather forecasts, and by extension those of similar ML models, do not have the fidelity and physical consistency of physics-based models and their advantage in accuracy on traditional deterministic metrics of forecast skill can be attributed, to a large extent, to these peculiarities. Similarly to other current post-processing technol
    
[^26]: 比例响应：用于简单和累积遗憾最小化的情境赌博算法

    Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v1 [cs.LG])

    [http://arxiv.org/abs/2307.02108](http://arxiv.org/abs/2307.02108)

    这篇论文提出了一种适用于情境赌博设置的新型计算效率高的赌博算法，具有简单和累积遗憾最小化的优势，并可自适应模型错误规范和连续臂设置。该算法利用"一致臂集"（CAS）来提供在每个情境下囊括情境特定的最佳臂的一组臂，跨越情境分布。这篇论文对简单和累积遗憾保证的研究提供了正面结果，同时也揭示了无法实现实例依赖性的简单遗憾保证的消极结果。

    

    在医疗保健和电子商务等领域，简单遗憾最小化是学习最佳治疗分配策略的关键问题。然而，情境赌博设置中的简单遗憾最小化问题仍未充分研究。我们提出了一种新的计算效率高的赌博算法族，针对随机情境赌博设置，在累积遗憾最小化（具有近乎最优的极小极大保证）和简单遗憾最小化（具有SOTA保证）方面具有灵活性。此外，我们的算法对模型错误规范进行自适应，并扩展到连续臂设置。这些优势来自于构建和依赖于“一致臂集”（CAS），CAS在每个情境下提供一组臂，这些臂以一定的概率囊括了情境特定的最佳臂，跨越了情境分布。我们关于简单和累积遗憾保证的积极结果与一个消极结果形成对比，后者表明一个算法无法实现实例依赖性的简单遗憾保证。

    Simple regret minimization is a critical problem in learning optimal treatment assignment policies across various domains, including healthcare and e-commerce. However, it remains understudied in the contextual bandit setting. We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit settings, with the flexibility to be adapted for cumulative regret minimization (with near-optimal minimax guarantees) and simple regret minimization (with SOTA guarantees). Furthermore, our algorithms adapt to model misspecification and extend to the continuous arm settings. These advantages come from constructing and relying on "conformal arm sets" (CASs), which provide a set of arms at every context that encompass the context-specific optimal arm with some probability across the context distribution. Our positive results on simple and cumulative regret guarantees are contrasted by a negative result, which shows that an algorithm can't achieve instance-de
    
[^27]: 运输、变分推断和扩散：应用于回火流和薛定谔桥的论文研究

    Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges. (arXiv:2307.01050v1 [stat.ML])

    [http://arxiv.org/abs/2307.01050](http://arxiv.org/abs/2307.01050)

    本文研究了最优运输和变分推断之间的联系，并提出了一种基于路径空间散度的采样和生成建模框架。通过开发新颖的基于得分的回火流技术和正则化的迭代比例拟合目标，本文展示了这些方法的潜力。

    

    本文探讨了最优运输与变分推断之间的联系，重点研究了正向和反向随机微分方程以及Girsanov变换。我们提出了一个基于路径空间散度的采样和生成建模的原则性和系统性框架。我们的工作最终发展出一个新颖的基于得分的回火流技术（与统计物理中的Jarzynski和Crooks恒等式有关）和一个正则化的迭代比例拟合（IPF）型目标，不同于标准IPF的顺序性。通过一系列的生成建模示例和基于双井的稀有事件任务，我们展示了所提方法的潜力。

    This paper explores the connections between optimal transport and variational inference, with a focus on forward and reverse time stochastic differential equations and Girsanov transformations.We present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of a novel score-based annealed flow technique (with connections to Jarzynski and Crooks identities from statistical physics) and a regularised iterative proportional fitting (IPF)-type objective, departing from the sequential nature of standard IPF. Through a series of generative modelling examples and a double-well-based rare event task, we showcase the potential of the proposed methods.
    
[^28]: 宽松Pareto集识别的自适应算法

    Adaptive Algorithms for Relaxed Pareto Set Identification. (arXiv:2307.00424v1 [stat.ML])

    [http://arxiv.org/abs/2307.00424](http://arxiv.org/abs/2307.00424)

    本研究提出了一种自适应算法，用于宽松Pareto集的识别，通过放松策略来减少样本复杂度，并展示了在实际场景中的良好表现。

    

    本文重新审视了在多目标多臂赌博机模型中固定置信度下的Pareto最优集合的识别问题。由于准确识别Pareto集合的样本复杂度可能非常大，因此研究了允许输出一些额外近似最优臂的放松策略。在这项工作中，我们还解决了其他允许识别Pareto集合的相关子集的放松策略。值得注意的是，我们提出了一种称为自适应Pareto探索的单一抽样策略，可以与不同的停止规则结合使用，以考虑Pareto集合识别问题的不同放松策略。我们分析了这些不同组合的样本复杂度，并特别量化了在寻找识别最多$k$个Pareto最优臂时样本复杂度的减少。我们展示了自适应Pareto探索在一个真实场景中的良好实际性能，其中我们自适应地探索了几种疫苗接种策略。

    In this paper we revisit the fixed-confidence identification of the Pareto optimal set in a multi-objective multi-armed bandit model. As the sample complexity to identify the exact Pareto set can be very large, a relaxation allowing to output some additional near-optimal arms has been studied. In this work we also tackle alternative relaxations that allow instead to identify a relevant subset of the Pareto set. Notably, we propose a single sampling strategy, called Adaptive Pareto Exploration, that can be used in conjunction with different stopping rules to take into account different relaxations of the Pareto Set Identification problem. We analyze the sample complexity of these different combinations, quantifying in particular the reduction in sample complexity that occurs when one seeks to identify at most $k$ Pareto optimal arms. We showcase the good practical performance of Adaptive Pareto Exploration on a real-world scenario, in which we adaptively explore several vaccination stra
    
[^29]: 在具有未知和随机奖励的臂上分配可分资源

    Allocating Divisible Resources on Arms with Unknown and Random Rewards. (arXiv:2306.16578v1 [cs.LG])

    [http://arxiv.org/abs/2306.16578](http://arxiv.org/abs/2306.16578)

    本论文研究了在每个周期将一单位可分资源分配到多个臂上的问题，臂上的奖励是未知和随机的，而且与分配的资源成比例，而方差与分配资源的阶数成比例。我们设计了两种算法，实现了不同阶数下的最优有界和无界遗憾，结果表明在阶数为1/2时存在相变现象。

    

    我们考虑一个决策者在每个周期将一个可再生和可分资源分配到多个臂上。这些臂具有未知和随机的奖励，其均值与分配的资源成比例，方差与分配资源的阶数$b$成比例。特别地，如果决策者在一个周期将资源$A_i$分配给臂$i$，那么奖励$Y_i$是$Y_i(A_i)=A_i\mu_i+A_i^b\xi_i$，其中$\mu_i$是未知的均值，噪声$\xi_i$是独立且子高斯的。当阶数$b$从0到1变化时，该框架平滑地连接了标准的随机多臂赌博机和带有完全反馈的在线学习。我们设计了两种算法，它们实现了$b\in[0,1]$时的最优有界差和无界差的遗憾界，并展示了在$b=1/2$处的相变。理论结果依赖于我们开发的一种新型浓度不等式，它限制了子高斯随机变量的线性组合。

    We consider a decision maker allocating one unit of renewable and divisible resource in each period on a number of arms. The arms have unknown and random rewards whose means are proportional to the allocated resource and whose variances are proportional to an order $b$ of the allocated resource. In particular, if the decision maker allocates resource $A_i$ to arm $i$ in a period, then the reward $Y_i$ is$Y_i(A_i)=A_i \mu_i+A_i^b \xi_{i}$, where $\mu_i$ is the unknown mean and the noise $\xi_{i}$ is independent and sub-Gaussian. When the order $b$ ranges from 0 to 1, the framework smoothly bridges the standard stochastic multi-armed bandit and online learning with full feedback. We design two algorithms that attain the optimal gap-dependent and gap-independent regret bounds for $b\in [0,1]$, and demonstrate a phase transition at $b=1/2$. The theoretical results hinge on a novel concentration inequality we have developed that bounds a linear combination of sub-Gaussian random variables w
    
[^30]: 对数贝叶斯遗憾边界

    Logarithmic Bayes Regret Bounds. (arXiv:2306.09136v1 [cs.LG])

    [http://arxiv.org/abs/2306.09136](http://arxiv.org/abs/2306.09136)

    该论文提出了对于贝叶斯赌博机的首个有限时间对数遗憾边界，并用于高斯和线性赌博机，从而阐明了贝叶斯设置中先验价值以及对$\tilde{O}(\sqrt{n})$界限的改善。

    

    我们为贝叶斯赌博机导出了首个有限时间对数遗憾边界。对于高斯赌博机，我们获得了一个$O(c_h \log^2 n)$的边界，其中$c_h$是与先验相关的常量。这与Lai（1987）的渐近下限相匹配。我们的证明与先前的工作有所不同，且简单且普遍。为了显示一般性，我们将我们的技术应用于线性赌博机。我们的界限阐明了贝叶斯设置中先验的价值，既可以作为目标，也可以作为传递给学习者的附加信息。它们显着改善了现有的$\tilde{O}(\sqrt{n})$界限，尽管存在下限，但已成为文献中的标准。

    We derive the first finite-time logarithmic regret bounds for Bayesian bandits. For Gaussian bandits, we obtain a $O(c_h \log^2 n)$ bound, where $c_h$ is a prior-dependent constant. This matches the asymptotic lower bound of Lai (1987). Our proofs mark a technical departure from prior works, and are simple and general. To show generality, we apply our technique to linear bandits. Our bounds shed light on the value of the prior in the Bayesian setting, both in the objective and as a side information given to the learner. They significantly improve the $\tilde{O}(\sqrt{n})$ bounds, that despite the existing lower bounds, have become standard in the literature.
    
[^31]: 长序列 Hopfield内存

    Long Sequence Hopfield Memory. (arXiv:2306.04532v2 [cs.NE] CROSS LISTED)

    [http://arxiv.org/abs/2306.04532](http://arxiv.org/abs/2306.04532)

    这篇论文提出了一种增强Hopfield-like神经网络序列记忆模型的序列容量的方法，通过引入非线性相互作用项，显著优于传统Hopfield网络，同时也引入了一个新的回忆规则以回忆连续的序列。

    

    序列记忆是自然和人工智能的重要属性，它使代理能够编码、存储和检索复杂的刺激和行为序列。已经提出了计算模型，其中用时间非对称的Hebbian规则训练递归的Hopfield样神经网络。然而，这些网络由于记忆之间的干扰而具有有限的序列容量（存储序列的最大长度）。受密集关联记忆的最新工作的启发，我们通过引入非线性相互作用项来扩展这些模型的序列容量，增强模式之间的分离性。我们推导出序列容量与网络大小的新的标度定律，显著优于基于传统Hopfield网络的现有标度定律，并通过数值模拟验证了这些理论结果。此外，我们引入了一个广义伪逆规则来回忆高度连续的序列。

    Sequence memory is an essential attribute of natural and artificial intelligence that enables agents to encode, store, and retrieve complex sequences of stimuli and actions. Computational models of sequence memory have been proposed where recurrent Hopfield-like neural networks are trained with temporally asymmetric Hebbian rules. However, these networks suffer from limited sequence capacity (maximal length of the stored sequence) due to interference between the memories. Inspired by recent work on Dense Associative Memories, we expand the sequence capacity of these models by introducing a nonlinear interaction term, enhancing separation between the patterns. We derive novel scaling laws for sequence capacity with respect to network size, significantly outperforming existing scaling laws for models based on traditional Hopfield networks, and verify these theoretical results with numerical simulation. Moreover, we introduce a generalized pseudoinverse rule to recall sequences of highly 
    
[^32]: 学习具有未知干预的非参数潜在因果图。

    Learning nonparametric latent causal graphs with unknown interventions. (arXiv:2306.02899v1 [stat.ML])

    [http://arxiv.org/abs/2306.02899](http://arxiv.org/abs/2306.02899)

    本文提出了一种学习具有未知干预的非参数潜在因果图的方法，通过建立条件确定非参数潜在因果图并从中重构。这种方法不需要参数假设，可用于识别测量模型中潜在结构。

    

    我们在未知干预的潜在空间建立条件，以确定非参数潜在因果图并从中重构。我们的主要重点是测量模型中潜在结构的识别，即因果图模型，在其中观察变量之间的依赖性与潜在表示之间的依赖性相比，并不做出参数假设，如线性或高斯性。此外，我们不假设隐藏变量的数量已知，并且我们表明每个隐藏变量最多只需要一个未知的干预。这扩展了最近关于从观测和干预中学习因果表示的工作。证明是建设性的，并引入了两个新的图形概念——想象子集和孤立边——它们本身可能是有用的。作为一个独立的感兴趣的问题，证明还涉及对边缘定向限制的新的特征化。

    We establish conditions under which latent causal graphs are nonparametrically identifiable and can be reconstructed from unknown interventions in the latent space. Our primary focus is the identification of the latent structure in a measurement model, i.e. causal graphical models where dependence between observed variables is insignificant compared to dependence between latent representations, without making parametric assumptions such as linearity or Gaussianity. Moreover, we do not assume the number of hidden variables is known, and we show that at most one unknown intervention per hidden variable is needed. This extends a recent line of work on learning causal representations from observations and interventions. The proofs are constructive and introduce two new graphical concepts -- imaginary subsets and isolated edges -- that may be useful in their own right. As a matter of independent interest, the proofs also involve a novel characterization of the limits of edge orientations wi
    
[^33]: 广义平滑度下的凸和非凸优化

    Convex and Non-Convex Optimization under Generalized Smoothness. (arXiv:2306.01264v1 [math.OC])

    [http://arxiv.org/abs/2306.01264](http://arxiv.org/abs/2306.01264)

    本文发展了一种新的分析技术，并推广了广义平滑度条件，使凸和非凸优化问题获得更强的结果。在该条件下，获得了（随机）梯度下降和Nesterov加速梯度方法的经典收敛率。

    

    经典的凸和非凸优化方法的分析通常需要梯度的Lipshitz性质，这限制了分析范围仅限于二次函数的界限内。最近的工作放松了这个要求，转而使用一种非均匀平滑条件，其中Hessian范数受梯度范数的仿射函数限制，并通过梯度裁剪证明了非凸情况下的收敛性，假设存在有界噪声。在本文中，我们进一步推广了这种非均匀平滑条件，并开发了一种简单但功能强大的分析技术，可以沿轨迹方向限制梯度，从而获得更强的凸和非凸优化问题结果。特别地，在这个广义平滑条件下，我们得到了（随机）梯度下降和Nesterov加速梯度方法的经典收敛率，适用于凸和（或）非凸设定。新的分析方法不需要梯度裁剪，并允许有重尾噪声，这是一种非常实用的优化方法。

    Classical analysis of convex and non-convex optimization methods often requires the Lipshitzness of the gradient, which limits the analysis to functions bounded by quadratics. Recent work relaxed this requirement to a non-uniform smoothness condition with the Hessian norm bounded by an affine function of the gradient norm, and proved convergence in the non-convex setting via gradient clipping, assuming bounded noise. In this paper, we further generalize this non-uniform smoothness condition and develop a simple, yet powerful analysis technique that bounds the gradients along the trajectory, thereby leading to stronger results for both convex and non-convex optimization problems. In particular, we obtain the classical convergence rates for (stochastic) gradient descent and Nesterov's accelerated gradient method in the convex and/or non-convex setting under this general smoothness condition. The new analysis approach does not require gradient clipping and allows heavy-tailed noise with b
    
[^34]: 双重稳健自我训练

    Doubly Robust Self-Training. (arXiv:2306.00265v1 [cs.LG])

    [http://arxiv.org/abs/2306.00265](http://arxiv.org/abs/2306.00265)

    本文提出了一种双重稳健自我训练算法，可以在伪标签不准确和完全准确时分别采取不同的训练策略，实现有效的半监督学习。实验结果表明，该算法在ImageNet和nuScenes数据集上均比标准自我训练总结更好。

    

    自我训练是解决半监督学习问题的一种重要技术。它通过生成伪标签并将其与有限的标记数据集结合使用进行训练，从而利用无标签数据。自我训练的有效性在很大程度上依赖于这些伪标签的准确性。本文引入了双重稳健自我训练，这是一种新颖的半监督算法，可以保证在两个极端之间平衡。当伪标签完全不正确时，我们的方法将被减少到仅使用标记数据进行训练。相反，当伪标签完全准确时，我们的方法将变成利用所有伪标签数据和标记数据进行训练的过程，从而增加有效的样本量。通过在ImageNet图像分类和nuScenes自主驾驶数据集上的实证评估，我们证明了双重稳健损失优于标准自我训练基线的优越性。

    Self-training is an important technique for solving semi-supervised learning problems. It leverages unlabeled data by generating pseudo-labels and combining them with a limited labeled dataset for training. The effectiveness of self-training heavily relies on the accuracy of these pseudo-labels. In this paper, we introduce doubly robust self-training, a novel semi-supervised algorithm that provably balances between two extremes. When the pseudo-labels are entirely incorrect, our method reduces to a training process solely using labeled data. Conversely, when the pseudo-labels are completely accurate, our method transforms into a training process utilizing all pseudo-labeled data and labeled data, thus increasing the effective sample size. Through empirical evaluations on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection, we demonstrate the superiority of the doubly robust loss over the standard self-training baseline.
    
[^35]: 差分隐私在拓扑数据分析中的应用

    Differentially Private Topological Data Analysis. (arXiv:2305.03609v1 [stat.ML])

    [http://arxiv.org/abs/2305.03609](http://arxiv.org/abs/2305.03609)

    本文尝试使用差分隐私实现拓扑数据分析并生成接近最优的私有持久图，提出使用 $L^1$-距离计算持久图并采用指数机制保护隐私，成功实现在隐私保护和数据分析之间的平衡。

    

    本文是首篇尝试使用差分隐私实现拓扑数据分析并生成接近最优的私有持久图。我们通过瓶颈距离分析持久图的灵敏度，发现常用的 \v{C}ech 复形的灵敏度并不会随着样本量 $n$ 的增加而降低，这使得 \v{C}ech 复形持久图难以隐私化。作为替代方法，我们提出使用 $L^1$-距离来计算持久图，发现其灵敏度为 $O(1/n)$。基于灵敏度分析，我们提出采用指数机制，其效用函数定义为 $L^1$-DTM 持久图的瓶颈距离。同时，我们还推导出了我们隐私机制的精度上下界；得到的界限表明我们的机制隐私误差接近最优。我们展示了我们的私有持久图方法的性能。

    This paper is the first to attempt differentially private (DP) topological data analysis (TDA), producing near-optimal private persistence diagrams. We analyze the sensitivity of persistence diagrams in terms of the bottleneck distance, and we show that the commonly used \v{C}ech complex has sensitivity that does not decrease as the sample size $n$ increases. This makes it challenging for the persistence diagrams of \v{C}ech complexes to be privatized. As an alternative, we show that the persistence diagram obtained by the $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the sensitivity analysis, we propose using the exponential mechanism whose utility function is defined in terms of the bottleneck distance of the $L^1$-DTM persistence diagrams. We also derive upper and lower bounds of the accuracy of our privacy mechanism; the obtained bounds indicate that the privacy error of our mechanism is near-optimal. We demonstrate the performance of our privatized persistence
    
[^36]: 停留还是离开预训练基域：关于集成学习在迁移学习中的洞见

    To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning. (arXiv:2303.03374v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03374](http://arxiv.org/abs/2303.03374)

    该论文研究了在迁移学习中使用单个预训练检查点微调的模型集合，发现通过更好地探索预训练基域可以改进集成模型，但离开基域会导致失去迁移学习的好处，并且降低集成质量。作者提出了一种更有效的修改方法StarSSE，可以产生更强的集成模型和均匀的模型混合。

    

    迁移学习和集成学习是改善神经网络性能和鲁棒性的两种热门技术。由于预训练成本高昂，通常实践中使用从单个预训练检查点微调的模型集合。这些模型最终会进入损失函数梯度下降空间的相同区域，我们称之为预训练基域，因此具有有限的多样性。在这项工作中，我们展示了从单个预训练检查点训练的集成模型可以通过更好地探索预训练基域来改进，然而，离开基域会导致失去迁移学习的好处并导致集成质量的下降。基于对现有探索方法的分析，我们提出了一种更有效的修改Transfer Learning Setup中的Snapshot Ensembles（SSE）方法，名为StarSSE，它能产生更强的集成模型和均匀的模型混合。

    Transfer learning and ensembling are two popular techniques for improving the performance and robustness of neural networks. Due to the high cost of pre-training, ensembles of models fine-tuned from a single pre-trained checkpoint are often used in practice. Such models end up in the same basin of the loss landscape, which we call the pre-train basin, and thus have limited diversity. In this work, we show that ensembles trained from a single pre-trained checkpoint may be improved by better exploring the pre-train basin, however, leaving the basin results in losing the benefits of transfer learning and in degradation of the ensemble quality. Based on the analysis of existing exploration methods, we propose a more effective modification of the Snapshot Ensembles (SSE) for transfer learning setup, StarSSE, which results in stronger ensembles and uniform model soups.
    
[^37]: 使用聚合相似矩阵的多层超图聚类

    Multilayer hypergraph clustering using the aggregate similarity matrix. (arXiv:2301.11657v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2301.11657](http://arxiv.org/abs/2301.11657)

    本文提出了一个半定规划方法来解决基于超图的多层聚类问题，同时在同配和非同配情况下保证了精确恢复。

    

    本文考虑在超图的多层变体上执行社区恢复问题，每个层与 N 个顶点上的 d-均匀超图随机块模型 (HSBM) 的独立实现相关。给出包含与每对顶点相交的超边数量聚合的相似矩阵，目标是将 N 个顶点划分为不相交的社区。在本文中，我们研究了半定规划 (SDP) 方法，并获得了有关模型参数的信息论条件，保证在同配和非同配情况下均能确保精确恢复。

    We consider the community recovery problem on a multilayer variant of the hypergraph stochastic block model (HSBM). Each layer is associated with an independent realization of a d-uniform HSBM on N vertices. Given the similarity matrix containing the aggregated number of hyperedges incident to each pair of vertices, the goal is to obtain a partition of the N vertices into disjoint communities. In this work, we investigate a semidefinite programming (SDP) approach and obtain information-theoretic conditions on the model parameters that guarantee exact recovery both in the assortative and the disassortative cases.
    
[^38]: Tracr: 编译变压器模型作为可解释性实验室

    Tracr: Compiled Transformers as a Laboratory for Interpretability. (arXiv:2301.05062v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.05062](http://arxiv.org/abs/2301.05062)

    Tracr是一个编译器，将可读性强的程序编译成标准的仅解码变压器模型，该编译模型的已知结构可以用于设计实验和评估可解释方法。

    

    我们展示了如何将可读性强的程序编译成标准的仅解码变压器模型。我们的编译器Tracr生成具有已知结构的模型，可以用于设计实验。例如，我们使用它来研究执行多步算法的变压器中的“叠加”。此外，Tracr编译模型的已知结构可以作为评估可解释方法的真实基准。通常，由于变压器学习的“程序”是未知的，因此不清楚解释是否成功。我们通过实现和检查包括计算令牌频率、排序和括号检查在内的程序来演示我们的方法。我们在https://github.com/deepmind/tracr提供了Tracr的开源实现。

    We show how to "compile" human-readable programs into standard decoder-only transformer models. Our compiler, Tracr, generates models with known structure. This structure can be used to design experiments. For example, we use it to study "superposition" in transformers that execute multi-step algorithms. Additionally, the known structure of Tracr-compiled models can serve as ground-truth for evaluating interpretability methods. Commonly, because the "programs" learned by transformers are unknown it is unclear whether an interpretation succeeded. We demonstrate our approach by implementing and examining programs including computing token frequencies, sorting, and parenthesis checking. We provide an open-source implementation of Tracr at https://github.com/deepmind/tracr.
    
[^39]: 贝叶斯学习多任务问题的特征空间

    Bayesian learning of feature spaces for multitasks problems. (arXiv:2209.03028v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.03028](http://arxiv.org/abs/2209.03028)

    本文介绍了一种贝叶斯学习的方法，通过连接核机器和极限学习机，实现了在多任务回归问题中的特征空间的学习。该方法提供了优化RBF核参数、模型复杂度和多输出稀疏性的能力。

    

    本文介绍了一种新颖的多任务回归方法，通过利用随机傅里叶特征(RFFs)近似径向基函数(RBF)核，将核机器(KM)和极限学习机(ELM)相连接。其中的一个贡献是表明对于所提出的模型，KM和ELM的形式可以被看作是同一枚硬币的两面。这些提出的模型称为RFF-BLR，建立在贝叶斯框架上，同时解决了两个主要的设计目标。一方面，它基于带有RBF核的KM拟合多任务回归器。另一方面，它引入了一种跨任务的共同先验，促进了ELM视图中的多输出稀疏性。这种贝叶斯方法使得能够同时考虑KM和ELM的观点，实现了(i)在概率框架内优化RBF核参数$\gamma$，(ii)优化模型复杂度，和(iii)

    This paper introduces a novel approach for multi-task regression that connects Kernel Machines (KMs) and Extreme Learning Machines (ELMs) through the exploitation of the Random Fourier Features (RFFs) approximation of the RBF kernel. In this sense, one of the contributions of this paper shows that for the proposed models, the KM and the ELM formulations can be regarded as two sides of the same coin. These proposed models, termed RFF-BLR, stand on a Bayesian framework that simultaneously addresses two main design goals. On the one hand, it fits multitask regressors based on KMs endowed with RBF kernels. On the other hand, it enables the introduction of a common-across-tasks prior that promotes multioutput sparsity in the ELM view. This Bayesian approach facilitates the simultaneous consideration of both the KM and ELM perspectives enabling (i) the optimisation of the RBF kernel parameter $\gamma$ within a probabilistic framework, (ii) the optimisation of the model complexity, and (iii) 
    
[^40]: 最小最大拟贝叶斯估计在稀疏规范相关分析中的应用：基于瑞利商函数的方法

    Minimax Quasi-Bayesian estimation in sparse canonical correlation analysis via a Rayleigh quotient function. (arXiv:2010.08627v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.08627](http://arxiv.org/abs/2010.08627)

    本研究提出了一种利用重新缩放的瑞利商函数作为准对数似然函数并采用贝叶斯框架的方法，通过马尔科夫链蒙特卡罗计算稀疏规范向量的估计值。实验结果表明，该方法在连续和截断数据上表现优于其他方法。

    

    规范相关分析（CCA）是一种用于探索数据集之间关系的流行统计技术。近年来，稀疏规范向量的估计已成为CCA问题的一个重要且具有挑战性的变体，应用广泛。不幸的是，现有的稀疏规范向量的最优估计器计算成本较高。我们提出了一种准贝叶斯估计过程，既达到了最小最大估计速率，又可以通过马尔科夫链蒙特卡罗（MCMC）轻松计算。该方法基于Tan等人（2018）的研究，使用重新缩放的瑞利商函数作为准对数似然函数。然而，与Tan等人（2018）不同的是，我们采用了一个贝叶斯框架，将这个准对数似然函数与尖峰-平板先验结合起来进行规范化推理和促进稀疏性。我们研究了所提出方法在连续和截断数据上的经验行为，并证明它优于几种方法。

    Canonical correlation analysis (CCA) is a popular statistical technique for exploring relationships between datasets. In recent years, the estimation of sparse canonical vectors has emerged as an important but challenging variant of the CCA problem, with widespread applications. Unfortunately, existing rate-optimal estimators for sparse canonical vectors have high computational cost. We propose a quasi-Bayesian estimation procedure that not only achieves the minimax estimation rate, but also is easy to compute by Markov Chain Monte Carlo (MCMC). The method builds on Tan et al. (2018) and uses a re-scaled Rayleigh quotient function as the quasi-log-likelihood. However, unlike Tan et al. (2018), we adopt a Bayesian framework that combines this quasi-log-likelihood with a spike-and-slab prior to regularize the inference and promote sparsity. We investigate the empirical behavior of the proposed method on both continuous and truncated data, and we demonstrate that it outperforms several st
    
[^41]: 非平稳背景下的递归神经线性后验抽样应用于情境赌博

    Recurrent Neural-Linear Posterior Sampling for Nonstationary Contextual Bandits. (arXiv:2007.04750v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2007.04750](http://arxiv.org/abs/2007.04750)

    该论文提出了一种递归神经线性后验抽样的方法，用于解决非平稳情境下的情境赌博问题。实验证明该方法能够有效地表示相关情境并做出决策。

    

    在非平稳情境赌博问题中，一个智能体需要在探索和利用其先前经验中存在的(周期性或结构化)模式之间保持平衡。手工设计一个合适的历史情境是将非平稳问题转化为可以高效解决的平稳问题的一种有吸引力的替代方案。然而，即使是精心设计的历史情境也可能引入虚假关系或缺乏关键信息的方便表示。为了解决这些问题，我们提出了一种学习仅基于智能体与环境之间的原始交互历史来表示相关情境并做出决策的方法。该方法利用了由递归神经网络提取的特征与基于后验抽样的情境线性赌博算法的组合。我们在多样的情境和非情境非平稳问题上的实验证明了我们递归方法的有效性。

    An agent in a nonstationary contextual bandit problem should balance between exploration and the exploitation of (periodic or structured) patterns present in its previous experiences. Handcrafting an appropriate historical context is an attractive alternative to transform a nonstationary problem into a stationary problem that can be solved efficiently. However, even a carefully designed historical context may introduce spurious relationships or lack a convenient representation of crucial information. In order to address these issues, we propose an approach that learns to represent the relevant context for a decision based solely on the raw history of interactions between the agent and the environment. This approach relies on a combination of features extracted by recurrent neural networks with a contextual linear bandit algorithm based on posterior sampling. Our experiments on a diverse selection of contextual and noncontextual nonstationary problems show that our recurrent approach co
    

