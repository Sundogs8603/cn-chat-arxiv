# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Robust Linear Regression: Phase-Transitions and Precise Tradeoffs for General Norms.](http://arxiv.org/abs/2308.00556) | 本文研究了测试时的对抗攻击对线性回归模型的影响，并确定了在保持预测性能的情况下可以达到的最佳鲁棒性水平。该研究揭示了鲁棒性和准确性之间的权衡，并在不损害准确性的情况下找到了鲁棒性的实现方法。 |
| [^2] | [Doubly Robust Instance-Reweighted Adversarial Training.](http://arxiv.org/abs/2308.00311) | 本文提出了一种新颖的双重稳健的实例重新加权对抗训练框架，通过分布鲁棒优化（DRO）技术获得重要性权重，并在最脆弱的示例上提高稳健性。 |
| [^3] | [Predictive Modeling through Hyper-Bayesian Optimization.](http://arxiv.org/abs/2308.00285) | 本文提出了一种将模型选择和贝叶斯优化相结合的方法，以更快地达到函数的最优解。 |
| [^4] | [Best-Subset Selection in Generalized Linear Models: A Fast and Consistent Algorithm via Splicing Technique.](http://arxiv.org/abs/2308.00251) | 本文提出了一种在高维广义线性模型中进行最佳子集选择的快速且一致的算法，该算法通过拼接技术实现了高确定性的最佳子集选择，并在变量选择和系数估计方面优于现有方法。 |
| [^5] | [Crowd Safety Manager: Towards Data-Driven Active Decision Support for Planning and Control of Crowd Events.](http://arxiv.org/abs/2308.00076) | 这篇论文介绍了一种新颖的技术和方法，旨在通过数据驱动的决策支持系统提升人群管理的规划和操作阶段。该方法利用创新的数据收集技术、数据集成和3D数字孪生技术，结合人工智能工具进行风险识别，并引入了蝴蝶结模型来评估和预测风险水平。 |
| [^6] | [Provable convergence guarantees for black-box variational inference.](http://arxiv.org/abs/2306.03638) | 本文提出了一种基于密集高斯变分族的梯度估计器，在此基础上使用近端和投影随机梯度下降，提供了黑盒变分推断收敛于逼真推断问题的第一个严格保证。 |
| [^7] | [Learning and accurate generation of stochastic dynamics based on multi-model Generative Adversarial Networks.](http://arxiv.org/abs/2305.15920) | 本文使用GAN来学习一个原型晶格上的随机过程，并提出一种合适的多模型程序，可以显著提高精度。GAN似乎是处理复杂统计动力学问题的有前途的工具。 |
| [^8] | [Learning linear dynamical systems under convex constraints.](http://arxiv.org/abs/2303.15121) | 本文考虑在给定凸约束下学习线性动态系统，通过解出受约束的最小二乘估计，提出新的非渐进误差界，并应用于稀疏矩阵等情境，改进了现有统计方法。 |
| [^9] | [Convergence Rates for Non-Log-Concave Sampling and Log-Partition Estimation.](http://arxiv.org/abs/2303.03237) | 非对数凹势V的高维采样速率可以在一些条件下实现与凸函数相同的收敛速率。 |
| [^10] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^11] | [How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy.](http://arxiv.org/abs/2303.00654) | 这篇论文提供了关于如何将差分隐私应用于复杂机器学习模型的实用指南，填补了现有实践中的空白，为实现机器学习与差分隐私的结合提供了实际指导。 |
| [^12] | [Nystr\"om $M$-Hilbert-Schmidt Independence Criterion.](http://arxiv.org/abs/2302.09930) | 这项研究提出了Nystr\"om $M$-Hilbert-Schmidt独立准则，针对大规模应用的二次计算瓶颈问题进行了解决，并兼顾了多个随机变量的推广情况和理论保证。 |
| [^13] | [Simplifying Momentum-based Riemannian Submanifold Optimization.](http://arxiv.org/abs/2302.09738) | 本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。 |
| [^14] | [Graphical Dirichlet Process for Clustering Non-Exchangeable Grouped Data.](http://arxiv.org/abs/2302.09111) | 图形化狄利克雷过程用于聚类非交换分组数据，在联合模型中共享聚类，使用超图、断棍法、餐馆模型和有限混合模型极限进行描述，开发了高效的后验推断算法。 |
| [^15] | [On student-teacher deviations in distillation: does it pay to disobey?.](http://arxiv.org/abs/2301.12923) | 通过实验和理论分析，本论文发现在知识蒸馏中，学生网络对教师网络的概率偏离是系统性夸大的，同时也得到了更好的泛化能力。 |
| [^16] | [Lifelong Reinforcement Learning with Modulating Masks.](http://arxiv.org/abs/2212.11110) | 本文研究了终身强化学习中使用调整掩码的方法，通过将调整掩码应用于PPO和IMPALA代理，显著提高了在离散和连续强化学习任务中的性能。 |
| [^17] | [Deep Riemannian Networks for EEG Decoding.](http://arxiv.org/abs/2212.10426) | 本研究分析了深度黎曼网络对EEG的应用，探讨了网络大小、端到端能力、模型训练对模型性能的影响，并比较了其与基于黎曼几何的最先进方法。 |
| [^18] | [A Unified Analysis of Multi-task Functional Linear Regression Models with Manifold Constraint and Composite Quadratic Penalty.](http://arxiv.org/abs/2211.04874) | 本研究提出了带有流形约束和复合二次惩罚的多任务函数线性回归模型，并通过对样条系数矩阵进行双重正则化来实现斜率函数的估计，进一步结合了多任务学习的优势。该模型可以被视为许多多任务学习方法的特例，同时复合惩罚引入了特定的范数，帮助量化流形的曲率并确定适当的子集。 |
| [^19] | [On the Generalized Likelihood Ratio Test and One-Class Classifiers.](http://arxiv.org/abs/2210.12494) | 本文考虑了一类分类器和广义似然比检验的问题，证明了多层感知器神经网络和支持向量机模型在收敛时会表现为广义似然比检验。同时，作者还展示了一类最小二乘SVM在收敛时也能达到广义似然比检验的效果。 |
| [^20] | [Learning Graphical Factor Models with Riemannian Optimization.](http://arxiv.org/abs/2210.11950) | 本文提出了一种灵活的算法框架，用于在协方差矩阵上具有低秩结构约束的图学习。通过使用Riemannian优化，利用正定矩阵和固定秩正半定矩阵的几何特性，解决了这类问题。 |
| [^21] | [Causal Discovery and Knowledge Injection for Contestable Neural Networks.](http://arxiv.org/abs/2205.09787) | 本研究提出了一种可以进行双向互动的方法，通过允许神经网络展示其所学因果图，并允许人类修改因果图后重新注入机器中，从而提供了一种调试神经网络的方式，实验结果显示该方法可以显著改善预测性能。 |
| [^22] | [Seeded graph matching for the correlated Wigner model via the projected power method.](http://arxiv.org/abs/2204.04099) | 本文研究了在相关维格纳模型下的有种子图匹配问题，通过分析表明，使用投影功率方法（PPM）作为图匹配算法可以在给定接近真实匹配的种子的情况下高概率地改进种子并恢复真实匹配。 |
| [^23] | [A Framework and Benchmark for Deep Batch Active Learning for Regression.](http://arxiv.org/abs/2203.09410) | 本研究提出了一个深度批量主动学习回归的框架和基准测试，其中包括许多现有的贝叶斯和非贝叶斯方法。提出了一种替换常用最后一层特征的新方法，并结合一种新颖的聚类方法。在15个大型表格回归数据集上进行测试，该方法在基准测试中表现优异，适用于大型数据集且易于使用。 |
| [^24] | [AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment of Implicit Graph Generators.](http://arxiv.org/abs/2203.03673) | AgraSSt是一种用于评估隐式图生成器质量的统计方法，通过构建基于核的差异度量，它能够确定学习到的图生成过程是否能生成类似给定输入图的图形，并提供有关图生成器训练过程的可解释性问题和可靠样本批次的信息。 |
| [^25] | [Transfer-Learning Across Datasets with Different Input Dimensions: An Algorithm and Analysis for the Linear Regression Case.](http://arxiv.org/abs/2202.05069) | 本文提出了一种适用于线性回归情况的迁移学习算法，该算法能够将新数据与历史数据相结合，特别在新数据稀缺的情况下具有益处，并且在实验验证中表现出对负迁移学习的鲁棒性。 |
| [^26] | [Spectral learning of multivariate extremes.](http://arxiv.org/abs/2111.07799) | 我们提出了一种用于分析多元极值的谱聚类算法，并通过理论和数值实验展示了其在学习角度测度方面的性能。 |
| [^27] | [Integrated Conditional Estimation-Optimization.](http://arxiv.org/abs/2110.12351) | 该论文提出了一种综合条件估计-优化（ICEO）框架，可以在考虑优化问题结构的同时估计随机参数的条件分布，并提供了一些性能保证。 |
| [^28] | [On the Universality of the Double Descent Peak in Ridgeless Regression.](http://arxiv.org/abs/2010.01851) | 我们证明了在无岭线性回归中存在一个双下降峰，无论输入分布的特征映射是确定性的还是随机的，都会导致期望均方泛化误差增加。并且我们的结果适用于广泛的输入分布类。 |
| [^29] | [An Integrated Multi-Time-Scale Modeling for Solar Irradiance Forecasting Using Deep Learning.](http://arxiv.org/abs/1905.02616) | 本研究提出了一种使用深度学习方法进行太阳辐照度预测的统一架构，能够在不同时间尺度上进行预测，并提出了一个框架来将这种方法扩展到每小时预测范围。 |
| [^30] | [Considerations When Learning Additive Explanations for Black-Box Models.](http://arxiv.org/abs/1801.08640) | 本文研究了非增加型模型的全局增加性解释方法，发现不同的解释方法以不同的方式刻画了黑盒模型预测函数中的非增加性成分。尽管精简的解释一般是最准确的增加性解释，但显式建模非增加性成分的树形解释往往更准确。机器学习从业者能够更好地利用增加性解释来完成各种任务。 |

# 详细

[^1]: 坚强的线性回归：相变和对一般范数的精确权衡

    Robust Linear Regression: Phase-Transitions and Precise Tradeoffs for General Norms. (arXiv:2308.00556v1 [stat.ML])

    [http://arxiv.org/abs/2308.00556](http://arxiv.org/abs/2308.00556)

    本文研究了测试时的对抗攻击对线性回归模型的影响，并确定了在保持预测性能的情况下可以达到的最佳鲁棒性水平。该研究揭示了鲁棒性和准确性之间的权衡，并在不损害准确性的情况下找到了鲁棒性的实现方法。

    

    本文研究了测试时对线性回归模型的对抗攻击对其影响，并确定了任何模型在保持给定水平的预测性能（准确度）的同时可以达到的最佳鲁棒性水平。通过定量估计，我们揭示了在不同领域中鲁棒性和准确性之间的基本权衡。我们获得了一个明确的描述，区分了在不损害标准准确性的情况下可以实现鲁棒性的情况与不可避免地需要权衡的情况。我们的研究结果在多种设置下通过简单的实验得到了经验证实。这项工作适用于特征协方差矩阵和任何性质的攻击范数，并超越了之前在该领域的工作。

    In this paper, we investigate the impact of test-time adversarial attacks on linear regression models and determine the optimal level of robustness that any model can reach while maintaining a given level of standard predictive performance (accuracy). Through quantitative estimates, we uncover fundamental tradeoffs between adversarial robustness and accuracy in different regimes. We obtain a precise characterization which distinguishes between regimes where robustness is achievable without hurting standard accuracy and regimes where a tradeoff might be unavoidable. Our findings are empirically confirmed with simple experiments that represent a variety of settings. This work applies to feature covariance matrices and attack norms of any nature, and extends beyond previous works in this area.
    
[^2]: 双重稳健的实例重新加权对抗训练

    Doubly Robust Instance-Reweighted Adversarial Training. (arXiv:2308.00311v1 [cs.LG])

    [http://arxiv.org/abs/2308.00311](http://arxiv.org/abs/2308.00311)

    本文提出了一种新颖的双重稳健的实例重新加权对抗训练框架，通过分布鲁棒优化（DRO）技术获得重要性权重，并在最脆弱的示例上提高稳健性。

    

    在有限的模型容量下，为对抗性数据分配重要性权重在训练对抗性稳健网络方面取得了巨大成功。然而，现有的实例重新加权对抗训练方法严重依赖于启发式算法和/或几何解释来确定这些重要性权重，使得这些算法缺乏严格的理论解释/保证。此外，最近的研究表明，对抗训练在训练分布中的稳健性表现非均匀，例如，某些类别的数据点比其他类别更容易受到对抗性攻击。为了解决这两个问题，本文提出了一种新颖的双重稳健的实例重新加权对抗训练框架，通过探索分布鲁棒优化（DRO）技术来获得重要性权重，并在最脆弱的示例上提高稳健性。

    Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained
    
[^3]: 通过超贝叶斯优化进行预测模型

    Predictive Modeling through Hyper-Bayesian Optimization. (arXiv:2308.00285v1 [cs.LG])

    [http://arxiv.org/abs/2308.00285](http://arxiv.org/abs/2308.00285)

    本文提出了一种将模型选择和贝叶斯优化相结合的方法，以更快地达到函数的最优解。

    

    模型选择是基于模型的优化技术（如贝叶斯优化）最关键的问题之一。当前的方法通常将模型选择视为一个估计问题，需要定期更新来适应优化迭代中得到的观测结果。本文提出了一种新的方法来同时实现高效性。具体来说，我们提出了一种将模型选择和贝叶斯优化相结合的方法，以达到更快地达到函数的最优解。算法在模型空间和函数空间之间来回移动，其中推荐模型的好坏由一个评分函数来衡量并反馈，这个函数捕捉了模型在函数空间中对收敛的帮助程度。评分函数的推导方式使其抵消了贝叶斯优化在函数空间中的动态性质的影响，从而使模型选择问题保持稳定。这种来回迭代导致模型选择和贝叶斯优化都能快速收敛。

    Model selection is an integral problem of model based optimization techniques such as Bayesian optimization (BO). Current approaches often treat model selection as an estimation problem, to be periodically updated with observations coming from the optimization iterations. In this paper, we propose an alternative way to achieve both efficiently. Specifically, we propose a novel way of integrating model selection and BO for the single goal of reaching the function optima faster. The algorithm moves back and forth between BO in the model space and BO in the function space, where the goodness of the recommended model is captured by a score function and fed back, capturing how well the model helped convergence in the function space. The score function is derived in such a way that it neutralizes the effect of the moving nature of the BO in the function space, thus keeping the model selection problem stationary. This back and forth leads to quick convergence for both model selection and BO i
    
[^4]: 广义线性模型中的最佳子集选择：一种通过拼接技术的快速且一致的算法

    Best-Subset Selection in Generalized Linear Models: A Fast and Consistent Algorithm via Splicing Technique. (arXiv:2308.00251v1 [stat.ML])

    [http://arxiv.org/abs/2308.00251](http://arxiv.org/abs/2308.00251)

    本文提出了一种在高维广义线性模型中进行最佳子集选择的快速且一致的算法，该算法通过拼接技术实现了高确定性的最佳子集选择，并在变量选择和系数估计方面优于现有方法。

    

    在高维广义线性模型中，很重要的是确定一个能充分解释响应变化的稀疏模型。虽然最佳子集选择一直被认为是这类问题的终极目标，但要同时实现计算效率和统计保证却非常具有挑战性。本文目的在于利用快速算法，以高确定性选择最佳子集，解决这一难题。我们提出并演示了一种在正则条件下实现最佳子集恢复的算法。在一定条件下，我们的算法的计算复杂度与样本大小和维数的多项式级别相关。除了展示我们方法的统计特性，广泛的数值实验表明，它在变量选择和系数估计方面优于现有方法。运行时间分析显示，与流行的变量选择工具相比，我们的实现实现了近4倍的加速。

    In high-dimensional generalized linear models, it is crucial to identify a sparse model that adequately accounts for response variation. Although the best subset section has been widely regarded as the Holy Grail of problems of this type, achieving either computational efficiency or statistical guarantees is challenging. In this article, we intend to surmount this obstacle by utilizing a fast algorithm to select the best subset with high certainty. We proposed and illustrated an algorithm for best subset recovery in regularity conditions. Under mild conditions, the computational complexity of our algorithm scales polynomially with sample size and dimension. In addition to demonstrating the statistical properties of our method, extensive numerical experiments reveal that it outperforms existing methods for variable selection and coefficient estimation. The runtime analysis shows that our implementation achieves approximately a fourfold speedup compared to popular variable selection tool
    
[^5]: 人群安全管理系统：基于数据驱动的活动决策支持的规划和控制

    Crowd Safety Manager: Towards Data-Driven Active Decision Support for Planning and Control of Crowd Events. (arXiv:2308.00076v1 [cs.AI])

    [http://arxiv.org/abs/2308.00076](http://arxiv.org/abs/2308.00076)

    这篇论文介绍了一种新颖的技术和方法，旨在通过数据驱动的决策支持系统提升人群管理的规划和操作阶段。该方法利用创新的数据收集技术、数据集成和3D数字孪生技术，结合人工智能工具进行风险识别，并引入了蝴蝶结模型来评估和预测风险水平。

    

    本文提出了一种新颖的技术和方法，旨在增强规划和操作阶段的人群管理。该方法包括创新的数据收集技术、数据集成和可视化，使用3D数字孪生技术，并结合人工智能工具进行风险识别。本文介绍了“蝴蝶结”模型，这是一个综合性框架，旨在评估和预测风险水平。该模型结合了客观估计和预测，如交通流量运营和拥挤程度，以及各种恶化因素，如天气条件、情绪和游客的目的，以评估潜在事件风险。提出的框架应用于Scheveningen的人群安全管理项目，其中DigiTwin基于丰富的实时数据来源进行开发。一个值得注意的数据来源是Resono，提供访客数量和动向的见解，充分利用了一组

    This paper presents novel technology and methodology aimed at enhancing crowd management in both the planning and operational phases. The approach encompasses innovative data collection techniques, data integration, and visualization using a 3D Digital Twin, along with the incorporation of artificial intelligence (AI) tools for risk identification. The paper introduces the Bowtie model, a comprehensive framework designed to assess and predict risk levels. The model combines objective estimations and predictions, such as traffic flow operations and crowdedness levels, with various aggravating factors like weather conditions, sentiments, and the purpose of visitors, to evaluate the expected risk of incidents. The proposed framework is applied to the Crowd Safety Manager project in Scheveningen, where the DigiTwin is developed based on a wealth of real-time data sources. One noteworthy data source is Resono, offering insights into the number of visitors and their movements, leveraging a m
    
[^6]: 黑盒变分推断的收敛性保证

    Provable convergence guarantees for black-box variational inference. (arXiv:2306.03638v1 [cs.LG])

    [http://arxiv.org/abs/2306.03638](http://arxiv.org/abs/2306.03638)

    本文提出了一种基于密集高斯变分族的梯度估计器，在此基础上使用近端和投影随机梯度下降，提供了黑盒变分推断收敛于逼真推断问题的第一个严格保证。

    

    尽管黑盒变分推断被广泛应用，但没有证明其随机优化成功的证明。我们提出这是现有随机优化证明中的理论差距，即具有异常噪声边界和复合非平滑目标的梯度估计器的挑战。对于密集的高斯变分族，我们观察到现有的基于再参数化的梯度估计器满足二次噪声界，并为使用该界限的近端和投影随机梯度下降提供新的收敛保证。这提供了第一个黑盒变分推断收敛于逼真推断问题的严格保证。

    While black-box variational inference is widely used, there is no proof that its stochastic optimization succeeds. We suggest this is due to a theoretical gap in existing stochastic optimization proofs-namely the challenge of gradient estimators with unusual noise bounds, and a composite non-smooth objective. For dense Gaussian variational families, we observe that existing gradient estimators based on reparameterization satisfy a quadratic noise bound and give novel convergence guarantees for proximal and projected stochastic gradient descent using this bound. This provides the first rigorous guarantee that black-box variational inference converges for realistic inference problems.
    
[^7]: 基于多模型生成对抗网络的随机动力学学习和精确生成

    Learning and accurate generation of stochastic dynamics based on multi-model Generative Adversarial Networks. (arXiv:2305.15920v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2305.15920](http://arxiv.org/abs/2305.15920)

    本文使用GAN来学习一个原型晶格上的随机过程，并提出一种合适的多模型程序，可以显著提高精度。GAN似乎是处理复杂统计动力学问题的有前途的工具。

    

    生成对抗网络（GAN）已经在远离物理领域，如文本和图像生成方面展示出了巨大的潜力。本文使用GAN来学习一个原型晶格上的随机过程。通过合理地向原始数据添加噪声，我们成功地将生成器和鉴别器损失函数的值带到了它们的理想值附近。然而，像对抗性方法一样，震荡仍然存在。这会破坏模型选择和生成轨迹的质量。我们展示了，一种合适的多模型程序，在每一步随机选择生成器推进随机轨迹，可以显著提高精度。基于以上发现，GAN似乎是处理复杂统计动力学问题的有前途的工具。

    Generative Adversarial Networks (GANs) have shown immense potential in fields far from physics, such as in text and image generation. Here we use GANs to learn a prototypical stochastic process on a lattice. By suitably adding noise to the original data we succeed in bringing both the Generator and the Discriminator loss functions close to their ideal value. However, as typical for adversarial approaches, oscillations persist. This undermines model selection and the quality of the generated trajectory. We demonstrate that a suitable multi-model procedure where stochastic trajectories are advanced at each step upon randomly selecting a Generator leads to a remarkable increase in accuracy. Based on the reported findings GANs appears as a promising tool to tackle complex statistical dynamics.
    
[^8]: 在凸约束下学习线性动态系统

    Learning linear dynamical systems under convex constraints. (arXiv:2303.15121v1 [math.ST])

    [http://arxiv.org/abs/2303.15121](http://arxiv.org/abs/2303.15121)

    本文考虑在给定凸约束下学习线性动态系统，通过解出受约束的最小二乘估计，提出新的非渐进误差界，并应用于稀疏矩阵等情境，改进了现有统计方法。

    

    我们考虑从单个轨迹中识别线性动态系统的问题。最近的研究主要关注未对系统矩阵 $A^* \in \mathbb{R}^{n \times n}$ 进行结构假设的情况，并对普通最小二乘 (OLS) 估计器进行了详细分析。我们假设可用先前的 $A^*$ 的结构信息，可以在包含 $A^*$ 的凸集 $\mathcal{K}$ 中捕获。对于随后的受约束最小二乘估计的解，我们推导出 Frobenius 范数下依赖于 $\mathcal{K}$ 在 $A^*$ 处切锥的局部大小的非渐进误差界。为了说明这一结果的有用性，我们将其实例化为以下设置：(i) $\mathcal{K}$ 是 $\mathbb{R}^{n \times n}$ 中的 $d$ 维子空间，或者 (ii) $A^*$ 是 $k$ 稀疏的，$\mathcal{K}$ 是适当缩放的 $\ell_1$ 球。在 $d, k \ll n^2$ 的区域中，我们的误差界对于相同的统计和噪声假设比 OLS 估计器获得了改进。

    We consider the problem of identification of linear dynamical systems from a single trajectory. Recent results have predominantly focused on the setup where no structural assumption is made on the system matrix $A^* \in \mathbb{R}^{n \times n}$, and have consequently analyzed the ordinary least squares (OLS) estimator in detail. We assume prior structural information on $A^*$ is available, which can be captured in the form of a convex set $\mathcal{K}$ containing $A^*$. For the solution of the ensuing constrained least squares estimator, we derive non-asymptotic error bounds in the Frobenius norm which depend on the local size of the tangent cone of $\mathcal{K}$ at $A^*$. To illustrate the usefulness of this result, we instantiate it for the settings where, (i) $\mathcal{K}$ is a $d$ dimensional subspace of $\mathbb{R}^{n \times n}$, or (ii) $A^*$ is $k$-sparse and $\mathcal{K}$ is a suitably scaled $\ell_1$ ball. In the regimes where $d, k \ll n^2$, our bounds improve upon those obta
    
[^9]: 非对数凹采样和对数分区估计的收敛速率

    Convergence Rates for Non-Log-Concave Sampling and Log-Partition Estimation. (arXiv:2303.03237v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.03237](http://arxiv.org/abs/2303.03237)

    非对数凹势V的高维采样速率可以在一些条件下实现与凸函数相同的收敛速率。

    

    从吉布斯分布$p(x)\propto\exp(-V(x)/\epsilon)$中采样并计算其对数分区函数是统计学、机器学习和统计物理中的基本任务。然而，虽然有效的算法已知于凸势函数$V$，但非凸情况下的情况要困难得多，算法必然在最坏情况下受到维度灾难的困扰。最近，已经证明在适当的条件下，高维采样非对数凹势V的速率也可以达到同样快的速度。本文对这些结果进行了回顾，并强调了领域中的一些开放问题。

    Sampling from Gibbs distributions $p(x) \propto \exp(-V(x)/\varepsilon)$ and computing their log-partition function are fundamental tasks in statistics, machine learning, and statistical physics. However, while efficient algorithms are known for convex potentials $V$, the situation is much more difficult in the non-convex case, where algorithms necessarily suffer from the curse of dimensionality in the worst case. For optimization, which can be seen as a low-temperature limit of sampling, it is known that smooth functions $V$ allow faster convergence rates. Specifically, for $m$-times differentiable functions in $d$ dimensions, the optimal rate for algorithms with $n$ function evaluations is known to be $O(n^{-m/d})$, where the constant can potentially depend on $m, d$ and the function to be optimized. Hence, the curse of dimensionality can be alleviated for smooth functions at least in terms of the convergence rate. Recently, it has been shown that similarly fast rates can also be ach
    
[^10]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^11]: 如何用差分隐私实现机器学习：机器学习与差分隐私实用指南

    How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy. (arXiv:2303.00654v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00654](http://arxiv.org/abs/2303.00654)

    这篇论文提供了关于如何将差分隐私应用于复杂机器学习模型的实用指南，填补了现有实践中的空白，为实现机器学习与差分隐私的结合提供了实际指导。

    

    机器学习模型在现实世界应用广泛，并且是研究的重点。与此同时，社区开始意识到保护机器学习训练数据的隐私的重要性。差分隐私已经成为对数据匿名化做出正式陈述的黄金标准。然而，尽管在工业界已经有一些应用差分隐私的尝试，但将差分隐私应用于现实世界中的复杂机器学习模型仍然很少。差分隐私的应用受限于缺乏实际指导，不清楚需要什么样的隐私保证，并且在机器学习模型的隐私保护、效用和计算之间存在良好的平衡。调整和优化性能的技巧散布在论文中或者存在于从业者的头脑中。此外，文献似乎对于如何以及是否应用架构调整以及哪些组件在应用差分隐私时是“安全”的问题存在着相互矛盾的证据。本工作是一份自包含的指南，旨在填补这些空白并提供实际指导，帮助实现机器学习与差分隐私的结合。

    ML models are ubiquitous in real world applications and are a constant focus of research. At the same time, the community has started to realize the importance of protecting the privacy of ML training data.  Differential Privacy (DP) has become a gold standard for making formal statements about data anonymization. However, while some adoption of DP has happened in industry, attempts to apply DP to real world complex ML models are still few and far between. The adoption of DP is hindered by limited practical guidance of what DP protection entails, what privacy guarantees to aim for, and the difficulty of achieving good privacy-utility-computation trade-offs for ML models. Tricks for tuning and maximizing performance are scattered among papers or stored in the heads of practitioners. Furthermore, the literature seems to present conflicting evidence on how and whether to apply architectural adjustments and which components are "safe" to use with DP.  This work is a self-contained guide th
    
[^12]: Nystr\"om $M$-Hilbert-Schmidt独立准则

    Nystr\"om $M$-Hilbert-Schmidt Independence Criterion. (arXiv:2302.09930v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09930](http://arxiv.org/abs/2302.09930)

    这项研究提出了Nystr\"om $M$-Hilbert-Schmidt独立准则，针对大规模应用的二次计算瓶颈问题进行了解决，并兼顾了多个随机变量的推广情况和理论保证。

    

    核技术是数据科学中最受欢迎和强大的方法之一。核的广泛应用的关键特性包括：(i) 它们针对的领域数量多，(ii) 与核相关的函数类具有Hilbert结构，便于统计分析，以及(iii) 它们能够以不丢失信息的方式表示概率分布。这些特性导致了Hilbert-Schmidt独立准则(HSIC)的巨大成功，该准则能够在温和条件下捕捉随机变量的联合独立性，并允许具有二次计算复杂性的闭式估计器(相对于样本大小)。为了解决大规模应用中的二次计算瓶颈问题，已经提出了多个HSIC近似估计器，然而这些估计器限制于$M=2$个随机变量，不能自然地推广到$M \geq 2$的情况，并且缺乏理论保证。在这项工作中，我们提出了一个Nystr\"om $M$-Hilbert-Schmidt独立准则来解决这个问题。

    Kernel techniques are among the most popular and powerful approaches of data science. Among the key features that make kernels ubiquitous are (i) the number of domains they have been designed for, (ii) the Hilbert structure of the function class associated to kernels facilitating their statistical analysis, and (iii) their ability to represent probability distributions without loss of information. These properties give rise to the immense success of Hilbert-Schmidt independence criterion (HSIC) which is able to capture joint independence of random variables under mild conditions, and permits closed-form estimators with quadratic computational complexity (w.r.t. the sample size). In order to alleviate the quadratic computational bottleneck in large-scale applications, multiple HSIC approximations have been proposed, however these estimators are restricted to $M=2$ random variables, do not extend naturally to the $M\ge 2$ case, and lack theoretical guarantees. In this work, we propose an
    
[^13]: 简化基于动量的黎曼子流形优化

    Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09738](http://arxiv.org/abs/2302.09738)

    本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。

    

    带有动量的黎曼子流形优化在计算上是具有挑战性的，因为确保迭代保持在子流形上通常需要解决困难的微分方程。本文针对具有仿射不变度量的对称正定矩阵的子流形优化算法进行了简化。我们提出了黎曼正常坐标的广义版本，可以将问题动态地简化为欧几里得无约束问题。我们使用我们的方法来解释和简化现有的结构化协方差方法，并为深度学习开发了高效的二阶优化器，而无需显式矩阵求逆。

    Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
    
[^14]: 图形化狄利克雷过程用于聚类非交换分组数据

    Graphical Dirichlet Process for Clustering Non-Exchangeable Grouped Data. (arXiv:2302.09111v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2302.09111](http://arxiv.org/abs/2302.09111)

    图形化狄利克雷过程用于聚类非交换分组数据，在联合模型中共享聚类，使用超图、断棍法、餐馆模型和有限混合模型极限进行描述，开发了高效的后验推断算法。

    

    我们考虑聚类可能具有非交换组并且其依赖关系可以通过已知的有向无环图来描述的分组数据的问题。为了允许在非交换组之间共享聚类，我们提出了一种贝叶斯非参数方法，称为图形化狄利克雷过程，它通过假设每个随机测度分布如同狄利克雷过程，其中浓度参数和基本概率测度取决于其父组的浓度参数和基本概率测度，来共同对依赖于组的特定随机测度进行建模。所得到的联合随机过程尊重连接组的有向无环图的马尔可夫性质。我们使用新方法的超图表示以及断棍法表示、餐馆类型表示和作为有限混合模型极限的表示来描述图形化狄利克雷过程。我们开发了一个高效的后验推断算法，并用模拟和实例说明了我们的模型。

    We consider the problem of clustering grouped data with possibly non-exchangeable groups whose dependencies can be characterized by a known directed acyclic graph. To allow the sharing of clusters among the non-exchangeable groups, we propose a Bayesian nonparametric approach, termed graphical Dirichlet process, that jointly models the dependent group-specific random measures by assuming each random measure to be distributed as a Dirichlet process whose concentration parameter and base probability measure depend on those of its parent groups. The resulting joint stochastic process respects the Markov property of the directed acyclic graph that links the groups. We characterize the graphical Dirichlet process using a novel hypergraph representation as well as the stick-breaking representation, the restaurant-type representation, and the representation as a limit of a finite mixture model. We develop an efficient posterior inference algorithm and illustrate our model with simulations and
    
[^15]: 关于知识蒸馏中的学生-教师偏差：违反规则是否有益？

    On student-teacher deviations in distillation: does it pay to disobey?. (arXiv:2301.12923v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12923](http://arxiv.org/abs/2301.12923)

    通过实验和理论分析，本论文发现在知识蒸馏中，学生网络对教师网络的概率偏离是系统性夸大的，同时也得到了更好的泛化能力。

    

    知识蒸馏（KD）被广泛用于通过训练学生模仿经过训练的“教师”网络的软概率来提高“学生”网络的测试准确性。然而，最近的研究表明，尽管被训练成适应教师的概率，学生不仅明显偏离这些概率，而且表现比教师更好。我们的研究旨在通过确定学生-教师偏差的确切性质，并论证它们与更好的泛化能力如何共存来解决这一看似矛盾的观察。首先，通过对图像和语言数据进行实验，我们确定这些偏差对应于学生系统性地夸大教师的自信水平。接下来，在一些简单的设置中，我们从理论和实证上建立了KD在收敛更快的过程中夸大了梯度下降的隐含偏差的证据。最后，

    Knowledge distillation (KD) has been widely-used to improve the test accuracy of a ``student'' network by training the student to mimic soft probabilities of a trained "teacher" network. Yet, it has been shown in recent work that, despite being trained to fit the teacher's probabilities, the student not only significantly deviates from these probabilities, but also performs even better than the teacher. Our work aims to reconcile this seemingly paradoxical observation by characterizing the precise nature of the student-teacher deviations, and by arguing how they can co-occur with better generalization. First, through experiments on image and language data, we identify that these deviations correspond to the student systematically exaggerating the confidence levels of the teacher. Next, we theoretically and empirically establish in some simple settings that KD also exaggerates the implicit bias of gradient descent in converging faster along the top eigendirections of the data. Finally, 
    
[^16]: 使用调整掩码的终身强化学习

    Lifelong Reinforcement Learning with Modulating Masks. (arXiv:2212.11110v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.11110](http://arxiv.org/abs/2212.11110)

    本文研究了终身强化学习中使用调整掩码的方法，通过将调整掩码应用于PPO和IMPALA代理，显著提高了在离散和连续强化学习任务中的性能。

    

    终身学习旨在创建在其生命周期中持续和逐步学习的人工智能系统，类似生物学习。到目前为止，这方面的尝试遇到了问题，包括灾难性遗忘、任务之间的干扰，以及无法利用先前的知识。虽然已经有相当多的研究集中在学习涉及输入分布变化的多个监督分类任务上，但是终身强化学习必须处理状态和转换分布以及奖励函数的变化。最近针对分类问题开发的使用固定骨干网络的调整掩码对于处理如此大范围的任务变化特别适用。在本文中，我们将调整掩码应用于深层次的终身强化学习，具体包括PPO和IMPALA代理。在离散和连续强化学习任务中与终身强化学习基线进行了比较，结果显示出卓越的性能。我们进一步研究了先前任务的线性组合的使用。

    Lifelong learning aims to create AI systems that continuously and incrementally learn during a lifetime, similar to biological learning. Attempts so far have met problems, including catastrophic forgetting, interference among tasks, and the inability to exploit previous knowledge. While considerable research has focused on learning multiple supervised classification tasks that involve changes in the input distribution, lifelong reinforcement learning (LRL) must deal with variations in the state and transition distributions, and in the reward functions. Modulating masks with a fixed backbone network, recently developed for classification, are particularly suitable to deal with such a large spectrum of task variations. In this paper, we adapted modulating masks to work with deep LRL, specifically PPO and IMPALA agents. The comparison with LRL baselines in both discrete and continuous RL tasks shows superior performance. We further investigated the use of a linear combination of previousl
    
[^17]: EEG解码的深度黎曼网络

    Deep Riemannian Networks for EEG Decoding. (arXiv:2212.10426v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10426](http://arxiv.org/abs/2212.10426)

    本研究分析了深度黎曼网络对EEG的应用，探讨了网络大小、端到端能力、模型训练对模型性能的影响，并比较了其与基于黎曼几何的最先进方法。

    

    当前在电脑脑电图（EEG）解码任务中，最先进的性能通常是由深度学习或基于黎曼几何的解码器实现的。最近，越来越多的人对深度黎曼网络（DRNs）产生了兴趣，可能结合了之前两类方法的优点。然而，还有一系列问题需要进一步洞察，以铺平DRNs在EEG中更广泛应用的道路。这些问题包括架构设计问题，如网络大小和端到端能力，以及模型训练问题。这些因素如何影响模型性能尚未被探索。此外，这些网络中的数据如何转换，以及是否与传统的EEG解码相关也不清楚。本研究旨在通过分析具有广泛超参数的DRNs来奠定这些主题领域的基础。使用两个公共EEG数据集测试了网络，并与最先进的基于黎曼几何的方法进行了比较。

    State-of-the-art performance in electroencephalography (EEG) decoding tasks is currently often achieved with either Deep-Learning or Riemannian-Geometry-based decoders. Recently, there is growing interest in Deep Riemannian Networks (DRNs) possibly combining the advantages of both previous classes of methods. However, there are still a range of topics where additional insight is needed to pave the way for a more widespread application of DRNs in EEG. These include architecture design questions such as network size and end-to-end ability as well as model training questions. How these factors affect model performance has not been explored. Additionally, it is not clear how the data within these networks is transformed, and whether this would correlate with traditional EEG decoding. Our study aims to lay the groundwork in the area of these topics through the analysis of DRNs for EEG with a wide range of hyperparameters. Networks were tested on two public EEG datasets and compared with sta
    
[^18]: 带有流形约束和复合二次惩罚的多任务函数线性回归模型的统一分析

    A Unified Analysis of Multi-task Functional Linear Regression Models with Manifold Constraint and Composite Quadratic Penalty. (arXiv:2211.04874v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2211.04874](http://arxiv.org/abs/2211.04874)

    本研究提出了带有流形约束和复合二次惩罚的多任务函数线性回归模型，并通过对样条系数矩阵进行双重正则化来实现斜率函数的估计，进一步结合了多任务学习的优势。该模型可以被视为许多多任务学习方法的特例，同时复合惩罚引入了特定的范数，帮助量化流形的曲率并确定适当的子集。

    

    本研究探讨了多任务函数线性回归模型，其中协变量和未知回归系数（称为斜率函数）均为曲线。为了斜率函数估计，我们采用罚化样条来平衡偏差、方差和计算复杂度。多任务学习的优势在于通过对斜率函数施加额外的结构。我们提出了一个通用模型，通过对样条系数矩阵进行双重正则化：i）矩阵流形约束，和ii）一个由二次项求和构成的复合惩罚。许多多任务学习方法都可以被视为该提出模型的特例，例如降秩模型和图拉普拉斯正则化模型。我们展示了复合惩罚引入了一种特定的范数，有助于量化流形的曲率，并确定流形切空间中相应的适当子集。然后，切空间子集的复杂度与几何流形的复杂度相联系。

    This work studies the multi-task functional linear regression models where both the covariates and the unknown regression coefficients (called slope functions) are curves. For slope function estimation, we employ penalized splines to balance bias, variance, and computational complexity. The power of multi-task learning is brought in by imposing additional structures over the slope functions. We propose a general model with double regularization over the spline coefficient matrix: i) a matrix manifold constraint, and ii) a composite penalty as a summation of quadratic terms. Many multi-task learning approaches can be treated as special cases of this proposed model, such as a reduced-rank model and a graph Laplacian regularized model. We show the composite penalty induces a specific norm, which helps to quantify the manifold curvature and determine the corresponding proper subset in the manifold tangent space. The complexity of tangent space subset is then bridged to the complexity of ge
    
[^19]: 关于广义似然比检验和一类分类器

    On the Generalized Likelihood Ratio Test and One-Class Classifiers. (arXiv:2210.12494v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12494](http://arxiv.org/abs/2210.12494)

    本文考虑了一类分类器和广义似然比检验的问题，证明了多层感知器神经网络和支持向量机模型在收敛时会表现为广义似然比检验。同时，作者还展示了一类最小二乘SVM在收敛时也能达到广义似然比检验的效果。

    

    一类分类（OCC）是决定观察样本是否属于目标类的问题。我们考虑在包含目标类样本的数据集上学习一个表现为广义似然比检验（GLRT）的OCC模型的问题。当目标类的统计信息可用时，GLRT解决了相同的问题。GLRT是一个众所周知且在特定条件下可证明最佳的分类器。为此，我们考虑了多层感知器神经网络（NN）和支持向量机（SVM）模型。它们使用人工数据集训练为两类分类器，其中替代类使用在目标类数据集的定义域上均匀生成的随机样本。我们证明，在适当的假设下，模型在大数据集上收敛到了GLRT。此外，我们还展示了具有适当核函数的一类最小二乘SVM（OCLSSVM）在收敛时表现为GLRT。

    One-class classification (OCC) is the problem of deciding whether an observed sample belongs to a target class. We consider the problem of learning an OCC model that performs as the generalized likelihood ratio test (GLRT), given a dataset containing samples of the target class. The GLRT solves the same problem when the statistics of the target class are available. The GLRT is a well-known and provably optimal (under specific assumptions) classifier. To this end, we consider both the multilayer perceptron neural network (NN) and the support vector machine (SVM) models. They are trained as two-class classifiers using an artificial dataset for the alternative class, obtained by generating random samples, uniformly over the domain of the target-class dataset. We prove that, under suitable assumptions, the models converge (with a large dataset) to the GLRT. Moreover, we show that the one-class least squares SVM (OCLSSVM) with suitable kernels at convergence performs as the GLRT. Lastly, we
    
[^20]: 用Riemannian优化学习图形因子模型

    Learning Graphical Factor Models with Riemannian Optimization. (arXiv:2210.11950v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.11950](http://arxiv.org/abs/2210.11950)

    本文提出了一种灵活的算法框架，用于在协方差矩阵上具有低秩结构约束的图学习。通过使用Riemannian优化，利用正定矩阵和固定秩正半定矩阵的几何特性，解决了这类问题。

    

    图形模型和因子分析是多元统计学中成熟的工具。尽管这些模型都可以与协方差和精度矩阵的结构联系起来，但它们通常在图的学习过程中没有被共同利用。因此，本文通过提出一种在协方差矩阵上具有低秩结构约束的图学习的灵活算法框架来解决这个问题。该问题被表达为基于最大似然估计的罚函数方法，其中协方差矩阵可以选择性地被约束为低秩加对角线结构（低秩因子模型）。然后，我们利用正定矩阵和固定秩正半定矩阵的几何特性（这些特性非常适用于椭圆模型）来解决这类问题中的最优化问题。数值实验

    Graphical models and factor analysis are well-established tools in multivariate statistics. While these models can be both linked to structures exhibited by covariance and precision matrices, they are generally not jointly leveraged within graph learning processes. This paper therefore addresses this issue by proposing a flexible algorithmic framework for graph learning under low-rank structural constraints on the covariance matrix. The problem is expressed as penalized maximum likelihood estimation of an elliptical distribution (a generalization of Gaussian graphical models to possibly heavy-tailed distributions), where the covariance matrix is optionally constrained to be structured as low-rank plus diagonal (low-rank factor model). The resolution of this class of problems is then tackled with Riemannian optimization, where we leverage geometries of positive definite matrices and positive semi-definite matrices of fixed rank that are well suited to elliptical models. Numerical experi
    
[^21]: 可争议神经网络的因果发现与知识注入

    Causal Discovery and Knowledge Injection for Contestable Neural Networks. (arXiv:2205.09787v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09787](http://arxiv.org/abs/2205.09787)

    本研究提出了一种可以进行双向互动的方法，通过允许神经网络展示其所学因果图，并允许人类修改因果图后重新注入机器中，从而提供了一种调试神经网络的方式，实验结果显示该方法可以显著改善预测性能。

    

    神经网络在解决机器学习任务方面表现出色，但它们是否学习到了相关的因果关系尚不清楚，而它们的黑箱特性使得模型构建者难以理解和调试。我们提出了一种新颖的方法来解决这些问题，通过允许神经网络驱动的机器展示其所学因果图，并允许人类修改因果图后重新注入机器中，实现双向互动。所学模型保证符合因果图并遵循专家知识，其中部分知识也可以事先给定。通过对模型行为进行可视化并实现知识注入，我们的方法允许从数据中发现因果结构并支撑预测的从业者进行调试。在真实和合成表格数据上的实验表明，我们的方法可以改进预测性能高达2.4倍。

    Neural networks have proven to be effective at solving machine learning tasks but it is unclear whether they learn any relevant causal relationships, while their black-box nature makes it difficult for modellers to understand and debug them. We propose a novel method overcoming these issues by allowing a two-way interaction whereby neural-network-empowered machines can expose the underpinning learnt causal graphs and humans can contest the machines by modifying the causal graphs before re-injecting them into the machines. The learnt models are guaranteed to conform to the graphs and adhere to expert knowledge, some of which can also be given up-front. By building a window into the model behaviour and enabling knowledge injection, our method allows practitioners to debug networks based on the causal structure discovered from the data and underpinning the predictions. Experiments with real and synthetic tabular data show that our method improves predictive performance up to 2.4x while pr
    
[^22]: 通过投影功率方法进行相关维格纳模型的有种子图匹配

    Seeded graph matching for the correlated Wigner model via the projected power method. (arXiv:2204.04099v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2204.04099](http://arxiv.org/abs/2204.04099)

    本文研究了在相关维格纳模型下的有种子图匹配问题，通过分析表明，使用投影功率方法（PPM）作为图匹配算法可以在给定接近真实匹配的种子的情况下高概率地改进种子并恢复真实匹配。

    

    在图匹配问题中，我们观察两个图G和H，并通过最大化边协议的一些度量来找到它们顶点之间的赋值（或匹配）。我们假设观察到的图对G和H是从相关维格纳模型中抽取的，这是一个用于相关加权图的流行模型，其中G和H的邻接矩阵的元素是独立的高斯分布，并且G的每条边与H的其中一条边（由未知的匹配确定）相关联，边相关性由参数σ∈[0,1)描述。在本文中，我们分析了作为“有种子”的图匹配算法的“投影功率方法”（PPM）的性能，其中我们提供一个部分正确的初始匹配（称为种子）作为附加信息。我们证明，如果种子足够接近真实匹配，则PPM在高概率下会迭代改进种子并恢复真实匹配（或恢复最大化边协议）。

    In the \emph{graph matching} problem we observe two graphs $G,H$ and the goal is to find an assignment (or matching) between their vertices such that some measure of edge agreement is maximized. We assume in this work that the observed pair $G,H$ has been drawn from the correlated Wigner model -- a popular model for correlated weighted graphs -- where the entries of the adjacency matrices of $G$ and $H$ are independent Gaussians and each edge of $G$ is correlated with one edge of $H$ (determined by the unknown matching) with the edge correlation described by a parameter $\sigma\in [0,1)$. In this paper, we analyse the performance of the \emph{projected power method} (PPM) as a \emph{seeded} graph matching algorithm where we are given an initial partially correct matching (called the seed) as side information. We prove that if the seed is close enough to the ground-truth matching, then with high probability, PPM iteratively improves the seed and recovers the ground-truth matching (eithe
    
[^23]: 深度批量主动学习回归的框架和基准

    A Framework and Benchmark for Deep Batch Active Learning for Regression. (arXiv:2203.09410v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.09410](http://arxiv.org/abs/2203.09410)

    本研究提出了一个深度批量主动学习回归的框架和基准测试，其中包括许多现有的贝叶斯和非贝叶斯方法。提出了一种替换常用最后一层特征的新方法，并结合一种新颖的聚类方法。在15个大型表格回归数据集上进行测试，该方法在基准测试中表现优异，适用于大型数据集且易于使用。

    

    标注监督学习数据的获取成本较高。为了提高神经网络回归的样本效率，我们研究了自适应选择无标签数据批次进行标注的主动学习方法。我们提出了一个框架，用于构建这样的方法，基于(网络相关的)基础核、核变换和选择方法。我们的框架包括许多现有的基于高斯过程逼近神经网络的贝叶斯方法以及非贝叶斯方法。此外，我们建议用描绘有限宽度神经正切核替换常用的最后一层特征，并将它们与一种新颖的聚类方法相结合。为了评估不同的方法，我们介绍了一个由15个大型表格回归数据集组成的开放源代码的基准测试。我们提出的方法在基准测试中优于现有技术水平，适用于大型数据集，并且可以直接使用，无需调整网络架构或训练。

    The acquisition of labels for supervised learning can be expensive. In order to improve the sample-efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian Process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width Neural Tangent Kernels, and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or traini
    
[^24]: AgraSSt: 适用于解释性评估隐式图生成器的近似图斯坦统计方法

    AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment of Implicit Graph Generators. (arXiv:2203.03673v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.03673](http://arxiv.org/abs/2203.03673)

    AgraSSt是一种用于评估隐式图生成器质量的统计方法，通过构建基于核的差异度量，它能够确定学习到的图生成过程是否能生成类似给定输入图的图形，并提供有关图生成器训练过程的可解释性问题和可靠样本批次的信息。

    

    我们提出并分析了一种新的统计方法，称为AgraSSt，用于评估可能不存在显式形式的图生成器的质量。特别地，AgraSSt可用于确定学习到的图生成过程能否生成类似给定输入图的图形。受随机图的斯坦操纵符启发，AgraSSt的关键思想是基于从图生成器获得的操作符构建基于核的差异度量。AgraSSt可以为图生成器训练过程提供可解释的问题，并帮助识别可靠的样本批次用于下游任务。利用斯坦的方法，我们对广泛的随机图模型给出了理论保证。我们在已知图生成过程的合成输入图和最先进的（深度）图生成模型训练的真实世界输入图上提供了实证结果。

    We propose and analyse a novel statistical procedure, coined AgraSSt, to assess the quality of graph generators that may not be available in explicit form. In particular, AgraSSt can be used to determine whether a learnt graph generating process is capable of generating graphs that resemble a given input graph. Inspired by Stein operators for random graphs, the key idea of AgraSSt is the construction of a kernel discrepancy based on an operator obtained from the graph generator. AgraSSt can provide interpretable criticisms for a graph generator training procedure and help identify reliable sample batches for downstream tasks. Using Stein`s method we give theoretical guarantees for a broad class of random graph models. We provide empirical results on both synthetic input graphs with known graph generation procedures, and real-world input graphs that the state-of-the-art (deep) generative models for graphs are trained on.
    
[^25]: 不同输入维度数据集之间的迁移学习：线性回归情况下的算法和分析

    Transfer-Learning Across Datasets with Different Input Dimensions: An Algorithm and Analysis for the Linear Regression Case. (arXiv:2202.05069v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.05069](http://arxiv.org/abs/2202.05069)

    本文提出了一种适用于线性回归情况的迁移学习算法，该算法能够将新数据与历史数据相结合，特别在新数据稀缺的情况下具有益处，并且在实验验证中表现出对负迁移学习的鲁棒性。

    

    随着新传感器和监测设备的发展，越来越多的数据源可以作为机器学习模型的输入。这些数据既可以帮助提高模型的准确性，但将这些新输入与历史数据相结合仍然是一个尚未详细研究的挑战。在本文中，我们提出了一种迁移学习算法，将新数据和历史数据结合起来，特别在新数据稀缺的情况下具有益处。我们将重点放在线性回归情况下，这使得我们能够对该方法的益处进行严格的理论研究。我们表明我们的方法对负迁移学习是具有鲁棒性的，并通过真实和模拟数据进行了实证验证。

    With the development of new sensors and monitoring devices, more sources of data become available to be used as inputs for machine learning models. These can on the one hand help to improve the accuracy of a model. On the other hand however, combining these new inputs with historical data remains a challenge that has not yet been studied in enough detail. In this work, we propose a transfer-learning algorithm that combines the new and the historical data, that is especially beneficial when the new data is scarce. We focus the approach on the linear regression case, which allows us to conduct a rigorous theoretical study on the benefits of the approach. We show that our approach is robust against negative transfer-learning, and we confirm this result empirically with real and simulated data.
    
[^26]: 多元极值的谱学习

    Spectral learning of multivariate extremes. (arXiv:2111.07799v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.07799](http://arxiv.org/abs/2111.07799)

    我们提出了一种用于分析多元极值的谱聚类算法，并通过理论和数值实验展示了其在学习角度测度方面的性能。

    

    我们提出了一种用于分析多元极值的谱聚类算法。具体而言，我们关注极值理论中由角度或谱测度表征的多元极值的渐近依赖性。我们的工作研究了谱聚类的理论性能，该聚类基于从极值样本中构建的随机k最近邻图，即对于半径超过一个较大阈值的随机向量的角度部分。具体而言，我们推导出线性因子模型产生的极值的渐近分布，并证明，在某些条件下，谱聚类可以一致地识别出在该模型中产生的极值的聚类。基于这个结果，我们提出了一种简单的一致性估计策略来学习角度测度。我们的理论结果与数值实验相结合，展示了我们方法在有限样本情况下的性能。

    We propose a spectral clustering algorithm for analyzing the dependence structure of multivariate extremes. More specifically, we focus on the asymptotic dependence of multivariate extremes characterized by the angular or spectral measure in extreme value theory. Our work studies the theoretical performance of spectral clustering based on a random $k$-nearest neighbor graph constructed from an extremal sample, i.e., the angular part of random vectors for which the radius exceeds a large threshold. In particular, we derive the asymptotic distribution of extremes arising from a linear factor model and prove that, under certain conditions, spectral clustering can consistently identify the clusters of extremes arising in this model. Leveraging this result we propose a simple consistent estimation strategy for learning the angular measure. Our theoretical findings are complemented with numerical experiments illustrating the finite sample performance of our methods.
    
[^27]: 综合条件估计-优化

    Integrated Conditional Estimation-Optimization. (arXiv:2110.12351v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.12351](http://arxiv.org/abs/2110.12351)

    该论文提出了一种综合条件估计-优化（ICEO）框架，可以在考虑优化问题结构的同时估计随机参数的条件分布，并提供了一些性能保证。

    

    许多实际优化问题涉及具有概率分布的不确定参数，可以使用上下文特征信息进行估计。与先估计不确定参数的分布然后基于估计优化目标的标准方法相反，我们提出了一种综合条件估计-优化（ICEO）框架，该框架在考虑优化问题结构的同时估计随机参数的条件分布。我们直接建模随机参数的条件分布与上下文特征之间的关系，然后用与下游优化问题一致的目标估计概率模型。我们证明了我们的ICEO方法在适度规则条件下是渐进一致的，并进一步提供了一些推广界限形式的有限性能保证。计算上，使用

    Many real-world optimization problems involve uncertain parameters with probability distributions that can be estimated using contextual feature information. In contrast to the standard approach of first estimating the distribution of uncertain parameters and then optimizing the objective based on the estimation, we propose an integrated conditional estimation-optimization (ICEO) framework that estimates the underlying conditional distribution of the random parameter while considering the structure of the optimization problem. We directly model the relationship between the conditional distribution of the random parameter and the contextual features, and then estimate the probabilistic model with an objective that aligns with the downstream optimization problem. We show that our ICEO approach is asymptotically consistent under moderate regularity conditions and further provide finite performance guarantees in the form of generalization bounds. Computationally, performing estimation with
    
[^28]: 无岭回归中双下降峰的普遍性研究

    On the Universality of the Double Descent Peak in Ridgeless Regression. (arXiv:2010.01851v8 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.01851](http://arxiv.org/abs/2010.01851)

    我们证明了在无岭线性回归中存在一个双下降峰，无论输入分布的特征映射是确定性的还是随机的，都会导致期望均方泛化误差增加。并且我们的结果适用于广泛的输入分布类。

    

    我们证明了在无岭线性回归中由标签噪声引起的期望均方泛化误差的非渐近非分布相关下界。我们的下界将类似的已知结果推广到超参数化（插值）区域。与大多数前期工作不同，我们的分析适用于具有几乎必然完全秩特征矩阵的广泛输入分布类，这使我们能够覆盖各种确定性或随机特征映射类型。我们的下界是渐近尖锐的，并且意味着在存在标签噪声的情况下，无岭线性回归在任何这些特征映射的插值阈值周围表现不佳。我们详细分析了所施加的假设，并为解析（随机）特征映射提供了理论。利用这个理论，我们可以证明我们的假设对具有（勒贝格）密度的输入分布以及由分析激活函数给出的随机深度神经网络的特征映射成立。

    We prove a non-asymptotic distribution-independent lower bound for the expected mean squared generalization error caused by label noise in ridgeless linear regression. Our lower bound generalizes a similar known result to the overparameterized (interpolating) regime. In contrast to most previous works, our analysis applies to a broad class of input distributions with almost surely full-rank feature matrices, which allows us to cover various types of deterministic or random feature maps. Our lower bound is asymptotically sharp and implies that in the presence of label noise, ridgeless linear regression does not perform well around the interpolation threshold for any of these feature maps. We analyze the imposed assumptions in detail and provide a theory for analytic (random) feature maps. Using this theory, we can show that our assumptions are satisfied for input distributions with a (Lebesgue) density and feature maps given by random deep neural networks with analytic activation functi
    
[^29]: 使用深度学习的集成多时间尺度建模进行太阳辐照度预测

    An Integrated Multi-Time-Scale Modeling for Solar Irradiance Forecasting Using Deep Learning. (arXiv:1905.02616v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1905.02616](http://arxiv.org/abs/1905.02616)

    本研究提出了一种使用深度学习方法进行太阳辐照度预测的统一架构，能够在不同时间尺度上进行预测，并提出了一个框架来将这种方法扩展到每小时预测范围。

    

    针对短期太阳辐照度预测，传统的点预测方法由于太阳能功率的非平稳特性而变得不太有用。由于太阳能的变动性，需要更多的运行备用来确保电网的可靠运行。发电不确定性越大，运行备用需求越大，这将导致运行成本的增加。在这项研究工作中，我们提出了一种使用递归神经网络（RNN）和长短时记忆网络（LSTM）进行多时间尺度预测的统一架构，用于预测每天内的太阳辐照度。本文还提出了一个框架，将这种建模方法扩展到每小时预测范围，从而实现多时间范围的预测，能够预测每小时和每天的太阳辐照度。我们开发了一个端到端的流程来实施提出的架构。

    For short-term solar irradiance forecasting, the traditional point forecasting methods are rendered less useful due to the non-stationary characteristic of solar power. The amount of operating reserves required to maintain reliable operation of the electric grid rises due to the variability of solar energy. The higher the uncertainty in the generation, the greater the operating-reserve requirements, which translates to an increased cost of operation. In this research work, we propose a unified architecture for multi-time-scale predictions for intra-day solar irradiance forecasting using recurrent neural networks (RNN) and long-short-term memory networks (LSTMs). This paper also lays out a framework for extending this modeling approach to intra-hour forecasting horizons thus, making it a multi-time-horizon forecasting approach, capable of predicting intra-hour as well as intra-day solar irradiance. We develop an end-to-end pipeline to effectuate the proposed architecture. The performanc
    
[^30]: 在学习黑盒模型的增加性解释时需要考虑的问题

    Considerations When Learning Additive Explanations for Black-Box Models. (arXiv:1801.08640v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1801.08640](http://arxiv.org/abs/1801.08640)

    本文研究了非增加型模型的全局增加性解释方法，发现不同的解释方法以不同的方式刻画了黑盒模型预测函数中的非增加性成分。尽管精简的解释一般是最准确的增加性解释，但显式建模非增加性成分的树形解释往往更准确。机器学习从业者能够更好地利用增加性解释来完成各种任务。

    

    许多解释黑盒模型的方法，无论是局部还是全局的，都是增加型的。本文研究了非增加型模型的全局增加性解释，重点关注四种解释方法：局部依赖、适应全局环境的Shapley解释、精简的增加性解释和基于梯度的解释。我们展示了不同的解释方法以不同的方式刻画了黑盒模型预测函数中的非增加性成分。我们使用主效应和总效应的概念来锚定增加性解释，并定量评估增加性和非增加性解释。尽管精简的解释一般是最准确的增加性解释，但显式建模非增加性成分的树形解释往往更准确。尽管如此，我们的用户研究表明，机器学习从业者能够更好地利用增加性解释来完成各种任务。

    Many methods to explain black-box models, whether local or global, are additive. In this paper, we study global additive explanations for non-additive models, focusing on four explanation methods: partial dependence, Shapley explanations adapted to a global setting, distilled additive explanations, and gradient-based explanations. We show that different explanation methods characterize non-additive components in a black-box model's prediction function in different ways. We use the concepts of main and total effects to anchor additive explanations, and quantitatively evaluate additive and non-additive explanations. Even though distilled explanations are generally the most accurate additive explanations, non-additive explanations such as tree explanations that explicitly model non-additive components tend to be even more accurate. Despite this, our user study showed that machine learning practitioners were better able to leverage additive explanations for various tasks. These considerati
    

