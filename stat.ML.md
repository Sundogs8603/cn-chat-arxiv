# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation.](http://arxiv.org/abs/2401.16421) | 本研究提出一种新的位置编码方法，胆层位置编码（BiPE），通过将分段内编码和分段间编码结合起来，以提高模型对语义信息的捕捉和推测能力。实验证明，BiPE在不同文本模态的任务中具有优越的长度推测能力。 |
| [^2] | [Semi-parametric Expert Bayesian Network Learning with Gaussian Processes and Horseshoe Priors.](http://arxiv.org/abs/2401.16419) | 本文提出了一种半参数专家贝叶斯网络学习模型，利用高斯过程和Horseshoe先验引入最小的非线性组件，优化了差分Horseshoe尺度，通过生成多样的图来适应用户输入，解决可辨识性问题并增强可解释性，在合成和真实数据集上的评估结果表明该模型优于最先进的半参数贝叶斯网络模型。 |
| [^3] | [Boolean Logic as an Error feedback mechanism.](http://arxiv.org/abs/2401.16418) | 本研究提出了将布尔逻辑用作神经网络的错误反馈机制，并进行了收敛性分析。 |
| [^4] | [ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift.](http://arxiv.org/abs/2401.16410) | 本文提出了一种名为ReTaSA的非参数正则化方法，用于解决连续目标分布偏移问题，通过估计重要权重函数来解决该问题。 |
| [^5] | [Is K-fold cross validation the best model selection method for Machine Learning?.](http://arxiv.org/abs/2401.16407) | K折交叉验证在机器学习中是常用的模型选择方法，但在处理小样本数据集和异质数据源时存在困难。 |
| [^6] | [Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF.](http://arxiv.org/abs/2401.16335) | 这篇论文提出了一种称为“迭代数据平滑”的改进奖励学习算法，用于减轻强化学习从人类反馈中的过拟合和过优化问题。通过在每个训练轮次中更新模型和数据，并用软标签替换硬标签，该方法表现出优越性能。 |
| [^7] | [Prepare Non-classical Collective Spin State by Reinforcement Learning.](http://arxiv.org/abs/2401.16320) | 通过强化学习设计控制场的方案成功生成了非经典态，以应用于自旋压缩态的产生。该方法在保持压缩和纠缠的同时提供了不同的控制序列，并观察到控制脉冲密集应用可以提高结果的性能。 |
| [^8] | [Dual feature-based and example-based explanation methods.](http://arxiv.org/abs/2401.16294) | 该论文提出了一种基于双特征和基于示例的解释方法，通过选择凸包来对实例进行双重表示，并使用简单的矩阵计算来计算解释特征的重要性值。 |
| [^9] | [Probabilistic Guarantees of Stochastic Recursive Gradient in Non-Convex Finite Sum Problems.](http://arxiv.org/abs/2401.15890) | 本文提出了一种新的无维度边界，为随机递归梯度算法Prob-SARAH在非凸有限和问题中提供了高概率保证。实验结果表明Prob-SARAH在真实数据集上具有优秀的概率性能。 |
| [^10] | [Sliced Wasserstein with Random-Path Projecting Directions.](http://arxiv.org/abs/2401.15889) | 本研究提出了一种无需优化的切片分布方法，该方法能够快速进行蒙特卡洛期望估计。通过利用随机向量之间的归一化差异构建随机路径投影方向，从而得到了随机路径切片分布和两个切片瓦瑟斯坦的变种。这种方法在拓扑、统计和计算性质上有重要意义。 |
| [^11] | [lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap.](http://arxiv.org/abs/2401.15879) | 本文提出了一种名为lil'HDoC的算法，用于解决小阈值间隙下的好臂识别问题。实验证明该算法在样本效率上优于现有算法。 |
| [^12] | [Meta-Learning for Neural Network-based Temporal Point Processes.](http://arxiv.org/abs/2401.15846) | 本论文提出了一种基于神经网络的元学习方法，用于预测人类活动相关事件的发生。该方法通过循环神经网络将短序列嵌入到隐藏表示中，并利用这些表示进行预测。这种方法解决了长序列不可用和长期预测困难的问题。 |
| [^13] | [Distributed Markov Chain Monte Carlo Sampling based on the Alternating Direction Method of Multipliers.](http://arxiv.org/abs/2401.15838) | 本文提出了一种基于交替方向乘子法的分布式抽样方案，能够在分布式环境中进行马尔可夫链蒙特卡罗抽样，从而实现贝叶斯推断任务中的不确定性量化。实验证明该方案优于现有方法。 |
| [^14] | [On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension.](http://arxiv.org/abs/2401.15801) | 这篇论文研究了用于低固有数据维度的生成对抗模型的统计属性，提出了关于估计密度的统计保证，涉及数据和潜空间的内在维度，并证明了估计结果与目标的期望Wasserstein-1距离的缩放关系。 |
| [^15] | [Provably Stable Feature Rankings with SHAP and LIME.](http://arxiv.org/abs/2401.15800) | 这项研究提出了一种通过利用多重假设检验的思想，来设计可靠地排名机器学习模型中最重要特征的特征归因方法，旨在解决SHAP和LIME等常用方法由于随机采样导致的高度不稳定性问题。实验证明了该方法的有效性和计算效率。 |
| [^16] | [High-Dimensional False Discovery Rate Control for Dependent Variables.](http://arxiv.org/abs/2401.15796) | 提出了一个新框架，在高维度相关变量情况下实现虚警率控制，通过综合层次图模型在T-Rex框架中利用依赖结构，利用鞅论证明变量惩罚机制确保了FDR的控制。 |
| [^17] | [Sample Complexity of the Sign-Perturbed Sums Identification Method: Scalar Case.](http://arxiv.org/abs/2401.15792) | 本文研究了Sign-Perturbed Sum (SPS)识别方法的样本复杂性，特别是在标量线性回归问题中，通过分析其置信区间的行为。研究结果表明，如果观测噪声是次高斯的话，SPS置信区间的大小以几何速率缩小到真实参数的附近。 |
| [^18] | [Improving Kernel-Based Nonasymptotic Simultaneous Confidence Bands.](http://arxiv.org/abs/2401.15791) | 本文改进了基于内核的非渐近同时置信带的构建方法，通过放宽噪声假设、改进目标函数范数估计和加强隐含凸优化问题约束来提升了构建的效果。 |
| [^19] | [Bayesian Nonparametrics meets Data-Driven Robust Optimization.](http://arxiv.org/abs/2401.15771) | 本文提出了一种将贝叶斯非参数方法与最新的决策理论模型相结合的鲁棒优化准则，通过这种方法，可以在线性回归问题中获得有稳定性和优越性能的结果。 |
| [^20] | [Ensemble-Based Annealed Importance Sampling.](http://arxiv.org/abs/2401.15645) | 本文提出了一种基于集合的退火重要性抽样算法，通过结合人口蒙特卡洛方法来提高抽样效率，并利用集合的相互作用促进未发现模态的探索。 |
| [^21] | [GT-PCA: Effective and Interpretable Dimensionality Reduction with General Transform-Invariant Principal Component Analysis.](http://arxiv.org/abs/2401.15623) | GT-PCA是一种高效且可解释的主成分分析的降维方法，与具体转换不变，能显著优于其他方法。 |
| [^22] | [Prevalidated ridge regression is a highly-efficient drop-in replacement for logistic regression for high-dimensional data.](http://arxiv.org/abs/2401.15610) | 本论文提出了一种预验证的岭回归模型，该模型在高维数据中与逻辑回归非常接近，但具有更高的计算效率和几乎没有超参数。它通过利用在拟合过程中计算得到的数量来缩放模型系数，并最小化一组预验证预测的对数损失。 |
| [^23] | [Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization.](http://arxiv.org/abs/2401.15604) | 本文提出了基于神经网络的扩散模型中分数估计的优化和泛化方法，并建立了对分数估计进行分析的数学框架。 |
| [^24] | [Matrix Supermartingales and Randomized Matrix Concentration Inequalities.](http://arxiv.org/abs/2401.15567) | 本文提出了针对鞅相关或可交换随机对称矩阵的新集中不等式，这些不等式在多种尾条件下成立，在洛伊纳顺序表示，并且有时在任意数据相关停止时间都适用。 |
| [^25] | [On the Robustness of Cross-Concentrated Sampling for Matrix Completion.](http://arxiv.org/abs/2401.15566) | 本文研究了交叉集中采样（CCS）模型在矩阵补全中的鲁棒性，提出了一种高效的非凸迭代算法（RCURC），并通过实验验证了其在合成和真实数据集上的效果。 |
| [^26] | [Oracle-Efficient Hybrid Online Learning with Unknown Distribution.](http://arxiv.org/abs/2401.15520) | 本文研究了未知分布下的Oracle-Efficient混合在线学习问题，并提出了计算高效的在线预测器，它在有限的VC类和具有特定维度的类中分别实现了次线性的遗憾上界。此外，还将结果推广到了具有分布改变的情况，并建立了相应的遗憾界。 |
| [^27] | [Differentially Private Bayesian Tests.](http://arxiv.org/abs/2401.15502) | 本文提出了一种差分隐私贝叶斯检验框架，利用规范化的数据生成机制来进行推断，并避免了对完整数据生成机制的建模需求。该框架具有可解释性，并在计算上具有实质性的优势。 |
| [^28] | [Data-Driven Estimation of the False Positive Rate of the Bayes Binary Classifier via Soft Labels.](http://arxiv.org/abs/2401.15500) | 本文提出了一种数据驱动的方法，通过软标签对贝叶斯二分类器的误报率进行估计，并考虑了软标签和有噪声标签的情况。 |
| [^29] | [Continuous Treatment Effect Estimation Using Gradient Interpolation and Kernel Smoothing.](http://arxiv.org/abs/2401.15447) | 本文提出了一种使用梯度插值和核平滑的方法，用于个性化连续处理效果估计。通过增加独立采样的处理和推断的反事实结果来处理训练数据中的混淆问题。实验证明该方法在反事实预测性能上优于其他六种最先进的方法。 |
| [^30] | [Asymptotic Behavior of Adversarial Training Estimator under $\ell_\infty$-Perturbation.](http://arxiv.org/abs/2401.15262) | 本文研究了在$\ell_\infty$-扰动下的对抗性训练，证明当真实参数为0时，对抗性训练估计器在该扰动下的极限分布可能在0处有一个正概率质量，提供了稀疏性恢复能力的理论保证，并提出了一种两步过程——自适应对抗性训练，可以进一步提高性能。 |
| [^31] | [Finite Sample Confidence Regions for Linear Regression Parameters Using Arbitrary Predictors.](http://arxiv.org/abs/2401.15254) | 本文提出了一种新的方法，利用任意预测器构建线性模型参数的有限样本置信区间。该方法对噪声的要求很少，并且适用于严格线性函数偏差一定阈值的函数。这种方法能够进行鲁棒优化，并提取特定参数坐标的置信区间，也能用于假设检验。 |
| [^32] | [Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective.](http://arxiv.org/abs/2401.15248) | 该论文从理论角度探讨了在预训练中通过对抗训练改进表示的思路，并证明了特征净化在预训练模型的对抗鲁棒性和下游任务之间起到重要作用。 |
| [^33] | [FDR-Controlled Portfolio Optimization for Sparse Financial Index Tracking.](http://arxiv.org/abs/2401.15139) | 本论文提出了一种扩展的T-Rex框架，用于在稀疏金融指数跟踪中选择少数相关变量，并通过集成最近邻惩罚机制，可靠控制误发现率（FDR）。实验证明了该方法在过去20年内基于少量股票准确跟踪标准普尔500指数的能力。 |
| [^34] | [A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics.](http://arxiv.org/abs/2401.15122) | 提出了一种能够促进数值MD模拟并有效模拟蛋白质-配体结合动力学的NeuralMD方法，采用物理信息多级对称框架，实现了准确建模多级蛋白质-配体相互作用。 |
| [^35] | [A note on the capacity of the binary perceptron.](http://arxiv.org/abs/2401.15092) | 该论文研究了二进制感知机的容量问题，在确定了上界和下界后，给出了证明该容量小于0.847的条件一阶矩方法与已知结果的结合。 |
| [^36] | [Estimation of partially known Gaussian graphical models with score-based structural priors.](http://arxiv.org/abs/2401.14340) | 本论文提出了一种基于得分结构先验的算法，用于估计部分已知高斯图模型。通过使用图神经网络来估计图的得分函数，我们可以在生成样本时利用退火朗格维能扩散，从而更准确地估计后验分布。数值实验表明，我们的方法具有明显的优势。 |
| [^37] | [DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport.](http://arxiv.org/abs/2401.13112) | 本文提出了使用最优传输进行分布式对抗解释的方法DISCOUNT，将对抗解释的概念扩展到整个输入输出分布，并通过统计置信度来支撑这一方法。 |
| [^38] | [Deep multitask neural networks for solving some stochastic optimal control problems.](http://arxiv.org/abs/2401.12923) | 本文针对某些难以模拟底层状态变量的随机最优控制问题，引入了使用多任务神经网络的有效解决方案，并通过实验证明了该方法的优越性。 |
| [^39] | [A Good Score Does not Lead to A Good Generative Model.](http://arxiv.org/abs/2401.04856) | 本文通过反例证明，在某些情况下，即使评分函数学习良好，基于评分的生成模型（SGMs）仍然无法生成接近真实数据分布的样本，并且只能产生训练数据点的高斯模糊样本。 |
| [^40] | [Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint.](http://arxiv.org/abs/2312.11456) | 该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。 |
| [^41] | [The sample complexity of multi-distribution learning.](http://arxiv.org/abs/2312.04027) | 本文解决了多分布学习的样本复杂度问题，并给出了匹配下界的样本复杂度算法。 |
| [^42] | [Imputation using training labels and classification via label imputation.](http://arxiv.org/abs/2311.16877) | 本论文提出一种在填充缺失数据时将标签与输入堆叠的方法，能够显著提高填充效果，并同时填充标签和输入。该方法适用于各种类型的数据，且在实验证明具有有希望的准确性结果。 |
| [^43] | [Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes.](http://arxiv.org/abs/2311.08149) | 本文提出了一种深度生成模型的时间序列方法，利用潜在时间过程来模拟复杂疾病轨迹。通过结合医学知识和半监督方法，该方法可以解释和全面分析疾病轨迹，并用于进一步的数据分析和临床假设测试。 |
| [^44] | [Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems.](http://arxiv.org/abs/2309.13349) | 本文提出了一种能够在进化算法执行中选择适当的近似函数成本的技术，用于加速解决黑盒优化问题。 |
| [^45] | [Scalable neural network models and terascale datasets for particle-flow reconstruction.](http://arxiv.org/abs/2309.06782) | 本研究针对高能电子-正电子碰撞中的粒子流重建，使用可扩展的机器学习模型，并通过超参数调优和硬件处理器的高度可移植性，取得了真实且具有竞争力的物理性能。 |
| [^46] | [Unified Transfer Learning Models for High-Dimensional Linear Regression.](http://arxiv.org/abs/2307.00238) | UTrans是一种统一转移学习模型，它能检测可转移变量和源数据，并具有较低的估计和预测误差，同时保持可解释性。 |
| [^47] | [AdaStop: sequential testing for efficient and reliable comparisons of Deep RL Agents.](http://arxiv.org/abs/2306.10882) | AdaStop是一种基于多组序列测试的新统计测试方法，可用于比较多个深度强化学习算法来解决实验结果可复制性的问题。 |
| [^48] | [Partial Identification of Causal Effects Using Proxy Variables.](http://arxiv.org/abs/2304.04374) | 这篇论文提出了一种无需完备性的部分识别方法，它为我们提供了一组界限，用于在未能控制混淆因素的情形下，评估治疗对结果变量因果效应。 |
| [^49] | [Strong identifiability and parameter learning in regression with heterogeneous response.](http://arxiv.org/abs/2212.04091) | 本文研究了混合回归模型中的强可辨识性条件、参数估计的收敛速度和贝叶斯后验收缩行为，适用于常见的链函数和条件分布族。 |
| [^50] | [Fully Stochastic Trust-Region Sequential Quadratic Programming for Equality-Constrained Optimization Problems.](http://arxiv.org/abs/2211.15943) | 本文提出了一种完全随机的信任区间顺序二次规划算法(TR-StoSQP)，用于解决非线性优化问题，其中包含随机目标和确定性等式约束。该算法通过自适应选择信任区间半径，并允许使用未经修改的Hessian矩阵，在SQP子问题中应对不可行性问题。为了控制试验步长的长度并保证尺度不变性，作者采用自适应的松弛技术计算试验步长。 |
| [^51] | [Offline Estimation of Controlled Markov Chains: Minimaxity and Sample Complexity.](http://arxiv.org/abs/2211.07092) | 本论文研究了离线估计有限控制马尔可夫链的转移概率矩阵的非参数估计器，并通过记录策略的混合特性建立了样本复杂性界限和最小化条件。结果表明，实现特定的统计风险界限涉及到混合特性的强度和样本数量之间微妙而有趣的权衡。还使用这些样本复杂性界限建立了离线评估恒定马尔可夫控制策略的相关界限。 |
| [^52] | [Federated Offline Reinforcement Learning.](http://arxiv.org/abs/2206.05581) | 本文提出了一种联邦离线强化学习算法，可以处理医疗机构间数据共享的隐私限制和异质性问题，同时提供了通信效率和隐私保护性。该算法的样本复杂度证明以及在现实医学数据集上的模拟实验结果表明了其有效性和效率。 |
| [^53] | [AugLoss: A Robust Augmentation-based Fine Tuning Methodology.](http://arxiv.org/abs/2206.02286) | AugLoss是一种简单而有效的方法，通过统一数据增强和稳健损失函数，实现了对训练时的噪声标注和测试时的特征分布转移的稳健性。 |
| [^54] | [Global convergence of optimized adaptive importance samplers.](http://arxiv.org/abs/2201.00409) | 本文分析了用于一般提案的优化自适应重要抽样器（OAIS）的性能，并开发了一个可以全局优化$\chi^2$散度的方案。该方案通过利用非凸优化理论，填补了对于一般提案的全局优化缺失。得到的AIS方案具有显式的理论保证，并且保证在任意时刻均成立。 |
| [^55] | [Computer Vision Self-supervised Learning Methods on Time Series.](http://arxiv.org/abs/2109.00783) | 该研究评估了计算机视觉自监督学习框架在时间序列上的效果，并且提出了一种改进方法，通过改进协方差项和添加迭代归一化层，加速了模型的收敛。 |
| [^56] | [Dynamic covariate balancing: estimating treatment effects over time with potential local projections.](http://arxiv.org/abs/2103.01280) | 本文提出了一种通过动态协变量平衡方法，基于过去历史上潜在结果期望的局部投影，估计面板数据中动态变化的治疗效果，并考虑结果和时间变化的协变量与治疗轨迹的关系以及治疗效应的异质性。研究结果表明该方法具有良好的渐近性质和数值特性，在实证应用中具有优势。 |
| [^57] | [A method to integrate and classify normal distributions.](http://arxiv.org/abs/2012.14331) | 本文介绍了一种可以对任意参数维度下的任意域内正态分布进行积分的方法，提供了法向向量函数的相关概率密度和统计指标，同时还提供了可以对任意数量正态分布进行分类的方法和维度降低和可视化的技术。 |
| [^58] | [View selection in multi-view stacking: Choosing the meta-learner.](http://arxiv.org/abs/2010.16271) | 选择合适的元学习器对于多视角堆叠中的视图选择和分类准确性是非常重要的，通过对七种不同的算法进行评估，非负套索、非负自适应套索和非负弹性网络被认为是最合适的元学习器。 |
| [^59] | [An Intuitive Tutorial to Gaussian Process Regression.](http://arxiv.org/abs/2009.10862) | 《高斯过程回归的直观教程》是一篇介绍高斯过程回归的教程，旨在直观地解释GPR的基本概念、提供实现代码，并回顾最先进的高斯过程算法。适合机器学习初学者阅读，帮助他们清晰理解GPR的基本原理。 |
| [^60] | [Nonasymptotic analysis of Stochastic Gradient Hamiltonian Monte Carlo under local conditions for nonconvex optimization.](http://arxiv.org/abs/2002.05465) | 在非凸优化中，我们提供了随机梯度哈密顿蒙特卡罗（SGHMC）的非渐进性分析，证明了SGHMC作为采样器的关键理论性质，并在局部条件下获得非凸优化问题的非渐进性界限，该方法在迭代次数上可以提供高精度的结果，并以已知最佳速率收敛到全局最小值。 |
| [^61] | [Adversarial Attacks on Graph Neural Networks via Meta Learning.](http://arxiv.org/abs/1902.08412) | 本文通过元梯度方式对图神经网络进行训练时攻击，通过微小的图扰动导致性能下降，并证明了即使在无监督嵌入中也能产生迁移效应。这些攻击不需要任何关于目标分类器的知识或访问权限。 |

# 详细

[^1]: 两种石头击打一只鸟：胆层位置编码以更好地推测长度

    Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation. (arXiv:2401.16421v1 [cs.LG])

    [http://arxiv.org/abs/2401.16421](http://arxiv.org/abs/2401.16421)

    本研究提出一种新的位置编码方法，胆层位置编码（BiPE），通过将分段内编码和分段间编码结合起来，以提高模型对语义信息的捕捉和推测能力。实验证明，BiPE在不同文本模态的任务中具有优越的长度推测能力。

    

    在这项工作中，我们利用语言序列的内在分割，并设计了一种新的位置编码方法，称为胆层位置编码（BiPE）。对于每个位置，我们的BiPE将分段内编码和分段间编码融合在一起。分段内编码用于识别段内位置，并通过绝对位置编码帮助模型捕捉其中的语义信息。分段间编码则用于指定段索引，建模段之间的关系，并旨在通过相对位置编码提高推测能力。理论分析表明，位置信息的解耦使学习更加有效。经验结果还表明，我们的BiPE在不同文本模态的各种任务中具有优越的长度推测能力。

    In this work, we leverage the intrinsic segmentation of language sequences and design a new positional encoding method called Bilevel Positional Encoding (BiPE). For each position, our BiPE blends an intra-segment encoding and an inter-segment encoding. The intra-segment encoding identifies the locations within a segment and helps the model capture the semantic information therein via absolute positional encoding. The inter-segment encoding specifies the segment index, models the relationships between segments, and aims to improve extrapolation capabilities via relative positional encoding. Theoretical analysis shows this disentanglement of positional information makes learning more effective. The empirical results also show that our BiPE has superior length extrapolation capabilities across a wide range of tasks in diverse text modalities.
    
[^2]: 用高斯过程和Horseshoe先验的半参数专家贝叶斯网络学习

    Semi-parametric Expert Bayesian Network Learning with Gaussian Processes and Horseshoe Priors. (arXiv:2401.16419v1 [cs.LG])

    [http://arxiv.org/abs/2401.16419](http://arxiv.org/abs/2401.16419)

    本文提出了一种半参数专家贝叶斯网络学习模型，利用高斯过程和Horseshoe先验引入最小的非线性组件，优化了差分Horseshoe尺度，通过生成多样的图来适应用户输入，解决可辨识性问题并增强可解释性，在合成和真实数据集上的评估结果表明该模型优于最先进的半参数贝叶斯网络模型。

    

    本文提出了一种在专家贝叶斯网络（SEBN）中学习半参数关系的模型，该模型具有线性参数和结构约束。我们使用高斯过程和Horseshoe先验引入最小的非线性组件。为了优先调整专家图而不是添加新边，我们优化了差分Horseshoe尺度。在现实世界的数据集中，我们生成了多样的图以适应用户输入，解决了可辨识性问题并增强了可解释性。使用结构Hamming距离和测试似然等指标在合成和UCI肝病数据集上的评估表明，我们的模型优于最先进的半参数贝叶斯网络模型。

    This paper proposes a model learning Semi-parametric rela- tionships in an Expert Bayesian Network (SEBN) with linear parameter and structure constraints. We use Gaussian Pro- cesses and a Horseshoe prior to introduce minimal nonlinear components. To prioritize modifying the expert graph over adding new edges, we optimize differential Horseshoe scales. In real-world datasets with unknown truth, we gen- erate diverse graphs to accommodate user input, addressing identifiability issues and enhancing interpretability. Evalua- tion on synthetic and UCI Liver Disorders datasets, using metrics like structural Hamming Distance and test likelihood, demonstrates our models outperform state-of-the-art semi- parametric Bayesian Network model.
    
[^3]: 布尔逻辑作为一个错误反馈机制

    Boolean Logic as an Error feedback mechanism. (arXiv:2401.16418v1 [stat.ML])

    [http://arxiv.org/abs/2401.16418](http://arxiv.org/abs/2401.16418)

    本研究提出了将布尔逻辑用作神经网络的错误反馈机制，并进行了收敛性分析。

    

    引入了布尔逻辑反向传播的概念，用于构建具有布尔数字权重和激活的神经网络。大部分计算可以使用布尔逻辑而不是实数算术进行，在训练和推理阶段都可以使用。但是底层的离散优化问题是NP难的，并且布尔逻辑没有保证。本文在标准非凸假设下提出了第一个收敛性分析。

    The notion of Boolean logic backpropagation was introduced to build neural networks with weights and activations being Boolean numbers. Most of computations can be done with Boolean logic instead of real arithmetic, both during training and inference phases. But the underlying discrete optimization problem is NP-hard, and the Boolean logic has no guarantee. In this work we propose the first convergence analysis, under standard non-convex assumptions.
    
[^4]: ReTaSA：一种解决连续目标分布偏移的非参数函数估计方法

    ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift. (arXiv:2401.16410v1 [stat.ML])

    [http://arxiv.org/abs/2401.16410](http://arxiv.org/abs/2401.16410)

    本文提出了一种名为ReTaSA的非参数正则化方法，用于解决连续目标分布偏移问题，通过估计重要权重函数来解决该问题。

    

    分布偏移的存在在将现代机器学习模型部署到实际应用中提出了重要挑战。本文关注回归场景中的目标偏移问题，特别是目标变量 y（也称为响应变量）在训练来源和测试领域中具有不同的边缘分布，而给定 y 的特征 x 的条件分布保持不变。虽然大部分文献集中在有限目标空间的分类任务上，但回归问题具有无限维的目标空间，这使得许多现有方法不适用。在本文中，我们展示了可以通过从一个病态积分方程估计重要权重函数来解决连续目标偏移问题。我们提出了一种非参数正则化方法 ReTaSA 来解决病态积分方程，并提供了理论上的依据。

    The presence of distribution shifts poses a significant challenge for deploying modern machine learning models in real-world applications. This work focuses on the target shift problem in a regression setting (Zhang et al., 2013; Nguyen et al., 2016). More specifically, the target variable y (also known as the response variable), which is continuous, has different marginal distributions in the training source and testing domain, while the conditional distribution of features x given y remains the same. While most literature focuses on classification tasks with finite target space, the regression problem has an infinite dimensional target space, which makes many of the existing methods inapplicable. In this work, we show that the continuous target shift problem can be addressed by estimating the importance weight function from an ill-posed integral equation. We propose a nonparametric regularized approach named ReTaSA to solve the ill-posed integral equation and provide theoretical just
    
[^5]: K折交叉验证是否是机器学习中最好的模型选择方法？

    Is K-fold cross validation the best model selection method for Machine Learning?. (arXiv:2401.16407v1 [stat.ML])

    [http://arxiv.org/abs/2401.16407](http://arxiv.org/abs/2401.16407)

    K折交叉验证在机器学习中是常用的模型选择方法，但在处理小样本数据集和异质数据源时存在困难。

    

    机器学习作为一种能够紧凑表示复杂模式的技术，具有显著的预测推理潜力。K折交叉验证（CV）是确定机器学习结果是否是随机生成的最常用方法，并经常优于传统的假设检验。这种改进利用了直接从机器学习分类中获得的度量，比如准确性，这些度量没有参数描述。为了在机器学习流程中进行频率分析，可以添加排列测试或来自数据分区（即折叠）的简单统计量来估计置信区间。不幸的是，无论是参数化还是非参数化测试都无法解决围绕分割小样本数据集和来自异质数据源的学习固有问题。机器学习严重依赖学习参数和数据在折叠中的分布，这重新概括了熟悉的困难情况。

    As a technique that can compactly represent complex patterns, machine learning has significant potential for predictive inference. K-fold cross-validation (CV) is the most common approach to ascertaining the likelihood that a machine learning outcome is generated by chance and frequently outperforms conventional hypothesis testing. This improvement uses measures directly obtained from machine learning classifications, such as accuracy, that do not have a parametric description. To approach a frequentist analysis within machine learning pipelines, a permutation test or simple statistics from data partitions (i.e. folds) can be added to estimate confidence intervals. Unfortunately, neither parametric nor non-parametric tests solve the inherent problems around partitioning small sample-size datasets and learning from heterogeneous data sources. The fact that machine learning strongly depends on the learning parameters and the distribution of data across folds recapitulates familiar diffic
    
[^6]: 迭代数据平滑：减轻强化学习从人类反馈中过拟合和过优化问题

    Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF. (arXiv:2401.16335v1 [cs.LG])

    [http://arxiv.org/abs/2401.16335](http://arxiv.org/abs/2401.16335)

    这篇论文提出了一种称为“迭代数据平滑”的改进奖励学习算法，用于减轻强化学习从人类反馈中的过拟合和过优化问题。通过在每个训练轮次中更新模型和数据，并用软标签替换硬标签，该方法表现出优越性能。

    

    强化学习从人类反馈中（RLHF）是一种使语言模型与人类中心价值紧密对齐的关键技术。RLHF的初始阶段涉及使用排名数据的奖励模型来学习人类价值观。观察到在一轮训练后，奖励模型的性能会下降，并且过多地优化学习到的奖励模型最终会阻碍真正的目标。本文深入研究了这些问题，并利用理论洞察力设计了改进的奖励学习算法，称为“迭代数据平滑”（IDS）。核心思想是在每个训练轮次中，我们不仅用数据更新模型，还用模型更新数据，用软标签替换硬标签。我们的实证发现突出了这种方法相对于传统方法的优越性能。

    Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that aligns language models closely with human-centric values. The initial phase of RLHF involves learning human values using a reward model from ranking data. It is observed that the performance of the reward model degrades after one epoch of training, and optimizing too much against the learned reward model eventually hinders the true objective. This paper delves into these issues, leveraging the theoretical insights to design improved reward learning algorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that during each training epoch, we not only update the model with the data, but also update the date using the model, replacing hard labels with soft labels. Our empirical findings highlight the superior performance of this approach over the traditional methods.
    
[^7]: 利用强化学习生成非经典集合自旋态的方案

    Prepare Non-classical Collective Spin State by Reinforcement Learning. (arXiv:2401.16320v1 [quant-ph])

    [http://arxiv.org/abs/2401.16320](http://arxiv.org/abs/2401.16320)

    通过强化学习设计控制场的方案成功生成了非经典态，以应用于自旋压缩态的产生。该方法在保持压缩和纠缠的同时提供了不同的控制序列，并观察到控制脉冲密集应用可以提高结果的性能。

    

    我们提出了一种利用强化学习来设计控制场的方案，用于生成非经典态。该方案以应用于开放集体自旋模型中的自旋压缩态为例，其中设计了一个线性控制项来控制动力学。强化学习代理根据以耗散和去相干为特征的环境中的相干自旋态开始，确定了控制脉冲的时间序列。与恒定控制方案相比，这种方法提供了多种控制序列，保持了集体自旋压缩和纠缠。观察到控制脉冲的密集应用可以增强结果的性能。此外，通过添加控制操作，性能得到了轻微增强。所提出的策略在较大系统中展现了更高的效果。对储备热激发对控制结果有不利影响。应该确认这一点。

    We propose a scheme leveraging reinforcement learning to engineer control fields for generating non-classical states. It is exemplified by the application to prepare spin squeezed state for an open collective spin model where a linear control term is designed to govern the dynamics. The reinforcement learning agent determines the temporal sequence of control pulses, commencing from coherent spin state in an environment characterized by dissipation and dephasing. When compared to constant control scenarios, this approach provides various control sequences maintaining collective spin squeezing and entanglement. It is observed that denser application of the control pulses enhances the performance of the outcomes. Furthermore, there is a minor enhancement in the performance by adding control actions. The proposed strategy demonstrates increased effectiveness for larger systems. And thermal excitations of the reservoir are detrimental to the control outcomes. It should be confirmed that thi
    
[^8]: 基于双特征和基于示例的解释方法

    Dual feature-based and example-based explanation methods. (arXiv:2401.16294v1 [cs.LG])

    [http://arxiv.org/abs/2401.16294](http://arxiv.org/abs/2401.16294)

    该论文提出了一种基于双特征和基于示例的解释方法，通过选择凸包来对实例进行双重表示，并使用简单的矩阵计算来计算解释特征的重要性值。

    

    提出了一种新的局部和全局解释方法。该方法基于选取一个在解释实例周围的有限点构造的凸包。凸包使得我们能够以凸组合的形式对实例进行双重表示，这些凸组合由产生的多面体的极点组成。与在欧几里得特征空间中扰动新实例不同，凸组合系数的向量是从单位单纯形中均匀生成的，并且它们形成一个新的双重数据集。在双重数据集上训练双线性代理模型。通过简单的矩阵计算来计算解释特征的重要性值。这种方法可以看作是著名模型LIME的一种修改。双重表示本质上使我们能够获得基于示例的解释。神经添加模型也被视为实现基于示例的解释方法的工具。通过对真实数据集进行许多数值实验来评估该方法。

    A new approach to the local and global explanation is proposed. It is based on selecting a convex hull constructed for the finite number of points around an explained instance. The convex hull allows us to consider a dual representation of instances in the form of convex combinations of extreme points of a produced polytope. Instead of perturbing new instances in the Euclidean feature space, vectors of convex combination coefficients are uniformly generated from the unit simplex, and they form a new dual dataset. A dual linear surrogate model is trained on the dual dataset. The explanation feature importance values are computed by means of simple matrix calculations. The approach can be regarded as a modification of the well-known model LIME. The dual representation inherently allows us to get the example-based explanation. The neural additive model is also considered as a tool for implementing the example-based explanation approach. Many numerical experiments with real datasets are pe
    
[^9]: 非凸有限和问题中随机递归梯度的概率保证

    Probabilistic Guarantees of Stochastic Recursive Gradient in Non-Convex Finite Sum Problems. (arXiv:2401.15890v1 [stat.ML])

    [http://arxiv.org/abs/2401.15890](http://arxiv.org/abs/2401.15890)

    本文提出了一种新的无维度边界，为随机递归梯度算法Prob-SARAH在非凸有限和问题中提供了高概率保证。实验结果表明Prob-SARAH在真实数据集上具有优秀的概率性能。

    

    本文在具有随机个体边界的鞅差序列的求和范数上发展了一种新的无维度Azuma-Hoeffding类型的界限。借助这一创新结果，我们为提出的算法Prob-SARAH中的梯度范数估计提供了高概率界。Prob-SARAH是StochAstic Recursive grAdient algoritHm (SARAH)的改进版本，SARAH是一种现有的方差缩减算法，在期望下的计算复杂度上达到了最优水平。Prob-SARAH的概率复杂度与最优期望结果匹配，差距仅为对数因子。实验结果表明，与其他流行算法相比，Prob-SARAH在真实数据集上具有更优的概率性能。

    This paper develops a new dimension-free Azuma-Hoeffding type bound on summation norm of a martingale difference sequence with random individual bounds. With this novel result, we provide high-probability bounds for the gradient norm estimator in the proposed algorithm Prob-SARAH, which is a modified version of the StochAstic Recursive grAdient algoritHm (SARAH), a state-of-art variance reduced algorithm that achieves optimal computational complexity in expectation for the finite sum problem. The in-probability complexity by Prob-SARAH matches the best in-expectation result up to logarithmic factors. Empirical experiments demonstrate the superior probabilistic performance of Prob-SARAH on real datasets compared to other popular algorithms.
    
[^10]: 带有随机路径投影方向的切片瓦瑟斯坦方法

    Sliced Wasserstein with Random-Path Projecting Directions. (arXiv:2401.15889v1 [stat.ML])

    [http://arxiv.org/abs/2401.15889](http://arxiv.org/abs/2401.15889)

    本研究提出了一种无需优化的切片分布方法，该方法能够快速进行蒙特卡洛期望估计。通过利用随机向量之间的归一化差异构建随机路径投影方向，从而得到了随机路径切片分布和两个切片瓦瑟斯坦的变种。这种方法在拓扑、统计和计算性质上有重要意义。

    

    在应用中，切片分布选择已被用作提高基于最小化切片瓦瑟斯坦距离的参数估计器性能的有效技术。先前的工作要么利用昂贵的优化来选择切片分布，要么使用需要昂贵的抽样方法的切片分布。在这项工作中，我们提出了一种无需优化的切片分布，可以快速进行蒙特卡洛期望估计的抽样。具体来说，我们引入了随机路径投影方向（RPD），它是通过利用两个输入测量中两个随机向量之间的归一化差异构建的。从RPD中，我们得到了随机路径切片分布（RPSD）和两个切片瓦瑟斯坦的变种，即随机路径投影切片瓦瑟斯坦（RPSW）和重要性加权随机路径投影切片瓦瑟斯坦（IWRPSW）。然后我们讨论了拓扑、统计和计算性质。

    Slicing distribution selection has been used as an effective technique to improve the performance of parameter estimators based on minimizing sliced Wasserstein distance in applications. Previous works either utilize expensive optimization to select the slicing distribution or use slicing distributions that require expensive sampling methods. In this work, we propose an optimization-free slicing distribution that provides a fast sampling for the Monte Carlo estimation of expectation. In particular, we introduce the random-path projecting direction (RPD) which is constructed by leveraging the normalized difference between two random vectors following the two input measures. From the RPD, we derive the random-path slicing distribution (RPSD) and two variants of sliced Wasserstein, i.e., the Random-Path Projection Sliced Wasserstein (RPSW) and the Importance Weighted Random-Path Projection Sliced Wasserstein (IWRPSW). We then discuss the topological, statistical, and computational propert
    
[^11]: 小阈值间隙下的好臂识别算法: lil'HDoC

    lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap. (arXiv:2401.15879v1 [cs.LG])

    [http://arxiv.org/abs/2401.15879](http://arxiv.org/abs/2401.15879)

    本文提出了一种名为lil'HDoC的算法，用于解决小阈值间隙下的好臂识别问题。实验证明该算法在样本效率上优于现有算法。

    

    好臂识别（GAI）是一个纯探索性的赌博机问题，在这个问题中，一个单独的学习器会在确定一个臂是好臂时立即输出该臂。好臂被定义为期望回报大于等于给定阈值的臂。本文聚焦于小阈值间隙下的GAI问题，该间隙指的是臂的期望回报与给定阈值之间的距离。我们提出了一种名为lil'HDoC的新算法，显著改善了HDoC算法的总样本复杂度。我们证明了在小阈值间隙下，lil'HDoC算法输出的第一个λ臂的样本复杂度与原始HDoC算法相比仅有微小的差异。大量实验证明我们的算法在合成数据集和真实世界数据集上表现优于最先进的算法。

    Good arm identification (GAI) is a pure-exploration bandit problem in which a single learner outputs an arm as soon as it is identified as a good arm. A good arm is defined as an arm with an expected reward greater than or equal to a given threshold. This paper focuses on the GAI problem under a small threshold gap, which refers to the distance between the expected rewards of arms and the given threshold. We propose a new algorithm called lil'HDoC to significantly improve the total sample complexity of the HDoC algorithm. We demonstrate that the sample complexity of the first $\lambda$ output arm in lil'HDoC is bounded by the original HDoC algorithm, except for one negligible term, when the distance between the expected reward and threshold is small. Extensive experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both synthetic and real-world datasets.
    
[^12]: 基于神经网络的时间点过程的元学习

    Meta-Learning for Neural Network-based Temporal Point Processes. (arXiv:2401.15846v1 [cs.LG])

    [http://arxiv.org/abs/2401.15846](http://arxiv.org/abs/2401.15846)

    本论文提出了一种基于神经网络的元学习方法，用于预测人类活动相关事件的发生。该方法通过循环神经网络将短序列嵌入到隐藏表示中，并利用这些表示进行预测。这种方法解决了长序列不可用和长期预测困难的问题。

    

    人类活动产生各种事件序列，如出租车行程记录、共享单车取车、犯罪发生和传染病传播等。点过程被广泛应用于预测与人类活动相关的事件。然而，在预测与人类活动相关的事件方面，点过程存在两个问题。首先，最近的高性能点过程模型需要输入足够数量的长期收集的事件（即长序列）进行训练，但在现实情况下往往不可用。其次，在实际应用中需要进行长期预测比较困难。为了解决这些问题，我们提出了一种新颖的元学习方法，用于周期性感知预测未来事件给出短序列。所提出的方法首先通过循环神经网络将短序列嵌入到隐藏表示（即任务表示）中，从短序列创建预测。然后建立模型。

    Human activities generate various event sequences such as taxi trip records, bike-sharing pick-ups, crime occurrence, and infectious disease transmission. The point process is widely used in many applications to predict such events related to human activities. However, point processes present two problems in predicting events related to human activities. First, recent high-performance point process models require the input of sufficient numbers of events collected over a long period (i.e., long sequences) for training, which are often unavailable in realistic situations. Second, the long-term predictions required in real-world applications are difficult. To tackle these problems, we propose a novel meta-learning approach for periodicity-aware prediction of future events given short sequences. The proposed method first embeds short sequences into hidden representations (i.e., task representations) via recurrent neural networks for creating predictions from short sequences. It then model
    
[^13]: 基于交替方向乘子法的分布式马尔可夫链蒙特卡罗抽样

    Distributed Markov Chain Monte Carlo Sampling based on the Alternating Direction Method of Multipliers. (arXiv:2401.15838v1 [stat.ML])

    [http://arxiv.org/abs/2401.15838](http://arxiv.org/abs/2401.15838)

    本文提出了一种基于交替方向乘子法的分布式抽样方案，能够在分布式环境中进行马尔可夫链蒙特卡罗抽样，从而实现贝叶斯推断任务中的不确定性量化。实验证明该方案优于现有方法。

    

    许多机器学习应用需要对空间分布的数据集进行操作。尽管技术进步，但隐私考虑和通信约束可能阻止将整个数据集收集到一个中心单位。在本文中，我们提出了一种基于交替方向乘子法的分布式抽样方案，该方法由于其快速收敛在优化文献中常被使用。与分布式优化相比，分布式抽样可以在贝叶斯推断任务中进行不确定性量化。我们提供了算法收敛的理论保证和实验数据证明其优于现有方法。在我们的理论结果中，我们使用凸优化工具建立了生成的本地样本迭代的基本不等式。这个不等式使我们能够证明与这些迭代相关的分布以Wasserstein距离收敛到潜在目标分布。

    Many machine learning applications require operating on a spatially distributed dataset. Despite technological advances, privacy considerations and communication constraints may prevent gathering the entire dataset in a central unit. In this paper, we propose a distributed sampling scheme based on the alternating direction method of multipliers, which is commonly used in the optimization literature due to its fast convergence. In contrast to distributed optimization, distributed sampling allows for uncertainty quantification in Bayesian inference tasks. We provide both theoretical guarantees of our algorithm's convergence and experimental evidence of its superiority to the state-of-the-art. For our theoretical results, we use convex optimization tools to establish a fundamental inequality on the generated local sample iterates. This inequality enables us to show convergence of the distribution associated with these iterates to the underlying target distribution in Wasserstein distance.
    
[^14]: 关于用于低固有数据维度的生成对抗模型的统计属性

    On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension. (arXiv:2401.15801v1 [stat.ML])

    [http://arxiv.org/abs/2401.15801](http://arxiv.org/abs/2401.15801)

    这篇论文研究了用于低固有数据维度的生成对抗模型的统计属性，提出了关于估计密度的统计保证，涉及数据和潜空间的内在维度，并证明了估计结果与目标的期望Wasserstein-1距离的缩放关系。

    

    尽管生成对抗网络（GANs）取得了显著的实证成功，但其统计准确性的理论保证仍然相对悲观。特别是在应用GANs的数据分布（如自然图像）中，通常假设其在高维特征空间中具有固有的低维结构，但这在现有分析中往往没有得到反映。在本文中，我们试图通过推导关于数据和潜空间的内在维度的统计保证来弥合GANs及其双向变体BiGANs在理论和实践之间的差距。我们分析地证明，如果我们有来自未知目标分布的 n 个样本，并且选择了适当的网络架构，那么从目标中估计得出的期望 Wasserstein-1 距离会按照 $O(n^{-1/d_\mu })$ 缩放。

    Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$
    
[^15]: 使用SHAP和LIME进行可证明稳定的特征排名

    Provably Stable Feature Rankings with SHAP and LIME. (arXiv:2401.15800v1 [stat.ML])

    [http://arxiv.org/abs/2401.15800](http://arxiv.org/abs/2401.15800)

    这项研究提出了一种通过利用多重假设检验的思想，来设计可靠地排名机器学习模型中最重要特征的特征归因方法，旨在解决SHAP和LIME等常用方法由于随机采样导致的高度不稳定性问题。实验证明了该方法的有效性和计算效率。

    

    特征归因是了解机器学习模型预测的普遍工具。然而，用于评分输入变量的常用方法，如SHAP和LIME，由于随机采样而具有高度不稳定性。借鉴多重假设检验的思想，我们设计了能够以高概率正确排名最重要特征的归因方法。我们的算法RankSHAP保证$K$个最高Shapley值具有超过$1-\alpha$的正确排序概率。实证结果证明了其有效性和令人印象深刻的计算效率。我们还在之前的工作基础上为LIME提供了类似的结果，确保以正确顺序选择最重要的特征。

    Feature attributions are ubiquitous tools for understanding the predictions of machine learning models. However, popular methods for scoring input variables such as SHAP and LIME suffer from high instability due to random sampling. Leveraging ideas from multiple hypothesis testing, we devise attribution methods that correctly rank the most important features with high probability. Our algorithm RankSHAP guarantees that the $K$ highest Shapley values have the proper ordering with probability exceeding $1-\alpha$. Empirical results demonstrate its validity and impressive computational efficiency. We also build on previous work to yield similar results for LIME, ensuring the most important features are selected in the right order.
    
[^16]: 高维度相关变量的虚警率控制

    High-Dimensional False Discovery Rate Control for Dependent Variables. (arXiv:2401.15796v1 [stat.ME])

    [http://arxiv.org/abs/2401.15796](http://arxiv.org/abs/2401.15796)

    提出了一个新框架，在高维度相关变量情况下实现虚警率控制，通过综合层次图模型在T-Rex框架中利用依赖结构，利用鞅论证明变量惩罚机制确保了FDR的控制。

    

    在大规模、高维度数据中确保可复现的发现结果的算法在许多信号处理应用中至关重要。近年来，出现了多变量虚警率（FDR）控制方法，即使在变量数量超过样本数量的高维情况下，也能提供保证。然而，在存在高度相关变量组的情况下，这些方法往往无法可靠地控制FDR，在基因组学和金融等领域中很常见。为了解决这个关键问题，我们引入了一个考虑一般依赖结构的新框架。我们提出的依赖感知T-Rex选择器将层次图模型整合到T-Rex框架中，以有效利用变量之间的依赖结构。利用鞅论，我们证明了我们的变量惩罚机制确保了FDR的控制。我们进一步通过陈述和证明了一个清晰的FDR控制框架的推广。

    Algorithms that ensure reproducible findings from large-scale, high-dimensional data are pivotal in numerous signal processing applications. In recent years, multivariate false discovery rate (FDR) controlling methods have emerged, providing guarantees even in high-dimensional settings where the number of variables surpasses the number of samples. However, these methods often fail to reliably control the FDR in the presence of highly dependent variable groups, a common characteristic in fields such as genomics and finance. To tackle this critical issue, we introduce a novel framework that accounts for general dependency structures. Our proposed dependency-aware T-Rex selector integrates hierarchical graphical models within the T-Rex framework to effectively harness the dependency structure among variables. Leveraging martingale theory, we prove that our variable penalization mechanism ensures FDR control. We further generalize the FDR-controlling framework by stating and proving a clea
    
[^17]: Sign-Perturbed Sums识别方法的样本复杂性：标量情况

    Sample Complexity of the Sign-Perturbed Sums Identification Method: Scalar Case. (arXiv:2401.15792v1 [stat.ML])

    [http://arxiv.org/abs/2401.15792](http://arxiv.org/abs/2401.15792)

    本文研究了Sign-Perturbed Sum (SPS)识别方法的样本复杂性，特别是在标量线性回归问题中，通过分析其置信区间的行为。研究结果表明，如果观测噪声是次高斯的话，SPS置信区间的大小以几何速率缩小到真实参数的附近。

    

    Sign-Perturbed Sum (SPS)是一种强大的有限样本系统识别算法，可以构建真实数据生成系统的置信区间，并具有精确的覆盖概率，适用于任何有限的样本大小。SPS在一系列论文中进行了发展，并具有广泛的应用，从一般线性系统，甚至闭环设置下，到非线性和非参数方法。虽然SPS的几个理论性质在文献中已被证明，但该方法的样本复杂性尚未进行分析。本文旨在填补这一空白，并首次提供了关于SPS样本复杂性的结果。在这里，我们专注于标量线性回归问题，即研究SPS置信区间的行为。我们在三个不同的假设集下提供了高概率的上界，表明如果观测噪声是次高斯的话，SPS置信区间的大小以几何速率缩小到真实参数的附近。

    Sign-Perturbed Sum (SPS) is a powerful finite-sample system identification algorithm which can construct confidence regions for the true data generating system with exact coverage probabilities, for any finite sample size. SPS was developed in a series of papers and it has a wide range of applications, from general linear systems, even in a closed-loop setup, to nonlinear and nonparametric approaches. Although several theoretical properties of SPS were proven in the literature, the sample complexity of the method was not analysed so far. This paper aims to fill this gap and provides the first results on the sample complexity of SPS. Here, we focus on scalar linear regression problems, that is we study the behaviour of SPS confidence intervals. We provide high probability upper bounds, under three different sets of assumptions, showing that the sizes of SPS confidence intervals shrink at a geometric rate around the true parameter, if the observation noises are subgaussian. We also show 
    
[^18]: 改进基于内核的非渐近同时置信带

    Improving Kernel-Based Nonasymptotic Simultaneous Confidence Bands. (arXiv:2401.15791v1 [stat.ML])

    [http://arxiv.org/abs/2401.15791](http://arxiv.org/abs/2401.15791)

    本文改进了基于内核的非渐近同时置信带的构建方法，通过放宽噪声假设、改进目标函数范数估计和加强隐含凸优化问题约束来提升了构建的效果。

    

    本文研究构建非参数的、具有非渐近和分布无关保证的同时置信带的问题。目标函数被假设为带限函数，方法基于Paley-Wiener再生核希尔伯特空间理论。论文起点是一个最近开发的算法，我们提出了三种改进方法。首先，通过用较弱的分布不变性原理取代对噪声的对称性假设来放宽对噪声的假设。其次，我们提出了一种更高效的估计目标函数范数的方法，最后通过加强隐含凸优化问题的约束来增强置信带的构建。通过数值实验也对这些改进进行了说明。

    The paper studies the problem of constructing nonparametric simultaneous confidence bands with nonasymptotic and distribition-free guarantees. The target function is assumed to be band-limited and the approach is based on the theory of Paley-Wiener reproducing kernel Hilbert spaces. The starting point of the paper is a recently developed algorithm to which we propose three types of improvements. First, we relax the assumptions on the noises by replacing the symmetricity assumption with a weaker distributional invariance principle. Then, we propose a more efficient way to estimate the norm of the target function, and finally we enhance the construction of the confidence bands by tightening the constraints of the underlying convex optimization problems. The refinements are also illustrated through numerical experiments.
    
[^19]: 贝叶斯非参数方法与数据驱动鲁棒优化的结合

    Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])

    [http://arxiv.org/abs/2401.15771](http://arxiv.org/abs/2401.15771)

    本文提出了一种将贝叶斯非参数方法与最新的决策理论模型相结合的鲁棒优化准则，通过这种方法，可以在线性回归问题中获得有稳定性和优越性能的结果。

    

    训练机器学习和统计模型通常涉及优化数据驱动的风险准则。风险通常是根据经验数据分布计算的，但由于分布不确定性，这可能导致性能不稳定和不好的样本外表现。在分布鲁棒优化的精神下，我们提出了一个新颖的鲁棒准则，将贝叶斯非参数（即狄利克雷过程）理论和最近的平滑模糊规避偏好的决策理论模型的见解相结合。首先，我们强调了与标准正则化经验风险最小化技术的新连接，其中包括岭回归和套索回归。然后，我们从理论上证明了鲁棒优化过程在有限样本和渐近统计保证方面的有利性存在。对于实际实施，我们提出并研究了基于众所周知的狄利克雷过程表示的可行近似准则。

    Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
    
[^20]: 基于集合的退火重要性抽样

    Ensemble-Based Annealed Importance Sampling. (arXiv:2401.15645v1 [stat.CO])

    [http://arxiv.org/abs/2401.15645](http://arxiv.org/abs/2401.15645)

    本文提出了一种基于集合的退火重要性抽样算法，通过结合人口蒙特卡洛方法来提高抽样效率，并利用集合的相互作用促进未发现模态的探索。

    

    从多模态分布中进行抽样是计算科学和统计学中的一个基本且具有挑战性的问题。在各种方法中，一种流行的方法是退火重要性抽样（AIS）。在本文中，我们提出了一个基于集合的AIS版本，通过将其与基于人口的蒙特卡洛方法相结合，以提高其效率。通过跟踪集合而不是单个粒子沿起始分布和目标分布之间的某个延续路径，我们利用集合内的相互作用来促进未发现模态的探索。具体来说，我们的主要思想是利用Snooker算法或进化蒙特卡洛中使用的遗传算法。我们讨论了如何实现所提出的算法，并推导了在连续时间和均场极限下控制集合演化的偏微分方程。我们还测试了所提算法的效率。

    Sampling from a multimodal distribution is a fundamental and challenging problem in computational science and statistics. Among various approaches proposed for this task, one popular method is Annealed Importance Sampling (AIS). In this paper, we propose an ensemble-based version of AIS by combining it with population-based Monte Carlo methods to improve its efficiency. By keeping track of an ensemble instead of a single particle along some continuation path between the starting distribution and the target distribution, we take advantage of the interaction within the ensemble to encourage the exploration of undiscovered modes. Specifically, our main idea is to utilize either the snooker algorithm or the genetic algorithm used in Evolutionary Monte Carlo. We discuss how the proposed algorithm can be implemented and derive a partial differential equation governing the evolution of the ensemble under the continuous time and mean-field limit. We also test the efficiency of the proposed alg
    
[^21]: GT-PCA：具有普适变换不变性的主成分分析的高效和可解释的降维方法

    GT-PCA: Effective and Interpretable Dimensionality Reduction with General Transform-Invariant Principal Component Analysis. (arXiv:2401.15623v1 [stat.ML])

    [http://arxiv.org/abs/2401.15623](http://arxiv.org/abs/2401.15623)

    GT-PCA是一种高效且可解释的主成分分析的降维方法，与具体转换不变，能显著优于其他方法。

    

    数据分析通常需要与特定转换不变的方法，例如针对图像的旋转或图像和时间序列的移动。虽然主成分分析（PCA）是一种广泛使用的降维技术，但在这些转换方面缺乏鲁棒性。现代替代方法，如自动编码器，可以与特定转换不变，但通常不可解释。我们介绍了一种名为GT-PCA的普适变换不变的主成分分析方法，作为PCA和自动编码器的高效可解释替代方法。我们提出了一个神经网络，有效估计各个成分，并在基于合成和真实数据的实验中证明GT-PCA明显优于其他方法。

    Data analysis often requires methods that are invariant with respect to specific transformations, such as rotations in case of images or shifts in case of images and time series. While principal component analysis (PCA) is a widely-used dimension reduction technique, it lacks robustness with respect to these transformations. Modern alternatives, such as autoencoders, can be invariant with respect to specific transformations but are generally not interpretable. We introduce General Transform-Invariant Principal Component Analysis (GT-PCA) as an effective and interpretable alternative to PCA and autoencoders. We propose a neural network that efficiently estimates the components and show that GT-PCA significantly outperforms alternative methods in experiments based on synthetic and real data.
    
[^22]: 预验证的岭回归是高维数据中逻辑回归的高效替代方法

    Prevalidated ridge regression is a highly-efficient drop-in replacement for logistic regression for high-dimensional data. (arXiv:2401.15610v1 [cs.LG])

    [http://arxiv.org/abs/2401.15610](http://arxiv.org/abs/2401.15610)

    本论文提出了一种预验证的岭回归模型，该模型在高维数据中与逻辑回归非常接近，但具有更高的计算效率和几乎没有超参数。它通过利用在拟合过程中计算得到的数量来缩放模型系数，并最小化一组预验证预测的对数损失。

    

    逻辑回归是一种常见的概率分类方法。然而，逻辑回归的有效性取决于仔细且相对计算密集的调优，尤其是对于正则化超参数，并且尤其在高维数据的背景下。我们提出了一种预验证的岭回归模型，该模型在分类错误和对数损失方面与逻辑回归非常接近，特别适用于高维数据，同时在计算效率上明显更高，并且除了正则化之外没有超参数。我们通过缩放模型的系数来最小化由估计的留一交叉验证误差推导出的一组预验证预测的对数损失。这利用了在拟合岭回归模型过程中已经计算的数量，以找到具有名义附加计算开销的缩放参数。

    Logistic regression is a ubiquitous method for probabilistic classification. However, the effectiveness of logistic regression depends upon careful and relatively computationally expensive tuning, especially for the regularisation hyperparameter, and especially in the context of high-dimensional data. We present a prevalidated ridge regression model that closely matches logistic regression in terms of classification error and log-loss, particularly for high-dimensional data, while being significantly more computationally efficient and having effectively no hyperparameters beyond regularisation. We scale the coefficients of the model so as to minimise log-loss for a set of prevalidated predictions derived from the estimated leave-one-out cross-validation error. This exploits quantities already computed in the course of fitting the ridge regression model in order to find the scaling parameter with nominal additional computational expense.
    
[^23]: 基于神经网络的扩散模型中的分数估计：优化和泛化

    Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization. (arXiv:2401.15604v1 [cs.LG])

    [http://arxiv.org/abs/2401.15604](http://arxiv.org/abs/2401.15604)

    本文提出了基于神经网络的扩散模型中分数估计的优化和泛化方法，并建立了对分数估计进行分析的数学框架。

    

    扩散模型已经成为与GANs相媲美的强大工具，可以生成具有改进保真度，灵活性和鲁棒性的高质量样本。这些模型的一个关键组成部分是通过分数匹配来学习分数函数。尽管在各种任务上取得了实证成功，但尚不清楚基于梯度的算法是否可以以可证实的准确性学习分数函数。作为回答这个问题的首要步骤，本文建立了一个数学框架，用于分析用梯度下降训练的神经网络来进行分数估计。我们的分析包括学习过程的优化和泛化方面。特别是，我们提出了一个参数化形式来将去噪分数匹配问题制定为带有噪声标签的回归问题。与标准的监督学习设置相比，分数匹配问题引入了独特的挑战，包括无界输入，向量值输出和额外的时间变量。

    Diffusion models have emerged as a powerful tool rivaling GANs in generating high-quality samples with improved fidelity, flexibility, and robustness. A key component of these models is to learn the score function through score matching. Despite empirical success on various tasks, it remains unclear whether gradient-based algorithms can learn the score function with a provable accuracy. As a first step toward answering this question, this paper establishes a mathematical framework for analyzing score estimation using neural networks trained by gradient descent. Our analysis covers both the optimization and the generalization aspects of the learning procedure. In particular, we propose a parametric form to formulate the denoising score-matching problem as a regression with noisy labels. Compared to the standard supervised learning setup, the score-matching problem introduces distinct challenges, including unbounded input, vector-valued output, and an additional time variable, preventing
    
[^24]: 矩阵超鞅和随机矩阵集中不等式

    Matrix Supermartingales and Randomized Matrix Concentration Inequalities. (arXiv:2401.15567v1 [math.PR])

    [http://arxiv.org/abs/2401.15567](http://arxiv.org/abs/2401.15567)

    本文提出了针对鞅相关或可交换随机对称矩阵的新集中不等式，这些不等式在多种尾条件下成立，在洛伊纳顺序表示，并且有时在任意数据相关停止时间都适用。

    

    我们在多种尾条件下，提出了针对鞅相关或可交换随机对称矩阵的新集中不等式，包括标准的切尔诺夫上界和自归一化重尾设置。这些不等式通常以洛伊纳顺序表示，并且有时在任意数据相关停止时间都成立。在此过程中，我们探索了矩阵超鞅和极值不等式的理论，可能具有独立的研究价值。

    We present new concentration inequalities for either martingale dependent or exchangeable random symmetric matrices under a variety of tail conditions, encompassing standard Chernoff bounds to self-normalized heavy-tailed settings. These inequalities are often randomized in a way that renders them strictly tighter than existing deterministic results in the literature, are typically expressed in the Loewner order, and are sometimes valid at arbitrary data-dependent stopping times.  Along the way, we explore the theory of matrix supermartingales and maximal inequalities, potentially of independent interest.
    
[^25]: 关于矩阵补全的交叉集中采样的鲁棒性研究

    On the Robustness of Cross-Concentrated Sampling for Matrix Completion. (arXiv:2401.15566v1 [stat.ML])

    [http://arxiv.org/abs/2401.15566](http://arxiv.org/abs/2401.15566)

    本文研究了交叉集中采样（CCS）模型在矩阵补全中的鲁棒性，提出了一种高效的非凸迭代算法（RCURC），并通过实验验证了其在合成和真实数据集上的效果。

    

    矩阵补全是现代数据科学研究中的重要工具之一。最近，一种新的矩阵补全采样模型，即交叉集中采样（CCS），引起了很多关注。然而，现有研究中对CCS模型对稀疏异常值的鲁棒性仍不清楚。本文通过探索一种新颖的鲁棒CCS补全问题来回答这个问题。我们提出了一种高效的非凸迭代算法，命名为鲁棒CUR补全（RCURC）。通过在合成数据集和真实数据集上验证了所提算法在效率和鲁棒性方面的实际性能。

    Matrix completion is one of the crucial tools in modern data science research. Recently, a novel sampling model for matrix completion coined cross-concentrated sampling (CCS) has caught much attention. However, the robustness of the CCS model against sparse outliers remains unclear in the existing studies. In this paper, we aim to answer this question by exploring a novel Robust CCS Completion problem. A highly efficient non-convex iterative algorithm, dubbed Robust CUR Completion (RCURC), is proposed. The empirical performance of the proposed algorithm, in terms of both efficiency and robustness, is verified in synthetic and real datasets.
    
[^26]: 未知分布下的Oracle-Efficient混合在线学习

    Oracle-Efficient Hybrid Online Learning with Unknown Distribution. (arXiv:2401.15520v1 [cs.LG])

    [http://arxiv.org/abs/2401.15520](http://arxiv.org/abs/2401.15520)

    本文研究了未知分布下的Oracle-Efficient混合在线学习问题，并提出了计算高效的在线预测器，它在有限的VC类和具有特定维度的类中分别实现了次线性的遗憾上界。此外，还将结果推广到了具有分布改变的情况，并建立了相应的遗憾界。

    

    本文研究了在特征由未知i.i.d.过程生成，标签由对抗生成时的Oracle-Efficient混合在线学习问题。假设可以访问一个（离线）ERM Oracle，我们证明了存在一个计算高效的在线预测器，对于有限的VC类，遗憾上界为$\tilde{O}(T^{\frac{3}{4}})$，对于具有$\alpha$ fat-shattering维度$\alpha^{-p}$的类，遗憾上界为$\tilde{O}(T^{\frac{p+1}{p+2}})$，这为具有未知特征生成过程的混合在线学习提供了首个已知的Oracle-Efficient次线性遗憾界。特别地，它验证了Lazaric和Munos（JCSS 2012）的一个猜想。然后，我们将结果推广到了具有$K$个分布改变的情况下，得到了一个$\tilde{O}(T^{\frac{4}{5}}K^{\frac{1}{5}})$阶的遗憾界。最后，我们建立了一个$\tilde{O}((K^{\frac{2}{3}}(\log|\mathcal{H}|)^{\frac{1}{3}}+K)\cdot T^{\frac{4}{5}})$的遗憾界，其中$\mathcal{H}$是一个函数类。

    We study the problem of oracle-efficient hybrid online learning when the features are generated by an unknown i.i.d. process and the labels are generated adversarially. Assuming access to an (offline) ERM oracle, we show that there exists a computationally efficient online predictor that achieves a regret upper bounded by $\tilde{O}(T^{\frac{3}{4}})$ for a finite-VC class, and upper bounded by $\tilde{O}(T^{\frac{p+1}{p+2}})$ for a class with $\alpha$ fat-shattering dimension $\alpha^{-p}$. This provides the first known oracle-efficient sublinear regret bounds for hybrid online learning with an unknown feature generation process. In particular, it confirms a conjecture of Lazaric and Munos (JCSS 2012). We then extend our result to the scenario of shifting distributions with $K$ changes, yielding a regret of order $\tilde{O}(T^{\frac{4}{5}}K^{\frac{1}{5}})$. Finally, we establish a regret of $\tilde{O}((K^{\frac{2}{3}}(\log|\mathcal{H}|)^{\frac{1}{3}}+K)\cdot T^{\frac{4}{5}})$ for the c
    
[^27]: 差分隐私贝叶斯检验

    Differentially Private Bayesian Tests. (arXiv:2401.15502v1 [stat.ML])

    [http://arxiv.org/abs/2401.15502](http://arxiv.org/abs/2401.15502)

    本文提出了一种差分隐私贝叶斯检验框架，利用规范化的数据生成机制来进行推断，并避免了对完整数据生成机制的建模需求。该框架具有可解释性，并在计算上具有实质性的优势。

    

    在利用机密数据进行科学假设检验的领域中，差分隐私已经成为一个重要的基石。在报告科学发现时，广泛采用贝叶斯检验，因为它们有效地避免了P值的主要批评，即缺乏可解释性和无法量化对竞争假设的支持证据。我们提出了一个新颖的差分隐私贝叶斯假设检验框架，该框架在基于规范化的数据生成机制基础上自然产生，从而保持了推断结果的可解释性。此外，通过专注于基于广泛使用的检验统计量的差分隐私贝叶斯因子，我们避免了对完整数据生成机制建模的需求，并确保了实质性的计算优势。我们还提供了一组充分条件，以在所提框架下确立贝叶斯因子一致性的结果。

    Differential privacy has emerged as an significant cornerstone in the realm of scientific hypothesis testing utilizing confidential data. In reporting scientific discoveries, Bayesian tests are widely adopted since they effectively circumnavigate the key criticisms of P-values, namely, lack of interpretability and inability to quantify evidence in support of the competing hypotheses. We present a novel differentially private Bayesian hypotheses testing framework that arise naturally under a principled data generative mechanism, inherently maintaining the interpretability of the resulting inferences. Furthermore, by focusing on differentially private Bayes factors based on widely used test statistics, we circumvent the need to model the complete data generative mechanism and ensure substantial computational benefits. We also provide a set of sufficient conditions to establish results on Bayes factor consistency under the proposed framework. The utility of the devised technology is showc
    
[^28]: 基于软标签的贝叶斯二分类器误报率的数据驱动估计

    Data-Driven Estimation of the False Positive Rate of the Bayes Binary Classifier via Soft Labels. (arXiv:2401.15500v1 [cs.LG])

    [http://arxiv.org/abs/2401.15500](http://arxiv.org/abs/2401.15500)

    本文提出了一种数据驱动的方法，通过软标签对贝叶斯二分类器的误报率进行估计，并考虑了软标签和有噪声标签的情况。

    

    分类是许多应用中的一个基本任务，数据驱动方法已经显示出了出色的性能。然而，确定这些方法是否达到了最佳性能是具有挑战性的。这主要是因为通常无法知道最佳可达性能，因此有效地估计它是非常重要的。在本文中，我们考虑二分类问题，并提出了一个对于给定数据集中贝叶斯分类器的误报率（FPR）的估计方法，即相对于准确率而言最优的分类器。我们的方法利用了软标签或者实值标签，由于其特性，软标签正在获得显着的关注。我们对我们的估计器的各种理论性质进行了彻底的研究，包括其一致性、无偏性、收敛速度和方差。为了增强我们的估计器在软标签之外的通用性，我们还考虑了包含二元标签的有噪声标签。

    Classification is a fundamental task in many applications on which data-driven methods have shown outstanding performances. However, it is challenging to determine whether such methods have achieved the optimal performance. This is mainly because the best achievable performance is typically unknown and hence, effectively estimating it is of prime importance. In this paper, we consider binary classification problems and we propose an estimator for the false positive rate (FPR) of the Bayes classifier, that is, the optimal classifier with respect to accuracy, from a given dataset. Our method utilizes soft labels, or real-valued labels, which are gaining significant traction thanks to their properties. We thoroughly examine various theoretical properties of our estimator, including its consistency, unbiasedness, rate of convergence, and variance. To enhance the versatility of our estimator beyond soft labels, we also consider noisy labels, which encompass binary labels. For noisy labels, 
    
[^29]: 使用梯度插值和核平滑估计连续处理效果

    Continuous Treatment Effect Estimation Using Gradient Interpolation and Kernel Smoothing. (arXiv:2401.15447v1 [cs.LG])

    [http://arxiv.org/abs/2401.15447](http://arxiv.org/abs/2401.15447)

    本文提出了一种使用梯度插值和核平滑的方法，用于个性化连续处理效果估计。通过增加独立采样的处理和推断的反事实结果来处理训练数据中的混淆问题。实验证明该方法在反事实预测性能上优于其他六种最先进的方法。

    

    我们解决了个性化连续处理效果（ICTE）估计问题，通过观测数据预测任何连续值处理对个体的效果。这个估计任务的主要挑战是训练数据中处理分配与个体协变量的潜在混淆，而在推断ICTE时需要对独立采样的处理进行预测。与之前依赖于正则化器或不稳定的GAN训练的工作相反，我们主张直接方法，即通过增加独立采样的处理和推断的反事实结果来增强训练个体。 我们使用两种策略推断反事实结果：对接近观察到的处理进行梯度插值，以及基于高斯过程的核平滑，使我们能够减小推断的高方差。我们在五个基准测试上评估我们的方法，并显示我们的方法在反事实预测性能上胜过六种最先进的方法。

    We address the Individualized continuous treatment effect (ICTE) estimation problem where we predict the effect of any continuous-valued treatment on an individual using observational data. The main challenge in this estimation task is the potential confounding of treatment assignment with an individual's covariates in the training data, whereas during inference ICTE requires prediction on independently sampled treatments. In contrast to prior work that relied on regularizers or unstable GAN training, we advocate the direct approach of augmenting training individuals with independently sampled treatments and inferred counterfactual outcomes. We infer counterfactual outcomes using a two-pronged strategy: a Gradient Interpolation for close-to-observed treatments, and a Gaussian Process based Kernel Smoothing which allows us to downweigh high variance inferences. We evaluate our method on five benchmarks and show that our method outperforms six state-of-the-art methods on the counterfactu
    
[^30]: 在$\ell_\infty$-扰动下对抗性训练估计器的渐近行为

    Asymptotic Behavior of Adversarial Training Estimator under $\ell_\infty$-Perturbation. (arXiv:2401.15262v1 [math.ST])

    [http://arxiv.org/abs/2401.15262](http://arxiv.org/abs/2401.15262)

    本文研究了在$\ell_\infty$-扰动下的对抗性训练，证明当真实参数为0时，对抗性训练估计器在该扰动下的极限分布可能在0处有一个正概率质量，提供了稀疏性恢复能力的理论保证，并提出了一种两步过程——自适应对抗性训练，可以进一步提高性能。

    

    对抗性训练被提出来抵御机器学习和统计模型中的对抗性攻击。本文重点研究了在$\ell_\infty$-扰动下的对抗性训练，这个问题最近引起了很多研究的关注。在广义线性模型中研究了对抗性训练估计器的渐近行为。结果表明，当真实参数为0时，对抗性训练估计器在$\ell_\infty$-扰动下的极限分布可能在0处有一个正概率质量，为相关的稀疏性恢复能力提供了理论保证。此外，提出了一种两步过程——自适应对抗性训练，可以进一步提高在$\ell_\infty$-扰动下的对抗性训练的性能。具体而言，所提出的过程可以实现渐近无偏性和变量选择一致性。通过数值实验展示了稀疏性恢复的能力。

    Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under $\ell_\infty$-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under $\ell_\infty$-perturbation could put a positive probability mass at $0$ when the true parameter is $0$, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed -adaptive adversarial training, which could further improve the performance of adversarial training under $\ell_\infty$-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery a
    
[^31]: 用任意预测器构建线性回归参数的有限样本置信区间

    Finite Sample Confidence Regions for Linear Regression Parameters Using Arbitrary Predictors. (arXiv:2401.15254v1 [stat.ML])

    [http://arxiv.org/abs/2401.15254](http://arxiv.org/abs/2401.15254)

    本文提出了一种新的方法，利用任意预测器构建线性模型参数的有限样本置信区间。该方法对噪声的要求很少，并且适用于严格线性函数偏差一定阈值的函数。这种方法能够进行鲁棒优化，并提取特定参数坐标的置信区间，也能用于假设检验。

    

    我们探索了一种新的方法，利用任意预测器构建线性模型参数的置信区间。我们的框架对噪声的要求很少，并且可以扩展到严格线性函数偏差一定阈值的函数，从而适应了广泛而实用的函数集合。得出的置信区间可以作为混合整数线性规划框架中的约束条件，从而实现线性目标的优化。这种表示方式能够进行鲁棒优化，并提取特定参数坐标的置信区间。与以前的方法不同的是，置信区间可能为空，这可以用于假设检验。最后，我们在合成数据上验证了我们方法的实证适用性。

    We explore a novel methodology for constructing confidence regions for parameters of linear models, using predictions from any arbitrary predictor. Our framework requires minimal assumptions on the noise and can be extended to functions deviating from strict linearity up to some adjustable threshold, thereby accommodating a comprehensive and pragmatically relevant set of functions. The derived confidence regions can be cast as constraints within a Mixed Integer Linear Programming framework, enabling optimisation of linear objectives. This representation enables robust optimization and the extraction of confidence intervals for specific parameter coordinates. Unlike previous methods, the confidence region can be empty, which can be used for hypothesis testing. Finally, we validate the empirical applicability of our method on synthetic data.
    
[^32]: 在预训练中通过对抗训练改进表示：从理论角度出发

    Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective. (arXiv:2401.15248v1 [cs.LG])

    [http://arxiv.org/abs/2401.15248](http://arxiv.org/abs/2401.15248)

    该论文从理论角度探讨了在预训练中通过对抗训练改进表示的思路，并证明了特征净化在预训练模型的对抗鲁棒性和下游任务之间起到重要作用。

    

    预训练被认为可以为大规模深度学习中的下游任务生成通用表示，例如大型语言模型。现有文献例如\cite{kim2020adversarial}经验性地观察到下游任务可以继承预训练模型的对抗鲁棒性。我们提供了这种鲁棒性继承现象的理论证明。我们的理论结果揭示了在两层神经网络中，特征净化在连接预训练模型的对抗鲁棒性和下游任务中起重要作用。具体来说，我们展示了(i)通过对抗训练，每个隐藏节点倾向于选择只有一个（或几个）特征；(ii)在没有对抗训练的情况下，隐藏节点可能容易受到攻击。这个观察对于监督预训练和对比学习都是有效的。通过净化节点，事实证明在下游任务中，仅仅进行干净训练就足以实现对抗鲁棒性。

    Pre-training is known to generate universal representations for downstream tasks in large-scale deep learning such as large language models. Existing literature, e.g., \cite{kim2020adversarial}, empirically observe that the downstream tasks can inherit the adversarial robustness of the pre-trained model. We provide theoretical justifications for this robustness inheritance phenomenon. Our theoretical results reveal that feature purification plays an important role in connecting the adversarial robustness of the pre-trained model and the downstream tasks in two-layer neural networks. Specifically, we show that (i) with adversarial training, each hidden node tends to pick only one (or a few) feature; (ii) without adversarial training, the hidden nodes can be vulnerable to attacks. This observation is valid for both supervised pre-training and contrastive learning. With purified nodes, it turns out that clean training is enough to achieve adversarial robustness in downstream tasks.
    
[^33]: FDR控制的稀疏金融指数跟踪投资组合优化

    FDR-Controlled Portfolio Optimization for Sparse Financial Index Tracking. (arXiv:2401.15139v1 [q-fin.PM])

    [http://arxiv.org/abs/2401.15139](http://arxiv.org/abs/2401.15139)

    本论文提出了一种扩展的T-Rex框架，用于在稀疏金融指数跟踪中选择少数相关变量，并通过集成最近邻惩罚机制，可靠控制误发现率（FDR）。实验证明了该方法在过去20年内基于少量股票准确跟踪标准普尔500指数的能力。

    

    在高维数据分析中，如金融指数跟踪或生物医学应用中，关键是在保持对误发现率（FDR）的控制的同时选择少数相关变量。在这些应用中，变量之间经常存在强依赖关系（例如股票收益），这可能会削弱现有方法（如模型X knockoff方法或T-Rex选择器）的FDR控制特性。为了解决这个问题，我们扩展了T-Rex框架，以适应高度相关变量的重叠组。这是通过将最近邻惩罚机制集成到框架中实现的，该机制能够在用户定义的目标水平上可靠控制FDR。稀疏指数跟踪的实例展示了该方法在过去20年内基于少量股票准确跟踪标准普尔500指数的能力。在CRAN上提供了R包TRexSelector的开源实现。

    In high-dimensional data analysis, such as financial index tracking or biomedical applications, it is crucial to select the few relevant variables while maintaining control over the false discovery rate (FDR). In these applications, strong dependencies often exist among the variables (e.g., stock returns), which can undermine the FDR control property of existing methods like the model-X knockoff method or the T-Rex selector. To address this issue, we have expanded the T-Rex framework to accommodate overlapping groups of highly correlated variables. This is achieved by integrating a nearest neighbors penalization mechanism into the framework, which provably controls the FDR at the user-defined target level. A real-world example of sparse index tracking demonstrates the proposed method's ability to accurately track the S&P 500 index over the past 20 years based on a small number of stocks. An open-source implementation is provided within the R package TRexSelector on CRAN.
    
[^34]: 一种多级对称微分方程模型用于学习蛋白质-配体结合动力学

    A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics. (arXiv:2401.15122v1 [cs.LG])

    [http://arxiv.org/abs/2401.15122](http://arxiv.org/abs/2401.15122)

    提出了一种能够促进数值MD模拟并有效模拟蛋白质-配体结合动力学的NeuralMD方法，采用物理信息多级对称框架，实现了准确建模多级蛋白质-配体相互作用。

    

    在药物发现中，蛋白质-配体结合的分子动力学（MD）模拟提供了一种强大的工具，用于预测结合亲和力，估计运输性能和探索口袋位点。通过改进数值方法以及最近通过机器学习（ML）方法增强MD模拟的效率已经有了很长的历史。然而，仍然存在一些挑战，例如准确建模扩展时间尺度的模拟。为了解决这个问题，我们提出了NeuralMD，这是第一个能够促进数值MD并提供准确的蛋白质-配体结合动力学模拟的ML辅助工具。我们提出了一个合理的方法，将一种新的物理信息多级对称框架纳入模型中。具体而言，我们提出了（1）一个使用向量框架满足群对称性并捕获多级蛋白质-配体相互作用的BindingNet模型，以及（2）一个增强的神经微分方程求解器，学习轨迹的演化。

    In drug discovery, molecular dynamics (MD) simulation for protein-ligand binding provides a powerful tool for predicting binding affinities, estimating transport properties, and exploring pocket sites. There has been a long history of improving the efficiency of MD simulations through better numerical methods and, more recently, by augmenting them with machine learning (ML) methods. Yet, challenges remain, such as accurate modeling of extended-timescale simulations. To address this issue, we propose NeuralMD, the first ML surrogate that can facilitate numerical MD and provide accurate simulations of protein-ligand binding dynamics. We propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) a BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural differential equation solver that learns the trajectory und
    
[^35]: 二进制感知机容量的研究

    A note on the capacity of the binary perceptron. (arXiv:2401.15092v1 [math.PR])

    [http://arxiv.org/abs/2401.15092](http://arxiv.org/abs/2401.15092)

    该论文研究了二进制感知机的容量问题，在确定了上界和下界后，给出了证明该容量小于0.847的条件一阶矩方法与已知结果的结合。

    

    确定二进制感知机的容量αc是一个长期存在的问题。Krauth和Mezard（1989）猜测了αc的明确值，大约等于0.833，最近Ding和Sun（2019）建立了与此预测相符的严格下界。关于上界，Kim和Roche（1998）以及Talagrand（1999）分别显示αc < 0.996，而Krauth和Mezard概述了一个可以用于显示αc < 0.847的论证。这个说明的目的是记录一个完整的证明αc < 0.847的证明。该证明是一种条件一阶矩方法与已知的球形感知机结果相结合。

    Determining the capacity $\alpha_c$ of the Binary Perceptron is a long-standing problem. Krauth and Mezard (1989) conjectured an explicit value of $\alpha_c$, approximately equal to .833, and a rigorous lower bound matching this prediction was recently established by Ding and Sun (2019). Regarding the upper bound, Kim and Roche (1998) and Talagrand (1999) independently showed that $\alpha_c$ < .996, while Krauth and Mezard outlined an argument which can be used to show that $\alpha_c$ < .847. The purpose of this expository note is to record a complete proof of the bound $\alpha_c$ < .847. The proof is a conditional first moment method combined with known results on the spherical perceptron
    
[^36]: 基于得分结构先验的部分已知高斯图模型估计

    Estimation of partially known Gaussian graphical models with score-based structural priors. (arXiv:2401.14340v1 [stat.ML])

    [http://arxiv.org/abs/2401.14340](http://arxiv.org/abs/2401.14340)

    本论文提出了一种基于得分结构先验的算法，用于估计部分已知高斯图模型。通过使用图神经网络来估计图的得分函数，我们可以在生成样本时利用退火朗格维能扩散，从而更准确地估计后验分布。数值实验表明，我们的方法具有明显的优势。

    

    我们提出了一种新的算法，用于支持估计部分已知的高斯图模型，并且结合了关于底层图的先验信息。与传统方法相比，传统方法使用点估计方法基于最大似然或最大后验准则，并使用（简单的）精度矩阵先验来提供点估计。我们考虑对图进行先验，并依赖退火朗格维能扩散从后验分布中生成样本。由于朗格维能采样器需要访问底层图先验的得分函数，因此我们使用图神经网络来有效地从图数据集（事先可用或从已知分布生成）估计得分。数值实验证明了我们方法的优势。

    We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or a maximum a posteriori criterion using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments demonstrate the benefits of our approach.
    
[^37]: DISCOUNT: 使用最优传输进行分布式对抗解释

    DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport. (arXiv:2401.13112v1 [cs.AI])

    [http://arxiv.org/abs/2401.13112](http://arxiv.org/abs/2401.13112)

    本文提出了使用最优传输进行分布式对抗解释的方法DISCOUNT，将对抗解释的概念扩展到整个输入输出分布，并通过统计置信度来支撑这一方法。

    

    对抗解释是在黑盒决策模型中提供洞察力和可解释性的事实方法，通过确定导致不同结果的替代输入实例来实现。本文将对抗解释的概念扩展到分布上下文，从个体数据点扩大到整个输入输出分布，命名为分布式对抗解释。在分布式对抗解释中，我们的重点转向分析事实和对抗的分布属性，类似于评估个体实例及其结果决策的经典方法。我们利用最优传输来构建一个机会约束优化问题，旨在导出与事实对应的对抗分布，以统计置信度做支撑。我们提出的优化方法DISCOUNT在输入和输出分布之间平衡这种置信度。

    Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorit
    
[^38]: 用于解决一些随机最优控制问题的深度多任务神经网络

    Deep multitask neural networks for solving some stochastic optimal control problems. (arXiv:2401.12923v1 [stat.ML])

    [http://arxiv.org/abs/2401.12923](http://arxiv.org/abs/2401.12923)

    本文针对某些难以模拟底层状态变量的随机最优控制问题，引入了使用多任务神经网络的有效解决方案，并通过实验证明了该方法的优越性。

    

    大多数现有的基于神经网络的方法用于使用相关的反向动态规划原理解决随机最优控制问题，这些方法依赖于模拟底层状态变量的能力。然而，在某些问题中，这种模拟是不可行的，导致状态变量空间的离散化和需要为每个数据点训练一个神经网络。当处理大的状态变量空间时，这种方法在计算上变得低效。在本文中，我们考虑了一类这种类型的随机最优控制问题，并引入了一种使用多任务神经网络的有效解决方案。为了训练我们的多任务神经网络，我们引入了一种新的方案，在任务之间动态平衡学习。通过对真实世界的衍生品定价问题进行数值实验，我们证明了我们的方法优于最先进的方法。

    Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.
    
[^39]: 一个好的评分并不会导致一个好的生成模型

    A Good Score Does not Lead to A Good Generative Model. (arXiv:2401.04856v1 [cs.LG])

    [http://arxiv.org/abs/2401.04856](http://arxiv.org/abs/2401.04856)

    本文通过反例证明，在某些情况下，即使评分函数学习良好，基于评分的生成模型（SGMs）仍然无法生成接近真实数据分布的样本，并且只能产生训练数据点的高斯模糊样本。

    

    基于评分的生成模型（SGMs）是生成建模中的一种主要方法，以其能够从复杂的高维数据分布中生成高质量样本而闻名。该方法在经验上取得了成功，并且有着严格的理论收敛性质的支持。特别是已经证明，如果学习到的底层评分函数良好，SGMs能够生成接近真实数据分布的样本，这表明了SGM作为生成模型的成功之处。本文提供了一个反例。通过样本复杂度的分析，我们提供了一个特定的设置，其中评分函数学习得很好。然而，在这个设置中，SGMs只能输出训练数据点的高斯模糊样本，模拟核密度估计的效果。这一发现与最近的一系列发现相一致，揭示了SGMs可能表现出强大的记忆效应并且无法生成样本的问题。

    Score-based Generative Models (SGMs) is one leading method in generative modeling, renowned for their ability to generate high-quality samples from complex, high-dimensional data distributions. The method enjoys empirical success and is supported by rigorous theoretical convergence properties. In particular, it has been shown that SGMs can generate samples from a distribution that is close to the ground-truth if the underlying score function is learned well, suggesting the success of SGM as a generative model. We provide a counter-example in this paper. Through the sample complexity argument, we provide one specific setting where the score function is learned well. Yet, SGMs in this setting can only output samples that are Gaussian blurring of training data points, mimicking the effects of kernel density estimation. The finding resonates a series of recent finding that reveal that SGMs can demonstrate strong memorization effect and fail to generate.
    
[^40]: 人类反馈的迭代偏好学习：在KL约束下将理论与实践联系起来的RLHF

    Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint. (arXiv:2312.11456v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11456](http://arxiv.org/abs/2312.11456)

    该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。

    

    本文研究了生成模型与强化学习从人类反馈中的对齐过程的理论框架。我们考虑了一个标准的数学表达式，即反向KL正则化的上下文多臂赌博机用于RLHF。尽管它被广泛应用于实际应用，但对这个公式的严格理论分析仍然很开放。我们研究了它在离线、在线和混合三种不同场景下的行为，并提出了具有有限样本理论保证的高效算法。朝着实际应用的方向，我们的框架通过对信息理论策略改进预言的稳健近似，自然地产生了几种新颖的RLHF算法。这包括在线场景中的迭代版本的直接偏好优化(DPO)算法，以及离线情景下的多步拒绝抽样策略。我们对大型语言模型的真实对齐实验进行了实证评估。

    This paper studies the theoretical framework of the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees.  Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate t
    
[^41]: 多分布学习的样本复杂度

    The sample complexity of multi-distribution learning. (arXiv:2312.04027v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.04027](http://arxiv.org/abs/2312.04027)

    本文解决了多分布学习的样本复杂度问题，并给出了匹配下界的样本复杂度算法。

    

    多分布学习将经典的PAC学习推广到处理来自多个分布的数据。给定一组$k$个数据分布和一个VC维度为$d$的假设类，目标是学习一个假设，使得在$k$个分布上的最大总体损失最小，误差不超过$\epsilon$。本文通过给出一个样本复杂度算法$\widetilde{O}((d+k)\epsilon^{-2}) \cdot (k/\epsilon)^{o(1)}$来解决多分布学习的样本复杂度问题。这个结果与下界相匹配，解决了Awasthi、Haghtalab和Zhao在COLT 2023中提出的开放问题 [AHZ23]。

    Multi-distribution learning generalizes the classic PAC learning to handle data coming from multiple distributions. Given a set of $k$ data distributions and a hypothesis class of VC dimension $d$, the goal is to learn a hypothesis that minimizes the maximum population loss over $k$ distributions, up to $\epsilon$ additive error. In this paper, we settle the sample complexity of multi-distribution learning by giving an algorithm of sample complexity $\widetilde{O}((d+k)\epsilon^{-2}) \cdot (k/\epsilon)^{o(1)}$. This matches the lower bound up to sub-polynomial factor and resolves the COLT 2023 open problem of Awasthi, Haghtalab and Zhao [AHZ23].
    
[^42]: 使用训练标签进行填充和通过标签填充进行分类

    Imputation using training labels and classification via label imputation. (arXiv:2311.16877v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.16877](http://arxiv.org/abs/2311.16877)

    本论文提出一种在填充缺失数据时将标签与输入堆叠的方法，能够显著提高填充效果，并同时填充标签和输入。该方法适用于各种类型的数据，且在实验证明具有有希望的准确性结果。

    

    在实际应用中，缺失数据是一个常见的问题。已经开发了各种填充方法来处理缺失数据。然而，尽管训练数据通常都有标签，但常见的填充方法通常只依赖于输入而忽略标签。在这项工作中，我们阐述了将标签堆叠到输入中可以显着提高输入的填充效果。此外，我们提出了一种分类策略，该策略将预测的测试标签初始化为缺失值，并将标签与输入堆叠在一起进行填充。这样可以同时填充标签和输入。而且，该技术能够处理具有缺失标签的训练数据，无需任何先前的填充，并且适用于连续型、分类型或混合型数据。实验证明在准确性方面取得了有希望的结果。

    Missing data is a common problem in practical settings. Various imputation methods have been developed to deal with missing data. However, even though the label is usually available in the training data, the common practice of imputation usually only relies on the input and ignores the label. In this work, we illustrate how stacking the label into the input can significantly improve the imputation of the input. In addition, we propose a classification strategy that initializes the predicted test label with missing values and stacks the label with the input for imputation. This allows imputing the label and the input at the same time. Also, the technique is capable of handling data training with missing labels without any prior imputation and is applicable to continuous, categorical, or mixed-type data. Experiments show promising results in terms of accuracy.
    
[^43]: 使用含有半监督潜在过程的深度生成模型建模复杂疾病轨迹

    Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes. (arXiv:2311.08149v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.08149](http://arxiv.org/abs/2311.08149)

    本文提出了一种深度生成模型的时间序列方法，利用潜在时间过程来模拟复杂疾病轨迹。通过结合医学知识和半监督方法，该方法可以解释和全面分析疾病轨迹，并用于进一步的数据分析和临床假设测试。

    

    本文提出了一种使用潜在时间过程的深度生成时间序列方法，用于模拟和全面分析复杂疾病轨迹。我们旨在找到能够解释观察到的疾病轨迹的有意义的时间潜在表示，并以一种可解释和全面的方式进行分析。为了提高这些时间潜在过程的可解释性，我们开发了一种半监督方法，利用已建立的医学概念对潜在空间进行解缠。通过将生成方法与医学知识相结合，我们利用了发现疾病新方面的能力，同时将医学概念整合到模型中。我们展示了学得的时间潜在过程可以用于进一步的数据分析和临床假设测试，包括查找相似患者和将疾病聚类为新的亚型。此外，我们的方法还可以实现个性化的在线监测和预测多变量情况。

    In this paper, we propose a deep generative time series approach using latent temporal processes for modeling and holistically analyzing complex disease trajectories. We aim to find meaningful temporal latent representations of an underlying generative process that explain the observed disease trajectories in an interpretable and comprehensive way. To enhance the interpretability of these latent temporal processes, we develop a semi-supervised approach for disentangling the latent space using established medical concepts. By combining the generative approach with medical knowledge, we leverage the ability to discover novel aspects of the disease while integrating medical concepts into the model. We show that the learned temporal latent processes can be utilized for further data analysis and clinical hypothesis testing, including finding similar patients and clustering the disease into new sub-types. Moreover, our method enables personalized online monitoring and prediction of multivari
    
[^44]: 加速演化算法解决黑盒优化问题

    Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems. (arXiv:2309.13349v1 [cs.NE])

    [http://arxiv.org/abs/2309.13349](http://arxiv.org/abs/2309.13349)

    本文提出了一种能够在进化算法执行中选择适当的近似函数成本的技术，用于加速解决黑盒优化问题。

    

    在处理计算复杂的黑盒优化问题时，常常使用基于群体的演化算法。它们通过选择机制从给定的群体中选择最佳解决方案，比较它们的目标值，然后用这些目标值生成下一代群体。这个迭代过程能够高效地探索解空间，逐步改善解决方案。然而，这些算法需要大量的评估才能提供一个优质的解决方案，当评估成本很高时，可能会造成计算上的负担。在某些情况下，可以用成本较低的不太准确的近似函数替换原始目标函数。这就引入了评估成本与准确性之间的权衡。在本文中，我们提出了一种能够在优化算法执行过程中选择适当的近似函数成本的技术。

    Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, these algorithms require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a trade-off between the evaluation cost and its accuracy.  In this paper, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which th
    
[^45]: 可扩展的神经网络模型和千兆级数据集用于粒子流重建

    Scalable neural network models and terascale datasets for particle-flow reconstruction. (arXiv:2309.06782v1 [physics.data-an])

    [http://arxiv.org/abs/2309.06782](http://arxiv.org/abs/2309.06782)

    本研究针对高能电子-正电子碰撞中的粒子流重建，使用可扩展的机器学习模型，并通过超参数调优和硬件处理器的高度可移植性，取得了真实且具有竞争力的物理性能。

    

    本研究针对高能电子-正电子碰撞中基于高度粒度探测器模拟的完整事件重建，研究了可扩展的机器学习模型。粒子流（PF）重建可通过跟踪和量能器团簇或击中来构建监督学习任务。我们比较了图神经网络和基于内核的变换器，并证明两者都避免了二次内存分配和计算成本，同时实现了真实的粒子流重建。我们展示了在超级计算机上进行的超参数调优显著提高了模型的物理性能。我们还展示了所得模型在硬件处理器上具有高度可移植性，支持NVIDIA, AMD和英特尔 Habana卡。最后，我们证明了模型可以在由跟踪和量能器击中组成的高粒度输入上进行训练，从而获得与基准相竞争的物理性能。有关复现研究的数据集和软件已发布。

    We study scalable machine learning models for full event reconstruction in high-energy electron-positron collisions based on a highly granular detector simulation. Particle-flow (PF) reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters or hits. We compare a graph neural network and kernel-based transformer and demonstrate that both avoid quadratic memory allocation and computational cost while achieving realistic PF reconstruction. We show that hyperparameter tuning on a supercomputer significantly improves the physics performance of the models. We also demonstrate that the resulting model is highly portable across hardware processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we demonstrate that the model can be trained on highly granular inputs consisting of tracks and calorimeter hits, resulting in a competitive physics performance with the baseline. Datasets and software to reproduce the studies are published following 
    
[^46]: 高维线性回归的统一转移学习模型

    Unified Transfer Learning Models for High-Dimensional Linear Regression. (arXiv:2307.00238v1 [stat.ML])

    [http://arxiv.org/abs/2307.00238](http://arxiv.org/abs/2307.00238)

    UTrans是一种统一转移学习模型，它能检测可转移变量和源数据，并具有较低的估计和预测误差，同时保持可解释性。

    

    在现代数据分析中，当目标数据稀缺而源数据充足，或者源数据和目标数据的分布不同的情况下，转移学习在发挥重要作用。本文提出了一种可解释的统一转移学习模型，称为UTrans，该模型能够检测可转移变量和源数据。具体来说，我们建立了估计误差界限，并证明我们的界限低于仅有目标数据的界限。此外，我们基于假设检验提出了一种源数据检测算法，用于排除不可转移的数据。我们在多个实验中评估和比较了UTrans与现有算法。结果显示，UTrans在保持可解释性的同时，比现有方法具有更低的估计和预测误差。最后，我们将其应用于美国代际流动数据，并将我们提出的算法与经典的机器学习算法进行比较。

    Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.
    
[^47]: AdaStop：用于深度强化学习代理比较的高效可靠序列测试

    AdaStop: sequential testing for efficient and reliable comparisons of Deep RL Agents. (arXiv:2306.10882v1 [cs.LG])

    [http://arxiv.org/abs/2306.10882](http://arxiv.org/abs/2306.10882)

    AdaStop是一种基于多组序列测试的新统计测试方法，可用于比较多个深度强化学习算法来解决实验结果可复制性的问题。

    

    许多深度强化学习实验结果的可复现性受到质疑。为了解决这个可复现性危机，我们提出了一种理论上可靠的方法，用于比较多个深度强化学习算法。由于一个深度强化学习算法的一次执行性能是随机的，所以需要进行独立的多次执行来精确评估它。当比较多个强化学习算法时，一个主要问题是需要进行多少次执行，并且如何确保这样比较的结果在理论上是可靠的。深度强化学习的研究人员通常使用少于5个独立执行来比较算法：我们认为这通常是不够的。而且，当同时比较几个算法时，每个比较的误差都会累积，必须采用多重测试程序来考虑这些误差，以维持低误差保证。为了以统计学上的可靠方式解决这个问题，我们介绍了AdaStop，这是一种基于多组序列测试的新统计测试方法。

    The reproducibility of many experimental results in Deep Reinforcement Learning (RL) is under question. To solve this reproducibility crisis, we propose a theoretically sound methodology to compare multiple Deep RL algorithms. The performance of one execution of a Deep RL algorithm is random so that independent executions are needed to assess it precisely. When comparing several RL algorithms, a major question is how many executions must be made and how can we assure that the results of such a comparison is theoretically sound. Researchers in Deep RL often use less than 5 independent executions to compare algorithms: we claim that this is not enough in general. Moreover, when comparing several algorithms at once, the error of each comparison accumulates and must be taken into account with a multiple tests procedure to preserve low error guarantees. To address this problem in a statistically sound way, we introduce AdaStop, a new statistical test based on multiple group sequential tests
    
[^48]: 利用代理变量进行因果效应部分识别

    Partial Identification of Causal Effects Using Proxy Variables. (arXiv:2304.04374v1 [stat.ME])

    [http://arxiv.org/abs/2304.04374](http://arxiv.org/abs/2304.04374)

    这篇论文提出了一种无需完备性的部分识别方法，它为我们提供了一组界限，用于在未能控制混淆因素的情形下，评估治疗对结果变量因果效应。

    

    近年来，近端因果推断被提出为一种在未能控制混淆因素的情形下评估治疗对结果变量因果效应的框架。其中利用未被观测到的混淆因素的代理变量进行点估计，前提是这样的代理变量对混淆因素相当有关，然而这种完备性却是经验不可检验的。本文提出了一种不要求完备性的部分识别方法，并为感兴趣的因果效应提供了一组界限。该方法建立在敏感性分析的基础上，并且比现有的基于代理变量的方法要求更弱。这项工作在模拟数据和现实数据上进行了展示。

    Proximal causal inference is a recently proposed framework for evaluating the causal effect of a treatment on an outcome variable in the presence of unmeasured confounding (Miao et al., 2018a; Tchetgen Tchetgen et al., 2020). For nonparametric point identification, the framework leverages proxy variables of unobserved confounders, provided that such proxies are sufficiently relevant for the latter, a requirement that has previously been formalized as a completeness condition. Completeness is key to connecting the observed proxy data to hidden factors via a so-called confounding bridge function, identification of which is an important step towards proxy-based point identification of causal effects. However, completeness is well-known not to be empirically testable, therefore potentially restricting the application of the proximal causal framework. In this paper, we propose partial identification methods that do not require completeness and obviate the need for identification of a bridge
    
[^49]: 强可辨识性和异质响应回归中的参数学习

    Strong identifiability and parameter learning in regression with heterogeneous response. (arXiv:2212.04091v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2212.04091](http://arxiv.org/abs/2212.04091)

    本文研究了混合回归模型中的强可辨识性条件、参数估计的收敛速度和贝叶斯后验收缩行为，适用于常见的链函数和条件分布族。

    

    混合回归是一类强大的模型，用于对高度不确定和异质的目标响应变量进行回归学习。除了作为给定一些协变量的响应的丰富预测模型之外，该模型类中的参数还提供有关数据总体中异质性的有用信息，该异质性由与若干个不同但潜在的子群体相关联的协变量给定响应的条件分布表示。本文研究了混合回归模型中的强可辨识性条件、条件密度和参数估计的收敛速度，以及在精确拟合和过拟合设置以及组分数量未知时产生的贝叶斯后验收缩行为。该理论适用于实践者常见的链函数和条件分布族的选择。我们提供了模拟研究结果。

    Mixtures of regression are a powerful class of models for regression learning with respect to a highly uncertain and heterogeneous response variable of interest. In addition to being a rich predictive model for the response given some covariates, the parameters in this model class provide useful information about the heterogeneity in the data population, which is represented by the conditional distributions for the response given the covariates associated with a number of distinct but latent subpopulations. In this paper, we investigate conditions of strong identifiability, rates of convergence for conditional density and parameter estimation, and the Bayesian posterior contraction behavior arising in finite mixture of regression models, under exact-fitted and over-fitted settings and when the number of components is unknown. This theory is applicable to common choices of link functions and families of conditional distributions employed by practitioners. We provide simulation studies a
    
[^50]: 完全随机信任区间顺序二次规划方法用于等式约束优化问题

    Fully Stochastic Trust-Region Sequential Quadratic Programming for Equality-Constrained Optimization Problems. (arXiv:2211.15943v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2211.15943](http://arxiv.org/abs/2211.15943)

    本文提出了一种完全随机的信任区间顺序二次规划算法(TR-StoSQP)，用于解决非线性优化问题，其中包含随机目标和确定性等式约束。该算法通过自适应选择信任区间半径，并允许使用未经修改的Hessian矩阵，在SQP子问题中应对不可行性问题。为了控制试验步长的长度并保证尺度不变性，作者采用自适应的松弛技术计算试验步长。

    

    我们提出了一种信任区间随机顺序二次规划算法(TR-StoSQP)，用于解决具有随机目标和确定性等式约束的非线性优化问题。我们考虑了完全随机的情况，在每一步中生成一个样本来估计目标梯度。该算法自适应地选择信任区间半径，并且与现有的线搜索StoSQP方案相比，允许我们在SQP子问题中使用非确定Hessian矩阵（即未经修改的Hessian矩阵）。作为约束优化的信任区间方法，我们的算法必须解决一个不可行性问题--线性化的等式约束和信任区间约束可能导致不可行的SQP子问题。在这方面，我们提出了一种自适应的松弛技术来计算试验步长，包括一个正常步长和一个切线步长。为了控制这两个步长的长度，同时确保一个尺度不变的属性，我们自适应地装饰。

    We propose a trust-region stochastic sequential quadratic programming algorithm (TR-StoSQP) to solve nonlinear optimization problems with stochastic objectives and deterministic equality constraints. We consider a fully stochastic setting, where at each step a single sample is generated to estimate the objective gradient. The algorithm adaptively selects the trust-region radius and, compared to the existing line-search StoSQP schemes, allows us to utilize indefinite Hessian matrices (i.e., Hessians without modification) in SQP subproblems. As a trust-region method for constrained optimization, our algorithm must address an infeasibility issue -- the linearized equality constraints and trust-region constraints may lead to infeasible SQP subproblems. In this regard, we propose an adaptive relaxation technique to compute the trial step, consisting of a normal step and a tangential step. To control the lengths of these two steps while ensuring a scale-invariant property, we adaptively deco
    
[^51]: 离线估计控制马尔可夫链：最小化和样本复杂度

    Offline Estimation of Controlled Markov Chains: Minimaxity and Sample Complexity. (arXiv:2211.07092v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.07092](http://arxiv.org/abs/2211.07092)

    本论文研究了离线估计有限控制马尔可夫链的转移概率矩阵的非参数估计器，并通过记录策略的混合特性建立了样本复杂性界限和最小化条件。结果表明，实现特定的统计风险界限涉及到混合特性的强度和样本数量之间微妙而有趣的权衡。还使用这些样本复杂性界限建立了离线评估恒定马尔可夫控制策略的相关界限。

    

    在这项工作中，我们研究了有限控制马尔可夫链的转移概率矩阵的自然非参数估计器。我们考虑了一个固定数据集的离线设置，该数据集是使用所谓的记录策略收集的。我们为估计器开发了样本复杂性的界限，并建立了最小化的条件。我们的统计界限通过记录策略的混合特性来确定。我们表明，实现特定的统计风险界限涉及到混合特性的强度和样本数量之间微妙而有趣的权衡。我们在各种示例中验证了我们结果的有效性，包括遗传马尔可夫链，弱遗传非齐次马尔可夫链和具有非平稳马尔可夫、阶段性和贪婪控制的控制马尔可夫链。最后，我们使用这些样本复杂性界限来建立离线评估恒定马尔可夫控制策略的相关界限。

    In this work, we study a natural nonparametric estimator of the transition probability matrices of a finite controlled Markov chain. We consider an offline setting with a fixed dataset, collected using a so-called logging policy. We develop sample complexity bounds for the estimator and establish conditions for minimaxity. Our statistical bounds depend on the logging policy through its mixing properties. We show that achieving a particular statistical risk bound involves a subtle and interesting trade-off between the strength of the mixing properties and the number of samples. We demonstrate the validity of our results under various examples, such as ergodic Markov chains, weakly ergodic inhomogeneous Markov chains, and controlled Markov chains with non-stationary Markov, episodic, and greedy controls. Lastly, we use these sample complexity bounds to establish concomitant ones for offline evaluation of stationary Markov control policies.
    
[^52]: 联邦离线强化学习

    Federated Offline Reinforcement Learning. (arXiv:2206.05581v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.05581](http://arxiv.org/abs/2206.05581)

    本文提出了一种联邦离线强化学习算法，可以处理医疗机构间数据共享的隐私限制和异质性问题，同时提供了通信效率和隐私保护性。该算法的样本复杂度证明以及在现实医学数据集上的模拟实验结果表明了其有效性和效率。

    

    基于证据或数据的动态治疗方案对于个性化医疗至关重要，可以受益于离线强化学习（RL）。虽然医疗机构间有大量健康数据可用，但由于隐私限制，它们无法共享。此外，不同站点存在异质性。因此，联邦离线RL算法是必要的且有前途，以解决这些问题。本文提出了一种多站点马尔可夫决策过程模型，允许站点之间的同质性和异质性效应。所提出的模型可以分析站点级特征。我们设计了第一个具有样本复杂度的离线RL联邦策略优化算法。所提出的算法具有通信效率和隐私保护性，仅需要通过交换摘要统计量进行一轮通信交互。我们为所提出的算法提供了理论保证，无需假设站点之间具有相同的转换动态。我们在现实医学数据集上进行了模拟，展示了所提出算法的有效性和效率。

    Evidence-based or data-driven dynamic treatment regimes are essential for personalized medicine, which can benefit from offline reinforcement learning (RL). Although massive healthcare data are available across medical institutions, they are prohibited from sharing due to privacy constraints. Besides, heterogeneity exists in different sites. As a result, federated offline RL algorithms are necessary and promising to deal with the problems. In this paper, we propose a multi-site Markov decision process model which allows both homogeneous and heterogeneous effects across sites. The proposed model makes the analysis of the site-level features possible. We design the first federated policy optimization algorithm for offline RL with sample complexity. The proposed algorithm is communication-efficient and privacy-preserving, which requires only a single round of communication interaction by exchanging summary statistics. We give a theoretical guarantee for the proposed algorithm without the 
    
[^53]: AugLoss：一种稳健的基于数据增强的微调方法

    AugLoss: A Robust Augmentation-based Fine Tuning Methodology. (arXiv:2206.02286v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02286](http://arxiv.org/abs/2206.02286)

    AugLoss是一种简单而有效的方法，通过统一数据增强和稳健损失函数，实现了对训练时的噪声标注和测试时的特征分布转移的稳健性。

    

    深度学习模型在许多领域取得了巨大的成功。然而，深度学习模型越来越面临安全性和鲁棒性方面的问题，包括训练阶段的噪声标注和测试阶段的特征分布转移。以往的研究在解决这些问题方面取得了显著进展，但主要集中在一次只解决一个问题的解决方案上。例如，最近的研究提出了使用可调的稳健损失函数来减轻标签噪声，以及使用数据增强（例如AugMix）来解决分布转移问题。为了同时解决这两个问题，我们引入了AugLoss，一种简单但有效的方法，通过统一数据增强和稳健损失函数，实现了对训练时的噪声标注和测试时的特征分布转移的稳健性。我们在各种真实数据集损坏设置下进行了全面的实验，展示了与以前方法相比AugLoss所取得的收益。

    Deep Learning (DL) models achieve great successes in many domains. However, DL models increasingly face safety and robustness concerns, including noisy labeling in the training stage and feature distribution shifts in the testing stage. Previous works made significant progress in addressing these problems, but the focus has largely been on developing solutions for only one problem at a time. For example, recent work has argued for the use of tunable robust loss functions to mitigate label noise, and data augmentation (e.g., AugMix) to combat distribution shifts. As a step towards addressing both problems simultaneously, we introduce AugLoss, a simple but effective methodology that achieves robustness against both train-time noisy labeling and test-time feature distribution shifts by unifying data augmentation and robust loss functions. We conduct comprehensive experiments in varied settings of real-world dataset corruption to showcase the gains achieved by AugLoss compared to previous 
    
[^54]: 优化自适应重要抽样器的全局收敛性分析

    Global convergence of optimized adaptive importance samplers. (arXiv:2201.00409v2 [stat.CO] UPDATED)

    [http://arxiv.org/abs/2201.00409](http://arxiv.org/abs/2201.00409)

    本文分析了用于一般提案的优化自适应重要抽样器（OAIS）的性能，并开发了一个可以全局优化$\chi^2$散度的方案。该方案通过利用非凸优化理论，填补了对于一般提案的全局优化缺失。得到的AIS方案具有显式的理论保证，并且保证在任意时刻均成立。

    

    本文分析了用于一般提案的优化自适应重要抽样器（OAIS）在进行蒙特卡罗积分时的性能。我们利用了一个经典结果，该结果显示了重要抽样的偏差和均方误差（MSE）与目标和提案之间的$\chi^2$散度呈比例关系，并开发了一个方案，可以对$\chi^2$散度进行全局优化。虽然对于指数族提案，已知该量是凸的，但对于一般提案，这个问题一直是一个未解之谜。我们通过利用随机梯度Langevin动态（SGLD）的非渐近边界进行$\chi^2$散度的全局优化，并利用最近的非凸优化文献的结果推导出MSE的非渐近边界，来填补这个空白。得到的AIS方案具有显式的理论保证，并且保证在任意时刻均成立。

    We analyze the optimized adaptive importance sampler (OAIS) for performing Monte Carlo integration with general proposals. We leverage a classical result which shows that the bias and the mean-squared error (MSE) of the importance sampling scales with the $\chi^2$-divergence between the target and the proposal and develop a scheme which performs global optimization of $\chi^2$-divergence. While it is known that this quantity is convex for exponential family proposals, the case of the general proposals has been an open problem. We close this gap by utilizing the nonasymptotic bounds for stochastic gradient Langevin dynamics (SGLD) for the global optimization of $\chi^2$-divergence and derive nonasymptotic bounds for the MSE by leveraging recent results from non-convex optimization literature. The resulting AIS schemes have explicit theoretical guarantees that are uniform-in-time.
    
[^55]: 计算机视觉中基于自监督学习的时序方法

    Computer Vision Self-supervised Learning Methods on Time Series. (arXiv:2109.00783v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.00783](http://arxiv.org/abs/2109.00783)

    该研究评估了计算机视觉自监督学习框架在时间序列上的效果，并且提出了一种改进方法，通过改进协方差项和添加迭代归一化层，加速了模型的收敛。

    

    自监督学习（SSL）在计算机视觉领域取得了巨大成功。目前主流的计算机视觉自监督学习框架大多基于Siamese网络架构。这些方法通常依赖于精心设计的损失函数和训练设置，以避免特征崩溃。本研究评估了这些计算机视觉自监督学习框架在不同模态（即时间序列）上的效果。我们在UCR和UEA档案上进行了实验证明，计算机视觉自监督学习框架在时间序列上同样有效。此外，我们提出了一种改进最近提出的VICReg方法的新方法。我们改进了VICReg中提出的一个“协方差”项，同时在架构的头部增加了一个迭代归一化层，加速了模型的收敛。

    Self-supervised learning (SSL) has had great success in both computer vision. Most of the current mainstream computer vision SSL frameworks are based on Siamese network architecture. These approaches often rely on cleverly crafted loss functions and training setups to avoid feature collapse. In this study, we evaluate if those computer-vision SSL frameworks are also effective on a different modality (\textit{i.e.,} time series). The effectiveness is experimented and evaluated on the UCR and UEA archives, and we show that the computer vision SSL frameworks can be effective even for time series. In addition, we propose a new method that improves on the recently proposed VICReg method. Our method improves on a \textit{covariance} term proposed in VICReg, and in addition we augment the head of the architecture by an iterative normalization layer that accelerates the convergence of the model.
    
[^56]: 动态协变量平衡：基于潜在局部投影的治疗效果随时间估计

    Dynamic covariate balancing: estimating treatment effects over time with potential local projections. (arXiv:2103.01280v3 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2103.01280](http://arxiv.org/abs/2103.01280)

    本文提出了一种通过动态协变量平衡方法，基于过去历史上潜在结果期望的局部投影，估计面板数据中动态变化的治疗效果，并考虑结果和时间变化的协变量与治疗轨迹的关系以及治疗效应的异质性。研究结果表明该方法具有良好的渐近性质和数值特性，在实证应用中具有优势。

    

    本文研究了面板数据中治疗历史的估计和推断问题，特别是在治疗在时间上动态变化的情况下。我们提出了一种方法，允许治疗根据高维协变量、过去的结果和治疗动态分配，同时考虑结果和时间变化的协变量与治疗轨迹的关系，以及治疗效应的异质性。我们的方法通过在过去历史上对潜在结果期望进行递归投影，然后通过平衡动态可观测特征来控制偏差。我们研究了估计量的渐近性质和数值特性，并在实证应用中展示了该方法的优势。

    This paper studies the estimation and inference of treatment histories in panel data settings when treatments change dynamically over time.  We propose a method that allows for (i) treatments to be assigned dynamically over time based on high-dimensional covariates, past outcomes and treatments; (ii) outcomes and time-varying covariates to depend on treatment trajectories; (iii) heterogeneity of treatment effects.  Our approach recursively projects potential outcomes' expectations on past histories. It then controls the bias by balancing dynamically observable characteristics. We study the asymptotic and numerical properties of the estimator and illustrate the benefits of the procedure in an empirical application.
    
[^57]: 一种整合和分类正态分布的方法

    A method to integrate and classify normal distributions. (arXiv:2012.14331v8 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2012.14331](http://arxiv.org/abs/2012.14331)

    本文介绍了一种可以对任意参数维度下的任意域内正态分布进行积分的方法，提供了法向向量函数的相关概率密度和统计指标，同时还提供了可以对任意数量正态分布进行分类的方法和维度降低和可视化的技术。

    

    单变量和多变量正态概率分布在模拟不确定性决策中被广泛使用。计算这些模型的性能需要在特定区域内对这些分布进行积分，这在不同的模型中可以有很大的差异。除了一些特殊情况，目前不存在通用的分析表达式、标准数值方法或软件来计算这些积分。本文提供了数学结果和开源软件，可以提供以下内容：（i）任意参数维度下任意域内法向的概率，（ii）法向向量函数的概率密度、累积分布和逆累积分布，（iii）任意数量正态分布之间的分类误差、贝叶斯最优辨别指数以及其与工作特征曲线的关系，（iv）此类问题的维度降低和可视化，以及（v）对于给定数据这些方法的可靠性测试。我们通过几个具体的例子，包括金融、生物和心理学来演示这些功能。

    Univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. Computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. Besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. Here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the Bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. We demonstrate these
    
[^58]: 多视角堆叠中的视图选择：选择元学习器

    View selection in multi-view stacking: Choosing the meta-learner. (arXiv:2010.16271v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.16271](http://arxiv.org/abs/2010.16271)

    选择合适的元学习器对于多视角堆叠中的视图选择和分类准确性是非常重要的，通过对七种不同的算法进行评估，非负套索、非负自适应套索和非负弹性网络被认为是最合适的元学习器。

    

    多视角堆叠是一种将来自不同视图（即不同的特征集）描述相同对象的信息相结合的框架。在该框架中，基学习算法分别在每个视图上进行训练，它们的预测结果由元学习算法组合。在之前的研究中，堆叠的罚分逻辑回归，作为多视角堆叠的一种特殊情况，已被证明在识别对预测最重要的视图方面是有用的。在本文中，我们通过考虑七种不同的算法作为元学习器，并在模拟和两个真实的基因表达数据集上评估它们的视图选择和分类性能，扩展了这项研究。我们的结果表明，如果视图选择和分类准确性对研究都很重要，那么非负套索、非负自适应套索和非负弹性网络都是合适的元学习器。具体在这三种方法中该选择哪一种取决于...

    Multi-view stacking is a framework for combining information from different views (i.e. different feature sets) describing the same set of objects. In this framework, a base-learner algorithm is trained on each view separately, and their predictions are then combined by a meta-learner algorithm. In a previous study, stacked penalized logistic regression, a special case of multi-view stacking, has been shown to be useful in identifying which views are most important for prediction. In this article we expand this research by considering seven different algorithms to use as the meta-learner, and evaluating their view selection and classification performance in simulations and two applications on real gene-expression data sets. Our results suggest that if both view selection and classification accuracy are important to the research at hand, then the nonnegative lasso, nonnegative adaptive lasso and nonnegative elastic net are suitable meta-learners. Exactly which among these three is to be
    
[^59]: 《高斯过程回归的直观教程》

    An Intuitive Tutorial to Gaussian Process Regression. (arXiv:2009.10862v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2009.10862](http://arxiv.org/abs/2009.10862)

    《高斯过程回归的直观教程》是一篇介绍高斯过程回归的教程，旨在直观地解释GPR的基本概念、提供实现代码，并回顾最先进的高斯过程算法。适合机器学习初学者阅读，帮助他们清晰理解GPR的基本原理。

    

    本教程旨在直观介绍高斯过程回归（GPR）。由于其灵活性和对预测不确定性的固有能力，GPR模型在机器学习应用中得到广泛应用。教程从解释高斯过程构建的基本概念开始，包括多元正态分布、核函数、非参数模型以及联合概率和条件概率。然后，它提供了对GPR的简明描述和标准GPR算法的实现。此外，教程还回顾了实现最先进的高斯过程算法的软件包。本教程适用于广泛的受众，包括对机器学习不熟悉的人，以确保对GPR的基本原理有清晰的理解。

    This tutorial aims to provide an intuitive introduction to Gaussian process regression (GPR). GPR models have been widely used in machine learning applications due to their representation flexibility and inherent capability to quantify uncertainty over predictions. The tutorial starts with explaining the basic concepts that a Gaussian process is built on, including multivariate normal distribution, kernels, non-parametric models, and joint and conditional probability. It then provides a concise description of GPR and an implementation of a standard GPR algorithm. In addition, the tutorial reviews packages for implementing state-of-the-art Gaussian process algorithms. This tutorial is accessible to a broad audience, including those new to machine learning, ensuring a clear understanding of GPR fundamentals.
    
[^60]: 非渐进性分析中的随机梯度哈密顿蒙特卡罗方法在非凸优化中的局部条件下

    Nonasymptotic analysis of Stochastic Gradient Hamiltonian Monte Carlo under local conditions for nonconvex optimization. (arXiv:2002.05465v4 [math.OC] UPDATED)

    [http://arxiv.org/abs/2002.05465](http://arxiv.org/abs/2002.05465)

    在非凸优化中，我们提供了随机梯度哈密顿蒙特卡罗（SGHMC）的非渐进性分析，证明了SGHMC作为采样器的关键理论性质，并在局部条件下获得非凸优化问题的非渐进性界限，该方法在迭代次数上可以提供高精度的结果，并以已知最佳速率收敛到全局最小值。

    

    我们在不假设对数凹性的情况下，对随机梯度哈密顿蒙特卡罗（SGHMC）的收敛性进行了非渐进性分析，以Wasserstein-2距离衡量它到目标测度的收敛程度。我们的分析在局部条件下，量化了SGHMC作为采样器的关键理论性质，显著改进了之前结果的发现。特别是，我们证明了目标与SGHMC法则之间的Wasserstein-2距离由算法的步长统一控制，从而证明了SGHMC在迭代次数上可以提供高精度的结果。该分析还使我们能够在局部条件下获得非凸优化问题的非渐进性界限，并意味着将SGHMC视为非凸优化器时，它以已知最佳速率收敛到全局最小值。我们应用我们的结果来获得可扩展的贝叶斯推理和非渐进性泛化界限。

    We provide a nonasymptotic analysis of the convergence of the stochastic gradient Hamiltonian Monte Carlo (SGHMC) to a target measure in Wasserstein-2 distance without assuming log-concavity. Our analysis quantifies key theoretical properties of the SGHMC as a sampler under local conditions which significantly improves the findings of previous results. In particular, we prove that the Wasserstein-2 distance between the target and the law of the SGHMC is uniformly controlled by the step-size of the algorithm, therefore demonstrate that the SGHMC can provide high-precision results uniformly in the number of iterations. The analysis also allows us to obtain nonasymptotic bounds for nonconvex optimization problems under local conditions and implies that the SGHMC, when viewed as a nonconvex optimizer, converges to a global minimum with the best known rates. We apply our results to obtain nonasymptotic bounds for scalable Bayesian inference and nonasymptotic generalization bounds.
    
[^61]: 通过元学习对图神经网络进行对抗攻击

    Adversarial Attacks on Graph Neural Networks via Meta Learning. (arXiv:1902.08412v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1902.08412](http://arxiv.org/abs/1902.08412)

    本文通过元梯度方式对图神经网络进行训练时攻击，通过微小的图扰动导致性能下降，并证明了即使在无监督嵌入中也能产生迁移效应。这些攻击不需要任何关于目标分类器的知识或访问权限。

    

    图神经网络被广泛应用于许多任务中并取得了最新的成功，但它们的鲁棒性还知之甚少。本文通过研究对节点分类中的图神经网络进行的训练时攻击，在离散图结构上进行微小扰动。我们的核心原则是使用元梯度来解决训练时攻击背后的双层问题，本质上将图视为优化的超参数。我们的实验证明，微小的图扰动通常会导致图卷积网络性能的大幅下降，甚至传递给无监督嵌入。值得注意的是，我们的算法所创建的扰动可以误导图神经网络，使其性能比忽略所有关联信息的简单基线模型更差。我们的攻击不需要任何关于目标分类器的知识或访问权限。

    Deep learning models for graphs have advanced the state of the art on many tasks. Despite their recent success, little is known about their robustness. We investigate training time attacks on graph neural networks for node classification that perturb the discrete graph structure. Our core principle is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. Our experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings. Remarkably, the perturbations created by our algorithm can misguide the graph neural networks such that they perform worse than a simple baseline that ignores all relational information. Our attacks do not assume any knowledge about or access to the target classifiers.
    

