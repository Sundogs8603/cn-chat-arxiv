# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [On Computationally Efficient Learning of Exponential Family Distributions.](http://arxiv.org/abs/2309.06413) | 本研究提出了一种计算高效的估计器，用于准确学习具有任意精度的自然参数的指数族分布。该估计器是一致的、渐近正态的，并可视为最大似然估计的重新参数化分布。 |
| [^2] | [Generalized Regret Analysis of Thompson Sampling using Fractional Posteriors.](http://arxiv.org/abs/2309.06349) | 这项研究对使用分数后验概率的汤普森抽样算法进行了广义遗憾分析，获得了依赖于实例和实例独立的频率遗憾界。这对多臂赌博问题的解决有重要意义。 |
| [^3] | [Modeling Supply and Demand in Public Transportation Systems.](http://arxiv.org/abs/2309.06299) | 该论文在公共交通系统中建立了供需模型，利用数据分析和机器学习技术揭示了运营服务中的空缺。 |
| [^4] | [Consistency and adaptivity are complementary targets for the validation of variance-based uncertainty quantification metrics in machine learning regression tasks.](http://arxiv.org/abs/2309.06240) | 这篇论文研究了机器学习回归任务中基于方差的不确定性量化度量的验证，发现一致性和适应性是互补的验证目标，并提出了适应性验证方法。 |
| [^5] | [A Consistent and Scalable Algorithm for Best Subset Selection in Single Index Models.](http://arxiv.org/abs/2309.06230) | 该论文提出了针对高维单指数模型中最佳子集选择的一致性和可扩展算法，通过使用广义信息准则来确定支持的回归系数大小，消除了模型选择的调优需求，并具有子集选择一致性和高概率下的理想属性。 |
| [^6] | [Certified Robust Models with Slack Control and Large Lipschitz Constants.](http://arxiv.org/abs/2309.06166) | 本文提出了一种校准的Lipschitz边界误差（CLL）来提高认证鲁棒性，通过解决边界误差不会根据收缩的输出分布调整惩罚和最小化Lipschitz常数导致过度平滑的问题。 |
| [^7] | [On Regularized Sparse Logistic Regression.](http://arxiv.org/abs/2309.05925) | 本文提出了解决正则稀疏逻辑回归的方法，包括$\ell_1$正则化稀疏逻辑回归和一些满足先决条件的非凸惩罚正则化稀疏逻辑回归。经验实验表明，这些算法能够以较低的计算成本有效地进行分类和特征选择。 |
| [^8] | [Reaction coordinate flows for model reduction of molecular kinetics.](http://arxiv.org/abs/2309.05878) | 该论文介绍了一种基于流的机器学习方法，称为反应坐标流，用于发现分子系统低维动力学模型，该方法能够以连续时间和空间中的可训练和可处理的方式进行模型简化，产生准确和可解释的低维表示。 |
| [^9] | [Subgroup detection in linear growth curve models with generalized linear mixed model (GLMM) trees.](http://arxiv.org/abs/2309.05862) | 本研究介绍了如何使用广义线性混合效应模型（GLMM）树来识别线性增长曲线模型中的子群，扩展的GLMM树在各种数据集上表现出更准确的性能，并且可以同时建模离散和连续的预测变量。 |
| [^10] | [Liu-type Shrinkage Estimators for Mixture of Poisson Regressions with Experts: A Heart Disease Study.](http://arxiv.org/abs/2309.05838) | 这项研究开发了Ridge和刘型方法，用于处理混合泊松回归模型中的病态设计矩阵，证明了其有效性。 |
| [^11] | [Interpretable learning of effective dynamics for multiscale systems.](http://arxiv.org/abs/2309.05812) | 该论文提出了一种新的可解释学习有效动力学（iLED）框架，它通过引入深度循环神经网络技术，在保持准确性的同时提供了可解释性，解决了现有神经网络在复杂系统中应用受限的问题。 |
| [^12] | [On the Fine-Grained Hardness of Inverting Generative Models.](http://arxiv.org/abs/2309.05795) | 本文提供了反转生成模型的计算难度的细粒度视图，建立了对精确和近似模型反转的新的难度下界。 |
| [^13] | [The Effect of Intrinsic Dimension on Metric Learning under Compression.](http://arxiv.org/abs/2309.05751) | 本论文研究了内在维度对压缩下的度量学习的影响，提出了在对数据进行随机压缩后在低维空间内训练全秩度量的方法。理论保证了在不依赖环境维度的情况下，度量学习的误差可以被控制，并且在存在良性几何结构时效果更好。 |
| [^14] | [Diffusion on the Probability Simplex.](http://arxiv.org/abs/2309.02530) | 本文提出了一种在概率单纯形上执行扩散的方法，通过使用softmax函数应用于阿恩斯坦-乌伦贝克过程，可以在处理连续性和离散性对象之间的紧张关系时取得良好效果。这种方法也可以扩展到单位立方体上，从而在有界图像生成方面具有应用前景。 |
| [^15] | [Temporal-spatial model via Trend Filtering.](http://arxiv.org/abs/2308.16172) | 本研究通过趋势滤波方法对具有时空依赖性的数据进行了非参数回归函数的估计，研究了该方法在单变量和多变量情况下的应用，并验证了其极小化性。研究发现了以往未曾探索的独特相变现象，并通过仿真和实际数据应用验证了方法的优越性能。 |
| [^16] | [Pattern Recovery in Penalized and Thresholded Estimation and its Geometry.](http://arxiv.org/abs/2307.10158) | 我们提出了一种惩罚化和阈值化估计的模式恢复方法，并定义了模式和恢复条件。对于LASSO，无噪声恢复条件和互不表示条件起到了相同的作用。 |
| [^17] | [Flooding with Absorption: An Efficient Protocol for Heterogeneous Bandits over Complex Networks.](http://arxiv.org/abs/2303.05445) | 该论文提出了一种名为带吸收的泛洪（FwA）的新协议，用于解决复杂网络上的异构赌博机问题。通过严格的遗憾分析，证明了该协议的有效性。 |
| [^18] | [Deep-OSG: Deep Learning of Operators in Semigroup.](http://arxiv.org/abs/2302.03358) | 本文提出了一种深度学习方法，用于学习半群中的运算符，可以将未知自主动力系统建模为时间序列数据，在不同时间滞后下收集。这种方法能够学习具有可变时间步长的演化算符，构成自主系统的半群。 |
| [^19] | [Robust Markov Decision Processes without Model Estimation.](http://arxiv.org/abs/2302.01248) | 这篇论文提出了一种无需模型估计的鲁棒MDPs算法，通过将原始问题转化为另一种形式，并使用随机梯度方法求解，从而去除了对优化器的依赖。 |
| [^20] | [Spatiotemporal Clustering with Neyman-Scott Processes via Connections to Bayesian Nonparametric Mixture Models.](http://arxiv.org/abs/2201.05044) | 这篇论文介绍了Neyman-Scott过程（NSPs）和贝叶斯非参数混合模型（DPMM）之间的新颖联系，并探讨了NSP在时空数据建模中的应用。 |
| [^21] | [Out-of-distribution detection for regression tasks: parameter versus predictor entropy.](http://arxiv.org/abs/2010.12995) | 本研究针对回归任务中的离群样本检测进行了实证评估，发现通过学习多样的预测器可以估计新观测实例的认识不确定性，但参数的多样性并不一定能转化为预测器的多样性。 |
| [^22] | [Distributionally Robust Batch Contextual Bandits.](http://arxiv.org/abs/2006.05630) | 本文提出了一种方法，在不完整的观察数据下学习分布鲁棒的策略，通过引入策略评估过程和中心极限定理类型的保证，实现了针对最坏情况下的环境转变的策略学习。 |
| [^23] | [Empirical and Instance-Dependent Estimation of Markov Chain and Mixing Time.](http://arxiv.org/abs/1912.06845) | 我们提出了一种实证和实例依赖的方法来估计马尔可夫链的混合时间。我们基于收缩系数来估计混合时间，该系数能够控制混合时间直到强的普遍常数，并且适用于非可逆链。与现有方法相比，我们的方法计算更容易且置信区间更精确，还引入了一种新的分析方法来考虑转移矩阵的附加信息。 |

# 详细

[^1]: 计算有效学习指数族分布

    On Computationally Efficient Learning of Exponential Family Distributions. (arXiv:2309.06413v1 [cs.LG])

    [http://arxiv.org/abs/2309.06413](http://arxiv.org/abs/2309.06413)

    本研究提出了一种计算高效的估计器，用于准确学习具有任意精度的自然参数的指数族分布。该估计器是一致的、渐近正态的，并可视为最大似然估计的重新参数化分布。

    

    本研究考虑了以计算和统计的高效方式，准确学习具有任意精度的自然参数的$k$参数截断\textit{最小}指数族分布。我们关注的是支持和自然参数适当有界的情况。虽然传统的最大似然估计器对于这类指数族分布是一致的、渐近正态的和渐近有效的，但其计算复杂度很高。在这项工作中，我们提出了一种新的损失函数和计算高效的估计器，在温和条件下一致且渐近正态。我们证明，在总体水平上，我们的方法可以被看作是同一类指数族分布的参数化分布的最大似然估计。此外，我们还证明了我们的估计器可以解释为最小化特定Bregman得分的解决方案。

    We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner. We focus on the setting where the support as well as the natural parameters are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard. In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions. We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family. Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as w
    
[^2]: 使用分数后验概率对汤普森抽样进行广义遗憾分析

    Generalized Regret Analysis of Thompson Sampling using Fractional Posteriors. (arXiv:2309.06349v1 [stat.ML])

    [http://arxiv.org/abs/2309.06349](http://arxiv.org/abs/2309.06349)

    这项研究对使用分数后验概率的汤普森抽样算法进行了广义遗憾分析，获得了依赖于实例和实例独立的频率遗憾界。这对多臂赌博问题的解决有重要意义。

    

    汤普森抽样（TS）是解决随机多臂赌博问题的最流行和最早的算法之一。我们考虑了TS的一个变种，称为α-TS，其中我们使用分数或α-后验（α∈（0,1））代替标准后验分布。为了计算α-后验，标准后验的定义中的似然函数被一个因子α搅拌。对于α-TS，我们在非常温和的先验和奖励分布条件下获得了既依赖于实例的Ο（∑_{k≠i^*}Δ_k（\frac{\log(T)}{C(α)Δ_k^2}+\frac{1}{2}））也依赖于实例独立的Ο（\sqrt{KT\log K}）频率遗憾界，其中Δ_k是第k个和最好的臂的真实均值奖励之间的差，而C(α)是已知的常数。子高斯和指数族模型都满足我们对奖励分布的一般条件。我们对先验的条件是...

    Thompson sampling (TS) is one of the most popular and earliest algorithms to solve stochastic multi-armed bandit problems. We consider a variant of TS, named $\alpha$-TS, where we use a fractional or $\alpha$-posterior ($\alpha\in(0,1)$) instead of the standard posterior distribution. To compute an $\alpha$-posterior, the likelihood in the definition of the standard posterior is tempered with a factor $\alpha$. For $\alpha$-TS we obtain both instance-dependent $\mathcal{O}\left(\sum_{k \neq i^*} \Delta_k\left(\frac{\log(T)}{C(\alpha)\Delta_k^2} + \frac{1}{2} \right)\right)$ and instance-independent $\mathcal{O}(\sqrt{KT\log K})$ frequentist regret bounds under very mild conditions on the prior and reward distributions, where $\Delta_k$ is the gap between the true mean rewards of the $k^{th}$ and the best arms, and $C(\alpha)$ is a known constant. Both the sub-Gaussian and exponential family models satisfy our general conditions on the reward distribution. Our conditions on the prior di
    
[^3]: 在公共交通系统中建模供需

    Modeling Supply and Demand in Public Transportation Systems. (arXiv:2309.06299v1 [cs.LG])

    [http://arxiv.org/abs/2309.06299](http://arxiv.org/abs/2309.06299)

    该论文在公共交通系统中建立了供需模型，利用数据分析和机器学习技术揭示了运营服务中的空缺。

    

    哈里森堡公共交通部门旨在利用其数据提高运营效率和效果。我们构建了两个供需模型，帮助部门识别服务中的空缺。模型考虑了许多变量，包括哈里森堡市向联邦政府报告的方式以及最脆弱人口聚集的区域。我们采用数据分析和机器学习技术进行预测。

    The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations. We construct two supply and demand models that help the department identify gaps in their service. The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City. We employ data analysis and machine learning techniques to make our predictions.
    
[^4]: 一致性和适应性是验证机器学习回归任务中基于方差的不确定性量化度量的互补目标

    Consistency and adaptivity are complementary targets for the validation of variance-based uncertainty quantification metrics in machine learning regression tasks. (arXiv:2309.06240v1 [stat.ML])

    [http://arxiv.org/abs/2309.06240](http://arxiv.org/abs/2309.06240)

    这篇论文研究了机器学习回归任务中基于方差的不确定性量化度量的验证，发现一致性和适应性是互补的验证目标，并提出了适应性验证方法。

    

    可靠的不确定性量化是材料和化学科学中许多研究的焦点。目前已经认识到平均校准是不足够的，大多数研究都使用额外的方法来测试条件校准，即一致性。一致性主要通过可靠性图来评估。然而，除了平均校准之外还存在一种方法，即基于输入特征的条件校准，也就是适应性。实际上，适应性是ML-UQ方法的最终用户关注的主要问题，他们寻求对特征空间中的任何点的预测和不确定性的可靠性。本文旨在展示一致性和适应性是互补的验证目标，并且好的一致性并不意味着好的适应性。文章提出并在一个典型示例上进行了适应性验证方法的说明。

    Reliable uncertainty quantification (UQ) in machine learning (ML) regression tasks is becoming the focus of many studies in materials and chemical science. It is now well understood that average calibration is insufficient, and most studies implement additional methods testing the conditional calibration with respect to uncertainty, i.e. consistency. Consistency is assessed mostly by so-called reliability diagrams. There exists however another way beyond average calibration, which is conditional calibration with respect to input features, i.e. adaptivity. In practice, adaptivity is the main concern of the final users of a ML-UQ method, seeking for the reliability of predictions and uncertainties for any point in features space. This article aims to show that consistency and adaptivity are complementary validation targets, and that a good consistency does not imply a good adaptivity. Adapted validation methods are proposed and illustrated on a representative example.
    
[^5]: 单指数模型中最佳子集选择的一致性和可扩展算法

    A Consistent and Scalable Algorithm for Best Subset Selection in Single Index Models. (arXiv:2309.06230v1 [stat.ML])

    [http://arxiv.org/abs/2309.06230](http://arxiv.org/abs/2309.06230)

    该论文提出了针对高维单指数模型中最佳子集选择的一致性和可扩展算法，通过使用广义信息准则来确定支持的回归系数大小，消除了模型选择的调优需求，并具有子集选择一致性和高概率下的理想属性。

    

    高维数据的分析引发了对单指数模型（SIMs）和最佳子集选择的增加兴趣。SIMs为高维数据提供了一种可解释和灵活的建模框架，而最佳子集选择旨在从大量的预测因子中找到稀疏模型。然而，在高维模型中的最佳子集选择被认为是计算上难以处理的。现有的方法倾向于放宽选择，但不能得到最佳子集解。在本文中，我们通过提出第一个经过证明的针对高维SIMs中最佳子集选择的可扩展算法，直接解决了计算难题。我们的算法解具有子集选择一致性，并且几乎肯定具有用于参数估计的虚拟属性。该算法包括一个广义信息准则来确定回归系数的支持大小，消除模型选择调整。此外，我们的方法不假设误差分布或特定参数。

    Analysis of high-dimensional data has led to increased interest in both single index models (SIMs) and best subset selection. SIMs provide an interpretable and flexible modeling framework for high-dimensional data, while best subset selection aims to find a sparse model from a large set of predictors. However, best subset selection in high-dimensional models is known to be computationally intractable. Existing methods tend to relax the selection, but do not yield the best subset solution. In this paper, we directly tackle the intractability by proposing the first provably scalable algorithm for best subset selection in high-dimensional SIMs. Our algorithmic solution enjoys the subset selection consistency and has the oracle property with a high probability. The algorithm comprises a generalized information criterion to determine the support size of the regression coefficients, eliminating the model selection tuning. Moreover, our method does not assume an error distribution or a specif
    
[^6]: 具有弹性控制和较大Lipschitz常数的认证鲁棒模型

    Certified Robust Models with Slack Control and Large Lipschitz Constants. (arXiv:2309.06166v1 [cs.LG])

    [http://arxiv.org/abs/2309.06166](http://arxiv.org/abs/2309.06166)

    本文提出了一种校准的Lipschitz边界误差（CLL）来提高认证鲁棒性，通过解决边界误差不会根据收缩的输出分布调整惩罚和最小化Lipschitz常数导致过度平滑的问题。

    

    尽管最近取得了成功，但目前最先进的基于学习的模型仍然对输入变化，如对抗样本，非常容易受到攻击。为了获得对这种扰动的可证明的鲁棒性，最近的研究考虑了基于Lipschitz的正则化器或约束，同时增加了预测边界。不幸的是，这样做会显著降低准确性。在本文中，我们提出了一个校准的Lipschitz边界误差（CLL）来解决这个问题，并通过解决两个问题来提高认证鲁棒性：首先，常用的边界误差不会根据收缩的输出分布调整惩罚，这是由于最小化Lipschitz常数K所造成的。其次，最重要的是，我们观察到最小化K可以导致决策函数过度平滑。这限制了模型的复杂性，从而降低了准确性。我们的CLL通过明确校准损失与边界和Lipschitz常数的关系来解决这些问题，从而确保模型具有较高的准确性。

    Despite recent success, state-of-the-art learning-based models remain highly vulnerable to input changes such as adversarial examples. In order to obtain certifiable robustness against such perturbations, recent work considers Lipschitz-based regularizers or constraints while at the same time increasing prediction margin. Unfortunately, this comes at the cost of significantly decreased accuracy. In this paper, we propose a Calibrated Lipschitz-Margin Loss (CLL) that addresses this issue and improves certified robustness by tackling two problems: Firstly, commonly used margin losses do not adjust the penalties to the shrinking output distribution; caused by minimizing the Lipschitz constant $K$. Secondly, and most importantly, we observe that minimization of $K$ can lead to overly smooth decision functions. This limits the model's complexity and thus reduces accuracy. Our CLL addresses these issues by explicitly calibrating the loss w.r.t. margin and Lipschitz constant, thereby establis
    
[^7]: 关于正则稀疏逻辑回归的研究

    On Regularized Sparse Logistic Regression. (arXiv:2309.05925v1 [cs.LG])

    [http://arxiv.org/abs/2309.05925](http://arxiv.org/abs/2309.05925)

    本文提出了解决正则稀疏逻辑回归的方法，包括$\ell_1$正则化稀疏逻辑回归和一些满足先决条件的非凸惩罚正则化稀疏逻辑回归。经验实验表明，这些算法能够以较低的计算成本有效地进行分类和特征选择。

    

    稀疏逻辑回归旨在同时进行高维数据的分类和特征选择。虽然有许多研究解决了$\ell_1$正则化逻辑回归问题，但对于与非凸惩罚相关的稀疏逻辑回归解决方案并没有等量的文献。本文提出了解决$\ell_1$正则化稀疏逻辑回归和一些满足一定先决条件的非凸惩罚正则化稀疏逻辑回归的方法，并采用类似的优化框架。在提出的优化框架中，我们利用不同的线搜索准则来保证不同正则化项的良好收敛性能。通过对真实世界数据集的二元分类任务进行经验实验，我们证明了我们提出的算法能够以较低的计算成本有效地进行分类和特征选择。

    Sparse logistic regression aims to perform classification and feature selection simultaneously for high-dimensional data. Although many studies have been done to solve $\ell_1$-regularized logistic regression, there is no equivalently abundant literature about solving sparse logistic regression associated with nonconvex penalties. In this paper, we propose to solve $\ell_1$-regularized sparse logistic regression and some nonconvex penalties-regularized sparse logistic regression, when the nonconvex penalties satisfy some prerequisites, with similar optimization frameworks. In the proposed optimization frameworks, we utilize different line search criteria to guarantee good convergence performance for different regularization terms. Empirical experiments on binary classification tasks with real-world datasets demonstrate our proposed algorithms are capable of performing classification and feature selection effectively with a lower computational cost.
    
[^8]: 反应坐标流在分子动力学模型简化中的应用

    Reaction coordinate flows for model reduction of molecular kinetics. (arXiv:2309.05878v1 [cs.LG])

    [http://arxiv.org/abs/2309.05878](http://arxiv.org/abs/2309.05878)

    该论文介绍了一种基于流的机器学习方法，称为反应坐标流，用于发现分子系统低维动力学模型，该方法能够以连续时间和空间中的可训练和可处理的方式进行模型简化，产生准确和可解释的低维表示。

    

    在这项工作中，我们引入了一种基于流的机器学习方法，称为反应坐标（RC）流，用于发现分子系统低维动力学模型。RC流利用归一化流设计坐标变换，并使用布朗动力学模型来近似RC的动力学，所有模型参数可以以数据驱动的方式进行估计。与现有的分子动力学模型简化方法不同，由于归一化流的可逆性，RC流在连续时间和空间中提供了可训练和可处理的简化动力学模型。此外，本文研究的基于布朗动力学的简化动力学模型在分子系统的相空间中产生了易于辨别的亚稳态表示。数值实验证明了所提方法如何有效地发现给定的完整状态动力学的可解释和准确的低维表示。

    In this work, we introduce a flow based machine learning approach, called reaction coordinate (RC) flow, for discovery of low-dimensional kinetic models of molecular systems. The RC flow utilizes a normalizing flow to design the coordinate transformation and a Brownian dynamics model to approximate the kinetics of RC, where all model parameters can be estimated in a data-driven manner. In contrast to existing model reduction methods for molecular kinetics, RC flow offers a trainable and tractable model of reduced kinetics in continuous time and space due to the invertibility of the normalizing flow. Furthermore, the Brownian dynamics-based reduced kinetic model investigated in this work yields a readily discernible representation of metastable states within the phase space of the molecular system. Numerical experiments demonstrate how effectively the proposed method discovers interpretable and accurate low-dimensional representations of given full-state kinetics from simulations.
    
[^9]: 线性增长曲线模型中的子群检测与广义线性混合模型（GLMM）树研究

    Subgroup detection in linear growth curve models with generalized linear mixed model (GLMM) trees. (arXiv:2309.05862v1 [stat.ME])

    [http://arxiv.org/abs/2309.05862](http://arxiv.org/abs/2309.05862)

    本研究介绍了如何使用广义线性混合效应模型（GLMM）树来识别线性增长曲线模型中的子群，扩展的GLMM树在各种数据集上表现出更准确的性能，并且可以同时建模离散和连续的预测变量。

    

    增长曲线模型是研究随时间在个体内部发展的响应变量的常用工具。这种模型中经常存在个体之间的异质性，研究者通常对解释或预测这种异质性感兴趣。我们展示了如何使用广义线性混合效应模型（GLMM）树来识别线性增长曲线模型中具有不同形状轨迹的子群。最初是针对聚类的横断面数据开发的GLMM树在这里被扩展到纵向数据。得到的扩展GLMM树可直接应用于增长曲线模型作为一个重要的特例。在模拟和真实数据中，我们评估了扩展的性能，并与其他用于增长曲线模型的分割方法进行了比较。扩展的GLMM树的性能比原始算法和LongCART更准确，并且与结构方程模型（SEM）树的准确性相似。此外，GLMM树可以对离散和连续的预测变量建模。

    Growth curve models are popular tools for studying the development of a response variable within subjects over time. Heterogeneity between subjects is common in such models, and researchers are typically interested in explaining or predicting this heterogeneity. We show how generalized linear mixed effects model (GLMM) trees can be used to identify subgroups with differently shaped trajectories in linear growth curve models. Originally developed for clustered cross-sectional data, GLMM trees are extended here to longitudinal data. The resulting extended GLMM trees are directly applicable to growth curve models as an important special case. In simulated and real-world data, we assess the performance of the extensions and compare against other partitioning methods for growth curve models. Extended GLMM trees perform more accurately than the original algorithm and LongCART, and similarly accurate as structural equation model (SEM) trees. In addition, GLMM trees allow for modeling both dis
    
[^10]: 采用刘型收缩估计的混合泊松回归方法在心脏病研究中的应用

    Liu-type Shrinkage Estimators for Mixture of Poisson Regressions with Experts: A Heart Disease Study. (arXiv:2309.05838v1 [stat.ME])

    [http://arxiv.org/abs/2309.05838](http://arxiv.org/abs/2309.05838)

    这项研究开发了Ridge和刘型方法，用于处理混合泊松回归模型中的病态设计矩阵，证明了其有效性。

    

    计数数据在医学研究中，如心脏病研究中发挥着重要作用。泊松回归模型是评估一组协变量对计数响应影响的常用技术。混合泊松回归模型与专家方法是一种实用工具，不仅可以处理泊松回归中的异质性，还可以学习人群的混合结构。多重共线性是回归模型中常见的挑战之一，导致泊松回归分量和专家类的设计矩阵病态。最大似然方法在多重共线性中产生不可靠和误导性的估计结果。在这项研究中，我们开发了Ridge和刘型方法作为两种收缩方法，用于应对混合泊松回归模型与专家的病态设计矩阵。通过多种数值研究，我们证明了收缩方法在解决泊松回归模型与专家的病态设计矩阵中的有效性。

    Count data play a critical role in medical research, such as heart disease. The Poisson regression model is a common technique for evaluating the impact of a set of covariates on the count responses. The mixture of Poisson regression models with experts is a practical tool to exploit the covariates, not only to handle the heterogeneity in the Poisson regressions but also to learn the mixing structure of the population. Multicollinearity is one of the most common challenges with regression models, leading to ill-conditioned design matrices of Poisson regression components and expert classes. The maximum likelihood method produces unreliable and misleading estimates for the effects of the covariates in multicollinearity. In this research, we develop Ridge and Liu-type methods as two shrinkage approaches to cope with the ill-conditioned design matrices of the mixture of Poisson regression models with experts. Through various numerical studies, we demonstrate that the shrinkage methods off
    
[^11]: 可解释多尺度系统有效动力学学习

    Interpretable learning of effective dynamics for multiscale systems. (arXiv:2309.05812v1 [stat.ML])

    [http://arxiv.org/abs/2309.05812](http://arxiv.org/abs/2309.05812)

    该论文提出了一种新的可解释学习有效动力学（iLED）框架，它通过引入深度循环神经网络技术，在保持准确性的同时提供了可解释性，解决了现有神经网络在复杂系统中应用受限的问题。

    

    高维多尺度系统的建模和仿真是科学和工程领域面临的重要挑战。尽管现今的计算机技术不断进步，解决由控制方程描述的所有时空尺度仍然是一个遥不可及的目标。这种认识促使人们大力发展模型降阶技术。近年来，基于深度循环神经网络的技术在复杂时空系统的建模和仿真方面取得了令人鼓舞的成果，并且具有模型开发的灵活性，因为它们可以结合实验和计算数据。然而，神经网络缺乏可解释性，限制了它们在复杂系统中的实用性和普适性。在这里，我们提出了一种新的可解释学习有效动力学（iLED）框架，它具有与基于循环神经网络的最新方法相当的准确性，并提供了额外的好处。

    The modeling and simulation of high-dimensional multiscale systems is a critical challenge across all areas of science and engineering. It is broadly believed that even with today's computer advances resolving all spatiotemporal scales described by the governing equations remains a remote target. This realization has prompted intense efforts to develop model order reduction techniques. In recent years, techniques based on deep recurrent neural networks have produced promising results for the modeling and simulation of complex spatiotemporal systems and offer large flexibility in model development as they can incorporate experimental and computational data. However, neural networks lack interpretability, which limits their utility and generalizability across complex systems. Here we propose a novel framework of Interpretable Learning Effective Dynamics (iLED) that offers comparable accuracy to state-of-the-art recurrent neural network-based approaches while providing the added benefit o
    
[^12]: 关于反转生成模型的细粒度难度

    On the Fine-Grained Hardness of Inverting Generative Models. (arXiv:2309.05795v1 [stat.ML])

    [http://arxiv.org/abs/2309.05795](http://arxiv.org/abs/2309.05795)

    本文提供了反转生成模型的计算难度的细粒度视图，建立了对精确和近似模型反转的新的难度下界。

    

    生成模型反转的目标是识别一个大小为$n$的潜在向量，该向量能够产生与给定目标密切匹配的生成模型输出。这个问题在涉及计算机视觉和自然语言处理的许多现代应用中是核心的计算原语。然而，该问题在最坏情况下被认为是计算上具有挑战性和NP难解的。本文旨在提供对这个问题的计算难度的细粒度视图。我们针对精确和近似模型反转建立了几个新的难度下界。在精确反转中，目标是确定一个目标是否包含在给定生成模型的范围内。在强指数时间假设（SETH）下，我们通过从$k$-SAT的约简来证明，精确反转的计算复杂度下界为$\Omega(2^n)$；这是已知结果的加强版。对于更具实际意义的近似反转问题，目标是寻找一个潜在向量，使得生成模型输出与给定目标尽可能接近。在这种情况下，我们证明了存在一个常数$\gamma$，使得除非$\text{NP}\subseteq \text{BPTIME}(2^{O(n^\gamma)})$，否则近似反转问题的计算复杂度无法突破$\Omega(2^{n/2})$。

    The objective of generative model inversion is to identify a size-$n$ latent vector that produces a generative model output that closely matches a given target. This operation is a core computational primitive in numerous modern applications involving computer vision and NLP. However, the problem is known to be computationally challenging and NP-hard in the worst case. This paper aims to provide a fine-grained view of the landscape of computational hardness for this problem. We establish several new hardness lower bounds for both exact and approximate model inversion. In exact inversion, the goal is to determine whether a target is contained within the range of a given generative model. Under the strong exponential time hypothesis (SETH), we demonstrate that the computational complexity of exact inversion is lower bounded by $\Omega(2^n)$ via a reduction from $k$-SAT; this is a strengthening of known results. For the more practically relevant problem of approximate inversion, the goal 
    
[^13]: 内在维度对压缩下的度量学习的影响

    The Effect of Intrinsic Dimension on Metric Learning under Compression. (arXiv:2309.05751v1 [cs.LG])

    [http://arxiv.org/abs/2309.05751](http://arxiv.org/abs/2309.05751)

    本论文研究了内在维度对压缩下的度量学习的影响，提出了在对数据进行随机压缩后在低维空间内训练全秩度量的方法。理论保证了在不依赖环境维度的情况下，度量学习的误差可以被控制，并且在存在良性几何结构时效果更好。

    

    度量学习旨在在输入空间中找到适当的距离度量，以改善基于距离的学习算法的性能。在高维环境中，度量学习还可以作为降维的手段，通过对学习的度量施加一个低秩约束。本文中，我们考虑的是对数据的一个随机压缩版本，然后在其中训练一个全秩的度量。我们给出了关于距离度量学习的误差的理论保证，这些保证不依赖于环境维度。我们的边界除了对来自有界支持的独立同分布数据没有显式的假设之外，并且在存在良性几何结构时自动收敛。在合成和真实数据集上的实验结果支持我们在高维环境中的理论发现。

    Metric learning aims at finding a suitable distance metric over the input space, to improve the performance of distance-based learning algorithms. In high-dimensional settings, metric learning can also play the role of dimensionality reduction, by imposing a low-rank restriction to the learnt metric. In this paper, instead of training a low-rank metric on high-dimensional data, we consider a randomly compressed version of the data, and train a full-rank metric there. We give theoretical guarantees on the error of distance-based metric learning, with respect to the random compression, which do not depend on the ambient dimension. Our bounds do not make any explicit assumptions, aside from i.i.d. data from a bounded support, and automatically tighten when benign geometrical structures are present. Experimental results on both synthetic and real data sets support our theoretical findings in high-dimensional settings.
    
[^14]: 概率单纯形上的扩散

    Diffusion on the Probability Simplex. (arXiv:2309.02530v1 [cs.LG])

    [http://arxiv.org/abs/2309.02530](http://arxiv.org/abs/2309.02530)

    本文提出了一种在概率单纯形上执行扩散的方法，通过使用softmax函数应用于阿恩斯坦-乌伦贝克过程，可以在处理连续性和离散性对象之间的紧张关系时取得良好效果。这种方法也可以扩展到单位立方体上，从而在有界图像生成方面具有应用前景。

    

    扩散模型通过学习逆转数据分布的逐渐噪声化来创建一个生成模型。然而，连续的噪声化过程与离散数据之间的期望不一致。为了解决连续性和离散性对象之间的紧张关系，我们提出了在概率单纯形上执行扩散的方法。使用概率单纯形自然地创建了一种解释，其中点对应于分类概率分布。我们的方法使用对阿恩斯坦-乌伦贝克过程之间进行softmax函数的应用，这是一个众所周知的随机微分方程。我们发现我们的方法也自然地扩展到包括对单位立方体的扩散，这对于有界图像生成应用具有意义。

    Diffusion models learn to reverse the progressive noising of a data distribution to create a generative model. However, the desired continuous nature of the noising process can be at odds with discrete data. To deal with this tension between continuous and discrete objects, we propose a method of performing diffusion on the probability simplex. Using the probability simplex naturally creates an interpretation where points correspond to categorical probability distributions. Our method uses the softmax function applied to an Ornstein-Unlenbeck Process, a well-known stochastic differential equation. We find that our methodology also naturally extends to include diffusion on the unit cube which has applications for bounded image generation.
    
[^15]: 通过趋势滤波进行时空模型建模

    Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v1 [stat.ME])

    [http://arxiv.org/abs/2308.16172](http://arxiv.org/abs/2308.16172)

    本研究通过趋势滤波方法对具有时空依赖性的数据进行了非参数回归函数的估计，研究了该方法在单变量和多变量情况下的应用，并验证了其极小化性。研究发现了以往未曾探索的独特相变现象，并通过仿真和实际数据应用验证了方法的优越性能。

    

    本研究侧重于对具有同时时间和空间依赖性的数据进行非参数回归函数的估计。在这种情况下，我们研究了趋势滤波，这是一种非参数估计方法，由Mammen和Rudin提出。在单变量设置中，我们考虑的信号假设具有有界总变异度的k次弱导数，允许一定程度的平滑性。在多变量情况下，我们研究了Padilla等人的K最近邻融合套索估计器，采用适用于具有有界变异度且符合分段利普希茨连续性准则的信号的ADMM算法。通过与下界对齐，我们验证了我们估计器的极小化性。通过分析，我们发现了以往趋势滤波研究中未曾探索过的独特相变现象。仿真研究和实际数据应用都突出了我们方法的出色性能。

    This research focuses on the estimation of a non-parametric regression function designed for data with simultaneous time and space dependencies. In such a context, we study the Trend Filtering, a nonparametric estimator introduced by \cite{mammen1997locally} and \cite{rudin1992nonlinear}. For univariate settings, the signals we consider are assumed to have a kth weak derivative with bounded total variation, allowing for a general degree of smoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused lasso estimator as in \cite{padilla2018adaptive}, employing an ADMM algorithm, suitable for signals with bounded variation that adhere to a piecewise Lipschitz continuity criterion. By aligning with lower bounds, the minimax optimality of our estimators is validated. A unique phase transition phenomenon, previously uncharted in Trend Filtering studies, emerges through our analysis. Both Simulation studies and real data applications underscore the superior performance of o
    
[^16]: 惩罚化和阈值化估计中的模式恢复及其几何

    Pattern Recovery in Penalized and Thresholded Estimation and its Geometry. (arXiv:2307.10158v1 [math.ST])

    [http://arxiv.org/abs/2307.10158](http://arxiv.org/abs/2307.10158)

    我们提出了一种惩罚化和阈值化估计的模式恢复方法，并定义了模式和恢复条件。对于LASSO，无噪声恢复条件和互不表示条件起到了相同的作用。

    

    我们考虑惩罚估计的框架，其中惩罚项由实值的多面体规范给出，其中包括诸如LASSO（以及其许多变体如广义LASSO）、SLOPE、OSCAR、PACS等方法。每个估计器可以揭示未知参数向量的不同结构或“模式”。我们定义了基于次微分的模式的一般概念，并形式化了一种衡量其复杂性的方法。对于模式恢复，我们提供了一个特定模式以正概率被该过程检测到的最小条件，即所谓的可达性条件。利用我们的方法，我们还引入了更强的无噪声恢复条件。对于LASSO，众所周知，互不表示条件是使模式恢复的概率大于1/2所必需的，并且我们展示了无噪声恢复起到了完全相同的作用，从而扩展和统一了互不表示条件。

    We consider the framework of penalized estimation where the penalty term is given by a real-valued polyhedral gauge, which encompasses methods such as LASSO (and many variants thereof such as the generalized LASSO), SLOPE, OSCAR, PACS and others. Each of these estimators can uncover a different structure or ``pattern'' of the unknown parameter vector. We define a general notion of patterns based on subdifferentials and formalize an approach to measure their complexity. For pattern recovery, we provide a minimal condition for a particular pattern to be detected by the procedure with positive probability, the so-called accessibility condition. Using our approach, we also introduce the stronger noiseless recovery condition. For the LASSO, it is well known that the irrepresentability condition is necessary for pattern recovery with probability larger than $1/2$ and we show that the noiseless recovery plays exactly the same role, thereby extending and unifying the irrepresentability conditi
    
[^17]: 带吸收的泛洪：复杂网络上异构赌博机的高效协议

    Flooding with Absorption: An Efficient Protocol for Heterogeneous Bandits over Complex Networks. (arXiv:2303.05445v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.05445](http://arxiv.org/abs/2303.05445)

    该论文提出了一种名为带吸收的泛洪（FwA）的新协议，用于解决复杂网络上的异构赌博机问题。通过严格的遗憾分析，证明了该协议的有效性。

    

    多臂赌博机广泛用于建模顺序决策，在许多现实应用中如在线推荐系统和无线网络中无处不在。我们考虑一个多代理的场景，每个代理解决自己的赌博机问题，赌博机拥有不同的臂。他们的目标是在通过给定网络的通信协议协作的同时最小化他们的集体遗憾。先前关于此问题的文献只考虑了臂的异质性和网络化代理问题。在这项工作中，我们引入了一个同时包含这两个特性的设置。针对这一新颖的设置，我们首先对标准泛洪协议结合经典的上置信界策略提供了严格的遗憾分析。然后，为了减轻在复杂网络中泛洪造成的高通信成本问题，我们提出了一种新的协议，称为带吸收的泛洪（FwA）。我们对由此产生的遗憾上界进行了理论分析，并讨论了该协议的优点。

    Multi-armed bandits are extensively used to model sequential decision-making, making them ubiquitous in many real-life applications such as online recommender systems and wireless networking. We consider a multi-agent setting where each agent solves their own bandit instance endowed with a different set of arms. Their goal is to minimize their group regret while collaborating via some communication protocol over a given network. Previous literature on this problem only considered arm heterogeneity and networked agents separately. In this work, we introduce a setting that encompasses both features. For this novel setting, we first provide a rigorous regret analysis for a standard flooding protocol combined with the classic UCB policy. Then, to mitigate the issue of high communication costs incurred by flooding in complex networks, we propose a new protocol called Flooding with Absorption (FwA). We provide a theoretical analysis of the resulting regret bound and discuss the advantages of
    
[^18]: Deep-OSG：半群中的运算符的深度学习方法

    Deep-OSG: Deep Learning of Operators in Semigroup. (arXiv:2302.03358v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03358](http://arxiv.org/abs/2302.03358)

    本文提出了一种深度学习方法，用于学习半群中的运算符，可以将未知自主动力系统建模为时间序列数据，在不同时间滞后下收集。这种方法能够学习具有可变时间步长的演化算符，构成自主系统的半群。

    

    本文提出了一种新颖的深度学习方法，用于学习半群中的运算符，并应用于使用在不同时间滞后下收集的时间序列数据对未知自主动力系统进行建模。本文是之前流图学习(FML)工作的续集，该工作主要集中在学习具有固定时间步长的单一演化算符。本文旨在学习一族具有可变时间步长的演化算符，构成自主系统的半群。半群性质对于联系系统在不同时间尺度上的演化行为非常重要，但在以前的研究中没有考虑到这一点。我们首次提出了将半群性质嵌入数据驱动学习过程的框架，通过一种新颖的神经网络

    This paper proposes a novel deep learning approach for learning operators in semigroup, with applications to modeling unknown autonomous dynamical systems using time series data collected at varied time lags. It is a sequel to the previous flow map learning (FML) works [T. Qin, K. Wu, and D. Xiu, J. Comput. Phys., 395:620--635, 2019], [K. Wu and D. Xiu, J. Comput. Phys., 408:109307, 2020], and [Z. Chen, V. Churchill, K. Wu, and D. Xiu, J. Comput. Phys., 449:110782, 2022], which focused on learning single evolution operator with a fixed time step. This paper aims to learn a family of evolution operators with variable time steps, which constitute a semigroup for an autonomous system. The semigroup property is very crucial and links the system's evolutionary behaviors across varying time scales, but it was not considered in the previous works. We propose for the first time a framework of embedding the semigroup property into the data-driven learning process, through a novel neural network
    
[^19]: 无需模型估计的鲁棒马尔科夫决策过程

    Robust Markov Decision Processes without Model Estimation. (arXiv:2302.01248v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.01248](http://arxiv.org/abs/2302.01248)

    这篇论文提出了一种无需模型估计的鲁棒MDPs算法，通过将原始问题转化为另一种形式，并使用随机梯度方法求解，从而去除了对优化器的依赖。

    

    鲁棒马尔科夫决策过程（MDPs）在学习一个对环境变化不敏感的鲁棒策略方面受到了广泛关注。目前有越来越多的工作分析鲁棒MDPs的采样效率。然而，在实际应用中应用鲁棒MDPs存在两个主要障碍。首先，大多数工作都是在模型为基础的情况下研究鲁棒MDPs，其中转移概率需要进行估计，需要大量的记忆（O(|S|²|A|)）。其次，之前的工作通常假设存在一个强大的优化器来获得最优解，用作解决鲁棒MDPs的中间步骤。然而，在实践中，通常并不存在这样的优化器。为了去除优化器的依赖，我们将原始的鲁棒MDPs转化为另一种形式，使我们能够使用随机梯度方法来求解鲁棒MDPs。此外，我们证明了这种替代形式仍然具有类似的作用。通过这种新的公式，我们设计了一种采样有效的算法来解决鲁棒MDPs。

    Robust Markov Decision Processes (MDPs) are receiving much attention in learning a robust policy which is less sensitive to environment changes. There are an increasing number of works analyzing sample-efficiency of robust MDPs. However, there are two major barriers to applying robust MDPs in practice. First, most works study robust MDPs in a model-based regime, where the transition probability needs to be estimated and requires a large amount of memories $\mathcal{O}(|\mathcal{S}|^2|\mathcal{A}|)$. Second, prior work typically assumes a strong oracle to obtain the optimal solution as an intermediate step to solve robust MDPs. However, in practice, such an oracle does not exist usually. To remove the oracle, we transform the original robust MDPs into an alternative form, which allows us to use stochastic gradient methods to solve the robust MDPs. Moreover, we prove the alternative form still plays a similar role as the original form. With this new formulation, we devise a sample-effici
    
[^20]: 通过与贝叶斯非参数混合模型的联系，使用Neyman-Scott过程进行时空聚类

    Spatiotemporal Clustering with Neyman-Scott Processes via Connections to Bayesian Nonparametric Mixture Models. (arXiv:2201.05044v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2201.05044](http://arxiv.org/abs/2201.05044)

    这篇论文介绍了Neyman-Scott过程（NSPs）和贝叶斯非参数混合模型（DPMM）之间的新颖联系，并探讨了NSP在时空数据建模中的应用。

    

    Neyman-Scott过程（NSPs）是生成时间或空间中点簇的点过程模型。它们是一种适用于广泛现象的自然模型，从神经脉冲序列到文档流。聚类属性是通过双重随机公式实现的：首先，从泊松过程中绘制一组潜在事件；然后，每个潜在事件根据另一个泊松过程生成一组观测数据点。这个结构类似于贝叶斯非参数混合模型，如狄利克雷过程混合模型（DPMM），其中潜在事件（即簇）的数量是一个随机变量，但点过程的构造使得NSP特别适合于建模时空数据。虽然为DPMM开发了许多专门算法，但相对较少的工作集中在NSP的推断上。在这里，我们介绍了NSP与DPMM之间的新颖联系，关键的连接是第三类贝叶斯混合模型

    Neyman-Scott processes (NSPs) are point process models that generate clusters of points in time or space. They are natural models for a wide range of phenomena, ranging from neural spike trains to document streams. The clustering property is achieved via a doubly stochastic formulation: first, a set of latent events is drawn from a Poisson process; then, each latent event generates a set of observed data points according to another Poisson process. This construction is similar to Bayesian nonparametric mixture models like the Dirichlet process mixture model (DPMM) in that the number of latent events (i.e. clusters) is a random variable, but the point process formulation makes the NSP especially well suited to modeling spatiotemporal data. While many specialized algorithms have been developed for DPMMs, comparatively fewer works have focused on inference in NSPs. Here, we present novel connections between NSPs and DPMMs, with the key link being a third class of Bayesian mixture models c
    
[^21]: 回归任务中的离群样本检测：参数与预测器熵比较

    Out-of-distribution detection for regression tasks: parameter versus predictor entropy. (arXiv:2010.12995v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2010.12995](http://arxiv.org/abs/2010.12995)

    本研究针对回归任务中的离群样本检测进行了实证评估，发现通过学习多样的预测器可以估计新观测实例的认识不确定性，但参数的多样性并不一定能转化为预测器的多样性。

    

    对于机器学习模型来说，检测样本与训练样本相距太远时至关重要，这被称为离群样本（OOD）检测。对于神经网络而言，一种处理这个任务的方法是学习多样的预测器，这些预测器都能解释训练数据。这些信息可以用来估计新观测实例的认识不确定性，通过预测结果的不一致性来衡量。评估和认证方法检测OOD的能力需要指定在部署中可能发生但没有可用预测的实例。我们选择回归任务作为研究重点，在此任务中选择一个简单而有洞察力的模型来表示OOD分布，并对各种方法在区分OOD样本和数据中的能力进行实证评估。此外，我们还提供证据表明，参数的多样性可能无法转化为预测器的多样性。

    It is crucial to detect when an instance lies downright too far from the training samples for the machine learning model to be trusted, a challenge known as out-of-distribution (OOD) detection. For neural networks, one approach to this task consists of learning a diversity of predictors that all can explain the training data. This information can be used to estimate the epistemic uncertainty at a given newly observed instance in terms of a measure of the disagreement of the predictions. Evaluation and certification of the ability of a method to detect OOD require specifying instances which are likely to occur in deployment yet on which no prediction is available. Focusing on regression tasks, we choose a simple yet insightful model for this OOD distribution and conduct an empirical evaluation of the ability of various methods to discriminate OOD samples from the data. Moreover, we exhibit evidence that a diversity of parameters may fail to translate to a diversity of predictors. Based 
    
[^22]: 分布鲁棒的批次情境强化学习

    Distributionally Robust Batch Contextual Bandits. (arXiv:2006.05630v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.05630](http://arxiv.org/abs/2006.05630)

    本文提出了一种方法，在不完整的观察数据下学习分布鲁棒的策略，通过引入策略评估过程和中心极限定理类型的保证，实现了针对最坏情况下的环境转变的策略学习。

    

    使用历史观察数据进行策略学习是一个重要的问题，已经在广泛的应用中得到应用。例如，选择向客户发送的优惠、价格、广告，以及选择给患者开具哪种药物。然而，现有的文献基于一个关键假设，即学习到的策略将被部署到的未来环境与生成数据的过去环境相同，而这个假设往往是错误的或者过于粗略的近似。在本文中，我们放宽了这个假设，并旨在学习一个具有不完整观察数据的分布鲁棒策略。我们首先提出了一个策略评估过程，以评估策略在最坏情况下的环境转变下的表现。然后，我们建立了这个提出的策略评估方案的中心极限定理类型的保证。利用这个评估方案，我们进一步提出了一种新颖的学习算法，能够学习一个策略。

    Policy learning using historical observational data is an important problem that has found widespread applications. Examples include selecting offers, prices, advertisements to send to customers, as well as selecting which medication to prescribe to a patient. However, existing literature rests on the crucial assumption that the future environment where the learned policy will be deployed is the same as the past environment that has generated the data -- an assumption that is often false or too coarse an approximation. In this paper, we lift this assumption and aim to learn a distributionally robust policy with incomplete observational data. We first present a policy evaluation procedure that allows us to assess how well the policy does under the worst-case environment shift. We then establish a central limit theorem type guarantee for this proposed policy evaluation scheme. Leveraging this evaluation scheme, we further propose a novel learning algorithm that is able to learn a policy 
    
[^23]: 马尔可夫链和混合时间的实证和实例依赖估计

    Empirical and Instance-Dependent Estimation of Markov Chain and Mixing Time. (arXiv:1912.06845v4 [math.PR] UPDATED)

    [http://arxiv.org/abs/1912.06845](http://arxiv.org/abs/1912.06845)

    我们提出了一种实证和实例依赖的方法来估计马尔可夫链的混合时间。我们基于收缩系数来估计混合时间，该系数能够控制混合时间直到强的普遍常数，并且适用于非可逆链。与现有方法相比，我们的方法计算更容易且置信区间更精确，还引入了一种新的分析方法来考虑转移矩阵的附加信息。

    

    我们解决了从单个观测轨迹估计马尔可夫链混合时间的问题。与大多数先前使用希尔伯特空间方法估计谱缺口的工作不同，我们选择采用基于总变差收缩的方法。具体地，我们估计了Wolfer [2020]中引入的收缩系数，受到Dobrushin的启发。与谱缺口不同，这个数量控制着混合时间直到强的普遍常数，并且适用于非可逆链。我们改进了现有的完全依赖数据的置信区间，这些区间比谱相关数量更容易计算且更薄。此外，我们通过利用关于转移矩阵的附加信息，引入了一种超过最坏情况分析的新方法。这使我们能够针对诱导均匀范数和一些混合属性，导出与矩阵估计有关的实例依赖的速率。

    We address the problem of estimating the mixing time of a Markov chain from a single trajectory of observations. Unlike most previous works which employed Hilbert space methods to estimate spectral gaps, we opt for an approach based on contraction with respect to total variation. Specifically, we estimate the contraction coefficient introduced in Wolfer [2020], inspired from Dobrushin's. This quantity, unlike the spectral gap, controls the mixing time up to strong universal constants and remains applicable to non-reversible chains. We improve existing fully data-dependent confidence intervals around this contraction coefficient, which are both easier to compute and thinner than spectral counterparts. Furthermore, we introduce a novel analysis beyond the worst-case scenario by leveraging additional information about the transition matrix. This allows us to derive instance-dependent rates for estimating the matrix with respect to the induced uniform norm, and some of its mixing propertie
    

