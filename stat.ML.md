# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Understanding Optimization of Deep Learning.](http://arxiv.org/abs/2306.09338) | 本文全面介绍了深度学习中梯度消失和梯度爆炸等优化挑战，并通过提高梯度流和对网络Lipschitz常数施加约束等措施进行了解决。显式优化和隐式优化是两种解决优化问题的不同方式。 |
| [^2] | [Class-Conditional Conformal Prediction With Many Classes.](http://arxiv.org/abs/2306.09335) | 提出了一种叫做聚类符合性预测的方法，可以在多类条件下提供类别条件符合性预测，针对多个类别的图像数据集中经验评估结果表明其优于现有方法。 |
| [^3] | [Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains.](http://arxiv.org/abs/2306.09332) | 本文提出了一种从快速混合马尔可夫链中实现样本高效的广义得分匹配方法，解决了得分匹配算法在具有较差等周性质的分布上的统计代价问题。 |
| [^4] | [A Heavy-Tailed Algebra for Probabilistic Programming.](http://arxiv.org/abs/2306.09262) | 本文提出了一种用于分析随机变量尾部的系统性方法，并通过开发一个尾部渐近的代数来处理在概率编程语言中的应用。该代数运算在加法和乘法下是封闭的，并能够处理比率，直接从定义中重现大多数统计分布的尾部。 |
| [^5] | [Towards Faster Non-Asymptotic Convergence for Diffusion-Based Generative Models.](http://arxiv.org/abs/2306.09251) | 该论文针对扩散生成模型设计了非渐进理论，提出了针对两种主流采样器的新的收敛速度，提高了总步数与收敛速度的比例。 |
| [^6] | [Logarithmic Bayes Regret Bounds.](http://arxiv.org/abs/2306.09136) | 该论文提出了对于贝叶斯赌博机的首个有限时间对数遗憾边界，并用于高斯和线性赌博机，从而阐明了贝叶斯设置中先验价值以及对$\tilde{O}(\sqrt{n})$界限的改善。 |
| [^7] | [On Certified Generalization in Structured Prediction.](http://arxiv.org/abs/2306.09112) | 该论文提出了一种新的结构化预测PAC-Bayesian风险界限，它可以随着结构化示例的数量和大小的变化而进行泛化，为使用生成模型建立结构化预测的泛化界限迈出了第一步。 |
| [^8] | [Optimal Best-Arm Identification in Bandits with Access to Offline Data.](http://arxiv.org/abs/2306.09048) | 本文针对带有相应离线数据的K臂赌博机问题，设计了一种算法，以1-delta置信度找到平均值最高的臂，并且在满足置信度要求的前提下，样本复杂度达到了下限。 |
| [^9] | [Multi-Loss Convolutional Network with Time-Frequency Attention for Speech Enhancement.](http://arxiv.org/abs/2306.08956) | 本文提出了利用自注意力模块的多损失卷积网络与时频注意力（MNTFA）模型，用于语音增强，实验结果表明该模型在 PESQ 和 STOI 指标方面达到了当前最先进水平。 |
| [^10] | [Bootstrap aggregation and confidence measures to improve time series causal discovery.](http://arxiv.org/abs/2306.08946) | 本文介绍了一种新的自助聚合和置信度度量方法，使得时间序列因果发现能够提供连接的置信度度量。在广泛的数值实验中，实验证明该方法提高了因果发现的性能。 |
| [^11] | [Hyperbolic Convolution via Kernel Point Aggregation.](http://arxiv.org/abs/2306.08862) | HKConv是一种新颖且可训练的双曲卷积，它可以根据双曲距离测量类似于旋转的变换等变性。 |
| [^12] | [A Gromov--Wasserstein Geometric View of Spectrum-Preserving Graph Coarsening.](http://arxiv.org/abs/2306.08854) | 本文提出了一种基于Gromov-Wasserstein距离的图缩减方法，该方法可以保持图的距离，并利用加权核$ K $ -means方法最小化差异，从而提高保谱方法的性能。 |
| [^13] | [Differentially Private Domain Adaptation with Theoretical Guarantees.](http://arxiv.org/abs/2306.08838) | 该论文提出了两种具有差分隐私保障的自适应算法，用于在受隐私约束且有限标记数据条件下，从公开源领域到目标领域进行监督域自适应。该算法能够解决一般的优化问题，并具有有利的理论学习保证。 |
| [^14] | [Exact Count of Boundary Pieces of ReLU Classifiers: Towards the Proper Complexity Measure for Classification.](http://arxiv.org/abs/2306.08805) | 通过精确计算ReLU分类器的边界区域片段数量，本文提出了一种基于边界复杂性度量方法来适当度量分类器复杂度的思想，并发现边界片段计数与泛化性能的相关性更高，具有明显的优势。 |
| [^15] | [Langevin Thompson Sampling with Logarithmic Communication: Bandits and Reinforcement Learning.](http://arxiv.org/abs/2306.08803) | 本文提出了一种带有对数通信的 Langevin Thompson Sampling 算法，可用于解决在赌博机和强化学习中学习未知的奖励分布和转移动态等问题。 |
| [^16] | [MPSA-DenseNet: A novel deep learning model for English accent classification.](http://arxiv.org/abs/2306.08798) | 本文介绍了三种使用DenseNet结合多任务学习和PSA模块注意机制的深度学习模型用于英语口音分类，并通过实验证明MPSA-DenseNet模型在识别英语口音方面具有很高的精确性和前瞻性。 |
| [^17] | [MMD-FUSE: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting.](http://arxiv.org/abs/2306.08777) | 本文提出了MMD-FUSE方法，通过适应内核集合最大化基于MMD的双样本检验功率，避免数据分割，并在低维合成数据和高维实际数据上证明了其适用性和功率超过现有最先进的核检验方法。 |
| [^18] | [WavPool: A New Block for Deep Neural Networks.](http://arxiv.org/abs/2306.08734) | WavPool是一种新型的深度神经网络模块，它通过添加池化层来使比例和空间信息同时可访问于网络，相较于其他模块具有更好的性能。 |
| [^19] | [Integrating Uncertainty Awareness into Conformalized Quantile Regression.](http://arxiv.org/abs/2306.08693) | 新提出的方法 UACQR 将条件分位估计和整合推断结合，以区分随机不确定性和认识性不确定性，并相应地构造预测区间，可以在量子回归器在特征空间的不同子集上优于现有的 CQR 方法。 |
| [^20] | [Predicting Real-time Crash Risks during Hurricane Evacuation Using Connected Vehicle Data.](http://arxiv.org/abs/2306.08682) | 本文提出了使用联网车辆数据来预测飓风疏散期间的车祸风险，通过分析车速和加速度曲线，可以实时评估交通安全状况。 |
| [^21] | [Anticipatory Music Transformer.](http://arxiv.org/abs/2306.08620) | 该论文提出一种预测音乐转换器，它能够实现在符号音乐生成的过程中进行控制，包括补全控制任务和伴奏，并且在大型且多样的数据集上表现出色。 |
| [^22] | [Multi-class Graph Clustering via Approximated Effective $p$-Resistance.](http://arxiv.org/abs/2306.08617) | 本文提出了一种近似计算有效$p$-阻抗并将其应用于多类图聚类，该方法可以通过参数$p$偏向于具有高内部连通性或者更小的簇内顶点之间的最短路径距离的聚类。 |
| [^23] | [Kernel Debiased Plug-in Estimation.](http://arxiv.org/abs/2306.08598) | 本文提出了一种高效、不需要实现影响函数且可计算的去偏插值估计方法。 |
| [^24] | [Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning.](http://arxiv.org/abs/2306.08590) | 本文通过实际数据的全面实证分析证明了在在线学习中，大学习率和小批量大小并不会带来任何隐性偏差的优势。在线学习中SGD噪音的好处只是计算上的便利，可以促进更大或更具成本效益的梯度步骤。 |
| [^25] | [Noise Stability Optimization for Flat Minima with Optimal Convergence Rates.](http://arxiv.org/abs/2306.08553) | 本文提出了一个SGD-like算法，注入随机噪声并利用分布对称性来减少方差，以寻找具有低海森矩阵迹的平坦极小值，同时提供了收敛速率分析。 |
| [^26] | [Analysis and Approximate Inference of Large and Dense Random Kronecker Graphs.](http://arxiv.org/abs/2306.08489) | 本文对大规模密集随机Kronecker图进行了分析和近似推断，提出了“去噪声和求解”元算法，用于近似推断图参数，并具有较低的计算复杂度和性能保证。 |
| [^27] | [Bandits with Replenishable Knapsacks: the Best of both Worlds.](http://arxiv.org/abs/2306.08470) | 本文研究了一种BwK框架自然推广，允许资源通过正值补充。我们提出了一个新的在线学习算法方案，该算法结合了在线凸优化技术和背包文献的思想，能够处理任何可补给的在线学习问题。 |
| [^28] | [Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression.](http://arxiv.org/abs/2306.08432) | 本文研究了将数据分成批次的学习算法，在高维超参数线性回归模型中提供了隐式正则化，通过适当的批量大小选择，稳定了风险行为，消除了插值点处的膨胀和双峰现象 |
| [^29] | [Provably Efficient Offline Reinforcement Learning with Perturbed Data Sources.](http://arxiv.org/abs/2306.08364) | 本文讨论了用于离线强化学习中的多数据源问题，提出了HetPEVI算法，并证明了其在数据覆盖率高的情况下可行且有效。 |
| [^30] | [Bayesian Non-linear Latent Variable Modeling via Random Fourier Features.](http://arxiv.org/abs/2306.08352) | 本文介绍了一种基于随机傅里叶特征的方法，可以将GPLVM推广到非高斯观测情况下的广义贝叶斯非线性潜变量建模，并提出了一种通过MCMC进行推断的方法。 |
| [^31] | [Nearly Optimal Algorithms with Sublinear Computational Complexity for Online Kernel Regression.](http://arxiv.org/abs/2306.08320) | 本文提出了两种新的算法AOGD-ALD和NONS-ALD，可以在亚线性计算复杂度下达到几乎最优的遗憾度，通过控制近似误差维护一组用于近似核映射的几乎正交基。 |
| [^32] | [Differentially Private Wireless Federated Learning Using Orthogonal Sequences.](http://arxiv.org/abs/2306.08280) | 本文提出了一种使用正交序列的FLORAS方法，可消除发送端的信道状态信息，同时提供了项目级和客户级的差分隐私保证。FLORAS可以灵活地实现不同的差分隐私等级，并且通过推导收敛界限，实现了收敛速度和隐私保证之间的平稳权衡。 |
| [^33] | [Unbiased Learning of Deep Generative Models with Structured Discrete Representations.](http://arxiv.org/abs/2306.08230) | 该论文提出了一种名为结构化变分自编码器的深度生成模型，它通过图像模型的结构和可解释性以及深度学习的适用于高维数据的灵活似然，结合两种框架的优势。同时，该论文还提出了一种学习SVAE的新算法，与此同时，推导出了一种计算自然梯度的方法，这些优化创新使得SVAE首次能与最先进的时间序列模型进行比较。 |
| [^34] | [Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training.](http://arxiv.org/abs/2306.08173) | 本文提出了一种差分隐私的CLIP模型（Dp-CLIP），旨在保护多模态AI任务中的数据隐私，同时保持模型准确性。该方法在基准数据集上得到了验证，并表明其与标准非私有CLIP模型相比具有同等的性能。 |
| [^35] | [Implicit Compressibility of Overparametrized Neural Networks Trained with Heavy-Tailed SGD.](http://arxiv.org/abs/2306.08125) | 本研究提出了一种简单的SGD修改方法，使训练出的神经网络输出可被证明为可压缩，而不需要任何非平凡假设。 |
| [^36] | [Symmetry & Critical Points for Symmetric Tensor Decompositions Problems.](http://arxiv.org/abs/2306.07886) | 本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。 |
| [^37] | [Incentivizing High-Quality Content in Online Recommender Systems.](http://arxiv.org/abs/2306.07479) | 本文研究了在线推荐系统中激励高质量内容的算法问题，经典的在线学习算法会激励生产者创建低质量的内容，但本文提出的一种算法通过惩罚低质量内容的创建者，成功地激励了生产者创造高质量的内容。 |
| [^38] | [Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders.](http://arxiv.org/abs/2305.19259) | 本论文研究了一种允许任意数据排序的普通SGD算法,并表明在非凸函数情况下，随机和单次洗牌的SGD比经典替换的SGD更快或至少与其一样好，无论迭代次数如何。 |
| [^39] | [Leveraging Evolutionary Changes for Software Process Quality.](http://arxiv.org/abs/2305.18061) | 本文提出了一种利用演进变化来改善软件开发过程质量的方法，其包括使用统计过程控制和机器学习技术来分析应用程序生命周期管理所捕获的变更数据，实验表明该方法是有效的。 |
| [^40] | [Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes.](http://arxiv.org/abs/2304.14034) | 本文研究了解耦高斯过程的正交分解问题，提出了一种扩展方法，即引入球形跨域特征，构建更灵活的数据依赖基函数来缓解限制，并展示了其有效性。 |
| [^41] | [B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding.](http://arxiv.org/abs/2304.10577) | 本文提出了一种元学习器 B-Learner，它可以在限制隐藏混淆水平的情况下高效地学习 CATE 函数的尖锐界限。 |
| [^42] | [Contextual Combinatorial Bandits with Probabilistically Triggered Arms.](http://arxiv.org/abs/2303.17110) | 本文研究了带有概率触发臂的情境组合赌博机，在不同条件下设计了C$^2$-UCB-T算法和VAC$^2$-UCB算法，并分别导出了对应的遗憾值上限，为相关应用提供了理论支持。 |
| [^43] | [Optimistic Planning by Regularized Dynamic Programming.](http://arxiv.org/abs/2302.14004) | 本文提出了一种基于正则化动态规划的乐观规划方法，可用于学习折扣线性混合MDPs中的最优策略，且具有近乎最优的统计保证 |
| [^44] | [Extrapolated cross-validation for randomized ensembles.](http://arxiv.org/abs/2302.13511) | 本论文提出了一种名为ECV的交叉验证方法，用于调整随机集成中的集成和子样本大小。该方法基于Out-of-Bag错误和利用预测风险分解结构的新型风险外推技术，能够产生$\delta$-最优（关于Oracle调整风险）的集成。 |
| [^45] | [Revisiting the Gumbel-Softmax in MADDPG.](http://arxiv.org/abs/2302.11793) | 本文探索了多种Gumbel-Softmax的替代方法，并将其应用于MADDPG中，以解决离散动作空间下的性能问题。 |
| [^46] | [Learning Manifold Dimensions with Conditional Variational Autoencoders.](http://arxiv.org/abs/2302.11756) | 该论文证明全局最优变分自编码器(CVAE)可以学习正确的流形维度，同时提出了一种新方法可以共同学习流形维度和条件分布，以在多个数据集上实现更好的特征分离和样本质量。 |
| [^47] | [Tighter Information-Theoretic Generalization Bounds from Supersamples.](http://arxiv.org/abs/2302.02432) | 本文介绍了一种新颖的信息论泛化界限，利用投影损失对，与Rademacher序列相关联来源于超取样的设置，这些界限比同一超取样设置中迄今已知的所有信息理论界限都更紧密。 |
| [^48] | [Large language models predict human sensory judgments across six modalities.](http://arxiv.org/abs/2302.01308) | 本研究表明，最先进的大型语言模型能预测人类在六个感官模态下的感知评判，并能提供从语言中提取感知信息的下限。 |
| [^49] | [SOBER: Highly Parallel Bayesian Optimization and Bayesian Quadrature over Discrete and Mixed Spaces.](http://arxiv.org/abs/2301.11832) | SOBER算法是一种在离散和混合空间上进行高并行贝叶斯优化的方法，能够进行可扩展和多样化的批量全局优化和积分，且优于11个竞争基线方法。 |
| [^50] | [Diffusion-based Conditional ECG Generation with Structured State Space Models.](http://arxiv.org/abs/2301.08227) | 本研究提出了将扩散模型和结构化状态空间模型相结合的新技术SSSD-ECG，在根据70多个心电图语句生成合成12导联心电图方面表现出色。 |
| [^51] | [Tight Certification of Adversarially Trained Neural Networks via Nonconvex Low-Rank Semidefinite Relaxations.](http://arxiv.org/abs/2211.17244) | 本文提出了一种新的，基于低秩半正定松弛技术实现对对抗性训练神经网络的严格认证方法，它能够实现采用更便宜的SDP方法相当的强认证。 |
| [^52] | [Bayesian Fixed-Budget Best-Arm Identification.](http://arxiv.org/abs/2211.08572) | 本文提出一种贝叶斯消除算法，用于解决固定预算下最佳臂识别问题，并且推导了其与先验相关的误识别上界，此算法优于频率学派方法，与无保证的贝叶斯算法相竞争。 |
| [^53] | [On the Exactness of Dantzig-Wolfe Relaxation for Rank Constrained Optimization Problems.](http://arxiv.org/abs/2210.16191) | 本文研究了DW松弛对RCOP的强度，并提出了同时必要和充分的条件，以确定DWR何时与任何m个双边线性矩阵不等式相匹配，包括三个方面的准确性：极端点的准确性、凸包的准确性以及目标的准确性。 |
| [^54] | [Topological Singularity Detection at Multiple Scales.](http://arxiv.org/abs/2210.00069) | 本文提出了一种多尺度拓扑奇异性检测方法，可以评估数据的局部固有维度，并量化点的“流形度”，能够检测复杂空间和图像中的奇异性。 |
| [^55] | [Investigating the Impact of Model Width and Density on Generalization in Presence of Label Noise.](http://arxiv.org/abs/2208.08003) | 本文研究发现标签噪声会导致双丘降曲线出现“最终上升”，即在足够大的噪声样本比率下，中等宽度下实现最佳泛化性能。随机丢弃可训练参数来减少密度可在标签噪声下改善泛化性能。 |
| [^56] | [Energy Trees: Regression and Classification With Structured and Mixed-Type Covariates.](http://arxiv.org/abs/2207.04430) | 本文提出了能量树作为一种回归和分类模型，可以有效处理各种类型的结构化协变量，并具有可解释性、尺度不变性和无分布假设的自由。 |
| [^57] | [The Neural Covariance SDE: Shaped Infinite Depth-and-Width Networks at Initialization.](http://arxiv.org/abs/2206.02768) | 本文研究了前馈神经网络初始化时的随机协方差矩阵分布，发现对激活函数进行形状塑造可以使协方差矩阵是非退化的，而随机协方差矩阵受到神经协方差SDE的随机微分方程的控制。 |
| [^58] | [Short-Term Density Forecasting of Low-Voltage Load using Bernstein-Polynomial Normalizing Flows.](http://arxiv.org/abs/2204.13939) | 本文提出了一种基于伯恩斯坦多项式归一化流的灵活条件密度预测方法，用于短期低压负荷预测，相比传统方法表现更好，可用于规划和运营低碳能源系统。 |
| [^59] | [Visualizing Deep Neural Networks with Topographic Activation Maps.](http://arxiv.org/abs/2204.03528) | 本文提出使用拓扑激活图来可视化深度神经网络及其决策过程，提高了 DNN 的可解释性。 |
| [^60] | [Phase diagram of Stochastic Gradient Descent in high-dimensional two-layer neural networks.](http://arxiv.org/abs/2202.00293) | 本文研究了高维两层神经网络中随机梯度下降的相图，探究了窄网络和过参数化浅层网络之间的交界处，并研究了三个方面变量之间的相互作用，工作建立在统计物理的框架下。 |
| [^61] | [Entropic Issues in Likelihood-Based OOD Detection.](http://arxiv.org/abs/2109.10794) | 本文研究了最大似然训练的深度生成模型的OOD检测问题，提出了一种新的观察角度，即将平均似然分解为KL散度项和熵项。后者可以解释模型可能会给OOD数据高似然值的现象，因为它抑制具有更高熵的数据集上的似然值。 |
| [^62] | [Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses.](http://arxiv.org/abs/2106.09779) | 本文研究了无需信任服务器或其他数据源的跨 silo 联邦学习，考虑了跨 silo 记录级差分隐私 ISRL-DP。该算法可以确保来自每个人的数据都不会被泄漏。 |
| [^63] | [Robust Sample Weighting to Facilitate Individualized Treatment Rule Learning for a Target Population.](http://arxiv.org/abs/2105.00581) | 本文研究了个体化治疗规则的泛化问题，提出一种加权框架方法以缓解因规定的函数类不包含最优规则而导致的影响。 |
| [^64] | [Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs.](http://arxiv.org/abs/2010.15285) | 该论文介绍了一种新颖的概率分布集合比较方法，能在流形和图上使用，该方法使用内在切片构造，得出一种新的类Wasserstein距离，可将分布集合比较问题减少到希尔伯特空间中更熟悉的均值检验问题。 |
| [^65] | [We Should at Least Be Able to Design Molecules That Dock Well.](http://arxiv.org/abs/2006.16955) | 该文提出了一个基于对接的基准测试来评估分子结合蛋白质的流行计算方法，探究了目前基于图形的生成模型在新型药物设计上的局限性，并提出了新的基准测试版本。 |

# 详细

[^1]: 深度学习的优化理解

    Understanding Optimization of Deep Learning. (arXiv:2306.09338v1 [cs.LG])

    [http://arxiv.org/abs/2306.09338](http://arxiv.org/abs/2306.09338)

    本文全面介绍了深度学习中梯度消失和梯度爆炸等优化挑战，并通过提高梯度流和对网络Lipschitz常数施加约束等措施进行了解决。显式优化和隐式优化是两种解决优化问题的不同方式。

    

    本文全面介绍了深度学习中的优化理论，主要关注梯度消失和梯度爆炸等问题所带来的模型表示能力降低和训练不稳定性等挑战。我们通过提高梯度流和对网络Lipschitz 常数施加约束等措施来分析这两个挑战。为了帮助理解当前的优化方法，我们将其分为显式优化方法和隐式优化方法。显式优化方法涉及直接操作优化器参数，包括权重、梯度、学习率和权重衰减等。相比之下，隐式优化方法侧重于通过增强网络模块（如残差快捷方式、标准化方法、注意机制和激活）来改善网络整体形势。本文提供了深入的分析和实验，以帮助研究人员更好地了解深度学习模型的优化方法。

    This article provides a comprehensive understanding of optimization in deep learning, with a primary focus on the challenges of gradient vanishing and gradient exploding, which normally lead to diminished model representational ability and training instability, respectively. We analyze these two challenges through several strategic measures, including the improvement of gradient flow and the imposition of constraints on a network's Lipschitz constant. To help understand the current optimization methodologies, we categorize them into two classes: explicit optimization and implicit optimization. Explicit optimization methods involve direct manipulation of optimizer parameters, including weight, gradient, learning rate, and weight decay. Implicit optimization methods, by contrast, focus on improving the overall landscape of a network by enhancing its modules, such as residual shortcuts, normalization methods, attention mechanisms, and activations. In this article, we provide an in-depth a
    
[^2]: 多类条件下的类别条件符合性预测

    Class-Conditional Conformal Prediction With Many Classes. (arXiv:2306.09335v1 [stat.ML])

    [http://arxiv.org/abs/2306.09335](http://arxiv.org/abs/2306.09335)

    提出了一种叫做聚类符合性预测的方法，可以在多类条件下提供类别条件符合性预测，针对多个类别的图像数据集中经验评估结果表明其优于现有方法。

    

    标准符合性预测方法提供边缘覆盖保证，这意味着对于一个随机的测试点，符合性预测集合以用户选择的概率包含真实标签。在许多分类问题中，我们希望获得更强的保证——对于特定类别的测试点，预测集以相同的用户选择概率包含真实标签。现有的符合性预测方法在每个类别有限的标记数据的情况下表现不佳，而这在实际应用中往往是大量类别的情况。我们提出了一种称为聚类符合性预测的方法，它将具有“相似”符合性分数的类别聚类在一起，然后在聚类级别上执行符合性预测。在针对多个（多达1000）类别的四个图像数据集的经验评估中，我们发现，聚类符合性通常在类条件覆盖和集合方面优于现有方法。

    Standard conformal prediction methods provide a marginal coverage guarantee, which means that for a random test point, the conformal prediction set contains the true label with a user-chosen probability. In many classification problems, we would like to obtain a stronger guarantee -- that for test points of a specific class, the prediction set contains the true label with the same user-chosen probability. Existing conformal prediction methods do not work well when there is a limited amount of labeled data per class, as is often the case in real applications where the number of classes is large. We propose a method called clustered conformal prediction, which clusters together classes that have "similar" conformal scores and then performs conformal prediction at the cluster level. Based on empirical evaluation across four image data sets with many (up to 1000) classes, we find that clustered conformal typically outperforms existing methods in terms of class-conditional coverage and set 
    
[^3]: Fit Like You Sample: 从快速混合马尔可夫链中实现样本高效的广义得分匹配

    Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains. (arXiv:2306.09332v1 [cs.DS])

    [http://arxiv.org/abs/2306.09332](http://arxiv.org/abs/2306.09332)

    本文提出了一种从快速混合马尔可夫链中实现样本高效的广义得分匹配方法，解决了得分匹配算法在具有较差等周性质的分布上的统计代价问题。

    

    得分匹配是一种学习概率分布的方法，其参数化为比例常数（例如，能量基模型）。其思想是拟合分布的得分，而不是似然函数，从而避免评估比例常数的需求。虽然这具有明显的算法优势，但统计代价可能很高：Koehler等人的最新工作表明，对于具有较差等周性质（较大的Poincare或对数Sobolev常数）的分布，得分匹配的统计效率明显低于极大似然估计。然而，许多自然实际的分布，例如一维中的两个高斯分布混合物等多峰分布，具有较差的Poincaré常数。在本文中，我们展示了任意马尔可夫过程的混合时间与试图拟合$\frac{\mathcal{O} p}{p}$的广义得分匹配损失之间的密切关系。如果$\mathcal{L}$的特征向量不依赖于$p$，我们展示了一种基于随机梯度下降的算法，从而实现的样本高效广义得分匹配。

    Score matching is an approach to learning probability distributions parametrized up to a constant of proportionality (e.g. Energy-Based Models). The idea is to fit the score of the distribution, rather than the likelihood, thus avoiding the need to evaluate the constant of proportionality. While there's a clear algorithmic benefit, the statistical "cost'' can be steep: recent work by Koehler et al. 2022 showed that for distributions that have poor isoperimetric properties (a large Poincar\'e or log-Sobolev constant), score matching is substantially statistically less efficient than maximum likelihood. However, many natural realistic distributions, e.g. multimodal distributions as simple as a mixture of two Gaussians in one dimension -- have a poor Poincar\'e constant.  In this paper, we show a close connection between the mixing time of an arbitrary Markov process with generator $\mathcal{L}$ and a generalized score matching loss that tries to fit $\frac{\mathcal{O} p}{p}$. If $\mathca
    
[^4]: 概率编程的重尾代数

    A Heavy-Tailed Algebra for Probabilistic Programming. (arXiv:2306.09262v1 [stat.ML])

    [http://arxiv.org/abs/2306.09262](http://arxiv.org/abs/2306.09262)

    本文提出了一种用于分析随机变量尾部的系统性方法，并通过开发一个尾部渐近的代数来处理在概率编程语言中的应用。该代数运算在加法和乘法下是封闭的，并能够处理比率，直接从定义中重现大多数统计分布的尾部。

    

    尽管基于神经网络的传递噪声的概率模型取得了成功，但最近的研究发现，除非基础分布的尾部得到适当校准，否则这种方法往往不能准确捕捉尾部行为。为了克服这个缺陷，我们提出了一种系统性的方法来分析随机变量的尾部，并阐述了如何在概率编程语言编译器的静态分析（在绘制样本之前）的过程中使用这种方法。为了表征尾部在各种运算下的变化，我们发展了一个代数，它作用于一个三参数尾部渐近的家族上，它基于广义伽玛分布。我们的代数运算在加法和乘法下是封闭的；它们能够区分不同尺度的亚高斯函数；并且它们处理比率足够好，以直接从它们的定义中重现大多数重要的统计分布的尾部。

    Despite the successes of probabilistic models based on passing noise through neural networks, recent work has identified that such methods often fail to capture tail behavior accurately, unless the tails of the base distribution are appropriately calibrated. To overcome this deficiency, we propose a systematic approach for analyzing the tails of random variables, and we illustrate how this approach can be used during the static analysis (before drawing samples) pass of a probabilistic programming language compiler. To characterize how the tails change under various operations, we develop an algebra which acts on a three-parameter family of tail asymptotics and which is based on the generalized Gamma distribution. Our algebraic operations are closed under addition and multiplication; they are capable of distinguishing sub-Gaussians with differing scales; and they handle ratios sufficiently well to reproduce the tails of most important statistical distributions directly from their defini
    
[^5]: 面向扩散式生成模型的非渐进快速收敛方法

    Towards Faster Non-Asymptotic Convergence for Diffusion-Based Generative Models. (arXiv:2306.09251v1 [stat.ML])

    [http://arxiv.org/abs/2306.09251](http://arxiv.org/abs/2306.09251)

    该论文针对扩散生成模型设计了非渐进理论，提出了针对两种主流采样器的新的收敛速度，提高了总步数与收敛速度的比例。

    

    扩散模型通过学习反转马尔可夫扩散过程将噪音转化为新数据实例，在当代生成建模领域中已成为基石。虽然它们的实用性现在已被广泛认可，但其理论基础仍然不够成熟。在这项工作中，我们开发了一套非渐进理论，以理解离散时间下扩散模型的数据生成过程，假设可以获得（Stein）得分函数的可靠估计。针对一种流行的确定性采样器（基于概率流ODE），我们建立了一个与 $T$（总步数）成比例的收敛速度，改进了过去的结果；对于另一种主流的随机采样器（即一种去噪扩散概率模型（DDPM）），我们导出了一个与 $1/\sqrt{T}$ 成比例的收敛速度，与最先进的理论相匹配。我们的理论对目标数据分布只作出最小的假设（例如，没有平滑）。

    Diffusion models, which convert noise into new data instances by learning to reverse a Markov diffusion process, have become a cornerstone in contemporary generative modeling. While their practical power has now been widely recognized, the theoretical underpinnings remain far from mature. In this work, we develop a suite of non-asymptotic theory towards understanding the data generation process of diffusion models in discrete time, assuming access to reliable estimates of the (Stein) score functions. For a popular deterministic sampler (based on the probability flow ODE), we establish a convergence rate proportional to $1/T$ (with $T$ the total number of steps), improving upon past results; for another mainstream stochastic sampler (i.e., a type of the denoising diffusion probabilistic model (DDPM)), we derive a convergence rate proportional to $1/\sqrt{T}$, matching the state-of-the-art theory. Our theory imposes only minimal assumptions on the target data distribution (e.g., no smoot
    
[^6]: 对数贝叶斯遗憾边界

    Logarithmic Bayes Regret Bounds. (arXiv:2306.09136v1 [cs.LG])

    [http://arxiv.org/abs/2306.09136](http://arxiv.org/abs/2306.09136)

    该论文提出了对于贝叶斯赌博机的首个有限时间对数遗憾边界，并用于高斯和线性赌博机，从而阐明了贝叶斯设置中先验价值以及对$\tilde{O}(\sqrt{n})$界限的改善。

    

    我们为贝叶斯赌博机导出了首个有限时间对数遗憾边界。对于高斯赌博机，我们获得了一个$O(c_h \log^2 n)$的边界，其中$c_h$是与先验相关的常量。这与Lai（1987）的渐近下限相匹配。我们的证明与先前的工作有所不同，且简单且普遍。为了显示一般性，我们将我们的技术应用于线性赌博机。我们的界限阐明了贝叶斯设置中先验的价值，既可以作为目标，也可以作为传递给学习者的附加信息。它们显着改善了现有的$\tilde{O}(\sqrt{n})$界限，尽管存在下限，但已成为文献中的标准。

    We derive the first finite-time logarithmic regret bounds for Bayesian bandits. For Gaussian bandits, we obtain a $O(c_h \log^2 n)$ bound, where $c_h$ is a prior-dependent constant. This matches the asymptotic lower bound of Lai (1987). Our proofs mark a technical departure from prior works, and are simple and general. To show generality, we apply our technique to linear bandits. Our bounds shed light on the value of the prior in the Bayesian setting, both in the objective and as a side information given to the learner. They significantly improve the $\tilde{O}(\sqrt{n})$ bounds, that despite the existing lower bounds, have become standard in the literature.
    
[^7]: 关于结构预测中的认证泛化

    On Certified Generalization in Structured Prediction. (arXiv:2306.09112v1 [stat.ML])

    [http://arxiv.org/abs/2306.09112](http://arxiv.org/abs/2306.09112)

    该论文提出了一种新的结构化预测PAC-Bayesian风险界限，它可以随着结构化示例的数量和大小的变化而进行泛化，为使用生成模型建立结构化预测的泛化界限迈出了第一步。

    

    在结构预测中，目标对象具有丰富的内部结构，这种结构无法分解为独立的组件，并违反了常见的独立同分布假设。这一挑战在应用程序中表现为指数级的输出空间，如图像分割或场景图生成。我们提出了一种新的结构化预测PAC-Bayesian风险界限，其中泛化速率不仅随着结构化示例的数量而且还随着它们的大小而变化。基本假设符合生成模型上的最新研究，即数据由分解参考度量的Knothe-Rosenblatt重新排列生成。这使得我们可以将随机输出变量之间的结构显式地提取到Wasserstein依赖矩阵中。我们的工作为利用强大的生成模型在结构预测这种具有挑战性的情况下建立判别式下游任务的泛化界限迈出了初步的一步。

    In structured prediction, target objects have rich internal structure which does not factorize into independent components and violates common i.i.d. assumptions. This challenge becomes apparent through the exponentially large output space in applications such as image segmentation or scene graph generation. We present a novel PAC-Bayesian risk bound for structured prediction wherein the rate of generalization scales not only with the number of structured examples but also with their size. The underlying assumption, conforming to ongoing research on generative models, is that data are generated by the Knothe-Rosenblatt rearrangement of a factorizing reference measure. This allows to explicitly distill the structure between random output variables into a Wasserstein dependency matrix. Our work makes a preliminary step towards leveraging powerful generative models to establish generalization bounds for discriminative downstream tasks in the challenging setting of structured prediction.
    
[^8]: 带离线数据的赌博机最优臂识别问题

    Optimal Best-Arm Identification in Bandits with Access to Offline Data. (arXiv:2306.09048v1 [cs.LG])

    [http://arxiv.org/abs/2306.09048](http://arxiv.org/abs/2306.09048)

    本文针对带有相应离线数据的K臂赌博机问题，设计了一种算法，以1-delta置信度找到平均值最高的臂，并且在满足置信度要求的前提下，样本复杂度达到了下限。

    

    文献中已经研究了基于纯离线数据和完全基于顺序在线学习的学习范式，但将离线数据与在线学习相结合的领域却鲜有研究，这是实际上十分重要的。本文考虑在相关离线数据存在的情况下，以$1-\delta$的置信度识别出具有最高平均值的臂的随机K臂赌博机问题。我们对提供该$1-\delta$概率正确性保证的策略进行了一个下界分析，并开发出能够在$\delta$很小的情况下达到样本复杂性下界的算法。我们的算法在计算上非常高效，每个样本的收集成本平均为$\tilde {O}(K)$，并且依赖于一个对较低问题的最优性条件的仔细刻画。

    Learning paradigms based purely on offline data as well as those based solely on sequential online learning have been well-studied in the literature. In this paper, we consider combining offline data with online learning, an area less studied but of obvious practical importance. We consider the stochastic $K$-armed bandit problem, where our goal is to identify the arm with the highest mean in the presence of relevant offline data, with confidence $1-\delta$. We conduct a lower bound analysis on policies that provide such $1-\delta$ probabilistic correctness guarantees. We develop algorithms that match the lower bound on sample complexity when $\delta$ is small. Our algorithms are computationally efficient with an average per-sample acquisition cost of $\tilde{O}(K)$, and rely on a careful characterization of the optimality conditions of the lower bound problem.
    
[^9]: 利用时频注意力的多损失卷积网络用于语音增强

    Multi-Loss Convolutional Network with Time-Frequency Attention for Speech Enhancement. (arXiv:2306.08956v1 [cs.SD])

    [http://arxiv.org/abs/2306.08956](http://arxiv.org/abs/2306.08956)

    本文提出了利用自注意力模块的多损失卷积网络与时频注意力（MNTFA）模型，用于语音增强，实验结果表明该模型在 PESQ 和 STOI 指标方面达到了当前最先进水平。

    

    本文提出了一种称为多损失卷积网络与时频注意力（MNTFA）的模型，用于语音增强。该模型利用了自注意力模块来挖掘长时间信息，其中 intra-chunk 自注意力用于建模频谱模式，而 inter-chunk 自注意力用于建模连续帧之间的依赖关系。相比于 DPRNN，轴向自注意力大大降低了内存和计算的需求，更适合处理长语音序列。此外，作者还提出了一种使用预训练 WavLM 网络的多分辨率 STFT 损失和 WavLM 损失的联合训练方法。在 DNS-Challenge 数据集上的实验证明了所提出的 MNTFA 在 PESQ 和 STOI 指标方面的性能均达到了当前最先进水平。

    The Dual-Path Convolution Recurrent Network (DPCRN) was proposed to effectively exploit time-frequency domain information. By combining the DPRNN module with Convolution Recurrent Network (CRN), the DPCRN obtained a promising performance in speech separation with a limited model size. In this paper, we explore self-attention in the DPCRN module and design a model called Multi-Loss Convolutional Network with Time-Frequency Attention(MNTFA) for speech enhancement. We use self-attention modules to exploit the long-time information, where the intra-chunk self-attentions are used to model the spectrum pattern and the inter-chunk self-attention are used to model the dependence between consecutive frames. Compared to DPRNN, axial self-attention greatly reduces the need for memory and computation, which is more suitable for long sequences of speech signals. In addition, we propose a joint training method of a multi-resolution STFT loss and a WavLM loss using a pre-trained WavLM network. Experi
    
[^10]: 自助聚合和置信度度量方法用于改进时间序列因果发现

    Bootstrap aggregation and confidence measures to improve time series causal discovery. (arXiv:2306.08946v1 [stat.ME])

    [http://arxiv.org/abs/2306.08946](http://arxiv.org/abs/2306.08946)

    本文介绍了一种新的自助聚合和置信度度量方法，使得时间序列因果发现能够提供连接的置信度度量。在广泛的数值实验中，实验证明该方法提高了因果发现的性能。

    

    因果发现方法已经展示了识别表示动态系统的因果时间依赖结构的时序图的能力。然而，它们不包括对估计连接的置信度的测量。本文介绍了一种新的自助聚合（Bagging）和置信度度量方法，它与时间序列因果发现相结合。该方法允许通过在保留时间依赖性的情况下对原始时间序列数据集进行自助重采样来测量由因果发现方法计算出的时序图连接的置信度。除了置信度量，聚合引导图通过多数投票得出最终聚合输出图。在本文中，我们将我们的方法与最先进的基于条件独立性算法PCMCI+相结合。通过广泛的数值实验，我们实验性地展示了Bagged-PCMCI+除了提供连接的置信度度量外，还可以提高因果发现的性能。

    Causal discovery methods have demonstrated the ability to identify the time series graphs representing the causal temporal dependency structure of dynamical systems. However, they do not include a measure of the confidence of the estimated links. Here, we introduce a novel bootstrap aggregation (bagging) and confidence measure method that is combined with time series causal discovery. This new method allows measuring confidence for the links of the time series graphs calculated by causal discovery methods. This is done by bootstrapping the original times series data set while preserving temporal dependencies. Next to confidence measures, aggregating the bootstrapped graphs by majority voting yields a final aggregated output graph. In this work, we combine our approach with the state-of-the-art conditional-independence-based algorithm PCMCI+. With extensive numerical experiments we empirically demonstrate that, in addition to providing confidence measures for links, Bagged-PCMCI+ improv
    
[^11]: 基于核点聚合的双曲卷积

    Hyperbolic Convolution via Kernel Point Aggregation. (arXiv:2306.08862v1 [cs.LG])

    [http://arxiv.org/abs/2306.08862](http://arxiv.org/abs/2306.08862)

    HKConv是一种新颖且可训练的双曲卷积，它可以根据双曲距离测量类似于旋转的变换等变性。

    

    对于非欧几里得数据，根据底层几何学习表示是至关重要的。研究表明，双曲空间可以有效地嵌入分层或树状数据。近年来，双曲神经网络得到了快速发展。然而，学习良好的双曲表示是有挑战的，因为常见的欧几里得神经操作（如卷积）无法扩展到双曲空间。大多数双曲神经网络不包括卷积操作，并忽略局部模式。其他的则仅使用非双曲卷积，或者缺失诸如置换等价性的重要性质。我们提出了HKConv，一种新颖且可训练的双曲卷积，它首先将可训练的本地双曲特征与放置在双曲空间中的固定核心点相关联，然后在本地邻域内聚合输出特征。HKConv不仅可以有效地学习本地特征，还可以根据双曲距离测量类似于旋转的变换等变性。

    Learning representations according to the underlying geometry is of vital importance for non-Euclidean data. Studies have revealed that the hyperbolic space can effectively embed hierarchical or tree-like data. In particular, the few past years have witnessed a rapid development of hyperbolic neural networks. However, it is challenging to learn good hyperbolic representations since common Euclidean neural operations, such as convolution, do not extend to the hyperbolic space. Most hyperbolic neural networks do not embrace the convolution operation and ignore local patterns. Others either only use non-hyperbolic convolution, or miss essential properties such as equivariance to permutation. We propose HKConv, a novel trainable hyperbolic convolution which first correlates trainable local hyperbolic features with fixed kernel points placed in the hyperbolic space, then aggregates the output features within a local neighborhood. HKConv not only expressively learns local features according 
    
[^12]: Gromov-Wasserstein测地线视角下的保谱图缩减方法

    A Gromov--Wasserstein Geometric View of Spectrum-Preserving Graph Coarsening. (arXiv:2306.08854v1 [cs.LG])

    [http://arxiv.org/abs/2306.08854](http://arxiv.org/abs/2306.08854)

    本文提出了一种基于Gromov-Wasserstein距离的图缩减方法，该方法可以保持图的距离，并利用加权核$ K $ -means方法最小化差异，从而提高保谱方法的性能。

    

    图缩减是一种通过处理原图的较小版本来解决大规模图问题的技术，并可能将结果插值回原图。它在科学计算领域有着悠久的历史，最近在机器学习领域变得越来越流行，特别是在保持图谱的方法中。本文从不同的角度研究了图缩减，发展了一种保持图距离的理论并提出了一种可行的方法。这种几何方法在处理图集合时非常有用，例如在图分类和回归中。在本研究中，我们将图看作是装备有Gromov-Wasserstein（GW）距离的度量空间上的一个元素，并且限定了两个图和它们缩减版本之间的距离差异。使用流行的加权核$ K $ -means方法可以最小化此差异，利用GW距离可以提高现有的保谱方法。

    Graph coarsening is a technique for solving large-scale graph problems by working on a smaller version of the original graph, and possibly interpolating the results back to the original graph. It has a long history in scientific computing and has recently gained popularity in machine learning, particularly in methods that preserve the graph spectrum. This work studies graph coarsening from a different perspective, developing a theory for preserving graph distances and proposing a method to achieve this. The geometric approach is useful when working with a collection of graphs, such as in graph classification and regression. In this study, we consider a graph as an element on a metric space equipped with the Gromov--Wasserstein (GW) distance, and bound the difference between the distance of two graphs and their coarsened versions. Minimizing this difference can be done using the popular weighted kernel $K$-means method, which improves existing spectrum-preserving methods with the proper
    
[^13]: 具有理论保障的差分隐私域自适应算法

    Differentially Private Domain Adaptation with Theoretical Guarantees. (arXiv:2306.08838v1 [cs.LG])

    [http://arxiv.org/abs/2306.08838](http://arxiv.org/abs/2306.08838)

    该论文提出了两种具有差分隐私保障的自适应算法，用于在受隐私约束且有限标记数据条件下，从公开源领域到目标领域进行监督域自适应。该算法能够解决一般的优化问题，并具有有利的理论学习保证。

    

    在许多应用中，学习者可用的标记数据受到隐私约束并相对有限。为了为目标领域导出更准确的预测器，通常有利于利用来自与目标领域相近的另一领域的公开标记数据。这是从公共源领域到私有目标领域的现代监督域自适应问题。我们提出了两种 $(\epsilon, \delta)$-差分隐私自适应算法，用于监督性自适应。对于其我们使用了一般的优化问题，该优化问题最近被证明具有有利的理论学习保证。我们的第一个算法是为具有线性预测器的回归设计的，并显示为解决凸优化问题。我们的第二个算法是一种更一般的解决方案，用于可能是非凸但Lipschitz和平滑的损失函数。虽然我们的主要目标是进行理论分析，但我们也报告了几个实验的结果。

    In many applications, the labeled data at the learner's disposal is subject to privacy constraints and is relatively limited. To derive a more accurate predictor for the target domain, it is often beneficial to leverage publicly available labeled data from an alternative domain, somewhat close to the target domain. This is the modern problem of supervised domain adaptation from a public source to a private target domain. We present two $(\epsilon, \delta)$-differentially private adaptation algorithms for supervised adaptation, for which we make use of a general optimization problem, recently shown to benefit from favorable theoretical learning guarantees. Our first algorithm is designed for regression with linear predictors and shown to solve a convex optimization problem. Our second algorithm is a more general solution for loss functions that may be non-convex but Lipschitz and smooth. While our main objective is a theoretical analysis, we also report the results of several experiment
    
[^14]: ReLU分类器的边界区域精确计数：朝着基于边界复杂性的分类适当复杂度度量方法。

    Exact Count of Boundary Pieces of ReLU Classifiers: Towards the Proper Complexity Measure for Classification. (arXiv:2306.08805v1 [stat.ML])

    [http://arxiv.org/abs/2306.08805](http://arxiv.org/abs/2306.08805)

    通过精确计算ReLU分类器的边界区域片段数量，本文提出了一种基于边界复杂性度量方法来适当度量分类器复杂度的思想，并发现边界片段计数与泛化性能的相关性更高，具有明显的优势。

    

    经典学习理论表明适当的正则化是好的泛化和鲁棒性的关键。在分类中，当前的训练方案仅针对分类器本身的复杂性，这可能会导致误导和无效。相反，我们主张直接测量决策边界的复杂性。现有文献在这个领域的定义有限，边界复杂性的定义也往往存在争议。我们以ReLU神经网络为例进行概念证明，这些网络的边界复杂形态可以方便地用仿射片段的数量来刻画。我们借助于热带几何，发展了一种新方法，可以明确计算出边界精确的片段数量。实验表明，边界片段计数在训练中的独特性质与实际分类一致，与其他测量，例如权重的总和$l_2$范数相比，独立性更好。此外，边界片段计数与泛化性能的相关性更高，具有其他复杂度量度不能比拟的优势。我们的工作强调了测量边界复杂性的重要性，并提供了基于边界区域计数的实际分类器正则化工具。

    Classic learning theory suggests that proper regularization is the key to good generalization and robustness. In classification, current training schemes only target the complexity of the classifier itself, which can be misleading and ineffective. Instead, we advocate directly measuring the complexity of the decision boundary. Existing literature is limited in this area with few well-established definitions of boundary complexity. As a proof of concept, we start by analyzing ReLU neural networks, whose boundary complexity can be conveniently characterized by the number of affine pieces. With the help of tropical geometry, we develop a novel method that can explicitly count the exact number of boundary pieces, and as a by-product, the exact number of total affine pieces. Numerical experiments are conducted and distinctive properties of our boundary complexity are uncovered. First, the boundary piece count appears largely independent of other measures, e.g., total piece count, and $l_2$ 
    
[^15]: 带有对数通信的 Langevin Thompson Sampling：在赌博机和强化学习中的应用

    Langevin Thompson Sampling with Logarithmic Communication: Bandits and Reinforcement Learning. (arXiv:2306.08803v1 [cs.LG])

    [http://arxiv.org/abs/2306.08803](http://arxiv.org/abs/2306.08803)

    本文提出了一种带有对数通信的 Langevin Thompson Sampling 算法，可用于解决在赌博机和强化学习中学习未知的奖励分布和转移动态等问题。

    

    Thompson Sampling (TS)由于易于使用和良好的实验表现而被广泛应用于序贯决策。但许多TS的现有分析和实证结果都依赖于奖励分布的限制性假设，如属于共轭家族，这限制了它们在现实场景中的适用性。此外，序列决策问题往往以批处理方式进行，这既是由于问题本身的固有性质，也是为了减少通信和计算成本。在本文中，我们联合研究了两种常见的设置中的这些问题，即基于随机赌博机（MABs）和基于无限时域强化学习（RL），其中TS用于学习未知的奖励分布和转移动态。我们提出了批量化的 $\textit{Langevin Thompson Sampling}$算法，利用MCMC方法从近似后验中采样，其通信成本仅为对数。

    Thompson sampling (TS) is widely used in sequential decision making due to its ease of use and appealing empirical performance. However, many existing analytical and empirical results for TS rely on restrictive assumptions on reward distributions, such as belonging to conjugate families, which limits their applicability in realistic scenarios. Moreover, sequential decision making problems are often carried out in a batched manner, either due to the inherent nature of the problem or to serve the purpose of reducing communication and computation costs. In this work, we jointly study these problems in two popular settings, namely, stochastic multi-armed bandits (MABs) and infinite-horizon reinforcement learning (RL), where TS is used to learn the unknown reward distributions and transition dynamics, respectively. We propose batched $\textit{Langevin Thompson Sampling}$ algorithms that leverage MCMC methods to sample from approximate posteriors with only logarithmic communication costs in 
    
[^16]: MPSA-DenseNet: 一种用于英语口音分类的新型深度学习模型

    MPSA-DenseNet: A novel deep learning model for English accent classification. (arXiv:2306.08798v1 [cs.CL])

    [http://arxiv.org/abs/2306.08798](http://arxiv.org/abs/2306.08798)

    本文介绍了三种使用DenseNet结合多任务学习和PSA模块注意机制的深度学习模型用于英语口音分类，并通过实验证明MPSA-DenseNet模型在识别英语口音方面具有很高的精确性和前瞻性。

    

    本文提出了三种创新的深度学习模型，用于英语口音分类：Multi-DenseNet，PSA-DenseNet和MPSE-DenseNet，它们将多任务学习和PSA模块注意机制与DenseNet相结合。我们将这些模型应用于收集自英语母语区域（英国，美国，苏格兰）和非英语母语区域（中国，德国，印度）的六种英语方言的数据。我们的实验结果显示分类精度显著提高，特别是MPSA-DenseNet，它在口音识别方面表现优于所有其他模型，包括先前用于口音识别的DenseNet和EPSA模型。我们的研究结果表明，MPSA-DenseNet是一种高度有前途的模型，适用于准确识别英语口音。

    This paper presents three innovative deep learning models for English accent classification: Multi-DenseNet, PSA-DenseNet, and MPSE-DenseNet, that combine multi-task learning and the PSA module attention mechanism with DenseNet. We applied these models to data collected from six dialects of English across native English speaking regions (Britain, the United States, Scotland) and nonnative English speaking regions (China, Germany, India). Our experimental results show a significant improvement in classification accuracy, particularly with MPSA-DenseNet, which outperforms all other models, including DenseNet and EPSA models previously used for accent identification. Our findings indicate that MPSA-DenseNet is a highly promising model for accurately identifying English accents.
    
[^17]: MMD-FUSE: 在不分割数据的情况下学习和组合内核进行双样本检验

    MMD-FUSE: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting. (arXiv:2306.08777v1 [stat.ML])

    [http://arxiv.org/abs/2306.08777](http://arxiv.org/abs/2306.08777)

    本文提出了MMD-FUSE方法，通过适应内核集合最大化基于MMD的双样本检验功率，避免数据分割，并在低维合成数据和高维实际数据上证明了其适用性和功率超过现有最先进的核检验方法。

    

    本文提出了一种新的统计方法，通过适应定义该方法的内核集合，最大化基于最大平均偏差（MMD）的双样本检验的功率。 对于有限集合，这就缩小了通过加权软最大值组合（标准化的）每个内核下的MMD值。 对于零假设和备择假设，证明了我们提出的统计量的指数浓度上限。 我们进一步展示了如何通过数据依赖但与排列独立的方式选择这些内核，在一个经过良好校准的测试中避免数据分割。 这种技术更广泛地适用于基于一般排列的MMD测试，并且包括使用使用自编码器等无监督模型学习的深度内核。 我们强调了我们的MMD-FUSE测试在合成低维数据和现实世界高维数据方面的适用性，并比较了其功率表现与当前最先进的内核检验。

    We propose novel statistics which maximise the power of a two-sample test based on the Maximum Mean Discrepancy (MMD), by adapting over the set of kernels used in defining it. For finite sets, this reduces to combining (normalised) MMD values under each of these kernels via a weighted soft maximum. Exponential concentration bounds are proved for our proposed statistics under the null and alternative. We further show how these kernels can be chosen in a data-dependent but permutation-independent way, in a well-calibrated test, avoiding data splitting. This technique applies more broadly to general permutation-based MMD testing, and includes the use of deep kernels with features learnt using unsupervised models such as auto-encoders. We highlight the applicability of our MMD-FUSE test on both synthetic low-dimensional and real-world high-dimensional data, and compare its performance in terms of power against current state-of-the-art kernel tests.
    
[^18]: WavPool: 一种新的深度神经网络模块

    WavPool: A New Block for Deep Neural Networks. (arXiv:2306.08734v1 [cs.LG])

    [http://arxiv.org/abs/2306.08734](http://arxiv.org/abs/2306.08734)

    WavPool是一种新型的深度神经网络模块，它通过添加池化层来使比例和空间信息同时可访问于网络，相较于其他模块具有更好的性能。

    

    现代深度神经网络由许多操作层组成，例如稠密层或卷积层，通常被收集成块。在本文中，我们介绍了一种基于小波变换的新型网络架构，称为多分辨率感知器：通过添加池化层，我们创建了一个新的网络模块，WavPool。多分辨率感知器的第一步是通过将输入数据与固定系数但不断增加的滤波器卷积来将数据转换为其多分辨率分解形式。遵循图像处理技术，我们能够使比例和空间信息同时可访问于网络，而不增加数据向量的大小。WavPool在使用更少的参数时优于类似的多层感知器，并且在CIFAR-10上以相对准确度的 ~ 10％优于可比卷积神经网络。

    Modern deep neural networks comprise many operational layers, such as dense or convolutional layers, which are often collected into blocks. In this work, we introduce a new, wavelet-transform-based network architecture that we call the multi-resolution perceptron: by adding a pooling layer, we create a new network block, the WavPool. The first step of the multi-resolution perceptron is transforming the data into its multi-resolution decomposition form by convolving the input data with filters of fixed coefficients but increasing size. Following image processing techniques, we are able to make scale and spatial information simultaneously accessible to the network without increasing the size of the data vector. WavPool outperforms a similar multilayer perceptron while using fewer parameters, and outperforms a comparable convolutional neural network by ~ 10% on relative accuracy on CIFAR-10.
    
[^19]: 将不确定性意识整合到 Conformalized Quantile Regression 中

    Integrating Uncertainty Awareness into Conformalized Quantile Regression. (arXiv:2306.08693v1 [stat.ME])

    [http://arxiv.org/abs/2306.08693](http://arxiv.org/abs/2306.08693)

    新提出的方法 UACQR 将条件分位估计和整合推断结合，以区分随机不确定性和认识性不确定性，并相应地构造预测区间，可以在量子回归器在特征空间的不同子集上优于现有的 CQR 方法。

    

    Conformalized Quantile Regression (CQR) 是一种最近提出的方法，用于在不做分布假设的情况下构建给定协变量 X 的响应 Y 的预测区间。现有的 CQR 构造方法在量子回归器在特征空间的某些部分表现更好的问题上可能无效。其原因在于 CQR 的预测区间不区分两种不确定性形式：第一种是给定 X 的条件分布的变异性（即，随机不确定性），第二种是我们估计这种条件分布的不确定性（即，认识性不确定性）。这可能导致不均匀的覆盖范围，在认识性不确定性低（或高）的区域中过度宽（或过度窄）的区间。为了解决这个问题，我们提出了 Conformalized Quantile Regression 的新变体，即 Uncertainty-Aware CQR (UACQR)，该方法明确地分离这两种不确定性来源，并相应地构造预测区间。UACQR 方法使用整合推断来量化估计给定 X 的 Y 的条件分布的不确定性，同时还将有界的条件分位估计并入其中，以捕捉该分布的变异性。我们的实验结果表明，UACQR 在量子回归器在特征空间的子集上表现不同的设置中可以优于现有的 CQR 方法。

    Conformalized Quantile Regression (CQR) is a recently proposed method for constructing prediction intervals for a response $Y$ given covariates $X$, without making distributional assumptions. However, as we demonstrate empirically, existing constructions of CQR can be ineffective for problems where the quantile regressors perform better in certain parts of the feature space than others. The reason is that the prediction intervals of CQR do not distinguish between two forms of uncertainty: first, the variability of the conditional distribution of $Y$ given $X$ (i.e., aleatoric uncertainty), and second, our uncertainty in estimating this conditional distribution (i.e., epistemic uncertainty). This can lead to uneven coverage, with intervals that are overly wide (or overly narrow) in regions where epistemic uncertainty is low (or high). To address this, we propose a new variant of the CQR methodology, Uncertainty-Aware CQR (UACQR), that explicitly separates these two sources of uncertaint
    
[^20]: 利用联网车辆数据预测飓风疏散期间的实时车祸风险

    Predicting Real-time Crash Risks during Hurricane Evacuation Using Connected Vehicle Data. (arXiv:2306.08682v1 [stat.ML])

    [http://arxiv.org/abs/2306.08682](http://arxiv.org/abs/2306.08682)

    本文提出了使用联网车辆数据来预测飓风疏散期间的车祸风险，通过分析车速和加速度曲线，可以实时评估交通安全状况。

    

    飓风疏散为了拯救海岸地区的人们而进行，会导致交通需求增加，车祸风险也随之增加。为了减轻这种风险，交通机构需要预测高车祸风险的公路位置，以部署适当的对策。随着普及的传感器和通信技术，现在可以检索包含单个车辆轨迹和速度信息的微观级别车辆数据。这种高分辨率车辆数据可以在实时的情况下使用，用于评估当前的交通安全状况。利用车速和加速度曲线，可以实时预测潜在的车祸风险。以往的实时车祸风险预测研究主要使用基础设施传感器的数据，可能无法覆盖许多道路段。在本文中，我们提出了使用新兴的替代数据源（称为联网车辆数据）来确定飓风疏散期间潜在的车祸风险的方法。

    Hurricane evacuation, ordered to save lives of people of coastal regions, generates high traffic demand with increased crash risk. To mitigate such risk, transportation agencies need to anticipate highway locations with high crash risks to deploy appropriate countermeasures. With ubiquitous sensors and communication technologies, it is now possible to retrieve micro-level vehicular data containing individual vehicle trajectory and speed information. Such high-resolution vehicle data, potentially available in real time, can be used to assess prevailing traffic safety conditions. Using vehicle speed and acceleration profiles, potential crash risks can be predicted in real time. Previous studies on real-time crash risk prediction mainly used data from infrastructure-based sensors which may not cover many road segments. In this paper, we present methods to determine potential crash risks during hurricane evacuation from an emerging alternative data source known as connected vehicle data. S
    
[^21]: 预测音乐转换器

    Anticipatory Music Transformer. (arXiv:2306.08620v1 [cs.SD])

    [http://arxiv.org/abs/2306.08620](http://arxiv.org/abs/2306.08620)

    该论文提出一种预测音乐转换器，它能够实现在符号音乐生成的过程中进行控制，包括补全控制任务和伴奏，并且在大型且多样的数据集上表现出色。

    

    我们引入了anticipation（预测）：一种构建生成模型的方法，该模型基于事件过程（时间点过程）的实现，以异步地控制与第二个相关过程（控制过程）的相关性。我们通过交错事件和控件序列来实现这一目标，使控件出现在事件序列的停止时间之后。这项工作的动机来自符号音乐生成控制中出现的问题。我们专注于infiling（补全）控制任务，其中控制事件是事件本身的子集，并且条件生成完成给定固定控制事件的事件序列。我们使用大型多样的Lakh MIDI音乐数据集训练预测infiling模型。这些模型与提示音乐生成的自回归模型性能相当，并具有执行infilling控制任务的附加能力，包括伴奏。人工评估员报告说，预测模型产生的伴奏具有高可辨性和优美性。

    We introduce anticipation: a method for constructing a controllable generative model of a temporal point process (the event process) conditioned asynchronously on realizations of a second, correlated process (the control process). We achieve this by interleaving sequences of events and controls, such that controls appear following stopping times in the event sequence. This work is motivated by problems arising in the control of symbolic music generation. We focus on infilling control tasks, whereby the controls are a subset of the events themselves, and conditional generation completes a sequence of events given the fixed control events. We train anticipatory infilling models using the large and diverse Lakh MIDI music dataset. These models match the performance of autoregressive models for prompted music generation, with the additional capability to perform infilling control tasks, including accompaniment. Human evaluators report that an anticipatory model produces accompaniments with
    
[^22]: 基于近似有效的$p$-阻抗的多类图聚类

    Multi-class Graph Clustering via Approximated Effective $p$-Resistance. (arXiv:2306.08617v1 [cs.LG])

    [http://arxiv.org/abs/2306.08617](http://arxiv.org/abs/2306.08617)

    本文提出了一种近似计算有效$p$-阻抗并将其应用于多类图聚类，该方法可以通过参数$p$偏向于具有高内部连通性或者更小的簇内顶点之间的最短路径距离的聚类。

    

    本文提出了一种近似计算有效$p$-阻抗并将其应用于多类聚类。基于图拉普拉斯和其$p$-拉普拉斯推广的谱方法一直是非欧几里得聚类技术的支柱。$p$-拉普拉斯的优点在于参数$p$对聚类结构具有可控偏倚。$p$-拉普拉斯特征向量法的缺点在于难以计算第三和更高阶特征向量。因此，我们动机在于使用由$p$-拉普拉斯引导的$p$-阻抗进行聚类。对于$p$-阻抗而言，小$p$会偏向于具有高内部连通性的聚类，而大$p$则会偏向于大小“范围”的聚类，即更小的簇内顶点之间的最短路径距离。然而，计算$p$-阻抗成本很高。我们通过开发$p$-阻抗的近似方法来克服这一问题。我们证明了上下界。

    This paper develops an approximation to the (effective) $p$-resistance and applies it to multi-class clustering. Spectral methods based on the graph Laplacian and its generalization to the graph $p$-Laplacian have been a backbone of non-euclidean clustering techniques. The advantage of the $p$-Laplacian is that the parameter $p$ induces a controllable bias on cluster structure. The drawback of $p$-Laplacian eigenvector based methods is that the third and higher eigenvectors are difficult to compute. Thus, instead, we are motivated to use the $p$-resistance induced by the $p$-Laplacian for clustering. For $p$-resistance, small $p$ biases towards clusters with high internal connectivity while large $p$ biases towards clusters of small ``extent,'' that is a preference for smaller shortest-path distances between vertices in the cluster. However, the $p$-resistance is expensive to compute. We overcome this by developing an approximation to the $p$-resistance. We prove upper and lower bounds
    
[^23]: 核去偏插值估计

    Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])

    [http://arxiv.org/abs/2306.08598](http://arxiv.org/abs/2306.08598)

    本文提出了一种高效、不需要实现影响函数且可计算的去偏插值估计方法。

    

    本文考虑在干扰参数存在的情况下估计标量目标参数的问题。采用非参数估计器（例如机器学习（ML）模型）替换未知干扰参数是方便的，但因存在较大偏差而效率低下。为了避免偏差-方差权衡的次优选择，现代方法会进行插值预估的去偏差操作，如有目标最小损失估计（TMLE）和双机器学习（DML）等。现有的去偏方法需要将目标参数的影响函数（IF）作为输入，然而，IF的推导需要专业知识，从而阻碍了这些方法的适应性。我们提出了一种新的去偏插入估计器的方法，它（i）高效、（ii）不需要实现IF、（iii）可计算。

    We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
    
[^24]: 超越隐性偏差：SGD噪声在在线学习中的不重要性

    Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning. (arXiv:2306.08590v1 [cs.LG])

    [http://arxiv.org/abs/2306.08590](http://arxiv.org/abs/2306.08590)

    本文通过实际数据的全面实证分析证明了在在线学习中，大学习率和小批量大小并不会带来任何隐性偏差的优势。在线学习中SGD噪音的好处只是计算上的便利，可以促进更大或更具成本效益的梯度步骤。

    

    先前的研究认为，SGD在深度学习中的成功归因于高学习率或小批量大小所引起的隐性偏差（“SGD噪声”）。而我们研究了SGD噪声在在线（即单个epoch）学习中的影响，通过对图像和语言数据的全面实证分析，我们证明了在在线学习中，大学习率和小批量大小并不会带来任何隐性偏差的优势。与离线学习相反，在线学习中SGD噪声的好处严格来说只是计算上的便利，可以促进更大或更具成本效益的梯度步骤。我们的研究表明，SGD在在线模式下可以被视为是在“无噪声梯度流算法”的“黄金路径”上踩踏嘈杂步伐。通过减少训练期间的SGD噪声和测量模型之间的逐点功能距离，我们提供了支持此假设的证据。

    The success of SGD in deep learning has been ascribed by prior works to the implicit bias induced by high learning rate or small batch size ("SGD noise"). While prior works that focused on offline learning (i.e., multiple-epoch training), we study the impact of SGD noise on online (i.e., single epoch) learning. Through an extensive empirical analysis of image and language data, we demonstrate that large learning rate and small batch size do not confer any implicit bias advantages in online learning. In contrast to offline learning, the benefits of SGD noise in online learning are strictly computational, facilitating larger or more cost-effective gradient steps. Our work suggests that SGD in the online regime can be construed as taking noisy steps along the "golden path" of the noiseless gradient flow algorithm. We provide evidence to support this hypothesis by conducting experiments that reduce SGD noise during training and by measuring the pointwise functional distance between models 
    
[^25]: 噪声稳定优化对于具有最优收敛率的平坦极小值的影响

    Noise Stability Optimization for Flat Minima with Optimal Convergence Rates. (arXiv:2306.08553v1 [cs.LG])

    [http://arxiv.org/abs/2306.08553](http://arxiv.org/abs/2306.08553)

    本文提出了一个SGD-like算法，注入随机噪声并利用分布对称性来减少方差，以寻找具有低海森矩阵迹的平坦极小值，同时提供了收敛速率分析。

    

    本文研究通过加入加权扰动来找到平坦的极小值。给定一个非凸函数$f:\mathbb{R}^d\rightarrow \mathbb{R}$和一个$d$维分布$\mathcal{P}$，我们扰动$f$的权重，并定义$F(W)=\mathbb{E}[f({W+U})]$，其中$U$是一个从$\mathcal{P}$中随机抽取的样本。这个过程通过$f$的海森矩阵的迹来诱导正则化，以适应于小的、各向同性的高斯扰动。因此，加权扰动的函数偏向于带有低海森矩阵迹的极小值。本文提出了一种类似于SGD的算法，在计算梯度之前注入随机噪声，同时利用$\mathcal{P}$的对称性来减少方差。我们还提供了严格的分析，证明了...

    We consider finding flat, local minimizers by adding average weight perturbations. Given a nonconvex function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ and a $d$-dimensional distribution $\mathcal{P}$ which is symmetric at zero, we perturb the weight of $f$ and define $F(W) = \mathbb{E}[f({W + U})]$, where $U$ is a random sample from $\mathcal{P}$. This injection induces regularization through the Hessian trace of $f$ for small, isotropic Gaussian perturbations. Thus, the weight-perturbed function biases to minimizers with low Hessian trace. Several prior works have studied settings related to this weight-perturbed function by designing algorithms to improve generalization. Still, convergence rates are not known for finding minima under the average perturbations of the function $F$. This paper considers an SGD-like algorithm that injects random noise before computing gradients while leveraging the symmetry of $\mathcal{P}$ to reduce variance. We then provide a rigorous analysis, showing
    
[^26]: 大规模密集随机Kronecker图的分析和近似推断

    Analysis and Approximate Inference of Large and Dense Random Kronecker Graphs. (arXiv:2306.08489v1 [stat.ML])

    [http://arxiv.org/abs/2306.08489](http://arxiv.org/abs/2306.08489)

    本文对大规模密集随机Kronecker图进行了分析和近似推断，提出了“去噪声和求解”元算法，用于近似推断图参数，并具有较低的计算复杂度和性能保证。

    

    随机图模型在科学和工业中发挥着越来越重要的作用，并在各种领域中得到应用，包括社交和交通网络、推荐系统和分子遗传学。本文对\cite{leskovec2010kronecker}中提出的随机Kronecker图模型进行了深入的分析，当图顶点数量$N$很大时。基于最近在随机矩阵理论方面的进展，我们证明，在密集的情况下，随机Kronecker图邻接矩阵近似遵循一个信号加噪声模型，其中信号矩阵的秩很小（最多为$\log N$阶），在图参数中是线性的，而随机的噪声矩阵具有四分之一圆形奇异值分布。这个观察允许我们提出了一种“去噪声和求解”元算法来近似推断图参数，具有较低的计算复杂度和（渐近的）性能保证。通过图i的数值实验进行了验证。

    Random graph models are playing an increasingly important role in science and industry, and finds their applications in a variety of fields ranging from social and traffic networks, to recommendation systems and molecular genetics. In this paper, we perform an in-depth analysis of the random Kronecker graph model proposed in \cite{leskovec2010kronecker}, when the number of graph vertices $N$ is large. Built upon recent advances in random matrix theory, we show, in the dense regime, that the random Kronecker graph adjacency matrix follows approximately a signal-plus-noise model, with a small-rank (of order at most $\log N$) signal matrix that is linear in the graph parameters and a random noise matrix having a quarter-circle-form singular value distribution. This observation allows us to propose a ``denoise-and-solve'' meta algorithm to approximately infer the graph parameters, with reduced computational complexity and (asymptotic) performance guarantee. Numerical experiments of graph i
    
[^27]: 可补给背包机制下的赌博算法：两全其美之道

    Bandits with Replenishable Knapsacks: the Best of both Worlds. (arXiv:2306.08470v1 [cs.LG])

    [http://arxiv.org/abs/2306.08470](http://arxiv.org/abs/2306.08470)

    本文研究了一种BwK框架自然推广，允许资源通过正值补充。我们提出了一个新的在线学习算法方案，该算法结合了在线凸优化技术和背包文献的思想，能够处理任何可补给的在线学习问题。

    

    背包赌博机制(BwK)模型适用于在线决策问题，其中代理商做出一系列的决策，受到资源消耗的约束。传统模型假设每个动作消耗非负资源，过程在初始预算完全用尽时结束。我们研究了BwK框架的一种自然推广，允许非单调的资源利用，即资源可以通过正值补充。我们提出了一种最佳实践双重模板，可以处理任何存在合适原始遗憾最小化器的可补给在线学习问题。特别地，我们通过展示当$B=\Omega(T)$或每轮补给数是正常数时，我们的框架保证了常数竞争比率$α$的第一篇正面结果。此外，在随机输入模型下，我们的算法产生一个依赖于问题实例和资源消耗的常数$\alpha$和预算$B$的实例无关的竞争比率$\alpha\log B$。我们的方法基于在线凸优化技术和背包文献的思想的新颖组合。

    The bandits with knapsack (BwK) framework models online decision-making problems in which an agent makes a sequence of decisions subject to resource consumption constraints. The traditional model assumes that each action consumes a non-negative amount of resources and the process ends when the initial budgets are fully depleted. We study a natural generalization of the BwK framework which allows non-monotonic resource utilization, i.e., resources can be replenished by a positive amount. We propose a best-of-both-worlds primal-dual template that can handle any online learning problem with replenishment for which a suitable primal regret minimizer exists. In particular, we provide the first positive results for the case of adversarial inputs by showing that our framework guarantees a constant competitive ratio $\alpha$ when $B=\Omega(T)$ or when the possible per-round replenishment is a positive constant. Moreover, under a stochastic input model, our algorithm yields an instance-independ
    
[^28]: 批次使高维超参数线性回归的最小规范风险稳定

    Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression. (arXiv:2306.08432v1 [cs.LG])

    [http://arxiv.org/abs/2306.08432](http://arxiv.org/abs/2306.08432)

    本文研究了将数据分成批次的学习算法，在高维超参数线性回归模型中提供了隐式正则化，通过适当的批量大小选择，稳定了风险行为，消除了插值点处的膨胀和双峰现象

    

    将数据分成批次的学习算法在许多机器学习应用中很常见，通常在计算效率和性能之间提供有用的权衡。本文通过具有各向同性高斯特征的最小规范超参数线性回归模型的视角来研究批量分区的好处。我们建议最小规范估计量的自然小批量版本，并推导出其二次风险的上界，表明其与噪声水平以及过度参数化比例成反比，对于最佳批量大小的选择。与最小规范相比，我们的估计器具有稳定的风险行为，其在过度参数化比例上单调递增，消除了插值点处的膨胀和双峰现象。有趣的是，我们观察到批处理所提供的隐式正则化在一定程度上可以通过特征重叠来解释。

    Learning algorithms that divide the data into batches are prevalent in many machine-learning applications, typically offering useful trade-offs between computational efficiency and performance. In this paper, we examine the benefits of batch-partitioning through the lens of a minimum-norm overparameterized linear regression model with isotropic Gaussian features. We suggest a natural small-batch version of the minimum-norm estimator, and derive an upper bound on its quadratic risk, showing it is inversely proportional to the noise level as well as to the overparameterization ratio, for the optimal choice of batch size. In contrast to minimum-norm, our estimator admits a stable risk behavior that is monotonically increasing in the overparameterization ratio, eliminating both the blowup at the interpolation point and the double-descent phenomenon. Interestingly, we observe that this implicit regularization offered by the batch partition is partially explained by feature overlap between t
    
[^29]: 通过扰动数据源可证明高效的离线强化学习

    Provably Efficient Offline Reinforcement Learning with Perturbed Data Sources. (arXiv:2306.08364v1 [stat.ML])

    [http://arxiv.org/abs/2306.08364](http://arxiv.org/abs/2306.08364)

    本文讨论了用于离线强化学习中的多数据源问题，提出了HetPEVI算法，并证明了其在数据覆盖率高的情况下可行且有效。

    

    现有关于离线强化学习的理论研究大多考虑的是从目标任务直接采样得到的数据集。然而，在实践中，数据经常来自于几个异构但相关的源。鉴于这一差距，本文旨在通过从被随机扰动版本的目标任务中收集多个数据集，从而更严格地理解离线强化学习。我们推导出了一个信息论下界，揭示了一个除了数据样本数量之外对所涉及的源数量的必要要求。然后，我们提出了一种新的算法——HetPEVI，它同时考虑来自每个数据源的有限数量的数据样本的样本不确定性以及由于有限数量的可用数据源而产生的源不确定性。理论分析表明，只要数据源共同提供了良好的数据覆盖率，HetPEVI就能解决目标任务。此外，HetPEVI被证明是可行的且效率高的。

    Existing theoretical studies on offline reinforcement learning (RL) mostly consider a dataset sampled directly from the target task. In practice, however, data often come from several heterogeneous but related sources. Motivated by this gap, this work aims at rigorously understanding offline RL with multiple datasets that are collected from randomly perturbed versions of the target task instead of from itself. An information-theoretic lower bound is derived, which reveals a necessary requirement on the number of involved sources in addition to that on the number of data samples. Then, a novel HetPEVI algorithm is proposed, which simultaneously considers the sample uncertainties from a finite number of data samples per data source and the source uncertainties due to a finite number of available data sources. Theoretical analyses demonstrate that HetPEVI can solve the target task as long as the data sources collectively provide a good data coverage. Moreover, HetPEVI is demonstrated to b
    
[^30]: 基于随机傅里叶特征的贝叶斯非线性潜变量建模

    Bayesian Non-linear Latent Variable Modeling via Random Fourier Features. (arXiv:2306.08352v1 [stat.ML])

    [http://arxiv.org/abs/2306.08352](http://arxiv.org/abs/2306.08352)

    本文介绍了一种基于随机傅里叶特征的方法，可以将GPLVM推广到非高斯观测情况下的广义贝叶斯非线性潜变量建模，并提出了一种通过MCMC进行推断的方法。

    

    高斯过程潜变量模型(GPLVM)是一种广泛用于非线性降维、矩阵分解和状态空间建模的概率方法。当数据似然为高斯分布时，GPLVM的推断才是可计算的。此外，GPLVM的推断通常被限制在获得最大后验概率点估计 or 变分近似，这可能会导致过度拟合或误判后验不确定性。本文提出了一种通过MCMC进行广义贝叶斯非线性潜变量建模推断的方法。将高斯过程映射中的核函数用随机傅里叶特征近似的关键洞察力是我们可以计算出相对于潜变量的后验梯度，从而将GPLVM推广到非高斯观测。

    The Gaussian process latent variable model (GPLVM) is a popular probabilistic method used for nonlinear dimension reduction, matrix factorization, and state-space modeling. Inference for GPLVMs is computationally tractable only when the data likelihood is Gaussian. Moreover, inference for GPLVMs has typically been restricted to obtaining maximum a posteriori point estimates, which can lead to overfitting, or variational approximations, which mischaracterize the posterior uncertainty. Here, we present a method to perform Markov chain Monte Carlo (MCMC) inference for generalized Bayesian nonlinear latent variable modeling. The crucial insight necessary to generalize GPLVMs to arbitrary observation models is that we approximate the kernel function in the Gaussian process mappings with random Fourier features; this allows us to compute the gradient of the posterior in closed form with respect to the latent variables. We show that we can generalize GPLVMs to non-Gaussian observations, such 
    
[^31]: 在线核回归的亚线性计算复杂度近似最优算法

    Nearly Optimal Algorithms with Sublinear Computational Complexity for Online Kernel Regression. (arXiv:2306.08320v1 [cs.LG])

    [http://arxiv.org/abs/2306.08320](http://arxiv.org/abs/2306.08320)

    本文提出了两种新的算法AOGD-ALD和NONS-ALD，可以在亚线性计算复杂度下达到几乎最优的遗憾度，通过控制近似误差维护一组用于近似核映射的几乎正交基。

    

    在线核回归中遗憾和计算代价之间的权衡是一个基本问题，之前的算法在权衡上努力时无法保持在亚线性计算复杂度下的最优遗憾界。本文提出两种新算法AOGD-ALD和NONS-ALD，可以在亚线性计算复杂度下保持几乎最优的遗憾度，并给出我们的算法适用的充分条件。这两个算法动态地维护一组用于近似核映射的几乎正交基，并通过控制近似误差来保持近似最优的遗憾度。基数取决于近似误差和核矩阵特征值的衰减率。如果特征值呈指数衰减，则AOGD-ALD和NONS-ALD分别在$O(\ln^2{T})$的计算复杂度下达到$O(\sqrt{L(f)})$和$O(\mathrm{d}_{\mathrm{eff}}(\mu)\ln{T})$的遗憾度。如果特征值呈多项式衰减，则两个算法在$O(T^{\frac{-2}{3}}(\ln{T})^{\frac{4}{3}})$的计算复杂度下分别达到$O(\sqrt{L(f)})$遗憾度和$O(\mathrm{d}_{\mathrm{eff}}(\mu)(\ln{T})^{\frac{2}{3}})$遗憾度。

    The trade-off between regret and computational cost is a fundamental problem for online kernel regression, and previous algorithms worked on the trade-off can not keep optimal regret bounds at a sublinear computational complexity. In this paper, we propose two new algorithms, AOGD-ALD and NONS-ALD, which can keep nearly optimal regret bounds at a sublinear computational complexity, and give sufficient conditions under which our algorithms work. Both algorithms dynamically maintain a group of nearly orthogonal basis used to approximate the kernel mapping, and keep nearly optimal regret bounds by controlling the approximate error. The number of basis depends on the approximate error and the decay rate of eigenvalues of the kernel matrix. If the eigenvalues decay exponentially, then AOGD-ALD and NONS-ALD separately achieves a regret of $O(\sqrt{L(f)})$ and $O(\mathrm{d}_{\mathrm{eff}}(\mu)\ln{T})$ at a computational complexity in $O(\ln^2{T})$. If the eigenvalues decay polynomially with d
    
[^32]: 使用正交序列的差分隐私无线联合学习方法

    Differentially Private Wireless Federated Learning Using Orthogonal Sequences. (arXiv:2306.08280v1 [cs.IT])

    [http://arxiv.org/abs/2306.08280](http://arxiv.org/abs/2306.08280)

    本文提出了一种使用正交序列的FLORAS方法，可消除发送端的信道状态信息，同时提供了项目级和客户级的差分隐私保证。FLORAS可以灵活地实现不同的差分隐私等级，并且通过推导收敛界限，实现了收敛速度和隐私保证之间的平稳权衡。

    

    本文提出了一种新的隐私保护上行空中计算方法FLORAS，用于单输入单输出（SISO）无线联合学习（FL）系统。FLORAS从通信设计的角度出发，利用正交序列的性质消除了发送端的信道状态信息（CSIT）要求。从隐私保护的角度来看，我们证明FLORAS可以提供项目级和客户级差分隐私（DP）保证。此外，通过调整系统参数，FLORAS可以在不增加成本的情况下灵活地实现不同的DP等级。我们推导出了一个新的FL收敛界限，结合隐私保证，可以在收敛速度和差分隐私级别之间实现平稳的权衡。数值结果证明了FLORAS相对于基准AirComp方法的优势，并验证了我们的分析结果可以指导不同权衡条件下的隐私保护FL的设计。

    We propose a novel privacy-preserving uplink over-the-air computation (AirComp) method, termed FLORAS, for single-input single-output (SISO) wireless federated learning (FL) systems. From the communication design perspective, FLORAS eliminates the requirement of channel state information at the transmitters (CSIT) by leveraging the properties of orthogonal sequences. From the privacy perspective, we prove that FLORAS can offer both item-level and client-level differential privacy (DP) guarantees. Moreover, by adjusting the system parameters, FLORAS can flexibly achieve different DP levels at no additional cost. A novel FL convergence bound is derived which, combined with the privacy guarantees, allows for a smooth tradeoff between convergence rate and differential privacy levels. Numerical results demonstrate the advantages of FLORAS compared with the baseline AirComp method, and validate that our analytical results can guide the design of privacy-preserving FL with different tradeoff 
    
[^33]: 结构化离散表示的深度生成模型的无偏学习

    Unbiased Learning of Deep Generative Models with Structured Discrete Representations. (arXiv:2306.08230v1 [cs.LG])

    [http://arxiv.org/abs/2306.08230](http://arxiv.org/abs/2306.08230)

    该论文提出了一种名为结构化变分自编码器的深度生成模型，它通过图像模型的结构和可解释性以及深度学习的适用于高维数据的灵活似然，结合两种框架的优势。同时，该论文还提出了一种学习SVAE的新算法，与此同时，推导出了一种计算自然梯度的方法，这些优化创新使得SVAE首次能与最先进的时间序列模型进行比较。

    

    通过将图形模型与深度学习架构组合，我们学习具有两种框架优势的生成模型。 结构化变分自编码器（SVAE）从图形模型继承结构和可解释性，从深度学习中继承了适用于高维数据的灵活似然，但是会带来相当大的优化挑战。 我们提出了学习SVAE的新算法，并且首次证明了SVAE在含有缺失数据且包含离散潜变量时处理多模态不确定性的能力。我们的内存高效隐式微分方案使得SVAE可以通过梯度下降来学习，并且证明了鲁棒性。为了更快地学习准确的图形模型参数，我们推导了一种计算自然梯度的方法，而不需要手动进行导出，从而避免了先前工作中发现的偏差。这些优化创新使得首次能够将SVAE与最先进的时间序列模型进行比较。

    By composing graphical models with deep learning architectures, we learn generative models with the strengths of both frameworks. The structured variational autoencoder (SVAE) inherits structure and interpretability from graphical models, and flexible likelihoods for high-dimensional data from deep learning, but poses substantial optimization challenges. We propose novel algorithms for learning SVAEs, and are the first to demonstrate the SVAE's ability to handle multimodal uncertainty when data is missing by incorporating discrete latent variables. Our memory-efficient implicit differentiation scheme makes the SVAE tractable to learn via gradient descent, while demonstrating robustness to incomplete optimization. To more rapidly learn accurate graphical model parameters, we derive a method for computing natural gradients without manual derivations, which avoids biases found in prior work. These optimization innovations enable the first comparisons of the SVAE to state-of-the-art time s
    
[^34]: 在多模态人工智能中保护数据：一种差分隐私方法用于CLIP训练

    Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training. (arXiv:2306.08173v1 [cs.LG])

    [http://arxiv.org/abs/2306.08173](http://arxiv.org/abs/2306.08173)

    本文提出了一种差分隐私的CLIP模型（Dp-CLIP），旨在保护多模态AI任务中的数据隐私，同时保持模型准确性。该方法在基准数据集上得到了验证，并表明其与标准非私有CLIP模型相比具有同等的性能。

    

    多模态人工智能的成功引发了视觉和语言任务中数据隐私的关注。虽然CLIP通过对图像和文本的联合训练彻底改变了多模态学习，但其可能无意中披露敏感信息的潜力需要集成保护隐私的机制。我们引入了对比语言-图像预训练（CLIP）模型的差分隐私改进，有效地解决了隐私问题，同时保持准确性。我们提出的方法Dp-CLIP在包括图像分类和视觉问答等多样的视觉和语言任务的基准数据集上进行了严格评估。我们证明了我们的方法保持了与标准的非私有CLIP模型同等的性能。此外，我们在线性表示设置下分析了我们提出的算法。我们推导了算法的收敛速度，并展示了在梯度被剪辑时实用性和隐私之间的权衡。

    The surge in multimodal AI's success has sparked concerns over data privacy in vision-and-language tasks. While CLIP has revolutionized multimodal learning through joint training on images and text, its potential to unintentionally disclose sensitive information necessitates the integration of privacy-preserving mechanisms. We introduce a differentially private adaptation of the Contrastive Language-Image Pretraining (CLIP) model that effectively addresses privacy concerns while retaining accuracy. Our proposed method, Dp-CLIP, is rigorously evaluated on benchmark datasets encompassing diverse vision-and-language tasks such as image classification and visual question answering. We demonstrate that our approach retains performance on par with the standard non-private CLIP model. Furthermore, we analyze our proposed algorithm under linear representation settings. We derive the convergence rate of our algorithm and show a trade-off between utility and privacy when gradients are clipped pe
    
[^35]: 带有沉重尾部SGD训练的过参数化神经网络的隐式可压缩性

    Implicit Compressibility of Overparametrized Neural Networks Trained with Heavy-Tailed SGD. (arXiv:2306.08125v1 [stat.ML])

    [http://arxiv.org/abs/2306.08125](http://arxiv.org/abs/2306.08125)

    本研究提出了一种简单的SGD修改方法，使训练出的神经网络输出可被证明为可压缩，而不需要任何非平凡假设。

    

    由于减少计算需求和压缩与泛化误差之间的显式关系，神经网络压缩成为越来越重要的研究对象。最近的研究表明，随机梯度下降(SGD)的超参数选择可以影响学习参数向量的压缩性。虽然这些结果揭示了训练动态对压缩性的影响，但是它们依赖于不可验证的假设，由于隐含性质，得出的理论并没有提供实用的指导方针。在本研究中，我们提出了一种简单的SGD修改方法，使得算法的输出能够被证明是可压缩的，而不需要任何非平凡假设。我们考虑了一个使用SGD训练的单隐藏层神经网络，并在每次迭代中注入附加的沉重尾部噪声。

    Neural network compression has been an increasingly important subject, due to its practical implications in terms of reducing the computational requirements and its theoretical implications, as there is an explicit connection between compressibility and the generalization error. Recent studies have shown that the choice of the hyperparameters of stochastic gradient descent (SGD) can have an effect on the compressibility of the learned parameter vector. Even though these results have shed some light on the role of the training dynamics over compressibility, they relied on unverifiable assumptions and the resulting theory does not provide a practical guideline due to its implicitness. In this study, we propose a simple modification for SGD, such that the outputs of the algorithm will be provably compressible without making any nontrivial assumptions. We consider a one-hidden-layer neural network trained with SGD and we inject additive heavy-tailed noise to the iterates at each iteration.
    
[^36]: 对称张量分解问题的对称性与临界点

    Symmetry & Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])

    [http://arxiv.org/abs/2306.07886](http://arxiv.org/abs/2306.07886)

    本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。

    

    本文考虑了将一个实对称张量分解成秩为1项之和的非凸优化问题。利用其丰富的对称结构，导出Puiseux级数表示的一系列临界点，并获得了关于临界值和Hessian谱的精确分析估计。这些结果揭示了各种几何障碍，阻碍了局部优化方法的使用，最后，利用一个牛顿多面体论证了固定对称性的所有临界点的完全枚举，并证明了与全局最小值的集合相比，由于对称性的存在，临界点的集合可能会显示出组合的丰富性。

    We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
    
[^37]: 在在线推荐系统中激励高质量内容

    Incentivizing High-Quality Content in Online Recommender Systems. (arXiv:2306.07479v1 [cs.GT])

    [http://arxiv.org/abs/2306.07479](http://arxiv.org/abs/2306.07479)

    本文研究了在线推荐系统中激励高质量内容的算法问题，经典的在线学习算法会激励生产者创建低质量的内容，但本文提出的一种算法通过惩罚低质量内容的创建者，成功地激励了生产者创造高质量的内容。

    

    对于像TikTok和YouTube这样的内容推荐系统，平台的决策算法塑造了内容生产者的激励，包括生产者在内容质量上投入多少努力。许多平台采用在线学习，这会产生跨时间的激励，因为今天生产的内容会影响未来内容的推荐。在本文中，我们研究了在线学习产生的激励，分析了在纳什均衡下生产的内容质量。我们发现，像Hedge和EXP3这样的经典在线学习算法会激励生产者创建低质量的内容。特别地，内容质量在学习率方面有上限，并且随着典型学习率进展而趋近于零。在这一负面结果的基础上，我们设计了一种不同的学习算法——基于惩罚创建低质量内容的生产者——正确激励生产者创建高质量内容。我们的算法依赖于新颖的策略性赌博机问题，并克服了在组合设置中应用对抗性技术的挑战。在模拟和真实数据的实验中，我们的算法成功地激励生产者创建高质量内容。

    For content recommender systems such as TikTok and YouTube, the platform's decision algorithm shapes the incentives of content producers, including how much effort the content producers invest in the quality of their content. Many platforms employ online learning, which creates intertemporal incentives, since content produced today affects recommendations of future content. In this paper, we study the incentives arising from online learning, analyzing the quality of content produced at a Nash equilibrium. We show that classical online learning algorithms, such as Hedge and EXP3, unfortunately incentivize producers to create low-quality content. In particular, the quality of content is upper bounded in terms of the learning rate and approaches zero for typical learning rate schedules. Motivated by this negative result, we design a different learning algorithm -- based on punishing producers who create low-quality content -- that correctly incentivizes producers to create high-quality co
    
[^38]: Shuffle SGD总是比SGD更好：对具有任意数据顺序的SGD进行改进分析

    Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders. (arXiv:2305.19259v1 [cs.LG])

    [http://arxiv.org/abs/2305.19259](http://arxiv.org/abs/2305.19259)

    本论文研究了一种允许任意数据排序的普通SGD算法,并表明在非凸函数情况下，随机和单次洗牌的SGD比经典替换的SGD更快或至少与其一样好，无论迭代次数如何。

    

    随机梯度下降（SGD）算法被广泛用于优化神经网络，随机重排（RR）和单次洗牌（SS）是通过循环遍历训练数据的随机或单个排列的常见选择，然而这些算法在非凸情况下的收敛性质尚未完全理解。现有结果表明，在实际的训练场景中，当时代的数量小于训练集大小时，RR可能表现不如SGD。本文分析了一种允许任意数据排序的普通SGD算法，并展示了在非凸函数情况下的改进收敛速度。具体而言，我们的分析表明，随机和单次洗牌的SGD比经典替换的SGD更快或至少与其一样好，无论迭代次数如何。总的来说，我们的研究凸显了使用随机/单次洗牌的SGD的好处，并为其非凸收敛性质提供了新的见解。

    Stochastic Gradient Descent (SGD) algorithms are widely used in optimizing neural networks, with Random Reshuffling (RR) and Single Shuffle (SS) being popular choices for cycling through random or single permutations of the training data. However, the convergence properties of these algorithms in the non-convex case are not fully understood. Existing results suggest that, in realistic training scenarios where the number of epochs is smaller than the training set size, RR may perform worse than SGD.  In this paper, we analyze a general SGD algorithm that allows for arbitrary data orderings and show improved convergence rates for non-convex functions. Specifically, our analysis reveals that SGD with random and single shuffling is always faster or at least as good as classical SGD with replacement, regardless of the number of iterations. Overall, our study highlights the benefits of using SGD with random/single shuffling and provides new insights into its convergence properties for non-co
    
[^39]: 利用演进变化提高软件过程质量。

    Leveraging Evolutionary Changes for Software Process Quality. (arXiv:2305.18061v1 [cs.SE])

    [http://arxiv.org/abs/2305.18061](http://arxiv.org/abs/2305.18061)

    本文提出了一种利用演进变化来改善软件开发过程质量的方法，其包括使用统计过程控制和机器学习技术来分析应用程序生命周期管理所捕获的变更数据，实验表明该方法是有效的。

    

    现实世界中的软件应用必须不断演进才能保持相关性。传统的软件质量控制方法涉及软件质量模型和持续的代码检查工具。然而，软件开发过程的质量与最终软件产品的质量之间存在强关联和因果关系。因此，间接提高软件产品的质量需要改善软件开发过程的质量。本文提出了一种利用开发过程的演进变化来提高软件质量的新方法。该方法包括使用统计过程控制和机器学习技术来分析应用程序生命周期管理所捕获的变更数据。实验结果显示了该方法的有效性。

    Real-world software applications must constantly evolve to remain relevant. This evolution occurs when developing new applications or adapting existing ones to meet new requirements, make corrections, or incorporate future functionality. Traditional methods of software quality control involve software quality models and continuous code inspection tools. These measures focus on directly assessing the quality of the software. However, there is a strong correlation and causation between the quality of the development process and the resulting software product. Therefore, improving the development process indirectly improves the software product, too. To achieve this, effective learning from past processes is necessary, often embraced through post mortem organizational learning. While qualitative evaluation of large artifacts is common, smaller quantitative changes captured by application lifecycle management are often overlooked. In addition to software metrics, these smaller changes can 
    
[^40]: 正交解耦高斯过程的球形感应特征

    Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes. (arXiv:2304.14034v1 [cs.LG])

    [http://arxiv.org/abs/2304.14034](http://arxiv.org/abs/2304.14034)

    本文研究了解耦高斯过程的正交分解问题，提出了一种扩展方法，即引入球形跨域特征，构建更灵活的数据依赖基函数来缓解限制，并展示了其有效性。

    

    尽管高斯过程（GPs）具有许多优点，但它们缺乏学习表征的能力，因此经常与深度神经网络（NNs）进行比较。最近的工作通过在诱导变量与前馈NN的隐藏单元之间建立联系的跨域变分GPs来弥合 GPs和深度NN之间的差距。本文在研究此方法与实际应用中的一些实际问题，并提出一种扩展方法，利用GPs的正交分解来减轻这些限制。具体地，我们引入球形跨域特征，构建更灵活的数据依赖基函数，用于GP逼近的主要和正交分量，结果表明在此框架下加入NN激活特征，不仅可以缓解这些问题，而且比其他策略更具有可扩展性。在多个基准数据集上的实验表明了我们方法的有效性。

    Despite their many desirable properties, Gaussian processes (GPs) are often compared unfavorably to deep neural networks (NNs) for lacking the ability to learn representations. Recent efforts to bridge the gap between GPs and deep NNs have yielded a new class of inter-domain variational GPs in which the inducing variables correspond to hidden units of a feedforward NN. In this work, we examine some practical issues associated with this approach and propose an extension that leverages the orthogonal decomposition of GPs to mitigate these limitations. In particular, we introduce spherical inter-domain features to construct more flexible data-dependent basis functions for both the principal and orthogonal components of the GP approximation and show that incorporating NN activation features under this framework not only alleviates these shortcomings but is more scalable than alternative strategies. Experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.
    
[^41]: B-Learner：隐藏混淆下异质因果效应的准神谕界限

    B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding. (arXiv:2304.10577v1 [cs.LG])

    [http://arxiv.org/abs/2304.10577](http://arxiv.org/abs/2304.10577)

    本文提出了一种元学习器 B-Learner，它可以在限制隐藏混淆水平的情况下高效地学习 CATE 函数的尖锐界限。

    

    从观察数据中估计异质治疗效应是许多领域中的重要任务，有助于政策和决策者做出更好的行动。近年来，在估计条件平均治疗效应（CATE）函数方面取得了鲁棒且高效的方法，但这些方法通常未考虑隐藏混淆的风险，这可能会对基于观察数据的任何因果估计造成任意和不知情的偏差。我们提出了一种名为B-Learner的元学习器，它可以在限制隐藏混淆水平的情况下高效地学习CATE函数的尖锐界限。我们通过将最近针对平均治疗效应的尖锐且有效边界结果（Dorn等人，2021）调整为Kallus＆Oprescu（2022）所提供的稳健和模型无关的分布式治疗效应学习框架，派生出B-Learner。B-Learner可以使用任何函数估计器，例如随机森林和深度神经网络，我们证明了它的。

    Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus & Oprescu (2022) for robust and model-agnostic learning of distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its 
    
[^42]: 带有概率触发臂的情境组合赌博机

    Contextual Combinatorial Bandits with Probabilistically Triggered Arms. (arXiv:2303.17110v1 [cs.LG])

    [http://arxiv.org/abs/2303.17110](http://arxiv.org/abs/2303.17110)

    本文研究了带有概率触发臂的情境组合赌博机，在不同条件下设计了C$^2$-UCB-T算法和VAC$^2$-UCB算法，并分别导出了对应的遗憾值上限，为相关应用提供了理论支持。

    

    本研究探讨了在捕捉广泛应用范围的一系列平滑条件下的带有概率触发臂的情境组合赌博机(C$^2$MAB-T)，例如情境级联赌博机和情境最大化赌博机。在模拟触发概率(TPM)的条件下，我们设计了C$^2$-UCB-T算法，并提出了一种新的分析方法，实现了一个$\tilde{O}(d\sqrt{KT})$的遗憾值上限，消除了一个可能指数级增长的因子$O(1/p_{\min})$，其中$d$是情境的维数，$p_{\min}$是能被触发的任何臂的最小正概率，批大小$K$是每轮能被触发的臂的最大数量。在方差调制(VM)或触发概率和方差调制(TPVM)条件下，我们提出了一种新的方差自适应算法VAC$^2$-UCB，并导出了一个$\tilde{O}(d\sqrt{T})$的遗憾值上限，该上限与批大小$K$无关。作为一个有价值的副产品，我们发现我们的一个...

    We study contextual combinatorial bandits with probabilistically triggered arms (C$^2$MAB-T) under a variety of smoothness conditions that capture a wide range of applications, such as contextual cascading bandits and contextual influence maximization bandits. Under the triggering probability modulated (TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novel analysis that achieves an $\tilde{O}(d\sqrt{KT})$ regret bound, removing a potentially exponentially large factor $O(1/p_{\min})$, where $d$ is the dimension of contexts, $p_{\min}$ is the minimum positive probability that any arm can be triggered, and batch-size $K$ is the maximum number of arms that can be triggered per round. Under the variance modulated (VM) or triggering probability and variance modulated (TPVM) conditions, we propose a new variance-adaptive algorithm VAC$^2$-UCB and derive a regret bound $\tilde{O}(d\sqrt{T})$, which is independent of the batch-size $K$. As a valuable by-product, we find our a
    
[^43]: 基于正则化动态规划的乐观规划方法

    Optimistic Planning by Regularized Dynamic Programming. (arXiv:2302.14004v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14004](http://arxiv.org/abs/2302.14004)

    本文提出了一种基于正则化动态规划的乐观规划方法，可用于学习折扣线性混合MDPs中的最优策略，且具有近乎最优的统计保证

    

    我们提出了一种新的无限时段折扣马尔可夫决策过程中乐观规划的方法，基于在近似值迭代过程的更新中添加正则化的思想。此技术使我们能够避免萎缩和单调性论证，这通常是现有近似动态规划方法分析所要求的，特别是可以在具有线性函数逼近的MDPs中使用通过最小二乘法估计的近似转移函数。我们使用该方法恢复了表格MDPs中已知的保证，并提供了一种从单个流经验中学习折扣线性混合MDPs中接近最优策略的计算有效算法，并证明它实现了近乎最优的统计保证。

    We propose a new method for optimistic planning in infinite-horizon discounted Markov decision processes based on the idea of adding regularization to the updates of an otherwise standard approximate value iteration procedure. This technique allows us to avoid contraction and monotonicity arguments typically required by existing analyses of approximate dynamic programming methods, and in particular to use approximate transition functions estimated via least-squares procedures in MDPs with linear function approximation. We use our method to recover known guarantees in tabular MDPs and to provide a computationally efficient algorithm for learning near-optimal policies in discounted linear mixture MDPs from a single stream of experience, and show it achieves near-optimal statistical guarantees.
    
[^44]: 针对随机集成的外推交叉验证方法

    Extrapolated cross-validation for randomized ensembles. (arXiv:2302.13511v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2302.13511](http://arxiv.org/abs/2302.13511)

    本论文提出了一种名为ECV的交叉验证方法，用于调整随机集成中的集成和子样本大小。该方法基于Out-of-Bag错误和利用预测风险分解结构的新型风险外推技术，能够产生$\delta$-最优（关于Oracle调整风险）的集成。

    

    集成方法，如Bagging和随机森林在各个领域中随处可见，从金融到基因组学。尽管它们很常见，但关于有效调整集成参数的问题却受到相对较少的关注。本文介绍了一种交叉验证方法，即ECV（外推交叉验证），用于调整随机集成中的集成和子样本大小。我们的方法基于两个主要因素: 使用Out-of-Bag错误来获取小型集成的初步估计值和一种利用预测风险分解结构的新型风险外推技术。通过证明我们的风险外推技术在集成和子样本大小上具有统一的一致性，我们表明ECV对于平方预测风险能够产生$\delta$-最优（关于Oracle调整风险）。我们的理论适用于一般的集成预测器，只需要温和的矩假设，并允许具有高维度特征的情况。

    Ensemble methods such as bagging and random forests are ubiquitous in various fields, from finance to genomics. Despite their prevalence, the question of the efficient tuning of ensemble parameters has received relatively little attention. This paper introduces a cross-validation method, ECV (Extrapolated Cross-Validation), for tuning the ensemble and subsample sizes in randomized ensembles. Our method builds on two primary ingredients: initial estimators for small ensemble sizes using out-of-bag errors and a novel risk extrapolation technique that leverages the structure of prediction risk decomposition. By establishing uniform consistency of our risk extrapolation technique over ensemble and subsample sizes, we show that ECV yields $\delta$-optimal (with respect to the oracle-tuned risk) ensembles for squared prediction risk. Our theory accommodates general ensemble predictors, only requires mild moment assumptions, and allows for high-dimensional regimes where the feature dimension 
    
[^45]: 重访MADDPG中的Gumbel-Softmax

    Revisiting the Gumbel-Softmax in MADDPG. (arXiv:2302.11793v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11793](http://arxiv.org/abs/2302.11793)

    本文探索了多种Gumbel-Softmax的替代方法，并将其应用于MADDPG中，以解决离散动作空间下的性能问题。

    

    MADDPG是一种适用于多智能体强化学习的算法，它将单智能体方法DDPG推广到多智能体场景中。重要的是，DDPG是一种针对连续动作空间设计的算法，在其中状态-动作价值函数的梯度存在。为了使该算法适用于离散动作空间，必须进行离散的梯度估计。对于MADDPG算法，使用了Gumbel-Softmax（GS）估算器--一种将离散分布松弛到类似连续分布的再参数化方法。然而，该方法具有统计偏差，最近的多智能体强化学习算法基准测试论文表明，这种偏差使得MADDPG在格子世界等离散动作空间下表现不佳。幸运的是，GS的许多替代方法存在，具有各种各样的性能。本文探讨了其中几种替代方法，并将它们整合到离散格子世界场景中的MADDPG中。然后对各种性能指标的相应影响进行了测量。

    MADDPG is an algorithm in multi-agent reinforcement learning (MARL) that extends the popular single-agent method, DDPG, to multi-agent scenarios. Importantly, DDPG is an algorithm designed for continuous action spaces, where the gradient of the state-action value function exists. For this algorithm to work in discrete action spaces, discrete gradient estimation must be performed. For MADDPG, the Gumbel-Softmax (GS) estimator is used -- a reparameterisation which relaxes a discrete distribution into a similar continuous one. This method, however, is statistically biased, and a recent MARL benchmarking paper suggests that this bias makes MADDPG perform poorly in grid-world situations, where the action space is discrete. Fortunately, many alternatives to the GS exist, boasting a wide range of properties. This paper explores several of these alternatives and integrates them into MADDPG for discrete grid-world scenarios. The corresponding impact on various performance metrics is then measur
    
[^46]: 条件变分自编码器学习流形维度

    Learning Manifold Dimensions with Conditional Variational Autoencoders. (arXiv:2302.11756v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11756](http://arxiv.org/abs/2302.11756)

    该论文证明全局最优变分自编码器(CVAE)可以学习正确的流形维度，同时提出了一种新方法可以共同学习流形维度和条件分布，以在多个数据集上实现更好的特征分离和样本质量。

    

    虽然变分自编码器（VAE）及其条件扩展（CVAE）在多个领域中能够实现最先进的结果，但它们的精确行为仍未完全理解，特别是在数据（如图像）在或接近低维流形上的情况下。我们证明了VAE全局最小值确实能够恢复正确的流形维度，并通过引入一种新方法来共同学习流形维度和条件分布，进一步扩展了这一结果到更一般的CVAEs。我们在各种数据集上证明了我们方法的有效性，包括MNIST和CelebA，实现了表现最好的视觉质量和特征分离。

    Although the variational autoencoder (VAE) and its conditional extension (CVAE) are capable of state-of-the-art results across multiple domains, their precise behavior is still not fully understood, particularly in the context of data (like images) that lie on or near a low-dimensional manifold. For example, while prior work has suggested that the globally optimal VAE solution can learn the correct manifold dimension, a necessary (but not sufficient) condition for producing samples from the true data distribution, this has never been rigorously proven. Moreover, it remains unclear how such considerations would change when various types of conditioning variables are introduced, or when the data support is extended to a union of manifolds (e.g., as is likely the case for MNIST digits and related). In this work, we address these points by first proving that VAE global minima are indeed capable of recovering the correct manifold dimension. We then extend this result to more general CVAEs, 
    
[^47]: 源于超取样的信息论泛化界限更紧密

    Tighter Information-Theoretic Generalization Bounds from Supersamples. (arXiv:2302.02432v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.02432](http://arxiv.org/abs/2302.02432)

    本文介绍了一种新颖的信息论泛化界限，利用投影损失对，与Rademacher序列相关联来源于超取样的设置，这些界限比同一超取样设置中迄今已知的所有信息理论界限都更紧密。

    

    本文介绍了针对学习算法的各种新颖的信息论泛化界限，源于Steinke＆Zakynthinou（2020）的超取样设置-“条件互信息”框架的设置。我们的开发利用将损失对（从训练实例和测试实例获得）投影到单个数字，并将损失值与Rademacher序列（及其移动变体）相关联。所呈现的界限包括平方根界限，快速率界限，包括基于方差和尖锐度的界限以及插值算法的界限等。我们理论上或经验上证明，这些界限比同一超取样设置中迄今已知的所有信息理论界限都更紧密。

    In this work, we present a variety of novel information-theoretic generalization bounds for learning algorithms, from the supersample setting of Steinke & Zakynthinou (2020)-the setting of the "conditional mutual information" framework. Our development exploits projecting the loss pair (obtained from a training instance and a testing instance) down to a single number and correlating loss values with a Rademacher sequence (and its shifted variants). The presented bounds include square-root bounds, fast-rate bounds, including those based on variance and sharpness, and bounds for interpolating algorithms etc. We show theoretically or empirically that these bounds are tighter than all information-theoretic bounds known to date on the same supersample setting.
    
[^48]: 大型语言模型可以预测人类在六个感官模态下的感知评判

    Large language models predict human sensory judgments across six modalities. (arXiv:2302.01308v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.01308](http://arxiv.org/abs/2302.01308)

    本研究表明，最先进的大型语言模型能预测人类在六个感官模态下的感知评判，并能提供从语言中提取感知信息的下限。

    

    确定从语言中可以恢复感知世界的程度是哲学和认知科学中长期存在的问题。本研究展示了，最先进的大型语言模型通过提供从语言中提取感知信息的下限，可以为解决这个问题提供新的见解。具体而言，我们从GPT模型中引出了六个心理物理数据集的成对相似度评估结果。我们发现这些评估结果在所有领域中均与人类数据显著相关，回复了众所周知的表现，如颜色环和音高螺旋。令人惊讶的是，我们发现一个在视觉和语言上共同训练的模型（GPT-4）并不一定会导致对视觉模态的特定改进。为了研究特定语言对感知的影响，我们还将这些模型应用于多语言颜色命名任务。我们发现，GPT-4在英语和俄语中复制了跨语言差异，阐明了它们之间的相互作用。

    Determining the extent to which the perceptual world can be recovered from language is a longstanding problem in philosophy and cognitive science. We show that state-of-the-art large language models can unlock new insights into this problem by providing a lower bound on the amount of perceptual information that can be extracted from language. Specifically, we elicit pairwise similarity judgments from GPT models across six psychophysical datasets. We show that the judgments are significantly correlated with human data across all domains, recovering well-known representations like the color wheel and pitch spiral. Surprisingly, we find that a model (GPT-4) co-trained on vision and language does not necessarily lead to improvements specific to the visual modality. To study the influence of specific languages on perception, we also apply the models to a multilingual color-naming task. We find that GPT-4 replicates cross-linguistic variation in English and Russian illuminating the interacti
    
[^49]: SOBER：离散和混合空间上高并行贝叶斯优化和贝叶斯积分

    SOBER: Highly Parallel Bayesian Optimization and Bayesian Quadrature over Discrete and Mixed Spaces. (arXiv:2301.11832v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11832](http://arxiv.org/abs/2301.11832)

    SOBER算法是一种在离散和混合空间上进行高并行贝叶斯优化的方法，能够进行可扩展和多样化的批量全局优化和积分，且优于11个竞争基线方法。

    

    批处理贝叶斯优化和贝叶斯积分已被证明是在需并行查询昂贵的目标函数时执行优化和积分的高效方法。然而，当前的方法不适用于大批量操作。我们提出了一种新算法——SOBER，它允许在离散和混合空间上使用任意采集函数和内核进行可扩展和多样化的批量全局优化和积分。我们的方法的关键在于将全局优化的批量选择重新定义为积分问题，并将采集函数的最大化（非凸）松弛为内核重组（凸），从而有效地解决了两个任务。我们展示SOBER优于11个竞争基线方法。

    Batch Bayesian optimisation and Bayesian quadrature have been shown to be sample-efficient methods of performing optimisation and quadrature where expensive-to-evaluate objective functions can be queried in parallel. However, current methods do not scale to large batch sizes -- a frequent desideratum in practice (e.g. drug discovery or simulation-based inference). We present a novel algorithm, SOBER, which permits scalable and diversified batch global optimisation and quadrature with arbitrary acquisition functions and kernels over discrete and mixed spaces. The key to our approach is to reformulate batch selection for global optimisation as a quadrature problem, which relaxes acquisition function maximisation (non-convex) to kernel recombination (convex). Bridging global optimisation and quadrature can efficiently solve both tasks by balancing the merits of exploitative Bayesian optimisation and explorative Bayesian quadrature. We show that SOBER outperforms 11 competitive baselines o
    
[^50]: 基于扩散的结构化状态空间模型的条件心电信号生成

    Diffusion-based Conditional ECG Generation with Structured State Space Models. (arXiv:2301.08227v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2301.08227](http://arxiv.org/abs/2301.08227)

    本研究提出了将扩散模型和结构化状态空间模型相结合的新技术SSSD-ECG，在根据70多个心电图语句生成合成12导联心电图方面表现出色。

    

    合成数据生成是解决敏感健康数据分布时的隐私问题的一种有前途的解决方案。最近，扩散模型为不同的数据模式设定了新的生成模型标准。最近，结构化状态空间模型出现，成为捕捉时间序列中长期依赖关系的强大建模范例。我们提出了SSSD-ECG，将这两种技术相结合，用于根据70多个心电图语句生成合成12导联心电图的条件生成。由于没有可靠的基准，我们还提出了两种最先进的无条件生成模型的条件变体。我们通过评估在生成数据上预训练的分类器的性能来彻底评估所生成样本的质量，并评估了仅在合成数据上训练的分类器的性能，在这方面，SSSD-ECG明显优于其基于GAN的竞争对手。我们通过进一步的实验证明了我们方法的合理性。

    Synthetic data generation is a promising solution to address privacy issues with the distribution of sensitive health data. Recently, diffusion models have set new standards for generative models for different data modalities. Also very recently, structured state space models emerged as a powerful modeling paradigm to capture long-term dependencies in time series. We put forward SSSD-ECG, as the combination of these two technologies, for the generation of synthetic 12-lead electrocardiograms conditioned on more than 70 ECG statements. Due to a lack of reliable baselines, we also propose conditional variants of two state-of-the-art unconditional generative models. We thoroughly evaluate the quality of the generated samples, by evaluating pretrained classifiers on the generated data and by evaluating the performance of a classifier trained only on synthetic data, where SSSD-ECG clearly outperforms its GAN-based competitors. We demonstrate the soundness of our approach through further exp
    
[^51]: 通过非凸低秩半正定松弛实现对对抗训练神经网络的严格认证

    Tight Certification of Adversarially Trained Neural Networks via Nonconvex Low-Rank Semidefinite Relaxations. (arXiv:2211.17244v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.17244](http://arxiv.org/abs/2211.17244)

    本文提出了一种新的，基于低秩半正定松弛技术实现对对抗性训练神经网络的严格认证方法，它能够实现采用更便宜的SDP方法相当的强认证。

    

    众所周知，对抗训练可以产生高质量的神经网络模型，这些模型在经验上对抗性扰动具有鲁棒性。然而，一旦进行了对抗性训练，人们通常希望证明该模型在未来的所有攻击中真正具有鲁棒性。不幸的是，面对对抗训练模型时，所有现有方法都难以做出足够有效的证明。特别是线性规划（LP）技术，即使经过混合整数线性规划（MILP）和分支定界（BnB）技术的改进，也会面临"凸松弛壁垒"，使得它们难以进行高质量的证明。因此，本文提出了一种基于低秩半正定松弛的非凸认证技术。非凸松弛可以进行与更昂贵的半正定规划（SDP）方法相媲美的强认证，同时优化范围更广。

    Adversarial training is well-known to produce high-quality neural network models that are empirically robust against adversarial perturbations. Nevertheless, once a model has been adversarially trained, one often desires a certification that the model is truly robust against all future attacks. Unfortunately, when faced with adversarially trained models, all existing approaches have significant trouble making certifications that are strong enough to be practically useful. Linear programming (LP) techniques in particular face a "convex relaxation barrier" that prevent them from making high-quality certifications, even after refinement with mixed-integer linear programming (MILP) and branch-and-bound (BnB) techniques. In this paper, we propose a nonconvex certification technique, based on a low-rank restriction of a semidefinite programming (SDP) relaxation. The nonconvex relaxation makes strong certifications comparable to much more expensive SDP methods, while optimizing over dramatica
    
[^52]: 贝叶斯固定预算最佳臂识别

    Bayesian Fixed-Budget Best-Arm Identification. (arXiv:2211.08572v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.08572](http://arxiv.org/abs/2211.08572)

    本文提出一种贝叶斯消除算法，用于解决固定预算下最佳臂识别问题，并且推导了其与先验相关的误识别上界，此算法优于频率学派方法，与无保证的贝叶斯算法相竞争。

    

    固定预算最佳臂识别是一种赌博问题，代理人最大化识别最佳臂的概率，在一个固定的观察预算内。在本文中，我们研究了这个问题的贝叶斯设置。我们提出了一种贝叶斯消除算法，并推导出其误识别最优臂的概率的上界。这个上界反映了先验的质量，并且是此设置中第一个与分布相关的上界。我们使用类似于频率学派的论证证明了它，我们一直使用先验，然后在最后将赌徒实例积分掉，也为2个臂的贝叶斯赌徒提供了误识别概率的下界，并且展示了我们的上界在任何预算下（几乎）匹配。我们的实验证明了，贝叶斯消除优于频率学派方法，并且在此设置中，与无法保证的最先进的贝叶斯算法相竞争。

    Fixed-budget best-arm identification (BAI) is a bandit problem where the agent maximizes the probability of identifying the optimal arm within a fixed budget of observations. In this work, we study this problem in the Bayesian setting. We propose a Bayesian elimination algorithm and derive an upper bound on its probability of misidentifying the optimal arm. The bound reflects the quality of the prior and is the first distribution-dependent bound in this setting. We prove it using a frequentist-like argument, where we carry the prior through, and then integrate out the bandit instance at the end. We also provide a lower bound on the probability of misidentification in a $2$-armed Bayesian bandit and show that our upper bound (almost) matches it for any budget. Our experiments show that Bayesian elimination is superior to frequentist methods and competitive with the state-of-the-art Bayesian algorithms that have no guarantees in our setting.
    
[^53]: 关于Dantzig-Wolfe松弛对秩约束优化问题的准确性

    On the Exactness of Dantzig-Wolfe Relaxation for Rank Constrained Optimization Problems. (arXiv:2210.16191v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.16191](http://arxiv.org/abs/2210.16191)

    本文研究了DW松弛对RCOP的强度，并提出了同时必要和充分的条件，以确定DWR何时与任何m个双边线性矩阵不等式相匹配，包括三个方面的准确性：极端点的准确性、凸包的准确性以及目标的准确性。

    

    秩约束优化问题(RCOP)是最小化线性目标函数在一个预先指定的秩约束域集和m个通用的双边线性矩阵不等式上。受Dantzig-Wolfe (DW)分解的启发，我们研究了DW松弛(DWR)在RCOP中的强度，其与RCOP具有相同的表达式，只是将域集替换为其闭凸包。值得注意的是，我们的目标是确定使DWR与任何m个双边线性矩阵不等式相匹配的条件。从原始的角度出发，我们首次确定同时必要和充分的条件，以达到：(i)极端点的准确性——DWR可行集的所有极端点属于RCOP的极端点;(ii)凸包的准确性——DWR可行集等同于RCOP可行集的闭凸包; (iii)目标的准确性——优化的目标值在DWR可行集和RCOP可行集的闭凸包之间确切匹配。

    In the rank-constrained optimization problem (RCOP), it minimizes a linear objective function over a prespecified closed rank-constrained domain set and $m$ generic two-sided linear matrix inequalities. Motivated by the Dantzig-Wolfe (DW) decomposition, a popular approach of solving many nonconvex optimization problems, we investigate the strength of DW relaxation (DWR) of the RCOP, which admits the same formulation as RCOP except replacing the domain set by its closed convex hull. Notably, our goal is to characterize conditions under which the DWR matches RCOP for any m two-sided linear matrix inequalities. From the primal perspective, we develop the first-known simultaneously necessary and sufficient conditions that achieve: (i) extreme point exactness -- all the extreme points of the DWR feasible set belong to that of the RCOP; (ii) convex hull exactness -- the DWR feasible set is identical to the closed convex hull of RCOP feasible set; and (iii) objective exactness -- the optimal 
    
[^54]: 多尺度拓扑奇异性检测

    Topological Singularity Detection at Multiple Scales. (arXiv:2210.00069v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00069](http://arxiv.org/abs/2210.00069)

    本文提出了一种多尺度拓扑奇异性检测方法，可以评估数据的局部固有维度，并量化点的“流形度”，能够检测复杂空间和图像中的奇异性。

    

    流形假设是现代机器学习研究的一个基本假设，它假定数据位于或接近于低固有维度的未知流形上。然而，最近的研究表明，现实世界的数据表现出明显的非流形结构，即奇异性，这可能导致错误的发现。因此，检测这种奇异性在插值和推断任务之前是至关重要的。我们通过开发一个拓扑框架来解决这个问题，该框架能够（i）量化局部固有维度，以及（ii）在多个尺度上产生“欧几里得性”评分，用以评估点的“流形度”。我们的方法可以在图像数据中捕获复杂空间的奇异性，同时捕捉奇异结构和局部几何复杂性。

    The manifold hypothesis, which assumes that data lies on or close to an unknown manifold of low intrinsic dimension, is a staple of modern machine learning research. However, recent work has shown that real-world data exhibits distinct non-manifold structures, i.e. singularities, that can lead to erroneous findings. Detecting such singularities is therefore crucial as a precursor to interpolation and inference tasks. We address this issue by developing a topological framework that (i) quantifies the local intrinsic dimension, and (ii) yields a Euclidicity score for assessing the 'manifoldness' of a point along multiple scales. Our approach identifies singularities of complex spaces, while also capturing singular structures and local geometric complexity in image data.
    
[^55]: 研究模型宽度和密度对标签噪声下泛化性能的影响

    Investigating the Impact of Model Width and Density on Generalization in Presence of Label Noise. (arXiv:2208.08003v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.08003](http://arxiv.org/abs/2208.08003)

    本文研究发现标签噪声会导致双丘降曲线出现“最终上升”，即在足够大的噪声样本比率下，中等宽度下实现最佳泛化性能。随机丢弃可训练参数来减少密度可在标签噪声下改善泛化性能。

    

    扩大过参数化神经网络的规模是实现最先进性能的关键。这是通过双丘降现象捕捉的，其中测试损失随着模型宽度的增加呈现出降低-增加-降低的模式。然而，标签噪声对测试损失曲线的影响尚未被充分探索。在本文中，我们揭示了一个有趣的现象，即标签噪声导致原本观察到的双丘降曲线出现了“最终上升”。具体而言，在足够大的噪声样本比率下，中等宽度下实现最佳泛化性能。通过理论分析，我们将这种现象归因于标签噪声引起的测试损失方差形状转换。此外，我们将最终上升现象扩展到模型密度，并提供了第一个理论表征，表明随机丢弃可训练参数来减少密度可在标签噪声下改善泛化性能。

    Increasing the size of overparameterized neural networks has been a key in achieving state-of-the-art performance. This is captured by the double descent phenomenon, where the test loss follows a decreasing-increasing-decreasing pattern as model width increases. However, the effect of label noise on the test loss curve has not been fully explored. In this work, we uncover an intriguing phenomenon where label noise leads to a \textit{final ascent} in the originally observed double descent curve. Specifically, under a sufficiently large noise-to-sample-size ratio, optimal generalization is achieved at intermediate widths. Through theoretical analysis, we attribute this phenomenon to the shape transition of test loss variance induced by label noise. Furthermore, we extend the final ascent phenomenon to model density and provide the first theoretical characterization showing that reducing density by randomly dropping trainable parameters improves generalization under label noise. We also t
    
[^56]: 能量树: 结构和混合型协变量的回归和分类

    Energy Trees: Regression and Classification With Structured and Mixed-Type Covariates. (arXiv:2207.04430v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2207.04430](http://arxiv.org/abs/2207.04430)

    本文提出了能量树作为一种回归和分类模型，可以有效处理各种类型的结构化协变量，并具有可解释性、尺度不变性和无分布假设的自由。

    

    数据日益复杂，需要能够有效处理复杂结构的方法和模型，因为简化这些结构会导致信息丢失。虽然已经开发了多种分析工具来处理复杂数据对象的原始形式，但这些工具通常仅限于单一类型的变量。在本文中，我们提出了能量树作为回归和分类模型，能够容纳各种类型的结构化协变量。能量树利用能量统计量扩展了条件推断树的能力，从中继承了健全的统计基础、可解释性、尺度不变性和无分布假设的自由。我们特别关注功能和图形结构协变量，同时还突出了该模型在整合其他变量类型方面的灵活性。广泛的模拟研究表明，该模型在变量选择和抗过拟合的鲁棒性方面具有竞争性表现，以及对不同数据结构的适应能力。我们展示了能量树在实际数据集分析中的灵活性，包括功能数据、基因表达和社交网络。

    The increasing complexity of data requires methods and models that can effectively handle intricate structures, as simplifying them would result in loss of information. While several analytical tools have been developed to work with complex data objects in their original form, these tools are typically limited to single-type variables. In this work, we propose energy trees as a regression and classification model capable of accommodating structured covariates of various types. Energy trees leverage energy statistics to extend the capabilities of conditional inference trees, from which they inherit sound statistical foundations, interpretability, scale invariance, and freedom from distributional assumptions. We specifically focus on functional and graph-structured covariates, while also highlighting the model's flexibility in integrating other variable types. Extensive simulation studies demonstrate the model's competitive performance in terms of variable selection and robustness to ove
    
[^57]: 神经协方差SDE：初始化时具有无限深度和宽度的网络的形状。

    The Neural Covariance SDE: Shaped Infinite Depth-and-Width Networks at Initialization. (arXiv:2206.02768v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.02768](http://arxiv.org/abs/2206.02768)

    本文研究了前馈神经网络初始化时的随机协方差矩阵分布，发现对激活函数进行形状塑造可以使协方差矩阵是非退化的，而随机协方差矩阵受到神经协方差SDE的随机微分方程的控制。

    

    在初始化时，前馈神经网络的logit输出在给定由次表层定义的随机协方差矩阵的条件下是条件高斯分布的。本文研究了这种随机矩阵的分布。最近的研究表明，当网络深度增加时，对激活函数进行形状塑造是必要的，以使得这个协方差矩阵是非退化的。然而，当前无限宽度样式的这种理解在大深度时存在不足：无限宽度分析忽略了从层到层的微观波动，但这些波动在许多层上积累。为了克服这个问题，我们研究了由形状塑造的无限深度和宽度极限中的随机协方差矩阵。我们确定了到达非平凡极限所需的激活函数的精确缩放，并表明随机协方差矩阵受到我们称之为神经协方差SDE的随机微分方程的控制。使用模拟，我们证明了我们对神经协方差SDE的理解是准确的。

    The logit outputs of a feedforward neural network at initialization are conditionally Gaussian, given a random covariance matrix defined by the penultimate layer. In this work, we study the distribution of this random matrix. Recent work has shown that shaping the activation function as network depth grows large is necessary for this covariance matrix to be non-degenerate. However, the current infinite-width-style understanding of this shaping method is unsatisfactory for large depth: infinite-width analyses ignore the microscopic fluctuations from layer to layer, but these fluctuations accumulate over many layers.  To overcome this shortcoming, we study the random covariance matrix in the shaped infinite-depth-and-width limit. We identify the precise scaling of the activation function necessary to arrive at a non-trivial limit, and show that the random covariance matrix is governed by a stochastic differential equation (SDE) that we call the Neural Covariance SDE. Using simulations, w
    
[^58]: 低压负荷伯恩斯坦多项式归一化流的短期密度预测

    Short-Term Density Forecasting of Low-Voltage Load using Bernstein-Polynomial Normalizing Flows. (arXiv:2204.13939v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.13939](http://arxiv.org/abs/2204.13939)

    本文提出了一种基于伯恩斯坦多项式归一化流的灵活条件密度预测方法，用于短期低压负荷预测，相比传统方法表现更好，可用于规划和运营低碳能源系统。

    This paper proposes a flexible conditional density forecasting method based on Bernstein polynomial normalizing flows for short-term low-voltage load forecasting, which outperforms traditional methods and can be used for planning and operating low-carbon energy systems.

    实现全面可再生能源电网的转型需要更好地预测低压水平的需求，以提高效率并确保可靠的控制。然而，高波动性和不断增加的电气化导致巨大的预测变异性，这在传统的点估计中没有反映出来。概率负载预测考虑未来的不确定性，因此允许更明智的决策，用于规划和运营低碳能源系统。我们提出了一种基于伯恩斯坦多项式归一化流的灵活条件密度预测方法，其中神经网络控制流的参数。在一项包括363个智能电表客户的实证研究中，我们的密度预测与高斯和高斯混合密度相比表现出优势。此外，对于两种不同的神经网络架构，它们在24小时前的负载预测中优于基于针球损失的非参数方法。

    The transition to a fully renewable energy grid requires better forecasting of demand at the low-voltage level to increase efficiency and ensure reliable control. However, high fluctuations and increasing electrification cause huge forecast variability, not reflected in traditional point estimates. Probabilistic load forecasts take future uncertainties into account and thus allow more informed decision-making for the planning and operation of low-carbon energy systems. We propose an approach for flexible conditional density forecasting of short-term load based on Bernstein polynomial normalizing flows, where a neural network controls the parameters of the flow. In an empirical study with 363 smart meter customers, our density predictions compare favorably against Gaussian and Gaussian mixture densities. Also, they outperform a non-parametric approach based on the pinball loss for 24h-ahead load forecasting for two different neural network architectures.
    
[^59]: 用拓扑激活图来可视化深度神经网络

    Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.03528](http://arxiv.org/abs/2204.03528)

    本文提出使用拓扑激活图来可视化深度神经网络及其决策过程，提高了 DNN 的可解释性。

    

    深度神经网络（DNN）在解决各领域任务中已成为成功工具。然而，DNN的复杂性使得了解其如何解决所学任务变得困难。为了提高 DNN 的可解释性，我们采用神经科学的方法来分析复杂的不透明系统。我们从神经科学如何使用拓扑图可视化脑活动中获取灵感，同样地，我们研究了布置 DNN 层中神经元的技术，使得具有类似激活的神经元在彼此附近。本文中我们介绍了并比较了获得 DNN 层中神经元拓扑结构的方法。此外，我们展示了如何使用拓扑激活图来识别错误或编码偏见，并可视化训练过程。我们的新型可视化技术提高了基于 DNN 的决策系统的透明度。

    Machine Learning with Deep Neural Networks (DNNs) has become a successful tool in solving tasks across various fields of application. However, the complexity of DNNs makes it difficult to understand how they solve their learned task. To improve the explainability of DNNs, we adapt methods from neuroscience that analyze complex and opaque systems. Here, we draw inspiration from how neuroscience uses topographic maps to visualize brain activity. To also visualize activations of neurons in DNNs as topographic maps, we research techniques to layout the neurons in a two-dimensional space such that neurons of similar activity are in the vicinity of each other. In this work, we introduce and compare methods to obtain a topographic layout of neurons in a DNN layer. Moreover, we demonstrate how to use topographic activation maps to identify errors or encoded biases and to visualize training processes. Our novel visualization technique improves the transparency of DNN-based decision-making syste
    
[^60]: 高维两层神经网络中随机梯度下降的相图

    Phase diagram of Stochastic Gradient Descent in high-dimensional two-layer neural networks. (arXiv:2202.00293v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.00293](http://arxiv.org/abs/2202.00293)

    本文研究了高维两层神经网络中随机梯度下降的相图，探究了窄网络和过参数化浅层网络之间的交界处，并研究了三个方面变量之间的相互作用，工作建立在统计物理的框架下。

    

    虽然非凸优化景观，在过参数化的浅层网络中，梯度下降能够实现全局收敛。但情况对于窄网络却可能完全不同，它们倾向于被困在具有糟糕泛化的局部最小值。在这里，我们研究这两个范畴之间的交界处，特别是我们调查了所谓的平均场/流体力学范畴与Saad和Solla 的开创性方法之间的联系。我们重点研究了在高维随机梯度下降的动态中，学习率、时间尺度和隐含层数量之间的相互作用，以高斯数据为例。我们的工作基于从统计物理学中对于高维度随机梯度下降的确定性描述，我们加以拓展并提供了严密的收敛速率证明。

    Despite the non-convex optimization landscape, over-parametrized shallow networks are able to achieve global convergence under gradient descent. The picture can be radically different for narrow networks, which tend to get stuck in badly-generalizing local minima. Here we investigate the cross-over between these two regimes in the high-dimensional setting, and in particular investigate the connection between the so-called mean-field/hydrodynamic regime and the seminal approach of Saad & Solla. Focusing on the case of Gaussian data, we study the interplay between the learning rate, the time scale, and the number of hidden units in the high-dimensional dynamics of stochastic gradient descent (SGD). Our work builds on a deterministic description of SGD in high-dimensions from statistical physics, which we extend and for which we provide rigorous convergence rates.
    
[^61]: 基于最大似然的OOD检测中的熵问题

    Entropic Issues in Likelihood-Based OOD Detection. (arXiv:2109.10794v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2109.10794](http://arxiv.org/abs/2109.10794)

    本文研究了最大似然训练的深度生成模型的OOD检测问题，提出了一种新的观察角度，即将平均似然分解为KL散度项和熵项。后者可以解释模型可能会给OOD数据高似然值的现象，因为它抑制具有更高熵的数据集上的似然值。

    

    最大似然训练的深度生成模型仍然是关于数据概率推理的流行方法。然而，观察到它们可能会分配比正向分布数据更高的可能性，因此质疑这些似然值的含义。本文提供了一种新的观察角度，将平均似然分解为KL散度项和熵项。我们认为后者可以解释上述奇怪的OOD行为，抑制具有更高熵的数据集上的似然值。虽然我们的思路很简单，但我们还没有看到它在文献中得到探讨。这种分析进一步解释了基于似然比的OOD检测方法成功的原因，因为问题熵项在期望中会抵消。最后，我们讨论了这一观察结果如何与最近在流形支持模型中的OOD检测成功相关。

    Deep generative models trained by maximum likelihood remain very popular methods for reasoning about data probabilistically. However, it has been observed that they can assign higher likelihoods to out-of-distribution (OOD) data than in-distribution data, thus calling into question the meaning of these likelihood values. In this work we provide a novel perspective on this phenomenon, decomposing the average likelihood into a KL divergence term and an entropy term. We argue that the latter can explain the curious OOD behaviour mentioned above, suppressing likelihood values on datasets with higher entropy. Although our idea is simple, we have not seen it explored yet in the literature. This analysis provides further explanation for the success of OOD detection methods based on likelihood ratios, as the problematic entropy term cancels out in expectation. Finally, we discuss how this observation relates to recent success in OOD detection with manifold-supported models, for which the above
    
[^62]: 无需信任的私有联邦学习：凸损失函数的最优算法

    Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses. (arXiv:2106.09779v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.09779](http://arxiv.org/abs/2106.09779)

    本文研究了无需信任服务器或其他数据源的跨 silo 联邦学习，考虑了跨 silo 记录级差分隐私 ISRL-DP。该算法可以确保来自每个人的数据都不会被泄漏。

    

    本文探讨了联邦学习（FL）的研究，特别是跨数据源（跨 silo）FL，这些数据源的数据主人都不信任服务器或其他 silos。在这种情况下，每个数据源（例如医院）都有来自不同人（例如患者）的数据，并且必须维护每个人（例如医疗记录）数据的隐私，即使服务器或其他数据源是恶意监听者。这种要求促进了对跨 silo 记录级差分隐私（ISRL-DP）的研究，它要求 silo i 的通信满足记录 / 项目级差分隐私 (DP)。ISRL-DP 确保 silo i 中每个人（例如患者）的数据都不会泄漏。ISRL-DP 不同于各种已有的隐私概念。中心和用户级差分隐私假定人们信任服务器/其他数据源。在极端情况下，本地DP 假定人们根本不信任任何人（甚至是他们自己的数据源）。ISRL-DP 处于中心和本地DP 之间，使得在跨 silo 的真实情况下具有现实意义。

    This paper studies federated learning (FL)--especially cross-silo FL--with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person's data (e.g. medical record), even if the server or other silos act as adversarial eavesdroppers. This requirement motivates the study of Inter-Silo Record-Level Differential Privacy (ISRL-DP), which requires silo i's communications to satisfy record/item-level differential privacy (DP). ISRL-DP ensures that the data of each person (e.g. patient) in silo i (e.g. hospital i) cannot be leaked. ISRL-DP is different from well-studied privacy notions. Central and user-level DP assume that people trust the server/other silos. On the other end of the spectrum, local DP assumes that people do not trust anyone at all (even their own silo). Sitting between central and local DP, ISRL-DP makes the realistic assumption (in cross-sil
    
[^63]: 鲁棒的样本加权方法以便为目标人群学习个体化治疗规则

    Robust Sample Weighting to Facilitate Individualized Treatment Rule Learning for a Target Population. (arXiv:2105.00581v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2105.00581](http://arxiv.org/abs/2105.00581)

    本文研究了个体化治疗规则的泛化问题，提出一种加权框架方法以缓解因规定的函数类不包含最优规则而导致的影响。

    

    学习个体化治疗规则对于精准医疗至关重要。当前文献主要关注从单个来源人群中导出个体化治疗规则。然而，当来源人群与目标人群不同时，我们需要考虑观察数据设置。与平均治疗效应的因果推广不同，个体化治疗规则的推广由于需要基于一个预先指定的函数类对规则进行建模和推广，因此面临着新的挑战，该函数类可能不包含无约束真正最优个体化治疗规则。本文旨在开发一种加权框架，以缓解这种错误规定的影响，从而促进从来源人群到目标人群的最优个体化治疗规则的泛化。我们的方法寻求在由再生核希尔伯特空间表征的非参数函数类上进行协变量平衡，并且可以改进许多依赖于权重的个体化治疗规则学习方法。我们证明了样本加权估计的一致性。

    Learning individualized treatment rules (ITRs) is an important topic in precision medicine. Current literature mainly focuses on deriving ITRs from a single source population. We consider the observational data setting when the source population differs from a target population of interest. Compared with causal generalization for the average treatment effect which is a scalar quantity, ITR generalization poses new challenges due to the need to model and generalize the rules based on a prespecified class of functions which may not contain the unrestricted true optimal ITR. The aim of this paper is to develop a weighting framework to mitigate the impact of such misspecification and thus facilitate the generalizability of optimal ITRs from a source population to a target population. Our method seeks covariate balance over a non-parametric function class characterized by a reproducing kernel Hilbert space and can improve many ITR learning methods that rely on weights. We show that the prop
    
[^64]: 内在切片Wasserstein距离用于比较流形和图上的概率分布集合

    Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs. (arXiv:2010.15285v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2010.15285](http://arxiv.org/abs/2010.15285)

    该论文介绍了一种新颖的概率分布集合比较方法，能在流形和图上使用，该方法使用内在切片构造，得出一种新的类Wasserstein距离，可将分布集合比较问题减少到希尔伯特空间中更熟悉的均值检验问题。

    

    概率分布的集合在各种应用中广泛应用，范围从用户活动模式分析到脑连接学。实际上，这些分布可以定义在各种不同的域类型上，包括有限区间、圆、圆柱、球、其他流形和图。本文介绍了一种方法来检测在这样的一般域上两个概率分布集合之间的差异。为此，我们提出了内在切片构造，得出了一个新的类Wasserstein距离，用于流形和图上的分布。这些距离是希尔伯特可嵌入的，使我们能够将分布集合比较问题减少到希尔伯特空间中更熟悉的均值检验问题。我们提供了两种测试程序，一种基于重采样，另一种基于组合来自坐标化测试的p值。我们在各种合成和实际数据设置中的实验表明，所得到的测试是强有力的，p值是很好地校准过的。

    Collections of probability distributions arise in a variety of applications ranging from user activity pattern analysis to brain connectomics. In practice these distributions can be defined over diverse domain types including finite intervals, circles, cylinders, spheres, other manifolds, and graphs. This paper introduces an approach for detecting differences between two collections of distributions over such general domains. To this end, we propose the intrinsic slicing construction that yields a novel class of Wasserstein distances on manifolds and graphs. These distances are Hilbert embeddable, allowing us to reduce the distribution collection comparison problem to a more familiar mean testing problem in a Hilbert space. We provide two testing procedures one based on resampling and another on combining p-values from coordinate-wise tests. Our experiments in various synthetic and real data settings show that the resulting tests are powerful and the p-values are well-calibrated.
    
[^65]: 我们至少应该能够设计出好的分子结合体

    We Should at Least Be Able to Design Molecules That Dock Well. (arXiv:2006.16955v5 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2006.16955](http://arxiv.org/abs/2006.16955)

    该文提出了一个基于对接的基准测试来评估分子结合蛋白质的流行计算方法，探究了目前基于图形的生成模型在新型药物设计上的局限性，并提出了新的基准测试版本。

    

    设计具有所需特性的化合物是药物发现过程的关键元素。然而，由于缺乏现实的回顾性基准和前瞻性验证的高昂成本，衡量该领域的进展一直是具有挑战性的。为了弥补这一差距，我们提出了一个基于对接的基准测试，这是一种用于评估分子结合蛋白质的流行计算方法。具体而言，目标是生成得分高的药物样分子，这些药物属于SMINA，一种流行的对接软件。我们观察到，在使用真实大小的训练集进行训练后，流行的基于图形的生成模型无法生成具有高结合得分的分子。这表明了当前的模型在新型药物设计中存在局限性。最后，我们提出了基于简化评分函数的基准测试版本，并展示测试模型能够部分解决该问题。我们将该基准测试作为一个易于使用的软件包发布，可在 https://github.com 上获得。

    Designing compounds with desired properties is a key element of the drug discovery process. However, measuring progress in the field has been challenging due to the lack of realistic retrospective benchmarks, and the large cost of prospective validation. To close this gap, we propose a benchmark based on docking, a popular computational method for assessing molecule binding to a protein. Concretely, the goal is to generate drug-like molecules that are scored highly by SMINA, a popular docking software. We observe that popular graph-based generative models fail to generate molecules with a high docking score when trained using a realistically sized training set. This suggests a limitation of the current incarnation of models for de novo drug design. Finally, we propose a simplified version of the benchmark based on a simpler scoring function, and show that the tested models are able to partially solve it. We release the benchmark as an easy to use package available at https://github.com
    

