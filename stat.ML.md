# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Early Time Classification with Accumulated Accuracy Gap Control](https://arxiv.org/abs/2402.00857) | 本文介绍了一种早期时间分类算法，该算法通过统计框架和校准停止规则实现了对完全分类与早期时间分类之间的准确度间隔的有限样本、分布无关的控制。其主要贡献是提出了一种框架，该框架在累计停止时间的条件下控制了一种更强的错误概念的准确度间隔。 |
| [^2] | [Score-based Causal Representation Learning: Linear and General Transformations](https://arxiv.org/abs/2402.00849) | 这篇论文提出了一种基于得分的算法类，用于干预范围内的因果表示学习，涵盖了线性和一般转化。算法保证了可识别性和实现性，并且通过创造性地将得分函数与因果表示学习相结合。 |
| [^3] | [BootsTAP: Bootstrapped Training for Tracking-Any-Point](https://arxiv.org/abs/2402.00847) | 该论文展示了如何通过使用大规模、无标签、未筛选的真实世界数据，以及采用自监督的师生设置，来改进Tracking-Any-Point（TAP）模型的性能。通过在TAP-Vid基准测试上取得了state-of-the-art的结果，该方法在TAP任务上取得了显著的改进。 |
| [^4] | [Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI](https://arxiv.org/abs/2402.00809) | 《在大规模人工智能时代的贝叶斯深度学习》这篇立场论文探讨了贝叶斯深度学习在各种不同设置下的优势，并指出了与之相关的挑战和有趣的研究方向。未来的研究重点将放在如何将大规模基础模型与贝叶斯深度学习相结合，以发挥它们的全部潜力。 |
| [^5] | [Hybrid Quantum Vision Transformers for Event Classification in High Energy Physics](https://arxiv.org/abs/2402.00776) | 该论文提出了一种基于量子的混合视觉转换器模型，用于高能物理中的事件分类任务。通过减少训练和操作时间，该模型可以达到与经典模型相当的性能。 |
| [^6] | [Benefits of Transformer: In-Context Learning in Linear Regression Tasks with Unstructured Data](https://arxiv.org/abs/2402.00743) | 本研究通过线性回归任务的实验研究了Transformer在非结构化数据中的上下文学习能力，并解释了其中的关键组件。 |
| [^7] | [Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation](https://arxiv.org/abs/2402.00728) | 本文提出了一种利用Dropout技术探索拉肖蒙集中模型的新框架，以度量和减轻预测多重性。通过严格的理论推导和广泛的实验评价，结果表明我们的技术始终优于基线模型。 |
| [^8] | [Spectrally Transformed Kernel Regression](https://arxiv.org/abs/2402.00645) | 光谱变换核回归是一种能够利用无标签数据的通用和可扩展的方法，具有学习充分平滑函数的能力，并且在感知范式中提供了可扩展的实现。 |
| [^9] | [Bayesian Causal Inference with Gaussian Process Networks](https://arxiv.org/abs/2402.00623) | 以高斯过程网络为基础，通过模拟干预效果和传播干预效果，进行灵活的贝叶斯因果推断，同时以局部变量为函数估计干预分布并使用加性高斯过程对条件分布进行建模。 |
| [^10] | [Uncertainty-Aware Partial-Label Learning](https://arxiv.org/abs/2402.00592) | 本文提出了一种基于最近邻的部分标签学习算法，利用Dempster-Shafer理论实现对模糊标记的数据的训练。实验结果表明，该算法能够提供良好的不确定性估计，并具有竞争力的预测性能。 |
| [^11] | [Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling](https://arxiv.org/abs/2402.00522) | 本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。 |
| [^12] | [Equivalence of the Empirical Risk Minimization to Regularization on the Family of f-Divergences](https://arxiv.org/abs/2402.00501) | 经验风险最小化与f-分布族的正则化的解决方案在特定条件下是唯一的，并且可以通过使用不同的f-分布正则化等效地表示。 |
| [^13] | [Efficient Exploration for LLMs](https://arxiv.org/abs/2402.00396) | 高效探索在改善大型语言模型方面具有显著优势，可以以较少的查询实现较高的性能水平。不确定性估计和探索方案的选择是关键因素。 |
| [^14] | [Cumulative Distribution Function based General Temporal Point Processes](https://arxiv.org/abs/2402.00388) | 本研究引入了CuFun模型，基于累积分布函数的通用时间点过程，解决了深度时间点过程模型中的强度函数建模、积分计算复杂性和长期时序依赖性捕捉的问题。 |
| [^15] | [On the design-dependent suboptimality of the Lasso](https://arxiv.org/abs/2402.00382) | 本文研究了设计矩阵对Lasso估计器的影响，发现当最小奇异值很小时，Lasso估计器在最小化速率方面是次优的。我们提供了一族设计矩阵和稀疏参数，证明无论正则化参数的选择是数据依赖性的还是随机的，Lasso估计器都会在估计速率上表现出多项式因素的次优性。 |
| [^16] | [Comparing Spectral Bias and Robustness For Two-Layer Neural Networks: SGD vs Adaptive Random Fourier Features](https://arxiv.org/abs/2402.00332) | 本研究比较了两种训练算法对于两层神经网络的谱偏差和鲁棒性的影响，结果表明自适应随机傅里叶特征算法（ARFF）可以在谱偏差方面取得更好的结果，并且与随机梯度下降优化器（SGD）相比具有更好的鲁棒性。 |
| [^17] | [Information-Theoretic Thresholds for Planted Dense Cycles](https://arxiv.org/abs/2402.00305) | 本论文研究了一种小世界网络的随机图模型，在这个模型中，通过信息论阈值来刻画种植的稠密环路的检测和恢复问题，这与之前基于计算阈值的研究结果不同，揭示了统计与计算之间的差距。 |
| [^18] | [Not All Learnable Distribution Classes are Privately Learnable](https://arxiv.org/abs/2402.00267) | 这篇论文证明了一类分布虽然可以在有限样本下以总变差距离进行学习，但却无法在（ε，δ）-差分隐私下学习。 |
| [^19] | [Continuous Treatment Effects with Surrogate Outcomes](https://arxiv.org/abs/2402.00168) | 本文研究了在部分缺失主要结果的情况下，使用替代结果来估计连续治疗效果，并提出了一种双重稳健方法，通过使用标记和未标记数据，可以有效地纳入替代结果并避免选择偏误问题。该方法的估计值渐近正态性，并在方差方面可能比仅使用标记数据的方法有所改进。模拟实验证明了该方法的良好实证性能。 |
| [^20] | [Behind the Myth of Exploration in Policy Gradients](https://arxiv.org/abs/2402.00162) | 本论文提出了对政策梯度算法中探索项的新分析方法，区分了其平滑学习目标和增加梯度估计的两种不同作用。同时，详细讨论和实证了基于熵奖励的探索策略的局限性，并开辟了未来对这些策略设计和分析的研究方向。 |
| [^21] | [Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss](https://arxiv.org/abs/2402.00152) | 本文比较了更深的神经网络和更宽的神经网络在Sobolev损失的最优泛化误差方面的表现，研究发现神经网络的架构受多种因素影响，参数数量更多倾向于选择更宽的网络，而样本点数量和损失函数规则性更高倾向于选择更深的网络。 |
| [^22] | [Explainable AI for survival analysis: a median-SHAP approach](https://arxiv.org/abs/2402.00072) | 这项研究介绍了一种中位数-SHAP方法，用于解释黑盒子模型在预测个体生存时间方面产生的解释偏差问题。 |
| [^23] | [Comparing Machine Learning Algorithms by Union-Free Generic Depth](https://arxiv.org/abs/2312.12839) | 本研究提出了一种描述性分析偏序集合的框架，通过改进的无交并泛深度 (ufg) 比较机器学习算法，并在标准基准数据集上提供了示例。研究结果展示了基于ufg方法的多样性分析方法，并与现有的基准测试方法有很大区别。 |
| [^24] | [Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal Inference](https://arxiv.org/abs/2311.18826) | 本文提出了一种几何感知的归一化Wasserstein流的方法，通过整合连续归一化流（CNFs）和参数子模型，优化了因果推断的表现，并在最优传输理论中提高了鲁棒性。 |
| [^25] | [Parameter Inference based on Gaussian Processes Informed by Nonlinear Partial Differential Equations](https://arxiv.org/abs/2212.11880) | 本文提出了一种基于PDE信息的高斯过程（PIGP）的参数推断方法，通过将PDE解建模为高斯过程，利用PDE结构引起的约束条件来推断未知参数。 |
| [^26] | [Feed-Forward Latent Domain Adaptation](https://arxiv.org/abs/2207.07624) | 本文研究了前馈潜在领域自适应的问题，提出了一种通过元学习和交叉注意力实现动态适应的方法，该方法在资源受限的边缘设备上取得了一致的改进。 |
| [^27] | [Collaborative likelihood-ratio estimation over graphs](https://arxiv.org/abs/2205.14461) | 该论文提出了基于图的协同似然比估计方法，通过考虑图结构信息，估计每个节点间的似然比，节点可以协作来更高效地解决问题。 |
| [^28] | [The curse of overparametrization in adversarial training: Precise analysis of robust generalization for random features regression](https://arxiv.org/abs/2201.05149) | 本文精确分析了对对抗训练中过度参数化的影响，发现过度参数化模型对微小对抗扰动非常脆弱，显示了鲁棒泛化的性能明显差于标准泛化的性能。 |
| [^29] | [Probability-Generating Function Kernels for Spherical Data](https://arxiv.org/abs/2112.00365) | 该论文介绍了一种在球面数据分析中应用的概率生成函数核，扩展了RBF核并引入了半参数学习算法。 |
| [^30] | [Online Graph Topology Learning from Matrix-valued Time Series](https://arxiv.org/abs/2107.08020) | 本文通过研究矩阵值时间序列的统计分析，提出了在线图拓扑学习的方法。首先，将VAR模型扩展为矩阵变量模型以适用于图形学习。其次，提出了两种在线过程，针对低维和高维情况快速更新系数的估计。这些方法在高维情况下引入了一种新的Lasso-type进行拓扑处理。 |
| [^31] | [Individualized Multi-Treatment Response Curves Estimation using RBF-net with Shared Neurons.](http://arxiv.org/abs/2401.16571) | 我们提出了一种使用共享神经元的RBF网络的非参数化治疗效应估计方法，适用于多治疗设置。该方法能够建模治疗结果的共同性，并在贝叶斯框架下实现估计和推断，通过模拟实验证明了其数值性能，应用于真实临床数据后也得到了有趣的发现。 |
| [^32] | [A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics.](http://arxiv.org/abs/2401.15122) | 提出了一种能够促进数值MD模拟并有效模拟蛋白质-配体结合动力学的NeuralMD方法，采用物理信息多级对称框架，实现了准确建模多级蛋白质-配体相互作用。 |
| [^33] | [Conformal Prediction Sets Improve Human Decision Making.](http://arxiv.org/abs/2401.13744) | 该研究表明，通过规范预测量化模型的不确定性，可以提高人类决策的准确性和效果，对人机协同决策具有实用价值。 |
| [^34] | [Implicit Manifold Gaussian Process Regression.](http://arxiv.org/abs/2310.19390) | 本文提出了一种能够从数据中直接推断隐式结构的高斯过程回归技术，能够处理高维数据，并可能改善预测性能和校准。 |
| [^35] | [The Noise Geometry of Stochastic Gradient Descent: A Quantitative and Analytical Characterization.](http://arxiv.org/abs/2310.00692) | 本文对随机梯度下降（SGD）中的噪声几何进行了全面的理论研究，发现噪声与损失函数的局部几何特征有利的一致性。通过实验证明，SGD在逃脱尖锐极小值时与GD形成鲜明对比，逃脱方向在平坦方向上有显著分量。 |
| [^36] | [Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language.](http://arxiv.org/abs/2308.05061) | 本文提出了一种使用传感器数据、方程和自然语言提示上下文中运算符学习的方法。通过整合人类知识和语言描述，该方法不仅扩展了物理信息学习的灵活性和普适性，而且显著提高了学习性能和减少了数据需求。 |
| [^37] | [Corruption-Robust Lipschitz Contextual Search.](http://arxiv.org/abs/2307.13903) | 该论文研究了学习具有被篡改的二进制信号的Lipschitz函数的问题，提出了一种腐败鲁棒算法。该算法在不同损失函数下实现了不同程度的后悔。 |
| [^38] | [SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States.](http://arxiv.org/abs/2306.04817) | 本文提出了一种跨状态的图形相似性驱动的模块推理框架，可以同时考虑数据中的状态间和状态内关系，并允许状态之间的会话计数和持续时间的差异。它可以提取非正交组件，并且能够识别特定状态与状态非特定模块。 |
| [^39] | [Acceleration of stochastic gradient descent with momentum by averaging: finite-sample rates and asymptotic normality.](http://arxiv.org/abs/2305.17665) | 研究了动量随机梯度下降（SGDM）和其Polyak-averaging版本的特性，表明在较大的批量大小下，小批量SGDM比小批量SGD更快地收敛到最优值的邻域。 |
| [^40] | [Calibration Assessment and Boldness-Recalibration for Binary Events.](http://arxiv.org/abs/2305.03780) | 本研究提出了一种假设检验和贝叶斯模型选择方法来评估校准，并提供一种大胆再校准策略，使实践者能够在满足所需的校准水平的情况下负责任地增强预测。 |
| [^41] | [Piecewise Normalizing Flows.](http://arxiv.org/abs/2305.02930) | 介绍了一种分段归一化流方法，将目标分布分成集群，并通过训练模拟复杂的多模态目标。这种方法可以更好地匹配标准正态基础分布的拓扑结构。 |
| [^42] | [Estimating Higher-Order Mixed Memberships via the $\ell_{2,\infty}$ Tensor Perturbation Bound.](http://arxiv.org/abs/2212.08642) | 本文提出了一种用于估计更高阶混合成员关系的方法，该方法基于$\ell_{2,\infty}$张量扰动界限，通过张量混合成员模型对多样化数据的社区结构进行建模，并使用高阶正交迭代算法进行估计过程。通过提供每个节点的误差界限来证明了估计过程的一致性，展示了高阶结构对估计精度的影响。 |

# 详细

[^1]: 早期时间分类中的累积准确度间隔控制

    Early Time Classification with Accumulated Accuracy Gap Control

    [https://arxiv.org/abs/2402.00857](https://arxiv.org/abs/2402.00857)

    本文介绍了一种早期时间分类算法，该算法通过统计框架和校准停止规则实现了对完全分类与早期时间分类之间的准确度间隔的有限样本、分布无关的控制。其主要贡献是提出了一种框架，该框架在累计停止时间的条件下控制了一种更强的错误概念的准确度间隔。

    

    早期时间分类算法旨在在不处理完整输入流的情况下对特征流进行标记，同时保持与应用分类器到整个输入时相当的准确性。在本文中，我们引入了一个可以应用于任何顺序分类器的统计框架，制定了一个校准停止规则。这个数据驱动的规则在完全分类和早期时间分类之间的准确度间隔上获得了有限样本的、分布无关的控制。我们首先提出了一种新颖的方法，借鉴了学习-测试校准框架，在独立同分布实例上对这个间隔进行了平均控制。由于这种算法往往会产生过高的早停时间准确度间隔，我们的主要贡献是提出了一个框架，该框架在累计停止时间的条件下控制了一种更强的错误概念，其中准确度间隔受到控制。数值实验证明了该方法的有效性、适用性和实用性。

    Early time classification algorithms aim to label a stream of features without processing the full input stream, while maintaining accuracy comparable to that achieved by applying the classifier to the entire input. In this paper, we introduce a statistical framework that can be applied to any sequential classifier, formulating a calibrated stopping rule. This data-driven rule attains finite-sample, distribution-free control of the accuracy gap between full and early-time classification. We start by presenting a novel method that builds on the Learn-then-Test calibration framework to control this gap marginally, on average over i.i.d. instances. As this algorithm tends to yield an excessively high accuracy gap for early halt times, our main contribution is the proposal of a framework that controls a stronger notion of error, where the accuracy gap is controlled conditionally on the accumulated halt times. Numerical experiments demonstrate the effectiveness, applicability, and usefulnes
    
[^2]: 基于得分的因果表示学习：线性和一般的转化

    Score-based Causal Representation Learning: Linear and General Transformations

    [https://arxiv.org/abs/2402.00849](https://arxiv.org/abs/2402.00849)

    这篇论文提出了一种基于得分的算法类，用于干预范围内的因果表示学习，涵盖了线性和一般转化。算法保证了可识别性和实现性，并且通过创造性地将得分函数与因果表示学习相结合。

    

    本篇论文针对一般非参数潜在因果模型和将潜在变量映射到观测变量的未知转化，研究了基于干预的因果表示学习（CRL）。研究了线性和一般的转化。这篇论文同时讨论了可识别性和实现性两个方面。可识别性是指确定算法不相关的条件，以确保恢复真实的潜在因果变量和潜在因果图。实现性是指算法方面，解决设计算法来实现可识别保证的问题。通过将得分函数（即密度函数对数的梯度）与CRL之间建立新联系，本文设计了一种得分为基础的算法类，确保了可识别性和实现性。首先，本文专注于线性转化，并展示了每个n个随机硬干预下该转化的因果表示可识别。

    This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the \emph{identifiability} and \emph{achievability} aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between \emph{score functions} (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a \emph{score-based class of algorithms} that ensures both identifiability and achievability. First, the paper focuses on \emph{linear} transformations and shows that one stochastic hard intervention per n
    
[^3]: BootsTAP: 针对Tracking-Any-Point的自举训练

    BootsTAP: Bootstrapped Training for Tracking-Any-Point

    [https://arxiv.org/abs/2402.00847](https://arxiv.org/abs/2402.00847)

    该论文展示了如何通过使用大规模、无标签、未筛选的真实世界数据，以及采用自监督的师生设置，来改进Tracking-Any-Point（TAP）模型的性能。通过在TAP-Vid基准测试上取得了state-of-the-art的结果，该方法在TAP任务上取得了显著的改进。

    

    为了使模型对物理和运动有更深入的理解，让它们能够感知实景中固体表面的移动和变形是很有用的。这可以形式化为Tracking-Any-Point (TAP)，要求算法能够追踪视频中与固体表面对应的任意点，可能是在空间和时间上密集的。目前，TAP需要大规模的真实数据进行训练，但目前只能在模拟环境中获得有限种类的对象和运动。在这项工作中，我们演示了如何使用大规模、无标签、未筛选的真实世界数据，在仅进行最小架构更改的情况下提高TAP模型的性能，采用了自监督的师生设置。我们在TAP-Vid基准测试上展示了超过以往成果的最先进性能：例如，TAP-Vid-DAVIS的性能从61.3%提升到66.4%，TAP-Vid-Kinetics从57.2%提升到61.5%。

    To endow models with greater understanding of physics and motion, it is useful to enable them to perceive how solid surfaces move and deform in real scenes. This can be formalized as Tracking-Any-Point (TAP), which requires the algorithm to be able to track any point corresponding to a solid surface in a video, potentially densely in space and time. Large-scale ground-truth training data for TAP is only available in simulation, which currently has limited variety of objects and motion. In this work, we demonstrate how large-scale, unlabeled, uncurated real-world data can improve a TAP model with minimal architectural changes, using a self-supervised student-teacher setup. We demonstrate state-of-the-art performance on the TAP-Vid benchmark surpassing previous results by a wide margin: for example, TAP-Vid-DAVIS performance improves from 61.3% to 66.4%, and TAP-Vid-Kinetics from 57.2% to 61.5%.
    
[^4]: 《在大规模人工智能时代的贝叶斯深度学习》的立场论文

    Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI

    [https://arxiv.org/abs/2402.00809](https://arxiv.org/abs/2402.00809)

    《在大规模人工智能时代的贝叶斯深度学习》这篇立场论文探讨了贝叶斯深度学习在各种不同设置下的优势，并指出了与之相关的挑战和有趣的研究方向。未来的研究重点将放在如何将大规模基础模型与贝叶斯深度学习相结合，以发挥它们的全部潜力。

    

    在当前的深度学习研究领域中，人们主要关注在涉及大规模图像和语言数据集的监督任务中实现高预测准确性。然而，更广泛的视角揭示了许多被忽视的度量标准、任务和数据类型，如不确定性、主动和持续学习以及科学数据，这些方面需要关注。贝叶斯深度学习（BDL）是一条有前景的道路，可以在这些不同的设置中提供优势。本文认为BDL可以提升深度学习的能力。它重新审视了BDL的优势、承认了现有的挑战，并重点介绍了一些旨在解决这些障碍的有趣的研究方向。展望未来，讨论集中在可能的方式上，将大规模基础模型与BDL相结合，以充分发挥它们的潜力。

    In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.
    
[^5]: 混合量子视觉转换器用于高能物理事件分类

    Hybrid Quantum Vision Transformers for Event Classification in High Energy Physics

    [https://arxiv.org/abs/2402.00776](https://arxiv.org/abs/2402.00776)

    该论文提出了一种基于量子的混合视觉转换器模型，用于高能物理中的事件分类任务。通过减少训练和操作时间，该模型可以达到与经典模型相当的性能。

    

    基于视觉转换器架构的模型被认为是图像分类任务中的最先进技术。然而，它们在训练和部署中都需要大量的计算资源。随着数据的数量和复杂性增加，这个问题变得更加严重。基于量子的视觉转换器模型可能通过减少训练和操作时间来缓解这个问题，同时保持相同的预测能力。尽管当前的量子计算机尚不能执行高维任务，但它们提供了未来最高效的解决方案之一。在这项工作中，我们构建了几种不同的量子混合视觉转换器，用于高能物理中的分类问题（区分电子和光子在电磁量能器中）。我们将它们与经典的视觉转换器架构进行了测试。我们的研究结果表明，混合模型可以达到与经典模型相当的性能。

    Models based on vision transformer architectures are considered state-of-the-art when it comes to image classification tasks. However, they require extensive computational resources both for training and deployment. The problem is exacerbated as the amount and complexity of the data increases. Quantum-based vision transformer models could potentially alleviate this issue by reducing the training and operating time while maintaining the same predictive power. Although current quantum computers are not yet able to perform high-dimensional tasks yet, they do offer one of the most efficient solutions for the future. In this work, we construct several variations of a quantum hybrid vision transformer for a classification problem in high energy physics (distinguishing photons and electrons in the electromagnetic calorimeter). We test them against classical vision transformer architectures. Our findings indicate that the hybrid models can achieve comparable performance to their classical anal
    
[^6]: Transformer的好处：在非结构化数据的线性回归任务中的上下文学习

    Benefits of Transformer: In-Context Learning in Linear Regression Tasks with Unstructured Data

    [https://arxiv.org/abs/2402.00743](https://arxiv.org/abs/2402.00743)

    本研究通过线性回归任务的实验研究了Transformer在非结构化数据中的上下文学习能力，并解释了其中的关键组件。

    

    实践中观察到，基于Transformer的模型在推理阶段能够学习上下文中的概念。现有的文献，例如\citet{zhang2023trained,huang2023context}对这种上下文学习能力提供了理论解释，但是他们假设每个样本的输入$x_i$和输出$y_i$都被嵌入到相同的令牌中（即结构化数据）。然而，在现实中，它们呈现为两个令牌（即非结构化数据\cite{wibisono2023role}）。在这种情况下，本文进行了线性回归任务的实验，研究了Transformer架构的好处，并提供了一些相应的理论直觉，解释了为什么Transformer可以从非结构化数据中学习。我们研究了在Transformer中起到上下文学习作用的确切组件。特别地，我们观察到（1）带有两层softmax（自我）注意力和前瞻性注意力掩码的Transformer可以从提示中学习，如果$y_i$在令牌中。

    In practice, it is observed that transformer-based models can learn concepts in context in the inference stage. While existing literature, e.g., \citet{zhang2023trained,huang2023context}, provide theoretical explanations on this in-context learning ability, they assume the input $x_i$ and the output $y_i$ for each sample are embedded in the same token (i.e., structured data). However, in reality, they are presented in two tokens (i.e., unstructured data \cite{wibisono2023role}). In this case, this paper conducts experiments in linear regression tasks to study the benefits of the architecture of transformers and provides some corresponding theoretical intuitions to explain why the transformer can learn from unstructured data. We study the exact components in a transformer that facilitate the in-context learning. In particular, we observe that (1) a transformer with two layers of softmax (self-)attentions with look-ahead attention mask can learn from the prompt if $y_i$ is in the token n
    
[^7]: 用于高效预测多重性评估的基于Dropout的拉肖蒙集探索

    Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation

    [https://arxiv.org/abs/2402.00728](https://arxiv.org/abs/2402.00728)

    本文提出了一种利用Dropout技术探索拉肖蒙集中模型的新框架，以度量和减轻预测多重性。通过严格的理论推导和广泛的实验评价，结果表明我们的技术始终优于基线模型。

    

    预测多重性是指分类任务可能存在多个竞争模型，它们实现了几乎最优性能，但为单个样本生成了相互冲突的输出。这带来了显著的担忧，因为它可能导致系统性排除、难以解释的歧视和不公平的实际应用。然而，由于需要在可能庞大的假设空间中探索所有这些几乎最优的模型，即拉肖蒙集，度量和减轻预测多重性在计算上具有挑战性。为了应对这一挑战，我们提出了一个利用Dropout技术探索拉肖蒙集中模型的新框架。我们提供了严格的理论推导，将Dropout参数与拉肖蒙集的属性相连接，并通过广泛的实验对我们的框架进行了实证评价。数值结果显示，我们的技术在性能上始终优于基线模型。

    Predictive multiplicity refers to the phenomenon in which classification tasks may admit multiple competing models that achieve almost-equally-optimal performance, yet generate conflicting outputs for individual samples. This presents significant concerns, as it can potentially result in systemic exclusion, inexplicable discrimination, and unfairness in practical applications. Measuring and mitigating predictive multiplicity, however, is computationally challenging due to the need to explore all such almost-equally-optimal models, known as the Rashomon set, in potentially huge hypothesis spaces. To address this challenge, we propose a novel framework that utilizes dropout techniques for exploring models in the Rashomon set. We provide rigorous theoretical derivations to connect the dropout parameters to properties of the Rashomon set, and empirically evaluate our framework through extensive experimentation. Numerical results show that our technique consistently outperforms baselines in
    
[^8]: 光谱变换核回归

    Spectrally Transformed Kernel Regression

    [https://arxiv.org/abs/2402.00645](https://arxiv.org/abs/2402.00645)

    光谱变换核回归是一种能够利用无标签数据的通用和可扩展的方法，具有学习充分平滑函数的能力，并且在感知范式中提供了可扩展的实现。

    

    无标签数据是现代机器学习的关键组成部分。一般来说，无标签数据的作用是通过基础核（如ε-邻居核或图的邻接矩阵）中编码的相似性信息来实现一种平滑性形式。本研究重新审视了光谱变换核回归（STKR）的经典思想，并提供了一类新的通用和可扩展的STKR估计器，能够利用无标签数据。通过光谱变换，STKR利用了无标签数据提供的数据分布的信息。首先，我们证明了STKR是一种原则性和通用性的方法，通过表征一种"目标平滑性"的通用类型，并证明任何充分平滑的函数都可以通过STKR学习。其次，我们提供了可扩展的STKR实现，适用于感知范式，并提供了一般的变换函数，而先前的工作大部分限于推导范式。第三，我们推导出统计属性...

    Unlabeled data is a key component of modern machine learning. In general, the role of unlabeled data is to impose a form of smoothness, usually from the similarity information encoded in a base kernel, such as the $\epsilon$-neighbor kernel or the adjacency matrix of a graph. This work revisits the classical idea of spectrally transformed kernel regression (STKR), and provides a new class of general and scalable STKR estimators able to leverage unlabeled data. Intuitively, via spectral transformation, STKR exploits the data distribution for which unlabeled data can provide additional information. First, we show that STKR is a principled and general approach, by characterizing a universal type of "target smoothness", and proving that any sufficiently smooth function can be learned by STKR. Second, we provide scalable STKR implementations for the inductive setting and a general transformation function, while prior work is mostly limited to the transductive setting. Third, we derive stati
    
[^9]: 基于高斯过程网络的贝叶斯因果推断

    Bayesian Causal Inference with Gaussian Process Networks

    [https://arxiv.org/abs/2402.00623](https://arxiv.org/abs/2402.00623)

    以高斯过程网络为基础，通过模拟干预效果和传播干预效果，进行灵活的贝叶斯因果推断，同时以局部变量为函数估计干预分布并使用加性高斯过程对条件分布进行建模。

    

    从观测数据中进行因果推断和推断是统计学中的一个重要问题，它既涉及建模问题，也涉及计算问题。通常情况下，人们会对联合分布做出严格的假设，如线性性。我们考虑在高斯过程网络（GPN）模型中，对假设干预效果的贝叶斯估计问题，这是一个灵活的因果框架，可以非参数地描述因果关系。我们详细介绍了如何通过在整个网络上模拟干预效果，并在下游变量上传播干预效果来进行GPN的因果推断。我们进一步推导了一个简化的计算近似方法，通过仅将干预分布估计为局部变量的函数，并通过加性高斯过程对条件分布进行建模。我们将这两个框架扩展到了不仅仅是已知因果图的情况下，并引入了对因果结构的不确定性。

    Causal discovery and inference from observational data is an essential problem in statistics posing both modeling and computational challenges. These are typically addressed by imposing strict assumptions on the joint distribution such as linearity. We consider the problem of the Bayesian estimation of the effects of hypothetical interventions in the Gaussian Process Network (GPN) model, a flexible causal framework which allows describing the causal relationships nonparametrically. We detail how to perform causal inference on GPNs by simulating the effect of an intervention across the whole network and propagating the effect of the intervention on downstream variables. We further derive a simpler computational approximation by estimating the intervention distribution as a function of local variables only, modeling the conditional distributions via additive Gaussian processes. We extend both frameworks beyond the case of a known causal graph, incorporating uncertainty about the causal s
    
[^10]: 不确定性感知的部分标签学习

    Uncertainty-Aware Partial-Label Learning

    [https://arxiv.org/abs/2402.00592](https://arxiv.org/abs/2402.00592)

    本文提出了一种基于最近邻的部分标签学习算法，利用Dempster-Shafer理论实现对模糊标记的数据的训练。实验结果表明，该算法能够提供良好的不确定性估计，并具有竞争力的预测性能。

    

    在现实世界的应用中，人们经常遇到标记模糊的数据，即不同的标注者为相同样本分配了冲突的类别标签。部分标签学习允许在这种弱监督的情况下训练分类器。虽然最先进的方法已经具有良好的预测性能，但它们往往受到错误的不确定性估计的影响。然而，在医学和自动驾驶等安全关键领域，具有良好校准的不确定性估计尤为重要。在本文中，我们提出了一种基于最近邻的部分标签学习算法，该算法利用了Dempster-Shafer理论。对人工数据集和实际数据集进行的广泛实验表明，所提出的方法能够提供良好的不确定性估计，并具有竞争力的预测性能。此外，我们还证明了我们的算法具有风险一致性。

    In real-world applications, one often encounters ambiguously labeled data, where different annotators assign conflicting class labels. Partial-label learning allows training classifiers in this weakly supervised setting. While state-of-the-art methods already feature good predictive performance, they often suffer from miscalibrated uncertainty estimates. However, having well-calibrated uncertainty estimates is important, especially in safety-critical domains like medicine and autonomous driving. In this article, we propose a novel nearest-neighbor-based partial-label-learning algorithm that leverages Dempster-Shafer theory. Extensive experiments on artificial and real-world datasets show that the proposed method provides a well-calibrated uncertainty estimate and achieves competitive prediction performance. Additionally, we prove that our algorithm is risk-consistent.
    
[^11]: 理解Transformer在序列建模中的表达能力和机制

    Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling

    [https://arxiv.org/abs/2402.00522](https://arxiv.org/abs/2402.00522)

    本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。

    

    我们对Transformer在长、稀疏和复杂记忆的序列建模中的近似性质进行了系统研究。我们调查了Transformer的不同组件（如点积自注意力、位置编码和前馈层）是如何影响其表达能力的机制，并通过建立明确的近似率来研究它们的综合影响。我们的研究揭示了Transformer中关键参数（如层数和注意力头数）的作用，并且这些洞察还为替代架构提供了自然建议。

    We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.
    
[^12]: 经验风险最小化与f-分布族正则化的等价性

    Equivalence of the Empirical Risk Minimization to Regularization on the Family of f-Divergences

    [https://arxiv.org/abs/2402.00501](https://arxiv.org/abs/2402.00501)

    经验风险最小化与f-分布族的正则化的解决方案在特定条件下是唯一的，并且可以通过使用不同的f-分布正则化等效地表示。

    

    在对f中的温和条件下，给出了经验风险最小化与f-分布的正则化（ERM-$f$DR）的解法。在这些条件下，最优测度被证明是唯一的。并给出了特定选择函数f的解决方案的示例。通过利用f-分布族的灵活性，获得了先前对常见正则化选择的已知解决方案，包括相对熵正则化的唯一解（Type-I和Type-II）。对解的分析揭示了在ERM-$f$DR问题中使用f-分布时的以下属性：$i)$ f-分布正则化强制将解的支持与参考测度的支持重合，引入了在训练数据提供的证据中占主导地位的强归纳偏差；$ii)$ 任何f-分布的正则化都等价于另一种f-分布的正则化。

    The solution to empirical risk minimization with $f$-divergence regularization (ERM-$f$DR) is presented under mild conditions on $f$. Under such conditions, the optimal measure is shown to be unique. Examples of the solution for particular choices of the function $f$ are presented. Previously known solutions to common regularization choices are obtained by leveraging the flexibility of the family of $f$-divergences. These include the unique solutions to empirical risk minimization with relative entropy regularization (Type-I and Type-II). The analysis of the solution unveils the following properties of $f$-divergences when used in the ERM-$f$DR problem: $i\bigl)$ $f$-divergence regularization forces the support of the solution to coincide with the support of the reference measure, which introduces a strong inductive bias that dominates the evidence provided by the training data; and $ii\bigl)$ any $f$-divergence regularization is equivalent to a different $f$-divergence regularization 
    
[^13]: LLMs的高效探索

    Efficient Exploration for LLMs

    [https://arxiv.org/abs/2402.00396](https://arxiv.org/abs/2402.00396)

    高效探索在改善大型语言模型方面具有显著优势，可以以较少的查询实现较高的性能水平。不确定性估计和探索方案的选择是关键因素。

    

    我们提供了证据，表明高效探索在获取人类反馈以改善大型语言模型方面具有显著优势。在我们的实验中，一个代理程序在收到反馈时将奖励模型拟合到查询上。我们表现最佳的代理程序使用双Thompson采样生成查询，不确定性由认知神经网络表示。我们的结果表明，高效探索使得性能水平可以在较少的查询下达到较高水平。此外，不确定性估计和探索方案的选择起着关键作用。

    We present evidence of substantial benefit from efficient exploration in gathering human feedback to improve large language models. In our experiments, an agent sequentially generates queries while fitting a reward model to the feedback received. Our best-performing agent generates queries using double Thompson sampling, with uncertainty represented by an epistemic neural network. Our results demonstrate that efficient exploration enables high levels of performance with far fewer queries. Further, both uncertainty estimation and the choice of exploration scheme play critical roles.
    
[^14]: 基于累积分布函数的通用时间点过程

    Cumulative Distribution Function based General Temporal Point Processes

    [https://arxiv.org/abs/2402.00388](https://arxiv.org/abs/2402.00388)

    本研究引入了CuFun模型，基于累积分布函数的通用时间点过程，解决了深度时间点过程模型中的强度函数建模、积分计算复杂性和长期时序依赖性捕捉的问题。

    

    时间点过程在建模各个领域中的事件序列（包括社交网络和电子商务）中发挥着关键作用，并对推荐系统和信息检索策略的进展做出了重大贡献。通过分析用户交互和交易等事件，时间点过程提供了有价值的行为模式洞察，有助于预测未来的趋势。然而，由于这些模式的复杂性，准确预测未来事件仍然是一个巨大挑战。将神经网络与时间点过程相结合，开发了先进的深度时间点过程模型。虽然这些模型在处理复杂和非线性时间数据方面表现出色，但在建模强度函数、复杂积分计算和有效捕捉长期时序依赖方面存在局限性。在本研究中，我们介绍了CuFun模型，该模型代表了一种新的方法来解决这些问题。

    Temporal Point Processes (TPPs) hold a pivotal role in modeling event sequences across diverse domains, including social networking and e-commerce, and have significantly contributed to the advancement of recommendation systems and information retrieval strategies. Through the analysis of events such as user interactions and transactions, TPPs offer valuable insights into behavioral patterns, facilitating the prediction of future trends. However, accurately forecasting future events remains a formidable challenge due to the intricate nature of these patterns. The integration of Neural Networks with TPPs has ushered in the development of advanced deep TPP models. While these models excel at processing complex and nonlinear temporal data, they encounter limitations in modeling intensity functions, grapple with computational complexities in integral computations, and struggle to capture long-range temporal dependencies effectively. In this study, we introduce the CuFun model, representing
    
[^15]: 关于Lasso设计依赖性的子优问题

    On the design-dependent suboptimality of the Lasso

    [https://arxiv.org/abs/2402.00382](https://arxiv.org/abs/2402.00382)

    本文研究了设计矩阵对Lasso估计器的影响，发现当最小奇异值很小时，Lasso估计器在最小化速率方面是次优的。我们提供了一族设计矩阵和稀疏参数，证明无论正则化参数的选择是数据依赖性的还是随机的，Lasso估计器都会在估计速率上表现出多项式因素的次优性。

    

    本文研究了设计矩阵对线性回归中稀疏参数估计能力（或无能力）的影响。特别地，我们对设计矩阵的最小奇异值远离零时的最优估计速率进行了表征。除了这个信息理论结果，我们还提供并分析了一种同时具有统计最优性和计算效率的过程，该过程基于对普通最小二乘估计器进行软门限。最令人惊讶的是，尽管Lasso估计器被广泛采用用于稀疏线性回归，但我们证明当最小奇异值很小时，Lasso估计器在最小化速率方面是明显次优的。我们提供了一族设计矩阵和稀疏参数，可以保证无论正则化参数的选择是数据依赖性的还是随机的，Lasso估计器都会在估计速率上表现出多项式因素的次优性。

    This paper investigates the effect of the design matrix on the ability (or inability) to estimate a sparse parameter in linear regression. More specifically, we characterize the optimal rate of estimation when the smallest singular value of the design matrix is bounded away from zero. In addition to this information-theoretic result, we provide and analyze a procedure which is simultaneously statistically optimal and computationally efficient, based on soft thresholding the ordinary least squares estimator. Most surprisingly, we show that the Lasso estimator -- despite its widespread adoption for sparse linear regression -- is provably minimax rate-suboptimal when the minimum singular value is small. We present a family of design matrices and sparse parameters for which we can guarantee that the Lasso with any choice of regularization parameter -- including those which are data-dependent and randomized -- would fail in the sense that its estimation rate is suboptimal by polynomial fact
    
[^16]: 比较两层神经网络的谱偏差和鲁棒性：SGD与自适应随机傅里叶特征之间的比较

    Comparing Spectral Bias and Robustness For Two-Layer Neural Networks: SGD vs Adaptive Random Fourier Features

    [https://arxiv.org/abs/2402.00332](https://arxiv.org/abs/2402.00332)

    本研究比较了两种训练算法对于两层神经网络的谱偏差和鲁棒性的影响，结果表明自适应随机傅里叶特征算法（ARFF）可以在谱偏差方面取得更好的结果，并且与随机梯度下降优化器（SGD）相比具有更好的鲁棒性。

    

    我们提出的实验结果突出了选择训练算法对于两层神经网络的两个关键差异。神经网络的谱偏差是众所周知的，而谱偏差与训练算法的选择之间的关系很少被研究。我们的实验表明，相比于随机梯度下降优化器（SGD），自适应随机傅里叶特征算法（ARFF）可以产生更接近零的谱偏差。此外，我们使用SGD和ARFF训练了两个完全相同结构的分类器，将它们的准确性提高到相同水平，并经验性地评估了它们对抗噪声攻击的鲁棒性。

    We present experimental results highlighting two key differences resulting from the choice of training algorithm for two-layer neural networks. The spectral bias of neural networks is well known, while the spectral bias dependence on the choice of training algorithm is less studied. Our experiments demonstrate that an adaptive random Fourier features algorithm (ARFF) can yield a spectral bias closer to zero compared to the stochastic gradient descent optimizer (SGD). Additionally, we train two identically structured classifiers, employing SGD and ARFF, to the same accuracy levels and empirically assess their robustness against adversarial noise attacks.
    
[^17]: 信息论阈值对于种植的稠密环路的研究

    Information-Theoretic Thresholds for Planted Dense Cycles

    [https://arxiv.org/abs/2402.00305](https://arxiv.org/abs/2402.00305)

    本论文研究了一种小世界网络的随机图模型，在这个模型中，通过信息论阈值来刻画种植的稠密环路的检测和恢复问题，这与之前基于计算阈值的研究结果不同，揭示了统计与计算之间的差距。

    

    我们研究了一种用于社会和生物科学中无处不在的小世界网络的随机图模型。在这个模型中，预期带宽为$n \tau$的密集环路，代表了顶点之间隐藏的一维几何关系，种植在了一个包含$n$个顶点的随机图中。针对种植的稠密环路的检测和恢复，我们以$n$、$\tau$和边缘信噪比$\lambda$为参数，刻画了信息论阈值。特别地，这些信息论阈值与最近一个基于低次多项式算法的计算阈值不同，从而证明了该问题存在统计与计算之间的差距。

    We study a random graph model for small-world networks which are ubiquitous in social and biological sciences. In this model, a dense cycle of expected bandwidth $n \tau$, representing the hidden one-dimensional geometry of vertices, is planted in an ambient random graph on $n$ vertices. For both detection and recovery of the planted dense cycle, we characterize the information-theoretic thresholds in terms of $n$, $\tau$, and an edge-wise signal-to-noise ratio $\lambda$. In particular, the information-theoretic thresholds differ from the computational thresholds established in a recent work for low-degree polynomial algorithms, thereby justifying the existence of statistical-to-computational gaps for this problem.
    
[^18]: 并非所有可学习的分布类都能在差分隐私下进行学习

    Not All Learnable Distribution Classes are Privately Learnable

    [https://arxiv.org/abs/2402.00267](https://arxiv.org/abs/2402.00267)

    这篇论文证明了一类分布虽然可以在有限样本下以总变差距离进行学习，但却无法在（ε，δ）-差分隐私下学习。

    

    我们给出了一个示例，展示了一类分布在有限样本下可以以总变差距离进行学习，但在（ε，δ）-差分隐私下无法学习。这推翻了Ashtiani的一个猜想。

    We give an example of a class of distributions that is learnable in total variation distance with a finite number of samples, but not learnable under $(\varepsilon, \delta)$-differential privacy. This refutes a conjecture of Ashtiani.
    
[^19]: 使用替代结果进行连续治疗效果研究

    Continuous Treatment Effects with Surrogate Outcomes

    [https://arxiv.org/abs/2402.00168](https://arxiv.org/abs/2402.00168)

    本文研究了在部分缺失主要结果的情况下，使用替代结果来估计连续治疗效果，并提出了一种双重稳健方法，通过使用标记和未标记数据，可以有效地纳入替代结果并避免选择偏误问题。该方法的估计值渐近正态性，并在方差方面可能比仅使用标记数据的方法有所改进。模拟实验证明了该方法的良好实证性能。

    

    在许多实际因果推断应用中，主要结果（标签）常常是部分缺失的，特别是如果它们很昂贵或很难收集。如果缺失依赖于协变量（即缺失不完全随机），仅基于完全观测样本的分析可能存在偏误。在这种情况下，结合与主要结果相关的完全观测的治疗后变量（替代结果）可以改进估计。在本文中，我们研究了替代结果在估计连续治疗效果中的作用，并提出了一种双重稳健方法，以高效地将替代结果纳入分析中，该方法使用了标记和未标记数据，并且不会受到上述选择偏误问题的影响。重要的是，我们建立了所提估计器的渐近正态性，并展示了与仅使用标记数据的方法相比，方差的可能改进。广泛的模拟显示我们的方法具有吸引人的经验性能。

    In many real-world causal inference applications, the primary outcomes (labels) are often partially missing, especially if they are expensive or difficult to collect. If the missingness depends on covariates (i.e., missingness is not completely at random), analyses based on fully-observed samples alone may be biased. Incorporating surrogates, which are fully observed post-treatment variables related to the primary outcome, can improve estimation in this case. In this paper, we study the role of surrogates in estimating continuous treatment effects and propose a doubly robust method to efficiently incorporate surrogates in the analysis, which uses both labeled and unlabeled data and does not suffer from the above selection bias problem. Importantly, we establish asymptotic normality of the proposed estimator and show possible improvements on the variance compared with methods that solely use labeled data. Extensive simulations show our methods enjoy appealing empirical performance.
    
[^20]: 政策梯度探索背后的神话

    Behind the Myth of Exploration in Policy Gradients

    [https://arxiv.org/abs/2402.00162](https://arxiv.org/abs/2402.00162)

    本论文提出了对政策梯度算法中探索项的新分析方法，区分了其平滑学习目标和增加梯度估计的两种不同作用。同时，详细讨论和实证了基于熵奖励的探索策略的局限性，并开辟了未来对这些策略设计和分析的研究方向。

    

    政策梯度算法是解决具有连续状态和动作空间的控制问题的有效强化学习方法。为了计算接近最优的策略，在实践中必须在学习目标中包含探索项。尽管这些项的有效性通常通过对探索环境的内在需求进行证明，但我们提出了一种新的分析方法，区分了这些技术的两种不同含义。首先，它们使得平滑学习目标成为可能，并在保持全局最大值的同时消除了局部最优解。其次，它们修改了梯度估计，增加了随机参数更新最终提供最优策略的概率。基于这些效应，我们讨论并实证了基于熵奖励的探索策略，突出了其局限性，并为设计和分析这些策略的未来研究开辟了新方向。

    Policy-gradient algorithms are effective reinforcement learning methods for solving control problems with continuous state and action spaces. To compute near-optimal policies, it is essential in practice to include exploration terms in the learning objective. Although the effectiveness of these terms is usually justified by an intrinsic need to explore environments, we propose a novel analysis and distinguish two different implications of these techniques. First, they make it possible to smooth the learning objective and to eliminate local optima while preserving the global maximum. Second, they modify the gradient estimates, increasing the probability that the stochastic parameter update eventually provides an optimal policy. In light of these effects, we discuss and illustrate empirically exploration strategies based on entropy bonuses, highlighting their limitations and opening avenues for future works in the design and analysis of such strategies.
    
[^21]: 更深还是更宽: 从Sobolev损失的最优泛化误差角度看

    Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss

    [https://arxiv.org/abs/2402.00152](https://arxiv.org/abs/2402.00152)

    本文比较了更深的神经网络和更宽的神经网络在Sobolev损失的最优泛化误差方面的表现，研究发现神经网络的架构受多种因素影响，参数数量更多倾向于选择更宽的网络，而样本点数量和损失函数规则性更高倾向于选择更深的网络。

    

    构建神经网络的架构是机器学习界一个具有挑战性的追求，到底是更深还是更宽一直是一个持续的问题。本文探索了更深的神经网络（DeNNs）和具有有限隐藏层的更宽的神经网络（WeNNs）在Sobolev损失的最优泛化误差方面的比较。通过分析研究发现，神经网络的架构可以受到多种因素的显著影响，包括样本点的数量，神经网络内的参数以及损失函数的规则性。具体而言，更多的参数倾向于选择WeNNs，而更多的样本点和更高的损失函数规则性倾向于选择DeNNs。最后，我们将这个理论应用于使用深度Ritz和物理感知神经网络（PINN）方法解决偏微分方程的问题。

    Constructing the architecture of a neural network is a challenging pursuit for the machine learning community, and the dilemma of whether to go deeper or wider remains a persistent question. This paper explores a comparison between deeper neural networks (DeNNs) with a flexible number of layers and wider neural networks (WeNNs) with limited hidden layers, focusing on their optimal generalization error in Sobolev losses. Analytical investigations reveal that the architecture of a neural network can be significantly influenced by various factors, including the number of sample points, parameters within the neural networks, and the regularity of the loss function. Specifically, a higher number of parameters tends to favor WeNNs, while an increased number of sample points and greater regularity in the loss function lean towards the adoption of DeNNs. We ultimately apply this theory to address partial differential equations using deep Ritz and physics-informed neural network (PINN) methods,
    
[^22]: 可解释的人工智能用于生存分析：一种中位数-SHAP方法

    Explainable AI for survival analysis: a median-SHAP approach

    [https://arxiv.org/abs/2402.00072](https://arxiv.org/abs/2402.00072)

    这项研究介绍了一种中位数-SHAP方法，用于解释黑盒子模型在预测个体生存时间方面产生的解释偏差问题。

    

    随着机器学习在临床实践中的应用，对于医疗应用来说，需要针对性的可解释的人工智能方法。Shapley值在局部解释模型方面引起了广泛关注。在这里，我们展示了Shapley值的解释性强烈依赖于摘要统计量和估计量，这些统计量和估计量定义了我们所认为的“锚点”。我们表明，使用均值锚点的惯例可能在生存分析中产生误导性的解释，并引入了一种称为中位数-SHAP的方法，用于解释预测个体生存时间的黑盒子模型。

    With the adoption of machine learning into routine clinical practice comes the need for Explainable AI methods tailored to medical applications. Shapley values have sparked wide interest for locally explaining models. Here, we demonstrate their interpretation strongly depends on both the summary statistic and the estimator for it, which in turn define what we identify as an 'anchor point'. We show that the convention of using a mean anchor point may generate misleading interpretations for survival analysis and introduce median-SHAP, a method for explaining black-box models predicting individual survival times.
    
[^23]: 通过无交并的泛深度比较机器学习算法

    Comparing Machine Learning Algorithms by Union-Free Generic Depth

    [https://arxiv.org/abs/2312.12839](https://arxiv.org/abs/2312.12839)

    本研究提出了一种描述性分析偏序集合的框架，通过改进的无交并泛深度 (ufg) 比较机器学习算法，并在标准基准数据集上提供了示例。研究结果展示了基于ufg方法的多样性分析方法，并与现有的基准测试方法有很大区别。

    

    我们提出了一个基于深度函数概念的描述性分析偏序集合的框架。尽管线性空间和度量空间的研究非常深入，但关于偏序集合等非标准数据类型的深度函数的讨论几乎没有。我们介绍了一种适用于所有偏序集合的著名简单深度的改进版本，无交并泛深度 (ufg)。此外，我们利用我们的ufg深度来比较基于多维性能指标的机器学习算法。具体而言，我们提供了两个示例，对标准基准数据集的分类器比较。我们的结果有希望地展示了基于ufg方法的不同分析方法的广泛多样性。此外，这些示例说明了我们的方法与现有的基准测试方法有很大区别，因此为分类器比较的热烈讨论增添了新的视角。

    We propose a framework for descriptively analyzing sets of partial orders based on the concept of depth functions. Despite intensive studies in linear and metric spaces, there is very little discussion on depth functions for non-standard data types such as partial orders. We introduce an adaptation of the well-known simplicial depth to the set of all partial orders, the union-free generic (ufg) depth. Moreover, we utilize our ufg depth for a comparison of machine learning algorithms based on multidimensional performance measures. Concretely, we provide two examples of classifier comparisons on samples of standard benchmark data sets. Our results demonstrate promisingly the wide variety of different analysis approaches based on ufg methods. Furthermore, the examples outline that our approach differs substantially from existing benchmarking approaches, and thus adds a new perspective to the vivid debate on classifier comparison.
    
[^24]: 几何感知的归一化Wasserstein流在最优因果推断中的应用

    Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal Inference

    [https://arxiv.org/abs/2311.18826](https://arxiv.org/abs/2311.18826)

    本文提出了一种几何感知的归一化Wasserstein流的方法，通过整合连续归一化流（CNFs）和参数子模型，优化了因果推断的表现，并在最优传输理论中提高了鲁棒性。

    

    本文通过将连续归一化流（CNFs）与参数子模型相结合，提出了一种突破性的因果推断方法，增强了它们对几何敏感性，并改进了传统的目标最大似然估计（TMLE）。我们的方法利用CNFs改进TMLE，优化Cram\'er-Rao界限，并从预定义分布$p_0$过渡到数据驱动的分布$p_1$。我们进一步创新地将Wasserstein梯度流嵌入到Fokker-Planck方程中，从而在最优传输理论中添加了几何结构，提高了CNFs的鲁棒性。

    This paper presents a groundbreaking approach to causal inference by integrating continuous normalizing flows (CNFs) with parametric submodels, enhancing their geometric sensitivity and improving upon traditional Targeted Maximum Likelihood Estimation (TMLE). Our method employs CNFs to refine TMLE, optimizing the Cram\'er-Rao bound and transitioning from a predefined distribution $p_0$ to a data-driven distribution $p_1$. We innovate further by embedding Wasserstein gradient flows within Fokker-Planck equations, thus imposing geometric structures that boost the robustness of CNFs, particularly in optimal transport theory.   Our approach addresses the disparity between sample and population distributions, a critical factor in parameter estimation bias. We leverage optimal transport and Wasserstein gradient flows to develop causal inference methodologies with minimal variance in finite-sample settings, outperforming traditional methods like TMLE and AIPW. This novel framework, centered o
    
[^25]: 基于非线性偏微分方程的高斯过程参数推断

    Parameter Inference based on Gaussian Processes Informed by Nonlinear Partial Differential Equations

    [https://arxiv.org/abs/2212.11880](https://arxiv.org/abs/2212.11880)

    本文提出了一种基于PDE信息的高斯过程（PIGP）的参数推断方法，通过将PDE解建模为高斯过程，利用PDE结构引起的约束条件来推断未知参数。

    

    偏微分方程广泛用于描述物理和工程现象。PDE中涉及的一些关键参数代表具有重要科学解释的特定物理性质，直接测量这些参数是困难甚至不可能的。从与相关物理量的嘈杂和稀疏实验数据中估计这些参数是一项重要任务。许多PDE参数推断方法涉及通过有限元方法等算法对PDE的数值解进行大量评估，这可能非常耗时，特别是对于非线性PDE。在本文中，我们提出了一种新颖的PDE中未知参数推断方法，称为基于PDE信息的高斯过程（PIGP）基于参数推断方法。通过将PDE解建模为高斯过程（GP），我们得到了（线性）PDE结构引起的流形约束，使得在约束条件下，GP满足PDE。

    Partial differential equations (PDEs) are widely used for the description of physical and engineering phenomena. Some key parameters involved in PDEs, which represent certain physical properties with important scientific interpretations, are difficult or even impossible to measure directly. Estimating these parameters from noisy and sparse experimental data of related physical quantities is an important task. Many methods for PDE parameter inference involve a large number of evaluations for numerical solutions to PDE through algorithms such as the finite element method, which can be time-consuming, especially for nonlinear PDEs. In this paper, we propose a novel method for the inference of unknown parameters in PDEs, called the PDE-Informed Gaussian Process (PIGP) based parameter inference method. Through modeling the PDE solution as a Gaussian process (GP), we derive the manifold constraints induced by the (linear) PDE structure such that, under the constraints, the GP satisfies the P
    
[^26]: 前馈潜在领域自适应

    Feed-Forward Latent Domain Adaptation

    [https://arxiv.org/abs/2207.07624](https://arxiv.org/abs/2207.07624)

    本文研究了前馈潜在领域自适应的问题，提出了一种通过元学习和交叉注意力实现动态适应的方法，该方法在资源受限的边缘设备上取得了一致的改进。

    

    我们研究了一种新的高度实用的问题设置，使资源受限的边缘设备能够适应其本地数据分布的预训练模型。认识到设备的数据很可能来自包含混合未标记的领域相关和领域不相关示例的多个潜在领域，我们专注于相对较少研究的潜在领域自适应问题。考虑到边缘设备的局限性，我们目标是仅使用预训练模型，并以前馈方式进行适应，而无需使用反向传播和无需访问源数据。建模这些现实约束将我们带到前馈潜在领域自适应的新颖和实用重要的问题设置。我们的解决方案是元学习一个网络，能够将混合相关目标数据集嵌入，并使用交叉注意力动态地适应目标示例的推理。所得到的框架相对于强ERM基线方法能够持续改进。

    We study a new highly-practical problem setting that enables resource-constrained edge devices to adapt a pre-trained model to their local data distributions. Recognizing that device's data are likely to come from multiple latent domains that include a mixture of unlabelled domain-relevant and domain-irrelevant examples, we focus on the comparatively under-studied problem of latent domain adaptation. Considering limitations of edge devices, we aim to only use a pre-trained model and adapt it in a feed-forward way, without using back-propagation and without access to the source data. Modelling these realistic constraints bring us to the novel and practically important problem setting of feed-forward latent domain adaptation. Our solution is to meta-learn a network capable of embedding the mixed-relevance target dataset and dynamically adapting inference for target examples using cross-attention. The resulting framework leads to consistent improvements over strong ERM baselines. We also 
    
[^27]: 图上的协同似然比估计

    Collaborative likelihood-ratio estimation over graphs

    [https://arxiv.org/abs/2205.14461](https://arxiv.org/abs/2205.14461)

    该论文提出了基于图的协同似然比估计方法，通过考虑图结构信息，估计每个节点间的似然比，节点可以协作来更高效地解决问题。

    

    假设我们有来自两个未知概率密度函数 (pdfs) p 和 q 的独立同分布的观测值，似然比估计（LRE）是一种优雅的方法，只依靠现有数据来比较这两个概率密度函数。在本文中，我们介绍了目前为止首个基于图的扩展问题，其假设固定图的每个节点 v 都可以访问来自两个未知节点特定概率密度函数 p_v 和 q_v 的观测值，并且目标是通过同时考虑图结构提供的信息来估计每个节点之间的似然比。节点级别的估计任务应该展现出图传递的相似性，这暗示着节点可以协作来更有效地解决它们。我们以一个具体的非参数方法 GRULSIF 来开发这个想法。我们推导了我们方法的收敛速度。

    Assuming we have iid observations from two unknown probability density functions (pdfs), $p$ and $q$, the likelihood-ratio estimation (LRE) is an elegant approach to compare the two pdfs only by relying on the available data. In this paper, we introduce the first -to the best of our knowledge-graph-based extension of this problem, which reads as follows: Suppose each node $v$ of a fixed graph has access to observations coming from two unknown node-specific pdfs, $p_v$ and $q_v$, and the goal is to estimate for each node the likelihood-ratio between both pdfs by also taking into account the information provided by the graph structure. The node-level estimation tasks are supposed to exhibit similarities conveyed by the graph, which suggests that the nodes could collaborate to solve them more efficiently. We develop this idea in a concrete non-parametric method that we call Graph-based Relative Unconstrained Least-squares Importance Fitting (GRULSIF). We derive convergence rates for our c
    
[^28]: 对对抗训练中过度参数化的诅咒：随机特征回归的鲁棒泛化的精确分析

    The curse of overparametrization in adversarial training: Precise analysis of robust generalization for random features regression

    [https://arxiv.org/abs/2201.05149](https://arxiv.org/abs/2201.05149)

    本文精确分析了对对抗训练中过度参数化的影响，发现过度参数化模型对微小对抗扰动非常脆弱，显示了鲁棒泛化的性能明显差于标准泛化的性能。

    

    成功的深度学习模型通常涉及训练神经网络架构，其参数数量超过训练样本的数量。过度参数化模型在最近几年中得到了广泛研究，过度参数化的优点从统计学角度（通过双下降现象）和计算角度（通过优化景观的结构特性）已经得到建立。尽管过度参数化的深度学习架构取得了显著的成功，但众所周知，这些模型对其输入中的微小对抗扰动非常脆弱。即使在经过对抗训练的情况下，它们在被扰动的输入上的性能（鲁棒泛化）也明显比在良性输入上的最佳性能（标准泛化）要差。因此，了解过度参数化如何从根本上影响鲁棒性至关重要。

    Successful deep learning models often involve training neural network architectures that contain more parameters than the number of training samples. Such overparametrized models have been extensively studied in recent years, and the virtues of overparametrization have been established from both the statistical perspective, via the double-descent phenomenon, and the computational perspective via the structural properties of the optimization landscape.   Despite the remarkable success of deep learning architectures in the overparametrized regime, it is also well known that these models are highly vulnerable to small adversarial perturbations in their inputs. Even when adversarially trained, their performance on perturbed inputs (robust generalization) is considerably worse than their best attainable performance on benign inputs (standard generalization). It is thus imperative to understand how overparametrization fundamentally affects robustness.   In this paper, we will provide a preci
    
[^29]: 概率生成函数核在球面数据中的应用

    Probability-Generating Function Kernels for Spherical Data

    [https://arxiv.org/abs/2112.00365](https://arxiv.org/abs/2112.00365)

    该论文介绍了一种在球面数据分析中应用的概率生成函数核，扩展了RBF核并引入了半参数学习算法。

    

    引入概率生成函数（PGF）核，构成了一类在单位超球上支持的核，用于球面数据分析。PGF核在球面数据的背景下推广了RBF核。研究了PGF核的特性。引入了半参数学习算法，使得可以在球面数据中使用PGF核。

    Probability-generating function (PGF) kernels are introduced, which constitute a class of kernels supported on the unit hypersphere, for the purposes of spherical data analysis. PGF kernels generalize RBF kernels in the context of spherical data. The properties of PGF kernels are studied. A semi-parametric learning algorithm is introduced to enable the use of PGF kernels with spherical data.
    
[^30]: 基于矩阵值时间序列的在线图拓扑学习

    Online Graph Topology Learning from Matrix-valued Time Series

    [https://arxiv.org/abs/2107.08020](https://arxiv.org/abs/2107.08020)

    本文通过研究矩阵值时间序列的统计分析，提出了在线图拓扑学习的方法。首先，将VAR模型扩展为矩阵变量模型以适用于图形学习。其次，提出了两种在线过程，针对低维和高维情况快速更新系数的估计。这些方法在高维情况下引入了一种新的Lasso-type进行拓扑处理。

    

    本文研究了矩阵值时间序列的统计分析。这些数据是在一个传感器网络上收集的（通常是一组空间位置），观测到每个传感器的每个时间点的特征向量。因此，每个传感器由一个向量时序列来描述。我们希望识别这些传感器之间的依赖结构，并用图形来表示它。当每个传感器只有一个特征时，矢量自回归模型已被广泛应用于推断格兰杰因果关系的结构。所得到的图被称为因果图。我们的第一个贡献是将VAR模型扩展为矩阵变量模型，以用于图形学习的目的。其次，我们提出了两种在线过程，分别适用于低维和高维情况，在新样本到达时可以快速更新系数的估计。特别是在高维情况下，引入了一种新的Lasso-type，并对其进行了拓扑处理。

    This paper is concerned with the statistical analysis of matrix-valued time series. These are data collected over a network of sensors (typically a set of spatial locations) along time, where a vector of features is observed per time instant per sensor. Thus each sensor is characterized by a vectorial time series. We would like to identify the dependency structure among these sensors and represent it by a graph. When there is only one feature per sensor, the vector auto-regressive models have been widely adapted to infer the structure of Granger causality. The resulting graph is referred to as causal graph. Our first contribution is then extending VAR models to matrix-variate models to serve the purpose of graph learning. Secondly, we propose two online procedures respectively in low and high dimensions, which can update quickly the estimates of coefficients when new samples arrive. In particular in high dimensional regime, a novel Lasso-type is introduced and we develop its homotopy a
    
[^31]: 使用共享神经元的RBF网络估计个体化多治疗反应曲线

    Individualized Multi-Treatment Response Curves Estimation using RBF-net with Shared Neurons. (arXiv:2401.16571v1 [stat.ME])

    [http://arxiv.org/abs/2401.16571](http://arxiv.org/abs/2401.16571)

    我们提出了一种使用共享神经元的RBF网络的非参数化治疗效应估计方法，适用于多治疗设置。该方法能够建模治疗结果的共同性，并在贝叶斯框架下实现估计和推断，通过模拟实验证明了其数值性能，应用于真实临床数据后也得到了有趣的发现。

    

    异质治疗效应估计是精确医学中的一个重要问题。我们的研究兴趣在于基于一些外部协变量，确定不同治疗方式的差异效应。我们提出了一种新颖的非参数化治疗效应估计方法，适用于多治疗设置。我们对响应曲线的非参数建模依赖于带有共享隐藏神经元的径向基函数（RBF）网络。因此，我们的模型有助于建模治疗结果的共同性。我们在贝叶斯框架下开发了估计和推断方案，并通过高效的马尔科夫链蒙特卡罗算法进行实现，适当地处理了分析各个方面的不确定性。通过模拟实验，展示了该方法的数值性能。将我们提出的方法应用于MIMIC数据后，我们得到了关于不同治疗策略对ICU住院时间和12小时SOFA评分的影响的一些有趣发现。

    Heterogeneous treatment effect estimation is an important problem in precision medicine. Specific interests lie in identifying the differential effect of different treatments based on some external covariates. We propose a novel non-parametric treatment effect estimation method in a multi-treatment setting. Our non-parametric modeling of the response curves relies on radial basis function (RBF)-nets with shared hidden neurons. Our model thus facilitates modeling commonality among the treatment outcomes. The estimation and inference schemes are developed under a Bayesian framework and implemented via an efficient Markov chain Monte Carlo algorithm, appropriately accommodating uncertainty in all aspects of the analysis. The numerical performance of the method is demonstrated through simulation experiments. Applying our proposed method to MIMIC data, we obtain several interesting findings related to the impact of different treatment strategies on the length of ICU stay and 12-hour SOFA sc
    
[^32]: 一种多级对称微分方程模型用于学习蛋白质-配体结合动力学

    A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics. (arXiv:2401.15122v1 [cs.LG])

    [http://arxiv.org/abs/2401.15122](http://arxiv.org/abs/2401.15122)

    提出了一种能够促进数值MD模拟并有效模拟蛋白质-配体结合动力学的NeuralMD方法，采用物理信息多级对称框架，实现了准确建模多级蛋白质-配体相互作用。

    

    在药物发现中，蛋白质-配体结合的分子动力学（MD）模拟提供了一种强大的工具，用于预测结合亲和力，估计运输性能和探索口袋位点。通过改进数值方法以及最近通过机器学习（ML）方法增强MD模拟的效率已经有了很长的历史。然而，仍然存在一些挑战，例如准确建模扩展时间尺度的模拟。为了解决这个问题，我们提出了NeuralMD，这是第一个能够促进数值MD并提供准确的蛋白质-配体结合动力学模拟的ML辅助工具。我们提出了一个合理的方法，将一种新的物理信息多级对称框架纳入模型中。具体而言，我们提出了（1）一个使用向量框架满足群对称性并捕获多级蛋白质-配体相互作用的BindingNet模型，以及（2）一个增强的神经微分方程求解器，学习轨迹的演化。

    In drug discovery, molecular dynamics (MD) simulation for protein-ligand binding provides a powerful tool for predicting binding affinities, estimating transport properties, and exploring pocket sites. There has been a long history of improving the efficiency of MD simulations through better numerical methods and, more recently, by augmenting them with machine learning (ML) methods. Yet, challenges remain, such as accurate modeling of extended-timescale simulations. To address this issue, we propose NeuralMD, the first ML surrogate that can facilitate numerical MD and provide accurate simulations of protein-ligand binding dynamics. We propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) a BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural differential equation solver that learns the trajectory und
    
[^33]: 《规范预测集提升人类决策能力》

    Conformal Prediction Sets Improve Human Decision Making. (arXiv:2401.13744v1 [cs.LG])

    [http://arxiv.org/abs/2401.13744](http://arxiv.org/abs/2401.13744)

    该研究表明，通过规范预测量化模型的不确定性，可以提高人类决策的准确性和效果，对人机协同决策具有实用价值。

    

    作为对日常查询的回应，人类明确地表达不确定性，并在不确定的情况下提供替代答案。通过规范预测输出校准的预测集，模仿了人类的这种行为；更大的预测集表示更大的不确定性，同时提供了替代方案。在这项工作中，我们通过实施预注册的随机对照试验，并给人类受试者提供规范预测集，研究了规范预测集对人类决策的实用性。通过统计学显著性，我们发现当人类获得规范预测集时，他们在任务上的准确性比使用相同覆盖保证的固定尺寸预测集时有所提高。结果表明，用规范预测量化模型的不确定性有助于人机协同决策和人工智能团队的决策。

    In response to everyday queries, humans explicitly signal uncertainty and offer alternative answers when they are unsure. Machine learning models that output calibrated prediction sets through conformal prediction mimic this human behaviour; larger sets signal greater uncertainty while providing alternatives. In this work, we study the usefulness of conformal prediction sets as an aid for human decision making by conducting a pre-registered randomized controlled trial with conformal prediction sets provided to human subjects. With statistical significance, we find that when humans are given conformal prediction sets their accuracy on tasks improves compared to fixed-size prediction sets with the same coverage guarantee. The results show that quantifying model uncertainty with conformal prediction is helpful for human-in-the-loop decision making and human-AI teams.
    
[^34]: 隐式流形高斯过程回归

    Implicit Manifold Gaussian Process Regression. (arXiv:2310.19390v1 [stat.ML])

    [http://arxiv.org/abs/2310.19390](http://arxiv.org/abs/2310.19390)

    本文提出了一种能够从数据中直接推断隐式结构的高斯过程回归技术，能够处理高维数据，并可能改善预测性能和校准。

    

    高斯过程回归因其能够提供良好校准的不确定性估计和处理小型或稀疏数据集的能力而被广泛应用。然而，对于高维数据，它存在一定困难。一种将这种技术扩展到更高维度的可能途径是利用数据实际所处的隐式低维流形，这是流形假设所假定的。先前的工作通常要求显式提供流形结构，即由网格或已知为众所周知的流形之一（如球体）给出。相比之下，在本文中，我们提出了一种能够以完全可微的方式从数据（标记和未标记的）中推断出隐式结构的高斯过程回归技术。对于得到的模型，我们讨论了其在假设流形上收敛于Matérn高斯过程。我们的技术可扩展到数十万个数据点，并且可能改善预测性能和校准。

    Gaussian process regression is widely used because of its ability to provide well-calibrated uncertainty estimates and handle small or sparse datasets. However, it struggles with high-dimensional data. One possible way to scale this technique to higher dimensions is to leverage the implicit low-dimensional manifold upon which the data actually lies, as postulated by the manifold hypothesis. Prior work ordinarily requires the manifold structure to be explicitly provided though, i.e. given by a mesh or be known to be one of the well-known manifolds like the sphere. In contrast, in this paper we propose a Gaussian process regression technique capable of inferring implicit structure directly from data (labeled and unlabeled) in a fully differentiable way. For the resulting model, we discuss its convergence to the Mat\'ern Gaussian process on the assumed manifold. Our technique scales up to hundreds of thousands of data points, and may improve the predictive performance and calibration of t
    
[^35]: 随机梯度下降的噪声几何：定量和分析特征的研究

    The Noise Geometry of Stochastic Gradient Descent: A Quantitative and Analytical Characterization. (arXiv:2310.00692v1 [cs.LG])

    [http://arxiv.org/abs/2310.00692](http://arxiv.org/abs/2310.00692)

    本文对随机梯度下降（SGD）中的噪声几何进行了全面的理论研究，发现噪声与损失函数的局部几何特征有利的一致性。通过实验证明，SGD在逃脱尖锐极小值时与GD形成鲜明对比，逃脱方向在平坦方向上有显著分量。

    

    实证研究表明，随机梯度下降（SGD）中的噪声与损失函数的局部几何特征有利的一致性。然而，对于这种现象的理论和定量解释仍然不足。本文对过参数化线性模型和两层神经网络的上述“噪声几何”进行了全面的理论研究。我们细致地研究了平均和方向的一致性，特别关注样本大小和输入数据退化对一致性强度的影响。作为特定应用，我们利用噪声几何特征研究了SGD如何从尖锐极小值中逃脱，发现逃脱方向在平坦方向上有显著分量，这与只在最尖锐方向逃脱的梯度下降方法GD形成鲜明对比。为了验证我们的理论发现，我们进行了合成和真实世界的实验。

    Empirical studies have demonstrated that the noise in stochastic gradient descent (SGD) aligns favorably with the local geometry of loss landscape. However, theoretical and quantitative explanations for this phenomenon remain sparse. In this paper, we offer a comprehensive theoretical investigation into the aforementioned {\em noise geometry} for over-parameterized linear (OLMs) models and two-layer neural networks. We scrutinize both average and directional alignments, paying special attention to how factors like sample size and input data degeneracy affect the alignment strength. As a specific application, we leverage our noise geometry characterizations to study how SGD escapes from sharp minima, revealing that the escape direction has significant components along flat directions. This is in stark contrast to GD, which escapes only along the sharpest directions. To substantiate our theoretical findings, both synthetic and real-world experiments are provided.
    
[^36]: 使用传感器数据、方程和自然语言提示上下文中的运算符学习

    Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language. (arXiv:2308.05061v1 [cs.LG])

    [http://arxiv.org/abs/2308.05061](http://arxiv.org/abs/2308.05061)

    本文提出了一种使用传感器数据、方程和自然语言提示上下文中运算符学习的方法。通过整合人类知识和语言描述，该方法不仅扩展了物理信息学习的灵活性和普适性，而且显著提高了学习性能和减少了数据需求。

    

    在科学机器学习领域中，上下文中的运算符学习已经展示出了在推理阶段从提示数据中学习运算符的显著潜力，而无需进行权重更新。然而，当前模型对传感器数据的过度依赖可能会无意中忽视运算符的宝贵的人类洞察力。为了解决这个问题，我们将上下文中的运算符学习转化为一种多模式范式。我们提出使用“标题”来整合通过自然语言描述和方程式表达的运算符的人类知识。我们演示了这种方法不仅扩展了物理信息学习的灵活性和普遍性，而且还显著提高了学习性能并减少了数据需求。此外，我们引入了一种更高效的多模式上下文运算符学习的神经网络架构，称为“ICON-LM”，基于类似于语言模型的架构。

    In the growing domain of scientific machine learning, in-context operator learning has demonstrated notable potential in learning operators from prompted data during inference stage without weight updates. However, the current model's overdependence on sensor data, may inadvertently overlook the invaluable human insight into the operator. To address this, we present a transformation of in-context operator learning into a multi-modal paradigm. We propose the use of "captions" to integrate human knowledge about the operator, expressed through natural language descriptions and equations. We illustrate how this method not only broadens the flexibility and generality of physics-informed learning, but also significantly boosts learning performance and reduces data needs. Furthermore, we introduce a more efficient neural network architecture for multi-modal in-context operator learning, referred to as "ICON-LM", based on a language-model-like architecture. We demonstrate the viability of "ICO
    
[^37]: 腐败鲁棒的Lipschitz上下文搜索

    Corruption-Robust Lipschitz Contextual Search. (arXiv:2307.13903v1 [cs.LG])

    [http://arxiv.org/abs/2307.13903](http://arxiv.org/abs/2307.13903)

    该论文研究了学习具有被篡改的二进制信号的Lipschitz函数的问题，提出了一种腐败鲁棒算法。该算法在不同损失函数下实现了不同程度的后悔。

    

    我研究了学习具有被篡改的二进制信号的Lipschitz函数的问题。学习者试图学习一个由对手选择的Lipschitz函数$f$。在每一轮中，对手在输入空间中选择一个上下文向量$x_t$，学习者对真实函数值$f(x_t)$进行猜测，并接收一个指示猜测是高还是低的二进制信号。在总共$C$轮中，信号可能被篡改，但学习者不知道$C$的值。学习者的目标是造成小的累积损失。我提出了一个自然而强大的技术验证，对设计腐败鲁棒算法非常有用。我设计了一些算法（将Lipschitz参数$L$视为常数）：对于对称损失，学习者在$d=1$时达到后悔$O(C\log T)$，在$d>1$时达到后悔$O_d(C\log T + T^{(d-1)/d})$；对于计价损失，学习者在$d/(d+1)$时达到后悔$\widetilde{O}(T^{d/(d+1)} + C\cdot T^{1/(d+1)})$。

    I study the problem of learning a Lipschitz function with corrupted binary signals. The learner tries to learn a Lipschitz function $f$ that the adversary chooses. In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low. In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner. The learner's goal is to incur a small cumulative loss. I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms. I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\log T)$ with $d = 1$ and $O_d(C\log T + T^{(d-1)/d})$ with $d > 1$; for the pricing loss the learner achieves regret $\widetilde{O} (T^{d/(d+1)} + C\cdot T^{1/(d+1)})$.
    
[^38]: SiBBlInGS: 使用跨状态的图形相似性驱动模块推理的建模块方法

    SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States. (arXiv:2306.04817v1 [stat.ML])

    [http://arxiv.org/abs/2306.04817](http://arxiv.org/abs/2306.04817)

    本文提出了一种跨状态的图形相似性驱动的模块推理框架，可以同时考虑数据中的状态间和状态内关系，并允许状态之间的会话计数和持续时间的差异。它可以提取非正交组件，并且能够识别特定状态与状态非特定模块。

    

    对于多维时间序列来说，提取有意义的模块是发现复杂系统中有价值见解的关键。本文提出了一种基于图形相似性驱动的模块推理框架(SiBBlInGS)，用于发现模块，同时考虑到数据中的状态间和状态内关系，能够提取非正交组件，并允许状态之间的会话计数和持续时间差异。此外，SiBBlInGS还允许跨状态变化模块结构和每次试验的时间变异，并可识别特定状态与状态非特定模块。

    Interpretable methods for extracting meaningful building blocks (BBs) underlying multi-dimensional time series are vital for discovering valuable insights in complex systems. Existing techniques, however, encounter limitations that restrict their applicability to real-world systems, like reliance on orthogonality assumptions, inadequate incorporation of inter- and intra-state variability, and incapability to handle sessions of varying duration. Here, we present a framework for Similarity-driven Building Block Inference using Graphs across States (SiBBlInGS). SiBBlInGS employs a graph-based dictionary learning approach for BB discovery, simultaneously considers both inter- and intra-state relationships in the data, can extract non-orthogonal components, and allows for variations in session counts and duration across states. Additionally, SiBBlInGS allows for cross-state variations in BB structure and per-trial temporal variability, can identify state-specific vs state-invariant BBs, and
    
[^39]: 通过平均加速动量随机梯度下降：有限样本速率和渐近正态性

    Acceleration of stochastic gradient descent with momentum by averaging: finite-sample rates and asymptotic normality. (arXiv:2305.17665v1 [cs.LG])

    [http://arxiv.org/abs/2305.17665](http://arxiv.org/abs/2305.17665)

    研究了动量随机梯度下降（SGDM）和其Polyak-averaging版本的特性，表明在较大的批量大小下，小批量SGDM比小批量SGD更快地收敛到最优值的邻域。

    

    动量随机梯度下降（SGDM）被广泛应用于许多机器学习和统计应用中。尽管SGDM相对于传统的随机梯度下降具有观察到的经验优势，但在优化过程中动量对不同学习率的作用的理论理解仍然是开放的。我们在强凸设置下分析了SGDM的有限样本收敛速率，并表明在较大的批量大小下，小批量SGDM比小批量SGD更快地收敛到最优值的邻域。此外，我们分析了SGDM估计量的Polyak平均版本，建立了它的渐近正态性，并证明了它与平均SGD的渐近等价性。

    Stochastic gradient descent with momentum (SGDM) has been widely used in many machine learning and statistical applications. Despite the observed empirical benefits of SGDM over traditional SGD, the theoretical understanding of the role of momentum for different learning rates in the optimization process remains widely open. We analyze the finite-sample convergence rate of SGDM under the strongly convex settings and show that, with a large batch size, the mini-batch SGDM converges faster than mini-batch SGD to a neighborhood of the optimal value. Furthermore, we analyze the Polyak-averaging version of the SGDM estimator, establish its asymptotic normality, and justify its asymptotic equivalence to the averaged SGD.
    
[^40]: 二元事件的校准评估和大胆再校准

    Calibration Assessment and Boldness-Recalibration for Binary Events. (arXiv:2305.03780v1 [stat.ME])

    [http://arxiv.org/abs/2305.03780](http://arxiv.org/abs/2305.03780)

    本研究提出了一种假设检验和贝叶斯模型选择方法来评估校准，并提供一种大胆再校准策略，使实践者能够在满足所需的校准水平的情况下负责任地增强预测。

    

    概率预测对于医学、经济、图像分类、体育分析、娱乐等许多领域中的决策制定至关重要。理想情况下，概率预测应该 (i) 校准良好 (ii) 准确 (iii) 大胆，即远离事件的基础频率。满足这三个条件的预测对于决策制定是有信息量的。然而，校准和大胆之间存在基本的紧张关系，因为当预测过于谨慎时(即非大胆)校准度量可以很高。本文的目的是开发一种假设检验和贝叶斯模型选择方法来评估校准，并提供一种大胆再校准策略，使实践者能够在满足所需的校准水平的情况下负责任地增强预测。具体而言，我们允许用户预先指定他们所需的后验校准概率，然后在此约束下最大化增强预测。我们通过模拟研究和实际数据应用验证了我们方法的性能。

    Probability predictions are essential to inform decision making in medicine, economics, image classification, sports analytics, entertainment, and many other fields. Ideally, probability predictions are (i) well calibrated, (ii) accurate, and (iii) bold, i.e., far from the base rate of the event. Predictions that satisfy these three criteria are informative for decision making. However, there is a fundamental tension between calibration and boldness, since calibration metrics can be high when predictions are overly cautious, i.e., non-bold. The purpose of this work is to develop a hypothesis test and Bayesian model selection approach to assess calibration, and a strategy for boldness-recalibration that enables practitioners to responsibly embolden predictions subject to their required level of calibration. Specifically, we allow the user to pre-specify their desired posterior probability of calibration, then maximally embolden predictions subject to this constraint. We verify the perfo
    
[^41]: 分段归一化流

    Piecewise Normalizing Flows. (arXiv:2305.02930v1 [stat.ML])

    [http://arxiv.org/abs/2305.02930](http://arxiv.org/abs/2305.02930)

    介绍了一种分段归一化流方法，将目标分布分成集群，并通过训练模拟复杂的多模态目标。这种方法可以更好地匹配标准正态基础分布的拓扑结构。

    

    归一化流是一种通过从基础分布进行可逆转换来对复杂概率密度进行建模的成熟方法。然而，目标分布能否精确地被归一化流所捕捉，强烈受到基础分布的拓扑结构的影响。目标和基础分布之间的拓扑不匹配可能导致性能差，如对于多模态问题。一些不同的工作试图通过使用高斯混合模型 [Izmailov et al., 2020、Ardizzone et al., 2020、Hagemann and Neumayer, 2021] 或学习接受/拒绝采样 [Stimper et al., 2022] 来修改基础分布的拓扑结构以更好地匹配目标分布。我们引入了分段归一化流，将目标分布分成集群，并训练一系列流来模拟复杂的多模态目标。

    Normalizing flows are an established approach for modelling complex probability densities through invertible transformations from a base distribution. However, the accuracy with which the target distribution can be captured by the normalizing flow is strongly influenced by the topology of the base distribution. A mismatch between the topology of the target and the base can result in a poor performance, as is the case for multi-modal problems. A number of different works have attempted to modify the topology of the base distribution to better match the target, either through the use of Gaussian Mixture Models [Izmailov et al., 2020, Ardizzone et al., 2020, Hagemann and Neumayer, 2021] or learned accept/reject sampling [Stimper et al., 2022]. We introduce piecewise normalizing flows which divide the target distribution into clusters, with topologies that better match the standard normal base distribution, and train a series of flows to model complex multi-modal targets. The piecewise nat
    
[^42]: 通过$\ell_{2,\infty}$张量扰动界限估计更高阶混合成员关系

    Estimating Higher-Order Mixed Memberships via the $\ell_{2,\infty}$ Tensor Perturbation Bound. (arXiv:2212.08642v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2212.08642](http://arxiv.org/abs/2212.08642)

    本文提出了一种用于估计更高阶混合成员关系的方法，该方法基于$\ell_{2,\infty}$张量扰动界限，通过张量混合成员模型对多样化数据的社区结构进行建模，并使用高阶正交迭代算法进行估计过程。通过提供每个节点的误差界限来证明了估计过程的一致性，展示了高阶结构对估计精度的影响。

    

    更高阶的多样化数据在机器学习和统计中非常普遍，并经常表现出类似社区的结构，其中每个分量（节点）在每个不同的模式上都有一个与之关联的社区成员资格。本文提出了张量混合成员模型，这是张量块模型的一个推广，其假设成员关系不需要是离散的，而是潜在社区的凸组合。我们证明了我们模型的可辨识性，并提出了一种基于高阶正交迭代算法（HOOI）与单纯形角点寻找算法组合的计算效率估计过程。然后，我们通过提供每个节点的误差界限来证明我们的估计过程的一致性，这展示了高阶结构对估计精度的影响。为了证明我们的一致性结果，我们开发了独立的、可能异方差的$\ell_{2,\infty}$张量扰动界限的HOOI方法。

    Higher-order multiway data is ubiquitous in machine learning and statistics and often exhibits community-like structures, where each component (node) along each different mode has a community membership associated with it. In this paper we propose the tensor mixed-membership blockmodel, a generalization of the tensor blockmodel positing that memberships need not be discrete, but instead are convex combinations of latent communities. We establish the identifiability of our model and propose a computationally efficient estimation procedure based on the higher-order orthogonal iteration algorithm (HOOI) for tensor SVD composed with a simplex corner-finding algorithm. We then demonstrate the consistency of our estimation procedure by providing a per-node error bound, which showcases the effect of higher-order structures on estimation accuracy. To prove our consistency result, we develop the $\ell_{2,\infty}$ tensor perturbation bound for HOOI under independent, possibly heteroskedastic, su
    

