# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks.](http://arxiv.org/abs/2306.16415) | 本文研究了数据中毒攻击的聚合防御策略的实践方面，并针对Deep Partition Aggregation进行了评估，包括效率、性能和鲁棒性。实验结果显示，基于缩放基础模型的方法能够提高聚合防御的训练效率。 |
| [^2] | [Efficient and Multiply Robust Risk Estimation under General Forms of Dataset Shift.](http://arxiv.org/abs/2306.16406) | 本文研究了在通用的数据集转移条件下，利用半参数效率理论，高效估计目标总体风险的问题。 |
| [^3] | [Spatiotemporal Besov Priors for Bayesian Inverse Problems.](http://arxiv.org/abs/2306.16378) | 本研究通过将贝索夫过程推广到时空领域，以更好地处理贝叶斯逆问题中的时空重建。通过替换随机系数，该方法能够保持边缘特征并模拟动态变化图像的时空相关性。 |
| [^4] | [cuSLINK: Single-linkage Agglomerative Clustering on the GPU.](http://arxiv.org/abs/2306.16354) | cuSLINK是一种在GPU上实现的单链接聚类算法，具有较低的空间复杂度和可重复使用的构建模块，适用于广泛的数据挖掘和机器学习应用。 |
| [^5] | [Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise.](http://arxiv.org/abs/2306.16352) | 本文研究了学习具有随机分类噪声的边界半空间的信息-计算权衡问题，发现了样本复杂性和计算效率算法之间的固有差距，并给出了相应的样本复杂性下界。 |
| [^6] | [Gaussian random field approximation via Stein's method with applications to wide random neural networks.](http://arxiv.org/abs/2306.16308) | 本研究利用Stein方法推导出Wasserstein距离的上界，通过高斯平滑技术将平滑度量转化为Wasserstein距离。通过特殊化结果，我们获得了广义随机神经网络中对高斯随机场逼近的首个上界。 |
| [^7] | [A Meta-Learning Method for Estimation of Causal Excursion Effects to Assess Time-Varying Moderation.](http://arxiv.org/abs/2306.16297) | 这项研究介绍了一种元学习方法，用于评估因果偏离效应，以评估干预效果随时间的变化或通过个体特征、环境或过去的反应来调节。目前的数据分析方法需要预先指定观察到的高维历史的特征来构建重要干扰参数的工作模型，而机器学习算法可以自动进行特征构建，但其朴素应用存在问题。 |
| [^8] | [Recent Advances in Optimal Transport for Machine Learning.](http://arxiv.org/abs/2306.16156) | 最优输运在机器学习中的最新进展包括生成建模和迁移学习等领域，并且计算最优输运的发展也与机器学习实践相互影响。 |
| [^9] | [Sparse Representations, Inference and Learning.](http://arxiv.org/abs/2306.16097) | 这篇论文介绍了一种通用框架，可以用于解决涉及弱长程相互作用的各种推理问题，包括压缩感知和感知器学习。利用统计物理学的方法，我们可以研究这些问题的基本限制，并提出相应的算法。 |
| [^10] | [BayesFlow: Amortized Bayesian Workflows With Neural Networks.](http://arxiv.org/abs/2306.16015) | BayesFlow是一个Python库，提供了使用神经网络进行摊还贝叶斯推断的功能，用户可以在模型仿真上训练定制的神经网络，并将其用于任何后续应用。这种摊还贝叶斯推断能够快速准确地进行推断，并实现了对不可计算后验分布的近似。 |
| [^11] | [Curious Replay for Model-based Adaptation.](http://arxiv.org/abs/2306.15934) | 好奇回放是一种针对模型为基础的代理的优先经验回放方法，通过使用好奇度基础的优先信号，它提高了探索性能，并在Crafter基准测试中取得了更好的成绩。 |
| [^12] | [Transfer Learning with Random Coefficient Ridge Regression.](http://arxiv.org/abs/2306.15915) | 本文提出了在迁移学习中使用随机系数岭回归的方法，通过最小化估计风险或预测风险来确定目标模型和源模型的回归系数的最优权重，并使用随机矩阵理论得出了最优权重的极限值。 |
| [^13] | [Discovering stochastic partial differential equations from limited data using variational Bayes inference.](http://arxiv.org/abs/2306.15873) | 本文提出了一种新的框架，结合了随机微积分、变分贝叶斯理论和稀疏学习的概念，用于从有限数据中准确地发现随机偏微分方程（SPDEs）。作者应用该方法成功地识别了随机热方程、随机Allen-Cahn方程和随机Nagumo方程，并证明了该方法在各种科学应用中的重要性。 |
| [^14] | [Differentially Private Distributed Estimation and Learning.](http://arxiv.org/abs/2306.15865) | 本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。 |
| [^15] | [Pure exploration in multi-armed bandits with low rank structure using oblivious sampler.](http://arxiv.org/abs/2306.15856) | 本文研究了纯探索问题中具有低秩结构的多臂赌博机，提出了一种盲目采样器应用以解决分离设置下的纯探索问题，并给出了具有低秩序列的多臂赌博机纯探索问题的上界和下界。 |
| [^16] | [Non-parametric online market regime detection and regime clustering for multidimensional and path-dependent data structures.](http://arxiv.org/abs/2306.15835) | 本研究提出了一种非参数的在线市场制度检测和制度聚类方法，适用于多维和路径依赖的数据结构。该方法利用基于路径空间的最大均值差异相似度度量进行路径样本检验，并优化了针对新进数据少的情况的反应速度。同时，该方法也适用于高维度、非马尔可夫以及自相关性的数据结构。 |
| [^17] | [Ticketed Learning-Unlearning Schemes.](http://arxiv.org/abs/2306.15744) | 提出了一种新的票据化学习-遗忘模型，其中学习算法通过向每个参与训练示例发送额外信息并保留一部分中央信息，实现了学习和遗忘。我们提供了一种高效的票据化学习-遗忘方案，用于广泛的场景。 |
| [^18] | [Privacy-Preserving Community Detection for Locally Distributed Multiple Networks.](http://arxiv.org/abs/2306.15709) | 本文提出了一种保护隐私的本地分布多网络社区检测方法，利用隐私保护来进行共识社区检测和估计。采用随机响应机制对网络边进行扰动，通过隐私保护分布式谱聚类算法在扰动邻接矩阵上执行，以防止社区之间的抵消。同时，开发了两步偏差调整过程来消除扰动和网络矩阵带来的偏差。 |
| [^19] | [Variational Latent Discrete Representation for Time Series Modelling.](http://arxiv.org/abs/2306.15282) | 本文介绍了一种变分潜在离散表示模型，其中离散状态采用马尔可夫链，并在建筑管理数据集和电力变压器数据集上进行了性能评估。 |
| [^20] | [The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets.](http://arxiv.org/abs/2306.14975) | 本文研究了复杂数据集中的底层缩放定律和普适统计结构。通过将数据类比为物理系统，并应用统计物理学和随机矩阵理论的方法，揭示了特征-特征协方差矩阵的局部和全局特征值统计量的规律。研究发现，在无关随机数据和真实数据之间存在显著差异，并且可以通过引入长程相关性完全恢复缩放行为。同时，生成的数据和真实世界数据都属于混沌系统，并在较小的数据集大小上即可体现随机矩阵理论的统计行为。 |
| [^21] | [On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling.](http://arxiv.org/abs/2306.07252) | 研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性 |
| [^22] | [Human-Aligned Calibration for AI-Assisted Decision Making.](http://arxiv.org/abs/2306.00074) | 本文通过引入一种基于主动询问决策者个人偏好的置信度构造方法，解决了现有置信度对于决策者信任决策的不准确问题，从而提高决策的准确性和效率。 |
| [^23] | [Low-rank extended Kalman filtering for online learning of neural networks from streaming data.](http://arxiv.org/abs/2305.19535) | 本文提出一种基于低秩扩展卡尔曼滤波的高效在线学习算法，其能够估计非线性函数的参数，具有更快的适应性和更快的奖励积累。 |
| [^24] | [Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective.](http://arxiv.org/abs/2305.15408) | 本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。 |
| [^25] | [Relabel Minimal Training Subset to Flip a Prediction.](http://arxiv.org/abs/2305.12809) | 本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。 |
| [^26] | [Statistical Optimality of Deep Wide Neural Networks.](http://arxiv.org/abs/2305.02657) | 本文研究了深度宽松弛ReLU神经网络的泛化能力，证明适当早停的梯度下降训练的多层宽神经网络可以实现最小极大率，前提是回归函数在对应的NTK相关的再生核希尔伯特空间中，但过度拟合的多层宽神经网络在$\mathbb S^{d}$上不能很好地泛化。 |
| [^27] | [Optimal tests following sequential experiments.](http://arxiv.org/abs/2305.00403) | 本文分析了基于顺序实验的最优检验方法，重要发现是任何检验的渐近功率函数都可以与一种极限实验中匹配的检验相匹配，这个结果有重要的意义，包括一个强大的充分性结果。 |
| [^28] | [PyVBMC: Efficient Bayesian inference in Python.](http://arxiv.org/abs/2303.09519) | PyVBMC是一种高效的Python工具，用于黑盒计算模型的贝叶斯推断和模型选择，可以处理连续参数不超过约10-15个的计算或统计模型。 |
| [^29] | [Rosenthal-type inequalities for linear statistics of Markov chains.](http://arxiv.org/abs/2303.05838) | 本文建立了一种新的偏差界限，用于马尔可夫链的线性统计，我们关注界限与混合时间的依赖关系，并采用泊松分解的证明技术。 |
| [^30] | [Improved dimension dependence of a proximal algorithm for sampling.](http://arxiv.org/abs/2302.10081) | 提出了一种改进维度依赖性的近端采样算法，应用了近似拒绝采样实现了受限高斯预测者，取得了最先进的复杂度界限。 |
| [^31] | [Towards fully covariant machine learning.](http://arxiv.org/abs/2301.13724) | 本文探讨了机器学习中多个被动对称性的影响，并提出了关于机器学习实践中尊重被动对称性的 dos and don'ts。此外，还讨论了被动对称性与因果建模的关系，并指出在学习问题的目标是样本外推广时，实现被动对称性尤其有价值。 |
| [^32] | [Generalization on the Unseen, Logic Reasoning and Degree Curriculum.](http://arxiv.org/abs/2301.13105) | 本文研究了在逻辑推理任务中对未知数据的泛化能力，提供了网络架构在该设置下的表现证据，发现了一类网络模型在未知数据上学习了最小度插值器，并对长度普通化现象提供了解释。 |
| [^33] | [Support Vector Regression: Risk Quadrangle Framework.](http://arxiv.org/abs/2212.09178) | 本文结合风险四方理论，研究了支持向量回归（SVR）。研究结果发现，SVR的两种形式对应于等效误差度量的最小化，同时加上正则化惩罚项。通过构造基本风险四方框，我们证明了SVR是对两个对称条件分位数的平均数的渐近无偏估计量。此外，我们证明了$\varepsilon$-SVR和$\nu$-SVR在一般随机环境下的等价性。 |
| [^34] | [Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel.](http://arxiv.org/abs/2205.07384) | 本论文提出了一种通过深度学习和高斯过程的复合核来将先验知识融入神经网络的方法。通过隐式定义的神经网络核函数和选择的第二个核函数，可以模拟已知特性，并提高深度学习应用的性能。 |
| [^35] | [Probabilistic AutoRegressive Neural Networks for Accurate Long-range Forecasting.](http://arxiv.org/abs/2204.09640) | PARNN是一种概率自回归神经网络模型，能够准确预测具有非平稳性、非线性、非周期性、长期依赖和混沌模式的复杂时间序列数据，并通过预测区间提供不确定性量化。 |
| [^36] | [PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks.](http://arxiv.org/abs/2204.05731) | PyDTS是一个用于离散时间生存数据半参数竞争风险模型的Python包，支持包括LASSO和弹性网等正则化回归方法。 |
| [^37] | [Open-set learning with augmented category by exploiting unlabeled data (Open-LACU).](http://arxiv.org/abs/2002.01368) | Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。 |
| [^38] | [Understanding Graph Neural Networks with Asymmetric Geometric Scattering Transforms.](http://arxiv.org/abs/1911.06253) | 这项工作介绍了一种具有非对称几何散射变换的图神经网络，通过引入一类非对称小波，它统一和扩展了现有图形散射架构的理论结果，并为未来的深度学习架构为图形提供了基础。 |

# 详细

[^1]: 关于数据中毒攻击的聚合防御的实践方面

    On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks. (arXiv:2306.16415v1 [cs.LG])

    [http://arxiv.org/abs/2306.16415](http://arxiv.org/abs/2306.16415)

    本文研究了数据中毒攻击的聚合防御策略的实践方面，并针对Deep Partition Aggregation进行了评估，包括效率、性能和鲁棒性。实验结果显示，基于缩放基础模型的方法能够提高聚合防御的训练效率。

    

    对于深度学习来说，数据的增加不仅带来机会，也带来风险，因为恶意训练样本可以操纵深度学习模型的行为。这种攻击被称为数据中毒。近期对抗数据中毒的防御策略的进展突出了聚合方案在实现认证中毒鲁棒性方面的有效性。然而，这些方法的实践影响仍不清楚。本文重点研究了Deep Partition Aggregation，一种代表性的聚合防御，并评估了其实际方面，包括效率、性能和鲁棒性。为了评估，我们使用了被调整到64×64分辨率的ImageNet数据集，以便在比以前更大的规模上进行评估。首先，我们展示了一种简单且实用的基于缩放基础模型的方法，它改善了聚合防御的训练和推理效率。其次，我们提供了支持数据剖分的实证证据。

    The increasing access to data poses both opportunities and risks in deep learning, as one can manipulate the behaviors of deep learning models with malicious training samples. Such attacks are known as data poisoning. Recent advances in defense strategies against data poisoning have highlighted the effectiveness of aggregation schemes in achieving state-of-the-art results in certified poisoning robustness. However, the practical implications of these approaches remain unclear. Here we focus on Deep Partition Aggregation, a representative aggregation defense, and assess its practical aspects, including efficiency, performance, and robustness. For evaluations, we use ImageNet resized to a resolution of 64 by 64 to enable evaluations at a larger scale than previous ones. Firstly, we demonstrate a simple yet practical approach to scaling base models, which improves the efficiency of training and inference for aggregation defenses. Secondly, we provide empirical evidence supporting the data
    
[^2]: 通用形式下的高效且多重稳健的风险估计方法在数据转移中

    Efficient and Multiply Robust Risk Estimation under General Forms of Dataset Shift. (arXiv:2306.16406v1 [stat.ME])

    [http://arxiv.org/abs/2306.16406](http://arxiv.org/abs/2306.16406)

    本文研究了在通用的数据集转移条件下，利用半参数效率理论，高效估计目标总体风险的问题。

    

    统计机器学习方法经常面临来自感兴趣总体的有限数据的挑战。一种解决方法是利用来自辅助源总体的数据，这些数据与目标领域的某些条件分布相同或以其他方式相连。利用这种"数据转移"条件的技术被称为"领域适应"或"迁移学习"。尽管有大量关于数据转移的文献，但很少有研究探讨如何有效利用辅助总体来提高目标总体上机器学习任务风险评估的准确性。在本文中，我们利用半参数效率理论研究了在不同的数据集转移条件下高效估计目标总体风险的一般问题。我们考虑了一类通用的数据集转移条件，其中包括三种流行条件——协变量、标签和概念转移——作为特例。我们允许部分非重叠。

    Statistical machine learning methods often face the challenge of limited data available from the population of interest. One remedy is to leverage data from auxiliary source populations, which share some conditional distributions or are linked in other ways with the target domain. Techniques leveraging such \emph{dataset shift} conditions are known as \emph{domain adaptation} or \emph{transfer learning}. Despite extensive literature on dataset shift, limited works address how to efficiently use the auxiliary populations to improve the accuracy of risk evaluation for a given machine learning task in the target population.  In this paper, we study the general problem of efficiently estimating target population risk under various dataset shift conditions, leveraging semiparametric efficiency theory. We consider a general class of dataset shift conditions, which includes three popular conditions -- covariate, label and concept shift -- as special cases. We allow for partially non-overlappi
    
[^3]: 贝索夫先验在贝叶斯逆问题中的时空应用

    Spatiotemporal Besov Priors for Bayesian Inverse Problems. (arXiv:2306.16378v1 [stat.ME])

    [http://arxiv.org/abs/2306.16378](http://arxiv.org/abs/2306.16378)

    本研究通过将贝索夫过程推广到时空领域，以更好地处理贝叶斯逆问题中的时空重建。通过替换随机系数，该方法能够保持边缘特征并模拟动态变化图像的时空相关性。

    

    近年来，科学技术的快速发展促使对捕捉数据特征（如突变或明显对比度）的适当统计工具的需求。许多数据科学应用需要从具有不连续性或奇异性的时间相关对象序列中进行时空重建，如带有边缘的动态计算机断层影像（CT）图像。传统的基于高斯过程（GP）的方法可能无法提供令人满意的解决方案，因为它们往往提供过度平滑的先验候选。最近，通过随机系数的小波展开定义的贝索夫过程（BP）被提出作为这类贝叶斯逆问题的更合适的先验。BP在成像分析中表现出优于GP的性能，能够产生保留边缘特征的重建结果，但没有自动地纳入动态变化图像中的时间相关性。本文将BP推广到时空领域（STBP），通过在小波展开中替换随机系数，实现了时空相关性的建模。

    Fast development in science and technology has driven the need for proper statistical tools to capture special data features such as abrupt changes or sharp contrast. Many applications in the data science seek spatiotemporal reconstruction from a sequence of time-dependent objects with discontinuity or singularity, e.g. dynamic computerized tomography (CT) images with edges. Traditional methods based on Gaussian processes (GP) may not provide satisfactory solutions since they tend to offer over-smooth prior candidates. Recently, Besov process (BP) defined by wavelet expansions with random coefficients has been proposed as a more appropriate prior for this type of Bayesian inverse problems. While BP outperforms GP in imaging analysis to produce edge-preserving reconstructions, it does not automatically incorporate temporal correlation inherited in the dynamically changing images. In this paper, we generalize BP to the spatiotemporal domain (STBP) by replacing the random coefficients in 
    
[^4]: cuSLINK: GPU上的单链接聚类算法

    cuSLINK: Single-linkage Agglomerative Clustering on the GPU. (arXiv:2306.16354v1 [cs.LG])

    [http://arxiv.org/abs/2306.16354](http://arxiv.org/abs/2306.16354)

    cuSLINK是一种在GPU上实现的单链接聚类算法，具有较低的空间复杂度和可重复使用的构建模块，适用于广泛的数据挖掘和机器学习应用。

    

    在本文中，我们提出了cuSLINK，该算法是对GPU上的SLINK算法的一种新型和最先进的改进，它只需要$O(Nk)$的空间，并使用参数$k$来权衡空间和时间。我们还提出了一组新颖且可重复使用的构建模块，这些构建模块包括针对$k$-NN图构建、生成树和树状图聚类的高度优化的计算模式。我们展示了如何使用这些基本模块在GPU上全面实现cuSLINK，进一步使得原本难以处理的广泛的现实世界的数据挖掘和机器学习应用成为可能。除了在流行的HDBSCAN算法中是主要的计算瓶颈之外，我们的cuSLINK算法的全面影响还涵盖了一系列重要的应用，包括社交网络和计算机网络中的聚类分析、自然语言处理和计算机视觉。用户可以在https://docs.rapids.ai/api/cuml/latest/api/#agg获取cuSLINK。

    In this paper, we propose cuSLINK, a novel and state-of-the-art reformulation of the SLINK algorithm on the GPU which requires only $O(Nk)$ space and uses a parameter $k$ to trade off space and time. We also propose a set of novel and reusable building blocks that compose cuSLINK. These building blocks include highly optimized computational patterns for $k$-NN graph construction, spanning trees, and dendrogram cluster extraction. We show how we used our primitives to implement cuSLINK end-to-end on the GPU, further enabling a wide range of real-world data mining and machine learning applications that were once intractable. In addition to being a primary computational bottleneck in the popular HDBSCAN algorithm, the impact of our end-to-end cuSLINK algorithm spans a large range of important applications, including cluster analysis in social and computer networks, natural language processing, and computer vision. Users can obtain cuSLINK at https://docs.rapids.ai/api/cuml/latest/api/#agg
    
[^5]: 学习具有随机分类噪声的边界半空间的信息-计算权衡

    Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise. (arXiv:2306.16352v1 [cs.LG])

    [http://arxiv.org/abs/2306.16352](http://arxiv.org/abs/2306.16352)

    本文研究了学习具有随机分类噪声的边界半空间的信息-计算权衡问题，发现了样本复杂性和计算效率算法之间的固有差距，并给出了相应的样本复杂性下界。

    

    我们研究了使用随机分类噪声学习γ-边界半空间的问题。我们建立了一个信息-计算权衡，表明了问题的样本复杂性与计算效率算法的样本复杂性之间存在固有差距。具体而言，问题的样本复杂性为Θ(1/ (γ^2 ε))。我们首先给出了一个简单高效的算法，其样本复杂性为O(1/ (γ^2 ε^2))。我们的主要结果是统计查询（SQ）算法和低次多项式测试的下界，这表明在计算效率算法中，样本复杂性对1/ε的二次依赖是固有的。具体而言，我们的结果暗示了任何有效的SQ学习器或低次测试的样本复杂性的下界为Ω(1/ (γ^(1/2) ε^2))。

    We study the problem of PAC learning $\gamma$-margin halfspaces with Random Classification Noise. We establish an information-computation tradeoff suggesting an inherent gap between the sample complexity of the problem and the sample complexity of computationally efficient algorithms. Concretely, the sample complexity of the problem is $\widetilde{\Theta}(1/(\gamma^2 \epsilon))$. We start by giving a simple efficient algorithm with sample complexity $\widetilde{O}(1/(\gamma^2 \epsilon^2))$. Our main result is a lower bound for Statistical Query (SQ) algorithms and low-degree polynomial tests suggesting that the quadratic dependence on $1/\epsilon$ in the sample complexity is inherent for computationally efficient algorithms. Specifically, our results imply a lower bound of $\widetilde{\Omega}(1/(\gamma^{1/2} \epsilon^2))$ on the sample complexity of any efficient SQ learner or low-degree test.
    
[^6]: 通过Stein方法对高斯随机场进行逼近及其在广义随机神经网络中的应用

    Gaussian random field approximation via Stein's method with applications to wide random neural networks. (arXiv:2306.16308v1 [math.PR])

    [http://arxiv.org/abs/2306.16308](http://arxiv.org/abs/2306.16308)

    本研究利用Stein方法推导出Wasserstein距离的上界，通过高斯平滑技术将平滑度量转化为Wasserstein距离。通过特殊化结果，我们获得了广义随机神经网络中对高斯随机场逼近的首个上界。

    

    我们利用Stein方法推导出了基于Wasserstein距离（$W_1$）的上界，该距离是连续随机场与高斯分布之间的距离。我们开发了一种新颖的高斯平滑技术，使我们能够将平滑度量中的上界转化为$W_1$距离。平滑性是基于使用Laplacian算子的幂构建的协方差函数，设计成与Cameron-Martin或Reproducing Kernel Hilbert Space相关联的高斯过程具有易操作的特征。这个特征使我们能够超越之前文献中考虑的一维区间型指标集。通过特化我们的一般结果，我们获得了在任意深度和Lipschitz激活函数的广义随机神经网络中对高斯随机场逼近的首个上界。我们的上界明确地用网络宽度和随机权重的矩来表示。

    We derive upper bounds on the Wasserstein distance ($W_1$), with respect to $\sup$-norm, between any continuous $\mathbb{R}^d$ valued random field indexed by the $n$-sphere and the Gaussian, based on Stein's method. We develop a novel Gaussian smoothing technique that allows us to transfer a bound in a smoother metric to the $W_1$ distance. The smoothing is based on covariance functions constructed using powers of Laplacian operators, designed so that the associated Gaussian process has a tractable Cameron-Martin or Reproducing Kernel Hilbert Space. This feature enables us to move beyond one dimensional interval-based index sets that were previously considered in the literature. Specializing our general result, we obtain the first bounds on the Gaussian random field approximation of wide random neural networks of any depth and Lipschitz activation functions at the random field level. Our bounds are explicitly expressed in terms of the widths of the network and moments of the random wei
    
[^7]: 一种用于评估时变调节因素的因果偏离效应估计的元学习方法

    A Meta-Learning Method for Estimation of Causal Excursion Effects to Assess Time-Varying Moderation. (arXiv:2306.16297v1 [stat.ME])

    [http://arxiv.org/abs/2306.16297](http://arxiv.org/abs/2306.16297)

    这项研究介绍了一种元学习方法，用于评估因果偏离效应，以评估干预效果随时间的变化或通过个体特征、环境或过去的反应来调节。目前的数据分析方法需要预先指定观察到的高维历史的特征来构建重要干扰参数的工作模型，而机器学习算法可以自动进行特征构建，但其朴素应用存在问题。

    

    可穿戴技术和智能手机提供的数字化健康干预的双重革命显著增加了移动健康（mHealth）干预在各个健康科学领域的可及性和采纳率。顺序随机实验称为微随机试验（MRTs）已经越来越受欢迎，用于实证评估这些mHealth干预组成部分的有效性。MRTs产生了一类新的因果估计量，称为“因果偏离效应”，使健康科学家能够评估干预效果随时间的变化或通过个体特征、环境或过去的反应来调节。然而，目前用于估计因果偏离效应的数据分析方法需要预先指定观察到的高维历史的特征来构建重要干扰参数的工作模型。虽然机器学习算法在自动特征构建方面具有优势，但其朴素应用导致了问题。

    Twin revolutions in wearable technologies and smartphone-delivered digital health interventions have significantly expanded the accessibility and uptake of mobile health (mHealth) interventions across various health science domains. Sequentially randomized experiments called micro-randomized trials (MRTs) have grown in popularity to empirically evaluate the effectiveness of these mHealth intervention components. MRTs have given rise to a new class of causal estimands known as "causal excursion effects", which enable health scientists to assess how intervention effectiveness changes over time or is moderated by individual characteristics, context, or responses in the past. However, current data analysis methods for estimating causal excursion effects require pre-specified features of the observed high-dimensional history to construct a working model of an important nuisance parameter. While machine learning algorithms are ideal for automatic feature construction, their naive application
    
[^8]: 机器学习中最优输运的最新进展

    Recent Advances in Optimal Transport for Machine Learning. (arXiv:2306.16156v1 [cs.LG])

    [http://arxiv.org/abs/2306.16156](http://arxiv.org/abs/2306.16156)

    最优输运在机器学习中的最新进展包括生成建模和迁移学习等领域，并且计算最优输运的发展也与机器学习实践相互影响。

    

    最近，最优输运被提出作为机器学习中比较和操作概率分布的概率框架。这个框架源于其丰富的历史和理论，并提供了新的解决方案，如生成建模和迁移学习。在这项调查中，我们探讨了最优输运在2012年至2022年期间对机器学习的贡献，重点关注机器学习的四个子领域：有监督学习、无监督学习、迁移学习和强化学习。我们还突出了计算最优输运的最新发展，并与机器学习实践相互影响。

    Recently, Optimal Transport has been proposed as a probabilistic framework in Machine Learning for comparing and manipulating probability distributions. This is rooted in its rich history and theory, and has offered new solutions to different problems in machine learning, such as generative modeling and transfer learning. In this survey we explore contributions of Optimal Transport for Machine Learning over the period 2012 -- 2022, focusing on four sub-fields of Machine Learning: supervised, unsupervised, transfer and reinforcement learning. We further highlight the recent development in computational Optimal Transport, and its interplay with Machine Learning practice.
    
[^9]: 稀疏表示、推理和学习

    Sparse Representations, Inference and Learning. (arXiv:2306.16097v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2306.16097](http://arxiv.org/abs/2306.16097)

    这篇论文介绍了一种通用框架，可以用于解决涉及弱长程相互作用的各种推理问题，包括压缩感知和感知器学习。利用统计物理学的方法，我们可以研究这些问题的基本限制，并提出相应的算法。

    

    近年来，统计物理学已经证明是探究机器学习中出现的大维推理问题的一个有价值的工具。统计物理学提供了分析工具来研究其解决方案中的基本限制，并提出算法来解决个别实例。在这些笔记中，我们将基于2022年Les Houches夏季学校中Marc M\'ezard的讲座，介绍一种可以在弱长程相互作用的各种问题中使用的通用框架，包括压缩感知问题或感知器的学习问题。我们将看到这些问题如何在复制对称级别上进行研究，使用中腔方法的发展，既作为理论工具，也作为算法。

    In recent years statistical physics has proven to be a valuable tool to probe into large dimensional inference problems such as the ones occurring in machine learning. Statistical physics provides analytical tools to study fundamental limitations in their solutions and proposes algorithms to solve individual instances. In these notes, based on the lectures by Marc M\'ezard in 2022 at the summer school in Les Houches, we will present a general framework that can be used in a large variety of problems with weak long-range interactions, including the compressed sensing problem, or the problem of learning in a perceptron. We shall see how these problems can be studied at the replica symmetric level, using developments of the cavity methods, both as a theoretical tool and as an algorithm.
    
[^10]: BayesFlow: 使用神经网络的摊还贝叶斯工作流

    BayesFlow: Amortized Bayesian Workflows With Neural Networks. (arXiv:2306.16015v1 [cs.LG])

    [http://arxiv.org/abs/2306.16015](http://arxiv.org/abs/2306.16015)

    BayesFlow是一个Python库，提供了使用神经网络进行摊还贝叶斯推断的功能，用户可以在模型仿真上训练定制的神经网络，并将其用于任何后续应用。这种摊还贝叶斯推断能够快速准确地进行推断，并实现了对不可计算后验分布的近似。

    

    现代贝叶斯推断涉及一系列计算技术，用于估计、验证和从概率模型中得出结论，作为数据分析中有原则的工作流的一部分。贝叶斯工作流中的典型问题包括近似不可计算后验分布以适应不同的模型类型，以及通过复杂性和预测性能比较同一过程的竞争模型。本文介绍了Python库BayesFlow，用于基于仿真训练已建立的神经网络架构，用于摊还数据压缩和推断。在BayesFlow中实现的摊还贝叶斯推断使用户能够在模型仿真上训练定制的神经网络，并将这些网络重用于模型的任何后续应用。由于训练好的网络可以几乎即时地执行推断，因此前期的神经网络训练很快就能够摊还。

    Modern Bayesian inference involves a mixture of computational techniques for estimating, validating, and drawing conclusions from probabilistic models as part of principled workflows for data analysis. Typical problems in Bayesian workflows are the approximation of intractable posterior distributions for diverse model types and the comparison of competing models of the same process in terms of their complexity and predictive performance. This manuscript introduces the Python library BayesFlow for simulation-based training of established neural network architectures for amortized data compression and inference. Amortized Bayesian inference, as implemented in BayesFlow, enables users to train custom neural networks on model simulations and re-use these networks for any subsequent application of the models. Since the trained networks can perform inference almost instantaneously, the upfront neural network training is quickly amortized.
    
[^11]: 对于模型为基础的适应性的好奇回放

    Curious Replay for Model-based Adaptation. (arXiv:2306.15934v1 [cs.LG])

    [http://arxiv.org/abs/2306.15934](http://arxiv.org/abs/2306.15934)

    好奇回放是一种针对模型为基础的代理的优先经验回放方法，通过使用好奇度基础的优先信号，它提高了探索性能，并在Crafter基准测试中取得了更好的成绩。

    

    代理必须能够在环境改变时快速适应。我们发现现有的基于模型的强化学习代理在这方面做得不好，部分原因是它们如何利用过去的经验来训练其世界模型。在这里，我们提出了一种称为好奇回放的方法，它是针对基于模型的代理的一种优先经验回放方法，通过使用好奇度基础的优先信号。使用好奇回放的代理在受到动物行为启发的探索范式和Crafter基准测试中表现出改进的性能。带有好奇回放的DreamerV3在Crafter上超越了最先进的性能，实现了19.4的平均分数，大大改善了之前DreamerV3使用均匀回放时的最高分数14.5，并且在Deepmind Control Suite上的性能也相似。好奇回放的代码可以在https://github.com/AutonomousAgentsLab/curiousreplay上找到。

    Agents must be able to adapt quickly as an environment changes. We find that existing model-based reinforcement learning agents are unable to do this well, in part because of how they use past experiences to train their world model. Here, we present Curious Replay -- a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal. Agents using Curious Replay exhibit improved performance in an exploration paradigm inspired by animal behavior and on the Crafter benchmark. DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter, achieving a mean score of 19.4 that substantially improves on the previous high score of 14.5 by DreamerV3 with uniform replay, while also maintaining similar performance on the Deepmind Control Suite. Code for Curious Replay is available at https://github.com/AutonomousAgentsLab/curiousreplay
    
[^12]: 用随机系数岭回归进行迁移学习

    Transfer Learning with Random Coefficient Ridge Regression. (arXiv:2306.15915v1 [stat.ML])

    [http://arxiv.org/abs/2306.15915](http://arxiv.org/abs/2306.15915)

    本文提出了在迁移学习中使用随机系数岭回归的方法，通过最小化估计风险或预测风险来确定目标模型和源模型的回归系数的最优权重，并使用随机矩阵理论得出了最优权重的极限值。

    

    在高维环境中，随机系数岭回归提供了固定系数回归的一个重要替代方案，当效果被期望为小但不为零时。本文考虑在迁移学习的情况下估计和预测随机系数岭回归，在目标模型的观测值之外，还提供了来自不同但可能相关的回归模型的源样本。源模型对目标模型的信息量可以通过回归系数之间的相关性来量化。本文提出了两个目标模型回归系数的估计器，它们是目标模型和源模型岭估计的加权和，其中权重可以通过最小化经验估计风险或预测风险来确定。利用随机矩阵理论，在$p/n \rightarrow \gamma$的条件下，得出了最优权重的极限值，其中$p$是...

    Ridge regression with random coefficients provides an important alternative to fixed coefficients regression in high dimensional setting when the effects are expected to be small but not zeros. This paper considers estimation and prediction of random coefficient ridge regression in the setting of transfer learning, where in addition to observations from the target model, source samples from different but possibly related regression models are available. The informativeness of the source model to the target model can be quantified by the correlation between the regression coefficients. This paper proposes two estimators of regression coefficients of the target model as the weighted sum of the ridge estimates of both target and source models, where the weights can be determined by minimizing the empirical estimation risk or prediction risk. Using random matrix theory, the limiting values of the optimal weights are derived under the setting when $p/n \rightarrow \gamma$, where $p$ is the 
    
[^13]: 用变分贝叶斯推断从有限数据中发现随机偏微分方程

    Discovering stochastic partial differential equations from limited data using variational Bayes inference. (arXiv:2306.15873v1 [stat.ML])

    [http://arxiv.org/abs/2306.15873](http://arxiv.org/abs/2306.15873)

    本文提出了一种新的框架，结合了随机微积分、变分贝叶斯理论和稀疏学习的概念，用于从有限数据中准确地发现随机偏微分方程（SPDEs）。作者应用该方法成功地识别了随机热方程、随机Allen-Cahn方程和随机Nagumo方程，并证明了该方法在各种科学应用中的重要性。

    

    我们提出了一个新的框架，用于从数据中发现随机偏微分方程（SPDEs）。所提出的方法将随机微积分、变分贝叶斯理论和稀疏学习的概念相结合。我们提出了扩展的Kramers-Moyal展开形式，以响应状态来表示SPDE的漂移和扩散项，并使用带有稀疏学习技术的Spike-and-Slab先验来高效准确地发现潜在的SPDEs。所提出的方法已经应用于三个典型的SPDEs，分别是随机热方程、随机Allen-Cahn方程和随机Nagumo方程。我们的结果表明，所提出的方法可以准确地识别有限数据中的潜在SPDEs。这是首次尝试从数据中发现SPDEs，对于各种科学应用，如气候建模、金融预测和化学动力学，具有重要意义。

    We propose a novel framework for discovering Stochastic Partial Differential Equations (SPDEs) from data. The proposed approach combines the concepts of stochastic calculus, variational Bayes theory, and sparse learning. We propose the extended Kramers-Moyal expansion to express the drift and diffusion terms of an SPDE in terms of state responses and use Spike-and-Slab priors with sparse learning techniques to efficiently and accurately discover the underlying SPDEs. The proposed approach has been applied to three canonical SPDEs, (a) stochastic heat equation, (b) stochastic Allen-Cahn equation, and (c) stochastic Nagumo equation. Our results demonstrate that the proposed approach can accurately identify the underlying SPDEs with limited data. This is the first attempt at discovering SPDEs from data, and it has significant implications for various scientific applications, such as climate modeling, financial forecasting, and chemical kinetics.
    
[^14]: 差分隐私分布式估计和学习

    Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])

    [http://arxiv.org/abs/2306.15865](http://arxiv.org/abs/2306.15865)

    本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。

    

    我们研究了在网络环境中的分布式估计和学习问题，其中代理通过交换信息来估计从其私下观察的样本中未知的统计属性。通过交换私有观测信息，代理可以集体估计未知数量，但他们也面临隐私风险。我们的聚合方案的目标是在时间和网络中高效地组合观测数据，同时满足代理的隐私需求，而不需要任何超越他们本地附近的协调。我们的算法使参与的代理能够从离线或随时间在线获取的私有信号中估计完整的充分统计量，并保护其信号和网络附近的隐私。这是通过线性聚合方案和调整的随机化方案实现的，将噪声添加到交换的估计数据中以满足差分隐私（DP）。

    We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
    
[^15]: 纯探索问题中具有低秩结构的多臂赌博机的盲目采样器应用

    Pure exploration in multi-armed bandits with low rank structure using oblivious sampler. (arXiv:2306.15856v1 [cs.LG])

    [http://arxiv.org/abs/2306.15856](http://arxiv.org/abs/2306.15856)

    本文研究了纯探索问题中具有低秩结构的多臂赌博机，提出了一种盲目采样器应用以解决分离设置下的纯探索问题，并给出了具有低秩序列的多臂赌博机纯探索问题的上界和下界。

    

    本文考虑纯探索问题中奖励序列的低秩结构。首先，我们提出了纯探索问题中的分离设置，其中探索策略无法接收其探索的反馈。由于这种分离设置，探索策略需要盲目地采样臂。通过引入奖励向量的核信息，我们提供了对于时间变化和固定情况的高效算法，其遗憾界为$O(d\sqrt{(\ln N)/n})$。然后，我们证明了低秩序列的多臂赌博机的纯探索问题的下界。我们的上界与下界之间存在$O(\sqrt{\ln N})$的差距。

    In this paper, we consider the low rank structure of the reward sequence of the pure exploration problems. Firstly, we propose the separated setting in pure exploration problem, where the exploration strategy cannot receive the feedback of its explorations. Due to this separation, it requires that the exploration strategy to sample the arms obliviously. By involving the kernel information of the reward vectors, we provide efficient algorithms for both time-varying and fixed cases with regret bound $O(d\sqrt{(\ln N)/n})$. Then, we show the lower bound to the pure exploration in multi-armed bandits with low rank sequence. There is an $O(\sqrt{\ln N})$ gap between our upper bound and the lower bound.
    
[^16]: 非参数的在线市场制度检测和制度聚类方法对于多维和路径依赖的数据结构

    Non-parametric online market regime detection and regime clustering for multidimensional and path-dependent data structures. (arXiv:2306.15835v1 [stat.ML])

    [http://arxiv.org/abs/2306.15835](http://arxiv.org/abs/2306.15835)

    本研究提出了一种非参数的在线市场制度检测和制度聚类方法，适用于多维和路径依赖的数据结构。该方法利用基于路径空间的最大均值差异相似度度量进行路径样本检验，并优化了针对新进数据少的情况的反应速度。同时，该方法也适用于高维度、非马尔可夫以及自相关性的数据结构。

    

    本研究提出了一种非参数的在线市场制度检测方法，用于多维数据结构，利用基于路径空间上的最大均值差异相似度度量的路径样本检验。该相似度度量已经在最近的小规模数据环境的生成模型中作为鉴别器进行了发展和应用，并在此进行了优化，以适应新进数据量特别少的情况，以加快反应速度。在同样的原则下，我们还提出了一种基于路径的制度聚类方法，扩展了我们之前的工作。所提出的制度聚类技术被设计为前期市场分析工具，可以识别出大致相似的市场活动期间，但新的结果同时适用于基于路径的、高维度的和非马尔可夫的设置，以及表现出自相关性的数据结构。

    In this work we present a non-parametric online market regime detection method for multidimensional data structures using a path-wise two-sample test derived from a maximum mean discrepancy-based similarity metric on path space that uses rough path signatures as a feature map. The latter similarity metric has been developed and applied as a discriminator in recent generative models for small data environments, and has been optimised here to the setting where the size of new incoming data is particularly small, for faster reactivity.  On the same principles, we also present a path-wise method for regime clustering which extends our previous work. The presented regime clustering techniques were designed as ex-ante market analysis tools that can identify periods of approximatively similar market activity, but the new results also apply to path-wise, high dimensional-, and to non-Markovian settings as well as to data structures that exhibit autocorrelation.  We demonstrate our clustering t
    
[^17]: 票据化学习-遗忘方案

    Ticketed Learning-Unlearning Schemes. (arXiv:2306.15744v1 [cs.LG])

    [http://arxiv.org/abs/2306.15744](http://arxiv.org/abs/2306.15744)

    提出了一种新的票据化学习-遗忘模型，其中学习算法通过向每个参与训练示例发送额外信息并保留一部分中央信息，实现了学习和遗忘。我们提供了一种高效的票据化学习-遗忘方案，用于广泛的场景。

    

    我们考虑所定义的学习-遗忘范式。首先，给定一个数据集，目标是学习一个好的预测器，例如最小化某个损失函数的预测器。随后，给定任何希望遗忘的示例子集，目标是在不知道原始训练数据集的情况下，学习一个与在幸存示例上从头开始学习时所生成的预测器完全相同的好的预测器。我们提出了一种新的票据化学习-遗忘模型，其中学习算法可以通过一个小型（加密的）“票据”向每个参与训练示例发送额外的信息，并保留一小部分“中央”信息以供以后使用。随后，希望遗忘的示例将其票据提交给遗忘算法，该算法还使用中央信息返回一个新的预测器。我们提供了一种高效的票据化学习-遗忘方案，用于广泛的场景。

    We consider the learning--unlearning paradigm defined as follows. First given a dataset, the goal is to learn a good predictor, such as one minimizing a certain loss. Subsequently, given any subset of examples that wish to be unlearnt, the goal is to learn, without the knowledge of the original training dataset, a good predictor that is identical to the predictor that would have been produced when learning from scratch on the surviving examples.  We propose a new ticketed model for learning--unlearning wherein the learning algorithm can send back additional information in the form of a small-sized (encrypted) ``ticket'' to each participating training example, in addition to retaining a small amount of ``central'' information for later. Subsequently, the examples that wish to be unlearnt present their tickets to the unlearning algorithm, which additionally uses the central information to return a new predictor. We provide space-efficient ticketed learning--unlearning schemes for a broad
    
[^18]: 保护隐私的本地分布多网络社区检测

    Privacy-Preserving Community Detection for Locally Distributed Multiple Networks. (arXiv:2306.15709v1 [cs.SI])

    [http://arxiv.org/abs/2306.15709](http://arxiv.org/abs/2306.15709)

    本文提出了一种保护隐私的本地分布多网络社区检测方法，利用隐私保护来进行共识社区检测和估计。采用随机响应机制对网络边进行扰动，通过隐私保护分布式谱聚类算法在扰动邻接矩阵上执行，以防止社区之间的抵消。同时，开发了两步偏差调整过程来消除扰动和网络矩阵带来的偏差。

    

    现代多层网络由于隐私、所有权和通信成本的原因，常常以本地和分布式的方式存储和分析。关于基于这些数据的模型化统计方法用于社区检测的文献仍然有限。本文提出了一种新的方法，用于基于本地存储和计算的网络数据的多层随机块模型中的共识社区检测和估计，并采用隐私保护。开发了一种名为隐私保护分布式谱聚类（ppDSC）的新算法。为了保护边的隐私，我们采用了随机响应（RR）机制来扰动网络边，该机制满足差分隐私的强概念。ppDSC算法在平方的RR扰动邻接矩阵上执行，以防止不同层之间的社区相互抵消。为了消除RR和平方网络矩阵所带来的偏差，我们开发了一个两步偏差调整过程。

    Modern multi-layer networks are commonly stored and analyzed in a local and distributed fashion because of the privacy, ownership, and communication costs. The literature on the model-based statistical methods for community detection based on these data is still limited. This paper proposes a new method for consensus community detection and estimation in a multi-layer stochastic block model using locally stored and computed network data with privacy protection. A novel algorithm named privacy-preserving Distributed Spectral Clustering (ppDSC) is developed. To preserve the edges' privacy, we adopt the randomized response (RR) mechanism to perturb the network edges, which satisfies the strong notion of differential privacy. The ppDSC algorithm is performed on the squared RR-perturbed adjacency matrices to prevent possible cancellation of communities among different layers. To remove the bias incurred by RR and the squared network matrices, we develop a two-step bias-adjustment procedure.
    
[^19]: 变分潜在离散表示在时间序列建模中的应用

    Variational Latent Discrete Representation for Time Series Modelling. (arXiv:2306.15282v1 [stat.ML])

    [http://arxiv.org/abs/2306.15282](http://arxiv.org/abs/2306.15282)

    本文介绍了一种变分潜在离散表示模型，其中离散状态采用马尔可夫链，并在建筑管理数据集和电力变压器数据集上进行了性能评估。

    

    最近，离散潜在空间模型在深度变分推断中的性能与其连续对应物相媲美。虽然它们仍然面临各种实现挑战，但这些模型为潜在空间的更好解释提供了机会，同时更直接地表示自然离散现象。最近的一些方法建议分别在离散潜在数据上训练非常高维的先验模型，这本身就是一个具有挑战性的任务。在本文中，我们介绍了一种潜在数据模型，其中离散状态是一个马尔可夫链，它允许快速端到端训练。我们对我们的生成模型在建筑管理数据集和公开可用的电力变压器数据集上进行了性能评估。

    Discrete latent space models have recently achieved performance on par with their continuous counterparts in deep variational inference. While they still face various implementation challenges, these models offer the opportunity for a better interpretation of latent spaces, as well as a more direct representation of naturally discrete phenomena. Most recent approaches propose to train separately very high-dimensional prior models on the discrete latent data which is a challenging task on its own. In this paper, we introduce a latent data model where the discrete state is a Markov chain, which allows fast end-to-end training. The performance of our generative model is assessed on a building management dataset and on the publicly available Electricity Transformer Dataset.
    
[^20]: 复杂数据集的底层缩放定律和普适统计结构

    The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets. (arXiv:2306.14975v1 [cs.LG])

    [http://arxiv.org/abs/2306.14975](http://arxiv.org/abs/2306.14975)

    本文研究了复杂数据集中的底层缩放定律和普适统计结构。通过将数据类比为物理系统，并应用统计物理学和随机矩阵理论的方法，揭示了特征-特征协方差矩阵的局部和全局特征值统计量的规律。研究发现，在无关随机数据和真实数据之间存在显著差异，并且可以通过引入长程相关性完全恢复缩放行为。同时，生成的数据和真实世界数据都属于混沌系统，并在较小的数据集大小上即可体现随机矩阵理论的统计行为。

    

    我们研究了在真实世界的复杂数据集和人工生成的数据集中都出现的普遍特征。我们将数据类比为物理系统，并利用统计物理学和随机矩阵理论的工具揭示其底层结构。我们重点分析了特征-特征协方差矩阵，分析了其局部和全局特征值统计量。我们的主要观察结果是：(i) 大部分特征值呈现的幂律缩放在无相关随机数据和真实数据之间存在显著差异，(ii) 通过简单地引入长程相关性，可以完全恢复这种缩放行为到合成数据中，(iii) 从随机矩阵理论的角度看，生成的数据集和真实世界数据集属于同一个普适性类别，都是混沌系统而非可积系统，(iv) 预期的随机矩阵理论统计行为在相对较小的数据集大小上就已经在经验协方差矩阵中得到体现。

    We study universal traits which emerge both in real-world complex datasets, as well as in artificially generated ones. Our approach is to analogize data to a physical system and employ tools from statistical physics and Random Matrix Theory (RMT) to reveal their underlying structure. We focus on the feature-feature covariance matrix, analyzing both its local and global eigenvalue statistics. Our main observations are: (i) The power-law scalings that the bulk of its eigenvalues exhibit are vastly different for uncorrelated random data compared to real-world data, (ii) this scaling behavior can be completely recovered by introducing long range correlations in a simple way to the synthetic data, (iii) both generated and real-world datasets lie in the same universality class from the RMT perspective, as chaotic rather than integrable systems, (iv) the expected RMT statistical behavior already manifests for empirical covariance matrices at dataset sizes significantly smaller than those conv
    
[^21]: 非均匀抽样下网络数据中符合性预测的有效性研究

    On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])

    [http://arxiv.org/abs/2306.07252](http://arxiv.org/abs/2306.07252)

    研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性

    

    我们研究了针对常见非代表性节点采样机制下的网络数据符合性预测的性质。我们将这些采样机制解释为应用于超总体的选择规则，并在适当的选择事件条件下研究符合性预测的有效性。我们证明了，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则采样子阵列在选择事件条件下是可交换的。我们的结果意味着对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性。我们还表明，当数据通过图上的随机游走来采样时，加权符合性预测的变体可以对人口独立选择节点的预测集进行渐近有效的预测。

    We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
    
[^22]: 人类对齐校准用于AI辅助决策制定

    Human-Aligned Calibration for AI-Assisted Decision Making. (arXiv:2306.00074v1 [cs.LG])

    [http://arxiv.org/abs/2306.00074](http://arxiv.org/abs/2306.00074)

    本文通过引入一种基于主动询问决策者个人偏好的置信度构造方法，解决了现有置信度对于决策者信任决策的不准确问题，从而提高决策的准确性和效率。

    

    当使用二元分类器提供决策支持时，它通常提供标签预测和置信度值。然后，决策者应使用置信度值来校准对预测的信任程度。在这种情况下，人们经常认为置信度值应对预测标签与实际标签匹配的概率进行良好校准的估计。然而，多条实证证据表明，决策者难以使用这些置信度值很好地确定何时信任预测。本文的目标首先是理解为什么，然后研究如何构建更有用的置信度值。我们首先认为，在广泛类的效用函数中，存在数据分布，对于这些分布，理性决策者通常难以使用以上置信度值发现最佳决策政策——最佳的决策者需要人类对齐。然后，我们引入了一种基于主动询问决策者他们在所面临的二元分类任务的决策上的个人偏好的新方法来构造置信度值。我们表明，该方法产生的置信度值比使用标准置信度度量导致更好的决策。

    Whenever a binary classifier is used to provide decision support, it typically provides both a label prediction and a confidence value. Then, the decision maker is supposed to use the confidence value to calibrate how much to trust the prediction. In this context, it has been often argued that the confidence value should correspond to a well calibrated estimate of the probability that the predicted label matches the ground truth label. However, multiple lines of empirical evidence suggest that decision makers have difficulties at developing a good sense on when to trust a prediction using these confidence values. In this paper, our goal is first to understand why and then investigate how to construct more useful confidence values. We first argue that, for a broad class of utility functions, there exist data distributions for which a rational decision maker is, in general, unlikely to discover the optimal decision policy using the above confidence values -- an optimal decision maker wou
    
[^23]: 基于流数据的神经网络在线学习的低秩扩展卡尔曼滤波算法

    Low-rank extended Kalman filtering for online learning of neural networks from streaming data. (arXiv:2305.19535v1 [stat.ML])

    [http://arxiv.org/abs/2305.19535](http://arxiv.org/abs/2305.19535)

    本文提出一种基于低秩扩展卡尔曼滤波的高效在线学习算法，其能够估计非线性函数的参数，具有更快的适应性和更快的奖励积累。

    

    本文提出了一种高效的在线近似贝叶斯推理算法，用于从可能非平稳的数据流中估计非线性函数的参数。该方法基于扩展卡尔曼滤波器（EKF），但使用了一种新颖的低秩加对角线的后验精度矩阵分解，其每步的成本与模型参数数量成线性关系。与基于随机变分推理的方法不同，我们的方法是完全确定的，并且不需要步长调整。我们通过实验证明，这导致更快（更高效）的学习，从而在用作上下文赌博算法的一部分时实现更快速的适应性和更快的奖励积累。

    We propose an efficient online approximate Bayesian inference algorithm for estimating the parameters of a nonlinear function from a potentially non-stationary data stream. The method is based on the extended Kalman filter (EKF), but uses a novel low-rank plus diagonal decomposition of the posterior precision matrix, which gives a cost per step which is linear in the number of model parameters. In contrast to methods based on stochastic variational inference, our method is fully deterministic, and does not require step-size tuning. We show experimentally that this results in much faster (more sample efficient) learning, which results in more rapid adaptation to changing distributions, and faster accumulation of reward when used as part of a contextual bandit algorithm.
    
[^24]: 从理论角度揭示“思维链”背后的奥秘

    Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])

    [http://arxiv.org/abs/2305.15408](http://arxiv.org/abs/2305.15408)

    本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。

    

    最近的研究发现，"思维链"提示能够显著提高大型语言模型（LLMs）的性能，特别是在涉及数学或推理的复杂任务中。尽管获得了巨大的实证成功，但“思维链”背后的机制以及它如何释放LLMs的潜力仍然是神秘的。本文首次从理论上回答了这些问题。具体而言，我们研究了LLMs带有“思维链”在解决基本数学和决策问题中的能力。我们首先给出一个不可能的结果，表明任何有限深度的Transformer都不能直接输出正确的基本算术/方程任务的答案，除非模型大小随着输入长度的增加呈超多项式增长。相反，我们通过构造证明，大小恒定的自回归Transformer足以通过使用常用的数学语言形式生成“思维链”推导来解决这两个任务。

    Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
    
[^25]: 通过重新标记最小训练子集来翻转预测

    Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])

    [http://arxiv.org/abs/2305.12809](http://arxiv.org/abs/2305.12809)

    本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。

    

    Yang等人发现，仅删除1%的训练数据就可能导致预测结果翻转。鉴于机器学习模型中存在噪声数据的普遍性，本文提出了一个问题：在模型训练之前通过重新标记一个小的训练数据子集可否导致测试结果翻转？本文利用扩展影响函数提出了一种有效的识别和重新标记这种子集的方法，并证明了其始终能够产生成功的结果。这种机制有多重作用：（1）提供了一种补充方法，可以通过恢复可能错误标记的训练数据来挑战模型预测；（2）评估模型的鲁棒性，因为本文发现子集的大小与训练集中噪声数据的比例之间存在显著关系；（3）提供了洞察训练集偏差的见解。据我们所知，这项工作代表了对识别最小训练子集问题的第一次研究。

    Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
    
[^26]: 深度宽松弛神经网络的统计优化性

    Statistical Optimality of Deep Wide Neural Networks. (arXiv:2305.02657v1 [stat.ML])

    [http://arxiv.org/abs/2305.02657](http://arxiv.org/abs/2305.02657)

    本文研究了深度宽松弛ReLU神经网络的泛化能力，证明适当早停的梯度下降训练的多层宽神经网络可以实现最小极大率，前提是回归函数在对应的NTK相关的再生核希尔伯特空间中，但过度拟合的多层宽神经网络在$\mathbb S^{d}$上不能很好地泛化。

    

    本文研究了定义在有界域$\mathcal X \subset \mathbb R^{d}$上的深度宽松弛ReLU神经网络的泛化能力。首先证明了神经网络的泛化能力可以被相应的深度神经切向核回归所完全描绘。然后，我们研究了深度神经切向核的谱特性，并证明了深度神经切向核在$\mathcal{X}$上为正定，其特征值衰减率为$(d+1)/d$。由于核回归中已经建立的理论，我们得出结论，适当早停的梯度下降训练的多层宽神经网络可以实现最小极大率，前提是回归函数在对应的NTK相关的再生核希尔伯特空间中。最后，我们证明过度拟合的多层宽神经网络在$\mathbb S^{d}$上不能很好地泛化。

    In this paper, we consider the generalization ability of deep wide feedforward ReLU neural networks defined on a bounded domain $\mathcal X \subset \mathbb R^{d}$. We first demonstrate that the generalization ability of the neural network can be fully characterized by that of the corresponding deep neural tangent kernel (NTK) regression. We then investigate on the spectral properties of the deep NTK and show that the deep NTK is positive definite on $\mathcal{X}$ and its eigenvalue decay rate is $(d+1)/d$. Thanks to the well established theories in kernel regression, we then conclude that multilayer wide neural networks trained by gradient descent with proper early stopping achieve the minimax rate, provided that the regression function lies in the reproducing kernel Hilbert space (RKHS) associated with the corresponding NTK. Finally, we illustrate that the overfitted multilayer wide neural networks can not generalize well on $\mathbb S^{d}$.
    
[^27]: 基于顺序实验的最优检验方法

    Optimal tests following sequential experiments. (arXiv:2305.00403v1 [econ.EM])

    [http://arxiv.org/abs/2305.00403](http://arxiv.org/abs/2305.00403)

    本文分析了基于顺序实验的最优检验方法，重要发现是任何检验的渐近功率函数都可以与一种极限实验中匹配的检验相匹配，这个结果有重要的意义，包括一个强大的充分性结果。

    

    近年来，顺序实验的理论和应用取得了巨大进展。虽然这些实验不一定是为了进行假设检验而设计的，但研究人员仍然可能对实验完成后的检验感兴趣。本文的目的是通过分析它们的渐近性质来帮助发展顺序实验的最优检验方法。我们的关键发现是，任何检验的渐近功率函数都可以与极限实验中匹配的检验相匹配，在这个极限实验中，对于每种处理，观察产生一个高斯过程，并对这些过程的漂移进行推断。这个结果有重要的意义，包括一个强大的充分性结果：任何候选检验方法只需要依赖于一组固定的统计量，而不是顺序实验的类型。这些统计量是每种处理在实验结束时被采样的次数，以及得分的最终值（对于参数模型）

    Recent years have seen tremendous advances in the theory and application of sequential experiments. While these experiments are not always designed with hypothesis testing in mind, researchers may still be interested in performing tests after the experiment is completed. The purpose of this paper is to aid in the development of optimal tests for sequential experiments by analyzing their asymptotic properties. Our key finding is that the asymptotic power function of any test can be matched by a test in a limit experiment where a Gaussian process is observed for each treatment, and inference is made for the drifts of these processes. This result has important implications, including a powerful sufficiency result: any candidate test only needs to rely on a fixed set of statistics, regardless of the type of sequential experiment. These statistics are the number of times each treatment has been sampled by the end of the experiment, along with final value of the score (for parametric models)
    
[^28]: PyVBMC：Python中高效的贝叶斯推断

    PyVBMC: Efficient Bayesian inference in Python. (arXiv:2303.09519v1 [stat.ML])

    [http://arxiv.org/abs/2303.09519](http://arxiv.org/abs/2303.09519)

    PyVBMC是一种高效的Python工具，用于黑盒计算模型的贝叶斯推断和模型选择，可以处理连续参数不超过约10-15个的计算或统计模型。

    

    PyVBMC是Variational Bayesian Monte Carlo（VBMC）算法的Python实现，用于黑盒计算模型的后验和模型推断。VBMC是一种用于高效参数估计和模型评估的近似推断方法，当模型评估是有点到非常昂贵（例如第二次或更多次）和/或嘈杂时。具体而言，VBMC计算：

    PyVBMC is a Python implementation of the Variational Bayesian Monte Carlo (VBMC) algorithm for posterior and model inference for black-box computational models (Acerbi, 2018, 2020). VBMC is an approximate inference method designed for efficient parameter estimation and model assessment when model evaluations are mildly-to-very expensive (e.g., a second or more) and/or noisy. Specifically, VBMC computes:  - a flexible (non-Gaussian) approximate posterior distribution of the model parameters, from which statistics and posterior samples can be easily extracted;  - an approximation of the model evidence or marginal likelihood, a metric used for Bayesian model selection.  PyVBMC can be applied to any computational or statistical model with up to roughly 10-15 continuous parameters, with the only requirement that the user can provide a Python function that computes the target log likelihood of the model, or an approximation thereof (e.g., an estimate of the likelihood obtained via simulation
    
[^29]: 线性统计的马尔可夫链的罗森塔尔不等式

    Rosenthal-type inequalities for linear statistics of Markov chains. (arXiv:2303.05838v2 [math.PR] UPDATED)

    [http://arxiv.org/abs/2303.05838](http://arxiv.org/abs/2303.05838)

    本文建立了一种新的偏差界限，用于马尔可夫链的线性统计，我们关注界限与混合时间的依赖关系，并采用泊松分解的证明技术。

    

    本文建立了一种新的偏差界限，用于几何遍历的马尔可夫链的可加函数，类似于独立随机变量的罗森塔尔和伯恩斯坦不等式。我们特别关注界限与相应链的混合时间的依赖关系。更准确地说，我们建立了与罗森塔尔不等式的鞍点版本中的常量以及表征底层马尔可夫核混合特性的常量相关的明确界限。最后，我们的证明技术是新颖的，并且基于泊松分解的反复应用。

    In this paper, we establish novel deviation bounds for additive functionals of geometrically ergodic Markov chains similar to Rosenthal and Bernstein inequalities for sums of independent random variables. We pay special attention to the dependence of our bounds on the mixing time of the corresponding chain. More precisely, we establish explicit bounds that are linked to the constants from the martingale version of the Rosenthal inequality, as well as the constants that characterize the mixing properties of the underlying Markov kernel. Finally, our proof technique is, up to our knowledge, new and based on a recurrent application of the Poisson decomposition.
    
[^30]: 采样问题中一种改进维度依赖性的近端算法

    Improved dimension dependence of a proximal algorithm for sampling. (arXiv:2302.10081v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2302.10081](http://arxiv.org/abs/2302.10081)

    提出了一种改进维度依赖性的近端采样算法，应用了近似拒绝采样实现了受限高斯预测者，取得了最先进的复杂度界限。

    

    我们提出了一种采样算法，在所有经典情况（强对数凹、对数凹、对数 Sobolev 不等式 (LSI)、Poincaré 不等式）以及更一般的半光滑或复合势函数设置中都实现了优越的复杂度界限。我们的算法基于~\citet{lee2021structured} 中引入的近端采样器。近端采样器的性能取决于受限高斯预测者 (RGO) 的性能，这是近端采样器中的关键步骤。本工作的主要贡献是基于近似拒绝采样实现 RGO 的不精确性。为了界定 RGO 的不精确性，我们建立了一个针对高斯分布上半光滑函数的新的集中不等式，扩展了众所周知的 Lipschitz 函数的集中不等式。将我们的 RGO 实现应用于近端采样器，我们在几乎所有设置中都实现了最先进的复杂度界限。例如，对于强对数凹分布，

    We propose a sampling algorithm that achieves superior complexity bounds in all the classical settings (strongly log-concave, log-concave, Logarithmic-Sobolev inequality (LSI), Poincar\'e inequality) as well as more general settings with semi-smooth or composite potentials. Our algorithm is based on the proximal sampler introduced in~\citet{lee2021structured}. The performance of this proximal sampler is determined by that of the restricted Gaussian oracle (RGO), a key step in the proximal sampler. The main contribution of this work is an inexact realization of RGO based on approximate rejection sampling. To bound the inexactness of RGO, we establish a new concentration inequality for semi-smooth functions over Gaussian distributions, extending the well-known concentration inequality for Lipschitz functions. Applying our RGO implementation to the proximal sampler, we achieve state-of-the-art complexity bounds in almost all settings. For instance, for strongly log-concave distributions, 
    
[^31]: 迈向完全协变的机器学习

    Towards fully covariant machine learning. (arXiv:2301.13724v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.13724](http://arxiv.org/abs/2301.13724)

    本文探讨了机器学习中多个被动对称性的影响，并提出了关于机器学习实践中尊重被动对称性的 dos and don'ts。此外，还讨论了被动对称性与因果建模的关系，并指出在学习问题的目标是样本外推广时，实现被动对称性尤其有价值。

    

    任何对数据的表示都涉及到任意的研究者选择。由于这些选择是外部于数据生成过程的，每个选择都导致了一个确切的对称性，对应于将一个可能的表示转化为另一个表示的变换群。这些被动对称性包括坐标自由度、规范对称性和单位协变性，在物理学中都产生了重要的结果。在机器学习中，最明显的被动对称性是图的重新标记或置换对称性。我们的目标是理解这些被动对称性对机器学习的影响。如果要尊重被动对称性，我们讨论了机器学习实践中的应该和不应该。我们还讨论了与因果建模的联系，并认为在学习问题的目标是样本外推广时，实现被动对称性特别有价值。这篇论文是概念性的：它在物理学的语言之间进行翻译。

    Any representation of data involves arbitrary investigator choices. Because those choices are external to the data-generating process, each choice leads to an exact symmetry, corresponding to the group of transformations that takes one possible representation to another. These are the passive symmetries; they include coordinate freedom, gauge symmetry, and units covariance, all of which have led to important results in physics. In machine learning, the most visible passive symmetry is the relabeling or permutation symmetry of graphs. Our goal is to understand the implications for machine learning of the many passive symmetries in play. We discuss dos and don'ts for machine learning practice if passive symmetries are to be respected. We discuss links to causal modeling, and argue that the implementation of passive symmetries is particularly valuable when the goal of the learning problem is to generalize out of sample. This paper is conceptual: It translates among the languages of physic
    
[^32]: 对未知数据的泛化、逻辑推理和学位课程的概述

    Generalization on the Unseen, Logic Reasoning and Degree Curriculum. (arXiv:2301.13105v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13105](http://arxiv.org/abs/2301.13105)

    本文研究了在逻辑推理任务中对未知数据的泛化能力，提供了网络架构在该设置下的表现证据，发现了一类网络模型在未知数据上学习了最小度插值器，并对长度普通化现象提供了解释。

    

    本文考虑了逻辑（布尔）函数的学习，重点在于对未知数据的泛化（GOTU）设定，这是一种强大的分布外泛化的案例。这是由于某些推理任务（例如算术/逻辑）中数据的丰富组合性质使得代表性数据采样具有挑战性，并且在GOTU下成功学习为第一个“推理”学习者展示了一个小插图。然后，我们研究了通过(S)GD训练的不同网络架构在GOTU下的表现，并提供了理论和实验证据，证明了一个类别的网络模型（包括Transformer的实例、随机特征模型和对角线线性网络）在未知数据上学习了最小度插值器。我们还提供了证据表明，其他具有更大学习速率或均场网络的实例达到了渗漏最小度解。这些发现带来了两个影响：（1）我们提供了对长度普通化的解释

    This paper considers the learning of logical (Boolean) functions with focus on the generalization on the unseen (GOTU) setting, a strong case of out-of-distribution generalization. This is motivated by the fact that the rich combinatorial nature of data in certain reasoning tasks (e.g., arithmetic/logic) makes representative data sampling challenging, and learning successfully under GOTU gives a first vignette of an 'extrapolating' or 'reasoning' learner. We then study how different network architectures trained by (S)GD perform under GOTU and provide both theoretical and experimental evidence that for a class of network models including instances of Transformers, random features models, and diagonal linear networks, a min-degree-interpolator is learned on the unseen. We also provide evidence that other instances with larger learning rates or mean-field networks reach leaky min-degree solutions. These findings lead to two implications: (1) we provide an explanation to the length genera
    
[^33]: 支持向量回归: 风险四方框架

    Support Vector Regression: Risk Quadrangle Framework. (arXiv:2212.09178v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.09178](http://arxiv.org/abs/2212.09178)

    本文结合风险四方理论，研究了支持向量回归（SVR）。研究结果发现，SVR的两种形式对应于等效误差度量的最小化，同时加上正则化惩罚项。通过构造基本风险四方框，我们证明了SVR是对两个对称条件分位数的平均数的渐近无偏估计量。此外，我们证明了$\varepsilon$-SVR和$\nu$-SVR在一般随机环境下的等价性。

    

    本文在基本的风险四方理论的背景下研究了支持向量回归（SVR），该理论将优化、风险管理和统计估计联系起来。研究结果表明，SVR的两种形式，$\varepsilon$-SVR和$\nu$-SVR，都对应于等效误差度量（分别为Vapnik误差和CVaR范数）的最小化，同时加上正则化惩罚项。这些误差度量又定义了相应的风险四方框。通过构造与SVR对应的基本风险四方框，我们证明了SVR是两个对称条件分位数的平均数的渐近无偏估计量。此外，我们在一般随机环境中证明了$\varepsilon$-SVR和$\nu$-SVR的等价性。此外，SVR被表述为带有正则化惩罚项的正则偏离最小化问题。最后，推导了在风险四方框架中的SVR的对偶形式。

    This paper investigates Support Vector Regression (SVR) in the context of the fundamental risk quadrangle theory, which links optimization, risk management, and statistical estimation. It is shown that both formulations of SVR, $\varepsilon$-SVR and $\nu$-SVR, correspond to the minimization of equivalent error measures (Vapnik error and CVaR norm, respectively) with a regularization penalty. These error measures, in turn, define the corresponding risk quadrangles. By constructing the fundamental risk quadrangle, which corresponds to SVR, we show that SVR is the asymptotically unbiased estimator of the average of two symmetric conditional quantiles. Further, we prove the equivalence of the $\varepsilon$-SVR and $\nu$-SVR in a general stochastic setting. Additionally, SVR is formulated as a regular deviation minimization problem with a regularization penalty. Finally, the dual formulation of SVR in the risk quadrangle framework is derived.
    
[^34]: 通过隐式复合核将先验知识融入神经网络

    Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel. (arXiv:2205.07384v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.07384](http://arxiv.org/abs/2205.07384)

    本论文提出了一种通过深度学习和高斯过程的复合核来将先验知识融入神经网络的方法。通过隐式定义的神经网络核函数和选择的第二个核函数，可以模拟已知特性，并提高深度学习应用的性能。

    

    引导神经网络（NN）学习以先验知识是具有挑战性的。相比之下，许多已知特性，如空间平滑性或季节性，在高斯过程（GP）中通过选择适当的核函数来建模是直接的。许多深度学习应用可以通过建模这些已知特性来改进。例如，卷积神经网络（CNNs）广泛用于遥感，这受到强烈的季节效应影响。我们提出通过使用由神经网络隐式定义的核函数与选择用于建模已知特性的第二个核函数（例如季节性）相结合的复合核来结合深度学习和GP的建模能力。我们通过将深度网络和基于Nystrom近似的高效映射相结合来实现这一想法，将其称为隐式复合核（ICK）。然后，我们采用样本优化的方法来近似完整的GP后验分布。我们证明了ICK的有效性，并在遥感和时间序列的任务上进行了实验。

    It is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of deep learning and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). We implement this idea by combining a deep network and an efficient mapping based on the Nystrom approximation, which we call Implicit Composite Kernel (ICK). We then adopt a sample-then-optimize approach to approximate the full GP posterior distribution. We demons
    
[^35]: 准确的长期预测的概率自回归神经网络

    Probabilistic AutoRegressive Neural Networks for Accurate Long-range Forecasting. (arXiv:2204.09640v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.09640](http://arxiv.org/abs/2204.09640)

    PARNN是一种概率自回归神经网络模型，能够准确预测具有非平稳性、非线性、非周期性、长期依赖和混沌模式的复杂时间序列数据，并通过预测区间提供不确定性量化。

    

    预测时间序列数据是一个严重的研究领域，应用范围从股票价格到早期传染病预测。虽然已经提出了许多统计和机器学习方法，但实际预测问题通常需要将传统预测方法和现代神经网络模型相结合的混合解决方案。在这项研究中，我们介绍了概率自回归神经网络（PARNN），能够处理表现出非平稳性、非线性、非周期性、长期依赖和混沌模式的复杂时间序列数据。PARNN是通过改进自回归神经网络（ARNN）使用自回归积分移动平均（ARIMA）反馈误差进行构建的，结合了两种模型的可解释性、可扩展性和“白盒子般”的预测行为。值得注意的是，PARNN模型通过预测区间提供不确定性量化，使其与先进的深度学习工具区别开来。通过全面的计算。

    Forecasting time series data is a critical area of research with applications spanning from stock prices to early epidemic prediction. While numerous statistical and machine learning methods have been proposed, real-life prediction problems often require hybrid solutions that bridge classical forecasting approaches and modern neural network models. In this study, we introduce the Probabilistic AutoRegressive Neural Networks (PARNN), capable of handling complex time series data exhibiting non-stationarity, nonlinearity, non-seasonality, long-range dependence, and chaotic patterns. PARNN is constructed by improving autoregressive neural networks (ARNN) using autoregressive integrated moving average (ARIMA) feedback error, combining the explainability, scalability, and "white-box-like" prediction behavior of both models. Notably, the PARNN model provides uncertainty quantification through prediction intervals, setting it apart from advanced deep learning tools. Through comprehensive compu
    
[^36]: PyDTS：用于离散时间竞争风险（正则化）回归的 Python 包

    PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks. (arXiv:2204.05731v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.05731](http://arxiv.org/abs/2204.05731)

    PyDTS是一个用于离散时间生存数据半参数竞争风险模型的Python包，支持包括LASSO和弹性网等正则化回归方法。

    

    时间至事件分析（生存分析）用于响应时间是指预定事件发生的时间。由于时间本身是离散的或由于将失败时间分组为间隔或舍入测量，因此时间至事件数据有时是离散的。此外，个体的失败可能是几种不同的失败类型之一，称为竞争风险（事件）。大多数生存回归分析的方法和软件包假定时间是在连续尺度上测量的。众所周知，将标准的连续时间模型应用于离散时间数据可能导致离散时间模型的估计器存在偏差。介绍了 Python 包 PyDTS，用于模拟，估计和评估离散时间生存数据的半参数竞争风险模型。该包实现了快速过程，使有效地包括正则化回归方法，如 LASSO 和弹性网络等。一个模拟

    Time-to-event analysis (survival analysis) is used when the response of interest is the time until a pre-specified event occurs. Time-to-event data are sometimes discrete either because time itself is discrete or due to grouping of failure times into intervals or rounding off measurements. In addition, the failure of an individual could be one of several distinct failure types, known as competing risks (events). Most methods and software packages for survival regression analysis assume that time is measured on a continuous scale. It is well-known that naively applying standard continuous-time models with discrete-time data may result in biased estimators of the discrete-time models. The Python package PyDTS, for simulating, estimating and evaluating semi-parametric competing-risks models for discrete-time survival data, is introduced. The package implements a fast procedure that enables including regularized regression methods, such as LASSO and elastic net, among others. A simulation 
    
[^37]: 利用未标记数据扩展类别的开放集学习（Open-LACU）

    Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2002.01368](http://arxiv.org/abs/2002.01368)

    Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。

    

    对于半监督学习（SSL）和开放式识别（OSR），已经进行了许多尝试以合成单个训练策略。然而，每次尝试都违反了开放集定义，因为这些方法在未标记的训练集中包含新颖的类别。本研究提出了一种新的学习策略，其中分类器能够在观察到的和未观察到的新颖类别之间进行推广，从而定义了观察到新颖类别的背景类别和未观察到新颖类别的未知类别。通过分类这两种新颖类别的方式，Open-LACU能够提高训练的成本效益性，并确保在存在未观察到的新颖类别时进行安全分类。

    Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
    
[^38]: 了解具有非对称几何散射变换的图神经网络

    Understanding Graph Neural Networks with Asymmetric Geometric Scattering Transforms. (arXiv:1911.06253v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1911.06253](http://arxiv.org/abs/1911.06253)

    这项工作介绍了一种具有非对称几何散射变换的图神经网络，通过引入一类非对称小波，它统一和扩展了现有图形散射架构的理论结果，并为未来的深度学习架构为图形提供了基础。

    

    散射变换是一种基于小波的深度学习架构，作为卷积神经网络的模型。最近，有几篇工作引入了散射变换在非欧几里德设置（如图形）中的推广。我们的工作基于这些构造，引入了基于非常一般的非对称小波类的图形窗口化和非窗口化几何散射变换。我们证明了这些非对称图形散射变换与对称散射变换有许多相同的理论保证。因此，提出的构造统一和扩展了现有图形散射架构的已知理论结果。通过这样做，这项工作通过引入大量带有可证明稳定性和不变性保证的网络，有助于弥合几何散射和其他图神经网络之间的差距。这些结果为未来的深度学习架构为图形提供了基础。

    The scattering transform is a multilayered wavelet-based deep learning architecture that acts as a model of convolutional neural networks. Recently, several works have introduced generalizations of the scattering transform for non-Euclidean settings such as graphs. Our work builds upon these constructions by introducing windowed and non-windowed geometric scattering transforms for graphs based upon a very general class of asymmetric wavelets. We show that these asymmetric graph scattering transforms have many of the same theoretical guarantees as their symmetric counterparts. As a result, the proposed construction unifies and extends known theoretical results for many of the existing graph scattering architectures. In doing so, this work helps bridge the gap between geometric scattering and other graph neural networks by introducing a large family of networks with provable stability and invariance guarantees. These results lay the groundwork for future deep learning architectures for g
    

