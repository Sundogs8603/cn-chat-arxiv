# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications.](http://arxiv.org/abs/2306.04539) | 本文研究在只有带标签的单模态数据和自然出现的多模态数据的情况下，如何量化多模态交互的挑战，并提出了两个下界和一个上界来量化多模态交互量。 |
| [^2] | [Estimating Koopman operators with sketching to provably learn large scale dynamical systems.](http://arxiv.org/abs/2306.04520) | 本文提出利用随机投影技术优化了Koopman算子的估计器，加快了计算速度，并给出了精确的误差界限，提高了算法的可靠性。 |
| [^3] | [Fast Optimal Locally Private Mean Estimation via Random Projections.](http://arxiv.org/abs/2306.04444) | 提出了一种名为ProjUnit的算法框架，用于实现高效的本地隐私均值估计，通过随机投影低维空间实现最优解，且具有低通信复杂度和快速的服务器运行时间。 |
| [^4] | [Improving Diffusion-based Image Translation using Asymmetric Gradient Guidance.](http://arxiv.org/abs/2306.04396) | 本文提出了一种使用非对称梯度引导来指导扩散采样的反向过程的方法，以改善扩散图像翻译的风格转换和内容保留之间的平衡。 |
| [^5] | [Label Shift Quantification with Robustness Guarantees via Distribution Feature Matching.](http://arxiv.org/abs/2306.04376) | 本文提出一种名为DFM框架的方法，用于量化标签偏移，并证明了其性能上限和鲁棒性。使用基于核的DFM版本可以提高效率、可扩展性和鲁棒性。 |
| [^6] | [Learning via Wasserstein-Based High Probability Generalisation Bounds.](http://arxiv.org/abs/2306.04375) | 本文证明了基于Wasserstein距离的PAC-Bayesian泛化界限的新颖性，并提出了算法框架，该界限显著扩展了PAC-Bayesian界限的范围，并在经典的学习问题中展现了改进的泛化误差。 |
| [^7] | [Changing Data Sources in the Age of Machine Learning for Official Statistics.](http://arxiv.org/abs/2306.04338) | 本文总结了机器学习时代官方统计学中，数据源变更所带来的风险、责任和不确定性，并提供一份清单列出高频的变更起因和原因。 |
| [^8] | [Dear XAI Community, We Need to Talk! Fundamental Misconceptions in Current XAI Research.](http://arxiv.org/abs/2306.04292) | 当前XAI研究中存在基本误解，例如未明确解释技术的目的，依赖于关于深度学习算法所学“概念”的强烈假设等。我们需要采取措施使XAI成为更实质性的研究领域。 |
| [^9] | [Accounting For Informative Sampling When Learning to Forecast Treatment Outcomes Over Time.](http://arxiv.org/abs/2306.04255) | 本文针对存在信息抽样的观测数据，提出一种通过逆强度加权来学习治疗效果的通用框架，并提出了一种新方法TESAR-CDE。 |
| [^10] | [Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks.](http://arxiv.org/abs/2306.04251) | SGD在训练过度表达的网络时，会随机地将动态吸引到更简单的子网络，这种随机吸引性能够提高泛化能力。 |
| [^11] | [Causally Learning an Optimal Rework Policy.](http://arxiv.org/abs/2306.04223) | 本文利用双重/无偏机器学习方法研究了光电半导体制造中的返工步骤，为零件返工制定策略并从经验上估计它们的价值。 |
| [^12] | [Improving Hyperparameter Learning under Approximate Inference in Gaussian Process Models.](http://arxiv.org/abs/2306.04201) | 本文改进了高斯过程模型中的超参数学习，提出了一种混合训练方法来兼顾变分推断和期望传播方法，以优化超参数的学习目标，该方法实验结果表明有效性。 |
| [^13] | [End-to-End Learning for Stochastic Optimization: A Bayesian Perspective.](http://arxiv.org/abs/2306.04174) | 本文提出了一种基于贝叶斯视角的随机优化端到端学习方法，为经验风险最小化和分布式鲁棒优化问题提供新的端到端学习算法，方式主要是训练决策映射。该方法在合成的newsvendor问题和经济分配问题上均表现出显著的效果，同时也发现决策映射神经网络架构对测试性能的影响很大。 |
| [^14] | [MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY Estimation.](http://arxiv.org/abs/2306.04120) | MESSY估计方法是一种基于最大熵的随机和符号密度估计方法，通过构建基于梯度的漂移扩散过程来高效地找到最大熵分布的参数，支持高维问题，并具有优于现有最新方法的有效性和普适性。 |
| [^15] | [One-sided Matrix Completion from Two Observations Per Row.](http://arxiv.org/abs/2306.04049) | 本文研究了单边矩阵完成问题，在每行只有两个观测值的情况下，使用插值算法可以可靠恢复$X^TX$，进而恢复$X$的右奇异向量。 |
| [^16] | [Intervention Generalization: A View from Factor Graph Models.](http://arxiv.org/abs/2306.04027) | 本文提出了一种基于因子图模型的“干预因子模型”(IFM)方法，仅基于对操纵系统分布的因子分解的最小假设，以实现从过去的实验到新的条件的跃迁。 |
| [^17] | [Globally injective and bijective neural operators.](http://arxiv.org/abs/2306.03982) | 这篇论文研究了网络学习的运算符是否是单射和满射的情况，并给出了精确条件。它们提供的单射神经运算符是通用逼近器，并且使用有限秩神经网络实现它们，使得网络仍然单射。 |
| [^18] | [Stochastic Marginal Likelihood Gradients using Neural Tangent Kernels.](http://arxiv.org/abs/2306.03968) | 本文提出了使用神经切向核的随机边际似然梯度，可以加速基于梯度的超参数优化过程。 |
| [^19] | [PILLAR: How to make semi-private learning more effective.](http://arxiv.org/abs/2306.03962) | 本文提出了一种计算效率高的算法 PILLAR，可以在半监督半私有（SP）学习中明显降低私有标记样本复杂度，并可以在实际数据集上高效运行，可以利用在公共数据上预训练的网络提取的特征，并在实验证明了其显著有效性。 |
| [^20] | [Kernel Quadrature with Randomly Pivoted Cholesky.](http://arxiv.org/abs/2306.03955) | 本文提出了一种新的使用随机选择纯量分解算法的核求积方法，可以在达到可比的求积误差达到率的同时显著降低计算复杂度，并可以应用于任意核的复杂几何结构。 |
| [^21] | [Partial Inference in Structured Prediction.](http://arxiv.org/abs/2306.03949) | 本文研究了结构化预测中的问题，通过生成模型和凸优化算法，提出了可证明保证的部分标签恢复方法。 |
| [^22] | [Switching Autoregressive Low-rank Tensor Models.](http://arxiv.org/abs/2306.03291) | 该文提出了一种切换自回归低秩张量（SALT）模型，它将自回归隐Markov模型（ARHMM）和切换线性动态系统（SLDS）的优点结合起来，通过低秩参数化提高了模型性能。 |
| [^23] | [Solving NP-hard Min-max Routing Problems as Sequential Generation with Equity Context.](http://arxiv.org/abs/2306.02689) | 本文提出了一个新的深度学习框架Equity-Transformer来解决大规模的最小最大路径问题。该模型利用可扩展的深度学习模型进行顺序决策，并生成考虑公平工作负载的顺序动作。研究显示，Equity-Transformer在两个代表性最小最大路径问题中具有卓越的性能。 |
| [^24] | [Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization.](http://arxiv.org/abs/2306.02688) | 本研究提出了一种名为Meta-SAGE的新方法，用于解决组合优化任务中深度强化学习模型可扩展性的问题。该方法通过比例元学习和时间表调整来适应模型，并真实地优化了相关任务的性能表现。 |
| [^25] | [Meta-learning Control Variates: Variance Reduction with Limited Data.](http://arxiv.org/abs/2303.04756) | 该论文提出了一种元学习控制变量的方法，可在有限数据的情况下减小蒙特卡罗估计器的方差，并对多个任务进行处理。 |
| [^26] | [Simplifying Momentum-based Riemannian Submanifold Optimization.](http://arxiv.org/abs/2302.09738) | 本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。 |
| [^27] | [Cliff-Learning.](http://arxiv.org/abs/2302.07348) | 本研究探究了基于基础模型的迁移学习在低数据状态下的数据缩放，发现了一种称为悬崖学习的现象，它反映了学习算法的先验知识与任务之间的兼容程度。 |
| [^28] | [Counterfactual Identifiability of Bijective Causal Models.](http://arxiv.org/abs/2302.02228) | 本文研究逆向可辨识双射因果模型，确立了其在三种常见因果结构下的逆向可辨识性，提出了一种实用的学习方法，可以用于有效的逆向预测估计。 |
| [^29] | [Interventional and Counterfactual Inference with Diffusion Models.](http://arxiv.org/abs/2302.00860) | 本论文提出了基于扩散模型的因果模型 (DCM)，它可以在只有观测数据和因果图可用的情况下进行干预和反事实推断，其具有较好的表现。同时，论文还提供了一种分析反事实估计的方法，可以应用于更广泛的场景。 |
| [^30] | [Differentially Private Distributed Bayesian Linear Regression with MCMC.](http://arxiv.org/abs/2301.13778) | 提出了一种带有 MCMC 的差分隐私分布式贝叶斯线性回归算法，提供了快速版本，具有计算上的优势，并在实际数据和模拟数据上进行数字实验，结果表明算法能够提供全面的估计和预测。 |
| [^31] | [Rigid body flows for sampling molecular crystal structures.](http://arxiv.org/abs/2301.11355) | 本文介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计。通过在单位四元数群上定义平滑和表现力强的流以及定义适当的密度，在旋转群上进行训练，我们可以成功地采样分子晶体结构。 |
| [^32] | [Random Grid Neural Processes for Parametric Partial Differential Equations.](http://arxiv.org/abs/2301.11040) | 本论文引入了一种新的随机网格神经算法，用于处理参数化偏微分方程，创新地将概率测度赋予空间域，形成高斯过程模型，提供了一种解决数据受噪声干扰问题的方法。 |
| [^33] | [Tracr: Compiled Transformers as a Laboratory for Interpretability.](http://arxiv.org/abs/2301.05062) | Tracr是一个编译器，将可读性强的程序编译成标准的仅解码变压器模型，该编译模型的已知结构可以用于设计实验和评估可解释方法。 |
| [^34] | [Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data.](http://arxiv.org/abs/2301.00437) | 研究者证明对于均方误差和交叉熵损失，深度线性网络中出现的全局解在不同数据上都具有神经塌陷的特性，即最后一层特征会崩溃为类均值，而这些类均值是等角紧框架的顶点。 |
| [^35] | [Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria.](http://arxiv.org/abs/2212.02457) | 协变量转移和对抗扰动对统计学习的稳健性提出了挑战。本文在无限维度的情况下研究了对抗协变量转移对外推区域的影响以及其对后续学习的平衡的影响。 |
| [^36] | [Synergies between Disentanglement and Sparsity: Generalization and Identifiability in Multi-Task Learning.](http://arxiv.org/abs/2211.14666) | 本文提供了证据表明，脱耦表示与稀疏基预测器相结合可提高泛化能力。我们提出了一个实用方法来学习这种表示，并在少样本分类基准测试中取得了竞争性的结果。 |
| [^37] | [Global Contrastive Batch Sampling via Optimization on Sample Permutations.](http://arxiv.org/abs/2210.12874) | 本论文提出了一种有效的替代硬负例挖掘的全局对比批量采样方法GCBS，能够提高对比学习任务的性能表现，易于实现且适用于各种对比学习方法。 |
| [^38] | [SGD with Large Step Sizes Learns Sparse Features.](http://arxiv.org/abs/2210.05337) | 本文展示了SGD使用大步长训练能够学习稀疏特征，在训练过程中，通过步长调度，梯度和噪声相互作用，共同驱动SGD动态穿过神经网络的损失平面，从而发现稀疏表示。 |
| [^39] | [Adversarially Robust PAC Learnability of Real-Valued Functions.](http://arxiv.org/abs/2206.12977) | 该论文研究了在实值函数中对抗鲁棒PAC学习性，发现有限胖折射维的类既可以在实现和不可知设置中被学习，凸函数类可以正确学习，而一些非凸函数类需要不正当的学习算法。 |
| [^40] | [A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel.](http://arxiv.org/abs/2206.12543) | 该论文提出了一种名为“逻辑和”的经验神经切向核近似方法，可以在计算量上显著降低，同时经过证明在宽的最终“读出”层的网络中初始化后收敛于真实的eNTK。 |
| [^41] | [Neural Diffusion Processes.](http://arxiv.org/abs/2206.03992) | 提出了一种新方法——神经扩散过程（NDPs），通过有限边缘学习从丰富的函数分布中进行采样。NDPs 可以捕获接近真实贝叶斯后验的函数分布，具有超越神经过程的表现，实现了多种下游任务，比如回归、隐式超参数边缘化、非高斯后验预测和全局优化。 |
| [^42] | [Gradient boosting for convex cone predict and optimize problems.](http://arxiv.org/abs/2204.06895) | 本文介绍了dboost，它是第一个为“预测，然后优化”问题设计的智能梯度提升实现。该框架支持凸二次锥规划，并通过自定义不动点映射的隐式微分来执行梯度提升，在实验中表现出色。 |
| [^43] | [Invariance in Policy Optimisation and Partial Identifiability in Reward Learning.](http://arxiv.org/abs/2203.07475) | 本文探讨了奖励学习中奖励函数的部分可识别性，并分析了这种部分可识别性对政策优化等下游任务的影响。同时提出了一个框架，对比奖励学习的数据源和下游任务，以其不变性为依据，对奖励学习的数据源的设计和选择产生影响。 |
| [^44] | [Warped Dynamic Linear Models for Time Series of Counts.](http://arxiv.org/abs/2110.14790) | 本文提出了一种新颖的半参数计数时间序列方法，即通过扭曲高斯DLMs进行建模，扭曲函数由转换算子和取整算子组成。我们开发了扭曲DLMs的共轭推断方法，生成了用于推断和预测的定制和高效的算法，包括蒙特卡罗模拟以进行离线分析。我们的方法在模拟和现实世界的计数时间序列中表现优异。 |
| [^45] | [Kernel Thinning.](http://arxiv.org/abs/2105.05842) | 核细化是一种更有效的压缩分布的方法，它可以将$n$点近似的分布压缩到具有可比较最坏积分误差的$\sqrt{n}$点近似，其亚指数保证类似于在$[0,1]^d$上均匀$\mathbb{P}$的经典准蒙特卡罗误差率，但适用于$\mathbb{R}^d$上的一般分布。 |
| [^46] | [Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy Back.](http://arxiv.org/abs/2002.10855) | 本论文提出了一种高斯分层潜在狄利克雷分配模型，通过引入层次结构恢复了捕捉多义性的能力，相对于基于高斯的模型具有更好的多义词检测性能，相对于潜在狄利克雷分配的层次模型具有更加简洁的主题表示。 |
| [^47] | [ROIPCA: An online memory-restricted PCA algorithm based on rank-one updates.](http://arxiv.org/abs/1911.11049) | 本文提出了基于秩一更新的ROIPCA和fROIPCA两种在线PCA算法，在内存限制的情况下，算法准确性好、运行时间短。其中fROIPCA为梯度算法，具有最优学习率。 |
| [^48] | [Nuclear Norm Regularized Estimation of Panel Regression Models.](http://arxiv.org/abs/1810.10987) | 本文提出两种最小化凸目标函数的新估计方法，其中核范数罚项有助于解决低秩回归器下的交互固定效应模型的潜在识别问题，并且具有很重要的计算优势。 |

# 详细

[^1]: 无标记多模态数据的多模态学习：保证和应用

    Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications. (arXiv:2306.04539v1 [cs.LG])

    [http://arxiv.org/abs/2306.04539](http://arxiv.org/abs/2306.04539)

    本文研究在只有带标签的单模态数据和自然出现的多模态数据的情况下，如何量化多模态交互的挑战，并提出了两个下界和一个上界来量化多模态交互量。

    

    在许多共同学习多个模态的机器学习系统中，一个核心的研究问题是理解多模态交互的本质：在从两个都没有的模态学习时出现了新的任务相关信息。我们在半监督的情况下研究这一交互量化的挑战，只使用带标签的单模态数据和自然出现的多模态数据（例如，无标签的图像和标题，视频和相应的音频）。利用精确的信息论交互定义，我们的主要贡献是推导下界和上界，量化这种半监督设置下的多模态交互量。我们提出了基于模态共享信息量和单独训练的单模态分类器之间的不一致性的两个下界，并通过连接到近似算法来推导上界。

    In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms fo
    
[^2]: 利用草图技术估计Koopman算子并可靠地学习大规模动态系统

    Estimating Koopman operators with sketching to provably learn large scale dynamical systems. (arXiv:2306.04520v1 [stat.ML])

    [http://arxiv.org/abs/2306.04520](http://arxiv.org/abs/2306.04520)

    本文提出利用随机投影技术优化了Koopman算子的估计器，加快了计算速度，并给出了精确的误差界限，提高了算法的可靠性。

    

    Koopman算子理论允许使用非参数机器学习算法来预测和分析复杂的动态系统。本文提出利用随机投影（草图技术）提高基于核的Koopman算子估计器的计算效率。我们在合成和大规模分子动力学数据集上进行了广泛实验，并建立了非渐进误差界，给出了统计学习速率和计算效率之间的权衡的精确刻画。我们的经验和理论分析表明，经过改进的估计器在保证准确性的同时大大提高了计算效率。

    The theory of Koopman operators allows to deploy non-parametric machine learning algorithms to predict and analyze complex dynamical systems. Estimators such as principal component regression (PCR) or reduced rank regression (RRR) in kernel spaces can be shown to provably learn Koopman operators from finite empirical observations of the system's time evolution. Scaling these approaches to very long trajectories is a challenge and requires introducing suitable approximations to make computations feasible. In this paper, we boost the efficiency of different kernel-based Koopman operator estimators using random projections (sketching). We derive, implement and test the new "sketched" estimators with extensive experiments on synthetic and large-scale molecular dynamics datasets. Further, we establish non asymptotic error bounds giving a sharp characterization of the trade-offs between statistical learning rates and computational efficiency. Our empirical and theoretical analysis shows that
    
[^3]: 通过随机投影快速获得最优的本地隐私均值估计

    Fast Optimal Locally Private Mean Estimation via Random Projections. (arXiv:2306.04444v1 [cs.LG])

    [http://arxiv.org/abs/2306.04444](http://arxiv.org/abs/2306.04444)

    提出了一种名为ProjUnit的算法框架，用于实现高效的本地隐私均值估计，通过随机投影低维空间实现最优解，且具有低通信复杂度和快速的服务器运行时间。

    

    本文研究了欧几里得空间中高维向量的本地隐私均值估计问题。现有算法要么产生次优误差，要么具有高通信和/或运行时间复杂度。我们提出了一种新的算法框架ProjUnit，用于隐私均值估计的算法具有计算效率高、通信复杂度低且误差与最优解之间的差距最大为1 + o(1)。我们的框架实现起来非常简单：每个随机化器将其输入投影到一个随机的低维子空间中，对结果进行归一化，然后在低维空间中运行一个最优算法，例如PrivUnitG。此外，我们展示了通过适当地协调设备之间的随机投影矩阵，可以实现快速的服务器运行时间。我们通过随机投影的性质分析了算法的误差，并研究了两种实例。最后，我们的实验结果表明，ProjUnit相比现有方法具有显著的性能优势，特别是在高维高斯混合数据集上表现出色。

    We study the problem of locally private mean estimation of high-dimensional vectors in the Euclidean ball. Existing algorithms for this problem either incur sub-optimal error or have high communication and/or run-time complexity. We propose a new algorithmic framework, ProjUnit, for private mean estimation that yields algorithms that are computationally efficient, have low communication complexity, and incur optimal error up to a $1+o(1)$-factor. Our framework is deceptively simple: each randomizer projects its input to a random low-dimensional subspace, normalizes the result, and then runs an optimal algorithm such as PrivUnitG in the lower-dimensional space. In addition, we show that, by appropriately correlating the random projection matrices across devices, we can achieve fast server run-time. We mathematically analyze the error of the algorithm in terms of properties of the random projections, and study two instantiations. Lastly, our experiments for private mean estimation and pr
    
[^4]: 使用非对称梯度引导来改进扩散图像翻译

    Improving Diffusion-based Image Translation using Asymmetric Gradient Guidance. (arXiv:2306.04396v1 [cs.CV])

    [http://arxiv.org/abs/2306.04396](http://arxiv.org/abs/2306.04396)

    本文提出了一种使用非对称梯度引导来指导扩散采样的反向过程的方法，以改善扩散图像翻译的风格转换和内容保留之间的平衡。

    

    最近，扩散模型在图像翻译任务中取得了显着进展。然而，由于其随机性，通常存在着风格转换和内容保留之间的平衡。为了解决这些挑战，本文提出了一种使用非对称梯度引导来指导扩散采样的反向过程的方法。这导致了更快和更稳定的图像操作，适用于基于文本和图片的图像翻译。

    Diffusion models have shown significant progress in image translation tasks recently. However, due to their stochastic nature, there's often a trade-off between style transformation and content preservation. Current strategies aim to disentangle style and content, preserving the source image's structure while successfully transitioning from a source to a target domain under text or one-shot image conditions. Yet, these methods often require computationally intense fine-tuning of diffusion models or additional neural networks. To address these challenges, here we present an approach that guides the reverse process of diffusion sampling by applying asymmetric gradient guidance. This results in quicker and more stable image manipulation for both text-guided and image-guided image translation. Our model's adaptability allows it to be implemented with both image- and latent-diffusion models. Experiments show that our method outperforms various state-of-the-art models in image translation ta
    
[^5]: 基于分布特征匹配的标签偏移量量化及其鲁棒性保证

    Label Shift Quantification with Robustness Guarantees via Distribution Feature Matching. (arXiv:2306.04376v1 [stat.ML])

    [http://arxiv.org/abs/2306.04376](http://arxiv.org/abs/2306.04376)

    本文提出一种名为DFM框架的方法，用于量化标签偏移，并证明了其性能上限和鲁棒性。使用基于核的DFM版本可以提高效率、可扩展性和鲁棒性。

    

    量化学习处理在标签偏移下估计目标标签分布的任务。本文首先提出了一个统一的框架，分布特征匹配（DFM），将先前文献中引入的各种估计器恢复为特定实例。我们推导了DFM程序的一般性能界，改进了先前在特定情况下推导的界限的若干关键方面。然后，我们将这一分析扩展到研究DFM程序在未精确假设标签偏移量的情况下的鲁棒性，特别是在目标受到未知分布污染的情况下。这些理论发现在模拟和实际数据集上得到了详细的数字研究确认。我们还使用随机傅里叶特征原理介绍了一种高效，可扩展且具有鲁棒性的基于核的DFM版本。

    Quantification learning deals with the task of estimating the target label distribution under label shift. In this paper, we first present a unifying framework, distribution feature matching (DFM), that recovers as particular instances various estimators introduced in previous literature. We derive a general performance bound for DFM procedures, improving in several key aspects upon previous bounds derived in particular cases. We then extend this analysis to study robustness of DFM procedures in the misspecified setting under departure from the exact label shift hypothesis, in particular in the case of contamination of the target by an unknown distribution. These theoretical findings are confirmed by a detailed numerical study on simulated and real-world datasets. We also introduce an efficient, scalable and robust version of kernel-based DFM using the Random Fourier Feature principle.
    
[^6]: 基于Wasserstein的高概率泛化界限下的学习

    Learning via Wasserstein-Based High Probability Generalisation Bounds. (arXiv:2306.04375v1 [stat.ML])

    [http://arxiv.org/abs/2306.04375](http://arxiv.org/abs/2306.04375)

    本文证明了基于Wasserstein距离的PAC-Bayesian泛化界限的新颖性，并提出了算法框架，该界限显著扩展了PAC-Bayesian界限的范围，并在经典的学习问题中展现了改进的泛化误差。

    

    在结构风险最小化（SRM）中，最小化总体风险或泛化差距上限被广泛使用，这尤其是PAC-Bayesian学习的核心。尽管近年来其取得了成功并吸引了越来越多的关注，但PAC-Bayesian框架的局限是大多数界限涉及Kullback-Leibler（KL）散度项（或其变化），这可能表现出不规则行为并无法捕捉学习问题的底层几何结构，因此限制了其在实际应用中的使用。最近的一些研究企图用Wasserstein距离替换PAC-Bayesian界限中的KL散度。即使这些界限在一定程度上缓解了上述问题，但它们要么保持期望，要么对有界损失有效，要么难以在SRM框架中最小化。在这项工作中，我们为这一研究方向做出了贡献，证明了基于Wasserstein距离的PAC-Bayesian泛化界限的新颖性，并且我们的界限以显著性地扩展了PAC-Bayesian界限的范围，并在几种经典的学习问题中展现了改进的泛化误差。此外，我们提出了一种算法框架，用于学习新的界限，并在各种数据集上展示了有前途的实验结果。

    Minimising upper bounds on the population risk or the generalisation gap has been widely used in structural risk minimisation (SRM) - this is in particular at the core of PAC-Bayesian learning. Despite its successes and unfailing surge of interest in recent years, a limitation of the PAC-Bayesian framework is that most bounds involve a Kullback-Leibler (KL) divergence term (or its variations), which might exhibit erratic behavior and fail to capture the underlying geometric structure of the learning problem - hence restricting its use in practical applications. As a remedy, recent studies have attempted to replace the KL divergence in the PAC-Bayesian bounds with the Wasserstein distance. Even though these bounds alleviated the aforementioned issues to a certain extent, they either hold in expectation, are for bounded losses, or are nontrivial to minimize in an SRM framework. In this work, we contribute to this line of research and prove novel Wasserstein distance-based PAC-Bayesian ge
    
[^7]: 机器学习时代统计学数据来源的变更

    Changing Data Sources in the Age of Machine Learning for Official Statistics. (arXiv:2306.04338v1 [stat.ML])

    [http://arxiv.org/abs/2306.04338](http://arxiv.org/abs/2306.04338)

    本文总结了机器学习时代官方统计学中，数据源变更所带来的风险、责任和不确定性，并提供一份清单列出高频的变更起因和原因。

    

    数据科学在官方统计数据的生产中变得越来越重要，因为它使大量数据的自动收集、处理和分析成为可能。随着这样的数据科学方法的应用，它使得报告变得更及时、更有深度和更具灵活性。然而，数据科学驱动的统计数据的质量和完整性取决于数据源和支持它们的机器学习技术的准确性和可靠性。特别地，数据源的变更是不可避免的，它们会引发重大的风险，在机器学习驱动的统计学中必须得到妥善处理。本文概述了在官方统计机器学习中，与数据源变更相关的主要风险、责任和不确定性。我们提供了一个清单，列出了数据源变更最常见的起因和原因，不仅是在技术层面，而且涉及所有权、伦理和法规等方面。

    Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.  This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, 
    
[^8]: 亲爱的XAI社区，我们需要谈谈！关于当前XAI研究中存在的基本误解

    Dear XAI Community, We Need to Talk! Fundamental Misconceptions in Current XAI Research. (arXiv:2306.04292v1 [cs.AI])

    [http://arxiv.org/abs/2306.04292](http://arxiv.org/abs/2306.04292)

    当前XAI研究中存在基本误解，例如未明确解释技术的目的，依赖于关于深度学习算法所学“概念”的强烈假设等。我们需要采取措施使XAI成为更实质性的研究领域。

    

    尽管该领域已经取得了进展，但目前XAI研究的重要部分仍未建立在坚实的概念、伦理或方法论基础上。令人遗憾的是，这些基础薄弱的部分并没有减少，而是不断增长。许多解释技术仍然没有澄清其目的，而是用越来越花哨的热点图或看似相关的基准来宣传。此外，解释技术的动机存在问题，例如建立信任，或依赖于关于深度学习算法所学“概念”的强烈假设。本文中，我们突出并讨论了当前XAI研究中的这些和其他误解，同时提出了使XAI成为更实质性研究领域的步骤。

    Despite progress in the field, significant parts of current XAI research are still not on solid conceptual, ethical, or methodological grounds. Unfortunately, these unfounded parts are not on the decline but continue to grow. Many explanation techniques are still proposed without clarifying their purpose. Instead, they are advertised with ever more fancy-looking heatmaps or only seemingly relevant benchmarks. Moreover, explanation techniques are motivated with questionable goals, such as building trust, or rely on strong assumptions about the 'concepts' that deep learning algorithms learn. In this paper, we highlight and discuss these and other misconceptions in current XAI research. We also suggest steps to make XAI a more substantive area of research.
    
[^9]: 当学习随时间预测治疗效果时考虑信息抽样

    Accounting For Informative Sampling When Learning to Forecast Treatment Outcomes Over Time. (arXiv:2306.04255v1 [stat.ML])

    [http://arxiv.org/abs/2306.04255](http://arxiv.org/abs/2306.04255)

    本文针对存在信息抽样的观测数据，提出一种通过逆强度加权来学习治疗效果的通用框架，并提出了一种新方法TESAR-CDE。

    

    机器学习在准确预测治疗效果随时间变化方面具有巨大潜力，这最终可以使更多实际应用中采用个性化治疗策略成为可能。然而，机器学习领域在这个主题上被大量忽视的一个重要挑战是观测数据中存在信息抽样。当实例在时间上不规则观测时，抽样时间通常不是随机的，而是具有信息性的 - 取决于实例的特征、过去的结果和施用的治疗方案。在本文中，我们将信息抽样形式化为一个协变换移问题，并证明如果不适当地考虑它会限制治疗效果的准确估计。为了克服这个挑战，我们提出了一个通用框架，用于在存在信息抽样的情况下学习治疗效果，并提出了一种新的方法，TESAR-CDE，来实现这个框架。

    Machine learning (ML) holds great potential for accurately forecasting treatment outcomes over time, which could ultimately enable the adoption of more individualized treatment strategies in many practical applications. However, a significant challenge that has been largely overlooked by the ML literature on this topic is the presence of informative sampling in observational data. When instances are observed irregularly over time, sampling times are typically not random, but rather informative -- depending on the instance's characteristics, past outcomes, and administered treatments. In this work, we formalize informative sampling as a covariate shift problem and show that it can prohibit accurate estimation of treatment outcomes if not properly accounted for. To overcome this challenge, we present a general framework for learning treatment outcomes in the presence of informative sampling using inverse intensity-weighting, and propose a novel method, TESAR-CDE, that instantiates this f
    
[^10]: 随机坍缩：如何利用梯度噪声使SGD动态趋向更简单的子网络

    Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks. (arXiv:2306.04251v1 [cs.LG])

    [http://arxiv.org/abs/2306.04251](http://arxiv.org/abs/2306.04251)

    SGD在训练过度表达的网络时，会随机地将动态吸引到更简单的子网络，这种随机吸引性能够提高泛化能力。

    

    本文揭示了随机梯度下降（SGD）的一个强烈隐式偏好，它将过度表达的网络驱动到更简单的子网络，从而大大减少了独立参数的数量，并提高了泛化能力。为了揭示这个偏好，我们识别了不变集，或者说是SGD未修改的参数空间的子集。我们专注于两类不变集，它们对应于现代架构中常见的更简单的子网络。我们的分析揭示了SGD在这些简单不变集方面具有随机吸引性的特性。我们根据损失景观在不变集周围的曲率和随机梯度引入的噪声之间的竞争建立了一种随机吸引性的充分条件。值得注意的是，我们发现增加噪声水平会增强吸引力，导致与鞍点或训练损失的局部极大值相关的吸引不变集的出现。

    In this work, we reveal a strong implicit bias of stochastic gradient descent (SGD) that drives overly expressive networks to much simpler subnetworks, thereby dramatically reducing the number of independent parameters, and improving generalization. To reveal this bias, we identify invariant sets, or subsets of parameter space that remain unmodified by SGD. We focus on two classes of invariant sets that correspond to simpler subnetworks and commonly appear in modern architectures. Our analysis uncovers that SGD exhibits a property of stochastic attractivity towards these simpler invariant sets. We establish a sufficient condition for stochastic attractivity based on a competition between the loss landscape's curvature around the invariant set and the noise introduced by stochastic gradients. Remarkably, we find that an increased level of noise strengthens attractivity, leading to the emergence of attractive invariant sets associated with saddle-points or local maxima of the train loss.
    
[^11]: 学习制定最佳返工策略的因果关系研究

    Causally Learning an Optimal Rework Policy. (arXiv:2306.04223v1 [stat.ML])

    [http://arxiv.org/abs/2306.04223](http://arxiv.org/abs/2306.04223)

    本文利用双重/无偏机器学习方法研究了光电半导体制造中的返工步骤，为零件返工制定策略并从经验上估计它们的价值。

    

    在制造业中，返工是一种旨在消除错误或纠正不符合所需质量标准的产品的可选生产步骤。重新加工生产批次涉及重复以前的生产阶段，并进行调整以确保最终产品符合所需规格。虽然提供了改善产量从而增加生产批次收入的机会，但返工步骤也会产生额外的成本。此外，重新加工已满足目标规格的零件可能会损坏它们并降低产量。本文应用双重/无偏机器学习（DML）来估计光电半导体制造中颜色转换过程中一次返工步骤对最终产品产量的条件处理效应。 我们利用DoubleML实现制定零件返工策略并从经验上估计它们的价值。从我们的因果机器学习分析中

    In manufacturing, rework refers to an optional step of a production process which aims to eliminate errors or remedy products that do not meet the desired quality standards. Reworking a production lot involves repeating a previous production stage with adjustments to ensure that the final product meets the required specifications. While offering the chance to improve the yield and thus increase the revenue of a production lot, a rework step also incurs additional costs. Additionally, the rework of parts that already meet the target specifications may damage them and decrease the yield. In this paper, we apply double/debiased machine learning (DML) to estimate the conditional treatment effect of a rework step during the color conversion process in opto-electronic semiconductor manufacturing on the final product yield. We utilize the implementation DoubleML to develop policies for the rework of components and estimate their value empirically. From our causal machine learning analysis we 
    
[^12]: 在高斯过程模型的近似推断中改善超参数学习

    Improving Hyperparameter Learning under Approximate Inference in Gaussian Process Models. (arXiv:2306.04201v1 [cs.LG])

    [http://arxiv.org/abs/2306.04201](http://arxiv.org/abs/2306.04201)

    本文改进了高斯过程模型中的超参数学习，提出了一种混合训练方法来兼顾变分推断和期望传播方法，以优化超参数的学习目标，该方法实验结果表明有效性。

    

    在具有非共轭似然函数的高斯过程（GP）模型中，近似推断与模型超参数的学习纠缠在一起。我们改进了 GP 模型中的超参数学习，并关注变分推断（VI）与学习目标之间的相互作用。虽然 VI 对边缘似然函数的下界是推断近似后验的合适目标，但我们发现像期望传播（EP）中直接逼近边缘似然函数是更适合超参数优化的学习目标。我们设计了一个混合训练过程，将最佳效果结合到一起：利用共轭计算 VI 进行推断，并使用类似于 EP 的边缘似然函数逼近进行超参数学习。我们比较了 VI、EP、Laplace 近似和我们提出的训练过程，并在广泛的数据集上经验证明了我们的提议的有效性。

    Approximate inference in Gaussian process (GP) models with non-conjugate likelihoods gets entangled with the learning of the model hyperparameters. We improve hyperparameter learning in GP models and focus on the interplay between variational inference (VI) and the learning target. While VI's lower bound to the marginal likelihood is a suitable objective for inferring the approximate posterior, we show that a direct approximation of the marginal likelihood as in Expectation Propagation (EP) is a better learning objective for hyperparameter optimization. We design a hybrid training procedure to bring the best of both worlds: it leverages conjugate-computation VI for inference and uses an EP-like marginal likelihood approximation for hyperparameter learning. We compare VI, EP, Laplace approximation, and our proposed training procedure and empirically demonstrate the effectiveness of our proposal across a wide range of data sets.
    
[^13]: 基于贝叶斯视角的随机优化端到端学习方法

    End-to-End Learning for Stochastic Optimization: A Bayesian Perspective. (arXiv:2306.04174v1 [math.OC])

    [http://arxiv.org/abs/2306.04174](http://arxiv.org/abs/2306.04174)

    本文提出了一种基于贝叶斯视角的随机优化端到端学习方法，为经验风险最小化和分布式鲁棒优化问题提供新的端到端学习算法，方式主要是训练决策映射。该方法在合成的newsvendor问题和经济分配问题上均表现出显著的效果，同时也发现决策映射神经网络架构对测试性能的影响很大。

    

    我们提出了一种基于贝叶斯视角的随机优化端到端学习方法，该方法采用了标准端到端学习算法的思想，训练了一个后验贝叶斯行动映射。在此基础上，我们为解决经验风险最小化和分布式鲁棒优化问题提出了新的端到端学习算法。通过合成的newsvendor问题和基于真实数据的经济分配问题的数值结果，我们展示了不同训练方案之间的关键差异以及决策映射神经网络架构对测试性能的影响。

    We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.
    
[^14]: MESSY估计：基于最大熵的随机和符号密度估计

    MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY Estimation. (arXiv:2306.04120v1 [cs.LG])

    [http://arxiv.org/abs/2306.04120](http://arxiv.org/abs/2306.04120)

    MESSY估计方法是一种基于最大熵的随机和符号密度估计方法，通过构建基于梯度的漂移扩散过程来高效地找到最大熵分布的参数，支持高维问题，并具有优于现有最新方法的有效性和普适性。

    

    我们引入了基于最大熵的随机和符号密度估计方法MESSY。所提出的方法使用梯度流的矩将概率密度函数从样本中恢复为符号表达式，并将ansatz作为驱动力。特别地，我们构建了一个基于梯度的漂移扩散过程，将未知分布函数的样本与猜测的符号表达式相连。然后，我们展示出当猜测分布具有最大熵形式时，可以通过使用提供的样本的矩构建的线性方程组高效地找到该分布的参数。此外，我们使用符号回归来探索平滑函数的空间，并找到导致最大熵泛函指数的最优基函数，以获得良好条件。该方法在随机搜索的每次迭代中的成本与样本数量呈线性关系，与变量数量呈二次关系，使其可扩展到高维问题。数值实验显示出所提出方法的有效性和普适性，与现有的最新方法相比。

    We introduce MESSY estimation, a Maximum-Entropy based Stochastic and Symbolic densitY estimation method. The proposed approach recovers probability density functions symbolically from samples using moments of a Gradient flow in which the ansatz serves as the driving force. In particular, we construct a gradient-based drift-diffusion process that connects samples of the unknown distribution function to a guess symbolic expression. We then show that when the guess distribution has the maximum entropy form, the parameters of this distribution can be found efficiently by solving a linear system of equations constructed using the moments of the provided samples. Furthermore, we use Symbolic regression to explore the space of smooth functions and find optimal basis functions for the exponent of the maximum entropy functional leading to good conditioning. The cost of the proposed method in each iteration of the random search is linear with the number of samples and quadratic with the number 
    
[^15]: 从每行两个观测来看的单边矩阵完成问题

    One-sided Matrix Completion from Two Observations Per Row. (arXiv:2306.04049v1 [cs.LG])

    [http://arxiv.org/abs/2306.04049](http://arxiv.org/abs/2306.04049)

    本文研究了单边矩阵完成问题，在每行只有两个观测值的情况下，使用插值算法可以可靠恢复$X^TX$，进而恢复$X$的右奇异向量。

    

    给定一个低秩矩阵$X$的一些观测值，矩阵完成问题是推测缺失值的问题，它是形式化描述一系列需要估计缺失数据的现实世界设置。然而，当观测到的条目太少而无法完成矩阵时，可以可靠恢复基础矩阵的哪些其他方面？我们研究了一个这样的问题设置，即“单边”矩阵完成，我们的目标是恢复$X$的右奇异向量，即使在无法恢复左奇异向量的情况下，即当行数大于列数且观测的很少时。我们提出了一个自然算法，涉及到矩阵$X^TX$中缺失值的插值，并证明即使在每行只有两个观测值的情况下，只要我们有至少$\Omega(r^2 d \log d)$行，其中$r$为秩，$d$为列数，我们就可以可靠地恢复$X^TX$。我们评估了我们的算法在单边矩阵完成问题以及推荐任务上的表现，并发现它在所考虑的设置下优于现有的方法。

    Given only a few observed entries from a low-rank matrix $X$, matrix completion is the problem of imputing the missing entries, and it formalizes a wide range of real-world settings that involve estimating missing data. However, when there are too few observed entries to complete the matrix, what other aspects of the underlying matrix can be reliably recovered? We study one such problem setting, that of "one-sided" matrix completion, where our goal is to recover the right singular vectors of $X$, even in the regime where recovering the left singular vectors is impossible, which arises when there are more rows than columns and very few observations. We propose a natural algorithm that involves imputing the missing values of the matrix $X^TX$ and show that even with only two observations per row in $X$, we can provably recover $X^TX$ as long as we have at least $\Omega(r^2 d \log d)$ rows, where $r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on one-sided reco
    
[^16]: 因子图模型视角下的干预泛化

    Intervention Generalization: A View from Factor Graph Models. (arXiv:2306.04027v1 [stat.ML])

    [http://arxiv.org/abs/2306.04027](http://arxiv.org/abs/2306.04027)

    本文提出了一种基于因子图模型的“干预因子模型”(IFM)方法，仅基于对操纵系统分布的因子分解的最小假设，以实现从过去的实验到新的条件的跃迁。

    

    因果推断的一个目标是从过去的实验和观察数据推广到新的条件。在训练数据中提供足够多的实验的情况下，理论上可能最终学习从新的实验条件到感兴趣的结果的映射，但是处理大量可能的干预组合空间很困难。在典型的稀疏实验设计下，如果不依赖于重的规则化或先验分布，这种映射是不适当的。这样的假设可能是可靠的，也可能是不可靠的，很难辩护或测试。本文从因子图模型的语言角度深入探讨如何保证从过去的实验到新的条件的跃迁，仅基于对操纵系统分布的因子分解的最小假设。假设的“干预因子模型”可能并不总是有用的，但是它很方便地处理了大量可能的干预空间。

    One of the goals of causal inference is to generalize from past experiments and observational data to novel conditions. While it is in principle possible to eventually learn a mapping from a novel experimental condition to an outcome of interest, provided a sufficient variety of experiments is available in the training data, coping with a large combinatorial space of possible interventions is hard. Under a typical sparse experimental design, this mapping is ill-posed without relying on heavy regularization or prior distributions. Such assumptions may or may not be reliable, and can be hard to defend or test. In this paper, we take a close look at how to warrant a leap from past experiments to novel conditions based on minimal assumptions about the factorization of the distribution of the manipulated system, communicated in the well-understood language of factor graph models. A postulated $\textit{interventional factor model}$ (IFM) may not always be informative, but it conveniently abs
    
[^17]: 全球可测和可逆神经运算符

    Globally injective and bijective neural operators. (arXiv:2306.03982v1 [cs.LG])

    [http://arxiv.org/abs/2306.03982](http://arxiv.org/abs/2306.03982)

    这篇论文研究了网络学习的运算符是否是单射和满射的情况，并给出了精确条件。它们提供的单射神经运算符是通用逼近器，并且使用有限秩神经网络实现它们，使得网络仍然单射。

    

    最近，在运算学习领域，网络从基本上无限维度的视角学习函数空间之间的运算符，我们针对网络学习的运算符是单射和满射的情况进行了研究。

    Recently there has been great interest in operator learning, where networks learn operators between function spaces from an essentially infinite-dimensional perspective. In this work we present results for when the operators learned by these networks are injective and surjective. As a warmup, we combine prior work in both the finite-dimensional ReLU and operator learning setting by giving sharp conditions under which ReLU layers with linear neural operators are injective. We then consider the case the case when the activation function is pointwise bijective and obtain sufficient conditions for the layer to be injective. We remark that this question, while trivial in the finite-rank case, is subtler in the infinite-rank case and is proved using tools from Fredholm theory. Next, we prove that our supplied injective neural operators are universal approximators and that their implementation, with finite-rank neural networks, are still injective. This ensures that injectivity is not `lost' 
    
[^18]: 使用神经切向核的随机边际似然梯度。

    Stochastic Marginal Likelihood Gradients using Neural Tangent Kernels. (arXiv:2306.03968v1 [stat.ML])

    [http://arxiv.org/abs/2306.03968](http://arxiv.org/abs/2306.03968)

    本文提出了使用神经切向核的随机边际似然梯度，可以加速基于梯度的超参数优化过程。

    

    选择深度学习中的超参数对其有效性有重大影响，但需要人工努力和专业知识。最近的研究表明，使用拉普拉斯近似的贝叶斯模型选择能够像使用梯度优化标准神经网络参数一样优化这些超参数，并使用训练数据进行训练。然而，估计单个超参数梯度需要通过整个数据集，限制了这些算法的可伸缩性。在这项研究中，我们通过引入线性化拉普拉斯逼近的下限来克服这个问题。与以前的估计器不同，这些下限适用于基于随机梯度的优化，并允许在估计精度和计算复杂性之间进行权衡。我们使用线性化拉普拉斯的函数空间形式导出了它们，这可以使用神经切向核进行估计。在实验中，我们展示了这些估计器可以显著加速基于梯度的超参数优化过程。

    Selecting hyperparameters in deep learning greatly impacts its effectiveness but requires manual effort and expertise. Recent works show that Bayesian model selection with Laplace approximations can allow to optimize such hyperparameters just like standard neural network parameters using gradients and on the training data. However, estimating a single hyperparameter gradient requires a pass through the entire dataset, limiting the scalability of such algorithms. In this work, we overcome this issue by introducing lower bounds to the linearized Laplace approximation of the marginal likelihood. In contrast to previous estimators, these bounds are amenable to stochastic-gradient-based optimization and allow to trade off estimation accuracy against computational complexity. We derive them using the function-space form of the linearized Laplace, which can be estimated using the neural tangent kernel. Experimentally, we show that the estimators can significantly accelerate gradient-based hyp
    
[^19]: PILLAR：如何使半私有学习更有效

    PILLAR: How to make semi-private learning more effective. (arXiv:2306.03962v1 [cs.LG])

    [http://arxiv.org/abs/2306.03962](http://arxiv.org/abs/2306.03962)

    本文提出了一种计算效率高的算法 PILLAR，可以在半监督半私有（SP）学习中明显降低私有标记样本复杂度，并可以在实际数据集上高效运行，可以利用在公共数据上预训练的网络提取的特征，并在实验证明了其显著有效性。

    

    在半监督半私有（SP）学习中，学习者可以访问公共的未标记数据和私有的标记数据。我们提出了一种计算效率高的算法，假设数据符合一定条件，可以明显降低私有标记样本复杂度，并可以在实际数据集上高效运行。为此，我们利用在公共数据（标记或未标记）上预训练的网络提取的特征，这些特征的分布可能与进行SP学习的分布显著不同。为了验证其实证有效性，我们提出了多种在严格的隐私约束（\(\epsilon=0.1\))和低数据量情况下的实验。在所有这些设置中，我们的算法表现出显著优于使用类似数量的公共数据的现有基线的性能。

    In Semi-Supervised Semi-Private (SP) learning, the learner has access to both public unlabelled and private labelled data. We propose a computationally efficient algorithm that, under mild assumptions on the data, provably achieves significantly lower private labelled sample complexity and can be efficiently run on real-world datasets. For this purpose, we leverage the features extracted by networks pre-trained on public (labelled or unlabelled) data, whose distribution can significantly differ from the one on which SP learning is performed. To validate its empirical effectiveness, we propose a wide variety of experiments under tight privacy constraints (\(\epsilon=0.1\)) and with a focus on low-data regimes. In all of these settings, our algorithm exhibits significantly improved performance over available baselines that use similar amounts of public data.
    
[^20]: 随机选择纯量分解的核求积方法

    Kernel Quadrature with Randomly Pivoted Cholesky. (arXiv:2306.03955v1 [math.NA])

    [http://arxiv.org/abs/2306.03955](http://arxiv.org/abs/2306.03955)

    本文提出了一种新的使用随机选择纯量分解算法的核求积方法，可以在达到可比的求积误差达到率的同时显著降低计算复杂度，并可以应用于任意核的复杂几何结构。

    

    本文使用随机选择纯量分解的采样算法提出了一种新的重现核希尔伯特空间函数求积规则。所得的计算过程与既有的核求积方法相比，在精度和求解复杂度方面具有更好的性能。理论和实验结果表明，随机选择纯量分解的方法快速且具有可比的求积误差达到率，与基于连续体积采样、稀疏化和重组的更为昂贵的求积方案相匹配。随机选择纯量分解易于适应任意核的复杂几何结构，为核求积开辟了新的潜力。

    This paper presents new quadrature rules for functions in a reproducing kernel Hilbert space using nodes drawn by a sampling algorithm known as randomly pivoted Cholesky. The resulting computational procedure compares favorably to previous kernel quadrature methods, which either achieve low accuracy or require solving a computationally challenging sampling problem. Theoretical and numerical results show that randomly pivoted Cholesky is fast and achieves comparable quadrature error rates to more computationally expensive quadrature schemes based on continuous volume sampling, thinning, and recombination. Randomly pivoted Cholesky is easily adapted to complicated geometries with arbitrary kernels, unlocking new potential for kernel quadrature.
    
[^21]: 结构化预测中的部分推断

    Partial Inference in Structured Prediction. (arXiv:2306.03949v1 [cs.LG])

    [http://arxiv.org/abs/2306.03949](http://arxiv.org/abs/2306.03949)

    本文研究了结构化预测中的问题，通过生成模型和凸优化算法，提出了可证明保证的部分标签恢复方法。

    

    本文探讨了在结构化预测中部分推断的问题。使用生成模型方法，研究在标签图上最大化一种包含一元和二元因子的评分函数的任务。通过采用两阶段凸优化算法进行标签恢复，分析了大多数标签可恢复的条件。提出了一种新的Karush-Kuhn-Tucker（KKT）条件和原始对偶构造的观点，并提供了具有可证明保证的部分恢复的统计和拓扑要求。

    In this paper, we examine the problem of partial inference in the context of structured prediction. Using a generative model approach, we consider the task of maximizing a score function with unary and pairwise potentials in the space of labels on graphs. Employing a two-stage convex optimization algorithm for label recovery, we analyze the conditions under which a majority of the labels can be recovered. We introduce a novel perspective on the Karush-Kuhn-Tucker (KKT) conditions and primal and dual construction, and provide statistical and topological requirements for partial recovery with provable guarantees.
    
[^22]: 切换自回归低秩张量模型

    Switching Autoregressive Low-rank Tensor Models. (arXiv:2306.03291v1 [cs.LG])

    [http://arxiv.org/abs/2306.03291](http://arxiv.org/abs/2306.03291)

    该文提出了一种切换自回归低秩张量（SALT）模型，它将自回归隐Markov模型（ARHMM）和切换线性动态系统（SLDS）的优点结合起来，通过低秩参数化提高了模型性能。

    

    时序分析中一个重要的问题是对具有时变动力学的系统进行建模。共同连续和离散潜态的概率模型为这样的数据提供了可解释、高效和实验性有用的描述。常用的模型包括自回归隐Markov模型（ARHMM）和切换线性动态系统（SLDS），它们各有优缺点。ARHMM允许精确推理和简单的参数估计，但在对长依赖关系建模时具有参数密集性，因此容易出现过拟合。相比之下，通过马尔可夫潜态动力学，SLDS可以以参数高效的方式捕捉长距离依赖性，但困难的参数估计任务和一个难以处理的似然函数却是其具有挑战性的地方。在本文中，我们提出了切换自回归低秩张量（SALT）模型，该模型保留了两种方法的优点，同时改善了其局限性。SALT将ARHMM的张量参数化为低秩形式。

    An important problem in time-series analysis is modeling systems with time-varying dynamics. Probabilistic models with joint continuous and discrete latent states offer interpretable, efficient, and experimentally useful descriptions of such data. Commonly used models include autoregressive hidden Markov models (ARHMMs) and switching linear dynamical systems (SLDSs), each with its own advantages and disadvantages. ARHMMs permit exact inference and easy parameter estimation, but are parameter intensive when modeling long dependencies, and hence are prone to overfitting. In contrast, SLDSs can capture long-range dependencies in a parameter efficient way through Markovian latent dynamics, but present an intractable likelihood and a challenging parameter estimation task. In this paper, we propose switching autoregressive low-rank tensor (SALT) models, which retain the advantages of both approaches while ameliorating the weaknesses. SALT parameterizes the tensor of an ARHMM with a low-rank 
    
[^23]: 将NP困难的最小最大路径问题作为具有公平背景的顺序生成来解决

    Solving NP-hard Min-max Routing Problems as Sequential Generation with Equity Context. (arXiv:2306.02689v1 [cs.LG])

    [http://arxiv.org/abs/2306.02689](http://arxiv.org/abs/2306.02689)

    本文提出了一个新的深度学习框架Equity-Transformer来解决大规模的最小最大路径问题。该模型利用可扩展的深度学习模型进行顺序决策，并生成考虑公平工作负载的顺序动作。研究显示，Equity-Transformer在两个代表性最小最大路径问题中具有卓越的性能。

    

    最小最大路径问题旨在最小化所有代理商协同访问所有城市的最大旅游长度，即完成时间。这些问题包括有影响力的实际应用，但被认为是NP困难的。现有方法面临挑战，特别是在需要协调众多代理商覆盖数千个城市的大规模问题中。本文提出了一个新的深度学习框架来解决大规模的最小最大路径问题。我们将多个代理商的同时决策建模为顺序生成过程，允许利用可扩展的深度学习模型进行顺序决策。在顺序近似问题中，我们提出了一个可扩展的上下文Transformer模型Equity-Transformer，它生成考虑其他代理商之间公平工作负载的顺序动作。Equity-Transformer的有效性通过其在两个代表性最小最大路径问题中具有卓越的性能得到证明。

    Min-max routing problems aim to minimize the maximum tour length among agents as they collaboratively visit all cities, i.e., the completion time. These problems include impactful real-world applications but are known as NP-hard. Existing methods are facing challenges, particularly in large-scale problems that require the coordination of numerous agents to cover thousands of cities. This paper proposes a new deep-learning framework to solve large-scale min-max routing problems. We model the simultaneous decision-making of multiple agents as a sequential generation process, allowing the utilization of scalable deep-learning models for sequential decision-making. In the sequentially approximated problem, we propose a scalable contextual Transformer model, Equity-Transformer, which generates sequential actions considering an equitable workload among other agents. The effectiveness of Equity-Transformer is demonstrated through its superior performance in two representative min-max routing 
    
[^24]: Meta-SAGE：用引导探索的规划方法和比例一元学习进行协同优化规模偏移问题

    Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization. (arXiv:2306.02688v1 [cs.LG])

    [http://arxiv.org/abs/2306.02688](http://arxiv.org/abs/2306.02688)

    本研究提出了一种名为Meta-SAGE的新方法，用于解决组合优化任务中深度强化学习模型可扩展性的问题。该方法通过比例元学习和时间表调整来适应模型，并真实地优化了相关任务的性能表现。

    

    本文提出了一种称之为Meta-SAGE的新方法，旨在改善组合优化（CO）任务的深度强化学习模型的可扩展性。本方法通过建议两个组件来在测试时间适应预训练模型以解决规模问题：一个是比例元学习器（SML），另一个是具有引导探索和时间表调整功能的scheduled adaptation with guided exploration（SAGE）。实验结果表明，Meta-SAGE优于以前的适应方法，并显著提高了代表性CO任务的可扩展性。

    This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage
    
[^25]: 元学习控制变量：有限数据中方差缩减的方法

    Meta-learning Control Variates: Variance Reduction with Limited Data. (arXiv:2303.04756v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2303.04756](http://arxiv.org/abs/2303.04756)

    该论文提出了一种元学习控制变量的方法，可在有限数据的情况下减小蒙特卡罗估计器的方差，并对多个任务进行处理。

    

    控制变量是减小蒙特卡罗估计器方差的有力工具，但在样本数量较小的情况下构建有效的控制变量可能具有挑战性。本文表明，当需要计算大量相关积分时，即使每个任务的样本数很少，也可以利用这些积分任务之间的相似性来提高性能。我们所提出的元学习CV（Meta-CVs）方法可用于处理数百个或数千个任务，并通过实证评估表明，在这种情况下，Meta-CVs可以显著减小方差。我们的理论分析确定了Meta-CVs成功训练的一般条件。

    Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained.
    
[^26]: 简化基于动量的黎曼子流形优化

    Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09738](http://arxiv.org/abs/2302.09738)

    本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。

    

    带有动量的黎曼子流形优化在计算上是具有挑战性的，因为确保迭代保持在子流形上通常需要解决困难的微分方程。本文针对具有仿射不变度量的对称正定矩阵的子流形优化算法进行了简化。我们提出了黎曼正常坐标的广义版本，可以将问题动态地简化为欧几里得无约束问题。我们使用我们的方法来解释和简化现有的结构化协方差方法，并为深度学习开发了高效的二阶优化器，而无需显式矩阵求逆。

    Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
    
[^27]: 悬崖学习

    Cliff-Learning. (arXiv:2302.07348v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07348](http://arxiv.org/abs/2302.07348)

    本研究探究了基于基础模型的迁移学习在低数据状态下的数据缩放，发现了一种称为悬崖学习的现象，它反映了学习算法的先验知识与任务之间的兼容程度。

    

    我们研究了基于基础模型进行迁移学习在低下游数据状态下的数据缩放。我们观察到了一个有趣的现象，我们称之为悬崖学习。悬崖学习是指在数据缩放法则的某些区域中，性能的提升速度快于幂律速度的现象（即在对数缩放图上的凹形区域）。我们对基础模型的悬崖学习进行了深入调查并研究了这一现象的玩具模型。我们观察到悬崖学习的程度反映了学习算法的先验知识和所学任务之间的兼容程度。

    We study the data-scaling of transfer learning from foundation models in the low-downstream-data regime. We observe an intriguing phenomenon which we call cliff-learning. Cliff-learning refers to regions of data-scaling laws where performance improves at a faster than power law rate (i.e. regions of concavity on a log-log scaling plot). We conduct an in-depth investigation of foundation-model cliff-learning and study toy models of the phenomenon. We observe that the degree of cliff-learning reflects the degree of compatibility between the priors of a learning algorithm and the task being learned.
    
[^28]: 逆向可辨识双射因果模型

    Counterfactual Identifiability of Bijective Causal Models. (arXiv:2302.02228v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.02228](http://arxiv.org/abs/2302.02228)

    本文研究逆向可辨识双射因果模型，确立了其在三种常见因果结构下的逆向可辨识性，提出了一种实用的学习方法，可以用于有效的逆向预测估计。

    

    本文研究具有双射生成机制（BGM）的因果模型中的逆向可辨识性，其中BGM是一种广泛使用于文献中的因果模型类。我们确立了三种常见的具有未观察到混杂变量因果结构的逆向可辨识性，并提出了一种实用的学习方法，将学习BGM转化为结构化生成建模。学习到的BGM可以实现有效的逆向预测估计，并可以使用各种深度条件生成模型获得。我们在一个视觉任务中评估了我们的技术，并展示了它在现实世界视频流媒体仿真任务中的应用。

    We study counterfactual identifiability in causal models with bijective generation mechanisms (BGM), a class that generalizes several widely-used causal models in the literature. We establish their counterfactual identifiability for three common causal structures with unobserved confounding, and propose a practical learning method that casts learning a BGM as structured generative modeling. Learned BGMs enable efficient counterfactual estimation and can be obtained using a variety of deep conditional generative models. We evaluate our techniques in a visual task and demonstrate its application in a real-world video streaming simulation task.
    
[^29]: 利用扩散模型进行干预和反事实推断

    Interventional and Counterfactual Inference with Diffusion Models. (arXiv:2302.00860v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00860](http://arxiv.org/abs/2302.00860)

    本论文提出了基于扩散模型的因果模型 (DCM)，它可以在只有观测数据和因果图可用的情况下进行干预和反事实推断，其具有较好的表现。同时，论文还提供了一种分析反事实估计的方法，可以应用于更广泛的场景。

    

    我们考虑在只有观测数据和因果图可用的因果充分设置中回答观测、干预和反事实查询的问题。利用扩散模型的最新发展，我们引入了基于扩散的因果模型 (DCM)，来学习生成独特的潜在编码的因果机制。这些编码使我们能够在干预下直接采样和进行反事实推断。扩散模型在这里是一个自然的选择，因为它们可以将每个节点编码为一个代表外生噪声的潜在表示。我们的实证评估表明，在回答因果查询方面，与现有的最先进方法相比，有显着的改进。此外，我们提供了理论结果，为分析一般编码器-解码器模型中的反事实估计提供一种方法，这对我们提出的方法以外的设置可能也有用。

    We consider the problem of answering observational, interventional, and counterfactual queries in a causally sufficient setting where only observational data and the causal graph are available. Utilizing the recent developments in diffusion models, we introduce diffusion-based causal models (DCM) to learn causal mechanisms, that generate unique latent encodings. These encodings enable us to directly sample under interventions and perform abduction for counterfactuals. Diffusion models are a natural fit here, since they can encode each node to a latent representation that acts as a proxy for exogenous noise. Our empirical evaluations demonstrate significant improvements over existing state-of-the-art methods for answering causal queries. Furthermore, we provide theoretical results that offer a methodology for analyzing counterfactual estimation in general encoder-decoder models, which could be useful in settings beyond our proposed approach.
    
[^30]: 带有MCMC的差分隐私分布式贝叶斯线性回归

    Differentially Private Distributed Bayesian Linear Regression with MCMC. (arXiv:2301.13778v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.13778](http://arxiv.org/abs/2301.13778)

    提出了一种带有 MCMC 的差分隐私分布式贝叶斯线性回归算法，提供了快速版本，具有计算上的优势，并在实际数据和模拟数据上进行数字实验，结果表明算法能够提供全面的估计和预测。

    

    我们提出了一种新颖的分布式差分隐私线性回归的贝叶斯推断框架。我们考虑到在多个参与方拥有部分数据并分享其部分的某些总结统计信息的分布式环境中。我们开发了一种新型的生成式统计模型，用于私下共享的统计信息，该模型利用了线性回归摘要统计信息之间的有用分布关系。回归系数的贝叶斯估计主要通过马尔可夫链蒙特卡罗算法进行，同时我们还提供了一种快速版本，以在一次迭代中执行贝叶斯估计。所提出的方法具有计算上的优势。我们在实际数据和模拟数据上提供了数字实验结果，这些结果表明所提出的算法能够提供全面的估计和预测。

    We propose a novel Bayesian inference framework for distributed differentially private linear regression. We consider a distributed setting where multiple parties hold parts of the data and share certain summary statistics of their portions in privacy-preserving noise. We develop a novel generative statistical model for privately shared statistics, which exploits a useful distributional relation between the summary statistics of linear regression. Bayesian estimation of the regression coefficients is conducted mainly using Markov chain Monte Carlo algorithms, while we also provide a fast version to perform Bayesian estimation in one iteration. The proposed methods have computational advantages over their competitors. We provide numerical results on both real and simulated data, which demonstrate that the proposed algorithms provide well-rounded estimation and prediction.
    
[^31]: 用于采样分子晶体结构的刚体流

    Rigid body flows for sampling molecular crystal structures. (arXiv:2301.11355v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11355](http://arxiv.org/abs/2301.11355)

    本文介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计。通过在单位四元数群上定义平滑和表现力强的流以及定义适当的密度，在旋转群上进行训练，我们可以成功地采样分子晶体结构。

    

    正则化流(NF)是一类强大的生成模型，由于其高度灵活和表现力，近年来广受欢迎。在本文中，我们介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计，例如晶体中的分子。我们的方法基于两个关键思想:首先，我们在单位四元数群上定义平滑和表现力强的流，从而可以捕捉刚体的连续旋转运动;其次，我们利用单位四元数的双覆盖特性，在旋转群上定义一个适当的密度。这确保我们的模型可以使用标准的基于似然方法或基于热力学目标密度的变分推断进行训练。我们通过训练两个分子示例的Boltzmann生成器来评估该方法，即四面体系统的多模态密度。

    Normalizing flows (NF) are a class of powerful generative models that have gained popularity in recent years due to their ability to model complex distributions with high flexibility and expressiveness. In this work, we introduce a new type of normalizing flow that is tailored for modeling positions and orientations of multiple objects in three-dimensional space, such as molecules in a crystal. Our approach is based on two key ideas: first, we define smooth and expressive flows on the group of unit quaternions, which allows us to capture the continuous rotational motion of rigid bodies; second, we use the double cover property of unit quaternions to define a proper density on the rotation group. This ensures that our model can be trained using standard likelihood-based methods or variational inference with respect to a thermodynamic target density. We evaluate the method by training Boltzmann generators for two molecular examples, namely the multi-modal density of a tetrahedral system 
    
[^32]: 面向参数化偏微分方程的随机网格神经过程

    Random Grid Neural Processes for Parametric Partial Differential Equations. (arXiv:2301.11040v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11040](http://arxiv.org/abs/2301.11040)

    本论文引入了一种新的随机网格神经算法，用于处理参数化偏微分方程，创新地将概率测度赋予空间域，形成高斯过程模型，提供了一种解决数据受噪声干扰问题的方法。

    

    我们引入了一类新的基于可扩展变分神经过程的具有空间随机物理学和数据信息的深度潜在模型，用于处理参数化偏微分方程(PDE)。我们通过将概率测度赋予空间域来实现这一目的，这使我们能够将配点网格视为随机变量来边际化。通过适应这种空间统计视图，我们以产生解场的高斯过程模型作为结果，解决参数PDE的正向和反向问题。这些随机网格的实现为反向物理信息深度学习框架提出了一系列独特的挑战，我们提出了一种名为Grid Invariant Convolutional Networks(GICNets)的新架构来克服这些挑战。我们进一步展示了如何以原则性的方式将有噪声的数据纳入我们的物理知识模型中，以改进对一些可能有可用数据但测量结果被噪声污染的问题的预测能力。

    We introduce a new class of spatially stochastic physics and data informed deep latent models for parametric partial differential equations (PDEs) which operate through scalable variational neural processes. We achieve this by assigning probability measures to the spatial domain, which allows us to treat collocation grids probabilistically as random variables to be marginalised out. Adapting this spatial statistics view, we solve forward and inverse problems for parametric PDEs in a way that leads to the construction of Gaussian process models of solution fields. The implementation of these random grids poses a unique set of challenges for inverse physics informed deep learning frameworks and we propose a new architecture called Grid Invariant Convolutional Networks (GICNets) to overcome these challenges. We further show how to incorporate noisy data in a principled manner into our physics informed model to improve predictions for problems where data may be available but whose measurem
    
[^33]: Tracr: 编译变压器模型作为可解释性实验室

    Tracr: Compiled Transformers as a Laboratory for Interpretability. (arXiv:2301.05062v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.05062](http://arxiv.org/abs/2301.05062)

    Tracr是一个编译器，将可读性强的程序编译成标准的仅解码变压器模型，该编译模型的已知结构可以用于设计实验和评估可解释方法。

    

    我们展示了如何将可读性强的程序编译成标准的仅解码变压器模型。我们的编译器Tracr生成具有已知结构的模型，可以用于设计实验。例如，我们使用它来研究执行多步算法的变压器中的“叠加”。此外，Tracr编译模型的已知结构可以作为评估可解释方法的真实基准。通常，由于变压器学习的“程序”是未知的，因此不清楚解释是否成功。我们通过实现和检查包括计算令牌频率、排序和括号检查在内的程序来演示我们的方法。我们在https://github.com/deepmind/tracr提供了Tracr的开源实现。

    We show how to "compile" human-readable programs into standard decoder-only transformer models. Our compiler, Tracr, generates models with known structure. This structure can be used to design experiments. For example, we use it to study "superposition" in transformers that execute multi-step algorithms. Additionally, the known structure of Tracr-compiled models can serve as ground-truth for evaluating interpretability methods. Commonly, because the "programs" learned by transformers are unknown it is unclear whether an interpretation succeeded. We demonstrate our approach by implementing and examining programs including computing token frequencies, sorting, and parenthesis checking. We provide an open-source implementation of Tracr at https://github.com/deepmind/tracr.
    
[^34]: 深度线性网络中的神经塌陷:从平衡到不平衡的数据

    Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data. (arXiv:2301.00437v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00437](http://arxiv.org/abs/2301.00437)

    研究者证明对于均方误差和交叉熵损失，深度线性网络中出现的全局解在不同数据上都具有神经塌陷的特性，即最后一层特征会崩溃为类均值，而这些类均值是等角紧框架的顶点。

    

    现代深度神经网络在图像分类和自然语言处理等任务中表现出色，但令人惊讶的是，这些具有大量参数的复杂系统在训练到收敛时，它们的最后一层特征和分类器在经典数据集上表现出相同的结构性质。特别地，观察到最后一层特征会崩溃为类均值，并且这些类均值是等角紧框架(simplex Equiangular Tight Frame)的顶点。这种现象被称为神经塌陷(NC)。最近的论文理论上证明了在简化的“无约束特征模型”训练问题的全局最小值中出现了$\mathcal{NC}$。在这个语境下，我们进一步证明了在常用的均方误差(MSE)和交叉熵(CE)损失下，深度线性网络中也会发生$\mathcal{NC}$现象，表明全局解在不同数据上都具有$\mathcal{NC}$的特性。

    Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse ($\mathcal{NC}$). Recent papers have theoretically shown that $\mathcal{NC}$ emerges in the global minimizers of training problems with the simplified ``unconstrained feature model''. In this context, we take a step further and prove the $\mathcal{NC}$ occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit $\mathcal{NC}$ properties across
    
[^35]: 协变量转移的祝福和诅咒：对抗学习动态、方向收敛和平衡的影响

    Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria. (arXiv:2212.02457v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.02457](http://arxiv.org/abs/2212.02457)

    协变量转移和对抗扰动对统计学习的稳健性提出了挑战。本文在无限维度的情况下研究了对抗协变量转移对外推区域的影响以及其对后续学习的平衡的影响。

    

    协变量分布转移和对抗扰动对传统统计学习框架的稳健性提出了挑战：测试协变量分布中的轻微转移能显著影响基于训练分布学习的统计模型性能。当外推发生时，即协变量转移到训练分布稀缺的区域时，模型性能通常会降低，因此，学习模型信息很少。为了稳健性和正则化考虑，建议采用对抗扰动技术，然而，需要对给定学习模型时对抗协变量转移的外推区域进行仔细研究。本文在无限维度的设置中精确刻画了外推区域，在回归和分类方面进行了研究。研究了对抗协变量转移对随后的平衡学习的影响。

    Covariate distribution shifts and adversarial perturbations present robustness challenges to the conventional statistical learning framework: mild shifts in the test covariate distribution can significantly affect the performance of the statistical model learned based on the training distribution. The model performance typically deteriorates when extrapolation happens: namely, covariates shift to a region where the training distribution is scarce, and naturally, the learned model has little information. For robustness and regularization considerations, adversarial perturbation techniques are proposed as a remedy; however, careful study needs to be carried out about what extrapolation region adversarial covariate shift will focus on, given a learned model. This paper precisely characterizes the extrapolation region, examining both regression and classification in an infinite-dimensional setting. We study the implications of adversarial covariate shifts to subsequent learning of the equi
    
[^36]: 脱耦表示与稀疏性之间的协同作用：多任务学习中的泛化和可识别性

    Synergies between Disentanglement and Sparsity: Generalization and Identifiability in Multi-Task Learning. (arXiv:2211.14666v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14666](http://arxiv.org/abs/2211.14666)

    本文提供了证据表明，脱耦表示与稀疏基预测器相结合可提高泛化能力。我们提出了一个实用方法来学习这种表示，并在少样本分类基准测试中取得了竞争性的结果。

    

    尽管脱耦表示经常被认为对下游任务有益，但目前的经验和理论理解仍然有限。本文提供证据表明，与稀疏基预测器相结合的脱耦表示可提高泛化能力。在多任务学习的背景下，我们证明了一个新的可识别性结果，该结果提供了最大稀疏基预测器产生脱耦表示的条件。受这个理论结果的启发，我们提出了一种基于稀疏促进双层优化问题学习脱耦表示的实用方法。最后，我们探索了一个基于组 Lasso 多类 SVM 基预测器的元学习版本的算法，为此，我们推导出了一个可行的对偶公式。它在标准的少样本分类基准测试上获得了竞争性的结果，而每个任务仅使用了一小部分学习到的表示。

    Although disentangled representations are often said to be beneficial for downstream tasks, current empirical and theoretical understanding is limited. In this work, we provide evidence that disentangled representations coupled with sparse base-predictors improve generalization. In the context of multi-task learning, we prove a new identifiability result that provides conditions under which maximally sparse base-predictors yield disentangled representations. Motivated by this theoretical result, we propose a practical approach to learn disentangled representations based on a sparsity-promoting bi-level optimization problem. Finally, we explore a meta-learning version of this algorithm based on group Lasso multiclass SVM base-predictors, for which we derive a tractable dual formulation. It obtains competitive results on standard few-shot classification benchmarks, while each task is using only a fraction of the learned representations.
    
[^37]: 基于样本排列优化的全局对比批量采样

    Global Contrastive Batch Sampling via Optimization on Sample Permutations. (arXiv:2210.12874v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12874](http://arxiv.org/abs/2210.12874)

    本论文提出了一种有效的替代硬负例挖掘的全局对比批量采样方法GCBS，能够提高对比学习任务的性能表现，易于实现且适用于各种对比学习方法。

    

    对比学习最近在各种任务中取得了最先进的性能。许多对比学习方法使用挖掘的硬负例来在训练期间使批处理更加信息丰富，但这些方法效率低下，因为它们增加了与挖掘负例数成比例的纪元长度，并需要频繁更新最近邻居索引或从最近的批次中进行挖掘。在这项工作中，我们提供了另一种硬负例挖掘的替代方案：全局对比批量采样（GCBS），一种有效的近似批处理分配问题，它上界了对比学习设置中的全局损失和训练损失之间的差距$\mathcal{L}^{Global} - \mathcal{L}^{Train}$。通过实验，我们发现GCBS改善了句子嵌入和代码搜索任务的最先进性能。此外，GCBS易于实现，因为它只需要少量附加代码，不需要维护外部数据结构，如最近邻居索引，并且适用于各种对比学习方法。

    Contrastive Learning has recently achieved state-of-the-art performance in a wide range of tasks. Many contrastive learning approaches use mined hard negatives to make batches more informative during training but these approaches are inefficient as they increase epoch length proportional to the number of mined negatives and require frequent updates of nearest neighbor indices or mining from recent batches. In this work, we provide an alternative to hard negative mining, Global Contrastive Batch Sampling (GCBS), an efficient approximation to the batch assignment problem that upper bounds the gap between the global and training losses, $\mathcal{L}^{Global} - \mathcal{L}^{Train}$, in contrastive learning settings. Through experimentation we find GCBS improves state-of-the-art performance in sentence embedding and code-search tasks. Additionally, GCBS is easy to implement as it requires only a few additional lines of code, does not maintain external data structures such as nearest neighbo
    
[^38]: SGD使用大步长训练能够学习稀疏特征

    SGD with Large Step Sizes Learns Sparse Features. (arXiv:2210.05337v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05337](http://arxiv.org/abs/2210.05337)

    本文展示了SGD使用大步长训练能够学习稀疏特征，在训练过程中，通过步长调度，梯度和噪声相互作用，共同驱动SGD动态穿过神经网络的损失平面，从而发现稀疏表示。

    

    本文展示了随机梯度下降（SGD）在神经网络训练中动力学的重要特征。我们发现：常用的大步长会导致迭代从山谷的一侧跳到另一侧导致损失稳定，同时这种稳定性会引起一个隐含的、垂直于跳跃方向的随机动态，将其偏向于稀疏预测器。此外，我们实验证明，长时间使用大步长可保持SGD在损失平面中的高度，进而能更好地实现隐式正则化和发现稀疏表示。值得注意的是，这里没有使用任何显式正则化，因此正则化效果完全来自于受步长调度影响的SGD训练动态。因此，我们的发现揭示了通过步长调度，梯度和噪声如何共同驱动SGD动态穿过神经网络的损失平面。我们通过展示幂律步长调度匹配奥恩斯坦-乌伦贝克过程的理论预测并导致最稳健和最稀疏的表示来证明这些发现。

    We showcase important features of the dynamics of the Stochastic Gradient Descent (SGD) in the training of neural networks. We present empirical observations that commonly used large step sizes (i) lead the iterates to jump from one side of a valley to the other causing loss stabilization, and (ii) this stabilization induces a hidden stochastic dynamics orthogonal to the bouncing directions that biases it implicitly toward sparse predictors. Furthermore, we show empirically that the longer large step sizes keep SGD high in the loss landscape valleys, the better the implicit regularization can operate and find sparse representations. Notably, no explicit regularization is used so that the regularization effect comes solely from the SGD training dynamics influenced by the step size schedule. Therefore, these observations unveil how, through the step size schedules, both gradient and noise drive together the SGD dynamics through the loss landscape of neural networks. We justify these find
    
[^39]: 在实值函数中对抗鲁棒PAC学习性的研究

    Adversarially Robust PAC Learnability of Real-Valued Functions. (arXiv:2206.12977v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.12977](http://arxiv.org/abs/2206.12977)

    该论文研究了在实值函数中对抗鲁棒PAC学习性，发现有限胖折射维的类既可以在实现和不可知设置中被学习，凸函数类可以正确学习，而一些非凸函数类需要不正当的学习算法。

    

    我们研究了在使用$\ell_p$损失和任意扰动集的回归设置中，对测试时对抗性攻击的稳健性。我们探讨了在这种情况下哪些函数类是PAC可学习的。我们表明有限胖折射维的类既可以在实现和不可知设置中被学习。此外，对于凸函数类，它们甚至可以正确学习。相比之下，一些非凸函数类显然需要不正当的学习算法。我们的主要技术基于构建一个由胖折射维决定大小的具有对抗鲁棒性的样本压缩方案。在此过程中，我们介绍了一个新颖的面向实值函数的不可知样本压缩方案，这可能是具有独立兴趣的。

    We study robustness to test-time adversarial attacks in the regression setting with $\ell_p$ losses and arbitrary perturbation sets. We address the question of which function classes are PAC learnable in this setting. We show that classes of finite fat-shattering dimension are learnable in both realizable and agnostic settings. Moreover, for convex function classes, they are even properly learnable. In contrast, some non-convex function classes provably require improper learning algorithms. Our main technique is based on a construction of an adversarially robust sample compression scheme of a size determined by the fat-shattering dimension. Along the way, we introduce a novel agnostic sample compression scheme for real-valued functions, which may be of independent interest.
    
[^40]: 一种对经验神经切向核的快速且有根据的近似方法。

    A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel. (arXiv:2206.12543v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.12543](http://arxiv.org/abs/2206.12543)

    该论文提出了一种名为“逻辑和”的经验神经切向核近似方法，可以在计算量上显著降低，同时经过证明在宽的最终“读出”层的网络中初始化后收敛于真实的eNTK。

    

    经验神经切向核（eNTK）可以很好地理解给定网络的表示：它们通常比无限宽NTK计算便宜得多，适用范围更广。然而，对于具有O个输出单元（例如O类分类器）的网络，N个输入的eNTK的大小为$NO\times NO$，需要$O((NO)^2)$的内存和高达$O((NO)^3)$的计算量。因此，大多数现有的应用程序使用少数几个近似值之一，可以产生$N\times N$内核矩阵，从而节省数量级的计算，但没有或极少有理论依据。我们证明了其中一种近似方法，我们称之为“逻辑和”，对于任何具有宽的最终“读出”层的网络，在初始化时收敛于真实的eNTK。我们的实验展示了这个近似方法在各种不同设置中的各种用途的质量。

    Empirical neural tangent kernels (eNTKs) can provide a good understanding of a given network's representation: they are often far less expensive to compute and applicable more broadly than infinite width NTKs. For networks with O output units (e.g. an O-class classifier), however, the eNTK on N inputs is of size $NO \times NO$, taking $O((NO)^2)$ memory and up to $O((NO)^3)$ computation. Most existing applications have therefore used one of a handful of approximations yielding $N \times N$ kernel matrices, saving orders of magnitude of computation, but with limited to no justification. We prove that one such approximation, which we call "sum of logits", converges to the true eNTK at initialization for any network with a wide final "readout" layer. Our experiments demonstrate the quality of this approximation for various uses across a range of settings.
    
[^41]: 神经扩散过程

    Neural Diffusion Processes. (arXiv:2206.03992v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.03992](http://arxiv.org/abs/2206.03992)

    提出了一种新方法——神经扩散过程（NDPs），通过有限边缘学习从丰富的函数分布中进行采样。NDPs 可以捕获接近真实贝叶斯后验的函数分布，具有超越神经过程的表现，实现了多种下游任务，比如回归、隐式超参数边缘化、非高斯后验预测和全局优化。

    

    与函数元学习分布相关的神经网络方法具有灵活性增强和推断复杂性降低的优点。在去噪扩散模型用于生成建模方面取得成功的基础上，我们提出了一种新方法——神经扩散过程（NDPs），通过有限边缘学习从丰富的函数分布中进行采样。通过引入自定义注意力块，我们能够将随机过程的属性（如可交换性）直接纳入 NDP 的架构中。我们从实证角度证明了 NDPs 可以捕获接近真实贝叶斯后验的函数分布，表明它们能够成功模拟高斯过程的行为并超越神经过程的表现。NDPs 可以进行多种下游任务，包括回归、隐式超参数边缘化、非高斯后验预测和全局优化。

    Neural network approaches for meta-learning distributions over functions have desirable properties such as increased flexibility and a reduced complexity of inference. Building on the successes of denoising diffusion models for generative modelling, we propose Neural Diffusion Processes (NDPs), a novel approach that learns to sample from a rich distribution over functions through its finite marginals. By introducing a custom attention block we are able to incorporate properties of stochastic processes, such as exchangeability, directly into the NDP's architecture. We empirically show that NDPs can capture functional distributions close to the true Bayesian posterior, demonstrating that they can successfully emulate the behaviour of Gaussian processes and surpass the performance of neural processes. NDPs enable a variety of downstream tasks, including regression, implicit hyperparameter marginalisation, non-Gaussian posterior prediction and global optimisation.
    
[^42]: 基于梯度提升的凸锥预测和优化问题

    Gradient boosting for convex cone predict and optimize problems. (arXiv:2204.06895v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.06895](http://arxiv.org/abs/2204.06895)

    本文介绍了dboost，它是第一个为“预测，然后优化”问题设计的智能梯度提升实现。该框架支持凸二次锥规划，并通过自定义不动点映射的隐式微分来执行梯度提升，在实验中表现出色。

    

    预测模型通常独立于决策优化进行优化。智能预测优化（SPO）框架优化预测模型以最小化下游决策遗憾。本文提出了dboost，针对“预测，然后优化”问题的第一个通用的智能梯度提升实现。该框架支持凸二次锥规划，通过自定义不动点映射的隐式微分来执行梯度提升。与最先进的SPO方法的实验比较表明，dboost可以进一步减少样本外决策遗憾。

    Prediction models are typically optimized independently from decision optimization. A smart predict then optimize (SPO) framework optimizes prediction models to minimize downstream decision regret. In this paper we present dboost, the first general purpose implementation of smart gradient boosting for `predict, then optimize' problems. The framework supports convex quadratic cone programming and gradient boosting is performed by implicit differentiation of a custom fixed-point mapping. Experiments comparing with state-of-the-art SPO methods show that dboost can further reduce out-of-sample decision regret.
    
[^43]: 政策优化中的不变性及奖励学习中的部分可识别性

    Invariance in Policy Optimisation and Partial Identifiability in Reward Learning. (arXiv:2203.07475v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.07475](http://arxiv.org/abs/2203.07475)

    本文探讨了奖励学习中奖励函数的部分可识别性，并分析了这种部分可识别性对政策优化等下游任务的影响。同时提出了一个框架，对比奖励学习的数据源和下游任务，以其不变性为依据，对奖励学习的数据源的设计和选择产生影响。

    

    对于复杂的现实任务，手动设计奖励函数通常是非常具有挑战性的。为了解决这个问题，可以使用奖励学习从数据中推断奖励函数。然而，即使在无限数据的情况下，通常也会有多个奖励函数可以很好地拟合数据。这意味着奖励函数只能被部分地识别。在这项工作中，我们正式描述了在几种流行的奖励学习数据源（包括专家演示和轨迹比较）下奖励函数的部分可识别性。我们还分析了这种部分可识别性对于几项下游任务（例如政策优化）的影响。我们在一个框架中统一了我们的结果，该框架通过其不变性对比数据源和下游任务，并对奖励学习的数据源的设计和选择产生影响。

    It is often very challenging to manually design reward functions for complex, real-world tasks. To solve this, one can instead use reward learning to infer a reward function from data. However, there are often multiple reward functions that fit the data equally well, even in the infinite-data limit. This means that the reward function is only partially identifiable. In this work, we formally characterise the partial identifiability of the reward function given several popular reward learning data sources, including expert demonstrations and trajectory comparisons. We also analyse the impact of this partial identifiability for several downstream tasks, such as policy optimisation. We unify our results in a framework for comparing data sources and downstream tasks by their invariances, with implications for the design and selection of data sources for reward learning.
    
[^44]: 计数时间序列的扭曲动态线性模型

    Warped Dynamic Linear Models for Time Series of Counts. (arXiv:2110.14790v4 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2110.14790](http://arxiv.org/abs/2110.14790)

    本文提出了一种新颖的半参数计数时间序列方法，即通过扭曲高斯DLMs进行建模，扭曲函数由转换算子和取整算子组成。我们开发了扭曲DLMs的共轭推断方法，生成了用于推断和预测的定制和高效的算法，包括蒙特卡罗模拟以进行离线分析。我们的方法在模拟和现实世界的计数时间序列中表现优异。

    

    动态线性模型(DLMs)是时间序列分析中常用的模型，因其结构灵活、递归更新简单、能够处理缺失数据、能够进行概率预测而受到广泛应用。然而，对于计数时间序列而言，选项却非常有限：高斯DLMs需要连续数据，而基于泊松分布的替代方案则常常缺乏足够的建模灵活性。本文提出了一种新颖的半参数计数时间序列方法，即通过扭曲高斯DLMs进行建模。扭曲函数由两个部分组成：一个(非参数化的)转换算子，提供概率分布的灵活性；以及一个取整算子，确保离散数据生成过程的正确性。我们开发了扭曲DLMs的共轭推断方法，使得状态空间滤波和平滑分布的分析和递归更新成为可能。我们利用这些结果生成了用于推断和预测的定制和高效的算法，包括蒙特卡罗模拟以进行离线分析。我们的方法在模拟和现实世界的计数时间序列中表现优异。

    Dynamic Linear Models (DLMs) are commonly employed for time series analysis due to their versatile structure, simple recursive updating, ability to handle missing data, and probabilistic forecasting. However, the options for count time series are limited: Gaussian DLMs require continuous data, while Poisson-based alternatives often lack sufficient modeling flexibility. We introduce a novel semiparametric methodology for count time series by warping a Gaussian DLM. The warping function has two components: a (nonparametric) transformation operator that provides distributional flexibility and a rounding operator that ensures the correct support for the discrete data-generating process. We develop conjugate inference for the warped DLM, which enables analytic and recursive updates for the state space filtering and smoothing distributions. We leverage these results to produce customized and efficient algorithms for inference and forecasting, including Monte Carlo simulation for offline anal
    
[^45]: 核细化

    Kernel Thinning. (arXiv:2105.05842v9 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2105.05842](http://arxiv.org/abs/2105.05842)

    核细化是一种更有效的压缩分布的方法，它可以将$n$点近似的分布压缩到具有可比较最坏积分误差的$\sqrt{n}$点近似，其亚指数保证类似于在$[0,1]^d$上均匀$\mathbb{P}$的经典准蒙特卡罗误差率，但适用于$\mathbb{R}^d$上的一般分布。

    

    我们介绍了核细化，一种比独立同分布采样或标准细化更有效地压缩分布$\mathbb{P}$的新方法。给定一个合适的再生核$\mathbf{k}_{\star}$和$\mathcal{O}(n^2)$时间，核细化将一个$n$点近似的$\mathbb{P}$压缩成一个具有与相关再生核希尔伯特空间中的可比较最坏积分误差的$\sqrt{n}$点近似。在概率上，紧支撑的$\mathbb{P}$的积分误差最大差别为$\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$，在$\mathbb{R}^d$上的亚指数$\mathbb{P}$为$\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$。相比之下，来自$\mathbb{P}$的等大小i.i.d.样本面临$\Omega(n^{-1/4})$的积分误差。我们的亚指数保证类似于在$[0,1]^d$上均匀$\mathbb{P}$的经典准蒙特卡罗误差率，但适用于$\mathbb{R}^d$上的一般分布和一个大

    We introduce kernel thinning, a new procedure for compressing a distribution $\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given a suitable reproducing kernel $\mathbf{k}_{\star}$ and $\mathcal{O}(n^2)$ time, kernel thinning compresses an $n$-point approximation to $\mathbb{P}$ into a $\sqrt{n}$-point approximation with comparable worst-case integration error across the associated reproducing kernel Hilbert space. The maximum discrepancy in integration error is $\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$ in probability for compactly supported $\mathbb{P}$ and $\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$ for sub-exponential $\mathbb{P}$ on $\mathbb{R}^d$. In contrast, an equal-sized i.i.d. sample from $\mathbb{P}$ suffers $\Omega(n^{-1/4})$ integration error. Our sub-exponential guarantees resemble the classical quasi-Monte Carlo error rates for uniform $\mathbb{P}$ on $[0,1]^d$ but apply to general distributions on $\mathbb{R}^d$ and a wid
    
[^46]: 高斯分层潜在狄利克雷分配：再现多义词

    Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy Back. (arXiv:2002.10855v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2002.10855](http://arxiv.org/abs/2002.10855)

    本论文提出了一种高斯分层潜在狄利克雷分配模型，通过引入层次结构恢复了捕捉多义性的能力，相对于基于高斯的模型具有更好的多义词检测性能，相对于潜在狄利克雷分配的层次模型具有更加简洁的主题表示。

    

    话题模型被广泛应用于发现一组文档的潜在表示。两种典型的模型是潜在狄利克雷分配和高斯潜在狄利克雷分配，前者使用单词上的多项式分布，后者使用预训练的单词嵌入向量上的多元高斯分布作为潜在主题表示。与潜在狄利克雷分配相比，高斯潜在狄利克雷分配在捕捉“银行”等词的多义性方面存在限制。在本文中，我们证明高斯分层潜在狄利克雷分配通过为模型可以用于表示给定文档的主题集合引入层次结构，可以恢复捕捉多义性的能力。我们的高斯分层潜在狄利克雷分配相对于基于高斯的模型显著提高了多义词检测的能力，并提供了比基于潜在狄利克雷分配的层次模型更为简洁的主题表示。

    Topic models are widely used to discover the latent representation of a set of documents. The two canonical models are latent Dirichlet allocation, and Gaussian latent Dirichlet allocation, where the former uses multinomial distributions over words, and the latter uses multivariate Gaussian distributions over pre-trained word embedding vectors as the latent topic representations, respectively. Compared with latent Dirichlet allocation, Gaussian latent Dirichlet allocation is limited in the sense that it does not capture the polysemy of a word such as ``bank.'' In this paper, we show that Gaussian latent Dirichlet allocation could recover the ability to capture polysemy by introducing a hierarchical structure in the set of topics that the model can use to represent a given document. Our Gaussian hierarchical latent Dirichlet allocation significantly improves polysemy detection compared with Gaussian-based models and provides more parsimonious topic representations compared with hierarch
    
[^47]: ROIPCA：一种基于秩一更新的在线内存受限PCA算法

    ROIPCA: An online memory-restricted PCA algorithm based on rank-one updates. (arXiv:1911.11049v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1911.11049](http://arxiv.org/abs/1911.11049)

    本文提出了基于秩一更新的ROIPCA和fROIPCA两种在线PCA算法，在内存限制的情况下，算法准确性好、运行时间短。其中fROIPCA为梯度算法，具有最优学习率。

    

    主成分分析（PCA）是数据分析中基本的算法。其内存受限的在线版本在许多现代应用中非常有用，其中数据过大而无法在内存中存储，或者数据到达时为一系列项目。在本文中，我们提出了ROIPCA和fROIPCA两种基于秩一更新的在线PCA算法。虽然ROIPCA通常更准确，但fROIPCA更快，并且具有可比较的准确性。我们展示了fROIPCA与现有流行的在线PCA梯度算法之间的关系，并且特别证明了fROIPCA实际上是具有最优学习率的梯度算法。我们在数值上证明了我们的算法在准确性和运行时间方面比现有的最先进算法具有优势。

    Principal components analysis (PCA) is a fundamental algorithm in data analysis. Its memory-restricted online versions are useful in many modern applications, where the data are too large to fit in memory, or when data arrive as a stream of items. In this paper, we propose ROIPCA and fROIPCA, two online PCA algorithms that are based on rank-one updates. While ROIPCA is typically more accurate, fROIPCA is faster and has comparable accuracy. We show the relation between fROIPCA and an existing popular gradient algorithm for online PCA, and in particular, prove that fROIPCA is in fact a gradient algorithm with an optimal learning rate. We demonstrate numerically the advantages of our algorithms over existing state-of-the-art algorithms in terms of accuracy and runtime.
    
[^48]: 面板回归模型的核范数规则化估计

    Nuclear Norm Regularized Estimation of Panel Regression Models. (arXiv:1810.10987v3 [econ.EM] UPDATED)

    [http://arxiv.org/abs/1810.10987](http://arxiv.org/abs/1810.10987)

    本文提出两种最小化凸目标函数的新估计方法，其中核范数罚项有助于解决低秩回归器下的交互固定效应模型的潜在识别问题，并且具有很重要的计算优势。

    

    本文研究具有交互固定效应的面板回归模型。我们提出了两种基于最小化凸目标函数的新估计方法。第一种方法最小化残差平方和，带有核（迹）范数规则化。第二种方法最小化残差的核范数。我们建立了两个估计器的一致性。这些估计器与现有的最小二乘（LS）估计器相比具有非常重要的计算优势，因为它们被定义为凸目标函数的最小化器。此外，核范数罚项有助于解决交互固定效应模型的潜在识别问题，尤其是当回归器是低秩的且因素数量未知时。我们还展示了如何通过使用我们的核范数规则化估计器构造渐近等效于Bai（2009年）和Moon和Weidner（2017年）最小二乘（LS）估计器的估计器。

    In this paper we investigate panel regression models with interactive fixed effects. We propose two new estimation methods that are based on minimizing convex objective functions. The first method minimizes the sum of squared residuals with a nuclear (trace) norm regularization. The second method minimizes the nuclear norm of the residuals. We establish the consistency of the two resulting estimators. Those estimators have a very important computational advantage compared to the existing least squares (LS) estimator, in that they are defined as minimizers of a convex objective function. In addition, the nuclear norm penalization helps to resolve a potential identification problem for interactive fixed effect models, in particular when the regressors are low-rank and the number of the factors is unknown. We also show how to construct estimators that are asymptotically equivalent to the least squares (LS) estimator in Bai (2009) and Moon and Weidner (2017) by using our nuclear norm regul
    

