# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Of Mice and Mates: Automated Classification and Modelling of Mouse Behaviour in Groups using a Single Model across Cages.](http://arxiv.org/abs/2306.03066) | 本文提供了自动分类和模拟群体老鼠行为的工具，通过单一模型跨笼使用置换矩阵匹配老鼠身份，在家鼠环境下研究老鼠可以捕捉到个体行为的时间因素，而且无需人为干预。 |
| [^2] | [LibAUC: A Deep Learning Library for X-Risk Optimization.](http://arxiv.org/abs/2306.03065) | 本文介绍了一个名为LibAUC的深度学习库，用于解决X-risk的优化问题，并在实验中表现出优异的性能。 |
| [^3] | [Using Sequences of Life-events to Predict Human Lives.](http://arxiv.org/abs/2306.03009) | 本研究通过将人类生命表示成事件序列，利用自然语言处理的创新方法，分析了整个国家的超过六百万人的多年注册数据，旨在从中预测人类生命的演变和可预测性。 |
| [^4] | [Complex Preferences for Different Convergent Priors in Discrete Graph Diffusion.](http://arxiv.org/abs/2306.02957) | 本研究探讨了离散扩散核如何影响图的扩散模型的性能，结果表明选择正确的收敛先验对于扩散模型的生成性能至关重要。 |
| [^5] | [Random Distribution Shift in Refugee Placement: Strategies for Building Robust Models.](http://arxiv.org/abs/2306.02948) | 本文研究了难民安置中的随机分布转移问题，并提出并比较了三种建模策略，最终发现混合方法具有较强鲁棒性。 |
| [^6] | [Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm.](http://arxiv.org/abs/2306.02939) | 本文提出了新的算法稳定性理论来改进分布式SGD算法的泛化性能分析，推翻了现有技术对通信图负面影响的观点，并展示了D-SGD在凸设置中与经典SGD算法泛化界相同。 |
| [^7] | [Causal Discovery using Bayesian Model Selection.](http://arxiv.org/abs/2306.02931) | 对于具有现实假设的数据集，本文提出了使用贝叶斯模型选择进行因果推断的方法，使得确定因果方向变成了一个模型选择问题。使用实际数据集验证了本方法优于现有方法。 |
| [^8] | [Decentralized SGD and Average-direction SAM are Asymptotically Equivalent.](http://arxiv.org/abs/2306.02913) | 分散SGD和平均方向SAM在渐近意义下是等价的，D-SGD表现出梯度平滑效应和锐度正则化效应，而且可以提高后验评估，并证明了潜在的泛化能力 |
| [^9] | [Learning nonparametric latent causal graphs with unknown interventions.](http://arxiv.org/abs/2306.02899) | 本文提出了一种学习具有未知干预的非参数潜在因果图的方法，通过建立条件确定非参数潜在因果图并从中重构。这种方法不需要参数假设，可用于识别测量模型中潜在结构。 |
| [^10] | [Representational Strengths and Limitations of Transformers.](http://arxiv.org/abs/2306.02896) | 本文研究了transformer的表示能力，正面说明了transformer在稀疏平均任务中的效率比循环网络和前馈网络更高，并展示了大嵌入维度在transformer中的必要性和作用；负面说明了注意力层的复杂度随输入大小线性缩放，但这种情况在实践中很少发生，可以使用替代的变体。 |
| [^11] | [Evading Black-box Classifiers Without Breaking Eggs.](http://arxiv.org/abs/2306.02895) | 本文提出了一种基于实际代价的黑盒攻击，通过设计新的攻击方式，成功减少了“有害”查询的数量，提高了黑盒攻击效率。 |
| [^12] | [Data-Driven Regret Balancing for Online Model Selection in Bandits.](http://arxiv.org/abs/2306.02869) | 论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。 |
| [^13] | [The $L^\infty$ Learnability of Reproducing Kernel Hilbert Spaces.](http://arxiv.org/abs/2306.02833) | 本文分析了$L^\infty$范数下再生核希尔伯特空间的可学习性，建立了样本复杂性的下界和上界，并确定了在满足条件时可以多项式样本下实现$L^\infty$学习的频谱衰减条件。 |
| [^14] | [MM-DAG: Multi-task DAG Learning for Multi-modal Data -- with Application for Traffic Congestion Analysis.](http://arxiv.org/abs/2306.02831) | 本文提出了一种多任务、多模态的有向无环图（MM-DAG）学习方法，应用于交通拥堵分析，以最大化图的一致性和一致性，通过多模态回归对不同变量之间的关系进行线性因果关系描述。 |
| [^15] | [Near-Optimal Quantum Coreset Construction Algorithms for Clustering.](http://arxiv.org/abs/2306.02826) | 本文提供了一种基于量子核心集构造的近最优聚类算法，可以在$\tilde{O}(\sqrt{nk}d^{3/2})$的查询复杂度下缩小了输入大小，并为各种$k$-聚类近似算法提供了二次加速。 |
| [^16] | [Enhancing naive classifier for positive unlabeled data based on logistic regression approach.](http://arxiv.org/abs/2306.02798) | 通过基于逻辑回归方法的朴素分类器并优化选择分类器的截距，即使拟合的PU数据并不符合该模型，也能获得与竞争对手相当或更好的结果。 |
| [^17] | [Input gradient diversity for neural network ensembles.](http://arxiv.org/abs/2306.02775) | 本文提出了一阶斥力深度集成 (FoRDE) 算法，它使用输入梯度来增强多样性以提高神经网络集成的表现。 |
| [^18] | [Realising Synthetic Active Inference Agents, Part II: Variational Message Updates.](http://arxiv.org/abs/2306.02733) | 本文讨论了解决广义自由能（FE）目标的合成主动推理代理的变分信息更新和消息传递算法，通过对T形迷宫导航任务的模拟比较，表明AIF可引起认知行为。 |
| [^19] | [Conformal Prediction with Missing Values.](http://arxiv.org/abs/2306.02732) | 本文研究了在协变量中存在缺失值的一致性预测，提出了缺失数据扩充的广义一致化分位数回归框架，可以得出条件于缺失值模式的有效预测间隔。 |
| [^20] | [Gibbs Sampling the Posterior of Neural Networks.](http://arxiv.org/abs/2306.02729) | 这篇论文提出了一种添加噪声的神经网络模型，并使用Gibbs采样器从后验分布中进行采样，该方法在真实数据和合成数据中能够达到类似于马尔科夫链蒙特卡洛方法的性能。 |
| [^21] | [Comparative Study on Semi-supervised Learning Applied for Anomaly Detection in Hydraulic Condition Monitoring System.](http://arxiv.org/abs/2306.02709) | 本研究比较了不同类型的半监督学习方法在液压状态监测系统中用于异常检测。深度学习模型表现最好，而集成模型可以进一步提高检测性能。 |
| [^22] | [Solving NP-hard Min-max Routing Problems as Sequential Generation with Equity Context.](http://arxiv.org/abs/2306.02689) | 本文提出了一个新的深度学习框架Equity-Transformer来解决大规模的最小最大路径问题。该模型利用可扩展的深度学习模型进行顺序决策，并生成考虑公平工作负载的顺序动作。研究显示，Equity-Transformer在两个代表性最小最大路径问题中具有卓越的性能。 |
| [^23] | [Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization.](http://arxiv.org/abs/2306.02688) | 本研究提出了一种名为Meta-SAGE的新方法，用于解决组合优化任务中深度强化学习模型可扩展性的问题。该方法通过比例元学习和时间表调整来适应模型，并真实地优化了相关任务的性能表现。 |
| [^24] | [Faster Training of Diffusion Models and Improved Density Estimation via Parallel Score Matching.](http://arxiv.org/abs/2306.02658) | 本文提出一种基于并行评分匹配的扩散模型训练方法，通过利用不同时间点的任务独立性，采用独立网络建模分数演变，提高了密度估计性能，加速了训练过程。 |
| [^25] | [Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity.](http://arxiv.org/abs/2306.02652) | 本文提出了一种在Early-Exit网络中实现条件单调性的方法，将深度模型转化为真正的随时分类器。 |
| [^26] | [Covariance Adaptive Best Arm Identification.](http://arxiv.org/abs/2306.02630) | 本文提出了一个协方差自适应的最佳臂识别问题，相较于独立臂分布假设下的解决方案，能更有效地识别出高平均奖励的臂，适用于临床试验等场景。 |
| [^27] | [Active Ranking of Experts Based on their Performances in Many Tasks.](http://arxiv.org/abs/2306.02628) | 本文提出了基于多个任务表现的专家积极排名问题及处理方法，通过单调性假设及文章提供的策略在保证置信度的情况下，实现了专家正确排名，且该策略具有自适应性。 |
| [^28] | [Aiming towards the minimizers: fast convergence of SGD for overparametrized problems.](http://arxiv.org/abs/2306.02601) | 本文提出了在插值区域内的正则条件，对于过参数化问题采用随机梯度下降方法能够达到和确定性梯度下降相同的最坏情况复杂度，并具有更快的收敛速率。 |
| [^29] | [Explore and Exploit the Diverse Knowledge in Model Zoo for Domain Generalization.](http://arxiv.org/abs/2306.02595) | 本文探讨了通过利用模型库中多样化的知识来提高领域泛化能力的方法，强调认为弱模型中所包含的知识具有价值。通过比较各种已预训练好的模型在不同领域下的表现，刻画它们在编码表示上的多样性偏移和相关性偏移等特征以提高领域泛化能力。 |
| [^30] | [Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence.](http://arxiv.org/abs/2306.02572) | 用能量模型和潜变量模型相结合的层次联合嵌入预测架构（H-JEPA），是 Yann LeCun提出的实现未来自主智能的关键。 |
| [^31] | [Latent Optimal Paths by Gumbel Propagation for Variational Bayesian Dynamic Programming.](http://arxiv.org/abs/2306.02568) | 该论文使用动态规划和Gumbel传播在VAE的潜在空间中获得结构化稀疏最优路径，从而使得模型可以依赖于未观察到的结构特征信息，并成功实现了文本转语音和歌声合成。 |
| [^32] | [Coupled Variational Autoencoder.](http://arxiv.org/abs/2306.02565) | C-VAE通过将VAE问题制定为最优输运问题并在先验和数据分布之间强制耦合，实现了对先验的更大灵活性、解决了先验存在的空洞问题，并在保真度、潜在表示的质量和生成样本的质量等方面优于VAE、WAE和InfoVAE等替代方案。 |
| [^33] | [On Emergence of Clean-Priority Learning in Early Stopped Neural Networks.](http://arxiv.org/abs/2306.02533) | 当训练数据集中添加随机标签噪声时，神经网络会先学习干净数据再学习噪声，导致预测误差呈现U形曲线。本研究探索了这种清洁优先学习的学习动态，并提出了提高神经网络对标签噪声鲁棒性的潜在策略。 |
| [^34] | [Graph Fourier MMD for Signals on Graphs.](http://arxiv.org/abs/2306.02508) | 提出了一种新的用于比较图上信号的方法——图傅里叶移动距离（GFMMD），它是通过一个最优的见证函数进行定义，并且在合成和真实数据集上进行的实验表明它优于现有的比较图信号方法。 |
| [^35] | [For SALE: State-Action Representation Learning for Deep Reinforcement Learning.](http://arxiv.org/abs/2306.02451) | SALE是一种基于状态-动作表示学习的新方法，可以有效地从低级状态中实现表示学习，TD7算法引入了该方法并在连续控制任务中表现优异。 |
| [^36] | [Resilient Constrained Learning.](http://arxiv.org/abs/2306.02426) | 本论文提出了一个名为“抗干扰约束学习”的方法来解决在部署机器学习解决方案时需要满足除了准确性以外的多个要求，并以平衡从放宽中获得的性能增益与用户定义的放宽成本之间的关系的方式放松学习约束。 |
| [^37] | [ContraBAR: Contrastive Bayes-Adaptive Deep RL.](http://arxiv.org/abs/2306.02418) | ContraBAR是一种使用对比贝叶斯自适应深度强化学习的元RL算法，可以在基于状态观察的领域中实现与最先进方法可比较的性能，并规避了未来观察重建的计算代价，从而在基于图像的观察的领域中进行学习。 |
| [^38] | [Perceptual Kalman Filters: Online State Estimation under a Perfect Perceptual-Quality Constraint.](http://arxiv.org/abs/2306.02400) | 本文研究了在完美感知质量约束下的在线状态估计问题，提出了感知卡尔曼滤波器（PKF）这一最优估计器，并提供了其在线实现的实际算法，实现了实时操作。实验证明PKF可以显著提高估计信号的感知质量。 |
| [^39] | [Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz Dynamic Risk Measures.](http://arxiv.org/abs/2306.02399) | 本文研究了利普希茨动态风险度量的风险敏感强化学习，并建立了遗憾上限和下限，上限表明了最佳依赖关系和风险敏感性与样本复杂性之间的平衡。 |
| [^40] | [Matrix Completion from General Deterministic Sampling Patterns.](http://arxiv.org/abs/2306.02283) | 本文建立了一种适用于任何确定性取样方案的精确和近似低秩矩阵补全问题的理论保证方法，并且理论显著改进了已有工作的结果。 |
| [^41] | [Learning Linear Causal Representations from Interventions under General Nonlinear Mixing.](http://arxiv.org/abs/2306.02235) | 本文针对先前工作弱一类问题进行推广，提出了一种用于在非线性混合下的干预中学习线性因果表示的强可识别性算法，证明了其有效性，并提出了在实践中识别潜在变量的对比算法。 |
| [^42] | [Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth Convex Optimization.](http://arxiv.org/abs/2306.02212) | 本论文提出了一种加速拟牛顿近端外推的方法，用于解决无约束平滑凸优化问题，在$k = {O}(d)$时达到最优速率，并在$k = \Omega(d \log d)$时以更快的速率收敛。这是在凸设置中，首个证明拟牛顿类型方法比NAG有可证明优势的方法。 |
| [^43] | [Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits.](http://arxiv.org/abs/2306.02208) | 本文回答了单遍流式多臂赌博机的遗憾最小化问题，并展示了一个遗憾上界为$O(K^{1/3} T^{2/3})$ 的算法，说明均匀探索是最优的算法。 |
| [^44] | [Online Bootstrap Inference with Nonconvex Stochastic Gradient Descent Estimator.](http://arxiv.org/abs/2306.02205) | 本文提出了两种新型在线推断程序，将随机梯度下降法和乘数自举技术相结合，用于非凸目标函数的推断。同时，我们建立了这些程序的错误收敛速率，并验证了效果。 |
| [^45] | [Training Data Attribution for Diffusion Models.](http://arxiv.org/abs/2306.02174) | 本文提出了一种使用集成方法揭示训练数据对扩散模型输出影响的方法，这些模型集合可以有效减弱训练数据的影响，使我们能够评估训练数据对模型输出的影响。 |
| [^46] | [Gradient-free optimization of highly smooth functions: improved analysis and a new algorithm.](http://arxiv.org/abs/2306.02159) | 本文研究了具有零阶嘈杂正则信息的最小化问题，针对高光滑函数类推导了两种零阶投影梯度下降算法的收敛速率。 |
| [^47] | [DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation.](http://arxiv.org/abs/2306.02071) | 本论文提出了一种称为DU-Shapley的方法，用于更有效地计算Shapley值，以实现机器学习中的数据集价值评估。 |
| [^48] | [Variational Gaussian Process Diffusion Processes.](http://arxiv.org/abs/2306.02066) | 本文提出一种高斯变分过程参数化方法来更好地学习具有非线性扩散过程的潜在过程，此方法采用具有连续指数族描述的算法实现凸优化，可以代替缓慢的具有固定点迭代的算法。 |
| [^49] | [On Optimal Caching and Model Multiplexing for Large Model Inference.](http://arxiv.org/abs/2306.02003) | 本文提出了最优缓存与模型复用两种方法来缓解大型模型推理中资源消耗和延迟挑战，经过实证模拟发现这种组合大大提高了传统模型推理方法的性能。 |
| [^50] | [Asymptotically Optimal Pure Exploration for Infinite-Armed Bandits.](http://arxiv.org/abs/2306.01995) | 本文研究了从未知分布中生成的无限多臂老虎机的纯探索问题，旨在有效地选择单个高质量臂，并证明了在固定置信度和固定预算情况下算法的期望或渐进最优样本复杂度以及最优失效概率函数。 |
| [^51] | [Provable benefits of score matching.](http://arxiv.org/abs/2306.01993) | 本文给出了关于分数匹配的第一个可证明的指数族的例子，展示了它相对于最大似然的计算效率和统计效率的优越性，并且证明了在一定情况下，最大似然的损失函数是难以使用梯度方法来进行优化的。 |
| [^52] | [On Size-Independent Sample Complexity of ReLU Networks.](http://arxiv.org/abs/2306.01992) | 本文研究了ReLU神经网络的样本复杂度，给出了一个现有方法精细化的结果，实现了无深度依赖性的上界。 |
| [^53] | [DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting.](http://arxiv.org/abs/2306.01984) | 提出了一种新的扩散模型，其结合了数据中编码的时间动态，自然地编码了多步和长程预测能力，具有灵活的采样轨迹和折衷性能与加速采样的能力，同时提高了计算效率，可在时空预测方面取得竞争性表现。 |
| [^54] | [Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks.](http://arxiv.org/abs/2306.01870) | 本论文揭示了层间反馈对齐在深度神经网络中的保守性，并发现FA与GD之间存在隐式偏差的相似之处，同时阐明了ReLU网络中与反馈矩阵对齐的充分条件。 |
| [^55] | [Linear Time GPs for Inferring Latent Trajectories from Neural Spike Trains.](http://arxiv.org/abs/2306.01802) | 本论文提出了cvHM，一种使用Hida-Mat'ern核和共轭计算变分推理（CVI）的潜在高斯过程模型的通用推理框架，能够以线性时间复杂度执行潜在神经轨迹的变分推断，以适应任意的似然函数。 |
| [^56] | [Differential Privacy with Random Projections and Sign Random Projections.](http://arxiv.org/abs/2306.01751) | 本文提出了一系列差分隐私算法，其中iDP-SignRP算法在个体差分隐私设置下效果显著，DP-SignOPORP算法改进了现有算法，DP-OPORP算法表现最优，iDP提供了一种适用于特定数据集的隐私保护解决方案。 |
| [^57] | [PFNs Are Flexible Models for Real-World Bayesian Optimization.](http://arxiv.org/abs/2305.17535) | 本文使用灵活的PFN作为BO代理建模，该模型能够允许进一步信息纳入以进行非远视BO。在三种不同的问题上得到了很好的结果。 |
| [^58] | [Detecting Errors in Numerical Data via any Regression Model.](http://arxiv.org/abs/2305.16583) | 该论文提出了一种模型不可知的方法，通过考虑各种不确定性，可以利用任何回归器检测数值数据中的异常值与自然数据波动，能够有效区分真正的异常和自然数据波动。 |
| [^59] | [Exponential Smoothing for Off-Policy Learning.](http://arxiv.org/abs/2305.15877) | 本文研究了离线学习中最小化风险的倒数倾向评分(IPS)的平滑正则化，推导出了可处理、可扩展、可解释的学习证明，并确定了在何种情况下不需要正则化IPS。 |
| [^60] | [Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling.](http://arxiv.org/abs/2305.08062) | 本研究提出了一个称为OffCEM的估计器，用于对大离散动作空间下上下文匹配策略进行离线策略评估。该估计器通过基于模型的奖励估计来处理残余因果效应，并在新的本地正确性条件下保持无偏性。结果表明，OffCEM在合成和实际大动作空间数据集上优于现有方法。 |
| [^61] | [Building Neural Networks on Matrix Manifolds: A Gyrovector Space Approach.](http://arxiv.org/abs/2305.04560) | 本文通过将陀螺矢量空间中的一些概念推广到SPD和Grassmann流形，提出了在这些流形上构建神经网络的新模型和新层，并在人类动作识别和知识图谱完成两个应用中展示了其有效性。 |
| [^62] | [Model-agnostic Measure of Generalization Difficulty.](http://arxiv.org/abs/2305.01034) | 该论文提出了第一个无特定模型的、量化机器学习测试泛化难度的方法——归纳偏差复杂度度量。该方法量化了在任务上良好泛化所需的总信息量与数据提供的信息量之差，通常需要在许多维度上泛化的任务比涉及更少维度但要求更多细节的任务要困难得多。 |
| [^63] | [Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy.](http://arxiv.org/abs/2304.14762) | 本文提出了一种通过在样本中引入扰动，改进基于核化斯坦距的拟合优度检验方法的方法，以解决在同质但混合比例不同的情况下低功率的问题，并展示实验证据证明了该方法的功效。 |
| [^64] | [Convergence of Adam Under Relaxed Assumptions.](http://arxiv.org/abs/2304.13972) | 本文对Adam算法做了新的假设并进行了证明，证明了在更加现实的条件下，Adam能够以较小的梯度复杂度达到稳定点。 |
| [^65] | [Inexact iterative numerical linear algebra for neural network-based spectral estimation and rare-event prediction.](http://arxiv.org/abs/2303.12534) | 本文开发了一种不精确的迭代线性代数方法，用于基于神经网络的谱估计和从短轨迹数据集中进行稀有事件的预测，这对于理解复杂系统的动态是具有挑战性的，并讨论了该方法对强化学习中的预测问题的影响。 |
| [^66] | [Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing and Neural Networks with Quadratic Activations.](http://arxiv.org/abs/2303.11453) | 本文在矩阵感知问题中研究了基于Group Lasso正则化器的贪婪剪枝方法，证明了修剪低$\ell_2$范数列的解可以泛化到新样本上。 |
| [^67] | [Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference.](http://arxiv.org/abs/2303.10472) | 本文表明黑盒变分推理（BBVI）满足SGD文献中的ABC条件，该结果适用于平滑和二次增长的对数似然函数，同时我们的结果推广到广泛应用于BBVI实践中的非线性协方差参数化。 |
| [^68] | [Variance-reduced Clipping for Non-convex Optimization.](http://arxiv.org/abs/2303.00883) | 本文提出了一种非凸优化中的方差缩减裁剪方法SPIDER，可以实现在较少的随机梯度计算次数下找到一个较稳定的解决方案。 |
| [^69] | [Safe Peeling for L0-Regularized Least-Squares with supplementary material.](http://arxiv.org/abs/2302.14471) | 引入“安全剥离”方法加速解决L0正则化最小二乘问题，通过收缩松弛度允许更激进的剪枝，显著降低求解时间。 |
| [^70] | [Evaluating Robustness and Uncertainty of Graph Models Under Structural Distributional Shifts.](http://arxiv.org/abs/2302.13875) | 该论文提出了一种基于图结构的多样化分布转换的方法，并且针对性地设计了数据集。实验结果表明这些分布转换对于现有的图模型具有挑战性。 |
| [^71] | [Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC.](http://arxiv.org/abs/2302.11552) | 该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。 |
| [^72] | [On the Expressivity of Persistent Homology in Graph Learning.](http://arxiv.org/abs/2302.09826) | 本文通过在图学习任务中的理论讨论和实证分析，证明了持续同调技术在捕捉具有显著拓扑结构的数据集中的长程图性质方面表现出的高表达性。 |
| [^73] | [GFlowNet-EM for learning compositional latent variable models.](http://arxiv.org/abs/2302.06576) | GFlowNet-EM采用GFlowNets算法作为建模潜变量后验概率的E步骤，从而实现了对具有离散组合潜变量的表现力强的LVM进行训练。 |
| [^74] | [DIFF2: Differential Private Optimization via Gradient Differences for Nonconvex Distributed Learning.](http://arxiv.org/abs/2302.03884) | 本文提出了一种名为 DIFF2 的新型差分隐私优化框架，其以梯度差异为基础构造了一个具有小方差的全局梯度估计器，相比于之前的算法，该方法在非凸平滑目标优化问题中能够更好地减小误差下界，提高效用。 |
| [^75] | [Sampling-Based Accuracy Testing of Posterior Estimators for General Inference.](http://arxiv.org/abs/2302.03026) | 本文提出了一种基于“随机点精度测试”（TARP）覆盖测试的方法来估计生成后验估计器覆盖概率。该方法是一种估计生成模型中编码后验精度的必要和充分条件。该方法可用于测试高维空间中后验推断分析的结果。 |
| [^76] | [RLSbench: Domain Adaptation Under Relaxed Label Shift.](http://arxiv.org/abs/2302.03020) | 本文介绍了 RLSbench，它是一个大规模基准，用于宽松标签偏移。与现有基准不同，它旨在评估领域自适应方法在标签边际偏移下的表现。 |
| [^77] | [Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective.](http://arxiv.org/abs/2302.01425) | 本研究提出了一种新的可微分和稀疏的Top-k运算符，将其视为排列凸包上的线性规划，并引入p-范数正则化项以平滑运算符。算法方面，提出了一种新的近端算子，可以有效地进行Top-k运算。实验结果表明该方法在多个任务中都很有效。 |
| [^78] | [Alignment with human representations supports robust few-shot learning.](http://arxiv.org/abs/2301.11990) | 论文提出少样本学习的表现与人类表征的一致性存在U形关系，并通过计算机视觉模型的实验进行了验证。高度对齐的模型更加鲁棒，对数据的利用更加有效，但与人类对齐并非必要条件。 |
| [^79] | [On the Expressive Power of Geometric Graph Neural Networks.](http://arxiv.org/abs/2301.09308) | 本文提出了几何版本的Weisfeiler-Leman测试(GWL)，可以区分几何图形，揭示了关键设计选择如何影响几何GNN的表现力 |
| [^80] | [Insights into the drivers and spatio-temporal trends of extreme Mediterranean wildfires with statistical deep-learning.](http://arxiv.org/abs/2212.01796) | 本研究使用统计深度学习的方法分析了欧洲和地中海盆地2001年至2020年因野火而烧毁的月度面积，研究结果显示气温、降水和风速是极端野火的主要驱动因素，根据季节和地点有不同的影响。阿尔及利亚的野火活动正在增加，葡萄牙的趋势正在下降，而意大利的趋势是非线性的。 |
| [^81] | [Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection.](http://arxiv.org/abs/2211.11255) | 本文针对深度学习中的异常检测问题，提出了一种新的方法——使用扩散模型作为非对称插值的方法来增强输入并减轻过度自信的问题，从而提高判别器模型在异常检测方面的性能。 |
| [^82] | [Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars.](http://arxiv.org/abs/2211.01842) | 本研究基于无上下文文法提出了一个统一的搜索空间设计框架，可以生成表达力强大的分层搜索空间，实现了对整个体系结构的搜索并促进结构的规律性。 |
| [^83] | [Fair and Optimal Classification via Post-Processing.](http://arxiv.org/abs/2211.01528) | 本文提出了一个后处理算法，通过评分函数推导公平分类器，达到公平对待不同群体的目的。 |
| [^84] | [Optimality Guarantees for Particle Belief Approximation of POMDPs.](http://arxiv.org/abs/2210.05015) | 该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。 |
| [^85] | [Prediction intervals for neural network models using weighted asymmetric loss functions.](http://arxiv.org/abs/2210.04318) | 本论文提出了一种使用加权不对称损失函数的方法，生成可靠的预测区间，适用于复杂的机器学习情境，可扩展为参数化函数的PI预测。 |
| [^86] | [Test-time Recalibration of Conformal Predictors Under Distribution Shift Based on Unlabeled Examples.](http://arxiv.org/abs/2210.04166) | 本论文提出了一种基于未标记样本的分布漂移下测试时间校准置信度预测器。通过使用密度比估计技术来预测新分布的截止阈值，我们在几个标准图像数据集上展示了该方法优于最新的分布漂移下的测试时间校准方法。 |
| [^87] | [Sparsity by Redundancy: Solving $L_1$ with SGD.](http://arxiv.org/abs/2210.01212) | 该论文提出了一种通过冗余重参数化和简单的随机梯度下降来最小化带有$L_1$惩罚的通用可微损失函数的方法，称为\textit{spred}，是$L_1$的精确求解器，可用于训练稀疏神经网络以执行基因选择任务和神经网络压缩任务，弥合了深度学习中的稀疏性和传统统计学习之间的差距。 |
| [^88] | [Learning GFlowNets from partial episodes for improved convergence and stability.](http://arxiv.org/abs/2209.12782) | 本文提出了一种 GFlowNets 训练目标——子轨迹平衡(SubTB($\lambda$))，从部分 episode 学习的方式可以加速采样器在环境中的收敛速度，并使得在之前难以训练的长动作序列和奖励稀疏的环境中也能够训练 GFlowNets。 |
| [^89] | [Graph Embeddings via Tensor Products and Approximately Orthonormal Codes.](http://arxiv.org/abs/2208.10917) | 本文介绍了一种嵌入图形到向量空间的方法，使用张量积以及球形码实现高效压缩和表征，在稀疏图表示和其他应用中具有潜在技术优势。 |
| [^90] | [Adaptive Identification of Populations with Treatment Benefit in Clinical Trials: Machine Learning Challenges and Solutions.](http://arxiv.org/abs/2208.05844) | 本文提出了一种新的数据驱动的方法，同时使用了机器学习和自适应实验技术，用于自适应性临床试验中受益于给定治疗的患者亚群的识别。本文通过实验展示了该方法的优异表现，并解决了这一问题的独特挑战，产生了有效和有用的发现。 |
| [^91] | [A Supervised Tensor Dimension Reduction-Based Prognostics Model for Applications with Incomplete Imaging Data.](http://arxiv.org/abs/2207.11353) | 本文提出了一种基于监督张量降维的预测模型，能处理不完整的成像数据，利用失效时间监督提取低维特征，提高了预测的准确性。 |
| [^92] | [Orthonormal Expansions for Translation-Invariant Kernels.](http://arxiv.org/abs/2206.08648) | 该论文提出了一种傅里叶分析技术，用于从$\mathscr{L}_2(\mathbb{R})$的正交基中构建平移不变核函数的正交基展开，实现了马特尔核函数、柯西核函数和高斯核函数的明确展开表达式。 |
| [^93] | [Meta Optimal Transport.](http://arxiv.org/abs/2206.05262) | 本文提出了一种新的方法，利用过去问题的知识和信息来迅速预测和解决新问题，重复地解决不同度量之间的类似OT问题，从而改善最优输运问题的计算时间。 |
| [^94] | [Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression.](http://arxiv.org/abs/2205.14846) | 本文细致研究了点积核岭回归问题，针对 $m\propto d^r$ 高阶标度关系提出了精确的测试误差、偏差和方差公式。 |
| [^95] | [Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects.](http://arxiv.org/abs/2205.14714) | 本文探讨了利用元学习器估计多值处理异质效应的问题，发现朴素扩展并不总是可行，提出并讨论了一些表现良好的元学习器。 |
| [^96] | [Canonical foliations of neural networks: application to robustness.](http://arxiv.org/abs/2203.00922) | 本文探讨了利用黎曼几何和叶面理论创新应用于神经网络鲁棒性的新视角，提出了一种适用于数据空间的以曲率为考量因素的 two-step spectral 对抗攻击方法。 |
| [^97] | [Bayesian Active Learning for Discrete Latent Variable Models.](http://arxiv.org/abs/2202.13426) | 本文提出了一个新的框架，用于离散潜变量回归模型的最大相互信息输入选择。通过对线性回归混合物模型的Fisher信息分析，证明在这种情况下主动学习可以取得巨大的收益。同时，我们考虑了一类强大的时间结构潜变量模型，并展示了如何将我们的框架调整为在选择过程中融入时态依赖性。 |
| [^98] | [Exploratory Hidden Markov Factor Models for Longitudinal Mobile Health Data: Application to Adverse Posttraumatic Neuropsychiatric Sequelae.](http://arxiv.org/abs/2202.12819) | 本文提出了一个探索性的隐马尔可夫因子模型以利用长期移动设备数据，确定 APNS 状态并研究其转换和潜在风险因素，为理解和干预 APNS 提供了更全面和客观的途径。 |
| [^99] | [The Eigenlearning Framework: A Conservation Law Perspective on Kernel Regression and Wide Neural Networks.](http://arxiv.org/abs/2110.03922) | 该论文提出了Eigenlearning框架，通过限制核回归在学习正交基函数方面的能力并利用守恒定律来解释模型的泛化能力，同时还为Nakkiran等人的“深度引导”现象，经典奇偶问题难度和对抗鲁棒性提供了理论支持，并与统计物理学中的一个系统进行了类比。 |
| [^100] | [Sinkhorn Distributionally Robust Optimization.](http://arxiv.org/abs/2109.11926) | 本文通过使用Sinkhorn距离进行分布鲁棒优化，推导出更容易处理且在实际中更合理的最坏情况分布，提出了解决方案，并展示了其优越性能。 |
| [^101] | [Deep Bayesian Active Learning for Accelerating Stochastic Simulation.](http://arxiv.org/abs/2106.02770) | 本文提出了一个名为交互式神经过程(INP)的深度贝叶斯主动学习框架，用于学习深度代理模型以加速随机模拟过程，其中通过使用空间时间神经过程(STNP)实现模拟器动态的模拟，以及利用潜在信息增益(LIG)的主动学习方式来减少样本的复杂度。 |
| [^102] | [Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory.](http://arxiv.org/abs/2105.09788) | 提出一种新颖的分布式自适应NN分类器，通过随机选择数据驱动准则来调优最近邻数，提出了早期停止规则，实现了加速计算和改善有限样本性能。通过研究证明，当子样本大小足够大时，分类器实现了近乎最优的收敛速度。有效性已通过模拟和实证应用得到验证。 |
| [^103] | [Fast calculation of Gaussian Process multiple-fold cross-validation residuals and their covariances.](http://arxiv.org/abs/2101.03108) | 本研究提出了一种快速计算高斯过程多折交叉验证残差及其协方差的方法，在模型诊断和比例尺参数估计方面有一定应用价值。 |
| [^104] | [Probabilistic Fair Clustering.](http://arxiv.org/abs/2006.10916) | 本文提出了一种通过概率分配获得组成员身份的不完美知识的公平聚类算法，并在这种更一般的设置中给出了逼近比保证。 |
| [^105] | [Deep Weakly-supervised Anomaly Detection.](http://arxiv.org/abs/1910.13601) | PReNet是一种深度弱监督方法，可以检测既有已知又有未知的异常情况，通过学习成对的关系特征和异常分数，实现了异常-异常、异常-正常和正常-正常的联合学习。 |
| [^106] | [Proposing a Model for Predicting Passenger Origin-Destination in Online Taxi-Hailing Systems.](http://arxiv.org/abs/1910.08145) | 本文提出了一种模型，采用K均值和非负矩阵分解等方法，预测网约车叫车系统中乘客行程的起点和终点，相较于现有模型，具有更高的预测准确度。 |
| [^107] | [Sparse tree search optimality guarantees in POMDPs with continuous observation spaces.](http://arxiv.org/abs/1910.04332) | 本研究证明了一种基于采样的算法，部分可观察加权稀疏采样（POWSS），可以在具有连续观测空间的POMDPs中准确估计Q值，并通过增加计算能力来实现接近最优解。 |

# 详细

[^1]: 《鼠类与配偶：单一模型自动对群体中的老鼠行为进行分类和建模跨笼》

    Of Mice and Mates: Automated Classification and Modelling of Mouse Behaviour in Groups using a Single Model across Cages. (arXiv:2306.03066v1 [cs.CV])

    [http://arxiv.org/abs/2306.03066](http://arxiv.org/abs/2306.03066)

    本文提供了自动分类和模拟群体老鼠行为的工具，通过单一模型跨笼使用置换矩阵匹配老鼠身份，在家鼠环境下研究老鼠可以捕捉到个体行为的时间因素，而且无需人为干预。

    

    行为实验通常在专门的竞技场中进行，但这可能会混淆分析。为了解决这个问题，我们提供了工具来研究家鼠环境中的老鼠，为生物学家提供了捕捉个体行为的时间因素和模拟最小人为干预下笼友之间互动和相互依赖的可能性。我们开发了“活动标签模块”（ALM）来自动对老鼠行为进行分类，并开发了一种新的“群体行为模型”（GBM）来概括他们在笼子中的联合行为，使用置换矩阵将每个笼子中的老鼠身份与模型匹配。我们还发布了两个数据集，用于训练行为分类器（ABODe）和行为建模（IMADGE）。

    Behavioural experiments often happen in specialised arenas, but this may confound the analysis. To address this issue, we provide tools to study mice in the homecage environment, equipping biologists with the possibility to capture the temporal aspect of the individual's behaviour and model the interaction and interdependence between cage-mates with minimal human intervention. We develop the Activity Labelling Module (ALM) to automatically classify mouse behaviour from video, and a novel Group Behaviour Model (GBM) for summarising their joint behaviour across cages, using a permutation matrix to match the mouse identities in each cage to the model. We also release two datasets, ABODe for training behaviour classifiers and IMADGE for modelling behaviour.
    
[^2]: LibAUC: 用于X-Risk优化的深度学习库

    LibAUC: A Deep Learning Library for X-Risk Optimization. (arXiv:2306.03065v1 [cs.LG])

    [http://arxiv.org/abs/2306.03065](http://arxiv.org/abs/2306.03065)

    本文介绍了一个名为LibAUC的深度学习库，用于解决X-risk的优化问题，并在实验中表现出优异的性能。

    

    本文介绍了一个名为LibAUC的深度学习库，可以实现最先进的算法以优化一类风险函数，称为X-risk。 X-risk是一类组合函数，其中每个数据点的损失函数以与大量其他数据点进行对比的方式定义。它们在AI中具有广泛应用，可解决经典和新兴问题，包括但不限于不均衡数据的分类（CID），排名学习（LTR）和表示的对比学习（CLR）。 LibAUC的开发动机是解决现有库在解决这些问题时的收敛问题。特别地，现有库可能不会收敛或需要非常大的mini-batch大小才能获得良好的性能，因为在经验风险最小化（ERM）框架中使用了标准的mini-batch技术。我们的库是用于深度X-risk优化的，实验结果显示，它在测试准确性和收敛速度方面显着优于现有库。

    This paper introduces the award-winning deep learning (DL) library called LibAUC for implementing state-of-the-art algorithms towards optimizing a family of risk functions named X-risks. X-risks refer to a family of compositional functions in which the loss function of each data point is defined in a way that contrasts the data point with a large number of others. They have broad applications in AI for solving classical and emerging problems, including but not limited to classification for imbalanced data (CID), learning to rank (LTR), and contrastive learning of representations (CLR). The motivation of developing LibAUC is to address the convergence issues of existing libraries for solving these problems. In particular, existing libraries may not converge or require very large mini-batch sizes in order to attain good performance for these problems, due to the usage of the standard mini-batch technique in the empirical risk minimization (ERM) framework. Our library is for deep X-risk o
    
[^3]: 利用生活事件序列预测人类生命

    Using Sequences of Life-events to Predict Human Lives. (arXiv:2306.03009v1 [stat.ML])

    [http://arxiv.org/abs/2306.03009](http://arxiv.org/abs/2306.03009)

    本研究通过将人类生命表示成事件序列，利用自然语言处理的创新方法，分析了整个国家的超过六百万人的多年注册数据，旨在从中预测人类生命的演变和可预测性。

    

    在过去的十年中，机器学习通过灵活的计算模型，彻底改变了计算机分析文本的能力。由于其与书面语言的结构相似性，基于转换器的体系结构也显示出成为范围从蛋白质结构、音乐、电子医疗记录到天气预报等多变量序列的工具的前景。我们还可以以一种与语言具有结构相似性的方式来表示人类生命。从一个角度来看，生命只是一系列事件的序列：人们出生，去看小儿科医生，开始上学，搬到新地方，结婚等等。在这里，我们利用这种相似性，采用自然语言处理的创新来研究和预测人类生命的演变和可预测性，基于整个国家的六百多万人数十年间可用的可能是最全面的注册数据。

    Over the past decade, machine learning has revolutionized computers' ability to analyze text through flexible computational models. Due to their structural similarity to written language, transformer-based architectures have also shown promise as tools to make sense of a range of multi-variate sequences from protein-structures, music, electronic health records to weather-forecasts. We can also represent human lives in a way that shares this structural similarity to language. From one perspective, lives are simply sequences of events: People are born, visit the pediatrician, start school, move to a new location, get married, and so on. Here, we exploit this similarity to adapt innovations from natural language processing to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on arguably the most comprehensive registry data in existence, available for an entire nation of more than six million individuals across decades. Our dat
    
[^4]: 离散图扩散中不同收敛先验的复杂偏好

    Complex Preferences for Different Convergent Priors in Discrete Graph Diffusion. (arXiv:2306.02957v1 [cs.LG])

    [http://arxiv.org/abs/2306.02957](http://arxiv.org/abs/2306.02957)

    本研究探讨了离散扩散核如何影响图的扩散模型的性能，结果表明选择正确的收敛先验对于扩散模型的生成性能至关重要。

    

    扩散模型已经取得了在生成许多不同类型的数据，包括图像、文本和视频方面的最先进表现。尽管它们很成功，但对于基础扩散过程和最终收敛先验如何影响生成的性能进行的研究有限；此研究也仅限于连续数据类型和基于分数的扩散框架。我们探讨了不同离散扩散核（收敛到不同的先验分布）如何影响图的扩散模型的性能。为此，我们开发了一种新的离散扩散核系列公式，可以轻松调整以收敛到不同的伯努利先验，并研究这些不同的核对生成性能的影响。我们表明，生成的图的质量对使用的先验很敏感，最优选择不能用明显的统计数据或指标来解释，这挑战了扩散模型的直觉假设。我们的结果表明，在离散数据上，选择正确的收敛先验对于扩散模型的生成性能至关重要。

    Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuiti
    
[^5]: 难民安置中的随机分布转移: 建立健壮模型的策略。

    Random Distribution Shift in Refugee Placement: Strategies for Building Robust Models. (arXiv:2306.02948v1 [stat.ML])

    [http://arxiv.org/abs/2306.02948](http://arxiv.org/abs/2306.02948)

    本文研究了难民安置中的随机分布转移问题，并提出并比较了三种建模策略，最终发现混合方法具有较强鲁棒性。

    

    近年来，算法分配难民和寻求庇护者到主机国家的地点已经引起了关注，在美国和瑞士实施。这些方法使用过去抵达的数据生成可以用于匹配家庭到位置的机器学习模型（与分配算法一起使用），目标是最大化政策相关的整合结果，如在一定时间后的就业状态。现有的实现和研究通过直接预测政策结果来训练模型，并将这些预测用于分配过程。然而，这种方法的优点，特别是在非稳态环境下，尚未被先前探讨。本研究提出并比较了三种不同的建模策略：上述的标准方法、使用更新数据和代理结果的方法以及混合方法。我们证明混合方法在分布转移和弱代理关系方面具有鲁棒性-

    Algorithmic assignment of refugees and asylum seekers to locations within host countries has gained attention in recent years, with implementations in the US and Switzerland. These approaches use data on past arrivals to generate machine learning models that can be used (along with assignment algorithms) to match families to locations, with the goal of maximizing a policy-relevant integration outcome such as employment status after a certain duration. Existing implementations and research train models to predict the policy outcome directly, and use these predictions in the assignment procedure. However, the merits of this approach, particularly in non-stationary settings, has not been previously explored. This study proposes and compares three different modeling strategies: the standard approach described above, an approach that uses newer data and proxy outcomes, and a hybrid approach. We show that the hybrid approach is robust to both distribution shift and weak proxy relationships -
    
[^6]: 分布式SGD算法的稳定性与泛化分析改进

    Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm. (arXiv:2306.02939v1 [cs.LG])

    [http://arxiv.org/abs/2306.02939](http://arxiv.org/abs/2306.02939)

    本文提出了新的算法稳定性理论来改进分布式SGD算法的泛化性能分析，推翻了现有技术对通信图负面影响的观点，并展示了D-SGD在凸设置中与经典SGD算法泛化界相同。

    

    本文基于算法稳定性，提出了分布式随机梯度下降(D-SGD)算法的新的泛化误差分析方法。得到的结果大大改进了现有技术，并推翻了它们关于通信图对泛化的负面影响的观点。例如，在凸设置中，无论图的选择如何，D-SGD具有与经典SGD算法相同的泛化界。我们发现这种反直觉的结果来自于考虑本地参数的平均值，这会隐藏一个与分布式场景不兼容的最终全局平均化步骤。考虑到这一观察结果，我们倡导分析本地参数的上确界，并展示了在这种情况下，图确实对泛化产生影响。与之前的结果不同，我们的分析即使对于非连接图也能产生非平凡边界。

    This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.
    
[^7]: 使用贝叶斯模型选择进行因果推断

    Causal Discovery using Bayesian Model Selection. (arXiv:2306.02931v1 [stat.ML])

    [http://arxiv.org/abs/2306.02931](http://arxiv.org/abs/2306.02931)

    对于具有现实假设的数据集，本文提出了使用贝叶斯模型选择进行因果推断的方法，使得确定因果方向变成了一个模型选择问题。使用实际数据集验证了本方法优于现有方法。

    

    只有两个变量的观测数据且没有其他假设，无法推断哪个变量是引起另一个变量的原因。大部分因果文献聚焦于针对强假设的数据集(如加性噪声或参数计数限制)保证因果方向的可识别性。然而这些方法通常被测试于违反假设的现实数据集上。本文在此基础上提出如何在贝叶斯框架内使用因果假设。这使我们能够制定具有现实假设的模型，同时编码独立的因果机制，导致因果方向之间的非对称性。因此，确定因果方向成为贝叶斯模型选择问题。我们分析了为何在已知可识别的情况和灵活的模型类上贝叶斯模型选择

    With only observational data on two variables, and without other assumptions, it is not possible to infer which one causes the other. Much of the causal literature has focused on guaranteeing identifiability of causal direction in statistical models for datasets where strong assumptions hold, such as additive noise or restrictions on parameter count. These methods are then subsequently tested on realistic datasets, most of which violate their assumptions. Building on previous attempts, we show how to use causal assumptions within the Bayesian framework. This allows us to specify models with realistic assumptions, while also encoding independent causal mechanisms, leading to an asymmetry between the causal directions. Identifying causal direction then becomes a Bayesian model selection problem. We analyse why Bayesian model selection works for known identifiable cases and flexible model classes, while also providing correctness guarantees about its behaviour. To demonstrate our approach
    
[^8]: 分散化SGD和平均方向SAM在渐近意义下是等价的

    Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v1 [cs.LG])

    [http://arxiv.org/abs/2306.02913](http://arxiv.org/abs/2306.02913)

    分散SGD和平均方向SAM在渐近意义下是等价的，D-SGD表现出梯度平滑效应和锐度正则化效应，而且可以提高后验评估，并证明了潜在的泛化能力

    

    分散随机梯度下降（D-SGD）允许在没有中央服务器的控制下，大量设备同时进行协作学习。然而，现有理论认为，分散化不可避免地削弱了泛化能力。本文挑战传统信念，提出了完全新的角度来理解分散学习。我们证明了在一般非凸非-$\beta$-平滑设置下，D-SGD隐式地最小化了平均方向锐度感知最小化（SAM）算法的损失函数。这种惊人的渐近等价揭示了内在的正则化-优化权衡以及分散化的三个优点：（1）D-SGD中存在一个自由的不确定性评估机制，可以提高后验估计；（2）D-SGD表现出梯度平滑效应；（3）D-SGD的锐度正则化效应不会随着总批处理大小的增加而减少，这证明了潜在的泛化能力

    Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization b
    
[^9]: 学习具有未知干预的非参数潜在因果图。

    Learning nonparametric latent causal graphs with unknown interventions. (arXiv:2306.02899v1 [stat.ML])

    [http://arxiv.org/abs/2306.02899](http://arxiv.org/abs/2306.02899)

    本文提出了一种学习具有未知干预的非参数潜在因果图的方法，通过建立条件确定非参数潜在因果图并从中重构。这种方法不需要参数假设，可用于识别测量模型中潜在结构。

    

    我们在未知干预的潜在空间建立条件，以确定非参数潜在因果图并从中重构。我们的主要重点是测量模型中潜在结构的识别，即因果图模型，在其中观察变量之间的依赖性与潜在表示之间的依赖性相比，并不做出参数假设，如线性或高斯性。此外，我们不假设隐藏变量的数量已知，并且我们表明每个隐藏变量最多只需要一个未知的干预。这扩展了最近关于从观测和干预中学习因果表示的工作。证明是建设性的，并引入了两个新的图形概念——想象子集和孤立边——它们本身可能是有用的。作为一个独立的感兴趣的问题，证明还涉及对边缘定向限制的新的特征化。

    We establish conditions under which latent causal graphs are nonparametrically identifiable and can be reconstructed from unknown interventions in the latent space. Our primary focus is the identification of the latent structure in a measurement model, i.e. causal graphical models where dependence between observed variables is insignificant compared to dependence between latent representations, without making parametric assumptions such as linearity or Gaussianity. Moreover, we do not assume the number of hidden variables is known, and we show that at most one unknown intervention per hidden variable is needed. This extends a recent line of work on learning causal representations from observations and interventions. The proofs are constructive and introduce two new graphical concepts -- imaginary subsets and isolated edges -- that may be useful in their own right. As a matter of independent interest, the proofs also involve a novel characterization of the limits of edge orientations wi
    
[^10]: Transformer的代表性优势和局限性

    Representational Strengths and Limitations of Transformers. (arXiv:2306.02896v1 [cs.LG])

    [http://arxiv.org/abs/2306.02896](http://arxiv.org/abs/2306.02896)

    本文研究了transformer的表示能力，正面说明了transformer在稀疏平均任务中的效率比循环网络和前馈网络更高，并展示了大嵌入维度在transformer中的必要性和作用；负面说明了注意力层的复杂度随输入大小线性缩放，但这种情况在实践中很少发生，可以使用替代的变体。

    

    注意力层常用于transformer中，是现代深度学习的支柱之一，但与其他网络结构相比，它们的好处和缺陷没有数学描述。在本研究中，我们对注意力层的表示能力进行了正面和负面的研究，并聚焦于内在复杂度参数，如宽度、深度和嵌入维度。在正面方面，我们提出了一项稀疏平均任务，其中循环网络和前馈网络的复杂度都随输入大小呈多项式缩放，而transformer仅呈对数缩放；此外，我们使用相同的构造来展示transformer中大嵌入维度的必要性和作用。在负面方面，我们提出了一个三元检测任务，其中注意力层的复杂度随输入大小呈线性缩放；由于这种情况在实践中似乎很少发生，因此我们还提出了可以替代的变体。

    Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be 
    
[^11]: 不破坏黑盒分类器的情况下规避它的分类——基于实际代价的黑盒攻击

    Evading Black-box Classifiers Without Breaking Eggs. (arXiv:2306.02895v1 [cs.CR])

    [http://arxiv.org/abs/2306.02895](http://arxiv.org/abs/2306.02895)

    本文提出了一种基于实际代价的黑盒攻击，通过设计新的攻击方式，成功减少了“有害”查询的数量，提高了黑盒攻击效率。

    

    基于决策的规避攻击是通过不断查询黑盒分类器来生成对抗性样本。本文认为现有的攻击方式在处理对安全性敏感的机器学习系统时有缺陷。因为这些系统主要目的是过滤出有害数据（例如恶意软件、有害内容等），所以查询的代价是不对等的，一旦查询被检测出是有害的，就会触发额外的安全过滤，例如使用限制或账户暂停。然而，现有的基于决策的攻击产生了大量的“有害”查询，导致它们很可能对安全关键系统无效。因此，本文提出新的攻击方式，通过减少“有害”查询的数量（最多可以减少 $1.5$ 倍到 $7.3$ 倍），以实现更加有效的黑盒攻击。但这些攻击的正常查询数量大大增加，因此提出了在实际代价度量下构建更有效的黑盒攻击的开放性问题。

    Decision-based evasion attacks repeatedly query a black-box classifier to generate adversarial examples. Prior work measures the cost of such attacks by the total number of queries made to the classifier. We argue this metric is flawed. Most security-critical machine learning systems aim to weed out "bad" data (e.g., malware, harmful content, etc). Queries to such systems carry a fundamentally asymmetric cost: queries detected as "bad" come at a higher cost because they trigger additional security filters, e.g., usage throttling or account suspension. Yet, we find that existing decision-based attacks issue a large number of "bad" queries, which likely renders them ineffective against security-critical systems. We then design new attacks that reduce the number of bad queries by $1.5$-$7.3\times$, but often at a significant increase in total (non-bad) queries. We thus pose it as an open problem to build black-box attacks that are more effective under realistic cost metrics.
    
[^12]: 基于数据驱动的遗憾平衡在线模型选择的研究

    Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v1 [cs.LG])

    [http://arxiv.org/abs/2306.02869](http://arxiv.org/abs/2306.02869)

    论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。

    

    我们考虑在具有赌博反馈的随机环境中进行顺序决策模型选择，其中元学习器可以使用一组基本学习器，并根据每个基本学习器推荐的策略动态决策。我们通过遗憾平衡来执行模型选择，但与此相关的最近文献不同的是，我们没有假设任何关于基本学习器的先验知识，如候选遗憾保证；相反，我们以数据驱动的方式揭示这些数量。因此，元学习器能够利用每个基本学习器在给定的学习环境中产生的实际遗憾（而不是期望遗憾），并挑选出最佳的遗憾。我们设计了两个模型选择算法，操作更为雄心勃勃的遗憾概念，并且除了通过遗憾平衡证明模型选择保证外，我们还在实验中展示了处理实际遗憾的令人信服的实际优势。

    We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets ins
    
[^13]: 带有再生核希尔伯特空间的$L^\infty$可学习性分析

    The $L^\infty$ Learnability of Reproducing Kernel Hilbert Spaces. (arXiv:2306.02833v1 [stat.ML])

    [http://arxiv.org/abs/2306.02833](http://arxiv.org/abs/2306.02833)

    本文分析了$L^\infty$范数下再生核希尔伯特空间的可学习性，建立了样本复杂性的下界和上界，并确定了在满足条件时可以多项式样本下实现$L^\infty$学习的频谱衰减条件。

    

    在这项工作中，我们分析了$L^\infty$范数下再生核希尔伯特空间（RKHS）的可学习性，这对于理解核方法和随机特征模型在安全和安全关键应用中的性能至关重要。具体地，我们将RKHS的$L^\infty$可学习性与关联核的频谱衰减相关联，并建立了样本复杂性的下界和上界。特别地，对于球上的点积核，我们确定了在多项式样本下可以实现$L^\infty$学习的条件。假设输入维数为$d$，且核频谱大致衰减为$\lambda_k\sim k^{-1-\beta}$，其中$\beta>0$。我们证明，如果$\beta$独立于输入维数$d$，那么RKHS中的函数可以在$L^\infty$范数下有效地学习，即样本复杂度多项式地依赖于$d$。相反，如果$\beta=1/\mathrm{poly}(d)$，则$L^\infty$学习是不可能的。

    In this work, we analyze the learnability of reproducing kernel Hilbert spaces (RKHS) under the $L^\infty$ norm, which is critical for understanding the performance of kernel methods and random feature models in safety- and security-critical applications. Specifically, we relate the $L^\infty$ learnability of a RKHS to the spectrum decay of the associate kernel and both lower bounds and upper bounds of the sample complexity are established. In particular, for dot-product kernels on the sphere, we identify conditions when the $L^\infty$ learning can be achieved with polynomial samples. Let $d$ denote the input dimension and assume the kernel spectrum roughly decays as $\lambda_k\sim k^{-1-\beta}$ with $\beta>0$. We prove that if $\beta$ is independent of the input dimension $d$, then functions in the RKHS can be learned efficiently under the $L^\infty$ norm, i.e., the sample complexity depends polynomially on $d$. In contrast, if $\beta=1/\mathrm{poly}(d)$, then the $L^\infty$ learning 
    
[^14]: MM-DAG: 多模态数据的多任务有向无环图学习及其在交通拥堵分析中的应用

    MM-DAG: Multi-task DAG Learning for Multi-modal Data -- with Application for Traffic Congestion Analysis. (arXiv:2306.02831v1 [stat.ML])

    [http://arxiv.org/abs/2306.02831](http://arxiv.org/abs/2306.02831)

    本文提出了一种多任务、多模态的有向无环图（MM-DAG）学习方法，应用于交通拥堵分析，以最大化图的一致性和一致性，通过多模态回归对不同变量之间的关系进行线性因果关系描述。

    

    本文提出了学习多任务、多模态的有向无环图（MM-DAG），这种图常见于复杂系统，如交通、制造和天气系统，变量是标量、向量和函数的混合。本文以交通拥堵分析为具体案例，其中一个交通路口通常被认为是一个 DAG。在多个交叉口组成的交通网络中，不同的交叉口只能观察到一些重叠和不同的变量。例如，一个信号ized的路口有关于交通灯的变量，而非信号ized的路口则没有。这促进了多任务设计：将每个DAG作为一个任务，MM-DAG试图共同学习多个DAG，以最大化它们的一致性和一致性。为此，我们创新性地提出了多模态回归，用于线性因果关系描述不同变量之间的关系。然后，我们开发了一种新的因果性差异（CD）度量及其的差分形式。

    This paper proposes to learn Multi-task, Multi-modal Direct Acyclic Graphs (MM-DAGs), which are commonly observed in complex systems, e.g., traffic, manufacturing, and weather systems, whose variables are multi-modal with scalars, vectors, and functions. This paper takes the traffic congestion analysis as a concrete case, where a traffic intersection is usually regarded as a DAG. In a road network of multiple intersections, different intersections can only have some overlapping and distinct variables observed. For example, a signalized intersection has traffic light-related variables, whereas unsignalized ones do not. This encourages the multi-task design: with each DAG as a task, the MM-DAG tries to learn the multiple DAGs jointly so that their consensus and consistency are maximized. To this end, we innovatively propose a multi-modal regression for linear causal relationship description of different variables. Then we develop a novel Causality Difference (CD) measure and its differen
    
[^15]: 基于量子核心集构造的近最优聚类算法

    Near-Optimal Quantum Coreset Construction Algorithms for Clustering. (arXiv:2306.02826v1 [quant-ph])

    [http://arxiv.org/abs/2306.02826](http://arxiv.org/abs/2306.02826)

    本文提供了一种基于量子核心集构造的近最优聚类算法，可以在$\tilde{O}(\sqrt{nk}d^{3/2})$的查询复杂度下缩小了输入大小，并为各种$k$-聚类近似算法提供了二次加速。

    

    在$\mathbb{R}^d$中$k$-聚类（例如$k$-中位数和$k$-均值）是一种基本的机器学习问题。尽管已知在经典设置下对于具有基数$n$的数据集的近线性时间近似算法，但对于子线性时间量子算法仍然是未知的。我们提供了一种在$\mathbb{R}^d$中查找$k$-聚类核心集的量子算法，其查询复杂度为$\tilde{O}(\sqrt{nk}d^{3/2})$。我们的核心集将输入大小从$n$减少到$\mathrm{poly}(k\epsilon^{-1}d)$，从而现有的聚类$\alpha$-近似算法可以在其上运行并产生$(1+\epsilon)\alpha$-近似。这最终为各种$k$-聚类近似算法提供了二次加速。我们补充了近乎匹配的下界，即任何量子算法必须进行$\Omega(\sqrt{nk})$次查询才能实现甚至于$k$-聚类的$O(1)$-近似。

    $k$-Clustering in $\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a fundamental machine learning problem. While near-linear time approximation algorithms were known in the classical setting for a dataset with cardinality $n$, it remains open to find sublinear-time quantum algorithms. We give quantum algorithms that find coresets for $k$-clustering in $\mathbb{R}^d$ with $\tilde{O}(\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input size from $n$ to $\mathrm{poly}(k\epsilon^{-1}d)$, so that existing $\alpha$-approximation algorithms for clustering can run on top of it and yield $(1 + \epsilon)\alpha$-approximation. This eventually yields a quadratic speedup for various $k$-clustering approximation algorithms. We complement our algorithm with a nearly matching lower bound, that any quantum algorithm must make $\Omega(\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation for $k$-clustering.
    
[^16]: 基于逻辑回归方法增强正无标记数据的朴素分类器

    Enhancing naive classifier for positive unlabeled data based on logistic regression approach. (arXiv:2306.02798v1 [stat.ML])

    [http://arxiv.org/abs/2306.02798](http://arxiv.org/abs/2306.02798)

    通过基于逻辑回归方法的朴素分类器并优化选择分类器的截距，即使拟合的PU数据并不符合该模型，也能获得与竞争对手相当或更好的结果。

    

    我们认为，在选择完全随机（SCAR）假设下分析正无标记（PU）数据时，将问题视为对数据拟合错误规范模型将是有益的。换句话说，我们展示了在拟合逻辑回归模型时，即使拟合的PU数据并不符合该模型，拟合结果也意味着得到的参数向量与真实参数向量近似共线。这一观察结果与基于类似于F1度量的优化选择分类器的截距相结合，可在几个实际数据集上获得与竞争对手相当或更好的结果。

    We argue that for analysis of Positive Unlabeled (PU) data under Selected Completely At Random (SCAR) assumption it is fruitful to view the problem as fitting of misspecified model to the data. Namely, we show that the results on misspecified fit imply that in the case when posterior probability of the response is modelled by logistic regression, fitting the logistic regression to the observable PU data which {\it does not} follow this model, still yields the vector of estimated parameters approximately colinear with the true vector of parameters. This observation together with choosing the intercept of the classifier based on optimisation of analogue of F1 measure yields a classifier which performs on par or better than its competitors on several real data sets considered.
    
[^17]: 神经网络集合的输入梯度多样性

    Input gradient diversity for neural network ensembles. (arXiv:2306.02775v1 [stat.ML])

    [http://arxiv.org/abs/2306.02775](http://arxiv.org/abs/2306.02775)

    本文提出了一阶斥力深度集成 (FoRDE) 算法，它使用输入梯度来增强多样性以提高神经网络集成的表现。

    

    深度集成 (DE) 通过它们的功能多样性在准确性、校准性和抵抗干扰方面表现出比单个神经网络更好的表现。基于粒子的变分推断 (ParVI) 方法通过基于网络相似性内核的排斥项来增强多样性。然而，由于过度参数化，权重空间排斥是低效的，而直接功能空间排斥被发现对 DE 的改进很小。为了避免这些困难，我们提出了基于 ParVI 的一阶斥力深度集成 (FoRDE)，这是一种基于输入梯度的集成学习方法。由于输入梯度唯一地确定了一个函数并且比权重小得多，所以这种方法保证了集合成员在功能上是不同的。直观地说，多样化输入梯度鼓励每个网络学习不同的特征，这有望改善神经网络集成的表现。

    Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improv
    
[^18]: 实现合成主动推理代理，第二部分：变分信息更新

    Realising Synthetic Active Inference Agents, Part II: Variational Message Updates. (arXiv:2306.02733v1 [stat.ML])

    [http://arxiv.org/abs/2306.02733](http://arxiv.org/abs/2306.02733)

    本文讨论了解决广义自由能（FE）目标的合成主动推理代理的变分信息更新和消息传递算法，通过对T形迷宫导航任务的模拟比较，表明AIF可引起认知行为。

    

    自由能原理（FEP）描述生物代理通过相应环境的生成模型最小化变分自由能（FE）。主动推理（AIF）是FEP的推论，描述了代理人通过最小化期望的FE目标来探索和利用其环境。在两篇相关论文中，我们通过自由形式Forney-style因子图（FFG）上的消息传递，描述了一种可扩展的合成AIF代理的认知方法。本文（第二部分）根据变分演算法，导出了最小化CFFG上（广义）FE目标的消息传递算法。比较了模拟Bethe和广义FE代理之间的差异，说明了合成AIF如何在T形迷宫导航任务上引起认知行为。通过对合成AIF代理的完整消息传递描述，可以推导和重用该代理在不同环境下的行为。

    The Free Energy Principle (FEP) describes (biological) agents as minimising a variational Free Energy (FE) with respect to a generative model of their environment. Active Inference (AIF) is a corollary of the FEP that describes how agents explore and exploit their environment by minimising an expected FE objective. In two related papers, we describe a scalable, epistemic approach to synthetic AIF agents, by message passing on free-form Forney-style Factor Graphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG) notation that visually represents (generalised) FE objectives for AIF. The current paper (part II) derives message passing algorithms that minimise (generalised) FE objectives on a CFFG by variational calculus. A comparison between simulated Bethe and generalised FE agents illustrates how synthetic AIF induces epistemic behaviour on a T-maze navigation task. With a full message passing account of synthetic AIF agents, it becomes possible to derive and reuse 
    
[^19]: 缺失值下的一致性预测

    Conformal Prediction with Missing Values. (arXiv:2306.02732v1 [stat.ML])

    [http://arxiv.org/abs/2306.02732](http://arxiv.org/abs/2306.02732)

    本文研究了在协变量中存在缺失值的一致性预测，提出了缺失数据扩充的广义一致化分位数回归框架，可以得出条件于缺失值模式的有效预测间隔。

    

    一致性预测是一种构建预测间隔的理论基础框架。我们研究了在协变量中存在缺失值的一致性预测，这种情况给不确定性量化带来了新的挑战。我们首先证明了对于任何缺失数据分布和几乎所有的插补函数，一致性预测的边缘覆盖保证在插补数据上成立。然而，我们强调平均覆盖度取决于缺失值的模式：在某些缺失模式下，一致性方法倾向于构建低估响应的预测间隔。这激发了我们的新型广义一致化分位数回归框架，缺失数据扩充，它可以得出条件于缺失值模式的有效预测间隔，尽管存在指数数量的缺失模式。然后，我们证明在插补数据上训练的普遍一致分位数回归算法是期望损失最小的最优贝叶斯算法。

    Conformal prediction is a theoretically grounded framework for constructing predictive intervals. We study conformal prediction with missing values in the covariates -- a setting that brings new challenges to uncertainty quantification. We first show that the marginal coverage guarantee of conformal prediction holds on imputed data for any missingness distribution and almost all imputation functions. However, we emphasize that the average coverage varies depending on the pattern of missing values: conformal methods tend to construct prediction intervals that under-cover the response conditionally to some missing patterns. This motivates our novel generalized conformalized quantile regression framework, missing data augmentation, which yields prediction intervals that are valid conditionally to the patterns of missing values, despite their exponential number. We then show that a universally consistent quantile regression algorithm trained on the imputed data is Bayes optimal for the pin
    
[^20]: Gibbs采样神经网络的后验分布

    Gibbs Sampling the Posterior of Neural Networks. (arXiv:2306.02729v1 [cs.LG])

    [http://arxiv.org/abs/2306.02729](http://arxiv.org/abs/2306.02729)

    这篇论文提出了一种添加噪声的神经网络模型，并使用Gibbs采样器从后验分布中进行采样，该方法在真实数据和合成数据中能够达到类似于马尔科夫链蒙特卡洛方法的性能。

    

    本文研究了从神经网络的后验分布中进行采样。我们提出了一种新的概率模型，该模型在网络的每个预激活和后激活中添加噪声，并认为使用有效的Gibbs采样器可以采样得到所得到的后验分布。在真实数据和合成数据上，Gibbs采样器能够达到类似于状态-of-the-art的马尔科夫链蒙特卡洛方法（如哈密顿蒙特卡洛或Metropolis调整Langevin算法）的性能。通过在师生设置中进行分析，我们引入了一个热化准则，该准则允许我们检测算法在使用合成标签的数据上运行时是否无法从后验分布中采样。该准则基于师生设置中的事实，我们可以直接在平衡点处初始化算法。

    In this paper, we study sampling from a posterior derived from a neural network. We propose a new probabilistic model consisting of adding noise at every pre- and post-activation in the network, arguing that the resulting posterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler attains similar performances as the state-of-the-art Monte Carlo Markov chain methods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted Langevin algorithm, both on real and synthetic data. By framing our analysis in the teacher-student setting, we introduce a thermalization criterion that allows us to detect when an algorithm, when run on data with synthetic labels, fails to sample from the posterior. The criterion is based on the fact that in the teacher-student setting we can initialize an algorithm directly at equilibrium.
    
[^21]: 用于液压状态监测系统异常检测的半监督学习比较研究

    Comparative Study on Semi-supervised Learning Applied for Anomaly Detection in Hydraulic Condition Monitoring System. (arXiv:2306.02709v1 [cs.LG])

    [http://arxiv.org/abs/2306.02709](http://arxiv.org/abs/2306.02709)

    本研究比较了不同类型的半监督学习方法在液压状态监测系统中用于异常检测。深度学习模型表现最好，而集成模型可以进一步提高检测性能。

    

    基于状态的维护在液压系统中变得越来越重要。然而，这些系统的异常检测仍然具有挑战性，特别是由于异常数据很少，标记这些数据是费时费力甚至危险的。因此，建议使用无监督或半监督方法，特别是对于只有少量标签可用的情况下利用无监督学习作为特征提取机制来辅助监督学习的半监督学习方法。本研究系统地比较了在液压状态监测系统中应用的半监督学习方法用于异常检测。首先，进行了深入的数据分析和特征学习，以了解开源的液压状态监测数据集。然后，实施和评估了各种方法，包括传统的独立半监督学习模型（例如，一类支持向量机、鲁棒协方差）、集成模型（例如，孤立森林）和基于深度学习的模型（例如，自动编码器、图卷积网络）。结果表明，深度学习模型优于传统模型，而集成模型可以进一步提高检测性能。

    Condition-based maintenance is becoming increasingly important in hydraulic systems. However, anomaly detection for these systems remains challenging, especially since that anomalous data is scarce and labeling such data is tedious and even dangerous. Therefore, it is advisable to make use of unsupervised or semi-supervised methods, especially for semi-supervised learning which utilizes unsupervised learning as a feature extraction mechanism to aid the supervised part when only a small number of labels are available. This study systematically compares semi-supervised learning methods applied for anomaly detection in hydraulic condition monitoring systems. Firstly, thorough data analysis and feature learning were carried out to understand the open-sourced hydraulic condition monitoring dataset. Then, various methods were implemented and evaluated including traditional stand-alone semi-supervised learning models (e.g., one-class SVM, Robust Covariance), ensemble models (e.g., Isolation F
    
[^22]: 将NP困难的最小最大路径问题作为具有公平背景的顺序生成来解决

    Solving NP-hard Min-max Routing Problems as Sequential Generation with Equity Context. (arXiv:2306.02689v1 [cs.LG])

    [http://arxiv.org/abs/2306.02689](http://arxiv.org/abs/2306.02689)

    本文提出了一个新的深度学习框架Equity-Transformer来解决大规模的最小最大路径问题。该模型利用可扩展的深度学习模型进行顺序决策，并生成考虑公平工作负载的顺序动作。研究显示，Equity-Transformer在两个代表性最小最大路径问题中具有卓越的性能。

    

    最小最大路径问题旨在最小化所有代理商协同访问所有城市的最大旅游长度，即完成时间。这些问题包括有影响力的实际应用，但被认为是NP困难的。现有方法面临挑战，特别是在需要协调众多代理商覆盖数千个城市的大规模问题中。本文提出了一个新的深度学习框架来解决大规模的最小最大路径问题。我们将多个代理商的同时决策建模为顺序生成过程，允许利用可扩展的深度学习模型进行顺序决策。在顺序近似问题中，我们提出了一个可扩展的上下文Transformer模型Equity-Transformer，它生成考虑其他代理商之间公平工作负载的顺序动作。Equity-Transformer的有效性通过其在两个代表性最小最大路径问题中具有卓越的性能得到证明。

    Min-max routing problems aim to minimize the maximum tour length among agents as they collaboratively visit all cities, i.e., the completion time. These problems include impactful real-world applications but are known as NP-hard. Existing methods are facing challenges, particularly in large-scale problems that require the coordination of numerous agents to cover thousands of cities. This paper proposes a new deep-learning framework to solve large-scale min-max routing problems. We model the simultaneous decision-making of multiple agents as a sequential generation process, allowing the utilization of scalable deep-learning models for sequential decision-making. In the sequentially approximated problem, we propose a scalable contextual Transformer model, Equity-Transformer, which generates sequential actions considering an equitable workload among other agents. The effectiveness of Equity-Transformer is demonstrated through its superior performance in two representative min-max routing 
    
[^23]: Meta-SAGE：用引导探索的规划方法和比例一元学习进行协同优化规模偏移问题

    Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization. (arXiv:2306.02688v1 [cs.LG])

    [http://arxiv.org/abs/2306.02688](http://arxiv.org/abs/2306.02688)

    本研究提出了一种名为Meta-SAGE的新方法，用于解决组合优化任务中深度强化学习模型可扩展性的问题。该方法通过比例元学习和时间表调整来适应模型，并真实地优化了相关任务的性能表现。

    

    本文提出了一种称之为Meta-SAGE的新方法，旨在改善组合优化（CO）任务的深度强化学习模型的可扩展性。本方法通过建议两个组件来在测试时间适应预训练模型以解决规模问题：一个是比例元学习器（SML），另一个是具有引导探索和时间表调整功能的scheduled adaptation with guided exploration（SAGE）。实验结果表明，Meta-SAGE优于以前的适应方法，并显著提高了代表性CO任务的可扩展性。

    This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage
    
[^24]: 基于并行评分匹配的扩散模型更快的训练和改进密度估计

    Faster Training of Diffusion Models and Improved Density Estimation via Parallel Score Matching. (arXiv:2306.02658v1 [cs.LG])

    [http://arxiv.org/abs/2306.02658](http://arxiv.org/abs/2306.02658)

    本文提出一种基于并行评分匹配的扩散模型训练方法，通过利用不同时间点的任务独立性，采用独立网络建模分数演变，提高了密度估计性能，加速了训练过程。

    

    在扩散概率模型(DPMs)中，单个时间依赖神经网络模型评分演变的任务需要长时间的训练，可能会阻碍建模的灵活性和能力。为了克服这些挑战，我们提出利用 DPMs 固有的不同时间点学习任务的独立性。具体而言，我们通过使用独立的网络将学习任务进行划分，每个网络专门学习特定时间子间隔内的分数演变。受残差流的启发，我们将此策略扩展到其逻辑结论，采用单独的网络独立建模每个时间点的分数。通过对合成和图像数据集的实证证明，我们的方法不仅通过在数据并行化之上引入额外的并行化层显著加速了训练过程，而且在与现有方法比较时，提高了密度估计性能。

    In Diffusion Probabilistic Models (DPMs), the task of modeling the score evolution via a single time-dependent neural network necessitates extended training periods and may potentially impede modeling flexibility and capacity. To counteract these challenges, we propose leveraging the independence of learning tasks at different time points inherent to DPMs. More specifically, we partition the learning task by utilizing independent networks, each dedicated to learning the evolution of scores within a specific time sub-interval. Further, inspired by residual flows, we extend this strategy to its logical conclusion by employing separate networks to independently model the score at each individual time point. As empirically demonstrated on synthetic and image datasets, our approach not only significantly accelerates the training process by introducing an additional layer of parallelization atop data parallelization, but it also enhances density estimation performance when compared to the co
    
[^25]: 通过强制条件单调性在Early-Exit结构中实现随时分类

    Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity. (arXiv:2306.02652v1 [cs.LG])

    [http://arxiv.org/abs/2306.02652](http://arxiv.org/abs/2306.02652)

    本文提出了一种在Early-Exit网络中实现条件单调性的方法，将深度模型转化为真正的随时分类器。

    

    现代预测模型通常部署在计算预算动态的环境中。随时算法非常适用于这种环境，因为它们在计算的任何时候都可以输出预测值，其质量是计算时间的函数。由于其能够在网络各个阶段提供中间预测结果的能力，Early-Exit神经网络在随时计算的背景下引起了人们的关注。然而，我们证明当前的Early-Exit网络并不直接适用于任何时候的设置，因为单个数据点的预测质量不能保证随着计算时间的增加而提高。为了解决这个缺陷，我们提出了一种优雅的事后修改，基于专家乘积，鼓励Early-Exit网络逐渐变得自信。这赋予了我们的深度模型条件单调性的特性——这是实现真正随时分类的重要基石。

    Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of conditional monotonicity in the prediction quality -- an essential stepping stone towards truly an
    
[^26]: 协方差自适应最佳臂识别问题

    Covariance Adaptive Best Arm Identification. (arXiv:2306.02630v1 [stat.ML])

    [http://arxiv.org/abs/2306.02630](http://arxiv.org/abs/2306.02630)

    本文提出了一个协方差自适应的最佳臂识别问题，相较于独立臂分布假设下的解决方案，能更有效地识别出高平均奖励的臂，适用于临床试验等场景。

    

    本文研究了在多臂老虎机模型下，基于固定置信度的最佳臂识别问题。在给定置信度 $\delta$ 的情况下，旨在以至少 1 - $\delta$ 的概率识别出具有最高平均奖励的臂，同时最小化臂的拉动次数。虽然文献提供了针对独立臂分布假设下该问题的解决方案，但我们提出了一个更加灵活的情形，其中臂可以是相关的，并且收益可以同时进行采样。该框架允许学习者估计臂之间分布的协方差，从而更有效地识别最佳臂。我们提出了适应臂协方差的新算法，并通过理论保证证明其具有实质性改进。

    We consider the problem of best arm identification in the multi-armed bandit model, under fixed confidence. Given a confidence input $\delta$, the goal is to identify the arm with the highest mean reward with a probability of at least 1 -- $\delta$, while minimizing the number of arm pulls. While the literature provides solutions to this problem under the assumption of independent arms distributions, we propose a more flexible scenario where arms can be dependent and rewards can be sampled simultaneously. This framework allows the learner to estimate the covariance among the arms distributions, enabling a more efficient identification of the best arm. The relaxed setting we propose is relevant in various applications, such as clinical trials, where similarities between patients or drugs suggest underlying correlations in the outcomes. We introduce new algorithms that adapt to the unknown covariance of the arms and demonstrate through theoretical guarantees that substantial improvement 
    
[^27]: 基于多个任务表现的专家积极排名问题

    Active Ranking of Experts Based on their Performances in Many Tasks. (arXiv:2306.02628v1 [stat.ML])

    [http://arxiv.org/abs/2306.02628](http://arxiv.org/abs/2306.02628)

    本文提出了基于多个任务表现的专家积极排名问题及处理方法，通过单调性假设及文章提供的策略在保证置信度的情况下，实现了专家正确排名，且该策略具有自适应性。

    

    我们考虑基于d个任务的n个专家的表现来排名专家的问题。我们提出了一个单调性假设，即对于每对专家，其中一个在所有任务上表现优于另一个。我们考虑按顺序进行的情况，在每一轮中，学习者都可以访问有噪声的评估，并选择一对专家任务，给出到实际轮次为止可用的信息。给定置信度参数$\delta$ $\in$ (0,1)，我们提供策略，允许恢复专家的正确排名，并开发出一个算法在概率至少为1-$\delta$下保持的查询总数上的界限。我们表明我们的策略对问题的复杂性是自适应的(我们的限制是实例相关的)，并开发出与理论下限相匹配的结果(多对数的因子)。最后，我们将策略适应到最佳专家识别的问题上，并提供与我们的理论结果一致的数值模拟。

    We consider the problem of ranking n experts based on their performances on d tasks. We make a monotonicity assumption stating that for each pair of experts, one outperforms the other on all tasks. We consider the sequential setting where in each round, the learner has access to noisy evaluations of actively chosen pair of expert-task, given the information available up to the actual round. Given a confidence parameter $\delta$ $\in$ (0, 1), we provide strategies allowing to recover the correct ranking of experts and develop a bound on the total number of queries made by our algorithm that hold with probability at least 1 -- $\delta$. We show that our strategy is adaptive to the complexity of the problem (our bounds are instance dependent), and develop matching lower bounds up to a poly-logarithmic factor. Finally, we adapt our strategy to the relaxed problem of best expert identification and provide numerical simulation consistent with our theoretical results.
    
[^28]: 朝向最小化器：过参数化问题中随机梯度下降的快速收敛

    Aiming towards the minimizers: fast convergence of SGD for overparametrized problems. (arXiv:2306.02601v1 [cs.LG])

    [http://arxiv.org/abs/2306.02601](http://arxiv.org/abs/2306.02601)

    本文提出了在插值区域内的正则条件，对于过参数化问题采用随机梯度下降方法能够达到和确定性梯度下降相同的最坏情况复杂度，并具有更快的收敛速率。

    

    现代机器学习范式，如深度学习，出现在插值区域内或接近插值区域，其中模型参数的数量远大于数据样本的数量。在这项工作中，我们提出了插值区域内的一种正则条件，赋予随机梯度方法与确定性梯度方法相同的最坏迭代复杂度，而在每次迭代中仅使用单个抽样的梯度（或小批量）。相比之下，所有现有的保证都要求随机梯度方法采取小步长，从而导致收敛速率明显减慢。最后，我们证明了当训练具有线性输出层的足够宽的前馈神经网络时，我们的条件成立。

    Modern machine learning paradigms, such as deep learning, occur in or close to the interpolation regime, wherein the number of model parameters is much larger than the number of data samples. In this work, we propose a regularity condition within the interpolation regime which endows the stochastic gradient method with the same worst-case iteration complexity as the deterministic gradient method, while using only a single sampled gradient (or a minibatch) in each iteration. In contrast, all existing guarantees require the stochastic gradient method to take small steps, thereby resulting in a much slower linear rate of convergence. Finally, we demonstrate that our condition holds when training sufficiently wide feedforward neural networks with a linear output layer.
    
[^29]: 探索和利用模型库中多样化的知识以实现领域泛化

    Explore and Exploit the Diverse Knowledge in Model Zoo for Domain Generalization. (arXiv:2306.02595v1 [cs.LG])

    [http://arxiv.org/abs/2306.02595](http://arxiv.org/abs/2306.02595)

    本文探讨了通过利用模型库中多样化的知识来提高领域泛化能力的方法，强调认为弱模型中所包含的知识具有价值。通过比较各种已预训练好的模型在不同领域下的表现，刻画它们在编码表示上的多样性偏移和相关性偏移等特征以提高领域泛化能力。

    

    预训练模型的广泛应用已经导致了大量公共可用模型的出现。有效地利用这些资源，以获得在下游任务中具有强韧性的模型，已成为一个至关重要的研究领域。之前的研究主要集中在识别模型库中最强大的模型上，而忽视了其中包含的多样的归纳偏差。本文认为弱模型中所包含的知识具有价值，并提出了一种利用模型库中多样性以提高领域泛化能力的方法。具体来说，我们通过将编码表示的变化刻画为多元的“多样性偏移”和“相关性偏移”，来研究不同领域下的多种预训练模型的行为。

    The proliferation of pretrained models, as a result of advancements in pretraining techniques, has led to the emergence of a vast zoo of publicly available models. Effectively utilizing these resources to obtain models with robust out-of-distribution generalization capabilities for downstream tasks has become a crucial area of research. Previous research has primarily focused on identifying the most powerful models within the model zoo, neglecting to fully leverage the diverse inductive biases contained within. This paper argues that the knowledge contained in weaker models is valuable and presents a method for leveraging the diversity within the model zoo to improve out-of-distribution generalization capabilities. Specifically, we investigate the behaviors of various pretrained models across different domains of downstream tasks by characterizing the variations in their encoded representations in terms of two dimensions: diversity shift and correlation shift. This characterization ena
    
[^30]: 潜变量能量模型简介：实现自主机器智能路径

    Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence. (arXiv:2306.02572v1 [cs.LG])

    [http://arxiv.org/abs/2306.02572](http://arxiv.org/abs/2306.02572)

    用能量模型和潜变量模型相结合的层次联合嵌入预测架构（H-JEPA），是 Yann LeCun提出的实现未来自主智能的关键。

    

    当前自动化系统存在关键限制需要解决，才能达到人类水平的人工智能，并引领新的技术革命。在这篇论文中，我们总结了Yann LeCun提出的面向未来自主智能架构的主要思想。特别是，我们介绍了能量模型和潜变量模型，并将它们的优点结合起来，构建LeCun提出的层次联合嵌入预测架构（H-JEPA）的基本模块。

    Current automated systems have crucial limitations that need to be addressed before artificial intelligence can reach human-like levels and bring new technological revolutions. Among others, our societies still lack Level 5 self-driving cars, domestic robots, and virtual assistants that learn reliable world models, reason, and plan complex action sequences. In these notes, we summarize the main ideas behind the architecture of autonomous intelligence of the future proposed by Yann LeCun. In particular, we introduce energy-based and latent variable models and combine their advantages in the building block of LeCun's proposal, that is, in the hierarchical joint embedding predictive architecture (H-JEPA).
    
[^31]: Gumbel传播下的潜在最优路径变分贝叶斯动态规划

    Latent Optimal Paths by Gumbel Propagation for Variational Bayesian Dynamic Programming. (arXiv:2306.02568v1 [stat.ML])

    [http://arxiv.org/abs/2306.02568](http://arxiv.org/abs/2306.02568)

    该论文使用动态规划和Gumbel传播在VAE的潜在空间中获得结构化稀疏最优路径，从而使得模型可以依赖于未观察到的结构特征信息，并成功实现了文本转语音和歌声合成。

    

    我们提出了一种统一方法，使用动态规划和Gumbel传播在变分自编码器（VAE）的潜在空间中获取结构化稀疏最优路径。我们通过概率软化解，即随机最优路径，来解决经典最优路径问题，并将广泛的DP问题转化为有向无环图，其中所有可能的路径遵循Gibbs分布。我们通过Gumbel分布的属性显示Gibbs分布与消息传递算法的等价性，并提供了变分贝叶斯推理所需的所有要素。我们的方法获取了潜在最优路径，使生成任务的端到端训练成为可能，其中模型依赖于未观察到的结构特征的信息。我们验证了我们方法的行为，并展示了其在两个真实世界应用中的适用性：文本转语音和歌声合成。

    We propose a unified approach to obtain structured sparse optimal paths in the latent space of a variational autoencoder (VAE) using dynamic programming and Gumbel propagation. We solve the classical optimal path problem by a probability softening solution, called the stochastic optimal path, and transform a wide range of DP problems into directed acyclic graphs in which all possible paths follow a Gibbs distribution. We show the equivalence of the Gibbs distribution to a message-passing algorithm by the properties of the Gumbel distribution and give all the ingredients required for variational Bayesian inference. Our approach obtaining latent optimal paths enables end-to-end training for generative tasks in which models rely on the information of unobserved structural features. We validate the behavior of our approach and showcase its applicability in two real-world applications: text-to-speech and singing voice synthesis.
    
[^32]: 联合变分自编码器

    Coupled Variational Autoencoder. (arXiv:2306.02565v1 [stat.ML])

    [http://arxiv.org/abs/2306.02565](http://arxiv.org/abs/2306.02565)

    C-VAE通过将VAE问题制定为最优输运问题并在先验和数据分布之间强制耦合，实现了对先验的更大灵活性、解决了先验存在的空洞问题，并在保真度、潜在表示的质量和生成样本的质量等方面优于VAE、WAE和InfoVAE等替代方案。

    

    变分自编码器在生成任务中是强大的概率模型，但会产生低质量的样本，这是由于先验中存在空洞所导致的。我们提出了联合变分自编码器(C-VAE)，将VAE问题制定为先验和数据分布之间的最优输运(OT)问题。C-VAE通过在先验和数据分布之间强制耦合，实现了对先验的更大灵活性和自然地解决了先验存在的空洞问题，并通过熵OT的原始、对偶和半对偶形式实现了灵活的优化。对合成和真实数据的模拟表明，C-VAE在数据的保真度、潜在表示的质量和生成样本的质量等方面优于其他替代方案，包括VAE、WAE和InfoVAE。

    Variational auto-encoders are powerful probabilistic models in generative tasks but suffer from generating low-quality samples which are caused by the holes in the prior. We propose the Coupled Variational Auto-Encoder (C-VAE), which formulates the VAE problem as one of Optimal Transport (OT) between the prior and data distributions. The C-VAE allows greater flexibility in priors and natural resolution of the prior hole problem by enforcing coupling between the prior and the data distribution and enables flexible optimization through the primal, dual, and semi-dual formulations of entropic OT. Simulations on synthetic and real data show that the C-VAE outperforms alternatives including VAE, WAE, and InfoVAE in fidelity to the data, quality of the latent representation, and in quality of generated samples.
    
[^33]: 早期停止的神经网络中的清洁优先学习现象的出现

    On Emergence of Clean-Priority Learning in Early Stopped Neural Networks. (arXiv:2306.02533v1 [cs.LG])

    [http://arxiv.org/abs/2306.02533](http://arxiv.org/abs/2306.02533)

    当训练数据集中添加随机标签噪声时，神经网络会先学习干净数据再学习噪声，导致预测误差呈现U形曲线。本研究探索了这种清洁优先学习的学习动态，并提出了提高神经网络对标签噪声鲁棒性的潜在策略。

    

    当训练数据集中添加随机标签噪声时，神经网络在没有噪声的测试数据集上的预测误差在早期训练过程中会先改善后恶化，呈现出一个U形的依赖于训练时间的曲线。我们认为，这种行为是神经网络在训练中先学习干净数据的模式，然后再逐渐拟合噪声的结果。我们称之为清洁优先学习现象。本研究旨在探索该现象背后的学习动态。我们在理论上证明了，在训练的早期阶段，梯度下降的更新方向由训练数据的干净子集决定，噪声子集的影响是最小的或没有的，导致了优先进行干净数据的学习。此外，我们理论上和实验上都显示，在进行清洁优先学习的过程中，清洁样本的梯度在嘈杂样本的梯度之上的优势逐渐减小，最终形成了预测误差的U形曲线。我们的发现为清洁优先学习现象的出现提供了深入的洞察，并提出了提高神经网络对标签噪声的鲁棒性的潜在策略。

    When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time. This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning. In this study, we aim to explore the learning dynamics underlying this phenomenon. We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning. Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally res
    
[^34]: 图傅里叶移动距离用于图信号

    Graph Fourier MMD for Signals on Graphs. (arXiv:2306.02508v1 [cs.LG])

    [http://arxiv.org/abs/2306.02508](http://arxiv.org/abs/2306.02508)

    提出了一种新的用于比较图上信号的方法——图傅里叶移动距离（GFMMD），它是通过一个最优的见证函数进行定义，并且在合成和真实数据集上进行的实验表明它优于现有的比较图信号方法。

    

    尽管已经提出了许多方法来计算欧几里得空间概率分布之间的距离，但是相对于计算这样的距离在图上分布的情况下却给予了相对较少的关注。然而，在生物医学科学领域，无论是位于图上（如蛋白质相互作用网络）还是可被建模为图的数据（单细胞数据）都有显著增加。因此，重要的是要找到比较定义在这种图上的信号的方法。在这里，我们提出了一种新的分布和图上信号之间的距离，称为图傅里叶移动距离（GFMMD）。GFMMD通过一个最优的见证函数进行定义，这个函数既在图上平滑，又最大化了在图上的两个分布之间的期望差异。我们发现了这个优化问题的一个解析解以及由该方法产生的分布嵌入。我们还证明了该方法的几个性质，包括尺度不变性和适用于一般图形。我们在合成和真实数据集上对GFMMD进行了实证评估，并显示它优于现有比较图信号方法。

    While numerous methods have been proposed for computing distances between probability distributions in Euclidean space, relatively little attention has been given to computing such distances for distributions on graphs. However, there has been a marked increase in data that either lies on graph (such as protein interaction networks) or can be modeled as a graph (single cell data), particularly in the biomedical sciences. Thus, it becomes important to find ways to compare signals defined on such graphs. Here, we propose Graph Fourier MMD (GFMMD), a novel distance between distributions and signals on graphs. GFMMD is defined via an optimal witness function that is both smooth on the graph and maximizes difference in expectation between the pair of distributions on the graph. We find an analytical solution to this optimization problem as well as an embedding of distributions that results from this method. We also prove several properties of this method including scale invariance and appli
    
[^35]: 待售：基于状态-动作表示学习的深度强化学习

    For SALE: State-Action Representation Learning for Deep Reinforcement Learning. (arXiv:2306.02451v1 [cs.LG])

    [http://arxiv.org/abs/2306.02451](http://arxiv.org/abs/2306.02451)

    SALE是一种基于状态-动作表示学习的新方法，可以有效地从低级状态中实现表示学习，TD7算法引入了该方法并在连续控制任务中表现优异。

    

    在强化学习领域中，表示学习是处理复杂基于图像任务的有效工具，但通常被忽略了低级状态（例如物理控制问题）的环境。本文介绍了一种名为SALE的新方法，它可以学习嵌入来建模状态和动作之间微妙的相互作用，从低级状态中实现有效的表示学习。我们广泛研究了这些嵌入的设计空间，并强调了重要的设计考虑因素。我们将SALE和RL的检查点自适应方法整合到TD3中，形成TD7算法，该算法在连续控制任务中的表现明显优于现有算法。在OpenAI gym基准任务中，TD7在300k和5M时间步骤下的平均性能增益分别为276.7％和50.7％，可以在在线和离线设置中使用。

    In the field of reinforcement learning (RL), representation learning is a proven tool for complex image-based tasks, but is often overlooked for environments with low-level states, such as physical control problems. This paper introduces SALE, a novel approach for learning embeddings that model the nuanced interaction between state and action, enabling effective representation learning from low-level states. We extensively study the design space of these embeddings and highlight important design considerations. We integrate SALE and an adaptation of checkpoints for RL into TD3 to form the TD7 algorithm, which significantly outperforms existing continuous control algorithms. On OpenAI gym benchmark tasks, TD7 has an average performance gain of 276.7% and 50.7% over TD3 at 300k and 5M time steps, respectively, and works in both the online and offline settings.
    
[^36]: 抗干扰约束学习

    Resilient Constrained Learning. (arXiv:2306.02426v1 [cs.LG])

    [http://arxiv.org/abs/2306.02426](http://arxiv.org/abs/2306.02426)

    本论文提出了一个名为“抗干扰约束学习”的方法来解决在部署机器学习解决方案时需要满足除了准确性以外的多个要求，并以平衡从放宽中获得的性能增益与用户定义的放宽成本之间的关系的方式放松学习约束。

    

    在部署机器学习解决方案时，除了准确性之外，它们必须满足多个要求，如公平性、鲁棒性或安全性。这些要求可以通过使用惩罚来隐式地施加，或者通过基于Lagrangian对偶的约束优化方法来显式地施加。无论哪种方式，指定要求都受到妥协和有限的有关数据的先前知识的影响。此外，它们对性能的影响通常只能通过实际解决学习问题来评估。本文提出了一种约束学习方法，该方法在同时解决学习任务的同时调整要求。为此，它以平衡从放宽中获得的性能增益与用户定义的放宽成本之间的关系的方式放松了学习约束。我们将此方法称为具有弹性的约束学习，这是对用于描述生态系统的术语的一种借鉴。

    When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems tha
    
[^37]: ContraBAR: 对比贝叶斯自适应深度强化学习

    ContraBAR: Contrastive Bayes-Adaptive Deep RL. (arXiv:2306.02418v1 [cs.LG])

    [http://arxiv.org/abs/2306.02418](http://arxiv.org/abs/2306.02418)

    ContraBAR是一种使用对比贝叶斯自适应深度强化学习的元RL算法，可以在基于状态观察的领域中实现与最先进方法可比较的性能，并规避了未来观察重建的计算代价，从而在基于图像的观察的领域中进行学习。

    

    在元强化学习（meta RL）中，智能体寻求贝叶斯最优策略——面对从某些已知任务分布中采样的未知任务时的最优策略。以前的方法通过推断任务参数上的信念，使用变分推理方法解决这个问题。受强化学习中对比学习方法的最近成功启发，例如对比预测编码（CPC），我们调查对比方法是否可用于学习贝叶斯最优行为。我们首先证明了CPC学习到的表示足以进行贝叶斯最优化。基于这个观察结果，我们提出了一种简单的元RL算法——ContraBAR，它使用CPC代替变分信念推断。我们的方法在基于状态观察的域中实现了与最先进方法可比较的性能，并规避了未来观察重建的计算代价，从而在基于图像的观察的领域中进行学习。

    In meta reinforcement learning (meta RL), an agent seeks a Bayes-optimal policy -- the optimal policy when facing an unknown task that is sampled from some known task distribution. Previous approaches tackled this problem by inferring a belief over task parameters, using variational inference methods. Motivated by recent successes of contrastive learning approaches in RL, such as contrastive predictive coding (CPC), we investigate whether contrastive methods can be used for learning Bayes-optimal behavior. We begin by proving that representations learned by CPC are indeed sufficient for Bayes optimality. Based on this observation, we propose a simple meta RL algorithm that uses CPC in lieu of variational belief inference. Our method, ContraBAR, achieves comparable performance to state-of-the-art in domains with state-based observation and circumvents the computational toll of future observation reconstruction, enabling learning in domains with image-based observations. It can also be c
    
[^38]: 感知卡尔曼滤波器：在完美感知质量约束下的在线状态估计

    Perceptual Kalman Filters: Online State Estimation under a Perfect Perceptual-Quality Constraint. (arXiv:2306.02400v1 [cs.LG])

    [http://arxiv.org/abs/2306.02400](http://arxiv.org/abs/2306.02400)

    本文研究了在完美感知质量约束下的在线状态估计问题，提出了感知卡尔曼滤波器（PKF）这一最优估计器，并提供了其在线实现的实际算法，实现了实时操作。实验证明PKF可以显著提高估计信号的感知质量。

    

    许多实际应用需要从受损或缺失数据中重建时间信号。经典的例子包括解码、跟踪、信号增强和去噪。由于最终重建信号是由人类观看的，因此希望实现令人愉悦的重建效果。在数学上，通过恢复信号分布与自然信号的分布相同来实现完美感知质量，这是静态估计设置（即一次处理整个信号）中已经进行了大量研究的要求。在这里，我们研究了在完美感知质量约束条件下的最优因果滤波问题，这是一种根本不同的任务。具体而言，我们分析了通过线性噪声变换观察的高斯马尔可夫信号。在没有感知约束的情况下，卡尔曼滤波器被认为是该设置中MSE范围内的最优估计器。在这里，我们展示了加入完美感知质量约束会产生一种新的估计器，称为感知卡尔曼滤波器（PKF），它是在此约束条件下的最优估计器。此外，我们提供了其在线实现的实际算法，从而实现了实时操作。实验表明，与传统方法相比，PKF可以显著提高估计信号的感知质量。

    Many practical settings call for the reconstruction of temporal signals from corrupted or missing data. Classic examples include decoding, tracking, signal enhancement and denoising. Since the reconstructed signals are ultimately viewed by humans, it is desirable to achieve reconstructions that are pleasing to human perception. Mathematically, perfect perceptual-quality is achieved when the distribution of restored signals is the same as that of natural signals, a requirement which has been heavily researched in static estimation settings (i.e. when a whole signal is processed at once). Here, we study the problem of optimal causal filtering under a perfect perceptual-quality constraint, which is a task of fundamentally different nature. Specifically, we analyze a Gaussian Markov signal observed through a linear noisy transformation. In the absence of perceptual constraints, the Kalman filter is known to be optimal in the MSE sense for this setting. Here, we show that adding the perfect
    
[^39]: 利普希茨动态风险度量的风险敏感强化学习的遗憾界限

    Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz Dynamic Risk Measures. (arXiv:2306.02399v1 [cs.LG])

    [http://arxiv.org/abs/2306.02399](http://arxiv.org/abs/2306.02399)

    本文研究了利普希茨动态风险度量的风险敏感强化学习，并建立了遗憾上限和下限，上限表明了最佳依赖关系和风险敏感性与样本复杂性之间的平衡。

    

    本文研究了包含动态风险度量的有限情节马尔可夫决策过程，以捕捉风险敏感性。为此，我们提出了两种应用于利普希茨动态风险度量的基于模型的算法，利普希茨动态风险度量是一种广泛的风险度量，包括谱风险度量、优化确定等价、失真风险度量等。我们建立了遗憾上限和下限。值得注意的是，我们的上限表明了动作数量和情节数量的最佳依赖关系，同时反映了风险敏感性和样本复杂性之间固有的平衡。此外，我们通过数值实验验证了我们的理论结果。

    We study finite episodic Markov decision processes incorporating dynamic risk measures to capture risk sensitivity. To this end, we present two model-based algorithms applied to \emph{Lipschitz} dynamic risk measures, a wide range of risk measures that subsumes spectral risk measure, optimized certainty equivalent, distortion risk measures among others. We establish both regret upper bounds and lower bounds. Notably, our upper bounds demonstrate optimal dependencies on the number of actions and episodes, while reflecting the inherent trade-off between risk sensitivity and sample complexity. Additionally, we substantiate our theoretical results through numerical experiments.
    
[^40]: 从一般的确定性取样模式中进行矩阵补全

    Matrix Completion from General Deterministic Sampling Patterns. (arXiv:2306.02283v1 [stat.ML])

    [http://arxiv.org/abs/2306.02283](http://arxiv.org/abs/2306.02283)

    本文建立了一种适用于任何确定性取样方案的精确和近似低秩矩阵补全问题的理论保证方法，并且理论显著改进了已有工作的结果。

    

    现有的大多数低秩矩阵补全算法的可证保证都依赖于一些不切实际的假设，例如矩阵条目是随机采样的，或者采样模式具有特定的结构。在本文中，我们建立了理论保证，适用于任何确定性取样方案的精确和近似低秩矩阵补全问题。为此，我们引入一个图形，其中观察到的条目作为其边界，并研究了它的图形属性，包括标准约束核范数最小化算法的性能。我们从理论和实验上证明，当观察图形连接良好并且具有类似的节点度时，该算法可以成功运行。我们的结果可以看作是 Bhojanapalli 和 Jain [2014] 以及 Burnwal 和 Vidyasagar [2020] 的工作的扩展，在其中观察图的节点度被假定为相同。特别地，我们的理论显著改进了这些工作的结果。

    Most of the existing works on provable guarantees for low-rank matrix completion algorithms rely on some unrealistic assumptions such that matrix entries are sampled randomly or the sampling pattern has a specific structure. In this work, we establish theoretical guarantee for the exact and approximate low-rank matrix completion problems which can be applied to any deterministic sampling schemes. For this, we introduce a graph having observed entries as its edge set, and investigate its graph properties involving the performance of the standard constrained nuclear norm minimization algorithm. We theoretically and experimentally show that the algorithm can be successful as the observation graph is well-connected and has similar node degrees. Our result can be viewed as an extension of the works by Bhojanapalli and Jain [2014] and Burnwal and Vidyasagar [2020], in which the node degrees of the observation graph were assumed to be the same. In particular, our theory significantly improves
    
[^41]: 从非线性混合下的干预中学习线性因果表示

    Learning Linear Causal Representations from Interventions under General Nonlinear Mixing. (arXiv:2306.02235v1 [cs.LG])

    [http://arxiv.org/abs/2306.02235](http://arxiv.org/abs/2306.02235)

    本文针对先前工作弱一类问题进行推广，提出了一种用于在非线性混合下的干预中学习线性因果表示的强可识别性算法，证明了其有效性，并提出了在实践中识别潜在变量的对比算法。

    

    我们研究了在混合函数完全通用的一般设置下，从未知的潜在干预中学习因果表示的问题，其中潜在分布是高斯分布。 我们证明了在单节点未知干预（即没有干预目标的情况下）给出强可识别性结果。这推广了先前的工作，先前的工作着重于更弱的类别，例如线性映射或成对的反事实数据。这也是首次从非配对干预的深度神经网络嵌入中获得因果可识别性。我们的证明依赖于仔细揭示经过非线性密度转换后数据分布中存在的高维几何结构，我们通过分析潜在分布的精度矩阵的二次形式来捕捉这种结构。最后，我们提出了一种对比算法来实际识别潜在变量，并评估其在各种任务上的性能。

    We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of causal identifiability from non-paired interventions for deep neural network embeddings. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks.
    
[^42]: 加速拟牛顿近端外推法：平滑凸优化更快的收敛率

    Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth Convex Optimization. (arXiv:2306.02212v1 [math.OC])

    [http://arxiv.org/abs/2306.02212](http://arxiv.org/abs/2306.02212)

    本论文提出了一种加速拟牛顿近端外推的方法，用于解决无约束平滑凸优化问题，在$k = {O}(d)$时达到最优速率，并在$k = \Omega(d \log d)$时以更快的速率收敛。这是在凸设置中，首个证明拟牛顿类型方法比NAG有可证明优势的方法。

    

    本文提出了一种加速拟牛顿近端外推（A-QPNE）方法，用于解决无约束平滑凸优化问题。仅利用目标函数的梯度，我们证明了我们的方法可以达到收敛速率${O}\bigl(\min\{\frac{1}{k^2}, \frac{\sqrt{d\log k}}{k^{2.5}}\}\bigr)$，其中$d$是问题维度，$k$是迭代次数。特别地，在$k = {O}(d)$的情况下，我们的方法与Nesterov加速梯度（NAG）达到了$O(\frac{1}{k^2})$的最优速率。此外，在$k = \Omega(d \log d)$的区域，我们的方法优于NAG，并以更快的速率${O}\bigl(\frac{\sqrt{d\log k}}{k^{2.5}}\bigr)$收敛。据我们所知，这是首个在凸设置中证明拟牛顿类型方法比NAG有可证明优势的结果。为了实现这样的结果，我们基于Monteiro-Svaiter加速框架的最新变体构建了我们的方法，并采用了在线梯度估计技术。

    In this paper, we propose an accelerated quasi-Newton proximal extragradient (A-QPNE) method for solving unconstrained smooth convex optimization problems. With access only to the gradients of the objective, we prove that our method can achieve a convergence rate of ${O}\bigl(\min\{\frac{1}{k^2}, \frac{\sqrt{d\log k}}{k^{2.5}}\}\bigr)$, where $d$ is the problem dimension and $k$ is the number of iterations. In particular, in the regime where $k = {O}(d)$, our method matches the optimal rate of ${O}(\frac{1}{k^2})$ by Nesterov's accelerated gradient (NAG). Moreover, in the the regime where $k = \Omega(d \log d)$, it outperforms NAG and converges at a faster rate of ${O}\bigl(\frac{\sqrt{d\log k}}{k^{2.5}}\bigr)$. To the best of our knowledge, this result is the first to demonstrate a provable gain of a quasi-Newton-type method over NAG in the convex setting. To achieve such results, we build our method on a recent variant of the Monteiro-Svaiter acceleration framework and adopt an onlin
    
[^43]: 单遍流式多臂赌博机的紧凑遗憾界

    Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits. (arXiv:2306.02208v1 [cs.LG])

    [http://arxiv.org/abs/2306.02208](http://arxiv.org/abs/2306.02208)

    本文回答了单遍流式多臂赌博机的遗憾最小化问题，并展示了一个遗憾上界为$O(K^{1/3} T^{2/3})$ 的算法，说明均匀探索是最优的算法。

    

    近年来，流式多臂赌博机(MABs) 的遗憾最小化得到了广泛的研究。在 $K$ 臂和 $T$ 次试验的单遍设置中，已经证明了任何具有 $o(K)$ 内存的算法的遗憾下限为 $\Omega(T^{2/3})$ (Maiti等人 [NeurIPS'21]; Agarwal等人 [COLT'22])。另一方面，之前最好的遗憾上限仍然是 $O(K^{1/3} T^{2/3}\log^{1/3}(T))$，这是通过简单均匀探索的流式实现实现的。$O(K^{1/3}\log^{1/3}(T))$ 的差距留下了单遍 MABs 的最紧凑的遗憾界的问题。在本文中，我们回答了这个开放性问题，并完成了单遍流式 MABs 的遗憾最小化图景。我们首先将具有 $o(K)$ 内存的算法的遗憾下限改进为 $\Omega(K^{1/3}T^{2/3})$，这与 $T$ 的对数因子匹配均匀探索的遗憾。然后，我们证明了 $\log^{1/3}(T)$ 因子是不必要的，并为任何 $T$ 值提供了遗憾上界为 $O(K^{1/3} T^{2/3})$ 的算法。我们的结果意味着在所有具有次线性内存的算法中，均匀探索是本质上最优秀的。

    Regret minimization in streaming multi-armed bandits (MABs) has been studied extensively in recent years. In the single-pass setting with $K$ arms and $T$ trials, a regret lower bound of $\Omega(T^{2/3})$ has been proved for any algorithm with $o(K)$ memory (Maiti et al. [NeurIPS'21]; Agarwal at al. [COLT'22]). On the other hand, however, the previous best regret upper bound is still $O(K^{1/3} T^{2/3}\log^{1/3}(T))$, which is achieved by the streaming implementation of the simple uniform exploration. The $O(K^{1/3}\log^{1/3}(T))$ gap leaves the open question of the tight regret bound in the single-pass MABs with sublinear arm memory.  In this paper, we answer this open problem and complete the picture of regret minimization in single-pass streaming MABs. We first improve the regret lower bound to $\Omega(K^{1/3}T^{2/3})$ for algorithms with $o(K)$ memory, which matches the uniform exploration regret up to a logarithm factor in $T$. We then show that the $\log^{1/3}(T)$ factor is not n
    
[^44]: 非凸随机梯度下降估计的在线自举推断

    Online Bootstrap Inference with Nonconvex Stochastic Gradient Descent Estimator. (arXiv:2306.02205v1 [stat.ML])

    [http://arxiv.org/abs/2306.02205](http://arxiv.org/abs/2306.02205)

    本文提出了两种新型在线推断程序，将随机梯度下降法和乘数自举技术相结合，用于非凸目标函数的推断。同时，我们建立了这些程序的错误收敛速率，并验证了效果。

    

    在本文中，我们研究了随机梯度下降法（SGD）在非凸优化问题中的统计推断理论特性。相对于凸优化问题，这部分内容还比较未被探索。我们的研究是第一篇针对包含多个局部最小值可能的通用非凸目标函数，使用SGD估计器建立可证明推断程序的论文。我们提出了两种新型在线推断程序，将SGD和乘数自举技术相结合。第一种程序使用一致协方差矩阵估计器，并且我们建立了其误差收敛速率。第二种程序使用自举SGD估计器来逼近极限分布，产生渐进有效的自举置信区间。我们通过数值实验验证了两种方法的有效性。此外，我们的分析还产生了一个中间结果：原始SGD估计器的期望误差收敛速率。

    In this paper, we investigate the theoretical properties of stochastic gradient descent (SGD) for statistical inference in the context of nonconvex optimization problems, which have been relatively unexplored compared to convex settings. Our study is the first to establish provable inferential procedures using the SGD estimator for general nonconvex objective functions, which may contain multiple local minima.  We propose two novel online inferential procedures that combine SGD and the multiplier bootstrap technique. The first procedure employs a consistent covariance matrix estimator, and we establish its error convergence rate. The second procedure approximates the limit distribution using bootstrap SGD estimators, yielding asymptotically valid bootstrap confidence intervals. We validate the effectiveness of both approaches through numerical experiments.  Furthermore, our analysis yields an intermediate result: the in-expectation error convergence rate for the original SGD estimator 
    
[^45]: 神经扩散模型的训练数据归因

    Training Data Attribution for Diffusion Models. (arXiv:2306.02174v1 [stat.ML])

    [http://arxiv.org/abs/2306.02174](http://arxiv.org/abs/2306.02174)

    本文提出了一种使用集成方法揭示训练数据对扩散模型输出影响的方法，这些模型集合可以有效减弱训练数据的影响，使我们能够评估训练数据对模型输出的影响。

    

    随着神经扩散模型越来越受欢迎，用于合成高质量样本的训练数据集大小也不断增加，评估训练数据对训练后的模型生成样本的影响变得困难。为解决这一问题，本文提出了一种通过集成方法揭示训练数据对扩散模型输出的影响的新方法。在这种方法中，对整个训练数据集进行了精心设计的分裂，并在编码集合中训练单个模型，以允许识别有影响力的训练示例。由此产生的模型集合可以有效减弱训练数据的影响，使我们能够评估训练数据对模型输出的影响。我们证明了这些集合作为生成模型的可行性和有效性。

    Diffusion models have become increasingly popular for synthesizing high-quality samples based on training datasets. However, given the oftentimes enormous sizes of the training datasets, it is difficult to assess how training data impact the samples produced by a trained diffusion model. The difficulty of relating diffusion model inputs and outputs poses significant challenges to model explainability and training data attribution. Here we propose a novel solution that reveals how training data influence the output of diffusion models through the use of ensembles. In our approach individual models in an encoded ensemble are trained on carefully engineered splits of the overall training data to permit the identification of influential training examples. The resulting model ensembles enable efficient ablation of training data influence, allowing us to assess the impact of training data on model outputs. We demonstrate the viability of these ensembles as generative models and the validity 
    
[^46]: 高光滑函数的无梯度优化：改进分析与新算法

    Gradient-free optimization of highly smooth functions: improved analysis and a new algorithm. (arXiv:2306.02159v1 [math.ST])

    [http://arxiv.org/abs/2306.02159](http://arxiv.org/abs/2306.02159)

    本文研究了具有零阶嘈杂正则信息的最小化问题，针对高光滑函数类推导了两种零阶投影梯度下降算法的收敛速率。

    

    本文研究具有零阶嘈杂正则信息的最小化问题，假设目标函数高度光滑且可能满足附加属性。我们考虑两种零阶投影梯度下降算法，其梯度估计器形式不同。第一个算法使用基于Bach和Perchet（2016）的L2球上随机化的梯度估计器。我们在先前工作中研究的高光滑和强凸函数类上呈现了该算法的改进分析，并针对两个更一般的非凸函数类推导了收敛速率。即，我们考虑满足Polyak-Lojasiewicz条件的高光滑函数和没有附加属性的高光滑函数类。第二个算法基于L1球上的随机化，并将最近为Lipschitz函数提出的算法扩展到高光滑设置中。

    This work studies minimization problems with zero-order noisy oracle information under the assumption that the objective function is highly smooth and possibly satisfies additional properties. We consider two kinds of zero-order projected gradient descent algorithms, which differ in the form of the gradient estimator. The first algorithm uses a gradient estimator based on randomization over the $\ell_2$ sphere due to Bach and Perchet (2016). We present an improved analysis of this algorithm on the class of highly smooth and strongly convex functions studied in the prior work, and we derive rates of convergence for two more general classes of non-convex functions. Namely, we consider highly smooth functions satisfying the Polyak-{\L}ojasiewicz condition and the class of highly smooth functions with no additional property. The second algorithm is based on randomization over the $\ell_1$ sphere, and it extends to the highly smooth setting the algorithm that was recently proposed for Lipsc
    
[^47]: DU-Shapley: 一种有效的数据集价值评估的Shapley值代理

    DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation. (arXiv:2306.02071v1 [cs.AI])

    [http://arxiv.org/abs/2306.02071](http://arxiv.org/abs/2306.02071)

    本论文提出了一种称为DU-Shapley的方法，用于更有效地计算Shapley值，以实现机器学习中的数据集价值评估。

    

    许多机器学习问题需要进行数据集评估，即量化将一个单独的数据集与其他数据集聚合的增量收益，以某些相关预定义公用事业为基础。最近，Shapley值被提出作为实现这一目标的一种基本工具，因为它具有形式公理证明。由于其计算通常需要指数时间，因此考虑基于Monte Carlo积分的标准近似策略。然而，在某些情况下，这种通用近似方法仍然昂贵。本文利用数据集评估问题的结构知识，设计了更有效的Shapley值估计器。我们提出了一种新的Shapley值近似，称为离散均匀Shapley (DU-Shapley)，其表达为期望值

    Many machine learning problems require performing dataset valuation, i.e. to quantify the incremental gain, to some relevant pre-defined utility, of aggregating an individual dataset to others. As seminal examples, dataset valuation has been leveraged in collaborative and federated learning to create incentives for data sharing across several data owners. The Shapley value has recently been proposed as a principled tool to achieve this goal due to formal axiomatic justification. Since its computation often requires exponential time, standard approximation strategies based on Monte Carlo integration have been considered. Such generic approximation methods, however, remain expensive in some cases. In this paper, we exploit the knowledge about the structure of the dataset valuation problem to devise more efficient Shapley value estimators. We propose a novel approximation of the Shapley value, referred to as discrete uniform Shapley (DU-Shapley) which is expressed as an expectation under 
    
[^48]: 变分高斯过程扩散过程

    Variational Gaussian Process Diffusion Processes. (arXiv:2306.02066v1 [cs.LG])

    [http://arxiv.org/abs/2306.02066](http://arxiv.org/abs/2306.02066)

    本文提出一种高斯变分过程参数化方法来更好地学习具有非线性扩散过程的潜在过程，此方法采用具有连续指数族描述的算法实现凸优化，可以代替缓慢的具有固定点迭代的算法。

    

    扩散过程是一类随机微分方程，提供了一系列表现丰富的模型，自然地出现在动态建模任务中。概率推理和生成模型下具有非线性扩散过程的潜在过程的学习都是棘手的问题。本文在变分推理的基础上构建高斯过程扩散过程的参数化，指出方法中的病态，并提出一种使用连续指数族描述的高斯变分过程的替代参数化方法。这使我们可以用凸优化的快速算法代替具有固定点迭代的缓慢算法，这种算法类似于自然梯度下降，同时提供更好的目标来学习模型参数。

    Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference approximating the posterior process as a linear diffusion process, point out pathologies in the approach, and propose an alternative parameterization of the Gaussian variational process using a continuous exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for the learning of model parameters.
    
[^49]: 关于大型模型推理中的最优缓存与模型复用

    On Optimal Caching and Model Multiplexing for Large Model Inference. (arXiv:2306.02003v1 [cs.LG])

    [http://arxiv.org/abs/2306.02003](http://arxiv.org/abs/2306.02003)

    本文提出了最优缓存与模型复用两种方法来缓解大型模型推理中资源消耗和延迟挑战，经过实证模拟发现这种组合大大提高了传统模型推理方法的性能。

    

    大型语言模型和其他大型基础模型已经取得了显著的成功，但其尺寸加剧了现有的资源消耗和延迟挑战。本文研究了两种方法来缓解这些挑战：利用缓存存储先前的查询和学习模型复用器来选择用于查询处理的模型。理论上，我们提供了一种最优算法来联合优化这两种方法，从而减少离线和在线制表环境中的推理成本。通过将缓存算法和模型复用器相结合，我们在离线和在线设置下都实现了最优性能。实证模拟表明，我们的缓存和模型复用算法的组合大大提高了传统模型推理方法的性能。

    Large Language Models (LLMs) and other large foundation models have achieved noteworthy success, but their size exacerbates existing resource consumption and latency challenges. In particular, the large-scale deployment of these models is hindered by the significant resource requirements during inference. In this paper, we study two approaches for mitigating these challenges: employing a cache to store previous queries and learning a model multiplexer to choose from an ensemble of models for query processing.  Theoretically, we provide an optimal algorithm for jointly optimizing both approaches to reduce the inference cost in both offline and online tabular settings. By combining a caching algorithm, namely Greedy Dual Size with Frequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we achieve optimal rates in both offline and online settings. Empirically, simulations show that the combination of our caching and model multiplexing algorithms greatly improves over the 
    
[^50]: 无限臂老虎机的渐进最优纯探索

    Asymptotically Optimal Pure Exploration for Infinite-Armed Bandits. (arXiv:2306.01995v1 [cs.LG])

    [http://arxiv.org/abs/2306.01995](http://arxiv.org/abs/2306.01995)

    本文研究了从未知分布中生成的无限多臂老虎机的纯探索问题，旨在有效地选择单个高质量臂，并证明了在固定置信度和固定预算情况下算法的期望或渐进最优样本复杂度以及最优失效概率函数。

    

    我们研究了从未知分布中生成的无限多老虎机臂的纯探索问题。我们的目标是有效地选择单个高质量臂，其平均奖励在概率为$1-\delta$的情况下与前$\eta$等分的臂中，相差不超过$\varepsilon$；这是对无限行动集的经典实现可能性保证的自然调整。我们考虑固定置信度和固定预算两种情况，分别旨在实现最小期望和固定样本复杂度。对于固定置信度，我们提出了一种算法，其期望样本复杂度为$O\left(\frac{\log (1/\eta)\log (1/\delta)}{\eta\varepsilon^2}\right)$。这是除了$\log (1/\eta)$因子以外的最优解，并且$\delta$的依赖关系填补了文献中二次差距。对于固定预算，我们发现当$\delta\to 0$时，渐进最优样本复杂度是$c^{-1}\log(1/\delta)\big(\log\log(1/\delta)\big)^2$。等价的，给定精确的样本复杂度时，最优失效概率是一个$\log(1/\delta)$阶的函数。

    We study pure exploration with infinitely many bandit arms generated i.i.d. from an unknown distribution. Our goal is to efficiently select a single high quality arm whose average reward is, with probability $1-\delta$, within $\varepsilon$ of being among the top $\eta$-fraction of arms; this is a natural adaptation of the classical PAC guarantee for infinite action sets. We consider both the fixed confidence and fixed budget settings, aiming respectively for minimal expected and fixed sample complexity.  For fixed confidence, we give an algorithm with expected sample complexity $O\left(\frac{\log (1/\eta)\log (1/\delta)}{\eta\varepsilon^2}\right)$. This is optimal except for the $\log (1/\eta)$ factor, and the $\delta$-dependence closes a quadratic gap in the literature. For fixed budget, we show the asymptotically optimal sample complexity as $\delta\to 0$ is $c^{-1}\log(1/\delta)\big(\log\log(1/\delta)\big)^2$ to leading order. Equivalently, the optimal failure probability given exa
    
[^51]: 分数匹配的可证明好处

    Provable benefits of score matching. (arXiv:2306.01993v1 [cs.LG])

    [http://arxiv.org/abs/2306.01993](http://arxiv.org/abs/2306.01993)

    本文给出了关于分数匹配的第一个可证明的指数族的例子，展示了它相对于最大似然的计算效率和统计效率的优越性，并且证明了在一定情况下，最大似然的损失函数是难以使用梯度方法来进行优化的。

    

    分数匹配是估计参数化到比例常数的概率分布的替代方法，通过拟合分布的“分数”，它避开了计算比例常数的需求（这通常是棘手的）。虽然分数匹配及其变体在实践中很受欢迎，但对于与最大似然（ML）的好处和权衡，无论是计算还是统计，都没有精确的理论理解。在本文中，我们首次给出了一个自然指数分布族的例子，使得分数匹配损失计算效率高，统计效率与ML相当，而使用基于梯度的方法优化ML损失是棘手的。该家族由固定次数的多项式的指数组成，我们的结果可以视为离散情况下最近发展的连续模拟。具体地，我们展示了：（1）

    Score matching is an alternative to maximum likelihood (ML) for estimating a probability distribution parametrized up to a constant of proportionality. By fitting the ''score'' of the distribution, it sidesteps the need to compute this constant of proportionality (which is often intractable). While score matching and variants thereof are popular in practice, precise theoretical understanding of the benefits and tradeoffs with maximum likelihood -- both computational and statistical -- are not well understood. In this work, we give the first example of a natural exponential family of distributions such that the score matching loss is computationally efficient to optimize, and has a comparable statistical efficiency to ML, while the ML loss is intractable to optimize using a gradient-based method. The family consists of exponentials of polynomials of fixed degree, and our result can be viewed as a continuous analogue of recent developments in the discrete setting. Precisely, we show: (1)
    
[^52]: 关于ReLU网络的大小无关样本复杂度

    On Size-Independent Sample Complexity of ReLU Networks. (arXiv:2306.01992v1 [cs.LG])

    [http://arxiv.org/abs/2306.01992](http://arxiv.org/abs/2306.01992)

    本文研究了ReLU神经网络的样本复杂度，给出了一个现有方法精细化的结果，实现了无深度依赖性的上界。

    

    我们从泛化的角度研究了学习ReLU神经网络的样本复杂度。在权重矩阵上给定范数约束的情况下，一个常见的方法是估计相关函数类的Rademacher复杂度。之前Golowich-Rakhlin-Shamir (2020)获得了一个不依赖于网络大小的（与Frobenius范数的乘积成比例）上界，除了一个平方根深度的因子。我们给出了一个精细化的结果，通常根本没有明显的深度依赖性。

    We study the sample complexity of learning ReLU neural networks from the point of view of generalization. Given norm constraints on the weight matrices, a common approach is to estimate the Rademacher complexity of the associated function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound independent of the network size (scaling with a product of Frobenius norms) except for a factor of the square-root depth. We give a refinement which often has no explicit depth-dependence at all.
    
[^53]: DYffusion：面向时空预测的动态扩散模型

    DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting. (arXiv:2306.01984v1 [cs.LG])

    [http://arxiv.org/abs/2306.01984](http://arxiv.org/abs/2306.01984)

    提出了一种新的扩散模型，其结合了数据中编码的时间动态，自然地编码了多步和长程预测能力，具有灵活的采样轨迹和折衷性能与加速采样的能力，同时提高了计算效率，可在时空预测方面取得竞争性表现。

    

    尽管扩散模型可以成功地生成数据和做出预测，但它们主要是为静态图像设计的。我们提出了一种方法，可以训练用于动态预测的扩散模型，利用编码在数据中的时间动态，直接将其与网络中的扩散步骤耦合。我们训练了一个随机的、时间条件的插值器和一个骨干预测网络，分别模仿传统扩散模型的前向和后向过程。这种设计选择自然地编码了多步和长程预测能力，允许高度灵活的连续时间采样轨迹，并在推理时能够折衷性能与加速采样的能力。此外，面向动态的扩散过程强加了强的归纳偏差，相比传统基于高斯噪声的扩散模型，可以提高计算效率。我们的方法在概率滑雪预测任务上表现出竞争力。

    While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for training diffusion models for dynamics forecasting that leverages the temporal dynamics encoded in the data, directly coupling it with the diffusion steps in the network. We train a stochastic, time-conditioned interpolator and a backbone forecaster network that mimic the forward and reverse processes of conventional diffusion models, respectively. This design choice naturally encodes multi-step and long-range forecasting capabilities, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process imposes a strong inductive bias, allowing for improved computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic ski
    
[^54]: 层间反馈对齐在深度神经网络中的保守性

    Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks. (arXiv:2306.01870v1 [cs.LG])

    [http://arxiv.org/abs/2306.01870](http://arxiv.org/abs/2306.01870)

    本论文揭示了层间反馈对齐在深度神经网络中的保守性，并发现FA与GD之间存在隐式偏差的相似之处，同时阐明了ReLU网络中与反馈矩阵对齐的充分条件。

    

    为了提高深度神经网络的效率和生物可塑性，反馈对齐（FA）作为传统反向传播的替代方法应运而生，它将训练过程中的反向传输权重替换为随机矩阵。虽然FA的吸引力在于它能够绕过计算挑战和其可信的生物对齐性，但对于这种学习规则的理解还是有所欠缺的。本文揭示了支撑FA学习动态的一组守恒定律，揭示了FA和梯度下降（GD）之间的有趣相似之处。我们的分析表明，FA具有与GD表现出的隐式偏差相似的隐式偏差，挑战了现有的这些学习算法之间根本不同的流行说法。此外，我们证明，这些守恒定律阐明了ReLU网络中与反馈矩阵对齐的充分条件。我们进一步展示，这意味着过参数化的双线性网络中可以实现线性地代替后向权重。

    In the quest to enhance the efficiency and bio-plausibility of training deep neural networks, Feedback Alignment (FA), which replaces the backward pass weights with random matrices in the training process, has emerged as an alternative to traditional backpropagation. While the appeal of FA lies in its circumvention of computational challenges and its plausible biological alignment, the theoretical understanding of this learning rule remains partial. This paper uncovers a set of conservation laws underpinning the learning dynamics of FA, revealing intriguing parallels between FA and Gradient Descent (GD). Our analysis reveals that FA harbors implicit biases akin to those exhibited by GD, challenging the prevailing narrative that these learning algorithms are fundamentally different. Moreover, we demonstrate that these conservation laws elucidate sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks. We further show that this implies over-parameterized tw
    
[^55]: 线性时间高斯过程推断神经脉冲序列中的潜在轨迹

    Linear Time GPs for Inferring Latent Trajectories from Neural Spike Trains. (arXiv:2306.01802v1 [q-bio.NC])

    [http://arxiv.org/abs/2306.01802](http://arxiv.org/abs/2306.01802)

    本论文提出了cvHM，一种使用Hida-Mat'ern核和共轭计算变分推理（CVI）的潜在高斯过程模型的通用推理框架，能够以线性时间复杂度执行潜在神经轨迹的变分推断，以适应任意的似然函数。

    

    潜在高斯过程模型被广泛应用于神经科学中，以从顺序观测中揭示隐藏状态的演化，主要用于神经活动记录。虽然潜在GP模型在理论上提供了一个有原则和有力的解决方案，但在非共轭设置中的不可行后验需要近似推断方案，这些方案可能缺乏可扩展性。在这项工作中，我们提出了cvHM，一种使用Hida-Mat'ern核和共轭计算变分推理（CVI）的潜在GP模型的通用推理框架。使用cvHM，我们能够以线性时间复杂度执行潜在神经轨迹的变分推断，以适应任意的似然函数。使用Hida-Mat'ern GPs对平稳核进行重新参数化，帮助我们将编码先前假设的潜在变量模型与编码轨迹假设的GP连接起来，通过动力系统。与以前的工作不同，我们使用双向信息过滤，导致模型推断更清晰，估计更准确。

    Latent Gaussian process (GP) models are widely used in neuroscience to uncover hidden state evolutions from sequential observations, mainly in neural activity recordings. While latent GP models provide a principled and powerful solution in theory, the intractable posterior in non-conjugate settings necessitates approximate inference schemes, which may lack scalability. In this work, we propose cvHM, a general inference framework for latent GP models leveraging Hida-Mat\'ern kernels and conjugate computation variational inference (CVI). With cvHM, we are able to perform variational inference of latent neural trajectories with linear time complexity for arbitrary likelihoods. The reparameterization of stationary kernels using Hida-Mat\'ern GPs helps us connect the latent variable models that encode prior assumptions through dynamical systems to those that encode trajectory assumptions through GPs. In contrast to previous work, we use bidirectional information filtering, leading to a more
    
[^56]: 随机投影和符号随机投影的差分隐私算法

    Differential Privacy with Random Projections and Sign Random Projections. (arXiv:2306.01751v1 [cs.CR])

    [http://arxiv.org/abs/2306.01751](http://arxiv.org/abs/2306.01751)

    本文提出了一系列差分隐私算法，其中iDP-SignRP算法在个体差分隐私设置下效果显著，DP-SignOPORP算法改进了现有算法，DP-OPORP算法表现最优，iDP提供了一种适用于特定数据集的隐私保护解决方案。

    

    本文提出了一系列基于随机投影（RP）的差分隐私（DP）算法，适用于机器学习、数据挖掘和信息检索等各种应用。其中，基于符号随机投影（SignRP）的iDP-SignRP算法在个体差分隐私（iDP）设置下非常有效，而DP-SignOPORP算法在标准DP设置下利用“一次排列+一次随机投影”（OPORP）极大地改进了文献中现有的算法。除不考虑符号之外，在DP-RP家族中，DP-OPORP算法表现最佳。iDP（个体差分隐私）的概念仅适用于特定的数据集。虽然iDP不是严格的DP，但在某些应用中（如向小组用户发布包括嵌入信息或个性化推荐等内容的数据集，而不泄露不属于该组的个人的任何私人信息）可能很有用。

    In this paper, we develop a series of differential privacy (DP) algorithms from a family of random projections (RP), for general applications in machine learning, data mining, and information retrieval. Among the presented algorithms, \textbf{iDP-SignRP} is remarkably effective under the setting of ``individual differential privacy'' (iDP), based on sign random projections (SignRP). Also, \textbf{DP-SignOPORP} considerably improves existing algorithms in the literature under the standard DP setting, using ``one permutation + one random projection'' (OPORP), where OPORP is a variant of the celebrated count-sketch method with fixed-length binning and normalization. Without taking signs, among the DP-RP family, \textbf{DP-OPORP} achieves the best performance.  The concept of iDP (individual differential privacy) is defined only on a particular dataset of interest. While iDP is not strictly DP, iDP might be useful in certain applications, such as releasing a dataset (including sharing embe
    
[^57]: PFN是适用于实际贝叶斯优化的灵活模型。

    PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])

    [http://arxiv.org/abs/2305.17535](http://arxiv.org/abs/2305.17535)

    本文使用灵活的PFN作为BO代理建模，该模型能够允许进一步信息纳入以进行非远视BO。在三种不同的问题上得到了很好的结果。

    

    本文使用先验数据拟合网络(PFNs)作为贝叶斯优化(BO)的灵活代理。PFN是一种神经过程，被训练用于近似后验预测分布(PPD)，适用于任何可有效采样的先验分布。我们描述了如何利用这种灵活性来进行BO的代理建模。我们使用PFN来模拟一个朴素高斯过程(GP)，一个先进的GP和一个贝叶斯神经网络(BNN)。此外，我们展示了如何将进一步的信息纳入先验，例如允许有关最优位置的提示(用户先验)，忽略不相关的维度，并通过学习获取函数来执行非远视BO。这些扩展的灵活性为使用PFN进行BO开辟了广阔的可能性。我们在人工高斯过程样本和三个不同的超参数优化测试平台上展示了PFN对BO的有用性：HPO-B、Bayesmark和PD1。

    In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
    
[^58]: 通过任意回归模型检测数值数据中的错误。

    Detecting Errors in Numerical Data via any Regression Model. (arXiv:2305.16583v1 [stat.ML])

    [http://arxiv.org/abs/2305.16583](http://arxiv.org/abs/2305.16583)

    该论文提出了一种模型不可知的方法，通过考虑各种不确定性，可以利用任何回归器检测数值数据中的异常值与自然数据波动，能够有效区分真正的异常和自然数据波动。

    

    噪声困扰着许多数值数据集，其中数据记录的值可能由于错误的传感器、数据输入/处理错误或不完美的人类估计等原因而无法匹配真实的底层值。我们考虑估计沿数值列哪些数据值是不正确的。我们提出了一种模型不可知的方法，可以利用任何回归器（即基于数据集中的其他变量来预测该列值的统计学或机器学习模型）来解决问题。通过考虑各种不确定性，我们的方法区分了真正的异常和自然数据波动，条件是有可用的数据集信息。我们为我们的方法建立了理论保证，并表明其他方法（如符合性推断）难以检测错误。我们还提供了一个新的误差检测基准，涉及 5 个具有真实世界数字错误的回归数据集（对于其中的真实值）。

    Noise plagues many numerical datasets, where the recorded values in the data may fail to match the true underlying values due to reasons including: erroneous sensors, data entry/processing mistakes, or imperfect human estimates. Here we consider estimating \emph{which} data values are incorrect along a numerical column. We present a model-agnostic approach that can utilize \emph{any} regressor (i.e.\ statistical or machine learning model) which was fit to predict values in this column based on the other variables in the dataset. By accounting for various uncertainties, our approach distinguishes between genuine anomalies and natural data fluctuations, conditioned on the available information in the dataset. We establish theoretical guarantees for our method and show that other approaches like conformal inference struggle to detect errors. We also contribute a new error detection benchmark involving 5 regression datasets with real-world numerical errors (for which the true values are al
    
[^59]: 指数平滑用于离线策略学习

    Exponential Smoothing for Off-Policy Learning. (arXiv:2305.15877v1 [cs.LG])

    [http://arxiv.org/abs/2305.15877](http://arxiv.org/abs/2305.15877)

    本文研究了离线学习中最小化风险的倒数倾向评分(IPS)的平滑正则化，推导出了可处理、可扩展、可解释的学习证明，并确定了在何种情况下不需要正则化IPS。

    

    离线策略学习旨在通过最小化风险的倒数倾向评分（IPS）来寻找改进的策略，通常使用记录的赌博数据。在本文中，我们研究了IPS的平滑正则化，推导出了一个双向PAC-Bayes泛化界限。该界限是可处理的、可扩展的、可解释的并提供了学习证明。我们通过一系列学习任务展示了我们方法的相关性和有利的性能。由于我们的界限适用于标准IPS，因此我们能够提供关于何时正则化IPS有用的见解。即，我们确定了不需要正则化的情况。这与在实践中，剪辑IPS常常比OPL中的标准IPS表现更好的信念相反。

    Off-policy learning (OPL) aims at finding improved policies from logged bandit data, often by minimizing the inverse propensity scoring (IPS) estimator of the risk. In this work, we investigate a smooth regularization for IPS, for which we derive a two-sided PAC-Bayes generalization bound. The bound is tractable, scalable, interpretable and provides learning certificates. In particular, it is also valid for standard IPS without making the assumption that the importance weights are bounded. We demonstrate the relevance of our approach and its favorable performance through a set of learning tasks. Since our bound holds for standard IPS, we are able to provide insight into when regularizing IPS is useful. Namely, we identify cases where regularization might not be needed. This goes against the belief that, in practice, clipped IPS often enjoys favorable performance than standard IPS in OPL.
    
[^60]: 基于连词效应建模的大动作空间离线策略评估

    Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling. (arXiv:2305.08062v1 [stat.ML])

    [http://arxiv.org/abs/2305.08062](http://arxiv.org/abs/2305.08062)

    本研究提出了一个称为OffCEM的估计器，用于对大离散动作空间下上下文匹配策略进行离线策略评估。该估计器通过基于模型的奖励估计来处理残余因果效应，并在新的本地正确性条件下保持无偏性。结果表明，OffCEM在合成和实际大动作空间数据集上优于现有方法。

    

    本文讨论了对于传统重要性加权方法方巨的大离散动作空间下的上下文匹配策略的离线策略评估（OPE）问题。为了解决方巨问题，我们提出了一个新的估计器OffCEM，该方法基于连词效应模型（CEM），这是一种新的因果效应分解方法，可以将效应分为群集效应和残差效应。OffCEM仅对行动群集应用重要性加权，通过基于模型的奖励估计来处理残余因果效应。我们表明，在新的本地正确性条件下，该估计器是无偏的，该条件仅要求残差效应模型保留每个群集中行动的相对期望奖励差异。为了充分利用CEM和本地正确性，我们还提出了一种新的两步过程，用于执行基于模型的估计，第一步最小化偏差，第二步最小化方差。我们发现，所得到的OPE估计器OffCEM在合成和实际大动作空间数据集上都明显优于现有的最先进方法。

    We study off-policy evaluation (OPE) of contextual bandit policies for large discrete action spaces where conventional importance-weighting approaches suffer from excessive variance. To circumvent this variance issue, we propose a new estimator, called OffCEM, that is based on the conjunct effect model (CEM), a novel decomposition of the causal effect into a cluster effect and a residual effect. OffCEM applies importance weighting only to action clusters and addresses the residual causal effect through model-based reward estimation. We show that the proposed estimator is unbiased under a new condition, called local correctness, which only requires that the residual-effect model preserves the relative expected reward differences of the actions within each cluster. To best leverage the CEM and local correctness, we also propose a new two-step procedure for performing model-based estimation that minimizes bias in the first step and variance in the second step. We find that the resulting O
    
[^61]: 基于矩阵流形的神经网络构建：陀螺矢量空间方法

    Building Neural Networks on Matrix Manifolds: A Gyrovector Space Approach. (arXiv:2305.04560v1 [stat.ML])

    [http://arxiv.org/abs/2305.04560](http://arxiv.org/abs/2305.04560)

    本文通过将陀螺矢量空间中的一些概念推广到SPD和Grassmann流形，提出了在这些流形上构建神经网络的新模型和新层，并在人类动作识别和知识图谱完成两个应用中展示了其有效性。

    

    矩阵流形，如对称正定（SPD）矩阵和Grassmann流形，出现在许多应用中。最近，通过应用陀螺群和陀螺矢量空间的理论——这是一个研究双曲几何的强大框架——一些工作尝试在矩阵流形上构建欧几里德神经网络的原则性推广。然而，由于缺乏考虑流形的内积和陀螺角等概念的陀螺矢量空间，相比于用于研究双曲几何的那些概念，这些工作提供的技术和数学工具仍然有限。在本文中，我们将陀螺矢量空间中的一些概念推广到SPD和Grassmann流形，并提出了在这些流形上构建神经网络的新模型和新层。我们展示了我们的方法在人类动作识别和知识图谱完成两个应用中的有效性。

    Matrix manifolds, such as manifolds of Symmetric Positive Definite (SPD) matrices and Grassmann manifolds, appear in many applications. Recently, by applying the theory of gyrogroups and gyrovector spaces that is a powerful framework for studying hyperbolic geometry, some works have attempted to build principled generalizations of Euclidean neural networks on matrix manifolds. However, due to the lack of many concepts in gyrovector spaces for the considered manifolds, e.g., the inner product and gyroangles, techniques and mathematical tools provided by these works are still limited compared to those developed for studying hyperbolic geometry. In this paper, we generalize some notions in gyrovector spaces for SPD and Grassmann manifolds, and propose new models and layers for building neural networks on these manifolds. We show the effectiveness of our approach in two applications, i.e., human action recognition and knowledge graph completion.
    
[^62]: 无特定模型泛化难度度量

    Model-agnostic Measure of Generalization Difficulty. (arXiv:2305.01034v1 [cs.LG])

    [http://arxiv.org/abs/2305.01034](http://arxiv.org/abs/2305.01034)

    该论文提出了第一个无特定模型的、量化机器学习测试泛化难度的方法——归纳偏差复杂度度量。该方法量化了在任务上良好泛化所需的总信息量与数据提供的信息量之差，通常需要在许多维度上泛化的任务比涉及更少维度但要求更多细节的任务要困难得多。

    

    机器学习算法的度量是其可以执行的任务难度，足够困难的任务是强大机器学习模型的关键驱动因素。然而，量化机器学习测试的泛化难度一直是具有挑战性的。我们提出了据我们所知的第一个对任务固有泛化难度的无特定模型的度量。我们的归纳偏差复杂度度量量化了在任务上良好泛化所需的总信息量与数据提供的信息量之差。通过测量适合训练数据的假设在任务中泛化的分数占据的容积，来实现这一点。它与模型必须泛化的空间的内在维数成指数比例，但仅在每个维度的分辨率上呈多项式比例，表明需要在许多维度上泛化的任务比涉及更少维度的更多细节的任务要困难得多。

    The measure of a machine learning algorithm is the difficulty of the tasks it can perform, and sufficiently difficult tasks are critical drivers of strong machine learning models. However, quantifying the generalization difficulty of machine learning benchmarks has remained challenging. We propose what is to our knowledge the first model-agnostic measure of the inherent generalization difficulty of tasks. Our inductive bias complexity measure quantifies the total information required to generalize well on a task minus the information provided by the data. It does so by measuring the fractional volume occupied by hypotheses that generalize on a task given that they fit the training data. It scales exponentially with the intrinsic dimensionality of the space over which the model must generalize but only polynomially in resolution per dimension, showing that tasks which require generalizing over many dimensions are drastically more difficult than tasks involving more detail in fewer dimen
    
[^63]: 利用扰动来改善基于核化斯坦距的拟合优度检验

    Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy. (arXiv:2304.14762v1 [stat.ML])

    [http://arxiv.org/abs/2304.14762](http://arxiv.org/abs/2304.14762)

    本文提出了一种通过在样本中引入扰动，改进基于核化斯坦距的拟合优度检验方法的方法，以解决在同质但混合比例不同的情况下低功率的问题，并展示实验证据证明了该方法的功效。

    

    核化斯坦距（KSD）是一种广泛用于拟合优度检验的基于得分的差异度量。即使目标分布具有未知的标准化因子，例如在贝叶斯分析中，也可以应用它。我们理论上和实验证明，当目标分布和替代分布具有相同且相距较远的模式但在混合比例上有所不同时，KSD检验可能会出现低功率问题。我们提出通过马尔科夫转移核对观测样本进行扰动，使其相对于目标分布不变。这使我们可以在扰动样本上使用KSD检验。我们提供的数值证据表明，使用适当选择的核时，所提出的方法可以比KSD检验具有更高的功率。

    Kernelized Stein discrepancy (KSD) is a score-based discrepancy widely used in goodness-of-fit tests. It can be applied even when the target distribution has an unknown normalising factor, such as in Bayesian analysis. We show theoretically and empirically that the KSD test can suffer from low power when the target and the alternative distribution have the same well-separated modes but differ in mixing proportions. We propose to perturb the observed sample via Markov transition kernels, with respect to which the target distribution is invariant. This allows us to then employ the KSD test on the perturbed sample. We provide numerical evidence that with suitably chosen kernels the proposed approach can lead to a substantially higher power than the KSD test.
    
[^64]: 松弛假设下Adam收敛性的证明

    Convergence of Adam Under Relaxed Assumptions. (arXiv:2304.13972v1 [math.OC])

    [http://arxiv.org/abs/2304.13972](http://arxiv.org/abs/2304.13972)

    本文对Adam算法做了新的假设并进行了证明，证明了在更加现实的条件下，Adam能够以较小的梯度复杂度达到稳定点。

    

    本文针对一类广泛的优化目标，对自适应矩估计（Adam）算法的收敛性进行了严格证明。虽然Adam算法在训练深度神经网络中的流行度和效率很高，但其理论性质尚未完全理解，现有的收敛性证明需要过于强的假设，如全局梯度有界，以证明收敛到稳定点。本文证明了在更为现实的条件下，Adam能以$\mathcal{O}(\epsilon^{-4})$梯度复杂度收敛到$\epsilon$-稳定点。我们分析的关键是根据一种广义光滑性假设给出的，沿着优化轨迹的梯度有界的新证明。根据该假设，局部光滑性(即存在时的Hessian norm)受梯度范数的次平方函数限制。此外，我们提出了一种方差约减版本的Adam与加速Gradient。

    In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\epsilon$-stationary points with $\mathcal{O}(\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradien
    
[^65]: 不精确的迭代数值线性代数用于基于神经网络的谱估计和稀有事件预测

    Inexact iterative numerical linear algebra for neural network-based spectral estimation and rare-event prediction. (arXiv:2303.12534v1 [physics.comp-ph])

    [http://arxiv.org/abs/2303.12534](http://arxiv.org/abs/2303.12534)

    本文开发了一种不精确的迭代线性代数方法，用于基于神经网络的谱估计和从短轨迹数据集中进行稀有事件的预测，这对于理解复杂系统的动态是具有挑战性的，并讨论了该方法对强化学习中的预测问题的影响。

    

    由于复杂系统存在大量自由度，其中最重要的度量通常并不明显，因此理解其动态是具有挑战性的。转移算符的主要特征函数对于可视化很有用，它们可以为计算统计量（例如事件的可能性和平均时间）提供高效的基础（预测）。在本文中，我们开发了不精确的迭代线性代数方法来计算这些特征函数（谱估计）并从短轨迹数据集上进行预测。我们在便于可视化的低维模型和生物分子系统的高维模型上演示了该方法。我们还讨论了这些方法对强化学习中的预测问题的影响。

    Understanding dynamics in complex systems is challenging because there are many degrees of freedom, and those that are most important for describing events of interest are often not obvious. The leading eigenfunctions of the transition operator are useful for visualization, and they can provide an efficient basis for computing statistics such as the likelihood and average time of events (predictions). Here we develop inexact iterative linear algebra methods for computing these eigenfunctions (spectral estimation) and making predictions from a data set of short trajectories sampled at finite intervals. We demonstrate the methods on a low-dimensional model that facilitates visualization and a high-dimensional model of a biomolecular system. Implications for the prediction problem in reinforcement learning are discussed.
    
[^66]: 基于Group Lasso的贪婪剪枝在矩阵感知和二次激活神经网络上可证地泛化

    Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing and Neural Networks with Quadratic Activations. (arXiv:2303.11453v1 [cs.LG])

    [http://arxiv.org/abs/2303.11453](http://arxiv.org/abs/2303.11453)

    本文在矩阵感知问题中研究了基于Group Lasso正则化器的贪婪剪枝方法，证明了修剪低$\ell_2$范数列的解可以泛化到新样本上。

    

    剪枝方案广泛用于降低具有大量参数的模型的复杂性。实践研究表明，修剪过度参数化模型并微调可很好地泛化到新样本上。虽然以上被称为剪枝+微调的流程在降低训练模型的复杂性方面非常成功，但其背后的理论仍然不甚了解。本文通过研究超参数化矩阵感知问题上的剪枝+微调框架来解决这个问题，其中真实结果表示为$U_\star \in \mathbb{R}^{d \times r}$，而超参数化模型表示为$U \in \mathbb{R}^{d \times k}$，其中$k \gg r$。我们研究加上Group Lasso正则化器的平滑版本$\sum_{i=1}^k \| U e_i \|_2$的平均误差的近似局部极小值，证明修剪低$\ell_2$范数列的解$U_{

    Pruning schemes have been widely used in practice to reduce the complexity of trained models with a massive number of parameters. Several practical studies have shown that pruning an overparameterized model and fine-tuning generalizes well to new samples. Although the above pipeline, which we refer to as pruning + fine-tuning, has been extremely successful in lowering the complexity of trained models, there is very little known about the theory behind this success. In this paper we address this issue by investigating the pruning + fine-tuning framework on the overparameterized matrix sensing problem, with the ground truth denoted $U_\star \in \mathbb{R}^{d \times r}$ and the overparameterized model $U \in \mathbb{R}^{d \times k}$ with $k \gg r$. We study the approximate local minima of the empirical mean square error, augmented with a smooth version of a group Lasso regularizer, $\sum_{i=1}^k \| U e_i \|_2$ and show that pruning the low $\ell_2$-norm columns results in a solution $U_{\
    
[^67]: 黑盒变分贝叶斯推理的实用匹配梯度方差界限

    Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference. (arXiv:2303.10472v1 [cs.LG])

    [http://arxiv.org/abs/2303.10472](http://arxiv.org/abs/2303.10472)

    本文表明黑盒变分推理（BBVI）满足SGD文献中的ABC条件，该结果适用于平滑和二次增长的对数似然函数，同时我们的结果推广到广泛应用于BBVI实践中的非线性协方差参数化。

    

    理解黑盒变分推理（BBVI）的梯度方差是建立其收敛性和算法改进的关键一步。然而，现有研究尚未表明BBVI的梯度方差满足用于研究随机梯度下降（SGD）收敛的条件。在本文中，我们展示了当应用于平滑和二次增长的对数似然函数时，BBVI满足与SGD文献中使用的ABC条件相匹配的界限。我们的结果推广到广泛应用于BBVI实践中的非线性协方差参数化。此外，我们表明，平均场参数化的方差具有经过验证的优越维度依赖性。

    Understanding the gradient variance of black-box variational inference (BBVI) is a crucial step for establishing its convergence and developing algorithmic improvements. However, existing studies have yet to show that the gradient variance of BBVI satisfies the conditions used to study the convergence of stochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show that BBVI satisfies a matching bound corresponding to the $ABC$ condition used in the SGD literature when applied to smooth and quadratically-growing log-likelihoods. Our results generalize to nonlinear covariance parameterizations widely used in the practice of BBVI. Furthermore, we show that the variance of the mean-field parameterization has provably superior dimensional dependence.
    
[^68]: 非凸优化中的方差缩减裁剪

    Variance-reduced Clipping for Non-convex Optimization. (arXiv:2303.00883v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00883](http://arxiv.org/abs/2303.00883)

    本文提出了一种非凸优化中的方差缩减裁剪方法SPIDER，可以实现在较少的随机梯度计算次数下找到一个较稳定的解决方案。

    

    梯度裁剪是深度学习应用中的标准训练技术，用于减轻梯度爆炸等问题，最近的实验研究表明，当使用梯度裁剪进行训练时，训练目标沿着其轨迹的平滑性具有一种特殊的行为，即平滑性随着梯度范数增长而增长。这与民间非凸优化中广泛流传的$L$-平滑假设形成明显对比，即全局平滑性被假定为由常数$L$上界。最近引入的$(L_0,L_1)$-平滑度是一个更放松的概念，它捕捉到非凸优化中的这种特征。特别是，在这种放松的平滑性假设下，在SGD裁剪的情况下需要$O(\epsilon^{-4})$随机梯度计算才能找到一个$\epsilon$-稳定解。本文采用方差缩减技术SPIDER，并演示如何在理论上分析该方法的性质。

    Gradient clipping is a standard training technique used in deep learning applications such as large-scale language modeling to mitigate exploding gradients. Recent experimental studies have demonstrated a fairly special behavior in the smoothness of the training objective along its trajectory when trained with gradient clipping. That is, the smoothness grows with the gradient norm. This is in clear contrast to the well-established assumption in folklore non-convex optimization, a.k.a. $L$--smoothness, where the smoothness is assumed to be bounded by a constant $L$ globally. The recently introduced $(L_0,L_1)$--smoothness is a more relaxed notion that captures such behavior in non-convex optimization. In particular, it has been shown that under this relaxed smoothness assumption, SGD with clipping requires $O(\epsilon^{-4})$ stochastic gradient computations to find an $\epsilon$--stationary solution. In this paper, we employ a variance reduction technique, namely SPIDER, and demonstrate
    
[^69]: 安全剥离L0正则化最小二乘问题

    Safe Peeling for L0-Regularized Least-Squares with supplementary material. (arXiv:2302.14471v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14471](http://arxiv.org/abs/2302.14471)

    引入“安全剥离”方法加速解决L0正则化最小二乘问题，通过收缩松弛度允许更激进的剪枝，显著降低求解时间。

    

    我们引入了一种新的方法，称为“安全剥离”，通过分支定界算法加速解决L0正则化最小二乘问题。我们的程序使得在BnB决策树的每个节点处考虑到收缩松弛度，因此可能允许更加激进的剪枝。数值模拟表明，我们提出的方法在探索节点数量和整体求解时间方面具有显著的优势。

    We introduce a new methodology dubbed ``safe peeling'' to accelerate the resolution of L0-regularized least-squares problems via a Branch-and-Bound (BnB) algorithm. Our procedure enables to tighten the convex relaxation considered at each node of the BnB decision tree and therefore potentially allows for more aggressive pruning. Numerical simulations show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.s show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.
    
[^70]: 在结构分布偏移条件下评估图模型的鲁棒性和不确定性

    Evaluating Robustness and Uncertainty of Graph Models Under Structural Distributional Shifts. (arXiv:2302.13875v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13875](http://arxiv.org/abs/2302.13875)

    该论文提出了一种基于图结构的多样化分布转换的方法，并且针对性地设计了数据集。实验结果表明这些分布转换对于现有的图模型具有挑战性。

    

    在基于机器学习的可靠决策系统中，模型必须对分布偏移具有鲁棒性或提供其预测的不确定性。在图学习的节点级问题中，分布偏移可能尤为复杂，因为样本是相互依赖的。为了评估图模型的性能，重要的是在各种有意义的分布偏移下对它们进行测试。然而，大多数考虑节点级分布偏移的图基准主要关注节点特征，而结构属性对图问题也很重要。在这项工作中，我们提出了一种基于图结构引出多样化分布偏移的通用方法。我们使用这种方法根据几个节点的结构属性：流行度、局部性和密度来创建数据分割。在我们的实验中，我们全面评估了所提出的分布偏移，并表明它们对于现有的图模型可能非常具有挑战性。我们还修订了一些关于基准测试图模型的先前工作，并提出了一组新的基准测试，考虑了结构分布偏移条件。

    In reliable decision-making systems based on machine learning, models have to be robust to distributional shifts or provide the uncertainty of their predictions. In node-level problems of graph learning, distributional shifts can be especially complex since the samples are interdependent. To evaluate the performance of graph models, it is important to test them on diverse and meaningful distributional shifts. However, most graph benchmarks considering distributional shifts for node-level problems focus mainly on node features, while structural properties are also essential for graph problems. In this work, we propose a general approach for inducing diverse distributional shifts based on graph structure. We use this approach to create data splits according to several structural node properties: popularity, locality, and density. In our experiments, we thoroughly evaluate the proposed distributional shifts and show that they can be quite challenging for existing graph models. We also rev
    
[^71]: 减少、重复利用、回收：基于能量扩散模型和MCMC的组合生成

    Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. (arXiv:2302.11552v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11552](http://arxiv.org/abs/2302.11552)

    该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。

    

    自从扩散模型问世以来，它在许多领域中已经迅速成为生成模型的主要方法。它们可以被解释为学习一系列时变的对数概率密度函数的梯度。这种解释已经激发了基于分类器和无分类器指导的思想成为后续控制扩散模型的方法。在这项工作中，我们建立在这些想法的基础上，利用扩散模型的分数-based解释，探索了用于涉及组合生成和指导的条件、修改和重复使用扩散模型的替代方法。特别是，我们调查了为什么某些类型的组合使用当前技术失败，并介绍了一些解决方案。我们得出结论，采样者(而不是模型)对此失败负有责任，并提出了新的采样器，受MCMC的启发，使组合生成成功。此外，我们提出了一种基于能量的扩散模型参数化方法，它使得逼近目标分布更加容易。

    Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the 
    
[^72]: 持续同调在图学习中的表达性

    On the Expressivity of Persistent Homology in Graph Learning. (arXiv:2302.09826v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09826](http://arxiv.org/abs/2302.09826)

    本文通过在图学习任务中的理论讨论和实证分析，证明了持续同调技术在捕捉具有显著拓扑结构的数据集中的长程图性质方面表现出的高表达性。

    

    近来，计算拓扑学中的一项技术，持续同调展现出在图分类方面强大的实证性能。它能够通过高阶拓扑特征——如任意长度的环——以及多尺度拓扑描述符捕捉长程图性质，从而提高对具有显著拓扑结构的数据集——如分子——的预测性能。与此同时，持续同调的理论性质在这个背景下尚未得到正式评估。本文旨在通过提供持续同调在图中的简要介绍以及对其在图学习任务中的表达性进行理论讨论和实证分析，弥合计算拓扑学和图机器学习之间的差距。

    Persistent homology, a technique from computational topology, has recently shown strong empirical performance in the context of graph classification. Being able to capture long range graph properties via higher-order topological features, such as cycles of arbitrary length, in combination with multi-scale topological descriptors, has improved predictive performance for data sets with prominent topological structures, such as molecules. At the same time, the theoretical properties of persistent homology have not been formally assessed in this context. This paper intends to bridge the gap between computational topology and graph machine learning by providing a brief introduction to persistent homology in the context of graphs, as well as a theoretical discussion and empirical analysis of its expressivity for graph learning tasks.
    
[^73]: GFlowNet-EM用于学习组合隐变量模型

    GFlowNet-EM for learning compositional latent variable models. (arXiv:2302.06576v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06576](http://arxiv.org/abs/2302.06576)

    GFlowNet-EM采用GFlowNets算法作为建模潜变量后验概率的E步骤，从而实现了对具有离散组合潜变量的表现力强的LVM进行训练。

    

    具有离散组合潜变量的潜变量模型（LVM）是一个重要但具有挑战性的领域，由于潜变量的可能组合数量组合很大。在建模潜变量的后验概率时，表现和可跟踪的优化之间具有关键的权衡。对于基于期望最大化（EM）的算法，E-步骤往往在没有对后验进行限制的近似的情况下是不可跟踪的。我们提出使用GFlowNets，一种学习从未规范化的密度中采样的随机策略以进行顺序样本构建的算法，来处理这个不可跟踪的E-步骤。通过训练GFlowNets从潜变量后验中采样，我们利用了它们作为离散结构复杂分布的变分推理算法的优势。我们的方法，GFlowNet-EM，可以实现对具有离散组合潜变量的表现力强的LVM进行训练，如在非上下文无关文法归纳和图像翻译实验证明。

    Latent variable models (LVMs) with discrete compositional latents are an important but challenging setting due to a combinatorially large number of possible configurations of the latents. A key tradeoff in modeling the posteriors over latents is between expressivity and tractable optimization. For algorithms based on expectation-maximization (EM), the E-step is often intractable without restrictive approximations to the posterior. We propose the use of GFlowNets, algorithms for sampling from an unnormalized density by learning a stochastic policy for sequential construction of samples, for this intractable E-step. By training GFlowNets to sample from the posterior over latents, we take advantage of their strengths as amortized variational inference algorithms for complex distributions over discrete structures. Our approach, GFlowNet-EM, enables the training of expressive LVMs with discrete compositional latents, as shown by experiments on non-context-free grammar induction and on image
    
[^74]: DIFF2: 基于梯度差异的差分隐私优化方法用于非凸分布式学习

    DIFF2: Differential Private Optimization via Gradient Differences for Nonconvex Distributed Learning. (arXiv:2302.03884v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03884](http://arxiv.org/abs/2302.03884)

    本文提出了一种名为 DIFF2 的新型差分隐私优化框架，其以梯度差异为基础构造了一个具有小方差的全局梯度估计器，相比于之前的算法，该方法在非凸平滑目标优化问题中能够更好地减小误差下界，提高效用。

    

    本文考虑了非凸平滑目标的差分隐私优化问题。在以往的工作中，基于全梯度范数的最佳效用边界已知为 $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$，其中 $n$ 为样本大小，$d$ 为问题维度，$\varepsilon_\mathrm{DP}$ 为差分隐私参数，DP-GD 是实现该边界的一种算法。为了提高已知的效用边界，本文提出了一种新的差分隐私优化框架 DIFF2（DIFFerential private optimization via gradient DIFFerences），它构造了一个差分隐私全局梯度估计器，该估计器具有可能非常小的方差，基于通信的“梯度差异”，而不是梯度本身。实验证明，使用梯度下降子例程的 DIFF2 实现的效用为 $\widetilde O(d^{2/3}/(n\varepsilon_\mathrm{DP})^{4/3})$，比先前的方法显著更好。

    Differential private optimization for nonconvex smooth objective is considered. In the previous work, the best known utility bound is $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$ in terms of the squared full gradient norm, which is achieved by Differential Private Gradient Descent (DP-GD) as an instance, where $n$ is the sample size, $d$ is the problem dimensionality and $\varepsilon_\mathrm{DP}$ is the differential privacy parameter. To improve the best known utility bound, we propose a new differential private optimization framework called \emph{DIFF2 (DIFFerential private optimization via gradient DIFFerences)} that constructs a differential private global gradient estimator with possibly quite small variance based on communicated \emph{gradient differences} rather than gradients themselves. It is shown that DIFF2 with a gradient descent subroutine achieves the utility of $\widetilde O(d^{2/3}/(n\varepsilon_\mathrm{DP})^{4/3})$, which can be significantly better than the prev
    
[^75]: 基于采样的通用推断后验估计精度测试

    Sampling-Based Accuracy Testing of Posterior Estimators for General Inference. (arXiv:2302.03026v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.03026](http://arxiv.org/abs/2302.03026)

    本文提出了一种基于“随机点精度测试”（TARP）覆盖测试的方法来估计生成后验估计器覆盖概率。该方法是一种估计生成模型中编码后验精度的必要和充分条件。该方法可用于测试高维空间中后验推断分析的结果。

    

    参数推断是许多科学学科中的一个核心问题，即在给定一些数据的情况下推断统计模型参数的后验分布。生成模型可用作马尔可夫链蒙特卡罗方法的替代方法，用于进行基于似然和基于模拟的后验推断问题。然而，评估生成模型中编码的后验精度并不简单。本文引入了“随机点精度测试”（TARP）覆盖测试作为一种估计生成后验估计器覆盖概率的方法。我们的方法不同于以前存在的需要后验评估的基于覆盖率的方法。我们证明了我们的方法是确定后验估计器准确性的必要和充分条件。我们在各种合成示例上演示了该方法，并表明TARP可用于测试高维空间中后验推断分析的结果。

    Parameter inference, i.e. inferring the posterior distribution of the parameters of a statistical model given some data, is a central problem to many scientific disciplines. Generative models can be used as an alternative to Markov Chain Monte Carlo methods for conducting posterior inference, both in likelihood-based and simulation-based problems. However, assessing the accuracy of posteriors encoded in generative models is not straightforward. In this paper, we introduce `Tests of Accuracy with Random Points' (TARP) coverage testing as a method to estimate coverage probabilities of generative posterior estimators. Our method differs from previously-existing coverage-based methods, which require posterior evaluations. We prove that our approach is necessary and sufficient to show that a posterior estimator is accurate. We demonstrate the method on a variety of synthetic examples, and show that TARP can be used to test the results of posterior inference analyses in high-dimensional spac
    
[^76]: RLSbench: 宽松标签偏移下的领域自适应

    RLSbench: Domain Adaptation Under Relaxed Label Shift. (arXiv:2302.03020v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03020](http://arxiv.org/abs/2302.03020)

    本文介绍了 RLSbench，它是一个大规模基准，用于宽松标签偏移。与现有基准不同，它旨在评估领域自适应方法在标签边际偏移下的表现。

    

    尽管出现了解决标签偏移下领域自适应的原则性方法，但对于类条件分布的偏移敏感性却未得到充分探索。同时，流行的深度领域自适应启发式方法在面对标签比例偏移时往往疲软。虽然有几篇论文改进了这些启发方法以尝试处理标签比例偏移，但评估标准、数据集和基线的不一致使得评估当前最佳实践变得困难。在这篇论文中，我们引入 RLSbench，一个大规模的宽松标签偏移基准，涵盖500多个分布偏移对，跨视觉、表格和语言模式，具有不同的标签比例。与现有基准主要关注类条件$p(x|y)$偏移不同，我们的基准还关注标签边际偏移。首先，我们评估了13种流行的领域自适应方法，证明在标签比例偏移下更普遍地失败。

    Despite the emergence of principled methods for domain adaptation under label shift, their sensitivity to shifts in class conditional distributions is precariously under explored. Meanwhile, popular deep domain adaptation heuristics tend to falter when faced with label proportions shifts. While several papers modify these heuristics in attempts to handle label proportions shifts, inconsistencies in evaluation standards, datasets, and baselines make it difficult to gauge the current best practices. In this paper, we introduce RLSbench, a large-scale benchmark for relaxed label shift, consisting of $>$500 distribution shift pairs spanning vision, tabular, and language modalities, with varying label proportions. Unlike existing benchmarks, which primarily focus on shifts in class-conditional $p(x|y)$, our benchmark also focuses on label marginal shifts. First, we assess 13 popular domain adaptation methods, demonstrating more widespread failures under label proportion shifts than were pre
    
[^77]: 快速，可微分和稀疏的Top-k: 凸分析视角

    Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective. (arXiv:2302.01425v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01425](http://arxiv.org/abs/2302.01425)

    本研究提出了一种新的可微分和稀疏的Top-k运算符，将其视为排列凸包上的线性规划，并引入p-范数正则化项以平滑运算符。算法方面，提出了一种新的近端算子，可以有效地进行Top-k运算。实验结果表明该方法在多个任务中都很有效。

    

    Top-k运算符返回一个稀疏向量，其中非零值对应于输入k个最大值。然而，由于它是一个不连续的函数，所以很难将其纳入使用反向传播进行端到端训练的神经网络中。本文提出新的可微分和稀疏的Top-k运算符。我们将Top-k运算符视为排列凸包上的线性规划，并引入p-范数正则化项以平滑运算符，证明其计算可以减少到同向优化。我们的算法框架显著比现有框架更通用，可以表示选择大小值的Top-k运算符。在算法方面，除了池相邻违规算法（PAV）外，我们提出了一种新的近端算子，允许有效的Top-k运算，并可轻松集成到神经网络中。在图像分类和序列标记等多个任务上的实验验证了我们方法的有效性。

    The top-k operator returns a sparse vector, where the non-zero values correspond to the k largest values of the input. Unfortunately, because it is a discontinuous function, it is difficult to incorporate in neural networks trained end-to-end with backpropagation. Recent works have considered differentiable relaxations, based either on regularization or perturbation techniques. However, to date, no approach is fully differentiable and sparse. In this paper, we propose new differentiable and sparse top-k operators. We view the top-k operator as a linear program over the permutahedron, the convex hull of permutations. We then introduce a p-norm regularization term to smooth out the operator, and show that its computation can be reduced to isotonic optimization. Our framework is significantly more general than the existing one and allows for example to express top-k operators that select values in magnitude. On the algorithmic side, in addition to pool adjacent violator (PAV) algorithms, 
    
[^78]: 与人类表征的一致性支持鲁棒的少样本学习

    Alignment with human representations supports robust few-shot learning. (arXiv:2301.11990v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11990](http://arxiv.org/abs/2301.11990)

    论文提出少样本学习的表现与人类表征的一致性存在U形关系，并通过计算机视觉模型的实验进行了验证。高度对齐的模型更加鲁棒，对数据的利用更加有效，但与人类对齐并非必要条件。

    

    我们是否应该关心AI系统是否具有与人类相似的世界表征？我们提供了一个信息论分析，建议在少样本学习任务的表现度与人类表征的一致性之间应该存在一个U形关系。我们通过对491个计算机视觉模型的性能分析验证了这个预测的可行性，并且表明高度对齐的模型更加鲁棒于对抗攻击和域偏移。我们的结果表明，与人类对齐往往是模型有效利用有限数据、鲁棒性 以及泛化能力的充分但不必要条件。

    Should we care whether AI systems have representations of the world that are similar to those of humans? We provide an information-theoretic analysis that suggests that there should be a U-shaped relationship between the degree of representational alignment with humans and performance on few-shot learning tasks. We confirm this prediction empirically, finding such a relationship in an analysis of the performance of 491 computer vision models. We also show that highly-aligned models are more robust to both adversarial attacks and domain shifts. Our results suggest that human-alignment is often a sufficient, but not necessary, condition for models to make effective use of limited data, be robust, and generalize well.
    
[^79]: 论几何图神经网络表现力的研究

    On the Expressive Power of Geometric Graph Neural Networks. (arXiv:2301.09308v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.09308](http://arxiv.org/abs/2301.09308)

    本文提出了几何版本的Weisfeiler-Leman测试(GWL)，可以区分几何图形，揭示了关键设计选择如何影响几何GNN的表现力

    

    通过 Weisfeiler-Leman (WL) 图同构测试，已经广泛研究了图神经网络 (GNNs) 的表现力。然而，标准的 GNNs 和 WL 框架不适用于嵌入欧几里得空间的几何图形，例如生物分子、材料和其他物理系统。在本文中，我们提出了 WL 测试的几何版本 (GWL)，以区分几何图形，同时尊重底层物理对称性：排列、旋转、反射和平移。我们使用 GWL 来表征具有不变或等变于物理对称性的几何 GNN 的表现力，以区分几何图形。GWL 揭示了关键设计选择如何影响几何 GNN 的表现力：(1) 不变层表现力有限，因为它们无法区分一跳相同的几何图形；(2) 等变层通过传播局部邻域之外的几何信息，区分更大类别的图形；(3)

    The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3)
    
[^80]: 用统计深度学习揭示地中海地区极端野火的驱动因素和时空趋势

    Insights into the drivers and spatio-temporal trends of extreme Mediterranean wildfires with statistical deep-learning. (arXiv:2212.01796v3 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2212.01796](http://arxiv.org/abs/2212.01796)

    本研究使用统计深度学习的方法分析了欧洲和地中海盆地2001年至2020年因野火而烧毁的月度面积，研究结果显示气温、降水和风速是极端野火的主要驱动因素，根据季节和地点有不同的影响。阿尔及利亚的野火活动正在增加，葡萄牙的趋势正在下降，而意大利的趋势是非线性的。

    

    极端野火是地中海盆地国家中人类死亡和生物多样性破坏的重要原因。最近野火活动（即发生和蔓延）的趋势令人担忧，表明野火可能受到气候变化的高度影响。为了促进适当的风险缓解，我们必须确定极端野火的主要驱动因素，并评估它们的时空趋势，以便了解全球变暖对火灾活动的影响。我们分析了欧洲和地中海盆地大部分地区从2001年到2020年因野火而烧毁的月度面积，并确定阿尔及利亚、意大利和葡萄牙在这期间存在高发的野火活动。我们建立了一个高维预测器集描述气象条件、土地覆盖利用和山势的极端分位数回归模型。为了模拟预测变量和野火之间的复杂关系，我们使用了一个混合统计深度学习方法。我们的研究结果表明，气温、降水和风速是极端野火的主要驱动因素，根据季节和地点有不同的影响。我们还发现显著的时空趋势，阿尔及利亚的野火活动正在增加，葡萄牙的趋势正在下降，而意大利的趋势是非线性的。我们的研究为了解气候变化对地中海盆地极端野火当前和潜在的影响提供了重要见解。

    Extreme wildfires are a significant cause of human death and biodiversity destruction within countries that encompass the Mediterranean Basin. Recent worrying trends in wildfire activity (i.e., occurrence and spread) suggest that wildfires are likely to be highly impacted by climate change. In order to facilitate appropriate risk mitigation, we must identify the main drivers of extreme wildfires and assess their spatio-temporal trends, with a view to understanding the impacts of global warming on fire activity. We analyse the monthly burnt area due to wildfires over a region encompassing most of Europe and the Mediterranean Basin from 2001 to 2020, and identify high fire activity during this period in Algeria, Italy and Portugal. We build an extreme quantile regression model with a high-dimensional predictor set describing meteorological conditions, land cover usage, and orography. To model the complex relationships between the predictor variables and wildfires, we use a hybrid statist
    
[^81]: 基于扩散去噪过程的感知器偏置在异常检测中的应用

    Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection. (arXiv:2211.11255v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.11255](http://arxiv.org/abs/2211.11255)

    本文针对深度学习中的异常检测问题，提出了一种新的方法——使用扩散模型作为非对称插值的方法来增强输入并减轻过度自信的问题，从而提高判别器模型在异常检测方面的性能。

    

    异常检测对于保证深度学习模型的可靠性和安全性至关重要。目前，判别器模型在这方面的表现超过其他方法。然而，判别器模型使用的特征提取过程容易丢失关键信息，留下不良情况和恶意攻击的空间。在本文中，我们引入了一个新的感知器偏置假设，它表明判别器模型对输入的某些特征更为敏感，导致过度自信的问题。为了解决这个问题，我们提出了一个新的框架，它结合了判别器和生成模型，并将扩散模型(DMs)集成到OOD检测中。我们证明了扩散去噪过程(DDP)作为一种新形式的非对称插值，很适合增强输入并减轻过度自信的问题。在DDP下，OOD数据的判别器模型特征表现为尖锐的变化，我们利用范数...

    Out-of-distribution (OOD) detection is a crucial task for ensuring the reliability and safety of deep learning. Currently, discriminator models outperform other methods in this regard. However, the feature extraction process used by discriminator models suffers from the loss of critical information, leaving room for bad cases and malicious attacks. In this paper, we introduce a new perceptron bias assumption that suggests discriminator models are more sensitive to certain features of the input, leading to the overconfidence problem. To address this issue, we propose a novel framework that combines discriminator and generation models and integrates diffusion models (DMs) into OOD detection. We demonstrate that the diffusion denoising process (DDP) of DMs serves as a novel form of asymmetric interpolation, which is well-suited to enhance the input and mitigate the overconfidence problem. The discriminator model features of OOD data exhibit sharp changes under DDP, and we utilize the norm
    
[^82]: 基于无上下文文法的分层神经架构搜索空间构建

    Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars. (arXiv:2211.01842v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01842](http://arxiv.org/abs/2211.01842)

    本研究基于无上下文文法提出了一个统一的搜索空间设计框架，可以生成表达力强大的分层搜索空间，实现了对整个体系结构的搜索并促进结构的规律性。

    

    从简单的构建块中发现神经结构是神经架构搜索(NAS)的一个长期目标。分层搜索空间是实现这一目标的一个有前途的步骤，但缺乏统一的搜索空间设计框架，并且通常仅搜索一些限定方面的架构。在本研究中，我们介绍了一个基于无上下文文法的统一搜索空间设计框架，它可以自然而紧凑地生成表达力强大的分层搜索空间，比文献中常见的空间大几个数量级。通过增强和利用它们的属性，我们有效地实现了对整个体系结构的搜索，并促进了结构的规律性。此外，我们提出了一种高效的分层核设计用于贝叶斯优化搜索策略，以高效搜索如此庞大的空间。我们展示了我们搜索空间设计框架的多样性，并表明我们的搜索策略可以优于现有的NAS方法。

    The discovery of neural architectures from simple building blocks is a long-standing goal of Neural Architecture Search (NAS). Hierarchical search spaces are a promising step towards this goal but lack a unifying search space design framework and typically only search over some limited aspect of architectures. In this work, we introduce a unifying search space design framework based on context-free grammars that can naturally and compactly generate expressive hierarchical search spaces that are 100s of orders of magnitude larger than common spaces from the literature. By enhancing and using their properties, we effectively enable search over the complete architecture and can foster regularity. Further, we propose an efficient hierarchical kernel design for a Bayesian Optimization search strategy to efficiently search over such huge spaces. We demonstrate the versatility of our search space design framework and show that our search strategy can be superior to existing NAS approaches. Co
    
[^83]: 通过后处理实现公平和最优分类

    Fair and Optimal Classification via Post-Processing. (arXiv:2211.01528v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01528](http://arxiv.org/abs/2211.01528)

    本文提出了一个后处理算法，通过评分函数推导公平分类器，达到公平对待不同群体的目的。

    

    为了减轻机器学习模型所呈现的偏见，公平性标准可以整合到训练过程中，以确保在所有人口统计学中实现公平对待，然而这往往是以模型表现为代价的。因此，了解这种权衡是公平算法设计的基础。本文在最普遍的多组、多类别和嘈杂设置下，完整地表征了公平、达摩尔平等在分类问题中的内在权衡。具体而言，我们表明，通过随机化和属性感知公平分类器实现的最小错误率是由沃瑟斯坦重心问题的最优值给出的。在实践方面，我们的发现可以产生一个简单的后处理算法，从评分函数中推导出公平分类器，并在评分为贝叶斯最优时得到最优公平分类器。我们为我们的算法提供了次优性分析和样本复杂性，并展示了它的有效性。

    To mitigate the bias exhibited by machine learning models, fairness criteria can be integrated into the training process to ensure fair treatment across all demographics, but it often comes at the expense of model performance. Understanding such tradeoffs, therefore, underlies the design of fair algorithms. To this end, this paper provides a complete characterization of the inherent tradeoff of demographic parity on classification problems, under the most general multi-group, multi-class, and noisy setting. Specifically, we show that the minimum error rate achievable by randomized and attribute-aware fair classifiers is given by the optimal value of a Wasserstein-barycenter problem. On the practical side, our findings lead to a simple post-processing algorithm that derives fair classifiers from score functions, which yields the optimal fair classifier when the score is Bayes optimal. We provide suboptimality analysis and sample complexity for our algorithm, and demonstrate its effectiv
    
[^84]: 粒子信念近似POMDP的最优性保证

    Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.05015](http://arxiv.org/abs/2210.05015)

    该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。

    

    部分可观察马尔可夫决策过程(POMDP)提供了现实决策和控制问题的灵活表示。然而，POMDP的求解非常困难，特别是当状态和观测空间是连续或混合的时候，这在物理系统中经常发生。尽管最近使用观测似然权重策划的在线采样POMDP算法表现出了实用的有效性，但先前并没有提出一般理论来刻画这些算法使用的粒子滤波技术的逼近误差。我们的主要贡献是限定任何POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差。这种PB-MDP和POMDP之间的基础桥梁使得我们能够通过解决相应的粒子信念MDP将任何采样MDP算法适应到POMDP中，从而将MDP算法的收敛保证扩展到POMDP中。在实践中，这可以提高在解决具有大的或连续状态空间的POMDP时的性能和鲁棒性。

    Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, thi
    
[^85]: 使用加权不对称损失函数的神经网络模型预测区间

    Prediction intervals for neural network models using weighted asymmetric loss functions. (arXiv:2210.04318v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.04318](http://arxiv.org/abs/2210.04318)

    本论文提出了一种使用加权不对称损失函数的方法，生成可靠的预测区间，适用于复杂的机器学习情境，可扩展为参数化函数的PI预测。

    

    我们提出了一种简单而有效的方法来生成近似和预测趋势的预测区间（PIs）。我们利用加权不对称损失函数来估计PI的下限和上限，权重由区间宽度确定。我们提供了该方法的简洁数学证明，展示了如何将其扩展到为参数化函数推导PI，并论证了该方法为预测相关变量的PI而有效的原因。我们在基于神经网络的模型的真实世界预测任务上对该方法进行了测试，结果表明它在复杂的机器学习情境下可以产生可靠的PI。

    We propose a simple and efficient approach to generate prediction intervals (PIs) for approximated and forecasted trends. Our method leverages a weighted asymmetric loss function to estimate the lower and upper bounds of the PIs, with the weights determined by the interval width. We provide a concise mathematical proof of the method, show how it can be extended to derive PIs for parametrised functions and argue why the method works for predicting PIs of dependent variables. The presented tests of the method on a real-world forecasting task using a neural network-based model show that it can produce reliable PIs in complex machine learning scenarios.
    
[^86]: 基于未标记的样本的分布漂移下测试时间校准置信度预测器

    Test-time Recalibration of Conformal Predictors Under Distribution Shift Based on Unlabeled Examples. (arXiv:2210.04166v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04166](http://arxiv.org/abs/2210.04166)

    本论文提出了一种基于未标记样本的分布漂移下测试时间校准置信度预测器。通过使用密度比估计技术来预测新分布的截止阈值，我们在几个标准图像数据集上展示了该方法优于最新的分布漂移下的测试时间校准方法。

    

    现代图像分类器非常准确，但预测没有不确定性估计。基于分类器的概率估计，基本置信度预测器通过计算一组包含具有用户指定概率的正确类的类来提供不确定性估计。为了提供这样的集合，置信度预测器常常基于校准集合估计概率估计的截断阈值。置信度预测器仅在校准集合与测试集相同时保证可靠性。因此，置信度预测器需要为新分布重新校准。但在实践中，很少有来自新分布的标记数据，使校准成为不可行的。在这项工作中，我们考虑了基于未标记样本预测新分布截止阈值的问题。虽然一般情况下不能保证基于未标记样本进行校准时的可靠性，但我们提出了一种基于密度比估计技术的方法来预测新分布的截止阈值。我们在几个标准图像数据集上评估了我们的方法，并显示出在分布漂移下进行测试时间校准的最新方法。

    Modern image classifiers are very accurate, but the predictions come without uncertainty estimates. Conformal predictors provide uncertainty estimates by computing a set of classes containing the correct class with a user-specified probability based on the classifier's probability estimates. To provide such sets, conformal predictors often estimate a cutoff threshold for the probability estimates based on a calibration set. Conformal predictors guarantee reliability only when the calibration set is from the same distribution as the test set. Therefore, conformal predictors need to be recalibrated for new distributions. However, in practice, labeled data from new distributions is rarely available, making calibration infeasible. In this work, we consider the problem of predicting the cutoff threshold for a new distribution based on unlabeled examples. While it is impossible in general to guarantee reliability when calibrating based on unlabeled examples, we propose a method that provides
    
[^87]: 通过冗余性实现稀疏性：用SGD求解$L_1$

    Sparsity by Redundancy: Solving $L_1$ with SGD. (arXiv:2210.01212v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01212](http://arxiv.org/abs/2210.01212)

    该论文提出了一种通过冗余重参数化和简单的随机梯度下降来最小化带有$L_1$惩罚的通用可微损失函数的方法，称为\textit{spred}，是$L_1$的精确求解器，可用于训练稀疏神经网络以执行基因选择任务和神经网络压缩任务，弥合了深度学习中的稀疏性和传统统计学习之间的差距。

    This paper proposes a method called "spred" to minimize a generic differentiable loss function with $L_1$ penalty using redundant reparametrization and straightforward stochastic gradient descent. It is an exact solver of $L_1$ and can be used to train sparse neural networks for gene selection tasks and neural network compression tasks, bridging the gap between sparsity in deep learning and conventional statistical learning.

    我们提出了一种通过冗余重参数化和简单的随机梯度下降来最小化带有$L_1$惩罚的通用可微损失函数的方法。我们的提议是$L_1$惩罚等价于带有权重衰减的可微重参数化的直接推广。我们证明了所提出的方法，即\textit{spred}，是$L_1$的精确求解器，并且对于通用的非凸函数，重参数化技巧是完全“良性”的。在实践中，我们展示了该方法的实用性，包括(1)训练稀疏神经网络以执行基因选择任务，其中涉及在非常高维空间中找到相关特征，以及(2)神经网络压缩任务，先前尝试应用$L_1$惩罚的方法均未成功。从概念上讲，我们的结果弥合了深度学习中的稀疏性和传统统计学习之间的差距。

    We propose to minimize a generic differentiable loss function with $L_1$ penalty with a redundant reparametrization and straightforward stochastic gradient descent. Our proposal is the direct generalization of a series of previous ideas that the $L_1$ penalty may be equivalent to a differentiable reparametrization with weight decay. We prove that the proposed method, \textit{spred}, is an exact solver of $L_1$ and that the reparametrization trick is completely ``benign" for a generic nonconvex function. Practically, we demonstrate the usefulness of the method in (1) training sparse neural networks to perform gene selection tasks, which involves finding relevant features in a very high dimensional space, and (2) neural network compression task, to which previous attempts at applying the $L_1$-penalty have been unsuccessful. Conceptually, our result bridges the gap between the sparsity in deep learning and conventional statistical learning.
    
[^88]: 从部分 episode 中学习 GFlowNets 以改善收敛性和稳定性

    Learning GFlowNets from partial episodes for improved convergence and stability. (arXiv:2209.12782v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.12782](http://arxiv.org/abs/2209.12782)

    本文提出了一种 GFlowNets 训练目标——子轨迹平衡(SubTB($\lambda$))，从部分 episode 学习的方式可以加速采样器在环境中的收敛速度，并使得在之前难以训练的长动作序列和奖励稀疏的环境中也能够训练 GFlowNets。

    

    生成流网络(GFlowNets)是一类算法，用于在未归一化的目标密度下对离散对象进行顺序采样训练，并已成功应用于各种概率建模任务中。现有的GFlowNets训练目标既可以局部关注状态或转换，也可以在整个采样轨迹上传播奖励信号。我们认为这些替代方案代表了梯度偏差—方差平衡的两端，并提出了一种利用这种平衡来减轻其有害影响的方法。受强化学习中的 TD($\lambda$)算法的启发，我们引入了子轨迹平衡(SubTB($\lambda$))，一种 GFlowNets 训练目标，可以从不同长度的部分动作子序列中学习。我们展示了 SubTB($\lambda$) 加速了在先前研究过的和新的环境中的采样器收敛，并使得在动作序列更长、奖励更稀疏的环境中训练 GFlowNets 成为了可能。

    Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\lambda$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was poss
    
[^89]: 张量积与近似正交码的图嵌入方法

    Graph Embeddings via Tensor Products and Approximately Orthonormal Codes. (arXiv:2208.10917v4 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2208.10917](http://arxiv.org/abs/2208.10917)

    本文介绍了一种嵌入图形到向量空间的方法，使用张量积以及球形码实现高效压缩和表征，在稀疏图表示和其他应用中具有潜在技术优势。

    

    我们分析了一种以保持结构方式来嵌入图形的方法，展示了其丰富的表征能力并建立了一些理论性质。我们的过程属于绑定和求和方法，并且我们显示了张量积是尊重叠加原理的最一般的绑定操作。我们还建立了一些精确的结果对我们方法的行为进行了表征，并且我们证明我们使用的球形码实现了一个装箱上限。我们建立了与邻接矩阵的联系，表明我们的方法在某种意义上是一种邻接矩阵的压缩，具有稀疏图表示的应用。

    We analyze a method for embedding graphs as vectors in a structure-preserving manner, showcasing its rich representational capacity and establishing some of its theoretical properties. Our procedure falls under the bind-and-sum approach, and we show that the tensor product is the most general binding operation that respects the superposition principle. We also establish some precise results characterizing the behavior of our method, and we show that our use of spherical codes achieves a packing upper bound. We establish a link to adjacency matrices, showing that our method is, in some sense, a compression of adjacency matrices with applications towards sparse graph representations.
    
[^90]: 临床试验中受益人群的自适应识别：机器学习挑战与解决方案

    Adaptive Identification of Populations with Treatment Benefit in Clinical Trials: Machine Learning Challenges and Solutions. (arXiv:2208.05844v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.05844](http://arxiv.org/abs/2208.05844)

    本文提出了一种新的数据驱动的方法，同时使用了机器学习和自适应实验技术，用于自适应性临床试验中受益于给定治疗的患者亚群的识别。本文通过实验展示了该方法的优异表现，并解决了这一问题的独特挑战，产生了有效和有用的发现。

    

    本文研究了在确认性临床试验中自适应性地识别受益于给定治疗的患者亚群的问题。这种自适应性临床试验已经在生物统计学中得到了深入研究，但目前仅允许有限的自适应性。本文旨在放宽这样的设计的经典限制，并研究如何融合最近机器学习文献中的自适应和在线实验的思想，使试验更加灵活和高效。我们发现，亚群选择问题的独特特征——最重要的是，（i）通常感兴趣的是在有限的预算下找到任何受益于治疗的亚群（而不一定是单个效果最大的亚组），以及（ii）只需在平均水平上证明有效性——催生了有趣的挑战和设计算法解决方案的新要求。基于这些发现，我们提出了一种新的数据驱动的子群体识别方法，同时使用了机器学习和自适应实验技术。我们进行了大量的模拟和实际数据分析，展示了我们方法不仅表现优异，而且解决了这一问题的独特挑战，产生了有效和有用的发现。

    We study the problem of adaptively identifying patient subpopulations that benefit from a given treatment during a confirmatory clinical trial. This type of adaptive clinical trial has been thoroughly studied in biostatistics, but has been allowed only limited adaptivity so far. Here, we aim to relax classical restrictions on such designs and investigate how to incorporate ideas from the recent machine learning literature on adaptive and online experimentation to make trials more flexible and efficient. We find that the unique characteristics of the subpopulation selection problem -- most importantly that (i) one is usually interested in finding subpopulations with any treatment benefit (and not necessarily the single subgroup with largest effect) given a limited budget and that (ii) effectiveness only has to be demonstrated across the subpopulation on average -- give rise to interesting challenges and new desiderata when designing algorithmic solutions. Building on these findings, we 
    
[^91]: 一种基于监督张量降维的不完整成像数据的预测模型

    A Supervised Tensor Dimension Reduction-Based Prognostics Model for Applications with Incomplete Imaging Data. (arXiv:2207.11353v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.11353](http://arxiv.org/abs/2207.11353)

    本文提出了一种基于监督张量降维的预测模型，能处理不完整的成像数据，利用失效时间监督提取低维特征，提高了预测的准确性。

    

    本文提出了一种用于张量数据的监督降维方法，与大多数基于图像的预测模型相比具有两个优势。首先，该模型不要求张量数据完整，从而扩展了其应用范围；其次，利用失效时间（TTF）来监督提取低维特征，使提取的特征更有效地用于后续预测。此外，本文为参数估计提出了一种优化算法，并在特定分布下推导出了闭式解。

    This paper proposes a supervised dimension reduction methodology for tensor data which has two advantages over most image-based prognostic models. First, the model does not require tensor data to be complete which expands its application to incomplete data. Second, it utilizes time-to-failure (TTF) to supervise the extraction of low-dimensional features which makes the extracted features more effective for the subsequent prognostic. Besides, an optimization algorithm is proposed for parameter estimation and closed-form solutions are derived under certain distributions.
    
[^92]: 平移不变核函数的正交展开

    Orthonormal Expansions for Translation-Invariant Kernels. (arXiv:2206.08648v3 [math.CA] UPDATED)

    [http://arxiv.org/abs/2206.08648](http://arxiv.org/abs/2206.08648)

    该论文提出了一种傅里叶分析技术，用于从$\mathscr{L}_2(\mathbb{R})$的正交基中构建平移不变核函数的正交基展开，实现了马特尔核函数、柯西核函数和高斯核函数的明确展开表达式。

    

    我们提出了一种用于构建平移不变核函数的正交基展开的傅里叶分析技术，该技术利用$\mathscr{L}_2(\mathbb{R})$上的正交基，得到了实轴上所有半整数阶马特尔核函数、柯西核函数以及高斯核函数的明确展开表达式，分别由相关的拉盖尔函数、有理函数和厄米函数表示。

    We present a general Fourier analytic technique for constructing orthonormal basis expansions of translation-invariant kernels from orthonormal bases of $\mathscr{L}_2(\mathbb{R})$. This allows us to derive explicit expansions on the real line for (i) Mat\'ern kernels of all half-integer orders in terms of associated Laguerre functions, (ii) the Cauchy kernel in terms of rational functions, and (iii) the Gaussian kernel in terms of Hermite functions.
    
[^93]: 元最优输运

    Meta Optimal Transport. (arXiv:2206.05262v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.05262](http://arxiv.org/abs/2206.05262)

    本文提出了一种新的方法，利用过去问题的知识和信息来迅速预测和解决新问题，重复地解决不同度量之间的类似OT问题，从而改善最优输运问题的计算时间。

    

    我们研究了使用分摊优化来预测最优输运（OT）地图的方法，我们称之为元OT。这有助于通过利用过去问题的知识和信息来迅速预测和解决新问题，从而重复地解决不同度量之间的类似OT问题。否则，标准方法会忽略过去解决方案的知识，从头开始次优地重新解决每个问题。我们在灰度图像、球形数据、分类标签和颜色调色板之间实例化元OT模型，并使用它们来改善标准OT求解器的计算时间。我们的源代码可在此http URL找到。

    We study the use of amortized optimization to predict optimal transport (OT) maps from the input measures, which we call Meta OT. This helps repeatedly solve similar OT problems between different measures by leveraging the knowledge and information present from past problems to rapidly predict and solve new problems. Otherwise, standard methods ignore the knowledge of the past solutions and suboptimally re-solve each problem from scratch. We instantiate Meta OT models in discrete and continuous settings between grayscale images, spherical data, classification labels, and color palettes and use them to improve the computational time of standard OT solvers. Our source code is available at this http URL
    
[^94]: 点积核回归的精确学习曲线和高阶标度极限

    Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression. (arXiv:2205.14846v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14846](http://arxiv.org/abs/2205.14846)

    本文细致研究了点积核岭回归问题，针对 $m\propto d^r$ 高阶标度关系提出了精确的测试误差、偏差和方差公式。

    

    随着现代机器学习模型不断推进计算前沿，开发对不同模型和数据缩放方案下预期性能提高的精确估计变得越来越重要。目前，关于描述预测误差如何随着样本数量而变化的学习曲线的理论理解受限于大样本渐近性 ($m\to\infty$) 或对于某些简单数据分布的高维渐近性，其中样本数量与维数成线性比例 ($m\propto d$)。这两个范畴之间存在很大差距，包括所有高阶标度关系 $m\propto d^r$，这是本文的研究对象。我们专注于点积核岭回归的问题，并提供了在 $m/d\rightarrow2r$ 的 $r$ 阶渐近标度下（其中 $m\to\infty$），对于从球面上均匀抽取的数据，测试误差、偏差和方差的精确公式。

    As modern machine learning models continue to advance the computational frontier, it has become increasingly important to develop precise estimates for expected performance improvements under different model and data scaling regimes. Currently, theoretical understanding of the learning curves that characterize how the prediction error depends on the number of samples is restricted to either large-sample asymptotics ($m\to\infty$) or, for certain simple data distributions, to the high-dimensional asymptotics in which the number of samples scales linearly with the dimension ($m\propto d$). There is a wide gulf between these two regimes, including all higher-order scaling relations $m\propto d^r$, which are the subject of the present paper. We focus on the problem of kernel ridge regression for dot-product kernels and present precise formulas for the test error, bias, and variance, for data drawn uniformly from the sphere in the $r$th-order asymptotic scaling regime $m\to\infty$ with $m/d
    
[^95]: 元学习器用于多值处理异质作用估计的比较

    Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects. (arXiv:2205.14714v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.14714](http://arxiv.org/abs/2205.14714)

    本文探讨了利用元学习器估计多值处理异质效应的问题，发现朴素扩展并不总是可行，提出并讨论了一些表现良好的元学习器。

    

    在利用观察数据进行因果推断时，条件平均处理效应（CATE）估计是主要挑战之一。除了基于机器学习的模型外，还开发出了称为元学习器的非参数估计器以估计CATE，其主要优点是不局限于特定的监督学习方法。然而，当处理不是二进制的时，一些朴素扩展的限制会出现，这样的任务就变得更加复杂。本文研究了元学习器用于估计多值处理异质效应。我们考虑了不同的元学习器，理论分析了它们的误差上界作为重要参数的函数，例如处理水平的数量，结果显示，朴素扩展并不总是提供满意的结果。我们引入和讨论了一些元学习器，它们在处理数量增多时表现良好。通过模拟研究和一项乙肝治疗研究的真实数据示例，我们证实了元学习器的优缺点。

    Conditional Average Treatment Effects (CATE) estimation is one of the main challenges in causal inference with observational data. In addition to Machine Learning based-models, nonparametric estimators called meta-learners have been developed to estimate the CATE with the main advantage of not restraining the estimation to a specific supervised learning method. This task becomes, however, more complicated when the treatment is not binary as some limitations of the naive extensions emerge. This paper looks into meta-learners for estimating the heterogeneous effects of multi-valued treatments. We consider different meta-learners, and we carry out a theoretical analysis of their error upper bounds as functions of important parameters such as the number of treatment levels, showing that the naive extensions do not always provide satisfactory results. We introduce and discuss meta-learners that perform well as the number of treatments increases. We empirically confirm the strengths and weak
    
[^96]: 神经网络的规范叶面：鲁棒性应用研究

    Canonical foliations of neural networks: application to robustness. (arXiv:2203.00922v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.00922](http://arxiv.org/abs/2203.00922)

    本文探讨了利用黎曼几何和叶面理论创新应用于神经网络鲁棒性的新视角，提出了一种适用于数据空间的以曲率为考量因素的 two-step spectral 对抗攻击方法。

    

    深度学习模型易受到对抗攻击。而对抗学习正在变得至关重要。本文提出了一种新的神经网络鲁棒性视角，采用黎曼几何和叶面理论。通过创建考虑数据空间曲率的新对抗攻击，即 two-step spectral attack，来说明这个想法。数据空间被视为一个配备了神经网络的 Fisher 信息度量（FIM）拉回的（退化的）黎曼流形。大多数情况下，该度量仅为半正定，其内核成为研究的核心对象。从该核中导出一个规范叶面。横向叶的曲率给出了适当的修正，从而得到了两步近似的测地线和一种新的高效对抗攻击。该方法首先在一个 2D 玩具示例中进行演示。

    Deep learning models are known to be vulnerable to adversarial attacks. Adversarial learning is therefore becoming a crucial task. We propose a new vision on neural network robustness using Riemannian geometry and foliation theory. The idea is illustrated by creating a new adversarial attack that takes into account the curvature of the data space. This new adversarial attack called the two-step spectral attack is a piece-wise linear approximation of a geodesic in the data space. The data space is treated as a (degenerate) Riemannian manifold equipped with the pullback of the Fisher Information Metric (FIM) of the neural network. In most cases, this metric is only semi-definite and its kernel becomes a central object to study. A canonical foliation is derived from this kernel. The curvature of transverse leaves gives the appropriate correction to get a two-step approximation of the geodesic and hence a new efficient adversarial attack. The method is first illustrated on a 2D toy example
    
[^97]: 离散潜变量模型的贝叶斯主动学习

    Bayesian Active Learning for Discrete Latent Variable Models. (arXiv:2202.13426v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.13426](http://arxiv.org/abs/2202.13426)

    本文提出了一个新的框架，用于离散潜变量回归模型的最大相互信息输入选择。通过对线性回归混合物模型的Fisher信息分析，证明在这种情况下主动学习可以取得巨大的收益。同时，我们考虑了一类强大的时间结构潜变量模型，并展示了如何将我们的框架调整为在选择过程中融入时态依赖性。

    

    主动学习旨在减少拟合模型参数所需的数据量，因此成为现代机器学习中的重要技术类别。然而，过去的主动学习研究往往忽视了在神经科学、心理学和各种工程和科学学科中发挥关键作用的潜变量模型。本文提出了一种新的框架，用于离散潜变量回归模型的最大相互信息输入选择。我们首先将我们的方法应用于一类称为“线性回归混合物”的模型。虽然已知对于线性高斯回归模型，主动学习并不具有优势，但我们使用Fisher信息进行分析，表明即使对于这种混合模型，主动学习仍然可以取得巨大的收益，并使用模拟和真实数据对此进行了验证。然后，我们考虑了一类强大的时间结构潜变量模型，并展示了如何将我们的框架调整为在选择过程中融入时态依赖性。总的来说，我们的工作展示了主动学习在一个新领域的有效性，并提供了一个通用的框架，可应用于广泛的离散潜变量模型，只需进行较少的修改。

    Active learning seeks to reduce the amount of data required to fit the parameters of a model, thus forming an important class of techniques in modern machine learning. However, past work on active learning has largely overlooked latent variable models, which play a vital role in neuroscience, psychology, and a variety of other engineering and scientific disciplines. Here we address this gap by proposing a novel framework for maximum-mutual-information input selection for discrete latent variable regression models. We first apply our method to a class of models known as "mixtures of linear regressions" (MLR). While it is well known that active learning confers no advantage for linear-Gaussian regression models, we use Fisher information to show analytically that active learning can nevertheless achieve large gains for mixtures of such models, and we validate this improvement using both simulations and real-world data. We then consider a powerful class of temporally structured latent var
    
[^98]: 探索性的隐马尔可夫因子模型用于纵向移动健康数据：以不良创伤后神经精神后遗症为例。

    Exploratory Hidden Markov Factor Models for Longitudinal Mobile Health Data: Application to Adverse Posttraumatic Neuropsychiatric Sequelae. (arXiv:2202.12819v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2202.12819](http://arxiv.org/abs/2202.12819)

    本文提出了一个探索性的隐马尔可夫因子模型以利用长期移动设备数据，确定 APNS 状态并研究其转换和潜在风险因素，为理解和干预 APNS 提供了更全面和客观的途径。

    

    不良的创伤后神经精神后遗症（APNS）在退役军人和数百万美国人中很常见，给创伤幸存者和社会带来了巨大重负。尽管过去几十年对APNS进行了Numerous的研究，但由于几个独特的挑战，理解其潜在神经生物机制的进展有限。其中一个挑战是依赖于主观的自我报告测量APNS，这容易导致测量误差和偏差（例如回忆偏倚）。为了减轻这个问题，在本文中，我们研究了利用客观纵向移动设备数据以识别同质APNS状态并研究创伤暴露后APNS的动态转换和潜在风险因素的潜力。为了处理纵向移动设备数据所面临的特定挑战，我们开发了探索性的隐马尔可夫因子模型，并设计了一个稳定的期望最大化算法来学习模型参数。所提出的方法使用模拟和真实数据进行了评估，这些数据来自大量遭受创伤的退役军人。结果表明，所提出的模型能够成功地识别同质APNS状态，捕获这些状态之间的动态转换，并揭示与这些转换相关的风险因素。所提出的方法有潜力提供更客观和全面的理解APNS潜在神经形成机制，并为创伤幸存者的有针对性的干预的开发提供信息。

    Adverse posttraumatic neuropsychiatric sequelae (APNS) are common among veterans and millions of Americans after traumatic exposures, resulting in substantial burdens for trauma survivors and society. Despite numerous studies conducted on APNS over the past decades, there has been limited progress in understanding the underlying neurobiological mechanisms due to several unique challenges. One of these challenges is the reliance on subjective self-report measures to assess APNS, which can easily result in measurement errors and biases (e.g., recall bias). To mitigate this issue, in this paper, we investigate the potential of leveraging the objective longitudinal mobile device data to identify homogeneous APNS states and study the dynamic transitions and potential risk factors of APNS after trauma exposure. To handle specific challenges posed by longitudinal mobile device data, we developed exploratory hidden Markov factor models and designed a Stabilized Expectation-Maximization algorit
    
[^99]: Eigenlearning框架：核回归和宽神经网络的守恒定律视角

    The Eigenlearning Framework: A Conservation Law Perspective on Kernel Regression and Wide Neural Networks. (arXiv:2110.03922v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03922](http://arxiv.org/abs/2110.03922)

    该论文提出了Eigenlearning框架，通过限制核回归在学习正交基函数方面的能力并利用守恒定律来解释模型的泛化能力，同时还为Nakkiran等人的“深度引导”现象，经典奇偶问题难度和对抗鲁棒性提供了理论支持，并与统计物理学中的一个系统进行了类比。

    

    我们针对核岭回归（KRR）的测试风险和其他泛化指标导出了简单的闭式估计。相对于以前的工作，我们的推导大大简化，最终表达式更易于解释。这些改进得益于我们识别出的一个尖锐的守恒定律，它限制了KRR学习任何正交基函数的能力。测试风险和其他感兴趣的对象可以透明地用于我们在核特征基中评估的守恒量来表示。我们使用改进的框架来：i）为Nakkiran等人（2020）的“深度引导”提供理论解释，ii）推广先前关于经典奇偶问题难度的结果，iii）为对抗鲁棒性的研究提供理论工具，并iv）在统计物理学中研究核岭回归和熟知系统之间的严密类比。

    We derive simple closed-form estimates for the test risk and other generalization metrics of kernel ridge regression (KRR). Relative to prior work, our derivations are greatly simplified and our final expressions are more readily interpreted. These improvements are enabled by our identification of a sharp conservation law which limits the ability of KRR to learn any orthonormal basis of functions. Test risk and other objects of interest are expressed transparently in terms of our conserved quantity evaluated in the kernel eigenbasis. We use our improved framework to: i) provide a theoretical explanation for the "deep bootstrap" of Nakkiran et al (2020), ii) generalize a previous result regarding the hardness of the classic parity problem, iii) fashion a theoretical tool for the study of adversarial robustness, and iv) draw a tight analogy between KRR and a well-studied system in statistical physics.
    
[^100]: Sinkhorn分布鲁棒优化

    Sinkhorn Distributionally Robust Optimization. (arXiv:2109.11926v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2109.11926](http://arxiv.org/abs/2109.11926)

    本文通过使用Sinkhorn距离进行分布鲁棒优化，推导出更容易处理且在实际中更合理的最坏情况分布，提出了解决方案，并展示了其优越性能。

    

    我们研究了使用Sinkhorn距离 -一种基于熵正则化的Wasserstein距离变体- 的分布鲁棒优化（DRO）。我们为一般名义分布推导了凸规划对偶重构。相比于Wasserstein DRO，对于更大类的损失函数，它在计算上更容易处理，它的最坏情况分布对实际应用更合理。为了解决对偶重构，我们开发了一种使用有偏梯度神经元的随机镜像下降算法，并分析了其收敛速度。最后，我们提供了使用合成和真实数据的数值实例，以证明其优越性能。

    We study distributionally robust optimization (DRO) with Sinkhorn distance -a variant of Wasserstein distance based on entropic regularization. We derive convex programming dual reformulation for a general nominal distribution. Compared with Wasserstein DRO, it is computationally tractable for a larger class of loss functions, and its worst-case distribution is more reasonable for practical applications. To solve the dual reformulation, we develop a stochastic mirror descent algorithm using biased gradient oracles and analyze its convergence rate. Finally, we provide numerical examples using synthetic and real data to demonstrate its superior performance.
    
[^101]: 深度贝叶斯主动学习用于加速随机模拟

    Deep Bayesian Active Learning for Accelerating Stochastic Simulation. (arXiv:2106.02770v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.02770](http://arxiv.org/abs/2106.02770)

    本文提出了一个名为交互式神经过程(INP)的深度贝叶斯主动学习框架，用于学习深度代理模型以加速随机模拟过程，其中通过使用空间时间神经过程(STNP)实现模拟器动态的模拟，以及利用潜在信息增益(LIG)的主动学习方式来减少样本的复杂度。

    

    针对实现精细粒度下的大规模空间时间年龄结构流行病模型等随机模拟方法的高计算代价，本文提出了一个名为交互式神经过程(INP)的深度贝叶斯主动学习框架，用于学习深度代理模型以加速随机模拟过程。该框架由两个部分组成，即建立在神经过程(NP)家族基础之上的空间时间代理模型和一个用于主动学习的收购函数。其中，我们提出了空间时间神经过程(STNP)来模拟模拟器动态，同时在NP模型的潜空间中提出了一种新颖的收获函数——潜在信息增益(LIG)。理论分析和实践证明，LIG相对于高维随机抽样可以降低模拟样本复杂度。

    Stochastic simulations such as large-scale, spatiotemporal, age-structured epidemic models are computationally expensive at fine-grained resolution. While deep surrogate models can speed up the simulations, doing so for stochastic simulations and with active learning approaches is an underexplored area. We propose Interactive Neural Process (INP), a deep Bayesian active learning framework for learning deep surrogate models to accelerate stochastic simulations. INP consists of two components, a spatiotemporal surrogate model built upon Neural Process (NP) family and an acquisition function for active learning. For surrogate modeling, we develop Spatiotemporal Neural Process (STNP) to mimic the simulator dynamics. For active learning, we propose a novel acquisition function, Latent Information Gain (LIG), calculated in the latent space of NP based models. We perform a theoretical analysis and demonstrate that LIG reduces sample complexity compared with random sampling in high dimensions.
    
[^102]: 分布式自适应最近邻分类器：算法和理论

    Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory. (arXiv:2105.09788v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2105.09788](http://arxiv.org/abs/2105.09788)

    提出一种新颖的分布式自适应NN分类器，通过随机选择数据驱动准则来调优最近邻数，提出了早期停止规则，实现了加速计算和改善有限样本性能。通过研究证明，当子样本大小足够大时，分类器实现了近乎最优的收敛速度。有效性已通过模拟和实证应用得到验证。

    

    当数据规模异常庞大或分布在不同的位置上时，分布式最近邻（NN）分类器是一种吸引人的分类工具。我们提出了一种新颖的分布式自适应NN分类器，其中最近邻数是由数据驱动准则随机选择的调优参数。在寻找最优调优参数时提出了一种早期停止规则，这不仅加快了计算速度，还改善了所提算法的有限样本性能。在各种子样本大小组合下，研究了分布式自适应NN分类器的超额风险收敛速度。特别地，我们证明了当子样本大小足够大时，所提分类器实现了近乎最优的收敛速度。通过模拟研究和对真实世界数据集的实证应用，证明了所提方法的有效性。

    When data is of an extraordinarily large size or physically stored in different locations, the distributed nearest neighbor (NN) classifier is an attractive tool for classification. We propose a novel distributed adaptive NN classifier for which the number of nearest neighbors is a tuning parameter stochastically chosen by a data-driven criterion. An early stopping rule is proposed when searching for the optimal tuning parameter, which not only speeds up the computation but also improves the finite sample performance of the proposed Algorithm. Convergence rate of excess risk of the distributed adaptive NN classifier is investigated under various sub-sample size compositions. In particular, we show that when the sub-sample sizes are sufficiently large, the proposed classifier achieves the nearly optimal convergence rate. Effectiveness of the proposed approach is demonstrated through simulation studies as well as an empirical application to a real-world dataset.
    
[^103]: 高斯过程多折交叉验证残差及其协方差的快速计算

    Fast calculation of Gaussian Process multiple-fold cross-validation residuals and their covariances. (arXiv:2101.03108v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2101.03108](http://arxiv.org/abs/2101.03108)

    本研究提出了一种快速计算高斯过程多折交叉验证残差及其协方差的方法，在模型诊断和比例尺参数估计方面有一定应用价值。

    

    我们将快速高斯过程留一法则推广到多折交叉验证，重点介绍了简单和通用Kriging框架下交叉验证残差的协方差结构。我们展示了结果协方差如何影响模型诊断。我们进一步在无噪声观测值的情况下证明，在交叉验证估计比例尺参数时，纠正残差之间的协方差可导回MLE。此外，我们也强调了在更广泛的情况下，伪似然和似然方法之间的差异归结为是否考虑残差协方差。所提议的快速计算交叉验证残差已得到实现和基准测试，数值实验展示了我们方法所具有的精度和实现大幅提速的优势。然而，根据计算成本主要驱动因素的讨论和数字基准测试的支持，我们发现随着折数的增加，速度提升骤减。

    We generalize fast Gaussian process leave-one-out formulae to multiple-fold cross-validation, highlighting in turn the covariance structure of cross-validation residuals in both Simple and Universal Kriging frameworks. We illustrate how resulting covariances affect model diagnostics. We further establish in the case of noiseless observations that correcting for covariances between residuals in cross-validation-based estimation of the scale parameter leads back to MLE. Also, we highlight in broader settings how differences between pseudo-likelihood and likelihood methods boil down to accounting or not for residual covariances. The proposed fast calculation of cross-validation residuals is implemented and benchmarked against a naive implementation. Numerical experiments highlight the accuracy and substantial speed-ups that our approach enables. However, as supported by a discussion on main drivers of computational costs and by a numerical benchmark, speed-ups steeply decline as the numbe
    
[^104]: 概率公平聚类

    Probabilistic Fair Clustering. (arXiv:2006.10916v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.10916](http://arxiv.org/abs/2006.10916)

    本文提出了一种通过概率分配获得组成员身份的不完美知识的公平聚类算法，并在这种更一般的设置中给出了逼近比保证。

    

    在聚类问题中，一个中央决策者被赋予了一个顶点的完整度量图，并且必须提供顶点的聚类，以最小化某些客观函数。在公平聚类问题中，顶点被赋予了颜色（例如，属于一个组的成员资格），有效聚类的特征也可能包括颜色在该聚类中的表示。之前的公平聚类工作假设完全知道组成员身份。在本文中，我们通过假设通过概率分配来获得组成员身份的不完美知识，对以前的工作进行了推广。我们在这种更一般的设置中提出了聚类算法，并给出了逼近比担保。我们还解决了“度量成员身份”的问题，其中不同的组具有顺序和距离的概念。使用我们提出的算法以及基线进行实验，以验证我们的方法，并在不确定地知道组成员身份时揭示微妙的担忧。

    In clustering problems, a central decision-maker is given a complete metric graph over vertices and must provide a clustering of vertices that minimizes some objective function. In fair clustering problems, vertices are endowed with a color (e.g., membership in a group), and the features of a valid clustering might also include the representation of colors in that clustering. Prior work in fair clustering assumes complete knowledge of group membership. In this paper, we generalize prior work by assuming imperfect knowledge of group membership through probabilistic assignments. We present clustering algorithms in this more general setting with approximation ratio guarantees. We also address the problem of "metric membership", where different groups have a notion of order and distance. Experiments are conducted using our proposed algorithms as well as baselines to validate our approach and also surface nuanced concerns when group membership is not known deterministically.
    
[^105]: 深度弱监督异常检测

    Deep Weakly-supervised Anomaly Detection. (arXiv:1910.13601v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1910.13601](http://arxiv.org/abs/1910.13601)

    PReNet是一种深度弱监督方法，可以检测既有已知又有未知的异常情况，通过学习成对的关系特征和异常分数，实现了异常-异常、异常-正常和正常-正常的联合学习。

    

    最近的半监督异常检测方法使用较少的标记异常样本和大量的未标记数据（大多数为正常数据）进行训练，已经显示在与无监督方法相比可以大幅提高性能。然而，这些方法通常只会关注与给定异常样本对应的异常情况，因此无法泛化到不属于此类情况的新类型/类别的异常情况。为了检测既有已知又有未知的异常情况，我们提出了一种新的深度弱监督方法，称为Pairwise Relation Prediction Network (PReNet)，通过预测任意两个随机抽取的训练实例之间的关系来学习成对的关系特征和异常分数，其中成对的关系可以是异常-异常，异常-未标记或未标记-未标记。由于未标记的实例大多是正常的，这种关系预测强制进行异常-异常、异常-正常和正常-正常的联合学习。

    Recent semi-supervised anomaly detection methods that are trained using small labeled anomaly examples and large unlabeled data (mostly normal data) have shown largely improved performance over unsupervised methods. However, these methods often focus on fitting abnormalities illustrated by the given anomaly examples only (i.e.,, seen anomalies), and consequently they fail to generalize to those that are not, i.e., new types/classes of anomaly unseen during training. To detect both seen and unseen anomalies, we introduce a novel deep weakly-supervised approach, namely Pairwise Relation prediction Network (PReNet), that learns pairwise relation features and anomaly scores by predicting the relation of any two randomly sampled training instances, in which the pairwise relation can be anomaly-anomaly, anomaly-unlabeled, or unlabeled-unlabeled. Since unlabeled instances are mostly normal, the relation prediction enforces a joint learning of anomaly-anomaly, anomaly-normal, and normal-normal
    
[^106]: 在网约车叫车系统中预测乘客起终点的模型提出

    Proposing a Model for Predicting Passenger Origin-Destination in Online Taxi-Hailing Systems. (arXiv:1910.08145v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1910.08145](http://arxiv.org/abs/1910.08145)

    本文提出了一种模型，采用K均值和非负矩阵分解等方法，预测网约车叫车系统中乘客行程的起点和终点，相较于现有模型，具有更高的预测准确度。

    

    预测乘客的起终点对智能交通管理中的交通规划、交通管理和调度优化有着重要的意义。本文提出了一种模型，用于在给定时间窗口内预测行程的起点和终点。我们采用K均值聚类在四维空间中进行聚类，并设置了起点和终点区域的最大聚类大小约束来确定有效的出行流。由于集群数量庞大，我们采用非负矩阵分解降低出行集群的数量。此外，我们还实现了一种堆叠循环神经网络模型，用于预测每个集群中的出行次数。与现有模型的结果比较表明，我们的模型在1小时和30分钟的时间窗口内实现了5-7\%和14\%的较低均方绝对误差（MAPE）。

    Due to the significance of transportation planning, traffic management, and dispatch optimization, predicting passenger origin-destination has emerged as a crucial requirement for intelligent transportation systems management. In this study, we present a model designed to forecast the origin and destination of travels within a specified time window. To derive meaningful travel flows, we employ K-means clustering in a four-dimensional space with a maximum cluster size constraint for origin and destination zones. Given the large number of clusters, we utilize non-negative matrix factorization to reduce the number of travel clusters. Furthermore, we implement a stacked recurrent neural network model to predict the travel count in each cluster. A comparison of our results with existing models reveals that our proposed model achieves a 5-7\% lower mean absolute percentage error (MAPE) for 1-hour time windows and a 14\% lower MAPE for 30-minute time windows.
    
[^107]: 具有连续观测空间的POMDPs中的稀疏树搜索最优性保证

    Sparse tree search optimality guarantees in POMDPs with continuous observation spaces. (arXiv:1910.04332v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1910.04332](http://arxiv.org/abs/1910.04332)

    本研究证明了一种基于采样的算法，部分可观察加权稀疏采样（POWSS），可以在具有连续观测空间的POMDPs中准确估计Q值，并通过增加计算能力来实现接近最优解。

    

    具有连续状态和观测空间的部分可观察马尔可夫决策过程（POMDPs）具有表示实际决策和控制问题的强大灵活性，但解决起来非常困难。最近，使用观测权重的在线基于采样的算法在具有连续观测空间的领域中展现了前所未有的有效性。然而，这种技术尚未有正式的理论证明。本文提供了这样的证明，证明一种简化方法，部分可观察加权稀疏采样（POWSS），将正确地估计Q值，并且可以通过增加计算能力来使其接近最优解。

    Partially observable Markov decision processes (POMDPs) with continuous state and observation spaces have powerful flexibility for representing real-world decision and control problems but are notoriously difficult to solve. Recent online sampling-based algorithms that use observation likelihood weighting have shown unprecedented effectiveness in domains with continuous observation spaces. However there has been no formal theoretical justification for this technique. This work offers such a justification, proving that a simplified algorithm, partially observable weighted sparse sampling (POWSS), will estimate Q-values accurately with high probability and can be made to perform arbitrarily near the optimal solution by increasing computational power.
    

