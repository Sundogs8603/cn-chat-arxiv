# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Conformal PID Control for Time Series Prediction.](http://arxiv.org/abs/2307.16895) | 这项研究提出了一种在时间序列预测中应用的新的依从PID控制算法，能够量化不确定性并适应不同的系统误差，并在COVID-19死亡人数、电力需求和市场回报等方面取得了更好的预测结果。 |
| [^2] | [Classification with Deep Neural Networks and Logistic Loss.](http://arxiv.org/abs/2307.16792) | 本文提出了一种新颖的oracle型不等式，通过解决逻辑损失的目标函数无界性限制，推导出使用逻辑损失训练的全连接ReLU深度神经网络分类器的最优收敛速率，仅要求数据的条件类概率具有H\"older平滑性，并且考虑了组合假设，使得该方法具有更广泛的适用性。 |
| [^3] | [Lossless Transformations and Excess Risk Bounds in Statistical Inference.](http://arxiv.org/abs/2307.16735) | 在统计推断中，我们研究了无损转换和过量风险的概念。我们提出了无损转换的特征，并构建了一个用于判断给定转换是否是无损的统计量。我们还引入了delta-无损转换的概念，并给出了充分条件。这些研究在分类、非参数回归和投资组合策略等领域具有应用价值。 |
| [^4] | [An Efficient Shapley Value Computation for the Naive Bayes Classifier.](http://arxiv.org/abs/2307.16718) | 这篇论文提出了在朴素贝叶斯分类器中计算Shapley值的新方法，并与Weight of Evidence和KernelShap进行了实证比较。 |
| [^5] | [A theory of data variability in Neural Network Bayesian inference.](http://arxiv.org/abs/2307.16695) | 本文提出了一个泛化性的场论形式体系，用于研究神经网络在无限宽隐藏层的极限情况，并通过计算非线性和深度非线性网络的泛化特性，阐明了数据的变异性对网络行为的影响。 |
| [^6] | [Sequential and Shared-Memory Parallel Algorithms for Partitioned Local Depths.](http://arxiv.org/abs/2307.16652) | 本文设计了连续和共享内存并行算法用于分割局部深度，并引入了性能优化策略，实现了较高的加速。通过三元组比较两两距离，实现了对稠密和稀疏社区内强关系的识别。 |
| [^7] | [Model-based Causal Bayesian Optimization.](http://arxiv.org/abs/2307.16625) | 本文提出了一种基于模型的因果贝叶斯优化方法，通过考虑其他智能体或外部事件对系统的干预，使其能够适应非平稳性，同时引入了具有有界遗憾的对抗性因果贝叶斯优化算法CBO-MW。该方法结合了在线学习策略和因果建模，通过因果图传播不确定性来计算乐观的反事实奖励估计。 |
| [^8] | [Classifying multilingual party manifestos: Domain transfer across country, time, and genre.](http://arxiv.org/abs/2307.16511) | 本研究探索了对多语言政党纲领进行分类的领域转移，在大规模政治纲领数据库中展示了微调Transformer模型在同一领域内的强大性能，并测试了其在不同地理位置、语言、时间和体裁之间的稳健性和可转移性。 |
| [^9] | [Don't be so negative! Score-based Generative Modeling with Oracle-assisted Guidance.](http://arxiv.org/abs/2307.16463) | 本文提出了一种基于得分的生成建模方法Gen-neG，它利用额外的辅助信息来指导生成过程。通过引导生成过程朝着正支持区域生成样本，该方法在自动驾驶模拟器中的避碰应用和安全防护人体动作生成中展现了实用性。 |
| [^10] | [A continuous Structural Intervention Distance to compare Causal Graphs.](http://arxiv.org/abs/2307.16452) | 这篇论文提出了一种新的连续测量度量，用于比较真实因果图与学习到的因果图之间的差异，并通过在再生核希尔伯特空间中嵌入干预分布来计算差异。数值实验证明了该方法的有效性。 |
| [^11] | [Guaranteed Optimal Generative Modeling with Maximum Deviation from the Empirical Distribution.](http://arxiv.org/abs/2307.16422) | 本文提供了一种理论方法来训练生成模型，确保其在样本大小趋近无穷时与真实数据生成分布的误差收敛为零，并且远离复制训练数据中示例的任何分布。 |
| [^12] | [Wasserstein Mirror Gradient Flow as the limit of the Sinkhorn Algorithm.](http://arxiv.org/abs/2307.16421) | Sinkhorn算法和迭代比例拟合程序可以收敛到一个Wasserstein镜像梯度流，其中速度场的范数代表线性化最佳输运距离的度量导数。 |
| [^13] | [RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection.](http://arxiv.org/abs/2307.16412) | RCS-YOLO是一种快速且高准确性的脑肿瘤检测物体检测器，通过引入Reparameterized Convolution和RCS-OSA技术，提高了YOLO框架在处理脑肿瘤检测中的性能，达到了最先进水平。 |
| [^14] | [Causal-learn: Causal Discovery in Python.](http://arxiv.org/abs/2307.16405) | Causal-learn是一个Python库，提供了全面的因果发现方法，适用于从业者和研究人员。与其他语言开发的包不同，Causal-learn完全由Python开发。 |
| [^15] | [2D Convolutional Neural Network for Event Reconstruction in IceCube DeepCore.](http://arxiv.org/abs/2307.16373) | 冰立方DeepCore中的二维卷积神经网络用于事件重建，在GeV级能量下具有更好的成功率，对于味道识别和不弹性重建具有特别的重要意义。 |
| [^16] | [Probabilistically robust conformal prediction.](http://arxiv.org/abs/2307.16360) | 本文研究了概率鲁棒性的符合性预测（PRCP）问题，通过提出aPRCP算法，实现了对干净输入示例的大多数扰动具有鲁棒性的预测。 |
| [^17] | [Towards Practical Robustness Auditing for Linear Regression.](http://arxiv.org/abs/2307.16315) | 本论文研究了实用的算法，用于查找或证伪数据集中对普通最小二乘回归具有影响的小子集。通过实证研究发现，这些算法方法在鲁棒性检查中表现良好，并提供了对低维回归问题的有用检查。但对于高维回归问题，计算瓶颈仍然存在。通过使用新颖的谱算法，我们取得了一些进展。 |
| [^18] | [Adaptive learning of density ratios in RKHS.](http://arxiv.org/abs/2307.16164) | 该论文研究在再生核希尔伯特空间中的一类密度比率估计方法，提出了一种自适应学习的参数选择原则，并在有限样本情况下推导出新的误差界。其方法在二次损失的情况下实现了极小化最优误差率。 |
| [^19] | [On Neural Network approximation of ideal adversarial attack and convergence of adversarial training.](http://arxiv.org/abs/2307.16099) | 这项研究通过使用神经网络对理想的对抗攻击进行近似表示，并将对抗训练转化为进攻网络和防守网络之间的数学博弈，同时给出了对抗训练在样本大小$n$下的收敛速度。 |
| [^20] | [Structural restrictions in local causal discovery: identifying direct causes of a target variable.](http://arxiv.org/abs/2307.16048) | 这项研究的目标是从观测数据中识别目标变量的直接原因，通过不对其他变量做太多假设，研究者提出了可识别性结果和两种实用算法。 |
| [^21] | [Neural Classifiers based Monte Carlo simulation.](http://arxiv.org/abs/2307.16035) | 该论文介绍了一种基于神经分类器的蒙特卡洛模拟算法，可以通过标记训练数据集来近似计算概率密度函数的比率。 |
| [^22] | [A Theory for Emergence of Complex Skills in Language Models.](http://arxiv.org/abs/2307.15936) | 本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。 |
| [^23] | [Comprehensive Algorithm Portfolio Evaluation using Item Response Theory.](http://arxiv.org/abs/2307.15850) | 本文提出了一种改进的基于IRT的框架，用于评估算法组合在数据集仓库中的性能，同时获取算法一致性和异常性等特征。该框架通过对传统IRT模型进行倒转和重新解释来实现，不需要额外的数据集特征计算。 |
| [^24] | [Mean Estimation with User-level Privacy under Data Heterogeneity.](http://arxiv.org/abs/2307.15835) | 本文提出了一种在数据异质性中保持用户级隐私的均值估计方法，允许用户数据在分布和数量上的差异，并证明了估计器的渐近最优性和可达到的误差下界。 |
| [^25] | [Non-parametric Hypothesis Tests for Distributional Group Symmetry.](http://arxiv.org/abs/2307.15834) | 该论文提出了用于分布对称性的非参数假设检验方法，适用于具有对称性的数据集。具体而言，该方法在紧致群作用下测试边际或联合分布的不变性，并提出了一种易于实施的条件蒙特卡罗检验。 |
| [^26] | [Seeking the Yield Barrier: High-Dimensional SRAM Evaluation Through Optimal Manifold.](http://arxiv.org/abs/2307.15773) | 本研究通过最优流形概念将替代模型和重要性采样方法联系起来，提出了一种新型的高维SRAM评估方法。该方法名为OPTIMIS，结合了神经耦合流和洋葱采样，在保持性能优势的同时具备鲁棒性和一致性。 |
| [^27] | [Weighted variation spaces and approximation by shallow ReLU networks.](http://arxiv.org/abs/2307.15772) | 本文研究了在有界域上通过单隐藏层ReLU网络逼近函数的问题，介绍了新的模型类定义加权变差空间，该定义与域本身相关。 |
| [^28] | [Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior.](http://arxiv.org/abs/2307.14619) | 本文提出了一个理论框架，研究了在非线性动态系统中模仿复杂专家演示的行为。通过稳定模仿策略并确保准确估计演示者分布，可以使模仿者与演示者的轨迹分布相近。 |
| [^29] | [Simulation-based Inference for Cardiovascular Models.](http://arxiv.org/abs/2307.13918) | 本研究将心血管模型的逆问题作为统计推理进行解决，在体外进行了五个生物标记物的不确定性分析，展示了模拟推理的能力。 |
| [^30] | [Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective.](http://arxiv.org/abs/2307.06457) | 该论文研究了组合分布偏移的问题，提出了基于矩阵补全的解决方法。通过在特殊情况下的双线性嵌入，实现对训练中未涵盖的测试分布进行外推。这个设置将缺失非随机数据的矩阵补全问题广义化。 |
| [^31] | [Interpreting deep embeddings for disease progression clustering.](http://arxiv.org/abs/2307.06060) | 本文提出了一种在疾病进展聚类中解读深度嵌入的新方法，并通过评估2型糖尿病参与者数据集展示了对疾病进展模式的临床意义性见解。 |
| [^32] | [How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model.](http://arxiv.org/abs/2307.02129) | 本文研究了深度神经网络学习组合性数据的问题，通过对随机层次模型进行分类任务，发现深度CNN学习这个任务所需的训练数据数量随着类别数、组合数和迭代次数的增加而渐进增加。 |
| [^33] | [Estimating Koopman operators with sketching to provably learn large scale dynamical systems.](http://arxiv.org/abs/2306.04520) | 本文提出利用随机投影技术优化了Koopman算子的估计器，加快了计算速度，并给出了精确的误差界限，提高了算法的可靠性。 |
| [^34] | [The minimax risk in testing the histogram of discrete distributions for uniformity under missing ball alternatives.](http://arxiv.org/abs/2305.18111) | 研究了离散分布样本对于类别间的均匀分布拟合问题下的极小极大风险，在缺少球形替代方案的情况下进行了讨论，通过离散直方图进行检验，获得了一种具有精确刻画的检验方法，并在实证研究中表现出了显著性。 |
| [^35] | [The Representation Jensen-Shannon Divergence.](http://arxiv.org/abs/2305.16446) | 本文提出了一种基于表示的新型散度——表示Jensen-Shannon散度，通过将数据分布嵌入到RKHS中，并利用表示的协方差算子的频谱，实现对数据分布的估计，并提供了具有灵活性，可扩展性，可微分性的经验协方差矩阵估计函数和基于核矩阵的估计函数。 |
| [^36] | [Reservoir Computing with Error Correction: Long-term Behaviors of Stochastic Dynamical Systems.](http://arxiv.org/abs/2305.00669) | 本文提出了一种数据驱动的框架，将沉积计算和归一化流结合起来以研究随机动力学系统的预测和动力学行为，成功地预测了长期演化并复制了动力学行为。 |
| [^37] | [Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information.](http://arxiv.org/abs/2304.13646) | 本研究提出一种嵌入非凸分段仿射决策规则的经验风险最小化方法，用于学习特征与最优决策之间的直接映射。所提出的方法可用于广泛的非凸型SP问题，并且在数值研究中表现出优越的性能。 |
| [^38] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^39] | [One-Shot Federated Conformal Prediction.](http://arxiv.org/abs/2302.06322) | 这种方法提出了一种在一次性联邦学习设置下进行适应预测的方法，通过定义分位数估计器，并且仅需要进行一轮通信就可以获得具有期望覆盖率的预测集。实验结果表明该方法在覆盖率和长度方面与集中式设置的结果非常相似，证明了其在一次性联邦学习中的适用性。 |
| [^40] | [SpArX: Sparse Argumentative Explanations for Neural Networks.](http://arxiv.org/abs/2301.09559) | 该论文提出了一种稀疏的神经网络论证解释方法SpArX，通过利用多层感知器和定量论证框架之间的关系，可以为神经网络的决策过程提供更忠实和深入的解释。 |
| [^41] | [Latent Multimodal Functional Graphical Model Estimation.](http://arxiv.org/abs/2210.17237) | 本研究提出了一个潜在多模态功能图模型估计的新框架，通过同时估计转换算子和潜在图来填补当前科学方法在估计多模态功能数据图模型方面的空白 |
| [^42] | [$k$-Means Clustering for Persistent Homology.](http://arxiv.org/abs/2210.10003) | 本文证明了$k$-均值聚类算法在持久图空间上的收敛性，解决了代数构造导致的复杂度问题，通过实验证明直接在持久图和持久度量上进行聚类优于向量表示。 |
| [^43] | [CitySim: A Drone-Based Vehicle Trajectory Dataset for Safety Oriented Research and Digital Twins.](http://arxiv.org/abs/2208.11036) | 本文介绍了CitySim数据集，该数据集通过无人机录制的视频提取车辆轨迹，旨在促进安全导向的研究和应用。数据集包含大量的细粒度车辆轨迹，并通过五步骤的处理确保了轨迹的准确性。 |
| [^44] | [Causal Discovery and Knowledge Injection for Contestable Neural Networks.](http://arxiv.org/abs/2205.09787) | 本研究提出了一种可以进行双向互动的方法，通过允许神经网络展示其所学因果图，并允许人类修改因果图后重新注入机器中，从而提供了一种调试神经网络的方式，实验结果显示该方法可以显著改善预测性能。 |
| [^45] | [Holdouts set for predictive model updating.](http://arxiv.org/abs/2202.06374) | 该论文研究了在复杂环境中如何更新预测风险评分来指导干预。作者提出使用留置集的方式进行更新，通过找到留置集的合适大小可以保证更新后的风险评分性能良好，同时减少留置样本数量。研究结果表明，该方法在总成本增长速度方面具有竞争优势。 |
| [^46] | [Last-Iterate Convergence of Saddle-Point Optimizers via High-Resolution Differential Equations.](http://arxiv.org/abs/2112.13826) | 本研究利用高分辨率微分方程在鞍点优化中设计了不同的微分方程模型，这些模型在双线性博弈中的收敛性质与离散方法相匹配。 |
| [^47] | [Spectral learning of multivariate extremes.](http://arxiv.org/abs/2111.07799) | 我们提出了一种用于分析多元极值的谱聚类算法，并通过理论和数值实验展示了其在学习角度测度方面的性能。 |
| [^48] | [Nonasymptotic theory for two-layer neural networks: Beyond the bias-variance trade-off.](http://arxiv.org/abs/2106.04795) | 这项研究提出了针对两层神经网络的非渐近泛化理论，通过引入缩放变分正则化，并利用"岭-套索对偶性"获得了新的预测界限，解释了大型神经网络在超参数化情况下的表现以及双谷现象。 |
| [^49] | [Modelling of functional profiles and explainable shape shifts detection: An approach combining the notion of the Fr\'echet mean with the shape invariant model}.](http://arxiv.org/abs/2010.02968) | 该论文提出了一种结合Fréchet均值和形状不变模型的方法，用于检测功能性轮廓中的形状变化，并构建了功能性数据的控制图，可解释性强且能识别潜在变化。 |
| [^50] | [Fair Algorithms for Hierarchical Agglomerative Clustering.](http://arxiv.org/abs/2005.03197) | 提出了一种公平的层次聚类算法，该算法不受距离链接准则的限制，能适应不同的公平度量标准，并可以处理多个受保护群体。 |
| [^51] | [Generalization Bounds and Representation Learning for Estimation of Potential Outcomes and Causal Effects.](http://arxiv.org/abs/2001.07426) | 本论文研究了从记录的背景、决策和结果中估计个体层面的因果效应的问题，给出了基于距离度量的广义化界限以及相应的样本重新加权方法，并设计了最小化界限的表示学习算法来实现估计的准确性。 |
| [^52] | [Recovery Guarantees for Quadratic Tensors with Sparse Observations.](http://arxiv.org/abs/1811.00148) | 本研究考察了稀疏观测下的二次张量恢复问题，发现非凸方法能够在线性样本数量下保证误差最小化问题的全局极小值，并改进了观测有限情况下的CP模型性能。 |
| [^53] | [Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network.](http://arxiv.org/abs/1808.03314) | 本文通过形式化推导来解释了递归神经网络（RNN）和长短期记忆（LSTM）网络的基本原理，并提出了一种将RNN转化为“Vanilla LSTM”网络的方法。 |

# 详细

[^1]: 时间序列预测的依从PID控制

    Conformal PID Control for Time Series Prediction. (arXiv:2307.16895v1 [cs.LG])

    [http://arxiv.org/abs/2307.16895](http://arxiv.org/abs/2307.16895)

    这项研究提出了一种在时间序列预测中应用的新的依从PID控制算法，能够量化不确定性并适应不同的系统误差，并在COVID-19死亡人数、电力需求和市场回报等方面取得了更好的预测结果。

    

    我们研究了时间序列预测的不确定性量化问题，目标是提供易于使用的算法并具备形式保证。我们提出的算法基于依从预测和控制理论的思想，能够在在线环境中前瞻性地建模依从得分，并适应由于季节性、趋势和总体分布变化而导致的系统误差。我们的理论简化并加强了在线依从预测中的现有分析。在美国州级COVID-19死亡人数的4周预测实验中，与官方CDC通信中使用的集成预测器相比，得到了更好的覆盖率。我们还对使用自回归、Theta、Prophet和Transformer模型进行电力需求、市场回报和温度预测的实验进行了运行。我们提供了一个可扩展的代码库，用于测试我们的方法并集成新的算法、数据集和预测规则。

    We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in official CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules.
    
[^2]: 使用深度神经网络和逻辑损失进行分类

    Classification with Deep Neural Networks and Logistic Loss. (arXiv:2307.16792v1 [stat.ML])

    [http://arxiv.org/abs/2307.16792](http://arxiv.org/abs/2307.16792)

    本文提出了一种新颖的oracle型不等式，通过解决逻辑损失的目标函数无界性限制，推导出使用逻辑损失训练的全连接ReLU深度神经网络分类器的最优收敛速率，仅要求数据的条件类概率具有H\"older平滑性，并且考虑了组合假设，使得该方法具有更广泛的适用性。

    

    使用逻辑损失（即交叉熵损失）训练的深度神经网络在各种二分类任务中取得了显著的进展。然而，关于使用深度神经网络和逻辑损失进行二分类的泛化分析仍然很少。逻辑损失的目标函数的无界性是导致推导出令人满意的泛化界限的主要障碍。本文旨在通过建立一种新颖而优雅的oracle型不等式来填补这一空白，该不等式使我们能够处理目标函数的有界性限制，并利用它推导出使用逻辑损失训练的全连接ReLU深度神经网络分类器的收敛速率。特别地，我们仅需要数据的条件类概率$\eta$的H\"older平滑性，就可以获得最优的收敛速率（仅限于对数因子）。此外，我们考虑了一个组合假设，要求$\eta$是若干向量值函数的复合函数，其中每个向量值函数都是独立的。

    Deep neural networks (DNNs) trained with the logistic loss (i.e., the cross entropy loss) have made impressive advancements in various binary classification tasks. However, generalization analysis for binary classification with DNNs and logistic loss remains scarce. The unboundedness of the target function for the logistic loss is the main obstacle to deriving satisfying generalization bounds. In this paper, we aim to fill this gap by establishing a novel and elegant oracle-type inequality, which enables us to deal with the boundedness restriction of the target function, and using it to derive sharp convergence rates for fully connected ReLU DNN classifiers trained with logistic loss. In particular, we obtain optimal convergence rates (up to log factors) only requiring the H\"older smoothness of the conditional class probability $\eta$ of data. Moreover, we consider a compositional assumption that requires $\eta$ to be the composition of several vector-valued functions of which each co
    
[^3]: 无损转换和统计推断中的过量风险界限研究

    Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v1 [cs.IT])

    [http://arxiv.org/abs/2307.16735](http://arxiv.org/abs/2307.16735)

    在统计推断中，我们研究了无损转换和过量风险的概念。我们提出了无损转换的特征，并构建了一个用于判断给定转换是否是无损的统计量。我们还引入了delta-无损转换的概念，并给出了充分条件。这些研究在分类、非参数回归和投资组合策略等领域具有应用价值。

    

    我们研究了统计推断中的过量最小风险，定义为从观测到的特征向量中估计随机变量的最小期望损失与从特征向量的转换（统计量）中估计相同随机变量的最小期望损失之间的差异。在描述了无损转换（即对于所有损失函数，过量风险为零的转换）之后，我们构建了一个对假设进行分区检验的统计量，用于判断给定转换是否为无损转换，并证明对于i.i.d.数据，该检验是强一致的。更一般地，我们根据信息理论给出了过量风险的上界，该上界在相当一般的损失函数类上都是一致的。基于这些界限，我们引入了“delta-无损转换”的概念，并给出了给定转换普遍是delta-无损的充分条件。该研究在分类、非参数回归、投资组合策略等方面具有应用价值。

    We study the excess minimum risk in statistical inference, defined as the difference between the minimum expected loss in estimating a random variable from an observed feature vector and the minimum expected loss in estimating the same random variable from a transformation (statistic) of the feature vector. After characterizing lossless transformations, i.e., transformations for which the excess risk is zero for all loss functions, we construct a partitioning test statistic for the hypothesis that a given transformation is lossless and show that for i.i.d. data the test is strongly consistent. More generally, we develop information-theoretic upper bounds on the excess risk that uniformly hold over fairly general classes of loss functions. Based on these bounds, we introduce the notion of a delta-lossless transformation and give sufficient conditions for a given transformation to be universally delta-lossless. Applications to classification, nonparametric regression, portfolio strategie
    
[^4]: 朴素贝叶斯分类器的高效Shapley Value计算

    An Efficient Shapley Value Computation for the Naive Bayes Classifier. (arXiv:2307.16718v1 [cs.LG])

    [http://arxiv.org/abs/2307.16718](http://arxiv.org/abs/2307.16718)

    这篇论文提出了在朴素贝叶斯分类器中计算Shapley值的新方法，并与Weight of Evidence和KernelShap进行了实证比较。

    

    变量选择或输入变量的重要性测量已经成为机器学习模型研究的重点。拥有一个好的模型已经不足够，还必须解释其决策。这就是为什么现在有很多可解释性算法。其中，Shapley值估计算法是一种基于合作博弈理论的可解释性方法。在朴素贝叶斯分类器的情况下，据我们所知，没有关于Shapley值的“分析性”公式。本文在朴素贝叶斯分类器的特殊情况下提出了Shapley值的精确分析表达式。我们对比了这个Shapley提议与另一个常用的指标，证据权重（Weight of Evidence，WoE），并在真实世界数据集上对我们的提议与WoE以及KernelShap的结果进行了实证比较，讨论了相似和不相似的结果。结果表明，我们对朴素贝叶斯分类器的Shapley提议提供了

    Variable selection or importance measurement of input variables to a machine learning model has become the focus of much research. It is no longer enough to have a good model, one also must explain its decisions. This is why there are so many intelligibility algorithms available today. Among them, Shapley value estimation algorithms are intelligibility methods based on cooperative game theory. In the case of the naive Bayes classifier, and to our knowledge, there is no ``analytical" formulation of Shapley values. This article proposes an exact analytic expression of Shapley values in the special case of the naive Bayes Classifier. We analytically compare this Shapley proposal, to another frequently used indicator, the Weight of Evidence (WoE) and provide an empirical comparison of our proposal with (i) the WoE and (ii) KernelShap results on real world datasets, discussing similar and dissimilar results. The results show that our Shapley proposal for the naive Bayes classifier provides 
    
[^5]: 神经网络贝叶斯推理中的数据变异性理论

    A theory of data variability in Neural Network Bayesian inference. (arXiv:2307.16695v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2307.16695](http://arxiv.org/abs/2307.16695)

    本文提出了一个泛化性的场论形式体系，用于研究神经网络在无限宽隐藏层的极限情况，并通过计算非线性和深度非线性网络的泛化特性，阐明了数据的变异性对网络行为的影响。

    

    贝叶斯推理和核方法在机器学习中已经得到了很好的应用。特别是神经网络高斯过程通过使用核和推理方法提供了一种研究神经网络在无限宽隐藏层的极限情况的概念。本文在这个极限的基础上建立了一个场论形式体系，涵盖了无限宽网络的泛化特性。我们系统地计算了具有异质条目的核矩阵的线性、非线性和深度非线性网络的泛化特性。与目前使用的谱方法相比，我们通过从输入数据的统计特性推导出泛化特性，阐明了输入维度、训练数据集的大小以及数据的变异性之间的相互作用。我们表明数据的变异性导致了一种非高斯作用，类似于($\varphi^3+\varphi^4$)-理论。在一个合成任务和MNIST上使用我们的形式体系，我们获得了一个均匀的核。

    Bayesian inference and kernel methods are well established in machine learning. The neural network Gaussian process in particular provides a concept to investigate neural networks in the limit of infinitely wide hidden layers by using kernel and inference methods. Here we build upon this limit and provide a field-theoretic formalism which covers the generalization properties of infinitely wide networks. We systematically compute generalization properties of linear, non-linear, and deep non-linear networks for kernel matrices with heterogeneous entries. In contrast to currently employed spectral methods we derive the generalization properties from the statistical properties of the input, elucidating the interplay of input dimensionality, size of the training data set, and variability of the data. We show that data variability leads to a non-Gaussian action reminiscent of a ($\varphi^3+\varphi^4$)-theory. Using our formalism on a synthetic task and on MNIST we obtain a homogeneous kernel
    
[^6]: 针对分割局部深度的连续和共享内存并行算法

    Sequential and Shared-Memory Parallel Algorithms for Partitioned Local Depths. (arXiv:2307.16652v1 [cs.DC])

    [http://arxiv.org/abs/2307.16652](http://arxiv.org/abs/2307.16652)

    本文设计了连续和共享内存并行算法用于分割局部深度，并引入了性能优化策略，实现了较高的加速。通过三元组比较两两距离，实现了对稠密和稀疏社区内强关系的识别。

    

    在这项工作中，我们设计、分析和优化了分割局部深度（PaLD）的连续和共享内存并行算法。给定一组数据点和两两距离，PaLD是一种基于相对距离识别两两关系强度的方法，能够在稠密和稀疏社区内识别强关系，即使它们的大小和社区内部绝对距离差别很大。我们设计了两种算法变体，通过三元组比较两两距离进行社区结构分析。我们对计算和通信成本进行了理论分析，并证明了连续算法在通信方面是最优的，最多只有常数因子。我们引入了性能优化策略，在基准连续实现上实现了高达29倍的连续加速和在多核Intel上使用高达32个线程的优化连续实现上实现了高达19.4倍的并行加速。

    In this work, we design, analyze, and optimize sequential and shared-memory parallel algorithms for partitioned local depths (PaLD). Given a set of data points and pairwise distances, PaLD is a method for identifying strength of pairwise relationships based on relative distances, enabling the identification of strong ties within dense and sparse communities even if their sizes and within-community absolute distances vary greatly. We design two algorithmic variants that perform community structure analysis through triplet comparisons of pairwise distances. We present theoretical analyses of computation and communication costs and prove that the sequential algorithms are communication optimal, up to constant factors. We introduce performance optimization strategies that yield sequential speedups of up to $29\times$ over a baseline sequential implementation and parallel speedups of up to $19.4\times$ over optimized sequential implementations using up to $32$ threads on an Intel multicore 
    
[^7]: 基于模型的因果贝叶斯优化

    Model-based Causal Bayesian Optimization. (arXiv:2307.16625v1 [cs.LG])

    [http://arxiv.org/abs/2307.16625](http://arxiv.org/abs/2307.16625)

    本文提出了一种基于模型的因果贝叶斯优化方法，通过考虑其他智能体或外部事件对系统的干预，使其能够适应非平稳性，同时引入了具有有界遗憾的对抗性因果贝叶斯优化算法CBO-MW。该方法结合了在线学习策略和因果建模，通过因果图传播不确定性来计算乐观的反事实奖励估计。

    

    在因果贝叶斯优化中，一个智能体对未知的结构因果模型进行干预，以最大化下游的奖励变量。本文考虑了其他智能体或外部事件也对系统进行干预的情况，这对于适应非平稳性，如天气变化、市场力量或对手的变化至关重要。我们将这种因果贝叶斯优化的泛化形式称为对抗性因果贝叶斯优化，并引入了第一个具有有界遗憾的对抗性因果贝叶斯优化算法：基于乘法权重的因果贝叶斯优化（CBO-MW）。我们的方法将经典的在线学习策略与奖励的因果建模相结合。为了实现这一点，它通过因果图传播不确定性来计算乐观的反事实奖励估计。我们推导了CBO-MW的遗憾界限，这些界限自然地取决于与图相关的量。我们还提出了一种可扩展的实现方法，适用于组合干预和子模块的情况。

    In Causal Bayesian Optimization (CBO), an agent intervenes on an unknown structural causal model to maximize a downstream reward variable. In this paper, we consider the generalization where other agents or external events also intervene on the system, which is key for enabling adaptiveness to non-stationarities such as weather changes, market forces, or adversaries. We formalize this generalization of CBO as Adversarial Causal Bayesian Optimization (ACBO) and introduce the first algorithm for ACBO with bounded regret: Causal Bayesian Optimization with Multiplicative Weights (CBO-MW). Our approach combines a classical online learning strategy with causal modeling of the rewards. To achieve this, it computes optimistic counterfactual reward estimates by propagating uncertainty through the causal graph. We derive regret bounds for CBO-MW that naturally depend on graph-related quantities. We further propose a scalable implementation for the case of combinatorial interventions and submodul
    
[^8]: 对多语言政党纲领进行分类: 跨国家、时间和体裁的领域转移

    Classifying multilingual party manifestos: Domain transfer across country, time, and genre. (arXiv:2307.16511v1 [cs.CL])

    [http://arxiv.org/abs/2307.16511](http://arxiv.org/abs/2307.16511)

    本研究探索了对多语言政党纲领进行分类的领域转移，在大规模政治纲领数据库中展示了微调Transformer模型在同一领域内的强大性能，并测试了其在不同地理位置、语言、时间和体裁之间的稳健性和可转移性。

    

    在实证社会科学研究中，标注大型语料库的成本仍然是主要的瓶颈之一。一方面，利用领域转移的能力可以重复使用标注数据集和训练模型。另一方面，领域转移的效果如何以及在不同维度之间的转移结果的可靠性还不清楚。我们在一个大型政治纲领数据库中探索了地理位置、语言、时间和体裁等领域转移的潜力。首先，我们展示了经过微调的Transformer模型在同一领域内的强大分类性能。其次，我们通过改变测试集的体裁来测试经过微调的模型在上述领域中的稳健性和可转移性。对于体裁切换，我们使用了一份来自新西兰政治家的录音演讲的外部语料库，而对于其他三个维度，我们使用了Manifesto数据库的自定义划分。虽然BERT取得了最好的得分，但我们还发现其它模型也具有很好的性能和可转移性。

    Annotating costs of large corpora are still one of the main bottlenecks in empirical social science research. On the one hand, making use of the capabilities of domain transfer allows re-using annotated data sets and trained models. On the other hand, it is not clear how well domain transfer works and how reliable the results are for transfer across different dimensions. We explore the potential of domain transfer across geographical locations, languages, time, and genre in a large-scale database of political manifestos. First, we show the strong within-domain classification performance of fine-tuned transformer models. Second, we vary the genre of the test set across the aforementioned dimensions to test for the fine-tuned models' robustness and transferability. For switching genres, we use an external corpus of transcribed speeches from New Zealand politicians while for the other three dimensions, custom splits of the Manifesto database are used. While BERT achieves the best scores i
    
[^9]: 不要那么消极！带有Oracle辅助指导的基于得分的生成建模方法

    Don't be so negative! Score-based Generative Modeling with Oracle-assisted Guidance. (arXiv:2307.16463v1 [cs.LG])

    [http://arxiv.org/abs/2307.16463](http://arxiv.org/abs/2307.16463)

    本文提出了一种基于得分的生成建模方法Gen-neG，它利用额外的辅助信息来指导生成过程。通过引导生成过程朝着正支持区域生成样本，该方法在自动驾驶模拟器中的避碰应用和安全防护人体动作生成中展现了实用性。

    

    最大似然原则提倡通过优化数据似然函数进行参数估计。以这种方式估计的模型可以展现出各种由架构、参数化和优化偏差等因素决定的泛化特性。本文解决了在存在额外辅助信息的情况下的模型学习问题，该辅助信息以Oracle的形式存在，可以标记样本是否处于真实数据生成分布的支持范围之外。具体而言，我们开发了一种新的去噪扩散概率建模（DDPM）方法，称为Gen-neG，它利用了这个额外的辅助信息。我们的方法基于生成对抗网络（GANs）和扩散模型中的鉴别器指导，以引导生成过程朝着Oracle所指示的正支持区域生成样本。我们通过在自动驾驶模拟器中的避碰应用和安全防护人体动作生成中的实证验证了Gen-neG的实用性。

    The maximum likelihood principle advocates parameter estimation via optimization of the data likelihood function. Models estimated in this way can exhibit a variety of generalization characteristics dictated by, e.g. architecture, parameterization, and optimization bias. This work addresses model learning in a setting where there further exists side-information in the form of an oracle that can label samples as being outside the support of the true data generating distribution. Specifically we develop a new denoising diffusion probabilistic modeling (DDPM) methodology, Gen-neG, that leverages this additional side-information. Our approach builds on generative adversarial networks (GANs) and discriminator guidance in diffusion models to guide the generation process towards the positive support region indicated by the oracle. We empirically establish the utility of Gen-neG in applications including collision avoidance in self-driving simulators and safety-guarded human motion generation.
    
[^10]: 一种连续结构干预距离用于比较因果图

    A continuous Structural Intervention Distance to compare Causal Graphs. (arXiv:2307.16452v1 [stat.ML])

    [http://arxiv.org/abs/2307.16452](http://arxiv.org/abs/2307.16452)

    这篇论文提出了一种新的连续测量度量，用于比较真实因果图与学习到的因果图之间的差异，并通过在再生核希尔伯特空间中嵌入干预分布来计算差异。数值实验证明了该方法的有效性。

    

    了解和充分评估真实因果图与学习到的因果图之间的差异对于干预因果推断至关重要。作为基于图结构的结构汉明距离和结构干预距离的扩展，我们提出了一种新颖的连续测量度量，它不仅考虑了底层数据，还考虑了因果图之间的差异计算。该距离基于将干预分布作为条件均值嵌入到再生核希尔伯特空间中的每对节点，并通过最大（条件）均值差异来估计它们的差异。我们通过在合成数据上进行数值实验证明了理论结果。

    Understanding and adequately assessing the difference between a true and a learnt causal graphs is crucial for causal inference under interventions. As an extension to the graph-based structural Hamming distance and structural intervention distance, we propose a novel continuous-measured metric that considers the underlying data in addition to the graph structure for its calculation of the difference between a true and a learnt causal graph. The distance is based on embedding intervention distributions over each pair of nodes as conditional mean embeddings into reproducing kernel Hilbert spaces and estimating their difference by the maximum (conditional) mean discrepancy. We show theoretical results which we validate with numerical experiments on synthetic data.
    
[^11]: 保证从经验分布中最大偏差的最佳生成建模

    Guaranteed Optimal Generative Modeling with Maximum Deviation from the Empirical Distribution. (arXiv:2307.16422v1 [math.ST])

    [http://arxiv.org/abs/2307.16422](http://arxiv.org/abs/2307.16422)

    本文提供了一种理论方法来训练生成模型，确保其在样本大小趋近无穷时与真实数据生成分布的误差收敛为零，并且远离复制训练数据中示例的任何分布。

    

    生成建模是一种广泛应用于科学和工业领域的机器学习方法。其主要目标是在给定训练数据的情况下，模拟从未知分布中抽取的新示例，同时确保多样性并避免从训练数据中复制示例。本文提出了关于训练生成模型的理论见解，该模型具有两个属性：（i）将真实数据生成分布与训练数据生成分布替换的误差在样本大小趋近无穷时应最佳收敛于零；（ii）训练数据生成分布应远离复制训练数据中示例的任何分布。我们提供了以有限样本风险界为形式的非渐近结果，量化了这些属性，并取决于相关参数，如样本大小、环境空间的维数和潜空间的维数。我们的结果适用于生成模型的各种应用情况。

    Generative modeling is a widely-used machine learning method with various applications in scientific and industrial fields. Its primary objective is to simulate new examples drawn from an unknown distribution given training data while ensuring diversity and avoiding replication of examples from the training data.  This paper presents theoretical insights into training a generative model with two properties: (i) the error of replacing the true data-generating distribution with the trained data-generating distribution should optimally converge to zero as the sample size approaches infinity, and (ii) the trained data-generating distribution should be far enough from any distribution replicating examples in the training data.  We provide non-asymptotic results in the form of finite sample risk bounds that quantify these properties and depend on relevant parameters such as sample size, the dimension of the ambient space, and the dimension of the latent space. Our results are applicable to g
    
[^12]: Wasserstein镜像梯度流作为Sinkhorn算法的极限

    Wasserstein Mirror Gradient Flow as the limit of the Sinkhorn Algorithm. (arXiv:2307.16421v1 [math.PR])

    [http://arxiv.org/abs/2307.16421](http://arxiv.org/abs/2307.16421)

    Sinkhorn算法和迭代比例拟合程序可以收敛到一个Wasserstein镜像梯度流，其中速度场的范数代表线性化最佳输运距离的度量导数。

    

    我们证明了Sinkhorn算法或迭代比例拟合程序（IPFP）得到的序列边缘在$\varepsilon$趋向于零且迭代次数按$1/\varepsilon$缩放时，会收敛到$2$-Wasserstein空间上的一个绝对连续曲线（在满足其他技术假设的情况下）。我们称这个极限为Sinkhorn流，它是Wasserstein镜像梯度流的一个例子，这个概念是我们在这里引入的，受到了众所周知的欧几里得镜像梯度流的启发。在Sinkhorn的情况下，梯度是相对熵泛函相对于其中一个边缘的梯度，而镜像则是相对于另一个边缘的平方Wasserstein距离泛函的一半。有趣的是，这个流的速度场的范数可以解释为相对于线性化最佳输运（LOT）距离的度量导数。对这个流的等价描述是...

    We prove that the sequence of marginals obtained from the iterations of the Sinkhorn algorithm or the iterative proportional fitting procedure (IPFP) on joint densities, converges to an absolutely continuous curve on the $2$-Wasserstein space, as the regularization parameter $\varepsilon$ goes to zero and the number of iterations is scaled as $1/\varepsilon$ (and other technical assumptions). This limit, which we call the Sinkhorn flow, is an example of a Wasserstein mirror gradient flow, a concept we introduce here inspired by the well-known Euclidean mirror gradient flows. In the case of Sinkhorn, the gradient is that of the relative entropy functional with respect to one of the marginals and the mirror is half of the squared Wasserstein distance functional from the other marginal. Interestingly, the norm of the velocity field of this flow can be interpreted as the metric derivative with respect to the linearized optimal transport (LOT) distance. An equivalent description of this flo
    
[^13]: RCS-YOLO: 一种快速且高准确性的脑肿瘤检测物体检测器

    RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection. (arXiv:2307.16412v1 [cs.CV])

    [http://arxiv.org/abs/2307.16412](http://arxiv.org/abs/2307.16412)

    RCS-YOLO是一种快速且高准确性的脑肿瘤检测物体检测器，通过引入Reparameterized Convolution和RCS-OSA技术，提高了YOLO框架在处理脑肿瘤检测中的性能，达到了最先进水平。

    

    随着速度和准确性之间的出色平衡，先进的YOLO框架已成为最高效的物体检测算法之一。然而，在脑肿瘤检测中，使用YOLO网络的性能很少受到研究。我们提出了一种基于Reparameterized Convolution的RCS-YOLO的新型YOLO架构。我们提出了RCS和RCS的一次性聚合(RCS-OSA)，它将特征级联和计算效率相结合，以提取更丰富的信息并减少时间消耗。在脑肿瘤数据集Br35H上的实验结果表明，所提出的模型在速度和准确性上超过了YOLOv6，YOLOv7和YOLOv8。值得注意的是，与YOLOv7相比，RCS-YOLO的精度提高了2.6％，推断速度提高了60％，达到每秒114.8张图像检测（FPS）。我们提出的RCS-YOLO在脑肿瘤检测任务上取得了最先进的性能。代码可在https://github.com/mkang315/RCS-YOLO获取。

    With an excellent balance between speed and accuracy, cutting-edge YOLO frameworks have become one of the most efficient algorithms for object detection. However, the performance of using YOLO networks is scarcely investigated in brain tumor detection. We propose a novel YOLO architecture with Reparameterized Convolution based on channel Shuffle (RCS-YOLO). We present RCS and a One-Shot Aggregation of RCS (RCS-OSA), which link feature cascade and computation efficiency to extract richer information and reduce time consumption. Experimental results on the brain tumor dataset Br35H show that the proposed model surpasses YOLOv6, YOLOv7, and YOLOv8 in speed and accuracy. Notably, compared with YOLOv7, the precision of RCS-YOLO improves by 2.6%, and the inference speed by 60% at 114.8 images detected per second (FPS). Our proposed RCS-YOLO achieves state-of-the-art performance on the brain tumor detection task. The code is available at https://github.com/mkang315/RCS-YOLO.
    
[^14]: Causal-learn: Python中的因果发现

    Causal-learn: Causal Discovery in Python. (arXiv:2307.16405v1 [cs.LG])

    [http://arxiv.org/abs/2307.16405](http://arxiv.org/abs/2307.16405)

    Causal-learn是一个Python库，提供了全面的因果发现方法，适用于从业者和研究人员。与其他语言开发的包不同，Causal-learn完全由Python开发。

    

    因果发现旨在从观测数据中揭示因果关系，这是科学和工程中的一项基础任务。我们描述了$\textit {causal-learn}$，一个用于因果发现的开源Python库。该库专注于为从业者和研究人员提供全面的因果发现方法。它为非专业人员提供易于使用的API，为开发人员提供模块化构建块，为学习者提供详细的文档，并提供全面的方法。与之前的R或Java包不同，$\textit {causal-learn}$完全由Python开发，这更符合相关社区在编程语言方面的最近偏好转变。该库可在https://github.com/py-why/causal-learn上获得。

    Causal discovery aims at revealing causal relations from observational data, which is a fundamental task in science and engineering. We describe $\textit{causal-learn}$, an open-source Python library for causal discovery. This library focuses on bringing a comprehensive collection of causal discovery methods to both practitioners and researchers. It provides easy-to-use APIs for non-specialists, modular building blocks for developers, detailed documentation for learners, and comprehensive methods for all. Different from previous packages in R or Java, $\textit{causal-learn}$ is fully developed in Python, which could be more in tune with the recent preference shift in programming languages within related communities. The library is available at https://github.com/py-why/causal-learn.
    
[^15]: 冰立方DeepCore中的二维卷积神经网络用于事件重建

    2D Convolutional Neural Network for Event Reconstruction in IceCube DeepCore. (arXiv:2307.16373v1 [astro-ph.HE])

    [http://arxiv.org/abs/2307.16373](http://arxiv.org/abs/2307.16373)

    冰立方DeepCore中的二维卷积神经网络用于事件重建，在GeV级能量下具有更好的成功率，对于味道识别和不弹性重建具有特别的重要意义。

    

    冰立方DeepCore是冰立方中微子观测站的扩展，旨在测量GeV级大气中微子相互作用以进行中微子振荡研究。由于仪器稀疏，冰立方DeepCore在GeV级能量下区分muon中微子和其他味道以及重建不弹性是特别困难的任务。卷积神经网络（CNN）在中微子事件重建方面比传统的基于似然的方法更成功。在这篇论文中，我们提出了一个新的CNN模型，利用了冰立方DeepCore数据中的时间和深度平移对称性，并针对味道识别和不弹性重建评估了该模型的性能。

    IceCube DeepCore is an extension of the IceCube Neutrino Observatory designed to measure GeV scale atmospheric neutrino interactions for the purpose of neutrino oscillation studies. Distinguishing muon neutrinos from other flavors and reconstructing inelasticity are especially difficult tasks at GeV scale energies in IceCube DeepCore due to sparse instrumentation. Convolutional neural networks (CNNs) have been found to have better success at neutrino event reconstruction than conventional likelihood-based methods. In this contribution, we present a new CNN model that exploits time and depth translational symmetry in IceCube DeepCore data and present the model's performance, specifically for flavor identification and inelasticity reconstruction.
    
[^16]: 概率鲁棒性的符合性预测

    Probabilistically robust conformal prediction. (arXiv:2307.16360v1 [cs.LG])

    [http://arxiv.org/abs/2307.16360](http://arxiv.org/abs/2307.16360)

    本文研究了概率鲁棒性的符合性预测（PRCP）问题，通过提出aPRCP算法，实现了对干净输入示例的大多数扰动具有鲁棒性的预测。

    

    符合性预测（CP）是一种量化机器学习分类器不确定性的框架，包括深度神经网络。给定一个测试示例和一个训练好的分类器，CP会产生一个预测集，其中包含了候选标签，并且具有用户指定的覆盖率（即真实类标签以很高的概率包含在内）。几乎所有现有关于CP的工作都假设测试数据是干净的，并且对于与测试示例的自然/敌对扰动对CP算法的鲁棒性没有太多了解。本文研究了概率鲁棒性的符合性预测（PRCP）问题，它确保对干净输入示例的大多数扰动具有鲁棒性。PRCP推广了标准CP（无法处理扰动）和对抗鲁棒CP（确保针对最坏情况的扰动具有鲁棒性）之间的更好平衡nominal性能和鲁棒性。我们提出了一种新颖的自适应PRCP（aPRCP）算法来实现概率鲁棒的覆盖。

    Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness. We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea be
    
[^17]: 面向线性回归的实用鲁棒性审计

    Towards Practical Robustness Auditing for Linear Regression. (arXiv:2307.16315v1 [stat.ME])

    [http://arxiv.org/abs/2307.16315](http://arxiv.org/abs/2307.16315)

    本论文研究了实用的算法，用于查找或证伪数据集中对普通最小二乘回归具有影响的小子集。通过实证研究发现，这些算法方法在鲁棒性检查中表现良好，并提供了对低维回归问题的有用检查。但对于高维回归问题，计算瓶颈仍然存在。通过使用新颖的谱算法，我们取得了一些进展。

    

    我们研究了实用的算法，用于找到或证伪一个数据集中的小子集，当移除这些子集时，会改变普通最小二乘回归中的系数的符号。我们通过实证研究了用于此任务的先进算法技术的性能 - 混合整数二次约束优化用于一般线性回归问题，以及对特殊情况的确切贪婪方法。我们证明这些方法在很大程度上胜过了现有技术，并且为低维回归问题提供了有用的鲁棒性检查。然而，对于维度为3或更高的回归问题，仍然存在重要的计算瓶颈，特别是对于证伪这种小而具影响力的样本集合的存在。通过使用最近算法鲁棒统计领域创新的思想，我们在这一挑战上取得了一些进展，利用谱算法。我们总结了已知技术的局限性。

    We investigate practical algorithms to find or disprove the existence of small subsets of a dataset which, when removed, reverse the sign of a coefficient in an ordinary least squares regression involving that dataset. We empirically study the performance of well-established algorithmic techniques for this task -- mixed integer quadratically constrained optimization for general linear regression problems and exact greedy methods for special cases. We show that these methods largely outperform the state of the art and provide a useful robustness check for regression problems in a few dimensions. However, significant computational bottlenecks remain, especially for the important task of disproving the existence of such small sets of influential samples for regression problems of dimension $3$ or greater. We make some headway on this challenge via a spectral algorithm using ideas drawn from recent innovations in algorithmic robust statistics. We summarize the limitations of known techniqu
    
[^18]: 在RKHS中自适应学习密度比率

    Adaptive learning of density ratios in RKHS. (arXiv:2307.16164v1 [cs.LG])

    [http://arxiv.org/abs/2307.16164](http://arxiv.org/abs/2307.16164)

    该论文研究在再生核希尔伯特空间中的一类密度比率估计方法，提出了一种自适应学习的参数选择原则，并在有限样本情况下推导出新的误差界。其方法在二次损失的情况下实现了极小化最优误差率。

    

    从有限数量的密度观测中估计两个概率密度的比率是机器学习和统计学中的一个核心问题，应用包括双样本检验、分歧估计、生成建模、协变量转移适应、条件密度估计和新颖性检测。本研究分析了一大类密度比率估计方法，它们通过在再生核希尔伯特空间（RKHS）中最小化真实密度比率与模型之间的正则Bregman距离。我们推导出新的有限样本误差界，并提出了一种Lepskii类型的参数选择原则，在不知道密度比率的正则性的情况下最小化误差界。在二次损失的特殊情况下，我们的方法自适应地实现了极小化最优误差率。提供了一个数值示例。

    Estimating the ratio of two probability densities from finitely many observations of the densities is a central problem in machine learning and statistics with applications in two-sample testing, divergence estimation, generative modeling, covariate shift adaptation, conditional density estimation, and novelty detection. In this work, we analyze a large class of density ratio estimation methods that minimize a regularized Bregman divergence between the true density ratio and a model in a reproducing kernel Hilbert space (RKHS). We derive new finite-sample error bounds, and we propose a Lepskii type parameter choice principle that minimizes the bounds without knowledge of the regularity of the density ratio. In the special case of quadratic loss, our method adaptively achieves a minimax optimal error rate. A numerical illustration is provided.
    
[^19]: 关于神经网络近似理想对抗攻击和对抗训练收敛性的论文翻译

    On Neural Network approximation of ideal adversarial attack and convergence of adversarial training. (arXiv:2307.16099v1 [cs.LG])

    [http://arxiv.org/abs/2307.16099](http://arxiv.org/abs/2307.16099)

    这项研究通过使用神经网络对理想的对抗攻击进行近似表示，并将对抗训练转化为进攻网络和防守网络之间的数学博弈，同时给出了对抗训练在样本大小$n$下的收敛速度。

    

    对抗攻击通常是通过对输入数据和模型进行基于梯度的操作来实现的，这导致每次生成攻击时都需要进行大量的计算。在这项工作中，我们将对抗攻击表示为可训练的函数的思想更加巩固，而无需进一步计算梯度。我们首先激发出在适当条件下，理论上的最佳攻击可以表示为光滑的分段函数（分段H\"older函数）。然后我们通过神经网络得到了这些函数的近似结果。随后，我们通过神经网络模拟理想的攻击过程，并将对抗训练化简为进攻网络和防守模型（防守网络）之间的数学博弈。在这样的设置中，我们还得到了对抗训练的样本大小$n$对于对抗损失的收敛速度。

    Adversarial attacks are usually expressed in terms of a gradient-based operation on the input data and model, this results in heavy computations every time an attack is generated. In this work, we solidify the idea of representing adversarial attacks as a trainable function, without further gradient computation. We first motivate that the theoretical best attacks, under proper conditions, can be represented as smooth piece-wise functions (piece-wise H\"older functions). Then we obtain an approximation result of such functions by a neural network. Subsequently, we emulate the ideal attack process by a neural network and reduce the adversarial training to a mathematical game between an attack network and a training model (a defense network). We also obtain convergence rates of adversarial loss in terms of the sample size $n$ for adversarial training in such a setting.
    
[^20]: 局部因果发现中的结构限制: 识别目标变量的直接原因

    Structural restrictions in local causal discovery: identifying direct causes of a target variable. (arXiv:2307.16048v1 [stat.ME])

    [http://arxiv.org/abs/2307.16048](http://arxiv.org/abs/2307.16048)

    这项研究的目标是从观测数据中识别目标变量的直接原因，通过不对其他变量做太多假设，研究者提出了可识别性结果和两种实用算法。

    

    我们考虑从观察联合分布中学习目标变量的一组直接原因的问题。学习表示因果结构的有向无环图(DAG)是科学中的一个基本问题。当完整的DAG从分布中可识别时，已知有一些结果，例如假设非线性高斯数据生成过程。通常，我们只对识别一个目标变量的直接原因（局部因果结构），而不是完整的DAG感兴趣。在本文中，我们讨论了对目标变量的数据生成过程的不同假设，该假设下直接原因集合可以从分布中识别出来。在这样做的过程中，我们对除目标变量之外的变量基本上没有任何假设。除了新的可识别性结果，我们还提供了两种从有限随机样本估计直接原因的实用算法，并在几个基准数据集上证明了它们的有效性。

    We consider the problem of learning a set of direct causes of a target variable from an observational joint distribution. Learning directed acyclic graphs (DAGs) that represent the causal structure is a fundamental problem in science. Several results are known when the full DAG is identifiable from the distribution, such as assuming a nonlinear Gaussian data-generating process. Often, we are only interested in identifying the direct causes of one target variable (local causal structure), not the full DAG. In this paper, we discuss different assumptions for the data-generating process of the target variable under which the set of direct causes is identifiable from the distribution. While doing so, we put essentially no assumptions on the variables other than the target variable. In addition to the novel identifiability results, we provide two practical algorithms for estimating the direct causes from a finite random sample and demonstrate their effectiveness on several benchmark dataset
    
[^21]: 基于神经分类器的蒙特卡洛模拟

    Neural Classifiers based Monte Carlo simulation. (arXiv:2307.16035v1 [stat.ME])

    [http://arxiv.org/abs/2307.16035](http://arxiv.org/abs/2307.16035)

    该论文介绍了一种基于神经分类器的蒙特卡洛模拟算法，可以通过标记训练数据集来近似计算概率密度函数的比率。

    

    接受-拒绝(AR)，独立Metropolis Hastings（IMH）或重要性抽样（IS）蒙特卡洛（MC）模拟算法都涉及计算概率密度函数（pdf）的比率。另一方面，分类器可以区分混合密度模型产生的标记样本，即两个pdf的凸线性组合，并且可以用于近似这两个密度的比率。这个模拟和分类技术之间的桥梁使我们能够提出仅基于标记训练数据集构建的（近似）pdf比率的模拟算法。

    Acceptance-rejection (AR), Independent Metropolis Hastings (IMH) or importance sampling (IS) Monte Carlo (MC) simulation algorithms all involve computing ratios of probability density functions (pdfs). On the other hand, classifiers discriminate labellized samples produced by a mixture density model, i.e., a convex linear combination of two pdfs, and can thus be used for approximating the ratio of these two densities. This bridge between simulation and classification techniques enables us to propose (approximate) pdf-ratios-based simulation algorithms which are built only from a labellized training data set.
    
[^22]: 语言模型中复杂技能产生的理论

    A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v1 [cs.LG])

    [http://arxiv.org/abs/2307.15936](http://arxiv.org/abs/2307.15936)

    本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。

    

    当语言模型的参数集合和训练语料库扩大时，新的技能将在 AI 产品中出现的主要驱动因素。这种现象尚不为人所理解，并且通过对基于梯度训练的数学分析提供机械解释似乎很困难。本文采用不同的方法，使用著名的（和经验性的）LLM扩展定律和简单的统计框架来分析出现。贡献包括：（a）一个统计框架将LLM的交叉熵损失与语言任务基本技能的能力相关联。（b）数学分析表明，扩展定律意味着强烈的归纳偏见，使预训练模型能够学习得非常高效。我们非正式地称之为“弹弓泛化”，因为表面上看，它似乎提供了在技能水平上违反通常泛化理论的能力。（c）弹弓泛化的一个关键例子，即在执行任务时的能力。

    A major driver of AI products today is the fact that new skills emerge in language models when their parameter set and training corpora are scaled up. This phenomenon is poorly understood, and a mechanistic explanation via mathematical analysis of gradient-based training seems difficult. The current paper takes a different approach, analysing emergence using the famous (and empirical) Scaling Laws of LLMs and a simple statistical framework. Contributions include: (a) A statistical framework that relates cross-entropy loss of LLMs to competence on the basic skills that underlie language tasks. (b) Mathematical analysis showing that the Scaling Laws imply a strong form of inductive bias that allows the pre-trained model to learn very efficiently. We informally call this {\em slingshot generalization} since naively viewed it appears to give competence levels at skills that violate usual generalization theory. (c) A key example of slingshot generalization, that competence at executing task
    
[^23]: 使用项目反应理论对综合算法组合进行评估

    Comprehensive Algorithm Portfolio Evaluation using Item Response Theory. (arXiv:2307.15850v1 [stat.ML])

    [http://arxiv.org/abs/2307.15850](http://arxiv.org/abs/2307.15850)

    本文提出了一种改进的基于IRT的框架，用于评估算法组合在数据集仓库中的性能，同时获取算法一致性和异常性等特征。该框架通过对传统IRT模型进行倒转和重新解释来实现，不需要额外的数据集特征计算。

    

    项目反应理论（IRT）被提出用于教育心理测量学领域，用于评估学生能力、测试题难度和区分度。最近，IRT已被应用于评估单个分类数据集上的机器学习算法性能，其中学生现在是一个算法，而测试题是算法要对观察结果进行分类。本文提出了一种改进的基于IRT的框架，用于评估一个算法组合在一个数据集仓库中的表现，同时获取算法一致性和异常性等更丰富的特征，这些特征描述了算法性能的重要方面。这些特征是通过对传统IRT模型进行新颖的倒转和重新解释而得到的，而不需要额外的数据集特征计算。我们对不同应用的算法组合在该框架上进行了测试，证明了其广泛适用性。

    Item Response Theory (IRT) has been proposed within the field of Educational Psychometrics to assess student ability as well as test question difficulty and discrimination power. More recently, IRT has been applied to evaluate machine learning algorithm performance on a single classification dataset, where the student is now an algorithm, and the test question is an observation to be classified by the algorithm. In this paper we present a modified IRT-based framework for evaluating a portfolio of algorithms across a repository of datasets, while simultaneously eliciting a richer suite of characteristics such as algorithm consistency and anomalousness - that describe important aspects of algorithm performance. These characteristics arise from a novel inversion and reinterpretation of the traditional IRT model without requiring additional dataset feature computations. We test this framework on algorithm portfolios for a wide range of applications, demonstrating the broad applicability 
    
[^24]: 在数据异质性中保持用户级隐私的均值估计

    Mean Estimation with User-level Privacy under Data Heterogeneity. (arXiv:2307.15835v1 [cs.CR])

    [http://arxiv.org/abs/2307.15835](http://arxiv.org/abs/2307.15835)

    本文提出了一种在数据异质性中保持用户级隐私的均值估计方法，允许用户数据在分布和数量上的差异，并证明了估计器的渐近最优性和可达到的误差下界。

    

    当前许多现代数据分析任务面临的一个关键挑战是用户数据的异质性。不同的用户可能拥有截然不同数量的数据点。更重要的是，不能假设所有用户从相同的底层分布中进行采样。例如，在语言数据中，不同的语音风格导致了数据的异质性。在这项工作中，我们提出了一个简单的异质用户数据模型，允许用户数据在分布和数量上的差异，并提供了一种在保持用户级差分隐私的同时估计人口均值的方法。我们证明了我们的估计器的渐近最优性，并证明了在我们引入的设置中可以达到的误差的一般下界。

    A key challenge in many modern data analysis tasks is that user data are heterogeneous. Different users may possess vastly different numbers of data points. More importantly, it cannot be assumed that all users sample from the same underlying distribution. This is true, for example in language data, where different speech styles result in data heterogeneity. In this work we propose a simple model of heterogeneous user data that allows user data to differ in both distribution and quantity of data, and provide a method for estimating the population-level mean while preserving user-level differential privacy. We demonstrate asymptotic optimality of our estimator and also prove general lower bounds on the error achievable in the setting we introduce.
    
[^25]: 非参数假设检验对分配群对称性的研究

    Non-parametric Hypothesis Tests for Distributional Group Symmetry. (arXiv:2307.15834v1 [stat.ME])

    [http://arxiv.org/abs/2307.15834](http://arxiv.org/abs/2307.15834)

    该论文提出了用于分布对称性的非参数假设检验方法，适用于具有对称性的数据集。具体而言，该方法在紧致群作用下测试边际或联合分布的不变性，并提出了一种易于实施的条件蒙特卡罗检验。

    

    对称性在科学、机器学习和统计学中起着重要的作用。对于已知遵循对称性的数据，已经开发出了许多利用对称性的方法。然而，对于普遍群对称性的存在或不存在的统计检验几乎不存在。本研究提出了一种非参数假设检验方法，基于单个独立同分布样本，用于针对特定群的分布对称性。我们提供了适用于两种广泛情况的对称性检验的一般公式。第一种情况是测试在紧致群作用下的边际或联合分布的不变性。在这里，一个渐近无偏的检验只需要一个可计算的概率分布空间上的度量和能够均匀随机采样群元素的能力。在此基础上，我们提出了一种易于实施的条件蒙特卡罗检验，并证明它可以实现精确的p值。

    Symmetry plays a central role in the sciences, machine learning, and statistics. For situations in which data are known to obey a symmetry, a multitude of methods that exploit symmetry have been developed. Statistical tests for the presence or absence of general group symmetry, however, are largely non-existent. This work formulates non-parametric hypothesis tests, based on a single independent and identically distributed sample, for distributional symmetry under a specified group. We provide a general formulation of tests for symmetry that apply to two broad settings. The first setting tests for the invariance of a marginal or joint distribution under the action of a compact group. Here, an asymptotically unbiased test only requires a computable metric on the space of probability distributions and the ability to sample uniformly random group elements. Building on this, we propose an easy-to-implement conditional Monte Carlo test and prove that it achieves exact $p$-values with finitel
    
[^26]: 寻求收益壁垒：通过最优流形进行高维SRAM评估

    Seeking the Yield Barrier: High-Dimensional SRAM Evaluation Through Optimal Manifold. (arXiv:2307.15773v1 [cs.LG])

    [http://arxiv.org/abs/2307.15773](http://arxiv.org/abs/2307.15773)

    本研究通过最优流形概念将替代模型和重要性采样方法联系起来，提出了一种新型的高维SRAM评估方法。该方法名为OPTIMIS，结合了神经耦合流和洋葱采样，在保持性能优势的同时具备鲁棒性和一致性。

    

    随着模型电路将规模缩小到亚微米级别的先进技术节点，有效获得SRAM组件故障概率的准确估计已成为一个核心问题。在本研究中，我们重新审视了经典的范数最小化方法，并推广了它以适用于无限组件，并提出了新颖的最优流形概念，将基于替代模型和重要性采样（IS）的产量估计方法联系起来。接着，我们推导出了一个次优流形，最优超球体，它引导了一种高效的采样方法，能够识别到故障边界，称为洋葱采样。最后，我们使用神经耦合流作为重要性采样的提议分布，该分布类似于替代模型从样本中学习。这些组合产生了一种名为"优化流形重要性采样"（OPTIMIS）的新型产量估计方法，它保持了替代模型和重要性采样方法的优点，具有强韧性和稳定性。

    Being able to efficiently obtain an accurate estimate of the failure probability of SRAM components has become a central issue as model circuits shrink their scale to submicrometer with advanced technology nodes. In this work, we revisit the classic norm minimization method. We then generalize it with infinite components and derive the novel optimal manifold concept, which bridges the surrogate-based and importance sampling (IS) yield estimation methods. We then derive a sub-optimal manifold, optimal hypersphere, which leads to an efficient sampling method being aware of the failure boundary called onion sampling. Finally, we use a neural coupling flow (which learns from samples like a surrogate model) as the IS proposal distribution. These combinations give rise to a novel yield estimation method, named Optimal Manifold Important Sampling (OPTIMIS), which keeps the advantages of the surrogate and IS methods to deliver state-of-the-art performance with robustness and consistency, with 
    
[^27]: 加权变差空间与浅层ReLU网络的逼近

    Weighted variation spaces and approximation by shallow ReLU networks. (arXiv:2307.15772v1 [stat.ML])

    [http://arxiv.org/abs/2307.15772](http://arxiv.org/abs/2307.15772)

    本文研究了在有界域上通过单隐藏层ReLU网络逼近函数的问题，介绍了新的模型类定义加权变差空间，该定义与域本身相关。

    

    本文研究了在有界域Ω⊂Rd上，通过宽度为n的单隐藏层ReLU神经网络的输出来逼近函数f的情况。这种非线性的n项字典逼近已经得到广泛研究，因为它是神经网络逼近(NNA)的最简单情况。对于这种NNA形式，有几个著名的逼近结果，引入了在Ω上的函数的新型模型类，其逼近速率避免了维数灾难。这些新型模型类包括Barron类和基于稀疏性或变差的类，例如Radon域BV类。本文关注于在域Ω上定义这些新型模型类。当前这些模型类的定义不依赖于域Ω。通过引入加权变差空间的概念，给出了关于域的更恰当的模型类定义。这些新型模型类与域本身相关。

    We investigate the approximation of functions $f$ on a bounded domain $\Omega\subset \mathbb{R}^d$ by the outputs of single-hidden-layer ReLU neural networks of width $n$. This form of nonlinear $n$-term dictionary approximation has been intensely studied since it is the simplest case of neural network approximation (NNA). There are several celebrated approximation results for this form of NNA that introduce novel model classes of functions on $\Omega$ whose approximation rates avoid the curse of dimensionality. These novel classes include Barron classes, and classes based on sparsity or variation such as the Radon-domain BV classes.  The present paper is concerned with the definition of these novel model classes on domains $\Omega$. The current definition of these model classes does not depend on the domain $\Omega$. A new and more proper definition of model classes on domains is given by introducing the concept of weighted variation spaces. These new model classes are intrinsic to th
    
[^28]: 模仿复杂轨迹：桥接低层稳定性与高层行为

    Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])

    [http://arxiv.org/abs/2307.14619](http://arxiv.org/abs/2307.14619)

    本文提出了一个理论框架，研究了在非线性动态系统中模仿复杂专家演示的行为。通过稳定模仿策略并确保准确估计演示者分布，可以使模仿者与演示者的轨迹分布相近。

    

    我们提出了一个理论框架来研究在非线性动态系统中模仿随机、非马尔可夫、潜在多模态（即“复杂”）专家演示的行为。我们的框架使用低层控制器（无论是学习的还是隐含的）来稳定围绕专家演示的模仿策略。我们证明，在（a）合适的低层稳定性保证和（b）学习策略的随机连续性属性（我们称之为“总变差连续性”）（TVC）的情况下，一个精确估计演示者状态分布上的行动的模仿者会与演示者对整个轨迹的分布相近。然后，我们证明可以通过将流行的数据增强规则与一种新颖的算法技巧相结合（即在执行时添加增强噪声）来确保TVC并且最小程度上降低精度。我们将我们的保证实例化为由扩散模型参数化的策略，并证明如果学习者准确地估计了演示者的分布，则最终完成这种实例化。

    We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call "total variation continuity" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accuratel
    
[^29]: 基于模拟的推理用于心血管模型

    Simulation-based Inference for Cardiovascular Models. (arXiv:2307.13918v1 [stat.ML])

    [http://arxiv.org/abs/2307.13918](http://arxiv.org/abs/2307.13918)

    本研究将心血管模型的逆问题作为统计推理进行解决，在体外进行了五个生物标记物的不确定性分析，展示了模拟推理的能力。

    

    在过去的几十年中，血流动力学模拟器不断发展，已成为研究体外心血管系统的首选工具。虽然这样的工具通常用于从生理参数模拟全身血流动力学，但解决将波形映射回合理的生理参数的逆问题仍然有很大的潜力和挑战。受模拟推理（SBI）的进展的启发，我们将这个逆问题作为统计推理来处理。与其他方法不同，SBI为感兴趣的参数提供了后验分布，提供了关于个体测量的不确定性的多维表示。我们通过对比几种测量模态来展示这种能力，进行了五个临床感兴趣的生物标志物的体外不确定性分析。除了确认已知事实，比如估计心率的可行性，我们的研究还突出了…

    Over the past decades, hemodynamics simulators have steadily evolved and have become tools of choice for studying cardiovascular systems in-silico. While such tools are routinely used to simulate whole-body hemodynamics from physiological parameters, solving the corresponding inverse problem of mapping waveforms back to plausible physiological parameters remains both promising and challenging. Motivated by advances in simulation-based inference (SBI), we cast this inverse problem as statistical inference. In contrast to alternative approaches, SBI provides \textit{posterior distributions} for the parameters of interest, providing a \textit{multi-dimensional} representation of uncertainty for \textit{individual} measurements. We showcase this ability by performing an in-silico uncertainty analysis of five biomarkers of clinical interest comparing several measurement modalities. Beyond the corroboration of known facts, such as the feasibility of estimating heart rate, our study highlight
    
[^30]: 解决组合分布偏移问题：基于矩阵补全的观点

    Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])

    [http://arxiv.org/abs/2307.06457](http://arxiv.org/abs/2307.06457)

    该论文研究了组合分布偏移的问题，提出了基于矩阵补全的解决方法。通过在特殊情况下的双线性嵌入，实现对训练中未涵盖的测试分布进行外推。这个设置将缺失非随机数据的矩阵补全问题广义化。

    

    在分布偏移下获得严格的统计保证仍然是一个开放且活跃的研究领域。我们研究了一种称为组合分布偏移的设置，其中(a)在测试和训练分布下，标签$z$由特征$(x,y)$的对决定，(b)训练分布涵盖了$x$和$y$分别的一定边缘分布，但是(c)测试分布涉及了一个在训练分布中未涵盖的$(x,y)$的产品分布的示例。我们专注于标签由双线性嵌入到Hilbert空间$H$中给出的特殊情况：$\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$，我们的目标是对在训练中未涵盖的测试分布域进行外推，即实现双线性组合外推。我们的设置将缺失非随机数据的矩阵补全的一个特殊情况广义化，对于该情况，所有现有结果都要求....

    Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call combinatorial distribution shift, where (a) under the test- and training-distributions, the labels $z$ are determined by pairs of features $(x,y)$, (b) the training distribution has coverage of certain marginal distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is {not} covered by the training distribution. Focusing on the special case where the labels are given by bilinear embeddings into a Hilbert space $H$: $\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$, we aim to extrapolate to a test distribution domain that is $not$ covered in training, i.e., achieving bilinear combinatorial extrapolation.  Our setting generalizes a special case of matrix completion from missing-not-at-random data, for which all existing results requi
    
[^31]: 解读疾病进展聚类中的深度嵌入

    Interpreting deep embeddings for disease progression clustering. (arXiv:2307.06060v1 [stat.ML])

    [http://arxiv.org/abs/2307.06060](http://arxiv.org/abs/2307.06060)

    本文提出了一种在疾病进展聚类中解读深度嵌入的新方法，并通过评估2型糖尿病参与者数据集展示了对疾病进展模式的临床意义性见解。

    

    我们提出了一种在患者聚类的背景下解读深度嵌入的新方法。我们在来自英国生物库的2型糖尿病参与者数据集上评估我们的方法，并展示出对疾病进展模式的临床意义性见解。

    We propose a novel approach for interpreting deep embeddings in the context of patient clustering. We evaluate our approach on a dataset of participants with type 2 diabetes from the UK Biobank, and demonstrate clinically meaningful insights into disease progression patterns.
    
[^32]: 深度神经网络如何学习组合性数据：随机层次模型

    How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model. (arXiv:2307.02129v1 [cs.LG])

    [http://arxiv.org/abs/2307.02129](http://arxiv.org/abs/2307.02129)

    本文研究了深度神经网络学习组合性数据的问题，通过对随机层次模型进行分类任务，发现深度CNN学习这个任务所需的训练数据数量随着类别数、组合数和迭代次数的增加而渐进增加。

    

    学习一般高维任务是非常困难的，因为它需要与维度成指数增长的训练数据数量。然而，深度卷积神经网络（CNN）在克服这一挑战方面显示出了卓越的成功。一种普遍的假设是可学习任务具有高度结构化，CNN利用这种结构建立了数据的低维表示。然而，我们对它们需要多少训练数据以及这个数字如何取决于数据结构知之甚少。本文回答了针对一个简单的分类任务的这个问题，该任务旨在捕捉真实数据的相关方面：随机层次模型。在这个模型中，$n_c$个类别中的每一个对应于$m$个同义组合的高层次特征，并且这些特征又通过一个重复$L$次的迭代过程由子特征组成。我们发现，需要深度CNN学习这个任务的训练数据数量$P^*$（i）随着$n_c m^L$的增长而渐进地增长，这只有...

    Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension. Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge. A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data. However, little is known about how much training data they require, and how this number depends on the data structure. This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model. In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times. We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only
    
[^33]: 利用草图技术估计Koopman算子并可靠地学习大规模动态系统

    Estimating Koopman operators with sketching to provably learn large scale dynamical systems. (arXiv:2306.04520v1 [stat.ML])

    [http://arxiv.org/abs/2306.04520](http://arxiv.org/abs/2306.04520)

    本文提出利用随机投影技术优化了Koopman算子的估计器，加快了计算速度，并给出了精确的误差界限，提高了算法的可靠性。

    

    Koopman算子理论允许使用非参数机器学习算法来预测和分析复杂的动态系统。本文提出利用随机投影（草图技术）提高基于核的Koopman算子估计器的计算效率。我们在合成和大规模分子动力学数据集上进行了广泛实验，并建立了非渐进误差界，给出了统计学习速率和计算效率之间的权衡的精确刻画。我们的经验和理论分析表明，经过改进的估计器在保证准确性的同时大大提高了计算效率。

    The theory of Koopman operators allows to deploy non-parametric machine learning algorithms to predict and analyze complex dynamical systems. Estimators such as principal component regression (PCR) or reduced rank regression (RRR) in kernel spaces can be shown to provably learn Koopman operators from finite empirical observations of the system's time evolution. Scaling these approaches to very long trajectories is a challenge and requires introducing suitable approximations to make computations feasible. In this paper, we boost the efficiency of different kernel-based Koopman operator estimators using random projections (sketching). We derive, implement and test the new "sketched" estimators with extensive experiments on synthetic and large-scale molecular dynamics datasets. Further, we establish non asymptotic error bounds giving a sharp characterization of the trade-offs between statistical learning rates and computational efficiency. Our empirical and theoretical analysis shows that
    
[^34]: 在缺少球形替代方案下测试离散分布直方图均匀性的极小极大风险

    The minimax risk in testing the histogram of discrete distributions for uniformity under missing ball alternatives. (arXiv:2305.18111v1 [math.ST])

    [http://arxiv.org/abs/2305.18111](http://arxiv.org/abs/2305.18111)

    研究了离散分布样本对于类别间的均匀分布拟合问题下的极小极大风险，在缺少球形替代方案的情况下进行了讨论，通过离散直方图进行检验，获得了一种具有精确刻画的检验方法，并在实证研究中表现出了显著性。

    

    我们考虑测试一个来自许多类别的离散样本对于类别间的均匀分布拟合的问题。作为另一类替代假设，我们考虑去除半径为$\epsilon$的$\ell_p$球形替代方案，其中$p\leq 2$。我们给出了基于直方图（缺失类别、单例、碰撞的数量）的检验在样本数和维数趋向无穷大，$\epsilon\to0$时，渐进极小极大风险的一个精确刻画。例如，当$p=1$且期望样本数$n$与类别数$N$的比值很小（也称为“次线性”区域）时，渐进极小极大风险$R^*_\epsilon$趋近于$2\bar{\Phi}\left(n\epsilon^2/\sqrt{8N}\right)$，其中$\bar{\Phi}(x)$是正态残存函数。在一系列问题参数范围内的实证研究表明，这个估计在有限样本中很精确，并且我们的检验显著。

    We consider the problem of testing the fit of a discrete sample of items from many categories to the uniform distribution over the categories. As a class of alternative hypotheses, we consider the removal of an $\ell_p$ ball of radius $\epsilon$ around the uniform rate sequence for $p \leq 2$. We deliver a sharp characterization of the asymptotic minimax risk when $\epsilon \to 0$ as the number of samples and number of dimensions go to infinity, for testing based on the occurrences' histogram (number of absent categories, singletons, collisions, ...). For example, for $p=1$ and in the limit of a small expected number of samples $n$ compared to the number of categories $N$ (aka "sub-linear" regime), the minimax risk $R^*_\epsilon$ asymptotes to $2 \bar{\Phi}\left(n \epsilon^2/\sqrt{8N}\right) $, with $\bar{\Phi}(x)$ the normal survival function. Empirical studies over a range of problem parameters show that this estimate is accurate in finite samples, and that our test is significantly 
    
[^35]: 基于表示的Jensen-Shannon散度

    The Representation Jensen-Shannon Divergence. (arXiv:2305.16446v1 [cs.LG])

    [http://arxiv.org/abs/2305.16446](http://arxiv.org/abs/2305.16446)

    本文提出了一种基于表示的新型散度——表示Jensen-Shannon散度，通过将数据分布嵌入到RKHS中，并利用表示的协方差算子的频谱，实现对数据分布的估计，并提供了具有灵活性，可扩展性，可微分性的经验协方差矩阵估计函数和基于核矩阵的估计函数。

    

    统计散度量化概率分布之间的差异，是机器学习中的一种重要方法。但是，由于数据的底层分布通常未知，从经验样本中估计散度是一个基本难题。本文提出了一种基于再生核希尔伯特空间(RKHS)中协方差算子的新型散度——表示Jensen-Shannon散度。我们的方法将数据分布嵌入到RKHS中，并利用表示的协方差算子的频谱。我们提供了一个从经验协方差矩阵估计的估计函数，它通过使用Fourier特征将数据映射到RKHS中。此估计函数是灵活、可扩展、可微分的，并且适用于小批量优化问题。此外，我们还提供了一种基于核矩阵的估计函数，而不需要对RKHS进行显式映射。我们证明这个量是Jensen-Shannon散度的一个下界。

    Statistical divergences quantify the difference between probability distributions finding multiple uses in machine-learning. However, a fundamental challenge is to estimate divergence from empirical samples since the underlying distributions of the data are usually unknown. In this work, we propose the representation Jensen-Shannon Divergence, a novel divergence based on covariance operators in reproducing kernel Hilbert spaces (RKHS). Our approach embeds the data distributions in an RKHS and exploits the spectrum of the covariance operators of the representations. We provide an estimator from empirical covariance matrices by explicitly mapping the data to an RKHS using Fourier features. This estimator is flexible, scalable, differentiable, and suitable for minibatch-based optimization problems. Additionally, we provide an estimator based on kernel matrices without having an explicit mapping to the RKHS. We show that this quantity is a lower bound on the Jensen-Shannon divergence, and 
    
[^36]: 带误差校正的沉积计算：随机动力学系统的长期行为研究

    Reservoir Computing with Error Correction: Long-term Behaviors of Stochastic Dynamical Systems. (arXiv:2305.00669v1 [math.DS])

    [http://arxiv.org/abs/2305.00669](http://arxiv.org/abs/2305.00669)

    本文提出了一种数据驱动的框架，将沉积计算和归一化流结合起来以研究随机动力学系统的预测和动力学行为，成功地预测了长期演化并复制了动力学行为。

    

    随机动力学系统的预测和动力学行为的捕捉是一个深刻的问题。在本文中，我们提出了一种数据驱动框架，将沉积计算和归一化流结合起来研究这个问题，它模仿误差建模来提高传统沉积计算的性能，并充分利用了两种方法的优点。这种无模型方法成功地预测了随机动力学系统的长期演化，并复制了动力学行为。

    The prediction of stochastic dynamical systems and the capture of dynamical behaviors are profound problems. In this article, we propose a data-driven framework combining Reservoir Computing and Normalizing Flow to study this issue, which mimics error modeling to improve the traditional Reservoir Computing performance and takes advantage of both approaches. This model-free method successfully predicts the long-term evolution of stochastic dynamical systems and replicates dynamical behaviors. With few assumptions about the underlying stochastic dynamical systems, we deal with Markov/non-Markov and stationary/non-stationary stochastic processes defined by linear/nonlinear stochastic differential equations or stochastic delay differential equations. We verify the effectiveness of the proposed framework in five experiments, including the Ornstein-Uhlenbeck process, Double-Well system, El Ni\~no Southern Oscillation simplified model, and stochastic Lorenz system. Additionally, we explore th
    
[^37]: 基于数据驱动的分段仿射决策规则用于带协变信息的随机规划

    Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information. (arXiv:2304.13646v1 [math.OC])

    [http://arxiv.org/abs/2304.13646](http://arxiv.org/abs/2304.13646)

    本研究提出一种嵌入非凸分段仿射决策规则的经验风险最小化方法，用于学习特征与最优决策之间的直接映射。所提出的方法可用于广泛的非凸型SP问题，并且在数值研究中表现出优越的性能。

    

    本文针对带协变信息的随机规划，提出了一种嵌入非凸分段仿射决策规则(PADR)的经验风险最小化(ERM)方法，旨在学习特征与最优决策之间的直接映射。我们建立了基于PADR的ERM模型的非渐近一致性结果，可用于无约束问题，以及约束问题的渐近一致性结果。为了解决非凸和非可微的ERM问题，我们开发了一个增强的随机主导下降算法，并建立了沿（复合强）方向稳定性的渐近收敛以及复杂性分析。我们表明，所提出的PADR-based ERM方法适用于广泛的非凸型SP问题，并具有理论一致性保证和计算可处理性。数值研究表明，在各种设置下，PADR-based ERM方法相对于最先进的方法具有优越的性能。

    Focusing on stochastic programming (SP) with covariate information, this paper proposes an empirical risk minimization (ERM) method embedded within a nonconvex piecewise affine decision rule (PADR), which aims to learn the direct mapping from features to optimal decisions. We establish the nonasymptotic consistency result of our PADR-based ERM model for unconstrained problems and asymptotic consistency result for constrained ones. To solve the nonconvex and nondifferentiable ERM problem, we develop an enhanced stochastic majorization-minimization algorithm and establish the asymptotic convergence to (composite strong) directional stationarity along with complexity analysis. We show that the proposed PADR-based ERM method applies to a broad class of nonconvex SP problems with theoretical consistency guarantees and computational tractability. Our numerical study demonstrates the superior performance of PADR-based ERM methods compared to state-of-the-art approaches under various settings,
    
[^38]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^39]: 一次性联邦适应预测

    One-Shot Federated Conformal Prediction. (arXiv:2302.06322v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.06322](http://arxiv.org/abs/2302.06322)

    这种方法提出了一种在一次性联邦学习设置下进行适应预测的方法，通过定义分位数估计器，并且仅需要进行一轮通信就可以获得具有期望覆盖率的预测集。实验结果表明该方法在覆盖率和长度方面与集中式设置的结果非常相似，证明了其在一次性联邦学习中的适用性。

    

    本文介绍了一种在一次性联邦学习设置下构建预测集的适应预测方法。具体而言，我们定义了一个分位数估计器，并证明对于任何分布，只需一轮通信即可输出具有期望覆盖率的预测集。为了解决隐私问题，我们还描述了一个本地差分隐私版本的估计器。最后，在广泛的实验中，我们表明我们的方法返回的预测集的覆盖率和长度非常类似于在集中式设置中获得的结果。总体而言，这些结果证明了我们的方法在一次性联邦学习设置下进行适应预测的适用性。

    In this paper, we introduce a conformal prediction method to construct prediction sets in a oneshot federated learning setting. More specifically, we define a quantile-of-quantiles estimator and prove that for any distribution, it is possible to output prediction sets with desired coverage in only one round of communication. To mitigate privacy issues, we also describe a locally differentially private version of our estimator. Finally, over a wide range of experiments, we show that our method returns prediction sets with coverage and length very similar to those obtained in a centralized setting. Overall, these results demonstrate that our method is particularly well-suited to perform conformal predictions in a one-shot federated learning setting.
    
[^40]: SpArX: 稀疏的神经网络论证解释

    SpArX: Sparse Argumentative Explanations for Neural Networks. (arXiv:2301.09559v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.09559](http://arxiv.org/abs/2301.09559)

    该论文提出了一种稀疏的神经网络论证解释方法SpArX，通过利用多层感知器和定量论证框架之间的关系，可以为神经网络的决策过程提供更忠实和深入的解释。

    

    神经网络在人工智能中有各种应用，但解释它们的决策仍然具有挑战性。现有方法通常关注解释改变单个输入如何影响神经网络的输出。然而，一个与神经网络的输入输出行为一致的解释未必忠实于其实际机制。在本文中，我们利用多层感知器和定量论证框架之间的关系，为多层感知器的机制创建了论证性解释。我们的SpArX方法首先将多层感知器稀疏化，同时保持尽可能多的原始结构。然后将稀疏的多层感知器转化为等效的定量论证框架，以揭示多层感知器的潜在决策过程，产生全局和/或局部解释。我们通过实验证明，SpArX比现有方法可以给出更忠实的解释，同时提供更深入的洞察实际推理过程。

    Neural networks (NNs) have various applications in AI, but explaining their decisions remains challenging. Existing approaches often focus on explaining how changing individual inputs affects NNs' outputs. However, an explanation that is consistent with the input-output behaviour of an NN is not necessarily faithful to the actual mechanics thereof. In this paper, we exploit relationships between multi-layer perceptrons (MLPs) and quantitative argumentation frameworks (QAFs) to create argumentative explanations for the mechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining as much of the original structure as possible. It then translates the sparse MLP into an equivalent QAF to shed light on the underlying decision process of the MLP, producing global and/or local explanations. We demonstrate experimentally that SpArX can give more faithful explanations than existing approaches, while simultaneously providing deeper insights into the actual reasoning process of M
    
[^41]: 潜在多模态功能图模型估计

    Latent Multimodal Functional Graphical Model Estimation. (arXiv:2210.17237v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2210.17237](http://arxiv.org/abs/2210.17237)

    本研究提出了一个潜在多模态功能图模型估计的新框架，通过同时估计转换算子和潜在图来填补当前科学方法在估计多模态功能数据图模型方面的空白

    

    共同多模态功能数据采集是一种现代的方法，通过最近在神经学和生物科学中的工程突破，可以同时从同一主体中测量来自多种模式的功能数据。获取这样的数据的一个重要动机是通过结合多模态信号来发现潜在的连接性。尽管存在科学兴趣，但在估计多模态功能数据下的图模型方面仍存在差距。为此，我们提出了一个新的综合框架，对数据生成过程进行建模，并识别从观测空间到潜在空间的算子映射。然后，我们开发了一个估计器，可以同时估计转换算子和潜在图。这个估计器基于偏相关算子，我们从多元到功能设置中严格推广了它。我们的程序是pr封闭的

    Joint multimodal functional data acquisition, where functional data from multiple modes are measured simultaneously from the same subject, has emerged as an exciting modern approach enabled by recent engineering breakthroughs in the neurological and biological sciences. One prominent motivation to acquire such data is to enable new discoveries of the underlying connectivity by combining multimodal signals. Despite the scientific interest, there remains a gap in principled statistical methods for estimating the graph underlying multimodal functional data. To this end, we propose a new integrative framework that models the data generation process and identifies operators mapping from the observation space to the latent space. We then develop an estimator that simultaneously estimates the transformation operators and the latent graph. This estimator is based on the partial correlation operator, which we rigorously extend from the multivariate to the functional setting. Our procedure is pr
    
[^42]: $k$-均值聚类用于持久同调

    $k$-Means Clustering for Persistent Homology. (arXiv:2210.10003v3 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2210.10003](http://arxiv.org/abs/2210.10003)

    本文证明了$k$-均值聚类算法在持久图空间上的收敛性，解决了代数构造导致的复杂度问题，通过实验证明直接在持久图和持久度量上进行聚类优于向量表示。

    

    持久同调是拓扑数据分析中的一种方法，用于提取和总结数据集中的拓扑特征，并以持久图的形式表示。近年来，在许多领域中广泛应用的持久同调方法受到了很大的关注。然而，它的代数构造导致了一个具有高度复杂几何的持续图空间的度量空间。在本文中，我们证明了$k$-均值聚类算法在持久图空间上的收敛性，并在Karush-Kuhn-Tucker框架下建立了优化问题的理论性质。此外，我们对持久同调的各种表示进行了数值实验，包括持久图的嵌入以及图和它们的推广作为持久度量；我们发现，直接在持久图和持久度量上进行聚类的性能优于它们的向量表示。

    Persistent homology is a methodology central to topological data analysis that extracts and summarizes the topological features within a dataset as a persistence diagram; it has recently gained much popularity from its myriad successful applications to many domains. However, its algebraic construction induces a metric space of persistence diagrams with a highly complex geometry. In this paper, we prove convergence of the $k$-means clustering algorithm on persistence diagram space and establish theoretical properties of the solution to the optimization problem in the Karush--Kuhn--Tucker framework. Additionally, we perform numerical experiments on various representations of persistent homology, including embeddings of persistence diagrams as well as diagrams themselves and their generalizations as persistence measures; we find that clustering performance directly on persistence diagrams and measures outperform their vectorized representations.
    
[^43]: CitySim：面向安全研究和数字孪生的基于无人机车辆轨迹数据集

    CitySim: A Drone-Based Vehicle Trajectory Dataset for Safety Oriented Research and Digital Twins. (arXiv:2208.11036v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.11036](http://arxiv.org/abs/2208.11036)

    本文介绍了CitySim数据集，该数据集通过无人机录制的视频提取车辆轨迹，旨在促进安全导向的研究和应用。数据集包含大量的细粒度车辆轨迹，并通过五步骤的处理确保了轨迹的准确性。

    

    安全导向研究和应用的发展需要高精度且能捕捉重要安全事件的细粒度车辆轨迹数据。然而，现有的车辆轨迹数据集很难同时满足这两个要求。本文介绍了CitySim数据集，其核心目标是促进安全导向的研究和应用。CitySim包含从12个地点录制的1140分钟无人机视频中提取的车辆轨迹。它涵盖了各种道路几何形状，包括高速公路基本段、信号化十字路口、停控十字路口和无控交叉路口。CitySim通过五个步骤生成，确保了轨迹的准确性。这五个步骤包括视频稳定、目标过滤、多视频拼接、目标检测和跟踪以及增强式误差过滤。

    The development of safety-oriented research and applications requires fine-grain vehicle trajectories that not only have high accuracy, but also capture substantial safety-critical events. However, it would be challenging to satisfy both these requirements using the available vehicle trajectory datasets do not have the capacity to satisfy both.This paper introduces the CitySim dataset that has the core objective of facilitating safety-oriented research and applications. CitySim has vehicle trajectories extracted from 1140 minutes of drone videos recorded at 12 locations. It covers a variety of road geometries including freeway basic segments, signalized intersections, stop-controlled intersections, and control-free intersections. CitySim was generated through a five-step procedure that ensured trajectory accuracy. The five-step procedure included video stabilization, object filtering, multi-video stitching, object detection and tracking, and enhanced error filtering. Furthermore, CityS
    
[^44]: 可争议神经网络的因果发现与知识注入

    Causal Discovery and Knowledge Injection for Contestable Neural Networks. (arXiv:2205.09787v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09787](http://arxiv.org/abs/2205.09787)

    本研究提出了一种可以进行双向互动的方法，通过允许神经网络展示其所学因果图，并允许人类修改因果图后重新注入机器中，从而提供了一种调试神经网络的方式，实验结果显示该方法可以显著改善预测性能。

    

    神经网络在解决机器学习任务方面表现出色，但它们是否学习到了相关的因果关系尚不清楚，而它们的黑箱特性使得模型构建者难以理解和调试。我们提出了一种新颖的方法来解决这些问题，通过允许神经网络驱动的机器展示其所学因果图，并允许人类修改因果图后重新注入机器中，实现双向互动。所学模型保证符合因果图并遵循专家知识，其中部分知识也可以事先给定。通过对模型行为进行可视化并实现知识注入，我们的方法允许从数据中发现因果结构并支撑预测的从业者进行调试。在真实和合成表格数据上的实验表明，我们的方法可以改进预测性能高达2.4倍。

    Neural networks have proven to be effective at solving machine learning tasks but it is unclear whether they learn any relevant causal relationships, while their black-box nature makes it difficult for modellers to understand and debug them. We propose a novel method overcoming these issues by allowing a two-way interaction whereby neural-network-empowered machines can expose the underpinning learnt causal graphs and humans can contest the machines by modifying the causal graphs before re-injecting them into the machines. The learnt models are guaranteed to conform to the graphs and adhere to expert knowledge, some of which can also be given up-front. By building a window into the model behaviour and enabling knowledge injection, our method allows practitioners to debug networks based on the causal structure discovered from the data and underpinning the predictions. Experiments with real and synthetic tabular data show that our method improves predictive performance up to 2.4x while pr
    
[^45]: 针对预测模型更新的留置集

    Holdouts set for predictive model updating. (arXiv:2202.06374v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.06374](http://arxiv.org/abs/2202.06374)

    该论文研究了在复杂环境中如何更新预测风险评分来指导干预。作者提出使用留置集的方式进行更新，通过找到留置集的合适大小可以保证更新后的风险评分性能良好，同时减少留置样本数量。研究结果表明，该方法在总成本增长速度方面具有竞争优势。

    

    在复杂的环境中，如医疗保健领域，预测风险评分在指导干预方面起着越来越重要的作用。然而，直接更新用于指导干预的风险评分可能导致偏差风险估计。为了解决这个问题，我们提出使用“留置集”来进行更新-留置集是一个不接受风险评分指导干预的人群的子集。在留置集的大小上取得平衡是关键，以确保更新后的风险评分性能良好，同时最大限度地减少留置样本的数量。我们证明了这种方法使得总成本可以以$O\left(N^{2/3}\right)$的速度增长，其中$N$是人口规模，并且认为在一般情况下没有竞争性的替代方法。通过定义适当的损失函数，我们描述了一些条件，可以很容易地确定最佳留置集大小（OHS），并引入参数化和半参数化算法来估计OHS，并展示了其在最新风险评分中的应用。

    In complex settings, such as healthcare, predictive risk scores play an increasingly crucial role in guiding interventions. However, directly updating risk scores used to guide intervention can lead to biased risk estimates. To address this, we propose updating using a `holdout set' - a subset of the population that does not receive interventions guided by the risk score. Striking a balance in the size of the holdout set is essential, to ensure good performance of the updated risk score whilst minimising the number of held out samples. We prove that this approach enables total costs to grow at a rate $O\left(N^{2/3}\right)$ for a population of size $N$, and argue that in general circumstances there is no competitive alternative. By defining an appropriate loss function, we describe conditions under which an optimal holdout size (OHS) can be readily identified, and introduce parametric and semi-parametric algorithms for OHS estimation, demonstrating their use on a recent risk score for 
    
[^46]: 高分辨率微分方程在鞍点优化器的最后迭代收敛中的应用

    Last-Iterate Convergence of Saddle-Point Optimizers via High-Resolution Differential Equations. (arXiv:2112.13826v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2112.13826](http://arxiv.org/abs/2112.13826)

    本研究利用高分辨率微分方程在鞍点优化中设计了不同的微分方程模型，这些模型在双线性博弈中的收敛性质与离散方法相匹配。

    

    几种广泛使用的一阶鞍点优化方法在衍生时可以得到与梯度下降上升 (GDA) 方法相同的连续时间常微分方程 (ODE)，但是这些方法的收敛性质在简单的双线性博弈中是有差异的。因此，ODE 视角在分析单目标优化方法方面已经发挥了强大的作用，但在鞍点优化中的应用尚不明晰。我们采用在流体动力学中研究的高分辨率微分方程 (HRDEs) 框架来设计几种鞍点优化方法的微分方程模型。尤其需要指出的是，这些 HRDEs 对应于不同的鞍点优化方法是不同的。此外，在双线性博弈中，HRDEs 的收敛性质与相应的离散方法的性质相匹配。

    Several widely-used first-order saddle-point optimization methods yield an identical continuous-time ordinary differential equation (ODE) that is identical to that of the Gradient Descent Ascent (GDA) method when derived naively. However, the convergence properties of these methods are qualitatively different, even on simple bilinear games. Thus the ODE perspective, which has proved powerful in analyzing single-objective optimization methods, has not played a similar role in saddle-point optimization.  We adopt a framework studied in fluid dynamics -- known as High-Resolution Differential Equations (HRDEs) -- to design differential equation models for several saddle-point optimization methods. Critically, these HRDEs are distinct for various saddle-point optimization methods. Moreover, in bilinear games, the convergence properties of the HRDEs match the qualitative features of the corresponding discrete methods. Additionally, we show that the HRDE of Optimistic Gradient Descent Ascent 
    
[^47]: 多元极值的谱学习

    Spectral learning of multivariate extremes. (arXiv:2111.07799v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.07799](http://arxiv.org/abs/2111.07799)

    我们提出了一种用于分析多元极值的谱聚类算法，并通过理论和数值实验展示了其在学习角度测度方面的性能。

    

    我们提出了一种用于分析多元极值的谱聚类算法。具体而言，我们关注极值理论中由角度或谱测度表征的多元极值的渐近依赖性。我们的工作研究了谱聚类的理论性能，该聚类基于从极值样本中构建的随机k最近邻图，即对于半径超过一个较大阈值的随机向量的角度部分。具体而言，我们推导出线性因子模型产生的极值的渐近分布，并证明，在某些条件下，谱聚类可以一致地识别出在该模型中产生的极值的聚类。基于这个结果，我们提出了一种简单的一致性估计策略来学习角度测度。我们的理论结果与数值实验相结合，展示了我们方法在有限样本情况下的性能。

    We propose a spectral clustering algorithm for analyzing the dependence structure of multivariate extremes. More specifically, we focus on the asymptotic dependence of multivariate extremes characterized by the angular or spectral measure in extreme value theory. Our work studies the theoretical performance of spectral clustering based on a random $k$-nearest neighbor graph constructed from an extremal sample, i.e., the angular part of random vectors for which the radius exceeds a large threshold. In particular, we derive the asymptotic distribution of extremes arising from a linear factor model and prove that, under certain conditions, spectral clustering can consistently identify the clusters of extremes arising in this model. Leveraging this result we propose a simple consistent estimation strategy for learning the angular measure. Our theoretical findings are complemented with numerical experiments illustrating the finite sample performance of our methods.
    
[^48]: 两层神经网络的非渐近理论：超越偏差-方差折衷

    Nonasymptotic theory for two-layer neural networks: Beyond the bias-variance trade-off. (arXiv:2106.04795v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.04795](http://arxiv.org/abs/2106.04795)

    这项研究提出了针对两层神经网络的非渐近泛化理论，通过引入缩放变分正则化，并利用"岭-套索对偶性"获得了新的预测界限，解释了大型神经网络在超参数化情况下的表现以及双谷现象。

    

    大型神经网络在现代深度学习实践中表现出惊人的效果，即使在超参数化的情况下，即活跃参数数量相对于样本大小很大。这与传统观点相矛盾，传统观点认为机器学习模型必须在偏差和方差之间进行权衡以实现最佳泛化。为了解决这个冲突，我们通过引入缩放变分正则化，给出了针对具有ReLU激活函数的两层神经网络的非渐近泛化理论。有趣的是，这个正则化器从梯度优化的角度来看等价于岭回归，但在控制模型复杂性方面起到了类似于分组套索的作用。通过利用这种"岭-套索对偶性"，我们得到了适用于所有网络宽度的新的预测界限，从而重现了双谷现象。此外，在信号强的情况下，超参数化的最小风险低于其欠参数化的对应值，并且几乎是最小最大方法。

    Large neural networks have proved remarkably effective in modern deep learning practice, even in the overparametrized regime where the number of active parameters is large relative to the sample size. This contradicts the classical perspective that a machine learning model must trade off bias and variance for optimal generalization. To resolve this conflict, we present a nonasymptotic generalization theory for two-layer neural networks with ReLU activation function by incorporating scaled variation regularization. Interestingly, the regularizer is equivalent to ridge regression from the angle of gradient-based optimization, but plays a similar role to the group lasso in controlling the model complexity. By exploiting this "ridge-lasso duality," we obtain new prediction bounds for all network widths, which reproduce the double descent phenomenon. Moreover, the overparametrized minimum risk is lower than its underparametrized counterpart when the signal is strong, and is nearly minimax o
    
[^49]: 功能性轮廓建模和可解释形状变化检测：结合Fréchet均值与形状不变模型的方法

    Modelling of functional profiles and explainable shape shifts detection: An approach combining the notion of the Fr\'echet mean with the shape invariant model}. (arXiv:2010.02968v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2010.02968](http://arxiv.org/abs/2010.02968)

    该论文提出了一种结合Fréchet均值和形状不变模型的方法，用于检测功能性轮廓中的形状变化，并构建了功能性数据的控制图，可解释性强且能识别潜在变化。

    

    提出了一种适用于检测功能性轮廓中形状变化的建模框架，结合了Fréchet均值概念和变形模型的概念。利用Fréchet均值提供的广义均值感知能够捕捉研究对象轮廓的典型模式，而变形模型的概念，特别是形状不变模型，允许对轮廓与典型形状之间的偏差进行可解释的参数化。构建和提出了与数据的功能性特性和所采用的变形模型相兼容的EWMA类型控制图，利用研究对象的轮廓在广义均值感知下的某些形状特征，实现对形状和/或变形过程潜在变化的识别。进一步将形状变形过程的潜在变化区分为与幅度和/或相位相关的显著变化。

    A modelling framework suitable for detecting shape shifts in functional profiles combining the notion of Fr\'echet mean and the concept of deformation models is developed and proposed. The generalized mean sense offerred by the Fr\'echet mean notion is employed to capture the typical pattern of the profiles under study, while the concept of deformation models, and in particular of the shape invariant model, allows for interpretable parameterizations of profile's deviations from the typical shape. EWMA-type control charts compatible with the functional nature of data and the employed deformation model are built and proposed, exploiting certain shape characteristics of the profiles under study with respect to the generalised mean sense, allowing for the identification of potential shifts concerning the shape and/or the deformation process. Potential shifts in the shape deformation process, are further distingu\-ished to significant shifts with respect to amplitude and/or the phase of the
    
[^50]: 公平的层次聚类算法

    Fair Algorithms for Hierarchical Agglomerative Clustering. (arXiv:2005.03197v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.03197](http://arxiv.org/abs/2005.03197)

    提出了一种公平的层次聚类算法，该算法不受距离链接准则的限制，能适应不同的公平度量标准，并可以处理多个受保护群体。

    

    层次聚类算法在现代数据科学中被广泛使用，旨在将数据集分割为聚类，并生成数据样本之间的层次关系。层次聚类算法被应用于生物学、自然语言处理和推荐系统等许多应用中。因此，确保这些算法是公平的至关重要 -- 即使数据集对某些受保护群体存在偏差，生成的聚类输出也不应歧视来自任何这些群体的样本。然而，最近针对公平聚类的研究主要集中在基于中心的聚类算法，如k-中值和k-均值聚类。在本文中，我们提出了一种公平的层次聚类算法，它能在使用任何距离链接准则的情况下强制执行公平约束，并能推广到层次聚类的任何自然公平度量，适用于多个受保护群体。

    Hierarchical Agglomerative Clustering (HAC) algorithms are extensively utilized in modern data science, and seek to partition the dataset into clusters while generating a hierarchical relationship between the data samples. HAC algorithms are employed in many applications, such as biology, natural language processing, and recommender systems. Thus, it is imperative to ensure that these algorithms are fair -- even if the dataset contains biases against certain protected groups, the cluster outputs generated should not discriminate against samples from any of these groups. However, recent work in clustering fairness has mostly focused on center-based clustering algorithms, such as k-median and k-means clustering. In this paper, we propose fair algorithms for performing HAC that enforce fairness constraints 1) irrespective of the distance linkage criteria used, 2) generalize to any natural measures of clustering fairness for HAC, 3) work for multiple protected groups, and 4) have competiti
    
[^51]: 广义化界限和表示学习用于估计潜在结果和因果效应

    Generalization Bounds and Representation Learning for Estimation of Potential Outcomes and Causal Effects. (arXiv:2001.07426v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2001.07426](http://arxiv.org/abs/2001.07426)

    本论文研究了从记录的背景、决策和结果中估计个体层面的因果效应的问题，给出了基于距离度量的广义化界限以及相应的样本重新加权方法，并设计了最小化界限的表示学习算法来实现估计的准确性。

    

    医疗、经济和教育等各领域的从业者都渴望应用机器学习来改善决策。由于实验的成本和不切实际性，以及电子记录保留的巨大增长，非实验观测数据评估决策的问题引起了关注。本文即是在这个背景下展开研究。我们特别研究了从记录的背景、决策和结果中估计个体层面的因果效应，例如单个患者对不同药物的反应。我们给出了基于接受不同治疗组之间距离度量的估计效果误差的广义化界限，允许样本重新加权。我们给出了我们界限紧密的条件，并展示了它与无监督领域适应结果的关系。在我们的理论结果的指导下，我们设计了最小化界限的表示学习算法，通过正则化表示向量。

    Practitioners in diverse fields such as healthcare, economics and education are eager to apply machine learning to improve decision making. The cost and impracticality of performing experiments and a recent monumental increase in electronic record keeping has brought attention to the problem of evaluating decisions based on non-experimental observational data. This is the setting of this work. In particular, we study estimation of individual-level causal effects, such as a single patient's response to alternative medication, from recorded contexts, decisions and outcomes. We give generalization bounds on the error in estimated effects based on distance measures between groups receiving different treatments, allowing for sample re-weighting. We provide conditions under which our bound is tight and show how it relates to results for unsupervised domain adaptation. Led by our theoretical results, we devise representation learning algorithms that minimize our bound, by regularizing the rep
    
[^52]: 对稀疏观测下的二次张量进行恢复的保证

    Recovery Guarantees for Quadratic Tensors with Sparse Observations. (arXiv:1811.00148v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1811.00148](http://arxiv.org/abs/1811.00148)

    本研究考察了稀疏观测下的二次张量恢复问题，发现非凸方法能够在线性样本数量下保证误差最小化问题的全局极小值，并改进了观测有限情况下的CP模型性能。

    

    我们考虑张量完整问题，即预测张量中缺失的条目。常用的CP模型具有三次乘积形式，但一种替代的二次模型家族已经从推荐系统等应用中出现，其是对成对乘积求和而不是三次乘积。非凸方法是学习二次模型的首选方法，本研究考察了它们的样本复杂度和误差保证。我们的主要结果是，只需线性数量的样本，平均均方误差目标函数的所有局部极小值都是全局极小值，并可以恢复原始张量。我们通过对合成和真实世界数据的实验证实了我们的理论结果，表明在观测数量有限的情况下，二次模型比CP模型具有更好的性能。

    We consider the tensor completion problem of predicting the missing entries of a tensor. The commonly used CP model has a triple product form, but an alternate family of quadratic models, which are the sum of pairwise products instead of a triple product, have emerged from applications such as recommendation systems. Non-convex methods are the method of choice for learning quadratic models, and this work examines their sample complexity and error guarantee. Our main result is that with the number of samples being only linear in the dimension, all local minima of the mean squared error objective are global minima and recover the original tensor. We substantiate our theoretical results with experiments on synthetic and real-world data, showing that quadratic models have better performance than CP models where there are a limited amount of observations available.
    
[^53]: 递归神经网络（RNN）和长短期记忆（LSTM）网络的基础

    Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network. (arXiv:1808.03314v10 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1808.03314](http://arxiv.org/abs/1808.03314)

    本文通过形式化推导来解释了递归神经网络（RNN）和长短期记忆（LSTM）网络的基本原理，并提出了一种将RNN转化为“Vanilla LSTM”网络的方法。

    

    长短期记忆（LSTM）网络在广泛的实际应用中表现出了高效的效果，因此在科学期刊、技术博客和实现指南中得到了广泛的关注。然而，在大多数文章中，LSTM网络及其父类RNN的推推理公式被以公理的方式陈述，而训练公式则完全被省略。此外，关于“展开”RNN的技术在文献中通常被描述，但缺乏解释。本文旨在在一篇文章中解释RNN和LSTM的基本原理。我们从信号处理的概念中形式化地推导出了RNN的基本公式。然后，我们提出并证明了一个精确的陈述，得到了RNN的展开技术。我们还审查了训练标准RNN的困难，并通过一系列逻辑论证将RNN转化为“Vanilla LSTM”网络。我们提供了与训练过程相关的所有方程。

    Because of their effectiveness in broad practical applications, LSTM networks have received a wealth of coverage in scientific journals, technical blogs, and implementation guides. However, in most articles, the inference formulas for the LSTM network and its parent, RNN, are stated axiomatically, while the training formulas are omitted altogether. In addition, the technique of "unrolling" an RNN is routinely presented without justification throughout the literature. The goal of this paper is to explain the essential RNN and LSTM fundamentals in a single document. Drawing from concepts in signal processing, we formally derive the canonical RNN formulation from differential equations. We then propose and prove a precise statement, which yields the RNN unrolling technique. We also review the difficulties with training the standard RNN and address them by transforming the RNN into the "Vanilla LSTM" network through a series of logical arguments. We provide all equations pertaining to the 
    

