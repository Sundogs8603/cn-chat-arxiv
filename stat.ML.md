# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Weighted Averaged Stochastic Gradient Descent: Asymptotic Normality and Optimality.](http://arxiv.org/abs/2307.06915) | 本文探索了一种加权平均随机梯度下降（SGD）方案，并建立了渐近正态性，提供了渐近有效的在线推理方法。此外，我们提出了一种自适应平均方案，具有最优的统计速度和有利的非渐近收敛性。 |
| [^2] | [The complexity of non-stationary reinforcement learning.](http://arxiv.org/abs/2307.06877) | 强化学习中的非平稳学习是一个重要挑战，我们证明了在修改概率或奖励时需要花费大量的时间来保持值函数的最新状态，并且这个挑战与状态数目密切相关。 |
| [^3] | [A Novel Bayes' Theorem for Upper Probabilities.](http://arxiv.org/abs/2307.06831) | 本文推广了瓦塞尔曼和卡代纳的结果，给出了一种新的贝叶斯定理用于处理与似然函数相关的不确定性。该结果对于工程、机器学习和人工智能领域具有潜在应用价值。 |
| [^4] | [Cramer Type Distances for Learning Gaussian Mixture Models by Gradient Descent.](http://arxiv.org/abs/2307.06753) | 本文提出了一种用于学习高斯混合模型的Cramer距离，该距离函数在多元情况下具有闭式表达式，并且易于计算和实现，并在梯度下降算法中有效。 |
| [^5] | [Multivariate Time Series characterization and forecasting of VoIP traffic in real mobile networks.](http://arxiv.org/abs/2307.06645) | 本论文旨在通过多变量时间序列分析，预测实时移动网络中VoIP流量的关键QoS/QoE描述符的行为，以帮助运营商优化网络规划和资源分配。 |
| [^6] | [An Improved Uniform Convergence Bound with Fat-Shattering Dimension.](http://arxiv.org/abs/2307.06644) | 本文提出了一个改进的均匀收敛界限，填补了现有状态-of-the-art上界与下界之间的空缺。 |
| [^7] | [Deep Neural Networks for Semiparametric Frailty Models via H-likelihood.](http://arxiv.org/abs/2307.06581) | 本文提出了一种新的基于深度神经网络的脆弱性模型，并使用H-似然法进行训练和预测。实验结果表明该方法提高了预测性能，特别是在包含个体特定脆弱性的情况下。 |
| [^8] | [Deep Network Approximation: Beyond ReLU to Diverse Activation Functions.](http://arxiv.org/abs/2307.06555) | 本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。 |
| [^9] | [An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines.](http://arxiv.org/abs/2307.06542) | 本研究提出了一种通过受限玻尔兹曼机（RBMs）的二值图像去噪框架，该框架使用二次无约束二值优化（QUBO）形式的去噪目标，并且适用于量子退火。通过平衡训练的RBMs学习到的分布和噪声图像偏离的惩罚项，实现了去噪目标。通过进行实验，研究发现该方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。 |
| [^10] | [Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems.](http://arxiv.org/abs/2307.06538) | 本论文以张量分解方法为基础，提出了学习线性动力系统混合模型的新方法。算法成功地应用于没有组件分离条件的情况，并可以与贝叶斯最优聚类竞争。此外，算法可以在部分观测设置下工作。 |
| [^11] | [Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective.](http://arxiv.org/abs/2307.06457) | 该论文研究了组合分布偏移的问题，提出了基于矩阵补全的解决方法。通过在特殊情况下的双线性嵌入，实现对训练中未涵盖的测试分布进行外推。这个设置将缺失非随机数据的矩阵补全问题广义化。 |
| [^12] | [On Collaboration in Distributed Parameter Estimation with Resource Constraints.](http://arxiv.org/abs/2307.06442) | 在资源约束下的分布参数估计中，我们研究了传感器/代理数据收集和协作策略，通过最大化费舍尔信息或最小化Cramer-Rao界来解决传感器/代理的数据收集和协作策略设计问题。 |
| [^13] | [Energy Discrepancies: A Score-Independent Loss for Energy-Based Models.](http://arxiv.org/abs/2307.06431) | 我们提出了一种新的能量模型损失函数，能够在不依赖分数计算或昂贵的蒙特卡罗方法的情况下，近似实现显式分数匹配和负对数似然损失，并在学习低维数据分布时具有更好的性能。 |
| [^14] | [Robust scalable initialization for Bayesian variational inference with multi-modal Laplace approximations.](http://arxiv.org/abs/2307.06424) | 本论文提出了基于多模态Laplace近似的贝叶斯变分推断的鲁棒可扩展初始化方法，以应对在高度非高斯行为中，包括多峰性时，“均场”高斯分布近似过于限制性的问题。 |
| [^15] | [Testing Sparsity Assumptions in Bayesian Networks.](http://arxiv.org/abs/2307.06406) | 本论文研究了在贝叶斯网络中测试稀疏性假设的问题，并提出了一种基于样本特征值的假设检验方法，可以帮助选择适当的结构发现算法。 |
| [^16] | [Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks.](http://arxiv.org/abs/2307.06362) | 本文提出了一个综合的理论框架，解决了物理信息神经网络（PINN）设计和训练协议的选择问题。通过将超参数化神经网络和高斯过程回归等价起来，推导出了一种在大数据集限制下决定PINN预测的积分微分方程，以及通过原始微分方程中源项的谱分解来量化网络引入的隐含偏差。 |
| [^17] | [balance -- a Python package for balancing biased data samples.](http://arxiv.org/abs/2307.06024) | balance是一个用于分析和调整有偏数据样本的Python软件包，通过评估初始偏差、根据倾向分数产生权重校正数据以及评估拟合权重后的偏差和方差膨胀来提供功能。 |
| [^18] | [Bayesian taut splines for estimating the number of modes.](http://arxiv.org/abs/2307.05825) | 本研究提出了一种贝叶斯紧系数样条方法，用于估计概率密度函数中模式的数量。该方法结合了核估计器和组合样条，实现了特征探索、模型选择和模式检验，并允许引入专家判断。通过在体育分析中的案例研究中的验证，证明了该方法的实用性。 |
| [^19] | [Understanding Uncertainty Sampling.](http://arxiv.org/abs/2307.02719) | 本研究通过系统研究流式和池式主动学习下的不确定性采样算法，提出了一个等效损失的概念，并证明不确定性采样算法实质上是针对该等效损失进行优化。 |
| [^20] | [Accelerated stochastic approximation with state-dependent noise.](http://arxiv.org/abs/2307.01497) | 该论文研究了一类具有状态相关噪声的随机平滑凸优化问题。通过引入两种非欧几里得加速随机逼近算法，实现了在精度、问题参数和小批量大小方面的最优性。 |
| [^21] | [On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling.](http://arxiv.org/abs/2306.07252) | 研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性 |
| [^22] | [Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs.](http://arxiv.org/abs/2304.11140) | 本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。 |
| [^23] | [Learning Graph ARMA Processes from Time-Vertex Spectra.](http://arxiv.org/abs/2302.06887) | 本研究提出了一种基于学习过程谱密度的算法，用于推断缺失的信号值和进行信号插值，实验结果显示其在时间-顶点信号估计问题中具有高准确性。 |
| [^24] | [Robust online active learning.](http://arxiv.org/abs/2302.00422) | 本文提出了一种自适应方法，用于鲁棒的在线主动学习，并在受污染的数据流中证明了其性能表现优异，同时确保了稳定性并减少异常值的负面影响。 |
| [^25] | [A Deep Learning Method for Comparing Bayesian Hierarchical Models.](http://arxiv.org/abs/2301.11873) | 这个论文提出了一种深度学习方法，用于比较贝叶斯层次模型。该方法通过支持分摊推断，能够高效地进行模型比较和性能验证。同时，作者还对四个层次证据积累模型进行了比较。 |
| [^26] | [Adversarial Policies Beat Superhuman Go AIs.](http://arxiv.org/abs/2211.00241) | 通过对抗性策略攻击，我们成功战胜了超级人类级围棋AI KataGo，揭示了其核心弱点，并展示了即使是超级AI系统也可能存在意想不到的失败模式。 |
| [^27] | [A kernel Stein test of goodness of fit for sequential models.](http://arxiv.org/abs/2210.10741) | 我们提出了一种基于核斯坦检验的适配性度量方法，可以适用于具有不同维度观测的概率密度模型，包括文本文档或可变长度序列。这种方法扩展了核斯坦差异(KSD)到可变维度设置，并提出了一种新颖的KSD适配性检验方法，无需密度归一化，并在离散顺序数据基准上表现良好。 |
| [^28] | [Multiple Testing Framework for Out-of-Distribution Detection.](http://arxiv.org/abs/2206.09522) | 本研究提出了一个多重检验框架用于离群分布检测的问题，包括了定义OOD概念和提供强有力保证的方法，与之前的基于阈值的测试相比，在不同类型的OOD实例中表现更一致。 |
| [^29] | [Adapting to Mixing Time in Stochastic Optimization with Markovian Data.](http://arxiv.org/abs/2202.04428) | 本文提出了一种适用于马尔可夫数据的随机优化问题的方法，不需要对混合时间有任何了解，但在凸问题中可以获得最优收敛速度。这种方法还可以应用于非凸优化以及时差学习，并且完全无视混合时间。方法的关键是多层蒙特卡洛梯度估计与自适应学习方法的组合。 |
| [^30] | [Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations.](http://arxiv.org/abs/2109.13445) | 本研究提供了证据表明，深度神经网络具有通过传播方向不变性来泛化到新颖方向上的对象的能力。这种能力受到训练中使用的熟悉对象数量的影响，但仅限于涉及2D旋转的熟悉方向。 |
| [^31] | [Learning low-rank latent mesoscale structures in networks.](http://arxiv.org/abs/2102.06984) | 这项研究提出了一种学习网络中低秩潜在中尺度结构的新方法，并通过合成网络模型和实际网络验证了其有效性。通过利用少量的“潜在模式”，可以成功地近似网络的大多数子图。这项研究对于理解复杂系统的行为具有重要意义。 |
| [^32] | [Tensor Completion Made Practical.](http://arxiv.org/abs/2006.03134) | 本文提出了一种新的变种交替最小化算法，针对张量补全问题，具有强有力的可靠保证，同时在处理高度相关因子时仍能线性收敛到真实张量，并且具有极高的实用性。 |
| [^33] | [Towards Learning to Imitate from a Single Video Demonstration.](http://arxiv.org/abs/1901.07186) | 本研究提出了一种从单一视频演示中学习模仿的方法，通过使用对比训练和Siamese循环神经网络，我们能够学习到智能体的行为与演示之间的奖励函数，并通过 RL 策略的训练最小化这个距离。实验表明，引入多任务数据和额外的图像编码损失可以改善学习到的奖励的时间一致性，并显著提高策略学习的效果。我们在不同维度的仿真智能体上验证了我们的方法的优越性。 |

# 详细

[^1]: 加权平均随机梯度下降: 渐近正态性和最优性

    Weighted Averaged Stochastic Gradient Descent: Asymptotic Normality and Optimality. (arXiv:2307.06915v1 [stat.ML])

    [http://arxiv.org/abs/2307.06915](http://arxiv.org/abs/2307.06915)

    本文探索了一种加权平均随机梯度下降（SGD）方案，并建立了渐近正态性，提供了渐近有效的在线推理方法。此外，我们提出了一种自适应平均方案，具有最优的统计速度和有利的非渐近收敛性。

    

    随机梯度下降（SGD）是现代统计和机器学习中最简单和最流行的算法之一，由于其计算和内存效率而受到青睐。在不同的情境下，已经提出了各种平均方案来加速SGD的收敛。在本文中，我们探讨了一种用于SGD的通用平均方案。具体而言，我们建立了一类加权平均SGD解的渐近正态性，并提供了渐近有效的在线推理方法。此外，我们提出了一种自适应平均方案，展现出最优的统计速度和有利的非渐近收敛性，借鉴了线性模型的非渐近均方误差（MSE）的最优权重的见解。

    Stochastic Gradient Descent (SGD) is one of the simplest and most popular algorithms in modern statistical and machine learning due to its computational and memory efficiency. Various averaging schemes have been proposed to accelerate the convergence of SGD in different settings. In this paper, we explore a general averaging scheme for SGD. Specifically, we establish the asymptotic normality of a broad range of weighted averaged SGD solutions and provide asymptotically valid online inference approaches. Furthermore, we propose an adaptive averaging scheme that exhibits both optimal statistical rate and favorable non-asymptotic convergence, drawing insights from the optimal weight for the linear model in terms of non-asymptotic mean squared error (MSE).
    
[^2]: 非平稳强化学习的复杂性

    The complexity of non-stationary reinforcement learning. (arXiv:2307.06877v1 [cs.LG])

    [http://arxiv.org/abs/2307.06877](http://arxiv.org/abs/2307.06877)

    强化学习中的非平稳学习是一个重要挑战，我们证明了在修改概率或奖励时需要花费大量的时间来保持值函数的最新状态，并且这个挑战与状态数目密切相关。

    

    非平稳强化学习的问题被认为是强化学习应用中的一个重要挑战。我们证明了最坏情况下的复杂性结果，我们认为这恰好捕捉到了这个挑战：修改强化学习问题中一个状态-动作对的概率或奖励，需要花费几乎与状态数目一样多的时间来及时更新值函数，除非强指数时间假设(SETH)是错误的；SETH是P≠NP猜想的广泛接受的加强版。需要注意的是，目前强化学习应用中的状态数目通常是天文数字级别的。相反，我们还展示了仅仅"添加"一个新的状态-动作对要容易得多。

    The problem of continual learning in the domain of reinforcement learning, often called non-stationary reinforcement learning, has been identified as an important challenge to the application of reinforcement learning. We prove a worst-case complexity result, which we believe captures this challenge: Modifying the probabilities or the reward of a single state-action pair in a reinforcement learning problem requires an amount of time almost as large as the number of states in order to keep the value function up to date, unless the strong exponential time hypothesis (SETH) is false; SETH is a widely accepted strengthening of the P $\neq$ NP conjecture. Recall that the number of states in current applications of reinforcement learning is typically astronomical. In contrast, we show that just $\textit{adding}$ a new state-action pair is considerably easier to implement.
    
[^3]: 一种新的贝叶斯定理用于上概率

    A Novel Bayes' Theorem for Upper Probabilities. (arXiv:2307.06831v1 [stat.ML])

    [http://arxiv.org/abs/2307.06831](http://arxiv.org/abs/2307.06831)

    本文推广了瓦塞尔曼和卡代纳的结果，给出了一种新的贝叶斯定理用于处理与似然函数相关的不确定性。该结果对于工程、机器学习和人工智能领域具有潜在应用价值。

    

    在他们1990年的开创性论文中，瓦塞尔曼和卡代纳建立了在先验概率位于概率类别P，且似然函数是精确函数时，可测集A的贝叶斯后验概率的上限。他们还给出了这种上限成立时的充分条件。本文中，我们通过额外处理与似然函数相关的不确定性来引入他们结果的推广。我们给出了当先验概率和似然函数都属于一组概率时的后验概率上限，并且给出了这种上限成为等式的充分条件。这个结果本身很有趣，并且有可能应用于工程领域（例如模型预测控制）、机器学习和人工智能。

    In their seminal 1990 paper, Wasserman and Kadane establish an upper bound for the Bayes' posterior probability of a measurable set $A$, when the prior lies in a class of probability measures $\mathcal{P}$ and the likelihood is precise. They also give a sufficient condition for such upper bound to hold with equality. In this paper, we introduce a generalization of their result by additionally addressing uncertainty related to the likelihood. We give an upper bound for the posterior probability when both the prior and the likelihood belong to a set of probabilities. Furthermore, we give a sufficient condition for this upper bound to become an equality. This result is interesting on its own, and has the potential of being applied to various fields of engineering (e.g. model predictive control), machine learning, and artificial intelligence.
    
[^4]: 用梯度下降学习高斯混合模型的Cramer距离

    Cramer Type Distances for Learning Gaussian Mixture Models by Gradient Descent. (arXiv:2307.06753v1 [cs.LG])

    [http://arxiv.org/abs/2307.06753](http://arxiv.org/abs/2307.06753)

    本文提出了一种用于学习高斯混合模型的Cramer距离，该距离函数在多元情况下具有闭式表达式，并且易于计算和实现，并在梯度下降算法中有效。

    

    高斯混合模型的学习在机器学习中起着重要作用。高斯混合模型以其表达力和可解释性而闻名，广泛应用于统计学、计算机视觉和分布式强化学习等领域。然而，目前为止，很少有已知算法可以拟合或学习这些模型，其中一些包括期望最大化算法和分割Wasserstein距离。与梯度下降相兼容的算法更少，这是神经网络的常见学习过程。在本文中，我们推导了一维情况下两个高斯混合模型的闭式公式，然后提出了一种称为Sliced Cramer 2距离的距离函数，用于学习一般的多元高斯混合模型。我们的方法比许多先前方法具有几个优点。首先，在一维情况下具有闭式表达式，并且可以使用常见的机器学习库（例如PyTorch）进行易于计算和实现的操作。

    The learning of Gaussian Mixture Models (also referred to simply as GMMs) plays an important role in machine learning. Known for their expressiveness and interpretability, Gaussian mixture models have a wide range of applications, from statistics, computer vision to distributional reinforcement learning. However, as of today, few known algorithms can fit or learn these models, some of which include Expectation-Maximization algorithms and Sliced Wasserstein Distance. Even fewer algorithms are compatible with gradient descent, the common learning process for neural networks.  In this paper, we derive a closed formula of two GMMs in the univariate, one-dimensional case, then propose a distance function called Sliced Cram\'er 2-distance for learning general multivariate GMMs. Our approach has several advantages over many previous methods. First, it has a closed-form expression for the univariate case and is easy to compute and implement using common machine learning libraries (e.g., PyTorc
    
[^5]: 实时移动网络中VoIP流量的多变量时间序列特征和预测

    Multivariate Time Series characterization and forecasting of VoIP traffic in real mobile networks. (arXiv:2307.06645v1 [cs.NI])

    [http://arxiv.org/abs/2307.06645](http://arxiv.org/abs/2307.06645)

    本论文旨在通过多变量时间序列分析，预测实时移动网络中VoIP流量的关键QoS/QoE描述符的行为，以帮助运营商优化网络规划和资源分配。

    

    预测移动网络中实时流量（例如VoIP）的行为，可以帮助运营商更好地规划网络基础设施并优化资源分配。因此，本研究提出了对VoIP流量在实际移动环境中关键QoS/QoE描述符进行预测分析（其中一些在技术文献中被忽略）。该问题以多变量时间序列分析的形式进行建模，这种形式化可以发现和建模各种描述符之间的时间关系，并预测它们在未来时期的行为。通过将多变量时间序列问题转化为监督学习问题，采用向量自回归模型和机器学习（基于深度学习和基于树的方法）进行性能和时间复杂度的比较。此外，还进行了一系列辅助分析（平稳性，正交脉冲响应等）可以发现VoIP流量的特性。

    Predicting the behavior of real-time traffic (e.g., VoIP) in mobility scenarios could help the operators to better plan their network infrastructures and to optimize the allocation of resources. Accordingly, in this work the authors propose a forecasting analysis of crucial QoS/QoE descriptors (some of which neglected in the technical literature) of VoIP traffic in a real mobile environment. The problem is formulated in terms of a multivariate time series analysis. Such a formalization allows to discover and model the temporal relationships among various descriptors and to forecast their behaviors for future periods. Techniques such as Vector Autoregressive models and machine learning (deep-based and tree-based) approaches are employed and compared in terms of performance and time complexity, by reframing the multivariate time series problem into a supervised learning one. Moreover, a series of auxiliary analyses (stationarity, orthogonal impulse responses, etc.) are performed to disco
    
[^6]: 一个具有“fat-shattering”维度的改进的均匀收敛界限

    An Improved Uniform Convergence Bound with Fat-Shattering Dimension. (arXiv:2307.06644v1 [cs.LG])

    [http://arxiv.org/abs/2307.06644](http://arxiv.org/abs/2307.06644)

    本文提出了一个改进的均匀收敛界限，填补了现有状态-of-the-art上界与下界之间的空缺。

    

    “fat-shattering”维度刻画了实值函数的均匀收敛特性。现有的状态-of-the-art上界在样本复杂度上存在一个乘法平方对数因子，与已有的下界之间存在一个空缺。本文提供了一个改进的均匀收敛界限来填补这个空缺。

    The fat-shattering dimension characterizes the uniform convergence property of real-valued functions. The state-of-the-art upper bounds feature a multiplicative squared logarithmic factor on the sample complexity, leaving an open gap with the existing lower bound. We provide an improved uniform convergence bound that closes this gap.
    
[^7]: 基于深度神经网络的半参数脆弱性模型及其H-似然法

    Deep Neural Networks for Semiparametric Frailty Models via H-likelihood. (arXiv:2307.06581v1 [stat.ML])

    [http://arxiv.org/abs/2307.06581](http://arxiv.org/abs/2307.06581)

    本文提出了一种新的基于深度神经网络的脆弱性模型，并使用H-似然法进行训练和预测。实验结果表明该方法提高了预测性能，特别是在包含个体特定脆弱性的情况下。

    

    为了预测群集化的时间至事件数据，我们提出了一种新的基于深度神经网络的伽马脆弱性模型（DNN-FM）。该模型的一个优势是通过新的H-似然函数的联合最大化，为固定参数提供了最大似然估计器，并为随机脆性提供了最佳无偏预测器。因此，所提出的DNN-FM通过使用负面剖析的H-似然函数作为损失函数进行训练，通过剖析非参数基线风险来构造。实验研究表明，所提出的方法提高了现有方法的预测性能。实际数据分析表明，包含个体特定脆弱性有助于改善基于DNN的Cox模型（DNN-Cox）的预测能力。

    For prediction of clustered time-to-event data, we propose a new deep neural network based gamma frailty model (DNN-FM). An advantage of the proposed model is that the joint maximization of the new h-likelihood provides maximum likelihood estimators for fixed parameters and best unbiased predictors for random frailties. Thus, the proposed DNN-FM is trained by using a negative profiled h-likelihood as a loss function, constructed by profiling out the non-parametric baseline hazard. Experimental studies show that the proposed method enhances the prediction performance of the existing methods. A real data analysis shows that the inclusion of subject-specific frailties helps to improve prediction of the DNN based Cox model (DNN-Cox).
    
[^8]: 深度网络逼近：从ReLU到多种激活函数

    Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])

    [http://arxiv.org/abs/2307.06555](http://arxiv.org/abs/2307.06555)

    本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。

    

    本文探究了深度神经网络在多种激活函数下的表达能力。定义了一个激活函数集合A，包括大多数常用的激活函数，如ReLU、LeakyReLU、ReLU^2、ELU、SELU、Softplus、GELU、SiLU、Swish、Mish、Sigmoid、Tanh、Arctan、Softsign、dSiLU和SRS。我们证明了对于任意激活函数varrho∈A，可以通过一个宽度为6N、深度为2L的varrho激活网络在有界集合上以任意精度逼近一个宽度为N、深度为L的ReLU网络。这一发现使得大部分对于ReLU网络的逼近结果能够推广到其他激活函数，尽管需要稍大的常数代价。

    This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
    
[^9]: 量子退火中适合的图像去噪框架：QUBO和受限玻尔兹曼机

    An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines. (arXiv:2307.06542v1 [quant-ph])

    [http://arxiv.org/abs/2307.06542](http://arxiv.org/abs/2307.06542)

    本研究提出了一种通过受限玻尔兹曼机（RBMs）的二值图像去噪框架，该框架使用二次无约束二值优化（QUBO）形式的去噪目标，并且适用于量子退火。通过平衡训练的RBMs学习到的分布和噪声图像偏离的惩罚项，实现了去噪目标。通过进行实验，研究发现该方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。

    

    我们研究了一种通过受限玻尔兹曼机（RBMs）实现的二值图像去噪框架，该框架引入了一个二次无约束二值优化（QUBO）形式的去噪目标，并且非常适合量子退火。通过在训练的RBMs上学习到的分布与噪声图像偏离的惩罚项的平衡，实现了去噪目标。我们推导了在目标分布被良好近似的情况下，惩罚参数的统计最优选择，并进一步建议了一种经过经验证支持的修改方法，使该方法对于理想化假设具有鲁棒性。我们还在额外的假设下展示了，我们方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。虽然我们将该模型构建为图像去噪模型，但它可以应用于任何二值数据。由于QUBO公式非常适合在量子退火器上实现，我们在一个数据集上对该模型进行了测试。

    We investigate a framework for binary image denoising via restricted Boltzmann machines (RBMs) that introduces a denoising objective in quadratic unconstrained binary optimization (QUBO) form and is well-suited for quantum annealing. The denoising objective is attained by balancing the distribution learned by a trained RBM with a penalty term for derivations from the noisy image. We derive the statistically optimal choice of the penalty parameter assuming the target distribution has been well-approximated, and further suggest an empirically supported modification to make the method robust to that idealistic assumption. We also show under additional assumptions that the denoised images attained by our method are, in expectation, strictly closer to the noise-free images than the noisy images are. While we frame the model as an image denoising model, it can be applied to any binary data. As the QUBO formulation is well-suited for implementation on quantum annealers, we test the model on a
    
[^10]: 张量分解与控制理论的结合：学习线性动力系统的混合模型

    Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems. (arXiv:2307.06538v1 [cs.LG])

    [http://arxiv.org/abs/2307.06538](http://arxiv.org/abs/2307.06538)

    本论文以张量分解方法为基础，提出了学习线性动力系统混合模型的新方法。算法成功地应用于没有组件分离条件的情况，并可以与贝叶斯最优聚类竞争。此外，算法可以在部分观测设置下工作。

    

    最近，Chen和Poor开始研究学习线性动力系统的混合模型。虽然线性动力系统已经在建模时间序列数据方面有广泛的应用，但使用混合模型可以带来更好的拟合或者对数据中表示的基础子群体有更丰富的理解。在这项工作中，我们提出了一种基于张量分解的学习线性动力系统混合模型的新方法。因此，我们的算法在组件无强分离条件的情况下成功，并可以用于与轨迹的贝叶斯最优聚类竞争。此外，我们的算法适用于具有挑战性的部分观测设置。我们的起点是简单但强大的观察，即经典的何-卡尔曼算法是学习潜变量模型的现代张量分解方法的近亲。这为我们提供了一个扩展到更复杂的生成模型的操作指南。

    Recently Chen and Poor initiated the study of learning mixtures of linear dynamical systems. While linear dynamical systems already have wide-ranging applications in modeling time-series data, using mixture models can lead to a better fit or even a richer understanding of underlying subpopulations represented in the data. In this work we give a new approach to learning mixtures of linear dynamical systems that is based on tensor decompositions. As a result, our algorithm succeeds without strong separation conditions on the components, and can be used to compete with the Bayes optimal clustering of the trajectories. Moreover our algorithm works in the challenging partially-observed setting. Our starting point is the simple but powerful observation that the classic Ho-Kalman algorithm is a close relative of modern tensor decomposition methods for learning latent variable models. This gives us a playbook for how to extend it to work with more complicated generative models.
    
[^11]: 解决组合分布偏移问题：基于矩阵补全的观点

    Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])

    [http://arxiv.org/abs/2307.06457](http://arxiv.org/abs/2307.06457)

    该论文研究了组合分布偏移的问题，提出了基于矩阵补全的解决方法。通过在特殊情况下的双线性嵌入，实现对训练中未涵盖的测试分布进行外推。这个设置将缺失非随机数据的矩阵补全问题广义化。

    

    在分布偏移下获得严格的统计保证仍然是一个开放且活跃的研究领域。我们研究了一种称为组合分布偏移的设置，其中(a)在测试和训练分布下，标签$z$由特征$(x,y)$的对决定，(b)训练分布涵盖了$x$和$y$分别的一定边缘分布，但是(c)测试分布涉及了一个在训练分布中未涵盖的$(x,y)$的产品分布的示例。我们专注于标签由双线性嵌入到Hilbert空间$H$中给出的特殊情况：$\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$，我们的目标是对在训练中未涵盖的测试分布域进行外推，即实现双线性组合外推。我们的设置将缺失非随机数据的矩阵补全的一个特殊情况广义化，对于该情况，所有现有结果都要求....

    Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call combinatorial distribution shift, where (a) under the test- and training-distributions, the labels $z$ are determined by pairs of features $(x,y)$, (b) the training distribution has coverage of certain marginal distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is {not} covered by the training distribution. Focusing on the special case where the labels are given by bilinear embeddings into a Hilbert space $H$: $\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$, we aim to extrapolate to a test distribution domain that is $not$ covered in training, i.e., achieving bilinear combinatorial extrapolation.  Our setting generalizes a special case of matrix completion from missing-not-at-random data, for which all existing results requi
    
[^12]: 在资源约束下的分布参数估计中的协作研究

    On Collaboration in Distributed Parameter Estimation with Resource Constraints. (arXiv:2307.06442v1 [cs.LG])

    [http://arxiv.org/abs/2307.06442](http://arxiv.org/abs/2307.06442)

    在资源约束下的分布参数估计中，我们研究了传感器/代理数据收集和协作策略，通过最大化费舍尔信息或最小化Cramer-Rao界来解决传感器/代理的数据收集和协作策略设计问题。

    

    我们研究了考虑资源约束和不同传感器/代理收集的观测之间的相关性的参数估计的传感器/代理数据收集和协作策略。具体地，我们考虑了一组传感器/代理，每个传感器/代理样本来自多元高斯分布的不同变量，并且具有不同的估计目标，我们将传感器/代理的数据收集和协作策略设计问题阐述为费舍尔信息最大化（或Cramer-Rao界最小化）问题。当变量之间的相关性知识可用时，我们可以分析地识别出两个特定情况：（1）不能利用样本之间的相关性知识进行协作估计的情况，（2）最优数据收集策略涉及投资有限资源以协作采样和转移已知统计信息的情况。

    We study sensor/agent data collection and collaboration policies for parameter estimation, accounting for resource constraints and correlation between observations collected by distinct sensors/agents. Specifically, we consider a group of sensors/agents each samples from different variables of a multivariate Gaussian distribution and has different estimation objectives, and we formulate a sensor/agent's data collection and collaboration policy design problem as a Fisher information maximization (or Cramer-Rao bound minimization) problem. When the knowledge of correlation between variables is available, we analytically identify two particular scenarios: (1) where the knowledge of the correlation between samples cannot be leveraged for collaborative estimation purposes and (2) where the optimal data collection policy involves investing scarce resources to collaboratively sample and transfer information that is not of immediate interest and whose statistics are already known, with the sol
    
[^13]: 能量差异：一种适用于能量模型的独立于评分的损失函数

    Energy Discrepancies: A Score-Independent Loss for Energy-Based Models. (arXiv:2307.06431v1 [stat.ML])

    [http://arxiv.org/abs/2307.06431](http://arxiv.org/abs/2307.06431)

    我们提出了一种新的能量模型损失函数，能够在不依赖分数计算或昂贵的蒙特卡罗方法的情况下，近似实现显式分数匹配和负对数似然损失，并在学习低维数据分布时具有更好的性能。

    

    能量模型是一种简单而强大的概率模型，但它们的普及受到了训练的计算负担的限制。我们提出了一种新的损失函数称为能量差异（ED），它不依赖于分数的计算或昂贵的马尔可夫链蒙特卡罗。我们证明了在不同的极限下，ED接近于显式分数匹配和负对数似然损失，有效地在两者之间插值。因此，最小化ED估计克服了在基于分数的估计方法中遇到的近视问题，同时还享有理论保证。通过数值实验证明，与显式分数匹配或对比散度相比，ED能够更快速、更准确地学习低维数据分布。对于高维图像数据，我们描述了流形假设对我们方法的限制，并通过对e模型的训练，证明了能量差异的有效性。

    Energy-based models are a simple yet powerful class of probabilistic models, but their widespread adoption has been limited by the computational burden of training them. We propose a novel loss function called Energy Discrepancy (ED) which does not rely on the computation of scores or expensive Markov chain Monte Carlo. We show that ED approaches the explicit score matching and negative log-likelihood loss under different limits, effectively interpolating between both. Consequently, minimum ED estimation overcomes the problem of nearsightedness encountered in score-based estimation methods, while also enjoying theoretical guarantees. Through numerical experiments, we demonstrate that ED learns low-dimensional data distributions faster and more accurately than explicit score matching or contrastive divergence. For high-dimensional image data, we describe how the manifold hypothesis puts limitations on our approach and demonstrate the effectiveness of energy discrepancy by training the e
    
[^14]: 基于多模态Laplace近似的贝叶斯变分推断的鲁棒可扩展初始化

    Robust scalable initialization for Bayesian variational inference with multi-modal Laplace approximations. (arXiv:2307.06424v1 [stat.ME])

    [http://arxiv.org/abs/2307.06424](http://arxiv.org/abs/2307.06424)

    本论文提出了基于多模态Laplace近似的贝叶斯变分推断的鲁棒可扩展初始化方法，以应对在高度非高斯行为中，包括多峰性时，“均场”高斯分布近似过于限制性的问题。

    

    在依赖贝叶斯反演的预测建模中，通常使用完全独立或“均场”高斯分布作为变分推断中的近似概率密度函数，因为变分参数的数量是未知模型参数数量的两倍。由于具有对角协方差结构和单峰行为，当处理高度非高斯行为时，包括多峰性时，这种方法可能过于限制性。形式上为高斯混合物的高保真代理后验分布能够以任意精度捕获任何分布，同时仍保留一定的分析可追踪性。具有完全协方差结构的高斯混合物的变分推断随着模型参数数量的增加而出现变分参数的二次增长。由于与变分推断常常相关的损失函数中非凸趋势引起的多个局部极小值的存在，这些挑战促使需要进行鲁棒可扩展初始化。

    For predictive modeling relying on Bayesian inversion, fully independent, or ``mean-field'', Gaussian distributions are often used as approximate probability density functions in variational inference since the number of variational parameters is twice the number of unknown model parameters. The resulting diagonal covariance structure coupled with unimodal behavior can be too restrictive when dealing with highly non-Gaussian behavior, including multimodality. High-fidelity surrogate posteriors in the form of Gaussian mixtures can capture any distribution to an arbitrary degree of accuracy while maintaining some analytical tractability. Variational inference with Gaussian mixtures with full-covariance structures suffers from a quadratic growth in variational parameters with the number of model parameters. Coupled with the existence of multiple local minima due to nonconvex trends in the loss functions often associated with variational inference, these challenges motivate the need for ro
    
[^15]: 在贝叶斯网络中测试稀疏性假设

    Testing Sparsity Assumptions in Bayesian Networks. (arXiv:2307.06406v1 [stat.ML])

    [http://arxiv.org/abs/2307.06406](http://arxiv.org/abs/2307.06406)

    本论文研究了在贝叶斯网络中测试稀疏性假设的问题，并提出了一种基于样本特征值的假设检验方法，可以帮助选择适当的结构发现算法。

    

    贝叶斯网络（BN）结构发现算法通常要么对真正的底层网络稀疏性做出假设，要么受到计算限制而仅适用于具有少量变量的网络。尽管这些稀疏性假设可以采取多种形式，但通常假设集中在底层图的最大入度上限$\nabla_G$。Duttweiler等人（2023）的定理2证明了线性BN的标准化逆协方差矩阵$\Omega$的最大特征值是$\nabla_G$的一个下界。在此结果的基础上，本文提供了$\Omega$样本特征值的渐近性质和去偏过程，从而得到了一种假设检验，可以用来确定BN的最大入度是否大于1。建议在线性BN结构发现工作流中使用此假设检验来辅助选择适当的结构发现算法。

    Bayesian network (BN) structure discovery algorithms typically either make assumptions about the sparsity of the true underlying network, or are limited by computational constraints to networks with a small number of variables. While these sparsity assumptions can take various forms, frequently the assumptions focus on an upper bound for the maximum in-degree of the underlying graph $\nabla_G$. Theorem 2 in Duttweiler et. al. (2023) demonstrates that the largest eigenvalue of the normalized inverse covariance matrix ($\Omega$) of a linear BN is a lower bound for $\nabla_G$. Building on this result, this paper provides the asymptotic properties of, and a debiasing procedure for, the sample eigenvalues of $\Omega$, leading to a hypothesis test that may be used to determine if the BN has max in-degree greater than 1. A linear BN structure discovery workflow is suggested in which the investigator uses this hypothesis test to aid in selecting an appropriate structure discovery algorithm. Th
    
[^16]: 具有谱偏差和内核-任务对齐的物理信息神经网络

    Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks. (arXiv:2307.06362v1 [stat.ML])

    [http://arxiv.org/abs/2307.06362](http://arxiv.org/abs/2307.06362)

    本文提出了一个综合的理论框架，解决了物理信息神经网络（PINN）设计和训练协议的选择问题。通过将超参数化神经网络和高斯过程回归等价起来，推导出了一种在大数据集限制下决定PINN预测的积分微分方程，以及通过原始微分方程中源项的谱分解来量化网络引入的隐含偏差。

    

    物理信息神经网络（PINN）是解决微分方程的一种有前景的新方法。与许多其他深度学习方法一样，PINN的设计和训练协议的选择需要精心制定。在这里，我们提出了一个综合的理论框架，对这个重要问题进行了阐述。通过利用超参数化神经网络和高斯过程回归（GPR）之间的等价性，我们推导出一种在大数据集限制下决定PINN预测的积分微分方程——神经信息方程（NIE）。该方程通过反映架构选择的内核项来补充原始方程，并通过原始微分方程中源项的谱分解来量化网络引入的隐含偏差。

    Physically informed neural networks (PINNs) are a promising emerging method for solving differential equations. As in many other deep learning approaches, the choice of PINN design and training protocol requires careful craftsmanship. Here, we suggest a comprehensive theoretical framework that sheds light on this important problem. Leveraging an equivalence between infinitely over-parameterized neural networks and Gaussian process regression (GPR), we derive an integro-differential equation that governs PINN prediction in the large data-set limit -- the Neurally-Informed Equation (NIE). This equation augments the original one by a kernel term reflecting architecture choices and allows quantifying implicit bias induced by the network via a spectral decomposition of the source term in the original differential equation.
    
[^17]: balance -- 一个用于平衡有偏数据样本的Python软件包

    balance -- a Python package for balancing biased data samples. (arXiv:2307.06024v1 [stat.CO])

    [http://arxiv.org/abs/2307.06024](http://arxiv.org/abs/2307.06024)

    balance是一个用于分析和调整有偏数据样本的Python软件包，通过评估初始偏差、根据倾向分数产生权重校正数据以及评估拟合权重后的偏差和方差膨胀来提供功能。

    

    调查是一种重要的研究工具，可以提供关于情感和意见等主观体验的独特测量，这些测量无法通过其他方式进行。然而，由于调查数据是从自愿参与的人群中收集的，直接从中推断出对所关注的人群或者训练机器学习模型，可能会导致错误的估计或者性能下降的模型。本文介绍了一个开源的Python软件包balance，它由Meta开发，提供一个简单的工作流程来分析和校正有偏数据样本，使其相对于所关注的人群具有平衡性。balance工作流程包括三个步骤：了解数据的初始偏差，根据倾向分数为样本中的每个单位产生权重以校正偏差，以及在应用拟合权重后评估最终偏差和方差膨胀。该软件包提供了一个简单的API，可以用于...

    Surveys are an important research tool, providing unique measurements on subjective experiences such as sentiment and opinions that cannot be measured by other means. However, because survey data is collected from a self-selected group of participants, directly inferring insights from it to a population of interest, or training ML models on such data, can lead to erroneous estimates or under-performing models. In this paper we present balance, an open-source Python package by Meta, offering a simple workflow for analyzing and adjusting biased data samples with respect to a population of interest.  The balance workflow includes three steps: understanding the initial bias in the data relative to a target we would like to infer, adjusting the data to correct for the bias by producing weights for each unit in the sample based on propensity scores, and evaluating the final biases and the variance inflation after applying the fitted weights. The package provides a simple API that can be used
    
[^18]: 贝叶斯紧系数样条估计模式的数量

    Bayesian taut splines for estimating the number of modes. (arXiv:2307.05825v1 [stat.ME])

    [http://arxiv.org/abs/2307.05825](http://arxiv.org/abs/2307.05825)

    本研究提出了一种贝叶斯紧系数样条方法，用于估计概率密度函数中模式的数量。该方法结合了核估计器和组合样条，实现了特征探索、模型选择和模式检验，并允许引入专家判断。通过在体育分析中的案例研究中的验证，证明了该方法的实用性。

    

    概率密度函数中模式的数量代表模型的复杂性，也可以看作现有亚群体的数量。尽管其相关性，对其估计的研究非常有限。我们针对单变量情况提出一个新颖的方法，致力于预测准确性，受到了问题的一些被忽视的方面的启发。我们认为解决方案需要结构，模式的主观且不确定性，以及融合全局和局部密度特性的整体视图的便利性。我们的方法结合了灵活的核估计器和简洁的组合样条。特征探索、模型选择和模式检验都在贝叶斯推理范式中实现，为软解决方案提供了便利，并允许在过程中引入专家判断。我们的提议的实用性通过在体育分析中的案例研究中进行了验证，并展示了多个陪伴的可视化。

    The number of modes in a probability density function is representative of the model's complexity and can also be viewed as the number of existing subpopulations. Despite its relevance, little research has been devoted to its estimation. Focusing on the univariate setting, we propose a novel approach targeting prediction accuracy inspired by some overlooked aspects of the problem. We argue for the need for structure in the solutions, the subjective and uncertain nature of modes, and the convenience of a holistic view blending global and local density properties. Our method builds upon a combination of flexible kernel estimators and parsimonious compositional splines. Feature exploration, model selection and mode testing are implemented in the Bayesian inference paradigm, providing soft solutions and allowing to incorporate expert judgement in the process. The usefulness of our proposal is illustrated through a case study in sports analytics, showcasing multiple companion visualisation 
    
[^19]: 理解不确定性采样

    Understanding Uncertainty Sampling. (arXiv:2307.02719v1 [cs.LG])

    [http://arxiv.org/abs/2307.02719](http://arxiv.org/abs/2307.02719)

    本研究通过系统研究流式和池式主动学习下的不确定性采样算法，提出了一个等效损失的概念，并证明不确定性采样算法实质上是针对该等效损失进行优化。

    

    不确定性采样是一种常见的主动学习算法，它顺序地查询当前预测模型对数据样本的不确定性。然而，不确定性采样的使用往往是启发式的：（i）关于在特定任务和特定损失函数下对“不确定性”的准确定义没有共识；（ii）没有理论保证能够给出一个标准协议来实施该算法，例如，在随机梯度下降等优化算法框架下如何处理顺序到达的注释数据。在本研究中，我们系统地研究了流式和池式主动学习下的不确定性采样算法。我们提出了一个等效损失的概念，该概念取决于使用的不确定性度量和原始损失函数，并确立了不确定性采样算法本质上是针对这种等效损失进行优化。这一观点验证了算法的适当性。

    Uncertainty sampling is a prevalent active learning algorithm that queries sequentially the annotations of data samples which the current prediction model is uncertain about. However, the usage of uncertainty sampling has been largely heuristic: (i) There is no consensus on the proper definition of "uncertainty" for a specific task under a specific loss; (ii) There is no theoretical guarantee that prescribes a standard protocol to implement the algorithm, for example, how to handle the sequentially arrived annotated data under the framework of optimization algorithms such as stochastic gradient descent. In this work, we systematically examine uncertainty sampling algorithms under both stream-based and pool-based active learning. We propose a notion of equivalent loss which depends on the used uncertainty measure and the original loss function and establish that an uncertainty sampling algorithm essentially optimizes against such an equivalent loss. The perspective verifies the properne
    
[^20]: 具有状态相关噪声的加速随机逼近

    Accelerated stochastic approximation with state-dependent noise. (arXiv:2307.01497v1 [math.OC])

    [http://arxiv.org/abs/2307.01497](http://arxiv.org/abs/2307.01497)

    该论文研究了一类具有状态相关噪声的随机平滑凸优化问题。通过引入两种非欧几里得加速随机逼近算法，实现了在精度、问题参数和小批量大小方面的最优性。

    

    我们考虑具有一般噪声假设的随机平滑凸优化问题的一类问题，在这些问题中，随机梯度观测的噪声的方差与算法产生的近似解的"亚最优性" 相关。这类问题在多种应用中自然而然地出现，特别是在统计学中的广义线性回归问题中。然而，据我们所知，现有的解决这类问题的随机逼近算法在精度、问题参数和小批量大小的依赖性方面都未达到最优。我们讨论了两种非欧几里得加速随机逼近算法——随机加速梯度下降（SAGD）和随机梯度外推（SGE）——它们具有一种特殊的对偶关系

    We consider a class of stochastic smooth convex optimization problems under rather general assumptions on the noise in the stochastic gradient observation. As opposed to the classical problem setting in which the variance of noise is assumed to be uniformly bounded, herein we assume that the variance of stochastic gradients is related to the "sub-optimality" of the approximate solutions delivered by the algorithm. Such problems naturally arise in a variety of applications, in particular, in the well-known generalized linear regression problem in statistics. However, to the best of our knowledge, none of the existing stochastic approximation algorithms for solving this class of problems attain optimality in terms of the dependence on accuracy, problem parameters, and mini-batch size.  We discuss two non-Euclidean accelerated stochastic approximation routines--stochastic accelerated gradient descent (SAGD) and stochastic gradient extrapolation (SGE)--which carry a particular duality rela
    
[^21]: 非均匀抽样下网络数据中符合性预测的有效性研究

    On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])

    [http://arxiv.org/abs/2306.07252](http://arxiv.org/abs/2306.07252)

    研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性

    

    我们研究了针对常见非代表性节点采样机制下的网络数据符合性预测的性质。我们将这些采样机制解释为应用于超总体的选择规则，并在适当的选择事件条件下研究符合性预测的有效性。我们证明了，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则采样子阵列在选择事件条件下是可交换的。我们的结果意味着对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性。我们还表明，当数据通过图上的随机游走来采样时，加权符合性预测的变体可以对人口独立选择节点的预测集进行渐近有效的预测。

    We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
    
[^22]: 基于消息传递的图神经网络在大规模随机图上的通用聚合收敛性研究

    Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])

    [http://arxiv.org/abs/2304.11140](http://arxiv.org/abs/2304.11140)

    本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。

    

    本文研究了消息传递图神经网络在随机图模型上的收敛性，当节点数量趋近于无限时，该网络模型能收敛于其连续模型。迄今为止，该收敛性结果只适用于聚合函数采用度规范化平均值形式的网络结构。我们将此结果扩展到包含所有传统消息传递图神经网络的大类聚合函数上，例如基于注意力和最大卷积的网络。在一定假设下，我们给出了高概率的非渐进上限来量化这种收敛性。我们的主要结果基于McDiarmid不等式。有趣的是，我们特别处理了聚合函数采用逐个坐标最大值的情况，因为它需要非常不同的证明技巧，并产生了定性不同的收敛率。

    We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
    
[^23]: 从时间-顶点谱学习图ARMA过程

    Learning Graph ARMA Processes from Time-Vertex Spectra. (arXiv:2302.06887v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.06887](http://arxiv.org/abs/2302.06887)

    本研究提出了一种基于学习过程谱密度的算法，用于推断缺失的信号值和进行信号插值，实验结果显示其在时间-顶点信号估计问题中具有高准确性。

    

    将时间变化的图信号建模为稳态时间-顶点随机过程，可以通过有效地利用过程在不同图节点和时间瞬间之间的相关性模式来推断缺失的信号值。在这项研究中，我们提出了一种算法，用于基于学习过程的不完整实现的联合时间-顶点功率谱密度来计算图自回归移动平均（图ARMA）过程，以用于信号插值任务。我们的解决方案首先通过部分观察到的实现粗略估计过程的联合谱，然后通过凸松弛将其投影到图ARMA过程的谱流形上来改进这个估计。然后，基于学习的模型估计最初缺失的信号值。实验结果表明，所提出的方法在时间-顶点信号估计问题中达到了很高的准确度。

    The modeling of time-varying graph signals as stationary time-vertex stochastic processes permits the inference of missing signal values by efficiently employing the correlation patterns of the process across different graph nodes and time instants. In this study, we propose an algorithm for computing graph autoregressive moving average (graph ARMA) processes based on learning the joint time-vertex power spectral density of the process from its incomplete realizations for the task of signal interpolation. Our solution relies on first roughly estimating the joint spectrum of the process from partially observed realizations and then refining this estimate by projecting it onto the spectrum manifold of the graph ARMA process through convex relaxations. The initially missing signal values are then estimated based on the learnt model. Experimental results show that the proposed approach achieves high accuracy in time-vertex signal estimation problems.
    
[^24]: 鲁棒的在线主动学习策略

    Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00422](http://arxiv.org/abs/2302.00422)

    本文提出了一种自适应方法，用于鲁棒的在线主动学习，并在受污染的数据流中证明了其性能表现优异，同时确保了稳定性并减少异常值的负面影响。

    

    在许多工业应用中，获得标记的观测数据并不简单，通常需要人工专家干预或使用昂贵的测试设备。在这种情况下，主动学习可以大大提高拟合模型时最信息数据点的建议。减少模型开发所需的观测数据数量可以减轻训练所需的计算负担和标记相关的操作支出。特别是在线主动学习，在需要在极短时间内决定是否获取数据点标记的高容量生产过程中非常有用。然而，尽管最近致力于开发在线主动学习策略，但在存在异常值的情况下这些方法的行为仍未得到彻底研究。在这项工作中，我们调查了在线主动线性回归在受污染的数据流中的性能，并提出了一种自适应方法，用于鲁棒的在线主动学习，同时保证稳定性并减少异常值的负面影响。

    In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
    
[^25]: 比较贝叶斯层次模型的深度学习方法

    A Deep Learning Method for Comparing Bayesian Hierarchical Models. (arXiv:2301.11873v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.11873](http://arxiv.org/abs/2301.11873)

    这个论文提出了一种深度学习方法，用于比较贝叶斯层次模型。该方法通过支持分摊推断，能够高效地进行模型比较和性能验证。同时，作者还对四个层次证据积累模型进行了比较。

    

    贝叶斯模型比较（BMC）提供了一种基于原则的方法来评估竞争计算模型的相对优势，并将不确定性传播到模型选择决策中。然而，由于高维嵌套参数结构，BMC在常见的层次模型中常常难以计算。为了解决这个难题，我们提出了一种深度学习方法，用于对任何可实例化为概率程序的层次模型集进行BMC。由于我们的方法支持分摊推断，它可以在任何实际数据应用之前，对后验模型概率进行高效的重新估计和快速性能验证。在一系列广泛的验证研究中，我们对比了我们的方法与最先进的桥式抽样方法的性能，并展示了在所有BMC设置中出色的分摊推断能力。然后，我们展示了我们的方法，通过比较先前被认为是四个层次证据积累模型。

    Bayesian model comparison (BMC) offers a principled approach for assessing the relative merits of competing computational models and propagating uncertainty into model selection decisions. However, BMC is often intractable for the popular class of hierarchical models due to their high-dimensional nested parameter structure. To address this intractability, we propose a deep learning method for performing BMC on any set of hierarchical models which can be instantiated as probabilistic programs. Since our method enables amortized inference, it allows efficient re-estimation of posterior model probabilities and fast performance validation prior to any real-data application. In a series of extensive validation studies, we benchmark the performance of our method against the state-of-the-art bridge sampling method and demonstrate excellent amortized inference across all BMC settings. We then showcase our method by comparing four hierarchical evidence accumulation models that have previously b
    
[^26]: 对抗性策略战胜超级人类级围棋AI

    Adversarial Policies Beat Superhuman Go AIs. (arXiv:2211.00241v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00241](http://arxiv.org/abs/2211.00241)

    通过对抗性策略攻击，我们成功战胜了超级人类级围棋AI KataGo，揭示了其核心弱点，并展示了即使是超级AI系统也可能存在意想不到的失败模式。

    

    我们通过训练对抗性策略来攻击最先进的围棋AI系统KataGo，在超人类设置下取得了超过97%的胜率。我们的对手并不是通过出色地下围棋来获胜，而是通过诱使KataGo犯下严重失误。我们的攻击可以零损耗地传输给其他超级人类级围棋AI，并且对人类专家来说是可以理解的，他们可以在没有算法辅助的情况下实施这种攻击来持续战胜超级人类级AI。我们的攻击揭示了KataGo的核心弱点，即使是对抗性训练的KataGo代理也无法防御我们的攻击。我们的研究结果表明，即使是超级人类级的AI系统也可能存在意想不到的失败模式。

    We attack the state-of-the-art Go-playing AI system KataGo by training adversarial policies against it, achieving a >97% win rate against KataGo running at superhuman settings. Our adversaries do not win by playing Go well. Instead, they trick KataGo into making serious blunders. Our attack transfers zero-shot to other superhuman Go-playing AIs, and is comprehensible to the extent that human experts can implement it without algorithmic assistance to consistently beat superhuman AIs. The core vulnerability uncovered by our attack persists even in KataGo agents adversarially trained to defend against our attack. Our results demonstrate that even superhuman AI systems may harbor surprising failure modes. Example games are available https://goattack.far.ai/.
    
[^27]: 基于核斯坦检验的顺序模型适配性检验

    A kernel Stein test of goodness of fit for sequential models. (arXiv:2210.10741v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.10741](http://arxiv.org/abs/2210.10741)

    我们提出了一种基于核斯坦检验的适配性度量方法，可以适用于具有不同维度观测的概率密度模型，包括文本文档或可变长度序列。这种方法扩展了核斯坦差异(KSD)到可变维度设置，并提出了一种新颖的KSD适配性检验方法，无需密度归一化，并在离散顺序数据基准上表现良好。

    

    我们提出了一种适用于具有不同维度观测的概率密度模型的适配性度量方法，例如具有不同长度或可变长度序列的文本文档。我们提出的度量方法是核斯坦差异(Kernel Stein Discrepancy, KSD)的一个实例，KSD已被用于构建非标准化密度的适配性检验。KSD通过斯坦算子来定义，目前用于检验的斯坦算子适用于固定维度空间。作为我们的主要贡献，我们通过识别合适的斯坦算子，在可变维度设置下扩展了KSD，并提出了一种新颖的KSD适配性检验方法。与之前的变体一样，我们提出的KSD不要求密度归一化，可以评估大量的模型。我们的测试在离散顺序数据基准上表现良好。

    We propose a goodness-of-fit measure for probability densities modeling observations with varying dimensionality, such as text documents of differing lengths or variable-length sequences. The proposed measure is an instance of the kernel Stein discrepancy (KSD), which has been used to construct goodness-of-fit tests for unnormalized densities. The KSD is defined by its Stein operator: current operators used in testing apply to fixed-dimensional spaces. As our main contribution, we extend the KSD to the variable-dimension setting by identifying appropriate Stein operators, and propose a novel KSD goodness-of-fit test. As with the previous variants, the proposed KSD does not require the density to be normalized, allowing the evaluation of a large class of models. Our test is shown to perform well in practice on discrete sequential data benchmarks.
    
[^28]: 多重检验框架用于离群分布检测

    Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.09522](http://arxiv.org/abs/2206.09522)

    本研究提出了一个多重检验框架用于离群分布检测的问题，包括了定义OOD概念和提供强有力保证的方法，与之前的基于阈值的测试相比，在不同类型的OOD实例中表现更一致。

    

    我们研究离群分布（OOD）检测的问题，即在推理时检测学习算法的输出是否可信。尽管之前的工作中提出了一些OOD检测的测试方法，但缺乏一个形式化的框架来研究这个问题。我们提出了一个OOD概念的定义，包括输入分布和学习算法，这为构建强大的OOD检测测试提供了启示。我们提出了一种多重假设检验启发的过程，使用符合性p值系统地结合学习算法中的任意数量的不同统计量。我们进一步对将入群样本错误分类为OOD的概率提供了强有力的保证。在实验中，我们发现之前工作中提出的基于阈值的测试在特定场景下表现良好，但在不同类型的OOD实例中的表现并不一致。相比之下，我们提出的方法结合了m个不同统计量。

    We study the problem of Out-of-Distribution (OOD) detection, that is, detecting whether a learning algorithm's output can be trusted at inference time. While a number of tests for OOD detection have been proposed in prior work, a formal framework for studying this problem is lacking. We propose a definition for the notion of OOD that includes both the input distribution and the learning algorithm, which provides insights for the construction of powerful tests for OOD detection. We propose a multiple hypothesis testing inspired procedure to systematically combine any number of different statistics from the learning algorithm using conformal p-values. We further provide strong guarantees on the probability of incorrectly classifying an in-distribution sample as OOD. In our experiments, we find that threshold-based tests proposed in prior work perform well in specific settings, but not uniformly well across different types of OOD instances. In contrast, our proposed method that combines m
    
[^29]: 适应具有马尔可夫数据的随机优化中的混合时间

    Adapting to Mixing Time in Stochastic Optimization with Markovian Data. (arXiv:2202.04428v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.04428](http://arxiv.org/abs/2202.04428)

    本文提出了一种适用于马尔可夫数据的随机优化问题的方法，不需要对混合时间有任何了解，但在凸问题中可以获得最优收敛速度。这种方法还可以应用于非凸优化以及时差学习，并且完全无视混合时间。方法的关键是多层蒙特卡洛梯度估计与自适应学习方法的组合。

    

    我们考虑数据从马尔可夫链中提取的随机优化问题。现有的这种设置的方法关键依赖于对链的混合时间的了解，而在实际应用中通常是未知的。我们提出了一种不需要了解混合时间的最优化方法，但在应用于凸问题时可以获得最优的渐近收敛速度。我们进一步展示了我们的方法可以扩展到：(i)寻找非凸优化中的稳定点以及(ii)在时差学习中获得对混合时间更好的依赖。在这两种情况下，我们的方法对混合时间完全无视。我们的方法依赖于多层蒙特卡洛(MLMC)梯度估计与自适应学习方法的新颖组合。

    We consider stochastic optimization problems where data is drawn from a Markov chain. Existing methods for this setting crucially rely on knowing the mixing time of the chain, which in real-world applications is usually unknown. We propose the first optimization method that does not require the knowledge of the mixing time, yet obtains the optimal asymptotic convergence rate when applied to convex problems. We further show that our approach can be extended to: (i) finding stationary points in non-convex optimization with Markovian data, and (ii) obtaining better dependence on the mixing time in temporal difference (TD) learning; in both cases, our method is completely oblivious to the mixing time. Our method relies on a novel combination of multi-level Monte Carlo (MLMC) gradient estimation together with an adaptive learning method.
    
[^30]: 新颖方向上对象泛化的新兴神经网络机制

    Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations. (arXiv:2109.13445v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.13445](http://arxiv.org/abs/2109.13445)

    本研究提供了证据表明，深度神经网络具有通过传播方向不变性来泛化到新颖方向上的对象的能力。这种能力受到训练中使用的熟悉对象数量的影响，但仅限于涉及2D旋转的熟悉方向。

    

    深度神经网络（DNNs）在识别训练数据分布之外的方向上的对象的能力尚不完全了解。我们提供证据表明，DNNs能够通过传播从多个视点观察到的熟悉对象获得的方向不变性来泛化到新颖方向上的对象。这种能力在训练DNN时使用越来越多的熟悉对象时会增强，但仅限于涉及到熟悉方向的2D旋转的方向。我们展示了这种传播是通过调整到熟悉和不熟悉对象之间共同特征的神经元实现的。这些结果揭示了类脑神经机制的泛化能力。

    The capability of Deep Neural Networks (DNNs) to recognize objects in orientations outside the distribution of the training data is not well understood. We present evidence that DNNs are capable of generalizing to objects in novel orientations by disseminating orientation-invariance obtained from familiar objects seen from many viewpoints. This capability strengthens when training the DNN with an increasing number of familiar objects, but only in orientations that involve 2D rotations of familiar orientations. We show that this dissemination is achieved via neurons tuned to common features between familiar and unfamiliar objects. These results implicate brain-like neural mechanisms for generalization.
    
[^31]: 在网络中学习低秩潜在中尺度结构

    Learning low-rank latent mesoscale structures in networks. (arXiv:2102.06984v5 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2102.06984](http://arxiv.org/abs/2102.06984)

    这项研究提出了一种学习网络中低秩潜在中尺度结构的新方法，并通过合成网络模型和实际网络验证了其有效性。通过利用少量的“潜在模式”，可以成功地近似网络的大多数子图。这项研究对于理解复杂系统的行为具有重要意义。

    

    在复杂系统中，常常使用网络来编码实体之间的相互作用的体系结构，包括物理、生物、社会和信息科学。为了研究复杂系统的大规模行为，有必要研究网络中的中尺度结构作为影响这种行为的构建块。我们提出了一种描述网络中低秩潜在中尺度结构的新方法，并且通过使用几个合成网络模型和实证友谊、合作和蛋白质相互作用（PPI）网络来说明我们的方法。我们发现，这些网络具有一个相对较小数量的“潜在模式”，这些模式共同可以成功地近似网络的大多数子图在固定的中尺度上。我们使用了一种“网络字典学习”（NDL）的算法，该算法结合了网络采样方法和非负矩阵分解，以学习给定网络的潜在模式。

    It is common to use networks to encode the architecture of interactions between entities in complex systems in the physical, biological, social, and information sciences. To study the large-scale behavior of complex systems, it is useful to examine mesoscale structures in networks as building blocks that influence such behavior. We present a new approach for describing low-rank mesoscale structures in networks, and we illustrate our approach using several synthetic network models and empirical friendship, collaboration, and protein--protein interaction (PPI) networks. We find that these networks possess a relatively small number of `latent motifs' that together can successfully approximate most subgraphs of a network at a fixed mesoscale. We use an algorithm for `network dictionary learning' (NDL), which combines a network-sampling method and nonnegative matrix factorization, to learn the latent motifs of a given network. The ability to encode a network using a set of latent motifs has
    
[^32]: 张量补全的实用性研究

    Tensor Completion Made Practical. (arXiv:2006.03134v2 [cs.DS] CROSS LISTED)

    [http://arxiv.org/abs/2006.03134](http://arxiv.org/abs/2006.03134)

    本文提出了一种新的变种交替最小化算法，针对张量补全问题，具有强有力的可靠保证，同时在处理高度相关因子时仍能线性收敛到真实张量，并且具有极高的实用性。

    

    张量补全是对矩阵补全的高阶推广，其目标是从对其项的稀疏观测中恢复出低秩张量。现有的算法要么是启发式的，没有可靠的保证；要么基于求解大型半定规划问题，不可行；或者是需要强假设，例如要求因子近似正交。本文引入了一种新的交替最小化变种，受到了理解交替最小化在矩阵情况下的收敛指标如何适应张量情况的启发。我们提供了强有力的可靠保证，包括证明了即使在因子高度相关的情况下，我们的算法也能线性收敛到真实张量，并且几乎可以在线性时间内实现。此外，我们的算法也非常实用，我们展示了我们可以从观测到的微小信息中补全千维度的三阶张量。

    Tensor completion is a natural higher-order generalization of matrix completion where the goal is to recover a low-rank tensor from sparse observations of its entries. Existing algorithms are either heuristic without provable guarantees, based on solving large semidefinite programs which are impractical to run, or make strong assumptions such as requiring the factors to be nearly orthogonal. In this paper we introduce a new variant of alternating minimization, which in turn is inspired by understanding how the progress measures that guide convergence of alternating minimization in the matrix setting need to be adapted to the tensor setting. We show strong provable guarantees, including showing that our algorithm converges linearly to the true tensors even when the factors are highly correlated and can be implemented in nearly linear time. Moreover our algorithm is also highly practical and we show that we can complete third order tensors with a thousand dimensions from observing a tiny
    
[^33]: 从一个单一的视频演示中学习模仿的方法

    Towards Learning to Imitate from a Single Video Demonstration. (arXiv:1901.07186v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1901.07186](http://arxiv.org/abs/1901.07186)

    本研究提出了一种从单一视频演示中学习模仿的方法，通过使用对比训练和Siamese循环神经网络，我们能够学习到智能体的行为与演示之间的奖励函数，并通过 RL 策略的训练最小化这个距离。实验表明，引入多任务数据和额外的图像编码损失可以改善学习到的奖励的时间一致性，并显著提高策略学习的效果。我们在不同维度的仿真智能体上验证了我们的方法的优越性。

    

    能够从视频观察中学习模仿的智能体——\emph{没有直接访问状态或动作信息}，对于在自然世界中的学习更具适用性。然而，制定一个能够实现此目标的增强学习（RL）智能体仍然是一个重大挑战。我们使用对比训练来解决这个挑战，学习一个将智能体的行为与单个演示进行比较的奖励函数。我们使用连体循环神经网络架构在时间和空间上学习动作片段之间的奖励，同时训练一个RL策略来最小化这个距离。通过实验证明，多任务数据和额外的图像编码损失的引入改进了学习到的奖励的时间一致性，从而显着提高了策略学习的效果。我们在2D中的模拟人型、狗和迅猛龙智能体以及3D中的四足动物和人型智能体上展示了我们的方法。我们展示了我们的方法优于当前最先进的状态。

    Agents that can learn to imitate given video observation -- \emph{without direct access to state or action information} are more applicable to learning in the natural world. However, formulating a reinforcement learning (RL) agent that facilitates this goal remains a significant challenge. We approach this challenge using contrastive training to learn a reward function comparing an agent's behaviour with a single demonstration. We use a Siamese recurrent neural network architecture to learn rewards in space and time between motion clips while training an RL policy to minimize this distance. Through experimentation, we also find that the inclusion of multi-task data and additional image encoding losses improve the temporal consistency of the learned rewards and, as a result, significantly improves policy learning. We demonstrate our approach on simulated humanoid, dog, and raptor agents in 2D and a quadruped and a humanoid in 3D. We show that our method outperforms current state-of-the-
    

