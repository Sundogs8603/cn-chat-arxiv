# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive Questioning.](http://arxiv.org/abs/2308.08427) | 本文提出了一个新的方法，通过交互式问答来识别代理人的风险规避。在一期情景和无限期情景下，我们通过要求代理人展示她的最优策略来回答问题，使用随机设计的问题来识别代理人的风险规避。这个方法可以通过一个有限的候选集有效地识别出代理人的风险规避。 |
| [^2] | [Continuous Sweep: an improved, binary quantifier.](http://arxiv.org/abs/2308.08387) | Continuous Sweep是一种改进的二元量化器，通过使用参数化类别分布、优化决策边界以及计算均值等方法，它在量化学习中取得了更好的性能。 |
| [^3] | [Convergence of Two-Layer Regression with Nonlinear Units.](http://arxiv.org/abs/2308.08358) | 本研究研究了两层非线性单元回归的收敛性，提出了一个softmax ReLU回归问题，并证明了Hessian的性质，引入了基于近似牛顿法的贪婪算法，最后证明了收敛性。 |
| [^4] | [Warped geometric information on the optimisation of Euclidean functions.](http://arxiv.org/abs/2308.08305) | 使用扭曲几何学的概念，我们提出了一种在高维欧几里德空间中优化函数的方法，并通过在重新定义的黎曼流形上进行计算，找到了函数的最优解。 |
| [^5] | [Two Phases of Scaling Laws for Nearest Neighbor Classifiers.](http://arxiv.org/abs/2308.08247) | 最近邻分类器的缩放律可分为两个阶段：第一阶段中，泛化误差多项式地依赖于数据维度并迅速减小；第二阶段中，误差指数地依赖于数据维度并缓慢减小。这表明最近邻分类器在数据分布良好时可以实现泛化误差多项式地依赖于数据维度，而不是指数地依赖于数据维度。 |
| [^6] | [Deep Generative Imputation Model for Missing Not At Random Data.](http://arxiv.org/abs/2308.08158) | 本文介绍了一种用于处理非随机缺失数据的深度生成填充模型，提出了一种从新的角度去处理这个问题的方法，并且通过实验证明了直接将统计方法纳入深度生成模型的次优之处。 |
| [^7] | [Max-affine regression via first-order methods.](http://arxiv.org/abs/2308.08070) | 本文研究了最大仿射回归问题，并提出了基于梯度下降和随机梯度下降的收敛分析方法。数值实验验证了理论结果的有效性。该方法在运行时间和观测次数较少时都能取得较好的效果。 |
| [^8] | [Robust Bayesian Tensor Factorization with Zero-Inflated Poisson Model and Consensus Aggregation.](http://arxiv.org/abs/2308.08060) | 本文提出了一种鲁棒的贝叶斯张量分解方法，使用零膨胀泊松模型来处理包含过多零值的高维计数数据。为了解决随机性问题，引入了一致聚合的方法。在合成和真实数据集上的实验证明了该方法的优越性能。 |
| [^9] | [Simple online learning with consistency oracle.](http://arxiv.org/abs/2308.08055) | 该论文介绍了在只能通过一致性预言机访问类的模型下的在线学习算法，提出了一种更简单且效果更好的算法。该算法最多会犯O(256^d)个错误，并观察到不存在一个最多会犯2^(d+1)-2个错误的算法。 |
| [^10] | [Regret Lower Bounds in Multi-agent Multi-armed Bandit.](http://arxiv.org/abs/2308.08046) | 在多智能体多臂赌博机中，我们首次全面研究了后悔下界，并证明了在具有良好连通性属性和随机分布奖励的情况下，存在紧密的实例相关和实例无关的下界。 |
| [^11] | [Classification of Data Generated by Gaussian Mixture Models Using Deep ReLU Networks.](http://arxiv.org/abs/2308.08030) | 本文研究了如何使用深度ReLU神经网络在没有对模型参数施加限制的情况下，对由高斯混合模型生成的无界数据进行二分类。我们首次获得了收敛速度不受维度诅咒影响的非渐近上界，并通过使用高斯分布的特性在无限域上进行了分类分析。 |
| [^12] | [Potential Energy Advantage of Quantum Economy.](http://arxiv.org/abs/2308.08025) | 量子计算在能源效率方面具有优势，并且能够在盈利和能源效率上超越经典计算。这使得量子计算成为计算行业更可持续的选择。 |
| [^13] | [Monte Carlo guided Diffusion for Bayesian linear inverse problems.](http://arxiv.org/abs/2308.07983) | 本研究提出了一种在贝叶斯框架下利用蒙特卡洛方法解决非完备线性逆问题的算法，该算法通过利用基于得分的生成模型的先验结构和Feynman-Kac模型，并进行顺序蒙特卡洛采样，表现出比竞争对手更好的性能。 |
| [^14] | [SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation.](http://arxiv.org/abs/2308.07896) | SciRE-Solver是一种高效的采样器，通过引入得分积分求解器和递归导数估计方法，它解决了扩散概率模型采样过程缓慢的挑战，并实现了最先进的采样性能。 |
| [^15] | [Multiclass Learnability Does Not Imply Sample Compression.](http://arxiv.org/abs/2308.06424) | 学习二元假设类具有样本压缩方案，而多类别假设类则不具备这个性质。 |
| [^16] | [Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation.](http://arxiv.org/abs/2308.06422) | 本研究引入了一种创新的深度神经网络优化方法，通过自动选择最佳的位宽和层宽来提高网络效率。同时，通过剪枝和聚类技术，优化了搜索过程，并在多个数据集上进行了严格测试，结果显示该方法明显优于现有方法。 |
| [^17] | [Variational Latent Discrete Representation for Time Series Modelling.](http://arxiv.org/abs/2306.15282) | 本文介绍了一种变分潜在离散表示模型，其中离散状态采用马尔可夫链，并在建筑管理数据集和电力变压器数据集上进行了性能评估。 |
| [^18] | [Latent Dynamical Implicit Diffusion Processes.](http://arxiv.org/abs/2306.07077) | 本文提出了一种新型的潜在变量模型 LDIDPs，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本，相较于最先进的顺序生成模型有更好的性能。 |
| [^19] | [Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection.](http://arxiv.org/abs/2306.05989) | 本文提出了一种名为QBSD的实时预测方法，以在时间序列异常检测中取得最佳平衡。 |
| [^20] | [How does over-squashing affect the power of GNNs?.](http://arxiv.org/abs/2306.03589) | 本文通过测量节点之间成对交互的水平，提供了严格的分析，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。结果表明，为了保证节点对之间的充分通信，MPNN的容量必须是... |
| [^21] | [Are demographically invariant models and representations in medical imaging fair?.](http://arxiv.org/abs/2305.01397) | 医学影像模型编码患者人口统计信息，引发有关潜在歧视的担忧。研究表明，不编码人口属性的模型容易损失预测性能，而考虑人口统计属性的反事实模型不变性存在复杂性。人口统计学编码可以被认为是优势。 |
| [^22] | [Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification.](http://arxiv.org/abs/2301.11562) | 在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。 |
| [^23] | [Conformal Frequency Estimation using Discrete Sketched Data with Coverage for Distinct Queries.](http://arxiv.org/abs/2211.04612) | 本文开发了一种基于离散草图数据的一致性频率估计方法，可以构建查询对象在大规模离散数据集中频率的置信区间。通过新颖的一致性校准技术，提供了对数据的离散性和异质查询频率的更强推断，并具有鲁棒性。 |
| [^24] | [Learning Ability of Interpolating Deep Convolutional Neural Networks.](http://arxiv.org/abs/2210.14184) | 本文研究了深度卷积神经网络（DCNNs）在欠参数和过参数设置下的学习能力，建立了欠参数DCNNs的学习速度，并通过一种新颖的网络加深方案获得了插值DCNN，从而验证了过拟合的DCNN的泛化性能。 |
| [^25] | [Diffusion Models for Graphs Benefit From Discrete State Spaces.](http://arxiv.org/abs/2210.01549) | 本论文提出了一种在生成离散图时使用离散噪声的方法，相比于之前的方法，实验证明使用离散噪声可以生成更高质量的样本，同时采样过程速度提高了30倍。 |
| [^26] | [Unbiased Estimation using Underdamped Langevin Dynamics.](http://arxiv.org/abs/2206.07202) | 本研究提出了一种使用欠阻尼 Langevin 动力学进行无偏估计的方法，旨在对具有非负密度的概率测度进行估计，通过使用离散化版本的动力学和双重随机估计方案，消除了离散化偏差和有限次运行动力学产生的偏差。 |
| [^27] | [Time-uniform central limit theory and asymptotic confidence sequences.](http://arxiv.org/abs/2103.06476) | 本论文介绍了时间均匀的渐近置信序列的方法，这些序列在时间上是统一有效的，能够在任意停止时间进行有效推断，并填补了现有文献中非渐近置信序列与渐近置信区间之间的空白。 |

# 详细

[^1]: 借助交互式问答通过逆强化学习来引导风险规避

    Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive Questioning. (arXiv:2308.08427v1 [stat.ML])

    [http://arxiv.org/abs/2308.08427](http://arxiv.org/abs/2308.08427)

    本文提出了一个新的方法，通过交互式问答来识别代理人的风险规避。在一期情景和无限期情景下，我们通过要求代理人展示她的最优策略来回答问题，使用随机设计的问题来识别代理人的风险规避。这个方法可以通过一个有限的候选集有效地识别出代理人的风险规避。

    

    本文提出了一个新颖的框架，利用交互式问答来识别代理人的风险规避。我们的研究在两种情景中进行：一期情景和无限期情景。在一期情景中，我们假设代理人的风险规避由状态的成本函数和失真风险度量所表征。在无限期情景中，我们用一个额外的成分，折扣因子，来建模风险规避。假设我们可以访问一个包含代理人真实风险规避的有限候选集，我们证明通过要求代理人在各种环境中展示她的最优政策来回答问题，这可以有效地识别代理人的风险规避。具体而言，我们证明了当问题的数量趋近无穷大并且问题是随机设计的时候，可以识别出代理人的风险规避。我们还开发了一个算法用于设计最优问题，并提供了实证证据来支持我们的方法。

    This paper proposes a novel framework for identifying an agent's risk aversion using interactive questioning. Our study is conducted in two scenarios: a one-period case and an infinite horizon case. In the one-period case, we assume that the agent's risk aversion is characterized by a cost function of the state and a distortion risk measure. In the infinite horizon case, we model risk aversion with an additional component, a discount factor. Assuming the access to a finite set of candidates containing the agent's true risk aversion, we show that asking the agent to demonstrate her optimal policies in various environment, which may depend on their previous answers, is an effective means of identifying the agent's risk aversion. Specifically, we prove that the agent's risk aversion can be identified as the number of questions tends to infinity, and the questions are randomly designed. We also develop an algorithm for designing optimal questions and provide empirical evidence that our met
    
[^2]: Continuous Sweep: 一种改进的二元量化器

    Continuous Sweep: an improved, binary quantifier. (arXiv:2308.08387v1 [stat.ML])

    [http://arxiv.org/abs/2308.08387](http://arxiv.org/abs/2308.08387)

    Continuous Sweep是一种改进的二元量化器，通过使用参数化类别分布、优化决策边界以及计算均值等方法，它在量化学习中取得了更好的性能。

    

    量化是一种监督式机器学习任务，其关注的是估计数据集中类别的普遍性，而不是标记其个体观测。我们引入了Continuous Sweep，这是一种新的参数化二元量化器，受到表现良好的Median Sweep的启发。Median Sweep目前是最好的二元量化器之一，但我们在三个方面改变了这个量化器，即1）使用参数化的类别分布而不是经验分布，2）优化决策边界而不是应用离散的决策规则，3）计算均值而不是中位数。在一般模型假设下，我们推导了Continuous Sweep的偏差和方差的解析表达式。这是量化学习领域中的首次理论贡献之一。此外，这些推导使我们能够找到最优的决策边界。最后，我们的模拟研究表明，在广泛的情况下，Continuous Sweep优于Median Sweep。

    Quantification is a supervised machine learning task, focused on estimating the class prevalence of a dataset rather than labeling its individual observations. We introduce Continuous Sweep, a new parametric binary quantifier inspired by the well-performing Median Sweep. Median Sweep is currently one of the best binary quantifiers, but we have changed this quantifier on three points, namely 1) using parametric class distributions instead of empirical distributions, 2) optimizing decision boundaries instead of applying discrete decision rules, and 3) calculating the mean instead of the median. We derive analytic expressions for the bias and variance of Continuous Sweep under general model assumptions. This is one of the first theoretical contributions in the field of quantification learning. Moreover, these derivations enable us to find the optimal decision boundaries. Finally, our simulation study shows that Continuous Sweep outperforms Median Sweep in a wide range of situations.
    
[^3]: 两层非线性单元回归的收敛性研究

    Convergence of Two-Layer Regression with Nonlinear Units. (arXiv:2308.08358v1 [cs.LG])

    [http://arxiv.org/abs/2308.08358](http://arxiv.org/abs/2308.08358)

    本研究研究了两层非线性单元回归的收敛性，提出了一个softmax ReLU回归问题，并证明了Hessian的性质，引入了基于近似牛顿法的贪婪算法，最后证明了收敛性。

    

    大型语言模型（LLMs），如ChatGPT和GPT4，在许多人类生活任务中表现出色。注意力计算在训练LLMs中起着重要作用。Softmax单元和ReLU单元是注意力计算的关键结构。受到它们的启发，我们提出了一个softmax ReLU回归问题。总的来说，我们的目标是找到涉及ReLU单元的回归问题的最优解。在这项工作中，我们计算了损失函数的Hessian的闭合形式表示。在一定的假设下，我们证明了Hessian的Lipschitz连续性和PSD性质。然后，我们引入了基于近似牛顿法的贪婪算法，该算法在距离最优解的意义下收敛。最后，我们放宽了Lipschitz条件，并证明了在损失值的意义下的收敛性。

    Large language models (LLMs), such as ChatGPT and GPT4, have shown outstanding performance in many human life task. Attention computation plays an important role in training LLMs. Softmax unit and ReLU unit are the key structure in attention computation. Inspired by them, we put forward a softmax ReLU regression problem. Generally speaking, our goal is to find an optimal solution to the regression problem involving the ReLU unit. In this work, we calculate a close form representation for the Hessian of the loss function. Under certain assumptions, we prove the Lipschitz continuous and the PSDness of the Hessian. Then, we introduce an greedy algorithm based on approximate Newton method, which converges in the sense of the distance to optimal solution. Last, We relax the Lipschitz condition and prove the convergence in the sense of loss value.
    
[^4]: 在欧几里德函数优化中的扭曲几何信息

    Warped geometric information on the optimisation of Euclidean functions. (arXiv:2308.08305v1 [stat.ML])

    [http://arxiv.org/abs/2308.08305](http://arxiv.org/abs/2308.08305)

    使用扭曲几何学的概念，我们提出了一种在高维欧几里德空间中优化函数的方法，并通过在重新定义的黎曼流形上进行计算，找到了函数的最优解。

    

    我们考虑了在潜在高维欧几里德空间中优化实值函数的基本任务，例如许多机器学习任务中的损失函数或统计推断中的概率分布的对数。我们使用扭曲黎曼几何概念，将欧几里德空间上的函数优化问题重新定义为一个带有扭曲度量的黎曼流形，并在该流形上找到函数的最优解。选择用于搜索域的扭曲度量引入了一个计算友好的度量张量，使得在流形上找到最优搜索方向与测地线变得更容易计算。沿测地线进行优化通常是不可行的，但我们表明在这个特定的流形中，我们可以解析地得到高达三阶的泰勒近似。一般情况下，这些对测地线的近似不会位于流形上，但我们构造了合适的回缩方程将这些近似重新映射到流形上。

    We consider the fundamental task of optimizing a real-valued function defined in a potentially high-dimensional Euclidean space, such as the loss function in many machine-learning tasks or the logarithm of the probability distribution in statistical inference. We use the warped Riemannian geometry notions to redefine the optimisation problem of a function on Euclidean space to a Riemannian manifold with a warped metric, and then find the function's optimum along this manifold. The warped metric chosen for the search domain induces a computational friendly metric-tensor for which optimal search directions associate with geodesic curves on the manifold becomes easier to compute. Performing optimization along geodesics is known to be generally infeasible, yet we show that in this specific manifold we can analytically derive Taylor approximations up to third-order. In general these approximations to the geodesic curve will not lie on the manifold, however we construct suitable retraction m
    
[^5]: 最近邻分类器的两个阶段的缩放律

    Two Phases of Scaling Laws for Nearest Neighbor Classifiers. (arXiv:2308.08247v1 [stat.ML])

    [http://arxiv.org/abs/2308.08247](http://arxiv.org/abs/2308.08247)

    最近邻分类器的缩放律可分为两个阶段：第一阶段中，泛化误差多项式地依赖于数据维度并迅速减小；第二阶段中，误差指数地依赖于数据维度并缓慢减小。这表明最近邻分类器在数据分布良好时可以实现泛化误差多项式地依赖于数据维度，而不是指数地依赖于数据维度。

    

    缩放律是指当训练数据数量增加时，模型的测试性能会提高的观察结果。快速的缩放律意味着通过增加数据和模型大小就能解决机器学习问题。然而，在许多情况下，增加更多数据的好处可能是微不足道的。在本研究中，我们研究了最近邻分类器的缩放律。我们发现缩放律可能有两个阶段：在第一阶段，泛化误差多项式地依赖于数据维度并且快速减小；而在第二阶段，误差指数地依赖于数据维度并且减小得慢。我们的分析突显了数据分布在决定泛化误差中的复杂性。当数据分布良好时，我们的结果表明最近邻分类器可以实现泛化误差多项式地依赖于数据维度，而不是指数地依赖于数据维度。

    A scaling law refers to the observation that the test performance of a model improves as the number of training data increases. A fast scaling law implies that one can solve machine learning problems by simply boosting the data and the model sizes. Yet, in many cases, the benefit of adding more data can be negligible. In this work, we study the rate of scaling laws of nearest neighbor classifiers. We show that a scaling law can have two phases: in the first phase, the generalization error depends polynomially on the data dimension and decreases fast; whereas in the second phase, the error depends exponentially on the data dimension and decreases slowly. Our analysis highlights the complexity of the data distribution in determining the generalization error. When the data distributes benignly, our result suggests that nearest neighbor classifier can achieve a generalization error that depends polynomially, instead of exponentially, on the data dimension.
    
[^6]: 深度生成填充模型用于非随机缺失数据

    Deep Generative Imputation Model for Missing Not At Random Data. (arXiv:2308.08158v1 [cs.LG])

    [http://arxiv.org/abs/2308.08158](http://arxiv.org/abs/2308.08158)

    本文介绍了一种用于处理非随机缺失数据的深度生成填充模型，提出了一种从新的角度去处理这个问题的方法，并且通过实验证明了直接将统计方法纳入深度生成模型的次优之处。

    

    数据分析通常面临非随机缺失（MNAR）问题，其中缺失值的原因没有完全观察到。与简单的完全随机缺失（MCAR）问题相比，这更符合实际情况，也更复杂和具有挑战性。现有的统计方法通过不同的完整数据和缺失蒙版的联合分布分解来建模MNAR机制。但我们在经验上发现，直接将这些统计方法纳入深度生成模型是次优的。具体来说，它会忽视MNAR填充过程中重构蒙版的置信度，导致信息提取不足和填充质量不够可靠。在本文中，我们从一种新的角度重新审视MNAR问题，即完整数据和缺失蒙版是两个不完整数据的模态。沿着这条线，我们提出了一种生成模型特定的联合预测框架

    Data analysis usually suffers from the Missing Not At Random (MNAR) problem, where the cause of the value missing is not fully observed. Compared to the naive Missing Completely At Random (MCAR) problem, it is more in line with the realistic scenario whereas more complex and challenging. Existing statistical methods model the MNAR mechanism by different decomposition of the joint distribution of the complete data and the missing mask. But we empirically find that directly incorporating these statistical methods into deep generative models is sub-optimal. Specifically, it would neglect the confidence of the reconstructed mask during the MNAR imputation process, which leads to insufficient information extraction and less-guaranteed imputation quality. In this paper, we revisit the MNAR problem from a novel perspective that the complete data and missing mask are two modalities of incomplete data on an equal footing. Along with this line, we put forward a generative-model-specific joint pr
    
[^7]: 最大仿射回归及其一阶方法

    Max-affine regression via first-order methods. (arXiv:2308.08070v1 [stat.ML])

    [http://arxiv.org/abs/2308.08070](http://arxiv.org/abs/2308.08070)

    本文研究了最大仿射回归问题，并提出了基于梯度下降和随机梯度下降的收敛分析方法。数值实验验证了理论结果的有效性。该方法在运行时间和观测次数较少时都能取得较好的效果。

    

    本文考虑了最大仿射模型的回归问题，该模型通过使用最大化函数将仿射模型组合成分段线性模型。最大仿射模型广泛应用于信号处理和统计学中，包括多类别分类、拍卖问题和凸回归。它还推广了相位恢复和学习整流线性单元激活函数。我们对梯度下降（GD）和小批量随机梯度下降（SGD）方法在最大仿射回归中的非渐近收敛性进行了分析，假设模型以随机位置观测，遵循次高斯分布和具有加性次高斯噪声的反浓度。在这些假设下，适当初始化的GD和SGD能够线性收敛到由相应误差界限确定的目标区域附近。我们提供了与理论发现相一致的数值结果。值得注意的是，SGD不仅在运行时间上收敛更快，而且在观测次数较少时也能获得较好的效果。

    We consider regression of a max-affine model that produces a piecewise linear model by combining affine models via the max function. The max-affine model ubiquitously arises in applications in signal processing and statistics including multiclass classification, auction problems, and convex regression. It also generalizes phase retrieval and learning rectifier linear unit activation functions. We present a non-asymptotic convergence analysis of gradient descent (GD) and mini-batch stochastic gradient descent (SGD) for max-affine regression when the model is observed at random locations following the sub-Gaussianity and an anti-concentration with additive sub-Gaussian noise. Under these assumptions, a suitably initialized GD and SGD converge linearly to a neighborhood of the ground truth specified by the corresponding error bound. We provide numerical results that corroborate the theoretical finding. Importantly, SGD not only converges faster in run time with fewer observations than alt
    
[^8]: 鲁棒贝叶斯张量分解与零膨胀泊松模型和一致聚合

    Robust Bayesian Tensor Factorization with Zero-Inflated Poisson Model and Consensus Aggregation. (arXiv:2308.08060v1 [stat.ML])

    [http://arxiv.org/abs/2308.08060](http://arxiv.org/abs/2308.08060)

    本文提出了一种鲁棒的贝叶斯张量分解方法，使用零膨胀泊松模型来处理包含过多零值的高维计数数据。为了解决随机性问题，引入了一致聚合的方法。在合成和真实数据集上的实验证明了该方法的优越性能。

    

    张量分解是一种用于高效表示和分析多维数据的强大工具。然而，传统的基于最大似然估计的张量分解方法在应用于包含过多零值的计数数据（如单细胞RNA测序数据）时表现不佳。此外，张量分解的随机性导致因子在多次运行中变化，使得结果的解释和重现具有挑战性。本文提出了一种新颖的方法，称为零膨胀泊松张量分解（ZIPTF），用于分解具有过多零值的高维计数数据。为了解决随机性挑战，我们引入了一种称为一致零膨胀泊松张量分解（C-ZIPTF）的方法，将ZIPTF与基于一致性的元分析相结合。我们在合成的零膨胀计数数据和合成的真实单细胞RNA测序数据上评估了我们提出的ZIPTF和C-ZIPTF方法。结果显示，ZIPTF方法在性能上始终优于基线矩阵和张量分解方法。

    Tensor factorizations (TF) are powerful tools for the efficient representation and analysis of multidimensional data. However, classic TF methods based on maximum likelihood estimation underperform when applied to zero-inflated count data, such as single-cell RNA sequencing (scRNA-seq) data. Additionally, the stochasticity inherent in TFs results in factors that vary across repeated runs, making interpretation and reproducibility of the results challenging. In this paper, we introduce Zero Inflated Poisson Tensor Factorization (ZIPTF), a novel approach for the factorization of high-dimensional count data with excess zeros. To address the challenge of stochasticity, we introduce Consensus Zero Inflated Poisson Tensor Factorization (C-ZIPTF), which combines ZIPTF with a consensus-based meta-analysis. We evaluate our proposed ZIPTF and C-ZIPTF on synthetic zero-inflated count data and synthetic and real scRNA-seq data. ZIPTF consistently outperforms baseline matrix and tensor factorizatio
    
[^9]: 通过一致性预言机进行简单的在线学习

    Simple online learning with consistency oracle. (arXiv:2308.08055v1 [cs.LG])

    [http://arxiv.org/abs/2308.08055](http://arxiv.org/abs/2308.08055)

    该论文介绍了在只能通过一致性预言机访问类的模型下的在线学习算法，提出了一种更简单且效果更好的算法。该算法最多会犯O(256^d)个错误，并观察到不存在一个最多会犯2^(d+1)-2个错误的算法。

    

    我们考虑在只能通过一致性预言机访问类的模型下的在线学习——在任何时刻，预言机都能给出与目前为止看到的所有示例一致的类函数。该模型最近由Assos等人（COLT'23）考虑。这个模型的动机是标准的在线学习方法依赖于计算子类的Littlestone维度，这是一个计算复杂的问题。Assos等人在这个模型中给出了一个在线学习算法，对于Littlestone维度为d的类，最多会犯C^d个错误，其中C是一个未指定的绝对常数且大于0。我们提出了一个新的算法，最多会犯O(256^d)个错误。我们的证明更简单，只使用了Littlestone维度的基本属性。我们还观察到，不存在一个在这个模型中最多会犯2^(d+1)-2个错误的算法。我们还观察到，我们的算法（以及Assos等人的算法）。

    We consider online learning in the model where a learning algorithm can access the class only via the consistency oracle -- an oracle, that, at any moment, can give a function from the class that agrees with all examples seen so far. This model was recently considered by Assos et al. (COLT'23). It is motivated by the fact that standard methods of online learning rely on computing the Littlestone dimension of subclasses, a problem that is computationally intractable. Assos et al. gave an online learning algorithm in this model that makes at most $C^d$ mistakes on classes of Littlestone dimension $d$, for some absolute unspecified constant $C > 0$. We give a novel algorithm that makes at most $O(256^d)$ mistakes. Our proof is significantly simpler and uses only very basic properties of the Littlestone dimension. We also observe that there exists no algorithm in this model that makes at most $2^{d+1}-2$ mistakes. We also observe that our algorithm (as well as the algorithm of Assos et al.
    
[^10]: 多智能体多臂赌博机中的后悔下界

    Regret Lower Bounds in Multi-agent Multi-armed Bandit. (arXiv:2308.08046v1 [cs.LG])

    [http://arxiv.org/abs/2308.08046](http://arxiv.org/abs/2308.08046)

    在多智能体多臂赌博机中，我们首次全面研究了后悔下界，并证明了在具有良好连通性属性和随机分布奖励的情况下，存在紧密的实例相关和实例无关的下界。

    

    多臂赌博机激发了具有可证明后悔上界的方法，与之对应的后悔下界在这个背景下也被广泛研究。最近，多智能体多臂赌博机在各个领域中得到了显著的关注，其中个体客户以分布式的方式面临着赌博问题，目标是整体系统的性能，通常用后悔来衡量。尽管已经出现了具有后悔上界的高效算法，但对应的后悔下界却没有得到足够的关注，除了最近针对对抗设置的一个下界，然而，它与已知上界有差距。为此，我们在不同的设置下提供了第一次全面研究后悔下界，并建立了它们的紧密性。具体来说，当图表现出良好的连通性属性且奖励随机分布时，我们证明了一阶为$O(\log T)$的实例相关下界和$O(\log T)$的实例无关下界。

    Multi-armed Bandit motivates methods with provable upper bounds on regret and also the counterpart lower bounds have been extensively studied in this context. Recently, Multi-agent Multi-armed Bandit has gained significant traction in various domains, where individual clients face bandit problems in a distributed manner and the objective is the overall system performance, typically measured by regret. While efficient algorithms with regret upper bounds have emerged, limited attention has been given to the corresponding regret lower bounds, except for a recent lower bound for adversarial settings, which, however, has a gap with let known upper bounds. To this end, we herein provide the first comprehensive study on regret lower bounds across different settings and establish their tightness. Specifically, when the graphs exhibit good connectivity properties and the rewards are stochastically distributed, we demonstrate a lower bound of order $O(\log T)$ for instance-dependent bounds and $
    
[^11]: 使用深度ReLU网络对由高斯混合模型生成的数据进行分类

    Classification of Data Generated by Gaussian Mixture Models Using Deep ReLU Networks. (arXiv:2308.08030v1 [stat.ML])

    [http://arxiv.org/abs/2308.08030](http://arxiv.org/abs/2308.08030)

    本文研究了如何使用深度ReLU神经网络在没有对模型参数施加限制的情况下，对由高斯混合模型生成的无界数据进行二分类。我们首次获得了收敛速度不受维度诅咒影响的非渐近上界，并通过使用高斯分布的特性在无限域上进行了分类分析。

    

    本文研究了使用深度ReLU神经网络对由高斯混合模型生成的无界数据进行二分类。我们首次获得了对于没有对模型参数施加限制的分类任务中超出风险（超出错误分类率）的非渐近上界和收敛速率。我们得到的收敛速率不依赖于维度$d$，证明了深度ReLU网络可以克服在分类中的维度诅咒。虽然现有的分类算法的广义分析大多依赖于有界域，但我们通过利用高斯分布的解析性和快速衰减将其应用于无界域。为了便于我们的分析，我们给出了一个使用ReLU网络对一般解析函数的新近似误差界，这可能具有独立的研究价值。高斯分布可以很好地用于建模产生的数据。

    This paper studies the binary classification of unbounded data from ${\mathbb R}^d$ generated under Gaussian Mixture Models (GMMs) using deep ReLU neural networks. We obtain $\unicode{x2013}$ for the first time $\unicode{x2013}$ non-asymptotic upper bounds and convergence rates of the excess risk (excess misclassification error) for the classification without restrictions on model parameters. The convergence rates we derive do not depend on dimension $d$, demonstrating that deep ReLU networks can overcome the curse of dimensionality in classification. While the majority of existing generalization analysis of classification algorithms relies on a bounded domain, we consider an unbounded domain by leveraging the analyticity and fast decay of Gaussian distributions. To facilitate our analysis, we give a novel approximation error bound for general analytic functions using ReLU networks, which may be of independent interest. Gaussian distributions can be adopted nicely to model data arising
    
[^12]: 量子经济的势能优势

    Potential Energy Advantage of Quantum Economy. (arXiv:2308.08025v1 [quant-ph])

    [http://arxiv.org/abs/2308.08025](http://arxiv.org/abs/2308.08025)

    量子计算在能源效率方面具有优势，并且能够在盈利和能源效率上超越经典计算。这使得量子计算成为计算行业更可持续的选择。

    

    随着大规模机器学习模型和语言模型的广泛部署，能源成本越来越关键。对于提供计算服务的公司来说，低能耗对于市场增长和政府法规来说都非常重要。本文研究了量子计算与经典计算之间的能源优势。我们在能源效率的背景下重新定义优势，与仅基于计算复杂性的传统量子优势不同。通过一个以能量使用为约束条件的Cournot竞争模型，我们证明量子计算公司在Nash均衡点上在盈利能力和能源效率方面都能超越经典对手。因此，量子计算可能代表计算行业更可持续的发展路径。此外，我们发现量子计算经济的能源利益取决于大规模计算。

    Energy cost is increasingly crucial in the modern computing industry with the wide deployment of large-scale machine learning models and language models. For the firms that provide computing services, low energy consumption is important both from the perspective of their own market growth and the government's regulations. In this paper, we study the energy benefits of quantum computing vis-a-vis classical computing. Deviating from the conventional notion of quantum advantage based solely on computational complexity, we redefine advantage in an energy efficiency context. Through a Cournot competition model constrained by energy usage, we demonstrate quantum computing firms can outperform classical counterparts in both profitability and energy efficiency at Nash equilibrium. Therefore quantum computing may represent a more sustainable pathway for the computing industry. Moreover, we discover that the energy benefits of quantum computing economies are contingent on large-scale computation
    
[^13]: 蒙特卡洛引导扩散的贝叶斯线性逆问题研究

    Monte Carlo guided Diffusion for Bayesian linear inverse problems. (arXiv:2308.07983v1 [stat.ML])

    [http://arxiv.org/abs/2308.07983](http://arxiv.org/abs/2308.07983)

    本研究提出了一种在贝叶斯框架下利用蒙特卡洛方法解决非完备线性逆问题的算法，该算法通过利用基于得分的生成模型的先验结构和Feynman-Kac模型，并进行顺序蒙特卡洛采样，表现出比竞争对手更好的性能。

    

    非完备的线性逆问题经常在各种应用中出现，从计算摄影到医学成像。最近的研究集中于使用基于得分的生成模型（SGMs），在填补问题中产生具有感知合理性的图像来解决这些问题。本研究利用SGM定义的先验结构来制定贝叶斯框架下的恢复问题，将其作为Feynman-Kac模型，该模型改编自用于构建基于得分扩散的前向扩散模型。为了解决这个Feynman-Kac问题，我们提出使用顺序蒙特卡洛方法。所提出的算法MCGdiff在理论上是有根据的，并且我们提供了数值模拟结果，表明它在处理非完备逆问题时优于竞争对手的基准方法。

    Ill-posed linear inverse problems that combine knowledge of the forward measurement model with prior models arise frequently in various applications, from computational photography to medical imaging. Recent research has focused on solving these problems with score-based generative models (SGMs) that produce perceptually plausible images, especially in inpainting problems. In this study, we exploit the particular structure of the prior defined in the SGM to formulate recovery in a Bayesian framework as a Feynman--Kac model adapted from the forward diffusion model used to construct score-based diffusion. To solve this Feynman--Kac problem, we propose the use of Sequential Monte Carlo methods. The proposed algorithm, MCGdiff, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems.
    
[^14]: SciRE-Solver: 用得分积分求解器和递归导数估计快速采样扩散概率模型

    SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation. (arXiv:2308.07896v1 [stat.ML])

    [http://arxiv.org/abs/2308.07896](http://arxiv.org/abs/2308.07896)

    SciRE-Solver是一种高效的采样器，通过引入得分积分求解器和递归导数估计方法，它解决了扩散概率模型采样过程缓慢的挑战，并实现了最先进的采样性能。

    

    扩散概率模型(DPMs)是一类强大的生成模型，以其生成高保真图像样本的能力而闻名。DPMs的实现面临的主要挑战是采样过程缓慢。在这项工作中，我们提出了一种高效的DPMs采样器。具体而言，我们针对与DPMs采样过程对应的扩散ODE提出了一个基于得分的精确解决方案范式，该范式为求解扩散ODE的数值算法开发提供了新的视角。为了实现高效的采样器，我们提出了一种递归导数估计(RDE)方法来减小估计误差。通过我们提出的解决方案范式和RDE方法，我们提出了具有收敛顺序保证的得分积分求解器(SciRE-Solver)来解决扩散ODEs。SciRE-Solver在离散时间和连续时间DPMs上获得了最先进的采样性能，并且仅需有限数量的得分函数评估(NFE)。

    Diffusion probabilistic models (DPMs) are a powerful class of generative models known for their ability to generate high-fidelity image samples. A major challenge in the implementation of DPMs is the slow sampling process. In this work, we bring a high-efficiency sampler for DPMs. Specifically, we propose a score-based exact solution paradigm for the diffusion ODEs corresponding to the sampling process of DPMs, which introduces a new perspective on developing numerical algorithms for solving diffusion ODEs. To achieve an efficient sampler, we propose a recursive derivative estimation (RDE) method to reduce the estimation error. With our proposed solution paradigm and RDE method, we propose the score-integrand solver with the convergence order guarantee as efficient solver (SciRE-Solver) for solving diffusion ODEs. The SciRE-Solver attains state-of-the-art (SOTA) sampling performance with a limited number of score function evaluations (NFE) on both discrete-time and continuous-time DPMs
    
[^15]: 学习能力与样本压缩并不相同的多类别问题

    Multiclass Learnability Does Not Imply Sample Compression. (arXiv:2308.06424v1 [cs.LG])

    [http://arxiv.org/abs/2308.06424](http://arxiv.org/abs/2308.06424)

    学习二元假设类具有样本压缩方案，而多类别假设类则不具备这个性质。

    

    如果一个假设类能够通过只保留一个小的子样本推断出整个样本的标签，那么它就具有样本压缩方案。学习二元假设类（必须具有有限的VC维度）都可以通过VC维度的一个有限函数大小的样本压缩方案实现。然而，对于多类别假设类来说，DS维度是相对应的，我们发现学习多类别假设类（必须具有有限的DS维度）并不能通过一个DS维度的有限函数大小的样本压缩方案实现。

    A hypothesis class admits a sample compression scheme, if for every sample labeled by a hypothesis from the class, it is possible to retain only a small subsample, using which the labels on the entire sample can be inferred. The size of the compression scheme is an upper bound on the size of the subsample produced. Every learnable binary hypothesis class (which must necessarily have finite VC dimension) admits a sample compression scheme of size only a finite function of its VC dimension, independent of the sample size. For multiclass hypothesis classes, the analog of VC dimension is the DS dimension. We show that the analogous statement pertaining to sample compression is not true for multiclass hypothesis classes: every learnable multiclass hypothesis class, which must necessarily have finite DS dimension, does not admit a sample compression scheme of size only a finite function of its DS dimension.
    
[^16]: 使用基于聚类的树状Parzen估计的敏感性感知混合精度量化和宽度优化的深度神经网络

    Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation. (arXiv:2308.06422v1 [cs.LG])

    [http://arxiv.org/abs/2308.06422](http://arxiv.org/abs/2308.06422)

    本研究引入了一种创新的深度神经网络优化方法，通过自动选择最佳的位宽和层宽来提高网络效率。同时，通过剪枝和聚类技术，优化了搜索过程，并在多个数据集上进行了严格测试，结果显示该方法明显优于现有方法。

    

    随着深度学习模型的复杂性和计算需求的提高，对神经网络设计的有效优化方法的需求变得至关重要。本文引入了一种创新的搜索机制，用于自动选择单个神经网络层的最佳位宽和层宽。这导致深度神经网络效率的明显提高。通过利用基于Hessian的剪枝策略，有选择地减少搜索域，确保移除非关键参数。随后，我们通过使用基于聚类的树状Parzen估计器开发有利和不利结果的替代模型。这种策略允许对架构可能性进行简化的探索，并迅速确定表现最好的设计。通过对知名数据集进行严格测试，我们的方法证明了与现有方法相比的明显优势。与领先的压缩策略相比，我们的方法取得了令人瞩目的成果。

    As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 
    
[^17]: 变分潜在离散表示在时间序列建模中的应用

    Variational Latent Discrete Representation for Time Series Modelling. (arXiv:2306.15282v1 [stat.ML])

    [http://arxiv.org/abs/2306.15282](http://arxiv.org/abs/2306.15282)

    本文介绍了一种变分潜在离散表示模型，其中离散状态采用马尔可夫链，并在建筑管理数据集和电力变压器数据集上进行了性能评估。

    

    最近，离散潜在空间模型在深度变分推断中的性能与其连续对应物相媲美。虽然它们仍然面临各种实现挑战，但这些模型为潜在空间的更好解释提供了机会，同时更直接地表示自然离散现象。最近的一些方法建议分别在离散潜在数据上训练非常高维的先验模型，这本身就是一个具有挑战性的任务。在本文中，我们介绍了一种潜在数据模型，其中离散状态是一个马尔可夫链，它允许快速端到端训练。我们对我们的生成模型在建筑管理数据集和公开可用的电力变压器数据集上进行了性能评估。

    Discrete latent space models have recently achieved performance on par with their continuous counterparts in deep variational inference. While they still face various implementation challenges, these models offer the opportunity for a better interpretation of latent spaces, as well as a more direct representation of naturally discrete phenomena. Most recent approaches propose to train separately very high-dimensional prior models on the discrete latent data which is a challenging task on its own. In this paper, we introduce a latent data model where the discrete state is a Markov chain, which allows fast end-to-end training. The performance of our generative model is assessed on a building management dataset and on the publicly available Electricity Transformer Dataset.
    
[^18]: 潜在动态隐式扩散过程

    Latent Dynamical Implicit Diffusion Processes. (arXiv:2306.07077v1 [cs.LG])

    [http://arxiv.org/abs/2306.07077](http://arxiv.org/abs/2306.07077)

    本文提出了一种新型的潜在变量模型 LDIDPs，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本，相较于最先进的顺序生成模型有更好的性能。

    

    潜在动态模型常被用来学习代表一系列噪声数据样本的潜在动态过程的分布。然而，由于潜在的和观测动态的复杂性和变异性，产生具有高保真度的样本具有挑战性。最近，在基于扩散的生成模型（例如DDPM和NCSN）方面取得的进展，展示了一些有前景的替代方法，适用于从先验分布中生成高质量的序列样本，相较于先进的潜在生成模型（如神经ODE、RNN和正则化流网络）。然而，将它们应用于建模具有潜在动态模型的序列数据尚未被探索。因此，本文提出了一种名为潜在动态隐式扩散过程（LDIDPs）的新型潜在变量模型，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本。我们在合成和模拟神经数据上测试了LDIDPs，并证明它优于最先进的顺序生成模型。

    Latent dynamical models are commonly used to learn the distribution of a latent dynamical process that represents a sequence of noisy data samples. However, producing samples from such models with high fidelity is challenging due to the complexity and variability of latent and observation dynamics. Recent advances in diffusion-based generative models, such as DDPM and NCSN, have shown promising alternatives to state-of-the-art latent generative models, such as Neural ODEs, RNNs, and Normalizing flow networks, for generating high-quality sequential samples from a prior distribution. However, their application in modeling sequential data with latent dynamical models is yet to be explored. Here, we propose a novel latent variable model named latent dynamical implicit diffusion processes (LDIDPs), which utilizes implicit diffusion processes to sample from dynamical latent processes and generate sequential observation samples accordingly. We tested LDIDPs on synthetic and simulated neural d
    
[^19]: 基于四分位数的季节性分解用于时间序列预测和异常检测

    Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection. (arXiv:2306.05989v1 [cs.LG])

    [http://arxiv.org/abs/2306.05989](http://arxiv.org/abs/2306.05989)

    本文提出了一种名为QBSD的实时预测方法，以在时间序列异常检测中取得最佳平衡。

    

    在电信领域，及时检测异常非常重要，因为这有助于识别和表征不规则模式、异常行为和网络异常，从而提高服务质量和操作效率。精确地预测和消除可预测的时间序列模式是时间序列异常检测的重要组成部分。本文提出了一种名为基于四分位数的季节性分解（QBSD）的实时预测方法，以在计算复杂度和预测准确率之间取得最佳平衡。本文比较了QBSD与现有预测方法的性能及其适用性。

    The timely detection of anomalies is essential in the telecom domain as it facilitates the identification and characterization of irregular patterns, abnormal behaviors, and network anomalies, contributing to enhanced service quality and operational efficiency. Precisely forecasting and eliminating predictable time series patterns constitutes a vital component of time series anomaly detection. While the state-of-the-art methods aim to maximize forecasting accuracy, the computational performance takes a hit. In a system composed of a large number of time series variables, e.g., cell Key Performance Indicators (KPIs), the time and space complexity of the forecasting employed is of crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is a live forecasting method proposed in this paper to make an optimal trade-off between computational complexity and forecasting accuracy. This paper compares the performance of QBSD to the state-of-the-art forecasting methods and their applic
    
[^20]: 过度压缩如何影响GNN的能力？

    How does over-squashing affect the power of GNNs?. (arXiv:2306.03589v1 [cs.LG])

    [http://arxiv.org/abs/2306.03589](http://arxiv.org/abs/2306.03589)

    本文通过测量节点之间成对交互的水平，提供了严格的分析，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。结果表明，为了保证节点对之间的充分通信，MPNN的容量必须是...

    

    图神经网络（GNN）是处理图结构数据的机器学习的最先进模型。最流行的GNN类别是通过相邻节点间的信息交换来操作的，称为消息传递神经网络（MPNN）。鉴于它们的广泛应用，了解MPNN的表达能力是一个关键问题。然而，现有结果通常考虑具有无信息节点特征的环境。在本文中，我们提供了一种严格的分析方法，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。我们通过测量MPNN允许的节点之间的成对交互水平来实现此目的。该测量提供了一种新的量化特性，即所谓的过度压缩效应，该效应被观察到是当大量的信息聚合成固定大小的向量时发生的。使用我们的测量，我们证明，为了保证节点对之间的充分通信，MPNN的容量必须是...

    Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). Given their widespread use, understanding the expressive power of MPNNs is a key question. However, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of pairwise interactions between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be l
    
[^21]: 医学影像中的人口统计学不变模型和表示是否公平？

    Are demographically invariant models and representations in medical imaging fair?. (arXiv:2305.01397v1 [cs.LG])

    [http://arxiv.org/abs/2305.01397](http://arxiv.org/abs/2305.01397)

    医学影像模型编码患者人口统计信息，引发有关潜在歧视的担忧。研究表明，不编码人口属性的模型容易损失预测性能，而考虑人口统计属性的反事实模型不变性存在复杂性。人口统计学编码可以被认为是优势。

    

    研究表明，医学成像模型在其潜在表示中编码了有关患者人口统计学信息（年龄、种族、性别），这引发了有关其潜在歧视的担忧。在这里，我们询问是否可行和值得训练不编码人口属性的模型。我们考虑不同类型的与人口统计学属性的不变性，即边际、类条件和反事实模型不变性，并说明它们与算法公平的标准概念的等价性。根据现有理论，我们发现边际和类条件的不变性可被认为是实现某些公平概念的过度限制方法，导致显著的预测性能损失。关于反事实模型不变性，我们注意到对于人口统计学属性，定义医学图像反事实存在复杂性。最后，我们认为人口统计学编码甚至可以被认为是优势。

    Medical imaging models have been shown to encode information about patient demographics (age, race, sex) in their latent representation, raising concerns about their potential for discrimination. Here, we ask whether it is feasible and desirable to train models that do not encode demographic attributes. We consider different types of invariance with respect to demographic attributes marginal, class-conditional, and counterfactual model invariance - and lay out their equivalence to standard notions of algorithmic fairness. Drawing on existing theory, we find that marginal and class-conditional invariance can be considered overly restrictive approaches for achieving certain fairness notions, resulting in significant predictive performance losses. Concerning counterfactual model invariance, we note that defining medical image counterfactuals with respect to demographic attributes is fraught with complexities. Finally, we posit that demographic encoding may even be considered advantageou
    
[^22]: 预测是否随意？在公平分类中评估自洽性

    Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification. (arXiv:2301.11562v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11562](http://arxiv.org/abs/2301.11562)

    在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。

    

    在公平分类中，不同经过训练的模型之间的预测方差是一个重要但鲜为人知的误差来源问题。 实证表明，某些情况下，预测的方差差异非常大，以至于决策实际上是随意的。 为了研究这个问题，我们进行了大规模的实证研究，并做出了四个总体贡献：我们1）定义了一种基于方差的度量标准，称为自洽性，在测量和减少随意性时使用； 2）开发了一种合理的算法，当预测无法做出决策时，可以放弃分类； 3）进行了迄今为止有关公平分类中方差（相对于自洽性和随意性）作用的最大规模实证研究； 4）推出了一个工具包，使美国住房抵押贷款披露法案（HMDA）数据集易于用于未来研究。 总的来说，我们的实证结果揭示了关于可重复性的令人震惊的见解。当考虑到方差和随意预测的可能性时，大多数公平分类基准接近公平。 但是，一小部分实例显示出极大的随意性水平，这表明当前的模型可能无法处理某些类型的数据。

    Variance in predictions across different trained models is a significant, under-explored source of error in fair classification. Empirically, the variance on some instances is so large that decisions can be effectively arbitrary. To study this problem, we perform a large-scale empirical study and make four overarching contributions: We 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance (vis-a-vis self-consistency and arbitrariness) in fair classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily usable for future research. Altogether, our empirical results reveal shocking insights about reproducibility. Most fairness classification benchmarks are close-to-fair when taking into
    
[^23]: 使用离散的草图数据和覆盖率进行一致性频率估计的方法

    Conformal Frequency Estimation using Discrete Sketched Data with Coverage for Distinct Queries. (arXiv:2211.04612v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2211.04612](http://arxiv.org/abs/2211.04612)

    本文开发了一种基于离散草图数据的一致性频率估计方法，可以构建查询对象在大规模离散数据集中频率的置信区间。通过新颖的一致性校准技术，提供了对数据的离散性和异质查询频率的更强推断，并具有鲁棒性。

    

    本文开发了一种一致性推断方法，可以基于具有较小内存占用的草图，构建一个查询对象在大规模离散数据集中频率的置信区间。这种方法不需要对数据分布有任何了解，并且可以与任何草图算法结合使用，包括但不限于著名的count-min草图、count-sketch以及它们的变体。在解释如何实现可交换随机查询的边际覆盖后，我们将我们的解决方案扩展到提供更强的推断，可以考虑数据的离散性和异质查询频率，还增加了对可能的分布转换的鲁棒性。这些结果得益于一种新颖的一致性校准技术，可以保证大部分不同的随机查询具有有效的覆盖率。最后，我们通过模拟实验证明了我们的方法相比于现有的频率派和贝叶斯派替代方法具有更好的经验性能。

    This paper develops conformal inference methods to construct a confidence interval for the frequency of a queried object in a very large discrete data set, based on a sketch with a lower memory footprint. This approach requires no knowledge of the data distribution and can be combined with any sketching algorithm, including but not limited to the renowned count-min sketch, the count-sketch, and variations thereof. After explaining how to achieve marginal coverage for exchangeable random queries, we extend our solution to provide stronger inferences that can account for the discreteness of the data and for heterogeneous query frequencies, increasing also robustness to possible distribution shifts. These results are facilitated by a novel conformal calibration technique that guarantees valid coverage for a large fraction of distinct random queries. Finally, we show our methods have improved empirical performance compared to existing frequentist and Bayesian alternatives in simulations as
    
[^24]: 插值深度卷积神经网络的学习能力

    Learning Ability of Interpolating Deep Convolutional Neural Networks. (arXiv:2210.14184v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.14184](http://arxiv.org/abs/2210.14184)

    本文研究了深度卷积神经网络（DCNNs）在欠参数和过参数设置下的学习能力，建立了欠参数DCNNs的学习速度，并通过一种新颖的网络加深方案获得了插值DCNN，从而验证了过拟合的DCNN的泛化性能。

    

    高参数神经网络往往具有良好的泛化能力。现有的理论工作主要研究了线性设置或全连接神经网络的情况。本文研究了一类重要的深度神经网络，即深度卷积神经网络（DCNNs）在欠参数和过参数设置下的学习能力。我们在文献中首次建立了无参数或函数变量结构限制的欠参数DCNNs的学习速度。我们还表明，通过向非插值DCNN添加良定义的层，可以获得一些保持非插值DCNN良好学习速度的插值DCNN。这一结果是通过为DCNN设计的一种新颖的网络加深方案实现的。我们的工作在理论上验证了过拟合的DCNN如何良好地进行泛化。

    It is frequently observed that overparameterized neural networks generalize well. Regarding such phenomena, existing theoretical work mainly devotes to linear settings or fully-connected neural networks. This paper studies the learning ability of an important family of deep neural networks, deep convolutional neural networks (DCNNs), under both underparameterized and overparameterized settings. We establish the first learning rates of underparameterized DCNNs without parameter or function variable structure restrictions presented in the literature. We also show that by adding well-defined layers to a non-interpolating DCNN, we can obtain some interpolating DCNNs that maintain the good learning rates of the non-interpolating DCNN. This result is achieved by a novel network deepening scheme designed for DCNNs. Our work provides theoretical verification of how overfitted DCNNs generalize well.
    
[^25]: 图的扩散模型受益于离散状态空间

    Diffusion Models for Graphs Benefit From Discrete State Spaces. (arXiv:2210.01549v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01549](http://arxiv.org/abs/2210.01549)

    本论文提出了一种在生成离散图时使用离散噪声的方法，相比于之前的方法，实验证明使用离散噪声可以生成更高质量的样本，同时采样过程速度提高了30倍。

    

    去噪扩散概率模型和评分匹配模型已被证明在生成任务中非常强大。虽然这些方法也被应用于离散图的生成，但迄今为止，它们仍依赖于连续高斯扰动。相反，在本研究中，我们建议使用离散噪声进行前向马尔可夫过程。这确保在每个中间步骤中，图保持离散。与先前的方法相比，我们在四个数据集和多个架构上的实验结果显示，使用离散噪声处理过程生成的样本质量更高，平均 MMDs 降低了1.5倍。此外，去噪步骤的数量从1000减少到32步，导致采样过程速度提高了30倍。

    Denoising diffusion probabilistic models and score-matching models have proven to be very powerful for generative tasks. While these approaches have also been applied to the generation of discrete graphs, they have, so far, relied on continuous Gaussian perturbations. Instead, in this work, we suggest using discrete noise for the forward Markov process. This ensures that in every intermediate step the graph remains discrete. Compared to the previous approach, our experimental results on four datasets and multiple architectures show that using a discrete noising process results in higher quality generated samples indicated with an average MMDs reduced by a factor of 1.5. Furthermore, the number of denoising steps is reduced from 1000 to 32 steps, leading to a 30 times faster sampling procedure.
    
[^26]: 使用欠阻尼 Langevin 动力学进行无偏估计

    Unbiased Estimation using Underdamped Langevin Dynamics. (arXiv:2206.07202v2 [stat.CO] UPDATED)

    [http://arxiv.org/abs/2206.07202](http://arxiv.org/abs/2206.07202)

    本研究提出了一种使用欠阻尼 Langevin 动力学进行无偏估计的方法，旨在对具有非负密度的概率测度进行估计，通过使用离散化版本的动力学和双重随机估计方案，消除了离散化偏差和有限次运行动力学产生的偏差。

    

    在这项工作中，我们考虑了对具有非负 Lebesgue 密度且在归一化常数上已知的概率测度进行无偏估计的问题。我们专注于通过欠阻尼 Langevin 动力学开发一种无偏方法，这种方法近来在统计学和机器学习中得到广泛应用。具体来说，在连续时间下，可以构造这种动力学使其随着时间趋于无穷，其稳态测度为所关注的概率测度。在实践中，经常使用离散化的欠阻尼 Langevin 动力学的时间离散版本，仅运行有限次迭代。我们提出了一种基于双重随机估计的新方案，该方案仅需要使用时间离散版本的动力学。所提出的方案旨在消除离散化偏差和由于有限次运行动力学产生的偏差。

    In this work we consider the unbiased estimation of expectations w.r.t.~probability measures that have non-negative Lebesgue density, and which are known point-wise up-to a normalizing constant. We focus upon developing an unbiased method via the underdamped Langevin dynamics, which has proven to be popular of late due to applications in statistics and machine learning. Specifically in continuous-time, the dynamics can be constructed {so that as the time goes to infinity they} admit the probability of interest as a stationary measure. {In many cases, time-discretized versions of the underdamped Langevin dynamics are used in practice which are run only with a fixed number of iterations.} We develop a novel scheme based upon doubly randomized estimation as in \cite{ub_grad,disc_model}, which requires access only to time-discretized versions of the dynamics. {The proposed scheme aims to remove the dicretization bias and the bias resulting from running the dynamics for a finite number of i
    
[^27]: 时间均匀的中心极限定理和渐近置信序列

    Time-uniform central limit theory and asymptotic confidence sequences. (arXiv:2103.06476v7 [math.ST] UPDATED)

    [http://arxiv.org/abs/2103.06476](http://arxiv.org/abs/2103.06476)

    本论文介绍了时间均匀的渐近置信序列的方法，这些序列在时间上是统一有效的，能够在任意停止时间进行有效推断，并填补了现有文献中非渐近置信序列与渐近置信区间之间的空白。

    

    基于中心极限定理（CLT）的置信区间是经典统计学的基石。尽管只是渐近有效的，但它们普遍存在，因为它们允许在非常弱的假设下进行统计推断，并且通常可以应用于即使非渐近推断也不可能的问题。本文介绍了时间均匀的类似于这样的渐近置信区间。具体而言，我们的方法采用置信序列（CS）的形式 - 置信区间的序列，这些区间在时间上是统一有效的。CS可在任意停止时间进行有效推断，而不需要像经典置信区间那样在先固定样本大小的情况下产生“窥视”数据的惩罚。现有文献中的CS都是非渐近的，因此不能享受渐近置信区间的广泛适用性。我们的工作填补了这一空白，给出了“渐近CS”的定义，并推导出一个通用的渐近置信序列。

    Confidence intervals based on the central limit theorem (CLT) are a cornerstone of classical statistics. Despite being only asymptotically valid, they are ubiquitous because they permit statistical inference under very weak assumptions, and can often be applied to problems even when nonasymptotic inference is impossible. This paper introduces time-uniform analogues of such asymptotic confidence intervals. To elaborate, our methods take the form of confidence sequences (CS) -- sequences of confidence intervals that are uniformly valid over time. CSs provide valid inference at arbitrary stopping times, incurring no penalties for "peeking" at the data, unlike classical confidence intervals which require the sample size to be fixed in advance. Existing CSs in the literature are nonasymptotic, and hence do not enjoy the aforementioned broad applicability of asymptotic confidence intervals. Our work bridges the gap by giving a definition for "asymptotic CSs", and deriving a universal asympto
    

