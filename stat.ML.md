# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Connecting the Dots: Is Mode-Connectedness the Key to Feasible Sample-Based Inference in Bayesian Neural Networks?](https://rss.arxiv.org/abs/2402.01484) | 通过揭示权重和函数空间之间的关系，我们成功实现了贝叶斯神经网络的可行的基于样本推理，并提出了一种有效的贝叶斯深度集成方法来解决采样和收敛问题。 |
| [^2] | [Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes](https://rss.arxiv.org/abs/2402.01476) | 本论文提出了自核-特征对稀疏变分高斯过程（KEP-SVGP）用于构建具有不确定性感知的自注意力。通过核SVD（KSVD）解决了注意力核的不对称性，并实现了降低的复杂度。 |
| [^3] | [Online conformal prediction with decaying step sizes](https://rss.arxiv.org/abs/2402.01139) | 本文介绍了一种在线自适应预测方法，通过使用递减步长来改进在任意序列上的覆盖率保证，并且能够同时估计总体分位数。 |
| [^4] | [A Dynamical Model of Neural Scaling Laws](https://rss.arxiv.org/abs/2402.01092) | 这篇论文提出了一个动力学模型来解释神经缩放定律。通过分析梯度下降训练的随机特征模型，研究发现训练时间和模型大小的缩放具有不同的幂律指数，而计算最优缩放规则要求增加训练步数快于增加模型参数，与实证观察相一致。 |
| [^5] | [On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games](https://arxiv.org/abs/2403.00993) | 明确表示信息结构是分析和解决强化学习问题的重要组成部分。 |
| [^6] | [AdAdaGrad: Adaptive Batch Size Schemes for Adaptive Gradient Methods](https://arxiv.org/abs/2402.11215) | AdAdaGrad和AdAdaGradNorm是一个自适应增加批大小的方法，在深度学习中引入了自适应批大小策略，证明AdaGradNorm以高概率在$O(1/K)$速度下收敛。 |
| [^7] | [Stochastic Localization via Iterative Posterior Sampling](https://arxiv.org/abs/2402.10758) | 本论文提出了一种名为SLIPS的方法，通过迭代后验抽样实现随机定位，填补了从非标准化目标密度中抽样的问题的空白。 |
| [^8] | [Combining Evidence Across Filtrations](https://arxiv.org/abs/2402.09698) | 这篇论文研究了合并使用不同过滤器计算的e进程的方法，探讨了其在顺序推理中的应用。 |
| [^9] | [Weisfeiler-Leman at the margin: When more expressivity matters](https://arxiv.org/abs/2402.07568) | 研究探讨了1-WL算法在图同构问题中的表达能力和泛化性能之间的关系，发现增强的表达能力对提高泛化性能并不总是有效。此外，通过引入子图信息和经典的边缘理论，探索了更高表达力与改进泛化性能的条件。梯度流也被证明可以促进模型学习更丰富的表达能力。 |
| [^10] | [Low-Rank Approximation of Structural Redundancy for Self-Supervised Learning](https://arxiv.org/abs/2402.06884) | 本文研究结构冗余的低秩逼近在自监督学习中的应用，提出了一个逼近冗余组件的新方法，并通过分析过量风险来支持理论。 |
| [^11] | [Towards Understanding Inductive Bias in Transformers: A View From Infinity](https://arxiv.org/abs/2402.05173) | 本文研究了Transformer模型的归纳偏差，并发现它们倾向于对称排列函数，对称群的表示理论可以用于分析预测，同时提出了一个简化模型来解决学习曲线和网络输出，并在常见设置中得出学习能力的紧密边界，最后还证明了WikiText数据集具有排列对称性。 |
| [^12] | [Variational DAG Estimation via State Augmentation With Stochastic Permutations](https://arxiv.org/abs/2402.02644) | 使用状态扩展和随机排列进行变分DAG估计的方法可以超越竞争的贝叶斯和非贝叶斯基准方法，从而在估计贝叶斯网络结构方面取得更好的性能。 |
| [^13] | [Independence Testing for Temporal Data](https://arxiv.org/abs/1908.06486) | 本文介绍了一种适用于测试时序数据之间独立性的时序依赖统计方法，并能够估计最佳依赖滞后。该方法解决了现有方法的限制，并且在测试平稳时间序列之间的独立性时渐近有效和普遍一致，并且与多种依赖度量方法兼容。 |
| [^14] | [Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference.](http://arxiv.org/abs/2310.16705) | 本文将变分推断重新框架为在变分参数空间上的概率分布优化问题，提出了沃瑟斯坦梯度下降方法来解决优化问题，有效性经过实证实验证实。 |
| [^15] | [An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback.](http://arxiv.org/abs/2308.10675) | 提出了一种改进的延迟反馈的强化适应性算法，通过消除先验知识需求和控制分布漂移，该算法在遗憾界限方面具有突出贡献。 |
| [^16] | [Graph Automorphism Group Equivariant Neural Networks.](http://arxiv.org/abs/2307.07810) | 本论文提供了图自同态群等变神经网络的完整特征化，找到了可学习的、线性的层函数之间的矩阵的生成集。 |
| [^17] | [Causal Discovery using Bayesian Model Selection.](http://arxiv.org/abs/2306.02931) | 对于具有现实假设的数据集，本文提出了使用贝叶斯模型选择进行因果推断的方法，使得确定因果方向变成了一个模型选择问题。使用实际数据集验证了本方法优于现有方法。 |
| [^18] | [Plug-in Performative Optimization.](http://arxiv.org/abs/2305.18728) | 研究了一种可能“规范不正确”模型的通用协议，“插件式表现优化”。 |
| [^19] | [Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts.](http://arxiv.org/abs/2302.06495) | 本文提出了一种称为Density-Softmax的快速确定性方法，通过将密度函数与softmax结合来提高分布变化下的校准不确定性估计，具有较高的效率和可行性 |

# 详细

[^1]: 连接点：模式连接是否是贝叶斯神经网络可行的基于样本推理的关键？

    Connecting the Dots: Is Mode-Connectedness the Key to Feasible Sample-Based Inference in Bayesian Neural Networks?

    [https://rss.arxiv.org/abs/2402.01484](https://rss.arxiv.org/abs/2402.01484)

    通过揭示权重和函数空间之间的关系，我们成功实现了贝叶斯神经网络的可行的基于样本推理，并提出了一种有效的贝叶斯深度集成方法来解决采样和收敛问题。

    

    在贝叶斯神经网络的基于样本推理（SBI）中，网络参数空间的大小和结构是一个主要挑战。我们的研究表明，通过接受权重和函数空间之间的特征关系，成功实现SBI是可能的，揭示了过度参数化和采样问题困难之间的系统联系。通过大量实验，我们建立了采样和收敛诊断的实际指南。因此，我们提出了一种贝叶斯深度集成方法作为一种有效的解决方案，具有竞争性能和不确定性量化能力。

    A major challenge in sample-based inference (SBI) for Bayesian neural networks is the size and structure of the networks' parameter space. Our work shows that successful SBI is possible by embracing the characteristic relationship between weight and function space, uncovering a systematic link between overparameterization and the difficulty of the sampling problem. Through extensive experiments, we establish practical guidelines for sampling and convergence diagnosis. As a result, we present a Bayesian deep ensemble approach as an effective solution with competitive performance and uncertainty quantification.
    
[^2]: 自核-特征对稀疏变分高斯过程中的自注意力

    Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes

    [https://rss.arxiv.org/abs/2402.01476](https://rss.arxiv.org/abs/2402.01476)

    本论文提出了自核-特征对稀疏变分高斯过程（KEP-SVGP）用于构建具有不确定性感知的自注意力。通过核SVD（KSVD）解决了注意力核的不对称性，并实现了降低的复杂度。

    

    尽管Transformer具有显著提高预测准确性的能力，但它也可能产生过于自信的预测，并需要校准的不确定性估计，这通常可以通过高斯过程（GPs）来解决。现有的工作将对称核应用于变分推断下的注意力核；然而，忽略了注意力核本质上是不对称的事实。此外，推导出大规模数据的GP后验的复杂度仍然很高。在这项工作中，我们提出了一种用于构建具有不确定性感知的自注意力的核-特征对稀疏变 分高斯过程（KEP-SVGP），其中通过核SVD（KSVD）解决了注意力核的不对称性，并获得了降低的复杂度。通过KEP-SVGP，i）由于与注意力核的KSVD相对应的两组奇异向量引导的SVGP对完全表征了不对称性；ii）仅使用少量与KSVD相对应的伴随特征函数，推导SVGP后验概率密度可以实现较低的复杂度。

    While the great capability of Transformers significantly boosts prediction accuracy, it could also yield overconfident predictions and require calibrated uncertainty estimation, which can be commonly tackled by Gaussian processes (GPs). Existing works apply GPs with symmetric kernels under variational inference to the attention kernel; however, omitting the fact that attention kernels are in essence asymmetric. Moreover, the complexity of deriving the GP posteriors remains high for large-scale data. In this work, we propose Kernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for building uncertainty-aware self-attention where the asymmetry of attention kernels is tackled by Kernel SVD (KSVD) and a reduced complexity is acquired. Through KEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors from KSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) using only a small set of adjoint eigenfunctions from KSVD, the derivation of SVGP posteri
    
[^3]: 在线自适应预测方法中带有递减步长

    Online conformal prediction with decaying step sizes

    [https://rss.arxiv.org/abs/2402.01139](https://rss.arxiv.org/abs/2402.01139)

    本文介绍了一种在线自适应预测方法，通过使用递减步长来改进在任意序列上的覆盖率保证，并且能够同时估计总体分位数。

    

    本文介绍一种带有递减步长的在线自适应预测方法。和之前的方法一样，我们的方法也能在任意序列上回溯性地保证覆盖率。然而，与之前的方法不同的是，我们能够在存在的情况下同时估计出总体分位数。我们的理论和实验证明了显著改进的实际特性：特别是在分布稳定的情况下，覆盖率接近所期望的水平，不仅仅在观测序列的平均值上。

    We introduce a method for online conformal prediction with decaying step sizes. Like previous methods, ours possesses a retrospective guarantee of coverage for arbitrary sequences. However, unlike previous methods, we can simultaneously estimate a population quantile when it exists. Our theory and experiments indicate substantially improved practical properties: in particular, when the distribution is stable, the coverage is close to the desired level for every time point, not just on average over the observed sequence.
    
[^4]: 神经缩放定律的动力学模型

    A Dynamical Model of Neural Scaling Laws

    [https://rss.arxiv.org/abs/2402.01092](https://rss.arxiv.org/abs/2402.01092)

    这篇论文提出了一个动力学模型来解释神经缩放定律。通过分析梯度下降训练的随机特征模型，研究发现训练时间和模型大小的缩放具有不同的幂律指数，而计算最优缩放规则要求增加训练步数快于增加模型参数，与实证观察相一致。

    

    在各种任务中，神经网络的性能随着训练时间、数据集大小和模型大小的增加而预测性地提高，跨多个数量级。这种现象被称为神经缩放定律。最重要的是计算最优缩放定律，它报告了在选择最佳模型大小时性能与计算数量的关系。我们分析了一个通过梯度下降进行训练和泛化的随机特征模型作为网络训练和泛化的可解模型。这个模型复现了关于神经缩放定律的许多观察结果。首先，我们的模型对于为什么训练时间和模型大小的缩放具有不同的幂律指数提出了一个预测。因此，理论预测了一种不对称的计算最优缩放规则，其中训练步数的增加速度快于模型参数的增加速度，与最近的实证观察一致。其次，观察到在训练的早期，网络会收敛到无限宽度情况下的结果。

    On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-wi
    
[^5]: 论部分可观察序列团队和游戏中信息结构在强化学习中的作用

    On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games

    [https://arxiv.org/abs/2403.00993](https://arxiv.org/abs/2403.00993)

    明确表示信息结构是分析和解决强化学习问题的重要组成部分。

    

    在顺序决策问题中，信息结构描述了系统中不同时刻事件如何相互影响。本文主张明确表示信息结构是分析和解决强化学习问题的重要组成部分，并提出具有明确信息结构表示的新型强化学习模型。

    arXiv:2403.00993v1 Announce Type: cross  Abstract: In a sequential decision-making problem, the information structure is the description of how events in the system occurring at different points in time affect each other. Classical models of reinforcement learning (e.g., MDPs, POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular information structure, while more general models like predictive state representations do not explicitly model the information structure. By contrast, real-world sequential decision-making problems typically involve a complex and time-varying interdependence of system variables, requiring a rich and flexible representation of information structure.   In this paper, we argue for the perspective that explicit representation of information structures is an important component of analyzing and solving reinforcement learning problems. We propose novel reinforcement learning models with an explicit representation of information structure, capturing 
    
[^6]: AdAdaGrad：自适应梯度方法的自适应批大小方案

    AdAdaGrad: Adaptive Batch Size Schemes for Adaptive Gradient Methods

    [https://arxiv.org/abs/2402.11215](https://arxiv.org/abs/2402.11215)

    AdAdaGrad和AdAdaGradNorm是一个自适应增加批大小的方法，在深度学习中引入了自适应批大小策略，证明AdaGradNorm以高概率在$O(1/K)$速度下收敛。

    

    随机梯度优化器中批量大小的选择对模型训练至关重要。然而，在训练过程中变化批大小的实践相对其他超参数较少探讨。我们研究了从自适应采样方法中导出的自适应批大小策略，传统上仅应用于随机梯度下降。考虑到学习速率和批大小之间的显著相互作用，以及自适应梯度方法在深度学习中的普及，我们强调在这些情境中需要自适应批大小策略。我们介绍了AdAdaGrad及其标量变体AdAdaGradNorm，它们在训练过程中逐渐增加批大小，同时使用AdaGrad和AdaGradNorm进行模型更新。我们证明了AdaGradNorm以高概率以$O(1/K)$的速度收敛，用于找到光滑非凸函数的一阶稳定点在$K$次迭代内。

    arXiv:2402.11215v1 Announce Type: new  Abstract: The choice of batch sizes in stochastic gradient optimizers is critical for model training. However, the practice of varying batch sizes throughout the training process is less explored compared to other hyperparameters. We investigate adaptive batch size strategies derived from adaptive sampling methods, traditionally applied only in stochastic gradient descent. Given the significant interplay between learning rates and batch sizes, and considering the prevalence of adaptive gradient methods in deep learning, we emphasize the need for adaptive batch size strategies in these contexts. We introduce AdAdaGrad and its scalar variant AdAdaGradNorm, which incrementally increase batch sizes during training, while model updates are performed using AdaGrad and AdaGradNorm. We prove that AdaGradNorm converges with high probability at a rate of $\mathscr{O}(1/K)$ for finding a first-order stationary point of smooth nonconvex functions within $K$ i
    
[^7]: 通过迭代后验抽样实现随机定位

    Stochastic Localization via Iterative Posterior Sampling

    [https://arxiv.org/abs/2402.10758](https://arxiv.org/abs/2402.10758)

    本论文提出了一种名为SLIPS的方法，通过迭代后验抽样实现随机定位，填补了从非标准化目标密度中抽样的问题的空白。

    

    建立在基于得分学习的基础上，近期对随机定位技术产生了新的兴趣。在这些模型中，人们通过随机过程（称为观测过程）为数据分布中的样本引入噪声，并逐渐学习与该动力学关联的去噪器。除了特定应用之外，对于从非标准化目标密度中抽样的问题，对随机定位的使用尚未得到广泛探讨。本项工作旨在填补这一空白。我们考虑了一个通用的随机定位框架，并引入了一类明确的观测过程，与灵活的去噪时间表相关联。我们提供了一种完整的方法论，即“通过迭代后验抽样实现随机定位”（SLIPS），以获得该动力学的近似样本，并作为副产品，样本来自目标分布。我们的方案基于马尔可夫链蒙特卡洛估计。

    arXiv:2402.10758v1 Announce Type: cross  Abstract: Building upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, $\textit{Stochastic Localization via Iterative Posterior Sampling}$ (SLIPS), to obtain approximate samples of this dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimati
    
[^8]: 合并不同过滤器中的证据

    Combining Evidence Across Filtrations

    [https://arxiv.org/abs/2402.09698](https://arxiv.org/abs/2402.09698)

    这篇论文研究了合并使用不同过滤器计算的e进程的方法，探讨了其在顺序推理中的应用。

    

    在任何时刻有效的顺序推理中，已知任何可接受的推理方法必须基于测试鞅和它们的组合广义化，称为e进程，它们是非负进程，其在任何任意停时的期望上界不超过一。e进程量化了针对复合零假设的一系列结果的累积证据。本文研究了使用不同信息集（即过滤器）计算的e进程的合并方法，针对一个零假设。尽管在相同过滤器上构建的e进程可以轻松地合并（例如，通过平均），但在不同过滤器上构建的e进程不能那么容易地合并，因为它们在较粗的过滤器中的有效性不能转换为在更细的过滤器中的有效性。我们讨论了文献中三个具体例子：可交换性测试，独立性测试等。

    arXiv:2402.09698v1 Announce Type: cross  Abstract: In anytime-valid sequential inference, it is known that any admissible inference procedure must be based on test martingales and their composite generalization, called e-processes, which are nonnegative processes whose expectation at any arbitrary stopping time is upper-bounded by one. An e-process quantifies the accumulated evidence against a composite null hypothesis over a sequence of outcomes. This paper studies methods for combining e-processes that are computed using different information sets, i.e., filtrations, for a null hypothesis. Even though e-processes constructed on the same filtration can be combined effortlessly (e.g., by averaging), e-processes constructed on different filtrations cannot be combined as easily because their validity in a coarser filtration does not translate to validity in a finer filtration. We discuss three concrete examples of such e-processes in the literature: exchangeability tests, independence te
    
[^9]: Weisfeiler-Leman在边缘条件下的更高表达力的重要性

    Weisfeiler-Leman at the margin: When more expressivity matters

    [https://arxiv.org/abs/2402.07568](https://arxiv.org/abs/2402.07568)

    研究探讨了1-WL算法在图同构问题中的表达能力和泛化性能之间的关系，发现增强的表达能力对提高泛化性能并不总是有效。此外，通过引入子图信息和经典的边缘理论，探索了更高表达力与改进泛化性能的条件。梯度流也被证明可以促进模型学习更丰富的表达能力。

    

    Weisfeiler-Leman算法（1-WL）是一个被广泛研究的用于图同构问题的启发式算法。最近，该算法在理解传递消息的图神经网络（MPNNs）的表达能力以及作为图核函数方面发挥了重要作用。尽管取得了成功，但1-WL在区分非同构图方面面临挑战，从而导致了更具表达力的MPNN和核架构的发展。然而，增强的表达能力和改进的泛化性能之间的关系仍不清楚。在本文中，我们展示了当通过图同构来观察时，架构的表达能力在解释其泛化性能方面具有有限的洞察力。此外，我们着重在1-WL和MPNN中引入子图信息，并运用经典的边缘理论来研究架构的增强表达能力与改进的泛化性能之间的条件。此外，我们还展示了梯度流如何推动模型学习更丰富的表达能力。

    The Weisfeiler-Leman algorithm ($1$-WL) is a well-studied heuristic for the graph isomorphism problem. Recently, the algorithm has played a prominent role in understanding the expressive power of message-passing graph neural networks (MPNNs) and being effective as a graph kernel. Despite its success, $1$-WL faces challenges in distinguishing non-isomorphic graphs, leading to the development of more expressive MPNN and kernel architectures. However, the relationship between enhanced expressivity and improved generalization performance remains unclear. Here, we show that an architecture's expressivity offers limited insights into its generalization performance when viewed through graph isomorphism. Moreover, we focus on augmenting $1$-WL and MPNNs with subgraph information and employ classical margin theory to investigate the conditions under which an architecture's increased expressivity aligns with improved generalization performance. In addition, we show that gradient flow pushes the 
    
[^10]: 结构冗余的低秩逼近用于自监督学习

    Low-Rank Approximation of Structural Redundancy for Self-Supervised Learning

    [https://arxiv.org/abs/2402.06884](https://arxiv.org/abs/2402.06884)

    本文研究结构冗余的低秩逼近在自监督学习中的应用，提出了一个逼近冗余组件的新方法，并通过分析过量风险来支持理论。

    

    我们研究重构型自监督学习的数据生成机制，以揭示其有效性。在拥有无限量的标记样本的情况下，我们提供了完美线性逼近的充分必要条件。该条件揭示了一个保留标签类别Y的满秩组件，以及一个冗余组件。受到该条件的启发，我们提出通过低秩分解逼近冗余组件，并通过引入一个由分解秩s参数化的新量$\epsilon_s$来衡量逼近质量。我们将$\epsilon_s$整合到线性回归和岭回归设置下的过量风险分析中，后一种正则化方法用于处理学习特征的维度远大于下游任务的标记样本数n的情况。我们设计了三个简化实验，以比较不同设置下的自监督学习和监督学习，以支持我们的理论。

    We study the data-generating mechanism for reconstructive SSL to shed light on its effectiveness. With an infinite amount of labeled samples, we provide a sufficient and necessary condition for perfect linear approximation. The condition reveals a full-rank component that preserves the label classes of Y, along with a redundant component. Motivated by the condition, we propose to approximate the redundant component by a low-rank factorization and measure the approximation quality by introducing a new quantity $\epsilon_s$, parameterized by the rank of factorization s. We incorporate $\epsilon_s$ into the excess risk analysis under both linear regression and ridge regression settings, where the latter regularization approach is to handle scenarios when the dimension of the learned features is much larger than the number of labeled samples n for downstream tasks. We design three stylized experiments to compare SSL with supervised learning under different settings to support our theoretic
    
[^11]: 探索Transformer模型的归纳偏差: 一个来自无穷的视角

    Towards Understanding Inductive Bias in Transformers: A View From Infinity

    [https://arxiv.org/abs/2402.05173](https://arxiv.org/abs/2402.05173)

    本文研究了Transformer模型的归纳偏差，并发现它们倾向于对称排列函数，对称群的表示理论可以用于分析预测，同时提出了一个简化模型来解决学习曲线和网络输出，并在常见设置中得出学习能力的紧密边界，最后还证明了WikiText数据集具有排列对称性。

    

    我们研究了Transformer模型在无穷的过参数化高斯过程极限中的归纳偏差，并指出Transformer模型在序列空间中更倾向于对称排列函数。我们证明了对称群的表示理论可以用于在数据集对token之间的排列具有对称性时给出定量的分析预测。我们提出了一个简化的Transformer模型，并在极限条件下求解模型，包括对学习曲线和网络输出的准确预测。我们展示了在常见的设置中，可以推导出学习能力的紧密边界，以上下文长度作为函数的缩放定律。最后，我们认为WikiText数据集确实具有一定程度的排列对称性。

    We study inductive bias in Transformers in the infinitely over-parameterized Gaussian process limit and argue transformers tend to be biased towards more permutation symmetric functions in sequence space. We show that the representation theory of the symmetric group can be used to give quantitative analytical predictions when the dataset is symmetric to permutations between tokens. We present a simplified transformer block and solve the model at the limit, including accurate predictions for the learning curves and network outputs. We show that in common setups, one can derive tight bounds in the form of a scaling law for the learnability as a function of the context length. Finally, we argue WikiText dataset, does indeed possess a degree of permutation symmetry.
    
[^12]: 通过状态扩展和随机排列的方法进行变分DAG估计

    Variational DAG Estimation via State Augmentation With Stochastic Permutations

    [https://arxiv.org/abs/2402.02644](https://arxiv.org/abs/2402.02644)

    使用状态扩展和随机排列进行变分DAG估计的方法可以超越竞争的贝叶斯和非贝叶斯基准方法，从而在估计贝叶斯网络结构方面取得更好的性能。

    

    从观测数据中估计贝叶斯网络的结构，即有向无环图（DAG），是一个在统计和计算上都很困难的问题，在因果发现等领域有着重要应用。贝叶斯方法在解决这个任务方面是一个有希望的方向，因为它们允许进行不确定性量化，并处理众所周知的可识别性问题。从概率推断的角度来看，主要的挑战是（i）表示满足DAG约束的图的分布和（ii）估计底层组合空间的后验概率。我们提出了一种方法，通过在DAG和排列的扩展空间上构建联合分布来解决这些挑战。我们通过变分推断进行后验估计，在其中利用了离散分布的连续松弛。我们展示了我们的方法在一系列合成和实际数据上能够超越竞争的贝叶斯和非贝叶斯基准方法。

    Estimating the structure of a Bayesian network, in the form of a directed acyclic graph (DAG), from observational data is a statistically and computationally hard problem with essential applications in areas such as causal discovery. Bayesian approaches are a promising direction for solving this task, as they allow for uncertainty quantification and deal with well-known identifiability issues. From a probabilistic inference perspective, the main challenges are (i) representing distributions over graphs that satisfy the DAG constraint and (ii) estimating a posterior over the underlying combinatorial space. We propose an approach that addresses these challenges by formulating a joint distribution on an augmented space of DAGs and permutations. We carry out posterior estimation via variational inference, where we exploit continuous relaxations of discrete distributions. We show that our approach can outperform competitive Bayesian and non-Bayesian benchmarks on a range of synthetic and re
    
[^13]: 时序数据的独立性检验

    Independence Testing for Temporal Data

    [https://arxiv.org/abs/1908.06486](https://arxiv.org/abs/1908.06486)

    本文介绍了一种适用于测试时序数据之间独立性的时序依赖统计方法，并能够估计最佳依赖滞后。该方法解决了现有方法的限制，并且在测试平稳时间序列之间的独立性时渐近有效和普遍一致，并且与多种依赖度量方法兼容。

    

    时序数据在现代数据科学中越来越常见。一个基本问题是判断两个时间序列是否相关。现有方法常常存在限制，如依赖参数假设、仅检测线性关联、需要多个测试和修正等。虽然最近提出了许多非参数和普遍一致的依赖度量方法，但直接应用于时序数据可能导致p值膨胀和无效的检验。为了解决这些挑战，本文引入了基于块置换的时序依赖统计量来测试时序数据之间的独立性。在适当的假设下，所提出的方法在测试平稳时间序列之间的独立性时是渐近有效和普遍一致的，并且能够估计最大化依赖的最佳依赖滞后。值得注意的是，它与丰富的距离和核心依赖度量方法兼容，消除了

    Temporal data are increasingly prevalent in modern data science. A fundamental question is whether two time-series are related or not. Existing approaches often have limitations, such as relying on parametric assumptions, detecting only linear associations, and requiring multiple tests and corrections. While many non-parametric and universally consistent dependence measures have recently been proposed, directly applying them to temporal data can inflate the p-value and result in invalid test. To address these challenges, this paper introduces the temporal dependence statistic with block permutation to test independence between temporal data. Under proper assumptions, the proposed procedure is asymptotically valid and universally consistent for testing independence between stationary time-series, and capable of estimating the optimal dependence lag that maximizes the dependence. Notably, it is compatible with a rich family of distance and kernel based dependence measures, eliminates the
    
[^14]: 沃瑟斯坦梯度流在变分推断的变分参数空间上的应用

    Wasserstein Gradient Flow over Variational Parameter Space for Variational Inference. (arXiv:2310.16705v1 [cs.LG])

    [http://arxiv.org/abs/2310.16705](http://arxiv.org/abs/2310.16705)

    本文将变分推断重新框架为在变分参数空间上的概率分布优化问题，提出了沃瑟斯坦梯度下降方法来解决优化问题，有效性经过实证实验证实。

    

    变分推断可以被看作是一个优化问题，其中变分参数被调整以使变分分布与真实后验尽可能接近。可以通过黑箱变分推断中的普通梯度下降或自然梯度变分推断中的自然梯度下降来解决优化任务。在本文中，我们将变分推断重新框架为在一个“变分参数空间”中定义的概率分布的目标优化问题。随后，我们提出了沃瑟斯坦梯度下降方法来解决这个优化问题。值得注意的是，这些优化技术，即黑箱变分推断和自然梯度变分推断，可以重新解释为所提出的沃瑟斯坦梯度下降的特定实例。为了提高优化效率，我们开发了实用的方法来数值求解离散梯度流。通过在一个合成数据集上的实证实验，我们验证了所提出方法的有效性。

    Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior. The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI. In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \textit{variational parameter space}. Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem. Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent. To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows. We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theore
    
[^15]: 延迟反馈的强化适应性算法中的最佳方案改进

    An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback. (arXiv:2308.10675v1 [cs.LG])

    [http://arxiv.org/abs/2308.10675](http://arxiv.org/abs/2308.10675)

    提出了一种改进的延迟反馈的强化适应性算法，通过消除先验知识需求和控制分布漂移，该算法在遗憾界限方面具有突出贡献。

    

    我们提出了一种用于具有可变延迟反馈的强化适应性算法的新方法。该算法通过消除对最大延迟$d_{\mathrm{max}}$的先验知识的需求，并在两个情景下提供更紧密的遗憾界限，改进了Masoudian等人[2022]的先前工作。算法和它的遗憾界限是基于未解决的观测次数（在行动时间观察到的数量）而不是延迟或最大延迟（只有当反馈到达时才能观察到的数量）。一个主要的贡献是基于有偏损失估计器和跳过具有过大延迟观测的新型分布漂移控制。另一个主要的贡献是证明了具有延迟反馈的强化适应性算法的复杂性是由在跳过具有过大延迟观测后的累积未解决观测次数来描述的，而不是延迟或最大延迟。

    We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. The algorithm improves on prior work by Masoudian et al. [2022] by eliminating the need in prior knowledge of the maximal delay $d_{\mathrm{max}}$ and providing tighter regret bounds in both regimes. The algorithm and its regret bounds are based on counts of outstanding observations (a quantity that is observed at action time) rather than delays or the maximal delay (quantities that are only observed when feedback arrives). One major contribution is a novel control of distribution drift, which is based on biased loss estimators and skipping of observations with excessively large delays. Another major contribution is demonstrating that the complexity of best-of-both-worlds bandits with delayed feedback is characterized by the cumulative count of outstanding observations after skipping of observations with excessively large delays, rather than the delays or the maximal delay.
    
[^16]: 图自同态群等变神经网络

    Graph Automorphism Group Equivariant Neural Networks. (arXiv:2307.07810v1 [cs.LG])

    [http://arxiv.org/abs/2307.07810](http://arxiv.org/abs/2307.07810)

    本论文提供了图自同态群等变神经网络的完整特征化，找到了可学习的、线性的层函数之间的矩阵的生成集。

    

    对于任何具有n个顶点和其自同态群Aut(G)的图G，我们提供了所有可能的Aut(G)-等变神经网络的完整特征化，其层是n维实数张量的某些张量幂次。特别地，我们在n维实数空间的标准基下找到了可学习的、线性的Aut(G)-等变层函数之间的矩阵的生成集。

    For any graph $G$ having $n$ vertices and its automorphism group $\textrm{Aut}(G)$, we provide a full characterisation of all of the possible $\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a spanning set of matrices for the learnable, linear, $\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$.
    
[^17]: 使用贝叶斯模型选择进行因果推断

    Causal Discovery using Bayesian Model Selection. (arXiv:2306.02931v1 [stat.ML])

    [http://arxiv.org/abs/2306.02931](http://arxiv.org/abs/2306.02931)

    对于具有现实假设的数据集，本文提出了使用贝叶斯模型选择进行因果推断的方法，使得确定因果方向变成了一个模型选择问题。使用实际数据集验证了本方法优于现有方法。

    

    只有两个变量的观测数据且没有其他假设，无法推断哪个变量是引起另一个变量的原因。大部分因果文献聚焦于针对强假设的数据集(如加性噪声或参数计数限制)保证因果方向的可识别性。然而这些方法通常被测试于违反假设的现实数据集上。本文在此基础上提出如何在贝叶斯框架内使用因果假设。这使我们能够制定具有现实假设的模型，同时编码独立的因果机制，导致因果方向之间的非对称性。因此，确定因果方向成为贝叶斯模型选择问题。我们分析了为何在已知可识别的情况和灵活的模型类上贝叶斯模型选择

    With only observational data on two variables, and without other assumptions, it is not possible to infer which one causes the other. Much of the causal literature has focused on guaranteeing identifiability of causal direction in statistical models for datasets where strong assumptions hold, such as additive noise or restrictions on parameter count. These methods are then subsequently tested on realistic datasets, most of which violate their assumptions. Building on previous attempts, we show how to use causal assumptions within the Bayesian framework. This allows us to specify models with realistic assumptions, while also encoding independent causal mechanisms, leading to an asymmetry between the causal directions. Identifying causal direction then becomes a Bayesian model selection problem. We analyse why Bayesian model selection works for known identifiable cases and flexible model classes, while also providing correctness guarantees about its behaviour. To demonstrate our approach
    
[^18]: 插件化表现优化

    Plug-in Performative Optimization. (arXiv:2305.18728v1 [cs.LG])

    [http://arxiv.org/abs/2305.18728](http://arxiv.org/abs/2305.18728)

    研究了一种可能“规范不正确”模型的通用协议，“插件式表现优化”。

    

    当预测具有表现性时，选择哪个预测器部署将影响未来观测的分布。在表现性学习中，总体目标是找到具有低“表现性风险”的预测器，即在其引导的分布上表现良好。最优化表现性风险的一系列解决方案，包括赌徒算法和其他无导数方法，在表现性反馈中不知道任何结构，导致收敛速度极慢。补充的一系列解决方案利用反馈中的显式“模型”，例如战略分类中的最佳响应模型，可以实现更快的速率。然而，这些速率关键依赖于反馈模型的规范。在本研究中，我们启动了对在表现性预测中使用可能的“规范不正确”模型的研究。我们研究了一种使用模型的通用协议，称为“插件式表现优化”。

    When predictions are performative, the choice of which predictor to deploy influences the distribution of future observations. The overarching goal in learning under performativity is to find a predictor that has low \emph{performative risk}, that is, good performance on its induced distribution. One family of solutions for optimizing the performative risk, including bandits and other derivative-free methods, is agnostic to any structure in the performative feedback, leading to exceedingly slow convergence rates. A complementary family of solutions makes use of explicit \emph{models} for the feedback, such as best-response models in strategic classification, enabling significantly faster rates. However, these rates critically rely on the feedback model being well-specified. In this work we initiate a study of the use of possibly \emph{misspecified} models in performative prediction. We study a general protocol for making use of models, called \emph{plug-in performative optimization}, a
    
[^19]: Density-Softmax: 在分布变化下提高不确定性估计的快速确定性方法

    Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts. (arXiv:2302.06495v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06495](http://arxiv.org/abs/2302.06495)

    本文提出了一种称为Density-Softmax的快速确定性方法，通过将密度函数与softmax结合来提高分布变化下的校准不确定性估计，具有较高的效率和可行性

    

    常见确定性深度学习模型在分布变化下存在较大的过度自信问题，概率方法虽然能缓解此问题但计算效率不佳。本文提出Density-Softmax方法，通过将密度函数与softmax结合，以快速且轻量级的方式提高校准不确定性估计。该方法利用潜在表示的似然值，在测试时在远离训练样本时增加不确定性。在理论证明和实验上，Density-Softmax证明了在使用神经网络的情况下可以实现高质量的不确定性估计，从而减少了标准softmax的过度自信。

    Prevalent deterministic deep-learning models suffer from significant over-confidence under distribution shifts. Probabilistic approaches can reduce this problem but struggle with computational efficiency. In this paper, we propose Density-Softmax, a fast and lightweight deterministic method to improve calibrated uncertainty estimation via a combination of density function with the softmax layer. By using the latent representation's likelihood value, our approach produces more uncertain predictions when test samples are distant from the training samples. Theoretically, we show that Density-Softmax can produce high-quality uncertainty estimation with neural networks, as it is the solution of minimax uncertainty risk and is distance-aware, thus reducing the over-confidence of the standard softmax. Empirically, our method enjoys similar computational efficiency as a single forward pass deterministic with standard softmax on the shifted toy, vision, and language datasets across modern deep-
    

