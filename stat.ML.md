# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations](https://arxiv.org/abs/2403.13748) | 不同的散度排序可以通过它们的变分近似误估不确定性的各种度量，并且因子化近似无法同时匹配这些度量中的任意两个 |
| [^2] | [Probabilistic Forecasting with Stochastic Interpolants and F\"ollmer Processes](https://arxiv.org/abs/2403.13724) | 提出了一个基于生成建模的动态系统概率预测框架，利用随机插值器构建虚构的随机动力学，在有限时间内无偏见地生成未来系统状态的概率性预测集合 |
| [^3] | [Does Differentially Private Synthetic Data Lead to Synthetic Discoveries?](https://arxiv.org/abs/2403.13612) | 评估差分隐私合成生物医学数据上的Mann-Whitney U检验，以确定在隐私保护合成数据上执行的统计假设检验是否可能导致测试有效性的丧失或功率下降。 |
| [^4] | [AdaTrans: Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Regression](https://arxiv.org/abs/2403.13565) | 提出了一种针对高维回归的自适应迁移学习方法，可以根据可迁移结构自适应检测和聚合特征和样本的可迁移结构。 |
| [^5] | [Uncertainty quantification for data-driven weather models](https://arxiv.org/abs/2403.13458) | 研究旨在系统比较不确定性量化方法，以生成概率性天气预测，超越传统基于物理的天气预测模型。 |
| [^6] | [Kernel Multigrid: Accelerate Back-fitting via Sparse Gaussian Process Regression](https://arxiv.org/abs/2403.13300) | 通过核包技术证明反向拟合的收敛速度，并提出了核多重网格算法，通过稀疏高斯过程回归增强反向拟合，适用于结构化和分散数据的加性GPs。 |
| [^7] | [A Sampling-based Framework for Hypothesis Testing on Large Attributed Graphs](https://arxiv.org/abs/2403.13286) | 本论文提出了一个基于抽样的假设检验框架，能够在大属性图中处理节点、边和路径假设，通过提出路径假设感知采样器 PHASE 以及 PHASEopt，实现了准确且高效的抽样，实验证明了其在假设检验上的优势。 |
| [^8] | [What makes a small-world network? Leveraging machine learning for the robust prediction and classification of networks](https://arxiv.org/abs/2403.13215) | 通过利用可解释的机器学习，该研究强调了特定网络特征及其相互作用，有助于区分生成模型、理解复杂网络结构和生成真实世界网络 |
| [^9] | [Diversity-Aware Agnostic Ensemble of Sharpness Minimizers](https://arxiv.org/abs/2403.13204) | 提出了一种促进深度集成内多样性和平坦性的学习算法DASH，通过鼓励基础学习器向最小锐度区域的低损失区域发散移动来提高泛化能力。 |
| [^10] | [ADAPT to Robustify Prompt Tuning Vision Transformers](https://arxiv.org/abs/2403.13196) | 本文提出了ADAPT框架，用于在prompt调优范式中进行自适应对抗训练，增强视觉Transformer在下游任务中的稳健性。 |
| [^11] | [Predictive, scalable and interpretable knowledge tracing on structured domains](https://arxiv.org/abs/2403.13179) | 本研究提出了一种解决深度学习模型高准确性但低解释性问题的方法，通过PSI-KT的分层生成方法实现了对个体认知特征和知识结构的解释，同时使用可扩展的贝叶斯推断实现了对不断增长的学习者群体的高效个性化。 |
| [^12] | [Fast Value Tracking for Deep Reinforcement Learning](https://arxiv.org/abs/2403.13178) | 我们的研究提出一种基于Kalman滤波范式的新颖和可扩展的采样算法LKTD，用于深度强化学习，能够有效地从深度神经网络参数的后验分布中抽取样本，并证明这些后验样本会收敛到一个稳定分布。 |
| [^13] | [Training Survival Models using Scoring Rules](https://arxiv.org/abs/2403.13150) | 提出了一种使用评分规则训练生存模型的通用方法，将其应用于各种模型类别中并与神经网络结合，实现了高效可扩展的优化例程，并展示了优于基于似然性方法的预测性能。 |
| [^14] | [Function Trees: Transparent Machine Learning](https://arxiv.org/abs/2403.13141) | 提出了一种表示一般多变量函数为简单函数树的方法，该树能够快速识别和计算函数的主要和交互效应直至高阶，以图形化方式展示涉及到四个变量的交互效应。 |
| [^15] | [Robust NAS under adversarial training: benchmark, theory, and beyond](https://arxiv.org/abs/2403.13134) | 该论文提出了针对对抗训练下的鲁棒神经结构搜索的基准数据集和泛化理论，有望极大地推动NAS领域的发展。 |
| [^16] | [Modal Analysis of Spatiotemporal Data via Multivariate Gaussian Process Regression](https://arxiv.org/abs/2403.13118) | 提出了一种使用多元高斯过程回归的新型模态分析技术，以解决稀疏时间不规则数据的限制。 |
| [^17] | [Optimal Flow Matching: Learning Straight Trajectories in Just One Step](https://arxiv.org/abs/2403.13117) | 该论文提出了一种新颖的最优流匹配方法，能够在一步中学习实现二次成本下的直线 OT 位移。 |
| [^18] | [Provable Privacy with Non-Private Pre-Processing](https://arxiv.org/abs/2403.13041) | 提出了一个框架，能够评估非私密数据相关预处理算法引起的额外隐私成本，并利用平滑DP和预处理算法的有界敏感性建立整体隐私保证的上限 |
| [^19] | [Towards Better Statistical Understanding of Watermarking LLMs](https://arxiv.org/abs/2403.13027) | 本文研究了水印LLMs的问题，提出了一种基于优化算法的水印算法，实现了模型失真和检测能力之间的最优平衡。 |
| [^20] | [When SMILES have Language: Drug Classification using Text Classification Methods on Drug SMILES Strings](https://arxiv.org/abs/2403.12984) | 将药物SMILES字符串视为句子并利用文本分类方法进行药物分类，证实了通过简单的自然语言处理方法解决复杂问题的可能性 |
| [^21] | [Training morphological neural networks with gradient descent: some theoretical insights](https://arxiv.org/abs/2403.12975) | 形态神经网络的训练存在挑战，本文通过使用基于梯度下降的优化算法，探讨了基于微分方法和反向传播对形态网络的潜力和局限性，提供了关于初始化和学习率的理论指导。 |
| [^22] | [The Power of Few: Accelerating and Enhancing Data Reweighting with Coreset Selection](https://arxiv.org/abs/2403.12166) | 提出一种利用核心子集选择进行数据重新加权的方法，有效优化了计算时间和模型性能，突显其作为模型训练的可扩展和精确解决方案的潜力。 |
| [^23] | [Graph Neural Networks for Learning Equivariant Representations of Neural Networks](https://arxiv.org/abs/2403.12143) | 本研究提出了将神经网络表示为参数的计算图的方法，利用图神经网络和变压器来实现置换对称性，使得单个模型能够处理具有多种架构的神经计算图。 |
| [^24] | [Analysis of singular subspaces under random perturbations](https://arxiv.org/abs/2403.09170) | 在信号加随机高斯噪声矩阵模型的背景下，扩展了对奇异向量和奇异子空间扰动的Wedin-Davis-Kahan定理，获得了奇异向量和奇异子空间的细粒度分析结果，并探索了与奇异向量相关的线性和双线性函数，同时探讨了这些发现在高斯混合模型和子矩阵定位问题中的实际应用。 |
| [^25] | [A Causal Framework to Evaluate Racial Bias in Law Enforcement Systems](https://arxiv.org/abs/2402.14959) | 本论文提出了一个多阶段因果框架，融入犯罪行为，用于评估执法系统中的种族偏见，以解决以往研究中存在的限制，对偏见进行量化，并确定主要偏见来源。 |
| [^26] | [Diffusive Gibbs Sampling](https://arxiv.org/abs/2402.03008) | 扩散吉布斯采样是一种创新的采样方法，通过集成扩散模型并应用吉布斯采样，有效地从具有远程和断开模态特征的分布中采样，表现出比其他方法更好的混合性能，并在多种任务中取得显著改进的结果。 |
| [^27] | [Hybrid Quantum Vision Transformers for Event Classification in High Energy Physics](https://arxiv.org/abs/2402.00776) | 该论文提出了一种基于量子的混合视觉转换器模型，用于高能物理中的事件分类任务。通过减少训练和操作时间，该模型可以达到与经典模型相当的性能。 |
| [^28] | [Does provable absence of barren plateaus imply classical simulability? Or, why we need to rethink variational quantum computing](https://arxiv.org/abs/2312.09121) | 常用的具有无荒原证明的模型也可以在进行初始数据采集阶段从量子设备中收集一些经典数据的情况下经典模拟 |
| [^29] | [Precipitation Downscaling with Spatiotemporal Video Diffusion](https://arxiv.org/abs/2312.06071) | 通过扩展视频扩散模型至降水超分辨率，本研究提出了一种利用确定性降尺度器和暂时条件扩散模型来捕捉噪声特征和高频率模式的方法。 |
| [^30] | [Analyzing and Improving the Training Dynamics of Diffusion Models](https://arxiv.org/abs/2312.02696) | 通过重新设计网络层来保持期望的激活、权重和更新幅度，消除了扩散模型中观察到的漂移和不平衡，从而在相同的计算复杂性下获得了更好的网络性能。 |
| [^31] | [Interpretable Meta-Learning of Physical Systems](https://arxiv.org/abs/2312.00477) | 通过提出一个具有仿射结构的简单学习模型，本研究实现了多环境泛化，能够识别物理系统的参数，实现了可解释性学习。 |
| [^32] | [Are Ensembles Getting Better all the Time?](https://arxiv.org/abs/2311.17885) | 只有当考虑的损失函数为凸函数时，集成模型一直在变得更好，当损失函数为非凸函数时，好模型的集成变得更好，坏模型的集成变得更糟。 |
| [^33] | [Span-Based Optimal Sample Complexity for Average Reward MDPs](https://arxiv.org/abs/2311.13469) | 该研究提出了基于跨度的平均回报MDP中学习最优策略的最优样本复杂度界限，是首个在所有参数方面都是极小极大最优的结果。 |
| [^34] | [Distributed Estimation and Inference for Semi-parametric Binary Response Models](https://arxiv.org/abs/2210.08393) | 通过一次性分治估计和多轮估计，本文提出了分布式环境下对半参数二元选择模型的新估计方法，实现了优化误差的超线性改进。 |
| [^35] | [Sparsification of the regularized magnetic Laplacian with multi-type spanning forests](https://arxiv.org/abs/2208.14797) | 本文研究了具有多类型生成森林的正则化磁 Laplacian 的稀疏化方法，以解决大而密集图的谱近似问题。 |
| [^36] | [Roto-translated Local Coordinate Frames For Interacting Dynamical Systems](https://arxiv.org/abs/2110.14961) | 本研究提出了为每个节点-对象引入局部坐标系，以诱导相互作用动态系统的几何图具有旋转-平移不变性。 |
| [^37] | [Learning Weakly Convex Sets in Metric Spaces](https://arxiv.org/abs/2105.06251) | 本文表明可以在多项式时间内解决一致的假设找到问题，并展示了一种广泛类别的弱凸假设。 |
| [^38] | [The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms](https://arxiv.org/abs/2002.10121) | 发现贪婪算法在多臂老虎机问题中表现出不合理的有效性，并提出了一种新形式的自由探索，对贪婪算法有益。 |
| [^39] | [DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations.](http://arxiv.org/abs/2401.12517) | DDMI是一种面向领域无关的隐式神经表示的高质量合成的潜在扩散模型，通过生成自适应位置嵌入而不是网络权重，解决了现有方法中生成质量较低的问题。 |
| [^40] | [Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery.](http://arxiv.org/abs/2401.05394) | 该论文介绍了一种新的迭代正则化算法IRKSN，它通过使用$k$支撑范数正则化实现稀疏恢复，并提供了条件。这是对基于$\ell_1$范数的迭代方法的一种重要补充。 |
| [^41] | [Extracting the Multiscale Causal Backbone of Brain Dynamics.](http://arxiv.org/abs/2311.00118) | 该研究提出了一种用于提取脑动力学多尺度因果骨架的方法，并通过对合成数据和静息态fMRI数据的实验证明其优越性。研究结果显示，因果动力在不同频率下受不同脑区驱动，这为理解脑功能提供了新的视角。 |
| [^42] | [Latent Field Discovery In Interacting Dynamical Systems With Neural Fields.](http://arxiv.org/abs/2310.20679) | 本文通过笛卡尔积和神经场提出了一种新的图网络，用于在相互作用动态系统中发现局部物体相互作用和全局场效应的潜在力场。 |
| [^43] | [MCRAGE: Synthetic Healthcare Data for Fairness.](http://arxiv.org/abs/2310.18430) | MCRAGE是一种使用深度生成模型来增强不平衡的医疗数据集的方法，以解决少数群体在机器学习模型中的不公平问题。 |
| [^44] | [Asymptotically free sketched ridge ensembles: Risks, cross-validation, and tuning.](http://arxiv.org/abs/2310.04357) | 该论文利用随机矩阵理论建立了一致性估计方法，用于估计素描岭回归集合的预测风险，从而实现了正则化和素描参数的高效一致调整。 |
| [^45] | [Mitigating Over-Smoothing and Over-Squashing using Augmentations of Forman-Ricci Curvature.](http://arxiv.org/abs/2309.09384) | 本文提出了一种使用Forman-Ricci曲率扩展的方法来减轻图神经网络中的过度平滑和过度压缩问题。通过观察离散曲率，可以添加或删除边以减轻这两种效应。 |
| [^46] | [Prediction Error Estimation in Random Forests.](http://arxiv.org/abs/2309.00736) | 本文通过量化评估分类随机森林的误差估计方法，发现随机森林的预测误差估计比平均预测误差更接近真实误差率，并且这一结果适用于不同的误差估计策略。 |
| [^47] | [Prodigy: An Expeditiously Adaptive Parameter-Free Learner.](http://arxiv.org/abs/2306.06101) | 本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。 |

# 详细

[^1]: 变分推断中因子化高斯近似的差异排序

    An Ordering of Divergences for Variational Inference with Factorized Gaussian Approximations

    [https://arxiv.org/abs/2403.13748](https://arxiv.org/abs/2403.13748)

    不同的散度排序可以通过它们的变分近似误估不确定性的各种度量，并且因子化近似无法同时匹配这些度量中的任意两个

    

    在变分推断（VI）中，给定一个难以处理的分布$p$，问题是从一些更易处理的族$\mathcal{Q}$中计算最佳近似$q$。通常情况下，这种近似是通过最小化Kullback-Leibler (KL)散度来找到的。然而，存在其他有效的散度选择，当$\mathcal{Q}$不包含$p$时，每个散度都支持不同的解决方案。我们分析了在高斯的密集协方差矩阵被对角协方差矩阵的高斯近似所影响的VI结果中，散度选择如何影响VI结果。在这种设置中，我们展示了不同的散度可以通过它们的变分近似误估不确定性的各种度量，如方差、精度和熵，进行\textit{排序}。我们还得出一个不可能定理，表明无法通过因子化近似同时匹配这些度量中的任意两个；因此

    arXiv:2403.13748v1 Announce Type: cross  Abstract: Given an intractable distribution $p$, the problem of variational inference (VI) is to compute the best approximation $q$ from some more tractable family $\mathcal{Q}$. Most commonly the approximation is found by minimizing a Kullback-Leibler (KL) divergence. However, there exist other valid choices of divergences, and when $\mathcal{Q}$ does not contain~$p$, each divergence champions a different solution. We analyze how the choice of divergence affects the outcome of VI when a Gaussian with a dense covariance matrix is approximated by a Gaussian with a diagonal covariance matrix. In this setting we show that different divergences can be \textit{ordered} by the amount that their variational approximations misestimate various measures of uncertainty, such as the variance, precision, and entropy. We also derive an impossibility theorem showing that no two of these measures can be simultaneously matched by a factorized approximation; henc
    
[^2]: 使用随机插值器和F\"ollmer过程进行概率预测

    Probabilistic Forecasting with Stochastic Interpolants and F\"ollmer Processes

    [https://arxiv.org/abs/2403.13724](https://arxiv.org/abs/2403.13724)

    提出了一个基于生成建模的动态系统概率预测框架，利用随机插值器构建虚构的随机动力学，在有限时间内无偏见地生成未来系统状态的概率性预测集合

    

    我们提出了一个基于生成建模的动态系统概率预测框架。在给定系统随时间的状态观测之后，我们将预测问题构建为从给定当前状态的条件分布中进行采样得到未来系统状态的分布。为此，我们利用了随机插值器的框架，这有助于构建在任意基础分布和目标之间的生成模型。我们设计了一个虚构的、非物理的随机动力学，其以当前系统状态作为初始条件，并在有限时间内无偏见地生成一个来自目标条件分布的样本。因此，这个过程将以当前状态为中心的点状质量映射到一个概率性的预测集合。我们证明了实现这一任务的随机微分方程(SDE)中的漂移系数是非奇异的，并且可以学习。

    arXiv:2403.13724v1 Announce Type: new  Abstract: We propose a framework for probabilistic forecasting of dynamical systems based on generative modeling. Given observations of the system state over time, we formulate the forecasting problem as sampling from the conditional distribution of the future system state given its current state. To this end, we leverage the framework of stochastic interpolants, which facilitates the construction of a generative model between an arbitrary base distribution and the target. We design a fictitious, non-physical stochastic dynamics that takes as initial condition the current system state and produces as output a sample from the target conditional distribution in finite time and without bias. This process therefore maps a point mass centered at the current state onto a probabilistic ensemble of forecasts. We prove that the drift coefficient entering the stochastic differential equation (SDE) achieving this task is non-singular, and that it can be lear
    
[^3]: 差分隐私合成数据能导致合成发现吗？

    Does Differentially Private Synthetic Data Lead to Synthetic Discoveries?

    [https://arxiv.org/abs/2403.13612](https://arxiv.org/abs/2403.13612)

    评估差分隐私合成生物医学数据上的Mann-Whitney U检验，以确定在隐私保护合成数据上执行的统计假设检验是否可能导致测试有效性的丧失或功率下降。

    

    合成数据已被提出作为共享敏感生物医学数据的匿名化解决方案。理想情况下，合成数据应保留原始数据的结构和统计特性，同时保护个体主体的隐私。差分隐私（DP）目前被认为是平衡这种权衡的最佳方法。本研究的目的是评估在差分隐私生物医学数据上进行的Mann-Whitney U检验在I型和II型错误方面，以确定在隐私保护合成数据上执行的统计假设检验是否可能导致测试有效性的丧失或功率下降。

    arXiv:2403.13612v1 Announce Type: new  Abstract: Background: Synthetic data has been proposed as a solution for sharing anonymized versions of sensitive biomedical datasets. Ideally, synthetic data should preserve the structure and statistical properties of the original data, while protecting the privacy of the individual subjects. Differential privacy (DP) is currently considered the gold standard approach for balancing this trade-off.   Objectives: The aim of this study is to evaluate the Mann-Whitney U test on DP-synthetic biomedical data in terms of Type I and Type II errors, in order to establish whether statistical hypothesis testing performed on privacy preserving synthetic data is likely to lead to loss of test's validity or decreased power.   Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated from real-world data, including a prostate cancer dataset (n=500) and a cardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian distribution
    
[^4]: AdaTrans：针对高维回归的特征自适应与样本自适应迁移学习

    AdaTrans: Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Regression

    [https://arxiv.org/abs/2403.13565](https://arxiv.org/abs/2403.13565)

    提出了一种针对高维回归的自适应迁移学习方法，可以根据可迁移结构自适应检测和聚合特征和样本的可迁移结构。

    

    我们考虑高维背景下的迁移学习问题，在该问题中，特征维度大于样本大小。为了学习可迁移的信息，该信息可能在特征或源样本之间变化，我们提出一种自适应迁移学习方法，可以检测和聚合特征-wise (F-AdaTrans)或样本-wise (S-AdaTrans)可迁移结构。我们通过采用一种新颖的融合惩罚方法，结合权重，可以根据可迁移结构进行调整。为了选择权重，我们提出了一个在理论上建立，数据驱动的过程，使得 F-AdaTrans 能够选择性地将可迁移的信号与目标融合在一起，同时滤除非可迁移的信号，S-AdaTrans则可以获得每个源样本传递的信息的最佳组合。我们建立了非渐近速率，可以在特殊情况下恢复现有的近最小似乎最优速率。效果证明...

    arXiv:2403.13565v1 Announce Type: cross  Abstract: We consider the transfer learning problem in the high dimensional setting, where the feature dimension is larger than the sample size. To learn transferable information, which may vary across features or the source samples, we propose an adaptive transfer learning method that can detect and aggregate the feature-wise (F-AdaTrans) or sample-wise (S-AdaTrans) transferable structures. We achieve this by employing a novel fused-penalty, coupled with weights that can adapt according to the transferable structure. To choose the weight, we propose a theoretically informed, data-driven procedure, enabling F-AdaTrans to selectively fuse the transferable signals with the target while filtering out non-transferable signals, and S-AdaTrans to obtain the optimal combination of information transferred from each source sample. The non-asymptotic rates are established, which recover existing near-minimax optimal rates in special cases. The effectivene
    
[^5]: 基于数据驱动的天气模型的不确定性量化

    Uncertainty quantification for data-driven weather models

    [https://arxiv.org/abs/2403.13458](https://arxiv.org/abs/2403.13458)

    研究旨在系统比较不确定性量化方法，以生成概率性天气预测，超越传统基于物理的天气预测模型。

    

    人工智能（AI）驱动的数据驱动天气预报模型在过去几年取得了快速进展。最近的研究使用再分析数据训练的模型取得了令人印象深刻的结果，并在一系列变量和评估指标上展示了明显改进，超越了现有的基于物理的数值天气预测模型。除了改进的预测外，数据驱动天气模型的主要优势是它们显著较低的计算成本和一旦模型被训练就能更快地生成预测。然而，大多数数据驱动天气预测的努力都局限于确定性的、点值预测，使得无法量化预测的不确定性，对于研究和应用中的最佳决策至关重要。我们的整体目标是系统地研究和比较不确定性量化方法，以生成概率性预测。

    arXiv:2403.13458v1 Announce Type: cross  Abstract: Artificial intelligence (AI)-based data-driven weather forecasting models have experienced rapid progress over the last years. Recent studies, with models trained on reanalysis data, achieve impressive results and demonstrate substantial improvements over state-of-the-art physics-based numerical weather prediction models across a range of variables and evaluation metrics. Beyond improved predictions, the main advantages of data-driven weather models are their substantially lower computational costs and the faster generation of forecasts, once a model has been trained. However, most efforts in data-driven weather forecasting have been limited to deterministic, point-valued predictions, making it impossible to quantify forecast uncertainties, which is crucial in research and for optimal decision making in applications. Our overarching aim is to systematically study and compare uncertainty quantification methods to generate probabilistic 
    
[^6]: 核多重网格：通过稀疏高斯过程回归加速反向拟合

    Kernel Multigrid: Accelerate Back-fitting via Sparse Gaussian Process Regression

    [https://arxiv.org/abs/2403.13300](https://arxiv.org/abs/2403.13300)

    通过核包技术证明反向拟合的收敛速度，并提出了核多重网格算法，通过稀疏高斯过程回归增强反向拟合，适用于结构化和分散数据的加性GPs。

    

    添加高斯过程(GPs)是非参数特征选择的流行方法。对于这些模型的常见训练方法是贝叶斯反向拟合。然而，在训练加性GPs时，反向拟合的收敛速度仍然是一个悬而未决的问题。通过利用一种称为核包(KP)的技术，我们证明了反向拟合的收敛速度不会比$(1-\mathcal{O}(\frac{1}{n}))^t$更快，其中$n$和$t$分别表示数据大小和迭代次数。因此，反向拟合需要最少$\mathcal{O}(n\log n)$次迭代才能实现收敛。基于KP，我们进一步提出了一种称为核多重网格(KMG)的算法。该算法通过将稀疏高斯过程回归(GPR)纳入每个反向拟合迭代之后处理残差来增强反向拟合。它适用于具有结构化和分散数据的加性GPs。从理论上讲，我们证明K

    arXiv:2403.13300v1 Announce Type: cross  Abstract: Additive Gaussian Processes (GPs) are popular approaches for nonparametric feature selection. The common training method for these models is Bayesian Back-fitting. However, the convergence rate of Back-fitting in training additive GPs is still an open problem. By utilizing a technique called Kernel Packets (KP), we prove that the convergence rate of Back-fitting is no faster than $(1-\mathcal{O}(\frac{1}{n}))^t$, where $n$ and $t$ denote the data size and the iteration number, respectively. Consequently, Back-fitting requires a minimum of $\mathcal{O}(n\log n)$ iterations to achieve convergence. Based on KPs, we further propose an algorithm called Kernel Multigrid (KMG). This algorithm enhances Back-fitting by incorporating a sparse Gaussian Process Regression (GPR) to process the residuals subsequent to each Back-fitting iteration. It is applicable to additive GPs with both structured and scattered data. Theoretically, we prove that K
    
[^7]: 基于抽样的大属性图假设检验框架

    A Sampling-based Framework for Hypothesis Testing on Large Attributed Graphs

    [https://arxiv.org/abs/2403.13286](https://arxiv.org/abs/2403.13286)

    本论文提出了一个基于抽样的假设检验框架，能够在大属性图中处理节点、边和路径假设，通过提出路径假设感知采样器 PHASE 以及 PHASEopt，实现了准确且高效的抽样，实验证明了其在假设检验上的优势。

    

    假设检验是一种用于从样本数据中得出关于总体的结论的统计方法，通常用表格表示。随着现实应用中图表示的普及，图中的假设检验变得越来越重要。本文对属性图中的节点、边和路径假设进行了形式化。我们开发了一个基于抽样的假设检验框架，可以容纳现有的假设不可知的图抽样方法。为了实现准确和高效的抽样，我们提出了一种路径假设感知采样器 PHASE，它是一种考虑假设中指定路径的 m-维随机游走。我们进一步优化了其时间效率并提出了 PHASEopt。对真实数据集的实验表明，我们的框架能够利用常见的图抽样方法进行假设检验，并且在准确性和时间效率方面假设感知抽样具有优势。

    arXiv:2403.13286v1 Announce Type: cross  Abstract: Hypothesis testing is a statistical method used to draw conclusions about populations from sample data, typically represented in tables. With the prevalence of graph representations in real-life applications, hypothesis testing in graphs is gaining importance. In this work, we formalize node, edge, and path hypotheses in attributed graphs. We develop a sampling-based hypothesis testing framework, which can accommodate existing hypothesis-agnostic graph sampling methods. To achieve accurate and efficient sampling, we then propose a Path-Hypothesis-Aware SamplEr, PHASE, an m- dimensional random walk that accounts for the paths specified in a hypothesis. We further optimize its time efficiency and propose PHASEopt. Experiments on real datasets demonstrate the ability of our framework to leverage common graph sampling methods for hypothesis testing, and the superiority of hypothesis-aware sampling in terms of accuracy and time efficiency.
    
[^8]: 什么造就了一个小世界网络？利用机器学习进行网络的稳健预测和分类

    What makes a small-world network? Leveraging machine learning for the robust prediction and classification of networks

    [https://arxiv.org/abs/2403.13215](https://arxiv.org/abs/2403.13215)

    通过利用可解释的机器学习，该研究强调了特定网络特征及其相互作用，有助于区分生成模型、理解复杂网络结构和生成真实世界网络

    

    从流行病学到计算机科学，基于实证数据模拟真实网络的能力是一个重要的任务。通常，模拟方法涉及选择适合的网络生成模型，如Erd\"os-R\'enyi或小世界。然而，很少有工具可用于量化特定生成模型是否适合捕捉给定的网络结构或组织。我们利用可解释的机器学习进展，根据各种网络属性以及它们的相互作用，对我们的生成模型对模拟网络进行分类。我们的研究强调了特定网络特征及其相互作用在区分生成模型、理解复杂网络结构以及形成现实世界网络中的重要性。

    arXiv:2403.13215v1 Announce Type: cross  Abstract: The ability to simulate realistic networks based on empirical data is an important task across scientific disciplines, from epidemiology to computer science. Often simulation approaches involve selecting a suitable network generative model such as Erd\"os-R\'enyi or small-world. However, few tools are available to quantify if a particular generative model is suitable for capturing a given network structure or organization. We utilize advances in interpretable machine learning to classify simulated networks by our generative models based on various network attributes, using both primary features and their interactions. Our study underscores the significance of specific network features and their interactions in distinguishing generative models, comprehending complex network structures, and forming real-world networks
    
[^9]: 多样性感知的无偏小人集成

    Diversity-Aware Agnostic Ensemble of Sharpness Minimizers

    [https://arxiv.org/abs/2403.13204](https://arxiv.org/abs/2403.13204)

    提出了一种促进深度集成内多样性和平坦性的学习算法DASH，通过鼓励基础学习器向最小锐度区域的低损失区域发散移动来提高泛化能力。

    

    长期以来，有大量理论和经验证据支持集成学习的成功。特别是深度集成利用训练中的随机性和单个神经网络的表现力，获得预测多样性，从而最终实现更好的泛化、鲁棒性和不确定性估计。在泛化方面，发现追求更广泛的局部最小值会导致模型对训练和测试集之间的转变更加鲁棒。基于这两种方法，一个自然的研究问题是，如果集成学习和损失锐度最小化相结合，是否可以实现泛化能力的提升。我们的工作研究了这种联系，并提出了一种促进深度集成内多样性和平坦性的学习算法——DASH。更具体地说，DASH鼓励基础学习器向最小锐度区域的低损失区域发散移动。

    arXiv:2403.13204v1 Announce Type: new  Abstract: There has long been plenty of theoretical and empirical evidence supporting the success of ensemble learning. Deep ensembles in particular take advantage of training randomness and expressivity of individual neural networks to gain prediction diversity, ultimately leading to better generalization, robustness and uncertainty estimation. In respect of generalization, it is found that pursuing wider local minima result in models being more robust to shifts between training and testing sets. A natural research question arises out of these two approaches as to whether a boost in generalization ability can be achieved if ensemble learning and loss sharpness minimization are integrated. Our work investigates this connection and proposes DASH - a learning algorithm that promotes diversity and flatness within deep ensembles. More concretely, DASH encourages base learners to move divergently towards low-loss regions of minimal sharpness. We provid
    
[^10]: 使Prompt调优视觉Transformer更为健壮的ADAPT

    ADAPT to Robustify Prompt Tuning Vision Transformers

    [https://arxiv.org/abs/2403.13196](https://arxiv.org/abs/2403.13196)

    本文提出了ADAPT框架，用于在prompt调优范式中进行自适应对抗训练，增强视觉Transformer在下游任务中的稳健性。

    

    深度模型的性能，包括视觉Transformer，已知容易受到对抗性攻击的影响。许多现有对抗性防御方法，如对抗性训练，依赖于对整个模型进行全面微调以增加模型的稳健性。这些防御方法需要为每个任务存储整个模型的副本，而模型可能包含数十亿个参数。与此同时，参数高效的prompt调优被用来适应大型基于Transformer的模型到下游任务，无需保存大型副本。本文从稳健性的角度研究了对视觉Transformer进行下游任务的参数高效prompt调优。我们发现，之前的对抗性防御方法在应用到prompt调优范式时，存在梯度模糊并容易受到自适应攻击的影响。我们引入了ADAPT，一种在prompt调优范式中执行自适应对抗训练的新框架。

    arXiv:2403.13196v1 Announce Type: new  Abstract: The performance of deep models, including Vision Transformers, is known to be vulnerable to adversarial attacks. Many existing defenses against these attacks, such as adversarial training, rely on full-model fine-tuning to induce robustness in the models. These defenses require storing a copy of the entire model, that can have billions of parameters, for each task. At the same time, parameter-efficient prompt tuning is used to adapt large transformer-based models to downstream tasks without the need to save large copies. In this paper, we examine parameter-efficient prompt tuning of Vision Transformers for downstream tasks under the lens of robustness. We show that previous adversarial defense methods, when applied to the prompt tuning paradigm, suffer from gradient obfuscation and are vulnerable to adaptive attacks. We introduce ADAPT, a novel framework for performing adaptive adversarial training in the prompt tuning paradigm. Our meth
    
[^11]: 结构化领域上的预测性、可伸缩性和可解释性知识追踪

    Predictive, scalable and interpretable knowledge tracing on structured domains

    [https://arxiv.org/abs/2403.13179](https://arxiv.org/abs/2403.13179)

    本研究提出了一种解决深度学习模型高准确性但低解释性问题的方法，通过PSI-KT的分层生成方法实现了对个体认知特征和知识结构的解释，同时使用可扩展的贝叶斯推断实现了对不断增长的学习者群体的高效个性化。

    

    智能辅导系统通过优化学习材料的选择和时间安排来增强理解和长期记忆。这需要对学习者的进度（''知识追踪''; KT）和学习领域的先决条件结构（''知识映射''）进行估计。在最近的深度学习模型中，高KT准确性是可以实现的，但这是以牺牲心理启发模型的解释性为代价的。在这项工作中，我们提出了一个解决这种权衡的方案。PSI-KT是一种分层生成方法，明确建模了个体认知特征和知识的先决结构如何影响学习动态，从而通过设计实现可解释性。此外，通过使用可扩展的贝叶斯推断，PSI-KT针对现实世界中对高效个性化的需求，即使有着不断增长的学习者群体和学习历史。在在线学习平台的三个数据集上进行了评估。

    arXiv:2403.13179v1 Announce Type: new  Abstract: Intelligent tutoring systems optimize the selection and timing of learning materials to enhance understanding and long-term retention. This requires estimates of both the learner's progress (''knowledge tracing''; KT), and the prerequisite structure of the learning domain (''knowledge mapping''). While recent deep learning models achieve high KT accuracy, they do so at the expense of the interpretability of psychologically-inspired models. In this work, we present a solution to this trade-off. PSI-KT is a hierarchical generative approach that explicitly models how both individual cognitive traits and the prerequisite structure of knowledge influence learning dynamics, thus achieving interpretability by design. Moreover, by using scalable Bayesian inference, PSI-KT targets the real-world need for efficient personalization even with a growing body of learners and learning histories. Evaluated on three datasets from online learning platform
    
[^12]: 深度强化学习的快速价值跟踪

    Fast Value Tracking for Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.13178](https://arxiv.org/abs/2403.13178)

    我们的研究提出一种基于Kalman滤波范式的新颖和可扩展的采样算法LKTD，用于深度强化学习，能够有效地从深度神经网络参数的后验分布中抽取样本，并证明这些后验样本会收敛到一个稳定分布。

    

    强化学习（RL）通过创建与环境互动的Agent来解决顺序决策问题。然而，现有算法通常将这些问题视为静态问题，专注于模型参数的点估计以最大化预期奖励，忽视了Agent-Environment互动的随机动力学和不确定性量化的关键作用。我们的研究利用卡尔曼滤波范式引入了一种新颖且可扩展的采样算法，称为Langevinized Kalman Temporal-Difference（LKTD）用于深度强化学习。这种算法基于随机梯度马尔科夫链蒙特卡罗（SGMCMC），能够有效地从深度神经网络参数的后验分布中抽取样本。在温和条件下，我们证明了LKTD算法生成的后验样本会收敛到一个稳定分布。这种收敛不仅使我们能够量化不确定性，

    arXiv:2403.13178v1 Announce Type: cross  Abstract: Reinforcement learning (RL) tackles sequential decision-making problems by creating agents that interacts with their environment. However, existing algorithms often view these problem as static, focusing on point estimates for model parameters to maximize expected rewards, neglecting the stochastic dynamics of agent-environment interactions and the critical role of uncertainty quantification. Our research leverages the Kalman filtering paradigm to introduce a novel and scalable sampling algorithm called Langevinized Kalman Temporal-Difference (LKTD) for deep reinforcement learning. This algorithm, grounded in Stochastic Gradient Markov Chain Monte Carlo (SGMCMC), efficiently draws samples from the posterior distribution of deep neural network parameters. Under mild conditions, we prove that the posterior samples generated by the LKTD algorithm converge to a stationary distribution. This convergence not only enables us to quantify uncer
    
[^13]: 使用评分规则训练生存模型

    Training Survival Models using Scoring Rules

    [https://arxiv.org/abs/2403.13150](https://arxiv.org/abs/2403.13150)

    提出了一种使用评分规则训练生存模型的通用方法，将其应用于各种模型类别中并与神经网络结合，实现了高效可扩展的优化例程，并展示了优于基于似然性方法的预测性能。

    

    生存分析为各个领域中部分不完整的事件发生时间数据提供了关键见解。它也是概率机器学习的一个重要示例。我们的提案以一种通用的方式利用了预测的概率性质，通过在模型拟合过程中使用（合适的）评分规则而非基于似然性的优化。我们建立了不同的参数化和非参数化子框架，允许不同程度的灵活性。将其混入神经网络中，导致了一个计算有效且可扩展的优化例程，产生了最先进的预测性能。最后，我们展示了使用我们的框架，可以恢复各种参数化模型，并证明在与基于似然性方法的比较中，优化效果同样出色。

    arXiv:2403.13150v1 Announce Type: new  Abstract: Survival Analysis provides critical insights for partially incomplete time-to-event data in various domains. It is also an important example of probabilistic machine learning. The probabilistic nature of the predictions can be exploited by using (proper) scoring rules in the model fitting process instead of likelihood-based optimization. Our proposal does so in a generic manner and can be used for a variety of model classes. We establish different parametric and non-parametric sub-frameworks that allow different degrees of flexibility. Incorporated into neural networks, it leads to a computationally efficient and scalable optimization routine, yielding state-of-the-art predictive performance. Finally, we show that using our framework, we can recover various parametric models and demonstrate that optimization works equally well when compared to likelihood-based methods.
    
[^14]: Function Trees: 透明机器学习

    Function Trees: Transparent Machine Learning

    [https://arxiv.org/abs/2403.13141](https://arxiv.org/abs/2403.13141)

    提出了一种表示一般多变量函数为简单函数树的方法，该树能够快速识别和计算函数的主要和交互效应直至高阶，以图形化方式展示涉及到四个变量的交互效应。

    

    机器学习算法的输出通常可以用其输入变量的一个或多个多变量函数表示。了解这类函数的全局特性有助于理解生成数据的系统，以及解释和阐释相应的模型预测。提出了一种将一般多变量函数表示为简单函数树的方法。这棵树通过揭示和描述其输入变量子集的联合影响，来暴露函数的全局内部结构。根据输入和对应的函数值，构建了一个可以快速识别和计算函数的所有主要和交互效应直至高阶的函数树。涉及到四个变量的交互效应进行了图形化可视化。

    arXiv:2403.13141v1 Announce Type: cross  Abstract: The output of a machine learning algorithm can usually be represented by one or more multivariate functions of its input variables. Knowing the global properties of such functions can help in understanding the system that produced the data as well as interpreting and explaining corresponding model predictions. A method is presented for representing a general multivariate function as a tree of simpler functions. This tree exposes the global internal structure of the function by uncovering and describing the combined joint influences of subsets of its input variables. Given the inputs and corresponding function values, a function tree is constructed that can be used to rapidly identify and compute all of the function's main and interaction effects up to high order. Interaction effects involving up to four variables are graphically visualized.
    
[^15]: 针对对抗训练的鲁棒神经结构搜索：基准、理论及其扩展

    Robust NAS under adversarial training: benchmark, theory, and beyond

    [https://arxiv.org/abs/2403.13134](https://arxiv.org/abs/2403.13134)

    该论文提出了针对对抗训练下的鲁棒神经结构搜索的基准数据集和泛化理论，有望极大地推动NAS领域的发展。

    

    近期神经结构搜索（NAS）的发展强调考虑针对恶意数据的鲁棒结构的重要性。然而，在搜索这些鲁棒结构时，在考虑对抗训练时存在着明显的缺乏基准评估和理论保证。本文旨在解决这两个挑战，做出双重贡献。首先，我们发布了一个全面的数据集，涵盖了来自NAS-Bench-201搜索空间的广泛图像数据集上经过对抗训练的网络的干净精度和鲁棒精度。然后，利用深度学习理论中的神经切向核(NTK)工具，我们建立了一个多目标对抗训练下搜索结构的泛化理论，以干净精度和鲁棒精度作为考量。我们坚信我们的基准和理论见解将极大地有益于NAS领域。

    arXiv:2403.13134v1 Announce Type: new  Abstract: Recent developments in neural architecture search (NAS) emphasize the significance of considering robust architectures against malicious data. However, there is a notable absence of benchmark evaluations and theoretical guarantees for searching these robust architectures, especially when adversarial training is considered. In this work, we aim to address these two challenges, making twofold contributions. First, we release a comprehensive data set that encompasses both clean accuracy and robust accuracy for a vast array of adversarially trained networks from the NAS-Bench-201 search space on image datasets. Then, leveraging the neural tangent kernel (NTK) tool from deep learning theory, we establish a generalization theory for searching architecture in terms of clean accuracy and robust accuracy under multi-objective adversarial training. We firmly believe that our benchmark and theoretical insights will significantly benefit the NAS com
    
[^16]: 通过多元高斯过程回归对时空数据进行模态分析

    Modal Analysis of Spatiotemporal Data via Multivariate Gaussian Process Regression

    [https://arxiv.org/abs/2403.13118](https://arxiv.org/abs/2403.13118)

    提出了一种使用多元高斯过程回归的新型模态分析技术，以解决稀疏时间不规则数据的限制。

    

    模态分析已成为理解复杂流体的一种重要工具。传统的模态分析方法，如动态模态分解（DMD）和谱Proper Orthogonal Decomposition（SPOD），依赖于在时间上定期取样的充分数据量。然而，通常需要处理稀疏的时间不规则数据，例如由于实验测量和仿真算法。为了克服数据稀缺和不规则采样的限制，我们提出了一种使用多元高斯过程回归（MVGPR）的新型模态分析技术。我们首先从线性系统识别的角度建立了MVGPR与现有模态分析技术DMD和SPOD之间的联系。接下来，利用这种联系，我们开发了一种基于MVGPR的模态分析技术，以解决前述的限制。MVGPR的功能是通过其谨慎的判断能力赋予的。

    arXiv:2403.13118v1 Announce Type: cross  Abstract: Modal analysis has become an essential tool to understand the coherent structure of complex flows. The classical modal analysis methods, such as dynamic mode decomposition (DMD) and spectral proper orthogonal decomposition (SPOD), rely on a sufficient amount of data that is regularly sampled in time. However, often one needs to deal with sparse temporally irregular data, e.g., due to experimental measurements and simulation algorithm. To overcome the limitations of data scarcity and irregular sampling, we propose a novel modal analysis technique using multi-variate Gaussian process regression (MVGPR). We first establish the connection between MVGPR and the existing modal analysis techniques, DMD and SPOD, from a linear system identification perspective. Next, leveraging this connection, we develop a MVGPR-based modal analysis technique that addresses the aforementioned limitations. The capability of MVGPR is endowed by its judiciously 
    
[^17]: 最优流匹配：在一步中学习直线轨迹

    Optimal Flow Matching: Learning Straight Trajectories in Just One Step

    [https://arxiv.org/abs/2403.13117](https://arxiv.org/abs/2403.13117)

    该论文提出了一种新颖的最优流匹配方法，能够在一步中学习实现二次成本下的直线 OT 位移。

    

    在过去几年中，流匹配方法在生成建模中得到了蓬勃发展。社区追求的一个引人注目的属性是能够学习具有直线轨迹的流，这些轨迹实现了最优输运（OT）置换。直线性对于快速集成学习流的路径至关重要。不幸的是，大多数现有的流直线化方法都基于非平凡的迭代过程，在训练过程中积累误差或利用启发式小批量OT近似。为解决这一问题，我们开发了一种新颖的最优流匹配方法，仅通过一次流匹配步骤即可为二次成本恢复直线OT置换。

    arXiv:2403.13117v1 Announce Type: cross  Abstract: Over the several recent years, there has been a boom in development of flow matching methods for generative modeling. One intriguing property pursued by the community is the ability to learn flows with straight trajectories which realize the optimal transport (OT) displacements. Straightness is crucial for fast integration of the learned flow's paths. Unfortunately, most existing flow straightening methods are based on non-trivial iterative procedures which accumulate the error during training or exploit heuristic minibatch OT approximations. To address this issue, we develop a novel optimal flow matching approach which recovers the straight OT displacement for the quadratic cost in just one flow matching step.
    
[^18]: 具有非私密预处理的可证明隐私

    Provable Privacy with Non-Private Pre-Processing

    [https://arxiv.org/abs/2403.13041](https://arxiv.org/abs/2403.13041)

    提出了一个框架，能够评估非私密数据相关预处理算法引起的额外隐私成本，并利用平滑DP和预处理算法的有界敏感性建立整体隐私保证的上限

    

    当分析差分私密（DP）机器学习管道时，通常会忽略数据相关的预处理的潜在隐私成本。在这项工作中，我们提出了一个通用框架，用于评估由非私密数据相关预处理算法引起的额外隐私成本。我们的框架通过利用两个新的技术概念建立了整体隐私保证的上限：一种称为平滑DP的DP变体以及预处理算法的有界敏感性。

    arXiv:2403.13041v1 Announce Type: cross  Abstract: When analysing Differentially Private (DP) machine learning pipelines, the potential privacy cost of data-dependent pre-processing is frequently overlooked in privacy accounting. In this work, we propose a general framework to evaluate the additional privacy cost incurred by non-private data-dependent pre-processing algorithms. Our framework establishes upper bounds on the overall privacy guarantees by utilising two new technical notions: a variant of DP termed Smooth DP and the bounded sensitivity of the pre-processing algorithms. In addition to the generic framework, we provide explicit overall privacy guarantees for multiple data-dependent pre-processing algorithms, such as data imputation, quantization, deduplication and PCA, when used in combination with several DP algorithms. Notably, this framework is also simple to implement, allowing direct integration into existing DP pipelines.
    
[^19]: 更好地统计理解水印LLMs

    Towards Better Statistical Understanding of Watermarking LLMs

    [https://arxiv.org/abs/2403.13027](https://arxiv.org/abs/2403.13027)

    本文研究了水印LLMs的问题，提出了一种基于优化算法的水印算法，实现了模型失真和检测能力之间的最优平衡。

    

    在本文中，我们研究了水印大型语言模型（LLMs）的问题。我们考虑模型失真和检测能力之间的权衡，并将其构建为基于Kirchenbauer等人（2023a）的绿-红算法的受限优化问题。我们展示了优化问题的最优解享有良好的分析性质，这有助于更好地理解并启发水印过程的算法设计。我们根据这一优化公式开发了一个在线双梯度上升水印算法，并证明了其在模型失真和检测能力之间的渐近帕累托最优性。这样的结果保证了平均增加的绿色列表概率，从而明确提高了检测能力（与先前结果相比）。此外，我们对水印问题的模型失真度量的选择进行了系统讨论。

    arXiv:2403.13027v1 Announce Type: cross  Abstract: In this paper, we study the problem of watermarking large language models (LLMs). We consider the trade-off between model distortion and detection ability and formulate it as a constrained optimization problem based on the green-red algorithm of Kirchenbauer et al. (2023a). We show that the optimal solution to the optimization problem enjoys a nice analytical property which provides a better understanding and inspires the algorithm design for the watermarking process. We develop an online dual gradient ascent watermarking algorithm in light of this optimization formulation and prove its asymptotic Pareto optimality between model distortion and detection ability. Such a result guarantees an averaged increased green list probability and henceforth detection ability explicitly (in contrast to previous results). Moreover, we provide a systematic discussion on the choice of the model distortion metrics for the watermarking problem. We justi
    
[^20]: 当SMILES拥有语言：使用文本分类方法对药物SMILES字符串进行药物分类

    When SMILES have Language: Drug Classification using Text Classification Methods on Drug SMILES Strings

    [https://arxiv.org/abs/2403.12984](https://arxiv.org/abs/2403.12984)

    将药物SMILES字符串视为句子并利用文本分类方法进行药物分类，证实了通过简单的自然语言处理方法解决复杂问题的可能性

    

    复杂的化学结构，如药物，通常由SMILES字符串来定义，作为分子和键的序列。这些SMILES字符串在不同的基于机器学习的药物相关研究和表示工作中使用。在这项工作中，我们摆脱复杂的表示法，提出了一个问题：如果我们将药物SMILES视为常规句子，并进行文本分类以进行药物分类会怎样？我们的实验证实了这种可能性，获得了非常有竞争力的分数。该研究探讨了将每个原子和键视为句子组件的概念，利用基本的自然语言处理方法对药物类型进行分类，表明复杂的问题也可以用更简单的视角来解决。数据和代码可在此处找到：https://github.com/azminewasi/Drug-Classification-NLP。

    arXiv:2403.12984v1 Announce Type: cross  Abstract: Complex chemical structures, like drugs, are usually defined by SMILES strings as a sequence of molecules and bonds. These SMILES strings are used in different complex machine learning-based drug-related research and representation works. Escaping from complex representation, in this work, we pose a single question: What if we treat drug SMILES as conventional sentences and engage in text classification for drug classification? Our experiments affirm the possibility with very competitive scores. The study explores the notion of viewing each atom and bond as sentence components, employing basic NLP methods to categorize drug types, proving that complex problems can also be solved with simpler perspectives. The data and code are available here: https://github.com/azminewasi/Drug-Classification-NLP.
    
[^21]: 用梯度下降训练形态神经网络：一些理论见解

    Training morphological neural networks with gradient descent: some theoretical insights

    [https://arxiv.org/abs/2403.12975](https://arxiv.org/abs/2403.12975)

    形态神经网络的训练存在挑战，本文通过使用基于梯度下降的优化算法，探讨了基于微分方法和反向传播对形态网络的潜力和局限性，提供了关于初始化和学习率的理论指导。

    

    形态神经网络或层可以成为提升数学形态学进展的强大工具，无论是在理论方面，如完整格算子的表示，还是在图像处理流程的开发方面。然而，当这些架构包含多层形态学时，至少在使用基于梯度下降的优化算法的流行机器学习框架内，这些网络很难进行训练。在本文中，我们探讨了基于微分方法和反向传播应用于形态网络的潜力和局限性，考虑到Bouligand导数的非光滑优化概念。我们提供了见解和首个理论指南，特别是关于初始化和学习率。

    arXiv:2403.12975v1 Announce Type: cross  Abstract: Morphological neural networks, or layers, can be a powerful tool to boost the progress in mathematical morphology, either on theoretical aspects such as the representation of complete lattice operators, or in the development of image processing pipelines. However, these architectures turn out to be difficult to train when they count more than a few morphological layers, at least within popular machine learning frameworks which use gradient descent based optimization algorithms. In this paper we investigate the potential and limitations of differentiation based approaches and back-propagation applied to morphological networks, in light of the non-smooth optimization concept of Bouligand derivative. We provide insights and first theoretical guidelines, in particular regarding initialization and learning rates.
    
[^22]: 少数个体的力量：利用核心子集选择加速和优化数据重新加权

    The Power of Few: Accelerating and Enhancing Data Reweighting with Coreset Selection

    [https://arxiv.org/abs/2403.12166](https://arxiv.org/abs/2403.12166)

    提出一种利用核心子集选择进行数据重新加权的方法，有效优化了计算时间和模型性能，突显其作为模型训练的可扩展和精确解决方案的潜力。

    

    随着机器学习任务不断发展，趋势是收集更大的数据集并训练规模越来越大的模型。虽然这提高了准确性，但也将计算成本提高到不可持续的水平。针对这一问题，我们的工作旨在在计算效率和模型准确性之间取得微妙的平衡，这是该领域中一直存在的挑战。我们引入了一种利用核心子集选择进行重新加权的新方法，有效优化了计算时间和模型性能。通过专注于 strategically selected coreset，我们的方法提供了一个稳健的表示，因为它有效地最小化了异常值的影响。然后，重新校准的权重被映射回并传播到整个数据集。我们的实验结果证实了这种方法的有效性，突显了它作为模型训练的可扩展和精确解决方案的潜力。

    arXiv:2403.12166v1 Announce Type: new  Abstract: As machine learning tasks continue to evolve, the trend has been to gather larger datasets and train increasingly larger models. While this has led to advancements in accuracy, it has also escalated computational costs to unsustainable levels. Addressing this, our work aims to strike a delicate balance between computational efficiency and model accuracy, a persisting challenge in the field. We introduce a novel method that employs core subset selection for reweighting, effectively optimizing both computational time and model performance. By focusing on a strategically selected coreset, our approach offers a robust representation, as it efficiently minimizes the influence of outliers. The re-calibrated weights are then mapped back to and propagated across the entire dataset. Our experimental results substantiate the effectiveness of this approach, underscoring its potential as a scalable and precise solution for model training.
    
[^23]: 用于学习神经网络等变表示的图神经网络

    Graph Neural Networks for Learning Equivariant Representations of Neural Networks

    [https://arxiv.org/abs/2403.12143](https://arxiv.org/abs/2403.12143)

    本研究提出了将神经网络表示为参数的计算图的方法，利用图神经网络和变压器来实现置换对称性，使得单个模型能够处理具有多种架构的神经计算图。

    

    处理其他神经网络参数的神经网络在诸如分类隐式神经表示、生成神经网络权重和预测泛化错误等领域中得到应用。然而，现有方法要么忽视神经网络中固有的置换对称性，要么依赖复杂的权重共享模式来实现等变性，同时忽略网络架构本身的影响。在本文中，我们提出将神经网络表示为参数的计算图，这使我们能够利用强大的保留置换对称性的图神经网络和变压器。因此，我们的方法使得单个模型能够对具有多样架构的神经计算图进行编码。我们展示了我们的方法在包括分类和编辑隐式神经表示、预测泛化错误等多种任务中的有效性。

    arXiv:2403.12143v1 Announce Type: cross  Abstract: Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalizati
    
[^24]: 随机扰动下奇异子空间的分析

    Analysis of singular subspaces under random perturbations

    [https://arxiv.org/abs/2403.09170](https://arxiv.org/abs/2403.09170)

    在信号加随机高斯噪声矩阵模型的背景下，扩展了对奇异向量和奇异子空间扰动的Wedin-Davis-Kahan定理，获得了奇异向量和奇异子空间的细粒度分析结果，并探索了与奇异向量相关的线性和双线性函数，同时探讨了这些发现在高斯混合模型和子矩阵定位问题中的实际应用。

    

    我们在信号加随机高斯噪声矩阵模型的背景下，对奇异向量和奇异子空间的扰动进行了全面分析。假设一个低秩信号矩阵，我们以一种完全泛化的方式扩展了Wedin-Davis-Kahan定理，适用于任何酉不变矩阵范数，扩展了O'Rourke、Vu和作者之前的结果。我们还获得了细粒度的结果，其中包括奇异向量的$\ell_\infty$分析，奇异子空间的$\ell_{2,\infty}$分析，以及与奇异向量相关的线性和双线性函数的探索。此外，我们探讨了这些发现在高斯混合模型和子矩阵定位问题的实际影响。

    arXiv:2403.09170v1 Announce Type: cross  Abstract: We present a comprehensive analysis of singular vector and singular subspace perturbations in the context of the signal plus random Gaussian noise matrix model. Assuming a low-rank signal matrix, we extend the Wedin-Davis-Kahan theorem in a fully generalized manner, applicable to any unitarily invariant matrix norm, extending previous results of O'Rourke, Vu and the author. We also obtain the fine-grained results, which encompass the $\ell_\infty$ analysis of singular vectors, the $\ell_{2, \infty}$ analysis of singular subspaces, as well as the exploration of linear and bilinear functions related to the singular vectors. Moreover, we explore the practical implications of these findings, in the context of the Gaussian mixture model and the submatrix localization problem.
    
[^25]: 评估执法系统中种族偏见的因果框架

    A Causal Framework to Evaluate Racial Bias in Law Enforcement Systems

    [https://arxiv.org/abs/2402.14959](https://arxiv.org/abs/2402.14959)

    本论文提出了一个多阶段因果框架，融入犯罪行为，用于评估执法系统中的种族偏见，以解决以往研究中存在的限制，对偏见进行量化，并确定主要偏见来源。

    

    我们致力于开发一种数据驱动方法来评估执法系统中种族诱发的偏见。 在最近的研究中，已经讨论了在警民互动背景下使用警察停车数据解决这个问题，但存在两个关键限制。 首先，只有在将真实犯罪行为考虑在内时，偏见才能得到恰当量化，但在以前的研究中缺乏。 第二，执法系统是多阶段的，因此重要的是在“因果交互链”中孤立出偏见的真正来源，而不仅仅关注最终结果； 这有助于引导改革。 在这项工作中，我们通过提出一个包含犯罪行为的多阶段因果框架来解决这些挑战。 我们提供了一个理论特征和一个相关的数据驱动方法来评估(a)任何形式的种族偏见的存在，以及(b)如果是这样，这种偏见的主要来源是种族和...

    arXiv:2402.14959v1 Announce Type: cross  Abstract: We are interested in developing a data-driven method to evaluate race-induced biases in law enforcement systems. While the recent works have addressed this question in the context of police-civilian interactions using police stop data, they have two key limitations. First, bias can only be properly quantified if true criminality is accounted for in addition to race, but it is absent in prior works. Second, law enforcement systems are multi-stage and hence it is important to isolate the true source of bias within the "causal chain of interactions" rather than simply focusing on the end outcome; this can help guide reforms. In this work, we address these challenges by presenting a multi-stage causal framework incorporating criminality. We provide a theoretical characterization and an associated data-driven method to evaluate (a) the presence of any form of racial bias, and (b) if so, the primary source of such a bias in terms of race and
    
[^26]: 扩散吉布斯采样

    Diffusive Gibbs Sampling

    [https://arxiv.org/abs/2402.03008](https://arxiv.org/abs/2402.03008)

    扩散吉布斯采样是一种创新的采样方法，通过集成扩散模型并应用吉布斯采样，有效地从具有远程和断开模态特征的分布中采样，表现出比其他方法更好的混合性能，并在多种任务中取得显著改进的结果。

    

    传统马尔可夫链蒙特卡洛（MCMC）方法在多模态分布的混合不足方面存在着挑战，特别是在贝叶斯推断和分子动力学等实际应用中。针对这个问题，我们提出了一种创新的采样方法——扩散吉布斯采样（DiGS），用于有效采样具有远程和断开模态特征的分布。DiGS集成了扩散模型的最新发展，利用高斯卷积创建一个辅助噪声分布，以在原始空间中连接孤立的模态，并应用吉布斯采样从两个空间中交替抽取样本。我们的方法在采样多模态分布方面表现出比并行温度法等最先进方法更好的混合性能。我们证明我们的采样器在各种任务中取得了显著改进的结果，包括高斯混合模型、贝叶斯神经网络和分子动力学。

    The inadequate mixing of conventional Markov Chain Monte Carlo (MCMC) methods for multi-modal distributions presents a significant challenge in practical applications such as Bayesian inference and molecular dynamics. Addressing this, we propose Diffusive Gibbs Sampling (DiGS), an innovative family of sampling methods designed for effective sampling from distributions characterized by distant and disconnected modes. DiGS integrates recent developments in diffusion models, leveraging Gaussian convolution to create an auxiliary noisy distribution that bridges isolated modes in the original space and applying Gibbs sampling to alternately draw samples from both spaces. Our approach exhibits a better mixing property for sampling multi-modal distributions than state-of-the-art methods such as parallel tempering. We demonstrate that our sampler attains substantially improved results across various tasks, including mixtures of Gaussians, Bayesian neural networks and molecular dynamics.
    
[^27]: 混合量子视觉转换器用于高能物理事件分类

    Hybrid Quantum Vision Transformers for Event Classification in High Energy Physics

    [https://arxiv.org/abs/2402.00776](https://arxiv.org/abs/2402.00776)

    该论文提出了一种基于量子的混合视觉转换器模型，用于高能物理中的事件分类任务。通过减少训练和操作时间，该模型可以达到与经典模型相当的性能。

    

    基于视觉转换器架构的模型被认为是图像分类任务中的最先进技术。然而，它们在训练和部署中都需要大量的计算资源。随着数据的数量和复杂性增加，这个问题变得更加严重。基于量子的视觉转换器模型可能通过减少训练和操作时间来缓解这个问题，同时保持相同的预测能力。尽管当前的量子计算机尚不能执行高维任务，但它们提供了未来最高效的解决方案之一。在这项工作中，我们构建了几种不同的量子混合视觉转换器，用于高能物理中的分类问题（区分电子和光子在电磁量能器中）。我们将它们与经典的视觉转换器架构进行了测试。我们的研究结果表明，混合模型可以达到与经典模型相当的性能。

    Models based on vision transformer architectures are considered state-of-the-art when it comes to image classification tasks. However, they require extensive computational resources both for training and deployment. The problem is exacerbated as the amount and complexity of the data increases. Quantum-based vision transformer models could potentially alleviate this issue by reducing the training and operating time while maintaining the same predictive power. Although current quantum computers are not yet able to perform high-dimensional tasks yet, they do offer one of the most efficient solutions for the future. In this work, we construct several variations of a quantum hybrid vision transformer for a classification problem in high energy physics (distinguishing photons and electrons in the electromagnetic calorimeter). We test them against classical vision transformer architectures. Our findings indicate that the hybrid models can achieve comparable performance to their classical anal
    
[^28]: 证实无荒原存在是否意味着经典模拟？或者，为什么我们需要重新思考变分量子计算

    Does provable absence of barren plateaus imply classical simulability? Or, why we need to rethink variational quantum computing

    [https://arxiv.org/abs/2312.09121](https://arxiv.org/abs/2312.09121)

    常用的具有无荒原证明的模型也可以在进行初始数据采集阶段从量子设备中收集一些经典数据的情况下经典模拟

    

    最近，人们对荒原现象进行了大量研究。 在这篇观点文章中，我们面对了越来越明显的问题，并提出了一个许多人暗示但尚未明确解决的问题：允许避免荒原的结构是否也可以被利用来有效地经典模拟损失？ 我们提供了强有力的证据，表明常用的具有无荒原证明的模型也可以在进行初始数据采集阶段从量子设备中收集一些经典数据的情况下经典模拟。 这是因为荒原现象是由维度的诅咒导致的，而目前解决问题的方法最终将问题编码到一些小的、经典可模拟的子空间中。 因此，尽管强调量子计算可以是收集数据的必要条件，我们的分析引起了严重的思考。

    arXiv:2312.09121v2 Announce Type: replace-cross  Abstract: A large amount of effort has recently been put into understanding the barren plateau phenomenon. In this perspective article, we face the increasingly loud elephant in the room and ask a question that has been hinted at by many but not explicitly addressed: Can the structure that allows one to avoid barren plateaus also be leveraged to efficiently simulate the loss classically? We present strong evidence that commonly used models with provable absence of barren plateaus are also classically simulable, provided that one can collect some classical data from quantum devices during an initial data acquisition phase. This follows from the observation that barren plateaus result from a curse of dimensionality, and that current approaches for solving them end up encoding the problem into some small, classically simulable, subspaces. Thus, while stressing quantum computers can be essential for collecting data, our analysis sheds seriou
    
[^29]: 具有时空视频扩散的降水降尺度

    Precipitation Downscaling with Spatiotemporal Video Diffusion

    [https://arxiv.org/abs/2312.06071](https://arxiv.org/abs/2312.06071)

    通过扩展视频扩散模型至降水超分辨率，本研究提出了一种利用确定性降尺度器和暂时条件扩散模型来捕捉噪声特征和高频率模式的方法。

    

    在气候科学和气象学领域，高分辨率的局部降水（雨雪）预测受到基于模拟方法的计算成本限制。统计降尺度，或者称为超分辨率，是一种常见的解决方法，其中低分辨率预测通过统计方法得到改进。与传统计算机视觉任务不同，天气和气候应用需要捕捉给定低分辨率模式的高分辨率的准确条件分布，以确保可靠的集合平均和极端事件（如暴雨）的无偏估计。本研究将最新的视频扩散模型扩展到降水超分辨率，使用确定性降尺度器，然后是暂时条件的扩散模型来捕捉噪声特征和高频率模式。我们在FV3GFS输出上测试了我们的方法，这是一个已建立的大规模全球大气模型，并将其与其他方法进行了比较。

    arXiv:2312.06071v2 Announce Type: replace-cross  Abstract: In climate science and meteorology, high-resolution local precipitation (rain and snowfall) predictions are limited by the computational costs of simulation-based methods. Statistical downscaling, or super-resolution, is a common workaround where a low-resolution prediction is improved using statistical approaches. Unlike traditional computer vision tasks, weather and climate applications require capturing the accurate conditional distribution of high-resolution given low-resolution patterns to assure reliable ensemble averages and unbiased estimates of extreme events, such as heavy rain. This work extends recent video diffusion models to precipitation super-resolution, employing a deterministic downscaler followed by a temporally-conditioned diffusion model to capture noise characteristics and high-frequency patterns. We test our approach on FV3GFS output, an established large-scale global atmosphere model, and compare it agai
    
[^30]: 分析和改进扩散模型的训练动力学

    Analyzing and Improving the Training Dynamics of Diffusion Models

    [https://arxiv.org/abs/2312.02696](https://arxiv.org/abs/2312.02696)

    通过重新设计网络层来保持期望的激活、权重和更新幅度，消除了扩散模型中观察到的漂移和不平衡，从而在相同的计算复杂性下获得了更好的网络性能。

    

    扩散模型目前在数据驱动图像合成领域占据主导地位，其对大规模数据集的无与伦比的扩展能力。本文在不改变其高级结构的前提下，识别并纠正了流行的ADM扩散模型架构中导致不均匀和低效训练的几个原因。观察到在训练过程中网络激活和权重的不受控制的幅度变化和不平衡，我们重新设计了网络层以保持期望上的激活、权重和更新幅度。我们发现，系统应用这一理念消除了观察到的漂移和不平衡，导致相当更好的网络在等效的计算复杂性下。我们的修改将之前在ImageNet-512合成中的记录FID从2.41改进到了1.81，采用了快速确定性采样实现。

    arXiv:2312.02696v2 Announce Type: replace-cross  Abstract: Diffusion models currently dominate the field of data-driven image synthesis with their unparalleled scaling to large datasets. In this paper, we identify and rectify several causes for uneven and ineffective training in the popular ADM diffusion model architecture, without altering its high-level structure. Observing uncontrolled magnitude changes and imbalances in both the network activations and weights over the course of training, we redesign the network layers to preserve activation, weight, and update magnitudes on expectation. We find that systematic application of this philosophy eliminates the observed drifts and imbalances, resulting in considerably better networks at equal computational complexity. Our modifications improve the previous record FID of 2.41 in ImageNet-512 synthesis to 1.81, achieved using fast deterministic sampling.   As an independent contribution, we present a method for setting the exponential mov
    
[^31]: 可解释的物理系统元学习

    Interpretable Meta-Learning of Physical Systems

    [https://arxiv.org/abs/2312.00477](https://arxiv.org/abs/2312.00477)

    通过提出一个具有仿射结构的简单学习模型，本研究实现了多环境泛化，能够识别物理系统的参数，实现了可解释性学习。

    

    机器学习方法可以在科学过程中发挥重要作用，但它们需要面对数据来自不均匀实验条件的挑战性情境。近期的元学习方法在多任务学习方面取得了显著进展，但它们依赖于黑盒神经网络，导致高计算成本和有限的可解释性。通过利用学习问题的结构，我们认为可以使用一个更简单的学习模型，即对于学习任务具有仿射结构，来实现多环境泛化。至关重要的是，我们证明了这种架构能够识别系统的物理参数，实现可解释性学习。我们通过将其与物理系统上的最先进算法进行比较，从玩具模型到复杂的非解析系统，展示了我们方法的竞争性泛化性能和低计算成本。

    arXiv:2312.00477v2 Announce Type: replace  Abstract: Machine learning methods can be a valuable aid in the scientific process, but they need to face challenging settings where data come from inhomogeneous experimental conditions. Recent meta-learning methods have made significant progress in multi-task learning, but they rely on black-box neural networks, resulting in high computational costs and limited interpretability. Leveraging the structure of the learning problem, we argue that multi-environment generalization can be achieved using a simpler learning model, with an affine structure with respect to the learning task. Crucially, we prove that this architecture can identify the physical parameters of the system, enabling interpreable learning. We demonstrate the competitive generalization performance and the low computational cost of our method by comparing it to state-of-the-art algorithms on physical systems, ranging from toy models to complex, non-analytical systems. The interpr
    
[^32]: 集成模型是否一直在不断进步？

    Are Ensembles Getting Better all the Time?

    [https://arxiv.org/abs/2311.17885](https://arxiv.org/abs/2311.17885)

    只有当考虑的损失函数为凸函数时，集成模型一直在变得更好，当损失函数为非凸函数时，好模型的集成变得更好，坏模型的集成变得更糟。

    

    集成方法结合了几个基础模型的预测。本研究探讨了是否始终将更多模型纳入集成会提升其平均性能。这个问题取决于所考虑的集成类型，以及选择的预测度量。我们专注于所有集成成员被预期表现相同的情况，这是几种流行方法（如随机森林或深度集成）的情况。在这种设定下，我们表明，只有当考虑的损失函数为凸函数时，集成才会一直变得更好。更具体地说，在这种情况下，集成的平均损失是模型数量的减函数。当损失函数为非凸函数时，我们展示了一系列结果，可以总结为：好模型的集成会变得更好，坏模型的集成会变得更糟。为此，我们证明了关于尾概率单调性的新结果。

    arXiv:2311.17885v2 Announce Type: replace-cross  Abstract: Ensemble methods combine the predictions of several base models. We study whether or not including more models always improves their average performance. This question depends on the kind of ensemble considered, as well as the predictive metric chosen. We focus on situations where all members of the ensemble are a priori expected to perform as well, which is the case of several popular methods such as random forests or deep ensembles. In this setting, we show that ensembles are getting better all the time if, and only if, the considered loss function is convex. More precisely, in that case, the average loss of the ensemble is a decreasing function of the number of models. When the loss function is nonconvex, we show a series of results that can be summarised as: ensembles of good models keep getting better, and ensembles of bad models keep getting worse. To this end, we prove a new result on the monotonicity of tail probabiliti
    
[^33]: 基于跨度的平均回报MDP的最优采样复杂性

    Span-Based Optimal Sample Complexity for Average Reward MDPs

    [https://arxiv.org/abs/2311.13469](https://arxiv.org/abs/2311.13469)

    该研究提出了基于跨度的平均回报MDP中学习最优策略的最优样本复杂度界限，是首个在所有参数方面都是极小极大最优的结果。

    

    我们研究了在一个生成模型下学习平均回报马尔可夫决策过程（MDP）中的$\varepsilon$-最优策略的样本复杂性。我们建立了复杂度界限$\widetilde{O}\left(SA\frac{H}{\varepsilon^2} \right)$，其中$H$是最优策略的偏差函数的跨度，$SA$是状态-动作空间的基数。我们的结果是第一个在所有参数$S,A,H$和$\varepsilon$中（最多对数因子）是极小极大最优的，改进了现有工作，现有工作要么假设所有策略的混合时间均匀有界，要么对参数有次最优的依赖。我们的结果基于将平均回报MDP降级为折扣MDP。为了建立这种降级的最优性，我们为$\gamma$-折扣MDP开发了改进的界限，表明$\widetilde{O}\left(SA\frac{H}{(1-\gamma)^2\varepsilon^2} \right)$个样本足以学习弱ly c

    arXiv:2311.13469v2 Announce Type: replace  Abstract: We study the sample complexity of learning an $\varepsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. We establish the complexity bound $\widetilde{O}\left(SA\frac{H}{\varepsilon^2} \right)$, where $H$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,H$ and $\varepsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters.   Our result is based on reducing the average-reward MDP to a discounted MDP. To establish the optimality of this reduction, we develop improved bounds for $\gamma$-discounted MDPs, showing that $\widetilde{O}\left(SA\frac{H}{(1-\gamma)^2\varepsilon^2} \right)$ samples suffice to learn a $\varepsilon$-optimal policy in weakly c
    
[^34]: 分布式估计和推断用于半参数二元响应模型

    Distributed Estimation and Inference for Semi-parametric Binary Response Models

    [https://arxiv.org/abs/2210.08393](https://arxiv.org/abs/2210.08393)

    通过一次性分治估计和多轮估计，本文提出了分布式环境下对半参数二元选择模型的新估计方法，实现了优化误差的超线性改进。

    

    现代技术的发展使得数据收集的规模前所未有，这给许多统计估计和推断问题带来了新挑战。本文研究了在分布式计算环境下对半参数二元选择模型的最大分数估计器，而无需预先指定噪声分布。传统的分治估计器在计算上昂贵，并受到机器数量的非正则约束的限制，这是由于目标函数的高度非光滑性质导致的。我们提出了(1)在平滑目标之后进行一次性分治估计以放宽约束，以及(2)通过迭代平滑完全去除约束的多轮估计。我们指定了一种自适应的核平滑器选择，通过顺序缩小带宽在多次迭代中实现了对优化误差的超线性改进。

    arXiv:2210.08393v3 Announce Type: replace-cross  Abstract: The development of modern technology has enabled data collection of unprecedented size, which poses new challenges to many statistical estimation and inference problems. This paper studies the maximum score estimator of a semi-parametric binary choice model under a distributed computing environment without pre-specifying the noise distribution. An intuitive divide-and-conquer estimator is computationally expensive and restricted by a non-regular constraint on the number of machines, due to the highly non-smooth nature of the objective function. We propose (1) a one-shot divide-and-conquer estimator after smoothing the objective to relax the constraint, and (2) a multi-round estimator to completely remove the constraint via iterative smoothing. We specify an adaptive choice of kernel smoother with a sequentially shrinking bandwidth to achieve the superlinear improvement of the optimization error over the multiple iterations. The
    
[^35]: 具有多类型生成森林的正则化磁 Laplacian 的稀疏化

    Sparsification of the regularized magnetic Laplacian with multi-type spanning forests

    [https://arxiv.org/abs/2208.14797](https://arxiv.org/abs/2208.14797)

    本文研究了具有多类型生成森林的正则化磁 Laplacian 的稀疏化方法，以解决大而密集图的谱近似问题。

    

    在本文中，我们考虑一个 ${\rm U}(1)$-connection 图，即一个图，其中每条有向边都赋予一个单位模复数，在反向时取共轭。对于组合 Laplacian 的一个自然替代物是磁 Laplacian，一个包含了关于图连接信息的 Hermite 矩阵。磁 Laplacians 在角度同步问题中出现。在大而密集的图的背景下，我们研究了磁 Laplacian $\Delta$ 的稀疏化，即基于具有少量边的子图的谱近似。我们的方法依赖于使用自定义行列式点过程对多类型生成森林（MTSFs）进行抽样，这是一个概率分布，有利于多样性。简而言之，MTSF 是一个生成子图，其连通分量为树或环根树。

    arXiv:2208.14797v2 Announce Type: replace-cross  Abstract: In this paper, we consider a ${\rm U}(1)$-connection graph, that is, a graph where each oriented edge is endowed with a unit modulus complex number that is conjugated under orientation flip. A natural replacement for the combinatorial Laplacian is then the magnetic Laplacian, an Hermitian matrix that includes information about the graph's connection. Magnetic Laplacians appear, e.g., in the problem of angular synchronization. In the context of large and dense graphs, we study here sparsifiers of the magnetic Laplacian $\Delta$, i.e., spectral approximations based on subgraphs with few edges. Our approach relies on sampling multi-type spanning forests (MTSFs) using a custom determinantal point process, a probability distribution over edges that favours diversity. In a word, an MTSF is a spanning subgraph whose connected components are either trees or cycle-rooted trees. The latter partially capture the angular inconsistencies of
    
[^36]: 用于相互作用动态系统的Roto-translated局部坐标系

    Roto-translated Local Coordinate Frames For Interacting Dynamical Systems

    [https://arxiv.org/abs/2110.14961](https://arxiv.org/abs/2110.14961)

    本研究提出了为每个节点-对象引入局部坐标系，以诱导相互作用动态系统的几何图具有旋转-平移不变性。

    

    建模相互作用在学习复杂动态系统中是至关重要的，即相互作用对象具有高度非线性和时变行为的系统。在$\textit{几何图}$，$\textit{即}$，节点在欧几里得空间中放置的图形中，即使是在$\textit{任意}$选择的全局坐标系中，可以形式化地表示大类这样的系统，例如交通场景中的车辆。尽管全局坐标系是任意选择的，但各自动态系统的控制动力学不变于旋转和平移，也被称为$\textit{伽利略不变性}$。忽略这些不变性会导致更差的泛化能力，因此在这项工作中，我们提出每个节点对象的局部坐标系，以诱导相互作用动态系统的几何图具有旋转-平移不变性。此外，局部坐标系允许自然定义各向异性滤波器

    arXiv:2110.14961v3 Announce Type: replace  Abstract: Modelling interactions is critical in learning complex dynamical systems, namely systems of interacting objects with highly non-linear and time-dependent behaviour. A large class of such systems can be formalized as $\textit{geometric graphs}$, $\textit{i.e.}$, graphs with nodes positioned in the Euclidean space given an $\textit{arbitrarily}$ chosen global coordinate system, for instance vehicles in a traffic scene. Notwithstanding the arbitrary global coordinate system, the governing dynamics of the respective dynamical systems are invariant to rotations and translations, also known as $\textit{Galilean invariance}$. As ignoring these invariances leads to worse generalization, in this work we propose local coordinate frames per node-object to induce roto-translation invariance to the geometric graph of the interacting dynamical system. Further, the local coordinate frames allow for a natural definition of anisotropic filtering in g
    
[^37]: 在度量空间中学习弱凸集合

    Learning Weakly Convex Sets in Metric Spaces

    [https://arxiv.org/abs/2105.06251](https://arxiv.org/abs/2105.06251)

    本文表明可以在多项式时间内解决一致的假设找到问题，并展示了一种广泛类别的弱凸假设。

    

    机器学习理论中研究的一个核心问题是对于给定类别的假设，是否可能有效地找到一个{一致的}假设，即具有零训练误差的假设。尽管涉及{\em 凸}假设的问题已得到广泛研究，但对于由可能有几个不连续区域组成的非凸假设是否可以进行有效学习的问题仍不太清楚。虽然很久以前就已经表明对于布尔函数的特殊情况可以有效地学习弱凸假设（凸假设的参数化调整），但至今尚未研究这个想法是否可以发展为通用范式。在本文中，我们给出了积极答复，并展示了一种广泛类别的弱凸假设的一致假设找到问题确实可以在多项式时间内解决。

    arXiv:2105.06251v2 Announce Type: replace  Abstract: One of the central problems studied in the theory of machine learning is the question of whether, for a given class of hypotheses, it is possible to efficiently find a {consistent} hypothesis, i.e., which has zero training error. While problems involving {\em convex} hypotheses have been extensively studied, the question of whether efficient learning is possible for non-convex hypotheses composed of possibly several disconnected regions is still less understood. Although it has been shown quite a while ago that efficient learning of weakly convex hypotheses, a parameterized relaxation of convex hypotheses, is possible for the special case of Boolean functions, the question of whether this idea can be developed into a generic paradigm has not been studied yet. In this paper, we provide a positive answer and show that the consistent hypothesis finding problem can indeed be solved in polynomial time for a broad class of weakly convex hy
    
[^38]: 在具有许多臂的多臂老虎机中，贪婪算法的不合理有效性

    The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms

    [https://arxiv.org/abs/2002.10121](https://arxiv.org/abs/2002.10121)

    发现贪婪算法在多臂老虎机问题中表现出不合理的有效性，并提出了一种新形式的自由探索，对贪婪算法有益。

    

    我们研究了贝叶斯$k$-臂老虎机问题，在\emph{众多臂}情景下，其中$k \geq \sqrt{T}$，$T$代表时间跨度。最初，与最近有关多臂老虎机问题的文献一致，我们观察到子采样在设计最优算法中起着关键作用；传统的上置信界（UCB）算法是次优的，而一个子采样的UCB（SS-UCB），在UCB框架下选择$\Theta(\sqrt{T})$个臂进行执行，达到了速率最优性。然而，尽管SS-UCB在理论上承诺了最优遗憾，但在实验中与一种始终选择经验上最佳臂的贪婪算法相比表现不佳。这一发现通过对真实世界数据的模拟延伸到了情境设置。我们的发现提示一种对于多臂情况下贪婪算法有益的新形式的\emph{自由探索}，从根本上与臂的先验分布相关的一个尾事件有关。

    arXiv:2002.10121v4 Announce Type: replace  Abstract: We investigate a Bayesian $k$-armed bandit problem in the \emph{many-armed} regime, where $k \geq \sqrt{T}$ and $T$ represents the time horizon. Initially, and aligned with recent literature on many-armed bandit problems, we observe that subsampling plays a key role in designing optimal algorithms; the conventional UCB algorithm is sub-optimal, whereas a subsampled UCB (SS-UCB), which selects $\Theta(\sqrt{T})$ arms for execution under the UCB framework, achieves rate-optimality. However, despite SS-UCB's theoretical promise of optimal regret, it empirically underperforms compared to a greedy algorithm that consistently chooses the empirically best arm. This observation extends to contextual settings through simulations with real-world data. Our findings suggest a new form of \emph{free exploration} beneficial to greedy algorithms in the many-armed context, fundamentally linked to a tail event concerning the prior distribution of arm
    
[^39]: DDMI: 面向领域无关的隐式神经表示的高质量合成的潜在扩散模型

    DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations. (arXiv:2401.12517v1 [cs.LG])

    [http://arxiv.org/abs/2401.12517](http://arxiv.org/abs/2401.12517)

    DDMI是一种面向领域无关的隐式神经表示的高质量合成的潜在扩散模型，通过生成自适应位置嵌入而不是网络权重，解决了现有方法中生成质量较低的问题。

    

    最近的研究引入了一类用于合成各个领域中任意连续信号的隐式神经表示生成模型，为领域无关的生成模型打开了大门，但往往无法实现高质量的生成。我们观察到现有方法通过生成神经网络的权重来参数化隐式神经表示，并使用固定的位置嵌入来评估网络。可以说，这种架构限制了生成模型的表达能力，导致隐式神经表示生成的质量较低。为了解决这个限制，我们提出了一种面向领域无关的隐式神经表示的潜在扩散模型 (DDMI)，其生成自适应位置嵌入而不是网络权重。具体而言，我们开发了一个离散到连续空间的变分自编码器 (D2C-VAE)，它在共享的潜在空间中无缝连接离散数据和连续信号函数。此外，我们引入了一种新颖的...

    Recent studies have introduced a new class of generative models for synthesizing implicit neural representations (INRs) that capture arbitrary continuous signals in various domains. These models opened the door for domain-agnostic generative models, but they often fail to achieve high-quality generation. We observed that the existing methods generate the weights of neural networks to parameterize INRs and evaluate the network with fixed positional embeddings (PEs). Arguably, this architecture limits the expressive power of generative models and results in low-quality INR generation. To address this limitation, we propose Domain-agnostic Latent Diffusion Model for INRs (DDMI) that generates adaptive positional embeddings instead of neural networks' weights. Specifically, we develop a Discrete-to-continuous space Variational AutoEncoder (D2C-VAE), which seamlessly connects discrete data and the continuous signal functions in the shared latent space. Additionally, we introduce a novel con
    
[^40]: 迭代正则化与k支撑范数：稀疏恢复的重要补充

    Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])

    [http://arxiv.org/abs/2401.05394](http://arxiv.org/abs/2401.05394)

    该论文介绍了一种新的迭代正则化算法IRKSN，它通过使用$k$支撑范数正则化实现稀疏恢复，并提供了条件。这是对基于$\ell_1$范数的迭代方法的一种重要补充。

    

    稀疏恢复在机器学习和信号处理中无处不在。由于稀疏恢复的NP困难性质，现有方法通常要么受限于适用条件（甚至未知），要么计算成本高。最近，迭代正则化方法作为一种快速方法出现，因为它们可以通过提前停止一次通过来实现稀疏恢复，而不是传统方法中繁琐的网格搜索。然而，大多数这些迭代方法都基于$\ell_1$范数，需要受限的适用条件，并且在许多情况下可能会失败。因此，迭代正则化方法在更广泛的条件下实现稀疏恢复仍需进一步探索。为了解决这个问题，我们提出了一种新的迭代正则化算法IRKSN，它基于$k$支撑范数正则化而不是$\ell_1$范数。我们提供了使用IRKSN进行稀疏恢复的条件，并进行了比较。

    Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar
    
[^41]: 提取脑动力学的多尺度因果骨架

    Extracting the Multiscale Causal Backbone of Brain Dynamics. (arXiv:2311.00118v1 [cs.LG])

    [http://arxiv.org/abs/2311.00118](http://arxiv.org/abs/2311.00118)

    该研究提出了一种用于提取脑动力学多尺度因果骨架的方法，并通过对合成数据和静息态fMRI数据的实验证明其优越性。研究结果显示，因果动力在不同频率下受不同脑区驱动，这为理解脑功能提供了新的视角。

    

    大部分关于脑连接性的研究集中在脑区之间的统计关联上，这与统治脑动力学的因果机制不直接相关。在这里，我们提出了多尺度因果骨架（MCB），它是在多个时间尺度上共享的一组个体的脑动力学特征，并设计了一种有原则的方法来提取它。我们的方法利用了多尺度因果结构学习的最新进展，并优化了模型拟合与复杂性之间的权衡。对合成数据的实证评估显示，我们的方法优于基于规范功能连接网络的基线。当应用于静息态fMRI数据时，我们发现左右脑半球都有稀疏的MCB。由于其多尺度的特性，我们的方法表明在低频带上，因果动力来自与高级认知功能相关的脑区；而在更高的频率上，由nod产生。

    The bulk of the research effort on brain connectivity revolves around statistical associations among brain regions, which do not directly relate to the causal mechanisms governing brain dynamics. Here we propose the multiscale causal backbone (MCB) of brain dynamics shared by a set of individuals across multiple temporal scales, and devise a principled methodology to extract it.  Our approach leverages recent advances in multiscale causal structure learning and optimizes the trade-off between the model fitting and its complexity. Empirical assessment on synthetic data shows the superiority of our methodology over a baseline based on canonical functional connectivity networks. When applied to resting-state fMRI data, we find sparse MCBs for both the left and right brain hemispheres. Thanks to its multiscale nature, our approach shows that at low-frequency bands, causal dynamics are driven by brain regions associated with high-level cognitive functions; at higher frequencies instead, nod
    
[^42]: 使用神经场在相互作用动态系统中发现潜在场效应

    Latent Field Discovery In Interacting Dynamical Systems With Neural Fields. (arXiv:2310.20679v1 [cs.LG])

    [http://arxiv.org/abs/2310.20679](http://arxiv.org/abs/2310.20679)

    本文通过笛卡尔积和神经场提出了一种新的图网络，用于在相互作用动态系统中发现局部物体相互作用和全局场效应的潜在力场。

    

    相互作用对象的系统在其动力学中通常会受到场效应的影响，然而以往的研究常常忽略了这些效应，假设系统在真空中演化。本文着眼于发现这些场效应，并仅通过观察到的动力学来进行推断，而无需直接观测它们。我们假设存在潜在的力场，并提出使用神经场来学习它们。由于观察到的动力学是局部物体相互作用和整体场效应的综合结果，最近流行的等变网络无法应用，因为它们无法捕捉到全局信息。为了解决这个问题，我们提出将局部物体相互作用（SE(n)等变的，依赖于相对状态）与外部全局场效应（依赖于绝对状态）相分离。我们使用等变图网络对相互作用进行建模，并将其与神经场结合在一起，构建了一种融合了场效应的图网络。

    Systems of interacting objects often evolve under the influence of field effects that govern their dynamics, yet previous works have abstracted away from such effects, and assume that systems evolve in a vacuum. In this work, we focus on discovering these fields, and infer them from the observed dynamics alone, without directly observing them. We theorize the presence of latent force fields, and propose neural fields to learn them. Since the observed dynamics constitute the net effect of local object interactions and global field effects, recently popularized equivariant networks are inapplicable, as they fail to capture global information. To address this, we propose to disentangle local object interactions -- which are $\mathrm{SE}(n)$ equivariant and depend on relative states -- from external global field effects -- which depend on absolute states. We model interactions with equivariant graph networks, and combine them with neural fields in a novel graph network that integrates fiel
    
[^43]: MCRAGE: 公平性的合成医疗数据

    MCRAGE: Synthetic Healthcare Data for Fairness. (arXiv:2310.18430v1 [stat.ML])

    [http://arxiv.org/abs/2310.18430](http://arxiv.org/abs/2310.18430)

    MCRAGE是一种使用深度生成模型来增强不平衡的医疗数据集的方法，以解决少数群体在机器学习模型中的不公平问题。

    

    在医疗领域，电子健康记录（EHR）是开发诊断、治疗和管理医疗资源的机器学习模型的关键训练数据。然而，医疗数据集在种族/民族、性别和年龄等敏感属性方面往往存在不平衡。在类不平衡的EHR数据集上训练的机器学习模型在部署时，对于少数群体的个体而言，表现显著不如多数群体的样本，这可能导致少数群体的不公平医疗结果。为了解决这个挑战，我们提出了一种名为Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE)的新方法，通过由深度生成模型生成的样本来增强不平衡的数据集。MCRAGE过程包括训练一个能够从少数群体中产生高质量合成EHR样本的条件去噪扩散概率模型（CDDPM）。

    In the field of healthcare, electronic health records (EHR) serve as crucial training data for developing machine learning models for diagnosis, treatment, and the management of healthcare resources. However, medical datasets are often imbalanced in terms of sensitive attributes such as race/ethnicity, gender, and age. Machine learning models trained on class-imbalanced EHR datasets perform significantly worse in deployment for individuals of the minority classes compared to samples from majority classes, which may lead to inequitable healthcare outcomes for minority groups. To address this challenge, we propose Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE), a novel approach to augment imbalanced datasets using samples generated by a deep generative model. The MCRAGE process involves training a Conditional Denoising Diffusion Probabilistic Model (CDDPM) capable of generating high-quality synthetic EHR samples from underrepresented classes. We use this 
    
[^44]: 渐进免费素描稀疏岭集合：风险，交叉验证和调整

    Asymptotically free sketched ridge ensembles: Risks, cross-validation, and tuning. (arXiv:2310.04357v1 [math.ST])

    [http://arxiv.org/abs/2310.04357](http://arxiv.org/abs/2310.04357)

    该论文利用随机矩阵理论建立了一致性估计方法，用于估计素描岭回归集合的预测风险，从而实现了正则化和素描参数的高效一致调整。

    

    我们利用随机矩阵理论，建立了推广交叉验证（GCV）用于估计素描岭回归集合的预测风险的一致性，从而实现了正则化和素描参数的高效一致调整。我们的结果适用于一类广泛的渐进免费素描，对数据假设非常温和。对于平方预测风险，我们提供了一个分解成等效非素描隐含岭偏差和基于素描的方差的方法，并证明风险可以通过仅调整无限集合中的素描大小来全局优化。对于一般的亚二次预测风险函数，我们扩展了GCV来构建一致的风险估计，从而在Wasserstein-2度量下获得了GCV修正的预测的分布收敛性。这特别允许在训练数据条件下构建具有渐进正确覆盖率的预测区间。我们还提出了一种“集合技巧”，通过这种技巧可以推断未经过描绘的风险。

    We employ random matrix theory to establish consistency of generalized cross validation (GCV) for estimating prediction risks of sketched ridge regression ensembles, enabling efficient and consistent tuning of regularization and sketching parameters. Our results hold for a broad class of asymptotically free sketches under very mild data assumptions. For squared prediction risk, we provide a decomposition into an unsketched equivalent implicit ridge bias and a sketching-based variance, and prove that the risk can be globally optimized by only tuning sketch size in infinite ensembles. For general subquadratic prediction risk functionals, we extend GCV to construct consistent risk estimators, and thereby obtain distributional convergence of the GCV-corrected predictions in Wasserstein-2 metric. This in particular allows construction of prediction intervals with asymptotically correct coverage conditional on the training data. We also propose an "ensemble trick" whereby the risk for unsket
    
[^45]: 使用Forman-Ricci曲率的扩展来减轻过度平滑和过度压缩问题

    Mitigating Over-Smoothing and Over-Squashing using Augmentations of Forman-Ricci Curvature. (arXiv:2309.09384v1 [cs.LG])

    [http://arxiv.org/abs/2309.09384](http://arxiv.org/abs/2309.09384)

    本文提出了一种使用Forman-Ricci曲率扩展的方法来减轻图神经网络中的过度平滑和过度压缩问题。通过观察离散曲率，可以添加或删除边以减轻这两种效应。

    

    虽然图神经网络（GNNs）在不同领域的图结构数据学习中取得了成功，但最近描述了几个潜在的陷阱。这些包括无法准确利用编码在长距离连接中的信息（过度压缩），以及在网络深度增加时难以区分附近节点的学习表示（过度平滑）。一种有效的表征这两种效应的方法是离散曲率：导致过度压缩效应的长距离连接具有低曲率，而导致过度平滑的边具有高曲率。这个观察引发了一些重连技术，通过增加或删除边来减轻过度平滑和过度压缩问题。已经提出了几种利用图特征（如曲率或图拉普拉斯算子的谱）的重连方法。然而，现有方法，特别是基于曲率的方法，通常需要昂贵的子图操作。

    While Graph Neural Networks (GNNs) have been successfully leveraged for learning on graph-structured data across domains, several potential pitfalls have been described recently. Those include the inability to accurately leverage information encoded in long-range connections (over-squashing), as well as difficulties distinguishing the learned representations of nearby nodes with growing network depth (over-smoothing). An effective way to characterize both effects is discrete curvature: Long-range connections that underlie over-squashing effects have low curvature, whereas edges that contribute to over-smoothing have high curvature. This observation has given rise to rewiring techniques, which add or remove edges to mitigate over-smoothing and over-squashing. Several rewiring approaches utilizing graph characteristics, such as curvature or the spectrum of the graph Laplacian, have been proposed. However, existing methods, especially those based on curvature, often require expensive subr
    
[^46]: 随机森林中的预测误差估计

    Prediction Error Estimation in Random Forests. (arXiv:2309.00736v1 [stat.ML])

    [http://arxiv.org/abs/2309.00736](http://arxiv.org/abs/2309.00736)

    本文通过量化评估分类随机森林的误差估计方法，发现随机森林的预测误差估计比平均预测误差更接近真实误差率，并且这一结果适用于不同的误差估计策略。

    

    本文定量评估了分类随机森林的误差估计。在Bates等人（2023年）建立的初步理论框架的基础上，从理论和经验角度探讨了随机森林中常见的各种误差估计方法在真实误差率和期望误差率方面的情况。我们发现，在分类情况下，随机森林的预测误差估计平均更接近真实误差率，而不是平均预测误差。与Bates等人（2023年）对逻辑回归的研究结果相反。我们进一步证明，这个结果适用于交叉验证、自举和数据划分等不同的误差估计策略。

    In this paper, error estimates of classification Random Forests are quantitatively assessed. Based on the initial theoretical framework built by Bates et al. (2023), the true error rate and expected error rate are theoretically and empirically investigated in the context of a variety of error estimation methods common to Random Forests. We show that in the classification case, Random Forests' estimates of prediction error is closer on average to the true error rate instead of the average prediction error. This is opposite the findings of Bates et al. (2023) which were given for logistic regression. We further show that this result holds across different error estimation strategies such as cross-validation, bagging, and data splitting.
    
[^47]: Prodigy: 一种快速自适应零参数学习算法

    Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])

    [http://arxiv.org/abs/2306.06101](http://arxiv.org/abs/2306.06101)

    本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。

    

    本文研究自适应算法(如Adagrad和Adam)中的学习率估计问题，描述了两种技术Prodigy和Resetting，可以证明地估计到达解决方案所需的距离D，以便最优设置学习率。我们的技术是基于学习率自由的D-Adaptation方法的修改，并通过$O(\sqrt{\log(D/d_0)})$的因子提高了D-Adaptation的收敛速度，其中$d_0$是$D$的初始估计值。我们在12个常见的逻辑回归基准数据集、在CIFAR10上训练的VGG11和ResNet-50、在Imagenet上训练的ViT、在IWSLT14上训练的LSTM、在Criteo数据集上训练的DLRM、在Knee MRI数据集上的VarNet，以及在BookWiki上训练的RoBERTa和GPT transformer上测试了我们的方法。我们的实验结果表明，我们的方法始终优于D-Adaptation，并达到手动调整Adam的测试准确度值。

    We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
    

