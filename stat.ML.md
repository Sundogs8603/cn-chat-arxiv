# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Individual Treatment Effects in Extreme Regimes.](http://arxiv.org/abs/2306.11697) | 本文提出了一种新的框架，通过测量潜在结果在存在或缺乏治疗的情况下的尾部衰减率变化，来估计极端环境下的个体治疗效果（ITE$_2$）。 |
| [^2] | [Statistical Tests for Replacing Human Decision Makers with Algorithms.](http://arxiv.org/abs/2306.11689) | 本文提出了一种利用人工智能改善人类决策的统计框架，通过基准测试与机器预测，替换部分人类决策者的决策制定，并经过实验检验得出算法具有更高的真阳性率和更低的假阳性率，尤其是来自农村地区的医生的诊断更容易被替代。 |
| [^3] | [The Implicit Bias of Batch Normalization in Linear Models and Two-layer Linear Convolutional Neural Networks.](http://arxiv.org/abs/2306.11680) | 本文研究了使用批规范化训练线性模型和两层线性卷积神经网络时的隐式偏差，并证明批规范化对于均匀间隔具有隐含偏差。通过两个例子，我们发现在特定学习问题中，均匀间隔分类器的表现甚至优于最大间隔分类器。 |
| [^4] | [Principles for Initialization and Architecture Selection in Graph Neural Networks with ReLU Activations.](http://arxiv.org/abs/2306.11668) | 本文提出了三个原则来指导ReLU激活下图神经网络初始化和架构选择，其中关键在于使用残差聚合算子可以减轻过度平滑，使用修复型初始化的残差连接可以避免最终层特征的相关崩溃。 |
| [^5] | [Mean-field Analysis of Generalization Errors.](http://arxiv.org/abs/2306.11623) | 该论文提出了一个通过概率测度空间上的微分演算探讨算法稳健性的新框架，并得出了广义误差的收敛速率为$\mathcal{O}(1/n)$的一般条件。 |
| [^6] | [Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent.](http://arxiv.org/abs/2306.11589) | 本文探索了使用随机梯度下降算法从高斯过程后验中采样的方法，该方法计算高效且能在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。 |
| [^7] | [Conditional Independence Testing with Heteroskedastic Data and Applications to Causal Discovery.](http://arxiv.org/abs/2306.11498) | 本文提出了一种适用于异方差数据的CI测试方法，能够在专家知识的帮助下高效进行因果发现，且实验结果表明其效果优于标准测试方法。 |
| [^8] | [Convergence and concentration properties of constant step-size SGD through Markov chains.](http://arxiv.org/abs/2306.11497) | 本文通过马尔科夫链研究了常步长随机梯度下降的性质，证明了迭代收敛于一个不变分布，并获得了高置信度边界。 |
| [^9] | [Efficient Large-scale Nonstationary Spatial Covariance Function Estimation Using Convolutional Neural Networks.](http://arxiv.org/abs/2306.11487) | 本研究利用卷积神经网络从非平稳的空间数据中派生子区域，并采用选择机制识别表现出与稳态场相似行为的子区域。 |
| [^10] | [Learning Locally Interpretable Rule Ensemble.](http://arxiv.org/abs/2306.11481) | 本文提出了一种学习可解释规则集合的框架，引入了本地可解释性概念来避免准确性和可解释性之间权衡，通过正则化器和坐标下降算法的结合进行学习。 |
| [^11] | [Spatio-temporal DeepKriging for Interpolation and Probabilistic Forecasting.](http://arxiv.org/abs/2306.11472) | 本文提出了一种基于深度学习的时空插值和概率预测方法，在预测中克服了传统技术的局限性，并在插值和概率预测方面实现了高精度的表现。 |
| [^12] | [Provably Robust Temporal Difference Learning for Heavy-Tailed Rewards.](http://arxiv.org/abs/2306.11455) | 证明了一种带有动态梯度剪裁机制的时间差分（TD）学习可以在重尾奖励分布下被证明具有鲁棒性。 |
| [^13] | [Computing large deviation prefactors of stochastic dynamical systems based on machine learning.](http://arxiv.org/abs/2306.11418) | 本文利用机器学习的研究成果计算大偏差前置因子的接近次导数的逼近值，并证明了算法在计算平均退出时间以及探索被弱随机波动触发的罕见事件的内在机制方面具有高效性和准确性。 |
| [^14] | [A Bayesian Take on Gaussian Process Networks.](http://arxiv.org/abs/2306.11380) | 该论文提出了一种基于高斯过程和贝叶斯方法的网络模型，通过蒙特卡罗和马尔可夫链蒙特卡罗方法采样网络结构的后验分布。该方法在恢复网络的图形结构方面优于最先进的算法，并提供了后验概率的准确近似。 |
| [^15] | [Deep graph kernel point processes.](http://arxiv.org/abs/2306.11313) | 本文提出了一种基于潜在图拓扑的图点过程方法，并开发了一种新颖的深度图核来描述事件之间的触发和抑制效应，该方法在合成和实际数据集上具有优越性。 |
| [^16] | [Data Structures for Density Estimation.](http://arxiv.org/abs/2306.11312) | 该论文提出了一个可以在较小的样本数量和时间内识别出“接近”的分布的数据结构，同时还改进了一个线性时间算法，能够更有效地实现给定准确性所需操作数的减少。 |
| [^17] | [The Unintended Consequences of Discount Regularization: Improving Regularization in Certainty Equivalence Reinforcement Learning.](http://arxiv.org/abs/2306.11208) | 折扣正则化不仅可以通过忽略延迟效应来缩小规划空间，还可以看作是具有先验分布的正则化，而低折扣因子的使用会导致状态-动作对之间数据量不均的性能下降。 |
| [^18] | [Insufficiently Justified Disparate Impact: A New Criterion for Subgroup Fairness.](http://arxiv.org/abs/2306.11181) | 本文提出了一个新标准“不充分的理由落差”（IJDI），用于评估算法决策支持工具所做出的建议是否公平，并描述了IJDI-Scan方法来发现重要的IJDI。在模拟和现实世界的数据上进行实验，包括再犯风险评估和信用评分，并实现了减轻IJDI的方法。 |
| [^19] | [Human Limits in Machine Learning: Prediction of Plant Phenotypes Using Soil Microbiome Data.](http://arxiv.org/abs/2306.11157) | 本论文深入研究了机器学习模型在预测土壤与植物表型之间联系方面的潜力，证明加入土壤物理化学性质和微生物种群密度等环境特征可以提高预测准确性。 |
| [^20] | [Nonlinear Feature Aggregation: Two Algorithms driven by Theory.](http://arxiv.org/abs/2306.11143) | 本文提出了两种聚合非线性特征的新算法：通过信息瓶颈进行非线性特征聚合（NFA-IB）和通过核嵌入进行非线性特征聚合（NFA-KE）。这些方法可以有效地解决处理非线性数据时基于相关性的方法可能导致子优表示的问题。 |
| [^21] | [Correcting Underrepresentation and Intersectional Bias for Fair Classification.](http://arxiv.org/abs/2306.11112) | 本文提出一种可以有效纠正数据偏差和交叉偏差的学习方法，并构造了一个重新加权方案，可以精确评估任何假设在真实分布上的损失。 |
| [^22] | [Beyond Normal: On the Evaluation of Mutual Information Estimators.](http://arxiv.org/abs/2306.11078) | 本文提出了一种语言无关的互信息估计基准平台，并讨论了经典和神经估计器在处理高维数据、长尾分布和高互信息时的普适性和局限性。 |
| [^23] | [Simple and Fast Group Robustness by Automatic Feature Reweighting.](http://arxiv.org/abs/2306.11074) | 本文提出了一个自动特征重新加权（AFR）的简单快速方法，使用加权损失重新训练ERC模型的最后一层来减少对虚假特征的依赖，从而提高了多个群体的鲁棒性表现。 |
| [^24] | [Application of Deep Learning for Predictive Maintenance of Oilfield Equipment.](http://arxiv.org/abs/2306.11040) | 本论文探讨了神经网络技术在预测性维护中的应用，通过深度学习和数据处理技术，可以诊断设备的健康状态和预测故障前的剩余寿命。这项技术还被应用于油田设备的预测性维护中。 |
| [^25] | [Adversarial Training Should Be Cast as a Non-Zero-Sum Game.](http://arxiv.org/abs/2306.11035) | 本论文提出了一种新的针对对抗性训练的非零和双层公式，实现了与最先进攻击相匹配并且能够达到与标准对抗性训练相同的鲁棒性水平。 |
| [^26] | [High-dimensional Contextual Bandit Problem without Sparsity.](http://arxiv.org/abs/2306.11017) | 本论文研究了高维情境赌博问题，无需施加稀疏性要求，并提出了一种探索-开发算法以解决此问题。研究表明，可以通过平衡探索和开发实现最优速率。同时，还介绍了一种自适应探索-开发算法来找到最优平衡点。 |
| [^27] | [Front-door Adjustment Beyond Markov Equivalence with Limited Graph Knowledge.](http://arxiv.org/abs/2306.11008) | 本论文提出了可以不需要完全了解图形结构的情况下，使用前门调整法计算因果效应的一种方法，通过提供测试性条件独立性陈述的方式实现，这种方法适用于不知道马尔可夫等价类的情况下。 |
| [^28] | [A VAE Approach to Sample Multivariate Extremes.](http://arxiv.org/abs/2306.10987) | 本论文提出了一种用于抽样多元重尾分布的VAE方法，该方法可以模拟真实世界的多元极值情况，如河流水位，从而有助于评估未来可能出现的风险。 |
| [^29] | [Effect-Invariant Mechanisms for Policy Generalization.](http://arxiv.org/abs/2306.10983) | 本文提出了一种松弛了完全不变性的方法，称为效果不变性，证明它足以进行零样本策略概括，并讨论了基于少量样本的扩展。 |
| [^30] | [Prediction model for rare events in longitudinal follow-up and resampling methods.](http://arxiv.org/abs/2306.10977) | 本文比较了几种重抽样方法以改进标准回归模型，并评估了抽样率对预测模型的影响。 |
| [^31] | [sEMG-based Hand Gesture Recognition with Deep Learning.](http://arxiv.org/abs/2306.10954) | 本文通过应用深度学习技术在Unibo-INAIL数据集上实现了基于sEMG信号的手势识别，探索了被试者之间、会话之间和手臂姿势之间的可变性，并提出了相应的解决方案。 |
| [^32] | [Understanding Generalization in the Interpolation Regime using the Rate Function.](http://arxiv.org/abs/2306.10947) | 本文利用大偏差理论，提出一种基于函数的平滑模型特征描述方法，解释了为什么一些插值器有很好的泛化能力以及现代学习技术为什么能够找到它们。 |
| [^33] | [Probabilistic matching of real and generated data statistics in generative adversarial networks.](http://arxiv.org/abs/2306.10943) | 本文提出一种通过向生成器损失函数中添加KL散度项的方法，来保证生成数据统计分布与真实数据的相应分布重合，并在实验中展示了此方法的优越性能。 |
| [^34] | [Practical Equivariances via Relational Conditional Neural Processes.](http://arxiv.org/abs/2306.10915) | 本文提出的关系条件神经过程（RCNPs）是一种有效将等变性纳入任何神经过程模型的方法，并扩展了等变神经过程的适用性和影响力到更高的维度。 |
| [^35] | [AdaStop: sequential testing for efficient and reliable comparisons of Deep RL Agents.](http://arxiv.org/abs/2306.10882) | AdaStop是一种基于多组序列测试的新统计测试方法，可用于比较多个深度强化学习算法来解决实验结果可复制性的问题。 |
| [^36] | [Interpreting Deep Neural Networks with the Package innsight.](http://arxiv.org/abs/2306.10822) | innsight是一个通用的R包，能够独立于深度学习库，解释来自任何R包的模型，并提供了丰富的可视化工具，以揭示深度神经网络预测的变量解释。 |
| [^37] | [$\texttt{causalAssembly}$: Generating Realistic Production Data for Benchmarking Causal Discovery.](http://arxiv.org/abs/2306.10816) | 该论文提出了一种生成基于装配线数据的半合成制造数据集的方法，以支持因果发现方法的基准测试。 |
| [^38] | [Practical First-Order Bayesian Optimization Algorithms.](http://arxiv.org/abs/2306.10815) | 本文提出了一种实用的FOBO算法，通过利用梯度GP的信息，有效地识别具有零梯度的潜在查询点，采用多级采集函数来潜在确定全局最大值。 |
| [^39] | [P-tensors: a General Formalism for Constructing Higher Order Message Passing Networks.](http://arxiv.org/abs/2306.10767) | P-tensors 提供了构建高阶消息传递网络的通用形式，其在分子等高度结构化的图形中具有优异的性能表现。 |
| [^40] | [BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming.](http://arxiv.org/abs/2306.10742) | 本文提出了一个高效算法框架BNN-DP，使用动态规划算法来保证贝叶斯神经网络的鲁棒性。在多个实验中，该算法框架的精度和时间效率均高于现有方法。 |
| [^41] | [Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics.](http://arxiv.org/abs/2306.10656) | 本论文提出了一种名为VHGM的深度生成模型，基于掩码建模的方法来学习健康属性、生活方式和人格之间的关系。通过使用异构表格数据集，VHGM有效地学习了超过1,800个属性。该模型具有潜在的应用前景，例如用于医疗属性的虚拟测量和生活方式的假设验证。 |
| [^42] | [Agnostically Learning Single-Index Models using Omnipredictors.](http://arxiv.org/abs/2306.10615) | 本文提出了使用全能预测器对单指数模型进行自主学习的方法，且仅需要边缘具有有界的二阶矩。该方法可适用于任意单调和利普希茨激活，并且过往方法中所需的更强分布假设不再需要。研究者们通过匹配损失与$\ell_p$距离的关系，提供了一种简单的分析方式，并在不可知设置中为标准算法提供了新的保证。 |
| [^43] | [Identifiable causal inference with noisy treatment and no side information.](http://arxiv.org/abs/2306.10614) | 本论文提出了一种在没有侧面信息和具有复杂非线性依赖性的情况下，纠正因治疗变量不准确测量引起的因果效应估计偏差的模型，并证明了该模型的因果效应估计是可识别的。该方法使用了深度潜在变量模型和分摊权重变分客观函数进行训练。 |
| [^44] | [Conditional expectation via compact kernels.](http://arxiv.org/abs/2306.10592) | 本文提出了一种基于紧核的算子理论方法来解决条件期望估计问题，在再生核希尔伯特空间中实现，易于实现，且成功应用于实际问题中。 |
| [^45] | [Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?.](http://arxiv.org/abs/2306.10590) | 本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。 |
| [^46] | [Optimism and Adaptivity in Policy Optimization.](http://arxiv.org/abs/2306.10587) | 本文通过将看似无关的策略优化算法重新构造为共同的两个交错步骤，即乐观策略改进和后见适应，统一了强化学习中的策略优化方法，揭示了加速方法中的乐观性和适应性的共同理论属性。 |
| [^47] | [OpenDataVal: a Unified Benchmark for Data Valuation.](http://arxiv.org/abs/2306.10577) | 本文介绍了一种名为OpenDataVal的基准测试框架，该框架整合了多种数据集和九种最先进的数据估值算法实现，并提供了四个下游机器学习任务来评估数据价值的质量。 |
| [^48] | [Score-based Data Assimilation.](http://arxiv.org/abs/2306.10574) | 本文介绍了基于评分的数据同化方法，通过对状态轨迹模型的训练，实现了无需依赖传统推断方法和满足高维系统与长时间跨度下进行推断。 |
| [^49] | [Can predictive models be used for causal inference?.](http://arxiv.org/abs/2306.10551) | 尽管传统的机器学习和深度学习算法常常利用非因果相关性，但是通过适当的特征选择和超参数调整，预测模型仍然可以有效地用于因果推断。 |
| [^50] | [Dropout Regularization Versus $\ell_2$-Penalization in the Linear Model.](http://arxiv.org/abs/2306.10529) | 研究发现，线性回归模型中采用dropout技术的统计行为具有更加微妙的与$\ell_2$正则化的联系，dropout并不像预期中那样具有稳定的正则化效果。 |
| [^51] | [Variational Sequential Optimal Experimental Design using Reinforcement Learning.](http://arxiv.org/abs/2306.10430) | 该研究提出了一种基于贝叶斯框架和信息增益效用的变分序列最优实验设计方法，通过强化学习求解最优设计策略，适用于多种OED问题，结果具有更高的样本效率和更少的前向模型模拟次数。 |
| [^52] | [Distributed Semi-Supervised Sparse Statistical Inference.](http://arxiv.org/abs/2306.10395) | 本文提出了一种分布式半监督稀疏统计推断的高效算法，融合了有/无标签数据，为M估计和广义线性模型提供了定制去偏方法，并在模拟和真实数据应用中展示了结合无标签数据的效果。 |
| [^53] | [Non-asymptotic System Identification for Linear Systems with Nonlinear Policies.](http://arxiv.org/abs/2306.10369) | 本文提供了一个非渐近误差界，适用于独立同分布随机激励噪声下的任何非线性和/或时变策略下生成的轨迹。这适用于安全学习控制中的受限制线性系统，与线性策略相一致。 |
| [^54] | [Deep Huber quantile regression networks.](http://arxiv.org/abs/2306.10306) | DHQRN可以预测更一般的Huber分位数，并且在预测分布的尾部提供更好的预测。 |
| [^55] | [Adaptive Strategies in Non-convex Optimization.](http://arxiv.org/abs/2306.10278) | 本文介绍了应用于随机优化和深度神经网络训练中的自适应算法。算法可以自动适应不同的噪声水平和梯度比例范围，从而达到（近似）最优速度。 |
| [^56] | [Active Policy Improvement from Multiple Black-box Oracles.](http://arxiv.org/abs/2306.10259) | 本研究提出了MAPS和MAPS-SE两个算法，可在多黑盒预言情况下，采用模仿学习并主动选择和改进最优预言，显著提升了性能。 |
| [^57] | [Learning High-Dimensional Nonparametric Differential Equations via Multivariate Occupation Kernel Functions.](http://arxiv.org/abs/2306.10189) | 本论文提出了一种线性方法，通过多元占位核函数在高维状态空间中学习非参数ODE系统，可以解决显式公式按二次方缩放的问题。这种方法在高度非线性的数据和图像数据中都具有通用性。 |
| [^58] | [Samplet basis pursuit.](http://arxiv.org/abs/2306.10180) | 本文提出了基于Samplet坐标下核学习的方法，其中引入l1正则化项可以增加系数的稀疏性。相比于单尺度基，Samplet基可以更好地表示更多类型的信号。作者提出了使用软阈值和半光滑牛顿法解决该问题的方法，并通过实验证明了其优越性。 |
| [^59] | [Bootstrapped Representations in Reinforcement Learning.](http://arxiv.org/abs/2306.10171) | 本研究对强化学习中引导式表示进行了理论分析，发现与蒙特卡罗和残差梯度算法学习的特征大多不同 |
| [^60] | [Fairness in Multi-Task Learning via Wasserstein Barycenters.](http://arxiv.org/abs/2306.10155) | 本文提出了一种方法，通过多元Wasserstein barycenters扩展`Strong Demographic Parity`的定义，实现多任务学习中的公平性，包括回归和二元分类任务。在实验中表现出良好的效果。 |
| [^61] | [Memory-Constrained Algorithms for Convex Optimization via Recursive Cutting-Planes.](http://arxiv.org/abs/2306.10096) | 递归割平面算法族可在具有受限内存的情况下进行凸优化，并使用子多项式范围内预言机复杂度/内存的权衡。 |
| [^62] | [Joint Path planning and Power Allocation of a Cellular-Connected UAV using Apprenticeship Learning via Deep Inverse Reinforcement Learning.](http://arxiv.org/abs/2306.10071) | 本论文通过学徒学习方法，采用基于Q学习和深度强化学习（DRL）的逆强化学习 (IRL)，解决了一个稀疏郊区环境中，无人机的联网路径规划与功率分配的干扰感知问题，优于传统的行为克隆（BC）调节学习技术。 |
| [^63] | [Evaluating Superhuman Models with Consistency Checks.](http://arxiv.org/abs/2306.09983) | 本文提出了一个用一致性检查评估超人模型的框架，可以发现决策制定中的逻辑不一致性，即使对于超人模型的决策正确性可能是不可能评估的情况。 |
| [^64] | [Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains.](http://arxiv.org/abs/2306.09332) | 本文提出了一种从快速混合马尔可夫链中实现样本高效的广义得分匹配方法，解决了得分匹配算法在具有较差等周性质的分布上的统计代价问题。 |
| [^65] | [Local-to-global Perspectives on Graph Neural Networks.](http://arxiv.org/abs/2306.06547) | 本文提出了局部到全局的图神经网络模型，包括不变图网络、局部信息传递神经网络和全局图变换器，并研究其收敛性质和在图粗化中的应用。 |
| [^66] | [Comparative Study on Semi-supervised Learning Applied for Anomaly Detection in Hydraulic Condition Monitoring System.](http://arxiv.org/abs/2306.02709) | 本研究比较了不同类型的半监督学习方法在液压状态监测系统中用于异常检测。深度学习模型表现最好，而集成模型可以进一步提高检测性能。 |
| [^67] | [Doubly Robust Self-Training.](http://arxiv.org/abs/2306.00265) | 本文提出了一种双重稳健自我训练算法，可以在伪标签不准确和完全准确时分别采取不同的训练策略，实现有效的半监督学习。实验结果表明，该算法在ImageNet和nuScenes数据集上均比标准自我训练总结更好。 |
| [^68] | [Error-Tolerant Exact Query Learning of Finite Set Partitions with Same-Cluster Oracle.](http://arxiv.org/abs/2305.13402) | 本文提出了一个新问题：如何通过同簇预言机在存在有限对抗错误时积极学习完全恢复划分。我们建立了解析框架并证明了最坏情况下查询复杂度的上下界，并研究了适应性和查询复杂度之间的关系。 |
| [^69] | [On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation.](http://arxiv.org/abs/2305.11283) | 本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。 |
| [^70] | [Kernel-based Joint Independence Tests for Multivariate Stationary and Nonstationary Time-Series.](http://arxiv.org/abs/2305.08529) | 本文提出了一种基于核的多元时间序列联合独立性统计检验方法，可以用于平稳和非平稳随机过程，通过针对单个和多个实现时间序列的重采样技术，可以稳健地发现重要的高阶依赖关系。 |
| [^71] | [Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos.](http://arxiv.org/abs/2305.08074) | 本文在简单的混沌映射上证明了扩展动态模态分解（EDMD）对于多项式可观测字典有指数效率，从而有效处理了混沌动力学中的正则函数问题，并展示了在这种情况下使用EDMD产生的预测和Koopman谱数据收敛至物理上有意义的极限。 |
| [^72] | [Streaming PCA for Markovian Data.](http://arxiv.org/abs/2305.02456) | 本文提出了一种面向马尔可夫数据采样的流式PCA算法，并获得了该算法在整个数据集上的第一个尖锐率，提高了算法的效率。同时，本文提出的自适应方案在模拟和真实数据示例中表现良好。 |
| [^73] | [Cross-Entropy Loss Functions: Theoretical Analysis and Applications.](http://arxiv.org/abs/2304.07288) | 本文对交叉熵、广义交叉熵、均方误差等一大类损失函数进行了理论分析，并提出了具有优势的双交叉熵损失函数，特别适用于存在标签噪声或类别不平衡的情况。 |
| [^74] | [Inhomogeneous graph trend filtering via a l2,0 cardinality penalty.](http://arxiv.org/abs/2304.05223) | 本文提出了一种基于L2，0基数惩罚的图趋势过滤（GTF）模型，可同时进行k-means聚类和基于图的最小割，以估计在节点之间具有不均匀平滑水平的分段平滑图信号，并在降噪、支持恢复和半监督分类任务上表现更好，比现有方法更高效地处理大型数据集。 |
| [^75] | [Graph Kalman Filters.](http://arxiv.org/abs/2303.12021) | 本文首次将卡尔曼和扩展卡尔曼滤波器推广到图形上，使得它可以适用于输出是向量或标量的情况，并且可以学习未知的状态转移和读取函数。 |
| [^76] | [Variational Gaussian filtering via Wasserstein gradient flows.](http://arxiv.org/abs/2303.06398) | 本论文提出了一种新方法通过Wasserstein梯度流进行变分高斯滤波，竞争力突出。 |
| [^77] | [Gaussian processes at the Helm(holtz): A more fluid model for ocean currents.](http://arxiv.org/abs/2302.10364) | 该论文提出了一种更符合已知电流物理特性的模型，在通过Helmholtz分解获得的向量场的发散和无旋分量上使用高斯过程来预测海流。证明了这种方法在模拟数据和真实浮标数据方面都比之前的方法更有效。 |
| [^78] | [JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models.](http://arxiv.org/abs/2302.09125) | 本文提出了 JANA 方法，用于处理复杂贝叶斯模型的近似计算。通过端到端训练三个神经网络来实现分摊的近似后验和似然，为贝叶斯工作流程提供了一种新的途径。此方法在多种模拟模型中进行了基准测试，并提出了一种联合校准诊断方法。 |
| [^79] | [Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion.](http://arxiv.org/abs/2302.04451) | 本文提出了用特征扩散矩阵的最大奇异值来缩放泛化界限的方法，并用Hessians来衡量图神经网络对噪声扰动的稳定性。实验证明，这些方法可以有效减小泛化界限，更好地解决了实际图形问题。 |
| [^80] | [Toward Large Kernel Models.](http://arxiv.org/abs/2302.02605) | 本文提出了一种构建大规模通用核模型的方法，这解决了传统核机器中模型大小与数据大小相互耦合的问题，使其能够在大数据集上进行训练。 |
| [^81] | [Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees.](http://arxiv.org/abs/2301.11911) | 提出了多维概念发现(MCD)方法，它满足概念层面上的完整性关系，不需要加强概念可解释性或重新训练模型部分，并提供概念激活图分析工具 |
| [^82] | [Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series.](http://arxiv.org/abs/2301.11308) | 本研究提出了一个用于不规则采样时间序列的神经连续离散状态空间模型，其采用辅助变量来区分识别和动态，从而实现了准确的贝叶斯推理和改进的性能。 |
| [^83] | [How Jellyfish Characterise Alternating Group Equivariant Neural Networks.](http://arxiv.org/abs/2301.10152) | 该论文提供了交替群($A_n$)等变神经网络的完整表征，其中描述了可学习的、线性的、$A_n$等变层函数的矩阵基，在神经网络构建中具有广泛的适用性。 |
| [^84] | [Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data.](http://arxiv.org/abs/2301.00437) | 研究者证明对于均方误差和交叉熵损失，深度线性网络中出现的全局解在不同数据上都具有神经塌陷的特性，即最后一层特征会崩溃为类均值，而这些类均值是等角紧框架的顶点。 |
| [^85] | [Brauer's Group Equivariant Neural Networks.](http://arxiv.org/abs/2212.08630) | 本文描述了对于三个在机器学习文献中缺失的对称群（$O(n)$、$SO(n)$和$Sp(n)$），所有可能的群等变神经网络的特征，并找到了这些网络在不同基础下矩阵的生成集。 |
| [^86] | [Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes.](http://arxiv.org/abs/2211.10420) | 该论文提出了一种在传输多面体上进行在线凸目标优化的算法，此算法基于Sinkhorn矩阵缩放和镜像下降的原理，并且可以在噪音环境下使用。 |
| [^87] | [Benefits of Monotonicity in Safe Exploration with Gaussian Processes.](http://arxiv.org/abs/2211.01561) | 本文提出了一种名为单调安全UCB(M-SafeUCB)的算法，通过单调性假设，取得了在保证精度的同时显著的优势。 |
| [^88] | [Lifelong Bandit Optimization: No Prior and No Regret.](http://arxiv.org/abs/2210.15513) | 本文提出了一种算法LIBO，可以无需直接访问数据，对一系列赌博优化任务进行学习和适应，并保证最优性能和亚线性终身后悔率。 |
| [^89] | [Decomposed Linear Dynamical Systems (dLDS) for learning the latent components of neural dynamics.](http://arxiv.org/abs/2206.02972) | 该论文提出了一种新的分解动力系统模型，将复杂非平稳和非线性动态表示为简单、可解释的稀疏组合，并通过字典学习过程进行训练。 |
| [^90] | [Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification.](http://arxiv.org/abs/2205.13094) | 该论文证明在非参数二元分类中，缺乏少数派样本是学习的根本限制，并探讨了欠采样算法的最小化极差风险的鲁棒性表现，特别是在标签转移的情况下可以最优化。 |
| [^91] | [Scale Dependencies and Self-Similar Models with Wavelet Scattering Spectra.](http://arxiv.org/abs/2204.10177) | 本论文提出了小波散射谱方法，可以用于建模具有平稳增量的时间序列的非高斯特性，其系数可以用于构建最大熵模型和生成新的时间序列，同时证明了自相似过程具有散射谱的尺度不变性。 |
| [^92] | [Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine.](http://arxiv.org/abs/2204.07124) | 该论文开发了两种新的方法，用于有效处理复杂的患者数据，基于数据驱动的异质性治疗效应估计，使用因果树方法（具体来说是因果树和因果森林），学习非线性关系，控制时间变化混淆，是双重稳健的和可解释的。在治疗抑郁症的真实世界数据应用程序中，该方法在准确性和实际可解释性方面表现出色。 |
| [^93] | [Prediction Sets Adaptive to Unknown Covariate Shift.](http://arxiv.org/abs/2203.06126) | 本文提出 PredSet-1Step 方法，可以在未知协变量漂移下高效构建具备渐近覆盖保障的预测集，具备很好的校准覆盖误差和高置信度。 |
| [^94] | [The Dual PC Algorithm and the Role of Gaussianity for Structure Learning of Bayesian Networks.](http://arxiv.org/abs/2112.09036) | 双重PC算法通过利用协方差和精度矩阵之间的反向关系，实现了CI测试，能够恢复正确的等价类，并可对互补调节集的偏相关进行测试。 |
| [^95] | [Quantifying Epistemic Uncertainty in Deep Learning.](http://arxiv.org/abs/2110.12122) | 本文提供了一个理论框架来分解深度学习中的不确定性，并提出了两种方法来估计这些不确定性，这些方法使我们能够克服在使用传统统计方法时遇到的困难，从而为建模和数据收集提供直接的指导。 |
| [^96] | [On the Convergence and Calibration of Deep Learning with Differential Privacy.](http://arxiv.org/abs/2106.07830) | 本文通过NTK对差分隐私训练进行连续时间分析，发现噪声只会影响隐私风险而不影响收敛性和校准性，而基于每个样本的梯度剪裁会影响收敛性和校准性。此外，大剪裁范数下的差分隐私模型不仅享有相同的隐私保证，而且校准效果好。 |
| [^97] | [Clustered Federated Learning via Generalized Total Variation Minimization.](http://arxiv.org/abs/2105.12769) | 本文介绍了一种基于广义全变差最小化的完全分散的联邦学习算法，可以训练适用于具有本地数据集的分散式去中心化环境的本地化（或个性化）模型，并获得了良好的模拟结果。 |
| [^98] | [Riemannian Langevin Algorithm for Solving Semidefinite Programs.](http://arxiv.org/abs/2010.11176) | 研究了一种基于Langevin扩散的算法，用于在球面的乘积流形上进行非凸优化和采样，展示了在适当的温度选择下，该算法可以保证次优解到全局最小值的间隙概率非常小，并在此基础上提出了求解半定向规划模型的新方法，并给出了全局最优性的保证。 |
| [^99] | [Cooperative Multi-Agent Reinforcement Learning with Partial Observations.](http://arxiv.org/abs/2006.10822) | 本文提出了一种基于局部状态和动作信息的分布式零阶策略优化方法，可用于部分观测的协作多智能体强化学习，减小通信开销并取得更好的效果。 |
| [^100] | [Equivariant online predictions of non-stationary time series.](http://arxiv.org/abs/1911.08662) | 本文讨论了模型错误下的非平稳时间序列在线预测问题，并且证明了随机游走动态线性模型可以产生精确的极小化预测密度。这个结果为其他模型提供了理论基线，并且在流行病学、气候学和经济学中得到了应用。 |

# 详细

[^1]: 极端环境下的个体治疗效果

    Individual Treatment Effects in Extreme Regimes. (arXiv:2306.11697v1 [stat.ME])

    [http://arxiv.org/abs/2306.11697](http://arxiv.org/abs/2306.11697)

    本文提出了一种新的框架，通过测量潜在结果在存在或缺乏治疗的情况下的尾部衰减率变化，来估计极端环境下的个体治疗效果（ITE$_2$）。

    

    了解极端环境下的个体治疗效果对于描述不同干预策略的风险至关重要。但极端环境数据很难收集，因为它在实践中很少被观察到。为了解决这个问题，我们提出了一个新的框架来估计极端环境下的个体治疗效果（ITE$_2$）。具体而言，我们通过测量潜在结果在存在或缺乏治疗的情况下的尾部衰减率变化来量化这种效果。随后，我们建立了 ITE$_2$ 的计算条件，并开发了计算算法。我们在各种合成和半合成数据集上演示了我们提出的方法的功效。

    Understanding individual treatment effects in extreme regimes is important for characterizing risks associated with different interventions. This is hindered by the fact that extreme regime data may be hard to collect, as it is scarcely observed in practice. In addressing this issue, we propose a new framework for estimating the individual treatment effect in extreme regimes (ITE$_2$). Specifically, we quantify this effect by the changes in the tail decay rates of potential outcomes in the presence or absence of the treatment. Subsequently, we establish conditions under which ITE$_2$ may be calculated and develop algorithms for its computation. We demonstrate the efficacy of our proposed method on various synthetic and semi-synthetic datasets.
    
[^2]: 统计测试替代人类决策者的算法

    Statistical Tests for Replacing Human Decision Makers with Algorithms. (arXiv:2306.11689v1 [econ.EM])

    [http://arxiv.org/abs/2306.11689](http://arxiv.org/abs/2306.11689)

    本文提出了一种利用人工智能改善人类决策的统计框架，通过基准测试与机器预测，替换部分人类决策者的决策制定，并经过实验检验得出算法具有更高的真阳性率和更低的假阳性率，尤其是来自农村地区的医生的诊断更容易被替代。

    

    本文提出了一个统计框架，可以通过人工智能来改善人类的决策。首先将每个人类决策者的表现与机器预测进行基准测试；然后用所提出的人工智能算法的建议替换决策制定者的一个子集所做出的决策。利用全国大型孕产结果和繁殖年龄夫妇孕前检查的医生诊断数据集，我们试验了一种启发式高频率方法以及一种贝叶斯后验损失函数方法，并将其应用于异常出生检测。我们发现，我们的算法在一个测试数据集上的结果比仅由医生诊断的结果具有更高的总体真阳性率和更低的假阳性率。我们还发现，来自农村地区的医生的诊断更容易被替代，这表明人工智能辅助决策制定更容易提高精确度。

    This paper proposes a statistical framework with which artificial intelligence can improve human decision making. The performance of each human decision maker is first benchmarked against machine predictions; we then replace the decisions made by a subset of the decision makers with the recommendation from the proposed artificial intelligence algorithm. Using a large nationwide dataset of pregnancy outcomes and doctor diagnoses from prepregnancy checkups of reproductive age couples, we experimented with both a heuristic frequentist approach and a Bayesian posterior loss function approach with an application to abnormal birth detection. We find that our algorithm on a test dataset results in a higher overall true positive rate and a lower false positive rate than the diagnoses made by doctors only. We also find that the diagnoses of doctors from rural areas are more frequently replaceable, suggesting that artificial intelligence assisted decision making tends to improve precision more i
    
[^3]: 批规范化在线性模型和两层线性卷积神经网络中的隐式偏差

    The Implicit Bias of Batch Normalization in Linear Models and Two-layer Linear Convolutional Neural Networks. (arXiv:2306.11680v1 [cs.LG])

    [http://arxiv.org/abs/2306.11680](http://arxiv.org/abs/2306.11680)

    本文研究了使用批规范化训练线性模型和两层线性卷积神经网络时的隐式偏差，并证明批规范化对于均匀间隔具有隐含偏差。通过两个例子，我们发现在特定学习问题中，均匀间隔分类器的表现甚至优于最大间隔分类器。

    

    本文研究了由梯度下降训练的批规范化的隐含偏差。我们证明，当使用批规范化训练二分类线性模型时，梯度下降会收敛到一个具有均匀间隔的分类器，收敛速度为$\exp（- \Omega（\log ^ 2 t））$。这将批规范化的线性模型与不使用批规范化的模型区分开来，其隐含偏差和收敛速度均不同。我们进一步将结果扩展到了一类两层单滤波器线性卷积神经网络中，并表明批规范化对于均匀间隔具有隐含偏差。通过两个例子，我们证明了特定学习问题中均匀间隔分类器的性能可以优于最大间隔分类器。我们的研究为更好地理解批规范化提供了理论基础。

    We study the implicit bias of batch normalization trained by gradient descent. We show that when learning a linear model with batch normalization for binary classification, gradient descent converges to a uniform margin classifier on the training data with an $\exp(-\Omega(\log^2 t))$ convergence rate. This distinguishes linear models with batch normalization from those without batch normalization in terms of both the type of implicit bias and the convergence rate. We further extend our result to a class of two-layer, single-filter linear convolutional neural networks, and show that batch normalization has an implicit bias towards a patch-wise uniform margin. Based on two examples, we demonstrate that patch-wise uniform margin classifiers can outperform the maximum margin classifiers in certain learning problems. Our results contribute to a better theoretical understanding of batch normalization.
    
[^4]: ReLU激活下图神经网络初始化和架构选择的原则

    Principles for Initialization and Architecture Selection in Graph Neural Networks with ReLU Activations. (arXiv:2306.11668v1 [stat.ML])

    [http://arxiv.org/abs/2306.11668](http://arxiv.org/abs/2306.11668)

    本文提出了三个原则来指导ReLU激活下图神经网络初始化和架构选择，其中关键在于使用残差聚合算子可以减轻过度平滑，使用修复型初始化的残差连接可以避免最终层特征的相关崩溃。

    

    本文在有限宽度的ReLU激活图神经网络(GNNs)中推导并验证了三个初始化和架构选择的原则。首先，我们理论上推导了ReLU GNNs He初始化的本质唯一泛化。我们的初始化方案保证了初始化时网络输出和梯度的平均规模保持为一阶。其次，在有限宽度的vanilla ReLU GNNs中，我们证明了使用固定聚合算子时，在大深度上过度平滑是不可避免的，无论初始化如何。然后我们证明，使用残差聚合算子，通过插值固定聚合算子和恒等算子来获得，可以在初始化时有效减轻过度平滑。最后，我们展示了使用修复型初始化的残差连接常规做法，可以在初始化时合理避免最终层特征的相关崩溃。通过消融实验，我们发现在GNNs中，修复型初始化+残差连接是关键。

    This article derives and validates three principles for initialization and architecture selection in finite width graph neural networks (GNNs) with ReLU activations. First, we theoretically derive what is essentially the unique generalization to ReLU GNNs of the well-known He-initialization. Our initialization scheme guarantees that the average scale of network outputs and gradients remains order one at initialization. Second, we prove in finite width vanilla ReLU GNNs that oversmoothing is unavoidable at large depth when using fixed aggregation operator, regardless of initialization. We then prove that using residual aggregation operators, obtained by interpolating a fixed aggregation operator with the identity, provably alleviates oversmoothing at initialization. Finally, we show that the common practice of using residual connections with a fixup-type initialization provably avoids correlation collapse in final layer features at initialization. Through ablation studies we find that u
    
[^5]: 平均场分析广义化误差

    Mean-field Analysis of Generalization Errors. (arXiv:2306.11623v1 [stat.ML])

    [http://arxiv.org/abs/2306.11623](http://arxiv.org/abs/2306.11623)

    该论文提出了一个通过概率测度空间上的微分演算探讨算法稳健性的新框架，并得出了广义误差的收敛速率为$\mathcal{O}(1/n)$的一般条件。

    

    我们提出了一个新的框架，通过概率测度空间上的微分演算，探讨算法的弱稳健性与$L_2$正则化误差。具体而言，我们考虑KL正则化的经验风险最小化问题，并建立了一般条件，使得当样本容量为$n$时，广义误差收敛速率为$\mathcal{O}(1/n)$。在单隐藏层神经网络的均场区域的监督学习背景下，这些条件体现在对损失和激活函数的合适可积和正则性假设中。

    We propose a novel framework for exploring weak and $L_2$ generalization errors of algorithms through the lens of differential calculus on the space of probability measures. Specifically, we consider the KL-regularized empirical risk minimization problem and establish generic conditions under which the generalization error convergence rate, when training on a sample of size $n$, is $\mathcal{O}(1/n)$. In the context of supervised learning with a one-hidden layer neural network in the mean-field regime, these conditions are reflected in suitable integrability and regularity assumptions on the loss and activation functions.
    
[^6]: 使用随机梯度下降从高斯过程后验中采样

    Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent. (arXiv:2306.11589v1 [cs.LG])

    [http://arxiv.org/abs/2306.11589](http://arxiv.org/abs/2306.11589)

    本文探索了使用随机梯度下降算法从高斯过程后验中采样的方法，该方法计算高效且能在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。

    

    高斯过程是用于量化不确定性和顺序决策的强大框架，但其需要求解线性系统，每当数据集大小增加时代价是立方级别的且对条件敏感。本文探索了随机梯度算法作为一种计算高效的方法来近似解决这些线性系统：我们开发了低方差的最优化目标以从后验中进行采样，并将其扩展到引入点。令人意想不到的是，即使在不快速收敛到最优解的情况下，随机梯度下降通常也会产生准确的预测。我们通过非收敛的隐式偏置的谱特征来解释这一点。我们表明，随机梯度下降会在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。在实验中，随机梯度下降实现了

    Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves sta
    
[^7]: 有关异方差数据的条件独立性检验及其在因果发现中的应用

    Conditional Independence Testing with Heteroskedastic Data and Applications to Causal Discovery. (arXiv:2306.11498v1 [stat.ME])

    [http://arxiv.org/abs/2306.11498](http://arxiv.org/abs/2306.11498)

    本文提出了一种适用于异方差数据的CI测试方法，能够在专家知识的帮助下高效进行因果发现，且实验结果表明其效果优于标准测试方法。

    

    条件独立性(CI)检验是数据分析和机器学习中各学科的频繁使用方法，也是基于约束条件的因果发现的基础。但是，CI测试经常依赖于强烈而不切实际的假设之一：同方差性，也就是假定存在常数条件方差。我们将异方差性放在结构因果模型框架中，并提出了适用于异方差噪声下的偏相关CI测试方法，前提是已经掌握关于异方差关系的专家知识。此外，我们为所提出的CI测试方法提供了理论一致性结果，并在某些假设下将其推广到因果发现领域。数字因果发现实验证明，适应了的偏相关CI测试方法在存在异方差性的情况下优于标准测试方法，并在同方差情况下保持一致。最后，我们讨论了该方法在实际应用中的相关问题。

    Conditional independence (CI) testing is frequently used in data analysis and machine learning for various scientific fields and it forms the basis of constraint-based causal discovery. Oftentimes, CI testing relies on strong, rather unrealistic assumptions. One of these assumptions is homoskedasticity, in other words, a constant conditional variance is assumed. We frame heteroskedasticity in a structural causal model framework and present an adaptation of the partial correlation CI test that works well in the presence of heteroskedastic noise, given that expert knowledge about the heteroskedastic relationships is available. Further, we provide theoretical consistency results for the proposed CI test which carry over to causal discovery under certain assumptions. Numerical causal discovery experiments demonstrate that the adapted partial correlation CI test outperforms the standard test in the presence of heteroskedasticity and is on par for the homoskedastic case. Finally, we discuss 
    
[^8]: 基于马尔科夫链的常步长SGD的收敛和集中性质

    Convergence and concentration properties of constant step-size SGD through Markov chains. (arXiv:2306.11497v1 [stat.ML])

    [http://arxiv.org/abs/2306.11497](http://arxiv.org/abs/2306.11497)

    本文通过马尔科夫链研究了常步长随机梯度下降的性质，证明了迭代收敛于一个不变分布，并获得了高置信度边界。

    

    本文考虑使用常步长随机梯度下降（SGD）优化平滑且强凸的目标，并通过马尔科夫链研究其性质。我们证明，对于具有轻微受控方差的无偏梯度估计，迭代以总变差距离收敛于一个不变分布。我们还在与以前工作相比梯度噪声分布的放宽假设下，在Wasserstein-2距离下建立了这种收敛性。由于极限分布的不变性质，我们的分析表明，当这些对于梯度成立时，后者继承了亚高斯或亚指数浓度特性。这允许推导出对于最终估计的高置信度边界。最后，在这种条件下，在线性情况下，对于Polyak-Ruppert序列的尾部，我们获得了一个无维度偏差限制。所有结果均为非渐近性质，并讨论了其后果。

    We consider the optimization of a smooth and strongly convex objective using constant step-size stochastic gradient descent (SGD) and study its properties through the prism of Markov chains. We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance. We also establish this convergence in Wasserstein-2 distance under a relaxed assumption on the gradient noise distribution compared to previous work. Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient. This allows the derivation of high-confidence bounds for the final estimate. Finally, under such conditions in the linear case, we obtain a dimension-free deviation bound for the Polyak-Ruppert average of a tail sequence. All our results are non-asymptotic and their consequences are discussed thr
    
[^9]: 利用卷积神经网络高效地估计大规模非平稳空间协方差函数

    Efficient Large-scale Nonstationary Spatial Covariance Function Estimation Using Convolutional Neural Networks. (arXiv:2306.11487v1 [stat.ML])

    [http://arxiv.org/abs/2306.11487](http://arxiv.org/abs/2306.11487)

    本研究利用卷积神经网络从非平稳的空间数据中派生子区域，并采用选择机制识别表现出与稳态场相似行为的子区域。

    

    在气候和环境科学等领域观察到的空间过程往往发生在大规模上，并呈现出空间不平稳性。拟合具有非平稳Matern协方差的高斯过程具有挑战性。文献中的先前研究通过采用空间划分技术估计在协方差函数中空间变化的参数来解决这一挑战。划分的选择是一个重要的考虑因素，但往往是主观的，缺乏数据驱动的方法。为了解决这个问题，本研究利用卷积神经网络（ConvNets）的能力从非平稳的数据中派生子区域。我们采用选择机制来识别表现出与稳态场相似行为的子区域。为了区分稳态和非平稳随机场，我们使用各种模拟数据对ConvNet进行训练。这些模拟数据是从高斯过程中生成的。

    Spatial processes observed in various fields, such as climate and environmental science, often occur on a large scale and demonstrate spatial nonstationarity. Fitting a Gaussian process with a nonstationary Mat\'ern covariance is challenging. Previous studies in the literature have tackled this challenge by employing spatial partitioning techniques to estimate the parameters that vary spatially in the covariance function. The selection of partitions is an important consideration, but it is often subjective and lacks a data-driven approach. To address this issue, in this study, we utilize the power of Convolutional Neural Networks (ConvNets) to derive subregions from the nonstationary data. We employ a selection mechanism to identify subregions that exhibit similar behavior to stationary fields. In order to distinguish between stationary and nonstationary random fields, we conducted training on ConvNet using various simulated data. These simulations are generated from Gaussian processes
    
[^10]: 学习本地可解释规则集合

    Learning Locally Interpretable Rule Ensemble. (arXiv:2306.11481v1 [cs.LG])

    [http://arxiv.org/abs/2306.11481](http://arxiv.org/abs/2306.11481)

    本文提出了一种学习可解释规则集合的框架，引入了本地可解释性概念来避免准确性和可解释性之间权衡，通过正则化器和坐标下降算法的结合进行学习。

    

    本文提出了一个新的框架来学习既准确又可解释的规则集合模型。规则集合是一种基于加权规则线性组合的可解释模型。在实践中，我们经常需要在规则集合的准确性和可解释性之间权衡。也就是说，规则集合需要包含足够多的加权规则来保持其准确性，这会损害其对人类用户的可解释性。为了避免这种权衡，我们引入了一种新的可解释性概念，称为本地可解释性，它的评估是通过模型所做的个体预测所需的规则总数来进行的，而不是为了表示模型本身。然后，我们提出了一种促进本地可解释性的正则化器，并使用带有本地搜索的坐标下降算法来学习具有所提出的正则化器的规则集合。

    This paper proposes a new framework for learning a rule ensemble model that is both accurate and interpretable. A rule ensemble is an interpretable model based on the linear combination of weighted rules. In practice, we often face the trade-off between the accuracy and interpretability of rule ensembles. That is, a rule ensemble needs to include a sufficiently large number of weighted rules to maintain its accuracy, which harms its interpretability for human users. To avoid this trade-off and learn an interpretable rule ensemble without degrading accuracy, we introduce a new concept of interpretability, named local interpretability, which is evaluated by the total number of rules necessary to express individual predictions made by the model, rather than to express the model itself. Then, we propose a regularizer that promotes local interpretability and develop an efficient algorithm for learning a rule ensemble with the proposed regularizer by coordinate descent with local search. Exp
    
[^11]: 基于深度学习Kriging的时空插值和概率预测方法

    Spatio-temporal DeepKriging for Interpolation and Probabilistic Forecasting. (arXiv:2306.11472v1 [stat.ML])

    [http://arxiv.org/abs/2306.11472](http://arxiv.org/abs/2306.11472)

    本文提出了一种基于深度学习的时空插值和概率预测方法，在预测中克服了传统技术的局限性，并在插值和概率预测方面实现了高精度的表现。

    

    高斯过程和Kriging在传统的时空建模和预测中得到了广泛应用。然而，这些技术通常预设数据是从具有参数协方差结构的平稳高斯过程中观测得到的。现实中的过程往往表现出非高斯性和非平稳性。此外，基于似然的高斯过程推断对于大型数据集来说计算成本高昂。本文提出了一个基于深度神经网络的时空插值和预测的两阶段模型。第一步进行插值，利用具有时空基函数构建的相关神经网络的嵌入层。第二步采用长短期记忆（LSTM）和卷积LSTM来预测给定位置的未来观测。我们在DNN中采用基于分位数的损失函数来提供概率预测。与Kriging相比，提出的方法不需要假设过程是平稳和高斯性的，可以处理现实世界中的非高斯性和非平稳性时空数据集。基于深度学习和LSTM的预测模型实现了高精度的插值和概率预测。

    Gaussian processes (GP) and Kriging are widely used in traditional spatio-temporal mod-elling and prediction. These techniques typically presuppose that the data are observed from a stationary GP with parametric covariance structure. However, processes in real-world applications often exhibit non-Gaussianity and nonstationarity. Moreover, likelihood-based inference for GPs is computationally expensive and thus prohibitive for large datasets. In this paper we propose a deep neural network (DNN) based two-stage model for spatio-temporal interpolation and forecasting. Interpolation is performed in the first step, which utilizes a dependent DNN with the embedding layer constructed with spatio-temporal basis functions. For the second stage, we use Long-Short Term Memory (LSTM) and convolutional LSTM to forecast future observations at a given location. We adopt the quantile-based loss function in the DNN to provide probabilistic forecasting. Compared to Kriging, the proposed method does not 
    
[^12]: 重尾奖励的可证明鲁棒时间差分学习

    Provably Robust Temporal Difference Learning for Heavy-Tailed Rewards. (arXiv:2306.11455v1 [cs.LG])

    [http://arxiv.org/abs/2306.11455](http://arxiv.org/abs/2306.11455)

    证明了一种带有动态梯度剪裁机制的时间差分（TD）学习可以在重尾奖励分布下被证明具有鲁棒性。

    

    在广泛的强化学习应用中，随机奖励具有重尾分布，这导致策略评估和直接策略优化中的随机（半）梯度具有无限的二阶矩。在这种情况下，由于经常出现统计上的离群值，现有的强化学习方法可能会失败。本研究证明了一种带有动态梯度剪裁机制的时间差分（TD）学习，以及相应操作的自然演员-评论家（NAC），可以在重尾奖励分布下被证明具有鲁棒性。在线性函数逼近的框架下，证明了这种动态梯度剪裁机制可以在偏差和随机梯度变差之间取得有利的折衷。特别地，证明了TD学习的鲁棒版本可以达到$\mathcal{O}(\varepsilon^{-\frac{1}{p}})$和$\mathcal{O}(\varepsilon^{-1-\frac{1}{p}})$的样本复杂度。

    In a broad class of reinforcement learning applications, stochastic rewards have heavy-tailed distributions, which lead to infinite second-order moments for stochastic (semi)gradients in policy evaluation and direct policy optimization. In such instances, the existing RL methods may fail miserably due to frequent statistical outliers. In this work, we establish that temporal difference (TD) learning with a dynamic gradient clipping mechanism, and correspondingly operated natural actor-critic (NAC), can be provably robustified against heavy-tailed reward distributions. It is shown in the framework of linear function approximation that a favorable tradeoff between bias and variability of the stochastic gradients can be achieved with this dynamic gradient clipping mechanism. In particular, we prove that robust versions of TD learning achieve sample complexities of order $\mathcal{O}(\varepsilon^{-\frac{1}{p}})$ and $\mathcal{O}(\varepsilon^{-1-\frac{1}{p}})$ with and without the full-rank
    
[^13]: 基于机器学习计算随机动力系统大偏差率的前置因子

    Computing large deviation prefactors of stochastic dynamical systems based on machine learning. (arXiv:2306.11418v1 [stat.ML])

    [http://arxiv.org/abs/2306.11418](http://arxiv.org/abs/2306.11418)

    本文利用机器学习的研究成果计算大偏差前置因子的接近次导数的逼近值，并证明了算法在计算平均退出时间以及探索被弱随机波动触发的罕见事件的内在机制方面具有高效性和准确性。

    

    本文提出了一个大偏差理论，以表征在弱噪声极限下随机动力系统中的罕见事件的指数估计。我们旨在通过利用机器学习的研究成果，计算大偏差前置因子的接近次导数的逼近值，以更准确地计算平均退出时间。更具体地说，我们设计了一个神经网络框架，以基于向量场的正交分解计算准势，最可能的路径和前置因子。实证例子证明了我们算法的高效性和准确性。数值实验展示了它在探索被弱随机波动触发的罕见事件的内在机制方面具有强大的功能。

    In this paper, we present large deviation theory that characterizes the exponential estimate for rare events of stochastic dynamical systems in the limit of weak noise. We aim to consider next-to-leading-order approximation for more accurate calculation of mean exit time via computing large deviation prefactors with the research efforts of machine learning. More specifically, we design a neural network framework to compute quasipotential, most probable paths and prefactors based on the orthogonal decomposition of vector field. We corroborate the higher effectiveness and accuracy of our algorithm with a practical example. Numerical experiments demonstrate its powerful function in exploring internal mechanism of rare events triggered by weak random fluctuations.
    
[^14]: 高斯过程网络的贝叶斯方法

    A Bayesian Take on Gaussian Process Networks. (arXiv:2306.11380v1 [stat.ML])

    [http://arxiv.org/abs/2306.11380](http://arxiv.org/abs/2306.11380)

    该论文提出了一种基于高斯过程和贝叶斯方法的网络模型，通过蒙特卡罗和马尔可夫链蒙特卡罗方法采样网络结构的后验分布。该方法在恢复网络的图形结构方面优于最先进的算法，并提供了后验概率的准确近似。

    

    高斯过程网络（GPNs）是一类有向图模型，其使用高斯过程作为网络中每个变量给定其父变量的条件期望的先验分布。该模型允许以紧凑但灵活的方式描述连续联合分布，对变量之间的依赖关系仅做最少的参数假设。GPNs的贝叶斯结构学习需要计算网络结构的后验分布，即使在低维情况下，这也是计算上不可行的。本文实现了蒙特卡罗和马尔可夫链蒙特卡罗方法来从网络结构的后验分布中采样。因此，该方法遵循贝叶斯范式，通过边缘似然比较模型，并计算GPN特征的后验概率。模拟研究表明，我们的方法在恢复网络的图形结构方面优于最先进的算法，并提供其后验的准确近似。

    Gaussian Process Networks (GPNs) are a class of directed graphical models which employ Gaussian processes as priors for the conditional expectation of each variable given its parents in the network. The model allows describing continuous joint distributions in a compact but flexible manner with minimal parametric assumptions on the dependencies between variables. Bayesian structure learning of GPNs requires computing the posterior over graphs of the network and is computationally infeasible even in low dimensions. This work implements Monte Carlo and Markov Chain Monte Carlo methods to sample from the posterior distribution of network structures. As such, the approach follows the Bayesian paradigm, comparing models via their marginal likelihood and computing the posterior probability of the GPN features. Simulation studies show that our method outperforms state-of-the-art algorithms in recovering the graphical structure of the network and provides an accurate approximation of its poste
    
[^15]: 深度图核点过程

    Deep graph kernel point processes. (arXiv:2306.11313v1 [stat.ML])

    [http://arxiv.org/abs/2306.11313](http://arxiv.org/abs/2306.11313)

    本文提出了一种基于潜在图拓扑的图点过程方法，并开发了一种新颖的深度图核来描述事件之间的触发和抑制效应，该方法在合成和实际数据集上具有优越性。

    

    点过程模型广泛用于分析图中异步事件，反映不同类型事件之间的相互影响。预测未来事件的时间和类型是一项关键任务，并且图的大小和拓扑结构增加了问题的难度。最近的神经点过程模型揭示了捕捉复杂的事件类别之间依赖关系的可能性。然而，这些方法在每个目标事件类型的强度计算中使用了包括所有事件类别在内的未经滤波的事件记录。在本文中，我们提出了一种基于潜在图拓扑的图点过程方法。对应的无向图具有代表事件类别的节点和表示潜在贡献关系的边。然后，我们开发了一种新颖的深度图核来描述事件之间的触发和抑制效应。本质影响结构通过图神经网络-based的局部邻域信息聚合进行了融合。我们在合成和实际数据集上展示了我们提出的方法比最先进的模型更具优越性。

    Point process models are widely used to analyze asynchronous events occurring within a graph that reflect how different types of events influence one another. Predicting future events' times and types is a crucial task, and the size and topology of the graph add to the challenge of the problem. Recent neural point process models unveil the possibility of capturing intricate inter-event-category dependencies. However, such methods utilize an unfiltered history of events, including all event categories in the intensity computation for each target event type. In this work, we propose a graph point process method where event interactions occur based on a latent graph topology. The corresponding undirected graph has nodes representing event categories and edges indicating potential contribution relationships. We then develop a novel deep graph kernel to characterize the triggering and inhibiting effects between events. The intrinsic influence structures are incorporated via the graph neural
    
[^16]: 密度估计的数据结构

    Data Structures for Density Estimation. (arXiv:2306.11312v1 [cs.DS])

    [http://arxiv.org/abs/2306.11312](http://arxiv.org/abs/2306.11312)

    该论文提出了一个可以在较小的样本数量和时间内识别出“接近”的分布的数据结构，同时还改进了一个线性时间算法，能够更有效地实现给定准确性所需操作数的减少。

    

    我们研究了以下密度估计问题的统计/计算权衡：给定离散域大小为$n$的$k$个分布$v_1, \ldots, v_k$，以及对分布$p$的采样访问，找到与$p$“接近”的$v_i$。我们的主要结果是第一个数据结构，给定$p$的子线性（在$n$中）样本数量，能够在$k$的子线性时间内识别$v_i$。我们还提供了Acharya等人（2018）算法的改进版本，可以在线性时间内报告$v_i$。后者算法的实验评估表明，它相对于之前的工作，在实现给定精度所需操作数上实现了显着的降低。

    We study statistical/computational tradeoffs for the following density estimation problem: given $k$ distributions $v_1, \ldots, v_k$ over a discrete domain of size $n$, and sampling access to a distribution $p$, identify $v_i$ that is "close" to $p$. Our main result is the first data structure that, given a sublinear (in $n$) number of samples from $p$, identifies $v_i$ in time sublinear in $k$. We also give an improved version of the algorithm of Acharya et al. (2018) that reports $v_i$ in time linear in $k$. The experimental evaluation of the latter algorithm shows that it achieves a significant reduction in the number of operations needed to achieve a given accuracy compared to prior work.
    
[^17]: 折扣正则化的非预期结果：改进确定等价强化学习中的正则化

    The Unintended Consequences of Discount Regularization: Improving Regularization in Certainty Equivalence Reinforcement Learning. (arXiv:2306.11208v1 [cs.LG])

    [http://arxiv.org/abs/2306.11208](http://arxiv.org/abs/2306.11208)

    折扣正则化不仅可以通过忽略延迟效应来缩小规划空间，还可以看作是具有先验分布的正则化，而低折扣因子的使用会导致状态-动作对之间数据量不均的性能下降。

    

    折扣正则化是一种常用的方法，用于从稀疏或嘈杂的数据中估计MDP时将规划限制为一个较简单的策略集。然而，在本文中我们揭示了折扣正则化的另一种视角，暴露出了非预期的结果。我们证明了，使用较低的折扣因子进行规划可以产生与使用具有相同分布的转移矩阵先验的任何规划得到的最优策略相同的结果。实际上，它的作用类似于对具有更多转移数据的状态-动作对进行更强的正则化。然而，当转移矩阵从数据集中估计时，对于状态-动作对之间数据量不均的情况，这将导致性能不佳。我们的等价定理导致了一个明确的公式来设置正则化。

    Discount regularization, using a shorter planning horizon when calculating the optimal policy, is a popular choice to restrict planning to a less complex set of policies when estimating an MDP from sparse or noisy data (Jiang et al., 2015). It is commonly understood that discount regularization functions by de-emphasizing or ignoring delayed effects. In this paper, we reveal an alternate view of discount regularization that exposes unintended consequences. We demonstrate that planning under a lower discount factor produces an identical optimal policy to planning using any prior on the transition matrix that has the same distribution for all states and actions. In fact, it functions like a prior with stronger regularization on state-action pairs with more transition data. This leads to poor performance when the transition matrix is estimated from data sets with uneven amounts of data across state-action pairs. Our equivalence theorem leads to an explicit formula to set regularization pa
    
[^18]: 不充分的理由落差：子组公平性的新标准

    Insufficiently Justified Disparate Impact: A New Criterion for Subgroup Fairness. (arXiv:2306.11181v1 [cs.LG])

    [http://arxiv.org/abs/2306.11181](http://arxiv.org/abs/2306.11181)

    本文提出了一个新标准“不充分的理由落差”（IJDI），用于评估算法决策支持工具所做出的建议是否公平，并描述了IJDI-Scan方法来发现重要的IJDI。在模拟和现实世界的数据上进行实验，包括再犯风险评估和信用评分，并实现了减轻IJDI的方法。

    

    本文提出一种新的标准“不充分的理由落差”（IJDI），用于评估由算法决策支持工具做出的建议（二元预测）是否公平。我们的实用型IJDI标准评估假阳性和假阴性误差率的不平衡性，识别出即使在调整群体基础比率差异的情况下仍存在的群体间显著差异。我们描述了一种新的IJDI-Scan方法，可以有效地识别跨越数据的多个观察属性的交叉子人群，其中具有最重要的IJDI。为了评估IJDI-Scan的性能，我们在模拟和真实世界的数据上进行了实验，包括再犯风险评估和信用评分。此外，我们实现和评估了在这些领域检测到的子人群上减轻IJDI的方法。

    In this paper, we develop a new criterion, "insufficiently justified disparate impact" (IJDI), for assessing whether recommendations (binarized predictions) made by an algorithmic decision support tool are fair. Our novel, utility-based IJDI criterion evaluates false positive and false negative error rate imbalances, identifying statistically significant disparities between groups which are present even when adjusting for group-level differences in base rates. We describe a novel IJDI-Scan approach which can efficiently identify the intersectional subpopulations, defined across multiple observed attributes of the data, with the most significant IJDI. To evaluate IJDI-Scan's performance, we conduct experiments on both simulated and real-world data, including recidivism risk assessment and credit scoring. Further, we implement and evaluate approaches to mitigating IJDI for the detected subpopulations in these domains.
    
[^19]: 机器学习中的人类限制：利用土壤微生物数据预测植物表型

    Human Limits in Machine Learning: Prediction of Plant Phenotypes Using Soil Microbiome Data. (arXiv:2306.11157v1 [stat.ML])

    [http://arxiv.org/abs/2306.11157](http://arxiv.org/abs/2306.11157)

    本论文深入研究了机器学习模型在预测土壤与植物表型之间联系方面的潜力，证明加入土壤物理化学性质和微生物种群密度等环境特征可以提高预测准确性。

    

    保护土壤健康被认为是21世纪的主要挑战之一，因为它在农业、人类健康和生物多样性方面具有广泛（可能具有威胁性的）影响。本研究通过两种模型（随机森林和贝叶斯神经网络）探索了利用机器学习模型来理解土壤和生物表型之间联系的预测潜力。结果表明，在模型中加入土壤物理化学性质和微生物种群密度等环境特征可以提高预测准确性。此外，通过探索多种数据预处理策略，如归一化、零替换和数据增强，进一步提高了预测性能。

    The preservation of soil health has been identified as one of the main challenges of the XXI century given its vast (and potentially threatening) ramifications in agriculture, human health and biodiversity. Here, we provide the first deep investigation of the predictive potential of machine-learning models to understand the connections between soil and biological phenotypes. Indeed, we investigate an integrative framework performing accurate machine-learning-based prediction of plant phenotypes from biological, chemical and physical properties of the soil via two models: random forest and Bayesian neural network. We show that prediction is improved, as evidenced by higher weighted F1 scores, when incorporating into the models environmental features like soil physicochemical properties and microbial population density in addition to the microbiome information. Furthermore, by exploring multiple data preprocessing strategies such as normalization, zero replacement, and data augmentation,
    
[^20]: 非线性特征聚合：由理论推导而来的两个算法

    Nonlinear Feature Aggregation: Two Algorithms driven by Theory. (arXiv:2306.11143v1 [cs.LG])

    [http://arxiv.org/abs/2306.11143](http://arxiv.org/abs/2306.11143)

    本文提出了两种聚合非线性特征的新算法：通过信息瓶颈进行非线性特征聚合（NFA-IB）和通过核嵌入进行非线性特征聚合（NFA-KE）。这些方法可以有效地解决处理非线性数据时基于相关性的方法可能导致子优表示的问题。

    

    许多现实世界的机器学习应用程序都具有大量的特征，这导致了计算和内存问题，以及过拟合的风险。理想情况下，应该仅考虑相关的非冗余特征，以保留原始数据的完整信息并限制维数。降维和特征选择是常用的预处理技术，用于解决高维数据的有效处理挑战。维度缩减方法控制数据集中特征的数量，同时保留其结构并最小化信息损失。特征选择旨在识别任务的最相关特征，舍弃信息较少的特征。先前的工作提出了基于相关性聚合特征的方法，而不丢弃任何特征，并通过平均聚合保持其可解释性。基于相关性的方法的局限性在于假设特征之间的关系是线性的，这在处理非线性数据时可能导致子优表示。本文提出了两种聚合非线性特征的新算法：通过信息瓶颈进行非线性特征聚合（NFA-IB）和通过核嵌入进行非线性特征聚合（NFA-KE）。NFA-IB基于信息瓶颈原理，而NFA-KE使用核函数将原始特征转换为更高维的空间，可以在其中捕捉特征之间的非线性关系。我们展示了我们的方法在各种场景中与最先进的技术相比的有效性。

    Many real-world machine learning applications are characterized by a huge number of features, leading to computational and memory issues, as well as the risk of overfitting. Ideally, only relevant and non-redundant features should be considered to preserve the complete information of the original data and limit the dimensionality. Dimensionality reduction and feature selection are common preprocessing techniques addressing the challenge of efficiently dealing with high-dimensional data. Dimensionality reduction methods control the number of features in the dataset while preserving its structure and minimizing information loss. Feature selection aims to identify the most relevant features for a task, discarding the less informative ones. Previous works have proposed approaches that aggregate features depending on their correlation without discarding any of them and preserving their interpretability through aggregation with the mean. A limitation of methods based on correlation is the as
    
[^21]: 纠正公平分类中的低估偏差和交叉偏差

    Correcting Underrepresentation and Intersectional Bias for Fair Classification. (arXiv:2306.11112v1 [cs.LG])

    [http://arxiv.org/abs/2306.11112](http://arxiv.org/abs/2306.11112)

    本文提出一种可以有效纠正数据偏差和交叉偏差的学习方法，并构造了一个重新加权方案，可以精确评估任何假设在真实分布上的损失。

    

    我们考虑学习被低估偏差损坏的数据的问题，其中正例在固定数量的敏感组中以不同的未知速率从数据中过滤掉。我们表明，在有少量无偏数据的情况下，我们可以有效地估计每个组的减少参数，即使在交叉组成员资格使得学习每个交叉率变得计算上不可行的情况下。利用这个分组丢失率的估计，我们构造了一个重新加权方案，可以使我们近似评估任何假设在真实分布上的损失，即使我们只能在一个有偏样本上观察到经验误差。最后，我们提出了一个封装了这个学习和重新加权过程的算法，并提供了强PAC风格的保证，即有很高的概率我们对假设在真实分布上的风险的估计将与真实风险任意接近。

    We consider the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered from the data at different, unknown rates for a fixed number of sensitive groups. We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out parameters, even in settings where intersectional group membership makes learning each intersectional rate computationally infeasible. Using this estimate for the group-wise drop-out rate, we construct a re-weighting scheme that allows us to approximate the loss of any hypothesis on the true distribution, even if we only observe the empirical error on a biased sample. Finally, we present an algorithm encapsulating this learning and re-weighting process, and we provide strong PAC-style guarantees that, with high probability, our estimate of the risk of the hypothesis over the true distribution will be arbitrarily close to the true risk.
    
[^22]: 超越正常：关于互信息估计的评估

    Beyond Normal: On the Evaluation of Mutual Information Estimators. (arXiv:2306.11078v1 [stat.ML])

    [http://arxiv.org/abs/2306.11078](http://arxiv.org/abs/2306.11078)

    本文提出了一种语言无关的互信息估计基准平台，并讨论了经典和神经估计器在处理高维数据、长尾分布和高互信息时的普适性和局限性。

    

    互信息是一种常用的统计相关度量，已在表示学习、因果性、域泛化和计算生物学等领域得到应用。然而，互信息估计通常只在简单的概率分布族类（即多元正态分布和具有一维随机变量的选择分布）上进行评估。在本文中，我们展示了如何构建具有已知基准互信息的各种分布族，并提出了一种语言无关的互信息估计基准平台。我们讨论了经典和神经网络估计器在涉及高维度、稀疏相互作用、长尾分布和高互信息的情境中的普适性和局限性。最后，我们为从业人员提供了选择适当的估计器以适应所考虑问题难度和应用估计互信息时需要考虑的问题的指南。

    Mutual information is a general statistical dependency measure which has found applications in representation learning, causality, domain generalization and computational biology. However, mutual information estimators are typically evaluated on simple families of probability distributions, namely multivariate normal distribution and selected distributions with one-dimensional random variables. In this paper, we show how to construct a diverse family of distributions with known ground-truth mutual information and propose a language-independent benchmarking platform for mutual information estimators. We discuss the general applicability and limitations of classical and neural estimators in settings involving high dimensions, sparse interactions, long-tailed distributions, and high mutual information. Finally, we provide guidelines for practitioners on how to select appropriate estimator adapted to the difficulty of problem considered and issues one needs to consider when applying an est
    
[^23]: 自动特征重新加权实现简单快速的组鲁棒性

    Simple and Fast Group Robustness by Automatic Feature Reweighting. (arXiv:2306.11074v1 [cs.LG])

    [http://arxiv.org/abs/2306.11074](http://arxiv.org/abs/2306.11074)

    本文提出了一个自动特征重新加权（AFR）的简单快速方法，使用加权损失重新训练ERC模型的最后一层来减少对虚假特征的依赖，从而提高了多个群体的鲁棒性表现。

    

    对于越界泛化的主要挑战是依赖于虚假特征--它们是在训练数据分布中预测类标签的模式，但与目标不具有因果关系。减少对虚假特征的依赖的标准方法通常假设我们知道虚假特征是什么，在现实世界中很少是真实的。试图减轻这种限制的方法复杂，难以调整，与标准训练相比具有显著的计算开销。在本文中，我们提出了一种称为自动特征重新加权（AFR）的极其简单快速的方法来更新模型以减少对虚假特征的依赖。AFR使用加权损失重新训练标准ERM训练的基本模型的最后一层，强调ERM模型预测不佳的示例，自动提高少数群体的权重，而无需组标签。通过这个简单的过程，我们改进了最佳报告结果中的许多群体鲁棒性的性能。

    A major challenge to out-of-distribution generalization is reliance on spurious features -- patterns that are predictive of the class label in the training data distribution, but not causally related to the target. Standard methods for reducing the reliance on spurious features typically assume that we know what the spurious feature is, which is rarely true in the real world. Methods that attempt to alleviate this limitation are complex, hard to tune, and lead to a significant computational overhead compared to standard training. In this paper, we propose Automatic Feature Reweighting (AFR), an extremely simple and fast method for updating the model to reduce the reliance on spurious features. AFR retrains the last layer of a standard ERM-trained base model with a weighted loss that emphasizes the examples where the ERM model predicts poorly, automatically upweighting the minority group without group labels. With this simple procedure, we improve upon the best reported results among co
    
[^24]: 应用深度学习进行油田设备预测性维护

    Application of Deep Learning for Predictive Maintenance of Oilfield Equipment. (arXiv:2306.11040v1 [stat.ML])

    [http://arxiv.org/abs/2306.11040](http://arxiv.org/abs/2306.11040)

    本论文探讨了神经网络技术在预测性维护中的应用，通过深度学习和数据处理技术，可以诊断设备的健康状态和预测故障前的剩余寿命。这项技术还被应用于油田设备的预测性维护中。

    

    本论文探讨了人工智能和深度学习（尤其是神经网络）在预测性维护、诊断和预测中的应用。许多神经网络架构（例如全连接、卷积和循环神经网络）在公共数据集上进行了开发和测试，例如NASA C-MAPSS、Case Western Reserve University Bearings和FEMTO Bearings数据集，以诊断设备的健康状态和/或预测故障前剩余寿命（RUL）。许多数据处理和特征提取程序与深度学习技术一起使用，例如降维（主成分分析）和信号处理（傅里叶和小波分析），以创建更有意义和更稳健的特征，用作神经网络架构的输入。本论文还探讨了这些技术在监测油田卡车和设备的预测性维护中的潜在用途。

    This thesis explored applications of the new emerging techniques of artificial intelligence and deep learning (neural networks in particular) for predictive maintenance, diagnostics and prognostics. Many neural architectures such as fully-connected, convolutional and recurrent neural networks were developed and tested on public datasets such as NASA C-MAPSS, Case Western Reserve University Bearings and FEMTO Bearings datasets to diagnose equipment health state and/or predict the remaining useful life (RUL) before breakdown. Many data processing and feature extraction procedures were used in combination with deep learning techniques such as dimensionality reduction (Principal Component Analysis) and signal processing (Fourier and Wavelet analyses) in order to create more meaningful and robust features to use as an input for neural networks architectures. This thesis also explored the potential use of these techniques in predictive maintenance within oil rigs for monitoring oilfield crit
    
[^25]: 对抗训练应被视为一个非零和博弈

    Adversarial Training Should Be Cast as a Non-Zero-Sum Game. (arXiv:2306.11035v1 [cs.LG])

    [http://arxiv.org/abs/2306.11035](http://arxiv.org/abs/2306.11035)

    本论文提出了一种新的针对对抗性训练的非零和双层公式，实现了与最先进攻击相匹配并且能够达到与标准对抗性训练相同的鲁棒性水平。

    

    解决深度神经网络对抗性脆弱性的一个突出方法是采用对抗性训练的两个玩家零和范式，其中预测器被训练以对抗性选择的数据扰动。虽然这种方法很有前途，但是基于这种范式的算法并没有产生足够的鲁棒性，并且遭受病态行为，如强健的过拟合。为了理解这种缺陷，我们首先展示了在对抗训练算法中使用的常见基于代理的松弛方法使所训练分类器的稳健性没有任何保证。我们发现这个问题后，提出了一个新的非零和双层对抗训练公式，其中每个玩家优化不同的目标函数，我们的公式自然地产生了一个简单的算法框架，可以与最先进的攻击相匹配，并且在一些情况下，能够达到与标准对抗性训练相当的鲁棒性水平。

    One prominent approach toward resolving the adversarial vulnerability of deep neural networks is the two-player zero-sum paradigm of adversarial training, in which predictors are trained against adversarially-chosen perturbations of data. Despite the promise of this approach, algorithms based on this paradigm have not engendered sufficient levels of robustness, and suffer from pathological behavior like robust overfitting. To understand this shortcoming, we first show that the commonly used surrogate-based relaxation used in adversarial training algorithms voids all guarantees on the robustness of trained classifiers. The identification of this pitfall informs a novel non-zero-sum bilevel formulation of adversarial training, wherein each player optimizes a different objective function. Our formulation naturally yields a simple algorithmic framework that matches and in some cases outperforms state-of-the-art attacks, attains comparable levels of robustness to standard adversarial traini
    
[^26]: 无稀疏性的高维情境赌博问题研究

    High-dimensional Contextual Bandit Problem without Sparsity. (arXiv:2306.11017v1 [stat.ML])

    [http://arxiv.org/abs/2306.11017](http://arxiv.org/abs/2306.11017)

    本论文研究了高维情境赌博问题，无需施加稀疏性要求，并提出了一种探索-开发算法以解决此问题。研究表明，可以通过平衡探索和开发实现最优速率。同时，还介绍了一种自适应探索-开发算法来找到最优平衡点。

    

    本研究探讨了高维线性情境赌博问题，其中特征数 $p$ 大于预算 $T$ 或甚至无限制。与此领域的大部分研究不同的是，我们不对回归系数施加稀疏性要求。相反，我们依靠最近关于过参数化模型的研究成果，从而能够在数据分布具有较小有效秩时分析最小范数插值估计器的性能。我们提出了一个探索-开发 (EtC) 算法来解决这个问题，并检验了它的性能。通过我们的分析，我们以 $T$ 为变量，导出了ETC算法的最优速率，并表明这个速率可以通过平衡探索和开发来实现。此外，我们介绍了一种自适应探索-开发 (AEtC)算法，它可以自适应地找到最优平衡点。我们通过一系列模拟评估了所提出算法的性能。

    In this research, we investigate the high-dimensional linear contextual bandit problem where the number of features $p$ is greater than the budget $T$, or it may even be infinite. Differing from the majority of previous works in this field, we do not impose sparsity on the regression coefficients. Instead, we rely on recent findings on overparameterized models, which enables us to analyze the performance the minimum-norm interpolating estimator when data distributions have small effective ranks. We propose an explore-then-commit (EtC) algorithm to address this problem and examine its performance. Through our analysis, we derive the optimal rate of the ETC algorithm in terms of $T$ and show that this rate can be achieved by balancing exploration and exploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC) algorithm that adaptively finds the optimal balance. We assess the performance of the proposed algorithms through a series of simulations.
    
[^27]: 前门调整法：在有限的图结构知识下超越马尔可夫等价

    Front-door Adjustment Beyond Markov Equivalence with Limited Graph Knowledge. (arXiv:2306.11008v1 [cs.LG])

    [http://arxiv.org/abs/2306.11008](http://arxiv.org/abs/2306.11008)

    本论文提出了可以不需要完全了解图形结构的情况下，使用前门调整法计算因果效应的一种方法，通过提供测试性条件独立性陈述的方式实现，这种方法适用于不知道马尔可夫等价类的情况下。

    

    从数据中估计因果效应通常需要对因果关系做出假设，可以显式地在Pearlian框架中陈述因果图结构，也可以隐含地使用潜在结果框架中的（条件）独立性陈述。当处理变量和结果变量混淆时，前门调整法是一个重要的特殊情况，其中，在给定图形的情况下，可以使用后处理变量估计处理对目标的因果效应。然而，前门调整法的精确公式取决于难以在实践中学习的图形结构。在这项工作中，我们提供了可测试的条件独立性陈述，以使用类似前门的调整法计算因果效应，而无需了解有限的结构侧面信息的图形。我们展示了我们的方法适用于不知道马尔可夫等价类的情况。

    Causal effect estimation from data typically requires assumptions about the cause-effect relations either explicitly in the form of a causal graph structure within the Pearlian framework, or implicitly in terms of (conditional) independence statements between counterfactual variables within the potential outcomes framework. When the treatment variable and the outcome variable are confounded, front-door adjustment is an important special case where, given the graph, causal effect of the treatment on the target can be estimated using post-treatment variables. However, the exact formula for front-door adjustment depends on the structure of the graph, which is difficult to learn in practice. In this work, we provide testable conditional independence statements to compute the causal effect using front-door-like adjustment without knowing the graph under limited structural side information. We show that our method is applicable in scenarios where knowing the Markov equivalence class is not s
    
[^28]: 一种用于生成多元极值的VAE方法

    A VAE Approach to Sample Multivariate Extremes. (arXiv:2306.10987v1 [stat.ML])

    [http://arxiv.org/abs/2306.10987](http://arxiv.org/abs/2306.10987)

    本论文提出了一种用于抽样多元重尾分布的VAE方法，该方法可以模拟真实世界的多元极值情况，如河流水位，从而有助于评估未来可能出现的风险。

    

    当我们需要评估未来可能会出现的比已观察到的极值更大的极端情况的风险时，从观测数据集中准确地生成极值至关重要。 应用范围包括自然灾害和金融崩溃。 机器学习社区的生成方法不适用于极端样本，需要仔细适应。此外，极值理论的渐进结果提供了一个理论框架，尤其是通过多元正则变化的概念来模拟多元极端事件。 连接这两个领域，本文详细介绍了一种用于抽样多元重尾分布的变分自动编码器（VAE）方法，即可能具有特别大强度的极端分布。 我们在合成数据集和沿多瑙河网络的实际数据集上说明了我们方法的相关性。 后者显示了我们的方法通过从已观察到的极值分布中抽样来模拟河流水位的潜力。

    Generating accurate extremes from an observational data set is crucial when seeking to estimate risks associated with the occurrence of future extremes which could be larger than those already observed. Applications range from the occurrence of natural disasters to financial crashes. Generative approaches from the machine learning community do not apply to extreme samples without careful adaptation. Besides, asymptotic results from extreme value theory (EVT) give a theoretical framework to model multivariate extreme events, especially through the notion of multivariate regular variation. Bridging these two fields, this paper details a variational autoencoder (VAE) approach for sampling multivariate heavy-tailed distributions, i.e., distributions likely to have extremes of particularly large intensities. We illustrate the relevance of our approach on a synthetic data set and on a real data set of discharge measurements along the Danube river network. The latter shows the potential of ou
    
[^29]: 策略概括中的效果不变机制

    Effect-Invariant Mechanisms for Policy Generalization. (arXiv:2306.10983v1 [stat.ML])

    [http://arxiv.org/abs/2306.10983](http://arxiv.org/abs/2306.10983)

    本文提出了一种松弛了完全不变性的方法，称为效果不变性，证明它足以进行零样本策略概括，并讨论了基于少量样本的扩展。

    

    策略学习是许多实际学习系统的重要组成部分。策略学习的一个主要挑战是如何有效地适应未见过的环境或任务。最近，有人建议利用不变的条件分布来学习更好地概括未见过环境的模型。然而，假设整个条件分布是不变的（我们称之为完全不变性），在实践中可能是一个太强的假设。在本文中，我们引入了一种松弛完全不变性的方法，称为效果不变性（简称e-不变性），并证明它是足够的（在适当的假设下），用于零样本策略概括。我们还讨论了一种扩展，它在测试环境中只有少量样本时利用e-不变性，从而实现了少样本策略推广。我们的工作不假设存在一个基础因果图，也不假设数据是由结构因果模型生成的。相反，我们开发了测试过程来测试e-不变性。

    Policy learning is an important component of many real-world learning systems. A major challenge in policy learning is how to adapt efficiently to unseen environments or tasks. Recently, it has been suggested to exploit invariant conditional distributions to learn models that generalize better to unseen environments. However, assuming invariance of entire conditional distributions (which we call full invariance) may be too strong of an assumption in practice. In this paper, we introduce a relaxation of full invariance called effect-invariance (e-invariance for short) and prove that it is sufficient, under suitable assumptions, for zero-shot policy generalization. We also discuss an extension that exploits e-invariance when we have a small sample from the test environment, enabling few-shot policy generalization. Our work does not assume an underlying causal graph or that the data are generated by a structural causal model; instead, we develop testing procedures to test e-invariance dir
    
[^30]: 纵向跟踪研究中罕见事件的预测模型及重抽样方法

    Prediction model for rare events in longitudinal follow-up and resampling methods. (arXiv:2306.10977v1 [stat.ME])

    [http://arxiv.org/abs/2306.10977](http://arxiv.org/abs/2306.10977)

    本文比较了几种重抽样方法以改进标准回归模型，并评估了抽样率对预测模型的影响。

    

    本文探讨了纵向跟踪研究中针对罕见事件预测的模型构建问题。我们在实际案例中比较了几种重抽样方法，以改进标准回归模型。我们评估了抽样率对模型预测性能的影响。为了评估纵向模型的预测性能，我们采用了一种考虑时间因素、与实际应用相对应的验证技术。

    We consider the problem of model building for rare events prediction in longitudinal follow-up studies. In this paper, we compare several resampling methods to improve standard regression models on a real life example. We evaluate the effect of the sampling rate on the predictive performances of the models. To evaluate the predictive performance of a longitudinal model, we consider a validation technique that takes into account time and corresponds to the actual use in real life.
    
[^31]: 基于深度学习的sEMG手势识别

    sEMG-based Hand Gesture Recognition with Deep Learning. (arXiv:2306.10954v1 [eess.SP])

    [http://arxiv.org/abs/2306.10954](http://arxiv.org/abs/2306.10954)

    本文通过应用深度学习技术在Unibo-INAIL数据集上实现了基于sEMG信号的手势识别，探索了被试者之间、会话之间和手臂姿势之间的可变性，并提出了相应的解决方案。

    

    基于表面肌电图(sEMG)信号的手势识别是发展自然控制的人机界面(HMIs)的一种有前途的方法，比如直观的机器人界面或多关节假肢。然而，由于运动伪影、姿态和时间变化以及传感器重新定位等可靠性问题，真实应用受到限制。本文是在Unibo-INAIL数据集上首次应用深度学习，该数据集是第一个公开的sEMG数据集，通过采集每个7个健康被试者在4种姿势下执行6种手势的8个会话，来探索被试者之间、会话之间和手臂姿势之间的可变性。最近的研究通过基于训练集构成的策略来解决可变性问题，改善非深度机器学习分类器的跨姿势和跨天泛化能力，其中径向基核SVM的准确率最高。本研究实现的深度结构是一个1d-CNN。

    Hand gesture recognition based on surface electromyographic (sEMG) signals is a promising approach for developing Human-Machine Interfaces (HMIs) with a natural control, such as intuitive robot interfaces or poly-articulated prostheses. However, real-world applications are limited by reliability problems due to motion artefacts, postural and temporal variability, and sensor re-positioning. This master thesis is the first application of deep learning on the Unibo-INAIL dataset, the first public sEMG dataset exploring the variability between subjects, sessions and arm postures by collecting data over 8 sessions of each of 7 able-bodied subjects executing 6 hand gestures in 4 arm postures. Recent studies address variability with strategies based on training set composition, which improve inter-posture and inter-day generalization of non-deep machine learning classifiers, among which the RBF-kernel SVM yields the highest accuracy. The deep architecture realized in this work is a 1d-CNN ins
    
[^32]: 使用速率函数理解插值区间的泛化

    Understanding Generalization in the Interpolation Regime using the Rate Function. (arXiv:2306.10947v1 [cs.LG])

    [http://arxiv.org/abs/2306.10947](http://arxiv.org/abs/2306.10947)

    本文利用大偏差理论，提出一种基于函数的平滑模型特征描述方法，解释了为什么一些插值器有很好的泛化能力以及现代学习技术为什么能够找到它们。

    

    本文基于大偏差理论的基本原理，提出了一种模型平滑度的新特征描述方法。与以往的工作不同，以往的工作通常用实数值（如权重范数）来表征模型的平滑度，我们表明可以用简单的实值函数来描述平滑度。基于模型平滑度的这一概念，我们提出了一个统一的理论解释，为什么一些插值器表现出非常好的泛化能力，以及为什么广泛使用的现代学习技术（如随机梯度下降，$\ell_2$-规范化，数据增强，不变的架构和超参数化）能够找到它们。我们得出的结论是，所有这些方法都提供了互补的过程，这些过程使优化器偏向于更平滑的插值器，而根据这种理论分析，更平滑的插值器是具有更好的泛化误差的插值器。

    In this paper, we present a novel characterization of the smoothness of a model based on basic principles of Large Deviation Theory. In contrast to prior work, where the smoothness of a model is normally characterized by a real value (e.g., the weights' norm), we show that smoothness can be described by a simple real-valued function. Based on this concept of smoothness, we propose an unifying theoretical explanation of why some interpolators generalize remarkably well and why a wide range of modern learning techniques (i.e., stochastic gradient descent, $\ell_2$-norm regularization, data augmentation, invariant architectures, and overparameterization) are able to find them. The emergent conclusion is that all these methods provide complimentary procedures that bias the optimizer to smoother interpolators, which, according to this theoretical analysis, are the ones with better generalization error.
    
[^33]: 生成对抗网络中真实数据和生成数据统计的概率匹配

    Probabilistic matching of real and generated data statistics in generative adversarial networks. (arXiv:2306.10943v1 [stat.ML])

    [http://arxiv.org/abs/2306.10943](http://arxiv.org/abs/2306.10943)

    本文提出一种通过向生成器损失函数中添加KL散度项的方法，来保证生成数据统计分布与真实数据的相应分布重合，并在实验中展示了此方法的优越性能。

    

    生成对抗网络是一种强大的生成建模方法。虽然生成样本往往难以区分真实数据，但不能保证它们遵循真实数据分布。本文提出了一种方法，确保某些生成数据统计分布与真实数据的相应分布重合。为此，我们在生成器损失函数中添加了Kullback-Leibler项：KL散度是在每次迭代中从小批量值获得的相应生成分布和由条件能量模型表示的真实分布之间的差异。我们在一个合成数据集和两个实际数据集上评估了该方法，并展示了我们方法的优越性能。

    Generative adversarial networks constitute a powerful approach to generative modeling. While generated samples often are indistinguishable from real data, there is no guarantee that they will follow the true data distribution. In this work, we propose a method to ensure that the distributions of certain generated data statistics coincide with the respective distributions of the real data. In order to achieve this, we add a Kullback-Leibler term to the generator loss function: the KL divergence is taken between the true distributions as represented by a conditional energy-based model, and the corresponding generated distributions obtained from minibatch values at each iteration. We evaluate the method on a synthetic dataset and two real-world datasets and demonstrate improved performance of our method.
    
[^34]: 通过关系条件神经过程实现实用的等变性

    Practical Equivariances via Relational Conditional Neural Processes. (arXiv:2306.10915v1 [stat.ML])

    [http://arxiv.org/abs/2306.10915](http://arxiv.org/abs/2306.10915)

    本文提出的关系条件神经过程（RCNPs）是一种有效将等变性纳入任何神经过程模型的方法，并扩展了等变神经过程的适用性和影响力到更高的维度。

    

    条件神经过程（CNPs）是一类元学习模型，以其综合运行时效率和可靠的不确定性量化而受欢迎。许多相关的机器学习任务，例如时空建模、贝叶斯优化和连续控制，包含等变性，例如对于平移，模型可以利用最大的性能。然而，先前试图在CNPs中包含等变性在超过两个输入维度之外的尺度上无法有效扩展。在本文中，我们提出了关系条件神经过程（RCNPs），这是一种有效将等变性纳入任何神经过程模型的方法。我们提出的方法扩展了等变神经过程的适用性和影响力到更高的维度。我们在自然包含等变性任务的大量任务上经验证实了RCNPs的竞争性能。

    Conditional Neural Processes (CNPs) are a class of metalearning models popular for combining the runtime efficiency of amortized inference with reliable uncertainty quantification. Many relevant machine learning tasks, such as spatio-temporal modeling, Bayesian Optimization and continuous control, contain equivariances -- for example to translation -- which the model can exploit for maximal performance. However, prior attempts to include equivariances in CNPs do not scale effectively beyond two input dimensions. In this work, we propose Relational Conditional Neural Processes (RCNPs), an effective approach to incorporate equivariances into any neural process model. Our proposed method extends the applicability and impact of equivariant neural processes to higher dimensions. We empirically demonstrate the competitive performance of RCNPs on a large array of tasks naturally containing equivariances.
    
[^35]: AdaStop：用于深度强化学习代理比较的高效可靠序列测试

    AdaStop: sequential testing for efficient and reliable comparisons of Deep RL Agents. (arXiv:2306.10882v1 [cs.LG])

    [http://arxiv.org/abs/2306.10882](http://arxiv.org/abs/2306.10882)

    AdaStop是一种基于多组序列测试的新统计测试方法，可用于比较多个深度强化学习算法来解决实验结果可复制性的问题。

    

    许多深度强化学习实验结果的可复现性受到质疑。为了解决这个可复现性危机，我们提出了一种理论上可靠的方法，用于比较多个深度强化学习算法。由于一个深度强化学习算法的一次执行性能是随机的，所以需要进行独立的多次执行来精确评估它。当比较多个强化学习算法时，一个主要问题是需要进行多少次执行，并且如何确保这样比较的结果在理论上是可靠的。深度强化学习的研究人员通常使用少于5个独立执行来比较算法：我们认为这通常是不够的。而且，当同时比较几个算法时，每个比较的误差都会累积，必须采用多重测试程序来考虑这些误差，以维持低误差保证。为了以统计学上的可靠方式解决这个问题，我们介绍了AdaStop，这是一种基于多组序列测试的新统计测试方法。

    The reproducibility of many experimental results in Deep Reinforcement Learning (RL) is under question. To solve this reproducibility crisis, we propose a theoretically sound methodology to compare multiple Deep RL algorithms. The performance of one execution of a Deep RL algorithm is random so that independent executions are needed to assess it precisely. When comparing several RL algorithms, a major question is how many executions must be made and how can we assure that the results of such a comparison is theoretically sound. Researchers in Deep RL often use less than 5 independent executions to compare algorithms: we claim that this is not enough in general. Moreover, when comparing several algorithms at once, the error of each comparison accumulates and must be taken into account with a multiple tests procedure to preserve low error guarantees. To address this problem in a statistically sound way, we introduce AdaStop, a new statistical test based on multiple group sequential tests
    
[^36]: 利用innsight包解释深度神经网络

    Interpreting Deep Neural Networks with the Package innsight. (arXiv:2306.10822v1 [stat.ML])

    [http://arxiv.org/abs/2306.10822](http://arxiv.org/abs/2306.10822)

    innsight是一个通用的R包，能够独立于深度学习库，解释来自任何R包的模型，并提供了丰富的可视化工具，以揭示深度神经网络预测的变量解释。

    

    R包innsight提供了一个通用的工具箱，通过所谓的特征归因方法，揭示了深度神经网络预测的变量解释。除了统一的用户友好的框架外，该包在三个方面脱颖而出：首先，它通常是第一个实现神经网络特征归因方法的R包。其次，它独立于深度学习库，允许解释来自任何R包，包括keras、torch、neuralnet甚至用户定义模型的模型。尽管它很灵活，但innsight在内部从torch包的快速和高效的数组计算中受益，这建立在LibTorch（PyTorch的C++后端）上，而不需要Python依赖。最后，它提供了各种可视化工具，用于表格、信号、图像数据或这些数据的组合。此外，可以使用plotly包以交互方式呈现这些图。

    The R package innsight offers a general toolbox for revealing variable-wise interpretations of deep neural networks' predictions with so-called feature attribution methods. Aside from the unified and user-friendly framework, the package stands out in three ways: It is generally the first R package implementing feature attribution methods for neural networks. Secondly, it operates independently of the deep learning library allowing the interpretation of models from any R package, including keras, torch, neuralnet, and even custom models. Despite its flexibility, innsight benefits internally from the torch package's fast and efficient array calculations, which builds on LibTorch $-$ PyTorch's C++ backend $-$ without a Python dependency. Finally, it offers a variety of visualization tools for tabular, signal, image data or a combination of these. Additionally, the plots can be rendered interactively using the plotly package.
    
[^37]: $\texttt{causalAssembly}$: 用于基准因果发现的生成真实生产数据

    $\texttt{causalAssembly}$: Generating Realistic Production Data for Benchmarking Causal Discovery. (arXiv:2306.10816v1 [stat.ML])

    [http://arxiv.org/abs/2306.10816](http://arxiv.org/abs/2306.10816)

    该论文提出了一种生成基于装配线数据的半合成制造数据集的方法，以支持因果发现方法的基准测试。

    

    因果发现算法近年来取得了快速进展并越来越多地依靠灵活的非参数方法来处理复杂数据。然而，由于大多数真实数据源中真正的因果关系仍不为人所知，因此这些算法需要充分的经验验证。这个问题进一步加剧了环绕合适高质量数据发布的隐私问题。为了解决这些挑战，我们收集了一组复杂数据集，包括制造过程中装配线的测量数据。借助于对物理学的深入研究，这个数据集能够提供地面的因果关系对照。我们使用这个装配线数据和相关的地面真实信息来构建一个系统，生成半合成造数据来支持基准因果发现方法。为了实现这个目标，我们采用了最先进的仿真技术来生成数据集，模仿原始装配线数据集的特征，保留了过程变量之间的因果关系和它们的非线性依赖关系。

    Algorithms for causal discovery have recently undergone rapid advances and increasingly draw on flexible nonparametric methods to process complex data. With these advances comes a need for adequate empirical validation of the causal relationships learned by different algorithms. However, for most real data sources true causal relations remain unknown. This issue is further compounded by privacy concerns surrounding the release of suitable high-quality data. To help address these challenges, we gather a complex dataset comprising measurements from an assembly line in a manufacturing context. This line consists of numerous physical processes for which we are able to provide ground truth causal relationships on the basis of a detailed study of the underlying physics. We use the assembly line data and associated ground truth information to build a system for generation of semisynthetic manufacturing data that supports benchmarking of causal discovery methods. To accomplish this, we employ 
    
[^38]: 实用的一阶贝叶斯优化算法

    Practical First-Order Bayesian Optimization Algorithms. (arXiv:2306.10815v1 [cs.LG])

    [http://arxiv.org/abs/2306.10815](http://arxiv.org/abs/2306.10815)

    本文提出了一种实用的FOBO算法，通过利用梯度GP的信息，有效地识别具有零梯度的潜在查询点，采用多级采集函数来潜在确定全局最大值。

    

    第一阶贝叶斯优化(FOBO)是一种有效的顺序方法，通过适当地查询函数及其梯度评估，来寻找昂贵的黑盒子目标函数的全局极值。这种方法假设函数和其梯度的高斯过程(GP)模型，并使用它们构建一个获取函数，以识别下一个查询点。在本文中，我们提出了一类实用的FOBO算法，它有效利用了梯度GP的信息，以识别具有零梯度的潜在查询点。我们构建了一个多级采集函数，在第一步中，我们使用多重重启来优化较低级别的采集函数，以识别具有零梯度值的潜在查询点。然后，我们使用上层获取函数根据它们的函数值对这些查询点进行排序，以潜在地确定全局最大值。作为最后一步，最大值的潜在点被选择。

    First Order Bayesian Optimization (FOBO) is a sample efficient sequential approach to find the global maxima of an expensive-to-evaluate black-box objective function by suitably querying for the function and its gradient evaluations. Such methods assume Gaussian process (GP) models for both, the function and its gradient, and use them to construct an acquisition function that identifies the next query point. In this paper, we propose a class of practical FOBO algorithms that efficiently utilizes the information from the gradient GP to identify potential query points with zero gradients. We construct a multi-level acquisition function where in the first step, we optimize a lower level acquisition function with multiple restarts to identify potential query points with zero gradient value. We then use the upper level acquisition function to rank these query points based on their function values to potentially identify the global maxima. As a final step, the potential point of maxima is ch
    
[^39]: P张量：构建高阶消息传递网络的通用形式。

    P-tensors: a General Formalism for Constructing Higher Order Message Passing Networks. (arXiv:2306.10767v1 [stat.ML])

    [http://arxiv.org/abs/2306.10767](http://arxiv.org/abs/2306.10767)

    P-tensors 提供了构建高阶消息传递网络的通用形式，其在分子等高度结构化的图形中具有优异的性能表现。

    

    最近的几篇论文表明，高阶图神经网络在高度结构化的图形如分子中能够比其标准的消息传递对应物获得更好的准确性。这些模型通常通过考虑包含在给定图形中的子图的高阶表示，然后在它们之间执行某些线性映射来工作。我们将这些结构正式化为排列等变张量或P张量，并推导出所有线性映射之间的任意顺序等变P张量的基础。在实验中，我们展示了这种范式在几个基准数据集上达到了现有最先进性能。

    Several recent papers have recently shown that higher order graph neural networks can achieve better accuracy than their standard message passing counterparts, especially on highly structured graphs such as molecules. These models typically work by considering higher order representations of subgraphs contained within a given graph and then perform some linear maps between them. We formalize these structures as permutation equivariant tensors, or P-tensors, and derive a basis for all linear maps between arbitrary order equivariant P-tensors. Experimentally, we demonstrate this paradigm achieves state of the art performance on several benchmark datasets.
    
[^40]: BNN-DP: 通过动态规划对贝叶斯神经网络进行鲁棒性认证

    BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming. (arXiv:2306.10742v1 [cs.LG])

    [http://arxiv.org/abs/2306.10742](http://arxiv.org/abs/2306.10742)

    本文提出了一个高效算法框架BNN-DP，使用动态规划算法来保证贝叶斯神经网络的鲁棒性。在多个实验中，该算法框架的精度和时间效率均高于现有方法。

    

    本文提出了一种高效的算法框架BNN-DP，用于分析贝叶斯神经网络（BNN）的对抗性鲁棒性。该框架基于将BNN视为随机动态系统的解释，利用动态规划算法沿着网络层次边界估计BNN的预测范围。具体而言，该方法使用边界传播技术和凸松弛来导出反向递归过程，利用分段仿射函数来优化BNN的预测范围。该算法是通用的，可以处理回归和分类任务。在对各种回归和分类任务以及BNN体系结构进行的一系列实验中，我们证明了BNN-DP优于现有方法四个数量级，同时具有更高的精度和时间效率。

    In this paper, we introduce BNN-DP, an efficient algorithmic framework for analysis of adversarial robustness of Bayesian Neural Networks (BNNs). Given a compact set of input points $T\subset \mathbb{R}^n$, BNN-DP computes lower and upper bounds on the BNN's predictions for all the points in $T$. The framework is based on an interpretation of BNNs as stochastic dynamical systems, which enables the use of Dynamic Programming (DP) algorithms to bound the prediction range along the layers of the network. Specifically, the method uses bound propagation techniques and convex relaxations to derive a backward recursion procedure to over-approximate the prediction range of the BNN with piecewise affine functions. The algorithm is general and can handle both regression and classification tasks. On a set of experiments on various regression and classification tasks and BNN architectures, we show that BNN-DP outperforms state-of-the-art methods by up to four orders of magnitude in both tightness 
    
[^41]: 虚拟人类生成模型：基于掩码建模的方法来学习人类特征

    Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])

    [http://arxiv.org/abs/2306.10656](http://arxiv.org/abs/2306.10656)

    本论文提出了一种名为VHGM的深度生成模型，基于掩码建模的方法来学习健康属性、生活方式和人格之间的关系。通过使用异构表格数据集，VHGM有效地学习了超过1,800个属性。该模型具有潜在的应用前景，例如用于医疗属性的虚拟测量和生活方式的假设验证。

    

    识别医疗属性、生活方式和人格之间的关系对于理解和改善身体和精神状况至关重要。本文提出了一种名为虚拟人类生成模型（VHGM）的机器学习模型，用于估计有关医疗保健、生活方式和个性的属性。VHGM是一个深度生成模型，使用掩码建模训练，在已知属性的条件下学习属性的联合分布。利用异构表格数据集，VHGM高效地学习了超过1,800个属性。我们数值评估了VHGM及其训练技术的性能。作为VHGM的概念验证，我们提出了几个应用程序，演示了用户情境，例如医疗属性的虚拟测量和生活方式的假设验证。

    Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
    
[^42]: 使用全能预测器对单指数模型进行自主学习

    Agnostically Learning Single-Index Models using Omnipredictors. (arXiv:2306.10615v1 [cs.LG])

    [http://arxiv.org/abs/2306.10615](http://arxiv.org/abs/2306.10615)

    本文提出了使用全能预测器对单指数模型进行自主学习的方法，且仅需要边缘具有有界的二阶矩。该方法可适用于任意单调和利普希茨激活，并且过往方法中所需的更强分布假设不再需要。研究者们通过匹配损失与$\ell_p$距离的关系，提供了一种简单的分析方式，并在不可知设置中为标准算法提供了新的保证。

    

    我们给出了第一个结果，即在具有任意单调和利普希茨激活的单指数模型（SIM）中进行自主学习。所有之前的工作要么仅适用于可以实现的设置，要么需要知道激活函数。此外，我们仅需要边缘具有有界的二阶矩，而所有之前的工作都需要更强的分布假设（如反浓度或有界性）。我们的算法基于[GHK＋23]最近的全能预测使用符合校准的观察精度的预测器方案。我们的分析简单且依赖于Bregman距离（或匹配损失）与$\ell_p$距离之间的关系。我们还为GLMtron和逻辑回归等标准算法在不可知设置中提供了新的保证。

    We give the first result for agnostically learning Single-Index Models (SIMs) with arbitrary monotone and Lipschitz activations. All prior work either held only in the realizable setting or required the activation to be known. Moreover, we only require the marginal to have bounded second moments, whereas all prior work required stronger distributional assumptions (such as anticoncentration or boundedness). Our algorithm is based on recent work by [GHK$^+$23] on omniprediction using predictors satisfying calibrated multiaccuracy. Our analysis is simple and relies on the relationship between Bregman divergences (or matching losses) and $\ell_p$ distances. We also provide new guarantees for standard algorithms like GLMtron and logistic regression in the agnostic setting.
    
[^43]: 带有嘈杂治疗和没有侧面信息的可识别因果推断

    Identifiable causal inference with noisy treatment and no side information. (arXiv:2306.10614v1 [cs.LG])

    [http://arxiv.org/abs/2306.10614](http://arxiv.org/abs/2306.10614)

    本论文提出了一种在没有侧面信息和具有复杂非线性依赖性的情况下，纠正因治疗变量不准确测量引起的因果效应估计偏差的模型，并证明了该模型的因果效应估计是可识别的。该方法使用了深度潜在变量模型和分摊权重变分客观函数进行训练。

    

    在某些因果推断场景中，治疗（即原因）变量的测量存在不准确性，例如在流行病学或计量经济学中。未能纠正测量误差的影响可能导致偏差的因果效应估计。以前的研究没有从因果视角研究解决这个问题的方法，同时允许复杂的非线性依赖关系并且不假设可以访问侧面信息。对于这样的场景，本论文提出了一个模型，它假设存在一个连续的治疗变量，该变量测量不准确。建立在现有测量误差模型的基础上，我们证明了我们的模型的因果效应估计是可识别的，即使没有测量误差方差或其他侧面信息的知识。我们的方法依赖于深度潜在变量模型，其中高斯条件由神经网络参数化，并且我们开发了一个分摊权重变分客观函数来训练该模型。

    In some causal inference scenarios, the treatment (i.e. cause) variable is measured inaccurately, for instance in epidemiology or econometrics. Failure to correct for the effect of this measurement error can lead to biased causal effect estimates. Previous research has not studied methods that address this issue from a causal viewpoint while allowing for complex nonlinear dependencies and without assuming access to side information. For such as scenario, this paper proposes a model that assumes a continuous treatment variable which is inaccurately measured. Building on existing results for measurement error models, we prove that our model's causal effect estimates are identifiable, even without knowledge of the measurement error variance or other side information. Our method relies on a deep latent variable model where Gaussian conditionals are parameterized by neural networks, and we develop an amortized importance-weighted variational objective for training the model. Empirical resul
    
[^44]: 基于紧核的条件期望估计

    Conditional expectation via compact kernels. (arXiv:2306.10592v1 [stat.ML])

    [http://arxiv.org/abs/2306.10592](http://arxiv.org/abs/2306.10592)

    本文提出了一种基于紧核的算子理论方法来解决条件期望估计问题，在再生核希尔伯特空间中实现，易于实现，且成功应用于实际问题中。

    

    去噪、条件期望和流形学习任务通常可以在寻找两个随机变量积的条件期望的公共环境下表述。本文针对这个更一般的问题，描述了一种算子理论方法来估计条件期望。核积分算子被用作紧致化工具，将估计问题设置为在再生核希尔伯特空间中的线性逆问题。该方程的解被证明对数值逼近是稳定的，从而确保了数据驱动实现的收敛性。总体技术易于实现，还展示了其在一些实际问题中的成功应用。

    The separate tasks of denoising, conditional expectation and manifold learning can often be posed in a common setting of finding the conditional expectations arising from a product of two random variables. This paper focuses on this more general problem and describes an operator theoretic approach to estimating the conditional expectation. Kernel integral operators are used as a compactification tool, to set up the estimation problem as a linear inverse problem in a reproducing kernel Hilbert space. This equation is shown to have solutions that are stable to numerical approximation, thus guaranteeing the convergence of data-driven implementations. The overall technique is easy to implement, and their successful application to some real-world problems are also shown.
    
[^45]: 我们能否在不做任何假设的情况下，证伪Wald置信区间在双重稳健函数下的有效性？

    Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])

    [http://arxiv.org/abs/2306.10590](http://arxiv.org/abs/2306.10590)

    本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。

    

    本文提出了一种可行的版本的无假设检验方法，可否定分析师对报道的以双重机器学习(DML)估计量为中心的名义$(1-\alpha)$Wald置信区间的有效性的证明，对Rotnitzky等人所研究的双重稳健(DR)函数类的任何成员进行检验。DR函数类在经济学和生物统计学中具有广泛和核心的重要性。它严格包括两个类别，即(i)可以被写成条件期望的仿射函数期望的均方连续函数的类别，这是由Chernozhukov等人研究的，以及Robins等人所研究的类别。目前DR函数的最先进的估计值是DML估计值。$\hat{\psi}_{1}$的偏差取决于两个辅助函数$b$和$p$的估计率的乘积。最常见的是，分析师证明了

    In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
    
[^46]: 策略优化中的乐观性和适应性

    Optimism and Adaptivity in Policy Optimization. (arXiv:2306.10587v1 [cs.LG])

    [http://arxiv.org/abs/2306.10587](http://arxiv.org/abs/2306.10587)

    本文通过将看似无关的策略优化算法重新构造为共同的两个交错步骤，即乐观策略改进和后见适应，统一了强化学习中的策略优化方法，揭示了加速方法中的乐观性和适应性的共同理论属性。

    

    本文致力于通过“乐观性”和“适应性”在强化学习中加速策略优化方法的统一范式。通过利用策略迭代和策略梯度方法之间的深刻联系，我们将一些看似无关的策略优化算法重新构造为两个交错步骤（i）乐观策略改进操作器使用“梯度上升预测”将先前的策略$\pi_t$映射到一个假设$\pi_{t+1}$，然后（ii）对$\pi_{t+1}$的性能进行部分评估，并基于此进行“后见适应”。我们使用这个共享的视角来共同表达其他众所周知的算法，包括软件和乐观策略迭代、自然演员-评论家方法、基于前向搜索的基于模型的策略改进和元学习算法。通过这样做，我们揭示了关于通过乐观性和适应性加速的共同理论属性。

    We work towards a unifying paradigm for accelerating policy optimization methods in reinforcement learning (RL) through \emph{optimism} \& \emph{adaptivity}. Leveraging the deep connection between policy iteration and policy gradient methods, we recast seemingly unrelated policy optimization algorithms as the repeated application of two interleaving steps (i) an \emph{optimistic policy improvement operator} maps a prior policy $\pi_t$ to a hypothesis $\pi_{t+1}$ using a \emph{gradient ascent prediction}, followed by (ii) a \emph{hindsight adaptation} of the optimistic prediction based on a partial evaluation of the performance of $\pi_{t+1}$. We use this shared lens to jointly express other well-known algorithms, including soft and optimistic policy iteration, natural actor-critic methods, model-based policy improvement based on forward search, and meta-learning algorithms. By doing so, we shed light on collective theoretical properties related to acceleration via optimism \& adaptivit
    
[^47]: OpenDataVal：一种数据价值评估的统一基准测试

    OpenDataVal: a Unified Benchmark for Data Valuation. (arXiv:2306.10577v1 [cs.LG])

    [http://arxiv.org/abs/2306.10577](http://arxiv.org/abs/2306.10577)

    本文介绍了一种名为OpenDataVal的基准测试框架，该框架整合了多种数据集和九种最先进的数据估值算法实现，并提供了四个下游机器学习任务来评估数据价值的质量。

    

    评估单个数据点的质量和影响对于提高模型性能和减轻训练数据集中不良偏差至关重要。尽管已经提出了几个数据估值算法来量化数据质量，但还缺乏一个系统化和标准化的数据估值基准测试系统。本文介绍了OpenDataVal，一种易于使用和统一的基准测试框架，使研究人员和从业者能够应用和比较各种数据估值算法。OpenDataVal提供了一个综合环境，包括（i）各种图像，自然语言和表格数据集，（ii）九种不同的最先进的数据估值算法的实现，以及（iii）可以导入任何scikit-learn模型的预测模型API。此外，我们提出了四个下游机器学习任务，用于评估数据值的质量。我们使用OpenDataVal进行基准测试分析，量化并比较不同数据估值算法在不同数据集上的表现。

    Assessing the quality and impact of individual data points is critical for improving model performance and mitigating undesirable biases within the training dataset. Several data valuation algorithms have been proposed to quantify data quality, however, there lacks a systemic and standardized benchmarking system for data valuation. In this paper, we introduce OpenDataVal, an easy-to-use and unified benchmark framework that empowers researchers and practitioners to apply and compare various data valuation algorithms. OpenDataVal provides an integrated environment that includes (i) a diverse collection of image, natural language, and tabular datasets, (ii) implementations of nine different state-of-the-art data valuation algorithms, and (iii) a prediction model API that can import any models in scikit-learn. Furthermore, we propose four downstream machine learning tasks for evaluating the quality of data values. We perform benchmarking analysis using OpenDataVal, quantifying and comparin
    
[^48]: 基于评分的数据同化

    Score-based Data Assimilation. (arXiv:2306.10574v1 [cs.LG])

    [http://arxiv.org/abs/2306.10574](http://arxiv.org/abs/2306.10574)

    本文介绍了基于评分的数据同化方法，通过对状态轨迹模型的训练，实现了无需依赖传统推断方法和满足高维系统与长时间跨度下进行推断。

    

    在最全面的形式下，数据同化解决了鉴定随机动态系统中的可能状态轨迹的贝叶斯逆问题，从而解释尽管存在噪声或不完整观测的内容。已经提出了各种方法来解决这个问题，包括基于粒子的和可变方法。然而，大多数算法依赖于转移动态进行推断，这在长时间跨度或具有复杂动态的高维系统中变得棘手，如海洋或大气。本文介绍了基于评分的数据同化来实现轨迹推断。我们学习了基于评分的生成状态轨迹模型，这是基于一个关键洞察，即任意长轨迹的得分可以分解为短部分的得分系列。在训练完成后，运用得分模型进行无自回归的推断，通过同时生成所有状态。与众不同的是，我们解耦了观测。

    Data assimilation, in its most comprehensive form, addresses the Bayesian inverse problem of identifying plausible state trajectories that explain noisy or incomplete observations of stochastic dynamical systems. Various approaches have been proposed to solve this problem, including particle-based and variational methods. However, most algorithms depend on the transition dynamics for inference, which becomes intractable for long time horizons or for high-dimensional systems with complex dynamics, such as oceans or atmospheres. In this work, we introduce score-based data assimilation for trajectory inference. We learn a score-based generative model of state trajectories based on the key insight that the score of an arbitrarily long trajectory can be decomposed into a series of scores over short segments. After training, inference is carried out using the score model, in a non-autoregressive manner by generating all states simultaneously. Quite distinctively, we decouple the observation 
    
[^49]: 预测模型可以用于因果推断吗？

    Can predictive models be used for causal inference?. (arXiv:2306.10551v1 [stat.ML])

    [http://arxiv.org/abs/2306.10551](http://arxiv.org/abs/2306.10551)

    尽管传统的机器学习和深度学习算法常常利用非因果相关性，但是通过适当的特征选择和超参数调整，预测模型仍然可以有效地用于因果推断。

    

    监督机器学习和深度学习算法在预测任务中表现出色，但通常假设它们常常利用非因果相关性，这可能会限制解释性和泛化能力。本文展示了解释和预测之间的这种权衡并不像预期的那么深刻和基本。虽然当提供所有数据进行预测时，机器学习和深度学习算法确实倾向于使用非因果特征进行预测，但是可以通过按照Pearl的反向门控准则选择特征来约束任何机器学习和深度学习算法的学习过程。在这种情况下，某些算法（尤其是深度神经网络）可以在特征共线性下提供近似无偏的效应估计。剩余的偏差可由特定的算法结构和超参数选择进行解释。因此，当用于预测或推断时，最佳超参数设置是不同的，这证实了两者之间存在权衡的一般直觉。然而，通过使用适当的特征选择和超参数调整，预测模型仍然可以有效地用于因果推断。

    Supervised machine learning (ML) and deep learning (DL) algorithms excel at predictive tasks, but it is commonly assumed that they often do so by exploiting non-causal correlations, which may limit both interpretability and generalizability. Here, we show that this trade-off between explanation and prediction is not as deep and fundamental as expected. Whereas ML and DL algorithms will indeed tend to use non-causal features for prediction when fed indiscriminately with all data, it is possible to constrain the learning process of any ML and DL algorithm by selecting features according to Pearl's backdoor adjustment criterion. In such a situation, some algorithms, in particular deep neural networks, can provide near unbiased effect estimates under feature collinearity. Remaining biases are explained by the specific algorithmic structures as well as hyperparameter choice. Consequently, optimal hyperparameter settings are different when tuned for prediction or inference, confirming the ge
    
[^50]: 线性模型中的Dropout正则化与$\ell_2$-Penalization比较

    Dropout Regularization Versus $\ell_2$-Penalization in the Linear Model. (arXiv:2306.10529v1 [math.ST])

    [http://arxiv.org/abs/2306.10529](http://arxiv.org/abs/2306.10529)

    研究发现，线性回归模型中采用dropout技术的统计行为具有更加微妙的与$\ell_2$正则化的联系，dropout并不像预期中那样具有稳定的正则化效果。

    

    本研究探讨了线性回归模型中采用dropout的梯度下降算法的统计行为。具体而言，推导了迭代的期望和协方差矩阵的非渐近性界限。与文献中广泛引用的dropout与$\ell_2$正则化的期望联系不同的是，结果表明了由于梯度下降动态与dropout引入的附加随机性之间的相互作用，两者之间存在着更加微妙的关系。我们还研究了一种简化版的dropout，它不具有正则化作用，并收敛于最小平方估计器。

    We investigate the statistical behavior of gradient descent iterates with dropout in the linear regression model. In particular, non-asymptotic bounds for expectations and covariance matrices of the iterates are derived. In contrast with the widely cited connection between dropout and $\ell_2$-regularization in expectation, the results indicate a much more subtle relationship, owing to interactions between the gradient descent dynamics and the additional randomness induced by dropout. We also study a simplified variant of dropout which does not have a regularizing effect and converges to the least squares estimator.
    
[^51]: 基于强化学习的变分序列最优实验设计方法

    Variational Sequential Optimal Experimental Design using Reinforcement Learning. (arXiv:2306.10430v1 [stat.ML])

    [http://arxiv.org/abs/2306.10430](http://arxiv.org/abs/2306.10430)

    该研究提出了一种基于贝叶斯框架和信息增益效用的变分序列最优实验设计方法，通过强化学习求解最优设计策略，适用于多种OED问题，结果具有更高的样本效率和更少的前向模型模拟次数。

    

    我们引入了变分序列最优实验设计 (vsOED) 的新方法，通过贝叶斯框架和信息增益效用来最优地设计有限序列的实验。具体而言，我们通过变分近似贝叶斯后验的下界估计期望效用。通过同时最大化变分下界和执行策略梯度更新来数值解决最优设计策略。我们将这种方法应用于一系列面向参数推断、模型区分和目标导向预测的OED问题。这些案例涵盖了显式和隐式似然函数、麻烦参数和基于物理的偏微分方程模型。我们的vsOED结果表明，与以前的顺序设计算法相比，样本效率大大提高，所需前向模型模拟次数减少了。

    We introduce variational sequential Optimal Experimental Design (vsOED), a new method for optimally designing a finite sequence of experiments under a Bayesian framework and with information-gain utilities. Specifically, we adopt a lower bound estimator for the expected utility through variational approximation to the Bayesian posteriors. The optimal design policy is solved numerically by simultaneously maximizing the variational lower bound and performing policy gradient updates. We demonstrate this general methodology for a range of OED problems targeting parameter inference, model discrimination, and goal-oriented prediction. These cases encompass explicit and implicit likelihoods, nuisance parameters, and physics-based partial differential equation models. Our vsOED results indicate substantially improved sample efficiency and reduced number of forward model simulations compared to previous sequential design algorithms.
    
[^52]: 分布式半监督稀疏统计推断

    Distributed Semi-Supervised Sparse Statistical Inference. (arXiv:2306.10395v1 [stat.ML])

    [http://arxiv.org/abs/2306.10395](http://arxiv.org/abs/2306.10395)

    本文提出了一种分布式半监督稀疏统计推断的高效算法，融合了有/无标签数据，为M估计和广义线性模型提供了定制去偏方法，并在模拟和真实数据应用中展示了结合无标签数据的效果。

    

    本文研究了分布式环境下半监督稀疏统计推断问题。我们提出了一种高效的多轮分布式去偏估计器，它融合了有标记和无标记数据，并且演示了额外的无标签数据如何帮助提高每轮迭代的统计速率。我们的方法为$M$- 估计和广义线性模型提供了量身定制的去偏方法，具体根据损失函数的特定形式而定。此外，我们的算法还可以应用于非光滑损失，例如绝对偏差损失。此外，我们的算法计算效率高，因为它只需要高维逆协方差矩阵的估计。通过模拟研究和真实数据应用，我们证明了我们的方法的有效性，并突出了结合无标签数据的好处。

    This paper is devoted to studying the semi-supervised sparse statistical inference in a distributed setup. An efficient multi-round distributed debiased estimator, which integrates both labeled and unlabelled data, is developed. We will show that the additional unlabeled data helps to improve the statistical rate of each round of iteration. Our approach offers tailored debiasing methods for $M$-estimation and generalized linear model according to the specific form of the loss function. Our method also applies to a non-smooth loss like absolute deviation loss. Furthermore, our algorithm is computationally efficient since it requires only one estimation of a high-dimensional inverse covariance matrix. We demonstrate the effectiveness of our method by presenting simulation studies and real data applications that highlight the benefits of incorporating unlabeled data.
    
[^53]: 非线性策略下线性系统的无渐进系统辨识

    Non-asymptotic System Identification for Linear Systems with Nonlinear Policies. (arXiv:2306.10369v1 [math.OC])

    [http://arxiv.org/abs/2306.10369](http://arxiv.org/abs/2306.10369)

    本文提供了一个非渐近误差界，适用于独立同分布随机激励噪声下的任何非线性和/或时变策略下生成的轨迹。这适用于安全学习控制中的受限制线性系统，与线性策略相一致。

    

    本文考虑在独立同分布随机激励噪声下，针对非线性和/或时变策略下的线性系统的单轨迹系统辨识问题。该问题的动机是保证基于学习的受限制线性系统的安全控制，在学习过程中的安全策略通常是非线性和时变的，以满足状态和输入限制。在本文中，我们提供了一个非渐近误差界，只要生成的状态和操作轨迹有界，该界适用于最小二乘估计中使用的任何非线性和/或时变策略下生成的轨迹。这显着推广了现有的线性系统辨识的非渐近保证，这些保证通常考虑独立同分布随机输入或线性策略。有趣的是，我们的误差界对于轨迹长度、系统维数和激励水平的依赖与线性策略相一致。最后，我们做了实验演示。

    This paper considers a single-trajectory system identification problem for linear systems under general nonlinear and/or time-varying policies with i.i.d. random excitation noises. The problem is motivated by safe learning-based control for constrained linear systems, where the safe policies during the learning process are usually nonlinear and time-varying for satisfying the state and input constraints. In this paper, we provide a non-asymptotic error bound for least square estimation when the data trajectory is generated by any nonlinear and/or time-varying policies as long as the generated state and action trajectories are bounded. This significantly generalizes the existing non-asymptotic guarantees for linear system identification, which usually consider i.i.d. random inputs or linear policies. Interestingly, our error bound is consistent with that for linear policies with respect to the dependence on the trajectory length, system dimensions, and excitation levels. Lastly, we demo
    
[^54]: 深度Huber分位数回归网络

    Deep Huber quantile regression networks. (arXiv:2306.10306v1 [stat.ML])

    [http://arxiv.org/abs/2306.10306](http://arxiv.org/abs/2306.10306)

    DHQRN可以预测更一般的Huber分位数，并且在预测分布的尾部提供更好的预测。

    

    典型的机器学习回归应用旨在通过使用平方误差或绝对误差评分函数来报告预测概率分布的均值或中位数。发出更多预测概率分布的函数（分位数和期望值）的重要性已被认为是量化预测不确定性的手段。在深度学习（DL）应用程序中，通过分位数和期望值回归神经网络（QRNN和ERNN）可以实现这一点。在这里，我们介绍了深度Huber分位数回归网络（DHQRN），它将QRNN和ERNN嵌套为边缘情况。 DHQRN可以预测Huber分位数，这是更一般的函数，因为它们将分位数和期望值作为极限情况嵌套起来。主要思想是使用Huber分位数回归函数训练深度学习算法，这与Huber分位数功能一致。作为概念验证，DHQRN被应用于预测房价的真实数据集，并与其他回归技术进行比较。我们观察到，在几个误差指标中，DHQRN胜过其他技术，在预测分布的尾部提供更好的预测。

    Typical machine learning regression applications aim to report the mean or the median of the predictive probability distribution, via training with a squared or an absolute error scoring function. The importance of issuing predictions of more functionals of the predictive probability distribution (quantiles and expectiles) has been recognized as a means to quantify the uncertainty of the prediction. In deep learning (DL) applications, that is possible through quantile and expectile regression neural networks (QRNN and ERNN respectively). Here we introduce deep Huber quantile regression networks (DHQRN) that nest QRNNs and ERNNs as edge cases. DHQRN can predict Huber quantiles, which are more general functionals in the sense that they nest quantiles and expectiles as limiting cases. The main idea is to train a deep learning algorithm with the Huber quantile regression function, which is consistent for the Huber quantile functional. As a proof of concept, DHQRN are applied to predict hou
    
[^55]: 非凸优化中的自适应策略

    Adaptive Strategies in Non-convex Optimization. (arXiv:2306.10278v1 [cs.LG])

    [http://arxiv.org/abs/2306.10278](http://arxiv.org/abs/2306.10278)

    本文介绍了应用于随机优化和深度神经网络训练中的自适应算法。算法可以自动适应不同的噪声水平和梯度比例范围，从而达到（近似）最优速度。

    

    如果算法不需要先验知识就可以表现得与知道这个问题特定参数的算法相竞争，那么就说算法对某个参数是自适应的。本论文介绍了我们在以下场景中开发自适应算法的工作：1. 在随机优化环境中，我们只收到随机梯度，并且评估这些梯度的噪声水平极大地影响了收敛速度。通常需要调整噪声水平才能实现最优速率，而我们开发了自适应算法，可以在不知道噪声范围的情况下自动保证（近似）最优速率。2. 在训练深度神经网络时，每个坐标轴上的梯度大小比例可以散布在非常广的范围内，除非采用像BatchNorm这样的归一化技术。在这种情况下，不考虑梯度比例问题的算法可能表现非常差。

    An algorithm is said to be adaptive to a certain parameter (of the problem) if it does not need a priori knowledge of such a parameter but performs competitively to those that know it. This dissertation presents our work on adaptive algorithms in following scenarios: 1. In the stochastic optimization setting, we only receive stochastic gradients and the level of noise in evaluating them greatly affects the convergence rate. Tuning is typically required when without prior knowledge of the noise scale in order to achieve the optimal rate. Considering this, we designed and analyzed noise-adaptive algorithms that can automatically ensure (near)-optimal rates under different noise scales without knowing it. 2. In training deep neural networks, the scales of gradient magnitudes in each coordinate can scatter across a very wide range unless normalization techniques, like BatchNorm, are employed. In such situations, algorithms not addressing this problem of gradient scales can behave very poor
    
[^56]: 多黑盒预言下的主动策略改进

    Active Policy Improvement from Multiple Black-box Oracles. (arXiv:2306.10259v1 [cs.LG])

    [http://arxiv.org/abs/2306.10259](http://arxiv.org/abs/2306.10259)

    本研究提出了MAPS和MAPS-SE两个算法，可在多黑盒预言情况下，采用模仿学习并主动选择和改进最优预言，显著提升了性能。

    

    强化学习在各种复杂领域中取得了重大进展，但是通过强化学习确定有效策略往往需要进行广泛的探索，而模仿学习旨在通过使用专家演示来指导探索，缓解这个问题。在真实世界情境下，人们通常只能接触到多个次优的黑盒预言，而不是单个最优的预言，这些预言不能在所有状态下普遍优于彼此，这给主动决定在哪种状态下使用哪种预言以及如何改进各自估计值函数提出了挑战。本文介绍了一个可行的解决方案，即MAPS和MAPS-SE算法。

    Reinforcement learning (RL) has made significant strides in various complex domains. However, identifying an effective policy via RL often necessitates extensive exploration. Imitation learning aims to mitigate this issue by using expert demonstrations to guide exploration. In real-world scenarios, one often has access to multiple suboptimal black-box experts, rather than a single optimal oracle. These experts do not universally outperform each other across all states, presenting a challenge in actively deciding which oracle to use and in which state. We introduce MAPS and MAPS-SE, a class of policy improvement algorithms that perform imitation learning from multiple suboptimal oracles. In particular, MAPS actively selects which of the oracles to imitate and improve their value function estimates, and MAPS-SE additionally leverages an active state exploration criterion to determine which states one should explore. We provide a comprehensive theoretical analysis and demonstrate that MAP
    
[^57]: 通过多元占位核函数学习高维非参数微分方程

    Learning High-Dimensional Nonparametric Differential Equations via Multivariate Occupation Kernel Functions. (arXiv:2306.10189v1 [stat.ML])

    [http://arxiv.org/abs/2306.10189](http://arxiv.org/abs/2306.10189)

    本论文提出了一种线性方法，通过多元占位核函数在高维状态空间中学习非参数ODE系统，可以解决显式公式按二次方缩放的问题。这种方法在高度非线性的数据和图像数据中都具有通用性。

    

    从$d$维状态空间中$n$个轨迹快照中学习非参数的常微分方程（ODE）系统需要学习$d$个函数。除非具有额外的系统属性知识，例如稀疏性和对称性，否则显式的公式按二次方缩放。在这项工作中，我们提出了一种使用向量值再生核希尔伯特空间提供的隐式公式学习的线性方法。通过将ODE重写为更弱的积分形式，我们随后进行最小化并推导出我们的学习算法。最小化问题的解向量场依赖于与解轨迹相关的多元占位核函数。我们通过对高度非线性的模拟和真实数据进行实验证实了我们的方法，其中$d$可能超过100。我们进一步通过从图像数据学习非参数一阶拟线性偏微分方程展示了所提出的方法的多样性。

    Learning a nonparametric system of ordinary differential equations (ODEs) from $n$ trajectory snapshots in a $d$-dimensional state space requires learning $d$ functions of $d$ variables. Explicit formulations scale quadratically in $d$ unless additional knowledge about system properties, such as sparsity and symmetries, is available. In this work, we propose a linear approach to learning using the implicit formulation provided by vector-valued Reproducing Kernel Hilbert Spaces. By rewriting the ODEs in a weaker integral form, which we subsequently minimize, we derive our learning algorithm. The minimization problem's solution for the vector field relies on multivariate occupation kernel functions associated with the solution trajectories. We validate our approach through experiments on highly nonlinear simulated and real data, where $d$ may exceed 100. We further demonstrate the versatility of the proposed method by learning a nonparametric first order quasilinear partial differential 
    
[^58]: 基于Samplet基 Pursuit 的核学习方法

    Samplet basis pursuit. (arXiv:2306.10180v1 [stat.ML])

    [http://arxiv.org/abs/2306.10180](http://arxiv.org/abs/2306.10180)

    本文提出了基于Samplet坐标下核学习的方法，其中引入l1正则化项可以增加系数的稀疏性。相比于单尺度基，Samplet基可以更好地表示更多类型的信号。作者提出了使用软阈值和半光滑牛顿法解决该问题的方法，并通过实验证明了其优越性。

    

    本文考虑了基于l1正则化的Samplet坐标下的核学习问题。在Samplet基的系数上，应用l1正则化项可以强制增加稀疏性。因此，我们称这种方法为Samplet基 Pursuit。Samplet基是波形类型的有符号测度，专门用于散乱数据。它们具有与小波相似的本地化、多分辨率分析和数据压缩性质。可以在Samplet基上稀疏地表示的信号类比单尺度基上能够表示稀疏的信号类别要大得多。特别地，仅用基函数映射的几个特征叠加即可表示的所有信号也可以在Samplet坐标下实现稀疏表示。我们提出了一种高效解决该问题的方法，将软阈值和半光滑牛顿法相结合，并将该方法与快速迭代收缩阈值算法进行了比较。实验结果表明了该方法在稀疏性和预测精度方面的优势。

    We consider kernel-based learning in samplet coordinates with l1-regularization. The application of an l1-regularization term enforces sparsity of the coefficients with respect to the samplet basis. Therefore, we call this approach samplet basis pursuit. Samplets are wavelet-type signed measures, which are tailored to scattered data. They provide similar properties as wavelets in terms of localization, multiresolution analysis, and data compression. The class of signals that can sparsely be represented in a samplet basis is considerably larger than the class of signals which exhibit a sparse representation in the single-scale basis. In particular, every signal that can be represented by the superposition of only a few features of the canonical feature map is also sparse in samplet coordinates. We propose the efficient solution of the problem under consideration by combining soft-shrinkage with the semi-smooth Newton method and compare the approach to the fast iterative shrinkage thresh
    
[^59]: 强化学习中的引导式表示

    Bootstrapped Representations in Reinforcement Learning. (arXiv:2306.10171v1 [cs.LG])

    [http://arxiv.org/abs/2306.10171](http://arxiv.org/abs/2306.10171)

    本研究对强化学习中引导式表示进行了理论分析，发现与蒙特卡罗和残差梯度算法学习的特征大多不同

    

    在强化学习中，状态表示是处理大型或连续状态空间的关键。尽管深度学习算法的承诺是自动构建适合解决任务的特征，但这样的表示可能不会从深度RL代理的端到端训练中出现。为了缓解这个问题，常常将辅助目标纳入学习过程中，并帮助形塑学习的状态表示。引导方法是如今此类附加预测的选择方法。然而，这些算法捕获的特征不清楚，也不知道它们与其他基于辅助任务的方法中的特征相关性如何。本文填补了这一空白，提供了时间差分学习(Sutton, 1988)学习的状态表示的理论刻画。令人惊讶的是，我们发现这种表示与通过蒙特卡罗和残差梯度算法学习的特征在大多数转移中是不同的。

    In reinforcement learning (RL), state representations are key to dealing with large or continuous state spaces. While one of the promises of deep learning algorithms is to automatically construct features well-tuned for the task they try to solve, such a representation might not emerge from end-to-end training of deep RL agents. To mitigate this issue, auxiliary objectives are often incorporated into the learning process and help shape the learnt state representation. Bootstrapping methods are today's method of choice to make these additional predictions. Yet, it is unclear which features these algorithms capture and how they relate to those from other auxiliary-task-based approaches. In this paper, we address this gap and provide a theoretical characterization of the state representation learnt by temporal difference learning (Sutton, 1988). Surprisingly, we find that this representation differs from the features learned by Monte Carlo and residual gradient algorithms for most transit
    
[^60]: 通过Wasserstein Barycenters实现多任务学习中的公平性

    Fairness in Multi-Task Learning via Wasserstein Barycenters. (arXiv:2306.10155v1 [stat.ML])

    [http://arxiv.org/abs/2306.10155](http://arxiv.org/abs/2306.10155)

    本文提出了一种方法，通过多元Wasserstein barycenters扩展`Strong Demographic Parity`的定义，实现多任务学习中的公平性，包括回归和二元分类任务。在实验中表现出良好的效果。

    

    算法公平性是机器学习中的一个已经成熟的领域，旨在减少数据中的偏差。最近的进展提出了各种方法来确保单变量环境下的公平性，即目标是去除单个任务的偏差。然而，将公平性扩展到多任务环境，其中使用共享表示来优化多个目标，仍未得到充分开发。为了填补这一差距，我们利用多元Wasserstein barycenters将\textit{Strong Demographic Parity}的定义扩展到多任务学习中。我们的方法为最优的公平多任务预测器提供了封闭式解，包括回归和二元分类任务。我们开发了一种数据驱动的估计过程，以寻找解决方案，并在合成和实际数据集上运行数字实验。经验结果突显了我们的后处理方法在促进公平决策方面的实际价值。

    Algorithmic Fairness is an established field in machine learning that aims to reduce biases in data. Recent advances have proposed various methods to ensure fairness in a univariate environment, where the goal is to de-bias a single task. However, extending fairness to a multi-task setting, where more than one objective is optimised using a shared representation, remains underexplored. To bridge this gap, we develop a method that extends the definition of \textit{Strong Demographic Parity} to multi-task learning using multi-marginal Wasserstein barycenters. Our approach provides a closed form solution for the optimal fair multi-task predictor including both regression and binary classification tasks. We develop a data-driven estimation procedure for the solution and run numerical experiments on both synthetic and real datasets. The empirical results highlight the practical value of our post-processing methodology in promoting fair decision-making.
    
[^61]: 递归割平面算法族用于具有受限内存的凸优化

    Memory-Constrained Algorithms for Convex Optimization via Recursive Cutting-Planes. (arXiv:2306.10096v1 [math.OC])

    [http://arxiv.org/abs/2306.10096](http://arxiv.org/abs/2306.10096)

    递归割平面算法族可在具有受限内存的情况下进行凸优化，并使用子多项式范围内预言机复杂度/内存的权衡。

    

    我们提出了一种递归割平面算法族，用于解决具有受限内存的可行性问题, 同时也可以用于一阶凸优化。该算法使用子多项式范围可提供预言机复杂度/内存权衡。

    We propose a family of recursive cutting-plane algorithms to solve feasibility problems with constrained memory, which can also be used for first-order convex optimization. Precisely, in order to find a point within a ball of radius $\epsilon$ with a separation oracle in dimension $d$ -- or to minimize $1$-Lipschitz convex functions to accuracy $\epsilon$ over the unit ball -- our algorithms use $\mathcal O(\frac{d^2}{p}\ln \frac{1}{\epsilon})$ bits of memory, and make $\mathcal O((C\frac{d}{p}\ln \frac{1}{\epsilon})^p)$ oracle calls, for some universal constant $C \geq 1$. The family is parametrized by $p\in[d]$ and provides an oracle-complexity/memory trade-off in the sub-polynomial regime $\ln\frac{1}{\epsilon}\gg\ln d$. While several works gave lower-bound trade-offs (impossibility results) -- we explicit here their dependence with $\ln\frac{1}{\epsilon}$, showing that these also hold in any sub-polynomial regime -- to the best of our knowledge this is the first class of algorithms
    
[^62]: 基于学徒学习的无人机联网路径规划与功率分配机制

    Joint Path planning and Power Allocation of a Cellular-Connected UAV using Apprenticeship Learning via Deep Inverse Reinforcement Learning. (arXiv:2306.10071v1 [cs.LG])

    [http://arxiv.org/abs/2306.10071](http://arxiv.org/abs/2306.10071)

    本论文通过学徒学习方法，采用基于Q学习和深度强化学习（DRL）的逆强化学习 (IRL)，解决了一个稀疏郊区环境中，无人机的联网路径规划与功率分配的干扰感知问题，优于传统的行为克隆（BC）调节学习技术。

    

    本文研究了在稀疏郊区环境中，一个联网的无人机通过沿着信号覆盖单元移动，从出发点飞向目的地以保证服务质量（QoS）的干扰感知联网路径规划与功率分配机制。专家知识被用来体验情景并为智能体（即，无人机）培训定义所需的行为，为此，一种基于逆强化学习（IRL）的学徒学习方法被采用，并通过Q学习和深度强化学习（DRL）进行比较性能，并将其与行为克隆（BC）调节学习技术的学习进行比较。

    This paper investigates an interference-aware joint path planning and power allocation mechanism for a cellular-connected unmanned aerial vehicle (UAV) in a sparse suburban environment. The UAV's goal is to fly from an initial point and reach a destination point by moving along the cells to guarantee the required quality of service (QoS). In particular, the UAV aims to maximize its uplink throughput and minimize the level of interference to the ground user equipment (UEs) connected to the neighbor cellular BSs, considering the shortest path and flight resource limitation. Expert knowledge is used to experience the scenario and define the desired behavior for the sake of the agent (i.e., UAV) training. To solve the problem, an apprenticeship learning method is utilized via inverse reinforcement learning (IRL) based on both Q-learning and deep reinforcement learning (DRL). The performance of this method is compared to learning from a demonstration technique called behavioral cloning (BC)
    
[^63]: 用一致性检查评估超人模型

    Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v1 [cs.LG])

    [http://arxiv.org/abs/2306.09983](http://arxiv.org/abs/2306.09983)

    本文提出了一个用一致性检查评估超人模型的框架，可以发现决策制定中的逻辑不一致性，即使对于超人模型的决策正确性可能是不可能评估的情况。

    

    如果机器学习模型在各种推理或决策任务上实现了超人能力，那么我们该如何评估这些模型，考虑到人类代理会产生偏差? 在本文中，我们提出了一个用一致性检查评估超人模型的框架。我们的前提是，虽然评估超人决策的正确性可能是不可能的，但是如果模型的决策未能满足某些逻辑上、可解释的规则，我们仍然可以发现错误。我们将我们的框架实现在三个任务上，这些任务的决策正确性由于超人模型能力或其他缺乏基本事实而难以评估：评估国际象棋局面、预测未来事件和作出法律判断。我们表明，无论模型在这些任务上的表现如何(可能是超人的)，我们都能发现决策制定中的逻辑不一致性。例如：国际象棋引擎给出对局中棋子相对估值的不同排列。

    If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model's decisions fail to satisfy certain logical, human-interpretable rules. We instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model's (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to 
    
[^64]: Fit Like You Sample: 从快速混合马尔可夫链中实现样本高效的广义得分匹配

    Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains. (arXiv:2306.09332v1 [cs.DS])

    [http://arxiv.org/abs/2306.09332](http://arxiv.org/abs/2306.09332)

    本文提出了一种从快速混合马尔可夫链中实现样本高效的广义得分匹配方法，解决了得分匹配算法在具有较差等周性质的分布上的统计代价问题。

    

    得分匹配是一种学习概率分布的方法，其参数化为比例常数（例如，能量基模型）。其思想是拟合分布的得分，而不是似然函数，从而避免评估比例常数的需求。虽然这具有明显的算法优势，但统计代价可能很高：Koehler等人的最新工作表明，对于具有较差等周性质（较大的Poincare或对数Sobolev常数）的分布，得分匹配的统计效率明显低于极大似然估计。然而，许多自然实际的分布，例如一维中的两个高斯分布混合物等多峰分布，具有较差的Poincaré常数。在本文中，我们展示了任意马尔可夫过程的混合时间与试图拟合$\frac{\mathcal{O} p}{p}$的广义得分匹配损失之间的密切关系。如果$\mathcal{L}$的特征向量不依赖于$p$，我们展示了一种基于随机梯度下降的算法，从而实现的样本高效广义得分匹配。

    Score matching is an approach to learning probability distributions parametrized up to a constant of proportionality (e.g. Energy-Based Models). The idea is to fit the score of the distribution, rather than the likelihood, thus avoiding the need to evaluate the constant of proportionality. While there's a clear algorithmic benefit, the statistical "cost'' can be steep: recent work by Koehler et al. 2022 showed that for distributions that have poor isoperimetric properties (a large Poincar\'e or log-Sobolev constant), score matching is substantially statistically less efficient than maximum likelihood. However, many natural realistic distributions, e.g. multimodal distributions as simple as a mixture of two Gaussians in one dimension -- have a poor Poincar\'e constant.  In this paper, we show a close connection between the mixing time of an arbitrary Markov process with generator $\mathcal{L}$ and a generalized score matching loss that tries to fit $\frac{\mathcal{O} p}{p}$. If $\mathca
    
[^65]: 图神经网络的局部到全局视角

    Local-to-global Perspectives on Graph Neural Networks. (arXiv:2306.06547v1 [cs.LG])

    [http://arxiv.org/abs/2306.06547](http://arxiv.org/abs/2306.06547)

    本文提出了局部到全局的图神经网络模型，包括不变图网络、局部信息传递神经网络和全局图变换器，并研究其收敛性质和在图粗化中的应用。

    

    本文提出了一种对于图神经网络（GNN）的局部到全局的视角，其中分为局部信息传递神经网络（MPNN）和全局图变换器。本文提出了三个工作：1）研究一种全局 GNN，不变图网络的收敛性质，2）连接局部 MPNN 和全局图变换器，3）在全局建模中，使用局部 MPNN 进行图粗化，这是一个常见的子程序。

    We present a local-to-global perspective on graph neural networks (GNN), which are categorized as local Message Passing Neural Networks (MPNN) and global Graph Transformer. We present three pieces of work: 1) study the convergence property of a type of global GNN, Invariant Graph Networks, 2) connect the local MPNN and global Graph Transformer, and 3) use local MPNN for graph coarsening, a common subroutine used in global modeling.
    
[^66]: 用于液压状态监测系统异常检测的半监督学习比较研究

    Comparative Study on Semi-supervised Learning Applied for Anomaly Detection in Hydraulic Condition Monitoring System. (arXiv:2306.02709v1 [cs.LG])

    [http://arxiv.org/abs/2306.02709](http://arxiv.org/abs/2306.02709)

    本研究比较了不同类型的半监督学习方法在液压状态监测系统中用于异常检测。深度学习模型表现最好，而集成模型可以进一步提高检测性能。

    

    基于状态的维护在液压系统中变得越来越重要。然而，这些系统的异常检测仍然具有挑战性，特别是由于异常数据很少，标记这些数据是费时费力甚至危险的。因此，建议使用无监督或半监督方法，特别是对于只有少量标签可用的情况下利用无监督学习作为特征提取机制来辅助监督学习的半监督学习方法。本研究系统地比较了在液压状态监测系统中应用的半监督学习方法用于异常检测。首先，进行了深入的数据分析和特征学习，以了解开源的液压状态监测数据集。然后，实施和评估了各种方法，包括传统的独立半监督学习模型（例如，一类支持向量机、鲁棒协方差）、集成模型（例如，孤立森林）和基于深度学习的模型（例如，自动编码器、图卷积网络）。结果表明，深度学习模型优于传统模型，而集成模型可以进一步提高检测性能。

    Condition-based maintenance is becoming increasingly important in hydraulic systems. However, anomaly detection for these systems remains challenging, especially since that anomalous data is scarce and labeling such data is tedious and even dangerous. Therefore, it is advisable to make use of unsupervised or semi-supervised methods, especially for semi-supervised learning which utilizes unsupervised learning as a feature extraction mechanism to aid the supervised part when only a small number of labels are available. This study systematically compares semi-supervised learning methods applied for anomaly detection in hydraulic condition monitoring systems. Firstly, thorough data analysis and feature learning were carried out to understand the open-sourced hydraulic condition monitoring dataset. Then, various methods were implemented and evaluated including traditional stand-alone semi-supervised learning models (e.g., one-class SVM, Robust Covariance), ensemble models (e.g., Isolation F
    
[^67]: 双重稳健自我训练

    Doubly Robust Self-Training. (arXiv:2306.00265v1 [cs.LG])

    [http://arxiv.org/abs/2306.00265](http://arxiv.org/abs/2306.00265)

    本文提出了一种双重稳健自我训练算法，可以在伪标签不准确和完全准确时分别采取不同的训练策略，实现有效的半监督学习。实验结果表明，该算法在ImageNet和nuScenes数据集上均比标准自我训练总结更好。

    

    自我训练是解决半监督学习问题的一种重要技术。它通过生成伪标签并将其与有限的标记数据集结合使用进行训练，从而利用无标签数据。自我训练的有效性在很大程度上依赖于这些伪标签的准确性。本文引入了双重稳健自我训练，这是一种新颖的半监督算法，可以保证在两个极端之间平衡。当伪标签完全不正确时，我们的方法将被减少到仅使用标记数据进行训练。相反，当伪标签完全准确时，我们的方法将变成利用所有伪标签数据和标记数据进行训练的过程，从而增加有效的样本量。通过在ImageNet图像分类和nuScenes自主驾驶数据集上的实证评估，我们证明了双重稳健损失优于标准自我训练基线的优越性。

    Self-training is an important technique for solving semi-supervised learning problems. It leverages unlabeled data by generating pseudo-labels and combining them with a limited labeled dataset for training. The effectiveness of self-training heavily relies on the accuracy of these pseudo-labels. In this paper, we introduce doubly robust self-training, a novel semi-supervised algorithm that provably balances between two extremes. When the pseudo-labels are entirely incorrect, our method reduces to a training process solely using labeled data. Conversely, when the pseudo-labels are completely accurate, our method transforms into a training process utilizing all pseudo-labeled data and labeled data, thus increasing the effective sample size. Through empirical evaluations on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection, we demonstrate the superiority of the doubly robust loss over the standard self-training baseline.
    
[^68]: 通过同簇预言机的容错精确查询学习有限集合划分

    Error-Tolerant Exact Query Learning of Finite Set Partitions with Same-Cluster Oracle. (arXiv:2305.13402v1 [cs.DS])

    [http://arxiv.org/abs/2305.13402](http://arxiv.org/abs/2305.13402)

    本文提出了一个新问题：如何通过同簇预言机在存在有限对抗错误时积极学习完全恢复划分。我们建立了解析框架并证明了最坏情况下查询复杂度的上下界，并研究了适应性和查询复杂度之间的关系。

    

    本文研究了当存在有限的对抗错误时，仅通过同簇预言机来积极学习完全恢复划分的问题。首先突出了学习划分和相关聚类之间的新颖联系。然后利用这种联系为这个问题建立了一个Rényi-Ulam样式的解析框架，并证明了最坏情况下查询复杂度的上下界。此外，我们还限制了相关随机算法的期望性能。最后，我们研究了适应性和查询复杂度在该问题和相关变体中之间的关系。

    This paper initiates the study of active learning for exact recovery of partitions exclusively through access to a same-cluster oracle in the presence of bounded adversarial error. We first highlight a novel connection between learning partitions and correlation clustering. Then we use this connection to build a R\'enyi-Ulam style analytical framework for this problem, and prove upper and lower bounds on its worst-case query complexity. Further, we bound the expected performance of a relevant randomized algorithm. Finally, we study the relationship between adaptivity and query complexity for this problem and related variants.
    
[^69]: 关于一般函数逼近下的均场强化学习的统计效率

    On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])

    [http://arxiv.org/abs/2305.11283](http://arxiv.org/abs/2305.11283)

    本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。

    

    本文研究了一般函数逼近下的均场控制（MFC）和均场博弈（MFG）中强化学习的统计效率。引入了一种称为Mean-Field Model-Based Eluder Dimension (MBED)的新概念，包含了一系列丰富的均场强化学习问题。此外，我们提出了基于乐观最大似然估计的算法，可以返回一个$\epsilon$优的策略，适用于MFC或$\epsilon$纳什均衡策略适用于MFG，样本复杂度多项式与相关参数无关，与状态、动作和代理数量无关。值得注意的是，我们的结果仅对转移动力学具有Lipschitz连续性的假设，避免了以前的强结构假设。最后，在tabular设置下，假设有一个生成模型，我们建立了一个指数级的下界支持MFC设置，同时提供了一种新颖的样本高效的模型消除算法以逼近最优策略。

    In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
    
[^70]: 基于核的联合独立性检验用于多元、平稳和非平稳时间序列

    Kernel-based Joint Independence Tests for Multivariate Stationary and Nonstationary Time-Series. (arXiv:2305.08529v1 [stat.ME])

    [http://arxiv.org/abs/2305.08529](http://arxiv.org/abs/2305.08529)

    本文提出了一种基于核的多元时间序列联合独立性统计检验方法，可以用于平稳和非平稳随机过程，通过针对单个和多个实现时间序列的重采样技术，可以稳健地发现重要的高阶依赖关系。

    

    捕捉相互连接系统的时间演变的多元时间序列数据在各个领域中普遍存在。了解共同观察变量之间的复杂关系和潜在依赖关系是准确统计建模和分析此类系统至关重要。本文通过将 d 变量 Hilbert-Schmidt 独立性准则（dHSIC）扩展到包含平稳和非平稳随机过程，从而允许更广泛的实际应用，提出了基于核的多元时间序列联合独立性统计检验。通过利用针对单个和多个实现时间序列量身定制的重采样技术，我们展示了该方法如何在合成示例（包括频率混合数据）以及实际气候和社会经济数据中稳健地发现重要的高阶依赖关系。我们的方法为分析复杂高维时间序列数据集增加了数学工具箱。

    Multivariate time-series data that capture the temporal evolution of interconnected systems are ubiquitous in diverse areas. Understanding the complex relationships and potential dependencies among co-observed variables is crucial for the accurate statistical modelling and analysis of such systems. Here, we introduce kernel-based statistical tests of joint independence in multivariate time-series by extending the d-variable Hilbert-Schmidt independence criterion (dHSIC) to encompass both stationary and nonstationary random processes, thus allowing broader real-world applications. By leveraging resampling techniques tailored for both single- and multiple-realization time series, we show how the method robustly uncovers significant higher-order dependencies in synthetic examples, including frequency mixing data, as well as real-world climate and socioeconomic data. Our method adds to the mathematical toolbox for the analysis of complex high-dimensional time-series datasets.
    
[^71]: 正交多项式逼近和扩展动态模态分解在混沌中的应用

    Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos. (arXiv:2305.08074v1 [math.NA])

    [http://arxiv.org/abs/2305.08074](http://arxiv.org/abs/2305.08074)

    本文在简单的混沌映射上证明了扩展动态模态分解（EDMD）对于多项式可观测字典有指数效率，从而有效处理了混沌动力学中的正则函数问题，并展示了在这种情况下使用EDMD产生的预测和Koopman谱数据收敛至物理上有意义的极限。

    

    扩展动态模态分解（EDMD）是一种数据驱动的工具，用于动态的预测和模型简化，在物理科学领域得到广泛应用。虽然这种方法在概念上很简单，但在确定性混沌中，它的性质或者它的收敛性还不清楚。特别是，EDMD的最小二乘逼近如何处理需要描绘混沌动力学含义的正则函数的类别，这也是不清楚的。本文在分析上简单的一个圆环展开映射的最简单例子上，发展了关于EDMD的一般的、严格的理论。证明了一个新的关于在单位圆上的正交多项式（OPUC）的理论结果，我们证明在无限数据极限时，针对多项式的可观测字典的最小二乘投影具有指数效率。因此，我们展示了在这种情况下使用EDMD产生的预测和Koopman谱数据收敛到物理上有意义的极限的指数速率。

    Extended Dynamic Mode Decomposition (EDMD) is a data-driven tool for forecasting and model reduction of dynamics, which has been extensively taken up in the physical sciences. While the method is conceptually simple, in deterministic chaos it is unclear what its properties are or even what it converges to. In particular, it is not clear how EDMD's least-squares approximation treats the classes of regular functions needed to make sense of chaotic dynamics.  In this paper we develop a general, rigorous theory of EDMD on the simplest examples of chaotic maps: analytic expanding maps of the circle. Proving a new result in the theory of orthogonal polynomials on the unit circle (OPUC), we show that in the infinite-data limit, the least-squares projection is exponentially efficient for polynomial observable dictionaries. As a result, we show that the forecasts and Koopman spectral data produced using EDMD in this setting converge to the physically meaningful limits, at an exponential rate.  
    
[^72]: 面向马尔可夫数据的流式PCA算法

    Streaming PCA for Markovian Data. (arXiv:2305.02456v1 [math.ST])

    [http://arxiv.org/abs/2305.02456](http://arxiv.org/abs/2305.02456)

    本文提出了一种面向马尔可夫数据采样的流式PCA算法，并获得了该算法在整个数据集上的第一个尖锐率，提高了算法的效率。同时，本文提出的自适应方案在模拟和真实数据示例中表现良好。

    

    自从Oja在1982年的经典论文中首次提出以来，Oja算法已成为流式主成分分析(PCA)的一种常用方法。本文研究了流式PCA问题，其中数据点从一个不可约、无周期、可逆的马尔可夫链中采样。我们的目标是估计平稳分布的未知协方差矩阵的前一个特征向量。这种情况适用于只能从马尔可夫链蒙特卡罗(MCMC)类型的算法中采样数据，并且目标是对该链的平稳分布的参数进行推断的情况。现有文献中大多数Oja算法的收敛保证都假定数据点是IID采样的。对于具有马尔可夫依赖关系的数据流，人们通常对数据进行下采样以获得"几乎"独立的数据流。在本文中，我们获得了Oja算法在整个数据集上的第一个尖锐率，其中去掉了$n$的对数依赖性，结果是$\mathcal{O}(n^{-1})$的速率。我们还提出了一种自适应方案来调整算法的步长，它在模拟和真实数据示例中都表现更好。

    Since its inception in Erikki Oja's seminal paper in 1982, Oja's algorithm has become an established method for streaming principle component analysis (PCA). We study the problem of streaming PCA, where the data-points are sampled from an irreducible, aperiodic, and reversible Markov chain. Our goal is to estimate the top eigenvector of the unknown covariance matrix of the stationary distribution. This setting has implications in situations where data can only be sampled from a Markov Chain Monte Carlo (MCMC) type algorithm, and the goal is to do inference for parameters of the stationary distribution of this chain. Most convergence guarantees for Oja's algorithm in the literature assume that the data-points are sampled IID. For data streams with Markovian dependence, one typically downsamples the data to get a "nearly" independent data stream. In this paper, we obtain the first sharp rate for Oja's algorithm on the entire data, where we remove the logarithmic dependence on $n$ resulti
    
[^73]: 交叉熵损失函数：理论分析与应用

    Cross-Entropy Loss Functions: Theoretical Analysis and Applications. (arXiv:2304.07288v1 [cs.LG])

    [http://arxiv.org/abs/2304.07288](http://arxiv.org/abs/2304.07288)

    本文对交叉熵、广义交叉熵、均方误差等一大类损失函数进行了理论分析，并提出了具有优势的双交叉熵损失函数，特别适用于存在标签噪声或类别不平衡的情况。

    

    交叉熵是广泛应用的损失函数。当使用softmax函数时，它与神经网络输出应用于逻辑回归损失函数相符。但是，使用交叉熵作为代理损失函数时，我们能依靠什么保证呢？我们提出了对广泛的损失函数家族进行理论分析，包括交叉熵（或逻辑损失）、广义交叉熵、均方误差和其他交叉熵类函数。我们给出了这些损失函数的第一个$H$-连续性界限。这些都是非渐进保证，以估计代理损失的估计误差为上限，用于特定的假设集$H$。我们进一步展示了这些边界的紧密程度。这些边界取决于称为可最小化间隙的量，这些间隙只取决于损失函数和假设集。为了使它们更具体化，我们对复杂和损失函数的这些间隙进行了具体分析。我们还引入了一种新的损失函数，称为双交叉熵损失，它基于两个交叉熵损失的组合。我们表明，它可以优于标准交叉熵损失，特别是在存在标签噪声或类别不平衡的情况下。

    Cross-entropy is a widely used loss function in applications. It coincides with the logistic loss applied to the outputs of a neural network, when the softmax is used. But, what guarantees can we rely on when using cross-entropy as a surrogate loss? We present a theoretical analysis of a broad family of losses, comp-sum losses, that includes cross-entropy (or logistic loss), generalized cross-entropy, the mean absolute error and other loss cross-entropy-like functions. We give the first $H$-consistency bounds for these loss functions. These are non-asymptotic guarantees that upper bound the zero-one loss estimation error in terms of the estimation error of a surrogate loss, for the specific hypothesis set $H$ used. We further show that our bounds are tight. These bounds depend on quantities called minimizability gaps, which only depend on the loss function and the hypothesis set. To make them more explicit, we give a specific analysis of these gaps for comp-sum losses. We also introduc
    
[^74]: 基于L2，0基数惩罚的不均匀图趋势过滤。

    Inhomogeneous graph trend filtering via a l2,0 cardinality penalty. (arXiv:2304.05223v1 [cs.LG])

    [http://arxiv.org/abs/2304.05223](http://arxiv.org/abs/2304.05223)

    本文提出了一种基于L2，0基数惩罚的图趋势过滤（GTF）模型，可同时进行k-means聚类和基于图的最小割，以估计在节点之间具有不均匀平滑水平的分段平滑图信号，并在降噪、支持恢复和半监督分类任务上表现更好，比现有方法更高效地处理大型数据集。

    

    我们研究了在图上估计分段平滑信号的方法，并提出了一种$\ell_{2,0}$-范数惩罚图趋势过滤（GTF）模型，以估计在节点之间具有不均匀平滑水平的分段平滑图信号。我们证明了所提出的GTF模型同时是基于节点上的信号的k-means聚类和基于图的最小割，其中聚类和割共享相同的分配矩阵。我们提出了两种方法来解决所提出的GTF模型：一种是基于谱分解的方法，另一种是基于模拟退火的方法。在合成和现实数据集的实验中，我们展示了所提出的GTF模型在降噪、支持恢复和半监督分类任务上表现更好，且比现有方法更高效地解决了大型数据集的问题。

    We study estimation of piecewise smooth signals over a graph. We propose a $\ell_{2,0}$-norm penalized Graph Trend Filtering (GTF) model to estimate piecewise smooth graph signals that exhibits inhomogeneous levels of smoothness across the nodes. We prove that the proposed GTF model is simultaneously a k-means clustering on the signal over the nodes and a minimum graph cut on the edges of the graph, where the clustering and the cut share the same assignment matrix. We propose two methods to solve the proposed GTF model: a spectral decomposition method and a method based on simulated annealing. In the experiment on synthetic and real-world datasets, we show that the proposed GTF model has a better performances compared with existing approaches on the tasks of denoising, support recovery and semi-supervised classification. We also show that the proposed GTF model can be solved more efficiently than existing models for the dataset with a large edge set.
    
[^75]: 图卡尔曼滤波器

    Graph Kalman Filters. (arXiv:2303.12021v1 [cs.LG])

    [http://arxiv.org/abs/2303.12021](http://arxiv.org/abs/2303.12021)

    本文首次将卡尔曼和扩展卡尔曼滤波器推广到图形上，使得它可以适用于输出是向量或标量的情况，并且可以学习未知的状态转移和读取函数。

    

    众所周知，卡尔曼滤波器通过使用状态空间表示来模拟动态系统，下一个状态的更新以及与新观察到的系统输出相关的信息来控制其不确定性。本文首次将卡尔曼和扩展卡尔曼滤波器推广到离散时间的设置下，其中输入、状态和输出均表示为带属性的图形，其拓扑和属性可以随时间变化。此设置使得我们可以将框架适应于输出是向量或标量的情况（节点/图级任务）。在所提出的理论框架内，未知的状态转移和读取函数与下游预测任务一起端到端学习。

    The well-known Kalman filters model dynamical systems by relying on state-space representations with the next state updated, and its uncertainty controlled, by fresh information associated with newly observed system outputs. This paper generalizes, for the first time in the literature, Kalman and extended Kalman filters to discrete-time settings where inputs, states, and outputs are represented as attributed graphs whose topology and attributes can change with time. The setup allows us to adapt the framework to cases where the output is a vector or a scalar too (node/graph level tasks). Within the proposed theoretical framework, the unknown state-transition and the readout functions are learned end-to-end along with the downstream prediction task.
    
[^76]: 通过Wasserstein梯度流进行变分高斯滤波

    Variational Gaussian filtering via Wasserstein gradient flows. (arXiv:2303.06398v2 [stat.CO] UPDATED)

    [http://arxiv.org/abs/2303.06398](http://arxiv.org/abs/2303.06398)

    本论文提出了一种新方法通过Wasserstein梯度流进行变分高斯滤波，竞争力突出。

    

    我们提出了一种新方法来近似高斯和高斯混合滤波。我们的方法依赖于通过梯度流表示的变分近似。梯度流是基于在概率分布空间上配备了Wasserstein度量的Kullback-Leibler差异最小化导出的。我们概述了一般方法，并展示了它在后验表示和参数估计上的竞争力，针对高斯近似通常失败的两种状态空间模型：具有乘法噪声和多峰态分布。

    We present a novel approach to approximate Gaussian and mixture-of-Gaussians filtering. Our method relies on a variational approximation via a gradient-flow representation. The gradient flow is derived from a Kullback--Leibler discrepancy minimization on the space of probability distributions equipped with the Wasserstein metric. We outline the general method and show its competitiveness in posterior representation and parameter estimation on two state-space models for which Gaussian approximations typically fail: systems with multiplicative noise and multi-modal state distributions.
    
[^77]: 高斯过程在赫赫尔姆霍兹分解中的应用：一种更流体的海洋气流模型

    Gaussian processes at the Helm(holtz): A more fluid model for ocean currents. (arXiv:2302.10364v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2302.10364](http://arxiv.org/abs/2302.10364)

    该论文提出了一种更符合已知电流物理特性的模型，在通过Helmholtz分解获得的向量场的发散和无旋分量上使用高斯过程来预测海流。证明了这种方法在模拟数据和真实浮标数据方面都比之前的方法更有效。

    

    海洋学家有兴趣预测海流和基于浮标速度的稀疏观测数据来识别当前矢量场中的发散性。高斯过程(GPs)在空间位置上充当连续但高度非线性功能的速度提供了一种吸引人的模型。但我们表明，将具有标准平稳核的GP直接应用于浮标数据可能在当前预测和发散性识别方面遇到困难—由于一些物理上不切实际的先验假设。为了更好地反映已知的电流物理特性，我们建议将标准平稳核放在通过Helmholtz分解获得的向量场的发散和无旋分量上。我们表明，由于该分解仅通过混合偏导数与原始向量场相关，因此我们仍然可以在原始数据给定的情况下进行推理，并且只需要额外进行少数计算。我们通过模拟数据和真实浮标数据证明了这种螺旋GP的有效性，从而在均方预测误差方面优于先前的方法。

    Oceanographers are interested in predicting ocean currents and identifying divergences in a current vector field based on sparse observations of buoy velocities. Since we expect current velocity to be a continuous but highly non-linear function of spatial location, Gaussian processes (GPs) offer an attractive model. But we show that applying a GP with a standard stationary kernel directly to buoy data can struggle at both current prediction and divergence identification -- due to some physically unrealistic prior assumptions. To better reflect known physical properties of currents, we propose to instead put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition. We show that, because this decomposition relates to the original vector field just via mixed partial derivatives, we can still perform inference given the original data with only a small constant multiple of additional computational expense. We illust
    
[^78]: JANA：复杂贝叶斯模型的联合分摊近似神经网络

    JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models. (arXiv:2302.09125v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09125](http://arxiv.org/abs/2302.09125)

    本文提出了 JANA 方法，用于处理复杂贝叶斯模型的近似计算。通过端到端训练三个神经网络来实现分摊的近似后验和似然，为贝叶斯工作流程提供了一种新的途径。此方法在多种模拟模型中进行了基准测试，并提出了一种联合校准诊断方法。

    

    本文提出了“联合分摊神经网络近似”（JANA）方法，用于处理贝叶斯代理建模和基于模拟的推理中出现的难以计算的似然函数和后验密度。我们以端到端的方式训练三个相互补充的神经网络：1）一个总结网络，将个别数据点、集合或时间序列压缩成信息嵌入向量；2）一个后验网络，学习分摊的近似后验；3）一个似然网络，学习分摊的近似似然。它们的交互为分摊边缘似然和后验预测估计提供了新的途径，这是贝叶斯工作流程的两个重要组成部分，常常对于标准方法来说太昂贵了。我们在各种模拟模型中对JANA的保真度进行了基准测试，与最先进的贝叶斯方法进行了比较，并提出了一种强大而可解释的联合校准诊断方法。此外，我们研究了循环似然网络模拟复杂模型的能力。

    This work proposes ''jointly amortized neural approximation'' (JANA) of intractable likelihood functions and posterior densities arising in Bayesian surrogate modeling and simulation-based inference. We train three complementary networks in an end-to-end fashion: 1) a summary network to compress individual data points, sets, or time series into informative embedding vectors; 2) a posterior network to learn an amortized approximate posterior; and 3) a likelihood network to learn an amortized approximate likelihood. Their interaction opens a new route to amortized marginal likelihood and posterior predictive estimation -- two important ingredients of Bayesian workflows that are often too expensive for standard methods. We benchmark the fidelity of JANA on a variety of simulation models against state-of-the-art Bayesian methods and propose a powerful and interpretable diagnostic for joint calibration. In addition, we investigate the ability of recurrent likelihood networks to emulate comp
    
[^79]: 图神经网络中的泛化：基于图扩散的改进PAC-Bayesian界限。

    Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion. (arXiv:2302.04451v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04451](http://arxiv.org/abs/2302.04451)

    本文提出了用特征扩散矩阵的最大奇异值来缩放泛化界限的方法，并用Hessians来衡量图神经网络对噪声扰动的稳定性。实验证明，这些方法可以有效减小泛化界限，更好地解决了实际图形问题。

    

    图神经网络是图预测任务中广泛使用的工具。由其实证表现所驱动，先前的研究开发了图神经网络的泛化界限，它们根据最大度数在图结构方面进行缩放。在本文中，我们提出了泛化界限，这些界限根据图神经网络特征扩散矩阵的最大奇异值进行缩放。对于实际图形，这些界限的数值要比先前的界限小得多。我们还构建了一个相符的泛化差距下限，其渐近地匹配了我们的上限界限。为了实现这些结果，我们分析了一个统一的模型，其中包括先前的设置（即卷积和消息传递网络）和新的设置（即图同构网络）。我们的关键思想是利用Hessians来衡量图神经网络对于噪声扰动的稳定性。实验证明，基于Hessian的测量与观察到的泛化差距相关。

    Graph neural networks are widely used tools for graph prediction tasks. Motivated by their empirical performance, prior works have developed generalization bounds for graph neural networks, which scale with graph structures in terms of the maximum degree. In this paper, we present generalization bounds that instead scale with the largest singular value of the graph neural network's feature diffusion matrix. These bounds are numerically much smaller than prior bounds for real-world graphs. We also construct a lower bound of the generalization gap that matches our upper bound asymptotically. To achieve these results, we analyze a unified model that includes prior works' settings (i.e., convolutional and message-passing networks) and new settings (i.e., graph isomorphism networks). Our key idea is to measure the stability of graph neural networks against noise perturbations using Hessians. Empirically, we find that Hessian-based measurements correlate with the observed generalization gaps
    
[^80]: 向大核模型迈进

    Toward Large Kernel Models. (arXiv:2302.02605v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02605](http://arxiv.org/abs/2302.02605)

    本文提出了一种构建大规模通用核模型的方法，这解决了传统核机器中模型大小与数据大小相互耦合的问题，使其能够在大数据集上进行训练。

    

    最近的研究表明，与深度神经网络（DNN）相比，核机器在小数据集上的表现通常可以达到或超过DNN。核机器的兴趣受到其在某些情况下等效于宽神经网络的发现的推动。然而，DNN的一个关键特征是它们能够独立地扩展模型大小和训练数据量，而在传统的核机器中，模型大小与数据大小是相互耦合的。由于这种耦合，将核机器扩展到大数据是计算上具有挑战性的。在本文中，我们提供了一种构建大规模通用核模型的方法，这是核机器的一般化，通过解耦模型和数据，允许在大数据集上进行训练。具体地，我们引入了基于投影双重预处理SGD的EigenPro 3.0算法，并展示了使用现有核方法不可能实现的模型和数据规模的扩展。

    Recent studies indicate that kernel machines can often perform similarly or better than deep neural networks (DNNs) on small datasets. The interest in kernel machines has been additionally bolstered by the discovery of their equivalence to wide neural networks in certain regimes. However, a key feature of DNNs is their ability to scale the model size and training data size independently, whereas in traditional kernel machines model size is tied to data size. Because of this coupling, scaling kernel machines to large data has been computationally challenging. In this paper, we provide a way forward for constructing large-scale general kernel models, which are a generalization of kernel machines that decouples the model and data, allowing training on large datasets. Specifically, we introduce EigenPro 3.0, an algorithm based on projected dual preconditioned SGD and show scaling to model and data sizes which have not been possible with existing kernel methods.
    
[^81]: 多维概念发现(MCD): 一个具有完整性保证的统一框架

    Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees. (arXiv:2301.11911v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11911](http://arxiv.org/abs/2301.11911)

    提出了多维概念发现(MCD)方法，它满足概念层面上的完整性关系，不需要加强概念可解释性或重新训练模型部分，并提供概念激活图分析工具

    

    完整性公理使得后续XAI方法的解释仅对模型在单个决策上有效。为了可信地应用XAI，特别是对于高风险的决策，需要更全球的模型理解。最近，已经提出了基于概念的方法，但这些方法不能保证与实际的模型推理相结合。为了解决这个问题，我们提出了多维概念发现(MCD)，作为之前方法的扩展，满足概念层面上的完整性关系。我们的方法从通用的线性子空间作为概念开始，并不需要加强概念可解释性或重新训练模型部分。我们提出了稀疏子空间聚类来发现改进的概念，充分利用了多维子空间的潜能。MCD提供了两种概念在输入空间中的互补分析工具：(1)概念激活图，显示概念表达的位置

    The completeness axiom renders the explanation of a post-hoc XAI method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. Recently, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is express
    
[^82]: 针对不规则采样时间序列的神经连续离散状态空间模型

    Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series. (arXiv:2301.11308v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11308](http://arxiv.org/abs/2301.11308)

    本研究提出了一个用于不规则采样时间序列的神经连续离散状态空间模型，其采用辅助变量来区分识别和动态，从而实现了准确的贝叶斯推理和改进的性能。

    

    学习真实世界动态现象（如气候、生物学等）的准确预测模型仍然是一个具有挑战性的任务。一项关键问题是，自然和人工过程生成的数据往往包含不规则采样和/或缺失的时间序列。本研究提出神经连续离散状态空间模型（NCDSSM），用于通过离散时间观测对时间序列进行连续时间建模。NCDSSM采用辅助变量来区分识别和动态，因此仅需要对辅助变量进行摊销推理。利用连续-离散滤波理论的技术，我们展示了如何对动态状态进行准确的贝叶斯推断。我们提出了三种灵活的潜在动态参数化方法和一种在推断期间对动态状态进行边缘化的高效培训目标。在各个领域的多个基准数据集上的实证结果表明了改进了的性能。

    Learning accurate predictive models of real-world dynamic phenomena (e.g., climate, biological) remains a challenging task. One key issue is that the data generated by both natural and artificial processes often comprise time series that are irregularly sampled and/or contain missing observations. In this work, we propose the Neural Continuous-Discrete State Space Model (NCDSSM) for continuous-time modeling of time series through discrete-time observations. NCDSSM employs auxiliary variables to disentangle recognition from dynamics, thus requiring amortized inference only for the auxiliary variables. Leveraging techniques from continuous-discrete filtering theory, we demonstrate how to perform accurate Bayesian inference for the dynamic states. We propose three flexible parameterizations of the latent dynamics and an efficient training objective that marginalizes the dynamic states during inference. Empirical results on multiple benchmark datasets across various domains show improved i
    
[^83]: 水母如何表征交替群等变神经网络

    How Jellyfish Characterise Alternating Group Equivariant Neural Networks. (arXiv:2301.10152v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10152](http://arxiv.org/abs/2301.10152)

    该论文提供了交替群($A_n$)等变神经网络的完整表征，其中描述了可学习的、线性的、$A_n$等变层函数的矩阵基，在神经网络构建中具有广泛的适用性。

    

    我们提供了所有可能的层数为$\mathbb{R}^{n}$张量幂次的交替群($A_n$)等变神经网络的完整表征。特别地，我们在$\mathbb{R}^{n}$的标准基础上找到一组可学习的、线性的、$A_n$等变层函数的矩阵基。我们还描述了我们的方法如何推广到构建等变于局部对称性的神经网络。

    We provide a full characterisation of all of the possible alternating group ($A_n$) equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a basis of matrices for the learnable, linear, $A_n$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$. We also describe how our approach generalises to the construction of neural networks that are equivariant to local symmetries.
    
[^84]: 深度线性网络中的神经塌陷:从平衡到不平衡的数据

    Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data. (arXiv:2301.00437v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00437](http://arxiv.org/abs/2301.00437)

    研究者证明对于均方误差和交叉熵损失，深度线性网络中出现的全局解在不同数据上都具有神经塌陷的特性，即最后一层特征会崩溃为类均值，而这些类均值是等角紧框架的顶点。

    

    现代深度神经网络在图像分类和自然语言处理等任务中表现出色，但令人惊讶的是，这些具有大量参数的复杂系统在训练到收敛时，它们的最后一层特征和分类器在经典数据集上表现出相同的结构性质。特别地，观察到最后一层特征会崩溃为类均值，并且这些类均值是等角紧框架(simplex Equiangular Tight Frame)的顶点。这种现象被称为神经塌陷(NC)。最近的论文理论上证明了在简化的“无约束特征模型”训练问题的全局最小值中出现了$\mathcal{NC}$。在这个语境下，我们进一步证明了在常用的均方误差(MSE)和交叉熵(CE)损失下，深度线性网络中也会发生$\mathcal{NC}$现象，表明全局解在不同数据上都具有$\mathcal{NC}$的特性。

    Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse ($\mathcal{NC}$). Recent papers have theoretically shown that $\mathcal{NC}$ emerges in the global minimizers of training problems with the simplified ``unconstrained feature model''. In this context, we take a step further and prove the $\mathcal{NC}$ occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit $\mathcal{NC}$ properties across
    
[^85]: Brauer群等变神经网络

    Brauer's Group Equivariant Neural Networks. (arXiv:2212.08630v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08630](http://arxiv.org/abs/2212.08630)

    本文描述了对于三个在机器学习文献中缺失的对称群（$O(n)$、$SO(n)$和$Sp(n)$），所有可能的群等变神经网络的特征，并找到了这些网络在不同基础下矩阵的生成集。

    

    我们提供了所有可能的群等变神经网络的完整特征描述，其中的层是$\mathbb{R}^{n}$的某些张量幂，适用于三个在机器学习文献中缺失的对称群：$O(n)$（正交群），$SO(n)$（特殊正交群）和$Sp(n)$（辛群）。特别地，当群为$O(n)$或$SO(n)$时，在$\mathbb{R}^{n}$的标准基础下，我们找到了可学习的、线性的、等变的层函数之间的矩阵的生成集；当群为$Sp(n)$时，我们则在$\mathbb{R}^{n}$的辛基础下找到了这样的生成集。

    We provide a full characterisation of all of the possible group equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$ for three symmetry groups that are missing from the machine learning literature: $O(n)$, the orthogonal group; $SO(n)$, the special orthogonal group; and $Sp(n)$, the symplectic group. In particular, we find a spanning set of matrices for the learnable, linear, equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$ when the group is $O(n)$ or $SO(n)$, and in the symplectic basis of $\mathbb{R}^{n}$ when the group is $Sp(n)$.
    
[^86]: 镜像Sinkhorn：在传输多面体上进行快速在线优化

    Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes. (arXiv:2211.10420v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.10420](http://arxiv.org/abs/2211.10420)

    该论文提出了一种在传输多面体上进行在线凸目标优化的算法，此算法基于Sinkhorn矩阵缩放和镜像下降的原理，并且可以在噪音环境下使用。

    

    最优传输是机器学习中的重要工具，通过在传输多面体上的线性规划来捕捉数据的几何属性。我们提出了一种单循环优化算法，利用Sinkhorn矩阵缩放和镜像下降的原理，在这些领域上最小化一般凸目标。该算法对噪音具有鲁棒性，并可在在线设置中使用。我们提供了凸目标的理论保证和实验结果，展示了其在合成数据和实际数据上的有效性。

    Optimal transport is an important tool in machine learning, allowing to capture geometric properties of the data through a linear program on transport polytopes. We present a single-loop optimization algorithm for minimizing general convex objectives on these domains, utilizing the principles of Sinkhorn matrix scaling and mirror descent. The proposed algorithm is robust to noise, and can be used in an online setting. We provide theoretical guarantees for convex objectives and experimental results showcasing it effectiveness on both synthetic and real-world data.
    
[^87]: 基于高斯过程中单调性的安全探索的优势

    Benefits of Monotonicity in Safe Exploration with Gaussian Processes. (arXiv:2211.01561v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.01561](http://arxiv.org/abs/2211.01561)

    本文提出了一种名为单调安全UCB(M-SafeUCB)的算法，通过单调性假设，取得了在保证精度的同时显著的优势。

    

    本文考虑了在相应的安全阈值下顺序地寻找未知函数的最大值的问题。我们使用基于核的和高斯过程方法建模函数，但假设该函数相对于“安全变量”是单调递增的，这与以前的工作不同。此假设受到了各种实际应用的启发，例如自适应临床试验设计和机器人学。我们从GP-UCB和SafeOpt算法中汲取灵感，提出了一种名为单调安全UCB(M-SafeUCB)的算法来完成这个任务。我们证明了M-SafeUCB在安全性、适当定义的后悔概念和近似找到整个安全边界方面具有理论保证。此外，我们说明，单调性假设在保证准确性的同时也具有显著优势。

    We consider the problem of sequentially maximising an unknown function over a set of actions while ensuring that every sampled point has a function value below a given safety threshold. We model the function using kernel-based and Gaussian process methods, while differing from previous works in our assumption that the function is monotonically increasing with respect to a \emph{safety variable}. This assumption is motivated by various practical applications such as adaptive clinical trial design and robotics. Taking inspiration from the \textsc{\sffamily GP-UCB} and \textsc{\sffamily SafeOpt} algorithms, we propose an algorithm, monotone safe {\sffamily UCB} (\textsc{\sffamily M-SafeUCB}) for this task. We show that \textsc{\sffamily M-SafeUCB} enjoys theoretical guarantees in terms of safety, a suitably-defined regret notion, and approximately finding the entire safe boundary. In addition, we illustrate that the monotonicity assumption yields significant benefits in terms of the guara
    
[^88]: 终身赌博优化：无先验知识和无后悔算法

    Lifelong Bandit Optimization: No Prior and No Regret. (arXiv:2210.15513v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.15513](http://arxiv.org/abs/2210.15513)

    本文提出了一种算法LIBO，可以无需直接访问数据，对一系列赌博优化任务进行学习和适应，并保证最优性能和亚线性终身后悔率。

    

    机器学习算法经常重复应用于相似结构的问题。本文关注解决一系列赌博优化任务，并开发了一种适应环境的算法LIBO。我们假设内核化结构，其中的内核在所有任务中都是未知的但共享的。LIBO依次元学习一个逼近真实内核的内核，然后用最新的内核估计来解决即将到来的任务。本算法可以与任何内核化或线性赌博算法配对，并保证最优的预期性能。如果与亚线性赌博算法配对，LIBO将产生一个亚线性终身后悔率。

    Machine learning algorithms are often repeatedly applied to problems with similar structure over and over again. We focus on solving a sequence of bandit optimization tasks and develop LIBO, an algorithm which adapts to the environment by learning from past experience and becomes more sample-efficient in the process. We assume a kernelized structure where the kernel is unknown but shared across all tasks. LIBO sequentially meta-learns a kernel that approximates the true kernel and solves the incoming tasks with the latest kernel estimate. Our algorithm can be paired with any kernelized or linear bandit algorithm and guarantees oracle optimal performance, meaning that as more tasks are solved, the regret of LIBO on each task converges to the regret of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong regret. We also show that direct access to the data from each task is not necessary for
    
[^89]: 分解线性动态系统（dLDS）用于学习神经动力学的潜在成分

    Decomposed Linear Dynamical Systems (dLDS) for learning the latent components of neural dynamics. (arXiv:2206.02972v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.02972](http://arxiv.org/abs/2206.02972)

    该论文提出了一种新的分解动力系统模型，将复杂非平稳和非线性动态表示为简单、可解释的稀疏组合，并通过字典学习过程进行训练。

    

    在群体水平上学习神经动力学的可解释表示是理解观察到的神经活动如何与知觉和行为相关的关键第一步。神经动力学模型通常集中于神经活动的低维投影，或者学习与神经状态随时间明确相关的动力系统。通过将动力系统视为低维流的代表，我们讨论了这两种方法之间的相互关系。在此概念基础上，我们提出了一种新的分解动力系统模型，将时间序列数据的复杂非平稳和非线性动态表示为更简单、更可解释的成分的稀疏组合。我们的模型通过一个字典学习过程进行训练，其中我们利用了最近在跟踪稀疏向量随时间变化方面的结果。相较于以往的开关方法，在给定参数数量的情况下，我们的分解动态性质更为明显。

    Learning interpretable representations of neural dynamics at a population level is a crucial first step to understanding how observed neural activity relates to perception and behavior. Models of neural dynamics often focus on either low-dimensional projections of neural activity, or on learning dynamical systems that explicitly relate to the neural state over time. We discuss how these two approaches are interrelated by considering dynamical systems as representative of flows on a low-dimensional manifold. Building on this concept, we propose a new decomposed dynamical system model that represents complex non-stationary and nonlinear dynamics of time series data as a sparse combination of simpler, more interpretable components. Our model is trained through a dictionary learning procedure, where we leverage recent results in tracking sparse vectors over time. The decomposed nature of the dynamics is more expressive than previous switched approaches for a given number of parameters and 
    
[^90]: 非参数分类中的欠采样是一种极小化极差风险的鲁棒性干预方法

    Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification. (arXiv:2205.13094v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13094](http://arxiv.org/abs/2205.13094)

    该论文证明在非参数二元分类中，缺乏少数派样本是学习的根本限制，并探讨了欠采样算法的最小化极差风险的鲁棒性表现，特别是在标签转移的情况下可以最优化。

    

    尽管已经提出了广泛的技术来解决分布偏移问题，但在几个流行的基准测试中，基于欠采样的平衡数据集的训练通常能够实现接近最先进准确性。我们证明了在非参数二元分类设置下，学习的基本限制是由于缺乏少数群体样本而产生的。我们的结果表明，除非训练和测试分布之间存在高度重叠（这在真实数据集中不太可能），否则算法无法超越欠采样，除非算法利用有关分布偏移的其他结构。特别地，在标签转移的情况下，我们证明了总是存在一种最小化极差风险的欠采样算法。在组转换的情况下，我们介绍了一类最小极差风险的欠采样算法。我们在合成和真实数据集上进行了验证实验以验证我们的理论结果。

    While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an $\textit{undersampled}$ balanced dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of nonparametric binary classification. Our results show that in the worst case, an algorithm cannot outperform undersampling unless there is a high degree of overlap between the train and test distributions (which is unlikely to be the case in real-world datasets), or if the algorithm leverages additional structure about the distribution shift. In particular, in the case of label shift we show that there is always an undersampling algorithm that is minimax optimal. In the case of grou
    
[^91]: 基于小波散射谱的尺度依赖性和自相似模型

    Scale Dependencies and Self-Similar Models with Wavelet Scattering Spectra. (arXiv:2204.10177v2 [physics.data-an] UPDATED)

    [http://arxiv.org/abs/2204.10177](http://arxiv.org/abs/2204.10177)

    本论文提出了小波散射谱方法，可以用于建模具有平稳增量的时间序列的非高斯特性，其系数可以用于构建最大熵模型和生成新的时间序列，同时证明了自相似过程具有散射谱的尺度不变性。

    

    我们提出了小波散射谱，提供了一种具有平稳增量的时间序列的非高斯模型。复小波变换计算每个尺度上的信号变化。跨尺度的依赖关系由小波系数及其模数在时间和尺度上的联合相关性所捕获。该相关矩阵由第二个小波变换近似对角化，定义了散射谱。我们证明了自相似过程具有散射谱的尺度不变性。该特性可以在单个实现上进行统计测试，并定义了一类宽义自相似过程。我们通过散射谱系数构建最大熵模型，并使用微正则采样算法生成新的时间序列。展示了高度非高斯的金融和湍流时间序列的应用。

    We introduce the wavelet scattering spectra which provide non-Gaussian models of time-series having stationary increments. A complex wavelet transform computes signal variations at each scale. Dependencies across scales are captured by the joint correlation across time and scales of wavelet coefficients and their modulus. This correlation matrix is nearly diagonalized by a second wavelet transform, which defines the scattering spectra. We show that this vector of moments characterizes a wide range of non-Gaussian properties of multi-scale processes. We prove that self-similar processes have scattering spectra which are scale invariant. This property can be tested statistically on a single realization and defines a class of wide-sense self-similar processes. We build maximum entropy models conditioned by scattering spectra coefficients, and generate new time-series with a microcanonical sampling algorithm. Applications are shown for highly non-Gaussian financial and turbulence time-seri
    
[^92]: 在医学中使用因果树方法学习最佳动态治疗方案

    Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine. (arXiv:2204.07124v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.07124](http://arxiv.org/abs/2204.07124)

    该论文开发了两种新的方法，用于有效处理复杂的患者数据，基于数据驱动的异质性治疗效应估计，使用因果树方法（具体来说是因果树和因果森林），学习非线性关系，控制时间变化混淆，是双重稳健的和可解释的。在治疗抑郁症的真实世界数据应用程序中，该方法在准确性和实际可解释性方面表现出色。

    

    动态治疗方案（DTR）在医学中用于根据患者异质性定制连续的治疗决策。然而，常见的学习最佳DTR的方法存在缺陷：它们通常基于结果预测而非治疗效应估计，或者使用线性模型，对于现代电子健康记录中的患者数据具有限制性。为了解决这些缺陷，我们开发了两种新的方法，用于有效处理复杂的患者数据，称为DTR-CT和DTR-CF。我们的方法基于数据驱动的异质性治疗效应估计，使用因果树方法（具体来说是因果树和因果森林），学习非线性关系，控制时间变化混淆，是双重稳健的和可解释的。据我们所知，我们的论文是第一篇为了学习最佳DTR而改编因果树方法的论文。我们使用合成数据和在抑郁症治疗背景下的真实世界数据应用程序来评估我们提出的方法。我们的结果表明，我们的方法在准确性和实际可解释性方面优于现有的方法。

    Dynamic treatment regimes (DTRs) are used in medicine to tailor sequential treatment decisions to patients by considering patient heterogeneity. Common methods for learning optimal DTRs, however, have shortcomings: they are typically based on outcome prediction and not treatment effect estimation, or they use linear models that are restrictive for patient data from modern electronic health records. To address these shortcomings, we develop two novel methods for learning optimal DTRs that effectively handle complex patient data. We call our methods DTR-CT and DTR-CF. Our methods are based on a data-driven estimation of heterogeneous treatment effects using causal tree methods, specifically causal trees and causal forests, that learn non-linear relationships, control for time-varying confounding, are doubly robust, and explainable. To the best of our knowledge, our paper is the first that adapts causal tree methods for learning optimal DTRs. We evaluate our proposed methods using synthet
    
[^93]: 针对未知协变量漂移的自适应预测集构建方法

    Prediction Sets Adaptive to Unknown Covariate Shift. (arXiv:2203.06126v6 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2203.06126](http://arxiv.org/abs/2203.06126)

    本文提出 PredSet-1Step 方法，可以在未知协变量漂移下高效构建具备渐近覆盖保障的预测集，具备很好的校准覆盖误差和高置信度。

    

    在统计学习中，预测结果的集合而非单个结果是对不确定性的一种解决方案。构建具有统计保障的预测集的文献很丰富，但适应未知协变量漂移这一在实践中普遍存在的问题仍然是一大难点。本文表明，具备有限样本覆盖保障的预测集是无信息的，提出了一种新颖的灵活无分布方法 PredSet-1Step 用于快速构建在未知协变量漂移下具备渐近覆盖保障的预测集。我们正式证明了这种方法是渐近几乎正确的，对于大样本具有高置信度的校准覆盖误差。我们还通过 HIV 风险预测的实验和南非队列研究数据集演示了它达到名义覆盖的能力。我们的理论基于一种新的收敛速度上界。

    Predicting sets of outcomes -- instead of unique outcomes -- is a promising solution to uncertainty quantification in statistical learning. Despite a rich literature on constructing prediction sets with statistical guarantees, adapting to unknown covariate shift -- a prevalent issue in practice -- poses a serious unsolved challenge. In this paper, we show that prediction sets with finite-sample coverage guarantee are uninformative and propose a novel flexible distribution-free method, PredSet-1Step, to efficiently construct prediction sets with an asymptotic coverage guarantee under unknown covariate shift. We formally show that our method is \textit{asymptotically probably approximately correct}, having well-calibrated coverage error with high confidence for large samples. We illustrate that it achieves nominal coverage in a number of experiments and a data set concerning HIV risk prediction in a South African cohort study. Our theory hinges on a new bound for the convergence rate of 
    
[^94]: 双重PC算法及其对高斯性质在贝叶斯网络结构学习中的作用

    The Dual PC Algorithm and the Role of Gaussianity for Structure Learning of Bayesian Networks. (arXiv:2112.09036v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.09036](http://arxiv.org/abs/2112.09036)

    双重PC算法通过利用协方差和精度矩阵之间的反向关系，实现了CI测试，能够恢复正确的等价类，并可对互补调节集的偏相关进行测试。

    

    学习贝叶斯网络的图形结构是描述许多复杂应用程序中的数据生成机制的关键，但面临着巨大的计算挑战。在某些假设下，流行的PC算法可以通过逆向工程变量分布中所具有的条件独立关系来一致地恢复正确的等价类。双重PC算法是一种新颖的方案，通过利用协方差和精度矩阵之间的反向关系来进行PC算法中的CI测试。通过利用块矩阵求逆，我们还可以对互补（或双重）调节集的偏相关进行测试。双重PC算法的多个CI测试首先考虑边缘和完全排序CI关系。

    Learning the graphical structure of Bayesian networks is key to describing data-generating mechanisms in many complex applications but poses considerable computational challenges. Observational data can only identify the equivalence class of the directed acyclic graph underlying a Bayesian network model, and a variety of methods exist to tackle the problem. Under certain assumptions, the popular PC algorithm can consistently recover the correct equivalence class by reverse-engineering the conditional independence (CI) relationships holding in the variable distribution. The dual PC algorithm is a novel scheme to carry out the CI tests within the PC algorithm by leveraging the inverse relationship between covariance and precision matrices. By exploiting block matrix inversions we can also perform tests on partial correlations of complementary (or dual) conditioning sets. The multiple CI tests of the dual PC algorithm proceed by first considering marginal and full-order CI relationships a
    
[^95]: 深度学习中认识不确定性的量化

    Quantifying Epistemic Uncertainty in Deep Learning. (arXiv:2110.12122v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.12122](http://arxiv.org/abs/2110.12122)

    本文提供了一个理论框架来分解深度学习中的不确定性，并提出了两种方法来估计这些不确定性，这些方法使我们能够克服在使用传统统计方法时遇到的困难，从而为建模和数据收集提供直接的指导。

    

    不确定性量化是机器学习可靠性和鲁棒性的核心。本文提供了一个理论框架来分解深度学习中的不确定性，特别是\textit {认识成分}；分为\textit {程序变异性}(来自训练过程)和\textit {数据变异性} (来自训练数据)，这是文献中首次尝试。然后我们提出两种方法来估计这些不确定性，一种是基于影响函数的方法，另一种是批次化的方法。我们展示了我们的方法如何克服在应用经典统计方法时遇到的计算困难。多个问题设置的实验评估证实了我们的理论，并说明了我们的框架和估计如何提供对建模和数据收集工作的直接指导。

    Uncertainty quantification is at the core of the reliability and robustness of machine learning. In this paper, we provide a theoretical framework to dissect the uncertainty, especially the \textit{epistemic} component, in deep learning into \textit{procedural variability} (from the training procedure) and \textit{data variability} (from the training data), which is the first such attempt in the literature to our best knowledge. We then propose two approaches to estimate these uncertainties, one based on influence function and one on batching. We demonstrate how our approaches overcome the computational difficulties in applying classical statistical methods. Experimental evaluations on multiple problem settings corroborate our theory and illustrate how our framework and estimation can provide direct guidance on modeling and data collection efforts.
    
[^96]: 论深度学习在差分隐私下的收敛性与校准性

    On the Convergence and Calibration of Deep Learning with Differential Privacy. (arXiv:2106.07830v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.07830](http://arxiv.org/abs/2106.07830)

    本文通过NTK对差分隐私训练进行连续时间分析，发现噪声只会影响隐私风险而不影响收敛性和校准性，而基于每个样本的梯度剪裁会影响收敛性和校准性。此外，大剪裁范数下的差分隐私模型不仅享有相同的隐私保证，而且校准效果好。

    

    差分隐私训练通常会以数据隐私保护为代价，导致收敛速度变慢（从而精度降低），且比非隐私方法更容易出现严重的校准误差。本研究通过神经切向核（NTK）从连续时间的角度分析了差分隐私训练的收敛性，对任意网络结构和损失函数进行了建模，发现噪声只会影响隐私风险而不影响收敛性和校准性，而基于每个样本的梯度剪裁（在平坦和层级剪裁风格下）会影响收敛性和校准性。此外，研究表明，尽管小剪裁范数下的差分隐私模型通常会在精度上表现最佳，但其校准性较差且不可靠。而在大剪裁范数下训练的差分隐私模型不仅享有相同的隐私保证，而且校准效果好。

    Differentially private (DP) training preserves the data privacy usually at the cost of slower convergence (and thus lower accuracy), as well as more severe mis-calibration than its non-private counterpart. To analyze the convergence of DP training, we formulate a continuous time analysis through the lens of neural tangent kernel (NTK), which characterizes the per-sample gradient clipping and the noise addition in DP training, for arbitrary network architectures and loss functions. Interestingly, we show that the noise addition only affects the privacy risk but not the convergence or calibration, whereas the per-sample gradient clipping (under both flat and layerwise clipping styles) only affects the convergence and calibration.  Furthermore, we observe that while DP models trained with small clipping norm usually achieve the best accurate, but are poorly calibrated and thus unreliable. In sharp contrast, DP models trained with large clipping norm enjoy the same privacy guarantee and si
    
[^97]: 基于广义全变差最小化的聚类联邦学习

    Clustered Federated Learning via Generalized Total Variation Minimization. (arXiv:2105.12769v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.12769](http://arxiv.org/abs/2105.12769)

    本文介绍了一种基于广义全变差最小化的完全分散的联邦学习算法，可以训练适用于具有本地数据集的分散式去中心化环境的本地化（或个性化）模型，并获得了良好的模拟结果。

    

    本文研究了在具有内在网络结构的分散式本地数据集的去中心化环境下训练本地（或个性化）模型的优化方法。这种网络结构是由本地数据集之间的领域特定相似性概念引起的。这些概念的例子包括时空邻近性，统计依赖性或功能关系。我们的主要概念性贡献在于将联邦学习描述为广义总变差（GTV）最小化。这种表述统一并显著扩展了现有的联邦学习方法。它具有高度的灵活性，并且可以与广泛的参数模型结合使用，包括广义线性模型或深度神经网络。我们的主要算法贡献是一种完全分散的联邦学习算法。该算法是通过应用已建立的原始-对偶方法来解决GTV最小化问题而获得的。它可以实现为消息传递，并且对于由通信延迟或干扰产生的不精确计算很稳健。我们在合成和真实数据集上的模拟中展示了我们方法的有效性。

    We study optimization methods to train local (or personalized) models for decentralized collections of local datasets with an intrinsic network structure. This network structure arises from domain-specific notions of similarity between local datasets. Examples for such notions include spatio-temporal proximity, statistical dependencies or functional relations. Our main conceptual contribution is to formulate federated learning as generalized total variation (GTV) minimization. This formulation unifies and considerably extends existing federated learning methods. It is highly flexible and can be combined with a broad range of parametric models, including generalized linear models or deep neural networks. Our main algorithmic contribution is a fully decentralized federated learning algorithm. This algorithm is obtained by applying an established primal-dual method to solve GTV minimization. It can be implemented as message passing and is robust against inexact computations that arise fro
    
[^98]: 用黎曼Langevin算法求解半定向规划

    Riemannian Langevin Algorithm for Solving Semidefinite Programs. (arXiv:2010.11176v6 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.11176](http://arxiv.org/abs/2010.11176)

    研究了一种基于Langevin扩散的算法，用于在球面的乘积流形上进行非凸优化和采样，展示了在适当的温度选择下，该算法可以保证次优解到全局最小值的间隙概率非常小，并在此基础上提出了求解半定向规划模型的新方法，并给出了全局最优性的保证。

    

    我们提出了一种基于 Langevin 扩散的算法，用于在球面的乘积流形上进行非凸优化和采样。在对数 Sobolev 不等式下，我们建立了一个有限迭代收敛到 Gibbs 分布的保证，这个保证是基于 Kullback-Leibler 散度的。我们展示了一个合适的温度选择，可以保证次优解到全局最小值的间隙概率极高地非常小。作为一个应用，我们考虑 Burer-Monteiro 方法用于解决带对角约束的半定向规划(SDP)，并分析了用于优化非凸目标的 Langevin 算法。特别地，我们证明了在没有虚假局部极小值的情况下，Burer-Monteiro 问题的对数 Sobolev 不等式是成立的，但这里存在鞍点。结合这些结果，我们提供了 SDP 和 Max-Cut 问题的全局最优性保证。更具体地说，我们展示了 Langevin 算法实现了这个保证。

    We propose a Langevin diffusion-based algorithm for non-convex optimization and sampling on a product manifold of spheres. Under a logarithmic Sobolev inequality, we establish a guarantee for finite iteration convergence to the Gibbs distribution in terms of Kullback--Leibler divergence. We show that with an appropriate temperature choice, the suboptimality gap to the global minimum is guaranteed to be arbitrarily small with high probability.  As an application, we consider the Burer--Monteiro approach for solving a semidefinite program (SDP) with diagonal constraints, and analyze the proposed Langevin algorithm for optimizing the non-convex objective. In particular, we establish a logarithmic Sobolev inequality for the Burer--Monteiro problem when there are no spurious local minima, but under the presence saddle points. Combining the results, we then provide a global optimality guarantee for the SDP and the Max-Cut problem. More precisely, we show that the Langevin algorithm achieves 
    
[^99]: 部分观测下的协作多智能体强化学习

    Cooperative Multi-Agent Reinforcement Learning with Partial Observations. (arXiv:2006.10822v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.10822](http://arxiv.org/abs/2006.10822)

    本文提出了一种基于局部状态和动作信息的分布式零阶策略优化方法，可用于部分观测的协作多智能体强化学习，减小通信开销并取得更好的效果。

    

    本文提出了一种分布式的零阶策略优化方法，用于多智能体强化学习（MARL）。现有的MARL算法通常假设每个智能体都可以观察网络中所有其他智能体的状态和动作。但在大规模问题中，与多跳邻居共享状态和动作信息可能会导致显着的通信开销。提出的零阶策略优化方法的优势在于，它允许智能体仅基于局部的、部分的状态和动作信息来计算本地策略梯度，从而更新它们的本地策略函数，并使用共识来获得依赖于全局累积奖励的局部估计。具体来说，为了计算本地策略梯度，我们开发了一种新的分布式零阶策略梯度估计器，它依赖于一点残差反馈， im同时与现有的依赖于一点反馈的零阶估计器相比，显著降低了通信开销。我们在几个协作多智能体基准任务上展示了提出方法的有效性，并表明它胜过了现有的假设具有全观察信息的方法。

    In this paper, we propose a distributed zeroth-order policy optimization method for Multi-Agent Reinforcement Learning (MARL). Existing MARL algorithms often assume that every agent can observe the states and actions of all the other agents in the network. This can be impractical in large-scale problems, where sharing the state and action information with multi-hop neighbors may incur significant communication overhead. The advantage of the proposed zeroth-order policy optimization method is that it allows the agents to compute the local policy gradients needed to update their local policy functions using local estimates of the global accumulated rewards that depend on partial state and action information only and can be obtained using consensus. Specifically, to calculate the local policy gradients, we develop a new distributed zeroth-order policy gradient estimator that relies on one-point residual-feedback which, compared to existing zeroth-order estimators that also rely on one-poi
    
[^100]: 非平稳时间序列等变在线预测

    Equivariant online predictions of non-stationary time series. (arXiv:1911.08662v5 [math.ST] UPDATED)

    [http://arxiv.org/abs/1911.08662](http://arxiv.org/abs/1911.08662)

    本文讨论了模型错误下的非平稳时间序列在线预测问题，并且证明了随机游走动态线性模型可以产生精确的极小化预测密度。这个结果为其他模型提供了理论基线，并且在流行病学、气候学和经济学中得到了应用。

    

    我们讨论了模型错误下非平稳时间序列在线预测的有限样本理论性质。为了分析决策论框架下统计方法在这种情况下的理论预测性能，我们首先定义了Kullback-Leibler风险。在这个框架下，我们展示了一类特定的动态模型--随机游走动态线性模型--产生了精确的极小化预测密度。我们首先在高斯假设下展示了这个结果，然后使用半鞅过程放松了这个假设。该结果为非平稳和平稳时间序列数据提供了一个理论基线，可以用来与其他模型进行比较。我们将结果扩展到多个预测密度的综合。在流行病学、气候学和经济学中的三个主题应用，证实并凸显了我们的理论结果。

    We discuss the finite sample theoretical properties of online predictions in non-stationary time series under model misspecification. To analyze the theoretical predictive properties of statistical methods under this setting, we first define the Kullback-Leibler risk, in order to place the problem within a decision theoretic framework. Under this framework, we show that a specific class of dynamic models -- random walk dynamic linear models -- produce exact minimax predictive densities. We first show this result under Gaussian assumptions, then relax this assumption using semi-martingale processes. This result provides a theoretical baseline, under both non-stationary and stationary time series data, for which other models can be compared against. We extend the result to the synthesis of multiple predictive densities. Three topical applications in epidemiology, climatology, and economics, confirm and highlight our theoretical results.
    

