# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Unreasonable Ineffectiveness of the Deeper Layers](https://arxiv.org/abs/2403.17887) | 层剪枝方法可以在流行的预训练语言模型中实现大部分层的移除而保持性能，同时使用参数高效的微调方法可以进一步减少计算资源，提高推断的内存和延迟。 |
| [^2] | [Counterfactual Fairness through Transforming Data Orthogonal to Bias](https://arxiv.org/abs/2403.17852) | 提出了一种新颖的数据预处理算法，正交于偏见（OB），通过确保数据与敏感变量不相关，实现机器学习应用中的反事实公平性。 |
| [^3] | [Towards Multilevel Modelling of Train Passing Events on the Staffordshire Bridge](https://arxiv.org/abs/2403.17820) | 该研究提出了一个多层模型，用于表示斯塔福德郡桥监测系统中的火车通过事件的聚合情况，可以模拟先前未观察到的火车类型，为进一步实验提供重要信息。 |
| [^4] | [Asymptotic Bayes risk of semi-supervised learning with uncertain labeling](https://arxiv.org/abs/2403.17767) | 论文研究了具有不确定标签的半监督学习中的渐近贝叶斯风险计算，并通过与最佳算法比较得出新的见解。 |
| [^5] | [On the Benefits of Over-parameterization for Out-of-Distribution Generalization](https://arxiv.org/abs/2403.17592) | 研究了超参数化模型在超出分布泛化方面的表现，探讨了在良性过拟合条件下的表现，并发现了恒定的超出分布损失。 |
| [^6] | [Test-time Adaptation Meets Image Enhancement: Improving Accuracy via Uncertainty-aware Logit Switching](https://arxiv.org/abs/2403.17423) | 将图像增强与测试时间适应相结合，提出了一种新方法TECA，通过减少预测的不确定性来提高模型准确性。 |
| [^7] | [On permutation-invariant neural networks](https://arxiv.org/abs/2403.17410) | 神经网络如Deep Sets和Transformers的出现显著推动了基于集合的数据处理的进展 |
| [^8] | [An Analysis of Switchback Designs in Reinforcement Learning](https://arxiv.org/abs/2403.17285) | 本文通过提出“弱信号分析”框架，研究了强化学习中往返设计对平均处理效应估计准确性的影响，发现在大部分奖励误差为正相关时，往返设计比每日切换策略更有效，增加政策切换频率可以降低平均处理效应估计器的均方误差。 |
| [^9] | [DASA: Delay-Adaptive Multi-Agent Stochastic Approximation](https://arxiv.org/abs/2403.17247) | DASA算法是第一个收敛速度仅依赖于混合时间和平均延迟的算法，同时在马尔科夫采样下实现N倍的收敛加速。 |
| [^10] | [Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data](https://arxiv.org/abs/2403.17091) | 研究提出了对于脱机策略评估任务，样本复杂度受聚合马尔科夫转换模型中的浓缩系数控制，而不是原始MDP中的系数。 |
| [^11] | [Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction](https://arxiv.org/abs/2403.17042) | 开发了一个算法框架，用于将基于得分的扩散模型作为通用非线性逆的表达数据先验。 |
| [^12] | [Multivariate Gaussian Approximation for Random Forest via Region-based Stabilization](https://arxiv.org/abs/2403.09960) | 该论文通过基于区域稳定性的方法，推导出了随机森林预测的高斯逼近界限，并建立了适用于各种相关统计问题的概率结果。 |
| [^13] | [Applying statistical learning theory to deep learning](https://arxiv.org/abs/2311.15404) | 深度学习的理论方面仍不清楚，本研究通过将统计学习理论应用于深度学习，探讨了不同架构在基于梯度方法训练时可能导致的归纳偏差，并详细研究了隐含偏差的数量化表示。 |
| [^14] | [Riemannian Laplace Approximation with the Fisher Metric](https://arxiv.org/abs/2311.02766) | 黎曼拉普拉斯逼近的新方法利用Fisher度量提供更丰富的逼近族，解决了在无限数据极限下先前方法度量选择不当导致逼近过于狭窄和有偏的问题。 |
| [^15] | [A distribution-free mixed-integer optimization approach to hierarchical modelling of clustered and longitudinal data](https://arxiv.org/abs/2302.03157) | 该论文提出了一个面向层次化数据建模的分布无关混合整数优化方法，通过在线性混合效应模型中选取群体特性来提高解决问题的效率，并在生成稀疏解方面表现出更高的预测能力。 |
| [^16] | [Optimal Design of Volt/VAR Control Rules of Inverters using Deep Learning](https://arxiv.org/abs/2211.09557) | 使用深度学习重新制定混合整数非线性规划问题，以优化逆变器的电压/无功控制规则设计。 |
| [^17] | [Differentially private multivariate medians](https://arxiv.org/abs/2210.06459) | 差分私有多变量中位数的有限样本性能保证为常用深度函数提供了尖锐的结果，表明重尾位置估计的成本超过了隐私保护成本。 |
| [^18] | [A Semismooth Newton Stochastic Proximal Point Algorithm with Variance Reduction](https://arxiv.org/abs/2204.00406) | 提出了一种具有方差减少机制的半光滑牛顿随机近端点算法，通过在不精确的框架下解决近端点更新，实现了对弱凸性、复合优化问题的有效求解。 |
| [^19] | [Bayesian data-driven discovery of partial differential equations with variable coefficients](https://arxiv.org/abs/2102.01432) | 提出了一种用于具有可变系数的偏微分方程发现的先进贝叶斯稀疏学习算法，通过阈值贝叶斯组Lasso回归和Gibbs采样器提高了稳健性和减轻了计算负担 |
| [^20] | [PPI++: Efficient Prediction-Powered Inference.](http://arxiv.org/abs/2311.01453) | PPI++是一种高效的预测驱动推理方法，通过自动调整预测质量来改善经典区间的计算置信区间的计算效率和统计效率。 |
| [^21] | [Entropy-MCMC: Sampling from Flat Basins with Ease.](http://arxiv.org/abs/2310.05401) | 本文提出了一种Entropy-MCMC的方法，通过引入一个辅助的引导变量来在平坦盆地中进行采样，以解决深度神经网络后验分布的多模态问题，并证明了该方法的收敛性。 |
| [^22] | [Prediction Error Estimation in Random Forests.](http://arxiv.org/abs/2309.00736) | 本文通过量化评估分类随机森林的误差估计方法，发现随机森林的预测误差估计比平均预测误差更接近真实误差率，并且这一结果适用于不同的误差估计策略。 |
| [^23] | [Spatiotemporal Besov Priors for Bayesian Inverse Problems.](http://arxiv.org/abs/2306.16378) | 本研究通过将贝索夫过程推广到时空领域，以更好地处理贝叶斯逆问题中的时空重建。通过替换随机系数，该方法能够保持边缘特征并模拟动态变化图像的时空相关性。 |
| [^24] | [Omega: Optimistic EMA Gradients.](http://arxiv.org/abs/2306.07905) | Omega是一种优化算法，通过加入历史梯度EMA来减轻噪声的影响并在随机游戏上表现更佳。 |
| [^25] | [Shotgun crystal structure prediction using machine-learned formation energies.](http://arxiv.org/abs/2305.02158) | 本研究使用机器学习方法在多个结构预测标准测试中精确识别含有100个以上原子的许多材料的全局最小结构，并以单次能量评估为基础，取代了重复的第一原理能量计算过程。 |
| [^26] | [Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance.](http://arxiv.org/abs/2304.10025) | 本文针对治疗不服从性提出了一种半参数框架来评估因果中介效应，提出了一组假设来识别自然中介效应并推导出成倍稳健估计器。 |
| [^27] | [An optimal control perspective on diffusion-based generative modeling.](http://arxiv.org/abs/2211.01364) | 本文建立了随机最优控制与基于扩散的生成模型之间的联系，推导了用于控制潜在SDE边际密度演化的汉密尔顿-雅可比-贝尔曼方程，并将生成建模表述为对合适度量之间Kullback-Leibler散度的最小化。此外，作者还开发了一种新型扩散方法用于采样非归一化密度。 |

# 详细

[^1]: 深层神经网络层剪枝的不合理无效性

    The Unreasonable Ineffectiveness of the Deeper Layers

    [https://arxiv.org/abs/2403.17887](https://arxiv.org/abs/2403.17887)

    层剪枝方法可以在流行的预训练语言模型中实现大部分层的移除而保持性能，同时使用参数高效的微调方法可以进一步减少计算资源，提高推断的内存和延迟。

    

    我们在流行的预训练语言模型中进行了简单的层剪枝策略的实证研究，发现在移除大部分层（最高达一半）之前，不同问答基准测试的性能几乎没有受到影响。为了剪枝这些模型，我们通过考虑层间的相似性来确定最佳的剪枝层块；然后，为了“修复”损害，我们进行了少量微调。特别地，我们使用参数高效的微调（PEFT）方法，具体包括量化和低秩适配器（QLoRA），这样我们的每个实验都可以在单个A100 GPU上执行。从实际的角度来看，这些结果表明层剪枝方法可以补充其他PEFT策略，从而进一步减少微调的计算资源，另一方面可以提高推断的内存和延迟。从科学的角度来看，该研究表明深层神经网络在某种程度上具有鲁棒性，并且对模型的剪枝没有太大影响。

    arXiv:2403.17887v1 Announce Type: new  Abstract: We empirically study a simple layer-pruning strategy for popular families of open-weight pretrained LLMs, finding minimal degradation of performance on different question-answering benchmarks until after a large fraction (up to half) of the layers are removed. To prune these models, we identify the optimal block of layers to prune by considering similarity across layers; then, to "heal" the damage, we perform a small amount of finetuning. In particular, we use parameter-efficient finetuning (PEFT) methods, specifically quantization and Low Rank Adapters (QLoRA), such that each of our experiments can be performed on a single A100 GPU. From a practical perspective, these results suggest that layer pruning methods can complement other PEFT strategies to further reduce computational resources of finetuning on the one hand, and can improve the memory and latency of inference on the other hand. From a scientific perspective, the robustness of 
    
[^2]: 通过将数据转化为与偏见正交的方式实现反事实公平性

    Counterfactual Fairness through Transforming Data Orthogonal to Bias

    [https://arxiv.org/abs/2403.17852](https://arxiv.org/abs/2403.17852)

    提出了一种新颖的数据预处理算法，正交于偏见（OB），通过确保数据与敏感变量不相关，实现机器学习应用中的反事实公平性。

    

    机器学习模型在解决各个领域的复杂问题中展现出了卓越的能力。然而，这些模型有时可能表现出有偏见的决策，导致不同群体之间的待遇不平等。尽管公平性方面的研究已经很广泛，但多元连续敏感变量对决策结果的微妙影响尚未得到充分研究。我们引入了一种新颖的数据预处理算法，即正交于偏见（OB），旨在消除连续敏感变量的影响，从而促进机器学习应用中的反事实公平性。我们的方法基于结构因果模型（SCM）中联合正态分布的假设，证明了通过确保数据与敏感变量不相关即可实现反事实公平性。OB算法与模型无关，适用于多种机器学习应用。

    arXiv:2403.17852v1 Announce Type: new  Abstract: Machine learning models have shown exceptional prowess in solving complex issues across various domains. Nonetheless, these models can sometimes exhibit biased decision-making, leading to disparities in treatment across different groups. Despite the extensive research on fairness, the nuanced effects of multivariate and continuous sensitive variables on decision-making outcomes remain insufficiently studied. We introduce a novel data pre-processing algorithm, Orthogonal to Bias (OB), designed to remove the influence of a group of continuous sensitive variables, thereby facilitating counterfactual fairness in machine learning applications. Our approach is grounded in the assumption of a jointly normal distribution within a structural causal model (SCM), proving that counterfactual fairness can be achieved by ensuring the data is uncorrelated with sensitive variables. The OB algorithm is model-agnostic, catering to a wide array of machine 
    
[^3]: 在斯塔福德郡桥火车通过事件的多层建模研究

    Towards Multilevel Modelling of Train Passing Events on the Staffordshire Bridge

    [https://arxiv.org/abs/2403.17820](https://arxiv.org/abs/2403.17820)

    该研究提出了一个多层模型，用于表示斯塔福德郡桥监测系统中的火车通过事件的聚合情况，可以模拟先前未观察到的火车类型，为进一步实验提供重要信息。

    

    我们提出了一个多层模型，以代表斯塔福德郡桥监测系统中的火车通过事件的聚合情况。我们从简单单元构建了一个综合模型，代表了两种类型通勤火车的应变包络（每列火车通过的）。测量值被处理为一个纵向数据集，并用（低秩近似）分层高斯过程表示。对于组合模型中的每个单元，我们将领域专业知识编码为边界条件约束，并致力于应变响应的一般表示。展望未来，这应该允许对先前在训练数据中未观察到的火车类型进行模拟。例如，乘客更多的火车或运载更重货物的货车。应变事件模拟具有价值，因为它们可以为进一步实验（包括有限元法校准、疲劳分析或设计）提供信息，以在假设的情景下测试桥梁。

    arXiv:2403.17820v1 Announce Type: cross  Abstract: We suggest a multilevel model, to represent aggregate train-passing events from the Staffordshire bridge monitoring system. We formulate a combined model from simple units, representing strain envelopes (of each train passing) for two types of commuter train. The measurements are treated as a longitudinal dataset and represented with a (low-rank approximation) hierarchical Gaussian process. For each unit in the combined model, we encode domain expertise as boundary condition constraints and work towards a general representation of the strain response. Looking forward, this should allow for the simulation of train types that were previously unobserved in the training data. For example, trains with more passengers or freights with a heavier payload. The strain event simulations are valuable since they can inform further experiments (including FEM calibration, fatigue analysis, or design) to test the bridge in hypothesised scenarios.
    
[^4]: 在具有不确定标签的半监督学习中的渐近贝叶斯风险

    Asymptotic Bayes risk of semi-supervised learning with uncertain labeling

    [https://arxiv.org/abs/2403.17767](https://arxiv.org/abs/2403.17767)

    论文研究了具有不确定标签的半监督学习中的渐近贝叶斯风险计算，并通过与最佳算法比较得出新的见解。

    

    本文考虑了高斯混合模型上的半监督分类设置，其中数据的标签不像通常那样严格，而是带有不确定标签。我们的主要目标是计算该模型的贝叶斯风险。我们比较了该模型的贝叶斯风险与目前已知的最佳算法的行为。这种比较最终为该算法提供了新的见解。

    arXiv:2403.17767v1 Announce Type: cross  Abstract: This article considers a semi-supervised classification setting on a Gaussian mixture model, where the data is not labeled strictly as usual, but instead with uncertain labels. Our main aim is to compute the Bayes risk for this model. We compare the behavior of the Bayes risk and the best known algorithm for this model. This comparison eventually gives new insights over the algorithm.
    
[^5]: 对超参数化对于超出分布泛化的益处

    On the Benefits of Over-parameterization for Out-of-Distribution Generalization

    [https://arxiv.org/abs/2403.17592](https://arxiv.org/abs/2403.17592)

    研究了超参数化模型在超出分布泛化方面的表现，探讨了在良性过拟合条件下的表现，并发现了恒定的超出分布损失。

    

    在最近几年，基于独立同分布假设的机器学习模型取得了成功。然而，这一假设在现实世界的应用中很容易被违反，导致了超出分布（OOD）问题。理解现代超参数化深度神经网络在非平凡自然分布偏移下的行为是至关重要的，因为目前对其在理论上的理解是不足的。现有的理论工作常常为OOD场景中的超参数化模型提供无意义的结果，甚至与实证结果相矛盾。为此，我们正在研究在一般良性过拟合条件下，超参数化模型在OOD泛化方面的性能。我们的分析集中在随机特征模型上，并研究非平凡自然分布偏移，其中良性过拟合估计器展示出恒定的过大OOD损失，尽管达到了零过大i

    arXiv:2403.17592v1 Announce Type: new  Abstract: In recent years, machine learning models have achieved success based on the independently and identically distributed assumption. However, this assumption can be easily violated in real-world applications, leading to the Out-of-Distribution (OOD) problem. Understanding how modern over-parameterized DNNs behave under non-trivial natural distributional shifts is essential, as current theoretical understanding is insufficient. Existing theoretical works often provide meaningless results for over-parameterized models in OOD scenarios or even contradict empirical findings. To this end, we are investigating the performance of the over-parameterized model in terms of OOD generalization under the general benign overfitting conditions. Our analysis focuses on a random feature model and examines non-trivial natural distributional shifts, where the benign overfitting estimators demonstrate a constant excess OOD loss, despite achieving zero excess i
    
[^6]: 测试时间适应遇见图像增强:通过基于不确定性感知的对数转换提高准确性

    Test-time Adaptation Meets Image Enhancement: Improving Accuracy via Uncertainty-aware Logit Switching

    [https://arxiv.org/abs/2403.17423](https://arxiv.org/abs/2403.17423)

    将图像增强与测试时间适应相结合，提出了一种新方法TECA，通过减少预测的不确定性来提高模型准确性。

    

    深度神经网络在各种计算机视觉应用中取得了显著成功。然而，当数据分布在训练和测试之间发生偏移时，准确性会下降。为了解决这一问题，测试时间适应（TTA）已被广泛研究因为其实用性。虽然TTA方法通过在测试时更新模型来提高在分布偏移下的准确性，但使用高不确定性预测已知会降低准确性。由于输入图像是分布偏移的根源，我们将一个新的视角融入到TTA方法中，通过增强输入图像来减少预测的不确定性。我们假设增强输入图像可以降低预测的不确定性，提高TTA方法的准确性。基于这一假设，我们提出了一种新的方法：测试时间增强器和分类器适应（TECA）。在TECA中，分类模型与增强模型同时训练并在测试时进行适应，以提高测试时性能。

    arXiv:2403.17423v1 Announce Type: cross  Abstract: Deep neural networks have achieved remarkable success in a variety of computer vision applications. However, there is a problem of degrading accuracy when the data distribution shifts between training and testing. As a solution of this problem, Test-time Adaptation~(TTA) has been well studied because of its practicality. Although TTA methods increase accuracy under distribution shift by updating the model at test time, using high-uncertainty predictions is known to degrade accuracy. Since the input image is the root of the distribution shift, we incorporate a new perspective on enhancing the input image into TTA methods to reduce the prediction's uncertainty. We hypothesize that enhancing the input image reduces prediction's uncertainty and increase the accuracy of TTA methods. On the basis of our hypothesis, we propose a novel method: Test-time Enhancer and Classifier Adaptation~(TECA). In TECA, the classification model is combined wi
    
[^7]: 论排列不变神经网络

    On permutation-invariant neural networks

    [https://arxiv.org/abs/2403.17410](https://arxiv.org/abs/2403.17410)

    神经网络如Deep Sets和Transformers的出现显著推动了基于集合的数据处理的进展

    

    传统机器学习算法通常在假设输入数据遵循基于向量的格式的前提下设计，着重于基于向量的范式。然而，随着需求涉及基于集合的任务的增长，研究界对解决这些挑战的兴趣发生了范式转变。近年来，Deep Sets和Transformers等神经网络架构的出现在处理基于集合的数据方面取得了重大进展。这些架构专门设计为自然容纳集合作为输入，从而更有效地表示和处理集合结构。因此，近年来出现了大量致力于探索和利用这些架构能力的研究努力，以逼近集合函数的各种任务。这项综合调查旨在概述th

    arXiv:2403.17410v1 Announce Type: cross  Abstract: Conventional machine learning algorithms have traditionally been designed under the assumption that input data follows a vector-based format, with an emphasis on vector-centric paradigms. However, as the demand for tasks involving set-based inputs has grown, there has been a paradigm shift in the research community towards addressing these challenges. In recent years, the emergence of neural network architectures such as Deep Sets and Transformers has presented a significant advancement in the treatment of set-based data. These architectures are specifically engineered to naturally accommodate sets as input, enabling more effective representation and processing of set structures. Consequently, there has been a surge of research endeavors dedicated to exploring and harnessing the capabilities of these architectures for various tasks involving the approximation of set functions. This comprehensive survey aims to provide an overview of th
    
[^8]: 对强化学习中的往返设计进行的分析

    An Analysis of Switchback Designs in Reinforcement Learning

    [https://arxiv.org/abs/2403.17285](https://arxiv.org/abs/2403.17285)

    本文通过提出“弱信号分析”框架，研究了强化学习中往返设计对平均处理效应估计准确性的影响，发现在大部分奖励误差为正相关时，往返设计比每日切换策略更有效，增加政策切换频率可以降低平均处理效应估计器的均方误差。

    

    本文提供了对A/B测试中往返设计的详细研究，这些设计随时间在基准和新策略之间交替。我们的目标是全面评估这些设计对其产生的平均处理效应（ATE）估计器准确性的影响。我们提出了一个新颖的“弱信号分析”框架，大大简化了这些ATE的均方误差（MSE）在马尔科夫决策过程环境中的计算。我们的研究结果表明：(i) 当大部分奖励误差呈正相关时，往返设计比每日切换策略的交替设计更有效。此外，增加政策切换的频率往往会降低ATE估计器的MSE。(ii) 然而，当误差不相关时，所有这些设计变得渐近等效。(iii) 在大多数误差为负相关时

    arXiv:2403.17285v1 Announce Type: cross  Abstract: This paper offers a detailed investigation of switchback designs in A/B testing, which alternate between baseline and new policies over time. Our aim is to thoroughly evaluate the effects of these designs on the accuracy of their resulting average treatment effect (ATE) estimators. We propose a novel "weak signal analysis" framework, which substantially simplifies the calculations of the mean squared errors (MSEs) of these ATEs in Markov decision process environments. Our findings suggest that (i) when the majority of reward errors are positively correlated, the switchback design is more efficient than the alternating-day design which switches policies in a daily basis. Additionally, increasing the frequency of policy switches tends to reduce the MSE of the ATE estimator. (ii) When the errors are uncorrelated, however, all these designs become asymptotically equivalent. (iii) In cases where the majority of errors are negative correlate
    
[^9]: DASA: 延迟自适应多智能体随机逼近

    DASA: Delay-Adaptive Multi-Agent Stochastic Approximation

    [https://arxiv.org/abs/2403.17247](https://arxiv.org/abs/2403.17247)

    DASA算法是第一个收敛速度仅依赖于混合时间和平均延迟的算法，同时在马尔科夫采样下实现N倍的收敛加速。

    

    我们考虑一种设置，其中$N$个智能体旨在通过并行操作并与中央服务器通信来加速一个常见的随机逼近（SA）问题。我们假定上行传输到服务器的传输受到异步和潜在无界时变延迟的影响。为了减轻延迟和落后者的影响，同时又能获得分布式计算的好处，我们提出了一种名为DASA的延迟自适应多智能体随机逼近算法。我们对DASA进行了有限时间分析，假设智能体的随机观测过程是独立马尔科夫链。与现有结果相比，DASA是第一个其收敛速度仅取决于混合时间$tmix$和平均延迟$\tau_{avg}$，同时在马尔科夫采样下实现N倍的收敛加速的算法。我们的工作对于各种SA应用是相关的。

    arXiv:2403.17247v1 Announce Type: new  Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tmix$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA applications, inc
    
[^10]: 脱机强化学习：状态聚合和轨迹数据的作用

    Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data

    [https://arxiv.org/abs/2403.17091](https://arxiv.org/abs/2403.17091)

    研究提出了对于脱机策略评估任务，样本复杂度受聚合马尔科夫转换模型中的浓缩系数控制，而不是原始MDP中的系数。

    

    我们重新审视了具有价值函数可实现性但不具有贝尔曼完备性的脱机强化学习问题。我们对脱机策略评估的样本复杂度受聚合马尔科夫转换模型中的浓缩系数控制的发现，以及提供了仅具有价值函数可实现性的脱机策略评估的相当完整的图景。我们的主要发现有三个：1）脱机策略评估的样本复杂度由聚合的马尔科夫转换模型中的集中系数决定，这个系数由函数类和脱机数据分布共同确定，而不是原始MDP中的系数。

    arXiv:2403.17091v1 Announce Type: cross  Abstract: We revisit the problem of offline reinforcement learning with value function realizability but without Bellman completeness. Previous work by Xie and Jiang (2021) and Foster et al. (2022) left open the question whether a bounded concentrability coefficient along with trajectory-based offline data admits a polynomial sample complexity. In this work, we provide a negative answer to this question for the task of offline policy evaluation. In addition to addressing this question, we provide a rather complete picture for offline policy evaluation with only value function realizability. Our primary findings are threefold: 1) The sample complexity of offline policy evaluation is governed by the concentrability coefficient in an aggregated Markov Transition Model jointly determined by the function class and the offline data distribution, rather than that in the original MDP. This unifies and generalizes the ideas of Xie and Jiang (2021) and Fo
    
[^11]: 可证实鲁棒的基于得分的扩散后验采样用于即插即用图像重建

    Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction

    [https://arxiv.org/abs/2403.17042](https://arxiv.org/abs/2403.17042)

    开发了一个算法框架，用于将基于得分的扩散模型作为通用非线性逆的表达数据先验。

    

    在科学和工程中的许多任务中，目标是从已知描述某种感知或成像模式的已知前向模型收集的少量测量中推断未知图像。由于资源限制，这个任务通常非常不适合，这就需要采纳表达丰富的先验信息来规范解空间。由于其令人印象深刻的经验成功，基于分数的扩散模型已经成为图像重建中一个具有吸引力的表达先验的候选者。为了一次性容纳多样的任务，开发将图像先验分布的无条件评分函数与灵活的前向模型选择相结合的高效、一致和鲁棒算法非常重要。这项工作开发了一个算法框架，用于将基于得分的扩散模型作为通用非线性逆的表达数据先验。

    arXiv:2403.17042v1 Announce Type: cross  Abstract: In a great number of tasks in science and engineering, the goal is to infer an unknown image from a small number of measurements collected from a known forward model describing certain sensing or imaging modality. Due to resource constraints, this task is often extremely ill-posed, which necessitates the adoption of expressive prior information to regularize the solution space. Score-based diffusion models, due to its impressive empirical success, have emerged as an appealing candidate of an expressive prior in image reconstruction. In order to accommodate diverse tasks at once, it is of great interest to develop efficient, consistent and robust algorithms that incorporate {\em unconditional} score functions of an image prior distribution in conjunction with flexible choices of forward models.   This work develops an algorithmic framework for employing score-based diffusion models as an expressive data prior in general nonlinear invers
    
[^12]: 通过基于区域稳定性的多元高斯逼近改进随机森林

    Multivariate Gaussian Approximation for Random Forest via Region-based Stabilization

    [https://arxiv.org/abs/2403.09960](https://arxiv.org/abs/2403.09960)

    该论文通过基于区域稳定性的方法，推导出了随机森林预测的高斯逼近界限，并建立了适用于各种相关统计问题的概率结果。

    

    我们在给定由泊松过程产生的一组训练点的情况下，推导了随机森林预测的高斯逼近界限，假设数据生成过程存在相当温和的正则性假设。我们的方法基于一个关键观察：随机森林的预测满足一定的称为基于区域稳定性的几何属性。在为随机森林开发结果的过程中，我们还为基于区域稳定的泊松过程的一般泛函建立了一个概率结果，这可能是独立感兴趣的。这一普遍结果利用了Malliavin-Stein方法，并且可能适用于各种相关的统计问题。

    arXiv:2403.09960v1 Announce Type: cross  Abstract: We derive Gaussian approximation bounds for random forest predictions based on a set of training points given by a Poisson process, under fairly mild regularity assumptions on the data generating process. Our approach is based on the key observation that the random forest predictions satisfy a certain geometric property called region-based stabilization. In the process of developing our results for the random forest, we also establish a probabilistic result, which might be of independent interest, on multivariate Gaussian approximation bounds for general functionals of Poisson process that are region-based stabilizing. This general result makes use of the Malliavin-Stein method, and is potentially applicable to various related statistical problems.
    
[^13]: 将统计学习理论应用于深度学习

    Applying statistical learning theory to deep learning

    [https://arxiv.org/abs/2311.15404](https://arxiv.org/abs/2311.15404)

    深度学习的理论方面仍不清楚，本研究通过将统计学习理论应用于深度学习，探讨了不同架构在基于梯度方法训练时可能导致的归纳偏差，并详细研究了隐含偏差的数量化表示。

    

    虽然统计学习理论提供了一个理解监督学习的坚实框架，但深度学习的许多理论方面仍然不清楚，特别是在使用基于梯度的方法进行训练时，不同的架构如何导致归纳偏差。这些讲座的目标是从学习理论的角度提供了解深度学习时出现的一些主要问题的概览。在简要回顾统计学习理论和随机优化之后，我们讨论了在良性过拟合的背景下的隐含偏差。然后，我们对镜像下降算法进行一般性描述，展示了我们如何在给定学习问题的参数空间和相应的函数空间之间来回移动，以及学习问题的几何性质如何可以用度量张量表示。在这个框架的基础上，我们对数量化隐含偏差的具体研究进行了详细探讨。

    arXiv:2311.15404v2 Announce Type: replace  Abstract: Although statistical learning theory provides a robust framework to understand supervised learning, many theoretical aspects of deep learning remain unclear, in particular how different architectures may lead to inductive bias when trained using gradient based methods. The goal of these lectures is to provide an overview of some of the main questions that arise when attempting to understand deep learning from a learning theory perspective. After a brief reminder on statistical learning theory and stochastic optimization, we discuss implicit bias in the context of benign overfitting. We then move to a general description of the mirror descent algorithm, showing how we may go back and forth between a parameter space and the corresponding function space for a given learning problem, as well as how the geometry of the learning problem may be represented by a metric tensor. Building on this framework, we provide a detailed study of the im
    
[^14]: 具有Fisher度量的黎曼拉普拉斯逼近

    Riemannian Laplace Approximation with the Fisher Metric

    [https://arxiv.org/abs/2311.02766](https://arxiv.org/abs/2311.02766)

    黎曼拉普拉斯逼近的新方法利用Fisher度量提供更丰富的逼近族，解决了在无限数据极限下先前方法度量选择不当导致逼近过于狭窄和有偏的问题。

    

    Laplace方法用高斯分布在其模式处对目标密度进行近似。基于Bernstein-von Mises定理，它在贝叶斯推断中是计算效率高且渐近准确的，但对于复杂的目标和有限数据后验，它往往是一种过于粗糙的近似。最近对Laplace逼近的一般化是根据选择的黎曼几何对高斯近似进行转换，提供了更丰富的近似族，同时保持计算效率。然而，正如本文所示，其性质严重依赖于所选择的度量，实际上，在先前研究中采用的度量导致的逼近即使在无限数据量的极限下也过于狭窄且存在偏差。我们通过进一步发展逼近族，推导出两种在无限数据极限下精确的替代变种，扩展了理论分析。

    arXiv:2311.02766v3 Announce Type: replace  Abstract: Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the
    
[^15]: 一个面向层次化建模的分布无关混合整数优化方法

    A distribution-free mixed-integer optimization approach to hierarchical modelling of clustered and longitudinal data

    [https://arxiv.org/abs/2302.03157](https://arxiv.org/abs/2302.03157)

    该论文提出了一个面向层次化数据建模的分布无关混合整数优化方法，通过在线性混合效应模型中选取群体特性来提高解决问题的效率，并在生成稀疏解方面表现出更高的预测能力。

    

    最近混合整数优化（MIO）算法的进展，结合硬件增强，大大加快了解决MIO问题的速度。这些策略已被用于最优子集选择，特别是在线性回归中在给定$n$观测的情况下选择$k$个特征中的$p$个。在本文中，我们将这种方法扩展到促进群集感知回归，选择$LMM$模型的$K$个群集中的$\lambda$个，每个群集有$n_k$个观测。通过对多种合成和真实数据集的全面测试，我们展示了我们的方法可以在几分钟内高效地解决问题。通过数值实验，我们还展示了MIO方法在生成具有高预测能力的稀疏解方面优于高斯分布和拉普拉斯分布LMM。传统的LMM通常假设聚类效果为

    arXiv:2302.03157v2 Announce Type: replace-cross  Abstract: Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired with hardware enhancements, have led to significant speedups in resolving MIO problems. These strategies have been utilized for optimal subset selection, specifically for choosing $k$ features out of $p$ in linear regression given $n$ observations. In this paper, we broaden this method to facilitate cluster-aware regression, where selection aims to choose $\lambda$ out of $K$ clusters in a linear mixed effects (LMM) model with $n_k$ observations for each cluster. Through comprehensive testing on a multitude of synthetic and real datasets, we exhibit that our method efficiently solves problems within minutes. Through numerical experiments, we also show that the MIO approach outperforms both Gaussian- and Laplace-distributed LMMs in terms of generating sparse solutions with high predictive power. Traditional LMMs typically assume that clustering effects ar
    
[^16]: 利用深度学习优化逆变器的电压/无功控制规则设计

    Optimal Design of Volt/VAR Control Rules of Inverters using Deep Learning

    [https://arxiv.org/abs/2211.09557](https://arxiv.org/abs/2211.09557)

    使用深度学习重新制定混合整数非线性规划问题，以优化逆变器的电压/无功控制规则设计。

    

    配电网面临由分布式能源资源（DERs）可变功率注入引起的电压快速波动的挑战。为了调节电压，IEEE标准1547建议每个DER根据分段线性的电压/无功控制规则注入无功功率。尽管该标准建议了默认形状，但规则可以按母线自定义。最优规则设计（ORD）的任务具有挑战性，因为电压/无功规则引入非线性动态，并存在稳定性和稳态电压轮廓之间的折衷。 ORD被制定为混合整数非线性规划（MINLP），但在问题规模上并不理想。为了找到更高效的解决方案，我们将ORD重新制定为深度学习问题。其思想是设计一个模拟电压/无功动态的DNN。DNN以电网场景为输入，规则参数为权重，输出平衡电压。通过训练可以找到最佳规则参数。

    arXiv:2211.09557v2 Announce Type: replace-cross  Abstract: Distribution grids are challenged by rapid voltage fluctuations induced by variable power injections from distributed energy resources (DERs). To regulate voltage, the IEEE Standard 1547 recommends each DER inject reactive power according to piecewise-affine Volt/VAR control rules. Although the standard suggests a default shape, the rule can be customized per bus. This task of optimal rule design (ORD) is challenging as Volt/VAR rules introduce nonlinear dynamics, and lurk trade-offs between stability and steady-state voltage profiles. ORD is formulated as a mixed-integer nonlinear program (MINLP), but scales unfavorably with the problem size. Towards a more efficient solution, we reformulate ORD as a deep learning problem. The idea is to design a DNN that emulates Volt/VAR dynamics. The DNN takes grid scenarios as inputs, rule parameters as weights, and outputs equilibrium voltages. Optimal rule parameters can be found by trai
    
[^17]: 差分私有多变量中位数

    Differentially private multivariate medians

    [https://arxiv.org/abs/2210.06459](https://arxiv.org/abs/2210.06459)

    差分私有多变量中位数的有限样本性能保证为常用深度函数提供了尖锐的结果，表明重尾位置估计的成本超过了隐私保护成本。

    

    现代数据分析需要满足严格隐私保证的统计工具。众所周知，对污染的鲁棒性与差分隐私有关。尽管如此，使用多元中位数进行差分私有和鲁棒的多元位置估计尚未得到系统研究。我们为差分私有多元深度中位数开发了新颖的有限样本性能保证，这些保证基本上是尖锐的。我们的结果涵盖了常用的深度函数，如半平面（或Tukey）深度，空间深度和集成双深度。我们展示了在柯西边际下，重尾位置估计的代价超过了隐私的代价。我们在高达d = 100的维度上使用高斯污染模型进行了数值演示，并将其与最先进的私有均值估计算法进行了比较。作为我们研究的一个副产品，

    arXiv:2210.06459v2 Announce Type: replace-cross  Abstract: Statistical tools which satisfy rigorous privacy guarantees are necessary for modern data analysis. It is well-known that robustness against contamination is linked to differential privacy. Despite this fact, using multivariate medians for differentially private and robust multivariate location estimation has not been systematically studied. We develop novel finite-sample performance guarantees for differentially private multivariate depth-based medians, which are essentially sharp. Our results cover commonly used depth functions, such as the halfspace (or Tukey) depth, spatial depth, and the integrated dual depth. We show that under Cauchy marginals, the cost of heavy-tailed location estimation outweighs the cost of privacy. We demonstrate our results numerically using a Gaussian contamination model in dimensions up to d = 100, and compare them to a state-of-the-art private mean estimation algorithm. As a by-product of our inv
    
[^18]: 具有方差减少的半光滑牛顿随机近端点算法

    A Semismooth Newton Stochastic Proximal Point Algorithm with Variance Reduction

    [https://arxiv.org/abs/2204.00406](https://arxiv.org/abs/2204.00406)

    提出了一种具有方差减少机制的半光滑牛顿随机近端点算法，通过在不精确的框架下解决近端点更新，实现了对弱凸性、复合优化问题的有效求解。

    

    我们为一类弱凸性、复合优化问题开发了一个可实施的随机近端点（SPP）方法。所提出的随机近端点算法融合了方差减少机制，由于采用了不精确的半光滑牛顿框架来求解得到的SPP更新。我们建立了详细的收敛性结果，考虑了SPP步骤的不精确性，并符合（近端）随机方差减少梯度方法的现有收敛保证。数值实验表明，所提出的算法与其他最先进的方法竞争优势，并在步长选择方面具有更高的稳健性。

    arXiv:2204.00406v3 Announce Type: replace-cross  Abstract: We develop an implementable stochastic proximal point (SPP) method for a class of weakly convex, composite optimization problems. The proposed stochastic proximal point algorithm incorporates a variance reduction mechanism and the resulting SPP updates are solved using an inexact semismooth Newton framework. We establish detailed convergence results that take the inexactness of the SPP steps into account and that are in accordance with existing convergence guarantees of (proximal) stochastic variance-reduced gradient methods. Numerical experiments show that the proposed algorithm competes favorably with other state-of-the-art methods and achieves higher robustness with respect to the step size selection.
    
[^19]: 带可变系数的贝叶斯数据驱动的偏微分方程发现

    Bayesian data-driven discovery of partial differential equations with variable coefficients

    [https://arxiv.org/abs/2102.01432](https://arxiv.org/abs/2102.01432)

    提出了一种用于具有可变系数的偏微分方程发现的先进贝叶斯稀疏学习算法，通过阈值贝叶斯组Lasso回归和Gibbs采样器提高了稳健性和减轻了计算负担

    

    偏微分方程（PDEs）的发现是应用科学和工程的重要任务。然而，数据驱动的PDEs发现通常具有挑战性，主要是由于所发现方程对噪声的敏感性以及模型选择的复杂性。在本工作中，我们提出了一种先进的贝叶斯稀疏学习算法，用于具有可变系数的PDE发现，尤其是当系数在空间或时间上具有相关性时。具体来说，我们应用了具有尖峰和平板先验的阈值贝叶斯组Lasso回归（tBGL-SS），并利用Gibbs采样器来对PDE系数进行贝叶斯后验估计。这种方法不仅增强了点估计的稳健性并具有有效的不确定性量化，而且通过将系数阈值集成为近似MCMC方法，减轻了来自贝叶斯推断的计算负担。

    arXiv:2102.01432v2 Announce Type: replace-cross  Abstract: The discovery of Partial Differential Equations (PDEs) is an essential task for applied science and engineering. However, data-driven discovery of PDEs is generally challenging, primarily stemming from the sensitivity of the discovered equation to noise and the complexities of model selection. In this work, we propose an advanced Bayesian sparse learning algorithm for PDE discovery with variable coefficients, predominantly when the coefficients are spatially or temporally dependent. Specifically, we apply threshold Bayesian group Lasso regression with a spike-and-slab prior (tBGL-SS) and leverage a Gibbs sampler for Bayesian posterior estimation of PDE coefficients. This approach not only enhances the robustness of point estimation with valid uncertainty quantification but also relaxes the computational burden from Bayesian inference through the integration of coefficient thresholds as an approximate MCMC method. Moreover, from
    
[^20]: PPI++:高效的预测驱动推理方法

    PPI++: Efficient Prediction-Powered Inference. (arXiv:2311.01453v1 [stat.ML])

    [http://arxiv.org/abs/2311.01453](http://arxiv.org/abs/2311.01453)

    PPI++是一种高效的预测驱动推理方法，通过自动调整预测质量来改善经典区间的计算置信区间的计算效率和统计效率。

    

    我们提出了PPI++：一种基于小型标记数据集和通常比较大的机器学习预测数据集的计算轻量级的估计和推理方法。该方法能够自动适应可用预测的质量，产生易于计算的置信区间 - 对于任意维度的参数 - 总是能够在只使用标记数据的情况下改善经典区间。PPI++基于预测驱动推理（PPI），针对相同的问题场景，提高了计算和统计效率。真实和合成实验证明了所提出的改进的优势。

    We present PPI++: a computationally lightweight methodology for estimation and inference based on a small labeled dataset and a typically much larger dataset of machine-learning predictions. The methods automatically adapt to the quality of available predictions, yielding easy-to-compute confidence sets -for parameters of any dimensionality -- that always improve on classical intervals using only the labeled data. PPI++ builds on prediction-powered inference (PPI), which targets the same problem setting, improving its computational and statistical efficiency. Real and synthetic experiments demonstrate the benefits of the proposed adaptations.
    
[^21]: Entropy-MCMC: 轻松从平坦盆地进行采样

    Entropy-MCMC: Sampling from Flat Basins with Ease. (arXiv:2310.05401v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2310.05401](http://arxiv.org/abs/2310.05401)

    本文提出了一种Entropy-MCMC的方法，通过引入一个辅助的引导变量来在平坦盆地中进行采样，以解决深度神经网络后验分布的多模态问题，并证明了该方法的收敛性。

    

    贝叶斯深度学习依赖于对后验分布的质量估计。然而，深度神经网络的后验分布在性质上是高度多模态的，局部模式表现出不同的泛化性能。在有限的计算资源下，从原始后验分布中进行采样可能会导致次优性能，因为一些样本可能会陷入“坏”模式并出现过拟合。基于观察到低泛化误差的“好”模式通常存在于能量景观的平坦盆地中，我们提出通过偏置采样朝向这些平坦区域的后验。具体而言，我们引入了一个辅助引导变量，其稳态分布类似于平滑后验分布，并且没有尖锐的模态，以引导MCMC采样器在平坦的盆地中采样。通过将此引导变量与模型参数相结合，我们创建了一个简单的联合分布，可以在最小计算开销下实现高效采样。我们证明了我们的元算法的收敛性。

    Bayesian deep learning counts on the quality of posterior distribution estimation. However, the posterior of deep neural networks is highly multi-modal in nature, with local modes exhibiting varying generalization performance. Given a practical budget, sampling from the original posterior can lead to suboptimal performance, as some samples may become trapped in "bad" modes and suffer from overfitting. Leveraging the observation that "good" modes with low generalization error often reside in flat basins of the energy landscape, we propose to bias sampling on the posterior toward these flat regions. Specifically, we introduce an auxiliary guiding variable, the stationary distribution of which resembles a smoothed posterior free from sharp modes, to lead the MCMC sampler to flat basins. By integrating this guiding variable with the model parameter, we create a simple joint distribution that enables efficient sampling with minimal computational overhead. We prove the convergence of our met
    
[^22]: 随机森林中的预测误差估计

    Prediction Error Estimation in Random Forests. (arXiv:2309.00736v1 [stat.ML])

    [http://arxiv.org/abs/2309.00736](http://arxiv.org/abs/2309.00736)

    本文通过量化评估分类随机森林的误差估计方法，发现随机森林的预测误差估计比平均预测误差更接近真实误差率，并且这一结果适用于不同的误差估计策略。

    

    本文定量评估了分类随机森林的误差估计。在Bates等人（2023年）建立的初步理论框架的基础上，从理论和经验角度探讨了随机森林中常见的各种误差估计方法在真实误差率和期望误差率方面的情况。我们发现，在分类情况下，随机森林的预测误差估计平均更接近真实误差率，而不是平均预测误差。与Bates等人（2023年）对逻辑回归的研究结果相反。我们进一步证明，这个结果适用于交叉验证、自举和数据划分等不同的误差估计策略。

    In this paper, error estimates of classification Random Forests are quantitatively assessed. Based on the initial theoretical framework built by Bates et al. (2023), the true error rate and expected error rate are theoretically and empirically investigated in the context of a variety of error estimation methods common to Random Forests. We show that in the classification case, Random Forests' estimates of prediction error is closer on average to the true error rate instead of the average prediction error. This is opposite the findings of Bates et al. (2023) which were given for logistic regression. We further show that this result holds across different error estimation strategies such as cross-validation, bagging, and data splitting.
    
[^23]: 贝索夫先验在贝叶斯逆问题中的时空应用

    Spatiotemporal Besov Priors for Bayesian Inverse Problems. (arXiv:2306.16378v1 [stat.ME])

    [http://arxiv.org/abs/2306.16378](http://arxiv.org/abs/2306.16378)

    本研究通过将贝索夫过程推广到时空领域，以更好地处理贝叶斯逆问题中的时空重建。通过替换随机系数，该方法能够保持边缘特征并模拟动态变化图像的时空相关性。

    

    近年来，科学技术的快速发展促使对捕捉数据特征（如突变或明显对比度）的适当统计工具的需求。许多数据科学应用需要从具有不连续性或奇异性的时间相关对象序列中进行时空重建，如带有边缘的动态计算机断层影像（CT）图像。传统的基于高斯过程（GP）的方法可能无法提供令人满意的解决方案，因为它们往往提供过度平滑的先验候选。最近，通过随机系数的小波展开定义的贝索夫过程（BP）被提出作为这类贝叶斯逆问题的更合适的先验。BP在成像分析中表现出优于GP的性能，能够产生保留边缘特征的重建结果，但没有自动地纳入动态变化图像中的时间相关性。本文将BP推广到时空领域（STBP），通过在小波展开中替换随机系数，实现了时空相关性的建模。

    Fast development in science and technology has driven the need for proper statistical tools to capture special data features such as abrupt changes or sharp contrast. Many applications in the data science seek spatiotemporal reconstruction from a sequence of time-dependent objects with discontinuity or singularity, e.g. dynamic computerized tomography (CT) images with edges. Traditional methods based on Gaussian processes (GP) may not provide satisfactory solutions since they tend to offer over-smooth prior candidates. Recently, Besov process (BP) defined by wavelet expansions with random coefficients has been proposed as a more appropriate prior for this type of Bayesian inverse problems. While BP outperforms GP in imaging analysis to produce edge-preserving reconstructions, it does not automatically incorporate temporal correlation inherited in the dynamically changing images. In this paper, we generalize BP to the spatiotemporal domain (STBP) by replacing the random coefficients in 
    
[^24]: Omega: 乐观EMA Gradients

    Omega: Optimistic EMA Gradients. (arXiv:2306.07905v1 [cs.LG])

    [http://arxiv.org/abs/2306.07905](http://arxiv.org/abs/2306.07905)

    Omega是一种优化算法，通过加入历史梯度EMA来减轻噪声的影响并在随机游戏上表现更佳。

    

    随着GAN和对抗性训练的进步，随机min-max优化受到了机器学习界的关注。尽管确定性状态下的博弈优化已经相当好地理解了，但在随机状态下仍存在一些问题。最近的研究表明，像乐观梯度这样的随机梯度下降-上升方法对噪声非常敏感或者会导致失败。虽然存在替代策略，但这些策略可能成本过高。我们引入了Omega，一种具有类似于乐观更新的方法，通过在其更新规则中合并历史梯度的EMA来减轻噪声的影响。我们还探讨了一种包含动量的该算法的变体。虽然我们没有提供收敛性保证，但我们在随机游戏上的实验表明，当应用于线性玩家时，Omega优于乐观梯度方法。

    Stochastic min-max optimization has gained interest in the machine learning community with the advancements in GANs and adversarial training. Although game optimization is fairly well understood in the deterministic setting, some issues persist in the stochastic regime. Recent work has shown that stochastic gradient descent-ascent methods such as the optimistic gradient are highly sensitive to noise or can fail to converge. Although alternative strategies exist, they can be prohibitively expensive. We introduce Omega, a method with optimistic-like updates that mitigates the impact of noise by incorporating an EMA of historic gradients in its update rule. We also explore a variation of this algorithm that incorporates momentum. Although we do not provide convergence guarantees, our experiments on stochastic games show that Omega outperforms the optimistic gradient method when applied to linear players.
    
[^25]: 使用机器学习的形成能量预测方法进行猎枪晶体结构预测

    Shotgun crystal structure prediction using machine-learned formation energies. (arXiv:2305.02158v1 [physics.comp-ph])

    [http://arxiv.org/abs/2305.02158](http://arxiv.org/abs/2305.02158)

    本研究使用机器学习方法在多个结构预测标准测试中精确识别含有100个以上原子的许多材料的全局最小结构，并以单次能量评估为基础，取代了重复的第一原理能量计算过程。

    

    可以通过找到原子构型能量曲面的全局或局部极小值来预测组装原子的稳定或亚稳定晶体结构。通常，这需要重复的第一原理能量计算，这在包含30个以上原子的大型系统中是不实际的。本研究使用简单但功能强大的机器学习工作流，使用机器学习辅助第一原理能量计算，对大量虚拟创建的晶体结构进行非迭代式单次筛选，从而在解决晶体结构预测问题方面取得了重大进展。

    Stable or metastable crystal structures of assembled atoms can be predicted by finding the global or local minima of the energy surface with respect to the atomic configurations. Generally, this requires repeated first-principles energy calculations that are impractical for large systems, such as those containing more than 30 atoms in the unit cell. Here, we have made significant progress in solving the crystal structure prediction problem with a simple but powerful machine-learning workflow; using a machine-learning surrogate for first-principles energy calculations, we performed non-iterative, single-shot screening using a large library of virtually created crystal structures. The present method relies on two key technical components: transfer learning, which enables a highly accurate energy prediction of pre-relaxed crystalline states given only a small set of training samples from first-principles calculations, and generative models to create promising and diverse crystal structure
    
[^26]: 用于因果中介分析中具有治疗不服从性的识别和倍增稳健估计

    Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance. (arXiv:2304.10025v1 [stat.ME])

    [http://arxiv.org/abs/2304.10025](http://arxiv.org/abs/2304.10025)

    本文针对治疗不服从性提出了一种半参数框架来评估因果中介效应，提出了一组假设来识别自然中介效应并推导出成倍稳健估计器。

    

    在实验和观察研究中，人们通常对了解干预方案如何改善最终结果的潜在机制感兴趣。因果中介分析旨在达到此目的，但主要限于治疗完全服从的情况，只有少数情况需要排除限制。在本文中，我们建立了一个半参数框架，用于在无需排除限制的情况下评估具有治疗不服从性的因果中介效应。我们提出了一组假设来识别整个研究人群的自然中介效应，并进一步针对由潜在服从行为特征化的亚人群中的主要自然中介效应进行识别。我们推导出了主要自然中介效应估计量的有效影响函数，这激励了一组倍增稳健估计器进行推论。这些被识别估计量的半参数效率理论。

    In experimental and observational studies, there is often interest in understanding the potential mechanism by which an intervention program improves the final outcome. Causal mediation analyses have been developed for this purpose but are primarily restricted to the case of perfect treatment compliance, with a few exceptions that require exclusion restriction. In this article, we establish a semiparametric framework for assessing causal mediation in the presence of treatment noncompliance without exclusion restriction. We propose a set of assumptions to identify the natural mediation effects for the entire study population and further, for the principal natural mediation effects within subpopulations characterized by the potential compliance behaviour. We derive the efficient influence functions for the principal natural mediation effect estimands, which motivate a set of multiply robust estimators for inference. The semiparametric efficiency theory for the identified estimands is der
    
[^27]: 对基于扩散的生成模型的最优控制视角

    An optimal control perspective on diffusion-based generative modeling. (arXiv:2211.01364v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01364](http://arxiv.org/abs/2211.01364)

    本文建立了随机最优控制与基于扩散的生成模型之间的联系，推导了用于控制潜在SDE边际密度演化的汉密尔顿-雅可比-贝尔曼方程，并将生成建模表述为对合适度量之间Kullback-Leibler散度的最小化。此外，作者还开发了一种新型扩散方法用于采样非归一化密度。

    

    我们建立了随机最优控制与基于随机微分方程（SDE）的生成模型之间的联系，例如最近发展起来的扩散概率模型。特别地，我们推导出一个汉密尔顿-雅可比-贝尔曼方程，用于控制潜在的SDE边际密度的演化。这个视角允许将最优控制理论的方法应用于生成建模中。首先，我们展示了证据下界是控制理论中广为人知的验证定理的直接结果。此外，我们可以将基于扩散的生成建模表述为路径空间中合适度量之间的Kullback-Leibler散度的最小化。最后，我们开发了一种从非归一化密度中进行采样的新型扩散方法，这在统计学和计算科学中经常出现的问题。我们证明了我们的时序反向扩散采样器（DIS）可以胜过其他基于扩散的采样方法。

    We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton-Jacobi-Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback-Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approache
    

