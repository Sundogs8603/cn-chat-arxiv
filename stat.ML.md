# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning.](http://arxiv.org/abs/2308.14705) | 本文提出了一个新的自助培训体制，利用独立子网络的集成和新的损失函数来提高自助的鲁棒性表示学习的效率和多样性。 |
| [^2] | [Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences.](http://arxiv.org/abs/2308.14555) | 本文研究了循环神经网络在遍历数据序列上训练时的核极限，利用数学方法对其渐近特性进行了描述，并证明了RNN收敛到与随机代数方程的不动点耦合的无穷维ODE的解。这对于理解和改进循环神经网络具有重要意义。 |
| [^3] | [Deep graphical regression for jointly moderate and extreme Australian wildfires.](http://arxiv.org/abs/2308.14547) | 该论文介绍了一种利用深度图形回归方法来联合调节和预测澳大利亚野火的新方法。研究结果表明，对于火灾的全分布建模是非常关键的，因为极端野火可能导致巨大的影响，而小规模和中等规模火灾仍然会对当地社区和生态系统造成重大破坏。 |
| [^4] | [Spectral Estimators for Structured Generalized Linear Models via Approximate Message Passing.](http://arxiv.org/abs/2308.14507) | 本论文研究了针对广义线性模型的参数估计问题，提出了一种通过谱估计器进行预处理的方法。通过对测量进行特征协方差矩阵Σ表示，分析了谱估计器在结构化设计中的性能，并确定了最优预处理以最小化样本数量。 |
| [^5] | [Some issues in robust clustering.](http://arxiv.org/abs/2308.14478) | 关于鲁棒聚类，讨论了高斯混合模型、异常值定义、异常值与聚类的模糊性、鲁棒聚类与聚类数目估计的相互作用以及聚类稳定性衡量的不足。 |
| [^6] | [Identifying topology of leaky photonic lattices with machine learning.](http://arxiv.org/abs/2308.14407) | 本研究展示了利用机器学习技术，通过仅使用局部测量数据，可以在漏电光子晶格中准确识别拓扑相，避免了复杂的相位重构步骤。 |
| [^7] | [Biclustering Methods via Sparse Penalty.](http://arxiv.org/abs/2308.14388) | 本文提出了一种基于稀疏惩罚的双聚类方法，主要关注了SSVD方法，并尝试了一种新的稀疏惩罚方法。模拟研究结果表明混合的Prenet惩罚对于非重叠数据非常有效。 |
| [^8] | [Buy when? Survival machine learning model comparison for purchase timing.](http://arxiv.org/abs/2308.14343) | 本文研究了购买时机的生存机器学习模型，在考虑了性别、收入、位置、购买历史、在线行为、兴趣、促销折扣和客户体验等因素的影响下，进行了个人购买决策时间的预测。 |
| [^9] | [Improved learning theory for kernel distribution regression with two-stage sampling.](http://arxiv.org/abs/2308.14335) | 本文改进了核分布回归的学习理论，引入了新的近无偏条件，并提供了关于两阶段采样效果的新误差界。 |
| [^10] | [Predictive Sparse Manifold Transform.](http://arxiv.org/abs/2308.14207) | 预测稀疏流形变换是一个简约、可解释且生物可行的框架，用于学习和预测自然动态。它通过稀疏编码和流形学习实现了更好的预测性能。 |
| [^11] | [Hypergraph Structure Inference From Data Under Smoothness Prior.](http://arxiv.org/abs/2308.14172) | 本文提出了一种光滑性先验方法，用于从节点特征中推断超图的结构，并捕捉数据内在的关系。该方法不需要标记数据作为监督，能够推断出每个潜在超边的概率。 |
| [^12] | [Integrated Variational Fourier Features for Fast Spatial Modelling with Gaussian Processes.](http://arxiv.org/abs/2308.14142) | 本论文提出了一种综合变分傅里叶特征的方法，可以对广泛的平稳协方差函数进行快速空间建模，相比其他方法具有更高的性能和加速效果。 |
| [^13] | [A Bayesian Non-parametric Approach to Generative Models: Integrating Variational Autoencoder and Generative Adversarial Networks using Wasserstein and Maximum Mean Discrepancy.](http://arxiv.org/abs/2308.14048) | 本研究提出了一种融合生成对抗网络和变分自编码器的贝叶斯非参数方法，通过在损失函数中使用Wasserstein和最大均值差异度量，实现了对潜在空间的有效学习，并能够生成多样且高质量的样本。 |
| [^14] | [Online GentleAdaBoost -- Technical Report.](http://arxiv.org/abs/2308.14004) | 该论文研究了在线版的GentleAdaboost算法，通过在线方式将弱分类器与强分类器结合，提出了一种通过线搜索将批处理方法扩展为在线方法的方法，并与其他在线方法在各种基准数据集上进行了对比。 |
| [^15] | [A transport approach to sequential simulation-based inference.](http://arxiv.org/abs/2308.13940) | 提出了一种新的基于运输的方法，用于高效地进行静态模型参数的顺序贝叶斯推断。该方法可以处理包括干扰参数的复杂噪声模型，并且适用于仅作为黑箱的正向模型。数值应用表明该方法在使用电导率测量来表征冰厚度的情况下是有效的。 |
| [^16] | [Learning variational autoencoders via MCMC speed measures.](http://arxiv.org/abs/2308.13731) | 本研究提出了一种基于熵的短期调整MCMC链的方法，用于在优化更紧的变分边界的同时，适应深度潜变量模型的提案分布。实验证明，这种方法能够使模型得到更高的保留对数似然和改进的生成性能。 |
| [^17] | [SGMM: Stochastic Approximation to Generalized Method of Moments.](http://arxiv.org/abs/2308.13564) | 我们提出了一种新的随机广义矩方法（SGMM），用于估计和推断矩限制模型。该方法具有快速和可扩展的实时处理能力，并且能够处理大规模和在线数据集。 |
| [^18] | [Federated Linear Bandit Learning via Over-the-Air Computation.](http://arxiv.org/abs/2308.13298) | 本研究针对联邦线性赌博学习提出了一种通过无线计算的方案，以减少通信开销。通过在噪声衰落信道上进行的模拟信号传输，我们的方案在降低累积遗憾方面表现出竞争力。 |
| [^19] | [MKL-$L_{0/1}$-SVM.](http://arxiv.org/abs/2308.12016) | 本文提出了一种多核学习的支持向量机框架(MKL-$L_{0/1}$-SVM)，通过开发快速的ADMM求解器处理非凸非光滑的优化问题，并在实验中展示了与领先方法相当的性能。 |
| [^20] | [Wasserstein Geodesic Generator for Conditional Distributions.](http://arxiv.org/abs/2308.10145) | 通过Wasserstein几何生成器学习条件分布，生成给定特定标签的样本。使用最优输运理论提出的方法能学习观察域的条件分布和它们之间的最优输运映射。在人脸图像数据上的实验验证了该方法的有效性。 |
| [^21] | [Dyadic Reinforcement Learning.](http://arxiv.org/abs/2308.07843) | 该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。 |
| [^22] | [Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis.](http://arxiv.org/abs/2307.15424) | 本文综述了近期合成数据生成的深度生成模型发展，重点关注表格数据集。通过使用深度生成模型，可以有效地生成隐私敏感数据的合成数据，并解决数据归一化、隐私和评估等方面的挑战。 |
| [^23] | [Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?.](http://arxiv.org/abs/2306.10590) | 本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。 |
| [^24] | [Interpolation for Robust Learning: Data Augmentation on Wasserstein Geodesics.](http://arxiv.org/abs/2302.02092) | 本文提出一种通过插值训练数据分布来提升模型鲁棒性的方法。通过寻找连接不同类别子人口分布的测地线上的最坏情况Wasserstein barycenter来增加数据，并对模型进行正则化以获得更平滑的性能。我们的方法在多个数据集上进行了实验证实，并改进了基线的可证明鲁棒性和经验鲁棒性。该研究从Wasserstein测地线的角度探索了模型鲁棒性。 |
| [^25] | [Invariant Lipschitz Bandits: A Side Observation Approach.](http://arxiv.org/abs/2212.07524) | 本文研究了不变Lipschitz赌徒设置，并提出了一种名为\texttt{UniformMesh-N}的算法。使用侧面观察的方法，证明了改进的遗憾上界。 |
| [^26] | [TuneUp: A Simple Improved Training Strategy for Graph Neural Networks.](http://arxiv.org/abs/2210.14843) | TuneUp是一种简单的基于课程的训练策略，用于改进图神经网络在难以预测的尾节点上的泛化性能。 |
| [^27] | [Sufficient Invariant Learning for Distribution Shift.](http://arxiv.org/abs/2210.13533) | 本文研究了分布转移情况下的充分不变学习，观察到之前的工作只学习了部分不变特征，我们提出了学习充分不变特征的重要性，并指出在分布转移时，从训练集中学习的部分不变特征可能不适用于测试集，限制了性能提升。 |
| [^28] | [Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning.](http://arxiv.org/abs/2208.06193) | 本文提出了一种将策略表示为扩散模型的方法，用于离线强化学习。我们引入了Diffusion Q-learning（Diffusion-QL），利用条件扩散模型表示策略，并通过最大化动作值来寻求接近行为策略的最优动作。 |
| [^29] | [Diffusion-GAN: Training GANs with Diffusion.](http://arxiv.org/abs/2206.02262) | Diffusion-GAN提出了一种新颖的GAN框架，通过使用前向扩散链生成高斯混合分布的实例噪声，在训练中解决了GAN稳定性的问题。 |
| [^30] | [Adaptive Experimentation in the Presence of Exogenous Nonstationary Variation.](http://arxiv.org/abs/2202.09036) | 本论文研究了在外生非平稳变化存在下的自适应实验。提出了无偏汤普森抽样(DTS)算法来解决多臂老虎机算法在面对非平稳外生因素时的脆弱性，DTS算法通过控制背景信息预测一个臂的人口层级表现，并提供了实验内和实验后的遗憾界限，显示了其对外生变异的弹性。 |
| [^31] | [Continuous-time stochastic gradient descent for optimizing over the stationary distribution of stochastic differential equations.](http://arxiv.org/abs/2202.06637) | 我们提出了一种连续时间随机梯度下降算法用于优化随机微分方程模型的平稳分布。算法通过估计平稳分布的梯度，并使用正向传播进行连续更新参数，实现收敛至最陡下降方向。我们严格证明了在线正向传播算法在线性模型上的收敛性，并在非线性示例上进行了数值验证。 |
| [^32] | [Stochastic coordinate transformations with applications to robust machine learning.](http://arxiv.org/abs/2110.01729) | 本文提出了一种利用随机坐标变换进行异常检测的新方法，该方法通过层级张量积展开来逼近随机过程，并通过训练机器学习分类器对投影系数进行检测。在基准数据集上的实验表明，该方法胜过现有的最先进方法。 |
| [^33] | [Meta-Calibration: Learning of Model Calibration Using Differentiable Expected Calibration Error.](http://arxiv.org/abs/2106.09613) | 本论文提出了元校准框架，通过引入可微的期望校准误差代理指标和元学习框架，实现了对模型校准质量的直接优化。实验证明，该方法能够达到与现有校准方法相竞争的性能表现。该框架为进一步解决校准问题提供了新的思路和工具。 |
| [^34] | [Functional optimal transport: map estimation and domain adaptation for functional data.](http://arxiv.org/abs/2102.03895) | 这篇论文介绍了在函数空间上解决分布最优输运问题的方法，通过使用Hilbert-Schmidt算子将函数域之间的随机映射进行表示。这种方法对于处理函数数据的机器学习任务非常有用。 |
| [^35] | [On the Estimation of Derivatives Using Plug-in Kernel Ridge Regression Estimators.](http://arxiv.org/abs/2006.01350) | 本文提出了一种插值核岭回归（KRR）估计器，可广泛适用于非参数回归中的多维支持和任意混合偏导数，并且具有较强的误差界。 |
| [^36] | [Learning to Generate Time Series Conditioned Graphs with Generative Adversarial Nets.](http://arxiv.org/abs/2003.01436) | 本文提出了一种新颖的时间序列条件图生成方法(TSGG-GAN)，通过结合丰富的节点级上下文结构来推断时间序列之间的关系图。 |
| [^37] | [Generalization in Deep Learning.](http://arxiv.org/abs/1710.05468) | 本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，提出了一些新的开放问题，并讨论了研究结果的局限性。 |

# 详细

[^1]: 自助的鲁棒性表示学习的独立子网络多样化集成

    Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning. (arXiv:2308.14705v1 [stat.ML])

    [http://arxiv.org/abs/2308.14705](http://arxiv.org/abs/2308.14705)

    本文提出了一个新的自助培训体制，利用独立子网络的集成和新的损失函数来提高自助的鲁棒性表示学习的效率和多样性。

    

    集成神经网络是提高模型性能、估计不确定性和改善深度有监督学习鲁棒性的广泛承认方法。然而，深层集成通常具有高计算成本和内存需求。此外，深度集成的效率与集成成员之间的多样性有关，这对于大型的过参数化深度神经网络来说是具有挑战性的。而且，集成学习尚未得到如此广泛的采用，并且对于自助的或无监督的表示学习来说仍然是一项具有挑战性的工作。在这些挑战的推动下，我们提出了一个新颖的自助培训体制，利用独立子网络的集成，辅以一个旨在鼓励多样性的新损失函数。我们的方法以高多样性实现了高效的子模型集成，从而获得了良好校准的模型不确定性估计，并与传统方法相比，计算开销最小。

    Ensembling a neural network is a widely recognized approach to enhance model performance, estimate uncertainty, and improve robustness in deep supervised learning. However, deep ensembles often come with high computational costs and memory demands. In addition, the efficiency of a deep ensemble is related to diversity among the ensemble members which is challenging for large, over-parameterized deep neural networks. Moreover, ensemble learning has not yet seen such widespread adoption, and it remains a challenging endeavor for self-supervised or unsupervised representation learning. Motivated by these challenges, we present a novel self-supervised training regime that leverages an ensemble of independent sub-networks, complemented by a new loss function designed to encourage diversity. Our method efficiently builds a sub-model ensemble with high diversity, leading to well-calibrated estimates of model uncertainty, all achieved with minimal computational overhead compared to traditional
    
[^2]: 循环神经网络在遍历数据序列上训练的核极限

    Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences. (arXiv:2308.14555v1 [cs.LG])

    [http://arxiv.org/abs/2308.14555](http://arxiv.org/abs/2308.14555)

    本文研究了循环神经网络在遍历数据序列上训练时的核极限，利用数学方法对其渐近特性进行了描述，并证明了RNN收敛到与随机代数方程的不动点耦合的无穷维ODE的解。这对于理解和改进循环神经网络具有重要意义。

    

    本文开发了数学方法来描述循环神经网络（RNN）的渐近特性，其中隐藏单元的数量、序列中的数据样本、隐藏状态的更新和训练步骤同时趋于无穷大。对于具有简化权重矩阵的RNN，我们证明了RNN收敛到与随机代数方程的不动点耦合的无穷维ODE的解。分析需要解决RNN所特有的几个挑战。在典型的均场应用中（例如前馈神经网络），离散的更新量为$\mathcal{O}(\frac{1}{N})$，更新的次数为$\mathcal{O}(N)$。因此，系统可以表示为适当ODE/PDE的Euler逼近，当$N \rightarrow \infty$时收敛到该ODE/PDE。然而，RNN的隐藏层更新为$\mathcal{O}(1)$。因此，RNN不能表示为ODE/PDE的离散化和标准均场技术。

    Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity. In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation. The analysis requires addressing several challenges which are unique to RNNs. In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\mathcal{O}(\frac{1}{N})$ and the number of updates is $\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \rightarrow \infty$. However, the RNN hidden layer updates are $\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field tec
    
[^3]: 深度图形回归用于联合调节和极端澳大利亚野火

    Deep graphical regression for jointly moderate and extreme Australian wildfires. (arXiv:2308.14547v1 [stat.AP])

    [http://arxiv.org/abs/2308.14547](http://arxiv.org/abs/2308.14547)

    该论文介绍了一种利用深度图形回归方法来联合调节和预测澳大利亚野火的新方法。研究结果表明，对于火灾的全分布建模是非常关键的，因为极端野火可能导致巨大的影响，而小规模和中等规模火灾仍然会对当地社区和生态系统造成重大破坏。

    

    澳大利亚最近的野火造成了巨大的经济损失和财产破坏，人们越来越担心气候变化可能加剧其强度、持续时间和频率。对于极端野火的灾害评估是野火管理的重要组成部分，它有助于资源分配的高效性、负面影响的减轻和恢复工作的开展。然而，虽然极端野火通常具有最大的影响力，但小规模和中等规模的火灾仍然可以对当地社区和生态系统造成毁灭性的影响。因此，我们迫切需要开发稳健的统计方法来可靠地建模野火的全分布。我们对1999年至2019年的澳大利亚野火进行了新的数据集分析，并分析了大约相当于统计区域层次1和层次2（SA1/SA2）区域的火灾月度蔓延。鉴于野火点燃和蔓延的复杂性，我们利用了统计深度学习和外部信息的最新进展。

    Recent wildfires in Australia have led to considerable economic loss and property destruction, and there is increasing concern that climate change may exacerbate their intensity, duration, and frequency. hazard quantification for extreme wildfires is an important component of wildfire management, as it facilitates efficient resource distribution, adverse effect mitigation, and recovery efforts. However, although extreme wildfires are typically the most impactful, both small and moderate fires can still be devastating to local communities and ecosystems. Therefore, it is imperative to develop robust statistical methods to reliably model the full distribution of wildfire spread. We do so for a novel dataset of Australian wildfires from 1999 to 2019, and analyse monthly spread over areas approximately corresponding to Statistical Areas Level 1 and 2 (SA1/SA2) regions. Given the complex nature of wildfire ignition and spread, we exploit recent advances in statistical deep learning and extr
    
[^4]: 通过近似传递消息实现结构化广义线性模型的谱估计器

    Spectral Estimators for Structured Generalized Linear Models via Approximate Message Passing. (arXiv:2308.14507v1 [math.ST])

    [http://arxiv.org/abs/2308.14507](http://arxiv.org/abs/2308.14507)

    本论文研究了针对广义线性模型的参数估计问题，提出了一种通过谱估计器进行预处理的方法。通过对测量进行特征协方差矩阵Σ表示，分析了谱估计器在结构化设计中的性能，并确定了最优预处理以最小化样本数量。

    

    我们考虑从广义线性模型中的观测中进行参数估计的问题。谱方法是一种简单而有效的估计方法：它通过对观测进行适当预处理得到的矩阵的主特征向量来估计参数。尽管谱估计器被广泛使用，但对于结构化（即独立同分布的高斯和哈尔）设计，目前仅有对谱估计器的严格性能表征以及对数据进行预处理的基本方法可用。相反，实际的设计矩阵具有高度结构化并且表现出非平凡的相关性。为解决这个问题，我们考虑了捕捉测量的非各向同性特性的相关高斯设计，通过特征协方差矩阵Σ进行表示。我们的主要结果是对于这种情况下谱估计器性能的精确渐近分析。然后，可以通过这一结果来确定最优预处理，从而最小化所需样本的数量。

    We consider the problem of parameter estimation from observations given by a generalized linear model. Spectral methods are a simple yet effective approach for estimation: they estimate the parameter via the principal eigenvector of a matrix obtained by suitably preprocessing the observations. Despite their wide use, a rigorous performance characterization of spectral estimators, as well as a principled way to preprocess the data, is available only for unstructured (i.e., i.i.d. Gaussian and Haar) designs. In contrast, real-world design matrices are highly structured and exhibit non-trivial correlations. To address this problem, we consider correlated Gaussian designs which capture the anisotropic nature of the measurements via a feature covariance matrix $\Sigma$. Our main result is a precise asymptotic characterization of the performance of spectral estimators in this setting. This then allows to identify the optimal preprocessing that minimizes the number of samples needed to meanin
    
[^5]: 关于鲁棒聚类中的一些问题

    Some issues in robust clustering. (arXiv:2308.14478v1 [stat.ML])

    [http://arxiv.org/abs/2308.14478](http://arxiv.org/abs/2308.14478)

    关于鲁棒聚类，讨论了高斯混合模型、异常值定义、异常值与聚类的模糊性、鲁棒聚类与聚类数目估计的相互作用以及聚类稳定性衡量的不足。

    

    讨论了鲁棒聚类中的一些关键问题，主要集中在基于高斯混合模型的聚类上，包括异常值的形式定义、异常值与聚类之间的模糊性、鲁棒聚类与聚类数目估计之间的相互作用、(不仅仅是)鲁棒聚类对调试决策的必要依赖以及现有的聚类稳定性衡量在处理异常值时的不足。

    Some key issues in robust clustering are discussed with focus on Gaussian mixture model based clustering, namely the formal definition of outliers, ambiguity between groups of outliers and clusters, the interaction between robust clustering and the estimation of the number of clusters, the essential dependence of (not only) robust clustering on tuning decisions, and shortcomings of existing measurements of cluster stability when it comes to outliers.
    
[^6]: 使用机器学习技术识别漏电光子晶格的拓扑结构

    Identifying topology of leaky photonic lattices with machine learning. (arXiv:2308.14407v1 [physics.optics])

    [http://arxiv.org/abs/2308.14407](http://arxiv.org/abs/2308.14407)

    本研究展示了利用机器学习技术，通过仅使用局部测量数据，可以在漏电光子晶格中准确识别拓扑相，避免了复杂的相位重构步骤。

    

    我们展示了如何利用有限的测量数据，通过机器学习技术对漏电光子晶格中的拓扑相进行分类。我们提出了一种仅基于体积强度测量的方法，因此不需要复杂的相位重构步骤。特别地，我们设计了一个全连接神经网络，能够从有漏电通道的二聚波导阵列的输出强度分布中准确确定拓扑特性，在一个紧密模拟实际实验条件的设置中，通过在有限距离上传播空间局部化的初始激发。

    We show how machine learning techniques can be applied for the classification of topological phases in leaky photonic lattices using limited measurement data. We propose an approach based solely on bulk intensity measurements, thus exempt from the need for complicated phase retrieval procedures. In particular, we design a fully connected neural network that accurately determines topological properties from the output intensity distribution in dimerized waveguide arrays with leaky channels, after propagation of a spatially localized initial excitation at a finite distance, in a setting that closely emulates realistic experimental conditions.
    
[^7]: 通过稀疏惩罚进行的双聚类方法

    Biclustering Methods via Sparse Penalty. (arXiv:2308.14388v1 [stat.ML])

    [http://arxiv.org/abs/2308.14388](http://arxiv.org/abs/2308.14388)

    本文提出了一种基于稀疏惩罚的双聚类方法，主要关注了SSVD方法，并尝试了一种新的稀疏惩罚方法。模拟研究结果表明混合的Prenet惩罚对于非重叠数据非常有效。

    

    本文首先回顾了几种用于识别基因表达数据中最显著聚类的双聚类方法。我们主要关注了SSVD（稀疏SVD）方法，并尝试了一种仅用于因子分析的新的稀疏惩罚方法，称为"Prenet惩罚"。然后在模拟研究中，我们尝试了不同类型的生成数据集（具有不同的稀疏性和维度），并尝试了一层逼近和k层逼近，结果表明混合的Prenet惩罚对于非重叠数据非常有效。最后，我们使用了一些真实的基因表达数据来展示我们方法的行为。

    In this paper, we first reviewed several biclustering methods that are used to identify the most significant clusters in gene expression data. Here we mainly focused on the SSVD(sparse SVD) method and tried a new sparse penalty named "Prenet penalty" which has been used only in factor analysis to gain sparsity. Then in the simulation study, we tried different types of generated datasets (with different sparsity and dimension) and tried 1-layer approximation then for k-layers which shows the mixed Prenet penalty is very effective for non-overlapped data. Finally, we used some real gene expression data to show the behavior of our methods.
    
[^8]: 何时购买？购买时机的生存机器学习模型比较

    Buy when? Survival machine learning model comparison for purchase timing. (arXiv:2308.14343v1 [stat.ML])

    [http://arxiv.org/abs/2308.14343](http://arxiv.org/abs/2308.14343)

    本文研究了购买时机的生存机器学习模型，在考虑了性别、收入、位置、购买历史、在线行为、兴趣、促销折扣和客户体验等因素的影响下，进行了个人购买决策时间的预测。

    

    将原始数据转化为可以驱动决策的信息和知识才能实现其价值。机器学习算法能够分析大型数据集并进行准确的预测。市场细分、客户终身价值和营销技术都已经利用了机器学习。本文研究了营销机器学习技术，如支持向量机、遗传算法、深度学习和K-Means。机器学习用于分析消费者行为、提出物品选择，并在购买产品或服务时做出其他客户决策，但很少用于预测一个人何时购买一个产品或一篮子产品。本文研究了生存模型 Kernel SVM、DeepSurv、Survival Random Forest 和 MTLR，以预测个人购买决策的时间。性别、收入、位置、购买历史、在线行为、兴趣、促销折扣和客户体验都对购买有影响。

    The value of raw data is unlocked by converting it into information and knowledge that drives decision-making. Machine Learning (ML) algorithms are capable of analysing large datasets and making accurate predictions. Market segmentation, client lifetime value, and marketing techniques have all made use of machine learning. This article examines marketing machine learning techniques such as Support Vector Machines, Genetic Algorithms, Deep Learning, and K-Means. ML is used to analyse consumer behaviour, propose items, and make other customer choices about whether or not to purchase a product or service, but it is seldom used to predict when a person will buy a product or a basket of products. In this paper, the survival models Kernel SVM, DeepSurv, Survival Random Forest, and MTLR are examined to predict tine-purchase individual decisions. Gender, Income, Location, PurchaseHistory, OnlineBehavior, Interests, PromotionsDiscounts and CustomerExperience all have an influence on purchasing 
    
[^9]: 改进的核分布回归学习理论与两阶段采样

    Improved learning theory for kernel distribution regression with two-stage sampling. (arXiv:2308.14335v1 [math.ST])

    [http://arxiv.org/abs/2308.14335](http://arxiv.org/abs/2308.14335)

    本文改进了核分布回归的学习理论，引入了新的近无偏条件，并提供了关于两阶段采样效果的新误差界。

    

    分布回归问题涵盖了许多重要的统计和机器学习任务，在各种应用中都有出现。在解决这个问题的各种现有方法中，核方法已经成为首选的方法。事实上，核分布回归在计算上是有利的，并且得到了最近的学习理论的支持。该理论还解决了两阶段采样的设置，其中只有输入分布的样本可用。在本文中，我们改进了核分布回归的学习理论。我们研究了基于希尔伯特嵌入的核，这些核包含了大多数（如果不是全部）现有方法。我们引入了嵌入的新近无偏条件，使我们能够通过新的分析提供关于两阶段采样效果的新误差界。我们证明了这种新近无偏条件对三个重要的核类别成立，这些核基于最优输运和平均嵌入。

    The distribution regression problem encompasses many important statistics and machine learning tasks, and arises in a large range of applications. Among various existing approaches to tackle this problem, kernel methods have become a method of choice. Indeed, kernel distribution regression is both computationally favorable, and supported by a recent learning theory. This theory also tackles the two-stage sampling setting, where only samples from the input distributions are available. In this paper, we improve the learning theory of kernel distribution regression. We address kernels based on Hilbertian embeddings, that encompass most, if not all, of the existing approaches. We introduce the novel near-unbiased condition on the Hilbertian embeddings, that enables us to provide new error bounds on the effect of the two-stage sampling, thanks to a new analysis. We show that this near-unbiased condition holds for three important classes of kernels, based on optimal transport and mean embedd
    
[^10]: 预测稀疏流形变换

    Predictive Sparse Manifold Transform. (arXiv:2308.14207v1 [stat.ML])

    [http://arxiv.org/abs/2308.14207](http://arxiv.org/abs/2308.14207)

    预测稀疏流形变换是一个简约、可解释且生物可行的框架，用于学习和预测自然动态。它通过稀疏编码和流形学习实现了更好的预测性能。

    

    我们提出了预测稀疏流形变换（PSMT），这是一个简约、可解释且生物可行的框架，用于学习和预测自然动态。PSMT包含两个层次，第一个稀疏编码层将输入序列表示为过完备字典上的稀疏系数，第二个流形学习层学习一个几何嵌入空间，该空间捕捉了稀疏系数的拓扑相似性和动态时间线性。我们在自然视频数据集上应用PSMT，并通过上下文可变性、稀疏编码基函数的数量和训练样本进行重建性能评估。然后，我们解释了嵌入空间中的动态拓扑结构。接下来，我们利用PSMT与静态嵌入空间的两种基准方法进行未来帧的预测。我们证明了与静态基准方法相比，具有动态嵌入空间的PSMT可以实现更好的预测性能。

    We present Predictive Sparse Manifold Transform (PSMT), a minimalistic, interpretable and biologically plausible framework for learning and predicting natural dynamics. PSMT incorporates two layers where the first sparse coding layer represents the input sequence as sparse coefficients over an overcomplete dictionary and the second manifold learning layer learns a geometric embedding space that captures topological similarity and dynamic temporal linearity in sparse coefficients. We apply PSMT on a natural video dataset and evaluate the reconstruction performance with respect to contextual variability, the number of sparse coding basis functions and training samples. We then interpret the dynamic topological organization in the embedding space. We next utilize PSMT to predict future frames compared with two baseline methods with a static embedding space. We demonstrate that PSMT with a dynamic embedding space can achieve better prediction performance compared to static baselines. Our w
    
[^11]: 从数据中基于光滑性先验推断超图结构

    Hypergraph Structure Inference From Data Under Smoothness Prior. (arXiv:2308.14172v1 [cs.LG])

    [http://arxiv.org/abs/2308.14172](http://arxiv.org/abs/2308.14172)

    本文提出了一种光滑性先验方法，用于从节点特征中推断超图的结构，并捕捉数据内在的关系。该方法不需要标记数据作为监督，能够推断出每个潜在超边的概率。

    

    超图在处理涉及多个实体的高阶关系数据中非常重要。在没有明确超图可用的情况下，希望能够从节点特征中推断出有意义的超图结构，以捕捉数据内在的关系。然而，现有的方法要么采用简单预定义的规则，不能精确捕捉潜在超图结构的分布，要么学习超图结构和节点特征之间的映射，但需要大量标记数据（即预先存在的超图结构）进行训练。这两种方法都局限于实际情景中的应用。为了填补这一空白，我们提出了一种新的光滑性先验，使我们能够设计一种方法，在没有标记数据作为监督的情况下推断出每个潜在超边的概率。所提出的先验表示超边中的节点特征与包含该超边的超边的特征高度相关。

    Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing th
    
[^12]: 快速空间建模的综合变分傅里叶特征

    Integrated Variational Fourier Features for Fast Spatial Modelling with Gaussian Processes. (arXiv:2308.14142v1 [stat.ML])

    [http://arxiv.org/abs/2308.14142](http://arxiv.org/abs/2308.14142)

    本论文提出了一种综合变分傅里叶特征的方法，可以对广泛的平稳协方差函数进行快速空间建模，相比其他方法具有更高的性能和加速效果。

    

    稀疏变分逼近是扩展高斯过程推理和学习至更大数据集的流行方法。对于$N$个训练点，精确推理的成本为$O(N^3)$；使用$M \ll N$特征的先进稀疏变分方法成本为$O(NM^2)$。最近，提出了使用更复杂特征的方法；这些方法在低维任务（如空间建模）中能够有很好的性能，但只使用了一类非常有限的核函数，排除了一些常用的核函数。在这项工作中，我们提出了综合傅里叶特征，将这些性能优势扩展到非常广泛的平稳协方差函数。我们从收敛分析和经验探索的角度来解释该方法和参数的选择，同时展示该方法在合成和实际空间回归任务中的实际加速效果。

    Sparse variational approximations are popular methods for scaling up inference and learning in Gaussian processes to larger datasets. For $N$ training points, exact inference has $O(N^3)$ cost; with $M \ll N$ features, state of the art sparse variational methods have $O(NM^2)$ cost. Recently, methods have been proposed using more sophisticated features; these promise $O(M^3)$ cost, with good performance in low dimensional tasks such as spatial modelling, but they only work with a very limited class of kernels, excluding some of the most commonly used. In this work, we propose integrated Fourier features, which extends these performance benefits to a very broad class of stationary covariance functions. We motivate the method and choice of parameters from a convergence analysis and empirical exploration, and show practical speedup in synthetic and real world spatial regression tasks.
    
[^13]: 一种贝叶斯非参数方法用于生成模型：使用Wasserstein和最大均值差异度量集成变分自编码器和生成对抗网络

    A Bayesian Non-parametric Approach to Generative Models: Integrating Variational Autoencoder and Generative Adversarial Networks using Wasserstein and Maximum Mean Discrepancy. (arXiv:2308.14048v1 [stat.ML])

    [http://arxiv.org/abs/2308.14048](http://arxiv.org/abs/2308.14048)

    本研究提出了一种融合生成对抗网络和变分自编码器的贝叶斯非参数方法，通过在损失函数中使用Wasserstein和最大均值差异度量，实现了对潜在空间的有效学习，并能够生成多样且高质量的样本。

    

    生成模型已成为一种产生与真实图像难以区分的高质量图像的有前途的技术。生成对抗网络（GAN）和变分自编码器（VAE）是最为重要且被广泛研究的两种生成模型。GAN在生成逼真图像方面表现出色，而VAE则能够生成多样的图像。然而，GAN忽视了大部分可能的输出空间，这导致不能完全体现目标分布的多样性，而VAE则常常生成模糊图像。为了充分发挥两种模型的优点并减轻它们的弱点，我们采用了贝叶斯非参数方法将GAN和VAE相结合。我们的方法在损失函数中同时使用了Wasserstein和最大均值差异度量，以有效学习潜在空间并生成多样且高质量的样本。

    Generative models have emerged as a promising technique for producing high-quality images that are indistinguishable from real images. Generative adversarial networks (GANs) and variational autoencoders (VAEs) are two of the most prominent and widely studied generative models. GANs have demonstrated excellent performance in generating sharp realistic images and VAEs have shown strong abilities to generate diverse images. However, GANs suffer from ignoring a large portion of the possible output space which does not represent the full diversity of the target distribution, and VAEs tend to produce blurry images. To fully capitalize on the strengths of both models while mitigating their weaknesses, we employ a Bayesian non-parametric (BNP) approach to merge GANs and VAEs. Our procedure incorporates both Wasserstein and maximum mean discrepancy (MMD) measures in the loss function to enable effective learning of the latent space and generate diverse and high-quality samples. By fusing the di
    
[^14]: 在线GentleAdaBoost -- 技术报告

    Online GentleAdaBoost -- Technical Report. (arXiv:2308.14004v1 [stat.ML])

    [http://arxiv.org/abs/2308.14004](http://arxiv.org/abs/2308.14004)

    该论文研究了在线版的GentleAdaboost算法，通过在线方式将弱分类器与强分类器结合，提出了一种通过线搜索将批处理方法扩展为在线方法的方法，并与其他在线方法在各种基准数据集上进行了对比。

    

    我们研究了在线版的GentleAdaboost，其中我们以在线方式将一个弱分类器与一个强分类器结合起来。我们提供了一种通过线搜索应用的方法，将批处理方法扩展为在线方法，并通过理论证明了其正确性。最后，我们在各种基准数据集上比较了我们的在线boosting方法与其他在线方法。

    We study the online variant of GentleAdaboost, where we combine a weak learner to a strong learner in an online fashion. We provide an approach to extend the batch approach to an online approach with theoretical justifications through application of line search. Finally we compare our online boosting approach with other online approaches across a variety of benchmark datasets.
    
[^15]: 使用运输方法进行顺序基于模拟的推断

    A transport approach to sequential simulation-based inference. (arXiv:2308.13940v1 [stat.ME])

    [http://arxiv.org/abs/2308.13940](http://arxiv.org/abs/2308.13940)

    提出了一种新的基于运输的方法，用于高效地进行静态模型参数的顺序贝叶斯推断。该方法可以处理包括干扰参数的复杂噪声模型，并且适用于仅作为黑箱的正向模型。数值应用表明该方法在使用电导率测量来表征冰厚度的情况下是有效的。

    

    我们提出了一种新的基于运输的方法，用于高效地进行静态模型参数的顺序贝叶斯推断。该策略基于从参数和数据的联合分布中提取条件分布，通过估计结构化（例如，块三角形）运输映射来实现。这为似然函数及其梯度提供了明确的代理模型。这允许在模型无关、在线阶段通过运输映射进行基于梯度的后验密度表征。这个框架非常适用于复杂噪声模型（包括干扰参数）和仅作为黑箱的正向模型的参数估计。我们在使用电导率测量来表征冰厚度的情况下对该方法进行了数值应用。

    We present a new transport-based approach to efficiently perform sequential Bayesian inference of static model parameters. The strategy is based on the extraction of conditional distribution from the joint distribution of parameters and data, via the estimation of structured (e.g., block triangular) transport maps. This gives explicit surrogate models for the likelihood functions and their gradients. This allow gradient-based characterizations of posterior density via transport maps in a model-free, online phase. This framework is well suited for parameter estimation in case of complex noise models including nuisance parameters and when the forward model is only known as a black box. The numerical application of this method is performed in the context of characterization of ice thickness with conductivity measurements.
    
[^16]: 通过MCMC速度度量学习变分自动编码器

    Learning variational autoencoders via MCMC speed measures. (arXiv:2308.13731v1 [stat.ML])

    [http://arxiv.org/abs/2308.13731](http://arxiv.org/abs/2308.13731)

    本研究提出了一种基于熵的短期调整MCMC链的方法，用于在优化更紧的变分边界的同时，适应深度潜变量模型的提案分布。实验证明，这种方法能够使模型得到更高的保留对数似然和改进的生成性能。

    

    变分自动编码器（VAEs）是一种流行的基于似然的生成模型，可以通过最大化下界（ELBO）来有效训练。为了获得更紧的变分边界和更高的生成性能，改进变分分布的表达能力取得了很大进展。虽然先前的工作利用马尔可夫链蒙特卡洛（MCMC）方法构建了变分密度，但针对深度潜变量模型调整提案分布的基于梯度的方法受到的关注较少。本研究提出一种基于熵的短期调整Metropolis-adjusted Langevin（MALA）或Hamiltonian Monte Carlo（HMC）链的方法，并优化更紧的变分边界以获得对数似然。实验证明，该方法产生了更高的保留对数似然以及改进的生成指标。我们的隐式变分密度能够适应潜在层次表示的复杂后验几何形状。

    Variational autoencoders (VAEs) are popular likelihood-based generative models which can be efficiently trained by maximizing an Evidence Lower Bound (ELBO). There has been much progress in improving the expressiveness of the variational distribution to obtain tighter variational bounds and increased generative performance. Whilst previous work has leveraged Markov chain Monte Carlo (MCMC) methods for the construction of variational densities, gradient-based methods for adapting the proposal distributions for deep latent variable models have received less attention. This work suggests an entropy-based adaptation for a short-run Metropolis-adjusted Langevin (MALA) or Hamiltonian Monte Carlo (HMC) chain while optimising a tighter variational bound to the log-evidence. Experiments show that this approach yields higher held-out log-likelihoods as well as improved generative metrics. Our implicit variational density can adapt to complicated posterior geometries of latent hierarchical repres
    
[^17]: SGMM: 广义矩方法的随机近似

    SGMM: Stochastic Approximation to Generalized Method of Moments. (arXiv:2308.13564v1 [econ.EM])

    [http://arxiv.org/abs/2308.13564](http://arxiv.org/abs/2308.13564)

    我们提出了一种新的随机广义矩方法（SGMM），用于估计和推断矩限制模型。该方法具有快速和可扩展的实时处理能力，并且能够处理大规模和在线数据集。

    

    我们引入了一种新的算法类，随机广义矩方法（SGMM），用于估计和推断（超识别）矩限制模型。我们的SGMM是一种新颖的随机逼近方法，替代了流行的Hansen（1982年）的（离线）GMM，并提供了快速和可扩展的实时流数据处理能力。我们证明了SGMM对于效率不高的在线2SLS和高效的SGMM具有几乎确定的收敛性和（函数）中心极限定理。此外，我们提出了Durbin-Wu-Hausman和Sargan-Hansen测试的在线版本，可以无缝集成到SGMM框架中。广泛的蒙特卡洛模拟结果表明，随着样本量的增加，SGMM在估计准确性和计算效率方面与标准（离线）GMM相匹配，并显示出在大规模和在线数据集上的实际价值。我们通过使用两个示例证明了我们方法的有效性。

    We introduce a new class of algorithms, Stochastic Generalized Method of Moments (SGMM), for estimation and inference on (overidentified) moment restriction models. Our SGMM is a novel stochastic approximation alternative to the popular Hansen (1982) (offline) GMM, and offers fast and scalable implementation with the ability to handle streaming datasets in real time. We establish the almost sure convergence, and the (functional) central limit theorem for the inefficient online 2SLS and the efficient SGMM. Moreover, we propose online versions of the Durbin-Wu-Hausman and Sargan-Hansen tests that can be seamlessly integrated within the SGMM framework. Extensive Monte Carlo simulations show that as the sample size increases, the SGMM matches the standard (offline) GMM in terms of estimation accuracy and gains over computational efficiency, indicating its practical value for both large-scale and online datasets. We demonstrate the efficacy of our approach by a proof of concept using two we
    
[^18]: 通过无线计算实现联邦线性赌博学习

    Federated Linear Bandit Learning via Over-the-Air Computation. (arXiv:2308.13298v1 [cs.LG])

    [http://arxiv.org/abs/2308.13298](http://arxiv.org/abs/2308.13298)

    本研究针对联邦线性赌博学习提出了一种通过无线计算的方案，以减少通信开销。通过在噪声衰落信道上进行的模拟信号传输，我们的方案在降低累积遗憾方面表现出竞争力。

    

    本文研究了在由服务器和多个设备组成的无线系统中的联邦背景下的线性赌博学习。每个设备与环境交互，在接收到奖励后选择一个动作，并将模型更新发送到服务器。主要目标是在有限的时间范围内最小化所有设备的累积遗憾。为了减少通信开销，设备通过无线计算（AirComp）在噪声衰落信道上与服务器通信，其中通道噪声可能会扭曲信号。在这个背景下，我们提出了一种定制的联邦线性赌博方案，其中每个设备传输一个模拟信号，服务器接收到的是这些信号的叠加，受到信道噪声的扭曲。我们进行了严格的数学分析，确定了该方案的遗憾上限。理论分析和数值实验都证明了我们提出的方案在性能方面的竞争力。

    In this paper, we investigate federated contextual linear bandit learning within a wireless system that comprises a server and multiple devices. Each device interacts with the environment, selects an action based on the received reward, and sends model updates to the server. The primary objective is to minimize cumulative regret across all devices within a finite time horizon. To reduce the communication overhead, devices communicate with the server via over-the-air computation (AirComp) over noisy fading channels, where the channel noise may distort the signals. In this context, we propose a customized federated linear bandits scheme, where each device transmits an analog signal, and the server receives a superposition of these signals distorted by channel noise. A rigorous mathematical analysis is conducted to determine the regret bound of the proposed scheme. Both theoretical analysis and numerical experiments demonstrate the competitive performance of our proposed scheme in terms o
    
[^19]: MKL-$L_{0/1}$-SVM: 一种多核学习的支持向量机框架

    MKL-$L_{0/1}$-SVM. (arXiv:2308.12016v1 [stat.ML])

    [http://arxiv.org/abs/2308.12016](http://arxiv.org/abs/2308.12016)

    本文提出了一种多核学习的支持向量机框架(MKL-$L_{0/1}$-SVM)，通过开发快速的ADMM求解器处理非凸非光滑的优化问题，并在实验中展示了与领先方法相当的性能。

    

    本文提出了一种适用于$(0, 1)$损失函数的支持向量机的多核学习（MKL）框架。首先给出了一阶最优性条件，然后利用它们开发了一个快速的ADMM求解器来处理非凸非光滑的优化问题。详细的合成和真实数据集上的实验表明，我们的MKL-$L_{0/1}$-SVM的性能与一种名为SimpleMKL的领先方法相当。

    This paper presents a Multiple Kernel Learning (abbreviated as MKL) framework for the Support Vector Machine (SVM) with the $(0, 1)$ loss function. Some first-order optimality conditions are given and then exploited to develop a fast ADMM solver to deal with the nonconvex and nonsmooth optimization problem. Extensive numerical experiments on synthetic and real datasets show that the performance of our MKL-$L_{0/1}$-SVM is comparable with the one of the leading approaches called SimpleMKL developed by Rakotomamonjy, Bach, Canu, and Grandvalet [Journal of Machine Learning Research, vol. 9, pp. 2491-2521, 2008].
    
[^20]: Wasserstein几何生成器用于条件分布

    Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v1 [stat.ML])

    [http://arxiv.org/abs/2308.10145](http://arxiv.org/abs/2308.10145)

    通过Wasserstein几何生成器学习条件分布，生成给定特定标签的样本。使用最优输运理论提出的方法能学习观察域的条件分布和它们之间的最优输运映射。在人脸图像数据上的实验验证了该方法的有效性。

    

    生成给定特定标签的样本需要估计条件分布。我们推导出条件分布之间Wasserstein距离的可处理的上界，以建立学习条件分布的理论基础。基于这一结果，我们提出了一种新颖的条件生成算法，其中条件分布完全由由统计距离定义的度量空间来表征。我们利用最优输运理论来提出了Wasserstein几何生成器，一种学习Wasserstein几何的新的条件生成器。所提出的方法学习观察域的条件分布和它们之间的最优输运映射。给定两个观察域标签，未观察到的中间域的条件分布位于给定的条件分布之间的Wasserstein几何中。在以光照条件为域标签的人脸图像上的实验证明了所提出方法的有效性。

    Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the \textit{Wasserstein geodesic generator}, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
    
[^21]: Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) 该论文标题已翻译：二元强化学习。

    Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])

    [http://arxiv.org/abs/2308.07843](http://arxiv.org/abs/2308.07843)

    该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。

    

    移动医疗旨在通过在个人日常生活中提供干预来提高健康结果。照顾伴侣和社会支持网络的参与经常在帮助个人管理繁重的医疗条件方面起着关键作用。这为移动医疗提供了机会，设计针对二元关系——目标人和其照顾伴侣之间关系——以提高社会支持的干预措施。在本文中，我们开发了二元强化学习（Dyadic RL），这是一种基于环境因素和目标人及其照顾伴侣的过去反馈个性化干预措施的在线强化学习算法。在这里，多组干预措施影响着二元关系在多个时间间隔内。开发的二元强化学习是贝叶斯和层次的。我们正式介绍了问题设定，开发了二元强化学习并确定了遗憾边界。通过模拟，我们展示了二元强化学习的实证效果。

    Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
    
[^22]: 深度生成模型、合成表格数据和差分隐私：综述与综合

    Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis. (arXiv:2307.15424v1 [cs.LG])

    [http://arxiv.org/abs/2307.15424](http://arxiv.org/abs/2307.15424)

    本文综述了近期合成数据生成的深度生成模型发展，重点关注表格数据集。通过使用深度生成模型，可以有效地生成隐私敏感数据的合成数据，并解决数据归一化、隐私和评估等方面的挑战。

    

    本文全面综述了通过深度生成模型生成合成数据的最新发展，重点关注表格数据集。我们特别概述了在隐私敏感数据背景下合成数据生成的重要性。此外，我们强调了使用深度生成模型相对于其他方法的优势，并详细解释了包括无监督学习、神经网络和生成模型在内的基本概念。论文涵盖了在使用深度生成模型处理表格数据集时涉及的挑战和考虑因素，如数据归一化、隐私问题和模型评估。本综述为对合成数据生成及其应用感兴趣的研究人员和实践者提供了宝贵的资源。

    This article provides a comprehensive synthesis of the recent developments in synthetic data generation via deep generative models, focusing on tabular datasets. We specifically outline the importance of synthetic data generation in the context of privacy-sensitive data. Additionally, we highlight the advantages of using deep generative models over other methods and provide a detailed explanation of the underlying concepts, including unsupervised learning, neural networks, and generative models. The paper covers the challenges and considerations involved in using deep generative models for tabular datasets, such as data normalization, privacy concerns, and model evaluation. This review provides a valuable resource for researchers and practitioners interested in synthetic data generation and its applications.
    
[^23]: 我们能否在不做任何假设的情况下，证伪Wald置信区间在双重稳健函数下的有效性？

    Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])

    [http://arxiv.org/abs/2306.10590](http://arxiv.org/abs/2306.10590)

    本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。

    

    本文提出了一种可行的版本的无假设检验方法，可否定分析师对报道的以双重机器学习(DML)估计量为中心的名义$(1-\alpha)$Wald置信区间的有效性的证明，对Rotnitzky等人所研究的双重稳健(DR)函数类的任何成员进行检验。DR函数类在经济学和生物统计学中具有广泛和核心的重要性。它严格包括两个类别，即(i)可以被写成条件期望的仿射函数期望的均方连续函数的类别，这是由Chernozhukov等人研究的，以及Robins等人所研究的类别。目前DR函数的最先进的估计值是DML估计值。$\hat{\psi}_{1}$的偏差取决于两个辅助函数$b$和$p$的估计率的乘积。最常见的是，分析师证明了

    In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
    
[^24]: 对鲁棒性学习的插值方法：基于Wasserstein测地线的数据增强

    Interpolation for Robust Learning: Data Augmentation on Wasserstein Geodesics. (arXiv:2302.02092v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02092](http://arxiv.org/abs/2302.02092)

    本文提出一种通过插值训练数据分布来提升模型鲁棒性的方法。通过寻找连接不同类别子人口分布的测地线上的最坏情况Wasserstein barycenter来增加数据，并对模型进行正则化以获得更平滑的性能。我们的方法在多个数据集上进行了实验证实，并改进了基线的可证明鲁棒性和经验鲁棒性。该研究从Wasserstein测地线的角度探索了模型鲁棒性。

    

    我们提出通过插值训练数据分布来研究和提升模型的鲁棒性能。具体地，我们通过找到连接不同类别子人口分布的测地线上的最坏情况Wasserstein barycenter来增加数据；我们对模型进行正则化，使其在连接子人口分布的连续测地线路径上具有更平滑的性能；此外，我们还提供了一种理论保证鲁棒性改进并研究测地线位置和样本大小的贡献。在包括CIFAR-100和ImageNet在内的四个数据集上进行实验证实了我们方法的有效性，例如，我们的方法在CIFAR10上提高了基线的可证明鲁棒性达到7.7%，在CIFAR-100上提高了16.8%的经验鲁棒性。我们的工作通过Wasserstein测地线揭示了模型鲁棒性的新视角。

    We propose to study and promote the robustness of a model as per its performance through the interpolation of training data distributions. Specifically, (1) we augment the data by finding the worst-case Wasserstein barycenter on the geodesic connecting subpopulation distributions of different categories. (2) We regularize the model for smoother performance on the continuous geodesic path connecting subpopulation distributions. (3) Additionally, we provide a theoretical guarantee of robustness improvement and investigate how the geodesic location and the sample size contribute, respectively. Experimental validations of the proposed strategy on \textit{four} datasets, including CIFAR-100 and ImageNet, establish the efficacy of our method, e.g., our method improves the baselines' certifiable robustness on CIFAR10 up to $7.7\%$, with $16.8\%$ on empirical robustness on CIFAR-100. Our work provides a new perspective of model robustness through the lens of Wasserstein geodesic-based interpol
    
[^25]: 不变Lipschitz赌徒：一个侧观发现方法

    Invariant Lipschitz Bandits: A Side Observation Approach. (arXiv:2212.07524v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07524](http://arxiv.org/abs/2212.07524)

    本文研究了不变Lipschitz赌徒设置，并提出了一种名为\texttt{UniformMesh-N}的算法。使用侧面观察的方法，证明了改进的遗憾上界。

    

    对称出现在许多优化和决策问题中，并吸引了优化界的相当关注：通过利用这样的对称性，可以显著改进寻找最优解的过程。尽管对称性在（离线）优化中取得成功，但在在线优化设置中，特别是在赌徒文献中，其利用还未得到充分的研究。因此，在本文中，我们研究了不变Lipschitz赌徒设置，这是Lipschitz赌徒的一个子类，在该子类中，奖励函数和臂集在一组变换下保持不变。我们引入了一种名为\texttt{UniformMesh-N}的算法，它自然地将侧面观察使用群轨道整合到\texttt{UniformMesh}算法（\cite{Kleinberg2005_UniformMesh}）中，该算法均匀地分割了臂的集合。通过侧面观察方法，我们证明了改进的遗憾上界，其取决于基数。

    Symmetry arises in many optimization and decision-making problems, and has attracted considerable attention from the optimization community: By utilizing the existence of such symmetries, the process of searching for optimal solutions can be improved significantly. Despite its success in (offline) optimization, the utilization of symmetries has not been well examined within the online optimization settings, especially in the bandit literature. As such, in this paper we study the invariant Lipschitz bandit setting, a subclass of the Lipschitz bandits where the reward function and the set of arms are preserved under a group of transformations. We introduce an algorithm named \texttt{UniformMesh-N}, which naturally integrates side observations using group orbits into the \texttt{UniformMesh} algorithm (\cite{Kleinberg2005_UniformMesh}), which uniformly discretizes the set of arms. Using the side-observation approach, we prove an improved regret upper bound, which depends on the cardinalit
    
[^26]: TuneUp:一种简单的改进的图神经网络训练策略

    TuneUp: A Simple Improved Training Strategy for Graph Neural Networks. (arXiv:2210.14843v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.14843](http://arxiv.org/abs/2210.14843)

    TuneUp是一种简单的基于课程的训练策略，用于改进图神经网络在难以预测的尾节点上的泛化性能。

    

    尽管图神经网络（GNN）在近期取得了许多进展，但它们的训练策略仍然未被充分探索。传统的训练策略对原始图中的所有节点进行平等学习，这可能是次优的，因为某些节点往往比其他节点更难学习。在这里，我们提出了TuneUp，一种简单的基于课程的训练策略，用于提高GNN的预测性能。TuneUp将GNN分为两个阶段进行训练。在第一阶段，TuneUp应用传统的训练方法，获得一个强大的基础GNN。基础GNN在头节点（具有大度数的节点）上表现良好，但在尾节点（具有小度数的节点）上表现较差。因此，TuneUp的第二阶段侧重于通过进一步训练基础GNN以在难以预测的尾节点上提高预测能力。我们在理论上分析了TuneUp，并证明它能够改善尾节点的泛化性能。TuneUp实现简单，适用于广泛的范围。

    Despite recent advances in Graph Neural Networks (GNNs), their training strategies remain largely under-explored. The conventional training strategy learns over all nodes in the original graph(s) equally, which can be sub-optimal as certain nodes are often more difficult to learn than others. Here we present TuneUp, a simple curriculum-based training strategy for improving the predictive performance of GNNs. TuneUp trains a GNN in two stages. In the first stage, TuneUp applies conventional training to obtain a strong base GNN. The base GNN tends to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). Therefore, the second stage of TuneUp focuses on improving prediction on the difficult tail nodes by further training the base GNN on synthetically generated tail node data. We theoretically analyze TuneUp and show it provably improves generalization performance on tail nodes. TuneUp is simple to implement and applicable to a broad ran
    
[^27]: 分布转移的充分不变学习

    Sufficient Invariant Learning for Distribution Shift. (arXiv:2210.13533v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13533](http://arxiv.org/abs/2210.13533)

    本文研究了分布转移情况下的充分不变学习，观察到之前的工作只学习了部分不变特征，我们提出了学习充分不变特征的重要性，并指出在分布转移时，从训练集中学习的部分不变特征可能不适用于测试集，限制了性能提升。

    

    机器学习算法在各种应用中展现出了卓越的性能。然而，在训练集和测试集的分布不同的情况下，保证性能仍然具有挑战性。为了改善分布转移情况下的性能，已经提出了一些方法，通过学习跨组或领域的不变特征来提高性能。然而，我们观察到之前的工作只部分地学习了不变特征。虽然先前的工作侧重于有限的不变特征，但我们首次提出了充分不变特征的重要性。由于只有训练集是经验性的，从训练集中学习得到的部分不变特征可能不存在于分布转移时的测试集中。因此，分布转移情况下的性能提高可能受到限制。本文认为从训练集中学习充分的不变特征对于分布转移情况至关重要。

    Machine learning algorithms have shown remarkable performance in diverse applications. However, it is still challenging to guarantee performance in distribution shifts when distributions of training and test datasets are different. There have been several approaches to improve the performance in distribution shift cases by learning invariant features across groups or domains. However, we observe that the previous works only learn invariant features partially. While the prior works focus on the limited invariant features, we first raise the importance of the sufficient invariant features. Since only training sets are given empirically, the learned partial invariant features from training sets might not be present in the test sets under distribution shift. Therefore, the performance improvement on distribution shifts might be limited. In this paper, we argue that learning sufficient invariant features from the training set is crucial for the distribution shift case. Concretely, we newly 
    
[^28]: 离线强化学习中的扩散策略作为表达性策略类的研究

    Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning. (arXiv:2208.06193v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.06193](http://arxiv.org/abs/2208.06193)

    本文提出了一种将策略表示为扩散模型的方法，用于离线强化学习。我们引入了Diffusion Q-learning（Diffusion-QL），利用条件扩散模型表示策略，并通过最大化动作值来寻求接近行为策略的最优动作。

    

    离线强化学习是通过利用先前收集的静态数据集来学习最优策略的重要强化学习范式。标准的强化学习方法在这种情况下通常表现不佳，原因是在分布不匹配的行为上存在函数逼近误差。尽管已经提出了各种正则化方法来缓解这个问题，但它们往往受限于具有有限表达能力的策略类，可能导致高度次优的解决方案。本文提出了以扩散模型作为策略表示的方法，这是一种近期出现的高度表达能力的深度生成模型类。我们引入了扩散Q-learning（Diffusion-QL），利用条件扩散模型来表示策略。在我们的方法中，我们学习一个动作值函数，并将最大化动作值的项加入到条件扩散模型的训练损失中，从而得到一个寻求接近行为策略的最优动作的损失函数。我们展示了扩散策略的表达能力。

    Offline reinforcement learning (RL), which aims to learn an optimal policy using a previously collected static dataset, is an important paradigm of RL. Standard RL methods often perform poorly in this regime due to the function approximation errors on out-of-distribution actions. While a variety of regularization methods have been proposed to mitigate this issue, they are often constrained by policy classes with limited expressiveness that can lead to highly suboptimal solutions. In this paper, we propose representing the policy as a diffusion model, a recent class of highly-expressive deep generative models. We introduce Diffusion Q-learning (Diffusion-QL) that utilizes a conditional diffusion model to represent the policy. In our approach, we learn an action-value function and we add a term maximizing action-values into the training loss of the conditional diffusion model, which results in a loss that seeks optimal actions that are near the behavior policy. We show the expressiveness
    
[^29]: Diffusion-GAN: 使用扩散训练生成对抗网络

    Diffusion-GAN: Training GANs with Diffusion. (arXiv:2206.02262v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02262](http://arxiv.org/abs/2206.02262)

    Diffusion-GAN提出了一种新颖的GAN框架，通过使用前向扩散链生成高斯混合分布的实例噪声，在训练中解决了GAN稳定性的问题。

    

    生成对抗网络（GANs）的稳定训练是一个挑战，将实例噪声注入鉴别器输入的方法在实践中并不十分有效。本文提出了Diffusion-GAN，一种新颖的GAN框架，利用前向扩散链生成高斯混合分布的实例噪声。Diffusion-GAN包括三个组件，包括自适应扩散过程、时间步依赖的判别器和生成器。观察到的和生成的数据都通过相同的自适应扩散过程进行扩散。在每个扩散时间步中，有不同的噪声到数据比例，时间步依赖的判别器学习区分扩散的真实数据和扩散的生成数据。生成器通过反向传播通过自适应调整扩散链的长度来平衡噪声和数据水平。我们从理论上证明了判别器的收敛性和生成器的收敛性，同时在一些标准数据集上的实验证明了Diffusion-GAN的有效性。

    Generative adversarial networks (GANs) are challenging to train stably, and a promising remedy of injecting instance noise into the discriminator input has not been very effective in practice. In this paper, we propose Diffusion-GAN, a novel GAN framework that leverages a forward diffusion chain to generate Gaussian-mixture distributed instance noise. Diffusion-GAN consists of three components, including an adaptive diffusion process, a diffusion timestep-dependent discriminator, and a generator. Both the observed and generated data are diffused by the same adaptive diffusion process. At each diffusion timestep, there is a different noise-to-data ratio and the timestep-dependent discriminator learns to distinguish the diffused real data from the diffused generated data. The generator learns from the discriminator's feedback by backpropagating through the forward diffusion chain, whose length is adaptively adjusted to balance the noise and data levels. We theoretically show that the dis
    
[^30]: 在外生非平稳变化存在下的自适应实验

    Adaptive Experimentation in the Presence of Exogenous Nonstationary Variation. (arXiv:2202.09036v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.09036](http://arxiv.org/abs/2202.09036)

    本论文研究了在外生非平稳变化存在下的自适应实验。提出了无偏汤普森抽样(DTS)算法来解决多臂老虎机算法在面对非平稳外生因素时的脆弱性，DTS算法通过控制背景信息预测一个臂的人口层级表现，并提供了实验内和实验后的遗憾界限，显示了其对外生变异的弹性。

    

    我们研究设计用于选择人口部署治疗方案的实验。多臂老虎机算法可以通过根据观察到的反馈动态分配测量工作量到表现更好的臂上，从而提高效率。然而，这种动态性可能导致面对影响实验中臂表现的非平稳外生因素时出现脆弱行为。为了应对这个问题，我们提出了无偏汤普森抽样(DTS)，这是一种更稳健的著名汤普森抽样算法的变体。随着观察结果的积累，DTS会控制观察到的治疗决策的背景，同时预测一个臂的人口层级表现。这里的背景可以捕捉到一个可理解的变化源，比如一个受治疗个体的国家，或者仅仅是记录治疗时间。我们给出了DTS在实验内和实验后遗憾的界限，说明它对于外生变异的弹性。

    We investigate experiments that are designed to select a treatment arm for population deployment. Multi-armed bandit algorithms can enhance efficiency by dynamically allocating measurement effort towards higher performing arms based on observed feedback. However, such dynamics can result in brittle behavior in the face of nonstationary exogenous factors influencing arms' performance during the experiment. To counter this, we propose deconfounded Thompson sampling (DTS), a more robust variant of the prominent Thompson sampling algorithm. As observations accumulate, DTS projects the population-level performance of an arm while controlling for the context within which observed treatment decisions were made. Contexts here might capture a comprehensible source of variation, such as the country of a treated individual, or simply record the time of treatment. We provide bounds on both within-experiment and post-experiment regret of DTS, illustrating its resilience to exogenous variation and t
    
[^31]: 连续时间随机梯度下降用于优化随机微分方程的平稳分布

    Continuous-time stochastic gradient descent for optimizing over the stationary distribution of stochastic differential equations. (arXiv:2202.06637v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.06637](http://arxiv.org/abs/2202.06637)

    我们提出了一种连续时间随机梯度下降算法用于优化随机微分方程模型的平稳分布。算法通过估计平稳分布的梯度，并使用正向传播进行连续更新参数，实现收敛至最陡下降方向。我们严格证明了在线正向传播算法在线性模型上的收敛性，并在非线性示例上进行了数值验证。

    

    我们开发了一种新的连续时间随机梯度下降方法，用于优化随机微分方程模型的平稳分布。算法使用平稳分布的梯度估计连续更新SDE模型的参数。梯度估计同时使用SDE状态导数的正向传播进行更新，渐近地收敛到最陡下降方向。我们严格证明了在线正向传播算法在线性SDE模型（如多维Ornstein-Uhlenbeck过程）上的收敛性，并呈现了非线性示例的数值结果。证明需要对参数演化在最陡下降方向附近的波动进行分析。由于算法的在线性质，获得波动的界限很具挑战性（例如，随着参数的变化，稳定分布将持续变化）。

    We develop a new continuous-time stochastic gradient descent method for optimizing over the stationary distribution of stochastic differential equation (SDE) models. The algorithm continuously updates the SDE model's parameters using an estimate for the gradient of the stationary distribution. The gradient estimate is simultaneously updated using forward propagation of the SDE state derivatives, asymptotically converging to the direction of steepest descent. We rigorously prove convergence of the online forward propagation algorithm for linear SDE models (i.e., the multi-dimensional Ornstein-Uhlenbeck process) and present its numerical results for nonlinear examples. The proof requires analysis of the fluctuations of the parameter evolution around the direction of steepest descent. Bounds on the fluctuations are challenging to obtain due to the online nature of the algorithm (e.g., the stationary distribution will continuously change as the parameters change). We prove bounds for the s
    
[^32]: 随机坐标变换及其在鲁棒机器学习中的应用

    Stochastic coordinate transformations with applications to robust machine learning. (arXiv:2110.01729v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.01729](http://arxiv.org/abs/2110.01729)

    本文提出了一种利用随机坐标变换进行异常检测的新方法，该方法通过层级张量积展开来逼近随机过程，并通过训练机器学习分类器对投影系数进行检测。在基准数据集上的实验表明，该方法胜过现有的最先进方法。

    

    本文介绍了一组新的特征，利用Karhunen-Loeve展开法来识别输入数据的潜在随机行为。这些新特征是通过基于最近的函数数据分析理论进行的坐标变换构建的，用于异常检测。相关的信号分解是用已知优化属性的层级张量积展开来逼近具有有限功能空间的随机过程（随机场）。原则上，这些低维空间可以捕捉给定名义类别的'底层信号'的大部分随机变化，并且可以将来自其它类别的信号拒绝为随机异常。通过名义类别的层级有限维展开，构建了一系列用于检测异常信号组件的正交嵌套子空间。然后使用这些子空间中的投影系数来训练用于异常检测的机器学习（ML）分类器。我们在几个基准数据集上评估所提出的方法，结果表明其胜过现有的最先进方法。

    In this paper we introduce a set of novel features for identifying underlying stochastic behavior of input data using the Karhunen-Loeve expansion. These novel features are constructed by applying a coordinate transformation based on the recent Functional Data Analysis theory for anomaly detection. The associated signal decomposition is an exact hierarchical tensor product expansion with known optimality properties for approximating stochastic processes (random fields) with finite dimensional function spaces. In principle these low dimensional spaces can capture most of the stochastic behavior of `underlying signals' in a given nominal class, and can reject signals in alternative classes as stochastic anomalies. Using a hierarchical finite dimensional expansion of the nominal class, a series of orthogonal nested subspaces is constructed for detecting anomalous signal components. Projection coefficients of input data in these subspaces are then used to train a Machine Learning (ML) clas
    
[^33]: 元校准：使用可微之期望校准误差学习模型校准

    Meta-Calibration: Learning of Model Calibration Using Differentiable Expected Calibration Error. (arXiv:2106.09613v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.09613](http://arxiv.org/abs/2106.09613)

    本论文提出了元校准框架，通过引入可微的期望校准误差代理指标和元学习框架，实现了对模型校准质量的直接优化。实验证明，该方法能够达到与现有校准方法相竞争的性能表现。该框架为进一步解决校准问题提供了新的思路和工具。

    

    神经网络的校准是一个重要的问题，在神经网络越来越多地应用于现实世界应用的情况下，变得越来越重要。当使用现代神经网络时，模型的置信度与正确预测的概率之间存在明显差异，这一问题尤为明显。已经提出了各种策略来改善校准，但准确的校准仍然具有挑战性。我们提出了一个新的框架，包含两个贡献：引入了一个新的可微代理指标，用于直接优化校准质量的期望校准误差 (DECE)，以及一个元学习框架，使用DECE根据模型超参数优化验证集校准。结果表明，我们的方法在校准方面具有竞争性能。我们的框架为处理校准问题开辟了新的途径和工具，我们相信这将激发更多研究。

    Calibration of neural networks is a topical problem that is becoming more and more important as neural networks increasingly underpin real-world applications. The problem is especially noticeable when using modern neural networks, for which there is a significant difference between the confidence of the model and the probability of correct prediction. Various strategies have been proposed to improve calibration, yet accurate calibration remains challenging. We propose a novel framework with two contributions: introducing a new differentiable surrogate for expected calibration error (DECE) that allows calibration quality to be directly optimised, and a meta-learning framework that uses DECE to optimise for validation set calibration with respect to model hyper-parameters. The results show that we achieve competitive performance with existing calibration approaches. Our framework opens up a new avenue and toolset for tackling calibration, which we believe will inspire further work on thi
    
[^34]: 功能性最优输运：功能数据的映射估计和领域适应

    Functional optimal transport: map estimation and domain adaptation for functional data. (arXiv:2102.03895v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2102.03895](http://arxiv.org/abs/2102.03895)

    这篇论文介绍了在函数空间上解决分布最优输运问题的方法，通过使用Hilbert-Schmidt算子将函数域之间的随机映射进行表示。这种方法对于处理函数数据的机器学习任务非常有用。

    

    我们引入了一种在函数空间上对分布进行最优输运问题的表达，其中函数域之间的随机映射可以部分地表示为一个（无限维）Hilbert-Schmidt算子，将一个函数的希尔伯特空间映射到另一个函数上。对于许多机器学习任务，数据可以自然地视为从函数空间中采样得到的，例如曲线和曲面，在高维空间中。功能数据分析的最优输运提供了对这些领域进行处理的有用框架。

    We introduce a formulation of optimal transport problem for distributions on function spaces, where the stochastic map between functional domains can be partially represented in terms of an (infinite-dimensional) Hilbert-Schmidt operator mapping a Hilbert space of functions to another. For numerous machine learning tasks, data can be naturally viewed as samples drawn from spaces of functions, such as curves and surfaces, in high dimensions. Optimal transport for functional data analysis provides a useful framework of treatment for such domains. { Since probability measures in infinite dimensional spaces generally lack absolute continuity (that is, with respect to non-degenerate Gaussian measures), the Monge map in the standard optimal transport theory for finite dimensional spaces may not exist. Our approach to the optimal transport problem in infinite dimensions is by a suitable regularization technique -- we restrict the class of transport maps to be a Hilbert-Schmidt space of operat
    
[^35]: 使用插值核岭回归估计导数的研究

    On the Estimation of Derivatives Using Plug-in Kernel Ridge Regression Estimators. (arXiv:2006.01350v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2006.01350](http://arxiv.org/abs/2006.01350)

    本文提出了一种插值核岭回归（KRR）估计器，可广泛适用于非参数回归中的多维支持和任意混合偏导数，并且具有较强的误差界。

    

    我们研究了对回归函数的导数进行估计的问题，这在未知函数的非参数化功能中具有广泛的应用。标准的分析可能针对特定的导数阶数进行调整，而参数调优特别是对于高阶导数来说仍然是一个困难的挑战。在本文中，我们提出了一种简单的插值核岭回归（KRR）估计器，用于具有随机设计的非参数回归，广泛适用于多维支持和任意混合偏导数。我们提供了非渐近分析，以统一地研究所提出的估计器的行为，包括回归函数及其导数，在强L∞范数下导致了一个一般类的核函数的两个误差界。在一个具体的例子中，该估计器专门针对具有多项式衰减特征值的核函数，实现了最小化的最优速率，只有一个对数因子可估计

    We study the problem of estimating the derivatives of a regression function, which has a wide range of applications as a key nonparametric functional of unknown functions. Standard analysis may be tailored to specific derivative orders, and parameter tuning remains a daunting challenge particularly for high-order derivatives. In this article, we propose a simple plug-in kernel ridge regression (KRR) estimator in nonparametric regression with random design that is broadly applicable for multi-dimensional support and arbitrary mixed-partial derivatives. We provide a non-asymptotic analysis to study the behavior of the proposed estimator in a unified manner that encompasses the regression function and its derivatives, leading to two error bounds for a general class of kernels under the strong $L_\infty$ norm. In a concrete example specialized to kernels with polynomially decaying eigenvalues, the proposed estimator recovers the minimax optimal rate up to a logarithmic factor for estimatin
    
[^36]: 使用生成对抗网络学习生成时间系列条件图

    Learning to Generate Time Series Conditioned Graphs with Generative Adversarial Nets. (arXiv:2003.01436v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2003.01436](http://arxiv.org/abs/2003.01436)

    本文提出了一种新颖的时间序列条件图生成方法(TSGG-GAN)，通过结合丰富的节点级上下文结构来推断时间序列之间的关系图。

    

    最近，基于深度学习的方法已被用于建模和生成符合不同分布的图。然而，它们通常是基于无监督学习的、无条件的生成模型，或者仅基于图级上下文条件生成，这与丰富的语义节点级上下文无关。不同地，在本文中，我们对一个名为时间序列条件图生成的新问题感兴趣：给定一个输入的多变量时间序列，我们的目标是推断一个目标关系图，该图建模了时间序列之间的潜在相互关系，其中每个节点对应一个时间序列。例如，我们可以研究以基因表达数据作为时间序列条件的某种疾病的基因调控网络中基因之间的相互关系。为了实现这个目标，我们提出了一种新颖的时间序列条件图生成-生成对抗网络（TSGG-GAN）来处理丰富的节点级上下文结构的挑战。

    Deep learning based approaches have been utilized to model and generate graphs subjected to different distributions recently. However, they are typically unsupervised learning based and unconditioned generative models or simply conditioned on the graph-level contexts, which are not associated with rich semantic node-level contexts. Differently, in this paper, we are interested in a novel problem named Time Series Conditioned Graph Generation: given an input multivariate time series, we aim to infer a target relation graph modeling the underlying interrelationships between time series with each node corresponding to each time series. For example, we can study the interrelationships between genes in a gene regulatory network of a certain disease conditioned on their gene expression data recorded as time series. To achieve this, we propose a novel Time Series conditioned Graph Generation-Generative Adversarial Networks (TSGG-GAN) to handle challenges of rich node-level context structures 
    
[^37]: 深度学习的泛化问题

    Generalization in Deep Learning. (arXiv:1710.05468v8 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1710.05468](http://arxiv.org/abs/1710.05468)

    本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，提出了一些新的开放问题，并讨论了研究结果的局限性。

    

    本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，回应了文献中的一个开放问题。我们还讨论了提供深度学习非虚空泛化保证的方法。基于理论观察，我们提出了一些新的开放问题，并讨论了我们研究结果的局限性。

    This paper provides theoretical insights into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, responding to an open question in the literature. We also discuss approaches to provide non-vacuous generalization guarantees for deep learning. Based on theoretical observations, we propose new open problems and discuss the limitations of our results.
    

