# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees](https://rss.arxiv.org/abs/2402.00899) | 这项工作提出了使用具有可证明性能保证的弱监督AI错误修正器来处理AI错误。修正器通过批准或拒绝底层分类器的决策来提升性能，并通过概率界限保证其性能。实验证明该方法在训练数据稀缺的真实世界任务中提升图像分类器的性能。 |
| [^2] | [Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification](https://arxiv.org/abs/2402.04211) | 本研究引入了变分Shapley网络，通过概率化的方法简化了计算Shapley值的过程，并解决了估计模型边际值和处理解释可变性的挑战。 |
| [^3] | [Scaling Laws for Downstream Task Performance of Large Language Models](https://arxiv.org/abs/2402.04177) | 本研究探讨了在转移学习环境中大型语言模型的尺度行为，发现微调数据集的大小和预训练数据与下游数据的分布一致性对下游性能有显著影响。 |
| [^4] | [Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains](https://arxiv.org/abs/2402.04161) | 提出了一个新的框架，通过马尔可夫链的视角研究了注意力模型的顺序建模能力，理论上刻画了单层Transformer的损失景观并发现了全局最小值和坏局部最小值的存在。 |
| [^5] | [Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process](https://arxiv.org/abs/2402.04146) | 这篇论文提出了一种基于潜变量高斯过程的多源数据融合框架，用于解决多个数据源之间质量和全面性差异给系统优化带来的问题。 |
| [^6] | [SCAFFLSA: Quantifying and Eliminating Heterogeneity Bias in Federated Linear Stochastic Approximation and Temporal Difference Learning](https://arxiv.org/abs/2402.04114) | 本文量化了联邦线性随机逼近算法中异质性偏差的影响，并提出SCAFFLSA作为一种改进方法来消除此偏差。在联邦时间差异学习中，该方法能够显著提高算法的复杂性。 |
| [^7] | [Provably learning a multi-head attention layer](https://arxiv.org/abs/2402.04084) | 该论文介绍了可证学习多头注意力层的研究，并给出了该问题的非平凡的上下界限制。 |
| [^8] | [More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms](https://arxiv.org/abs/2402.04054) | 通过学习学习算法，实现更灵活的PAC-Bayesian元学习，允许更灵活的任务之间的知识转移，提供新的泛化界限，可适用于分析和设计各种元学习机制，并在实际应用中改善了预测质量。 |
| [^9] | [PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network](https://arxiv.org/abs/2402.04038) | 本文提出了一种基于PAC-Bayesian框架的方法，来研究对抗鲁棒性泛化界限问题，针对两种流行的图神经网络模型进行了分析，结果发现图上扩散矩阵的谱范数、权重的谱范数和扰动因子对模型的鲁棒泛化界限有重要影响。 |
| [^10] | [A General Theory for Kernel Packets: from state space model to compactly supported basis](https://arxiv.org/abs/2402.04022) | 该论文提出了一种从状态空间模型到紧支持基的核分组的通用理论，该理论可以用于降低高斯过程的训练和预测时间，并且通过适当的线性组合产生了$m$个紧支持的核分组函数。 |
| [^11] | [Efficient Availability Attacks against Supervised and Contrastive Learning Simultaneously](https://arxiv.org/abs/2402.04010) | 本文提出了一种高效的可用性攻击方法，可以同时针对监督学习和对比学习，通过生成难以察觉的噪音和制造不可学习的示例来防止未经授权使用数据，并实现了监督和对比学习算法的最新最坏情况的不可学习性。 |
| [^12] | [Gradient Sketches for Training Data Attribution and Studying the Loss Landscape](https://arxiv.org/abs/2402.03994) | 本论文提出了一种可扩展的渐变草图算法，用于训练数据归因和损失地貌研究。作者在三个应用中展示了该方法的有效性。 |
| [^13] | [Neural Rank Collapse: Weight Decay and Small Within-Class Variability Yield Low-Rank Bias](https://arxiv.org/abs/2402.03991) | 神经网络中的权重衰减和小的类内变化与低秩偏差现象有关 |
| [^14] | [Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation](https://arxiv.org/abs/2402.03990) | 通过研究差分隐私随机梯度下降（DP-SGD）中的总梯度方差，我们发现大批次大小有助于减小則采樣引起的方差，从而提高优化效果。 |
| [^15] | [A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets](https://arxiv.org/abs/2402.03985) | 本研究通过对多个合成数据集进行偏差-方差分解，增加了对其理论理解。实验证明多个合成数据集对于高方差的下游预测器特别有益，并提供了一个简单的经验法则用于选择适当的合成数据集数量。 |
| [^16] | [On Convergence of Adam for Stochastic Optimization under Relaxed Assumptions](https://arxiv.org/abs/2402.03982) | 本文研究了在宽松假设下的随机优化中Adam算法的收敛性。我们引入了一个全面的噪声模型，并证明了在这个模型下，Adam算法可以以较高的概率高效地寻找到一个稳定点。与其他随机一阶算法相比，Adam算法具有更好的自适应性能，无需调整步长和问题参数。 |
| [^17] | [Mixed Matrix Completion in Complex Survey Sampling under Heterogeneous Missingness](https://arxiv.org/abs/2402.03954) | 本论文针对现代大样本和混合类型问卷调查的特点，提出了一个在异质缺失情况下恢复复杂抽样混合矩阵的方法，通过两阶段的过程，利用逻辑回归建模缺失机制并最大化加权对数似然以实现矩阵补全。实验结果表明该方法具有优越性能。 |
| [^18] | [Learning Metrics that Maximise Power for Accelerated A/B-Tests](https://arxiv.org/abs/2402.03915) | 本论文提出了一种新方法，通过从短期信号中学习指标，直接最大化指标与北极度量标准之间的统计能力，从而减少在线控制实验的成本。 |
| [^19] | [Batch Universal Prediction](https://arxiv.org/abs/2402.03901) | 该论文研究了大型语言模型（LLM）在通用预测方面的性能评估，引入了批量遗憾的概念，并研究了在无记忆源和一阶马尔可夫源的情况下的渐近值。 |
| [^20] | [A Framework for Bilevel Optimization on Riemannian Manifolds](https://arxiv.org/abs/2402.03883) | 本论文提出了一个在黎曼流形上解决约束双层优化问题的框架，并提供了多种超梯度估计策略，并对其进行了研究。该框架不仅适用于确定性双层优化问题，还适用于随机双层优化问题，并且可以使用一般的回退。在各种应用中，该框架都具有很高的实用性。 |
| [^21] | [Random features models: a way to study the success of naive imputation](https://arxiv.org/abs/2402.03839) | 这项研究探讨了在高维线性预测器和完全随机缺失数据的背景下，天真插补方法在预测性能上的偏差较低，并且在非常低的维度下依然是有效的。 |
| [^22] | [Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels](https://arxiv.org/abs/2402.03838) | 本研究提出了一种带有切片Wasserstein Weisfeiler-Lehman图核的高斯过程回归方法，在处理大规模稀疏图形数据集时具有正定性和显著的复杂度降低。 |
| [^23] | [Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies](https://arxiv.org/abs/2402.03819) | SMOTE是一种处理不平衡数据集的常用重新平衡策略，它通过复制原始少数样本来重新生成原始分布。本研究证明了SMOTE的密度在少数样本分布的边界附近逐渐减小，从而验证了BorderLine SMOTE策略的合理性。此外，研究还提出了两种新的SMOTE相关策略，并与其他重新平衡方法进行了比较。最终发现，在数据集极度不平衡的情况下，SMOTE、提出的方法或欠采样程序是最佳的策略。 |
| [^24] | [Combining additivity and active subspaces for high-dimensional Gaussian process modeling](https://arxiv.org/abs/2402.03809) | 本论文的贡献是将可加性和主动子空间与多重真实度策略结合，解决了高维高斯过程建模中的维度灾难问题，并通过实验证明了这些优势。 |
| [^25] | [EERO: Early Exit with Reject Option for Efficient Classification with limited budget](https://arxiv.org/abs/2402.03779) | EERO 是一种早期退出与拒绝选项的新方法，通过使用多个分类器来选择每个实例的退出头，以实现高效分类。实验结果表明，它可以有效管理预算分配并提高准确性。 |
| [^26] | [Differentially Private High Dimensional Bandits](https://arxiv.org/abs/2402.03737) | 这篇论文提出了PrivateLASSO算法，用于解决高维随机上下文线性赌臂问题，并在差分隐私的约束下证明了其隐私和实用性保证。 |
| [^27] | [Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes](https://arxiv.org/abs/2402.03726) | 本论文提出了一种名为ISAHP的深度学习框架，可以从异步、相互依赖的多类型事件序列中无监督地学习实例级的格兰杰因果关系。它是第一个满足格兰杰因果关系要求的神经点过程模型，并利用变压器的自我注意机制来实现格兰杰因果关系的推断。 |
| [^28] | [Statistical Test for Anomaly Detections by Variational Auto-Encoders](https://arxiv.org/abs/2402.03724) | 本研究提出了一种利用变分自动编码器进行异常检测的统计测试方法（VAE-AD测试），通过量化异常区域的可靠性，可以控制误检的概率到所期望的水平。 |
| [^29] | [Improving and Unifying Discrete&Continuous-time Discrete Denoising Diffusion](https://arxiv.org/abs/2402.03701) | 本文提出了一种改进和统一离散和连续时间离散去噪扩散的方法。通过数学简化和推导，使得离散扩散的训练更准确易优化，并且实现了精确和加速的采样。同时，成功地统一了离散时间和连续时间离散扩散。 |
| [^30] | [Estimating the Local Learning Coefficient at Scale](https://arxiv.org/abs/2402.03698) | 本文提出了一种方法，可以在深度线性网络中准确地测量高达1亿参数的局部学习系数(LLC)，并证明了估计得到的LLC具有重缩放不变性。 |
| [^31] | [Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation](https://arxiv.org/abs/2402.03687) | PARD是一种将扩散模型与自回归方法相结合的置换不变性自回归扩散模型，通过使用图中的部分顺序以块逐块的自回归方式生成图。 |
| [^32] | [Efficient Solvers for Partial Gromov-Wasserstein](https://arxiv.org/abs/2402.03664) | 本文提出了两个基于Frank-Wolfe算法的新的高效求解器来解决偏差Gromov-Wasserstein问题，并且证明了PGW问题构成了度量测度空间的度量。 |
| [^33] | [Operator SVD with Neural Networks via Nested Low-Rank Approximation](https://arxiv.org/abs/2402.03655) | 本文提出了一个新的优化框架，使用嵌套的低秩近似方法通过神经网络实现运算符的奇异值分解。该方法通过无约束优化公式隐式高效地保持学习函数的正交性。 |
| [^34] | [Bayesian Factorised Granger-Causal Graphs For Multivariate Time-series Data](https://arxiv.org/abs/2402.03614) | 本研究提出了一种新的贝叶斯VAR模型，利用分层图先验推断二元格兰杰因果图的后验概率。相比竞争方法，我们的方法在不确定性量化、超参数数量和稀疏多变量时间序列数据上都表现更好。 |
| [^35] | [Effective Acquisition Functions for Active Correlation Clustering](https://arxiv.org/abs/2402.03587) | 本文提出了三种有效的获取函数用于主动相关聚类，分别基于不一致性概念和信息论量。 |
| [^36] | [Regulation Games for Trustworthy Machine Learning](https://arxiv.org/abs/2402.03540) | 本论文提出了一个以调节游戏为基础的框架，将可信机器学习视为多目标多主体优化问题。通过引入ParetoPlay算法，寻找社会最优的游戏解决方案，该算法能够确保代理方始终保持在Pareto前沿上。 |
| [^37] | [Consistent Validation for Predictive Methods in Spatial Settings](https://arxiv.org/abs/2402.03527) | 本论文研究了在空间环境中验证预测方法的一致性问题，提出了一种能够处理不匹配情况的方法。 |
| [^38] | [How Does Unlabeled Data Provably Help Out-of-Distribution Detection?](https://arxiv.org/abs/2402.03502) | 本文介绍了一种新的学习框架SAL（Separate And Learn），通过利用未标记数据和标记数据，分离并训练异常点和OOD分类器，理论上提供了强大的保证和严格的错误界限。 |
| [^39] | [Attention Meets Post-hoc Interpretability: A Mathematical Perspective](https://arxiv.org/abs/2402.03485) | 本文通过数学方式研究了基于注意力机制的架构，比较了事后解释和基于注意力机制的解释的差异，发现尽管有局限性，事后解释方法能够捕获比仅仅检查注意力权重更有用的洞察。 |
| [^40] | [Stochastic Modified Flows for Riemannian Stochastic Gradient Descent](https://arxiv.org/abs/2402.03467) | 本文研究了黎曼随机梯度下降（RSGD）的收敛速度，并介绍了一种基于随机修改流（RSMF）的扩散逼近方法，该方法可以提高对RSGD的近似精度。 |
| [^41] | [Breaking the Curse of Dimensionality with Distributed Neural Computation](https://arxiv.org/abs/2402.03460) | 通过分布式神经计算算法，我们提出了一种理论方法来克服维度灾难，并证明了我们的模型可以在任意精度下逼近Lipschitz函数，在参数量和前向传播方面具有优势。 |
| [^42] | [Challenges in Variable Importance Ranking Under Correlation](https://arxiv.org/abs/2402.03447) | 变量重要性排序在解释机器学习中很重要，但是特征之间的相关性是一个挑战。最近提出了基于特征 Knockoffs 的改进方法来解决这个问题，我们的工作重点是对这些方法进行评估和评估。 |
| [^43] | [Zeroth-Order primal-dual Alternating Projection Gradient Algorithms for Nonconvex Minimax Problems with Coupled linear Constraints](https://arxiv.org/abs/2402.03352) | 本文研究了具有耦合线性约束的非凸极小极大问题的零阶算法，提出了两个单循环算法用于求解这些问题，并证明了它们的迭代复杂度分别为O(ε^(-2))和O(ε^(-4))。 |
| [^44] | [Weakly supervised covariance matrices alignment through Stiefel matrices estimation for MEG applications](https://arxiv.org/abs/2402.03345) | 本文引入了一种在MEG应用中用于时间序列数据的新颖领域自适应技术，称为混合模型斯蒂弗适应（MSA），通过利用无标记数据建立了等效信号方差的成对对应关系以确保有效的预测性能。在神经科学问题中，MSA在使用脑磁图进行脑龄回归时表现优于最近的方法。 |
| [^45] | [Bayes-Optimal Fair Classification with Linear Disparity Constraints via Pre-, In-, and Post-processing](https://arxiv.org/abs/2402.02817) | 本文提出了一种基于贝叶斯最优的公平分类方法，通过先处理、中处理和后处理来最小化分类错误，并在给定群体公平性约束的情况下进行优化。该方法引入了线性和双线性差异度量的概念，并找到了贝叶斯最优公平分类器的形式。本方法能够处理多个公平性约束和常见情况。 |
| [^46] | [Causal Bayesian Optimization via Exogenous Distribution Learning](https://arxiv.org/abs/2402.02277) | 本文引入了一种新的方法，通过学习外源变量的分布，提高了结构化因果模型的近似精度，并将因果贝叶斯优化扩展到更一般的因果方案。 |
| [^47] | [Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI](https://arxiv.org/abs/2402.00809) | 《在大规模人工智能时代的贝叶斯深度学习》这篇立场论文探讨了贝叶斯深度学习在各种不同设置下的优势，并指出了与之相关的挑战和有趣的研究方向。未来的研究重点将放在如何将大规模基础模型与贝叶斯深度学习相结合，以发挥它们的全部潜力。 |
| [^48] | [Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling](https://arxiv.org/abs/2402.00522) | 本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。 |
| [^49] | [Conditional Optimal Transport on Function Spaces](https://arxiv.org/abs/2311.05672) | 我们在函数空间中研究了条件性最优输运，提出了描述条件测度的块三角蒙特地图以及它们的Kantorovich松弛的约束最优输运问题的理论，并在贝叶斯推理问题中得到了条件映射的正则性估计。 |
| [^50] | [Neurosymbolic AI for Reasoning over Knowledge Graphs: A Survey](https://arxiv.org/abs/2302.07200) | 这项综述介绍了神经符号人工智能在知识图谱推理方面的研究。研究表明，最近的方法试图将符号推理和深度学习相结合，以生成具有解释性、竞争性能力并集成专家知识的模型。 |
| [^51] | [Semiparametric inference using fractional posteriors](https://arxiv.org/abs/2301.08158) | 本研究通过使用非参数先验基于分数后验分布的近似线性半参数函数，建立了一个通用的Bernstein-von Mises定理，提出了可靠的半参数不确定性量化方法，并通过改进的分数后验集解决了可信集大小夸大的问题。 |
| [^52] | [Optimal Regularization for a Data Source](https://arxiv.org/abs/2212.13597) | 本文研究了基于优化的方法中凸正则化的能力和局限性问题，通过研究给定分布情况下，对数据采用何种正则化方法是最优的。 |
| [^53] | [Hilbert Curve Projection Distance for Distribution Comparison](https://arxiv.org/abs/2205.15059) | 本研究提出了一种新的度量方法，称为Hilbert曲线投影(HCP)距离，用于测量两个概率分布之间的距离，并具有低复杂度。通过Hilbert曲线投影和运输距离计算，该方法适用于有界支撑的概率测度，并在高维空间中具有较好的收敛性能。为了解决维度灾难，还开发了两个HCP距离的变体，使用子空间投影。 |
| [^54] | [Bayes-Optimal Classifiers under Group Fairness](https://arxiv.org/abs/2202.09724) | 这篇论文提供了一个统一的框架，推导出在组公平性下的贝叶斯最优分类器，并提出了一种名为FairBayes的基于组的阈值方法，可以直接控制不公平现象，实现基本最优的公平性-准确性权衡。 |
| [^55] | [Alignment and Comparison of Directed Networks via Transition Couplings of Random Walks](https://arxiv.org/abs/2106.07106) | NetOTC是一种用于比较和对齐两个网络的方法，通过最小化随机行走的转换耦合的期望成本来量化网络之间的差异，并提供顶点和边的对齐。它捕捉到了关于网络的局部和全局信息，并保留了边缘。 |
| [^56] | [InstaHide's Sample Complexity When Mixing Two Private Images](https://arxiv.org/abs/2011.11877) | 本文研究了对InstaHide的最新攻击，提出了一个统一的框架来理解和分析这些攻击。通过一种新算法，在InstaHide挑战设置下，以可证明的保证和最优样本复杂度恢复所有私人图片，并提供了关于检索所有InstaHide图片的计算难度结果。 |
| [^57] | [Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot Learning](https://arxiv.org/abs/2005.09218) | 本文提出了一种基于大边际机制和伪查询集的跨域少样本学习方法，通过生成伪查询图像，并借鉴人脸识别方法中的大边际机制对特征提取模块进行微调。实验证明，该方法在各个领域上都取得了显著的优势，展示了其鲁棒性和适应预训练模型到新领域的能力。 |
| [^58] | [High-Dimensional Independence Testing via Maximum and Average Distance Correlations](https://arxiv.org/abs/2001.01095) | 本文介绍并研究了利用最大和平均距离相关性进行高维度独立性检测的方法，并提出了一种快速卡方检验的程序。该方法适用于欧氏距离和高斯核，具有较好的实证表现和广泛的应用场景。 |
| [^59] | [Independence Testing for Temporal Data](https://arxiv.org/abs/1908.06486) | 本文介绍了一种适用于测试时序数据之间独立性的时序依赖统计方法，并能够估计最佳依赖滞后。该方法解决了现有方法的限制，并且在测试平稳时间序列之间的独立性时渐近有效和普遍一致，并且与多种依赖度量方法兼容。 |
| [^60] | [Sampling in Unit Time with Kernel Fisher-Rao Flow.](http://arxiv.org/abs/2401.03892) | 本文提出了一种具有核Fisher-Rao流的新方法，在单位时间内从非归一化目标密度或贝叶斯后验中进行采样。方法使用了均场ODE和相互作用粒子系统，无需梯度，只需要能够从参考密度中采样并计算目标对参考密度的比率。该方法通过在几何混合的路径上沿速度场运输样本，径向输运样本。方法通过在再生核希尔伯特空间中求解泊松方程，使泊松方程的求解变得可行，并将其离散化为有限样本的均场ODE，作为实现简单的相互作用粒子系统。同时，这种方法也可以从离散时间的角度推导出均场ODE，作为蒙杰-安普尔方程连续线性化的极限。 |
| [^61] | [On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond.](http://arxiv.org/abs/2401.03301) | 本文提出了通过数据多样性概念来统一离线强化学习算法的方法，并证明了基于版本空间、正则化优化和后验采样的算法在标准假设下达到了可比的样本效率。 |
| [^62] | [PAC-Bayes-Chernoff bounds for unbounded losses.](http://arxiv.org/abs/2401.01148) | 这篇论文提出了一种用于无界损失的高概率PAC-Bayes参考界限，并通过优化自由参数解决了一些开放问题，并通过灵活的假设产生了新的广义界限。 |
| [^63] | [Mean-field underdamped Langevin dynamics and its spacetime discretization.](http://arxiv.org/abs/2312.16360) | 这篇论文提出了一种新的算法，用于优化在概率测度空间上定义的非线性泛函，特别适用于训练均场神经网络、最大均值差异最小化和核斯坦差异最小化问题。算法基于均场欠阻尼朗之万动力学的新颖时空离散化，具有快速混合保证，并且在总变化距离下全局收敛。 |
| [^64] | [An Empirical Study of Simplicial Representation Learning with Wasserstein Distance.](http://arxiv.org/abs/2310.10143) | 本文研究了在树结构上利用Wasserstein距离进行简化表示学习的问题，并提出了一种基于SimCLR和负TWD的自监督学习方法来估计简化表示，通过实证研究找到了稳定的训练策略。 |
| [^65] | [On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism.](http://arxiv.org/abs/2310.07852) | 本文研究了在高维稀疏线性回归模型中的差分隐私模型选择问题。我们使用指数机制进行模型选择，并提出了Metropolis-Hastings算法来克服指数搜索空间的计算复杂性。我们的算法在一定边界条件下能够实现强模型恢复性质，并具有多项式混合时间和近似差分隐私性质。 |
| [^66] | [Molecule Design by Latent Prompt Transformer.](http://arxiv.org/abs/2310.03253) | 本文提出了一种潜在提示Transformer模型，用于解决分子设计中的优化问题。该模型包括潜在向量、分子生成模型和性质预测模型，通过对现有分子进行训练后进行模型分布的逐渐转移。 |
| [^67] | [Energy-Guided Continuous Entropic Barycenter Estimation for General Costs.](http://arxiv.org/abs/2310.01105) | 本文提出了一种基于能量导向的方法用于近似计算任意OT成本函数的连续熵OT巴氏中心，该方法具有优越的性能，并且能与基于能量的模型（EBMs）学习过程无缝连接。 |
| [^68] | [The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing.](http://arxiv.org/abs/2309.16883) | 本文提出了一个增强随机平滑的方法，通过研究随机平滑引入的方差与分类器的Lipschitz常数和边界之间的关系，以及采用单纯形投影技术来增加认证鲁棒半径。 |
| [^69] | [Deep Nonnegative Matrix Factorization with Beta Divergences.](http://arxiv.org/abs/2309.08249) | 本文提出了一种使用Beta散度的深度非负矩阵分解方法，应用于面部特征提取、文档主题识别和高光谱图像材料识别。 |
| [^70] | [Provably Efficient UCB-type Algorithms For Learning Predictive State Representations.](http://arxiv.org/abs/2307.00405) | 这篇论文提出了第一种已知的UCB类型方法用于学习预测状态表示（PSRs），并设计了一个新的奖励项来上界t |
| [^71] | [Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition.](http://arxiv.org/abs/2306.14670) | 本文研究了机器学习模型在竞争环境下的行为，发现提高数据表示质量可能会导致供应商整体预测准确性降低，从而降低社会福利。 |
| [^72] | [Better Batch for Deep Probabilistic Time Series Forecasting.](http://arxiv.org/abs/2305.17028) | 该研究提出了一种新的训练方法，通过在 mini-batch 中显式地学习误差的序列相关性，来提高深度概率时间序列预测的准确性和不确定性量化。 |
| [^73] | [The emergence of clusters in self-attention dynamics.](http://arxiv.org/abs/2305.05465) | 本文证实了当Transformer处理一系列token时，出现“领导者”的经验观察，即随着时间趋于无穷大，代表token的粒子会聚集在特定的极限对象附近，这取决于价值矩阵的谱。 |
| [^74] | [Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards.](http://arxiv.org/abs/2304.14989) | 本文提出了Kullback-Leibler Maillard Sampling (KL-MS)算法，能够在有界奖励的多臂赌博机中实现KL空间的扩展，具有较好的渐近性能。 |
| [^75] | [Estimation of sparse linear regression coefficients under $L$-subexponential covariates.](http://arxiv.org/abs/2304.11958) | 本文提出了一种方法，在不需要更强条件的情况下，即使在协变量来自 $L$-亚指数随机向量的情况下，使用$\ell_1$ -帕伯回归进行线性回归，可以得到与高斯随机向量相同（在常数因子下）的误差界限。 |
| [^76] | [Approaching an unknown communication system by latent space exploration and causal inference.](http://arxiv.org/abs/2303.10931) | 本文通过探索无监督深度生成模型的潜在空间来发现数据中有意义的属性，提出了一种极端值因果分离 (CDEV) 的方法，应用于测试鲸鱼通信系统并发现其中存在语法。 |
| [^77] | [Quasi-Arithmetic Mixtures, Divergence Minimization, and Bregman Information.](http://arxiv.org/abs/2209.07481) | 本文提供了对准算术混合、散度最小化和Bregman信息的全面分析。通过在密度函数的单调嵌入下使用Bregman散度，我们将常见的散度函数与退火路径上的中间密度关联起来。 |
| [^78] | [Variational Inference with Gaussian Mixture by Entropy Approximation.](http://arxiv.org/abs/2202.13059) | 论文提出了一种用高斯混合分布作为参数分布的变分推断方法，通过将高斯混合的熵近似为单峰高斯的熵之和来解决多峰性的问题，并从理论上分析近似误差。 |
| [^79] | [Adaptive, Rate-Optimal Hypothesis Testing in Nonparametric IV Models.](http://arxiv.org/abs/2006.09587) | 我们提出了一种自适应检验方法，用于处理非参数仪器变量模型中的结构函数的不等式和等式限制。该方法可以适应未知的平滑度和工具强度，并达到了最小值率的自适应最优检验率。 |

# 详细

[^1]: 弱监督学习器实现具有可证明性能保证的AI错误修正

    Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees

    [https://rss.arxiv.org/abs/2402.00899](https://rss.arxiv.org/abs/2402.00899)

    这项工作提出了使用具有可证明性能保证的弱监督AI错误修正器来处理AI错误。修正器通过批准或拒绝底层分类器的决策来提升性能，并通过概率界限保证其性能。实验证明该方法在训练数据稀缺的真实世界任务中提升图像分类器的性能。

    

    我们提出了一种新的方法来处理AI错误，通过引入具有先验性能保证的弱监督AI错误修正器。这些AI修正器是辅助映射，其作用是通过批准或拒绝以调节之前构建的底层分类器的决策。拒绝一个决策可以用作建议放弃做出决策的信号。该工作的一个关键技术重点是通过对错误决策的概率界限提供这些新的AI修正器的性能保证。这些界限是分布不可知的，并且不依赖于对数据维度的假设。我们的实证示例说明了该框架如何应用于改善在训练数据稀缺的具有挑战性的真实世界任务中图像分类器的性能。

    We present a new methodology for handling AI errors by introducing weakly supervised AI error correctors with a priori performance guarantees. These AI correctors are auxiliary maps whose role is to moderate the decisions of some previously constructed underlying classifier by either approving or rejecting its decisions. The rejection of a decision can be used as a signal to suggest abstaining from making a decision. A key technical focus of the work is in providing performance guarantees for these new AI correctors through bounds on the probabilities of incorrect decisions. These bounds are distribution agnostic and do not rely on assumptions on the data dimension. Our empirical example illustrates how the framework can be applied to improve the performance of an image classifier in a challenging real-world task where training data are scarce.
    
[^2]: 变分Shapley网络：一种概率化的方法用于具有不确定性量化的自解释Shapley值

    Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification

    [https://arxiv.org/abs/2402.04211](https://arxiv.org/abs/2402.04211)

    本研究引入了变分Shapley网络，通过概率化的方法简化了计算Shapley值的过程，并解决了估计模型边际值和处理解释可变性的挑战。

    

    Shapley值已经成为机器学习中阐明模型决策过程的基础工具。尽管它们被广泛采用并具有满足重要可解释性公理的独特能力，但在估计过程中仍然存在计算挑战，包括（i）对模型在所有可能的输入特征组合上进行评估，（ii）估计模型的边际值，以及（iii）处理解释的可变性。我们提出了一种新颖的自解释方法，显著简化了Shapley值的计算，只需要一次前向传递。鉴于Shapley值的确定性处理被认为是一种限制，我们探索了将概率框架纳入其中以捕捉解释中固有的不确定性。与其他替代方法不同，我们的技术不直接依赖于观测数据空间来估计边际值；相反，它使用从潜在的、特定于特征的嵌入空间中派生出的可适应的基线值。

    Shapley values have emerged as a foundational tool in machine learning (ML) for elucidating model decision-making processes. Despite their widespread adoption and unique ability to satisfy essential explainability axioms, computational challenges persist in their estimation when ($i$) evaluating a model over all possible subset of input feature combinations, ($ii$) estimating model marginals, and ($iii$) addressing variability in explanations. We introduce a novel, self-explaining method that simplifies the computation of Shapley values significantly, requiring only a single forward pass. Recognizing the deterministic treatment of Shapley values as a limitation, we explore incorporating a probabilistic framework to capture the inherent uncertainty in explanations. Unlike alternatives, our technique does not rely directly on the observed data space to estimate marginals; instead, it uses adaptable baseline values derived from a latent, feature-specific embedding space, generated by a no
    
[^3]: 大型语言模型的下游任务性能的尺度律

    Scaling Laws for Downstream Task Performance of Large Language Models

    [https://arxiv.org/abs/2402.04177](https://arxiv.org/abs/2402.04177)

    本研究探讨了在转移学习环境中大型语言模型的尺度行为，发现微调数据集的大小和预训练数据与下游数据的分布一致性对下游性能有显著影响。

    

    尺度律提供了重要的见解，可以指导大型语言模型（LLM）的设计。现有研究主要集中在研究预训练（上游）损失的尺度律。然而，在转移学习环境中，LLM先在无监督数据集上进行预训练，然后在下游任务上进行微调，我们通常也关心下游性能。在这项工作中，我们研究了在转移学习环境中的尺度行为，其中LLM被微调用于机器翻译任务。具体而言，我们研究了预训练数据的选择和大小对下游性能（翻译质量）的影响，使用了两个评价指标：下游交叉熵和BLEU分数。我们的实验证明，微调数据集的大小和预训练数据与下游数据的分布一致性显著影响尺度行为。在充分一致性情况下，下游交叉熵和BLEU分数都会逐渐提升。

    Scaling laws provide important insights that can guide the design of large language models (LLMs). Existing work has primarily focused on studying scaling laws for pretraining (upstream) loss. However, in transfer learning settings, in which LLMs are pretrained on an unsupervised dataset and then finetuned on a downstream task, we often also care about the downstream performance. In this work, we study the scaling behavior in a transfer learning setting, where LLMs are finetuned for machine translation tasks. Specifically, we investigate how the choice of the pretraining data and its size affect downstream performance (translation quality) as judged by two metrics: downstream cross-entropy and BLEU score. Our experiments indicate that the size of the finetuning dataset and the distribution alignment between the pretraining and downstream data significantly influence the scaling behavior. With sufficient alignment, both downstream cross-entropy and BLEU score improve monotonically with 
    
[^4]: 基于马尔可夫链的注意力模型的规范分析框架：通过马尔可夫链研究Transformer的顺序建模能力

    Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains

    [https://arxiv.org/abs/2402.04161](https://arxiv.org/abs/2402.04161)

    提出了一个新的框架，通过马尔可夫链的视角研究了注意力模型的顺序建模能力，理论上刻画了单层Transformer的损失景观并发现了全局最小值和坏局部最小值的存在。

    

    近年来，基于注意力的Transformer在包括自然语言在内的多个领域取得了巨大成功。其中一个关键因素是生成式预训练过程，模型在此过程中通过自回归的方式在大型文本语料库上进行训练。为了揭示这一现象，我们提出了一个新的框架，通过马尔可夫链的视角，允许理论和系统实验来研究Transformer的顺序建模能力。受到自然语言的马尔可夫性质的启发，我们将数据建模为一个马尔可夫源，并利用这个框架系统地研究数据分布特性、Transformer架构、学到的分布和最终模型性能之间的相互作用。特别地，我们理论上刻画了单层Transformer的损失景观，并展示了全局最小值和坏局部最小值的存在，这取决于具体的数据性质。

    In recent years, attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. A key ingredient behind their success is the generative pretraining procedure, during which these models are trained on a large text corpus in an auto-regressive manner. To shed light on this phenomenon, we propose a new framework that allows both theory and systematic experiments to study the sequential modeling capabilities of transformers through the lens of Markov chains. Inspired by the Markovianity of natural languages, we model the data as a Markovian source and utilize this framework to systematically study the interplay between the data-distributional properties, the transformer architecture, the learnt distribution, and the final model performance. In particular, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima and bad local minima contingent upon the specific data chara
    
[^5]: 可解释的多源数据融合通过潜变量高斯过程

    Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process

    [https://arxiv.org/abs/2402.04146](https://arxiv.org/abs/2402.04146)

    这篇论文提出了一种基于潜变量高斯过程的多源数据融合框架，用于解决多个数据源之间质量和全面性差异给系统优化带来的问题。

    

    随着人工智能（AI）和机器学习（ML）的出现，各个科学和工程领域已经利用数据驱动的替代模型来建模来自大量信息源（数据）的复杂系统。这种增加导致了开发出用于执行特定功能的优越系统所需的成本和时间的显著降低。这样的替代模型往往广泛地融合多个数据来源，可能是发表的论文、专利、开放资源库或其他资源。然而，对于已知和未知的信息来源的基础物理参数的质量和全面性的差异，可能对系统优化过程产生后续影响，却没有得到充分的关注。为了解决这个问题，提出了一种基于潜变量高斯过程（LVGP）的多源数据融合框架。

    With the advent of artificial intelligence (AI) and machine learning (ML), various domains of science and engineering communites has leveraged data-driven surrogates to model complex systems from numerous sources of information (data). The proliferation has led to significant reduction in cost and time involved in development of superior systems designed to perform specific functionalities. A high proposition of such surrogates are built extensively fusing multiple sources of data, may it be published papers, patents, open repositories, or other resources. However, not much attention has been paid to the differences in quality and comprehensiveness of the known and unknown underlying physical parameters of the information sources that could have downstream implications during system optimization. Towards resolving this issue, a multi-source data fusion framework based on Latent Variable Gaussian Process (LVGP) is proposed. The individual data sources are tagged as a characteristic cate
    
[^6]: SCAFFLSA：量化和消除联邦线性随机逼近和时间差异学习中的异质性偏差

    SCAFFLSA: Quantifying and Eliminating Heterogeneity Bias in Federated Linear Stochastic Approximation and Temporal Difference Learning

    [https://arxiv.org/abs/2402.04114](https://arxiv.org/abs/2402.04114)

    本文量化了联邦线性随机逼近算法中异质性偏差的影响，并提出SCAFFLSA作为一种改进方法来消除此偏差。在联邦时间差异学习中，该方法能够显著提高算法的复杂性。

    

    本文对联邦线性随机逼近算法（FedLSA）进行了非渐进分析。我们明确量化了异质代理本地训练引入的偏差，并研究了该算法的样本复杂性。我们证明了FedLSA的通信复杂性与所需精度 $\epsilon$ 呈多项式关系，这限制了联邦的好处。为了克服这一问题，我们提出了SCAFFLSA，一种新型的FedLSA变体，它使用控制变量来校正本地训练的偏差，并在不对统计异质性做出任何假设的情况下证明了其收敛性。我们将所提出的方法应用于具有线性函数逼近的联邦时间差异学习，并分析了相应的复杂性改进。

    In this paper, we perform a non-asymptotic analysis of the federated linear stochastic approximation (FedLSA) algorithm. We explicitly quantify the bias introduced by local training with heterogeneous agents, and investigate the sample complexity of the algorithm. We show that the communication complexity of FedLSA scales polynomially with the desired precision $\epsilon$, which limits the benefits of federation. To overcome this, we propose SCAFFLSA, a novel variant of FedLSA, that uses control variates to correct the bias of local training, and prove its convergence without assumptions on statistical heterogeneity. We apply the proposed methodology to federated temporal difference learning with linear function approximation, and analyze the corresponding complexity improvements.
    
[^7]: 可证学习多头注意力层

    Provably learning a multi-head attention layer

    [https://arxiv.org/abs/2402.04084](https://arxiv.org/abs/2402.04084)

    该论文介绍了可证学习多头注意力层的研究，并给出了该问题的非平凡的上下界限制。

    

    多头注意力层是变形器架构的关键组件之一，使其与传统的前馈模型有所区别。通过给定序列长度 $k$，注意力矩阵 $\mathbf{\Theta}_1,\ldots,\mathbf{\Theta}_m\in\mathbb{R}^{d\times d}$，以及投影矩阵 $\mathbf{W}_1,\ldots,\mathbf{W}_m\in\mathbb{R}^{d\times d}$，相应的多头注意力层 $F: \mathbb{R}^{k\times d}\to \mathbb{R}^{k\times d}$ 通过 $F(\mathbf{X}) \triangleq \sum^m_{i=1} \mathrm{softmax}(\mathbf{X}\mathbf{\Theta}_i\mathbf{X}^\top)\mathbf{X}\mathbf{W}_i$ 来转化长度为 $k$ 的 $d$ 维令牌序列 $\mathbf{X}\in\mathbb{R}^{k\times d}$。在这项工作中，我们开始研究通过随机示例可证学习多头注意力层，并为该问题给出了首个非平凡的上下界限制：假设 $\{\mathbf{W}_i, \mathbf{\Theta}_i\}$ 满足某些非退化条件，我们提供了一个 $(dk)^{O(m^3)}$ 时间复杂度的算法，用于学习。

    The multi-head attention layer is one of the key components of the transformer architecture that sets it apart from traditional feed-forward models. Given a sequence length $k$, attention matrices $\mathbf{\Theta}_1,\ldots,\mathbf{\Theta}_m\in\mathbb{R}^{d\times d}$, and projection matrices $\mathbf{W}_1,\ldots,\mathbf{W}_m\in\mathbb{R}^{d\times d}$, the corresponding multi-head attention layer $F: \mathbb{R}^{k\times d}\to \mathbb{R}^{k\times d}$ transforms length-$k$ sequences of $d$-dimensional tokens $\mathbf{X}\in\mathbb{R}^{k\times d}$ via $F(\mathbf{X}) \triangleq \sum^m_{i=1} \mathrm{softmax}(\mathbf{X}\mathbf{\Theta}_i\mathbf{X}^\top)\mathbf{X}\mathbf{W}_i$. In this work, we initiate the study of provably learning a multi-head attention layer from random examples and give the first nontrivial upper and lower bounds for this problem:   - Provided $\{\mathbf{W}_i, \mathbf{\Theta}_i\}$ satisfy certain non-degeneracy conditions, we give a $(dk)^{O(m^3)}$-time algorithm that learns
    
[^8]: 通过学习学习算法，实现更灵活的PAC-Bayesian元学习

    More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms

    [https://arxiv.org/abs/2402.04054](https://arxiv.org/abs/2402.04054)

    通过学习学习算法，实现更灵活的PAC-Bayesian元学习，允许更灵活的任务之间的知识转移，提供新的泛化界限，可适用于分析和设计各种元学习机制，并在实际应用中改善了预测质量。

    

    我们引入了一种使用PAC-Bayesian理论研究元学习方法的新框架。与之前的工作相比，其主要优势在于它允许在任务之间的知识转移中更具灵活性。以往的方法只能通过学习模型的先验分布间接发生。相比之下，我们证明的新的泛化界限更直接地表达了元学习的过程，即学习适用于将来任务的学习算法。我们的框架的灵活性使其适用于分析各种元学习机制甚至设计新的机制。除了我们的理论贡献外，我们还在实际元学习机制中展示了我们的框架提高了预测质量。

    We introduce a new framework for studying meta-learning methods using PAC-Bayesian theory. Its main advantage over previous work is that it allows for more flexibility in how the transfer of knowledge between tasks is realized. For previous approaches, this could only happen indirectly, by means of learning prior distributions over models. In contrast, the new generalization bounds that we prove express the process of meta-learning much more directly as learning the learning algorithm that should be used for future tasks. The flexibility of our framework makes it suitable to analyze a wide range of meta-learning mechanisms and even design new mechanisms. Other than our theoretical contributions we also show empirically that our framework improves the prediction quality in practical meta-learning mechanisms.
    
[^9]: PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network

    PAC-Bayesian Adversarially Robust Generalization Bounds for Graph Neural Network

    [https://arxiv.org/abs/2402.04038](https://arxiv.org/abs/2402.04038)

    本文提出了一种基于PAC-Bayesian框架的方法，来研究对抗鲁棒性泛化界限问题，针对两种流行的图神经网络模型进行了分析，结果发现图上扩散矩阵的谱范数、权重的谱范数和扰动因子对模型的鲁棒泛化界限有重要影响。

    

    图神经网络（GNNs）在各种与图相关的任务中广受欢迎。然而，类似于深度神经网络，GNNs也容易受到对抗攻击。经验研究表明，对抗鲁棒性泛化在建立有效的抵御对抗攻击的防御算法方面起着关键作用。本文通过使用PAC-Bayesian框架，为两种流行的GNNs，即图卷积网络（GCN）和消息传递图神经网络，提供了对抗鲁棒泛化界限。我们的结果揭示了图上扩散矩阵的谱范数、权重的谱范数以及扰动因子对两个模型的鲁棒泛化界限的影响。我们的界限是（Liao等人，2020）中结果的非平凡推广，从标准设置扩展到对抗设置，同时避免了最大节点度的指数依赖。作为推论，我们得出更好的界限...

    Graph neural networks (GNNs) have gained popularity for various graph-related tasks. However, similar to deep neural networks, GNNs are also vulnerable to adversarial attacks. Empirical studies have shown that adversarially robust generalization has a pivotal role in establishing effective defense algorithms against adversarial attacks. In this paper, we contribute by providing adversarially robust generalization bounds for two kinds of popular GNNs, graph convolutional network (GCN) and message passing graph neural network, using the PAC-Bayesian framework. Our result reveals that spectral norm of the diffusion matrix on the graph and spectral norm of the weights as well as the perturbation factor govern the robust generalization bounds of both models. Our bounds are nontrivial generalizations of the results developed in (Liao et al., 2020) from the standard setting to adversarial setting while avoiding exponential dependence of the maximum node degree. As corollaries, we derive bette
    
[^10]: 一种从状态空间模型到紧支持基的核分组的通用理论

    A General Theory for Kernel Packets: from state space model to compactly supported basis

    [https://arxiv.org/abs/2402.04022](https://arxiv.org/abs/2402.04022)

    该论文提出了一种从状态空间模型到紧支持基的核分组的通用理论，该理论可以用于降低高斯过程的训练和预测时间，并且通过适当的线性组合产生了$m$个紧支持的核分组函数。

    

    众所周知，高斯过程（GP）的状态空间（SS）模型公式可以将其训练和预测时间降低到O（n）（n为数据点个数）。我们证明了一个m维的GP的SS模型公式等价于我们引入的一个概念，称为通用右核分组（KP）：一种用于GP协方差函数K的变换，使得对于任意$t \leq t_1$，$0 \leq j \leq m-1$和$m+1$个连续点$t_i$，都满足$\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$，其中${D}_t^{(j)}f(t)$表示在$t$上作用的第j阶导数。我们将这个思想扩展到了GP的向后SS模型公式，得到了下一个$m$个连续点的左核分组的概念：$\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$，对于任意$t\geq t_{2m}$。通过结合左右核分组，可以证明这些协方差函数的适当线性组合产生了$m$个紧支持的核分组函数：对于任意$t\not\in(t_0,t_{2m})$和$j=0,\cdots,m-1$，$\phi^{(j)}(t)=0$。

    It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \leq t_1$, 0 $\leq j \leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\phi^{(j)}(t)=0$ for any $t\not\in(t_0,t_{2m})$ and $j=0,\cdots,m-1$
    
[^11]: 针对监督和对比学习的高效可用性攻击

    Efficient Availability Attacks against Supervised and Contrastive Learning Simultaneously

    [https://arxiv.org/abs/2402.04010](https://arxiv.org/abs/2402.04010)

    本文提出了一种高效的可用性攻击方法，可以同时针对监督学习和对比学习，通过生成难以察觉的噪音和制造不可学习的示例来防止未经授权使用数据，并实现了监督和对比学习算法的最新最坏情况的不可学习性。

    

    可用性攻击可以通过生成难以察觉的噪音和制造不可学习的示例来防止私人数据和商业数据集的未经授权使用。当监督学习算法失败时，恶意的数据收集者可能会转向对比学习算法以绕过保护。通过评估，我们发现现有的大多数方法无法同时实现监督和对比的不可学习性，这给数据保护带来了风险。与基于对比误差最小化的最新方法不同，我们在监督误差最小化或最大化框架中使用类似对比的数据增强来获得对监督和对比学习均有效的攻击。我们提出的AUE和AAP攻击在减少计算消耗的前提下，实现了监督和对比学习算法的最新最坏情况的不可学习性，展示了未来的前景。

    Availability attacks can prevent the unauthorized use of private data and commercial datasets by generating imperceptible noise and making unlearnable examples before release. Ideally, the obtained unlearnability prevents algorithms from training usable models. When supervised learning (SL) algorithms have failed, a malicious data collector possibly resorts to contrastive learning (CL) algorithms to bypass the protection. Through evaluation, we have found that most of the existing methods are unable to achieve both supervised and contrastive unlearnability, which poses risks to data protection. Different from recent methods based on contrastive error minimization, we employ contrastive-like data augmentations in supervised error minimization or maximization frameworks to obtain attacks effective for both SL and CL. Our proposed AUE and AAP attacks achieve state-of-the-art worst-case unlearnability across SL and CL algorithms with less computation consumption, showcasing prospects in re
    
[^12]: 使用渐变草图进行训练数据归因和损失地貌研究

    Gradient Sketches for Training Data Attribution and Studying the Loss Landscape

    [https://arxiv.org/abs/2402.03994](https://arxiv.org/abs/2402.03994)

    本论文提出了一种可扩展的渐变草图算法，用于训练数据归因和损失地貌研究。作者在三个应用中展示了该方法的有效性。

    

    随机投影或渐变和Hessian向量乘积的草图在需要存储许多这些向量并保留关于它们的相对几何信息的应用中起着重要作用。两个重要场景是训练数据归因（跟踪模型对训练数据的行为），其中需要存储每个训练示例的渐变，以及Hessian的频谱研究（分析训练动态），其中需要存储多个Hessian向量乘积。虽然使用密集矩阵的草图易于实现，但它们受存储限制，不能扩展到现代神经网络。在神经网络内在维度的研究工作的推动下，我们提出并研究了可伸缩草图算法的设计空间。我们在三个应用中展示了我们方法的有效性：训练数据归因，Hessian谱分析和微调预先训练时的内在维度计算。

    Random projections or sketches of gradients and Hessian vector products play an essential role in applications where one needs to store many such vectors while retaining accurate information about their relative geometry. Two important scenarios are training data attribution (tracing a model's behavior to the training data), where one needs to store a gradient for each training example, and the study of the spectrum of the Hessian (to analyze the training dynamics), where one needs to store multiple Hessian vector products. While sketches that use dense matrices are easy to implement, they are memory bound and cannot be scaled to modern neural networks. Motivated by work on the intrinsic dimension of neural networks, we propose and study a design space for scalable sketching algorithms. We demonstrate the efficacy of our approach in three applications: training data attribution, the analysis of the Hessian spectrum and the computation of the intrinsic dimension when fine-tuning pre-tra
    
[^13]: 神经网络的权重衰减和类内变化小会导致低秩偏差

    Neural Rank Collapse: Weight Decay and Small Within-Class Variability Yield Low-Rank Bias

    [https://arxiv.org/abs/2402.03991](https://arxiv.org/abs/2402.03991)

    神经网络中的权重衰减和小的类内变化与低秩偏差现象有关

    

    近期在深度学习领域的研究显示了一个隐含的低秩偏差现象：深度网络中的权重矩阵往往近似为低秩，在训练过程中或从已经训练好的模型中去除相对较小的奇异值可以显著减小模型大小，同时保持甚至提升模型性能。然而，大多数关于神经网络低秩偏差的理论研究都涉及到简化的线性深度网络。在本文中，我们考虑了带有非线性激活函数和权重衰减参数的通用网络，并展示了一个有趣的神经秩崩溃现象，它将训练好的网络的低秩偏差与网络的神经崩溃特性联系起来：随着权重衰减参数的增加，网络中每一层的秩呈比例递减，与前面层的隐藏空间嵌入的类内变化成反比。我们的理论发现得到了支持。

    Recent work in deep learning has shown strong empirical and theoretical evidence of an implicit low-rank bias: weight matrices in deep networks tend to be approximately low-rank and removing relatively small singular values during training or from available trained models may significantly reduce model size while maintaining or even improving model performance. However, the majority of the theoretical investigations around low-rank bias in neural networks deal with oversimplified deep linear networks. In this work, we consider general networks with nonlinear activations and the weight decay parameter, and we show the presence of an intriguing neural rank collapse phenomenon, connecting the low-rank bias of trained networks with networks' neural collapse properties: as the weight decay parameter grows, the rank of each layer in the network decreases proportionally to the within-class variability of the hidden-space embeddings of the previous layers. Our theoretical findings are supporte
    
[^14]: 則采樣并不是魔法: 大批量大小為什麼適用於差分隱私隨機優化

    Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation

    [https://arxiv.org/abs/2402.03990](https://arxiv.org/abs/2402.03990)

    通过研究差分隐私随机梯度下降（DP-SGD）中的总梯度方差，我们发现大批次大小有助于减小則采樣引起的方差，从而提高优化效果。

    

    我們研究了批次大小對差分隱私隨機梯度下降（DP-SGD）中總梯度方差的影響，尋求對大批次大小有用性的理論解釋。由於DP-SGD是現代差分隱私深度學習的基礎，其性質已被廣泛研究，最近的工作在實踐中發現大批次大小有益。然而，對於這種好處的理論解釋目前最多只能說是啟發式的。我們首先觀察到，在DP-SGD中，總梯度方差可以分解為由則采樣和噪聲引起的方差。然後，我們證明在無限次迭代的極限情況下，有效的噪聲引起的方差對批次大小是不變的。剩下的則采樣引起的方差隨著批次大小的增大而減小，因此大批次大小減小了有效的總梯度方差。我們在數值上確認這種漸進的情況在實際環境中是相關的，當批次大小不小的時候會起作用，並且發現

    We study the effect of the batch size to the total gradient variance in differentially private stochastic gradient descent (DP-SGD), seeking a theoretical explanation for the usefulness of large batch sizes. As DP-SGD is the basis of modern DP deep learning, its properties have been widely studied, and recent works have empirically found large batch sizes to be beneficial. However, theoretical explanations of this benefit are currently heuristic at best. We first observe that the total gradient variance in DP-SGD can be decomposed into subsampling-induced and noise-induced variances. We then prove that in the limit of an infinite number of iterations, the effective noise-induced variance is invariant to the batch size. The remaining subsampling-induced variance decreases with larger batch sizes, so large batches reduce the effective total gradient variance. We confirm numerically that the asymptotic regime is relevant in practical settings when the batch size is not small, and find tha
    
[^15]: 对多个合成数据集的集成进行偏差-方差分解

    A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets

    [https://arxiv.org/abs/2402.03985](https://arxiv.org/abs/2402.03985)

    本研究通过对多个合成数据集进行偏差-方差分解，增加了对其理论理解。实验证明多个合成数据集对于高方差的下游预测器特别有益，并提供了一个简单的经验法则用于选择适当的合成数据集数量。

    

    最近的研究强调了为监督学习生成多个合成数据集的好处，包括增加准确性、更有效的模型选择和不确定性估计。这些好处在经验上有明确的支持，但对它们的理论理解目前非常有限。我们通过推导使用多个合成数据集的几种设置的偏差-方差分解，来增加理论理解。我们的理论预测，对于高方差的下游预测器，多个合成数据集将特别有益，并为均方误差和Brier分数的情况提供了一个简单的经验法则来选择合适的合成数据集数量。我们通过评估一个集成在多个合成数据集和几个真实数据集以及下游预测器上的性能来研究我们的理论在实践中的效果。结果验证了我们的理论，表明我们的洞察也在实践中具有相关性。

    Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets. Our theory predicts multiple synthetic datasets to be especially beneficial for high-variance downstream predictors, and yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice by evaluating the performance of an ensemble over many synthetic datasets for several real datasets and downstream predictors. The results follow our theory, showing that our insights are also practically relevant.
    
[^16]: 在宽松假设下关于随机优化中Adam收敛性的研究

    On Convergence of Adam for Stochastic Optimization under Relaxed Assumptions

    [https://arxiv.org/abs/2402.03982](https://arxiv.org/abs/2402.03982)

    本文研究了在宽松假设下的随机优化中Adam算法的收敛性。我们引入了一个全面的噪声模型，并证明了在这个模型下，Adam算法可以以较高的概率高效地寻找到一个稳定点。与其他随机一阶算法相比，Adam算法具有更好的自适应性能，无需调整步长和问题参数。

    

    适应性动量评估（Adam）算法在训练各种深度学习任务中非常有效。尽管如此，在非凸光滑场景下，特别是在可能存在无界梯度和仿射方差噪声的情况下，对于Adam的理论理解仍然有限。在本文中，我们研究了在这些具有挑战性条件下的普通Adam算法。我们引入了一个全面的噪声模型，该模型控制着仿射方差噪声、有界噪声和次高斯噪声。我们证明了在这个通用噪声模型下，Adam算法可以以$\mathcal{O}(\text{poly}(\log T)/\sqrt{T})$的概率高效地寻找到一个稳定点，其中$T$表示总迭代次数，与随机一阶算法的更底效率相匹配。更重要的是，我们揭示了在相同条件下，Adam算法无需调整步长和任何问题参数，具有比随机梯度下降更好的自适应性能。

    The Adaptive Momentum Estimation (Adam) algorithm is highly effective in training various deep learning tasks. Despite this, there's limited theoretical understanding for Adam, especially when focusing on its vanilla form in non-convex smooth scenarios with potential unbounded gradients and affine variance noise. In this paper, we study vanilla Adam under these challenging conditions. We introduce a comprehensive noise model which governs affine variance noise, bounded noise and sub-Gaussian noise. We show that Adam can find a stationary point with a $\mathcal{O}(\text{poly}(\log T)/\sqrt{T})$ rate in high probability under this general noise model where $T$ denotes total number iterations, matching the lower rate of stochastic first-order algorithms up to logarithm factors. More importantly, we reveal that Adam is free of tuning step-sizes with any problem-parameters, yielding a better adaptation property than the Stochastic Gradient Descent under the same conditions. We also provide 
    
[^17]: 在异质缺失下的复杂抽样混合矩阵补全

    Mixed Matrix Completion in Complex Survey Sampling under Heterogeneous Missingness

    [https://arxiv.org/abs/2402.03954](https://arxiv.org/abs/2402.03954)

    本论文针对现代大样本和混合类型问卷调查的特点，提出了一个在异质缺失情况下恢复复杂抽样混合矩阵的方法，通过两阶段的过程，利用逻辑回归建模缺失机制并最大化加权对数似然以实现矩阵补全。实验结果表明该方法具有优越性能。

    

    现代具有大样本量和不断增长的混合类型问卷的调查需要稳健且可扩展的分析方法。在这项工作中，我们考虑通过复杂的抽样方式获得的混合数据框矩阵恢复问题，其中条目遵循不同的指数分布并受到异质缺失的影响。为了解决这个具有挑战性的任务，我们提出了一个两阶段的方法：在第一阶段，我们使用逻辑回归对条目级缺失机制进行建模；在第二阶段，我们通过最大化带有低秩约束的加权对数似然来完成目标参数矩阵的补全。我们提出了一个快速且可扩展的估计算法，它实现了次线性收敛，并严格推导了所提方法的估计误差上界。实验结果支持我们的理论结果，并且所提出的估计器在与其他现有方法的比较中展现了其优点。该方法被应用于对国家健康与...

    Modern surveys with large sample sizes and growing mixed-type questionnaires require robust and scalable analysis methods. In this work, we consider recovering a mixed dataframe matrix, obtained by complex survey sampling, with entries following different canonical exponential distributions and subject to heterogeneous missingness. To tackle this challenging task, we propose a two-stage procedure: in the first stage, we model the entry-wise missing mechanism by logistic regression, and in the second stage, we complete the target parameter matrix by maximizing a weighted log-likelihood with a low-rank constraint. We propose a fast and scalable estimation algorithm that achieves sublinear convergence, and the upper bound for the estimation error of the proposed method is rigorously derived. Experimental results support our theoretical claims, and the proposed estimator shows its merits compared to other existing methods. The proposed method is applied to analyze the National Health and N
    
[^18]: 学习最大化加速A/B测试的指标

    Learning Metrics that Maximise Power for Accelerated A/B-Tests

    [https://arxiv.org/abs/2402.03915](https://arxiv.org/abs/2402.03915)

    本论文提出了一种新方法，通过从短期信号中学习指标，直接最大化指标与北极度量标准之间的统计能力，从而减少在线控制实验的成本。

    

    在技术公司中，在线控制实验是一种重要的工具，可以实现自信的决策。定义了一个北极度量标准（如长期收入或用户保留），在A/B测试中，能够在这个指标上有统计显著提升的系统变体可以被认为是优越的。然而，北极度量标准通常具有时延和不敏感性。因此，实验的成本很高：实验需要长时间运行，即使如此，二类错误（即假阴性）仍然普遍存在。为了解决这个问题，我们提出了一种从短期信号中学习指标的方法，这些指标直接最大化它们相对于北极度量标准所具有的统计能力。我们展示了现有方法容易过拟合的问题，即更高的平均度量敏感性并不意味着改进了二类错误，我们建议通过最小化指标在过去实验的$log$上产生的$p$-value来解决。我们从两个社交媒体应用程序中收集了这样的数据集。

    Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent.   We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the $p$-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with
    
[^19]: 批处理通用预测

    Batch Universal Prediction

    [https://arxiv.org/abs/2402.03901](https://arxiv.org/abs/2402.03901)

    该论文研究了大型语言模型（LLM）在通用预测方面的性能评估，引入了批量遗憾的概念，并研究了在无记忆源和一阶马尔可夫源的情况下的渐近值。

    

    大型语言模型（LLM）因其惊人的生成类似人类英语句子的能力而近年来备受关注。LLMs本质上是预测器，通过估计给定过去的单词序列的概率来评估它们的性能。因此，从通用预测的角度评估它们的性能是自然而然的。为了公平地进行评估，我们引入了批量遗憾的概念作为经典平均遗憾的修改，并研究了在无记忆源和一阶马尔可夫源的情况下，对于增加常数预测器的渐近值。

    Large language models (LLMs) have recently gained much popularity due to their surprising ability at generating human-like English sentences. LLMs are essentially predictors, estimating the probability of a sequence of words given the past. Therefore, it is natural to evaluate their performance from a universal prediction perspective. In order to do that fairly, we introduce the notion of batch regret as a modification of the classical average regret, and we study its asymptotical value for add-constant predictors, in the case of memoryless sources and first-order Markov sources.
    
[^20]: 在黎曼流形上进行双层优化的框架

    A Framework for Bilevel Optimization on Riemannian Manifolds

    [https://arxiv.org/abs/2402.03883](https://arxiv.org/abs/2402.03883)

    本论文提出了一个在黎曼流形上解决约束双层优化问题的框架，并提供了多种超梯度估计策略，并对其进行了研究。该框架不仅适用于确定性双层优化问题，还适用于随机双层优化问题，并且可以使用一般的回退。在各种应用中，该框架都具有很高的实用性。

    

    双层优化在各个领域的应用中越来越常见。在这项工作中，我们提出了一个在黎曼流形上约束双层优化问题变量的框架。我们提供了几种在流形上的超梯度估计策略，并研究了它们的估计误差。我们对流形上的超梯度下降算法提供了收敛性和复杂性分析。我们还将这些研究扩展到随机双层优化和使用一般的回退。我们展示了该框架在各种应用中的实用性。

    Bilevel optimization has seen an increasing presence in various domains of applications. In this work, we propose a framework for solving bilevel optimization problems where variables of both lower and upper level problems are constrained on Riemannian manifolds. We provide several hypergradient estimation strategies on manifolds and study their estimation error. We provide convergence and complexity analysis for the proposed hypergradient descent algorithm on manifolds. We also extend the developments to stochastic bilevel optimization and to the use of general retraction. We showcase the utility of the proposed framework on various applications.
    
[^21]: 随机特征模型：研究天真插补的成功方法

    Random features models: a way to study the success of naive imputation

    [https://arxiv.org/abs/2402.03839](https://arxiv.org/abs/2402.03839)

    这项研究探讨了在高维线性预测器和完全随机缺失数据的背景下，天真插补方法在预测性能上的偏差较低，并且在非常低的维度下依然是有效的。

    

    常数（天真）插补作为一种最简单易用的处理缺失数据的技术，仍然被广泛使用。然而，这种简单的方法在预测目的上可能会引起很大的偏差，因为插补的输入可能与真实的基础数据差异很大。然而，最近的研究表明，在高维线性预测器的背景下，当数据被假设为完全随机缺失（MCAR）时，这种偏差较低。本文通过确认直觉，完善了线性预测器的情况，并且令人惊讶的是，天真插补在非常低的维度下仍然是有效的。为此，我们考虑了一个独特的基础随机特征模型，这个模型在观察特征的维度变化的情况下，为研究预测性能提供了严格的框架。基于这些理论结果，我们建立了应用于零插补数据的随机梯度（SGD）预测器的有限样本界限，一种策略

    Constant (naive) imputation is still widely used in practice as this is a first easy-to-use technique to deal with missing data. Yet, this simple method could be expected to induce a large bias for prediction purposes, as the imputed input may strongly differ from the true underlying data. However, recent works suggest that this bias is low in the context of high-dimensional linear predictors when data is supposed to be missing completely at random (MCAR). This paper completes the picture for linear predictors by confirming the intuition that the bias is negligible  and  that surprisingly naive imputation also remains relevant in very low dimension.To this aim, we consider a unique underlying random features model, which offers a rigorous framework for studying predictive performances, whilst the dimension of the observed features varies.Building on these theoretical results, we establish finite-sample bounds on stochastic gradient (SGD) predictors applied to zero-imputed data, a strat
    
[^22]: 带有切片Wasserstein Weisfeiler-Lehman图核的高斯过程回归

    Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels

    [https://arxiv.org/abs/2402.03838](https://arxiv.org/abs/2402.03838)

    本研究提出了一种带有切片Wasserstein Weisfeiler-Lehman图核的高斯过程回归方法，在处理大规模稀疏图形数据集时具有正定性和显著的复杂度降低。

    

    监督学习在计算物理领域引起了广泛关注，因为它能够有效地提取复杂模式，用于解决偏微分方程或预测材料性质等任务。传统上，这类数据集由具有大量节点的网格表示的输入（视为图形）和使用数值求解器获得的相应输出组成。这意味着监督学习模型必须能够处理具有连续节点属性的大规模稀疏图形。在本研究中，我们专注于高斯过程回归，引入了切片Wasserstein Weisfeiler-Lehman（SWWL）图核。与现有的图核相比，所提出的SWWL核具有正定性和显著的复杂度降低，使其能够处理此前不可处理的数据集。新的核首先在分子图分类中进行了验证。

    Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which  makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molec
    
[^23]: SMOTE的理论和实验研究：关于重新平衡策略的限制和比较

    Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies

    [https://arxiv.org/abs/2402.03819](https://arxiv.org/abs/2402.03819)

    SMOTE是一种处理不平衡数据集的常用重新平衡策略，它通过复制原始少数样本来重新生成原始分布。本研究证明了SMOTE的密度在少数样本分布的边界附近逐渐减小，从而验证了BorderLine SMOTE策略的合理性。此外，研究还提出了两种新的SMOTE相关策略，并与其他重新平衡方法进行了比较。最终发现，在数据集极度不平衡的情况下，SMOTE、提出的方法或欠采样程序是最佳的策略。

    

    SMOTE（Synthetic Minority Oversampling Technique）是处理不平衡数据集常用的重新平衡策略。我们证明了在渐进情况下，SMOTE（默认参数）通过简单复制原始少数样本来重新生成原始分布。我们还证明了在少数样本分布的支持边界附近，SMOTE的密度会减小，从而验证了常见的BorderLine SMOTE策略。随后，我们提出了两种新的SMOTE相关策略，并将它们与现有的重新平衡方法进行了比较。我们发现，只有当数据集极度不平衡时才需要重新平衡策略。对于这种数据集，SMOTE、我们提出的方法或欠采样程序是最佳的策略。

    Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.
    
[^24]: 结合可加性和主动子空间用于高维高斯过程建模

    Combining additivity and active subspaces for high-dimensional Gaussian process modeling

    [https://arxiv.org/abs/2402.03809](https://arxiv.org/abs/2402.03809)

    本论文的贡献是将可加性和主动子空间与多重真实度策略结合，解决了高维高斯过程建模中的维度灾难问题，并通过实验证明了这些优势。

    

    高斯过程是一种被广泛接受的回归和分类技术，因其良好的预测准确性、分析可追溯性和内置的不确定性量化能力而倍受欢迎。然而，当变量数量增加时，它们受到维度灾难的困扰。这个挑战通常通过在问题中假设额外结构来解决，首选选项是可加性或低内在维度。我们在高维高斯过程建模中的贡献是将它们与多重真实度策略相结合，通过对合成函数和数据集进行实验证明了这些优势。

    Gaussian processes are a widely embraced technique for regression and classification due to their good prediction accuracy, analytical tractability and built-in capabilities for uncertainty quantification. However, they suffer from the curse of dimensionality whenever the number of variables increases. This challenge is generally addressed by assuming additional structure in theproblem, the preferred options being either additivity or low intrinsic dimensionality. Our contribution for high-dimensional Gaussian process modeling is to combine them with a multi-fidelity strategy, showcasing the advantages through experiments on synthetic functions and datasets.
    
[^25]: EERO: 早期退出与拒绝选项用于有限预算下的高效分类

    EERO: Early Exit with Reject Option for Efficient Classification with limited budget

    [https://arxiv.org/abs/2402.03779](https://arxiv.org/abs/2402.03779)

    EERO 是一种早期退出与拒绝选项的新方法，通过使用多个分类器来选择每个实例的退出头，以实现高效分类。实验结果表明，它可以有效管理预算分配并提高准确性。

    

    先进的机器学习模型的不断复杂化要求创新的方法来有效管理计算资源。其中一种方法是早期退出策略，通过提供缩短简单数据实例处理路径的机制，实现自适应计算。在本文中，我们提出了EERO，一种将早期退出问题转化为使用具有拒绝选项的多个分类器问题的新方法，以便更好地选择每个实例的退出头。我们使用指数权重聚合来校准不同头部退出的概率，以保证一个固定的预算。我们考虑贝叶斯风险、预算约束和头部特定预算消耗等因素。通过在Cifar和ImageNet数据集上使用ResNet-18模型和ConvNext架构进行的实验结果表明，我们的方法不仅能有效管理预算分配，还能提高过度考虑场景中的准确性。

    The increasing complexity of advanced machine learning models requires innovative approaches to manage computational resources effectively. One such method is the Early Exit strategy, which allows for adaptive computation by providing a mechanism to shorten the processing path for simpler data instances. In this paper, we propose EERO, a new methodology to translate the problem of early exiting to a problem of using multiple classifiers with reject option in order to better select the exiting head for each instance. We calibrate the probabilities of exiting at the different heads using aggregation with exponential weights to guarantee a fixed budget .We consider factors such as Bayesian risk, budget constraints, and head-specific budget consumption. Experimental results, conducted using a ResNet-18 model and a ConvNext architecture on Cifar and ImageNet datasets, demonstrate that our method not only effectively manages budget allocation but also enhances accuracy in overthinking scenar
    
[^26]: 面向高维上下文线性赌臂问题的差分隐私算法

    Differentially Private High Dimensional Bandits

    [https://arxiv.org/abs/2402.03737](https://arxiv.org/abs/2402.03737)

    这篇论文提出了PrivateLASSO算法，用于解决高维随机上下文线性赌臂问题，并在差分隐私的约束下证明了其隐私和实用性保证。

    

    我们在参数向量为$s_{0}$-稀疏且决策制定者受到差分隐私的中央和本地模型的约束下考虑高维随机上下文线性赌臂问题。我们提出了PrivateLASSO，一种差分隐私LASSO赌臂算法。PrivateLASSO基于两个子程序：(i)基于稀疏硬阈值的隐私机制和(ii)用于识别参数$\theta$支持集的阈值规则。我们证明了PrivateLASSO的最小最大私有下界，并在标准假设下建立了PrivateLASSO在中央模型下的隐私和实用性保证。

    We consider a high-dimensional stochastic contextual linear bandit problem when the parameter vector is $s_{0}$-sparse and the decision maker is subject to privacy constraints under both central and local models of differential privacy. We present PrivateLASSO, a differentially private LASSO bandit algorithm. PrivateLASSO is based on two sub-routines: (i) a sparse hard-thresholding-based privacy mechanism and (ii) an episodic thresholding rule for identifying the support of the parameter $\theta$. We prove minimax private lower bounds and establish privacy and utility guarantees for PrivateLASSO for the central model under standard assumptions.
    
[^27]: 从实例级的自我注意力Hawkes过程中学习格兰杰因果关系

    Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes

    [https://arxiv.org/abs/2402.03726](https://arxiv.org/abs/2402.03726)

    本论文提出了一种名为ISAHP的深度学习框架，可以从异步、相互依赖的多类型事件序列中无监督地学习实例级的格兰杰因果关系。它是第一个满足格兰杰因果关系要求的神经点过程模型，并利用变压器的自我注意机制来实现格兰杰因果关系的推断。

    

    我们解决了从异步、相互依赖的多类型事件序列中学习格兰杰因果关系的问题。特别是，我们对以无监督的方式发现实例级的因果结构感兴趣。实例级因果关系识别单个事件之间的因果关系，为决策提供了更精细化的信息。现有文献中的工作要么需要强加一些假设，比如强加到强度函数中的线性假设，要么启发式地定义模型参数，这些不一定满足格兰杰因果关系的要求。我们提出了一种新颖的深度学习框架，即实例级自我注意力Hawkes过程（ISAHP），可以直接推断事件实例级的格兰杰因果关系。ISAHP是第一个满足格兰杰因果关系要求的神经点过程模型。它利用了变压器的自我注意机制，与格兰杰因果关系的原理相一致。我们通过实验证明了ISAHP的有效性和优越性。

    We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate th
    
[^28]: 变分自动编码器进行异常检测的统计测试

    Statistical Test for Anomaly Detections by Variational Auto-Encoders

    [https://arxiv.org/abs/2402.03724](https://arxiv.org/abs/2402.03724)

    本研究提出了一种利用变分自动编码器进行异常检测的统计测试方法（VAE-AD测试），通过量化异常区域的可靠性，可以控制误检的概率到所期望的水平。

    

    在本研究中，我们考虑使用变分自动编码器（VAE）进行异常检测（AD）的可靠性评估。在过去的十年里，基于VAE的AD已经在各个角度进行了积极的研究，从方法开发到应用研究。然而，当AD的结果用于高风险的决策时，如医学诊断，需要确保检测到的异常的可靠性。在本研究中，我们提出了VAE-AD测试作为在统计检验框架下量化基于VAE的AD的统计可靠性的方法。利用VAE-AD测试，可以以p值的形式量化VAE检测到的异常区域的可靠性。这意味着，如果在p值低于某个阈值时宣布为异常，则可以将误检的概率控制在所期望的水平。由于VAE-AD测试是基于一种称为选择性推理的新统计推断框架构建的，其有效性是确保被证明的。

    In this study, we consider the reliability assessment of anomaly detection (AD) using Variational Autoencoder (VAE). Over the last decade, VAE-based AD has been actively studied in various perspective, from method development to applied research. However, when the results of ADs are used in high-stakes decision-making, such as in medical diagnosis, it is necessary to ensure the reliability of the detected anomalies. In this study, we propose the VAE-AD Test as a method for quantifying the statistical reliability of VAE-based AD within the framework of statistical testing. Using the VAE-AD Test, the reliability of the anomaly regions detected by a VAE can be quantified in the form of p-values. This means that if an anomaly is declared when the p-value is below a certain threshold, it is possible to control the probability of false detection to a desired level. Since the VAE-AD Test is constructed based on a new statistical inference framework called selective inference, its validity is 
    
[^29]: 改进和统一离散和连续时间离散去噪扩散

    Improving and Unifying Discrete&Continuous-time Discrete Denoising Diffusion

    [https://arxiv.org/abs/2402.03701](https://arxiv.org/abs/2402.03701)

    本文提出了一种改进和统一离散和连续时间离散去噪扩散的方法。通过数学简化和推导，使得离散扩散的训练更准确易优化，并且实现了精确和加速的采样。同时，成功地统一了离散时间和连续时间离散扩散。

    

    离散扩散模型在自然离散数据如语言和图形上得到了广泛关注。虽然离散时间离散扩散已经建立了一段时间，但直到最近Campbell等人（2022）才引入了连续时间离散扩散的第一个框架。然而，他们的训练和采样过程与离散时间版本有很大差异，需要非平凡的近似才能进行可行性分析。本文首先介绍了一系列对变分下界的数学简化，这些简化使离散扩散的训练更加准确和易于优化。此外，我们推导出了一种简单的反向去噪公式，能够实现精确和加速的采样，更重要的是能够优雅地统一离散时间和连续时间离散扩散。通过更简单的分析公式，前向和现在也包括了后向概率可以灵活地适应任何噪声分布。

    Discrete diffusion models have seen a surge of attention with applications on naturally discrete data such as language and graphs. Although discrete-time discrete diffusion has been established for a while, only recently Campbell et al. (2022) introduced the first framework for continuous-time discrete diffusion. However, their training and sampling processes differ significantly from the discrete-time version, necessitating nontrivial approximations for tractability. In this paper, we first present a series of mathematical simplifications of the variational lower bound that enable more accurate and easy-to-optimize training for discrete diffusion. In addition, we derive a simple formulation for backward denoising that enables exact and accelerated sampling, and importantly, an elegant unification of discrete-time and continuous-time discrete diffusion. Thanks to simpler analytical formulations, both forward and now also backward probabilities can flexibly accommodate any noise distrib
    
[^30]: 在大规模情况下估计局部学习系数

    Estimating the Local Learning Coefficient at Scale

    [https://arxiv.org/abs/2402.03698](https://arxiv.org/abs/2402.03698)

    本文提出了一种方法，可以在深度线性网络中准确地测量高达1亿参数的局部学习系数(LLC)，并证明了估计得到的LLC具有重缩放不变性。

    

    局部学习系数(LLC)是一种量化模型复杂性的原则性方法，最初是在贝叶斯统计中使用奇异学习理论(SLT)推导出来的。已知有几种数值估计局部学习系数的方法，但迄今为止这些方法尚未扩展到现代深度学习架构或数据集的规模。通过在arXiv:2308.12108 [stat.ML]中开发的一种方法，我们经验证明可以准确和自洽地测量深度线性网络(DLN)中高达1亿参数的局部学习系数(LLC)。我们还证明了估计得到的LLC具有理论数量所具备的重缩放不变性。

    The \textit{local learning coefficient} (LLC) is a principled way of quantifying model complexity, originally derived in the context of Bayesian statistics using singular learning theory (SLT). Several methods are known for numerically estimating the local learning coefficient, but so far these methods have not been extended to the scale of modern deep learning architectures or data sets. Using a method developed in {\tt arXiv:2308.12108 [stat.ML]} we empirically show how the LLC may be measured accurately and self-consistently for deep linear networks (DLNs) up to 100M parameters. We also show that the estimated LLC has the rescaling invariance that holds for the theoretical quantity.
    
[^31]: Pard: 具有置换不变性的自回归扩散用于图生成

    Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation

    [https://arxiv.org/abs/2402.03687](https://arxiv.org/abs/2402.03687)

    PARD是一种将扩散模型与自回归方法相结合的置换不变性自回归扩散模型，通过使用图中的部分顺序以块逐块的自回归方式生成图。

    

    尽管自回归模型对于图的顺序敏感，但其简单有效，在图生成领域一直占据主导地位。然而，扩散模型因其置换不变性而越来越受关注。目前的图扩散模型一次性生成图，但需要额外的特征和成千上万步的去噪才能达到最佳性能。我们引入了PARD，一种将扩散模型与自回归方法相结合的置换不变性自回归扩散模型。PARD利用自回归模型的效果和效率，同时保持置换不变性，无需关注图的顺序敏感性。具体来说，我们发现与集合不同，图中的元素并不是完全无序的，节点和边有一个独特的部分顺序。利用这个部分顺序，PARD以块逐块的自回归方式生成图，其中每个块的概率为c。

    Graph generation has been dominated by autoregressive models due to their simplicity and effectiveness, despite their sensitivity to ordering. Yet diffusion models have garnered increasing attention, as they offer comparable performance while being permutation-invariant. Current graph diffusion models generate graphs in a one-shot fashion, but they require extra features and thousands of denoising steps to achieve optimal performance. We introduce PARD, a Permutation-invariant Auto Regressive Diffusion model that integrates diffusion models with autoregressive methods. PARD harnesses the effectiveness and efficiency of the autoregressive model while maintaining permutation invariance without ordering sensitivity. Specifically, we show that contrary to sets, elements in a graph are not entirely unordered and there is a unique partial order for nodes and edges. With this partial order, PARD generates a graph in a block-by-block, autoregressive fashion, where each block's probability is c
    
[^32]: 高效求解偏差Gromov-Wasserstein问题

    Efficient Solvers for Partial Gromov-Wasserstein

    [https://arxiv.org/abs/2402.03664](https://arxiv.org/abs/2402.03664)

    本文提出了两个基于Frank-Wolfe算法的新的高效求解器来解决偏差Gromov-Wasserstein问题，并且证明了PGW问题构成了度量测度空间的度量。

    

    偏差Gromov-Wasserstein（PGW）问题可以比较具有不均匀质量的度量空间中的测度，从而实现这些空间之间的不平衡和部分匹配。本文证明了PGW问题可以转化为Gromov-Wasserstein问题的一个变种，类似于把偏差最优运输问题转化为最优运输问题。这个转化导致了两个新的求解器，基于Frank-Wolfe算法，数学和计算上等价，提供了高效的PGW问题解决方案。我们进一步证明了PGW问题构成了度量测度空间的度量。最后，我们通过与现有基线方法在形状匹配和正样本未标记学习问题上的计算时间和性能比较，验证了我们提出的求解器的有效性。

    The partial Gromov-Wasserstein (PGW) problem facilitates the comparison of measures with unequal masses residing in potentially distinct metric spaces, thereby enabling unbalanced and partial matching across these spaces. In this paper, we demonstrate that the PGW problem can be transformed into a variant of the Gromov-Wasserstein problem, akin to the conversion of the partial optimal transport problem into an optimal transport problem. This transformation leads to two new solvers, mathematically and computationally equivalent, based on the Frank-Wolfe algorithm, that provide efficient solutions to the PGW problem. We further establish that the PGW problem constitutes a metric for metric measure spaces. Finally, we validate the effectiveness of our proposed solvers in terms of computation time and performance on shape-matching and positive-unlabeled learning problems, comparing them against existing baselines.
    
[^33]: 使用神经网络通过嵌套低秩近似实现运算符的奇异值分解

    Operator SVD with Neural Networks via Nested Low-Rank Approximation

    [https://arxiv.org/abs/2402.03655](https://arxiv.org/abs/2402.03655)

    本文提出了一个新的优化框架，使用嵌套的低秩近似方法通过神经网络实现运算符的奇异值分解。该方法通过无约束优化公式隐式高效地保持学习函数的正交性。

    

    在许多机器学习和科学计算问题中，计算给定线性算子的特征值分解（EVD）或找到其主要特征值和特征函数是一项基础任务。对于高维特征值问题，训练神经网络参数化特征函数被认为是传统数值线性代数技术的有希望的替代方法。本文提出了一个新的优化框架，基于截断奇异值分解的低秩近似表征，并伴随着称为嵌套的学习方法，以正确的顺序学习前L个奇异值和奇异函数。所提出的方法通过无约束优化公式隐式高效地促进了学习函数的正交性，这个公式可以很容易地通过现成的基于梯度的优化算法求解。我们展示了所提出的优化框架在使用案例中的有效性。

    Computing eigenvalue decomposition (EVD) of a given linear operator, or finding its leading eigenvalues and eigenfunctions, is a fundamental task in many machine learning and scientific computing problems. For high-dimensional eigenvalue problems, training neural networks to parameterize the eigenfunctions is considered as a promising alternative to the classical numerical linear algebra techniques. This paper proposes a new optimization framework based on the low-rank approximation characterization of a truncated singular value decomposition, accompanied by new techniques called nesting for learning the top-$L$ singular values and singular functions in the correct order. The proposed method promotes the desired orthogonality in the learned functions implicitly and efficiently via an unconstrained optimization formulation, which is easy to solve with off-the-shelf gradient-based optimization algorithms. We demonstrate the effectiveness of the proposed optimization framework for use cas
    
[^34]: 贝叶斯分解格兰杰因果图用于多变量时间序列数据的研究

    Bayesian Factorised Granger-Causal Graphs For Multivariate Time-series Data

    [https://arxiv.org/abs/2402.03614](https://arxiv.org/abs/2402.03614)

    本研究提出了一种新的贝叶斯VAR模型，利用分层图先验推断二元格兰杰因果图的后验概率。相比竞争方法，我们的方法在不确定性量化、超参数数量和稀疏多变量时间序列数据上都表现更好。

    

    我们研究了自动发现多变量时间序列数据中格兰杰因果关系的问题。矢量自回归(VAR)模型已经在解决这个问题上经过了时间的考验，包括贝叶斯变种和使用深度神经网络的最新发展。大多数现有的VAR格兰杰因果方法使用稀疏性诱导惩罚/先验或事后阈值来解释它们的系数作为格兰杰因果图。相反，我们提出了一个新的贝叶斯VAR模型，其中包含了一个分层图先验来表示二元格兰杰因果图，与VAR系数分开考虑。我们开发了一种高效的算法来推断二元格兰杰因果图的后验概率。我们的方法提供了更好的不确定性量化，较少的超参数，并在稀疏多变量时间序列数据上实现了更好的性能。

    We study the problem of automatically discovering Granger causal relations from observational multivariate time-series data. Vector autoregressive (VAR) models have been time-tested for this problem, including Bayesian variants and more recent developments using deep neural networks. Most existing VAR methods for Granger causality use sparsity-inducing penalties/priors or post-hoc thresholds to interpret their coefficients as Granger causal graphs. Instead, we propose a new Bayesian VAR model with a hierarchical graph prior over binary Granger causal graphs, separately from the VAR coefficients. We develop an efficient algorithm to infer the posterior over binary Granger causal graphs. Our method provides better uncertainty quantification, has less hyperparameters, and achieves better performance than competing approaches, especially on sparse multivariate time-series data.
    
[^35]: 主动相关聚类的有效获取函数

    Effective Acquisition Functions for Active Correlation Clustering

    [https://arxiv.org/abs/2402.03587](https://arxiv.org/abs/2402.03587)

    本文提出了三种有效的获取函数用于主动相关聚类，分别基于不一致性概念和信息论量。

    

    相关聚类是一种强大的无监督学习范例，支持正和负的相似性。本文假设相似性事先未知，而是采用主动学习以一种成本有效的方式迭代地查询相似性。具体而言，我们开发了三种有效的获取函数用于在此设置下使用。其中一种基于不一致性概念（即当相似性违反传递性时）。其余两个基于信息论量，即熵和信息增益。

    Correlation clustering is a powerful unsupervised learning paradigm that supports positive and negative similarities. In this paper, we assume the similarities are not known in advance. Instead, we employ active learning to iteratively query similarities in a cost-efficient way. In particular, we develop three effective acquisition functions to be used in this setting. One is based on the notion of inconsistency (i.e., when similarities violate the transitive property). The remaining two are based on information-theoretic quantities, i.e., entropy and information gain.
    
[^36]: 《可信机器学习的调节游戏》

    Regulation Games for Trustworthy Machine Learning

    [https://arxiv.org/abs/2402.03540](https://arxiv.org/abs/2402.03540)

    本论文提出了一个以调节游戏为基础的框架，将可信机器学习视为多目标多主体优化问题。通过引入ParetoPlay算法，寻找社会最优的游戏解决方案，该算法能够确保代理方始终保持在Pareto前沿上。

    

    现有的关于可信机器学习的研究往往集中在信任的个别方面，如公平性或隐私。此外，许多技术忽视了训练机器学习模型的人和负责评估其可信度的人之间的区别。为了解决这些问题，我们提出了一个框架，将可信机器学习视为多目标多主体优化问题。这自然地导致了一个称为调节游戏的博弈论形式。我们介绍了一个特定的游戏实例——SpecGame，其中我们建模了机器学习模型构建者与公平性和隐私监管者之间的关系。监管者希望设计处罚措施来强制执行他们的规范，但不希望阻止构建者的参与。为了寻找这种社会最优（即对所有代理方都有效）的游戏解决方案，我们引入了ParetoPlay。这种新型均衡搜索算法确保代理方始终保持在Pareto前沿上。

    Existing work on trustworthy machine learning (ML) often concentrates on individual aspects of trust, such as fairness or privacy. Additionally, many techniques overlook the distinction between those who train ML models and those responsible for assessing their trustworthiness. To address these issues, we propose a framework that views trustworthy ML as a multi-objective multi-agent optimization problem. This naturally lends itself to a game-theoretic formulation we call regulation games. We illustrate a particular game instance, the SpecGame in which we model the relationship between an ML model builder and fairness and privacy regulators. Regulators wish to design penalties that enforce compliance with their specification, but do not want to discourage builders from participation. Seeking such socially optimal (i.e., efficient for all agents) solutions to the game, we introduce ParetoPlay. This novel equilibrium search algorithm ensures that agents remain on the Pareto frontier of th
    
[^37]: 在空间环境中一致验证预测方法

    Consistent Validation for Predictive Methods in Spatial Settings

    [https://arxiv.org/abs/2402.03527](https://arxiv.org/abs/2402.03527)

    本论文研究了在空间环境中验证预测方法的一致性问题，提出了一种能够处理不匹配情况的方法。

    

    空间预测任务对于天气预报、空气污染研究和其他科学工作至关重要。确定我们对统计或物理方法所作预测的可信度是科学结论的重要问题。不幸的是，传统的验证方法无法处理验证位置和我们希望进行预测的（测试）位置之间的不匹配。这种不匹配通常不是协变量偏移的一个实例（常常被形式化），因为验证和测试位置是固定的（例如，在网格上或选定的点上），而不是从两个分布中独立同分布地采样。在本文中，我们形式化了对验证方法的检查：随着验证数据的密度越来越大，它们能够变得任意精确。我们证明了传统方法和协变量偏移方法可能不满足这个检查。相反，我们提出了一种方法，它借鉴了协变量偏移文献中的现有思想，但对验证数据进行了调整。

    Spatial prediction tasks are key to weather forecasting, studying air pollution, and other scientific endeavors. Determining how much to trust predictions made by statistical or physical methods is essential for the credibility of scientific conclusions. Unfortunately, classical approaches for validation fail to handle mismatch between locations available for validation and (test) locations where we want to make predictions. This mismatch is often not an instance of covariate shift (as commonly formalized) because the validation and test locations are fixed (e.g., on a grid or at select points) rather than i.i.d. from two distributions. In the present work, we formalize a check on validation methods: that they become arbitrarily accurate as validation data becomes arbitrarily dense. We show that classical and covariate-shift methods can fail this check. We instead propose a method that builds from existing ideas in the covariate-shift literature, but adapts them to the validation data 
    
[^38]: 未标记数据如何在超出分布检测中发挥可证明的作用？

    How Does Unlabeled Data Provably Help Out-of-Distribution Detection?

    [https://arxiv.org/abs/2402.03502](https://arxiv.org/abs/2402.03502)

    本文介绍了一种新的学习框架SAL（Separate And Learn），通过利用未标记数据和标记数据，分离并训练异常点和OOD分类器，理论上提供了强大的保证和严格的错误界限。

    

    使用未标记数据对机器学习模型进行正则化已经显示出在检测超出分布（OOD）数据方面改进安全性和可靠性的潜力。利用野外未标记数据的能力是非常困难的，因为内分布（ID）和OOD数据的异质性。缺乏清洁的OOD样本集合在学习最优OOD分类器方面存在重大挑战。目前，缺乏对未标记数据如何帮助OOD检测的研究。本文通过引入新的学习框架SAL（Separate And Learn），填补了这一空白，该框架在理论上具有强大的保证和实证的有效性。该框架将候选异常点从未标记数据中分离出来，并使用候选异常点和标记的ID数据训练OOD分类器。从可分离性和可学习性的角度，我们在理论上提供了严格的错误界限，正式证明了我们算法中的两个组成部分。

    Using unlabeled data to regularize the machine learning models has demonstrated promise for improving safety and reliability in detecting out-of-distribution (OOD) data. Harnessing the power of unlabeled in-the-wild data is non-trivial due to the heterogeneity of both in-distribution (ID) and OOD data. This lack of a clean set of OOD samples poses significant challenges in learning an optimal OOD classifier. Currently, there is a lack of research on formally understanding how unlabeled data helps OOD detection. This paper bridges the gap by introducing a new learning framework SAL (Separate And Learn) that offers both strong theoretical guarantees and empirical effectiveness. The framework separates candidate outliers from the unlabeled data and then trains an OOD classifier using the candidate outliers and the labeled ID data. Theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our algorithm. Our the
    
[^39]: 注意力与事后可解释性相遇：数学视角

    Attention Meets Post-hoc Interpretability: A Mathematical Perspective

    [https://arxiv.org/abs/2402.03485](https://arxiv.org/abs/2402.03485)

    本文通过数学方式研究了基于注意力机制的架构，比较了事后解释和基于注意力机制的解释的差异，发现尽管有局限性，事后解释方法能够捕获比仅仅检查注意力权重更有用的洞察。

    

    注意力机制基于transformer等架构，成为了技术革命的核心。有趣的是，除了帮助在各种应用中获得最先进的结果之外，注意力机制本身还提供了关于模型内部行为的有意义洞察。这些洞察是否可以用作解释？关于此争论不断。本文通过数学方式研究了一个简单的基于注意力机制的架构，并准确定位了事后解释和基于注意力机制的解释之间的区别。我们表明它们提供了相当不同的结果，并且尽管有其局限性，事后解释方法能够捕获比仅仅检查注意力权重更有用的洞察。

    Attention-based architectures, in particular transformers, are at the heart of a technological revolution. Interestingly, in addition to helping obtain state-of-the-art results on a wide range of applications, the attention mechanism intrinsically provides meaningful insights on the internal behavior of the model. Can these insights be used as explanations? Debate rages on. In this paper, we mathematically study a simple attention-based architecture and pinpoint the differences between post-hoc and attention-based explanations. We show that they provide quite different results, and that, despite their limitations, post-hoc methods are capable of capturing more useful insights than merely examining the attention weights.
    
[^40]: 基于随机修改流的黎曼随机梯度下降

    Stochastic Modified Flows for Riemannian Stochastic Gradient Descent

    [https://arxiv.org/abs/2402.03467](https://arxiv.org/abs/2402.03467)

    本文研究了黎曼随机梯度下降（RSGD）的收敛速度，并介绍了一种基于随机修改流（RSMF）的扩散逼近方法，该方法可以提高对RSGD的近似精度。

    

    我们对黎曼随机梯度下降（RSGD）收敛速度给出了定量估计，并将其与黎曼梯度流和扩散过程——黎曼随机修改流（RSMF）进行了比较。利用随机微分几何工具，我们证明在小学习率范围内，RSGD可以近似为由无穷维维纳过程驱动的RSMF的解。RSMF考虑到了RSGD的随机波动，从而提高了与确定性黎曼梯度流的逼近顺序。RSGD使用了重传递映射的概念，即对指数映射的一种成本效益近似，我们对扩散逼近的弱误差进行了定量界定，在重传递映射、流形几何和梯度的随机估计的假设下证明了这些界定。

    We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.
    
[^41]: 用分布式神经计算突破维度灾难

    Breaking the Curse of Dimensionality with Distributed Neural Computation

    [https://arxiv.org/abs/2402.03460](https://arxiv.org/abs/2402.03460)

    通过分布式神经计算算法，我们提出了一种理论方法来克服维度灾难，并证明了我们的模型可以在任意精度下逼近Lipschitz函数，在参数量和前向传播方面具有优势。

    

    我们提出了一种理论方法，利用分布式神经计算算法来克服维度灾难。我们的模块化分布式深度学习范式，称为“神经途径”，可以在多台机器上实现任意精度，同时仅加载少量参数到GPU VRAM中。具体地，我们证明了对于每个误差水平$\varepsilon>0$和每个Lipschitz函数$f:[0,1]^n\to \mathbb{R}$，我们可以构建一个神经途径模型，该模型能够在$[0,1]^n$上以$\varepsilon$精度均匀逼近$f$，并且仅需要在内存中加载$\mathcal{O}(\varepsilon^{-1})$个网络参数以及在前向传播期间加载$\mathcal{O}(\varepsilon^{-1}\log(\varepsilon^{-1}))$个网络参数。这改进了传统非分布式深度学习模型（即ReLU多层感知机）的最优界限，后者需要$\mathcal{O}(\varepsilon^{-n/2})$个参数来达到相同的精度。目前唯一的其他可用深度学习模型

    We present a theoretical approach to overcome the curse of dimensionality using a neural computation algorithm which can be distributed across several machines. Our modular distributed deep learning paradigm, termed \textit{neural pathways}, can achieve arbitrary accuracy while only loading a small number of parameters into GPU VRAM. Formally, we prove that for every error level $\varepsilon>0$ and every Lipschitz function $f:[0,1]^n\to \mathbb{R}$, one can construct a neural pathways model which uniformly approximates $f$ to $\varepsilon$ accuracy over $[0,1]^n$ while only requiring networks of $\mathcal{O}(\varepsilon^{-1})$ parameters to be loaded in memory and $\mathcal{O}(\varepsilon^{-1}\log(\varepsilon^{-1}))$ to be loaded during the forward pass. This improves the optimal bounds for traditional non-distributed deep learning models, namely ReLU MLPs, which need $\mathcal{O}(\varepsilon^{-n/2})$ parameters to achieve the same accuracy. The only other available deep learning model
    
[^42]: 变量重要性排序在相关性下的挑战

    Challenges in Variable Importance Ranking Under Correlation

    [https://arxiv.org/abs/2402.03447](https://arxiv.org/abs/2402.03447)

    变量重要性排序在解释机器学习中很重要，但是特征之间的相关性是一个挑战。最近提出了基于特征 Knockoffs 的改进方法来解决这个问题，我们的工作重点是对这些方法进行评估和评估。

    

    变量重要性在可解释机器学习中起到了关键作用，它帮助衡量因素对预测模型输出的影响。基于通过排列生成“空”特征的模型无关方法可以应用于此。这种分析通常在制药应用中使用，因为它能解释包括基于树的集成模型在内的黑盒模型。然而，变量重要性估算中存在的一个主要挑战和显著干扰因素是特征之间的相关性。最近，针对这个问题提出了几种基于特征 Knockoffs 的边际排列调整，如条件预测影响（CPI）等变量重要性度量方法。我们的工作重点是对这些方法进行评估和评估。我们首先提出了一项综合模拟研究，探讨了特征相关性对变量重要性评估的影响。然后我们在理论上证明了...

    Variable importance plays a pivotal role in interpretable machine learning as it helps measure the impact of factors on the output of the prediction model. Model agnostic methods based on the generation of "null" features via permutation (or related approaches) can be applied. Such analysis is often utilized in pharmaceutical applications due to its ability to interpret black-box models, including tree-based ensembles. A major challenge and significant confounder in variable importance estimation however is the presence of between-feature correlation. Recently, several adjustments to marginal permutation utilizing feature knockoffs were proposed to address this issue, such as the variable importance measure known as conditional predictive impact (CPI). Assessment and evaluation of such approaches is the focus of our work. We first present a comprehensive simulation study investigating the impact of feature correlation on the assessment of variable importance. We then theoretically prov
    
[^43]: 面向具有耦合线性约束的非凸极小极大问题的零阶原始对偶交替投影梯度算法

    Zeroth-Order primal-dual Alternating Projection Gradient Algorithms for Nonconvex Minimax Problems with Coupled linear Constraints

    [https://arxiv.org/abs/2402.03352](https://arxiv.org/abs/2402.03352)

    本文研究了具有耦合线性约束的非凸极小极大问题的零阶算法，提出了两个单循环算法用于求解这些问题，并证明了它们的迭代复杂度分别为O(ε^(-2))和O(ε^(-4))。

    

    本文研究了确定性和随机设置下具有耦合线性约束的非凸极小极大问题的零阶算法，这在机器学习、信号处理和其他领域中近年来引起了广泛关注，例如资源分配问题和网络流问题中的对抗攻击等。我们提出了两个单循环算法，分别是零阶原始对偶交替投影梯度（ZO-PDAPG）算法和零阶正则动量原始对偶投影梯度算法（ZO-RMPDPG），用于解决具有耦合线性约束的确定性和随机非凸-(强)凹极小极大问题。证明了这两个算法获得一个ε-稳定点的迭代复杂度分别为O(ε^(-2))（对于求解非凸-凹极小极大问题）和O(ε^(-4))（对于求解非凸-凹极小极大问题）。

    In this paper, we study zeroth-order algorithms for nonconvex minimax problems with coupled linear constraints under the deterministic and stochastic settings, which have attracted wide attention in machine learning, signal processing and many other fields in recent years, e.g., adversarial attacks in resource allocation problems and network flow problems etc. We propose two single-loop algorithms, namely the zero-order primal-dual alternating projected gradient (ZO-PDAPG) algorithm and the zero-order regularized momentum primal-dual projected gradient algorithm (ZO-RMPDPG), for solving deterministic and stochastic nonconvex-(strongly) concave minimax problems with coupled linear constraints. The iteration complexity of the two proposed algorithms to obtain an $\varepsilon$-stationary point are proved to be $\mathcal{O}(\varepsilon ^{-2})$ (resp. $\mathcal{O}(\varepsilon ^{-4})$) for solving nonconvex-strongly concave (resp. nonconvex-concave) minimax problems with coupled linear const
    
[^44]: 弱监督协方差矩阵对齐通过斯蒂弗矩阵估计在MEG应用中

    Weakly supervised covariance matrices alignment through Stiefel matrices estimation for MEG applications

    [https://arxiv.org/abs/2402.03345](https://arxiv.org/abs/2402.03345)

    本文引入了一种在MEG应用中用于时间序列数据的新颖领域自适应技术，称为混合模型斯蒂弗适应（MSA），通过利用无标记数据建立了等效信号方差的成对对应关系以确保有效的预测性能。在神经科学问题中，MSA在使用脑磁图进行脑龄回归时表现优于最近的方法。

    

    本文介绍了一种新的基于混合模型斯蒂弗适应（MSA）的时间序列数据领域自适应技巧，特别解决了目标数据集中有限标记信号的挑战。通过利用领域相关的混合模型和最优传输领域自适应假设，我们利用目标域中丰富的无标记数据，通过建立等效信号方差之间的成对对应关系，确保了有效的预测性能。为了从观测信号协方差的黎曼表示中恢复基础信号方差，我们建立了识别关键的斯蒂弗矩阵的理论基础。我们提出了一个综合成本函数，同时学习这些矩阵、成对域关系以及根据任务的预测器、分类器或回归器。应用于神经科学问题中，MSA在使用脑磁图进行任务变化的脑龄回归中优于最近的方法。

    This paper introduces a novel domain adaptation technique for time series data, called Mixing model Stiefel Adaptation (MSA), specifically addressing the challenge of limited labeled signals in the target dataset. Leveraging a domain-dependent mixing model and the optimal transport domain adaptation assumption, we exploit abundant unlabeled data in the target domain to ensure effective prediction by establishing pairwise correspondence with equivalent signal variances between domains. Theoretical foundations are laid for identifying crucial Stiefel matrices, essential for recovering underlying signal variances from a Riemannian representation of observed signal covariances. We propose an integrated cost function that simultaneously learns these matrices, pairwise domain relationships, and a predictor, classifier, or regressor, depending on the task. Applied to neuroscience problems, MSA outperforms recent methods in brain-age regression with task variations using magnetoencephalography
    
[^45]: 基于先处理、中处理和后处理的线性差异约束下的贝叶斯最优公平分类

    Bayes-Optimal Fair Classification with Linear Disparity Constraints via Pre-, In-, and Post-processing

    [https://arxiv.org/abs/2402.02817](https://arxiv.org/abs/2402.02817)

    本文提出了一种基于贝叶斯最优的公平分类方法，通过先处理、中处理和后处理来最小化分类错误，并在给定群体公平性约束的情况下进行优化。该方法引入了线性和双线性差异度量的概念，并找到了贝叶斯最优公平分类器的形式。本方法能够处理多个公平性约束和常见情况。

    

    机器学习算法可能对受保护的群体产生不公平的影响。为解决这个问题，我们开发了基于贝叶斯最优的公平分类方法，旨在在给定群体公平性约束的情况下最小化分类错误。我们引入了线性差异度量的概念，它们是概率分类器的线性函数；以及双线性差异度量，它们在群体回归函数方面也是线性的。我们证明了几种常见的差异度量（如人口平等、机会平等和预测平等）都是双线性的。我们通过揭示与Neyman-Pearson引理的连接，找到了在单一线性差异度量下的贝叶斯最优公平分类器的形式。对于双线性差异度量，贝叶斯最优公平分类器变成了群体阈值规则。我们的方法还可以处理多个公平性约束（如平等的几率）和受保护属性常见的情况。

    Machine learning algorithms may have disparate impacts on protected groups. To address this, we develop methods for Bayes-optimal fair classification, aiming to minimize classification error subject to given group fairness constraints. We introduce the notion of \emph{linear disparity measures}, which are linear functions of a probabilistic classifier; and \emph{bilinear disparity measures}, which are also linear in the group-wise regression functions. We show that several popular disparity measures -- the deviations from demographic parity, equality of opportunity, and predictive equality -- are bilinear.   We find the form of Bayes-optimal fair classifiers under a single linear disparity measure, by uncovering a connection with the Neyman-Pearson lemma. For bilinear disparity measures, Bayes-optimal fair classifiers become group-wise thresholding rules. Our approach can also handle multiple fairness constraints (such as equalized odds), and the common scenario when the protected attr
    
[^46]: 因果贝叶斯优化通过外源分布学习

    Causal Bayesian Optimization via Exogenous Distribution Learning

    [https://arxiv.org/abs/2402.02277](https://arxiv.org/abs/2402.02277)

    本文引入了一种新的方法，通过学习外源变量的分布，提高了结构化因果模型的近似精度，并将因果贝叶斯优化扩展到更一般的因果方案。

    

    在结构化因果模型中，将目标变量最大化作为操作目标是一个重要的问题。现有的因果贝叶斯优化（CBO）方法要么依赖于改变因果结构以最大化奖励的硬干预，要么引入动作节点到内生变量中，以调整数据生成机制以实现目标。本文引入了一种新的方法来学习外源变量的分布，这在现有方法中通常被忽略或通过期望进行边缘化。外源分布学习提高了通常通过有限观测数据训练的代理模型中的结构化因果模型的近似精度。此外，学习到的外源分布将现有的CBO扩展到超出加性噪声模型（ANM）的一般因果方案。恢复外源变量使我们能够为噪声或未观测到的隐藏变量使用更灵活的先验。引入了一种新的CBO方法。

    Maximizing a target variable as an operational objective in a structured causal model is an important problem. Existing Causal Bayesian Optimization (CBO) methods either rely on hard interventions that alter the causal structure to maximize the reward; or introduce action nodes to endogenous variables so that the data generation mechanisms are adjusted to achieve the objective. In this paper, a novel method is introduced to learn the distribution of exogenous variables, which is typically ignored or marginalized through expectation by existing methods.   Exogenous distribution learning improves the approximation accuracy of structured causal models in a surrogate model that is usually trained with limited observational data. Moreover, the learned exogenous distribution extends existing CBO to general causal schemes beyond Additive Noise Models (ANM). The recovery of exogenous variables allows us to use a more flexible prior for noise or unobserved hidden variables. A new CBO method is 
    
[^47]: 《在大规模人工智能时代的贝叶斯深度学习》的立场论文

    Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI

    [https://arxiv.org/abs/2402.00809](https://arxiv.org/abs/2402.00809)

    《在大规模人工智能时代的贝叶斯深度学习》这篇立场论文探讨了贝叶斯深度学习在各种不同设置下的优势，并指出了与之相关的挑战和有趣的研究方向。未来的研究重点将放在如何将大规模基础模型与贝叶斯深度学习相结合，以发挥它们的全部潜力。

    

    在当前的深度学习研究领域中，人们主要关注在涉及大规模图像和语言数据集的监督任务中实现高预测准确性。然而，更广泛的视角揭示了许多被忽视的度量标准、任务和数据类型，如不确定性、主动和持续学习以及科学数据，这些方面需要关注。贝叶斯深度学习（BDL）是一条有前景的道路，可以在这些不同的设置中提供优势。本文认为BDL可以提升深度学习的能力。它重新审视了BDL的优势、承认了现有的挑战，并重点介绍了一些旨在解决这些障碍的有趣的研究方向。展望未来，讨论集中在可能的方式上，将大规模基础模型与BDL相结合，以充分发挥它们的潜力。

    In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.
    
[^48]: 理解Transformer在序列建模中的表达能力和机制

    Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling

    [https://arxiv.org/abs/2402.00522](https://arxiv.org/abs/2402.00522)

    本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。

    

    我们对Transformer在长、稀疏和复杂记忆的序列建模中的近似性质进行了系统研究。我们调查了Transformer的不同组件（如点积自注意力、位置编码和前馈层）是如何影响其表达能力的机制，并通过建立明确的近似率来研究它们的综合影响。我们的研究揭示了Transformer中关键参数（如层数和注意力头数）的作用，并且这些洞察还为替代架构提供了自然建议。

    We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.
    
[^49]: 条件性函数空间上的条件最优输运

    Conditional Optimal Transport on Function Spaces

    [https://arxiv.org/abs/2311.05672](https://arxiv.org/abs/2311.05672)

    我们在函数空间中研究了条件性最优输运，提出了描述条件测度的块三角蒙特地图以及它们的Kantorovich松弛的约束最优输运问题的理论，并在贝叶斯推理问题中得到了条件映射的正则性估计。

    

    我们从最优输运的视角，以及对摊销贝叶斯推理的考虑，系统地研究了函数空间中的条件三角形输运映射。更具体地说，我们发展了一个描述块三角蒙特地图以及它们的Kantorovich松弛的约束最优输运问题的理论，这个理论将最优三角形输运理论推广到带有一般代价函数的可分无限维函数空间。我们进一步根据贝叶斯推理问题的情况调整我们的结果，并获得了从先验到后验的条件映射的正则性估计。最后，我们展示了数值实验，证明了我们理论结果在函数参数的摊销和无似然推断的计算适用性。

    We present a systematic study of conditional triangular transport maps in function spaces from the perspective of optimal transportation and with a view towards amortized Bayesian inference. More specifically, we develop a theory of constrained optimal transport problems that describe block-triangular Monge maps that characterize conditional measures along with their Kantorovich relaxations. This generalizes the theory of optimal triangular transport to separable infinite-dimensional function spaces with general cost functions. We further tailor our results to the case of Bayesian inference problems and obtain regularity estimates on the conditioning maps from the prior to the posterior. Finally, we present numerical experiments that demonstrate the computational applicability of our theoretical results for amortized and likelihood-free inference of functional parameters.
    
[^50]: 知识图谱推理的神经符号人工智能：一项综述

    Neurosymbolic AI for Reasoning over Knowledge Graphs: A Survey

    [https://arxiv.org/abs/2302.07200](https://arxiv.org/abs/2302.07200)

    这项综述介绍了神经符号人工智能在知识图谱推理方面的研究。研究表明，最近的方法试图将符号推理和深度学习相结合，以生成具有解释性、竞争性能力并集成专家知识的模型。

    

    神经符号人工智能是一个日益活跃的研究领域，它将符号推理方法与深度学习相结合，以利用它们的互补优势。随着知识图谱成为表示异构和多关系数据的一种流行方式，对图结构进行推理的方法开始遵循这种神经符号范式。传统上，这些方法要么利用基于规则的推理，要么生成代表性的数值嵌入，从中可以提取出模式。然而，最近的一些研究尝试弥合这种二元对立，提出了能够促进可解释性、保持竞争性能力并集成专家知识的模型。因此，我们调查了在知识图谱上执行神经符号推理任务的方法，并提出了一种新的分类法。具体而言，我们提出了三个主要类别：（1）逻辑信息嵌入方法，（2）基于嵌入的方法与逻辑一致的方法

    Neurosymbolic AI is an increasingly active area of research that combines symbolic reasoning methods with deep learning to leverage their complementary benefits. As knowledge graphs are becoming a popular way to represent heterogeneous and multi-relational data, methods for reasoning on graph structures have attempted to follow this neurosymbolic paradigm. Traditionally, such approaches have utilized either rule-based inference or generated representative numerical embeddings from which patterns could be extracted. However, several recent studies have attempted to bridge this dichotomy to generate models that facilitate interpretability, maintain competitive performance, and integrate expert knowledge. Therefore, we survey methods that perform neurosymbolic reasoning tasks on knowledge graphs and propose a novel taxonomy by which we can classify them. Specifically, we propose three major categories: (1) logically-informed embedding approaches, (2) embedding approaches with logical cons
    
[^51]: 使用分数后验进行半参数推断

    Semiparametric inference using fractional posteriors

    [https://arxiv.org/abs/2301.08158](https://arxiv.org/abs/2301.08158)

    本研究通过使用非参数先验基于分数后验分布的近似线性半参数函数，建立了一个通用的Bernstein-von Mises定理，提出了可靠的半参数不确定性量化方法，并通过改进的分数后验集解决了可信集大小夸大的问题。

    

    我们在基于非参数先验的分数后验分布的近似线性半参数函数上建立了一个通用的Bernstein-von Mises定理。在许多非参数设置和不同类别的先验分布（包括高斯过程先验）中进行了说明。我们表明，分数后验可信集可以提供可靠的半参数不确定性量化，但是大小会被夸大。为了解决这个问题，我们进一步提出了一种"移动和重新缩放"的分数后验集，它是一个具有最优大小的高效置信集，尽管在正则条件下。作为我们证明的一部分，我们通过细化率对于分数指数的依赖性，改进了现有的分数后验压缩率结果。

    We establish a general Bernstein--von Mises theorem for approximately linear semiparametric functionals of fractional posterior distributions based on nonparametric priors. This is illustrated in a number of nonparametric settings and for different classes of prior distributions, including Gaussian process priors. We show that fractional posterior credible sets can provide reliable semiparametric uncertainty quantification, but have inflated size. To remedy this, we further propose a \textit{shifted-and-rescaled} fractional posterior set that is an efficient confidence set having optimal size under regularity conditions. As part of our proofs, we also refine existing contraction rate results for fractional posteriors by sharpening the dependence of the rate on the fractional exponent.
    
[^52]: 适用于数据源的最优正则化方法

    Optimal Regularization for a Data Source

    [https://arxiv.org/abs/2212.13597](https://arxiv.org/abs/2212.13597)

    本文研究了基于优化的方法中凸正则化的能力和局限性问题，通过研究给定分布情况下，对数据采用何种正则化方法是最优的。

    

    在基于优化的逆问题和统计估计中，常常通过加入促使数据保真性的准则和促进解的所需结构性质的正则化项来解决问题。选择适当的正则化约束通常由前领域知识和计算考虑共同驱动。凸正则化项在计算上具有吸引力，但在提升结构类型方面存在局限性。另一方面，非凸正则化项在促进结构类型方面更具灵活性，并且在某些应用中展示出了强大的实证性能，但同时也带来了解决相关优化问题的计算挑战。本文通过研究以下问题，寻求对凸正则化在效能和局限性方面的系统理解：给定一个分布，对于从该分布中抽取的数据，什么是最优的正则化方法？

    In optimization-based approaches to inverse problems and to statistical estimation, it is common to augment criteria that enforce data fidelity with a regularizer that promotes desired structural properties in the solution. The choice of a suitable regularizer is typically driven by a combination of prior domain information and computational considerations. Convex regularizers are attractive computationally but they are limited in the types of structure they can promote. On the other hand, nonconvex regularizers are more flexible in the forms of structure they can promote and they have showcased strong empirical performance in some applications, but they come with the computational challenge of solving the associated optimization problems. In this paper, we seek a systematic understanding of the power and the limitations of convex regularization by investigating the following questions: Given a distribution, what is the optimal regularizer for data drawn from the distribution? What pro
    
[^53]: Hilbert曲线投影距离用于分布比较

    Hilbert Curve Projection Distance for Distribution Comparison

    [https://arxiv.org/abs/2205.15059](https://arxiv.org/abs/2205.15059)

    本研究提出了一种新的度量方法，称为Hilbert曲线投影(HCP)距离，用于测量两个概率分布之间的距离，并具有低复杂度。通过Hilbert曲线投影和运输距离计算，该方法适用于有界支撑的概率测度，并在高维空间中具有较好的收敛性能。为了解决维度灾难，还开发了两个HCP距离的变体，使用子空间投影。

    

    分布比较在数据分类和生成建模等许多机器学习任务中起着核心作用。本研究提出了一种新的度量方法，称为Hilbert曲线投影(HCP)距离，用于测量两个概率分布之间的距离，并具有低复杂度。具体而言，我们首先使用Hilbert曲线将两个高维概率分布投影到一起，得到它们之间的耦合，然后根据耦合在原始空间中计算这两个分布之间的运输距离。我们证明了HCP距离是一个适当的度量，并且对于有界支撑的概率测度是良定义的。此外，我们还证明了在$d$维空间中具有$L_p$成本的改进经验HCP距离以不超过$O(n^{-1/2\max\{d,p\}})$的速率收敛到其总体对应项。为了抑制维度灾难，我们还开发了两个HCP距离的变体，使用（可学习的）子空间投影。

    Distribution comparison plays a central role in many machine learning tasks like data classification and generative modeling. In this study, we propose a novel metric, called Hilbert curve projection (HCP) distance, to measure the distance between two probability distributions with low complexity. In particular, we first project two high-dimensional probability distributions using Hilbert curve to obtain a coupling between them, and then calculate the transport distance between these two distributions in the original space, according to the coupling. We show that HCP distance is a proper metric and is well-defined for probability measures with bounded supports. Furthermore, we demonstrate that the modified empirical HCP distance with the $L_p$ cost in the $d$-dimensional space converges to its population counterpart at a rate of no more than $O(n^{-1/2\max\{d,p\}})$. To suppress the curse-of-dimensionality, we also develop two variants of the HCP distance using (learnable) subspace pro
    
[^54]: 基于组公平性的贝叶斯最优分类器

    Bayes-Optimal Classifiers under Group Fairness

    [https://arxiv.org/abs/2202.09724](https://arxiv.org/abs/2202.09724)

    这篇论文提供了一个统一的框架，推导出在组公平性下的贝叶斯最优分类器，并提出了一种名为FairBayes的基于组的阈值方法，可以直接控制不公平现象，实现基本最优的公平性-准确性权衡。

    

    机器学习算法正越来越多地融入到高风险决策过程中，例如社会福利问题。由于需要减少算法预测可能造成的不平等影响，许多公平机器学习方法已经被提出。然而，在各种组公平性约束下刻画贝叶斯最优分类器的基本问题仅在一些特殊情况下进行了研究。本文基于经典的Neyman-Pearson假设检验理论（Neyman和Pearson，1933；Shao，2003），提供了一个统一框架来推导在组公平性下的贝叶斯最优分类器。这使我们能够提出一种基于组的阈值方法，称为FairBayes，可以直接控制不公平现象，并实现基本最优的公平性-准确性权衡。这些优势通过充分的实验支持。

    Machine learning algorithms are becoming integrated into more and more high-stakes decision-making processes, such as in social welfare issues. Due to the need of mitigating the potentially disparate impacts from algorithmic predictions, many approaches have been proposed in the emerging area of fair machine learning. However, the fundamental problem of characterizing Bayes-optimal classifiers under various group fairness constraints has only been investigated in some special cases. Based on the classical Neyman-Pearson argument (Neyman and Pearson, 1933; Shao, 2003) for optimal hypothesis testing, this paper provides a unified framework for deriving Bayes-optimal classifiers under group fairness. This enables us to propose a group-based thresholding method we call FairBayes, that can directly control disparity, and achieve an essentially optimal fairness-accuracy tradeoff. These advantages are supported by thorough experiments.
    
[^55]: 通过随机行走的转换耦合比对和对齐有向网络

    Alignment and Comparison of Directed Networks via Transition Couplings of Random Walks

    [https://arxiv.org/abs/2106.07106](https://arxiv.org/abs/2106.07106)

    NetOTC是一种用于比较和对齐两个网络的方法，通过最小化随机行走的转换耦合的期望成本来量化网络之间的差异，并提供顶点和边的对齐。它捕捉到了关于网络的局部和全局信息，并保留了边缘。

    

    我们描述并研究了一种基于传输的过程，称为NetOTC（网络优化转换耦合），用于比较和对齐两个网络。所研究的网络可以是有向或无向的，带权重或不带权重，并且可能具有不同大小的不同顶点集。给定两个网络和一个与它们的顶点相关的成本函数，NetOTC找到其随机行走的转换耦合，使其具有最小的期望成本。最小化的成本量化了网络之间的差异，而最佳传输计划本身提供了两个网络的顶点和边的对齐。通过耦合完整的随机行走，而不是它们的边缘分布，确保NetOTC捕捉到了关于网络的局部和全局信息，并保留了边缘。NetOTC没有自由参数，并且不依赖随机化。我们研究了NetOTC的一些理论特性，并进行了一些实验证明其实际性能。

    We describe and study a transport based procedure called NetOTC (network optimal transition coupling) for the comparison and alignment of two networks. The networks of interest may be directed or undirected, weighted or unweighted, and may have distinct vertex sets of different sizes. Given two networks and a cost function relating their vertices, NetOTC finds a transition coupling of their associated random walks having minimum expected cost. The minimizing cost quantifies the difference between the networks, while the optimal transport plan itself provides alignments of both the vertices and the edges of the two networks. Coupling of the full random walks, rather than their marginal distributions, ensures that NetOTC captures local and global information about the networks, and preserves edges. NetOTC has no free parameters, and does not rely on randomization. We investigate a number of theoretical properties of NetOTC and present experiments establishing its empirical performance.
    
[^56]: InstaHide混合两个私人图片时的样本复杂度

    InstaHide's Sample Complexity When Mixing Two Private Images

    [https://arxiv.org/abs/2011.11877](https://arxiv.org/abs/2011.11877)

    本文研究了对InstaHide的最新攻击，提出了一个统一的框架来理解和分析这些攻击。通过一种新算法，在InstaHide挑战设置下，以可证明的保证和最优样本复杂度恢复所有私人图片，并提供了关于检索所有InstaHide图片的计算难度结果。

    

    训练神经网络通常需要大量的敏感训练数据，如何保护训练数据的隐私已成为深度学习研究中的重要课题。InstaHide是一种最先进的用于保护训练数据隐私的方案，对测试准确性只有微小影响，并且其安全性已成为一个突出的问题。本文系统研究了对InstaHide的最新攻击，并提出了一个统一的框架来理解和分析这些攻击。我们发现现有的攻击要么没有可证明的保证，要么只能恢复一个私人图片。在当前的InstaHide挑战设置下，每个InstaHide图片是两个私人图片的混合，我们提出了一种新算法来以可证明的保证和最优样本复杂度恢复所有私人图片。此外，我们还提供了关于检索所有InstaHide图片的计算难度结果。我们的结果表明InstaHide在信息论上并非是安全的。

    Training neural networks usually require large numbers of sensitive training data, and how to protect the privacy of training data has thus become a critical topic in deep learning research. InstaHide is a state-of-the-art scheme to protect training data privacy with only minor effects on test accuracy, and its security has become a salient question. In this paper, we systematically study recent attacks on InstaHide and present a unified framework to understand and analyze these attacks. We find that existing attacks either do not have a provable guarantee or can only recover a single private image. On the current InstaHide challenge setup, where each InstaHide image is a mixture of two private images, we present a new algorithm to recover all the private images with a provable guarantee and optimal sample complexity. In addition, we also provide a computational hardness result on retrieving all InstaHide images. Our results demonstrate that InstaHide is not information-theoretically s
    
[^57]: 基于大边际机制和伪查询集的跨域少样本学习

    Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot Learning

    [https://arxiv.org/abs/2005.09218](https://arxiv.org/abs/2005.09218)

    本文提出了一种基于大边际机制和伪查询集的跨域少样本学习方法，通过生成伪查询图像，并借鉴人脸识别方法中的大边际机制对特征提取模块进行微调。实验证明，该方法在各个领域上都取得了显著的优势，展示了其鲁棒性和适应预训练模型到新领域的能力。

    

    近年来，少样本学习问题引起了广泛的关注。然而，大多数以前的方法都是在单一领域的数据集上进行训练和测试，跨域少样本学习是少样本学习问题的一个全新分支，其中模型在训练和测试阶段处理不同领域的数据集。在本文中，为了解决在单个数据集上进行预训练（元训练）而在包括普通物体、卫星图像和医学图像在内的四个不同领域的数据集上进行微调的问题，我们提出了一种新颖的大边际微调方法（LMM-PQS）。该方法通过支持图像生成伪查询图像，并借鉴人脸识别方法中的大边际机制对特征提取模块进行微调。根据实验结果，LMM-PQS在比基准模型上取得了显著的优势，并证明了我们的方法具有鲁棒性，并能够轻松地将预训练模型适应新的领域。

    In recent years, few-shot learning problems have received a lot of attention. While methods in most previous works were trained and tested on datasets in one single domain, cross-domain few-shot learning is a brand-new branch of few-shot learning problems, where models handle datasets in different domains between training and testing phases. In this paper, to solve the problem that the model is pre-trained (meta-trained) on a single dataset while fine-tuned on datasets in four different domains, including common objects, satellite images, and medical images, we propose a novel large margin fine-tuning method (LMM-PQS), which generates pseudo query images from support images and fine-tunes the feature extraction modules with a large margin mechanism inspired by methods in face recognition. According to the experiment results, LMM-PQS surpasses the baseline models by a significant margin and demonstrates that our approach is robust and can easily adapt pre-trained models to new domains w
    
[^58]: 高维度独立性检测: 通过最大和平均距离相关性

    High-Dimensional Independence Testing via Maximum and Average Distance Correlations

    [https://arxiv.org/abs/2001.01095](https://arxiv.org/abs/2001.01095)

    本文介绍并研究了利用最大和平均距离相关性进行高维度独立性检测的方法，并提出了一种快速卡方检验的程序。该方法适用于欧氏距离和高斯核，具有较好的实证表现和广泛的应用场景。

    

    本文介绍并研究了利用最大和平均距离相关性进行多元独立性检测的方法。我们在高维环境中表征了它们相对于边际相关维度数量的一致性特性，评估了每个检验统计量的优势，检查了它们各自的零分布，并提出了一种基于快速卡方检验的检测程序。得出的检验是非参数的，并适用于欧氏距离和高斯核作为底层度量。为了更好地理解所提出的测试的实际使用情况，我们在各种多元相关场景中评估了最大距离相关性、平均距离相关性和原始距离相关性的实证表现，同时进行了一个真实数据实验，以检测人类血浆中不同癌症类型和肽水平的存在。

    This paper introduces and investigates the utilization of maximum and average distance correlations for multivariate independence testing. We characterize their consistency properties in high-dimensional settings with respect to the number of marginally dependent dimensions, assess the advantages of each test statistic, examine their respective null distributions, and present a fast chi-square-based testing procedure. The resulting tests are non-parametric and applicable to both Euclidean distance and the Gaussian kernel as the underlying metric. To better understand the practical use cases of the proposed tests, we evaluate the empirical performance of the maximum distance correlation, average distance correlation, and the original distance correlation across various multivariate dependence scenarios, as well as conduct a real data experiment to test the presence of various cancer types and peptide levels in human plasma.
    
[^59]: 时序数据的独立性检验

    Independence Testing for Temporal Data

    [https://arxiv.org/abs/1908.06486](https://arxiv.org/abs/1908.06486)

    本文介绍了一种适用于测试时序数据之间独立性的时序依赖统计方法，并能够估计最佳依赖滞后。该方法解决了现有方法的限制，并且在测试平稳时间序列之间的独立性时渐近有效和普遍一致，并且与多种依赖度量方法兼容。

    

    时序数据在现代数据科学中越来越常见。一个基本问题是判断两个时间序列是否相关。现有方法常常存在限制，如依赖参数假设、仅检测线性关联、需要多个测试和修正等。虽然最近提出了许多非参数和普遍一致的依赖度量方法，但直接应用于时序数据可能导致p值膨胀和无效的检验。为了解决这些挑战，本文引入了基于块置换的时序依赖统计量来测试时序数据之间的独立性。在适当的假设下，所提出的方法在测试平稳时间序列之间的独立性时是渐近有效和普遍一致的，并且能够估计最大化依赖的最佳依赖滞后。值得注意的是，它与丰富的距离和核心依赖度量方法兼容，消除了

    Temporal data are increasingly prevalent in modern data science. A fundamental question is whether two time-series are related or not. Existing approaches often have limitations, such as relying on parametric assumptions, detecting only linear associations, and requiring multiple tests and corrections. While many non-parametric and universally consistent dependence measures have recently been proposed, directly applying them to temporal data can inflate the p-value and result in invalid test. To address these challenges, this paper introduces the temporal dependence statistic with block permutation to test independence between temporal data. Under proper assumptions, the proposed procedure is asymptotically valid and universally consistent for testing independence between stationary time-series, and capable of estimating the optimal dependence lag that maximizes the dependence. Notably, it is compatible with a rich family of distance and kernel based dependence measures, eliminates the
    
[^60]: 以核Fisher-Rao流进行单位时间采样

    Sampling in Unit Time with Kernel Fisher-Rao Flow. (arXiv:2401.03892v1 [stat.CO])

    [http://arxiv.org/abs/2401.03892](http://arxiv.org/abs/2401.03892)

    本文提出了一种具有核Fisher-Rao流的新方法，在单位时间内从非归一化目标密度或贝叶斯后验中进行采样。方法使用了均场ODE和相互作用粒子系统，无需梯度，只需要能够从参考密度中采样并计算目标对参考密度的比率。该方法通过在几何混合的路径上沿速度场运输样本，径向输运样本。方法通过在再生核希尔伯特空间中求解泊松方程，使泊松方程的求解变得可行，并将其离散化为有限样本的均场ODE，作为实现简单的相互作用粒子系统。同时，这种方法也可以从离散时间的角度推导出均场ODE，作为蒙杰-安普尔方程连续线性化的极限。

    

    我们引入了一种新的均场ODE和相应的相互作用粒子系统，用于从非归一化的目标密度或贝叶斯后验中进行采样。相互作用粒子系统无需梯度，可以闭合形式获得，并且只需要能够从参考密度中采样并计算（非归一化的）目标对参考密度的比率。通过求解运输样本沿两个密度的几何混合的速度场的泊松方程来获得均场ODE，这是一种特定的Fisher-Rao梯度流的路径。我们采用再生核希尔伯特空间方法来获得速度场的泊松方程，这使得泊松方程可处理，并使我们能够离散化有限样本的结果均场ODE，形成一个简单的相互作用粒子系统。均场ODE还可以通过离散时间视角从蒙杰-安普尔方程的连续线性化的极限中推导出来，这在一个已知的框架内进行。

    We introduce a new mean-field ODE and corresponding interacting particle systems for sampling from an unnormalized target density or Bayesian posterior. The interacting particle systems are gradient-free, available in closed form, and only require the ability to sample from the reference density and compute the (unnormalized) target-to-reference density ratio. The mean-field ODE is obtained by solving a Poisson equation for a velocity field that transports samples along the geometric mixture of the two densities, which is the path of a particular Fisher-Rao gradient flow. We employ a reproducing kernel Hilbert space ansatz for the velocity field, which makes the Poisson equation tractable and enables us to discretize the resulting mean-field ODE over finite samples, as a simple interacting particle system. The mean-field ODE can be additionally be derived from a discrete-time perspective as the limit of successive linearizations of the Monge-Amp\`ere equations within a framework known 
    
[^61]: 在样本高效的离线强化学习中：数据多样性、后验采样，以及更多

    On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond. (arXiv:2401.03301v1 [cs.LG])

    [http://arxiv.org/abs/2401.03301](http://arxiv.org/abs/2401.03301)

    本文提出了通过数据多样性概念来统一离线强化学习算法的方法，并证明了基于版本空间、正则化优化和后验采样的算法在标准假设下达到了可比的样本效率。

    

    我们试图理解什么促进了对于序贝叶斯决策的历史数据集进行样本高效学习，这个问题通常被称为离线强化学习（RL）。此外，我们对于在利用（值）函数逼近的同时享受样本效率的算法感兴趣。在本文中，我们通过提出一个包括离线RL中覆盖度量的先前概念的数据多样性概念来解决这些基本问题，并且利用这个概念将基于版本空间（VS）、正则化优化（RO）和后验采样（PS）的三个不同类别的离线RL算法进行统一。我们在标准假设下证明，基于VS、基于RO和基于PS的算法达到了\emph{可比}的样本效率，这恢复了在有限和线性模型类别下的最优性的标准假设的边界。这个结果令人惊讶，因为之前的研究表明这些算法不具有有利性的样本效率。

    We seek to understand what facilitates sample-efficient learning from historical datasets for sequential decision-making, a problem that is popularly known as offline reinforcement learning (RL). Further, we are interested in algorithms that enjoy sample efficiency while leveraging (value) function approximation. In this paper, we address these fundamental questions by (i) proposing a notion of data diversity that subsumes the previous notions of coverage measures in offline RL and (ii) using this notion to {unify} three distinct classes of offline RL algorithms based on version spaces (VS), regularized optimization (RO), and posterior sampling (PS). We establish that VS-based, RO-based, and PS-based algorithms, under standard assumptions, achieve \emph{comparable} sample efficiency, which recovers the state-of-the-art sub-optimality bounds for finite and linear model classes with the standard assumptions. This result is surprising, given that the prior work suggested an unfavorable sa
    
[^62]: 无界损失的PAC-Bayes-Chernoff界限

    PAC-Bayes-Chernoff bounds for unbounded losses. (arXiv:2401.01148v1 [stat.ML])

    [http://arxiv.org/abs/2401.01148](http://arxiv.org/abs/2401.01148)

    这篇论文提出了一种用于无界损失的高概率PAC-Bayes参考界限，并通过优化自由参数解决了一些开放问题，并通过灵活的假设产生了新的广义界限。

    

    我们提出了一种新的用于无界损失的高概率PAC-Bayes参考界限。这个结果可以理解为Chernoff界限的PAC-Bayes版本。证明技巧依赖于通过Cramér变换对损失进行统一边界的尾部随机变量。我们强调了我们主要结果的两个应用。首先，我们证明了我们的界限解决了许多PAC-Bayes界限上的自由参数优化的开放问题。最后，我们证明了我们的方法允许在损失函数上进行灵活的假设，从而产生了广义了之前的界限，并且可以通过最小化来获得类似Gibbs的后验概率。

    We present a new high-probability PAC-Bayes oracle bound for unbounded losses. This result can be understood as a PAC-Bayes version of the Chernoff bound. The proof technique relies on uniformly bounding the tail of certain random variable based on the Cram\'er transform of the loss. We highlight two applications of our main result. First, we show that our bound solves the open problem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we show that our approach allows working with flexible assumptions on the loss function, resulting in novel bounds that generalize previous ones and can be minimized to obtain Gibbs-like posteriors.
    
[^63]: 均场欠阻尼朗之万动力学及其时空离散化算法

    Mean-field underdamped Langevin dynamics and its spacetime discretization. (arXiv:2312.16360v3 [stat.CO] UPDATED)

    [http://arxiv.org/abs/2312.16360](http://arxiv.org/abs/2312.16360)

    这篇论文提出了一种新的算法，用于优化在概率测度空间上定义的非线性泛函，特别适用于训练均场神经网络、最大均值差异最小化和核斯坦差异最小化问题。算法基于均场欠阻尼朗之万动力学的新颖时空离散化，具有快速混合保证，并且在总变化距离下全局收敛。

    

    我们提出了一种名为N粒子欠阻尼朗之万算法的新方法，用于优化在概率测度空间上定义的一类非线性泛函。这种公式的问题示例包括训练均场神经网络、最大均值差异最小化和核斯坦差异最小化。我们的算法基于均场欠阻尼朗之万动力学的新颖时空离散化，我们提供了一种新的快速混合保证。此外，我们证明了我们的算法在总变化距离下全局收敛，填补了动力学与实际实施之间的理论差距。

    We propose a new method called the N-particle underdamped Langevin algorithm for optimizing a special class of non-linear functionals defined over the space of probability measures. Examples of problems with this formulation include training mean-field neural networks, maximum mean discrepancy minimization and kernel Stein discrepancy minimization. Our algorithm is based on a novel spacetime discretization of the mean-field underdamped Langevin dynamics, for which we provide a new, fast mixing guarantee. In addition, we demonstrate that our algorithm converges globally in total variation distance, bridging the theoretical gap between the dynamics and its practical implementation.
    
[^64]: 用Wasserstein距离进行简化表示学习的实证研究

    An Empirical Study of Simplicial Representation Learning with Wasserstein Distance. (arXiv:2310.10143v1 [stat.ML])

    [http://arxiv.org/abs/2310.10143](http://arxiv.org/abs/2310.10143)

    本文研究了在树结构上利用Wasserstein距离进行简化表示学习的问题，并提出了一种基于SimCLR和负TWD的自监督学习方法来估计简化表示，通过实证研究找到了稳定的训练策略。

    

    本文探讨了在树结构上利用1-Wasserstein距离进行简化表示学习的问题，其中树- Wasserstein距离(TWD)定义为两个树嵌入向量之间的L1距离。具体而言，我们考虑了一种基于SimCLR和负TWD作为相似度度量的自监督学习方法来估计简化表示。在SimCLR中，通常使用与实向量嵌入的余弦相似度，但是尚未对利用L1距离与简化嵌入进行深入研究。一个关键挑战是训练L1距离在数值上具有挑战性，并且往往会产生不令人满意的结果，概率模型的选择也有很多。因此，本研究从实证角度探究了用TWD优化自监督学习的策略，并找到了稳定的训练过程。更具体地说，我们评估了两种类型TWD的组合（总 ...

    In this paper, we delve into the problem of simplicial representation learning utilizing the 1-Wasserstein distance on a tree structure (a.k.a., Tree-Wasserstein distance (TWD)), where TWD is defined as the L1 distance between two tree-embedded vectors. Specifically, we consider a framework for simplicial representation estimation employing a self-supervised learning approach based on SimCLR with a negative TWD as a similarity measure. In SimCLR, the cosine similarity with real-vector embeddings is often utilized; however, it has not been well studied utilizing L1-based measures with simplicial embeddings. A key challenge is that training the L1 distance is numerically challenging and often yields unsatisfactory outcomes, and there are numerous choices for probability models. Thus, this study empirically investigates a strategy for optimizing self-supervised learning with TWD and find a stable training procedure. More specifically, we evaluate the combination of two types of TWD (total
    
[^65]: 关于通过指数机制进行高维私有模型选择的计算复杂性

    On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])

    [http://arxiv.org/abs/2310.07852](http://arxiv.org/abs/2310.07852)

    本文研究了在高维稀疏线性回归模型中的差分隐私模型选择问题。我们使用指数机制进行模型选择，并提出了Metropolis-Hastings算法来克服指数搜索空间的计算复杂性。我们的算法在一定边界条件下能够实现强模型恢复性质，并具有多项式混合时间和近似差分隐私性质。

    

    在差分隐私框架下，我们考虑了高维稀疏线性回归模型中的模型选择问题。具体而言，我们考虑了差分隐私最佳子集选择的问题，并研究了其效用保证。我们采用了广为人知的指数机制来选择最佳模型，并在一定边界条件下，建立了其强模型恢复性质。然而，指数机制的指数搜索空间导致了严重的计算瓶颈。为了克服这个挑战，我们提出了Metropolis-Hastings算法来进行采样步骤，并在问题参数$n$、$p$和$s$中建立了其到稳态分布的多项式混合时间。此外，我们还利用其混合性质建立了Metropolis-Hastings随机行走的最终估计的近似差分隐私性质。最后，我们还进行了一些说明性模拟，印证了我们主要结果的理论发现。

    We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
    
[^66]: 潜在提示Transformer模型在分子设计中的应用

    Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])

    [http://arxiv.org/abs/2310.03253](http://arxiv.org/abs/2310.03253)

    本文提出了一种潜在提示Transformer模型，用于解决分子设计中的优化问题。该模型包括潜在向量、分子生成模型和性质预测模型，通过对现有分子进行训练后进行模型分布的逐渐转移。

    

    本文提出了一种用于解决分子设计等具有挑战性优化问题的潜在提示Transformer模型，其中目标是找到具有目标化学或生物性质最优值的分子，该值可以由现有软件计算得出。我们提出的模型包括三个组件：（1）潜在向量，其先验分布由高斯白噪声向量的Unet变换建模。（2）分子生成模型，在（1）中给定潜在向量的条件下生成基于字符串的分子表示。我们采用了以（1）中的潜在向量作为提示的因果Transformer模型。（3）性质预测模型，根据（1）中的潜在向量进行非线性回归预测分子的目标性质值。我们称该提出的模型为潜在提示Transformer模型。在对现有分子及其性质值进行初步训练后，我们逐渐转移模型分布的学习。

    This paper proposes a latent prompt Transformer model for solving challenging optimization problems such as molecule design, where the goal is to find molecules with optimal values of a target chemical or biological property that can be computed by an existing software. Our proposed model consists of three components. (1) A latent vector whose prior distribution is modeled by a Unet transformation of a Gaussian white noise vector. (2) A molecule generation model that generates the string-based representation of molecule conditional on the latent vector in (1). We adopt the causal Transformer model that takes the latent vector in (1) as prompt. (3) A property prediction model that predicts the value of the target property of a molecule based on a non-linear regression on the latent vector in (1). We call the proposed model the latent prompt Transformer model. After initial training of the model on existing molecules and their property values, we then gradually shift the model distributi
    
[^67]: 基于能量导向的连续熵巴氏中心估计方法及其在一般成本问题中的应用

    Energy-Guided Continuous Entropic Barycenter Estimation for General Costs. (arXiv:2310.01105v1 [cs.LG])

    [http://arxiv.org/abs/2310.01105](http://arxiv.org/abs/2310.01105)

    本文提出了一种基于能量导向的方法用于近似计算任意OT成本函数的连续熵OT巴氏中心，该方法具有优越的性能，并且能与基于能量的模型（EBMs）学习过程无缝连接。

    

    优化输运（OT）巴氏中心是一种在捕捉概率分布几何特性的同时对其进行平均的数学方法。本文提出了一种新颖的算法，用于近似计算任意OT成本函数的连续熵OT巴氏中心。我们的方法基于最近在机器学习社区中受到关注的基于弱OT的连续熵最优输运问题的对偶重构。除了创新性之外，我们的方法还具有以下若干优势特点：（i）我们建立了对恢复解的质量界限；（ii）该方法与基于能量的模型（EBMs）学习过程无缝连接，可以使用经过良好调整的算法解决感兴趣的问题；（iii）它提供了一种直观的优化方案，避免使用极小-极大、强化等复杂技巧。为了验证我们的方法，我们考虑了s

    Optimal transport (OT) barycenters are a mathematically grounded way of averaging probability distributions while capturing their geometric properties. In short, the barycenter task is to take the average of a collection of probability distributions w.r.t. given OT discrepancies. We propose a novel algorithm for approximating the continuous Entropic OT (EOT) barycenter for arbitrary OT cost functions. Our approach is built upon the dual reformulation of the EOT problem based on weak OT, which has recently gained the attention of the ML community. Beyond its novelty, our method enjoys several advantageous properties: (i) we establish quality bounds for the recovered solution; (ii) this approach seemlessly interconnects with the Energy-Based Models (EBMs) learning procedure enabling the use of well-tuned algorithms for the problem of interest; (iii) it provides an intuitive optimization scheme avoiding min-max, reinforce and other intricate technical tricks. For validation, we consider s
    
[^68]: 增强随机平滑的Lipschitz-方差-边界权衡

    The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing. (arXiv:2309.16883v1 [cs.LG])

    [http://arxiv.org/abs/2309.16883](http://arxiv.org/abs/2309.16883)

    本文提出了一个增强随机平滑的方法，通过研究随机平滑引入的方差与分类器的Lipschitz常数和边界之间的关系，以及采用单纯形投影技术来增加认证鲁棒半径。

    

    面对噪声输入和对抗性攻击时，深度神经网络的实际应用受到其不稳定的预测的阻碍。在这种情况下，认证半径是模型鲁棒性的关键指标。然而，如何设计一个具有足够认证半径的高效分类器呢？随机平滑通过在输入中注入噪声来获得平滑且更鲁棒的分类器的框架提供了有希望的解决方案。本文首先展示了随机平滑引入的方差与分类器的另外两个重要属性，即其Lipschitz常数和边界之间的密切关系。更具体地说，我们的工作强调了基分类器的Lipschitz常数对平滑分类器和经验方差的双重影响。此外，为了增加认证鲁棒半径，我们引入了一种不同的单纯形投影技术，以便通过Bernst的方差-边界权衡来利用基分类器。

    Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernst
    
[^69]: 带有Beta散度的深度非负矩阵分解

    Deep Nonnegative Matrix Factorization with Beta Divergences. (arXiv:2309.08249v1 [cs.LG])

    [http://arxiv.org/abs/2309.08249](http://arxiv.org/abs/2309.08249)

    本文提出了一种使用Beta散度的深度非负矩阵分解方法，应用于面部特征提取、文档主题识别和高光谱图像材料识别。

    

    深度非负矩阵分解（deep NMF）最近成为一种有价值的技术，用于在不同尺度上提取多层特征。然而，所有现有的深度NMF模型和算法主要都以最小二乘误差为评估标准，这可能不是评估多样化数据集近似质量的最合适指标。例如，当处理音频信号和文档等数据类型时，广泛认可的是$\beta$-divergences提供了更适合的替代方案。本文基于$\beta$-divergences开发了新的深度NMF模型和算法，并将这些技术应用于面部特征提取、文档集合中的主题识别以及高光谱图像中材料的识别。

    Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a valuable technique for extracting multiple layers of features across different scales. However, all existing deep NMF models and algorithms have primarily centered their evaluation on the least squares error, which may not be the most appropriate metric for assessing the quality of approximations on diverse datasets. For instance, when dealing with data types such as audio signals and documents, it is widely acknowledged that $\beta$-divergences offer a more suitable alternative. In this paper, we develop new models and algorithms for deep NMF using $\beta$-divergences. Subsequently, we apply these techniques to the extraction of facial features, the identification of topics within document collections, and the identification of materials within hyperspectral images.
    
[^70]: 可证明高效的UCB类型算法用于学习预测状态表示

    Provably Efficient UCB-type Algorithms For Learning Predictive State Representations. (arXiv:2307.00405v1 [cs.LG])

    [http://arxiv.org/abs/2307.00405](http://arxiv.org/abs/2307.00405)

    这篇论文提出了第一种已知的UCB类型方法用于学习预测状态表示（PSRs），并设计了一个新的奖励项来上界t

    

    一般的顺序决策问题旨在通过基于过去观察和行动的历史来最大化累积奖励。最近的研究表明，如果顺序决策问题可以用预测状态表示（PSRs）建模低秩结构，那么它是可统计学习的。尽管有这些进展，但现有方法通常需要使用预先设计好的步骤或者是计算效率低下的或者是不可计算的。另一方面，上限置信区间（UCB）方法在赌博机和MDPs中被成功地作为计算效率高的方法，但对PSR这种更具挑战性的问题还没有进行研究，这是由于在这种更具挑战性的情况下，乐观型奖励的设计十分困难。本文提出了PSRs的第一种已知的UCB类型方法，其中包含了一个新的奖励项来上界t

    The general sequential decision-making problem, which includes Markov decision processes (MDPs) and partially observable MDPs (POMDPs) as special cases, aims at maximizing a cumulative reward by making a sequence of decisions based on a history of observations and actions over time. Recent studies have shown that the sequential decision-making problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). Despite these advancements, existing approaches typically involve oracles or steps that are not computationally efficient. On the other hand, the upper confidence bound (UCB) based approaches, which have served successfully as computationally efficient methods in bandits and MDPs, have not been investigated for more general PSRs, due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the t
    
[^71]: 竞争环境下贝叶斯风险的提高可能导致社会福利的降低

    Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition. (arXiv:2306.14670v1 [cs.GT])

    [http://arxiv.org/abs/2306.14670](http://arxiv.org/abs/2306.14670)

    本文研究了机器学习模型在竞争环境下的行为，发现提高数据表示质量可能会导致供应商整体预测准确性降低，从而降低社会福利。

    

    随着机器学习模型规模的增长，缩放定律等趋势预计会导致预测准确性的持续改进。然而，这些趋势只考虑了单个模型供应商的视角，而实际上供应商之间常常竞争用户。本文证明了竞争可以从根本上改变这些缩放趋势的行为，甚至可能造成整体预测准确性随着规模的增大而非单调或降低。我们定义了一个分类任务的竞争模型，并使用数据表示作为研究规模增加的影响的镜头。我们发现在一家市场上，改善数据表示质量（按贝叶斯风险计量）可能会降低竞争模型供应商的整体预测准确性（即社会福利）。我们的例子涵盖了简单设置中的封闭式公式到预训练的 CIFAR-10 模拟。

    As the scale of machine learning models increases, trends such as scaling laws anticipate consistent downstream improvements in predictive accuracy. However, these trends take the perspective of a single model-provider in isolation, while in reality providers often compete with each other for users. In this work, we demonstrate that competition can fundamentally alter the behavior of these scaling trends, even causing overall predictive accuracy across users to be non-monotonic or decreasing with scale. We define a model of competition for classification tasks, and use data representations as a lens for studying the impact of increases in scale. We find many settings where improving data representation quality (as measured by Bayes risk) decreases the overall predictive accuracy across users (i.e., social welfare) for a marketplace of competing model-providers. Our examples range from closed-form formulas in simple settings to simulations with pretrained representations on CIFAR-10. At
    
[^72]: 深度概率时间序列预测的更好Batch方法

    Better Batch for Deep Probabilistic Time Series Forecasting. (arXiv:2305.17028v1 [stat.ML])

    [http://arxiv.org/abs/2305.17028](http://arxiv.org/abs/2305.17028)

    该研究提出了一种新的训练方法，通过在 mini-batch 中显式地学习误差的序列相关性，来提高深度概率时间序列预测的准确性和不确定性量化。

    

    深度概率时间序列预测因其能够提供有价值的不确定性量化而受到广泛关注。然而，许多现有模型过于简单化问题，假设误差过程是与时间无关的，从而忽略了误差过程中的序列相关性。这可能会降低预测的准确性，使这些模型对决策性任务的有效性减弱。为了克服这一限制，我们提出了一种创新的训练方法，将误差自相关性纳入考虑，以增强概率预测的准确性。我们的方法涉及构造一个mini-batch，作为$D$个连续时间序列段进行模型训练，并显式地学习一个协方差矩阵，覆盖了相邻时间步之间的误差相关性。由此产生的协方差矩阵可用于提高预测准确性和增强不确定性的量化。

    Deep probabilistic time series forecasting has gained significant attention due to its ability to provide valuable uncertainty quantification for decision-making tasks. However, many existing models oversimplify the problem by assuming the error process is time-independent, thereby overlooking the serial correlation in the error process. This oversight can potentially diminish the accuracy of the forecasts, rendering these models less effective for decision-making purposes. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance the accuracy of probabilistic forecasting. Our method involves constructing a mini-batch as a collection of $D$ consecutive time series segments for model training and explicitly learning a covariance matrix over each mini-batch that encodes the error correlation among adjacent time steps. The resulting covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantifica
    
[^73]: 自注意力动态中的聚类现象

    The emergence of clusters in self-attention dynamics. (arXiv:2305.05465v1 [cs.LG])

    [http://arxiv.org/abs/2305.05465](http://arxiv.org/abs/2305.05465)

    本文证实了当Transformer处理一系列token时，出现“领导者”的经验观察，即随着时间趋于无穷大，代表token的粒子会聚集在特定的极限对象附近，这取决于价值矩阵的谱。

    

    将Transformer视为相互作用的粒子系统，当权重不随时间变化时，本文描述了学习表示的几何形状。我们展示了代表token的粒子随着时间趋于无穷大而趋向于特定的极限对象。出现的极限对象类型取决于价值矩阵的谱。此外，在一维情况下，我们证明了自我注意力矩阵收敛于低秩布尔矩阵。这些结果的组合在数学上证实了Vaswani等人的经验观察，即Transformer处理一系列token时会出现“领导者”。

    Viewing Transformers as interacting particle systems, we describe the geometry of learned representations when the weights are not time dependent. We show that particles, representing tokens, tend to cluster toward particular limiting objects as time tends to infinity. The type of limiting object that emerges depends on the spectrum of the value matrix. Additionally, in the one-dimensional case we prove that the self-attention matrix converges to a low-rank Boolean matrix. The combination of these results mathematically confirms the empirical observation made by Vaswani et al. \cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokens when processed by Transformers.
    
[^74]: Kullback-Leibler Maillard采样在有界奖励的多臂赌博机问题中的应用

    Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards. (arXiv:2304.14989v1 [cs.LG])

    [http://arxiv.org/abs/2304.14989](http://arxiv.org/abs/2304.14989)

    本文提出了Kullback-Leibler Maillard Sampling (KL-MS)算法，能够在有界奖励的多臂赌博机中实现KL空间的扩展，具有较好的渐近性能。

    

    本文研究了奖励分布集中在区间$[0,1]$内的$K$臂数臂赌博机问题。本文提出了一种名为Kullback-Leibler Maillard Sampling (KL-MS)的新算法，它是Maillard采样在KL空间的自然扩展。实验表明，KL-MS在Bernoulli奖励时具有渐近最优性能，其最坏情况遗憾度上界为$O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$，其中$\mu^*$是最优臂的期望奖励，$T$是时段长度。

    We study $K$-armed bandit problems where the reward distributions of the arms are all supported on the $[0,1]$ interval. It has been a challenge to design regret-efficient randomized exploration algorithms in this setting. Maillard sampling~\cite{maillard13apprentissage}, an attractive alternative to Thompson sampling, has recently been shown to achieve competitive regret guarantees in the sub-Gaussian reward setting~\cite{bian2022maillard} while maintaining closed-form action probabilities, which is useful for offline policy evaluation. In this work, we propose the Kullback-Leibler Maillard Sampling (KL-MS) algorithm, a natural extension of Maillard sampling for achieving KL-style gap-dependent regret bound. We show that KL-MS enjoys the asymptotic optimality when the rewards are Bernoulli and has a worst-case regret bound of the form $O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$, where $\mu^*$ is the expected reward of the optimal arm, and $T$ is the time horizon length.
    
[^75]: 在 $L$-亚指数协变量下的稀疏线性回归系数估计

    Estimation of sparse linear regression coefficients under $L$-subexponential covariates. (arXiv:2304.11958v1 [math.ST])

    [http://arxiv.org/abs/2304.11958](http://arxiv.org/abs/2304.11958)

    本文提出了一种方法，在不需要更强条件的情况下，即使在协变量来自 $L$-亚指数随机向量的情况下，使用$\ell_1$ -帕伯回归进行线性回归，可以得到与高斯随机向量相同（在常数因子下）的误差界限。

    

    当协变量来自 $L$-亚指数随机向量时，我们解决了在线性回归中估计稀疏系数的任务，该随机向量属于一类具有比高斯随机向量更重的尾巴的分布。以前的工作通过假设协变量来自 $L$-亚指数随机向量来解决这个问题，并建立了类似于对高斯随机向量导出的误差界限。然而，这些以前的方法要求更强的条件，以导出与高斯随机向量相同的误差界限。在本文中，我们在不需要更强的条件的情况下提出了与高斯随机向量相同（在常数因子下），甚至当协变量来自 $L$-亚指数随机向量时的误差界限。有趣的是，我们利用了 $\ell_1$-帕伯回归，该回归因其对重尾随机噪声的鲁棒性而被认为是重要的，而不是协变量。我们相信...

    We address a task of estimating sparse coefficients in linear regression when the covariates are drawn from an $L$-subexponential random vector, which belongs to a class of distributions having heavier tails than a Gaussian random vector. Prior works have tackled this issue by assuming that the covariates are drawn from an $L$-subexponential random vector and have established error bounds that resemble those derived for Gaussian random vectors. However, these previous methods require stronger conditions to derive error bounds than those employed for Gaussian random vectors. In the present paper, we present an error bound identical to that obtained for Gaussian random vectors, up to constant factors, without requiring stronger conditions, even when the covariates are drawn from an $L$-subexponential random vector. Somewhat interestingly, we utilize an $\ell_1$-penalized Huber regression, that is recognized for its robustness to heavy-tailed random noises, not covariates. We believe that
    
[^76]: 通过潜在空间探索和因果推断方法逼近未知的通信系统

    Approaching an unknown communication system by latent space exploration and causal inference. (arXiv:2303.10931v1 [stat.ML])

    [http://arxiv.org/abs/2303.10931](http://arxiv.org/abs/2303.10931)

    本文通过探索无监督深度生成模型的潜在空间来发现数据中有意义的属性，提出了一种极端值因果分离 (CDEV) 的方法，应用于测试鲸鱼通信系统并发现其中存在语法。

    

    本文提出了一种方法，通过探索无监督深度生成模型的潜在空间来发现数据中有意义的属性。我们将对单个潜在变量的操作与因果推断方法相结合，实现了一个称为极端值因果分离 (CDEV) 的方法，并展示了该方法对模型可解释性的洞察力。通过此技术，我们可以推断模型将未知数据编码为有意义的属性。我们将该方法应用于测试鲸鱼的通信系统中存在哪些有意义的属性，鲸鱼通信是最具有吸引力和研究不足的动物通信之一。我们训练了一个网络，该网络已被证明能够学习到有意义的语音表示，并测试是否可以利用这种无监督学习来解析另一个我们没有地面真相的声音通信系统的属性。所提出的技术表明，鲸鱼在其声音通信中存在语法，这是以前不知道的。

    This paper proposes a methodology for discovering meaningful properties in data by exploring the latent space of unsupervised deep generative models. We combine manipulation of individual latent variables to extreme values outside the training range with methods inspired by causal inference into an approach we call causal disentanglement with extreme values (CDEV) and show that this approach yields insights for model interpretability. Using this technique, we can infer what properties of unknown data the model encodes as meaningful. We apply the methodology to test what is meaningful in the communication system of sperm whales, one of the most intriguing and understudied animal communication systems. We train a network that has been shown to learn meaningful representations of speech and test whether we can leverage such unsupervised learning to decipher the properties of another vocal communication system for which we have no ground truth. The proposed technique suggests that sperm wh
    
[^77]: 准算术混合、散度最小化和Bregman信息

    Quasi-Arithmetic Mixtures, Divergence Minimization, and Bregman Information. (arXiv:2209.07481v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.07481](http://arxiv.org/abs/2209.07481)

    本文提供了对准算术混合、散度最小化和Bregman信息的全面分析。通过在密度函数的单调嵌入下使用Bregman散度，我们将常见的散度函数与退火路径上的中间密度关联起来。

    

    马尔可夫链蒙特卡洛方法用于从复杂分布中采样和估计归一化常数通常模拟沿着连接可跟踪初始分布和目标密度的退火路径的中间分布的样本。先前的工作使用准算术平均构建了退火路径，并解释了由此产生的中间密度是最小化期望散度到端点的。我们通过在密度函数的单调嵌入下使用Bregman散度对这个“质心”性质进行了全面分析，从而将常见的散度（如Amari和Renyi的alpha散度、（alpha，beta）散度和Jensen-Shannon散度）与沿着退火路径的中间密度关联起来。我们的分析突出了参数化族、准算术平均和散度函数之间的相互作用，使用了Zhang的rho-tau Bregman散度框架。

    Markov Chain Monte Carlo methods for sampling from complex distributions and estimating normalization constants often simulate samples from a sequence of intermediate distributions along an annealing path, which bridges between a tractable initial distribution and a target density of interest. Prior work has constructed annealing paths using quasi-arithmetic means, and interpreted the resulting intermediate densities as minimizing an expected divergence to the endpoints. We provide a comprehensive analysis of this 'centroid' property using Bregman divergences under a monotonic embedding of the density function, thereby associating common divergences such as Amari's and Renyi's ${\alpha}$-divergences, ${(\alpha,\beta)}$-divergences, and the Jensen-Shannon divergence with intermediate densities along an annealing path. Our analysis highlights the interplay between parametric families, quasi-arithmetic means, and divergence functions using the rho-tau Bregman divergence framework of Zhang
    
[^78]: 用熵近似的高斯混合变分推断

    Variational Inference with Gaussian Mixture by Entropy Approximation. (arXiv:2202.13059v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.13059](http://arxiv.org/abs/2202.13059)

    论文提出了一种用高斯混合分布作为参数分布的变分推断方法，通过将高斯混合的熵近似为单峰高斯的熵之和来解决多峰性的问题，并从理论上分析近似误差。

    

    变分推断是一种用于近似无法处理的后验分布以量化机器学习不确定性的技术。然而，单峰的高斯分布通常被选择作为参数分布，很难逼近多峰性。在本文中，我们采用高斯混合分布作为参数分布。使用高斯混合进行变分推断的一个主要难点是如何近似高斯混合的熵。我们将高斯混合的熵近似为单峰高斯的熵之和，可以通过解析计算得到。此外，我们从理论上分析了真实熵与近似熵之间的近似误差，以便揭示我们的近似何时起作用。具体而言，近似误差由高斯混合均值之间距离与方差之和的比率控制。此外，当高斯混合组件的数量趋近于无穷大时，近似误差趋近于零。

    Variational inference is a technique for approximating intractable posterior distributions in order to quantify the uncertainty of machine learning. Although the unimodal Gaussian distribution is usually chosen as a parametric distribution, it hardly approximates the multimodality. In this paper, we employ the Gaussian mixture distribution as a parametric distribution. A main difficulty of variational inference with the Gaussian mixture is how to approximate the entropy of the Gaussian mixture. We approximate the entropy of the Gaussian mixture as the sum of the entropy of the unimodal Gaussian, which can be analytically calculated. In addition, we theoretically analyze the approximation error between the true entropy and approximated one in order to reveal when our approximation works well. Specifically, the approximation error is controlled by the ratios of the distances between the means to the sum of the variances of the Gaussian mixture. Furthermore, it converges to zero when the 
    
[^79]: 非参数IV模型中的自适应高效假设检验

    Adaptive, Rate-Optimal Hypothesis Testing in Nonparametric IV Models. (arXiv:2006.09587v3 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2006.09587](http://arxiv.org/abs/2006.09587)

    我们提出了一种自适应检验方法，用于处理非参数仪器变量模型中的结构函数的不等式和等式限制。该方法可以适应未知的平滑度和工具强度，并达到了最小值率的自适应最优检验率。

    

    我们提出了一种新的自适应假设检验方法，用于非参数仪器变量（NPIV）模型中结构函数的不等式（如单调性、凸性）和等式（如参数、半参数）限制。我们的检验统计量基于修改版的留一法样本模拟，计算受限和不受限筛子NPIV估计量间的二次距离。我们提供了计算简单、数据驱动的筛子调参和Bonferroni调整卡方临界值的选择。我们的检验适应未知的内生性平滑度和工具强度，达到了$L^2$最小值率的自适应最优检验率。也就是说，在复合零假设下其类型I误差的总体和其类型II误差的总体均不能被任何其他NPIV模型的假设检验所提高。我们还提出了基于数据的置信区间。

    We propose a new adaptive hypothesis test for inequality (e.g., monotonicity, convexity) and equality (e.g., parametric, semiparametric) restrictions on a structural function in a nonparametric instrumental variables (NPIV) model. Our test statistic is based on a modified leave-one-out sample analog of a quadratic distance between the restricted and unrestricted sieve NPIV estimators. We provide computationally simple, data-driven choices of sieve tuning parameters and Bonferroni adjusted chi-squared critical values. Our test adapts to the unknown smoothness of alternative functions in the presence of unknown degree of endogeneity and unknown strength of the instruments. It attains the adaptive minimax rate of testing in $L^2$.  That is, the sum of its type I error uniformly over the composite null and its type II error uniformly over nonparametric alternative models cannot be improved by any other hypothesis test for NPIV models of unknown regularities. Data-driven confidence sets in 
    

