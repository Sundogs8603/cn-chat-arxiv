# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Private Distribution Learning with Public Data: The View from Sample Compression.](http://arxiv.org/abs/2308.06239) | 本论文研究了在具有公共数据的情况下的私有分布学习问题，通过压缩样本和列表学习的方式，我们对高斯分布以及高斯混合分布进行了学习上限的分析，并提出了对不可知学习和分布变化抵抗学习的新结果。 |
| [^2] | [Nonlinear Permuted Granger Causality.](http://arxiv.org/abs/2308.06220) | 这项研究提出了一种处理非线性数据的格兰杰因果性方法，通过在特征提取过程中使用人工神经网络，利用置换来度量功能连接性，并实现了每个置换的方差的一致估计。在与其他技术的比较中，该方法表现出良好的性能。 |
| [^3] | [Change Point Detection With Conceptors.](http://arxiv.org/abs/2308.06213) | 我们提出了一种使用概念器矩阵进行变点检测的方法，通过学习时间序列中的特征动态，并利用单变量量化来识别变点。该方法在条件和无条件的变点检测问题上进行了测试，可以提供潜在的需要进一步研究的感兴趣位置。 |
| [^4] | [Towards a Causal Probabilistic Framework for Prediction, Action-Selection & Explanations for Robot Block-Stacking Tasks.](http://arxiv.org/abs/2308.06203) | 这项工作提出了一个新颖的因果性概率框架，用于解决机器人堆积方块任务的问题，通过结合因果推断，使机器人能够理解、推理和解释其环境。 |
| [^5] | [Gaussian Process Regression for Maximum Entropy Distribution.](http://arxiv.org/abs/2308.06149) | 本论文研究了高斯过程回归用于近似最大熵分布中的拉格朗日乘子，通过优化超参数来实现数据驱动的最大熵闭合。通过对比多个测试案例，验证了该方法的有效性。 |
| [^6] | [Application of Artificial Neural Networks for Investigation of Pressure Filtration Performance, a Zinc Leaching Filter Cake Moisture Modeling.](http://arxiv.org/abs/2308.06138) | 这项研究利用人工神经网络模型成功预测了锌生产压力过滤过程中的滤饼含水率，为锌生产工艺提供了可靠的预测手段。 |
| [^7] | [Uncertainty Quantification for Image-based Traffic Prediction across Cities.](http://arxiv.org/abs/2308.06129) | 本研究调查了不确定性量化方法在跨城市交通预测中的应用，发现存在的UQ方法可以提供有意义的不确定性估计，并可以用于无监督异常检测。 |
| [^8] | [Hawkes Processes with Delayed Granger Causality.](http://arxiv.org/abs/2308.06106) | 本论文提出了一个基于霍克斯过程的延迟格兰杰因果效应模型，通过显式地建模时间延迟，增加了模型的灵活性，并推断出时间延迟的后验分布，有助于追踪原始因果时间。 |
| [^9] | [Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction.](http://arxiv.org/abs/2308.06058) | 本文提出了AdaSPS和AdaSLS两种新的变种算法，用于解决SGD在非插值环境下的收敛问题，并在训练超参数模型时保持线性和亚线性的收敛速度。 |
| [^10] | [Learning nonparametric DAGs with incremental information via high-order HSIC.](http://arxiv.org/abs/2308.05969) | 本文提出了一个基于高阶HSIC的方法，在学习Bayesian网络中解决了局部变量同时具有直接和间接依赖关系的问题，通过确定子集和两阶段算法来进行局部修正，取得了良好的效果。 |
| [^11] | [Node Embedding for Homophilous Graphs with ARGEW: Augmentation of Random walks by Graph Edge Weights.](http://arxiv.org/abs/2308.05957) | 提出了一种名为ARGEW的增强随机游走方法，用于生成能够更好反映节点之间边权重的节点嵌入。 |
| [^12] | [Comparing the quality of neural network uncertainty estimates for classification problems.](http://arxiv.org/abs/2308.05903) | 本研究比较了用于分类问题的神经网络的不确定性估计质量，并通过统计方法和指标对不同方法进行了评估。研究展示了这些估计方法的一致性问题。 |
| [^13] | [Empirical Bayes Estimation with Side Information: A Nonparametric Integrative Tweedie Approach.](http://arxiv.org/abs/2308.05883) | 本研究提出了一种非参数综合 Tweedie 方法，通过利用侧信息的结构知识，在考虑了辅助数据的情况下进行正态均值的复合估计。理论分析和实证结果证明了该方法的优越性。 |
| [^14] | [SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling.](http://arxiv.org/abs/2308.04365) | SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。 |
| [^15] | [Scalable method for Bayesian experimental design without integrating over posterior distribution.](http://arxiv.org/abs/2306.17615) | 本论文提出了一种新颖的无似然方法，用于在基于偏微分方程的观测模型下解决A-最优贝叶斯实验设计问题，无需对贝叶斯后验分布进行采样或积分。 |
| [^16] | [Trained Transformers Learn Linear Models In-Context.](http://arxiv.org/abs/2306.09927) | 本文研究了Transformer在具有单层线性自注意层的线性回归任务上通过梯度流进行训练的ICL机制，揭示了梯度流具有找到目标函数全局最小值的能力。 |
| [^17] | [Differentially private sliced inverse regression in the federated paradigm.](http://arxiv.org/abs/2306.06324) | 本文提出了以联邦学习为基础的差分隐私切片逆回归方法，通过协作估计足够维数的降维子空间以保护敏感数据不被暴露，同时采用多种扰动策略保障差分隐私，还能自然地结合协作变量筛选步骤以有效处理高维数据。 |
| [^18] | [Collaborative Learning with a Drone Orchestrator.](http://arxiv.org/abs/2303.02266) | 本文研究了无人机辅助的协同学习问题，提出了一种通过智能设备群与无人机协同训练神经网络模型的方法。在考虑数据异质性和通信错误的情况下，导出了协同学习的收敛速度，并通过优化无人机轨迹来提高训练准确率。 |
| [^19] | [Unconstrained Dynamic Regret via Sparse Coding.](http://arxiv.org/abs/2301.13349) | 本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。 |
| [^20] | [Inverse Kernel Decomposition.](http://arxiv.org/abs/2211.05961) | 本文提出了一种新的非线性降维方法——逆核分解（IKD），通过特征值分解样本协方差矩阵实现。该方法受到高斯过程潜变量模型（GPLVMs）的启发，并在处理噪声数据方面提供了两种解决方案，具有良好的性能。 |
| [^21] | [A Law of Data Separation in Deep Learning.](http://arxiv.org/abs/2210.17020) | 深度学习中存在一个简单而定量的数据分离定律，每一层都以恒定的几何速率改善数据的分离程度。这个定律为架构设计、提高模型的健壮性和样本外性能以及预测的解释提供了实际的指导。 |
| [^22] | [How many perturbations break this model? Evaluating robustness beyond adversarial accuracy.](http://arxiv.org/abs/2207.04129) | 这项工作介绍了一种评估神经网络鲁棒性的替代方法-对抗稀疏性，它量化了成功扰动的难度。稀疏性揭示了鲁棒模型之间的重要差异并提出了改进鲁棒性的方法。 |
| [^23] | [Joint Multi-view Unsupervised Feature Selection and Graph Learning.](http://arxiv.org/abs/2204.08247) | 本文提出了一种联合多视图无监督特征选择和图学习的方法，通过正交分解建模多视图特征选择，应用跨空间局部保持进行聚类结构学习和相似性学习的连接。 |
| [^24] | [Graph Neural Network Sensitivity Under Probabilistic Error Model.](http://arxiv.org/abs/2203.07831) | 本文研究了概率误差模型对图卷积网络（GCN）性能的影响，并证明了误差模型下邻接矩阵的受限性。通过实验验证了这种误差界限，并研究了GCN在这种概率误差模型下的准确性敏感性。 |
| [^25] | [Selecting the number of clusters, clustering models, and algorithms. A unifying approach based on the quadratic discriminant score.](http://arxiv.org/abs/2111.02302) | 本文提出了一种基于二次判别得分的统一方法，用于选择聚类数目、聚类模型和算法。我们定义了基于二次判别得分函数和参数的参考聚类概念，并开发了两个一致性准则。这种方法适用于可以通过二次或线性边界很好分隔的群组，对于应用中寻找这种类型的群组很有帮助。 |
| [^26] | [Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers.](http://arxiv.org/abs/2010.11750) | 本文利用随机矩阵理论在线性回归设置中，对于具有两个任务的高维情况下的常用估计量的超额风险进行了精确渐近分析。 |
| [^27] | [A method for escaping limit cycles in training GANs.](http://arxiv.org/abs/2010.03322) | 本文提出了一种用于逃逸训练GAN中的极限周期的方法，通过预测离心加速度算法（PCAA）和自适应矩估计算法（Adam）相结合，有效改善了训练过程中的极限周期行为问题。 |
| [^28] | [Non-linear Neurons with Human-like Apical Dendrite Activations.](http://arxiv.org/abs/2003.03229) | 本论文提出了一种新的人工神经元模型和激活函数，通过使用单个神经元学习非线性决策边界，并在多个基准数据集上取得了优于传统方法的结果。 |
| [^29] | [Nonparametric Inference under B-bits Quantization.](http://arxiv.org/abs/1901.08571) | 本文提出了一种基于B位量化的非参数推断方法，通过一种高效的算法对样本进行量化处理。结果表明，当B超过阈值时，所提出的方法在样条模型中能够达到经典极小极值率的测试水平。另外，本文还拓展了方法的适用性，包括非参数直线性检验和自适应非参数检验。通过广泛的模拟研究和实际数据分析，证明了方法的有效性和效果。 |

# 详细

[^1]: 具有公共数据的私有分布学习：基于样本压缩的视角

    Private Distribution Learning with Public Data: The View from Sample Compression. (arXiv:2308.06239v1 [cs.LG])

    [http://arxiv.org/abs/2308.06239](http://arxiv.org/abs/2308.06239)

    本论文研究了在具有公共数据的情况下的私有分布学习问题，通过压缩样本和列表学习的方式，我们对高斯分布以及高斯混合分布进行了学习上限的分析，并提出了对不可知学习和分布变化抵抗学习的新结果。

    

    我们研究了在可以访问公共数据的情况下的私有分布学习问题。在这个设置中，我们称之为公私学习，学习器被给予来自未知分布p的属于类$\mathcal Q$的公共样本和私有样本，目标是输出一个对p的估计，同时遵守与私有样本相关的隐私约束（这里是纯差分隐私）。我们展示了类$\mathcal Q$的公私可学习性与$\mathcal Q$的样本压缩方案以及中间概念——列表学习的存在性有关。利用这个联系：（1）近似恢复了关于$\mathbb R^d$上高斯分布的先前结果；（2）得出了新的结果，包括对任意$k$-高斯混合分布在$\mathbb R^d$上的样本复杂度上界，以及对不可知和分布变化抵抗学习器的结果，以及公私可学习性的闭包性质。

    We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.  We show that the public-private learnability of a class $\mathcal Q$ is connected to the existence of a sample compression scheme for $\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability
    
[^2]: 非线性置换格兰杰因果性

    Nonlinear Permuted Granger Causality. (arXiv:2308.06220v1 [stat.ME])

    [http://arxiv.org/abs/2308.06220](http://arxiv.org/abs/2308.06220)

    这项研究提出了一种处理非线性数据的格兰杰因果性方法，通过在特征提取过程中使用人工神经网络，利用置换来度量功能连接性，并实现了每个置换的方差的一致估计。在与其他技术的比较中，该方法表现出良好的性能。

    

    格兰杰因果推断是从经济学到神经科学等领域广泛使用的一种有争议的方法。原始定义基于指定模型条件下建立因果关系的时间序列概念。将格兰杰因果性应用于非线性数据仍然具有挑战性，许多方法使用样本内测试，不能纳入样本外的可预测性，导致模型过拟合的担忧。为了进行样本外比较，我们明确地定义了使用协变量集的置换来表示功能连接性的度量。人工神经网络作为数据的特征提取器，用于近似任何任意的非线性关系，并在特征提取过程和模型残差的一定条件下，证明对每个置换的方差进行了一致的估计。通过模拟比较了置换方法与惩罚目标、天真替代和遗漏技术的性能

    Granger causal inference is a contentious but widespread method used in fields ranging from economics to neuroscience. The original definition addresses the notion of causality in time series by establishing functional dependence conditional on a specified model. Adaptation of Granger causality to nonlinear data remains challenging, and many methods apply in-sample tests that do not incorporate out-of-sample predictability leading to concerns of model overfitting. To allow for out-of-sample comparison, we explicitly define a measure of functional connectivity using permutations of the covariate set. Artificial neural networks serve as featurizers of the data to approximate any arbitrary, nonlinear relationship, and under certain conditions on the featurization process and the model residuals, we prove consistent estimation of the variance for each permutation. Performance of the permutation method is compared to penalized objective, naive replacement, and omission techniques via simula
    
[^3]: 使用概念器进行变点检测

    Change Point Detection With Conceptors. (arXiv:2308.06213v1 [stat.ML])

    [http://arxiv.org/abs/2308.06213](http://arxiv.org/abs/2308.06213)

    我们提出了一种使用概念器矩阵进行变点检测的方法，通过学习时间序列中的特征动态，并利用单变量量化来识别变点。该方法在条件和无条件的变点检测问题上进行了测试，可以提供潜在的需要进一步研究的感兴趣位置。

    

    离线变点检测旨在识别时间序列中数据生成过程发生变化的点。对于单变量独立同分布数据，这个问题已经得到了较好的研究，但是随着维度和时间依赖性的增加，变得具有挑战性。针对至多一个变点的问题，我们提出使用概念器矩阵来学习时间序列中指定训练窗口的特征动态。相关的随机递归神经网络作为数据的特征提取器，并且通过计算特征化与代表性概念器矩阵所张成空间之间的距离的单变量量化来识别变点。这种模型无关的方法可以提示可能需要进一步研究的感兴趣的位置。我们证明，在温和的假设下，该方法提供了真实变点的一致估计，并通过对原始数据进行移动块自助法产生统计量的分位数估计。该方法在条件和无条件的变点检测问题上进行了测试。

    Offline change point detection seeks to identify points in a time series where the data generating process changes. This problem is well studied for univariate i.i.d. data, but becomes challenging with increasing dimension and temporal dependence. For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series. The associated random recurrent neural network acts as a featurizer of the data, and change points are identified from a univariate quantification of the distance between the featurization and the space spanned by a representative conceptor matrix. This model agnostic method can suggest potential locations of interest that warrant further study. We prove that, under mild assumptions, the method provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on si
    
[^4]: 为机器人堆积方块任务构建因果性概率框架

    Towards a Causal Probabilistic Framework for Prediction, Action-Selection & Explanations for Robot Block-Stacking Tasks. (arXiv:2308.06203v1 [cs.RO])

    [http://arxiv.org/abs/2308.06203](http://arxiv.org/abs/2308.06203)

    这项工作提出了一个新颖的因果性概率框架，用于解决机器人堆积方块任务的问题，通过结合因果推断，使机器人能够理解、推理和解释其环境。

    

    现实世界中的不确定性意味着系统设计者无法预测并明确设计出机器人可能遇到的所有场景。因此，以这种方式设计的机器人在高度受控的环境之外容易出现故障。因果模型提供了一个原则性的框架，用于编码机器人与其环境相互作用的因果关系的形式化知识，并结合现实世界机器人通常遇到的噪声和不确定性的概率表示。结合因果推断，这些模型使自主代理能够理解、推理和解释其环境。在这项工作中，我们关注机器人堆积方块任务的问题，因为它展示了许多应用所需的基本感知和操作能力，包括仓库物流和家庭人工支持机器人。我们提出了一个新颖的因果性概率框架，将物理模拟功能嵌入到这个任务中。

    Uncertainties in the real world mean that is impossible for system designers to anticipate and explicitly design for all scenarios that a robot might encounter. Thus, robots designed like this are fragile and fail outside of highly-controlled environments. Causal models provide a principled framework to encode formal knowledge of the causal relationships that govern the robot's interaction with its environment, in addition to probabilistic representations of noise and uncertainty typically encountered by real-world robots. Combined with causal inference, these models permit an autonomous agent to understand, reason about, and explain its environment. In this work, we focus on the problem of a robot block-stacking task due to the fundamental perception and manipulation capabilities it demonstrates, required by many applications including warehouse logistics and domestic human support robotics. We propose a novel causal probabilistic framework to embed a physics simulation capability int
    
[^5]: 高斯过程回归用于最大熵分布

    Gaussian Process Regression for Maximum Entropy Distribution. (arXiv:2308.06149v1 [stat.ML])

    [http://arxiv.org/abs/2308.06149](http://arxiv.org/abs/2308.06149)

    本论文研究了高斯过程回归用于近似最大熵分布中的拉格朗日乘子，通过优化超参数来实现数据驱动的最大熵闭合。通过对比多个测试案例，验证了该方法的有效性。

    

    最大熵分布提供了一类适用于矩闭合问题的吸引人的概率密度函数。然而，找到参数化这些分布的拉格朗日乘子对于实际闭合设置来说却是一个计算瓶颈。受到高斯过程的最近成功的启发，我们研究了使用高斯先验来近似拉格朗日乘子作为给定一组矩的映射的适用性。通过最大化对数似然函数，优化了各种核函数的超参数。研究了所设计的数据驱动最大熵闭合在包括由Bhatnagar-Gross-Krook和Boltzmann动力学方程控制的非平衡分布松弛的几个测试案例中的性能。

    Maximum-Entropy Distributions offer an attractive family of probability densities suitable for moment closure problems. Yet finding the Lagrange multipliers which parametrize these distributions, turns out to be a computational bottleneck for practical closure settings. Motivated by recent success of Gaussian processes, we investigate the suitability of Gaussian priors to approximate the Lagrange multipliers as a map of a given set of moments. Examining various kernel functions, the hyperparameters are optimized by maximizing the log-likelihood. The performance of the devised data-driven Maximum-Entropy closure is studied for couple of test cases including relaxation of non-equilibrium distributions governed by Bhatnagar-Gross-Krook and Boltzmann kinetic equations.
    
[^6]: 应用人工神经网络研究压力过滤性能的探索和锌浸出滤饼含水率建模

    Application of Artificial Neural Networks for Investigation of Pressure Filtration Performance, a Zinc Leaching Filter Cake Moisture Modeling. (arXiv:2308.06138v1 [cs.LG])

    [http://arxiv.org/abs/2308.06138](http://arxiv.org/abs/2308.06138)

    这项研究利用人工神经网络模型成功预测了锌生产压力过滤过程中的滤饼含水率，为锌生产工艺提供了可靠的预测手段。

    

    机器学习是材料科学应用中的强大工具。人工神经网络是一种能够提供高预测准确性的机器学习技术。本研究旨在开发一种人工神经网络模型，用于预测锌生产的压力过滤过程中的滤饼含水率。滤饼含水率受到七个参数的影响：温度（35摄氏度和65摄氏度），固体浓度（0.2克/升和0.38克/升），pH值（2、3.5和5），吹气时间（2分钟、10分钟和15分钟），滤饼厚度（14毫米、20毫米、26毫米和34毫米），压力和过滤时间。本研究使用两种类型的织物进行了288次测试：聚丙烯（S1）和涤纶（S2）。通过决定系数（R2）、均方误差（MSE）和平均绝对误差（MAE）指标评估了人工神经网络模型在两个数据集上的性能。结果显示，对于S1和S2，R2值分别为0.88和0.83，MSE值分别为6.243x10-07和1.086x10-06，MAE值分别为0.00056和0.00088。

    Machine Learning (ML) is a powerful tool for material science applications. Artificial Neural Network (ANN) is a machine learning technique that can provide high prediction accuracy. This study aimed to develop an ANN model to predict the cake moisture of the pressure filtration process of zinc production. The cake moisture was influenced by seven parameters: temperature (35 and 65 Celsius), solid concentration (0.2 and 0.38 g/L), pH (2, 3.5, and 5), air-blow time (2, 10, and 15 min), cake thickness (14, 20, 26, and 34 mm), pressure, and filtration time. The study conducted 288 tests using two types of fabrics: polypropylene (S1) and polyester (S2). The ANN model was evaluated by the Coefficient of determination (R2), the Mean Square Error (MSE), and the Mean Absolute Error (MAE) metrics for both datasets. The results showed R2 values of 0.88 and 0.83, MSE values of 6.243x10-07 and 1.086x10-06, and MAE values of 0.00056 and 0.00088 for S1 and S2, respectively. These results indicated t
    
[^7]: 基于图像的跨城市交通预测的不确定性量化

    Uncertainty Quantification for Image-based Traffic Prediction across Cities. (arXiv:2308.06129v1 [cs.CV])

    [http://arxiv.org/abs/2308.06129](http://arxiv.org/abs/2308.06129)

    本研究调查了不确定性量化方法在跨城市交通预测中的应用，发现存在的UQ方法可以提供有意义的不确定性估计，并可以用于无监督异常检测。

    

    尽管深度学习模型在交通预测方面具有较强的预测性能，但由于解释性的缺乏，它们在实际智能交通系统中的普遍部署受到了限制。不确定性量化（UQ）方法提供了一种引入概率推理、改进决策和提高模型部署潜力的方法。为了全面了解现有UQ方法在交通预测中的有用性以及获得的不确定性与城市范围内交通动态之间的关系，我们对跨越多个城市和时间段的大规模基于图像的交通数据集应用了这些方法。我们比较了两种认知不确定性和两种重要性不确定性UQ方法在时间和时空转换任务上的表现，并发现可以获得有意义的不确定性估计。我们进一步展示了如何利用不确定性估计来进行城市交通动态变化的无监督异常检测。我们发现我们的方法可以在城市交通动态变化方面发现异常。

    Despite the strong predictive performance of deep learning models for traffic prediction, their widespread deployment in real-world intelligent transportation systems has been restrained by a lack of interpretability. Uncertainty quantification (UQ) methods provide an approach to induce probabilistic reasoning, improve decision-making and enhance model deployment potential. To gain a comprehensive picture of the usefulness of existing UQ methods for traffic prediction and the relation between obtained uncertainties and city-wide traffic dynamics, we investigate their application to a large-scale image-based traffic dataset spanning multiple cities and time periods. We compare two epistemic and two aleatoric UQ methods on both temporal and spatio-temporal transfer tasks, and find that meaningful uncertainty estimates can be recovered. We further demonstrate how uncertainty estimates can be employed for unsupervised outlier detection on changes in city traffic dynamics. We find that our 
    
[^8]: 延迟格兰杰因果性的霍克斯过程

    Hawkes Processes with Delayed Granger Causality. (arXiv:2308.06106v1 [cs.LG])

    [http://arxiv.org/abs/2308.06106](http://arxiv.org/abs/2308.06106)

    本论文提出了一个基于霍克斯过程的延迟格兰杰因果效应模型，通过显式地建模时间延迟，增加了模型的灵活性，并推断出时间延迟的后验分布，有助于追踪原始因果时间。

    

    我们旨在基于多元霍克斯过程明确地建模延迟的格兰杰因果效应。这个想法的灵感来自于因果事件通常需要一些时间才能产生影响。研究这个时间延迟本身就很有意义。在提出的模型中，我们首先证明了在适当条件下的延迟参数的可辨识性。我们进一步研究了在复杂情况下的模型估计方法，其中我们希望推断出时间延迟的后验分布，并了解该分布在不同情况下的变化。我们将时间延迟视为潜在变量，并制定了一个变分自编码器（VAE）算法来近似时间延迟的后验分布。通过明确地建模霍克斯过程中的时间延迟，我们为模型增加了灵活性。推断出的时间延迟后验分布具有科学意义，并有助于追踪支持根本原因分析的原始因果时间。我们对模型进行了实证评估。

    We aim to explicitly model the delayed Granger causal effects based on multivariate Hawkes processes. The idea is inspired by the fact that a causal event usually takes some time to exert an effect. Studying this time lag itself is of interest. Given the proposed model, we first prove the identifiability of the delay parameter under mild conditions. We further investigate a model estimation method under a complex setting, where we want to infer the posterior distribution of the time lags and understand how this distribution varies across different scenarios. We treat the time lags as latent variables and formulate a Variational Auto-Encoder (VAE) algorithm to approximate the posterior distribution of the time lags. By explicitly modeling the time lags in Hawkes processes, we add flexibility to the model. The inferred time-lag posterior distributions are of scientific meaning and help trace the original causal time that supports the root cause analysis. We empirically evaluate our model
    
[^9]: 带有Polyak步长和线性搜索的自适应SGD: 鲁棒收敛和方差减小

    Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction. (arXiv:2308.06058v1 [cs.LG])

    [http://arxiv.org/abs/2308.06058](http://arxiv.org/abs/2308.06058)

    本文提出了AdaSPS和AdaSLS两种新的变种算法，用于解决SGD在非插值环境下的收敛问题，并在训练超参数模型时保持线性和亚线性的收敛速度。

    

    最近提出的随机Polyak步长 (SPS) 和随机线性搜索 (SLS) 在训练超参数模型时显示出了显著的有效性。然而，在非插值环境下，这两种算法只能保证收敛到一个解的邻域，可能导致比初始猜测更差的输出结果。尽管已经提出了人为减小自适应步长的方法来解决这个问题 (Orvieto et al. [2022])，但这种方法会导致凸函数和超参数模型的收敛速度变慢。在本文中，我们做出了两个贡献：首先，我们提出了两种新的SPS和SLS变种，分别称为AdaSPS和AdaSLS，它们在非插值环境中保证收敛，并且在训练超参数模型时保持凸函数和强凸函数的亚线性和线性收敛速度。AdaSLS不需要对问题相关参数的了解，而AdaSPS只需要最优函数值的下界。

    The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al. [2022]), this approach results in slower convergence rates for convex and over-parameterized models. In this work, we make two contributions: Firstly, we propose two new variants of SPS and SLS, called AdaSPS and AdaSLS, which guarantee convergence in non-interpolation settings and maintain sub-linear and linear convergence rates for convex and strongly convex functions when training over-parameterized models. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value 
    
[^10]: 通过高阶HSIC学习具有增量信息的非参数DAGs

    Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v1 [cs.LG])

    [http://arxiv.org/abs/2308.05969](http://arxiv.org/abs/2308.05969)

    本文提出了一个基于高阶HSIC的方法，在学习Bayesian网络中解决了局部变量同时具有直接和间接依赖关系的问题，通过确定子集和两阶段算法来进行局部修正，取得了良好的效果。

    

    针对学习贝叶斯网络（BN）的基于评分的方法，目标是最大化全局评分函数。然而，如果局部变量同时具有直接和间接依赖关系，那么基于评分函数的全局优化将忽略具有间接依赖关系的变量之间的边缘，其得分小于具有直接依赖关系的边缘。本文提出了一个基于确定子集的可辨识性条件，以识别潜在的DAG。通过可辨识性条件，我们开发了一个两阶段算法，即最优调整（OT）算法，以在全局优化的基础上进行局部修正。在最优阶段，基于一阶Hilbert-Schmidt独立性准则（HSIC）的优化问题给出了一个估计的骨架作为初始确定的父节点子集。在调整阶段，根据高阶HSIC的理论证明增量特性，对骨架进行局部调整，包括删除、添加和DAG格式化策略。

    Score-based methods for learning Bayesain networks(BN) aim to maximizing the global score functions. However, if local variables have direct and indirect dependence simultaneously, the global optimization on score functions misses edges between variables with indirect dependent relationship, of which scores are smaller than those with direct dependent relationship. In this paper, we present an identifiability condition based on a determined subset of parents to identify the underlying DAG. By the identifiability condition, we develop a two-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the global optimization. In the optimal phase, an optimization problem based on first-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated skeleton as the initial determined parents subset. In the tuning phase, the skeleton is locally tuned by deletion, addition and DAG-formalization strategies using the theoretically proved incremental properties of high-order HS
    
[^11]: 带有ARGEW的同质图节点嵌入：通过图边权重增强的随机游走

    Node Embedding for Homophilous Graphs with ARGEW: Augmentation of Random walks by Graph Edge Weights. (arXiv:2308.05957v1 [cs.SI])

    [http://arxiv.org/abs/2308.05957](http://arxiv.org/abs/2308.05957)

    提出了一种名为ARGEW的增强随机游走方法，用于生成能够更好反映节点之间边权重的节点嵌入。

    

    将网络中的节点表示为密集向量节点嵌入对于理解给定网络和解决许多下游任务非常重要。特别是对于权重同质图，其中具有相似节点的边缘权重较大，我们希望节点嵌入中具有强权重的节点对具有更接近的嵌入。虽然基于随机游走的节点嵌入方法，如node2vec和node2vec+，通过将边权重包含在行走转移概率中，可以适用于加权网络，但我们的实验证明嵌入结果不足以反映边权重。在本文中，我们提出了ARGEW（通过图边权重增强的随机游走），这是一种新颖的随机游走增强方法，通过扩展语料库使具有较大边权重的节点最终具有更接近的嵌入。ARGEW可以与任何基于随机游走的节点嵌入方法一起使用，因为它独立于随机采样策略本身并在已有方法的基础上工作。

    Representing nodes in a network as dense vectors node embeddings is important for understanding a given network and solving many downstream tasks. In particular, for weighted homophilous graphs where similar nodes are connected with larger edge weights, we desire node embeddings where node pairs with strong weights have closer embeddings. Although random walk based node embedding methods like node2vec and node2vec+ do work for weighted networks via including edge weights in the walk transition probabilities, our experiments show that the embedding result does not adequately reflect edge weights. In this paper, we propose ARGEW (Augmentation of Random walks by Graph Edge Weights), a novel augmentation method for random walks that expands the corpus in such a way that nodes with larger edge weights end up with closer embeddings. ARGEW can work with any random walk based node embedding method, because it is independent of the random sampling strategy itself and works on top of the already
    
[^12]: 比较神经网络分类问题的不确定性估计质量

    Comparing the quality of neural network uncertainty estimates for classification problems. (arXiv:2308.05903v1 [cs.LG])

    [http://arxiv.org/abs/2308.05903](http://arxiv.org/abs/2308.05903)

    本研究比较了用于分类问题的神经网络的不确定性估计质量，并通过统计方法和指标对不同方法进行了评估。研究展示了这些估计方法的一致性问题。

    

    传统的深度学习模型是强大的分类器，但许多方法没有提供对其估计结果的不确定性。不确定性量化（UQ）方法对于深度学习模型在决策中的有用性引起了文献中的关注，尤其是对于高风险决策。然而，目前对这些方法的质量评估研究很少。我们使用经验主义置信区间覆盖率和区间宽度的统计方法来评估置信区间的质量，并使用期望校准误差评估分类预测的置信度。我们将这些不同的UQ方法应用于使用马尔科夫链蒙特卡洛（MCMC）和变分推断（VI）拟合的贝叶斯神经网络（BNN），自助式神经网络（NN），深度集成（DE）和蒙特卡洛（MC）dropout的高光谱图像目标检测问题，并展示了不同方法结果的一致性问题。

    Traditional deep learning (DL) models are powerful classifiers, but many approaches do not provide uncertainties for their estimates. Uncertainty quantification (UQ) methods for DL models have received increased attention in the literature due to their usefulness in decision making, particularly for high-consequence decisions. However, there has been little research done on how to evaluate the quality of such methods. We use statistical methods of frequentist interval coverage and interval width to evaluate the quality of credible intervals, and expected calibration error to evaluate classification predicted confidence. These metrics are evaluated on Bayesian neural networks (BNN) fit using Markov Chain Monte Carlo (MCMC) and variational inference (VI), bootstrapped neural networks (NN), Deep Ensembles (DE), and Monte Carlo (MC) dropout. We apply these different UQ for DL methods to a hyperspectral image target detection problem and show the inconsistency of the different methods' resu
    
[^13]: 使用侧信息的经验贝叶斯估计：一种非参数综合 Tweedie 方法

    Empirical Bayes Estimation with Side Information: A Nonparametric Integrative Tweedie Approach. (arXiv:2308.05883v1 [stat.ME])

    [http://arxiv.org/abs/2308.05883](http://arxiv.org/abs/2308.05883)

    本研究提出了一种非参数综合 Tweedie 方法，通过利用侧信息的结构知识，在考虑了辅助数据的情况下进行正态均值的复合估计。理论分析和实证结果证明了该方法的优越性。

    

    我们研究了在考虑到侧信息存在的情况下，正态均值的复合估计问题。利用经验贝叶斯框架，我们开发了一种非参数综合 Tweedie（NIT）方法，该方法将多变量辅助数据中编码的结构知识合并到复合估计的精度中。我们的方法使用凸优化工具直接估计对数密度的梯度，从而能够将结构约束纳入考虑。我们对 NIT 的渐近风险进行理论分析，并确定了 NIT 收敛到 Oracle 估计器的速率。随着辅助数据的维度增加，我们准确地量化了估计风险的改善以及收敛速度的恶化。通过对模拟数据和真实数据进行分析，我们展示了 NIT 的数值性能，证明了其优于现有方法。

    We investigate the problem of compound estimation of normal means while accounting for the presence of side information. Leveraging the empirical Bayes framework, we develop a nonparametric integrative Tweedie (NIT) approach that incorporates structural knowledge encoded in multivariate auxiliary data to enhance the precision of compound estimation. Our approach employs convex optimization tools to estimate the gradient of the log-density directly, enabling the incorporation of structural constraints. We conduct theoretical analyses of the asymptotic risk of NIT and establish the rate at which NIT converges to the oracle estimator. As the dimension of the auxiliary data increases, we accurately quantify the improvements in estimation risk and the associated deterioration in convergence rate. The numerical performance of NIT is illustrated through the analysis of both simulated and real data, demonstrating its superiority over existing methods.
    
[^14]: SLEM：机器学习用于路径建模和因果推断的超级学习者方程模型

    SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])

    [http://arxiv.org/abs/2308.04365](http://arxiv.org/abs/2308.04365)

    SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。

    

    因果推断是科学的关键目标，使研究人员能够通过观察数据得出关于对假定干预的预测的有意义的结论。路径模型、结构方程模型(SEMs)以及更一般的有向无环图(DAGs)能够明确地指定关于现象背后的因果结构的假设。与DAGs不同，SEMs假设线性关系，这可能导致函数错误规范，从而阻碍研究人员进行可靠的效果大小估计。相反，我们提出了超级学习者方程模型（SLEM），一种集成了机器学习超级学习者集成的路径建模技术。我们通过实证研究，证明了SLEM能够提供一致且无偏的因果效应估计，在与SEMs进行线性模型比较时表现出竞争力，并且在处理非线性关系时优于SEMs。

    Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
    
[^15]: 无需对后验分布进行积分的可扩展贝叶斯实验设计方法

    Scalable method for Bayesian experimental design without integrating over posterior distribution. (arXiv:2306.17615v1 [math.NA])

    [http://arxiv.org/abs/2306.17615](http://arxiv.org/abs/2306.17615)

    本论文提出了一种新颖的无似然方法，用于在基于偏微分方程的观测模型下解决A-最优贝叶斯实验设计问题，无需对贝叶斯后验分布进行采样或积分。

    

    本文解决了在基于偏微分方程的观测模型中求解A-最优贝叶斯实验设计问题时的计算效率问题，由于需要计算复杂，A-最优性是贝叶斯实验设计中广泛使用的、易于解释的标准。该标准通过最小化预期条件方差，也称为预期后验方差，来寻求最优实验设计。本工作提出了一种新颖的无似然方法，用于寻找A-最优实验设计，而无需对贝叶斯后验分布进行采样或积分。在我们的方法中，通过使用总方差定理，通过条件期望的方差来获得预期条件方差，同时利用正交投影性质来近似条件期望。通过渐近误差估计，我们证明了后验不可计算性问题。

    We address the computational efficiency in solving the A-optimal Bayesian design of experiments problems for which the observational model is based on partial differential equations and, consequently, is computationally expensive to evaluate. A-optimality is a widely used and easy-to-interpret criterion for the Bayesian design of experiments. The criterion seeks the optimal experiment design by minimizing the expected conditional variance, also known as the expected posterior variance. This work presents a novel likelihood-free method for seeking the A-optimal design of experiments without sampling or integrating the Bayesian posterior distribution. In our approach, the expected conditional variance is obtained via the variance of the conditional expectation using the law of total variance, while we take advantage of the orthogonal projection property to approximate the conditional expectation. Through an asymptotic error estimation, we show that the intractability of the posterior doe
    
[^16]: 训练好的Transformer在上下文中学习线性模型

    Trained Transformers Learn Linear Models In-Context. (arXiv:2306.09927v1 [stat.ML])

    [http://arxiv.org/abs/2306.09927](http://arxiv.org/abs/2306.09927)

    本文研究了Transformer在具有单层线性自注意层的线性回归任务上通过梯度流进行训练的ICL机制，揭示了梯度流具有找到目标函数全局最小值的能力。

    

    基于注意力的神经网络，例如Transformers，在上下文学习（ICL）方面表现出了非凡的能力：给定一个来自未见过的任务的短语序列的提示，它们可以制定相关的每个令牌和下一个令牌的预测，而不需要任何参数更新。通过将标记的训练数据和未标记的测试数据序列嵌入到提示中，这使得Transformer表现得像有监督学习算法。事实上，最近的工作表明，在随机实例上训练Transformer体系结构的线性回归问题时，这些模型的预测会模仿普通最小二乘法的预测。

    Attention-based neural networks such as transformers have demonstrated a remarkable ability to exhibit in-context learning (ICL): Given a short prompt sequence of tokens from an unseen task, they can formulate relevant per-token and next-token predictions without any parameter updates. By embedding a sequence of labeled training data and unlabeled test data as a prompt, this allows for transformers to behave like supervised learning algorithms. Indeed, recent work has shown that when training transformer architectures over random instances of linear regression problems, these models' predictions mimic those of ordinary least squares.  Towards understanding the mechanisms underlying this phenomenon, we investigate the dynamics of ICL in transformers with a single linear self-attention layer trained by gradient flow on linear regression tasks. We show that despite non-convexity, gradient flow with a suitable random initialization finds a global minimum of the objective function. At this 
    
[^17]: 以联邦学习范式为基础的差分隐私切片逆回归

    Differentially private sliced inverse regression in the federated paradigm. (arXiv:2306.06324v1 [stat.ME])

    [http://arxiv.org/abs/2306.06324](http://arxiv.org/abs/2306.06324)

    本文提出了以联邦学习为基础的差分隐私切片逆回归方法，通过协作估计足够维数的降维子空间以保护敏感数据不被暴露，同时采用多种扰动策略保障差分隐私，还能自然地结合协作变量筛选步骤以有效处理高维数据。

    

    我们将广受欢迎的切片逆回归扩展到去解决分散式数据、优先保护隐私和通信效率等挑战。我们的方法，被称为联邦切片逆回归（FSIR），便于多个客户端之间协作估计足够维数的降维子空间，只共享本地估计，以保护敏感数据不被暴露。为了防范潜在的攻击，FSIR还采用了多种扰动策略，包括一种新颖的多元高斯机制，以低成本的统计精度保证差分隐私。此外，FSIR自然地结合了协作变量筛选步骤，能够有效地处理高维客户端数据。FSIR的理论性质在低维和高维设置中得到了证实，并得到了广泛的数字实验和实际数据分析的支持。

    We extend the celebrated sliced inverse regression to address the challenges of decentralized data, prioritizing privacy and communication efficiency. Our approach, federated sliced inverse regression (FSIR), facilitates collaborative estimation of the sufficient dimension reduction subspace among multiple clients, solely sharing local estimates to protect sensitive datasets from exposure. To guard against potential adversary attacks, FSIR further employs diverse perturbation strategies, including a novel multivariate Gaussian mechanism that guarantees differential privacy at a low cost of statistical accuracy. Additionally, FSIR naturally incorporates a collaborative variable screening step, enabling effective handling of high-dimensional client data. Theoretical properties of FSIR are established for both low-dimensional and high-dimensional settings, supported by extensive numerical experiments and real data analysis.
    
[^18]: 采用机载协调器进行协同学习

    Collaborative Learning with a Drone Orchestrator. (arXiv:2303.02266v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2303.02266](http://arxiv.org/abs/2303.02266)

    本文研究了无人机辅助的协同学习问题，提出了一种通过智能设备群与无人机协同训练神经网络模型的方法。在考虑数据异质性和通信错误的情况下，导出了协同学习的收敛速度，并通过优化无人机轨迹来提高训练准确率。

    

    本文考虑了无人机辅助协同学习的问题。在这种场景下，智能无线设备群通过无人机共同训练一个共享的神经网络模型。每个设备使用其传感器记录来自环境的样本，以获取用于训练的本地数据集。由于各设备的数据量和传感器噪声水平不同，训练数据具有严重的异质性。智能设备对其本地数据集进行迭代训练，并将模型参数与无人机进行交换以进行聚合。在考虑数据异质性、传感器噪声水平和通信错误的情况下，导出了协同学习的收敛速率，并获得了最大化训练的神经网络的最终准确率的无人机轨迹。所提出的轨迹优化方法考虑了设备的数据特性（即本地数据集大小和噪声水平）以及其无线通信条件。

    In this paper, the problem of drone-assisted collaborative learning is considered. In this scenario, swarm of intelligent wireless devices train a shared neural network (NN) model with the help of a drone. Using its sensors, each device records samples from its environment to gather a local dataset for training. The training data is severely heterogeneous as various devices have different amount of data and sensor noise level. The intelligent devices iteratively train the NN on their local datasets and exchange the model parameters with the drone for aggregation. For this system, the convergence rate of collaborative learning is derived while considering data heterogeneity, sensor noise levels, and communication errors, then, the drone trajectory that maximizes the final accuracy of the trained NN is obtained. The proposed trajectory optimization approach is aware of both the devices data characteristics (i.e., local dataset size and noise level) and their wireless channel conditions, 
    
[^19]: 通过稀疏编码实现无约束动态遗憾

    Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13349](http://arxiv.org/abs/2301.13349)

    本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。

    

    受时间序列预测的影响，本研究探讨了在线线性优化（OLO）在两个问题结构的耦合下的情况：域无界，而算法的性能是通过动态遗憾来衡量的。处理任一问题都要求遗憾界限依赖于比较序列的某些复杂度量度 - 特别是无约束OLO中的比较器范数，以及动态遗憾中的路径长度。与最近一篇文章(Jacobsen& Cutkosky，2022)适应这两个复杂度量度相比，我们提出了一种通过重新构造问题为稀疏编码的复杂度度量方式。可以通过一个简单的模块化框架实现适应性，这个框架自然地利用了环境更复杂的前置知识。同时，我们还提出了一种新的静态无约束OLO梯度自适应算法，使用了新颖的连续时间机制设计。这可能是具有独立兴趣的。

    Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen & Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
    
[^20]: 反向核分解

    Inverse Kernel Decomposition. (arXiv:2211.05961v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05961](http://arxiv.org/abs/2211.05961)

    本文提出了一种新的非线性降维方法——逆核分解（IKD），通过特征值分解样本协方差矩阵实现。该方法受到高斯过程潜变量模型（GPLVMs）的启发，并在处理噪声数据方面提供了两种解决方案，具有良好的性能。

    

    最先进的降维方法在很大程度上依赖于复杂的优化过程。而仅需特征值分解的闭式方法在复杂性和非线性方面不够。在本文中，我们提出了一种新的非线性降维方法——逆核分解（IKD），基于数据的样本协方差矩阵的特征值分解。该方法受到高斯过程潜变量模型（GPLVMs）的启发，具有与GPLVMs相当的性能。为了处理具有较弱相关性的噪声数据，我们提出了两种解决方案——分块和测地线——以利用局部相关的数据点并提供更好和数值上更稳定的潜变量估计。我们使用合成数据集和四个真实数据集表明，IKD是一种比其他基于特征值分解的方法更好的降维方法，并且在优化方法方面具有相当的性能。

    The state-of-the-art dimensionality reduction approaches largely rely on complicated optimization procedures. On the other hand, closed-form approaches requiring merely eigen-decomposition do not have enough sophistication and nonlinearity. In this paper, we propose a novel nonlinear dimensionality reduction method -- Inverse Kernel Decomposition (IKD) -- based on an eigen-decomposition of the sample covariance matrix of data. The method is inspired by Gaussian process latent variable models (GPLVMs) and has comparable performance with GPLVMs. To deal with very noisy data with weak correlations, we propose two solutions -- blockwise and geodesic -- to make use of locally correlated data points and provide better and numerically more stable latent estimations. We use synthetic datasets and four real-world datasets to show that IKD is a better dimensionality reduction method than other eigen-decomposition-based methods, and achieves comparable performance against optimization-based metho
    
[^21]: 深度学习中的数据分离定律

    A Law of Data Separation in Deep Learning. (arXiv:2210.17020v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17020](http://arxiv.org/abs/2210.17020)

    深度学习中存在一个简单而定量的数据分离定律，每一层都以恒定的几何速率改善数据的分离程度。这个定律为架构设计、提高模型的健壮性和样本外性能以及预测的解释提供了实际的指导。

    

    虽然深度学习在科学的许多领域取得了重大进展，但其黑盒特性阻碍了未来人工智能应用的架构设计和高风险决策的解释。我们通过研究深度神经网络在中间层中如何处理数据来解决这个问题。我们的发现是一个简单而定量的定律，它规定了深度神经网络如何根据类别成员将数据在所有层中分离出来进行分类。这个定律表明，每一层都以恒定的几何速率改善数据的分离程度，并且在训练过程中观察到了它的出现，无论是在一系列网络架构还是数据集上。这个定律为架构设计、提高模型的健壮性和样本外性能以及预测的解释提供了实际的指导。

    While deep learning has enabled significant advances in many areas of science, its black-box nature hinders architecture design for future artificial intelligence applications and interpretation for high-stakes decision makings. We addressed this issue by studying the fundamental question of how deep neural networks process data in the intermediate layers. Our finding is a simple and quantitative law that governs how deep neural networks separate data according to class membership throughout all layers for classification. This law shows that each layer improves data separation at a constant geometric rate, and its emergence is observed in a collection of network architectures and datasets during training. This law offers practical guidelines for designing architectures, improving model robustness and out-of-sample performance, as well as interpreting the predictions.
    
[^22]: 这个模型有多少扰动会破坏它？评估超越对抗准确度的鲁棒性。

    How many perturbations break this model? Evaluating robustness beyond adversarial accuracy. (arXiv:2207.04129v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04129](http://arxiv.org/abs/2207.04129)

    这项工作介绍了一种评估神经网络鲁棒性的替代方法-对抗稀疏性，它量化了成功扰动的难度。稀疏性揭示了鲁棒模型之间的重要差异并提出了改进鲁棒性的方法。

    

    对抗攻击的鲁棒性通常通过对抗准确度来评估。然而，这个度量标准并不能完全捕捉到鲁棒性的所有方面，尤其是忽略了针对每个数据点可以找到多少扰动的问题。在这项工作中，我们引入了一种替代方法，即对抗稀疏性，它量化了在给定输入点和扰动方向约束的情况下找到成功扰动的难度。我们展示了稀疏性在多个方面对神经网络提供了有价值的洞察力：例如，它揭示了当前最先进的鲁棒模型之间的重要差异，这是精确度分析所不具备的，并且提出了提高它们鲁棒性的方法。当应用对弱攻击有效但对强攻击无效的破解防御时，稀疏性可以区分完全无效和部分有效的防御。最后，通过稀疏性，我们可以度量鲁棒性的增加。

    Robustness to adversarial attacks is typically evaluated with adversarial accuracy. While essential, this metric does not capture all aspects of robustness and in particular leaves out the question of how many perturbations can be found for each point. In this work, we introduce an alternative approach, adversarial sparsity, which quantifies how difficult it is to find a successful perturbation given both an input point and a constraint on the direction of the perturbation. We show that sparsity provides valuable insight into neural networks in multiple ways: for instance, it illustrates important differences between current state-of-the-art robust models them that accuracy analysis does not, and suggests approaches for improving their robustness. When applying broken defenses effective against weak attacks but not strong ones, sparsity can discriminate between the totally ineffective and the partially effective defenses. Finally, with sparsity we can measure increases in robustness th
    
[^23]: 多视图无监督特征选择与图学习的联合方法

    Joint Multi-view Unsupervised Feature Selection and Graph Learning. (arXiv:2204.08247v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.08247](http://arxiv.org/abs/2204.08247)

    本文提出了一种联合多视图无监督特征选择和图学习的方法，通过正交分解建模多视图特征选择，应用跨空间局部保持进行聚类结构学习和相似性学习的连接。

    

    尽管取得了一定的进展，但之前的多视图无监督特征选择方法主要存在两个限制。首先，它们通常使用聚类结构或相似性结构来指导特征选择，忽略了联合公式可能带来的互惠效益。其次，它们通常通过全局结构学习或局部结构学习来学习相似性结构，缺乏同时具备全局和局部结构感知的图学习能力。鉴于此，本文提出了一种联合多视图无监督特征选择和图学习的方法（JMVFG）。具体而言，我们采用正交分解对多视图特征选择进行建模，其中每个目标矩阵被分解为一个视图特定的基矩阵和一个视图一致的聚类指示器。跨空间局部保持被应用于在投影空间中进行聚类结构学习和相似性学习的连接。

    Despite significant progress, previous multi-view unsupervised feature selection methods mostly suffer from two limitations. First, they generally utilize either cluster structure or similarity structure to guide the feature selection, which neglect the possibility of a joint formulation with mutual benefits. Second, they often learn the similarity structure by either global structure learning or local structure learning, which lack the capability of graph learning with both global and local structural awareness. In light of this, this paper presents a joint multi-view unsupervised feature selection and graph learning (JMVFG) approach. Particularly, we formulate the multi-view feature selection with orthogonal decomposition, where each target matrix is decomposed into a view-specific basis matrix and a view-consistent cluster indicator. The cross-space locality preservation is incorporated to bridge the cluster structure learning in the projected space and the similarity learning (i.e.
    
[^24]: 图形神经网络在概率误差模型下的敏感性

    Graph Neural Network Sensitivity Under Probabilistic Error Model. (arXiv:2203.07831v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.07831](http://arxiv.org/abs/2203.07831)

    本文研究了概率误差模型对图卷积网络（GCN）性能的影响，并证明了误差模型下邻接矩阵的受限性。通过实验验证了这种误差界限，并研究了GCN在这种概率误差模型下的准确性敏感性。

    

    图卷积网络（GCN）可以通过图卷积成功学习图信号表示。图卷积依赖于图滤波器，其中包含数据的拓扑依赖关系并传播数据特征。然而，在传播矩阵（例如邻接矩阵）中的估计误差可能对图滤波器和GCNs产生重大影响。本文研究概率图误差模型对GCN性能的影响。我们证明了在误差模型下的邻接矩阵受到图大小和误差概率函数的限制。我们进一步分析了带有自循环的归一化邻接矩阵的上界。最后，我们通过在合成数据集上运行实验来说明误差界限，并研究简单GCN在这种概率误差模型下的准确性敏感性。

    Graph convolutional networks (GCNs) can successfully learn the graph signal representation by graph convolution. The graph convolution depends on the graph filter, which contains the topological dependency of data and propagates data features. However, the estimation errors in the propagation matrix (e.g., the adjacency matrix) can have a significant impact on graph filters and GCNs. In this paper, we study the effect of a probabilistic graph error model on the performance of the GCNs. We prove that the adjacency matrix under the error model is bounded by a function of graph size and error probability. We further analytically specify the upper bound of a normalized adjacency matrix with self-loop added. Finally, we illustrate the error bounds by running experiments on a synthetic dataset and study the sensitivity of a simple GCN under this probabilistic error model on accuracy.
    
[^25]: 选择聚类数目、聚类模型和算法：基于二次判别得分的统一方法

    Selecting the number of clusters, clustering models, and algorithms. A unifying approach based on the quadratic discriminant score. (arXiv:2111.02302v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.02302](http://arxiv.org/abs/2111.02302)

    本文提出了一种基于二次判别得分的统一方法，用于选择聚类数目、聚类模型和算法。我们定义了基于二次判别得分函数和参数的参考聚类概念，并开发了两个一致性准则。这种方法适用于可以通过二次或线性边界很好分隔的群组，对于应用中寻找这种类型的群组很有帮助。

    

    聚类分析需要做出许多决策：聚类方法和隐含的参考模型、聚类数目，以及通常还有一些超参数和算法的调整。在实践中，我们会得到多个划分，最终根据验证或选择准则选择一个最终的划分。存在大量的验证方法，它们隐式或显式地假设某种聚类概念。此外，它们常常被限制在特定方法得到的划分上进行操作。本文聚焦于可以通过二次或线性边界很好分隔的群组。基于二次判别得分函数和描述聚类大小、中心和散布的参数，我们定义了参考聚类概念。我们开发了两个聚类质量准则，称为二次得分。我们展示了这些准则与一般类别的椭圆对称分布生成的群组一致。在应用中，寻找这种类型的群组是常见的。

    Cluster analysis requires many decisions: the clustering method and the implied reference model, the number of clusters and, often, several hyper-parameters and algorithms' tunings. In practice, one produces several partitions, and a final one is chosen based on validation or selection criteria. There exist an abundance of validation methods that, implicitly or explicitly, assume a certain clustering notion. Moreover, they are often restricted to operate on partitions obtained from a specific method. In this paper, we focus on groups that can be well separated by quadratic or linear boundaries. The reference cluster concept is defined through the quadratic discriminant score function and parameters describing clusters' size, center and scatter. We develop two cluster-quality criteria called quadratic scores. We show that these criteria are consistent with groups generated from a general class of elliptically-symmetric distributions. The quest for this type of groups is common in applic
    
[^26]: 量化异构转移的精确高维渐近分析

    Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers. (arXiv:2010.11750v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.11750](http://arxiv.org/abs/2010.11750)

    本文利用随机矩阵理论在线性回归设置中，对于具有两个任务的高维情况下的常用估计量的超额风险进行了精确渐近分析。

    

    最近，学习一个任务时使用来自另一个任务的样本的问题引起了广泛关注。本文提出了一个基本问题：什么时候将来自两个任务的数据合并比单独学习一个任务更好？直观上，从一个任务到另一个任务的转移效应取决于数据集的转移，如样本大小和协方差矩阵。然而，量化这种转移效应是具有挑战性的，因为我们需要比较联合学习和单任务学习之间的风险，并且一个任务是否比另一个任务具有比较优势取决于两个任务之间确切的数据集转移类型。本文利用随机矩阵理论在具有两个任务的线性回归设置中解决了这一挑战。我们给出了在高维情况下一些常用估计量的超额风险的精确渐近分析，当样本大小与特征维度成比例增加时，固定比例。精确渐近分析以样本大小的函数形式给出。

    The problem of learning one task with samples from another task has received much interest recently. In this paper, we ask a fundamental question: when is combining data from two tasks better than learning one task alone? Intuitively, the transfer effect from one task to another task depends on dataset shifts such as sample sizes and covariance matrices. However, quantifying such a transfer effect is challenging since we need to compare the risks between joint learning and single-task learning, and the comparative advantage of one over the other depends on the exact kind of dataset shift between both tasks. This paper uses random matrix theory to tackle this challenge in a linear regression setting with two tasks. We give precise asymptotics about the excess risks of some commonly used estimators in the high-dimensional regime, when the sample sizes increase proportionally with the feature dimension at fixed ratios. The precise asymptotics is provided as a function of the sample sizes 
    
[^27]: 一种用于逃逸训练GAN中的极限周期的方法

    A method for escaping limit cycles in training GANs. (arXiv:2010.03322v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.03322](http://arxiv.org/abs/2010.03322)

    本文提出了一种用于逃逸训练GAN中的极限周期的方法，通过预测离心加速度算法（PCAA）和自适应矩估计算法（Adam）相结合，有效改善了训练过程中的极限周期行为问题。

    

    本文通过提出的预测离心加速度算法（PCAA），对训练生成对抗网络（GANs）中极限周期行为问题进行深入研究。具体而言，我们首先推导了PCAA在一般双线性博弈的最后迭代收敛速率的上下界，在上界方面得到了显著改进。然后，我们将PCAA与自适应矩估计算法（Adam）相结合，提出了一种用于训练GANs的实用方法PCAA-Adam。最后，我们通过在双线性博弈、多元高斯分布和CelebA数据集上进行的实验证明了所提出算法的有效性。

    This paper mainly conducts further research to alleviate the issue of limit cycling behavior in training generative adversarial networks (GANs) through the proposed predictive centripetal acceleration algorithm (PCAA). Specifically, we first derive the upper and lower bounds on the last-iterate convergence rates of PCAA for the general bilinear game, with the upper bound notably improving upon previous results. Then, we combine PCAA with the adaptive moment estimation algorithm (Adam) to propose PCAA-Adam, a practical approach for training GANs. Finally, we validate the effectiveness of the proposed algorithm through experiments conducted on bilinear games, multivariate Gaussian distributions, and the CelebA dataset, respectively.
    
[^28]: 具有类人类树突激活的非线性神经元

    Non-linear Neurons with Human-like Apical Dendrite Activations. (arXiv:2003.03229v4 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2003.03229](http://arxiv.org/abs/2003.03229)

    本论文提出了一种新的人工神经元模型和激活函数，通过使用单个神经元学习非线性决策边界，并在多个基准数据集上取得了优于传统方法的结果。

    

    为了对线性不可分的数据进行分类，通常将神经元组织成至少包含一个隐藏层的多层神经网络。受神经科学的一些最新发现的启发，我们提出了一种新的人工神经元模型和一种新颖的激活函数，可使用单个神经元学习非线性决策边界。我们展示了一个标准神经元接上我们的新型树突激活函数（ADA）可以以100%的准确率学习XOR逻辑函数。此外，我们对计算机视觉、信号处理和自然语言处理领域的六个基准数据集进行了实验，即MOROCO、UTKFace、CREMA-D、Fashion-MNIST、Tiny ImageNet和ImageNet，结果显示ADA和漏电ADA函数在各种神经网络结构（如一层或两层隐藏层的多层感知机和卷积神经网络）上优于修正线性单元（ReLU）、漏电ReLU、径向基函数（RBF）和Swish。

    In order to classify linearly non-separable data, neurons are typically organized into multi-layer neural networks that are equipped with at least one hidden layer. Inspired by some recent discoveries in neuroscience, we propose a new model of artificial neuron along with a novel activation function enabling the learning of nonlinear decision boundaries using a single neuron. We show that a standard neuron followed by our novel apical dendrite activation (ADA) can learn the XOR logical function with 100% accuracy. Furthermore, we conduct experiments on six benchmark data sets from computer vision, signal processing and natural language processing, i.e. MOROCO, UTKFace, CREMA-D, Fashion-MNIST, Tiny ImageNet and ImageNet, showing that the ADA and the leaky ADA functions provide superior results to Rectified Linear Units (ReLU), leaky ReLU, RBF and Swish, for various neural network architectures, e.g. one-hidden-layer or two-hidden-layer multi-layer perceptrons (MLPs) and convolutional ne
    
[^29]: B位量化下的非参数推断

    Nonparametric Inference under B-bits Quantization. (arXiv:1901.08571v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/1901.08571](http://arxiv.org/abs/1901.08571)

    本文提出了一种基于B位量化的非参数推断方法，通过一种高效的算法对样本进行量化处理。结果表明，当B超过阈值时，所提出的方法在样条模型中能够达到经典极小极值率的测试水平。另外，本文还拓展了方法的适用性，包括非参数直线性检验和自适应非参数检验。通过广泛的模拟研究和实际数据分析，证明了方法的有效性和效果。

    

    在信号/图像处理、医学图像存储、遥感、信号传输等研究领域中，常常需要基于有损或不完整样本的统计推断。本文提出了一种基于经计算效率高的算法对样本进行B位量化的非参数检验程序。在一些温和技术条件下，我们建立了所提出的检验统计量的渐近性质，并研究了检验功率在B增加时的变化。特别地，我们表明如果B超过某个阈值，则所提出的非参数检验程序在样条模型中实现了经典极小极值率的测试（Shang和Cheng，2015）。我们还进一步将理论研究扩展到了非参数直线性检验和自适应非参数检验，拓展了所提方法的适用性。我们使用广泛的模拟研究和实际数据分析来证明所提方法的有效性和效果。

    Statistical inference based on lossy or incomplete samples is often needed in research areas such as signal/image processing, medical image storage, remote sensing, signal transmission. In this paper, we propose a nonparametric testing procedure based on samples quantized to $B$ bits through a computationally efficient algorithm. Under mild technical conditions, we establish the asymptotic properties of the proposed test statistic and investigate how the testing power changes as $B$ increases. In particular, we show that if $B$ exceeds a certain threshold, the proposed nonparametric testing procedure achieves the classical minimax rate of testing (Shang and Cheng, 2015) for spline models. We further extend our theoretical investigations to a nonparametric linearity test and an adaptive nonparametric test, expanding the applicability of the proposed methods. Extensive simulation studies {together with a real-data analysis} are used to demonstrate the validity and effectiveness of the pr
    

