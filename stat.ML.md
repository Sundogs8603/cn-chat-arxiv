# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs.](http://arxiv.org/abs/2310.20145) | 本文介绍了一种新颖的robust Bayesian Optimization算法，AIRBO，它能够在任意输入不确定性下有效识别出表现一致良好的鲁棒最优解。 |
| [^2] | [Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximation.](http://arxiv.org/abs/2310.18919) | 本研究解决了强化学习中延迟反馈对线性函数逼近的挑战，通过后验采样算法实现了在不同情况下的优越性能。 |
| [^3] | [On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers.](http://arxiv.org/abs/2310.14421) | 本文研究了针对AI分类器的对抗鲁棒性度量的存在性、唯一性和可扩展性，提出了可以验证的数学条件，并在合成基准测试和生物医学应用中进行了实际计算和解释。 |
| [^4] | [Almost Equivariance via Lie Algebra Convolutions.](http://arxiv.org/abs/2310.13164) | 本文研究了几乎等变性的主题，并提供了一个不同于现有定义的几乎等变性定义，并通过利用李群的李代数给出了在模型中编码几乎等变性的实用方法。 |
| [^5] | [Sampling via Gradient Flows in the Space of Probability Measures.](http://arxiv.org/abs/2310.03597) | 通过梯度流抽样方法的研究方向在计算科学和工程中具有重要意义。本文通过研究概率测度空间中的梯度流的设计组成部分，提出了三个贡献：Kullback-Leibler散度作为能量泛函的独特属性、度量的选择与不变性的关系。 |
| [^6] | [Uncertainty Quantification via Neural Posterior Principal Components.](http://arxiv.org/abs/2309.15533) | 本论文提出了一种使用神经网络在单次前向传递中预测任意输入图像后验分布的主成分的方法，以实现不确定性量化。 |
| [^7] | [PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA LUT-based Inference.](http://arxiv.org/abs/2309.02334) | 提出了一种名为PolyLUT的新方法，用于训练神经网络在FPGA上进行部署。该方法利用多变量多项式作为基本模块，并利用软逻辑将多项式评估隐藏在FPGA的查找表中，从而实现超低延迟推理，并减少了软件逻辑的层数。 |
| [^8] | [Low Tensor Rank Learning of Neural Dynamics.](http://arxiv.org/abs/2308.11567) | 研究发现通过学习过程中的张量秩演化来理解神经元连接在学习中的协调变化。研究表明训练过的递归神经网络的权重矩阵通常具有低秩结构，而这种结构在整个学习过程中保持在一个固定的低维子空间中。对真实权重进行低秩分解验证了这一观察结果。 |
| [^9] | [Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language.](http://arxiv.org/abs/2308.05061) | 本文提出了一种使用传感器数据、方程和自然语言提示上下文中运算符学习的方法。通过整合人类知识和语言描述，该方法不仅扩展了物理信息学习的灵活性和普适性，而且显著提高了学习性能和减少了数据需求。 |
| [^10] | [Online covariance estimation for stochastic gradient descent under Markovian sampling.](http://arxiv.org/abs/2308.01481) | 本文研究了在马尔可夫采样下的随机梯度下降中的在线重叠批次均值协方差估计器，并证明了其收敛速率为$O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$和$O\big(\sqrt{d}\,n^{-1/8}\big)$，分别对应于状态相关和状态无关的马尔可夫采样。这些速率与独立同分布情况下的最佳收敛速率相匹配，并且克服了由于马尔可夫采样而引起的挑战。 |
| [^11] | [A Theory for Emergence of Complex Skills in Language Models.](http://arxiv.org/abs/2307.15936) | 本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。 |
| [^12] | [Adaptive Linear Estimating Equations.](http://arxiv.org/abs/2307.07320) | 本文提出了一种解决自适应线性回归模型中非正态渐近行为的方法，使用自适应线性估计方程构建去偏估计量，并在多臂老虎机的背景下保持了最小二乘估计量的非渐近性能。 |
| [^13] | [Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges.](http://arxiv.org/abs/2307.01050) | 本文研究了最优运输和变分推断之间的联系，并提出了一种基于路径空间散度的采样和生成建模框架。通过开发新颖的基于得分的回火流技术和正则化的迭代比例拟合目标，本文展示了这些方法的潜力。 |
| [^14] | [Is RLHF More Difficult than Standard RL?.](http://arxiv.org/abs/2306.14111) | 本文证明了对于广泛的偏好模型，我们可以使用现有的算法和技术直接解决基于偏好的RL问题，而几乎不需要额外的成本。 |
| [^15] | [Practical Equivariances via Relational Conditional Neural Processes.](http://arxiv.org/abs/2306.10915) | 本文提出的关系条件神经过程（RCNPs）是一种有效将等变性纳入任何神经过程模型的方法，并扩展了等变神经过程的适用性和影响力到更高的维度。 |
| [^16] | [For SALE: State-Action Representation Learning for Deep Reinforcement Learning.](http://arxiv.org/abs/2306.02451) | SALE是一种基于状态-动作表示学习的新方法，可以有效地从低级状态中实现表示学习，TD7算法引入了该方法并在连续控制任务中表现优异。 |
| [^17] | [DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model.](http://arxiv.org/abs/2306.01001) | 本文提出了一种扩散模型中的负荷预测不确定性量化方法，采用Seq2Seq网络结构来分离两种类型的不确定性并处理异常情况，不仅着眼于预测条件期望值。 |
| [^18] | [Exact Generalization Guarantees for (Regularized) Wasserstein Distributionally Robust Models.](http://arxiv.org/abs/2305.17076) | 本文表明Wasserstein分布式强鲁棒估计器的泛化保证适用于一般模型类别，不受维数灾难所困扰，甚至可以涵盖测试时的分布变化。 |
| [^19] | [Differentiable Clustering with Perturbed Spanning Forests.](http://arxiv.org/abs/2305.16358) | 介绍了一种基于扰动生成树的可微聚类方法，依赖于线性规划解的随机扰动，具有良好的性能。 |
| [^20] | [An $\varepsilon$-Best-Arm Identification Algorithm for Fixed-Confidence and Beyond.](http://arxiv.org/abs/2305.16041) | 提出一种新颖的采样规则EB-TC $\varepsilon$，用于随机赌博机中的$\varepsilon$-最佳臂的辨识。该规则可用于确定固定置信度或固定预算标识且具备自适应调整勘探参数的渐近最优性。在仿真实验中表现良好，适用于不同问题领域。 |
| [^21] | [Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective.](http://arxiv.org/abs/2305.15408) | 本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。 |
| [^22] | [Data-Dependent Bounds for Online Portfolio Selection Without Lipschitzness and Smoothness.](http://arxiv.org/abs/2305.13946) | 本文提出了在线投资组合选择的第一个数据相关上界，算法显示亚线性遗憾率，并在数据“容易”时实现对数遗憾。 |
| [^23] | [Deep Learning with Kernels through RKHM and the Perron-Frobenius Operator.](http://arxiv.org/abs/2305.13588) | 该论文提出了一种基于核方法的深度学习框架：深度RKHM，通过使用$C^*$代数获得更温和的界限，并提供了良性过拟合的理论解释。 |
| [^24] | [Moment Matching Denoising Gibbs Sampling.](http://arxiv.org/abs/2305.11650) | 本文提出了动量匹配去噪Gibbs采样方法，可以在给定‘嘈杂’的模型的情况下，从干净的模型中有效地进行采样。 |
| [^25] | [Bridging RL Theory and Practice with the Effective Horizon.](http://arxiv.org/abs/2304.09853) | 本论文通过对常见深度强化学习测试基准中155个MDP的数据集进行分析，发现当最高Q值的动作在随机策略下Q值最高时，深度强化学习往往会成功；反之，则失败的可能性较高。 |
| [^26] | [Flooding with Absorption: An Efficient Protocol for Heterogeneous Bandits over Complex Networks.](http://arxiv.org/abs/2303.05445) | 该论文提出了一种名为带吸收的泛洪（FwA）的新协议，用于解决复杂网络上的异构赌博机问题。通过严格的遗憾分析，证明了该协议的有效性。 |
| [^27] | [Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation.](http://arxiv.org/abs/2303.04772) | 本文介绍了无限维度得分扩散模型在多个分辨率水平上的离散化方法，并使用多级扩散算法在多个分辨率上高效地学习。实证表明，该模型在相同或更高分辨率下产生比传统基于得分的扩散模型更高质量的样本，并可以生成不同分辨率的图像并处理矩形域。 |
| [^28] | [Data pruning and neural scaling laws: fundamental limitations of score-based algorithms.](http://arxiv.org/abs/2302.06960) | 评分数据修剪算法在高压缩区域失败，通过随机化的校准协议可以提高现有修剪算法在该区域的性能。 |
| [^29] | [A unified recipe for deriving (time-uniform) PAC-Bayes bounds.](http://arxiv.org/abs/2302.03421) | 该论文提出了一种用于推导PAC-Bayesian泛化界限的统一框架，不同于传统的固定样本大小方式，该框架适用于所有停止时间。同时，该论文还提出了新的边界方法，也可以应用于非平稳损失函数和非独立同分布的数据。 |
| [^30] | [The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing.](http://arxiv.org/abs/2302.01186) | 该研究提出了ScaledGD(𝜆)方法，相较于传统梯度下降法更加鲁棒，并且在处理低秩矩阵感知问题时具有很好的表现。 |
| [^31] | [Are you using test log-likelihood correctly?.](http://arxiv.org/abs/2212.00219) | 使用测试对数似然进行比较可能与其他指标相矛盾，并且高测试对数似然不意味着更准确的后验近似。 |
| [^32] | [Statistical inference for transfer learning with high-dimensional quantile regression.](http://arxiv.org/abs/2211.14578) | 本研究提出了一种高维分位数回归模型中的转移学习方法，以适应源域和目标域中的异质性和重尾分布。根据精心选择的可转移源域建立了转移学习估计量的误差界限，并提出了有效的置信区间和假设检验程序，以实现一步完成。 |
| [^33] | [Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees.](http://arxiv.org/abs/2210.07893) | 本文针对高斯过程模型的数值稳定性进行了研究，通过感兴趣点的选择和计算，提供了稳定可靠的稀疏逼近方法。 |
| [^34] | [Detecting hidden confounding in observational data using multiple environments.](http://arxiv.org/abs/2205.13935) | 使用独立数据生成过程下的多环境方法，可以检测观测数据中的未观察到的混淆因素，并提出了测试独立性的程序。 |
| [^35] | [Transfer-Learning Across Datasets with Different Input Dimensions: An Algorithm and Analysis for the Linear Regression Case.](http://arxiv.org/abs/2202.05069) | 本文提出了一种适用于线性回归情况的迁移学习算法，该算法能够将新数据与历史数据相结合，特别在新数据稀缺的情况下具有益处，并且在实验验证中表现出对负迁移学习的鲁棒性。 |
| [^36] | [Interpretable Sequence Classification Via Prototype Trajectory.](http://arxiv.org/abs/2007.01777) | ProtoryNet是一种基于原型轨迹的可解释深度神经网络，它通过捕捉时间模式和原型的近似程度来进行文本分类，并实现了直观和细致的推理过程解释。 |

# 详细

[^1]: 高效robust Bayesian Optimization对于任意不确定输入的应用

    Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs. (arXiv:2310.20145v1 [cs.LG])

    [http://arxiv.org/abs/2310.20145](http://arxiv.org/abs/2310.20145)

    本文介绍了一种新颖的robust Bayesian Optimization算法，AIRBO，它能够在任意输入不确定性下有效识别出表现一致良好的鲁棒最优解。

    

    Bayesian Optimization (BO) 是一种广泛应用于各种应用中的高效优化算法。在一些具有挑战性的BO任务中，由于优化过程中的不可避免的随机性，如加工误差、执行噪声或上下文变异，输入不确定性会出现。这种不确定性会使输入在评估之前偏离预期值，导致最终结果的性能波动较大。在本文中，我们引入了一种新颖的robust Bayesian Optimization算法，AIRBO，它能有效地识别在任意输入不确定性下表现一致良好的鲁棒最优解。我们的方法通过使用最大均值差(MMD)赋能高斯过程，直接建模任意分布的不确定输入，并通过Nystrom逼近加速后验推断。我们在MMD估计误差下建立了严格的理论遗憾界，并在合成函数上进行了广泛的实验。

    Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in the final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic function
    
[^2]: 延迟反馈的线性函数逼近强化学习中的后验采样

    Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximation. (arXiv:2310.18919v1 [cs.LG])

    [http://arxiv.org/abs/2310.18919](http://arxiv.org/abs/2310.18919)

    本研究解决了强化学习中延迟反馈对线性函数逼近的挑战，通过后验采样算法实现了在不同情况下的优越性能。

    

    运用函数逼近在强化学习中取得了显著进展，但现有的高效算法通常依赖于即时反馈。本文通过采用后验采样来解决延迟反馈对强化学习中线性函数逼近的挑战，首先介绍了Delayed-PSVI算法，通过后验采样中的噪声扰动有效地探索价值函数空间。我们提供了延迟反馈强化学习中后验采样算法的首次分析，并展示了我们的算法在一系列情况下的优越性。

    Recent studies in reinforcement learning (RL) have made significant progress by leveraging function approximation to alleviate the sample complexity hurdle for better performance. Despite the success, existing provably efficient algorithms typically rely on the accessibility of immediate feedback upon taking actions. The failure to account for the impact of delay in observations can significantly degrade the performance of real-world systems due to the regret blow-up. In this work, we tackle the challenge of delayed feedback in RL with linear function approximation by employing posterior sampling, which has been shown to empirically outperform the popular UCB algorithms in a wide range of regimes. We first introduce Delayed-PSVI, an optimistic value-based algorithm that effectively explores the value function space via noise perturbation with posterior sampling. We provide the first analysis for posterior sampling algorithms with delayed feedback in RL and show our algorithm achieves $
    
[^3]: 对AI分类器的对抗鲁棒性度量的存在性，唯一性和可扩展性研究

    On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers. (arXiv:2310.14421v1 [stat.ML])

    [http://arxiv.org/abs/2310.14421](http://arxiv.org/abs/2310.14421)

    本文研究了针对AI分类器的对抗鲁棒性度量的存在性、唯一性和可扩展性，提出了可以验证的数学条件，并在合成基准测试和生物医学应用中进行了实际计算和解释。

    

    本文提出并证明了针对（局部）唯一可逆分类器、广义线性模型（GLM）和熵AI（EAI）具有最小对抗路径（MAP）和最小对抗距离（MAD）的存在性、唯一性和明确的分析计算的简单可验证的数学条件。在常见的合成基准测试数据集上，针对神经网络、提升随机森林、GLM和EAI等各类AI工具进行MAP和MAD的实际计算、比较和解释，包括双卷状螺旋线及其扩展以及两个生物医学数据问题（用于健康保险理赔预测和心脏病发作致死率分类）。在生物医学应用中，展示了MAP如何在预定义的可访问控制变量子集中提供唯一的最小患者特定风险缓解干预措施。

    Simply-verifiable mathematical conditions for existence, uniqueness and explicit analytical computation of minimal adversarial paths (MAP) and minimal adversarial distances (MAD) for (locally) uniquely-invertible classifiers, for generalized linear models (GLM), and for entropic AI (EAI) are formulated and proven. Practical computation of MAP and MAD, their comparison and interpretations for various classes of AI tools (for neuronal networks, boosted random forests, GLM and EAI) are demonstrated on the common synthetic benchmarks: on a double Swiss roll spiral and its extensions, as well as on the two biomedical data problems (for the health insurance claim predictions, and for the heart attack lethality classification). On biomedical applications it is demonstrated how MAP provides unique minimal patient-specific risk-mitigating interventions in the predefined subsets of accessible control variables.
    
[^4]: 几乎等变性通过李代数卷积

    Almost Equivariance via Lie Algebra Convolutions. (arXiv:2310.13164v1 [cs.LG])

    [http://arxiv.org/abs/2310.13164](http://arxiv.org/abs/2310.13164)

    本文研究了几乎等变性的主题，并提供了一个不同于现有定义的几乎等变性定义，并通过利用李群的李代数给出了在模型中编码几乎等变性的实用方法。

    

    最近，在机器学习中，模型相对于群作用的等变性已成为一个重要的研究课题。然而，赋予一个架构具体的群等变性对模型所期望看到的数据变换类型施加了强大的先验。严格等变模型强制执行对称性，但真实世界的数据并不总是符合这样的严格等变性，可能是因为数据中的噪声或仅编码了近似或部分对称性的潜在物理定律。在这种情况下，严格等变性的先验实际上可能过于强大，导致模型在真实数据上表现不佳。因此，在这项工作中，我们研究了一个相关的主题，即几乎等变性。我们提供了一个与当前文献中现有定义不同的几乎等变性定义，并通过利用李群的李代数给出了在模型中编码几乎等变性的实用方法。

    Recently, the equivariance of models with respect to a group action has become an important topic of research in machine learning. However, imbuing an architecture with a specific group equivariance imposes a strong prior on the types of data transformations that the model expects to see. While strictly-equivariant models enforce symmetries, real-world data does not always conform to such strict equivariances, be it due to noise in the data or underlying physical laws that encode only approximate or partial symmetries. In such cases, the prior of strict equivariance can actually prove too strong and cause models to underperform on real-world data. Therefore, in this work we study a closely related topic, that of almost equivariance. We provide a definition of almost equivariance that differs from those extant in the current literature and give a practical method for encoding almost equivariance in models by appealing to the Lie algebra of a Lie group. Specifically, we define Lie algebr
    
[^5]: 在概率测度空间中通过梯度流进行抽样

    Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])

    [http://arxiv.org/abs/2310.03597](http://arxiv.org/abs/2310.03597)

    通过梯度流抽样方法的研究方向在计算科学和工程中具有重要意义。本文通过研究概率测度空间中的梯度流的设计组成部分，提出了三个贡献：Kullback-Leibler散度作为能量泛函的独特属性、度量的选择与不变性的关系。

    

    在计算科学和工程中，使用未知归一化常数的目标概率分布进行抽样是一项基本的挑战。最近的研究表明，通过考虑概率测度空间中的梯度流派生的算法为算法开发开辟了新的途径。本文通过审查这种梯度流的设计组成部分，对这种抽样方法做出了三个贡献。抽样的任何实例化都需要一个能量泛函和一个度量来确定流动，以及流动的数值近似来推导算法。我们的第一个贡献是展示了Kullback-Leibler散度作为一个能量泛函具有唯一的特征（在所有f-散度中），即由其得到的梯度流不依赖于目标分布的归一化常数。我们的第二个贡献是从不变性的角度研究度量的选择。Fisher-Rao度量被称为t

    Sampling a target probability distribution with an unknown normalization constant is a fundamental challenge in computational science and engineering. Recent work shows that algorithms derived by considering gradient flows in the space of probability measures open up new avenues for algorithm development. This paper makes three contributions to this sampling approach by scrutinizing the design components of such gradient flows. Any instantiation of a gradient flow for sampling needs an energy functional and a metric to determine the flow, as well as numerical approximations of the flow to derive algorithms. Our first contribution is to show that the Kullback-Leibler divergence, as an energy functional, has the unique property (among all f-divergences) that gradient flows resulting from it do not depend on the normalization constant of the target distribution. Our second contribution is to study the choice of metric from the perspective of invariance. The Fisher-Rao metric is known as t
    
[^6]: 通过神经后验主成分进行不确定性量化

    Uncertainty Quantification via Neural Posterior Principal Components. (arXiv:2309.15533v1 [cs.CV])

    [http://arxiv.org/abs/2309.15533](http://arxiv.org/abs/2309.15533)

    本论文提出了一种使用神经网络在单次前向传递中预测任意输入图像后验分布的主成分的方法，以实现不确定性量化。

    

    不确定性量化对于在自动驾驶和生物成像等安全关键领域中部署图像恢复模型至关重要。迄今为止，关于不确定性可视化的方法主要集中在每像素估计上。然而，每像素方差的热图通常在实际中用途有限，因为它无法捕捉像素之间的强相关性。更自然的不确定性度量对应于后验分布的主成分（PCs）上的方差。理论上，可以通过对输入图像的条件生成模型生成的样本应用PCA来计算PCs。然而，这需要在测试时生成大量的样本，而在目前的最先进（扩散）模型下非常缓慢。在该工作中，我们提出了一种方法来在神经网络的单次前向传递中预测后验分布的PCs，适用于任意输入图像。

    Uncertainty quantification is crucial for the deployment of image restoration models in safety-critical domains, like autonomous driving and biological imaging. To date, methods for uncertainty visualization have mainly focused on per-pixel estimates. However, a heatmap of per-pixel variances is typically of little practical use, as it does not capture the strong correlations between pixels. A more natural measure of uncertainty corresponds to the variances along the principal components (PCs) of the posterior distribution. Theoretically, the PCs can be computed by applying PCA on samples generated from a conditional generative model for the input image. However, this requires generating a very large number of samples at test time, which is painfully slow with the current state-of-the-art (diffusion) models. In this work, we present a method for predicting the PCs of the posterior distribution for any input image, in a single forward pass of a neural network. Our method can either wrap
    
[^7]: PolyLUT: 用于超低延迟FPGA基于查找表推理的分段多项式学习

    PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA LUT-based Inference. (arXiv:2309.02334v1 [cs.LG])

    [http://arxiv.org/abs/2309.02334](http://arxiv.org/abs/2309.02334)

    提出了一种名为PolyLUT的新方法，用于训练神经网络在FPGA上进行部署。该方法利用多变量多项式作为基本模块，并利用软逻辑将多项式评估隐藏在FPGA的查找表中，从而实现超低延迟推理，并减少了软件逻辑的层数。

    

    可编程门阵列（FPGA）被广泛用于实现深度学习推理。标准的深度神经网络推理涉及交错线性映射和非线性激活函数的计算。以往的超低延迟实现工作在FPGA查找表（LUT）中硬编码了线性映射和非线性激活的组合。我们的工作受到这个想法的启发，即FPGA中的LUT可以用来实现比这更多样化的函数。在本文中，我们提出了一种新的方法来训练用于FPGA部署的神经网络，以多变量多项式作为基本模块。我们的方法利用软件逻辑提供的灵活性，将多项式评估隐藏在LUT中且没有任何开销。我们表明，通过使用多项式模块，我们可以实现相同的准确度，而使用的软件逻辑层数要比使用线性函数要少得多，从而带来显著的延迟和面积的减少。

    Field-programmable gate arrays (FPGAs) are widely used to implement deep learning inference. Standard deep neural network inference involves the computation of interleaved linear maps and nonlinear activation functions. Prior work for ultra-low latency implementations has hardcoded the combination of linear maps and nonlinear activations inside FPGA lookup tables (LUTs). Our work is motivated by the idea that the LUTs in an FPGA can be used to implement a much greater variety of functions than this. In this paper, we propose a novel approach to training neural networks for FPGA deployment using multivariate polynomials as the basic building block. Our method takes advantage of the flexibility offered by the soft logic, hiding the polynomial evaluation inside the LUTs with zero overhead. We show that by using polynomial building blocks, we can achieve the same accuracy using considerably fewer layers of soft logic than by using linear functions, leading to significant latency and area i
    
[^8]: 神经动力学的低阶张量秩学习

    Low Tensor Rank Learning of Neural Dynamics. (arXiv:2308.11567v1 [q-bio.NC])

    [http://arxiv.org/abs/2308.11567](http://arxiv.org/abs/2308.11567)

    研究发现通过学习过程中的张量秩演化来理解神经元连接在学习中的协调变化。研究表明训练过的递归神经网络的权重矩阵通常具有低秩结构，而这种结构在整个学习过程中保持在一个固定的低维子空间中。对真实权重进行低秩分解验证了这一观察结果。

    

    学习依赖于神经元群体中的协调突触变化。因此，了解学习过程中突触连接的集体演化是神经科学和机器学习中的一个关键挑战。近期的研究表明，经过训练的递归神经网络（RNN）的权重矩阵通常是低秩的，但是这种低秩结构如何在学习过程中展开还不清楚。为了解决这个问题，我们研究了整个学习过程中由权重矩阵形成的3阶张量的秩。通过用不同秩的RNN拟合大规模神经记录的运动学习任务，我们发现推断的权重是低阶张量秩的，因此在整个学习过程中在一个固定的低维子空间中演化。接下来，我们通过在真实权重上直接进行低阶张量秩分解，并展示我们所使用的方法，验证了低阶张量秩学习的观察结论。

    Learning relies on coordinated synaptic changes in recurrently connected populations of neurons. Therefore, understanding the collective evolution of synaptic connectivity over learning is a key challenge in neuroscience and machine learning. In particular, recent work has shown that the weight matrices of task-trained RNNs are typically low rank, but how this low rank structure unfolds over learning is unknown. To address this, we investigate the rank of the 3-tensor formed by the weight matrices throughout learning. By fitting RNNs of varying rank to large-scale neural recordings during a motor learning task, we find that the inferred weights are low-tensor-rank and therefore evolve over a fixed low-dimensional subspace throughout the entire course of learning. We next validate the observation of low-tensor-rank learning on an RNN trained to solve the same task by performing a low-tensor-rank decomposition directly on the ground truth weights, and by showing that the method we applie
    
[^9]: 使用传感器数据、方程和自然语言提示上下文中的运算符学习

    Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language. (arXiv:2308.05061v1 [cs.LG])

    [http://arxiv.org/abs/2308.05061](http://arxiv.org/abs/2308.05061)

    本文提出了一种使用传感器数据、方程和自然语言提示上下文中运算符学习的方法。通过整合人类知识和语言描述，该方法不仅扩展了物理信息学习的灵活性和普适性，而且显著提高了学习性能和减少了数据需求。

    

    在科学机器学习领域中，上下文中的运算符学习已经展示出了在推理阶段从提示数据中学习运算符的显著潜力，而无需进行权重更新。然而，当前模型对传感器数据的过度依赖可能会无意中忽视运算符的宝贵的人类洞察力。为了解决这个问题，我们将上下文中的运算符学习转化为一种多模式范式。我们提出使用“标题”来整合通过自然语言描述和方程式表达的运算符的人类知识。我们演示了这种方法不仅扩展了物理信息学习的灵活性和普遍性，而且还显著提高了学习性能并减少了数据需求。此外，我们引入了一种更高效的多模式上下文运算符学习的神经网络架构，称为“ICON-LM”，基于类似于语言模型的架构。

    In the growing domain of scientific machine learning, in-context operator learning has demonstrated notable potential in learning operators from prompted data during inference stage without weight updates. However, the current model's overdependence on sensor data, may inadvertently overlook the invaluable human insight into the operator. To address this, we present a transformation of in-context operator learning into a multi-modal paradigm. We propose the use of "captions" to integrate human knowledge about the operator, expressed through natural language descriptions and equations. We illustrate how this method not only broadens the flexibility and generality of physics-informed learning, but also significantly boosts learning performance and reduces data needs. Furthermore, we introduce a more efficient neural network architecture for multi-modal in-context operator learning, referred to as "ICON-LM", based on a language-model-like architecture. We demonstrate the viability of "ICO
    
[^10]: 在马尔可夫采样下，用于随机梯度下降的在线协方差估计

    Online covariance estimation for stochastic gradient descent under Markovian sampling. (arXiv:2308.01481v1 [math.ST])

    [http://arxiv.org/abs/2308.01481](http://arxiv.org/abs/2308.01481)

    本文研究了在马尔可夫采样下的随机梯度下降中的在线重叠批次均值协方差估计器，并证明了其收敛速率为$O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$和$O\big(\sqrt{d}\,n^{-1/8}\big)$，分别对应于状态相关和状态无关的马尔可夫采样。这些速率与独立同分布情况下的最佳收敛速率相匹配，并且克服了由于马尔可夫采样而引起的挑战。

    

    我们研究了用于马尔可夫采样下随机梯度下降的在线重叠批次均值协方差估计器。我们证明了协方差估计器的收敛速率分别为$O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$和$O\big(\sqrt{d}\,n^{-1/8}\big)$，其中$d$代表维度，$n$表示观测数量或SGD迭代次数。值得注意的是，这些速率与先前由\cite{zhu2021online}在独立同分布($\iid$)情况下建立的最佳收敛速率相匹配，除了对数因子。我们的分析克服了由于马尔可夫采样而产生的重要挑战，引入了额外的误差项和批次均值协方差估计器的复杂依赖关系。此外，我们还建立了SGD动态误差$\ell_2$范数的前四阶矩的收敛速率。

    We study the online overlapping batch-means covariance estimator for Stochastic Gradient Descent (SGD) under Markovian sampling. We show that the convergence rates of the covariance estimator are $O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$ and $O\big(\sqrt{d}\,n^{-1/8}\big)$ under state-dependent and state-independent Markovian sampling, respectively, with $d$ representing dimensionality and $n$ denoting the number of observations or SGD iterations. Remarkably, these rates match the best-known convergence rate previously established for the independent and identically distributed ($\iid$) case by \cite{zhu2021online}, up to logarithmic factors. Our analysis overcomes significant challenges that arise due to Markovian sampling, leading to the introduction of additional error terms and complex dependencies between the blocks of the batch-means covariance estimator. Moreover, we establish the convergence rate for the first four moments of the $\ell_2$ norm of the error of SGD dynamics u
    
[^11]: 语言模型中复杂技能产生的理论

    A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v1 [cs.LG])

    [http://arxiv.org/abs/2307.15936](http://arxiv.org/abs/2307.15936)

    本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。

    

    当语言模型的参数集合和训练语料库扩大时，新的技能将在 AI 产品中出现的主要驱动因素。这种现象尚不为人所理解，并且通过对基于梯度训练的数学分析提供机械解释似乎很困难。本文采用不同的方法，使用著名的（和经验性的）LLM扩展定律和简单的统计框架来分析出现。贡献包括：（a）一个统计框架将LLM的交叉熵损失与语言任务基本技能的能力相关联。（b）数学分析表明，扩展定律意味着强烈的归纳偏见，使预训练模型能够学习得非常高效。我们非正式地称之为“弹弓泛化”，因为表面上看，它似乎提供了在技能水平上违反通常泛化理论的能力。（c）弹弓泛化的一个关键例子，即在执行任务时的能力。

    A major driver of AI products today is the fact that new skills emerge in language models when their parameter set and training corpora are scaled up. This phenomenon is poorly understood, and a mechanistic explanation via mathematical analysis of gradient-based training seems difficult. The current paper takes a different approach, analysing emergence using the famous (and empirical) Scaling Laws of LLMs and a simple statistical framework. Contributions include: (a) A statistical framework that relates cross-entropy loss of LLMs to competence on the basic skills that underlie language tasks. (b) Mathematical analysis showing that the Scaling Laws imply a strong form of inductive bias that allows the pre-trained model to learn very efficiently. We informally call this {\em slingshot generalization} since naively viewed it appears to give competence levels at skills that violate usual generalization theory. (c) A key example of slingshot generalization, that competence at executing task
    
[^12]: 自适应线性估计方程

    Adaptive Linear Estimating Equations. (arXiv:2307.07320v1 [math.ST])

    [http://arxiv.org/abs/2307.07320](http://arxiv.org/abs/2307.07320)

    本文提出了一种解决自适应线性回归模型中非正态渐近行为的方法，使用自适应线性估计方程构建去偏估计量，并在多臂老虎机的背景下保持了最小二乘估计量的非渐近性能。

    

    顺序数据收集已成为增强数据收集过程效率的广泛采用的技术。尽管具有优势，但这种数据收集机制常常给统计推断过程引入复杂性。例如，在自适应线性回归模型中，普通最小二乘（OLS）估计量可能表现出非正态的渐近行为，从而对准确的推断和解释提出挑战。本文提出了一种构建去偏估计量的通用方法，该方法采用自适应线性估计方程的思想，并在理论上保证了渐近正态性，并讨论了实现近似最优渐近方差的问题。我们的估计量的一个显著特点是，在多臂老虎机的背景下，我们的估计量保留了最小二乘估计量的非渐近性能，同时获得了渐近正态性。因此，本工作解决了自适应线性回归模型中非正态渐近行为的问题，并为统计推断提供了可靠的方法。

    Sequential data collection has emerged as a widely adopted technique for enhancing the efficiency of data gathering processes. Despite its advantages, such data collection mechanism often introduces complexities to the statistical inference procedure. For instance, the ordinary least squares (OLS) estimator in an adaptive linear regression model can exhibit non-normal asymptotic behavior, posing challenges for accurate inference and interpretation. In this paper, we propose a general method for constructing debiased estimator which remedies this issue. It makes use of the idea of adaptive linear estimating equations, and we establish theoretical guarantees of asymptotic normality, supplemented by discussions on achieving near-optimal asymptotic variance. A salient feature of our estimator is that in the context of multi-armed bandits, our estimator retains the non-asymptotic performance of the least square estimator while obtaining asymptotic normality property. Consequently, this work
    
[^13]: 运输、变分推断和扩散：应用于回火流和薛定谔桥的论文研究

    Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges. (arXiv:2307.01050v1 [stat.ML])

    [http://arxiv.org/abs/2307.01050](http://arxiv.org/abs/2307.01050)

    本文研究了最优运输和变分推断之间的联系，并提出了一种基于路径空间散度的采样和生成建模框架。通过开发新颖的基于得分的回火流技术和正则化的迭代比例拟合目标，本文展示了这些方法的潜力。

    

    本文探讨了最优运输与变分推断之间的联系，重点研究了正向和反向随机微分方程以及Girsanov变换。我们提出了一个基于路径空间散度的采样和生成建模的原则性和系统性框架。我们的工作最终发展出一个新颖的基于得分的回火流技术（与统计物理中的Jarzynski和Crooks恒等式有关）和一个正则化的迭代比例拟合（IPF）型目标，不同于标准IPF的顺序性。通过一系列的生成建模示例和基于双井的稀有事件任务，我们展示了所提方法的潜力。

    This paper explores the connections between optimal transport and variational inference, with a focus on forward and reverse time stochastic differential equations and Girsanov transformations.We present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of a novel score-based annealed flow technique (with connections to Jarzynski and Crooks identities from statistical physics) and a regularised iterative proportional fitting (IPF)-type objective, departing from the sequential nature of standard IPF. Through a series of generative modelling examples and a double-well-based rare event task, we showcase the potential of the proposed methods.
    
[^14]: RLHF是否比标准RL更困难？

    Is RLHF More Difficult than Standard RL?. (arXiv:2306.14111v1 [cs.LG])

    [http://arxiv.org/abs/2306.14111](http://arxiv.org/abs/2306.14111)

    本文证明了对于广泛的偏好模型，我们可以使用现有的算法和技术直接解决基于偏好的RL问题，而几乎不需要额外的成本。

    

    从人类反馈学习的强化学习（RLHF）是从偏好信号学习，而标准强化学习（RL）则直接从奖励信号学习。偏好信号可能包含的信息比奖励信号少，这使得基于偏好的RL似乎更加困难。本文理论上证明，对于广泛的偏好模型，我们可以使用现有的算法和技术直接解决基于偏好的RL问题，而几乎不需要额外的成本。具体而言，我们将问题分为两类：（1）基于奖励概率模型的偏好，此时可以将问题简化为容忍奖励小误差的鲁棒奖励RL问题；（2）对于一般的任意偏好且目标是找到von Neumann获胜者的情况，我们将问题简化为多智能体奖励RL问题，该问题可以在一组受限制的策略下找到马尔可夫博弈的因子纳什平衡解。后一种情况可以进一步降低成对关系的MDP。

    Reinforcement learning from Human Feedback (RLHF) learns from preference signals, while standard Reinforcement Learning (RL) directly learns from reward signals. Preferences arguably contain less information than rewards, which makes preference-based RL seemingly more difficult. This paper theoretically proves that, for a wide range of preference models, we can solve preference-based RL directly using existing algorithms and techniques for reward-based RL, with small or no extra costs. Specifically, (1) for preferences that are drawn from reward-based probabilistic models, we reduce the problem to robust reward-based RL that can tolerate small errors in rewards; (2) for general arbitrary preferences where the objective is to find the von Neumann winner, we reduce the problem to multiagent reward-based RL which finds Nash equilibria for factored Markov games under a restricted set of policies. The latter case can be further reduce to adversarial MDP when preferences only depend on the f
    
[^15]: 通过关系条件神经过程实现实用的等变性

    Practical Equivariances via Relational Conditional Neural Processes. (arXiv:2306.10915v1 [stat.ML])

    [http://arxiv.org/abs/2306.10915](http://arxiv.org/abs/2306.10915)

    本文提出的关系条件神经过程（RCNPs）是一种有效将等变性纳入任何神经过程模型的方法，并扩展了等变神经过程的适用性和影响力到更高的维度。

    

    条件神经过程（CNPs）是一类元学习模型，以其综合运行时效率和可靠的不确定性量化而受欢迎。许多相关的机器学习任务，例如时空建模、贝叶斯优化和连续控制，包含等变性，例如对于平移，模型可以利用最大的性能。然而，先前试图在CNPs中包含等变性在超过两个输入维度之外的尺度上无法有效扩展。在本文中，我们提出了关系条件神经过程（RCNPs），这是一种有效将等变性纳入任何神经过程模型的方法。我们提出的方法扩展了等变神经过程的适用性和影响力到更高的维度。我们在自然包含等变性任务的大量任务上经验证实了RCNPs的竞争性能。

    Conditional Neural Processes (CNPs) are a class of metalearning models popular for combining the runtime efficiency of amortized inference with reliable uncertainty quantification. Many relevant machine learning tasks, such as spatio-temporal modeling, Bayesian Optimization and continuous control, contain equivariances -- for example to translation -- which the model can exploit for maximal performance. However, prior attempts to include equivariances in CNPs do not scale effectively beyond two input dimensions. In this work, we propose Relational Conditional Neural Processes (RCNPs), an effective approach to incorporate equivariances into any neural process model. Our proposed method extends the applicability and impact of equivariant neural processes to higher dimensions. We empirically demonstrate the competitive performance of RCNPs on a large array of tasks naturally containing equivariances.
    
[^16]: 待售：基于状态-动作表示学习的深度强化学习

    For SALE: State-Action Representation Learning for Deep Reinforcement Learning. (arXiv:2306.02451v1 [cs.LG])

    [http://arxiv.org/abs/2306.02451](http://arxiv.org/abs/2306.02451)

    SALE是一种基于状态-动作表示学习的新方法，可以有效地从低级状态中实现表示学习，TD7算法引入了该方法并在连续控制任务中表现优异。

    

    在强化学习领域中，表示学习是处理复杂基于图像任务的有效工具，但通常被忽略了低级状态（例如物理控制问题）的环境。本文介绍了一种名为SALE的新方法，它可以学习嵌入来建模状态和动作之间微妙的相互作用，从低级状态中实现有效的表示学习。我们广泛研究了这些嵌入的设计空间，并强调了重要的设计考虑因素。我们将SALE和RL的检查点自适应方法整合到TD3中，形成TD7算法，该算法在连续控制任务中的表现明显优于现有算法。在OpenAI gym基准任务中，TD7在300k和5M时间步骤下的平均性能增益分别为276.7％和50.7％，可以在在线和离线设置中使用。

    In the field of reinforcement learning (RL), representation learning is a proven tool for complex image-based tasks, but is often overlooked for environments with low-level states, such as physical control problems. This paper introduces SALE, a novel approach for learning embeddings that model the nuanced interaction between state and action, enabling effective representation learning from low-level states. We extensively study the design space of these embeddings and highlight important design considerations. We integrate SALE and an adaptation of checkpoints for RL into TD3 to form the TD7 algorithm, which significantly outperforms existing continuous control algorithms. On OpenAI gym benchmark tasks, TD7 has an average performance gain of 276.7% and 50.7% over TD3 at 300k and 5M time steps, respectively, and works in both the online and offline settings.
    
[^17]: DiffLoad:扩散模型中的负荷预测不确定性量化

    DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion Model. (arXiv:2306.01001v1 [cs.LG])

    [http://arxiv.org/abs/2306.01001](http://arxiv.org/abs/2306.01001)

    本文提出了一种扩散模型中的负荷预测不确定性量化方法，采用Seq2Seq网络结构来分离两种类型的不确定性并处理异常情况，不仅着眼于预测条件期望值。

    

    电力负荷预测对电力系统的决策制定，如机组投入和能源管理等具有重要意义。近年来，各种基于自监督神经网络的方法已经被应用于电力负荷预测，以提高预测准确性和捕捉不确定性。然而，大多数现有的方法是基于高斯似然方法的，它旨在在给定的协变量下准确估计分布期望值。这种方法很难适应存在分布偏移和异常值的时间数据。在本文中，我们提出了一种基于扩散的Seq2seq结构来估计本体不确定性，并使用鲁棒的加性柯西分布来估计物象不确定性。我们展示了我们的方法能够分离两种类型的不确定性并处理突变情况，而不是准确预测条件期望。

    Electrical load forecasting is of great significance for the decision makings in power systems, such as unit commitment and energy management. In recent years, various self-supervised neural network-based methods have been applied to electrical load forecasting to improve forecasting accuracy and capture uncertainties. However, most current methods are based on Gaussian likelihood methods, which aim to accurately estimate the distribution expectation under a given covariate. This kind of approach is difficult to adapt to situations where temporal data has a distribution shift and outliers. In this paper, we propose a diffusion-based Seq2seq structure to estimate epistemic uncertainty and use the robust additive Cauchy distribution to estimate aleatoric uncertainty. Rather than accurately forecasting conditional expectations, we demonstrate our method's ability in separating two types of uncertainties and dealing with the mutant scenarios.
    
[^18]: （正则化）Wasserstein分布式强最优模型的确切泛化保证

    Exact Generalization Guarantees for (Regularized) Wasserstein Distributionally Robust Models. (arXiv:2305.17076v1 [cs.LG])

    [http://arxiv.org/abs/2305.17076](http://arxiv.org/abs/2305.17076)

    本文表明Wasserstein分布式强鲁棒估计器的泛化保证适用于一般模型类别，不受维数灾难所困扰，甚至可以涵盖测试时的分布变化。

    

    Wasserstein分布式强鲁棒估计器已经成为面对不确定性的预测和决策的强大模型。这些估计器提供了有吸引力的泛化保证：训练分布得到的强鲁棒目标是真实风险的一个精确上界，并且高概率成立。然而，现有的保证要么受到维数灾难的困扰，要么仅限于特定的设置，或者会导致虚假的错误术语。在本文中，我们表明这些泛化保证实际上适用于一般的模型类别，不受维数灾难所困扰，甚至可以涵盖测试时的分布变化。我们还证明，这些结果可以推广到新引入的Wasserstein分布式强最优问题的正则化版本。

    Wasserstein distributionally robust estimators have emerged as powerful models for prediction and decision-making under uncertainty. These estimators provide attractive generalization guarantees: the robust objective obtained from the training distribution is an exact upper bound on the true risk with high probability. However, existing guarantees either suffer from the curse of dimensionality, are restricted to specific settings, or lead to spurious error terms. In this paper, we show that these generalization guarantees actually hold on general classes of models, do not suffer from the curse of dimensionality, and can even cover distribution shifts at testing. We also prove that these results carry over to the newly-introduced regularized versions of Wasserstein distributionally robust problems.
    
[^19]: 带扰动生成树的可微聚类方法

    Differentiable Clustering with Perturbed Spanning Forests. (arXiv:2305.16358v1 [cs.LG])

    [http://arxiv.org/abs/2305.16358](http://arxiv.org/abs/2305.16358)

    介绍了一种基于扰动生成树的可微聚类方法，依赖于线性规划解的随机扰动，具有良好的性能。

    

    我们介绍了一种基于最小权重生成树的可微聚类方法，它是生成树的一种变体，具有多个连通分量。我们的方法依赖于线性规划解的随机扰动，以实现平滑和高效的梯度计算。这使我们能够在端到端可训练的流水线中包含聚类。我们证明了我们的方法即使在嘈杂的数据集和具有挑战性的几何环境下也能良好地工作。我们还利用这种方法制定了一个特别的损失，以有效地从部分聚类数据学习。我们在几个现实世界的数据集上展示了它在监督和半监督任务中的表现。

    We introduce a differentiable clustering method based on minimum-weight spanning forests, a variant of spanning trees with several connected components. Our method relies on stochastic perturbations of solutions of linear programs, for smoothing and efficient gradient computations. This allows us to include clustering in end-to-end trainable pipelines. We show that our method performs well even in difficult settings, such as datasets with high noise and challenging geometries. We also formulate an ad hoc loss to efficiently learn from partial clustering data using this operation. We demonstrate its performance on several real world datasets for supervised and semi-supervised tasks.
    
[^20]: 一种用于确定固定置信度和以上的 $\varepsilon$-最佳臂辨识算法

    An $\varepsilon$-Best-Arm Identification Algorithm for Fixed-Confidence and Beyond. (arXiv:2305.16041v1 [stat.ML])

    [http://arxiv.org/abs/2305.16041](http://arxiv.org/abs/2305.16041)

    提出一种新颖的采样规则EB-TC $\varepsilon$，用于随机赌博机中的$\varepsilon$-最佳臂的辨识。该规则可用于确定固定置信度或固定预算标识且具备自适应调整勘探参数的渐近最优性。在仿真实验中表现良好，适用于不同问题领域。

    

    我们提出了一种新颖的采样规则EB-TC $\varepsilon$，该规则用于随机赌博机中的$\varepsilon$-最佳臂的辨识。这是第一种用于近似最佳臂辨识的Top Two算法分析实例。 EB-TC $\varepsilon$ 是一种“随时可用”的采样规则，因此可以在没有预算知识的情况下用于确定固定置信度或固定预算标识（无需修改）。我们为EB-TC $\varepsilon$ 提供了三种理论保证。首先，我们证明其在固定置信度设置中预期的样本复杂度上有界，特别是在其勘探参数的自适应调整与组合的情况下呈现其渐近最优性。我们通过在任何时间和对于任何误差参数的概率上界来补充这些发现，这进一步产生其任何时间的简单遗憾上界。最后，我们通过数值模拟表明，与现有算法相比，EB-TC $\varepsilon$ 的性能表现优秀，且适用于不同问题领域。

    We propose EB-TC$\varepsilon$, a novel sampling rule for $\varepsilon$-best arm identification in stochastic bandits. It is the first instance of Top Two algorithm analyzed for approximate best arm identification. EB-TC$\varepsilon$ is an *anytime* sampling rule that can therefore be employed without modification for fixed confidence or fixed budget identification (without prior knowledge of the budget). We provide three types of theoretical guarantees for EB-TC$\varepsilon$. First, we prove bounds on its expected sample complexity in the fixed confidence setting, notably showing its asymptotic optimality in combination with an adaptive tuning of its exploration parameter. We complement these findings with upper bounds on its probability of error at any time and for any error parameter, which further yield upper bounds on its simple regret at any time. Finally, we show through numerical simulations that EB-TC$\varepsilon$ performs favorably compared to existing algorithms, in different
    
[^21]: 从理论角度揭示“思维链”背后的奥秘

    Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])

    [http://arxiv.org/abs/2305.15408](http://arxiv.org/abs/2305.15408)

    本文从理论层面探究了带有“思维链”提示的大型语言模型在解决基本数学和决策问题中的能力，发现自回归Transformer大小恒定即可解决任务，揭示了“思维链”提示的背后机制。

    

    最近的研究发现，"思维链"提示能够显著提高大型语言模型（LLMs）的性能，特别是在涉及数学或推理的复杂任务中。尽管获得了巨大的实证成功，但“思维链”背后的机制以及它如何释放LLMs的潜力仍然是神秘的。本文首次从理论上回答了这些问题。具体而言，我们研究了LLMs带有“思维链”在解决基本数学和决策问题中的能力。我们首先给出一个不可能的结果，表明任何有限深度的Transformer都不能直接输出正确的基本算术/方程任务的答案，除非模型大小随着输入长度的增加呈超多项式增长。相反，我们通过构造证明，大小恒定的自回归Transformer足以通过使用常用的数学语言形式生成“思维链”推导来解决这两个任务。

    Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
    
[^22]: 无需Lipschitzness和Smoothness的在线投资组合选择的数据相关上界

    Data-Dependent Bounds for Online Portfolio Selection Without Lipschitzness and Smoothness. (arXiv:2305.13946v1 [cs.LG])

    [http://arxiv.org/abs/2305.13946](http://arxiv.org/abs/2305.13946)

    本文提出了在线投资组合选择的第一个数据相关上界，算法显示亚线性遗憾率，并在数据“容易”时实现对数遗憾。

    

    本文介绍了在线投资组合选择中的第一种小损失和平稳变化的遗憾上界，并标志着在线凸优化具有非Lipschitz、非光滑损失的数据相关上界的首次实例。我们提出的算法在最坏情况下显示出亚线性遗憾率，并在数据“容易”时实现对数遗憾，每次迭代的时间几乎是投资选择数量的线性。遗憾上界是使用对数损失的新型光滑性表征、遵循具有自共轭正则化器的正则化领袖（FTRL）的局部范数分析、它们不一定是障碍的和具有log障碍的乐观FTRL的隐式变体来推导的。

    This work introduces the first small-loss and gradual-variation regret bounds for online portfolio selection, marking the first instances of data-dependent bounds for online convex optimization with non-Lipschitz, non-smooth losses. The algorithms we propose exhibit sublinear regret rates in the worst cases and achieve logarithmic regrets when the data is "easy," with per-iteration time almost linear in the number of investment alternatives. The regret bounds are derived using novel smoothness characterizations of the logarithmic loss, a local norm-based analysis of following the regularized leader (FTRL) with self-concordant regularizers, which are not necessarily barriers, and an implicit variant of optimistic FTRL with the log-barrier.
    
[^23]: 通过RKHM和Perron-Frobenius算子的深度学习

    Deep Learning with Kernels through RKHM and the Perron-Frobenius Operator. (arXiv:2305.13588v1 [stat.ML])

    [http://arxiv.org/abs/2305.13588](http://arxiv.org/abs/2305.13588)

    该论文提出了一种基于核方法的深度学习框架：深度RKHM，通过使用$C^*$代数获得更温和的界限，并提供了良性过拟合的理论解释。

    

    重现核希尔伯特$C^*$-模(RKHM)通过$C^*$代数对重现核希尔伯特空间(RKHS)进行了泛化，而Perron-Frobenius算子是与函数组合相关的线性算子。将这两个概念结合起来，我们提出了深度RKHM，一种基于核方法的深度学习框架。我们在这个设置中推导了一个新的Rademacher广义界限，并通过Perron-Frobenius算子提供了良性过拟合的理论解释。由于$C^*$代数的优势，该界限对输出维度的依赖性较现有界限更加温和。我们展示了$C^*$代数是深度学习的核心工具，使我们能够利用算子的乘积结构，并提供与卷积神经网络的明确联系。我们的理论分析为设计和分析深度核方法提供了一个新的视角。

    Reproducing kernel Hilbert $C^*$-module (RKHM) is a generalization of reproducing kernel Hilbert space (RKHS) by means of $C^*$-algebra, and the Perron-Frobenius operator is a linear operator related to the composition of functions. Combining these two concepts, we present deep RKHM, a deep learning framework for kernel methods. We derive a new Rademacher generalization bound in this setting and provide a theoretical interpretation of benign overfitting by means of Perron-Frobenius operators. By virtue of $C^*$-algebra, the dependency of the bound on output dimension is milder than existing bounds. We show that $C^*$-algebra is a suitable tool for deep learning with kernels, enabling us to take advantage of the product structure of operators and to provide a clear connection with convolutional neural networks. Our theoretical analysis provides a new lens through which one can design and analyze deep kernel methods.
    
[^24]: 动量匹配去噪Gibbs采样

    Moment Matching Denoising Gibbs Sampling. (arXiv:2305.11650v1 [stat.ML])

    [http://arxiv.org/abs/2305.11650](http://arxiv.org/abs/2305.11650)

    本文提出了动量匹配去噪Gibbs采样方法，可以在给定‘嘈杂’的模型的情况下，从干净的模型中有效地进行采样。

    

    能量基模型（EBMs）为建模复杂数据分布提供了一个通用的框架。然而，EBMs 的训练和采样仍然面临重大挑战。用于可扩展 EBM 训练的广泛使用的去噪分数匹配（DSM）方法存在不一致性问题，导致能量模型学习到“嘈杂”的数据分布。在本文中，我们提出了一种有效的采样框架：（伪）Gibbs采样与动量匹配，可以在给定经过DSM训练良好的“嘈杂”模型的情况下，从基础“干净”模型中有效地进行采样。我们探讨了我们的方法相对于相关方法的优势，并展示了如何将该方法扩展到高维数据集。

    Energy-Based Models (EBMs) offer a versatile framework for modeling complex data distributions. However, training and sampling from EBMs continue to pose significant challenges. The widely-used Denoising Score Matching (DSM) method for scalable EBM training suffers from inconsistency issues, causing the energy model to learn a `noisy' data distribution. In this work, we propose an efficient sampling framework: (pseudo)-Gibbs sampling with moment matching, which enables effective sampling from the underlying clean model when given a `noisy' model that has been well-trained via DSM. We explore the benefits of our approach compared to related methods and demonstrate how to scale the method to high-dimensional datasets.
    
[^25]: 用有效的视野连接强化学习理论和实践

    Bridging RL Theory and Practice with the Effective Horizon. (arXiv:2304.09853v1 [cs.LG])

    [http://arxiv.org/abs/2304.09853](http://arxiv.org/abs/2304.09853)

    本论文通过对常见深度强化学习测试基准中155个MDP的数据集进行分析，发现当最高Q值的动作在随机策略下Q值最高时，深度强化学习往往会成功；反之，则失败的可能性较高。

    

    深度强化学习在某些环境中表现出色，但在其他环境中却失败得非常严重。理想情况下，强化学习理论应该能够解释这种现象，提供预测实际性能的界限。不幸的是，当前的理论还没有这种能力。本文通过引入包含155个MDP的新数据集BRIDGE，将标准的深度强化学习算法与之前的样本复杂度先前界进行比较，并发现了一个意想不到的性质：当最高Q值的动作在随机策略下的Q值也是最高的时，深度强化学习往往会成功；反之，失败的可能性较高。基于这一性质，我们将其概括为一个新的MDP复杂度度量，称为有效的视野。

    Deep reinforcement learning (RL) works impressively in some environments and fails catastrophically in others. Ideally, RL theory should be able to provide an understanding of why this is, i.e. bounds predictive of practical performance. Unfortunately, current theory does not quite have this ability. We compare standard deep RL algorithms to prior sample complexity prior bounds by introducing a new dataset, BRIDGE. It consists of 155 MDPs from common deep RL benchmarks, along with their corresponding tabular representations, which enables us to exactly compute instance-dependent bounds. We find that prior bounds do not correlate well with when deep RL succeeds vs. fails, but discover a surprising property that does. When actions with the highest Q-values under the random policy also have the highest Q-values under the optimal policy, deep RL tends to succeed; when they don't, deep RL tends to fail. We generalize this property into a new complexity measure of an MDP that we call the eff
    
[^26]: 带吸收的泛洪：复杂网络上异构赌博机的高效协议

    Flooding with Absorption: An Efficient Protocol for Heterogeneous Bandits over Complex Networks. (arXiv:2303.05445v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.05445](http://arxiv.org/abs/2303.05445)

    该论文提出了一种名为带吸收的泛洪（FwA）的新协议，用于解决复杂网络上的异构赌博机问题。通过严格的遗憾分析，证明了该协议的有效性。

    

    多臂赌博机广泛用于建模顺序决策，在许多现实应用中如在线推荐系统和无线网络中无处不在。我们考虑一个多代理的场景，每个代理解决自己的赌博机问题，赌博机拥有不同的臂。他们的目标是在通过给定网络的通信协议协作的同时最小化他们的集体遗憾。先前关于此问题的文献只考虑了臂的异质性和网络化代理问题。在这项工作中，我们引入了一个同时包含这两个特性的设置。针对这一新颖的设置，我们首先对标准泛洪协议结合经典的上置信界策略提供了严格的遗憾分析。然后，为了减轻在复杂网络中泛洪造成的高通信成本问题，我们提出了一种新的协议，称为带吸收的泛洪（FwA）。我们对由此产生的遗憾上界进行了理论分析，并讨论了该协议的优点。

    Multi-armed bandits are extensively used to model sequential decision-making, making them ubiquitous in many real-life applications such as online recommender systems and wireless networking. We consider a multi-agent setting where each agent solves their own bandit instance endowed with a different set of arms. Their goal is to minimize their group regret while collaborating via some communication protocol over a given network. Previous literature on this problem only considered arm heterogeneity and networked agents separately. In this work, we introduce a setting that encompasses both features. For this novel setting, we first provide a rigorous regret analysis for a standard flooding protocol combined with the classic UCB policy. Then, to mitigate the issue of high communication costs incurred by flooding in complex networks, we propose a new protocol called Flooding with Absorption (FwA). We provide a theoretical analysis of the resulting regret bound and discuss the advantages of
    
[^27]: 多级扩散：图像生成的无限维度基于得分的扩散模型

    Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models for Image Generation. (arXiv:2303.04772v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04772](http://arxiv.org/abs/2303.04772)

    本文介绍了无限维度得分扩散模型在多个分辨率水平上的离散化方法，并使用多级扩散算法在多个分辨率上高效地学习。实证表明，该模型在相同或更高分辨率下产生比传统基于得分的扩散模型更高质量的样本，并可以生成不同分辨率的图像并处理矩形域。

    

    基于得分的扩散模型是近年来图像生成的最先进方法之一。现有的基于得分的扩散模型通常在有限维度设置中表述，其中图像被视为具有有限尺寸的张量。本文在无限维度设置中开发了基于得分的扩散模型，即我们将训练数据建模为支撑在矩形域上的函数。除了追求在更高分辨率下生成图像之外，我们的主要动机是创建一个良好定义的无限维度学习问题，以便可以在多个分辨率水平上一致地离散化它。我们希望获得能够横跨不同分辨率级别的扩散模型，并提高训练过程的效率。我们展示了如何克服当前基于得分的扩散模型在无限维度设置中存在的两个缺点。首先，我们修改了前向过程以确保在无限维度设置中潜在分布是良好定义的。其次，我们提出了一种多级扩散算法，使我们能够在多个分辨率上高效地学习。我们实证表明，我们的多级模型在相同或更高分辨率下产生比传统基于得分的扩散模型更高质量的样本。此外，我们的方法可以无缝地生成不同分辨率的图像并处理矩形域。

    Score-based diffusion models (SBDM) have recently emerged as state-of-the-art approaches for image generation. Existing SBDMs are typically formulated in a finite-dimensional setting, where images are considered as tensors of a finite size. This papers develops SBDMs in the infinite-dimensional setting, that is, we model the training data as functions supported on a rectangular domain. Besides the quest for generating images at ever higher resolution our primary motivation is to create a well-posed infinite-dimensional learning problem so that we can discretize it consistently on multiple resolution levels. We thereby hope to obtain diffusion models that generalize across different resolution levels and improve the efficiency of the training process. We demonstrate how to overcome two shortcomings of current SBDM approaches in the infinite-dimensional setting. First, we modify the forward process to ensure that the latent distribution is well-defined in the infinite-dimensional setting
    
[^28]: 数据修剪和神经缩放定律：基于评分的算法的基本限制

    Data pruning and neural scaling laws: fundamental limitations of score-based algorithms. (arXiv:2302.06960v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.06960](http://arxiv.org/abs/2302.06960)

    评分数据修剪算法在高压缩区域失败，通过随机化的校准协议可以提高现有修剪算法在该区域的性能。

    

    数据修剪算法常用于减少优化过程的内存和计算成本。最近的实证结果表明，随机数据修剪仍然是一个强大的基准，并在高压缩区域优于大多数现有的数据修剪方法，即保留了不到数据的30％的部分。这种压缩区域最近引起了很多关注，因为数据修剪在提高所谓的神经缩放定律中的作用；在[Sorscher et al.]中，作者展示了需要高质量的数据修剪算法才能击败样本势律。在这项工作中，我们关注评分数据修剪算法，并在理论上和实际上展示了为什么这样的算法在高压缩区域失败。我们证明了数据修剪的“没有免费午餐”定理，并通过随机化提出了校准协议，以提高现有修剪算法在高压缩区域的性能。

    Data pruning algorithms are commonly used to reduce the memory and computational cost of the optimization process. Recent empirical results reveal that random data pruning remains a strong baseline and outperforms most existing data pruning methods in the high compression regime, i.e., where a fraction of $30\%$ or less of the data is kept. This regime has recently attracted a lot of interest as a result of the role of data pruning in improving the so-called neural scaling laws; in [Sorscher et al.], the authors showed the need for high-quality data pruning algorithms in order to beat the sample power law.  In this work, we focus on score-based data pruning algorithms and show theoretically and empirically why such algorithms fail in the high compression regime. We demonstrate ``No Free Lunch" theorems for data pruning and present calibration protocols that enhance the performance of existing pruning algorithms in this high compression regime using randomization.
    
[^29]: 一种统一的方法推导（时间均匀的）PAC-Bayes界限

    A unified recipe for deriving (time-uniform) PAC-Bayes bounds. (arXiv:2302.03421v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.03421](http://arxiv.org/abs/2302.03421)

    该论文提出了一种用于推导PAC-Bayesian泛化界限的统一框架，不同于传统的固定样本大小方式，该框架适用于所有停止时间。同时，该论文还提出了新的边界方法，也可以应用于非平稳损失函数和非独立同分布的数据。

    

    我们提出了一个框架，用于推导PAC-Bayesian泛化界限。与大多数关于此主题的文献不同，我们的界限是任何时间都有效的（即时间均匀的），这意味着它们适用于所有停止时间，而不仅仅是固定的样本大小。我们的方法按照以下顺序结合了四种工具：（a）非负超马丁格尔或反向亚马逊，（b）混合法，（c）Donsker-Varadhan公式（或其它凸性对偶原理）和（d）Ville不等式。我们的主要成果是一个PAC-Bayes定理，适用于广泛的离散随机过程类。我们展示了这个结果如何推出知名的经典PAC-Bayes界限，例如Seeger、McAllester、Maurer和Catoni的界限，以及许多最新的界限。我们还提出了几个新的界限。我们的框架还使我们能够放松传统的假设；特别地，我们考虑非平稳损失函数和非独立同分布的数据。

    We present a unified framework for deriving PAC-Bayesian generalization bounds. Unlike most previous literature on this topic, our bounds are anytime-valid (i.e., time-uniform), meaning that they hold at all stopping times, not only for a fixed sample size. Our approach combines four tools in the following order: (a) nonnegative supermartingales or reverse submartingales, (b) the method of mixtures, (c) the Donsker-Varadhan formula (or other convex duality principles), and (d) Ville's inequality. Our main result is a PAC-Bayes theorem which holds for a wide class of discrete stochastic processes. We show how this result implies time-uniform versions of well-known classical PAC-Bayes bounds, such as those of Seeger, McAllester, Maurer, and Catoni, in addition to many recent bounds. We also present several novel bounds. Our framework also enables us to relax traditional assumptions; in particular, we consider nonstationary loss functions and non-i.i.d. data. In sum, we unify the derivati
    
[^30]: 预条件对超参化低秩矩阵感知的影响

    The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing. (arXiv:2302.01186v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01186](http://arxiv.org/abs/2302.01186)

    该研究提出了ScaledGD(𝜆)方法，相较于传统梯度下降法更加鲁棒，并且在处理低秩矩阵感知问题时具有很好的表现。

    

    本文提出了ScaledGD(𝜆)方法来解决低秩矩阵感知中矩阵可能病态以及真实秩未知的问题。该方法使用超参式表示，从一个小的随机初始化开始，通过使用特定形式的阻尼预条件梯度下降来对抗超参化和病态曲率的影响。与基准梯度下降（GD）相比，尽管预处理需要轻微的计算开销，但ScaledGD（𝜆）在面对病态问题时表现出了出色的鲁棒性。在高斯设计下，ScaledGD($\lambda$) 会在仅迭代数对数级别的情况下，以线性速率收敛到真实的低秩矩阵。

    We propose $\textsf{ScaledGD($\lambda$)}$, a preconditioned gradient descent method to tackle the low-rank matrix sensing problem when the true rank is unknown, and when the matrix is possibly ill-conditioned. Using overparametrized factor representations, $\textsf{ScaledGD($\lambda$)}$ starts from a small random initialization, and proceeds by gradient descent with a specific form of damped preconditioning to combat bad curvatures induced by overparameterization and ill-conditioning. At the expense of light computational overhead incurred by preconditioners, $\textsf{ScaledGD($\lambda$)}$ is remarkably robust to ill-conditioning compared to vanilla gradient descent ($\textsf{GD}$) even with overprameterization. Specifically, we show that, under the Gaussian design, $\textsf{ScaledGD($\lambda$)}$ converges to the true low-rank matrix at a constant linear rate after a small number of iterations that scales only logarithmically with respect to the condition number and the problem dimensi
    
[^31]: 你是否正确使用了测试对数似然？

    Are you using test log-likelihood correctly?. (arXiv:2212.00219v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.00219](http://arxiv.org/abs/2212.00219)

    使用测试对数似然进行比较可能与其他指标相矛盾，并且高测试对数似然不意味着更准确的后验近似。

    

    测试对数似然常被用来比较不同模型的同一数据，或者比较拟合同一概率模型的不同近似推断算法。我们通过简单的例子展示了如何基于测试对数似然的比较可能与其他目标相矛盾。具体来说，我们的例子表明：（i）达到更高测试对数似然的近似贝叶斯推断算法不必意味着能够产生更准确的后验近似，（ii）基于测试对数似然比较的预测准确性结论可能与基于均方根误差的结论不一致。

    Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.
    
[^32]: 高维分位数回归中的转移学习统计推断

    Statistical inference for transfer learning with high-dimensional quantile regression. (arXiv:2211.14578v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.14578](http://arxiv.org/abs/2211.14578)

    本研究提出了一种高维分位数回归模型中的转移学习方法，以适应源域和目标域中的异质性和重尾分布。根据精心选择的可转移源域建立了转移学习估计量的误差界限，并提出了有效的置信区间和假设检验程序，以实现一步完成。

    

    转移学习已经成为一种重要的技术，用于利用源域中的信息来提高目标任务的性能。尽管高维数据普遍存在异质性和/或重尾分布，但目前的转移学习方法未能充分考虑这些问题，可能会影响结果的性能。我们在高维分位数回归模型框架下提出了一种转移学习过程，以适应源域和目标域中的异质性和重尾分布。我们根据精心选择的可转移源域建立了转移学习估计量的误差界限，显示在关键选择标准和较大的源任务样本量下可以实现更低的误差界限。我们进一步提出了一个有效的置信区间和假设检验程序，用于高维分位数回归系数的各个分量，通过倡导双重转移学习估计量，实现一步完成。

    Transfer learning has become an essential technique to exploit information from the source domain to boost performance of the target task. Despite the prevalence in high-dimensional data, heterogeneity and/or heavy tails are insufficiently accounted for by current transfer learning approaches and thus may undermine the resulting performance. We propose a transfer learning procedure in the framework of high-dimensional quantile regression models to accommodate the heterogeneity and heavy tails in the source and target domains. We establish error bounds of the transfer learning estimator based on delicately selected transferable source domains, showing that lower error bounds can be achieved for critical selection criterion and larger sample size of source tasks. We further propose valid confidence interval and hypothesis test procedures for individual component of high-dimensional quantile regression coefficients by advocating a double transfer learning estimator, which is the one-step 
    
[^33]: 通过使用Cover Trees的最小间隔实现数值稳定的稀疏高斯过程

    Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees. (arXiv:2210.07893v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.07893](http://arxiv.org/abs/2210.07893)

    本文针对高斯过程模型的数值稳定性进行了研究，通过感兴趣点的选择和计算，提供了稳定可靠的稀疏逼近方法。

    

    高斯过程常用于较大的机器学习和决策系统中，例如地理空间建模、贝叶斯优化或潜在高斯模型中。在一个系统中，高斯过程模型需要以稳定可靠的方式运行，以确保与系统的其他部分正确交互。本文研究了基于感兴趣点的可扩展稀疏逼近的数值稳定性。为此，我们首先回顾了数值稳定性，并阐述了高斯过程模型可能不稳定的典型情况。在插值文献中原始开发的稳定性理论的基础上，我们导出了对感兴趣点进行计算的数值稳定性的充分条件和某些情况下的必要条件。对于地理空间建模等低维任务，我们提出了一种自动计算满足这些条件的感兴趣点的方法。

    Gaussian processes are frequently deployed as part of larger machine learning and decision-making systems, for instance in geospatial modeling, Bayesian optimization, or in latent Gaussian models. Within a system, the Gaussian process model needs to perform in a stable and reliable manner to ensure it interacts correctly with other parts of the system. In this work, we study the numerical stability of scalable sparse approximations based on inducing points. To do so, we first review numerical stability, and illustrate typical situations in which Gaussian process models can be unstable. Building on stability theory originally developed in the interpolation literature, we derive sufficient and in certain cases necessary conditions on the inducing points for the computations performed to be numerically stable. For low-dimensional tasks such as geospatial modeling, we propose an automated method for computing inducing points satisfying these conditions. This is done via a modification of t
    
[^34]: 使用多环境方法检测观测数据中的隐式混淆

    Detecting hidden confounding in observational data using multiple environments. (arXiv:2205.13935v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2205.13935](http://arxiv.org/abs/2205.13935)

    使用独立数据生成过程下的多环境方法，可以检测观测数据中的未观察到的混淆因素，并提出了测试独立性的程序。

    

    在因果推断中，常见的假设是没有隐式混淆。然而，在单个数据集中不能确定这个假设通常是不可能的。在独立的数据生成过程下，我们展示了一种方法来在多个来自不同环境的观测数据集中检测未观察到的混淆因素。我们提出了一种测试可验证的条件独立性的理论，这种独立性仅当存在混淆因素时才不存在，并检查了违反其假设的情况：退化和依赖机制以及忠实度违反。此外，我们提出了一种程序来测试这些独立性，并使用基于真实世界数据的半合成数据和模拟研究研究其经验有限样本行为。在大多数情况下，提出的程序能够正确预测存在隐式混淆，特别是当混淆偏差很大时。

    A common assumption in causal inference from observational data is that there is no hidden confounding. Yet it is, in general, impossible to verify this assumption from a single dataset. Under the assumption of independent causal mechanisms underlying the data-generating process, we demonstrate a way to detect unobserved confounders when having multiple observational datasets coming from different environments. We present a theory for testable conditional independencies that are only absent when there is hidden confounding and examine cases where we violate its assumptions: degenerate & dependent mechanisms, and faithfulness violations. Additionally, we propose a procedure to test these independencies and study its empirical finite-sample behavior using simulation studies and semi-synthetic data based on a real-world dataset. In most cases, the proposed procedure correctly predicts the presence of hidden confounding, particularly when the confounding bias is large.
    
[^35]: 不同输入维度数据集之间的迁移学习：线性回归情况下的算法和分析

    Transfer-Learning Across Datasets with Different Input Dimensions: An Algorithm and Analysis for the Linear Regression Case. (arXiv:2202.05069v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.05069](http://arxiv.org/abs/2202.05069)

    本文提出了一种适用于线性回归情况的迁移学习算法，该算法能够将新数据与历史数据相结合，特别在新数据稀缺的情况下具有益处，并且在实验验证中表现出对负迁移学习的鲁棒性。

    

    随着新传感器和监测设备的发展，越来越多的数据源可以作为机器学习模型的输入。这些数据既可以帮助提高模型的准确性，但将这些新输入与历史数据相结合仍然是一个尚未详细研究的挑战。在本文中，我们提出了一种迁移学习算法，将新数据和历史数据结合起来，特别在新数据稀缺的情况下具有益处。我们将重点放在线性回归情况下，这使得我们能够对该方法的益处进行严格的理论研究。我们表明我们的方法对负迁移学习是具有鲁棒性的，并通过真实和模拟数据进行了实证验证。

    With the development of new sensors and monitoring devices, more sources of data become available to be used as inputs for machine learning models. These can on the one hand help to improve the accuracy of a model. On the other hand however, combining these new inputs with historical data remains a challenge that has not yet been studied in enough detail. In this work, we propose a transfer-learning algorithm that combines the new and the historical data, that is especially beneficial when the new data is scarce. We focus the approach on the linear regression case, which allows us to conduct a rigorous theoretical study on the benefits of the approach. We show that our approach is robust against negative transfer-learning, and we confirm this result empirically with real and simulated data.
    
[^36]: 可解释的序列分类通过原型轨迹

    Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2007.01777](http://arxiv.org/abs/2007.01777)

    ProtoryNet是一种基于原型轨迹的可解释深度神经网络，它通过捕捉时间模式和原型的近似程度来进行文本分类，并实现了直观和细致的推理过程解释。

    

    我们提出了一种新颖的用于文本分类的可解释深度神经网络，称为ProtoryNet，它基于原型轨迹的新概念。受现代语言学中的原型理论的启发，ProtoryNet通过为文本序列中的每个句子找到最相似的原型，并将每个句子与相应的活动原型的接近程度输入到RNN主干中进行预测。然后，RNN主干捕捉到原型的时间模式，我们称之为原型轨迹。原型轨迹能够直观而细致地解释RNN模型的推理过程，类似于人类分析文本的方式。我们还设计了原型修剪过程，以减少模型使用的原型总数，以提高解释性。在多个公共数据集上的实验证明，ProtoryNet比基线的基于原型的深度神经网络更准确，并减少了与现有模型相比的性能差距。

    We propose a novel interpretable deep neural network for text classification, called ProtoryNet, based on a new concept of prototype trajectories. Motivated by the prototype theory in modern linguistics, ProtoryNet makes a prediction by finding the most similar prototype for each sentence in a text sequence and feeding an RNN backbone with the proximity of each sentence to the corresponding active prototype. The RNN backbone then captures the temporal pattern of the prototypes, which we refer to as prototype trajectories. Prototype trajectories enable intuitive and fine-grained interpretation of the reasoning process of the RNN model, in resemblance to how humans analyze texts. We also design a prototype pruning procedure to reduce the total number of prototypes used by the model for better interpretability. Experiments on multiple public data sets show that ProtoryNet is more accurate than the baseline prototype-based deep neural net and reduces the performance gap compared to state-o
    

