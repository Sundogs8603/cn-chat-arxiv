# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Sparse Recovery with Shuffled Labels: Statistical Limits and Practical Estimators.](http://arxiv.org/abs/2303.11233) | 本文探讨了带洗牌标签的稀疏恢复问题，提出了两种实用估计器，并建立了相应的理论保证，数值实验验证了这些方法的优越性能。 |
| [^2] | [Fitting Low-rank Models on Egocentrically Sampled Partial Networks.](http://arxiv.org/abs/2303.11230) | 本文提出了一种方法，用于在以自我为中心采样的部分网络上拟合低秩模型，能够有效地解决目前的一些统计方法存在的问题，从而稳健地恢复缺失的子网络。 |
| [^3] | [A Unified Framework of Policy Learning for Contextual Bandit with Confounding Bias and Missing Observations.](http://arxiv.org/abs/2303.11187) | 本文提出了一个名为“因果调整悲观（CAP）策略学习”的算法，旨在克服离线情境赌博机问题中存在的混淆偏差和缺失观测问题，该算法通过构建奖励函数的积分方程系统的解并建立置信区间来达到目的，并带有悲观主义地采取行动。 |
| [^4] | [Integration of Radiomics and Tumor Biomarkers in Interpretable Machine Learning Models.](http://arxiv.org/abs/2303.11177) | 本文提出了一个名为ConRad的模型，将放射组学和DNN预测的生物标志物集成到肺癌CT扫描的可解释分类器中，无需耗费劳动密集和耗时的生物标志物。该模型的性能优于CNN黑匣子模型。 |
| [^5] | [An ADMM approach for multi-response regression with overlapping groups and interaction effects.](http://arxiv.org/abs/2303.11155) | 本文提出了一种新的正则化回归方法MADMMplasso，能够找到具有多个相关响应的协变量和它们的对应交互作用，对于处理相关响应和交互效应具有优势。 |
| [^6] | [Fault Detection via Occupation Kernel Principal Component Analysis.](http://arxiv.org/abs/2303.11138) | 本文提出了一种使用占据核PCA方法进行故障检测的新方法，并且通过数值模拟验证了其有效性。 |
| [^7] | [Quantile and moment neural networks for learning functionals of distributions.](http://arxiv.org/abs/2303.11060) | 本研究提出了基于分位数和矩逼近的两类神经网络用于学习概率空间中分布的函数，并混合这些特征以优于现有网络的表现。 |
| [^8] | [Approaching an unknown communication system by latent space exploration and causal inference.](http://arxiv.org/abs/2303.10931) | 本文通过探索无监督深度生成模型的潜在空间来发现数据中有意义的属性，提出了一种极端值因果分离 (CDEV) 的方法，应用于测试鲸鱼通信系统并发现其中存在语法。 |
| [^9] | [Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs.](http://arxiv.org/abs/2303.10859) | 本文提出了一种新的基于模型的算法RAFFLE，能够在低秩MDP下实现无奖励探索，并且具有显著改进的样本复杂度。 |
| [^10] | [Calibration of Neural Networks.](http://arxiv.org/abs/2303.10761) | 本文概述了神经网络的置信度校准问题，并提供了现代校准技术的经验比较。 |
| [^11] | [Lower Generalization Bounds for GD and SGD in Smooth Stochastic Convex Optimization.](http://arxiv.org/abs/2303.10758) | 本论文证明了在平稳随机凸优化中，GD和SGD的泛化下界可以降低，并且长时间的训练可能导致更差的泛化能力，这与其他研究成果不同。 |
| [^12] | [Mixture of segmentation for heterogeneous functional data.](http://arxiv.org/abs/2303.10712) | 本文提出了一种混合分割模型，可以处理异质性功能数据，通过动态规划的EM算法近似最大似然估计器，方法在模拟与真实数据集上得到验证。 |
| [^13] | [Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis.](http://arxiv.org/abs/2303.10694) | 本文提出了一种新算法Neighborhood Conformal Prediction(NCP)，可以使用神经网络学习到的表示提高深度分类器的确定性量化效率；我们从理论上证明了NCP可以产生更小的预测集。 |
| [^14] | [Provable Convergence of Variational Monte Carlo Methods.](http://arxiv.org/abs/2303.10599) | 本文提出了一种对变分蒙特卡罗（VMC）方法收敛性的可验证方法，在假设局部能量是次指数的条件下，使用非平稳马尔可夫链的Bernstein不等式推导出了MCMC估计量的误差界限，证明了VMC具有一阶收敛速率，在某些情况下，收敛速率是最优的。 |
| [^15] | [Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference.](http://arxiv.org/abs/2303.10472) | 本文表明黑盒变分推理（BBVI）满足SGD文献中的ABC条件，该结果适用于平滑和二次增长的对数似然函数，同时我们的结果推广到广泛应用于BBVI实践中的非线性协方差参数化。 |
| [^16] | [Inverse Cubature and Quadrature Kalman filters.](http://arxiv.org/abs/2303.10322) | 本文提出了逆多面积积分卡尔曼滤波器（I-CKF）和逆多项式积分卡尔曼滤波器（I-QKF），用于解决高度非线性的系统模型的逆认知问题，并在指数-平均-二次有界性意义下推导了其的随机稳定性条件。数值实验证明了其高的估计精度和递归Cram\'{e}r-Rao下界相当。 |
| [^17] | [A statistical framework for GWAS of high dimensional phenotypes using summary statistics, with application to metabolite GWAS.](http://arxiv.org/abs/2303.10221) | 本文提出了一种统计学方法，可以使用摘要统计数据对高维表型进行GWAS，该方法明确建模多效性，具有快速计算能力并可以使用生物学先验信息。 |
| [^18] | [Deep Nonparametric Estimation of Intrinsic Data Structures by Chart Autoencoders: Generalization Error and Robustness.](http://arxiv.org/abs/2303.09863) | 本文介绍了一种图表自编码器用于深度非参数估计内部数据结构，并证明了其广义误差保证和去噪能力。 |
| [^19] | [DBSCAN of Multi-Slice Clustering for three-order Tensor.](http://arxiv.org/abs/2303.07768) | 本文提出了 MSC-DBSCAN扩展算法，可以在三元聚类中从数据中提取不同子空间的不同切片聚类，并可以获得与 MSC 算法在处理秩一张量数据时相同的解决方案。 |
| [^20] | [SurvLIMEpy: A Python package implementing SurvLIME.](http://arxiv.org/abs/2302.10571) | 本文介绍了一个名为SurvLIMEpy的Python包，它实现了一种算法，可以计算适用于建模生存分析数据的机器学习算法的局部特征重要性，并支持各种生存模型。 |
| [^21] | [Spatially heterogeneous learning by a deep student machine.](http://arxiv.org/abs/2302.07419) | 本论文研究了一种深度学生机器的教师-学生设置，通过学生机器的集合来研究由具有大量可调参数的DNN的监督学习。研究表明DNN的学习在网络空间中相当异质。 |
| [^22] | [A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity.](http://arxiv.org/abs/2302.06015) | 本文提供了第一份对于浅层ViT进行训练的理论分析，证明了使用SGD训练会产生稀疏的注意力图，目前的样本复杂度与标记相关令牌的分数倒数、标记级别的令牌噪声水平和初始模型错误呈正相关关系。 |
| [^23] | [Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons.](http://arxiv.org/abs/2301.11270) | 该论文提供了带有人类反馈强化学习问题的理论框架，证明了最大似然估计在Bradley-Terry-Luce和Plackett-Luce模型下收敛。此外，提出了在一定的覆盖假设下，基于悲观估计的MLE提供了性能更好的策略。在证明了真实MLE和以成对比较形式替代的备选MLE都可以在PL模型下收敛的同时，也表明了真实MLE的高效性。这些结果为RLHF算法提供了新的见解，并统一了RLHF问题和IRL问题。 |
| [^24] | [Sparse Signal Detection in Heteroscedastic Gaussian Sequence Models: Sharp Minimax Rates.](http://arxiv.org/abs/2211.08580) | 该论文探究了异方差高斯序列模型中的稀疏信号检测问题，提出了一种最小极大分离半径的上下界以及相应的测试，展示了关于稀疏度、距离衡量和异方差性质的新的相变特性。 |
| [^25] | [Efficient Estimation for Longitudinal Network via Adaptive Merging.](http://arxiv.org/abs/2211.07866) | 本文提出了一个有效的纵向网络估计框架，利用自适应合并、张量分解和点过程等方法来减少估计偏差和方差。 |
| [^26] | [Fully Bayesian inference for latent variable Gaussian process models.](http://arxiv.org/abs/2211.02218) | 隐变量高斯过程模型通过将定性因素映射到底层隐变量的方式解决了标准高斯过程无法适应定性输入的问题。本文提出了一种考虑隐变量估计不确定性的完全贝叶斯方法，支持通过隐变量可视化定性输入的效果。 |
| [^27] | [Symmetric (Optimistic) Natural Policy Gradient for Multi-agent Learning with Parameter Convergence.](http://arxiv.org/abs/2210.12812) | 本文研究了多智能体学习中的机器人学习算法，指出了香草自然策略梯度算法可能因具有不收敛的参数而存在学习不稳定性问题，并提出了新的NPG算法变种以解决此问题。 |
| [^28] | [Predictive Inference with Feature Conformal Prediction.](http://arxiv.org/abs/2210.00173) | 本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。 |
| [^29] | [Safe Exploration Method for Reinforcement Learning under Existence of Disturbance.](http://arxiv.org/abs/2209.15452) | 本文提出了一种能够在存在扰动情况下安全进行强化学习探索的方法，该方法利用了所控制对象和扰动的部分先验知识，可以保证以预先指定的概率满足显式状态约束。 |
| [^30] | [Multi-armed Bandit Learning on a Graph.](http://arxiv.org/abs/2209.09419) | 本文提出了一种基于乐观原则和离线图形规划算法的学习算法G-UCB，能够平衡长期探索利用，用于解决一种名为图赌博机的MAB扩展，从而获得最大化的收益。 |
| [^31] | [Active Exploration for Inverse Reinforcement Learning.](http://arxiv.org/abs/2207.08645) | AceIRL提出了一种新的逆强化学习算法，通过主动探索来学习奖励函数和策略，在不需要环境生成模型的情况下，能够确定可行奖励函数的置信区间，并找到侧重于环境中最有信息的区域的探索策略。 |
| [^32] | [Estimation and inference for the Wasserstein distance between mixing measures in topic models.](http://arxiv.org/abs/2206.12768) | 本文提出了对混合模型中混合测度的Wasserstein距离的新的规范解释，并提供了在主题模型中进行此距离推断的工具。 |
| [^33] | [Concentration inequalities and optimal number of layers for stochastic deep neural networks.](http://arxiv.org/abs/2206.11241) | 该论文提出了随机深度神经网络的浓度不等式，通过期望分类器给出了分类误差的概率上界，并确定了最优层数。 |
| [^34] | [Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem.](http://arxiv.org/abs/2206.04119) | 本研究提出了一种新的方法来解决蛋白质脚手架问题，采用E(3)-等变图神经网络来学习多样和长的蛋白质主干结构的分布，并用SMCDiff算法从分布中有效地采样出符合给定模体条件的脚手架，这一算法在大计算极限中可以理论上保证条件样本的采样；研究结果表明，我们的方法可以生成长达80个残基的脚手架，并可以为固定模体实现结构多样的脚手架。 |
| [^35] | [Principal Component Analysis based frameworks for efficient missing data imputation algorithms.](http://arxiv.org/abs/2205.15150) | 本文提出了基于主成分分析的缺失数据插补框架，可适用于高维数据，能够显著优于基线方法，同时在分类任务中实现可比较或更好的分类准确性。 |
| [^36] | [Byzantine-Robust Federated Learning with Optimal Statistical Rates and Privacy Guarantees.](http://arxiv.org/abs/2205.11765) | 本文提出了一种具有近乎最优统计率的拜占庭鲁棒联邦学习协议，并展示了其与竞争协议相比的经验优越性，协议通过分桶可以结合隐私保障程序以对半诚实服务器进行安全保障。 |
| [^37] | [New Lower Bounds for Private Estimation and a Generalized Fingerprinting Lemma.](http://arxiv.org/abs/2205.08532) | 本文提供了针对高斯分布隐私协方差估计和有界协方差分布的均值估计的新下界，通过广义化指纹法到指数家族来证明这些下界的正确性。 |
| [^38] | [Fighting Money Laundering with Statistics and Machine Learning: An Introduction and Review.](http://arxiv.org/abs/2201.04207) | 本文介绍了银行反洗钱的统计和机器学习方法，并提出客户风险评估和可疑行为标识两个核心要素。未来的研究方向包括生成合成数据、半监督和深度学习、可解释性以及结果的公平性。 |
| [^39] | [A generalization gap estimation for overparameterized models via the Langevin functional variance.](http://arxiv.org/abs/2112.03660) | 本文提出了一种函数方差的Langevin估计方法，用于高效计算超参数模型的泛化缺口，实现与基于梯度的优化算法一致。 |
| [^40] | [Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph Embedding.](http://arxiv.org/abs/2110.03789) | 本研究提出了一种“知识花扭”方法来描述知识图谱嵌入模型，并可以表达广泛的嵌入先验约束，可轻松应对复合关系推理。 |
| [^41] | [Long-Range Transformers for Dynamic Spatiotemporal Forecasting.](http://arxiv.org/abs/2109.12218) | 本研究提出了一种名为Spacetimeformer的方法，将多元时间序列预测转化为“时空序列”形式进行建模，实现了对变量之间动态空间关系的学习，同时在多个基准测试上取得了最先进的结果。 |
| [^42] | [Is Q-Learning Minimax Optimal? A Tight Sample Complexity Analysis.](http://arxiv.org/abs/2102.06548) | 本文通过紧密的样本复杂度分析回答了Q学习是否是极小极大最优的问题。 |
| [^43] | [Optimal and Safe Estimation for High-Dimensional Semi-Supervised Learning.](http://arxiv.org/abs/2011.14185) | 本研究探究了高维半监督学习的估计问题，提出了最优和安全的半监督估计器。最优估计器可以实现极小极大下界，改进监督估计器。安全估计器至少和监督估计器一样好，且两者聚合可以更好地解决误差问题。 |
| [^44] | [On lower bounds for the bias-variance trade-off.](http://arxiv.org/abs/2006.00278) | 研究提出了一种通用策略来获得任何偏差小于预定界限的估计器的方差下限。该方法基于一些关于方差的抽象下限，涉及到对不同概率测度的期望值的变化以及信息度量，如KL或$\chi^2$分歧。在几个统计模型上进行了应用。 |

# 详细

[^1]: 带洗牌标签的稀疏恢复：统计限制与实用估计

    Sparse Recovery with Shuffled Labels: Statistical Limits and Practical Estimators. (arXiv:2303.11233v1 [cs.IT])

    [http://arxiv.org/abs/2303.11233](http://arxiv.org/abs/2303.11233)

    本文探讨了带洗牌标签的稀疏恢复问题，提出了两种实用估计器，并建立了相应的理论保证，数值实验验证了这些方法的优越性能。

    

    本文研究带洗牌标签的稀疏恢复问题，即$\by=\bPitrue \bX \bbetatrue + \bw$，其中$\by \in \RR^n$，$\bPi\in \RR^{n\times n}$，$\bX\in \RR^{n\times p}$，$\bbetatrue\in \RR^p$，$\bw \in \RR^n$分别是观测结果、未知的置换矩阵、设计矩阵、稀疏信号和加性噪声。我们的目标是同时重构出置换矩阵$\bPitrue$和稀疏信号$\bbetatrue$。我们从统计和计算两个方面进行研究。从统计学的角度，我们首先建立了样本数$n$和"信噪比"($\snr$)的最小极大界，以确保正确恢复置换矩阵$\bPitrue$和支撑集$\supp(\bbetatrue)$，具体而言，$n\gtrsim k\log p$和$\log\snr\gtrsim\log n+\frac{k\log p}{n}$。然后，我们通过提出一种基于穷举搜索的估计器来确认这些最小极大界的紧致性，其表现与最小极大界相匹配，但存在一个常数。从计算的角度，我们提出了两种基于凸松弛方法和组合优化方法的实用估计器。当样本数$n$和稀疏度$k$满足某些条件时，我们显示了这两种方法的完全恢复理论保证。数值实验验证了我们的理论结果，并展示了我们提出的估计器相对于现有方法的优越性能。

    This paper considers the sparse recovery with shuffled labels, i.e., $\by = \bPitrue \bX \bbetatrue + \bw$, where $\by \in \RR^n$, $\bPi\in \RR^{n\times n}$, $\bX\in \RR^{n\times p}$, $\bbetatrue\in \RR^p$, $\bw \in \RR^n$ denote the sensing result, the unknown permutation matrix, the design matrix, the sparse signal, and the additive noise, respectively. Our goal is to reconstruct both the permutation matrix $\bPitrue$ and the sparse signal $\bbetatrue$. We investigate this problem from both the statistical and computational aspects. From the statistical aspect, we first establish the minimax lower bounds on the sample number $n$ and the \emph{signal-to-noise ratio} ($\snr$) for the correct recovery of permutation matrix $\bPitrue$ and the support set $\supp(\bbetatrue)$, to be more specific, $n \gtrsim k\log p$ and $\log\snr \gtrsim \log n + \frac{k\log p}{n}$. Then, we confirm the tightness of these minimax lower bounds by presenting an exhaustive-search based estimator whose perfor
    
[^2]: 在以自我为中心采样的部分网络上拟合低秩模型

    Fitting Low-rank Models on Egocentrically Sampled Partial Networks. (arXiv:2303.11230v1 [cs.SI])

    [http://arxiv.org/abs/2303.11230](http://arxiv.org/abs/2303.11230)

    本文提出了一种方法，用于在以自我为中心采样的部分网络上拟合低秩模型，能够有效地解决目前的一些统计方法存在的问题，从而稳健地恢复缺失的子网络。

    

    随机网络的统计建模被广泛用于揭示复杂系统中的相互作用机制和预测现实世界中未观测到的网络链接。在许多应用中，网络连接是通过自我为中心的采样收集的：首先对节点的子集进行采样，然后记录涉及该子集的所有链接；所有其他信息都缺失。与“均匀随机缺失”的假设相比，以自我为中心采样的部分网络需要特别设计的建模策略。当前的统计方法要么计算上不可行，要么基于直觉设计而没有理论依据。在这里，我们提出了一种适用于以自我为中心采样的网络的低秩通用模型的方法，其中包括几种流行的网络模型。该方法基于图谱特性且具有计算效率，适用于大规模网络。由于该方法能够恢复由自我为中心采样引起的缺失子网络，因此得到了稳健的恢复。

    The statistical modeling of random networks has been widely used to uncover interaction mechanisms in complex systems and to predict unobserved links in real-world networks. In many applications, network connections are collected via egocentric sampling: a subset of nodes is sampled first, after which all links involving this subset are recorded; all other information is missing. Compared with the assumption of ``uniformly missing at random", egocentrically sampled partial networks require specially designed modeling strategies. Current statistical methods are either computationally infeasible or based on intuitive designs without theoretical justification. Here, we propose an approach to fit general low-rank models for egocentrically sampled networks, which include several popular network models. This method is based on graph spectral properties and is computationally efficient for large-scale networks. It results in consistent recovery of missing subnetworks due to egocentric samplin
    
[^3]: 具有混杂偏差和缺失观测的情境赌博机策略学习的统一框架

    A Unified Framework of Policy Learning for Contextual Bandit with Confounding Bias and Missing Observations. (arXiv:2303.11187v1 [cs.LG])

    [http://arxiv.org/abs/2303.11187](http://arxiv.org/abs/2303.11187)

    本文提出了一个名为“因果调整悲观（CAP）策略学习”的算法，旨在克服离线情境赌博机问题中存在的混淆偏差和缺失观测问题，该算法通过构建奖励函数的积分方程系统的解并建立置信区间来达到目的，并带有悲观主义地采取行动。

    

    本文研究离线情境赌博机问题，旨在使用观察数据获得最优策略。但是，这些数据通常存在两个不足：(i)一些混淆行动的变量未被观察到，(ii)采集到的数据中存在缺失观测。未被观察到的混淆因素导致混淆偏差，缺失观测则导致偏差和低效问题。为了克服这些挑战，并从观察到的数据集中学习最优策略，我们提出了一种称为因果调整悲观（CAP）策略学习的新算法，它将奖励函数构建为积分方程系统的解，构建置信区间，并带有悲观主义地采取行动。在数据的温和假设下，我们为离线情境赌博机问题发展了CAP亚优解的上界。

    We study the offline contextual bandit problem, where we aim to acquire an optimal policy using observational data. However, this data usually contains two deficiencies: (i) some variables that confound actions are not observed, and (ii) missing observations exist in the collected data. Unobserved confounders lead to a confounding bias and missing observations cause bias and inefficiency problems. To overcome these challenges and learn the optimal policy from the observed dataset, we present a new algorithm called Causal-Adjusted Pessimistic (CAP) policy learning, which forms the reward function as the solution of an integral equation system, builds a confidence set, and greedily takes action with pessimism. With mild assumptions on the data, we develop an upper bound to the suboptimality of CAP for the offline contextual bandit problem.
    
[^4]: 待解释机器学习模型中的放射组学和肿瘤生物标志物的整合

    Integration of Radiomics and Tumor Biomarkers in Interpretable Machine Learning Models. (arXiv:2303.11177v1 [cs.LG])

    [http://arxiv.org/abs/2303.11177](http://arxiv.org/abs/2303.11177)

    本文提出了一个名为ConRad的模型，将放射组学和DNN预测的生物标志物集成到肺癌CT扫描的可解释分类器中，无需耗费劳动密集和耗时的生物标志物。该模型的性能优于CNN黑匣子模型。

    

    尽管深度神经网络在计算机视觉领域表现出了前所未有的性能，但它们在使用医学成像进行癌症诊断和预后的实际应用方面受到限制。其中一个关键挑战是将诊断性神经网络集成到放射学和肿瘤学应用中的可解释性不足，使临床医生无法理解模型预测。因此，我们研究和提出了专家导出的放射组学和DNN预测的生物标志物在可解释分类器中的集成，我们称之为ConRad，用于肺癌的计算机断层扫描（CT）。值得注意的是，肿瘤生物标志物是从概念瓶颈模型（CBM）预测的，因此一旦训练好，我们的ConRad模型就不需要耗费劳动密集和耗时的生物标志物。在我们的评估和实际应用中，ConRad的唯一输入是分割的CT扫描。所提出的模型与卷积神经网络（CNN）进行了比较，后者充当黑匣子。

    Despite the unprecedented performance of deep neural networks (DNNs) in computer vision, their practical application in the diagnosis and prognosis of cancer using medical imaging has been limited. One of the critical challenges for integrating diagnostic DNNs into radiological and oncological applications is their lack of interpretability, preventing clinicians from understanding the model predictions. Therefore, we study and propose the integration of expert-derived radiomics and DNN-predicted biomarkers in interpretable classifiers which we call ConRad, for computerized tomography (CT) scans of lung cancer. Importantly, the tumor biomarkers are predicted from a concept bottleneck model (CBM) such that once trained, our ConRad models do not require labor-intensive and time-consuming biomarkers. In our evaluation and practical application, the only input to ConRad is a segmented CT scan. The proposed model is compared to convolutional neural networks (CNNs) which act as a black box cl
    
[^5]: 一种带有重叠组和交互效应的多响应回归ADMM方法

    An ADMM approach for multi-response regression with overlapping groups and interaction effects. (arXiv:2303.11155v1 [stat.ME])

    [http://arxiv.org/abs/2303.11155](http://arxiv.org/abs/2303.11155)

    本文提出了一种新的正则化回归方法MADMMplasso，能够找到具有多个相关响应的协变量和它们的对应交互作用，对于处理相关响应和交互效应具有优势。

    

    本文考虑存在某些响应之间的结构关系以及协变量与一组修改变量之间关系的规范化多响应回归问题。为了处理这个问题，我们提出了一种新的正则化回归方法MADMMplasso。该方法能够找到具有多个相关响应的协变量和它们的对应交互作用。我们允许在首先考虑相应协变量的主要项是否在模型中的（弱）不对称的分层方式下包含协变量和修改变量之间的交互项。为了进行参数估计，我们开发了一种ADMM算法，允许我们以简单的方式实现重叠组。仿真和药理基因组筛选数据集分析的结果显示，所提出的方法在处理相关响应和交互效应方面具有优势，无论是在预测还是在方差方面。

    In this paper, we consider the regularized multi-response regression problem where there exists some structural relation within the responses and also between the covariates and a set of modifying variables. To handle this problem, we propose MADMMplasso, a novel regularized regression method. This method is able to find covariates and their corresponding interactions, with some joint association with multiple related responses. We allow the interaction term between covariate and modifying variable to be included in a (weak) asymmetrical hierarchical manner by first considering whether the corresponding covariate main term is in the model. For parameter estimation, we develop an ADMM algorithm that allows us to implement the overlapping groups in a simple way. The results from the simulations and analysis of a pharmacogenomic screen data set show that the proposed method has an advantage in handling correlated responses and interaction effects, both with respect to prediction and varia
    
[^6]: 基于占据核主成分分析的故障检测

    Fault Detection via Occupation Kernel Principal Component Analysis. (arXiv:2303.11138v1 [stat.ML])

    [http://arxiv.org/abs/2303.11138](http://arxiv.org/abs/2303.11138)

    本文提出了一种使用占据核PCA方法进行故障检测的新方法，并且通过数值模拟验证了其有效性。

    

    自动系统的可靠操作很大程度上依赖于检测基础动态系统中的故障。虽然传统的基于模型的方法已被广泛用于故障检测，但基于数据的方法因其易于部署和对专家知识需求最小的特点而受到越来越多的关注。本文提出了一种使用占据核进行主成分分析（PCA）的新方法。占据核产生的特征映射适用于测量数据，由于使用积分具有内在的噪声鲁棒性，并且可以利用长度可变的不规则采样系统轨迹进行PCA。占据核PCA方法被用于开发一种重构误差方法进行故障检测，并且通过数值模拟验证了其有效性。

    The reliable operation of automatic systems is heavily dependent on the ability to detect faults in the underlying dynamical system. While traditional model-based methods have been widely used for fault detection, data-driven approaches have garnered increasing attention due to their ease of deployment and minimal need for expert knowledge. In this paper, we present a novel principal component analysis (PCA) method that uses occupation kernels. Occupation kernels result in feature maps that are tailored to the measured data, have inherent noise-robustness due to the use of integration, and can utilize irregularly sampled system trajectories of variable lengths for PCA. The occupation kernel PCA method is used to develop a reconstruction error approach to fault detection and its efficacy is validated using numerical simulations.
    
[^7]: 分位数神经网络与矩神经网络学习分布的函数

    Quantile and moment neural networks for learning functionals of distributions. (arXiv:2303.11060v1 [stat.ML])

    [http://arxiv.org/abs/2303.11060](http://arxiv.org/abs/2303.11060)

    本研究提出了基于分位数和矩逼近的两类神经网络用于学习概率空间中分布的函数，并混合这些特征以优于现有网络的表现。

    

    本文研究了用神经网络逼近概率空间中分布函数的方法。提出了基于分位数和矩逼近的两类神经网络，理论上支持它们的普适逼近定理。通过在其他新网络中混合分位数和矩特征，我们开发出在涉及单变量分布的数值测试案例中优于现有网络的方案。对于双变量分布，矩神经网络优于所有其他网络。

    We study news neural networks to approximate function of distributions in a probability space. Two classes of neural networks based on quantile and moment approximation are proposed to learn these functions and are theoretically supported by universal approximation theorems. By mixing the quantile and moment features in other new networks, we develop schemes that outperform existing networks on numerical test cases involving univariate distributions. For bivariate distributions, the moment neural network outperforms all other networks.
    
[^8]: 通过潜在空间探索和因果推断方法逼近未知的通信系统

    Approaching an unknown communication system by latent space exploration and causal inference. (arXiv:2303.10931v1 [stat.ML])

    [http://arxiv.org/abs/2303.10931](http://arxiv.org/abs/2303.10931)

    本文通过探索无监督深度生成模型的潜在空间来发现数据中有意义的属性，提出了一种极端值因果分离 (CDEV) 的方法，应用于测试鲸鱼通信系统并发现其中存在语法。

    

    本文提出了一种方法，通过探索无监督深度生成模型的潜在空间来发现数据中有意义的属性。我们将对单个潜在变量的操作与因果推断方法相结合，实现了一个称为极端值因果分离 (CDEV) 的方法，并展示了该方法对模型可解释性的洞察力。通过此技术，我们可以推断模型将未知数据编码为有意义的属性。我们将该方法应用于测试鲸鱼的通信系统中存在哪些有意义的属性，鲸鱼通信是最具有吸引力和研究不足的动物通信之一。我们训练了一个网络，该网络已被证明能够学习到有意义的语音表示，并测试是否可以利用这种无监督学习来解析另一个我们没有地面真相的声音通信系统的属性。所提出的技术表明，鲸鱼在其声音通信中存在语法，这是以前不知道的。

    This paper proposes a methodology for discovering meaningful properties in data by exploring the latent space of unsupervised deep generative models. We combine manipulation of individual latent variables to extreme values outside the training range with methods inspired by causal inference into an approach we call causal disentanglement with extreme values (CDEV) and show that this approach yields insights for model interpretability. Using this technique, we can infer what properties of unknown data the model encodes as meaningful. We apply the methodology to test what is meaningful in the communication system of sperm whales, one of the most intriguing and understudied animal communication systems. We train a network that has been shown to learn meaningful representations of speech and test whether we can leverage such unsupervised learning to decipher the properties of another vocal communication system for which we have no ground truth. The proposed technique suggests that sperm wh
    
[^9]: 低秩MDP下无奖励强化学习样本复杂度的改进

    Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs. (arXiv:2303.10859v1 [cs.LG])

    [http://arxiv.org/abs/2303.10859](http://arxiv.org/abs/2303.10859)

    本文提出了一种新的基于模型的算法RAFFLE，能够在低秩MDP下实现无奖励探索，并且具有显著改进的样本复杂度。

    

    在无奖励强化学习中，智能体首先在没有奖励信息的情况下探索环境，以便在任何给定的奖励下实现某些学习目标。本文侧重于低秩MDP模型下的无奖励强化学习，其中表示和线性权向量均未知。虽然针对无奖励低秩MDP提出了各种算法，但相应的样本复杂度仍远未达到令人满意的水平。本文首先提供了低秩MDP下的首个已知的样本复杂度下界，该下界意味着在低秩MDP下找到接近最优策略比在线性MDP下更加困难。随后，我们提出一种新颖的基于模型的算法RAFFLE，并且通过无奖励探索，它能够获得$\epsilon$-最优策略和$\epsilon$-准确的系统识别，且其样本复杂度显著优于以前的结果。

    In reward-free reinforcement learning (RL), an agent explores the environment first without any reward information, in order to achieve certain learning goals afterwards for any given reward. In this paper we focus on reward-free RL under low-rank MDP models, in which both the representation and linear weight vectors are unknown. Although various algorithms have been proposed for reward-free low-rank MDPs, the corresponding sample complexity is still far from being satisfactory. In this work, we first provide the first known sample complexity lower bound that holds for any algorithm under low-rank MDPs. This lower bound implies it is strictly harder to find a near-optimal policy under low-rank MDPs than under linear MDPs. We then propose a novel model-based algorithm, coined RAFFLE, and show it can both find an $\epsilon$-optimal policy and achieve an $\epsilon$-accurate system identification via reward-free exploration, with a sample complexity significantly improving the previous res
    
[^10]: 神经网络的校准

    Calibration of Neural Networks. (arXiv:2303.10761v1 [cs.NE])

    [http://arxiv.org/abs/2303.10761](http://arxiv.org/abs/2303.10761)

    本文概述了神经网络的置信度校准问题，并提供了现代校准技术的经验比较。

    

    在解决现实问题时，神经网络不仅需要进行准确的预测，还需要提供预测结果的置信度水平。模型的校准指的是估计的置信度与真实概率之间的接近程度。本文在神经网络的背景下提供了置信度校准问题的概述，并提供了校准方法的经验比较。我们分析了问题陈述、校准定义以及对模型是否校准良好的可视化和标量度量的不同方法。我们审查了基于后处理或需要改变训练的现代校准技术。实证实验涵盖各种数据集和模型，根据不同的标准比较校准方法。

    Neural networks solving real-world problems are often required not only to make accurate predictions but also to provide a confidence level in the forecast. The calibration of a model indicates how close the estimated confidence is to the true probability. This paper presents a survey of confidence calibration problems in the context of neural networks and provides an empirical comparison of calibration methods. We analyze problem statement, calibration definitions, and different approaches to evaluation: visualizations and scalar measures that estimate whether the model is well-calibrated. We review modern calibration techniques: based on post-processing or requiring changes in training. Empirical experiments cover various datasets and models, comparing calibration methods according to different criteria.
    
[^11]: 平稳随机凸优化中GD和SGD的泛化下界降低

    Lower Generalization Bounds for GD and SGD in Smooth Stochastic Convex Optimization. (arXiv:2303.10758v1 [cs.LG])

    [http://arxiv.org/abs/2303.10758](http://arxiv.org/abs/2303.10758)

    本论文证明了在平稳随机凸优化中，GD和SGD的泛化下界可以降低，并且长时间的训练可能导致更差的泛化能力，这与其他研究成果不同。

    

    最近，学习理论界在刻画一般凸损失梯度方法的泛化误差方面取得了进展。本文侧重于讨论在泛化光滑随机凸优化（SCO）问题中训练时间如何影响泛化能力。我们首先为一般的不可实现SCO问题提供了严格的下界。此外，现有的上界结果表明，假设损失可实现（即最优解同时最小化所有数据点）可以提高样本复杂度。但是，当训练时间长且缺乏下界时，这种改进会受到损害。我们对此进行了研究，提供了对于梯度下降（GD）和随机梯度下降（SGD）在两种可实现情况下的过量风险下界：1）实现需$T = O(n)$，和（2）实现需$T = \Omega(n)$，其中$T$表示训练迭代次数，$n$为训练数据集的大小。这些下界的证明使用了来自优化的现代工具，包括对偶理论和镜像下降。我们的结果表明，在可实现的SCO中，更长的训练时间可能会导致更差的泛化，这与文献中的先前发现形成鲜明对比。我们还提供了支持我们结果的数值实验。

    Recent progress was made in characterizing the generalization error of gradient methods for general convex loss by the learning theory community. In this work, we focus on how training longer might affect generalization in smooth stochastic convex optimization (SCO) problems. We first provide tight lower bounds for general non-realizable SCO problems. Furthermore, existing upper bound results suggest that sample complexity can be improved by assuming the loss is realizable, i.e. an optimal solution simultaneously minimizes all the data points. However, this improvement is compromised when training time is long and lower bounds are lacking. Our paper examines this observation by providing excess risk lower bounds for gradient descent (GD) and stochastic gradient descent (SGD) in two realizable settings: 1) realizable with $T = O(n)$, and (2) realizable with $T = \Omega(n)$, where $T$ denotes the number of training iterations and $n$ is the size of the training dataset. These bounds are 
    
[^12]: 异质性功能数据的混合分割模型

    Mixture of segmentation for heterogeneous functional data. (arXiv:2303.10712v1 [stat.ME])

    [http://arxiv.org/abs/2303.10712](http://arxiv.org/abs/2303.10712)

    本文提出了一种混合分割模型，可以处理异质性功能数据，通过动态规划的EM算法近似最大似然估计器，方法在模拟与真实数据集上得到验证。

    

    本文针对时间和人口异质性的功能数据提出了一种混合分割模型，旨在保持功能结构的同时表示异质性。 讨论了最大似然估计器的可辨识性和一致性，并采用动态规划的EM算法来近似最大似然估计器。 该方法在模拟数据上进行了说明，并在用电量真实数据集上得到了应用。

    In this paper we consider functional data with heterogeneity in time and in population. We propose a mixture model with segmentation of time to represent this heterogeneity while keeping the functional structure. Maximum likelihood estimator is considered, proved to be identifiable and consistent. In practice, an EM algorithm is used, combined with dynamic programming for the maximization step, to approximate the maximum likelihood estimator. The method is illustrated on a simulated dataset, and used on a real dataset of electricity consumption.
    
[^13]: 通过领域一致性预测改进深度分类器的不确定性量化：新的算法和理论分析

    Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis. (arXiv:2303.10694v1 [cs.LG])

    [http://arxiv.org/abs/2303.10694](http://arxiv.org/abs/2303.10694)

    本文提出了一种新算法Neighborhood Conformal Prediction(NCP)，可以使用神经网络学习到的表示提高深度分类器的确定性量化效率；我们从理论上证明了NCP可以产生更小的预测集。

    

    在高风险实际应用中安全部署深度神经网络需要有理论基础的确定性量化。对于分类任务，符合性预测（CP）是一种可以以用户指定的覆盖率（即真实类标签包含在高概率内）来确定深度模型的不确定性的原则性框架。本文提出了一种新的算法——领域一致性预测（NCP），以改进由CP进行的深度分类器的确定性量化效率（即减少预测集大小）。NCP的关键思想是使用神经网络学习到的表示来识别给定测试输入的k个最近邻校准示例，并分配与其距离成比例的重要性权重以创建自适应预测集。我们从理论上证明了，如果神经网络学习到的数据表示满足一些温和的条件，NCP将产生更小的预测集。

    Safe deployment of deep neural networks in high-stake real-world applications requires theoretically sound uncertainty quantification. Conformal prediction (CP) is a principled framework for uncertainty quantification of deep models in the form of prediction set for classification tasks with a user-specified coverage (i.e., true class label is contained with high probability). This paper proposes a novel algorithm referred to as Neighborhood Conformal Prediction (NCP) to improve the efficiency of uncertainty quantification from CP for deep classifiers (i.e., reduce prediction set size). The key idea behind NCP is to use the learned representation of the neural network to identify k nearest-neighbors calibration examples for a given testing input and assign them importance weights proportional to their distance to create adaptive prediction sets. We theoretically show that if the learned data representation of the neural network satisfies some mild conditions, NCP will produce smaller p
    
[^14]: 可验证变分蒙特卡罗方法的收敛性

    Provable Convergence of Variational Monte Carlo Methods. (arXiv:2303.10599v1 [stat.ML])

    [http://arxiv.org/abs/2303.10599](http://arxiv.org/abs/2303.10599)

    本文提出了一种对变分蒙特卡罗（VMC）方法收敛性的可验证方法，在假设局部能量是次指数的条件下，使用非平稳马尔可夫链的Bernstein不等式推导出了MCMC估计量的误差界限，证明了VMC具有一阶收敛速率，在某些情况下，收敛速率是最优的。

    

    变分蒙特卡罗（VMC）是一种用于计算量子多体问题基态能量的有前途的方法，并由于机器学习的发展而越来越受到关注。最近的VMC方法以神经网络构建试探波函数，使用马尔可夫链蒙特卡罗（MCMC）采样量子态，并用随机梯度下降（SGD）方法训练神经网络。然而，当SGD与MCMC采样与设计良好的试探波函数交互作用时，VMC的理论收敛性仍然未知。由于MCMC降低了梯度估计的难度，实际上不可避免地存在偏差。此外，局部能量可能是无界的，这使得分析MCMC采样的误差更加困难。因此，我们假设局部能量是次指数的，并使用非平稳马尔可夫链的Bernstein不等式推导出MCMC估计量的误差界限。因此，在温和假设下，VMC被证明具有一阶收敛速率。此外，我们还展示了在某些情况下，收敛速率是最优的。

    The Variational Monte Carlo (VMC) is a promising approach for computing the ground state energy of many-body quantum problems and attracts more and more interests due to the development of machine learning. The recent paradigms in VMC construct neural networks as trial wave functions, sample quantum configurations using Markov chain Monte Carlo (MCMC) and train neural networks with stochastic gradient descent (SGD) method. However, the theoretical convergence of VMC is still unknown when SGD interacts with MCMC sampling given a well-designed trial wave function. Since MCMC reduces the difficulty of estimating gradients, it has inevitable bias in practice. Moreover, the local energy may be unbounded, which makes it harder to analyze the error of MCMC sampling. Therefore, we assume that the local energy is sub-exponential and use the Bernstein inequality for non-stationary Markov chains to derive error bounds of the MCMC estimator. Consequently, VMC is proven to have a first order conver
    
[^15]: 黑盒变分贝叶斯推理的实用匹配梯度方差界限

    Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference. (arXiv:2303.10472v1 [cs.LG])

    [http://arxiv.org/abs/2303.10472](http://arxiv.org/abs/2303.10472)

    本文表明黑盒变分推理（BBVI）满足SGD文献中的ABC条件，该结果适用于平滑和二次增长的对数似然函数，同时我们的结果推广到广泛应用于BBVI实践中的非线性协方差参数化。

    

    理解黑盒变分推理（BBVI）的梯度方差是建立其收敛性和算法改进的关键一步。然而，现有研究尚未表明BBVI的梯度方差满足用于研究随机梯度下降（SGD）收敛的条件。在本文中，我们展示了当应用于平滑和二次增长的对数似然函数时，BBVI满足与SGD文献中使用的ABC条件相匹配的界限。我们的结果推广到广泛应用于BBVI实践中的非线性协方差参数化。此外，我们表明，平均场参数化的方差具有经过验证的优越维度依赖性。

    Understanding the gradient variance of black-box variational inference (BBVI) is a crucial step for establishing its convergence and developing algorithmic improvements. However, existing studies have yet to show that the gradient variance of BBVI satisfies the conditions used to study the convergence of stochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show that BBVI satisfies a matching bound corresponding to the $ABC$ condition used in the SGD literature when applied to smooth and quadratically-growing log-likelihoods. Our results generalize to nonlinear covariance parameterizations widely used in the practice of BBVI. Furthermore, we show that the variance of the mean-field parameterization has provably superior dimensional dependence.
    
[^16]: 逆卡尔曼滤波器和逆多面积积分卡尔曼滤波器

    Inverse Cubature and Quadrature Kalman filters. (arXiv:2303.10322v1 [math.OC])

    [http://arxiv.org/abs/2303.10322](http://arxiv.org/abs/2303.10322)

    本文提出了逆多面积积分卡尔曼滤波器（I-CKF）和逆多项式积分卡尔曼滤波器（I-QKF），用于解决高度非线性的系统模型的逆认知问题，并在指数-平均-二次有界性意义下推导了其的随机稳定性条件。数值实验证明了其高的估计精度和递归Cram\'{e}r-Rao下界相当。

    

    反对抗系统研究的最新进展已经导致开发了逆随机滤波器，这些滤波器被防御者用来推断其对手可能学到的信息。早期的作品通过针对线性和非线性高斯状态空间模型分别提出了逆卡尔曼滤波器（I-KF）和逆扩展KF（I-EKF）来解决这个逆认知问题。然而，在实践中，很多反对抗性设置会涉及高度非线性的系统模型，其中EKF的线性化常常会失败。在本文中，我们考虑了有效的数值积分技术来解决这种非线性问题，并因此开发了逆多面积积分卡尔曼滤波器（I-CKF）和逆多项式积分卡尔曼滤波器（I-QKF）。我们在指数-平均-二次有界性意义下推导了所提出的滤波器的随机稳定性条件。数值实验证明了我们的I-CKF和I-QKF的估计精度，跟递归Cram\'{e}r-Rao下界作为基准。

    Recent developments in counter-adversarial system research have led to the development of inverse stochastic filters that are employed by a defender to infer the information its adversary may have learned. Prior works addressed this inverse cognition problem by proposing inverse Kalman filter (I-KF) and inverse extended KF (I-EKF), respectively, for linear and non-linear Gaussian state-space models. However, in practice, many counter-adversarial settings involve highly non-linear system models, wherein EKF's linearization often fails. In this paper, we consider the efficient numerical integration techniques to address such nonlinearities and, to this end, develop inverse cubature KF (I-CKF) and inverse quadrature KF (I-QKF). We derive the stochastic stability conditions for the proposed filters in the exponential-mean-squared-boundedness sense. Numerical experiments demonstrate the estimation accuracy of our I-CKF and I-QKF with the recursive Cram\'{e}r-Rao lower bound as a benchmark.
    
[^17]: 一种利用统计框架进行高维表型GWAS的摘要统计学方法，以代谢物GWAS为例

    A statistical framework for GWAS of high dimensional phenotypes using summary statistics, with application to metabolite GWAS. (arXiv:2303.10221v1 [stat.ME])

    [http://arxiv.org/abs/2303.10221](http://arxiv.org/abs/2303.10221)

    本文提出了一种统计学方法，可以使用摘要统计数据对高维表型进行GWAS，该方法明确建模多效性，具有快速计算能力并可以使用生物学先验信息。

    

    近年来，遗传和高维生物银行和“组学”数据的爆炸式增长为研究人员提供了研究数百到数千个相关表型的共同遗传起源（多效性）的机会。然而，现有的多表型全基因组关联研究（GWAS）方法并未建模多效性，只适用于少量表型，或无法进行推断。此外，很少观测到原始遗传和表型数据，这意味着必须在高维度的GWAS摘要统计信息上进行分析，而这些摘要统计信息在高维度下的统计特性还不够理解。因此，我们开发了一种新的模型、理论框架和一套方法，用于使用摘要统计学数据进行高维表型GWAS的贝叶斯推断，明确地建模多效性，促进快速计算，并有助于使用生物信息先验。我们通过将其应用于代谢物GWAS，证明了我们的程序的实用性。

    The recent explosion of genetic and high dimensional biobank and 'omic' data has provided researchers with the opportunity to investigate the shared genetic origin (pleiotropy) of hundreds to thousands of related phenotypes. However, existing methods for multi-phenotype genome-wide association studies (GWAS) do not model pleiotropy, are only applicable to a small number of phenotypes, or provide no way to perform inference. To add further complication, raw genetic and phenotype data are rarely observed, meaning analyses must be performed on GWAS summary statistics whose statistical properties in high dimensions are poorly understood. We therefore developed a novel model, theoretical framework, and set of methods to perform Bayesian inference in GWAS of high dimensional phenotypes using summary statistics that explicitly model pleiotropy, beget fast computation, and facilitate the use of biologically informed priors. We demonstrate the utility of our procedure by applying it to metaboli
    
[^18]: 通过图表自编码器进行内部数据结构的深度非参数估计：广义误差和鲁棒性。

    Deep Nonparametric Estimation of Intrinsic Data Structures by Chart Autoencoders: Generalization Error and Robustness. (arXiv:2303.09863v1 [stat.ML])

    [http://arxiv.org/abs/2303.09863](http://arxiv.org/abs/2303.09863)

    本文介绍了一种图表自编码器用于深度非参数估计内部数据结构，并证明了其广义误差保证和去噪能力。

    

    自编码器在学习高维数据的低维潜在特征方面已经在各种应用中展现出了显着的成功。假设数据在低维流形附近采样，我们采用图表自编码器，将数据编码为一组图表上的低维潜在特征，从而保留了数据流形的拓扑和几何。我们的论文为图表自编码器的广义误差建立了统计保证，并且通过考虑$d$维流形上$n$个带噪声训练样本及其无噪声对应物来展示它们的去噪能力。通过训练自编码器，我们展示了图表自编码器能够有效地去噪输入数据和正态分布噪声。我们证明，在适当的网络架构下，图表自编码器实现了一个大致为$\displaystyle n^{-\frac{2}{d+2}}\log^4 n$阶的平方广义误差，该误差取决于流形的内在维度，并且仅弱依赖于样本数量$n$。

    Autoencoders have demonstrated remarkable success in learning low-dimensional latent features of high-dimensional data across various applications. Assuming that data are sampled near a low-dimensional manifold, we employ chart autoencoders, which encode data into low-dimensional latent features on a collection of charts, preserving the topology and geometry of the data manifold. Our paper establishes statistical guarantees on the generalization error of chart autoencoders, and we demonstrate their denoising capabilities by considering $n$ noisy training samples, along with their noise-free counterparts, on a $d$-dimensional manifold. By training autoencoders, we show that chart autoencoders can effectively denoise the input data with normal noise. We prove that, under proper network architectures, chart autoencoders achieve a squared generalization error in the order of $\displaystyle n^{-\frac{2}{d+2}}\log^4 n$, which depends on the intrinsic dimension of the manifold and only weakly
    
[^19]: 多维数组的多切片聚类中的DBSCAN算法

    DBSCAN of Multi-Slice Clustering for three-order Tensor. (arXiv:2303.07768v1 [cs.LG])

    [http://arxiv.org/abs/2303.07768](http://arxiv.org/abs/2303.07768)

    本文提出了 MSC-DBSCAN扩展算法，可以在三元聚类中从数据中提取不同子空间的不同切片聚类，并可以获得与 MSC 算法在处理秩一张量数据时相同的解决方案。

    

    对于三维数据的三元聚类，现有的几种方法需要指定每个维度的聚类大小或聚类数量。为了解决这个问题，三元聚类(MSC)算法可以在低维子空间中找到保留信号的切片以便基于相似度阈值找到聚类。本文提出了 MSC-DBSCAN扩展算法以从数据中提取位于不同子空间的不同切片聚类(如果数据集是r个秩一张量(r>1)的总和)。我们的算法使用和 MSC 算法相同的输入，可以在处理秩一张量数据时与 MSC 算法获得相同的解决方案。

    Several methods for triclustering three-dimensional data require the cluster size or the number of clusters in each dimension to be specified. To address this issue, the Multi-Slice Clustering (MSC) for 3-order tensor finds signal slices that lie in a low dimensional subspace for a rank-one tensor dataset in order to find a cluster based on the threshold similarity. We propose an extension algorithm called MSC-DBSCAN to extract the different clusters of slices that lie in the different subspaces from the data if the dataset is a sum of r rank-one tensor (r > 1). Our algorithm uses the same input as the MSC algorithm and can find the same solution for rank-one tensor data as MSC.
    
[^20]: SurvLIMEpy: 一个实现了SurvLIME算法的Python包

    SurvLIMEpy: A Python package implementing SurvLIME. (arXiv:2302.10571v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.10571](http://arxiv.org/abs/2302.10571)

    本文介绍了一个名为SurvLIMEpy的Python包，它实现了一种算法，可以计算适用于建模生存分析数据的机器学习算法的局部特征重要性，并支持各种生存模型。

    

    本文介绍SurvLIMEpy，这是一个开源的Python包，实现了SurvLIME算法。该算法可以计算适用于建模生存分析数据的机器学习算法的局部特征重要性。我们的实现利用了并行化范例，因为所有计算都以矩阵方式执行，从而加快了执行时间。此外，SurvLIMEpy还提供了可视化工具来更好地理解算法的结果。该包支持各种生存模型，从Cox比例风险模型到DeepHit或DeepSurv等深度学习模型。本文介绍了两种类型的实验。首先，通过模拟数据，我们研究了算法捕获特征重要性的能力。其次，在使用三个开源生存数据集以及一组生存算法时，我们展示了SurvLIMEpy在应用于不同数据集时的表现。

    In this paper we present SurvLIMEpy, an open-source Python package that implements the SurvLIME algorithm. This method allows to compute local feature importance for machine learning algorithms designed for modelling Survival Analysis data. Our implementation takes advantage of the parallelisation paradigm as all computations are performed in a matrix-wise fashion which speeds up execution time. Additionally, SurvLIMEpy assists the user with visualization tools to better understand the result of the algorithm. The package supports a wide variety of survival models, from the Cox Proportional Hazards Model to deep learning models such as DeepHit or DeepSurv. Two types of experiments are presented in this paper. First, by means of simulated data, we study the ability of the algorithm to capture the importance of the features. Second, we use three open source survival datasets together with a set of survival algorithms in order to demonstrate how SurvLIMEpy behaves when applied to differen
    
[^21]: 通过深度学生机器实现空间异质性学习

    Spatially heterogeneous learning by a deep student machine. (arXiv:2302.07419v3 [cond-mat.dis-nn] UPDATED)

    [http://arxiv.org/abs/2302.07419](http://arxiv.org/abs/2302.07419)

    本论文研究了一种深度学生机器的教师-学生设置，通过学生机器的集合来研究由具有大量可调参数的DNN的监督学习。研究表明DNN的学习在网络空间中相当异质。

    

    尽管深度神经网络（DNN）取得了非凡的成功，但由于具有大量可调参数，其仍然是黑匣子。为了研究DNN的隐藏层，本文通过一种统计力学方法称为教师-学生设置，研究了由宽度为N，深度为L，由具有c个输入的感知机组成的DNN的监督学习。我们考虑了一个学生机器的集合，该集合可以精确重现由教师机器提供的M组N维输入/输出关系。我们使用副本方法（H. Yoshino（2020））理论分析了集合，并进行了贪婪的Monte Carlo模拟。对于高维数据$N \gg 1$，理论在'密集极限' $N \gg c \gg 1$ 和 $M \gg 1$ 且固定$\alpha=M/c$时变得精确。理论和模拟都表明，DNN的学习在网络空间中相当异质：机器的配置在靠近输入/输出的层内更加相关。

    Despite the spectacular successes, deep neural networks (DNN) with a huge number of adjustable parameters remain largely black boxes. To shed light on the hidden layers of DNN, we study supervised learning by a DNN of width $N$ and depth $L$ consisting of perceptrons with $c$ inputs by a statistical mechanics approach called the teacher-student setting. We consider an ensemble of student machines that exactly reproduce $M$ sets of $N$ dimensional input/output relations provided by a teacher machine. We analyze the ensemble theoretically using a replica method (H. Yoshino (2020)) and numerically performing greedy Monte Carlo simulations. The replica theory which works on high dimensional data $N \gg 1$ becomes exact in 'dense limit' $N \gg c \gg 1$ and $M \gg 1$ with fixed $\alpha=M/c$. Both the theory and the simulation suggest learning by the DNN is quite heterogeneous in the network space: configurations of the machines are more correlated within the layers closer to the input/output
    
[^22]: 浅层视觉Transformer的理论理解：学习、泛化和样本复杂性的分析

    A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity. (arXiv:2302.06015v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06015](http://arxiv.org/abs/2302.06015)

    本文提供了第一份对于浅层ViT进行训练的理论分析，证明了使用SGD训练会产生稀疏的注意力图，目前的样本复杂度与标记相关令牌的分数倒数、标记级别的令牌噪声水平和初始模型错误呈正相关关系。

    

    近年来，具有自我注意机制的视觉Transformer（ViTs）在许多视觉任务中取得了巨大的实证成功。然而，由于层间的非凸交互，理论上的学习和泛化分析大多是难以理解的。本文提供了对于一项分类任务，使用一个自我注意层和两层感知机的浅层ViT进行训练的第一篇理论分析，建立了对于数据模型的描述，该模型可以同时表征标记相关和标记不相关的令牌。我们界定了达到零泛化误差的样本复杂性。我们的样本复杂性限制与标记相关令牌的部分倒数、标记级别的令牌噪声水平和初始模型误差呈正相关。我们还证明了使用随机梯度下降SGD（stochastic gradient descent）进行训练过程会导致稀疏的注意力图，这是对于注意力成功的一种形式证明。此外，本文指出，适当的令牌确定是确保实现最优性能的关键。

    Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a shallow ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover, this paper indicates that a proper token spa
    
[^23]: 使用来自成对或$K$元比较的人类反馈的规范强化学习

    Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons. (arXiv:2301.11270v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11270](http://arxiv.org/abs/2301.11270)

    该论文提供了带有人类反馈强化学习问题的理论框架，证明了最大似然估计在Bradley-Terry-Luce和Plackett-Luce模型下收敛。此外，提出了在一定的覆盖假设下，基于悲观估计的MLE提供了性能更好的策略。在证明了真实MLE和以成对比较形式替代的备选MLE都可以在PL模型下收敛的同时，也表明了真实MLE的高效性。这些结果为RLHF算法提供了新的见解，并统一了RLHF问题和IRL问题。

    

    我们为带有人类反馈的强化学习问题提供了一个理论框架。我们的分析表明，当真实奖励函数为线性函数时，最大似然估计（MLE）在Bradley-Terry-Luce（BTL）模型和Plackett-Luce（PL）模型下均收敛。然而，我们发现当基于学得的奖励模型训练策略时，MLE会失败，而基于悲观估计的MLE在一定的覆盖假设下提供性能更好的策略。此外，我们证明在PL模型下，真实MLE和将$k$元比较拆分为成对比较的备选MLE都收敛。而真实MLE是渐近更为高效的。我们的结果验证了现有RLHF算法（如InstructGPT）的实验成功，并为算法设计提供了新的见解。此外，我们的结果统一了RLHF问题和最大熵反向强化学习(IRL)问题，并为其提供了第一个样本复杂度界。

    We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). Our analysis shows that when the true reward function is linear, the widely used maximum likelihood estimator (MLE) converges under both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. However, we show that when training a policy based on the learned reward model, MLE fails while a pessimistic MLE provides policies with improved performance under certain coverage assumptions. Additionally, we demonstrate that under the PL model, the true MLE and an alternative MLE that splits the $K$-wise comparison into pairwise comparisons both converge. Moreover, the true MLE is asymptotically more efficient. Our results validate the empirical success of existing RLHF algorithms in InstructGPT and provide new insights for algorithm design. Furthermore, our results unify the problem of RLHF and max-entropy Inverse Reinforcement Learning (IRL), and provide the first sample complexity bound fo
    
[^24]: 异方差高斯序列模型中的稀疏信号检测: 尖锐的极小极大速率

    Sparse Signal Detection in Heteroscedastic Gaussian Sequence Models: Sharp Minimax Rates. (arXiv:2211.08580v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2211.08580](http://arxiv.org/abs/2211.08580)

    该论文探究了异方差高斯序列模型中的稀疏信号检测问题，提出了一种最小极大分离半径的上下界以及相应的测试，展示了关于稀疏度、距离衡量和异方差性质的新的相变特性。

    

    在一个具有未知均值 $\theta \in \mathbb R^d$ 和已知协方差矩阵 $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$ 的异质高斯序列模型中，我们研究了针对稀疏备选方案的信号检测问题，对于已知的稀疏度 $s$。也就是说，我们确定了有多大的 $\epsilon^*>0$，以便可以区分出零假设 $\theta=0$ 和由 $\mathbb R^d$ 中 $s$-稀疏向量组成的备选解，它们通过 $L^t$ 范数 ($t \in [1,\infty]$) 与 $0$ 分开至少 $\epsilon^*$ 的概率很高。我们找到了极小极大分离半径 $\epsilon^*$ 的极小极大上下界，并证明它们总是匹配的。我们还推导了相应的极小极大测试来实现这些界。我们的结果揭示了关于 $\epsilon^*$ 行为的新的相变特性，这取决于稀疏程度、$L^t$指标和 $\Sigma$ 的异方差特性。在欧几里得（即 $L^2$）分离的情况下，我们的框架允许我们恢复以前的结果，并确定了相应的最优收敛速率。

    Given a heterogeneous Gaussian sequence model with unknown mean $\theta \in \mathbb R^d$ and known covariance matrix $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$, we study the signal detection problem against sparse alternatives, for known sparsity $s$. Namely, we characterize how large $\epsilon^*>0$ should be, in order to distinguish with high probability the null hypothesis $\theta=0$ from the alternative composed of $s$-sparse vectors in $\mathbb R^d$, separated from $0$ in $L^t$ norm ($t \in [1,\infty]$) by at least $\epsilon^*$. We find minimax upper and lower bounds over the minimax separation radius $\epsilon^*$ and prove that they are always matching. We also derive the corresponding minimax tests achieving these bounds. Our results reveal new phase transitions regarding the behavior of $\epsilon^*$ with respect to the level of sparsity, to the $L^t$ metric, and to the heteroscedasticity profile of $\Sigma$. In the case of the Euclidean (i.e. $L^2$) separation,
    
[^25]: 自适应合并下的纵向网络有效估计

    Efficient Estimation for Longitudinal Network via Adaptive Merging. (arXiv:2211.07866v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.07866](http://arxiv.org/abs/2211.07866)

    本文提出了一个有效的纵向网络估计框架，利用自适应合并、张量分解和点过程等方法来减少估计偏差和方差。

    

    纵向网络由多个节点之间的时间边序列组成，其中时间边在实时中被观察到。随着在线社交平台和电子商务的兴起，它已经变得普遍，但在文献中往往被忽略。本文提出了一个有效的纵向网络估计框架，利用自适应网络合并、张量分解和点过程的优势。它合并相邻的稀疏网络，以扩大观测边的数量并减少估计方差，同时通过利用本地时间结构进行自适应网络邻域控制引入的估计偏差。提出了一个投影梯度下降算法来促进估计，其中每次迭代的估计错误上界被建立。进行了彻底的分析，以量化所提出方法的渐近行为，结果表明它可以显着减少估计偏差。

    Longitudinal network consists of a sequence of temporal edges among multiple nodes, where the temporal edges are observed in real time. It has become ubiquitous with the rise of online social platform and e-commerce, but largely under-investigated in literature. In this paper, we propose an efficient estimation framework for longitudinal network, leveraging strengths of adaptive network merging, tensor decomposition and point process. It merges neighboring sparse networks so as to enlarge the number of observed edges and reduce estimation variance, whereas the estimation bias introduced by network merging is controlled by exploiting local temporal structures for adaptive network neighborhood. A projected gradient descent algorithm is proposed to facilitate estimation, where the upper bound of the estimation error in each iteration is established. A thorough analysis is conducted to quantify the asymptotic behavior of the proposed method, which shows that it can significantly reduce the
    
[^26]: 隐变量高斯过程模型的完全贝叶斯推断

    Fully Bayesian inference for latent variable Gaussian process models. (arXiv:2211.02218v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.02218](http://arxiv.org/abs/2211.02218)

    隐变量高斯过程模型通过将定性因素映射到底层隐变量的方式解决了标准高斯过程无法适应定性输入的问题。本文提出了一种考虑隐变量估计不确定性的完全贝叶斯方法，支持通过隐变量可视化定性输入的效果。

    

    实际工程和科学应用常常涉及一个或多个定性输入。然而，标准高斯过程（GP）不能直接适应定性输入。最近引入的隐变量高斯过程（LVGP）通过首先将每个定性因素映射到底层隐变量（LV），然后在这些LV上使用任何标准GP协方差函数来解决这个问题。通过最大似然估计，对LV进行估计，然后将其插入到预测表达式中。然而，这种插入方法不考虑LV估计的不确定性，而这种不确定性在训练数据有限的情况下可能会很大。在这项工作中，我们为LVGP模型开发了一个完全贝叶斯方法，并通过其LV可视化了定性输入的效果。我们还开发了适用于扩展LVGP和LVGP超参数的完全贝叶斯推断的近似方法。我们进行了数值研究。

    Real engineering and scientific applications often involve one or more qualitative inputs. Standard Gaussian processes (GPs), however, cannot directly accommodate qualitative inputs. The recently introduced latent variable Gaussian process (LVGP) overcomes this issue by first mapping each qualitative factor to underlying latent variables (LVs), and then uses any standard GP covariance function over these LVs. The LVs are estimated similarly to the other GP hyperparameters through maximum likelihood estimation, and then plugged into the prediction expressions. However, this plug-in approach will not account for uncertainty in estimation of the LVs, which can be significant especially with limited training data. In this work, we develop a fully Bayesian approach for the LVGP model and for visualizing the effects of the qualitative inputs via their LVs. We also develop approximations for scaling up LVGPs and fully Bayesian inference for the LVGP hyperparameters. We conduct numerical studi
    
[^27]: 对称（乐观）自然策略梯度的参数收敛性多智能体学习

    Symmetric (Optimistic) Natural Policy Gradient for Multi-agent Learning with Parameter Convergence. (arXiv:2210.12812v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.12812](http://arxiv.org/abs/2210.12812)

    本文研究了多智能体学习中的机器人学习算法，指出了香草自然策略梯度算法可能因具有不收敛的参数而存在学习不稳定性问题，并提出了新的NPG算法变种以解决此问题。

    

    在强化学习中，多智能体互动越来越重要，并且策略梯度方法的理论基础引起了人们的浓厚兴趣。本文研究了多智能体学习中自然策略梯度（NPG）算法的全局收敛性。我们首先展示了香草NPG可能没有参数收敛，即参数化策略的向量的收敛，即使成本被规则化（在文献中使策略空间有强的收敛保证）。这些非收敛的参数导致学习中的稳定性问题，在函数逼近的情况下尤为重要，在这种情况下，我们只能处理低维参数，而不是高维策略。然后我们针对几种标准多智能体学习场景提出了NPG算法的变种：两个玩家的零和矩阵和马尔可夫博弈，以及多个玩家的单调博弈，其具有全局最后迭代收敛性。

    Multi-agent interactions are increasingly important in the context of reinforcement learning, and the theoretical foundations of policy gradient methods have attracted surging research interest. We investigate the global convergence of natural policy gradient (NPG) algorithms in multi-agent learning. We first show that vanilla NPG may not have parameter convergence, i.e., the convergence of the vector that parameterizes the policy, even when the costs are regularized (which enabled strong convergence guarantees in the policy space in the literature). This non-convergence of parameters leads to stability issues in learning, which becomes especially relevant in the function approximation setting, where we can only operate on low-dimensional parameters, instead of the high-dimensional policy. We then propose variants of the NPG algorithm, for several standard multi-agent learning scenarios: two-player zero-sum matrix and Markov games, and multi-player monotone games, with global last-iter
    
[^28]: 基于特征符合预测的预测推断

    Predictive Inference with Feature Conformal Prediction. (arXiv:2210.00173v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00173](http://arxiv.org/abs/2210.00173)

    本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。

    

    符合预测是一种无分布技术，用于建立有效的预测间隔。虽然传统上人们在输出空间中进行符合预测，但这并不是唯一的可能性。在本文中，我们提出了基于特征的符合预测，通过利用深度表示学习的归纳偏置，扩展了符合预测对语义特征空间的范围。从理论上讲，我们证明了基于特征的符合预测在温和假设下可以证明优于常规符合预测。我们的方法不仅可以与普通符合预测结合使用，而且可以与其他自适应符合预测方法结合使用。除了现有预测推断基准测试的实验外，我们还展示了该方法在大规模任务（如ImageNet分类和Cityscapes图像分割）上的最先进性能。

    Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on large-scale tasks such as ImageNet classification and Cityscapes image segmentation.
    
[^29]: 存在扰动情况下强化学习的安全探索方法

    Safe Exploration Method for Reinforcement Learning under Existence of Disturbance. (arXiv:2209.15452v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.15452](http://arxiv.org/abs/2209.15452)

    本文提出了一种能够在存在扰动情况下安全进行强化学习探索的方法，该方法利用了所控制对象和扰动的部分先验知识，可以保证以预先指定的概率满足显式状态约束。

    

    近年来，强化学习算法的快速发展在许多领域为我们提供了新的可能性。然而，由于其探索特性，当我们将这些算法应用于安全关键问题，特别是在实际环境中时，我们必须考虑风险。本文提出了一种涉及存在扰动时强化学习中的安全探索问题的方法。我们将学习过程中的安全性定义为以状态明确定义的限制条件的满足，并提出了一种安全探索方法，该方法利用所控制对象和扰动的部分先验知识。即使所控制对象暴露于遵循正态分布的随机扰动，该方法也能保证以预先指定的概率满足显式状态约束。在理论上，我们引入了足够的条件来构建不包含传统探索方法中的探索因素的保守输入。在摆动任务的模拟实验中，我们证明了所提出的方法可以在满足显式约束条件的情况下安全地学习。

    Recent rapid developments in reinforcement learning algorithms have been giving us novel possibilities in many fields. However, due to their exploring property, we have to take the risk into consideration when we apply those algorithms to safety-critical problems especially in real environments. In this study, we deal with a safe exploration problem in reinforcement learning under the existence of disturbance. We define the safety during learning as satisfaction of the constraint conditions explicitly defined in terms of the state and propose a safe exploration method that uses partial prior knowledge of a controlled object and disturbance. The proposed method assures the satisfaction of the explicit state constraints with a pre-specified probability even if the controlled object is exposed to a stochastic disturbance following a normal distribution. As theoretical results, we introduce sufficient conditions to construct conservative inputs not containing an exploring aspect used in th
    
[^30]: 一种图上的多臂赌博机学习方法

    Multi-armed Bandit Learning on a Graph. (arXiv:2209.09419v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.09419](http://arxiv.org/abs/2209.09419)

    本文提出了一种基于乐观原则和离线图形规划算法的学习算法G-UCB，能够平衡长期探索利用，用于解决一种名为图赌博机的MAB扩展，从而获得最大化的收益。

    

    多臂赌博机问题是一个简单而强大的框架，在不确定性决策方面已经得到广泛研究。在许多现实世界的应用中，例如机器人应用中，选择一个臂对应于限制下一个可用臂（动作）的选择。出于这个目的，我们研究了一种名为图赌博机的MAB扩展，在此过程中，智能体从不同节点中收集奖励以获得最大化的收益。图定义了智能体在每一步中选择下一个可用节点的自由度。我们假设图的结构是完全可用的，但奖励分布是未知的。基于离线图形规划算法和乐观原则，我们设计了一种学习算法G-UCB，平衡长期探索利用使用乐观原则。我们证明了我们提出的算法达到了$O(\sqrt{|S|T\log(T)}+D|S|\log T)$的学习遗憾。其中$|S|$是

    The multi-armed bandit(MAB) problem is a simple yet powerful framework that has been extensively studied in the context of decision-making under uncertainty. In many real-world applications, such as robotic applications, selecting an arm corresponds to a physical action that constrains the choices of the next available arms (actions). Motivated by this, we study an extension of MAB called the graph bandit, where an agent travels over a graph to maximize the reward collected from different nodes. The graph defines the agent's freedom in selecting the next available nodes at each step. We assume the graph structure is fully available, but the reward distributions are unknown. Built upon an offline graph-based planning algorithm and the principle of optimism, we design a learning algorithm, G-UCB, that balances long-term exploration-exploitation using the principle of optimism. We show that our proposed algorithm achieves $O(\sqrt{|S|T\log(T)}+D|S|\log T)$ learning regret, where $|S|$ is 
    
[^31]: 逆强化学习的主动探索方法

    Active Exploration for Inverse Reinforcement Learning. (arXiv:2207.08645v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.08645](http://arxiv.org/abs/2207.08645)

    AceIRL提出了一种新的逆强化学习算法，通过主动探索来学习奖励函数和策略，在不需要环境生成模型的情况下，能够确定可行奖励函数的置信区间，并找到侧重于环境中最有信息的区域的探索策略。

    

    逆强化学习（IRL）是从专家演示中推断奖励函数的强大范式。许多IRL算法需要已知的转移模型，有时甚至需要已知的专家策略，或者至少需要访问生成模型。但是，这些假设对于许多实际应用来说太强了，因为只能通过顺序交互来访问环境。我们提出了一种新的IRL算法：主动探索逆强化学习（AceIRL），它主动探索未知环境和专家策略，快速学习专家的奖励函数并识别出一个好的策略。AceIRL使用先前的观察结果构建置信区间来捕捉可行的奖励函数，并找到侧重于环境中最有信息的区域的探索策略。AceIRL是第一种具有样本复杂度界限且不需要环境生成模型的主动IRL方法。

    Inverse Reinforcement Learning (IRL) is a powerful paradigm for inferring a reward function from expert demonstrations. Many IRL algorithms require a known transition model and sometimes even a known expert policy, or they at least require access to a generative model. However, these assumptions are too strong for many real-world applications, where the environment can be accessed only through sequential interaction. We propose a novel IRL algorithm: Active exploration for Inverse Reinforcement Learning (AceIRL), which actively explores an unknown environment and expert policy to quickly learn the expert's reward function and identify a good policy. AceIRL uses previous observations to construct confidence intervals that capture plausible reward functions and find exploration policies that focus on the most informative regions of the environment. AceIRL is the first approach to active IRL with sample-complexity bounds that does not require a generative model of the environment. AceIRL 
    
[^32]: 主题模型中混合测度的Wasserstein距离的估计和推断

    Estimation and inference for the Wasserstein distance between mixing measures in topic models. (arXiv:2206.12768v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2206.12768](http://arxiv.org/abs/2206.12768)

    本文提出了对混合模型中混合测度的Wasserstein距离的新的规范解释，并提供了在主题模型中进行此距离推断的工具。

    

    在混合模型的统计分析中，混合测度的Wasserstein距离已经成为了一个核心问题。本研究提出了这种距离的新的规范解释，并提供了在主题模型中进行混合测度的Wasserstein距离推断的工具。我们考虑了一般可识别混合模型的情况，其中包括了多个来自集合$\mathcal{A}$内带有任意度量$d$的分布的混合，我们证明了混合测度的Wasserstein距离是唯一地表征出混合元素集合$\mathcal{A}$上度量$d$的最有区分性的凸扩展。虽然Wasserstein距离在混合模型的研究中已被广泛使用，但缺乏公理证明。我们的结果确立了这个度量作为一个规范选择。特准化这个度量到主题模型，我们考虑了这个距离的估计和推断。虽然$i$

    The Wasserstein distance between mixing measures has come to occupy a central place in the statistical analysis of mixture models. This work proposes a new canonical interpretation of this distance and provides tools to perform inference on the Wasserstein distance between mixing measures in topic models.  We consider the general setting of an identifiable mixture model consisting of mixtures of distributions from a set $\mathcal{A}$ equipped with an arbitrary metric $d$, and show that the Wasserstein distance between mixing measures is uniquely characterized as the most discriminative convex extension of the metric $d$ to the set of mixtures of elements of $\mathcal{A}$. The Wasserstein distance between mixing measures has been widely used in the study of such models, but without axiomatic justification. Our results establish this metric to be a canonical choice.  Specializing our results to topic models, we consider estimation and inference of this distance. Though upper bounds for i
    
[^33]: 随机深度神经网络的浓度不等式和最优层数

    Concentration inequalities and optimal number of layers for stochastic deep neural networks. (arXiv:2206.11241v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.11241](http://arxiv.org/abs/2206.11241)

    该论文提出了随机深度神经网络的浓度不等式，通过期望分类器给出了分类误差的概率上界，并确定了最优层数。

    

    我们提出了随机深度神经网络（SDNN）隐藏层输出的浓度不等式，以及整个SDNN输出的浓度不等式。这些结果使我们能够引入期望分类器（EC），并给出EC分类误差的概率上界。我们还通过最优停止策略确定了SDNN的最佳层数。我们将分析应用于具有ReLU激活函数的前馈神经网络的随机版本。

    We state concentration inequalities for the output of the hidden layers of a stochastic deep neural network (SDNN), as well as for the output of the whole SDNN. These results allow us to introduce an expected classifier (EC), and to give probabilistic upper bound for the classification error of the EC. We also state the optimal number of layers for the SDNN via an optimal stopping procedure. We apply our analysis to a stochastic version of a feedforward neural network with ReLU activation function.
    
[^34]: 三维蛋白质主干的扩散概率建模在基于模体脚手架问题中的应用

    Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem. (arXiv:2206.04119v2 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2206.04119](http://arxiv.org/abs/2206.04119)

    本研究提出了一种新的方法来解决蛋白质脚手架问题，采用E(3)-等变图神经网络来学习多样和长的蛋白质主干结构的分布，并用SMCDiff算法从分布中有效地采样出符合给定模体条件的脚手架，这一算法在大计算极限中可以理论上保证条件样本的采样；研究结果表明，我们的方法可以生成长达80个残基的脚手架，并可以为固定模体实现结构多样的脚手架。

    

    构建支持所需模体的脚手架结构，即赋予蛋白质功能的脚手架设计对于疫苗和酶的设计具有潜在价值。然而，模体脚手架问题的通用解决方案仍然没有出现。目前用于脚手架设计的机器学习技术只适用于长度不超过20的不真实脚手架或难以生成多个不同样式的脚手架。我们提出了利用E(3)-等变图神经网络学习多种多样且长度更长的蛋白质主干结构的分布。我们开发了SMCDiff以有效地从给定的模体条件下的分布中采样出脚手架；我们的算法是第一个理论上保证从大计算极限中扩散模型中的条件样本的算法。我们通过与AlphaFold2预测结构的对齐程度评估我们设计的主干。我们表明我们的方法可以(1)采样长达80个残基的脚手架，并且(2)为固定模体实现结构多样的脚手架。

    Construction of a scaffold structure that supports a desired motif, conferring protein function, shows promise for the design of vaccines and enzymes. But a general solution to this motif-scaffolding problem remains open. Current machine-learning techniques for scaffold design are either limited to unrealistically small scaffolds (up to length 20) or struggle to produce multiple diverse scaffolds. We propose to learn a distribution over diverse and longer protein backbone structures via an E(3)-equivariant graph neural network. We develop SMCDiff to efficiently sample scaffolds from this distribution conditioned on a given motif; our algorithm is the first to theoretically guarantee conditional samples from a diffusion model in the large-compute limit. We evaluate our designed backbones by how well they align with AlphaFold2-predicted structures. We show that our method can (1) sample scaffolds up to 80 residues and (2) achieve structurally diverse scaffolds for a fixed motif.
    
[^35]: 基于主成分分析的高效缺失数据插补算法框架

    Principal Component Analysis based frameworks for efficient missing data imputation algorithms. (arXiv:2205.15150v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15150](http://arxiv.org/abs/2205.15150)

    本文提出了基于主成分分析的缺失数据插补框架，可适用于高维数据，能够显著优于基线方法，同时在分类任务中实现可比较或更好的分类准确性。

    

    缺失数据是实践中普遍存在的问题。许多填补缺失值的方法已经被开发出来。然而，并不是所有的方法都能够适用于高维数据，特别是多重插补技术。同时，如今的数据趋向于高维。因此，在这项工作中，我们提出了基于主成分分析（PCA）的简单而通用的缺失值插补框架PCA Imputation（PCAI），以加快插补过程并减轻许多可用插补技术的内存问题，而不会牺牲均方误差方面的插补质量。此外，即使部分或全部缺失特征是分类的，或者缺失特征数量较大，该框架也可以使用。接下来，我们介绍PCA Imputation - Classification（PIC），这是对具有一些调整的分类问题PCAI的应用。我们通过各种情况的实验验证了我们的方法，表明PCA I和PIC可以显著优于基线方法，同时在分类任务中实现可比较或更好的分类准确性。

    Missing data is a commonly occurring problem in practice. Many imputation methods have been developed to fill in the missing entries. However, not all of them can scale to high-dimensional data, especially the multiple imputation techniques. Meanwhile, the data nowadays tends toward high-dimensional. Therefore, in this work, we propose Principal Component Analysis Imputation (PCAI), a simple but versatile framework based on Principal Component Analysis (PCA) to speed up the imputation process and alleviate memory issues of many available imputation techniques, without sacrificing the imputation quality in term of MSE. In addition, the frameworks can be used even when some or all of the missing features are categorical, or when the number of missing features is large. Next, we introduce PCA Imputation - Classification (PIC), an application of PCAI for classification problems with some adjustments. We validate our approach by experiments on various scenarios, which shows that PCAI and PI
    
[^36]: 具有最优统计率和隐私保证的拜占庭鲁棒联邦学习

    Byzantine-Robust Federated Learning with Optimal Statistical Rates and Privacy Guarantees. (arXiv:2205.11765v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11765](http://arxiv.org/abs/2205.11765)

    本文提出了一种具有近乎最优统计率的拜占庭鲁棒联邦学习协议，并展示了其与竞争协议相比的经验优越性，协议通过分桶可以结合隐私保障程序以对半诚实服务器进行安全保障。

    

    我们提出了一种具有近乎最优统计率的拜占庭鲁棒联邦学习协议。与之前的工作相比，我们提出的协议提高了维度依赖性，并在强凸损失的所有参数方面实现了紧密的统计率。我们对竞争协议进行了基准测试，并展示了所提出协议的经验优越性。最后，我们指出，我们的分桶协议可以与隐私保障程序自然地结合起来，以引入对半诚实服务器的安全保障。评估代码位于https://github.com/wanglun1996/secure-robust-federated-learning中。

    We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a tight statistical rate in terms of all the parameters for strongly convex losses. We benchmark against competing protocols and show the empirical superiority of the proposed protocols. Finally, we remark that our protocols with bucketing can be naturally combined with privacy-guaranteeing procedures to introduce security against a semi-honest server. The code for evaluation is provided in https://github.com/wanglun1996/secure-robust-federated-learning.
    
[^37]: 隐私估计的新下界和广义指纹引理

    New Lower Bounds for Private Estimation and a Generalized Fingerprinting Lemma. (arXiv:2205.08532v4 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2205.08532](http://arxiv.org/abs/2205.08532)

    本文提供了针对高斯分布隐私协方差估计和有界协方差分布的均值估计的新下界，通过广义化指纹法到指数家族来证明这些下界的正确性。

    

    我们证明了在$(\varepsilon, \delta)$-差分隐私约束下统计估计任务的新的下界。首先，我们给出了高斯分布隐私协方差估计的严格下界。我们证明，在Frobenius范数下估计协方差矩阵需要$\Omega(d^2)$个样本，在谱范数下需要$\Omega(d^{3/2})$个样本，两者都匹配上界，除了对数因子。后一项下界验证了一个关于高斯协方差谱估计的隐私和非隐私样本复杂度的猜想统计差距的存在。我们通过将指纹方法广义化到指数家族来证明这些下界是正确的技术贡献。此外，使用Acharya，Sun和Zhang提出的差分隐私Assouad方法，我们在$\ell_2$-距离下表明了在有界协方差分布的均值估计中，到$\alpha$误差的严格$\Omega(d/(\alpha^2 \varepsilon))$下界。

    We prove new lower bounds for statistical estimation tasks under the constraint of $(\varepsilon, \delta)$-differential privacy. First, we provide tight lower bounds for private covariance estimation of Gaussian distributions. We show that estimating the covariance matrix in Frobenius norm requires $\Omega(d^2)$ samples, and in spectral norm requires $\Omega(d^{3/2})$ samples, both matching upper bounds up to logarithmic factors. The latter bound verifies the existence of a conjectured statistical gap between the private and the non-private sample complexities for spectral estimation of Gaussian covariances. We prove these bounds via our main technical contribution, a broad generalization of the fingerprinting method to exponential families. Additionally, using the private Assouad method of Acharya, Sun, and Zhang, we show a tight $\Omega(d/(\alpha^2 \varepsilon))$ lower bound for estimating the mean of a distribution with bounded covariance to $\alpha$-error in $\ell_2$-distance. Prio
    
[^38]: 用统计和机器学习打击洗钱：综述与介绍

    Fighting Money Laundering with Statistics and Machine Learning: An Introduction and Review. (arXiv:2201.04207v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2201.04207](http://arxiv.org/abs/2201.04207)

    本文介绍了银行反洗钱的统计和机器学习方法，并提出客户风险评估和可疑行为标识两个核心要素。未来的研究方向包括生成合成数据、半监督和深度学习、可解释性以及结果的公平性。

    

    洗钱是一个严重的全球性问题，但是针对反洗钱的统计和机器学习方法的科学文献却很少。本文着重于银行反洗钱，并提供了文献综述和介绍。我们提出了一个统一的术语，其中包括客户风险评估和可疑行为标识两个核心要素。我们发现，客户风险评估是通过诊断来寻找和解释风险因素，而可疑行为标识则是通过未公开的特征和手工风险指数来实现的。最后，我们讨论了未来研究的方向，其中主要挑战之一是需要更多的公共数据集，这可能可以通过生成合成数据来解决，其他可能的研究方向包括半监督和深度学习、可解释性以及结果的公平性。

    Money laundering is a profound global problem. Nonetheless, there is little scientific literature on statistical and machine learning methods for anti-money laundering. In this paper, we focus on anti-money laundering in banks and provide an introduction and review of the literature. We propose a unifying terminology with two central elements: (i) client risk profiling and (ii) suspicious behavior flagging. We find that client risk profiling is characterized by diagnostics, i.e., efforts to find and explain risk factors. On the other hand, suspicious behavior flagging is characterized by non-disclosed features and hand-crafted risk indices. Finally, we discuss directions for future research. One major challenge is the need for more public data sets. This may potentially be addressed by synthetic data generation. Other possible research directions include semi-supervised and deep learning, interpretability, and fairness of the results.
    
[^39]: 通过Langevin函数方差估计超参数模型的泛化缺口

    A generalization gap estimation for overparameterized models via the Langevin functional variance. (arXiv:2112.03660v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.03660](http://arxiv.org/abs/2112.03660)

    本文提出了一种函数方差的Langevin估计方法，用于高效计算超参数模型的泛化缺口，实现与基于梯度的优化算法一致。

    

    本文讨论了泛化缺口的估计，即泛化性能与训练性能之间的差异，针对包括神经网络在内的超参数模型。我们首先展示了函数方差——一个定义广泛的信息准则中的关键概念——在超参数模型中也能表征泛化缺口，即使传统理论无法应用于超参数模型。由于函数方差的计算成本对于超参数模型而言非常昂贵，因此我们提出了函数方差的高效近似方法——函数方差的Langevin估计（Langevin FV）。这种方法只利用了平方损失函数的一阶梯度，而没有使用二阶梯度，从而保证了计算的高效性，并且实现与基于梯度的优化算法是一致的。我们通过数值演示了Langevin FV，估计了超参数模型的泛化缺口。

    This paper discusses the estimation of the generalization gap, the difference between generalization performance and training performance, for overparameterized models including neural networks. We first show that a functional variance, a key concept in defining a widely-applicable information criterion, characterizes the generalization gap even in overparameterized settings where a conventional theory cannot be applied. As the computational cost of the functional variance is expensive for the overparameterized models, we propose an efficient approximation of the function variance, the Langevin approximation of the functional variance (Langevin FV). This method leverages only the $1$st-order gradient of the squared loss function, without referencing the $2$nd-order gradient; this ensures that the computation is efficient and the implementation is consistent with gradient-based optimization algorithms. We demonstrate the Langevin FV numerically by estimating the generalization gaps of o
    
[^40]: 知识花束：适用于知识图谱嵌入的花扭理论框架

    Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph Embedding. (arXiv:2110.03789v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03789](http://arxiv.org/abs/2110.03789)

    本研究提出了一种“知识花扭”方法来描述知识图谱嵌入模型，并可以表达广泛的嵌入先验约束，可轻松应对复合关系推理。

    

    知识图谱嵌入指学习实体（图的顶点）和关系（图的边）的表示，以使得生成的表示编码知识图谱中已知的事实信息，并可以用于推理新的关系。我们展示了知识图谱嵌入自然地表达为“细胞花扭”的拓扑和范畴语言：一个知识图谱嵌入可以描述为适当的“知识花扭”在图上的近似全局截面，其一致性约束是由知识图谱的架构引起的。这种方法提供了一个广义的框架来推理知识图谱嵌入模型，并允许表达广泛的嵌入先验约束。此外，生成的嵌入可以轻松地适应于复合关系的推理，无需特殊的训练。我们实现了这些想法，以展示这种方法的效果。

    Knowledge graph embedding involves learning representations of entities -the vertices of the graph -- and relations -- the edges of the graph -- such that the resulting representations encode the known factual information represented by the knowledge graph and can be used in the inference of new relations. We show that knowledge graph embedding is naturally expressed in the topological and categorical language of \textit{cellular sheaves}: a knowledge graph embedding can be described as an approximate global section of an appropriate \textit{knowledge sheaf} over the graph, with consistency constraints induced by the knowledge graph's schema. This approach provides a generalized framework for reasoning about knowledge graph embedding models and allows for the expression of a wide range of prior constraints on embeddings. Further, the resulting embeddings can be easily adapted for reasoning over composite relations without special training. We implement these ideas to highlight the be
    
[^41]: 面向动态时空预测的长距离Transformer

    Long-Range Transformers for Dynamic Spatiotemporal Forecasting. (arXiv:2109.12218v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.12218](http://arxiv.org/abs/2109.12218)

    本研究提出了一种名为Spacetimeformer的方法，将多元时间序列预测转化为“时空序列”形式进行建模，实现了对变量之间动态空间关系的学习，同时在多个基准测试上取得了最先进的结果。

    

    多元时间序列预测致力于基于历史情境预测未来值。现有序列到序列模型利用神经关注机制进行时间学习，但未考虑变量间的空间关系。相比而言，基于图神经网络的方法明确建模变量关系，但往往依赖于预定义图，不能随时间变化且在每个时间步骤中对各变量进行独立的空间和时间更新。我们的工作通过将多元预测转化为“时空序列”形式来解决这些问题，其中每个Transformer输入表示给定时间单个变量的值。长距离Transformer可以沿着这个扩展序列共同学习空间、时间和值信息之间的交互。我们的方法称为Spacetimeformer，在多个多元预测基准测试上取得了最先进的结果，并可以动态更新变量关系。

    Multivariate time series forecasting focuses on predicting future values based on historical context. State-of-the-art sequence-to-sequence models rely on neural attention between timesteps, which allows for temporal learning but fails to consider distinct spatial relationships between variables. In contrast, methods based on graph neural networks explicitly model variable relationships. However, these methods often rely on predefined graphs that cannot change over time and perform separate spatial and temporal updates without establishing direct connections between each variable at every timestep. Our work addresses these problems by translating multivariate forecasting into a "spatiotemporal sequence" formulation where each Transformer input token represents the value of a single variable at a given time. Long-Range Transformers can then learn interactions between space, time, and value information jointly along this extended sequence. Our method, which we call Spacetimeformer, achie
    
[^42]: Q学习是否是极小极大最优的？一项紧密的样本复杂性分析。

    Is Q-Learning Minimax Optimal? A Tight Sample Complexity Analysis. (arXiv:2102.06548v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2102.06548](http://arxiv.org/abs/2102.06548)

    本文通过紧密的样本复杂度分析回答了Q学习是否是极小极大最优的问题。

    

    Q学习是强化学习的核心，旨在以模型自由的方式学习马尔可夫决策过程的最优Q函数。针对同步设置（即在每次迭代中从生成模型中独立地抽取所有状态-动作对的样本），在理解Q学习的样本效率方面已经取得了重大进展。对于一个具有状态空间Σ和动作空间Α的γ折扣的无限时间阶段MDP，为了产生最优Q函数的元素级ε近似，针对Q学习的最新理论需要一个样本大小超过Σ∣∣×Α∣∣∕(1−γ)^5ε^{2}的量级，但这并不符合现有的极小极大下界。这引出了一个自然的问题：Q学习的样本复杂性是多少？Q学习是否可证明是次优的？本文针对同步设置回答了这些问题：(1)

    Q-learning, which seeks to learn the optimal Q-function of a Markov decision process (MDP) in a model-free fashion, lies at the heart of reinforcement learning. When it comes to the synchronous setting (such that independent samples for all state-action pairs are drawn from a generative model in each iteration), substantial progress has been made towards understanding the sample efficiency of Q-learning. Consider a $\gamma$-discounted infinite-horizon MDP with state space $\mathcal{S}$ and action space $\mathcal{A}$: to yield an entrywise $\varepsilon$-approximation of the optimal Q-function, state-of-the-art theory for Q-learning requires a sample size exceeding the order of $\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^5\varepsilon^{2}}$, which fails to match existing minimax lower bounds. This gives rise to natural questions: what is the sharp sample complexity of Q-learning? Is Q-learning provably sub-optimal? This paper addresses these questions for the synchronous setting: (1) wh
    
[^43]: 高维半监督学习的最优与安全估计

    Optimal and Safe Estimation for High-Dimensional Semi-Supervised Learning. (arXiv:2011.14185v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2011.14185](http://arxiv.org/abs/2011.14185)

    本研究探究了高维半监督学习的估计问题，提出了最优和安全的半监督估计器。最优估计器可以实现极小极大下界，改进监督估计器。安全估计器至少和监督估计器一样好，且两者聚合可以更好地解决误差问题。

    

    本研究考虑高维半监督学习的估计问题，旨在探究无标签数据如何提高线性模型回归参数的估计准确性，因为这样的线性模型可能在数据分析中被错误地规定。首先，我们建立了半监督设置下参数估计的极小极大下界，并证明了仅使用有标签数据的监督估计器无法实现此下界。我们提出了一种最优半监督估计器，可以实现此下界，因此可以改进监督估计器，前提是条件均值函数可以以适当的速率一致地估计。我们进一步提出了一种安全的半监督估计器。我们认为它是安全的，因为这个估计器总是至少和监督估计器一样好。我们还将我们的想法扩展到多个由不同误差引起的半监督估计器的聚合。

    We consider the estimation problem in high-dimensional semi-supervised learning. Our goal is to investigate when and how the unlabeled data can be exploited to improve the estimation of the regression parameters of linear model in light of the fact that such linear models may be misspecified in data analysis. We first establish the minimax lower bound for parameter estimation in the semi-supervised setting, and show that this lower bound cannot be achieved by supervised estimators using the labeled data only. We propose an optimal semi-supervised estimator that can attain this lower bound and therefore improves the supervised estimators, provided that the conditional mean function can be consistently estimated with a proper rate. We further propose a safe semi-supervised estimator. We view it safe, because this estimator is always at least as good as the supervised estimators. We also extend our idea to the aggregation of multiple semi-supervised estimators caused by different misspeci
    
[^44]: 论偏差-方差均衡的下限

    On lower bounds for the bias-variance trade-off. (arXiv:2006.00278v4 [math.ST] UPDATED)

    [http://arxiv.org/abs/2006.00278](http://arxiv.org/abs/2006.00278)

    研究提出了一种通用策略来获得任何偏差小于预定界限的估计器的方差下限。该方法基于一些关于方差的抽象下限，涉及到对不同概率测度的期望值的变化以及信息度量，如KL或$\chi^2$分歧。在几个统计模型上进行了应用。

    

    对于高维和非参数统计模型，速率最优估计器通常平衡平方偏差和方差。虽然这种平衡广泛存在，但很少有人知道是否存在可以避免偏差和方差之间的权衡的方法。我们提出了一种通用策略，以获得任何偏差小于预定界限的估计器的方差下限。这表明了偏差-方差权衡不可避免的程度，并允许量化不遵守该权衡的方法的性能损失。该方法基于一些关于方差的抽象下限，涉及到对不同概率测度的期望值的变化以及信息度量，如Kullback-Leibler或$\chi^2$-分歧。在文章的第二部分中，将这些抽象下限应用于几个统计模型，包括高斯白噪声模型，边界估计问题，高斯简单协方差和均值矩阵估计等问题。

    It is a common phenomenon that for high-dimensional and nonparametric statistical models, rate-optimal estimators balance squared bias and variance. Although this balancing is widely observed, little is known whether methods exist that could avoid the trade-off between bias and variance. We propose a general strategy to obtain lower bounds on the variance of any estimator with bias smaller than a prespecified bound. This shows to which extent the bias-variance trade-off is unavoidable and allows to quantify the loss of performance for methods that do not obey it. The approach is based on a number of abstract lower bounds for the variance involving the change of expectation with respect to different probability measures as well as information measures such as the Kullback-Leibler or $\chi^2$-divergence. In a second part of the article, the abstract lower bounds are applied to several statistical models including the Gaussian white noise model, a boundary estimation problem, the Gaussian
    

