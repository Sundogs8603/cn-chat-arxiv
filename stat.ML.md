# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Locality-constrained autoregressive cum conditional normalizing flow for lattice field theory simulations.](http://arxiv.org/abs/2304.01798) | 本文提出了一种局部约束自回归条件归一化流模型，在格子场论的模拟中取得了很好的应用，并在二维 $\phi^4$ 理论的采样中相比等效归一化流模型有数倍的性能提升。 |
| [^2] | [Convergence of alternating minimisation algorithms for dictionary learning.](http://arxiv.org/abs/2304.01768) | 本文探讨了字典学习中两种交替极小化算法的收敛性，在良好的初始化下，这两种算法能够以几何收敛速率收敛于生成的字典，且可适用于非均匀分布的数据模型。 |
| [^3] | [Incorporating Unlabelled Data into Bayesian Neural Networks.](http://arxiv.org/abs/2304.01762) | 该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。 |
| [^4] | [Characterizing the contribution of dependent features in XAI methods.](http://arxiv.org/abs/2304.01717) | 该论文探讨了在XAI方法中考虑预测变量的依赖关系，提出了一种简单快速的方法，并证明其模型无关性。 |
| [^5] | [Inverse Unscented Kalman Filter.](http://arxiv.org/abs/2304.01698) | 本论文提出了针对非线性系统动态的反向无味卡尔曼滤波器（I-UKF）以及基于再生核希尔伯特空间的UKF（RKHS-UKF），用于学习未知的系统模型并估计状态。 |
| [^6] | [Optimal rates of approximation by shallow ReLU$^k$ neural networks and applications to nonparametric regression.](http://arxiv.org/abs/2304.01561) | 本文研究了Shallow ReLU$^k$神经网络的逼近容量，证明了其最优逼近速率。应用到非参数回归上，证明了浅层神经网络可以实现学习H\"older函数的最优渐进速率，补充了深层神经网络的最近结果。 |
| [^7] | [Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation.](http://arxiv.org/abs/2304.01541) | 本论文研究了在通信和差分隐私约束下，平均值和频率估计的最优准确性，证明每个客户端只需发送$\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$比特的FL问题和$\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$比特的FA问题即可实现最优误差，从而在联合学习和分析中实现了隐私、精确性和通信的最优权衡。 |
| [^8] | [OneShotSTL: One-Shot Seasonal-Trend Decomposition For Online Time Series Anomaly Detection And Forecasting.](http://arxiv.org/abs/2304.01506) | OneShotSTL提出了一种高效准确的算法，用于在线时间序列分解，在处理时间上仅需O(1)的更新时间复杂度，并可同时保持较高的精度，解决了现有批处理方法无法支持实时分析的挑战。 |
| [^9] | [Learning from data with structured missingness.](http://arxiv.org/abs/2304.01429) | 带有结构性缺失的数据学习是一个尚未被系统解决的问题，它对规模化的机器学习构成了重要阻碍，并且需要进一步的研究和解决。 |
| [^10] | [Matched Machine Learning: A Generalized Framework for Treatment Effect Inference With Learned Metrics.](http://arxiv.org/abs/2304.01316) | 匹配机器学习结合了机器学习的灵活性和匹配的可解释性，通过学习最佳度量用于匹配单位和估计结果，旨在实现机器学习黑盒子的性能，同时可解释结果，并具有广泛的应用前景。 |
| [^11] | [Improved Bound for Mixing Time of Parallel Tempering.](http://arxiv.org/abs/2304.01303) | 本研究提出了一种新的并行退火的下界，对除$\log L$之外的所有参数具有多项式依赖性，其改进了现有界限。因此，该算法的混合时间可能更优。 |
| [^12] | [Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes.](http://arxiv.org/abs/2304.01294) | 本文提出了一种稀疏Cholesky分解算法，用于高斯过程求解非线性偏微分方程，能够有效处理高维和畸形域的问题。 |
| [^13] | [Almost Linear Constant-Factor Sketching for $\ell_1$ and Logistic Regression.](http://arxiv.org/abs/2304.00051) | 本文提出了一种近线性、常数因子草图，适用于$\ell_1$和logistic回归，具有小的草图维度和高精度，这种草图还在草图空间内提供了高效的优化问题求解方法。 |
| [^14] | [Inference on eigenvectors of non-symmetric matrices.](http://arxiv.org/abs/2303.18233) | 本研究探讨了建立渐近推断非对称矩阵特征向量程序的必要条件，并针对完全向量和每个系数假设分别建立了 Wald 和 t 检验的分布理论，是多元统计学中的一种有用工具。 |
| [^15] | [The Graphical Nadaraya-Watson Estimator on Latent Position Models.](http://arxiv.org/abs/2303.17229) | 研究了潜在位置模型上的图形Nadaraya-Watson估计器的性质，对于更复杂的方法有理论指导意义。 |
| [^16] | [List Online Classification.](http://arxiv.org/abs/2303.15383) | 本文研究了多标签列表的在线预测问题，提出了 $b$-ary Littlestone 维度可学习模型，并且在懵懂的情况下探索不同的情况。可以使用改编自 Littlestone 的 SOA 和 Rosenblatt 的感知器等算法进行预测，同时还建立了列表可学习的组合结果。 |
| [^17] | [Extrapolation to complete basis-set limit in density-functional theory by quantile random-forest models.](http://arxiv.org/abs/2303.14760) | 本文利用分位随机森林模型外推完备基组极限，并提供了预测区间以量化模型的不确定性。 |
| [^18] | [Causal Razors.](http://arxiv.org/abs/2302.10331) | 本文比较了许多出现在文献中的因果剃刀，并特别研究了在多项式因果模型中不太受欢迎的因果剃刀——参数最小性。逻辑结果揭示了选择合理得分标准时的困境。 |
| [^19] | [Learning-Rate-Free Learning by D-Adaptation.](http://arxiv.org/abs/2301.07733) | D-Adaptation是一种可以自动设置学习率的方法，针对最小化凸性Lipschitz函数，用于实现最优收敛速率，而无需超参数，也无需额外对数因子改进，能够在各种机器学习问题中自动匹配手动调整的学习率。 |
| [^20] | [A Probabilistic Framework for Lifelong Test-Time Adaptation.](http://arxiv.org/abs/2212.09713) | 本文提出了一种用于处理测试输入分布随时间持续变化的概率框架PETAL，通过提供可靠的不确定性估计和使用源模型作为正则化项来推断时正则化模型更新，实现了终身TTA。 |
| [^21] | [Bayesian posterior approximation with stochastic ensembles.](http://arxiv.org/abs/2212.08123) | 本文提出一种新方法，即使用随机神经网络集合来近似贝叶斯后验，并通过变分推断进行训练，实验证明该方法比其他流行的贝叶斯推断基线提供了更准确的后验估计。 |
| [^22] | [FaiREE: Fair Classification with Finite-Sample and Distribution-Free Guarantee.](http://arxiv.org/abs/2211.15072) | 本研究提出了FaiREE算法，它是一种可满足群体公平性约束的公平分类算法，并且具有有限样本和无分布理论保证。在实验中表现优异。 |
| [^23] | [Outlier Robust and Sparse Estimation of Linear Regression Coefficients.](http://arxiv.org/abs/2208.11592) | 本文介绍了一种异常鲁棒稀疏估计方法，可用于线性回归系数的协方差矩阵已知或未知的情况下，具有较尖锐的误差界，适用于采样自$\mathfrak{L}$-subGaussian分布和重尾分布的协变量向量和噪声。 |
| [^24] | [Neural Networks for Extreme Quantile Regression with an Application to Forecasting of Flood Risk.](http://arxiv.org/abs/2208.07590) | 本文提出了一种结合神经网络和极值理论的EQRN模型，它能够在存在复杂预测变量相关性的情况下进行外推，并且能够应用于洪水风险预测中，提供一天前回归水平和超出概率的预测。 |
| [^25] | [A Framework and Benchmark for Deep Batch Active Learning for Regression.](http://arxiv.org/abs/2203.09410) | 本研究提出了一个深度批量主动学习回归的框架和基准测试，其中包括许多现有的贝叶斯和非贝叶斯方法。提出了一种替换常用最后一层特征的新方法，并结合一种新颖的聚类方法。在15个大型表格回归数据集上进行测试，该方法在基准测试中表现优异，适用于大型数据集且易于使用。 |
| [^26] | [Iterated Block Particle Filter for High-dimensional Parameter Learning: Beating the Curse of Dimensionality.](http://arxiv.org/abs/2110.10745) | 本文提出了一种迭代分块粒子滤波算法，用于学习高维参数。该算法克服了维度灾难，表现出良好的收敛性和似然最大化，成功地在非线性和非高斯空间时间模型上实现了参数学习。 |
| [^27] | [Adaptive joint distribution learning.](http://arxiv.org/abs/2110.04829) | 该论文提出了一种自适应联合分布学习的框架，可以从大量数据点中估计低维、归一化和正的Radon-Nikodym导数模型，并在不同学习问题上取得了良好的结果。 |
| [^28] | [A practical model-based segmentation approach for improved activation detection in single-subject functional Magnetic Resonance Imaging studies.](http://arxiv.org/abs/2102.03639) | 本研究提出了一种计算可行和方法学上合理的基于模型的方法来解决单个被试和低信号背景下的功能性磁共振成像的激活检测问题，并能够区分不同强度的激活，通过在 R 包 MixfMRI 中实现可以得到具体应用。 |
| [^29] | [MARS: Masked Automatic Ranks Selection in Tensor Decompositions.](http://arxiv.org/abs/2006.10859) | 本文介绍了一种名为MARS的新型高效方法，在一般的张量分解中自动选择秩，学习二值掩码来选择最佳的张量结构，在实验中显示出更好的结果。 |

# 详细

[^1]: 局部约束自回归条件归一化流在格子场论模拟中的应用

    Locality-constrained autoregressive cum conditional normalizing flow for lattice field theory simulations. (arXiv:2304.01798v1 [hep-lat])

    [http://arxiv.org/abs/2304.01798](http://arxiv.org/abs/2304.01798)

    本文提出了一种局部约束自回归条件归一化流模型，在格子场论的模拟中取得了很好的应用，并在二维 $\phi^4$ 理论的采样中相比等效归一化流模型有数倍的性能提升。

    

    基于归一化流的采样方法已经成功地解决了传统的模拟格子量子场论的计算难题。更进一步的研究将规范和平移不变性纳入到基础神经网络中，使模型在训练和推断时更高效。本文研究将动作积分的局部性纳入到模型中，从而简化了条件归一化流的输入域。我们采用自回归过程在子格子上采样并将其称为局部自回归条件归一化流（l-ACNF）。实验发现，相对于在二维格子上采样 $\phi^{4}$ 理论的等效归一化流模型，l-ACNF 模型的自相关时间快速下降，更加高效。

    Normalizing flow-based sampling methods have been successful in tackling computational challenges traditionally associated with simulating lattice quantum field theories. Further works have incorporated gauge and translational invariance of the action integral in the underlying neural networks, which have led to efficient training and inference in those models. In this paper, we incorporate locality of the action integral which leads to simplifications to the input domain of conditional normalizing flows that sample constant time sub-lattices in an autoregressive process, dubbed local-Autoregressive Conditional Normalizing Flow (l-ACNF). We find that the autocorrelation times of l-ACNF models outperform an equivalent normalizing flow model on the full lattice by orders of magnitude when sampling $\phi^{4}$ theory on a 2 dimensional lattice.
    
[^2]: 字典学习中交替极小化算法的收敛性

    Convergence of alternating minimisation algorithms for dictionary learning. (arXiv:2304.01768v1 [math.OC])

    [http://arxiv.org/abs/2304.01768](http://arxiv.org/abs/2304.01768)

    本文探讨了字典学习中两种交替极小化算法的收敛性，在良好的初始化下，这两种算法能够以几何收敛速率收敛于生成的字典，且可适用于非均匀分布的数据模型。

    

    本文导出了针对字典学习两种流行的交替极小化算法 - 最优方向法（MOD）和在线字典学习（ODL）的收敛性足够的条件。我们表明，只要初始值良好，即距离生成的字典不超过$1/\log(K)$或具有一定的结构，确保初始值中的每个元素只指向一个生成元，两种算法将以几何收敛速率收敛于生成的字典。这在具有非均匀分布的数据模型上也能实现，该模型中稀疏系数的支撑集的出现频率可以变化很大，从而更接近真实数据。

    In this paper we derive sufficient conditions for the convergence of two popular alternating minimisation algorithms for dictionary learning - the Method of Optimal Directions (MOD) and Online Dictionary Learning (ODL), which can also be thought of as approximative K-SVD. We show that given a well-behaved initialisation that is either within distance at most $1/\log(K)$ to the generating dictionary or has a special structure ensuring that each element of the initialisation only points to one generating element, both algorithms will converge with geometric convergence rate to the generating dictionary. This is done even for data models with non-uniform distributions on the supports of the sparse coefficients. These allow the appearance frequency of the dictionary elements to vary heavily and thus model real data more closely.
    
[^3]: 将未标记数据纳入贝叶斯神经网络中

    Incorporating Unlabelled Data into Bayesian Neural Networks. (arXiv:2304.01762v1 [cs.LG])

    [http://arxiv.org/abs/2304.01762](http://arxiv.org/abs/2304.01762)

    该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。

    

    我们提出了一个对贝叶斯神经网络（BNNs）中先验分布进行学习的对比框架，利用未标记数据来优化。基于该框架，我们提出了一种实用的BNN算法，同时具备自监督学习的标签效率和贝叶斯方法中的根据原则的不确定性估计。最后，我们展示了我们的方法在半监督和低预算主动学习问题中的数据高效学习优势。

    We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.
    
[^4]: 揭示XAI方法中依赖特征的贡献

    Characterizing the contribution of dependent features in XAI methods. (arXiv:2304.01717v1 [stat.ML])

    [http://arxiv.org/abs/2304.01717](http://arxiv.org/abs/2304.01717)

    该论文探讨了在XAI方法中考虑预测变量的依赖关系，提出了一种简单快速的方法，并证明其模型无关性。

    

    可解释的人工智能（XAI）提供了工具，帮助理解机器学习模型的工作原理和实现特定结果的方法。它有助于增加模型的可解释性，使得模型更为可信和透明。在这种情况下，许多XAI方法被提出，其中SHAP和LIME最广为人知。然而，这些方法假设机器学习模型中使用的预测变量相互独立，这在一般情况下并不一定成立。这种假设使得XAI结果的稳健性受到影响，比如信息预测变量的列表。在这里，我们提出了一个简单但有用的代理，修改任何XAI特征排名方法的结果，使其能够考虑预测变量之间的相关性。所提出的方法具有模型无关性，并且可以简单地计算在共线性存在的情况下每个预测变量在模型中的影响。

    Explainable Artificial Intelligence (XAI) provides tools to help understanding how the machine learning models work and reach a specific outcome. It helps to increase the interpretability of models and makes the models more trustworthy and transparent. In this context, many XAI methods were proposed being SHAP and LIME the most popular. However, the proposed methods assume that used predictors in the machine learning models are independent which in general is not necessarily true. Such assumption casts shadows on the robustness of the XAI outcomes such as the list of informative predictors. Here, we propose a simple, yet useful proxy that modifies the outcome of any XAI feature ranking method allowing to account for the dependency among the predictors. The proposed approach has the advantage of being model-agnostic as well as simple to calculate the impact of each predictor in the model in presence of collinearity.
    
[^5]: 反向无味卡尔曼滤波器

    Inverse Unscented Kalman Filter. (arXiv:2304.01698v1 [math.OC])

    [http://arxiv.org/abs/2304.01698](http://arxiv.org/abs/2304.01698)

    本论文提出了针对非线性系统动态的反向无味卡尔曼滤波器（I-UKF）以及基于再生核希尔伯特空间的UKF（RKHS-UKF），用于学习未知的系统模型并估计状态。

    

    设计认知和反对手系统的快速进步促进了反贝叶斯滤波器的发展。在这种情况下，认知“对手”通过随机框架（如卡尔曼滤波器（KF））跟踪其感兴趣的目标。然后，目标或“防御者”使用另一个逆随机滤波器来推断通过对手计算的防御者的前向滤波器估计。对于线性系统，最近已经证明了逆Kalman滤波器（I-KF）在这些反对抗应用中是有效的。本文与之前的工作相反，我们专注于非线性系统动态并制定逆非线性卡尔曼滤波器（I-UKF），以估计防御者的状态并减小线性化误差。然后，我们将这一框架推广到未知系统模型，通过提出基于再生核希尔伯特空间的UKF（RKHS-UKF）来学习系统动态并基于其观测来估计状态。我们的理论分析旨在保证所提出方法的随机稳定性，并进行数值模拟以证实所提出方法的有效性。

    Rapid advances in designing cognitive and counter-adversarial systems have motivated the development of inverse Bayesian filters. In this setting, a cognitive `adversary' tracks its target of interest via a stochastic framework such as a Kalman filter (KF). The target or `defender' then employs another inverse stochastic filter to infer the forward filter estimates of the defender computed by the adversary. For linear systems, inverse Kalman filter (I-KF) has been recently shown to be effective in these counter-adversarial applications. In the paper, contrary to prior works, we focus on non-linear system dynamics and formulate the inverse unscented KF (I-UKF) to estimate the defender's state with reduced linearization errors. We then generalize this framework to an unknown system model by proposing reproducing kernel Hilbert space-based UKF (RKHS-UKF) to learn the system dynamics and estimate the state based on its observations. Our theoretical analyses to guarantee the stochastic stab
    
[^6]: Shallow ReLU$^k$神经网络的逼近速率及其在非参数回归中的应用

    Optimal rates of approximation by shallow ReLU$^k$ neural networks and applications to nonparametric regression. (arXiv:2304.01561v1 [stat.ML])

    [http://arxiv.org/abs/2304.01561](http://arxiv.org/abs/2304.01561)

    本文研究了Shallow ReLU$^k$神经网络的逼近容量，证明了其最优逼近速率。应用到非参数回归上，证明了浅层神经网络可以实现学习H\"older函数的最优渐进速率，补充了深层神经网络的最近结果。

    

    本研究探讨与Shallow ReLU$^k$神经网络相关的变异空间的逼近容量。结果表明，在有限变异范数下，容纳了足够平滑的函数。对于较少平滑的函数，根据变异范数建立了逼近速率。运用这些结果，我们可以证明Shallow ReLU$^k$神经网络的最优逼近速率。同时阐明了这些结果如何用于推导深层神经网络和卷积神经网络(CNNs)的逼近界限。为应用研究，我们使用了三种ReLU神经网络模型：浅层神经网络，超参数神经网络和CNN进行非参数回归收敛速率研究。特别地，我们展示了浅层神经网络可以实现学习H\"older函数的最优渐进速率，这补充了深层神经网络的最近结果。

    We study the approximation capacity of some variation spaces corresponding to shallow ReLU$^k$ neural networks. It is shown that sufficiently smooth functions are contained in these spaces with finite variation norms. For functions with less smoothness, the approximation rates in terms of the variation norm are established. Using these results, we are able to prove the optimal approximation rates in terms of the number of neurons for shallow ReLU$^k$ neural networks. It is also shown how these results can be used to derive approximation bounds for deep neural networks and convolutional neural networks (CNNs). As applications, we study convergence rates for nonparametric regression using three ReLU neural network models: shallow neural network, over-parameterized neural network, and CNN. In particular, we show that shallow neural networks can achieve the minimax optimal rates for learning H\"older functions, which complements recent results for deep neural networks. It is also proven th
    
[^7]: 通过压缩实现隐私放大：在分布式均值估计中实现最优隐私-精度-通信权衡

    Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation. (arXiv:2304.01541v1 [stat.ML])

    [http://arxiv.org/abs/2304.01541](http://arxiv.org/abs/2304.01541)

    本论文研究了在通信和差分隐私约束下，平均值和频率估计的最优准确性，证明每个客户端只需发送$\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$比特的FL问题和$\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$比特的FA问题即可实现最优误差，从而在联合学习和分析中实现了隐私、精确性和通信的最优权衡。

    

    隐私和通信约束是联合学习（FL）和分析（FA）中的两个主要瓶颈。我们研究了在联合通信和$(\varepsilon, \delta)$-差分隐私（DP）约束下平均值和频率估计（FL和FA的标准模型）的最优准确性。我们展示了为了在$(\varepsilon, \delta)$-DP下达到最优误差，每个客户端只需要向服务器发送$\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$比特的FL问题和$\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$比特的FA问题。如果没有压缩，每个客户机需要$O(d)$比特和$\log d$比特来解决平均值估计和频率估计问题（其中$d$对应于FL中可训练参数的数量或FA中域的大小），这意味着我们可以获得在$n\min\left(\varepsilon,\varepsilon^2\right)$的区间中获得显著的节省。

    Privacy and communication constraints are two major bottlenecks in federated learning (FL) and analytics (FA). We study the optimal accuracy of mean and frequency estimation (canonical models for FL and FA respectively) under joint communication and $(\varepsilon, \delta)$-differential privacy (DP) constraints. We show that in order to achieve the optimal error under $(\varepsilon, \delta)$-DP, it is sufficient for each client to send $\Theta\left( n \min\left(\varepsilon, \varepsilon^2\right)\right)$ bits for FL and $\Theta\left(\log\left( n\min\left(\varepsilon, \varepsilon^2\right) \right)\right)$ bits for FA to the server, where $n$ is the number of participating clients. Without compression, each client needs $O(d)$ bits and $\log d$ bits for the mean and frequency estimation problems respectively (where $d$ corresponds to the number of trainable parameters in FL or the domain size in FA), which means that we can get significant savings in the regime $ n \min\left(\varepsilon, \va
    
[^8]: OneShotSTL：一种单次季节趋势分解方法，用于在线时间序列异常检测和预测

    OneShotSTL: One-Shot Seasonal-Trend Decomposition For Online Time Series Anomaly Detection And Forecasting. (arXiv:2304.01506v1 [cs.LG])

    [http://arxiv.org/abs/2304.01506](http://arxiv.org/abs/2304.01506)

    OneShotSTL提出了一种高效准确的算法，用于在线时间序列分解，在处理时间上仅需O(1)的更新时间复杂度，并可同时保持较高的精度，解决了现有批处理方法无法支持实时分析的挑战。

    

    季节趋势分解是时间序列分析中最基本的概念之一，它支持包括时间序列异常检测和预测在内的各种下游任务。然而，现有的分解方法依赖于批处理，时间复杂度为O(W)，其中W是时间窗口内的数据点数。因此，它们不能始终有效地支持需要低处理延迟的实时分析。为了解决这一挑战，我们提出了OneShotSTL，这是一种高效和准确的算法，可以在线上对时间序列进行分解，更新时间复杂度为O(1)。OneShotSTL比批处理方法快10倍以上，精度与最佳对手相当。广泛的实验在下游时间序列异常检测和预测任务的真实基准数据集上表明，OneShotSTL比现有技术快10倍以上，同时仍提供相当甚至更好的精度。

    Seasonal-trend decomposition is one of the most fundamental concepts in time series analysis that supports various downstream tasks, including time series anomaly detection and forecasting. However, existing decomposition methods rely on batch processing with a time complexity of O(W), where W is the number of data points within a time window. Therefore, they cannot always efficiently support real-time analysis that demands low processing delay. To address this challenge, we propose OneShotSTL, an efficient and accurate algorithm that can decompose time series online with an update time complexity of O(1). OneShotSTL is more than $1,000$ times faster than the batch methods, with accuracy comparable to the best counterparts. Extensive experiments on real-world benchmark datasets for downstream time series anomaly detection and forecasting tasks demonstrate that OneShotSTL is from 10 to over 1,000 times faster than the state-of-the-art methods, while still providing comparable or even be
    
[^9]: 带有结构性缺失的数据学习

    Learning from data with structured missingness. (arXiv:2304.01429v1 [stat.ML])

    [http://arxiv.org/abs/2304.01429](http://arxiv.org/abs/2304.01429)

    带有结构性缺失的数据学习是一个尚未被系统解决的问题，它对规模化的机器学习构成了重要阻碍，并且需要进一步的研究和解决。

    

    缺失数据是许多机器学习任务中不可避免的复杂问题。当数据是“随机缺失”时，存在一系列的工具和技术来解决此问题。然而，随着机器学习研究变得更加雄心勃勃，并且试图从越来越大量的异构数据中学习，越来越普遍的问题是出现了缺失值的关联或结构，无论是明确还是隐含。这种“结构性缺失”提出了一系列尚未系统解决的挑战，并对规模化的机器学习构成了重要阻碍。在这里，我们概述了当前的文献，并提出了一组关于如何在带有结构性缺失的数据中学习的挑战。

    Missing data are an unavoidable complication in many machine learning tasks. When data are `missing at random' there exist a range of tools and techniques to deal with the issue. However, as machine learning studies become more ambitious, and seek to learn from ever-larger volumes of heterogeneous data, an increasingly encountered problem arises in which missing values exhibit an association or structure, either explicitly or implicitly. Such `structured missingness' raises a range of challenges that have not yet been systematically addressed, and presents a fundamental hindrance to machine learning at scale. Here, we outline the current literature and propose a set of grand challenges in learning from data with structured missingness.
    
[^10]: 匹配机器学习：基于学习度量的治疗效果推断的广义框架

    Matched Machine Learning: A Generalized Framework for Treatment Effect Inference With Learned Metrics. (arXiv:2304.01316v1 [stat.ME])

    [http://arxiv.org/abs/2304.01316](http://arxiv.org/abs/2304.01316)

    匹配机器学习结合了机器学习的灵活性和匹配的可解释性，通过学习最佳度量用于匹配单位和估计结果，旨在实现机器学习黑盒子的性能，同时可解释结果，并具有广泛的应用前景。

    

    我们介绍了匹配机器学习，这是一种将机器学习黑盒的灵活性与匹配的可解释性相结合的框架，匹配是观察性因果推断中长期以来的一种工具。在许多高风险的因果推断应用中，可解释性是至关重要的。当前非参数估计平均和个性化治疗效果的工具都是黑盒子，不允许人类审计估计结果。我们的框架使用机器学习来学习用于匹配单位和估计结果的最佳度量，从而实现了机器学习黑盒子的性能，同时保持可解释性。我们的广义框架包含多个已发表作品作为特殊情况。我们为我们提出的框架提供渐近推断理论，使用户能够在个性化和平均治疗效果估计的结果周围构建近似置信区间。我们实证表明匹配机器学习的实例具有极高的表现。

    We introduce Matched Machine Learning, a framework that combines the flexibility of machine learning black boxes with the interpretability of matching, a longstanding tool in observational causal inference. Interpretability is paramount in many high-stakes application of causal inference. Current tools for nonparametric estimation of both average and individualized treatment effects are black-boxes that do not allow for human auditing of estimates. Our framework uses machine learning to learn an optimal metric for matching units and estimating outcomes, thus achieving the performance of machine learning black-boxes, while being interpretable. Our general framework encompasses several published works as special cases. We provide asymptotic inference theory for our proposed framework, enabling users to construct approximate confidence intervals around estimates of both individualized and average treatment effects. We show empirically that instances of Matched Machine Learning perform on 
    
[^11]: 并行退火混合时间的改进界限

    Improved Bound for Mixing Time of Parallel Tempering. (arXiv:2304.01303v1 [cs.LG])

    [http://arxiv.org/abs/2304.01303](http://arxiv.org/abs/2304.01303)

    本研究提出了一种新的并行退火的下界，对除$\log L$之外的所有参数具有多项式依赖性，其改进了现有界限。因此，该算法的混合时间可能更优。

    

    在采样算法领域中，当直接采样不可行时，MCMC（马尔科夫链蒙特卡罗）方法被广泛使用。然而，目标分布的多模态通常导致收敛速度缓慢和混合不佳。一种常见的解决方案是并行退火。尽管其在实践中非常有效，但其性能的理论保证有限。在本文中，我们提出了一个新的关于并行退火谱间隙的下界，其对除$\log L$之外的所有参数具有多项式依赖性，其中$(L + 1)$是级数的数量。这改进了现有界限，其与模态数呈指数关系。此外，我们用谱间隙的假设上界来补充我们的结果，其对$\log L$具有指数依赖性，这表明在某种意义上，我们的界限是紧密的。

    In the field of sampling algorithms, MCMC (Markov Chain Monte Carlo) methods are widely used when direct sampling is not possible. However, multimodality of target distributions often leads to slow convergence and mixing. One common solution is parallel tempering. Though highly effective in practice, theoretical guarantees on its performance are limited. In this paper, we present a new lower bound for parallel tempering on the spectral gap that has a polynomial dependence on all parameters except $\log L$, where $(L + 1)$ is the number of levels. This improves the best existing bound which depends exponentially on the number of modes. Moreover, we complement our result with a hypothetical upper bound on spectral gap that has an exponential dependence on $\log L$, which shows that, in some sense, our bound is tight.
    
[^12]: 通过高斯过程求解非线性偏微分方程的稀疏Cholesky分解方法

    Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes. (arXiv:2304.01294v1 [math.NA])

    [http://arxiv.org/abs/2304.01294](http://arxiv.org/abs/2304.01294)

    本文提出了一种稀疏Cholesky分解算法，用于高斯过程求解非线性偏微分方程，能够有效处理高维和畸形域的问题。

    

    本文研究了一个高斯过程框架求解一般非线性偏微分方程的计算可伸缩性。这个框架把求解PDE转化为解非线性约束下的二次优化问题。其复杂度的瓶颈在于利用高斯过程的协方差核及其在拟合点的偏导数进行点对点计算所得到的密集协方差矩阵的计算。我们提出了一种基于Diracs和导数测量的新排列顺序的稀疏Cholesky分解算法用于计算此类协方差矩阵。我们严格地确定了该Cholesky分解的稀疏模式，并量化了相应Vecchia近似的指数收敛精度，在Kullback-Leibler距离度量下达到最优。这使我们能够以$O(N\log^d(N/\epsilon))$的空间复杂度和$O(N\log^{d+2}(N/\epsilon))$的时间复杂度计算$\epsilon$-近似的逆Cholesky因子。其中，$N$表示拟合点的数量，$d$为物理域的维数。我们在几个高维（最高可达到$d=50$）和畸形域的基准问题上展示了这种方法的有效性。

    We study the computational scalability of a Gaussian process (GP) framework for solving general nonlinear partial differential equations (PDEs). This framework transforms solving PDEs to solving quadratic optimization problem with nonlinear constraints. Its complexity bottleneck lies in computing with dense kernel matrices obtained from pointwise evaluations of the covariance kernel of the GP and its partial derivatives at collocation points.  We present a sparse Cholesky factorization algorithm for such kernel matrices based on the near-sparsity of the Cholesky factor under a new ordering of Diracs and derivative measurements. We rigorously identify the sparsity pattern and quantify the exponentially convergent accuracy of the corresponding Vecchia approximation of the GP, which is optimal in the Kullback-Leibler divergence. This enables us to compute $\epsilon$-approximate inverse Cholesky factors of the kernel matrices with complexity $O(N\log^d(N/\epsilon))$ in space and $O(N\log^{
    
[^13]: $\ell_1$和logistic回归的近线性常数因子草图

    Almost Linear Constant-Factor Sketching for $\ell_1$ and Logistic Regression. (arXiv:2304.00051v1 [cs.DS])

    [http://arxiv.org/abs/2304.00051](http://arxiv.org/abs/2304.00051)

    本文提出了一种近线性、常数因子草图，适用于$\ell_1$和logistic回归，具有小的草图维度和高精度，这种草图还在草图空间内提供了高效的优化问题求解方法。

    

    我们改进了以前关于$\ell_1$和Logistic回归的草图算法结果，得到了更小的草图维度和更高的精度，我们的结果在草图空间内产生了高效的优化问题。特别地，我们对于任何常数$c>0$，实现了$\ell_1$回归的草图维度为$\tilde{O}(d^{1+c})$，而对于Logistic回归则为$\tilde{O}(\mu d^{1+c})$，其中$\mu$是一个标准的度量，捕获了压缩数据的复杂性。对于$\ell_1$回归，我们的草图维度是近线性的，具有比先前的工作更高的精度和更小的草图维度。类似地，对于Logistic回归，以前的工作在其草图维度上有更差的$\operatorname{poly}(\mu d)$因子。我们还提供了一种折衷方案，通过增加总大小到$(d\log$，在输入稀疏性时间内产生了$1+\varepsilon$的近似值。

    We improve upon previous oblivious sketching and turnstile streaming results for $\ell_1$ and logistic regression, giving a much smaller sketching dimension achieving $O(1)$-approximation and yielding an efficient optimization problem in the sketch space. Namely, we achieve for any constant $c>0$ a sketching dimension of $\tilde{O}(d^{1+c})$ for $\ell_1$ regression and $\tilde{O}(\mu d^{1+c})$ for logistic regression, where $\mu$ is a standard measure that captures the complexity of compressing the data. For $\ell_1$-regression our sketching dimension is near-linear and improves previous work which either required $\Omega(\log d)$-approximation with this sketching dimension, or required a larger $\operatorname{poly}(d)$ number of rows. Similarly, for logistic regression previous work had worse $\operatorname{poly}(\mu d)$ factors in its sketching dimension. We also give a tradeoff that yields a $1+\varepsilon$ approximation in input sparsity time by increasing the total size to $(d\log
    
[^14]: 非对称矩阵特征向量的推断

    Inference on eigenvectors of non-symmetric matrices. (arXiv:2303.18233v1 [math.ST])

    [http://arxiv.org/abs/2303.18233](http://arxiv.org/abs/2303.18233)

    本研究探讨了建立渐近推断非对称矩阵特征向量程序的必要条件，并针对完全向量和每个系数假设分别建立了 Wald 和 t 检验的分布理论，是多元统计学中的一种有用工具。

    

    本文认为，Tyler（1981）的可对称化条件并非建立渐近推断特征向量程序所必需的。 我们为完全向量和每个系数假设分别建立了 Wald 和 t 检验的分布理论。 我们的检验统计量来源于非对称矩阵的特征投影。 通过将投影表示为从基础矩阵到其谱数据的映射，我们通过解析摄动理论找到了导数。 这些结果演示了 Sun（1991）的解析摄动理论是多元统计学中的一种有用工具，并且具有独立的兴趣。作为一种应用，我们为由有向图引发的邻接矩阵估计的 Bonacich 中心性定义置信区间。

    This paper argues that the symmetrisability condition in Tyler(1981) is not necessary to establish asymptotic inference procedures for eigenvectors. We establish distribution theory for a Wald and t-test for full-vector and individual coefficient hypotheses, respectively. Our test statistics originate from eigenprojections of non-symmetric matrices. Representing projections as a mapping from the underlying matrix to its spectral data, we find derivatives through analytic perturbation theory. These results demonstrate how the analytic perturbation theory of Sun(1991) is a useful tool in multivariate statistics and are of independent interest. As an application, we define confidence sets for Bonacich centralities estimated from adjacency matrices induced by directed graphs.
    
[^15]: 潜在位置模型上的图形Nadaraya-Watson估计器

    The Graphical Nadaraya-Watson Estimator on Latent Position Models. (arXiv:2303.17229v1 [stat.ML])

    [http://arxiv.org/abs/2303.17229](http://arxiv.org/abs/2303.17229)

    研究了潜在位置模型上的图形Nadaraya-Watson估计器的性质，对于更复杂的方法有理论指导意义。

    

    鉴于有标记节点的图形，我们对估计器的质量感兴趣，该估计器针对未标记节点预测其标记邻居的观测值的平均值。我们在这个背景下严格研究了浓度属性、方差界和风险界。虽然估计器本身非常简单，数据生成过程对于实际应用过于理想，但我们相信我们的小步骤将有助于更复杂方法（如图形神经网络）的理论理解。

    Given a graph with a subset of labeled nodes, we are interested in the quality of the averaging estimator which for an unlabeled node predicts the average of the observations of its labeled neighbours. We rigorously study concentration properties, variance bounds and risk bounds in this context. While the estimator itself is very simple and the data generating process is too idealistic for practical applications, we believe that our small steps will contribute towards the theoretical understanding of more sophisticated methods such as Graph Neural Networks.
    
[^16]: 基于列表的在线分类

    List Online Classification. (arXiv:2303.15383v1 [cs.LG])

    [http://arxiv.org/abs/2303.15383](http://arxiv.org/abs/2303.15383)

    本文研究了多标签列表的在线预测问题，提出了 $b$-ary Littlestone 维度可学习模型，并且在懵懂的情况下探索不同的情况。可以使用改编自 Littlestone 的 SOA 和 Rosenblatt 的感知器等算法进行预测，同时还建立了列表可学习的组合结果。

    

    我们研究多分类在线预测，其中学习者可以使用多个标签的列表进行预测（与传统设置中仅使用一种标签不同）。我们使用 $b$-ary Littlestone 维度表征了该模型中的可学习性。该维度是经典 Littlestone 维度的变体，其中二进制错误树被替换为 $(k+1)$-ary 错误树，其中 k 是列表中标签的数量。在懵懂的场景中，我们根据比较类中是否包含单标签或多标签函数以及它与算法使用的列表大小之间的权衡来探索不同的情况。我们发现在某些情况下可以实现负悔，同时提供了什么情况下实现负悔的完整特性化。作为我们工作的一部分，我们改编了经典算法，如 Littlestone 的 SOA 和 Rosenblatt 的感知器，以使用标签列表进行预测。我们还为可以进行列表学习的组合结果建立了基础。

    We study multiclass online prediction where the learner can predict using a list of multiple labels (as opposed to just one label in the traditional setting). We characterize learnability in this model using the $b$-ary Littlestone dimension. This dimension is a variation of the classical Littlestone dimension with the difference that binary mistake trees are replaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in the list. In the agnostic setting, we explore different scenarios depending on whether the comparator class consists of single-labeled or multi-labeled functions and its tradeoff with the size of the lists the algorithm uses. We find that it is possible to achieve negative regret in some cases and provide a complete characterization of when this is possible. As part of our work, we adapt classical algorithms such as Littlestone's SOA and Rosenblatt's Perceptron to predict using lists of labels. We also establish combinatorial results for list-learnable c
    
[^17]: 用分位随机森林模型在密度泛函理论中外推完备基组极限

    Extrapolation to complete basis-set limit in density-functional theory by quantile random-forest models. (arXiv:2303.14760v2 [physics.comp-ph] CROSS LISTED)

    [http://arxiv.org/abs/2303.14760](http://arxiv.org/abs/2303.14760)

    本文利用分位随机森林模型外推完备基组极限，并提供了预测区间以量化模型的不确定性。

    

    密度泛函理论（DFT）计算的数值精度取决于各种计算参数，其中最关键的之一是基组大小。理论上，使用无限大的基组，即完备基组集，可以达到最高精度。我们的目标是找到一种机器学习模型，将有限基组大小计算外推到完备基组极限。我们从63个二元固体的数据集开始，这些固体使用两种全电子DFT代码，即exciting和FHI-aims，这两种代码使用非常不同类型的基组。使用分位随机森林模型来估计基组大小关于全收敛计算的总能量修正。该随机森林模型对于两种代码都实现了小于25%的对称平均绝对百分比误差，而且胜过了文献中之前的方法。我们的方法还提供了预测区间，可以量化模型的不确定性。

    The numerical precision of density-functional-theory (DFT) calculations depends on a variety of computational parameters, one of the most critical being the basis-set size. The ultimate precision is reached with an infinitely large basis set, i.e., in the limit of a complete basis set (CBS). Our aim in this work is to find a machine-learning model that extrapolates finite basis-size calculations to the CBS limit. We start with a data set of 63 binary solids investigated with two all-electron DFT codes, exciting and FHI-aims, which employ very different types of basis sets. A quantile-random-forest model is used to estimate the total-energy correction with respect to a fully converged calculation as a function of the basis-set size. The random-forest model achieves a symmetric mean absolute percentage error of lower than 25% for both codes and outperforms previous approaches in the literature. Our approach also provides prediction intervals, which quantify the uncertainty of the models'
    
[^18]: 因果剃刀

    Causal Razors. (arXiv:2302.10331v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10331](http://arxiv.org/abs/2302.10331)

    本文比较了许多出现在文献中的因果剃刀，并特别研究了在多项式因果模型中不太受欢迎的因果剃刀——参数最小性。逻辑结果揭示了选择合理得分标准时的困境。

    

    在进行因果推断时，必须对真实因果机制如何与底层联合概率分布相对应做出假设。本文将这些假设称为因果剃刀。我们回顾了许多出现在文献中的因果剃刀，对它们进行了全面的逻辑比较。特别地，我们对在多项式因果模型中不太受欢迎的因果剃刀——参数最小性进行了深入的研究，并研究了它与其他广泛研究的因果剃刀之间的逻辑关系。我们的逻辑结果在为基于分数的因果搜索算法选择合理得分标准时提出了困境。

    When performing causal discovery, assumptions have to be made on how the true causal mechanism corresponds to the underlying joint probability distribution. These assumptions are labeled as causal razors in this work. We review numerous causal razors that appeared in the literature, and offer a comprehensive logical comparison of them. In particular, we scrutinize an unpopular causal razor, namely parameter minimality, in multinomial causal models and its logical relations with other well-studied causal razors. Our logical result poses a dilemma in selecting a reasonable scoring criterion for score-based casual search algorithms.
    
[^19]: 通过D适应实现学习率自由学习

    Learning-Rate-Free Learning by D-Adaptation. (arXiv:2301.07733v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07733](http://arxiv.org/abs/2301.07733)

    D-Adaptation是一种可以自动设置学习率的方法，针对最小化凸性Lipschitz函数，用于实现最优收敛速率，而无需超参数，也无需额外对数因子改进，能够在各种机器学习问题中自动匹配手动调整的学习率。

    

    D适应是一种自动设置学习率的方法，可以渐近地实现最优收敛速率，用于最小化凸性Lipschitz函数，无需回溯或线性搜索，并且每步无需进行额外的函数值或梯度评估。我们的方法是这一类问题的第一个无超参数且收敛速率无需额外对数因子改进的方法。我们针对SGD和Adam变体展示了广泛的实验，其中该方法自动匹配手动调整的学习率，在十多个不同的机器学习问题中应用，包括大规模的视觉和语言问题。开源实现在 \url{https://github.com/facebookresearch/dadaptation}.

    D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems.  An open-source implementation is available at \url{https://github.com/facebookresearch/dadaptation}.
    
[^20]: 一种用于终身测试时间自适应的概率框架

    A Probabilistic Framework for Lifelong Test-Time Adaptation. (arXiv:2212.09713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.09713](http://arxiv.org/abs/2212.09713)

    本文提出了一种用于处理测试输入分布随时间持续变化的概率框架PETAL，通过提供可靠的不确定性估计和使用源模型作为正则化项来推断时正则化模型更新，实现了终身TTA。

    

    测试时间适应（TTA）是在推理时针对来自不同目标域的测试输入更新预先训练的源模型的问题。目前大多数TTA方法都假设目标域是静态的，即所有测试输入都来自单个目标域。然而，在许多实际应用场景中，测试输入分布可能随着时间的推移而发生终身/持续变化。此外，现有的TTA方法也缺乏提供可靠的不确定性估计的能力，而在源域和目标域之间发生分布变化时，这一点至关重要。为了解决这些问题，我们提出了PETAL（具有自我训练先验知识的概率终身测试时间自适应），它使用概率方法解决了终身TTA问题，自然地得到了（1）学生-教师框架，其中教师模型是学生模型的指数移动平均值，以及（2）使用源模型作为正则化项来推断时正则化模型更新。

    Test-time adaptation (TTA) is the problem of updating a pre-trained source model at inference time given test input(s) from a different target domain. Most existing TTA approaches assume the setting in which the target domain is stationary, i.e., all the test inputs come from a single target domain. However, in many practical settings, the test input distribution might exhibit a lifelong/continual shift over time. Moreover, existing TTA approaches also lack the ability to provide reliable uncertainty estimates, which is crucial when distribution shifts occur between the source and target domain. To address these issues, we present PETAL (Probabilistic lifElong Test-time Adaptation with seLf-training prior), which solves lifelong TTA using a probabilistic approach, and naturally results in (1) a student-teacher framework, where the teacher model is an exponential moving average of the student model, and (2) regularizing the model updates at inference time using the source model as a reg
    
[^21]: 带有随机集合的贝叶斯后验近似

    Bayesian posterior approximation with stochastic ensembles. (arXiv:2212.08123v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08123](http://arxiv.org/abs/2212.08123)

    本文提出一种新方法，即使用随机神经网络集合来近似贝叶斯后验，并通过变分推断进行训练，实验证明该方法比其他流行的贝叶斯推断基线提供了更准确的后验估计。

    

    我们引入一种基于随机神经网络集的方法来近似贝叶斯后验。它将随机方法（如dropout）与深度集成相结合，并将随机集合公式化为分布族，并使用变分推断训练以近似贝叶斯后验。我们在一个玩具问题和CIFAR图像分类上实现了基于Monte Carlo Dropout，DropConnect和新颖的非参数版本的随机集合，并直接与哈密顿马尔可夫蒙特卡罗模拟比较质量来测试后验。结果表明，随机集合提供了比其他流行的贝叶斯推断基线更准确的后验估计。

    We introduce ensembles of stochastic neural networks to approximate the Bayesian posterior, combining stochastic methods such as dropout with deep ensembles. The stochastic ensembles are formulated as families of distributions and trained to approximate the Bayesian posterior with variational inference. We implement stochastic ensembles based on Monte Carlo dropout, DropConnect and a novel non-parametric version of dropout and evaluate them on a toy problem and CIFAR image classification. For both tasks, we test the quality of the posteriors directly against Hamiltonian Monte Carlo simulations. Our results show that stochastic ensembles provide more accurate posterior estimates than other popular baselines for Bayesian inference.
    
[^22]: FaiREE：具有有限样本和无分布保证的公平分类算法

    FaiREE: Fair Classification with Finite-Sample and Distribution-Free Guarantee. (arXiv:2211.15072v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.15072](http://arxiv.org/abs/2211.15072)

    本研究提出了FaiREE算法，它是一种可满足群体公平性约束的公平分类算法，并且具有有限样本和无分布理论保证。在实验中表现优异。

    

    算法公平性在机器学习研究中发挥着越来越重要的作用。已经提出了几种群体公平性概念和算法。然而，现有公平分类方法的公平保证主要依赖于特定的数据分布假设，通常需要大样本量，并且在样本量较小的情况下可能会违反公平性，而这在实践中经常发生。本文提出了FaiREE算法，它是一种公平分类算法，可以在有限样本和无分布理论保证下满足群体公平性约束。FaiREE可以适应各种群体公平性概念（例如，机会平等，平衡几率，人口统计学平衡等）并实现最佳准确性。这些理论保证进一步得到了对合成和实际数据的实验支持。FaiREE表现出比最先进的算法更好的性能。

    Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depends on specific data distributional assumptions, often requiring large sample sizes, and fairness could be violated when there is a modest number of samples, which is often the case in practice. In this paper, we propose FaiREE, a fair classification algorithm that can satisfy group fairness constraints with finite-sample and distribution-free theoretical guarantees. FaiREE can be adapted to satisfy various group fairness notions (e.g., Equality of Opportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal accuracy. These theoretical guarantees are further supported by experiments on both synthetic and real data. FaiREE is shown to have favorable performance over state-of-the-art algorithms.
    
[^23]: 线性回归系数的异常鲁棒稀疏估计

    Outlier Robust and Sparse Estimation of Linear Regression Coefficients. (arXiv:2208.11592v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2208.11592](http://arxiv.org/abs/2208.11592)

    本文介绍了一种异常鲁棒稀疏估计方法，可用于线性回归系数的协方差矩阵已知或未知的情况下，具有较尖锐的误差界，适用于采样自$\mathfrak{L}$-subGaussian分布和重尾分布的协变量向量和噪声。

    

    我们考虑当协变量向量和噪声分别从$\mathfrak{L}$-subGaussian分布和重尾分布中随机采样时，对线性回归系数进行异常鲁棒稀疏估计。此外，协变量向量和噪声受到对抗性异常值的污染。我们处理两种情况：协变量的协方差矩阵已知或未知。特别地，在已知情况下，我们的估计器可以达到近似信息理论最优的误差界，且我们的误差界比早期处理类似情况的研究更加尖锐。我们的估计器分析在推导尖锐的误差界方面严重依赖于通用链。

    We consider outlier-robust and sparse estimation of linear regression coefficients, when covariate vectors and noises are sampled, respectively, from an $\mathfrak{L}$-subGaussian distribution and a heavy-tailed distribution. Additionally, the covariate vectors and noises are contaminated by adversarial outliers. We deal with two cases: the covariance matrix of the covariates is known or unknown. Particularly, in the known case, our estimator can attain a nearly information theoretical optimal error bound, and our error bound is sharper than those of earlier studies dealing with similar situations. Our estimator analysis relies heavily on generic chaining to derive sharp error bounds.
    
[^24]: 极端分位数回归的神经网络与洪水风险预测应用

    Neural Networks for Extreme Quantile Regression with an Application to Forecasting of Flood Risk. (arXiv:2208.07590v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2208.07590](http://arxiv.org/abs/2208.07590)

    本文提出了一种结合神经网络和极值理论的EQRN模型，它能够在存在复杂预测变量相关性的情况下进行外推，并且能够应用于洪水风险预测中，提供一天前回归水平和超出概率的预测。

    

    针对极端事件的风险评估需要准确估计超出历史观测范围的高分位数。当风险依赖于观测预测变量的值时，回归技术用于在预测空间中进行插值。我们提出了EQRN模型，它将神经网络和极值理论的工具结合起来，形成一种能够在复杂预测变量相关性存在的情况下进行外推的方法。神经网络可以自然地将数据中的附加结构纳入其中。我们开发了EQRN的循环版本，能够捕捉时间序列中复杂的顺序相关性。我们将这种方法应用于瑞士Aare流域的洪水风险预测。它利用空间和时间上的多个协变量信息，提供一天前回归水平和超出概率的预测。这个输出补充了传统极值分析的静态回归水平，并且预测能够适应分布变化。

    Risk assessment for extreme events requires accurate estimation of high quantiles that go beyond the range of historical observations. When the risk depends on the values of observed predictors, regression techniques are used to interpolate in the predictor space. We propose the EQRN model that combines tools from neural networks and extreme value theory into a method capable of extrapolation in the presence of complex predictor dependence. Neural networks can naturally incorporate additional structure in the data. We develop a recurrent version of EQRN that is able to capture complex sequential dependence in time series. We apply this method to forecasting of flood risk in the Swiss Aare catchment. It exploits information from multiple covariates in space and time to provide one-day-ahead predictions of return levels and exceedances probabilities. This output complements the static return level from a traditional extreme value analysis and the predictions are able to adapt to distribu
    
[^25]: 深度批量主动学习回归的框架和基准

    A Framework and Benchmark for Deep Batch Active Learning for Regression. (arXiv:2203.09410v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.09410](http://arxiv.org/abs/2203.09410)

    本研究提出了一个深度批量主动学习回归的框架和基准测试，其中包括许多现有的贝叶斯和非贝叶斯方法。提出了一种替换常用最后一层特征的新方法，并结合一种新颖的聚类方法。在15个大型表格回归数据集上进行测试，该方法在基准测试中表现优异，适用于大型数据集且易于使用。

    

    标注监督学习数据的获取成本较高。为了提高神经网络回归的样本效率，我们研究了自适应选择无标签数据批次进行标注的主动学习方法。我们提出了一个框架，用于构建这样的方法，基于(网络相关的)基础核、核变换和选择方法。我们的框架包括许多现有的基于高斯过程逼近神经网络的贝叶斯方法以及非贝叶斯方法。此外，我们建议用描绘有限宽度神经正切核替换常用的最后一层特征，并将它们与一种新颖的聚类方法相结合。为了评估不同的方法，我们介绍了一个由15个大型表格回归数据集组成的开放源代码的基准测试。我们提出的方法在基准测试中优于现有技术水平，适用于大型数据集，并且可以直接使用，无需调整网络架构或训练。

    The acquisition of labels for supervised learning can be expensive. In order to improve the sample-efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian Process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width Neural Tangent Kernels, and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or traini
    
[^26]: 高维参数学习的迭代分块粒子滤波算法：摆脱维度灾难。

    Iterated Block Particle Filter for High-dimensional Parameter Learning: Beating the Curse of Dimensionality. (arXiv:2110.10745v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.10745](http://arxiv.org/abs/2110.10745)

    本文提出了一种迭代分块粒子滤波算法，用于学习高维参数。该算法克服了维度灾难，表现出良好的收敛性和似然最大化，成功地在非线性和非高斯空间时间模型上实现了参数学习。

    

    高维、部分观测和非线性随机过程的参数学习是一种方法论上的挑战。空间时间疾病传播系统提供了这种产生开放推断问题的过程的示例。我们提出了迭代分块粒子滤波算法，用于学习具有一般状态空间、测量、转移密度和图结构的图形状态空间模型的高维参数。对击败维度灾难 (COD)、算法收敛和似然最大化获得了理论性能保证。对麻疹传播的高度非线性和非高斯空间时间模型进行的实验表明，迭代集合卡尔曼滤波算法 (Li et al. (2020)) 是无效的，而迭代滤波算法 (Ionides et al. (2015)) 受到维度灾难的困扰，而我们的IBPF算法在各种具有不同度量的实验中始终击败了COD。

    Parameter learning for high-dimensional, partially observed, and nonlinear stochastic processes is a methodological challenge. Spatiotemporal disease transmission systems provide examples of such processes giving rise to open inference problems. We propose the iterated block particle filter (IBPF) algorithm for learning high-dimensional parameters over graphical state space models with general state spaces, measures, transition densities and graph structure. Theoretical performance guarantees are obtained on beating the curse of dimensionality (COD), algorithm convergence, and likelihood maximization. Experiments on a highly nonlinear and non-Gaussian spatiotemporal model for measles transmission reveal that the iterated ensemble Kalman filter algorithm (Li et al. (2020)) is ineffective and the iterated filtering algorithm (Ionides et al. (2015)) suffers from the COD, while our IBPF algorithm beats COD consistently across various experiments with different metrics.
    
[^27]: 自适应联合分布学习

    Adaptive joint distribution learning. (arXiv:2110.04829v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.04829](http://arxiv.org/abs/2110.04829)

    该论文提出了一种自适应联合分布学习的框架，可以从大量数据点中估计低维、归一化和正的Radon-Nikodym导数模型，并在不同学习问题上取得了良好的结果。

    

    我们开发了一个新的框架，用于将联合概率分布嵌入张量积再生核希尔伯特空间（RKHS）中。我们的框架可以容纳一个低维、归一化和正的Radon-Nikodym导数模型，该模型可以从多达数百万个数据点的样本大小中进行估计，减轻了RKHS建模的固有限制。我们的方法自然产生了定义良好的归一化和正的条件分布。嵌入计算速度快且适用于从预测到分类的各种学习问题。我们的理论结果得到了有益的数值结果的支持。

    We develop a new framework for embedding joint probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). Our framework accommodates a low-dimensional, normalized and positive model of a Radon-Nikodym derivative, which we estimate from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and accommodates learning problems ranging from prediction to classification. Our theoretical findings are supplemented by favorable numerical results.
    
[^28]: 一种实用的模型分析方法在单个被试功能性磁共振成像研究中提高激活检测的精度

    A practical model-based segmentation approach for improved activation detection in single-subject functional Magnetic Resonance Imaging studies. (arXiv:2102.03639v3 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2102.03639](http://arxiv.org/abs/2102.03639)

    本研究提出了一种计算可行和方法学上合理的基于模型的方法来解决单个被试和低信号背景下的功能性磁共振成像的激活检测问题，并能够区分不同强度的激活，通过在 R 包 MixfMRI 中实现可以得到具体应用。

    

    功能性磁共振成像（fMRI）用于对刺激的大脑激活进行成像，但是在低信号环境和单个受试研究中往往难以检测到这种激活。考虑到实际上只有极少数体素真正被激活，而且这些体素在空间上是局部化的，因此可以通过准确的激活检测来指导。本研究通过发展一种计算可行和方法学上合理的基于模型的方法来应对这个挑战，在 R 包 MixfMRI 中实现，其限制了先验预期的激活体素比例，并结合了空间上下文。我们的方法的一个附加优势是能够区分不同强度激活的体素和区域。本研究的方法在现实的二维和三维模拟实验以及多个真实世界数据集中得到评估。

    Functional Magnetic Resonance Imaging (fMRI) maps cerebral activation in response to stimuli but this activation is often difficult to detect, especially in low-signal contexts and single-subject studies. Accurate activation detection can be guided by the fact that very few voxels are, in reality, truly activated and that these voxels are spatially localized, but it is challenging to incorporate both these facts. We address these twin challenges to single-subject and low-signal fMRI by developing a computationally feasible and methodologically sound model-based approach, implemented in the R package MixfMRI, that bounds the a priori expected proportion of activated voxels while also incorporating spatial context. An added benefit of our methodology is the ability to distinguish voxels and regions having different intensities of activation. Our suggested approach is evaluated in realistic two- and three-dimensional simulation experiments as well as on multiple real-world datasets. Final
    
[^29]: MARS:张量分解中的自动排名选择问题

    MARS: Masked Automatic Ranks Selection in Tensor Decompositions. (arXiv:2006.10859v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.10859](http://arxiv.org/abs/2006.10859)

    本文介绍了一种名为MARS的新型高效方法，在一般的张量分解中自动选择秩，学习二值掩码来选择最佳的张量结构，在实验中显示出更好的结果。

    

    张量分解方法已被证明在各种应用中具有很好的效果，包括神经网络的压缩和加速。同时，确定最优分解秩的问题仍然很严峻，因为它是控制压缩-准确性平衡的关键参数。本文介绍了一种名为MARS的新型高效方法，在一般的张量分解中自动选择秩。在训练过程中，该方法学习二值掩码，这些掩码可以选择最佳的张量结构。学习是通过特定的贝叶斯模型中的松弛最大后验(MAP)估计来完成的，并可以自然地嵌入到标准的神经网络训练过程中。各种实验表明，与先前的工作相比，MARS在各种任务中都取得了更好的结果。

    Tensor decomposition methods have proven effective in various applications, including compression and acceleration of neural networks. At the same time, the problem of determining optimal decomposition ranks, which present the crucial parameter controlling the compression-accuracy trade-off, is still acute. In this paper, we introduce MARS -- a new efficient method for the automatic selection of ranks in general tensor decompositions. During training, the procedure learns binary masks over decomposition cores that "select" the optimal tensor structure. The learning is performed via relaxed maximum a posteriori (MAP) estimation in a specific Bayesian model and can be naturally embedded into the standard neural network training routine. Diverse experiments demonstrate that MARS achieves better results compared to previous works in various tasks.
    

