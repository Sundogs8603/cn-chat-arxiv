# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Temporal-spatial model via Trend Filtering.](http://arxiv.org/abs/2308.16172) | 本研究通过趋势滤波方法对具有时空依赖性的数据进行了非参数回归函数的估计，研究了该方法在单变量和多变量情况下的应用，并验证了其极小化性。研究发现了以往未曾探索的独特相变现象，并通过仿真和实际数据应用验证了方法的优越性能。 |
| [^2] | [survex: an R package for explaining machine learning survival models.](http://arxiv.org/abs/2308.16113) | survex是一个R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型，可以改进模型，提高透明度和责任感。 |
| [^3] | [Likelihood-based inference and forecasting for trawl processes: a stochastic optimization approach.](http://arxiv.org/abs/2308.16092) | 本研究开发了一种基于似然的方法来推断渔网过程，并引入了新颖的预测方法。通过使用复合似然函数和迭代梯度下降方法，我们成功地估计了渔网过程的参数，并减小了估计器的方差。这项研究为进一步研究渔网过程提供了重要的方法学基础。 |
| [^4] | [A Parameter-Free Two-Bit Covariance Estimator with Improved Operator Norm Error Rate.](http://arxiv.org/abs/2308.16059) | 提出了一种无需参数的二位协方差估计器，通过使用变化的抖动尺度，解决了在协方差矩阵对角线主导情况下估计器与样本协方差之间的算子范数误差差距以及依赖未知参数的抖动尺度问题。 |
| [^5] | [PAVI: Plate-Amortized Variational Inference.](http://arxiv.org/abs/2308.16022) | PAVI是一种板块化的变分推断方法，能够高效地处理大规模人口研究，通过共享参数化和学习加速训练变分分布，实现了在大规模分层问题上的表达力强和简明的结果。 |
| [^6] | [Domain Generalization without Excess Empirical Risk.](http://arxiv.org/abs/2308.15856) | 本论文提出了一种解决域泛化中过量风险问题的方法，通过在保证经验风险最优的约束下最小化惩罚，避免了惩罚对经验风险优化的影响。 |
| [^7] | [Adaptive Lasso, Transfer Lasso, and Beyond: An Asymptotic Perspective.](http://arxiv.org/abs/2308.15838) | 本文研究了自适应Lasso和转移Lasso的理论性质，通过对转移Lasso的渐进性质进行理论研究，分析了它与自适应Lasso的区别，并提出了一种新的方法，将两者的优势进行了融合并补偿了他们的弱点。 |
| [^8] | [Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials.](http://arxiv.org/abs/2308.15728) | 通过低次多项式计算图论估计存在计算障碍，传统的优化估计方法具有指数级的计算复杂度，而最优多项式时间估计器只能达到较慢的估计错误率。 |
| [^9] | [Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation.](http://arxiv.org/abs/2308.15709) | 本论文研究了数据价值评估面临的隐私挑战，并提出了一种隐私友好的改进方法TKNN-Shapley，该方法在保护隐私的前提下能够评估数据质量，具有较好的隐私-实用性权衡。 |
| [^10] | [Clustering Without an Eigengap.](http://arxiv.org/abs/2308.15642) | 这个论文介绍了在随机块模型中进行图聚类的新算法，能够恢复大聚类，无论其他聚类的大小，并且对中等大小的聚类提出了新的技术挑战。 |
| [^11] | [Mixed Variational Flows for Discrete Variables.](http://arxiv.org/abs/2308.15613) | 本文提出了一种混合方差流方法，用于近似离散分布，通过开发一个离散且保持度量的映射，而不需要连续嵌入。实验证明，与连续嵌入流相比，该方法产生更可靠的近似。 |
| [^12] | [Parametric quantile autoregressive conditional duration models with application to intraday value-at-risk.](http://arxiv.org/abs/2308.15571) | 本文提出了一种新的扩展ACD模型，该模型基于以分位数重新参数化的对数对称分布，可以对不同的百分位数进行建模，而不是传统上使用的均值（或中位数）条件持续时间。 |
| [^13] | [Glocal Explanations of Expected Goal Models in Soccer.](http://arxiv.org/abs/2308.15559) | 本文提出了预期进球模型的全局解释（介于本地和全局之间的解释），通过使用聚合版本的SHAP值和部分依赖函数，可以对团队和球员水平进行绩效分析和知识提取。 |
| [^14] | [Pure Exploration under Mediators' Feedback.](http://arxiv.org/abs/2308.15552) | 本研究提出了一种严格推广的传统最优臂识别问题，即中介反馈下的最优臂识别（BAI-MF），通过引入中介者来模拟一些实际决策问题，如离线学习、部分可控环境和人类反馈。 |
| [^15] | [Tuning the perplexity for and computing sampling-based t-SNE embeddings.](http://arxiv.org/abs/2308.15513) | 本文通过采样的方法改进了大数据集下t-SNE嵌入的质量和计算速度。 |
| [^16] | [Deep Learning and Bayesian inference for Inverse Problems.](http://arxiv.org/abs/2308.15492) | 这项研究探讨了在反问题中应用深度学习和贝叶斯推断的方法。通过使用深度神经网络代理模型和近似计算，可以有效地解决复杂的反问题，并考虑不确定性。 |
| [^17] | [Noise-Free Sampling Algorithms via Regularized Wasserstein Proximals.](http://arxiv.org/abs/2308.14945) | 本文通过正则化Wasserstein Proximal方法提出了一种无噪声的抽样算法，通过给定的潜势函数确定性地进行粒子演化，并提供了优于传统方法的维度依赖性和速度收敛性能。 |
| [^18] | [On the Consistency of Average Embeddings for Item Recommendation.](http://arxiv.org/abs/2308.12767) | 本文研究了推荐系统中平均嵌入的一致性，并提出了一种衡量方法。实证结果表明，现实世界的平均嵌入在推荐中一致性较低，为进一步改进现实世界嵌入提供了方向。 |
| [^19] | [Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained Markov Decision Processes.](http://arxiv.org/abs/2306.07001) | 本文提出了一种创新的模型驱动的双重算法OptAug-CMDP，用于约束马尔可夫决策过程（CMDPs），解决了原先算法中安全性问题的缺陷，证明了其遗憾值优秀。 |
| [^20] | [Quantum Convolutional Neural Networks for Multi-Channel Supervised Learning.](http://arxiv.org/abs/2305.18961) | 本文介绍了多通道监督学习的量子卷积神经网络，通过硬件适应性的量子电路ansatzes用作卷积核，能够有效学习通道间信息，优于现有的QCNNs。 |
| [^21] | [Geometric Algebra Transformers.](http://arxiv.org/abs/2305.18415) | 本文介绍了一种通用架构几何代数变换器（GATr），用于解决几何数据问题。GATr使用投影几何代数表示输入输出和状态，具有可缩放性、表达性、多功能性。在n体建模和机器人规划的实验中，GATr相对于非几何基线表现出强大的改进。 |
| [^22] | [Leveraging Evolutionary Changes for Software Process Quality.](http://arxiv.org/abs/2305.18061) | 本文提出了一种利用演进变化来改善软件开发过程质量的方法，其包括使用统计过程控制和机器学习技术来分析应用程序生命周期管理所捕获的变更数据，实验表明该方法是有效的。 |
| [^23] | [On progressive sharpening, flat minima and generalisation.](http://arxiv.org/abs/2305.14683) | 本文提出了一种用损失黑塞矩阵和输入-输出雅克比矩阵联系起来的假设，量化了模型的输入-输出雅克比矩阵近似其在数据分布上的利普西茨范数的程度，并推导出了一个基于经验雅克比矩阵的新的泛化界，给出了关于进化磨锋和平坦极小的泛化性质的新解释。 |
| [^24] | [RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment.](http://arxiv.org/abs/2304.06767) | RAFT框架引入了奖励排名微调方法，用于对齐生成型基础模型，以解决强化学习带来的低效和不稳定性问题。 |
| [^25] | [Quantized Low-Rank Multivariate Regression with Random Dithering.](http://arxiv.org/abs/2302.11197) | 本文研究了量子化的低秩多元回归，通过采用均匀量化与随机抖动的方法，提出了约束Lasso和正则化Lasso估计器，实现了最小最优率的估计，同时量化仅对乘法因子略有影响。 |
| [^26] | [Rule Generation for Classification: Scalability, Interpretability, and Fairness.](http://arxiv.org/abs/2104.10751) | 这项研究介绍了一种新的基于规则的分类优化方法，利用列生成线性规划实现可扩展性，并通过分配成本系数和引入额外约束解决了解释性和公平性问题。该方法在局部解释性和公平性之间取得了良好的平衡。 |
| [^27] | [Coagent Networks Revisited.](http://arxiv.org/abs/2001.10474) | Coagent Networks（共智网络）是指在强化学习环境中协作的随机代理网络。这篇论文重新审视了共智网络理论，提出了执行路径的思想，并通过这一思想实现了对策梯度定理的简洁证明。 |
| [^28] | [On Low-rank Trace Regression under General Sampling Distribution.](http://arxiv.org/abs/1904.08576) | 本文研究了在一般采样分布下的低秩迹回归问题，并引入了一种通用峰值概念，提供了证明迹回归采样算子强凸性和获得非渐进、近乎最优界的方法。同时，将误差界扩展到以交叉验证选择正则化参数的情况下。 |

# 详细

[^1]: 通过趋势滤波进行时空模型建模

    Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v1 [stat.ME])

    [http://arxiv.org/abs/2308.16172](http://arxiv.org/abs/2308.16172)

    本研究通过趋势滤波方法对具有时空依赖性的数据进行了非参数回归函数的估计，研究了该方法在单变量和多变量情况下的应用，并验证了其极小化性。研究发现了以往未曾探索的独特相变现象，并通过仿真和实际数据应用验证了方法的优越性能。

    

    本研究侧重于对具有同时时间和空间依赖性的数据进行非参数回归函数的估计。在这种情况下，我们研究了趋势滤波，这是一种非参数估计方法，由Mammen和Rudin提出。在单变量设置中，我们考虑的信号假设具有有界总变异度的k次弱导数，允许一定程度的平滑性。在多变量情况下，我们研究了Padilla等人的K最近邻融合套索估计器，采用适用于具有有界变异度且符合分段利普希茨连续性准则的信号的ADMM算法。通过与下界对齐，我们验证了我们估计器的极小化性。通过分析，我们发现了以往趋势滤波研究中未曾探索过的独特相变现象。仿真研究和实际数据应用都突出了我们方法的出色性能。

    This research focuses on the estimation of a non-parametric regression function designed for data with simultaneous time and space dependencies. In such a context, we study the Trend Filtering, a nonparametric estimator introduced by \cite{mammen1997locally} and \cite{rudin1992nonlinear}. For univariate settings, the signals we consider are assumed to have a kth weak derivative with bounded total variation, allowing for a general degree of smoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused lasso estimator as in \cite{padilla2018adaptive}, employing an ADMM algorithm, suitable for signals with bounded variation that adhere to a piecewise Lipschitz continuity criterion. By aligning with lower bounds, the minimax optimality of our estimators is validated. A unique phase transition phenomenon, previously uncharted in Trend Filtering studies, emerges through our analysis. Both Simulation studies and real data applications underscore the superior performance of o
    
[^2]: survex：用于解释机器学习生存模型的R软件包

    survex: an R package for explaining machine learning survival models. (arXiv:2308.16113v1 [cs.LG])

    [http://arxiv.org/abs/2308.16113](http://arxiv.org/abs/2308.16113)

    survex是一个R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型，可以改进模型，提高透明度和责任感。

    

    由于其灵活性和出色性能，机器学习模型经常用于补充和超越传统的统计生存模型。然而，它们的广泛应用受到缺乏用户友好的工具来解释其内部操作和预测原理的限制。为了解决这个问题，我们引入了survex R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型。所提软件的功能包括理解和诊断生存模型，从而可以改进它们。通过揭示变量效应和重要性等决策过程的见解，survex能够评估模型的可靠性并检测偏差。因此，在生物医学研究和医疗应用等敏感领域可以促进透明度和责任。

    Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models. However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales. To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques. The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement. By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases. Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications.
    
[^3]: 基于似然的渔网过程推断和预测：一种随机优化方法

    Likelihood-based inference and forecasting for trawl processes: a stochastic optimization approach. (arXiv:2308.16092v1 [stat.ME])

    [http://arxiv.org/abs/2308.16092](http://arxiv.org/abs/2308.16092)

    本研究开发了一种基于似然的方法来推断渔网过程，并引入了新颖的预测方法。通过使用复合似然函数和迭代梯度下降方法，我们成功地估计了渔网过程的参数，并减小了估计器的方差。这项研究为进一步研究渔网过程提供了重要的方法学基础。

    

    本文考虑渔网过程，渔网过程是平稳且无限可分的随机过程，可以描述各种统计特性，如重尾和长记忆。我们开发了第一种基于似然的方法来推断实值渔网过程，并引入了新颖的确定性和概率预测方法。由于渔网过程是非马尔科夫过程，似然函数高度复杂，需要使用复合似然函数来简化捕捉其统计特性。我们将复合似然估计问题表示为随机优化问题，可以使用迭代梯度下降方法进行实现。我们提出了具有几个数量级减小方差的新颖梯度估计器。我们分析了这些估计器的理论性质和实际实施细节，并发布了一个Python库，可以用于拟合大类渔网过程。

    We consider trawl processes, which are stationary and infinitely divisible stochastic processes and can describe a wide range of statistical properties, such as heavy tails and long memory. In this paper, we develop the first likelihood-based methodology for the inference of real-valued trawl processes and introduce novel deterministic and probabilistic forecasting methods. Being non-Markovian, with a highly intractable likelihood function, trawl processes require the use of composite likelihood functions to parsimoniously capture their statistical properties. We formulate the composite likelihood estimation as a stochastic optimization problem for which it is feasible to implement iterative gradient descent methods. We derive novel gradient estimators with variances that are reduced by several orders of magnitude. We analyze both the theoretical properties and practical implementation details of these estimators and release a Python library which can be used to fit a large class of tr
    
[^4]: 一种无需参数的改进二位协方差估计器

    A Parameter-Free Two-Bit Covariance Estimator with Improved Operator Norm Error Rate. (arXiv:2308.16059v1 [stat.ML])

    [http://arxiv.org/abs/2308.16059](http://arxiv.org/abs/2308.16059)

    提出了一种无需参数的二位协方差估计器，通过使用变化的抖动尺度，解决了在协方差矩阵对角线主导情况下估计器与样本协方差之间的算子范数误差差距以及依赖未知参数的抖动尺度问题。

    

    最近Dirksen, Maly and Rauhut在《Annals of Statistics》上开发了一种使用每个条目两位的协方差矩阵估计器。该估计器在一般亚高斯分布下达到了近似极小化速率，但也存在两个问题：理论上，在协方差矩阵的对角线由少数条目主导时，其估计器与样本协方差之间存在本质上的算子范数误差差距；实际上，其性能严重依赖于需要根据一些未知参数进行调整的抖动尺度。在这项工作中，我们提出了一种同时解决这两个问题的新型二位协方差矩阵估计器。与Dirksen等人采用的均匀抖动相关的符号量化器不同，我们采用了受多位均匀量化器启发的三角抖动器之后再进行二位量化。通过使用各个条目之间变化的抖动尺度，我们的估计器获得了改进的算子范数误差率，该误差率取决于...

    A covariance matrix estimator using two bits per entry was recently developed by Dirksen, Maly and Rauhut [Annals of Statistics, 50(6), pp. 3538-3562]. The estimator achieves near minimax rate for general sub-Gaussian distributions, but also suffers from two downsides: theoretically, there is an essential gap on operator norm error between their estimator and sample covariance when the diagonal of the covariance matrix is dominated by only a few entries; practically, its performance heavily relies on the dithering scale, which needs to be tuned according to some unknown parameters. In this work, we propose a new 2-bit covariance matrix estimator that simultaneously addresses both issues. Unlike the sign quantizer associated with uniform dither in Dirksen et al., we adopt a triangular dither prior to a 2-bit quantizer inspired by the multi-bit uniform quantizer. By employing dithering scales varying across entries, our estimator enjoys an improved operator norm error rate that depends o
    
[^5]: PAVI：板块化的变分推断

    PAVI: Plate-Amortized Variational Inference. (arXiv:2308.16022v1 [stat.ML])

    [http://arxiv.org/abs/2308.16022](http://arxiv.org/abs/2308.16022)

    PAVI是一种板块化的变分推断方法，能够高效地处理大规模人口研究，通过共享参数化和学习加速训练变分分布，实现了在大规模分层问题上的表达力强和简明的结果。

    

    在给定观测数据和概率生成模型的情况下，贝叶斯推断寻找可能产生数据的模型参数的分布。在大规模人口研究中，推断是具有挑战性的，因为在成百上千的受试者群体上进行了数百万次测量，导致参数空间巨大。这种大基数使得现成的变分推断在计算上变得不切实际。在这项工作中，我们设计了有效处理大规模人口研究的结构化变分推断家族。我们的主要思想是共享参数化和学习，跨越生成模型中的不同i.i.d.变量，由模型的“板块”来象征。我们将这个概念命名为“板块化”。与减缓推断的现成随机变分推断相反，板块化导致训练变分分布的速度提高数个数量级。应用于大规模分层问题，PAVI产生了表达力强、简明的结果。

    Given observed data and a probabilistic generative model, Bayesian inference searches for the distribution of the model's parameters that could have yielded the data. Inference is challenging for large population studies where millions of measurements are performed over a cohort of hundreds of subjects, resulting in a massive parameter space. This large cardinality renders off-the-shelf Variational Inference (VI) computationally impractical.  In this work, we design structured VI families that efficiently tackle large population studies. Our main idea is to share the parameterization and learning across the different i.i.d. variables in a generative model, symbolized by the model's \textit{plates}. We name this concept \textit{plate amortization}. Contrary to off-the-shelf stochastic VI, which slows down inference, plate amortization results in orders of magnitude faster to train variational distributions.  Applied to large-scale hierarchical problems, PAVI yields expressive, parsimoni
    
[^6]: 不需要过量经验风险的域泛化

    Domain Generalization without Excess Empirical Risk. (arXiv:2308.15856v1 [cs.LG])

    [http://arxiv.org/abs/2308.15856](http://arxiv.org/abs/2308.15856)

    本论文提出了一种解决域泛化中过量风险问题的方法，通过在保证经验风险最优的约束下最小化惩罚，避免了惩罚对经验风险优化的影响。

    

    在给定不同分布的多样数据集的情况下，域泛化旨在学习可以推广到未见分布的模型。一种常见的方法是设计一个数据驱动的替代惩罚来捕捉泛化性能，并与惩罚一起最小化经验风险。我们认为这种方法的一个重要失败模式是由于错误的惩罚或联合优化的困难而导致的过量风险。我们提出了一种解决这个问题的方法。我们不是将经验风险和惩罚联合最小化，而是在保证经验风险最优的约束下最小化惩罚。这种改变保证了域泛化惩罚不会影响对经验风险的优化，即在分布内的性能。为了解决这个优化问题，我们展示了与率失真理论的令人兴奋的联系，并利用其工具设计了一个高效的方法。我们的方法可以应用于任何基于惩罚的域泛化问题。

    Given data from diverse sets of distinct distributions, domain generalization aims to learn models that generalize to unseen distributions. A common approach is designing a data-driven surrogate penalty to capture generalization and minimize the empirical risk jointly with the penalty. We argue that a significant failure mode of this recipe is an excess risk due to an erroneous penalty or hardness in joint optimization. We present an approach that eliminates this problem. Instead of jointly minimizing empirical risk with the penalty, we minimize the penalty under the constraint of optimality of the empirical risk. This change guarantees that the domain generalization penalty cannot impair optimization of the empirical risk, i.e., in-distribution performance. To solve the proposed optimization problem, we demonstrate an exciting connection to rate-distortion theory and utilize its tools to design an efficient method. Our approach can be applied to any penalty-based domain generalization
    
[^7]: 自适应Lasso、转移Lasso及其拓展：渐进视角下的研究

    Adaptive Lasso, Transfer Lasso, and Beyond: An Asymptotic Perspective. (arXiv:2308.15838v1 [stat.ML])

    [http://arxiv.org/abs/2308.15838](http://arxiv.org/abs/2308.15838)

    本文研究了自适应Lasso和转移Lasso的理论性质，通过对转移Lasso的渐进性质进行理论研究，分析了它与自适应Lasso的区别，并提出了一种新的方法，将两者的优势进行了融合并补偿了他们的弱点。

    

    本文全面探讨了自适应Lasso和转移Lasso的理论性质。自适应Lasso是一种成熟的方法，采用根据初始估计值进行的正则化，具有渐进正态性和变量选择一致性的特点。相比之下，最近提出的转移Lasso采用根据初始估计值进行的正则化减法，具有减少非渐进估计误差的能力。一个关键问题因此出现：鉴于自适应Lasso和转移Lasso在使用初始估计值方面存在的不同方式，这种差异给每种方法带来了什么好处或弊端？本文对转移Lasso的渐进性质进行了理论研究，从而阐明了它与自适应Lasso的区别。根据这个分析的结果，我们引入了一种新的方法，将各自的优势进行了融合并补偿了他们的弱点。

    This paper presents a comprehensive exploration of the theoretical properties inherent in the Adaptive Lasso and the Transfer Lasso. The Adaptive Lasso, a well-established method, employs regularization divided by initial estimators and is characterized by asymptotic normality and variable selection consistency. In contrast, the recently proposed Transfer Lasso employs regularization subtracted by initial estimators with the demonstrated capacity to curtail non-asymptotic estimation errors. A pivotal question thus emerges: Given the distinct ways the Adaptive Lasso and the Transfer Lasso employ initial estimators, what benefits or drawbacks does this disparity confer upon each method? This paper conducts a theoretical examination of the asymptotic properties of the Transfer Lasso, thereby elucidating its differentiation from the Adaptive Lasso. Informed by the findings of this analysis, we introduce a novel method, one that amalgamates the strengths and compensates for the weaknesses o
    
[^8]: 通过低次多项式计算图论估计的下界

    Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials. (arXiv:2308.15728v1 [math.ST])

    [http://arxiv.org/abs/2308.15728](http://arxiv.org/abs/2308.15728)

    通过低次多项式计算图论估计存在计算障碍，传统的优化估计方法具有指数级的计算复杂度，而最优多项式时间估计器只能达到较慢的估计错误率。

    

    图论估计是网络分析中最基本的问题之一，在过去十年中受到了相当大的关注。从统计学的角度来看，高等提出了对于随机块模型（SBM）和非参数图论估计的图论估计的极小极差误差率。统计优化估计是基于约束最小二乘法，并且在维度上具有指数级的计算复杂度。从计算的角度来看，已知的最优多项式时间估计器是基于通用奇异值阈值（USVT），但是它只能达到比极小极差错误率慢得多的估计错误率。人们自然会想知道这样的差距是否是必要的。USVT的计算优化性或图论估计中的计算障碍的存在一直是一个长期存在的问题。在这项工作中，我们对此迈出了第一步，并为图论估计的计算障碍提供了严格的证据。

    Graphon estimation has been one of the most fundamental problems in network analysis and has received considerable attention in the past decade. From the statistical perspective, the minimax error rate of graphon estimation has been established by Gao et al (2015) for both stochastic block model (SBM) and nonparametric graphon estimation. The statistical optimal estimators are based on constrained least squares and have computational complexity exponential in the dimension. From the computational perspective, the best-known polynomial-time estimator is based on universal singular value thresholding (USVT), but it can only achieve a much slower estimation error rate than the minimax one. It is natural to wonder if such a gap is essential. The computational optimality of the USVT or the existence of a computational barrier in graphon estimation has been a long-standing open problem. In this work, we take the first step towards it and provide rigorous evidence for the computational barrie
    
[^9]: 阈值KNN-Shapley：一种线性时间和隐私友好的数据价值评估方法

    Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation. (arXiv:2308.15709v1 [cs.LG])

    [http://arxiv.org/abs/2308.15709](http://arxiv.org/abs/2308.15709)

    本论文研究了数据价值评估面临的隐私挑战，并提出了一种隐私友好的改进方法TKNN-Shapley，该方法在保护隐私的前提下能够评估数据质量，具有较好的隐私-实用性权衡。

    

    数据价值评估是数据中心化机器学习研究中的关键问题，旨在量化单个数据源在训练机器学习模型中的有用性。然而，尽管其重要性，数据价值评估面临着很多重要但经常被忽视的隐私挑战。本文针对目前最实用的数据价值评估方法之一KNN-Shapley，研究了这些挑战。我们首先强调了KNN-Shapley固有的隐私风险，并展示了将KNN-Shapley改进以满足差分隐私(DP)的显著技术困难。为了克服这些挑战，我们引入了TKNN-Shapley，KNN-Shapley的一种改进变体，具有隐私友好性，可以进行简单的修正以包含DP保证（DP-TKNN-Shapley）。我们证明，DP-TKNN-Shapley在辨别数据质量方面具有一些优势，并在隐私-实用性权衡方面优于朴素化的KNN-Shapley。此外，即使是非隐私的TKNN-Shapley也能以线性时间运行。

    Data valuation, a critical aspect of data-centric ML research, aims to quantify the usefulness of individual data sources in training machine learning (ML) models. However, data valuation faces significant yet frequently overlooked privacy challenges despite its importance. This paper studies these challenges with a focus on KNN-Shapley, one of the most practical data valuation methods nowadays. We first emphasize the inherent privacy risks of KNN-Shapley, and demonstrate the significant technical difficulties in adapting KNN-Shapley to accommodate differential privacy (DP). To overcome these challenges, we introduce TKNN-Shapley, a refined variant of KNN-Shapley that is privacy-friendly, allowing for straightforward modifications to incorporate DP guarantee (DP-TKNN-Shapley). We show that DP-TKNN-Shapley has several advantages and offers a superior privacy-utility tradeoff compared to naively privatized KNN-Shapley in discerning data quality. Moreover, even non-private TKNN-Shapley ac
    
[^10]: 无需特征间隔的聚类方法

    Clustering Without an Eigengap. (arXiv:2308.15642v1 [cs.LG])

    [http://arxiv.org/abs/2308.15642](http://arxiv.org/abs/2308.15642)

    这个论文介绍了在随机块模型中进行图聚类的新算法，能够恢复大聚类，无论其他聚类的大小，并且对中等大小的聚类提出了新的技术挑战。

    

    我们在随机块模型（SBM）中研究了具有大聚类和小不可恢复聚类的图聚类问题。之前的方法要么不允许小于$ o（\sqrt {n}）$大小的小聚类，要么要求最小可恢复聚类和最大不可恢复聚类之间存在大小间隔。我们提供了一个基于半定规划（SDP）的算法，它消除了这些要求，并可以确定地恢复大聚类，而不考虑其他聚类的大小。中等大小的聚类对分析提出了独特的挑战，因为它们接近恢复阈值，非常敏感于小的噪声扰动，不允许闭合形式的候选解决方案。我们开发了新颖的技术，包括leave-one-out风格的论证，即使去掉一行噪声也可能大幅改变SDP解决方案，仍然可以控制SDP解决方案与噪声向量之间的相关性。

    We study graph clustering in the Stochastic Block Model (SBM) in the presence of both large clusters and small, unrecoverable clusters. Previous approaches achieving exact recovery do not allow any small clusters of size $o(\sqrt{n})$, or require a size gap between the smallest recovered cluster and the largest non-recovered cluster. We provide an algorithm based on semidefinite programming (SDP) which removes these requirements and provably recovers large clusters regardless of the remaining cluster sizes. Mid-sized clusters pose unique challenges to the analysis, since their proximity to the recovery threshold makes them highly sensitive to small noise perturbations and precludes a closed-form candidate solution. We develop novel techniques, including a leave-one-out-style argument which controls the correlation between SDP solutions and noise vectors even when the removal of one row of noise can drastically change the SDP solution. We also develop improved eigenvalue perturbation bo
    
[^11]: 混合方差流用于离散变量

    Mixed Variational Flows for Discrete Variables. (arXiv:2308.15613v1 [stat.CO])

    [http://arxiv.org/abs/2308.15613](http://arxiv.org/abs/2308.15613)

    本文提出了一种混合方差流方法，用于近似离散分布，通过开发一个离散且保持度量的映射，而不需要连续嵌入。实验证明，与连续嵌入流相比，该方法产生更可靠的近似。

    

    变分流允许从事者学习复杂的连续分布，但是近似离散分布仍然是一个挑战。目前的方法通常将离散目标嵌入连续空间中-通常是通过连续松弛或去量化-然后应用连续流动。这些方法涉及一个可能无法捕捉到原始离散目标的替代目标，可能具有偏倚或不稳定的梯度，并且可能会创建一个困难的优化问题。在这项工作中，我们开发了一种针对离散分布的变分流族，而不需要任何连续嵌入。首先，我们开发了一个保持度量的离散可逆映射，使离散目标保持不变，然后基于该映射创建了一个混合变分流(MAD Mix)。我们还开发了一个扩展，用于处理联合离散和连续模型。我们的实验表明，MAD Mix产生了比连续嵌入流更可靠的近似。

    Variational flows allow practitioners to learn complex continuous distributions, but approximating discrete distributions remains a challenge. Current methodologies typically embed the discrete target in a continuous space - usually via continuous relaxation or dequantization - and then apply a continuous flow. These approaches involve a surrogate target that may not capture the original discrete target, might have biased or unstable gradients, and can create a difficult optimization problem. In this work, we develop a variational flow family for discrete distributions without any continuous embedding. First, we develop a measure-preserving and discrete (MAD) invertible map that leaves the discrete target invariant, and then create a mixed variational flow (MAD Mix) based on that map. We also develop an extension to MAD Mix that handles joint discrete and continuous models. Our experiments suggest that MAD Mix produces more reliable approximations than continuous-embedding flows while 
    
[^12]: 参数化分位数自回归条件持续时间模型及其在日内风险价值上的应用。

    Parametric quantile autoregressive conditional duration models with application to intraday value-at-risk. (arXiv:2308.15571v1 [stat.ME])

    [http://arxiv.org/abs/2308.15571](http://arxiv.org/abs/2308.15571)

    本文提出了一种新的扩展ACD模型，该模型基于以分位数重新参数化的对数对称分布，可以对不同的百分位数进行建模，而不是传统上使用的均值（或中位数）条件持续时间。

    

    高频金融资产交易数据的建模一直是统计学家和计量经济学家感兴趣的领域，尤其是对金融持续时间时间序列的分析。自回归条件持续时间（ACD）模型一直是建模金融交易数据的主要工具，其中持续时间通常定义为两个连续事件之间的时间间隔。这些模型通常以时变均值（或中位数）条件持续时间的形式进行规定。本文提出了ACD模型的新扩展，该模型基于以分位数重新参数化的对数对称分布。所提出的分位数对数对称条件持续时间自回归模型允许我们对不同的百分位数进行建模，而不是传统上使用的均值（或中位数）条件持续时间。我们开展了对于理论性质和实际问题（如使用最大似然估计进行参数估计）的深入研究。

    The modeling of high-frequency data that qualify financial asset transactions has been an area of relevant interest among statisticians and econometricians -- above all, the analysis of time series of financial durations. Autoregressive conditional duration (ACD) models have been the main tool for modeling financial transaction data, where duration is usually defined as the time interval between two successive events. These models are usually specified in terms of a time-varying mean (or median) conditional duration. In this paper, a new extension of ACD models is proposed which is built on the basis of log-symmetric distributions reparametrized by their quantile. The proposed quantile log-symmetric conditional duration autoregressive model allows us to model different percentiles instead of the traditionally used conditional mean (or median) duration. We carry out an in-depth study of theoretical properties and practical issues, such as parameter estimation using maximum likelihood me
    
[^13]: 足球中预期进球模型的全局解释

    Glocal Explanations of Expected Goal Models in Soccer. (arXiv:2308.15559v1 [cs.LG])

    [http://arxiv.org/abs/2308.15559](http://arxiv.org/abs/2308.15559)

    本文提出了预期进球模型的全局解释（介于本地和全局之间的解释），通过使用聚合版本的SHAP值和部分依赖函数，可以对团队和球员水平进行绩效分析和知识提取。

    

    预期进球模型的解释性通常有限，尤其是在使用黑盒方法进行训练时。随着解释性人工智能工具的出现，可以增强模型的透明度，并从单个观察或所有观察中提取描述性知识。然而，在某些领域中，解释特定群体观察的黑盒模型可能更有用。本文通过提出使用SHAP值和部分依赖函数的聚合版本，引入预期进球模型的全局解释（介于本地和全局之间的解释）来实现对团队和球员水平的绩效分析。这样可以从预期进球模型中提取与球员或球队相关的知识，而不仅仅是单个射门。另外，我们进行了实际数据应用来说明聚合SHAP值和聚合函数的有用性。本文最后对这些解释的潜力进行了评论。

    The expected goal models have gained popularity, but their interpretability is often limited, especially when trained using black-box methods. Explainable artificial intelligence tools have emerged to enhance model transparency and extract descriptive knowledge for a single observation or for all observations. However, explaining black-box models for a specific group of observations may be more useful in some domains. This paper introduces the glocal explanations (between local and global levels) of the expected goal models to enable performance analysis at the team and player levels by proposing the use of aggregated versions of the SHAP values and partial dependence profiles. This allows knowledge to be extracted from the expected goal model for a player or team rather than just a single shot. In addition, we conducted real-data applications to illustrate the usefulness of aggregated SHAP and aggregated profiles. The paper concludes with remarks on the potential of these explanations
    
[^14]: 纯探索下的中介反馈

    Pure Exploration under Mediators' Feedback. (arXiv:2308.15552v1 [cs.LG])

    [http://arxiv.org/abs/2308.15552](http://arxiv.org/abs/2308.15552)

    本研究提出了一种严格推广的传统最优臂识别问题，即中介反馈下的最优臂识别（BAI-MF），通过引入中介者来模拟一些实际决策问题，如离线学习、部分可控环境和人类反馈。

    

    随机多臂赌博机是一种顺序决策框架，每一步交互中学习者选择一个臂并观察一个随机回报。在最优臂识别（BAI）问题的背景下，学习者的目标是尽可能准确和高效地找到最优臂，即具有最高期望回报的臂。然而，传统BAI问题的顺序交互协议，即学习者在每一轮中对选择的臂具有完全控制权，无法有效地模拟一些值得关注的决策问题（例如，离线学习，部分可控环境和人类反馈）。因此，在这项工作中，我们提出了一种新的严格推广的传统BAI问题，称之为中介反馈下的最优臂识别（BAI-MF）。更具体地说，我们考虑了学习者可以访问一组中介者的情况，每个中介者都选择要拉动的臂。

    Stochastic multi-armed bandits are a sequential-decision-making framework, where, at each interaction step, the learner selects an arm and observes a stochastic reward. Within the context of best-arm identification (BAI) problems, the goal of the agent lies in finding the optimal arm, i.e., the one with highest expected reward, as accurately and efficiently as possible. Nevertheless, the sequential interaction protocol of classical BAI problems, where the agent has complete control over the arm being pulled at each round, does not effectively model several decision-making problems of interest (e.g., off-policy learning, partially controllable environments, and human feedback). For this reason, in this work, we propose a novel strict generalization of the classical BAI problem that we refer to as best-arm identification under mediators' feedback (BAI-MF). More specifically, we consider the scenario in which the learner has access to a set of mediators, each of which selects the arms on 
    
[^15]: 调整困惑度并计算基于采样的t-SNE嵌入

    Tuning the perplexity for and computing sampling-based t-SNE embeddings. (arXiv:2308.15513v1 [cs.LG])

    [http://arxiv.org/abs/2308.15513](http://arxiv.org/abs/2308.15513)

    本文通过采样的方法改进了大数据集下t-SNE嵌入的质量和计算速度。

    

    高维数据分析常用的管道利用二维可视化，例如通过t分布邻近随机嵌入（t-SNE）。但在处理大数据集时，应用这些可视化技术会生成次优的嵌入，因为超参数不适用于大数据。将这些参数增加通常不起作用，因为计算对于实际工作流程来说太昂贵。本文中，我们认为基于采样的嵌入方法可以解决这些问题。我们展示了必须谨慎选择超参数，取决于采样率和预期的最终嵌入。此外，我们展示了该方法如何加速计算并提高嵌入的质量。

    Widely used pipelines for the analysis of high-dimensional data utilize two-dimensional visualizations. These are created, e.g., via t-distributed stochastic neighbor embedding (t-SNE). When it comes to large data sets, applying these visualization techniques creates suboptimal embeddings, as the hyperparameters are not suitable for large data. Cranking up these parameters usually does not work as the computations become too expensive for practical workflows. In this paper, we argue that a sampling-based embedding approach can circumvent these problems. We show that hyperparameters must be chosen carefully, depending on the sampling rate and the intended final embedding. Further, we show how this approach speeds up the computation and increases the quality of the embeddings.
    
[^16]: 深度学习与贝叶斯推断在反问题中的应用

    Deep Learning and Bayesian inference for Inverse Problems. (arXiv:2308.15492v1 [stat.ML])

    [http://arxiv.org/abs/2308.15492](http://arxiv.org/abs/2308.15492)

    这项研究探讨了在反问题中应用深度学习和贝叶斯推断的方法。通过使用深度神经网络代理模型和近似计算，可以有效地解决复杂的反问题，并考虑不确定性。

    

    反问题在任何间接测量的情况下都会出现。由于通常情况下它们是病态的，为了得到令人满意的解决方案，需要先有先验知识。经典方法包括不同的正则化方法和基于贝叶斯推断的方法。由于这些方法需要大量的正向和反向计算，尤其是当正向或生成模型复杂且似然函数的评估非常昂贵时，计算成本就会变高。使用深度神经网络代理模型和近似计算可以非常有帮助。但是，为了考虑不确定性，我们需要先了解贝叶斯深度学习，然后再看如何将其用于反问题。本研究重点关注神经网络、深度学习，特别是适用于反问题的贝叶斯深度学习。我们首先详细介绍了贝叶斯深度学习近似计算与指数族的方法，然后再看如何将其应用于反问题中。

    Inverse problems arise anywhere we have indirect measurement. As, in general they are ill-posed, to obtain satisfactory solutions for them needs prior knowledge. Classically, different regularization methods and Bayesian inference based methods have been proposed. As these methods need a great number of forward and backward computations, they become costly in computation, in particular, when the forward or generative models are complex and the evaluation of the likelihood becomes very costly. Using Deep Neural Network surrogate models and approximate computation can become very helpful. However, accounting for the uncertainties, we need first understand the Bayesian Deep Learning and then, we can see how we can use them for inverse problems. In this work, we focus on NN, DL and more specifically the Bayesian DL particularly adapted for inverse problems. We first give details of Bayesian DL approximate computations with exponential families, then we will see how we can use them for inve
    
[^17]: 通过正则化Wasserstein Proximals实现无噪声的抽样算法

    Noise-Free Sampling Algorithms via Regularized Wasserstein Proximals. (arXiv:2308.14945v1 [stat.ML])

    [http://arxiv.org/abs/2308.14945](http://arxiv.org/abs/2308.14945)

    本文通过正则化Wasserstein Proximal方法提出了一种无噪声的抽样算法，通过给定的潜势函数确定性地进行粒子演化，并提供了优于传统方法的维度依赖性和速度收敛性能。

    

    本文考虑由潜势函数控制的分布抽样问题。本文提出了一种显式的基于评分的确定性马尔科夫链蒙特卡洛方法，使得粒子的演化变为确定性的，而不是随机微分方程的演化。评分项由正则化的Wasserstein proximal以闭合形式给出，使用采样来近似核卷积。我们在不同问题上展示了快速收敛，并且与未调整Langevin算法和Metropolis调整Langevin算法相比，显示了高斯分布的混合时间边界的改善维度依赖性。我们还推导了二次潜势函数每次迭代的分布的闭合形式表达式，表征了方差降低。实证结果表明，粒子的行为是有组织的，位于潜势的等值线上。此外，后验均值估计结果显示了该方法的有效性。

    We consider the problem of sampling from a distribution governed by a potential function. This work proposes an explicit score-based MCMC method that is deterministic, resulting in a deterministic evolution for particles rather than a stochastic differential equation evolution. The score term is given in closed form by a regularized Wasserstein proximal, using a kernel convolution that is approximated by sampling. We demonstrate fast convergence on various problems and show improved dimensional dependence of mixing time bounds for the case of Gaussian distributions compared to the unadjusted Langevin algorithm (ULA) and the Metropolis-adjusted Langevin algorithm (MALA). We additionally derive closed form expressions for the distributions at each iterate for quadratic potential functions, characterizing the variance reduction. Empirical results demonstrate that the particles behave in an organized manner, lying on level set contours of the potential. Moreover, the posterior mean estimat
    
[^18]: 关于平均嵌入用于物品推荐的一致性研究

    On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])

    [http://arxiv.org/abs/2308.12767](http://arxiv.org/abs/2308.12767)

    本文研究了推荐系统中平均嵌入的一致性，并提出了一种衡量方法。实证结果表明，现实世界的平均嵌入在推荐中一致性较低，为进一步改进现实世界嵌入提供了方向。

    

    推荐系统中一种流行的做法是将物品嵌入进行平均以在同一嵌入空间中代表用户或更高级的概念。本文研究了这种做法的相关性。为此，我们提出了一种期望精度分数，用于衡量平均嵌入与其构建所使用的物品的一致性。我们随后在具有特定假设的理论环境和来自音乐流媒体服务的真实数据上分析了该分数的数学表达式及其经验表现。我们的结果强调了现实世界的平均值在推荐中的一致性较低，为未来研究更好地将现实世界的嵌入与我们理论环境的假设相一致铺平了道路。

    A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.
    
[^19]: 基于Lagrangian方法的约束马尔可夫决策过程中无需取消惩罚的遗憾界限

    Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained Markov Decision Processes. (arXiv:2306.07001v1 [cs.LG])

    [http://arxiv.org/abs/2306.07001](http://arxiv.org/abs/2306.07001)

    本文提出了一种创新的模型驱动的双重算法OptAug-CMDP，用于约束马尔可夫决策过程（CMDPs），解决了原先算法中安全性问题的缺陷，证明了其遗憾值优秀。

    

    约束马尔可夫决策过程（CMDPs）是建模安全强化学习问题的常见方法，其中安全目标由约束函数建模。基于Lagrangian的双重或原始双重算法为CMDPs中的学习提供了高效的方法。但是，当前已知的有限时间段遗憾界限允许“取消错误”，这意味着可以通过另一种场景中的严格约束满足来补偿一个场景中的约束违规行为。本文提出了一种创新的模型驱动的双重算法OptAug-CMDP，该算法受增广拉格朗日方法启发，并可以有效地执行来弥补这种缺陷。我们证明，在$K$个探索CMDP的情况下，我们的算法可以获得$\tilde{O}(\sqrt{K})$的遗憾界限，适用于目标和约束条件。

    Constrained Markov Decision Processes (CMDPs) are one of the common ways to model safe reinforcement learning problems, where the safety objectives are modeled by constraint functions. Lagrangian-based dual or primal-dual algorithms provide efficient methods for learning in CMDPs. For these algorithms, the currently known regret bounds in the finite-horizon setting allow for a \textit{cancellation of errors}; that is, one can compensate for a constraint violation in one episode with a strict constraint satisfaction in another episode. However, in practical applications, we do not consider such a behavior safe.  In this paper, we overcome this weakness by proposing a novel model-based dual algorithm \textsc{OptAug-CMDP} for tabular finite-horizon CMDPs. Our algorithm is motivated by the augmented Lagrangian method and can be performed efficiently. We show that during $K$ episodes of exploring the CMDP, our algorithm obtains a regret of $\tilde{O}(\sqrt{K})$ for both the objective and th
    
[^20]: 多通道监督学习的量子卷积神经网络

    Quantum Convolutional Neural Networks for Multi-Channel Supervised Learning. (arXiv:2305.18961v1 [quant-ph])

    [http://arxiv.org/abs/2305.18961](http://arxiv.org/abs/2305.18961)

    本文介绍了多通道监督学习的量子卷积神经网络，通过硬件适应性的量子电路ansatzes用作卷积核，能够有效学习通道间信息，优于现有的QCNNs。

    

    随着机器学习领域的快速发展，制造出非常有用的工具和模型，量子计算为机器学习算法提供加速的潜力正在日益受到重视。特别是，研究用于基于图像检测任务的量子电路取代经典卷积滤波器以利用量子优势的尝试，称为量子卷积神经网络（QCNNs）。然而，这些尝试缺乏处理具有多个通道的数据的能力，因此只适用于相对简单的输入。在这项工作中，我们提出了多种硬件适应性的量子电路ansatzes用作卷积核，并证明我们报告的量子神经网络在涉及多通道数据的分类任务中优于现有的QCNNs。我们预计，这些实现有效学习通道间信息的能力将允许量子机器学习在处理现实任务时获得重大突破。

    As the rapidly evolving field of machine learning continues to produce incredibly useful tools and models, the potential for quantum computing to provide speed up for machine learning algorithms is becoming increasingly desirable. In particular, quantum circuits in place of classical convolutional filters for image detection-based tasks are being investigated for the ability to exploit quantum advantage. However, these attempts, referred to as quantum convolutional neural networks (QCNNs), lack the ability to efficiently process data with multiple channels and therefore are limited to relatively simple inputs. In this work, we present a variety of hardware-adaptable quantum circuit ansatzes for use as convolutional kernels, and demonstrate that the quantum neural networks we report outperform existing QCNNs on classification tasks involving multi-channel data. We envision that the ability of these implementations to effectively learn inter-channel information will allow quantum machine
    
[^21]: 几何代数变换器

    Geometric Algebra Transformers. (arXiv:2305.18415v1 [cs.LG])

    [http://arxiv.org/abs/2305.18415](http://arxiv.org/abs/2305.18415)

    本文介绍了一种通用架构几何代数变换器（GATr），用于解决几何数据问题。GATr使用投影几何代数表示输入输出和状态，具有可缩放性、表达性、多功能性。在n体建模和机器人规划的实验中，GATr相对于非几何基线表现出强大的改进。

    

    几何数据问题涉及计算机视觉、机器人、化学和物理领域。这些数据可以采用许多形式，例如点、方向向量、平面或变换，但迄今为止还没有一种单一的架构，可以应用于如此多种几何类型, 同时尊重它们的对称性。在本文中，我们介绍了几何代数变换器（GATr），一种用于几何数据的通用架构。GATr使用投影几何代数来表示输入、输出和隐藏状态，其提供常见几何对象的高效16维向量空间表示以及作用于它们的运算符。GATr是相对于E(3)（3D欧几里得空间的对称群）等变的。作为变换器，GATr可扩展、表达丰富且多功能。在n体建模和机器人规划的实验中，GATr相对于非几何基线均表现出强大的改进。

    Problems involving geometric data arise in a variety of fields, including computer vision, robotics, chemistry, and physics. Such data can take numerous forms, such as points, direction vectors, planes, or transformations, but to date there is no single architecture that can be applied to such a wide variety of geometric types while respecting their symmetries. In this paper we introduce the Geometric Algebra Transformer (GATr), a general-purpose architecture for geometric data. GATr represents inputs, outputs, and hidden states in the projective geometric algebra, which offers an efficient 16-dimensional vector space representation of common geometric objects as well as operators acting on them. GATr is equivariant with respect to E(3), the symmetry group of 3D Euclidean space. As a transformer, GATr is scalable, expressive, and versatile. In experiments with n-body modeling and robotic planning, GATr shows strong improvements over non-geometric baselines.
    
[^22]: 利用演进变化提高软件过程质量。

    Leveraging Evolutionary Changes for Software Process Quality. (arXiv:2305.18061v1 [cs.SE])

    [http://arxiv.org/abs/2305.18061](http://arxiv.org/abs/2305.18061)

    本文提出了一种利用演进变化来改善软件开发过程质量的方法，其包括使用统计过程控制和机器学习技术来分析应用程序生命周期管理所捕获的变更数据，实验表明该方法是有效的。

    

    现实世界中的软件应用必须不断演进才能保持相关性。传统的软件质量控制方法涉及软件质量模型和持续的代码检查工具。然而，软件开发过程的质量与最终软件产品的质量之间存在强关联和因果关系。因此，间接提高软件产品的质量需要改善软件开发过程的质量。本文提出了一种利用开发过程的演进变化来提高软件质量的新方法。该方法包括使用统计过程控制和机器学习技术来分析应用程序生命周期管理所捕获的变更数据。实验结果显示了该方法的有效性。

    Real-world software applications must constantly evolve to remain relevant. This evolution occurs when developing new applications or adapting existing ones to meet new requirements, make corrections, or incorporate future functionality. Traditional methods of software quality control involve software quality models and continuous code inspection tools. These measures focus on directly assessing the quality of the software. However, there is a strong correlation and causation between the quality of the development process and the resulting software product. Therefore, improving the development process indirectly improves the software product, too. To achieve this, effective learning from past processes is necessary, often embraced through post mortem organizational learning. While qualitative evaluation of large artifacts is common, smaller quantitative changes captured by application lifecycle management are often overlooked. In addition to software metrics, these smaller changes can 
    
[^23]: 论进化磨锋、平坦极小和泛化

    On progressive sharpening, flat minima and generalisation. (arXiv:2305.14683v1 [cs.LG])

    [http://arxiv.org/abs/2305.14683](http://arxiv.org/abs/2305.14683)

    本文提出了一种用损失黑塞矩阵和输入-输出雅克比矩阵联系起来的假设，量化了模型的输入-输出雅克比矩阵近似其在数据分布上的利普西茨范数的程度，并推导出了一个基于经验雅克比矩阵的新的泛化界，给出了关于进化磨锋和平坦极小的泛化性质的新解释。

    

    我们提出了一种新的方法来理解深度学习中损失曲率与泛化之间的关系。具体来说，我们利用现有的深度网络损失黑塞矩阵频谱经验分析，提出了一个将损失黑塞矩阵和深度神经网络的输入-输出雅克比矩阵联系起来的假设。然后，我们证明了一系列理论结果，量化了模型的输入-输出雅克比矩阵近似其在数据分布上的利普西茨范数的程度，并推导出了一个基于经验雅克比矩阵的新的泛化界。我们利用我们的假设和理论结果，给出了关于最近观察到的进化磨锋现象以及平坦极小的泛化性质的新描述。实验证据验证了我们的主张。

    We present a new approach to understanding the relationship between loss curvature and generalisation in deep learning. Specifically, we use existing empirical analyses of the spectrum of deep network loss Hessians to ground an ansatz tying together the loss Hessian and the input-output Jacobian of a deep neural network. We then prove a series of theoretical results which quantify the degree to which the input-output Jacobian of a model approximates its Lipschitz norm over a data distribution, and deduce a novel generalisation bound in terms of the empirical Jacobian. We use our ansatz, together with our theoretical results, to give a new account of the recently observed progressive sharpening phenomenon, as well as the generalisation properties of flat minima. Experimental evidence is provided to validate our claims.
    
[^24]: RAFT: 奖励排名微调用于生成型基础模型对齐

    RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v1 [cs.LG])

    [http://arxiv.org/abs/2304.06767](http://arxiv.org/abs/2304.06767)

    RAFT框架引入了奖励排名微调方法，用于对齐生成型基础模型，以解决强化学习带来的低效和不稳定性问题。

    

    生成型基础模型容易受到广泛的无监督训练数据带来的隐式偏见的影响。这些偏见可能导致子优样本、扭曲的结果和不公平，可能产生重大影响。因此，将这些模型与人的伦理和偏好对齐是确保它们在真实应用中负责任和有效的部署的关键步骤。以往的研究主要采用人类反馈的强化学习（ RLHF）作为解决这个问题的手段。在 RL 算法的指导下，用人类反馈指导的奖励模型对生成模型进行微调。然而， RL 算法的低效性和不稳定性常常会对生成模型的成功对齐产生重大障碍，因此需要开发一种更为强大和简化的方法。为此，我们引入了一个新的框架，即奖励排名微调（ RAFT ），旨在对齐生成基础模型。

    Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generat
    
[^25]: 量子化的低秩多元回归与随机抖动

    Quantized Low-Rank Multivariate Regression with Random Dithering. (arXiv:2302.11197v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.11197](http://arxiv.org/abs/2302.11197)

    本文研究了量子化的低秩多元回归，通过采用均匀量化与随机抖动的方法，提出了约束Lasso和正则化Lasso估计器，实现了最小最优率的估计，同时量化仅对乘法因子略有影响。

    

    低秩多元回归（LRMR）是一种重要的统计学习模型，将高度相关的任务作为具有低秩先验的多响应回归问题进行组合。本文研究了量子化的LRMR，这是一种实际的设置，其中响应和/或协变量被离散化为有限的精度。我们专注于估计基础系数矩阵。为了使能够实现任意小误差的一致估计器成为可能，我们采用了均匀量化与随机抖动，即在量化之前向数据添加适当的随机噪声。具体而言，响应使用均匀抖动，协变量使用三角抖动。基于量化数据，我们提出了约束Lasso和正则化Lasso估计器，并推导了非渐近性误差界。通过抖动的帮助，估计器实现了最小最优率，而量化仅略微恶化了乘法因子。

    Low-rank multivariate regression (LRMR) is an important statistical learning model that combines highly correlated tasks as a multiresponse regression problem with low-rank priori on the coefficient matrix. In this paper, we study quantized LRMR, a practical setting where the responses and/or the covariates are discretized to finite precision. We focus on the estimation of the underlying coefficient matrix. To make consistent estimator that could achieve arbitrarily small error possible, we employ uniform quantization with random dithering, i.e., we add appropriate random noise to the data before quantization. Specifically, uniform dither and triangular dither are used for responses and covariates, respectively. Based on the quantized data, we propose the constrained Lasso and regularized Lasso estimators, and derive the non-asymptotic error bounds. With the aid of dithering, the estimators achieve minimax optimal rate, while quantization only slightly worsens the multiplicative factor
    
[^26]: 分类规则生成：可扩展性，解释性和公平性

    Rule Generation for Classification: Scalability, Interpretability, and Fairness. (arXiv:2104.10751v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2104.10751](http://arxiv.org/abs/2104.10751)

    这项研究介绍了一种新的基于规则的分类优化方法，利用列生成线性规划实现可扩展性，并通过分配成本系数和引入额外约束解决了解释性和公平性问题。该方法在局部解释性和公平性之间取得了良好的平衡。

    

    我们引入了一种新的基于规则的分类优化方法，具有约束条件。所提出的方法利用列生成线性规划，因此可扩展到大型数据集。所得定价子问题被证明是NP难问题。我们采用基于决策树的启发式方法，并解决了一个代理定价子问题以加速。该方法返回一组规则以及它们的最优权重，指示每个规则对学习的重要性。我们通过为规则分配成本系数和引入额外约束来解决解释性和公平性问题。具体而言，我们关注局部解释性，并将公平性的一般分离准则推广到多个敏感属性和类别。我们在一系列数据集上测试了所提出方法的性能，并提供了一个案例研究来详细阐述其不同方面。所提出的基于规则的学习方法在局部解释性和公平性之间达到了良好的平衡点。

    We introduce a new rule-based optimization method for classification with constraints. The proposed method leverages column generation for linear programming, and hence, is scalable to large datasets. The resulting pricing subproblem is shown to be NP-Hard. We recourse to a decision tree-based heuristic and solve a proxy pricing subproblem for acceleration. The method returns a set of rules along with their optimal weights indicating the importance of each rule for learning. We address interpretability and fairness by assigning cost coefficients to the rules and introducing additional constraints. In particular, we focus on local interpretability and generalize separation criterion in fairness to multiple sensitive attributes and classes. We test the performance of the proposed methodology on a collection of datasets and present a case study to elaborate on its different aspects. The proposed rule-based learning method exhibits a good compromise between local interpretability and fairn
    
[^27]: Coagent Networks再探讨

    Coagent Networks Revisited. (arXiv:2001.10474v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2001.10474](http://arxiv.org/abs/2001.10474)

    Coagent Networks（共智网络）是指在强化学习环境中协作的随机代理网络。这篇论文重新审视了共智网络理论，提出了执行路径的思想，并通过这一思想实现了对策梯度定理的简洁证明。

    

    Coagent networks（共智网络）形式化了在强化学习环境中协作以采取行动的随机代理网络的概念。共智网络的显著应用包括层次强化学习（HRL）的方法，例如使用选项的方法，通过在HRL代理中串联多个随机网络引入不同层次的抽象动作，来解决探索利用权衡问题。我们首先通过在共智网络中形式化执行规则、通过共智网络中执行路径的新颖而直观的思想，提供了一个统一的视角来描述许多不同的例子。在层次选项评论者架构中受到参数共享的启发，我们重新审视了共智网络理论，并使用我们的执行路径思想得到了对策梯度定理的更简洁证明，而不需要对参数共享做出任何假设。

    Coagent networks formalize the concept of arbitrary networks of stochastic agents that collaborate to take actions in a reinforcement learning environment. Prominent examples of coagent networks in action include approaches to hierarchical reinforcement learning (HRL), such as those using options, which attempt to address the exploration exploitation trade-off by introducing abstract actions at different levels by sequencing multiple stochastic networks within the HRL agents. We first provide a unifying perspective on the many diverse examples that fall under coagent networks. We do so by formalizing the rules of execution in a coagent network, enabled by the novel and intuitive idea of execution paths in a coagent network. Motivated by parameter sharing in the hierarchical option-critic architecture, we revisit the coagent network theory and achieve a much shorter proof of the policy gradient theorem using our idea of execution paths, without any assumption on how parameters are share
    
[^28]: 关于在一般采样分布下的低秩迹回归的研究

    On Low-rank Trace Regression under General Sampling Distribution. (arXiv:1904.08576v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1904.08576](http://arxiv.org/abs/1904.08576)

    本文研究了在一般采样分布下的低秩迹回归问题，并引入了一种通用峰值概念，提供了证明迹回归采样算子强凸性和获得非渐进、近乎最优界的方法。同时，将误差界扩展到以交叉验证选择正则化参数的情况下。

    

    本文研究了通过秩正则化回归的凸松弛或正则化非凸优化来估计参数矩阵B*的迹回归问题。已知这些估计器在对B*的秩、一致性和峰值性假设下满足近乎最优的误差界。我们首先引入了对B*的一种通用峰值概念，该概念提供了证明迹回归采样算子的受限强凸性以及获得估计误差的非渐进、近乎最优界的通用方法。与现有文献类似，这些结果要求正则化参数高于某个理论上的阈值，该阈值取决于实践中可能未知的观测噪声。接下来，我们将误差界扩展到以交叉验证选择正则化参数的情况。这个结果的重要性在于现有关于交叉验证估计器的理论结果(Kale等)。

    In this paper, we study the trace regression when a matrix of parameters B* is estimated via the convex relaxation of a rank-regularized regression or via regularized non-convex optimization. It is known that these estimators satisfy near-optimal error bounds under assumptions on the rank, coherence, and spikiness of B*. We start by introducing a general notion of spikiness for B* that provides a generic recipe to prove the restricted strong convexity of the sampling operator of the trace regression and obtain near-optimal and non-asymptotic error bounds for the estimation error. Similar to the existing literature, these results require the regularization parameter to be above a certain theory-inspired threshold that depends on observation noise that may be unknown in practice. Next, we extend the error bounds to cases where the regularization parameter is chosen via cross-validation. This result is significant in that existing theoretical results on cross-validated estimators (Kale et
    

