# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery](https://arxiv.org/abs/2403.14593) | 重新思考对抗逆强化学习中的策略模仿和可转移奖励恢复，提出了一个混合框架PPO-AIRL + SAC以解决SAC算法在AIRL训练中无法全面解开奖励函数的问题。 |
| [^2] | [A Transfer Learning Causal Approach to Evaluate Racial/Ethnic and Geographic Variation in Outcomes Following Congenital Heart Surgery](https://arxiv.org/abs/2403.14573) | 提出了一个传递学习因果方法来评估先天性心脏手术后结果的种族/民族和地理变异，有助于在考虑不同人群风险因素和结果差异来源的情况下估计因果效应 |
| [^3] | [Estimating Causal Effects with Double Machine Learning -- A Method Evaluation](https://arxiv.org/abs/2403.14385) | 双重/无偏机器学习（DML）方法改进了因果效应估计中对非线性混淆关系的调整，摆脱传统函数形式假设，但仍然依赖于标准因果假设。 |
| [^4] | [Recovering Latent Confounders from High-dimensional Proxy Variables](https://arxiv.org/abs/2403.14228) | 提出了一种新颖的代理混淆因子分解 (PCF) 框架，用于处理高维混合代理变量来估计连续处理效应，实验证明在高样本大小情况下，该方法在因果效果估计中表现出较高的相关性和较低的误差。 |
| [^5] | [Posterior concentrations of fully-connected Bayesian neural networks with general priors on the weights](https://arxiv.org/abs/2403.14225) | 本文提出了一种新的近似理论，表明具有非稀疏通用先验的BNNs可以实现接近最小化最优后验浓度速率至真实模型。 |
| [^6] | [OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2403.14183) | 通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。 |
| [^7] | [Policy Mirror Descent with Lookahead](https://arxiv.org/abs/2403.14156) | 提出了一种新类别的策略镜像下降算法$h$-PMD，它通过在PMD更新规则中结合多步贪心策略改进和前瞻深度$h，以解决折扣无限时间视角下的马尔可夫决策过程。 |
| [^8] | [Learning causal graphs using variable grouping according to ancestral relationship](https://arxiv.org/abs/2403.14125) | 使用分治方法将变量分组，按照条件独立关系学习因果图，以提高在样本量较小的情况下的估算准确性。 |
| [^9] | [Automatic Outlier Rectification via Optimal Transport](https://arxiv.org/abs/2403.14067) | 提出了一种自动异常值矫正机制，通过将矫正和估计集成到联合优化框架中，利用最优输运和凹成本函数来检测和移除异常值，并选择最佳分布来执行估计任务 |
| [^10] | [Hypothesis-Driven Deep Learning for Out of Distribution Detection](https://arxiv.org/abs/2403.14058) | 本论文提出了一种基于假设的深度学习方法，用于量化新样本是否属于内部分布或外部分布，在高风险应用中如医疗保健领域具有重要意义。 |
| [^11] | [Analysing heavy-tail properties of Stochastic Gradient Descent by means of Stochastic Recurrence Equations](https://arxiv.org/abs/2403.13868) | 本文通过随机递归方程的概率框架，研究了随机梯度下降的重尾特性，并通过i-p矩阵理论扩展了G\"{u}rb\"{u}zbalaban等人的结果。 |
| [^12] | [Tree-based Learning for High-Fidelity Prediction of Chaos](https://arxiv.org/abs/2403.13836) | TreeDOX是一种基于树的方法，不需要超参数调整，使用时间延迟过度嵌入和额外树回归器进行特征降维和预测，并在深度预测混沌系统中表现出state-of-the-art的性能。 |
| [^13] | [Linearly Constrained Weights: Reducing Activation Shift for Faster Training of Neural Networks](https://arxiv.org/abs/2403.13833) | 神经网络中引入线性约束权重（LCW）来减少激活偏移，有效解决了梯度消失问题，提高了深度前向网络的训练效率。 |
| [^14] | [Towards AI-Based Precision Oncology: A Machine Learning Framework for Personalized Counterfactual Treatment Suggestions based on Multi-Omics Data](https://arxiv.org/abs/2402.12190) | 提出了一种基于机器学习的框架，用于个性化反事实癌症治疗建议，集成了多种多组学技术的专家，可提供优越性能和决策解释。 |
| [^15] | [A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective](https://arxiv.org/abs/2302.13425) | 本研究对深度学习的不确定性量化进行了调查，从不确定性来源的角度分析不同方法，以评估DNN预测的置信度。 |
| [^16] | [A Non-Parametric Bootstrap for Spectral Clustering](https://arxiv.org/abs/2209.05812) | 开发了两种新的算法，结合了数据矩阵的谱分解和非参数自举抽样方案，解决了谱聚类中收敛到次优解的问题，并展示出了其在估计有限混合模型时的优越性。 |
| [^17] | [On the consistency of supervised learning with missing values](https://arxiv.org/abs/1902.06931) | 两种方法在带缺失值的监督学习中表现出一致性，当缺失值不具信息性时，使用常数进行插补是一种简单且重要的实践方法。 |
| [^18] | [Let's do the time-warp-attend: Learning topological invariants of dynamical systems.](http://arxiv.org/abs/2312.09234) | 该论文提出了一个数据驱动、基于物理信息的深度学习框架，用于分类和表征动力学变化的拓扑不变特征提取，特别关注超临界霍普分歧。这个方法可以帮助预测系统的质变和常发行为变化。 |
| [^19] | [$\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks.](http://arxiv.org/abs/2311.18744) | 本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与经典神经网络的性能进行了全面比较分析，结果表明《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上表现优越。 |
| [^20] | [Exact and efficient solutions of the LMC Multitask Gaussian Process model.](http://arxiv.org/abs/2310.12032) | LMC多任务高斯过程模型的精确解决方案表明，只需对噪声模型进行温和假设，即可实现高效计算。通过引入完整参数化的“投影LMC”模型和边缘似然函数表达式，展示了该方法相对于未经处理的方法的优异性能。 |
| [^21] | [Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel.](http://arxiv.org/abs/2310.03054) | 本文提出了一种基于负距离核的最大平均距离(MMD)的条件流方法，用于后验抽样和条件生成建模。通过离散的Wasserstein梯度流近似联合分布，证明了粒子流是适当功能的Wasserstein梯度流。在条件图像生成和超分辨率等逆问题中展示了方法的有效性。 |
| [^22] | [ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF.](http://arxiv.org/abs/2310.02712) | ED-NeRF 提出了一种高效的 3D 场景编辑方法，通过将场景嵌入到潜空间中，得到更快速且更易于编辑的 NeRF 骨干。 |
| [^23] | [Learning to Make Adherence-Aware Advice.](http://arxiv.org/abs/2310.00817) | 本文提出了一种顺序决策模型，考虑了人的依从程度和机器提供建议的时机，并提供了学习算法来学习最佳的建议策略。 |
| [^24] | [Generalized Early Stopping in Evolutionary Direct Policy Search.](http://arxiv.org/abs/2308.03574) | 本文提出了一种适用于直接策略搜索的早停止方法，通过观察每个时间步骤的目标值来决定是否停止评估，而无需问题特定的知识。在测试中，该方法在游戏、机器人和经典控制领域中表现出节省计算时间的优势。 |
| [^25] | [From Tempered to Benign Overfitting in ReLU Neural Networks.](http://arxiv.org/abs/2305.15141) | 本论文通过对二层ReLU神经网络进行研究，证明了各种假设下过拟合的类型会从一维数据的极端情况下缓和到高维的良性，揭示了输入维度在神经网络过拟合中的关键作用。 |
| [^26] | [Mixture of segmentation for heterogeneous functional data.](http://arxiv.org/abs/2303.10712) | 本文提出了一种混合分割模型，可以处理异质性功能数据，通过动态规划的EM算法近似最大似然估计器，方法在模拟与真实数据集上得到验证。 |
| [^27] | [Instance-dependent uniform tail bounds for empirical processes.](http://arxiv.org/abs/2209.10053) | 该论文提出了一个经验过程的统一尾部界，该尾部界以函数的个体偏差而不是在考虑的类中的最坏情况偏差为基础。 |

# 详细

[^1]: 重新思考对抗逆强化学习：从策略模仿和可转移奖励恢复的角度

    Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery

    [https://arxiv.org/abs/2403.14593](https://arxiv.org/abs/2403.14593)

    重新思考对抗逆强化学习中的策略模仿和可转移奖励恢复，提出了一个混合框架PPO-AIRL + SAC以解决SAC算法在AIRL训练中无法全面解开奖励函数的问题。

    

    对抗逆强化学习（AIRL）作为模仿学习中的基石方法。本文重新思考了AIRL的两个不同角度：策略模仿和可转移奖励恢复。我们从用Soft Actor-Critic（SAC）替换AIRL中的内置算法开始，以增强样本效率，这要归功于SAC的离策略形式和相对于AIRL而言可识别的马尔可夫决策过程（MDP）模型。这确实在策略模仿方面表现出显著的改进，但不慎给可转移奖励恢复带来了缺点。为了解决这个问题，我们阐述了SAC算法本身在AIRL训练过程中无法全面解开奖励函数，提出了一个混合框架，PPO-AIRL + SAC，以获得令人满意的转移效果。此外，我们分析了环境提取解开的奖励的能力。

    arXiv:2403.14593v1 Announce Type: new  Abstract: Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone approach in imitation learning. This paper rethinks the two different angles of AIRL: policy imitation and transferable reward recovery. We begin with substituting the built-in algorithm in AIRL with soft actor-critic (SAC) during the policy optimization process to enhance sample efficiency, thanks to the off-policy formulation of SAC and identifiable Markov decision process (MDP) models with respect to AIRL. It indeed exhibits a significant improvement in policy imitation but accidentally brings drawbacks to transferable reward recovery. To learn this issue, we illustrate that the SAC algorithm itself is not feasible to disentangle the reward function comprehensively during the AIRL training process, and propose a hybrid framework, PPO-AIRL + SAC, for satisfactory transfer effect. Additionally, we analyze the capability of environments to extract disentangled rewa
    
[^2]: 一个传递学习因果方法来评估先天性心脏手术后结果的种族/民族和地理变异

    A Transfer Learning Causal Approach to Evaluate Racial/Ethnic and Geographic Variation in Outcomes Following Congenital Heart Surgery

    [https://arxiv.org/abs/2403.14573](https://arxiv.org/abs/2403.14573)

    提出了一个传递学习因果方法来评估先天性心脏手术后结果的种族/民族和地理变异，有助于在考虑不同人群风险因素和结果差异来源的情况下估计因果效应

    

    先天性心脏缺陷(CHD)是美国最常见的先天缺陷，手术结果在全国范围内变化很大。特定患者亚组的CHD治疗结果有所不同，非西班牙裔黑人和西班牙裔人口的死亡率和发病率较高。由于病例混合有很大差异和亚组规模较小，种族/民族亚组内结果的有效比较很困难。我们提出了一个因果推断框架用于结果评估，并利用传递学习的进展结合目标和源人群的数据，帮助估计因果效应，同时考虑跨人群不同风险因素和结果差异的来源。

    arXiv:2403.14573v1 Announce Type: cross  Abstract: Congenital heart defects (CHD) are the most prevalent birth defects in the United States and surgical outcomes vary considerably across the country. The outcomes of treatment for CHD differ for specific patient subgroups, with non-Hispanic Black and Hispanic populations experiencing higher rates of mortality and morbidity. A valid comparison of outcomes within racial/ethnic subgroups is difficult given large differences in case-mix and small subgroup sizes. We propose a causal inference framework for outcome assessment and leverage advances in transfer learning to incorporate data from both target and source populations to help estimate causal effects while accounting for different sources of risk factor and outcome differences across populations. Using the Society of Thoracic Surgeons' Congenital Heart Surgery Database (STS-CHSD), we focus on a national cohort of patients undergoing the Norwood operation from 2016-2022 to assess opera
    
[^3]: 用双机器学习估计因果效应--一种方法评估

    Estimating Causal Effects with Double Machine Learning -- A Method Evaluation

    [https://arxiv.org/abs/2403.14385](https://arxiv.org/abs/2403.14385)

    双重/无偏机器学习（DML）方法改进了因果效应估计中对非线性混淆关系的调整，摆脱传统函数形式假设，但仍然依赖于标准因果假设。

    

    使用观测数据估计因果效应仍然是一个非常活跃的研究领域。近年来，研究人员开发了利用机器学习放宽传统假设以估计因果效应的新框架。在本文中，我们回顾了其中一个最重要的方法-"双/无偏机器学习"（DML），并通过比较它在模拟数据上相对于更传统的统计方法的表现，然后将其应用于真实世界数据进行了实证评估。我们的研究发现表明，在DML中应用一个适当灵活的机器学习算法可以改进对各种非线性混淆关系的调整。这种优势使得可以摆脱通常在因果效应估计中必需的传统函数形式假设。然而，我们表明该方法在关于因果关系的标准假设方面仍然至关重要。

    arXiv:2403.14385v1 Announce Type: cross  Abstract: The estimation of causal effects with observational data continues to be a very active research area. In recent years, researchers have developed new frameworks which use machine learning to relax classical assumptions necessary for the estimation of causal effects. In this paper, we review one of the most prominent methods - "double/debiased machine learning" (DML) - and empirically evaluate it by comparing its performance on simulated data relative to more traditional statistical methods, before applying it to real-world data. Our findings indicate that the application of a suitably flexible machine learning algorithm within DML improves the adjustment for various nonlinear confounding relationships. This advantage enables a departure from traditional functional form assumptions typically necessary in causal effect estimation. However, we demonstrate that the method continues to critically depend on standard assumptions about causal 
    
[^4]: 从高维代理变量中恢复潜在潜在因素

    Recovering Latent Confounders from High-dimensional Proxy Variables

    [https://arxiv.org/abs/2403.14228](https://arxiv.org/abs/2403.14228)

    提出了一种新颖的代理混淆因子分解 (PCF) 框架，用于处理高维混合代理变量来估计连续处理效应，实验证明在高样本大小情况下，该方法在因果效果估计中表现出较高的相关性和较低的误差。

    

    检测潜在潜伏者，从代理变量是因果效应估计中的一个重要问题。以前的方法局限于低维代理，排序代理和二元治疗。我们消除了这些假设，并提出了一个新颖的代理混淆因子分解 (PCF) 框架，用于连续处理效应估计，当潜在混淆因子通过高维，混合代理变量而显现。对于特定样本大小，我们的两步 PCF 实施，使用独立成分分析 (ICA-PCF) 和端到端实施，使用梯度下降 (GD-PCF)，在高样本大小范围内，与潜在混淆因子的相关性较高，因果效应估计的绝对误差较低。，利用合成数据。即使面对气候数据，ICA-PCF 恢复了解释欧洲降雨模式的 North Atlantic Oscillation $75.9\%$ 方差的四个分量，一个已知的降水模式的混淆

    arXiv:2403.14228v1 Announce Type: cross  Abstract: Detecting latent confounders from proxy variables is an essential problem in causal effect estimation. Previous approaches are limited to low-dimensional proxies, sorted proxies, and binary treatments. We remove these assumptions and present a novel Proxy Confounder Factorization (PCF) framework for continuous treatment effect estimation when latent confounders manifest through high-dimensional, mixed proxy variables. For specific sample sizes, our two-step PCF implementation, using Independent Component Analysis (ICA-PCF), and the end-to-end implementation, using Gradient Descent (GD-PCF), achieve high correlation with the latent confounder and low absolute error in causal effect estimation with synthetic datasets in the high sample size regime. Even when faced with climate data, ICA-PCF recovers four components that explain $75.9\%$ of the variance in the North Atlantic Oscillation, a known confounder of precipitation patterns in Eur
    
[^5]: 具有权重通用先验的全连接贝叶斯神经网络的后验浓度

    Posterior concentrations of fully-connected Bayesian neural networks with general priors on the weights

    [https://arxiv.org/abs/2403.14225](https://arxiv.org/abs/2403.14225)

    本文提出了一种新的近似理论，表明具有非稀疏通用先验的BNNs可以实现接近最小化最优后验浓度速率至真实模型。

    

    训练深度神经网络（BNNs）的贝叶斯方法备受关注，并已在广泛的应用中得到有效利用。先前有关BNNs后验浓度性质的研究已有几项。然而，大多数这些研究仅在具有稀疏或重尾先验的BNN模型中展示结果。令人惊讶的是，目前尚无关于使用高斯先验的BNNs的理论结果，而高斯先验是最常用的先验之一。这种理论缺失源于缺乏近似非稀疏且具有有界参数的深度神经网络（DNNs）的结果。本文提出了用于具有有界参数的非稀疏DNNs的新近似理论。此外，基于这一近似理论，我们展示了具有非稀疏通用先验的BNNs可以实现接近最小化最优后验浓度速率至真实模型的结果。

    arXiv:2403.14225v1 Announce Type: cross  Abstract: Bayesian approaches for training deep neural networks (BNNs) have received significant interest and have been effectively utilized in a wide range of applications. There have been several studies on the properties of posterior concentrations of BNNs. However, most of these studies only demonstrate results in BNN models with sparse or heavy-tailed priors. Surprisingly, no theoretical results currently exist for BNNs using Gaussian priors, which are the most commonly used one. The lack of theory arises from the absence of approximation results of Deep Neural Networks (DNNs) that are non-sparse and have bounded parameters. In this paper, we present a new approximation theory for non-sparse DNNs with bounded parameters. Additionally, based on the approximation theory, we show that BNNs with non-sparse general priors can achieve near-minimax optimal posterior concentration rates to the true model.
    
[^6]: OTSeg：多提示Sinkhorn注意力用于零样本语义分割

    OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation

    [https://arxiv.org/abs/2403.14183](https://arxiv.org/abs/2403.14183)

    通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。

    

    CLIP的最新成功证明了通过将多模态知识转移到像素级分类来进行零样本语义分割的有希望的结果。然而，在现有方法中，利用预先训练的CLIP知识来紧密对齐文本嵌入和像素嵌入仍然存在局限性。为了解决这个问题，我们提出了OTSeg，这是一种新颖的多模态注意力机制，旨在增强多个文本提示匹配相关像素嵌入的潜力。我们首先提出了基于最优输运（OT）算法的多提示Sinkhorn（MPS），这使得多个文本提示可以有选择地关注图像像素内的各种语义特征。此外，受到Sinkformers在单模态设置中的成功启发，我们引入了MPS的扩展，称为多提示Sinkhorn注意力（MPSA），它有效地取代了Transformer框架中多模态设置中的交叉注意力机制。

    arXiv:2403.14183v1 Announce Type: cross  Abstract: The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. To address this issue, we propose OTSeg, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. We first propose Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads multiple text prompts to selectively focus on various semantic features within image pixels. Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn Attention (MPSA), which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settin
    
[^7]: 具有前瞻特性的策略镜像下降算法

    Policy Mirror Descent with Lookahead

    [https://arxiv.org/abs/2403.14156](https://arxiv.org/abs/2403.14156)

    提出了一种新类别的策略镜像下降算法$h$-PMD，它通过在PMD更新规则中结合多步贪心策略改进和前瞻深度$h，以解决折扣无限时间视角下的马尔可夫决策过程。

    

    策略镜像下降（PMD）作为一种多功能算法框架，包括几种重要的策略梯度算法，如自然策略梯度，并与最先进的强化学习（RL）算法（如TRPO和PPO）相联系。PMD可以看作是实现正则化1步贪心策略改进的软策略迭代算法。然而，1步贪心策略可能不是最佳选择，最近在RL领域取得了显着的实证成功，如AlphaGo和AlphaZero已经证明，相对于多步骤，贪心方法可以超越它们的1步骤对应物。在这项工作中，我们提出了一种新类别的PMD算法，称为$h$-PMD，它将具有前瞻深度$h$的多步贪心策略改进结合到PMD更新规则中。为了解决折扣无限时间视角下的马尔可夫决策过程，其中折扣因子为$\gamma$，我们展示了$h$-PMD可以推广标准的PMD。

    arXiv:2403.14156v1 Announce Type: cross  Abstract: Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\gamma$, we show that $h$-PMD which generalizes the standard PMD enj
    
[^8]: 使用根祖关系对变量进行分组学习因果图

    Learning causal graphs using variable grouping according to ancestral relationship

    [https://arxiv.org/abs/2403.14125](https://arxiv.org/abs/2403.14125)

    使用分治方法将变量分组，按照条件独立关系学习因果图，以提高在样本量较小的情况下的估算准确性。

    

    已经提出了几种因果发现算法。然而，当样本量相对于变量数量较小时，使用现有方法估算因果图的准确性会降低。有些方法在样本量小于变量数量时并不可行。为了规避这些问题，一些研究人员提出了采用分治方法的因果结构学习算法。为了学习整个因果图，这些方法首先根据变量之间的条件独立关系将变量分割成几个子集，然后将常规的因果发现算法应用于每个子集并合并估计结果。由于分治方法减少了因果结构学习算法应用的变量数量，因此预计可以改善因果图的估算准确性，尤其是在样本量相对较小时。

    arXiv:2403.14125v1 Announce Type: cross  Abstract: Several causal discovery algorithms have been proposed. However, when the sample size is small relative to the number of variables, the accuracy of estimating causal graphs using existing methods decreases. And some methods are not feasible when the sample size is smaller than the number of variables. To circumvent these problems, some researchers proposed causal structure learning algorithms using divide-and-conquer approaches. For learning the entire causal graph, the approaches first split variables into several subsets according to the conditional independence relationships among the variables, then apply a conventional causal discovery algorithm to each subset and merge the estimated results. Since the divide-and-conquer approach reduces the number of variables to which a causal structure learning algorithm is applied, it is expected to improve the estimation accuracy of causal graphs, especially when the sample size is small rela
    
[^9]: 通过最优输运的自动异常值矫正

    Automatic Outlier Rectification via Optimal Transport

    [https://arxiv.org/abs/2403.14067](https://arxiv.org/abs/2403.14067)

    提出了一种自动异常值矫正机制，通过将矫正和估计集成到联合优化框架中，利用最优输运和凹成本函数来检测和移除异常值，并选择最佳分布来执行估计任务

    

    在本文中，我们提出了一个新颖的概念框架，使用具有凹成本函数的最优输运来检测异常值。传统的异常值检测方法通常使用两阶段流程：首先检测并移除异常值，然后在清洁数据上执行估计。然而，这种方法并没有将异常值移除与估计任务联系起来，留下了改进的空间。为了解决这一局限性，我们提出了一种自动异常值矫正机制，将矫正和估计集成到一个联合优化框架中。我们首先利用具有凹成本函数的最优输运距离来构建概率分布空间中的矫正集合。然后，我们选择在矫正集合中的最佳分布来执行估计任务。值得注意的是，我们在本文中引入的凹成本函数是使我们的估计器具有关键性的因素。

    arXiv:2403.14067v1 Announce Type: cross  Abstract: In this paper, we propose a novel conceptual framework to detect outliers using optimal transport with a concave cost function. Conventional outlier detection approaches typically use a two-stage procedure: first, outliers are detected and removed, and then estimation is performed on the cleaned data. However, this approach does not inform outlier removal with the estimation task, leaving room for improvement. To address this limitation, we propose an automatic outlier rectification mechanism that integrates rectification and estimation within a joint optimization framework. We take the first step to utilize an optimal transport distance with a concave cost function to construct a rectification set in the space of probability distributions. Then, we select the best distribution within the rectification set to perform the estimation task. Notably, the concave cost function we introduced in this paper is the key to making our estimator e
    
[^10]: 基于假设的深度学习用于外域检测

    Hypothesis-Driven Deep Learning for Out of Distribution Detection

    [https://arxiv.org/abs/2403.14058](https://arxiv.org/abs/2403.14058)

    本论文提出了一种基于假设的深度学习方法，用于量化新样本是否属于内部分布或外部分布，在高风险应用中如医疗保健领域具有重要意义。

    

    不透明黑盒系统的预测经常用于诸如医疗保健等高风险应用中。对于这类应用，评估模型处理超出训练数据域的样本的方式至关重要。虽然存在几种度量和测试来检测深度神经网络（DNN）中的超出分布（OoD）数据和分布内（InD）数据，但它们的性能在数据集、模型和任务之间存在显著差异，这限制了它们的实际应用。在本文中，我们提出了一种基于假设的方法来量化新样本是InD还是OoD。给定一个训练过的DNN和一些输入，我们首先通过DNN馈送输入并计算一组OoD度量，称为潜在响应。然后，我们将OoD检测问题表述为潜在响应之间的假设检验，并使用基于排列的重新采样来推断在零假设下观察到的潜在响应的显著性。

    arXiv:2403.14058v1 Announce Type: new  Abstract: Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothe
    
[^11]: 通过随机递归方程分析随机梯度下降的重尾特性

    Analysing heavy-tail properties of Stochastic Gradient Descent by means of Stochastic Recurrence Equations

    [https://arxiv.org/abs/2403.13868](https://arxiv.org/abs/2403.13868)

    本文通过随机递归方程的概率框架，研究了随机梯度下降的重尾特性，并通过i-p矩阵理论扩展了G\"{u}rb\"{u}zbalaban等人的结果。

    

    在机器学习理论的最近研究中，观察到可以在随机递归的概率框架下研究随机梯度下降（SGD）的重尾特性。特别地，G\"{u}rb\"{u}zbalaban等人（arXiv:2006.04740）考虑了一个对应于线性回归的设置，其中SGD的迭代可以通过多变量仿射随机递归$X_k=A_k X_{k-1}+B_k$来建模，其中$(A_k, B_k)$是独立同分布对，$A_k$是一个随机对称矩阵，$B_k$是一个随机向量。本文将回答引用论文中的几个未解问题，并通过应用不可约-近端（i-p）矩阵理论扩展他们的结果。

    arXiv:2403.13868v1 Announce Type: cross  Abstract: In recent works on the theory of machine learning, it has been observed that heavy tail properties of Stochastic Gradient Descent (SGD) can be studied in the probabilistic framework of stochastic recursions. In particular, G\"{u}rb\"{u}zbalaban et al. (arXiv:2006.04740) considered a setup corresponding to linear regression for which iterations of SGD can be modelled by a multivariate affine stochastic recursion $X_k=A_k X_{k-1}+B_k$, for independent and identically distributed pairs $(A_k, B_k)$, where $A_k$ is a random symmetric matrix and $B_k$ is a random vector. In this work, we will answer several open questions of the quoted paper and extend their results by applying the theory of irreducible-proximal (i-p) matrices.
    
[^12]: 基于树的学习用于深度预测混沌现象

    Tree-based Learning for High-Fidelity Prediction of Chaos

    [https://arxiv.org/abs/2403.13836](https://arxiv.org/abs/2403.13836)

    TreeDOX是一种基于树的方法，不需要超参数调整，使用时间延迟过度嵌入和额外树回归器进行特征降维和预测，并在深度预测混沌系统中表现出state-of-the-art的性能。

    

    深度预测混沌系统的时间演变是至关重要但具有挑战性的。现有解决方案需要进行超参数调整，这严重阻碍了它们的广泛应用。在这项工作中，我们引入了一种无需超参数调整的基于树的方法：TreeDOX。它使用时间延迟过度嵌入作为显式短期记忆，以及额外树回归器来执行特征降维和预测。我们使用Henon映射，Lorenz和Kuramoto-Sivashinsky系统以及现实世界的Southern Oscillation Index展示了TreeDOX的最先进性能。

    arXiv:2403.13836v1 Announce Type: new  Abstract: Model-free forecasting of the temporal evolution of chaotic systems is crucial but challenging. Existing solutions require hyperparameter tuning, significantly hindering their wider adoption. In this work, we introduce a tree-based approach not requiring hyperparameter tuning: TreeDOX. It uses time delay overembedding as explicit short-term memory and Extra-Trees Regressors to perform feature reduction and forecasting. We demonstrate the state-of-the-art performance of TreeDOX using the Henon map, Lorenz and Kuramoto-Sivashinsky systems, and the real-world Southern Oscillation Index.
    
[^13]: 线性约束权重：减少神经网络训练中的激活偏移

    Linearly Constrained Weights: Reducing Activation Shift for Faster Training of Neural Networks

    [https://arxiv.org/abs/2403.13833](https://arxiv.org/abs/2403.13833)

    神经网络中引入线性约束权重（LCW）来减少激活偏移，有效解决了梯度消失问题，提高了深度前向网络的训练效率。

    

    在本文中，我们首次确定了激活偏移，这是神经网络中的一个简单但显著的现象，即神经元的预激活值具有非零均值，该均值取决于神经元的权重向量与前一层激活向量均值之间的夹角。然后，我们提出了线性约束权重（LCW），以减少全连接和卷积层中的激活偏移。从网络变量的方差如何通过前向和反向链中的层操作来改变的角度研究了减少神经网络中激活偏移的影响。我们还讨论了它与梯度消失问题的关系。实验结果表明，LCW使具有sigmoid激活函数的深度前向网络能够通过解决梯度消失问题而得以有效训练。此外，与批归一化结合使用，LCW改进了genera

    arXiv:2403.13833v1 Announce Type: cross  Abstract: In this paper, we first identify activation shift, a simple but remarkable phenomenon in a neural network in which the preactivation value of a neuron has non-zero mean that depends on the angle between the weight vector of the neuron and the mean of the activation vector in the previous layer. We then propose linearly constrained weights (LCW) to reduce the activation shift in both fully connected and convolutional layers. The impact of reducing the activation shift in a neural network is studied from the perspective of how the variance of variables in the network changes through layer operations in both forward and backward chains. We also discuss its relationship to the vanishing gradient problem. Experimental results show that LCW enables a deep feedforward network with sigmoid activation functions to be trained efficiently by resolving the vanishing gradient problem. Moreover, combined with batch normalization, LCW improves genera
    
[^14]: 基于AI的精准肿瘤学：基于多组学数据的个性化反事实治疗建议的机器学习框架

    Towards AI-Based Precision Oncology: A Machine Learning Framework for Personalized Counterfactual Treatment Suggestions based on Multi-Omics Data

    [https://arxiv.org/abs/2402.12190](https://arxiv.org/abs/2402.12190)

    提出了一种基于机器学习的框架，用于个性化反事实癌症治疗建议，集成了多种多组学技术的专家，可提供优越性能和决策解释。

    

    AI驱动的精准肿瘤学具有通过利用AI模型分析复杂患者特征与对应治疗结果之间互动的潜力，有望重塑癌症治疗。新技术平台促进了及时获取多模态肿瘤生物学数据，如单细胞多组学数据，使得这种数据的质量和数量可用于数据驱动的改进临床决策。本文提出了一个模块化的机器学习框架，旨在基于训练有关多种多组学技术的机器学习专家组成的集成来进行个性化反事实癌症治疗建议。这些专门的反事实专家根据技术不断聚合为性能更优越的专家，可提供决策的置信度和解释。

    arXiv:2402.12190v1 Announce Type: cross  Abstract: AI-driven precision oncology has the transformative potential to reshape cancer treatment by leveraging the power of AI models to analyze the interaction between complex patient characteristics and their corresponding treatment outcomes. New technological platforms have facilitated the timely acquisition of multimodal data on tumor biology at an unprecedented resolution, such as single-cell multi-omics data, making this quality and quantity of data available for data-driven improved clinical decision-making. In this work, we propose a modular machine learning framework designed for personalized counterfactual cancer treatment suggestions based on an ensemble of machine learning experts trained on diverse multi-omics technologies. These specialized counterfactual experts per technology are consistently aggregated into a more powerful expert with superior performance and can provide both confidence and an explanation of its decision. The
    
[^15]: 对深度学习的不确定性量化进行调查：从不确定性来源的角度分析

    A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective

    [https://arxiv.org/abs/2302.13425](https://arxiv.org/abs/2302.13425)

    本研究对深度学习的不确定性量化进行了调查，从不确定性来源的角度分析不同方法，以评估DNN预测的置信度。

    

    深度神经网络(DNNs)在计算机视觉、自然语言处理以及科学与工程领域取得了巨大成功。然而，人们也认识到DNNs有时会做出意外、错误但过于自信的预测。这可能导致在自动驾驶、医学诊断和灾难响应等高风险应用中出现严重后果。不确定性量化（UQ）旨在估计DNN预测的置信度，超越预测准确性。近年来，已经开发了许多针对DNNs的UQ方法。系统地对这些UQ方法进行分类并比较它们的优势和劣势具有极大的实际价值。然而，现有调查大多集中在从神经网络架构角度或贝叶斯角度对UQ方法进行分类，忽略了每种方法可能引入的不确定性来源。

    arXiv:2302.13425v3 Announce Type: replace  Abstract: Deep neural networks (DNNs) have achieved tremendous success in making accurate predictions for computer vision, natural language processing, as well as science and engineering domains. However, it is also well-recognized that DNNs sometimes make unexpected, incorrect, but overconfident predictions. This can cause serious consequences in high-stake applications, such as autonomous driving, medical diagnosis, and disaster response. Uncertainty quantification (UQ) aims to estimate the confidence of DNN predictions beyond prediction accuracy. In recent years, many UQ methods have been developed for DNNs. It is of great practical value to systematically categorize these UQ methods and compare their advantages and disadvantages. However, existing surveys mostly focus on categorizing UQ methodologies from a neural network architecture perspective or a Bayesian perspective and ignore the source of uncertainty that each methodology can incor
    
[^16]: 一种用于谱聚类的非参数自举方法

    A Non-Parametric Bootstrap for Spectral Clustering

    [https://arxiv.org/abs/2209.05812](https://arxiv.org/abs/2209.05812)

    开发了两种新的算法，结合了数据矩阵的谱分解和非参数自举抽样方案，解决了谱聚类中收敛到次优解的问题，并展示出了其在估计有限混合模型时的优越性。

    

    有限混合模型是聚类领域中常用的方法，其软聚类成员概率很有益处。拟合有限混合模型的常见方法是使用谱聚类，该方法可以利用期望最大化（EM）算法。然而，EM算法存在一些问题，包括收敛到次优解。我们通过开发两种新算法来解决这个问题，这两种算法结合了数据矩阵的谱分解和非参数自举抽样方案。模拟显示了我们算法的有效性，并且展示出它们不仅具有灵活性，而且在估计有限混合模型时，与其他聚类算法相比，它们还具有计算效率和避免糟糕解的能力。相较于其他拟合有限混合模型的自举算法，我们的技术在收敛性方面更加一致。

    arXiv:2209.05812v2 Announce Type: replace-cross  Abstract: Finite mixture modelling is a popular method in the field of clustering and is beneficial largely due to its soft cluster membership probabilities. A common method for fitting finite mixture models is to employ spectral clustering, which can utilize the expectation-maximization (EM) algorithm. However, the EM algorithm falls victim to a number of issues, including convergence to sub-optimal solutions. We address this issue by developing two novel algorithms that incorporate the spectral decomposition of the data matrix and a non-parametric bootstrap sampling scheme. Simulations display the validity of our algorithms and demonstrate not only their flexibility, but also their computational efficiency and ability to avoid poor solutions when compared to other clustering algorithms for estimating finite mixture models. Our techniques are more consistent in their convergence when compared to other bootstrapped algorithms that fit fi
    
[^17]: 关于带缺失值的监督学习的一致性

    On the consistency of supervised learning with missing values

    [https://arxiv.org/abs/1902.06931](https://arxiv.org/abs/1902.06931)

    两种方法在带缺失值的监督学习中表现出一致性，当缺失值不具信息性时，使用常数进行插补是一种简单且重要的实践方法。

    

    在许多应用设置中，数据存在缺失值，这使得分析变得具有挑战性。丰富的文献涉及缺失值在推断框架中的处理：从不完整的表中估计参数及其方差。在这里，我们考虑监督学习设置：在训练和测试数据中出现缺失值时预测目标。我们表明了两种方法在预测中的一致性。一个引人注目的结果是，当缺失值不具信息性时，使用常数进行插补，例如在学习之前使用均值，是一致的。这与推断设置形成鲜明对比，推断设置中常用的均值插补方法被指责扭曲数据的分布。这样一个简单的方法在实践中能够保持一致性是很重要的。我们还展示了适用于完整观测的预测器可以通过多重插补在不完整数据上进行最佳预测。最后，为了比较插补

    arXiv:1902.06931v4 Announce Type: replace-cross  Abstract: In many application settings, the data have missing entries which make analysis challenging. An abundant literature addresses missing values in an inferential framework: estimating parameters and their variance from incomplete tables. Here, we consider supervised-learning settings: predicting a target when missing values appear in both training and testing data. We show the consistency of two approaches in prediction. A striking result is that the widely-used method of imputing with a constant, such as the mean prior to learning is consistent when missing values are not informative. This contrasts with inferential settings where mean imputation is pointed at for distorting the distribution of the data. That such a simple approach can be consistent is important in practice. We also show that a predictor suited for complete observations can predict optimally on incomplete data,through multiple imputation.Finally, to compare imput
    
[^18]: 做时间扭曲吧：学习动力系统的拓扑不变量

    Let's do the time-warp-attend: Learning topological invariants of dynamical systems. (arXiv:2312.09234v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.09234](http://arxiv.org/abs/2312.09234)

    该论文提出了一个数据驱动、基于物理信息的深度学习框架，用于分类和表征动力学变化的拓扑不变特征提取，特别关注超临界霍普分歧。这个方法可以帮助预测系统的质变和常发行为变化。

    

    科学领域中的动力系统，从电路到生态网络，当其基本参数跨越阈值时，会发生质变和常发性的行为变化，称为分歧。现有方法能够预测单个系统中即将发生的灾难，但主要基于时间序列，并且在分类不同系统的定性动力学变化和推广到真实数据方面存在困难。为了应对这一挑战，我们提出了一个数据驱动的、基于物理信息的深度学习框架，用于对动力学变化进行分类并表征分歧边界的拓扑不变特征提取。我们专注于超临界霍普分歧的典型案例，其用于模拟广泛应用的周期性动力学。我们的卷积关注方法经过了数据增强训练，鼓励学习可以用于检测分歧边界的拓扑不变量。

    Dynamical systems across the sciences, from electrical circuits to ecological networks, undergo qualitative and often catastrophic changes in behavior, called bifurcations, when their underlying parameters cross a threshold. Existing methods predict oncoming catastrophes in individual systems but are primarily time-series-based and struggle both to categorize qualitative dynamical regimes across diverse systems and to generalize to real data. To address this challenge, we propose a data-driven, physically-informed deep-learning framework for classifying dynamical regimes and characterizing bifurcation boundaries based on the extraction of topologically invariant features. We focus on the paradigmatic case of the supercritical Hopf bifurcation, which is used to model periodic dynamics across a wide range of applications. Our convolutional attention method is trained with data augmentations that encourage the learning of topological invariants which can be used to detect bifurcation boun
    
[^19]: 《$\mathbb{Z}_2\times \mathbb{Z}_2$》等变量量子神经网络：与经典神经网络的基准比较

    $\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks. (arXiv:2311.18744v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2311.18744](http://arxiv.org/abs/2311.18744)

    本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与经典神经网络的性能进行了全面比较分析，结果表明《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上表现优越。

    

    本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与它们的经典对应物：等变量神经网络（ENN）和深度神经网络（DNN）的性能进行了全面比较分析。我们通过两个二元分类任务的玩具示例评估每个网络的性能，关注模型复杂度（由参数数量测量）和训练数据集的大小。我们的结果显示，《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上提供了更优秀的性能。

    This paper presents a comprehensive comparative analysis of the performance of Equivariant Quantum Neural Networks (EQNN) and Quantum Neural Networks (QNN), juxtaposed against their classical counterparts: Equivariant Neural Networks (ENN) and Deep Neural Networks (DNN). We evaluate the performance of each network with two toy examples for a binary classification task, focusing on model complexity (measured by the number of parameters) and the size of the training data set. Our results show that the $\mathbb{Z}_2\times \mathbb{Z}_2$ EQNN and the QNN provide superior performance for smaller parameter sets and modest training data samples.
    
[^20]: LMC多任务高斯过程模型的精确和高效解决方案

    Exact and efficient solutions of the LMC Multitask Gaussian Process model. (arXiv:2310.12032v1 [cs.LG])

    [http://arxiv.org/abs/2310.12032](http://arxiv.org/abs/2310.12032)

    LMC多任务高斯过程模型的精确解决方案表明，只需对噪声模型进行温和假设，即可实现高效计算。通过引入完整参数化的“投影LMC”模型和边缘似然函数表达式，展示了该方法相对于未经处理的方法的优异性能。

    

    线性共同关联模型（LMC）是一种非常通用的多任务高斯过程模型，用于回归或分类。虽然其表达能力和概念简单性很有吸引力，但朴素实现在数据点数量和任务数量方面具有立方复杂度，使得对大多数应用来说，必须进行近似处理。然而，最近的研究表明，在某些条件下，该模型的潜在过程可以解耦，导致仅与所述过程数量呈线性复杂度。我们在这里扩展了这些结果，从最一般的假设中展示了在LMC的高效精确计算所需的唯一条件是对噪声模型进行温和假设。我们引入了结果的完整参数化“投影LMC”模型，并给出了边缘似然函数的表达式，以实现高效的优化。我们对合成数据进行了参数研究，展示了我们方法相对于未经处理的方法的优异性能。

    The Linear Model of Co-regionalization (LMC) is a very general model of multitask gaussian process for regression or classification. While its expressivity and conceptual simplicity are appealing, naive implementations have cubic complexity in the number of datapoints and number of tasks, making approximations mandatory for most applications. However, recent work has shown that under some conditions the latent processes of the model can be decoupled, leading to a complexity that is only linear in the number of said processes. We here extend these results, showing from the most general assumptions that the only condition necessary to an efficient exact computation of the LMC is a mild hypothesis on the noise model. We introduce a full parametrization of the resulting \emph{projected LMC} model, and an expression of the marginal likelihood enabling efficient optimization. We perform a parametric study on synthetic data to show the excellent performance of our approach, compared to an unr
    
[^21]: 基于负距离核的最大平均距离(MMD)梯度流的后验抽样

    Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])

    [http://arxiv.org/abs/2310.03054](http://arxiv.org/abs/2310.03054)

    本文提出了一种基于负距离核的最大平均距离(MMD)的条件流方法，用于后验抽样和条件生成建模。通过离散的Wasserstein梯度流近似联合分布，证明了粒子流是适当功能的Wasserstein梯度流。在条件图像生成和超分辨率等逆问题中展示了方法的有效性。

    

    我们提出了基于负距离核的最大平均距离(MMD)的条件流用于后验抽样和条件生成建模。这个MMD，也被称为能量距离，具有像通过切片和排序进行高效计算的几个有益属性。我们使用离散的Wasserstein梯度流来近似真实情况和观察值的联合分布，并为后验分布建立了误差界限。此外，我们证明了我们的粒子流确实是适当功能的Wasserstein梯度流。我们方法的能力通过数字示例进行了演示，包括条件图像生成和诸如超分辨率、修复和低剂量和有限角度设置下的计算机断层扫描等逆问题。

    We propose conditional flows of the maximum mean discrepancy (MMD) with the negative distance kernel for posterior sampling and conditional generative modeling. This MMD, which is also known as energy distance, has several advantageous properties like efficient computation via slicing and sorting. We approximate the joint distribution of the ground truth and the observations using discrete Wasserstein gradient flows and establish an error bound for the posterior distributions. Further, we prove that our particle flow is indeed a Wasserstein gradient flow of an appropriate functional. The power of our method is demonstrated by numerical examples including conditional image generation and inverse problems like superresolution, inpainting and computed tomography in low-dose and limited-angle settings.
    
[^22]: ED-NeRF: 使用潜空间 NeRF 实现高效的文本引导的 3D 场景编辑

    ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF. (arXiv:2310.02712v1 [cs.CV])

    [http://arxiv.org/abs/2310.02712](http://arxiv.org/abs/2310.02712)

    ED-NeRF 提出了一种高效的 3D 场景编辑方法，通过将场景嵌入到潜空间中，得到更快速且更易于编辑的 NeRF 骨干。

    

    最近，文本到图像扩散模型取得了显著进展，在二维图像生成方面取得了突破性的性能。这些进展已经扩展到三维模型，实现了从文本描述中生成新的三维对象。这演变成了 NeRF 编辑方法，通过文本条件允许对现有的三维对象进行操作。然而，现有的 NeRF 编辑技术在性能上面临着一些限制，如训练速度慢和使用的损失函数不充分考虑编辑。为了解决这个问题，我们提出了一种新颖的 3D NeRF 编辑方法，称为 ED-NeRF，通过将真实世界场景成功嵌入到潜扩散模型 (LDM) 的潜空间中，通过独特的细化层。这种方法使我们能够获得一个不仅更快，而且更适合于编辑的 NeRF 骨干，与传统的图像空间 NeRF 编辑相比。此外，我们提出了一种改进的损失函数。

    Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this, here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss 
    
[^23]: 学习如何提供注重依从性的建议

    Learning to Make Adherence-Aware Advice. (arXiv:2310.00817v1 [stat.ML])

    [http://arxiv.org/abs/2310.00817](http://arxiv.org/abs/2310.00817)

    本文提出了一种顺序决策模型，考虑了人的依从程度和机器提供建议的时机，并提供了学习算法来学习最佳的建议策略。

    

    随着人工智能系统在人类决策中扮演越来越重要的角色，人工智能与人类之间的交互存在挑战。由于没有充分考虑到人类忽视人工智能建议和人工智能选择性提供建议的需求，一个挑战就来自于底层人工智能策略的不佳表现。本文提出了一个顺序决策模型，该模型考虑了人类的依从程度（即人类遵循/拒绝机器建议的概率），并引入了一个推迟选项，使得机器在最合适的时候可以暂时不提供建议。我们提供了学习算法，可以学习最佳的建议策略，并仅在关键时刻提供建议。与问题不可知的强化学习算法相比，我们的专门化学习算法不仅具有更好的理论收敛性能，而且在实证性能上表现出色。

    As artificial intelligence (AI) systems play an increasingly prominent role in human decision-making, challenges surface in the realm of human-AI interactions. One challenge arises from the suboptimal AI policies due to the inadequate consideration of humans disregarding AI recommendations, as well as the need for AI to provide advice selectively when it is most pertinent. This paper presents a sequential decision-making model that (i) takes into account the human's adherence level (the probability that the human follows/rejects machine advice) and (ii) incorporates a defer option so that the machine can temporarily refrain from making advice. We provide learning algorithms that learn the optimal advice policy and make advice only at critical time stamps. Compared to problem-agnostic reinforcement learning algorithms, our specialized learning algorithms not only enjoy better theoretical convergence properties but also show strong empirical performance.
    
[^24]: 演化直接策略搜索中的广义早停止方法

    Generalized Early Stopping in Evolutionary Direct Policy Search. (arXiv:2308.03574v1 [stat.ML])

    [http://arxiv.org/abs/2308.03574](http://arxiv.org/abs/2308.03574)

    本文提出了一种适用于直接策略搜索的早停止方法，通过观察每个时间步骤的目标值来决定是否停止评估，而无需问题特定的知识。在测试中，该方法在游戏、机器人和经典控制领域中表现出节省计算时间的优势。

    

    在许多优化问题中，尤其是涉及在物理世界中进行评估的直接策略搜索任务中，评估时间通常较长。当在固定时间段内评估解决方案时，往往会明确无法通过增加计算时间来提高目标值（例如，当两轮机器人持续在原地旋转时）。在这种情况下，及早停止评估以节省计算时间是有意义的。然而，大多数评估停止方法都是问题特定的，并且需要专门为当前任务设计。因此，我们提出了一种直接策略搜索的早停止方法。该方法只查看每个时间步骤的目标值，不需要任何问题特定的知识。我们在五个来自游戏、机器人和经典控制领域的直接策略搜索环境中测试了引入的停止准则，并展示了其节省了计算时间的优势。

    Lengthy evaluation times are common in many optimization problems such as direct policy search tasks, especially when they involve conducting evaluations in the physical world, e.g. in robotics applications. Often, when evaluating a solution over a fixed time period, it becomes clear that the objective value will not increase with additional computation time (for example, when a two-wheeled robot continuously spins on the spot). In such cases, it makes sense to stop the evaluation early to save computation time. However, most approaches to stop the evaluation are problem-specific and need to be specifically designed for the task at hand. Therefore, we propose an early stopping method for direct policy search. The proposed method only looks at the objective value at each time step and requires no problem-specific knowledge.  We test the introduced stopping criterion in five direct policy search environments drawn from games, robotics, and classic control domains, and show that it can sa
    
[^25]: 从ReLU神经网络的缓和过拟合到良性过拟合

    From Tempered to Benign Overfitting in ReLU Neural Networks. (arXiv:2305.15141v1 [cs.LG])

    [http://arxiv.org/abs/2305.15141](http://arxiv.org/abs/2305.15141)

    本论文通过对二层ReLU神经网络进行研究，证明了各种假设下过拟合的类型会从一维数据的极端情况下缓和到高维的良性，揭示了输入维度在神经网络过拟合中的关键作用。

    

    过参数化神经网络被观察到即使训练模型来完美地适应嘈杂的数据也能很好地推广。这一现象引发了大量关于“良性过拟合”的工作，其中内插预测器实现接近最优性能。最近，有人猜测并经验性地观察到神经网络的行为通常更好地描述为“缓和过拟合”，其中性能既非最优，也非微不足道，并随噪声水平的变化而降低。然而，迄今为止，这一主张尚缺乏关于非线性神经网络理论的证明。在这项工作中，我们提供了几个结果，旨在弥合这些互补的观点。我们研究了一个简单的分类设置，使用二层ReLU神经网络，并证明在各种假设下，过拟合的类型从一维数据的极端情况下缓和到高维的良性。因此，我们证明输入维度在这种情况下有关键作用。

    Overparameterized neural networks (NNs) are observed to generalize well even when trained to perfectly fit noisy data. This phenomenon motivated a large body of work on "benign overfitting", where interpolating predictors achieve near-optimal performance. Recently, it was conjectured and empirically observed that the behavior of NNs is often better described as "tempered overfitting", where the performance is non-optimal yet also non-trivial, and degrades as a function of the noise level. However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views. We study a simple classification setting with 2-layer ReLU NNs, and prove that under various assumptions, the type of overfitting transitions from tempered in the extreme case of one-dimensional data, to benign in high dimensions. Thus, we show that the input dimension has a crucial role on the type of overfitting in thi
    
[^26]: 异质性功能数据的混合分割模型

    Mixture of segmentation for heterogeneous functional data. (arXiv:2303.10712v1 [stat.ME])

    [http://arxiv.org/abs/2303.10712](http://arxiv.org/abs/2303.10712)

    本文提出了一种混合分割模型，可以处理异质性功能数据，通过动态规划的EM算法近似最大似然估计器，方法在模拟与真实数据集上得到验证。

    

    本文针对时间和人口异质性的功能数据提出了一种混合分割模型，旨在保持功能结构的同时表示异质性。 讨论了最大似然估计器的可辨识性和一致性，并采用动态规划的EM算法来近似最大似然估计器。 该方法在模拟数据上进行了说明，并在用电量真实数据集上得到了应用。

    In this paper we consider functional data with heterogeneity in time and in population. We propose a mixture model with segmentation of time to represent this heterogeneity while keeping the functional structure. Maximum likelihood estimator is considered, proved to be identifiable and consistent. In practice, an EM algorithm is used, combined with dynamic programming for the maximization step, to approximate the maximum likelihood estimator. The method is illustrated on a simulated dataset, and used on a real dataset of electricity consumption.
    
[^27]: 经验过程的实例相关的一致尾部界

    Instance-dependent uniform tail bounds for empirical processes. (arXiv:2209.10053v3 [math.PR] UPDATED)

    [http://arxiv.org/abs/2209.10053](http://arxiv.org/abs/2209.10053)

    该论文提出了一个经验过程的统一尾部界，该尾部界以函数的个体偏差而不是在考虑的类中的最坏情况偏差为基础。

    

    我们提出了一个经验过程的统一尾部界，该尾部界以函数类为指标，以函数的个体偏差而不是在考虑的类中的最坏情况偏差为基础。通过将标准通用链接论证引入一个最初的“泄气”步骤来建立尾部界。生成的尾部界有一个主要的复杂度组成部分，即一个关于泄气函数类的 Talagrand $\gamma$ 函数的变体，以及一个实例相关的偏差项，通过一个适当缩放的适当范数的版本来衡量。这些项都使用基于相关的母函数的某些系数来表达。当函数类在给定的（指数型）Orlicz空间中时，我们还提供了更明确的近似值来描述所提到的系数。

    We formulate a uniform tail bound for empirical processes indexed by a class of functions, in terms of the individual deviations of the functions rather than the worst-case deviation in the considered class. The tail bound is established by introducing an initial "deflation" step to the standard generic chaining argument. The resulting tail bound has a main complexity component, a variant of Talagrand's $\gamma$ functional for the deflated function class, as well as an instance-dependent deviation term, measured by an appropriately scaled version of a suitable norm. Both of these terms are expressed using certain coefficients formulated based on the relevant cumulant generating functions. We also provide more explicit approximations for the mentioned coefficients, when the function class lies in a given (exponential type) Orlicz space.
    

