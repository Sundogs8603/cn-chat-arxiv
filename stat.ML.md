# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Unexpected Improvements to Expected Improvement for Bayesian Optimization.](http://arxiv.org/abs/2310.20708) | 提出了LogEI作为一类新的贝叶斯优化的获得函数，具有与传统的EI函数相同或近似相等的最优解，但数值上更容易进行优化。 |
| [^2] | [Vanishing Gradients in Reinforcement Finetuning of Language Models.](http://arxiv.org/abs/2310.20703) | 本研究发现在强化微调（RFT）中存在梯度消失的问题，当模型下奖励的标准差较小时，输入的期望梯度会消失，导致奖励最大化缓慢。初始监督微调（SFT）阶段是克服这个问题的最有希望的方法。 |
| [^3] | [Latent Field Discovery In Interacting Dynamical Systems With Neural Fields.](http://arxiv.org/abs/2310.20679) | 本文通过笛卡尔积和神经场提出了一种新的图网络，用于在相互作用动态系统中发现局部物体相互作用和全局场效应的潜在力场。 |
| [^4] | [Projecting basis functions with tensor networks for Gaussian process regression.](http://arxiv.org/abs/2310.20630) | 本文提出了一种使用低秩张量网络实现高斯过程回归的方法，该方法允许在指数数量的基函数情况下进行高效计算。 |
| [^5] | [Graph Matching via convex relaxation to the simplex.](http://arxiv.org/abs/2310.20609) | 本文提出了一种新的图匹配方法，通过对单位单纯形进行凸松弛，并开发了高效的镜像下降方案来解决该问题。在相关高斯Wigner模型下，单纯形松弛法具有唯一解，并且能够精确恢复地面真实排列。 |
| [^6] | [Stochastic Gradient Descent for Gaussian Processes Done Right.](http://arxiv.org/abs/2310.20581) | 本文研究了使用随机梯度下降方法优化高斯过程回归问题，并引入了一种特定的随机对偶梯度下降算法，该方法在标准回归基准和贝叶斯优化任务上表现出很高的竞争力。 |
| [^7] | [Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks.](http://arxiv.org/abs/2310.20579) | 通过分析研究了超参数化神经网络的初始化对于隐私保护的影响，发现隐私界的改善与深度和初始化分布的关系密切相关。 |
| [^8] | [Multi-task learning of convex combinations of forecasting models.](http://arxiv.org/abs/2310.20545) | 本文提出了一种多任务学习方法，通过深度神经网络同时解决了预测模型选择和凸组合权重学习的问题。通过回归分支学习权重和分类分支选择具有多样性的预测方法，提高了基于特征的预测的精确度。 |
| [^9] | [Directed Cyclic Graph for Causal Discovery from Multivariate Functional Data.](http://arxiv.org/abs/2310.20537) | 本文提出了一个功能线性结构方程模型，用于从多元函数数据中进行因果发现。模型通过低维因果嵌入空间将多元函数数据中的所有相关因果信息保留下来。通过模拟研究，证明了该模型在因果可辨识性和因果图估计方面具有优势。 |
| [^10] | [Parametric Fairness with Statistical Guarantees.](http://arxiv.org/abs/2310.20508) | 该论文研究了具有统计保证的参数公平性问题，提出了一种新的指标来解决公平性中的交叉问题，并开发了一种参数化方法来高效解决实际挑战。 |
| [^11] | [Generative Learning of Continuous Data by Tensor Networks.](http://arxiv.org/abs/2310.20498) | 张量网络生成模型一般适用于二进制或类别数据，这篇论文介绍了一种新型张量网络生成模型，它可以用于学习连续数据分布，并展示了该模型在合成和真实数据集上的性能表现。 |
| [^12] | [AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms.](http://arxiv.org/abs/2310.20452) | 我们提出了一个统一的收敛理论，分析了异步-SGD算法在异构设置下的性能，这对于提高算法性能和收敛速度具有重要意义。 |
| [^13] | [Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks.](http://arxiv.org/abs/2310.20447) | 本文提出了一种使用先验数据拟合神经网络进行高效贝叶斯学习曲线外推的方法，该方法相比现有方法更准确且速度更快。 |
| [^14] | [The Phase Transition Phenomenon of Shuffled Regression.](http://arxiv.org/abs/2310.20438) | 本研究研究了洗牌回归问题的相变现象，并利用信息传递技术确定了相变点的位置，为排列恢复问题提供了分析工具。 |
| [^15] | [Coalitional Manipulations and Immunity of the Shapley Value.](http://arxiv.org/abs/2310.20415) | 本文研究了在群体博弈中的操纵现象，并提出了一种新的Shapley值基础，它是唯一的有效和对称的分配规则，对集体操纵具有免疫性。 |
| [^16] | [Multi-Base Station Cooperative Sensing with AI-Aided Tracking.](http://arxiv.org/abs/2310.20403) | 本文研究了一个多基站合作感知网络，在此网络中，各个基站依次进行雷达扫描并通过融合中心进行信息交换，利用卷积神经网络辅助聚类算法，能够更准确地分组并跟踪检测结果。 |
| [^17] | [Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory.](http://arxiv.org/abs/2310.20360) | 本书提供了对深度学习算法的数学介绍，包括不同的神经网络架构和优化算法，并涵盖了深度学习算法的理论方面。此外，还介绍了深度学习逼近偏微分方程的方法。希望对学生和科学家们有所帮助。 |
| [^18] | [Accelerating Generalized Linear Models by Trading off Computation for Uncertainty.](http://arxiv.org/abs/2310.20285) | 本论文提出了一种迭代方法，通过增加不确定性来降低计算量，并显著提高广义线性模型的训练速度。 |
| [^19] | [Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with Graphs for Passenger Trajectory Clustering.](http://arxiv.org/abs/2310.20224) | 本论文提出了一种新的张量狄利克雷过程多项式混合模型，利用图形结构和空间语义图对基于轨迹记录的乘客聚类进行了改进，能在一步中自动确定聚类数量，并保留了多维出行信息的分层结构。 |
| [^20] | [Calibration by Distribution Matching: Trainable Kernel Calibration Metrics.](http://arxiv.org/abs/2310.20211) | 该论文提出了基于核的校准度量方法，统一和推广了分类和回归中常见的校准形式。这些度量可以产生可微的样本估计，易于纳入经验风险最小化，并通过定制校准度量来优化决策任务。 |
| [^21] | [Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs.](http://arxiv.org/abs/2310.20145) | 本文介绍了一种新颖的robust Bayesian Optimization算法，AIRBO，它能够在任意输入不确定性下有效识别出表现一致良好的鲁棒最优解。 |
| [^22] | [Sample-Conditioned Hypothesis Stability Sharpens Information-Theoretic Generalization Bounds.](http://arxiv.org/abs/2310.20102) | 通过构建"相邻假设"矩阵和引入样本条件的假设稳定性，本文提出了新的信息论泛化保证，改进了先前信息论界限，并解决了随机凸优化问题中信息论界限的局限性。 |
| [^23] | [Bridging the Gap Between Variational Inference and Wasserstein Gradient Flows.](http://arxiv.org/abs/2310.20090) | 本文研究了消除变分推断与Wasserstein梯度流之间的差距，证明了布雷斯-瓦瑟斯坦梯度流可以重新表示为欧氏梯度流，提出了路径导数梯度估计器和蒸馏过程来拓展该方法，同时可以适用于f-散度和非高斯变分族。 |
| [^24] | [Meek Separators and Their Applications in Targeted Causal Discovery.](http://arxiv.org/abs/2310.20075) | 本论文研究了Meek分离器及其在目标因果发现中的应用。通过引入Meek分离器，我们可以设计出高效的算法来寻找小规模的分离器，从而实现对目标因果发现问题的优化。 |
| [^25] | [AdaSub: Stochastic Optimization Using Second-Order Information in Low-Dimensional Subspaces.](http://arxiv.org/abs/2310.20060) | AdaSub是一种使用低维子空间中的二阶信息进行随机优化的算法，通过选择搜索的子空间维度来管理计算开销和算法效率。初步数值结果显示，AdaSub在时间和迭代次数方面优于其他随机优化器。 |
| [^26] | [Estimating optimal PAC-Bayes bounds with Hamiltonian Monte Carlo.](http://arxiv.org/abs/2310.20053) | 本研究使用Hamiltonian Monte Carlo方法估计最优PAC-Bayes界限，研究了通过限制后验分布为因子化高斯分布在优化PAC-Bayes界限方面所失去的紧致度，并提出了三种方法来获得高概率界限。实验证明在MNIST数据集上存在显著的紧致度差距，高达5-6％。 |
| [^27] | [Scaling Riemannian Diffusion Models.](http://arxiv.org/abs/2310.20030) | 本文提出了一种改进的黎曼扩散模型，通过重新审视近似方法和利用对称空间的性质，实现了高精度计算和在高维任务上的扩展能力。 |
| [^28] | [Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning.](http://arxiv.org/abs/2310.20007) | 本文在多种情境下证明了汤普森采样在强化学习中的贝叶斯遗憾界，并通过对信息比的精确分析提出了一个基于时间不均匀强化学习问题的上界估计。同时，本文找到了各种设置中具体的界限，并讨论了这些结果是第一个其类别或改进了最先进方法的情况。 |
| [^29] | [Scaling Up Differentially Private LASSO Regularized Logistic Regression via Faster Frank-Wolfe Iterations.](http://arxiv.org/abs/2310.19978) | 本论文提出了一种通过改进Frank-Wolfe算法来训练差分隐私回归模型的方法，并在稀疏输入数据上有效。通过这种方法，可以显著减少算法的训练时间，并在实验中取得了显著的性能提升。 |
| [^30] | [Unified Enhancement of Privacy Bounds for Mixture Mechanisms via $f$-Differential Privacy.](http://arxiv.org/abs/2310.19973) | 本文通过$f$-差分隐私方法改进了洗牌模型和DP-GD中随机初始化的隐私边界，折衷函数的闭式表达式优于$(\epsilon,\delta)$-DP的结果，并且随机初始化可以增强DP-GD的隐私性。 |
| [^31] | [Posterior Sampling for Competitive RL: Function Approximation and Partial Observation.](http://arxiv.org/abs/2310.19861) | 本文研究了使用后验采样算法在竞争性强化学习中的应用。通过引入自对弈和对抗性广义艾略特系数，提出了用于探索-利用平衡的模型方法，并且成功处理了状态的部分可观测性。同时，提出了学习具有潜在部分可观测性的对抗性博弈模型的后验采样方法，并给出了低遗憾界限。 |
| [^32] | [Exact Recovery and Bregman Hard Clustering of Node-Attributed Stochastic Block Model.](http://arxiv.org/abs/2310.19854) | 该论文介绍了一种精确恢复节点属性随机块模型的聚类算法，该算法利用网络信息和节点属性信息交换，实现更可靠的网络信息需要更少可靠的属性信息的精确恢复。 |
| [^33] | [Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning.](http://arxiv.org/abs/2310.19831) | 本文提出了一种新的模型基于的贝叶斯方法，通过可解释的策略学习来理解决策，该方法具有透明度、适应部分可观测性和完全离线运行的特点。通过对阿尔茨海默病诊断问题的实验验证，展示了该方法作为审计和分析工具的潜力。 |
| [^34] | [A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed Bandits.](http://arxiv.org/abs/2310.19821) | 我们提出了一种适用于非平稳环境的自适应风险感知策略框架，通过结合各种风险度量和重启贝叶斯在线变点检测算法，解决了高波动性领域中简单奖励最大化方法的不可靠性问题。 |
| [^35] | [Hodge-Compositional Edge Gaussian Processes.](http://arxiv.org/abs/2310.19450) | 本论文提出了一种新的方法用于对边缘集合上的函数进行建模，该方法基于Hodge分解开发了适用于不同应用场景的无散度和无旋度的高斯过程，并通过组合它们来表示任意边缘函数。实验结果表明这种方法在流动数据推断中具有潜在的实际应用价值。 |
| [^36] | [Causal Q-Aggregation for CATE Model Selection.](http://arxiv.org/abs/2310.16945) | 该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率 |
| [^37] | [Canonical normalizing flows for manifold learning.](http://arxiv.org/abs/2310.12743) | 该论文介绍了一种规范化正态流方法，用于流形学习。通过可学习的可逆变换将数据嵌入到高维空间中，从而实现了在流形上计算概率密度并优化网络参数的目标。然而，当前的方法在学习到的流形表示中存在着与流形关联且退化的内在基函数的问题。 |
| [^38] | [Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior.](http://arxiv.org/abs/2310.00097) | 本文研究了稀疏变分高斯过程回归中点估计和不确定性量化的方法，通过使用布朗运动先验和特征向量引导变量，推导了频率派可信区间的理论保证和限制，并在足够多的引导变量的情况下精确定义了渐近频率派覆盖，从而推断出这个变分方法的可信区间何时保守，何时过于自信/误导。数值实验证明了这些结果的适用性，并讨论了与其他常见高斯过程先验的相关性。 |
| [^39] | [Sharpness-Aware Minimization and the Edge of Stability.](http://arxiv.org/abs/2309.12488) | 本研究通过类似的计算方法，为锐度感知最小化(SAM)，一种改进泛化性能的梯度下降变种，确定了一个稳定性边界，该边界取决于梯度的范数。 |
| [^40] | [SGMM: Stochastic Approximation to Generalized Method of Moments.](http://arxiv.org/abs/2308.13564) | 我们提出了一种新的随机广义矩方法（SGMM），用于估计和推断矩限制模型。该方法具有快速和可扩展的实时处理能力，并且能够处理大规模和在线数据集。 |
| [^41] | [Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis.](http://arxiv.org/abs/2306.16803) | 本文提出了一种新的基于模型的信用分配算法，通过量化反事实查询来测量动作对未来奖励的影响。与现有方法不同的是，我们通过测量对奖励或奖励对象表示的贡献，获得了具有更低方差的梯度估计。 |
| [^42] | [Score-based Data Assimilation.](http://arxiv.org/abs/2306.10574) | 本文介绍了基于评分的数据同化方法，通过对状态轨迹模型的训练，实现了无需依赖传统推断方法和满足高维系统与长时间跨度下进行推断。 |
| [^43] | [Stabilized Neural Differential Equations for Learning Constrained Dynamics.](http://arxiv.org/abs/2306.09739) | 本文提出了一种稳定神经微分方程（SNDEs）的方法，可以强制使用任意流形约束。该方法通过添加稳定项使约束流形成为渐进稳定的，并且在实验中表现优于现有方法。 |
| [^44] | [Identification of Nonlinear Latent Hierarchical Models.](http://arxiv.org/abs/2306.07916) | 本文提出了一种方法，可以在观测变量由因果相关的潜变量生成的非线性潜变量层次因果模型中实现因果结构和潜变量的可识别性。 |
| [^45] | [On the Robustness of Removal-Based Feature Attributions.](http://arxiv.org/abs/2306.07462) | 本文研究了Removal-Based特征归因的鲁棒性，提供了全面的理论和实验分析，并证明了所提方法的实际有效性。 |
| [^46] | [Variational Imbalanced Regression.](http://arxiv.org/abs/2306.06599) | 本文提出的变分不平衡回归（VIR）模型通过引入Probabilistic Reweighting方法，可以在不平衡回归方面表现良好，并自然产生合理的不确定性估计。 |
| [^47] | [Differentially Private Image Classification by Learning Priors from Random Processes.](http://arxiv.org/abs/2306.06076) | 本文提出了一种名为DP-RandP的方法，从随机过程中学习先验知识，并将其传递给私有数据，以改进差分隐私的图像分类，实现了新的最先进的结果，提高了CIFAR-10的精度。 |
| [^48] | [Explaining Predictive Uncertainty with Information Theoretic Shapley Values.](http://arxiv.org/abs/2306.05724) | 本文提出了一种新的方法，通过Shapley值解释不确定性预测，可以量化每个特征对个别模型输出条件熵的贡献，适用于协变量转移检测、主动学习、特征选择和活动特征价值评估等方面。 |
| [^49] | [Bayes optimal learning in high-dimensional linear regression with network side information.](http://arxiv.org/abs/2306.05679) | 本文首次研究了具有网络辅助信息的高维线性回归中的贝叶斯最优学习问题，引入了Reg-Graph模型并提出了基于AMP的迭代算法，在实验中优于现有的几种网络辅助回归方法。 |
| [^50] | [Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning.](http://arxiv.org/abs/2306.04746) | 该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。 |
| [^51] | [Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models.](http://arxiv.org/abs/2306.04675) | 系统地研究了图像生成模型的评估，发现常见的评价指标如FID等不能很好地体现扩散模型的感知真实性，建议使用SwAV特征提取器结合FID进行评估。 |
| [^52] | [Variational Gaussian Process Diffusion Processes.](http://arxiv.org/abs/2306.02066) | 本文提出一种高斯变分过程参数化方法来更好地学习具有非线性扩散过程的潜在过程，此方法采用具有连续指数族描述的算法实现凸优化，可以代替缓慢的具有固定点迭代的算法。 |
| [^53] | [Uncertainty Quantification over Graph with Conformalized Graph Neural Networks.](http://arxiv.org/abs/2305.14535) | 本文提出了一种基于符合性的图神经网络模型（CF-GNN），通过将符合性预测（CP）扩展到基于图的模型中，对GNN不确定性进行了有效估计。CF-GNN生成的预测集/区间可根据预定义的覆盖概率保证包含真实标签，并且提供了一种减少预测集大小/区间长度的拓扑意识输出校正方法。 |
| [^54] | [Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks.](http://arxiv.org/abs/2305.06986) | 本文研究了三层神经网络的特征学习能力，相比之下，它具有比两层网络更丰富的可证的特征学习能力，并提出了一个通用定理，限制了目标结构的样本复杂度和宽度，以实现低测试误差。 |
| [^55] | [Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation.](http://arxiv.org/abs/2305.06563) | 本文提出了一种基于流形正则化Tucker分解的时空交通数据填充方法，该方法利用稀疏正则化项改善了Tucker核的稀疏性，并引入流形正则化和时间约束项来优化张量的填充性能。 |
| [^56] | [When Do Neural Nets Outperform Boosted Trees on Tabular Data?.](http://arxiv.org/abs/2305.02997) | 这项研究通过对176个数据集的比较分析发现，在许多数据集中，GBDT和NN之间的性能差异可以忽略不计，或者GBDT的轻微超参数调整比选择最佳算法更重要。此外，研究人员对965个元特征进行了分析，发现GBDT在高维稀疏数据上表现更好。 |
| [^57] | [Classification of Superstatistical Features in High Dimensions.](http://arxiv.org/abs/2304.02912) | 本文利用经验风险最小化的方法，对高维超统计特征下的数据进行分类，并分析了正则化和分布尺度参数对分类的影响。 |
| [^58] | [Applications of No-Collision Transportation Maps in Manifold Learning.](http://arxiv.org/abs/2304.00199) | 本文研究了在流形学习中应用无碰撞运输图的方法，其可以比OT图更便宜地计算距离，并提供单个概率测度的平移和伸缩的等距性。 |
| [^59] | [A polar prediction model for learning to represent visual transformations.](http://arxiv.org/abs/2303.03432) | 一种新的自监督表示学习框架，利用自然视频的规律进行准确预测，并发现了在数据中的简单变换群的表示。 |
| [^60] | [The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness in ReLU Networks.](http://arxiv.org/abs/2303.01456) | 这项研究研究了ReLU网络中梯度流的隐式偏差对泛化和对抗鲁棒性的影响，发现梯度流倾向于泛化能力强但对抗性高的解决方案，并且这种偏差还导致非鲁棒性解决方案的出现。 |
| [^61] | [Data pruning and neural scaling laws: fundamental limitations of score-based algorithms.](http://arxiv.org/abs/2302.06960) | 评分数据修剪算法在高压缩区域失败，通过随机化的校准协议可以提高现有修剪算法在该区域的性能。 |
| [^62] | [Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions.](http://arxiv.org/abs/2301.11781) | 该论文研究了机器学习模型中的偶然性和认知性歧视，将其分类为数据分布中固有的歧视和模型开发过程中的决策导致的歧视。通过量化偶然性歧视的性能限制和刻画认知性歧视，揭示了公平干预的基本限制。研究还应用这种方法评估了现有的公平干预措施，并探究了在存在缺失值的数据中的公平风险。 |
| [^63] | [Sparse PCA With Multiple Components.](http://arxiv.org/abs/2209.14790) | 本研究提出了一种新的方法来解决稀疏主成分分析问题，通过将正交性条件重新表述为秩约束，并同时对稀疏性和秩约束进行优化。我们设计了紧凑的半正定松弛来提供高质量的上界，当每个主成分的个体稀疏性被指定时，我们通过额外的二阶锥不等式加强上界。 |
| [^64] | [Double logistic regression approach to biased positive-unlabeled data.](http://arxiv.org/abs/2209.07787) | 该论文提出了一种基于双逻辑回归的方法，用于处理存在偏差的正向无标记数据。通过避免假设倾向得分函数为常数，作者共同估计后验概率和倾向得分函数，并提出了两种估计方法。实验结果显示，所提出的方法与现有的基于期望最大化方案的方法相比是可比较或更优的。 |
| [^65] | [Recovery Guarantees for Distributed-OMP.](http://arxiv.org/abs/2209.07230) | 该论文研究了基于正交匹配追踪的分布式方案在高维稀疏线性回归中的应用。通过适当的假设，分布式OMP方案能够以较低的信噪比下实现线性通信复杂度，并能与更复杂的方法相竞争。 |
| [^66] | [Stronger Privacy Amplification by Shuffling for R\'enyi and Approximate Differential Privacy.](http://arxiv.org/abs/2208.04591) | 本研究在R\'enyi和近似差分隐私中通过洗牌提出了更强隐私放大的方法，并对理论和数值进行了改进和优化。 |
| [^67] | [DAMNETS: A Deep Autoregressive Model for Generating Markovian Network Time Series.](http://arxiv.org/abs/2203.15009) | DAMNETS是一种用于生成马尔可夫网络时间序列的深度自回归模型，通过在真实数据和合成数据集上的表现超过竞争方法，达到了设计灵活且可扩展的生成模型的目标。 |
| [^68] | [A general class of surrogate functions for stable and efficient reinforcement learning.](http://arxiv.org/abs/2108.05828) | 本研究提出了一个基于函数镜像上升的普适框架(FMA-PG)，构建了一系列替代函数，这些函数可以实现策略改进，并且不受策略参数化选择的影响。通过实验证实，该方法具有良好的性能和理论保证。 |
| [^69] | [Helmholtzian Eigenmap: Topological feature discovery & edge flow learning from point cloud data.](http://arxiv.org/abs/2103.07626) | 本论文提出了一种从点云数据中估计流形Helmholtzian的方法，通过加权1-Laplacian构建了图Helmholtzian作为连续算子的一致估计器，并利用Helmholtz-Hodge定理对流和向量场进行分析。通过该方法，可以对流进行平滑、预测和特征提取。 |
| [^70] | [Outlier-robust sparse/low-rank least-squares regression and robust matrix completion.](http://arxiv.org/abs/2012.06750) | 该论文研究了带异质噪声的高维最小二乘回归问题，包括稀疏和低秩最小二乘回归。研究者提出了新颖的"亚高斯"估计速率，并在不同概率下有效。此外，还提出了一种新近优的处理方法用于有噪声的鲁棒矩阵完成问题。 |
| [^71] | [Synthetic Interventions.](http://arxiv.org/abs/2006.07691) | 提出了一个称为合成干预的因果框架，能够在观察到每个单元最多两个干预措施的情况下推断每个单元对每个干预措施的预期潜在结果，具有有限样本一致性和渐近正态性。 |
| [^72] | [Revisiting Parameter Sharing in Multi-Agent Deep Reinforcement Learning.](http://arxiv.org/abs/2005.13625) | 本研究重访了多智能体深度强化学习中的参数共享方法。我们通过引入智能体指示信号实现了在不同策略网络共享参数的同时学习不同策略或任务的能力，并且证明了这些方法在异构观测和行动空间学习中可以收敛到最优策略。 |
| [^73] | [Open-set learning with augmented category by exploiting unlabeled data (Open-LACU).](http://arxiv.org/abs/2002.01368) | Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。 |
| [^74] | [Weighted bandits or: How bandits learn distorted values that are not expected.](http://arxiv.org/abs/1611.10283) | 本论文研究了带有扭曲概率的随机多臂赌博机问题，并提出了以UCB算法为基础、考虑了奖励扭曲并具有次线性后悔的算法。 |

# 详细

[^1]: 对贝叶斯优化的期望改进的意外提升

    Unexpected Improvements to Expected Improvement for Bayesian Optimization. (arXiv:2310.20708v1 [cs.LG])

    [http://arxiv.org/abs/2310.20708](http://arxiv.org/abs/2310.20708)

    提出了LogEI作为一类新的贝叶斯优化的获得函数，具有与传统的EI函数相同或近似相等的最优解，但数值上更容易进行优化。

    

    期望改进（EI）可以说是贝叶斯优化中最流行的获得函数，并且已经在很多成功的应用中得到了应用。但是，EI的性能往往被一些新方法超越。尤其是，EI及其变种在并行和多目标设置中很难进行优化，因为它们的获得值在许多区域中数值上变为零。当观测次数增加、搜索空间的维度增加或约束条件的数量增加时，这种困难通常会增加，导致性能在文献中不一致且大多数情况下亚优化。在本论文中，我们提出了LogEI，这是一类新的采样函数。与标准EI相比，这些LogEI函数的成员要么具有相同的最优解，要么具有近似相等的最优解，但数值上更容易进行优化。我们证明了数值病态在“经典”分析EI、期望超体积改进（EHVI）以及它们的...

    Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in "classic" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their
    
[^2]: 强化微调语言模型中的梯度消失问题

    Vanishing Gradients in Reinforcement Finetuning of Language Models. (arXiv:2310.20703v1 [cs.LG])

    [http://arxiv.org/abs/2310.20703](http://arxiv.org/abs/2310.20703)

    本研究发现在强化微调（RFT）中存在梯度消失的问题，当模型下奖励的标准差较小时，输入的期望梯度会消失，导致奖励最大化缓慢。初始监督微调（SFT）阶段是克服这个问题的最有希望的方法。

    

    预训练的语言模型通过强化微调（RFT）与人类偏好和下游任务对齐，即使用策略梯度算法最大化（可能是学习得到的）奖励函数。本研究发现了RFT中的一个基本的优化障碍：我们证明了当模型下的奖励标准差较小时，输入的期望梯度会消失，即使期望奖励远离最优解。通过在RFT基准和控制环境中进行实验，以及理论分析，我们证明了由于小的奖励标准差导致的梯度消失问题普遍存在且有害，导致奖励最大化极其缓慢。最后，我们探索了克服RFT中梯度消失的方法。我们发现初始监督微调（SFT）阶段是最有希望的候选方法，并且揭示了它在RFT流程中的重要性。此外，我们还表明相对较小的训练数据集的SFT阶段可以有效克服梯度消失问题。

    Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small num
    
[^3]: 使用神经场在相互作用动态系统中发现潜在场效应

    Latent Field Discovery In Interacting Dynamical Systems With Neural Fields. (arXiv:2310.20679v1 [cs.LG])

    [http://arxiv.org/abs/2310.20679](http://arxiv.org/abs/2310.20679)

    本文通过笛卡尔积和神经场提出了一种新的图网络，用于在相互作用动态系统中发现局部物体相互作用和全局场效应的潜在力场。

    

    相互作用对象的系统在其动力学中通常会受到场效应的影响，然而以往的研究常常忽略了这些效应，假设系统在真空中演化。本文着眼于发现这些场效应，并仅通过观察到的动力学来进行推断，而无需直接观测它们。我们假设存在潜在的力场，并提出使用神经场来学习它们。由于观察到的动力学是局部物体相互作用和整体场效应的综合结果，最近流行的等变网络无法应用，因为它们无法捕捉到全局信息。为了解决这个问题，我们提出将局部物体相互作用（SE(n)等变的，依赖于相对状态）与外部全局场效应（依赖于绝对状态）相分离。我们使用等变图网络对相互作用进行建模，并将其与神经场结合在一起，构建了一种融合了场效应的图网络。

    Systems of interacting objects often evolve under the influence of field effects that govern their dynamics, yet previous works have abstracted away from such effects, and assume that systems evolve in a vacuum. In this work, we focus on discovering these fields, and infer them from the observed dynamics alone, without directly observing them. We theorize the presence of latent force fields, and propose neural fields to learn them. Since the observed dynamics constitute the net effect of local object interactions and global field effects, recently popularized equivariant networks are inapplicable, as they fail to capture global information. To address this, we propose to disentangle local object interactions -- which are $\mathrm{SE}(n)$ equivariant and depend on relative states -- from external global field effects -- which depend on absolute states. We model interactions with equivariant graph networks, and combine them with neural fields in a novel graph network that integrates fiel
    
[^4]: 使用张量网络为高斯过程回归投影基函数

    Projecting basis functions with tensor networks for Gaussian process regression. (arXiv:2310.20630v1 [stat.ML])

    [http://arxiv.org/abs/2310.20630](http://arxiv.org/abs/2310.20630)

    本文提出了一种使用低秩张量网络实现高斯过程回归的方法，该方法允许在指数数量的基函数情况下进行高效计算。

    

    本文提出了一种使用张量网络对高斯过程回归进行近似的方法。GP的参数化近似使用基函数的线性组合，其中近似的准确性取决于总基函数数量 $M$。我们提出了一种能够使用指数数量基函数而不引起相应指数计算复杂性的方法。实现这一点的关键思想是使用低秩张量网络。我们首先从数据中找到一个适当的低维子空间，该子空间由低秩张量网络描述。在这个低维子空间中，我们通过求解贝叶斯推理问题来推断出模型的权重。最后，我们将得到的权重投影回原始空间进行GP预测。我们的方法的好处在于投影到一个较小的子空间：它根据给定数据适应性地修改基函数的形状，并且允许进行高效的计算。

    This paper presents a method for approximate Gaussian process (GP) regression with tensor networks (TNs). A parametric approximation of a GP uses a linear combination of basis functions, where the accuracy of the approximation depends on the total number of basis functions $M$. We develop an approach that allows us to use an exponential amount of basis functions without the corresponding exponential computational complexity. The key idea to enable this is using low-rank TNs. We first find a suitable low-dimensional subspace from the data, described by a low-rank TN. In this low-dimensional subspace, we then infer the weights of our model by solving a Bayesian inference problem. Finally, we project the resulting weights back to the original space to make GP predictions. The benefit of our approach comes from the projection to a smaller subspace: It modifies the shape of the basis functions in a way that it sees fit based on the given data, and it allows for efficient computations in the
    
[^5]: 通过对单纯形进行凸松弛解决图匹配问题

    Graph Matching via convex relaxation to the simplex. (arXiv:2310.20609v1 [stat.ML])

    [http://arxiv.org/abs/2310.20609](http://arxiv.org/abs/2310.20609)

    本文提出了一种新的图匹配方法，通过对单位单纯形进行凸松弛，并开发了高效的镜像下降方案来解决该问题。在相关高斯Wigner模型下，单纯形松弛法具有唯一解，并且能够精确恢复地面真实排列。

    

    本文针对图匹配问题进行研究，该问题包括在两个输入图之间找到最佳对齐，并在计算机视觉、网络去匿名化和蛋白质对齐等领域有许多应用。解决这个问题的常见方法是通过对NP难问题“二次分配问题”（QAP）进行凸松弛。本文引入了一种新的凸松弛方法，即对单位单纯形进行松弛，并开发了一种具有闭合迭代形式的高效镜像下降方案来解决该问题。在相关高斯Wigner模型下，我们证明了单纯形松弛法在高概率下具有唯一解。在无噪声情况下，这被证明可以精确恢复地面真实排列。此外，我们建立了一种新的输入矩阵假设条件，用于标准贪心取整方法，并且这个条件比常用的“对角线优势”条件更宽松。我们使用这个条件证明了地面真实排列的精确一步恢复。

    This paper addresses the Graph Matching problem, which consists of finding the best possible alignment between two input graphs, and has many applications in computer vision, network deanonymization and protein alignment. A common approach to tackle this problem is through convex relaxations of the NP-hard \emph{Quadratic Assignment Problem} (QAP).  Here, we introduce a new convex relaxation onto the unit simplex and develop an efficient mirror descent scheme with closed-form iterations for solving this problem. Under the correlated Gaussian Wigner model, we show that the simplex relaxation admits a unique solution with high probability. In the noiseless case, this is shown to imply exact recovery of the ground truth permutation. Additionally, we establish a novel sufficiency condition for the input matrix in standard greedy rounding methods, which is less restrictive than the commonly used `diagonal dominance' condition. We use this condition to show exact one-step recovery of the gro
    
[^6]: 高斯过程的随机梯度下降的正确实现

    Stochastic Gradient Descent for Gaussian Processes Done Right. (arXiv:2310.20581v1 [cs.LG])

    [http://arxiv.org/abs/2310.20581](http://arxiv.org/abs/2310.20581)

    本文研究了使用随机梯度下降方法优化高斯过程回归问题，并引入了一种特定的随机对偶梯度下降算法，该方法在标准回归基准和贝叶斯优化任务上表现出很高的竞争力。

    

    本文研究了使用平方损失函数的高斯过程回归的优化问题。目前，解决这个问题的最常见方法是应用精确求解器，比如共轭梯度下降，要么直接应用，要么应用于问题的降阶版本。最近，在深度学习的成功推动下，随机梯度下降作为一种替代方法获得了广泛关注。本文展示了当正确使用时（我们指的是利用优化和核函数领域的特定见解），这种方法是非常有效的。因此，我们引入了一种特定的随机对偶梯度下降算法，可以使用任何深度学习框架的几行代码实现。我们通过消融实验解释了我们的设计决策的优势，并表明新方法具有很高的竞争力。我们对标准回归基准和贝叶斯优化任务进行评估，证明了我们的方法的优越性。

    We study the optimisation problem associated with Gaussian process regression using squared loss. The most common approach to this problem is to apply an exact solver, such as conjugate gradient descent, either directly, or to a reduced-order version of the problem. Recently, driven by successes in deep learning, stochastic gradient descent has gained traction as an alternative. In this paper, we show that when done right$\unicode{x2014}$by which we mean using specific insights from the optimisation and kernel communities$\unicode{x2014}$this approach is highly effective. We thus introduce a particular stochastic dual gradient descent algorithm, that may be implemented with a few lines of code using any deep learning framework. We explain our design decisions by illustrating their advantage against alternatives with ablation studies and show that the new method is highly competitive. Our evaluations on standard regression benchmarks and a Bayesian optimisation task set our approach apa
    
[^7]: 初始化很重要：超参数化神经网络的隐私-效用分析

    Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks. (arXiv:2310.20579v1 [stat.ML])

    [http://arxiv.org/abs/2310.20579](http://arxiv.org/abs/2310.20579)

    通过分析研究了超参数化神经网络的初始化对于隐私保护的影响，发现隐私界的改善与深度和初始化分布的关系密切相关。

    

    我们通过分析研究了随机机器学习算法中模型的超参数化对训练数据信息泄漏的影响。具体而言，我们证明了模型分布在最坏情况下邻近数据集间的KL散度的隐私界，并探索了它与完全连接神经网络的初始化、宽度和深度的关系。我们发现这个KL隐私界主要由训练过程中模型参数相对于预期梯度范数决定。值得注意的是，在线性化网络的特殊设置下，我们的分析表明梯度范数的平方（因此隐私损失的递增）与初始化分布的每层方差直接相关。通过使用这个分析，我们证明了在某些初始化（LeCun和Xavier）下，随着深度的增加，隐私界得到了改善，而在其他初始化（He和NTK）下，随着深度的增加，隐私界得到了恶化。我们的工作可以帮助论证初始化对于神经网络隐私保护的重要性。

    We analytically investigate how over-parameterization of models in randomized machine learning algorithms impacts the information leakage about their training data. Specifically, we prove a privacy bound for the KL divergence between model distributions on worst-case neighboring datasets, and explore its dependence on the initialization, width, and depth of fully connected neural networks. We find that this KL privacy bound is largely determined by the expected squared gradient norm relative to model parameters during training. Notably, for the special setting of linearized network, our analysis indicates that the squared gradient norm (and therefore the escalation of privacy loss) is tied directly to the per-layer variance of the initialization distribution. By using this analysis, we demonstrate that privacy bound improves with increasing depth under certain initializations (LeCun and Xavier), while degrades with increasing depth under other initializations (He and NTK). Our work rev
    
[^8]: 多任务学习凸组合预测模型

    Multi-task learning of convex combinations of forecasting models. (arXiv:2310.20545v1 [cs.LG])

    [http://arxiv.org/abs/2310.20545](http://arxiv.org/abs/2310.20545)

    本文提出了一种多任务学习方法，通过深度神经网络同时解决了预测模型选择和凸组合权重学习的问题。通过回归分支学习权重和分类分支选择具有多样性的预测方法，提高了基于特征的预测的精确度。

    

    预测组合涉及使用多个预测来创建单一、更精确的预测。最近，基于特征的预测已被用于选择最合适的预测模型或学习它们的凸组合权重。在本文中，我们提出了一种同时解决这两个问题的多任务学习方法。该方法通过深度神经网络实现，其中包括两个分支：回归分支通过最小化组合预测误差来学习各种预测方法的权重，分类分支则重点选择多样性的预测方法。为了为分类任务生成训练标签，我们引入了一种优化驱动的方法，用于确定给定时间序列的最合适的方法。所提出的方法揭示了基于特征的预测中多样性的重要作用，并凸显了模型组合和选择之间的相互作用。

    Forecast combination involves using multiple forecasts to create a single, more accurate prediction. Recently, feature-based forecasting has been employed to either select the most appropriate forecasting models or to learn the weights of their convex combination. In this paper, we present a multi-task learning methodology that simultaneously addresses both problems. This approach is implemented through a deep neural network with two branches: the regression branch, which learns the weights of various forecasting methods by minimizing the error of combined forecasts, and the classification branch, which selects forecasting methods with an emphasis on their diversity. To generate training labels for the classification task, we introduce an optimization-driven approach that identifies the most appropriate methods for a given time series. The proposed approach elicits the essential role of diversity in feature-based forecasting and highlights the interplay between model combination and mo
    
[^9]: 从多元函数数据中进行因果发现的定向循环图

    Directed Cyclic Graph for Causal Discovery from Multivariate Functional Data. (arXiv:2310.20537v1 [stat.ME])

    [http://arxiv.org/abs/2310.20537](http://arxiv.org/abs/2310.20537)

    本文提出了一个功能线性结构方程模型，用于从多元函数数据中进行因果发现。模型通过低维因果嵌入空间将多元函数数据中的所有相关因果信息保留下来。通过模拟研究，证明了该模型在因果可辨识性和因果图估计方面具有优势。

    

    最近，使用多元函数数据进行因果关系发现引起了相当大的关注。在本文中，我们介绍了一个功能线性结构方程模型，用于在涉及多元函数的底层图中进行因果结构学习，该图可能具有循环。为了增强解释性，我们的模型涉及一个低维因果嵌入空间，以便将多元函数数据中的所有相关因果信息保留在这个较低维的子空间中。我们证明了所提出的模型在因果发现文献中常常做出的标准假设下具有因果可辨识性。为了进行我们模型的推理，我们开发了一个完全贝叶斯框架，并通过后验摘要来量化先验规范和不确定性。通过广泛的模拟研究，我们展示了我们方法在因果图估计方面相对于现有方法的卓越性能。

    Discovering causal relationship using multivariate functional data has received a significant amount of attention very recently. In this article, we introduce a functional linear structural equation model for causal structure learning when the underlying graph involving the multivariate functions may have cycles. To enhance interpretability, our model involves a low-dimensional causal embedded space such that all the relevant causal information in the multivariate functional data is preserved in this lower-dimensional subspace. We prove that the proposed model is causally identifiable under standard assumptions that are often made in the causal discovery literature. To carry out inference of our model, we develop a fully Bayesian framework with suitable prior specifications and uncertainty quantification through posterior summaries. We illustrate the superior performance of our method over existing methods in terms of causal graph estimation through extensive simulation studies. We als
    
[^10]: 具有统计保证的参数公平性

    Parametric Fairness with Statistical Guarantees. (arXiv:2310.20508v1 [stat.ML])

    [http://arxiv.org/abs/2310.20508](http://arxiv.org/abs/2310.20508)

    该论文研究了具有统计保证的参数公平性问题，提出了一种新的指标来解决公平性中的交叉问题，并开发了一种参数化方法来高效解决实际挑战。

    

    由于对机器学习模型中偏见的社会和监管关注，算法公平性日益受到重视。常见的分类公平性指标如均衡几率和人口平等以及回归公平性指标被广泛使用，并且围绕这些指标开发了许多计算优势的后处理方法。然而，这些指标通常限制用户融入领域知识。尽管满足传统的公平标准，但它们可能掩盖与交叉公平性相关的问题，甚至在结果公平解中复制不希望的组内偏见。为了避免这种狭隘的视角，我们将人口平等的概念扩展到在预测中结合分布特性，允许专家知识用于公平解决方案。我们通过一个工资的实际示例说明了这个新指标的使用，并且开发了一种参数化方法，高效地解决诸如限制等实际挑战。

    Algorithmic fairness has gained prominence due to societal and regulatory concerns about biases in Machine Learning models. Common group fairness metrics like Equalized Odds for classification or Demographic Parity for both classification and regression are widely used and a host of computationally advantageous post-processing methods have been developed around them. However, these metrics often limit users from incorporating domain knowledge. Despite meeting traditional fairness criteria, they can obscure issues related to intersectional fairness and even replicate unwanted intra-group biases in the resulting fair solution. To avoid this narrow perspective, we extend the concept of Demographic Parity to incorporate distributional properties in the predictions, allowing expert knowledge to be used in the fair solution. We illustrate the use of this new metric through a practical example of wages, and develop a parametric method that efficiently addresses practical challenges like limit
    
[^11]: 通过张量网络生成连续数据的生成学习

    Generative Learning of Continuous Data by Tensor Networks. (arXiv:2310.20498v1 [cs.LG])

    [http://arxiv.org/abs/2310.20498](http://arxiv.org/abs/2310.20498)

    张量网络生成模型一般适用于二进制或类别数据，这篇论文介绍了一种新型张量网络生成模型，它可以用于学习连续数据分布，并展示了该模型在合成和真实数据集上的性能表现。

    

    张量网络除了用于建模多体量子系统外，还成为解决机器学习问题的一类有前景的模型，尤其是在无监督生成学习中。然而，以量子启发式为特点的张量网络生成模型之前主要局限于二进制或类别数据，限制了它们在现实世界建模问题中的效用。我们通过引入一种能够学习包含连续随机变量的分布的新型张量网络生成模型，克服了这一局限。我们首先在矩阵积态的设置下开发了我们的方法，证明了这个模型族能够以任意精度逼近任何相对平滑的概率密度函数的一般表达性定理。然后，我们在几个合成和真实世界数据集上评估了这个模型的性能，发现该模型具有较好的表现。

    Beyond their origin in modeling many-body quantum systems, tensor networks have emerged as a promising class of models for solving machine learning problems, notably in unsupervised generative learning. While possessing many desirable features arising from their quantum-inspired nature, tensor network generative models have previously been largely restricted to binary or categorical data, limiting their utility in real-world modeling problems. We overcome this by introducing a new family of tensor network generative models for continuous data, which are capable of learning from distributions containing continuous random variables. We develop our method in the setting of matrix product states, first deriving a universal expressivity theorem proving the ability of this model family to approximate any reasonably smooth probability density function with arbitrary precision. We then benchmark the performance of this model on several synthetic and real-world datasets, finding that the model 
    
[^12]: AsGrad: 异步-SGD算法的尖锐统一分析

    AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms. (arXiv:2310.20452v1 [cs.LG])

    [http://arxiv.org/abs/2310.20452](http://arxiv.org/abs/2310.20452)

    我们提出了一个统一的收敛理论，分析了异步-SGD算法在异构设置下的性能，这对于提高算法性能和收敛速度具有重要意义。

    

    我们分析了异步类型的分布式SGD算法在异构设置下的性能，其中每个工作节点都具有自己的计算和通信速度，以及数据分布。在这些算法中，工作节点根据其局部数据在某个历史迭代时计算可能过期和随机的梯度，然后将这些梯度返回给服务器，而不与其他工作节点同步。我们提出了一个非凸平滑函数的异构收敛理论。所提出的分析为纯异步SGD及其各种改进提供了收敛性。此外，我们的理论解释了影响收敛速度的因素以及可以采取哪些方法来提高异步算法的性能。特别地，我们介绍了一种基于节点重新排序的新型异步方法。作为我们分析的副产品，我们还展示了梯度型算法（例如随机重新排序的SGD和一次随机排序）

    We analyze asynchronous-type algorithms for distributed SGD in the heterogeneous setting, where each worker has its own computation and communication speeds, as well as data distribution. In these algorithms, workers compute possibly stale and stochastic gradients associated with their local data at some iteration back in history and then return those gradients to the server without synchronizing with other workers. We present a unified convergence theory for non-convex smooth functions in the heterogeneous regime. The proposed analysis provides convergence for pure asynchronous SGD and its various modifications. Moreover, our theory explains what affects the convergence rate and what can be done to improve the performance of asynchronous algorithms. In particular, we introduce a novel asynchronous method based on worker shuffling. As a by-product of our analysis, we also demonstrate convergence guarantees for gradient-type algorithms such as SGD with random reshuffling and shuffle-onc
    
[^13]: 使用先验数据拟合神经网络进行高效贝叶斯学习曲线外推

    Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks. (arXiv:2310.20447v1 [cs.LG])

    [http://arxiv.org/abs/2310.20447](http://arxiv.org/abs/2310.20447)

    本文提出了一种使用先验数据拟合神经网络进行高效贝叶斯学习曲线外推的方法，该方法相比现有方法更准确且速度更快。

    

    学习曲线外推旨在基于早期训练阶段的表现来预测模型在后期训练中的性能。本文认为，虽然学习曲线外推中的固有不确定性需要采用贝叶斯方法，但现有方法要么过于限制，要么计算成本过高。我们首次在这个领域应用了先验数据拟合神经网络（PFN）。PFN是一个在先验数据上进行预训练的转换器，通过一次前向传递进行近似贝叶斯推断。我们提出了LC-PFN，一个通过MCMC在先前文献中提出的参数化先验生成的1000万条人造右截尾学习曲线进行训练的PFN。我们证明LC-PFN比MCMC更准确地近似后验预测分布，并且速度快了超过10,000倍。我们还展示了相同的LC-PFN在外推总共20,000条真实学习曲线时具有竞争性能。

    Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs. In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real 
    
[^14]: 洗牌回归问题的相变现象研究

    The Phase Transition Phenomenon of Shuffled Regression. (arXiv:2310.20438v1 [stat.ML])

    [http://arxiv.org/abs/2310.20438](http://arxiv.org/abs/2310.20438)

    本研究研究了洗牌回归问题的相变现象，并利用信息传递技术确定了相变点的位置，为排列恢复问题提供了分析工具。

    

    本研究探讨了洗牌（排列）回归问题中固有的相变现象，在数据库、隐私、数据分析等领域有广泛的应用。在本研究中，我们旨在利用信息传递（MP）技术准确地确定相变点的位置。在分析中，我们首先将排列恢复问题转化为一个概率图模型。然后，我们利用信息传递算法的分析工具，并推导出一个方程来跟踪信息传递算法的收敛性。通过将这个方程与分支随机行走过程相联系，我们能够描述信噪比（SNR）对排列恢复的影响。根据信号是否已知，我们分别研究了神谕情况和非神谕情况。确定相变区域的瓶颈在于推导相应临界点的闭合公式。

    We study the phase transition phenomenon inherent in the shuffled (permuted) regression problem, which has found numerous applications in databases, privacy, data analysis, etc. In this study, we aim to precisely identify the locations of the phase transition points by leveraging techniques from message passing (MP). In our analysis, we first transform the permutation recovery problem into a probabilistic graphical model. We then leverage the analytical tools rooted in the message passing (MP) algorithm and derive an equation to track the convergence of the MP algorithm. By linking this equation to the branching random walk process, we are able to characterize the impact of the signal-to-noise-ratio ($\snr$) on the permutation recovery. Depending on whether the signal is given or not, we separately investigate the oracle case and the non-oracle case. The bottleneck in identifying the phase transition regimes lies in deriving closed-form formulas for the corresponding critical points, b
    
[^15]: 群体操纵与Shapley值的免疫性

    Coalitional Manipulations and Immunity of the Shapley Value. (arXiv:2310.20415v1 [econ.TH])

    [http://arxiv.org/abs/2310.20415](http://arxiv.org/abs/2310.20415)

    本文研究了在群体博弈中的操纵现象，并提出了一种新的Shapley值基础，它是唯一的有效和对称的分配规则，对集体操纵具有免疫性。

    

    我们考虑在群体博弈的背景下的操纵，其中一个联盟旨在增加其成员的总支付。如果一种分配规则对集体操纵免疫，那么没有任何联盟可以通过在其子联盟的层级上重新分配价值来获益（具有重新分配证明性），而且如果在其他条件不变的情况下，没有任何联盟可以从较低的价值中受益（具有弱集体单调性）。将Shapley在原始特征的可加性替换为这些要求可以得到Shapley值的新基础，即它是唯一的有效和对称的分配规则，对空玩家不予任何奖励，并且对集体操纵免疫。我们进一步发现，对于有效的分配规则，重新分配证明性等效于有约束的边际性，这是Young的边际性公理的一个较弱变体。我们的第二个特征改进了Young的特征，弱化了边际性内在的独立性要求。

    We consider manipulations in the context of coalitional games, where a coalition aims to increase the total payoff of its members. An allocation rule is immune to coalitional manipulation if no coalition can benefit from internal reallocation of worth on the level of its subcoalitions (reallocation-proofness), and if no coalition benefits from a lower worth while all else remains the same (weak coalitional monotonicity). Replacing additivity in Shapley's original characterization by these requirements yields a new foundation of the Shapley value, i.e., it is the unique efficient and symmetric allocation rule that awards nothing to a null player and is immune to coalitional manipulations. We further find that for efficient allocation rules, reallocation-proofness is equivalent to constrained marginality, a weaker variant of Young's marginality axiom. Our second characterization improves upon Young's characterization by weakening the independence requirement intrinsic to marginality.
    
[^16]: 多基站合作感知与AI辅助跟踪

    Multi-Base Station Cooperative Sensing with AI-Aided Tracking. (arXiv:2310.20403v1 [eess.SP])

    [http://arxiv.org/abs/2310.20403](http://arxiv.org/abs/2310.20403)

    本文研究了一个多基站合作感知网络，在此网络中，各个基站依次进行雷达扫描并通过融合中心进行信息交换，利用卷积神经网络辅助聚类算法，能够更准确地分组并跟踪检测结果。

    

    本文研究了一个由多个基站组成的联合感知和通信（JSC）网络的性能，这些基站通过一个融合中心（FC）合作，交换有关感知环境的信息，同时与一组用户设备（UEs）建立通信链路。网络中的每个基站都作为一个单兵雷达系统运行，能够对监测区域进行全面扫描，并生成提供关于一组异构物体位置的距离-角度图。获取到的地图随后在FC中进行融合。然后，采用卷积神经网络（CNN）来推断目标的类别，例如行人或车辆，并且这些信息被自适应聚类算法利用，从而更有效地将来自同一目标的检测结果进行分组。最后，采用了两种多目标跟踪算法，即概率假设密度（PHD）滤波器和多伯努利混合滤波算法。

    In this work, we investigate the performance of a joint sensing and communication (JSC) network consisting of multiple base stations (BSs) that cooperate through a fusion center (FC) to exchange information about the sensed environment while concurrently establishing communication links with a set of user equipments (UEs). Each BS within the network operates as a monostatic radar system, enabling comprehensive scanning of the monitored area and generating range-angle maps that provide information regarding the position of a group of heterogeneous objects. The acquired maps are subsequently fused in the FC. Then, a convolutional neural network (CNN) is employed to infer the category of the targets, e.g., pedestrians or vehicles, and such information is exploited by an adaptive clustering algorithm to group the detections originating from the same target more effectively. Finally, two multi-target tracking algorithms, the probability hypothesis density (PHD) filter and multi-Bernoulli mi
    
[^17]: 深度学习的数学介绍：方法、实现和理论

    Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory. (arXiv:2310.20360v1 [cs.LG])

    [http://arxiv.org/abs/2310.20360](http://arxiv.org/abs/2310.20360)

    本书提供了对深度学习算法的数学介绍，包括不同的神经网络架构和优化算法，并涵盖了深度学习算法的理论方面。此外，还介绍了深度学习逼近偏微分方程的方法。希望对学生和科学家们有所帮助。

    

    本书旨在介绍深度学习算法的主题。我们详细介绍了深度学习算法的基本组成部分，包括不同的人工神经网络架构（如全连接前馈神经网络、卷积神经网络、循环神经网络、残差神经网络和带有批归一化的神经网络）以及不同的优化算法（如基本的随机梯度下降法、加速方法和自适应方法）。我们还涵盖了深度学习算法的几个理论方面，如人工神经网络的逼近能力（包括神经网络的微积分）、优化理论（包括Kurdyka-Lojasiewicz不等式）和泛化误差。在本书的最后一部分，我们还回顾了一些用于偏微分方程的深度学习逼近方法，包括物理信息神经网络（PINNs）和深度Galerkin方法。希望本书能对学生和科学家们有所帮助。

    This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet 
    
[^18]: 通过以计算为代价加速广义线性模型

    Accelerating Generalized Linear Models by Trading off Computation for Uncertainty. (arXiv:2310.20285v1 [cs.LG])

    [http://arxiv.org/abs/2310.20285](http://arxiv.org/abs/2310.20285)

    本论文提出了一种迭代方法，通过增加不确定性来降低计算量，并显著提高广义线性模型的训练速度。

    

    贝叶斯广义线性模型（GLMs）定义了一个灵活的概率框架，用于建模分类、有序和连续数据，并且在实践中被广泛使用。然而，对于大型数据集，GLMs的精确推断代价太高，因此需要在实践中进行近似。造成的近似误差对模型的可靠性产生不利影响，并且没有被考虑在预测的不确定性中。在这项工作中，我们引入了一系列迭代方法，明确地对这个误差建模。它们非常适合并行计算硬件，有效地回收计算并压缩信息，以减少GLMs的时间和内存需求。正如我们在一个实际的大型分类问题上展示的那样，我们的方法通过明确地将减少计算与增加不确定性进行权衡来显著加速训练。

    Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in GLMs is prohibitively expensive for large datasets, thus requiring approximations in practice. The resulting approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. In this work, we introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for GLMs. As we demonstrate on a realistically large classification problem, our method significantly accelerates training by explicitly trading off reduced computation for increased uncertainty.
    
[^19]: 选择一个表：基于图的张量狄利克雷过程多项式混合模型用于乘客轨迹聚类

    Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with Graphs for Passenger Trajectory Clustering. (arXiv:2310.20224v1 [stat.ML])

    [http://arxiv.org/abs/2310.20224](http://arxiv.org/abs/2310.20224)

    本论文提出了一种新的张量狄利克雷过程多项式混合模型，利用图形结构和空间语义图对基于轨迹记录的乘客聚类进行了改进，能在一步中自动确定聚类数量，并保留了多维出行信息的分层结构。

    

    基于轨迹记录的乘客聚类对于交通运营商至关重要。然而，现有方法由于乘客出行信息的分层结构，包括每个乘客内部的多次出行以及每次出行的多维信息，无法轻松地聚类乘客。此外，现有方法依赖于准确指定聚类数量的起始值。最后，现有方法未考虑空间语义图，如地理邻近性和位置间的功能相似性。在本文中，我们提出了一种新颖的基于图的张量狄利克雷过程多项式混合模型，它能够保留多维出行信息的分层结构，并能以统一的一步方式对其进行聚类，具有自动确定聚类数量的能力。空间图被用于社区检测以连接语义邻居。我们进一步提出了张量版本的Coll...

    Passenger clustering based on trajectory records is essential for transportation operators. However, existing methods cannot easily cluster the passengers due to the hierarchical structure of the passenger trip information, including multiple trips within each passenger and multi-dimensional information about each trip. Furthermore, existing approaches rely on an accurate specification of the clustering number to start. Finally, existing methods do not consider spatial semantic graphs such as geographical proximity and functional similarity between the locations. In this paper, we propose a novel tensor Dirichlet Process Multinomial Mixture model with graphs, which can preserve the hierarchical structure of the multi-dimensional trip information and cluster them in a unified one-step manner with the ability to determine the number of clusters automatically. The spatial graphs are utilized in community detection to link the semantic neighbors. We further propose a tensor version of Coll
    
[^20]: 分布匹配校准：可训练的核校准度量

    Calibration by Distribution Matching: Trainable Kernel Calibration Metrics. (arXiv:2310.20211v1 [cs.LG])

    [http://arxiv.org/abs/2310.20211](http://arxiv.org/abs/2310.20211)

    该论文提出了基于核的校准度量方法，统一和推广了分类和回归中常见的校准形式。这些度量可以产生可微的样本估计，易于纳入经验风险最小化，并通过定制校准度量来优化决策任务。

    

    校准确保概率预测能够有效地捕捉不确定性，要求预测概率与经验频率相吻合。然而，许多现有的校准方法专门用于事后再校准，可能会恶化预测的尖锐性。基于将校准视为分布匹配任务的洞察，我们引入了基于核的校准度量，统一和推广了分类和回归中常见的校准形式。这些度量可以产生可微的样本估计，可以很容易地将校准目标纳入经验风险最小化中。此外，我们提供了直观的机制来定制决策任务的校准度量，并强制准确的损失估计和无遗憾决策。我们的实证评估表明，使用这些度量作为正则化项可以提高在一系列回归和分类任务中的校准性、尖锐性和决策性能。

    Calibration ensures that probabilistic forecasts meaningfully capture uncertainty by requiring that predicted probabilities align with empirical frequencies. However, many existing calibration methods are specialized for post-hoc recalibration, which can worsen the sharpness of forecasts. Drawing on the insight that calibration can be viewed as a distribution matching task, we introduce kernel-based calibration metrics that unify and generalize popular forms of calibration for both classification and regression. These metrics admit differentiable sample estimates, making it easy to incorporate a calibration objective into empirical risk minimization. Furthermore, we provide intuitive mechanisms to tailor calibration metrics to a decision task, and enforce accurate loss estimation and no regret decisions. Our empirical evaluation demonstrates that employing these metrics as regularizers enhances calibration, sharpness, and decision-making across a range of regression and classification 
    
[^21]: 高效robust Bayesian Optimization对于任意不确定输入的应用

    Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs. (arXiv:2310.20145v1 [cs.LG])

    [http://arxiv.org/abs/2310.20145](http://arxiv.org/abs/2310.20145)

    本文介绍了一种新颖的robust Bayesian Optimization算法，AIRBO，它能够在任意输入不确定性下有效识别出表现一致良好的鲁棒最优解。

    

    Bayesian Optimization (BO) 是一种广泛应用于各种应用中的高效优化算法。在一些具有挑战性的BO任务中，由于优化过程中的不可避免的随机性，如加工误差、执行噪声或上下文变异，输入不确定性会出现。这种不确定性会使输入在评估之前偏离预期值，导致最终结果的性能波动较大。在本文中，我们引入了一种新颖的robust Bayesian Optimization算法，AIRBO，它能有效地识别在任意输入不确定性下表现一致良好的鲁棒最优解。我们的方法通过使用最大均值差(MMD)赋能高斯过程，直接建模任意分布的不确定输入，并通过Nystrom逼近加速后验推断。我们在MMD估计误差下建立了严格的理论遗憾界，并在合成函数上进行了广泛的实验。

    Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in the final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic function
    
[^22]: 样本条件的假设稳定性提升了信息论的泛化界限

    Sample-Conditioned Hypothesis Stability Sharpens Information-Theoretic Generalization Bounds. (arXiv:2310.20102v1 [stat.ML])

    [http://arxiv.org/abs/2310.20102](http://arxiv.org/abs/2310.20102)

    通过构建"相邻假设"矩阵和引入样本条件的假设稳定性，本文提出了新的信息论泛化保证，改进了先前信息论界限，并解决了随机凸优化问题中信息论界限的局限性。

    

    我们通过一种新的"相邻假设"矩阵的构造和一种新的稳定性概念——样本条件的假设稳定性（SCH稳定性），提出了新的信息论泛化保证。我们的方法提供了比先前信息论界限更准确的界限，在各种学习场景中有所改善。值得注意的是，这些界限解决了最近Haghifam等人在随机凸优化（SCO）问题上的研究中存在的信息论界限的局限性。

    We present new information-theoretic generalization guarantees through the a novel construction of the "neighboring-hypothesis" matrix and a new family of stability notions termed sample-conditioned hypothesis (SCH) stability. Our approach yields sharper bounds that improve upon previous information-theoretic bounds in various learning scenarios. Notably, these bounds address the limitations of existing information-theoretic bounds in the context of stochastic convex optimization (SCO) problems, as explored in the recent work by Haghifam et al. (2023).
    
[^23]: 消除变分推断与Wasserstein梯度流之间的鸿沟

    Bridging the Gap Between Variational Inference and Wasserstein Gradient Flows. (arXiv:2310.20090v1 [stat.ML])

    [http://arxiv.org/abs/2310.20090](http://arxiv.org/abs/2310.20090)

    本文研究了消除变分推断与Wasserstein梯度流之间的差距，证明了布雷斯-瓦瑟斯坦梯度流可以重新表示为欧氏梯度流，提出了路径导数梯度估计器和蒸馏过程来拓展该方法，同时可以适用于f-散度和非高斯变分族。

    

    变分推断是一种通过在变分族参数空间内进行优化来近似目标分布的技术。而Wasserstein梯度流描述了在概率测度的空间内进行优化，其中不一定存在参数密度函数。在本文中，我们消除了这两种方法之间的差距。我们证明，在一定条件下，布雷斯-瓦瑟斯坦梯度流可以重新表示为欧氏梯度流，其前向欧拉方案是标准的黑盒变分推断算法。具体而言，梯度流的向量场通过路径导数梯度估计器生成。我们还提供了一个关于路径导数梯度的替代视角，将其框架化为对Wasserstein梯度流的蒸馏过程。蒸馏可以扩展到包含f-散度和非高斯变分族。这种扩展产生了一个新的梯度估计器

    Variational inference is a technique that approximates a target distribution by optimizing within the parameter space of variational families. On the other hand, Wasserstein gradient flows describe optimization within the space of probability measures where they do not necessarily admit a parametric density function. In this paper, we bridge the gap between these two methods. We demonstrate that, under certain conditions, the Bures-Wasserstein gradient flow can be recast as the Euclidean gradient flow where its forward Euler scheme is the standard black-box variational inference algorithm. Specifically, the vector field of the gradient flow is generated via the path-derivative gradient estimator. We also offer an alternative perspective on the path-derivative gradient, framing it as a distillation procedure to the Wasserstein gradient flow. Distillations can be extended to encompass $f$-divergences and non-Gaussian variational families. This extension yields a new gradient estimator fo
    
[^24]: Meek分离器及其在目标因果发现中的应用

    Meek Separators and Their Applications in Targeted Causal Discovery. (arXiv:2310.20075v1 [cs.LG])

    [http://arxiv.org/abs/2310.20075](http://arxiv.org/abs/2310.20075)

    本论文研究了Meek分离器及其在目标因果发现中的应用。通过引入Meek分离器，我们可以设计出高效的算法来寻找小规模的分离器，从而实现对目标因果发现问题的优化。

    

    从干预数据中学习因果结构是一个具有广泛应用的基本问题。尽管许多之前的工作都集中于恢复整个因果图，但实际上存在一些场景，仅学习因果图的部分即可满足需求。这被称为“目标因果发现”。在我们的工作中，我们关注两个这样的问题：子集搜索和因果匹配。我们的目标是在这两种情况下尽量减少干预的次数。为此，我们引入了Meek分离器，它是一个子集，在干预时将剩余的未定向边分解为较小的连通分量。然后，我们提出了一种高效的算法来寻找小规模的Meek分离器。这样的过程有助于设计各种基于分而治之的方法。特别地，我们提出了两个随机算法，分别对子集搜索和因果匹配实现对数近似。我们的结果表明，

    Learning causal structures from interventional data is a fundamental problem with broad applications across various fields. While many previous works have focused on recovering the entire causal graph, in practice, there are scenarios where learning only part of the causal graph suffices. This is called $targeted$ causal discovery. In our work, we focus on two such well-motivated problems: subset search and causal matching. We aim to minimize the number of interventions in both cases.  Towards this, we introduce the $Meek~separator$, which is a subset of vertices that, when intervened, decomposes the remaining unoriented edges into smaller connected components. We then present an efficient algorithm to find Meek separators that are of small sizes. Such a procedure is helpful in designing various divide-and-conquer-based approaches. In particular, we propose two randomized algorithms that achieve logarithmic approximation for subset search and causal matching, respectively. Our results 
    
[^25]: AdaSub：使用低维子空间中的二阶信息进行随机优化

    AdaSub: Stochastic Optimization Using Second-Order Information in Low-Dimensional Subspaces. (arXiv:2310.20060v1 [math.OC])

    [http://arxiv.org/abs/2310.20060](http://arxiv.org/abs/2310.20060)

    AdaSub是一种使用低维子空间中的二阶信息进行随机优化的算法，通过选择搜索的子空间维度来管理计算开销和算法效率。初步数值结果显示，AdaSub在时间和迭代次数方面优于其他随机优化器。

    

    我们介绍了AdaSub，一种基于低维自适应定义的二阶信息的随机优化算法。与一阶方法相比，二阶方法具有更好的收敛特性，但在每次迭代中计算Hessian矩阵会导致过高的计算开销，使其不实用。为解决这个问题，我们的方法通过选择搜索的子空间维度来管理计算开销和算法效率。我们的代码在GitHub上免费提供，我们的初步数值结果表明，AdaSub在达到给定精度所需的时间和迭代次数方面超过了流行的随机优化器。

    We introduce AdaSub, a stochastic optimization algorithm that computes a search direction based on second-order information in a low-dimensional subspace that is defined adaptively based on available current and past information. Compared to first-order methods, second-order methods exhibit better convergence characteristics, but the need to compute the Hessian matrix at each iteration results in excessive computational expenses, making them impractical. To address this issue, our approach enables the management of computational expenses and algorithm efficiency by enabling the selection of the subspace dimension for the search. Our code is freely available on GitHub, and our preliminary numerical results demonstrate that AdaSub surpasses popular stochastic optimizers in terms of time and number of iterations required to reach a given accuracy.
    
[^26]: 使用Hamiltonian Monte Carlo方法估计最优PAC-Bayes界限

    Estimating optimal PAC-Bayes bounds with Hamiltonian Monte Carlo. (arXiv:2310.20053v1 [stat.ML])

    [http://arxiv.org/abs/2310.20053](http://arxiv.org/abs/2310.20053)

    本研究使用Hamiltonian Monte Carlo方法估计最优PAC-Bayes界限，研究了通过限制后验分布为因子化高斯分布在优化PAC-Bayes界限方面所失去的紧致度，并提出了三种方法来获得高概率界限。实验证明在MNIST数据集上存在显著的紧致度差距，高达5-6％。

    

    PAC-Bayes文献中一个重要但未被充分研究的问题是在优化PAC-Bayes界限时，通过限制后验分布为因子化高斯分布，我们失去了多少紧致度。我们通过估计独立于数据的PAC-Bayes界限来调查此问题，使用最优的后验与使用MFVI得到的界限进行比较。具体而言，我们采用Hamiltonian Monte Carlo从最优的Gibbs后验中进行采样，用热力学积分估计其与先验的KL散度，并提出了三种在不同假设下获得高概率界限的方法。我们在MNIST数据集上的实验揭示了显著的紧致度差距，在某些情况下可达5-6％。

    An important yet underexplored question in the PAC-Bayes literature is how much tightness we lose by restricting the posterior family to factorized Gaussian distributions when optimizing a PAC-Bayes bound. We investigate this issue by estimating data-independent PAC-Bayes bounds using the optimal posteriors, comparing them to bounds obtained using MFVI. Concretely, we (1) sample from the optimal Gibbs posterior using Hamiltonian Monte Carlo, (2) estimate its KL divergence from the prior with thermodynamic integration, and (3) propose three methods to obtain high-probability bounds under different assumptions. Our experiments on the MNIST dataset reveal significant tightness gaps, as much as 5-6\% in some cases.
    
[^27]: 缩放黎曼扩散模型

    Scaling Riemannian Diffusion Models. (arXiv:2310.20030v1 [cs.LG])

    [http://arxiv.org/abs/2310.20030](http://arxiv.org/abs/2310.20030)

    本文提出了一种改进的黎曼扩散模型，通过重新审视近似方法和利用对称空间的性质，实现了高精度计算和在高维任务上的扩展能力。

    

    黎曼扩散模型从标准欧几里得空间扩散模型中汲取灵感，学习在一般流形上的分布。不幸的是，额外的几何复杂性使得扩散过渡项无法用闭式表达式表示，因此先前的方法只能使用粗略的近似方法来降低性能并阻止在高维度下的应用。在这项工作中，我们重新审视这些近似方法，并提出几个实用的改进方法。我们的关键观察是，大多数相关流形是对称空间，这些对称空间在计算上更容易处理。通过利用和组合各种方法，我们可以快速计算相关的量到高精度。在低维数据集上，我们的校正产生了明显的改进，使扩散能够与其他方法竞争。此外，我们展示了我们的方法使我们能够在非平凡流形上扩展到高维任务。

    Riemannian diffusion models draw inspiration from standard Euclidean space diffusion models to learn distributions on general manifolds. Unfortunately, the additional geometric complexity renders the diffusion transition term inexpressible in closed form, so prior methods resort to imprecise approximations of the score matching training objective that degrade performance and preclude applications in high dimensions. In this work, we reexamine these approximations and propose several practical improvements. Our key observation is that most relevant manifolds are symmetric spaces, which are much more amenable to computation. By leveraging and combining various ans\"{a}tze, we can quickly compute relevant quantities to high precision. On low dimensional datasets, our correction produces a noticeable improvement, allowing diffusion to compete with other methods. Additionally, we show that our method enables us to scale to high dimensional tasks on nontrivial manifolds. In particular, we mo
    
[^28]: 提升强化学习中汤普森采样的贝叶斯遗憾界

    Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning. (arXiv:2310.20007v1 [stat.ML])

    [http://arxiv.org/abs/2310.20007](http://arxiv.org/abs/2310.20007)

    本文在多种情境下证明了汤普森采样在强化学习中的贝叶斯遗憾界，并通过对信息比的精确分析提出了一个基于时间不均匀强化学习问题的上界估计。同时，本文找到了各种设置中具体的界限，并讨论了这些结果是第一个其类别或改进了最先进方法的情况。

    

    本文证明了在多种情境下，汤普森采样在强化学习中的第一个贝叶斯遗憾界。我们利用离散的代理环境简化学习问题，并通过后验一致性对信息比进行了精确分析。这导致了一个基于时间不均匀强化学习问题的上界估计为$\widetilde{O}(H\sqrt{d_{l_1}T})$，其中$H$为回合长度，$d_{l_1}$为环境空间的Kolmogorov $l_1$维度。然后，我们在各种设置中找到了$d_{l_1}$的具体界限，比如表格、线性和有限混合，讨论了我们的结果是第一个其类别或改进了最先进方法的情况。

    In this paper, we prove the first Bayesian regret bounds for Thompson Sampling in reinforcement learning in a multitude of settings. We simplify the learning problem using a discrete set of surrogate environments, and present a refined analysis of the information ratio using posterior consistency. This leads to an upper bound of order $\widetilde{O}(H\sqrt{d_{l_1}T})$ in the time inhomogeneous reinforcement learning problem where $H$ is the episode length and $d_{l_1}$ is the Kolmogorov $l_1-$dimension of the space of environments. We then find concrete bounds of $d_{l_1}$ in a variety of settings, such as tabular, linear and finite mixtures, and discuss how how our results are either the first of their kind or improve the state-of-the-art.
    
[^29]: 通过更快的Frank-Wolfe迭代方法提高差分隐私LASSO正则化逻辑回归的扩展能力

    Scaling Up Differentially Private LASSO Regularized Logistic Regression via Faster Frank-Wolfe Iterations. (arXiv:2310.19978v1 [cs.LG])

    [http://arxiv.org/abs/2310.19978](http://arxiv.org/abs/2310.19978)

    本论文提出了一种通过改进Frank-Wolfe算法来训练差分隐私回归模型的方法，并在稀疏输入数据上有效。通过这种方法，可以显著减少算法的训练时间，并在实验中取得了显著的性能提升。

    

    据我们所知，目前没有方法可以在稀疏输入数据上训练差分隐私回归模型。为了解决这个问题，我们将$ L_1 $惩罚线性回归的Frank-Wolfe算法适应于稀疏输入，并有效地利用它们。通过这样做，我们将算法的训练时间从$ \mathcal {O}（TDS + TNS）$减少到$ \mathcal {O}（NS + T \sqrt {D} \log {D} + TS ^ 2）$，其中$ T $是迭代次数，而$ N $是数据集的行数，$ D $是特征数，$ S $是稀疏率。我们的结果表明，这个过程可以将运行时间缩短多达$ 2,200 \times $，这取决于隐私参数$ \epsilon $的值和数据集的稀疏程度。

    To the best of our knowledge, there are no methods today for training differentially private regression models on sparse input data. To remedy this, we adapt the Frank-Wolfe algorithm for $L_1$ penalized linear regression to be aware of sparse inputs and to use them effectively. In doing so, we reduce the training time of the algorithm from $\mathcal{O}( T D S + T N S)$ to $\mathcal{O}(N S + T \sqrt{D} \log{D} + T S^2)$, where $T$ is the number of iterations and a sparsity rate $S$ of a dataset with $N$ rows and $D$ features. Our results demonstrate that this procedure can reduce runtime by a factor of up to $2,200\times$, depending on the value of the privacy parameter $\epsilon$ and the sparsity of the dataset.
    
[^30]: 通过$f$-差分隐私统一增强混合机制的隐私边界

    Unified Enhancement of Privacy Bounds for Mixture Mechanisms via $f$-Differential Privacy. (arXiv:2310.19973v1 [stat.ML])

    [http://arxiv.org/abs/2310.19973](http://arxiv.org/abs/2310.19973)

    本文通过$f$-差分隐私方法改进了洗牌模型和DP-GD中随机初始化的隐私边界，折衷函数的闭式表达式优于$(\epsilon,\delta)$-DP的结果，并且随机初始化可以增强DP-GD的隐私性。

    

    差分隐私（DP）机器学习算法会产生许多随机性，如随机初始化、随机批次抽样和洗牌。然而，由于这些随机性会导致难以分析的混合分布，所以在证明差分隐私边界时很难将其纳入考虑。本文旨在改进洗牌模型和一次迭代的差分隐私梯度下降（DP-GD）中用于随机初始化的隐私边界，采用$f$-DP方法。我们导出了洗牌模型的折衷函数的闭式表达式，优于基于$(\epsilon,\delta)$-DP的最新结果。此外，我们还对随机初始化对一次迭代的DP-GD的隐私性进行了研究。我们对折衷函数的数值计算表明，随机初始化可以增强DP-GD的隐私性。我们对这些混合机制的$f$-DP保证的分析依赖于一种不等式。

    Differentially private (DP) machine learning algorithms incur many sources of randomness, such as random initialization, random batch subsampling, and shuffling. However, such randomness is difficult to take into account when proving differential privacy bounds because it induces mixture distributions for the algorithm's output that are difficult to analyze. This paper focuses on improving privacy bounds for shuffling models and one-iteration differentially private gradient descent (DP-GD) with random initializations using $f$-DP. We derive a closed-form expression of the trade-off function for shuffling models that outperforms the most up-to-date results based on $(\epsilon,\delta)$-DP. Moreover, we investigate the effects of random initialization on the privacy of one-iteration DP-GD. Our numerical computations of the trade-off function indicate that random initialization can enhance the privacy of DP-GD. Our analysis of $f$-DP guarantees for these mixture mechanisms relies on an ine
    
[^31]: 后验采样在竞争性强化学习中的应用：函数近似和部分观测

    Posterior Sampling for Competitive RL: Function Approximation and Partial Observation. (arXiv:2310.19861v1 [cs.LG])

    [http://arxiv.org/abs/2310.19861](http://arxiv.org/abs/2310.19861)

    本文研究了使用后验采样算法在竞争性强化学习中的应用。通过引入自对弈和对抗性广义艾略特系数，提出了用于探索-利用平衡的模型方法，并且成功处理了状态的部分可观测性。同时，提出了学习具有潜在部分可观测性的对抗性博弈模型的后验采样方法，并给出了低遗憾界限。

    

    本文研究了在一般函数近似的背景下，用于竞争性强化学习的后验采样算法。针对零和马尔可夫博弈中的自对弈和对抗学习两个关键情景，我们首先提出了自对弈和对抗性广义艾略特系数(GEC)作为函数近似的复杂度度量，并捕捉博弈中的探索-利用平衡。基于自对弈GEC，我们提出了一种基于模型的自对弈后验采样方法，以控制两个玩家学习纳什均衡，可以成功处理状态的部分可观测性。此外，我们确定了一套与对手的对抗策略相适应的部分可观测博弈模型。结合对抗GEC，我们提出了一种基于模型的后验采样方法，用于学习具有潜在部分可观测性的对抗性博弈模型。我们进一步为所提出的算法提供了低遗憾界限。

    This paper investigates posterior sampling algorithms for competitive reinforcement learning (RL) in the context of general function approximations. Focusing on zero-sum Markov games (MGs) under two critical settings, namely self-play and adversarial learning, we first propose the self-play and adversarial generalized eluder coefficient (GEC) as complexity measures for function approximation, capturing the exploration-exploitation trade-off in MGs. Based on self-play GEC, we propose a model-based self-play posterior sampling method to control both players to learn Nash equilibrium, which can successfully handle the partial observability of states. Furthermore, we identify a set of partially observable MG models fitting MG learning with the adversarial policies of the opponent. Incorporating the adversarial GEC, we propose a model-based posterior sampling method for learning adversarial MG with potential partial observability. We further provide low regret bounds for proposed algorithms
    
[^32]: 节点属性随机块模型的精确恢复与Bregman硬聚类

    Exact Recovery and Bregman Hard Clustering of Node-Attributed Stochastic Block Model. (arXiv:2310.19854v1 [cs.SI])

    [http://arxiv.org/abs/2310.19854](http://arxiv.org/abs/2310.19854)

    该论文介绍了一种精确恢复节点属性随机块模型的聚类算法，该算法利用网络信息和节点属性信息交换，实现更可靠的网络信息需要更少可靠的属性信息的精确恢复。

    

    网络聚类解决了识别具有相似连接模式的节点集（社区）的问题。然而，在许多情况下，节点还具有与聚类结构相关的属性。因此，可以联合利用网络信息（边）和节点信息（属性）来设计高性能的聚类算法。在网络和节点属性的一般模型下，该工作建立了一个信息论准则，用于精确恢复社区标签，并确定了由模型的Chernoff-Hellinger散度确定的相变。这个准则显示了网络和属性信息如何交换，以实现精确恢复（例如，更可靠的网络信息需要更不可靠的属性信息）。该工作还提出了一种迭代聚类算法，最大化联合似然，假设网络交互和节点属性的概率分布。

    Network clustering tackles the problem of identifying sets of nodes (communities) that have similar connection patterns. However, in many scenarios, nodes also have attributes that are correlated with the clustering structure. Thus, network information (edges) and node information (attributes) can be jointly leveraged to design high-performance clustering algorithms. Under a general model for the network and node attributes, this work establishes an information-theoretic criterion for the exact recovery of community labels and characterizes a phase transition determined by the Chernoff-Hellinger divergence of the model. The criterion shows how network and attribute information can be exchanged in order to have exact recovery (e.g., more reliable network information requires less reliable attribute information). This work also presents an iterative clustering algorithm that maximizes the joint likelihood, assuming that the probability distribution of network interactions and node attrib
    
[^33]: 模仿解释：通过可解释的策略学习理解决策

    Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning. (arXiv:2310.19831v1 [stat.ML])

    [http://arxiv.org/abs/2310.19831](http://arxiv.org/abs/2310.19831)

    本文提出了一种新的模型基于的贝叶斯方法，通过可解释的策略学习来理解决策，该方法具有透明度、适应部分可观测性和完全离线运行的特点。通过对阿尔茨海默病诊断问题的实验验证，展示了该方法作为审计和分析工具的潜力。

    

    从观察数据中理解人类行为对于透明度和决策的问责是至关重要的。在现实世界中，如医疗保健领域，建模决策者的策略具有挑战性——没有访问底层状态的权限，没有了解环境动态的知识，也没有进行实时实验的容错能力。我们希望学习一个数据驱动的决策行为表示，它具有（1）设计上的透明度，（2）适应部分可观测性，（3）完全离线运行。为了满足这些关键条件，我们提出了一种新颖的基于模型的贝叶斯方法来进行可解释的策略学习（"Interpole"），它同时估计一个代理人的（可能有偏差的）置信更新过程以及他们（可能次优的）信念动作映射。通过对模拟和真实世界的阿尔茨海默病诊断问题的实验，我们展示了我们的方法作为审计和分析工具的潜力。

    Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker's policy is challenging -- with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision-making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning ("Interpole") that jointly estimates an agent's (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer's disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, qua
    
[^34]: 一种面向非平稳随机多臂老虎机的风险规避框架

    A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed Bandits. (arXiv:2310.19821v1 [cs.LG])

    [http://arxiv.org/abs/2310.19821](http://arxiv.org/abs/2310.19821)

    我们提出了一种适用于非平稳环境的自适应风险感知策略框架，通过结合各种风险度量和重启贝叶斯在线变点检测算法，解决了高波动性领域中简单奖励最大化方法的不可靠性问题。

    

    在典型的随机多臂老虎机问题中，目标通常是在一定的时间范围内最大化预期奖励总和。然而，当提供额外的环境特定知识时，选择一个能够达到最优的策略不再适用。尤其是在医疗或金融等高波动性领域，简单的奖励最大化方法往往不能准确捕捉学习问题的复杂性，导致不可靠的解决方案。为解决这类问题，我们提出了一种自适应风险感知策略的框架，用于在非平稳环境中操作。我们的框架结合了文献中普遍存在的各种风险度量，将多个多臂老虎机算法族映射到风险敏感设置中。此外，我们将结果算法配备了重启贝叶斯在线变点检测（R-BOCPD）算法，并施加了（可调节的）强制终止机制。

    In a typical stochastic multi-armed bandit problem, the objective is often to maximize the expected sum of rewards over some time horizon $T$. While the choice of a strategy that accomplishes that is optimal with no additional information, it is no longer the case when provided additional environment-specific knowledge. In particular, in areas of high volatility like healthcare or finance, a naive reward maximization approach often does not accurately capture the complexity of the learning problem and results in unreliable solutions. To tackle problems of this nature, we propose a framework of adaptive risk-aware strategies that operate in non-stationary environments. Our framework incorporates various risk measures prevalent in the literature to map multiple families of multi-armed bandit algorithms into a risk-sensitive setting. In addition, we equip the resulting algorithms with the Restarted Bayesian Online Change-Point Detection (R-BOCPD) algorithm and impose a (tunable) forced ex
    
[^35]: Hodge-Compositional 边缘高斯过程

    Hodge-Compositional Edge Gaussian Processes. (arXiv:2310.19450v1 [stat.ML])

    [http://arxiv.org/abs/2310.19450](http://arxiv.org/abs/2310.19450)

    本论文提出了一种新的方法用于对边缘集合上的函数进行建模，该方法基于Hodge分解开发了适用于不同应用场景的无散度和无旋度的高斯过程，并通过组合它们来表示任意边缘函数。实验结果表明这种方法在流动数据推断中具有潜在的实际应用价值。

    

    我们提出了一种基于边缘集合的2-复形结构（类似于图形，其中边缘可形成三角面）的函数建模的有原则的高斯过程（GPs）。这种方法适用于学习网络上的流动类型数据，其中边缘流可以通过离散的散度和旋度来表征。借鉴Hodge分解，我们首先开发了适用于各种应用的无散度和无旋游的边缘GPs。然后将它们组合起来创建Hodge-组合边缘GPs，这些GPs足够表达任何边缘函数。这些GPs便于对边缘函数的不同Hodge分量进行直接和独立的学习，使我们能够在超参数优化过程中捕捉它们的相关性。为了突显它们的实际潜力，我们将它们应用于货币兑换、海洋流动和供水网络中的流动数据推断，并将其与替代模型进行比较。

    We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create \emph{Hodge-compositional edge GPs} that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean flows and water supply networks, comparing them to alternative models.
    
[^36]: Causal Q-Aggregation for CATE Model Selection（CATE模型选择中的因果Q集成）

    Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])

    [http://arxiv.org/abs/2310.16945](http://arxiv.org/abs/2310.16945)

    该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率

    

    准确估计条件平均处理效应（CATE）是个性化决策的核心。尽管有大量用于CATE估计的模型，但由于因果推断的基本问题，模型选择是一项非常棘手的任务。最近的实证工作提供了有利于具有双重鲁棒性质的代理损失度量和模型集成的证据。然而，对于这些模型的理论理解还不够。直接应用先前的理论工作会由于模型选择问题的非凸性而导致次优的预测模型选择率。我们提供了现有主要CATE集成方法的遗憾率，并提出了一种基于双重鲁棒损失的Q集成的新的CATE模型集成方法。我们的主要结果表明，因果Q集成在预测模型选择的遗憾率上达到了统计上的最优值为$\frac{\log(M)}{n}$（其中$M$为模型数，$n$为样本数），加上高阶估计误差项

    Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
    
[^37]: 流形学习的规范化正态流

    Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])

    [http://arxiv.org/abs/2310.12743](http://arxiv.org/abs/2310.12743)

    该论文介绍了一种规范化正态流方法，用于流形学习。通过可学习的可逆变换将数据嵌入到高维空间中，从而实现了在流形上计算概率密度并优化网络参数的目标。然而，当前的方法在学习到的流形表示中存在着与流形关联且退化的内在基函数的问题。

    

    流形学习流是一类生成建模技术，假设数据具有低维流形描述。通过可学习的可逆变换将这种流形嵌入到数据的高维空间中。因此，一旦通过重构损失正确对齐流形，流形上的概率密度就是可计算的，并且可以使用最大似然来优化网络参数。自然地，数据的低维表示需要是单射映射。最近的方法能够在建模的流形上对密度进行对准，并在嵌入到高维空间时高效计算密度体积变化项。然而，除非单射映射在解析上预定义，否则学习到的流形不一定是数据的有效表示。也就是说，这种模型的潜在维度经常会学习到与流形相关并且退化的内在基函数。

    Manifold learning flows are a class of generative modelling techniques that assume a low-dimensional manifold description of the data. The embedding of such manifold into the high-dimensional space of the data is achieved via learnable invertible transformations. Therefore, once the manifold is properly aligned via a reconstruction loss, the probability density is tractable on the manifold and maximum likelihood can be used optimize the network parameters. Naturally, the lower-dimensional representation of the data requires an injective-mapping. Recent approaches were able to enforce that density aligns with the modelled manifold, while efficiently calculating the density volume-change term when embedding to the higher-dimensional space. However, unless the injective-mapping is analytically predefined, the learned manifold is not necessarily an efficient representation of the data. Namely, the latent dimensions of such models frequently learn an entangled intrinsic basis with degenerat
    
[^38]: 稀疏变分高斯过程回归的点估计和不确定性量化与布朗运动先验的研究

    Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior. (arXiv:2310.00097v1 [math.ST])

    [http://arxiv.org/abs/2310.00097](http://arxiv.org/abs/2310.00097)

    本文研究了稀疏变分高斯过程回归中点估计和不确定性量化的方法，通过使用布朗运动先验和特征向量引导变量，推导了频率派可信区间的理论保证和限制，并在足够多的引导变量的情况下精确定义了渐近频率派覆盖，从而推断出这个变分方法的可信区间何时保守，何时过于自信/误导。数值实验证明了这些结果的适用性，并讨论了与其他常见高斯过程先验的相关性。

    

    本文研究了使用特征向量引导变量的稀疏变分高斯过程方法的点估计和不确定性量化。对于具有重标定布朗运动先验的情况，我们推导了点化可信区间的频率派大小和覆盖的理论保证和限制。通过充分的引导变量，我们精确地描述了渐近频率派覆盖，推断了这个变分方法的可信区间何时保守，何时过于自信/误导。我们通过数值实验说明了我们的结果的适用性，并讨论了与其他常见高斯过程先验的联系。

    We study pointwise estimation and uncertainty quantification for a sparse variational Gaussian process method with eigenvector inducing variables. For a rescaled Brownian motion prior, we derive theoretical guarantees and limitations for the frequentist size and coverage of pointwise credible sets. For sufficiently many inducing variables, we precisely characterize the asymptotic frequentist coverage, deducing when credible sets from this variational method are conservative and when overconfident/misleading. We numerically illustrate the applicability of our results and discuss connections with other common Gaussian process priors.
    
[^39]: 锐度感知最小化和稳定性边界。

    Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v1 [cs.LG])

    [http://arxiv.org/abs/2309.12488](http://arxiv.org/abs/2309.12488)

    本研究通过类似的计算方法，为锐度感知最小化(SAM)，一种改进泛化性能的梯度下降变种，确定了一个稳定性边界，该边界取决于梯度的范数。

    

    最近的实验表明，当使用梯度下降(GD)训练神经网络时，损失函数的Hessian矩阵的操作符范数会增长，直到接近$2/\eta$，之后会在该值周围波动。根据对损失函数的局部二次逼近，$2/\eta$被称为“稳定性边界”。我们使用类似的计算方法，为锐度感知最小化(SAM)确定了一个“稳定性边界”，SAM是一种改进泛化性能的GD变种。与GD不同，SAM的稳定性边界取决于梯度的范数。通过三个深度学习任务的实证，我们观察到SAM在这个分析中确定的稳定性边界上运行。

    Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value.  The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
    
[^40]: SGMM: 广义矩方法的随机近似

    SGMM: Stochastic Approximation to Generalized Method of Moments. (arXiv:2308.13564v1 [econ.EM])

    [http://arxiv.org/abs/2308.13564](http://arxiv.org/abs/2308.13564)

    我们提出了一种新的随机广义矩方法（SGMM），用于估计和推断矩限制模型。该方法具有快速和可扩展的实时处理能力，并且能够处理大规模和在线数据集。

    

    我们引入了一种新的算法类，随机广义矩方法（SGMM），用于估计和推断（超识别）矩限制模型。我们的SGMM是一种新颖的随机逼近方法，替代了流行的Hansen（1982年）的（离线）GMM，并提供了快速和可扩展的实时流数据处理能力。我们证明了SGMM对于效率不高的在线2SLS和高效的SGMM具有几乎确定的收敛性和（函数）中心极限定理。此外，我们提出了Durbin-Wu-Hausman和Sargan-Hansen测试的在线版本，可以无缝集成到SGMM框架中。广泛的蒙特卡洛模拟结果表明，随着样本量的增加，SGMM在估计准确性和计算效率方面与标准（离线）GMM相匹配，并显示出在大规模和在线数据集上的实际价值。我们通过使用两个示例证明了我们方法的有效性。

    We introduce a new class of algorithms, Stochastic Generalized Method of Moments (SGMM), for estimation and inference on (overidentified) moment restriction models. Our SGMM is a novel stochastic approximation alternative to the popular Hansen (1982) (offline) GMM, and offers fast and scalable implementation with the ability to handle streaming datasets in real time. We establish the almost sure convergence, and the (functional) central limit theorem for the inefficient online 2SLS and the efficient SGMM. Moreover, we propose online versions of the Durbin-Wu-Hausman and Sargan-Hansen tests that can be seamlessly integrated within the SGMM framework. Extensive Monte Carlo simulations show that as the sample size increases, the SGMM matches the standard (offline) GMM in terms of estimation accuracy and gains over computational efficiency, indicating its practical value for both large-scale and online datasets. We demonstrate the efficacy of our approach by a proof of concept using two we
    
[^41]: 长期信用归因通过反事实贡献分析的方式

    Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis. (arXiv:2306.16803v1 [cs.LG])

    [http://arxiv.org/abs/2306.16803](http://arxiv.org/abs/2306.16803)

    本文提出了一种新的基于模型的信用分配算法，通过量化反事实查询来测量动作对未来奖励的影响。与现有方法不同的是，我们通过测量对奖励或奖励对象表示的贡献，获得了具有更低方差的梯度估计。

    

    为了使强化学习更加样本高效，我们需要更好的信用归因方法来衡量动作对未来奖励的影响。在悔棋信用归因（HCA）的基础上，我们引入了反事实贡献分析（COCOA），这是一种新的基于模型的信用归因算法系列。我们的算法通过量化一个反事实查询来实现精确的信用分配：“如果代理选择另一个动作，它仍然会获得这个奖励吗？”通过测量动作对获得后续奖励的贡献，我们展示了对于奖励状态测量贡献（即HCA中所做的）会导致贡献的错误估计，使得HCA在许多相关环境中向高方差的REINFORCE估计器退化。相反，我们通过测量对奖励或所学习的奖励对象的表示的贡献，得到具有更低方差的梯度估计。我们在一系列特定问题上进行了实验

    To make reinforcement learning more sample efficient, we need better credit assignment methods that measure an action's influence on future rewards. Building upon Hindsight Credit Assignment (HCA), we introduce Counterfactual Contribution Analysis (COCOA), a new family of model-based credit assignment algorithms. Our algorithms achieve precise credit assignment by measuring the contribution of actions upon obtaining subsequent rewards, by quantifying a counterfactual query: "Would the agent still have reached this reward if it had taken another action?". We show that measuring contributions w.r.t. rewarding states, as is done in HCA, results in spurious estimates of contributions, causing HCA to degrade towards the high-variance REINFORCE estimator in many relevant environments. Instead, we measure contributions w.r.t. rewards or learned representations of the rewarding objects, resulting in gradient estimates with lower variance. We run experiments on a suite of problems specifically 
    
[^42]: 基于评分的数据同化

    Score-based Data Assimilation. (arXiv:2306.10574v1 [cs.LG])

    [http://arxiv.org/abs/2306.10574](http://arxiv.org/abs/2306.10574)

    本文介绍了基于评分的数据同化方法，通过对状态轨迹模型的训练，实现了无需依赖传统推断方法和满足高维系统与长时间跨度下进行推断。

    

    在最全面的形式下，数据同化解决了鉴定随机动态系统中的可能状态轨迹的贝叶斯逆问题，从而解释尽管存在噪声或不完整观测的内容。已经提出了各种方法来解决这个问题，包括基于粒子的和可变方法。然而，大多数算法依赖于转移动态进行推断，这在长时间跨度或具有复杂动态的高维系统中变得棘手，如海洋或大气。本文介绍了基于评分的数据同化来实现轨迹推断。我们学习了基于评分的生成状态轨迹模型，这是基于一个关键洞察，即任意长轨迹的得分可以分解为短部分的得分系列。在训练完成后，运用得分模型进行无自回归的推断，通过同时生成所有状态。与众不同的是，我们解耦了观测。

    Data assimilation, in its most comprehensive form, addresses the Bayesian inverse problem of identifying plausible state trajectories that explain noisy or incomplete observations of stochastic dynamical systems. Various approaches have been proposed to solve this problem, including particle-based and variational methods. However, most algorithms depend on the transition dynamics for inference, which becomes intractable for long time horizons or for high-dimensional systems with complex dynamics, such as oceans or atmospheres. In this work, we introduce score-based data assimilation for trajectory inference. We learn a score-based generative model of state trajectories based on the key insight that the score of an arbitrarily long trajectory can be decomposed into a series of scores over short segments. After training, inference is carried out using the score model, in a non-autoregressive manner by generating all states simultaneously. Quite distinctively, we decouple the observation 
    
[^43]: 学习受限动力学的稳定神经微分方程

    Stabilized Neural Differential Equations for Learning Constrained Dynamics. (arXiv:2306.09739v1 [cs.LG])

    [http://arxiv.org/abs/2306.09739](http://arxiv.org/abs/2306.09739)

    本文提出了一种稳定神经微分方程（SNDEs）的方法，可以强制使用任意流形约束。该方法通过添加稳定项使约束流形成为渐进稳定的，并且在实验中表现优于现有方法。

    

    最近出现了许多成功的从数据学习动态系统的方法。然而，确保推断出的动态系统保留已知约束条件（例如守恒定律或对允许的系统状态的限制）仍然具有挑战性。我们提出了稳定神经微分方程（SNDEs）的方法，这是一种用于神经微分方程强制使用任意流形约束的方法。我们的方法基于一个稳定项，当添加到原始动态系统中时，可以将约束流形成为渐进稳定的。由于其简单性，我们的方法与所有常见的神经常微分方程（NODE）模型兼容并广泛适用。在广泛的经验评估中，我们证明SNDE在扩展可纳入NODE训练的约束类型方面胜过现有方法。

    Many successful methods to learn dynamical systems from data have recently been introduced. However, assuring that the inferred dynamics preserve known constraints, such as conservation laws or restrictions on the allowed system states, remains challenging. We propose stabilized neural differential equations (SNDEs), a method to enforce arbitrary manifold constraints for neural differential equations. Our approach is based on a stabilization term that, when added to the original dynamics, renders the constraint manifold provably asymptotically stable. Due to its simplicity, our method is compatible with all common neural ordinary differential equation (NODE) models and broadly applicable. In extensive empirical evaluations, we demonstrate that SNDEs outperform existing methods while extending the scope of which types of constraints can be incorporated into NODE training.
    
[^44]: 非线性潜变量层次模型的识别

    Identification of Nonlinear Latent Hierarchical Models. (arXiv:2306.07916v1 [cs.LG])

    [http://arxiv.org/abs/2306.07916](http://arxiv.org/abs/2306.07916)

    本文提出了一种方法，可以在观测变量由因果相关的潜变量生成的非线性潜变量层次因果模型中实现因果结构和潜变量的可识别性。

    

    从观测数据中识别潜变量和因果结构对于许多涉及生物数据、医学数据和非结构化数据（如图像和语言）的实际应用至关重要。然而，当观测变量由因果相关的潜变量生成，并且关系是非线性的时，这项任务可能非常具有挑战性。在这项工作中，我们研究了非线性潜变量层次因果模型的识别问题，在这种模型中，观测变量由一组因果相关的潜变量生成，有些潜变量可能没有观察到的后代。我们证明，在温和的假设下可以实现因果结构和潜变量的可识别性：对于因果结构，我们允许图中任意两个变量之间存在多条路径，这放宽了先前工作中的潜变量树假设；对于结构函数，我们没有进行参数假设，因此可以允许基因

    Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of both causal structure and latent variables can be achieved under mild assumptions: on causal structures, we allow for the existence of multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we do not make parametric assumptions, thus permitting gene
    
[^45]: 关于Removal-Based特征归因的鲁棒性研究

    On the Robustness of Removal-Based Feature Attributions. (arXiv:2306.07462v1 [cs.LG])

    [http://arxiv.org/abs/2306.07462](http://arxiv.org/abs/2306.07462)

    本文研究了Removal-Based特征归因的鲁棒性，提供了全面的理论和实验分析，并证明了所提方法的实际有效性。

    

    为了解释基于输入的复杂模型，开发了许多特征归因方法来分配输入特征的重要性分数。然而，最近的一些研究挑战了特征归因的鲁棒性，指出这些方法对输入和模型扰动敏感，而其他研究通过提出鲁棒归因方法和模型修改来解决这个问题。然而，以往的归因鲁棒性研究主要侧重于基于梯度的特征归因。相比之下，Removal-Based归因方法的鲁棒性质尚未全面地得到理解。为了弥补这一差距，我们从理论上对Removal-Based特征归因的鲁棒性进行了全面的阐述。具体而言，我们对这种方法进行了统一的分析，并在输入和模型扰动的情况下证明了完好和受扰动的归因之间的差异的上限。我们在合成和真实数据集上的实验验证了我们的理论结果，并证明了所提出方法的实际有效性。

    To explain complex models based on their inputs, many feature attribution methods have been developed that assign importance scores to input features. However, some recent work challenges the robustness of feature attributions by showing that these methods are sensitive to input and model perturbations, while other work addresses this robustness issue by proposing robust attribution methods and model modifications. Nevertheless, previous work on attribution robustness has focused primarily on gradient-based feature attributions. In contrast, the robustness properties of removal-based attribution methods are not comprehensively well understood. To bridge this gap, we theoretically characterize the robustness of removal-based feature attributions. Specifically, we provide a unified analysis of such methods and prove upper bounds for the difference between intact and perturbed attributions, under settings of both input and model perturbations. Our empirical experiments on synthetic and re
    
[^46]: 变分不平衡回归(Variational Imbalanced Regression)

    Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])

    [http://arxiv.org/abs/2306.06599](http://arxiv.org/abs/2306.06599)

    本文提出的变分不平衡回归（VIR）模型通过引入Probabilistic Reweighting方法，可以在不平衡回归方面表现良好，并自然产生合理的不确定性估计。

    

    当标签分布不平衡时，现有的回归模型往往在准确性和不确定性估计方面表现不佳。本文提出了一种概率深度学习模型——变分不平衡回归（VIR），它不仅在不平衡回归方面表现出色，而且自然地产生合理的不确定性估计。与典型的变分自编码器假设I.I.D.表示（数据点的表示不直接受其他数据点的影响）不同，我们的VIR借用具有类似回归标签的数据来计算潜在表示的变分分布；此外，不同于产生点估计的确定性回归模型， VIR预测整个正态反-伽玛分布并调节相关联的共轭分布，对不平衡数据施加概率重新加权，从而提供更好的不确定性估计。在几个真实世界的数据集上进行了实验。

    Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
    
[^47]: 从随机过程中学习先验知识的差分隐私图像分类

    Differentially Private Image Classification by Learning Priors from Random Processes. (arXiv:2306.06076v1 [cs.CV])

    [http://arxiv.org/abs/2306.06076](http://arxiv.org/abs/2306.06076)

    本文提出了一种名为DP-RandP的方法，从随机过程中学习先验知识，并将其传递给私有数据，以改进差分隐私的图像分类，实现了新的最先进的结果，提高了CIFAR-10的精度。

    

    在隐私保护的机器学习中，不同ially私有的随机梯度下降（DP-SGD）由于每个样本梯度剪辑和噪声添加而表现不佳。隐私学习研究的一个最近重点是通过将在真实世界公共数据上学习的先验知识纳入这些数据，从而提高DP-SGD在私有数据上的性能。在这项工作中，我们探讨了如何通过从由随机过程生成的图像中学习先验知识并将这些先验知识转移到私有数据来改进DP-SGD的隐私-效用折衷。我们提出了DP-RandP，这是一个三阶段的方法。在CIFAR10、CIFAR100和MedMNIST上从头开始训练时，我们获得了新的最先进的结果，并适用于一系列隐私预算ε∈[1，8]。特别地，我们将在ε=1时在CIFAR10上报告的最佳准确性从60.6%提高到72.3%。我们的代码可在https://github.com/inspire-group/DP-RandP上找到。

    In privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) performs worse than SGD due to per-sample gradient clipping and noise addition. A recent focus in private learning research is improving the performance of DP-SGD on private data by incorporating priors that are learned on real-world public data. In this work, we explore how we can improve the privacy-utility tradeoff of DP-SGD by learning priors from images generated by random processes and transferring these priors to private data. We propose DP-RandP, a three-phase approach. We attain new state-of-the-art accuracy when training from scratch on CIFAR10, CIFAR100, and MedMNIST for a range of privacy budgets $\varepsilon \in [1, 8]$. In particular, we improve the previous best reported accuracy on CIFAR10 from $60.6 \%$ to $72.3 \%$ for $\varepsilon=1$. Our code is available at https://github.com/inspire-group/DP-RandP.
    
[^48]: 用信息理论的Shapley值解释预测的不确定性

    Explaining Predictive Uncertainty with Information Theoretic Shapley Values. (arXiv:2306.05724v1 [stat.ML])

    [http://arxiv.org/abs/2306.05724](http://arxiv.org/abs/2306.05724)

    本文提出了一种新的方法，通过Shapley值解释不确定性预测，可以量化每个特征对个别模型输出条件熵的贡献，适用于协变量转移检测、主动学习、特征选择和活动特征价值评估等方面。

    

    可解释人工智能研究人员开发了大量方法来帮助用户理解复杂监督学习模型的预测结果。相比之下，解释模型输出的$\textit{不确定性}$却受到了相对较少的关注。我们将广泛使用的Shapley值框架用于解释各种类型的预测不确定性，量化每个特征对个别模型输出条件熵的贡献。我们考虑了修改特征函数的博弈，并发现了由此产生的Shapley值与信息论和条件独立性测试中的基本量之间的深刻联系。我们概述了有证明保证的有限样本误差率控制的推理过程，并实现了一种高效的算法，在真实和模拟数据的一系列实验中表现良好。我们的方法适用于协变量转移检测、主动学习、特征选择和活动特征价值评估等方面。

    Researchers in explainable artificial intelligence have developed numerous methods for helping users understand the predictions of complex supervised learning models. By contrast, explaining the $\textit{uncertainty}$ of model outputs has received relatively little attention. We adapt the popular Shapley value framework to explain various types of predictive uncertainty, quantifying each feature's contribution to the conditional entropy of individual model outputs. We consider games with modified characteristic functions and find deep connections between the resulting Shapley values and fundamental quantities from information theory and conditional independence testing. We outline inference procedures for finite sample error rate control with provable guarantees, and implement an efficient algorithm that performs well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection, active learning, feature selection, and active feature-val
    
[^49]: 具有网络辅助信息的高维线性回归中的贝叶斯最优学习

    Bayes optimal learning in high-dimensional linear regression with network side information. (arXiv:2306.05679v1 [math.ST])

    [http://arxiv.org/abs/2306.05679](http://arxiv.org/abs/2306.05679)

    本文首次研究了具有网络辅助信息的高维线性回归中的贝叶斯最优学习问题，引入了Reg-Graph模型并提出了基于AMP的迭代算法，在实验中优于现有的几种网络辅助回归方法。

    

    在基因组学、蛋白质组学和神经科学等应用中，具有网络辅助信息的监督学习问题经常出现。本文中，我们首次研究了具有网络辅助信息的高维线性回归中的贝叶斯最优学习问题。为此，我们首先引入了一个简单的生成模型（称为Reg-Graph模型），通过一组共同的潜在参数为监督数据和观测到的网络设定了一个联合分布。接下来，我们介绍了一种基于近似消息传递（AMP）的迭代算法，在非常一般的条件下可证明是贝叶斯最优的。此外，我们对潜在信号和观测到的数据之间的极限互信息进行了表征，从而精确量化了网络辅助信息在回归问题中的统计影响。我们对模拟数据和实际数据的实验表明，我们的方法优于现有的几种网络辅助回归方法。

    Supervised learning problems with side information in the form of a network arise frequently in applications in genomics, proteomics and neuroscience. For example, in genetic applications, the network side information can accurately capture background biological information on the intricate relations among the relevant genes. In this paper, we initiate a study of Bayes optimal learning in high-dimensional linear regression with network side information. To this end, we first introduce a simple generative model (called the Reg-Graph model) which posits a joint distribution for the supervised data and the observed network through a common set of latent parameters. Next, we introduce an iterative algorithm based on Approximate Message Passing (AMP) which is provably Bayes optimal under very general conditions. In addition, we characterize the limiting mutual information between the latent signal and the data observed, and thus precisely quantify the statistical impact of the network side 
    
[^50]: 使用大型语言模型注释进行社会科学中的有效下游统计推断: 基于设计的半监督学习

    Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning. (arXiv:2306.04746v1 [stat.ME])

    [http://arxiv.org/abs/2306.04746](http://arxiv.org/abs/2306.04746)

    该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。

    

    在计算社会科学（CSS）中，研究人员通过分析文档来解释社会和政治现象。在大多数情况下，CSS研究人员首先获取文档的标签，然后使用可解释的回归分析来解释标签。大型语言模型（LLMs）的最近进展可以通过在规模上便宜地注释文档来降低CSS研究成本，但这些替代标签通常是不完美和有偏的。我们提出了一种新算法，用于使用LLMs的输出进行下游统计分析，同时保证与CSS研究基本相关的统计属性-如渐近无偏性和正确的不确定性量化。我们表明，直接在下游统计分析中使用LLM预测的替代标签会导致实质性偏差和无效置信区间，即使替代准确性高达80-90％。为了解决这个问题，我们基于无偏机器学习提出了基于设计的半监督学习（D-SSL）算法，该算法将LLM注释与有针对性的采样相结合，以实现有效的下游统计推断。我们的方法可以将标签获取的CSS研究成本降低80％，而不影响统计分析的有效性。模拟研究和实际数据示例表明，与直接使用LLM预测标签相比，D-SSL可以将回归估计的准确性提高多达40％。

    In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80--90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised le
    
[^51]: 揭示生成模型评价度量的缺陷及其不公平对待扩散模型的现象

    Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models. (arXiv:2306.04675v1 [cs.LG])

    [http://arxiv.org/abs/2306.04675](http://arxiv.org/abs/2306.04675)

    系统地研究了图像生成模型的评估，发现常见的评价指标如FID等不能很好地体现扩散模型的感知真实性，建议使用SwAV特征提取器结合FID进行评估。

    

    我们系统地研究了许多种基于图像的生成模型，包括语义多样的数据集，以理解和改进用于评估它们的特征提取器和度量。使用心理物理学的最佳实践，我们进行了迄今为止最大规模的生成模型评估实验，通过对生成样本进行人类感知图像真实性的测量，发现没有任何现有的度量能与人类评估强相关。我们比较了用于评估生成模型整体性能、保真度、多样性和记忆能力的16个现代指标，发现以人类为基准的扩散模型的最先进的感知真实性不反映在常见的度量指标，如FID中。这种差异并不能通过生成样本的多样性来解释，尽管其中一个原因是过度依赖于Inception-V3。通过研究替代的自监督特征提取器，我们解决了这些缺陷，发现个别弱Downstream任务编码的语义信息最能解释图像真实性，建议在评估生成模型时使用SwAV特征提取器结合FID。

    We systematically study a wide variety of image-based generative models spanning semantically-diverse datasets to understand and improve the feature extractors and metrics used to evaluate them. Using best practices in psychophysics, we measure human perception of image realism for generated samples by conducting the largest experiment evaluating generative models to date, and find that no existing metric strongly correlates with human evaluations. Comparing to 16 modern metrics for evaluating the overall performance, fidelity, diversity, and memorization of generative models, we find that the state-of-the-art perceptual realism of diffusion models as judged by humans is not reflected in commonly reported metrics such as FID. This discrepancy is not explained by diversity in generated samples, though one cause is over-reliance on Inception-V3. We address these flaws through a study of alternative self-supervised feature extractors, find that the semantic information encoded by individu
    
[^52]: 变分高斯过程扩散过程

    Variational Gaussian Process Diffusion Processes. (arXiv:2306.02066v1 [cs.LG])

    [http://arxiv.org/abs/2306.02066](http://arxiv.org/abs/2306.02066)

    本文提出一种高斯变分过程参数化方法来更好地学习具有非线性扩散过程的潜在过程，此方法采用具有连续指数族描述的算法实现凸优化，可以代替缓慢的具有固定点迭代的算法。

    

    扩散过程是一类随机微分方程，提供了一系列表现丰富的模型，自然地出现在动态建模任务中。概率推理和生成模型下具有非线性扩散过程的潜在过程的学习都是棘手的问题。本文在变分推理的基础上构建高斯过程扩散过程的参数化，指出方法中的病态，并提出一种使用连续指数族描述的高斯变分过程的替代参数化方法。这使我们可以用凸优化的快速算法代替具有固定点迭代的缓慢算法，这种算法类似于自然梯度下降，同时提供更好的目标来学习模型参数。

    Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference approximating the posterior process as a linear diffusion process, point out pathologies in the approach, and propose an alternative parameterization of the Gaussian variational process using a continuous exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for the learning of model parameters.
    
[^53]: 用基于符合性的图神经网络对图上不确定性进行量化

    Uncertainty Quantification over Graph with Conformalized Graph Neural Networks. (arXiv:2305.14535v1 [cs.LG])

    [http://arxiv.org/abs/2305.14535](http://arxiv.org/abs/2305.14535)

    本文提出了一种基于符合性的图神经网络模型（CF-GNN），通过将符合性预测（CP）扩展到基于图的模型中，对GNN不确定性进行了有效估计。CF-GNN生成的预测集/区间可根据预定义的覆盖概率保证包含真实标签，并且提供了一种减少预测集大小/区间长度的拓扑意识输出校正方法。

    

    图神经网络（GNN）是一种强大的用于图结构数据预测的机器学习模型。然而，GNN缺乏严格的不确定性估计，限制了它们在错误成本显著的环境中的可靠部署。我们提出了一种符合性GNN（CF-GNN），将符合性预测（CP）扩展到基于图的模型中，以获得可靠的不确定性估计。给定图中的实体，CF-GNN生成一个预测集/区间，以先验覆盖概率（例如90%）的方式保证包含真实标签。我们建立了一个排列不变条件，使得CP在图数据上成立，并提供了测试时间覆盖率的精确特征。此外，除了有效的覆盖，减少预测集大小/区间长度对于实际使用至关重要。我们发现非符合性得分和网络结构之间存在关键联系，这促使我们开发具有拓扑意识的输出校正模型来学习更新预测。

    Graph Neural Networks (GNNs) are powerful machine learning prediction models on graph-structured data. However, GNNs lack rigorous uncertainty estimates, limiting their reliable deployment in settings where the cost of errors is significant. We propose conformalized GNN (CF-GNN), extending conformal prediction (CP) to graph-based models for guaranteed uncertainty estimates. Given an entity in the graph, CF-GNN produces a prediction set/interval that provably contains the true label with pre-defined coverage probability (e.g. 90%). We establish a permutation invariance condition that enables the validity of CP on graph data and provide an exact characterization of the test-time coverage. Moreover, besides valid coverage, it is crucial to reduce the prediction set size/interval length for practical use. We observe a key connection between non-conformity scores and network structures, which motivates us to develop a topology-aware output correction model that learns to update the predicti
    
[^54]: 三层神经网络中非线性特征学习的可证保证

    Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks. (arXiv:2305.06986v1 [cs.LG])

    [http://arxiv.org/abs/2305.06986](http://arxiv.org/abs/2305.06986)

    本文研究了三层神经网络的特征学习能力，相比之下，它具有比两层网络更丰富的可证的特征学习能力，并提出了一个通用定理，限制了目标结构的样本复杂度和宽度，以实现低测试误差。

    

    深度学习理论中的一个核心问题是理解神经网络如何学习分层特征。深度网络提取显著特征的能力对其卓越的泛化能力和现代深度学习范式的预训练和微调至关重要。然而，从理论角度来看，这种特征学习过程仍然不够清晰，现有的分析主要局限于两层网络。在本文中，我们展示了三层神经网络具有证明的比两层网络更丰富的特征学习能力。我们分析了通过逐层梯度下降训练的三层网络学习的特征，并提出了一个通用定理，它上界了目标具有特定层次结构时实现低测试错误所需的样本复杂度和宽度。我们将我们的框架实例化到特定的统计学学习设置中——单指数模型和二次函数。

    One of the central questions in the theory of deep learning is to understand how neural networks learn hierarchical features. The ability of deep networks to extract salient features is crucial to both their outstanding generalization ability and the modern deep learning paradigm of pretraining and finetuneing. However, this feature learning process remains poorly understood from a theoretical perspective, with existing analyses largely restricted to two-layer networks. In this work we show that three-layer neural networks have provably richer feature learning capabilities than two-layer networks. We analyze the features learned by a three-layer network trained with layer-wise gradient descent, and present a general purpose theorem which upper bounds the sample complexity and width needed to achieve low test error when the target has specific hierarchical structure. We instantiate our framework in specific statistical learning settings -- single-index models and functions of quadratic 
    
[^55]: 基于流形正则化 Tucker 分解的时空交通数据填充方法

    Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation. (arXiv:2305.06563v1 [stat.ML])

    [http://arxiv.org/abs/2305.06563](http://arxiv.org/abs/2305.06563)

    本文提出了一种基于流形正则化Tucker分解的时空交通数据填充方法，该方法利用稀疏正则化项改善了Tucker核的稀疏性，并引入流形正则化和时间约束项来优化张量的填充性能。

    

    时空交通数据填充(STDI)是数据驱动智能交通系统中不可避免和具有挑战性的任务，在部分观测到的交通数据中估计丢失数据。由于交通数据具有多维和时空性质，我们将丢失数据填充视为张量完成问题。过去十年中，许多关于基于张量分解的 STDI 的研究已经展开。然而，如何利用时空相关性和核张量稀疏性来改善填充性能仍然需要解决。本文重新构造了3/4阶汉克尔张量，并提出了一种创新的流形正则化 Tucker 分解(maniRTD)模型用于STDI。明确地，我们通过引入多维延迟嵌入变换将传感交通状态数据表示为3/4阶张量。然后，ManiRTD使用稀疏正则化项改善了Tucker核的稀疏性，并使用流形正则化和时间约束项来优化张量的填充性能。

    Spatiotemporal traffic data imputation (STDI), estimating the missing data from partially observed traffic data, is an inevitable and challenging task in data-driven intelligent transportation systems (ITS). Due to traffic data's multidimensional and spatiotemporal properties, we treat the missing data imputation as a tensor completion problem. Many studies have been on STDI based on tensor decomposition in the past decade. However, how to use spatiotemporal correlations and core tensor sparsity to improve the imputation performance still needs to be solved. This paper reshapes a 3rd/4th order Hankel tensor and proposes an innovative manifold regularized Tucker decomposition (ManiRTD) model for STDI. Expressly, we represent the sensory traffic state data as the 3rd/4th tensors by introducing Multiway Delay Embedding Transforms. Then, ManiRTD improves the sparsity of the Tucker core using a sparse regularization term and employs manifold regularization and temporal constraint terms of f
    
[^56]: 神经网络何时在表格数据上胜过增强树？

    When Do Neural Nets Outperform Boosted Trees on Tabular Data?. (arXiv:2305.02997v1 [cs.LG])

    [http://arxiv.org/abs/2305.02997](http://arxiv.org/abs/2305.02997)

    这项研究通过对176个数据集的比较分析发现，在许多数据集中，GBDT和NN之间的性能差异可以忽略不计，或者GBDT的轻微超参数调整比选择最佳算法更重要。此外，研究人员对965个元特征进行了分析，发现GBDT在高维稀疏数据上表现更好。

    

    表格数据是机器学习中最常用的数据类型之一。尽管神经网络（NN）在表格数据上取得了最近的进展，但人们仍在积极讨论NN是否通常优于梯度提升决策树（GBDT）在表格数据上的表现，一些最近的工作要么认为GBDT在表格数据上一贯优于NN，要么认为NN优于GBDT。在这项工作中，我们退一步问：'这重要吗？'我们通过对176个数据集比较19种算法，进行了迄今为止最大的表格数据分析，并发现'NN vs. GBDT'争论被过分强调：令人惊讶的是，在相当多的数据集中，GBDT和NN之间的性能差异要么可以忽略不计，要么GBDT的轻微超参数调整比选择最佳算法更重要。接下来，我们分析了965个元特征，以确定数据集的哪些特性使NN或GBDT更适合表现良好。例如，我们发现GBDT要比NN在高维稀疏数据上表现更好。

    Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and ask, 'does it matter?' We conduct the largest tabular data analysis to date, by comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than selecting the best algorithm. Next, we analyze 965 metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better th
    
[^57]: 高维超统计特征的分类方法

    Classification of Superstatistical Features in High Dimensions. (arXiv:2304.02912v1 [stat.ML])

    [http://arxiv.org/abs/2304.02912](http://arxiv.org/abs/2304.02912)

    本文利用经验风险最小化的方法，对高维超统计特征下的数据进行分类，并分析了正则化和分布尺度参数对分类的影响。

    

    在高维情况下，我们通过经验风险最小化的方法，对具有一般中心点的两个数据云的混合进行了学习，假设具有通用的凸损失和凸正则化。每个数据云是通过从可能是不可数的高斯分布叠加中进行采样来获得的，其方差具有通用的概率密度$\varrho$。我们的分析涵盖了大量的数据分布，包括没有协方差的幂律尾部分布的情况。我们研究了所得估计器的泛化性能，分析了正则化的作用以及分离转换与分布尺度参数的相关性。

    We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation. Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance. We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters.
    
[^58]: 无碰撞运输图在流行学习中的应用

    Applications of No-Collision Transportation Maps in Manifold Learning. (arXiv:2304.00199v1 [cs.LG])

    [http://arxiv.org/abs/2304.00199](http://arxiv.org/abs/2304.00199)

    本文研究了在流形学习中应用无碰撞运输图的方法，其可以比OT图更便宜地计算距离，并提供单个概率测度的平移和伸缩的等距性。

    

    本文研究了引入于[Nurbekyan et al.，2020]的无碰撞运输图在图像数据的流形学习中的应用。近年来，在表示类似运动或变形现象的数据中，应用基于运输的距离和特征的研究大幅增加。事实上，固定位置比较强度通常无法显示数据结构。在[Nurbekyan et al.，2020]中开发的无碰撞图和距离类似于最优传输(OT)图的几何特征但由于无需优化，计算成本要便宜得多。本文证明无碰撞距离提供单个概率测度的平移(分别是伸缩)和装备欧几里得距离的平移(分别是伸缩)向量之间的等距性。此外，我们证明，无碰撞运输图以及OT和线性OT图，一般来说不能为旋转提供等距性。

    In this work, we investigate applications of no-collision transportation maps introduced in [Nurbekyan et. al., 2020] in manifold learning for image data. Recently, there has been a surge in applying transportation-based distances and features for data representing motion-like or deformation-like phenomena. Indeed, comparing intensities at fixed locations often does not reveal the data structure. No-collision maps and distances developed in [Nurbekyan et. al., 2020] are sensitive to geometric features similar to optimal transportation (OT) maps but much cheaper to compute due to the absence of optimization. In this work, we prove that no-collision distances provide an isometry between translations (respectively dilations) of a single probability measure and the translation (respectively dilation) vectors equipped with a Euclidean distance. Furthermore, we prove that no-collision transportation maps, as well as OT and linearized OT maps, do not in general provide an isometry for rotatio
    
[^59]: 一种用于学习表示视觉转换的极坐标预测模型

    A polar prediction model for learning to represent visual transformations. (arXiv:2303.03432v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.03432](http://arxiv.org/abs/2303.03432)

    一种新的自监督表示学习框架，利用自然视频的规律进行准确预测，并发现了在数据中的简单变换群的表示。

    

    所有生物都会做时间预测，并且它们的进化适应度取决于这些预测的准确性。在视觉感知的情境下，观察者和场景中物体的运动构成了感官信号的动态，使得可以基于过去的信号部分预测未来的信号。在这里，我们提出了一种自监督的表示学习框架，它提取和利用自然视频的规律来计算准确的预测。我们通过引用Fourier移位定理及其群论推广来展示了极坐标架构的动机，并通过对下一帧预测进行参数优化。通过对比实验证明，这种方法能够发现在数据中作用的简单变换群的表示。当在自然视频数据集上进行训练时，我们的框架实现了比传统的运动补偿更好的预测性能，并且与传统的深度网络不相上下，同时保持了...

    All organisms make temporal predictions, and their evolutionary fitness level depends on the accuracy of these predictions. In the context of visual perception, the motions of both the observer and objects in the scene structure the dynamics of sensory signals, allowing for partial prediction of future signals based on past ones. Here, we propose a self-supervised representation-learning framework that extracts and exploits the regularities of natural videos to compute accurate predictions. We motivate the polar architecture by appealing to the Fourier shift theorem and its group-theoretic generalization, and we optimize its parameters on next-frame prediction. Through controlled experiments, we demonstrate that this approach can discover the representation of simple transformation groups acting in data. When trained on natural video datasets, our framework achieves better prediction performance than traditional motion compensation and rivals conventional deep networks, while maintaini
    
[^60]: 隐含偏见的双刃剑：ReLU网络中的泛化与鲁棒性比较

    The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness in ReLU Networks. (arXiv:2303.01456v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01456](http://arxiv.org/abs/2303.01456)

    这项研究研究了ReLU网络中梯度流的隐式偏差对泛化和对抗鲁棒性的影响，发现梯度流倾向于泛化能力强但对抗性高的解决方案，并且这种偏差还导致非鲁棒性解决方案的出现。

    

    在这项工作中，我们研究了梯度流的隐式偏差对ReLU网络中泛化和对抗鲁棒性的影响。我们关注的是数据由簇组成且簇之间的相关性较小的情况，并且发现在两层ReLU网络中，梯度流在偏向泛化能力强的解决方案的同时也对小规模对抗性例子高度脆弱。我们的结果即使在网络参数远远多余训练样本的情况下也成立。尽管在这种过度参数化的设置中有潜在的有害过拟合可能性，我们证明梯度流的隐式偏差可以防止这种情况发生。然而，隐式偏差也会导致非鲁棒性的解决方案（容易受到小的对抗性$\ell_2$扰动），尽管也存在能够拟合数据的鲁棒网络。

    In this work, we study the implications of the implicit bias of gradient flow on generalization and adversarial robustness in ReLU networks. We focus on a setting where the data consists of clusters and the correlations between cluster means are small, and show that in two-layer ReLU networks gradient flow is biased towards solutions that generalize well, but are highly vulnerable to adversarial examples. Our results hold even in cases where the network has many more parameters than training examples. Despite the potential for harmful overfitting in such overparameterized settings, we prove that the implicit bias of gradient flow prevents it. However, the implicit bias also leads to non-robust solutions (susceptible to small adversarial $\ell_2$-perturbations), even though robust networks that fit the data exist.
    
[^61]: 数据修剪和神经缩放定律：基于评分的算法的基本限制

    Data pruning and neural scaling laws: fundamental limitations of score-based algorithms. (arXiv:2302.06960v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.06960](http://arxiv.org/abs/2302.06960)

    评分数据修剪算法在高压缩区域失败，通过随机化的校准协议可以提高现有修剪算法在该区域的性能。

    

    数据修剪算法常用于减少优化过程的内存和计算成本。最近的实证结果表明，随机数据修剪仍然是一个强大的基准，并在高压缩区域优于大多数现有的数据修剪方法，即保留了不到数据的30％的部分。这种压缩区域最近引起了很多关注，因为数据修剪在提高所谓的神经缩放定律中的作用；在[Sorscher et al.]中，作者展示了需要高质量的数据修剪算法才能击败样本势律。在这项工作中，我们关注评分数据修剪算法，并在理论上和实际上展示了为什么这样的算法在高压缩区域失败。我们证明了数据修剪的“没有免费午餐”定理，并通过随机化提出了校准协议，以提高现有修剪算法在高压缩区域的性能。

    Data pruning algorithms are commonly used to reduce the memory and computational cost of the optimization process. Recent empirical results reveal that random data pruning remains a strong baseline and outperforms most existing data pruning methods in the high compression regime, i.e., where a fraction of $30\%$ or less of the data is kept. This regime has recently attracted a lot of interest as a result of the role of data pruning in improving the so-called neural scaling laws; in [Sorscher et al.], the authors showed the need for high-quality data pruning algorithms in order to beat the sample power law.  In this work, we focus on score-based data pruning algorithms and show theoretically and empirically why such algorithms fail in the high compression regime. We demonstrate ``No Free Lunch" theorems for data pruning and present calibration protocols that enhance the performance of existing pruning algorithms in this high compression regime using randomization.
    
[^62]: 偶然性和认知性歧视：公平干预的基本限制

    Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions. (arXiv:2301.11781v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11781](http://arxiv.org/abs/2301.11781)

    该论文研究了机器学习模型中的偶然性和认知性歧视，将其分类为数据分布中固有的歧视和模型开发过程中的决策导致的歧视。通过量化偶然性歧视的性能限制和刻画认知性歧视，揭示了公平干预的基本限制。研究还应用这种方法评估了现有的公平干预措施，并探究了在存在缺失值的数据中的公平风险。

    

    机器学习模型在某些人群中可能表现不佳，原因是在模型开发过程中做出的选择和数据中固有的偏见。我们将机器学习流程中的歧视来源分为两类：偶然性歧视，即数据分布中固有的歧视，和认知性歧视，即模型开发过程中做出的决策导致的歧视。我们通过确定在完全了解数据分布的情况下，在公平约束下模型的性能限制来量化偶然性歧视。我们通过应用布莱克韦尔对比统计实验的结果来刻画偶然性歧视。然后，我们将认知性歧视定义为在应用公平约束时模型的准确性与偶然性歧视所限定的界限之间的差距。我们将这种方法应用于评估现有的公平干预措施，并调查具有缺失值的数据中的公平风险。我们的结果表明...

    Machine learning (ML) models can underperform on certain population groups due to choices made during model development and bias inherent in the data. We categorize sources of discrimination in the ML pipeline into two classes: aleatoric discrimination, which is inherent in the data distribution, and epistemic discrimination, which is due to decisions made during model development. We quantify aleatoric discrimination by determining the performance limits of a model under fairness constraints, assuming perfect knowledge of the data distribution. We demonstrate how to characterize aleatoric discrimination by applying Blackwell's results on comparing statistical experiments. We then quantify epistemic discrimination as the gap between a model's accuracy when fairness constraints are applied and the limit posed by aleatoric discrimination. We apply this approach to benchmark existing fairness interventions and investigate fairness risks in data with missing values. Our results indicate th
    
[^63]: 多组分的稀疏主成分分析

    Sparse PCA With Multiple Components. (arXiv:2209.14790v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2209.14790](http://arxiv.org/abs/2209.14790)

    本研究提出了一种新的方法来解决稀疏主成分分析问题，通过将正交性条件重新表述为秩约束，并同时对稀疏性和秩约束进行优化。我们设计了紧凑的半正定松弛来提供高质量的上界，当每个主成分的个体稀疏性被指定时，我们通过额外的二阶锥不等式加强上界。

    

    稀疏主成分分析是一种用于以可解释的方式解释高维数据集方差的基本技术。这涉及解决一个稀疏性和正交性约束的凸最大化问题，其计算复杂度非常高。大多数现有的方法通过迭代计算一个稀疏主成分并缩减协方差矩阵来解决稀疏主成分分析，但在寻找多个相互正交的主成分时，这些方法不能保证所得解的正交性和最优性。我们挑战这种现状，通过将正交性条件重新表述为秩约束，并同时对稀疏性和秩约束进行优化。我们设计了紧凑的半正定松弛来提供高质量的上界，当每个主成分的个体稀疏性被指定时，我们通过额外的二阶锥不等式加强上界。此外，我们采用另一种方法来加强上界，我们使用额外的二阶锥不等式来加强上界。

    Sparse Principal Component Analysis (sPCA) is a cardinal technique for obtaining combinations of features, or principal components (PCs), that explain the variance of high-dimensional datasets in an interpretable manner. This involves solving a sparsity and orthogonality constrained convex maximization problem, which is extremely computationally challenging. Most existing works address sparse PCA via methods-such as iteratively computing one sparse PC and deflating the covariance matrix-that do not guarantee the orthogonality, let alone the optimality, of the resulting solution when we seek multiple mutually orthogonal PCs. We challenge this status by reformulating the orthogonality conditions as rank constraints and optimizing over the sparsity and rank constraints simultaneously. We design tight semidefinite relaxations to supply high-quality upper bounds, which we strengthen via additional second-order cone inequalities when each PC's individual sparsity is specified. Further, we de
    
[^64]: 基于双逻辑回归的有偏正无标记数据方法

    Double logistic regression approach to biased positive-unlabeled data. (arXiv:2209.07787v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.07787](http://arxiv.org/abs/2209.07787)

    该论文提出了一种基于双逻辑回归的方法，用于处理存在偏差的正向无标记数据。通过避免假设倾向得分函数为常数，作者共同估计后验概率和倾向得分函数，并提出了两种估计方法。实验结果显示，所提出的方法与现有的基于期望最大化方案的方法相比是可比较或更优的。

    

    正向和无标记学习是许多应用中自然产生的重要问题。几乎所有现有方法的一个显著限制在于假设倾向得分函数是常数（SCAR假设），这在许多实际情况下是不现实的。为了避免这种假设，我们考虑了参数化方法来共同估计后验概率和倾向得分函数的问题。我们证明，在温和的假设下，当两个函数具有相同的参数形式时（例如具有不同参数的逻辑函数），相应的参数是可识别的。在此基础上，我们提出了两种估计方法：联合最大似然方法和基于两个Fisher一致表达式的交替最大化的第二种方法。我们的实验结果表明，所提出的方法与基于期望最大化方案的现有方法可比较或更优。

    Positive and unlabelled learning is an important problem which arises naturally in many applications. The significant limitation of almost all existing methods lies in assuming that the propensity score function is constant (SCAR assumption), which is unrealistic in many practical situations. Avoiding this assumption, we consider parametric approach to the problem of joint estimation of posterior probability and propensity score functions. We show that under mild assumptions when both functions have the same parametric form (e.g. logistic with different parameters) the corresponding parameters are identifiable. Motivated by this, we propose two approaches to their estimation: joint maximum likelihood method and the second approach based on alternating maximization of two Fisher consistent expressions. Our experimental results show that the proposed methods are comparable or better than the existing methods based on Expectation-Maximisation scheme.
    
[^65]: 分布式OMP的恢复保证

    Recovery Guarantees for Distributed-OMP. (arXiv:2209.07230v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.07230](http://arxiv.org/abs/2209.07230)

    该论文研究了基于正交匹配追踪的分布式方案在高维稀疏线性回归中的应用。通过适当的假设，分布式OMP方案能够以较低的信噪比下实现线性通信复杂度，并能与更复杂的方法相竞争。

    

    我们研究了基于正交匹配追踪(OMP)的高维稀疏线性回归的分布式方案。这种方案特别适用于有计算和通信限制的末端机器连接到中央融合中心的设置。我们证明，在适当的假设下，分布式OMP方案能够以与稀疏度线性和维度对数成比例的通信恢复回归向量的支持。值得注意的是，即使在信噪比低的情况下，单个机器也无法检测到支持时，这仍然成立。我们的模拟结果表明，分布式OMP方案与更计算密集的方法竞争，并在某些情况下甚至表现更好。

    We study distributed schemes for high-dimensional sparse linear regression, based on orthogonal matching pursuit (OMP). Such schemes are particularly suited for settings where a central fusion center is connected to end machines, that have both computation and communication limitations. We prove that under suitable assumptions, distributed-OMP schemes recover the support of the regression vector with communication per machine linear in its sparsity and logarithmic in the dimension. Remarkably, this holds even at low signal-to-noise-ratios, where individual machines are unable to detect the support. Our simulations show that distributed-OMP schemes are competitive with more computationally intensive methods, and in some cases even outperform them.
    
[^66]: R\'enyi和近似差分隐私中通过洗牌实现更强隐私放大效果

    Stronger Privacy Amplification by Shuffling for R\'enyi and Approximate Differential Privacy. (arXiv:2208.04591v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2208.04591](http://arxiv.org/abs/2208.04591)

    本研究在R\'enyi和近似差分隐私中通过洗牌提出了更强隐私放大的方法，并对理论和数值进行了改进和优化。

    

    差分隐私的洗牌模型作为标准本地和集中模型之间的一种中间信任模型，引起了极大的关注。在该模型中的一个关键结果是，随机洗牌本地随机化数据可以放大差分隐私的保证。这种放大效果意味着对于匿名贡献数据的系统而言，隐私保证会更加强大。本研究在理论和数值上改进了洗牌导致的隐私放大效果。首先，我们首次提出了LDP随机化器洗牌输出的R\'enyi差分隐私参数的渐近最优分析。其次，我们对隐私放大效果进行了新的分析，改进了[FMT20]的技术，并在所有参数设置下得到了更紧密的数值界限。

    The shuffle model of differential privacy has gained significant interest as an intermediate trust model between the standard local and central models [EFMRTT19; CSUZZ19]. A key result in this model is that randomly shuffling locally randomized data amplifies differential privacy guarantees. Such amplification implies substantially stronger privacy guarantees for systems in which data is contributed anonymously [BEMMRLRKTS17].  In this work, we improve the state of the art privacy amplification by shuffling results both theoretically and numerically. Our first contribution is the first asymptotically optimal analysis of the R\'enyi differential privacy parameters for the shuffled outputs of LDP randomizers. Our second contribution is a new analysis of privacy amplification by shuffling. This analysis improves on the techniques of [FMT20] and leads to tighter numerical bounds in all parameter settings.
    
[^67]: DAMNETS：一种用于生成马尔可夫网络时间序列的深度自回归模型

    DAMNETS: A Deep Autoregressive Model for Generating Markovian Network Time Series. (arXiv:2203.15009v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.15009](http://arxiv.org/abs/2203.15009)

    DAMNETS是一种用于生成马尔可夫网络时间序列的深度自回归模型，通过在真实数据和合成数据集上的表现超过竞争方法，达到了设计灵活且可扩展的生成模型的目标。

    

    生成模型在网络时间序列（也称为动态图）中具有巨大的潜力，可以应用于流行病学、生物学和经济学等领域，其中复杂的基于图的动态是核心研究对象。由于数据的高维度以及表示时间依赖性和边际网络结构的需要，设计灵活且可扩展的生成模型是一项非常具有挑战性的任务。在这里，我们介绍了一种名为DAMNETS的可扩展深度生成模型，它在真实数据和合成数据集上的所有样本质量指标上表现优于竞争方法。

    Generative models for network time series (also known as dynamic graphs) have tremendous potential in fields such as epidemiology, biology and economics, where complex graph-based dynamics are core objects of study. Designing flexible and scalable generative models is a very challenging task due to the high dimensionality of the data, as well as the need to represent temporal dependencies and marginal network structure. Here we introduce DAMNETS, a scalable deep generative model for network time series. DAMNETS outperforms competing methods on all of our measures of sample quality, over both real and synthetic data sets.
    
[^68]: 一类稳定高效的强化学习用替代函数的普适框架

    A general class of surrogate functions for stable and efficient reinforcement learning. (arXiv:2108.05828v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.05828](http://arxiv.org/abs/2108.05828)

    本研究提出了一个基于函数镜像上升的普适框架(FMA-PG)，构建了一系列替代函数，这些函数可以实现策略改进，并且不受策略参数化选择的影响。通过实验证实，该方法具有良好的性能和理论保证。

    

    传统的策略梯度方法依赖于一系列替代函数的最大化。近年来，提出了许多这样的替代函数，大多数没有强有力的理论保证，从而导致了TRPO、PPO或MPO等算法的出现。我们不是设计另一个替代函数，而是提出了一个基于函数镜像上升的普适框架（FMA-PG），从而产生了一整套替代函数。我们构建了替代函数，使其能够保证策略改进，这是大多数现有替代函数所没有的特性。关键是，这些保证不受策略参数化选择的影响。此外，FMA-PG的特定实例恢复了重要的实现启发式方法（例如，使用前向和反向KL散度），从而产生了具有额外理想性质的TRPO变种。通过在简单贝叶斯问题上进行实验，我们评估了FMA-PG产生的算法实例。该框架也支持其他应用。

    Common policy gradient methods rely on the maximization of a sequence of surrogate functions. In recent years, many such surrogate functions have been proposed, most without strong theoretical guarantees, leading to algorithms such as TRPO, PPO or MPO. Rather than design yet another surrogate function, we instead propose a general framework (FMA-PG) based on functional mirror ascent that gives rise to an entire family of surrogate functions. We construct surrogate functions that enable policy improvement guarantees, a property not shared by most existing surrogate functions. Crucially, these guarantees hold regardless of the choice of policy parameterization. Moreover, a particular instantiation of FMA-PG recovers important implementation heuristics (e.g., using forward vs reverse KL divergence) resulting in a variant of TRPO with additional desirable properties. Via experiments on simple bandit problems, we evaluate the algorithms instantiated by FMA-PG. The proposed framework also su
    
[^69]: Helmholtzian特征图：从点云数据中发现拓扑特征和边缘流学习

    Helmholtzian Eigenmap: Topological feature discovery & edge flow learning from point cloud data. (arXiv:2103.07626v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2103.07626](http://arxiv.org/abs/2103.07626)

    本论文提出了一种从点云数据中估计流形Helmholtzian的方法，通过加权1-Laplacian构建了图Helmholtzian作为连续算子的一致估计器，并利用Helmholtz-Hodge定理对流和向量场进行分析。通过该方法，可以对流进行平滑、预测和特征提取。

    

    流形Helmholtzian（1-Laplacian）算子$ \Delta_1 $将Laplace-Beltrami算子优雅地广义化到流形$ \mathcal M $上的向量场。在本工作中，我们提出了通过加权1-Laplacian $ \mathcal L_1 $从点云数据估计流形Helmholtzian的方法。虽然已经引入和研究了高阶Laplacian，但本工作是首次提出了从单纯复合物构建的图Helmholtzian作为连续算子在非参数设置中的一致估计器。具备关于$ \mathcal M $的几何和拓扑信息的Helmholtzian是通过Helmholtz-Hodge定理对$ \mathcal M $上的流和向量场进行分析的有用工具。此外，$ \mathcal L_1 $允许对流进行平滑、预测和特征提取。我们在具有非平凡拓扑结构的大量合成和真实点云数据集上展示了这些可能性，并提供了理论依据。

    The manifold Helmholtzian (1-Laplacian) operator $\Delta_1$ elegantly generalizes the Laplace-Beltrami operator to vector fields on a manifold $\mathcal M$. In this work, we propose the estimation of the manifold Helmholtzian from point cloud data by a weighted 1-Laplacian $\mathcal L_1$. While higher order Laplacians have been introduced and studied, this work is the first to present a graph Helmholtzian constructed from a simplicial complex as a consistent estimator for the continuous operator in a non-parametric setting. Equipped with the geometric and topological information about $\mathcal M$, the Helmholtzian is a useful tool for the analysis of flows and vector fields on $\mathcal M$ via the Helmholtz-Hodge theorem. In addition, the $\mathcal L_1$ allows the smoothing, prediction, and feature extraction of the flows. We demonstrate these possibilities on substantial sets of synthetic and real point cloud datasets with non-trivial topological structures; and provide theoretical r
    
[^70]: 异常鲁棒的稀疏/低秩最小二乘回归和鲁棒矩阵完成

    Outlier-robust sparse/low-rank least-squares regression and robust matrix completion. (arXiv:2012.06750v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2012.06750](http://arxiv.org/abs/2012.06750)

    该论文研究了带异质噪声的高维最小二乘回归问题，包括稀疏和低秩最小二乘回归。研究者提出了新颖的"亚高斯"估计速率，并在不同概率下有效。此外，还提出了一种新近优的处理方法用于有噪声的鲁棒矩阵完成问题。

    

    我们在具有异质噪声的亚高斯统计学习框架中研究高维最小二乘回归。当标签的一部分受到对抗性污染时，它包括$s$-稀疏和$r$-低秩最小二乘回归。我们还提出了一种基于新的乘积过程的矩阵分解的迹回归的新理论应用。对于这些问题，我们展示了新颖的"亚高斯"估计速率形式$r(n,d_{e})+\sqrt{\log(1/\delta)/n}+\epsilon\log(1/\epsilon)$，以至少概率$1-\delta$成立。这里，$r(n,d_{e})$是作为有效维度$d_{e}$的函数而独立于失败概率$\delta$的最优无污染速率。这些速率在$\delta$上是一致有效的，即估计器的调优不依赖于$\delta$。最后，我们考虑具有非均匀采样的有噪声的鲁棒矩阵完成问题。如果只对低秩矩阵感兴趣，我们提出了一种新近优的方法

    We study high-dimensional least-squares regression within a subgaussian statistical learning framework with heterogeneous noise. It includes $s$-sparse and $r$-low-rank least-squares regression when a fraction $\epsilon$ of the labels are adversarially contaminated. We also present a novel theory of trace-regression with matrix decomposition based on a new application of the product process. For these problems, we show novel near-optimal "subgaussian" estimation rates of the form $r(n,d_{e})+\sqrt{\log(1/\delta)/n}+\epsilon\log(1/\epsilon)$, valid with probability at least $1-\delta$. Here, $r(n,d_{e})$ is the optimal uncontaminated rate as a function of the effective dimension $d_{e}$ but independent of the failure probability $\delta$. These rates are valid uniformly on $\delta$, i.e., the estimators' tuning do not depend on $\delta$. Lastly, we consider noisy robust matrix completion with non-uniform sampling. If only the low-rank matrix is of interest, we present a novel near-optim
    
[^71]: 合成干预

    Synthetic Interventions. (arXiv:2006.07691v6 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2006.07691](http://arxiv.org/abs/2006.07691)

    提出了一个称为合成干预的因果框架，能够在观察到每个单元最多两个干预措施的情况下推断每个单元对每个干预措施的预期潜在结果，具有有限样本一致性和渐近正态性。

    

    考虑一个拥有$N$个异质单元（例如个体或子群体）和$D$个干预措施（例如社会经济政策）的情景。我们的目标是学习每个单元对每个干预措施的预期潜在结果，总共有$N \times D$个因果参数。为此，我们提出了一个因果框架——合成干预（SI），以推断这$N \times D$个因果参数，同时仅观察每个单元在最多两个干预措施下的情况，与$D$无关。当个性化水平增加时，这将具有重要意义。在一个新的张量因子模型下，跨单元、结果和干预措施，我们证明了这$N \times D$个因果参数的识别结果，并在附加条件下证明了我们估计值的有限样本一致性和渐近正态性。重要的是，我们的估计器还允许存在决定干预分配方式的潜在混淆因素。

    Consider a setting with $N$ heterogeneous units (e.g., individuals, sub-populations) and $D$ interventions (e.g., socio-economic policies). Our goal is to learn the expected potential outcome associated with every intervention on every unit, totaling $N \times D$ causal parameters. Towards this, we present a causal framework, synthetic interventions (SI), to infer these $N \times D$ causal parameters while only observing each of the $N$ units under at most two interventions, independent of $D$. This can be significant as the number of interventions, i.e., level of personalization, grows. Under a novel tensor factor model across units, outcomes, and interventions, we prove an identification result for each of these $N \times D$ causal parameters, establish finite-sample consistency of our estimator along with asymptotic normality under additional conditions. Importantly, our estimator also allows for latent confounders that determine how interventions are assigned. The estimator is furt
    
[^72]: 重访多智能体深度强化学习中的参数共享

    Revisiting Parameter Sharing in Multi-Agent Deep Reinforcement Learning. (arXiv:2005.13625v8 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.13625](http://arxiv.org/abs/2005.13625)

    本研究重访了多智能体深度强化学习中的参数共享方法。我们通过引入智能体指示信号实现了在不同策略网络共享参数的同时学习不同策略或任务的能力，并且证明了这些方法在异构观测和行动空间学习中可以收敛到最优策略。

    

    参数共享是多智能体深度强化学习中一种常用的基准方法，每个智能体都独立学习一个策略，并且所有策略之间共享参数。然而，由于所有智能体共享同一策略网络，它们无法学习不同的策略或任务。为了解决这个问题，我们通过向观测中添加智能体特定的指示信号（称为“智能体指示”）来进行实验性的改进。然而，智能体指示的局限在于，如果不进行修改，它无法应用于行动空间和/或观测空间不同质的环境。本研究正式定义了智能体指示的概念，并证明了它首次实现了收敛到最优策略。接下来，我们正式介绍了扩展参数共享到异构观测和行动空间学习的方法，并证明了这些方法可以实现收敛到最优策略。最后，我们进行了实验验证并对比了各种方法的性能。

    Parameter sharing, where each agent independently learns a policy with fully shared parameters between all policies, is a popular baseline method for multi-agent deep reinforcement learning. Unfortunately, since all agents share the same policy network, they cannot learn different policies or tasks. This issue has been circumvented experimentally by adding an agent-specific indicator signal to observations, which we term "agent indication". Agent indication is limited, however, in that without modification it does not allow parameter sharing to be applied to environments where the action spaces and/or observation spaces are heterogeneous. This work formalizes the notion of agent indication and proves that it enables convergence to optimal policies for the first time. Next, we formally introduce methods to extend parameter sharing to learning in heterogeneous observation and action spaces, and prove that these methods allow for convergence to optimal policies. Finally, we experimentally
    
[^73]: 利用未标记数据扩展类别的开放集学习（Open-LACU）

    Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2002.01368](http://arxiv.org/abs/2002.01368)

    Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。

    

    对于半监督学习（SSL）和开放式识别（OSR），已经进行了许多尝试以合成单个训练策略。然而，每次尝试都违反了开放集定义，因为这些方法在未标记的训练集中包含新颖的类别。本研究提出了一种新的学习策略，其中分类器能够在观察到的和未观察到的新颖类别之间进行推广，从而定义了观察到新颖类别的背景类别和未观察到新颖类别的未知类别。通过分类这两种新颖类别的方式，Open-LACU能够提高训练的成本效益性，并确保在存在未观察到的新颖类别时进行安全分类。

    Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
    
[^74]: 加权赌博机或者：赌博机如何学习预期之外的扭曲价值

    Weighted bandits or: How bandits learn distorted values that are not expected. (arXiv:1611.10283v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1611.10283](http://arxiv.org/abs/1611.10283)

    本论文研究了带有扭曲概率的随机多臂赌博机问题，并提出了以UCB算法为基础、考虑了奖励扭曲并具有次线性后悔的算法。

    

    受到用于解释常见偏离传统预期价值偏好的人类决策模型的启发，我们提出了两个带有扭曲概率的随机多臂赌博机问题：经典的K臂赌博机和线性参数化赌博机设置。我们在对多臂赌博机的后悔最小化和最佳臂识别框架下研究了上述问题。对于K臂赌博机以及线性赌博机问题的后悔最小化设置，我们提出了受到上置信界(UCB)算法启发、包含奖励扭曲并且具有次线性后悔的算法。对于K臂赌博机设置，我们得出了对我们提出的算法的预期后悔的上界，然后我们证明了一个匹配的下界，以验证我们算法的次线性优化顺序。对于线性参数化设置，我们的算法实现了一个后悔上界，该上界是次线性的。

    Motivated by models of human decision making proposed to explain commonly observed deviations from conventional expected value preferences, we formulate two stochastic multi-armed bandit problems with distorted probabilities on the reward distributions: the classic $K$-armed bandit and the linearly parameterized bandit settings. We consider the aforementioned problems in the regret minimization as well as best arm identification framework for multi-armed bandits. For the regret minimization setting in $K$-armed as well as linear bandit problems, we propose algorithms that are inspired by Upper Confidence Bound (UCB) algorithms, incorporate reward distortions, and exhibit sublinear regret. For the $K$-armed bandit setting, we derive an upper bound on the expected regret for our proposed algorithm, and then we prove a matching lower bound to establish the order-optimality of our algorithm. For the linearly parameterized setting, our algorithm achieves a regret upper bound that is of the 
    

