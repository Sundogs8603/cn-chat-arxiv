# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Tutorial on the Non-Asymptotic Theory of System Identification.](http://arxiv.org/abs/2309.03873) | 这个教程介绍了系统识别中最近发展的非渐近方法、强调了覆盖技术、Hanson-Wright不等式和自标准化马丁格尔法等工具的应用、并给出了利用这些工具简化证明的最小二乘估计器在自回归模型中参数识别中的性能、最后介绍了将这些思想扩展到某些非线性识别问题的方法。 |
| [^2] | [Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples.](http://arxiv.org/abs/2309.03847) | 通过多项式数量的样本和差分隐私约束，我们提出了一个可以估计高斯混合物的方法，并证明了这个方法的有效性，而无需对GMMs做任何结构性假设。 |
| [^3] | [Gradient-Based Feature Learning under Structured Data.](http://arxiv.org/abs/2309.03843) | 本论文研究了基于梯度的结构化数据特征学习的问题，发现了在非各向异性设置中，常用的球形梯度动力学可能无法恢复真实方向，并提出了一个适当的权重归一化方法来解决这个问题。通过利用输入协方差与目标之间的对齐，可以获得比各向同性情况更好的样本复杂度。 |
| [^4] | [Early warning via transitions in latent stochastic dynamical systems.](http://arxiv.org/abs/2309.03842) | 本研究提出了一种基于定向异性扩散图的方法，通过捕捉低维流形中的潜在演化动态，能够有效提取早期警报信号来检测复杂系统或高维观测数据中的动力学转变，并在真实的脑电图数据上得到了验证。 |
| [^5] | [Empirical Risk Minimization for Losses without Variance.](http://arxiv.org/abs/2309.03818) | 本文研究了在重尾分布条件下的经验风险最小化问题，通过最小化风险值选择优化器，并通过使用广义通用链方法建立了过度风险的上界。数值研究表明，通过Catoni风格估计的经验风险优化器比其他基准表现更好。 |
| [^6] | [Improved theoretical guarantee for rank aggregation via spectral method.](http://arxiv.org/abs/2309.03808) | 本论文通过谱方法改进了排名聚合问题的理论保证，通过研究基于未归一化和归一化数据矩阵的谱排名算法，提供了更准确的扰动误差界限。 |
| [^7] | [Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck.](http://arxiv.org/abs/2309.03800) | 本研究研究了深度学习算法设计中的微妙选择，特别关注计算统计差距。通过理论和实验，发现稀疏初始化和增加网络宽度可以提高样本效率，并且合成稀疏奇偶任务可以作为真实问题的代理。 |
| [^8] | [Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences.](http://arxiv.org/abs/2309.03791) | 本论文介绍了一种新的方法ARMOR_D来加强深度学习模型的对抗鲁棒性，该方法基于最优传输正则化差异，通过在分布的邻域上进行最大化期望损失来实现。实验证明，ARMOR_D方法在恶意软件检测和图像识别应用中能够优于现有方法，在对抗攻击下的鲁棒性方面具有较好的效果。 |
| [^9] | [Neural lasso: a unifying approach of lasso and neural networks.](http://arxiv.org/abs/2309.03770) | 本文提出了一种神经套索方法，将套索和神经网络相结合，通过模仿统计框架进行修改的方式，在变量选择中提供更准确的参数估计。 |
| [^10] | [Medoid Silhouette clustering with automatic cluster number selection.](http://arxiv.org/abs/2309.03751) | 本文介绍了一种具有自动聚类数量选择的中心轮廓聚类算法，其中结合了原始轮廓系数和PAM算法的思想，并通过两种快速版本进行了理论分析和实验验证，在实验中获得了显著的加速效果。 |
| [^11] | [Enhancing Pipeline-Based Conversational Agents with Large Language Models.](http://arxiv.org/abs/2309.03748) | 本文研究了如何使用大型语言模型（LLM）来增强基于流水线的对话系统。在设计和开发阶段，LLM可以帮助生成训练数据、提取实体和同义词、本地化和角色设计。在运营阶段，LLM可以辅助上下文化、意图分类、自动纠正话语、改写回复、摘要和使闭合问题回答能力。通过在私人银行领域的实验，证明了这些能力的有效性。 |
| [^12] | [A Probabilistic Semi-Supervised Approach with Triplet Markov Chains.](http://arxiv.org/abs/2309.03707) | 本文提出了一种基于变分贝叶斯推断的通用框架，用于在半监督的情况下训练参数化的三元马尔科夫链模型，并且能够针对各种生成模型推导出半监督算法，用于顺序贝叶斯分类。 |
| [^13] | [Trinary Decision Trees for missing value handling.](http://arxiv.org/abs/2309.03561) | 本文介绍了一种称为三值决策树的算法，用于改善决策树在处理缺失数据时的表现。与其他方法不同，该算法不假设缺失值包含任何关于响应的信息。实验证明，在特定缺失数据场景下，三值决策树在MCAR设置中表现优异，在IM设置中略逊一筹。同时，通过将三值决策树与缺失在属性方法相结合，可以获得更稳健的性能。尽管训练速度较慢，但三值决策树提供了一种有前途且更准确的方法。 |
| [^14] | [On the dynamics of multi agent nonlinear filtering and learning.](http://arxiv.org/abs/2309.03557) | 本文研究了具有非线性滤波/学习动力学的多智能体网络系统的行为，并介绍了在分布式和联邦学习场景中的应用。 |
| [^15] | [Ensemble linear interpolators: The role of ensembling.](http://arxiv.org/abs/2309.03354) | 本文研究了集成线性插值器如何稳定和提升个体插值器的泛化性能，并引入了基于乘数自助法的袋装最小二乘估计器。在比例区域内，研究了简化和袋装的外样本预测风险。 |
| [^16] | [Knowledge Distillation Layer that Lets the Student Decide.](http://arxiv.org/abs/2309.02843) | 本论文提出了一个可学习的知识蒸馏层，能够明确地嵌入教师的知识到学生的特征变换中，从而改进了知识蒸馏技术。 |
| [^17] | [Causal thinking for decision making on Electronic Health Records: why and how.](http://arxiv.org/abs/2308.01605) | 本文介绍了在电子健康记录中使用因果思维进行决策的必要性和方法。通过模拟随机试验来个性化决策，以减少数据中的偏见。这对于分析电子健康记录或索赔数据以得出因果结论的最重要陷阱和考虑因素进行了重点强调。 |
| [^18] | [Deep Network Approximation: Beyond ReLU to Diverse Activation Functions.](http://arxiv.org/abs/2307.06555) | 本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。 |
| [^19] | [Explanation Shift: Investigating Interactions between Models and Shifting Data Distributions.](http://arxiv.org/abs/2303.08081) | 该论文提出了一种新的方法，通过模型解释特征的转移性质来检测分布转移下学习模型的行为是否越界，在比较中发现其比最先进的技术更为优秀，提供了算法方法并在实验中得到验证。 |
| [^20] | [Deep Metric Learning with Chance Constraints.](http://arxiv.org/abs/2209.09060) | 本文将深度度量学习与有限机会约束的可行性问题相关联，证明了基于代理的DML的最小化者满足机会约束，并提出多个代理有助于性能提升，通过迭代投影解决DML问题。 |
| [^21] | [Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming.](http://arxiv.org/abs/2209.08901) | 本文提出了一种基于半定规划的全局优化方法来解决带基数约束的最小平方和聚类问题，并通过引入新的SDP松弛方法和定制的分支策略来改善解的质量和性能。 |
| [^22] | [Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems.](http://arxiv.org/abs/2205.04151) | 本文提出了一种名为Auto-SDE的算法来学习慢-快随机动力学系统的有效降维动力学，通过自动编码器神经网络和离散化的随机微分方程，捕捉了系统的演化特性，并在数值实验证明了其准确性、稳定性和有效性。 |
| [^23] | [Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders.](http://arxiv.org/abs/2202.09671) | 我们提出了一种更快更廉价的截断扩散概率模型方法，通过从隐藏噪声数据分布开始生成数据，相较于传统的方法可以获得更好的性能改进。 |
| [^24] | [Comparing Sequential Forecasters.](http://arxiv.org/abs/2110.00115) | 本文提出了一种比较序贯预测器的方法，通过设计新的序贯推断程序来估计预测得分的时变差异，这种方法避免了对预测和结果生成方式的不可验证假设。 |
| [^25] | [Bridging the Gap Between Target Networks and Functional Regularization.](http://arxiv.org/abs/2106.02613) | 该论文研究了靶网络与功能正则化在深度强化学习中的作用。通过实验证明靶网络作为隐式正则化器在某些情况下有利，但不灵活且可能导致不稳定。为了解决这些问题，作者提出了一种明确的功能正则化替代方法，并对其收敛性进行了理论研究。 |
| [^26] | [BoXHED2.0: Scalable boosting of dynamic survival analysis.](http://arxiv.org/abs/2103.12591) | BoXHED2.0是一个可扩展的动态生存分析提升方法，适用于包括重复事件和竞争风险在内的多种生存环境，具有与参数化提升生存模型相媲美的速度。 |
| [^27] | [Proper Learning of Linear Dynamical Systems as a Non-Commutative Polynomial Optimisation Problem.](http://arxiv.org/abs/2002.01444) | 该论文提出了一种方法来解决适当学习线性动态系统的问题，通过非交换多项式优化，保证了数值解对最小二乘估计器的全局收敛性。 |
| [^28] | [Copula Representations and Error Surface Projections for the Exclusive Or Problem.](http://arxiv.org/abs/1907.04483) | 本研究讨论了通过概率逻辑和关联Copula函数解决异或表示和逼近问题的方法，并通过比较不同激活函数下的误差面动态来说明其优势。通过将xor表示从布尔值扩展到实数值，我们提供了一种演示交叉验证概念的方便方式。 |

# 详细

[^1]: 系统识别的非渐近理论教程

    A Tutorial on the Non-Asymptotic Theory of System Identification. (arXiv:2309.03873v1 [eess.SY])

    [http://arxiv.org/abs/2309.03873](http://arxiv.org/abs/2309.03873)

    这个教程介绍了系统识别中最近发展的非渐近方法、强调了覆盖技术、Hanson-Wright不等式和自标准化马丁格尔法等工具的应用、并给出了利用这些工具简化证明的最小二乘估计器在自回归模型中参数识别中的性能、最后介绍了将这些思想扩展到某些非线性识别问题的方法。

    

    这个教程介绍最近发展的非渐近方法在主要线性系统识别理论中的应用。我们强调一些在这个领域中特别有用的工具，如覆盖技术、Hanson-Wright不等式和自标准化马丁格尔法。然后我们利用这些工具来给出一些基于最小二乘估计器的性能的简化证明，用于识别自回归模型中的参数。最后，我们概述了如何将所呈现的思想扩展到某些非线性识别问题中。

    This tutorial serves as an introduction to recently developed non-asymptotic methods in the theory of -- mainly linear -- system identification. We emphasize tools we deem particularly useful for a range of problems in this domain, such as the covering technique, the Hanson-Wright Inequality and the method of self-normalized martingales. We then employ these tools to give streamlined proofs of the performance of various least-squares based estimators for identifying the parameters in autoregressive models. We conclude by sketching out how the ideas presented herein can be extended to certain nonlinear identification problems.
    
[^2]: 高斯混合物可以通过多项式数量的样本进行差分隐私学习

    Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v1 [stat.ML])

    [http://arxiv.org/abs/2309.03847](http://arxiv.org/abs/2309.03847)

    通过多项式数量的样本和差分隐私约束，我们提出了一个可以估计高斯混合物的方法，并证明了这个方法的有效性，而无需对GMMs做任何结构性假设。

    

    我们研究了在差分隐私(DP)约束下估计高斯混合物的问题。我们的主要结果是，使用$\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$个样本即可在满足$(\varepsilon, \delta)$-DP的条件下估计$k$个高斯混合物，使其达到总变差距离$\alpha$。这是该问题的第一个有限样本复杂性上限，而无需对GMMs做任何结构性假设。为了解决这个问题，我们构建了一个新的框架，该框架对于其他任务可能也有用。在高层次上，我们展示了如果一个分布类（比如高斯分布）是（1）可列表译码的并且（2）在总变差距离方面具有“局部小”覆盖[ BKSW19]，则其混合物类是私密可学习的。证明绕过了一个已知障碍，表明与高斯分布不同，GMMs不具有局部小的覆盖[AAL21]。

    We study the problem of estimating mixtures of Gaussians under the constraint of differential privacy (DP). Our main result is that $\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$ samples are sufficient to estimate a mixture of $k$ Gaussians up to total variation distance $\alpha$ while satisfying $(\varepsilon, \delta)$-DP. This is the first finite sample complexity upper bound for the problem that does not make any structural assumptions on the GMMs.  To solve the problem, we devise a new framework which may be useful for other tasks. On a high level, we show that if a class of distributions (such as Gaussians) is (1) list decodable and (2) admits a "locally small'' cover [BKSW19] with respect to total variation distance, then the class of its mixtures is privately learnable. The proof circumvents a known barrier indicating that, unlike Gaussians, GMMs do not admit a locally small cover [AAL21].
    
[^3]: 基于梯度的结构化数据特征学习

    Gradient-Based Feature Learning under Structured Data. (arXiv:2309.03843v1 [stat.ML])

    [http://arxiv.org/abs/2309.03843](http://arxiv.org/abs/2309.03843)

    本论文研究了基于梯度的结构化数据特征学习的问题，发现了在非各向异性设置中，常用的球形梯度动力学可能无法恢复真实方向，并提出了一个适当的权重归一化方法来解决这个问题。通过利用输入协方差与目标之间的对齐，可以获得比各向同性情况更好的样本复杂度。

    

    最近的研究表明，基于梯度的单指数模型学习的样本复杂度取决于它们的信息指数。然而，这些结果仅涉及各向同性数据，而实际应用中的输入往往包含额外的结构，可以隐含地指导算法。在这项工作中，我们研究了一种尖峰协方差结构的影响，并揭示了一些有趣的现象。首先，我们发现在非各向异性设置中，常用的球形梯度动力学即使在尖峰与目标方向完全对齐时也可能无法恢复真实方向。接下来，我们展示了一种适当的权重归一化方法，类似于批量归一化，可以缓解这个问题。此外，通过利用（尖峰）输入协方差与目标之间的对齐，我们获得了比各向同性情况更好的样本复杂度。

    Recent works have demonstrated that the sample complexity of gradient-based learning of single index models, i.e. functions that depend on a 1-dimensional projection of the input data, is governed by their information exponent. However, these results are only concerned with isotropic data, while in practice the input often contains additional structure which can implicitly guide the algorithm. In this work, we investigate the effect of a spiked covariance structure and reveal several interesting phenomena. First, we show that in the anisotropic setting, the commonly used spherical gradient dynamics may fail to recover the true direction, even when the spike is perfectly aligned with the target direction. Next, we show that appropriate weight normalization that is reminiscent of batch normalization can alleviate this issue. Further, by exploiting the alignment between the (spiked) input covariance and the target, we obtain improved sample complexity compared to the isotropic case. In pa
    
[^4]: 隐性随机动力学系统中的转向预警

    Early warning via transitions in latent stochastic dynamical systems. (arXiv:2309.03842v1 [stat.ML])

    [http://arxiv.org/abs/2309.03842](http://arxiv.org/abs/2309.03842)

    本研究提出了一种基于定向异性扩散图的方法，通过捕捉低维流形中的潜在演化动态，能够有效提取早期警报信号来检测复杂系统或高维观测数据中的动力学转变，并在真实的脑电图数据上得到了验证。

    

    在许多实际应用中，如基因突变、脑疾病、自然灾害、金融危机和工程可靠性，对复杂系统或高维观测数据中的动力学转变进行早期警报是至关重要的。为了有效提取早期警报信号，我们开发了一种新方法：定向异性扩散图，它捕捉了低维流形中的潜在演化动态。将该方法应用于真实的脑电图（EEG）数据，我们成功找到了适当的有效坐标，并推导出能够检测状态转变中临界点的早期警报信号。我们的方法将潜在动态与原始数据集联系起来。通过数值实验证明了该框架在密度和转变概率等方面的准确性和有效性。结果表明，第二个坐标在各种评估指标中保持有意义的信息。

    Early warnings for dynamical transitions in complex systems or high-dimensional observation data are essential in many real world applications, such as gene mutation, brain diseases, natural disasters, financial crises, and engineering reliability. To effectively extract early warning signals, we develop a novel approach: the directed anisotropic diffusion map that captures the latent evolutionary dynamics in low-dimensional manifold. Applying the methodology to authentic electroencephalogram (EEG) data, we successfully find the appropriate effective coordinates, and derive early warning signals capable of detecting the tipping point during the state transition. Our method bridges the latent dynamics with the original dataset. The framework is validated to be accurate and effective through numerical experiments, in terms of density and transition probability. It is shown that the second coordinate holds meaningful information for critical transition in various evaluation metrics.
    
[^5]: 无方差损失下的经验风险最小化

    Empirical Risk Minimization for Losses without Variance. (arXiv:2309.03818v1 [stat.ML])

    [http://arxiv.org/abs/2309.03818](http://arxiv.org/abs/2309.03818)

    本文研究了在重尾分布条件下的经验风险最小化问题，通过最小化风险值选择优化器，并通过使用广义通用链方法建立了过度风险的上界。数值研究表明，通过Catoni风格估计的经验风险优化器比其他基准表现更好。

    

    本文考虑了在重尾分布条件下的经验风险最小化问题，其中数据没有有限方差，但只有$p$阶矩，其中$p \in (1,2)$。我们选择通过最小化风险值来选择优化器，而不是使用基于截断观测数据的估计过程。这些风险值可以通过使用Catoni的显著方法（Catoni, 2012）进行稳健估计来得到。由于Catoni型影响函数的结构，我们能够通过使用广义的通用链方法建立过度风险的上界。此外，我们考虑了计算问题。我们特别从理论上研究了两种类型的优化方法，即稳健梯度下降算法和基于经验风险的方法。通过广泛的数值研究，我们发现通过Catoni风格估计的经验风险优化器确实比其他基准表现更好。这表明直接基于截断数据的估计可能会导致较差的性能。

    This paper considers an empirical risk minimization problem under heavy-tailed settings, where data does not have finite variance, but only has $p$-th moment with $p \in (1,2)$. Instead of using estimation procedure based on truncated observed data, we choose the optimizer by minimizing the risk value. Those risk values can be robustly estimated via using the remarkable Catoni's method (Catoni, 2012). Thanks to the structure of Catoni-type influence functions, we are able to establish excess risk upper bounds via using generalized generic chaining methods. Moreover, we take computational issues into consideration. We especially theoretically investigate two types of optimization methods, robust gradient descent algorithm and empirical risk-based methods. With an extensive numerical study, we find that the optimizer based on empirical risks via Catoni-style estimation indeed shows better performance than other baselines. It indicates that estimation directly based on truncated data may 
    
[^6]: 通过谱方法改进了排名聚合的理论保证

    Improved theoretical guarantee for rank aggregation via spectral method. (arXiv:2309.03808v1 [stat.ML])

    [http://arxiv.org/abs/2309.03808](http://arxiv.org/abs/2309.03808)

    本论文通过谱方法改进了排名聚合问题的理论保证，通过研究基于未归一化和归一化数据矩阵的谱排名算法，提供了更准确的扰动误差界限。

    

    给定多个项目之间的成对比较，如何对它们进行排名以使得排名与观察相匹配？这个问题被称为排名聚合，在体育、推荐系统和其他网络应用中已经找到了许多应用。由于找到最小化不匹配的全局排名通常是NP困难的（称为Kemeny优化），我们将重点放在Erd\"os-R\'enyi离群点（ERO）模型上。在这个排名问题中，每个成对比较是真实分数差异的被损坏副本。我们研究了基于未归一化和归一化数据矩阵的谱排名算法。关键是理解它们在从观察数据中恢复每个项目的潜在分数方面的性能。这归结为推导未归一化/归一化数据矩阵的前几个特征向量和其总体对应物之间的逐个项扰动误差界限。通过使用留出技术，我们提供了一个更准确的$\ell_{\infty}$-norm扰动误差界限。

    Given pairwise comparisons between multiple items, how to rank them so that the ranking matches the observations? This problem, known as rank aggregation, has found many applications in sports, recommendation systems, and other web applications. As it is generally NP-hard to find a global ranking that minimizes the mismatch (known as the Kemeny optimization), we focus on the Erd\"os-R\'enyi outliers (ERO) model for this ranking problem. Here, each pairwise comparison is a corrupted copy of the true score difference. We investigate spectral ranking algorithms that are based on unnormalized and normalized data matrices. The key is to understand their performance in recovering the underlying scores of each item from the observed data. This reduces to deriving an entry-wise perturbation error bound between the top eigenvectors of the unnormalized/normalized data matrix and its population counterpart. By using the leave-one-out technique, we provide a sharper $\ell_{\infty}$-norm perturbati
    
[^7]: 神经特征学习中的帕累托前沿：数据、计算、宽度和运气

    Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. (arXiv:2309.03800v1 [cs.LG])

    [http://arxiv.org/abs/2309.03800](http://arxiv.org/abs/2309.03800)

    本研究研究了深度学习算法设计中的微妙选择，特别关注计算统计差距。通过理论和实验，发现稀疏初始化和增加网络宽度可以提高样本效率，并且合成稀疏奇偶任务可以作为真实问题的代理。

    

    本研究探讨了在计算统计差距存在的情况下，深度学习中微妙的算法设计选择。我们首先考虑了离线稀疏奇偶学习，这是一个有关多层感知器梯度训练的监督分类问题，其具有统计查询下界。这个下界可以解释为多资源的权衡前沿：成功学习只有在一个足够丰富（大型模型）、知识渊博（大规模数据集）、耐心（训练迭代次数多）或幸运（随机猜测次数多）的情况下才能发生。我们通过理论和实验表明，在这种情况下，稀疏初始化和增加网络宽度可以显著提高样本效率。在这里，宽度起到了并行搜索的作用：它增加了找到“幸运神经元”的概率，这些神经元可以更高效地学习稀疏特征。最后，我们表明合成稀疏奇偶任务可以作为真实问题的代理。

    This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding "lottery ticket" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real pro
    
[^8]: 使用最优传输正则化差异来提高对抗性鲁棒深度学习

    Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])

    [http://arxiv.org/abs/2309.03791](http://arxiv.org/abs/2309.03791)

    本论文介绍了一种新的方法ARMOR_D来加强深度学习模型的对抗鲁棒性，该方法基于最优传输正则化差异，通过在分布的邻域上进行最大化期望损失来实现。实验证明，ARMOR_D方法在恶意软件检测和图像识别应用中能够优于现有方法，在对抗攻击下的鲁棒性方面具有较好的效果。

    

    我们引入了ARMOR_D方法作为增强深度学习模型对抗性鲁棒性的创新方法。这些方法基于一种新的最优传输正则化差异类，通过信息差异和最优传输成本之间的infimal卷积构建。我们使用这些方法来增强对抗性鲁棒性，通过在分布的邻域上最大化期望损失，这被称为分布鲁棒优化技术。作为构建对抗样本的工具，我们的方法允许样本根据最优传输成本进行传输，并根据信息差异进行重新加权。我们在恶意软件检测和图像识别应用上证明了我们方法的有效性，并发现在增强对抗攻击鲁棒性方面，据我们所知，它优于现有方法。ARMOR_D在FGSM攻击下的robustified准确率达到98.29%，在其他攻击下达到98.18%。

    We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\%$ against $FGSM$ and $98.18\%$ aga
    
[^9]: 神经套索：一种将套索和神经网络相结合的统一方法

    Neural lasso: a unifying approach of lasso and neural networks. (arXiv:2309.03770v1 [stat.ML])

    [http://arxiv.org/abs/2309.03770](http://arxiv.org/abs/2309.03770)

    本文提出了一种神经套索方法，将套索和神经网络相结合，通过模仿统计框架进行修改的方式，在变量选择中提供更准确的参数估计。

    

    近年来，将统计和机器学习领域的技术相结合以获得两种方法的优点已经成为研究热点。本文通过神经网络来表示变量选择的统计技术套索。观察发现，尽管统计方法和神经网络版本具有相同的目标函数，但由于优化方法不同而存在差异。特别是，神经网络版本通常使用单个验证集进行一步优化，而统计对应方法基于交叉验证进行两步优化。统计方法更为精细的优化导致更准确的参数估计，尤其是在训练集较小的情况下。因此，本文提出了一种修改标准神经网络训练方法的方法，模仿统计框架。在开发上述修改的过程中，提出了一种新的优化算法。

    In recent years, there is a growing interest in combining techniques attributed to the areas of Statistics and Machine Learning in order to obtain the benefits of both approaches. In this article, the statistical technique lasso for variable selection is represented through a neural network. It is observed that, although both the statistical approach and its neural version have the same objective function, they differ due to their optimization. In particular, the neural version is usually optimized in one-step using a single validation set, while the statistical counterpart uses a two-step optimization based on cross-validation. The more elaborated optimization of the statistical method results in more accurate parameter estimation, especially when the training set is small. For this reason, a modification of the standard approach for training neural networks, that mimics the statistical framework, is proposed. During the development of the above modification, a new optimization algori
    
[^10]: 具有自动聚类数量选择的中心轮廓聚类

    Medoid Silhouette clustering with automatic cluster number selection. (arXiv:2309.03751v1 [cs.LG])

    [http://arxiv.org/abs/2309.03751](http://arxiv.org/abs/2309.03751)

    本文介绍了一种具有自动聚类数量选择的中心轮廓聚类算法，其中结合了原始轮廓系数和PAM算法的思想，并通过两种快速版本进行了理论分析和实验验证，在实验中获得了显著的加速效果。

    

    聚类结果的评估是困难的，高度依赖于评估的数据集和观察者的观点。有许多不同的聚类质量度量，试图提供一个通用的度量来验证聚类结果。一个非常流行的度量是轮廓系数。我们讨论了高效的基于中心点的轮廓系数，对其属性进行了理论分析，提供了两个直接优化的快速版本，并讨论了选择最佳聚类数量的使用。我们将原始轮廓系数和著名的PAM算法以及其最新改进FasterPAM的思想相结合。其中一个版本保证与原始版本相等的结果，并提供了$O(k^2)$的运行加速。在具有30000个样本和$k$=100的实际数据上，与原始的PAMMEDSIL算法相比，我们观察到了10464倍的加速。此外，我们提供了一种直接选择最佳聚类数量的变种方法。

    The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder. There are many different clustering quality measures, which try to provide a general measure to validate clustering results. A very popular measure is the Silhouette. We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, provide two fast versions for the direct optimization, and discuss the use to choose the optimal number of clusters. We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM. One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\times$ speedup compared to the original PAMMEDSIL algorithm. Additionally, we provide a variant to choose the optimal number of clusters directly.
    
[^11]: 使用大型语言模型增强基于流水线的对话系统

    Enhancing Pipeline-Based Conversational Agents with Large Language Models. (arXiv:2309.03748v1 [cs.CL])

    [http://arxiv.org/abs/2309.03748](http://arxiv.org/abs/2309.03748)

    本文研究了如何使用大型语言模型（LLM）来增强基于流水线的对话系统。在设计和开发阶段，LLM可以帮助生成训练数据、提取实体和同义词、本地化和角色设计。在运营阶段，LLM可以辅助上下文化、意图分类、自动纠正话语、改写回复、摘要和使闭合问题回答能力。通过在私人银行领域的实验，证明了这些能力的有效性。

    

    AI和深度学习的最新进展使得基于大型语言模型（LLM）的代理器（如GPT-4）取得了突破。然而，许多商业化对话系统开发工具是基于流水线的，并且在进行人类对话时存在限制。本文研究了LLM在以下两个阶段中增强基于流水线的对话系统的能力：1）设计和开发阶段；2）运营阶段。在1）中，LLM可以在生成训练数据、提取实体和同义词、本地化和角色设计方面提供帮助。在2）中，LLM可以辅助上下文化、意图分类以防止对话中断和处理超出范围的问题、自动纠正话语、改写回复、制定消歧问句、摘要和使闭合问题回答能力。我们在私人银行领域进行了使用GPT-4的非正式实验，以实际示例证明上述情景。

    The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4. However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation. This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations. In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design. In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities. We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example.
    
[^12]: 一种基于三元马尔科夫链的概率半监督方法

    A Probabilistic Semi-Supervised Approach with Triplet Markov Chains. (arXiv:2309.03707v1 [stat.ML])

    [http://arxiv.org/abs/2309.03707](http://arxiv.org/abs/2309.03707)

    本文提出了一种基于变分贝叶斯推断的通用框架，用于在半监督的情况下训练参数化的三元马尔科夫链模型，并且能够针对各种生成模型推导出半监督算法，用于顺序贝叶斯分类。

    

    三元马尔科夫链是用于顺序数据的一种通用生成模型，考虑了三种随机变量：（带噪）观测值、它们相关的离散标签和旨在增强观测值及其相关标签分布的潜在变量。然而，在实际应用中，我们没有所有与观测值相关的标签来估计这种模型的参数。本文提出了一种基于变分贝叶斯推断的通用框架，用于在半监督的情况下训练参数化的三元马尔科夫链模型。我们的方法的普适性使我们能够针对各种生成模型推导出半监督算法，用于顺序贝叶斯分类。

    Triplet Markov chains are general generative models for sequential data which take into account three kinds of random variables: (noisy) observations, their associated discrete labels and latent variables which aim at strengthening the distribution of the observations and their associated labels. However, in practice, we do not have at our disposal all the labels associated to the observations to estimate the parameters of such models. In this paper, we propose a general framework based on a variational Bayesian inference to train parameterized triplet Markov chain models in a semi-supervised context. The generality of our approach enables us to derive semi-supervised algorithms for a variety of generative models for sequential Bayesian classification.
    
[^13]: 缺失值处理的三值决策树

    Trinary Decision Trees for missing value handling. (arXiv:2309.03561v1 [stat.ML])

    [http://arxiv.org/abs/2309.03561](http://arxiv.org/abs/2309.03561)

    本文介绍了一种称为三值决策树的算法，用于改善决策树在处理缺失数据时的表现。与其他方法不同，该算法不假设缺失值包含任何关于响应的信息。实验证明，在特定缺失数据场景下，三值决策树在MCAR设置中表现优异，在IM设置中略逊一筹。同时，通过将三值决策树与缺失在属性方法相结合，可以获得更稳健的性能。尽管训练速度较慢，但三值决策树提供了一种有前途且更准确的方法。

    

    本文介绍了三值决策树，这是一种旨在改善决策树回归器和分类器中处理缺失数据的算法。与其他方法不同，三值决策树不假设缺失值包含有关响应的任何信息。本文通过理论计算和使用真实数据集的数值示例，比较了其在不同缺失数据场景（完全随机缺失（MCAR）和信息性缺失（IM））中与已建立算法的性能。值得注意的是，在MCAR设置中，三值树在只有样本外缺失数据时表现优于其同行，而在IM设置中落后。一个混合模型，即三值缺失在属性（MIA）方法和三值树相结合的TrinaryMIA树，在所有缺失类型中表现出强大的性能。尽管训练速度较慢可能是一个潜在的缺点，但三值决策树提供了一个有前途且更准确的方法。

    This paper introduces the Trinary decision tree, an algorithm designed to improve the handling of missing data in decision tree regressors and classifiers. Unlike other approaches, the Trinary decision tree does not assume that missing values contain any information about the response. Both theoretical calculations on estimator bias and numerical illustrations using real data sets are presented to compare its performance with established algorithms in different missing data scenarios (Missing Completely at Random (MCAR), and Informative Missingness (IM)). Notably, the Trinary tree outperforms its peers in MCAR settings, especially when data is only missing out-of-sample, while lacking behind in IM settings. A hybrid model, the TrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes (MIA) approach, shows robust performance in all types of missingness. Despite the potential drawback of slower training speed, the Trinary tree offers a promising and more accurate met
    
[^14]: 论多智能体非线性滤波和学习的动力学

    On the dynamics of multi agent nonlinear filtering and learning. (arXiv:2309.03557v1 [stat.ML])

    [http://arxiv.org/abs/2309.03557](http://arxiv.org/abs/2309.03557)

    本文研究了具有非线性滤波/学习动力学的多智能体网络系统的行为，并介绍了在分布式和联邦学习场景中的应用。

    

    多智能体系统通过分散一致性寻求动力学来完成高度复杂的学习任务，其在信号处理和计算智能社区引起了极大关注。本文研究了具有非线性滤波/学习动力学的多智能体网络系统的行为。为此，提出了多智能体网络系统中一个智能体的行动的一般表述，并给出了实现协同学习行为的条件。重要的是，还介绍了该推导框架在分布式和联邦学习场景中的应用。

    Multiagent systems aim to accomplish highly complex learning tasks through decentralised consensus seeking dynamics and their use has garnered a great deal of attention in the signal processing and computational intelligence societies. This article examines the behaviour of multiagent networked systems with nonlinear filtering/learning dynamics. To this end, a general formulation for the actions of an agent in multiagent networked systems is presented and conditions for achieving a cohesive learning behaviour is given. Importantly, application of the so derived framework in distributed and federated learning scenarios are presented.
    
[^15]: 集成线性插值器: 集成的作用

    Ensemble linear interpolators: The role of ensembling. (arXiv:2309.03354v1 [stat.ML])

    [http://arxiv.org/abs/2309.03354](http://arxiv.org/abs/2309.03354)

    本文研究了集成线性插值器如何稳定和提升个体插值器的泛化性能，并引入了基于乘数自助法的袋装最小二乘估计器。在比例区域内，研究了简化和袋装的外样本预测风险。

    

    插值器是不稳定的。例如，当处理噪声数据时，最小l2范数最小二乘插值器的测试误差会无界增长。本文研究集成如何稳定和提升个体插值器的泛化性能，通过对外样本预测风险进行衡量。我们以袋装线性插值器为重点，因为袋装是一种流行的基于随机化的集成方法，可以并行实现。我们引入基于乘数自助法的袋装最小二乘估计器，可以将其表达为简化最小二乘估计器的平均值。所提出的乘数自助法包含了经典的有放回自助法作为一种特殊情况，以及更有趣的变体，我们称之为伯努利自助法。在样本大小与特征维度成正比的比例区域内，我们研究了简化和袋装的外样本预测风险。

    Interpolators are unstable. For example, the mininum $\ell_2$ norm least square interpolator exhibits unbounded test errors when dealing with noisy data. In this paper, we study how ensemble stabilizes and thus improves the generalization performance, measured by the out-of-sample prediction risk, of an individual interpolator. We focus on bagged linear interpolators, as bagging is a popular randomization-based ensemble method that can be implemented in parallel. We introduce the multiplier-bootstrap-based bagged least square estimator, which can then be formulated as an average of the sketched least square estimators. The proposed multiplier bootstrap encompasses the classical bootstrap with replacement as a special case, along with a more intriguing variant which we call the Bernoulli bootstrap.  Focusing on the proportional regime where the sample size scales proportionally with the feature dimensionality, we investigate the out-of-sample prediction risks of the sketched and bagged 
    
[^16]: 让学生决策的知识蒸馏层

    Knowledge Distillation Layer that Lets the Student Decide. (arXiv:2309.02843v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2309.02843](http://arxiv.org/abs/2309.02843)

    本论文提出了一个可学习的知识蒸馏层，能够明确地嵌入教师的知识到学生的特征变换中，从而改进了知识蒸馏技术。

    

    知识蒸馏（KD）中的典型技术是通过将学生的响应与强大模型（教师）的响应匹配来规范学生的学习。然而，它对学生的特征变换的作用相对隐含，限制了其在中间层的实践。为了明确地嵌入教师的知识，我们提出了一个可学习的KD层，它通过两个不同的能力改进了KD：i）学习如何利用教师的知识，能够丢弃无关的信息；ii）将转移的知识向前传递得更深入。因此，在推理过程中，学生可以享受到教师的知识，而不仅仅是在训练中。正式地说，我们重新分配1x1-BN-ReLU-1x1卷积块，根据学生对应区域与模板（由教师监督）的匹配情况，为每个局部区域分配一个语义向量。

    Typical technique in knowledge distillation (KD) is regularizing the learning of a limited capacity model (student) by pushing its responses to match a powerful model's (teacher). Albeit useful especially in the penultimate layer and beyond, its action on student's feature transform is rather implicit, limiting its practice in the intermediate layers. To explicitly embed the teacher's knowledge in feature transform, we propose a learnable KD layer for the student which improves KD with two distinct abilities: i) learning how to leverage the teacher's knowledge, enabling to discard nuisance information, and ii) feeding forward the transferred knowledge deeper. Thus, the student enjoys the teacher's knowledge during the inference besides training. Formally, we repurpose 1x1-BN-ReLU-1x1 convolution block to assign a semantic vector to each local region according to the template (supervised by the teacher) that the corresponding region of the student matches. To facilitate template learnin
    
[^17]: 用于决策的因果思维在电子健康记录中的应用：为什么以及如何

    Causal thinking for decision making on Electronic Health Records: why and how. (arXiv:2308.01605v1 [stat.ME])

    [http://arxiv.org/abs/2308.01605](http://arxiv.org/abs/2308.01605)

    本文介绍了在电子健康记录中使用因果思维进行决策的必要性和方法。通过模拟随机试验来个性化决策，以减少数据中的偏见。这对于分析电子健康记录或索赔数据以得出因果结论的最重要陷阱和考虑因素进行了重点强调。

    

    准确的预测，如同机器学习一样，可能无法为每个患者提供最佳医疗保健。确实，预测可能受到数据中的捷径（如种族偏见）的驱动。为数据驱动的决策需要因果思维。在这里，我们介绍关键要素，重点关注常规收集的数据，即电子健康记录（EHRs）和索赔数据。使用这些数据评估干预的价值需要谨慎：时间依赖性和现有实践很容易混淆因果效应。我们提供了一个逐步框架，帮助从真实患者记录中构建有效的决策，通过模拟随机试验来个性化决策，例如使用机器学习。我们的框架强调了分析EHRs或索赔数据以得出因果结论时最重要的陷阱和考虑因素。我们在用于重症医学信息市场中的肌酐对败血症死亡率的影响的研究中说明了各种选择。

    Accurate predictions, as with machine learning, may not suffice to provide optimal healthcare for every patient. Indeed, prediction can be driven by shortcuts in the data, such as racial biases. Causal thinking is needed for data-driven decisions. Here, we give an introduction to the key elements, focusing on routinely-collected data, electronic health records (EHRs) and claims data. Using such data to assess the value of an intervention requires care: temporal dependencies and existing practices easily confound the causal effect. We present a step-by-step framework to help build valid decision making from real-life patient records by emulating a randomized trial before individualizing decisions, eg with machine learning. Our framework highlights the most important pitfalls and considerations in analysing EHRs or claims data to draw causal conclusions. We illustrate the various choices in studying the effect of albumin on sepsis mortality in the Medical Information Mart for Intensive C
    
[^18]: 深度网络逼近：从ReLU到多种激活函数

    Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])

    [http://arxiv.org/abs/2307.06555](http://arxiv.org/abs/2307.06555)

    本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。

    

    本文探究了深度神经网络在多种激活函数下的表达能力。定义了一个激活函数集合A，包括大多数常用的激活函数，如ReLU、LeakyReLU、ReLU^2、ELU、SELU、Softplus、GELU、SiLU、Swish、Mish、Sigmoid、Tanh、Arctan、Softsign、dSiLU和SRS。我们证明了对于任意激活函数varrho∈A，可以通过一个宽度为6N、深度为2L的varrho激活网络在有界集合上以任意精度逼近一个宽度为N、深度为L的ReLU网络。这一发现使得大部分对于ReLU网络的逼近结果能够推广到其他激活函数，尽管需要稍大的常数代价。

    This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
    
[^19]: 解释位移：研究模型与转移数据分布的交互作用。

    Explanation Shift: Investigating Interactions between Models and Shifting Data Distributions. (arXiv:2303.08081v1 [cs.LG])

    [http://arxiv.org/abs/2303.08081](http://arxiv.org/abs/2303.08081)

    该论文提出了一种新的方法，通过模型解释特征的转移性质来检测分布转移下学习模型的行为是否越界，在比较中发现其比最先进的技术更为优秀，提供了算法方法并在实验中得到验证。

    

    当输入数据分布发生变化时，机器学习模型的预测性能往往会下降。在实践中，新的输入数据往往没有目标标签。因此，最先进的技术模型输入数据分布或模型预测分布，并试图理解学习模型和转移分布之间的相互作用问题。我们提出了一种新方法，该方法模型如何解释特征的转移性质受到分布转移的影响。我们发现，解释位移的建模可以比最先进的技术更好地指示检测超出分布的模型行为。我们分析了使用合成示例和真实数据集的不同类型的分布转移。我们提供了一种算法方法，允许我们检查数据集特征和学习模型之间的交互作用，并将其与最先进技术进行比较。我们在开源Python包中发布了我们的方法，以及使用的代码。

    As input data distributions evolve, the predictive performance of machine learning models tends to deteriorate. In practice, new input data tend to come without target labels. Then, state-of-the-art techniques model input data distributions or model prediction distributions and try to understand issues regarding the interactions between learned models and shifting distributions. We suggest a novel approach that models how explanation characteristics shift when affected by distribution shifts. We find that the modeling of explanation shifts can be a better indicator for detecting out-of-distribution model behaviour than state-of-the-art techniques. We analyze different types of distribution shifts using synthetic examples and real-world data sets. We provide an algorithmic method that allows us to inspect the interaction between data set features and learned models and compare them to the state-of-the-art. We release our methods in an open-source Python package, as well as the code used
    
[^20]: 带有机会约束的深度度量学习

    Deep Metric Learning with Chance Constraints. (arXiv:2209.09060v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.09060](http://arxiv.org/abs/2209.09060)

    本文将深度度量学习与有限机会约束的可行性问题相关联，证明了基于代理的DML的最小化者满足机会约束，并提出多个代理有助于性能提升，通过迭代投影解决DML问题。

    

    深度度量学习（DML）旨在最小化嵌入空间中成对内/间类近似违规的经验预期损失。我们将DML与有限机会约束的可行性问题相关联。我们证明了基于代理的DML的最小化者满足某些机会约束，并且基于代理的方法的最坏情况泛化性能可以用覆盖对应类样本整个域的最小球的半径来描述，这表明每个类别使用多个代理有助于性能提升。为了提供可扩展的算法并利用更多的代理，我们考虑了基于代理的DML实例最小化者所蕴含的机会约束，并将DML重新制定为在这些约束交集中找到可行点的问题，从而得到一个通过迭代投影来近似解决的问题。简而言之，我们反复训练正则化的基于代理的损失，并重新初始化嵌入的代理。

    Deep metric learning (DML) aims to minimize empirical expected loss of the pairwise intra-/inter- class proximity violations in the embedding space. We relate DML to feasibility problem of finite chance constraints. We show that minimizer of proxy-based DML satisfies certain chance constraints, and that the worst case generalization performance of the proxy-based methods can be characterized by the radius of the smallest ball around a class proxy to cover the entire domain of the corresponding class samples, suggesting multiple proxies per class helps performance. To provide a scalable algorithm as well as exploiting more proxies, we consider the chance constraints implied by the minimizers of proxy-based DML instances and reformulate DML as finding a feasible point in intersection of such constraints, resulting in a problem to be approximately solved by iterative projections. Simply put, we repeatedly train a regularized proxy-based loss and re-initialize the proxies with the embeddin
    
[^21]: 基于半定规划的带基数约束最小平方和聚类的全局优化

    Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming. (arXiv:2209.08901v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2209.08901](http://arxiv.org/abs/2209.08901)

    本文提出了一种基于半定规划的全局优化方法来解决带基数约束的最小平方和聚类问题，并通过引入新的SDP松弛方法和定制的分支策略来改善解的质量和性能。

    

    最小平方和聚类(MSSC)或k均值类型聚类最近已经扩展以利用对每个簇基数的先验知识。这种知识被用于提高性能和解决方案质量。在本文中，我们提出了一种基于分支定界技术的全局优化方法来解决基数约束的MSSC问题。对于下界例程，我们使用了Rujeerapaiboon等人最近提出的半定规划(SDP)松弛方法。然而，该松弛方法只适用于小规模实例的分支定界方法。因此，我们导出了一种新的SDP松弛方法，它能更好地适应实例规模和簇的数目。在两种情况下，我们通过添加多面体割线来加强下界。通过定制的分支策略，我们实施了成对约束，从而减少了子节点中出现的问题的复杂性。对于上界，

    The minimum sum-of-squares clustering (MSSC), or k-means type clustering, has been recently extended to exploit prior knowledge on the cardinality of each cluster. Such knowledge is used to increase performance as well as solution quality. In this paper, we propose a global optimization approach based on the branch-and-cut technique to solve the cardinality-constrained MSSC. For the lower bound routine, we use the semidefinite programming (SDP) relaxation recently proposed by Rujeerapaiboon et al. [SIAM J. Optim. 29(2), 1211-1239, (2019)]. However, this relaxation can be used in a branch-and-cut method only for small-size instances. Therefore, we derive a new SDP relaxation that scales better with the instance size and the number of clusters. In both cases, we strengthen the bound by adding polyhedral cuts. Benefiting from a tailored branching strategy which enforces pairwise constraints, we reduce the complexity of the problems arising in the children nodes. For the upper bound, inste
    
[^22]: Auto-SDE:从数据驱动的随机动力学系统中学习有效的降维动力学

    Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems. (arXiv:2205.04151v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.04151](http://arxiv.org/abs/2205.04151)

    本文提出了一种名为Auto-SDE的算法来学习慢-快随机动力学系统的有效降维动力学，通过自动编码器神经网络和离散化的随机微分方程，捕捉了系统的演化特性，并在数值实验证明了其准确性、稳定性和有效性。

    

    由于能够描绘许多实际应用中的复杂现象，多尺度随机动力学系统被广泛应用于科学和工程问题。本文致力于研究慢-快随机动力学系统的有效降维动力学。给定满足某些未知慢-快随机系统的短期观测数据，我们提出了一种包括自动编码器神经网络Auto-SDE的新算法来学习不变的慢流形。我们的方法捕捉了一系列时间相关的自动编码器神经网络的演化特性，损失函数通过离散化的随机微分方程构造。通过在各种评估指标下的数值实验证明，我们的算法具有准确性、稳定性和有效性。

    Multiscale stochastic dynamical systems have been widely adopted to scientific and engineering problems due to their capability of depicting complex phenomena in many real world applications. This work is devoted to investigating the effective reduced dynamics for a slow-fast stochastic dynamical system. Given observation data on a short-term period satisfying some unknown slow-fast stochastic system, we propose a novel algorithm including a neural network called Auto-SDE to learn invariant slow manifold. Our approach captures the evolutionary nature of a series of time-dependent autoencoder neural networks with the loss constructed from a discretized stochastic differential equation. Our algorithm is also proved to be accurate, stable and effective through numerical experiments under various evaluation metrics.
    
[^23]: 截断扩散概率模型和基于扩散的对抗自编码器

    Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders. (arXiv:2202.09671v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.09671](http://arxiv.org/abs/2202.09671)

    我们提出了一种更快更廉价的截断扩散概率模型方法，通过从隐藏噪声数据分布开始生成数据，相较于传统的方法可以获得更好的性能改进。

    

    扩散型生成模型通过使用正向扩散链逐步将数据映射到噪声分布，并通过推断反向扩散链来学习如何生成数据。然而，这种方法速度慢且成本高，因为需要许多正向和反向步骤。我们提出了一种更快更廉价的方法，不是将噪声添加到数据变为纯随机噪声，而是直到达到一个可以自信学习的隐藏噪声数据分布。然后，我们使用较少的反向步骤通过从这个隐藏分布开始生成类似于噪声数据的数据。我们揭示了该模型可以被视为一个通过扩散过程和可学习的隐含先验增强的对抗性自编码器。实验结果表明，即使在较少的反向扩散步骤下，所提出的截断扩散概率模型在性能方面仍然可以相较于非截断模型提供一致的改进。

    Employing a forward diffusion chain to gradually map the data to a noise distribution, diffusion-based generative models learn how to generate the data by inferring a reverse diffusion chain. However, this approach is slow and costly because it needs many forward and reverse steps. We propose a faster and cheaper approach that adds noise not until the data become pure random noise, but until they reach a hidden noisy data distribution that we can confidently learn. Then, we use fewer reverse steps to generate data by starting from this hidden distribution that is made similar to the noisy data. We reveal that the proposed model can be cast as an adversarial auto-encoder empowered by both the diffusion process and a learnable implicit prior. Experimental results show even with a significantly smaller number of reverse diffusion steps, the proposed truncated diffusion probabilistic models can provide consistent improvements over the non-truncated ones in terms of performance in both unco
    
[^24]: 比较序贯预测器

    Comparing Sequential Forecasters. (arXiv:2110.00115v5 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2110.00115](http://arxiv.org/abs/2110.00115)

    本文提出了一种比较序贯预测器的方法，通过设计新的序贯推断程序来估计预测得分的时变差异，这种方法避免了对预测和结果生成方式的不可验证假设。

    

    考虑两个预测器，在一段时间内对一系列事件进行单次预测。我们提出一个相对基础的问题：在不假设预测和结果生成方式的情况下，我们如何比较这些预测器，无论是在线还是事后比较？在本文中，我们通过设计用于估计时变预测得分差异的新型序贯推断程序，对这个问题给出了严格的答案。为此，我们采用置信序列（CS），它是一系列置信区间，可以连续监测并在任意数据依赖停时（“anytime-valid”）下有效。我们的置信序列的宽度是自适应的，适应了得分差异的底层方差。它们的构建基于博弈论统计框架，在这个框架中，我们进一步确定了用于顺序检验弱零假设的e过程和p过程，即一个预测器平均表现是否优于另一个预测器。

    Consider two forecasters, each making a single prediction for a sequence of events over time. We ask a relatively basic question: how might we compare these forecasters, either online or post-hoc, while avoiding unverifiable assumptions on how the forecasts and outcomes were generated? In this paper, we present a rigorous answer to this question by designing novel sequential inference procedures for estimating the time-varying difference in forecast scores. To do this, we employ confidence sequences (CS), which are sequences of confidence intervals that can be continuously monitored and are valid at arbitrary data-dependent stopping times ("anytime-valid"). The widths of our CSs are adaptive to the underlying variance of the score differences. Underlying their construction is a game-theoretic statistical framework, in which we further identify e-processes and p-processes for sequentially testing a weak null hypothesis -- whether one forecaster outperforms another on average (rather tha
    
[^25]: 架起靶网络与功能正则化之间的鸿沟

    Bridging the Gap Between Target Networks and Functional Regularization. (arXiv:2106.02613v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.02613](http://arxiv.org/abs/2106.02613)

    该论文研究了靶网络与功能正则化在深度强化学习中的作用。通过实验证明靶网络作为隐式正则化器在某些情况下有利，但不灵活且可能导致不稳定。为了解决这些问题，作者提出了一种明确的功能正则化替代方法，并对其收敛性进行了理论研究。

    

    引导是深度强化学习成功的关键。然而，通过引导学习值函数往往导致训练不稳定，原因是目标值快速变化。靶网络通过使用额外的滞后参数集合来估计目标值，以稳定训练。尽管靶网络很受欢迎，但其对优化的影响仍未被理解。在这项工作中，我们展示了靶网络作为一个隐式正则化器的作用，它在某些情况下是有益的，但也存在一些缺点，如不灵活和可能导致不稳定，即使香草TD(0)收敛。为了克服这些问题，我们提出了一个明确的功能正则化替代方法，它在函数空间中是灵活和凸正则化器，并对其收敛性进行了理论研究。我们在一系列环境、折扣因子和非随机数据收集下进行了实验研究，以调查其有效性。

    Bootstrapping is behind much of the successes of deep Reinforcement Learning. However, learning the value function via bootstrapping often leads to unstable training due to fast-changing target values. Target Networks are employed to stabilize training by using an additional set of lagging parameters to estimate the target values. Despite the popularity of Target Networks, their effect on the optimization is still misunderstood. In this work, we show that they act as an implicit regularizer which can be beneficial in some cases, but also have disadvantages such as being inflexible and can result in instabilities, even when vanilla TD(0) converges. To overcome these issues, we propose an explicit Functional Regularization alternative that is flexible and a convex regularizer in function space and we theoretically study its convergence. We conduct an experimental study across a range of environments, discount factors, and off-policiness data collections to investigate the effectiveness o
    
[^26]: BoXHED2.0：可扩展的动态生存分析提升方法

    BoXHED2.0: Scalable boosting of dynamic survival analysis. (arXiv:2103.12591v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.12591](http://arxiv.org/abs/2103.12591)

    BoXHED2.0是一个可扩展的动态生存分析提升方法，适用于包括重复事件和竞争风险在内的多种生存环境，具有与参数化提升生存模型相媲美的速度。

    

    现代生存分析的应用越来越多地涉及到时间依赖的协变量。Python软件包BoXHED2.0是一个完全非参数的树提升生存风险估计器，适用于比右截尾更通用的生存环境，包括重复事件和竞争风险。由于其核心是用C++编写的，还支持使用GPU和多核CPU，因此BoXHED2.0的可伸缩性可与参数化提升生存模型相媲美。BoXHED2.0可从PyPI和www.github.com/BoXHED获取。

    Modern applications of survival analysis increasingly involve time-dependent covariates. The Python package BoXHED2.0 is a tree-boosted hazard estimator that is fully nonparametric, and is applicable to survival settings far more general than right-censoring, including recurring events and competing risks. BoXHED2.0 is also scalable to the point of being on the same order of speed as parametric boosted survival models, in part because its core is written in C++ and it also supports the use of GPUs and multicore CPUs. BoXHED2.0 is available from PyPI and also from www.github.com/BoXHED.
    
[^27]: 线性动态系统的适当学习作为非交换多项式优化问题

    Proper Learning of Linear Dynamical Systems as a Non-Commutative Polynomial Optimisation Problem. (arXiv:2002.01444v5 [math.OC] UPDATED)

    [http://arxiv.org/abs/2002.01444](http://arxiv.org/abs/2002.01444)

    该论文提出了一种方法来解决适当学习线性动态系统的问题，通过非交换多项式优化，保证了数值解对最小二乘估计器的全局收敛性。

    

    最近在预测线性动态系统（LDS）的下一个观测值（称为不适当学习）以及估计其系统矩阵（称为适当学习LDS）方面取得了很大进展。我们提出了一种适当学习LDS的方法，尽管问题非凸，但能够保证数值解的全局收敛性到最小二乘估计器。我们展示了有希望的计算结果。

    There has been much recent progress in forecasting the next observation of a linear dynamical system (LDS), which is known as the improper learning, as well as in the estimation of its system matrices, which is known as the proper learning of LDS. We present an approach to proper learning of LDS, which in spite of the non-convexity of the problem, guarantees global convergence of numerical solutions to a least-squares estimator. We present promising computational results.
    
[^28]: Copula表示和误差面投影对于异或问题的应用

    Copula Representations and Error Surface Projections for the Exclusive Or Problem. (arXiv:1907.04483v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1907.04483](http://arxiv.org/abs/1907.04483)

    本研究讨论了通过概率逻辑和关联Copula函数解决异或表示和逼近问题的方法，并通过比较不同激活函数下的误差面动态来说明其优势。通过将xor表示从布尔值扩展到实数值，我们提供了一种演示交叉验证概念的方便方式。

    

    异或（xor）函数是展示为什么非线性前馈网络在机器学习应用中优于线性回归的最简单的示例之一。我们通过概率逻辑和关联Copula函数讨论了xor表示和逼近问题及其解决方案。在简要回顾前馈网络规范之后，我们通过一组色彩丰富的三维图表比较了使用RELU和tanh等不同激活函数的学习误差面的动态。Copula表示将xor从布尔值扩展到实数值，从而提供了一种方便的方式来演示在样本内和样本外数据集上的交叉验证的概念。我们的方法是教学性的，旨在成为机器学习导论。

    The exclusive or (xor) function is one of the simplest examples that illustrate why nonlinear feedforward networks are superior to linear regression for machine learning applications. We review the xor representation and approximation problems and discuss their solutions in terms of probabilistic logic and associative copula functions. After briefly reviewing the specification of feedforward networks, we compare the dynamics of learned error surfaces with different activation functions such as RELU and tanh through a set of colorful three-dimensional charts. The copula representations extend xor from Boolean to real values, thereby providing a convenient way to demonstrate the concept of cross-validation on in-sample and out-sample data sets. Our approach is pedagogical and is meant to be a machine learning prolegomenon.
    

