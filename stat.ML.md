# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Variable selection for Na\"ive Bayes classification](https://arxiv.org/abs/2401.18039) | 该论文提出了一种稀疏版本的Na\"ive Bayes分类器，通过考虑特征间的相关结构实现了稀疏性，并支持不同的性能度量来指导特征选择。 |
| [^2] | [A cost-sensitive constrained Lasso](https://arxiv.org/abs/2401.18023) | 这种成本敏感的约束Lasso提出了一种新颖的Lasso版本，在Lasso基础上添加了二次性能约束，以限制不同感兴趣组中的预测误差。该方法适用于异质样本，具有许多生物医学背景下的直接应用。 |
| [^3] | [Causal Discovery by Kernel Deviance Measures with Heterogeneous Transforms](https://arxiv.org/abs/2401.18017) | 本文提出了一种通过异构变换的核偏差测量来解决因果关系发现中的挑战，以捕捉因果关系和效应之间的高阶结构变异的主要标记。 |
| [^4] | [Causal Coordinated Concurrent Reinforcement Learning](https://arxiv.org/abs/2401.18012) | 这项工作提出了一种用于并发强化学习的新算法框架，通过数据共享和协同探索来学习更高效和表现更好的策略。算法中利用因果推断算法提取控制个体差异的模型参数，并提出了一种基于相似性度量的数据共享方案，展示了更快的学习速度和多样化动作选择的有效性。 |
| [^5] | [Convergence Analysis for General Probability Flow ODEs of Diffusion Models in Wasserstein Distances](https://arxiv.org/abs/2401.17958) | 本文提供了在2-Wasserstein距离中的一般类概率流ODE抽样器的非渐近收敛性分析，假设得分估计准确。 |
| [^6] | [Multitask methods for predicting molecular properties from heterogeneous data](https://arxiv.org/abs/2401.17898) | 多任务方法可以通过利用异质数据源来预测分子属性，大大降低数据生成成本，并且达到与耦合簇数据相当的准确度。 |
| [^7] | [Robustly overfitting latents for flexible neural image compression](https://arxiv.org/abs/2401.17789) | 这项研究提出了一种鲁棒的过拟合潜变量方法来改进神经图像压缩模型，通过使用SGA+，可以显著提高性能并减少对超参数选择的敏感性。 |
| [^8] | [Double InfoGAN for Contrastive Analysis](https://arxiv.org/abs/2401.17776) | 这篇论文提出了双重InfoGAN方法用于对比分析，通过结合GAN的高质量合成和InfoGAN的分离能力，有效地解决了当前基于VAE的方法在处理共同因素和特殊因素时的不足，并在不同的视觉数据集上展现出优越的性能。 |
| [^9] | [Convergence of Expectation-Maximization Algorithm with Mixed-Integer Optimization](https://arxiv.org/abs/2401.17763) | 本文引入了一组条件，保证了一类估计离散和连续参数混合的特定EM算法的收敛性，并为解决混合整数非线性优化问题的迭代算法提供了一种新的分析技术。 |
| [^10] | [Regularized Linear Discriminant Analysis Using a Nonlinear Covariance Matrix Estimator](https://arxiv.org/abs/2401.17760) | 本文研究了使用非线性协方差矩阵估计器的正则化线性判别分析方法，以解决特征空间维度高于训练数据大小时数据协方差矩阵病态导致效率低下的问题。 |
| [^11] | [Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation](https://arxiv.org/abs/2401.17737) | BICauseTree是一种基于层级偏差驱动分层的可解释因果效应估计方法，通过使用决策树进行平衡、减少偏差和确定目标人群定义，提供了可解释性和透明性。 |
| [^12] | [Convergence analysis of t-SNE as a gradient flow for point cloud on a manifold](https://arxiv.org/abs/2401.17675) | 我们在本论文提出了关于t-SNE算法的收敛性分析，证明了t-SNE生成的点是有界的，并得出了KL散度最小值的存在性。 |
| [^13] | [Tensor-based process control and monitoring for semiconductor manufacturing with unstable disturbances](https://arxiv.org/abs/2401.17573) | 本文提出了一种基于张量的工艺控制和监控方法，用于半导体制造过程中高维度基于图像的叠加误差的复杂结构。该方法通过有限的控制配方减小叠加误差，并设计了稳定的张量数据控制器来处理高维度扰动。 |
| [^14] | [Game-Theoretic Unlearnable Example Generator](https://arxiv.org/abs/2401.17523) | 本论文研究了从游戏论域的角度来进行不可学习示例攻击的方法。研究发现，博弈均衡给出了最强大的毒攻击，并提出了一种名为游戏论域不可学习示例（GUE）的新攻击方法。 |
| [^15] | [Explaining Predictive Uncertainty by Exposing Second-Order Effects](https://arxiv.org/abs/2401.17441) | 该论文研究发现，预测不确定性主要受到单个特征或特征之间乘积相互作用的二阶影响的影响。作者提出了一种基于这些二阶影响来解释预测不确定性的新方法。该方法通过简单的协方差计算对一阶解释进行处理，可以将常见的归因技术转化为强大的二阶不确定性解释器。作者通过量化评估验证了该方法解释的准确性，并展示了整体实用性。 |
| [^16] | [Superiority of Multi-Head Attention in In-Context Linear Regression](https://arxiv.org/abs/2401.17426) | 多头注意力在上下文线性回归任务中表现出优于单头注意力的性能，通过理论分析证明了多头注意力在大嵌入维度情况下有更小的预测损失，并且在各种数据分布设置下都显示出优势。 |
| [^17] | [Decentralized Federated Learning: A Survey on Security and Privacy](https://arxiv.org/abs/2401.17319) | 去中心化联邦学习架构允许保护隐私，但也引入了新的安全和隐私威胁，该综述对去中心化联邦学习中的威胁、对手和防御机制进行了研究。 |
| [^18] | [Calibrating dimension reduction hyperparameters in the presence of noise](https://arxiv.org/abs/2312.02946) | 本文提出了一个框架，用于在噪声存在的情况下校准降维超参数，探索了困惑度和维度数量的作用。 |
| [^19] | [Intrinsic Gaussian Processes on Manifolds and Their Accelerations by Symmetry](https://arxiv.org/abs/2006.14266) | 本研究提出了一种在一般流形上构造高斯过程的方法，并引入了适用于具有额外对称性流形的条带算法和适用于任意流形的球算法，这些算法的有效性通过理论证明和数值测试得到了验证。 |
| [^20] | [Causal Machine Learning for Cost-Effective Allocation of Development Aid.](http://arxiv.org/abs/2401.16986) | 本文提出了一个因果机器学习框架，用于预测援助分配的异质化治疗效果，以支持有效的援助分配决策。 |
| [^21] | [Rademacher Complexity of Neural ODEs via Chen-Fliess Series.](http://arxiv.org/abs/2401.16655) | 本文通过Chen-Fliess序列展开将连续深度神经ODE模型转化为单层、无限宽度的网络，并利用此框架推导出了将初始条件映射到某个终端时间的ODE模型的Rademacher复杂度的紧凑表达式。 |
| [^22] | [Improving Antibody Humanness Prediction using Patent Data.](http://arxiv.org/abs/2401.14442) | 本研究利用专利数据提高了抗体人性预测的能力，通过多阶段、多损失的训练过程以及弱监督对比学习的方法，成功地预测了抗体序列的人性评分。 |
| [^23] | [Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes.](http://arxiv.org/abs/2401.04286) | 本文扩展了之前的结果，证明了基于宽而深的ReLU神经网络和逻辑损失训练的分类规则具有普适一致性，并给出了一类概率测度条件下基于神经网络的分类器实现极小极限收敛速率的充分条件。 |
| [^24] | [Vanishing Gradients in Reinforcement Finetuning of Language Models.](http://arxiv.org/abs/2310.20703) | 本研究发现在强化微调（RFT）中存在梯度消失的问题，当模型下奖励的标准差较小时，输入的期望梯度会消失，导致奖励最大化缓慢。初始监督微调（SFT）阶段是克服这个问题的最有希望的方法。 |
| [^25] | [Fundamental Limits of Membership Inference Attacks on Machine Learning Models.](http://arxiv.org/abs/2310.13786) | 本文探讨了机器学习模型上成员推断攻击的基本限制，包括推导了效果和成功率的统计量，并提供了几种情况下的界限。这使得我们能够根据样本数量和其他结构参数推断潜在攻击的准确性。 |
| [^26] | [Deep Network Approximation: Beyond ReLU to Diverse Activation Functions.](http://arxiv.org/abs/2307.06555) | 本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。 |
| [^27] | [Uncertainty Quantification via Spatial-Temporal Tweedie Model for Zero-inflated and Long-tail Travel Demand Prediction.](http://arxiv.org/abs/2306.09882) | 本文提出了一种新型的时空Tweedie模型STTD，旨在解决高分辨率OD矩阵中稀疏和长尾特征的问题，并成功量化预测不确定性，具有很高的应用前景。 |
| [^28] | [Combinatorial and algebraic perspectives on the marginal independence structure of Bayesian networks.](http://arxiv.org/abs/2210.00822) | 本研究通过组合和代数视角探讨了贝叶斯网络的边际独立结构问题，并提出了一个基于 Gröbner 基础的 MCMC 方法 GrUES，该方法在恢复真实结构和估计后验上具有优势。 |

# 详细

[^1]: Na\"ive Bayes分类的变量选择

    Variable selection for Na\"ive Bayes classification

    [https://arxiv.org/abs/2401.18039](https://arxiv.org/abs/2401.18039)

    该论文提出了一种稀疏版本的Na\"ive Bayes分类器，通过考虑特征间的相关结构实现了稀疏性，并支持不同的性能度量来指导特征选择。

    

    在多变量分析中，经典的Na\"ive Bayes分类方法已被证明是一种易于处理和高效的方法。然而，特征通常是相关的，这违反了Na\"ive Bayes条件独立性的假设，可能会损害该方法的性能。此外，数据集通常具有大量的特征，这可能会使结果的解释变得复杂，并减慢该方法的执行。在本文中，我们提出了一种稀疏版本的Na\"ive Bayes分类器，它具有三个特点。首先，通过考虑协变量的相关结构实现了稀疏性。其次，可以使用不同的性能度量来指导特征的选择。第三，可以包括对更感兴趣的组别的性能约束。我们的提案可以实现智能搜索，具有竞争力的运行时间，同时在分类的性能度量方面具有灵活性。

    The Na\"ive Bayes has proven to be a tractable and efficient method for classification in multivariate analysis. However, features are usually correlated, a fact that violates the Na\"ive Bayes' assumption of conditional independence, and may deteriorate the method's performance. Moreover, datasets are often characterized by a large number of features, which may complicate the interpretation of the results as well as slow down the method's execution.   In this paper we propose a sparse version of the Na\"ive Bayes classifier that is characterized by three properties. First, the sparsity is achieved taking into account the correlation structure of the covariates. Second, different performance measures can be used to guide the selection of features. Third, performance constraints on groups of higher interest can be included. Our proposal leads to a smart search, which yields competitive running times, whereas the flexibility in terms of performance measure for classification is integrate
    
[^2]: 一种成本敏感的约束Lasso

    A cost-sensitive constrained Lasso

    [https://arxiv.org/abs/2401.18023](https://arxiv.org/abs/2401.18023)

    这种成本敏感的约束Lasso提出了一种新颖的Lasso版本，在Lasso基础上添加了二次性能约束，以限制不同感兴趣组中的预测误差。该方法适用于异质样本，具有许多生物医学背景下的直接应用。

    

    Lasso已经成为一个基准数据分析方法，并且在文献中提出了许多变体。虽然Lasso的公式是为了优化整体预测误差而设定的，但不能对感兴趣的特定个体的准确性预测进行完全控制。在这项工作中，我们提出了一种新颖的Lasso版本，其中通过向基于Lasso的目标函数添加二次性能约束的方式来设置阈值，以限制不同感兴趣组（不一定互斥）中的预测误差。因此，通过非线性优化问题定义了一种受成本限制的稀疏回归模型。这种成本敏感的约束Lasso在异质样本中具有直接应用，其中数据是从不同来源收集的，这在许多生物医学背景下是标准的。本文探讨了这种新方法的理论性质和经验证明研究。此外，本文还进行了两个应用示例的演示：

    The Lasso has become a benchmark data analysis procedure, and numerous variants have been proposed in the literature. Although the Lasso formulations are stated so that overall prediction error is optimized, no full control over the accuracy prediction on certain individuals of interest is allowed. In this work we propose a novel version of the Lasso in which quadratic performance constraints are added to Lasso-based objective functions, in such a way that threshold values are set to bound the prediction errors in the different groups of interest (not necessarily disjoint). As a result, a constrained sparse regression model is defined by a nonlinear optimization problem. This cost-sensitive constrained Lasso has a direct application in heterogeneous samples where data are collected from distinct sources, as it is standard in many biomedical contexts. Both theoretical properties and empirical studies concerning the new method are explored in this paper. In addition, two illustrations of
    
[^3]: 通过异构变换的核偏差测量来进行因果关系发现

    Causal Discovery by Kernel Deviance Measures with Heterogeneous Transforms

    [https://arxiv.org/abs/2401.18017](https://arxiv.org/abs/2401.18017)

    本文提出了一种通过异构变换的核偏差测量来解决因果关系发现中的挑战，以捕捉因果关系和效应之间的高阶结构变异的主要标记。

    

    在一组随机变量中发现因果关系是科学的基本目标，并且最近也被认为是实现真正机器智能的必要组成部分。其中一类因果关系发现技术基于这样一种论点：因果方向和反因果方向之间存在固有的结构不对称性，可以利用这种不对称性来确定因果关系的方向。然而，如何捕捉因果关系和效应之间的差异仍然是一个挑战，许多当前最先进的算法提出了通过比较条件分布的核均值嵌入的范数来解决这个问题。本文认为，基于RKHS嵌入的这种方法不足以捕捉涉及条件分布的高阶结构变异的主要标记的因果效应不对称性。因此，我们提出了一种引入了异构变换的核内在不变性测量（KIIM-HT）方法。

    The discovery of causal relationships in a set of random variables is a fundamental objective of science and has also recently been argued as being an essential component towards real machine intelligence. One class of causal discovery techniques are founded based on the argument that there are inherent structural asymmetries between the causal and anti-causal direction which could be leveraged in determining the direction of causation. To go about capturing these discrepancies between cause and effect remains to be a challenge and many current state-of-the-art algorithms propose to compare the norms of the kernel mean embeddings of the conditional distributions. In this work, we argue that such approaches based on RKHS embeddings are insufficient in capturing principal markers of cause-effect asymmetry involving higher-order structural variabilities of the conditional distributions. We propose Kernel Intrinsic Invariance Measure with Heterogeneous Transform (KIIM-HT) which introduces 
    
[^4]: 因果协同并发强化学习

    Causal Coordinated Concurrent Reinforcement Learning

    [https://arxiv.org/abs/2401.18012](https://arxiv.org/abs/2401.18012)

    这项工作提出了一种用于并发强化学习的新算法框架，通过数据共享和协同探索来学习更高效和表现更好的策略。算法中利用因果推断算法提取控制个体差异的模型参数，并提出了一种基于相似性度量的数据共享方案，展示了更快的学习速度和多样化动作选择的有效性。

    

    在这项工作中，我们提出了一种新颖的算法框架，用于数据共享和协同探索，以在并发强化学习（CRL）环境下学习更高效和表现更好的策略。与其他假设所有代理都在相同环境下行动的工作相比，我们放宽了这一限制，而是考虑每个代理在共享全局结构但也存在个体差异的环境中行动的情况。我们的算法利用了一个因果推断算法，即加性噪声模型 - 混合模型（ANM-MM），通过独立性强化提取控制个体差异的模型参数。我们提出了一种基于提取的模型参数相似性度量的数据共享方案，并在一组自回归、摆杆和倒立摆任务上展示了更快的学习速度，最后我们展示了多样化动作选择的有效性。

    In this work, we propose a novel algorithmic framework for data sharing and coordinated exploration for the purpose of learning more data-efficient and better performing policies under a concurrent reinforcement learning (CRL) setting. In contrast to other work which make the assumption that all agents act under identical environments, we relax this restriction and instead consider the formulation where each agent acts within an environment which shares a global structure but also exhibits individual variations. Our algorithm leverages a causal inference algorithm in the form of Additive Noise Model - Mixture Model (ANM-MM) in extracting model parameters governing individual differentials via independence enforcement. We propose a new data sharing scheme based on a similarity measure of the extracted model parameters and demonstrate superior learning speeds on a set of autoregressive, pendulum and cart-pole swing-up tasks and finally, we show the effectiveness of diverse action selecti
    
[^5]: 在Wasserstein距离中的扩散模型的一般概率流ODE的收敛性分析

    Convergence Analysis for General Probability Flow ODEs of Diffusion Models in Wasserstein Distances

    [https://arxiv.org/abs/2401.17958](https://arxiv.org/abs/2401.17958)

    本文提供了在2-Wasserstein距离中的一般类概率流ODE抽样器的非渐近收敛性分析，假设得分估计准确。

    

    基于概率流常微分方程（ODE）的基于得分的生成模型在各种应用中取得了显著的成功。虽然文献中提出了各种快速的基于ODE的抽样器并在实践中使用，但对概率流ODE的收敛性属性的理论理解仍然非常有限。在本文中，我们提供了适用于2-Wasserstein距离中的一般类概率流ODE抽样器的首个非渐近收敛性分析结果，假设准确的得分估计。接下来，我们考虑了各种示例，并确定了相应基于ODE的抽样器的迭代复杂度的结果。

    Score-based generative modeling with probability flow ordinary differential equations (ODEs) has achieved remarkable success in a variety of applications. While various fast ODE-based samplers have been proposed in the literature and employed in practice, the theoretical understandings about convergence properties of the probability flow ODE are still quite limited. In this paper, we provide the first non-asymptotic convergence analysis for a general class of probability flow ODE samplers in 2-Wasserstein distance, assuming accurate score estimates. We then consider various examples and establish results on the iteration complexity of the corresponding ODE-based samplers.
    
[^6]: 从异质数据预测分子属性的多任务方法

    Multitask methods for predicting molecular properties from heterogeneous data

    [https://arxiv.org/abs/2401.17898](https://arxiv.org/abs/2401.17898)

    多任务方法可以通过利用异质数据源来预测分子属性，大大降低数据生成成本，并且达到与耦合簇数据相当的准确度。

    

    数据生成仍然是训练代理模型预测分子属性的瓶颈。我们证明，多任务高斯过程回归通过利用昂贵和廉价的数据源，克服了这个限制。特别是，我们考虑从耦合簇（CC）和密度泛函理论（DFT）数据构建的训练集。我们报告说，多任务代理模型可以以CC级精度进行预测，并且数据生成成本减少了一个数量级。值得注意的是，我们的方法允许训练集包括由异质混合的交换相关泛函生成的DFT数据，而不对泛函精度施加任何人为的层次结构。更一般地，多任务框架可以适应更广泛范围的训练集结构，包括不同保真级别之间的完全差异，而不像现有的基于$\Delta$学习的核方法那样，我们证明这两种方法的准确度可以相似。

    Data generation remains a bottleneck in training surrogate models to predict molecular properties. We demonstrate that multitask Gaussian process regression overcomes this limitation by leveraging both expensive and cheap data sources. In particular, we consider training sets constructed from coupled-cluster (CC) and density function theory (DFT) data. We report that multitask surrogates can predict at CC level accuracy with a reduction to data generation cost by over an order of magnitude. Of note, our approach allows the training set to include DFT data generated by a heterogeneous mix of exchange-correlation functionals without imposing any artificial hierarchy on functional accuracy. More generally, the multitask framework can accommodate a wider range of training set structures -- including full disparity between the different levels of fidelity -- than existing kernel approaches based on $\Delta$-learning, though we show that the accuracy of the two approaches can be similar. Con
    
[^7]: 弹性神经图像压缩中的鲁棒过拟合潜变量

    Robustly overfitting latents for flexible neural image compression

    [https://arxiv.org/abs/2401.17789](https://arxiv.org/abs/2401.17789)

    这项研究提出了一种鲁棒的过拟合潜变量方法来改进神经图像压缩模型，通过使用SGA+，可以显著提高性能并减少对超参数选择的敏感性。

    

    神经图像压缩取得了很大的进展。最先进的模型基于变分自编码器，胜过了传统模型。神经压缩模型学会将图像编码为量化的潜变量表示，然后将其高效地发送给解码器，解码器再将量化的潜变量解码为重建图像。虽然这些模型在实践中取得了成功，但由于优化不完美以及编码器和解码器容量的限制，它们导致了次优结果。最近的研究表明，如何利用随机Gumbel退火（SGA）来改进预训练的神经图像压缩模型的潜变量。我们通过引入SGA+扩展了这个想法，SGA+包含了三种不同的方法，这些方法都建立在SGA的基础上。此外，我们对我们提出的方法进行了详细分析，展示了它们如何改进性能，并且证明它们对超参数选择不敏感。此外，我们还展示了如何将每个方法扩展到三个而不是两个。

    Neural image compression has made a great deal of progress. State-of-the-art models are based on variational autoencoders and are outperforming classical models. Neural compression models learn to encode an image into a quantized latent representation that can be efficiently sent to the decoder, which decodes the quantized latent into a reconstructed image. While these models have proven successful in practice, they lead to sub-optimal results due to imperfect optimization and limitations in the encoder and decoder capacity. Recent work shows how to use stochastic Gumbel annealing (SGA) to refine the latents of pre-trained neural image compression models. We extend this idea by introducing SGA+, which contains three different methods that build upon SGA. Further, we give a detailed analysis of our proposed methods, show how they improve performance, and show that they are less sensitive to hyperparameter choices. Besides, we show how each method can be extended to three- instead of two
    
[^8]: 双重InfoGAN用于对比分析

    Double InfoGAN for Contrastive Analysis

    [https://arxiv.org/abs/2401.17776](https://arxiv.org/abs/2401.17776)

    这篇论文提出了双重InfoGAN方法用于对比分析，通过结合GAN的高质量合成和InfoGAN的分离能力，有效地解决了当前基于VAE的方法在处理共同因素和特殊因素时的不足，并在不同的视觉数据集上展现出优越的性能。

    

    对比分析（CA）处理的是发现目标领域与背景领域相比的共同点和特殊点。这在许多应用中具有极大的兴趣，例如医学成像。目前的最新方法是基于VAE的潜在变量模型（CA-VAEs）。然而，它们要么忽略重要的约束条件，要么没有强制执行基本假设。这可能导致次优解，其中将特殊因素误认为共同因素（或反之亦然）。此外，生成的图像具有VAE的较差质量，降低了其可解释性和实用性。在这里，我们提出了双重InfoGAN，这是第一个基于GAN的CA方法，它充分利用了GAN的高质量合成和InfoGAN的分离能力。在从简单的合成示例到复杂的医学图像的四个视觉数据集上的实验结果表明，所提出的方法在潜在分离和图像质量方面优于最新的CA-VAEs。

    Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CA-VAEs). However, they all either ignore important constraints or they don't enforce fundamental assumptions. This may lead to sub-optimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image qu
    
[^9]: 基于混合整数优化的期望最大化算法的收敛性

    Convergence of Expectation-Maximization Algorithm with Mixed-Integer Optimization

    [https://arxiv.org/abs/2401.17763](https://arxiv.org/abs/2401.17763)

    本文引入了一组条件，保证了一类估计离散和连续参数混合的特定EM算法的收敛性，并为解决混合整数非线性优化问题的迭代算法提供了一种新的分析技术。

    

    期望最大化（EM）算法的收敛通常需要似然函数对所有未知参数（优化变量）连续。当参数包括离散和连续变量时，这一要求无法满足，导致收敛分析非常困难。本文引入了一组条件，保证了一类估计离散和连续参数混合的特定EM算法的收敛性。我们的结果为解决混合整数非线性优化问题的迭代算法提供了一种新的分析技术。作为一个具体的例子，我们证明了基于EM的稀疏贝叶斯学习算法在估计具有联合稀疏输入和断续缺失观测的线性动态系统的状态时的收敛性。我们的结果证明了[1]中的算法收敛到最大似然代价关于连续优化变量的稳定点集。

    The convergence of expectation-maximization (EM)-based algorithms typically requires continuity of the likelihood function with respect to all the unknown parameters (optimization variables). The requirement is not met when parameters comprise both discrete and continuous variables, making the convergence analysis nontrivial. This paper introduces a set of conditions that ensure the convergence of a specific class of EM algorithms that estimate a mixture of discrete and continuous parameters. Our results offer a new analysis technique for iterative algorithms that solve mixed-integer non-linear optimization problems. As a concrete example, we prove the convergence of the EM-based sparse Bayesian learning algorithm in [1] that estimates the state of a linear dynamical system with jointly sparse inputs and bursty missing observations. Our results establish that the algorithm in [1] converges to the set of stationary points of the maximum likelihood cost with respect to the continuous opt
    
[^10]: 使用非线性协方差矩阵估计器的正则化线性判别分析方法

    Regularized Linear Discriminant Analysis Using a Nonlinear Covariance Matrix Estimator

    [https://arxiv.org/abs/2401.17760](https://arxiv.org/abs/2401.17760)

    本文研究了使用非线性协方差矩阵估计器的正则化线性判别分析方法，以解决特征空间维度高于训练数据大小时数据协方差矩阵病态导致效率低下的问题。

    

    线性判别分析（LDA）是一种广泛使用的数据分类技术。该方法在许多分类问题中具有良好的性能，但在数据协方差矩阵病态条件下效率低下。这通常发生在特征空间的维度高于或接近训练数据大小的情况下。为了应对这种情况，提出了基于正则化线性估计器的正则化LDA（RLDA）方法。RLDA方法的性能已得到充分研究，并已提出了最优的正则化方案。本文研究了与非线性（NL）协方差矩阵估计器相一致的正半定 Ridge 型逆协方差矩阵估计器的能力。通过重新制定利用线性估计方法的最优分类器的得分函数，得到了该估计器，最终形成了所提出的NL-RLDA分类器。

    Linear discriminant analysis (LDA) is a widely used technique for data classification. The method offers adequate performance in many classification problems, but it becomes inefficient when the data covariance matrix is ill-conditioned. This often occurs when the feature space's dimensionality is higher than or comparable to the training data size. Regularized LDA (RLDA) methods based on regularized linear estimators of the data covariance matrix have been proposed to cope with such a situation. The performance of RLDA methods is well studied, with optimal regularization schemes already proposed. In this paper, we investigate the capability of a positive semidefinite ridge-type estimator of the inverse covariance matrix that coincides with a nonlinear (NL) covariance matrix estimator. The estimator is derived by reformulating the score function of the optimal classifier utilizing linear estimation methods, which eventually results in the proposed NL-RLDA classifier. We derive asymptot
    
[^11]: 基于层级偏差驱动分层的可解释因果效应估计

    Hierarchical Bias-Driven Stratification for Interpretable Causal Effect Estimation

    [https://arxiv.org/abs/2401.17737](https://arxiv.org/abs/2401.17737)

    BICauseTree是一种基于层级偏差驱动分层的可解释因果效应估计方法，通过使用决策树进行平衡、减少偏差和确定目标人群定义，提供了可解释性和透明性。

    

    可解释性和透明性对于将观察数据中的因果效应模型纳入政策决策至关重要。它们可以在缺乏真实标签来评估这些模型准确性的情况下提供对模型的信任。到目前为止，透明的因果效应估计尝试包括将事后解释方法应用于不可解释的黑盒模型。在这里，我们提出了BICauseTree：一种可解释的平衡方法，用于识别局部发生自然实验的聚类。我们的方法基于带有自定义目标函数的决策树，以改进平衡和减少处理分配偏差。因此，它还可以检测出存在正性违规的子群体，排除它们，并提供基于协变量的目标人群定义，我们可以从中推断并推广。我们使用合成和真实数据集评估该方法的性能，并探索其偏差可解释性的权衡。

    Interpretability and transparency are essential for incorporating causal effect models from observational data into policy decision-making. They can provide trust for the model in the absence of ground truth labels to evaluate the accuracy of such models. To date, attempts at transparent causal effect estimation consist of applying post hoc explanation methods to black-box models, which are not interpretable. Here, we present BICauseTree: an interpretable balancing method that identifies clusters where natural experiments occur locally. Our approach builds on decision trees with a customized objective function to improve balancing and reduce treatment allocation bias. Consequently, it can additionally detect subgroups presenting positivity violations, exclude them, and provide a covariate-based definition of the target population we can infer from and generalize to. We evaluate the method's performance using synthetic and realistic datasets, explore its bias-interpretability tradeoff, 
    
[^12]: t-SNE作为流形上点云的梯度流的收敛分析

    Convergence analysis of t-SNE as a gradient flow for point cloud on a manifold

    [https://arxiv.org/abs/2401.17675](https://arxiv.org/abs/2401.17675)

    我们在本论文提出了关于t-SNE算法的收敛性分析，证明了t-SNE生成的点是有界的，并得出了KL散度最小值的存在性。

    

    我们提出了关于t-SNE算法有界性的理论基础。t-SNE采用梯度下降迭代和KL散度作为目标函数，旨在在高维空间中找到一组点，使其与原始数据点的相似度较高，最小化KL散度。在对采样数据集进行弱收敛假设的情况下，研究了t-SNE的属性，如困惑度和相似度，探究了t-SNE生成的点在连续梯度流下的行为。通过证明t-SNE生成的点保持有界，我们利用这个结论来建立KL散度的最小值存在性。

    We present a theoretical foundation regarding the boundedness of the t-SNE algorithm. t-SNE employs gradient descent iteration with Kullback-Leibler (KL) divergence as the objective function, aiming to identify a set of points that closely resemble the original data points in a high-dimensional space, minimizing KL divergence. Investigating t-SNE properties such as perplexity and affinity under a weak convergence assumption on the sampled dataset, we examine the behavior of points generated by t-SNE under continuous gradient flow. Demonstrating that points generated by t-SNE remain bounded, we leverage this insight to establish the existence of a minimizer for KL divergence.
    
[^13]: 基于张量的半导体制造过程控制与监控研究

    Tensor-based process control and monitoring for semiconductor manufacturing with unstable disturbances

    [https://arxiv.org/abs/2401.17573](https://arxiv.org/abs/2401.17573)

    本文提出了一种基于张量的工艺控制和监控方法，用于半导体制造过程中高维度基于图像的叠加误差的复杂结构。该方法通过有限的控制配方减小叠加误差，并设计了稳定的张量数据控制器来处理高维度扰动。

    

    随着制造系统中安装传感器的发展和普及，制造过程中收集到了复杂的数据，给传统的过程控制方法带来了挑战。本文提出了一种新颖的工艺控制和监控方法，用于半导体制造过程中高维度基于图像的叠加误差（以张量形式建模）的复杂结构。所提出的方法旨在使用有限的控制配方减小叠加误差。首先建立了一个高维度的过程模型，并提出了不同的张量-向量回归算法来估计模型中的参数，以减轻维度灾难。然后，基于张量参数的估计，设计了具有稳定性的指数加权移动平均（EWMA）张量数据控制器，其稳定性在理论上得到了保证。考虑到低维度的控制配方不能弥补所有高维度扰动的事实。

    With the development and popularity of sensors installed in manufacturing systems, complex data are collected during manufacturing processes, which brings challenges for traditional process control methods. This paper proposes a novel process control and monitoring method for the complex structure of high-dimensional image-based overlay errors (modeled in tensor form), which are collected in semiconductor manufacturing processes. The proposed method aims to reduce overlay errors using limited control recipes. We first build a high-dimensional process model and propose different tensor-on-vector regression algorithms to estimate parameters in the model to alleviate the curse of dimensionality. Then, based on the estimate of tensor parameters, the exponentially weighted moving average (EWMA) controller for tensor data is designed whose stability is theoretically guaranteed. Considering the fact that low-dimensional control recipes cannot compensate for all high-dimensional disturbances o
    
[^14]: 游戏论域不可学习示例生成器

    Game-Theoretic Unlearnable Example Generator

    [https://arxiv.org/abs/2401.17523](https://arxiv.org/abs/2401.17523)

    本论文研究了从游戏论域的角度来进行不可学习示例攻击的方法。研究发现，博弈均衡给出了最强大的毒攻击，并提出了一种名为游戏论域不可学习示例（GUE）的新攻击方法。

    

    不可学习示例攻击是一种数据毒化攻击，旨在通过向训练样本添加微不可察觉的扰动，降低深度学习的干净测试准确性，这可以被定义为一个二层优化问题。然而，直接解决这个优化问题对于深度神经网络来说是难以处理的。在本文中，我们从博弈论的角度对不可学习示例攻击进行了研究，将攻击形式化为一个非零和Stackelberg博弈。首先，在正常设置和对抗训练设置下证明了博弈均衡的存在性。结果表明，在使用特定损失函数时，博弈均衡给出了最强大的毒攻击，即在相同假设空间内，受害者的测试准确率最低。其次，我们提出了一种新的攻击方法，称为游戏论域不可学习示例（GUE），它主要包括三个梯度。（1）通过直接求解均衡获得毒攻击。

    Unlearnable example attacks are data poisoning attacks aiming to degrade the clean test accuracy of deep learning by adding imperceptible perturbations to the training samples, which can be formulated as a bi-level optimization problem. However, directly solving this optimization problem is intractable for deep neural networks. In this paper, we investigate unlearnable example attacks from a game-theoretic perspective, by formulating the attack as a nonzero sum Stackelberg game. First, the existence of game equilibria is proved under the normal setting and the adversarial training setting. It is shown that the game equilibrium gives the most powerful poison attack in that the victim has the lowest test accuracy among all networks within the same hypothesis space, when certain loss functions are used. Second, we propose a novel attack method, called the Game Unlearnable Example (GUE), which has three main gradients. (1) The poisons are obtained by directly solving the equilibrium of the
    
[^15]: 揭示二阶影响来解释预测不确定性

    Explaining Predictive Uncertainty by Exposing Second-Order Effects

    [https://arxiv.org/abs/2401.17441](https://arxiv.org/abs/2401.17441)

    该论文研究发现，预测不确定性主要受到单个特征或特征之间乘积相互作用的二阶影响的影响。作者提出了一种基于这些二阶影响来解释预测不确定性的新方法。该方法通过简单的协方差计算对一阶解释进行处理，可以将常见的归因技术转化为强大的二阶不确定性解释器。作者通过量化评估验证了该方法解释的准确性，并展示了整体实用性。

    

    可解释的人工智能（Explainable AI）使复杂的机器学习黑箱变得透明，特别是可以确定模型用来进行预测的特征。然而，关于解释预测不确定性，即为什么模型“不确定”，目前研究较少。我们的研究发现，预测不确定性主要由涉及单个特征或特征之间的乘积相互作用的二阶影响所主导。我们提出了一种基于这些二阶影响来解释预测不确定性的新方法。在计算上，我们的方法简化成对一组一阶解释进行简单协方差计算。我们的方法具有普遍适用性，可以将常见的归因技术（LRP，Gradient x Input等）转化为强大的二阶不确定性解释器，称为CovLRP，CovGI等。我们通过系统量化评估验证了我们方法产生解释的准确性，展示了我们方法的整体实用性。

    Explainable AI has brought transparency into complex ML blackboxes, enabling, in particular, to identify which features these models use for their predictions. So far, the question of explaining predictive uncertainty, i.e. why a model 'doubts', has been scarcely studied. Our investigation reveals that predictive uncertainty is dominated by second-order effects, involving single features or product interactions between them. We contribute a new method for explaining predictive uncertainty based on these second-order effects. Computationally, our method reduces to a simple covariance computation over a collection of first-order explanations. Our method is generally applicable, allowing for turning common attribution techniques (LRP, Gradient x Input, etc.) into powerful second-order uncertainty explainers, which we call CovLRP, CovGI, etc. The accuracy of the explanations our method produces is demonstrated through systematic quantitative evaluations, and the overall usefulness of our m
    
[^16]: 多头注意力在上下文线性回归中的优势

    Superiority of Multi-Head Attention in In-Context Linear Regression

    [https://arxiv.org/abs/2401.17426](https://arxiv.org/abs/2401.17426)

    多头注意力在上下文线性回归任务中表现出优于单头注意力的性能，通过理论分析证明了多头注意力在大嵌入维度情况下有更小的预测损失，并且在各种数据分布设置下都显示出优势。

    

    我们通过理论分析在线性回归任务的上下文学习中，使用softmax注意力的transformer的性能。与现有文献主要关注单头/多头注意力的收敛性不同，我们的研究着重比较它们的性能。我们进行了精确的理论分析，证明了具有较大嵌入维度的多头注意力比单头注意力表现更好。当上下文示例数量D增加时，使用单头/多头注意力的预测损失为O(1/D)，而多头注意力的乘法常数较小。除了最简单的数据分布设置，我们考虑了更多情景，例如噪声标签，局部示例，相关特征和先验知识。我们观察到，总的来说，多头注意力优于单头注意力。我们的结果验证了多头注意力设计的有效性。

    We present a theoretical analysis of the performance of transformer with softmax attention in in-context learning with linear regression tasks. While the existing literature predominantly focuses on the convergence of transformers with single-/multi-head attention, our research centers on comparing their performance. We conduct an exact theoretical analysis to demonstrate that multi-head attention with a substantial embedding dimension performs better than single-head attention. When the number of in-context examples D increases, the prediction loss using single-/multi-head attention is in O(1/D), and the one for multi-head attention has a smaller multiplicative constant. In addition to the simplest data distribution setting, we consider more scenarios, e.g., noisy labels, local examples, correlated features, and prior knowledge. We observe that, in general, multi-head attention is preferred over single-head attention. Our results verify the effectiveness of the design of multi-head at
    
[^17]: 去中心化联邦学习：安全与隐私综述

    Decentralized Federated Learning: A Survey on Security and Privacy

    [https://arxiv.org/abs/2401.17319](https://arxiv.org/abs/2401.17319)

    去中心化联邦学习架构允许保护隐私，但也引入了新的安全和隐私威胁，该综述对去中心化联邦学习中的威胁、对手和防御机制进行了研究。

    

    联邦学习由于其保护隐私等优势，在近年来迅速发展并受到广泛关注。然而，在这种架构中，模型更新和梯度的交换为网络中的恶意用户提供了新的攻击面，可能危及模型性能以及用户和数据的隐私。因此，去中心化联邦学习的主要动机之一是通过去除服务器并通过区块链等技术进行补偿来消除与服务器相关的威胁。然而，这种优势却以挑战系统面临新的隐私威胁为代价。因此，对这种新范 paradigm，并进行全面的安全分析是必要的。这项调查研究了去中心化联邦学习中可能存在的威胁和对手变化，并概述了潜在的防御机制。还考虑了去中心化联邦学习的可信度和验证性。

    Federated learning has been rapidly evolving and gaining popularity in recent years due to its privacy-preserving features, among other advantages. Nevertheless, the exchange of model updates and gradients in this architecture provides new attack surfaces for malicious users of the network which may jeopardize the model performance and user and data privacy. For this reason, one of the main motivations for decentralized federated learning is to eliminate server-related threats by removing the server from the network and compensating for it through technologies such as blockchain. However, this advantage comes at the cost of challenging the system with new privacy threats. Thus, performing a thorough security analysis in this new paradigm is necessary. This survey studies possible variations of threats and adversaries in decentralized federated learning and overviews the potential defense mechanisms. Trustability and verifiability of decentralized federated learning are also considered 
    
[^18]: 在噪声存在的情况下校准降维超参数

    Calibrating dimension reduction hyperparameters in the presence of noise

    [https://arxiv.org/abs/2312.02946](https://arxiv.org/abs/2312.02946)

    本文提出了一个框架，用于在噪声存在的情况下校准降维超参数，探索了困惑度和维度数量的作用。

    

    降维工具的目标是构建高维数据的低维表示。这些工具被用于噪声降低、可视化和降低计算成本等各种原因。然而，在降维文献中几乎没有讨论过的一个基本问题是过拟合，而在其他建模问题中这个问题已经被广泛讨论。如果我们将数据解释为信号和噪声的组合，先前的研究对降维技术的评判是其是否能够捕捉到数据的全部内容，即信号和噪声。在其他建模问题的背景下，我们会采用特征选择、交叉验证和正则化等技术来防止过拟合，但在进行降维时却没有采取类似的预防措施。本文提出了一个框架，用于在噪声存在的情况下建模降维问题，并利用该框架探索了困惑度和维度数量的作用。

    The goal of dimension reduction tools is to construct a low-dimensional representation of high-dimensional data. These tools are employed for a variety of reasons such as noise reduction, visualization, and to lower computational costs. However, there is a fundamental issue that is highly discussed in other modeling problems, but almost entirely ignored in the dimension reduction literature: overfitting. If we interpret data as a combination of signal and noise, prior works judge dimension reduction techniques on their ability to capture the entirety of the data, i.e. both the signal and the noise. In the context of other modeling problems, techniques such as feature-selection, cross-validation, and regularization are employed to combat overfitting, but no such precautions are taken when performing dimension reduction. In this paper, we present a framework that models dimension reduction problems in the presence of noise and use this framework to explore the role perplexity and number 
    
[^19]: 流形上的内在高斯过程及其通过对称性的加速

    Intrinsic Gaussian Processes on Manifolds and Their Accelerations by Symmetry

    [https://arxiv.org/abs/2006.14266](https://arxiv.org/abs/2006.14266)

    本研究提出了一种在一般流形上构造高斯过程的方法，并引入了适用于具有额外对称性流形的条带算法和适用于任意流形的球算法，这些算法的有效性通过理论证明和数值测试得到了验证。

    

    在对流形预测器应用高斯过程（GP）时，我们面临一个重要的挑战。现有的方法主要集中在低维约束域中用于热核估计，限制了它们在高维流形中的效果。我们的研究提出了一种在一般流形上构造GP的内在方法，例如正交群、幺正群、Stiefel流形和Grassmann流形。我们的方法使用指数映射模拟布朗运动样本路径来估计热核，确保与流形的嵌入无关。我们引入的用于具有额外对称性流形的条带算法和用于任意流形的球算法构成了我们的重大贡献。通过理论证明和数值测试，两个算法都得到了严格证实，其中条带算法展示了显着的效率提升。

    Amidst the growing interest in nonparametric regression, we address a significant challenge in Gaussian processes(GP) applied to manifold-based predictors. Existing methods primarily focus on low dimensional constrained domains for heat kernel estimation, limiting their effectiveness in higher-dimensional manifolds. Our research proposes an intrinsic approach for constructing GP on general manifolds such as orthogonal groups, unitary groups, Stiefel manifolds and Grassmannian manifolds. Our methodology estimates the heat kernel by simulating Brownian motion sample paths using the exponential map, ensuring independence from the manifold's embedding. The introduction of our strip algorithm, tailored for manifolds with extra symmetries, and the ball algorithm, designed for arbitrary manifolds, constitutes our significant contribution. Both algorithms are rigorously substantiated through theoretical proofs and numerical testing, with the strip algorithm showcasing remarkable efficiency gai
    
[^20]: 用于成本效益优化的因果机器学习在发展援助分配中的应用

    Causal Machine Learning for Cost-Effective Allocation of Development Aid. (arXiv:2401.16986v1 [stat.ML])

    [http://arxiv.org/abs/2401.16986](http://arxiv.org/abs/2401.16986)

    本文提出了一个因果机器学习框架，用于预测援助分配的异质化治疗效果，以支持有效的援助分配决策。

    

    联合国的可持续发展目标提供了“无人被遗弃”的更美好未来蓝图，为了在2030年之前实现这些目标，贫穷国家需要大量的发展援助。本文提出了一个因果机器学习框架，用于预测援助分配的异质化治疗效果，以支持有效的援助分配决策。具体而言，我们的框架包括三个组成部分：（i）一个平衡自编码器，利用表示学习将高维国家特征嵌入，同时解决治疗选择偏差问题；（ii）一个反事实生成器，用于计算在不同援助规模下的反事实结果，以解决小样本问题；（iii）一个推断模型，用于预测异质化的治疗效果曲线。我们使用105个国家战略性发展援助数据（总额超过52亿美元），以结束HIV/AIDS为目标，证明了我们的框架的有效性。

    The Sustainable Development Goals (SDGs) of the United Nations provide a blueprint of a better future by 'leaving no one behind', and, to achieve the SDGs by 2030, poor countries require immense volumes of development aid. In this paper, we develop a causal machine learning framework for predicting heterogeneous treatment effects of aid disbursements to inform effective aid allocation. Specifically, our framework comprises three components: (i) a balancing autoencoder that uses representation learning to embed high-dimensional country characteristics while addressing treatment selection bias; (ii) a counterfactual generator to compute counterfactual outcomes for varying aid volumes to address small sample-size settings; and (iii) an inference model that is used to predict heterogeneous treatment-response curves. We demonstrate the effectiveness of our framework using data with official development aid earmarked to end HIV/AIDS in 105 countries, amounting to more than USD 5.2 billion. F
    
[^21]: 通过Chen-Fliess序列，我们展示了如何将连续深度神经ODE模型构建为单层、无限宽度的网络。

    Rademacher Complexity of Neural ODEs via Chen-Fliess Series. (arXiv:2401.16655v1 [stat.ML])

    [http://arxiv.org/abs/2401.16655](http://arxiv.org/abs/2401.16655)

    本文通过Chen-Fliess序列展开将连续深度神经ODE模型转化为单层、无限宽度的网络，并利用此框架推导出了将初始条件映射到某个终端时间的ODE模型的Rademacher复杂度的紧凑表达式。

    

    本文将连续深度神经ODE模型使用Chen-Fliess序列展开为单层、无限宽度的网络。在这个网络中，输出的“权重”来自控制输入的特征序列，它由控制输入在单纯形上的迭代积分构成。而“特征”则基于受控ODE模型中输出函数相对于向量场的迭代李导数。本文的主要结果是，应用这个框架推导出了将初始条件映射到某个终端时间的ODE模型的Rademacher复杂度的紧凑表达式。这一结果利用了单层结构所带来的直接分析性质。最后，我们通过一些具体系统的例子实例化该界，并讨论了可能的后续工作。

    We show how continuous-depth neural ODE models can be framed as single-layer, infinite-width nets using the Chen--Fliess series expansion for nonlinear ODEs. In this net, the output ''weights'' are taken from the signature of the control input -- a tool used to represent infinite-dimensional paths as a sequence of tensors -- which comprises iterated integrals of the control input over a simplex. The ''features'' are taken to be iterated Lie derivatives of the output function with respect to the vector fields in the controlled ODE model. The main result of this work applies this framework to derive compact expressions for the Rademacher complexity of ODE models that map an initial condition to a scalar output at some terminal time. The result leverages the straightforward analysis afforded by single-layer architectures. We conclude with some examples instantiating the bound for some specific systems and discuss potential follow-up work.
    
[^22]: 利用专利数据提高抗体人性预测能力

    Improving Antibody Humanness Prediction using Patent Data. (arXiv:2401.14442v1 [q-bio.QM])

    [http://arxiv.org/abs/2401.14442](http://arxiv.org/abs/2401.14442)

    本研究利用专利数据提高了抗体人性预测的能力，通过多阶段、多损失的训练过程以及弱监督对比学习的方法，成功地预测了抗体序列的人性评分。

    

    我们研究了利用专利数据来提高抗体人性预测的潜力，采用了多阶段、多损失的训练过程。抗体人性作为对抗体治疗的免疫反应的代理，是药物发现中的主要原因之一，在临床环境中使用抗体治疗面临着具有挑战性的障碍。我们将初始学习阶段视为一个弱监督对比学习问题，每个抗体序列与可能有多个功能标识符相关联，目标是学习一个编码器，根据其专利属性将它们分组。然后，我们冻结对比编码器的一部分，并继续使用交叉熵损失在专利数据上训练，以预测给定抗体序列的人性评分。我们通过对三个不同的免疫原性数据集进行推理，展示了专利数据和我们的方法的效用。我们的实证结果表明，l

    We investigate the potential of patent data for improving the antibody humanness prediction using a multi-stage, multi-loss training process. Humanness serves as a proxy for the immunogenic response to antibody therapeutics, one of the major causes of attrition in drug discovery and a challenging obstacle for their use in clinical settings. We pose the initial learning stage as a weakly-supervised contrastive-learning problem, where each antibody sequence is associated with possibly multiple identifiers of function and the objective is to learn an encoder that groups them according to their patented properties. We then freeze a part of the contrastive encoder and continue training it on the patent data using the cross-entropy loss to predict the humanness score of a given antibody sequence. We illustrate the utility of the patent data and our approach by performing inference on three different immunogenicity datasets, unseen during training. Our empirical results demonstrate that the l
    
[^23]: 宽而深的ReLU神经网络的普适一致性以及Kolmogorov-Donoho最优函数类的极小极限收敛速率

    Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes. (arXiv:2401.04286v1 [stat.ML])

    [http://arxiv.org/abs/2401.04286](http://arxiv.org/abs/2401.04286)

    本文扩展了之前的结果，证明了基于宽而深的ReLU神经网络和逻辑损失训练的分类规则具有普适一致性，并给出了一类概率测度条件下基于神经网络的分类器实现极小极限收敛速率的充分条件。

    

    本文首先扩展了FL93的结果，并证明了基于宽而深的ReLU神经网络和逻辑损失训练的分类规则的普适一致性。与FL93中分解估计和经验误差的方法不同，我们根据一个广泛的神经网络能够插值任意数量的点的观察，直接分析分类风险。其次，我们给出了一类概率测度的充分条件，在这些条件下，基于神经网络的分类器实现了极小极限收敛速率。我们的结果源于实践者观察到神经网络通常被训练成达到0训练误差的事实，这也是我们提出的神经网络分类器的情况。我们的证明依赖于最近在经验风险最小化和深ReLU神经网络的逼近速率方面的发展，适用于不同的感兴趣函数类的应用。

    In this paper, we first extend the result of FL93 and prove universal consistency for a classification rule based on wide and deep ReLU neural networks trained on the logistic loss. Unlike the approach in FL93 that decomposes the estimation and empirical error, we directly analyze the classification risk based on the observation that a realization of a neural network that is wide enough is capable of interpolating an arbitrary number of points. Secondly, we give sufficient conditions for a class of probability measures under which classifiers based on neural networks achieve minimax optimal rates of convergence. Our result is motivated from the practitioner's observation that neural networks are often trained to achieve 0 training error, which is the case for our proposed neural network classifiers. Our proofs hinge on recent developments in empirical risk minimization and on approximation rates of deep ReLU neural networks for various function classes of interest. Applications to clas
    
[^24]: 强化微调语言模型中的梯度消失问题

    Vanishing Gradients in Reinforcement Finetuning of Language Models. (arXiv:2310.20703v1 [cs.LG])

    [http://arxiv.org/abs/2310.20703](http://arxiv.org/abs/2310.20703)

    本研究发现在强化微调（RFT）中存在梯度消失的问题，当模型下奖励的标准差较小时，输入的期望梯度会消失，导致奖励最大化缓慢。初始监督微调（SFT）阶段是克服这个问题的最有希望的方法。

    

    预训练的语言模型通过强化微调（RFT）与人类偏好和下游任务对齐，即使用策略梯度算法最大化（可能是学习得到的）奖励函数。本研究发现了RFT中的一个基本的优化障碍：我们证明了当模型下的奖励标准差较小时，输入的期望梯度会消失，即使期望奖励远离最优解。通过在RFT基准和控制环境中进行实验，以及理论分析，我们证明了由于小的奖励标准差导致的梯度消失问题普遍存在且有害，导致奖励最大化极其缓慢。最后，我们探索了克服RFT中梯度消失的方法。我们发现初始监督微调（SFT）阶段是最有希望的候选方法，并且揭示了它在RFT流程中的重要性。此外，我们还表明相对较小的训练数据集的SFT阶段可以有效克服梯度消失问题。

    Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small num
    
[^25]: 机器学习模型的成员推断攻击的基本限制

    Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])

    [http://arxiv.org/abs/2310.13786](http://arxiv.org/abs/2310.13786)

    本文探讨了机器学习模型上成员推断攻击的基本限制，包括推导了效果和成功率的统计量，并提供了几种情况下的界限。这使得我们能够根据样本数量和其他结构参数推断潜在攻击的准确性。

    

    成员推断攻击（MIA）可以揭示特定数据点是否是训练数据集的一部分，可能暴露个人的敏感信息。本文探讨了关于机器学习模型上MIA的基本统计限制。具体而言，我们首先推导了统计量，该统计量决定了这种攻击的有效性和成功率。然后，我们研究了几种情况，并对这个感兴趣的统计量提供了界限。这使我们能够根据样本数量和学习模型的其他结构参数推断潜在攻击的准确性，在某些情况下可以直接从数据集中估计。

    Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
    
[^26]: 深度网络逼近：从ReLU到多种激活函数

    Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])

    [http://arxiv.org/abs/2307.06555](http://arxiv.org/abs/2307.06555)

    本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。

    

    本文探究了深度神经网络在多种激活函数下的表达能力。定义了一个激活函数集合A，包括大多数常用的激活函数，如ReLU、LeakyReLU、ReLU^2、ELU、SELU、Softplus、GELU、SiLU、Swish、Mish、Sigmoid、Tanh、Arctan、Softsign、dSiLU和SRS。我们证明了对于任意激活函数varrho∈A，可以通过一个宽度为6N、深度为2L的varrho激活网络在有界集合上以任意精度逼近一个宽度为N、深度为L的ReLU网络。这一发现使得大部分对于ReLU网络的逼近结果能够推广到其他激活函数，尽管需要稍大的常数代价。

    This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
    
[^27]: 时空Tweedie模型在预测存在零膨胀和长尾旅行需求中的应用及不确定性量化

    Uncertainty Quantification via Spatial-Temporal Tweedie Model for Zero-inflated and Long-tail Travel Demand Prediction. (arXiv:2306.09882v1 [cs.LG])

    [http://arxiv.org/abs/2306.09882](http://arxiv.org/abs/2306.09882)

    本文提出了一种新型的时空Tweedie模型STTD，旨在解决高分辨率OD矩阵中稀疏和长尾特征的问题，并成功量化预测不确定性，具有很高的应用前景。

    

    传统的时空深度学习模型难以解决高分辨率OD矩阵中稀疏和长尾特征的问题，从而难以量化预测不确定性，而这对于交通管理至关重要。为了解决这些挑战，本文提出了一种新颖的方法：空间-Tweedie图神经网络（STTD）。STTD将Tweedie分布作为传统的“零膨胀”模型的有力替代品，并利用空间和时间嵌入来参数化旅行需求分布。我们使用真实世界的数据集进行评估，结果表明STTD在高分辨率场景下提供了准确的预测和精确的置信区间，具有优越性。

    crucial for transportation management. However, traditional spatial-temporal deep learning models grapple with addressing the sparse and long-tail characteristics in high-resolution O-D matrices and quantifying prediction uncertainty. This dilemma arises from the numerous zeros and over-dispersed demand patterns within these matrices, which challenge the Gaussian assumption inherent to deterministic deep learning models. To address these challenges, we propose a novel approach: the Spatial-Temporal Tweedie Graph Neural Network (STTD). The STTD introduces the Tweedie distribution as a compelling alternative to the traditional 'zero-inflated' model and leverages spatial and temporal embeddings to parameterize travel demand distributions. Our evaluations using real-world datasets highlight STTD's superiority in providing accurate predictions and precise confidence intervals, particularly in high-resolution scenarios.
    
[^28]: 关于贝叶斯网络边际独立结构的组合和代数视角

    Combinatorial and algebraic perspectives on the marginal independence structure of Bayesian networks. (arXiv:2210.00822v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2210.00822](http://arxiv.org/abs/2210.00822)

    本研究通过组合和代数视角探讨了贝叶斯网络的边际独立结构问题，并提出了一个基于 Gröbner 基础的 MCMC 方法 GrUES，该方法在恢复真实结构和估计后验上具有优势。

    

    我们考虑从观测数据中估计贝叶斯网络的边际独立结构的问题，这些数据以一个无向图的形式呈现，被称为无条件依赖图。我们证明了贝叶斯网络的无条件依赖图对应于具有相等独立性和交集数的图。基于这一观察结果，我们给出了与贝叶斯网络的无条件依赖图相关的一个拓扑理想的 Gröbner 基础，然后通过额外的二项式关系将其扩展以连接所有这些图的空间。我们实现了一种名为 GrUES (Gröbner-based Unconditional Equivalence Search) 的 MCMC 方法，该方法基于所得的移动并应用于合成高斯数据。GrUES 以比简单的独立性测试更高的速率恢复真实的边际独立结构，同时还产生了一个包括真实结构的后验估计，其中 $20\%$ 的 HPD 置信区间包含真实结构。

    We consider the problem of estimating the marginal independence structure of a Bayesian network from observational data in the form of an undirected graph called the unconditional dependence graph. We show that unconditional dependence graphs of Bayesian networks correspond to the graphs having equal independence and intersection numbers. Using this observation, a Gr\"obner basis for a toric ideal associated to unconditional dependence graphs of Bayesian networks is given and then extended by additional binomial relations to connect the space of all such graphs. An MCMC method, called GrUES (Gr\"obner-based Unconditional Equivalence Search), is implemented based on the resulting moves and applied to synthetic Gaussian data. GrUES recovers the true marginal independence structure via a penalized maximum likelihood or MAP estimate at a higher rate than simple independence tests while also yielding an estimate of the posterior, for which the $20\%$ HPD credible sets include the true struc
    

