# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Stable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures.](http://arxiv.org/abs/2306.03801) | 本研究提出了使用签名条码来稳定向量化多参数持久同调，将多参数持久同调的丰富信息和稳定向量化的优势相结合。 |
| [^2] | [Asymptotics of Bayesian Uncertainty Estimation in Random Features Regression.](http://arxiv.org/abs/2306.03783) | 论文比较和对比了后验预测分布和最大后验估计的风险，重点关注了模型维度增长速度大于任何常数倍的样本数时它们之间的渐近一致性。数值模拟表明这两个数量在限定维度上具有高斯波动，并表现出相似的属性。 |
| [^3] | [Graph Classification Gaussian Processes via Spectral Features.](http://arxiv.org/abs/2306.03770) | 本文提出了一种使用谱特征的高斯过程模型来解决图分类问题，即使是基于节点特征信号在图谱上能量分布这样简单的方法也有竞争力的表现。同时，更复杂的变体使用谱图小波滤波器可以在合成和真实世界数据集上获得改进，而两种模型都能够产生计算估计，能够可靠地做出决策。 |
| [^4] | [Human-imperceptible, Machine-recognizable Images.](http://arxiv.org/abs/2306.03679) | 本文提出了一种高效的隐私保护学习范式，通过加密图像实现人类不可感知但机器可识别，并使用经过最小适配的视觉转换器完成计算机视觉任务。实验证明该方法准确性与竞争方法相当。 |
| [^5] | [Provable convergence guarantees for black-box variational inference.](http://arxiv.org/abs/2306.03638) | 本文提出了一种基于密集高斯变分族的梯度估计器，在此基础上使用近端和投影随机梯度下降，提供了黑盒变分推断收敛于逼真推断问题的第一个严格保证。 |
| [^6] | [Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy Learning.](http://arxiv.org/abs/2306.03625) | 本文提出了一种公平且健壮的异质治疗效果的估计框架，可以在公平约束下非参数地估计，并可用于权衡公平和最大福利之间的关系。 |
| [^7] | [Entropic covariance models.](http://arxiv.org/abs/2306.03590) | 本文提出了一个通用的线性约束协方差矩阵变换的框架，并提出了一种估计方法，解决了一个凸问题，允许相对简单的渐近性和有限样本分析。研究的重点是关于建模相关矩阵和稀疏性方面的内容。 |
| [^8] | [How does over-squashing affect the power of GNNs?.](http://arxiv.org/abs/2306.03589) | 本文通过测量节点之间成对交互的水平，提供了严格的分析，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。结果表明，为了保证节点对之间的充分通信，MPNN的容量必须是... |
| [^9] | [L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference.](http://arxiv.org/abs/2306.03580) | 本文提出了一种名为 L-C2ST 的基于本地诊断实现模拟推断中后验近似的新方法，其可以在任何给定的观测下本地评估后验估计器，有效地解决了目前评估后验估计器限制解决方法的问题。 |
| [^10] | [Memory-Based Dual Gaussian Processes for Sequential Learning.](http://arxiv.org/abs/2306.03566) | 本论文提出了一种基于记忆的双高斯过程用于序列学习的方法，能够控制误差并改善学习。 |
| [^11] | [A Functional Data Perspective and Baseline On Multi-Layer Out-of-Distribution Detection.](http://arxiv.org/abs/2306.03522) | 本文提出了一种基于网络的函数数据视角的原创方法，利用样本通过各层的轨迹及其统计上的依赖关系，优于现有最先进方法，实现了多层次带基准的ODD检测。 |
| [^12] | [On the Role of Attention in Prompt-tuning.](http://arxiv.org/abs/2306.03435) | 本论文研究了Prompt-tuning在注意力架构中的应用，通过探索上下文混合模型，表明softmax-prompt-attention在表达上优于其他模型，同时也证明了该方法可以高效的使用数据学习提示。 |
| [^13] | [Binary Classification with Instance and Label Dependent Label Noise.](http://arxiv.org/abs/2306.03402) | 本文研究解决带有实例和标签相关的标签噪声对于二分类问题的困难，通过理论分析得到经验风险最小化可以实现最优的超额风险界限。 |
| [^14] | [A Lightweight Method for Tackling Unknown Participation Probabilities in Federated Averaging.](http://arxiv.org/abs/2306.03401) | 本文提出了一种轻量级方法来调整联邦平均中的聚合权重，通过根据每个客户的参与历史来处理具有不同参与率的客户，解决了在联邦学习中未知参与概率的问题。 |
| [^15] | [Online Tensor Learning: Computational and Statistical Trade-offs, Adaptivity and Optimal Regret.](http://arxiv.org/abs/2306.03372) | 本文提出了在线黎曼梯度下降算法，用于在在线情况下估计潜在的低秩张量。其中，我们在处理连续或分类变量时提供了灵活的方法，并在在线情况下尝试了两个具体的应用，即在线张量补全和在线二元张量学习。我们还建立了逐个条目的精确错误界限，这是在在线张量补全中首次纳入噪声。我们观察到，在存在噪声的情况下，计算和统计方面存在着令人惊讶的权衡。 |
| [^16] | [Unraveling Projection Heads in Contrastive Learning: Insights from Expansion and Shrinkage.](http://arxiv.org/abs/2306.03335) | 本文研究了对比学习中的投影头，在理论和实践中找到了两个关键效应：信号方向的扩展和收缩，提出了一系列线性变换来改善下游分类准确性。 |
| [^17] | [Global universal approximation of functional input maps on weighted spaces.](http://arxiv.org/abs/2306.03303) | 本文提出了功能性输入神经网络，可以在带权重空间上完成全局函数逼近。这一方法适用于连续函数的推广，还可用于路径空间函数的逼近，同时也可以逼近线性函数签名。 |
| [^18] | [Switching Autoregressive Low-rank Tensor Models.](http://arxiv.org/abs/2306.03291) | 该文提出了一种切换自回归低秩张量（SALT）模型，它将自回归隐Markov模型（ARHMM）和切换线性动态系统（SLDS）的优点结合起来，通过低秩参数化提高了模型性能。 |
| [^19] | [Deep Learning From Crowdsourced Labels: Coupled Cross-entropy Minimization, Identifiability, and Regularization.](http://arxiv.org/abs/2306.03288) | 本文提出了使用众包标签进行深度学习的方法，通过耦合交叉熵最小化和正则化使学习过程更加鲁棒，同时提出了性能保证。 |
| [^20] | [Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking Folklore Weisfeiler-Lehman.](http://arxiv.org/abs/2306.03266) | 本文提出了$(k, t)$-FWL和$k$-FWL+两种方法，理论上证明了它们可以在$O(n^2)$的空间复杂度下，解决图同构问题。 |
| [^21] | [Explaining and Adapting Graph Conditional Shift.](http://arxiv.org/abs/2306.03256) | 本研究通过量化输入特征和输出标签之间的条件偏移量，对图神经网络易受分布偏移影响的问题进行理论分析。研究发现，图形异质性和模型架构都会导致条件偏移，影响性能。作者提出了一种方法，通过条件偏移的估计和最小化来应对这一问题，该方法在节点分类和图分类任务上表现更优。 |
| [^22] | [Nonlinear Distributionally Robust Optimization.](http://arxiv.org/abs/2306.03202) | 本文提出一种新的非线性分布鲁棒优化算法，用于处理一类分布鲁棒优化问题，通过 Gateaux Derivative 处理一般风险度量。经过实验验证，该方法成功处理分布的非线性目标函数。 |
| [^23] | [Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning.](http://arxiv.org/abs/2306.03175) | LatFormer是一种将格点对称先验融入到注意力掩码中的模型，能够用卷积网络生成软掩码来调整注意力权重。该模型在合成几何推理中取得了较好效果。 |
| [^24] | [Bootstrapped Training of Score-Conditioned Generator for Offline Design of Biological Sequences.](http://arxiv.org/abs/2306.03111) | 本文提出了一种BootGen算法，使用代理得分函数增强生物序列生成器的训练数据集，并产生多样化的设计，将其应用于优化生物序列，取得了比竞争对手更好的结果。 |
| [^25] | [Provable Benefit of Mixup for Finding Optimal Decision Boundaries.](http://arxiv.org/abs/2306.00267) | 本研究证明了使用Mixup训练具有可证实的益处，可以显著降低在更可分离数据分布中寻找最佳决策边界的样本复杂度。 |
| [^26] | [Linear Neural Network Layers Promote Learning Single- and Multiple-Index Models.](http://arxiv.org/abs/2305.15598) | 本研究探究了过度参数化的深度神经网络的偏见，发现在ReLU网络中添加线性层有助于逼近具有低秩线性算子和低表示成本函数组成的函数，从而得到一个与低维子空间垂直方向近乎恒定的插值函数。 |
| [^27] | [Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern.](http://arxiv.org/abs/2305.11640) | 本文提出了两种实用算法，能够在任意丢失模式下有效地保证覆盖率的有效性，并量化了缺失对预测精度的影响。 |
| [^28] | [From Random Search to Bandit Learning in Metric Measure Spaces.](http://arxiv.org/abs/2305.11509) | 本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。 |
| [^29] | [Fisher Information Embedding for Node and Graph Learning.](http://arxiv.org/abs/2305.07580) | 本文提出了一种新的基于注意力机制的图节点嵌入框架，可以更好地理解基于注意力机制的GNN。 |
| [^30] | [Communication-Constrained Bandits under Additive Gaussian Noise.](http://arxiv.org/abs/2304.12680) | 本文研究了在受限通信和加性高斯噪声下的多臂赌博机问题，提出了一个多阶段赌博算法，并给出了信息理论下限。 |
| [^31] | [Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts.](http://arxiv.org/abs/2304.09836) | 本研究通过有限样本和功率分析确定了多元概率时间序列预测评分规则的可靠性区域，并在电力生产问题上评估了结果对真实世界任务的普适性。 |
| [^32] | [Fast Rates for Maximum Entropy Exploration.](http://arxiv.org/abs/2303.08059) | 本文解决了强化学习中稀疏奖励下的最大熵探索问题，提出了两种类型的最大熵探索方法，并提高了其样本复杂度。 |
| [^33] | [Safe Peeling for L0-Regularized Least-Squares with supplementary material.](http://arxiv.org/abs/2302.14471) | 引入“安全剥离”方法加速解决L0正则化最小二乘问题，通过收缩松弛度允许更激进的剪枝，显著降低求解时间。 |
| [^34] | [Causal isotonic calibration for heterogeneous treatment effects.](http://arxiv.org/abs/2302.14011) | 提出了因果等保校准方法及其数据有效的变体交叉校准，这两种方法都能快速稳健地校准异质性处理效应的预测器，而且可以应用于任何黑盒学习算法。 |
| [^35] | [Aligning Language Models with Preferences through f-divergence Minimization.](http://arxiv.org/abs/2302.08215) | 本文提出一种新的方法f-DPG，用于对齐语言模型和偏好，该方法适用于评估任何目标分布，统一了现有的各种框架和逼近方法。 |
| [^36] | [In Search of Insights, Not Magic Bullets: Towards Demystification of the Model Selection Dilemma in Heterogeneous Treatment Effect Estimation.](http://arxiv.org/abs/2302.02923) | 本文研究在具有高风险应用的个性化处理效应估计中，不同模型选择标准的优点和缺点，并提出未来研究方向。 |
| [^37] | [The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing.](http://arxiv.org/abs/2302.01186) | 该研究提出了ScaledGD(𝜆)方法，相较于传统梯度下降法更加鲁棒，并且在处理低秩矩阵感知问题时具有很好的表现。 |
| [^38] | [Revisiting Bellman Errors for Offline Model Selection.](http://arxiv.org/abs/2302.00141) | 本文重新审视 Bellman Errors，发现之前的Bellman Errors 方法需要在特定条件下才能表现良好，同时提出了更准确的 MSBE 估计器，在离散控制任务方面表现出色。 |
| [^39] | [On the Correctness of Automatic Differentiation for Neural Networks with Machine-Representable Parameters.](http://arxiv.org/abs/2301.13370) | 本论文研究了神经网络参数为机器可表示数字时自动微分的正确性问题，证明了神经网络带偏置参数时自动微分始终正确，给出了限制不可微性在激活函数中数目的界，并提供了判断参数是否在不可微参数组中的条件。 |
| [^40] | [Rigid body flows for sampling molecular crystal structures.](http://arxiv.org/abs/2301.11355) | 本文介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计。通过在单位四元数群上定义平滑和表现力强的流以及定义适当的密度，在旋转群上进行训练，我们可以成功地采样分子晶体结构。 |
| [^41] | [Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors.](http://arxiv.org/abs/2301.08987) | 本研究提出了层次平衡的概念，该概念捕捉了未观察到的潜在因果因素的情况变化，并探讨了动态公平性的实现。在指定的动态下，通常不能通过一步干预来实现长期公平目标。 |
| [^42] | [I Prefer not to Say: Protecting User Consent in Models with Optional Personal Data.](http://arxiv.org/abs/2210.13954) | 该论文研究了个人可以选择与决策系统共享可选个人信息的机器学习模型，并提出了保护用户同意的PUC概念，为用户隐私保护提供了有力的解决方案。 |
| [^43] | ["Why did the Model Fail?": Attributing Model Performance Changes to Distribution Shifts.](http://arxiv.org/abs/2210.10769) | 本文介绍了一种将模型性能变化归因于底层数据生成机制的分布偏移的方法，并通过推导一种重要性权重方法来计算任意一组分布的价值。 |
| [^44] | [Sparsity by Redundancy: Solving $L_1$ with SGD.](http://arxiv.org/abs/2210.01212) | 该论文提出了一种通过冗余重参数化和简单的随机梯度下降来最小化带有$L_1$惩罚的通用可微损失函数的方法，称为\textit{spred}，是$L_1$的精确求解器，可用于训练稀疏神经网络以执行基因选择任务和神经网络压缩任务，弥合了深度学习中的稀疏性和传统统计学习之间的差距。 |
| [^45] | [Transfer Learning for Individual Treatment Effect Estimation.](http://arxiv.org/abs/2210.00380) | 本论文探讨了个体治疗效果估计中迁移因果知识的问题，并提出了一个使用CITA度量进行ITE知识转移的框架，实验证明该方法的有效性。 |
| [^46] | [Homomorphism Autoencoder -- Learning Group Structured Representations from Observed Transitions.](http://arxiv.org/abs/2207.12067) | 本文提出了一种同态自编码器方法，使机器能够在行动中学习到与其行为相一致的感知信息的内部表示，并捕获环境中的转换结构。 |
| [^47] | [When are Post-hoc Conceptual Explanations Identifiable?.](http://arxiv.org/abs/2206.13872) | 本论文提出了可识别的概念发现方法，可以恢复出多个已知的概念，以确保解释的可靠性。对于具有依赖关系的概念，提出了两种新的方法，利用图像生成过程的功能组合性质。该方法明显优于现有方法。 |
| [^48] | [Beyond Uniform Lipschitz Condition in Differentially Private Optimization.](http://arxiv.org/abs/2206.10713) | 本文提出了一种新的差分隐私优化算法来处理其它算法无法处理的非均匀李普希茨情形，并且在具体应用中提供了相应的参数调整方案。 |
| [^49] | [Optimally tackling covariate shift in RKHS-based nonparametric regression.](http://arxiv.org/abs/2205.02986) | 本文研究了在RKHS的非参数回归中的协变量转移问题，针对两个不同的似然比族，证明了使用KRR估计量具有极小化率最优的特点，尤其是在似然比被均匀有界时。与此同时，本文也证明了，在协变量转移下一个naive的估计器相比于KRR是严格次优的。 |
| [^50] | [A Symmetric Loss Perspective of Reliable Machine Learning.](http://arxiv.org/abs/2101.01366) | 对称损失是一种新型的代理损失，能够使得学习过程对于受损标签更加鲁棒，从而提高分类器的性能。 |
| [^51] | [Growing Efficient Deep Networks by Structured Continuous Sparsification.](http://arxiv.org/abs/2007.15353) | 本文提出一种结构化连续稀疏化的深度网络结构生长方法，通过连续松弛和采样稀疏子网络，可以在训练过程中达到紧凑的修剪网络结构，同时大幅降低计算复杂度并保持较高的准确率。 |
| [^52] | [Conditional Sampling with Monotone GANs: from Generative Models to Likelihood-Free Inference.](http://arxiv.org/abs/2006.06755) | 本文提出了一种新的概率测度条件采样框架，使用单调GAN学习块状三角形映射，仅使用来自底层联合概率测度的样本实现无似然推断。 |
| [^53] | [Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices.](http://arxiv.org/abs/2004.13612) | Denise是一种基于深度学习的算法，用于对协方差矩阵进行低秩加稀疏分解，达到了与最先进技术相当的性能而且近乎接近20倍的加速。 |
| [^54] | [Certified Reinforcement Learning with Logic Guidance.](http://arxiv.org/abs/1902.00778) | 本文提出了一种模型无关的强化学习算法，能够使用线性时态逻辑来制定马尔科夫决策过程的目标，将LTL属性转化为LDGBA自动机，通过调整同步奖励函数最大概率获得满足LTL规定要求的控制策略。 |
| [^55] | [Orthogonal Statistical Learning.](http://arxiv.org/abs/1901.09036) | 本文提出了一个两阶段样本拆分的元算法，该算法能够在评估总体风险时考虑干扰参数，并且实现的超额风险界的影响为二次。 |

# 详细

[^1]: 签名条码作为度量的多参数持久同调的稳定向量化

    Stable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures. (arXiv:2306.03801v1 [cs.LG])

    [http://arxiv.org/abs/2306.03801](http://arxiv.org/abs/2306.03801)

    本研究提出了使用签名条码来稳定向量化多参数持久同调，将多参数持久同调的丰富信息和稳定向量化的优势相结合。

    

    持久同调（PH）提供了几何数据（例如加权图）的拓扑描述符，它们是可解释的，对扰动稳定，并具有诸如重标记等不变性。大多数PH应用关注一参数情况——描述符总结数据的拓扑随着单个感兴趣因素的滤波而发生变化；现在，有各种方法使得一参数PH描述符在数据科学中得到应用，并且依赖于将这些描述符稳定向量化为希尔伯特空间的元素。虽然由几个感兴趣因素过滤的数据的多参数PH（MPH）编码比其一参数同型的信息更丰富，但迄今为止，MPH描述符的稳定性结果的稀缺性已经限制了MPH的稳定向量化的可用选项。在本文中，我们旨在通过展示如何解释签名条码来集结两方面的优点。

    Persistent homology (PH) provides topological descriptors for geometric data, such as weighted graphs, which are interpretable, stable to perturbations, and invariant under, e.g., relabeling. Most applications of PH focus on the one-parameter case -- where the descriptors summarize the changes in topology of data as it is filtered by a single quantity of interest -- and there is now a wide array of methods enabling the use of one-parameter PH descriptors in data science, which rely on the stable vectorization of these descriptors as elements of a Hilbert space. Although the multiparameter PH (MPH) of data that is filtered by several quantities of interest encodes much richer information than its one-parameter counterpart, the scarceness of stability results for MPH descriptors has so far limited the available options for the stable vectorization of MPH. In this paper, we aim to bring together the best of both worlds by showing how the interpretation of signed barcodes -- a recent famil
    
[^2]: 随机特征回归中贝叶斯不确定性估计的渐近性

    Asymptotics of Bayesian Uncertainty Estimation in Random Features Regression. (arXiv:2306.03783v1 [stat.ML])

    [http://arxiv.org/abs/2306.03783](http://arxiv.org/abs/2306.03783)

    论文比较和对比了后验预测分布和最大后验估计的风险，重点关注了模型维度增长速度大于任何常数倍的样本数时它们之间的渐近一致性。数值模拟表明这两个数量在限定维度上具有高斯波动，并表现出相似的属性。

    

    本文比较和对比了贝叶斯回归模型中后验预测分布和最大后验估计（MAP）风险在超参数化区域中的行为。我们将重点关注后验预测分布（贝叶斯模型平均）的方差，并将其渐近性与MAP估计器的风险进行比较。当模型维度增长速度大于任何常数倍的样本数时，它们之间的渐近一致性受到信噪比的相变的控制。当样本数增长速度大于任何常数倍的模型维度时，它们也会渐近一致。数值模拟说明了两个数量的有限维分布性质。我们推测它们具有高斯波动，并表现出与之前在高斯序列模型中发现的类似属性。

    In this paper we compare and contrast the behavior of the posterior predictive distribution to the risk of the maximum a posteriori estimator for the random features regression model in the overparameterized regime. We will focus on the variance of the posterior predictive distribution (Bayesian model average) and compare its asymptotics to that of the risk of the MAP estimator. In the regime where the model dimensions grow faster than any constant multiple of the number of samples, asymptotic agreement between these two quantities is governed by the phase transition in the signal-to-noise ratio. They also asymptotically agree with each other when the number of samples grow faster than any constant multiple of model dimensions. Numerical simulations illustrate finer distributional properties of the two quantities for finite dimensions. We conjecture they have Gaussian fluctuations and exhibit similar properties as found by previous authors in a Gaussian sequence model, which is of inde
    
[^3]: 通过谱特征的高斯过程进行图分类

    Graph Classification Gaussian Processes via Spectral Features. (arXiv:2306.03770v1 [cs.LG])

    [http://arxiv.org/abs/2306.03770](http://arxiv.org/abs/2306.03770)

    本文提出了一种使用谱特征的高斯过程模型来解决图分类问题，即使是基于节点特征信号在图谱上能量分布这样简单的方法也有竞争力的表现。同时，更复杂的变体使用谱图小波滤波器可以在合成和真实世界数据集上获得改进，而两种模型都能够产生计算估计，能够可靠地做出决策。

    

    图分类旨在根据其结构和节点属性对图进行分类。本文提出使用图信号处理工具，通过得出谱特征来设计两种变体的高斯过程模型来解决这个问题。第一种变体使用基于节点特征信号在图谱上能量分布的谱特征。我们展示即使使用没有学习参数的如此简单的方法，也可以与强大的神经网络和图内核基线相比具有竞争力的表现。第二种更复杂的变体通过学习谱图小波滤波器来捕捉图中的多尺度和局部模式，在合成和真实世界的数据集上获得了改进。最后，我们展示两种模型都可以产生良好的计算估计，从而基于模型预测可靠地做出决策。

    Graph classification aims to categorise graphs based on their structure and node attributes. In this work, we propose to tackle this task using tools from graph signal processing by deriving spectral features, which we then use to design two variants of Gaussian process models for graph classification. The first variant uses spectral features based on the distribution of energy of a node feature signal over the spectrum of the graph. We show that even such a simple approach, having no learned parameters, can yield competitive performance compared to strong neural network and graph kernel baselines. A second, more sophisticated variant is designed to capture multi-scale and localised patterns in the graph by learning spectral graph wavelet filters, obtaining improved performance on synthetic and real-world data sets. Finally, we show that both models produce well calibrated uncertainty estimates, enabling reliable decision making based on the model predictions.
    
[^4]: 人类不可感知、机器可识别的图像

    Human-imperceptible, Machine-recognizable Images. (arXiv:2306.03679v1 [cs.CV])

    [http://arxiv.org/abs/2306.03679](http://arxiv.org/abs/2306.03679)

    本文提出了一种高效的隐私保护学习范式，通过加密图像实现人类不可感知但机器可识别，并使用经过最小适配的视觉转换器完成计算机视觉任务。实验证明该方法准确性与竞争方法相当。

    

    大量与人类相关的数据被收集用于训练神经网络进行计算机视觉任务。我们发现了一种关于软件工程师的重大冲突：在更好地开发人工智能系统与远离敏感训练数据之间存在一大矛盾。为了解决这个问题，本文提出了一种高效的隐私保护学习范式，其中图像被加密成“人类不可感知，机器可识别”状态，通过以下两种加密策略之一来实现：(1) 将图像随机洗牌成一组相等大小的小块，(2) 对图像的子块进行混合。然后，对视觉转换器进行最小的适配，使其能够学习加密图像的计算机视觉任务，包括图像分类和目标检测。在 ImageNet 和 COCO 上进行了广泛的实验，结果表明，所提出的方法在准确性方面与竞争方法相当。解密加密图像需要解决 NP 难的拼图问题或病态的反问题，这是经验证明的。

    Massive human-related data is collected to train neural networks for computer vision tasks. A major conflict is exposed relating to software engineers between better developing AI systems and distancing from the sensitive training data. To reconcile this conflict, this paper proposes an efficient privacy-preserving learning paradigm, where images are first encrypted to become ``human-imperceptible, machine-recognizable'' via one of the two encryption strategies: (1) random shuffling to a set of equally-sized patches and (2) mixing-up sub-patches of the images. Then, minimal adaptations are made to vision transformer to enable it to learn on the encrypted images for vision tasks, including image classification and object detection. Extensive experiments on ImageNet and COCO show that the proposed paradigm achieves comparable accuracy with the competitive methods. Decrypting the encrypted images requires solving an NP-hard jigsaw puzzle or an ill-posed inverse problem, which is empirical
    
[^5]: 黑盒变分推断的收敛性保证

    Provable convergence guarantees for black-box variational inference. (arXiv:2306.03638v1 [cs.LG])

    [http://arxiv.org/abs/2306.03638](http://arxiv.org/abs/2306.03638)

    本文提出了一种基于密集高斯变分族的梯度估计器，在此基础上使用近端和投影随机梯度下降，提供了黑盒变分推断收敛于逼真推断问题的第一个严格保证。

    

    尽管黑盒变分推断被广泛应用，但没有证明其随机优化成功的证明。我们提出这是现有随机优化证明中的理论差距，即具有异常噪声边界和复合非平滑目标的梯度估计器的挑战。对于密集的高斯变分族，我们观察到现有的基于再参数化的梯度估计器满足二次噪声界，并为使用该界限的近端和投影随机梯度下降提供新的收敛保证。这提供了第一个黑盒变分推断收敛于逼真推断问题的严格保证。

    While black-box variational inference is widely used, there is no proof that its stochastic optimization succeeds. We suggest this is due to a theoretical gap in existing stochastic optimization proofs-namely the challenge of gradient estimators with unusual noise bounds, and a composite non-smooth objective. For dense Gaussian variational families, we observe that existing gradient estimators based on reparameterization satisfy a quadratic noise bound and give novel convergence guarantees for proximal and projected stochastic gradient descent using this bound. This provides the first rigorous guarantee that black-box variational inference converges for realistic inference problems.
    
[^6]: 公平且健壮的异质治疗效果政策学习估计

    Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy Learning. (arXiv:2306.03625v1 [stat.ME])

    [http://arxiv.org/abs/2306.03625](http://arxiv.org/abs/2306.03625)

    本文提出了一种公平且健壮的异质治疗效果的估计框架，可以在公平约束下非参数地估计，并可用于权衡公平和最大福利之间的关系。

    

    我们提出了一种简单且通用的框架，用于在公平约束条件下非参数估计异质治疗效果。在标准正则条件下，我们证明了所得到的估计器具有双重健壮性。我们利用此框架来表征公平和最佳政策可实现的最大福利之间的权衡。我们在模拟研究中评估了该方法，并在一个真实世界的案例研究中进行了说明。

    We propose a simple and general framework for nonparametric estimation of heterogeneous treatment effects under fairness constraints. Under standard regularity conditions, we show that the resulting estimators possess the double robustness property. We use this framework to characterize the trade-off between fairness and the maximum welfare achievable by the optimal policy. We evaluate the methods in a simulation study and illustrate them in a real-world case study.
    
[^7]: 熵协方差模型

    Entropic covariance models. (arXiv:2306.03590v1 [math.ST])

    [http://arxiv.org/abs/2306.03590](http://arxiv.org/abs/2306.03590)

    本文提出了一个通用的线性约束协方差矩阵变换的框架，并提出了一种估计方法，解决了一个凸问题，允许相对简单的渐近性和有限样本分析。研究的重点是关于建模相关矩阵和稀疏性方面的内容。

    

    在协方差矩阵估计中，找到合适的模型和有效的估计方法是一项挑战。文献中通常采用两种方法，一种是对协方差矩阵或其逆施加线性约束，另一种是考虑施加在协方差矩阵的矩阵对数上的线性约束。本文提出了一个通用的线性约束协方差矩阵变换的框架，包括上述例子。我们提出的估计方法解决了一个凸问题，并产生了一个M估计量，允许相对简单的渐近性和有限样本分析。在开发了一般理论之后，我们集中在建模相关矩阵和稀疏性方面。我们的几何洞察力允许我们扩展协方差矩阵建模中的一些最新结果。这包括提供相关矩阵空间的无限制参数化，这是一种替代利用变换的最新结果。我们还展示了如何对协方差矩阵的Cholesky因子施加稀疏性限制，这与现有方法不同。

    In covariance matrix estimation, one of the challenges lies in finding a suitable model and an efficient estimation method. Two commonly used approaches in the literature involve imposing linear restrictions on the covariance matrix or its inverse. Another approach considers linear restrictions on the matrix logarithm of the covariance matrix. In this paper, we present a general framework for linear restrictions on different transformations of the covariance matrix, including the mentioned examples. Our proposed estimation method solves a convex problem and yields an M-estimator, allowing for relatively straightforward asymptotic and finite sample analysis. After developing the general theory, we focus on modelling correlation matrices and on sparsity. Our geometric insights allow to extend various recent results in covariance matrix modelling. This includes providing unrestricted parametrizations of the space of correlation matrices, which is alternative to a recent result utilizing t
    
[^8]: 过度压缩如何影响GNN的能力？

    How does over-squashing affect the power of GNNs?. (arXiv:2306.03589v1 [cs.LG])

    [http://arxiv.org/abs/2306.03589](http://arxiv.org/abs/2306.03589)

    本文通过测量节点之间成对交互的水平，提供了严格的分析，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。结果表明，为了保证节点对之间的充分通信，MPNN的容量必须是...

    

    图神经网络（GNN）是处理图结构数据的机器学习的最先进模型。最流行的GNN类别是通过相邻节点间的信息交换来操作的，称为消息传递神经网络（MPNN）。鉴于它们的广泛应用，了解MPNN的表达能力是一个关键问题。然而，现有结果通常考虑具有无信息节点特征的环境。在本文中，我们提供了一种严格的分析方法，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。我们通过测量MPNN允许的节点之间的成对交互水平来实现此目的。该测量提供了一种新的量化特性，即所谓的过度压缩效应，该效应被观察到是当大量的信息聚合成固定大小的向量时发生的。使用我们的测量，我们证明，为了保证节点对之间的充分通信，MPNN的容量必须是...

    Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). Given their widespread use, understanding the expressive power of MPNNs is a key question. However, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of pairwise interactions between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be l
    
[^9]: L-C2ST: 基于本地诊断实现模拟推断中后验近似

    L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference. (arXiv:2306.03580v1 [stat.ML])

    [http://arxiv.org/abs/2306.03580](http://arxiv.org/abs/2306.03580)

    本文提出了一种名为 L-C2ST 的基于本地诊断实现模拟推断中后验近似的新方法，其可以在任何给定的观测下本地评估后验估计器，有效地解决了目前评估后验估计器限制解决方法的问题。

    

    最近许多模拟推断（SBI）的工作都依赖于深度生成模型来近似复杂、高维度的后验分布。然而，评估这些近似是否可信仍是一个挑战。大多数方法仅在观测空间期望下评估后验估计器。这限制了它们的可解释性，并不能足够地确定哪些观测结果可以信任这些近似或应该改进。我们基于著名的分类器两样本检验 (C2ST)，引入 L-C2ST，一个新方法，允许在任何给定的观测下本地评估后验估计器。它提供有理论基础和易于解释的，如图示诊断。与 C2ST 不同的是，L-C2ST 不需要访问真实后验的样本。对于基于归一化流的后验估计器，L-C2ST 可以专门提供更好的统计功率，同时计算效率更高。

    Many recent works in simulation-based inference (SBI) rely on deep generative models to approximate complex, high-dimensional posterior distributions. However, evaluating whether or not these approximations can be trusted remains a challenge. Most approaches evaluate the posterior estimator only in expectation over the observation space. This limits their interpretability and is not sufficient to identify for which observations the approximation can be trusted or should be improved. Building upon the well-known classifier two-sample test (C2ST), we introduce L-C2ST, a new method that allows for a local evaluation of the posterior estimator at any given observation. It offers theoretically grounded and easy to interpret - e.g. graphical - diagnostics, and unlike C2ST, does not require access to samples from the true posterior. In the case of normalizing flow-based posterior estimators, L-C2ST can be specialized to offer better statistical power, while being computationally more efficien
    
[^10]: 基于记忆的双高斯过程用于序列学习

    Memory-Based Dual Gaussian Processes for Sequential Learning. (arXiv:2306.03566v1 [cs.LG])

    [http://arxiv.org/abs/2306.03566](http://arxiv.org/abs/2306.03566)

    本论文提出了一种基于记忆的双高斯过程用于序列学习的方法，能够控制误差并改善学习。

    

    在连续和主动学习中，访问过去数据的能力有限，因此使用高斯过程（GPs）进行序列学习是具有挑战性的。在后验、超参数和诱导点的不准确性导致错误随时间累积的情况下，准确学习变得困难。在这里，我们提出了一种使用最近提出的双稀疏变分高斯过程来控制所有这些误差的方法。我们的方法能够进行通用似然的准确推断，并通过主动建立和更新过去数据的记忆来改善学习。我们在涉及贝叶斯优化、主动学习和连续学习的几个应用中展示了其有效性。

    Sequential learning with Gaussian processes (GPs) is challenging when access to past data is limited, for example, in continual and active learning. In such cases, errors can accumulate over time due to inaccuracies in the posterior, hyperparameters, and inducing points, making accurate learning challenging. Here, we present a method to keep all such errors in check using the recently proposed dual sparse variational GP. Our method enables accurate inference for generic likelihoods and improves learning by actively building and updating a memory of past data. We demonstrate its effectiveness in several applications involving Bayesian optimization, active learning, and continual learning.
    
[^11]: 多层次带基准的异常检测的函数数据视角

    A Functional Data Perspective and Baseline On Multi-Layer Out-of-Distribution Detection. (arXiv:2306.03522v1 [cs.LG])

    [http://arxiv.org/abs/2306.03522](http://arxiv.org/abs/2306.03522)

    本文提出了一种基于网络的函数数据视角的原创方法，利用样本通过各层的轨迹及其统计上的依赖关系，优于现有最先进方法，实现了多层次带基准的ODD检测。

    

    实现外样本检测的关键特征是通过多层分类器提取统计模式和数据间的关系，以检测预期输入数据分布的变化。但是，现有的一些最先进的方法仅使用倒数第二层或最后一层的输出，留下了用于ODD检测的有价值的信息。本文提出了一种基于网络的函数视角的原创方法，利用样本通过各层的轨迹及其统计上的依赖关系。它超越了多元特征聚合，并引入了基于函数异常检测的基准。在这个新的框架中，ODD检测转化为检测样本的轨迹与训练集所表现的典型行为不同的情况。我们在各种基准测试中验证了我们的方法，并展示了通过利用网络的所有层的信息，其在性能上优于现有的最先进方法。

    A key feature of out-of-distribution (OOD) detection is to exploit a trained neural network by extracting statistical patterns and relationships through the multi-layer classifier to detect shifts in the expected input data distribution. Despite achieving solid results, several state-of-the-art methods rely on the penultimate or last layer outputs only, leaving behind valuable information for OOD detection. Methods that explore the multiple layers either require a special architecture or a supervised objective to do so. This work adopts an original approach based on a functional view of the network that exploits the sample's trajectories through the various layers and their statistical dependencies. It goes beyond multivariate features aggregation and introduces a baseline rooted in functional anomaly detection. In this new framework, OOD detection translates into detecting samples whose trajectories differ from the typical behavior characterized by the training set. We validate our me
    
[^12]: 关注点对Prompt-tuning的作用

    On the Role of Attention in Prompt-tuning. (arXiv:2306.03435v1 [cs.LG])

    [http://arxiv.org/abs/2306.03435](http://arxiv.org/abs/2306.03435)

    本论文研究了Prompt-tuning在注意力架构中的应用，通过探索上下文混合模型，表明softmax-prompt-attention在表达上优于其他模型，同时也证明了该方法可以高效的使用数据学习提示。

    

    Prompt-tuning 是一种新兴的策略，通过从数据中学习 (软) 提示参数，使大型语言模型 (LLM) 适应下游任务。尽管其在 LLM 中取得了成功，但对于 Prompt-tuning 的能力及关注机制在提示中的作用，理论理解尚有限。在这项工作中，我们探索一个注意力架构的 Prompt-tuning，并研究上下文混合模型，其中每个输入表示属于上下文相关或无关集合。我们通过一个自包含的提示-注意力模型来隔离 Prompt-tuning 的作用。我们的贡献如下：(1) 我们表明在我们的上下文数据模型下，softmax-prompt-attention 在可证明地比softmax-self-attention 和线性提示注意力更具表达力。(2) 我们分析了渐变下降的初始轨迹，并展示可以通过近乎最优的样本复杂度学习提示和预测头，从而证明了提示可以证明地注意到稀疏的上下文相关信息。(3)

    Prompt-tuning is an emerging strategy to adapt large language models (LLM) to downstream tasks by learning a (soft-)prompt parameter from data. Despite its success in LLMs, there is limited theoretical understanding of the power of prompt-tuning and the role of the attention mechanism in prompting. In this work, we explore prompt-tuning for one-layer attention architectures and study contextual mixture-models where each input token belongs to a context-relevant or -irrelevant set. We isolate the role of prompt-tuning through a self-contained prompt-attention model. Our contributions are as follows: (1) We show that softmax-prompt-attention is provably more expressive than softmax-self-attention and linear-prompt-attention under our contextual data model. (2) We analyze the initial trajectory of gradient descent and show that it learns the prompt and prediction head with near-optimal sample complexity and demonstrate how prompt can provably attend to sparse context-relevant tokens. (3) 
    
[^13]: 带有实例和标签相关的标签噪声的二分类问题

    Binary Classification with Instance and Label Dependent Label Noise. (arXiv:2306.03402v1 [stat.ML])

    [http://arxiv.org/abs/2306.03402](http://arxiv.org/abs/2306.03402)

    本文研究解决带有实例和标签相关的标签噪声对于二分类问题的困难，通过理论分析得到经验风险最小化可以实现最优的超额风险界限。

    

    学习带有标签相关的标签噪声在理论和实践中得到了广泛探讨，然而处理带有实例和标签相关的标签噪声仍然是一项具有挑战性的任务。这种困难在于噪声率因每个实例而异，使得准确估计噪声率成为一项具有挑战性的任务。目前还没有解决能否仅使用含有噪声样本来学习可靠模型的问题。我们通过理论分析回答了这个问题，提供了匹配的上界和下界。令人惊讶的是，我们的结果表明，不需要任何额外的假设，经验风险最小化可以实现最优的超额风险界限。具体而言，我们通过比较从干净样本和噪声样本中得到的经验风险最小化器来导出一种与噪声水平成比例的新的超额风险界限，在非常一般的情况下都成立。其次，我们表明了0-1损失的极小极大下界是一个与标签数成比例的常数。

    Learning with label dependent label noise has been extensively explored in both theory and practice; however, dealing with instance (i.e., feature) and label dependent label noise continues to be a challenging task. The difficulty arises from the fact that the noise rate varies for each instance, making it challenging to estimate accurately. The question of whether it is possible to learn a reliable model using only noisy samples remains unresolved. We answer this question with a theoretical analysis that provides matching upper and lower bounds. Surprisingly, our results show that, without any additional assumptions, empirical risk minimization achieves the optimal excess risk bound. Specifically, we derive a novel excess risk bound proportional to the noise level, which holds in very general settings, by comparing the empirical risk minimizers obtained from clean samples and noisy samples. Second, we show that the minimax lower bound for the 0-1 loss is a constant proportional to the
    
[^14]: 处理联邦平均中未知参与概率的轻量级方法

    A Lightweight Method for Tackling Unknown Participation Probabilities in Federated Averaging. (arXiv:2306.03401v1 [cs.LG])

    [http://arxiv.org/abs/2306.03401](http://arxiv.org/abs/2306.03401)

    本文提出了一种轻量级方法来调整联邦平均中的聚合权重，通过根据每个客户的参与历史来处理具有不同参与率的客户，解决了在联邦学习中未知参与概率的问题。

    

    在联邦学习中，客户端通常具有先验未知的不同参与率，如果不适当处理，则可能会对联邦学习的性能造成重大影响。现有的解决方法通常基于全局方差缩减，这需要大量额外的内存，其乘法因子等于客户总数。一个重要的未解决问题是找到一种轻量级方法来处理具备不同参与率客户的联邦学习。在这篇论文中，我们通过根据每个客户的参与历史来调整联邦平均（FedAvg）中的聚合权重来解决此问题。我们首先展示了在具有异构参与概率的情况下，非最优聚合权重的FedAvg可能会从原始FL目标的最优解偏离，这表明需要找到最优聚合权重。然而，当参与概率不可知时计算最优权重非常困难。

    In federated learning (FL), clients usually have diverse participation probabilities that are unknown a priori, which can significantly harm the performance of FL if not handled properly. Existing works aiming at addressing this problem are usually based on global variance reduction, which requires a substantial amount of additional memory in a multiplicative factor equal to the total number of clients. An important open problem is to find a lightweight method for FL in the presence of clients with unknown participation rates. In this paper, we address this problem by adapting the aggregation weights in federated averaging (FedAvg) based on the participation history of each client. We first show that, with heterogeneous participation probabilities, FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective, indicating the need of finding optimal aggregation weights. However, it is difficult to compute the optimal weights when the part
    
[^15]: 在线张量学习：计算和统计权衡，适应性和最优遗憾

    Online Tensor Learning: Computational and Statistical Trade-offs, Adaptivity and Optimal Regret. (arXiv:2306.03372v1 [stat.ML])

    [http://arxiv.org/abs/2306.03372](http://arxiv.org/abs/2306.03372)

    本文提出了在线黎曼梯度下降算法，用于在在线情况下估计潜在的低秩张量。其中，我们在处理连续或分类变量时提供了灵活的方法，并在在线情况下尝试了两个具体的应用，即在线张量补全和在线二元张量学习。我们还建立了逐个条目的精确错误界限，这是在在线张量补全中首次纳入噪声。我们观察到，在存在噪声的情况下，计算和统计方面存在着令人惊讶的权衡。

    

    我们研究了一个广义框架，用于在线情况下估计潜在的低秩张量，包括线性和广义线性模型。该框架提供了一种处理连续或分类变量的灵活方法。此外，我们研究了两个具体的应用：在线张量补全和在线二元张量学习。为了应对这些挑战，我们提出了在线黎曼梯度下降算法，在所有应用程序中都可以根据适当的条件线性收敛并恢复低秩组件。此外，我们为在线张量补全建立了精确的逐个条目错误界限。值得注意的是，我们的工作代表了首次尝试在在线低秩张量恢复任务中纳入噪声的努力。有趣的是，我们观察到在存在噪声的情况下，在计算和统计方面存在着令人惊讶的权衡。增加步长可以加快收敛，但会导致更高的统计误差。

    We investigate a generalized framework for estimating latent low-rank tensors in an online setting, encompassing both linear and generalized linear models. This framework offers a flexible approach for handling continuous or categorical variables. Additionally, we investigate two specific applications: online tensor completion and online binary tensor learning. To address these challenges, we propose the online Riemannian gradient descent algorithm, which demonstrates linear convergence and the ability to recover the low-rank component under appropriate conditions in all applications. Furthermore, we establish a precise entry-wise error bound for online tensor completion. Notably, our work represents the first attempt to incorporate noise in the online low-rank tensor recovery task. Intriguingly, we observe a surprising trade-off between computational and statistical aspects in the presence of noise. Increasing the step size accelerates convergence but leads to higher statistical error
    
[^16]: 对比学习中的投影头：扩展和收缩的启示

    Unraveling Projection Heads in Contrastive Learning: Insights from Expansion and Shrinkage. (arXiv:2306.03335v1 [stat.ML])

    [http://arxiv.org/abs/2306.03335](http://arxiv.org/abs/2306.03335)

    本文研究了对比学习中的投影头，在理论和实践中找到了两个关键效应：信号方向的扩展和收缩，提出了一系列线性变换来改善下游分类准确性。

    

    本文研究了对比学习中编码器-投影器框架（例如SimCLR）中的投影头，也称为投影仪，的作用。我们旨在揭示一个观察现象的真相：通过下游线性分类准确度的衡量，即使在投影头本身是线性的情况下，也可以学习出在投影器之前的表示优于之后。通过实证和理论分析，我们首先确定了两个由对比损失引起的关键效应。本质上，对比损失会扩展或收缩编码器学习的表示中的信号方向，具体取决于如增强强度，对比损失中使用的温度等因素。其次，受到扩展和收缩现象的启示，我们提出了一系列线性变换来准确建模投影头。我们提出的变换可以提高下游的分类准确度，而且计算成本低，易于实现。

    We investigate the role of projection heads, also known as projectors, within the encoder-projector framework (e.g., SimCLR) used in contrastive learning. We aim to demystify the observed phenomenon where representations learned before projectors outperform those learned after -- measured using the downstream linear classification accuracy, even when the projectors themselves are linear.  In this paper, we make two significant contributions towards this aim. Firstly, through empirical and theoretical analysis, we identify two crucial effects -- expansion and shrinkage -- induced by the contrastive loss on the projectors. In essence, contrastive loss either expands or shrinks the signal direction in the representations learned by an encoder, depending on factors such as the augmentation strength, the temperature used in contrastive loss, etc. Secondly, drawing inspiration from the expansion and shrinkage phenomenon, we propose a family of linear transformations to accurately model the p
    
[^17]: 带权重空间上功能性输入映射的全局普适逼近

    Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v1 [stat.ML])

    [http://arxiv.org/abs/2306.03303](http://arxiv.org/abs/2306.03303)

    本文提出了功能性输入神经网络，可以在带权重空间上完成全局函数逼近。这一方法适用于连续函数的推广，还可用于路径空间函数的逼近，同时也可以逼近线性函数签名。

    

    我们引入了所谓的功能性输入神经网络，定义在可能是无限维带权重空间上，其值也在可能是无限维的输出空间中。为此，我们使用一个加性族作为隐藏层映射，以及一个非线性激活函数应用于每个隐藏层。依靠带权重空间上的Stone-Weierstrass定理，我们可以证明连续函数的推广的全局普适逼近结果，超越了常规紧集逼近。这特别适用于通过功能性输入神经网络逼近（非先见之明的）路径空间函数。作为带权Stone-Weierstrass定理的进一步应用，我们证明了线性函数签名的全局普适逼近结果。我们还在这个设置中引入了高斯过程回归的观点，并展示了签名内核的再生核希尔伯特空间是某些高斯过程的Cameron-Martin空间。

    We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family as hidden layer maps and a non-linear activation function applied to each hidden layer. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result for generalizations of continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and show that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gauss
    
[^18]: 切换自回归低秩张量模型

    Switching Autoregressive Low-rank Tensor Models. (arXiv:2306.03291v1 [cs.LG])

    [http://arxiv.org/abs/2306.03291](http://arxiv.org/abs/2306.03291)

    该文提出了一种切换自回归低秩张量（SALT）模型，它将自回归隐Markov模型（ARHMM）和切换线性动态系统（SLDS）的优点结合起来，通过低秩参数化提高了模型性能。

    

    时序分析中一个重要的问题是对具有时变动力学的系统进行建模。共同连续和离散潜态的概率模型为这样的数据提供了可解释、高效和实验性有用的描述。常用的模型包括自回归隐Markov模型（ARHMM）和切换线性动态系统（SLDS），它们各有优缺点。ARHMM允许精确推理和简单的参数估计，但在对长依赖关系建模时具有参数密集性，因此容易出现过拟合。相比之下，通过马尔可夫潜态动力学，SLDS可以以参数高效的方式捕捉长距离依赖性，但困难的参数估计任务和一个难以处理的似然函数却是其具有挑战性的地方。在本文中，我们提出了切换自回归低秩张量（SALT）模型，该模型保留了两种方法的优点，同时改善了其局限性。SALT将ARHMM的张量参数化为低秩形式。

    An important problem in time-series analysis is modeling systems with time-varying dynamics. Probabilistic models with joint continuous and discrete latent states offer interpretable, efficient, and experimentally useful descriptions of such data. Commonly used models include autoregressive hidden Markov models (ARHMMs) and switching linear dynamical systems (SLDSs), each with its own advantages and disadvantages. ARHMMs permit exact inference and easy parameter estimation, but are parameter intensive when modeling long dependencies, and hence are prone to overfitting. In contrast, SLDSs can capture long-range dependencies in a parameter efficient way through Markovian latent dynamics, but present an intractable likelihood and a challenging parameter estimation task. In this paper, we propose switching autoregressive low-rank tensor (SALT) models, which retain the advantages of both approaches while ameliorating the weaknesses. SALT parameterizes the tensor of an ARHMM with a low-rank 
    
[^19]: 从众包标签进行深度学习：耦合交叉熵最小化、可识别性和正则化

    Deep Learning From Crowdsourced Labels: Coupled Cross-entropy Minimization, Identifiability, and Regularization. (arXiv:2306.03288v1 [cs.LG])

    [http://arxiv.org/abs/2306.03288](http://arxiv.org/abs/2306.03288)

    本文提出了使用众包标签进行深度学习的方法，通过耦合交叉熵最小化和正则化使学习过程更加鲁棒，同时提出了性能保证。

    

    使用多个注释者提供的有噪声的众包标签，一个基于深度学习的端到端 (E2E) 系统旨在同时学习标签校正机制和神经分类器。耦合交叉熵最小化 (CCEM) 类型准则直观且在实践中表现良好。本文提出了对 CCEM 准则的性能保证，并提出了一种正则化方法，从而使学习过程更加鲁棒。

    Using noisy crowdsourced labels from multiple annotators, a deep learning-based end-to-end (E2E) system aims to learn the label correction mechanism and the neural classifier simultaneously. To this end, many E2E systems concatenate the neural classifier with multiple annotator-specific ``label confusion'' layers and co-train the two parts in a parameter-coupled manner. The formulated coupled cross-entropy minimization (CCEM)-type criteria are intuitive and work well in practice. Nonetheless, theoretical understanding of the CCEM criterion has been limited. The contribution of this work is twofold: First, performance guarantees of the CCEM criterion are presented. Our analysis reveals for the first time that the CCEM can indeed correctly identify the annotators' confusion characteristics and the desired ``ground-truth'' neural classifier under realistic conditions, e.g., when only incomplete annotator labeling and finite samples are available. Second, based on the insights learned from
    
[^20]: 通过重新思考民间威斯费勒-莱曼算法，实现$O(n^2)$空间内任意表达能力的GNNs

    Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking Folklore Weisfeiler-Lehman. (arXiv:2306.03266v1 [cs.LG])

    [http://arxiv.org/abs/2306.03266](http://arxiv.org/abs/2306.03266)

    本文提出了$(k, t)$-FWL和$k$-FWL+两种方法，理论上证明了它们可以在$O(n^2)$的空间复杂度下，解决图同构问题。

    

    近年来，消息传递神经网络（MPNNs）已成为图神经网络（GNNs）中最受欢迎的框架。然而，其表达能力受到一维威斯费勒-莱曼（1-WL）测试的限制。一些研究受到$k$-WL/FWL（民间WL）的启发并设计其相应的神经版本。尽管具有很高的表达能力，但这一研究方向存在严重局限性。为解决这些问题，作者提出了$(k, t)$-FWL和$k$-FWL+，并在理论上证明了它们的有效性。

    Message passing neural networks (MPNNs) have emerged as the most popular framework of graph neural networks (GNNs) in recent years. However, their expressive power is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Some works are inspired by $k$-WL/FWL (Folklore WL) and design the corresponding neural versions. Despite the high expressive power, there are serious limitations in this line of research. In particular, (1) $k$-WL/FWL requires at least $O(n^k)$ space complexity, which is impractical for large graphs even when $k=3$; (2) The design space of $k$-WL/FWL is rigid, with the only adjustable hyper-parameter being $k$. To tackle the first limitation, we propose an extension, $(k, t)$-FWL. We theoretically prove that even if we fix the space complexity to $O(n^2)$ in $(k, t)$-FWL, we can construct an expressiveness hierarchy up to solving the graph isomorphism problem. To tackle the second problem, we propose $k$-FWL+, which considers any equivariant set as neighbors ins
    
[^21]: 解释与调整图形条件转移

    Explaining and Adapting Graph Conditional Shift. (arXiv:2306.03256v1 [cs.LG])

    [http://arxiv.org/abs/2306.03256](http://arxiv.org/abs/2306.03256)

    本研究通过量化输入特征和输出标签之间的条件偏移量，对图神经网络易受分布偏移影响的问题进行理论分析。研究发现，图形异质性和模型架构都会导致条件偏移，影响性能。作者提出了一种方法，通过条件偏移的估计和最小化来应对这一问题，该方法在节点分类和图分类任务上表现更优。

    

    图神经网络在图结构数据上表现出卓越的性能。然而，最近的实证研究表明，GNN非常容易受到分布偏移的影响。目前关于为什么基于图形的模型似乎更容易受到这些偏移影响的问题还存在显著的歧义。在这项工作中，我们通过量化输入特征和输出标签之间的条件偏移量，对它进行了彻底的理论分析。我们的研究结果表明，图形异质性和模型架构都加剧了条件偏移，导致性能下降。为了应对这一问题，我们提出了一种方法，涉及对图形上的无监督域适应性进行条件偏移的估计和最小化。在我们的控制性综合实验中，我们的算法表现出对分布偏移的鲁棒性，相对第二优算法实现了高达10%的ROC AUC绝对改善。此外，对节点分类和图分类任务的全面实验表明，我们的方法始终优于最先进的域适应方法。

    Graph Neural Networks (GNNs) have shown remarkable performance on graph-structured data. However, recent empirical studies suggest that GNNs are very susceptible to distribution shift. There is still significant ambiguity about why graph-based models seem more vulnerable to these shifts. In this work we provide a thorough theoretical analysis on it by quantifying the magnitude of conditional shift between the input features and the output label. Our findings show that both graph heterophily and model architecture exacerbate conditional shifts, leading to performance degradation. To address this, we propose an approach that involves estimating and minimizing the conditional shift for unsupervised domain adaptation on graphs. In our controlled synthetic experiments, our algorithm demonstrates robustness towards distribution shift, resulting in up to 10% absolute ROC AUC improvement versus the second-best algorithm. Furthermore, comprehensive experiments on both node classification and gr
    
[^22]: 非线性分布鲁棒优化

    Nonlinear Distributionally Robust Optimization. (arXiv:2306.03202v1 [stat.ML])

    [http://arxiv.org/abs/2306.03202](http://arxiv.org/abs/2306.03202)

    本文提出一种新的非线性分布鲁棒优化算法，用于处理一类分布鲁棒优化问题，通过 Gateaux Derivative 处理一般风险度量。经过实验验证，该方法成功处理分布的非线性目标函数。

    

    本文关注一类分布鲁棒优化（DRO）问题，其中目标函数在分布上可能是非线性的，这与现有的文献有所不同。为解决在概率空间中优化非线性函数面临的理论和计算挑战，我们提出了一种Derivative和相应的平滑度概念，基于Gateaux Derivative来处理一般风险度量。我们通过Var、entropic risk和有限支持集上的三个运行风险度量示例来解释这些概念。然后，我们为概率空间中一般非线性优化问题提出了一种基于G-derivative的Frank-Wolfe（FW）算法，并以完全独立于范数的方式推导出其收敛性在提出的平滑度概念下。我们利用FW算法的设置来设计一种计算非线性DRO问题鞍点的方法。我们通过数值实验展示了我们方法处理分布的非线性目标函数的成功。

    This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially non-linear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present both theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative based Frank-Wolfe~(FW) algorithm for generic non-linear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the non-lin
    
[^23]: 基于格点对注意机制进行先验加入，以提高抽象几何推理的样本效率

    Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning. (arXiv:2306.03175v1 [cs.AI])

    [http://arxiv.org/abs/2306.03175](http://arxiv.org/abs/2306.03175)

    LatFormer是一种将格点对称先验融入到注意力掩码中的模型，能够用卷积网络生成软掩码来调整注意力权重。该模型在合成几何推理中取得了较好效果。

    

    抽象和推理语料库（ARC）及其最近的语言完整实例（LARC）被认为是通往通用人工智能的重要一步。然而，即使是最先进的机器学习模型在这些问题上也难以实现有意义的性能，落后于非学习方法。我们认为解决这些任务需要极端的泛化能力，只有通过适当考虑核心知识先验才能实现。为了达到这个目标，我们聚焦于几何先验，并引入LatFormer模型，将格点对称先验融入到注意力掩码中。我们证明了对于超立方格的任何变换，都存在一个二值注意力掩码来实现该群作用。因此，我们的研究激发了对标准注意力机制的修改，其中使用卷积网络生成的软掩码来调整关注权重。在合成几何推理方面的实验表明，LatFormer

    The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most recent language-complete instantiation (LARC) has been postulated as an important step towards general AI. Yet, even state-of-the-art machine learning models struggle to achieve meaningful performance on these problems, falling behind non-learning based approaches. We argue that solving these tasks requires extreme generalization that can only be achieved by proper accounting for core knowledge priors. As a step towards this goal, we focus on geometry priors and introduce LatFormer, a model that incorporates lattice symmetry priors in attention masks. We show that, for any transformation of the hypercubic lattice, there exists a binary attention mask that implements that group action. Hence, our study motivates a modification to the standard attention mechanism, where attention weights are scaled using soft masks generated by a convolutional network. Experiments on synthetic geometric reasoning show that LatFormer 
    
[^24]: 针对离线设计生物序列的得分条件生成器的自助增强训练

    Bootstrapped Training of Score-Conditioned Generator for Offline Design of Biological Sequences. (arXiv:2306.03111v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.03111](http://arxiv.org/abs/2306.03111)

    本文提出了一种BootGen算法，使用代理得分函数增强生物序列生成器的训练数据集，并产生多样化的设计，将其应用于优化生物序列，取得了比竞争对手更好的结果。

    

    本文研究了优化生物序列（如蛋白质、DNA和RNA）以最大化仅在离线数据集中评估的黑匣子得分函数的问题。我们提出了一种新颖的解决方案——得分条件生成器的自助增强训练（BootGen）算法。我们的算法重复了一个两阶段过程。在第一阶段，我们的算法使用排名加权法训练生物序列生成器，以提高基于高分数的序列生成的准确性。接下来的阶段涉及到自助增强，通过自动生成的数据并标记代理得分函数，来增强训练数据集。我们的关键思想是将基于得分的生成与代理得分函数对齐，将代理得分函数的知识传递给生成器。训练后，我们聚合来自多个自助增强生成器和代理的样本，产生多样化的设计。大量实验表明，我们的方法在生物序列优化方面胜过竞争对手。

    We study the problem of optimizing biological sequences, e.g., proteins, DNA, and RNA, to maximize a black-box score function that is only evaluated in an offline dataset. We propose a novel solution, bootstrapped training of score-conditioned generator (BootGen) algorithm. Our algorithm repeats a two-stage process. In the first stage, our algorithm trains the biological sequence generator with rank-based weights to enhance the accuracy of sequence generation based on high scores. The subsequent stage involves bootstrapping, which augments the training dataset with self-generated data labeled by a proxy score function. Our key idea is to align the score-based generation with a proxy score function, which distills the knowledge of the proxy score function to the generator. After training, we aggregate samples from multiple bootstrapped generators and proxies to produce a diverse design. Extensive experiments show that our method outperforms competitive baselines on biological sequential
    
[^25]: Mixup在寻找最佳决策边界中的可证实益处

    Provable Benefit of Mixup for Finding Optimal Decision Boundaries. (arXiv:2306.00267v1 [cs.LG])

    [http://arxiv.org/abs/2306.00267](http://arxiv.org/abs/2306.00267)

    本研究证明了使用Mixup训练具有可证实的益处，可以显著降低在更可分离数据分布中寻找最佳决策边界的样本复杂度。

    

    本文研究了像Mixup这样的成对数据增强技术如何影响在二元线性分类问题中寻找最佳决策边界的样本复杂度。针对一类具有可分离常数$\kappa$的数据分布，我们分析了训练损失最优分类器与测试准确率最优分类器（即贝叶斯最优分类器）之间的对齐程度。对于没有增强的普通训练，我们发现了一种有趣的现象，称为可分离性的诅咒。随着我们增加$\kappa$使数据分布更加可分离，普通训练的样本复杂度会在$\kappa$中呈指数增长。也许更令人惊讶的是，对于更可分离的数据分布而言，寻找最佳决策边界的任务变得更加困难。针对Mixup训练，我们展示了Mixup减轻了这个问题，通过显著降低样本复杂度。为此，我们开发了适用于Mixup考虑的$n^2$成对增强数据点的新的集中结果。我们的结果提供了关于Mixup的泛化益处的可证保证，并提供了理解Mixup为什么在实践中表现良好的见解。

    We investigate how pair-wise data augmentation techniques like Mixup affect the sample complexity of finding optimal decision boundaries in a binary linear classification problem. For a family of data distributions with a separability constant $\kappa$, we analyze how well the optimal classifier in terms of training loss aligns with the optimal one in test accuracy (i.e., Bayes optimal classifier). For vanilla training without augmentation, we uncover an interesting phenomenon named the curse of separability. As we increase $\kappa$ to make the data distribution more separable, the sample complexity of vanilla training increases exponentially in $\kappa$; perhaps surprisingly, the task of finding optimal decision boundaries becomes harder for more separable distributions. For Mixup training, we show that Mixup mitigates this problem by significantly reducing the sample complexity. To this end, we develop new concentration results applicable to $n^2$ pair-wise augmented data points cons
    
[^26]: 线性神经网络层促进学习单指数和多指数模型

    Linear Neural Network Layers Promote Learning Single- and Multiple-Index Models. (arXiv:2305.15598v1 [cs.LG])

    [http://arxiv.org/abs/2305.15598](http://arxiv.org/abs/2305.15598)

    本研究探究了过度参数化的深度神经网络的偏见，发现在ReLU网络中添加线性层有助于逼近具有低秩线性算子和低表示成本函数组成的函数，从而得到一个与低维子空间垂直方向近乎恒定的插值函数。

    

    本文探究了深度大于两层的过度参数化神经网络的隐含偏见。我们的框架考虑了一类深度不同但容量相同的网络，它们具有不同的显式定义的表示成本。神经网络架构诱导的函数的表示成本是网络表示该函数所需的平方权重之和的最小值；它反映了与该架构相关的函数空间偏差。结果表明，将线性层添加到ReLU网络会产生一个表示成本，这有利于使用两层网络来逼近由低秩线性算子和具有低表示成本的函数组成的函数。具体来说，使用神经网络以最小的表示成本拟合训练数据会得到一个与低维子空间垂直方向近乎恒定的插值函数。

    This paper explores the implicit bias of overparameterized neural networks of depth greater than two layers. Our framework considers a family of networks of varying depths that all have the same capacity but different implicitly defined representation costs. The representation cost of a function induced by a neural network architecture is the minimum sum of squared weights needed for the network to represent the function; it reflects the function space bias associated with the architecture. Our results show that adding linear layers to a ReLU network yields a representation cost that favors functions that can be approximated by a low-rank linear operator composed with a function with low representation cost using a two-layer network. Specifically, using a neural network to fit training data with minimum representation cost yields an interpolating function that is nearly constant in directions orthogonal to a low-dimensional subspace. This means that the learned network will approximate
    
[^27]: 任意缺失模式下的无分布矩阵预测

    Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern. (arXiv:2305.11640v1 [cs.LG])

    [http://arxiv.org/abs/2305.11640](http://arxiv.org/abs/2305.11640)

    本文提出了两种实用算法，能够在任意丢失模式下有效地保证覆盖率的有效性，并量化了缺失对预测精度的影响。

    

    本文研究了在行/列可交换矩阵中预测缺失条目的问题。虽然矩阵设置提出了新颖和独特的挑战，但是在这个有趣的主题上存在很少的工作。我们精细地定义了问题，将其与密切相关的问题区分开来，并严格划分了可达成和不可能的目标的边界。然后我们提出了两种实用算法。第一种方法提供了全面的预测的快速仿真，而第二种方法利用算法稳定性技术加速计算。这两种方法计算效率高，能够在任意丢失模式下有效地保证覆盖率的有效性。此外，我们量化了缺失对预测精度的影响，并建立了基本的极限结果。来自合成和真实数据集的经验证据证实了我们提出的方法的卓越性能。

    This paper studies the open problem of conformalized entry prediction in a row/column-exchangeable matrix. The matrix setting presents novel and unique challenges, but there exists little work on this interesting topic. We meticulously define the problem, differentiate it from closely related problems, and rigorously delineate the boundary between achievable and impossible goals. We then propose two practical algorithms. The first method provides a fast emulation of the full conformal prediction, while the second method leverages the technique of algorithmic stability for acceleration. Both methods are computationally efficient and can effectively safeguard coverage validity in presence of arbitrary missing pattern. Further, we quantify the impact of missingness on prediction accuracy and establish fundamental limit results. Empirical evidence from synthetic and real-world data sets corroborates the superior performance of our proposed methods.
    
[^28]: 从随机搜索到度量测度空间中的赌博学习

    From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])

    [http://arxiv.org/abs/2305.11509](http://arxiv.org/abs/2305.11509)

    本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。

    

    随机搜索是超参数优化中最常用的方法之一，对于深度学习模型的成功至关重要。尽管其性能令人惊叹，但很少有非启发式的理论用于描述其工作机制。本文给出了关于随机搜索的理论解释。我们引入了“散射维度”的概念，描述了底层函数的状态，并量化了随机搜索的性能。我们表明，当环境没有噪声时，随机搜索的输出以概率收敛到最优值，其速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $，其中$ d_s \ge 0 $是底层函数的散射维度。当观察到的函数值受到有界的独立同分布噪声影响时，随机搜索的输出以概率收敛到最优值，速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $。

    Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
    
[^29]: 基于Fisher信息嵌入的节点和图学习

    Fisher Information Embedding for Node and Graph Learning. (arXiv:2305.07580v1 [stat.ML])

    [http://arxiv.org/abs/2305.07580](http://arxiv.org/abs/2305.07580)

    本文提出了一种新的基于注意力机制的图节点嵌入框架，可以更好地理解基于注意力机制的GNN。

    

    基于注意力机制的图神经网络（GNN），例如图注意力网络（GAT），已成为处理图结构数据和学习节点嵌入的流行神经网络结构。尽管这些模型在经验上取得了成功，但它们依赖于标注数据，且这些模型的理论属性尚未完全理解。本文提出了一种新颖的基于注意力机制的图节点嵌入框架。我们的框架建立在一种多重集合内节点周围子图的分层核之上（例如，邻域），并且每个核利用平滑统计流形的几何来比较多重集合的成对差异，通过将多重集合“映射”到流形上。通过显式计算高斯混合物流形中的节点嵌入，我们的方法引导出了一种新的关注机制进行邻域聚合。我们提供了有关嵌入的泛化和表达能力的理论见解，为更深入理解基于注意力机制的GNN做出了贡献。

    Attention-based graph neural networks (GNNs), such as graph attention networks (GATs), have become popular neural architectures for processing graph-structured data and learning node embeddings. Despite their empirical success, these models rely on labeled data and the theoretical properties of these models have yet to be fully understood. In this work, we propose a novel attention-based node embedding framework for graphs. Our framework builds upon a hierarchical kernel for multisets of subgraphs around nodes (e.g. neighborhoods) and each kernel leverages the geometry of a smooth statistical manifold to compare pairs of multisets, by "projecting" the multisets onto the manifold. By explicitly computing node embeddings with a manifold of Gaussian mixtures, our method leads to a new attention mechanism for neighborhood aggregation. We provide theoretical insights into genralizability and expressivity of our embeddings, contributing to a deeper understanding of attention-based GNNs. We p
    
[^30]: 受限通信加性高斯噪声下的多臂赌博机问题研究

    Communication-Constrained Bandits under Additive Gaussian Noise. (arXiv:2304.12680v1 [cs.LG])

    [http://arxiv.org/abs/2304.12680](http://arxiv.org/abs/2304.12680)

    本文研究了在受限通信和加性高斯噪声下的多臂赌博机问题，提出了一个多阶段赌博算法，并给出了信息理论下限。

    

    本文研究了一个分布式随机多臂赌博机,其中客户端根据相应的拉臂奖励提供受限通信反馈给学习者。在我们的设定下,客户端必须编码奖励，使得编码奖励的二阶矩不超过P，并且这个编码奖励会被方差为$\sigma^2$的加性高斯噪声所污染；学习者只能访问这个被污染的奖励。我们在这个设置中导出了任何方案的最小化后悔的信息论下限$\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$，其中 $ \mathtt{SNR} := \frac{P}{\sigma^2}$，$K$和$T$分别是臂数和时间长度。此外，我们提出了一个多阶段赌博算法$\mathtt{UE\text{-}UCB++}$，它可以将这个下限的值加上一个微小的可加性因子。$\mathtt{UE\text{-}UCB++}$在其初始阶段执行均匀探索，然后在后续阶段使用“上置信界”(UCB)算法。我们还展示了数值结果，表明在实际情况下需要这样的通信有效算法。

    We study a distributed stochastic multi-armed bandit where a client supplies the learner with communication-constrained feedback based on the rewards for the corresponding arm pulls. In our setup, the client must encode the rewards such that the second moment of the encoded rewards is no more than $P$, and this encoded reward is further corrupted by additive Gaussian noise of variance $\sigma^2$; the learner only has access to this corrupted reward. For this setting, we derive an information-theoretic lower bound of $\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$ on the minimax regret of any scheme, where $ \mathtt{SNR} := \frac{P}{\sigma^2}$, and $K$ and $T$ are the number of arms and time horizon, respectively. Furthermore, we propose a multi-phase bandit algorithm, $\mathtt{UE\text{-}UCB++}$, which matches this lower bound to a minor additive factor. $\mathtt{UE\text{-}UCB++}$ performs uniform exploration in its initial phases and then utilizes the {\em upper confidence
    
[^31]: 多元概率预测评估中的可靠性区域研究

    Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts. (arXiv:2304.09836v1 [cs.LG])

    [http://arxiv.org/abs/2304.09836](http://arxiv.org/abs/2304.09836)

    本研究通过有限样本和功率分析确定了多元概率时间序列预测评分规则的可靠性区域，并在电力生产问题上评估了结果对真实世界任务的普适性。

    

    在多元概率时间序列预测的评估中，通常使用适当的评分规则进行评估，即对于基准分布期望最小的函数。然而，在非渐进情况下，这一属性不能保证具有良好的区分度。在本文中，我们提供了第一篇系统的有限样本适当评分规则研究，通过功率分析，我们确定了一个分数规则的“可靠性区域”，即它可以可靠地识别预测误差的一组实际条件。我们在一个全面的人造基准测试上进行了分析，该测试专门设计以测试基准分布与预测分布之间的几个关键差异，并通过在电力生产问题上应用来评估我们的结果对真实世界任务的普适性。我们的结果揭示了在多元概率预测的评估中的重大缺陷。

    Multivariate probabilistic time series forecasts are commonly evaluated via proper scoring rules, i.e., functions that are minimal in expectation for the ground-truth distribution. However, this property is not sufficient to guarantee good discrimination in the non-asymptotic regime. In this paper, we provide the first systematic finite-sample study of proper scoring rules for time-series forecasting evaluation. Through a power analysis, we identify the "region of reliability" of a scoring rule, i.e., the set of practical conditions where it can be relied on to identify forecasting errors. We carry out our analysis on a comprehensive synthetic benchmark, specifically designed to test several key discrepancies between ground-truth and forecast distributions, and we gauge the generalizability of our findings to real-world tasks with an application to an electricity production problem. Our results reveal critical shortcomings in the evaluation of multivariate probabilistic forecasts as co
    
[^32]: 快速率的最大熵探索方法

    Fast Rates for Maximum Entropy Exploration. (arXiv:2303.08059v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.08059](http://arxiv.org/abs/2303.08059)

    本文解决了强化学习中稀疏奖励下的最大熵探索问题，提出了两种类型的最大熵探索方法，并提高了其样本复杂度。

    

    当智能体在一个未知的、稀疏或没有奖励的环境中操作时，我们解决了强化学习（RL）中探索的挑战。在本文中，我们研究了两种不同类型的最大熵探索问题。第一种类型是回访熵最大化，这在折扣设置中已经由Hazan et al.（2019）考虑过。对于这种类型的探索，我们提出了一种博弈论算法，其样本复杂性为$\widetilde{\mathcal{O}}(H^3S^2A/\varepsilon^2)$，从而改进了现有结果的$\varepsilon$依赖关系，其中$S$是状态数，$A$是行动数，$H$是每个回合的长度，$\varepsilon$是期望的精度。我们研究的第二种熵是轨迹熵。这个目标函数与熵正则化MDPs密切相关，我们提出了一个简单的算法，其样本复杂度为$\widetilde{\mathcal{O}}(\mathrm{poly}(S,A,H)/\varepsilon)$。有趣的是，这是第一个在具有$\mathrm{poly}(S,A,H)$样本复杂度的情况下解决轨迹熵最大化问题的算法。

    We address the challenge of exploration in reinforcement learning (RL) when the agent operates in an unknown environment with sparse or no rewards. In this work, we study the maximum entropy exploration problem of two different types. The first type is visitation entropy maximization previously considered by Hazan et al.(2019) in the discounted setting. For this type of exploration, we propose a game-theoretic algorithm that has $\widetilde{\mathcal{O}}(H^3S^2A/\varepsilon^2)$ sample complexity thus improving the $\varepsilon$-dependence upon existing results, where $S$ is a number of states, $A$ is a number of actions, $H$ is an episode length, and $\varepsilon$ is a desired accuracy. The second type of entropy we study is the trajectory entropy. This objective function is closely related to the entropy-regularized MDPs, and we propose a simple algorithm that has a sample complexity of order $\widetilde{\mathcal{O}}(\mathrm{poly}(S,A,H)/\varepsilon)$. Interestingly, it is the first th
    
[^33]: 安全剥离L0正则化最小二乘问题

    Safe Peeling for L0-Regularized Least-Squares with supplementary material. (arXiv:2302.14471v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14471](http://arxiv.org/abs/2302.14471)

    引入“安全剥离”方法加速解决L0正则化最小二乘问题，通过收缩松弛度允许更激进的剪枝，显著降低求解时间。

    

    我们引入了一种新的方法，称为“安全剥离”，通过分支定界算法加速解决L0正则化最小二乘问题。我们的程序使得在BnB决策树的每个节点处考虑到收缩松弛度，因此可能允许更加激进的剪枝。数值模拟表明，我们提出的方法在探索节点数量和整体求解时间方面具有显著的优势。

    We introduce a new methodology dubbed ``safe peeling'' to accelerate the resolution of L0-regularized least-squares problems via a Branch-and-Bound (BnB) algorithm. Our procedure enables to tighten the convex relaxation considered at each node of the BnB decision tree and therefore potentially allows for more aggressive pruning. Numerical simulations show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.s show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.
    
[^34]: 异质性处理效应的因果等保校准方法

    Causal isotonic calibration for heterogeneous treatment effects. (arXiv:2302.14011v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.14011](http://arxiv.org/abs/2302.14011)

    提出了因果等保校准方法及其数据有效的变体交叉校准，这两种方法都能快速稳健地校准异质性处理效应的预测器，而且可以应用于任何黑盒学习算法。

    

    本文提出一种新的非参数方法——因果等保校准方法，用于校准异质性处理效应的预测器。此外，我们还介绍了交叉校准，这是一种数据有效的校准变体，消除了保留校准集的需要。交叉校准利用交叉拟合的预测器，并使用所有可用数据生成一个单一的校准预测器。在不要求单调性的弱条件下，我们证明了因果等保校准和交叉校准都能实现快速双重稳健校准速率，只要利用类似意义下精确估计了倾向得分或后果回归。这种因果等保校准器可以包装在任何黑盒学习算法周围，提供强健和分布自由的校准保证，同时保持预测性能。

    We propose causal isotonic calibration, a novel nonparametric method for calibrating predictors of heterogeneous treatment effects. Furthermore, we introduce cross-calibration, a data-efficient variant of calibration that eliminates the need for hold-out calibration sets. Cross-calibration leverages cross-fitted predictors and generates a single calibrated predictor using all available data. Under weak conditions that do not assume monotonicity, we establish that both causal isotonic calibration and cross-calibration achieve fast doubly-robust calibration rates, as long as either the propensity score or outcome regression is estimated accurately in a suitable sense. The proposed causal isotonic calibrator can be wrapped around any black-box learning algorithm, providing robust and distribution-free calibration guarantees while preserving predictive performance.
    
[^35]: 通过f-散度最小化对齐语言模型与偏好

    Aligning Language Models with Preferences through f-divergence Minimization. (arXiv:2302.08215v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08215](http://arxiv.org/abs/2302.08215)

    本文提出一种新的方法f-DPG，用于对齐语言模型和偏好，该方法适用于评估任何目标分布，统一了现有的各种框架和逼近方法。

    

    对齐语言模型和偏好可以被看作是对目标分布进行逼近，以期达到某种所需行为。现有的方法在目标分布的函数形式和用于逼近目标分布的算法上存在差异。本文提出了一种新方法f-DPG，该方法允许使用任何可评估的f-散度逼近任何目标分布，从而统一了现有的各种框架和逼近方法。我们展示了各种散度目标的实际好处，并证明了没有普适的最佳选择。

    Aligning language models with preferences can be posed as approximating a target distribution representing some desired behavior. Existing approaches differ both in the functional form of the target distribution and the algorithm used to approximate it. For instance, Reinforcement Learning from Human Feedback (RLHF) corresponds to minimizing a reverse KL from an implicit target distribution arising from a KL penalty in the objective. On the other hand, Generative Distributional Control (GDC) has an explicit target distribution and minimizes a forward KL from it using the Distributional Policy Gradient (DPG) algorithm. In this paper, we propose a new approach, f-DPG, which allows the use of any f-divergence to approximate any target distribution that can be evaluated. f-DPG unifies both frameworks (RLHF, GDC) and the approximation methods (DPG, RL with KL penalties). We show the practical benefits of various choices of divergence objectives and demonstrate that there is no universally o
    
[^36]: 不是神奇药丸，而是洞察力之搜寻：消除异质性处理效应估计中的模型选择困境

    In Search of Insights, Not Magic Bullets: Towards Demystification of the Model Selection Dilemma in Heterogeneous Treatment Effect Estimation. (arXiv:2302.02923v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.02923](http://arxiv.org/abs/2302.02923)

    本文研究在具有高风险应用的个性化处理效应估计中，不同模型选择标准的优点和缺点，并提出未来研究方向。

    

    个性化处理效应估计在高风险应用中经常备受关注，因此，在实践中部署估计这种效应的模型之前，需要确信已经选择了最好的机器学习工具箱中的候选模型。不幸的是，由于实践中缺乏反事实信息，通常无法依靠标准验证指标完成此任务，导致了处理效应估计文献中已知的模型选择困境。虽然最近已经研究了一些解决方案，但对不同模型选择标准的优缺点的系统理解仍然缺乏。因此，在本文中，我们并没有试图宣布全局“胜者”，而是对不同选择标准的成功和失败模式进行了实证研究。我们强调选择策略，候选估计量和用于比较它们的数据之间存在复杂的相互作用，并提出了未来研究的方向。

    Personalized treatment effect estimates are often of interest in high-stakes applications -- thus, before deploying a model estimating such effects in practice, one needs to be sure that the best candidate from the ever-growing machine learning toolbox for this task was chosen. Unfortunately, due to the absence of counterfactual information in practice, it is usually not possible to rely on standard validation metrics for doing so, leading to a well-known model selection dilemma in the treatment effect estimation literature. While some solutions have recently been investigated, systematic understanding of the strengths and weaknesses of different model selection criteria is still lacking. In this paper, instead of attempting to declare a global `winner', we therefore empirically investigate success- and failure modes of different selection criteria. We highlight that there is a complex interplay between selection strategies, candidate estimators and the data used for comparing them, an
    
[^37]: 预条件对超参化低秩矩阵感知的影响

    The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing. (arXiv:2302.01186v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01186](http://arxiv.org/abs/2302.01186)

    该研究提出了ScaledGD(𝜆)方法，相较于传统梯度下降法更加鲁棒，并且在处理低秩矩阵感知问题时具有很好的表现。

    

    本文提出了ScaledGD(𝜆)方法来解决低秩矩阵感知中矩阵可能病态以及真实秩未知的问题。该方法使用超参式表示，从一个小的随机初始化开始，通过使用特定形式的阻尼预条件梯度下降来对抗超参化和病态曲率的影响。与基准梯度下降（GD）相比，尽管预处理需要轻微的计算开销，但ScaledGD（𝜆）在面对病态问题时表现出了出色的鲁棒性。在高斯设计下，ScaledGD($\lambda$) 会在仅迭代数对数级别的情况下，以线性速率收敛到真实的低秩矩阵。

    We propose $\textsf{ScaledGD($\lambda$)}$, a preconditioned gradient descent method to tackle the low-rank matrix sensing problem when the true rank is unknown, and when the matrix is possibly ill-conditioned. Using overparametrized factor representations, $\textsf{ScaledGD($\lambda$)}$ starts from a small random initialization, and proceeds by gradient descent with a specific form of damped preconditioning to combat bad curvatures induced by overparameterization and ill-conditioning. At the expense of light computational overhead incurred by preconditioners, $\textsf{ScaledGD($\lambda$)}$ is remarkably robust to ill-conditioning compared to vanilla gradient descent ($\textsf{GD}$) even with overprameterization. Specifically, we show that, under the Gaussian design, $\textsf{ScaledGD($\lambda$)}$ converges to the true low-rank matrix at a constant linear rate after a small number of iterations that scales only logarithmically with respect to the condition number and the problem dimensi
    
[^38]: 重新审视 Bellman Errors 用于离线模型选择

    Revisiting Bellman Errors for Offline Model Selection. (arXiv:2302.00141v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00141](http://arxiv.org/abs/2302.00141)

    本文重新审视 Bellman Errors，发现之前的Bellman Errors 方法需要在特定条件下才能表现良好，同时提出了更准确的 MSBE 估计器，在离散控制任务方面表现出色。

    

    离线模型选择（OMS）即在只有已记录数据的情况下从众多策略中选择最佳策略，对于在实际环境下应用离线RL至关重要。一个经过广泛探讨的想法是根据相关Q函数的均方Bellman误差（MSBE）选择策略。然而，之前的研究一直在使用Bellman误差时无法获得足够的OMS性能，导致许多研究人员放弃此想法。为此，本文阐述了为什么之前的结果使用Bellman误差时会看到悲观的结果，并确定了基于Bellman误差的OMS算法将表现良好的条件。此外，我们开发了一个比之前方法更准确的MSBE的新的估计器。我们的估计器在不同的离散控制任务（包括 Atari 游戏）上获得了出色的OMS性能。

    Offline model selection (OMS), that is, choosing the best policy from a set of many policies given only logged data, is crucial for applying offline RL in real-world settings. One idea that has been extensively explored is to select policies based on the mean squared Bellman error (MSBE) of the associated Q-functions. However, previous work has struggled to obtain adequate OMS performance with Bellman errors, leading many researchers to abandon the idea. To this end, we elucidate why previous work has seen pessimistic results with Bellman errors and identify conditions under which OMS algorithms based on Bellman errors will perform well. Moreover, we develop a new estimator of the MSBE that is more accurate than prior methods. Our estimator obtains impressive OMS performance on diverse discrete control tasks, including Atari games.
    
[^39]: 关于具有机器可表示参数的神经网络自动微分正确性的研究

    On the Correctness of Automatic Differentiation for Neural Networks with Machine-Representable Parameters. (arXiv:2301.13370v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13370](http://arxiv.org/abs/2301.13370)

    本论文研究了神经网络参数为机器可表示数字时自动微分的正确性问题，证明了神经网络带偏置参数时自动微分始终正确，给出了限制不可微性在激活函数中数目的界，并提供了判断参数是否在不可微参数组中的条件。

    

    最近的研究表明，实数域上的前向和反向模式自动微分几乎始终在数学上是准确的。然而，实际编程使用的是机器可表示的数字（例如浮点数），而不是实数。本文研究了当神经网络的参数空间仅由机器可表示的数字组成时，自动微分的正确性。我们分析了两组可能导致自动微分不正确的参数：一组是网络可微但自动微分无法计算其导数的参数组，另一组是网络不可微的参数组。对于带有偏置参数的神经网络，我们首先证明了第一组参数组始终为空。然后我们给出了一个线性上限来限制第二组参数组中不可微性在激活函数中的数目，并给出了一个简单的必要和充分条件来判断一个参数是否在这个参数组中。

    Recent work has shown that forward- and reverse- mode automatic differentiation (AD) over the reals is almost always correct in a mathematically precise sense. However, actual programs work with machine-representable numbers (e.g., floating-point numbers), not reals. In this paper, we study the correctness of AD when the parameter space of a neural network consists solely of machine-representable numbers. In particular, we analyze two sets of parameters on which AD can be incorrect: the incorrect set on which the network is differentiable but AD does not compute its derivative, and the non-differentiable set on which the network is non-differentiable. For a neural network with bias parameters, we first prove that the incorrect set is always empty. We then prove a tight bound on the size of the non-differentiable set, which is linear in the number of non-differentiabilities in activation functions, and give a simple necessary and sufficient condition for a parameter to be in this set. W
    
[^40]: 用于采样分子晶体结构的刚体流

    Rigid body flows for sampling molecular crystal structures. (arXiv:2301.11355v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11355](http://arxiv.org/abs/2301.11355)

    本文介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计。通过在单位四元数群上定义平滑和表现力强的流以及定义适当的密度，在旋转群上进行训练，我们可以成功地采样分子晶体结构。

    

    正则化流(NF)是一类强大的生成模型，由于其高度灵活和表现力，近年来广受欢迎。在本文中，我们介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计，例如晶体中的分子。我们的方法基于两个关键思想:首先，我们在单位四元数群上定义平滑和表现力强的流，从而可以捕捉刚体的连续旋转运动;其次，我们利用单位四元数的双覆盖特性，在旋转群上定义一个适当的密度。这确保我们的模型可以使用标准的基于似然方法或基于热力学目标密度的变分推断进行训练。我们通过训练两个分子示例的Boltzmann生成器来评估该方法，即四面体系统的多模态密度。

    Normalizing flows (NF) are a class of powerful generative models that have gained popularity in recent years due to their ability to model complex distributions with high flexibility and expressiveness. In this work, we introduce a new type of normalizing flow that is tailored for modeling positions and orientations of multiple objects in three-dimensional space, such as molecules in a crystal. Our approach is based on two key ideas: first, we define smooth and expressive flows on the group of unit quaternions, which allows us to capture the continuous rotational motion of rigid bodies; second, we use the double cover property of unit quaternions to define a proper density on the rotation group. This ensures that our model can be trained using standard likelihood-based methods or variational inference with respect to a thermodynamic target density. We evaluate the method by training Boltzmann generators for two molecular examples, namely the multi-modal density of a tetrahedral system 
    
[^41]: 层次平衡：实现基于潜在因果因素的动态公平性

    Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors. (arXiv:2301.08987v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.08987](http://arxiv.org/abs/2301.08987)

    本研究提出了层次平衡的概念，该概念捕捉了未观察到的潜在因果因素的情况变化，并探讨了动态公平性的实现。在指定的动态下，通常不能通过一步干预来实现长期公平目标。

    

    实现长期公平性需要决策和底层数据生成过程之间的相互作用。本文通过在决策和分布交互作用上进行因果建模，并提出层次平衡的概念，从动态的角度探讨实现长期公平性的可能性。与之前仅在观察变量上定义公平概念的方法不同，我们的方法在进一步捕捉未观察到的潜在因果因素方面更为精确。在指定的动态下，我们证明通常不能通过一步干预来实现长期公平目标。此外，在努力实现长期公平性的过程中，我们考虑调节公平度和性能度之间的权衡。

    The pursuit of long-term fairness involves the interplay between decision-making and the underlying data generating process. In this paper, through causal modeling with a directed acyclic graph (DAG) on the decision-distribution interplay, we investigate the possibility of achieving long-term fairness from a dynamic perspective. We propose Tier Balancing, a technically more challenging but more natural notion to achieve in the context of long-term, dynamic fairness analysis. Different from previous fairness notions that are defined purely on observed variables, our notion goes one step further, capturing behind-the-scenes situation changes on the unobserved latent causal factors that directly carry out the influence from the current decision to the future data distribution. Under the specified dynamics, we prove that in general one cannot achieve the long-term fairness goal only through one-step interventions. Furthermore, in the effort of approaching long-term fairness, we consider th
    
[^42]: 我不想说：在可选个人数据模型中保护用户同意

    I Prefer not to Say: Protecting User Consent in Models with Optional Personal Data. (arXiv:2210.13954v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13954](http://arxiv.org/abs/2210.13954)

    该论文研究了个人可以选择与决策系统共享可选个人信息的机器学习模型，并提出了保护用户同意的PUC概念，为用户隐私保护提供了有力的解决方案。

    

    我们研究了一种机器学习模型，其中个人可以选择与决策系统共享可选个人信息，这在现代保险定价模型中很常见。一些用户同意使用他们的数据，而其他人则反对并保持其数据未公开。本文表明，不共享数据的决定本身可以被视为信息，应该受到保护，以尊重用户的隐私。这一观察结果引发了一个被忽视的问题，即如何确保保护其个人数据的用户不会因此受到任何不利影响。为了解决这个问题，我们对仅使用获得积极用户同意的信息的模型进行了保护要求的正式化。这排除了作出共享数据与否决定所包含的隐含信息。我们提出了Protected User Consent (PUC)概念，这是我们证明在保护要求下损失最小的解决方案。

    We examine machine learning models in a setup where individuals have the choice to share optional personal information with a decision-making system, as seen in modern insurance pricing models. Some users consent to their data being used whereas others object and keep their data undisclosed. In this work, we show that the decision not to share data can be considered as information in itself that should be protected to respect users' privacy. This observation raises the overlooked problem of how to ensure that users who protect their personal data do not suffer any disadvantages as a result. To address this problem, we formalize protection requirements for models which only use the information for which active user consent was obtained. This excludes implicit information contained in the decision to share data or not. We offer the first solution to this problem by proposing the notion of Protected User Consent (PUC), which we prove to be loss-optimal under our protection requirement. To
    
[^43]: 为什么模型会失败？将模型性能变化归因于分布偏移

    "Why did the Model Fail?": Attributing Model Performance Changes to Distribution Shifts. (arXiv:2210.10769v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.10769](http://arxiv.org/abs/2210.10769)

    本文介绍了一种将模型性能变化归因于底层数据生成机制的分布偏移的方法，并通过推导一种重要性权重方法来计算任意一组分布的价值。

    

    机器学习模型在分布偏移下经常会出现性能下降的情况。这种偏移的根本原因可能是多重的因素，比如数据质量的变化、特定协变量分布的差异或者标签与特征之间的关系变化等。当模型在部署时失败时，将性能变化归因于这些因素对于模型开发人员来说至关重要，以识别根本原因并采取缓解措施。在本文中，我们介绍了将环境之间的性能差异归因于底层数据生成机制的分布偏移问题。我们将该问题构造为一种合作博弈的形式，其中玩家是分布。我们定义一组分布的价值为当只有这组分布在环境之间发生变化时模型性能的变化，并推导出一种重要性权重方法以计算任意一组分布的价值。

    Machine learning models frequently experience performance drops under distribution shifts. The underlying cause of such shifts may be multiple simultaneous factors such as changes in data quality, differences in specific covariate distributions, or changes in the relationship between label and features. When a model does fail during deployment, attributing performance change to these factors is critical for the model developer to identify the root cause and take mitigating actions. In this work, we introduce the problem of attributing performance differences between environments to distribution shifts in the underlying data generating mechanisms. We formulate the problem as a cooperative game where the players are distributions. We define the value of a set of distributions to be the change in model performance when only this set of distributions has changed between environments, and derive an importance weighting method for computing the value of an arbitrary set of distributions. The
    
[^44]: 通过冗余性实现稀疏性：用SGD求解$L_1$

    Sparsity by Redundancy: Solving $L_1$ with SGD. (arXiv:2210.01212v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01212](http://arxiv.org/abs/2210.01212)

    该论文提出了一种通过冗余重参数化和简单的随机梯度下降来最小化带有$L_1$惩罚的通用可微损失函数的方法，称为\textit{spred}，是$L_1$的精确求解器，可用于训练稀疏神经网络以执行基因选择任务和神经网络压缩任务，弥合了深度学习中的稀疏性和传统统计学习之间的差距。

    This paper proposes a method called "spred" to minimize a generic differentiable loss function with $L_1$ penalty using redundant reparametrization and straightforward stochastic gradient descent. It is an exact solver of $L_1$ and can be used to train sparse neural networks for gene selection tasks and neural network compression tasks, bridging the gap between sparsity in deep learning and conventional statistical learning.

    我们提出了一种通过冗余重参数化和简单的随机梯度下降来最小化带有$L_1$惩罚的通用可微损失函数的方法。我们的提议是$L_1$惩罚等价于带有权重衰减的可微重参数化的直接推广。我们证明了所提出的方法，即\textit{spred}，是$L_1$的精确求解器，并且对于通用的非凸函数，重参数化技巧是完全“良性”的。在实践中，我们展示了该方法的实用性，包括(1)训练稀疏神经网络以执行基因选择任务，其中涉及在非常高维空间中找到相关特征，以及(2)神经网络压缩任务，先前尝试应用$L_1$惩罚的方法均未成功。从概念上讲，我们的结果弥合了深度学习中的稀疏性和传统统计学习之间的差距。

    We propose to minimize a generic differentiable loss function with $L_1$ penalty with a redundant reparametrization and straightforward stochastic gradient descent. Our proposal is the direct generalization of a series of previous ideas that the $L_1$ penalty may be equivalent to a differentiable reparametrization with weight decay. We prove that the proposed method, \textit{spred}, is an exact solver of $L_1$ and that the reparametrization trick is completely ``benign" for a generic nonconvex function. Practically, we demonstrate the usefulness of the method in (1) training sparse neural networks to perform gene selection tasks, which involves finding relevant features in a very high dimensional space, and (2) neural network compression task, to which previous attempts at applying the $L_1$-penalty have been unsuccessful. Conceptually, our result bridges the gap between the sparsity in deep learning and conventional statistical learning.
    
[^45]: 个体治疗效果估计的迁移学习

    Transfer Learning for Individual Treatment Effect Estimation. (arXiv:2210.00380v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00380](http://arxiv.org/abs/2210.00380)

    本论文探讨了个体治疗效果估计中迁移因果知识的问题，并提出了一个使用CITA度量进行ITE知识转移的框架，实验证明该方法的有效性。

    

    本研究探讨了在个体治疗效果估计中通过任务之间转移因果知识的问题。我们从理论上评估了转移个体治疗效果知识的可行性，并提出了一个实用的框架来实现有效的转移。我们引入了一个下界来说明目标任务的个体治疗效果误差存在挑战，因为缺乏反事实信息。尽管如此，我们建立了目标任务反事实损失和个体治疗效果误差的泛化上界，证明了个体治疗效果知识转移的可行性。随后，我们引入了一个框架，其中使用新的因果推断任务亲和度（CITA）度量进行ITE知识转移。具体而言，我们使用CITA来找到最接近目标任务的源任务，并利用它来进行ITE知识转移。我们提供了实证研究，证明了所提出方法的有效性。我们观察到，ITE知识转移可以显著（

    This work considers the problem of transferring causal knowledge between tasks for Individual Treatment Effect (ITE) estimation. To this end, we theoretically assess the feasibility of transferring ITE knowledge and present a practical framework for efficient transfer. A lower bound is introduced on the ITE error of the target task to demonstrate that ITE knowledge transfer is challenging due to the absence of counterfactual information. Nevertheless, we establish generalization upper bounds on the counterfactual loss and ITE error of the target task, demonstrating the feasibility of ITE knowledge transfer. Subsequently, we introduce a framework with a new Causal Inference Task Affinity (CITA) measure for ITE knowledge transfer. Specifically, we use CITA to find the closest source task to the target task and utilize it for ITE knowledge transfer. Empirical studies are provided, demonstrating the efficacy of the proposed method. We observe that ITE knowledge transfer can significantly (
    
[^46]: 同态自编码器 - 从观察到转化学习群组结构表现

    Homomorphism Autoencoder -- Learning Group Structured Representations from Observed Transitions. (arXiv:2207.12067v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.12067](http://arxiv.org/abs/2207.12067)

    本文提出了一种同态自编码器方法，使机器能够在行动中学习到与其行为相一致的感知信息的内部表示，并捕获环境中的转换结构。

    

    如何让机器学习系统学习到准确表示其与真实世界交互的内在模型是一个尚待解决的问题。为了构建不仅包含观察性知识，也包含干预性知识的表现学习框架，我们使用了表示学习和群论的方法来研究该问题。我们提出一种方法，使机器能够在行动过程中学习到与之相一致的感知信息的内部表示，而这些行动实际上是变换这些信息的。我们使用一个自编码器并在其潜在空间上应用群组表示，通过利用等变损失强制实施适当的同态性质以完成训练。与现有方法不同的是，我们的方法不需要先验群组知识，并且不限制代理可执行的行动集合。理论上，我们证明了该方法的有效性，并通过实验证明了其能够学习到行动的群组表示，从而捕获了环境中的转换结构。

    How can agents learn internal models that veridically represent interactions with the real world is a largely open question. As machine learning is moving towards representations containing not just observational but also interventional knowledge, we study this problem using tools from representation learning and group theory. We propose methods enabling an agent acting upon the world to learn internal representations of sensory information that are consistent with actions that modify it. We use an autoencoder equipped with a group representation acting on its latent space, trained using an equivariance-derived loss in order to enforce a suitable homomorphism property on the group representation. In contrast to existing work, our approach does not require prior knowledge of the group and does not restrict the set of actions the agent can perform. We motivate our method theoretically, and show empirically that it can learn a group representation of the actions, thereby capturing the str
    
[^47]: 后验概念解释何时可识别？

    When are Post-hoc Conceptual Explanations Identifiable?. (arXiv:2206.13872v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.13872](http://arxiv.org/abs/2206.13872)

    本论文提出了可识别的概念发现方法，可以恢复出多个已知的概念，以确保解释的可靠性。对于具有依赖关系的概念，提出了两种新的方法，利用图像生成过程的功能组合性质。该方法明显优于现有方法。

    

    学习嵌入通常需要通过概念解释来理解和分解，这种需求在解释中不包含有效概念标签的情况下尤为显著。为了提供后验解释，概念发现方法会在已训练的嵌入空间中搜索解释性强的概念，例如物体形状或颜色。与之前的工作不同，我们认为概念发现应该是可识别的，这意味着可以被证明地恢复出多个已知的概念，以确保解释的可靠性。为了作为一个起点，我们明确地将概念发现与传统方法（例如主成分分析和独立成分分析）联系起来，并通过表明它们可以恢复具有非高斯分布的独立概念来阐明这一点。对于具有依赖关系的概念，我们提出了两种新的方法，利用图像生成过程的功能组合性质。我们的可证明可识别的概念发现方法明显优于现有方法。

    Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can be used to provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts with non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outpe
    
[^48]: 差分隐私优化中超越统一李普希茨条件

    Beyond Uniform Lipschitz Condition in Differentially Private Optimization. (arXiv:2206.10713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10713](http://arxiv.org/abs/2206.10713)

    本文提出了一种新的差分隐私优化算法来处理其它算法无法处理的非均匀李普希茨情形，并且在具体应用中提供了相应的参数调整方案。

    

    大多数关于差分隐私随机梯度下降（DP-SGD）的先前结果都是在统一李普希茨性的简化假设下导出的，即每个样本的梯度都是均匀有界的。我们通过假定每个样本的梯度具有样本相关的上界，即每个样本的李普希茨常数，从而推广了统一李普希茨性。这些本身可能是无界的。当每个样本的李普希茨常数是有界的时，我们为DP-SGD在凸超参数化设置中选择剪辑范数提供了原则性指导；具体而言，我们建议仅调整剪辑范数，直到最小每个样本李普希茨常数的值。这在深度网络上预先训练公共数据的 softmax 层的私人训练中有应用。我们通过对8个数据集的实验验证了我们的建议的功效。此外，我们还为DP-SGD在凸和非凸函数上提供了新的收敛结果。

    Most prior results on differentially private stochastic gradient descent (DP-SGD) are derived under the simplistic assumption of uniform Lipschitzness, i.e., the per-sample gradients are uniformly bounded. We generalize uniform Lipschitzness by assuming that the per-sample gradients have sample-dependent upper bounds, i.e., per-sample Lipschitz constants, which themselves may be unbounded. We provide principled guidance on choosing the clip norm in DP-SGD for convex over-parameterized settings satisfying our general version of Lipschitzness when the per-sample Lipschitz constants are bounded; specifically, we recommend tuning the clip norm only till values up to the minimum per-sample Lipschitz constant. This finds application in the private training of a softmax layer on top of a deep network pre-trained on public data. We verify the efficacy of our recommendation via experiments on 8 datasets. Furthermore, we provide new convergence results for DP-SGD on convex and nonconvex function
    
[^49]: 在RKHS的非参数回归中最优解决协变量转移问题

    Optimally tackling covariate shift in RKHS-based nonparametric regression. (arXiv:2205.02986v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2205.02986](http://arxiv.org/abs/2205.02986)

    本文研究了在RKHS的非参数回归中的协变量转移问题，针对两个不同的似然比族，证明了使用KRR估计量具有极小化率最优的特点，尤其是在似然比被均匀有界时。与此同时，本文也证明了，在协变量转移下一个naive的估计器相比于KRR是严格次优的。

    

    在再生核希尔伯特空间（RKHS）上研究了非参数回归中的协变量转移问题。我们关注两个使用源和目标分布之间的似然比定义的自然协变量转移问题族。当似然比被均匀有界时，我们证明带有精心选择的正则化参数的核岭回归(KRR)估计量是极小化率最优的（最多差一个对数因子），对于一大类具有正则核特征值的RKHS而言。有趣的是，除了似然比上界之外，KRR不需要对似然比有完全的知识。与没有协变量转移的标准统计设置形成鲜明对比的是，我们还证明了一个简单估计器，即在函数类中最小化经验风险，与KRR相比，在协变量转移下是严格次优的。然后，我们解决了更大的协变量转移问题类，其中似然比可能是无界的。

    We study the covariate shift problem in the context of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We focus on two natural families of covariate shift problems defined using the likelihood ratios between the source and target distributions. When the likelihood ratios are uniformly bounded, we prove that the kernel ridge regression (KRR) estimator with a carefully chosen regularization parameter is minimax rate-optimal (up to a log factor) for a large family of RKHSs with regular kernel eigenvalues. Interestingly, KRR does not require full knowledge of likelihood ratios apart from an upper bound on them. In striking contrast to the standard statistical setting without covariate shift, we also demonstrate that a naive estimator, which minimizes the empirical risk over the function class, is strictly sub-optimal under covariate shift as compared to KRR. We then address the larger class of covariate shift problems where the likelihood ratio is possibly unbounde
    
[^50]: 可靠机器学习的对称损失视角

    A Symmetric Loss Perspective of Reliable Machine Learning. (arXiv:2101.01366v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2101.01366](http://arxiv.org/abs/2101.01366)

    对称损失是一种新型的代理损失，能够使得学习过程对于受损标签更加鲁棒，从而提高分类器的性能。

    

    当在二元分类中最小化经验风险时，常常将零一损失替换为代理损失，以使学习目标易于优化。二元分类的代理损失例如逻辑损失，hinge损失和sigmoid损失广为人知。已知代理损失的选择会极大地影响训练分类器的性能，因此应该仔细选择。最近，满足某些对称条件（称为对称损失）的代理损失已经证明了它们在学习来自损坏标签的数据方面的实用性。在本文中，我们提供对称损失及其应用的概述。首先，我们回顾了对称损失如何在平衡误差率（BER）最小化和操作特征曲线下面积（AUC）最大化中产生鲁棒分类的方法。然后，我们演示了鲁棒AUC最大化方法可以受益于受损标签，尤其是与其他代理损失相比。

    When minimizing the empirical risk in binary classification, it is a common practice to replace the zero-one loss with a surrogate loss to make the learning objective feasible to optimize. Examples of well-known surrogate losses for binary classification include the logistic loss, hinge loss, and sigmoid loss. It is known that the choice of a surrogate loss can highly influence the performance of the trained classifier and therefore it should be carefully chosen. Recently, surrogate losses that satisfy a certain symmetric condition (aka., symmetric losses) have demonstrated their usefulness in learning from corrupted labels. In this article, we provide an overview of symmetric losses and their applications. First, we review how a symmetric loss can yield robust classification from corrupted labels in balanced error rate (BER) minimization and area under the receiver operating characteristic curve (AUC) maximization. Then, we demonstrate how the robust AUC maximization method can benefi
    
[^51]: 结构化连续稀疏化增强深度网络的训练效率

    Growing Efficient Deep Networks by Structured Continuous Sparsification. (arXiv:2007.15353v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2007.15353](http://arxiv.org/abs/2007.15353)

    本文提出一种结构化连续稀疏化的深度网络结构生长方法，通过连续松弛和采样稀疏子网络，可以在训练过程中达到紧凑的修剪网络结构，同时大幅降低计算复杂度并保持较高的准确率。

    

    我们开发了一种在训练过程中以精度和稀疏性为驱动的深度网络结构生长方法。与现有的基于完整模型或超网格架构的剪枝或架构搜索技术不同，我们的方法可以从一个小而简单的种子架构开始，动态地增长和修剪层和过滤器。通过将离散网络结构优化的连续松弛与采样稀疏子网络方案相结合，我们可以产生紧凑的修剪网络，同时显著降低训练的计算复杂度。例如，在ImageNet上，与基线ResNet-50相比，我们实现了49.7％的推理FLOPs和47.4％的训练FLOPs节省，同时保持75.2％的top-1精度--所有这些都没有任何专门的微调阶段。在CIFAR，ImageNet，PASCAL VOC和Penn Treebank上进行实验，使用卷积网络进行图像分类和语义分割。

    We develop an approach to growing deep network architectures over the course of training, driven by a principled combination of accuracy and sparsity objectives. Unlike existing pruning or architecture search techniques that operate on full-sized models or supernet architectures, our method can start from a small, simple seed architecture and dynamically grow and prune both layers and filters. By combining a continuous relaxation of discrete network structure optimization with a scheme for sampling sparse subnetworks, we produce compact, pruned networks, while also drastically reducing the computational expense of training. For example, we achieve $49.7\%$ inference FLOPs and $47.4\%$ training FLOPs savings compared to a baseline ResNet-50 on ImageNet, while maintaining $75.2\%$ top-1 accuracy -- all without any dedicated fine-tuning stage. Experiments across CIFAR, ImageNet, PASCAL VOC, and Penn Treebank, with convolutional networks for image classification and semantic segmentation, 
    
[^52]: 基于单调GAN的条件采样：从生成模型到无似然推断

    Conditional Sampling with Monotone GANs: from Generative Models to Likelihood-Free Inference. (arXiv:2006.06755v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2006.06755](http://arxiv.org/abs/2006.06755)

    本文提出了一种新的概率测度条件采样框架，使用单调GAN学习块状三角形映射，仅使用来自底层联合概率测度的样本实现无似然推断。

    

    我们提出了一种新的概率测度条件采样框架，使用了块状三角形传输映射。我们在Banach空间设置下开发了块状三角形传输的理论基础，建立了可以实现条件采样的一般条件，并在单调块状三角形映射与最优传输之间建立联系。基于该理论，我们提出了一种计算方法，称为单调生成对抗网络（M-GAN），用于学习合适的块状三角形映射。我们的算法仅使用来自底层联合概率测度的样本，因此无需似然。M-GAN的数值实验证明了在合成示例、涉及常微分方程和偏微分方程的贝叶斯反问题，以及概率图像修复中准确采样条件测度的能力。

    We present a novel framework for conditional sampling of probability measures, using block triangular transport maps. We develop the theoretical foundations of block triangular transport in a Banach space setting, establishing general conditions under which conditional sampling can be achieved and drawing connections between monotone block triangular maps and optimal transport. Based on this theory, we then introduce a computational approach, called monotone generative adversarial networks (M-GANs), to learn suitable block triangular maps. Our algorithm uses only samples from the underlying joint probability measure and is hence likelihood-free. Numerical experiments with M-GAN demonstrate accurate sampling of conditional measures in synthetic examples, Bayesian inverse problems involving ordinary and partial differential equations, and probabilistic image in-painting.
    
[^53]: Denise: 面向半正定矩阵的深度健壮主成分分析

    Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices. (arXiv:2004.13612v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2004.13612](http://arxiv.org/abs/2004.13612)

    Denise是一种基于深度学习的算法，用于对协方差矩阵进行低秩加稀疏分解，达到了与最先进技术相当的性能而且近乎接近20倍的加速。

    

    协方差矩阵的健壮主成分分析在隔离关键解释特征方面发挥着至关重要的作用。目前可用的执行低秩加稀疏分解的方法是针对特定矩阵的，也就是说，这些算法必须针对每个新的矩阵重新运行。由于这些算法的计算成本很高，因此最好学习和存储一个函数，在评估时几乎立即执行此分解。因此，我们引入了 Denise，一种基于深度学习的协方差矩阵的健壮主成分分析算法，或更一般地说，对称半正定矩阵，它学习到了这样一个函数。我们提供了 Denise 的理论保证。这些包括一个新的通用逼近定理，适用于我们的几何深度学习问题，并趋于学习问题的最优解。我们的实验表明，Denise 在分解质量方面与最先进的性能相匹配，同时近乎接近20倍的加速。

    The robust PCA of covariance matrices plays an essential role when isolating key explanatory features. The currently available methods for performing such a low-rank plus sparse decomposition are matrix specific, meaning, those algorithms must re-run for every new matrix. Since these algorithms are computationally expensive, it is preferable to learn and store a function that nearly instantaneously performs this decomposition when evaluated. Therefore, we introduce Denise, a deep learning-based algorithm for robust PCA of covariance matrices, or more generally, of symmetric positive semidefinite matrices, which learns precisely such a function. Theoretical guarantees for Denise are provided. These include a novel universal approximation theorem adapted to our geometric deep learning problem and convergence to an optimal solution to the learning problem. Our experiments show that Denise matches state-of-the-art performance in terms of decomposition quality, while being approximately $20
    
[^54]: 通过逻辑指导的认证强化学习

    Certified Reinforcement Learning with Logic Guidance. (arXiv:1902.00778v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1902.00778](http://arxiv.org/abs/1902.00778)

    本文提出了一种模型无关的强化学习算法，能够使用线性时态逻辑来制定马尔科夫决策过程的目标，将LTL属性转化为LDGBA自动机，通过调整同步奖励函数最大概率获得满足LTL规定要求的控制策略。

    

    强化学习在各种控制问题上得到了广泛应用。然而，在安全关键领域的应用需要一个系统和正式的方法来指定任务或目标。我们提出了一种无模型强化学习算法，它能够使用线性时态逻辑（LTL）来制定未知连续状态/动作马尔科夫决策过程（MDPs）的目标。给定的LTL属性被转化为极限确定化广义布氏自动机（LDGBA），通过LDGBA在行进过程中不断调整同步奖励函数。在某些假设下，该算法将保证合成出一个控制策略，其轨迹最大概率满足LTL规定的要求。

    Reinforcement Learning (RL) is a widely employed machine learning architecture that has been applied to a variety of control problems. However, applications in safety-critical domains require a systematic and formal approach to specifying requirements as tasks or goals. We propose a model-free RL algorithm that enables the use of Linear Temporal Logic (LTL) to formulate a goal for unknown continuous-state/action Markov Decision Processes (MDPs). The given LTL property is translated into a Limit-Deterministic Generalised Buchi Automaton (LDGBA), which is then used to shape a synchronous reward function on-the-fly. Under certain assumptions, the algorithm is guaranteed to synthesise a control policy whose traces satisfy the LTL specification with maximal probability.
    
[^55]: 正交统计学习

    Orthogonal Statistical Learning. (arXiv:1901.09036v4 [math.ST] UPDATED)

    [http://arxiv.org/abs/1901.09036](http://arxiv.org/abs/1901.09036)

    本文提出了一个两阶段样本拆分的元算法，该算法能够在评估总体风险时考虑干扰参数，并且实现的超额风险界的影响为二次。

    

    我们在一个统计学习的设置下提供了关于非渐近超额风险保证，其中目标参数所评估的总体风险取决于必须从数据中估计的未知干扰参数。我们分析了一个两阶段样本拆分的元算法，该算法将任意估计目标参数和干扰参数的算法作为输入。我们表明，如果总体风险满足一个称为Neyman正交性的条件，则干扰估计误差对元算法实现的超额风险界的影响为二次。我们的定理不关心用于目标和干扰的特定算法，只做出了有关它们各自性能的假设。这样，就可以利用现有机器学习的大量结果，为带有干扰组成的学习提供新的保证。此外，通过关注超额风险而不是参数估计，我们可以提供一个弱化的速率。

    We provide non-asymptotic excess risk guarantees for statistical learning in a setting where the population risk with respect to which we evaluate the target parameter depends on an unknown nuisance parameter that must be estimated from data. We analyze a two-stage sample splitting meta-algorithm that takes as input arbitrary estimation algorithms for the target parameter and nuisance parameter. We show that if the population risk satisfies a condition called Neyman orthogonality, the impact of the nuisance estimation error on the excess risk bound achieved by the meta-algorithm is of second order. Our theorem is agnostic to the particular algorithms used for the target and nuisance and only makes an assumption on their individual performance. This enables the use of a plethora of existing results from machine learning to give new guarantees for learning with a nuisance component. Moreover, by focusing on excess risk rather than parameter estimation, we can provide rates under weaker a
    

