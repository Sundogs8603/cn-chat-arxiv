# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility.](http://arxiv.org/abs/2308.10846) | 本研究创建了COB原油基准数据集，通过将资产价格转化为波动性代理，并生成与现实世界事件相一致的上下文任务标签，这些标签能普遍提升多个预测时段上四种持续学习算法的性能。这些基准数据集有望加速金融领域中的创新。 |
| [^2] | [Sparse Linear Concept Discovery Models.](http://arxiv.org/abs/2308.10782) | 本论文提出了一种基于对比语言图像模型和单个稀疏线性层的可解释框架，通过贝叶斯推断来实现概念之间的稀疏性，达到了比最近的CBM方法更好的准确性和解释性。 |
| [^3] | [Clustered Linear Contextual Bandits with Knapsacks.](http://arxiv.org/abs/2308.10722) | 本论文研究了带背包的聚类线性上下文赌博机问题，在不知道聚类成员的情况下，提供了一种实现子线性遗憾的算法，该算法只需对一个随机选择的臂子集进行一次聚类。 |
| [^4] | [An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback.](http://arxiv.org/abs/2308.10675) | 提出了一种改进的延迟反馈的强化适应性算法，通过消除先验知识需求和控制分布漂移，该算法在遗憾界限方面具有突出贡献。 |
| [^5] | [Deep Evidential Learning for Bayesian Quantile Regression.](http://arxiv.org/abs/2308.10650) | 本文提出了一种基于证据学习的深度贝叶斯分位回归模型，通过使用单一确定性前向传递模型来捕捉连续目标分布的分位数，从而实现了高效的不确定性估计。 |
| [^6] | [Faster Training of Neural ODEs Using Gau{\ss}-Legendre Quadrature.](http://arxiv.org/abs/2308.10644) | 本文提出了一种使用Gauß-Legendre积分加速神经ODE训练的方法，并通过训练相应的ODE和转移参数的方式扩展到SDE训练，加快了神经ODE的训练速度，特别适用于大型模型。该方法也提供了一种训练基于SDE的模型的新方式。 |
| [^7] | [Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian Networks.](http://arxiv.org/abs/2308.10606) | 本论文提出了一种使用连续时间贝叶斯网络分析复杂系统级联行为的建模框架，能够描述事件在系统中传播并识别可能导致级联行为的系统状态。同时，该框架具有简单的图形表示和可解释的输出。 |
| [^8] | [A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely.](http://arxiv.org/abs/2308.10505) | 本文提出了一种用于远程追踪灾害火灾的卫星热点数据聚类算法，能够在空间和时间上对点进行聚类，并允许根据需要调整参数以适应不同的位置和卫星数据源。 |
| [^9] | [Adaptive Thresholding Heuristic for KPI Anomaly Detection.](http://arxiv.org/abs/2308.10504) | 该论文提出了一种自适应阈值启发式方法（ATH），用于时间序列KPI的异常检测。该方法通过根据数据分布的局部属性动态调整检测阈值，并适应于时间序列模式的变化，以最小化误报和应对概念漂移。 |
| [^10] | [GradientCoin: A Peer-to-Peer Decentralized Large Language Models.](http://arxiv.org/abs/2308.10502) | 提出了一种理论设计的去中心化大型语言模型GradientCoin，类似于比特币现金系统的运作方式，解决了现有大型语言模型集中化和安全性的问题，但实施难度较大，经济上较标准比特币系统表现不佳。 |
| [^11] | [Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series.](http://arxiv.org/abs/2308.10496) | 本文提出了一种使用自编码器和自动微分来重构一组时间序列中缺失变量的新方法。通过训练自编码器，并在该训练之后固定神经网络参数，可以实现不同输入和输出特征组合的重构。该方法在强非线性电子元件上得到了验证，对于缺失的变量有效。 |
| [^12] | [Approximately Equivariant Graph Networks.](http://arxiv.org/abs/2308.10436) | 本文关注于图神经网络（GNNs）的主动对称性，通过考虑信号在固定图上的学习设置，提出了一种近似的对称性概念，通过图粗化实现。这篇工作提出了一个偏差-方差公式来衡量近似对称性... |
| [^13] | [Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit.](http://arxiv.org/abs/2308.10238) | 这篇论文介绍了一种名为广义汤普森抽样探索算法，能够解决多臂老虎机实值组合纯探索问题中动作集合大小为指数级别的情况。 |
| [^14] | [Wasserstein Geodesic Generator for Conditional Distributions.](http://arxiv.org/abs/2308.10145) | 通过Wasserstein几何生成器学习条件分布，生成给定特定标签的样本。使用最优输运理论提出的方法能学习观察域的条件分布和它们之间的最优输运映射。在人脸图像数据上的实验验证了该方法的有效性。 |
| [^15] | [Modeling Random Networks with Heterogeneous Reciprocity.](http://arxiv.org/abs/2308.10113) | 本文提出了一种模型，用于模拟不断增长的社交网络中多样的互惠行为。该模型考虑了用户对受欢迎用户的吸引力以及他们对链接的异质性回应。我们比较了贝叶斯和频率主义的拟合技术，并应用于Facebook留言网络的分析。 |
| [^16] | [Semi-Implicit Variational Inference via Score Matching.](http://arxiv.org/abs/2308.10014) | 本文提出了一种基于得分匹配的半隐式变分推断方法SIVI-SM，该方法利用了半隐式变分家族的层次结构，并通过处理不可计算的变分密度来实现与MCMC相当的准确性，在各种贝叶斯推断任务中优于基于ELBO的SIVI方法。 |
| [^17] | [On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design.](http://arxiv.org/abs/2308.09888) | 该论文提出了一种估计贝叶斯实验设计中期望信息增益梯度的方法，通过结合随机梯度下降算法，实现了高效优化。具体而言，通过后验期望表示来估计与设计变量相关的梯度，并提出了UEEG-MCMC和BEEG-AP两种估计方法。这些方法在不同的实验设计问题上都表现出良好的性能。 |
| [^18] | [A Two-Part Machine Learning Approach to Characterizing Network Interference in A/B Testing.](http://arxiv.org/abs/2308.09790) | 本论文提出了一种两部分机器学习方法，用于识别和描述A/B测试中的网络干扰。通过考虑潜在的复杂网络结构和建立适合的曝光映射，该方法在合成实验和真实大规模测试中的模拟中表现优于传统方法。 |
| [^19] | [Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction.](http://arxiv.org/abs/2308.06058) | 本文提出了AdaSPS和AdaSLS两种新的变种算法，用于解决SGD在非插值环境下的收敛问题，并在训练超参数模型时保持线性和亚线性的收敛速度。 |
| [^20] | [Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?.](http://arxiv.org/abs/2306.10590) | 本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。 |
| [^21] | [Learning Rate Schedules in the Presence of Distribution Shift.](http://arxiv.org/abs/2303.15634) | 该论文提出了一种学习速率表，以在数据分布发生变化时最小化SGD在线学习的后悔，能够对分布转移具有鲁棒性，同时适用于凸损失函数和非凸损失函数。最优学习速率表通常会在数据分布转移的情况下增加，能够用于高维回归模型和神经网络。 |
| [^22] | [Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time.](http://arxiv.org/abs/2302.11068) | 本论文提出了一种在几乎线性时间内用鲁棒交替最小化方法完成低秩矩阵补全的方法，并证明了观察几乎线性数量的条目即可恢复矩阵$M$，此方法克服了交替最小化方法需要精确计算的限制，更符合实际实现中对效率的要求。 |
| [^23] | [Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes based on a Hybrid Spectral Method and the Harmonic Oscillator.](http://arxiv.org/abs/2302.09580) | 该论文提出了一种基于混合谱方法和谐振子的非可分离协方差核的时空高斯过程研究，通过物理论证推导出一类新型的非可分离协方差核，能更好地捕捉观测到的时空相关性。 |
| [^24] | [Towards Explainable Land Cover Mapping: a Counterfactual-based Strategy.](http://arxiv.org/abs/2301.01520) | 本论文提出了一种基于反事实的策略，用于土地覆盖分类任务中的卫星图像时间序列。该方法具有灵活性，能发现土地覆盖类别之间的有趣信息关系，同时通过鼓励时间连续的扰动来得到更稀疏且可解释的解决方案。 |
| [^25] | [Bias and Extrapolation in Markovian Linear Stochastic Approximation with Constant Stepsizes.](http://arxiv.org/abs/2210.00953) | 本研究研究了线性随机逼近中的偏差和外推问题。我们证明了在恒定步长和Markov数据的情况下，LSA迭代会收敛到唯一的极限和稳定分布，并建立了非渐进的几何收敛速度。我们还发现，这个极限的偏差与步长成比例，直至更高阶项。在可逆链的情况下，我们还探讨了偏差与Markov数据的混合时间之间的关系。 |
| [^26] | [A Fourier representation of kernel Stein discrepancy with application to Goodness-of-Fit tests for measures on infinite dimensional Hilbert spaces.](http://arxiv.org/abs/2206.04552) | 本文对于在无限维度希尔伯特空间中的测度使用的核Stein差异进行了分析，并提出了利用傅里叶表示分离测度的方法，从而验证了KSD在实践中的有效性。 |
| [^27] | [A Control Theoretic Framework for Adaptive Gradient Optimizers in Machine Learning.](http://arxiv.org/abs/2206.02034) | 本文提出了一个通用的自适应梯度方法框架，用于解决非凸优化问题。文章将自适应梯度方法建模为状态空间框架，并利用经典控制理论中的传递函数范式提出了一种新的Adam变体，称为AdamSSM。该算法在基准机器学习任务上表现出较好的性能优势。 |
| [^28] | [Hybrid Models for Mixed Variables in Bayesian Optimization.](http://arxiv.org/abs/2206.01409) | 本文提出了一种新型的混合模型，用于混合变量贝叶斯优化，并且在搜索和代理模型阶段都具有创新之处。数值实验证明了混合模型的优越性。 |
| [^29] | [Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent DAGs with Applications.](http://arxiv.org/abs/2205.02654) | 本文提出了一种多项式时间算法，用于在马尔可夫等价类中计数和采样有向无环图。该算法解决了这一领域的长期未解决问题，并且在实验中得到验证，可以在活跃学习因果结构和因果效应识别方面实际应用。 |
| [^30] | [Black-box Selective Inference via Bootstrapping.](http://arxiv.org/abs/2203.14504) | 本论文提出了一种通过引入自举法来进行黑盒选择性推断的通用方法。通过重复生成自举数据和运行选择算法，我们能够估计选择事件的概率，并在此基础上进行条件选择性推断。这个方法适用于各种缺乏精确描述的问题。 |
| [^31] | [MMD Aggregated Two-Sample Test.](http://arxiv.org/abs/2110.15073) | 本文提出了两种新颖的基于最大均值差异（MMD）的非参数双样本核检验，并构造了一种自适应平均测试，称为MMDAgg，以解决平滑参数未知的问题。 |
| [^32] | [Anomalous Edge Detection in Edge Exchangeable Social Network Models.](http://arxiv.org/abs/2109.12727) | 本文研究了在社交网络模型中检测异常边缘的问题，并提出了一种基于边缘可交换性和一致预测理论的异常检测算法，该算法在实验中表现出卓越的性能。 |
| [^33] | [Learning Domain Invariant Representations by Joint Wasserstein Distance Minimization.](http://arxiv.org/abs/2106.04923) | 本文通过研究监督机器学习损失与联合空间的Wasserstein距离之间的关系，提出了一种学习域不变表示的方法。 |
| [^34] | [Discriminative Bayesian filtering lends momentum to the stochastic Newton method for minimizing log-convex functions.](http://arxiv.org/abs/2104.12949) | 该论文提出了一种判别贝叶斯滤波的方法，为随机牛顿法在最小化对数凸函数中提供了动力。通过考虑整个历史信息形成更新，该方法能够在迭代开始时减弱旧观测的影响。 |
| [^35] | [A method to integrate and classify normal distributions.](http://arxiv.org/abs/2012.14331) | 本文介绍了一种可以对任意参数维度下的任意域内正态分布进行积分的方法，提供了法向向量函数的相关概率密度和统计指标，同时还提供了可以对任意数量正态分布进行分类的方法和维度降低和可视化的技术。 |
| [^36] | [Generalization in Deep Learning.](http://arxiv.org/abs/1710.05468) | 本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，提出了一些新的开放问题，并讨论了研究结果的局限性。 |

# 详细

[^1]: 具有分布变化的现实世界时间序列基准数据集：全球原油价格和波动性

    Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility. (arXiv:2308.10846v1 [cs.LG])

    [http://arxiv.org/abs/2308.10846](http://arxiv.org/abs/2308.10846)

    本研究创建了COB原油基准数据集，通过将资产价格转化为波动性代理，并生成与现实世界事件相一致的上下文任务标签，这些标签能普遍提升多个预测时段上四种持续学习算法的性能。这些基准数据集有望加速金融领域中的创新。

    

    在金融领域中，缺乏带有任务标签的时间序列基准数据集阻碍了持续学习的进展。为了解决这个问题，我们提出了COB，即原油基准数据集。COB包括展示显著分布变化的30年资产价格，并基于这些分布变化生成相应的任务（即制度）标签，其中包括全球最重要的三种原油。我们的贡献包括将资产价格数据转化为波动性代理，使用期望最大化模型拟合，生成与现实世界事件相一致的上下文任务标签，并将这些标签以及通用算法公开提供。我们展示了包含这些任务标签对四种持续学习算法（包括一些最新技术）在多个预测时段上的性能普遍提升。我们希望这些基准数据集能加速创新。

    The scarcity of task-labeled time-series benchmarks in the financial domain hinders progress in continual learning. Addressing this deficit would foster innovation in this area. Therefore, we present COB, Crude Oil Benchmark datasets. COB includes 30 years of asset prices that exhibit significant distribution shifts and optimally generates corresponding task (i.e., regime) labels based on these distribution shifts for the three most important crude oils in the world. Our contributions include creating real-world benchmark datasets by transforming asset price data into volatility proxies, fitting models using expectation-maximization (EM), generating contextual task labels that align with real-world events, and providing these labels as well as the general algorithm to the public. We show that the inclusion of these task labels universally improves performance on four continual learning algorithms, some state-of-the-art, over multiple forecasting horizons. We hope these benchmarks accel
    
[^2]: 稀疏线性概念发现模型

    Sparse Linear Concept Discovery Models. (arXiv:2308.10782v1 [cs.LG])

    [http://arxiv.org/abs/2308.10782](http://arxiv.org/abs/2308.10782)

    本论文提出了一种基于对比语言图像模型和单个稀疏线性层的可解释框架，通过贝叶斯推断来实现概念之间的稀疏性，达到了比最近的CBM方法更好的准确性和解释性。

    

    最近，在安全关键场景中也大规模采用了深度神经网络(DNN)，这使得研究界的关注点转向了创造固有可解释模型。概念瓶颈模型 (CBMs) 是一种流行的方法，其中隐藏层与人类可理解的概念相连，允许对网络决策进行调查和修正。然而，CBMs通常存在以下问题：(i) 性能下降和(ii) 解释性不如预期，因为每个决策都涉及到许多概念的贡献。在这项工作中，我们提出了一种简单但极其直观的可解释框架，该框架基于对比语言图像模型和单个稀疏线性层。与其他相关方法截然不同的是，我们的框架中的稀疏性是通过基于数据驱动的伯努利分布进行的基于贝叶斯原理的概念推断实现的。正如我们在实验中所表明的那样，我们的框架不仅在准确性方面优于最近的CBM方法，而且在解释性方面也更好。

    The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from: (i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also
    
[^3]: 带背包的聚类线性上下文赌博机问题

    Clustered Linear Contextual Bandits with Knapsacks. (arXiv:2308.10722v1 [cs.LG])

    [http://arxiv.org/abs/2308.10722](http://arxiv.org/abs/2308.10722)

    本论文研究了带背包的聚类线性上下文赌博机问题，在不知道聚类成员的情况下，提供了一种实现子线性遗憾的算法，该算法只需对一个随机选择的臂子集进行一次聚类。

    

    在这项工作中，我们研究了聚类上下文赌博机问题，其中奖励和资源消耗是聚类特定线性模型的结果。臂被分成聚类，而聚类成员对算法是未知的。在一个时间段内拉动一个臂导致奖励和对多种资源的消耗，并且任何资源的总消耗超过约束意味着算法的终止。因此，最大化总奖励需要学习关于奖励和资源消耗的模型，还有聚类成员。我们提供了一个算法，在时间段数量的子线性遗憾下实现，而不需要访问所有臂。特别是，我们表明只需要对一个随机选择的臂子集进行一次聚类就足够了。为了实现这个结果，我们提供了一种复杂的组合技术，结合了计量经济学和带约束的赌博机领域的技术。

    In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.
    
[^4]: 延迟反馈的强化适应性算法中的最佳方案改进

    An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback. (arXiv:2308.10675v1 [cs.LG])

    [http://arxiv.org/abs/2308.10675](http://arxiv.org/abs/2308.10675)

    提出了一种改进的延迟反馈的强化适应性算法，通过消除先验知识需求和控制分布漂移，该算法在遗憾界限方面具有突出贡献。

    

    我们提出了一种用于具有可变延迟反馈的强化适应性算法的新方法。该算法通过消除对最大延迟$d_{\mathrm{max}}$的先验知识的需求，并在两个情景下提供更紧密的遗憾界限，改进了Masoudian等人[2022]的先前工作。算法和它的遗憾界限是基于未解决的观测次数（在行动时间观察到的数量）而不是延迟或最大延迟（只有当反馈到达时才能观察到的数量）。一个主要的贡献是基于有偏损失估计器和跳过具有过大延迟观测的新型分布漂移控制。另一个主要的贡献是证明了具有延迟反馈的强化适应性算法的复杂性是由在跳过具有过大延迟观测后的累积未解决观测次数来描述的，而不是延迟或最大延迟。

    We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. The algorithm improves on prior work by Masoudian et al. [2022] by eliminating the need in prior knowledge of the maximal delay $d_{\mathrm{max}}$ and providing tighter regret bounds in both regimes. The algorithm and its regret bounds are based on counts of outstanding observations (a quantity that is observed at action time) rather than delays or the maximal delay (quantities that are only observed when feedback arrives). One major contribution is a novel control of distribution drift, which is based on biased loss estimators and skipping of observations with excessively large delays. Another major contribution is demonstrating that the complexity of best-of-both-worlds bandits with delayed feedback is characterized by the cumulative count of outstanding observations after skipping of observations with excessively large delays, rather than the delays or the maximal delay.
    
[^5]: 深度证据学习用于贝叶斯分位回归

    Deep Evidential Learning for Bayesian Quantile Regression. (arXiv:2308.10650v1 [cs.LG])

    [http://arxiv.org/abs/2308.10650](http://arxiv.org/abs/2308.10650)

    本文提出了一种基于证据学习的深度贝叶斯分位回归模型，通过使用单一确定性前向传递模型来捕捉连续目标分布的分位数，从而实现了高效的不确定性估计。

    

    传统的不确定性量化方法计算代价高，因此希望能从单一确定性前向传递模型中获得准确的不确定性估计。然而，这很困难，因为单一前向传递模型在推断过程中不对权重进行采样，并且常常对目标分布做出假设，如假设为高斯分布。这在回归任务中会有限制，因为均值和标准差无法准确建模目标分布。本文提出了一种深度贝叶斯分位回归模型，可以在不假设高斯分布的情况下估计连续目标分布的分位数。所提出的方法基于证据学习，可以使用单一确定性前向传递模型捕捉随机与认知不确定性。因此，该方法高效且可扩展到大型模型和数据集。我们证明所提出的方法能够实现校准的不确定性估计。

    It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncerta
    
[^6]: 使用Gauß-Legendre积分加速神经ODE的训练

    Faster Training of Neural ODEs Using Gau{\ss}-Legendre Quadrature. (arXiv:2308.10644v1 [cs.LG])

    [http://arxiv.org/abs/2308.10644](http://arxiv.org/abs/2308.10644)

    本文提出了一种使用Gauß-Legendre积分加速神经ODE训练的方法，并通过训练相应的ODE和转移参数的方式扩展到SDE训练，加快了神经ODE的训练速度，特别适用于大型模型。该方法也提供了一种训练基于SDE的模型的新方式。

    

    神经ODE在生成模型和时间序列建模中表现出强大性能。然而，通过伴随方法训练它们比离散模型慢，因为需要数值解ODE。为了加速神经ODE，常用的方法是对解进行正则化。然而，这种方法可能会影响模型的表达能力；当轨迹本身很重要时，这一点尤为重要。本文提出了一种加速神经ODE训练的另一种方法。关键思想是通过使用Gauß-Legendre积分比ODE方法更快地求解积分，同时保持内存效率，加速伴随方法。我们还通过训练相应的ODE并转移参数，将这种想法扩展到使用Wong-Zakai定理训练SDE。我们的方法导致了神经ODE的快速训练，特别是对于大型模型。它还提出了一种训练基于SDE的模型的新方法。

    Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau{\ss}-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.
    
[^7]: 使用连续时间贝叶斯网络分析复杂系统中的级联行为

    Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian Networks. (arXiv:2308.10606v1 [stat.ML])

    [http://arxiv.org/abs/2308.10606](http://arxiv.org/abs/2308.10606)

    本论文提出了一种使用连续时间贝叶斯网络分析复杂系统级联行为的建模框架，能够描述事件在系统中传播并识别可能导致级联行为的系统状态。同时，该框架具有简单的图形表示和可解释的输出。

    

    事件相互作用的系统可能表现出事件在时间上聚集的级联行为。虽然级联本身可能从数据中显而易见，但理解触发它们的系统状态非常重要。为此，我们提出了一个基于连续时间贝叶斯网络（CTBNs）的建模框架，用于分析复杂系统中的级联行为。这个框架允许我们描述事件如何在系统中传播，并识别可能的守卫状态，即可能导致即将发生级联行为的系统状态。此外，CTBNs具有简单的图形表示和可解释的输出，这对于与领域专家的沟通非常重要。我们还开发了从CTBNs中提取知识的新方法，并将所提出的方法应用于一个大型工业系统中的警报数据集。

    Interacting systems of events may exhibit cascading behavior where events tend to be temporally clustered. While the cascades themselves may be obvious from the data, it is important to understand which states of the system trigger them. For this purpose, we propose a modeling framework based on continuous-time Bayesian networks (CTBNs) to analyze cascading behavior in complex systems. This framework allows us to describe how events propagate through the system and to identify likely sentry states, that is, system states that may lead to imminent cascading behavior. Moreover, CTBNs have a simple graphical representation and provide interpretable outputs, both of which are important when communicating with domain experts. We also develop new methods for knowledge extraction from CTBNs and we apply the proposed methodology to a data set of alarms in a large industrial system.
    
[^8]: 用于远程追踪灾害火灾的卫星热点数据聚类算法

    A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely. (arXiv:2308.10505v1 [cs.LG])

    [http://arxiv.org/abs/2308.10505](http://arxiv.org/abs/2308.10505)

    本文提出了一种用于远程追踪灾害火灾的卫星热点数据聚类算法，能够在空间和时间上对点进行聚类，并允许根据需要调整参数以适应不同的位置和卫星数据源。

    

    本文提出了一种时空聚类算法，并在R软件包spotoroo中实现。本研究受到2019-2020年澳大利亚灾难性火灾的影响，并借助卫星热点数据的可用性实现。该算法受到两种已有的时空聚类算法的启发，在空间上改进了点的聚类，并在连续的时间段内跟踪其运动。同时，该算法还允许根据需要调整重要参数，以适应不同的位置和卫星数据源。使用澳大利亚维多利亚州的火灾数据对算法进行了演示。

    This paper proposes a spatiotemporal clustering algorithm and its implementation in the R package spotoroo. This work is motivated by the catastrophic bushfires in Australia throughout the summer of 2019-2020 and made possible by the availability of satellite hotspot data. The algorithm is inspired by two existing spatiotemporal clustering algorithms but makes enhancements to cluster points spatially in conjunction with their movement across consecutive time periods. It also allows for the adjustment of key parameters, if required, for different locations and satellite data sources. Bushfire data from Victoria, Australia, is used to illustrate the algorithm and its use within the package.
    
[^9]: 适应性阈值启发式方法用于KPI异常检测

    Adaptive Thresholding Heuristic for KPI Anomaly Detection. (arXiv:2308.10504v1 [cs.LG])

    [http://arxiv.org/abs/2308.10504](http://arxiv.org/abs/2308.10504)

    该论文提出了一种自适应阈值启发式方法（ATH），用于时间序列KPI的异常检测。该方法通过根据数据分布的局部属性动态调整检测阈值，并适应于时间序列模式的变化，以最小化误报和应对概念漂移。

    

    在时间序列领域中，已经探索了大量的异常检测方法，然而从商业角度讲，并不是所有的异常都是我们关心的。现有的异常检测解决方案局限于某些异常检测算法，限制了其在更广泛的异常检测场景中的适用性。网络KPI（关键性能指标）往往表现出随机行为，产生统计异常，其中大部分不会对业务运营产生不利影响。因此，需要一种启发式方法来捕捉时间序列KPI中异常的商业定义。本文提出了一种自适应阈值启发式方法（ATH），通过根据数据分布的局部属性动态调整检测阈值，并适应于时间序列模式的变化。该方法基于预期的周期性和观察到的异常比例来确定阈值，以最小化误报和应对概念漂移。ATH可以与任何基础的异常检测方法结合使用。

    A plethora of outlier detectors have been explored in the time series domain, however, in a business sense, not all outliers are anomalies of interest. Existing anomaly detection solutions are confined to certain outlier detectors limiting their applicability to broader anomaly detection use cases. Network KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour producing statistical outliers, most of which do not adversely affect business operations. Thus, a heuristic is required to capture the business definition of an anomaly for time series KPI. This article proposes an Adaptive Thresholding Heuristic (ATH) to dynamically adjust the detection threshold based on the local properties of the data distribution and adapt to changes in time series patterns. The heuristic derives the threshold based on the expected periodicity and the observed proportion of anomalies minimizing false positives and addressing concept drift. ATH can be used in conjunction with any underlying s
    
[^10]: GradientCoin:一个点对点的去中心化大型语言模型

    GradientCoin: A Peer-to-Peer Decentralized Large Language Models. (arXiv:2308.10502v1 [cs.LG])

    [http://arxiv.org/abs/2308.10502](http://arxiv.org/abs/2308.10502)

    提出了一种理论设计的去中心化大型语言模型GradientCoin，类似于比特币现金系统的运作方式，解决了现有大型语言模型集中化和安全性的问题，但实施难度较大，经济上较标准比特币系统表现不佳。

    

    自2008年比特币电子现金系统提出以来，比特币已经从根本上改变了过去十年的经济系统。自2022年以来，如GPT等大型语言模型在许多现实生活任务中表现出超越人类的能力。然而，这些大型语言模型存在一些实际问题。例如，模型是集中化的，由特定单位控制。一个弱点是，如果该单位决定关闭模型，则无法再使用。第二个弱点是缺乏对这个模型背后的保证差异，因为某些不诚实的单位可能设计自己的模型并为其提供不健康的训练数据。在这项工作中，我们提出了一个纯理论设计的去中心化语言模型，其运作方式类似于比特币现金系统。然而，实施这样的系统可能会遇到各种实际困难。此外，这个新系统在经济学上不太可能比标准的比特币系统表现更好。因此，去中心化大型语言模型的动机是什么呢？

    Since 2008, after the proposal of a Bitcoin electronic cash system, Bitcoin has fundamentally changed the economic system over the last decade. Since 2022, large language models (LLMs) such as GPT have outperformed humans in many real-life tasks. However, these large language models have several practical issues. For example, the model is centralized and controlled by a specific unit. One weakness is that if that unit decides to shut down the model, it cannot be used anymore. The second weakness is the lack of guaranteed discrepancy behind this model, as certain dishonest units may design their own models and feed them unhealthy training data.  In this work, we propose a purely theoretical design of a decentralized LLM that operates similarly to a Bitcoin cash system. However, implementing such a system might encounter various practical difficulties. Furthermore, this new system is unlikely to perform better than the standard Bitcoin system in economics. Therefore, the motivation for d
    
[^11]: 使用自编码器和自动微分来重构一组时间序列中的缺失变量

    Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series. (arXiv:2308.10496v1 [cs.LG])

    [http://arxiv.org/abs/2308.10496](http://arxiv.org/abs/2308.10496)

    本文提出了一种使用自编码器和自动微分来重构一组时间序列中缺失变量的新方法。通过训练自编码器，并在该训练之后固定神经网络参数，可以实现不同输入和输出特征组合的重构。该方法在强非线性电子元件上得到了验证，对于缺失的变量有效。

    

    机器学习中现有的黑盒建模方法受到固定输入和输出特征组合的限制。本文提出了一种新的方法，用于重构一组时间序列中的缺失变量。采用常规方式训练一个自编码器，将每个特征都放在两侧，然后在该训练之后固定神经网络参数。然后，将搜索的变量定义为自编码器输入处的缺失变量，并通过自动微分进行优化。这种优化是针对可用特征损失计算进行的。通过将搜索的变量定义为缺失变量并对其进行重构，可以实现训练模型的不同输入和输出特征组合。而且，无需再次训练自编码器即可更改组合。该方法在一个强非线性电子元件的基础上进行了评估。对于四个变量中的一个缺失，该方法效果良好，甚至对于多个缺失变量也有效。

    Existing black box modeling approaches in machine learning suffer from a fixed input and output feature combination. In this paper, a new approach to reconstruct missing variables in a set of time series is presented. An autoencoder is trained as usual with every feature on both sides and the neural network parameters are fixed after this training. Then, the searched variables are defined as missing variables at the autoencoder input and optimized via automatic differentiation. This optimization is performed with respect to the available features loss calculation. With this method, different input and output feature combinations of the trained model can be realized by defining the searched variables as missing variables and reconstructing them. The combination can be changed without training the autoencoder again. The approach is evaluated on the base of a strongly nonlinear electrical component. It is working well for one of four variables missing and generally even for multiple missi
    
[^12]: 近似等变图网络

    Approximately Equivariant Graph Networks. (arXiv:2308.10436v1 [stat.ML])

    [http://arxiv.org/abs/2308.10436](http://arxiv.org/abs/2308.10436)

    本文关注于图神经网络（GNNs）的主动对称性，通过考虑信号在固定图上的学习设置，提出了一种近似的对称性概念，通过图粗化实现。这篇工作提出了一个偏差-方差公式来衡量近似对称性...

    

    图神经网络（GNNs）通常被描述为对图中的节点重新排序具有置换等变性。GNNs的这种对称性常被与欧几里得卷积神经网络（CNNs）的平移等变性比较。然而，这两种对称性本质上是不同的：CNNs的平移等变性对应于作用于图像信号的固定域的对称性（有时称为主动对称性），而在GNNs中，任何置换都作用于图信号和图域（有时描述为被动对称性）。在这项工作中，我们聚焦于GNNs的主动对称性，考虑信号在一个固定图上进行学习的情况。在这种情况下，GNNs的自然对称性是图的自同构。由于现实世界中的图往往是非对称的，我们通过形式化图粗化来放松对称性的概念，提出了一个偏差-方差公式来衡量...

    Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that qu
    
[^13]: Thompson Sampling用于多臂老虎机的实值组合纯探索

    Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit. (arXiv:2308.10238v1 [cs.LG])

    [http://arxiv.org/abs/2308.10238](http://arxiv.org/abs/2308.10238)

    这篇论文介绍了一种名为广义汤普森抽样探索算法，能够解决多臂老虎机实值组合纯探索问题中动作集合大小为指数级别的情况。

    

    我们研究了多臂老虎机的实值组合纯探索（R-CPE-MAB）问题。在R-CPE-MAB中，玩家从给定的d个随机臂中选择一个，每个臂s的奖励遵循未知分布，其平均值为μs。在每个时间步骤中，玩家拉动一个臂并观察其奖励。玩家的目标是以尽可能少的臂拉动次数来确定最优动作π* = argmaxπ∈A μTπ，其中A是有限大小的实值动作集合。之前的方法假设动作集合A的大小在d的多项式级别上。我们引入了一种名为广义汤普森抽样探索（GenTS-Explore）算法，它是第一个可以解决动作集合大小在d的指数级别上的算法。同时，我们还引入了一种新的问题相关的样本复杂性。

    We study the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown distribution with mean $\mu_s$. In each time step, a player pulls a single arm and observes its reward. The player's goal is to identify the optimal \emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in $d$. We also introduce a novel problem-dependent sample complexity 
    
[^14]: Wasserstein几何生成器用于条件分布

    Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v1 [stat.ML])

    [http://arxiv.org/abs/2308.10145](http://arxiv.org/abs/2308.10145)

    通过Wasserstein几何生成器学习条件分布，生成给定特定标签的样本。使用最优输运理论提出的方法能学习观察域的条件分布和它们之间的最优输运映射。在人脸图像数据上的实验验证了该方法的有效性。

    

    生成给定特定标签的样本需要估计条件分布。我们推导出条件分布之间Wasserstein距离的可处理的上界，以建立学习条件分布的理论基础。基于这一结果，我们提出了一种新颖的条件生成算法，其中条件分布完全由由统计距离定义的度量空间来表征。我们利用最优输运理论来提出了Wasserstein几何生成器，一种学习Wasserstein几何的新的条件生成器。所提出的方法学习观察域的条件分布和它们之间的最优输运映射。给定两个观察域标签，未观察到的中间域的条件分布位于给定的条件分布之间的Wasserstein几何中。在以光照条件为域标签的人脸图像上的实验证明了所提出方法的有效性。

    Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the \textit{Wasserstein geodesic generator}, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
    
[^15]: 用具有异质互惠的随机网络建模

    Modeling Random Networks with Heterogeneous Reciprocity. (arXiv:2308.10113v1 [stat.ML])

    [http://arxiv.org/abs/2308.10113](http://arxiv.org/abs/2308.10113)

    本文提出了一种模型，用于模拟不断增长的社交网络中多样的互惠行为。该模型考虑了用户对受欢迎用户的吸引力以及他们对链接的异质性回应。我们比较了贝叶斯和频率主义的拟合技术，并应用于Facebook留言网络的分析。

    

    互惠性，或者说个体呈现行为的趋同性，是描述社交网络中信息交流的关键指标。社交网络中的用户往往呈现不同程度的互惠行为。这种行为的差异可能表明存在以不同速率互换链接的社区。本文提出了一种方法来模拟不断增长的社交网络中多样的互惠行为。具体而言，我们提出了一种具有异质互惠性的优先连接模型，该模型模拟了用户对受欢迎用户的吸引力，以及他们对链接的异质性回应。我们比较了贝叶斯和频率主义的用于大型网络的模型拟合技术，以及计算效率高的变分替代方法。同时考虑了已知和未知社区数量的情况。我们将所提出的方法应用于分析一个Facebook留言网络，其中用户具有非均匀的互惠行为。

    Reciprocity, or the tendency of individuals to mirror behavior, is a key measure that describes information exchange in a social network. Users in social networks tend to engage in different levels of reciprocal behavior. Differences in such behavior may indicate the existence of communities that reciprocate links at varying rates. In this paper, we develop methodology to model the diverse reciprocal behavior in growing social networks. In particular, we present a preferential attachment model with heterogeneous reciprocity that imitates the attraction users have for popular users, plus the heterogeneous nature by which they reciprocate links. We compare Bayesian and frequentist model fitting techniques for large networks, as well as computationally efficient variational alternatives. Cases where the number of communities are known and unknown are both considered. We apply the presented methods to the analysis of a Facebook wallpost network where users have non-uniform reciprocal behav
    
[^16]: 通过得分匹配实现的半隐式变分推断

    Semi-Implicit Variational Inference via Score Matching. (arXiv:2308.10014v1 [stat.ML])

    [http://arxiv.org/abs/2308.10014](http://arxiv.org/abs/2308.10014)

    本文提出了一种基于得分匹配的半隐式变分推断方法SIVI-SM，该方法利用了半隐式变分家族的层次结构，并通过处理不可计算的变分密度来实现与MCMC相当的准确性，在各种贝叶斯推断任务中优于基于ELBO的SIVI方法。

    

    半隐式变分推断（SIVI）通过考虑以层次方式定义的隐式变分分布，极大地丰富了变分家族的表达能力。然而，由于变分分布的不可计算密度，当前的SIVI方法通常使用替代证据下界（ELBO）或使用昂贵的内循环MCMC运行以进行无偏ELBO的训练。在本文中，我们提出了SIVI-SM，一种基于得分匹配的替代训练目标的SIVI新方法。利用半隐式变分家族的层次结构，得分匹配目标允许使用去噪得分匹配自然处理不可计算的变分密度的最小最大形式。我们表明，SIVI-SM在各种贝叶斯推断任务中几乎与MCMC的准确性一致，并且优于基于ELBO的SIVI方法。

    Semi-implicit variational inference (SIVI) greatly enriches the expressiveness of variational families by considering implicit variational distributions defined in a hierarchical manner. However, due to the intractable densities of variational distributions, current SIVI approaches often use surrogate evidence lower bounds (ELBOs) or employ expensive inner-loop MCMC runs for unbiased ELBOs for training. In this paper, we propose SIVI-SM, a new method for SIVI based on an alternative training objective via score matching. Leveraging the hierarchical structure of semi-implicit variational families, the score matching objective allows a minimax formulation where the intractable variational densities can be naturally handled with denoising score matching. We show that SIVI-SM closely matches the accuracy of MCMC and outperforms ELBO-based SIVI methods in a variety of Bayesian inference tasks.
    
[^17]: 关于贝叶斯实验设计中期望信息增益梯度的估计

    On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design. (arXiv:2308.09888v1 [stat.ML])

    [http://arxiv.org/abs/2308.09888](http://arxiv.org/abs/2308.09888)

    该论文提出了一种估计贝叶斯实验设计中期望信息增益梯度的方法，通过结合随机梯度下降算法，实现了高效优化。具体而言，通过后验期望表示来估计与设计变量相关的梯度，并提出了UEEG-MCMC和BEEG-AP两种估计方法。这些方法在不同的实验设计问题上都表现出良好的性能。

    

    贝叶斯实验设计旨在找到贝叶斯推断的最佳实验条件，通常被描述为优化期望信息增益（EIG）。为了高效地优化EIG，往往需要梯度信息，因此估计EIG的梯度能力对于贝叶斯实验设计问题至关重要。该工作的主要目标是开发估计EIG梯度的方法，结合随机梯度下降算法，实现EIG的高效优化。具体而言，我们首先介绍了与设计变量相关的EIG梯度的后验期望表示。基于此，我们提出了两种估计EIG梯度的方法，UEEG-MCMC利用通过马尔科夫链蒙特卡洛（MCMC）生成的后验样本来估计EIG梯度，而BEEG-AP则专注于通过反复使用参数样本来实现高模拟效率。理论分析和数值实验表明，我们的方法在不同的实验设计问题上都能获得较好的性能。

    Bayesian Experimental Design (BED), which aims to find the optimal experimental conditions for Bayesian inference, is usually posed as to optimize the expected information gain (EIG). The gradient information is often needed for efficient EIG optimization, and as a result the ability to estimate the gradient of EIG is essential for BED problems. The primary goal of this work is to develop methods for estimating the gradient of EIG, which, combined with the stochastic gradient descent algorithms, result in efficient optimization of EIG. Specifically, we first introduce a posterior expected representation of the EIG gradient with respect to the design variables. Based on this, we propose two methods for estimating the EIG gradient, UEEG-MCMC that leverages posterior samples generated through Markov Chain Monte Carlo (MCMC) to estimate the EIG gradient, and BEEG-AP that focuses on achieving high simulation efficiency by repeatedly using parameter samples. Theoretical analysis and numerica
    
[^18]: 一种用于描述A/B测试中网络干扰的两部分机器学习方法

    A Two-Part Machine Learning Approach to Characterizing Network Interference in A/B Testing. (arXiv:2308.09790v1 [stat.ML])

    [http://arxiv.org/abs/2308.09790](http://arxiv.org/abs/2308.09790)

    本论文提出了一种两部分机器学习方法，用于识别和描述A/B测试中的网络干扰。通过考虑潜在的复杂网络结构和建立适合的曝光映射，该方法在合成实验和真实大规模测试中的模拟中表现优于传统方法。

    

    受网络干扰现象的影响，控制实验或"A/B测试"的可靠性通常会受到损害。为了解决这个问题，我们提出了一种基于机器学习的方法来识别和描述异质网络干扰。我们的方法考虑了潜在的复杂网络结构，并自动化了"曝光映射"确定的任务，从而解决了现有文献中的两个主要限制。我们引入了"因果网络模式"，并采用透明的机器学习模型来建立最适合反映潜在网络干扰模式的曝光映射。我们的方法通过在两个合成实验和一个涉及100-200万Instagram用户的真实大规模测试中的模拟得到了验证，表现优于传统方法，如基于设计的集群随机化和基于分析的邻域曝光映射。

    The reliability of controlled experiments, or "A/B tests," can often be compromised due to the phenomenon of network interference, wherein the outcome for one unit is influenced by other units. To tackle this challenge, we propose a machine learning-based method to identify and characterize heterogeneous network interference. Our approach accounts for latent complex network structures and automates the task of "exposure mapping'' determination, which addresses the two major limitations in the existing literature. We introduce "causal network motifs'' and employ transparent machine learning models to establish the most suitable exposure mapping that reflects underlying network interference patterns. Our method's efficacy has been validated through simulations on two synthetic experiments and a real-world, large-scale test involving 1-2 million Instagram users, outperforming conventional methods such as design-based cluster randomization and analysis-based neighborhood exposure mapping. 
    
[^19]: 带有Polyak步长和线性搜索的自适应SGD: 鲁棒收敛和方差减小

    Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction. (arXiv:2308.06058v1 [cs.LG])

    [http://arxiv.org/abs/2308.06058](http://arxiv.org/abs/2308.06058)

    本文提出了AdaSPS和AdaSLS两种新的变种算法，用于解决SGD在非插值环境下的收敛问题，并在训练超参数模型时保持线性和亚线性的收敛速度。

    

    最近提出的随机Polyak步长 (SPS) 和随机线性搜索 (SLS) 在训练超参数模型时显示出了显著的有效性。然而，在非插值环境下，这两种算法只能保证收敛到一个解的邻域，可能导致比初始猜测更差的输出结果。尽管已经提出了人为减小自适应步长的方法来解决这个问题 (Orvieto et al. [2022])，但这种方法会导致凸函数和超参数模型的收敛速度变慢。在本文中，我们做出了两个贡献：首先，我们提出了两种新的SPS和SLS变种，分别称为AdaSPS和AdaSLS，它们在非插值环境中保证收敛，并且在训练超参数模型时保持凸函数和强凸函数的亚线性和线性收敛速度。AdaSLS不需要对问题相关参数的了解，而AdaSPS只需要最优函数值的下界。

    The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al. [2022]), this approach results in slower convergence rates for convex and over-parameterized models. In this work, we make two contributions: Firstly, we propose two new variants of SPS and SLS, called AdaSPS and AdaSLS, which guarantee convergence in non-interpolation settings and maintain sub-linear and linear convergence rates for convex and strongly convex functions when training over-parameterized models. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value 
    
[^20]: 我们能否在不做任何假设的情况下，证伪Wald置信区间在双重稳健函数下的有效性？

    Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])

    [http://arxiv.org/abs/2306.10590](http://arxiv.org/abs/2306.10590)

    本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。

    

    本文提出了一种可行的版本的无假设检验方法，可否定分析师对报道的以双重机器学习(DML)估计量为中心的名义$(1-\alpha)$Wald置信区间的有效性的证明，对Rotnitzky等人所研究的双重稳健(DR)函数类的任何成员进行检验。DR函数类在经济学和生物统计学中具有广泛和核心的重要性。它严格包括两个类别，即(i)可以被写成条件期望的仿射函数期望的均方连续函数的类别，这是由Chernozhukov等人研究的，以及Robins等人所研究的类别。目前DR函数的最先进的估计值是DML估计值。$\hat{\psi}_{1}$的偏差取决于两个辅助函数$b$和$p$的估计率的乘积。最常见的是，分析师证明了

    In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
    
[^21]: 学习速率表在分布转移条件下的应用

    Learning Rate Schedules in the Presence of Distribution Shift. (arXiv:2303.15634v1 [cs.LG])

    [http://arxiv.org/abs/2303.15634](http://arxiv.org/abs/2303.15634)

    该论文提出了一种学习速率表，以在数据分布发生变化时最小化SGD在线学习的后悔，能够对分布转移具有鲁棒性，同时适用于凸损失函数和非凸损失函数。最优学习速率表通常会在数据分布转移的情况下增加，能够用于高维回归模型和神经网络。

    

    我们设计了学习速率表，以在数据分布发生变化时最小化SGD在线学习的后悔。我们通过随机微分方程的新颖分析，完全表征了在线线性回归的最优学习速率表。对于一般的凸损失函数，我们提出了新的学习速率表，对分布转移具有鲁棒性，我们给出了只有常数差异的后悔上下界。对于非凸损失函数，我们基于估计模型的梯度范数定义了一种后悔概念，并提出了一种学习时间表，以最小化总预期后悔的上限。直观地说，我们预计损失领域的变化需要更多的探索，我们证实了最优学习速率表通常会在数据分布转移的情况下增加。最后，我们提供了针对高维回归模型和神经网络的实验，以说明这些学习速率表的应用。

    We design learning rate schedules that minimize regret for SGD-based online learning in the presence of a changing data distribution. We fully characterize the optimal learning rate schedule for online linear regression via a novel analysis with stochastic differential equations. For general convex loss functions, we propose new learning rate schedules that are robust to distribution shift, and we give upper and lower bounds for the regret that only differ by constants. For non-convex loss functions, we define a notion of regret based on the gradient norm of the estimated models and propose a learning schedule that minimizes an upper bound on the total expected regret. Intuitively, one expects changing loss landscapes to require more exploration, and we confirm that optimal learning rate schedules typically increase in the presence of distribution shift. Finally, we provide experiments for high-dimensional regression models and neural networks to illustrate these learning rate schedule
    
[^22]: 用鲁棒交替最小化方法在几乎线性时间内完成低秩矩阵补全

    Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time. (arXiv:2302.11068v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11068](http://arxiv.org/abs/2302.11068)

    本论文提出了一种在几乎线性时间内用鲁棒交替最小化方法完成低秩矩阵补全的方法，并证明了观察几乎线性数量的条目即可恢复矩阵$M$，此方法克服了交替最小化方法需要精确计算的限制，更符合实际实现中对效率的要求。

    

    给定一个矩阵$M\in \mathbb{R}^{m\times n}$，低秩矩阵补全问题要求我们通过只观察一组指定的条目$\Omega\subseteq [m]\times [n]$来找到$M$的秩为$k$的近似$UV^\top$，其中$U\in \mathbb{R}^{m\times k}$，$V\in \mathbb{R}^{n\times k}$。本文主要研究了一种被广泛使用的方法--交替最小化框架。Jain、Netrapalli和Sanghavi~\cite{jns13}证明了如果$M$的行和列是不相干的，那么交替最小化方法可以通过观察几乎线性数量的条目可靠地恢复矩阵$M$。虽然样本复杂度之后被改进~\cite{glz17}，但交替最小化步骤要求精确计算。这阻碍了更高效算法的开发，并未描述交替最小化的实际实现，其中更新通常是近似执行，以提高效率。

    Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in \mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a few entries specified by a set of entries $\Omega\subseteq [m]\times [n]$. In particular, we examine an approach that is widely used in practice -- the alternating minimization framework. Jain, Netrapalli and Sanghavi~\cite{jns13} showed that if $M$ has incoherent rows and columns, then alternating minimization provably recovers the matrix $M$ by observing a nearly linear in $n$ number of entries. While the sample complexity has been subsequently improved~\cite{glz17}, alternating minimization steps are required to be computed exactly. This hinders the development of more efficient algorithms and fails to depict the practical implementation of alternating minimization, where the updates are usually performed approximately in favor of efficiency.  In this p
    
[^23]: 基于混合谱方法和谐振子的非可分离协方差核的时空高斯过程研究

    Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes based on a Hybrid Spectral Method and the Harmonic Oscillator. (arXiv:2302.09580v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09580](http://arxiv.org/abs/2302.09580)

    该论文提出了一种基于混合谱方法和谐振子的非可分离协方差核的时空高斯过程研究，通过物理论证推导出一类新型的非可分离协方差核，能更好地捕捉观测到的时空相关性。

    

    高斯过程提供了一个灵活的非参数框架，用于近似高维空间中的函数。协方差核是高斯过程的主要引擎，包含了预测分布的相关性。对于具有时空数据集的应用，合适的核应该建模联合的时空依赖关系。可分离的时空协方差核提供了简单和计算效率较高的方案。然而，非可分离核包含了更好地捕捉观测到的相关性的时空交互作用。大多数具有显式表达式的非可分离核是基于数学考虑（可允许条件）而非基于第一原理导出的。我们提出了一种基于物理论证的混合谱方法来生成协方差核。我们使用这种方法推导了一类新型的物理动机的非可分离协方差核，它们的根源来自随机线性...

    Gaussian processes provide a flexible, non-parametric framework for the approximation of functions in high-dimensional spaces. The covariance kernel is the main engine of Gaussian processes, incorporating correlations that underpin the predictive distribution. For applications with spatiotemporal datasets, suitable kernels should model joint spatial and temporal dependence. Separable space-time covariance kernels offer simplicity and computational efficiency. However, non-separable kernels include space-time interactions that better capture observed correlations. Most non-separable kernels that admit explicit expressions are based on mathematical considerations (admissibility conditions) rather than first-principles derivations. We present a hybrid spectral approach for generating covariance kernels which is based on physical arguments. We use this approach to derive a new class of physically motivated, non-separable covariance kernels which have their roots in the stochastic, linear, 
    
[^24]: 探索可解释的土地覆盖映射：一种基于反事实的策略

    Towards Explainable Land Cover Mapping: a Counterfactual-based Strategy. (arXiv:2301.01520v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01520](http://arxiv.org/abs/2301.01520)

    本论文提出了一种基于反事实的策略，用于土地覆盖分类任务中的卫星图像时间序列。该方法具有灵活性，能发现土地覆盖类别之间的有趣信息关系，同时通过鼓励时间连续的扰动来得到更稀疏且可解释的解决方案。

    

    反事实解释是提高深度学习模型解释性的新兴工具。在给定样本的情况下，这些方法寻找并向用户显示决策边界上类似的样本。在本文中，我们提出了一种用于土地覆盖分类任务的多类别设置中的卫星图像时间序列的对抗生成反事实方法。该方法的一个独特特点是在给定反事实解释的情况下对目标类别没有先验假设。这种固有的灵活性允许发现土地覆盖类别之间的有趣信息关系。另一个特点是鼓励反事实与原始样本之间仅在一个小而紧凑的时间段内有所不同。这些时间连续的扰动允许得到更稀疏且因此更可解释的解决方案。此外，通过强制生成的反事实解释的合理性/真实性。

    Counterfactual explanations are an emerging tool to enhance interpretability of deep learning models. Given a sample, these methods seek to find and display to the user similar samples across the decision boundary. In this paper, we propose a generative adversarial counterfactual approach for satellite image time series in a multi-class setting for the land cover classification task. One of the distinctive features of the proposed approach is the lack of prior assumption on the targeted class for a given counterfactual explanation. This inherent flexibility allows for the discovery of interesting information on the relationship between land cover classes. The other feature consists of encouraging the counterfactual to differ from the original sample only in a small and compact temporal segment. These time-contiguous perturbations allow for a much sparser and, thus, interpretable solution. Furthermore, plausibility/realism of the generated counterfactual explanations is enforced via the
    
[^25]: Markov线性随机逼近中的偏差和外推问题

    Bias and Extrapolation in Markovian Linear Stochastic Approximation with Constant Stepsizes. (arXiv:2210.00953v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.00953](http://arxiv.org/abs/2210.00953)

    本研究研究了线性随机逼近中的偏差和外推问题。我们证明了在恒定步长和Markov数据的情况下，LSA迭代会收敛到唯一的极限和稳定分布，并建立了非渐进的几何收敛速度。我们还发现，这个极限的偏差与步长成比例，直至更高阶项。在可逆链的情况下，我们还探讨了偏差与Markov数据的混合时间之间的关系。

    

    我们考虑了具有恒定步长和Markov数据的线性随机逼近（LSA）。将数据和LSA迭代的联合过程视为时间齐次Markov链，我们证明其在Wasserstein距离下收敛到唯一的极限和稳定分布，并建立了非渐进的几何收敛速度。此外，我们表明，该极限的偏差向量可以通过步长展开为无限级数。因此，偏差与步长成比例，直至更高阶项。这个结果与i.i.d.数据下的LSA形成对比，其中偏差为零。在可逆链设置下，我们提供了偏差与Markov数据的混合时间之间关系的一般特征，建立了它们大致成正比的结论。虽然Polyak-Ruppert尾平均减少了LSA迭代的方差，但并不影响偏差。以上特征使我们能够展示

    We consider Linear Stochastic Approximation (LSA) with a constant stepsize and Markovian data. Viewing the joint process of the data and LSA iterate as a time-homogeneous Markov chain, we prove its convergence to a unique limiting and stationary distribution in Wasserstein distance and establish non-asymptotic, geometric convergence rates. Furthermore, we show that the bias vector of this limit admits an infinite series expansion with respect to the stepsize. Consequently, the bias is proportional to the stepsize up to higher order terms. This result stands in contrast with LSA under i.i.d. data, for which the bias vanishes. In the reversible chain setting, we provide a general characterization of the relationship between the bias and the mixing time of the Markovian data, establishing that they are roughly proportional to each other.  While Polyak-Ruppert tail-averaging reduces the variance of the LSA iterates, it does not affect the bias. The above characterization allows us to show 
    
[^26]: 用于无限维希尔伯特空间的测度的核Stein差异的傅里叶表示及其在拟合优度检验中的应用

    A Fourier representation of kernel Stein discrepancy with application to Goodness-of-Fit tests for measures on infinite dimensional Hilbert spaces. (arXiv:2206.04552v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2206.04552](http://arxiv.org/abs/2206.04552)

    本文对于在无限维度希尔伯特空间中的测度使用的核Stein差异进行了分析，并提出了利用傅里叶表示分离测度的方法，从而验证了KSD在实践中的有效性。

    

    核Stein差异(KSD)是一种广泛使用的基于核的测度差异指标，常用于将用户从候选测度中收集的样本与指定的目标测度进行比较的场景。KSD已经在拟合优度检验、参数推断、MCMC输出评估和生成模型等多个领域得到应用。然而，目前该方法仅限于有限维数据。本文提供了KSD在可分离希尔伯特空间中的首个分析，例如函数数据。主要结果是通过将测度方程理论与核方法相结合，得到了KSD的新颖傅里叶表示。这使得我们能够证明KSD能够区分测度，因此在实践中是有效的。此外，我们的结果通过解耦核函数与Stein算子的效应，提高了KSD的可解释性。

    Kernel Stein discrepancy (KSD) is a widely used kernel-based measure of discrepancy between probability measures. It is often employed in the scenario where a user has a collection of samples from a candidate probability measure and wishes to compare them against a specified target probability measure. KSD has been employed in a range of settings including goodness-of-fit testing, parametric inference, MCMC output assessment and generative modelling. However, so far the method has been restricted to finite-dimensional data. We provide the first analysis of KSD in the generality of data lying in a separable Hilbert space, for example functional data. The main result is a novel Fourier representation of KSD obtained by combining the theory of measure equations with kernel methods. This allows us to prove that KSD can separate measures and thus is valid to use in practice. Additionally, our results improve the interpretability of KSD by decoupling the effect of the kernel and Stein operat
    
[^27]: 一个控制理论框架用于机器学习中的自适应梯度优化器

    A Control Theoretic Framework for Adaptive Gradient Optimizers in Machine Learning. (arXiv:2206.02034v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02034](http://arxiv.org/abs/2206.02034)

    本文提出了一个通用的自适应梯度方法框架，用于解决非凸优化问题。文章将自适应梯度方法建模为状态空间框架，并利用经典控制理论中的传递函数范式提出了一种新的Adam变体，称为AdamSSM。该算法在基准机器学习任务上表现出较好的性能优势。

    

    自适应梯度方法已经在优化深度神经网络中变得流行起来，最近的例子包括AdaGrad和Adam。虽然Adam通常收敛更快，但是Adam的一些变体，比如AdaBelief算法，已经被提出来增强Adam与经典随机梯度方法相比的泛化能力较差的问题。本文提出了一个通用的自适应梯度方法框架用于解决非凸优化问题。我们首先在状态空间框架中建模自适应梯度方法，这使得我们能够简化自适应优化器（如AdaGrad、Adam和AdaBelief）的收敛证明。然后，我们利用经典控制理论中的传递函数范式，提出了一种新的Adam变体，称为AdamSSM。我们在传递函数中从平方梯度到二阶矩估计中添加了一个合适的极点-零点对。我们证明了所提出的AdamSSM算法的收敛性。在基准机器学习任务上的应用展示了该算法的性能优势。

    Adaptive gradient methods have become popular in optimizing deep neural networks; recent examples include AdaGrad and Adam. Although Adam usually converges faster, variations of Adam, for instance, the AdaBelief algorithm, have been proposed to enhance Adam's poor generalization ability compared to the classical stochastic gradient method. This paper develops a generic framework for adaptive gradient methods that solve non-convex optimization problems. We first model the adaptive gradient methods in a state-space framework, which allows us to present simpler convergence proofs of adaptive optimizers such as AdaGrad, Adam, and AdaBelief. We then utilize the transfer function paradigm from classical control theory to propose a new variant of Adam, coined AdamSSM. We add an appropriate pole-zero pair in the transfer function from squared gradients to the second moment estimate. We prove the convergence of the proposed AdamSSM algorithm. Applications on benchmark machine learning tasks of 
    
[^28]: 混合变量贝叶斯优化中的混合模型

    Hybrid Models for Mixed Variables in Bayesian Optimization. (arXiv:2206.01409v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.01409](http://arxiv.org/abs/2206.01409)

    本文提出了一种新型的混合模型，用于混合变量贝叶斯优化，并且在搜索和代理模型阶段都具有创新之处。数值实验证明了混合模型的优越性。

    

    本文提出了一种新型的混合模型，用于处理混合变量贝叶斯优化中的定量（连续和整数）和定性（分类）类型。我们的混合模型将蒙特卡洛树搜索结构（MCTS）用于分类变量，并将高斯过程（GP）用于连续变量。在搜索阶段中，我们将频率派的上置信度树搜索（UCTS）和贝叶斯狄利克雷搜索策略进行对比，展示了树结构在贝叶斯优化中的融合。在代理模型阶段，我们的创新之处在于针对混合变量贝叶斯优化的在线核选择。我们的创新，包括动态核选择、独特的UCTS（hybridM）和贝叶斯更新策略（hybridD），将我们的混合模型定位为混合变量代理模型的进步。数值实验凸显了混合模型的优越性，凸显了它们的潜力。

    This paper presents a new type of hybrid models for Bayesian optimization (BO) adept at managing mixed variables, encompassing both quantitative (continuous and integer) and qualitative (categorical) types. Our proposed new hybrid models merge Monte Carlo Tree Search structure (MCTS) for categorical variables with Gaussian Processes (GP) for continuous ones. Addressing efficiency in searching phase, we juxtapose the original (frequentist) upper confidence bound tree search (UCTS) and the Bayesian Dirichlet search strategies, showcasing the tree architecture's integration into Bayesian optimization. Central to our innovation in surrogate modeling phase is online kernel selection for mixed-variable BO. Our innovations, including dynamic kernel selection, unique UCTS (hybridM) and Bayesian update strategies (hybridD), position our hybrid models as an advancement in mixed-variable surrogate models. Numerical experiments underscore the hybrid models' superiority, highlighting their potentia
    
[^29]: 多项式时间算法在计数和采样马尔可夫等价的有向无环图中的应用

    Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent DAGs with Applications. (arXiv:2205.02654v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.02654](http://arxiv.org/abs/2205.02654)

    本文提出了一种多项式时间算法，用于在马尔可夫等价类中计数和采样有向无环图。该算法解决了这一领域的长期未解决问题，并且在实验中得到验证，可以在活跃学习因果结构和因果效应识别方面实际应用。

    

    在图形因果分析中，从马尔可夫等价类中计数和采样有向无环图是基本任务。本文展示了这些任务可以在多项式时间内完成，解决了这一领域的长期未解决问题。我们的算法有效且易于实现。正如我们在实验中展示的那样，这些突破使得在活跃学习因果结构和因果效应识别方面，对于马尔可夫等价类，原本认为不可行的策略实际可应用。

    Counting and sampling directed acyclic graphs from a Markov equivalence class are fundamental tasks in graphical causal analysis. In this paper we show that these tasks can be performed in polynomial time, solving a long-standing open problem in this area. Our algorithms are effective and easily implementable. As we show in experiments, these breakthroughs make thought-to-be-infeasible strategies in active learning of causal structures and causal effect identification with regard to a Markov equivalence class practically applicable.
    
[^30]: 通过引入自举法进行黑盒选择性推断

    Black-box Selective Inference via Bootstrapping. (arXiv:2203.14504v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2203.14504](http://arxiv.org/abs/2203.14504)

    本论文提出了一种通过引入自举法来进行黑盒选择性推断的通用方法。通过重复生成自举数据和运行选择算法，我们能够估计选择事件的概率，并在此基础上进行条件选择性推断。这个方法适用于各种缺乏精确描述的问题。

    

    条件选择性推断需要对选择事件进行精确描述，但通常除了一些示例（如套索法）外，很难获得。本研究通过引入一种通用方法来估计选择事件，从而促进在选择事件条件下的可行推断。该方法通过重复生成自举数据并在新数据集上运行选择算法来进行。利用选择算法的输出，我们可以将选择概率估计为特定摘要统计量的函数。这导致了在选择事件条件下的数据分布的估计，为条件选择性推断奠定了基础。我们提供了一个理论保证，假设相关统计量的渐近正常性和选择概率的准确估计。通过多种缺乏精确描述的问题，我们证明了所提出的方法的适用性。

    Conditional selective inference requires an exact characterization of the selection event, which is often unavailable except for a few examples like the lasso. This work addresses this challenge by introducing a generic approach to estimate the selection event, facilitating feasible inference conditioned on the selection event. The method proceeds by repeatedly generating bootstrap data and running the selection algorithm on the new datasets. Using the outputs of the selection algorithm, we can estimate the selection probability as a function of certain summary statistics. This leads to an estimate of the distribution of the data conditioned on the selection event, which forms the basis for conditional selective inference. We provide a theoretical guarantee assuming both asymptotic normality of relevant statistics and accurate estimation of the selection probability. The applicability of the proposed method is demonstrated through a variety of problems that lack exact characterizations
    
[^31]: MMD聚合双样本检验

    MMD Aggregated Two-Sample Test. (arXiv:2110.15073v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.15073](http://arxiv.org/abs/2110.15073)

    本文提出了两种新颖的基于最大均值差异（MMD）的非参数双样本核检验，并构造了一种自适应平均测试，称为MMDAgg，以解决平滑参数未知的问题。

    

    我们提出了两种新颖的基于最大均值差异（MMD）的非参数双样本核检验。首先，对于固定的核，我们使用排列或野蛮自举（wild bootstrap）构造了一个MMD检验，这两种流行的数值程序可确定测试阈值。我们证明这个测试可以在非渐近情况下控制I型错误的概率。因此，即使在小样本情况下，它仍然保持良好的校准性，这与以前的MMD测试不同，前者只能在渐近意义下保证正确的测试水平。当密度差异在Sobolev球中时，我们证明了我们的MMD检验在特定的核函数下是最优的，该核函数依赖于Sobolev球的平滑参数。在实践中，这个参数是未知的，因此不能使用具有特定核的最优MMD检验。为了解决这个问题，我们构造了一个自适应平均测试，称为MMDAgg。测试功率在Sobolev球的平滑参数上最大化。

    We propose two novel nonparametric two-sample kernel tests based on the Maximum Mean Discrepancy (MMD). First, for a fixed kernel, we construct an MMD test using either permutations or a wild bootstrap, two popular numerical procedures to determine the test threshold. We prove that this test controls the probability of type I error non-asymptotically. Hence, it can be used reliably even in settings with small sample sizes as it remains well-calibrated, which differs from previous MMD tests which only guarantee correct test level asymptotically. When the difference in densities lies in a Sobolev ball, we prove minimax optimality of our MMD test with a specific kernel depending on the smoothness parameter of the Sobolev ball. In practice, this parameter is unknown and, hence, the optimal MMD test with this particular kernel cannot be used. To overcome this issue, we construct an aggregated test, called MMDAgg, which is adaptive to the smoothness parameter. The test power is maximised ove
    
[^32]: 在边缘可交换的社交网络模型中的异常边缘检测

    Anomalous Edge Detection in Edge Exchangeable Social Network Models. (arXiv:2109.12727v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2109.12727](http://arxiv.org/abs/2109.12727)

    本文研究了在社交网络模型中检测异常边缘的问题，并提出了一种基于边缘可交换性和一致预测理论的异常检测算法，该算法在实验中表现出卓越的性能。

    

    本文研究了在模拟社交网络的有向图中检测异常边缘。我们利用边缘可交换性作为鉴别异常边缘和正常边缘的标准。然后我们基于一致预测理论提出了一种异常检测器；该检测器具有保证的误判率上界。在数值实验中，我们展示了所提算法相对于基准方法的卓越性能。

    This paper studies detecting anomalous edges in directed graphs that model social networks. We exploit edge exchangeability as a criterion for distinguishing anomalous edges from normal edges. Then we present an anomaly detector based on conformal prediction theory; this detector has a guaranteed upper bound for false positive rate. In numerical experiments, we show that the proposed algorithm achieves superior performance to baseline methods.
    
[^33]: 通过联合Wasserstein距离最小化学习域不变表示

    Learning Domain Invariant Representations by Joint Wasserstein Distance Minimization. (arXiv:2106.04923v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.04923](http://arxiv.org/abs/2106.04923)

    本文通过研究监督机器学习损失与联合空间的Wasserstein距离之间的关系，提出了一种学习域不变表示的方法。

    

    实际应用中，训练数据中的领域偏移很常见，例如数据来自不同的来源。理想情况下，机器学习模型应该在不考虑这些领域偏移的情况下表现良好，例如通过学习一个域不变表示。然而，常见的机器学习损失函数对模型在不同领域上的一致表现没有强有力的保障，特别是模型在某个领域上的表现是否是以损害其他领域表现为代价的。本文建立了这个问题的新的理论基础，通过提出经典监督机器学习损失和联合空间（表示空间和输出空间）中的Wasserstein距离之间的一组数学关系。我们证明分类或回归损失与GAN类型的领域判别器结合时形成了真实Wasserstein距离的上界。这意味着更不变的表示形式。

    Domain shifts in the training data are common in practical applications of machine learning; they occur for instance when the data is coming from different sources. Ideally, a ML model should work well independently of these shifts, for example, by learning a domain-invariant representation. However, common ML losses do not give strong guarantees on how consistently the ML model performs for different domains, in particular, whether the model performs well on a domain at the expense of its performance on another domain. In this paper, we build new theoretical foundations for this problem, by contributing a set of mathematical relations between classical losses for supervised ML and the Wasserstein distance in joint space (i.e. representation and output space). We show that classification or regression losses, when combined with a GAN-type discriminator between domains, form an upper-bound to the true Wasserstein distance between domains. This implies a more invariant representation and
    
[^34]: 判别贝叶斯滤波为随机牛顿法在最小化对数凸函数中提供动力

    Discriminative Bayesian filtering lends momentum to the stochastic Newton method for minimizing log-convex functions. (arXiv:2104.12949v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2104.12949](http://arxiv.org/abs/2104.12949)

    该论文提出了一种判别贝叶斯滤波的方法，为随机牛顿法在最小化对数凸函数中提供了动力。通过考虑整个历史信息形成更新，该方法能够在迭代开始时减弱旧观测的影响。

    

    为了最小化一组对数凸函数的平均值，随机牛顿法通过对完整目标函数的梯度和海森矩阵进行子采样版本的迭代更新其估计值。我们将这个优化问题置于一种具有判别性观测过程的潜在状态空间模型的顺序贝叶斯推断背景中。应用贝叶斯滤波可以得到一种新的优化算法，在形成更新时考虑了梯度和海森矩阵的整个历史。我们建立了基于矩阵的条件，在这些条件下，旧观测的影响随时间减弱，类似于Polyak的重球动力。通过一个示例展示了我们方法的各个方面，并回顾了随机牛顿法的其他相关创新。

    To minimize the average of a set of log-convex functions, the stochastic Newton method iteratively updates its estimate using subsampled versions of the full objective's gradient and Hessian. We contextualize this optimization problem as sequential Bayesian inference on a latent state-space model with a discriminatively-specified observation process. Applying Bayesian filtering then yields a novel optimization algorithm that considers the entire history of gradients and Hessians when forming an update. We establish matrix-based conditions under which the effect of older observations diminishes over time, in a manner analogous to Polyak's heavy ball momentum. We illustrate various aspects of our approach with an example and review other relevant innovations for the stochastic Newton method.
    
[^35]: 一种整合和分类正态分布的方法

    A method to integrate and classify normal distributions. (arXiv:2012.14331v8 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2012.14331](http://arxiv.org/abs/2012.14331)

    本文介绍了一种可以对任意参数维度下的任意域内正态分布进行积分的方法，提供了法向向量函数的相关概率密度和统计指标，同时还提供了可以对任意数量正态分布进行分类的方法和维度降低和可视化的技术。

    

    单变量和多变量正态概率分布在模拟不确定性决策中被广泛使用。计算这些模型的性能需要在特定区域内对这些分布进行积分，这在不同的模型中可以有很大的差异。除了一些特殊情况，目前不存在通用的分析表达式、标准数值方法或软件来计算这些积分。本文提供了数学结果和开源软件，可以提供以下内容：（i）任意参数维度下任意域内法向的概率，（ii）法向向量函数的概率密度、累积分布和逆累积分布，（iii）任意数量正态分布之间的分类误差、贝叶斯最优辨别指数以及其与工作特征曲线的关系，（iv）此类问题的维度降低和可视化，以及（v）对于给定数据这些方法的可靠性测试。我们通过几个具体的例子，包括金融、生物和心理学来演示这些功能。

    Univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. Computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. Besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. Here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the Bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. We demonstrate these
    
[^36]: 深度学习的泛化问题

    Generalization in Deep Learning. (arXiv:1710.05468v8 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1710.05468](http://arxiv.org/abs/1710.05468)

    本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，提出了一些新的开放问题，并讨论了研究结果的局限性。

    

    本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，回应了文献中的一个开放问题。我们还讨论了提供深度学习非虚空泛化保证的方法。基于理论观察，我们提出了一些新的开放问题，并讨论了我们研究结果的局限性。

    This paper provides theoretical insights into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, responding to an open question in the literature. We also discuss approaches to provide non-vacuous generalization guarantees for deep learning. Based on theoretical observations, we propose new open problems and discuss the limitations of our results.
    

