# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Novel Approach in Solving Stochastic Generalized Linear Regression via Nonconvex Programming.](http://arxiv.org/abs/2401.08488) | 通过非凸规划技术，利用聚类和分位数估计的方法解决了随机广义线性回归模型，并在各种指标上表现优于传统模型。 |
| [^2] | [Statistical inference for pairwise comparison models.](http://arxiv.org/abs/2401.08463) | 本论文通过建立极大似然估计量的渐近正态性结果，填补了配对比较模型中统计推断的空白，为各种配对比较模型提供了统一的方法，超越了Bradley-Terry模型，为实践者提供了坚实的理论保证。 |
| [^3] | [Sparse PCA with False Discovery Rate Controlled Variable Selection.](http://arxiv.org/abs/2401.08375) | 该论文提出了一种通过可控的误发现率（FDR）驱动的稀疏PCA方法，在不需要调整稀疏参数的情况下，实现了对加载向量的自动选择，从而解决了传统稀疏PCA方法容易选择不相关变量的问题。 |
| [^4] | [Causal Machine Learning for Moderation Effects.](http://arxiv.org/abs/2401.08290) | 本文提出了一种新的参数，平衡群体平均处理效应（BGATE），用于解释处理在群体间的效应差异，该参数基于因果机器学习方法，对离散处理进行估计。通过比较两个BGATE的差异，能更好地分析处理的异质性。 |
| [^5] | [Statistical Test for Attention Map in Vision Transformer.](http://arxiv.org/abs/2401.08169) | 本研究提出了一种Vision Transformer中注意力图的统计检验方法，可以将注意力作为可靠的定量证据指标用于决策，并通过p值进行统计显著性量化。 |
| [^6] | [Fundamental limits of community detection from multi-view data: multi-layer, dynamic and partially labeled block models.](http://arxiv.org/abs/2401.08167) | 该论文通过统一的理论框架研究了多视角数据中的社区检测问题，并提取出了在不同模型下社区恢复的基本阈值。 |
| [^7] | [Differentially Private Sliced Inverse Regression: Minimax Optimality and Algorithm.](http://arxiv.org/abs/2401.08150) | 本文提出了针对充足维度减少中的隐私问题的最佳差分隐私算法，并在低维和高维设置下建立了不同ially private 切片逆回归的下界。通过仿真和真实数据分析验证了这些算法的有效性。 |
| [^8] | [Contextual Bandits with Stage-wise Constraints.](http://arxiv.org/abs/2401.08016) | 本研究探讨了具有阶段约束的上下文赌博机问题，并提出了一种基于上限置信区间的算法和相应的遗憾上界。通过使用不同的缩放因子来平衡探索和约束满足，我们的算法可以适应高概率和期望设置，并在多个约束情况下得到了扩展。 |
| [^9] | [Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs.](http://arxiv.org/abs/2401.07961) | 这项研究将概率Lambert问题与最优质量传输、Schr\"odinger桥和反应-扩散偏微分方程等领域连接起来，从而解决了概率Lambert问题的解的存在和唯一性，并提供了数值求解的方法。 |
| [^10] | [Conformal Approach To Gaussian Process Surrogate Evaluation With Coverage Guarantees.](http://arxiv.org/abs/2401.07733) | 本文提出了一种使用高斯过程构建适应性交叉均匀预测区间的方法，解决了先验适合度不恰当的问题，并且所得到的预测区间具有贝叶斯可信度集的自适应性和与代理模型的局部逼近误差的相关性。 |
| [^11] | [Efficient Nonparametric Tensor Decomposition for Binary and Count Data.](http://arxiv.org/abs/2401.07711) | 我们提出了 ENTED，一个适用于二元和计数张量的高效非参数张量分解方法，通过使用非参数高斯过程来替代传统的多线性结构，并利用增强技术建立共轭模型，解决了处理复杂实际数据集的问题。 |
| [^12] | [Stochastic optimization with arbitrary recurrent data sampling.](http://arxiv.org/abs/2401.07694) | 这篇论文研究了一种随机优化算法，证明了对于非凸、可能不光滑的目标函数，在一般的经常性抽样方案下，可以以最佳速率收敛；同时指出了收敛速度与"经常性的速度"之间的关系。 |
| [^13] | [Cost-sensitive Feature Selection for Support Vector Machines.](http://arxiv.org/abs/2401.07627) | 该论文提出了一种针对支持向量机的成本敏感特征选择方法，通过最小化所选特征的数量来适应误分类成本的不对称性。 |
| [^14] | [RedEx: Beyond Fixed Representation Methods via Convex Optimization.](http://arxiv.org/abs/2401.07606) | 本文提出了一种名为RedEx的新架构，通过凸优化方法学习神经网络无法学习的目标函数，具有优化保证。 |
| [^15] | [Efficient Frameworks for Generalized Low-Rank Matrix Bandit Problems.](http://arxiv.org/abs/2401.07298) | 本文提出了一种高效的框架来解决广义低秩矩阵多臂赌博问题，在计算和理论上克服了现有算法的限制，通过使用Stein的方法和正则化思想对子空间进行估计，以及通过一种新的排除思想进一步提高了效率。 |
| [^16] | [Use of Prior Knowledge to Discover Causal Additive Models with Unobserved Variables and its Application to Time Series Data.](http://arxiv.org/abs/2401.07231) | 本文提出了两种用于具有未观测变量的因果可加模型（CAM-UV）的方法，并扩展了这些方法以应用于时间序列数据。这些方法利用先验知识进行高效因果发现，并具有对因果关系顺序的特殊处理。 |
| [^17] | [Probabilistic Reduced-Dimensional Vector Autoregressive Modeling with Oblique Projections.](http://arxiv.org/abs/2401.07206) | 本论文提出了一种概率降维向量自回归（PredVAR）模型，通过斜投影方法从高维噪声数据中提取低维动态信息，并通过迭代的算法更新潜在动态和最佳斜投影的估计，得到具有排序预测能力的动态潜变量和与外部投影模型一致的显式潜在VAR模型。 |
| [^18] | [A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models.](http://arxiv.org/abs/2401.07187) | 该论文综述了深度学习的统计理论，包括近似方法、训练动态和生成模型。在非参数框架中，结果揭示了神经网络过度风险的快速收敛速率，以及如何通过梯度方法训练网络以找到良好的泛化解决方案。 |
| [^19] | [On the (In)Compatibility between Group Fairness and Individual Fairness.](http://arxiv.org/abs/2401.07174) | 论文研究了最优统计平等解和个体公平之间的兼容性，提出了充分条件，并分析了解决冲突的方法。 |
| [^20] | [Hebbian Learning from First Principles.](http://arxiv.org/abs/2401.07110) | 本文从第一原理中得到了赫布学习的明确表达式，并证明了这些学习规则在大数据极限下收敛到原始的存储方案。 |
| [^21] | [An ADRC-Incorporated Stochastic Gradient Descent Algorithm for Latent Factor Analysis.](http://arxiv.org/abs/2401.07012) | 本文提出了一种将ADRC融入到随机梯度下降算法中的潜在因子分析方法，通过改进学习误差的计算方法，提高了模型的收敛速度和准确性。 |
| [^22] | [Modeling Latent Selection with Structural Causal Models.](http://arxiv.org/abs/2401.06925) | 本文介绍了一种在结构因果模型中对潜在选择进行建模的方法，并展示了它如何帮助进行因果推理任务，包括处理选择偏差。 |
| [^23] | [Open RAN LSTM Traffic Prediction and Slice Management using Deep Reinforcement Learning.](http://arxiv.org/abs/2401.06922) | 本文提出了一种使用深度强化学习进行Open RAN LSTM流量预测和切片管理的方法，在保持服务质量的前提下，通过利用分布式单元的异构经验和预测模型的辅助信息，显著改善了网络性能。 |
| [^24] | [Deep Learning With DAGs.](http://arxiv.org/abs/2401.06864) | 本文介绍了一种使用深度神经网络来对因果图进行实证评估的新方法。这种方法称为因果图标准化流(cGNFs)，通过使用DAGs表示理论，并避免功能形式的假设，来更准确地捕捉因果系统的复杂性。 |
| [^25] | [A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models.](http://arxiv.org/abs/2401.06740) | 这份论文介绍了一种用于定价跳跃扩散模型下欧式篮式期权的深度学习方法，采用了隐式-显式最小移动方法以及残差型人工神经网络逼近，并通过稀疏网格高斯-埃尔米特逼近和基于ANN的高维专用求积规则来离散化积分运算符。 |
| [^26] | [Machine learning a fixed point action for SU(3) gauge theory with a gauge equivariant convolutional neural network.](http://arxiv.org/abs/2401.06481) | 本研究使用具有精确规范不变性的卷积神经网络，通过机器学习方法找到了四维SU（3）规范理论的优秀固定点作用的参数化方法，为未来的蒙特卡洛模拟打下了必要的基础。 |
| [^27] | [A tree-based varying coefficient model.](http://arxiv.org/abs/2401.05982) | 本论文介绍了一种基于树的可变系数模型，使用循环梯度提升机进行建模，实现了逐维早停和特征重要性评分，该模型能够产生与基于神经网络的VCM相当的结果。 |
| [^28] | [Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery.](http://arxiv.org/abs/2401.05394) | 该论文介绍了一种新的迭代正则化算法IRKSN，它通过使用$k$支撑范数正则化实现稀疏恢复，并提供了条件。这是对基于$\ell_1$范数的迭代方法的一种重要补充。 |
| [^29] | [Multi-Lattice Sampling of Quantum Field Theories via Neural Operator-based Flows.](http://arxiv.org/abs/2401.00828) | 本文提出了一种基于神经算子流的方法，通过近似时间相关算子，实现了在量子场论中从底层自由理论到目标理论的离散-连续归一化流。 |
| [^30] | [Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures.](http://arxiv.org/abs/2401.00773) | 提出一种基于随机子空间和子抽样集合的Dirichlet过程高斯混合模型的无监督异常检测方法，提高了计算效率和检测器的鲁棒性。 |
| [^31] | [Leveraging Public Representations for Private Transfer Learning.](http://arxiv.org/abs/2312.15551) | 该论文探讨了如何利用公共数据来改进私有学习的问题。研究发现，通过学习公共数据中的共享表示，可以在两种迁移学习场景中实现最优的学习效果。在单任务迁移场景中，算法在给定子空间范围内搜索线性模型，并实现了最优超额风险。在多任务个性化场景中，足够的公共数据可以消除私有协调需求，并通过纯局部学习达到相同的效用。 |
| [^32] | [Time-changed normalizing flows for accurate SDE modeling.](http://arxiv.org/abs/2312.14698) | 本论文提出了一种新的动态正则化流的变种，即时间变换正则化流(TCNF)，通过时间变形的方法能有效地建模一些无法用其他方法建模的随机微分方程(SDEs)，包括著名的奥恩斯坦-乌伦贝克过程，并泛化了先前的方法，从而提高了结果的准确度和推断和预测的精度。 |
| [^33] | [Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference.](http://arxiv.org/abs/2312.05910) | 这篇论文介绍了一种将集合卡尔曼滤波引入变分推理框架的方法，用于近似高斯过程状态空间模型的后验分布，并且有效地利用了潜在状态和动力学之间的依赖关系，减少了变分参数的数量。 |
| [^34] | [Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More.](http://arxiv.org/abs/2312.02708) | 本文提出了一种考虑任务对称性的可证明的对抗鲁棒性概念，并通过选择合适的模型和认证方法来实现鲁棒性。同时，通过开发保持对称性的随机平滑的框架，解决了对于具有连续对称性的模型的认证方法不可用的问题。 |
| [^35] | [Coefficient Shape Alignment in Multivariate Functional Regression.](http://arxiv.org/abs/2312.01925) | 该论文提出了一种新的分组多元函数回归模型，其中采用了一种新的正则化方法来解决不同函数协变量的潜在同质性问题。 |
| [^36] | [Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation.](http://arxiv.org/abs/2312.01520) | 本文提出了一种计算贝叶斯网络中Shannon熵和Kullback-Leibler散度的高效算法，并通过一系列数值示例进行了演示。此外，还展示了如何将高斯贝叶斯网络中KL的计算复杂度从立方降低到二次。 |
| [^37] | [$\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks.](http://arxiv.org/abs/2311.18744) | 本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与经典神经网络的性能进行了全面比较分析，结果表明《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上表现优越。 |
| [^38] | [Fixed point actions from convolutional neural networks.](http://arxiv.org/abs/2311.17816) | 本研究使用晶格规范等变卷积神经网络（L-CNN）描述了基于重整化群变换的固定点作用（FP），这种方法更准确地参数化FP作用，可以规避临界减速和拓扑冻结问题，并在粗晶格上产生具有非常小晶格效应的物理预测。 |
| [^39] | [How do Minimum-Norm Shallow Denoisers Look in Function Space?.](http://arxiv.org/abs/2311.06748) | 研究了最小范数浅层去噪器在函数空间中的表现，推导出一元数据和多元数据上的闭合形式，并发现其具有收缩性和较好的泛化能力。 |
| [^40] | [Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder.](http://arxiv.org/abs/2311.02794) | 本研究提出了一种稀疏添加机制移位变分自动编码器（SAMS-VAE），用于建模细胞的扰动情况，并结合复合性、解缠和可解释性。通过稀疏化处理全局潜变量，SAMS-VAE能够识别出特定于干扰的潜在子空间，并在多个任务上进行了定量和定性评估。 |
| [^41] | [Should Under-parameterized Student Networks Copy or Average Teacher Weights?.](http://arxiv.org/abs/2311.01644) | 这项研究探讨了在欠参数化情况下，学生网络是否应该复制教师神经元或平均一组教师神经元的权重。研究发现对于特定的网络结构和输入分布，当教师网络的输入向量正交且输出权重为酉时，复制-平均配置将达到优化结果，其中大部分学生神经元复制一个教师神经元，最后一个学生神经元对所有教师神经元取平均值。 |
| [^42] | [The Memory Perturbation Equation: Understanding Model's Sensitivity to Data.](http://arxiv.org/abs/2310.19273) | 这个论文介绍了记忆扰动方程（MPE），该方程通过应用贝叶斯原理将模型的敏感性与训练数据的扰动联系起来，并且能够准确预测模型在未见测试数据上的泛化能力。 |
| [^43] | [Hierarchical Randomized Smoothing.](http://arxiv.org/abs/2310.16221) | 分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。 |
| [^44] | [DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data.](http://arxiv.org/abs/2310.13349) | DeepFDR是一种基于深度学习的虚警控制方法，通过利用无监督的图像分割技术解决神经影像数据中的多重检验问题，并在实验证明其相对于现有方法具有卓越的性能。 |
| [^45] | [Constrained Reweighting of Distributions: an Optimal Transport Approach.](http://arxiv.org/abs/2310.12447) | 本文提出了一种最优传输方法，通过引入非参数化的分布约束权重，并利用最大熵原理和最优传输工具设计了一个通用框架，以实现对观测数据的最优权重调整。这种方法在不同的应用场景中展现了灵活性和多功能性。 |
| [^46] | [Unsupervised Fact Verification by Language Model Distillation.](http://arxiv.org/abs/2309.16540) | 本文提出了一种名为SFAVEL的无监督框架，通过语言模型蒸馏将自监督特征转化为高质量的主张-事实对齐，实现无监督事实验证。这通过一种新颖的对比损失函数实现，同时保留语料库间的语义关系。 |
| [^47] | [Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds.](http://arxiv.org/abs/2309.13915) | 本研究探讨了神经策略镜像梯度算法在低维流形上的样本复杂性。研究发现在每次迭代中，卷积神经网络可以很好地逼近价值函数和策略，且逼近误差受网络大小的影响，并且可以继承之前网络的平滑性。 |
| [^48] | [Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization.](http://arxiv.org/abs/2309.11856) | 本论文提出了一种使用改进的方差最小化的分块量化策略，用于压缩图神经网络的激活，实现内存消耗的降低和运行时的加速。 |
| [^49] | [A Sequentially Fair Mechanism for Multiple Sensitive Attributes.](http://arxiv.org/abs/2309.06627) | 本论文提出了一个顺序框架来逐步实现对多个敏感特征的公平性，通过利用多边际Wasserstein重心扩展了标准的强人口平等概念，并提供了闭式解来解释敏感特征之间的相关性。 |
| [^50] | [Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling.](http://arxiv.org/abs/2308.09460) | 本文提出了一种加速贝叶斯推断方法，用于解决具有凸几何的成像逆问题。该方法通过随机弛缓纵坐标迭代实现，对于高斯目标是渐近无偏的，并且对于$\kappa$-强对数凹的任何目标都能以加速方式收敛。 |
| [^51] | [Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering.](http://arxiv.org/abs/2308.06399) | 本研究介绍了一种将混合效应模型和层次聚类应用于贝叶斯网络学习的新方法，在农学研究中广泛应用。通过整合随机效应，该方法可以提高贝叶斯网络的结构学习能力，实现因果关系网络的发现。 |
| [^52] | [CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery.](http://arxiv.org/abs/2307.00859) | CardiGraphormer是一种革命性的方法，结合了自监督学习、图神经网络和保持基数注意力，颠覆了药物发现的方式。它利用自监督学习学习分子表示并利用图神经网络提取分子指纹，提高了预测性能和可解释性，同时减少了计算时间，并在处理复杂数据和执行各种与图结构相关的任务方面表现出色。 |
| [^53] | [iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models.](http://arxiv.org/abs/2306.17361) | 本文提出了一种识别非线性加性噪声模型中因果机制转变的方法，该方法专注于在相关的结构因果模型中识别功能机制的变化，而不需要估计整个有向无环图(DAG)的结构。 |
| [^54] | [Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent.](http://arxiv.org/abs/2306.11589) | 本文探索了使用随机梯度下降算法从高斯过程后验中采样的方法，该方法计算高效且能在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。 |
| [^55] | [Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning.](http://arxiv.org/abs/2306.04746) | 该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。 |
| [^56] | [Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking Folklore Weisfeiler-Lehman.](http://arxiv.org/abs/2306.03266) | 本文提出了$(k, t)$-FWL和$k$-FWL+两种方法，理论上证明了它们可以在$O(n^2)$的空间复杂度下，解决图同构问题。 |
| [^57] | [Restless Bandits with Average Reward: Breaking the Uniform Global Attractor Assumption.](http://arxiv.org/abs/2306.00196) | 本文提出了一个通用的框架，将任何单臂策略转化为原始的$N$臂问题的策略，解决了依赖于复杂UGAP假设的问题，并实现了具有$O(1/\sqrt{N})$最优性差距的策略。 |
| [^58] | [Learning to solve Bayesian inverse problems: An amortized variational inference approach.](http://arxiv.org/abs/2305.20004) | 本文提出了一种基于深度神经网络的参数化表示后验分布的摊销变分推理方法，以实现实时推理的目的，可应用于流体力学中的参数估计和流场重构等领域。 |
| [^59] | [DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method.](http://arxiv.org/abs/2305.16284) | 本文提出了一种名为DoWG的无参数梯度下降方法，它是第一个既高效又通用的算法，能够自适应于平稳和非平稳问题，并且无需回溯搜索过程。 |
| [^60] | [Koopman Kernel Regression.](http://arxiv.org/abs/2305.16215) | 提出了一种基于Koopman核的回归方法，用于预测非线性动力系统的时间演变。该方法在机器人操作，视频预测和交通预测等各种应用中均有优异表现，并具有可证明的学习理论保证。 |
| [^61] | [Convergence of stochastic gradient descent under a local Lajasiewicz condition for deep neural networks.](http://arxiv.org/abs/2304.09221) | 本文通过随机梯度下降算法研究了解析度函数为非凸的深度神经网络的全局收敛性，证明了当机器学习噪声的尺度与目标函数相等时，在局部区域内初始化后，以正的概率能够收敛到该区域内的全局最小值。 |
| [^62] | [On the strong stability of ergodic iterations.](http://arxiv.org/abs/2304.04657) | 本论文研究了迭代随机函数生成的过程的强稳定性，证明了适用于递归映射的温和条件下的强稳定性，并且提供了多个应用及相关领域的新结果。 |
| [^63] | [Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions.](http://arxiv.org/abs/2303.14226) | 提出了一种在组合干预下进行因果推断的模型，通过施加潜在结构跨越单位和组合，在降低实验数量和处理混杂问题方面有着良好表现。 |
| [^64] | [To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning.](http://arxiv.org/abs/2303.03374) | 该论文研究了在迁移学习中使用单个预训练检查点微调的模型集合，发现通过更好地探索预训练基域可以改进集成模型，但离开基域会导致失去迁移学习的好处，并且降低集成质量。作者提出了一种更有效的修改方法StarSSE，可以产生更强的集成模型和均匀的模型混合。 |
| [^65] | [CAMEL: Curvature-Augmented Manifold Embedding and Learning.](http://arxiv.org/abs/2303.02561) | CAMEL是一种新的方法，利用黎曼流形上的拓扑度量和独特的黎曼度量进行高维数据分类、降维和可视化。它通过平滑分区统一算子将局部正交投影转换为全局嵌入，并提供了聚类显著特征的物理解释。CAMEL在各种基准数据集上表现优于其他方法，特别是对于高维数据集。 |
| [^66] | [Comparative Study of Coupling and Autoregressive Flows through Robust Statistical Tests.](http://arxiv.org/abs/2302.12024) | 本论文通过比较耦合流和自回归流的不同架构和多样目标分布，利用各种测试统计量进行性能比较，为正规化流的生成模型提供了深入的研究和实证评估。 |
| [^67] | [Information Theoretic Lower Bounds for Information Theoretic Upper Bounds.](http://arxiv.org/abs/2302.04925) | 本文研究了在随机凸优化中，输出模型和经验样本之间的互信息与算法泛化之间的关系。研究结果表明，现有的信息理论泛化界限不足以捕捉到像SGD和正则化ERM这样具有维度无关样本复杂度的算法的泛化能力。 |
| [^68] | [Managing Temporal Resolution in Continuous Value Estimation: A Fundamental Trade-off.](http://arxiv.org/abs/2212.08949) | 本论文分析了在强化学习和最优控制中观测时间以离散时间点固定周期到达的默认假设与实际情况下的连续时间系统之间的差异，并在LQR系统中揭示了近似误差和统计误差之间的基本权衡。在有限数据的情况下，管理时间分辨率可以显著改善策略评估的效率。 |
| [^69] | [On LASSO for High Dimensional Predictive Regression.](http://arxiv.org/abs/2212.07052) | 本文研究了高维预测回归中LASSO的应用，提出了LASSO的收敛速度与横断面情况不同的新的概率界限，并展示了LASSO在预测失业率方面的强大性能。 |
| [^70] | [Exploring validation metrics for offline model-based optimisation with diffusion models.](http://arxiv.org/abs/2211.10747) | 本论文研究基于扩散模型的离线模型优化中的验证指标。在离线模型优化中，我们希望在没有访问真值预言机的情况下设计候选方案。现有的验证指标是对预言机的近似，我们希望找到与真值预言机最相关的验证指标。 |
| [^71] | [Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees.](http://arxiv.org/abs/2210.07893) | 本文针对高斯过程模型的数值稳定性进行了研究，通过感兴趣点的选择和计算，提供了稳定可靠的稀疏逼近方法。 |
| [^72] | [Normalised clustering accuracy: An asymmetric external cluster validity measure.](http://arxiv.org/abs/2209.02935) | 本文提出了一种非对称的外部聚类有效度量方法，旨在区分不同任务类型上表现良好和系统性表现不佳的聚类算法。与传统的内部度量不同，该方法利用参考真实分组进行评估，并弥补了现有方法在最坏情况下的误差。 |
| [^73] | [Prediction of good reaction coordinates and future evolution of MD trajectories using Regularized Sparse Autoencoders: A novel deep learning approach.](http://arxiv.org/abs/2208.10962) | 本研究提出了一种新的深度学习方法，使用正则化稀疏自编码器预测良好的反应坐标以及MD轨迹的演化情况，并展示了正则化约束对于选择重要反应坐标的帮助。 |
| [^74] | [Provably tuning the ElasticNet across instances.](http://arxiv.org/abs/2207.10199) | 这篇论文提供了一个针对ElasticNet的新颖结构结果，用以证明在多个问题实例中调整正规化参数，同时提供了统计和在线学习情景下的泛化保证。 |
| [^75] | [Tensor-on-Tensor Regression: Riemannian Optimization, Over-parameterization, Statistical-computational Gap, and Their Interplay.](http://arxiv.org/abs/2206.08756) | 张量对张量回归问题中，我们提出了黎曼优化方法和秩过参数化的研究，并展示了黎曼优化方法的线性和二次收敛性以及适应过参数化的能力。同时，我们证明了标量对张量回归中的统计计算差异。 |
| [^76] | [Optimising for Interpretability: Convolutional Dynamic Alignment Networks.](http://arxiv.org/abs/2109.13004) | CoDA Nets是一种性能良好的分类器，具有高度内在可解释性。它们通过动态对齐单元实现输入依赖的线性变换，并将输出线性分解为各个输入的贡献。这些模型在视觉质量和分类准确度上优于现有方法，并且在CIFAR-10和TinyImagenet等数据集上表现出与ResNet和VGG模型相媲美的性能。 |
| [^77] | [SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking.](http://arxiv.org/abs/2109.10399) | 这个论文介绍了SubseasonalClimateUSA，这是一个用于训练和基准测试美国的亚季节预测模型的数据集。作者使用该数据集对多种模型进行了基准测试。 |
| [^78] | [Generalized Orthogonal Procrustes Problem under Arbitrary Adversaries.](http://arxiv.org/abs/2106.15493) | 广义正交Procrustes问题在多个科学领域中起到基础性作用。SDR可以精确恢复最小二乘估计，而适当初始化下的广义功率方法以线性方式收敛于SDR的全局最小化器。 |
| [^79] | [Adversarial Estimation of Riesz Representers.](http://arxiv.org/abs/2101.00009) | 我们提出了一个敌对框架，使用通用函数空间来估计Riesz Representer，并且证明了非渐近均方速率以及渐近正态性的条件。这个条件使得在机器学习中进行推断时无需样本分割，并且能够提高有限样本性能。 |
| [^80] | [End-to-end Kernel Learning via Generative Random Fourier Features.](http://arxiv.org/abs/2009.04614) | 本文提出了一种通过生成型随机傅立叶特征进行端到端内核学习的方法，将内核学习和线性学习器融合为一个统一框架，通过生成网络和线性分类器联合训练以实现更好的泛化性能。 |
| [^81] | [Unifying supervised learning and VAEs -- coverage, systematics and goodness-of-fit in normalizing-flow based neural network models for astro-particle reconstructions.](http://arxiv.org/abs/2008.05825) | 本研究将监督学习和VAEs统一于基于正态流的神经网络模型中，对天文粒子重建进行了覆盖、系统性和拟合好坏的研究，并通过KL散度目标实现了监督学习和VAEs的统一。利用条件正态化流的方法可以计算神经网络模型的拟合优度p值。 |
| [^82] | [On Biased Compression for Distributed Learning.](http://arxiv.org/abs/2002.12410) | 本研究研究了偏压压缩在分布式学习中的应用，首次证明了偏压压缩器可以在单节点和分布式环境中实现线性收敛速率。 |
| [^83] | [On the Generalization of Stochastic Gradient Descent with Momentum.](http://arxiv.org/abs/1809.04564) | 该论文研究了带动量的随机梯度下降方法的泛化性能，并通过分析不同的损失函数形式和动量范围，提出了一种可以在多个周期内训练机器学习模型并保证泛化性能的修改后的动量更新规则。对于特殊情况下的损失函数，标准的带动量随机梯度下降方法也能够具有泛化性能。该论文还给出了对于期望真实风险的上界估计。 |

# 详细

[^1]: 通过非凸规划解决随机广义线性回归的新方法

    A Novel Approach in Solving Stochastic Generalized Linear Regression via Nonconvex Programming. (arXiv:2401.08488v1 [stat.ML])

    [http://arxiv.org/abs/2401.08488](http://arxiv.org/abs/2401.08488)

    通过非凸规划技术，利用聚类和分位数估计的方法解决了随机广义线性回归模型，并在各种指标上表现优于传统模型。

    

    广义线性回归(如逻辑回归或泊松回归)是长期研究的回归分析方法，在各种分类问题中广泛应用。我们的研究将随机广义线性回归模型视为带有机会约束的随机问题，并使用非凸规划技术解决它。同时运用聚类技术和分位数估计来估计随机数据的均值和方差-协方差矩阵。使用F1得分、精确度得分和召回率得分等指标来评估逻辑回归模型的效果。在相同数据集上，所提算法的结果比普通逻辑回归模型在以上评估标准上提高了1-2个百分点。

    Generalized linear regressions, such as logistic regressions or Poisson regressions, are long-studied regression analysis approaches, and their applications are widely employed in various classification problems. Our study considers a stochastic generalized linear regression model as a stochastic problem with chance constraints and tackles it using nonconvex programming techniques. Clustering techniques and quantile estimation are also used to estimate random data's mean and variance-covariance matrix. Metrics for measuring the performance of logistic regression are used to assess the model's efficacy, including the F1 score, precision score, and recall score. The results of the proposed algorithm were over 1 to 2 percent better than the ordinary logistic regression model on the same dataset with the above assessment criteria.
    
[^2]: 对于配对比较模型的统计推断

    Statistical inference for pairwise comparison models. (arXiv:2401.08463v1 [math.ST])

    [http://arxiv.org/abs/2401.08463](http://arxiv.org/abs/2401.08463)

    本论文通过建立极大似然估计量的渐近正态性结果，填补了配对比较模型中统计推断的空白，为各种配对比较模型提供了统一的方法，超越了Bradley-Terry模型，为实践者提供了坚实的理论保证。

    

    配对比较模型被用于各个领域的实用性和排名评估。现代问题规模的增加强调了对于当被比较对象数量无限增加时，对于这些模型中的统计推断的理解的需求。目前，文献中对于这些模型中的统计推断的理解还相当有限，除非只是在少数特殊实例中。本文通过在广泛的配对比较模型中建立极大似然估计量的渐近正态性结果来填补这一空白。关键思想在于将费舍尔信息矩阵识别为加权图拉普拉斯矩阵，通过一种细致入微的谱分析方法来进行研究。我们的发现为在各种配对比较模型中进行统计推断提供了第一个统一的方法，超越了Bradley-Terry模型，为实践者提供了坚实的理论保证。通过利用合成数据进行的模拟验证这一渐近正态性结果，然后进行了

    Pairwise comparison models are used for quantitatively evaluating utility and ranking in various fields. The increasing scale of modern problems underscores the need to understand statistical inference in these models when the number of subjects diverges, which is currently lacking in the literature except in a few special instances. This paper addresses this gap by establishing an asymptotic normality result for the maximum likelihood estimator in a broad class of pairwise comparison models. The key idea lies in identifying the Fisher information matrix as a weighted graph Laplacian matrix which can be studied via a meticulous spectral analysis. Our findings provide the first unified theory for performing statistical inference in a wide range of pairwise comparison models beyond the Bradley--Terry model, benefiting practitioners with a solid theoretical guarantee for their use. Simulations utilizing synthetic data are conducted to validate the asymptotic normality result, followed by 
    
[^3]: 通过可控的误发现率选择的稀疏PCA

    Sparse PCA with False Discovery Rate Controlled Variable Selection. (arXiv:2401.08375v1 [stat.ML])

    [http://arxiv.org/abs/2401.08375](http://arxiv.org/abs/2401.08375)

    该论文提出了一种通过可控的误发现率（FDR）驱动的稀疏PCA方法，在不需要调整稀疏参数的情况下，实现了对加载向量的自动选择，从而解决了传统稀疏PCA方法容易选择不相关变量的问题。

    

    稀疏主成分分析（PCA）旨在将高维数据映射到较低维的线性子空间。通过使加载向量稀疏，它既可以实现降维又可以进行变量选择。稀疏PCA算法通常是在解释方差和加载向量稀疏性之间权衡，加载向量的稀疏性即选择的变量数量。由于高解释方差不一定代表相关信息，这些方法容易选择不相关的变量。为了克服这个问题，我们提出了一种以误发现率（FDR）为驱动的稀疏PCA的替代形式。然后，我们利用终止随机实验（T-Rex）选择器自动确定加载向量的FDR控制支撑。得到的T-Rex PCA的一大优势是不需要调整稀疏参数。数值实验和股票市场数据示例证明了性能的显著改善。

    Sparse principal component analysis (PCA) aims at mapping large dimensional data to a linear subspace of lower dimension. By imposing loading vectors to be sparse, it performs the double duty of dimension reduction and variable selection. Sparse PCA algorithms are usually expressed as a trade-off between explained variance and sparsity of the loading vectors (i.e., number of selected variables). As a high explained variance is not necessarily synonymous with relevant information, these methods are prone to select irrelevant variables. To overcome this issue, we propose an alternative formulation of sparse PCA driven by the false discovery rate (FDR). We then leverage the Terminating-Random Experiments (T-Rex) selector to automatically determine an FDR-controlled support of the loading vectors. A major advantage of the resulting T-Rex PCA is that no sparsity parameter tuning is required. Numerical experiments and a stock market data example demonstrate a significant performance improvem
    
[^4]: 因果机器学习用于中介效应。 (arXiv:2401.08290v1 [econ.EM])

    Causal Machine Learning for Moderation Effects. (arXiv:2401.08290v1 [econ.EM])

    [http://arxiv.org/abs/2401.08290](http://arxiv.org/abs/2401.08290)

    本文提出了一种新的参数，平衡群体平均处理效应（BGATE），用于解释处理在群体间的效应差异，该参数基于因果机器学习方法，对离散处理进行估计。通过比较两个BGATE的差异，能更好地分析处理的异质性。

    

    对于任何决策者来说，了解决策（处理）对整体和子群的影响是非常有价值的。因果机器学习最近提供了用于估计群体平均处理效应（GATE）的工具，以更好地理解处理的异质性。本文解决了在考虑其他协变量变化的情况下解释群体间处理效应差异的难题。我们提出了一个新的参数，即平衡群体平均处理效应（BGATE），它衡量了具有特定分布的先验确定协变量的GATE。通过比较两个BGATE的差异，我们可以更有意义地分析异质性，而不仅仅比较两个GATE。这个参数的估计策略是基于无混淆设置中离散处理的双重/去偏机器学习，该估计量在标准条件下表现为$\sqrt{N}$一致性和渐近正态性。添加额外的标识

    It is valuable for any decision maker to know the impact of decisions (treatments) on average and for subgroups. The causal machine learning literature has recently provided tools for estimating group average treatment effects (GATE) to understand treatment heterogeneity better. This paper addresses the challenge of interpreting such differences in treatment effects between groups while accounting for variations in other covariates. We propose a new parameter, the balanced group average treatment effect (BGATE), which measures a GATE with a specific distribution of a priori-determined covariates. By taking the difference of two BGATEs, we can analyse heterogeneity more meaningfully than by comparing two GATEs. The estimation strategy for this parameter is based on double/debiased machine learning for discrete treatments in an unconfoundedness setting, and the estimator is shown to be $\sqrt{N}$-consistent and asymptotically normal under standard conditions. Adding additional identifyin
    
[^5]: Vision Transformer中的注意力图统计检验

    Statistical Test for Attention Map in Vision Transformer. (arXiv:2401.08169v1 [stat.ML])

    [http://arxiv.org/abs/2401.08169](http://arxiv.org/abs/2401.08169)

    本研究提出了一种Vision Transformer中注意力图的统计检验方法，可以将注意力作为可靠的定量证据指标用于决策，并通过p值进行统计显著性量化。

    

    Vision Transformer（ViT）在各种计算机视觉任务中展示出了出色的性能。注意力对于ViT捕捉图像补丁之间复杂广泛的关系非常重要，使得模型可以权衡图像补丁的重要性，并帮助我们理解决策过程。然而，当将ViT的注意力用作高风险决策任务（如医学诊断）中的证据时，面临一个挑战，即注意机制可能错误地关注无关的区域。在本研究中，我们提出了一种ViT注意力的统计检验，使我们能够将注意力作为可靠的定量证据指标用于ViT的决策，并严格控制误差率。使用选择性推理框架，我们以p值的形式量化注意力的统计显著性，从而能够理论上基于假阳性检测概率量化注意力。

    The Vision Transformer (ViT) demonstrates exceptional performance in various computer vision tasks. Attention is crucial for ViT to capture complex wide-ranging relationships among image patches, allowing the model to weigh the importance of image patches and aiding our understanding of the decision-making process. However, when utilizing the attention of ViT as evidence in high-stakes decision-making tasks such as medical diagnostics, a challenge arises due to the potential of attention mechanisms erroneously focusing on irrelevant regions. In this study, we propose a statistical test for ViT's attentions, enabling us to use the attentions as reliable quantitative evidence indicators for ViT's decision-making with a rigorously controlled error rate. Using the framework called selective inference, we quantify the statistical significance of attentions in the form of p-values, which enables the theoretically grounded quantification of the false positive detection probability of attentio
    
[^6]: 多视角数据的社区检测的基本限制：多层、动态和部分标记的块模型

    Fundamental limits of community detection from multi-view data: multi-layer, dynamic and partially labeled block models. (arXiv:2401.08167v1 [math.ST])

    [http://arxiv.org/abs/2401.08167](http://arxiv.org/abs/2401.08167)

    该论文通过统一的理论框架研究了多视角数据中的社区检测问题，并提取出了在不同模型下社区恢复的基本阈值。

    

    多视角数据在现代网络分析中经常出现，例如社交网络分析中个体之间的多种类型关系、观测单位之间的长期互动测量以及带有噪声部分标记顶点的注释网络等。我们通过统一的理论框架研究了这些不同设置下的社区检测，并研究了社区恢复的基本阈值。我们在度数足够大的情况下表征了数据和潜在参数之间的互信息。基于这个通用结果，(i)我们推导出了在非均匀多层块模型中进行社区检测的尖锐阈值，(ii)表征了动态随机块模型中弱恢复的尖锐阈值，(iii)确定了不平衡部分标记块模型中的互信息极限。我们的前两个结果是在坐标上保凸的条件下推导出的。

    Multi-view data arises frequently in modern network analysis e.g. relations of multiple types among individuals in social network analysis, longitudinal measurements of interactions among observational units, annotated networks with noisy partial labeling of vertices etc. We study community detection in these disparate settings via a unified theoretical framework, and investigate the fundamental thresholds for community recovery. We characterize the mutual information between the data and the latent parameters, provided the degrees are sufficiently large. Based on this general result, (i) we derive a sharp threshold for community detection in an inhomogeneous multilayer block model \citep{chen2022global}, (ii) characterize a sharp threshold for weak recovery in a dynamic stochastic block model \citep{matias2017statistical}, and (iii) identify the limiting mutual information in an unbalanced partially labeled block model. Our first two results are derived modulo coordinate-wise convexit
    
[^7]: 差分隐私切片逆回归: 极小极大性和算法

    Differentially Private Sliced Inverse Regression: Minimax Optimality and Algorithm. (arXiv:2401.08150v1 [stat.ML])

    [http://arxiv.org/abs/2401.08150](http://arxiv.org/abs/2401.08150)

    本文提出了针对充足维度减少中的隐私问题的最佳差分隐私算法，并在低维和高维设置下建立了不同ially private 切片逆回归的下界。通过仿真和真实数据分析验证了这些算法的有效性。

    

    随着数据驱动应用的普及，隐私保护已成为高维数据分析中的一个关键问题。切片逆回归是一种广泛应用的统计技术，通过降低协变量的维度，同时保持足够的统计信息。本文提出了针对充足维度减少中的隐私问题的最佳差分隐私算法。我们在低维和高维设置下建立了不同ially private 切片逆回归的下界。此外，我们设计了差分隐私算法，实现了极小极大下界的要求，并在降维空间中同时保护隐私和保存重要信息的有效性。通过一系列的仿真实验和真实数据分析，我们证明了这些差分隐私算法的有效性。

    Privacy preservation has become a critical concern in high-dimensional data analysis due to the growing prevalence of data-driven applications. Proposed by Li (1991), sliced inverse regression has emerged as a widely utilized statistical technique for reducing covariate dimensionality while maintaining sufficient statistical information. In this paper, we propose optimally differentially private algorithms specifically designed to address privacy concerns in the context of sufficient dimension reduction. We proceed to establish lower bounds for differentially private sliced inverse regression in both the low and high-dimensional settings. Moreover, we develop differentially private algorithms that achieve the minimax lower bounds up to logarithmic factors. Through a combination of simulations and real data analysis, we illustrate the efficacy of these differentially private algorithms in safeguarding privacy while preserving vital information within the reduced dimension space. As a na
    
[^8]: 具有阶段约束的上下文赌博机

    Contextual Bandits with Stage-wise Constraints. (arXiv:2401.08016v1 [cs.LG])

    [http://arxiv.org/abs/2401.08016](http://arxiv.org/abs/2401.08016)

    本研究探讨了具有阶段约束的上下文赌博机问题，并提出了一种基于上限置信区间的算法和相应的遗憾上界。通过使用不同的缩放因子来平衡探索和约束满足，我们的算法可以适应高概率和期望设置，并在多个约束情况下得到了扩展。

    

    当约束问题必须满足高概率和期望时，我们研究了上下文赌博机在阶段约束存在的情况下的表现。显然，期望约束的设定是对高概率约束的放宽。我们首先从线性情况开始，其中上下文赌博机问题（奖励函数）和阶段约束（成本函数）都是线性的。在高概率和期望设置中，我们提出了一种上限置信区间算法，并证明了此问题的T轮遗憾上界。我们的算法使用一种新的思想来平衡探索和约束满足，通过不同的缩放因子缩放奖励和成本置信区间的半径。我们还证明了该约束问题的下界，展示了我们的算法和分析如何扩展到多个约束，并提供了模拟实验来验证我们的理论结果。

    We study contextual bandits in the presence of a stage-wise constraint (a constraint at each round), when the constraint must be satisfied both with high probability and in expectation. Obviously the setting where the constraint is in expectation is a relaxation of the one with high probability. We start with the linear case where both the contextual bandit problem (reward function) and the stage-wise constraint (cost function) are linear. In each of the high probability and in expectation settings, we propose an upper-confidence bound algorithm for the problem and prove a $T$-round regret bound for it. Our algorithms balance exploration and constraint satisfaction using a novel idea that scales the radii of the reward and cost confidence sets with different scaling factors. We also prove a lower-bound for this constrained problem, show how our algorithms and analyses can be extended to multiple constraints, and provide simulations to validate our theoretical results. In the high proba
    
[^9]: 概率Lambert问题的解决方案：与最优质量传输、Schr\"odinger桥和反应-扩散偏微分方程的连接

    Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs. (arXiv:2401.07961v1 [math.OC])

    [http://arxiv.org/abs/2401.07961](http://arxiv.org/abs/2401.07961)

    这项研究将概率Lambert问题与最优质量传输、Schr\"odinger桥和反应-扩散偏微分方程等领域连接起来，从而解决了概率Lambert问题的解的存在和唯一性，并提供了数值求解的方法。

    

    Lambert问题涉及通过速度控制在规定的飞行时间内将航天器从给定的初始位置转移到给定的终端位置，受到重力力场的限制。我们考虑了Lambert问题的概率变种，其中位置向量的端点约束的知识被它们各自的联合概率密度函数所替代。我们证明了具有端点联合概率密度约束的Lambert问题是一个广义的最优质量传输（OMT）问题，从而将这个经典的天体动力学问题与现代随机控制和随机机器学习的新兴研究领域联系起来。这个新发现的连接使我们能够严格建立概率Lambert问题的解的存在性和唯一性。同样的连接还帮助通过扩散正规化数值求解概率Lambert问题，即通过进一步的连接来利用。

    Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection 
    
[^10]: 高斯过程替代评估的适应性均匀预测方法

    Conformal Approach To Gaussian Process Surrogate Evaluation With Coverage Guarantees. (arXiv:2401.07733v1 [stat.ML])

    [http://arxiv.org/abs/2401.07733](http://arxiv.org/abs/2401.07733)

    本文提出了一种使用高斯过程构建适应性交叉均匀预测区间的方法，解决了先验适合度不恰当的问题，并且所得到的预测区间具有贝叶斯可信度集的自适应性和与代理模型的局部逼近误差的相关性。

    

    高斯过程广泛应用于构建工业应用中计算机模拟代码的不确定性量化的代理模型。本文提出了一种使用适应性交叉均匀预测区间构建的方法，通过将非一致性得分与高斯过程的后验标准差加权，解决了先验适合度不恰当的问题。得到的均匀预测区间表现出类似于贝叶斯可信度集的自适应水平，并且与代理模型的局部逼近误差具有显著相关性，同时不受优化问题的影响。

    Gaussian processes (GPs) are a Bayesian machine learning approach widely used to construct surrogate models for the uncertainty quantification of computer simulation codes in industrial applications. It provides both a mean predictor and an estimate of the posterior prediction variance, the latter being used to produce Bayesian credibility intervals. Interpreting these intervals relies on the Gaussianity of the simulation model as well as the well-specification of the priors which are not always appropriate. We propose to address this issue with the help of conformal prediction. In the present work, a method for building adaptive cross-conformal prediction intervals is proposed by weighting the non-conformity score with the posterior standard deviation of the GP. The resulting conformal prediction intervals exhibit a level of adaptivity akin to Bayesian credibility sets and display a significant correlation with the surrogate model local approximation error, while being free from the u
    
[^11]: 适用于二元和计数数据的高效非参数张量分解

    Efficient Nonparametric Tensor Decomposition for Binary and Count Data. (arXiv:2401.07711v1 [cs.LG])

    [http://arxiv.org/abs/2401.07711](http://arxiv.org/abs/2401.07711)

    我们提出了 ENTED，一个适用于二元和计数张量的高效非参数张量分解方法，通过使用非参数高斯过程来替代传统的多线性结构，并利用增强技术建立共轭模型，解决了处理复杂实际数据集的问题。

    

    在许多应用中，观察和存储二元反应或事件计数的数据以及高阶张量。张量分解（TD）是处理这种高维稀疏数据的强力工具。然而，许多传统的TD都是基于高斯分布明确或隐式设计的，对于离散数据是不合适的。此外，大多数TD依赖于预定义的多线性结构，如CP和Tucker格式。因此，它们可能不足以处理复杂的现实世界数据集。为了解决这些问题，我们提出了ENTED，一个适用于二元和计数张量的\textbf{高效非参数张量分解}。具体而言，我们首先采用了非参数高斯过程（GP）来替代传统的多线性结构。接下来，我们利用了\pg增强，为二元和计数分布建立共轭模型提供了一个统一的框架。最后，为了解决计算问题。

    In numerous applications, binary reactions or event counts are observed and stored within high-order tensors. Tensor decompositions (TDs) serve as a powerful tool to handle such high-dimensional and sparse data. However, many traditional TDs are explicitly or implicitly designed based on the Gaussian distribution, which is unsuitable for discrete data. Moreover, most TDs rely on predefined multi-linear structures, such as CP and Tucker formats. Therefore, they may not be effective enough to handle complex real-world datasets. To address these issues, we propose ENTED, an \underline{E}fficient \underline{N}onparametric \underline{TE}nsor \underline{D}ecomposition for binary and count tensors. Specifically, we first employ a nonparametric Gaussian process (GP) to replace traditional multi-linear structures. Next, we utilize the \pg augmentation which provides a unified framework to establish conjugate models for binary and count distributions. Finally, to address the computational issue 
    
[^12]: 具有任意经常性数据抽样的随机优化

    Stochastic optimization with arbitrary recurrent data sampling. (arXiv:2401.07694v1 [math.OC])

    [http://arxiv.org/abs/2401.07694](http://arxiv.org/abs/2401.07694)

    这篇论文研究了一种随机优化算法，证明了对于非凸、可能不光滑的目标函数，在一般的经常性抽样方案下，可以以最佳速率收敛；同时指出了收敛速度与"经常性的速度"之间的关系。

    

    为了获得随机优化的最佳一阶收敛保证，需要使用一个经常性数据抽样算法，该算法以足够的频率对每个数据点进行抽样。大多数常用的数据抽样算法（如i.i.d.，MCMC，随机重排）在温和的假设下确实是经常性的。在这项工作中，我们表明对于一类特殊的随机优化算法，我们无需除了数据抽样算法中的经常性之外的任何其他属性（如独立性，指数混合和重排）来保证最佳的一阶收敛速率。也就是说，使用Minimization by Incremental Surrogate Optimization (MISO)的正则化版本，我们证明了对于非凸的、可能不光滑的目标函数，期望的最优性差异在一般的经常性抽样方案下收敛于最佳速率$O(n^{-1/2})$。此外，暗示的常数明确取决于"经常性的速度"，由指数测量。

    For obtaining optimal first-order convergence guarantee for stochastic optimization, it is necessary to use a recurrent data sampling algorithm that samples every data point with sufficient frequency. Most commonly used data sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed recurrent under mild assumptions. In this work, we show that for a particular class of stochastic optimization algorithms, we do not need any other property (e.g., independence, exponential mixing, and reshuffling) than recurrence in data sampling algorithms to guarantee the optimal rate of first-order convergence. Namely, using regularized versions of Minimization by Incremental Surrogate Optimization (MISO), we show that for non-convex and possibly non-smooth objective functions, the expected optimality gap converges at an optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes. Furthermore, the implied constant depends explicitly on the `speed of recurrence', measured by the expe
    
[^13]: 针对支持向量机的成本敏感特征选择

    Cost-sensitive Feature Selection for Support Vector Machines. (arXiv:2401.07627v1 [stat.ML])

    [http://arxiv.org/abs/2401.07627](http://arxiv.org/abs/2401.07627)

    该论文提出了一种针对支持向量机的成本敏感特征选择方法，通过最小化所选特征的数量来适应误分类成本的不对称性。

    

    特征选择是数据科学任务（如分类）中的关键步骤，它可以识别相关变量，使分类过程更具解释性，更省成本（测量方面），通过减少噪声和数据过拟合而更有效。特征在分类过程中的相关性与误分类成本的不对称性有关，因为假阳性和假阴性情况可能具有非常不同的后果。然而，现有的特征选择方法很少考虑到这种误差的成本敏感性。本文提出了一种基于数学优化的特征选择方法，嵌入到其中一个最常用的分类方法——支持向量机中，以适应误分类成本的不对称性。其关键思想是通过最小化所选特征的数量来取代传统的边界最大化，并对假阳性设置上限。

    Feature Selection is a crucial procedure in Data Science tasks such as Classification, since it identifies the relevant variables, making thus the classification procedures more interpretable, cheaper in terms of measurement and more effective by reducing noise and data overfit. The relevance of features in a classification procedure is linked to the fact that misclassifications costs are frequently asymmetric, since false positive and false negative cases may have very different consequences. However, off-the-shelf Feature Selection procedures seldom take into account such cost-sensitivity of errors.  In this paper we propose a mathematical-optimization-based Feature Selection procedure embedded in one of the most popular classification procedures, namely, Support Vector Machines, accommodating asymmetric misclassification costs. The key idea is to replace the traditional margin maximization by minimizing the number of features selected, but imposing upper bounds on the false positive
    
[^14]: RedEx: 通过凸优化方法超越固定表示方法

    RedEx: Beyond Fixed Representation Methods via Convex Optimization. (arXiv:2401.07606v1 [cs.LG])

    [http://arxiv.org/abs/2401.07606](http://arxiv.org/abs/2401.07606)

    本文提出了一种名为RedEx的新架构，通过凸优化方法学习神经网络无法学习的目标函数，具有优化保证。

    

    优化神经网络是一个难以理解的困难任务。与此同时，固定表示方法如核函数和随机特征具有可证明的优化保证，但由于其固有的无法学习表示的能力而表现较差。本文旨在通过提出一种新的架构RedEx（Reduced Expander Extractor），来弥合这一差距。RedEx具有与神经网络一样的表达能力，并且可以通过一个带有半正定约束和优化保证的凸程序按层次进行训练。我们还证明了RedEx可以有效地学习固定表示方法无法学习的一类目标函数。

    Optimizing Neural networks is a difficult task which is still not well understood. On the other hand, fixed representation methods such as kernels and random features have provable optimization guarantees but inferior performance due to their inherent inability to learn the representations. In this paper, we aim at bridging this gap by presenting a novel architecture called RedEx (Reduced Expander Extractor) that is as expressive as neural networks and can also be trained in a layer-wise fashion via a convex program with semi-definite constraints and optimization guarantees. We also show that RedEx provably surpasses fixed representation methods, in the sense that it can efficiently learn a family of target functions which fixed representation methods cannot.
    
[^15]: 广义低秩矩阵多臂赌博问题的高效框架

    Efficient Frameworks for Generalized Low-Rank Matrix Bandit Problems. (arXiv:2401.07298v1 [stat.ML])

    [http://arxiv.org/abs/2401.07298](http://arxiv.org/abs/2401.07298)

    本文提出了一种高效的框架来解决广义低秩矩阵多臂赌博问题，在计算和理论上克服了现有算法的限制，通过使用Stein的方法和正则化思想对子空间进行估计，以及通过一种新的排除思想进一步提高了效率。

    

    在随机背景下的低秩矩阵多臂赌博问题中，一个动作的期望回报由该动作的特征矩阵与某个固定但最初未知的$d_1 \times d_2$秩为$r \ll \{d_1, d_2\}$的矩阵$\Theta^*$的内积给出，代理根据过去的经验顺序采取动作以最大化累积回报。本文研究了最近在广义线性模型（GLM）框架下提出的广义低秩矩阵多臂赌博问题。为了克服现有算法在该问题上的计算不可行性和理论限制，我们首先提出了G-ESTT框架，通过在子空间估计上使用Stein的方法并通过正则化思想利用估计的子空间。此外，我们通过在估计的子空间上使用一种新的排除思想，显著提高了G-ESTT的效率，并提出了...

    In the stochastic contextual low-rank matrix bandit problem, the expected reward of an action is given by the inner product between the action's feature matrix and some fixed, but initially unknown $d_1$ by $d_2$ matrix $\Theta^*$ with rank $r \ll \{d_1, d_2\}$, and an agent sequentially takes actions based on past experience to maximize the cumulative reward. In this paper, we study the generalized low-rank matrix bandit problem, which has been recently proposed in \cite{lu2021low} under the Generalized Linear Model (GLM) framework. To overcome the computational infeasibility and theoretical restrain of existing algorithms on this problem, we first propose the G-ESTT framework that modifies the idea from \cite{jun2019bilinear} by using Stein's method on the subspace estimation and then leverage the estimated subspaces via a regularization idea. Furthermore, we remarkably improve the efficiency of G-ESTT by using a novel exclusion idea on the estimated subspace instead, and propose the
    
[^16]: 利用先验知识发现具有未观测变量的因果可加模型及其在时间序列数据中的应用

    Use of Prior Knowledge to Discover Causal Additive Models with Unobserved Variables and its Application to Time Series Data. (arXiv:2401.07231v1 [cs.LG])

    [http://arxiv.org/abs/2401.07231](http://arxiv.org/abs/2401.07231)

    本文提出了两种用于具有未观测变量的因果可加模型（CAM-UV）的方法，并扩展了这些方法以应用于时间序列数据。这些方法利用先验知识进行高效因果发现，并具有对因果关系顺序的特殊处理。

    

    本文提出了两种用于具有未观测变量的因果可加模型（CAM-UV）的方法。CAM-UV假设因果函数采用广义可加模型的形式，并存在潜在的混淆变量。首先，我们提出了一种利用先验知识进行高效因果发现的方法。然后，我们扩展了这种方法，用于推断时间序列数据的因果关系。与其他现有的因果函数模型不同，原始的CAM-UV算法不寻求观测变量之间的因果顺序，而是旨在确定每个观测变量的原因。因此，本文中提出的第一种方法利用先验知识，例如理解某些变量不能成为特定变量的原因。此外，通过融入因果在时间上的先验知识，我们将第一个算法扩展为第二种用于时间序列数据中的因果发现的方法。我们验证了第一个提出的方法。

    This paper proposes two methods for causal additive models with unobserved variables (CAM-UV). CAM-UV assumes that the causal functions take the form of generalized additive models and that latent confounders are present. First, we propose a method that leverages prior knowledge for efficient causal discovery. Then, we propose an extension of this method for inferring causality in time series data. The original CAM-UV algorithm differs from other existing causal function models in that it does not seek the causal order between observed variables, but rather aims to identify the causes for each observed variable. Therefore, the first proposed method in this paper utilizes prior knowledge, such as understanding that certain variables cannot be causes of specific others. Moreover, by incorporating the prior knowledge that causes precedes their effects in time, we extend the first algorithm to the second method for causal discovery in time series data. We validate the first proposed method
    
[^17]: 概率降维向量自回归模型及其斜投影方法

    Probabilistic Reduced-Dimensional Vector Autoregressive Modeling with Oblique Projections. (arXiv:2401.07206v1 [stat.ML])

    [http://arxiv.org/abs/2401.07206](http://arxiv.org/abs/2401.07206)

    本论文提出了一种概率降维向量自回归（PredVAR）模型，通过斜投影方法从高维噪声数据中提取低维动态信息，并通过迭代的算法更新潜在动态和最佳斜投影的估计，得到具有排序预测能力的动态潜变量和与外部投影模型一致的显式潜在VAR模型。

    

    本论文提出了一种概率降维向量自回归（PredVAR）模型，用于从高维噪声数据中提取低维动态信息。该模型采用斜投影将测量空间划分为适应降维动态的子空间和补充的静态子空间。通过最佳斜分解，实现了关于预测误差协方差的最佳预测能力。在此基础上，我们提出了一种迭代的PredVAR算法，利用最大似然和期望最大化（EM）框架交替更新潜在动态和最佳斜投影的估计，得到具有排序预测能力的动态潜变量和与外部投影模型一致的显式潜在VAR模型。通过使用合成Lorenz系统和工业数据集，验证了该方法的卓越性能和效率。

    In this paper, we propose a probabilistic reduced-dimensional vector autoregressive (PredVAR) model to extract low-dimensional dynamics from high-dimensional noisy data. The model utilizes an oblique projection to partition the measurement space into a subspace that accommodates the reduced-dimensional dynamics and a complementary static subspace. An optimal oblique decomposition is derived for the best predictability regarding prediction error covariance. Building on this, we develop an iterative PredVAR algorithm using maximum likelihood and the expectation-maximization (EM) framework. This algorithm alternately updates the estimates of the latent dynamics and optimal oblique projection, yielding dynamic latent variables with rank-ordered predictability and an explicit latent VAR model that is consistent with the outer projection model. The superior performance and efficiency of the proposed approach are demonstrated using data sets from a synthesized Lorenz system and an industrial 
    
[^18]: 深度学习的统计理论综述：近似，训练动态和生成模型

    A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models. (arXiv:2401.07187v1 [stat.ML])

    [http://arxiv.org/abs/2401.07187](http://arxiv.org/abs/2401.07187)

    该论文综述了深度学习的统计理论，包括近似方法、训练动态和生成模型。在非参数框架中，结果揭示了神经网络过度风险的快速收敛速率，以及如何通过梯度方法训练网络以找到良好的泛化解决方案。

    

    在这篇文章中，我们从三个角度回顾了关于神经网络统计理论的文献。第一部分回顾了在回归或分类的非参数框架下关于神经网络过度风险的结果。这些结果依赖于神经网络的显式构造，以及采用了近似理论的工具，导致过度风险的快速收敛速率。通过这些构造，可以用样本大小、数据维度和函数平滑性来表达网络的宽度和深度。然而，他们的基本分析仅适用于深度神经网络高度非凸的全局极小值点。这促使我们在第二部分回顾神经网络的训练动态。具体而言，我们回顾了那些试图回答“基于梯度方法训练的神经网络如何找到能够在未见数据上有良好泛化性能的解”的论文。尤其是两个知名的

    In this article, we review the literature on statistical theories of neural networks from three perspectives. In the first part, results on excess risks for neural networks are reviewed in the nonparametric framework of regression or classification. These results rely on explicit constructions of neural networks, leading to fast convergence rates of excess risks, in that tools from the approximation theory are adopted. Through these constructions, the width and depth of the networks can be expressed in terms of sample size, data dimension, and function smoothness. Nonetheless, their underlying analysis only applies to the global minimizer in the highly non-convex landscape of deep neural networks. This motivates us to review the training dynamics of neural networks in the second part. Specifically, we review papers that attempt to answer ``how the neural network trained via gradient-based methods finds the solution that can generalize well on unseen data.'' In particular, two well-know
    
[^19]: 关于群体公平和个体公平之间的（不）兼容性

    On the (In)Compatibility between Group Fairness and Individual Fairness. (arXiv:2401.07174v1 [math.ST])

    [http://arxiv.org/abs/2401.07174](http://arxiv.org/abs/2401.07174)

    论文研究了最优统计平等解和个体公平之间的兼容性，提出了充分条件，并分析了解决冲突的方法。

    

    我们研究了最优统计平等解和个体公平之间的兼容性。虽然个体公平旨在对待类似的个体，最优统计平等则旨在为在各自敏感群体内共享相对相似性的个体提供类似的待遇。这两种公平观点虽然都是公平的角度来看都是可取的，但在应用中往往会发生冲突。我们的目标是分析这种冲突的存在及其潜在解决方案。具体而言，我们建立了充分（尖锐）的条件，使最优（后处理）统计平等 $L^2$ 学习与（$K$-Lipschitz 或 $(\epsilon,\delta)$）个体公平要求之间兼容。此外，在两者之间存在冲突时，我们首先将前者放松为 Pareto 前沿（或等效地说是 $L^2$ 误差和统计偏离之间的最优权衡），然后分析兼容性。

    We study the compatibility between the optimal statistical parity solutions and individual fairness. While individual fairness seeks to treat similar individuals similarly, optimal statistical parity aims to provide similar treatment to individuals who share relative similarity within their respective sensitive groups. The two fairness perspectives, while both desirable from a fairness perspective, often come into conflict in applications. Our goal in this work is to analyze the existence of this conflict and its potential solution. In particular, we establish sufficient (sharp) conditions for the compatibility between the optimal (post-processing) statistical parity $L^2$ learning and the ($K$-Lipschitz or $(\epsilon,\delta)$) individual fairness requirements. Furthermore, when there exists a conflict between the two, we first relax the former to the Pareto frontier (or equivalently the optimal trade-off) between $L^2$ error and statistical disparity, and then analyze the compatibilit
    
[^20]: 从第一原理中的赫布学习

    Hebbian Learning from First Principles. (arXiv:2401.07110v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2401.07110](http://arxiv.org/abs/2401.07110)

    本文从第一原理中得到了赫布学习的明确表达式，并证明了这些学习规则在大数据极限下收敛到原始的存储方案。

    

    最近，针对神经网络的Hopfield模型及其密集概化形式的原始存储方案已通过假设其哈密顿量的表达式为监督和无监督协议，成为真正的赫布学习规则。在本文中，我们首先依靠Jaynes的最大熵极值法得到了这些明确的表达式。除了形式上推导出这些赫布学习的规则，这个构建还突显了熵极值中的朗格朗日约束如何强制网络结果上的神经相关性：这些尝试模仿提供给网络进行训练的数据集中隐藏的经验支持，而且网络越密集，能够捕捉到的相关性时间越长。接下来，我们证明在大数据极限下，无论是否存在教师，这些赫布学习规则都会收敛到原始的存储方案。

    Recently, the original storage prescription for the Hopfield model of neural networks -- as well as for its dense generalizations -- has been turned into a genuine Hebbian learning rule by postulating the expression of its Hamiltonian for both the supervised and unsupervised protocols. In these notes, first, we obtain these explicit expressions by relying upon maximum entropy extremization \`a la Jaynes. Beyond providing a formal derivation of these recipes for Hebbian learning, this construction also highlights how Lagrangian constraints within entropy extremization force network's outcomes on neural correlations: these try to mimic the empirical counterparts hidden in the datasets provided to the network for its training and, the denser the network, the longer the correlations that it is able to capture. Next, we prove that, in the big data limit, whatever the presence of a teacher (or its lacking), not only these Hebbian learning rules converge to the original storage prescription o
    
[^21]: 一种将ADRC融入到随机梯度下降算法中的潜在因子分析方法

    An ADRC-Incorporated Stochastic Gradient Descent Algorithm for Latent Factor Analysis. (arXiv:2401.07012v1 [cs.LG])

    [http://arxiv.org/abs/2401.07012](http://arxiv.org/abs/2401.07012)

    本文提出了一种将ADRC融入到随机梯度下降算法中的潜在因子分析方法，通过改进学习误差的计算方法，提高了模型的收敛速度和准确性。

    

    高维和不完整的矩阵包含着许多复杂的节点间相互作用。基于随机梯度下降（SGD）的潜在因子分析（LFA）模型在从高维不完整的矩阵中提取有价值信息方面非常有效。然而，这样的模型通常会遇到收敛速度慢的问题，因为标准的SGD算法只考虑当前的学习误差来计算随机梯度，而不考虑学习误差的历史和未来状态。为了解决这个关键问题，本文创新性地提出了一种将ADRC融入到SGD算法中的ADS（ADRC-incorporated SGD）算法，通过考虑学习误差的历史和未来状态来改进实例的学习误差，遵循ADRC控制器的原则。基于此，进一步实现了一种基于ADS的LFA模型，用于在高维不完整的矩阵上进行快速准确的潜在因子分析。对两个高维不完整的数据集进行的实证研究表明，所提出的模型在技术性能上优于现有的LFA模型。

    High-dimensional and incomplete (HDI) matrix contains many complex interactions between numerous nodes. A stochastic gradient descent (SGD)-based latent factor analysis (LFA) model is remarkably effective in extracting valuable information from an HDI matrix. However, such a model commonly encounters the problem of slow convergence because a standard SGD algorithm only considers the current learning error to compute the stochastic gradient without considering the historical and future state of the learning error. To address this critical issue, this paper innovatively proposes an ADRC-incorporated SGD (ADS) algorithm by refining the instance learning error by considering the historical and future state by following the principle of an ADRC controller. With it, an ADS-based LFA model is further achieved for fast and accurate latent factor analysis on an HDI matrix. Empirical studies on two HDI datasets demonstrate that the proposed model outperforms the state-of-the-art LFA models in te
    
[^22]: 用结构因果模型对潜在选择进行建模

    Modeling Latent Selection with Structural Causal Models. (arXiv:2401.06925v1 [cs.AI])

    [http://arxiv.org/abs/2401.06925](http://arxiv.org/abs/2401.06925)

    本文介绍了一种在结构因果模型中对潜在选择进行建模的方法，并展示了它如何帮助进行因果推理任务，包括处理选择偏差。

    

    选择偏倚在现实世界的数据中是普遍存在的，如果不正确处理可能导致误导性结果。我们引入了对结构因果模型（SCMs）进行条件操作的方法，以从因果的角度对潜在选择进行建模。我们展示了条件操作将具有明确潜在选择机制的SCM转换为没有此类选择机制的SCM，这在一定程度上编码了根据原始SCM选择的亚总体的因果语义。此外，我们还展示了该条件操作保持SCMs的简洁性，无环性和线性性，并与边际化操作相符合。由于这些特性与边际化和干预结合起来，条件操作为在潜在细节已经去除的因果模型中进行因果推理任务提供了一个有价值的工具。我们通过例子演示了如何将因果推断的经典结果推广以包括选择偏倚。

    Selection bias is ubiquitous in real-world data, and can lead to misleading results if not dealt with properly. We introduce a conditioning operation on Structural Causal Models (SCMs) to model latent selection from a causal perspective. We show that the conditioning operation transforms an SCM with the presence of an explicit latent selection mechanism into an SCM without such selection mechanism, which partially encodes the causal semantics of the selected subpopulation according to the original SCM. Furthermore, we show that this conditioning operation preserves the simplicity, acyclicity, and linearity of SCMs, and commutes with marginalization. Thanks to these properties, combined with marginalization and intervention, the conditioning operation offers a valuable tool for conducting causal reasoning tasks within causal models where latent details have been abstracted away. We demonstrate by example how classical results of causal inference can be generalized to include selection b
    
[^23]: 使用深度强化学习进行Open RAN LSTM流量预测和切片管理

    Open RAN LSTM Traffic Prediction and Slice Management using Deep Reinforcement Learning. (arXiv:2401.06922v1 [cs.LG])

    [http://arxiv.org/abs/2401.06922](http://arxiv.org/abs/2401.06922)

    本文提出了一种使用深度强化学习进行Open RAN LSTM流量预测和切片管理的方法，在保持服务质量的前提下，通过利用分布式单元的异构经验和预测模型的辅助信息，显著改善了网络性能。

    

    随着自动驾驶、智慧城市和智能工厂等新兴应用的出现，网络切片成为5G及以上网络中满足面向服务的网络需求的关键组成部分。然而，在动态环境中管理不同的网络切片并保持服务质量(QoS)是一个挑战。为解决这个问题，本文利用ORAN系统中分布式单元(DUs)的异构经验，引入了一种使用分布式深度强化学习(DDRL)的ORAN切片xApp的新方法。此外，为了提高强化学习代理的决策性能，还引入了基于长短期记忆(LSTM)的预测rApp，从动态环境中提供额外信息给xApp。模拟结果表明网络性能有了显著的改进，尤其在降低QoS违规方面表现出色。这凸显了使用预测rApp和分布式actor的重要性。

    With emerging applications such as autonomous driving, smart cities, and smart factories, network slicing has become an essential component of 5G and beyond networks as a means of catering to a service-aware network. However, managing different network slices while maintaining quality of services (QoS) is a challenge in a dynamic environment. To address this issue, this paper leverages the heterogeneous experiences of distributed units (DUs) in ORAN systems and introduces a novel approach to ORAN slicing xApp using distributed deep reinforcement learning (DDRL). Additionally, to enhance the decision-making performance of the RL agent, a prediction rApp based on long short-term memory (LSTM) is incorporated to provide additional information from the dynamic environment to the xApp. Simulation results demonstrate significant improvements in network performance, particularly in reducing QoS violations. This emphasizes the importance of using the prediction rApp and distributed actors' inf
    
[^24]: 使用DAGs的深度学习

    Deep Learning With DAGs. (arXiv:2401.06864v1 [stat.ML])

    [http://arxiv.org/abs/2401.06864](http://arxiv.org/abs/2401.06864)

    本文介绍了一种使用深度神经网络来对因果图进行实证评估的新方法。这种方法称为因果图标准化流(cGNFs)，通过使用DAGs表示理论，并避免功能形式的假设，来更准确地捕捉因果系统的复杂性。

    

    社会科学理论经常假设一组变量或事件之间存在因果关系。尽管有向无环图(DAGs)越来越多地被用来表示这些理论，但它们在实践中的全部潜力尚未得到实现。作为非参数因果模型，DAGs不需要关于假设关系的功能形式的任何假设。然而，为了简化实证评估的任务，研究人员倾向于无论如何激活这些假设，尽管它们通常是任意的，不反映任何理论内容或先前知识。此外，功能形式的假设可能导致偏见，因为它们未能准确捕捉研究中因果系统的复杂性。在本文中，我们介绍了一种名为因果图标准化流(cGNFs)的新方法，该方法利用深度神经网络来对表示为DAGs的理论进行实证评估。与传统方法不同，cGNFs模拟了全联合概率。

    Social science theories often postulate causal relationships among a set of variables or events. Although directed acyclic graphs (DAGs) are increasingly used to represent these theories, their full potential has not yet been realized in practice. As non-parametric causal models, DAGs require no assumptions about the functional form of the hypothesized relationships. Nevertheless, to simplify the task of empirical evaluation, researchers tend to invoke such assumptions anyway, even though they are typically arbitrary and do not reflect any theoretical content or prior knowledge. Moreover, functional form assumptions can engender bias, whenever they fail to accurately capture the complexity of the causal system under investigation. In this article, we introduce causal-graphical normalizing flows (cGNFs), a novel approach to causal inference that leverages deep neural networks to empirically evaluate theories represented as DAGs. Unlike conventional approaches, cGNFs model the full joint
    
[^25]: 一种用于跳跃扩散模型期权定价的深度隐式-显式最小移动方法

    A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models. (arXiv:2401.06740v1 [q-fin.CP])

    [http://arxiv.org/abs/2401.06740](http://arxiv.org/abs/2401.06740)

    这份论文介绍了一种用于定价跳跃扩散模型下欧式篮式期权的深度学习方法，采用了隐式-显式最小移动方法以及残差型人工神经网络逼近，并通过稀疏网格高斯-埃尔米特逼近和基于ANN的高维专用求积规则来离散化积分运算符。

    

    我们提出了一种新颖的深度学习方法，用于定价跳跃扩散动态下的欧式篮式期权。将期权定价问题表述为一个偏积分微分方程，并通过一种新的隐式-显式最小移动时间步法进行近似，该方法使用深度残差型人工神经网络（ANNs）逐步逼近。积分运算符通过两种不同的方法离散化：a）通过稀疏网格高斯-埃尔米特逼近，采用奇异值分解产生的局部坐标轴，并且b）通过基于ANN的高维专用求积规则。关键是，所提出的ANN的构造确保了解决方案在标的资产较大值时的渐近行为，并且与解决方案先验已知的定性特性相一致输出。对方法维度的性能和鲁棒性进行了评估。

    We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assesse
    
[^26]: 使用具有规范等变性的卷积神经网络机器学习SU（3）规范理论的固定点作用

    Machine learning a fixed point action for SU(3) gauge theory with a gauge equivariant convolutional neural network. (arXiv:2401.06481v1 [hep-lat] CROSS LISTED)

    [http://arxiv.org/abs/2401.06481](http://arxiv.org/abs/2401.06481)

    本研究使用具有精确规范不变性的卷积神经网络，通过机器学习方法找到了四维SU（3）规范理论的优秀固定点作用的参数化方法，为未来的蒙特卡洛模拟打下了必要的基础。

    

    固定点的格子作用被设计成具有不受离散化效应影响的连续经典性质，并在量子层面上减少格子效应。它们提供了一种用较粗的格子来提取连续物理的可能方法，从而绕过与连续极限相关的临界减慢和拓扑冻结问题。实际应用的关键是找到一个精确且紧凑的固定点作用参数化方法，因为其许多性质只是隐含定义的。在这里，我们使用机器学习方法重新思考了如何参数化固定点作用的问题。特别地，我们使用具有精确规范不变性的卷积神经网络获得四维SU（3）规范理论的固定点作用。大的算子空间使我们能够找到比之前研究更好的参数化方法，这是未来蒙特卡洛模拟的必要第一步。

    Fixed point lattice actions are designed to have continuum classical properties unaffected by discretization effects and reduced lattice artifacts at the quantum level. They provide a possible way to extract continuum physics with coarser lattices, thereby allowing to circumvent problems with critical slowing down and topological freezing toward the continuum limit. A crucial ingredient for practical applications is to find an accurate and compact parametrization of a fixed point action, since many of its properties are only implicitly defined. Here we use machine learning methods to revisit the question of how to parametrize fixed point actions. In particular, we obtain a fixed point action for four-dimensional SU(3) gauge theory using convolutional neural networks with exact gauge invariance. The large operator space allows us to find superior parametrizations compared to previous studies, a necessary first step for future Monte Carlo simulations.
    
[^27]: 基于树的可变系数模型介绍

    A tree-based varying coefficient model. (arXiv:2401.05982v1 [stat.ML])

    [http://arxiv.org/abs/2401.05982](http://arxiv.org/abs/2401.05982)

    本论文介绍了一种基于树的可变系数模型，使用循环梯度提升机进行建模，实现了逐维早停和特征重要性评分，该模型能够产生与基于神经网络的VCM相当的结果。

    

    本论文介绍了一种基于树的可变系数模型(VCM)，其中可变系数使用Delong等人(2023)的循环梯度提升机(CGBM)进行建模。使用CGBM对系数函数进行建模，可以进行逐维早停和特征重要性评分。逐维早停不仅可以减少维度特定的过拟合风险，还可以揭示维度之间模型复杂性的差异。使用特征重要性评分可以进行简单的特征选择和易于解释的模型解释。该模型在Richman和Wüthrich（2023）使用的相同的模拟和真实数据示例上进行评估，结果表明，它在样本外损失方面产生了与他们的基于神经网络的VCM LocalGLMnet相当的结果。

    The paper introduces a tree-based varying coefficient model (VCM) where the varying coefficients are modelled using the cyclic gradient boosting machine (CGBM) from Delong et al. (2023). Modelling the coefficient functions using a CGBM allows for dimension-wise early stopping and feature importance scores. The dimension-wise early stopping not only reduces the risk of dimension-specific overfitting, but also reveals differences in model complexity across dimensions. The use of feature importance scores allows for simple feature selection and easy model interpretation. The model is evaluated on the same simulated and real data examples as those used in Richman and W\"uthrich (2023), and the results show that it produces results in terms of out of sample loss that are comparable to those of their neural network-based VCM called LocalGLMnet.
    
[^28]: 迭代正则化与k支撑范数：稀疏恢复的重要补充

    Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])

    [http://arxiv.org/abs/2401.05394](http://arxiv.org/abs/2401.05394)

    该论文介绍了一种新的迭代正则化算法IRKSN，它通过使用$k$支撑范数正则化实现稀疏恢复，并提供了条件。这是对基于$\ell_1$范数的迭代方法的一种重要补充。

    

    稀疏恢复在机器学习和信号处理中无处不在。由于稀疏恢复的NP困难性质，现有方法通常要么受限于适用条件（甚至未知），要么计算成本高。最近，迭代正则化方法作为一种快速方法出现，因为它们可以通过提前停止一次通过来实现稀疏恢复，而不是传统方法中繁琐的网格搜索。然而，大多数这些迭代方法都基于$\ell_1$范数，需要受限的适用条件，并且在许多情况下可能会失败。因此，迭代正则化方法在更广泛的条件下实现稀疏恢复仍需进一步探索。为了解决这个问题，我们提出了一种新的迭代正则化算法IRKSN，它基于$k$支撑范数正则化而不是$\ell_1$范数。我们提供了使用IRKSN进行稀疏恢复的条件，并进行了比较。

    Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar
    
[^29]: 基于神经算子流的量子场论多格采样方法

    Multi-Lattice Sampling of Quantum Field Theories via Neural Operator-based Flows. (arXiv:2401.00828v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.00828](http://arxiv.org/abs/2401.00828)

    本文提出了一种基于神经算子流的方法，通过近似时间相关算子，实现了在量子场论中从底层自由理论到目标理论的离散-连续归一化流。

    

    本文考虑从玻尔兹曼分布中采样离散场配置$\phi$的问题，其中$S$是某个量子场论连续欧几里得作用$\mathcal S$的格点离散化。我们将该密度近似视为底层函数密度$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$的学习算子实例。具体而言，我们提出了近似时间相关算子$\mathcal V_t$的方法，其时间积分提供了自由理论$[\mathcal D\phi(x)]\mathcal Z_0^{-1}e^{-\mathcal S_{0}[\phi(x)]}$的函数分布与目标理论$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$之间的映射。当选择特定的格点时，算子$\mathcal V_t$可以离散化为有限维的时间相关矢量场$V_t$，从而在离散格点上实现了连续的归一化流。

    We consider the problem of sampling discrete field configurations $\phi$ from the Boltzmann distribution $[d\phi] Z^{-1} e^{-S[\phi]}$, where $S$ is the lattice-discretization of the continuous Euclidean action $\mathcal S$ of some quantum field theory. Since such densities arise as the approximation of the underlying functional density $[\mathcal D\phi(x)] \mathcal Z^{-1} e^{-\mathcal S[\phi(x)]}$, we frame the task as an instance of operator learning. In particular, we propose to approximate a time-dependent operator $\mathcal V_t$ whose time integral provides a mapping between the functional distributions of the free theory $[\mathcal D\phi(x)] \mathcal Z_0^{-1} e^{-\mathcal S_{0}[\phi(x)]}$ and of the target theory $[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$. Whenever a particular lattice is chosen, the operator $\mathcal V_t$ can be discretized to a finite dimensional, time-dependent vector field $V_t$ which in turn induces a continuous normalizing flow between fi
    
[^30]: 使用随机子空间和Dirichlet过程混合模型的子抽样集合进行无监督异常检测

    Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures. (arXiv:2401.00773v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.00773](http://arxiv.org/abs/2401.00773)

    提出一种基于随机子空间和子抽样集合的Dirichlet过程高斯混合模型的无监督异常检测方法，提高了计算效率和检测器的鲁棒性。

    

    概率混合模型被认为是一种有价值的工具，用于无监督异常检测，因为它们具有解释性，并且在统计原理上有直观基础。在这个框架内，Dirichlet过程混合模型作为传统有限混合模型在聚类和异常检测任务中的一个引人注目的替代选择。然而，尽管它们明显具有优势，但在无监督异常检测中广泛采用Dirichlet过程混合模型受到与构建检测器过程中的计算效率和对异常值的敏感性有关的挑战的阻碍。为了解决这些挑战，我们提出了一种基于Dirichlet过程高斯混合模型集合的新型异常检测方法。所提出的方法是一种完全无监督的算法，利用了随机子空间和子抽样集合，不仅确保了高效计算，还增强了结果异常检测器的鲁棒性。

    Probabilistic mixture models are acknowledged as a valuable tool for unsupervised outlier detection owing to their interpretability and intuitive grounding in statistical principles. Within this framework, Dirichlet process mixture models emerge as a compelling alternative to conventional finite mixture models for both clustering and outlier detection tasks. However, despite their evident advantages, the widespread adoption of Dirichlet process mixture models in unsupervised outlier detection has been hampered by challenges related to computational inefficiency and sensitivity to outliers during the construction of detectors. To tackle these challenges, we propose a novel outlier detection method based on ensembles of Dirichlet process Gaussian mixtures. The proposed method is a fully unsupervised algorithm that capitalizes on random subspace and subsampling ensembles, not only ensuring efficient computation but also enhancing the robustness of the resulting outlier detector. Moreover,
    
[^31]: 利用公共表示来进行私有迁移学习

    Leveraging Public Representations for Private Transfer Learning. (arXiv:2312.15551v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.15551](http://arxiv.org/abs/2312.15551)

    该论文探讨了如何利用公共数据来改进私有学习的问题。研究发现，通过学习公共数据中的共享表示，可以在两种迁移学习场景中实现最优的学习效果。在单任务迁移场景中，算法在给定子空间范围内搜索线性模型，并实现了最优超额风险。在多任务个性化场景中，足够的公共数据可以消除私有协调需求，并通过纯局部学习达到相同的效用。

    

    受到将公共数据纳入差分隐私学习的最新实证成功的启发，我们在理论上研究了从公共数据中学到的共享表示如何改进私有学习。我们探讨了线性回归的两种常见迁移学习场景，两者都假设公共任务和私有任务（回归向量）在高维空间中共享一个低秩子空间。在第一种单任务迁移场景中，目标是学习一个在所有用户之间共享的单一模型，每个用户对应数据集中的一行。我们提供了匹配的上下界，证明了我们的算法在给定子空间估计范围内搜索线性模型的算法类中实现了最优超额风险。在多任务模型个性化的第二种情景中，我们表明在有足够的公共数据情况下，用户可以避免私有协调，因为在给定子空间内纯粹的局部学习可以达到相同的效用。

    Motivated by the recent empirical success of incorporating public data into differentially private learning, we theoretically investigate how a shared representation learned from public data can improve private learning. We explore two common scenarios of transfer learning for linear regression, both of which assume the public and private tasks (regression vectors) share a low-rank subspace in a high-dimensional space. In the first single-task transfer scenario, the goal is to learn a single model shared across all users, each corresponding to a row in a dataset. We provide matching upper and lower bounds showing that our algorithm achieves the optimal excess risk within a natural class of algorithms that search for the linear model within the given subspace estimate. In the second scenario of multitask model personalization, we show that with sufficient public data, users can avoid private coordination, as purely local learning within the given subspace achieves the same utility. Take
    
[^32]: 准确建模随机微分方程的时间变换正则化流

    Time-changed normalizing flows for accurate SDE modeling. (arXiv:2312.14698v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.14698](http://arxiv.org/abs/2312.14698)

    本论文提出了一种新的动态正则化流的变种，即时间变换正则化流(TCNF)，通过时间变形的方法能有效地建模一些无法用其他方法建模的随机微分方程(SDEs)，包括著名的奥恩斯坦-乌伦贝克过程，并泛化了先前的方法，从而提高了结果的准确度和推断和预测的精度。

    

    生成范式在机器学习和深度学习模型中变得越来越重要。其中流行的生成模型之一是正则化流，通过微分同胚变换将基本分布转变为准确估计的似然函数。将正则化流框架扩展到处理时间索引流产生动态正则化流，这是一种用于模拟时间序列、随机过程和神经随机微分方程(SDEs)的强大工具。在这项工作中，我们提出了一种新颖的动态正则化流变体，即时间变换正则化流(TCNF)，它基于布朗运动的时间变形，构成了一族多才多艺的高斯过程。这种方法使我们能够有效地模拟一些无法使用其他方法建模的SDEs，包括著名的奥恩斯坦-乌伦贝克过程以及泛化了先前的方法，从而提供了改进的结果和更好的推断和预测能力。

    The generative paradigm has become increasingly important in machine learning and deep learning models. Among popular generative models are normalizing flows, which enable exact likelihood estimation by transforming a base distribution through diffeomorphic transformations. Extending the normalizing flow framework to handle time-indexed flows gave dynamic normalizing flows, a powerful tool to model time series, stochastic processes, and neural stochastic differential equations (SDEs). In this work, we propose a novel variant of dynamic normalizing flows, a Time Changed Normalizing Flow (TCNF), based on time deformation of a Brownian motion which constitutes a versatile and extensive family of Gaussian processes. This approach enables us to effectively model some SDEs, that cannot be modeled otherwise, including standard ones such as the well-known Ornstein-Uhlenbeck process, and generalizes prior methodologies, leading to improved results and better inference and prediction capability.
    
[^33]: 集合卡尔曼滤波与高斯过程状态空间模型在非均场和在线推理中的应用

    Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference. (arXiv:2312.05910v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.05910](http://arxiv.org/abs/2312.05910)

    这篇论文介绍了一种将集合卡尔曼滤波引入变分推理框架的方法，用于近似高斯过程状态空间模型的后验分布，并且有效地利用了潜在状态和动力学之间的依赖关系，减少了变分参数的数量。

    

    高斯过程状态空间模型（GPSSMs）是一种多功能和原则性的非线性动态系统模型。然而，现有的GPSSMs变分学习和推理方法通常需要优化大量变分参数，导致性能和效率不足。为了解决这个问题，我们提出将集合卡尔曼滤波（EnKF），一种成熟的基于模型的滤波技术，纳入变分推理框架中，以近似潜在状态的后验分布。这种利用EnKF的方法可以有效地利用潜在状态和GP动力学之间的依赖关系，同时消除了对变分分布进行参数化的需求，从而显著减少了变分参数的数量。此外，我们还展示了我们提出的算法可以通过简单地对多个项进行求和来直接评估变分推理中的近似证据下界（ELBO）。

    Gaussian process state-space models (GPSSMs) are a versatile and principled family of nonlinear dynamical system models. However, existing variational learning and inference methods for GPSSMs often necessitate optimizing a substantial number of variational parameters, leading to inadequate performance and efficiency. To overcome this issue, we propose incorporating the ensemble Kalman filter (EnKF), a well-established model-based filtering technique, into the variational inference framework to approximate the posterior distribution of latent states. This utilization of EnKF can effectively exploit the dependencies between latent states and GP dynamics, while eliminating the need for parameterizing the variational distribution, thereby significantly reducing the number of variational parameters. Moreover, we show that our proposed algorithm allows straightforward evaluation of an approximated evidence lower bound (ELBO) in variational inference via simply summating multiple terms with 
    
[^34]: 可证明的对称任务的对抗鲁棒性：图形、点云、分子等

    Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More. (arXiv:2312.02708v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.02708](http://arxiv.org/abs/2312.02708)

    本文提出了一种考虑任务对称性的可证明的对抗鲁棒性概念，并通过选择合适的模型和认证方法来实现鲁棒性。同时，通过开发保持对称性的随机平滑的框架，解决了对于具有连续对称性的模型的认证方法不可用的问题。

    

    传统上，机器学习模型被认为在输入扰动的情况下保持（几乎）恒定的预测是健壮的。然而，现实世界中的任务，如分子性质预测或点云分割，具有固有的对称性，如旋转或置换对称性。在这些任务中，即使是具有大范数的扰动也不一定会改变输入的语义内容。此外，有些扰动需要明确改变模型的预测。我们首次提出了一种考虑任务对称性的可靠对抗鲁棒性概念。然后，我们证明了可以通过选择与任务对称性相匹配的模型和认证传统的对抗鲁棒性来实现可证明的鲁棒性。然而，对于许多具有连续对称性的模型，认证方法不可用。通过开发保持对称性的随机平滑的框架，我们填补了这个空白。

    A machine learning model is traditionally considered robust if its prediction remains (almost) constant under input perturbations with small norm. However, real-world tasks like molecular property prediction or point cloud segmentation have inherent equivariances, such as rotation or permutation equivariance. In such tasks, even perturbations with large norm do not necessarily change an input's semantic content. Furthermore, there are perturbations for which a model's prediction explicitly needs to change. For the first time, we propose a sound notion of adversarial robustness that accounts for task equivariance. We then demonstrate that provable robustness can be achieved by (1) choosing a model that matches the task's equivariances (2) certifying traditional adversarial robustness. Certification methods are, however, unavailable for many models, such as those with continuous equivariances. We close this gap by developing the framework of equivariance-preserving randomized smoothing, 
    
[^35]: 在多元函数回归中的系数形状对齐

    Coefficient Shape Alignment in Multivariate Functional Regression. (arXiv:2312.01925v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2312.01925](http://arxiv.org/abs/2312.01925)

    该论文提出了一种新的分组多元函数回归模型，其中采用了一种新的正则化方法来解决不同函数协变量的潜在同质性问题。

    

    在多元函数数据分析中，不同的函数协变量可能具有同质性。隐藏的同质性结构对于不同协变量的连接或关联具有信息价值。具有明显同质性的协变量可以在同一群组中进行联合分析，从而产生一种简化建模多元函数数据的方法。本文提出了一种新颖的分组多元函数回归模型，采用称为“系数形状对齐”的新正则化方法来解决不同函数协变量的潜在同质性问题。建模过程包括两个主要步骤：首先，使用新的正则化方法检测未知分组结构，将协变量聚合到不相交的群组中；然后，基于检测到的分组结构建立分组多元函数回归模型。在这个新的分组模型中，同一同质群组中的系数函数应对齐。

    In multivariate functional data analysis, different functional covariates can be homogeneous. The hidden homogeneity structure is informative about the connectivity or association of different covariates. The covariates with pronounced homogeneity can be analyzed jointly within the same group, which gives rise to a way of parsimoniously modeling multivariate functional data. In this paper, a novel grouped multivariate functional regression model with a new regularization approach termed "coefficient shape alignment" is developed to tackle the potential homogeneity of different functional covariates. The modeling procedure includes two main steps: first detect the unknown grouping structure with the new regularization approach to aggregate covariates into disjoint groups; and then the grouped multivariate functional regression model is established based on the detected grouping structure. In this new grouped model, the coefficient functions of covariates in the same homogeneous group sh
    
[^36]: Bayesian网络的熵和Kullback-Leibler散度：计算复杂度和高效实现

    Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation. (arXiv:2312.01520v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.01520](http://arxiv.org/abs/2312.01520)

    本文提出了一种计算贝叶斯网络中Shannon熵和Kullback-Leibler散度的高效算法，并通过一系列数值示例进行了演示。此外，还展示了如何将高斯贝叶斯网络中KL的计算复杂度从立方降低到二次。

    

    贝叶斯网络（BNs）是机器学习和因果推断中的基础模型。它们的图结构可以处理高维问题，并将其分为稀疏的一系列较小问题，这是Judea Pearl的因果性的基础，也决定了它们的可解释性和可理解性。尽管它们很受欢迎，但在文献中几乎没有关于如何在最常见的分布假设下计算BNs的Shannon熵和Kullback-Leibler（KL）散度的资源。在本文中，我们利用BNs的图结构提供了计算效率高的算法，并用一整套数值示例说明了它们。在此过程中，我们展示了可以将高斯BNs的KL计算复杂度从立方降低到二次的可能性。

    Bayesian networks (BNs) are a foundational model in machine learning and causal inference. Their graphical structure can handle high-dimensional problems, divide them into a sparse collection of smaller ones, underlies Judea Pearl's causality, and determines their explainability and interpretability. Despite their popularity, there are almost no resources in the literature on how to compute Shannon's entropy and the Kullback-Leibler (KL) divergence for BNs under their most common distributional assumptions. In this paper, we provide computationally efficient algorithms for both by leveraging BNs' graphical structure, and we illustrate them with a complete set of numerical examples. In the process, we show it is possible to reduce the computational complexity of KL from cubic to quadratic for Gaussian BNs.
    
[^37]: 《$\mathbb{Z}_2\times \mathbb{Z}_2$》等变量量子神经网络：与经典神经网络的基准比较

    $\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks. (arXiv:2311.18744v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2311.18744](http://arxiv.org/abs/2311.18744)

    本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与经典神经网络的性能进行了全面比较分析，结果表明《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上表现优越。

    

    本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与它们的经典对应物：等变量神经网络（ENN）和深度神经网络（DNN）的性能进行了全面比较分析。我们通过两个二元分类任务的玩具示例评估每个网络的性能，关注模型复杂度（由参数数量测量）和训练数据集的大小。我们的结果显示，《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上提供了更优秀的性能。

    This paper presents a comprehensive comparative analysis of the performance of Equivariant Quantum Neural Networks (EQNN) and Quantum Neural Networks (QNN), juxtaposed against their classical counterparts: Equivariant Neural Networks (ENN) and Deep Neural Networks (DNN). We evaluate the performance of each network with two toy examples for a binary classification task, focusing on model complexity (measured by the number of parameters) and the size of the training data set. Our results show that the $\mathbb{Z}_2\times \mathbb{Z}_2$ EQNN and the QNN provide superior performance for smaller parameter sets and modest training data samples.
    
[^38]: 从卷积神经网络中获得的固定点作用

    Fixed point actions from convolutional neural networks. (arXiv:2311.17816v1 [hep-lat] CROSS LISTED)

    [http://arxiv.org/abs/2311.17816](http://arxiv.org/abs/2311.17816)

    本研究使用晶格规范等变卷积神经网络（L-CNN）描述了基于重整化群变换的固定点作用（FP），这种方法更准确地参数化FP作用，可以规避临界减速和拓扑冻结问题，并在粗晶格上产生具有非常小晶格效应的物理预测。

    

    晶格规范等变卷积神经网络（L-CNN）可用于形成任意形状的Wilson环，并且可以近似晶格上的任何规范依变或规范不变函数。在这里，我们使用L-CNN来描述基于重整化群变换的固定点（FP）作用。FP作用在经典规范场满足运动方程的情况下是经典完美的，即它们没有晶格效应，并且具有尺度不变的瞬子解。FP作用在晶格间距的所有阶层中都是树级Symanzik改进的，即使在粗晶格上也能产生具有非常小晶格效应的物理预测。我们发现与较旧的方法相比，L-CNN在参数化FP作用方面更准确。因此，它们可能提供一种规避临界减速和拓扑冻结以接近连续极限的方法。

    Lattice gauge-equivariant convolutional neural networks (L-CNNs) can be used to form arbitrarily shaped Wilson loops and can approximate any gauge-covariant or gauge-invariant function on the lattice. Here we use L-CNNs to describe fixed point (FP) actions which are based on renormalization group transformations. FP actions are classically perfect, i.e., they have no lattice artifacts on classical gauge-field configurations satisfying the equations of motion, and therefore possess scale invariant instanton solutions. FP actions are tree-level Symanzik-improved to all orders in the lattice spacing and can produce physical predictions with very small lattice artifacts even on coarse lattices. We find that L-CNNs are much more accurate at parametrizing the FP action compared to older approaches. They may therefore provide a way to circumvent critical slowing down and topological freezing towards the continuum limit.
    
[^39]: 最小范数浅层去噪器在函数空间中的表现如何？

    How do Minimum-Norm Shallow Denoisers Look in Function Space?. (arXiv:2311.06748v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2311.06748](http://arxiv.org/abs/2311.06748)

    研究了最小范数浅层去噪器在函数空间中的表现，推导出一元数据和多元数据上的闭合形式，并发现其具有收缩性和较好的泛化能力。

    

    神经网络去噪器（NN去噪器）是许多常见任务中的基本构建块，从图像重建到图像生成。然而，从理论角度来看，这些模型的成功尚不明确。本文旨在描述浅层ReLU NN去噪器实现的函数特性--在插值的常见理论设置下（即零训练损失）以及最小表示成本（即最小的l^2范数权重）。首先，对于一元数据，我们导出了NN去噪器函数的闭合形式，发现它对干净数据点具有收缩性，并证明在低噪声水平下它比经验MMSE估计器更好地泛化。接下来，对于多元数据，我们在多种几何假设下找到了闭合形式的NN去噪器函数：数据包含在低维子空间中，数据包含在单向射线的并集中，或者多种类型的简单形状。这些函数分解为一个和的形式。

    Neural network (NN) denoisers are an essential building block in many common tasks, ranging from image reconstruction to image generation. However, the success of these models is not well understood from a theoretical perspective. In this paper, we aim to characterize the functions realized by shallow ReLU NN denoisers -- in the common theoretical setting of interpolation (i.e., zero training loss) with a minimal representation cost (i.e., minimal $\ell^2$ norm weights). First, for univariate data, we derive a closed form for the NN denoiser function, find it is contractive toward the clean data points, and prove it generalizes better than the empirical MMSE estimator at a low noise level. Next, for multivariate data, we find the NN denoiser functions in a closed form under various geometric assumptions on the training data: data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or several types of simplexes. These functions decompose into a sum of s
    
[^40]: 用稀疏添加机制移位变分自动编码器对细胞扰动进行建模

    Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder. (arXiv:2311.02794v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2311.02794](http://arxiv.org/abs/2311.02794)

    本研究提出了一种稀疏添加机制移位变分自动编码器（SAMS-VAE），用于建模细胞的扰动情况，并结合复合性、解缠和可解释性。通过稀疏化处理全局潜变量，SAMS-VAE能够识别出特定于干扰的潜在子空间，并在多个任务上进行了定量和定性评估。

    

    近年来，针对干预下观测数据的生成模型在机器学习和科学领域引起了广泛关注。例如，在药物发现中，需要对细胞的多种干预效应进行建模，以揭示未知的生物作用机制。我们提出了稀疏添加机制移位变分自动编码器（SAMS-VAE），以组合复合性、解缠和可解释性进行扰动模型。SAMS-VAE将扰动样本的潜在状态建模为一个局部潜在变量和稀疏全局变量之和，用于捕捉样本特定的变化和潜在干预效应。关键是，SAMS-VAE通过对各个干预的全局潜变量进行稀疏化处理，从而识别出解缠的、干扰特定的潜在子空间，这些子空间具有灵活的组合性。我们在两个流行的单细胞测序数据集上定量和定性评估了SAMS-VAE的性能。

    Generative models of observations under interventions have been a vibrant topic of interest across machine learning and the sciences in recent years. For example, in drug discovery, there is a need to model the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action. We propose the Sparse Additive Mechanism Shift Variational Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and interpretability for perturbation models. SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects. Crucially, SAMS-VAE sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable. We evaluate SAMS-VAE both quantitatively and qualitatively on a range of tasks using two popular single cell sequencing datasets. In 
    
[^41]: 学生网络是否应该复制或平均教师权重？

    Should Under-parameterized Student Networks Copy or Average Teacher Weights?. (arXiv:2311.01644v1 [cs.LG])

    [http://arxiv.org/abs/2311.01644](http://arxiv.org/abs/2311.01644)

    这项研究探讨了在欠参数化情况下，学生网络是否应该复制教师神经元或平均一组教师神经元的权重。研究发现对于特定的网络结构和输入分布，当教师网络的输入向量正交且输出权重为酉时，复制-平均配置将达到优化结果，其中大部分学生神经元复制一个教师神经元，最后一个学生神经元对所有教师神经元取平均值。

    

    任何连续函数 $f^*$ 都可以用足够多的神经元 $k$来近似。我们考虑 $f^*$ 本身是一个具有一个隐藏层和 $k$ 个神经元的神经网络的情况。用具有 $n<k$ 个神经元的神经网络来逼近 $f^*$ 可以看作是将一个欠参数化的“学生”网络与 $k$ 个神经元的“教师”网络进行拟合。由于学生具有较少的神经元，所以不清楚每个 $n$ 个学生神经元应该复制一个教师神经元还是平均一组教师神经元。对于具有 erf 激活函数和标准高斯输入分布的浅层神经网络，我们证明了当教师的输入向量是正交的并且输出权重是酉的时候，“复制-平均”配置是临界点。此外，在这样的配置中，优化结果是当 $n-1$ 个学生神经元分别复制一个教师神经元，并且第 $n$ 个学生神经元是所有教师神经元的平均。

    Any continuous function $f^*$ can be approximated arbitrarily well by a neural network with sufficiently many neurons $k$. We consider the case when $f^*$ itself is a neural network with one hidden layer and $k$ neurons. Approximating $f^*$ with a neural network with $n< k$ neurons can thus be seen as fitting an under-parameterized "student" network with $n$ neurons to a "teacher" network with $k$ neurons. As the student has fewer neurons than the teacher, it is unclear, whether each of the $n$ student neurons should copy one of the teacher neurons or rather average a group of teacher neurons. For shallow neural networks with erf activation function and for the standard Gaussian input distribution, we prove that "copy-average" configurations are critical points if the teacher's incoming vectors are orthonormal and its outgoing weights are unitary. Moreover, the optimum among such configurations is reached when $n-1$ student neurons each copy one teacher neuron and the $n$-th student ne
    
[^42]: The Memory Perturbation Equation: Understanding Model's Sensitivity to Data（理解模型对数据的敏感性的记忆扰动方程）

    The Memory Perturbation Equation: Understanding Model's Sensitivity to Data. (arXiv:2310.19273v1 [cs.LG])

    [http://arxiv.org/abs/2310.19273](http://arxiv.org/abs/2310.19273)

    这个论文介绍了记忆扰动方程（MPE），该方程通过应用贝叶斯原理将模型的敏感性与训练数据的扰动联系起来，并且能够准确预测模型在未见测试数据上的泛化能力。

    

    理解模型对其训练数据的敏感性对于训练过程至关重要，但也可能具有挑战性和成本高昂。为了简化这类问题，我们提出了记忆扰动方程（MPE），它将模型的敏感性与其训练数据的扰动联系起来。使用贝叶斯原理导出的MPE将现有的敏感性度量统一起来，泛化到各种模型和算法，并揭示了有关敏感性的有用性质。我们的实证结果表明，训练过程中获得的敏感性估计可以准确预测在未见测试数据上的泛化能力。该提出的方程预计将对未来的鲁棒和自适应学习研究有用。

    Understanding model's sensitivity to its training data is crucial but can also be challenging and costly, especially during training. To simplify such issues, we present the Memory-Perturbation Equation (MPE) which relates model's sensitivity to perturbation in its training data. Derived using Bayesian principles, the MPE unifies existing sensitivity measures, generalizes them to a wide-variety of models and algorithms, and unravels useful properties regarding sensitivities. Our empirical results show that sensitivity estimates obtained during training can be used to faithfully predict generalization on unseen test data. The proposed equation is expected to be useful for future research on robust and adaptive learning.
    
[^43]: 分层随机平滑

    Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])

    [http://arxiv.org/abs/2310.16221](http://arxiv.org/abs/2310.16221)

    分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。

    

    真实世界的数据是复杂的，通常由可分解为多个实体的对象组成（例如，将图像分解为像素，将图形分解为相互连接的节点）。随机平滑是一种强大的框架，可以使模型在其输入的微小变化上具有证明的鲁棒性-通过在分类之前随机添加噪声来保证多数投票的鲁棒性。然而，当对手不是任意干扰整个对象（例如图像），而是对象的某个实体的子集（例如像素）时，通过随机平滑对这种复杂数据进行鲁棒性认证是具有挑战性的。作为解决方案，我们引入了分层随机平滑：我们通过仅在随机选择的实体子集上添加随机噪声来部分平滑对象。通过以比现有方法更有针对性的方式添加噪声，我们获得更强的鲁棒性保证，同时保持高准确性。我们使用不同的噪声分布初始化分层平滑，得到了新的鲁棒性保证。

    Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
    
[^44]: DeepFDR：一种用于神经影像数据的基于深度学习的虚警控制方法

    DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data. (arXiv:2310.13349v1 [stat.ML])

    [http://arxiv.org/abs/2310.13349](http://arxiv.org/abs/2310.13349)

    DeepFDR是一种基于深度学习的虚警控制方法，通过利用无监督的图像分割技术解决神经影像数据中的多重检验问题，并在实验证明其相对于现有方法具有卓越的性能。

    

    基于体素的多重检验在神经影像数据分析中广泛应用。传统的虚警控制方法常常忽视基于体素的检验之间的空间相关性，从而导致测试能力的大幅损失。虽然最近出现了一些空间虚警控制方法，但是当处理复杂的脑空间依赖关系时，它们的有效性和最优性仍存在疑问。与此同时，深度学习方法已经在图像分割方面取得了革命性的进展，而图像分割与基于体素的多重检验密切相关。本文提出了一种名为DeepFDR的新型空间虚警控制方法，利用无监督的基于深度学习的图像分割来解决基于体素的多重检验问题。包括全面的模拟和阿尔茨海默病FDG-PET影像分析在内的数值研究表明DeepFDR相对于现有方法具有优势。DeepFDR不仅在虚警控制方面表现出色，还有效降低了虚假的非发现率。

    Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but als
    
[^45]: 约束重加权分布：一种最优传输方法的研究

    Constrained Reweighting of Distributions: an Optimal Transport Approach. (arXiv:2310.12447v1 [stat.ML])

    [http://arxiv.org/abs/2310.12447](http://arxiv.org/abs/2310.12447)

    本文提出了一种最优传输方法，通过引入非参数化的分布约束权重，并利用最大熵原理和最优传输工具设计了一个通用框架，以实现对观测数据的最优权重调整。这种方法在不同的应用场景中展现了灵活性和多功能性。

    

    我们经常遇到的问题是要识别出符合预定义的权重约束条件的观测数据的经验分布的最优调整版本。这些约束通常表现为对权重的矩、尾部行为、形状、模式数量等的限制。在本文中，我们通过引入一种非参数化的分布约束权重并利用最大熵原理和最优传输工具开发了一个通用框架，从而大大提高了这种方法的灵活性。关键思想是确保观测数据的最大熵权重调整经验分布与预定的概率分布在最优传输度量下接近，并允许细微的偏差。该框架的多功能性在三个不同的应用场景中得到了证明，其中数据重加权是合理的。

    We commonly encounter the problem of identifying an optimally weight adjusted version of the empirical distribution of observed data, adhering to predefined constraints on the weights. Such constraints often manifest as restrictions on the moments, tail behaviour, shapes, number of modes, etc., of the resulting weight adjusted empirical distribution. In this article, we substantially enhance the flexibility of such methodology by introducing a nonparametrically imbued distributional constraints on the weights, and developing a general framework leveraging the maximum entropy principle and tools from optimal transport. The key idea is to ensure that the maximum entropy weight adjusted empirical distribution of the observed data is close to a pre-specified probability distribution in terms of the optimal transport metric while allowing for subtle departures. The versatility of the framework is demonstrated in the context of three disparate applications where data re-weighting is warrante
    
[^46]: 无监督语言模型蒸馏的事实验证

    Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])

    [http://arxiv.org/abs/2309.16540](http://arxiv.org/abs/2309.16540)

    本文提出了一种名为SFAVEL的无监督框架，通过语言模型蒸馏将自监督特征转化为高质量的主张-事实对齐，实现无监督事实验证。这通过一种新颖的对比损失函数实现，同时保留语料库间的语义关系。

    

    无监督事实验证旨在通过可靠知识库中的证据来验证主张，而无需任何形式的数据注释。为了解决这个挑战，算法必须为每个主张生成既语义明确又紧凑的特征，以便与源信息进行语义对齐。与之前的工作不同，前者通过学习包含主张及其相应标签的注释语料库来解决对齐问题。我们提出了SFAVEL（通过语言模型蒸馏的自监督事实验证），这是一个新颖的无监督框架，利用预训练的语言模型将自监督特征蒸馏为高质量的主张-事实对齐，而无需注释。这是通过一种新颖的对比损失函数实现的，该函数鼓励特征在保持语料库间的语义关系的同时实现高质量的主张和证据对齐。值得注意的是，我们展示了达到新颖的状态一.

    Unsupervised fact verification aims to verify a claim using evidence from a trustworthy knowledge base without any kind of data annotation. To address this challenge, algorithms must produce features for every claim that are both semantically meaningful, and compact enough to find a semantic alignment with the source information. In contrast to previous work, which tackled the alignment problem by learning over annotated corpora of claims and their corresponding labels, we propose SFAVEL (Self-supervised Fact Verification via Language Model Distillation), a novel unsupervised framework that leverages pre-trained language models to distil self-supervised features into high-quality claim-fact alignments without the need for annotations. This is enabled by a novel contrastive loss function that encourages features to attain high-quality claim and evidence alignments whilst preserving the semantic relationships across the corpora. Notably, we present results that achieve a new state-of-the
    
[^47]: 神经策略镜像梯度在低维流形上的策略优化的样本复杂性研究

    Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds. (arXiv:2309.13915v1 [cs.LG])

    [http://arxiv.org/abs/2309.13915](http://arxiv.org/abs/2309.13915)

    本研究探讨了神经策略镜像梯度算法在低维流形上的样本复杂性。研究发现在每次迭代中，卷积神经网络可以很好地逼近价值函数和策略，且逼近误差受网络大小的影响，并且可以继承之前网络的平滑性。

    

    在强化学习中，配备有深度神经网络的策略优化算法在解决高维度的问题中取得了巨大的成功。然而，目前的分析无法解释它们为何能抵抗维度诅咒。在本研究中，我们研究了具有卷积神经网络作为函数逼近器的神经策略镜像梯度（NPMD）算法的样本复杂性。受到许多高维环境具有低维结构的经验观察的启发，例如将图像作为状态，我们将状态空间视为嵌入在$D$维欧氏空间中的$d$维流形，其中$d\ll D$是内在维度。我们证明了在NPMD的每次迭代中，价值函数和策略都可以很好地由卷积神经网络进行逼近。逼近误差由网络的大小控制，并且前一个网络的平滑性可以保留。

    Policy-based algorithms equipped with deep neural networks have achieved great success in solving high-dimensional policy optimization problems in reinforcement learning. However, current analyses cannot explain why they are resistant to the curse of dimensionality. In this work, we study the sample complexity of the neural policy mirror descent (NPMD) algorithm with convolutional neural networks (CNN) as function approximators. Motivated by the empirical observation that many high-dimensional environments have state spaces possessing low-dimensional structures, such as those taking images as states, we consider the state space to be a $d$-dimensional manifold embedded in the $D$-dimensional Euclidean space with intrinsic dimension $d\ll D$. We show that in each iteration of NPMD, both the value function and the policy can be well approximated by CNNs. The approximation errors are controlled by the size of the networks, and the smoothness of the previous networks can be inherited. As a
    
[^48]: 使用改进的方差最小化的分块量化对图神经网络进行激活压缩

    Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization. (arXiv:2309.11856v1 [stat.ML])

    [http://arxiv.org/abs/2309.11856](http://arxiv.org/abs/2309.11856)

    本论文提出了一种使用改进的方差最小化的分块量化策略，用于压缩图神经网络的激活，实现内存消耗的降低和运行时的加速。

    

    已经研究了大规模图神经网络（GNNs）的高效训练，重点是减少其内存消耗。Liu等人（2022年）提出了极限激活压缩（EXACT），通过将中间激活图的量化降至INT2精度，实现了内存消耗的剧烈减少。他们在实现大幅减少GPU内存消耗的同时，表现几乎没有降低。在这项工作中，我们通过使用中间激活图的分块量化，对EXACT策略进行了改进。我们实验分析了不同的块大小，并展示了进一步的内存消耗降低（>15%）和每个epoch的运行时加速（约5%），即使进行了极其大的量化程度，也能获得与原始EXACT相似的性能权衡。此外，我们对EXACT中关于中间激活图分布的假设进行了纠正（假设为u

    Efficient training of large-scale graph neural networks (GNNs) has been studied with a specific focus on reducing their memory consumption. Work by Liu et al. (2022) proposed extreme activation compression (EXACT) which demonstrated drastic reduction in memory consumption by performing quantization of the intermediate activation maps down to using INT2 precision. They showed little to no reduction in performance while achieving large reductions in GPU memory consumption. In this work, we present an improvement to the EXACT strategy by using block-wise quantization of the intermediate activation maps. We experimentally analyze different block sizes and show further reduction in memory consumption (>15%), and runtime speedup per epoch (about 5%) even when performing extreme extents of quantization with similar performance trade-offs as with the original EXACT. Further, we present a correction to the assumptions on the distribution of intermediate activation maps in EXACT (assumed to be u
    
[^49]: 多个敏感属性的顺序公平机制

    A Sequentially Fair Mechanism for Multiple Sensitive Attributes. (arXiv:2309.06627v1 [stat.ML])

    [http://arxiv.org/abs/2309.06627](http://arxiv.org/abs/2309.06627)

    本论文提出了一个顺序框架来逐步实现对多个敏感特征的公平性，通过利用多边际Wasserstein重心扩展了标准的强人口平等概念，并提供了闭式解来解释敏感特征之间的相关性。

    

    在算法公平性的标准用例中，目标是消除敏感变量和相应分数之间的关系。然而，在多个敏感属性的情况下，这些工具和定义的适用性和有效性变得更加复杂。为了解决这个问题，我们提出了一个顺序框架，可以逐步实现对一组敏感特征的公平性。我们通过利用多边际Wasserstein重心来实现这一点，将标准的强人口平等概念扩展到具有多个敏感特征的情况。这种方法还为最优的顺序公平预测器提供了闭式解，可以清楚地解释敏感特征之间的相关性。我们的方法也可以无缝扩展到近似解决方案。

    In the standard use case of Algorithmic Fairness, the goal is to eliminate the relationship between a sensitive variable and a corresponding score. Throughout recent years, the scientific community has developed a host of definitions and tools to solve this task, which work well in many practical applications. However, the applicability and effectivity of these tools and definitions becomes less straightfoward in the case of multiple sensitive attributes. To tackle this issue, we propose a sequential framework, which allows to progressively achieve fairness across a set of sensitive features. We accomplish this by leveraging multi-marginal Wasserstein barycenters, which extends the standard notion of Strong Demographic Parity to the case with multiple sensitive characteristics. This method also provides a closed-form solution for the optimal, sequentially fair predictor, permitting a clear interpretation of inter-sensitive feature correlations. Our approach seamlessly extends to approx
    
[^50]: 加速贝叶斯成像的弛缓纵坐标兰氏抽样方法

    Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling. (arXiv:2308.09460v1 [stat.CO])

    [http://arxiv.org/abs/2308.09460](http://arxiv.org/abs/2308.09460)

    本文提出了一种加速贝叶斯推断方法，用于解决具有凸几何的成像逆问题。该方法通过随机弛缓纵坐标迭代实现，对于高斯目标是渐近无偏的，并且对于$\kappa$-强对数凹的任何目标都能以加速方式收敛。

    

    本文提出了一种新的加速贝叶斯推断方法，用于在具有凸几何的成像逆问题中进行贝叶斯推断。所提出的策略采用随机弛缓纵坐标迭代的形式，具有两种互补的解释方式。对于通过Moreau-Yosida平滑进行平滑或正则化的模型，该算法等价于目标后验分布上的隐式中点离散化过点兰氏扩散，对于高斯目标是渐近无偏的，并且对于$\kappa$-强对数凹（即需要大约$\sqrt{\kappa}$次迭代来收敛，类似于加速优化方案）的任何目标都收敛加速，与[M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935]相比，在高斯目标上只能证明加速。

    This paper presents a new accelerated proximal Markov chain Monte Carlo methodology to perform Bayesian inference in imaging inverse problems with an underlying convex geometry. The proposed strategy takes the form of a stochastic relaxed proximal-point iteration that admits two complementary interpretations. For models that are smooth or regularised by Moreau-Yosida smoothing, the algorithm is equivalent to an implicit midpoint discretisation of an overdamped Langevin diffusion targeting the posterior distribution of interest. This discretisation is asymptotically unbiased for Gaussian targets and shown to converge in an accelerated manner for any target that is $\kappa$-strongly log-concave (i.e., requiring in the order of $\sqrt{\kappa}$ iterations to converge, similarly to accelerated optimisation schemes), comparing favorably to [M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935] which is only provably accelerated for Gaussian target
    
[^51]: 通过混合效应模型和层次聚类学习具有异构农业数据集的贝叶斯网络

    Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering. (arXiv:2308.06399v1 [stat.ML])

    [http://arxiv.org/abs/2308.06399](http://arxiv.org/abs/2308.06399)

    本研究介绍了一种将混合效应模型和层次聚类应用于贝叶斯网络学习的新方法，在农学研究中广泛应用。通过整合随机效应，该方法可以提高贝叶斯网络的结构学习能力，实现因果关系网络的发现。

    

    在涉及多样但相关数据集的研究中，其中协变量与结果之间的关联可能会有所不同，在包括农学研究在内的各个领域都很普遍。在这种情况下，常常使用层次模型，也被称为多层模型，来融合来自不同数据集的信息，并适应它们的不同特点。然而，它们的结构超出了简单的异质性，因为变量通常形成复杂的因果关系网络。贝叶斯网络（BNs）使用有向无环图来模拟这种关系的强大框架。本研究介绍了一种将随机效应整合到BN学习中的新方法。这种方法基于线性混合效应模型，特别适用于处理层次数据。来自真实农学试验的结果表明，采用这种方法可以增强结构学习，从而实现发现

    Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.  Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery 
    
[^52]: CardiGraphormer: 揭示自监督学习在颠覆药物发现中的力量

    CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery. (arXiv:2307.00859v1 [cs.LG])

    [http://arxiv.org/abs/2307.00859](http://arxiv.org/abs/2307.00859)

    CardiGraphormer是一种革命性的方法，结合了自监督学习、图神经网络和保持基数注意力，颠覆了药物发现的方式。它利用自监督学习学习分子表示并利用图神经网络提取分子指纹，提高了预测性能和可解释性，同时减少了计算时间，并在处理复杂数据和执行各种与图结构相关的任务方面表现出色。

    

    在广阔的药物发现领域中，已知药物约有15,000种，但只有大约4,200种得到了批准，化学空间的组合性质提供了一项艰巨的挑战。尽管人工智能成为了有力的伙伴，传统的人工智能框架仍面临重大障碍。本文介绍了CardiGraphormer，这是一种划时代的方法，通过结合自监督学习（SSL）、图神经网络（GNN）和保持基数注意力，从而颠覆药物发现。CardiGraphormer是Graphormer和保持基数注意力的新颖组合，利用SSL学习有效的分子表示，并利用GNN提取分子指纹，提高了预测性能和可解释性，并减少了计算时间。它在处理分子结构等复杂数据方面表现出色，并能执行与节点、节点对、子图或整个图结构相关的任务。

    In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge. While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles. This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery. CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time. It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential a
    
[^53]: iSCAN：识别非线性加性噪声模型中的因果机制转变

    iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models. (arXiv:2306.17361v1 [cs.LG])

    [http://arxiv.org/abs/2306.17361](http://arxiv.org/abs/2306.17361)

    本文提出了一种识别非线性加性噪声模型中因果机制转变的方法，该方法专注于在相关的结构因果模型中识别功能机制的变化，而不需要估计整个有向无环图(DAG)的结构。

    

    结构因果模型(SCM)被广泛应用于各个领域，以表示复杂系统中变量之间的因果关系。然而，真正的底层有向无环图(DAG)结构通常是未知的，并且从观测数据或干预数据中确定它仍然是一项具有挑战性的任务。然而，在许多情况下，目标是识别相关SCM之间的因果机制的变化(转变)而不是恢复整个底层DAG结构。例子包括分析健康和癌症患者之间的基因调控网络结构变化，或者在不同细胞环境下理解生物途径的变化。本文重点研究了在相同的变量集上识别两个或多个相关SCM中的$\textit{功能}$机制转变，而不需要估计每个SCM的整个DAG结构。在这种设置下，先前的工作假设使用了具有高斯噪声的线性模型；而本文中我们则考虑了非线性加性噪声模型。

    Structural causal models (SCMs) are widely used in various disciplines to represent causal relationships among variables in complex systems. Unfortunately, the true underlying directed acyclic graph (DAG) structure is often unknown, and determining it from observational or interventional data remains a challenging task. However, in many situations, the end goal is to identify changes (shifts) in causal mechanisms between related SCMs rather than recovering the entire underlying DAG structure. Examples include analyzing gene regulatory network structure changes between healthy and cancerous individuals or understanding variations in biological pathways under different cellular contexts. This paper focuses on identifying $\textit{functional}$ mechanism shifts in two or more related SCMs over the same set of variables -$\textit{without estimating the entire DAG structure of each SCM}$. Prior work under this setting assumed linear models with Gaussian noises; instead, in this work we ass
    
[^54]: 使用随机梯度下降从高斯过程后验中采样

    Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent. (arXiv:2306.11589v1 [cs.LG])

    [http://arxiv.org/abs/2306.11589](http://arxiv.org/abs/2306.11589)

    本文探索了使用随机梯度下降算法从高斯过程后验中采样的方法，该方法计算高效且能在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。

    

    高斯过程是用于量化不确定性和顺序决策的强大框架，但其需要求解线性系统，每当数据集大小增加时代价是立方级别的且对条件敏感。本文探索了随机梯度算法作为一种计算高效的方法来近似解决这些线性系统：我们开发了低方差的最优化目标以从后验中进行采样，并将其扩展到引入点。令人意想不到的是，即使在不快速收敛到最优解的情况下，随机梯度下降通常也会产生准确的预测。我们通过非收敛的隐式偏置的谱特征来解释这一点。我们表明，随机梯度下降会在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。在实验中，随机梯度下降实现了

    Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves sta
    
[^55]: 使用大型语言模型注释进行社会科学中的有效下游统计推断: 基于设计的半监督学习

    Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning. (arXiv:2306.04746v1 [stat.ME])

    [http://arxiv.org/abs/2306.04746](http://arxiv.org/abs/2306.04746)

    该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。

    

    在计算社会科学（CSS）中，研究人员通过分析文档来解释社会和政治现象。在大多数情况下，CSS研究人员首先获取文档的标签，然后使用可解释的回归分析来解释标签。大型语言模型（LLMs）的最近进展可以通过在规模上便宜地注释文档来降低CSS研究成本，但这些替代标签通常是不完美和有偏的。我们提出了一种新算法，用于使用LLMs的输出进行下游统计分析，同时保证与CSS研究基本相关的统计属性-如渐近无偏性和正确的不确定性量化。我们表明，直接在下游统计分析中使用LLM预测的替代标签会导致实质性偏差和无效置信区间，即使替代准确性高达80-90％。为了解决这个问题，我们基于无偏机器学习提出了基于设计的半监督学习（D-SSL）算法，该算法将LLM注释与有针对性的采样相结合，以实现有效的下游统计推断。我们的方法可以将标签获取的CSS研究成本降低80％，而不影响统计分析的有效性。模拟研究和实际数据示例表明，与直接使用LLM预测标签相比，D-SSL可以将回归估计的准确性提高多达40％。

    In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80--90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised le
    
[^56]: 通过重新思考民间威斯费勒-莱曼算法，实现$O(n^2)$空间内任意表达能力的GNNs

    Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking Folklore Weisfeiler-Lehman. (arXiv:2306.03266v1 [cs.LG])

    [http://arxiv.org/abs/2306.03266](http://arxiv.org/abs/2306.03266)

    本文提出了$(k, t)$-FWL和$k$-FWL+两种方法，理论上证明了它们可以在$O(n^2)$的空间复杂度下，解决图同构问题。

    

    近年来，消息传递神经网络（MPNNs）已成为图神经网络（GNNs）中最受欢迎的框架。然而，其表达能力受到一维威斯费勒-莱曼（1-WL）测试的限制。一些研究受到$k$-WL/FWL（民间WL）的启发并设计其相应的神经版本。尽管具有很高的表达能力，但这一研究方向存在严重局限性。为解决这些问题，作者提出了$(k, t)$-FWL和$k$-FWL+，并在理论上证明了它们的有效性。

    Message passing neural networks (MPNNs) have emerged as the most popular framework of graph neural networks (GNNs) in recent years. However, their expressive power is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Some works are inspired by $k$-WL/FWL (Folklore WL) and design the corresponding neural versions. Despite the high expressive power, there are serious limitations in this line of research. In particular, (1) $k$-WL/FWL requires at least $O(n^k)$ space complexity, which is impractical for large graphs even when $k=3$; (2) The design space of $k$-WL/FWL is rigid, with the only adjustable hyper-parameter being $k$. To tackle the first limitation, we propose an extension, $(k, t)$-FWL. We theoretically prove that even if we fix the space complexity to $O(n^2)$ in $(k, t)$-FWL, we can construct an expressiveness hierarchy up to solving the graph isomorphism problem. To tackle the second problem, we propose $k$-FWL+, which considers any equivariant set as neighbors ins
    
[^57]: 具有平均奖励的不安定赌徒问题：打破统一全局引子假设

    Restless Bandits with Average Reward: Breaking the Uniform Global Attractor Assumption. (arXiv:2306.00196v1 [cs.LG])

    [http://arxiv.org/abs/2306.00196](http://arxiv.org/abs/2306.00196)

    本文提出了一个通用的框架，将任何单臂策略转化为原始的$N$臂问题的策略，解决了依赖于复杂UGAP假设的问题，并实现了具有$O(1/\sqrt{N})$最优性差距的策略。

    

    我们研究了具有平均奖励标准下的无限时不安定赌徒问题，包括离散时间和连续时间设置。一个基本问题是如何设计计算有效的策略，使得优化差距随着臂的数量$N$的增加而减小。现有的渐近最优性结果都依赖于统一全局引子性质(UGAP)，这是一个复杂且难以验证的假设。在本文中，我们提出了一个通用的、基于模拟的框架，将任何单臂策略转化为原始的$N$臂问题的策略。这是通过在每个臂上模拟单臂策略，并仔细地将真实状态引导向模拟状态来实现的。我们的框架可以实例化，产生一个具有$O(1/\sqrt{N})$的最优解差距的策略。在离散时间设置中，我们的结果在更简单的同步假设下成立，涵盖了一些不满足UGAP的问题实例。更值得注意的是，我们的框架可以处理比现有方法更大的问题类，而不需对问题实例做任何特定的结构假设。

    We study the infinite-horizon restless bandit problem with the average reward criterion, under both discrete-time and continuous-time settings. A fundamental question is how to design computationally efficient policies that achieve a diminishing optimality gap as the number of arms, $N$, grows large. Existing results on asymptotical optimality all rely on the uniform global attractor property (UGAP), a complex and challenging-to-verify assumption. In this paper, we propose a general, simulation-based framework that converts any single-armed policy into a policy for the original $N$-armed problem. This is accomplished by simulating the single-armed policy on each arm and carefully steering the real state towards the simulated state. Our framework can be instantiated to produce a policy with an $O(1/\sqrt{N})$ optimality gap. In the discrete-time setting, our result holds under a simpler synchronization assumption, which covers some problem instances that do not satisfy UGAP. More notabl
    
[^58]: 学习解决贝叶斯逆问题：一种摊销变分推理方法

    Learning to solve Bayesian inverse problems: An amortized variational inference approach. (arXiv:2305.20004v1 [stat.ML])

    [http://arxiv.org/abs/2305.20004](http://arxiv.org/abs/2305.20004)

    本文提出了一种基于深度神经网络的参数化表示后验分布的摊销变分推理方法，以实现实时推理的目的，可应用于流体力学中的参数估计和流场重构等领域。

    

    逆问题，即从实验数据中估计物理模型的参数，在科学和工程中普遍存在。贝叶斯公式是黄金标准，因为它可以缓解病态性问题并量化认识不确定性。然而，由于解析后验不通常可用，人们采用马尔可夫链蒙特卡罗采样或近似变分推理。但是，需要重新从头开始进行推理以适应每组新数据。这种缺点限制了贝叶斯公式在实时设置，例如工程系统的健康监测和医疗诊断中的适用性。本文的目标是开发一种方法，通过学习从数据到后验的贝叶斯逆映射，即从数据到后验的映射，实现实时推理的方法。我们的方法如下。我们使用基于深度神经网络的参数化表示后验分布。接下来，我们通过摊销变分推理学习网络参数，其中训练神经网络以预测从数据中预测后验分布，从而实现快速准确的推理。我们在流体力学中的一些逆问题上展示了我们方法的有效性，其中包括参数估计和流场重构。

    Inverse problems, i.e., estimating parameters of physical models from experimental data, are ubiquitous in science and engineering. The Bayesian formulation is the gold standard because it alleviates ill-posedness issues and quantifies epistemic uncertainty. Since analytical posteriors are not typically available, one resorts to Markov chain Monte Carlo sampling or approximate variational inference. However, inference needs to be rerun from scratch for each new set of data. This drawback limits the applicability of the Bayesian formulation to real-time settings, e.g., health monitoring of engineered systems, and medical diagnosis. The objective of this paper is to develop a methodology that enables real-time inference by learning the Bayesian inverse map, i.e., the map from data to posteriors. Our approach is as follows. We represent the posterior distribution using a parameterization based on deep neural networks. Next, we learn the network parameters by amortized variational inferenc
    
[^59]: DoWG展示：一种高效的通用无参数梯度下降方法

    DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method. (arXiv:2305.16284v1 [cs.LG])

    [http://arxiv.org/abs/2305.16284](http://arxiv.org/abs/2305.16284)

    本文提出了一种名为DoWG的无参数梯度下降方法，它是第一个既高效又通用的算法，能够自适应于平稳和非平稳问题，并且无需回溯搜索过程。

    

    本文提出了一种新的易于实现的无参数梯度优化器：DoWG（Weighted Gradients的距离）。我们证明了该方法是高效的——在不调整任何参数的情况下，匹配优化凸优化中最优调的梯度下降的收敛速度，直到对数因子，并且是通用的——自动适应平滑和非平滑问题。与AdaGrad，Adam或DoG等流行算法计算平方梯度的运行平均值不同，DoWG保持运行平均值的一种新的基于距离的加权版本，这对于实现所需的性质至关重要。据我们所知，DoWG是第一个不需要回溯搜索过程的无参数，高效和通用算法。它还是第一个适应于平稳优化的无参数AdaGrad样式算法。为了补充我们的理论，我们还通过实验证明DoWG在稳定的边缘训练，并证明其在实践中的有效性。

    This paper proposes a new easy-to-implement parameter-free gradient-based optimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG is efficient -- matching the convergence rate of optimally tuned gradient descent in convex optimization up to a logarithmic factor without tuning any parameters, and universal -- automatically adapting to both smooth and nonsmooth problems. While popular algorithms such as AdaGrad, Adam, or DoG compute a running average of the squared gradients, DoWG maintains a new distance-based weighted version of the running average, which is crucial to achieve the desired properties. To our best knowledge, DoWG is the first parameter-free, efficient, and universal algorithm that does not require backtracking search procedures. It is also the first parameter-free AdaGrad style algorithm that adapts to smooth optimization. To complement our theory, we also show empirically that DoWG trains at the edge of stability, and validate its effectiveness on practic
    
[^60]: Koopman核回归

    Koopman Kernel Regression. (arXiv:2305.16215v1 [cs.LG])

    [http://arxiv.org/abs/2305.16215](http://arxiv.org/abs/2305.16215)

    提出了一种基于Koopman核的回归方法，用于预测非线性动力系统的时间演变。该方法在机器人操作，视频预测和交通预测等各种应用中均有优异表现，并具有可证明的学习理论保证。

    

    许多决策制定的机器学习方法，如强化学习，依赖于模拟器或预测模型来预测感兴趣的量的时间演变，例如智能体的状态或策略的奖励。这些复杂现象的预测通常由高度非线性的动力系统描述，使得它们在基于优化的决策制定中的使用具有挑战性。Koopman算子理论通过通过线性动态系统描述预测来解决这个问题。这使得系统分析和长期预测变得简单--只涉及矩阵乘法。然而，将其转化为线性系统通常是非平凡的和未知的，需要基于学习的方法。虽然存在各种方法，但它们通常缺乏关键的学习理论保证，因此所获得的模型在数据和维度增加时的行为通常不清楚。通过提出一种新颖的基于Koopman核的回归方法，我们解决了上述挑战，该方法直接从历史观察中学习到未来预测在Koopman算子空间中的映射。我们的方法享有可证明的学习理论保证，并在广泛的应用中与现有的最先进方法匹配（或优于），包括机器人操作，视频预测和交通预测。

    Many machine learning approaches for decision making, such as reinforcement learning, rely on simulators or predictive models to forecast the time-evolution of quantities of interest, e.g., the state of an agent or the reward of a policy. Forecasts of such complex phenomena are commonly described by highly nonlinear dynamical systems, making their use in optimization-based decision-making challenging. Koopman operator theory offers a beneficial paradigm for addressing this problem by characterizing forecasts via linear dynamical systems. This makes system analysis and long-term predictions simple -- involving only matrix multiplications. However, the transformation to a linear system is generally non-trivial and unknown, requiring learning-based approaches. While there exists a variety of approaches, they usually lack crucial learning-theoretic guarantees, such that the behavior of the obtained models with increasing data and dimensionality is often unclear. We address the aforemention
    
[^61]: 基于局部Lajasiewicz条件的随机梯度下降在深度神经网络中的收敛性研究

    Convergence of stochastic gradient descent under a local Lajasiewicz condition for deep neural networks. (arXiv:2304.09221v1 [cs.LG])

    [http://arxiv.org/abs/2304.09221](http://arxiv.org/abs/2304.09221)

    本文通过随机梯度下降算法研究了解析度函数为非凸的深度神经网络的全局收敛性，证明了当机器学习噪声的尺度与目标函数相等时，在局部区域内初始化后，以正的概率能够收敛到该区域内的全局最小值。

    

    本文考虑了解析度函数为非凸的情况下，通过随机梯度下降算法对深度神经网络的全局收敛性进行了研究。在有限宽的神经网络中，通过加入最小的额外假设并保证机器学习噪声的尺度与目标函数相等，证明了在局部区域内初始化时，以正的概率随机梯度下降迭代收敛到该区域内的全局最小值。本文的关键是确保随机梯度下降的整个轨迹以正的概率保留在局部区域内。文章提供了负面分析，表明使用Robbins-Monro类型的步长之间具有有界噪声的假设不足以保持该关键部分的有效性。

    We extend the global convergence result of Chatterjee \cite{chatterjee2022convergence} by considering the stochastic gradient descent (SGD) for non-convex objective functions. With minimal additional assumptions that can be realized by finitely wide neural networks, we prove that if we initialize inside a local region where the \L{}ajasiewicz condition holds, with a positive probability, the stochastic gradient iterates converge to a global minimum inside this region. A key component of our proof is to ensure that the whole trajectories of SGD stay inside the local region with a positive probability. For that, we assume the SGD noise scales with the objective function, which is called machine learning noise and achievable in many real examples. Furthermore, we provide a negative argument to show why using the boundedness of noise with Robbins-Monro type step sizes is not enough to keep the key component valid.
    
[^62]: 论随机遍历的强稳定性

    On the strong stability of ergodic iterations. (arXiv:2304.04657v1 [math.PR])

    [http://arxiv.org/abs/2304.04657](http://arxiv.org/abs/2304.04657)

    本论文研究了迭代随机函数生成的过程的强稳定性，证明了适用于递归映射的温和条件下的强稳定性，并且提供了多个应用及相关领域的新结果。

    

    我们重新审视了由随机函数迭代生成的过程，这些函数由一个平稳且符合遍历条件的序列驱动。如果存在一个随机初始化使得该过程是稳定和遍历的，并且对于任何其他初始化，两个过程之间的差异几乎肯定收敛于零，那么这样的过程被称为强稳定。在对应递归映射上施加一些温和的条件，而不在驱动序列上施加任何条件下，我们展示了迭代的强稳定性。多个应用被研究，如随机逼近和排队。此外，我们推导出了具有依赖噪声的 Langevin 型迭代和多型分支过程的新结果。

    We revisit processes generated by iterated random functions driven by a stationary and ergodic sequence. Such a process is called strongly stable if a random initialization exists, for which the process is stationary and ergodic, and for any other initialization, the difference of the two processes converges to zero almost surely. Under some mild conditions on the corresponding recursive map, without any condition on the driving sequence, we show the strong stability of iterations. Several applications are surveyed such as stochastic approximation and queuing. Furthermore, new results are deduced for Langevin-type iterations with dependent noise and for multitype branching processes.
    
[^63]: 组合干预的因果推断框架:合成组合

    Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions. (arXiv:2303.14226v1 [stat.ME])

    [http://arxiv.org/abs/2303.14226](http://arxiv.org/abs/2303.14226)

    提出了一种在组合干预下进行因果推断的模型，通过施加潜在结构跨越单位和组合，在降低实验数量和处理混杂问题方面有着良好表现。

    

    我们考虑一个包含N个异质单位和p个干预的设置。 我们的目标是学习任意组合的单位特定潜在结果，即N×2 ^ p个因果参数。在许多应用程序中自然出现了选择干预组合的问题，例如因子设计试验，推荐引擎(例如，为用户显示最大程度的参与度的一组电影)，医学中的组合疗法，选择ML模型的重要特征等等。当N和p增长时，进行N×2 ^ p个实验来估计各种参数是不可行的。而且，观测数据很可能存在混杂，即单位是否在组合下出现与其在该组合下的潜在结果相关。为了解决这些问题，我们提出了一种新颖的模型，它在单位和组合之间都施加了潜在结构。我们假设单位之间存在潜在的相似性(即类似单位的潜在结果是相似的)，并且组合之间也存在潜在的相似性(即类似组合的效果是相似的)。我们使用层次贝叶斯非参数模型来形式化这一点，该模型联合聚类单元和组合，并且足够灵活，可以模拟连续或离散结果。我们在模拟和实际数据上演示了所提出的方法，并表明它可以显着减少学习因果参数所需的实验数量。

    We consider a setting with $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \times 2^p$ causal parameters. Choosing combinations of interventions is a problem that naturally arises in many applications such as factorial design experiments, recommendation engines (e.g., showing a set of movies that maximizes engagement for users), combination therapies in medicine, selecting important features for ML models, etc. Running $N \times 2^p$ experiments to estimate the various parameters is infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. To address these challenges, we propose a novel model that imposes latent structure across both units and combinations. We assume latent similarity across units (i.e., the potential outco
    
[^64]: 停留还是离开预训练基域：关于集成学习在迁移学习中的洞见

    To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning. (arXiv:2303.03374v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03374](http://arxiv.org/abs/2303.03374)

    该论文研究了在迁移学习中使用单个预训练检查点微调的模型集合，发现通过更好地探索预训练基域可以改进集成模型，但离开基域会导致失去迁移学习的好处，并且降低集成质量。作者提出了一种更有效的修改方法StarSSE，可以产生更强的集成模型和均匀的模型混合。

    

    迁移学习和集成学习是改善神经网络性能和鲁棒性的两种热门技术。由于预训练成本高昂，通常实践中使用从单个预训练检查点微调的模型集合。这些模型最终会进入损失函数梯度下降空间的相同区域，我们称之为预训练基域，因此具有有限的多样性。在这项工作中，我们展示了从单个预训练检查点训练的集成模型可以通过更好地探索预训练基域来改进，然而，离开基域会导致失去迁移学习的好处并导致集成质量的下降。基于对现有探索方法的分析，我们提出了一种更有效的修改Transfer Learning Setup中的Snapshot Ensembles（SSE）方法，名为StarSSE，它能产生更强的集成模型和均匀的模型混合。

    Transfer learning and ensembling are two popular techniques for improving the performance and robustness of neural networks. Due to the high cost of pre-training, ensembles of models fine-tuned from a single pre-trained checkpoint are often used in practice. Such models end up in the same basin of the loss landscape, which we call the pre-train basin, and thus have limited diversity. In this work, we show that ensembles trained from a single pre-trained checkpoint may be improved by better exploring the pre-train basin, however, leaving the basin results in losing the benefits of transfer learning and in degradation of the ensemble quality. Based on the analysis of existing exploration methods, we propose a more effective modification of the Snapshot Ensembles (SSE) for transfer learning setup, StarSSE, which results in stronger ensembles and uniform model soups.
    
[^65]: CAMEL: 曲率增强的流形嵌入与学习

    CAMEL: Curvature-Augmented Manifold Embedding and Learning. (arXiv:2303.02561v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02561](http://arxiv.org/abs/2303.02561)

    CAMEL是一种新的方法，利用黎曼流形上的拓扑度量和独特的黎曼度量进行高维数据分类、降维和可视化。它通过平滑分区统一算子将局部正交投影转换为全局嵌入，并提供了聚类显著特征的物理解释。CAMEL在各种基准数据集上表现优于其他方法，特别是对于高维数据集。

    

    提出了一种名为Curvature-Augmented Manifold Embedding and Learning (CAMEL)的新方法，用于高维数据分类、降维和可视化。CAMEL利用在黎曼流形上定义的拓扑度量以及用于距离和曲率的独特黎曼度量来增强其表达能力。该方法还在黎曼流形上使用平滑分区统一算子，将局部正交投影转换为全局嵌入，同时捕捉整体拓扑结构和局部相似性。局部正交向量提供了聚类的显著特征的物理解释。因此，CAMEL不仅提供了低维嵌入，还解释了此嵌入背后的物理情况。CAMEL已在各种基准数据集上进行了评估，并显示出优于其他最先进方法，特别是对于高维数据集。该方法的显著优势是。

    A novel method, named Curvature-Augmented Manifold Embedding and Learning (CAMEL), is proposed for high dimensional data classification, dimension reduction, and visualization. CAMEL utilizes a topology metric defined on the Riemannian manifold, and a unique Riemannian metric for both distance and curvature to enhance its expressibility. The method also employs a smooth partition of unity operator on the Riemannian manifold to convert localized orthogonal projection to global embedding, which captures both the overall topological structure and local similarity simultaneously. The local orthogonal vectors provide a physical interpretation of the significant characteristics of clusters. Therefore, CAMEL not only provides a low-dimensional embedding but also interprets the physics behind this embedding. CAMEL has been evaluated on various benchmark datasets and has shown to outperform state-of-the-art methods, especially for high-dimensional datasets. The method's distinct benefits are it
    
[^66]: 比较耦合流和自回归流的鲁棒统计检验研究

    Comparative Study of Coupling and Autoregressive Flows through Robust Statistical Tests. (arXiv:2302.12024v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.12024](http://arxiv.org/abs/2302.12024)

    本论文通过比较耦合流和自回归流的不同架构和多样目标分布，利用各种测试统计量进行性能比较，为正规化流的生成模型提供了深入的研究和实证评估。

    

    正规化流已经成为一种强大的生成模型，因为它们不仅能够有效地对复杂目标分布进行采样，而且还通过构造提供密度估计。我们在这里提出了对耦合流和自回归流进行深入比较的研究，包括仿射和有理二次样条类型的四种不同架构：实值非体积保持（RealNVP）、掩蔽自回归流（MAF）、耦合有理二次样条（C-RQS）和自回归有理二次样条（A-RQS）。我们关注一组从4维到400维递增的多模态目标分布。通过使用不同的两样本测试的测试统计量进行比较，我们建立了已知距离度量的测试统计量：切片Wasserstein距离、维度平均一维Kolmogorov-Smirnov检验和相关矩阵之差的Frobenius范数。另外，我们还包括了以下估计：

    Normalizing Flows have emerged as a powerful brand of generative models, as they not only allow for efficient sampling of complicated target distributions, but also deliver density estimation by construction. We propose here an in-depth comparison of coupling and autoregressive flows, both of the affine and rational quadratic spline type, considering four different architectures: Real-valued Non-Volume Preserving (RealNVP), Masked Autoregressive Flow (MAF), Coupling Rational Quadratic Spline (C-RQS), and Autoregressive Rational Quadratic Spline (A-RQS). We focus on a set of multimodal target distributions of increasing dimensionality ranging from 4 to 400. The performances are compared by means of different test-statistics for two-sample tests, built from known distance measures: the sliced Wasserstein distance, the dimension-averaged one-dimensional Kolmogorov-Smirnov test, and the Frobenius norm of the difference between correlation matrices. Furthermore, we include estimations of th
    
[^67]: 信息理论上界对信息理论下界的贡献

    Information Theoretic Lower Bounds for Information Theoretic Upper Bounds. (arXiv:2302.04925v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04925](http://arxiv.org/abs/2302.04925)

    本文研究了在随机凸优化中，输出模型和经验样本之间的互信息与算法泛化之间的关系。研究结果表明，现有的信息理论泛化界限不足以捕捉到像SGD和正则化ERM这样具有维度无关样本复杂度的算法的泛化能力。

    

    本文在随机凸优化的背景下研究了输出模型和经验样本之间的互信息与算法的泛化之间的关系。尽管对信息理论泛化界限的兴趣日益增加，但这些界限能否揭示各种学习算法的卓越性能还不确定。我们对随机凸优化的研究表明，对于真正的风险最小化，依赖于维度的互信息是必要的。这表明现有的信息理论泛化界限不能完全捕捉到像SGD和正则化ERM这样具有维度无关样本复杂度的算法的泛化能力。

    We examine the relationship between the mutual information between the output model and the empirical sample and the generalization of the algorithm in the context of stochastic convex optimization. Despite increasing interest in information-theoretic generalization bounds, it is uncertain if these bounds can provide insight into the exceptional performance of various learning algorithms. Our study of stochastic convex optimization reveals that, for true risk minimization, dimension-dependent mutual information is necessary. This indicates that existing information-theoretic generalization bounds fall short in capturing the generalization capabilities of algorithms like SGD and regularized ERM, which have dimension-independent sample complexity.
    
[^68]: 在连续值估计中管理时间分辨率: 一项基本权衡的研究

    Managing Temporal Resolution in Continuous Value Estimation: A Fundamental Trade-off. (arXiv:2212.08949v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08949](http://arxiv.org/abs/2212.08949)

    本论文分析了在强化学习和最优控制中观测时间以离散时间点固定周期到达的默认假设与实际情况下的连续时间系统之间的差异，并在LQR系统中揭示了近似误差和统计误差之间的基本权衡。在有限数据的情况下，管理时间分辨率可以显著改善策略评估的效率。

    

    强化学习（RL）和最优控制中的默认假设是观测以固定的时钟周期在离散的时间点到达。然而，许多应用涉及连续时间系统，理论上可以对时间离散化进行管理。时间离散化对RL方法的影响尚未在现有理论中完全表征，但对其影响进行更详细的分析可能揭示提高数据效率的机会。我们通过分析LQR系统的Monte-Carlo策略评估来填补这一空白，并发现了估值过程中近似误差和统计误差之间的基本权衡。重要的是，这两种错误对时间离散化的表现不同，这导致了对于给定数据预算的时间分辨率的最佳选择。这些发现表明，在具有有限数据的LQR系统中，管理时间分辨率可以改善策略评估的效率。从实证角度来看，我们在数值模拟中展示了这种权衡。

    A default assumption in reinforcement learning (RL) and optimal control is that observations arrive at discrete time points on a fixed clock cycle. Yet, many applications involve continuous-time systems where the time discretization, in principle, can be managed. The impact of time discretization on RL methods has not been fully characterized in existing theory, but a more detailed analysis of its effect could reveal opportunities for improving data-efficiency. We address this gap by analyzing Monte-Carlo policy evaluation for LQR systems and uncover a fundamental trade-off between approximation and statistical error in value estimation. Importantly, these two errors behave differently to time discretization, leading to an optimal choice of temporal resolution for a given data budget. These findings show that managing the temporal resolution can provably improve policy evaluation efficiency in LQR systems with finite data. Empirically, we demonstrate the trade-off in numerical simulati
    
[^69]: 高维预测回归中LASSO的研究

    On LASSO for High Dimensional Predictive Regression. (arXiv:2212.07052v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2212.07052](http://arxiv.org/abs/2212.07052)

    本文研究了高维预测回归中LASSO的应用，提出了LASSO的收敛速度与横断面情况不同的新的概率界限，并展示了LASSO在预测失业率方面的强大性能。

    

    本文研究了LASSO在高维线性预测回归中的应用，特别是在潜在预测变量数量超过样本量且存在大量单位根回归器的情况下。LASSO的一致性取决于两个关键组成部分：回归器和误差项的交叉乘积的偏差界限以及Gram矩阵的受限特征值。我们提出了这些组成部分的新的概率界限，表明LASSO的收敛速度与典型的横断面情况不同。当应用于混合的平稳、非平稳和协整预测器时，如果预测器进行了标度标准化，LASSO仍然保持其渐近保证。利用机器学习和宏观经济领域的专业知识，LASSO在预测失业率方面表现出强大的性能，这一点在其应用于FRED-MD数据库中得到了证实。

    This paper examines LASSO, a widely-used $L_{1}$-penalized regression method, in high dimensional linear predictive regressions, particularly when the number of potential predictors exceeds the sample size and numerous unit root regressors are present. The consistency of LASSO is contingent upon two key components: the deviation bound of the cross product of the regressors and the error term, and the restricted eigenvalue of the Gram matrix. We present new probabilistic bounds for these components, suggesting that LASSO's rates of convergence are different from those typically observed in cross-sectional cases. When applied to a mixture of stationary, nonstationary, and cointegrated predictors, LASSO maintains its asymptotic guarantee if predictors are scale-standardized. Leveraging machine learning and macroeconomic domain expertise, LASSO demonstrates strong performance in forecasting the unemployment rate, as evidenced by its application to the FRED-MD database.
    
[^70]: 探索基于扩散模型的离线模型优化的验证指标

    Exploring validation metrics for offline model-based optimisation with diffusion models. (arXiv:2211.10747v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.10747](http://arxiv.org/abs/2211.10747)

    本论文研究基于扩散模型的离线模型优化中的验证指标。在离线模型优化中，我们希望在没有访问真值预言机的情况下设计候选方案。现有的验证指标是对预言机的近似，我们希望找到与真值预言机最相关的验证指标。

    

    在基于模型的优化中，我们希望利用机器学习设计候选方案，以最大化对于一个称为（地面真值）预言机的黑盒函数的某种奖励度量。然而，由于涉及到执行真实世界过程，计算预言机是昂贵的。在离线模型优化中，我们希望在训练或验证过程中不假设对预言机有访问权限，这使得评估变得复杂。虽然可以训练一个预言机的近似模型并在模型验证过程中使用它代替真值预言机来测量生成候选方案的平均奖励，但这种评估是近似的且容易受到对抗性样本的影响。我们将这种近似下生成候选方案的平均奖励作为一种“验证指标”，而我们更关心的是一个更基本的问题，即找到与真值预言机最相关的验证指标。这涉及到提出验证指标并对许多数据集进行量化。

    In model-based optimisation (MBO) we are interested in using machine learning to design candidates that maximise some measure of reward with respect to a black box function called the (ground truth) oracle, which is expensive to compute since it involves executing a real world process. In offline MBO we wish to do so without assuming access to such an oracle during training or validation, with makes evaluation non-straightforward. While an approximation to the ground oracle can be trained and used in place of it during model validation to measure the mean reward over generated candidates, the evaluation is approximate and vulnerable to adversarial examples. Measuring the mean reward of generated candidates over this approximation is one such `validation metric', whereas we are interested in a more fundamental question which is finding which validation metrics correlate the most with the ground truth. This involves proposing validation metrics and quantifying them over many datasets for
    
[^71]: 通过使用Cover Trees的最小间隔实现数值稳定的稀疏高斯过程

    Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees. (arXiv:2210.07893v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.07893](http://arxiv.org/abs/2210.07893)

    本文针对高斯过程模型的数值稳定性进行了研究，通过感兴趣点的选择和计算，提供了稳定可靠的稀疏逼近方法。

    

    高斯过程常用于较大的机器学习和决策系统中，例如地理空间建模、贝叶斯优化或潜在高斯模型中。在一个系统中，高斯过程模型需要以稳定可靠的方式运行，以确保与系统的其他部分正确交互。本文研究了基于感兴趣点的可扩展稀疏逼近的数值稳定性。为此，我们首先回顾了数值稳定性，并阐述了高斯过程模型可能不稳定的典型情况。在插值文献中原始开发的稳定性理论的基础上，我们导出了对感兴趣点进行计算的数值稳定性的充分条件和某些情况下的必要条件。对于地理空间建模等低维任务，我们提出了一种自动计算满足这些条件的感兴趣点的方法。

    Gaussian processes are frequently deployed as part of larger machine learning and decision-making systems, for instance in geospatial modeling, Bayesian optimization, or in latent Gaussian models. Within a system, the Gaussian process model needs to perform in a stable and reliable manner to ensure it interacts correctly with other parts of the system. In this work, we study the numerical stability of scalable sparse approximations based on inducing points. To do so, we first review numerical stability, and illustrate typical situations in which Gaussian process models can be unstable. Building on stability theory originally developed in the interpolation literature, we derive sufficient and in certain cases necessary conditions on the inducing points for the computations performed to be numerically stable. For low-dimensional tasks such as geospatial modeling, we propose an automated method for computing inducing points satisfying these conditions. This is done via a modification of t
    
[^72]: 规范化聚类准确度：一种非对称的外部聚类有效度量

    Normalised clustering accuracy: An asymmetric external cluster validity measure. (arXiv:2209.02935v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.02935](http://arxiv.org/abs/2209.02935)

    本文提出了一种非对称的外部聚类有效度量方法，旨在区分不同任务类型上表现良好和系统性表现不佳的聚类算法。与传统的内部度量不同，该方法利用参考真实分组进行评估，并弥补了现有方法在最坏情况下的误差。

    

    没有一个最好的聚类算法，我们仍然希望能够区分出在某些任务类型上表现良好和系统性表现不佳的方法。传统上，聚类算法使用内部或外部有效度量进行评估。内部度量量化所得分区的不同方面，例如，簇紧密度的平均程度或点的可分离性。然而，它们的有效性是有问题的，因为它们促使的聚类有时可能是无意义的。另一方面，外部度量将算法的输出与由专家提供的参考真实分组进行比较。在本文中，我们认为常用的经典分区相似性评分，例如规范化互信息、Fowlkes-Mallows或调整兰德指数，缺少一些可取的属性，例如，它们不能正确识别最坏情况，也不易解释。

    There is no, nor will there ever be, single best clustering algorithm, but we would still like to be able to distinguish between methods which work well on certain task types and those that systematically underperform. Clustering algorithms are traditionally evaluated using either internal or external validity measures. Internal measures quantify different aspects of the obtained partitions, e.g., the average degree of cluster compactness or point separability. Yet, their validity is questionable, because the clusterings they promote can sometimes be meaningless. External measures, on the other hand, compare the algorithms' outputs to the reference, ground truth groupings that are provided by experts. In this paper, we argue that the commonly-used classical partition similarity scores, such as the normalised mutual information, Fowlkes-Mallows, or adjusted Rand index, miss some desirable properties, e.g., they do not identify worst-case scenarios correctly or are not easily interpretab
    
[^73]: 使用正则化稀疏自编码器预测良好反应坐标和MD轨迹的未来演化：一种新的深度学习方法

    Prediction of good reaction coordinates and future evolution of MD trajectories using Regularized Sparse Autoencoders: A novel deep learning approach. (arXiv:2208.10962v2 [physics.chem-ph] UPDATED)

    [http://arxiv.org/abs/2208.10962](http://arxiv.org/abs/2208.10962)

    本研究提出了一种新的深度学习方法，使用正则化稀疏自编码器预测良好的反应坐标以及MD轨迹的演化情况，并展示了正则化约束对于选择重要反应坐标的帮助。

    

    鉴定反应坐标(RCs)是一个活跃的研究领域，因为RCs在确定化学反应的进展中起着关键作用。选择反应坐标通常基于启发式知识。然而，选择的标准之一是该坐标应清晰地捕获反应物和生成物状态。此外，坐标应该是最慢的，使得所有其他自由度可以沿着反应坐标轻松达到平衡。我们使用了一种正则化稀疏自编码器，即基于能量的模型，来发现一组关键的反应坐标。除了发现反应坐标，我们的模型还可以预测分子动力学(MD)轨迹的演化。我们展示了包括稀疏约束正则化有助于选择一个小但重要的一组反应坐标。

    Identifying reaction coordinates(RCs) is an active area of research, given the crucial role RCs play in determining the progress of a chemical reaction. The choice of the reaction coordinate is often based on heuristic knowledge. However, an essential criterion for the choice is that the coordinate should capture both the reactant and product states unequivocally. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. We used a regularised sparse autoencoder, an energy-based model, to discover a crucial set of reaction coordinates. Along with discovering reaction coordinates, our model also predicts the evolution of a molecular dynamics(MD) trajectory. We showcased that including sparsity enforcing regularisation helps in choosing a small but important set of r
    
[^74]: 可证明地调整ElasticNet在多个实例间的参数

    Provably tuning the ElasticNet across instances. (arXiv:2207.10199v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.10199](http://arxiv.org/abs/2207.10199)

    这篇论文提供了一个针对ElasticNet的新颖结构结果，用以证明在多个问题实例中调整正规化参数，同时提供了统计和在线学习情景下的泛化保证。

    

    正规化理论中一个重要未解决的挑战是如何设置常用技术（如ElasticNet）的正规化系数，并提供一般可证明的保证。我们考虑了在多个问题实例中调整Ridge回归、LASSO和ElasticNet的正规化参数的问题，这种设置包括了交叉验证和多任务超参数优化。我们获得了针对ElasticNet的新颖结构结果，将损失函数表达为以调整参数为函数的分段有理函数，其中包含代数边界。我们利用这一结果对正规化损失函数的结构复杂性进行了界定，并在统计情景下展示了调整ElasticNet回归系数的泛化保证。我们还考虑了更具挑战性的在线学习情景，展示了与最优参数对相对而言，消失的平均预期遗憾。我们进一步将我们的结果扩展到调整分类问题的情景。

    An important unresolved challenge in the theory of regularization is to set the regularization coefficients of popular techniques like the ElasticNet with general provable guarantees. We consider the problem of tuning the regularization parameters of Ridge regression, LASSO, and the ElasticNet across multiple problem instances, a setting that encompasses both cross-validation and multi-task hyperparameter optimization. We obtain a novel structural result for the ElasticNet which characterizes the loss as a function of the tuning parameters as a piecewise-rational function with algebraic boundaries. We use this to bound the structural complexity of the regularized loss functions and show generalization guarantees for tuning the ElasticNet regression coefficients in the statistical setting. We also consider the more challenging online learning setting, where we show vanishing average expected regret relative to the optimal parameter pair. We further extend our results to tuning classific
    
[^75]: 张量对张量回归: 黎曼优化，过参数化，统计计算差异及其相互作用

    Tensor-on-Tensor Regression: Riemannian Optimization, Over-parameterization, Statistical-computational Gap, and Their Interplay. (arXiv:2206.08756v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2206.08756](http://arxiv.org/abs/2206.08756)

    张量对张量回归问题中，我们提出了黎曼优化方法和秩过参数化的研究，并展示了黎曼优化方法的线性和二次收敛性以及适应过参数化的能力。同时，我们证明了标量对张量回归中的统计计算差异。

    

    我们研究了张量对张量回归问题，其目标是在不知道其内在秩的情况下，将张量响应与张量协变量相连接，通过低Tucker秩参数张量/矩阵。我们提出了黎曼梯度下降（RGD）和黎曼高斯牛顿（RGN）方法，并通过研究秩过参数化的影响来应对未知秩的挑战。我们首次提供了关于一般张量对张量回归的收敛性保证，表明RGD和RGN分别在正确参数化和过参数化设置下线性和二次收敛到统计上的最优估计。我们的理论揭示了一个有趣的现象：黎曼优化方法在不修改实现方式的情况下自然地适应过参数化。我们还通过直接的低次多项式论证证明了标量对张量回归中的统计计算差异。我们的理论证明了统计学的福音。

    We study the tensor-on-tensor regression, where the goal is to connect tensor responses to tensor covariates with a low Tucker rank parameter tensor/matrix without the prior knowledge of its intrinsic rank. We propose the Riemannian gradient descent (RGD) and Riemannian Gauss-Newton (RGN) methods and cope with the challenge of unknown rank by studying the effect of rank over-parameterization. We provide the first convergence guarantee for the general tensor-on-tensor regression by showing that RGD and RGN respectively converge linearly and quadratically to a statistically optimal estimate in both rank correctly-parameterized and over-parameterized settings. Our theory reveals an intriguing phenomenon: Riemannian optimization methods naturally adapt to over-parameterization without modifications to their implementation. We also prove the statistical-computational gap in scalar-on-tensor regression by a direct low-degree polynomial argument. Our theory demonstrates a "blessing of statist
    
[^76]: 优化可解释性：卷积动态对齐网络

    Optimising for Interpretability: Convolutional Dynamic Alignment Networks. (arXiv:2109.13004v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2109.13004](http://arxiv.org/abs/2109.13004)

    CoDA Nets是一种性能良好的分类器，具有高度内在可解释性。它们通过动态对齐单元实现输入依赖的线性变换，并将输出线性分解为各个输入的贡献。这些模型在视觉质量和分类准确度上优于现有方法，并且在CIFAR-10和TinyImagenet等数据集上表现出与ResNet和VGG模型相媲美的性能。

    

    我们引入了一种新的神经网络模型，称为卷积动态对齐网络（CoDA Nets），它是一种具有高度内在可解释性的性能分类器。它们的核心构建模块是动态对齐单元（DAUs），其经过优化后能够通过动态计算的权重向量将其输入转换为与任务相关模式对齐的形式。因此，CoDA Nets通过一系列依赖于输入的线性变换来模拟分类预测，允许将输出线性分解为各个输入的贡献。根据DAUs的对齐情况，得到的贡献映射与鉴别性输入模式相一致。这些模型固有的分解具有很高的视觉质量，在定量指标下优于现有的归因方法。此外，CoDA Nets是性能出色的分类器，在CIFAR-10和TinyImagenet等数据集上取得了与ResNet和VGG模型相媲美的结果。

    We introduce a new family of neural network models called Convolutional Dynamic Alignment Networks (CoDA Nets), which are performant classifiers with a high degree of inherent interpretability. Their core building blocks are Dynamic Alignment Units (DAUs), which are optimised to transform their inputs with dynamically computed weight vectors that align with task-relevant patterns. As a result, CoDA Nets model the classification prediction through a series of input-dependent linear transformations, allowing for linear decomposition of the output into individual input contributions. Given the alignment of the DAUs, the resulting contribution maps align with discriminative input patterns. These model-inherent decompositions are of high visual quality and outperform existing attribution methods under quantitative metrics. Further, CoDA Nets constitute performant classifiers, achieving on par results to ResNet and VGG models on e.g. CIFAR-10 and TinyImagenet. Lastly, CoDA Nets can be combin
    
[^77]: SubseasonalClimateUSA: 用于亚季节预测和基准测试的数据集。

    SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking. (arXiv:2109.10399v3 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2109.10399](http://arxiv.org/abs/2109.10399)

    这个论文介绍了SubseasonalClimateUSA，这是一个用于训练和基准测试美国的亚季节预测模型的数据集。作者使用该数据集对多种模型进行了基准测试。

    

    天气的亚季节预测对资源配置和气候适应至关重要，但对预测社区提出了许多挑战。在这个预测时间范围内，基于物理的动力学模型的技能有限，并且预测目标以一种复杂的方式依赖于本地天气和全球气候变量。最近，机器学习方法显示出推进技术的潜力，但需要复杂的数据整理，将专家知识与多个相关数据来源、文件格式和时间空间分辨率的聚合进行整合。为了简化这个过程并加速未来的发展，我们介绍了SubseasonalClimateUSA，这是一个经过策划的数据集，用于训练和基准测试美国的亚季节预测模型。我们使用这个数据集来对各种不同的亚季节模型进行基准测试，包括操作性动力学模型、古典的气象基线以及十个统计模型。

    Subseasonal forecasting of the weather two to six weeks in advance is critical for resource allocation and climate adaptation but poses many challenges for the forecasting community. At this forecast horizon, physics-based dynamical models have limited skill, and the targets for prediction depend in a complex manner on both local weather and global climate variables. Recently, machine learning methods have shown promise in advancing the state of the art but only at the cost of complex data curation, integrating expert knowledge with aggregation across multiple relevant data sources, file formats, and temporal and spatial resolutions. To streamline this process and accelerate future development, we introduce SubseasonalClimateUSA, a curated dataset for training and benchmarking subseasonal forecasting models in the United States. We use this dataset to benchmark a diverse suite of subseasonal models, including operational dynamical models, classical meteorological baselines, and ten sta
    
[^78]: 任意对手下的广义正交Procrustes问题

    Generalized Orthogonal Procrustes Problem under Arbitrary Adversaries. (arXiv:2106.15493v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2106.15493](http://arxiv.org/abs/2106.15493)

    广义正交Procrustes问题在多个科学领域中起到基础性作用。SDR可以精确恢复最小二乘估计，而适当初始化下的广义功率方法以线性方式收敛于SDR的全局最小化器。

    

    广义正交Procrustes问题（Generalized Orthogonal Procrustes Problem，GOPP）在统计学、成像科学和计算机视觉等多个科学领域中都具有基础性作用。尽管其在实际中具有巨大的重要性，但通常很难找到最小二乘估计的 NP-hard 问题。我们研究了半定松弛（Semidefinite Relaxation，SDR）和一种名为广义功率方法（Generalized Power Method，GPM）的迭代方法，以寻找最小二乘估计，并研究了在信号加噪声模型下的性能。我们展示了SDR可以精确恢复最小二乘估计，并且在适当的初始化下，广义功率方法以线性方式收敛于SDR的全局最小化器，前提是信噪比较大。主要技术基于展示GPM中涉及的非线性映射本质上是局部收缩映射，然后应用著名的Banach不动点定理完成证明。此外，我们还分析了低秩分解算法。

    The generalized orthogonal Procrustes problem (GOPP) plays a fundamental role in several scientific disciplines including statistics, imaging science and computer vision. Despite its tremendous practical importance, it is generally an NP-hard problem to find the least squares estimator. We study the semidefinite relaxation (SDR) and an iterative method named generalized power method (GPM) to find the least squares estimator, and investigate the performance under a signal-plus-noise model. We show that the SDR recovers the least squares estimator exactly and moreover the generalized power method with a proper initialization converges linearly to the global minimizer to the SDR, provided that the signal-to-noise ratio is large. The main technique follows from showing the nonlinear mapping involved in the GPM is essentially a local contraction mapping and then applying the well-known Banach fixed-point theorem finishes the proof. In addition, we analyze the low-rank factorization algorith
    
[^79]: 对Riesz Representer的敌对估计

    Adversarial Estimation of Riesz Representers. (arXiv:2101.00009v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2101.00009](http://arxiv.org/abs/2101.00009)

    我们提出了一个敌对框架，使用通用函数空间来估计Riesz Representer，并且证明了非渐近均方速率以及渐近正态性的条件。这个条件使得在机器学习中进行推断时无需样本分割，并且能够提高有限样本性能。

    

    许多因果和结构参数是基于底层回归的线性泛函。Riesz Representer是半参数线性泛函渐近方差的关键组成部分。我们提出了一个敌对框架，使用通用函数空间来估计Riesz Representer。我们证明了一个非渐近均方速率，其中涉及一个称为临界半径的抽象量，然后将其专门应用于神经网络、随机森林和再生核希尔伯特空间作为主要案例。此外，我们使用临界半径理论来证明了渐近正态性，而不需要样本分割，揭示了一种“复杂度-速率鲁棒性”条件。这个条件具有实际后果：在几个机器学习设置中，可以实现无需样本分割的推断，这可能会提高有限样本性能。我们的估计器在高度非线性的模拟中实现了名义覆盖率。

    Many causal and structural parameters are linear functionals of an underlying regression. The Riesz representer is a key component in the asymptotic variance of a semiparametrically estimated linear functional. We propose an adversarial framework to estimate the Riesz representer using general function spaces. We prove a nonasymptotic mean square rate in terms of an abstract quantity called the critical radius, then specialize it for neural networks, random forests, and reproducing kernel Hilbert spaces as leading cases. Furthermore, we use critical radius theory -- in place of Donsker theory -- to prove asymptotic normality without sample splitting, uncovering a ``complexity-rate robustness'' condition. This condition has practical consequences: inference without sample splitting is possible in several machine learning settings, which may improve finite sample performance compared to sample splitting. Our estimators achieve nominal coverage in highly nonlinear simulations where previo
    
[^80]: 通过生成型随机傅立叶特征进行端到端内核学习

    End-to-end Kernel Learning via Generative Random Fourier Features. (arXiv:2009.04614v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2009.04614](http://arxiv.org/abs/2009.04614)

    本文提出了一种通过生成型随机傅立叶特征进行端到端内核学习的方法，将内核学习和线性学习器融合为一个统一框架，通过生成网络和线性分类器联合训练以实现更好的泛化性能。

    

    随机傅立叶特征（RFFs）为谱内核学习提供了一种有前景的方法。目前基于RFFs的内核学习方法通常以两阶段方式工作。在第一阶段过程中，学习最优特征映射通常被表述为目标对齐问题，其目标是将学习到的内核与预定义的目标内核（通常是理想内核）对齐。在第二阶段过程中，线性学习器针对映射的随机特征进行训练。然而，目标对齐中的预定义内核不一定对于线性学习器的泛化是最优的。相反，在本文中，我们考虑将内核学习和线性学习器融合为一个统一框架的一阶段过程。具体而言，我们设计了一个通过RFFs隐式学习内核的生成网络，接着使用一个全连接层参数化的线性分类器。然后，通过求解优化问题，联合训练生成网络和分类器。

    Random Fourier features (RFFs) provide a promising way for kernel learning in a spectral case. Current RFFs-based kernel learning methods usually work in a two-stage way. In the first-stage process, learning the optimal feature map is often formulated as a target alignment problem, which aims to align the learned kernel with the pre-defined target kernel (usually the ideal kernel). In the second-stage process, a linear learner is conducted with respect to the mapped random features. Nevertheless, the pre-defined kernel in target alignment is not necessarily optimal for the generalization of the linear learner. Instead, in this paper, we consider a one-stage process that incorporates the kernel learning and linear learner into a unifying framework. To be specific, a generative network via RFFs is devised to implicitly learn the kernel, followed by a linear classifier parameterized as a full-connected layer. Then the generative network and the classifier are jointly trained by solving th
    
[^81]: 将监督学习和VAEs统一在基于正态流的神经网络模型中对天文粒子重建进行覆盖、系统性和拟合好坏的研究

    Unifying supervised learning and VAEs -- coverage, systematics and goodness-of-fit in normalizing-flow based neural network models for astro-particle reconstructions. (arXiv:2008.05825v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2008.05825](http://arxiv.org/abs/2008.05825)

    本研究将监督学习和VAEs统一于基于正态流的神经网络模型中，对天文粒子重建进行了覆盖、系统性和拟合好坏的研究，并通过KL散度目标实现了监督学习和VAEs的统一。利用条件正态化流的方法可以计算神经网络模型的拟合优度p值。

    

    在天文粒子物理学中，基于神经网络的事件属性预测变得越来越常见。然而，在许多情况下，结果只被用作点预测。统计不确定性和覆盖率(1)，系统不确定性(2)或拟合优度度量(3)经常没有被计算。在这里，我们描述了一种特定的训练和网络架构选择，可以将所有这些属性融入到一个单一的网络模型中。我们展示了数据和标签联合分布的KL散度目标使得在随机变分推理的一种统一下将监督学习和变分自编码器(VAEs)统一起来。这种统一性激发了一种扩展的监督学习方案，可以计算神经网络模型的拟合优度p值。在这种建设中，利用神经网络进行的条件正态化流至关重要。我们讨论了它们如何为已定义的后验分布严格定义覆盖率。

    Neural-network based predictions of event properties in astro-particle physics are getting more and more common. However, in many cases the result is just utilized as a point prediction. Statistical uncertainties and coverage (1), systematic uncertainties (2) or a goodness-of-fit measure (3) are often not calculated. Here we describe a certain choice of training and network architecture that allows to incorporate all these properties into a single network model. We show that a KL-divergence objective of the joint distribution of data and labels allows to unify supervised learning and variational autoencoders (VAEs) under one umbrella of stochastic variational inference. The unification motivates an extended supervised learning scheme which allows to calculate a goodness-of-fit p-value for the neural network model. Conditional normalizing flows amortized with a neural network are crucial in this construction. We discuss how they allow to rigorously define coverage for posteriors defined
    
[^82]: 关于偏压压缩在分布式学习中的应用

    On Biased Compression for Distributed Learning. (arXiv:2002.12410v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2002.12410](http://arxiv.org/abs/2002.12410)

    本研究研究了偏压压缩在分布式学习中的应用，首次证明了偏压压缩器可以在单节点和分布式环境中实现线性收敛速率。

    

    近年来，各种通信压缩技术作为分布式学习中缓解通信瓶颈的必不可少的工具而出现。然而，尽管偏压压缩器在实践中往往表现出比被广泛研究和理解的无偏压压缩器更好的性能，但对它们的了解非常有限。在本研究中，我们研究了三类偏压压缩算子，其中两类是新的，并研究了它们在（随机）梯度下降和分布式（随机）梯度下降中的性能。我们首次证明了偏压压缩器可以在单节点和分布式环境中实现线性收敛速率。我们证明了经过错误反馈机制处理的分布式压缩的SGD方法具有遗传速率$O\left( \delta L \exp \left[-\frac{\mu K}{\delta L}\right] + \frac{(C + \delta D)}{K\mu}\right)$，其中$\delta\ge 1$是一个逐渐增长的压缩参数，m未完待续

    In the last few years, various communication compression techniques have emerged as an indispensable tool helping to alleviate the communication bottleneck in distributed learning. However, despite the fact biased compressors often show superior performance in practice when compared to the much more studied and understood unbiased compressors, very little is known about them. In this work we study three classes of biased compression operators, two of which are new, and their performance when applied to (stochastic) gradient descent and distributed (stochastic) gradient descent. We show for the first time that biased compressors can lead to linear convergence rates both in the single node and distributed settings. We prove that distributed compressed SGD method, employed with error feedback mechanism, enjoys the ergodic rate $O\left( \delta L \exp \left[-\frac{\mu K}{\delta L}\right] + \frac{(C + \delta D)}{K\mu}\right)$, where $\delta\ge 1$ is a compression parameter which grows when m
    
[^83]: 关于带动量的随机梯度下降方法的泛化性能研究

    On the Generalization of Stochastic Gradient Descent with Momentum. (arXiv:1809.04564v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1809.04564](http://arxiv.org/abs/1809.04564)

    该论文研究了带动量的随机梯度下降方法的泛化性能，并通过分析不同的损失函数形式和动量范围，提出了一种可以在多个周期内训练机器学习模型并保证泛化性能的修改后的动量更新规则。对于特殊情况下的损失函数，标准的带动量随机梯度下降方法也能够具有泛化性能。该论文还给出了对于期望真实风险的上界估计。

    

    尽管在训练机器学习模型时，基于动量的加速随机梯度下降（SGD）变种广泛应用，但对于这些方法的泛化误差几乎没有理论上的理解。在这项工作中，我们首先展示了存在一种凸损失函数，对于多个周期的标准重球动量（SGDM）SGD，其稳定间隙变得无限大。然后，对于平滑Lipschitz损失函数，我们分析了一种修改后的基于动量的更新规则，即SGD提前动量（SGDEM），在广泛的步长范围内，它可以在多个周期内训练机器学习模型并保证泛化性能。最后，对于强凸损失函数的特殊情况，我们发现了一种动量范围，使得多个周期的标准SGDM，作为SGDEM的特殊形式，也具有泛化性能。在泛化性能的基础上，我们还对期望真实风险进行了一个上界，与训练步骤数量有关。

    While momentum-based accelerated variants of stochastic gradient descent (SGD) are widely used when training machine learning models, there is little theoretical understanding on the generalization error of such methods. In this work, we first show that there exists a convex loss function for which the stability gap for multiple epochs of SGD with standard heavy-ball momentum (SGDM) becomes unbounded. Then, for smooth Lipschitz loss functions, we analyze a modified momentum-based update rule, i.e., SGD with early momentum (SGDEM) under a broad range of step-sizes, and show that it can train machine learning models for multiple epochs with a guarantee for generalization. Finally, for the special case of strongly convex loss functions, we find a range of momentum such that multiple epochs of standard SGDM, as a special form of SGDEM, also generalizes. Extending our results on generalization, we also develop an upper bound on the expected true risk, in terms of the number of training step
    

