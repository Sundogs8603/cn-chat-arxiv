# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Effect of Weight Quantization on Learning Models by Typical Case Analysis.](http://arxiv.org/abs/2401.17269) | 本文研究了大规模数据分析模型中的权重量化方法及超参数选择。通过典型案例分析，我们发现低位数和大量化宽度会导致不稳定的超参数阶段。 |
| [^2] | [Adaptive Experiment Design with Synthetic Controls.](http://arxiv.org/abs/2401.17205) | 这种方法提出了Syntax，一个具有合成对照组的自适应实验设计，能够在多个亚群体中识别出具有正面治疗效果的亚群体，对于多样化患者反应的临床试验具有样本效率的优势。 |
| [^3] | [Dynamical Survival Analysis with Controlled Latent States.](http://arxiv.org/abs/2401.17077) | 本论文提出了一种动态生存分析方法，通过控制潜在状态来学习个体特定的计数过程强度。研究者设计了一个神经控制微分方程模型，并证明了在足够正则条件下，可以在签名空间中线性化模型，得到一种基于签名的估计器。通过对金融、预测性维护和食品供应链管理等数据集的实验，验证了模型的性能。 |
| [^4] | [Gower's similarity coefficients with automatic weight selection.](http://arxiv.org/abs/2401.17041) | Gower相似系数是一种用于处理混合类型变量的最受欢迎的不相似性度量方法，它能够处理缺失值并允许用户定义加权方案。 |
| [^5] | [Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration.](http://arxiv.org/abs/2401.17037) | 该论文研究了基于无噪声观测的贝叶斯优化问题，提出了一种基于散乱数据逼近的新算法，并引入随机探索步骤以实现接近最优填充距离的速率衰减。该算法在实现的易用性和累积遗憾边界的性能上超过了传统的GP-UCB算法，并在多个示例中优于其他贝叶斯优化策略。 |
| [^6] | [Causal Machine Learning for Cost-Effective Allocation of Development Aid.](http://arxiv.org/abs/2401.16986) | 本文提出了一个因果机器学习框架，用于预测援助分配的异质化治疗效果，以支持有效的援助分配决策。 |
| [^7] | [Multiple Yield Curve Modeling and Forecasting using Deep Learning.](http://arxiv.org/abs/2401.16985) | 本文介绍了一种使用深度学习模型同时描述多种收益率曲线动态的方法，并通过结合自注意机制和非参数分位数回归，生成未来收益率的点预测和区间预测。实验证实了该方法的有效性，并且提出了深度集成和迁移学习的扩展和改进。 |
| [^8] | [Dynamical System Identification, Model Selection and Model Uncertainty Quantification by Bayesian Inference.](http://arxiv.org/abs/2401.16943) | 本研究提出了一种基于贝叶斯推理的动力系统识别方法，可以估计模型系数，进行模型排序和模型不确定性量化，并展示了与其他算法的比较结果。 |
| [^9] | [Analysis of Knowledge Tracing performance on synthesised student data.](http://arxiv.org/abs/2401.16832) | 通过合成数据进行训练可以达到与真实数据相似的知识追踪性能。 |
| [^10] | [Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods.](http://arxiv.org/abs/2401.16776) | 本研究提出一种嵌套APT方法来解决顺序神经后验估计中的嵌套期望计算问题，从而实现了收敛性分析。 |
| [^11] | [Polynomial Chaos Expansions on Principal Geodesic Grassmannian Submanifolds for Surrogate Modeling and Uncertainty Quantification.](http://arxiv.org/abs/2401.16683) | 本论文提出了一种基于流形学习的代理建模框架，用于高维随机系统中的不确定性量化。通过在Grassmann流形上进行主测地分析，识别出一组潜在的低维描述符，然后利用多项式混沌展开构建映射。 |
| [^12] | [Rademacher Complexity of Neural ODEs via Chen-Fliess Series.](http://arxiv.org/abs/2401.16655) | 本文通过Chen-Fliess序列展开将连续深度神经ODE模型转化为单层、无限宽度的网络，并利用此框架推导出了将初始条件映射到某个终端时间的ODE模型的Rademacher复杂度的紧凑表达式。 |
| [^13] | [Learning a Gaussian Mixture for Sparsity Regularization in Inverse Problems.](http://arxiv.org/abs/2401.16612) | 本研究提出了一种基于高斯混合模型的稀疏正则化方法，通过神经网络进行贝叶斯估计，有效地解决了逆问题中的稀疏建模和参数估计问题。 |
| [^14] | [PrIsing: Privacy-Preserving Peer Effect Estimation via Ising Model.](http://arxiv.org/abs/2401.16596) | 本文提出了通过Ising模型实现隐私保护的同伴效应估计算法，能够精确估计自然参数并保护个体代理结果的隐私，在合成数据集和现实世界网络上具有良好的性能。 |
| [^15] | [Individualized Multi-Treatment Response Curves Estimation using RBF-net with Shared Neurons.](http://arxiv.org/abs/2401.16571) | 我们提出了一种使用共享神经元的RBF网络的非参数化治疗效应估计方法，适用于多治疗设置。该方法能够建模治疗结果的共同性，并在贝叶斯框架下实现估计和推断，通过模拟实验证明了其数值性能，应用于真实临床数据后也得到了有趣的发现。 |
| [^16] | [Parallel Affine Transformation Tuning of Markov Chain Monte Carlo.](http://arxiv.org/abs/2401.16567) | 本文研究了采用双射仿射变换来改善Markov Chain Monte Carlo采样器性能的方法，并提出了一种灵活并用户友好的自适应学习仿射变换的方案。实验证明，与Gibbsian极坐标切片采样相结合产生的样本具有高质量且计算成本较低。 |
| [^17] | [Topological Detection of Phenomenological Bifurcations with Unreliable Kernel Densities.](http://arxiv.org/abs/2401.16563) | 本研究提出了一种利用不可靠密度估计检测P型分岔的方法，并比较了几种复制原始持久化图的方法。 |
| [^18] | [Active learning of Boltzmann samplers and potential energies with quantum mechanical accuracy.](http://arxiv.org/abs/2401.16487) | 该论文利用增强采样、深度生成模型和主动学习机器学习势能的方法，开发了一个自适应马尔科夫链蒙特卡洛框架，实现了高效的量子精度分子动力学模拟及玻尔兹曼分布采样。 |
| [^19] | [Improving conversion rate prediction via self-supervised pre-training in online advertising.](http://arxiv.org/abs/2401.16432) | 这项研究通过自监督预训练方法，改进了在线广告系统中的转化率预测。由于数据稀疏性的挑战，添加非点击归因的转化会损坏模型的校准，而自监督预训练能够解决这个问题。 |
| [^20] | [High-Dimensional False Discovery Rate Control for Dependent Variables.](http://arxiv.org/abs/2401.15796) | 提出了一个新框架，在高维度相关变量情况下实现虚警率控制，通过综合层次图模型在T-Rex框架中利用依赖结构，利用鞅论证明变量惩罚机制确保了FDR的控制。 |
| [^21] | [Bayesian Nonparametrics meets Data-Driven Robust Optimization.](http://arxiv.org/abs/2401.15771) | 本文提出了一种将贝叶斯非参数方法与最新的决策理论模型相结合的鲁棒优化准则，通过这种方法，可以在线性回归问题中获得有稳定性和优越性能的结果。 |
| [^22] | [FDR-Controlled Portfolio Optimization for Sparse Financial Index Tracking.](http://arxiv.org/abs/2401.15139) | 本论文提出了一种扩展的T-Rex框架，用于在稀疏金融指数跟踪中选择少数相关变量，并通过集成最近邻惩罚机制，可靠控制误发现率（FDR）。实验证明了该方法在过去20年内基于少量股票准确跟踪标准普尔500指数的能力。 |
| [^23] | [Causal Forecasting for Pricing.](http://arxiv.org/abs/2312.15282) | 本文提出了一种在定价环境下进行需求预测的新方法，通过将因果推断的双重机器学习方法和最先进的基于变压器的预测模型结合在一起，我们的方法在完全控制的情况下更好地估计因果效应，并在离线政策设置中优于其他预测方法。 |
| [^24] | [Policy Learning with Distributional Welfare.](http://arxiv.org/abs/2311.15878) | 本文提出了一种针对分配福利的最优治疗分配策略，该策略根据个体治疗效应的条件分位数来决定治疗分配，并引入了鲁棒的最小最大化策略来解决对反事实结果联合分布的恢复问题。 |
| [^25] | [Equivariant Matrix Function Neural Networks.](http://arxiv.org/abs/2310.10434) | 矩阵函数神经网络（MFNs）是一种通过解析矩阵等变函数来参数化非局部相互作用的新型架构，能够在各种应用中实现最先进的性能。 |
| [^26] | [Exact Inference for Continuous-Time Gaussian Process Dynamics.](http://arxiv.org/abs/2309.02351) | 本论文提出了一种对连续时间高斯过程动力学进行精确推断的方法，解决了在离散时间下进行预测可能带来的问题，并利用高阶数值积分器进行动力学函数的离散化，避免了传统方法中的近似推断的限制。 |
| [^27] | [Unified Transfer Learning Models for High-Dimensional Linear Regression.](http://arxiv.org/abs/2307.00238) | UTrans是一种统一转移学习模型，它能检测可转移变量和源数据，并具有较低的估计和预测误差，同时保持可解释性。 |
| [^28] | [Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast.](http://arxiv.org/abs/2306.07119) | 本文提出了一种基于相似度度量的通用框架，利用k最近邻的方式构建邻域，并通过平均来改进可能简单模型的预测，提高异质性时间序列的预测准确性。 |
| [^29] | [DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method.](http://arxiv.org/abs/2305.16284) | 本文提出了一种名为DoWG的无参数梯度下降方法，它是第一个既高效又通用的算法，能够自适应于平稳和非平稳问题，并且无需回溯搜索过程。 |
| [^30] | [Federated Stochastic Bandit Learning with Unobserved Context.](http://arxiv.org/abs/2303.17043) | 本文提出了一种联邦随机多臂上下文赌博算法以最大化累积奖励，针对未知上下文的情况通过执行特征向量转换解决问题。 |
| [^31] | [Data-dependent Generalization Bounds via Variable-Size Compressibility.](http://arxiv.org/abs/2303.05369) | 本文通过引入可变大小压缩性框架，建立了一种新的数据相关的泛化误差上界。该方法将算法的泛化误差与其输入数据的可变大小压缩率相关联，并提供了依赖于经验分布而非未知分布的界限。此外，该方法还可以推导出输入数据和输出假设随机变量的任何函数的泛化界限，并包含并可能优于现有的基于PAC-Bayes和数据相关内在维度的界限。 |
| [^32] | [Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing.](http://arxiv.org/abs/2212.10789) | 本论文介绍了一种名为MoleculeSTM的多模态分子结构-文本模型，通过联合学习化学结构和文本描述，可以实现基于文本的检索和编辑。通过构建大型的多模态数据集，并设计挑战性的零样本任务进行验证，该模型展示了开放词汇和组合性的特性。 |
| [^33] | [Doubly robust nearest neighbors in factor models.](http://arxiv.org/abs/2211.14297) | 该论文介绍了一种在潜在因子模型中处理缺失数据的双重稳健最近邻方法，可以提供一致的估计，并在存在良好的行和列邻居时提供（近似）二次改进非渐近性能。 |
| [^34] | [On the potential benefits of entropic regularization for smoothing Wasserstein estimators.](http://arxiv.org/abs/2210.06934) | 本文研究了熵正则化作为一种平滑方法在Wasserstein估计器中的潜在益处，通过替换最优输运成本的正则化版本来实现。主要发现是熵正则化可以以较低的计算成本达到与未正则化的Wasserstein估计器相当的统计性能。 |
| [^35] | [Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios.](http://arxiv.org/abs/2206.01900) | 本论文提出了一个可解释的反事实循环网络，用于在复杂的多智能体场景中估计干预效果。该模型考虑了时间变化的多智能体关系和协变量反事实预测的复杂结构，能够准确评估个体治疗效果，并提供解释性。 |
| [^36] | [Nearest neighbor process: weak convergence and non-asymptotic bound.](http://arxiv.org/abs/2110.15083) | 本文介绍了一种中心统计量——最近邻测度，并通过均匀中心极限定理和一种均匀的非渐近界限研究了它。该测度可能为推断提供了一种替代方法。 |

# 详细

[^1]: 权重量化对典型案例分析中学习模型的影响

    Effect of Weight Quantization on Learning Models by Typical Case Analysis. (arXiv:2401.17269v1 [stat.ML])

    [http://arxiv.org/abs/2401.17269](http://arxiv.org/abs/2401.17269)

    本文研究了大规模数据分析模型中的权重量化方法及超参数选择。通过典型案例分析，我们发现低位数和大量化宽度会导致不稳定的超参数阶段。

    

    本文研究了在大规模数据分析模型中使用的量化方法及其超参数选择。随着数据分析规模的增加，计算资源需求显著增加。为了解决这个问题，在数据分析应用（如深度学习）中，量化模型权重已经成为一种常见的做法。对于在计算资源有限的设备上部署大型模型，量化尤为重要。然而，量化超参数的选择，如位数和权重量化的值范围，仍然是一个未经充分研究的领域。在本研究中，我们采用了统计物理学中的典型案例分析方法，具体是重复方法，来探索超参数对简单学习模型量化的影响。我们的分析得出了三个关键发现：（i）小位数和大量化宽度会导致不稳定的超参数阶段，即重复对称性破缺；（ii）

    This paper examines the quantization methods used in large-scale data analysis models and their hyperparameter choices. The recent surge in data analysis scale has significantly increased computational resource requirements. To address this, quantizing model weights has become a prevalent practice in data analysis applications such as deep learning. Quantization is particularly vital for deploying large models on devices with limited computational resources. However, the selection of quantization hyperparameters, like the number of bits and value range for weight quantization, remains an underexplored area. In this study, we employ the typical case analysis from statistical physics, specifically the replica method, to explore the impact of hyperparameters on the quantization of simple learning models. Our analysis yields three key findings: (i) an unstable hyperparameter phase, known as replica symmetry breaking, occurs with a small number of bits and a large quantization width; (ii) t
    
[^2]: 具有合成对照组的自适应实验设计

    Adaptive Experiment Design with Synthetic Controls. (arXiv:2401.17205v1 [stat.ML])

    [http://arxiv.org/abs/2401.17205](http://arxiv.org/abs/2401.17205)

    这种方法提出了Syntax，一个具有合成对照组的自适应实验设计，能够在多个亚群体中识别出具有正面治疗效果的亚群体，对于多样化患者反应的临床试验具有样本效率的优势。

    

    临床试验通常用于了解新治疗对给定患者群体的影响。然而，大规模群体中的患者很少以相同的方式对待相同的治疗做出反应。患者反应的多样性需要进行多个亚群体的效果研究 - 尤其是当治疗对整体群体没有或几乎没有益处，而对特定亚群体可能具有显著的益处时。基于这种需求，我们提出了Syntax，一种探索性试验设计，在众多亚群体中识别具有正面治疗效果的亚群体。Syntax具有样本效率，因为它(i) 自适应招募和分配患者，(ii) 通过合成对照组形成每个亚群体的控制样本，从而估计治疗效果。我们通过实验证实了Syntax的性能，并提供了关于它何时可能优于传统试验设计的见解。

    Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations - especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through e
    
[^3]: 动态生存分析与控制潜在状态

    Dynamical Survival Analysis with Controlled Latent States. (arXiv:2401.17077v1 [stat.ML])

    [http://arxiv.org/abs/2401.17077](http://arxiv.org/abs/2401.17077)

    本论文提出了一种动态生存分析方法，通过控制潜在状态来学习个体特定的计数过程强度。研究者设计了一个神经控制微分方程模型，并证明了在足够正则条件下，可以在签名空间中线性化模型，得到一种基于签名的估计器。通过对金融、预测性维护和食品供应链管理等数据集的实验，验证了模型的性能。

    

    我们考虑从一组静态变量和不规则采样的时间序列中学习个体特定的计数过程强度的任务。我们引入一种新颖的建模方法，其中强度是控制微分方程的解。首先，我们通过构建神经控制微分方程来设计一个神经估计器。然后，我们证明在足够正则条件下，我们的模型可以在签名空间中线性化，得到一种基于签名的估计器，我们称之为CoxSig。我们为这两种估计器提供理论学习保证，并展示了我们的模型在金融、预测性维护和食品供应链管理等各种模拟和真实数据集上的性能。

    We consider the task of learning individual-specific intensities of counting processes from a set of static variables and irregularly sampled time series. We introduce a novel modelization approach in which the intensity is the solution to a controlled differential equation. We first design a neural estimator by building on neural controlled differential equations. In a second time, we show that our model can be linearized in the signature space under sufficient regularity conditions, yielding a signature-based estimator which we call CoxSig. We provide theoretical learning guarantees for both estimators, before showcasing the performance of our models on a vast array of simulated and real-world datasets from finance, predictive maintenance and food supply chain management.
    
[^4]: Gower相似系数与自动权重选择

    Gower's similarity coefficients with automatic weight selection. (arXiv:2401.17041v1 [stat.ME])

    [http://arxiv.org/abs/2401.17041](http://arxiv.org/abs/2401.17041)

    Gower相似系数是一种用于处理混合类型变量的最受欢迎的不相似性度量方法，它能够处理缺失值并允许用户定义加权方案。

    

    最近邻方法在统计学中变得流行起来，并在统计学习中发挥着重要作用。最近邻方法中的重要决策涉及要使用的变量（当存在许多潜在候选变量时）以及如何测量单位之间的不相似性。第一个决策取决于应用的范围，而第二个决策主要取决于变量的类型。不幸的是，相对较少的选项可以处理混合类型的变量，这在实际应用中经常遇到。混合类型变量的最受欢迎的不相似性是作为Gower相似系数的补集推导而来。它具有吸引力，因为它的取值范围在0和1之间，是变量之间缩放的不相似性的平均值，可以处理缺失值，并且在平均不相似性时允许用户定义的加权方案。有关加权方案的讨论有时会引导人们错误的认识，因为它经常忽略了不加权的情况。

    Nearest-neighbor methods have become popular in statistics and play a key role in statistical learning. Important decisions in nearest-neighbor methods concern the variables to use (when many potential candidates exist) and how to measure the dissimilarity between units. The first decision depends on the scope of the application while second depends mainly on the type of variables. Unfortunately, relatively few options permit to handle mixed-type variables, a situation frequently encountered in practical applications. The most popular dissimilarity for mixed-type variables is derived as the complement to one of the Gower's similarity coefficient. It is appealing because ranges between 0 and 1, being an average of the scaled dissimilarities calculated variable by variable, handles missing values and allows for a user-defined weighting scheme when averaging dissimilarities. The discussion on the weighting schemes is sometimes misleading since it often ignores that the unweighted "standar
    
[^5]: 基于无噪声观测的贝叶斯优化：通过随机探索改善遗憾边界

    Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration. (arXiv:2401.17037v1 [cs.LG])

    [http://arxiv.org/abs/2401.17037](http://arxiv.org/abs/2401.17037)

    该论文研究了基于无噪声观测的贝叶斯优化问题，提出了一种基于散乱数据逼近的新算法，并引入随机探索步骤以实现接近最优填充距离的速率衰减。该算法在实现的易用性和累积遗憾边界的性能上超过了传统的GP-UCB算法，并在多个示例中优于其他贝叶斯优化策略。

    

    本文研究了基于无噪声观测的贝叶斯优化。我们引入了新的基于散乱数据逼近的算法，并通过随机探索步骤确保查询点的填充距离以接近最优的速率衰减。我们的算法保留了经典的GP-UCB算法的易实现性，并满足了几乎与arXiv:2002.05096中的猜想相匹配的累积遗憾边界，从而解决了COLT的一个开放问题。此外，新算法在几个示例中优于GP-UCB和其他流行的贝叶斯优化策略。

    This paper studies Bayesian optimization with noise-free observations. We introduce new algorithms rooted in scattered data approximation that rely on a random exploration step to ensure that the fill-distance of query points decays at a near-optimal rate. Our algorithms retain the ease of implementation of the classical GP-UCB algorithm and satisfy cumulative regret bounds that nearly match those conjectured in arXiv:2002.05096, hence solving a COLT open problem. Furthermore, the new algorithms outperform GP-UCB and other popular Bayesian optimization strategies in several examples.
    
[^6]: 用于成本效益优化的因果机器学习在发展援助分配中的应用

    Causal Machine Learning for Cost-Effective Allocation of Development Aid. (arXiv:2401.16986v1 [stat.ML])

    [http://arxiv.org/abs/2401.16986](http://arxiv.org/abs/2401.16986)

    本文提出了一个因果机器学习框架，用于预测援助分配的异质化治疗效果，以支持有效的援助分配决策。

    

    联合国的可持续发展目标提供了“无人被遗弃”的更美好未来蓝图，为了在2030年之前实现这些目标，贫穷国家需要大量的发展援助。本文提出了一个因果机器学习框架，用于预测援助分配的异质化治疗效果，以支持有效的援助分配决策。具体而言，我们的框架包括三个组成部分：（i）一个平衡自编码器，利用表示学习将高维国家特征嵌入，同时解决治疗选择偏差问题；（ii）一个反事实生成器，用于计算在不同援助规模下的反事实结果，以解决小样本问题；（iii）一个推断模型，用于预测异质化的治疗效果曲线。我们使用105个国家战略性发展援助数据（总额超过52亿美元），以结束HIV/AIDS为目标，证明了我们的框架的有效性。

    The Sustainable Development Goals (SDGs) of the United Nations provide a blueprint of a better future by 'leaving no one behind', and, to achieve the SDGs by 2030, poor countries require immense volumes of development aid. In this paper, we develop a causal machine learning framework for predicting heterogeneous treatment effects of aid disbursements to inform effective aid allocation. Specifically, our framework comprises three components: (i) a balancing autoencoder that uses representation learning to embed high-dimensional country characteristics while addressing treatment selection bias; (ii) a counterfactual generator to compute counterfactual outcomes for varying aid volumes to address small sample-size settings; and (iii) an inference model that is used to predict heterogeneous treatment-response curves. We demonstrate the effectiveness of our framework using data with official development aid earmarked to end HIV/AIDS in 105 countries, amounting to more than USD 5.2 billion. F
    
[^7]: 使用深度学习进行多种收益率曲线建模和预测

    Multiple Yield Curve Modeling and Forecasting using Deep Learning. (arXiv:2401.16985v1 [stat.ML])

    [http://arxiv.org/abs/2401.16985](http://arxiv.org/abs/2401.16985)

    本文介绍了一种使用深度学习模型同时描述多种收益率曲线动态的方法，并通过结合自注意机制和非参数分位数回归，生成未来收益率的点预测和区间预测。实验证实了该方法的有效性，并且提出了深度集成和迁移学习的扩展和改进。

    

    本文介绍了一种使用深度学习模型同时描述多种收益率曲线动态的方法。我们旨在学习金融市场全球化引起的不同收益率曲线之间的依赖结构，并利用它来产生更准确的预测。通过结合自注意机制和非参数分位数回归，我们的模型可以生成未来收益率的点预测和区间预测。该框架的设计旨在避免影响多个分位数回归模型的分位数交叉问题。对两个不同数据集进行的数值实验证实了我们方法的有效性。最后，我们通过结合深度集成方法和迁移学习机制，探讨了潜在的扩展和改进。

    This manuscript introduces deep learning models that simultaneously describe the dynamics of several yield curves. We aim to learn the dependence structure among the different yield curves induced by the globalization of financial markets and exploit it to produce more accurate forecasts. By combining the self-attention mechanism and nonparametric quantile regression, our model generates both point and interval forecasts of future yields. The architecture is designed to avoid quantile crossing issues affecting multiple quantile regression models. Numerical experiments conducted on two different datasets confirm the effectiveness of our approach. Finally, we explore potential extensions and enhancements by incorporating deep ensemble methods and transfer learning mechanisms.
    
[^8]: 动力系统识别、模型选择和贝叶斯推理中的模型不确定性量化

    Dynamical System Identification, Model Selection and Model Uncertainty Quantification by Bayesian Inference. (arXiv:2401.16943v1 [stat.ME])

    [http://arxiv.org/abs/2401.16943](http://arxiv.org/abs/2401.16943)

    本研究提出了一种基于贝叶斯推理的动力系统识别方法，可以估计模型系数，进行模型排序和模型不确定性量化，并展示了与其他算法的比较结果。

    

    本研究提出了一种基于贝叶斯最大后验概率 (MAP) 框架的动力系统识别方法，用于从时间序列数据中恢复系统模型。实验证明这等价于广义的零阶 Tikhonov 正则化，通过负对数似然和先验分布来合理选择残差和正则化项。除了估计模型系数外，贝叶斯解释还提供了完整的贝叶斯推理工具，包括模型排序、模型不确定性量化和未知超参数的估计。通过应用于带有噪声的几个动力系统，比较了两种贝叶斯算法，即联合最大后验概率 (JMAP) 和变分贝叶斯近似 (VBA)，与流行的阈值最小二乘回归算法SINDy。对于多元高斯似然和先验分布，

    This study presents a Bayesian maximum \textit{a~posteriori} (MAP) framework for dynamical system identification from time-series data. This is shown to be equivalent to a generalized zeroth-order Tikhonov regularization, providing a rational justification for the choice of the residual and regularization terms, respectively, from the negative logarithms of the likelihood and prior distributions. In addition to the estimation of model coefficients, the Bayesian interpretation gives access to the full apparatus for Bayesian inference, including the ranking of models, the quantification of model uncertainties and the estimation of unknown (nuisance) hyperparameters. Two Bayesian algorithms, joint maximum \textit{a~posteriori} (JMAP) and variational Bayesian approximation (VBA), are compared to the popular SINDy algorithm for thresholded least-squares regression, by application to several dynamical systems with added noise. For multivariate Gaussian likelihood and prior distributions, the
    
[^9]: 对合成学生数据的知识追踪性能分析

    Analysis of Knowledge Tracing performance on synthesised student data. (arXiv:2401.16832v1 [cs.CY])

    [http://arxiv.org/abs/2401.16832](http://arxiv.org/abs/2401.16832)

    通过合成数据进行训练可以达到与真实数据相似的知识追踪性能。

    

    知识追踪旨在通过跟踪学生的知识状态的发展来预测他们未来的表现。尽管在这一领域取得了一些进展，但由于数据保护问题，KT模型在教育系统中的应用仍受到数据限制：1）由于数据保护问题，无法获得现实生活数据；2）公共数据集中缺乏多样性；3）基准数据集中存在重复记录的噪音。为解决这些问题，我们使用三种基于公共数据集的统计策略模拟了学生数据，并测试了它们在两个KT基准上的性能。虽然我们观察到额外的合成数据只带来了轻微的性能改进，但我们的研究表明，仅使用合成数据进行训练可以达到与真实数据相似的性能水平。

    Knowledge Tracing (KT) aims to predict the future performance of students by tracking the development of their knowledge states. Despite all the recent progress made in this field, the application of KT models in education systems is still restricted from the data perspectives: 1) limited access to real life data due to data protection concerns, 2) lack of diversity in public datasets, 3) noises in benchmark datasets such as duplicate records. To resolve these problems, we simulated student data with three statistical strategies based on public datasets and tested their performance on two KT baselines. While we observe only minor performance improvement with additional synthetic data, our work shows that using only synthetic data for training can lead to similar performance as real data.
    
[^10]: 利用嵌套MLMC对具有难以处理的似然函数的顺序神经后验估计进行优化

    Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods. (arXiv:2401.16776v1 [stat.CO])

    [http://arxiv.org/abs/2401.16776](http://arxiv.org/abs/2401.16776)

    本研究提出一种嵌套APT方法来解决顺序神经后验估计中的嵌套期望计算问题，从而实现了收敛性分析。

    

    最近提出了顺序神经后验估计（SNPE）技术，用于处理具有难以处理的似然函数的基于模拟的模型。它们致力于通过使用基于神经网络的条件密度估计器自适应地生成的模拟来学习后验。作为一种SNPE技术，Greenberg等人（2019）提出的自动后验变换（APT）方法表现出色，并可应用于高维数据。然而，APT方法包含计算难以处理的归一化常数的对数的期望，即嵌套期望。尽管原子APT通过离散化归一化常数来解决这个问题，但分析学习的收敛性仍然具有挑战性。在本文中，我们提出了一种嵌套APT方法来估计相关的嵌套期望。这有助于建立收敛性分析。由于损失函数及其梯度的嵌套估计是有偏的，我们进行了

    Sequential neural posterior estimation (SNPE) techniques have been recently proposed for dealing with simulation-based models with intractable likelihoods. They are devoted to learning the posterior from adaptively proposed simulations using neural network-based conditional density estimators. As a SNPE technique, the automatic posterior transformation (APT) method proposed by Greenberg et al. (2019) performs notably and scales to high dimensional data. However, the APT method bears the computation of an expectation of the logarithm of an intractable normalizing constant, i.e., a nested expectation. Although atomic APT was proposed to solve this by discretizing the normalizing constant, it remains challenging to analyze the convergence of learning. In this paper, we propose a nested APT method to estimate the involved nested expectation instead. This facilitates establishing the convergence analysis. Since the nested estimators for the loss function and its gradient are biased, we make
    
[^11]: 在主测地Grassmannian子流形上的多项式混沌展开用于代理建模和不确定性量化

    Polynomial Chaos Expansions on Principal Geodesic Grassmannian Submanifolds for Surrogate Modeling and Uncertainty Quantification. (arXiv:2401.16683v1 [stat.ML])

    [http://arxiv.org/abs/2401.16683](http://arxiv.org/abs/2401.16683)

    本论文提出了一种基于流形学习的代理建模框架，用于高维随机系统中的不确定性量化。通过在Grassmann流形上进行主测地分析，识别出一组潜在的低维描述符，然后利用多项式混沌展开构建映射。

    

    在这项工作中，我们介绍了一种基于流形学习的代理建模框架，用于高维随机系统中的不确定性量化。我们的首要目标是对可用的模拟数据进行数据挖掘，以确定能够高效参数化高维计算模型响应的一组低维（潜在）描述符。为此，我们采用Grassmann流形上的主测地分析，识别出一组可能具有不同维度的不相交主测地子流形，以捕捉数据的变化。由于Grassmann上的操作需要数据集中，我们提出了一种基于Riemanniann K-means和Grassmann流形上样本Frechet方差最小化的自适应算法，用于识别代表参数空间中不同系统行为的“本地”主测地子流形。然后使用多项式混沌展开构建映射

    In this work we introduce a manifold learning-based surrogate modeling framework for uncertainty quantification in high-dimensional stochastic systems. Our first goal is to perform data mining on the available simulation data to identify a set of low-dimensional (latent) descriptors that efficiently parameterize the response of the high-dimensional computational model. To this end, we employ Principal Geodesic Analysis on the Grassmann manifold of the response to identify a set of disjoint principal geodesic submanifolds, of possibly different dimension, that captures the variation in the data. Since operations on the Grassmann require the data to be concentrated, we propose an adaptive algorithm based on Riemanniann K-means and the minimization of the sample Frechet variance on the Grassmann manifold to identify "local" principal geodesic submanifolds that represent different system behavior across the parameter space. Polynomial chaos expansion is then used to construct a mapping bet
    
[^12]: 通过Chen-Fliess序列，我们展示了如何将连续深度神经ODE模型构建为单层、无限宽度的网络。

    Rademacher Complexity of Neural ODEs via Chen-Fliess Series. (arXiv:2401.16655v1 [stat.ML])

    [http://arxiv.org/abs/2401.16655](http://arxiv.org/abs/2401.16655)

    本文通过Chen-Fliess序列展开将连续深度神经ODE模型转化为单层、无限宽度的网络，并利用此框架推导出了将初始条件映射到某个终端时间的ODE模型的Rademacher复杂度的紧凑表达式。

    

    本文将连续深度神经ODE模型使用Chen-Fliess序列展开为单层、无限宽度的网络。在这个网络中，输出的“权重”来自控制输入的特征序列，它由控制输入在单纯形上的迭代积分构成。而“特征”则基于受控ODE模型中输出函数相对于向量场的迭代李导数。本文的主要结果是，应用这个框架推导出了将初始条件映射到某个终端时间的ODE模型的Rademacher复杂度的紧凑表达式。这一结果利用了单层结构所带来的直接分析性质。最后，我们通过一些具体系统的例子实例化该界，并讨论了可能的后续工作。

    We show how continuous-depth neural ODE models can be framed as single-layer, infinite-width nets using the Chen--Fliess series expansion for nonlinear ODEs. In this net, the output ''weights'' are taken from the signature of the control input -- a tool used to represent infinite-dimensional paths as a sequence of tensors -- which comprises iterated integrals of the control input over a simplex. The ''features'' are taken to be iterated Lie derivatives of the output function with respect to the vector fields in the controlled ODE model. The main result of this work applies this framework to derive compact expressions for the Rademacher complexity of ODE models that map an initial condition to a scalar output at some terminal time. The result leverages the straightforward analysis afforded by single-layer architectures. We conclude with some examples instantiating the bound for some specific systems and discuss potential follow-up work.
    
[^13]: 在逆问题中学习高斯混合物进行稀疏正则化

    Learning a Gaussian Mixture for Sparsity Regularization in Inverse Problems. (arXiv:2401.16612v1 [stat.ML])

    [http://arxiv.org/abs/2401.16612](http://arxiv.org/abs/2401.16612)

    本研究提出了一种基于高斯混合模型的稀疏正则化方法，通过神经网络进行贝叶斯估计，有效地解决了逆问题中的稀疏建模和参数估计问题。

    

    在逆问题中，广泛认为引入稀疏先验对解决方案具有正则化效果。这种方法是基于一个先验假设，即未知量可以在一个有限数量的显著成分的基础上适当表示，而大多数系数接近于零。这种情况在现实世界中经常出现，比如分段平滑信号。在本研究中，我们提出了一种以高斯退化混合物形式表述的概率稀疏先验，能够对于任意基进行稀疏建模。在这个前提下，我们设计了一个可以解释为线性逆问题的贝叶斯估计器的神经网络。此外，我们提出了一种有监督和无监督的训练策略来估计这个网络的参数。为了评估我们方法的有效性，我们进行了与常用的稀疏正则化方法的数值比较。

    In inverse problems, it is widely recognized that the incorporation of a sparsity prior yields a regularization effect on the solution. This approach is grounded on the a priori assumption that the unknown can be appropriately represented in a basis with a limited number of significant components, while most coefficients are close to zero. This occurrence is frequently observed in real-world scenarios, such as with piecewise smooth signals. In this study, we propose a probabilistic sparsity prior formulated as a mixture of degenerate Gaussians, capable of modeling sparsity with respect to a generic basis. Under this premise, we design a neural network that can be interpreted as the Bayes estimator for linear inverse problems. Additionally, we put forth both a supervised and an unsupervised training strategy to estimate the parameters of this network. To evaluate the effectiveness of our approach, we conduct a numerical comparison with commonly employed sparsity-promoting regularization
    
[^14]: PrIsing: 通过Ising模型实现隐私保护的同伴效应估计

    PrIsing: Privacy-Preserving Peer Effect Estimation via Ising Model. (arXiv:2401.16596v1 [stat.ME])

    [http://arxiv.org/abs/2401.16596](http://arxiv.org/abs/2401.16596)

    本文提出了通过Ising模型实现隐私保护的同伴效应估计算法，能够精确估计自然参数并保护个体代理结果的隐私，在合成数据集和现实世界网络上具有良好的性能。

    

    Ising模型最初作为铁磁元素自旋模型而开发，已经被广泛应用于捕捉代理输出之间的依赖性的网络模型。它在医疗保健和社会科学领域的不断应用引发了关于代理响应机密性的隐私担忧。在本文中，我们提出了一种新颖的$(\varepsilon,\delta)$-差分隐私算法，专门设计用于保护个体代理结果的隐私。我们的算法通过目标扰动技术，允许对自然参数使用单一网络进行精确估计。此外，我们为该算法建立了遗憾界限，并在合成数据集和两个现实世界的网络上评估了其性能：一个涉及社交网络中的HIV状况，另一个涉及在线博客的政治倾向。

    The Ising model, originally developed as a spin-glass model for ferromagnetic elements, has gained popularity as a network-based model for capturing dependencies in agents' outputs. Its increasing adoption in healthcare and the social sciences has raised privacy concerns regarding the confidentiality of agents' responses. In this paper, we present a novel $(\varepsilon,\delta)$-differentially private algorithm specifically designed to protect the privacy of individual agents' outcomes. Our algorithm allows for precise estimation of the natural parameter using a single network through an objective perturbation technique. Furthermore, we establish regret bounds for this algorithm and assess its performance on synthetic datasets and two real-world networks: one involving HIV status in a social network and the other concerning the political leaning of online blogs.
    
[^15]: 使用共享神经元的RBF网络估计个体化多治疗反应曲线

    Individualized Multi-Treatment Response Curves Estimation using RBF-net with Shared Neurons. (arXiv:2401.16571v1 [stat.ME])

    [http://arxiv.org/abs/2401.16571](http://arxiv.org/abs/2401.16571)

    我们提出了一种使用共享神经元的RBF网络的非参数化治疗效应估计方法，适用于多治疗设置。该方法能够建模治疗结果的共同性，并在贝叶斯框架下实现估计和推断，通过模拟实验证明了其数值性能，应用于真实临床数据后也得到了有趣的发现。

    

    异质治疗效应估计是精确医学中的一个重要问题。我们的研究兴趣在于基于一些外部协变量，确定不同治疗方式的差异效应。我们提出了一种新颖的非参数化治疗效应估计方法，适用于多治疗设置。我们对响应曲线的非参数建模依赖于带有共享隐藏神经元的径向基函数（RBF）网络。因此，我们的模型有助于建模治疗结果的共同性。我们在贝叶斯框架下开发了估计和推断方案，并通过高效的马尔科夫链蒙特卡罗算法进行实现，适当地处理了分析各个方面的不确定性。通过模拟实验，展示了该方法的数值性能。将我们提出的方法应用于MIMIC数据后，我们得到了关于不同治疗策略对ICU住院时间和12小时SOFA评分的影响的一些有趣发现。

    Heterogeneous treatment effect estimation is an important problem in precision medicine. Specific interests lie in identifying the differential effect of different treatments based on some external covariates. We propose a novel non-parametric treatment effect estimation method in a multi-treatment setting. Our non-parametric modeling of the response curves relies on radial basis function (RBF)-nets with shared hidden neurons. Our model thus facilitates modeling commonality among the treatment outcomes. The estimation and inference schemes are developed under a Bayesian framework and implemented via an efficient Markov chain Monte Carlo algorithm, appropriately accommodating uncertainty in all aspects of the analysis. The numerical performance of the method is demonstrated through simulation experiments. Applying our proposed method to MIMIC data, we obtain several interesting findings related to the impact of different treatment strategies on the length of ICU stay and 12-hour SOFA sc
    
[^16]: 并行仿射变换调整Markov Chain Monte Carlo

    Parallel Affine Transformation Tuning of Markov Chain Monte Carlo. (arXiv:2401.16567v1 [stat.ME])

    [http://arxiv.org/abs/2401.16567](http://arxiv.org/abs/2401.16567)

    本文研究了采用双射仿射变换来改善Markov Chain Monte Carlo采样器性能的方法，并提出了一种灵活并用户友好的自适应学习仿射变换的方案。实验证明，与Gibbsian极坐标切片采样相结合产生的样本具有高质量且计算成本较低。

    

    Markov Chain Monte Carlo采样器的性能强烈依赖于目标分布的性质，如其协方差结构，概率质量的位置和尾部行为。我们探索了使用样本空间的双射仿射变换来改善目标分布的性质，从而提高在变换空间中运行的采样器的性能。特别地，我们提出了一种灵活且用户友好的方案，用于自适应学习采样过程中的仿射变换。此外，我们的方案与Gibbsian极坐标切片采样的组合在几个基于真实数据的场景中显示出以相对较低的计算成本产生高质量样本的能力。

    The performance of Markov chain Monte Carlo samplers strongly depends on the properties of the target distribution such as its covariance structure, the location of its probability mass and its tail behavior. We explore the use of bijective affine transformations of the sample space to improve the properties of the target distribution and thereby the performance of samplers running in the transformed space. In particular, we propose a flexible and user-friendly scheme for adaptively learning the affine transformation during sampling. Moreover, the combination of our scheme with Gibbsian polar slice sampling is shown to produce samples of high quality at comparatively low computational cost in several settings based on real-world data.
    
[^17]: 用不可靠核密度检测现象学分岔

    Topological Detection of Phenomenological Bifurcations with Unreliable Kernel Densities. (arXiv:2401.16563v1 [math.AT])

    [http://arxiv.org/abs/2401.16563](http://arxiv.org/abs/2401.16563)

    本研究提出了一种利用不可靠密度估计检测P型分岔的方法，并比较了几种复制原始持久化图的方法。

    

    现象学（P型）分岔是随机动力系统中的定性变化，其中稳态概率密度函数（PDF）改变了其拓扑结构。目前检测这些分岔的技术需要可靠的核密度估计，而这需要从系统实现集合中计算得到。然而，在一些真实世界的信号中，比如大数据，只有一个系统实现可用，因此无法估计可靠的核密度。本研究提出一种使用不可靠密度估计检测P型分岔的方法。该方法利用了一种称为拓扑数据分析（TDA）的技术从系统的单个实现中创建了一个对象集合，并对结果集进行统计分析。我们比较了复制原始持久化图的几种方法，包括Gibbs点过程建模、成对交互点建模和子采样。我们表明，这些方法在预测方面是有效的。

    Phenomenological (P-type) bifurcations are qualitative changes in stochastic dynamical systems whereby the stationary probability density function (PDF) changes its topology. The current state of the art for detecting these bifurcations requires reliable kernel density estimates computed from an ensemble of system realizations. However, in several real world signals such as Big Data, only a single system realization is available -- making it impossible to estimate a reliable kernel density. This study presents an approach for detecting P-type bifurcations using unreliable density estimates. The approach creates an ensemble of objects from Topological Data Analysis (TDA) called persistence diagrams from the system's sole realization and statistically analyzes the resulting set. We compare several methods for replicating the original persistence diagram including Gibbs point process modelling, Pairwise Interaction Point Modelling, and subsampling. We show that for the purpose of predicti
    
[^18]: 活性学习玻尔兹曼采样器和具有量子力学精度的势能

    Active learning of Boltzmann samplers and potential energies with quantum mechanical accuracy. (arXiv:2401.16487v1 [physics.chem-ph])

    [http://arxiv.org/abs/2401.16487](http://arxiv.org/abs/2401.16487)

    该论文利用增强采样、深度生成模型和主动学习机器学习势能的方法，开发了一个自适应马尔科夫链蒙特卡洛框架，实现了高效的量子精度分子动力学模拟及玻尔兹曼分布采样。

    

    对于物理学、化学和生物学来说，提取分子系统相关自由能极小值之间的一致统计数据至关重要。分子动力学（MD）模拟可以帮助完成这项任务，但对于需要量子精度的系统而言，计算代价很高。为了克服这一挑战，我们开发了一种结合增强采样、深度生成模型和主动学习机器学习势能（MLP）的方法。我们引入了一个自适应马尔科夫链蒙特卡洛框架，使得每个状态可以训练一个正则化流（NF）和一个MLP。我们并行模拟多个马尔科夫链直到收敛，使用高效的能量评估从玻尔兹曼分布中采样。在每次迭代中，我们使用密度泛函理论（DFT）计算NF生成的配置子集的能量，用MLP预测剩余配置的能量，并使用DFT计算得到的能量对MLP进行主动训练。

    Extracting consistent statistics between relevant free-energy minima of a molecular system is essential for physics, chemistry and biology. Molecular dynamics (MD) simulations can aid in this task but are computationally expensive, especially for systems that require quantum accuracy. To overcome this challenge, we develop an approach combining enhanced sampling with deep generative models and active learning of a machine learning potential (MLP). We introduce an adaptive Markov chain Monte Carlo framework that enables the training of one Normalizing Flow (NF) and one MLP per state. We simulate several Markov chains in parallel until they reach convergence, sampling the Boltzmann distribution with an efficient use of energy evaluations. At each iteration, we compute the energy of a subset of the NF-generated configurations using Density Functional Theory (DFT), we predict the remaining configuration's energy with the MLP and actively train the MLP using the DFT-computed energies. Lever
    
[^19]: 在在线广告中通过自监督预训练改进转化率预测

    Improving conversion rate prediction via self-supervised pre-training in online advertising. (arXiv:2401.16432v1 [cs.IR])

    [http://arxiv.org/abs/2401.16432](http://arxiv.org/abs/2401.16432)

    这项研究通过自监督预训练方法，改进了在线广告系统中的转化率预测。由于数据稀疏性的挑战，添加非点击归因的转化会损坏模型的校准，而自监督预训练能够解决这个问题。

    

    预测转化率是在线广告系统中优化投标以满足广告主性能要求的关键任务。尽管深度神经网络的崛起，但这些预测通常由分解机（FM）进行，特别是在推理延迟至关重要的商业环境中。这些模型使用逻辑回归框架训练，利用与任务相关的过去用户活动形成的标记表格数据。许多广告主只关心被点击属性的转化。预测给定点击的转化模型训练的主要挑战来自数据稀疏性 - 点击很少，点击归因的转化更少。然而，在训练集中添加非点击归因的转化来减轻稀疏性会损坏模型的校准。由于校准对实现广告主目标至关重要，这是不可行的。在这项工作中，我们使用了自监督预训练的众所周知的思想来解决这个问题。

    The task of predicting conversion rates (CVR) lies at the heart of online advertising systems aiming to optimize bids to meet advertiser performance requirements. Even with the recent rise of deep neural networks, these predictions are often made by factorization machines (FM), especially in commercial settings where inference latency is key. These models are trained using the logistic regression framework on labeled tabular data formed from past user activity that is relevant to the task at hand.  Many advertisers only care about click-attributed conversions. A major challenge in training models that predict conversions-given-clicks comes from data sparsity - clicks are rare, conversions attributed to clicks are even rarer. However, mitigating sparsity by adding conversions that are not click-attributed to the training set impairs model calibration. Since calibration is critical to achieving advertiser goals, this is infeasible.  In this work we use the well-known idea of self-supervi
    
[^20]: 高维度相关变量的虚警率控制

    High-Dimensional False Discovery Rate Control for Dependent Variables. (arXiv:2401.15796v1 [stat.ME])

    [http://arxiv.org/abs/2401.15796](http://arxiv.org/abs/2401.15796)

    提出了一个新框架，在高维度相关变量情况下实现虚警率控制，通过综合层次图模型在T-Rex框架中利用依赖结构，利用鞅论证明变量惩罚机制确保了FDR的控制。

    

    在大规模、高维度数据中确保可复现的发现结果的算法在许多信号处理应用中至关重要。近年来，出现了多变量虚警率（FDR）控制方法，即使在变量数量超过样本数量的高维情况下，也能提供保证。然而，在存在高度相关变量组的情况下，这些方法往往无法可靠地控制FDR，在基因组学和金融等领域中很常见。为了解决这个关键问题，我们引入了一个考虑一般依赖结构的新框架。我们提出的依赖感知T-Rex选择器将层次图模型整合到T-Rex框架中，以有效利用变量之间的依赖结构。利用鞅论，我们证明了我们的变量惩罚机制确保了FDR的控制。我们进一步通过陈述和证明了一个清晰的FDR控制框架的推广。

    Algorithms that ensure reproducible findings from large-scale, high-dimensional data are pivotal in numerous signal processing applications. In recent years, multivariate false discovery rate (FDR) controlling methods have emerged, providing guarantees even in high-dimensional settings where the number of variables surpasses the number of samples. However, these methods often fail to reliably control the FDR in the presence of highly dependent variable groups, a common characteristic in fields such as genomics and finance. To tackle this critical issue, we introduce a novel framework that accounts for general dependency structures. Our proposed dependency-aware T-Rex selector integrates hierarchical graphical models within the T-Rex framework to effectively harness the dependency structure among variables. Leveraging martingale theory, we prove that our variable penalization mechanism ensures FDR control. We further generalize the FDR-controlling framework by stating and proving a clea
    
[^21]: 贝叶斯非参数方法与数据驱动鲁棒优化的结合

    Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])

    [http://arxiv.org/abs/2401.15771](http://arxiv.org/abs/2401.15771)

    本文提出了一种将贝叶斯非参数方法与最新的决策理论模型相结合的鲁棒优化准则，通过这种方法，可以在线性回归问题中获得有稳定性和优越性能的结果。

    

    训练机器学习和统计模型通常涉及优化数据驱动的风险准则。风险通常是根据经验数据分布计算的，但由于分布不确定性，这可能导致性能不稳定和不好的样本外表现。在分布鲁棒优化的精神下，我们提出了一个新颖的鲁棒准则，将贝叶斯非参数（即狄利克雷过程）理论和最近的平滑模糊规避偏好的决策理论模型的见解相结合。首先，我们强调了与标准正则化经验风险最小化技术的新连接，其中包括岭回归和套索回归。然后，我们从理论上证明了鲁棒优化过程在有限样本和渐近统计保证方面的有利性存在。对于实际实施，我们提出并研究了基于众所周知的狄利克雷过程表示的可行近似准则。

    Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
    
[^22]: FDR控制的稀疏金融指数跟踪投资组合优化

    FDR-Controlled Portfolio Optimization for Sparse Financial Index Tracking. (arXiv:2401.15139v1 [q-fin.PM])

    [http://arxiv.org/abs/2401.15139](http://arxiv.org/abs/2401.15139)

    本论文提出了一种扩展的T-Rex框架，用于在稀疏金融指数跟踪中选择少数相关变量，并通过集成最近邻惩罚机制，可靠控制误发现率（FDR）。实验证明了该方法在过去20年内基于少量股票准确跟踪标准普尔500指数的能力。

    

    在高维数据分析中，如金融指数跟踪或生物医学应用中，关键是在保持对误发现率（FDR）的控制的同时选择少数相关变量。在这些应用中，变量之间经常存在强依赖关系（例如股票收益），这可能会削弱现有方法（如模型X knockoff方法或T-Rex选择器）的FDR控制特性。为了解决这个问题，我们扩展了T-Rex框架，以适应高度相关变量的重叠组。这是通过将最近邻惩罚机制集成到框架中实现的，该机制能够在用户定义的目标水平上可靠控制FDR。稀疏指数跟踪的实例展示了该方法在过去20年内基于少量股票准确跟踪标准普尔500指数的能力。在CRAN上提供了R包TRexSelector的开源实现。

    In high-dimensional data analysis, such as financial index tracking or biomedical applications, it is crucial to select the few relevant variables while maintaining control over the false discovery rate (FDR). In these applications, strong dependencies often exist among the variables (e.g., stock returns), which can undermine the FDR control property of existing methods like the model-X knockoff method or the T-Rex selector. To address this issue, we have expanded the T-Rex framework to accommodate overlapping groups of highly correlated variables. This is achieved by integrating a nearest neighbors penalization mechanism into the framework, which provably controls the FDR at the user-defined target level. A real-world example of sparse index tracking demonstrates the proposed method's ability to accurately track the S&P 500 index over the past 20 years based on a small number of stocks. An open-source implementation is provided within the R package TRexSelector on CRAN.
    
[^23]: 定价的因果预测方法

    Causal Forecasting for Pricing. (arXiv:2312.15282v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2312.15282](http://arxiv.org/abs/2312.15282)

    本文提出了一种在定价环境下进行需求预测的新方法，通过将因果推断的双重机器学习方法和最先进的基于变压器的预测模型结合在一起，我们的方法在完全控制的情况下更好地估计因果效应，并在离线政策设置中优于其他预测方法。

    

    本文提出了一种在定价环境下进行需求预测的新方法。在这种情况下，建模价格作为需求的输入变量之间的因果关系至关重要，因为零售商的目标是以（利润）最佳方式设定价格，以解决下游决策问题。我们的方法将因果推断的双重机器学习方法和最先进的基于变压器的预测模型结合在一起。通过大量的实证实验，我们一方面展示了我们的方法在完全控制的情况下对合成的、但现实的数据更好地估计因果效应。另一方面，我们还展示了在实际数据中，我们的方法在离线政策设置（即定价政策发生变化时）中优于其他预测方法，而在在线政策设置中略有落后。

    This paper proposes a novel method for demand forecasting in a pricing context. Here, modeling the causal relationship between price as an input variable to demand is crucial because retailers aim to set prices in a (profit) optimal manner in a downstream decision making problem. Our methods bring together the Double Machine Learning methodology for causal inference and state-of-the-art transformer-based forecasting models. In extensive empirical experiments, we show on the one hand that our method estimates the causal effect better in a fully controlled setting via synthetic, yet realistic data. On the other hand, we demonstrate on real-world data that our method outperforms forecasting methods in off-policy settings (i.e., when there's a change in the pricing policy) while only slightly trailing in the on-policy setting.
    
[^24]: 分配福利的政策学习

    Policy Learning with Distributional Welfare. (arXiv:2311.15878v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2311.15878](http://arxiv.org/abs/2311.15878)

    本文提出了一种针对分配福利的最优治疗分配策略，该策略根据个体治疗效应的条件分位数来决定治疗分配，并引入了鲁棒的最小最大化策略来解决对反事实结果联合分布的恢复问题。

    

    本文探讨了针对分配福利的最优治疗分配策略。大部分关于治疗选择的文献都考虑了基于条件平均治疗效应（ATE）的功利福利。虽然平均福利是直观的，但在个体异质化（例如，存在离群值）情况下可能会产生不理想的分配 - 这正是个性化治疗引入的原因之一。这个观察让我们提出了一种根据个体治疗效应的条件分位数（QoTE）来分配治疗的最优策略。根据分位数概率的选择，这个准则可以适应谨慎或粗心的决策者。确定QoTE的挑战在于其需要对反事实结果的联合分布有所了解，但即使使用实验数据，通常也很难恢复出来。因此，我们介绍了鲁棒的最小最大化策略

    In this paper, we explore optimal treatment allocation policies that target distributional welfare. Most literature on treatment choice has considered utilitarian welfare based on the conditional average treatment effect (ATE). While average welfare is intuitive, it may yield undesirable allocations especially when individuals are heterogeneous (e.g., with outliers) - the very reason individualized treatments were introduced in the first place. This observation motivates us to propose an optimal policy that allocates the treatment based on the conditional quantile of individual treatment effects (QoTE). Depending on the choice of the quantile probability, this criterion can accommodate a policymaker who is either prudent or negligent. The challenge of identifying the QoTE lies in its requirement for knowledge of the joint distribution of the counterfactual outcomes, which is generally hard to recover even with experimental data. Therefore, we introduce minimax policies that are robust 
    
[^25]: 等变矩阵函数神经网络

    Equivariant Matrix Function Neural Networks. (arXiv:2310.10434v1 [stat.ML])

    [http://arxiv.org/abs/2310.10434](http://arxiv.org/abs/2310.10434)

    矩阵函数神经网络（MFNs）是一种通过解析矩阵等变函数来参数化非局部相互作用的新型架构，能够在各种应用中实现最先进的性能。

    

    图神经网络（GNNs），尤其是消息传递神经网络（MPNNs），已经成为在各种应用中学习图形的强大架构。然而，当建模非局部相互作用时，MPNNs在大共轭分子，金属或非晶态材料等系统中面临挑战。尽管谱GNN和传统的神经网络（例如循环神经网络和Transformer）可以缓解这些挑战，但它们常常缺乏扩展性，适应性，泛化能力，计算效率，或者不能捕捉数据中的详细结构关系或对称性。为了解决这些问题，我们引入了矩阵函数神经网络（MFNs），一种通过解析矩阵等变函数来参数化非局部相互作用的新型架构。采用解析矩阵展开提供了一种直接的实现方法，并具有随系统大小线性扩展的潜力。该MFN架构在标准任务中实现了最先进的性能。

    Graph Neural Networks (GNNs), especially message-passing neural networks (MPNNs), have emerged as powerful architectures for learning on graphs in diverse applications. However, MPNNs face challenges when modeling non-local interactions in systems such as large conjugated molecules, metals, or amorphous materials. Although Spectral GNNs and traditional neural networks such as recurrent neural networks and transformers mitigate these challenges, they often lack extensivity, adaptability, generalizability, computational efficiency, or fail to capture detailed structural relationships or symmetries in the data. To address these concerns, we introduce Matrix Function Neural Networks (MFNs), a novel architecture that parameterizes non-local interactions through analytic matrix equivariant functions. Employing resolvent expansions offers a straightforward implementation and the potential for linear scaling with system size. The MFN architecture achieves state-of-the-art performance in standa
    
[^26]: 连续时间高斯过程动力学的精确推断

    Exact Inference for Continuous-Time Gaussian Process Dynamics. (arXiv:2309.02351v1 [cs.LG])

    [http://arxiv.org/abs/2309.02351](http://arxiv.org/abs/2309.02351)

    本论文提出了一种对连续时间高斯过程动力学进行精确推断的方法，解决了在离散时间下进行预测可能带来的问题，并利用高阶数值积分器进行动力学函数的离散化，避免了传统方法中的近似推断的限制。

    

    实际物理系统通常可以通过连续时间动力系统来描述。在实际应用中，真实系统通常是未知的，需要从测量数据中学习。由于数据通常以离散时间收集，例如通过传感器，高斯过程（GP）动力模型学习中的大多数方法都是针对一步预测进行训练的。在一些场景中，这可能会导致问题，例如如果测量结果以不规则的时间步长提供，或者物理系统属性需要保持不变。因此，我们的目标是建立对真实连续时间动力学的GP模型。高阶数值积分器提供了通过任意精度离散化动力学函数来解决这个问题的工具。许多高阶积分器需要在中间时间步骤进行动力学评估，这使得精确的GP推断变得难以处理。在先前的工作中，通常通过使用变分推断来近似GP后验来解决这个问题。然而，精确的GP推断是很困难的。

    Physical systems can often be described via a continuous-time dynamical system. In practice, the true system is often unknown and has to be learned from measurement data. Since data is typically collected in discrete time, e.g. by sensors, most methods in Gaussian process (GP) dynamics model learning are trained on one-step ahead predictions. This can become problematic in several scenarios, e.g. if measurements are provided at irregularly-sampled time steps or physical system properties have to be conserved. Thus, we aim for a GP model of the true continuous-time dynamics. Higher-order numerical integrators provide the necessary tools to address this problem by discretizing the dynamics function with arbitrary accuracy. Many higher-order integrators require dynamics evaluations at intermediate time steps making exact GP inference intractable. In previous work, this problem is often tackled by approximating the GP posterior with variational inference. However, exact GP inference is pre
    
[^27]: 高维线性回归的统一转移学习模型

    Unified Transfer Learning Models for High-Dimensional Linear Regression. (arXiv:2307.00238v1 [stat.ML])

    [http://arxiv.org/abs/2307.00238](http://arxiv.org/abs/2307.00238)

    UTrans是一种统一转移学习模型，它能检测可转移变量和源数据，并具有较低的估计和预测误差，同时保持可解释性。

    

    在现代数据分析中，当目标数据稀缺而源数据充足，或者源数据和目标数据的分布不同的情况下，转移学习在发挥重要作用。本文提出了一种可解释的统一转移学习模型，称为UTrans，该模型能够检测可转移变量和源数据。具体来说，我们建立了估计误差界限，并证明我们的界限低于仅有目标数据的界限。此外，我们基于假设检验提出了一种源数据检测算法，用于排除不可转移的数据。我们在多个实验中评估和比较了UTrans与现有算法。结果显示，UTrans在保持可解释性的同时，比现有方法具有更低的估计和预测误差。最后，我们将其应用于美国代际流动数据，并将我们提出的算法与经典的机器学习算法进行比较。

    Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.
    
[^28]: 基于“平均”的异质性时间序列预测方法的改进，以食品需求预测为例

    Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast. (arXiv:2306.07119v1 [stat.ME])

    [http://arxiv.org/abs/2306.07119](http://arxiv.org/abs/2306.07119)

    本文提出了一种基于相似度度量的通用框架，利用k最近邻的方式构建邻域，并通过平均来改进可能简单模型的预测，提高异质性时间序列的预测准确性。

    

    实际应用中的常见预测场景是考虑一组可能异质性的相同领域时间序列。由于每个时间序列的不同特性，如长度等，直接对每个时间序列进行预测是具有挑战性的。本文提出了一种通用框架，利用动态时间规整中的相似度度量找到相似的时间序列，以k最近邻的方式构建邻域，并通过平均来改进可能简单模型的预测。提出了几种执行平均的方法，并理论证明了平均对于预测的有效性。此外，本文还提出了诊断工具，允许深入理解该过程。

    A common forecasting setting in real world applications considers a set of possibly heterogeneous time series of the same domain. Due to different properties of each time series such as length, obtaining forecasts for each individual time series in a straight-forward way is challenging. This paper proposes a general framework utilizing a similarity measure in Dynamic Time Warping to find similar time series to build neighborhoods in a k-Nearest Neighbor fashion, and improve forecasts of possibly simple models by averaging. Several ways of performing the averaging are suggested, and theoretical arguments underline the usefulness of averaging for forecasting. Additionally, diagnostics tools are proposed allowing a deep understanding of the procedure.
    
[^29]: DoWG展示：一种高效的通用无参数梯度下降方法

    DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method. (arXiv:2305.16284v1 [cs.LG])

    [http://arxiv.org/abs/2305.16284](http://arxiv.org/abs/2305.16284)

    本文提出了一种名为DoWG的无参数梯度下降方法，它是第一个既高效又通用的算法，能够自适应于平稳和非平稳问题，并且无需回溯搜索过程。

    

    本文提出了一种新的易于实现的无参数梯度优化器：DoWG（Weighted Gradients的距离）。我们证明了该方法是高效的——在不调整任何参数的情况下，匹配优化凸优化中最优调的梯度下降的收敛速度，直到对数因子，并且是通用的——自动适应平滑和非平滑问题。与AdaGrad，Adam或DoG等流行算法计算平方梯度的运行平均值不同，DoWG保持运行平均值的一种新的基于距离的加权版本，这对于实现所需的性质至关重要。据我们所知，DoWG是第一个不需要回溯搜索过程的无参数，高效和通用算法。它还是第一个适应于平稳优化的无参数AdaGrad样式算法。为了补充我们的理论，我们还通过实验证明DoWG在稳定的边缘训练，并证明其在实践中的有效性。

    This paper proposes a new easy-to-implement parameter-free gradient-based optimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG is efficient -- matching the convergence rate of optimally tuned gradient descent in convex optimization up to a logarithmic factor without tuning any parameters, and universal -- automatically adapting to both smooth and nonsmooth problems. While popular algorithms such as AdaGrad, Adam, or DoG compute a running average of the squared gradients, DoWG maintains a new distance-based weighted version of the running average, which is crucial to achieve the desired properties. To our best knowledge, DoWG is the first parameter-free, efficient, and universal algorithm that does not require backtracking search procedures. It is also the first parameter-free AdaGrad style algorithm that adapts to smooth optimization. To complement our theory, we also show empirically that DoWG trains at the edge of stability, and validate its effectiveness on practic
    
[^30]: 无观测上下文的联邦随机赌博学习

    Federated Stochastic Bandit Learning with Unobserved Context. (arXiv:2303.17043v1 [cs.LG])

    [http://arxiv.org/abs/2303.17043](http://arxiv.org/abs/2303.17043)

    本文提出了一种联邦随机多臂上下文赌博算法以最大化累积奖励，针对未知上下文的情况通过执行特征向量转换解决问题。

    

    本文研究了具有未知上下文的联邦随机多臂上下文赌博问题，其中M个代理面临不同的赌博机并协作学习。通信模型由中央服务器组成，并且代理会定期与中央服务器共享其估计结果，以便选择最优动作以最小化总后悔。我们假设精确的上下文不可观察，代理仅观测上下文的分布。例如，当上下文本身是噪声测量或基于预测机制时，就会出现这种情况。我们的目标是开发一种分布式联邦算法，促进代理之间的协作学习，选择一系列最优动作以最大化累积奖励。通过执行特征向量转换，我们提出了一种基于消除的算法，并证明了线性参数化奖励函数的后悔界。最后，我们验证了算法的性能。

    We study the problem of federated stochastic multi-arm contextual bandits with unknown contexts, in which M agents are faced with different bandits and collaborate to learn. The communication model consists of a central server and the agents share their estimates with the central server periodically to learn to choose optimal actions in order to minimize the total regret. We assume that the exact contexts are not observable and the agents observe only a distribution of the contexts. Such a situation arises, for instance, when the context itself is a noisy measurement or based on a prediction mechanism. Our goal is to develop a distributed and federated algorithm that facilitates collaborative learning among the agents to select a sequence of optimal actions so as to maximize the cumulative reward. By performing a feature vector transformation, we propose an elimination-based algorithm and prove the regret bound for linearly parametrized reward functions. Finally, we validated the perfo
    
[^31]: 通过可变大小的压缩性建立数据相关的泛化界限

    Data-dependent Generalization Bounds via Variable-Size Compressibility. (arXiv:2303.05369v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.05369](http://arxiv.org/abs/2303.05369)

    本文通过引入可变大小压缩性框架，建立了一种新的数据相关的泛化误差上界。该方法将算法的泛化误差与其输入数据的可变大小压缩率相关联，并提供了依赖于经验分布而非未知分布的界限。此外，该方法还可以推导出输入数据和输出假设随机变量的任何函数的泛化界限，并包含并可能优于现有的基于PAC-Bayes和数据相关内在维度的界限。

    

    本文通过引入“可变大小压缩性”框架，建立了一种新的数据相关泛化误差的上界。在这个框架中，算法的泛化误差与其输入数据的可变大小“压缩率”相关联。通过这种方式，我们得到的界限依赖于手头给定输入数据的经验分布，而不是其未知分布。我们建立的新的泛化界限包括尾部界限、期望值的尾部界限和期望界限。此外，我们的框架还可以推导出对输入数据和输出假设随机变量的任何函数的泛化界限。特别是，这些泛化界限包含并可能优于几种现有的基于PAC-Bayes和数据相关内在维度的界限，这些界限作为特殊情况得到复原，从而揭示出我们方法的统一特性。

    In this paper, we establish novel data-dependent upper bounds on the generalization error through the lens of a "variable-size compressibility" framework that we introduce newly here. In this framework, the generalization error of an algorithm is linked to a variable-size 'compression rate' of its input data. This is shown to yield bounds that depend on the empirical measure of the given input data at hand, rather than its unknown distribution. Our new generalization bounds that we establish are tail bounds, tail bounds on the expectation, and in-expectations bounds. Moreover, it is shown that our framework also allows to derive general bounds on any function of the input data and output hypothesis random variables. In particular, these general bounds are shown to subsume and possibly improve over several existing PAC-Bayes and data-dependent intrinsic dimension-based bounds that are recovered as special cases, thus unveiling a unifying character of our approach. For instance, a new da
    
[^32]: 多模态分子结构-文本模型用于基于文本的检索和编辑

    Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing. (arXiv:2212.10789v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10789](http://arxiv.org/abs/2212.10789)

    本论文介绍了一种名为MoleculeSTM的多模态分子结构-文本模型，通过联合学习化学结构和文本描述，可以实现基于文本的检索和编辑。通过构建大型的多模态数据集，并设计挑战性的零样本任务进行验证，该模型展示了开放词汇和组合性的特性。

    

    药物发现中正在越来越广泛地采用人工智能，然而，现有研究主要利用分子的化学结构，忽视了化学领域中可用的丰富文本知识。将文本知识纳入考虑可以实现新的药物设计目标，适应基于文本的指导和预测复杂的生物活性。在这里，我们提出了一种多模态的分子结构-文本模型MoleculeSTM，通过联合学习分子的化学结构和文本描述来实现，采用对比学习策略。为了训练MoleculeSTM，我们构建了一个大型的多模态数据集，名为PubChemSTM，包含超过28万个化学结构-文本对。为了展示MoleculeSTM的有效性和实用性，我们设计了两个基于文本指令的挑战性零样本任务，包括结构-文本检索和分子编辑。MoleculeSTM具有两个主要特性：开放词汇和通过自然语言实现组合性。

    There is increasing adoption of artificial intelligence in drug discovery. However, existing studies use machine learning to mainly utilize the chemical structures of molecules but ignore the vast textual knowledge available in chemistry. Incorporating textual knowledge enables us to realize new drug design objectives, adapt to text-based instructions and predict complex biological activities. Here we present a multi-modal molecule structure-text model, MoleculeSTM, by jointly learning molecules' chemical structures and textual descriptions via a contrastive learning strategy. To train MoleculeSTM, we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000 chemical structure-text pairs. To demonstrate the effectiveness and utility of MoleculeSTM, we design two challenging zero-shot tasks based on text instructions, including structure-text retrieval and molecule editing. MoleculeSTM has two main properties: open vocabulary and compositionality via natural language.
    
[^33]: 因子模型中的双重稳健最近邻方法

    Doubly robust nearest neighbors in factor models. (arXiv:2211.14297v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.14297](http://arxiv.org/abs/2211.14297)

    该论文介绍了一种在潜在因子模型中处理缺失数据的双重稳健最近邻方法，可以提供一致的估计，并在存在良好的行和列邻居时提供（近似）二次改进非渐近性能。

    

    我们介绍并分析了在潜在因子模型中处理缺失数据的改进最近邻（NN）方法。我们考虑一个带有缺失数据的矩阵补全问题，其中当被观察到时，第$(i, t)$个条目由其均值$f(u_i, v_t)$加上均值为零的噪声给出，其中$f$为未知函数，$u_i$和$v_t$为潜在因子。之前的NN策略，如单元-单元NN，用于估计均值$f(u_i, v_t)$，依赖于存在其他行$j$使得$u_j \approx u_i$。类似地，时间-时间NN策略依赖于存在列$t'$使得$v_{t'} \approx v_t$。当相似行或相似列不可用时，这些策略的性能较差。我们的估计在两个方面对这种不足是双重稳健的：(1) 只要存在良好的行或列邻居，我们的估计提供一致的估计。 (2) 此外，如果存在良好的行和列邻居，它提供了（近似）二次改进非渐近性能。

    We introduce and analyze an improved variant of nearest neighbors (NN) for estimation with missing data in latent factor models. We consider a matrix completion problem with missing data, where the $(i, t)$-th entry, when observed, is given by its mean $f(u_i, v_t)$ plus mean-zero noise for an unknown function $f$ and latent factors $u_i$ and $v_t$. Prior NN strategies, like unit-unit NN, for estimating the mean $f(u_i, v_t)$ relies on existence of other rows $j$ with $u_j \approx u_i$. Similarly, time-time NN strategy relies on existence of columns $t'$ with $v_{t'} \approx v_t$. These strategies provide poor performance respectively when similar rows or similar columns are not available. Our estimate is doubly robust to this deficit in two ways: (1) As long as there exist either good row or good column neighbors, our estimate provides a consistent estimate. (2) Furthermore, if both good row and good column neighbors exist, it provides a (near-)quadratic improvement in the non-asympto
    
[^34]: 关于使用熵正则化平滑Wasserstein估计器的潜在益处

    On the potential benefits of entropic regularization for smoothing Wasserstein estimators. (arXiv:2210.06934v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.06934](http://arxiv.org/abs/2210.06934)

    本文研究了熵正则化作为一种平滑方法在Wasserstein估计器中的潜在益处，通过替换最优输运成本的正则化版本来实现。主要发现是熵正则化可以以较低的计算成本达到与未正则化的Wasserstein估计器相当的统计性能。

    

    本文专注于研究熵正则化在最优输运中作为Wasserstein估计器的平滑方法，通过统计学中逼近误差和估计误差的经典权衡。Wasserstein估计器被定义为解决变分问题的解，其目标函数涉及概率测度之间的最优输运成本的使用。这样的估计器可以通过用熵惩罚替换最优输运成本的正则化版本来进行正则化，从而对结果估计器产生潜在的平滑效果。在这项工作中，我们探讨了熵正则化对正则化Wasserstein估计器的逼近和估计性质可能带来的益处。我们的主要贡献是讨论熵正则化如何以更低的计算成本达到与未正则化的Wasserstein估计器相当的统计性能。

    This paper is focused on the study of entropic regularization in optimal transport as a smoothing method for Wasserstein estimators, through the prism of the classical tradeoff between approximation and estimation errors in statistics. Wasserstein estimators are defined as solutions of variational problems whose objective function involves the use of an optimal transport cost between probability measures. Such estimators can be regularized by replacing the optimal transport cost by its regularized version using an entropy penalty on the transport plan. The use of such a regularization has a potentially significant smoothing effect on the resulting estimators. In this work, we investigate its potential benefits on the approximation and estimation properties of regularized Wasserstein estimators. Our main contribution is to discuss how entropic regularization may reach, at a lower computational cost, statistical performances that are comparable to those of un-regularized Wasserstein esti
    
[^35]: 在复杂的多智能体场景中估计反事实治疗结果的时间变化

    Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios. (arXiv:2206.01900v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2206.01900](http://arxiv.org/abs/2206.01900)

    本论文提出了一个可解释的反事实循环网络，用于在复杂的多智能体场景中估计干预效果。该模型考虑了时间变化的多智能体关系和协变量反事实预测的复杂结构，能够准确评估个体治疗效果，并提供解释性。

    

    在各种工程和科学领域中，评估多智能体系统中的干预行为（例如，人类何时应该干预自动驾驶系统，何时球员应该传给队友进行好射门）是一项具有挑战性的任务。使用反事实的长期预测来估计个体治疗效果（ITE）是评估此类干预措施的实用方法。然而，大多数传统框架没有考虑到多智能体关系的时间变化和协变量反事实预测的复杂结构，这可能导致ITE的错误评估和解释困难。在这里，我们提出了一个可解释的反事实循环网络，用于估计干预的效果。我们的模型利用图形变分循环神经网络和基于领域知识的计算来进行基于多智能体协变量和结果的长期预测的ITE估计框架，能够确认循环结构。

    Evaluation of intervention in a multi-agent system, e.g., when humans should intervene in autonomous driving systems and when a player should pass to teammates for a good shot, is challenging in various engineering and scientific fields. Estimating the individual treatment effect (ITE) using counterfactual long-term prediction is practical to evaluate such interventions. However, most of the conventional frameworks did not consider the time-varying complex structure of multi-agent relationships and covariate counterfactual prediction. This may lead to erroneous assessments of ITE and difficulty in interpretation. Here we propose an interpretable, counterfactual recurrent network in multi-agent systems to estimate the effect of the intervention. Our model leverages graph variational recurrent neural networks and theory-based computation with domain knowledge for the ITE estimation framework based on long-term prediction of multi-agent covariates and outcomes, which can confirm the circu
    
[^36]: 最近邻过程：弱收敛和非渐近界限

    Nearest neighbor process: weak convergence and non-asymptotic bound. (arXiv:2110.15083v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2110.15083](http://arxiv.org/abs/2110.15083)

    本文介绍了一种中心统计量——最近邻测度，并通过均匀中心极限定理和一种均匀的非渐近界限研究了它。该测度可能为推断提供了一种替代方法。

    

    介绍并研究了由给定点的最近邻所得到的经验测度——最近邻测度作为一种中心统计量。首先，在底层函数类上满足（反映最近邻算法的本地化特性的）（本地）支撑熵条件下，将相关经验过程证明为满足均匀中心极限定理。其次，在统一熵数的著名条件（通常称为Vapnik-Chervonenkis）下建立了一种均匀的非渐近界限。在均匀中心极限定理中所获得的高斯极限的协方差等于条件协方差算子（给出兴趣点）。这提示了一种可能性，即在使用相同的推理方式但仅使用最近邻而不是全部替换标准经验测度的标准方法的情况下，扩展标准方法 - 非局部。

    The empirical measure resulting from the nearest neighbors to a given point \textit{the nearest neighbor measure} - is introduced and studied as a central statistical quantity. First, the associated empirical process is shown to satisfy a uniform central limit theorem under a (local) bracketing entropy condition on the underlying class of functions (reflecting the localizing nature of the nearest neighbor algorithm). Second a uniform non-asymptotic bound is established under a well-known condition, often referred to as Vapnik-Chervonenkis, on the uniform entropy numbers. The covariance of the Gaussian limit obtained in the uniform central limit theorem is equal to the conditional covariance operator (given the point of interest). This suggests the possibility of extending standard approaches - non local - replacing simply the standard empirical measure by the nearest neighbor measure while using the same way of making inference but with the nearest neighbors only instead of the full 
    

