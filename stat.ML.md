# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning.](http://arxiv.org/abs/2305.20043) | 本文提出了一种新的攻击方法，其中对手欺骗性地遗漏了部分真实的训练数据，以偏向所需的方式来影响学习到的因果结构。 |
| [^2] | [A Study of Bayesian Neural Network Surrogates for Bayesian Optimization.](http://arxiv.org/abs/2305.20028) | 本文研究贝叶斯神经网络替代高斯过程模型作为贝叶斯优化中的代理模型，并在多个基准问题上证明了其优于标准GP代理的能力。 |
| [^3] | [Constrained Causal Bayesian Optimization.](http://arxiv.org/abs/2305.20011) | 本论文提出了一种名为限制因果贝叶斯优化的方法，用于在已知因果图中寻找优化目标变量的干预方式并满足约束条件，成功地平衡了快速收敛和可行干预百分比之间的权衡。 |
| [^4] | [Knowledge Graph Embedding with Electronic Health Records Data via Latent Graphical Block Model.](http://arxiv.org/abs/2305.19997) | 本文提出了一种利用潜在图解构模型嵌入电子病历数据的知识图谱技术，以解决从EHR数据中获取可推广的知识的挑战。 |
| [^5] | [A Nested Matrix-Tensor Model for Noisy Multi-view Clustering.](http://arxiv.org/abs/2305.19992) | 本文提出了一种嵌套矩阵-张量模型，用于解决多视角聚类问题，通过执行最佳秩一张量逼近来估计隐藏的聚类，理论结果可以预期精确准确度。 |
| [^6] | [Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts.](http://arxiv.org/abs/2305.19951) | 本研究通过将NeSy模型中出现的推理快捷方式定义为学习目标的意外最优解，并确定其发生的四个关键条件，提出了几种可行的缓解策略并对其进行了分析，显示推理快捷方式难以处理。 |
| [^7] | [A Geometric Perspective on Diffusion Models.](http://arxiv.org/abs/2305.19947) | 本文研究了扩散模型的几何结构，发现通过一个明确的准线性采样轨迹和另一个隐式的去噪轨迹平滑连接了数据分布和噪声分布，建立了基于ODE的最优采样和经典的均值漂移算法之间的理论关系。 |
| [^8] | [Fully Dynamic Submodular Maximization over Matroids.](http://arxiv.org/abs/2305.19918) | 本论文研究了在元素可以实时地被插入和删除的情况下，最大化拟阵限制下的单调子模函数问题，提出了一种随机算法，时间复杂度为$\tilde{O}(k^2)$，可以产生一个$4$近似解。 |
| [^9] | [Adaptive Conformal Regression with Jackknife+ Rescaled Scores.](http://arxiv.org/abs/2305.19901) | 提出一种新的自适应方法，它基于用局部分数分布的估计来重新缩放符合分数。该方法不会牺牲校准集大小，实现了局部覆盖并提高了符合预测间隔的适用性，特别适用于低数据范围内的应用。 |
| [^10] | [EAMDrift: An interpretable self retrain model for time series.](http://arxiv.org/abs/2305.19837) | EAMDrift是一种可解释的时间序列预测模型，通过对多个预测器的预测进行加权，自动适应分布外模式，并在每个时刻选择最合适的模型。其设计包括自动重训练机制和基于概念编码的观察者模型。 |
| [^11] | [Direct Diffusion Bridge using Data Consistency for Inverse Problems.](http://arxiv.org/abs/2305.19809) | 本文提出了一种用于逆问题的直接扩散链桥算法，提高了逆问题求解器的性能，并通过使用数据一致性解决了当前DDB框架存在的关键限制。 |
| [^12] | [Distance Rank Score: Unsupervised filter method for feature selection on imbalanced dataset.](http://arxiv.org/abs/2305.19804) | 本文提出了一种新的滤波器方法，能有效处理不平衡多类数据集上的特征选择问题，它基于Spearman排名相关性而不是特征方差。 |
| [^13] | [Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya.](http://arxiv.org/abs/2305.19779) | 本研究提出了一种利用aggVAE进行深度学习和MCMC处理行政边界变化的解决方案，可以更准确地映射以县为层级的聚合级别数据，并处理行政边界的变化，相比最先进的模型表现更好。 |
| [^14] | [Neural Markov Jump Processes.](http://arxiv.org/abs/2305.19744) | 介绍了一种基于神经常微分方程的马尔可夫跳跃过程的变分推断算法，可通过反向传播进行训练，用于近似后验马尔可夫跳跃过程的初始分布和时间相关的转移概率率，同时在先验过程的时间无关率上也有很好的表现。 |
| [^15] | [Bures-Wasserstein Means of Graphs.](http://arxiv.org/abs/2305.19738) | 该论文提出了一个新颖的框架，通过在平滑图信号分布空间中嵌入图来定义图的平均值，其中可以使用Wasserstein度量衡量图相似性。实验结果表明，在各种任务中都有很好的表现。 |
| [^16] | [Hypothesis Transfer Learning with Surrogate Classification Losses.](http://arxiv.org/abs/2305.19694) | 本文研究了使用代理分类损失的假设迁移学习的学习理论，通过算法稳定性提供了在温和假设下的学习保证，适用于机器学习算法。 |
| [^17] | [Constant or logarithmic regret in asynchronous multiplayer bandits.](http://arxiv.org/abs/2305.19691) | 本文解决了异步多人赌博问题的集中式情况，推出了Cautious Greedy算法，可以保证常数遗憾，同时UCB算法的自然扩展展现出了 $\mathcal{O}(\sqrt{T\log(T)})$ 极小化遗憾。 |
| [^18] | [Deep Stochastic Mechanics.](http://arxiv.org/abs/2305.19685) | 本文提出了一种基于深度学习的方法，用于数值模拟时间演化薛定谔方程，利用马尔可夫扩散采样来适应波函数的潜在低维结构，并提出了新的随机量子力学方程，具有线性的计算复杂度。数值模拟显示出显着的优势。 |
| [^19] | [End-to-end Training of Deep Boltzmann Machines by Unbiased Contrastive Divergence with Local Mode Initialization.](http://arxiv.org/abs/2305.19684) | 本研究提出一种基于Metropolis-Hastings耦合和局部模态初始化的方法，解决了深度玻尔兹曼机中的偏差梯度估计问题，使得DBMs可以端到端地训练，实验结果表明与其他深度生成模型相当的生成性能。 |
| [^20] | [Online-to-PAC Conversions: Generalization Bounds via Regret Analysis.](http://arxiv.org/abs/2305.19674) | 本文提出了在线学习游戏“泛化游戏”的框架，将在线学习算法的表现和统计学习算法的泛化界限联系了起来，并得出了一些标准的泛化限制。 |
| [^21] | [Optimal Estimates for Pairwise Learning with Deep ReLU Networks.](http://arxiv.org/abs/2305.19640) | 本文研究了深度ReLU网络中的成对学习，提出了一个针对一般损失函数的误差估计的尖锐界限，并基于成对最小二乘损失得出几乎最优的过度泛化误差界限。 |
| [^22] | [Parameter-free projected gradient descent.](http://arxiv.org/abs/2305.19605) | 本文提出了一种无参数的投影梯度下降算法，能够自适应地处理初始点与最优解之间的距离以及子梯度的平方和，适用于在闭合凸集上最小化凸函数的问题，并且能够在满足对数因子下的累积遗憾的最优收敛速率。 |
| [^23] | [Active causal structure learning with advice.](http://arxiv.org/abs/2305.19588) | 本研究提出了带建议的主动因果结构学习问题，并设计了一个自适应搜索算法，可以从建议中受益，即使建议是任意糟糕的情况下，仍然具有最坏情况下的保证。 |
| [^24] | [On the Linear Convergence of Policy Gradient under Hadamard Parameterization.](http://arxiv.org/abs/2305.19575) | 本文研究了Hadamard参数化下策略梯度的收敛性，证明了算法具有全局线性收敛性和局部线性收敛速度更快的性质。 |
| [^25] | [Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms.](http://arxiv.org/abs/2305.19570) | 本文提出了新算法来解决在线标签移位问题，在无需先验知识的情况下通过在线回归保证了最优动态遗憾，并在模拟和真实场景中表现出卓越的性能。 |
| [^26] | [Replicability in Reinforcement Learning.](http://arxiv.org/abs/2305.19562) | 这篇论文研究了在强化学习中的可复制性，提出了可复制算法和松弛可复制算法，并给出了相应的时间和样本复杂度，这对于RL算法设计以及未来的可复制性研究具有影响。 |
| [^27] | [Dictionary Learning under Symmetries via Group Representations.](http://arxiv.org/abs/2305.19557) | 本文研究在预定变换群下学习不变的字典问题。利用非阿贝尔傅里叶分析，提供了算法，建立了字典学习问题可以被有效地理解为某些矩阵优化问题的理论基础。 |
| [^28] | [Low-rank extended Kalman filtering for online learning of neural networks from streaming data.](http://arxiv.org/abs/2305.19535) | 本文提出一种基于低秩扩展卡尔曼滤波的高效在线学习算法，其能够估计非线性函数的参数，具有更快的适应性和更快的奖励积累。 |
| [^29] | [Recasting Self-Attention with Holographic Reduced Representations.](http://arxiv.org/abs/2305.19534) | 本文提出了一种使用HRR的神经符号方法重新构建自注意力的方法，可以实现较低的时间和空间复杂度，并在LRA基准测试中获得了接近于最先进的准确度。 |
| [^30] | [Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape.](http://arxiv.org/abs/2305.19510) | 本文研究了略微超参数化的ReLU网络在有限输入数据集上的损失景观，证明了大多数激活模式对应的参数区域没有坏的可微局部极小值，对于一维输入数据，网络可以通过大多数激活模式实现高维全局极小值集合而不具有坏的局部极小值。 |
| [^31] | [Adaptive False Discovery Rate Control with Privacy Guarantee.](http://arxiv.org/abs/2305.19482) | 本文提出了一种带隐私保障的自适应FDR控制方法，采用新颖的p值转换方法和镜像剥离算法，可在用户指定的水平α下确切地控制经典的FDR指标，表现更好且可减小隐私泄露风险。 |
| [^32] | [Chain of Log-Concave Markov Chains.](http://arxiv.org/abs/2305.19473) | 该论文提出了一种新的采样算法，基于对数凹条件概率密度，使用等向性高斯平滑来解决高维下抽样难题。 |
| [^33] | [Label Embedding by Johnson-Lindenstrauss Matrices.](http://arxiv.org/abs/2305.19470) | 这篇论文提出了基于JLMs的标签嵌入方法，将多元分类问题转化为有限回归问题，具有较高的计算效率和预测准确性。 |
| [^34] | [Machine learning with tree tensor networks, CP rank constraints, and tensor dropout.](http://arxiv.org/abs/2305.19440) | 本文介绍了一种新的机器学习方法，通过基于树状张量网络的CP秩约束和张量丢弃，来构建低秩分类器，并在时尚-MNIST图像分类中展示出了优异的表现。 |
| [^35] | [Adapting Fairness Interventions to Missing Values.](http://arxiv.org/abs/2305.19429) | 本文研究了如何在缺失值的情况下实现公平的分类。传统方法会加剧歧视。本文证明从插补数据训练分类器会恶化组公平性和平均准确性。作者提出可扩展和适应性的算法，可以与其他公平干预算法结合使用，以处理所有可能的缺失模式。 |
| [^36] | [What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization.](http://arxiv.org/abs/2305.19420) | 本文对In-Context Learning进行了全面的研究，通过贝叶斯模型平均算法来隐式地实现ICL估计量，并采用在线学习的角度来分析ICL性能，建立后悔界限，并通过关注机制近似参数化。 |
| [^37] | [KrADagrad: Kronecker Approximation-Domination Gradient Preconditioned Stochastic Optimization.](http://arxiv.org/abs/2305.19416) | 本文提出了一种名为KrAD的新的Kronecker分解预处理方法，用于降低深度学习中二阶优化器的内存和计算资源要求。通过KrADagrad方法，避免了64位精度要求，并在32位精度下表现更好。 |
| [^38] | [Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network.](http://arxiv.org/abs/2305.19366) | 本文提出了在单一生成流网络中联合建模贝叶斯网络结构和参数的方法，包括非离散样本空间，提高了贝叶斯网络局部概率模型的灵活性。 |
| [^39] | [Non-convex Bayesian Learning via Stochastic Gradient Markov Chain Monte Carlo.](http://arxiv.org/abs/2305.19350) | 提出了一种基于随机梯度马尔科夫链蒙特卡罗的方法来解决非凸贝叶斯学习问题，具有理论保证。 |
| [^40] | [On Riemannian Projection-free Online Learning.](http://arxiv.org/abs/2305.19349) | 本文提出了一种针对非凸约束集情况下的曲线空间在线测地凸优化的无投影算法，获得了次线性遗憾保证。 |
| [^41] | [Provable benefits of general coverage conditions in efficient online RL with function approximation.](http://arxiv.org/abs/2304.12886) | 研究者对在线强化学习提出了一种新的一般覆盖条件，并发现更多的覆盖条件，提高了在线强化学习的样本效率和表现，同时阐明良好的覆盖条件仍然有益于获得最优解。 |
| [^42] | [Adaptive Conformal Prediction by Reweighting Nonconformity Score.](http://arxiv.org/abs/2303.12695) | 该论文提出了一种新方法，利用分位数回归森林来学习非拟合分数的分布，并利用其权重分配更多的重要性给残差与测试点相似的样本，从而实现更符合模型的不确定性的预测区间。 |
| [^43] | [Statistical learning on measures: an application to persistence diagrams.](http://arxiv.org/abs/2303.08456) | 本文提出了一个新的统计学习框架，用于处理紧致空间上的测度数据，并且向我们展示了如何使用拓扑信息进行分类。 |
| [^44] | [Can We Scale Transformers to Predict Parameters of Diverse ImageNet Models?.](http://arxiv.org/abs/2303.04143) | 该论文提出了一个可以预测其他神经网络高质量ImageNet参数的神经网络，通过使用预测参数进行初始化，能够提高多种ImageNet模型的训练速度，并且在转移到其他数据集时可以更快地收敛并达到竞争力的最终性能。 |
| [^45] | [On Hierarchical Multi-Resolution Graph Generative Models.](http://arxiv.org/abs/2303.03293) | 本文提出一种新颖的分层多分辨率图生成模型，能递归地生成多个层次的社区结构，并符合训练数据分布。该方法由粗到细地生成图，同时具有高度的可扩展性，提升了生成性能。 |
| [^46] | [Consistency Models.](http://arxiv.org/abs/2303.01469) | 提出了一种支持一步生成且支持零样本编辑的生成模型——一致性模型，它们能够通过直接将噪声映射到数据来生成高质量样本，支持快速的一步生成，且仍然支持多步抽样以提高样本质量。 |
| [^47] | [Simple Disentanglement of Style and Content in Visual Representations.](http://arxiv.org/abs/2302.09795) | 该论文提出了一个简单的后处理框架，用于分离学习到的表征中的内容和风格，在领域泛化中表现出显著的提升。 |
| [^48] | [Zero-Shot Batch-Level Anomaly Detection.](http://arxiv.org/abs/2302.07849) | 本文提出了一种名为“自适应中心表示”的方法，用于零样本批次级异常检测。该方法利用批量归一化来训练现成的深度异常检测器，可以自动零样本泛化为未见过的AD任务。在实验中，该方法显示出了在多种数据集上的优秀表现，对表格数据进行了零样本AD。 |
| [^49] | [On Sampling with Approximate Transport Maps.](http://arxiv.org/abs/2302.04763) | 本研究探讨了两种基于传输映射的抽样方法，研究结果表明，基于流的提议可以处理多峰目标，在高维度和训练不良的情况下使用依赖于重新参数化的方法更加稳健。 |
| [^50] | [On Enhancing Expressive Power via Compositions of Single Fixed-Size ReLU Network.](http://arxiv.org/abs/2301.12353) | 本文探讨了深度神经网络的表达能力，通过组合单个固定大小RELU网络，证明了其具有惊人的表达能力，尤其是在逼近具有$1-$Lipschitz连续性和一般连续性的函数时。 |
| [^51] | [Learning the Dynamics of Sparsely Observed Interacting Systems.](http://arxiv.org/abs/2301.11647) | 本论文解决了学习稀疏观测交互系统的动力学问题，将其作为解的学习控制微分方程（CDE），利用签名理论将非线性问题转化为高维线性回归，具有明确的依赖于个体特定采样方案的预测误差的oracle界限。证明了该方法优于现有算法回收完整时间序列，且计算成本较低。 |
| [^52] | [Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification.](http://arxiv.org/abs/2301.11562) | 在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。 |
| [^53] | [Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing.](http://arxiv.org/abs/2301.00006) | 该论文提出了一种多项选择众包任务的模型，该模型可以恢复最令人困惑的答案和混淆概率。在该模型下，提出了一个两阶段推断算法来推断最有可能的答案和混淆概率。 |
| [^54] | [Pareto Regret Analyses in Multi-objective Multi-armed Bandit.](http://arxiv.org/abs/2212.00884) | 本文研究了多目标多臂赌博机中的Pareto最优性，提出了对抗性多目标多臂赌博机的表述和定义了Pareto后悔，提出了新算法，分析证明算法在对抗性环境最优，在随机环境中也接近最优，并将对抗性攻击机制从赌徒推广到多目标领域。 |
| [^55] | [Revisiting Over-smoothing and Over-squashing Using Ollivier-Ricci Curvature.](http://arxiv.org/abs/2211.15779) | 研究发现图神经网络模型存在过度平滑和过度压缩问题，这一问题与图形曲率相关，作者利用Ollivier-Ricci曲率提出了Batch Ollivier-Ricci Flow算法，解决了这一问题。 |
| [^56] | [Topological Singularity Detection at Multiple Scales.](http://arxiv.org/abs/2210.00069) | 本文提出了一种多尺度拓扑奇异性检测方法，可以评估数据的局部固有维度，并量化点的“流形度”，能够检测复杂空间和图像中的奇异性。 |
| [^57] | [Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies.](http://arxiv.org/abs/2209.14568) | 本文提出了一种概率框架，为每个观测值提供稀疏的局部反事实规则，并将这些规则聚合成区域反事实规则，以适应不稳定的实现环境，并产生稳健的救济措施。 |
| [^58] | [Bayesian Complementary Kernelized Learning for Multidimensional Spatiotemporal Data.](http://arxiv.org/abs/2208.09978) | 本文提出了一种贝叶斯互补核学习（BCKL）框架，它将核化低秩张量分解和短程时空高斯过程相结合，可有效地建模多维时空数据的复杂相关性。 |
| [^59] | [What Can Be Learnt With Wide Convolutional Neural Networks?.](http://arxiv.org/abs/2208.01003) | 本文研究在内核环境下的无限宽卷积神经网络，证明了深层CNN能够适应目标函数的空间尺度，即使数据没有局部结构，深层CNN也可以学习，只要全局结构可以被利用。 |
| [^60] | [IBP Regularization for Verified Adversarial Robustness via Branch-and-Bound.](http://arxiv.org/abs/2206.14772) | 本文提出了一种基于区间传播的IBP正则化算法，通过在扩大的领域上进行对抗性攻击并结合一种基于廉价区间传播的正则化项来引入网络的可验证性，从而实现对抗训练网络的验证稳健性。 |
| [^61] | [Understanding convolution on graphs via energies.](http://arxiv.org/abs/2206.10991) | 本论文结合能量的概念，证明了带对称滤波器的线性图卷积可以增强高频率，使图神经网络在同质和异质任务中表现更好。 |
| [^62] | [OmniMAE: Single Model Masked Pretraining on Images and Videos.](http://arxiv.org/abs/2206.08356) | 该论文提出了一种基于遮蔽自编码的方法，可以在图像和视频上训练一个简单的单一Vision Transformer模型，而不需要标记数据，该模型的视觉表示可与单模态表示在基准测试上相当或更好，并且使用更简单的架构。 |
| [^63] | [Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances.](http://arxiv.org/abs/2206.03230) | 本文利用 PAC-Bayesian 理论，提出了自适应切片瓦砾斯坦距离的概括特性界限和一种基于界限的切片分布学习流程，以提高 SW 的判别度。 |
| [^64] | [Faster Rates of Convergence to Stationary Points in Differentially Private Optimization.](http://arxiv.org/abs/2206.00846) | 本文研究了在差分隐私下近似利普希茨和平滑函数的静态点问题。提供了新的高效算法和构造，分别在有限和随机情况下比现有算法更快的收敛速度。 |
| [^65] | [Static Scheduling with Predictions Learned through Efficient Exploration.](http://arxiv.org/abs/2205.15695) | 本文研究了单机作业调度的问题，提出了一种基于学习预测的静态调度算法，在类型未知的情况下实现了次线性的过剩成本，尤其在抢占式问题中表现出色，可以在不同作业类型持续时间相差很大时优于非抢占匹配。 |
| [^66] | [Causal Inference Despite Limited Global Confounding via Mixture Models.](http://arxiv.org/abs/2112.11602) | 本论文提出了一种基于混合模型的因果推断方法，通过解决混合问题和恢复概率分布，可以确定原本无法确定的因果关系。 |
| [^67] | [Controlling Wasserstein Distances by Kernel Norms with Application to Compressive Statistical Learning.](http://arxiv.org/abs/2112.00423) | 本文提供了用MMD范数控制Wasserstein距离的条件，针对压缩统计学习提出了HLRIP属性，通过导出的新核范数提供了计算上高效的Wasserstein距离压缩统计学习保证。 |
| [^68] | [Optimum-statistical Collaboration Towards General and Efficient Black-box Optimization.](http://arxiv.org/abs/2106.09215) | 本文提出了最优统计协作算法框架，管理优化误差通量和演化中的统计误差通量。该框架通用性强且适用于多种函数和分区族，并启发提出了一种方差自适应算法。 |
| [^69] | [Accurate Shapley Values for explaining tree-based models.](http://arxiv.org/abs/2106.03820) | 本文提出了在树模型中计算Shapley值的两种更准确的估计器，相比于现有方法可以更高效地利用树结构，并探讨了Shapley值作为局部解释的局限性。 |
| [^70] | [How Powerful are Shallow Neural Networks with Bandlimited Random Weights?.](http://arxiv.org/abs/2008.08427) | 本文研究了深度为2的带限制随机神经网络的表达能力，通过数学证明确定了当隐藏参数分布于有界域时，网络可能无法达到零逼近误差。 |
| [^71] | [Asymptotic normality of robust risk minimizers.](http://arxiv.org/abs/2004.02328) | 本文研究了强健模拟算法的渐近性质，将经验平均值替换成鲁棒均值的替代物，使得得到的估计器具有比经典方法更弱的假设条件下的渐近正态性，且对于广泛类的参数问题，强健风险最小化的最小化器以与真实风险的估计器相同的渐近速率和方差收敛。 |

# 详细

[^1]: 遗漏欺骗：使用对抗性缺失来污染因果结构学习

    Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning. (arXiv:2305.20043v1 [cs.LG])

    [http://arxiv.org/abs/2305.20043](http://arxiv.org/abs/2305.20043)

    本文提出了一种新的攻击方法，其中对手欺骗性地遗漏了部分真实的训练数据，以偏向所需的方式来影响学习到的因果结构。

    

    从观测数据推断因果结构是因果机器学习的重要组成部分；在实践中，这些数据可能存在不完全观测的问题。此前的研究已经证明，对完全观测的训练数据进行对抗性扰动可能会导致学习到的因果结构模型（SCMs）不准确。然而，当数据可以进行正确性审计时（例如，它是由其源加密签名的），这种对抗性机制就会被驳回。本文引入了一种新的攻击方法，其中对手欺骗性地遗漏了部分真实的训练数据，以偏向所需的方式来影响学习到的因果结构。针对任意SCMs的攻击机制被理论上证明是有用的，对于高斯SCMs，该文还给出了一种高效的基于学习的启发式方法。在真实和合成数据集上进行的实验验证了这些方法的有效性，并证明了缺失攻击对欺骗流行的因果结构学习方法的有效性。

    Inference of causal structures from observational data is a key component of causal machine learning; in practice, this data may be incompletely observed. Prior work has demonstrated that adversarial perturbations of completely observed training data may be used to force the learning of inaccurate causal structural models (SCMs). However, when the data can be audited for correctness (e.g., it is crytographically signed by its source), this adversarial mechanism is invalidated. This work introduces a novel attack methodology wherein the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner. Theoretically sound attack mechanisms are derived for the case of arbitrary SCMs, and a sample-efficient learning-based heuristic is given for Gaussian SCMs. Experimental validation of these approaches on real and synthetic data sets demonstrates the effectiveness of adversarial missingness attacks at deceiving popular causal structu
    
[^2]: 贝叶斯神经网络替代贝叶斯优化中的高斯过程模型

    A Study of Bayesian Neural Network Surrogates for Bayesian Optimization. (arXiv:2305.20028v1 [cs.LG])

    [http://arxiv.org/abs/2305.20028](http://arxiv.org/abs/2305.20028)

    本文研究贝叶斯神经网络替代高斯过程模型作为贝叶斯优化中的代理模型，并在多个基准问题上证明了其优于标准GP代理的能力。

    

    贝叶斯优化是一种高效的优化方法，适用于难以查询的目标函数。这些目标函数通常由高斯过程（GP）代理模型表示，其易于优化并支持精确推理。虽然标准的GP代理已经在贝叶斯优化中被广泛应用，但贝叶斯神经网络（BNNs）最近成为了一个实用的函数逼近器，与标准的GP相比具有许多优点，例如天然处理非平稳性以及学习高维数据的表示。在本文中，我们研究了BNN作为标准GP代理的替代品。我们考虑了各种有限宽度BNN的近似推理过程，包括高质量Hamiltonian Monte Carlo，低成本的随机MCMC和启发式方法（如深度集成）。我们还考虑了无限宽度BNN和部分随机模型，例如深度核学习。我们评估了这些代理模型在多个基准问题上的表现，并证明它们在某些情况下可以优于标准GP代理。我们的结果表明，BNN是传统代理模型在贝叶斯优化中的一个很有前途的替代选择。

    Bayesian optimization is a highly efficient approach to optimizing objective functions which are expensive to query. These objectives are typically represented by Gaussian process (GP) surrogate models which are easy to optimize and support exact inference. While standard GP surrogates have been well-established in Bayesian optimization, Bayesian neural networks (BNNs) have recently become practical function approximators, with many benefits over standard GPs such as the ability to naturally handle non-stationarity and learn representations for high-dimensional data. In this paper, we study BNNs as alternatives to standard GP surrogates for optimization. We consider a variety of approximate inference procedures for finite-width BNNs, including high-quality Hamiltonian Monte Carlo, low-cost stochastic MCMC, and heuristics such as deep ensembles. We also consider infinite-width BNNs and partially stochastic models such as deep kernel learning. We evaluate this collection of surrogate mod
    
[^3]: 限制因果贝叶斯优化

    Constrained Causal Bayesian Optimization. (arXiv:2305.20011v1 [stat.ML])

    [http://arxiv.org/abs/2305.20011](http://arxiv.org/abs/2305.20011)

    本论文提出了一种名为限制因果贝叶斯优化的方法，用于在已知因果图中寻找优化目标变量的干预方式并满足约束条件，成功地平衡了快速收敛和可行干预百分比之间的权衡。

    

    我们提出了限制因果贝叶斯优化（cCBO）方法，用于在已知因果图中找到优化目标变量的干预方法，并满足一些约束条件。cCBO首先通过利用图形结构和存在的观测数据减少搜索空间；然后通过使用高斯过程对目标和约束量进行建模，并通过使用受限期望改进获取函数依次选择干预方法来解决受限制的优化问题。我们提出了不同的代理模型，能够集成观测和干预数据，同时以不断提高的复杂度捕捉效应之间的相关性。我们对人工和真实因果图进行了cCBO评估，成功在快速收敛和可行干预百分比之间达成平衡。

    We propose constrained causal Bayesian optimization (cCBO), an approach for finding interventions in a known causal graph that optimize a target variable under some constraints. cCBO first reduces the search space by exploiting the graph structure and, if available, an observational dataset; and then solves the restricted optimization problem by modelling target and constraint quantities using Gaussian processes and by sequentially selecting interventions via a constrained expected improvement acquisition function. We propose different surrogate models that enable to integrate observational and interventional data while capturing correlation among effects with increasing levels of sophistication. We evaluate cCBO on artificial and real-world causal graphs showing successful trade off between fast convergence and percentage of feasible interventions.
    
[^4]: 基于潜在图解构模型的电子病历知识图谱嵌入技术

    Knowledge Graph Embedding with Electronic Health Records Data via Latent Graphical Block Model. (arXiv:2305.19997v1 [stat.ML])

    [http://arxiv.org/abs/2305.19997](http://arxiv.org/abs/2305.19997)

    本文提出了一种利用潜在图解构模型嵌入电子病历数据的知识图谱技术，以解决从EHR数据中获取可推广的知识的挑战。

    

    随着电子病历（EHR）应用的不断增加，大规模的EHR已成为转化性临床研究的另一种丰富数据源。然而，从EHR数据中获取可推广的知识仍然具有挑战性。本研究提出了一种基于潜在图解构模型的电子病历知识图谱嵌入技术来解决这些挑战。

    Due to the increasing adoption of electronic health records (EHR), large scale EHRs have become another rich data source for translational clinical research. Despite its potential, deriving generalizable knowledge from EHR data remains challenging. First, EHR data are generated as part of clinical care with data elements too detailed and fragmented for research. Despite recent progress in mapping EHR data to common ontology with hierarchical structures, much development is still needed to enable automatic grouping of local EHR codes to meaningful clinical concepts at a large scale. Second, the total number of unique EHR features is large, imposing methodological challenges to derive reproducible knowledge graph, especially when interest lies in conditional dependency structure. Third, the detailed EHR data on a very large patient cohort imposes additional computational challenge to deriving a knowledge network. To overcome these challenges, we propose to infer the conditional dependenc
    
[^5]: 噪声多视角聚类的嵌套矩阵-张量模型

    A Nested Matrix-Tensor Model for Noisy Multi-view Clustering. (arXiv:2305.19992v1 [stat.ML])

    [http://arxiv.org/abs/2305.19992](http://arxiv.org/abs/2305.19992)

    本文提出了一种嵌套矩阵-张量模型，用于解决多视角聚类问题，通过执行最佳秩一张量逼近来估计隐藏的聚类，理论结果可以预期精确准确度。

    

    本文提出了一种扩展了三阶钉子秩一张量模型的嵌套矩阵-张量模型。该模型特别针对多视角聚类问题，其中获得了每个数据点的多个嘈杂观察值，并且可能存在非均匀的视角方差。在这种情况下，数据可以通过将视角堆叠来自然表示为三阶张量。给定这样一个张量，我们通过执行最佳秩一张量逼近来考虑估计隐藏的聚类。为了研究该方法的理论性能，我们以大维度情况下获得的分量向量与隐藏模型参数向量的对齐作为评估标准来表征最佳秩一逼近的行为。特别地，我们展示了理论结果允许我们预期所提出的聚类方法的精确准确度。此外，数值实验表明，利用我们所提出的模型可以更好地解决多视角聚类问题。

    In this paper, we propose a nested matrix-tensor model which extends the spiked rank-one tensor model of order three. This model is particularly motivated by a multi-view clustering problem in which multiple noisy observations of each data point are acquired, with potentially non-uniform variances along the views. In this case, data can be naturally represented by an order-three tensor where the views are stacked. Given such a tensor, we consider the estimation of the hidden clusters via performing a best rank-one tensor approximation. In order to study the theoretical performance of this approach, we characterize the behavior of this best rank-one approximation in terms of the alignments of the obtained component vectors with the hidden model parameter vectors, in the large-dimensional regime. In particular, we show that our theoretical results allow us to anticipate the exact accuracy of the proposed clustering approach. Furthermore, numerical experiments indicate that leveraging our
    
[^6]: 不是所有神经符号概念都是平等的： 推理快捷方式的分析和缓解

    Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts. (arXiv:2305.19951v1 [cs.LG])

    [http://arxiv.org/abs/2305.19951](http://arxiv.org/abs/2305.19951)

    本研究通过将NeSy模型中出现的推理快捷方式定义为学习目标的意外最优解，并确定其发生的四个关键条件，提出了几种可行的缓解策略并对其进行了分析，显示推理快捷方式难以处理。

    

    神经符号（NeSy）预测模型承诺具有改进的约束遵从性，系统化泛化和可解释性，因为它们允许通过对从子符号输入中提取出的高级概念进行推理来推断与某些先验知识一致的标签。最近显示NeSy预测器受到推理快捷方式的影响：它们可以通过利用具有意外语义的概念达到高精度，从而短于其承诺的优势。但是，缺少对推理快捷方式及其潜在缓解策略的系统描述。本文通过将其表征为学习目标的意外最优解，并确定其发生背后的四个关键条件来填补这一空白。基于此，我们推导出几种自然的缓解策略，并从理论和实证角度分析它们的功效。我们的分析显示，推理快捷方式很难处理，这对于信任它们的合理性产生了疑问。

    Neuro-Symbolic (NeSy) predictive models hold the promise of improved compliance with given constraints, systematic generalization, and interpretability, as they allow to infer labels that are consistent with some prior knowledge by reasoning over high-level concepts extracted from sub-symbolic inputs. It was recently shown that NeSy predictors are affected by reasoning shortcuts: they can attain high accuracy but by leveraging concepts with unintended semantics, thus coming short of their promised advantages. Yet, a systematic characterization of reasoning shortcuts and of potential mitigation strategies is missing. This work fills this gap by characterizing them as unintended optima of the learning objective and identifying four key conditions behind their occurrence. Based on this, we derive several natural mitigation strategies, and analyze their efficacy both theoretically and empirically. Our analysis shows reasoning shortcuts are difficult to deal with, casting doubts on the trus
    
[^7]: 扩散模型的几何视角

    A Geometric Perspective on Diffusion Models. (arXiv:2305.19947v1 [cs.CV])

    [http://arxiv.org/abs/2305.19947](http://arxiv.org/abs/2305.19947)

    本文研究了扩散模型的几何结构，发现通过一个明确的准线性采样轨迹和另一个隐式的去噪轨迹平滑连接了数据分布和噪声分布，建立了基于ODE的最优采样和经典的均值漂移算法之间的理论关系。

    

    近年来，针对扩散模型的高效训练和快速采样方法取得了显著进展。最近的一个重要进展是使用随机微分方程（SDE）来描述数据扰动和生成建模，以实现统一的数学框架。本文揭示了扩散模型的几个有趣的几何结构，并为其采样动力学提供了简单而强大的解释。通过仔细检查一种流行的方差爆炸SDE及其保持边际的普通微分方程（ODE）用于采样，我们发现数据分布和噪声分布通过一个明确的准线性采样轨迹和另一个隐式的去噪轨迹平滑连接，即使在视觉质量方面也收敛更快。我们还建立起基于ODE的最优采样和经典的均值漂移（寻找模式）算法之间的理论关系。

    Recent years have witnessed significant progress in developing efficient training and fast sampling approaches for diffusion models. A recent remarkable advancement is the use of stochastic differential equations (SDEs) to describe data perturbation and generative modeling in a unified mathematical framework. In this paper, we reveal several intriguing geometric structures of diffusion models and contribute a simple yet powerful interpretation to their sampling dynamics. Through carefully inspecting a popular variance-exploding SDE and its marginal-preserving ordinary differential equation (ODE) for sampling, we discover that the data distribution and the noise distribution are smoothly connected with an explicit, quasi-linear sampling trajectory, and another implicit denoising trajectory, which even converges faster in terms of visual quality. We also establish a theoretical relationship between the optimal ODE-based sampling and the classic mean-shift (mode-seeking) algorithm, with w
    
[^8]: 在拟阵上完全动态子模最大化问题

    Fully Dynamic Submodular Maximization over Matroids. (arXiv:2305.19918v1 [cs.DS])

    [http://arxiv.org/abs/2305.19918](http://arxiv.org/abs/2305.19918)

    本论文研究了在元素可以实时地被插入和删除的情况下，最大化拟阵限制下的单调子模函数问题，提出了一种随机算法，时间复杂度为$\tilde{O}(k^2)$，可以产生一个$4$近似解。

    

    在数据挖掘和机器学习中，最大化拟阵限制下的单调子模函数是一个具有多个应用的经典算法问题。本文研究了在完全动态的情况下，即元素可以实时地被插入和删除的情况下的这个问题。我们的主要结果是一种随机算法，它维护了一种高效的数据结构，其摊销更新时间为$\tilde{O}(k^2)$（在添加和删除次数上），并产生了一个$4$近似解，其中$k$是拟阵的秩。

    Maximizing monotone submodular functions under a matroid constraint is a classic algorithmic problem with multiple applications in data mining and machine learning. We study this classic problem in the fully dynamic setting, where elements can be both inserted and deleted in real-time. Our main result is a randomized algorithm that maintains an efficient data structure with an $\tilde{O}(k^2)$ amortized update time (in the number of additions and deletions) and yields a $4$-approximate solution, where $k$ is the rank of the matroid.
    
[^9]: 带有Jackknife+ Rescaled Scores的自适应符合回归

    Adaptive Conformal Regression with Jackknife+ Rescaled Scores. (arXiv:2305.19901v1 [cs.LG])

    [http://arxiv.org/abs/2305.19901](http://arxiv.org/abs/2305.19901)

    提出一种新的自适应方法，它基于用局部分数分布的估计来重新缩放符合分数。该方法不会牺牲校准集大小，实现了局部覆盖并提高了符合预测间隔的适用性，特别适用于低数据范围内的应用。

    

    符合回归提供了具有全局覆盖保证的预测区间，但往往无法捕获局部误差分布，导致不均匀覆盖。我们提出了一种新的自适应方法，它基于用局部分数分布的估计来重新缩放符合分数，灵感来自Jackknife+方法，它使得在不破坏校准-测试交换性的情况下可以利用校准数据的符合分数。我们的方法确保了正式的全局覆盖保证，并得到了关于局部覆盖的新理论结果，包括任何校准分数的后验界限。我们的方法的优势在于实现了局部覆盖，而不牺牲校准集大小，提高了符合预测间隔在各种设置中的适用性。因此，我们的方法提供了优于先前方法的预测区间，特别是在低数据范围内，使其在实际应用中尤为相关。

    Conformal regression provides prediction intervals with global coverage guarantees, but often fails to capture local error distributions, leading to non-homogeneous coverage. We address this with a new adaptive method based on rescaling conformal scores with an estimate of local score distribution, inspired by the Jackknife+ method, which enables the use of calibration data in conformal scores without breaking calibration-test exchangeability. Our approach ensures formal global coverage guarantees and is supported by new theoretical results on local coverage, including an a posteriori bound on any calibration score. The strength of our approach lies in achieving local coverage without sacrificing calibration set size, improving the applicability of conformal prediction intervals in various settings. As a result, our method provides prediction intervals that outperform previous methods, particularly in the low-data regime, making it especially relevant for real-world applications such a
    
[^10]: EAMDrift：一种可解释的自我重训练时间序列模型

    EAMDrift: An interpretable self retrain model for time series. (arXiv:2305.19837v1 [stat.ML])

    [http://arxiv.org/abs/2305.19837](http://arxiv.org/abs/2305.19837)

    EAMDrift是一种可解释的时间序列预测模型，通过对多个预测器的预测进行加权，自动适应分布外模式，并在每个时刻选择最合适的模型。其设计包括自动重训练机制和基于概念编码的观察者模型。

    

    随着时间序列数据的可用性和机器学习算法的不断发展，在各个行业中使用机器学习进行时间序列预测变得越来越流行。然而，传统的时间序列预测方法依赖于预先优化的模型，难以处理数据中的不可预测模式。在本文中，我们提出了一种新颖的方法——EAMDrift，该方法通过按性能度量加权每个预测，将多个独立预测器的预测组合起来。 EAMDrift旨在通过解释性机制自动适应数据中的分布外模式并识别每个时刻使用的最合适的模型，其中包括自动重训练过程。具体而言，我们使用不同的模型对不同的概念进行编码，每个模型作为特定行为的观察者。然后，整体模型的激活将确定哪个概念观察者子集正在识别概念。

    The use of machine learning for time series prediction has become increasingly popular across various industries thanks to the availability of time series data and advancements in machine learning algorithms. However, traditional methods for time series forecasting rely on pre-optimized models that are ill-equipped to handle unpredictable patterns in data. In this paper, we present EAMDrift, a novel method that combines forecasts from multiple individual predictors by weighting each prediction according to a performance metric. EAMDrift is designed to automatically adapt to out-of-distribution patterns in data and identify the most appropriate models to use at each moment through interpretable mechanisms, which include an automatic retraining process. Specifically, we encode different concepts with different models, each functioning as an observer of specific behaviors. The activation of the overall model then identifies which subset of the concept observers is identifying concepts in 
    
[^11]: 使用数据一致性的直接扩散链桥解决逆问题

    Direct Diffusion Bridge using Data Consistency for Inverse Problems. (arXiv:2305.19809v1 [cs.CV])

    [http://arxiv.org/abs/2305.19809](http://arxiv.org/abs/2305.19809)

    本文提出了一种用于逆问题的直接扩散链桥算法，提高了逆问题求解器的性能，并通过使用数据一致性解决了当前DDB框架存在的关键限制。

    

    基于扩散模型的逆问题求解器表现出令人印象深刻的性能，但速度受限，主要是因为需要从噪声开始进行反向扩散采样。近期的一些工作尝试通过构建扩散过程来直接桥接特定逆问题的清洁和污染数据以减轻这个问题。在本文中，我们首先将这些现有工作统一命名为直接扩散链桥（DDB），证明尽管受不同理论的启发，但由此产生的算法在参数选择上的不同。然后，我们强调当前DDB框架的一个关键限制，即它不能保证数据一致性。为了解决这个问题，我们提出了一种修改的推断程序，它在不需要精细调整的情况下强制数据一致性。我们将得到的方法称为数据一致的DDB（CDDB），它在感知和失真指标方面都优于不一致的对应物，从而有效地推动了逆问题求解器的最新进展。

    Diffusion model-based inverse problem solvers have shown impressive performance, but are limited in speed, mostly as they require reverse diffusion sampling starting from noise. Several recent works have tried to alleviate this problem by building a diffusion process, directly bridging the clean and the corrupted for specific inverse problems. In this paper, we first unify these existing works under the name Direct Diffusion Bridges (DDB), showing that while motivated by different theories, the resulting algorithms only differ in the choice of parameters. Then, we highlight a critical limitation of the current DDB framework, namely that it does not ensure data consistency. To address this problem, we propose a modified inference procedure that imposes data consistency without the need for fine-tuning. We term the resulting method data Consistent DDB (CDDB), which outperforms its inconsistent counterpart in terms of both perception and distortion metrics, thereby effectively pushing the
    
[^12]: 距离排名分数：不平衡数据集上无监督特征选择的滤波器方法

    Distance Rank Score: Unsupervised filter method for feature selection on imbalanced dataset. (arXiv:2305.19804v1 [stat.ML])

    [http://arxiv.org/abs/2305.19804](http://arxiv.org/abs/2305.19804)

    本文提出了一种新的滤波器方法，能有效处理不平衡多类数据集上的特征选择问题，它基于Spearman排名相关性而不是特征方差。

    

    本文提出了一种新的无监督特征选择的滤波器方法。该方法在不平衡的多类数据集上特别有效，如不同异常类型的群集中。现有方法通常涉及特征的方差，当不同类型的观测没有被平等地表示时，这种方法并不适用。我们的方法基于观测与特征值之间的Spearman排名相关性，避免了这种缺点。该方法的性能通过多个聚类问题进行了测试，并与适用于无监督数据的现有滤波器方法进行了比较。

    This paper presents a new filter method for unsupervised feature selection. This method is particularly effective on imbalanced multi-class dataset, as in case of clusters of different anomaly types. Existing methods usually involve the variance of the features, which is not suitable when the different types of observations are not represented equally. Our method, based on Spearman's Rank Correlation between distances on the observations and on feature values, avoids this drawback. The performance of the method is measured on several clustering problems and is compared with existing filter methods suitable for unsupervised data.
    
[^13]: 利用aggVAE进行深度学习和MCMC以处理行政边界变化：以肯尼亚的疟疾患病率为例

    Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya. (arXiv:2305.19779v1 [cs.LG])

    [http://arxiv.org/abs/2305.19779](http://arxiv.org/abs/2305.19779)

    本研究提出了一种利用aggVAE进行深度学习和MCMC处理行政边界变化的解决方案，可以更准确地映射以县为层级的聚合级别数据，并处理行政边界的变化，相比最先进的模型表现更好。

    

    基于模型的疾病映射是公共卫生和疾病监测中基本的政策信息工具，分层贝叶斯模型是当前最先进的方法。当处理区域数据，如行政区划单位（例如县或省）的聚合数据时，常用的模型依赖于区域单元的相邻结构以考虑空间相关性。疾病监测系统的目标是随时间跟踪疾病结果，但在危机情况下（例如政治变化导致行政边界更改），这将带来挑战。我们提出了一种新颖、实用和易于实施的解决方案，该方案依赖于组合深层生成模型和全贝叶斯推断。我们建立在现有的变分自编码器(VAE) 工作上，并展示我们提出的聚合VAE(aggVAE)体系结构可用于在以县为层级的聚合级别处理数据，以映射肯尼亚的疟疾患病率。我们的模型可以以连续的方式考虑空间相关性，而不依赖于相邻性假设，并且能够处理行政边界的变化。结果表明，相比最先进的模型，我们的模型表现出更好的性能和更准确的疟疾患病率映射。

    Model-based disease mapping remains a fundamental policy-informing tool in public health and disease surveillance with hierarchical Bayesian models being the current state-of-the-art approach. When working with areal data, e.g. aggregates at the administrative unit level such as district or province, routinely used models rely on the adjacency structure of areal units to account for spatial correlations. The goal of disease surveillance systems is to track disease outcomes over time, but this provides challenging in situations of crises, such as political changes, leading to changes of administrative boundaries. Kenya is an example of such country. Moreover, adjacency-based approach ignores the continuous nature of spatial processes and cannot solve the change-of-support problem, i.e. when administrative boundaries change. We present a novel, practical, and easy to implement solution relying on a methodology combining deep generative modelling and fully Bayesian inference. We build on 
    
[^14]: 神经马尔可夫跳跃过程

    Neural Markov Jump Processes. (arXiv:2305.19744v1 [cs.LG])

    [http://arxiv.org/abs/2305.19744](http://arxiv.org/abs/2305.19744)

    介绍了一种基于神经常微分方程的马尔可夫跳跃过程的变分推断算法，可通过反向传播进行训练，用于近似后验马尔可夫跳跃过程的初始分布和时间相关的转移概率率，同时在先验过程的时间无关率上也有很好的表现。

    

    马尔可夫跳跃过程是具有广泛应用的连续时间随机过程，被广泛应用于自然和社会科学领域。尽管它们被广泛使用，但这些模型中的推断是非常复杂的，通常需要通过蒙特卡罗或期望最大化方法进行。本文介绍了一种基于神经常微分方程的马尔可夫跳跃过程的变分推断算法，并可通过反向传播进行训练。该方法学习了观测数据的神经连续时间表示，用于近似后验马尔可夫跳跃过程的初始分布和时间相关的转移概率率。相比之下，先验过程的时间无关率则像生成对抗网络一样进行训练。我们在合成数据上测试了我们的方法，这些数据是从真实的马尔可夫跳跃过程、实验性开关离子通道数据和分子动力学模拟中采样得到的。

    Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source c
    
[^15]: 图的Bures-Wasserstein平均值

    Bures-Wasserstein Means of Graphs. (arXiv:2305.19738v1 [stat.ML])

    [http://arxiv.org/abs/2305.19738](http://arxiv.org/abs/2305.19738)

    该论文提出了一个新颖的框架，通过在平滑图信号分布空间中嵌入图来定义图的平均值，其中可以使用Wasserstein度量衡量图相似性。实验结果表明，在各种任务中都有很好的表现。

    

    在机器学习和统计学中，找到采样数据的平均值是一项基本任务。然而，在数据样本为图对象的情况下，定义平均值是一项困难的任务。我们提出了一个新颖的框架，通过在平滑图信号分布空间中嵌入图来定义图的平均值，其中可以使用Wasserstein度量衡量图相似性。通过在此嵌入空间中找到平均值，我们可以恢复保留结构信息的平均图。我们确定了新的图平均值的存在和唯一性，并提供了一个迭代算法来计算它。为了展示我们的框架作为机器学习中的一个有价值的工具，我们在各种任务中进行了评估，包括结构化图的k-means聚类、功能性脑网络的分类以及多层图的半监督节点分类。我们的实验结果表明，我们的方法实现了一致的p。

    Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent p
    
[^16]: 利用代理分类损失的假设迁移学习

    Hypothesis Transfer Learning with Surrogate Classification Losses. (arXiv:2305.19694v1 [stat.ML])

    [http://arxiv.org/abs/2305.19694](http://arxiv.org/abs/2305.19694)

    本文研究了使用代理分类损失的假设迁移学习的学习理论，通过算法稳定性提供了在温和假设下的学习保证，适用于机器学习算法。

    

    假设迁移学习（HTL）通过允许先前任务（即源任务）向一个新任务（目标任务）转移学习，而无需访问源数据，与领域自适应相对应。事实上，HTL仅依赖于从源数据学习到的假设，免除了大量数据存储的障碍，并提供了巨大的实际利益。因此，HTL对于依赖于大数据的实际应用非常有利。本文通过算法稳定性研究HTL的学习理论，这是一种用于分析机器学习算法的有吸引力的理论框架，特别是在二分类情况下感兴趣。我们的稳定性分析提供了在温和假设下的学习保证。因此，我们得出了几个比以前更紧密的理论界限，这些界限可以实际应用于机器学习算法。

    Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing for a previous task leverage, named the source, into a new one, the target, without requiring access to the source data. Indeed, HTL relies only on a hypothesis learnt from such source data, relieving the hurdle of expansive data storage and providing great practical benefits. Hence, HTL is highly beneficial for real-world applications relying on big data. The analysis of such a method from a theoretical perspective faces multiple challenges, particularly in classification tasks. This paper deals with this problem by studying the learning theory of HTL through algorithmic stability, an attractive theoretical framework for machine learning algorithms analysis. In particular, we are interested in the statistical behaviour of the regularized empirical risk minimizers in the case of binary classification. Our stability analysis provides learning guarantees under mild assumptions. Consequently, we derive several comp
    
[^17]: 异步多人赌博问题中的常数或对数遗憾

    Constant or logarithmic regret in asynchronous multiplayer bandits. (arXiv:2305.19691v1 [cs.LG])

    [http://arxiv.org/abs/2305.19691](http://arxiv.org/abs/2305.19691)

    本文解决了异步多人赌博问题的集中式情况，推出了Cautious Greedy算法，可以保证常数遗憾，同时UCB算法的自然扩展展现出了 $\mathcal{O}(\sqrt{T\log(T)})$ 极小化遗憾。

    

    最近，由于在认知无线电网络中的应用，多人赌博问题得到了广泛研究。虽然文献大多考虑同步玩家，但无线电网络（例如物联网） tend to have asynchronous devices。这引发了更加困难的异步多人赌博问题，首先用探索然后承诺（ETC）算法解决（请参见 Dakdouk，2022），遗憾上限为 $\mathcal{O}(T^{\frac{2}{3}})$。甚至在考虑分散化之前，理解集中式情况仍然是一个挑战，因为不知道是否可能得到小于 $\Omega(T^\frac{2}{3})$ 的遗憾。 我们对这个问题作出了肯定回答，因为UCB的自然扩展展现出了 $\mathcal{O}(\sqrt{T\log(T)})$ 极小化遗憾。更重要的是，我们介绍了一个叫做“谨慎贪婪”的集中式算法，如果最优策略至少将一个玩家指定在每个武器上（被证明会出现这种情况），则可以产生常数保证的遗憾。

    Multiplayer bandits have recently been extensively studied because of their application to cognitive radio networks.  While the literature mostly considers synchronous players, radio networks (e.g. for IoT) tend to have asynchronous devices. This motivates the harder, asynchronous multiplayer bandits problem, which was first tackled with an explore-then-commit (ETC) algorithm (see Dakdouk, 2022), with a regret upper-bound in $\mathcal{O}(T^{\frac{2}{3}})$. Before even considering decentralization, understanding the centralized case was still a challenge as it was unknown whether getting a regret smaller than $\Omega(T^{\frac{2}{3}})$ was possible.  We answer positively this question, as a natural extension of UCB exhibits a $\mathcal{O}(\sqrt{T\log(T)})$ minimax regret.  More importantly, we introduce Cautious Greedy, a centralized algorithm that yields constant instance-dependent regret if the optimal policy assigns at least one player on each arm (a situation that is proved to occur 
    
[^18]: 深度随机力学

    Deep Stochastic Mechanics. (arXiv:2305.19685v1 [cs.LG])

    [http://arxiv.org/abs/2305.19685](http://arxiv.org/abs/2305.19685)

    本文提出了一种基于深度学习的方法，用于数值模拟时间演化薛定谔方程，利用马尔可夫扩散采样来适应波函数的潜在低维结构，并提出了新的随机量子力学方程，具有线性的计算复杂度。数值模拟显示出显着的优势。

    

    本文引入了一种基于深度学习的方法，用于数值模拟时间演化薛定谔方程，受随机力学和生成性扩散模型的启发。与现有方法不同的是，我们的方法允许我们通过从马尔可夫扩散中采样来适应波函数潜在的低维结构，因此可以在更高的维度上降低计算复杂度。此外，我们提出了新的随机量子力学方程，结果具有与维数数量线性的计算复杂度。数值模拟验证了我们的理论发现，并显示出我们的方法与其他用于量子力学的基于深度学习的方法相比具有显着优势。

    This paper introduces a novel deep-learning-based approach for numerical simulation of a time-evolving Schr\"odinger equation inspired by stochastic mechanics and generative diffusion models. Unlike existing approaches, which exhibit computational complexity that scales exponentially in the problem dimension, our method allows us to adapt to the latent low-dimensional structure of the wave function by sampling from the Markovian diffusion. Depending on the latent dimension, our method may have far lower computational complexity in higher dimensions. Moreover, we propose novel equations for stochastic quantum mechanics, resulting in linear computational complexity with respect to the number of dimensions. Numerical simulations verify our theoretical findings and show a significant advantage of our method compared to other deep-learning-based approaches used for quantum mechanics.
    
[^19]: 通过局部模态初始化和无偏差对比散度实现深度玻尔兹曼机的端到端训练

    End-to-end Training of Deep Boltzmann Machines by Unbiased Contrastive Divergence with Local Mode Initialization. (arXiv:2305.19684v1 [cs.LG])

    [http://arxiv.org/abs/2305.19684](http://arxiv.org/abs/2305.19684)

    本研究提出一种基于Metropolis-Hastings耦合和局部模态初始化的方法，解决了深度玻尔兹曼机中的偏差梯度估计问题，使得DBMs可以端到端地训练，实验结果表明与其他深度生成模型相当的生成性能。

    

    本研究解决了深度玻尔兹曼机（DBMs）中的偏差梯度估计问题。现有的获取无偏估计量的方法使用基于Gibbs采样的最大耦合，但当状态是高维时，其收敛需要很长时间。因此，我们提出了基于Metropolis-Hastings的耦合，并围绕目标分布的局部模态初始化状态。由于MH倾向于拒绝提案，这种耦合有很高的概率在一步内收敛，因此具有高效性。我们发现，我们的方法可以在不进行贪心预训练的情况下端到端地训练DBMs。我们还提出了一些实用技术，以进一步提高DBMs的性能。我们通过实验证明，我们的训练算法使DBMs能够展现出与其他深度生成模型相当的生成性能，在MNIST上达到了10.33的FID分数。

    We address the problem of biased gradient estimation in deep Boltzmann machines (DBMs). The existing method to obtain an unbiased estimator uses a maximal coupling based on a Gibbs sampler, but when the state is high-dimensional, it takes a long time to converge. In this study, we propose to use a coupling based on the Metropolis-Hastings (MH) and to initialize the state around a local mode of the target distribution. Because of the propensity of MH to reject proposals, the coupling tends to converge in only one step with a high probability, leading to high efficiency. We find that our method allows DBMs to be trained in an end-to-end fashion without greedy pretraining. We also propose some practical techniques to further improve the performance of DBMs. We empirically demonstrate that our training algorithm enables DBMs to show comparable generative performance to other deep generative models, achieving the FID score of 10.33 for MNIST.
    
[^20]: 在线到PAC的转换: 通过遗憾分析得出泛化界限

    Online-to-PAC Conversions: Generalization Bounds via Regret Analysis. (arXiv:2305.19674v1 [stat.ML])

    [http://arxiv.org/abs/2305.19674](http://arxiv.org/abs/2305.19674)

    本文提出了在线学习游戏“泛化游戏”的框架，将在线学习算法的表现和统计学习算法的泛化界限联系了起来，并得出了一些标准的泛化限制。

    

    我们提出了一个新的框架，通过在线学习的视角推导出统计学习算法的泛化界限。具体而言，我们构建了一个在线学习游戏称为“泛化游戏”，其中在线学习器试图与固定的统计学习算法竞争，预测独立同分布数据点训练集上的泛化间隙序列。我们通过展示在这个游戏中存在有界遗憾的在线学习算法与统计学习设置之间的联系来建立这种关联，这意味着统计学习算法的泛化错误存在一个界限，直到与统计学习方法的复杂性无关的鞅浓度项。这种技术允许我们恢复几个标准的泛化限制，包括一系列的PAC-Bayesian保证和信息理论保证，以及它们的推广。

    We present a new framework for deriving bounds on the generalization bound of statistical learning algorithms from the perspective of online learning. Specifically, we construct an online learning game called the "generalization game", where an online learner is trying to compete with a fixed statistical learning algorithm in predicting the sequence of generalization gaps on a training set of i.i.d. data points. We establish a connection between the online and statistical learning setting by showing that the existence of an online learning algorithm with bounded regret in this game implies a bound on the generalization error of the statistical learning algorithm, up to a martingale concentration term that is independent of the complexity of the statistical learning method. This technique allows us to recover several standard generalization bounds including a range of PAC-Bayesian and information-theoretic guarantees, as well as generalizations thereof.
    
[^21]: 深度ReLU网络中的成对学习最优估计

    Optimal Estimates for Pairwise Learning with Deep ReLU Networks. (arXiv:2305.19640v1 [stat.ML])

    [http://arxiv.org/abs/2305.19640](http://arxiv.org/abs/2305.19640)

    本文研究了深度ReLU网络中的成对学习，提出了一个针对一般损失函数的误差估计的尖锐界限，并基于成对最小二乘损失得出几乎最优的过度泛化误差界限。

    

    成对学习指的是在损失函数中考虑一对样本的学习任务。本文研究了深度ReLU网络中的成对学习，并估计了过度泛化误差。对于满足某些温和条件的一般损失函数，建立了误差估计的尖锐界限，其误差估计的阶数为O（（Vlog（n）/ n）1 /（2-β））。特别地，对于成对最小二乘损失，我们得到了过度泛化误差的几乎最优界限，在真实的预测器满足某些光滑性正则性时，最优界限达到了最小化界限，差距仅为对数项。

    Pairwise learning refers to learning tasks where a loss takes a pair of samples into consideration. In this paper, we study pairwise learning with deep ReLU networks and estimate the excess generalization error. For a general loss satisfying some mild conditions, a sharp bound for the estimation error of order $O((V\log(n) /n)^{1/(2-\beta)})$ is established. In particular, with the pairwise least squares loss, we derive a nearly optimal bound of the excess generalization error which achieves the minimax lower bound up to a logrithmic term when the true predictor satisfies some smoothness regularities.
    
[^22]: 无参数投影梯度下降

    Parameter-free projected gradient descent. (arXiv:2305.19605v1 [stat.ML])

    [http://arxiv.org/abs/2305.19605](http://arxiv.org/abs/2305.19605)

    本文提出了一种无参数的投影梯度下降算法，能够自适应地处理初始点与最优解之间的距离以及子梯度的平方和，适用于在闭合凸集上最小化凸函数的问题，并且能够在满足对数因子下的累积遗憾的最优收敛速率。

    

    本文探讨了在闭合凸集上最小化凸函数的问题，使用投影梯度下降（PGD）进行求解。我们提出了完全无参数版本的AdaGrad，该方法能够自适应地处理初始点与最优解之间的距离以及子梯度的平方和。与经典的PGD相比，我们的算法能够处理投影步骤，无需重新启动、轨迹加权或额外的梯度评估。同时，它还满足了在对数因子下的累积遗憾的最优收敛速率。我们还提供了将该方法扩展到随机优化的方法，并进行了支持所开发的理论的数值实验。

    We consider the problem of minimizing a convex function over a closed convex set, with Projected Gradient Descent (PGD). We propose a fully parameter-free version of AdaGrad, which is adaptive to the distance between the initialization and the optimum, and to the sum of the square norm of the subgradients. Our algorithm is able to handle projection steps, does not involve restarts, reweighing along the trajectory or additional gradient evaluations compared to the classical PGD. It also fulfills optimal rates of convergence for cumulative regret up to logarithmic factors. We provide an extension of our approach to stochastic optimization and conduct numerical experiments supporting the developed theory.
    
[^23]: 带建议的主动因果结构学习

    Active causal structure learning with advice. (arXiv:2305.19588v1 [cs.LG])

    [http://arxiv.org/abs/2305.19588](http://arxiv.org/abs/2305.19588)

    本研究提出了带建议的主动因果结构学习问题，并设计了一个自适应搜索算法，可以从建议中受益，即使建议是任意糟糕的情况下，仍然具有最坏情况下的保证。

    

    我们引入了带建议的主动因果结构学习问题。在典型的研究中，学习算法针对观测分布获得本质图，并被要求在最小化干预次数的同时恢复出潜在的因果有向无环图(DAG) $G^*$。在我们的问题设定中，除了关于 $G^*$的必要信息外，例如一个声称是 $G^*$的DAG $G$，我们还会额外获得关于 $G^*$的侧面信息。我们想知道，当建议接近正确时，学习算法是否可以从建议中受益，同时即使建议是任意糟糕的情况下，仍然具有最坏情况下的保证。我们的工作与关于带预测算法的不断增加的研究领域相同。当建议是有向无环图$G$时，我们设计了自适应搜索算法来恢复 $G^*$，其干预成本最多为验证$G^*$的成本的$O(max\{1, \log \psi\})$倍。这里，$\psi$是$G$和$G^*$之间的距离度量，它被上界约束。

    We introduce the problem of active causal structure learning with advice. In the typical well-studied setting, the learning algorithm is given the essential graph for the observational distribution and is asked to recover the underlying causal directed acyclic graph (DAG) $G^*$ while minimizing the number of interventions made. In our setting, we are additionally given side information about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the learning algorithm can benefit from the advice when it is close to being correct, while still having worst-case guarantees even when the advice is arbitrarily bad. Our work is in the same space as the growing body of research on algorithms with predictions. When the advice is a DAG $G$, we design an adaptive search algorithm to recover $G^*$ whose intervention cost is at most $O(\max\{1, \log \psi\})$ times the cost for verifying $G^*$; here, $\psi$ is a distance measure between $G$ and $G^*$ that is upper bounded by the numb
    
[^24]: 关于Hadamard参数化下策略梯度的线性收敛性.

    On the Linear Convergence of Policy Gradient under Hadamard Parameterization. (arXiv:2305.19575v1 [math.OC])

    [http://arxiv.org/abs/2305.19575](http://arxiv.org/abs/2305.19575)

    本文研究了Hadamard参数化下策略梯度的收敛性，证明了算法具有全局线性收敛性和局部线性收敛速度更快的性质。

    

    本文研究了在表格式设置下Hadamard参数化下确定性策略梯度的收敛性，并建立了算法的全局线性收敛性。为此，我们首先证明了错误在所有迭代中以$O(\frac{1}{k})$的速率下降。基于这个结果，我们进一步证明了该算法在$k_0$次迭代之后具有更快的局部线性收敛速度，其中$k_0$是仅依赖于MDP问题和步长的常数。总体而言，该算法显示了一个较弱常数的线性收敛率，而不仅仅是局部线性收敛率。

    The convergence of deterministic policy gradient under the Hadamard parametrization is studied in the tabular setting and the global linear convergence of the algorithm is established. To this end, we first show that the error decreases at an $O(\frac{1}{k})$ rate for all the iterations. Based on this result, we further show that the algorithm has a faster local linear convergence rate after $k_0$ iterations, where $k_0$ is a constant that only depends on the MDP problem and the step size. Overall, the algorithm displays a linear convergence rate for all the iterations with a loose constant than that for the local linear convergence rate.
    
[^25]: 在线标签移位：最优动态遗憾相遇实用算法

    Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms. (arXiv:2305.19570v1 [stat.ML])

    [http://arxiv.org/abs/2305.19570](http://arxiv.org/abs/2305.19570)

    本文提出了新算法来解决在线标签移位问题，在无需先验知识的情况下通过在线回归保证了最优动态遗憾，并在模拟和真实场景中表现出卓越的性能。

    

    本文关注监督和无监督在线标签移位，其中类边际 $Q(y)$ 变化，但类条件 $Q(x|y)$ 保持不变。在无监督设置中，我们的目标是适应一个从某些离线标记数据训练的学习器，以适应给定未标记在线数据下的变化标签分布。在监督设置中，我们必须学习分类器并适应只给定有标记在线数据的动态演化类边际。我们开发了新算法，将适应问题减少到在线回归并保证无先验知识下的最优动态遗憾。我们的解决方案基于引导在线回归预测器估计，以跟踪漂移比例。在众多模拟和真实世界的在线标签移位场景中的实验证明了我们提出方法的卓越性能，通常实现1-3％的准确性提高，同时具有更小的计算和内存消耗。

    This paper focuses on supervised and unsupervised online label shift, where the class marginals $Q(y)$ varies but the class-conditionals $Q(x|y)$ remain invariant. In the unsupervised setting, our goal is to adapt a learner, trained on some offline labeled data, to changing label distributions given unlabeled online data. In the supervised setting, we must both learn a classifier and adapt to the dynamically evolving class marginals given only labeled online data. We develop novel algorithms that reduce the adaptation problem to online regression and guarantee optimal dynamic regret without any prior knowledge of the extent of drift in the label distribution. Our solution is based on bootstrapping the estimates of \emph{online regression oracles} that track the drifting proportions. Experiments across numerous simulated and real-world online label shift scenarios demonstrate the superior performance of our proposed approaches, often achieving 1-3\% improvement in accuracy while being s
    
[^26]: 强化学习中的可复现性研究

    Replicability in Reinforcement Learning. (arXiv:2305.19562v1 [cs.LG])

    [http://arxiv.org/abs/2305.19562](http://arxiv.org/abs/2305.19562)

    这篇论文研究了在强化学习中的可复制性，提出了可复制算法和松弛可复制算法，并给出了相应的时间和样本复杂度，这对于RL算法设计以及未来的可复制性研究具有影响。

    

    我们在强化学习 (RL) 的背景下，将可复现性作为算法属性进行了数学研究。我们关注的是具有生成模型访问权的带折扣表格MDP的基本设置。受Impagliazzo等人 [2022]的启发，如果在内部随机性相同时，RL算法在从生成器抽取的两个独立和同分布的样本上执行两次并输出完全相同的策略，则表示该RL算法是可复制的。我们首先提供一个有效的$\rho$-可复制算法，用于$(\varepsilon,\delta)$-最优策略估计，其样本和时间复杂度为 $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$，其中$N$是状态-动作对的数量。然后，对于确定性算法的子类，我们提供了 $ \Omega\left(\frac {N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right) $ 阶的下限。接下来，我们研究了Kalavasis等人[2019]提出的可复制性的松弛版本，其中仅要求算法的输出接近复制算法的输出，而不是相同。我们提供了一种有效算法，其时间和样本复杂度为 $\widetilde O\left(\frac{N^5\cdot\log(1/\delta)}{(1-\gamma)^9\cdot\varepsilon^4\cdot\rho^2}\right)$，用于$(\varepsilon,\delta)$意义下的可复制性，这比先前与相关问题的界限更好。最后，我们讨论了我们的结果对RL算法设计和可重复性研究的未来方向的影响。

    We initiate the mathematical study of replicability as an algorithmic property in the context of reinforcement learning (RL). We focus on the fundamental setting of discounted tabular MDPs with access to a generative model. Inspired by Impagliazzo et al. [2022], we say that an RL algorithm is replicable if, with high probability, it outputs the exact same policy after two executions on i.i.d. samples drawn from the generator when its internal randomness is the same. We first provide an efficient $\rho$-replicable algorithm for $(\varepsilon, \delta)$-optimal policy estimation with sample and time complexity $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$, where $N$ is the number of state-action pairs. Next, for the subclass of deterministic algorithms, we provide a lower bound of order $\Omega\left(\frac{N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right)$. Then, we study a relaxed version of replicability proposed by Kalavasis et 
    
[^27]: 通过群表示学习对称下的字典学习

    Dictionary Learning under Symmetries via Group Representations. (arXiv:2305.19557v1 [math.OC])

    [http://arxiv.org/abs/2305.19557](http://arxiv.org/abs/2305.19557)

    本文研究在预定变换群下学习不变的字典问题。利用非阿贝尔傅里叶分析，提供了算法，建立了字典学习问题可以被有效地理解为某些矩阵优化问题的理论基础。

    

    字典学习问题可以被看作是一个数据驱动的过程，旨在学习一个合适的变换，以便通过示例数据直接表示数据的稀疏性。本文研究了在预定的变换群下学习不变的字典问题。自然的应用领域包括冷冻电镜、多目标跟踪、同步和姿态估计等。我们特别从数学表示理论的角度研究了这个问题。通过利用非阿贝尔傅里叶分析，我们为符合这些不变性的字典学习提供了算法。我们将自然界中的字典学习问题，其自然被建模为无限维度的问题，与相关的计算问题，这必然是有限维度的问题，联系起来。我们建立了字典学习问题可以被有效地理解为某些矩阵优化问题的理论基础。

    The dictionary learning problem can be viewed as a data-driven process to learn a suitable transformation so that data is sparsely represented directly from example data. In this paper, we examine the problem of learning a dictionary that is invariant under a pre-specified group of transformations. Natural settings include Cryo-EM, multi-object tracking, synchronization, pose estimation, etc. We specifically study this problem under the lens of mathematical representation theory. Leveraging the power of non-abelian Fourier analysis for functions over compact groups, we prescribe an algorithmic recipe for learning dictionaries that obey such invariances. We relate the dictionary learning problem in the physical domain, which is naturally modelled as being infinite dimensional, with the associated computational problem, which is necessarily finite dimensional. We establish that the dictionary learning problem can be effectively understood as an optimization instance over certain matrix o
    
[^28]: 基于流数据的神经网络在线学习的低秩扩展卡尔曼滤波算法

    Low-rank extended Kalman filtering for online learning of neural networks from streaming data. (arXiv:2305.19535v1 [stat.ML])

    [http://arxiv.org/abs/2305.19535](http://arxiv.org/abs/2305.19535)

    本文提出一种基于低秩扩展卡尔曼滤波的高效在线学习算法，其能够估计非线性函数的参数，具有更快的适应性和更快的奖励积累。

    

    本文提出了一种高效的在线近似贝叶斯推理算法，用于从可能非平稳的数据流中估计非线性函数的参数。该方法基于扩展卡尔曼滤波器（EKF），但使用了一种新颖的低秩加对角线的后验精度矩阵分解，其每步的成本与模型参数数量成线性关系。与基于随机变分推理的方法不同，我们的方法是完全确定的，并且不需要步长调整。我们通过实验证明，这导致更快（更高效）的学习，从而在用作上下文赌博算法的一部分时实现更快速的适应性和更快的奖励积累。

    We propose an efficient online approximate Bayesian inference algorithm for estimating the parameters of a nonlinear function from a potentially non-stationary data stream. The method is based on the extended Kalman filter (EKF), but uses a novel low-rank plus diagonal decomposition of the posterior precision matrix, which gives a cost per step which is linear in the number of model parameters. In contrast to methods based on stochastic variational inference, our method is fully deterministic, and does not require step-size tuning. We show experimentally that this results in much faster (more sample efficient) learning, which results in more rapid adaptation to changing distributions, and faster accumulation of reward when used as part of a contextual bandit algorithm.
    
[^29]: 用全息约化表示重新建模自注意力

    Recasting Self-Attention with Holographic Reduced Representations. (arXiv:2305.19534v1 [cs.LG])

    [http://arxiv.org/abs/2305.19534](http://arxiv.org/abs/2305.19534)

    本文提出了一种使用HRR的神经符号方法重新构建自注意力的方法，可以实现较低的时间和空间复杂度，并在LRA基准测试中获得了接近于最先进的准确度。

    

    近年来，自注意力已经成为各个领域序列建模的主要范例。然而，在序列长度非常长的领域中，复杂度为$\mathcal{O}(T^2)$的内存和$\mathcal{O}(T^2 \cdot H)$的计算成本可能会使得使用变形金刚网络不可行。受惊物检测中$T \geq 100,000$的序列长度成为深度学习的拦路虎的问题的启发，我们使用全息约化表示（HRR）的神经符号化方法重新构建自注意力。这样我们执行相同的高级策略，即标准自 注意力的查询匹配钥匙，返回每个键的值的加权响应。通过实现“Hrrformer”，我们获得了一些好处，包括$\mathcal{O}(T H \log H)$的时间复杂度、$\mathcal{O}(T H)$的空间复杂度和收敛于$10\times$更少的迭代次数。然而，Hrrformer在LRA基准测试中实现了接近于最先进的准确度，我们能够学习到深度模型。

    In recent years, self-attention has become the dominant paradigm for sequence modeling in a variety of domains. However, in domains with very long sequence lengths the $\mathcal{O}(T^2)$ memory and $\mathcal{O}(T^2 H)$ compute costs can make using transformers infeasible. Motivated by problems in malware detection, where sequence lengths of $T \geq 100,000$ are a roadblock to deep learning, we re-cast self-attention using the neuro-symbolic approach of Holographic Reduced Representations (HRR). In doing so we perform the same high-level strategy of the standard self-attention: a set of queries matching against a set of keys, and returning a weighted response of the values for each key. Implemented as a ``Hrrformer'' we obtain several benefits including $\mathcal{O}(T H \log H)$ time complexity, $\mathcal{O}(T H)$ space complexity, and convergence in $10\times$ fewer epochs. Nevertheless, the Hrrformer achieves near state-of-the-art accuracy on LRA benchmarks and we are able to learn wi
    
[^30]: 略微超参数化的ReLU网络具有有利的损失景观

    Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape. (arXiv:2305.19510v1 [cs.LG])

    [http://arxiv.org/abs/2305.19510](http://arxiv.org/abs/2305.19510)

    本文研究了略微超参数化的ReLU网络在有限输入数据集上的损失景观，证明了大多数激活模式对应的参数区域没有坏的可微局部极小值，对于一维输入数据，网络可以通过大多数激活模式实现高维全局极小值集合而不具有坏的局部极小值。

    

    本文研究了有限输入数据集上，二层略微超参数化ReLU神经网络的损失景观，使用了参数映射的Jacobian矩阵的秩来估计局部和全局极小值集的维度。使用随机二进制矩阵的结果，我们证明大多数激活模式对应的参数区域没有坏的可微局部极小值。此外，对于一维输入数据，我们证明了网络可以通过大多数的激活模式实现高维全局极小值集合而不具有坏的局部极小值。我们通过发现大多数区域具有完整的秩或缺乏秩，以实验的方式证实了这些结果，这取决于超参数的数量。

    We study the loss landscape of two-layer mildly overparameterized ReLU neural networks on a generic finite input dataset for the squared error loss. Our approach involves bounding the dimension of the sets of local and global minima using the rank of the Jacobian of the parameterization map. Using results on random binary matrices, we show most activation patterns correspond to parameter regions with no bad differentiable local minima. Furthermore, for one-dimensional input data, we show most activation regions realizable by the network contain a high dimensional set of global minima and no bad local minima. We experimentally confirm these results by finding a phase transition from most regions having full rank to many regions having deficient rank depending on the amount of overparameterization.
    
[^31]: 带隐私保障的自适应FDR控制

    Adaptive False Discovery Rate Control with Privacy Guarantee. (arXiv:2305.19482v1 [stat.ML])

    [http://arxiv.org/abs/2305.19482](http://arxiv.org/abs/2305.19482)

    本文提出了一种带隐私保障的自适应FDR控制方法，采用新颖的p值转换方法和镜像剥离算法，可在用户指定的水平α下确切地控制经典的FDR指标，表现更好且可减小隐私泄露风险。

    

    差分隐私的多重检验程序可在保证假阳性率的同时保护用于假设检验的个体信息。本文提出了一种差分隐私的自适应FDR控制方法，可以在用户指定的水平α下确切地控制经典的FDR指标，并提供隐私保障。我们的分析基于两个关键洞见：1）一种新颖的p值转换方法，既保护隐私，同时又保持了镜像保守特性；2）一种镜像剥离算法，允许构建过滤器，并应用最优停止技术。数值研究表明，所提出的DP-AdaPT相比现有的差分隐私FDR控制方法表现更好。与非隐私的AdaPT相比，它会产生一些精度损失，但显著地减小了隐私泄露风险。

    Differentially private multiple testing procedures can protect the information of individuals used in hypothesis tests while guaranteeing a small fraction of false discoveries. In this paper, we propose a differentially private adaptive FDR control method that can control the classic FDR metric exactly at a user-specified level $\alpha$ with privacy guarantee, which is a non-trivial improvement compared to the differentially private Benjamini-Hochberg method proposed in Dwork et al. (2021). Our analysis is based on two key insights: 1) a novel p-value transformation that preserves both privacy and the mirror conservative property, and 2) a mirror peeling algorithm that allows the construction of the filtration and application of the optimal stopping technique. Numerical studies demonstrate that the proposed DP-AdaPT performs better compared to the existing differentially private FDR control methods. Compared to the non-private AdaPT, it incurs a small accuracy loss but significantly re
    
[^32]: 对数凹马尔可夫链之链

    Chain of Log-Concave Markov Chains. (arXiv:2305.19473v1 [stat.ML])

    [http://arxiv.org/abs/2305.19473](http://arxiv.org/abs/2305.19473)

    该论文提出了一种新的采样算法，基于对数凹条件概率密度，使用等向性高斯平滑来解决高维下抽样难题。

    

    马尔科夫链蒙特卡罗（MCMC）是一种从未标准化密度中抽样的通用算法类。在高维情况下，MCMC面临两个众所周知的问题：(i)感兴趣的分布在由小概率块隔开的区域中集中;(ii)对数凹性的小概率块本身通常存在病态问题。我们引入了一种采用等向性高斯平滑来解决这些问题的框架。我们证明，无论密度函数的最小假设是什么，从密度函数中采样总是可以分解为通过等噪声测量的累积，从对数凹性条件密度中采样的序列。该构造跟踪了样本历史，因此作为一个整体而言是非马尔可夫的，但历史仅以经验均值的形式出现，从而保证了内存印迹的最小化。我们的采样算法推广了步行跳跃采样（1）。"走"阶段变成了对数凹链的(非马尔可夫)链。

    Markov chain Monte Carlo (MCMC) is a class of general-purpose algorithms for sampling from unnormalized densities. There are two well-known problems facing MCMC in high dimensions: (i) The distributions of interest are concentrated in pockets separated by large regions with small probability mass, and (ii) The log-concave pockets themselves are typically ill-conditioned. We introduce a framework to tackle these problems using isotropic Gaussian smoothing. We prove one can always decompose sampling from a density (minimal assumptions made on the density) into a sequence of sampling from log-concave conditional densities via accumulation of noisy measurements with equal noise levels. This construction keeps track of a history of samples, making it non-Markovian as a whole, but the history only shows up in the form of an empirical mean, making the memory footprint minimal. Our sampling algorithm generalizes walk-jump sampling [1]. The "walk" phase becomes a (non-Markovian) chain of log-co
    
[^33]: 用Johnson-Lindenstrauss矩阵进行标签嵌入

    Label Embedding by Johnson-Lindenstrauss Matrices. (arXiv:2305.19470v1 [cs.LG])

    [http://arxiv.org/abs/2305.19470](http://arxiv.org/abs/2305.19470)

    这篇论文提出了基于JLMs的标签嵌入方法，将多元分类问题转化为有限回归问题，具有较高的计算效率和预测准确性。

    

    我们提出了一个基于Johnson-Lindenstrauss矩阵（JLMs）的简单且可扩展的极端多元分类框架。利用JLM的列来嵌入标签，将一个C类分类问题转化为具有$\cO(\log C)$输出维度的回归问题。我们得出了一个超量风险限制，阐明了计算效率和预测准确性之间的权衡，并进一步表明，在Massart噪声条件下，降维的惩罚会消失。我们的方法易于并行化，并且实验结果展示了在大规模应用中其有效性和可扩展性。

    We present a simple and scalable framework for extreme multiclass classification based on Johnson-Lindenstrauss matrices (JLMs). Using the columns of a JLM to embed the labels, a $C$-class classification problem is transformed into a regression problem with $\cO(\log C)$ output dimension. We derive an excess risk bound, revealing a tradeoff between computational efficiency and prediction accuracy, and further show that under the Massart noise condition, the penalty for dimension reduction vanishes. Our approach is easily parallelizable, and experimental results demonstrate its effectiveness and scalability in large-scale applications.
    
[^34]: 基于树张量网络、CP秩约束和张量丢弃的机器学习方法。

    Machine learning with tree tensor networks, CP rank constraints, and tensor dropout. (arXiv:2305.19440v1 [cs.LG])

    [http://arxiv.org/abs/2305.19440](http://arxiv.org/abs/2305.19440)

    本文介绍了一种新的机器学习方法，通过基于树状张量网络的CP秩约束和张量丢弃，来构建低秩分类器，并在时尚-MNIST图像分类中展示出了优异的表现。

    

    张量网络可以通过降低自由度来近似表示$N$阶张量，并构成一系列压缩的小张量网络。在[arXiv:2205.15296]文章中，作者提出可以通过对张量网络中的张量的CP秩附加约束，进一步降低计算成本。本文旨在展示如何利用基于树状张量网络(TTN)的CP秩约束和张量丢弃的方法来进行机器学习，并表明该方法在时尚-MNIST图像分类中优于其他基于张量网络的方法。当分支系数$b=4$时，低秩TTN分类器达到了测试集准确率90.3\%，同时拥有较低的计算成本。基于线性元素构成的张量网络分类器避免了深度神经网络的梯度消失问题。CP秩约束还有其他优点：可以减少和调整模型参数数量。

    Tensor networks approximate order-$N$ tensors with a reduced number of degrees of freedom that is only polynomial in $N$ and arranged as a network of partially contracted smaller tensors. As suggested in [arXiv:2205.15296] in the context of quantum many-body physics, computation costs can be further substantially reduced by imposing constraints on the canonical polyadic (CP) rank of the tensors in such networks. Here we demonstrate how tree tensor networks (TTN) with CP rank constraints and tensor dropout can be used in machine learning. The approach is found to outperform other tensor-network based methods in Fashion-MNIST image classification. A low-rank TTN classifier with branching ratio $b=4$ reaches test set accuracy 90.3\% with low computation costs. Consisting of mostly linear elements, tensor network classifiers avoid the vanishing gradient problem of deep neural networks. The CP rank constraints have additional advantages: The number of parameters can be decreased and tuned m
    
[^35]: 缺失值下的公平性干预措施的适应性研究

    Adapting Fairness Interventions to Missing Values. (arXiv:2305.19429v1 [cs.LG])

    [http://arxiv.org/abs/2305.19429](http://arxiv.org/abs/2305.19429)

    本文研究了如何在缺失值的情况下实现公平的分类。传统方法会加剧歧视。本文证明从插补数据训练分类器会恶化组公平性和平均准确性。作者提出可扩展和适应性的算法，可以与其他公平干预算法结合使用，以处理所有可能的缺失模式。

    

    真实世界中数据的缺失值对算法公平性提出了显著而独特的挑战。不同的族群可能不会同等地受到缺失数据的影响，而处理缺失值的标准程序，即先对数据进行插补，然后使用插补的数据进行分类，这个过程被称为“插补再分类”，会加剧歧视。本文分析了缺失值如何影响算法公平性。我们首先证明了从插补数据训练分类器会显著恶化可以实现的组公平性和平均准确性的值。这是因为插补数据会导致数据缺失模式的丢失，数据缺失模式通常会传达有关预测标签的信息。我们提出了可扩展和适应性的算法，用于处理缺失值的公平分类。这些算法可以与任何现有的公平干预算法结合使用，以处理所有可能的缺失模式，并保留信息。

    Missing values in real-world data pose a significant and unique challenge to algorithmic fairness. Different demographic groups may be unequally affected by missing data, and the standard procedure for handling missing values where first data is imputed, then the imputed data is used for classification -- a procedure referred to as "impute-then-classify" -- can exacerbate discrimination. In this paper, we analyze how missing values affect algorithmic fairness. We first prove that training a classifier from imputed data can significantly worsen the achievable values of group fairness and average accuracy. This is because imputing data results in the loss of the missing pattern of the data, which often conveys information about the predictive label. We present scalable and adaptive algorithms for fair classification with missing values. These algorithms can be combined with any preexisting fairness-intervention algorithm to handle all possible missing patterns while preserving informatio
    
[^36]: In-Context Learning学习了什么以及如何学习？贝叶斯模型平均、参数化和泛化。

    What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization. (arXiv:2305.19420v1 [stat.ML])

    [http://arxiv.org/abs/2305.19420](http://arxiv.org/abs/2305.19420)

    本文对In-Context Learning进行了全面的研究，通过贝叶斯模型平均算法来隐式地实现ICL估计量，并采用在线学习的角度来分析ICL性能，建立后悔界限，并通过关注机制近似参数化。

    

    本文通过回答几个开放性问题，对In-Context Learning（ICL）进行了全面的研究：(a)在语言模型中学习的是什么类型的ICL估计量？(b)适合评估ICL的性能度量是什么，并且错误率是多少？(c)Transformer架构如何实现ICL？为了回答(a)，我们采取了贝叶斯观点，并证明ICL隐含实现了贝叶斯模型平均算法。我们证明了这个贝叶斯模型平均算法可以通过关注机制近似参数化。(b)从在线学习的角度分析ICL性能，建立一个后悔界限 $\mathcal{O}(1/T)$，其中$T$是ICL输入序列长度。(c)除了在关注中编码的贝叶斯模型平均算法，我们还表明，在涉及期间，学习模型和名义模型之间的总变分距离被一个近似误差和一个泛化误差之和所界定。

    In this paper, we conduct a comprehensive study of In-Context Learning (ICL) by addressing several open questions: (a) What type of ICL estimator is learned within language models? (b) What are suitable performance metrics to evaluate ICL accurately and what are the error rates? (c) How does the transformer architecture enable ICL? To answer (a), we take a Bayesian view and demonstrate that ICL implicitly implements the Bayesian model averaging algorithm. This Bayesian model averaging algorithm is proven to be approximately parameterized by the attention mechanism. For (b), we analyze the ICL performance from an online learning perspective and establish a regret bound $\mathcal{O}(1/T)$, where $T$ is the ICL input sequence length. To address (c), in addition to the encoded Bayesian model averaging algorithm in attention, we show that during pertaining, the total variation distance between the learned model and the nominal model is bounded by a sum of an approximation error and a genera
    
[^37]: KrADagrad：Kronecker近似-主导梯度预处理随机优化

    KrADagrad: Kronecker Approximation-Domination Gradient Preconditioned Stochastic Optimization. (arXiv:2305.19416v1 [stat.ML])

    [http://arxiv.org/abs/2305.19416](http://arxiv.org/abs/2305.19416)

    本文提出了一种名为KrAD的新的Kronecker分解预处理方法，用于降低深度学习中二阶优化器的内存和计算资源要求。通过KrADagrad方法，避免了64位精度要求，并在32位精度下表现更好。

    

    二阶随机优化器允许参数更新步长和方向适应损失曲率，但传统上对于深度学习而言需要太多的内存和计算资源。最近，Shampoo [Gupta et al.，2018]引入了Kronecker分解的预处理方法来减少这些要求： 它用于大型深度模型[Anil et al.，2020]并且在生产中[Anil et al.，2022]。 但是，它需要求解病态矩阵的逆矩阵根。这需要64位精度，会产生强硬件限制。本文中，我们提出了一种新的分解方法，即Kronecker近似-主导（KrAD）。 使用KrAD，我们更新一个矩阵，直接近似逆经验Fisher矩阵（类似于完整矩阵AdaGrad），避免求逆矩阵，因此不需要64位精度。我们随后提出KrADagrad$^\star$，其计算成本与Shampoo相似并具有相同的后悔值。在32位精度下，合成的病态实验表现优于Shampoo，同时在64位精度下实现了可比较的结果。我们为KrADagrad的收敛性提供了理论分析，并在标准深度学习基准测试中展示了其有效性。

    Second order stochastic optimizers allow parameter update step size and direction to adapt to loss curvature, but have traditionally required too much memory and compute for deep learning. Recently, Shampoo [Gupta et al., 2018] introduced a Kronecker factored preconditioner to reduce these requirements: it is used for large deep models [Anil et al., 2020] and in production [Anil et al., 2022]. However, it takes inverse matrix roots of ill-conditioned matrices. This requires 64-bit precision, imposing strong hardware constraints. In this paper, we propose a novel factorization, Kronecker Approximation-Domination (KrAD). Using KrAD, we update a matrix that directly approximates the inverse empirical Fisher matrix (like full matrix AdaGrad), avoiding inversion and hence 64-bit precision. We then propose KrADagrad$^\star$, with similar computational costs to Shampoo and the same regret. Synthetic ill-conditioned experiments show improved performance over Shampoo for 32-bit precision, while
    
[^38]: 单一生成流网络中的图结构与参数的联合贝叶斯推理

    Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network. (arXiv:2305.19366v1 [cs.LG])

    [http://arxiv.org/abs/2305.19366](http://arxiv.org/abs/2305.19366)

    本文提出了在单一生成流网络中联合建模贝叶斯网络结构和参数的方法，包括非离散样本空间，提高了贝叶斯网络局部概率模型的灵活性。

    

    生成流网络是一类对离散和结构化样本空间进行建模的生成模型。先前的研究已将其应用于推断给定观测数据的贝叶斯网络的有向无环图（DAG）的边缘后验分布。本文基于最近的研究进展，在非离散样本空间上将此框架扩展到联合后验分布的建模，不仅包括贝叶斯网络的结构，还考虑了其条件概率分布的参数。

    Generative Flow Networks (GFlowNets), a class of generative models over discrete and structured sample spaces, have been previously applied to the problem of inferring the marginal posterior distribution over the directed acyclic graph (DAG) of a Bayesian Network, given a dataset of observations. Based on recent advances extending this framework to non-discrete sample spaces, we propose in this paper to approximate the joint posterior over not only the structure of a Bayesian Network, but also the parameters of its conditional probability distributions. We use a single GFlowNet whose sampling policy follows a two-phase process: the DAG is first generated sequentially one edge at a time, and then the corresponding parameters are picked once the full structure is known. Since the parameters are included in the posterior distribution, this leaves more flexibility for the local probability models of the Bayesian Network, making our approach applicable even to non-linear models parametrized
    
[^39]: 基于随机梯度马尔科夫链蒙特卡罗的非凸贝叶斯学习

    Non-convex Bayesian Learning via Stochastic Gradient Markov Chain Monte Carlo. (arXiv:2305.19350v1 [stat.CO])

    [http://arxiv.org/abs/2305.19350](http://arxiv.org/abs/2305.19350)

    提出了一种基于随机梯度马尔科夫链蒙特卡罗的方法来解决非凸贝叶斯学习问题，具有理论保证。

    

    人工智能的兴起取决于现代深度神经网络的有效训练，这涉及到非凸优化和不确定性量化，归结为非凸贝叶斯学习问题。为了解决这个问题，本文提出了一种基于随机梯度马尔科夫链蒙特卡罗的方法，用于近似后验分布并具有理论保证。

    The rise of artificial intelligence (AI) hinges on the efficient training of modern deep neural networks (DNNs) for non-convex optimization and uncertainty quantification, which boils down to a non-convex Bayesian learning problem. A standard tool to handle the problem is Langevin Monte Carlo, which proposes to approximate the posterior distribution with theoretical guarantees. In this thesis, we start with the replica exchange Langevin Monte Carlo (also known as parallel tempering), which proposes appropriate swaps between exploration and exploitation to achieve accelerations. However, the na\"ive extension of swaps to big data problems leads to a large bias, and bias-corrected swaps are required. Such a mechanism leads to few effective swaps and insignificant accelerations. To alleviate this issue, we first propose a control variates method to reduce the variance of noisy energy estimators and show a potential to accelerate the exponential convergence. We also present the population-
    
[^40]: 关于黎曼流形上无投影在线学习的研究

    On Riemannian Projection-free Online Learning. (arXiv:2305.19349v1 [cs.LG])

    [http://arxiv.org/abs/2305.19349](http://arxiv.org/abs/2305.19349)

    本文提出了一种针对非凸约束集情况下的曲线空间在线测地凸优化的无投影算法，获得了次线性遗憾保证。

    

    投影操作是许多优化算法（例如在线梯度下降[OGD]）中强制约束和实现最优遗憾边界所必需的关键组成部分。然而，当处理高维设置或具有病态约束集时，它会受到计算复杂度限制。无投影算法通过用更有效的优化子程序取代投影预测来解决此问题。但到目前为止，这些方法主要在欧几里得设置中开发，并且虽然越来越多地关注黎曼流形上的优化，但在尝试利用无投影工具方面基本上没有工作。一个明显的问题是，在这些领域中，非平凡的仿射函数通常是非凸的。在本文中，我们提出了一种方法，在曲线空间上进行在线测地凸优化，以获得两种情况下的次线性遗憾保证：当我们访问（a）时

    The projection operation is a critical component in a wide range of optimization algorithms, such as online gradient descent (OGD), for enforcing constraints and achieving optimal regret bounds. However, it suffers from computational complexity limitations in high-dimensional settings or when dealing with ill-conditioned constraint sets. Projection-free algorithms address this issue by replacing the projection oracle with more efficient optimization subroutines. But to date, these methods have been developed primarily in the Euclidean setting, and while there has been growing interest in optimization on Riemannian manifolds, there has been essentially no work in trying to utilize projection-free tools here. An apparent issue is that non-trivial affine functions are generally non-convex in such domains. In this paper, we present methods for obtaining sub-linear regret guarantees in online geodesically convex optimization on curved spaces for two scenarios: when we have access to (a) a s
    
[^41]: 针对函数逼近的在线强化学习的一般覆盖条件的可证明优势

    Provable benefits of general coverage conditions in efficient online RL with function approximation. (arXiv:2304.12886v1 [stat.ML])

    [http://arxiv.org/abs/2304.12886](http://arxiv.org/abs/2304.12886)

    研究者对在线强化学习提出了一种新的一般覆盖条件，并发现更多的覆盖条件，提高了在线强化学习的样本效率和表现，同时阐明良好的覆盖条件仍然有益于获得最优解。

    

    在线强化学习中，与其使用马尔可夫决策过程（MDPs）的标准结构假设，使用某种覆盖条件（源自离线强化学习）足以确保样本有效保证（Xie等人，2023）。本文关注这个新方向，挖掘更多可能和更普遍的覆盖条件，并研究它们在高效在线强化学习中的潜力和用途。我们鉴定了更多概念，包括$L^p$功能集中度、密度比实现性以及部分/全覆盖条件的权衡，这些概念也有益于实现样本有效的在线强化学习，从而实现改进的遗憾边界。此外，如果利用探索性的离线数据，在我们的覆盖条件下，可以为在线强化学习实现统计和计算上高效的保证。此外，即使MDP结构已经给出，例如线性MDP，我们也阐明了良好的覆盖条件仍然有益于获得最优解。

    In online reinforcement learning (RL), instead of employing standard structural assumptions on Markov decision processes (MDPs), using a certain coverage condition (original from offline RL) is enough to ensure sample-efficient guarantees (Xie et al. 2023). In this work, we focus on this new direction by digging more possible and general coverage conditions, and study the potential and the utility of them in efficient online RL. We identify more concepts, including the $L^p$ variant of concentrability, the density ratio realizability, and trade-off on the partial/rest coverage condition, that can be also beneficial to sample-efficient online RL, achieving improved regret bound. Furthermore, if exploratory offline data are used, under our coverage conditions, both statistically and computationally efficient guarantees can be achieved for online RL. Besides, even though the MDP structure is given, e.g., linear MDP, we elucidate that, good coverage conditions are still beneficial to obtai
    
[^42]: 非拟合分数重新权重实现自适应一致性预测

    Adaptive Conformal Prediction by Reweighting Nonconformity Score. (arXiv:2303.12695v1 [stat.ML])

    [http://arxiv.org/abs/2303.12695](http://arxiv.org/abs/2303.12695)

    该论文提出了一种新方法，利用分位数回归森林来学习非拟合分数的分布，并利用其权重分配更多的重要性给残差与测试点相似的样本，从而实现更符合模型的不确定性的预测区间。

    

    尽管具有吸引人的理论保证和实际成功，但由一致性预测（CP）给出的预测区间（PI）可能无法反映给定模型的不确定性。这种限制源于CP方法对所有测试点使用常数修正，无视它们的不确定性，以确保覆盖特性。为了解决这个问题，我们提出使用分位数回归森林（QRF）来学习非拟合分数的分布，并利用QRF的权重将更多的重要性分配给残差与测试点相似的样本。这种方法导致的PI长度更符合模型的不确定性。此外，QRF学习到的权重提供了特征空间的划分，通过组合一致化可以实现更高效的计算和改进PI的适应性。我们的方法享有基于样本和基于训练条件的无假设有限覆盖率，并在适当的假设下，也可以

    Despite attractive theoretical guarantees and practical successes, Predictive Interval (PI) given by Conformal Prediction (CP) may not reflect the uncertainty of a given model. This limitation arises from CP methods using a constant correction for all test points, disregarding their individual uncertainties, to ensure coverage properties. To address this issue, we propose using a Quantile Regression Forest (QRF) to learn the distribution of nonconformity scores and utilizing the QRF's weights to assign more importance to samples with residuals similar to the test point. This approach results in PI lengths that are more aligned with the model's uncertainty. In addition, the weights learnt by the QRF provide a partition of the features space, allowing for more efficient computations and improved adaptiveness of the PI through groupwise conformalization. Our approach enjoys an assumption-free finite sample marginal and training-conditional coverage, and under suitable assumptions, it also
    
[^43]: 应用于持续图的测度统计学习

    Statistical learning on measures: an application to persistence diagrams. (arXiv:2303.08456v1 [cs.CG])

    [http://arxiv.org/abs/2303.08456](http://arxiv.org/abs/2303.08456)

    本文提出了一个新的统计学习框架，用于处理紧致空间上的测度数据，并且向我们展示了如何使用拓扑信息进行分类。

    

    我们考虑了一个二元有监督学习分类问题，其中我们观察到紧致空间 $\mathcal{X}$ 上的测度，而不是在有限维欧几里得空间中观察到数据。更具体地说，我们观察到数据 $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ ，其中 $\mu_i$ 是 $\mathcal{X}$ 上的测度， $Y_i$ 是 $0$ 或 $1$ 中的标签。对于 $\mathcal{X}$ 上的基分类器的集合 $\mathcal{F}$ ，我们在测度空间中构建相应的分类器。我们提供了这种新分类器类的 Rademacher 复杂性的上下界，它可以简单地用 $\mathcal{F}$ 类相关量来表达。如果 $\mu_i$ 是有限集上的均匀分布，那么这个分类任务就会变成一个多实例学习问题。但是，我们的方法允许我们处理更具有灵活性和多样性的输入数据。虽然这种框架有许多可能的应用，但本文强调通过拓扑数据进行分类。

    We consider a binary supervised learning classification problem where instead of having data in a finite-dimensional Euclidean space, we observe measures on a compact space $\mathcal{X}$. Formally, we observe data $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ where $\mu_i$ is a measure on $\mathcal{X}$ and $Y_i$ is a label in $\{0, 1\}$. Given a set $\mathcal{F}$ of base-classifiers on $\mathcal{X}$, we build corresponding classifiers in the space of measures. We provide upper and lower bounds on the Rademacher complexity of this new class of classifiers that can be expressed simply in terms of corresponding quantities for the class $\mathcal{F}$. If the measures $\mu_i$ are uniform over a finite set, this classification task boils down to a multi-instance learning problem. However, our approach allows more flexibility and diversity in the input data we can deal with. While such a framework has many possible applications, this work strongly emphasizes on classifying data via topological d
    
[^44]: 我们能否将Transformer应用到多种ImageNet模型的参数预测中进行扩展？

    Can We Scale Transformers to Predict Parameters of Diverse ImageNet Models?. (arXiv:2303.04143v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04143](http://arxiv.org/abs/2303.04143)

    该论文提出了一个可以预测其他神经网络高质量ImageNet参数的神经网络，通过使用预测参数进行初始化，能够提高多种ImageNet模型的训练速度，并且在转移到其他数据集时可以更快地收敛并达到竞争力的最终性能。

    

    在大规模数据集上对神经网络进行预训练已成为机器学习中的基石，但这只能由一些拥有充足资源的社区实现。我们旨在实现一个雄心勃勃的目标：民主化预训练。为此，我们训练并发布了一个单一的神经网络，可以预测其他神经网络的高质量ImageNet参数。通过使用预测参数进行初始化，我们可以提高PyTorch中可用的各种ImageNet模型的训练速度。在转移到其他数据集时，使用预测参数初始化的模型也会更快地收敛并达到竞争力的最终性能。

    Pretraining a neural network on a large dataset is becoming a cornerstone in machine learning that is within the reach of only a few communities with large-resources. We aim at an ambitious goal of democratizing pretraining. Towards that goal, we train and release a single neural network that can predict high quality ImageNet parameters of other neural networks. By using predicted parameters for initialization we are able to boost training of diverse ImageNet models available in PyTorch. When transferred to other datasets, models initialized with predicted parameters also converge faster and reach competitive final performance.
    
[^45]: 关于分层多分辨率图生成模型的研究

    On Hierarchical Multi-Resolution Graph Generative Models. (arXiv:2303.03293v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03293](http://arxiv.org/abs/2303.03293)

    本文提出一种新颖的分层多分辨率图生成模型，能递归地生成多个层次的社区结构，并符合训练数据分布。该方法由粗到细地生成图，同时具有高度的可扩展性，提升了生成性能。

    

    在现实世界中，大部分的图都具有层次结构。然而，数据驱动的图生成仍然没有有效地捕捉到这种结构。为了解决这个问题，我们提出了一种新颖的方法，以多个分辨率递归地生成社区结构，生成的结构在每个层次结构上，都符合训练数据的分布。图的生成被设计为一系列由粗到细的生成模型，允许所有子结构的并行生成，从而实现高度的可扩展性。我们的方法在多个图数据集上展示了生成性能的提升。

    In real world domains, most graphs naturally exhibit a hierarchical structure. However, data-driven graph generation is yet to effectively capture such structures. To address this, we propose a novel approach that recursively generates community structures at multiple resolutions, with the generated structures conforming to training data distribution at each level of the hierarchy. The graphs generation is designed as a sequence of coarse-to-fine generative models allowing for parallel generation of all sub-structures, resulting in a high degree of scalability. Our method demonstrates generative performance improvement on multiple graph datasets.
    
[^46]: 一种新的生成模型：一步生成且支持零样本编辑——一致性模型

    Consistency Models. (arXiv:2303.01469v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01469](http://arxiv.org/abs/2303.01469)

    提出了一种支持一步生成且支持零样本编辑的生成模型——一致性模型，它们能够通过直接将噪声映射到数据来生成高质量样本，支持快速的一步生成，且仍然支持多步抽样以提高样本质量。

    

    扩散模型在图像、音频和视频生成领域有了显著的进展，但它们依赖于一个迭代抽样过程，导致生成速度缓慢。为了克服这个限制，我们提出了一致性模型，这是一族通过直接将噪声映射到数据来生成高质量样本的新模型。它们通过设计支持快速的一步生成，同时仍允许多步抽样来以计算换取样本质量。它们还支持零样本数据编辑，如图像修复、上色和超分辨率，而无需明确训练这些任务。一致性模型可以通过蒸馏预训练的扩散模型来训练，也可以作为独立的生成模型进行训练。

    Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation. To overcome this limitation, we propose consistency models, a new family of models that generate high quality samples by directly mapping noise to data. They support fast one-step generation by design, while still allowing multistep sampling to trade compute for sample quality. They also support zero-shot data editing, such as image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either by distilling pre-trained diffusion models, or as standalone generative models altogether. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one- and few-step sampling, achieving the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet 64x64 for one-step generatio
    
[^47]: 视觉表征中风格与内容的简单分离

    Simple Disentanglement of Style and Content in Visual Representations. (arXiv:2302.09795v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09795](http://arxiv.org/abs/2302.09795)

    该论文提出了一个简单的后处理框架，用于分离学习到的表征中的内容和风格，在领域泛化中表现出显著的提升。

    

    学习具有可解释特征的视觉表征，即分离的表征，仍然是一个具有挑战性的问题。现有方法在某些情况下表现出成功，但要应用于像ImageNet这样的大规模视觉数据集则很困难。在这项工作中，我们提出了一个简单的后处理框架，用于从预训练的视觉模型中分离学习到的表征中的内容和风格。我们将预训练特征概率地建模为潜在内容和风格因素的线性综合，并基于概率模型开发了一个简单的分离算法。我们证明了该方法能够可靠地分离内容和风格特征，并在实践中验证了其有效性。我们处理后的特征在样式变化或与样式相关的虚假相关性导致分布偏移时，可以显著提高领域泛化性能。

    Learning visual representations with interpretable features, i.e., disentangled representations, remains a challenging problem. Existing methods demonstrate some success but are hard to apply to large-scale vision datasets like ImageNet. In this work, we propose a simple post-processing framework to disentangle content and style in learned representations from pre-trained vision models. We model the pre-trained features probabilistically as linearly entangled combinations of the latent content and style factors and develop a simple disentanglement algorithm based on the probabilistic model. We show that the method provably disentangles content and style features and verify its efficacy empirically. Our post-processed features yield significant domain generalization performance improvements when the distribution shift occurs due to style changes or style-related spurious correlations.
    
[^48]: 零样本批次级异常检测

    Zero-Shot Batch-Level Anomaly Detection. (arXiv:2302.07849v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07849](http://arxiv.org/abs/2302.07849)

    本文提出了一种名为“自适应中心表示”的方法，用于零样本批次级异常检测。该方法利用批量归一化来训练现成的深度异常检测器，可以自动零样本泛化为未见过的AD任务。在实验中，该方法显示出了在多种数据集上的优秀表现，对表格数据进行了零样本AD。

    

    异常检测（AD）在许多安全关键的应用领域中发挥着关键作用。适应正常数据分布漂移的异常检测器调整，特别是当没有针对“新正常”进行训练的数据时，这一挑战导致产生了零样本AD技术。在本文中，我们提出了一种名为自适应中心表示（ACR）的简单而有效的方法，用于零样本批次级AD。我们的方法使用批量归一化来训练现成的深度异常检测器（例如深度SVDD）来适应一组相互关联的训练数据分布，使其能够自动零样本泛化为未见过的AD任务。这个简单的方法，批量归一化加元训练，是一种非常有效和多功能的工具。我们的结果展示了对表格数据的第一个零样本AD结果，并在来自专业领域的图像数据的零样本异常检测和分段方面优于现有方法。

    Anomaly detection (AD) plays a crucial role in many safety-critical application domains. The challenge of adapting an anomaly detector to drift in the normal data distribution, especially when no training data is available for the "new normal," has led to the development of zero-shot AD techniques. In this paper, we propose a simple yet effective method called Adaptive Centered Representations (ACR) for zero-shot batch-level AD. Our approach trains off-the-shelf deep anomaly detectors (such as deep SVDD) to adapt to a set of inter-related training data distributions in combination with batch normalization, enabling automatic zero-shot generalization for unseen AD tasks. This simple recipe, batch normalization plus meta-training, is a highly effective and versatile tool. Our results demonstrate the first zero-shot AD results for tabular data and outperform existing methods in zero-shot anomaly detection and segmentation on image data from specialized domains.
    
[^49]: 关于使用近似传输映射进行抽样的研究

    On Sampling with Approximate Transport Maps. (arXiv:2302.04763v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.04763](http://arxiv.org/abs/2302.04763)

    本研究探讨了两种基于传输映射的抽样方法，研究结果表明，基于流的提议可以处理多峰目标，在高维度和训练不良的情况下使用依赖于重新参数化的方法更加稳健。

    

    通过将分布转化为易于处理的分布，传输映射可以简化具有非平凡几何结构的分布的抽样。随着深度神经网络参数化的传统流（NF）的发展，这种方法的潜力不断提高。NF增强采样器最近提出了将马尔可夫链蒙特卡罗方法与（i）来自流的提议绘制或（ii）基于流的重新参数化相结合。在这两种情况下，学习到的传输的质量会影响性能。本研究首次阐明了这两种方法的相对优势和劣势。我们的研究得出结论：直到中等维度，可以可靠地使用基于流的提议处理多峰目标。相比之下，在高维度和训练不良的情况下，依赖于重新参数化的方法在多模式方面存在困难，但其他方面更为稳健。

    Transport maps can ease the sampling of distributions with non-trivial geometries by transforming them into distributions that are easier to handle. The potential of this approach has risen with the development of Normalizing Flows (NF) which are maps parameterized with deep neural networks trained to push a reference distribution towards a target. NF-enhanced samplers recently proposed blend (Markov chain) Monte Carlo methods with either (i) proposal draws from the flow or (ii) a flow-based reparametrization. In both cases, the quality of the learned transport conditions performance. The present work clarifies for the first time the relative strengths and weaknesses of these two approaches. Our study concludes that multimodal targets can be reliably handled with flow-based proposals up to moderately high dimensions. In contrast, methods relying on reparametrization struggle with multimodality but are more robust otherwise in high-dimensional settings and under poor training. To furthe
    
[^50]: 通过单个固定大小RELU网络的组合来增强表达能力

    On Enhancing Expressive Power via Compositions of Single Fixed-Size ReLU Network. (arXiv:2301.12353v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12353](http://arxiv.org/abs/2301.12353)

    本文探讨了深度神经网络的表达能力，通过组合单个固定大小RELU网络，证明了其具有惊人的表达能力，尤其是在逼近具有$1-$Lipschitz连续性和一般连续性的函数时。

    

    本文探讨了深度神经网络的表达能力，通过函数组合的框架，我们证明了重复组合单个固定大小RELU网络的惊人表达能力，尽管单个网络的表达能力有限。我们进一步将此结果扩展到了$[0,1]^d$上的一般连续函数，其逼近误差由连续性模量表征。

    This paper explores the expressive power of deep neural networks through the framework of function compositions. We demonstrate that the repeated compositions of a single fixed-size ReLU network exhibit surprising expressive power, despite the limited expressive capabilities of the individual network itself. Specifically, we prove by construction that $\mathcal{L}_2\circ \boldsymbol{g}^{\circ r}\circ \boldsymbol{\mathcal{L}}_1$ can approximate $1$-Lipschitz continuous functions on $[0,1]^d$ with an error $\mathcal{O}(r^{-1/d})$, where $\boldsymbol{g}$ is realized by a fixed-size ReLU network, $\boldsymbol{\mathcal{L}}_1$ and $\mathcal{L}_2$ are two affine linear maps matching the dimensions, and $\boldsymbol{g}^{\circ r}$ denotes the $r$-times composition of $\boldsymbol{g}$. Furthermore, we extend such a result to generic continuous functions on $[0,1]^d$ with the approximation error characterized by the modulus of continuity. Our results reveal that a continuous-depth network generat
    
[^51]: 学习稀疏观测交互系统的动力学

    Learning the Dynamics of Sparsely Observed Interacting Systems. (arXiv:2301.11647v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.11647](http://arxiv.org/abs/2301.11647)

    本论文解决了学习稀疏观测交互系统的动力学问题，将其作为解的学习控制微分方程（CDE），利用签名理论将非线性问题转化为高维线性回归，具有明确的依赖于个体特定采样方案的预测误差的oracle界限。证明了该方法优于现有算法回收完整时间序列，且计算成本较低。

    

    我们解决了一个问题，即学习未知的非参数系统的动力学，该系统将目标时间序列和特征时间序列联系起来。特征时间序列在稀疏和不规则的网格上测量，而我们只能访问目标时间序列的一些点。学习后，我们可以使用这些动态将特征时间序列的前几个时间点来预测目标的值。我们将这个任务作为控制微分方程（CDE）解的学习。通过利用签名理论的丰富理论，我们能够将这个非线性问题转化为高维线性回归。我们提供了一个预测误差的oracle界限，其具有明确的依赖于个体特定采样方案的依赖。我们的理论结果通过模拟得到了证明，表明我们的方法在回收完整时间序列时优于现有算法，同时计算成本较低。我们最后展示了它在现实世界流行病学中的潜力。

    We address the problem of learning the dynamics of an unknown non-parametric system linking a target and a feature time series. The feature time series is measured on a sparse and irregular grid, while we have access to only a few points of the target time series. Once learned, we can use these dynamics to predict values of the target from the previous values of the feature time series. We frame this task as learning the solution map of a controlled differential equation (CDE). By leveraging the rich theory of signatures, we are able to cast this non-linear problem as a high-dimensional linear regression. We provide an oracle bound on the prediction error which exhibits explicit dependencies on the individual-specific sampling schemes. Our theoretical results are illustrated by simulations which show that our method outperforms existing algorithms for recovering the full time series while being computationally cheap. We conclude by demonstrating its potential on real-world epidemiologi
    
[^52]: 预测是否随意？在公平分类中评估自洽性

    Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification. (arXiv:2301.11562v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11562](http://arxiv.org/abs/2301.11562)

    在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。

    

    在公平分类中，不同经过训练的模型之间的预测方差是一个重要但鲜为人知的误差来源问题。 实证表明，某些情况下，预测的方差差异非常大，以至于决策实际上是随意的。 为了研究这个问题，我们进行了大规模的实证研究，并做出了四个总体贡献：我们1）定义了一种基于方差的度量标准，称为自洽性，在测量和减少随意性时使用； 2）开发了一种合理的算法，当预测无法做出决策时，可以放弃分类； 3）进行了迄今为止有关公平分类中方差（相对于自洽性和随意性）作用的最大规模实证研究； 4）推出了一个工具包，使美国住房抵押贷款披露法案（HMDA）数据集易于用于未来研究。 总的来说，我们的实证结果揭示了关于可重复性的令人震惊的见解。当考虑到方差和随意预测的可能性时，大多数公平分类基准接近公平。 但是，一小部分实例显示出极大的随意性水平，这表明当前的模型可能无法处理某些类型的数据。

    Variance in predictions across different trained models is a significant, under-explored source of error in fair classification. Empirically, the variance on some instances is so large that decisions can be effectively arbitrary. To study this problem, we perform a large-scale empirical study and make four overarching contributions: We 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance (vis-a-vis self-consistency and arbitrariness) in fair classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily usable for future research. Altogether, our empirical results reveal shocking insights about reproducibility. Most fairness classification benchmarks are close-to-fair when taking into
    
[^53]: 在多项选择众包中恢复前两个答案和混淆概率

    Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing. (arXiv:2301.00006v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2301.00006](http://arxiv.org/abs/2301.00006)

    该论文提出了一种多项选择众包任务的模型，该模型可以恢复最令人困惑的答案和混淆概率。在该模型下，提出了一个两阶段推断算法来推断最有可能的答案和混淆概率。

    

    众包已经成为一种标记大量数据的有效平台，具有成本和时间效益。大部分先前的工作都集中在设计一种有效的算法，仅恢复数据的真实标签。在本文中，我们考虑了多项选择众包任务，目标不仅是恢复真实标签，还包括最令人困惑的答案和混淆概率。最令人困惑的答案提供了关于任务的有用信息，揭示了除真实答案以外最可信的答案以及它的可信度。为了理论分析这样的情况，我们提出了一个模型，每个任务有两个最可信的答案，与其他选择有所不同。任务难度由前两个答案之间的混淆概率量化，工作可靠性由给出前两个答案的概率量化。在此模型下，我们提出了一个两阶段推断算法来推断前两个答案和混淆概率。

    Crowdsourcing has emerged as an effective platform for labeling large amounts of data in a cost- and time-efficient manner. Most previous work has focused on designing an efficient algorithm to recover only the ground-truth labels of the data. In this paper, we consider multi-choice crowdsourcing tasks with the goal of recovering not only the ground truth, but also the most confusing answer and the confusion probability. The most confusing answer provides useful information about the task by revealing the most plausible answer other than the ground truth and how plausible it is. To theoretically analyze such scenarios, we propose a model in which there are the top two plausible answers for each task, distinguished from the rest of the choices. Task difficulty is quantified by the probability of confusion between the top two, and worker reliability is quantified by the probability of giving an answer among the top two. Under this model, we propose a two-stage inference algorithm to infe
    
[^54]: 多目标多臂赌博机中的Pareto后悔分析

    Pareto Regret Analyses in Multi-objective Multi-armed Bandit. (arXiv:2212.00884v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.00884](http://arxiv.org/abs/2212.00884)

    本文研究了多目标多臂赌博机中的Pareto最优性，提出了对抗性多目标多臂赌博机的表述和定义了Pareto后悔，提出了新算法，分析证明算法在对抗性环境最优，在随机环境中也接近最优，并将对抗性攻击机制从赌徒推广到多目标领域。

    

    本文研究了多目标多臂赌博机中的Pareto最优性。通过提出对抗性多目标多臂赌博机的表述并定义其Pareto后悔，可以应用于随机和对抗性环境。这些后悔不依赖于任何标量化函数，并反映了与标量化后悔相比的Pareto最优性。同时，我们提出了在有和无先验信息的多目标多臂赌博机环境下的新算法。通过我们对Pareto后悔的上下界分析证明，在对抗性环境中算法是最优的，在随机环境中也接近最优。此外，下界分析表明，新的后悔与随机环境下的现有Pareto后悔一致，并将对抗性攻击机制从赌徒推广到了多目标领域。

    We study Pareto optimality in multi-objective multi-armed bandit by providing a formulation of adversarial multi-objective multi-armed bandit and defining its Pareto regrets that can be applied to both stochastic and adversarial settings. The regrets do not rely on any scalarization functions and reflect Pareto optimality compared to scalarized regrets. We also present new algorithms assuming both with and without prior information of the multi-objective multi-armed bandit setting. The algorithms are shown optimal in adversarial settings and nearly optimal up to a logarithmic factor in stochastic settings simultaneously by our established upper bounds and lower bounds on Pareto regrets. Moreover, the lower bound analyses show that the new regrets are consistent with the existing Pareto regret for stochastic settings and extend an adversarial attack mechanism from bandit to the multi-objective one.
    
[^55]: 使用Ollivier-Ricci曲率重新审视过度平滑和过度压缩问题

    Revisiting Over-smoothing and Over-squashing Using Ollivier-Ricci Curvature. (arXiv:2211.15779v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15779](http://arxiv.org/abs/2211.15779)

    研究发现图神经网络模型存在过度平滑和过度压缩问题，这一问题与图形曲率相关，作者利用Ollivier-Ricci曲率提出了Batch Ollivier-Ricci Flow算法，解决了这一问题。

    

    图神经网络(GNN)天生容易出现过度平滑和过度压缩问题。这些问题限制了GNN在进行远距离信息处理时对复杂图形相互作用建模的效力。我们的研究揭示了局部图形空间和这两个问题之间的关键联系，从而提供了一个统一的框架来使用Ollivier-Ricci曲率在局部尺度上研究它们。具体来说，我们证明过度平滑与正图曲率相联系，而过度压缩则与负图曲率相联系。基于我们的理论，我们提出了Batch Ollivier-Ricci Flow，这是一种新颖的重连算法，能够同时解决过度平滑和过度压缩问题。

    Graph Neural Networks (GNNs) had been demonstrated to be inherently susceptible to the problems of over-smoothing and over-squashing. These issues prohibit the ability of GNNs to model complex graph interactions by limiting their effectiveness in taking into account distant information. Our study reveals the key connection between the local graph geometry and the occurrence of both of these issues, thereby providing a unified framework for studying them at a local scale using the Ollivier-Ricci curvature. Specifically, we demonstrate that over-smoothing is linked to positive graph curvature while over-squashing is linked to negative graph curvature. Based on our theory, we propose the Batch Ollivier-Ricci Flow, a novel rewiring algorithm capable of simultaneously addressing both over-smoothing and over-squashing.
    
[^56]: 多尺度拓扑奇异性检测

    Topological Singularity Detection at Multiple Scales. (arXiv:2210.00069v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00069](http://arxiv.org/abs/2210.00069)

    本文提出了一种多尺度拓扑奇异性检测方法，可以评估数据的局部固有维度，并量化点的“流形度”，能够检测复杂空间和图像中的奇异性。

    

    流形假设是现代机器学习研究的一个基本假设，它假定数据位于或接近于低固有维度的未知流形上。然而，最近的研究表明，现实世界的数据表现出明显的非流形结构，即奇异性，这可能导致错误的发现。因此，检测这种奇异性在插值和推断任务之前是至关重要的。我们通过开发一个拓扑框架来解决这个问题，该框架能够（i）量化局部固有维度，以及（ii）在多个尺度上产生“欧几里得性”评分，用以评估点的“流形度”。我们的方法可以在图像数据中捕获复杂空间的奇异性，同时捕捉奇异结构和局部几何复杂性。

    The manifold hypothesis, which assumes that data lies on or close to an unknown manifold of low intrinsic dimension, is a staple of modern machine learning research. However, recent work has shown that real-world data exhibits distinct non-manifold structures, i.e. singularities, that can lead to erroneous findings. Detecting such singularities is therefore crucial as a precursor to interpolation and inference tasks. We address this issue by developing a topological framework that (i) quantifies the local intrinsic dimension, and (ii) yields a Euclidicity score for assessing the 'manifoldness' of a point along multiple scales. Our approach identifies singularities of complex spaces, while also capturing singular structures and local geometric complexity in image data.
    
[^57]: 重新思考反事实解释：作为局部和区域反事实政策的反事实解释

    Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies. (arXiv:2209.14568v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.14568](http://arxiv.org/abs/2209.14568)

    本文提出了一种概率框架，为每个观测值提供稀疏的局部反事实规则，并将这些规则聚合成区域反事实规则，以适应不稳定的实现环境，并产生稳健的救济措施。

    

    反事实解释（CE）面临着许多未解决的挑战，如确保稳定性、综合多个CE以及提供合理性和稀疏性保证。从更实际的角度来看，最近的研究表明，所规定的反事实救济措施通常不会被个体完全实施，并证明大多数最先进的CE算法在这种嘈杂的环境中很可能失败。为了解决这些问题，我们提出了一个概率框架，为每个观测值提供稀疏的局部反事实规则，提供能够以高概率改变决策的值范围的规则。这些规则作为多样的反事实解释的总结，并产生稳健的救济措施。我们进一步将这些局部规则聚合成区域反事实规则，识别数据子组的共享救济措施。我们的局部和区域规则来自于随机森林算法。

    Counterfactual Explanations (CE) face several unresolved challenges, such as ensuring stability, synthesizing multiple CEs, and providing plausibility and sparsity guarantees. From a more practical point of view, recent studies [Pawelczyk et al., 2022] show that the prescribed counterfactual recourses are often not implemented exactly by individuals and demonstrate that most state-of-the-art CE algorithms are very likely to fail in this noisy environment. To address these issues, we propose a probabilistic framework that gives a sparse local counterfactual rule for each observation, providing rules that give a range of values capable of changing decisions with high probability. These rules serve as a summary of diverse counterfactual explanations and yield robust recourses. We further aggregate these local rules into a regional counterfactual rule, identifying shared recourses for subgroups of the data. Our local and regional rules are derived from the Random Forest algorithm, which of
    
[^58]: 多维时空数据的贝叶斯互补核学习

    Bayesian Complementary Kernelized Learning for Multidimensional Spatiotemporal Data. (arXiv:2208.09978v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.09978](http://arxiv.org/abs/2208.09978)

    本文提出了一种贝叶斯互补核学习（BCKL）框架，它将核化低秩张量分解和短程时空高斯过程相结合，可有效地建模多维时空数据的复杂相关性。

    

    多维时空数据的概率建模对许多现实应用至关重要。由于现实世界中的时空数据往往表现出非平稳和非可分离的复杂依赖关系，因此开发有效且计算效率高的统计模型以适应同时包含长程和短程变化的非稳态/不可分离过程变得具有挑战性，尤其是对于具有不同破坏/缺失结构的大规模数据集。在本文中，我们提出了一种新的统计框架 - 贝叶斯互补核学习（BCKL） - 用于实现多维时空数据的可扩展概率建模。为了有效地表征复杂依赖关系，BCKL集成了两个互补方法——核低秩张量分解和短程时空高斯过程。具体而言，我们使用多线性低秩因子分解组件来捕获全局/长程相关性，并使用短程时空高斯过程来捕获局部/短程相关性。

    Probabilistic modeling of multidimensional spatiotemporal data is critical to many real-world applications. As real-world spatiotemporal data often exhibits complex dependencies that are nonstationary and nonseparable, developing effective and computationally efficient statistical models to accommodate nonstationary/nonseparable processes containing both long-range and short-scale variations becomes a challenging task, in particular for large-scale datasets with various corruption/missing structures. In this paper, we propose a new statistical framework -- Bayesian Complementary Kernelized Learning (BCKL) -to achieve scalable probabilistic modeling for multidimensional spatiotemporal data. To effectively characterize complex dependencies, BCKL integrates two complementary approaches -- kernelized low-rank tensor factorization and short-range spatiotemporal Gaussian Processes. Specifically, we use a multi-linear low-rank factorization component to capture the global/long-range correla
    
[^59]: 宽卷积神经网络能够学到什么？

    What Can Be Learnt With Wide Convolutional Neural Networks?. (arXiv:2208.01003v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.01003](http://arxiv.org/abs/2208.01003)

    本文研究在内核环境下的无限宽卷积神经网络，证明了深层CNN能够适应目标函数的空间尺度，即使数据没有局部结构，深层CNN也可以学习，只要全局结构可以被利用。

    

    理解卷积神经网络（CNN）如何高效地学习高维函数仍然是一个基本挑战。人们普遍认为，这些模型利用了自然数据（如图像）的局部和分层结构。然而，我们缺乏如此结构如何影响性能的量化理解，如泛化误差随训练样本数量的衰减速率。本文研究了在内核环境下的无限宽卷积神经网络，并展示了相应核的谱沿袭了网络的分层结构，并表征了其渐进性。然后，我们将这个结果与泛化误差界限结合起来，证明了深层CNN能够适应目标函数的空间尺度。特别是，我们发现，如果目标函数依赖于相邻输入变量的低维子集，则误差的衰减受到这些子集的有效维数的控制。相反，如果函数依赖于高维结构，则有效维数受网络宽度的影响。我们的结果表明，在过度参数化的情况下，即使数据没有局部结构，深层CNN也可以学习，只要全局结构可以被利用。

    Understanding how convolutional neural networks (CNNs) can efficiently learn high-dimensional functions remains a fundamental challenge. A popular belief is that these models harness the local and hierarchical structure of natural data such as images. Yet, we lack a quantitative understanding of how such structure affects performance, e.g., the rate of decay of the generalisation error with the number of training samples. In this paper, we study infinitely-wide deep CNNs in the kernel regime. First, we show that the spectrum of the corresponding kernel inherits the hierarchical structure of the network, and we characterise its asymptotics. Then, we use this result together with generalisation bounds to prove that deep CNNs adapt to the spatial scale of the target function. In particular, we find that if the target function depends on low-dimensional subsets of adjacent input variables, then the decay of the error is controlled by the effective dimensionality of these subsets. Conversel
    
[^60]: 基于区间传播的IBP正则化方法提高对抗训练网络的验证稳健性

    IBP Regularization for Verified Adversarial Robustness via Branch-and-Bound. (arXiv:2206.14772v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14772](http://arxiv.org/abs/2206.14772)

    本文提出了一种基于区间传播的IBP正则化算法，通过在扩大的领域上进行对抗性攻击并结合一种基于廉价区间传播的正则化项来引入网络的可验证性，从而实现对抗训练网络的验证稳健性。

    

    近期的工作尝试通过在扩大的领域上运行攻击并向目标函数中添加各种正则项来增加对抗训练网络的可验证性。然而，这些算法要么性能不佳，要么需要复杂和昂贵的分阶段训练过程，从而影响其实际应用。本文提出了一种新颖的验证训练算法IBP-R，它既简单又有效。IBP-R通过在扩大的领域上进行对抗性攻击并结合一种基于廉价区间传播的正则化项来引入网络的可验证性，从而最小化非凸验证问题与其近似之间的差距。通过利用最近的分支定界框架，我们展示了IBP-R在CIFAR-10小扰动上获得了最先进的验证稳健性-准确性平衡，同时比相关先前工作训练速度更快。此外，我们还提出了一种新的分支算法UPB。

    Recent works have tried to increase the verifiability of adversarially trained networks by running the attacks over domains larger than the original perturbations and adding various regularization terms to the objective. However, these algorithms either underperform or require complex and expensive stage-wise training procedures, hindering their practical applicability. We present IBP-R, a novel verified training algorithm that is both simple and effective. IBP-R induces network verifiability by coupling adversarial attacks on enlarged domains with a regularization term, based on inexpensive interval bound propagation, that minimizes the gap between the non-convex verification problem and its approximations. By leveraging recent branch-and-bound frameworks, we show that IBP-R obtains state-of-the-art verified robustness-accuracy trade-offs for small perturbations on CIFAR-10 while training significantly faster than relevant previous work. Additionally, we present UPB, a novel branching
    
[^61]: 通过图上的能量理解卷积

    Understanding convolution on graphs via energies. (arXiv:2206.10991v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10991](http://arxiv.org/abs/2206.10991)

    本论文结合能量的概念，证明了带对称滤波器的线性图卷积可以增强高频率，使图神经网络在同质和异质任务中表现更好。

    

    图神经网络（GNN）通常通过消息传递操作，其中节点的状态是基于其邻居收到的信息进行更新的。大多数消息传递模型都是作为图卷积进行操作的，其中特征在被传播到边缘之前通过共享的线性变换混合。在节点分类任务中，图卷积已经表现出两个限制：在heterophilic图上表现欠佳，并且过度平滑。常见的看法是，这两种现象的发生是因为这种模型表现为低通滤波器，意味着在图层间特征的Dirichlet能量会减少，导致平滑效应，最终特征不再可区分。在这项工作中，我们严谨地证明了简单的图卷积模型实际上可以增强高频率甚至引导一种我们所称的过度锐化的渐近行为，与过度平滑相反。我们通过表明对称滤波器的线性图卷积可以被解释为在图形上的能量最小化问题来做到这一点。具体而言，能量函数惩罚高能信号，有效地抑制低频，同时促进相关的高频。我们的结果表明，精心设计的图卷积模型可以在同质和异质任务上提供更好的性能。

    Graph Neural Networks (GNNs) typically operate by message-passing, where the state of a node is updated based on the information received from its neighbours. Most message-passing models act as graph convolutions, where features are mixed by a shared, linear transformation before being propagated over the edges. On node-classification tasks, graph convolutions have been shown to suffer from two limitations: poor performance on heterophilic graphs, and over-smoothing. It is common belief that both phenomena occur because such models behave as low-pass filters, meaning that the Dirichlet energy of the features decreases along the layers incurring a smoothing effect that ultimately makes features no longer distinguishable. In this work, we rigorously prove that simple graph-convolutional models can actually enhance high frequencies and even lead to an asymptotic behaviour we refer to as over-sharpening, opposite to over-smoothing. We do so by showing that linear graph convolutions with sy
    
[^62]: OmniMAE: 图片和视频上的单一模型遮蔽预训练

    OmniMAE: Single Model Masked Pretraining on Images and Videos. (arXiv:2206.08356v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.08356](http://arxiv.org/abs/2206.08356)

    该论文提出了一种基于遮蔽自编码的方法，可以在图像和视频上训练一个简单的单一Vision Transformer模型，而不需要标记数据，该模型的视觉表示可与单模态表示在基准测试上相当或更好，并且使用更简单的架构。

    

    基于Transformer的体系结构在各种视觉领域中已变得竞争力十足，其中最著名的是图像和视频。之前的工作通常是研究这些模态之间的隔离，但是具有相同的架构意味着可以为多个视觉模态训练一个单一的统一模型。之前的统一建模尝试通常使用专门为视觉任务量身定制的架构，或与单模态模型相比表现更差。在这项工作中，我们展示了遮蔽自编码可以用于在图像和视频上训练一个简单的Vision Transformer模型，而无需任何标记数据。这个单一的模型学习的视觉表示与单模态表示在图像和视频基准测试上相当或更好，同时使用更简单的架构。此外，通过删除90％的图像和95％的视频补丁，可以学习该模型，从而实现极快的大型模型架构训练。特别地，我们展示了我们的单一ViT-Hu

    Transformer-based architectures have become competitive across a variety of visual domains, most notably images and videos. While prior work studies these modalities in isolation, having a common architecture suggests that one can train a single unified model for multiple visual modalities. Prior attempts at unified modeling typically use architectures tailored for vision tasks, or obtain worse performance compared to single modality models. In this work, we show that masked autoencoding can be used to train a simple Vision Transformer on images and videos, without requiring any labeled data. This single model learns visual representations that are comparable to or better than single-modality representations on both image and video benchmarks, while using a much simpler architecture. Furthermore, this model can be learned by dropping 90% of the image and 95% of the video patches, enabling extremely fast training of huge model architectures. In particular, we show that our single ViT-Hu
    
[^63]: 自适应切片瓦砾斯坦距离的 PAC-Bayesian 光照

    Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances. (arXiv:2206.03230v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.03230](http://arxiv.org/abs/2206.03230)

    本文利用 PAC-Bayesian 理论，提出了自适应切片瓦砾斯坦距离的概括特性界限和一种基于界限的切片分布学习流程，以提高 SW 的判别度。

    

    切片瓦砾斯坦距离（SW）是瓦砾斯坦距离的一种计算有效且理论基础良好的替代方法。然而，关于其统计特性（或更准确地说，关于其相对于“切片”的分布的概括特性，超越均匀分布），文献资料极为有限。为了为这一研究方向带来新的贡献，本文利用 PAC-Bayesian 理论和一个核心观察结果：SW 可以被解释为平均风险，PAC-Bayesian 界定其特性的量。本文提供了三种结果：i）PAC-Bayesian 的概括性界限，适用于我们所称的自适应切片瓦砾斯坦距离，即相对于任意分布的切片（包括数据相关分布）定义的 SW；ii）一种基于理论界限的原则性流程，用于学习切片分布，以得到最大判别 SW；iii）我们的理论和算法的实证说明。

    The Sliced-Wasserstein distance (SW) is a computationally efficient and theoretically grounded alternative to the Wasserstein distance. Yet, the literature on its statistical properties -- or, more accurately, its generalization properties -- with respect to the distribution of slices, beyond the uniform measure, is scarce. To bring new contributions to this line of research, we leverage the PAC-Bayesian theory and a central observation that SW may be interpreted as an average risk, the quantity PAC-Bayesian bounds have been designed to characterize. We provide three types of results: i) PAC-Bayesian generalization bounds that hold on what we refer as adaptive Sliced-Wasserstein distances, i.e. SW defined with respect to arbitrary distributions of slices (among which data-dependent distributions), ii) a principled procedure to learn the distribution of slices that yields maximally discriminative SW, by optimizing our theoretical bounds, and iii) empirical illustrations of our theoretic
    
[^64]: 差分隐私优化中更快的收敛速度到静态点

    Faster Rates of Convergence to Stationary Points in Differentially Private Optimization. (arXiv:2206.00846v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00846](http://arxiv.org/abs/2206.00846)

    本文研究了在差分隐私下近似利普希茨和平滑函数的静态点问题。提供了新的高效算法和构造，分别在有限和随机情况下比现有算法更快的收敛速度。

    

    我们研究了在$(\varepsilon,\delta)$-差分隐私（DP）下，近似利普希茨和平滑函数的静态点的问题，涉及了有限和和随机情况。如果$\|\nabla F(\widehat{w})\|\leq \alpha$，则称点$\widehat{w}$是函数$F:\mathbb{R}^d\rightarrow\mathbb{R}$的$\alpha$-静态点。我们提供了一个新的高效算法，在有限和设置中找到一个$\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{2/3}\big)$的静态点，其中$n$是样本数。这优于以前最佳速率$\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$。我们还提供了一种新的构造，改进了随机优化设置中现有的速率，在该设置中，目标是找到人口风险的近似静态点。我们的构造找到了一个$\tilde{O}\big(\frac{1}{n^{1/3}} + \big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$的人口风险静态点。

    We study the problem of approximating stationary points of Lipschitz and smooth functions under $(\varepsilon,\delta)$-differential privacy (DP) in both the finite-sum and stochastic settings. A point $\widehat{w}$ is called an $\alpha$-stationary point of a function $F:\mathbb{R}^d\rightarrow\mathbb{R}$ if $\|\nabla F(\widehat{w})\|\leq \alpha$. We provide a new efficient algorithm that finds an $\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{2/3}\big)$-stationary point in the finite-sum setting, where $n$ is the number of samples. This improves on the previous best rate of $\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$. We also give a new construction that improves over the existing rates in the stochastic optimization setting, where the goal is to find approximate stationary points of the population risk. Our construction finds a $\tilde{O}\big(\frac{1}{n^{1/3}} + \big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$-stationary point of the population risk 
    
[^65]: 通过高效探索学习预测的静态调度

    Static Scheduling with Predictions Learned through Efficient Exploration. (arXiv:2205.15695v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15695](http://arxiv.org/abs/2205.15695)

    本文研究了单机作业调度的问题，提出了一种基于学习预测的静态调度算法，在类型未知的情况下实现了次线性的过剩成本，尤其在抢占式问题中表现出色，可以在不同作业类型持续时间相差很大时优于非抢占匹配。

    

    我们研究了单机作业调度，每个作业都属于决定其持续时间分布的作业类型。我们首先分析了类型特征已知的情况，然后转向两种学习情景，其中类型未知：非抢占式问题，它要求完成已启动的作业，然后才能移动到另一个作业；和抢占式问题，这里作业执行可以暂停以优先转移到另一个作业。在两种情况下，我们设计的算法相对于已知类型的性能实现了次线性的过剩成本，并证明了非抢占式情况的下限。值得注意的是，我们展示了抢占算法在不同作业类型持续时间相差很大时，理论上和通过模拟的方式可以优于非抢占匹配，在类型持续时间已知时并不存在这种现象。

    We study single-machine scheduling of jobs, each belonging to a job type that determines its duration distribution. We start by analyzing the scenario where the type characteristics are known and then move to two learning scenarios where the types are unknown: non-preemptive problems, where each started job must be completed before moving to another job; and preemptive problems, where job execution can be paused in the favor of moving to a different job. In both cases, we design algorithms that achieve sublinear excess cost, compared to the performance with known types, and prove lower bounds for the non-preemptive case. Notably, we demonstrate, both theoretically and through simulations, how preemptive algorithms can greatly outperform non-preemptive ones when the durations of different job types are far from one another, a phenomenon that does not occur when the type durations are known.
    
[^66]: 通过混合模型进行有限全局混淆的因果推断

    Causal Inference Despite Limited Global Confounding via Mixture Models. (arXiv:2112.11602v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.11602](http://arxiv.org/abs/2112.11602)

    本论文提出了一种基于混合模型的因果推断方法，通过解决混合问题和恢复概率分布，可以确定原本无法确定的因果关系。

    

    贝叶斯网络是一组$n$个随机变量（图的顶点）上的有向无环图（DAG）; 贝叶斯网络分布（BND）是在图上马尔可夫的随机变量的概率分布。这种模型的有限$k$-混合由一个更大的图形式化表示，该图具有一个额外的“隐藏”（或“潜在”）随机变量$U$，其范围为$\{1,\ldots,k\}$，并且$U$到每个其他顶点都有一个有向边。这种类型的模型在因果推断中是基本的，其中$U$模拟了多个群体的未观察到的混淆效应，使得可观察的DAG中的因果关系变得模糊不清。通过解决混合问题并恢复$U$上的联合概率分布，传统上无法确定的因果关系变得可确定。通过将其约化为更为研究的“空”图中的“乘积”情况，我们提出了第一个学习非空DAG的混合算法。

    A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random variables (the vertices); a Bayesian Network Distribution (BND) is a probability distribution on the random variables that is Markovian on the graph. A finite $k$-mixture of such models is graphically represented by a larger graph which has an additional "hidden" (or "latent") random variable $U$, ranging in $\{1,\ldots,k\}$, and a directed edge from $U$ to every other vertex. Models of this type are fundamental to causal inference, where $U$ models an unobserved confounding effect of multiple populations, obscuring the causal relationships in the observable DAG. By solving the mixture problem and recovering the joint probability distribution on $U$, traditionally unidentifiable causal relationships become identifiable. Using a reduction to the more well-studied "product" case on empty graphs, we give the first algorithm to learn mixtures of non-empty DAGs.
    
[^67]: 用核范数控制Wasserstein距离，并在压缩统计学习中应用

    Controlling Wasserstein Distances by Kernel Norms with Application to Compressive Statistical Learning. (arXiv:2112.00423v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.00423](http://arxiv.org/abs/2112.00423)

    本文提供了用MMD范数控制Wasserstein距离的条件，针对压缩统计学习提出了HLRIP属性，通过导出的新核范数提供了计算上高效的Wasserstein距离压缩统计学习保证。

    

    在许多机器学习算法中，比较概率分布是关键。最大均值差异（MMD）和Wasserstein距离是两类概率分布距离，近年来受到了广泛关注。本文建立了一些条件，使得可以通过MMD范数来控制Wasserstein距离。我们的工作受到压缩统计学习（CSL）理论的启发，这是一种资源有效的大规模学习通用框架，在其中训练数据在单个向量（称为草图）中进行总结，以捕捉与考虑的学习任务相关的信息。我们在现有的CSL结果的启发下引入了H\"older Lower Restricted Isometric Property，并展示了这种属性对于压缩统计学习具有有趣的保证。基于MMD和Wasserstein距离之间的关系，我们提供了一种基于MMD导出的新核范数的压缩统计学习保证。我们的理论为在压缩统计学习中使用Wasserstein距离的学习提供了一种计算上高效的两步算法。我们将我们的方法应用于合成和真实数据集，展示了Wasserstein距离相对于CSL中其他常用距离的实质性改进。

    Comparing probability distributions is at the crux of many machine learning algorithms. Maximum Mean Discrepancies (MMD) and Wasserstein distances are two classes of distances between probability distributions that have attracted abundant attention in past years. This paper establishes some conditions under which the Wasserstein distance can be controlled by MMD norms. Our work is motivated by the compressive statistical learning (CSL) theory, a general framework for resource-efficient large scale learning in which the training data is summarized in a single vector (called sketch) that captures the information relevant to the considered learning task. Inspired by existing results in CSL, we introduce the H\"older Lower Restricted Isometric Property and show that this property comes with interesting guarantees for compressive statistical learning. Based on the relations between the MMD and the Wasserstein distances, we provide guarantees for compressive statistical learning by introduci
    
[^68]: 面向通用和高效黑盒优化的最优统计协作

    Optimum-statistical Collaboration Towards General and Efficient Black-box Optimization. (arXiv:2106.09215v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.09215](http://arxiv.org/abs/2106.09215)

    本文提出了最优统计协作算法框架，管理优化误差通量和演化中的统计误差通量。该框架通用性强且适用于多种函数和分区族，并启发提出了一种方差自适应算法。

    

    本文中，我们针对分层赌博机式黑盒优化算法中分辨率和统计不确定性的作用进行关键阐述，引导更为通用的分析和更高效的算法设计。我们引入了最优统计协作，一种管理优化误差通量和优化过程中演化的统计误差通量相互作用的算法框架。我们提供了此框架的通用分析，而不需要指定统计误差和不确定性量化器的形式。由于其通用性，我们的框架和分析可应用于满足不同局部平滑性假设和具有不同局部最优值数量的大量函数和分区族，这比之前的作品所研究的函数类要丰富得多。该框架还启发我们提出更好的统计不确定性测量方法，因此提出了一种方差自适应算法。

    In this paper, we make the key delineation on the roles of resolution and statistical uncertainty in hierarchical bandits-based black-box optimization algorithms, guiding a more general analysis and a more efficient algorithm design. We introduce the \textit{optimum-statistical collaboration}, an algorithm framework of managing the interaction between optimization error flux and statistical error flux evolving in the optimization process. We provide a general analysis of this framework without specifying the forms of statistical error and uncertainty quantifier. Our framework and its analysis, due to their generality, can be applied to a large family of functions and partitions that satisfy different local smoothness assumptions and have different numbers of local optimums, which is much richer than the class of functions studied in prior works. Our framework also inspires us to propose a better measure of the statistical uncertainty and consequently a variance-adaptive algorithm \text
    
[^69]: 解释树模型的准确Shapley值

    Accurate Shapley Values for explaining tree-based models. (arXiv:2106.03820v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.03820](http://arxiv.org/abs/2106.03820)

    本文提出了在树模型中计算Shapley值的两种更准确的估计器，相比于现有方法可以更高效地利用树结构，并探讨了Shapley值作为局部解释的局限性。

    

    Shapley值广泛用于可解释的人工智能，但它们的估计和解释可能具有挑战性，导致不准确的推论和解释。本文提出了两种基于树结构的Shapley值估计器，利用树结构高效地计算Shapley值，比现有方法更准确。通过与最先进的算法进行模拟和比较，展示了我们方法的实际收益。最后，我们讨论了Shapley值作为局部解释的局限性。这些方法可以作为Python包使用。

    Shapley Values (SV) are widely used in explainable AI, but their estimation and interpretation can be challenging, leading to inaccurate inferences and explanations. As a starting point, we remind an invariance principle for SV and derive the correct approach for computing the SV of categorical variables that are particularly sensitive to the encoding used. In the case of tree-based models, we introduce two estimators of Shapley Values that exploit the tree structure efficiently and are more accurate than state-of-the-art methods. Simulations and comparisons are performed with state-of-the-art algorithms and show the practical gain of our approach. Finally, we discuss the limitations of Shapley Values as a local explanation. These methods are available as a Python package.
    
[^70]: 浅层神经网络带限制的随机权重有多大的能力？

    How Powerful are Shallow Neural Networks with Bandlimited Random Weights?. (arXiv:2008.08427v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2008.08427](http://arxiv.org/abs/2008.08427)

    本文研究了深度为2的带限制随机神经网络的表达能力，通过数学证明确定了当隐藏参数分布于有界域时，网络可能无法达到零逼近误差。

    

    本文探讨了深度为2的带限制随机神经网络的表达能力。随机网络是指隐藏层参数被冻结并赋予随机分配的神经网络，只有输出层参数通过损失最小化进行训练。使用随机权重的隐藏层是避免标准梯度下降学习中的非凸优化的有效方法，并已被近期深度学习理论所采用。尽管神经网络是普适逼近器的众所周知的事实，在这项研究中，我们数学上证明了当隐藏参数分布于有界域时，网络可能无法达到零逼近误差。我们特别导出了一个新的非平凡逼近误差下界。证明利用了Ridgelet分析技术，这是一种为神经网络设计的谐波分析方法。这种方法受到了经典信号处理中的基本原理的启发，特别是信号在某种限制下的采样。

    We investigate the expressive power of depth-2 bandlimited random neural networks. A random net is a neural network where the hidden layer parameters are frozen with random assignment, and only the output layer parameters are trained by loss minimization. Using random weights for a hidden layer is an effective method to avoid non-convex optimization in standard gradient descent learning. It has also been adopted in recent deep learning theories. Despite the well-known fact that a neural network is a universal approximator, in this study, we mathematically show that when hidden parameters are distributed in a bounded domain, the network may not achieve zero approximation error. In particular, we derive a new nontrivial approximation error lower bound. The proof utilizes the technique of ridgelet analysis, a harmonic analysis method designed for neural networks. This method is inspired by fundamental principles in classical signal processing, specifically the idea that signals with limit
    
[^71]: 强健风险最小化的渐近正态性

    Asymptotic normality of robust risk minimizers. (arXiv:2004.02328v4 [math.ST] UPDATED)

    [http://arxiv.org/abs/2004.02328](http://arxiv.org/abs/2004.02328)

    本文研究了强健模拟算法的渐近性质，将经验平均值替换成鲁棒均值的替代物，使得得到的估计器具有比经典方法更弱的假设条件下的渐近正态性，且对于广泛类的参数问题，强健风险最小化的最小化器以与真实风险的估计器相同的渐近速率和方差收敛。

    

    本文研究了一类可以看作经典经验风险最小化的强健模拟算法的渐近性质。这些策略基于用鲁棒均值的替代物（如均值中位数估计的版本）来替换通常的经验平均值。现在已经众所周知，由这些方法得到的估计器的过剩风险通常以比其“经典”对应物需要更弱的假设收敛为零。但是，对于估计量本身的渐近性质知之甚少，例如是否强健模拟的最大似然估计的渐近效率相同。我们采取一步措施回答这些问题，并表明对于广泛类的参数问题，适当定义的强健风险最小化的最小化器以与最小化真实风险的估计器相同的速率收敛，并且通常具有相同的渐近方差。

    This paper investigates asymptotic properties of algorithms that can be viewed as robust analogues of the classical empirical risk minimization. These strategies are based on replacing the usual empirical average by a robust proxy of the mean, such as the (version of) the median of means estimator. It is well known by now that the excess risk of resulting estimators often converges to zero at optimal rates under much weaker assumptions than those required by their ``classical'' counterparts. However, less is known about the asymptotic properties of the estimators themselves, for instance, whether robust analogues of the maximum likelihood estimators are asymptotically efficient. We make a step towards answering these questions and show that for a wide class of parametric problems, minimizers of the appropriately defined robust proxy of the risk converge to the minimizers of the true risk at the same rate, and often have the same asymptotic variance, as the estimators obtained by minimi
    

