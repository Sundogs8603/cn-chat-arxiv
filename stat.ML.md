# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Causal normalizing flows: from theory to practice.](http://arxiv.org/abs/2306.05415) | 本文研究了使用因果归一化流进行因果推论的方法，证明了在给定因果排序情况下，利用自回归归一化流可以恢复因果模型。通过实验和比较研究，证明了因果归一化流可用于解决实际问题。 |
| [^2] | [Are fairness metric scores enough to assess discrimination biases in machine learning?.](http://arxiv.org/abs/2306.05307) | 本文在机器学习算法在文本数据上对性别歧视的偏见的度量标准的局限性上进行了实验研究。 |
| [^3] | [Bayesian Optimisation of Functions on Graphs.](http://arxiv.org/abs/2306.05304) | 本论文提出了一种在通用的大规模和潜在未知图上定义函数的贝叶斯优化算法，并通过学习适当的图内核，适应目标函数行为。 |
| [^4] | [Federated Linear Contextual Bandits with User-level Differential Privacy.](http://arxiv.org/abs/2306.05275) | 本文研究了带有用户级差分隐私的联邦线性上下文强化学习模型，为CDP提出了近乎最优的联邦算法\robin，在LDP下证明了学习必须承受至少一个遗憾膨胀因子。 |
| [^5] | [Representing and Learning Functions Invariant Under Crystallographic Groups.](http://arxiv.org/abs/2306.05261) | 本研究提出了线性和非线性表达形式，用于描述具有晶体对称性的函数。线性表达形式提供了晶体对称性下的基函数，而非线性表达将轨道空间嵌入到有限维欧几里得空间中进行描述。 |
| [^6] | [Stratification of uncertainties recalibrated by isotonic regression and its impact on calibration error statistics.](http://arxiv.org/abs/2306.05180) | 本论文探讨了通过保序回归进行重新校准会引起分层不确定性问题，这可能会对基于箱式分布的校准误差统计造成重大影响。 |
| [^7] | [Conformal Prediction for Federated Uncertainty Quantification Under Label Shift.](http://arxiv.org/abs/2306.05131) | 该论文提出了一种基于分位数回归的新型联邦合规性预测方法，该方法利用重要性加权有效地解决了代理之间的标签漂移问题，并为预测集的有效覆盖和差分隐私提供了理论保证。广泛的实验结果表明，该方法优于目前的竞争对手。 |
| [^8] | [A Causal Framework for Decomposing Spurious Variations.](http://arxiv.org/abs/2306.05071) | 本论文提出了一种因果框架，用于分解伪变异，包括虚假性图表和理论框架，能够在真假相关关系上帮助区分直接效应和间接效应。 |
| [^9] | [Causal Fairness for Outcome Control.](http://arxiv.org/abs/2306.05066) | 本论文研究了一种特定的决策任务叫做结果控制，针对涉及到刑事司法、福利、临床决策以及公共卫生等多个方面，提出了因果公平的概念以及一组因果工具和技术来推断结果控制中的公平性。 |
| [^10] | [Posterior Collapse in Linear Conditional and Hierarchical Variational Autoencoders.](http://arxiv.org/abs/2306.05023) | 本文研究了高度相似的变分后验分布和先验分布之间的后验崩溃现象，特别地，通过对线性条件VAE和分层VAE进行分析，证明了这种现象是由于潜在变量层次关系不清晰而引起的。 |
| [^11] | [Entropy-based Training Methods for Scalable Neural Implicit Sampler.](http://arxiv.org/abs/2306.04952) | 本文提出了一种高效且可扩展的神经隐式采样器，并引入了KL训练法和Fisher训练法来训练它，实现了低计算成本下生成大批量样本。 |
| [^12] | [InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural Language Understanding.](http://arxiv.org/abs/2306.04933) | 本文提出了一种新的信息论框架，通过最大化提示和其他模型参数之间互信息来优化软提示调整，从而开发了更加高效、准确和稳健的软提示调整方法InfoPrompt。该方法通过两个新型损失函数，发现合适的提示初始化，并从提示令牌中学习足够的任务相关信息，同时鼓励预训练语言模型的输出表示更加关注任务相关信息。 |
| [^13] | [Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation.](http://arxiv.org/abs/2306.04924) | 本研究针对均值估计问题，探讨了在通信和本地差分隐私约束下的精确最优方法，提出了利用旋转对称的共享随机码书，并通过$k$-closest编码实现了随机旋转的单纯形$c$的精确最优。 |
| [^14] | [Unconstrained Online Learning with Unbounded Losses.](http://arxiv.org/abs/2306.04923) | 本论文提出了一种算法，可用于解决无界域和非Lipschitz损失的在线学习问题，并提供了一个遗憾的度量，以衡量该算法的性能。此外，我们还利用该算法开发了一种新的鞍点优化算法，即使在没有有意义的曲率的情况下，也能够在无界领域中收敛于对偶间隙。最后，我们提供了一种算法，在无界域和非Lipschitz损失的情况下实现了非平凡的动态遗憾，以及相匹配的下界。 |
| [^15] | [Solution of physics-based inverse problems using conditional generative adversarial networks with full gradient penalty.](http://arxiv.org/abs/2306.04895) | 本研究提出了一种新型的基于深度学习的方法，利用样本和物理学的正向模型生成训练数据，得到条件Wasserstein生成式对抗网络（cWGAN）的概率分布，可用于解决困难的概率反问题。 |
| [^16] | [A Bayesian Framework for learning governing Partial Differential Equation from Data.](http://arxiv.org/abs/2306.04894) | 本文介绍了一种采用变分贝叶斯和稀疏线性回归相结合的方法，用于从预定义的基函数字典中学习相关基本知识，并发现偏微分方程。 |
| [^17] | [Interpreting and Improving Diffusion Models Using the Euclidean Distance Function.](http://arxiv.org/abs/2306.04848) | 本文利用欧几里得距离函数解释去噪扩散模型，并提出了一种新的采样器。采样器表现出了最先进的FID得分，并能够生成高质量的样本。 |
| [^18] | [Classical Verification of Quantum Learning.](http://arxiv.org/abs/2306.04843) | 本文提出了一个经典验证量子学习的框架，以便经典客户委托学习给不可信的量子服务器，并成功解决了对仗学习奇偶性和傅里叶稀疏函数不可信量子证明的问题。 |
| [^19] | [$K$-Nearest-Neighbor Resampling for Off-Policy Evaluation in Stochastic Control.](http://arxiv.org/abs/2306.04836) | 提出了一种新颖的$K$最近邻重采样方法，用于估算历史数据中由不同策略生成的决策过程的性能，解决了离线策略评估中的反事实估计问题。 |
| [^20] | [SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States.](http://arxiv.org/abs/2306.04817) | 本文提出了一种跨状态的图形相似性驱动的模块推理框架，可以同时考虑数据中的状态间和状态内关系，并允许状态之间的会话计数和持续时间的差异。它可以提取非正交组件，并且能够识别特定状态与状态非特定模块。 |
| [^21] | [On the Joint Interaction of Models, Data, and Features.](http://arxiv.org/abs/2306.04793) | 本文提出了一种新工具--交互张量用于通过特征对模型和数据之间的交互进行经验分析，并提出了一个特征学习的概念框架，可以解释一些经验观察现象，表明深度学习可能受益于探索传统IID（独立同分布）假设之外的数据。 |
| [^22] | [Interpretable Deep Clustering.](http://arxiv.org/abs/2306.04785) | 本文提出了一种可解释的深度学习框架，通过自我监督的方式从数据点中标识信息量丰富的特征，设计了一个模型和门矩阵来预测可解释的实例和聚类级别的聚类分配，并在合成和实际数据中验证了其可靠性和可解释性。 |
| [^23] | [Invariant Causal Set Covering Machines.](http://arxiv.org/abs/2306.04777) | 本文提出了一种名为不变因果集覆盖机的算法，它避免了产生虚假关联，可以在多项式时间内识别感兴趣变量的因果父节点。 |
| [^24] | [Exploiting Observation Bias to Improve Matrix Completion.](http://arxiv.org/abs/2306.04775) | 本研究利用观测偏差来改进矩阵补全问题，提出一个简单的两阶段算法，实现了与对未观测协变量的监督学习性能相当的结果。 |
| [^25] | [Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning.](http://arxiv.org/abs/2306.04746) | 该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。 |
| [^26] | [Machine-Learning Kronecker Coefficients.](http://arxiv.org/abs/2306.04734) | 本文研究如何使用标准机器学习算法来预测 Kronecker 系数是否为零，并表明机器可以高精度地执行此二元分类任务。 |
| [^27] | [Stochastic Natural Thresholding Algorithms.](http://arxiv.org/abs/2306.04730) | 该论文提出了一种随机自然阈值算法，用于稀疏信号恢复，并扩展了现有的自然阈值法，可以提高算法的计算效率和性能。 |
| [^28] | [Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models.](http://arxiv.org/abs/2306.04675) | 系统地研究了图像生成模型的评估，发现常见的评价指标如FID等不能很好地体现扩散模型的感知真实性，建议使用SwAV特征提取器结合FID进行评估。 |
| [^29] | [On training locally adaptive CP.](http://arxiv.org/abs/2306.04648) | 本文提出了一种新的Conformal Prediction方法，使用可训练的变量变换重新定义符合度量，使得预测区间在保持边际有效的同时具有对象属性相关的大小。通过训练可最大化间隔效率。 |
| [^30] | [Compressed Sensing: A Discrete Optimization Approach.](http://arxiv.org/abs/2306.04647) | 本文中提出了一种离散优化方法来解决压缩感知问题，该方法在二次锥松弛下，可以找到最稀疏的向量，得到了可靠的最优解。 |
| [^31] | [Designing Decision Support Systems Using Counterfactual Prediction Sets.](http://arxiv.org/abs/2306.03928) | 本文提出了一种基于反事实预测集的决策支持系统设计方法，不同于传统的单一标签预测，它使用符合预测器构建预测集，并引导人类专家从中选择标签值。 |
| [^32] | [BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models.](http://arxiv.org/abs/2306.01506) | 本文提出了一种语言习得友好型基准，以检验自我监督口语语言模型在儿童词汇和句法经历中的表现，并提出了两个需要解决的挑战：文本和语音之间的差距和干净语音和野外语音之间的差距。 |
| [^33] | [An Empirical Study on Challenging Math Problem Solving with GPT-4.](http://arxiv.org/abs/2306.01337) | 本研究探索使用GPT-4解决更复杂和有挑战性的数学问题，提出了一种名为MathChat的对话式问题求解框架，并在困难高中竞赛问题上进行了评估。 |
| [^34] | [Parity Calibration.](http://arxiv.org/abs/2305.18655) | 本文介绍一种新的校准预测目标——parity校准，其考虑时间序列中未来观测值的增加或减少。我们使用在线二进制校准方法实现了parity校准，并在流行病学、天气预报和核聚变控制等领域中表明该方法的有效性。 |
| [^35] | [A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes.](http://arxiv.org/abs/2305.08841) | 本文提出了一种乐观的近端策略优化算法，用于解决带有全信息反馈的周期性对抗性线性MDP，在随机线性MDP和带有全信息的敌对线性MDP中，达到了最先进的后悔边界，并具有新颖的多批次更新机制。 |
| [^36] | [When does Metropolized Hamiltonian Monte Carlo provably outperform Metropolis-adjusted Langevin algorithm?.](http://arxiv.org/abs/2304.04724) | 本文表明，从高维平滑目标分布采样时，Metropolized Hamiltonian Monte Carlo (HMC)比Metropolis-adjusted Langevin算法（MALA）更有效。 |
| [^37] | [A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry.](http://arxiv.org/abs/2304.04095) | 本文证明了，在光滑和等周条件下，MALA的混合时间仅与Hessian矩阵的trace有关，而与其算子范数和log-concave没有关系。 |
| [^38] | [DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference.](http://arxiv.org/abs/2303.06171) | 本文提出了一种新的DP-Fast MH算法，用于大规模贝叶斯推断，具有精确、快速和隐私保护的特点。 |
| [^39] | [Polynomial Time and Private Learning of Unbounded Gaussian Mixture Models.](http://arxiv.org/abs/2303.04288) | 本文开发了一种技术，将高维高斯混合模型的私有参数估计问题降低到非私有算法，从而使现有的非私有算法能够在隐私保护的条件下使用，提供了第一个多项式时间的私有学习GMMs算法。 |
| [^40] | [Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC.](http://arxiv.org/abs/2302.11552) | 该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。 |
| [^41] | [A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization.](http://arxiv.org/abs/2302.01539) | BLiE是一种用于超参数优化的算法，只假设目标函数具有Lipschitz连续性。理论和实验证明BLiE优于现有算法，并且可以应用于搜索扩散模型的噪声调度。 |
| [^42] | [Robust online active learning.](http://arxiv.org/abs/2302.00422) | 本文提出了一种自适应方法，用于鲁棒的在线主动学习，并在受污染的数据流中证明了其性能表现优异，同时确保了稳定性并减少异常值的负面影响。 |
| [^43] | [Causal Bandits without Graph Learning.](http://arxiv.org/abs/2301.11401) | 本文针对因果图未知的情况，提出了一种在因果赌博机问题中使用原子干预找到奖励节点父节点的有效算法，并扩展至奖励节点具有多个父节点的情况。同时，还得出了算法执行期望干预次数的精确方程，并证明在特定图形条件下，该算法可以快速执行对数。 |
| [^44] | [Deep Learning Meets Sparse Regularization: A Signal Processing Perspective.](http://arxiv.org/abs/2301.09554) | 本文介绍了一个新的数学框架，恰当地表征了被训练对数据拟合的神经网络的功能属性。这个框架解释了深度神经网络的一些优秀性能、网络体系结构中跳跃连接和低秩权重矩阵的使用、稀疏在神经网络中的作用以及为什么神经网络可作为优秀的特征提取器。 |
| [^45] | [Learning to Maximize Mutual Information for Dynamic Feature Selection.](http://arxiv.org/abs/2301.00557) | 本文提出一种基于互信息的动态特征选择方法，使用摊销优化进行学习。在实验中取得了比现有方法更好效果。 |
| [^46] | [Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation.](http://arxiv.org/abs/2208.12401) | 本文提出了一种可扩展的集合编码方法UMBC，可以与任意非MBC组件相结合，同时仍满足MBC；同时提出了一种高效的MBC训练算法，可以为任何集合大小在训练和测试时都具有恒定的内存开销，给出完整集合梯度的无偏近似。 |
| [^47] | [Efficient computation of rankings from pairwise comparisons.](http://arxiv.org/abs/2207.00076) | 本文提出了一种比已有迭代算法运行速度快100倍的基于成对比较的排名高效计算方法。 |
| [^48] | [Multitask Learning and Bandits via Robust Statistics.](http://arxiv.org/abs/2112.14233) | 本研究探讨了多任务学习以及Bandits方法的健壮统计学实现，提出了一种新颖的两阶段多任务学习估计器，该估计器以一种样本高效的方式利用共享全局参数和稀疏实例特定术语的结构。 |
| [^49] | [Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for Non-Spherical Gaussian Mixtures.](http://arxiv.org/abs/2112.05445) | 本文针对具有未知均值和未知协方差的$k\geq2$的高斯组分混合物，提出了一种准多项式时间内可靠区分该混合物与纯高斯分布的算法，并且该算法仅需要在多项式下界混合重量的情况下运行。 |
| [^50] | [Unique Bispectrum Inversion for Signals with Finite Spectral/Temporal Support.](http://arxiv.org/abs/2111.06479) | 本文提出了一种独特的方法，可以从至少 $3B$ 个 bispectrum 测量结果中唯一地恢复带限信号，该方法适用于时限信号，并通过最小化非凸目标函数来进行优化。 |
| [^51] | [Attentional-Biased Stochastic Gradient Descent.](http://arxiv.org/abs/2012.06951) | 本文提出了一种名为ABSGD的简单而有效的方法，用于解决深度学习中的数据不平衡或标签噪声问题。我们为每个样本分配一个个别重要性权重，该权重系统地与数据的损失值成比例，并且可以捕捉到每个类中个别示例之间的多样性。与现有的加权方案相比，我们的方法可以减轻计算负担并在分布鲁棒优化 (DRO) 框架中解释为正则化参数。 |
| [^52] | [Causal Inference of General Treatment Effects using Neural Networks with A Diverging Number of Confounders.](http://arxiv.org/abs/2009.07055) | 本文提出了一种利用神经网络进行因果推断的方法，已经通过仿真研究验证了其可行性，可以缓解维数诅咒问题。 |

# 详细

[^1]: 因果归一化流：从理论到实践

    Causal normalizing flows: from theory to practice. (arXiv:2306.05415v1 [cs.LG])

    [http://arxiv.org/abs/2306.05415](http://arxiv.org/abs/2306.05415)

    本文研究了使用因果归一化流进行因果推论的方法，证明了在给定因果排序情况下，利用自回归归一化流可以恢复因果模型。通过实验和比较研究，证明了因果归一化流可用于解决实际问题。

    

    本文深入探讨了利用归一化流进行因果推论的应用。具体来说，我们首先利用非线性ICA的最新结果，显示出在给定因果排序的情况下，因果模型可以从观测数据中鉴别出来，并且可以使用自回归归一化流进行恢复。其次，我们分析了用于捕捉潜在因果数据生成过程的不同设计和学习选择的因果归一化流。第三，我们描述了如何在因果归一化流中实现do-operator，从而回答干预和反事实问题。最后，在我们的实验中，我们通过综合对比研究验证了我们的设计和训练选择；将因果归一化流与其他逼近因果模型的方法进行比较；并通过实证研究证明因果归一化流可用于解决现实世界中存在混合离散连续数据和因果图部分知识的问题。本文的代码可以进行访问。

    In this work, we deepen on the use of normalizing flows for causal reasoning. Specifically, we first leverage recent results on non-linear ICA to show that causal models are identifiable from observational data given a causal ordering, and thus can be recovered using autoregressive normalizing flows (NFs). Second, we analyze different design and learning choices for causal normalizing flows to capture the underlying causal data-generating process. Third, we describe how to implement the do-operator in causal NFs, and thus, how to answer interventional and counterfactual questions. Finally, in our experiments, we validate our design and training choices through a comprehensive ablation study; compare causal NFs to other approaches for approximating causal models; and empirically demonstrate that causal NFs can be used to address real-world problems, where the presence of mixed discrete-continuous data and partial knowledge on the causal graph is the norm. The code for this work can be f
    
[^2]: 机器学习中公平度指标评估歧视偏差是否足够？

    Are fairness metric scores enough to assess discrimination biases in machine learning?. (arXiv:2306.05307v1 [cs.CL])

    [http://arxiv.org/abs/2306.05307](http://arxiv.org/abs/2306.05307)

    本文在机器学习算法在文本数据上对性别歧视的偏见的度量标准的局限性上进行了实验研究。

    

    本文提出了新的实验，揭示了当前用于评估机器学习算法在文本数据上对性别歧视的偏见的度量标准的局限性。我们以Bios数据集为例，学习预测个人的职业。这种预测任务在商业自然语言处理（NLP）应用程序中很常见，例如自动工作推荐。

    This paper presents novel experiments shedding light on the shortcomings of current metrics for assessing biases of gender discrimination made by machine learning algorithms on textual data. We focus on the Bios dataset, and our learning task is to predict the occupation of individuals, based on their biography. Such prediction tasks are common in commercial Natural Language Processing (NLP) applications such as automatic job recommendations. We address an important limitation of theoretical discussions dealing with group-wise fairness metrics: they focus on large datasets, although the norm in many industrial NLP applications is to use small to reasonably large linguistic datasets for which the main practical constraint is to get a good prediction accuracy. We then question how reliable are different popular measures of bias when the size of the training set is simply sufficient to learn reasonably accurate predictions. Our experiments sample the Bios dataset and learn more than 200 m
    
[^3]: 图上函数的贝叶斯优化

    Bayesian Optimisation of Functions on Graphs. (arXiv:2306.05304v1 [cs.LG])

    [http://arxiv.org/abs/2306.05304](http://arxiv.org/abs/2306.05304)

    本论文提出了一种在通用的大规模和潜在未知图上定义函数的贝叶斯优化算法，并通过学习适当的图内核，适应目标函数行为。

    

    图结构数据的不断涌现推动了在图节点集上定义函数的优化任务。传统的图搜索算法可用于此，但它们可能样本效率低下，并且不利用关于函数值的信息；另一方面，贝叶斯优化是一类有前途的黑盒求解器，具有更高的样本效率，但它很少被应用于这样的新颖设置。为了填补这一空白，我们提出了一种新颖的贝叶斯优化框架，该框架优化在通用，大规模和潜在的未知图上定义的函数。通过学习适当的图内核，我们的框架具有适应目标函数行为的优点。局部建模方法进一步保证了我们方法的效率。在合成和真实世界图上的大量实验表明了所提出的优化框架的有效性。

    The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has been scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.
    
[^4]: 带有用户级差分隐私的联邦线性上下文强化学习

    Federated Linear Contextual Bandits with User-level Differential Privacy. (arXiv:2306.05275v1 [cs.LG])

    [http://arxiv.org/abs/2306.05275](http://arxiv.org/abs/2306.05275)

    本文研究了带有用户级差分隐私的联邦线性上下文强化学习模型，为CDP提出了近乎最优的联邦算法\robin，在LDP下证明了学习必须承受至少一个遗憾膨胀因子。

    

    本文研究了在用户级差分隐私（DP）概念下的联邦线性上下文强化学习。我们首先介绍了一个统一的联邦强化学习框架，可以适应顺序决策设置中DP的各种定义。然后在联邦强化学习框架中正式引入了用户级中心DP和本地DP，并研究了联邦线性上下文强化学习模型中学习遗憾和相应DP保证之间的基本权衡。对于CDP，我们提出了一种称为\robin的联邦算法，并通过推导在满足用户级DP时的几乎匹配的上界和下界遗憾界，证明其在客户端数量$M$和隐私预算$\varepsilon$方面是近乎最优的。对于LDP，我们获得了几个下界，表明在用户级$(\varepsilon,\delta)$-LDP下学习必须至少承受一个遗憾膨胀因子至少为{$\min\{1/\varepsilon,M\}$或$\min\{1/\sqrt{\varepsilon},\sq

    This paper studies federated linear contextual bandits under the notion of user-level differential privacy (DP). We first introduce a unified federated bandits framework that can accommodate various definitions of DP in the sequential decision-making setting. We then formally introduce user-level central DP (CDP) and local DP (LDP) in the federated bandits framework, and investigate the fundamental trade-offs between the learning regrets and the corresponding DP guarantees in a federated linear contextual bandits model. For CDP, we propose a federated algorithm termed as \robin and show that it is near-optimal in terms of the number of clients $M$ and the privacy budget $\varepsilon$ by deriving nearly-matching upper and lower regret bounds when user-level DP is satisfied. For LDP, we obtain several lower bounds, indicating that learning under user-level $(\varepsilon,\delta)$-LDP must suffer a regret blow-up factor at least {$\min\{1/\varepsilon,M\}$ or $\min\{1/\sqrt{\varepsilon},\sq
    
[^5]: 描述和学习晶体对称群下不变函数

    Representing and Learning Functions Invariant Under Crystallographic Groups. (arXiv:2306.05261v1 [stat.ML])

    [http://arxiv.org/abs/2306.05261](http://arxiv.org/abs/2306.05261)

    本研究提出了线性和非线性表达形式，用于描述具有晶体对称性的函数。线性表达形式提供了晶体对称性下的基函数，而非线性表达将轨道空间嵌入到有限维欧几里得空间中进行描述。

    

    晶体对称群描述了自然和科学中遇到的晶体和其他重复结构的对称性。本文推导出函数的线性和非线性表示形式，这些函数同时具有（1）平滑和（2）在此类群下不变的特性。线性表示将傅里叶基广义化为具有晶体对称性的基函数。我们证明了这种基函数对于每个晶体对称群都存在，对应$L_2$空间具有正交性，在纯平移群的情况下，可恢复为标准傅里叶基。非线性表示将该群的轨道空间嵌入到有限维欧几里得空间中。我们证明了每个晶体对称群都存在这样的嵌入，而且这个嵌入通过一个称为轨积流形的流形的广义化函数因子化。我们还描述了一些算法，可以根据该群的标准描述计算出傅里叶基和嵌入映射。

    Crystallographic groups describe the symmetries of crystals and other repetitive structures encountered in nature and the sciences. These groups include the wallpaper and space groups. We derive linear and nonlinear representations of functions that are (1) smooth and (2) invariant under such a group. The linear representation generalizes the Fourier basis to crystallographically invariant basis functions. We show that such a basis exists for each crystallographic group, that it is orthonormal in the relevant $L_2$ space, and recover the standard Fourier basis as a special case for pure shift groups. The nonlinear representation embeds the orbit space of the group into a finite-dimensional Euclidean space. We show that such an embedding exists for every crystallographic group, and that it factors functions through a generalization of a manifold called an orbifold. We describe algorithms that, given a standardized description of the group, compute the Fourier basis and an embedding map.
    
[^6]: 通过保序回归重新校准的不确定性分层及其对校准误差统计的影响

    Stratification of uncertainties recalibrated by isotonic regression and its impact on calibration error statistics. (arXiv:2306.05180v1 [stat.ME])

    [http://arxiv.org/abs/2306.05180](http://arxiv.org/abs/2306.05180)

    本论文探讨了通过保序回归进行重新校准会引起分层不确定性问题，这可能会对基于箱式分布的校准误差统计造成重大影响。

    

    按照保序回归的方式对机器学习回归问题的预测不确定性进行事后重校准，可能会对基于箱式分布的校准误差统计（例如ENCE）造成问题。保序回归经常产生分层不确定性，即具有相同数值的不确定性子集。将分层数据分成相等大小的箱时，将引入一个随机组分来估计基于箱式分布的校准统计量。分层数据的箱分区取决于数据的顺序，这通常是校准测试/验证集的一个不受控制的属性。用于分段的排序算法的插值方法也可能引入随机组分。我在一个示例中展示了这可能如何显着影响校准诊断。

    Abstract Post hoc recalibration of prediction uncertainties of machine learning regression problems by isotonic regression might present a problem for bin-based calibration error statistics (e.g. ENCE). Isotonic regression often produces stratified uncertainties, i.e. subsets of uncertainties with identical numerical values. Partitioning of the resulting data into equal-sized bins introduces an aleatoric component to the estimation of bin-based calibration statistics. The partitioning of stratified data into bins depends on the order of the data, which is typically an uncontrolled property of calibration test/validation sets. The tie-braking method of the ordering algorithm used for binning might also introduce an aleatoric component. I show on an example how this might significantly affect the calibration diagnostics.
    
[^7]: 面向标签漂移的联邦不确定性量化的合规性预测

    Conformal Prediction for Federated Uncertainty Quantification Under Label Shift. (arXiv:2306.05131v1 [stat.ML])

    [http://arxiv.org/abs/2306.05131](http://arxiv.org/abs/2306.05131)

    该论文提出了一种基于分位数回归的新型联邦合规性预测方法，该方法利用重要性加权有效地解决了代理之间的标签漂移问题，并为预测集的有效覆盖和差分隐私提供了理论保证。广泛的实验结果表明，该方法优于目前的竞争对手。

    

    联邦学习（FL）是一种机器学习框架，许多客户端协作训练模型，同时保持训练数据分散。尽管近年来在FL方面取得了进展，但未对不确定性量化主题（UQ）进行部分处理。在UQ方法中，合规性预测（CP）方法在最小假设下提供无分布保证。我们基于分位数回归开发了一种新的联邦合规性预测方法，并考虑了隐私约束。该方法利用重要性加权有效地解决了代理之间的标签漂移问题，并为预测集的有效覆盖和差分隐私提供了理论保证。广泛的实验证明，该方法优于目前的竞争对手。

    Federated Learning (FL) is a machine learning framework where many clients collaboratively train models while keeping the training data decentralized. Despite recent advances in FL, the uncertainty quantification topic (UQ) remains partially addressed. Among UQ methods, conformal prediction (CP) approaches provides distribution-free guarantees under minimal assumptions. We develop a new federated conformal prediction method based on quantile regression and take into account privacy constraints. This method takes advantage of importance weighting to effectively address the label shift between agents and provides theoretical guarantees for both valid coverage of the prediction sets and differential privacy. Extensive experimental studies demonstrate that this method outperforms current competitors.
    
[^8]: 分解伪变异的因果框架

    A Causal Framework for Decomposing Spurious Variations. (arXiv:2306.05071v1 [stat.ME])

    [http://arxiv.org/abs/2306.05071](http://arxiv.org/abs/2306.05071)

    本论文提出了一种因果框架，用于分解伪变异，包括虚假性图表和理论框架，能够在真假相关关系上帮助区分直接效应和间接效应。

    

    数据科学中一个根本性的挑战是解释为什么事情以特定的方式发生，或通过哪些机制某个变量$X$对另一个变量$Y$施加影响。本文提出了一种形式化工具，用于在马尔可夫和半马尔可夫系统中分解伪变异，引入了虚假性图表的概念，提出了一种理论框架，将伪效应分解为直接效应和间接效应，以识别生成这些虚假关系的基础因果机制。

    One of the fundamental challenges found throughout the data sciences is to explain why things happen in specific ways, or through which mechanisms a certain variable $X$ exerts influences over another variable $Y$. In statistics and machine learning, significant efforts have been put into developing machinery to estimate correlations across variables efficiently. In causal inference, a large body of literature is concerned with the decomposition of causal effects under the rubric of mediation analysis. However, many variations are spurious in nature, including different phenomena throughout the applied sciences. Despite the statistical power to estimate correlations and the identification power to decompose causal effects, there is still little understanding of the properties of spurious associations and how they can be decomposed in terms of the underlying causal mechanisms. In this manuscript, we develop formal tools for decomposing spurious variations in both Markovian and Semi-Mark
    
[^9]: 结果控制的因果公平性

    Causal Fairness for Outcome Control. (arXiv:2306.05066v1 [cs.AI])

    [http://arxiv.org/abs/2306.05066](http://arxiv.org/abs/2306.05066)

    本论文研究了一种特定的决策任务叫做结果控制，针对涉及到刑事司法、福利、临床决策以及公共卫生等多个方面，提出了因果公平的概念以及一组因果工具和技术来推断结果控制中的公平性。

    

    随着社会向基于人工智能的决策基础设施的过渡，越来越多的曾由人类控制的决策现在被委托给了自动化系统。尽管这样的发展使社会的各个方面更有效率，但大量的证据表明，需要非常小心地使这种自动化决策系统变得公平和公正，即考虑到诸如性别、种族和宗教等敏感属性。本文研究了一种特定的决策任务，称为结果控制，其中自动化系统旨在优化一个结果变量Y，同时保持公平和公正。对于这样一个设置的兴趣范围从与刑事司法和福利有关的干预措施，一直到临床决策和公共卫生。我们通过因果镜片首先分析了利益的概念，该概念捕捉了一个特定个体从积极决策中获得了多少好处，对照事实的公平性，捕捉了如果涉及到不同的敏感属性，问题所在，以及充分性的概念，它捕捉了需要多少干预来改善因果系统。然后，我们介绍了一组因果工具和技术来推断结果控制中的公平性。我们通过算法公平性的案例研究展示了我们的方法的有用性，其中我们控制了贷款决策过程中的不公平歧视。

    As society transitions towards an AI-based decision-making infrastructure, an ever-increasing number of decisions once under control of humans are now delegated to automated systems. Even though such developments make various parts of society more efficient, a large body of evidence suggests that a great deal of care needs to be taken to make such automated decision-making systems fair and equitable, namely, taking into account sensitive attributes such as gender, race, and religion. In this paper, we study a specific decision-making task called outcome control in which an automated system aims to optimize an outcome variable $Y$ while being fair and equitable. The interest in such a setting ranges from interventions related to criminal justice and welfare, all the way to clinical decision-making and public health. In this paper, we first analyze through causal lenses the notion of benefit, which captures how much a specific individual would benefit from a positive decision, counterfac
    
[^10]: 线性条件VAE和分层VAE中的后验崩溃现象

    Posterior Collapse in Linear Conditional and Hierarchical Variational Autoencoders. (arXiv:2306.05023v1 [stat.ML])

    [http://arxiv.org/abs/2306.05023](http://arxiv.org/abs/2306.05023)

    本文研究了高度相似的变分后验分布和先验分布之间的后验崩溃现象，特别地，通过对线性条件VAE和分层VAE进行分析，证明了这种现象是由于潜在变量层次关系不清晰而引起的。

    

    在变分自编码器（VAE）中，后验崩溃现象指的是变分后验分布与先验分布的相似度过高，导致编码器提取的潜在变量保存的输入数据信息较少，无法为解码器的数据重建过程产生有意义的表示。尽管该现象一直是VAEs性能的研究热点，但是对于后验崩溃的理论却相对薄弱，特别是在非标准的VAEs中。本文通过对两类重要而常见又较少研究的VAEs进行非平凡的理论分析，即具有两个潜在变量层次的线性条件VAE和分层VAE，提升了对后验崩溃的理论认识，证明了其成因。

    The posterior collapse phenomenon in variational autoencoders (VAEs), where the variational posterior distribution closely matches the prior distribution, can hinder the quality of the learned latent variables. As a consequence of posterior collapse, the latent variables extracted by the encoder in VAEs preserve less information from the input data and thus fail to produce meaningful representations as input to the reconstruction process in the decoder. While this phenomenon has been an actively addressed topic related to VAEs performance, the theory for posterior collapse remains underdeveloped, especially beyond the standard VAEs. In this work, we advance the theoretical understanding of posterior collapse to two important and prevalent yet less studied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically, via a non-trivial theoretical analysis of linear conditional VAEs and hierarchical VAEs with two levels of latent, we prove that the cause of posterior collapses i
    
[^11]: 基于熵的训练方法用于可扩展的神经隐式采样器

    Entropy-based Training Methods for Scalable Neural Implicit Sampler. (arXiv:2306.04952v1 [stat.ML])

    [http://arxiv.org/abs/2306.04952](http://arxiv.org/abs/2306.04952)

    本文提出了一种高效且可扩展的神经隐式采样器，并引入了KL训练法和Fisher训练法来训练它，实现了低计算成本下生成大批量样本。

    

    高效地从非标准目标分布中采样是科学计算和机器学习中的一个基本问题。传统方法如马尔科夫蒙特卡洛（MCMC）可保证从这些分布中渐进无偏采样，但在处理高维目标时计算效率低下，需要多次迭代生成一批样本。本文提出了一种高效且可扩展的神经隐式采样器，通过利用直接将易于采样的潜在向量映射到目标样本的神经变换，可以在低计算成本下生成大批量样本。为了训练神经隐式采样器，我们引入了两种新方法：KL训练法和Fisher训练法。前者最小化Kullback-Leibler散度，而后者则最小化Fisher散度。

    Efficiently sampling from un-normalized target distributions is a fundamental problem in scientific computing and machine learning. Traditional approaches like Markov Chain Monte Carlo (MCMC) guarantee asymptotically unbiased samples from such distributions but suffer from computational inefficiency, particularly when dealing with high-dimensional targets, as they require numerous iterations to generate a batch of samples. In this paper, we propose an efficient and scalable neural implicit sampler that overcomes these limitations. Our sampler can generate large batches of samples with low computational costs by leveraging a neural transformation that directly maps easily sampled latent vectors to target samples without the need for iterative procedures. To train the neural implicit sampler, we introduce two novel methods: the KL training method and the Fisher training method. The former minimizes the Kullback-Leibler divergence, while the latter minimizes the Fisher divergence. By empl
    
[^12]: InfoPrompt：用信息论软提示调整自然语言理解的方法

    InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural Language Understanding. (arXiv:2306.04933v1 [cs.CL])

    [http://arxiv.org/abs/2306.04933](http://arxiv.org/abs/2306.04933)

    本文提出了一种新的信息论框架，通过最大化提示和其他模型参数之间互信息来优化软提示调整，从而开发了更加高效、准确和稳健的软提示调整方法InfoPrompt。该方法通过两个新型损失函数，发现合适的提示初始化，并从提示令牌中学习足够的任务相关信息，同时鼓励预训练语言模型的输出表示更加关注任务相关信息。

    

    软提示调整在广泛的少样本任务中取得了卓越的性能。但是，提示调整的性能对初始化的提示非常敏感。本文发现，传统的提示调整方法不能从提示令牌中编码和学习足够的任务相关信息。我们开发了一种信息论框架，将软提示调整形式化为最大化提示和其他模型参数（或编码表示）之间互信息的优化问题。这种新颖的观点有助于我们开发一个更高效、准确和稳健的软提示调整方法InfoPrompt。在这个框架下，我们开发了两个基于互信息的新型损失函数，用于（i）发现下游任务的合适提示初始化，并从提示令牌中学习足够的任务相关信息，（ii）鼓励预训练语言模型的输出表示更加关注任务相关信息。

    Soft prompt tuning achieves superior performances across a wide range of few-shot tasks. However, the performances of prompt tuning can be highly sensitive to the initialization of the prompts. We also empirically observe that conventional prompt tuning methods cannot encode and learn sufficient task-relevant information from prompt tokens. In this work, we develop an information-theoretic framework that formulates soft prompt tuning as maximizing mutual information between prompts and other model parameters (or encoded representations). This novel view helps us to develop a more efficient, accurate and robust soft prompt tuning method InfoPrompt. With this framework, we develop two novel mutual information based loss functions, to (i) discover proper prompt initialization for the downstream tasks and learn sufficient task-relevant information from prompt tokens and (ii) encourage the output representation from the pretrained language model to be more aware of the task-relevant informa
    
[^13]: 分布式均值估计中的通信隐私效用权衡的精确最优性研究

    Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation. (arXiv:2306.04924v1 [cs.LG])

    [http://arxiv.org/abs/2306.04924](http://arxiv.org/abs/2306.04924)

    本研究针对均值估计问题，探讨了在通信和本地差分隐私约束下的精确最优方法，提出了利用旋转对称的共享随机码书，并通过$k$-closest编码实现了随机旋转的单纯形$c$的精确最优。

    

    本文研究了在通信和本地差分隐私约束下的均值估计问题。虽然以前的研究已经提出了相同问题的\emph{阶}-最优算法（即当我们花费更多比特时渐进最优），但在非渐进设置下仍然没有实现\emph{精确}最优性。在本文中，我们迈出了一步，描述了在共享随机性存在的情况下的\emph{精确}-最优方法，并确定了几个\emph{精确}最优的必要条件。我们证明了其中一个必要条件是利用旋转对称的共享随机码书。基于此，我们提出了一种随机化机制，其中码书是随机旋转的单纯形——满足\emph{精确}-最优码书的必要属性。该机制基于我们证明的$k$最近编码，对于随机旋转的单纯形$c$来说是\emph{精确}-最优的。

    We study the mean estimation problem under communication and local differential privacy constraints. While previous work has proposed \emph{order}-optimal algorithms for the same problem (i.e., asymptotically optimal as we spend more bits), \emph{exact} optimality (in the non-asymptotic setting) still has not been achieved. In this work, we take a step towards characterizing the \emph{exact}-optimal approach in the presence of shared randomness (a random variable shared between the server and the user) and identify several necessary conditions for \emph{exact} optimality. We prove that one of the necessary conditions is to utilize a rotationally symmetric shared random codebook. Based on this, we propose a randomization mechanism where the codebook is a randomly rotated simplex -- satisfying the necessary properties of the \emph{exact}-optimal codebook. The proposed mechanism is based on a $k$-closest encoding which we prove to be \emph{exact}-optimal for the randomly rotated simplex c
    
[^14]: 无约束在线学习和无界损失的算法

    Unconstrained Online Learning with Unbounded Losses. (arXiv:2306.04923v1 [cs.LG])

    [http://arxiv.org/abs/2306.04923](http://arxiv.org/abs/2306.04923)

    本论文提出了一种算法，可用于解决无界域和非Lipschitz损失的在线学习问题，并提供了一个遗憾的度量，以衡量该算法的性能。此外，我们还利用该算法开发了一种新的鞍点优化算法，即使在没有有意义的曲率的情况下，也能够在无界领域中收敛于对偶间隙。最后，我们提供了一种算法，在无界域和非Lipschitz损失的情况下实现了非平凡的动态遗憾，以及相匹配的下界。

    

    在线学习算法通常需要一个或多个有界性假设：即域是有界的，损失是Lipschitz的或两者都有。在本文中，我们为具有无界域和非Lipschitz损失的在线学习开发了一个新的设置。针对该场景，我们提供了一种算法，可以保证在任何满足子梯度满足$\|g_{t}\|\le G+L\|w_{t}\|$的问题中，其遗憾的度量值$R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$，并且表明除非有进一步 假设，否则该界限是不能进一步改进的。

    Algorithms for online learning typically require one or more boundedness assumptions: that the domain is bounded, that the losses are Lipschitz, or both. In this paper, we develop a new setting for online learning with unbounded domains and non-Lipschitz losses. For this setting we provide an algorithm which guarantees $R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$ regret on any problem where the subgradients satisfy $\|g_{t}\|\le G+L\|w_{t}\|$, and show that this bound is unimprovable without further assumptions. We leverage this algorithm to develop new saddle-point optimization algorithms that converge in duality gap in unbounded domains, even in the absence of meaningful curvature. Finally, we provide the first algorithm achieving non-trivial dynamic regret in an unbounded domain for non-Lipschitz losses, as well as a matching lower bound. The regret of our dynamic regret algorithm automatically improves to a novel $L^{*}$ bound when the losses are smooth.
    
[^15]: 使用带有全梯度惩罚的条件生成式对抗网络解决基于物理反问题。

    Solution of physics-based inverse problems using conditional generative adversarial networks with full gradient penalty. (arXiv:2306.04895v1 [stat.ML])

    [http://arxiv.org/abs/2306.04895](http://arxiv.org/abs/2306.04895)

    本研究提出了一种新型的基于深度学习的方法，利用样本和物理学的正向模型生成训练数据，得到条件Wasserstein生成式对抗网络（cWGAN）的概率分布，可用于解决困难的概率反问题。

    

    解决概率反问题是一项具有挑战性的任务，特别是当推断向量的维度很大且其先验信息是由一组样本组成时。本研究提出了一种基于深度学习的新方法，应用于解决这类问题。该方法利用从先验分布中绘制的推断向量样本和基于物理的正向模型来生成条件Wasserstein生成式对抗网络（cWGAN）的训练数据。cWGAN学习给定测量的推断向量的概率分布，并生成来自该分布的样本。本文所开发的cWGAN与早期版本不同之处在于其评论家必须在推断向量和测量向量方面都是1-Lipschitz。这导致了一个带有全梯度惩罚的损失项。

    The solution of probabilistic inverse problems for which the corresponding forward problem is constrained by physical principles is challenging. This is especially true if the dimension of the inferred vector is large and the prior information about it is in the form of a collection of samples. In this work, a novel deep learning based approach is developed and applied to solving these types of problems. The approach utilizes samples of the inferred vector drawn from the prior distribution and a physics-based forward model to generate training data for a conditional Wasserstein generative adversarial network (cWGAN). The cWGAN learns the probability distribution for the inferred vector conditioned on the measurement and produces samples from this distribution. The cWGAN developed in this work differs from earlier versions in that its critic is required to be 1-Lipschitz with respect to both the inferred and the measurement vectors and not just the former. This leads to a loss term with
    
[^16]: 一种用于从数据学习控制偏微分方程的贝叶斯框架

    A Bayesian Framework for learning governing Partial Differential Equation from Data. (arXiv:2306.04894v1 [stat.ML])

    [http://arxiv.org/abs/2306.04894](http://arxiv.org/abs/2306.04894)

    本文介绍了一种采用变分贝叶斯和稀疏线性回归相结合的方法，用于从预定义的基函数字典中学习相关基本知识，并发现偏微分方程。

    

    发现偏微分方程（PDE）是一项既涉及理论又涉及实证方法的挑战性任务。虽然机器学习方法已经被用来解决此问题，但是现有方法常常在存在噪声的情况下难以准确地识别潜在的方程式。在本研究中，我们提出了一种结合变分贝叶斯和稀疏线性回归的发现PDE的新方法。PDE发现问题被视为从预定义基函数字典中学习相关基础的问题。为了加速整个过程，提出了一种基于变分贝叶斯的方法来发现偏微分方程。为了确保稀疏性，我们采用了针尖和板条先验。我们在包括Burgers、Korteweg-de Vries、Kuramoto Sivashinsky、波动方程和热方程（1D和2D）在内的几个示例中展示了我们策略的功效。我们的方法提供了一种有希望的途径。

    The discovery of partial differential equations (PDEs) is a challenging task that involves both theoretical and empirical methods. Machine learning approaches have been developed and used to solve this problem; however, it is important to note that existing methods often struggle to identify the underlying equation accurately in the presence of noise. In this study, we present a new approach to discovering PDEs by combining variational Bayes and sparse linear regression. The problem of PDE discovery has been posed as a problem to learn relevant basis from a predefined dictionary of basis functions. To accelerate the overall process, a variational Bayes-based approach for discovering partial differential equations is proposed. To ensure sparsity, we employ a spike and slab prior. We illustrate the efficacy of our strategy in several examples, including Burgers, Korteweg-de Vries, Kuramoto Sivashinsky, wave equation, and heat equation (1D as well as 2D). Our method offers a promising ave
    
[^17]: 利用欧几里得距离函数解释和改进扩散模型

    Interpreting and Improving Diffusion Models Using the Euclidean Distance Function. (arXiv:2306.04848v1 [cs.LG])

    [http://arxiv.org/abs/2306.04848](http://arxiv.org/abs/2306.04848)

    本文利用欧几里得距离函数解释去噪扩散模型，并提出了一种新的采样器。采样器表现出了最先进的FID得分，并能够生成高质量的样本。

    

    去噪直觉上与投影有关。事实上，在流形假设下，添加随机噪声近似等价于正交扰动。因此，学习去噪近似于学习投影。本文利用这一观察结果，将去噪扩散模型解释为应用于欧几里得距离函数的近似梯度下降。随后，我们基于对去噪器投影误差的简单假设，提供DDIM（Denoising Diffusion Implicit Models）采样器的简单收敛分析。最后，我们基于理论结果的洞见提出一种基于对DDIM的两个简单修改的新采样器。仅需要5-10个函数评估，我们的采样器就能在预训练的CIFAR-10和CelebA模型上达到最先进的FID得分，并且可以在潜在扩散模型上生成高质量的样本。

    Denoising is intuitively related to projection. Indeed, under the manifold hypothesis, adding random noise is approximately equivalent to orthogonal perturbation. Hence, learning to denoise is approximately learning to project. In this paper, we use this observation to reinterpret denoising diffusion models as approximate gradient descent applied to the Euclidean distance function. We then provide straight-forward convergence analysis of the DDIM sampler under simple assumptions on the projection-error of the denoiser. Finally, we propose a new sampler based on two simple modifications to DDIM using insights from our theoretical results. In as few as 5-10 function evaluations, our sampler achieves state-of-the-art FID scores on pretrained CIFAR-10 and CelebA models and can generate high quality samples on latent diffusion models.
    
[^18]: 量子学习的经典验证

    Classical Verification of Quantum Learning. (arXiv:2306.04843v1 [quant-ph])

    [http://arxiv.org/abs/2306.04843](http://arxiv.org/abs/2306.04843)

    本文提出了一个经典验证量子学习的框架，以便经典客户委托学习给不可信的量子服务器，并成功解决了对仗学习奇偶性和傅里叶稀疏函数不可信量子证明的问题。

    

    量子数据访问和量子处理可以使某些经典难以处理的学习任务变得可行。然而，量子能力在不久的将来只能提供给少数人使用。因此，需要可靠的方案，允许经典客户委托学习给不可信的量子服务器，以促进广泛获得量子学习的优势。本文基于最近引入的古典机器学习交互证明系统框架，构建了一个经典验证量子学习的框架。我们展示了一些经典学习者无法自行高效求解的学习问题，但当与不可信的量子证明者交互时，他们可以高效且可靠地解决这些问题。具体而言，我们考虑了关于具有均匀输入边缘密度的对仗学习奇偶性和傅里叶稀疏函数的问题。我们提出了一个新的量子数据访问模型，称为“叠加混合量子样例”。

    Quantum data access and quantum processing can make certain classically intractable learning tasks feasible. However, quantum capabilities will only be available to a select few in the near future. Thus, reliable schemes that allow classical clients to delegate learning to untrusted quantum servers are required to facilitate widespread access to quantum learning advantages. Building on a recently introduced framework of interactive proof systems for classical machine learning, we develop a framework for classical verification of quantum learning. We exhibit learning problems that a classical learner cannot efficiently solve on their own, but that they can efficiently and reliably solve when interacting with an untrusted quantum prover. Concretely, we consider the problems of agnostic learning parities and Fourier-sparse functions with respect to distributions with uniform input marginal. We propose a new quantum data access model that we call "mixture-of-superpositions" quantum example
    
[^19]: $K$最近邻重采样用于随机控制中的离线策略评估

    $K$-Nearest-Neighbor Resampling for Off-Policy Evaluation in Stochastic Control. (arXiv:2306.04836v1 [stat.ML])

    [http://arxiv.org/abs/2306.04836](http://arxiv.org/abs/2306.04836)

    提出了一种新颖的$K$最近邻重采样方法，用于估算历史数据中由不同策略生成的决策过程的性能，解决了离线策略评估中的反事实估计问题。

    

    本文提出了一种新颖的$K$最近邻重采样方法，用于估算历史数据中由不同策略生成的决策过程的性能。我们专注于依赖于当前状态的反馈策略，这种策略适用于具有连续状态-动作空间和所选动作影响下的系统固有随机性的环境。这些设置在许多高风险应用程序中很常见，并在随机控制的上下文中积极研究。我们的过程利用了类似的状态/动作对（在度量意义下）与类似的奖励和状态转换相关。这使得我们的重采样过程通过类似于蒙特卡罗方法的轨迹模拟来解决离线策略评估（OPE）中的反事实估计问题。与其他OPE方法相比，我们的算法不需要优化，可以通过基于树的最近邻搜索高效实现，并且本质上是可并行化的。我们提供理论性能保证，并在基准环境下展示了我们算法的优越实验性能。

    We propose a novel $K$-nearest neighbor resampling procedure for estimating the performance of a policy from historical data containing realized episodes of a decision process generated under a different policy. We focus on feedback policies that depend deterministically on the current state in environments with continuous state-action spaces and system-inherent stochasticity effected by chosen actions. Such settings are common in a wide range of high-stake applications and are actively investigated in the context of stochastic control. Our procedure exploits that similar state/action pairs (in a metric sense) are associated with similar rewards and state transitions. This enables our resampling procedure to tackle the counterfactual estimation problem underlying off-policy evaluation (OPE) by simulating trajectories similarly to Monte Carlo methods. Compared to other OPE methods, our algorithm does not require optimization, can be efficiently implemented via tree-based nearest neighbo
    
[^20]: SiBBlInGS: 使用跨状态的图形相似性驱动模块推理的建模块方法

    SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States. (arXiv:2306.04817v1 [stat.ML])

    [http://arxiv.org/abs/2306.04817](http://arxiv.org/abs/2306.04817)

    本文提出了一种跨状态的图形相似性驱动的模块推理框架，可以同时考虑数据中的状态间和状态内关系，并允许状态之间的会话计数和持续时间的差异。它可以提取非正交组件，并且能够识别特定状态与状态非特定模块。

    

    对于多维时间序列来说，提取有意义的模块是发现复杂系统中有价值见解的关键。本文提出了一种基于图形相似性驱动的模块推理框架(SiBBlInGS)，用于发现模块，同时考虑到数据中的状态间和状态内关系，能够提取非正交组件，并允许状态之间的会话计数和持续时间差异。此外，SiBBlInGS还允许跨状态变化模块结构和每次试验的时间变异，并可识别特定状态与状态非特定模块。

    Interpretable methods for extracting meaningful building blocks (BBs) underlying multi-dimensional time series are vital for discovering valuable insights in complex systems. Existing techniques, however, encounter limitations that restrict their applicability to real-world systems, like reliance on orthogonality assumptions, inadequate incorporation of inter- and intra-state variability, and incapability to handle sessions of varying duration. Here, we present a framework for Similarity-driven Building Block Inference using Graphs across States (SiBBlInGS). SiBBlInGS employs a graph-based dictionary learning approach for BB discovery, simultaneously considers both inter- and intra-state relationships in the data, can extract non-orthogonal components, and allows for variations in session counts and duration across states. Additionally, SiBBlInGS allows for cross-state variations in BB structure and per-trial temporal variability, can identify state-specific vs state-invariant BBs, and
    
[^21]: 论模型、数据和特征的联合交互

    On the Joint Interaction of Models, Data, and Features. (arXiv:2306.04793v1 [cs.LG])

    [http://arxiv.org/abs/2306.04793](http://arxiv.org/abs/2306.04793)

    本文提出了一种新工具--交互张量用于通过特征对模型和数据之间的交互进行经验分析，并提出了一个特征学习的概念框架，可以解释一些经验观察现象，表明深度学习可能受益于探索传统IID（独立同分布）假设之外的数据。

    

    从数据中学习特征是深度学习的一个定义性特征，但是我们对于特征在深度学习中所起的作用的理解仍然很有限。为了弥补这一空白，我们引入了一种新工具，交互张量，用于通过特征对模型和数据之间的交互进行经验分析。通过交互张量，我们对特征在数据中的分布以及不同随机种子的模型学习不同特征等方面做出了几个关键观察。基于这些观察结果，我们提出了一个特征学习的概念框架。在这个框架下，可以通过闭式形式推导出单个假设的期望准确率和一对假设的一致性。我们证明了所提出的框架可以解释一些经验观察现象，包括最近发现的广义化不同等式（GDE），它可以使用仅无标签数据来估计泛化误差。此外，我们的理论表明，深度学习可能受益于探索传统IID（独立同分布）假设之外的数据。

    Learning features from data is one of the defining characteristics of deep learning, but our theoretical understanding of the role features play in deep learning is still rudimentary. To address this gap, we introduce a new tool, the interaction tensor, for empirically analyzing the interaction between data and model through features. With the interaction tensor, we make several key observations about how features are distributed in data and how models with different random seeds learn different features. Based on these observations, we propose a conceptual framework for feature learning. Under this framework, the expected accuracy for a single hypothesis and agreement for a pair of hypotheses can both be derived in closed-form. We demonstrate that the proposed framework can explain empirically observed phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with only unlabeled data. Further, our theory
    
[^22]: 可解释的深度聚类

    Interpretable Deep Clustering. (arXiv:2306.04785v1 [cs.LG])

    [http://arxiv.org/abs/2306.04785](http://arxiv.org/abs/2306.04785)

    本文提出了一种可解释的深度学习框架，通过自我监督的方式从数据点中标识信息量丰富的特征，设计了一个模型和门矩阵来预测可解释的实例和聚类级别的聚类分配，并在合成和实际数据中验证了其可靠性和可解释性。

    

    聚类是一项广泛应用于数据分析中的基础学习任务。例如，生物学家经常使用聚类分配来分析基因组序列、医疗记录或图像。由于下游分析通常在聚类级别上执行，因此从业者寻求可靠且可解释的聚类模型。本文提出了一种新的深度学习框架，它可以预测可解释的实例和聚类级别的聚类分配。首先，我们提出一个自我监督的过程来从每个数据点中标识出一组信息量丰富的特征子集。然后，我们设计了一个模型，用于预测聚类分配和一个门矩阵，用于引导聚类级别的特征选择。我们证明了所提出的方法可以使用合成和实际数据可靠地预测聚类分配。此外，我们验证了我们的模型可以在实例和聚类级别上产生可解释的结果。

    Clustering is a fundamental learning task widely used as a first step in data analysis. For example, biologists often use cluster assignments to analyze genome sequences, medical records, or images. Since downstream analysis is typically performed at the cluster level, practitioners seek reliable and interpretable clustering models. We propose a new deep-learning framework that predicts interpretable cluster assignments at the instance and cluster levels. First, we present a self-supervised procedure to identify a subset of informative features from each data point. Then, we design a model that predicts cluster assignments and a gate matrix that leads to cluster-level feature selection. We show that the proposed method can reliably predict cluster assignments using synthetic and real data. Furthermore, we verify that our model leads to interpretable results at a sample and cluster level.
    
[^23]: 不变因果集覆盖机

    Invariant Causal Set Covering Machines. (arXiv:2306.04777v1 [cs.LG])

    [http://arxiv.org/abs/2306.04777](http://arxiv.org/abs/2306.04777)

    本文提出了一种名为不变因果集覆盖机的算法，它避免了产生虚假关联，可以在多项式时间内识别感兴趣变量的因果父节点。

    

    基于规则的模型，如决策树，因其可解释的特性受到从业者的欢迎。然而，产生这种模型的学习算法往往容易受到虚假关联的影响，因此不能保证提取的是具有因果关系的洞见。在这项工作中，我们借鉴了不变因果预测文献中的思想，提出了不变的因果集覆盖机，这是一种经典的集覆盖机算法的扩展，用于二值规则的合取/析取，可以证明它避免了虚假关联。我们理论上和实践上证明，我们的方法可以在多项式时间内识别感兴趣变量的因果父节点。

    Rule-based models, such as decision trees, appeal to practitioners due to their interpretable nature. However, the learning algorithms that produce such models are often vulnerable to spurious associations and thus, they are not guaranteed to extract causally-relevant insights. In this work, we build on ideas from the invariant causal prediction literature to propose Invariant Causal Set Covering Machines, an extension of the classical Set Covering Machine algorithm for conjunctions/disjunctions of binary-valued rules that provably avoids spurious associations. We demonstrate both theoretically and empirically that our method can identify the causal parents of a variable of interest in polynomial time.
    
[^24]: 利用观测偏差提高矩阵补全的方法研究

    Exploiting Observation Bias to Improve Matrix Completion. (arXiv:2306.04775v1 [cs.LG])

    [http://arxiv.org/abs/2306.04775](http://arxiv.org/abs/2306.04775)

    本研究利用观测偏差来改进矩阵补全问题，提出一个简单的两阶段算法，实现了与对未观测协变量的监督学习性能相当的结果。

    

    我们考虑了一种变形的矩阵补全问题，其中输入数据以偏差的方式呈现，类似于Ma和Chen所引入的模型。我们的目标是利用偏差与感兴趣的结果之间的共享信息来改进预测。为此，我们提出了一个简单的两阶段算法：（i）将观测模式解释为完全观测的噪声矩阵，我们对观测模式应用传统的矩阵补全方法来估计潜在因素之间的距离； (ii)我们对恢复的特征应用监督学习来填补缺失观察。我们建立了有限样本误差率，这些误差率与相应的监督学习参数率相竞争，这表明我们的学习性能与使用未观测协变量相当。实证评估使用真实世界数据集反映了类似的表现。

    We consider a variant of matrix completion where entries are revealed in a biased manner, adopting a model akin to that introduced by Ma and Chen. Instead of treating this observation bias as a disadvantage, as is typically the case, our goal is to exploit the shared information between the bias and the outcome of interest to improve predictions. Towards this, we propose a simple two-stage algorithm: (i) interpreting the observation pattern as a fully observed noisy matrix, we apply traditional matrix completion methods to the observation pattern to estimate the distances between the latent factors; (ii) we apply supervised learning on the recovered features to impute missing observations. We establish finite-sample error rates that are competitive with the corresponding supervised learning parametric rates, suggesting that our learning performance is comparable to having access to the unobserved covariates. Empirical evaluation using a real-world dataset reflects similar performance g
    
[^25]: 使用大型语言模型注释进行社会科学中的有效下游统计推断: 基于设计的半监督学习

    Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning. (arXiv:2306.04746v1 [stat.ME])

    [http://arxiv.org/abs/2306.04746](http://arxiv.org/abs/2306.04746)

    该论文提出了一种新算法，使用大型语言模型（LLMs）输出进行下游统计分析，以实现有效的下游统计推断，并降低标签获取的研究成本80％，同时保证CSS研究的统计属性。

    

    在计算社会科学（CSS）中，研究人员通过分析文档来解释社会和政治现象。在大多数情况下，CSS研究人员首先获取文档的标签，然后使用可解释的回归分析来解释标签。大型语言模型（LLMs）的最近进展可以通过在规模上便宜地注释文档来降低CSS研究成本，但这些替代标签通常是不完美和有偏的。我们提出了一种新算法，用于使用LLMs的输出进行下游统计分析，同时保证与CSS研究基本相关的统计属性-如渐近无偏性和正确的不确定性量化。我们表明，直接在下游统计分析中使用LLM预测的替代标签会导致实质性偏差和无效置信区间，即使替代准确性高达80-90％。为了解决这个问题，我们基于无偏机器学习提出了基于设计的半监督学习（D-SSL）算法，该算法将LLM注释与有针对性的采样相结合，以实现有效的下游统计推断。我们的方法可以将标签获取的CSS研究成本降低80％，而不影响统计分析的有效性。模拟研究和实际数据示例表明，与直接使用LLM预测标签相比，D-SSL可以将回归估计的准确性提高多达40％。

    In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80--90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised le
    
[^26]: 机器学习 Kronecker 系数

    Machine-Learning Kronecker Coefficients. (arXiv:2306.04734v1 [math.RT])

    [http://arxiv.org/abs/2306.04734](http://arxiv.org/abs/2306.04734)

    本文研究如何使用标准机器学习算法来预测 Kronecker 系数是否为零，并表明机器可以高精度地执行此二元分类任务。

    

    Kronecker 系数是对称群的两个不可约表示张量积的分解重数。与 Littlewood-Richardson 系数（广义线性群上的类比物）不同，还没有已知的 Kronecker 系数组合描述方式，通过算法判断某个 Kronecker 系数是否为零是 NP-Hard 问题。本文表明，诸如最近邻、卷积神经网络和梯度提升决策树之类的标准机器学习算法可以被训练来预测给定的 Kronecker 系数是否为零。结果表明，训练好的机器可以高精度（$\approx 0.98$）地执行此二元分类任务。

    The Kronecker coefficients are the decomposition multiplicities of the tensor product of two irreducible representations of the symmetric group. Unlike the Littlewood--Richardson coefficients, which are the analogues for the general linear group, there is no known combinatorial description of the Kronecker coefficients, and it is an NP-hard problem to decide whether a given Kronecker coefficient is zero or not. In this paper, we show that standard machine-learning algorithms such as Nearest Neighbors, Convolutional Neural Networks and Gradient Boosting Decision Trees may be trained to predict whether a given Kronecker coefficient is zero or not. Our results show that a trained machine can efficiently perform this binary classification with high accuracy ($\approx 0.98$).
    
[^27]: 随机自然阈值算法

    Stochastic Natural Thresholding Algorithms. (arXiv:2306.04730v1 [eess.SP])

    [http://arxiv.org/abs/2306.04730](http://arxiv.org/abs/2306.04730)

    该论文提出了一种随机自然阈值算法，用于稀疏信号恢复，并扩展了现有的自然阈值法，可以提高算法的计算效率和性能。

    

    稀疏信号恢复是各种应用中最基本的问题之一，包括医学成像和遥感。许多基于硬阈值算子族的贪婪算法已被开发用于解决稀疏信号恢复问题。最近，提出了自然阈值法（NT），具有更好的计算效率。本文通过将NT从带线性测量的确定版本扩展到具有一般目标函数的随机版本，提出并讨论了随机自然阈值算法的收敛性保证。我们还进行了各种数值实验，对线性和非线性测量进行了演示，以展示StoNT的性能。

    Sparse signal recovery is one of the most fundamental problems in various applications, including medical imaging and remote sensing. Many greedy algorithms based on the family of hard thresholding operators have been developed to solve the sparse signal recovery problem. More recently, Natural Thresholding (NT) has been proposed with improved computational efficiency. This paper proposes and discusses convergence guarantees for stochastic natural thresholding algorithms by extending the NT from the deterministic version with linear measurements to the stochastic version with a general objective function. We also conduct various numerical experiments on linear and nonlinear measurements to demonstrate the performance of StoNT.
    
[^28]: 揭示生成模型评价度量的缺陷及其不公平对待扩散模型的现象

    Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models. (arXiv:2306.04675v1 [cs.LG])

    [http://arxiv.org/abs/2306.04675](http://arxiv.org/abs/2306.04675)

    系统地研究了图像生成模型的评估，发现常见的评价指标如FID等不能很好地体现扩散模型的感知真实性，建议使用SwAV特征提取器结合FID进行评估。

    

    我们系统地研究了许多种基于图像的生成模型，包括语义多样的数据集，以理解和改进用于评估它们的特征提取器和度量。使用心理物理学的最佳实践，我们进行了迄今为止最大规模的生成模型评估实验，通过对生成样本进行人类感知图像真实性的测量，发现没有任何现有的度量能与人类评估强相关。我们比较了用于评估生成模型整体性能、保真度、多样性和记忆能力的16个现代指标，发现以人类为基准的扩散模型的最先进的感知真实性不反映在常见的度量指标，如FID中。这种差异并不能通过生成样本的多样性来解释，尽管其中一个原因是过度依赖于Inception-V3。通过研究替代的自监督特征提取器，我们解决了这些缺陷，发现个别弱Downstream任务编码的语义信息最能解释图像真实性，建议在评估生成模型时使用SwAV特征提取器结合FID。

    We systematically study a wide variety of image-based generative models spanning semantically-diverse datasets to understand and improve the feature extractors and metrics used to evaluate them. Using best practices in psychophysics, we measure human perception of image realism for generated samples by conducting the largest experiment evaluating generative models to date, and find that no existing metric strongly correlates with human evaluations. Comparing to 16 modern metrics for evaluating the overall performance, fidelity, diversity, and memorization of generative models, we find that the state-of-the-art perceptual realism of diffusion models as judged by humans is not reflected in commonly reported metrics such as FID. This discrepancy is not explained by diversity in generated samples, though one cause is over-reliance on Inception-V3. We address these flaws through a study of alternative self-supervised feature extractors, find that the semantic information encoded by individu
    
[^29]: 论训练本地自适应的排名预测

    On training locally adaptive CP. (arXiv:2306.04648v1 [cs.LG])

    [http://arxiv.org/abs/2306.04648](http://arxiv.org/abs/2306.04648)

    本文提出了一种新的Conformal Prediction方法，使用可训练的变量变换重新定义符合度量，使得预测区间在保持边际有效的同时具有对象属性相关的大小。通过训练可最大化间隔效率。

    

    本文解决了使符合性预测（CP）间隔本地自适应的问题。大多数现有方法集中于通过划分或重新加权校准集来近似间隔的对象条件有效性。我们的策略是新的且概念上不同。我们不是重新加权校准数据，而是通过可训练的变量变换$A \to \phi_X(A)$重新定义符合度量，该变换明确地取决于对象属性$X$。在某些条件下，如果$\phi_X$对于任何$X$在$A$中是单调的，则变换将生成保证是边际有效且具有$X$相关大小的预测区间。我们描述了如何对$\phi_X$进行参数化和训练以最大化间隔效率。与其他CP-aware训练方法相反，目标函数是平滑的，可以通过标准梯度方法进行最小化而无需进行逼近。

    We address the problem of making Conformal Prediction (CP) intervals locally adaptive. Most existing methods focus on approximating the object-conditional validity of the intervals by partitioning or re-weighting the calibration set. Our strategy is new and conceptually different. Instead of re-weighting the calibration data, we redefine the conformity measure through a trainable change of variables, $A \to \phi_X(A)$, that depends explicitly on the object attributes, $X$. Under certain conditions and if $\phi_X$ is monotonic in $A$ for any $X$, the transformations produce prediction intervals that are guaranteed to be marginally valid and have $X$-dependent sizes. We describe how to parameterize and train $\phi_X$ to maximize the interval efficiency. Contrary to other CP-aware training methods, the objective function is smooth and can be minimized through standard gradient methods without approximations.
    
[^30]: 压缩感知：离散优化方法

    Compressed Sensing: A Discrete Optimization Approach. (arXiv:2306.04647v1 [eess.SP])

    [http://arxiv.org/abs/2306.04647](http://arxiv.org/abs/2306.04647)

    本文中提出了一种离散优化方法来解决压缩感知问题，该方法在二次锥松弛下，可以找到最稀疏的向量，得到了可靠的最优解。

    

    本文研究了压缩感知问题，即找到最稀疏的向量，该向量满足一组线性测量，同时达到一定的数值容限。压缩感知是统计学、运筹学和机器学习中的核心问题，应用于信号处理、数据压缩和图像重建等领域。我们引入了一个带有$\ell_2$正则化的压缩感知问题，将其作为混合整数二次锥规划来重新定义。我们推导出此问题的二次锥松弛，并展示了在正则化参数的温和限制下，得到的松弛等价于深入研究的基础追踪去噪问题。我们提出了一个半定松弛来加强二次锥松弛，开发了一种定制的分支定界算法，利用我们的二次锥松弛来解决压缩感知问题的实例，以确证的最优解。我们的数值结果表明，我们的方法产生的解决方案是精确的，并且优于其他方法。

    We study the Compressed Sensing (CS) problem, which is the problem of finding the most sparse vector that satisfies a set of linear measurements up to some numerical tolerance. CS is a central problem in Statistics, Operations Research and Machine Learning which arises in applications such as signal processing, data compression and image reconstruction. We introduce an $\ell_2$ regularized formulation of CS which we reformulate as a mixed integer second order cone program. We derive a second order cone relaxation of this problem and show that under mild conditions on the regularization parameter, the resulting relaxation is equivalent to the well studied basis pursuit denoising problem. We present a semidefinite relaxation that strengthens the second order cone relaxation and develop a custom branch-and-bound algorithm that leverages our second order cone relaxation to solve instances of CS to certifiable optimality. Our numerical results show that our approach produces solutions that 
    
[^31]: 使用反事实预测集设计决策支持系统

    Designing Decision Support Systems Using Counterfactual Prediction Sets. (arXiv:2306.03928v1 [cs.LG])

    [http://arxiv.org/abs/2306.03928](http://arxiv.org/abs/2306.03928)

    本文提出了一种基于反事实预测集的决策支持系统设计方法，不同于传统的单一标签预测，它使用符合预测器构建预测集，并引导人类专家从中选择标签值。

    

    分类任务的决策支持系统通常被设计用于预测地面实况标签的值。然而，由于它们的预测并不完美，这些系统还需要让人类专家了解何时以及如何使用这些预测来更新自己的预测。不幸的是，这被证明是具有挑战性的。最近有人认为，另一种类型的决策支持系统可能会避开这个挑战。这些系统不是提供单个标签预测，而是使用符合预测器构建一组标签预测值，即预测集，并强制要求专家从预测集中预测一个标签值。然而，这些系统的设计和评估迄今仍依赖于样式化的专家模型，这引发了人们对它们的承诺的质疑。本文从在线学习的角度重新审视了这种系统的设计，并开发了一种不需要。

    Decision support systems for classification tasks are predominantly designed to predict the value of the ground truth labels. However, since their predictions are not perfect, these systems also need to make human experts understand when and how to use these predictions to update their own predictions. Unfortunately, this has been proven challenging. In this context, it has been recently argued that an alternative type of decision support systems may circumvent this challenge. Rather than providing a single label prediction, these systems provide a set of label prediction values constructed using a conformal predictor, namely a prediction set, and forcefully ask experts to predict a label value from the prediction set. However, the design and evaluation of these systems have so far relied on stylized expert models, questioning their promise. In this paper, we revisit the design of this type of systems from the perspective of online learning and develop a methodology that does not requi
    
[^32]: BabySLM: 自我监督口语语言模型的语言习得友好型基准

    BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models. (arXiv:2306.01506v1 [cs.CL])

    [http://arxiv.org/abs/2306.01506](http://arxiv.org/abs/2306.01506)

    本文提出了一种语言习得友好型基准，以检验自我监督口语语言模型在儿童词汇和句法经历中的表现，并提出了两个需要解决的挑战：文本和语音之间的差距和干净语音和野外语音之间的差距。

    

    已经证明，学习语音表示的自我监督技术能够从听到的语音中发展出语言能力，而无需人类标签。为了充分发挥这些方法的潜力并进一步了解婴儿学习语言的方式，模拟必须紧密模仿现实情况，通过在开发上符合儿童语言经验典型词汇库和对应测试集进行基准测试。为此，我们提出了一种用于检测在词汇和句法层面上的口语语言模型的语言习得友好型基准。本文介绍了此基准，并总结了一系列实验，证明其有用性。此外，我们还强调了需要解决的两个挑战：填补文本和语音之间以及干净语音和野外语音之间的差距。

    Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech.
    
[^33]: 基于GPT-4的复杂数学问题求解的实证研究

    An Empirical Study on Challenging Math Problem Solving with GPT-4. (arXiv:2306.01337v1 [cs.CL])

    [http://arxiv.org/abs/2306.01337](http://arxiv.org/abs/2306.01337)

    本研究探索使用GPT-4解决更复杂和有挑战性的数学问题，提出了一种名为MathChat的对话式问题求解框架，并在困难高中竞赛问题上进行了评估。

    

    使用大型语言模型（LLM）来解决数学问题是一项有趣的研究，考虑到在各种科学和工程领域中用自然语言表达的数学问题的丰富性。虽然之前有几项工作研究了使用LLM解决初等数学问题，但本研究探索了使用GPT-4解决更复杂和有挑战性的数学问题的前沿。我们评估了使用GPT-4的各种方法。其中一些是从现有工作中改编而来的，其中一个是MathChat，这是本研究新提出的一种对话式问题求解框架。我们在来自MATH数据集的困难高中竞赛问题上进行评估，表明了所提出的对话式方法的优势。

    Employing Large Language Models (LLMs) to address mathematical problems is an intriguing research endeavor, considering the abundance of math problems expressed in natural language across numerous science and engineering fields. While several prior works have investigated solving elementary mathematics using LLMs, this work explores the frontier of using GPT-4 for solving more complex and challenging math problems. We evaluate various ways of using GPT-4. Some of them are adapted from existing work, and one is \MathChat, a conversational problem-solving framework newly proposed in this work. We perform the evaluation on difficult high school competition problems from the MATH dataset, which shows the advantage of the proposed conversational approach.
    
[^34]: Parity校准

    Parity Calibration. (arXiv:2305.18655v1 [cs.LG])

    [http://arxiv.org/abs/2305.18655](http://arxiv.org/abs/2305.18655)

    本文介绍一种新的校准预测目标——parity校准，其考虑时间序列中未来观测值的增加或减少。我们使用在线二进制校准方法实现了parity校准，并在流行病学、天气预报和核聚变控制等领域中表明该方法的有效性。

    

    在序列回归设置中，决策者可能更关注未来观测值是否比当前值增加或减少，而不是未来观测值的实际值。在此背景下，我们引入了平等校准的概念，它捕捉了时间序列增减事件的校准预测目标。平等概率可以从输出的预测分布中提取，但我们显示这种策略导致理论上的不可预测性和差劲的实际性能。然后我们发现，虽然原任务是回归，但平等校准可以被表达为二进制校准。基于这种联系，我们使用在线二进制校准方法实现了平等校准。我们通过流行病学、天气预报和基于模型的核聚变控制的实际案例展示了我们方法的有效性。

    In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or "parity") event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion.
    
[^35]: 乐观的近端策略优化在线性马尔可夫决策过程中的理论分析

    A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes. (arXiv:2305.08841v1 [cs.LG])

    [http://arxiv.org/abs/2305.08841](http://arxiv.org/abs/2305.08841)

    本文提出了一种乐观的近端策略优化算法，用于解决带有全信息反馈的周期性对抗性线性MDP，在随机线性MDP和带有全信息的敌对线性MDP中，达到了最先进的后悔边界，并具有新颖的多批次更新机制。

    

    近端策略优化（PPO）算法是强化学习领域中最成功的方法之一。尽管PPO很成功，但是对于PPO及其乐观变种是否能有效解决线性马尔可夫决策过程(MDPs)的理论理解仍不足。为了填补这一空白，我们提出了一种乐观的近端策略优化算法，用于带有全信息反馈的周期敌对线性MDP，并为其建立了一个$\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$的后悔值。其中$d$是线性MDPs的环境维数，$H$是每个周期的长度，$K$是周期数。与现有的基于策略的算法相比，在随机线性MDP和带有全信息的敌对线性MDP中，我们实现了当今最先进的后悔边界。此外，我们的算法设计具有新颖的多批次更新机制。

    The proximal policy optimization (PPO) algorithm stands as one of the most prosperous methods in the field of reinforcement learning (RL). Despite its success, the theoretical understanding of PPO remains deficient. Specifically, it is unclear whether PPO or its optimistic variants can effectively solve linear Markov decision processes (MDPs), which are arguably the simplest models in RL with function approximation. To bridge this gap, we propose an optimistic variant of PPO for episodic adversarial linear MDPs with full-information feedback, and establish a $\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for it. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each episode, and $K$ is the number of episodes. Compared with existing policy-based algorithms, we achieve the state-of-the-art regret bound in both stochastic linear MDPs and adversarial linear MDPs with full information. Additionally, our algorithm design features a novel multi-batched updating mechanism
    
[^36]: Metropolized Hamiltonian Monte Carlo何时能证明优于Metropolis-adjusted Langevin算法？

    When does Metropolized Hamiltonian Monte Carlo provably outperform Metropolis-adjusted Langevin algorithm?. (arXiv:2304.04724v1 [stat.CO])

    [http://arxiv.org/abs/2304.04724](http://arxiv.org/abs/2304.04724)

    本文表明，从高维平滑目标分布采样时，Metropolized Hamiltonian Monte Carlo (HMC)比Metropolis-adjusted Langevin算法（MALA）更有效。

    

    本文分析了Metropolized Hamiltonian Monte Carlo (HMC)的混合时间，使用leapfrog积分器从$\mathbb{R}^d$分布中采样，该分布的对数密度平滑，具有Frobenius范数上的李普希茨黑塞，并满足等周性。我们将梯度复杂度限制为从一个暖启动达到$\epsilon$误差的总变异距离所需的$\tilde O(d^{1/4}\text{polylog}(1/\epsilon))$，并展示了选择比1更大的leapfrog步数的好处。为了超越Wu等人（2022）对Metropolis-adjusted Langevin algorithm (MALA)的分析，其在维度依赖性上是$\tilde{O}(d^{1/2}\text{polylog}(1/\epsilon))$，我们揭示了证明中的一个关键特征：连续HMC动态的位置和速度变量的离散化的联合分布近似不变。当通过leapfrog步数的归纳来展示这个关键特征时，我们能够获得各种量的矩的估计，这些量在限制Metropolized HMC的混合时间时是至关重要的，而在MALA中已知的类似结果是错误的。我们的结果表明，在采样高维平滑目标分布时，使用具有大量leapfrog步骤的Metropolized HMC可能比使用MALA更有效。

    We analyze the mixing time of Metropolized Hamiltonian Monte Carlo (HMC) with the leapfrog integrator to sample from a distribution on $\mathbb{R}^d$ whose log-density is smooth, has Lipschitz Hessian in Frobenius norm and satisfies isoperimetry. We bound the gradient complexity to reach $\epsilon$ error in total variation distance from a warm start by $\tilde O(d^{1/4}\text{polylog}(1/\epsilon))$ and demonstrate the benefit of choosing the number of leapfrog steps to be larger than 1. To surpass previous analysis on Metropolis-adjusted Langevin algorithm (MALA) that has $\tilde{O}(d^{1/2}\text{polylog}(1/\epsilon))$ dimension dependency in Wu et al. (2022), we reveal a key feature in our proof that the joint distribution of the location and velocity variables of the discretization of the continuous HMC dynamics stays approximately invariant. This key feature, when shown via induction over the number of leapfrog steps, enables us to obtain estimates on moments of various quantities tha
    
[^37]: 元卡洛调整朗之万(MALA)在光滑且等周条件下的混合简单证明

    A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry. (arXiv:2304.04095v1 [stat.ML])

    [http://arxiv.org/abs/2304.04095](http://arxiv.org/abs/2304.04095)

    本文证明了，在光滑和等周条件下，MALA的混合时间仅与Hessian矩阵的trace有关，而与其算子范数和log-concave没有关系。

    

    本文研究了在$\mathbb{R}^d$上样本目标密度的元卡洛调整朗之万（MALA）的混合时间。我们假设目标密度满足$\psi_\mu$-等周和它的黑塞矩阵的trace和算子范数分别受$L$和$\Upsilon$的限制。我们的主要结论是，从热启动开始，为了达到$\epsilon$总变差距离，MALA在$O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$次迭代中混合。值得注意的是，该结果不仅适用于对数凹采样设置，而且混合时间仅取决于$\Upsilon$，而不是其上界$Ld$。在$m$-强对数凹和$L$-光滑采样设置中，我们的界限恢复了以前的MALA的最小值混合界限。

    We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for sampling a target density on $\mathbb{R}^d$. We assume that the target density satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its Hessian are bounded by $L$ and $\Upsilon$ respectively. Our main result establishes that, from a warm start, to achieve $\epsilon$-total variation distance to the target density, MALA mixes in $O\left(\frac{(L\Upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$ iterations. Notably, this result holds beyond the log-concave sampling setting and the mixing time depends on only $\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly logconcave and $L$-log-smooth sampling setting, our bound recovers the previous minimax mixing bound of MALA~\cite{wu2021minimax}.
    
[^38]: DP-Fast MH: 大规模贝叶斯推断的私有、快速、准确的Metropolis-Hastings算法

    DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference. (arXiv:2303.06171v1 [cs.LG])

    [http://arxiv.org/abs/2303.06171](http://arxiv.org/abs/2303.06171)

    本文提出了一种新的DP-Fast MH算法，用于大规模贝叶斯推断，具有精确、快速和隐私保护的特点。

    This paper proposes a new DP-Fast MH algorithm for large-scale Bayesian inference, which is accurate, fast, and privacy-preserving.

    贝叶斯推断提供了一个从复杂数据中学习和在不确定性下推理的原则性框架。它已经广泛应用于机器学习任务，如医学诊断、药物设计和政策制定。在这些常见应用中，数据可能非常敏感。差分隐私（DP）提供了具有强大最坏情况隐私保证的数据分析工具，并已发展成为隐私保护数据分析的主要方法。在本文中，我们研究了Metropolis-Hastings（MH）算法，这是最基本的MCMC方法之一，用于差分隐私下的大规模贝叶斯推断。虽然大多数现有的私有MCMC算法为了获得隐私而牺牲了准确性和效率，但我们提供了第一个精确且快速的DP MH算法，大多数迭代中仅使用一个小批量的数据。我们进一步揭示了隐私、可扩展性（即批量大小）和效率（即收敛速度）之间的三重权衡，从理论上说明了这一点。

    Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, the data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically char
    
[^39]: 多项式时间和私有学习无限高斯混合模型

    Polynomial Time and Private Learning of Unbounded Gaussian Mixture Models. (arXiv:2303.04288v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.04288](http://arxiv.org/abs/2303.04288)

    本文开发了一种技术，将高维高斯混合模型的私有参数估计问题降低到非私有算法，从而使现有的非私有算法能够在隐私保护的条件下使用，提供了第一个多项式时间的私有学习GMMs算法。

    

    本文研究了使用$k$个组件和$d$维高斯混合模型(GMMs)私下估计参数的问题。我们开发了一种技术，将此问题减少到非私有算法。这使我们能够以黑盒方式私有化现有的非私有算法，同时在样本复杂度和运行时间方面仅产生少量开销。作为我们框架的主要应用，我们使用Moitra和Valiant [MV10]的非私有算法开发了一个$(\varepsilon, \delta)$-差分隐私算法来学习GMMs。结果，这提供了第一个不对参数进行任何有界性假设的私有学习GMMs的样本复杂度上界和第一个多项式时间算法。作为我们分析的一部分，我们证明了高维高斯分布的总变差距离的紧密(高达常数因子)下界，这可以独立地得到研究。

    We study the problem of privately estimating the parameters of $d$-dimensional Gaussian Mixture Models (GMMs) with $k$ components. For this, we develop a technique to reduce the problem to its non-private counterpart. This allows us to privatize existing non-private algorithms in a blackbox manner, while incurring only a small overhead in the sample complexity and running time. As the main application of our framework, we develop an $(\varepsilon, \delta)$-differentially private algorithm to learn GMMs using the non-private algorithm of Moitra and Valiant [MV10] as a blackbox. Consequently, this gives the first sample complexity upper bound and first polynomial time algorithm for privately learning GMMs without any boundedness assumptions on the parameters. As part of our analysis, we prove a tight (up to a constant factor) lower bound on the total variation distance of high-dimensional Gaussians which can be of independent interest.
    
[^40]: 减少、重复利用、回收：基于能量扩散模型和MCMC的组合生成

    Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. (arXiv:2302.11552v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11552](http://arxiv.org/abs/2302.11552)

    该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。

    

    自从扩散模型问世以来，它在许多领域中已经迅速成为生成模型的主要方法。它们可以被解释为学习一系列时变的对数概率密度函数的梯度。这种解释已经激发了基于分类器和无分类器指导的思想成为后续控制扩散模型的方法。在这项工作中，我们建立在这些想法的基础上，利用扩散模型的分数-based解释，探索了用于涉及组合生成和指导的条件、修改和重复使用扩散模型的替代方法。特别是，我们调查了为什么某些类型的组合使用当前技术失败，并介绍了一些解决方案。我们得出结论，采样者(而不是模型)对此失败负有责任，并提出了新的采样器，受MCMC的启发，使组合生成成功。此外，我们提出了一种基于能量的扩散模型参数化方法，它使得逼近目标分布更加容易。

    Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the 
    
[^41]: 一种用于连续超参数优化的Lipschitz乐观策略算法

    A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization. (arXiv:2302.01539v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01539](http://arxiv.org/abs/2302.01539)

    BLiE是一种用于超参数优化的算法，只假设目标函数具有Lipschitz连续性。理论和实验证明BLiE优于现有算法，并且可以应用于搜索扩散模型的噪声调度。

    

    在机器学习中，超参数优化（HPO）是最关键的问题之一，因为超参数的选择对最终模型的性能有重要影响。虽然有许多HPO算法，但它们要么没有理论保证，要么需要强的假设。为此，我们介绍了BLiE——一种基于Lipschitz乐观策略的HPO算法，它只假设目标函数具有Lipschitz连续性。BLiE利用目标函数的景观以自适应地搜索超参数空间。理论上，我们证明了$(i)$ BLiE发现具有$O(\frac{1}{\epsilon})^{d_z+\beta}$个总预算的$\epsilon$最优超参数，其中$d_z$和$\beta$是问题内在的；$(ii)$ BLiE具有高度可并行性。实验上，我们证明了BLiE在基准任务上优于现有的HPO算法。我们还应用BLiE搜索扩散模型的噪声调度。与默认调度相比较，BLiE表现出更好的性能。

    One of the most critical problems in machine learning is HyperParameter Optimization (HPO), since choice of hyperparameters has a significant impact on final model performance. Although there are many HPO algorithms, they either have no theoretical guarantees or require strong assumptions. To this end, we introduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes Lipschitz continuity of the objective function. BLiE exploits the landscape of the objective function to adaptively search over the hyperparameter space. Theoretically, we show that $(i)$ BLiE finds an $\epsilon$-optimal hyperparameter with $O \left( \frac{1}{\epsilon} \right)^{d_z + \beta}$ total budgets, where $d_z$ and $\beta$ are problem intrinsic; $(ii)$ BLiE is highly parallelizable. Empirically, we demonstrate that BLiE outperforms the state-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to search for noise schedule of diffusion models. Comparison with the default schedule shows tha
    
[^42]: 鲁棒的在线主动学习策略

    Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00422](http://arxiv.org/abs/2302.00422)

    本文提出了一种自适应方法，用于鲁棒的在线主动学习，并在受污染的数据流中证明了其性能表现优异，同时确保了稳定性并减少异常值的负面影响。

    

    在许多工业应用中，获得标记的观测数据并不简单，通常需要人工专家干预或使用昂贵的测试设备。在这种情况下，主动学习可以大大提高拟合模型时最信息数据点的建议。减少模型开发所需的观测数据数量可以减轻训练所需的计算负担和标记相关的操作支出。特别是在线主动学习，在需要在极短时间内决定是否获取数据点标记的高容量生产过程中非常有用。然而，尽管最近致力于开发在线主动学习策略，但在存在异常值的情况下这些方法的行为仍未得到彻底研究。在这项工作中，我们调查了在线主动线性回归在受污染的数据流中的性能，并提出了一种自适应方法，用于鲁棒的在线主动学习，同时保证稳定性并减少异常值的负面影响。

    In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
    
[^43]: 无需图形学习的因果赌博机问题

    Causal Bandits without Graph Learning. (arXiv:2301.11401v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.11401](http://arxiv.org/abs/2301.11401)

    本文针对因果图未知的情况，提出了一种在因果赌博机问题中使用原子干预找到奖励节点父节点的有效算法，并扩展至奖励节点具有多个父节点的情况。同时，还得出了算法执行期望干预次数的精确方程，并证明在特定图形条件下，该算法可以快速执行对数。

    

    本文研究当因果图不知道的情况下的因果赌博机问题，并开发了一种使用原子干预找到奖励节点的父节点的有效算法。我们推导出算法执行的期望干预次数的精确方程，并表明，在某些图形条件下，它可以快速执行对数，或者在更一般的假设下，执行更慢但仍然是变量数的亚线性级别。我们正式表明我们的算法是最优的，因为它符合我们为执行原子干预的任何算法建立的通用下界。最后，我们将我们的算法扩展到奖励节点具有多个父节点的情况。使用这个算法和来自赌博文献的标准算法可以导致改进的遗憾界。

    We study the causal bandit problem when the causal graph is unknown and develop an efficient algorithm for finding the parent node of the reward node using atomic interventions. We derive the exact equation for the expected number of interventions performed by the algorithm and show that under certain graphical conditions it could perform either logarithmically fast or, under more general assumptions, slower but still sublinearly in the number of variables. We formally show that our algorithm is optimal as it meets the universal lower bound we establish for any algorithm that performs atomic interventions. Finally, we extend our algorithm to the case when the reward node has multiple parents. Using this algorithm together with a standard algorithm from bandit literature leads to improved regret bounds.
    
[^44]: 深度学习与稀疏正则化：信号处理的观点

    Deep Learning Meets Sparse Regularization: A Signal Processing Perspective. (arXiv:2301.09554v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.09554](http://arxiv.org/abs/2301.09554)

    本文介绍了一个新的数学框架，恰当地表征了被训练对数据拟合的神经网络的功能属性。这个框架解释了深度神经网络的一些优秀性能、网络体系结构中跳跃连接和低秩权重矩阵的使用、稀疏在神经网络中的作用以及为什么神经网络可作为优秀的特征提取器。

    

    深度学习在实践中取得了巨大成功，大多数最先进的机器学习方法都基于神经网络。然而，缺乏一个严格的数学理论，能够充分解释深度神经网络的惊人性能。本文介绍了一个相对较新的数学框架，提供了对深度学习的更深入理解的开端。这个框架恰当地表征了被训练对数据拟合的神经网络的功能属性。支持这个框架的关键数学工具包括变换域稀疏正则化、计算机断层摄影的Radon变换和逼近理论，这些技术都深深根植于信号处理。这个框架解释了加权衰减正则化在神经网络训练中的作用，网络体系结构中跳跃连接和低秩权重矩阵的使用，稀疏在神经网络中的作用，并解释了为什么神经网络可作为优秀的特征提取器。

    Deep learning has been wildly successful in practice and most state-of-the-art machine learning methods are based on neural networks. Lacking, however, is a rigorous mathematical theory that adequately explains the amazing performance of deep neural networks. In this article, we present a relatively new mathematical framework that provides the beginning of a deeper understanding of deep learning. This framework precisely characterizes the functional properties of neural networks that are trained to fit to data. The key mathematical tools which support this framework include transform-domain sparse regularization, the Radon transform of computed tomography, and approximation theory, which are all techniques deeply rooted in signal processing. This framework explains the effect of weight decay regularization in neural network training, the use of skip connections and low-rank weight matrices in network architectures, the role of sparsity in neural networks, and explains why neural networ
    
[^45]: 学习最大化互信息用于动态特征选择

    Learning to Maximize Mutual Information for Dynamic Feature Selection. (arXiv:2301.00557v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00557](http://arxiv.org/abs/2301.00557)

    本文提出一种基于互信息的动态特征选择方法，使用摊销优化进行学习。在实验中取得了比现有方法更好效果。

    

    特征选择有助于减少机器学习中的数据采集成本，但标准方法是使用静态特征子集来训练模型。本文考虑了动态特征选择（DFS）问题，即模型根据现有信息顺序查询特征。DFS通常采用强化学习方法处理，但本文探索了一种更简单的方法，即基于条件互信息贪婪地选择特征。虽然这种方法在理论上十分有吸引力，但需要对数据分布进行完全访问。因此，我们提出了一种基于摊销优化的学习方法。实验证明，该方法在训练到最优状态后可以恢复贪心策略，并且在我们的实验中优于许多现有的特征选择方法，从而验证其作为这个问题的简单而强大的解决方法。

    Feature selection helps reduce data acquisition costs in ML, but the standard approach is to train models with static feature subsets. Here, we consider the dynamic feature selection (DFS) problem where a model sequentially queries features based on the presently available information. DFS is often addressed with reinforcement learning, but we explore a simpler approach of greedily selecting features based on their conditional mutual information. This method is theoretically appealing but requires oracle access to the data distribution, so we develop a learning approach based on amortized optimization. The proposed method is shown to recover the greedy policy when trained to optimality, and it outperforms numerous existing feature selection methods in our experiments, thus validating it as a simple but powerful approach for this problem.
    
[^46]: 具有通用迷你批量一致性和无偏完全集合梯度近似的可扩展集合编码。

    Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation. (arXiv:2208.12401v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.12401](http://arxiv.org/abs/2208.12401)

    本文提出了一种可扩展的集合编码方法UMBC，可以与任意非MBC组件相结合，同时仍满足MBC；同时提出了一种高效的MBC训练算法，可以为任何集合大小在训练和测试时都具有恒定的内存开销，给出完整集合梯度的无偏近似。

    

    近期，关于集合函数的小批量一致性(MBC)的研究引起了人们对于保证将一个分割的集合的部分顺序处理和聚合，而保证所有分割的输出相同的需求的关注。然而，现有的MBC架构的限制导致了具有有限表达能力的模型。此外，先前的研究没有解决在需要完整集合梯度的情况下如何处理训练中的大型集合。为了解决这些问题，我们提出了一种可用于任意非-MBC组件相结合的通用MBC (UMBC) 类集合函数，同时仍满足MBC，使得MBC设置中可以使用更广泛的功能类。此外，我们提出了一种高效的MBC训练算法，它能够为任何集合大小在训练和测试时都具有恒定的内存开销，给出完整集合梯度的无偏近似。我们进行了广泛的实验，包括图像完成、文本分类、无监督聚类等。

    Recent work on mini-batch consistency (MBC) for set functions has brought attention to the need for sequentially processing and aggregating chunks of a partitioned set while guaranteeing the same output for all partitions. However, existing constraints on MBC architectures lead to models with limited expressive power. Additionally, prior work has not addressed how to deal with large sets during training when the full set gradient is required. To address these issues, we propose a Universally MBC (UMBC) class of set functions which can be used in conjunction with arbitrary non-MBC components while still satisfying MBC, enabling a wider range of function classes to be used in MBC settings. Furthermore, we propose an efficient MBC training algorithm which gives an unbiased approximation of the full set gradient and has a constant memory overhead for any set size for both train- and test-time. We conduct extensive experiments including image completion, text classification, unsupervised cl
    
[^47]: 基于成对比较的排名高效计算

    Efficient computation of rankings from pairwise comparisons. (arXiv:2207.00076v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.00076](http://arxiv.org/abs/2207.00076)

    本文提出了一种比已有迭代算法运行速度快100倍的基于成对比较的排名高效计算方法。

    

    本文研究了使用Bradley-Terry模型通过个体、团队或对象之间的成对比较来确定排名。该模型中排名的估计通常使用Zermelo近一百年前首次引入的简单迭代算法进行。本文提出了一种替代且同样简单的迭代方法，可证明它返回的结果是相同的，但速度更快。在一些情况下，速度可能快了一百倍。我们通过应用于一系列示例数据集来演示该算法，并导出有关其收敛性的许多结果。

    We study the ranking of individuals, teams, or objects, based on pairwise comparisons between them, using the Bradley-Terry model. Estimates of rankings within this model are commonly made using a simple iterative algorithm first introduced by Zermelo almost a century ago. Here we describe an alternative and similarly simple iteration that provably returns identical results but does so much faster -- over a hundred times faster in some cases. We demonstrate this algorithm with applications to a range of example data sets and derive a number of results regarding its convergence.
    
[^48]: 多任务学习和Bandits通过健壮统计学

    Multitask Learning and Bandits via Robust Statistics. (arXiv:2112.14233v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.14233](http://arxiv.org/abs/2112.14233)

    本研究探讨了多任务学习以及Bandits方法的健壮统计学实现，提出了一种新颖的两阶段多任务学习估计器，该估计器以一种样本高效的方式利用共享全局参数和稀疏实例特定术语的结构。

    

    决策者经常同时面对许多相关但异质的学习问题。在此工作中，我们研究了一种自然的设置，其中每个学习实例中的未知参数可以分解为共享全局参数加上稀疏的实例特定术语。我们提出了一种新颖的两阶段多任务学习估计器，以一种样本高效的方式利用这种结构，使用健壮统计学（在相似实例上学习）和LASSO回归（去偏差结果）的独特组合。我们的估计器提供了改进的样本复杂度界限。

    Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bound
    
[^49]: 超越平行平面：非球形高斯混合的准多项式时间保证

    Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for Non-Spherical Gaussian Mixtures. (arXiv:2112.05445v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.05445](http://arxiv.org/abs/2112.05445)

    本文针对具有未知均值和未知协方差的$k\geq2$的高斯组分混合物，提出了一种准多项式时间内可靠区分该混合物与纯高斯分布的算法，并且该算法仅需要在多项式下界混合重量的情况下运行。

    

    本文考虑具有未知则和未知方差（对于所有组分都相同）的$k\geq2$个高斯组分混合物，这些组分是良好分离的，即不同组分的统计重叠最多为$k^{-C}$，其中$C\geq1$为足够大的常数。我们展示了只有在允许混合权为指数级小数时才会出现这种难度，并且对于多项式下界混合重量，准多项式时间内可以实现非平凡算法保证。具体而言，我们开发了一种基于平方和方法的算法，其运行时间准多项式，并且可靠地区分一个由$k\geq2$个良好分离的高斯组分混合物和一个纯高斯分布。作为证书，该算法输出此区分的一个符号。

    We consider mixtures of $k\geq 2$ Gaussian components with unknown means and unknown covariance (identical for all components) that are well-separated, i.e., distinct components have statistical overlap at most $k^{-C}$ for a large enough constant $C\ge 1$. Previous statistical-query [DKS17] and lattice-based [BRST21, GVV22] lower bounds give formal evidence that even distinguishing such mixtures from (pure) Gaussians may be exponentially hard (in $k$).  We show that this kind of hardness can only appear if mixing weights are allowed to be exponentially small, and that for polynomially lower bounded mixing weights non-trivial algorithmic guarantees are possible in quasi-polynomial time. Concretely, we develop an algorithm based on the sum-of-squares method with running time quasi-polynomial in the minimum mixing weight. The algorithm can reliably distinguish between a mixture of $k\ge 2$ well-separated Gaussian components and a (pure) Gaussian distribution. As a certificate, the algori
    
[^50]: 具有有限时频支持信号的独特三次相关谱反演方法

    Unique Bispectrum Inversion for Signals with Finite Spectral/Temporal Support. (arXiv:2111.06479v3 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2111.06479](http://arxiv.org/abs/2111.06479)

    本文提出了一种独特的方法，可以从至少 $3B$ 个 bispectrum 测量结果中唯一地恢复带限信号，该方法适用于时限信号，并通过最小化非凸目标函数来进行优化。

    

    在许多信号处理问题中，从三次相关谱（也称为 bispectrum）中恢复信号是一项重要的任务。然而传统方法并不能准确地从 bispectrum 反演出底层信号。本文提出了一种方法，能够从至少 $3B$ 个 bispectrum 测量结果（其中 $B$ 是信号的带宽）中唯一地恢复带限信号。我们的方法也适用于时限信号。我们提出了一种两步信赖域算法，通过最小化一个非凸目标函数来进行优化。首先，我们通过谱算法对信号进行近似，然后根据一系列梯度迭代来改进所得到的初始化结果。数值实验表明，我们的算法可以从完整或欠采样的 bispectrum 观测结果中估计带限或时限信号。

    Retrieving a signal from its triple correlation spectrum, also called bispectrum, arises in a wide range of signal processing problems. Conventional methods do not provide an accurate inversion of bispectrum to the underlying signal. In this paper, we present an approach that uniquely recovers signals with finite spectral support (band-limited signals) from at least $3B$ measurements of its bispectrum function (BF), where $B$ is the signal's bandwidth. Our approach also extends to time-limited signals. We propose a two-step trust region algorithm that minimizes a non-convex objective function. First, we approximate the signal by a spectral algorithm and then refine the attained initialization based on a sequence of gradient iterations. Numerical experiments suggest that our proposed algorithm is able to estimate band-/time-limited signals from its BF for both complete and undersampled observations.
    
[^51]: 注意力偏向的随机梯度下降

    Attentional-Biased Stochastic Gradient Descent. (arXiv:2012.06951v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.06951](http://arxiv.org/abs/2012.06951)

    本文提出了一种名为ABSGD的简单而有效的方法，用于解决深度学习中的数据不平衡或标签噪声问题。我们为每个样本分配一个个别重要性权重，该权重系统地与数据的损失值成比例，并且可以捕捉到每个类中个别示例之间的多样性。与现有的加权方案相比，我们的方法可以减轻计算负担并在分布鲁棒优化 (DRO) 框架中解释为正则化参数。

    

    在本文中，我们提出了一种名为ABSGD的简单而有效的方法，用于解决深度学习中的数据不平衡或标签噪声问题。我们的方法是对动量SGD的简单修改，在小批量中为每个样本分配一个个别重要性权重。样本数据的个体级别权重系统地与数据的缩放损失值的指数成比例，其中缩放因子在分布鲁棒优化 (DRO) 框架中被解释为正则化参数。根据缩放因子是正还是负，ABSGD保证收敛到信息正则化的最小值最大值或最小值最小值 DRO 问题的静态点。与现有的类级加权方案相比，我们的方法可以捕捉到每个类中个别示例之间的多样性。与需要三次反向传播的元学习使用的现有个体级加权方法相比，我们的方法可以减轻计算负担。

    In this paper, we present a simple yet effective provable method (named ABSGD) for addressing the data imbalance or label noise problem in deep learning. Our method is a simple modification to momentum SGD where we assign an individual importance weight to each sample in the mini-batch. The individual-level weight of sampled data is systematically proportional to the exponential of a scaled loss value of the data, where the scaling factor is interpreted as the regularization parameter in the framework of distributionally robust optimization (DRO). Depending on whether the scaling factor is positive or negative, ABSGD is guaranteed to converge to a stationary point of an information-regularized min-max or min-min DRO problem, respectively. Compared with existing class-level weighting schemes, our method can capture the diversity between individual examples within each class. Compared with existing individual-level weighting methods using meta-learning that require three backward propaga
    
[^52]: 利用具有多个混淆因素的神经网络进行一般治疗效果的因果推断

    Causal Inference of General Treatment Effects using Neural Networks with A Diverging Number of Confounders. (arXiv:2009.07055v6 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2009.07055](http://arxiv.org/abs/2009.07055)

    本文提出了一种利用神经网络进行因果推断的方法，已经通过仿真研究验证了其可行性，可以缓解维数诅咒问题。

    

    因果效应的估算是行为科学、社会科学、经济学和生物医学科学的主要目标。本文考虑了一种广义优化框架，使用前馈神经网络（ANNs）有效估计一般治疗效果，即使协变量的数量可以随着样本数量的增加而增加。我们通过神经网络来估算干扰函数，并为ANN近似器建立了一个新的近似误差界限，当干扰函数属于混合Sobolev空间时。我们证明了在这种情况下，ANN可以缓解维数诅咒问题。我们进一步建立了所提出的治疗效果估计量的一致性和渐近正常性，并应用了一个加权自助法进行推断。仿真研究展示了这些方法。

    The estimation of causal effects is a primary goal of behavioral, social, economic and biomedical sciences. Under the unconfoundedness condition, adjustment for confounders requires estimating the nuisance functions relating outcome and/or treatment to confounders. This paper considers a generalized optimization framework for efficient estimation of general treatment effects using feedforward artificial neural networks (ANNs) when the number of covariates is allowed to increase with the sample size. We estimate the nuisance function by ANNs, and develop a new approximation error bound for the ANNs approximators when the nuisance function belongs to a mixed Sobolev space. We show that the ANNs can alleviate the curse of dimensionality under this circumstance. We further establish the consistency and asymptotic normality of the proposed treatment effects estimators, and apply a weighted bootstrap procedure for conducting inference. The proposed methods are illustrated via simulation stud
    

