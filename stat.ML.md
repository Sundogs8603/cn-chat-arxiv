# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generative Fractional Diffusion Models.](http://arxiv.org/abs/2310.17638) | 该论文提出了一种基于分数阶扩散模型的生成模型，其中通过将分数布朗运动表示为奥恩斯坦-乌伦贝克过程的随机积分，实现了驱动噪声收敛到非马尔可夫过程的效果。这是第一个在具有无限二次变差的随机过程上构建生成模型的尝试。 |
| [^2] | [Approximate Leave-one-out Cross Validation for Regression with $\ell_1$ Regularizers (extended version).](http://arxiv.org/abs/2310.17629) | 本论文提出了一个理论，用于处理广义线性模型家族中使用不可微分正则化器的问题。通过计算留一法交叉验证（LO）和近似留一法交叉验证（ALO）之间的误差，并考虑留一扰动的大小、样本大小、特征数量和正则化参数，我们得到了关于ALO误差的重要结果。 |
| [^3] | [Uncovering Meanings of Embeddings via Partial Orthogonality.](http://arxiv.org/abs/2310.17611) | 本文揭示了通过部分正交性来捕捉嵌入的语义独立性，提出了保持独立性的嵌入概念。 |
| [^4] | [A qualitative difference between gradient flows of convex functions in finite- and infinite-dimensional Hilbert spaces.](http://arxiv.org/abs/2310.17610) | 本文研究了凸函数梯度流在有限维和无限维希尔伯特空间中的差异，证明了在梯度流情况下，如果函数没有最小值，收敛速度可能非常缓慢；如果函数有最小值，过剩能量在时间上是可积的。此外，在希尔伯特空间中，过剩能量的衰减速度可以很慢，甚至可以与给定的单调递减可积函数一样慢。然而，在有限维情况下，存在比过剩能量衰减更慢的单调递减可积函数。 |
| [^5] | [Convergence of flow-based generative models via proximal gradient descent in Wasserstein space.](http://arxiv.org/abs/2310.17582) | 本文通过在Wasserstein空间中应用近端梯度下降，证明了基于流的生成模型的收敛性，并提供了生成数据分布的理论保证。 |
| [^6] | [Inside the black box: Neural network-based real-time prediction of US recessions.](http://arxiv.org/abs/2310.17571) | 本研究使用神经网络对美国衰退进行实时预测，发现长短期记忆（LSTM）和门控循环单元（GRU）模型在长期预测任务中表现优于其他模型，并通过SHAP方法对GRU模型进行特征重要性评估。 |
| [^7] | [Instability of computer vision models is a necessary result of the task itself.](http://arxiv.org/abs/2310.17559) | 该论文研究了计算机视觉模型的不稳定性，并指出这是当前问题表述方式的必然结果。该问题无法完全消除，但可以通过提高图像分辨率、提供上下文信息、全面标注训练数据和防止攻击者访问计算机视觉系统来部分缓解该问题。 |
| [^8] | [Learning Regularized Graphon Mean-Field Games with Unknown Graphons.](http://arxiv.org/abs/2310.17531) | 我们设计了用于学习图核均值场博弈的强化学习算法，通过近端策略优化算法GMFG-PPO以及核嵌入的方法来估计未知图核。我们的算法在收敛速度和效率方面取得了改进，并提供了相关的理论分析。 |
| [^9] | [The Expressive Power of Low-Rank Adaptation.](http://arxiv.org/abs/2310.17513) | 本文分析了低秩适应（LoRA）的表达能力，证明了对于全连接神经网络，当LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度）时，LoRA可以使任何模型f准确表示任何较小的目标模型f。对于Transformer网络，通过rank-（嵌入大小/ 2）的LoRA适配器可以使任何模型适应于相同大小的目标模型。 |
| [^10] | [Bias in Evaluation Processes: An Optimization-Based Model.](http://arxiv.org/abs/2310.17489) | 本研究提出了一个基于优化的模型，用于评估过程中的偏见分析。模型通过将真实效用分布转化为观察到的分布来考虑偏见，并对参数进行研究，以探究其对观察到的分布的影响。通过实证验证和数据拟合，我们证明了该模型的有效性。 |
| [^11] | [The statistical thermodynamics of generative diffusion models.](http://arxiv.org/abs/2310.17467) | 本文通过在生成性扩散模型中应用平衡统计力学的工具，揭示了这些模型中的二阶相变现象，并且认为这种稳定性形式是生成能力的关键。 |
| [^12] | [A Challenge in Reweighting Data with Bilevel Optimization.](http://arxiv.org/abs/2310.17386) | 在重新加权数据的任务中，经典的双层优化方法可能会导致次优解，使得最终的数据权重非常稀疏，这解释了为什么这种方法在实践中很少被使用。 |
| [^13] | [Demonstration-Regularized RL.](http://arxiv.org/abs/2310.17303) | 通过演示-正则化提高强化学习的采样效率，并找到最优策略的样本复杂度，该复杂度与专家演示数量成反比。 |
| [^14] | [Looping in the Human: Collaborative and Explainable Bayesian Optimization.](http://arxiv.org/abs/2310.17273) | 协作和可解释的贝叶斯优化框架(CoExBO)在贝叶斯优化中引入了循环，平衡了人工智能和人类的合作关系。它利用偏好学习将用户见解融合到优化中，解释每次迭代的候选选择，从而增强用户对优化过程的信任，并提供无害保证。 |
| [^15] | [Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity.](http://arxiv.org/abs/2310.17247) | 本文发现神经网络中的grokking现象不仅局限于神经网络，还出现在其他算法和模型中。通过在数据集中添加虚假信息的维度，可以诱发grokking现象。研究表明，grokking现象在解决方案搜索受复杂性和错误指导的任何情况下可能发生。这对理解grokking现象提供了更广泛的理论支持。 |
| [^16] | [Learning an Inventory Control Policy with General Inventory Arrival Dynamics.](http://arxiv.org/abs/2310.17168) | 本文解决了学习具有一般库存到货动态下的库存控制策略的问题，同时允许修改订购数量以满足供应商的限制，并将周期性审核库存控制问题定义为外部决策过程。 |
| [^17] | [Large-Scale Gaussian Processes via Alternating Projection.](http://arxiv.org/abs/2310.17137) | 本论文提出了一种通过交替投影的迭代方法来解决高斯过程在大规模数据集上的训练问题，并证明了该方法具有线性收敛性。 |
| [^18] | [On the Convergence of CART under Sufficient Impurity Decrease Condition.](http://arxiv.org/abs/2310.17114) | 本研究通过研究回归设置下CART的收敛性，建立了足够不纯度减少条件下CART预测误差的上界，并提供了易于验证的足够条件。这对于决策树模型的应用具有重要意义。 |
| [^19] | [Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult.](http://arxiv.org/abs/2310.17087) | 该论文研究了大学习率在非凸优化中产生的隐性偏差，包括稳定的边界、平衡和弹射，并通过发展新的全局收敛理论和研究良好规则性的目标函数，将这些现象归纳为同一现象的不同表现形式。 |
| [^20] | [Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates.](http://arxiv.org/abs/2310.17074) | 通过大学习率的随机梯度下降训练的神经网络，由于其权重的振荡，能够在特征噪声数据上实现良好的泛化性能。 |
| [^21] | [Coreset Markov Chain Monte Carlo.](http://arxiv.org/abs/2310.17063) | Coreset MCMC提出了一种新的方法，通过模拟马尔可夫链以更新coreset权重，从而实现在推断过程中降低计算成本的目的。与其他方法相比，Coreset MCMC提供了更高质量的后验近似和更高的采样效率。 |
| [^22] | [On the Identifiability and Interpretability of Gaussian Process Models.](http://arxiv.org/abs/2310.17023) | 本文研究了高斯过程模型中的可识别性和可解释性问题。对于单输出情况，我们发现Matern核混合的平滑性由最不平滑的组件决定，并且混合核等价于最不平滑的核组件。在多输出模型中，我们证明了协方差矩阵的可识别性，这表明乘法混合是可行的。 |
| [^23] | [Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference.](http://arxiv.org/abs/2310.16975) | 提出了两种神经网络方法来逼近静态和动态条件最优传输问题的解，实现了对条件概率分布的采样和密度估计，适用于贝叶斯推断。算法利用神经网络参数化传输映射以提高可扩展性。 |
| [^24] | [Causal Q-Aggregation for CATE Model Selection.](http://arxiv.org/abs/2310.16945) | 该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率 |
| [^25] | [Multi-scale Diffusion Denoised Smoothing.](http://arxiv.org/abs/2310.16779) | 本文研究了多尺度扩散去噪平滑的准确度和认证鲁棒性之间的权衡，并提出了一种在共享扩散模型上调整以实现平滑分类器鲁棒性的新方法。 |
| [^26] | [Covariate Shift Adaptation Robust to Density-Ratio Estimation.](http://arxiv.org/abs/2310.16638) | 该论文研究了在协变量偏移下的密度比估计的罕见问题，提出了一种适应性方法来减轻密度比估计的偏差对模型的影响。 |
| [^27] | [Assessing the overall and partial causal well-specification of nonlinear additive noise models.](http://arxiv.org/abs/2310.16502) | 提出了一种方法来评估非线性因果加性噪声模型的模型规范性问题，并识别出具有因果效应的预测变量。 |
| [^28] | [A Mean Field Approach to Empirical Bayes Estimation in High-dimensional Linear Regression.](http://arxiv.org/abs/2309.16843) | 这项研究提出了一种在高维线性回归中进行经验贝叶斯估计的均值场方法，通过变分经验贝叶斯逼近先验分布并建立了渐近一致性，从而实现了计算上可行的贝叶斯推断。 |
| [^29] | [Statistically Valid Variable Importance Assessment through Conditional Permutations.](http://arxiv.org/abs/2309.07593) | 本论文提出了一种通过条件置换进行统计有效的变量重要性评估的方法。实证结果表明，这种方法克服了标准置换重要性的局限性，并在深度神经网络中表现出最高的准确性。 |
| [^30] | [Monte Carlo guided Diffusion for Bayesian linear inverse problems.](http://arxiv.org/abs/2308.07983) | 本研究提出了一种在贝叶斯框架下利用蒙特卡洛方法解决非完备线性逆问题的算法，该算法通过利用基于得分的生成模型的先验结构和Feynman-Kac模型，并进行顺序蒙特卡洛采样，表现出比竞争对手更好的性能。 |
| [^31] | [Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory.](http://arxiv.org/abs/2307.04204) | 本文通过实证研究证明了梯度下降轨迹上的稳定边缘现象，并且对于特定的网络结构进行了轨迹对齐分析，建立了渐进尖锐化和稳定边缘现象，扩展了当前文献的研究结果。 |
| [^32] | [A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks.](http://arxiv.org/abs/2307.01951) | 本文以节点分类为例，通过“神经塌陷”现象探索图神经网络中特征演化的机制，并发现即使在节点分类情况下，特征的类内变异性也会减少，但不及基于实例的情况那么显著。 |
| [^33] | [Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures.](http://arxiv.org/abs/2306.15012) | 本论文提出了一种用于从噪声混合物中恢复目标信号的统计分量分离方法，并且在图像降噪任务中展示了其优于标准降噪方法的表现。 |
| [^34] | [Gaussian Membership Inference Privacy.](http://arxiv.org/abs/2306.07273) | 本文提出了$f$-成员推断隐私($f$-MIP)概念，并分析了似然比成员推断攻击，提出了$\mu$-高斯成员推断隐私($\mu$-GMIP)保证，同时提供了一种分析性的成员推断攻击方法，避免了训练大量影子模型。强调了方差的重要性。 |
| [^35] | [General Transformation for Consistent Online Approximation Algorithms.](http://arxiv.org/abs/2306.07163) | 本文提出一个转换框架，可以将离线逼近算法转换为具有低ε-近似遗憾的在线算法，并成功应用于多种问题并实现了多项式时间的近似效果。 |
| [^36] | [Label Embedding by Johnson-Lindenstrauss Matrices.](http://arxiv.org/abs/2305.19470) | 这篇论文提出了基于JLMs的标签嵌入方法，将多元分类问题转化为有限回归问题，具有较高的计算效率和预测准确性。 |
| [^37] | [No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions.](http://arxiv.org/abs/2305.17380) | 本文提出了一种算法，可以处理对抗性损失和对抗性转换，且后悔逐渐增加与对手的恶意程度成比例。 |
| [^38] | [Laplace-Approximated Neural Additive Models: Improving Interpretability with Bayesian Inference.](http://arxiv.org/abs/2305.16905) | 本文提出了拉普拉斯逼近神经加性模型，该模型从贝叶斯角度考虑加性结构，在恢复的特征交互中提供可信区间，提供可处理的边缘似然估计，可用于执行隐式特征选择并对特征对进行排名。 |
| [^39] | [Unifying GANs and Score-Based Diffusion as Generative Particle Models.](http://arxiv.org/abs/2305.16150) | 本文提出了一个新框架，将生成器训练作为粒子模型的一个推广，从而统一了粒子和对抗生成模型。这个框架可以将生成器集成到基于分数扩散模型中，并在没有生成器的情况下训练GAN。 |
| [^40] | [Small Total-Cost Constraints in Contextual Bandits with Knapsacks, with Application to Fairness.](http://arxiv.org/abs/2305.15807) | 本文提出了带总成本限制的上下文信息决策问题（CBwK），通过对术语进行重新组合，对CBwK进行了优化，支持小于$T^{3/4}$的总成本约束，并通过对偶策略实现了平等的成本限制。 |
| [^41] | [Learning Rate Free Bayesian Inference in Constrained Domains.](http://arxiv.org/abs/2305.14943) | 我们的算法是学习率无关的约束域采样算法，并提出了一个统一框架，能够处理多种约束采样问题，实现了与现有算法相竞争的性能。 |
| [^42] | [Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension.](http://arxiv.org/abs/2305.14077) | 这篇论文研究了固定维度下内核和神经网络的良性过拟合，发现良性过拟合的关键在于估计器的平滑度而不是维数，并证明在固定维度下中度导数的良性过拟合是不可能的。相反，我们证明了用序列核进行回归是可能出现良性过拟合的。 |
| [^43] | [Squared Neural Families: A New Class of Tractable Density Models.](http://arxiv.org/abs/2305.13552) | 提出一种新的可计算密度模型类——平方神经分布族，其通过对神经网络的2范数进行平方和基于某个基础度量进行归一化，严格推广了经典指数族，具有闭性条件推断和可计算的边际分布。 |
| [^44] | [Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods.](http://arxiv.org/abs/2305.12283) | 本文提出一种基于非参数方法的无分布模型无偏回归校准方法，具有计算效率和统计一致性，并建立了校准误差的上限和下限的统计保证和优势。 |
| [^45] | [Sequential Memory with Temporal Predictive Coding.](http://arxiv.org/abs/2305.11982) | 该论文提出了一种基于PC的新型时序记忆模型，称为时间预测编码（tPC），可以通过生物可行的神经实现准确地记忆和检索连续输入。其中tPC可以被看作是一种经典异向性霍普菲尔德网络（AHN），具有更稳定的性能，并且可以编码上下文相关信息，区分在序列中出现的重复元素。 |
| [^46] | [Mutual information of spin systems from autoregressive neural networks.](http://arxiv.org/abs/2304.13412) | 本论文介绍了一种基于自回归神经网络和Monte Carlo采样的直接方法来估算自旋系统的双部分互信息，可以研究任意子系统的几何形状，并且在Ising模型上演示了此方法的效果。 |
| [^47] | [Hierarchical clustering with OWA-based linkages, the Lance-Williams formula, and dendrogram inversions.](http://arxiv.org/abs/2303.05683) | 本研究通过使用基于OWA的链接，Lance-Williams公式和树枝反转技术，推广了凝聚层次聚类，并提供了一些条件用于保证结果的树枝图没有不美观的反转。 |
| [^48] | [Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms.](http://arxiv.org/abs/2302.13534) | 本文提出了对于多臂赌博机问题的改进的FTRL算法，通过使用一系列正则化器和新的学习率计划，不再需要假设存在唯一最优臂，并对某些正则化器的遗憾界限进行了改进。 |
| [^49] | [RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion.](http://arxiv.org/abs/2302.01757) | 本文提出了一种适应于离散序列分类器的随机删除（RS-Del）平滑机制，提供针对编辑距离受限对抗性的鲁棒性证明。 |
| [^50] | [Kernel Stein Discrepancy thinning: a theoretical perspective of pathologies and a practical fix with regularization.](http://arxiv.org/abs/2301.13528) | 本文针对后处理MCMC输出过程中的病态问题进行了理论分析，提出了正则化的Stein稀释算法，有效缓解了这些病态产生的影响，为提高逼近质量提供了新策略。 |
| [^51] | [Unconstrained Dynamic Regret via Sparse Coding.](http://arxiv.org/abs/2301.13349) | 本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。 |
| [^52] | [Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing.](http://arxiv.org/abs/2301.12930) | 通过引入异方差位置-尺度噪声函数模型，该论文在正确说明噪声分布的情况下，通过最大似然实现了最先进的准确性。但是，在用户错误指定噪声分布的形式时，分析表明因果推断的精度会急剧下降。因此，该论文提出通过因果模型选择实现稳定而准确的因果推断。 |
| [^53] | [Curvature Filtrations for Graph Generative Model Evaluation.](http://arxiv.org/abs/2301.12906) | 该论文使用图形曲率描述符和拓扑数据分析中的新方法相结合，以获得用于评估图形生成模型的稳健、表达性的描述符。 |
| [^54] | [Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning.](http://arxiv.org/abs/2301.12593) | 该论文提出了一种分布鲁棒安全强化学习框架，通过使用失真风险度量来处理模型不确定性。该方法不需要极小极大优化，具有高效且不依赖模型的特点。实验证明该框架能够在具有安全约束的控制任务中实现稳健的性能和安全性。 |
| [^55] | [Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty.](http://arxiv.org/abs/2301.11588) | 该论文提出了一种基于边界框的多目标贝叶斯优化方法，能够在输入不确定性下高效地识别风险衡量定义的帕累托前沿。该方法具有理论保证，并通过构建高概率边界框和选择下一个评估点的方法来减少不确定性。 |
| [^56] | [A framework for benchmarking clustering algorithms.](http://arxiv.org/abs/2209.09493) | 该论文开发了一个用于基准测试聚类算法的框架，旨在引入一种一致的方法进行测试。还汇总、改进和标准化了许多聚类基准数据集合，并包含了新数据集。提供了互动数据集浏览器、Python API的文档以及与其他编程语言进行框架交互的方式。 |
| [^57] | [Robust Output Analysis with Monte-Carlo Methodology.](http://arxiv.org/abs/2207.13612) | 本论文提出了一个统一的蒙特卡洛抽样输出分析框架，通过对模拟和机器学习输出进行分析，能够非参数化地量化输出的方差和偏差，并提出了一种新的偏差校正估计方法，以提高鲁棒性。 |
| [^58] | [SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks.](http://arxiv.org/abs/2206.05794) | 使用SGD和权重衰减训练深度ReLU神经网络会导致对于权重矩阵的秩最小化的偏差，特别是在使用较小批量大小、更高学习率或增加权重衰减时更为显著。此外，在中间神经网络崩溃时，学习的权重特别低秩。这种偏差与泛化之间存在关系。 |
| [^59] | [Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits.](http://arxiv.org/abs/2107.11419) | 本文研究了模型参数随时间变化的非稳态多臂赌博机问题，引入了自适应重置赌博机(ADR-bandit)算法，通过有限时间分析证明了ADR-bandit在全局变化的情况下具有几乎最优的性能，并且在稳定环境和非稳态环境中均具有最优的性能。 |
| [^60] | [Online Estimation and Community Detection of Network Point Processes for Event Streams.](http://arxiv.org/abs/2009.01742) | 本论文提出了一种在线变分推断算法，用于在网络事件流中估计潜在的社区结构。通过使用连续时间点过程潜在网络模型，可以捕捉动态事件到达的时间动态，并更新社区分配。 |

# 详细

[^1]: 生成分数阶扩散模型

    Generative Fractional Diffusion Models. (arXiv:2310.17638v1 [cs.LG])

    [http://arxiv.org/abs/2310.17638](http://arxiv.org/abs/2310.17638)

    该论文提出了一种基于分数阶扩散模型的生成模型，其中通过将分数布朗运动表示为奥恩斯坦-乌伦贝克过程的随机积分，实现了驱动噪声收敛到非马尔可夫过程的效果。这是第一个在具有无限二次变差的随机过程上构建生成模型的尝试。

    

    我们将基于分数布朗运动（FBM）的连续时间框架推广到基于分数布朗运动的近似形式。我们通过将FBM表示为家族奥恩斯坦-乌伦贝克过程的随机积分，推导出连续再参数化技巧和逆时模型，定义了具有驱动噪声收敛到无限二次变差的非马尔可夫过程的生成分数阶扩散模型（GFDM）。FBM的赫斯特指数$H \in (0,1)$ 可以控制路径变换分布的粗糙度。据我们所知，这是第一次尝试在具有无限二次变差的随机过程上建立生成模型。

    We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM) to an approximation of fractional Brownian motion (FBM). We derive a continuous reparameterization trick and the reverse time model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation. The Hurst index $H\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path. To the best of our knowledge, this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.
    
[^2]: 使用$\ell_1$正则化进行回归的近似留一法交叉验证（扩展版）

    Approximate Leave-one-out Cross Validation for Regression with $\ell_1$ Regularizers (extended version). (arXiv:2310.17629v1 [math.ST])

    [http://arxiv.org/abs/2310.17629](http://arxiv.org/abs/2310.17629)

    本论文提出了一个理论，用于处理广义线性模型家族中使用不可微分正则化器的问题。通过计算留一法交叉验证（LO）和近似留一法交叉验证（ALO）之间的误差，并考虑留一扰动的大小、样本大小、特征数量和正则化参数，我们得到了关于ALO误差的重要结果。

    

    在风险估计和模型选择中，外样误差（OO）是主要的关注量。留一法交叉验证（LO）提供了一个（几乎）无分布的、但计算复杂的方法来估计OO。最近的理论工作表明，近似留一法交叉验证（ALO）是对具有可微分正则化器的广义线性模型的LO（和OO）的计算有效和统计可靠的估计。对于涉及不可微分正则化器的问题，尽管有重要的经验证据，但对ALO误差的理论理解仍未知。本文提出了一个新的理论，适用于广义线性模型家族中具有不可微分正则化器的广泛问题。我们将ALO - LO的误差绑定在直观指标，如留一扰动的大小、样本大小n、特征数量p和正则化参数方面。因此，对于$\ell_1$正则化的问题，我们得到了如何计算和界定ALO误差的关键结果。

    The out-of-sample error (OO) is the main quantity of interest in risk estimation and model selection. Leave-one-out cross validation (LO) offers a (nearly) distribution-free yet computationally demanding approach to estimate OO. Recent theoretical work showed that approximate leave-one-out cross validation (ALO) is a computationally efficient and statistically reliable estimate of LO (and OO) for generalized linear models with differentiable regularizers. For problems involving non-differentiable regularizers, despite significant empirical evidence, the theoretical understanding of ALO's error remains unknown. In this paper, we present a novel theory for a wide class of problems in the generalized linear model family with non-differentiable regularizers. We bound the error |ALO - LO| in terms of intuitive metrics such as the size of leave-i-out perturbations in active sets, sample size n, number of features p and regularization parameters. As a consequence, for the $\ell_1$-regularized
    
[^3]: 通过部分正交性揭示嵌入的含义

    Uncovering Meanings of Embeddings via Partial Orthogonality. (arXiv:2310.17611v1 [cs.LG])

    [http://arxiv.org/abs/2310.17611](http://arxiv.org/abs/2310.17611)

    本文揭示了通过部分正交性来捕捉嵌入的语义独立性，提出了保持独立性的嵌入概念。

    

    机器学习工具通常依赖于将文本嵌入为实数向量。本文研究了语义结构如何在这些嵌入的代数结构中被编码。具体而言，我们研究了一个称为“语义独立性”的概念，该概念捕捉了“茄子”和“西红柿”相对于“蔬菜”的独立性。尽管这样的例子很直观，但很难形式化这样的语义独立性概念。关键观察是，任何合理的形式化都应遵守一组所谓的独立性公理，因此任何代数编码这种结构的方法也应遵守这些公理。这自然地导致我们使用部分正交性作为相关的代数结构。我们开发了理论和方法，可以证明部分正交性确实捕捉到了语义独立性。此外，我们还引入了保持独立性的嵌入概念，其中嵌入保持了独立性。

    Machine learning tools often rely on embedding text as vectors of real numbers. In this paper, we study how the semantic structure of language is encoded in the algebraic structure of such embeddings. Specifically, we look at a notion of ``semantic independence'' capturing the idea that, e.g., ``eggplant'' and ``tomato'' are independent given ``vegetable''. Although such examples are intuitive, it is difficult to formalize such a notion of semantic independence. The key observation here is that any sensible formalization should obey a set of so-called independence axioms, and thus any algebraic encoding of this structure should also obey these axioms. This leads us naturally to use partial orthogonality as the relevant algebraic structure. We develop theory and methods that allow us to demonstrate that partial orthogonality does indeed capture semantic independence. Complementary to this, we also introduce the concept of independence preserving embeddings where embeddings preserve the 
    
[^4]: 有限维和无限维希尔伯特空间中凸函数梯度流的定性差异

    A qualitative difference between gradient flows of convex functions in finite- and infinite-dimensional Hilbert spaces. (arXiv:2310.17610v1 [math.OC])

    [http://arxiv.org/abs/2310.17610](http://arxiv.org/abs/2310.17610)

    本文研究了凸函数梯度流在有限维和无限维希尔伯特空间中的差异，证明了在梯度流情况下，如果函数没有最小值，收敛速度可能非常缓慢；如果函数有最小值，过剩能量在时间上是可积的。此外，在希尔伯特空间中，过剩能量的衰减速度可以很慢，甚至可以与给定的单调递减可积函数一样慢。然而，在有限维情况下，存在比过剩能量衰减更慢的单调递减可积函数。

    

    我们研究了凸目标函数的梯度流/梯度下降和重球/加速梯度下降优化方法。在梯度流情况下，我们证明了以下结论：1. 如果$f$没有最小值，收敛$f(x_t)\to \inf f$可能非常缓慢。2. 如果$f$有最小值，过剩能量$f(x_t) - \inf f$在时间上是可积/可和的。特别地，当$t\to\infty$时，$f(x_t) - \inf f = o(1/t)$。3. 在希尔伯特空间中，这是最优的：$f(x_t) - \inf f$的衰减速度可以与任何给定的且在$\infty$处单调递减和可积的函数一样慢，即使对于固定的二次目标函数也是如此。4. 在有限维（或更一般地，对于所有有限长度的梯度流曲线），这并非最优：我们证明了对于$\mathbb R^d$上任何凸函数的梯度流，存在单调递减可积函数$g(t)$，其衰减速度比$f(x_t)-\inf f$更慢。例如，我们证明了任何梯度流$x_t$

    We consider gradient flow/gradient descent and heavy ball/accelerated gradient descent optimization for convex objective functions. In the gradient flow case, we prove the following:  1. If $f$ does not have a minimizer, the convergence $f(x_t)\to \inf f$ can be arbitrarily slow.  2. If $f$ does have a minimizer, the excess energy $f(x_t) - \inf f$ is integrable/summable in time. In particular, $f(x_t) - \inf f = o(1/t)$ as $t\to\infty$.  3. In Hilbert spaces, this is optimal: $f(x_t) - \inf f$ can decay to $0$ as slowly as any given function which is monotone decreasing and integrable at $\infty$, even for a fixed quadratic objective.  4. In finite dimension (or more generally, for all gradient flow curves of finite length), this is not optimal: We prove that there are convex monotone decreasing integrable functions $g(t)$ which decrease to zero slower than $f(x_t)-\inf f$ for the gradient flow of any convex function on $\mathbb R^d$. For instance, we show that any gradient flow $x_t$
    
[^5]: 在Wasserstein空间中通过近端梯度下降实现基于流的生成模型的收敛性

    Convergence of flow-based generative models via proximal gradient descent in Wasserstein space. (arXiv:2310.17582v1 [stat.ML])

    [http://arxiv.org/abs/2310.17582](http://arxiv.org/abs/2310.17582)

    本文通过在Wasserstein空间中应用近端梯度下降，证明了基于流的生成模型的收敛性，并提供了生成数据分布的理论保证。

    

    基于流的生成模型在计算数据生成和似然函数方面具有一定的优势，并且最近在实证表现上显示出竞争力。与相关基于分数扩散模型的积累理论研究相比，对于在正向（数据到噪声）和反向（噪声到数据）方向上都是确定性的流模型的分析还很少。本文通过在归一化流网络中实施Jordan-Kinderleherer-Otto（JKO）方案的所谓JKO流模型，提供了通过渐进流模型生成数据分布的理论保证。利用Wasserstein空间中近端梯度下降（GD）的指数收敛性，我们证明了通过JKO流模型生成数据的Kullback-Leibler（KL）保证为$O(\varepsilon^2)$，其中使用$N \lesssim \log (1/\varepsilon)$个JKO步骤（流中的$N$个残差块），其中$\varepsilon$是每步一阶条件的误差。

    Flow-based generative models enjoy certain advantages in computing the data generation and the likelihood, and have recently shown competitive empirical performance. Compared to the accumulating theoretical studies on related score-based diffusion models, analysis of flow-based models, which are deterministic in both forward (data-to-noise) and reverse (noise-to-data) directions, remain sparse. In this paper, we provide a theoretical guarantee of generating data distribution by a progressive flow model, the so-called JKO flow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a normalizing flow network. Leveraging the exponential convergence of the proximal gradient descent (GD) in Wasserstein space, we prove the Kullback-Leibler (KL) guarantee of data generation by a JKO flow model to be $O(\varepsilon^2)$ when using $N \lesssim \log (1/\varepsilon)$ many JKO steps ($N$ Residual Blocks in the flow) where $\varepsilon $ is the error in the per-step first-order condit
    
[^6]: 黑匣子内部：基于神经网络的实时预测美国衰退的研究

    Inside the black box: Neural network-based real-time prediction of US recessions. (arXiv:2310.17571v1 [econ.EM])

    [http://arxiv.org/abs/2310.17571](http://arxiv.org/abs/2310.17571)

    本研究使用神经网络对美国衰退进行实时预测，发现长短期记忆（LSTM）和门控循环单元（GRU）模型在长期预测任务中表现优于其他模型，并通过SHAP方法对GRU模型进行特征重要性评估。

    

    本研究使用前馈神经网络（FFN）和两种特定类型的循环神经网络，即长短期记忆（LSTM）和门控循环单元（GRU），对1967年至2021年的美国衰退进行建模。然后利用估计的模型对美国的大衰退和Covid-19衰退进行实时预测，将其预测性能与传统线性模型、逻辑回归模型（有和无岭回归惩罚）进行比较。外样本表现表明，LSTM和GRU在衰退预测领域具有应用潜力，特别适用于长期预测任务。相对于不同类型的统计性能指标，在5个预测周期内，它们优于其他类型的模型。而用Shapley增量解释（SHAP）方法评估衡量GRU在不同预测周期内的重要特征，以深入了解特征重要性。

    Feedforward neural network (FFN) and two specific types of recurrent neural network, long short-term memory (LSTM) and gated recurrent unit (GRU), are used for modeling US recessions in the period from 1967 to 2021. The estimated models are then employed to conduct real-time predictions of the Great Recession and the Covid-19 recession in US. Their predictive performances are compared to those of the traditional linear models, the logistic regression model both with and without the ridge penalty. The out-of-sample performance suggests the application of LSTM and GRU in the area of recession forecasting, especially for the long-term forecasting tasks. They outperform other types of models across 5 forecasting horizons with respect to different types of statistical performance metrics. Shapley additive explanations (SHAP) method is applied to the fitted GRUs across different forecasting horizons to gain insight into the feature importance. The evaluation of predictor importance differs b
    
[^7]: 计算机视觉模型的不稳定性是任务本身的必然结果

    Instability of computer vision models is a necessary result of the task itself. (arXiv:2310.17559v1 [cs.CV])

    [http://arxiv.org/abs/2310.17559](http://arxiv.org/abs/2310.17559)

    该论文研究了计算机视觉模型的不稳定性，并指出这是当前问题表述方式的必然结果。该问题无法完全消除，但可以通过提高图像分辨率、提供上下文信息、全面标注训练数据和防止攻击者访问计算机视觉系统来部分缓解该问题。

    

    由于当前计算机视觉模型的不稳定性而产生的对抗性样本是一个非常重要的话题，因为它们有可能危及任何应用。在本文中，我们证明了不稳定性是不可避免的，原因包括：a) 数据的对称性（平移不变性），b) 分类任务的范畴性质，以及c) 将图像分类为对象本身的基本差异。不完全标注的训练数据进一步加剧了这个问题。因此我们得出结论，不稳定性是当前计算机视觉问题表述方式所必然的结果。虽然问题无法完全消除，但通过分析原因，我们找到了一些方式来部分缓解该问题，包括：i) 提高图像的分辨率，ii) 为图像提供上下文信息，iii) 对训练数据进行全面标注，和iv) 防止攻击者频繁访问计算机视觉系统。

    Adversarial examples resulting from instability of current computer vision models are an extremely important topic due to their potential to compromise any application. In this paper we demonstrate that instability is inevitable due to a) symmetries (translational invariance) of the data, b) the categorical nature of the classification task, and c) the fundamental discrepancy of classifying images as objects themselves. The issue is further exacerbated by non-exhaustive labelling of the training data. Therefore we conclude that instability is a necessary result of how the problem of computer vision is currently formulated. While the problem cannot be eliminated, through the analysis of the causes, we have arrived at ways how it can be partially alleviated. These include i) increasing the resolution of images, ii) providing contextual information for the image, iii) exhaustive labelling of training data, and iv) preventing attackers from frequent access to the computer vision system.
    
[^8]: 学习带未知图核的规范化图均场博弈

    Learning Regularized Graphon Mean-Field Games with Unknown Graphons. (arXiv:2310.17531v1 [cs.GT])

    [http://arxiv.org/abs/2310.17531](http://arxiv.org/abs/2310.17531)

    我们设计了用于学习图核均值场博弈的强化学习算法，通过近端策略优化算法GMFG-PPO以及核嵌入的方法来估计未知图核。我们的算法在收敛速度和效率方面取得了改进，并提供了相关的理论分析。

    

    我们设计并分析了用于图均场博弈的强化学习算法。与之前需要精确图核值的工作不同，我们旨在学习当图核未知时的规范化图均场博弈的纳什均衡。我们的贡献有三个：首先，我们提出了用于图均场博弈的近端策略优化算法（GMFG-PPO），并通过一个估计预言机证明了其在T次迭代后以$O(T^{-1/3})$的速率收敛，改进了Xie等人（ICML，2021）的前期工作。其次，利用分布的核嵌入，我们设计了高效的算法来估计采样代理的转移核、奖励函数和图核。当代理的位置已知或未知时，推导了收敛速率。然后提供了运用GMFG-PPO优化算法和估计算法的结果。这些算法是首次专门设计用于学习图核的算法。

    We design and analyze reinforcement learning algorithms for Graphon Mean-Field Games (GMFGs). In contrast to previous works that require the precise values of the graphons, we aim to learn the Nash Equilibrium (NE) of the regularized GMFGs when the graphons are unknown. Our contributions are threefold. First, we propose the Proximal Policy Optimization for GMFG (GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$ after $T$ iterations with an estimation oracle, improving on a previous work by Xie et al. (ICML, 2021). Second, using kernel embedding of distributions, we design efficient algorithms to estimate the transition kernels, reward functions, and graphons from sampled agents. Convergence rates are then derived when the positions of the agents are either known or unknown. Results for the combination of the optimization algorithm GMFG-PPO and the estimation algorithm are then provided. These algorithms are the first specifically designed for learning graphons f
    
[^9]: 《低秩适应的表达能力》

    The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])

    [http://arxiv.org/abs/2310.17513](http://arxiv.org/abs/2310.17513)

    本文分析了低秩适应（LoRA）的表达能力，证明了对于全连接神经网络，当LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度）时，LoRA可以使任何模型f准确表示任何较小的目标模型f。对于Transformer网络，通过rank-（嵌入大小/ 2）的LoRA适配器可以使任何模型适应于相同大小的目标模型。

    

    低秩适应（LoRA）是一种参数高效的微调方法，利用矩阵的低秩适应性，在微调预训练模型（如大型语言模型和扩散模型）中得到了广泛应用。尽管在实践中取得了巨大成功，但是LoRA的理论基础在很大程度上尚未得到探索。本文通过从理论角度分析LoRA的表达能力，首次尝试弥合这一差距。我们证明了对于全连接神经网络，如果LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度），则LoRA可以使任何模型f准确表示任何较小的目标模型f。当LoRA-rank低于阈值时，我们还量化了逼近误差。对于Transformer网络，我们证明任何模型可以通过rank-（嵌入大小/ 2）的LoRA适配器适应于相同大小的目标模型。

    Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models. Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\overline{f}$ if LoRA-rank $\geq(\text{width of }f) \times \frac{\text{depth of }\overline{f}}{\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold. For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\frac{\text{embedding size}}{2})$ LoRA adapters.
    
[^10]: 评估过程中的偏见：基于优化的模型

    Bias in Evaluation Processes: An Optimization-Based Model. (arXiv:2310.17489v1 [cs.CY])

    [http://arxiv.org/abs/2310.17489](http://arxiv.org/abs/2310.17489)

    本研究提出了一个基于优化的模型，用于评估过程中的偏见分析。模型通过将真实效用分布转化为观察到的分布来考虑偏见，并对参数进行研究，以探究其对观察到的分布的影响。通过实证验证和数据拟合，我们证明了该模型的有效性。

    

    在诸如招生和招聘等设置中，关于个人社会显著属性的偏见已被广泛记录在评估过程中。我们将这样的评估过程视为将个人对任务的真实效用分布转化为观察到的分布，并将其建模为在信息约束下的损失最小化问题的解。我们的模型具有两个参数，被视为导致偏见的因素：信息约束中的资源信息交换参数和损失函数中的风险厌恶参数。我们表征了由我们的模型产生的分布，并研究了参数对观察到的分布的影响。我们模型的输出丰富了可用于捕捉观察评估中群组间变化的分布类。我们通过拟合真实世界数据集来进行实证验证，并使用它来研究介入效果。

    Biases with respect to socially-salient attributes of individuals have been well documented in evaluation processes used in settings such as admissions and hiring. We view such an evaluation process as a transformation of a distribution of the true utility of an individual for a task to an observed distribution and model it as a solution to a loss minimization problem subject to an information constraint. Our model has two parameters that have been identified as factors leading to biases: the resource-information trade-off parameter in the information constraint and the risk-averseness parameter in the loss function. We characterize the distributions that arise from our model and study the effect of the parameters on the observed distribution. The outputs of our model enrich the class of distributions that can be used to capture variation across groups in the observed evaluations. We empirically validate our model by fitting real-world datasets and use it to study the effect of interve
    
[^11]: 生成性扩散模型的统计热力学

    The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])

    [http://arxiv.org/abs/2310.17467](http://arxiv.org/abs/2310.17467)

    本文通过在生成性扩散模型中应用平衡统计力学的工具，揭示了这些模型中的二阶相变现象，并且认为这种稳定性形式是生成能力的关键。

    

    生成性扩散模型在生成建模的许多领域取得了惊人的表现。虽然这些模型的基本思想来自非平衡物理学，但本文中我们表明，可以用平衡统计力学的工具来理解这些模型的许多方面。利用这种重构，我们展示了生成性扩散模型经历了与对称性破缺现象相对应的二阶相变。我们认为，这导致了一种稳定性形式，它是生成能力的核心，并可以用一组平均场临界指数来描述。最后，我们根据热力学的公式分析了将扩散模型与关联记忆网络连接的最近研究。

    Generative diffusion models have achieved spectacular performance in many areas of generative modeling. While the fundamental ideas behind these models come from non-equilibrium physics, in this paper we show that many aspects of these models can be understood using the tools of equilibrium statistical mechanics. Using this reformulation, we show that generative diffusion models undergo second-order phase transitions corresponding to symmetry breaking phenomena. We argue that this lead to a form of instability that lies at the heart of their generative capabilities and that can be described by a set of mean field critical exponents. We conclude by analyzing recent work connecting diffusion models and associative memory networks in view of the thermodynamic formulations.
    
[^12]: 在使用双层优化中重新加权数据的挑战

    A Challenge in Reweighting Data with Bilevel Optimization. (arXiv:2310.17386v1 [stat.ML])

    [http://arxiv.org/abs/2310.17386](http://arxiv.org/abs/2310.17386)

    在重新加权数据的任务中，经典的双层优化方法可能会导致次优解，使得最终的数据权重非常稀疏，这解释了为什么这种方法在实践中很少被使用。

    

    在许多情况下，我们使用一个大的训练集来训练模型，目标是在一个不同分布的较小测试集上获得良好的性能。为训练集中的每个数据点学习一个权重是一个有吸引力的解决方案，因为理想情况下它可以自动学习每个训练点在测试集上的泛化重要性。这个任务通常被形式化为一个双层优化问题。传统的双层求解器基于一个热启动策略，即同时学习模型的参数和数据权重。我们展示了这种联合动态可能导致次优解，其中最终的数据权重非常稀疏。这一发现说明了数据重新加权的困难，并提示了为什么这种方法在实践中很少被使用的原因。

    In many scenarios, one uses a large training set to train a model with the goal of performing well on a smaller testing set with a different distribution. Learning a weight for each data point of the training set is an appealing solution, as it ideally allows one to automatically learn the importance of each training point for generalization on the testing set. This task is usually formalized as a bilevel optimization problem. Classical bilevel solvers are based on a warm-start strategy where both the parameters of the models and the data weights are learned at the same time. We show that this joint dynamic may lead to sub-optimal solutions, for which the final data weights are very sparse. This finding illustrates the difficulty of data reweighting and offers a clue as to why this method is rarely used in practice.
    
[^13]: 通过演示-正则化强化学习增强采样效率

    Demonstration-Regularized RL. (arXiv:2310.17303v1 [stat.ML])

    [http://arxiv.org/abs/2310.17303](http://arxiv.org/abs/2310.17303)

    通过演示-正则化提高强化学习的采样效率，并找到最优策略的样本复杂度，该复杂度与专家演示数量成反比。

    

    通过将专家演示纳入其中，可以在提高强化学习(SRL)的采样效率方面产生经验效果。本文在理论上量化这些额外信息降低了SRL的采样复杂性的程度。具体而言，我们研究了通过KL正则化利用专家演示学习的策略的演示-正则化强化学习。我们的研究发现，在有限状态下，在$\widetilde{\mathcal{O}}(\mathrm{Poly}(S,A,H)/(\varepsilon^2 N^{\mathrm{E}}))$的样本复杂度内，使用$N^{\mathrm{E}}$个专家演示能够找到最优策略，并在线性马尔科夫决策过程中，在$\widetilde{\mathcal{O}}(\mathrm{Poly}(d,H)/(\varepsilon^2 N^{\mathrm{E}}))$的样本复杂度内找到最优策略，其中$\varepsilon$是目标精度，$H$是规定，$A$是动作的数量，$S$是有限状态的数量，在线性情况下，$d$是特征空间的维数。

    Incorporating expert demonstrations has empirically helped to improve the sample efficiency of reinforcement learning (RL). This paper quantifies theoretically to what extent this extra information reduces RL's sample complexity. In particular, we study the demonstration-regularized reinforcement learning that leverages the expert demonstrations by KL-regularization for a policy learned by behavior cloning. Our findings reveal that using $N^{\mathrm{E}}$ expert demonstrations enables the identification of an optimal policy at a sample complexity of order $\widetilde{\mathcal{O}}(\mathrm{Poly}(S,A,H)/(\varepsilon^2 N^{\mathrm{E}}))$ in finite and $\widetilde{\mathcal{O}}(\mathrm{Poly}(d,H)/(\varepsilon^2 N^{\mathrm{E}}))$ in linear Markov decision processes, where $\varepsilon$ is the target precision, $H$ the horizon, $A$ the number of action, $S$ the number of states in the finite case and $d$ the dimension of the feature space in the linear case. As a by-product, we provide tight con
    
[^14]: 将循环引入人类：协作和可解释的贝叶斯优化

    Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])

    [http://arxiv.org/abs/2310.17273](http://arxiv.org/abs/2310.17273)

    协作和可解释的贝叶斯优化框架(CoExBO)在贝叶斯优化中引入了循环，平衡了人工智能和人类的合作关系。它利用偏好学习将用户见解融合到优化中，解释每次迭代的候选选择，从而增强用户对优化过程的信任，并提供无害保证。

    

    像许多优化器一样，贝叶斯优化在获得用户信任方面常常存在不足，因为其不透明性。虽然已经尝试开发面向人类的优化器，但它们通常假设用户知识是明确且无误的，并主要将用户作为优化过程的监督者。我们放宽了这些假设，提出了一种更平衡的人工智能和人类合作伙伴关系，即我们的协作和可解释的贝叶斯优化（CoExBO）框架。CoExBO使用偏好学习来无缝地将人类见解整合到优化中，从而产生与用户使用偏好一致的算法建议。CoExBO解释其每次迭代的候选选择，以培养信任，使用户更清楚地掌握优化的过程。此外，CoExBO提供无害保证，允许用户犯错误；即使在极端对抗性干扰下，算法也会渐进地收敛。

    Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to
    
[^15]: 超越神经网络：模型复杂性的经验探索

    Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity. (arXiv:2310.17247v1 [cs.LG])

    [http://arxiv.org/abs/2310.17247](http://arxiv.org/abs/2310.17247)

    本文发现神经网络中的grokking现象不仅局限于神经网络，还出现在其他算法和模型中。通过在数据集中添加虚假信息的维度，可以诱发grokking现象。研究表明，grokking现象在解决方案搜索受复杂性和错误指导的任何情况下可能发生。这对理解grokking现象提供了更广泛的理论支持。

    

    在某些情况下，神经网络展现出一种称为“grokking”的现象，即它们在验证集上实现完美或接近完美的准确度，而在训练集上则早已达到相同的性能。本文发现，grokking不仅限于神经网络，还出现在其他设置中，例如高斯过程（GP）分类、GP回归和线性回归。我们还发现了一种通过添加包含虚假信息的维度来诱发基于算法的数据集中的grokking现象的机制。非神经结构中的这种现象的存在证明了grokking不局限于SGD或权重范数正则化。相反，grokking可能发生在任何由复杂性和错误指导解决方案搜索的情况中。基于这一洞察和我们在贝叶斯神经网络（BNN）和GP回归模型的训练轨迹中观察到的进一步趋势，我们在grokking的更一般的理论方面取得了进展。

    In some settings neural networks exhibit a phenomenon known as grokking, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression and linear regression. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures provides evidence that grokking is not specific to SGD or weight norm regularisation. Instead, grokking may be possible in any setting where solution search is guided by complexity and error. Based on this insight and further trends we see in the training trajectories of a Bayesian neural network (BNN) and GP regression model, we make progress towards a more general theory of grokking. Spe
    
[^16]: 学习处理具有一般库存到货动态的库存控制策略

    Learning an Inventory Control Policy with General Inventory Arrival Dynamics. (arXiv:2310.17168v1 [cs.LG])

    [http://arxiv.org/abs/2310.17168](http://arxiv.org/abs/2310.17168)

    本文解决了学习具有一般库存到货动态下的库存控制策略的问题，同时允许修改订购数量以满足供应商的限制，并将周期性审核库存控制问题定义为外部决策过程。

    

    本文在面对一般到货动态的情况下解决了学习和回测库存控制策略的问题，我们将其称为数量随时间到货模型（QOT）。在实际供应链中，我们还允许修改订购数量以满足供应商的限制，例如订购最低数量和批次大小约束。据我们所知，这是第一篇处理任意到货动态或任意后续处理的订购数量的研究。在最近的工作（Madeka等，2022）的基础上，我们同样将周期性审核库存控制问题定义为外部决策过程，其中大部分状态不受代理的控制。Madeka等人（2022）展示了如何构建一个模拟器来回放历史数据以解决这类问题。在我们的例子中，我们将一个深度生成模型纳入到货过程的历史回放中。

    In this paper we address the problem of learning and backtesting inventory control policies in the presence of general arrival dynamics -- which we term as a quantity-over-time arrivals model (QOT). We also allow for order quantities to be modified as a post-processing step to meet vendor constraints such as order minimum and batch size constraints -- a common practice in real supply chains. To the best of our knowledge this is the first work to handle either arbitrary arrival dynamics or an arbitrary downstream post-processing of order quantities. Building upon recent work (Madeka et al., 2022) we similarly formulate the periodic review inventory control problem as an exogenous decision process, where most of the state is outside the control of the agent. Madeka et al. (2022) show how to construct a simulator that replays historic data to solve this class of problem. In our case, we incorporate a deep generative model for the arrivals process as part of the history replay. By formulat
    
[^17]: 大规模高斯过程通过交替投影

    Large-Scale Gaussian Processes via Alternating Projection. (arXiv:2310.17137v1 [cs.LG])

    [http://arxiv.org/abs/2310.17137](http://arxiv.org/abs/2310.17137)

    本论文提出了一种通过交替投影的迭代方法来解决高斯过程在大规模数据集上的训练问题，并证明了该方法具有线性收敛性。

    

    高斯过程（GP）超参数优化需要反复求解具有 nxn 核矩阵的线性系统。为了解决 O(n^3) 的时间复杂性问题，最近的研究采用了快速迭代数值方法，如共轭梯度（CG）。然而，随着数据集规模的增加，相应的核矩阵变得越来越病态，并且在没有分割的情况下仍然需要 O(n^2) 的空间。因此，虽然 CG 增加了可训练 GP 基于的数据集的大小，但现代数据集已经达到超出其适用范围的规模。在这项工作中，我们提出了一种只访问核矩阵的子块的迭代方法，有效地实现了小批量处理。我们的算法基于交替投影，每次迭代的时间和空间复杂度为 O(n)，解决了将 GP 扩展到非常大的数据集时的许多实际挑战。从理论上讲，我们证明了我们的方法具有线性收敛性，从实证的角度来看，我们证明了

    Gaussian process (GP) hyperparameter optimization requires repeatedly solving linear systems with $n \times n$ kernel matrices. To address the prohibitive $\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative numerical methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the corresponding kernel matrices become increasingly ill-conditioned and still require $\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling \emph{mini-batching}. Our algorithm, based on alternating projection, has $\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove our method enjoys linear convergence and empirically we demons
    
[^18]: CART在足够不纯度减少条件下的收敛性研究

    On the Convergence of CART under Sufficient Impurity Decrease Condition. (arXiv:2310.17114v1 [stat.ML])

    [http://arxiv.org/abs/2310.17114](http://arxiv.org/abs/2310.17114)

    本研究通过研究回归设置下CART的收敛性，建立了足够不纯度减少条件下CART预测误差的上界，并提供了易于验证的足够条件。这对于决策树模型的应用具有重要意义。

    

    决策树是一种灵活的机器学习模型，在许多应用中取得了成功。通常使用CART以递归贪婪的方式拟合决策树。本文研究了在回归设置下CART的收敛速率。首先，我们在足够不纯度减少条件下建立了CART的预测误差的上界，该结果改进了之前类似假设下的已知结果。此外，我们提供了一些示例证明误差界限无法通过常数或对数因子进一步改进。其次，我们介绍了一组易于验证的足够条件以满足不纯度减少条件。具体来说，我们证明了在加性模型的情况下，只要组件函数符合“局部反向波松不等式”，就可以满足不纯度减少条件。我们讨论了几个在非参数设置中众所周知的函数类。

    The decision tree is a flexible machine learning model that finds its success in numerous applications. It is usually fitted in a recursively greedy manner using CART. In this paper, we investigate the convergence rate of CART under a regression setting. First, we establish an upper bound on the prediction error of CART under a sufficient impurity decrease (SID) condition \cite{chi2022asymptotic} -- our result improves upon the known result by \cite{chi2022asymptotic} under a similar assumption. Furthermore, we provide examples that demonstrate the error bound cannot be further improved by more than a constant or a logarithmic factor. Second, we introduce a set of easily verifiable sufficient conditions for the SID condition. Specifically, we demonstrate that the SID condition can be satisfied in the case of an additive model, provided that the component functions adhere to a ``locally reverse Poincar{\'e} inequality". We discuss several well-known function classes in non-parametric es
    
[^19]: 良好的规则性创造了大学习率的隐性偏差：稳定的边界，平衡和弹射

    Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult. (arXiv:2310.17087v1 [cs.LG])

    [http://arxiv.org/abs/2310.17087](http://arxiv.org/abs/2310.17087)

    该论文研究了大学习率在非凸优化中产生的隐性偏差，包括稳定的边界、平衡和弹射，并通过发展新的全局收敛理论和研究良好规则性的目标函数，将这些现象归纳为同一现象的不同表现形式。

    

    当应用于非凸优化的梯度下降时，大学习率会产生各种隐性偏差，包括稳定的边界、平衡和弹射。这些现象无法用经典的优化理论很好地解释。尽管在理解这些隐性偏差方面已经取得了重要的理论进展，但仍然不清楚它们在哪些目标函数上会发生。本文对回答这个问题提供了一个初始的步骤，即这些隐性偏差实际上是同一冰山的各种尖端。当优化的目标函数具有一定的良好规则性，并与大学习率梯度下降对向更平坦区域移动的可证明偏好相结合时，就会产生这些非平凡的动力学现象。为了建立这个结果，我们发展了一个新的大学习率全局收敛理论，针对一族非凸函数。

    Large learning rates, when applied to gradient descent for nonconvex optimization, yield various implicit biases including the edge of stability (Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et al., 2020). These phenomena cannot be well explained by classical optimization theory. Though significant theoretical progress has been made in understanding these implicit biases, it remains unclear for which objective functions would they occur. This paper provides an initial step in answering this question, namely that these implicit biases are in fact various tips of the same iceberg. They occur when the objective function of optimization has some good regularity, which, in combination with a provable preference of large learning rate gradient descent for moving toward flatter regions, results in these nontrivial dynamical phenomena. To establish this result, we develop a new global convergence theory under large learning rates, for a family of nonconvex functi
    
[^20]: 带有大学习率的随机梯度下降的良性振荡

    Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates. (arXiv:2310.17074v1 [cs.LG])

    [http://arxiv.org/abs/2310.17074](http://arxiv.org/abs/2310.17074)

    通过大学习率的随机梯度下降训练的神经网络，由于其权重的振荡，能够在特征噪声数据上实现良好的泛化性能。

    

    在这项工作中，我们在理论上研究了使用大学习率训练的随机梯度下降（SGD）算法训练的神经网络（NN）的泛化特性。在这种训练方式下，我们的发现是，由于大学习率SGD训练引起的NN权重的振荡对NN的泛化有益，这有可能优于通过收敛较平滑的小学习率SGD训练的相同NN。基于这个发现，我们将这种现象称为“良性振荡”。我们解密这种现象的理论建立在深度学习的特征学习角度上。具体来说，我们考虑一个特征噪声数据生成模型，它包括（i）具有小的$\ell_2$-范数并出现在每个数据点中的弱特征；（ii）具有较大的$\ell_2$-范数但只出现在所有数据点的一部分中的强特征；和（iii）噪声。我们证明了通过振荡训练的NN能够在这个特征噪声数据生成模型上实现较好的泛化性能。

    In this work, we theoretically investigate the generalization properties of neural networks (NN) trained by stochastic gradient descent (SGD) algorithm with large learning rates. Under such a training regime, our finding is that, the oscillation of the NN weights caused by the large learning rate SGD training turns out to be beneficial to the generalization of the NN, which potentially improves over the same NN trained by SGD with small learning rates that converges more smoothly. In view of this finding, we call such a phenomenon "benign oscillation". Our theory towards demystifying such a phenomenon builds upon the feature learning perspective of deep learning. Specifically, we consider a feature-noise data generation model that consists of (i) weak features which have a small $\ell_2$-norm and appear in each data point; (ii) strong features which have a larger $\ell_2$-norm but only appear in a certain fraction of all data points; and (iii) noise. We prove that NNs trained by oscill
    
[^21]: Coreset马尔可夫链蒙特卡罗

    Coreset Markov Chain Monte Carlo. (arXiv:2310.17063v1 [stat.CO])

    [http://arxiv.org/abs/2310.17063](http://arxiv.org/abs/2310.17063)

    Coreset MCMC提出了一种新的方法，通过模拟马尔可夫链以更新coreset权重，从而实现在推断过程中降低计算成本的目的。与其他方法相比，Coreset MCMC提供了更高质量的后验近似和更高的采样效率。

    

    贝叶斯coreset是一个小而加权的数据子集，用于在推断过程中替代完整数据集以降低计算成本。然而，目前调整coreset权重的最先进方法耗时昂贵，需要复杂的用户输入，并对模型施加约束。在本文中，我们提出了一种新的方法——Coreset MCMC，该方法模拟了一个马尔可夫链，目标是coreset后验分布，同时使用相同的抽样更新coreset权重。Coreset MCMC易于实施和调整，并可与任何现有的MCMC内核一起使用。我们在一个代表性场景中分析了Coreset MCMC，以获得有关该方法收敛行为的关键见解。实证结果表明，与其他coreset构造方法相比，Coreset MCMC能够提供更高质量的后验近似和更低的计算成本。此外，与其他常规子采样MCMC方法相比，我们发现Coreset MCMC具有较高的采样效率。

    A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method -- Coreset MCMC -- that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze Coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that Coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that Coreset MCMC has a higher sampling efficiency with 
    
[^22]: 论高斯过程模型的可识别性和可解释性

    On the Identifiability and Interpretability of Gaussian Process Models. (arXiv:2310.17023v1 [stat.ML])

    [http://arxiv.org/abs/2310.17023](http://arxiv.org/abs/2310.17023)

    本文研究了高斯过程模型中的可识别性和可解释性问题。对于单输出情况，我们发现Matern核混合的平滑性由最不平滑的组件决定，并且混合核等价于最不平滑的核组件。在多输出模型中，我们证明了协方差矩阵的可识别性，这表明乘法混合是可行的。

    

    本文对使用加性Matern核在单输出高斯过程（GP）模型中的普遍做法进行了批判性分析，并探讨了用于多输出GP模型的乘法Matern核的性质。对于单输出情况，我们推导出一系列理论结果，表明Matern核混合的平滑性由最不平滑的组件决定，并且具有这样核的GP实际上等价于最不平滑的核组件。此外，我们证明了各个核组件中的混合权重或参数均无法识别。然后，我们将注意力转向多输出GP模型，并分析了乘法核$K(x,y) = AK_0(x,y)$中协方差矩阵$A$的可识别性，其中$K_0$是标准的单输出核，如Matern。我们展示了$A$在乘法常数上是可识别的，这表明乘法混合是可行的。

    In this paper, we critically examine the prevalent practice of using additive mixtures of Mat\'ern kernels in single-output Gaussian process (GP) models and explore the properties of multiplicative mixtures of Mat\'ern kernels for multi-output GP models. For the single-output case, we derive a series of theoretical results showing that the smoothness of a mixture of Mat\'ern kernels is determined by the least smooth component and that a GP with such a kernel is effectively equivalent to the least smooth kernel component. Furthermore, we demonstrate that none of the mixing weights or parameters within individual kernel components are identifiable. We then turn our attention to multi-output GP models and analyze the identifiability of the covariance matrix $A$ in the multiplicative kernel $K(x,y) = AK_0(x,y)$, where $K_0$ is a standard single output kernel such as Mat\'ern. We show that $A$ is identifiable up to a multiplicative constant, suggesting that multiplicative mixtures are well 
    
[^23]: 条件最优传输的高效神经网络方法及贝叶斯推断中的应用

    Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference. (arXiv:2310.16975v1 [stat.ML])

    [http://arxiv.org/abs/2310.16975](http://arxiv.org/abs/2310.16975)

    提出了两种神经网络方法来逼近静态和动态条件最优传输问题的解，实现了对条件概率分布的采样和密度估计，适用于贝叶斯推断。算法利用神经网络参数化传输映射以提高可扩展性。

    

    我们提出了两种神经网络方法，分别逼近静态和动态条件最优传输问题的解。这两种方法可以对条件概率分布进行采样和密度估计，这是贝叶斯推断中的核心任务。我们的方法将目标条件分布表示为可处理的参考分布的转换，因此属于测度传输的框架。在该框架中，COT映射是一个典型的选择，具有唯一性和单调性等可取的属性。然而，相关的COT问题在中等维度下计算具有挑战性。为了提高可扩展性，我们的数值算法利用神经网络对COT映射进行参数化。我们的方法充分利用了COT问题的静态和动态表达形式的结构。PCP-Map将条件传输映射建模为部分输入凸神经网络（PICNN）的梯度。

    We present two neural network approaches that approximate the solutions of static and dynamic conditional optimal transport (COT) problems, respectively. Both approaches enable sampling and density estimation of conditional probability distributions, which are core tasks in Bayesian inference. Our methods represent the target conditional distributions as transformations of a tractable reference distribution and, therefore, fall into the framework of measure transport. COT maps are a canonical choice within this framework, with desirable properties such as uniqueness and monotonicity. However, the associated COT problems are computationally challenging, even in moderate dimensions. To improve the scalability, our numerical algorithms leverage neural networks to parameterize COT maps. Our methods exploit the structure of the static and dynamic formulations of the COT problem. PCP-Map models conditional transport maps as the gradient of a partially input convex neural network (PICNN) and 
    
[^24]: Causal Q-Aggregation for CATE Model Selection（CATE模型选择中的因果Q集成）

    Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])

    [http://arxiv.org/abs/2310.16945](http://arxiv.org/abs/2310.16945)

    该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率

    

    准确估计条件平均处理效应（CATE）是个性化决策的核心。尽管有大量用于CATE估计的模型，但由于因果推断的基本问题，模型选择是一项非常棘手的任务。最近的实证工作提供了有利于具有双重鲁棒性质的代理损失度量和模型集成的证据。然而，对于这些模型的理论理解还不够。直接应用先前的理论工作会由于模型选择问题的非凸性而导致次优的预测模型选择率。我们提供了现有主要CATE集成方法的遗憾率，并提出了一种基于双重鲁棒损失的Q集成的新的CATE模型集成方法。我们的主要结果表明，因果Q集成在预测模型选择的遗憾率上达到了统计上的最优值为$\frac{\log(M)}{n}$（其中$M$为模型数，$n$为样本数），加上高阶估计误差项

    Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
    
[^25]: 多尺度扩散去噪平滑

    Multi-scale Diffusion Denoised Smoothing. (arXiv:2310.16779v1 [cs.LG])

    [http://arxiv.org/abs/2310.16779](http://arxiv.org/abs/2310.16779)

    本文研究了多尺度扩散去噪平滑的准确度和认证鲁棒性之间的权衡，并提出了一种在共享扩散模型上调整以实现平滑分类器鲁棒性的新方法。

    

    随着最近的扩散模型，随机平滑已成为少数几个切实可行的方法之一，为大规模预训练模型提供对抗鲁棒性。具体而言，可以通过简单的“去噪和分类”流程，即所谓的去噪平滑，在任何分类器上执行随机平滑，前提是有一个准确的去噪器可用，比如扩散模型。在本文中，我们研究了去噪平滑的准确度和认证鲁棒性之间的权衡：例如，我们质疑哪种扩散模型的表示形式能够最大化去噪平滑的认证鲁棒性。我们考虑了一个新的目标，旨在实现共同噪声水平下平滑分类器的鲁棒性，在共享扩散模型上进行精细调整，同时也为其认证鲁棒性补偿准确度的成本提供了一种新途径。

    Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple "denoise-and-classify" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing. We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness. This objective motivates us to fine-tune diffusion model (a) to perform consistent de
    
[^26]: 适应密度比估计的协变量偏移适应

    Covariate Shift Adaptation Robust to Density-Ratio Estimation. (arXiv:2310.16638v1 [stat.ME])

    [http://arxiv.org/abs/2310.16638](http://arxiv.org/abs/2310.16638)

    该论文研究了在协变量偏移下的密度比估计的罕见问题，提出了一种适应性方法来减轻密度比估计的偏差对模型的影响。

    

    在一种情况下，我们可以访问具有协变量和结果的训练数据，而测试数据只包含协变量。在这种情况下，我们的主要目标是预测测试数据中缺失的结果。为了实现这个目标，我们在协变量偏移下训练参数回归模型，其中训练数据和测试数据之间的协变量分布不同。对于这个问题，现有研究提出了通过使用密度比的重要性加权来进行协变量偏移适应的方法。该方法通过对训练数据损失进行加权平均，每个权重是训练数据和测试数据之间的协变量密度比的估计，以近似测试数据的风险。尽管它允许我们获得一个最小化测试数据风险的模型，但其性能严重依赖于密度比估计的准确性。此外，即使密度比可以一致地估计，密度比的估计误差也会导致回归模型的估计器产生偏差。

    Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model's 
    
[^27]: 评估非线性加性噪声模型的整体和部分因果良好规范性。

    Assessing the overall and partial causal well-specification of nonlinear additive noise models. (arXiv:2310.16502v1 [stat.ME])

    [http://arxiv.org/abs/2310.16502](http://arxiv.org/abs/2310.16502)

    提出了一种方法来评估非线性因果加性噪声模型的模型规范性问题，并识别出具有因果效应的预测变量。

    

    我们提出了一种方法来检测非线性因果加性噪声模型中的模型规范性问题，可能包括异方差性。我们旨在识别那些即使在这种模型规范问题存在的情况下，我们仍然可以推断出因果效应的预测变量。我们基于对多元观测数据分布的了解开发了一个通用框架，然后针对有限样本数据提出了一种算法，讨论了其渐近性质，并在模拟和真实数据上展示了其表现。

    We propose a method to detect model misspecifications in nonlinear causal additive and potentially heteroscedastic noise models. We aim to identify predictor variables for which we can infer the causal effect even in cases of such misspecification. We develop a general framework based on knowledge of the multivariate observational data distribution and we then propose an algorithm for finite sample data, discuss its asymptotic properties, and illustrate its performance on simulated and real data.
    
[^28]: 高维线性回归中经验贝叶斯估计的均值场方法

    A Mean Field Approach to Empirical Bayes Estimation in High-dimensional Linear Regression. (arXiv:2309.16843v1 [math.ST])

    [http://arxiv.org/abs/2309.16843](http://arxiv.org/abs/2309.16843)

    这项研究提出了一种在高维线性回归中进行经验贝叶斯估计的均值场方法，通过变分经验贝叶斯逼近先验分布并建立了渐近一致性，从而实现了计算上可行的贝叶斯推断。

    

    我们研究了高维线性回归中的经验贝叶斯估计。为了实现对潜在先验的计算有效估计，我们采用了变分经验贝叶斯方法，最初由Carbonetto和Stephens（2012）以及Kim等人（2022）引入。在对设计和先验做出温和假设的前提下，我们建立了非参数最大似然估计器（NPMLE）及其（可计算的）朴素均值场变分代理的渐近一致性。在假定朴素均值场逼近具有占优解的基础上，我们开发了一种计算效率高的近似正则分布的方法，并在1-Wasserstein度量下验证了其准确性。这使得贝叶斯推断可以在计算上可行，例如构建具有平均覆盖保证的后验可信区间，回归系数的贝叶斯最优估计，非空比例的估计等。我们的分析涵盖了...

    We study empirical Bayes estimation in high-dimensional linear regression. To facilitate computationally efficient estimation of the underlying prior, we adopt a variational empirical Bayes approach, introduced originally in Carbonetto and Stephens (2012) and Kim et al. (2022). We establish asymptotic consistency of the nonparametric maximum likelihood estimator (NPMLE) and its (computable) naive mean field variational surrogate under mild assumptions on the design and the prior. Assuming, in addition, that the naive mean field approximation has a dominant optimizer, we develop a computationally efficient approximation to the oracle posterior distribution, and establish its accuracy under the 1-Wasserstein metric. This enables computationally feasible Bayesian inference; e.g., construction of posterior credible intervals with an average coverage guarantee, Bayes optimal estimation for the regression coefficients, estimation of the proportion of non-nulls, etc. Our analysis covers both 
    
[^29]: 通过条件置换进行统计有效的变量重要性评估

    Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])

    [http://arxiv.org/abs/2309.07593](http://arxiv.org/abs/2309.07593)

    本论文提出了一种通过条件置换进行统计有效的变量重要性评估的方法。实证结果表明，这种方法克服了标准置换重要性的局限性，并在深度神经网络中表现出最高的准确性。

    

    在使用复杂学习器（如深度神经网络）处理大规模数据时，变量重要性评估已成为机器学习应用中的关键步骤。目前，基于移除的重要性评估是参考方法，特别是在需要统计保证来验证变量包含性时。通常，它们使用变量置换方案来实现。然而，这些方法在存在协变量之间的相关性时容易将不重要的变量误识别为重要变量。本文提出了一种系统方法来研究条件置换重要性（Conditional Permutation Importance，CPI），它是模型无关且计算效率高的方法，并提供了基准测试，用于评估当前最先进的变量重要性估计器。理论和实证结果表明，CPI通过提供准确的I型错误控制，克服了标准置换重要性的局限性。当与深度神经网络一起使用时，CPI始终显示出最高的准确性。

    Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that $\textit{CPI}$ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, $\textit{CPI}$ consistently showed top accuracy ac
    
[^30]: 蒙特卡洛引导扩散的贝叶斯线性逆问题研究

    Monte Carlo guided Diffusion for Bayesian linear inverse problems. (arXiv:2308.07983v1 [stat.ML])

    [http://arxiv.org/abs/2308.07983](http://arxiv.org/abs/2308.07983)

    本研究提出了一种在贝叶斯框架下利用蒙特卡洛方法解决非完备线性逆问题的算法，该算法通过利用基于得分的生成模型的先验结构和Feynman-Kac模型，并进行顺序蒙特卡洛采样，表现出比竞争对手更好的性能。

    

    非完备的线性逆问题经常在各种应用中出现，从计算摄影到医学成像。最近的研究集中于使用基于得分的生成模型（SGMs），在填补问题中产生具有感知合理性的图像来解决这些问题。本研究利用SGM定义的先验结构来制定贝叶斯框架下的恢复问题，将其作为Feynman-Kac模型，该模型改编自用于构建基于得分扩散的前向扩散模型。为了解决这个Feynman-Kac问题，我们提出使用顺序蒙特卡洛方法。所提出的算法MCGdiff在理论上是有根据的，并且我们提供了数值模拟结果，表明它在处理非完备逆问题时优于竞争对手的基准方法。

    Ill-posed linear inverse problems that combine knowledge of the forward measurement model with prior models arise frequently in various applications, from computational photography to medical imaging. Recent research has focused on solving these problems with score-based generative models (SGMs) that produce perceptually plausible images, especially in inpainting problems. In this study, we exploit the particular structure of the prior defined in the SGM to formulate recovery in a Bayesian framework as a Feynman--Kac model adapted from the forward diffusion model used to construct score-based diffusion. To solve this Feynman--Kac problem, we propose the use of Sequential Monte Carlo methods. The proposed algorithm, MCGdiff, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems.
    
[^31]: 轨迹对齐：通过分叉理论理解稳定边缘现象

    Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory. (arXiv:2307.04204v1 [cs.LG])

    [http://arxiv.org/abs/2307.04204](http://arxiv.org/abs/2307.04204)

    本文通过实证研究证明了梯度下降轨迹上的稳定边缘现象，并且对于特定的网络结构进行了轨迹对齐分析，建立了渐进尖锐化和稳定边缘现象，扩展了当前文献的研究结果。

    

    Cohen等人（2021）通过实证研究梯度下降（GD）轨迹上损失Hessian的最大特征值（即锐度），观察到一种称为稳定边缘（EoS）的现象。锐度在培训的早期阶段增加（称为渐进尖锐化），最终接近阈值$2/\text{(步长)}$附近停滞。本文通过实证研究首先证明了当EoS现象发生时，不同的GD轨迹（经过适当的参数化）在一个特定的分叉图上对齐，而与初始化无关。然后，我们对一个二层全连接线性网络和一个使用单个数据点训练的单神经元非线性网络严格证明了这种轨迹对齐现象。我们的轨迹对齐分析建立了渐进尖锐化和EoS现象，涵盖并扩展了最近文献中的研究结果。

    Cohen et al. (2021) empirically study the evolution of the largest eigenvalue of the loss Hessian, also known as sharpness, along the gradient descent (GD) trajectory and observe a phenomenon called the Edge of Stability (EoS). The sharpness increases at the early phase of training (referred to as progressive sharpening), and eventually saturates close to the threshold of $2 / \text{(step size)}$. In this paper, we start by demonstrating through empirical studies that when the EoS phenomenon occurs, different GD trajectories (after a proper reparameterization) align on a specific bifurcation diagram independent of initialization. We then rigorously prove this trajectory alignment phenomenon for a two-layer fully-connected linear network and a single-neuron nonlinear network trained with a single data point. Our trajectory alignment analysis establishes both progressive sharpening and EoS phenomena, encompassing and extending recent findings in the literature.
    
[^32]: 图神经网络中特征演化的神经塌陷视角

    A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks. (arXiv:2307.01951v1 [cs.LG])

    [http://arxiv.org/abs/2307.01951](http://arxiv.org/abs/2307.01951)

    本文以节点分类为例，通过“神经塌陷”现象探索图神经网络中特征演化的机制，并发现即使在节点分类情况下，特征的类内变异性也会减少，但不及基于实例的情况那么显著。

    

    图神经网络（GNNs）在图结构数据的分类任务中越来越受欢迎。然而，GNNs中图拓扑和特征演化之间的相互作用尚不清楚。本文以基于节点的分类为主题，以随机块模型图上的社区检测为例，通过“神经塌陷”现象来探索特征演化。当训练基于实例的深度分类器（例如图像分类）超过零训练误差点时，神经塌陷表现为最深层特征的类内变异性减少，并且类均值与特定的对称结构更加对齐。我们先从实证研究开始，显示类内变异性的减少在基于节点的分类环境中也普遍存在，但不及基于实例的案例那么明显。然后，我们从理论上研究了这种区别。具体而言，我们证明了即使在不考虑激活，图拓扑信息也能导致特征崩溃。

    Graph neural networks (GNNs) have become increasingly popular for classification tasks on graph-structured data. Yet, the interplay between graph topology and feature evolution in GNNs is not well understood. In this paper, we focus on node-wise classification, illustrated with community detection on stochastic block model graphs, and explore the feature evolution through the lens of the "Neural Collapse" (NC) phenomenon. When training instance-wise deep classifiers (e.g. for image classification) beyond the zero training error point, NC demonstrates a reduction in the deepest features' within-class variability and an increased alignment of their class means to certain symmetric structures. We start with an empirical study that shows that a decrease in within-class variability is also prevalent in the node-wise classification setting, however, not to the extent observed in the instance-wise case. Then, we theoretically study this distinction. Specifically, we show that even an "optimis
    
[^33]: 用于噪声混合物中目标信号恢复的统计分量分离

    Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures. (arXiv:2306.15012v1 [stat.ML])

    [http://arxiv.org/abs/2306.15012](http://arxiv.org/abs/2306.15012)

    本论文提出了一种用于从噪声混合物中恢复目标信号的统计分量分离方法，并且在图像降噪任务中展示了其优于标准降噪方法的表现。

    

    当只对给定信号的特定属性感兴趣时，从一个加性混合物中分离信号可能是一个不必要地困难的问题。在本工作中，我们解决了更简单的“统计分量分离”问题，该问题专注于从噪声混合物中恢复目标信号的预定义统计描述量。假设可以获得噪声过程的样本，我们研究了一种方法，该方法旨在使受噪声样本污染的解决方案候选的统计特性与观测的混合物的统计特性匹配。首先，我们使用具有解析可追踪计算的简单示例分析了该方法的行为。然后，我们将其应用于图像降噪环境中，使用了1）基于小波的描述符，2）针对天体物理和ImageNet数据的ConvNet-based描述符。在第一种情况下，我们展示了我们的方法在大多数情况下比标准降噪方法更好地恢复了目标数据的描述符。此外，尽管不是为此目的构建的，它也表现出对目标信号描述符恢复的潜力。

    Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler "statistical component separation" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it pe
    
[^34]: 高斯成员推断隐私

    Gaussian Membership Inference Privacy. (arXiv:2306.07273v1 [cs.LG])

    [http://arxiv.org/abs/2306.07273](http://arxiv.org/abs/2306.07273)

    本文提出了$f$-成员推断隐私($f$-MIP)概念，并分析了似然比成员推断攻击，提出了$\mu$-高斯成员推断隐私($\mu$-GMIP)保证，同时提供了一种分析性的成员推断攻击方法，避免了训练大量影子模型。强调了方差的重要性。

    

    我们提出了一个新的隐私概念，称为$f$-成员推断隐私($f$-MIP)，它明确考虑了在成员推断攻击威胁模型下现实对手的能力。通过这样做，$f$-MIP提供了可解释的隐私保证和改进的效用(例如更好的分类准确率)。我们对噪声随机梯度下降(SGD)的似然比成员推断攻击进行了新颖的理论分析，得到了一个参数化的$f$-MIP保证族，称为$\mu$-高斯成员推断隐私($\mu$-GMIP)。我们的分析还产生了一种分析性的成员推断攻击，与以前的方法相比具有显著优势。首先，与现有方法不同，我们的攻击不需要训练数百个影子模型来逼近似然比。其次，我们的分析攻击使得$f$-MIP的简单审计成为可能。最后，我们的分析强调了方差的重要性。

    We propose a new privacy notion called $f$-Membership Inference Privacy ($f$-MIP), which explicitly considers the capabilities of realistic adversaries under the membership inference attack threat model. By doing so $f$-MIP offers interpretable privacy guarantees and improved utility (e.g., better classification accuracy). Our novel theoretical analysis of likelihood ratio-based membership inference attacks on noisy stochastic gradient descent (SGD) results in a parametric family of $f$-MIP guarantees that we refer to as $\mu$-Gaussian Membership Inference Privacy ($\mu$-GMIP). Our analysis additionally yields an analytical membership inference attack that offers distinct advantages over previous approaches. First, unlike existing methods, our attack does not require training hundreds of shadow models to approximate the likelihood ratio. Second, our analytical attack enables straightforward auditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the importance of vario
    
[^35]: 一般转换构建一致的在线近似算法

    General Transformation for Consistent Online Approximation Algorithms. (arXiv:2306.07163v1 [cs.LG])

    [http://arxiv.org/abs/2306.07163](http://arxiv.org/abs/2306.07163)

    本文提出一个转换框架，可以将离线逼近算法转换为具有低ε-近似遗憾的在线算法，并成功应用于多种问题并实现了多项式时间的近似效果。

    

    我们提出了一个转换框架，可用于从离线逼近算法中开发具有低ε-近似遗憾的在线算法。我们首先给出了一个将具有低平均敏感度的离线逼近算法转换为具有低ε-近似遗憾的在线算法的通用约简定理。然后，我们展示了可以使用coreset构造方法将离线逼近算法转换为低敏感度版本。为了展示我们方法的多样性，我们将其应用于各种问题，包括在线(k，z)-聚类、在线矩阵逼近和在线回归，并成功地为每个问题实现了对数多项式ε-近似遗憾。此外，我们证明，在所有三种情况下，我们的算法也享有低不一致性，这可能是某些在线应用程序所需的。

    We introduce a transformation framework that can be utilized to develop online algorithms with low $\epsilon$-approximate regret in the random-order model from offline approximation algorithms. We first give a general reduction theorem that transforms an offline approximation algorithm with low average sensitivity to an online algorithm with low $\epsilon$-approximate regret. We then demonstrate that offline approximation algorithms can be transformed into a low-sensitivity version using a coreset construction method. To showcase the versatility of our approach, we apply it to various problems, including online $(k,z)$-clustering, online matrix approximation, and online regression, and successfully achieve polylogarithmic $\epsilon$-approximate regret for each problem. Moreover, we show that in all three cases, our algorithm also enjoys low inconsistency, which may be desired in some online applications.
    
[^36]: 用Johnson-Lindenstrauss矩阵进行标签嵌入

    Label Embedding by Johnson-Lindenstrauss Matrices. (arXiv:2305.19470v1 [cs.LG])

    [http://arxiv.org/abs/2305.19470](http://arxiv.org/abs/2305.19470)

    这篇论文提出了基于JLMs的标签嵌入方法，将多元分类问题转化为有限回归问题，具有较高的计算效率和预测准确性。

    

    我们提出了一个基于Johnson-Lindenstrauss矩阵（JLMs）的简单且可扩展的极端多元分类框架。利用JLM的列来嵌入标签，将一个C类分类问题转化为具有$\cO(\log C)$输出维度的回归问题。我们得出了一个超量风险限制，阐明了计算效率和预测准确性之间的权衡，并进一步表明，在Massart噪声条件下，降维的惩罚会消失。我们的方法易于并行化，并且实验结果展示了在大规模应用中其有效性和可扩展性。

    We present a simple and scalable framework for extreme multiclass classification based on Johnson-Lindenstrauss matrices (JLMs). Using the columns of a JLM to embed the labels, a $C$-class classification problem is transformed into a regression problem with $\cO(\log C)$ output dimension. We derive an excess risk bound, revealing a tradeoff between computational efficiency and prediction accuracy, and further show that under the Massart noise condition, the penalty for dimension reduction vanishes. Our approach is easily parallelizable, and experimental results demonstrate its effectiveness and scalability in large-scale applications.
    
[^37]: 具有对抗性损失和转换的无遗憾在线强化学习

    No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions. (arXiv:2305.17380v1 [cs.LG])

    [http://arxiv.org/abs/2305.17380](http://arxiv.org/abs/2305.17380)

    本文提出了一种算法，可以处理对抗性损失和对抗性转换，且后悔逐渐增加与对手的恶意程度成比例。

    

    现有的对抗性马尔可夫决策过程的在线学习算法可以在与对手的$ T $轮交互之后实现${ O}(\sqrt{T})$的后悔，即使损失函数是由对手任意选择的，但前提是转移函数必须固定。这是因为已经有研究表明，对抗性转移函数使无悔学习变得不可能。尽管存在这种不可能性结果，我们开发了可以处理对抗性损失和对抗性转换的算法，后悔逐渐增加与对手的恶意程度成比例。更具体地说，我们首先提出了一种算法，它的后悔为$\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$，其中$C^{\textsf{P}}$表示转换函数的对抗性，最多可以为${O}(T)$。虽然此算法本身需要$C^{\textsf{P}}$的知识，但我们还开发了一种黑盒缩减方法来消除此要求。此外，我们还展示了一种进一步的方法，使得算法能够处理任意长度的锚定期。

    Existing online learning algorithms for adversarial Markov Decision Processes achieve ${O}(\sqrt{T})$ regret after $T$ rounds of interactions even if the loss functions are chosen arbitrarily by an adversary, with the caveat that the transition function has to be fixed. This is because it has been shown that adversarial transition functions make no-regret learning impossible. Despite such impossibility results, in this work, we develop algorithms that can handle both adversarial losses and adversarial transitions, with regret increasing smoothly in the degree of maliciousness of the adversary. More concretely, we first propose an algorithm that enjoys $\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$ regret where $C^{\textsf{P}}$ measures how adversarial the transition functions are and can be at most ${O}(T)$. While this algorithm itself requires knowledge of $C^{\textsf{P}}$, we further develop a black-box reduction approach that removes this requirement. Moreover, we also show that furth
    
[^38]: 拉普拉斯逼近神经加性模型：贝叶斯推理提高解释性

    Laplace-Approximated Neural Additive Models: Improving Interpretability with Bayesian Inference. (arXiv:2305.16905v1 [stat.ML])

    [http://arxiv.org/abs/2305.16905](http://arxiv.org/abs/2305.16905)

    本文提出了拉普拉斯逼近神经加性模型，该模型从贝叶斯角度考虑加性结构，在恢复的特征交互中提供可信区间，提供可处理的边缘似然估计，可用于执行隐式特征选择并对特征对进行排名。

    

    深度神经网络（DNN）在许多领域取得了成功应用，但它们的黑盒性质阻碍了解释性。神经加性模型（NAM）解决了这个问题，将网络分为加性子网络，从而使输入特征和预测之间的交互变得明显。在本文中，我们从贝叶斯角度考虑加性结构，并开发了一个实用的拉普拉斯逼近方法。这种方法在以下三个方面提高了可解释性：a）它通过估计子网络的函数空间不确定性为恢复的特征交互提供可信区间；b）它提供可处理的边缘似然估计，可用于通过经验贝叶斯过程执行特征的隐式选择；c）它可用于对特征对进行排名，作为精细调整的交互模型候选。我们在几个基准数据集上实证表明，我们提出的拉普拉斯逼近神经加性模型（LA-NAM）提高了NAM模型的可解释性，并进一步揭示了学习到的子网络的交互结构。

    Deep neural networks (DNNs) have found successful applications in many fields, but their black-box nature hinders interpretability. This is addressed by the neural additive model (NAM), in which the network is divided into additive sub-networks, thus making apparent the interaction between input features and predictions. In this paper, we approach the additive structure from a Bayesian perspective and develop a practical Laplace approximation. This enhances interpretability in three primary ways: a) It provides credible intervals for the recovered feature interactions by estimating function-space uncertainty of the sub-networks; b) it yields a tractable estimate of the marginal likelihood, which can be used to perform an implicit selection of features through an empirical Bayes procedure; and c) it can be used to rank feature pairs as candidates for second-order interactions in fine-tuned interaction models. We show empirically that our proposed Laplace-approximated NAM (LA-NAM) improv
    
[^39]: 统一GAN和基于分数扩散的粒子生成模型

    Unifying GANs and Score-Based Diffusion as Generative Particle Models. (arXiv:2305.16150v1 [cs.LG])

    [http://arxiv.org/abs/2305.16150](http://arxiv.org/abs/2305.16150)

    本文提出了一个新框架，将生成器训练作为粒子模型的一个推广，从而统一了粒子和对抗生成模型。这个框架可以将生成器集成到基于分数扩散模型中，并在没有生成器的情况下训练GAN。

    

    基于粒子的深度生成模型，例如梯度流和基于分数的扩散模型，由于其惊人的性能而最近受到关注。传统上，通过微分方程来移动粒子分布的方法被普遍认为是与以前广泛使用的生成对抗网络（GAN）相对立的，后者涉及到训练一个向前的生成器网络。在本文中，我们质疑这种解释，并提出了一个统一粒子和对抗生成模型的新框架，通过将生成器训练作为粒子模型的推广。这表明，生成器是任何这样的生成模型的可选附件。因此，将生成器集成到基于分数扩散模型中，并在没有生成器的情况下训练GAN自然地出现在我们的框架中。我们通过实证测试这些原始模型的可行性，这些模型是我们框架可能应用的概念证明。

    Particle-based deep generative models, such as gradient flows and score-based diffusion models, have recently gained traction thanks to their striking performance. Their principle of displacing particle distributions by differential equations is conventionally seen as opposed to the previously widespread generative adversarial networks (GANs), which involve training a pushforward generator network. In this paper, we challenge this interpretation and propose a novel framework that unifies particle and adversarial generative models by framing generator training as a generalization of particle models. This suggests that a generator is an optional addition to any such generative model. Consequently, integrating a generator into a score-based diffusion model and training a GAN without a generator naturally emerge from our framework. We empirically test the viability of these original models as proofs of concepts of potential applications of our framework.
    
[^40]: 带小总成本限制的上下文信息决策问题与背包问题的相关性，及其对公平性的应用

    Small Total-Cost Constraints in Contextual Bandits with Knapsacks, with Application to Fairness. (arXiv:2305.15807v1 [stat.ML])

    [http://arxiv.org/abs/2305.15807](http://arxiv.org/abs/2305.15807)

    本文提出了带总成本限制的上下文信息决策问题（CBwK），通过对术语进行重新组合，对CBwK进行了优化，支持小于$T^{3/4}$的总成本约束，并通过对偶策略实现了平等的成本限制。

    

    本文考虑了带有背包问题的上下文信息决策问题（CBwK），每一轮获得一个标量奖励和一个向量值的成本。我们的目标是最大化累计的奖励，并确保累计成本低于某个预定的成本限制。我们假设环境来自一个连续集合，成本可以带符号，并且未知的期望奖励和成本函数可以被一致地估计，这是文献中的一个典型假设。在这种情况下，迄今为止总成本约束至少要为$T^{3/4}$，其中$T$是轮数，并且甚至通常被假定为与$T$线性相关。然而，我们受到鼓舞，使用CBwK来强制实施实现组之间平均成本平等的公平性约束：与相应成本约束相关的预算应尽可能接近于阶数为$\sqrt{T}$级别的自然偏差。为此，我们介绍了一种基于对偶策略的方法。

    We consider contextual bandit problems with knapsacks [CBwK], a problem where at each round, a scalar reward is obtained and vector-valued costs are suffered. The learner aims to maximize the cumulative rewards while ensuring that the cumulative costs are lower than some predetermined cost constraints. We assume that contexts come from a continuous set, that costs can be signed, and that the expected reward and cost functions, while unknown, may be uniformly estimated -- a typical assumption in the literature. In this setting, total cost constraints had so far to be at least of order $T^{3/4}$, where $T$ is the number of rounds, and were even typically assumed to depend linearly on $T$. We are however motivated to use CBwK to impose a fairness constraint of equalized average costs between groups: the budget associated with the corresponding cost constraints should be as close as possible to the natural deviations, of order $\sqrt{T}$. To that end, we introduce a dual strategy based on 
    
[^41]: 学习率无关的约束域Bayesian推断

    Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v1 [stat.ML])

    [http://arxiv.org/abs/2305.14943](http://arxiv.org/abs/2305.14943)

    我们的算法是学习率无关的约束域采样算法，并提出了一个统一框架，能够处理多种约束采样问题，实现了与现有算法相竞争的性能。

    

    我们引入了一套新的基于粒子的算法，用于在约束域内进行采样，这是完全与学习率无关的。我们的方法利用了凸优化中的硬币投注思想，以及约束采样作为概率测度空间上镜像优化问题的观点。基于这个观点，我们还提出了一个统一框架，用于几种现有的约束采样算法，包括镜像Langevin动力学和镜像Stein变分梯度下降。我们在一系列的数值实验中展示了算法的性能，包括从单纯形目标进行采样、带公平性约束进行采样以及后选择推断中的约束采样问题。我们的结果表明，我们的算法在不需要调整任何超参数的情况下，实现了与现有约束采样方法相竞争的性能。

    We introduce a suite of new particle-based algorithms for sampling on constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.
    
[^42]: 警惕尖峰：固定维度下内核和神经网络的良性过拟合

    Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension. (arXiv:2305.14077v1 [stat.ML])

    [http://arxiv.org/abs/2305.14077](http://arxiv.org/abs/2305.14077)

    这篇论文研究了固定维度下内核和神经网络的良性过拟合，发现良性过拟合的关键在于估计器的平滑度而不是维数，并证明在固定维度下中度导数的良性过拟合是不可能的。相反，我们证明了用序列核进行回归是可能出现良性过拟合的。

    

    过度参数化的神经网络训练达到接近零的训练误差的成功引起了人们对良性过拟合现象的极大兴趣，即使估计器插值嘈杂的训练数据，它们还是具有统计一致性。尽管某些学习方法的固定维度下已经确定了良性过拟合，但目前的文献表明，对于典型内核方法和宽神经网络的回归，良性过拟合需要高维度设置，其中维数随着样本大小的增加而增加。本文表明，估计器的平滑度是关键，而不是维数：只有当估计器的导数足够大时，良性过拟合才可能发生。我们将现有的不一致性结果推广到非插值模型和更多内核，以表明在固定维度下中度导数的良性过拟合是不可能的。相反，我们证明了用序列核进行回归是可能出现良性过拟合的。

    The success of over-parameterized neural networks trained to near-zero training error has caused great interest in the phenomenon of benign overfitting, where estimators are statistically consistent even though they interpolate noisy training data. While benign overfitting in fixed dimension has been established for some learning methods, current literature suggests that for regression with typical kernel methods and wide neural networks, benign overfitting requires a high-dimensional setting where the dimension grows with the sample size. In this paper, we show that the smoothness of the estimators, and not the dimension, is the key: benign overfitting is possible if and only if the estimator's derivatives are large enough. We generalize existing inconsistency results to non-interpolating models and more kernels to show that benign overfitting with moderate derivatives is impossible in fixed dimension. Conversely, we show that benign overfitting is possible for regression with a seque
    
[^43]: 平方神经分布族：一种新的可计算密度模型类

    Squared Neural Families: A New Class of Tractable Density Models. (arXiv:2305.13552v1 [cs.LG])

    [http://arxiv.org/abs/2305.13552](http://arxiv.org/abs/2305.13552)

    提出一种新的可计算密度模型类——平方神经分布族，其通过对神经网络的2范数进行平方和基于某个基础度量进行归一化，严格推广了经典指数族，具有闭性条件推断和可计算的边际分布。

    

    概率分布的灵活模型是许多机器学习任务的重要组成部分。我们开发并研究了一种新的概率分布类别，称为平方神经分布族（SNEFY），通过对神经网络的2范数进行平方并基于某个基础度量进行归一化。类似于无穷宽的神经网络和高斯过程之间的广泛联系的推理，我们展示了在许多感兴趣的情况下，SNEFY具有封闭形式的标准化常数，因此是灵活且完全可计算密度模型。SNEFY严格推广了经典的指数族，对于条件推断具有闭性，并且具有可计算的边际分布。我们在各种密度估计和条件密度估计任务中展示其实用性。

    Flexible models for probability distributions are an essential ingredient in many machine learning tasks. We develop and investigate a new class of probability distributions, which we call a Squared Neural Family (SNEFY), formed by squaring the 2-norm of a neural network and normalising it with respect to a base measure. Following the reasoning similar to the well established connections between infinitely wide neural networks and Gaussian processes, we show that SNEFYs admit a closed form normalising constants in many cases of interest, thereby resulting in flexible yet fully tractable density models. SNEFYs strictly generalise classical exponential families, are closed under conditioning, and have tractable marginal distributions. Their utility is illustrated on a variety of density estimation and conditional density estimation tasks. Software available at https://github.com/RussellTsuchida/snefy.
    
[^44]: 非参数方法下的无分布模型无偏回归校准

    Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods. (arXiv:2305.12283v1 [cs.LG])

    [http://arxiv.org/abs/2305.12283](http://arxiv.org/abs/2305.12283)

    本文提出一种基于非参数方法的无分布模型无偏回归校准方法，具有计算效率和统计一致性，并建立了校准误差的上限和下限的统计保证和优势。

    

    本文研究回归模型的不确定性量化问题，提出一种基于非参数方法的校准方法，该方法不依赖于底层预测模型，具有计算效率和统计一致性。我们建立了校准误差的上限和下限，并证明了我们提出的方法的统计保证和优势。

    In this paper, we consider the uncertainty quantification problem for regression models. Specifically, we consider an individual calibration objective for characterizing the quantiles of the prediction model. While such an objective is well-motivated from downstream tasks such as newsvendor cost, the existing methods have been largely heuristic and lack of statistical guarantee in terms of individual calibration. We show via simple examples that the existing methods focusing on population-level calibration guarantees such as average calibration or sharpness can lead to harmful and unexpected results. We propose simple nonparametric calibration methods that are agnostic of the underlying prediction model and enjoy both computational efficiency and statistical consistency. Our approach enables a better understanding of the possibility of individual calibration, and we establish matching upper and lower bounds for the calibration error of our proposed methods. Technically, our analysis co
    
[^45]: 带有时间预测编码的时序记忆

    Sequential Memory with Temporal Predictive Coding. (arXiv:2305.11982v1 [q-bio.NC])

    [http://arxiv.org/abs/2305.11982](http://arxiv.org/abs/2305.11982)

    该论文提出了一种基于PC的新型时序记忆模型，称为时间预测编码（tPC），可以通过生物可行的神经实现准确地记忆和检索连续输入。其中tPC可以被看作是一种经典异向性霍普菲尔德网络（AHN），具有更稳定的性能，并且可以编码上下文相关信息，区分在序列中出现的重复元素。

    

    对于生物体存储事件序列的时间顺序至关重要，然而大脑中支配时序记忆的计算机制仍不清楚。本文受到神经科学理论和预测编码（PC）在静态存储任务中的成功启示，提出了一种基于PC的新型时序记忆模型，称为时间预测编码（tPC）。我们展示了我们的tPC模型可以通过生物可行的神经实现准确地记忆和检索连续输入。重要的是，我们的分析研究表明，tPC可以被看作是一种具有隐式统计白化过程的经典异向性霍普菲尔德网络（AHN），这会在结构化输入的时序记忆任务中导致更稳定的性能。此外，我们发现具有多层结构的tPC可以编码上下文相关信息，因此可以区分在序列中出现的重复元素。

    Memorizing the temporal order of event sequences is critical for the survival of biological agents. However, the computational mechanism underlying sequential memory in the brain remains unclear. Inspired by neuroscience theories and recent successes in applying predictive coding (PC) to static memory tasks, in this work we propose a novel PC-based model for sequential memory, called temporal predictive coding (tPC). We show that our tPC models can memorize and retrieve sequential inputs accurately with a biologically plausible neural implementation. Importantly, our analytical study reveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN) with an implicit statistical whitening process, which leads to more stable performance in sequential memory tasks of structured inputs. Moreover, we find that tPC with a multi-layer structure can encode context-dependent information, thus distinguishing between repeating elements appearing in a sequence, a computation attribute
    
[^46]: 基于自回归神经网络的自旋系统互信息的估算

    Mutual information of spin systems from autoregressive neural networks. (arXiv:2304.13412v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2304.13412](http://arxiv.org/abs/2304.13412)

    本论文介绍了一种基于自回归神经网络和Monte Carlo采样的直接方法来估算自旋系统的双部分互信息，可以研究任意子系统的几何形状，并且在Ising模型上演示了此方法的效果。

    

    我们描述了一种基于Monte Carlo采样和自回归神经网络的直接方法来估算经典自旋系统的双部分互信息。它允许研究任意子系统的几何形状，并且可推广到经典场理论。我们用Ising模型的四个分区演示了它的效果，包括多重连接的偶奇分割。我们表明，当远离临界温度时，面积规律得到了满足：常数项是通用的，而比例系数对于偶奇分割是不同的。

    We describe a direct approach to estimate bipartite mutual information of a classical spin system based on Monte Carlo sampling enhanced by autoregressive neural networks. It allows studying arbitrary geometries of subsystems and can be generalized to classical field theories. We demonstrate it on the Ising model for four partitionings, including a multiply-connected even-odd division. We show that the area law is satisfied for temperatures away from the critical temperature: the constant term is universal, whereas the proportionality coefficient is different for the even-odd partitioning.
    
[^47]: 使用基于OWA的链接、Lance-Williams公式和树枝反转的层次聚类

    Hierarchical clustering with OWA-based linkages, the Lance-Williams formula, and dendrogram inversions. (arXiv:2303.05683v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.05683](http://arxiv.org/abs/2303.05683)

    本研究通过使用基于OWA的链接，Lance-Williams公式和树枝反转技术，推广了凝聚层次聚类，并提供了一些条件用于保证结果的树枝图没有不美观的反转。

    

    基于有序加权平均（OWA）算子的凝聚层次聚类不仅推广了单个的、完全的和平均的链接，还包括基于一些最近或最远邻居、修剪和修整的点对相似性的平均值的集群间距。我们探索了著名的Lance-Williams更新公式与扩展的基于OWA的链接之间的关系，并通过无限系数序列生成权重。此外，我们提供了一些条件，以保证权重生成器产生的树枝图不会出现不美观的反转。

    Agglomerative hierarchical clustering based on Ordered Weighted Averaging (OWA) operators not only generalises the single, complete, and average linkages, but also includes intercluster distances based on a few nearest or farthest neighbours, trimmed and winsorised means of pairwise point similarities, amongst many others. We explore the relationships between the famous Lance-Williams update formula and the extended OWA-based linkages with weights generated via infinite coefficient sequences. Furthermore, we provide some conditions for the weight generators to guarantee the resulting dendrograms to be free from unaesthetic inversions.
    
[^48]: 对于多臂赌博机问题，FTRL算法与一般正则化和多个最优臂的最佳保证有所提升

    Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms. (arXiv:2302.13534v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13534](http://arxiv.org/abs/2302.13534)

    本文提出了对于多臂赌博机问题的改进的FTRL算法，通过使用一系列正则化器和新的学习率计划，不再需要假设存在唯一最优臂，并对某些正则化器的遗憾界限进行了改进。

    

    本文研究设计自适应多臂赌博机算法，同时在随机设置和对抗设置中表现最优（通常称为最佳保证）。最近的一系列研究表明，当正确配置和分析时，原本设计用于对抗设置的Follow-the-Regularized-Leader（FTRL）算法实际上可以最优地适应随机设置。然而，这些结果关键依赖于存在唯一最优臂的假设。最近，Ito（2021）首次采取措施删除了一个特定FTRL算法对于$\frac{1}{2}$-Tsallis熵正则化的不可取唯一性假设。本文对这一结果进行了显著改进和推广，表明FTRL算法在广泛的正则化器和新的学习率计划下不需要唯一性。对于某些正则化器，我们的遗憾界限与前人的结果相比也有所提高。

    We study the problem of designing adaptive multi-armed bandit algorithms that perform optimally in both the stochastic setting and the adversarial setting simultaneously (often known as a best-of-both-world guarantee). A line of recent works shows that when configured and analyzed properly, the Follow-the-Regularized-Leader (FTRL) algorithm, originally designed for the adversarial setting, can in fact optimally adapt to the stochastic setting as well. Such results, however, critically rely on an assumption that there exists one unique optimal arm. Recently, Ito (2021) took the first step to remove such an undesirable uniqueness assumption for one particular FTRL algorithm with the $\frac{1}{2}$-Tsallis entropy regularizer. In this work, we significantly improve and generalize this result, showing that uniqueness is unnecessary for FTRL with a broad family of regularizers and a new learning rate schedule. For some regularizers, our regret bounds also improve upon prior results even when
    
[^49]: RS-Del: 随机删除对序列分类器的编辑距离鲁棒性证明

    RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion. (arXiv:2302.01757v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.01757](http://arxiv.org/abs/2302.01757)

    本文提出了一种适应于离散序列分类器的随机删除（RS-Del）平滑机制，提供针对编辑距离受限对抗性的鲁棒性证明。

    

    随机平滑是构建具有认证鲁棒性的分类器的主要方法。现有的随机平滑方法主要针对具有连续输入（如图像）的分类器，其中常常研究$\ell_p$范数受限的对抗性示例。然而，对于具有离散或可变大小输入（例如源代码）的分类器的研究较少，这些分类器需要不同的威胁模型和平滑机制。在本研究中，我们修改了随机平滑方法，以适用于离散序列分类器，以提供针对编辑距离受限的对抗性的可证明的鲁棒性。我们提出的平滑机制随机删除（RS-Del）应用了随机删除编辑，这种方式（也许令人惊讶地）足以提供针对对抗性删除、插入和替换编辑的鲁棒性。我们的认证证明不同于传统的Neyman-Pearson方法，在我们的情况下无法计算，而是围绕着另一种方式进行组织。

    Randomized smoothing is a leading approach for constructing classifiers that are certifiably robust against adversarial examples. Existing work on randomized smoothing has focused on classifiers with continuous inputs, such as images, where $\ell_p$-norm bounded adversaries are commonly studied. However, there has been limited work for classifiers with discrete or variable-size inputs, such as for source code, which require different threat models and smoothing mechanisms. In this work, we adapt randomized smoothing for discrete sequence classifiers to provide certified robustness against edit distance-bounded adversaries. Our proposed smoothing mechanism randomized deletion (RS-Del) applies random deletion edits, which are (perhaps surprisingly) sufficient to confer robustness against adversarial deletion, insertion and substitution edits. Our proof of certification deviates from the established Neyman-Pearson approach, which is intractable in our setting, and is instead organized aro
    
[^50]: 核斯坦距离稀释：关于病态的理论视角和正则化的实际修复（arXiv:2301.13528v2 [math.ST] 已更新）

    Kernel Stein Discrepancy thinning: a theoretical perspective of pathologies and a practical fix with regularization. (arXiv:2301.13528v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2301.13528](http://arxiv.org/abs/2301.13528)

    本文针对后处理MCMC输出过程中的病态问题进行了理论分析，提出了正则化的Stein稀释算法，有效缓解了这些病态产生的影响，为提高逼近质量提供了新策略。

    

    Stein稀释是一种有前途的算法，由（Riabiz et al.，2022）提出用于后处理马尔可夫链蒙特卡罗（MCMC）的输出。其主要原则是贪婪地最小化核化Stein差异（KSD），它仅需要对数目标分布的梯度，因此非常适合贝叶斯推断。 Stein稀释的主要优势是自动消除启动期，纠正最近的MCMC算法引入的偏差，并具有收敛至目标分布的渐近特性。然而， Stein稀释存在几个经验病态，可能导致劣质逼近，这在文献中已被观察到。 在本文中，我们对这些病态进行了理论分析，以明确识别涉及的机制，并提出了改进的策略。然后，我们引入了正则化的 Stein稀释算法来缓解已识别的病态。最后，我们提供了理论保证和扩展。

    Stein thinning is a promising algorithm proposed by (Riabiz et al., 2022) for post-processing outputs of Markov chain Monte Carlo (MCMC). The main principle is to greedily minimize the kernelized Stein discrepancy (KSD), which only requires the gradient of the log-target distribution, and is thus well-suited for Bayesian inference. The main advantages of Stein thinning are the automatic remove of the burn-in period, the correction of the bias introduced by recent MCMC algorithms, and the asymptotic properties of convergence towards the target distribution. Nevertheless, Stein thinning suffers from several empirical pathologies, which may result in poor approximations, as observed in the literature. In this article, we conduct a theoretical analysis of these pathologies, to clearly identify the mechanisms at stake, and suggest improved strategies. Then, we introduce the regularized Stein thinning algorithm to alleviate the identified pathologies. Finally, theoretical guarantees and exte
    
[^51]: 通过稀疏编码实现无约束动态遗憾

    Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13349](http://arxiv.org/abs/2301.13349)

    本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。

    

    受时间序列预测的影响，本研究探讨了在线线性优化（OLO）在两个问题结构的耦合下的情况：域无界，而算法的性能是通过动态遗憾来衡量的。处理任一问题都要求遗憾界限依赖于比较序列的某些复杂度量度 - 特别是无约束OLO中的比较器范数，以及动态遗憾中的路径长度。与最近一篇文章(Jacobsen& Cutkosky，2022)适应这两个复杂度量度相比，我们提出了一种通过重新构造问题为稀疏编码的复杂度度量方式。可以通过一个简单的模块化框架实现适应性，这个框架自然地利用了环境更复杂的前置知识。同时，我们还提出了一种新的静态无约束OLO梯度自适应算法，使用了新颖的连续时间机制设计。这可能是具有独立兴趣的。

    Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen & Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
    
[^52]: 位置-尺度噪声模型中因果推断的最大似然与独立性检验比较研究

    Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing. (arXiv:2301.12930v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12930](http://arxiv.org/abs/2301.12930)

    通过引入异方差位置-尺度噪声函数模型，该论文在正确说明噪声分布的情况下，通过最大似然实现了最先进的准确性。但是，在用户错误指定噪声分布的形式时，分析表明因果推断的精度会急剧下降。因此，该论文提出通过因果模型选择实现稳定而准确的因果推断。

    

    因果发现的一个基本问题是推断两个随机变量之间的正确因果方向。最近引入的异方差位置-尺度噪声函数模型 (LSNM) 结合了表达能力和可识别性保证，在正确指定噪声分布的情况下，通过最大似然实现了最先进的准确性。然而，我们通过广泛的实证评估表明，当用户错误指定噪声分布的形式时，精度会急剧下降。我们的分析表明，这种失败主要发生在反因果方向的条件方差小于因果方向的条件方差的情况下。作为一种替代方案，发现通过因果模型选择可以在缺乏噪声分布知识的情况下，实现稳定而准确的因果推断。

    A fundamental problem of causal discovery is cause-effect inference, learning the correct causal direction between two random variables. Significant progress has been made through modelling the effect as a function of its cause and a noise term, which allows us to leverage assumptions about the generating function class. The recently introduced heteroscedastic location-scale noise functional models (LSNMs) combine expressive power with identifiability guarantees. LSNM model selection based on maximizing likelihood achieves state-of-the-art accuracy, when the noise distributions are correctly specified. However, through an extensive empirical evaluation, we demonstrate that the accuracy deteriorates sharply when the form of the noise distribution is misspecified by the user. Our analysis shows that the failure occurs mainly when the conditional variance in the anti-causal direction is smaller than that in the causal direction. As an alternative, we find that causal model selection throu
    
[^53]: 图形生成模型评估的曲率滤波器

    Curvature Filtrations for Graph Generative Model Evaluation. (arXiv:2301.12906v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12906](http://arxiv.org/abs/2301.12906)

    该论文使用图形曲率描述符和拓扑数据分析中的新方法相结合，以获得用于评估图形生成模型的稳健、表达性的描述符。

    

    图形生成模型评估需要了解分布级别上的图形差异，这需要能够以有效的方式利用图形的显著属性。曲率是图形的一种属性，最近开始证明其在描述图形方面很有用。然而，其表达性质、稳定性和在模型评估中的实际效用仍然很少被探索。我们将图形曲率描述符与拓扑数据分析中的新方法相结合，以获得用于评估图形生成模型的稳健、表达性的描述符。

    Graph generative model evaluation necessitates understanding differences between graphs on the distributional level. This entails being able to harness salient attributes of graphs in an efficient manner. Curvature constitutes one such property of graphs, and has recently started to prove useful in characterising graphs. Its expressive properties, stability, and practical utility in model evaluation remain largely unexplored, however. We combine graph curvature descriptors with emerging methods from topological data analysis to obtain robust, expressive descriptors for evaluating graph generative models.
    
[^54]: 分布鲁棒安全强化学习的风险厌恶模型不确定性

    Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning. (arXiv:2301.12593v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12593](http://arxiv.org/abs/2301.12593)

    该论文提出了一种分布鲁棒安全强化学习框架，通过使用失真风险度量来处理模型不确定性。该方法不需要极小极大优化，具有高效且不依赖模型的特点。实验证明该框架能够在具有安全约束的控制任务中实现稳健的性能和安全性。

    

    许多现实领域需要在不确定的环境中进行安全决策。本研究引入了一个深度强化学习框架来解决这个重要问题。我们考虑过渡模型的分布，并通过使用相干失真风险度量来对模型不确定性采取风险厌恶的观点。我们通过展示它等价于一类特定的分布鲁棒安全强化学习问题，为这个框架提供了鲁棒性保证。然而，与现有的深度强化学习鲁棒性方法不同，我们的表达不涉及极小化最大优化。这导致我们的方法可以高效、不依赖模型地在单个训练环境中仅需要标准数据收集来实施。在具有安全约束的连续控制任务的实验中，我们证明了我们的框架在部署时能够产生稳健的性能和安全性。

    Many real-world domains require safe decision making in uncertain environments. In this work, we introduce a deep reinforcement learning framework for approaching this important problem. We consider a distribution over transition models, and apply a risk-averse perspective towards model uncertainty through the use of coherent distortion risk measures. We provide robustness guarantees for this framework by showing it is equivalent to a specific class of distributionally robust safe reinforcement learning problems. Unlike existing approaches to robustness in deep reinforcement learning, however, our formulation does not involve minimax optimization. This leads to an efficient, model-free implementation of our approach that only requires standard data collection from a single training environment. In experiments on continuous control tasks with safety constraints, we demonstrate that our framework produces robust performance and safety at deployment time across a range of perturbed test e
    
[^55]: 基于边界框的多目标贝叶斯优化在输入不确定性下的风险衡量

    Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty. (arXiv:2301.11588v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.11588](http://arxiv.org/abs/2301.11588)

    该论文提出了一种基于边界框的多目标贝叶斯优化方法，能够在输入不确定性下高效地识别风险衡量定义的帕累托前沿。该方法具有理论保证，并通过构建高概率边界框和选择下一个评估点的方法来减少不确定性。

    

    在本研究中，我们提出了一种新颖的多目标贝叶斯优化（MOBO）方法，用于在输入不确定性（IU）存在的情况下高效地识别由风险衡量定义的帕累托前沿（PF）。现有的IU下帕累托优化的BO方法是特定风险或者没有理论保证的，而我们提出的方法涉及一般风险衡量并具有理论保证。所提方法的基本思想是假设黑箱函数的高斯过程（GP）模型，并使用GP模型构建风险衡量的高概率边界框。此外，为了减少非支配边界框的不确定性，我们提出了一种使用基于边界框的拟距离的最大值定义的最大最小距离选择下一个评估点的方法。作为理论分析，我们证明了该算法可以在有限次迭代中返回任意精确的解。

    In this study, we propose a novel multi-objective Bayesian optimization (MOBO) method to efficiently identify the Pareto front (PF) defined by risk measures for black-box functions under the presence of input uncertainty (IU). Existing BO methods for Pareto optimization in the presence of IU are risk-specific or without theoretical guarantees, whereas our proposed method addresses general risk measures and has theoretical guarantees. The basic idea of the proposed method is to assume a Gaussian process (GP) model for the black-box function and to construct high-probability bounding boxes for the risk measures using the GP model. Furthermore, in order to reduce the uncertainty of non-dominated bounding boxes, we propose a method of selecting the next evaluation point using a maximin distance defined by the maximum value of a quasi distance based on bounding boxes. As theoretical analysis, we prove that the algorithm can return an arbitrary-accurate solution in a finite number of iterati
    
[^56]: 一个用于基准测试聚类算法的框架

    A framework for benchmarking clustering algorithms. (arXiv:2209.09493v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.09493](http://arxiv.org/abs/2209.09493)

    该论文开发了一个用于基准测试聚类算法的框架，旨在引入一种一致的方法进行测试。还汇总、改进和标准化了许多聚类基准数据集合，并包含了新数据集。提供了互动数据集浏览器、Python API的文档以及与其他编程语言进行框架交互的方式。

    

    聚类算法的评估可以涉及在各种基准问题上运行它们，并将其输出与专家提供的参考真实分组进行比较。不幸的是，许多研究论文和研究生论文只考虑了少数数据集。而且，很少考虑到在给定问题集上可以有许多同样有效的聚类方法的事实。为了克服这些限制，我们开发了一个框架，其目的是引入一种一致的方法来测试聚类算法。此外，我们还汇总、改进和标准化了机器学习和数据挖掘文献中提到的许多聚类基准数据集合，并包含了具有不同维度、大小和聚类类型的新数据集。还有一个互动数据集浏览器、Python API的文档以及如何与其他编程语言（如R或MATLAB）进行框架交互的描述。

    The evaluation of clustering algorithms can involve running them on a variety of benchmark problems, and comparing their outputs to the reference, ground-truth groupings provided by experts. Unfortunately, many research papers and graduate theses consider only a small number of datasets. Also, the fact that there can be many equally valid ways to cluster a given problem set is rarely taken into account. In order to overcome these limitations, we have developed a framework whose aim is to introduce a consistent methodology for testing clustering algorithms. Furthermore, we have aggregated, polished, and standardised many clustering benchmark dataset collections referred to across the machine learning and data mining literature, and included new datasets of different dimensionalities, sizes, and cluster types. An interactive datasets explorer, the documentation of the Python API, a description of the ways to interact with the framework from other programming languages such as R or MATLAB
    
[^57]: 鲁棒的蒙特卡洛方法输出分析

    Robust Output Analysis with Monte-Carlo Methodology. (arXiv:2207.13612v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2207.13612](http://arxiv.org/abs/2207.13612)

    本论文提出了一个统一的蒙特卡洛抽样输出分析框架，通过对模拟和机器学习输出进行分析，能够非参数化地量化输出的方差和偏差，并提出了一种新的偏差校正估计方法，以提高鲁棒性。

    

    在使用模拟或机器学习进行预测建模时，准确评估估计值的质量是非常重要的，因此需要进行输出分析。近几十年来，输出分析方法已经得到了丰富，并且提出了各种方法来量化输入数据不确定性对模型输出的影响，以增加鲁棒性。然而，大多数方法都是基于假设输入数据符合参数分布族的情况。本文提出了一个统一的输出分析框架，通过蒙特卡洛抽样的方式对模拟和机器学习输出进行分析。该框架可以对输出中引入的方差和偏差进行非参数化的量化，并具有更高阶的准确性。我们通过扩展快速迭代自举抽样和高阶影响函数，提出了一种新的从模型输出中校正偏差的估计方法。为了提高所提方法的可扩展性，我们设计了预算最优规则，并利用控制变量减少方差。

    In predictive modeling with simulation or machine learning, it is critical to accurately assess the quality of estimated values through output analysis. In recent decades output analysis has become enriched with methods that quantify the impact of input data uncertainty in the model outputs to increase robustness. However, most developments are applicable assuming that the input data adheres to a parametric family of distributions. We propose a unified output analysis framework for simulation and machine learning outputs through the lens of Monte Carlo sampling. This framework provides nonparametric quantification of the variance and bias induced in the outputs with higher-order accuracy. Our new bias-corrected estimation from the model outputs leverages the extension of fast iterative bootstrap sampling and higher-order influence functions. For the scalability of the proposed estimation methods, we devise budget-optimal rules and leverage control variates for variance reduction. Our t
    
[^58]: SGD和权重衰减在神经网络中被证明会引入低秩偏差

    SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks. (arXiv:2206.05794v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.05794](http://arxiv.org/abs/2206.05794)

    使用SGD和权重衰减训练深度ReLU神经网络会导致对于权重矩阵的秩最小化的偏差，特别是在使用较小批量大小、更高学习率或增加权重衰减时更为显著。此外，在中间神经网络崩溃时，学习的权重特别低秩。这种偏差与泛化之间存在关系。

    

    我们研究了使用随机梯度下降（SGD）在训练深度ReLU神经网络时学习低秩权重矩阵的偏差。我们的结果表明，使用小批量SGD和权重衰减来训练神经网络会导致对于权重矩阵的秩最小化的偏差。具体而言，我们通过理论和实验证明，当使用较小的批量大小、更高的学习率或增加的权重衰减时，这种偏差更加显著。此外，我们预测并通过实验证明，权重衰减是实现这种偏差的必要条件。此外，我们还发现在中间神经网络崩溃的情况下，学习的权重特别低秩。与先前的文献不同，我们的分析不依赖于关于数据、收敛性或权重矩阵优化的假设。此外，它适用于任意宽度或深度的各种神经网络结构。最后，我们通过实验证明了这种偏差与泛化之间的关系。

    We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank weight matrices when training deep ReLU neural networks. Our results show that training neural networks with mini-batch SGD and weight decay causes a bias towards rank minimization over the weight matrices. Specifically, we show, both theoretically and empirically, that this bias is more pronounced when using smaller batch sizes, higher learning rates, or increased weight decay. Additionally, we predict and observe empirically that weight decay is necessary to achieve this bias. In addition, we show that in the presence of intermediate neural collapse, the learned weights are particularly low-rank. Unlike previous literature, our analysis does not rely on assumptions about the data, convergence, or optimality of the weight matrices. Furthermore, it applies to a wide range of neural network architectures of any width or depth. Finally, we empirically investigate the connection between this bias and generalization, 
    
[^59]: 具有全局非稳态的有限时间分析的多臂赌博机问题

    Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits. (arXiv:2107.11419v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2107.11419](http://arxiv.org/abs/2107.11419)

    本文研究了模型参数随时间变化的非稳态多臂赌博机问题，引入了自适应重置赌博机(ADR-bandit)算法，通过有限时间分析证明了ADR-bandit在全局变化的情况下具有几乎最优的性能，并且在稳定环境和非稳态环境中均具有最优的性能。

    

    我们考虑模型参数随时间变化的非稳态多臂赌博机问题。我们引入了自适应重置赌博机(ADR-bandit)，这是一个利用数据流文献中的自适应窗口技术的赌博机算法类。我们首先提供了关于自适应窗口技术产生的估计器质量的新保证，这对于独立的研究是有意义的。此外，我们在两种典型环境下对ADR-bandit进行了有限时间分析：一种是突变环境，其中变化是瞬时发生的；另一种是渐变环境，其中变化是逐渐发生的。我们证明了当突变或渐变的变化以我们称为全局变化的协同方式发生时，ADR-bandit具有几乎最优的性能。我们证明了在假设这种全局变化的情况下，强制探索是不必要的。与现有的非稳态赌博机算法不同，ADR-bandit在稳定环境和非稳态环境中均具有最优的性能。

    We consider nonstationary multi-armed bandit problems where the model parameters of the arms change over time. We introduce the adaptive resetting bandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing techniques from literature on data streams. We first provide new guarantees on the quality of estimators resulting from adaptive windowing techniques, which are of independent interest. Furthermore, we conduct a finite-time analysis of ADR-bandit in two typical environments: an abrupt environment where changes occur instantaneously and a gradual environment where changes occur progressively. We demonstrate that ADR-bandit has nearly optimal performance when abrupt or gradual changes occur in a coordinated manner that we call global changes. We demonstrate that forced exploration is unnecessary when we assume such global changes. Unlike the existing nonstationary bandit algorithms, ADR-bandit has optimal performance in stationary environments as well as nonstation
    
[^60]: 在线估计和网络事件流的社区检测中的网络点过程

    Online Estimation and Community Detection of Network Point Processes for Event Streams. (arXiv:2009.01742v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2009.01742](http://arxiv.org/abs/2009.01742)

    本论文提出了一种在线变分推断算法，用于在网络事件流中估计潜在的社区结构。通过使用连续时间点过程潜在网络模型，可以捕捉动态事件到达的时间动态，并更新社区分配。

    

    网络建模的一个共同目标是揭示节点之间的潜在社区结构。对于许多现实世界中的网络，真实的连接都由作为流到达的事件组成，然后将其聚合形成边缘，忽略了动态的时间组件。考虑到这些交互的时间动态的一种自然方法是使用点过程作为网络模型中的基础进行社区检测。计算复杂性影响着这种方法在大型稀疏网络上的可扩展性。为了克服这一挑战，我们提出了一种快速在线变分推断算法，用于估计网络上基于动态事件到达的潜在结构，使用连续时间点过程潜在网络模型。我们描述了适用于捕捉社区结构的网络模型的此过程。当在网络上观察到新事件时，可以学习该结构，并更新推断的社区分配。我们研究了这种方法的理论性质。

    A common goal in network modeling is to uncover the latent community structure present among nodes. For many real-world networks, the true connections consist of events arriving as streams, which are then aggregated to form edges, ignoring the dynamic temporal component. A natural way to take account of these temporal dynamics of interactions is to use point processes as the foundation of network models for community detection. Computational complexity hampers the scalability of such approaches to large sparse networks. To circumvent this challenge, we propose a fast online variational inference algorithm for estimating the latent structure underlying dynamic event arrivals on a network, using continuous-time point process latent network models. We describe this procedure for networks models capturing community structure. This structure can be learned as new events are observed on the network, updating the inferred community assignments. We investigate the theoretical properties of suc
    

