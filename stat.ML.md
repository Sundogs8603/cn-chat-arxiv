# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Bayesian Semi-structured Subspace Inference.](http://arxiv.org/abs/2401.12950) | 本文提出了一种贝叶斯近似方法，通过使用子空间推理来解决半结构回归模型中解释性不确定性的问题，并展示了其在推断输入-输出关系和捕捉多重要素方面的有效性。 |
| [^2] | [Reward-Relevance-Filtered Linear Offline Reinforcement Learning.](http://arxiv.org/abs/2401.12934) | 本文研究了在线决策理论环境中线性函数逼近的离线强化学习，提出了一种基于奖励相关性过滤的方法，将状态-动作值函数的估计限制在稀疏组件上，具有理论保证，并且样本复杂度仅取决于稀疏组件的大小。 |
| [^3] | [DsDm: Model-Aware Dataset Selection with Datamodels.](http://arxiv.org/abs/2401.12926) | 该论文提出了一种模型感知的数据集选择方法，通过将数据集选择视为一个优化问题来解决，并明确地建模了学习过程如何使用训练数据点来预测目标任务。该方法在提高语言模型性能方面表现出色。 |
| [^4] | [Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection.](http://arxiv.org/abs/2401.12924) | 本文对于使用图像数据集进行森林火灾检测的支持向量机（SVM）进行了性能分析，并研究了关键因素如数据预处理、特征提取和模型训练。这项研究有助于开发高效的森林火灾检测系统。 |
| [^5] | [Deep multitask neural networks for solving some stochastic optimal control problems.](http://arxiv.org/abs/2401.12923) | 本文针对某些难以模拟底层状态变量的随机最优控制问题，引入了使用多任务神经网络的有效解决方案，并通过实验证明了该方法的优越性。 |
| [^6] | [MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage.](http://arxiv.org/abs/2401.12824) | 本文提出了一种使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类的方法，该方法克服了非独立同分布图结构中的拓扑依赖问题，并构建了一个模型无关的去偏置框架，以防止下游误用并提高训练的可靠性。 |
| [^7] | [Deep Neural Network Benchmarks for Selective Classification.](http://arxiv.org/abs/2401.12708) | 本论文研究了用于选择性分类的深度神经网络，目的是设计一种选择机制来平衡被拒绝的预测比例和所选预测的预测性能改进。 |
| [^8] | [Feature Selection via Robust Weighted Score for High Dimensional Binary Class-Imbalanced Gene Expression Data.](http://arxiv.org/abs/2401.12667) | 本文提出了一种用于高维基因表达二分类问题的稳健加权分数（ROWSU）方法，解决了基因表达数据中高度倾斜的类别分布对分类算法性能的不利影响问题。 |
| [^9] | [Interpreting Equivariant Representations.](http://arxiv.org/abs/2401.12588) | 本文研究了潜在表示的等变性以及在使用中考虑等变模型的归纳偏差的重要性，提出了选择不变投影的原则，并展示了两个实例的影响。 |
| [^10] | [DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations.](http://arxiv.org/abs/2401.12517) | DDMI是一种面向领域无关的隐式神经表示的高质量合成的潜在扩散模型，通过生成自适应位置嵌入而不是网络权重，解决了现有方法中生成质量较低的问题。 |
| [^11] | [Adiabatic Quantum Support Vector Machines.](http://arxiv.org/abs/2401.12485) | 本文描述了一种用于训练支持向量机的绝热量子方法，与经典方法相比，我们的方法在时间复杂度上取得了一个数量级的改进，并且在五个基准数据集上取得了与经典方法相当的测试准确率。我们还展示了我们的方法具有良好的可扩展性。 |
| [^12] | [Nonparametric logistic regression with deep learning.](http://arxiv.org/abs/2401.12482) | 本文提出了一种简单的方法来分析非参数 logistic 回归问题，通过在温和的假设下，在 Hellinger 距离下推导出了最大似然估计器的收敛速率。 |
| [^13] | [Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling.](http://arxiv.org/abs/2401.12476) | 本文提出了一种用于学习非分离哈密顿系统的结构保持的贝叶斯方法，可以处理统计相关的加性和乘性噪声，并且通过将结构保持方法纳入框架中，提供了对高维系统的高效识别。 |
| [^14] | [Towards Improved Variational Inference for Deep Bayesian Models.](http://arxiv.org/abs/2401.12418) | 本论文探讨了改进深度贝叶斯模型的变分推断方法，旨在解决深度模型训练过程中的过度自信和不准确预测问题。通过使用变分推断提供的后验近似和边缘似然下界，可以优化超参数并实现模型选择。 |
| [^15] | [VC dimension of Graph Neural Networks with Pfaffian activation functions.](http://arxiv.org/abs/2401.12362) | 本文分析了图神经网络（GNN）中使用不同常用激活函数（如sigmoid和双曲正切）时的VC维度，采用了Pfaffian函数理论框架，通过架构参数和合作数量提供了界限。 |
| [^16] | [Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation.](http://arxiv.org/abs/2401.12340) | 本论文提出了一种基于对比学习和循环一致性的混合非配对域转换网络（H-CUT）来解决自动目标识别（ATR）中标记数据不足的问题。该方法在跨领域转导迁移学习中取得了显著低的FID分数，并通过注意力和熵来强调领域特定区域，以生成高质量的合成图像。 |
| [^17] | [Transfer Learning for Nonparametric Regression: Non-asymptotic Minimax Analysis and Adaptive Procedure.](http://arxiv.org/abs/2401.12272) | 本文研究了非参数回归的迁移学习问题，提出了一种新的置信阈值估计器来实现渐近最小风险，并发现了迁移学习中的两个独特现象：自动平滑和超加速。此外，我们还提出了一种数据驱动算法，可以适应广泛的参数空间，并在仿真研究和真实世界的例子中证明了该方法的优势。 |
| [^18] | [Accelerating Sinkhorn Algorithm with Sparse Newton Iterations.](http://arxiv.org/abs/2401.12253) | 该论文提出了一种扩展的Sinkhorn算法，通过引入提前停止和牛顿迭代子程序，实现了可能的超指数收敛。他们利用了Sinkhorn算法最大化凹性李雅普诺夫势的特性，发现了势函数的Hessian矩阵近似稀疏，从而将每次迭代的复杂性降低到了$O(n^2)$。 |
| [^19] | [The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness.](http://arxiv.org/abs/2401.12236) | 这项研究证明了即使机器学习模型在训练过程中对噪声数据拟合得很好，对敌对示例具有鲁棒性，但当面临敌对操纵的数据时，过度拟合的模型可能会给系统带来意外的危害。 |
| [^20] | [Subgroup analysis methods for time-to-event outcomes in heterogeneous randomized controlled trials.](http://arxiv.org/abs/2401.11842) | 本论文评估了多种时间到事件结果的亚组分析算法，填补了这一领域的研究空白，并提出了一种新的数据生成过程，可以探索不同的异质性情景。 |
| [^21] | [Joint Unsupervised and Supervised Training for Automatic Speech Recognition via Bilevel Optimization.](http://arxiv.org/abs/2401.06980) | 本文提出了一种双层优化的训练方法，用于自动语音识别，通过联合无监督和监督训练来提高性能。 |
| [^22] | [Causal Forecasting for Pricing.](http://arxiv.org/abs/2312.15282) | 本文提出了一种在定价环境下进行需求预测的新方法，通过将因果推断的双重机器学习方法和最先进的基于变压器的预测模型结合在一起，我们的方法在完全控制的情况下更好地估计因果效应，并在离线政策设置中优于其他预测方法。 |
| [^23] | [Robust Loss Functions for Training Decision Trees with Noisy Labels.](http://arxiv.org/abs/2312.12937) | 本文研究了在带有噪声标签的数据上训练决策树的鲁棒损失函数。我们的研究主要有三个贡献：提供了对现有损失函数鲁棒性的新洞察，引入了分布损失函数的框架，并介绍了一种高效的贪婪减少不纯度的学习算法。 |
| [^24] | [On the Nystrom Approximation for Preconditioning in Kernel Machines.](http://arxiv.org/abs/2312.03311) | 本文分析了核机器预处理中使用Nystrom逼近的权衡。研究表明，使用对数大小的样本能够让Nystrom逼近的预处理器几乎与梯度下降同样有效地加速。 |
| [^25] | [Conditional Variational Diffusion Models.](http://arxiv.org/abs/2312.02246) | 该论文提出了一种新的条件变分扩散模型，通过学习调度作为训练过程的一部分，解决了扩散模型的敏感性问题，并且能够适应不同的应用场景，提供高质量的解决方案。 |
| [^26] | [A Stability Principle for Learning under Non-Stationarity.](http://arxiv.org/abs/2310.18304) | 本研究提出了一个适用于非稳态环境的统计学习框架，通过应用稳定性原则选择回溯窗口来最大化历史数据利用，并保持累积偏差在可接受范围内。该方法展示了对未知非稳态的适应性，遗憾界在强凸或满足Lipschitz条件下是极小化的最优解。该研究的创新点是函数相似度度量和非稳态数据序列划分技术。 |
| [^27] | [A Geometric Framework for Neural Feature Learning.](http://arxiv.org/abs/2309.10140) | 本论文提出了一个基于神经特征学习的几何框架，在特征空间中利用几何结构解决学习问题。通过引入特征几何，将统计依赖和特征统一到同一空间中，并使用嵌套技术设计学习算法，展示了其在多变量学习问题中的应用。 |
| [^28] | [Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm.](http://arxiv.org/abs/2309.08783) | 本文提出了一种解决高维度稀疏线性回归中异方差问题的方法，通过基于分区经验贝叶斯ECM算法的异方差高维度线性回归模型来实现。这个模型可以处理残差方差不恒定的情况，并且可以使用插值的经验贝叶斯估计超参数来灵活地调整方差模型。 |
| [^29] | [When Does Confidence-Based Cascade Deferral Suffice?.](http://arxiv.org/abs/2307.02764) | 本研究旨在探讨何时基于置信度的级联延迟可能失败，以及何时备选的延迟策略可能表现更好。通过理论分析和实验证明事后延迟机制能够显著提高性能。 |
| [^30] | [A Lightweight Method for Tackling Unknown Participation Probabilities in Federated Averaging.](http://arxiv.org/abs/2306.03401) | 本文提出了一种轻量级方法来调整联邦平均中的聚合权重，通过根据每个客户的参与历史来处理具有不同参与率的客户，解决了在联邦学习中未知参与概率的问题。 |
| [^31] | [Data-Driven Regret Balancing for Online Model Selection in Bandits.](http://arxiv.org/abs/2306.02869) | 论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。 |
| [^32] | [Calibrating Transformers via Sparse Gaussian Processes.](http://arxiv.org/abs/2303.02444) | 提出了一种通过Sparse Gaussian Process attention (SGPA)来校准Transformer模型不确定性的方法。在文本、图像和图形的预测任务中，SGPA-based Transformers在预测准确性上表现出竞争力，并显著改善了内分布校准和外分布的鲁棒性和检测能力。 |
| [^33] | [Homophily modulates double descent generalization in graph convolution networks.](http://arxiv.org/abs/2212.13069) | 本文通过使用统计物理和随机矩阵理论的分析工具，精确地表征了简单图卷积网络在背景随机块模型上的泛化，提出了同质性在图卷积网络的泛化中的调制作用。 |
| [^34] | [Gradual Domain Adaptation via Normalizing Flows.](http://arxiv.org/abs/2206.11492) | 该论文提出使用标准化流来解决逐渐领域适应中中间域有限且距离较大的问题，并通过从源域到高斯混合分布学习目标域的分布变换。 |

# 详细

[^1]: 贝叶斯半结构子空间推理

    Bayesian Semi-structured Subspace Inference. (arXiv:2401.12950v1 [cs.LG])

    [http://arxiv.org/abs/2401.12950](http://arxiv.org/abs/2401.12950)

    本文提出了一种贝叶斯近似方法，通过使用子空间推理来解决半结构回归模型中解释性不确定性的问题，并展示了其在推断输入-输出关系和捕捉多重要素方面的有效性。

    

    半结构回归模型能够联合建模可解释的结构化特征效应和复杂的非结构化特征效应。结构化模型部分受统计模型的启发，可用于推断重要特征的输入-输出关系。非结构化部分定义了一个任意深度的神经网络，从而提供了足够的灵活性，以实现竞争性的预测性能。虽然这些模型也可以解释随机不确定性，但在解释性不确定性方面仍然缺乏工作。在本文中，我们通过使用子空间推理，针对半结构回归模型提出了一种贝叶斯近似方法，解决了这个问题。为此，我们扩展了对结构化效应的完整参数空间和非结构化效应的子空间的联合后验采样的子空间推理。除了这种混合采样方案，我们的方法还允许子空间的可调复杂性，并能捕捉多重要素。

    Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multip
    
[^2]: 基于奖励相关性过滤的线性离线强化学习

    Reward-Relevance-Filtered Linear Offline Reinforcement Learning. (arXiv:2401.12934v1 [stat.ML])

    [http://arxiv.org/abs/2401.12934](http://arxiv.org/abs/2401.12934)

    本文研究了在线决策理论环境中线性函数逼近的离线强化学习，提出了一种基于奖励相关性过滤的方法，将状态-动作值函数的估计限制在稀疏组件上，具有理论保证，并且样本复杂度仅取决于稀疏组件的大小。

    

    本文研究了在线决策理论环境中线性函数逼近的离线强化学习，其中假设数据生成过程具有决策理论稀疏性而不是估计稀疏性。数据生成过程的结构性限制预设了转移可以分解为一个影响奖励的稀疏组件，并且可能影响不影响奖励的其他外生动力学。虽然用于估计全状态过渡属性的最小可调整集合取决于整个状态，但最优策略，因此状态-动作值函数只依赖于稀疏组件：我们将其称为因果/决策论稀疏性。我们通过修改阈值岭回归在最小二乘策略评估中的应用提出了一种过滤奖励的方法，将状态-动作值函数的估计限制在稀疏组件上。我们为奖励过滤的线性拟合Q-迭代提供了理论保证，样本复杂度仅取决于稀疏组件的大小。

    This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.
    
[^3]: DsDm：具有数据模型的模型感知数据集选择

    DsDm: Model-Aware Dataset Selection with Datamodels. (arXiv:2401.12926v1 [cs.LG])

    [http://arxiv.org/abs/2401.12926](http://arxiv.org/abs/2401.12926)

    该论文提出了一种模型感知的数据集选择方法，通过将数据集选择视为一个优化问题来解决，并明确地建模了学习过程如何使用训练数据点来预测目标任务。该方法在提高语言模型性能方面表现出色。

    

    在选择用于训练大规模模型的数据时，标准做法是根据人类对数据质量的认知进行筛选。这种筛选可以得到直观上能提高模型行为的数据点。然而，在实践中通常相反的情况可能发生：我们发现根据与“高质量”数据源的相似性进行选择可能不会增加（甚至可能削弱）与随机选择数据相比的性能。为了开发更好的数据选择方法，我们首先将数据集选择作为一个优化问题来解决：给定目标任务、学习算法和候选数据，选择最大化模型性能的子集。这个框架避免了手动选择数据质量的概念，并明确地建模了学习过程如何使用训练数据点来预测目标任务。我们的方法显著提高了语言模型（LM）在预先指定的任务和以前不包括的任务上的性能。

    When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with "high quality" data sources may not increase (and can even hurt) performance compared to randomly selecting data.  To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously
    
[^4]: 对于森林火灾检测中具有挑战性数据集的支持向量机（SVM）的性能分析

    Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection. (arXiv:2401.12924v1 [stat.ML])

    [http://arxiv.org/abs/2401.12924](http://arxiv.org/abs/2401.12924)

    本文对于使用图像数据集进行森林火灾检测的支持向量机（SVM）进行了性能分析，并研究了关键因素如数据预处理、特征提取和模型训练。这项研究有助于开发高效的森林火灾检测系统。

    

    本文深入分析了使用图像数据集进行森林火灾检测的支持向量机（SVM）的性能和利用情况。随着森林火灾对生态系统和人类定居点的威胁日益增加，迅速准确的检测系统的需求至关重要。SVM以其强大的分类能力而闻名，在图像中识别与火灾相关的模式方面表现出熟练度。通过在标记数据上进行训练，SVM获得了识别与火灾相关的独特属性的能力，如火焰、烟雾或森林区域视觉特征的变化。本文全面研究了使用SVM的各个要素，包括数据预处理、特征提取和模型训练。严格评估了准确性、效率和实际适用性等参数。从这项研究中获得的知识有助于开发高效的森林火灾检测系统。

    This article delves into the analysis of performance and utilization of Support Vector Machines (SVMs) for the critical task of forest fire detection using image datasets. With the increasing threat of forest fires to ecosystems and human settlements, the need for rapid and accurate detection systems is of utmost importance. SVMs, renowned for their strong classification capabilities, exhibit proficiency in recognizing patterns associated with fire within images. By training on labeled data, SVMs acquire the ability to identify distinctive attributes associated with fire, such as flames, smoke, or alterations in the visual characteristics of the forest area. The document thoroughly examines the use of SVMs, covering crucial elements like data preprocessing, feature extraction, and model training. It rigorously evaluates parameters such as accuracy, efficiency, and practical applicability. The knowledge gained from this study aids in the development of efficient forest fire detection sy
    
[^5]: 用于解决一些随机最优控制问题的深度多任务神经网络

    Deep multitask neural networks for solving some stochastic optimal control problems. (arXiv:2401.12923v1 [stat.ML])

    [http://arxiv.org/abs/2401.12923](http://arxiv.org/abs/2401.12923)

    本文针对某些难以模拟底层状态变量的随机最优控制问题，引入了使用多任务神经网络的有效解决方案，并通过实验证明了该方法的优越性。

    

    大多数现有的基于神经网络的方法用于使用相关的反向动态规划原理解决随机最优控制问题，这些方法依赖于模拟底层状态变量的能力。然而，在某些问题中，这种模拟是不可行的，导致状态变量空间的离散化和需要为每个数据点训练一个神经网络。当处理大的状态变量空间时，这种方法在计算上变得低效。在本文中，我们考虑了一类这种类型的随机最优控制问题，并引入了一种使用多任务神经网络的有效解决方案。为了训练我们的多任务神经网络，我们引入了一种新的方案，在任务之间动态平衡学习。通过对真实世界的衍生品定价问题进行数值实验，我们证明了我们的方法优于最先进的方法。

    Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.
    
[^6]: MAPPING: 使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类

    MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage. (arXiv:2401.12824v1 [cs.LG])

    [http://arxiv.org/abs/2401.12824](http://arxiv.org/abs/2401.12824)

    本文提出了一种使用有限敏感信息泄露的去偏置图神经网络进行公平节点分类的方法，该方法克服了非独立同分布图结构中的拓扑依赖问题，并构建了一个模型无关的去偏置框架，以防止下游误用并提高训练的可靠性。

    

    尽管在各种基于网络的应用中取得了显著的成功，但图神经网络（GNN）继承并进一步加剧了历史上的偏见和社会刻板印象，这严重阻碍了它们在在线临床诊断、金融信贷等高风险领域的部署。然而，当前的公平性研究主要集中在独立同分布数据上，并不能简单地复制到具有拓扑依赖的非独立同分布图结构中。现有的公平图学习通常偏好于使用成对约束来实现公平性，但无法克服维度限制并将其推广到多个敏感属性；此外，大多数研究集中在处理技术上来强制并调整公平性，在预处理阶段构建一个模型无关的去偏置GNN框架，以防止下游误用并提高训练的可靠性在先前的工作中，GNN往往倾向于增强公平性或增加预测性能，因此在二者之间进行全面权衡仍然是一个挑战。

    Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or 
    
[^7]: 用于选择性分类的深度神经网络基准

    Deep Neural Network Benchmarks for Selective Classification. (arXiv:2401.12708v1 [cs.LG])

    [http://arxiv.org/abs/2401.12708](http://arxiv.org/abs/2401.12708)

    本论文研究了用于选择性分类的深度神经网络，目的是设计一种选择机制来平衡被拒绝的预测比例和所选预测的预测性能改进。

    

    随着机器学习模型在许多具有社会敏感性的任务中的部署增加，对可靠和可信预测的需求也日益增长。实现这些要求的一种方法是允许模型在存在高错误风险时放弃进行预测。这需要为模型添加选择机制，该机制选择模型将提供预测的例子。选择性分类框架旨在设计一个平衡被拒绝预测比例（即模型不进行预测的例子比例）与在所选预测上的预测性能改进之间的机制。存在多个选择性分类框架，其中大多数依赖于深度神经网络架构。然而，现有方法的实证评估仍局限于部分方法和设置之间的比较，给实践者提供了很少的见解。

    With the increasing deployment of machine learning models in many socially-sensitive tasks, there is a growing demand for reliable and trustworthy predictions. One way to accomplish these requirements is to allow a model to abstain from making a prediction when there is a high risk of making an error. This requires adding a selection mechanism to the model, which selects those examples for which the model will provide a prediction. The selective classification framework aims to design a mechanism that balances the fraction of rejected predictions (i.e., the proportion of examples for which the model does not make a prediction) versus the improvement in predictive performance on the selected predictions. Multiple selective classification frameworks exist, most of which rely on deep neural network architectures. However, the empirical evaluation of the existing approaches is still limited to partial comparisons among methods and settings, providing practitioners with little insight into 
    
[^8]: 使用稳健加权分数进行高维二分类不平衡基因表达数据的特征选择

    Feature Selection via Robust Weighted Score for High Dimensional Binary Class-Imbalanced Gene Expression Data. (arXiv:2401.12667v1 [stat.ML])

    [http://arxiv.org/abs/2401.12667](http://arxiv.org/abs/2401.12667)

    本文提出了一种用于高维基因表达二分类问题的稳健加权分数（ROWSU）方法，解决了基因表达数据中高度倾斜的类别分布对分类算法性能的不利影响问题。

    

    本文提出了一种用于高维基因表达二分类问题的稳健加权分数（ROWSU）方法，用于选择最具有区分性的特征。该方法解决了基因表达数据中高度倾斜的类别分布对分类算法性能的不利影响问题。首先，通过从少数类别观测数据中合成生成数据点来平衡训练数据集。其次，采用贪婪搜索方法选择最小的基因子集。然后，引入一种新颖的加权稳健分数，其中权重由支持向量计算，以获得一组精炼的基因。基于这种方法得到的最高分数基因与贪婪搜索方法选择的最小基因子集相结合，形成最终的基因集合。这种新颖的方法确保在存在偏斜类别分布的情况下选择最具有区分性的基因。

    In this paper, a robust weighted score for unbalanced data (ROWSU) is proposed for selecting the most discriminative feature for high dimensional gene expression binary classification with class-imbalance problem. The method addresses one of the most challenging problems of highly skewed class distributions in gene expression datasets that adversely affect the performance of classification algorithms. First, the training dataset is balanced by synthetically generating data points from minority class observations. Second, a minimum subset of genes is selected using a greedy search approach. Third, a novel weighted robust score, where the weights are computed by support vectors, is introduced to obtain a refined set of genes. The highest-scoring genes based on this approach are combined with the minimum subset of genes selected by the greedy search approach to form the final set of genes. The novel method ensures the selection of the most discriminative genes, even in the presence of ske
    
[^9]: 解读等变表示

    Interpreting Equivariant Representations. (arXiv:2401.12588v1 [cs.LG])

    [http://arxiv.org/abs/2401.12588](http://arxiv.org/abs/2401.12588)

    本文研究了潜在表示的等变性以及在使用中考虑等变模型的归纳偏差的重要性，提出了选择不变投影的原则，并展示了两个实例的影响。

    

    对于深度学习模型的可视化、插值或特征提取等下游任务，潜在表示被广泛使用。不变和等变神经网络是用于强制执行归纳偏差的强大且已建立的模型。本文表明，在使用潜在表示时，必须同时考虑等变模型施加的归纳偏差。我们展示了不考虑归纳偏差会导致下游任务性能下降，相反，通过使用潜在表示的不变投影可以有效地考虑归纳偏差。我们提出了选择这样一个投影的原则，并展示了在两个常见例子中使用这些原则的影响：首先，我们研究了一种用于分子图生成的置换等变变分自动编码器；在这里，我们展示了可以设计出不产生信息损失的不变投影。

    Latent representations are used extensively for downstream tasks, such as visualization, interpolation or feature extraction of deep learning models. Invariant and equivariant neural networks are powerful and well-established models for enforcing inductive biases. In this paper, we demonstrate that the inductive bias imposed on the by an equivariant model must also be taken into account when using latent representations. We show how not accounting for the inductive biases leads to decreased performance on downstream tasks, and vice versa, how accounting for inductive biases can be done effectively by using an invariant projection of the latent representations. We propose principles for how to choose such a projection, and show the impact of using these principles in two common examples: First, we study a permutation equivariant variational auto-encoder trained for molecule graph generation; here we show that invariant projections can be designed that incur no loss of information in the
    
[^10]: DDMI: 面向领域无关的隐式神经表示的高质量合成的潜在扩散模型

    DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations. (arXiv:2401.12517v1 [cs.LG])

    [http://arxiv.org/abs/2401.12517](http://arxiv.org/abs/2401.12517)

    DDMI是一种面向领域无关的隐式神经表示的高质量合成的潜在扩散模型，通过生成自适应位置嵌入而不是网络权重，解决了现有方法中生成质量较低的问题。

    

    最近的研究引入了一类用于合成各个领域中任意连续信号的隐式神经表示生成模型，为领域无关的生成模型打开了大门，但往往无法实现高质量的生成。我们观察到现有方法通过生成神经网络的权重来参数化隐式神经表示，并使用固定的位置嵌入来评估网络。可以说，这种架构限制了生成模型的表达能力，导致隐式神经表示生成的质量较低。为了解决这个限制，我们提出了一种面向领域无关的隐式神经表示的潜在扩散模型 (DDMI)，其生成自适应位置嵌入而不是网络权重。具体而言，我们开发了一个离散到连续空间的变分自编码器 (D2C-VAE)，它在共享的潜在空间中无缝连接离散数据和连续信号函数。此外，我们引入了一种新颖的...

    Recent studies have introduced a new class of generative models for synthesizing implicit neural representations (INRs) that capture arbitrary continuous signals in various domains. These models opened the door for domain-agnostic generative models, but they often fail to achieve high-quality generation. We observed that the existing methods generate the weights of neural networks to parameterize INRs and evaluate the network with fixed positional embeddings (PEs). Arguably, this architecture limits the expressive power of generative models and results in low-quality INR generation. To address this limitation, we propose Domain-agnostic Latent Diffusion Model for INRs (DDMI) that generates adaptive positional embeddings instead of neural networks' weights. Specifically, we develop a Discrete-to-continuous space Variational AutoEncoder (D2C-VAE), which seamlessly connects discrete data and the continuous signal functions in the shared latent space. Additionally, we introduce a novel con
    
[^11]: 绝热量子支持向量机

    Adiabatic Quantum Support Vector Machines. (arXiv:2401.12485v1 [cs.LG])

    [http://arxiv.org/abs/2401.12485](http://arxiv.org/abs/2401.12485)

    本文描述了一种用于训练支持向量机的绝热量子方法，与经典方法相比，我们的方法在时间复杂度上取得了一个数量级的改进，并且在五个基准数据集上取得了与经典方法相当的测试准确率。我们还展示了我们的方法具有良好的可扩展性。

    

    绝热量子计算机可以解决困难的优化问题（例如二次无约束二进制优化问题），并且它们似乎非常适合用于训练机器学习模型。在本文中，我们描述了一种用于训练支持向量机的绝热量子方法。我们展示了我们的量子方法的时间复杂度比经典方法好一个数量级。接下来，我们在五个基准数据集（Iris，Wisconsin乳腺癌（WBC），Wine，Digits和Lambeq）上将我们的量子方法的测试准确率与使用Python中的Scikit-learn库的经典方法进行了比较。我们展示了我们的量子方法获得了与经典方法相当的准确度。最后，我们进行了一项可扩展性研究，其中我们计算了量子方法和经典方法在训练数据集中特征数量和数据点数量增加时的总训练时间。我们的可扩展性结果显示，量子方法具有良好的可扩展性。

    Adiabatic quantum computers can solve difficult optimization problems (e.g., the quadratic unconstrained binary optimization problem), and they seem well suited to train machine learning models. In this paper, we describe an adiabatic quantum approach for training support vector machines. We show that the time complexity of our quantum approach is an order of magnitude better than the classical approach. Next, we compare the test accuracy of our quantum approach against a classical approach that uses the Scikit-learn library in Python across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC), Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracies on par with the classical approach. Finally, we perform a scalability study in which we compute the total training times of the quantum approach and the classical approach with increasing number of features and number of data points in the training dataset. Our scalability results show that the quantum approa
    
[^12]: 非参数 logistic 回归与深度学习

    Nonparametric logistic regression with deep learning. (arXiv:2401.12482v1 [math.ST])

    [http://arxiv.org/abs/2401.12482](http://arxiv.org/abs/2401.12482)

    本文提出了一种简单的方法来分析非参数 logistic 回归问题，通过在温和的假设下，在 Hellinger 距离下推导出了最大似然估计器的收敛速率。

    

    考虑非参数 logistic 回归问题。在 logistic 回归中，我们通常考虑最大似然估计器，而过度风险是真实条件类概率和估计条件类概率之间 Kullback-Leibler (KL) 散度的期望。然而，在非参数 logistic 回归中，KL 散度很容易发散，因此，过度风险的收敛很难证明或不成立。若干现有研究表明，在强假设下 KL 散度的收敛性。在大多数情况下，我们的目标是估计真实的条件类概率。因此，不需要分析过度风险本身，只需在某些合适的度量下证明最大似然估计器的一致性即可。在本文中，我们使用简单统一的方法分析非参数最大似然估计器 (NPMLE)，直接推导出 NPMLE 在 Hellinger 距离下的收敛速率，在温和的假设下成立。

    Consider the nonparametric logistic regression problem. In the logistic regression, we usually consider the maximum likelihood estimator, and the excess risk is the expectation of the Kullback-Leibler (KL) divergence between the true and estimated conditional class probabilities. However, in the nonparametric logistic regression, the KL divergence could diverge easily, and thus, the convergence of the excess risk is difficult to prove or does not hold. Several existing studies show the convergence of the KL divergence under strong assumptions. In most cases, our goal is to estimate the true conditional class probabilities. Thus, instead of analyzing the excess risk itself, it suffices to show the consistency of the maximum likelihood estimator in some suitable metric. In this paper, using a simple unified approach for analyzing the nonparametric maximum likelihood estimator (NPMLE), we directly derive the convergence rates of the NPMLE in the Hellinger distance under mild assumptions. 
    
[^13]: 用深度学习和降阶建模进行贝叶斯非分离哈密顿系统的识别和多项式噪声 (arXiv:2401.12476v1 [stat.ML])

    Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling. (arXiv:2401.12476v1 [stat.ML])

    [http://arxiv.org/abs/2401.12476](http://arxiv.org/abs/2401.12476)

    本文提出了一种用于学习非分离哈密顿系统的结构保持的贝叶斯方法，可以处理统计相关的加性和乘性噪声，并且通过将结构保持方法纳入框架中，提供了对高维系统的高效识别。

    

    本文提出了一种结构保持的贝叶斯方法，用于学习使用随机动力模型的非分离哈密顿系统，该系统允许统计相关的，矢量值的加性和乘性测量噪声。该方法由三个主要方面组成。首先，我们推导了一个用于评估贝叶斯后验中的似然函数所需的统计相关的，矢量值的加性和乘性噪声模型的高斯滤波器。其次，我们开发了一种新算法，用于对高维系统进行高效的贝叶斯系统识别。第三，我们演示了如何将结构保持方法纳入所提议的框架中，使用非分离哈密顿系统作为一个举例的系统类别。我们将贝叶斯方法与一种最先进的机器学习方法在一个典型的非分离哈密顿模型和带有小型噪声训练数据集的混沌双摆模型上进行了比较，实验结果表明

    This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that us
    
[^14]: 改进深度贝叶斯模型的变分推断方法

    Towards Improved Variational Inference for Deep Bayesian Models. (arXiv:2401.12418v1 [cs.LG])

    [http://arxiv.org/abs/2401.12418](http://arxiv.org/abs/2401.12418)

    本论文探讨了改进深度贝叶斯模型的变分推断方法，旨在解决深度模型训练过程中的过度自信和不准确预测问题。通过使用变分推断提供的后验近似和边缘似然下界，可以优化超参数并实现模型选择。

    

    在过去的十年中，深度学习在计算机视觉、自然语言处理和强化学习等多个领域取得了重大突破。然而，众所周知，通过最大似然估计训练的深度模型往往过于自信，并且给出的预测不准确。贝叶斯深度学习试图通过给模型参数设置先验来解决这个问题，然后将先验与似然函数结合进行后验推断。然而，对于深度模型来说，真实的后验是无法计算的，因此需要使用近似方法。在本论文中，我们探讨了使用变分推断作为近似的方法，因为它既可以近似后验分布又可以提供边缘似然的下界。如果下界足够紧致，这个下界可以用来优化超参数和进行模型选择。然而，这种能力很少受到重视。

    Deep learning has revolutionized the last decade, being at the forefront of extraordinary advances in a wide range of tasks including computer vision, natural language processing, and reinforcement learning, to name but a few. However, it is well-known that deep models trained via maximum likelihood estimation tend to be overconfident and give poorly-calibrated predictions. Bayesian deep learning attempts to address this by placing priors on the model parameters, which are then combined with a likelihood to perform posterior inference. Unfortunately, for deep models, the true posterior is intractable, forcing the user to resort to approximations. In this thesis, we explore the use of variational inference (VI) as an approximation, as it is unique in simultaneously approximating the posterior and providing a lower bound to the marginal likelihood. If tight enough, this lower bound can be used to optimize hyperparameters and to facilitate model selection. However, this capacity has rarel
    
[^15]: 图神经网络中带有Pfaffian激活函数的VC维度

    VC dimension of Graph Neural Networks with Pfaffian activation functions. (arXiv:2401.12362v1 [stat.ML])

    [http://arxiv.org/abs/2401.12362](http://arxiv.org/abs/2401.12362)

    本文分析了图神经网络（GNN）中使用不同常用激活函数（如sigmoid和双曲正切）时的VC维度，采用了Pfaffian函数理论框架，通过架构参数和合作数量提供了界限。

    

    图神经网络（GNN）近年来作为一种强大的工具出现，以数据驱动的方式学习各种图领域的任务；基于消息传递机制，GNN由于其与Weisfeiler-Lehman（WL）图同构测试密切相关的直观表达而越来越受欢迎，它们已被证明等价。从理论角度看，GNN被证明是通用逼近器，并且最近对具有分段多项式激活函数的GNN的泛化能力（即，对Vapnik Cherovenikis（VC）维度的界限）进行了研究。我们的工作目标是将对GNN的VC维度的分析扩展到其他常用激活函数，如sigmoid和双曲正切，使用Pfaffian函数理论框架。提供了与架构参数（深度，神经元数量，输入尺寸）以及与合作数量有关的界限。

    Graph Neural Networks (GNNs) have emerged in recent years as a powerful tool to learn tasks across a wide range of graph domains in a data-driven fashion; based on a message passing mechanism, GNNs have gained increasing popularity due to their intuitive formulation, closely linked with the Weisfeiler-Lehman (WL) test for graph isomorphism, to which they have proven equivalent. From a theoretical point of view, GNNs have been shown to be universal approximators, and their generalization capability (namely, bounds on the Vapnik Chervonekis (VC) dimension) has recently been investigated for GNNs with piecewise polynomial activation functions. The aim of our work is to extend this analysis on the VC dimension of GNNs to other commonly used activation functions, such as sigmoid and hyperbolic tangent, using the framework of Pfaffian function theory. Bounds are provided with respect to architecture parameters (depth, number of neurons, input size) as well as with respect to the number of co
    
[^16]: 基于对比学习和循环一致性的跨领域转导迁移学习用于目标标注

    Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation. (arXiv:2401.12340v1 [cs.CV])

    [http://arxiv.org/abs/2401.12340](http://arxiv.org/abs/2401.12340)

    本论文提出了一种基于对比学习和循环一致性的混合非配对域转换网络（H-CUT）来解决自动目标识别（ATR）中标记数据不足的问题。该方法在跨领域转导迁移学习中取得了显著低的FID分数，并通过注意力和熵来强调领域特定区域，以生成高质量的合成图像。

    

    自动目标识别（ATR）的注释是一项极具挑战性的任务，主要由于目标域中标记数据的缺乏。因此，通过利用源域图像的标记信息来构建最佳目标域分类器是至关重要的。先前在文献中提出了一种包含基于CycleGAN的非配对域转换网络的跨领域转导迁移学习（TTL）方法，用于有效的ATR标注。尽管该方法显示出了ATR的巨大潜力，但它严重受到注释性能较低、更高的Fr\'echet Inception Distance（FID）分数以及合成图像中存在的视觉伪影的困扰。为了解决这些问题，我们提出了一种基于对比学习和循环一致性的混合非配对域转换（H-CUT）网络，它实现了显著较低的FID分数。它结合了注意力和熵来强调领域特定的区域，噪声特征混合模块用于生成高质量的合成图像。

    Annotating automatic target recognition (ATR) is a highly challenging task, primarily due to the unavailability of labeled data in the target domain. Hence, it is essential to construct an optimal target domain classifier by utilizing the labeled information of the source domain images. The transductive transfer learning (TTL) method that incorporates a CycleGAN-based unpaired domain translation network has been previously proposed in the literature for effective ATR annotation. Although this method demonstrates great potential for ATR, it severely suffers from lower annotation performance, higher Fr\'echet Inception Distance (FID) score, and the presence of visual artifacts in the synthetic images. To address these issues, we propose a hybrid contrastive learning base unpaired domain translation (H-CUT) network that achieves a significantly lower FID score. It incorporates both attention and entropy to emphasize the domain-specific region, a noisy feature mixup module to generate high
    
[^17]: 针对非参数回归的迁移学习：非渐近极小化分析和自适应过程

    Transfer Learning for Nonparametric Regression: Non-asymptotic Minimax Analysis and Adaptive Procedure. (arXiv:2401.12272v1 [stat.ML])

    [http://arxiv.org/abs/2401.12272](http://arxiv.org/abs/2401.12272)

    本文研究了非参数回归的迁移学习问题，提出了一种新的置信阈值估计器来实现渐近最小风险，并发现了迁移学习中的两个独特现象：自动平滑和超加速。此外，我们还提出了一种数据驱动算法，可以适应广泛的参数空间，并在仿真研究和真实世界的例子中证明了该方法的优势。

    

    本文研究了非参数回归的迁移学习问题。首先，我们研究了该问题的非渐近极小风险，并开发了一种新的估计器，称为置信阈值估计器，证明该估计器在一个对数因子的范围内实现了渐近极小的风险。我们的结果展示了迁移学习中的两个独特现象：自动平滑和超加速，这使其与传统设置中的非参数回归有所区别。然后，我们提出了一种数据驱动算法，通过自适应地在广泛的参数空间中实现了对数因子的渐近最小风险。通过仿真研究评估了自适应迁移学习算法的数值性能，并提供了一个真实世界的例子来展示该方法的好处。

    Transfer learning for nonparametric regression is considered. We first study the non-asymptotic minimax risk for this problem and develop a novel estimator called the confidence thresholding estimator, which is shown to achieve the minimax optimal risk up to a logarithmic factor. Our results demonstrate two unique phenomena in transfer learning: auto-smoothing and super-acceleration, which differentiate it from nonparametric regression in a traditional setting. We then propose a data-driven algorithm that adaptively achieves the minimax risk up to a logarithmic factor across a wide range of parameter spaces. Simulation studies are conducted to evaluate the numerical performance of the adaptive transfer learning algorithm, and a real-world example is provided to demonstrate the benefits of the proposed method.
    
[^18]: 使用稀疏牛顿迭代加速Sinkhorn算法

    Accelerating Sinkhorn Algorithm with Sparse Newton Iterations. (arXiv:2401.12253v1 [math.OC])

    [http://arxiv.org/abs/2401.12253](http://arxiv.org/abs/2401.12253)

    该论文提出了一种扩展的Sinkhorn算法，通过引入提前停止和牛顿迭代子程序，实现了可能的超指数收敛。他们利用了Sinkhorn算法最大化凹性李雅普诺夫势的特性，发现了势函数的Hessian矩阵近似稀疏，从而将每次迭代的复杂性降低到了$O(n^2)$。

    

    在机器学习中，计算统计分布之间的最优传输距离是一项基本任务。最近的一项突破性进展是熵正则化和Sinkhorn算法，它只使用矩阵缩放并保证近似解的线性运行时间。尽管Sinkhorn算法取得了成功，但由于可能需要大量迭代来达到收敛，它的运行时间仍可能较慢。为了实现可能的超指数收敛，我们提出了Sinkhorn-Newton-Sparse（SNS），这是Sinkhorn算法的一个扩展，通过引入矩阵缩放步骤的提前停止和一个特征牛顿子程序的第二阶段来实现。采用Sinkhorn算法最大化凹性李雅普诺夫势的变分视角，我们得出结论，势函数的Hessian矩阵近似稀疏。稀疏化Hessian矩阵导致每次迭代的复杂性为快速的$O(n^2)$，与传统Sinkhorn算法相同。

    Computing the optimal transport distance between statistical distributions is a fundamental task in machine learning. One remarkable recent advancement is entropic regularization and the Sinkhorn algorithm, which utilizes only matrix scaling and guarantees an approximated solution with near-linear runtime. Despite the success of the Sinkhorn algorithm, its runtime may still be slow due to the potentially large number of iterations needed for convergence. To achieve possibly super-exponential convergence, we present Sinkhorn-Newton-Sparse (SNS), an extension to the Sinkhorn algorithm, by introducing early stopping for the matrix scaling steps and a second stage featuring a Newton-type subroutine. Adopting the variational viewpoint that the Sinkhorn algorithm maximizes a concave Lyapunov potential, we offer the insight that the Hessian matrix of the potential function is approximately sparse. Sparsification of the Hessian results in a fast $O(n^2)$ per-iteration complexity, the same as t
    
[^19]: 无害过度拟合对敌对鲁棒性的意外危害

    The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness. (arXiv:2401.12236v1 [cs.LG])

    [http://arxiv.org/abs/2401.12236](http://arxiv.org/abs/2401.12236)

    这项研究证明了即使机器学习模型在训练过程中对噪声数据拟合得很好，对敌对示例具有鲁棒性，但当面临敌对操纵的数据时，过度拟合的模型可能会给系统带来意外的危害。

    

    最近的实证和理论研究已经证明了大规模机器学习模型对训练噪声数据的泛化能力。在本文中，我们证明了一个令人惊讶的结果：即使真正的数据本身对敌对示例具有鲁棒性，而且过度拟合的模型在“标准”的样本外风险目标上是无害的，但在样本外数据受到敌对操纵时，这种无害的过度拟合过程可能是有害的。具体而言，我们的主要结果包含两个部分：（i）在过度参数化线性模型中，最小范数估计总是在“无害过度拟合”设置中导致敌对易受攻击；（ii）我们验证了每个岭回归估计器的标准风险和“敌对”风险之间的渐进权衡结果，这意味着在适当的条件下，这两个项目不能同时通过任何单个岭正则化参数的选择来保持很小。

    Recent empirical and theoretical studies have established the generalization capabilities of large machine learning models that are trained to (approximately or exactly) fit noisy data. In this work, we prove a surprising result that even if the ground truth itself is robust to adversarial examples, and the benignly overfitted model is benign in terms of the ``standard'' out-of-sample risk objective, this benign overfitting process can be harmful when out-of-sample data are subject to adversarial manipulation. More specifically, our main results contain two parts: (i) the min-norm estimator in overparameterized linear model always leads to adversarial vulnerability in the ``benign overfitting'' setting; (ii) we verify an asymptotic trade-off result between the standard risk and the ``adversarial'' risk of every ridge regression estimator, implying that under suitable conditions these two items cannot both be small at the same time by any single choice of the ridge regularization parame
    
[^20]: 异质性随机对照试验中时间到事件结果的亚组分析方法

    Subgroup analysis methods for time-to-event outcomes in heterogeneous randomized controlled trials. (arXiv:2401.11842v1 [stat.ME])

    [http://arxiv.org/abs/2401.11842](http://arxiv.org/abs/2401.11842)

    本论文评估了多种时间到事件结果的亚组分析算法，填补了这一领域的研究空白，并提出了一种新的数据生成过程，可以探索不同的异质性情景。

    

    非显著的随机对照试验可能隐藏了对实验性药物有良好反应的亚组，从而阻碍了后续的发展。鉴定这种异质性治疗效应对于精准医学至关重要，为此已经开发出许多事后分析方法。虽然已经进行了几个基准测试来鉴定这些方法的优点和缺点，尤其是对于二进制和连续终点，但是对于时间到事件终点的亚组分析缺乏类似的系统实证评估。本工作旨在通过评估几种时间到事件结果的亚组分析算法来填补这个空白，通过三个不同的研究问题：是否存在异质性？什么生物标志物是导致这种异质性的原因？谁是对治疗有良好反应的人？在这种情况下，我们提出了一种新的合成和半合成数据生成过程，使人们能够探索广泛的异质性情景。

    Non-significant randomized control trials can hide subgroups of good responders to experimental drugs, thus hindering subsequent development. Identifying such heterogeneous treatment effects is key for precision medicine and many post-hoc analysis methods have been developed for that purpose. While several benchmarks have been carried out to identify the strengths and weaknesses of these methods, notably for binary and continuous endpoints, similar systematic empirical evaluation of subgroup analysis for time-to-event endpoints are lacking. This work aims to fill this gap by evaluating several subgroup analysis algorithms in the context of time-to-event outcomes, by means of three different research questions: Is there heterogeneity? What are the biomarkers responsible for such heterogeneity? Who are the good responders to treatment? In this context, we propose a new synthetic and semi-synthetic data generation process that allows one to explore a wide range of heterogeneity scenarios 
    
[^21]: 通过双层优化进行联合无监督和监督训练的自动语音识别方法

    Joint Unsupervised and Supervised Training for Automatic Speech Recognition via Bilevel Optimization. (arXiv:2401.06980v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2401.06980](http://arxiv.org/abs/2401.06980)

    本文提出了一种双层优化的训练方法，用于自动语音识别，通过联合无监督和监督训练来提高性能。

    

    本文提出了一种新颖的基于双层优化的训练方法，用于自动语音识别（ASR）任务中的声学模型训练，我们称之为“双层联合无监督和监督训练（BL-JUST）”。BL-JUST采用下层和上层优化，分别使用无监督损失和监督损失，利用最近在惩罚型双层优化方面取得的进展来解决这一具有可承受复杂度和严格收敛性保证的挑战性ASR问题。

    In this paper, we present a novel bilevel optimization-based training approach to training acoustic models for automatic speech recognition (ASR) tasks that we term {bi-level joint unsupervised and supervised training (BL-JUST)}. {BL-JUST employs a lower and upper level optimization with an unsupervised loss and a supervised loss respectively, leveraging recent advances in penalty-based bilevel optimization to solve this challenging ASR problem with affordable complexity and rigorous convergence guarantees.} To evaluate BL-JUST, extensive experiments on the LibriSpeech and TED-LIUM v2 datasets have been conducted. BL-JUST achieves superior performance over the commonly used pre-training followed by fine-tuning strategy.
    
[^22]: 定价的因果预测方法

    Causal Forecasting for Pricing. (arXiv:2312.15282v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2312.15282](http://arxiv.org/abs/2312.15282)

    本文提出了一种在定价环境下进行需求预测的新方法，通过将因果推断的双重机器学习方法和最先进的基于变压器的预测模型结合在一起，我们的方法在完全控制的情况下更好地估计因果效应，并在离线政策设置中优于其他预测方法。

    

    本文提出了一种在定价环境下进行需求预测的新方法。在这种情况下，建模价格作为需求的输入变量之间的因果关系至关重要，因为零售商的目标是以（利润）最佳方式设定价格，以解决下游决策问题。我们的方法将因果推断的双重机器学习方法和最先进的基于变压器的预测模型结合在一起。通过大量的实证实验，我们一方面展示了我们的方法在完全控制的情况下对合成的、但现实的数据更好地估计因果效应。另一方面，我们还展示了在实际数据中，我们的方法在离线政策设置（即定价政策发生变化时）中优于其他预测方法，而在在线政策设置中略有落后。

    This paper proposes a novel method for demand forecasting in a pricing context. Here, modeling the causal relationship between price as an input variable to demand is crucial because retailers aim to set prices in a (profit) optimal manner in a downstream decision making problem. Our methods bring together the Double Machine Learning methodology for causal inference and state-of-the-art transformer-based forecasting models. In extensive empirical experiments, we show on the one hand that our method estimates the causal effect better in a fully controlled setting via synthetic, yet realistic data. On the other hand, we demonstrate on real-world data that our method outperforms forecasting methods in off-policy settings (i.e., when there's a change in the pricing policy) while only slightly trailing in the on-policy setting.
    
[^23]: 训练带有噪声标签的决策树的鲁棒损失函数

    Robust Loss Functions for Training Decision Trees with Noisy Labels. (arXiv:2312.12937v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.12937](http://arxiv.org/abs/2312.12937)

    本文研究了在带有噪声标签的数据上训练决策树的鲁棒损失函数。我们的研究主要有三个贡献：提供了对现有损失函数鲁棒性的新洞察，引入了分布损失函数的框架，并介绍了一种高效的贪婪减少不纯度的学习算法。

    

    我们考虑使用有噪声标签的数据训练决策树，重点研究可以导致鲁棒学习算法的损失函数。我们的贡献有三个。首先，我们对决策树学习背景下许多现有损失函数的鲁棒性提供了新颖的理论洞察力。我们展示了一些损失属于我们所称的保守损失类别，并且保守损失在训练过程中会出现提前停止行为，而在测试过程中具有容忍噪声的预测能力。其次，我们引入了一个构建鲁棒损失函数的框架，称为分布损失。这些损失基于假设的边缘分布应用基于百分位的惩罚，它们通过鲁棒性参数自然地允许适应不同的噪声率。特别地，我们引入了一种称为负指数损失的新损失，它可以导致高效的贪婪减少不纯度的学习算法。最后，我们在多个数据集和噪声条件下进行了实验证明了我们的方法的有效性。

    We consider training decision trees using noisily labeled data, focusing on loss functions that can lead to robust learning algorithms. Our contributions are threefold. First, we offer novel theoretical insights on the robustness of many existing loss functions in the context of decision tree learning. We show that some of the losses belong to a class of what we call conservative losses, and the conservative losses lead to an early stopping behavior during training and noise-tolerant predictions during testing. Second, we introduce a framework for constructing robust loss functions, called distribution losses. These losses apply percentile-based penalties based on an assumed margin distribution, and they naturally allow adapting to different noise rates via a robustness parameter. In particular, we introduce a new loss called the negative exponential loss, which leads to an efficient greedy impurity-reduction learning algorithm. Lastly, our experiments on multiple datasets and noise se
    
[^24]: 对于核机器在预处理中的Nystrom逼近

    On the Nystrom Approximation for Preconditioning in Kernel Machines. (arXiv:2312.03311v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2312.03311](http://arxiv.org/abs/2312.03311)

    本文分析了核机器预处理中使用Nystrom逼近的权衡。研究表明，使用对数大小的样本能够让Nystrom逼近的预处理器几乎与梯度下降同样有效地加速。

    

    核方法是机器学习中一类流行的非线性预测模型。学习核模型的可扩展算法需要具有迭代性质，但由于糟糕的条件，收敛可能很慢。谱预处理是加快训练核模型迭代算法收敛速度的重要工具。然而，计算和存储谱预处理器可能代价高昂，会导致大量的计算和存储开销，限制了核方法在大型数据集问题上的应用。Nystrom逼近的谱预处理器通常更便宜和更容易计算和存储，并在实际应用中取得了成功。本文分析了使用这种逼近预处理器的权衡。具体来说，我们表明与数据集大小相关的对数样本数量能够让基于Nystrom逼近的预处理器几乎与梯度下降同样有效地加速。

    Kernel methods are a popular class of nonlinear predictive models in machine learning. Scalable algorithms for learning kernel models need to be iterative in nature, but convergence can be slow due to poor conditioning. Spectral preconditioning is an important tool to speed-up the convergence of such iterative algorithms for training kernel models. However computing and storing a spectral preconditioner can be expensive which can lead to large computational and storage overheads, precluding the application of kernel methods to problems with large datasets. A Nystrom approximation of the spectral preconditioner is often cheaper to compute and store, and has demonstrated success in practical applications. In this paper we analyze the trade-offs of using such an approximated preconditioner. Specifically, we show that a sample of logarithmic size (as a function of the size of the dataset) enables the Nystrom-based approximated preconditioner to accelerate gradient descent nearly as well as
    
[^25]: 条件变分扩散模型

    Conditional Variational Diffusion Models. (arXiv:2312.02246v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.02246](http://arxiv.org/abs/2312.02246)

    该论文提出了一种新的条件变分扩散模型，通过学习调度作为训练过程的一部分，解决了扩散模型的敏感性问题，并且能够适应不同的应用场景，提供高质量的解决方案。

    

    逆问题旨在从观测中确定参数，这是工程和科学中的一个关键任务。最近，生成模型，特别是扩散模型，因其能够产生逼真的解决方案和良好的数学特性而在这一领域中越来越受欢迎。尽管取得了成功，但扩散模型的一个重要缺点是对方差调度的选择敏感，该调度控制着扩散过程的动态。为特定应用程序微调这个调度是至关重要的，但时间成本高昂，并且不能保证最优结果。我们提出了一种新颖的方法，将学习调度作为训练过程的一部分。我们的方法支持对数据的概率条件，提供高质量的解决方案，并且具有灵活性，能够在最小的开销下适应不同的应用。这种方法在两个不相关的逆问题中进行了测试：超分辨率显微镜和定量相位成像，结果表明比较或更好。

    Inverse problems aim to determine parameters from observations, a crucial task in engineering and science. Lately, generative models, especially diffusion models, have gained popularity in this area for their ability to produce realistic solutions and their good mathematical properties. Despite their success, an important drawback of diffusion models is their sensitivity to the choice of variance schedule, which controls the dynamics of the diffusion process. Fine-tuning this schedule for specific applications is crucial but time-costly and does not guarantee an optimal result. We propose a novel approach for learning the schedule as part of the training process. Our method supports probabilistic conditioning on data, provides high-quality solutions, and is flexible, proving able to adapt to different applications with minimum overhead. This approach is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging, yielding comparable or superior 
    
[^26]: 学习非稳态条件下的稳定性原则

    A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])

    [http://arxiv.org/abs/2310.18304](http://arxiv.org/abs/2310.18304)

    本研究提出了一个适用于非稳态环境的统计学习框架，通过应用稳定性原则选择回溯窗口来最大化历史数据利用，并保持累积偏差在可接受范围内。该方法展示了对未知非稳态的适应性，遗憾界在强凸或满足Lipschitz条件下是极小化的最优解。该研究的创新点是函数相似度度量和非稳态数据序列划分技术。

    

    我们在非稳定环境中开发了一个灵活的统计学习框架。在每个时间段，我们的方法应用稳定性原则来选择一个回溯窗口，最大限度地利用历史数据，同时将累积偏差保持在与随机误差相对可接受的范围内。我们的理论展示了该方法对未知非稳定性的适应性。当人口损失函数强凸或仅满足Lipschitz条件时，遗憾界是极小化的最优解，仅受对数因子的影响。我们的分析核心是两个新颖的组成部分：函数之间的相似度度量和将非稳态数据序列划分为准稳态片段的分割技术。

    We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
    
[^27]: 一个基于神经特征学习的几何框架

    A Geometric Framework for Neural Feature Learning. (arXiv:2309.10140v1 [cs.LG])

    [http://arxiv.org/abs/2309.10140](http://arxiv.org/abs/2309.10140)

    本论文提出了一个基于神经特征学习的几何框架，在特征空间中利用几何结构解决学习问题。通过引入特征几何，将统计依赖和特征统一到同一空间中，并使用嵌套技术设计学习算法，展示了其在多变量学习问题中的应用。

    

    我们提出了一个基于神经特征提取器的学习系统设计的新框架，通过利用特征空间中的几何结构。首先，我们引入了特征几何，它将统计依赖和特征统一到同一个具有几何结构的函数空间中。通过应用特征几何，我们将每个学习问题形式化为解决由学习设置指定的依赖组件的最佳特征近似解。我们提出了一种嵌套技术来设计学习算法，从数据样本中学习最佳特征，这可以应用于现有的网络架构和优化器。为了展示嵌套技术的应用，我们进一步讨论了多变量学习问题，包括条件推理和多模态学习，在这些问题中，我们提出了最佳特征并揭示了它们与经典方法的联系。

    We present a novel framework for learning system design based on neural feature extractors by exploiting geometric structures in feature spaces. First, we introduce the feature geometry, which unifies statistical dependence and features in the same functional space with geometric structures. By applying the feature geometry, we formulate each learning problem as solving the optimal feature approximation of the dependence component specified by the learning setting. We propose a nesting technique for designing learning algorithms to learn the optimal features from data samples, which can be applied to off-the-shelf network architectures and optimizers. To demonstrate the application of the nesting technique, we further discuss multivariate learning problems, including conditioned inference and multimodal learning, where we present the optimal features and reveal their connections to classical approaches.
    
[^28]: 高维度稀疏线性回归中的异方差问题及基于分区经验贝叶斯ECM算法的解决方法

    Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm. (arXiv:2309.08783v1 [stat.ME])

    [http://arxiv.org/abs/2309.08783](http://arxiv.org/abs/2309.08783)

    本文提出了一种解决高维度稀疏线性回归中异方差问题的方法，通过基于分区经验贝叶斯ECM算法的异方差高维度线性回归模型来实现。这个模型可以处理残差方差不恒定的情况，并且可以使用插值的经验贝叶斯估计超参数来灵活地调整方差模型。

    

    高维度数据的稀疏线性回归方法通常假设残差具有常数方差。当这一假设被违背时，会导致估计系数的偏差，预测区间长度不合适以及增加I型错误。本文提出一种基于分区经验贝叶斯期望条件最大化(H-PROBE)算法的异方差高维度线性回归模型。H-PROBE是一种计算效率高的最大后验估计方法，基于参数扩展的期望条件最大化(PX-ECM)算法。它通过插值的经验贝叶斯估计超参数，在回归参数上假设最小。方差模型使用了多元对数伽马分布理论的最新进展，并可以包含假设会影响异质性的协变量。我们的方法的动机是通过T2高分辨率神经影像研究与失语指数(AQ)相关性。

    Sparse linear regression methods for high-dimensional data often assume that residuals have constant variance. When this assumption is violated, it can lead to bias in estimated coefficients, prediction intervals with improper length, and increased type I errors. This paper proposes a heteroscedastic (H) high-dimensional linear regression model through a partitioned empirical Bayes Expectation Conditional Maximization (H-PROBE) algorithm. H-PROBE is a computationally efficient maximum a posteriori (MAP) estimation approach based on a Parameter-Expanded Expectation-Conditional-Maximization (PX-ECM) algorithm. It requires minimal prior assumptions on the regression parameters through plug-in empirical Bayes estimates of hyperparameters. The variance model uses recent advances in multivariate log-Gamma distribution theory and can include covariates hypothesized to impact heterogeneity. The motivation of our approach is a study relating Aphasia Quotient (AQ) to high-resolution T2 neuroimag
    
[^29]: 何时使用基于置信度的级联延迟足够？

    When Does Confidence-Based Cascade Deferral Suffice?. (arXiv:2307.02764v1 [cs.LG])

    [http://arxiv.org/abs/2307.02764](http://arxiv.org/abs/2307.02764)

    本研究旨在探讨何时基于置信度的级联延迟可能失败，以及何时备选的延迟策略可能表现更好。通过理论分析和实验证明事后延迟机制能够显著提高性能。

    

    级联是一种经典的策略，可以实现适应性地在样本之间变化的推理成本，其中按顺序调用一系列分类器。延迟规则确定是否调用序列中的下一个分类器，或者终止预测。一种简单的延迟规则利用当前分类器的置信度，例如基于最大预测的softmax概率。尽管对级联结构不敏感——例如不建模下游模型的错误——但这种基于置信度的延迟经常在实践中表现出色。在本文中，我们旨在更好地理解基于置信度的延迟可能失败的条件，以及何时备选的延迟策略可能更好。我们首先对最优延迟规则进行了理论表征，精确地描述了基于置信度的延迟可能受到影响的设置。然后我们研究了事后延迟机制，并验证它们可以显著提高性能。

    Cascades are a classical strategy to enable inference cost to vary adaptively across samples, wherein a sequence of classifiers are invoked in turn. A deferral rule determines whether to invoke the next classifier in the sequence, or to terminate prediction. One simple deferral rule employs the confidence of the current classifier, e.g., based on the maximum predicted softmax probability. Despite being oblivious to the structure of the cascade -- e.g., not modelling the errors of downstream models -- such confidence-based deferral often works remarkably well in practice. In this paper, we seek to better understand the conditions under which confidence-based deferral may fail, and when alternate deferral strategies can perform better. We first present a theoretical characterisation of the optimal deferral rule, which precisely characterises settings under which confidence-based deferral may suffer. We then study post-hoc deferral mechanisms, and demonstrate they can significantly improv
    
[^30]: 处理联邦平均中未知参与概率的轻量级方法

    A Lightweight Method for Tackling Unknown Participation Probabilities in Federated Averaging. (arXiv:2306.03401v1 [cs.LG])

    [http://arxiv.org/abs/2306.03401](http://arxiv.org/abs/2306.03401)

    本文提出了一种轻量级方法来调整联邦平均中的聚合权重，通过根据每个客户的参与历史来处理具有不同参与率的客户，解决了在联邦学习中未知参与概率的问题。

    

    在联邦学习中，客户端通常具有先验未知的不同参与率，如果不适当处理，则可能会对联邦学习的性能造成重大影响。现有的解决方法通常基于全局方差缩减，这需要大量额外的内存，其乘法因子等于客户总数。一个重要的未解决问题是找到一种轻量级方法来处理具备不同参与率客户的联邦学习。在这篇论文中，我们通过根据每个客户的参与历史来调整联邦平均（FedAvg）中的聚合权重来解决此问题。我们首先展示了在具有异构参与概率的情况下，非最优聚合权重的FedAvg可能会从原始FL目标的最优解偏离，这表明需要找到最优聚合权重。然而，当参与概率不可知时计算最优权重非常困难。

    In federated learning (FL), clients usually have diverse participation probabilities that are unknown a priori, which can significantly harm the performance of FL if not handled properly. Existing works aiming at addressing this problem are usually based on global variance reduction, which requires a substantial amount of additional memory in a multiplicative factor equal to the total number of clients. An important open problem is to find a lightweight method for FL in the presence of clients with unknown participation rates. In this paper, we address this problem by adapting the aggregation weights in federated averaging (FedAvg) based on the participation history of each client. We first show that, with heterogeneous participation probabilities, FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective, indicating the need of finding optimal aggregation weights. However, it is difficult to compute the optimal weights when the part
    
[^31]: 基于数据驱动的遗憾平衡在线模型选择的研究

    Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v1 [cs.LG])

    [http://arxiv.org/abs/2306.02869](http://arxiv.org/abs/2306.02869)

    论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。

    

    我们考虑在具有赌博反馈的随机环境中进行顺序决策模型选择，其中元学习器可以使用一组基本学习器，并根据每个基本学习器推荐的策略动态决策。我们通过遗憾平衡来执行模型选择，但与此相关的最近文献不同的是，我们没有假设任何关于基本学习器的先验知识，如候选遗憾保证；相反，我们以数据驱动的方式揭示这些数量。因此，元学习器能够利用每个基本学习器在给定的学习环境中产生的实际遗憾（而不是期望遗憾），并挑选出最佳的遗憾。我们设计了两个模型选择算法，操作更为雄心勃勃的遗憾概念，并且除了通过遗憾平衡证明模型选择保证外，我们还在实验中展示了处理实际遗憾的令人信服的实际优势。

    We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets ins
    
[^32]: 通过稀疏高斯过程校准Transformer

    Calibrating Transformers via Sparse Gaussian Processes. (arXiv:2303.02444v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02444](http://arxiv.org/abs/2303.02444)

    提出了一种通过Sparse Gaussian Process attention (SGPA)来校准Transformer模型不确定性的方法。在文本、图像和图形的预测任务中，SGPA-based Transformers在预测准确性上表现出竞争力，并显著改善了内分布校准和外分布的鲁棒性和检测能力。

    

    Transformer模型在自然语言处理、语音识别和计算机视觉等广泛应用中取得了巨大成功。将Transformer的成功扩展到安全关键领域需要准确估计的不确定性，这方面的研究较少。为了解决这个问题，我们提出了稀疏高斯过程注意力（SGPA），它直接在Transformer的多头自注意力块（MHA）的输出空间中进行贝叶斯推断，以校准其不确定性。它用一个有效的对称核替代了缩放点积操作，并使用稀疏高斯过程（SGP）技术来近似MHA输出的后验过程。经验上，在文本、图像和图形的一系列预测任务中，基于SGPA的Transformer模型实现了有竞争力的预测准确性，同时显著改善了内分布校准和外分布的鲁棒性和检测能力。

    Transformer models have achieved profound success in prediction tasks in a wide range of applications in natural language processing, speech recognition and computer vision. Extending Transformer's success to safety-critical domains requires calibrated uncertainty estimation which remains under-explored. To address this, we propose Sparse Gaussian Process attention (SGPA), which performs Bayesian inference directly in the output space of multi-head attention blocks (MHAs) in transformer to calibrate its uncertainty. It replaces the scaled dot-product operation with a valid symmetric kernel and uses sparse Gaussian processes (SGP) techniques to approximate the posterior processes of MHA outputs. Empirically, on a suite of prediction tasks on text, images and graphs, SGPA-based Transformers achieve competitive predictive accuracy, while noticeably improving both in-distribution calibration and out-of-distribution robustness and detection.
    
[^33]: 同质性在图卷积网络的双下降泛化中的调制作用

    Homophily modulates double descent generalization in graph convolution networks. (arXiv:2212.13069v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13069](http://arxiv.org/abs/2212.13069)

    本文通过使用统计物理和随机矩阵理论的分析工具，精确地表征了简单图卷积网络在背景随机块模型上的泛化，提出了同质性在图卷积网络的泛化中的调制作用。

    

    图神经网络是用于关系数据集（如代谢、交通和社交网络）的最成功的机器学习模型之一。然而，它们对数据中编码的各种交互的强大泛化的决定因素并不为人所知。来自统计学习理论的方法无法解释出现的现象，如双下降或风险取决于交互性质的问题。我们使用统计物理和随机矩阵理论的分析工具来精确地表征简单图卷积网络在背景随机块模型上的泛化。导出的曲线现象学上十分丰富：它们解释了同质性和异质性学习之间的区别，并预测了最近作品所质疑的GNN中双下降现象的存在。我们展示了风险如何取决于图中的噪声、特征中的噪声和用于训练的节点比例之间的相互作用。我们的分析为理解同质性如何调制图神经网络的泛化提供了第一步。

    Graph neural networks are among the most successful machine learning models for relational datasets like metabolic, transportation, and social networks. Yet the determinants of their strong generalization for diverse interactions encoded in the data are not well understood. Methods from statistical learning theory do not explain emergent phenomena such as double descent or the dependence of risk on the nature of interactions. We use analytical tools from statistical physics and random matrix theory to precisely characterize generalization in simple graph convolution networks on the contextual stochastic block model. The derived curves are phenomenologically rich: they explain the distinction between learning on homophilic and heterophilic and they predict double descent whose existence in GNNs has been questioned by recent work. We show how risk depends on the interplay between the noise in the graph, noise in the features, and the proportion of nodes used for training. Our analysis pr
    
[^34]: 通过标准化流进行逐渐领域适应

    Gradual Domain Adaptation via Normalizing Flows. (arXiv:2206.11492v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.11492](http://arxiv.org/abs/2206.11492)

    该论文提出使用标准化流来解决逐渐领域适应中中间域有限且距离较大的问题，并通过从源域到高斯混合分布学习目标域的分布变换。

    

    当源域和目标域之间存在较大差距时，传统的领域适应方法效果不佳。逐渐领域适应是解决该问题的一种方法，它涉及利用逐渐从源域转移到目标域的中间域。在先前的工作中，假设中间域的数量较大且相邻域之间的距离较小，因此，涉及使用无标签数据集进行自我训练的逐渐领域适应算法是可行的。然而，在实践中，逐渐自我训练将失败，因为中间域的数量有限且相邻域之间的距离较大。我们提出使用标准化流来解决这个问题，同时保持无监督领域适应的框架。所提出的方法通过从源域到高斯混合分布学习目标域的分布变换。

    Standard domain adaptation methods do not work well when a large gap exists between the source and target domains. Gradual domain adaptation is one of the approaches used to address the problem. It involves leveraging the intermediate domain, which gradually shifts from the source domain to the target domain. In previous work, it is assumed that the number of intermediate domains is large and the distance between adjacent domains is small; hence, the gradual domain adaptation algorithm, involving self-training with unlabeled datasets, is applicable. In practice, however, gradual self-training will fail because the number of intermediate domains is limited and the distance between adjacent domains is large. We propose the use of normalizing flows to deal with this problem while maintaining the framework of unsupervised domain adaptation. The proposed method learns a transformation from the distribution of the target domain to the Gaussian mixture distribution via the source domain. We e
    

