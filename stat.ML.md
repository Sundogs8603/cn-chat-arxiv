# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Optimal Policy Learning with Observational Data in Multi-Action Scenarios: Estimation, Risk Preference, and Potential Failures](https://arxiv.org/abs/2403.20250) | 本文讨论了多动作场景中利用观测数据进行最优策略学习的方法，着重探讨了估计、风险偏好和潜在故障三个方面。 |
| [^2] | [Functional Bilevel Optimization for Machine Learning](https://arxiv.org/abs/2403.20233) | 介绍了机器学习中的函数双层优化问题，提出了不依赖于强凸假设的方法，并展示了在仪表回归和强化学习任务中使用神经网络的优势。 |
| [^3] | [High-dimensional analysis of ridge regression for non-identically distributed data with a variance profile](https://arxiv.org/abs/2403.20200) | 研究了对于独立但非独立同分布数据的高维回归模型，提出了在岭正则化参数趋近于零时高维回归中的双谷现象。 |
| [^4] | [Dual Simplex Volume Maximization for Simplex-Structured Matrix Factorization](https://arxiv.org/abs/2403.20197) | 通过使用对偶/极性概念，提出了一种双对偶体积最大化方法，用于解决单纯结构矩阵分解问题，填补了现有SSMF算法家族之间的差距。 |
| [^5] | [Conformal Prediction for Stochastic Decision-Making of PV Power in Electricity Markets](https://arxiv.org/abs/2403.20149) | 论文研究了在电力市场中使用一致性预测对光伏电力日前预测进行决策的方法，并发现结合特定出价策略可以在保持能量平衡最小的情况下获得高利润。 |
| [^6] | [A novel decision fusion approach for sale price prediction using Elastic Net and MOPSO](https://arxiv.org/abs/2403.20033) | 该研究提出了一种新型的决策融合方法，通过选择信息性变量来提高价格预测的准确性和效果 |
| [^7] | [Localizing Paragraph Memorization in Language Models](https://arxiv.org/abs/2403.19851) | 论文展示了语言模型中段落记忆的梯度具有可区分的空间模式，通过微调高梯度权重可以取消学习，定位了特别参与段落记忆的低层注意头，并研究了记忆在前缀中的本地化程度。 |
| [^8] | [Deep Learning Framework with Uncertainty Quantification for Survey Data: Assessing and Predicting Diabetes Mellitus Risk in the American Population](https://arxiv.org/abs/2403.19752) | 该论文提出了一个利用神经网络模型进行回归和分类的预测框架，并引入了适用于复杂调查设计数据的不确定性量化算法，以评估美国人群糖尿病风险。 |
| [^9] | [Meta-Learning with Generalized Ridge Regression: High-dimensional Asymptotics, Optimality and Hyper-covariance Estimation](https://arxiv.org/abs/2403.19720) | 本研究在高维多元随机效应线性模型框架下研究了元学习，在使用广义岭回归进行预测时发现，利用随机回归系数的协方差结构可以在新任务上做出更好的预测，并提出了一种最优的权重矩阵选择方法。 |
| [^10] | [On permutation-invariant neural networks](https://arxiv.org/abs/2403.17410) | 神经网络如Deep Sets和Transformers的出现显著推动了基于集合的数据处理的进展 |
| [^11] | [DASA: Delay-Adaptive Multi-Agent Stochastic Approximation](https://arxiv.org/abs/2403.17247) | DASA算法是第一个收敛速度仅依赖于混合时间和平均延迟的算法，同时在马尔科夫采样下实现N倍的收敛加速。 |
| [^12] | [Structured Evaluation of Synthetic Tabular Data](https://arxiv.org/abs/2403.10424) | 提出了一个具有单一数学目标的评估框架，用于确定合成数据应该从与观测数据相同的分布中提取，并且推理了任何一组指标的完整性，统一了现有的指标，并鼓励新的模型无关基线和指标。 |
| [^13] | [New Classes of the Greedy-Applicable Arm Feature Distributions in the Sparse Linear Bandit Problem](https://arxiv.org/abs/2312.12400) | 本文展示了贪婪算法适用于更广泛范围的臂特征分布，提出了新的适用类别和混合分布概念。 |
| [^14] | [Generalization bounds for learning under graph-dependence: A survey](https://arxiv.org/abs/2203.13534) | 通过收集各种图依赖性的集中界限，该研究推导出了用于基于图依赖性数据学习的Rademacher复杂度和稳定性的学习泛化界限。 |
| [^15] | [Two-sample Test using Projected Wasserstein Distance](https://arxiv.org/abs/2010.11970) | 提出了一种使用投影Wasserstein距离进行双样本检验的方法，可以避免高维度情况下的测试能力减弱问题，并通过最优投影和低维线性映射最大化Wasserstein距离来实现。 |
| [^16] | [Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space.](http://arxiv.org/abs/2310.11256) | 本文介绍了两种在高斯混合模型空间中的Gromov-Wasserstein类型距离，分别用于评估分布之间的距离和推导最优的点分配方案。 |
| [^17] | [GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers.](http://arxiv.org/abs/2310.10375) | 提出了一种面向几何的注意力机制（GTA），用于将几何结构编码为相对变换，从而改进了多视图Transformer的学习效率和性能。 |
| [^18] | [A multiobjective continuation method to compute the regularization path of deep neural networks.](http://arxiv.org/abs/2308.12044) | 本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。 |
| [^19] | [Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls.](http://arxiv.org/abs/2304.12420) | 该论文使用了高效的样本集优化和基于代理的方法来设计水下航行器船体，其中代理模型显著提高了计算效率，使优化更加快速准确。 |
| [^20] | [Multi-Antenna Dual-Blind Deconvolution for Joint Radar-Communications via SoMAN Minimization.](http://arxiv.org/abs/2303.13609) | 本论文研究了多天线接收器版本的双盲反卷积问题，提出了使用多元原子范数最小化的方法来恢复雷达和通信信号和通道参数。 |

# 详细

[^1]: 多动作场景中利用观测数据进行最优策略学习：估计、风险偏好和潜在故障

    Optimal Policy Learning with Observational Data in Multi-Action Scenarios: Estimation, Risk Preference, and Potential Failures

    [https://arxiv.org/abs/2403.20250](https://arxiv.org/abs/2403.20250)

    本文讨论了多动作场景中利用观测数据进行最优策略学习的方法，着重探讨了估计、风险偏好和潜在故障三个方面。

    

    本文讨论了利用观测数据进行最优策略学习（OPL），即数据驱动的最优决策，在多动作（或多臂）设置中，有限的决策选项可供选择。文章分为三个部分，分别讨论：估计、风险偏好和潜在故障。第一部分简要回顾了在这种分析背景下估计奖励（或值）函数和最优策略的关键方法。第二部分深入分析了决策风险。分析表明，决策者对风险的态度可以影响最优选择，具体体现在奖励条件均值与条件方差之间的权衡。在这里，作者将所提出的模型应用于...

    arXiv:2403.20250v1 Announce Type: cross  Abstract: This paper deals with optimal policy learning (OPL) with observational data, i.e. data-driven optimal decision-making, in multi-action (or multi-arm) settings, where a finite set of decision options is available. It is organized in three parts, where I discuss respectively: estimation, risk preference, and potential failures. The first part provides a brief review of the key approaches to estimating the reward (or value) function and optimal policy within this context of analysis. Here, I delineate the identification assumptions and statistical properties related to offline optimal policy learning estimators. In the second part, I delve into the analysis of decision risk. This analysis reveals that the optimal choice can be influenced by the decision maker's attitude towards risks, specifically in terms of the trade-off between reward conditional mean and conditional variance. Here, I present an application of the proposed model to rea
    
[^2]: 机器学习中的函数双层优化

    Functional Bilevel Optimization for Machine Learning

    [https://arxiv.org/abs/2403.20233](https://arxiv.org/abs/2403.20233)

    介绍了机器学习中的函数双层优化问题，提出了不依赖于强凸假设的方法，并展示了在仪表回归和强化学习任务中使用神经网络的优势。

    

    在本文中，我们介绍了针对机器学习中的双层优化问题的一种新的函数视角，其中内部目标在函数空间上被最小化。这些类型的问题通常通过在参数设置下开发的方法来解决，其中内部目标对于预测函数的参数强凸。函数视角不依赖于此假设，特别允许使用超参数化的神经网络作为内部预测函数。我们提出了可扩展和高效的算法来解决函数双层优化问题，并展示了我们方法在适合自然函数双层结构的仪表回归和强化学习任务上的优势。

    arXiv:2403.20233v1 Announce Type: cross  Abstract: In this paper, we introduce a new functional point of view on bilevel optimization problems for machine learning, where the inner objective is minimized over a function space. These types of problems are most often solved by using methods developed in the parametric setting, where the inner objective is strongly convex with respect to the parameters of the prediction function. The functional point of view does not rely on this assumption and notably allows using over-parameterized neural networks as the inner prediction function. We propose scalable and efficient algorithms for the functional bilevel optimization problem and illustrate the benefits of our approach on instrumental regression and reinforcement learning tasks, which admit natural functional bilevel structures.
    
[^3]: 对具有方差轮廓的非独立同分布数据的岭回归进行高维分析

    High-dimensional analysis of ridge regression for non-identically distributed data with a variance profile

    [https://arxiv.org/abs/2403.20200](https://arxiv.org/abs/2403.20200)

    研究了对于独立但非独立同分布数据的高维回归模型，提出了在岭正则化参数趋近于零时高维回归中的双谷现象。

    

    针对独立但非独立同分布数据，我们提出研究高维回归模型。假设观测到的预测变量集合是带有方差轮廓的随机矩阵，并且其维度以相应速率增长。在假设随机效应模型的情况下，我们研究了具有这种方差轮廓的岭估计器的线性回归的预测风险。在这种设置下，我们提供了该风险的确定性等价物以及岭估计器的自由度。对于某些方差轮廓类别，我们的工作突出了在岭正则化参数趋于零时，高维回归中的最小模最小二乘估计器出现双谷现象。我们还展示了一些方差轮廓f...

    arXiv:2403.20200v1 Announce Type: cross  Abstract: High-dimensional linear regression has been thoroughly studied in the context of independent and identically distributed data. We propose to investigate high-dimensional regression models for independent but non-identically distributed data. To this end, we suppose that the set of observed predictors (or features) is a random matrix with a variance profile and with dimensions growing at a proportional rate. Assuming a random effect model, we study the predictive risk of the ridge estimator for linear regression with such a variance profile. In this setting, we provide deterministic equivalents of this risk and of the degree of freedom of the ridge estimator. For certain class of variance profile, our work highlights the emergence of the well-known double descent phenomenon in high-dimensional regression for the minimum norm least-squares estimator when the ridge regularization parameter goes to zero. We also exhibit variance profiles f
    
[^4]: 双对偶体积最大化用于单纯结构矩阵分解

    Dual Simplex Volume Maximization for Simplex-Structured Matrix Factorization

    [https://arxiv.org/abs/2403.20197](https://arxiv.org/abs/2403.20197)

    通过使用对偶/极性概念，提出了一种双对偶体积最大化方法，用于解决单纯结构矩阵分解问题，填补了现有SSMF算法家族之间的差距。

    

    Simplex-structured matrix factorization（SSMF）是非负矩阵分解的泛化，是一种基础的可解释数据分析模型，在高光谱解混和和主题建模中有应用。为了获得可识别的解，标准方法是寻找最小体积解。通过利用多面体的对偶/极性概念，我们将原始空间中的最小体积SSMF转换为对偶空间中的最大体积问题。我们首先证明了这个最大体积对偶问题的可识别性。然后，我们使用这个对偶公式提供一种新颖的优化方法，以填补SSMF的两个现有算法家族之间的差距，即体积最小化和面识别。数值实验表明，所提出的方法相对于最先进的SSMF算法表现更好。

    arXiv:2403.20197v1 Announce Type: cross  Abstract: Simplex-structured matrix factorization (SSMF) is a generalization of nonnegative matrix factorization, a fundamental interpretable data analysis model, and has applications in hyperspectral unmixing and topic modeling. To obtain identifiable solutions, a standard approach is to find minimum-volume solutions. By taking advantage of the duality/polarity concept for polytopes, we convert minimum-volume SSMF in the primal space to a maximum-volume problem in the dual space. We first prove the identifiability of this maximum-volume dual problem. Then, we use this dual formulation to provide a novel optimization approach which bridges the gap between two existing families of algorithms for SSMF, namely volume minimization and facet identification. Numerical experiments show that the proposed approach performs favorably compared to the state-of-the-art SSMF algorithms.
    
[^5]: 电力市场中光伏电力随机决策的一致性预测

    Conformal Prediction for Stochastic Decision-Making of PV Power in Electricity Markets

    [https://arxiv.org/abs/2403.20149](https://arxiv.org/abs/2403.20149)

    论文研究了在电力市场中使用一致性预测对光伏电力日前预测进行决策的方法，并发现结合特定出价策略可以在保持能量平衡最小的情况下获得高利润。

    

    这篇论文研究了使用一致性预测（CP），一种新兴的概率预测方法，用于加强在电力市场中日前光伏电力预测的参与。首先，使用机器学习模型构建点预测。然后，实施了几种CP的变体，通过创建CP区间和累积分布函数来量化这些预测的不确定性。在不确定性下估计了多种出价策略下的电力市场的最优数量出价，即：信任预测、最坏情况、Newsvendor和期望效用最大化（EUM）。结果显示，结合k最近邻和/或Mondrian分箱的CP胜过其对应的线性分位数回归器。使用CP结合某些出价策略可以在保持能量平衡最小的情况下获得高利润。具体来说，使用具有k近

    arXiv:2403.20149v1 Announce Type: new  Abstract: This paper studies the use of conformal prediction (CP), an emerging probabilistic forecasting method, for day-ahead photovoltaic power predictions to enhance participation in electricity markets. First, machine learning models are used to construct point predictions. Thereafter, several variants of CP are implemented to quantify the uncertainty of those predictions by creating CP intervals and cumulative distribution functions. Optimal quantity bids for the electricity market are estimated using several bidding strategies under uncertainty, namely: trust-the-forecast, worst-case, Newsvendor and expected utility maximization (EUM). Results show that CP in combination with k-nearest neighbors and/or Mondrian binning outperforms its corresponding linear quantile regressors. Using CP in combination with certain bidding strategies can yield high profit with minimal energy imbalance. In concrete, using conformal predictive systems with k-near
    
[^6]: 使用弹性网络和MOPSO进行销售价格预测的新型决策融合方法

    A novel decision fusion approach for sale price prediction using Elastic Net and MOPSO

    [https://arxiv.org/abs/2403.20033](https://arxiv.org/abs/2403.20033)

    该研究提出了一种新型的决策融合方法，通过选择信息性变量来提高价格预测的准确性和效果

    

    价格预测算法根据市场趋势、预期需求以及其他特征（包括政府规定、国际交易、投机和期望）为每种产品或服务提出价格。作为价格预测中的因变量，价格受到多个独立和相关变量的影响，这可能对价格预测构成挑战。为了克服这一挑战，机器学习算法允许更准确地进行价格预测，而无需明确对变量之间的关联性建模。然而，随着输入变量的增加，这挑战了现有的机器学习方法在计算效率和预测效果上。因此，本研究介绍了一种新颖的决策级融合方法来选择价格预测中的信息性变量。建议的元启发式算法平衡了两个竞争的目标函数，旨在改善利用变量进行预测的效果。

    arXiv:2403.20033v1 Announce Type: cross  Abstract: Price prediction algorithms propose prices for every product or service according to market trends, projected demand, and other characteristics, including government rules, international transactions, and speculation and expectation. As the dependent variable in price prediction, it is affected by several independent and correlated variables which may challenge the price prediction. To overcome this challenge, machine learning algorithms allow more accurate price prediction without explicitly modeling the relatedness between variables. However, as inputs increase, it challenges the existing machine learning approaches regarding computing efficiency and prediction effectiveness. Hence, this study introduces a novel decision level fusion approach to select informative variables in price prediction. The suggested metaheuristic algorithm balances two competitive objective functions, which are defined to improve the prediction utilized vari
    
[^7]: 将语言模型中的段落记忆本地化

    Localizing Paragraph Memorization in Language Models

    [https://arxiv.org/abs/2403.19851](https://arxiv.org/abs/2403.19851)

    论文展示了语言模型中段落记忆的梯度具有可区分的空间模式，通过微调高梯度权重可以取消学习，定位了特别参与段落记忆的低层注意头，并研究了记忆在前缀中的本地化程度。

    

    我们能否将语言模型用于记忆和背诵整个训练数据段的权重和机制本地化？本文表明，虽然记忆分布在多个层次和模型组件中，但记忆段落的梯度具有可区分的空间模式，较低模型层次中的梯度比非记忆示例的梯度更大。此外，这些记忆示例可以通过仅微调高梯度权重来取消学习。我们定位了一个似乎特别参与段落记忆的低层注意头。这个头部主要将注意力集中在在语料库级别的单语分布中最不频繁的独特、罕见的令牌上。接下来，我们通过扰动令牌并测量对解码造成的改变来研究记忆在前缀中的本地化程度。前缀中的一些独特令牌经常会使整个内容受损。

    arXiv:2403.19851v1 Announce Type: new  Abstract: Can we localize the weights and mechanisms used by a language model to memorize and recite entire paragraphs of its training data? In this paper, we show that while memorization is spread across multiple layers and model components, gradients of memorized paragraphs have a distinguishable spatial pattern, being larger in lower model layers than gradients of non-memorized examples. Moreover, the memorized examples can be unlearned by fine-tuning only the high-gradient weights. We localize a low-layer attention head that appears to be especially involved in paragraph memorization. This head is predominantly focusing its attention on distinctive, rare tokens that are least frequent in a corpus-level unigram distribution. Next, we study how localized memorization is across the tokens in the prefix by perturbing tokens and measuring the caused change in the decoding. A few distinctive tokens early in a prefix can often corrupt the entire cont
    
[^8]: 具有不确定性量化的调查数据深度学习框架: 评估和预测美国人群糖尿病风险

    Deep Learning Framework with Uncertainty Quantification for Survey Data: Assessing and Predicting Diabetes Mellitus Risk in the American Population

    [https://arxiv.org/abs/2403.19752](https://arxiv.org/abs/2403.19752)

    该论文提出了一个利用神经网络模型进行回归和分类的预测框架，并引入了适用于复杂调查设计数据的不确定性量化算法，以评估美国人群糖尿病风险。

    

    多种医学队列中通常采用复杂的调查设计。在这种情况下，开发反映研究设计的独特特征的特定病例预测风险评分模型至关重要。本文的目标是:(i) 提出一个通用的预测框架，利用神经网络(NN)建模进行回归和分类，其将调查权重纳入估计过程中;(ii) 引入一种模型预测的不确定性量化算法，专为来自复杂调查设计的数据量身定制;(iii) 应用这种方法开发健壮的风险评分模型，评估美国人群糖尿病风险，利用NHANES 2011-2014队列中的数据。我们的估计器的理论性质旨在确保最小偏差和统计一致性，从而确保我们的

    arXiv:2403.19752v1 Announce Type: cross  Abstract: Complex survey designs are commonly employed in many medical cohorts. In such scenarios, developing case-specific predictive risk score models that reflect the unique characteristics of the study design is essential. This approach is key to minimizing potential selective biases in results. The objectives of this paper are: (i) To propose a general predictive framework for regression and classification using neural network (NN) modeling, which incorporates survey weights into the estimation process; (ii) To introduce an uncertainty quantification algorithm for model prediction, tailored for data from complex survey designs; (iii) To apply this method in developing robust risk score models to assess the risk of Diabetes Mellitus in the US population, utilizing data from the NHANES 2011-2014 cohort. The theoretical properties of our estimators are designed to ensure minimal bias and the statistical consistency, thereby ensuring that our m
    
[^9]: 具有广义岭回归的元学习：高维渐近性、最优性和超协方差估计

    Meta-Learning with Generalized Ridge Regression: High-dimensional Asymptotics, Optimality and Hyper-covariance Estimation

    [https://arxiv.org/abs/2403.19720](https://arxiv.org/abs/2403.19720)

    本研究在高维多元随机效应线性模型框架下研究了元学习，在使用广义岭回归进行预测时发现，利用随机回归系数的协方差结构可以在新任务上做出更好的预测，并提出了一种最优的权重矩阵选择方法。

    

    Meta-learning即元学习，指的是以一种方式在多个训练任务上训练模型，使之能够在新的、未见过的测试任务上有很好的泛化能力。本文将元学习纳入高维多元随机效应线性模型框架中，并研究基于广义岭回归的预测。在该设定下使用广义岭回归的统计直觉是，随机回归系数的协方差结构可以被利用来在新任务上做出更好的预测。我们首先详细描述了在数据维度与每个任务样本数成比例增长时，对于新测试任务的预测风险的精确渐近行为。接着我们证明了当广义岭回归中的权重矩阵选择为随机系数的协方差矩阵的逆时，这种预测风险是最优的。最后，我们提出并分析了一种估计方法。

    arXiv:2403.19720v1 Announce Type: cross  Abstract: Meta-learning involves training models on a variety of training tasks in a way that enables them to generalize well on new, unseen test tasks. In this work, we consider meta-learning within the framework of high-dimensional multivariate random-effects linear models and study generalized ridge-regression based predictions. The statistical intuition of using generalized ridge regression in this setting is that the covariance structure of the random regression coefficients could be leveraged to make better predictions on new tasks. Accordingly, we first characterize the precise asymptotic behavior of the predictive risk for a new test task when the data dimension grows proportionally to the number of samples per task. We next show that this predictive risk is optimal when the weight matrix in generalized ridge regression is chosen to be the inverse of the covariance matrix of random coefficients. Finally, we propose and analyze an estimat
    
[^10]: 论排列不变神经网络

    On permutation-invariant neural networks

    [https://arxiv.org/abs/2403.17410](https://arxiv.org/abs/2403.17410)

    神经网络如Deep Sets和Transformers的出现显著推动了基于集合的数据处理的进展

    

    传统机器学习算法通常在假设输入数据遵循基于向量的格式的前提下设计，着重于基于向量的范式。然而，随着需求涉及基于集合的任务的增长，研究界对解决这些挑战的兴趣发生了范式转变。近年来，Deep Sets和Transformers等神经网络架构的出现在处理基于集合的数据方面取得了重大进展。这些架构专门设计为自然容纳集合作为输入，从而更有效地表示和处理集合结构。因此，近年来出现了大量致力于探索和利用这些架构能力的研究努力，以逼近集合函数的各种任务。这项综合调查旨在概述th

    arXiv:2403.17410v1 Announce Type: cross  Abstract: Conventional machine learning algorithms have traditionally been designed under the assumption that input data follows a vector-based format, with an emphasis on vector-centric paradigms. However, as the demand for tasks involving set-based inputs has grown, there has been a paradigm shift in the research community towards addressing these challenges. In recent years, the emergence of neural network architectures such as Deep Sets and Transformers has presented a significant advancement in the treatment of set-based data. These architectures are specifically engineered to naturally accommodate sets as input, enabling more effective representation and processing of set structures. Consequently, there has been a surge of research endeavors dedicated to exploring and harnessing the capabilities of these architectures for various tasks involving the approximation of set functions. This comprehensive survey aims to provide an overview of th
    
[^11]: DASA: 延迟自适应多智能体随机逼近

    DASA: Delay-Adaptive Multi-Agent Stochastic Approximation

    [https://arxiv.org/abs/2403.17247](https://arxiv.org/abs/2403.17247)

    DASA算法是第一个收敛速度仅依赖于混合时间和平均延迟的算法，同时在马尔科夫采样下实现N倍的收敛加速。

    

    我们考虑一种设置，其中$N$个智能体旨在通过并行操作并与中央服务器通信来加速一个常见的随机逼近（SA）问题。我们假定上行传输到服务器的传输受到异步和潜在无界时变延迟的影响。为了减轻延迟和落后者的影响，同时又能获得分布式计算的好处，我们提出了一种名为DASA的延迟自适应多智能体随机逼近算法。我们对DASA进行了有限时间分析，假设智能体的随机观测过程是独立马尔科夫链。与现有结果相比，DASA是第一个其收敛速度仅取决于混合时间$tmix$和平均延迟$\tau_{avg}$，同时在马尔科夫采样下实现N倍的收敛加速的算法。我们的工作对于各种SA应用是相关的。

    arXiv:2403.17247v1 Announce Type: new  Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tmix$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA applications, inc
    
[^12]: 结构化评估合成表格数据

    Structured Evaluation of Synthetic Tabular Data

    [https://arxiv.org/abs/2403.10424](https://arxiv.org/abs/2403.10424)

    提出了一个具有单一数学目标的评估框架，用于确定合成数据应该从与观测数据相同的分布中提取，并且推理了任何一组指标的完整性，统一了现有的指标，并鼓励新的模型无关基线和指标。

    

    表格数据通常存在但往往不完整，数据量较小，并且由于隐私原因受限于访问。合成数据生成提供了潜在解决方案。存在许多用于评估合成表格式数据质量的指标；然而，我们缺乏对这些指标的客观、连贯的解释。为解决这一问题，我们提出了一个具有单一数学目标的评估框架，认为合成数据应该从与观测数据相同的分布中提取。通过对目标的各种结构分解，该框架首次允许我们推理任何一组指标的完整性，并统一现有的指标，包括源自忠实性考虑、下游应用和基于模型方法的指标。此外，该框架激励了无模型基线和一系列新的指标。我们评估了结构化信息合成器和合成器。

    arXiv:2403.10424v1 Announce Type: new  Abstract: Tabular data is common yet typically incomplete, small in volume, and access-restricted due to privacy concerns. Synthetic data generation offers potential solutions. Many metrics exist for evaluating the quality of synthetic tabular data; however, we lack an objective, coherent interpretation of the many metrics. To address this issue, we propose an evaluation framework with a single, mathematical objective that posits that the synthetic data should be drawn from the same distribution as the observed data. Through various structural decomposition of the objective, this framework allows us to reason for the first time the completeness of any set of metrics, as well as unifies existing metrics, including those that stem from fidelity considerations, downstream application, and model-based approaches. Moreover, the framework motivates model-free baselines and a new spectrum of metrics. We evaluate structurally informed synthesizers and syn
    
[^13]: 稀疏线性赌博问题中贪婪适用臂特征分布的新类别

    New Classes of the Greedy-Applicable Arm Feature Distributions in the Sparse Linear Bandit Problem

    [https://arxiv.org/abs/2312.12400](https://arxiv.org/abs/2312.12400)

    本文展示了贪婪算法适用于更广泛范围的臂特征分布，提出了新的适用类别和混合分布概念。

    

    我们考虑稀疏情境赌博问题，其中臂特征通过稀疏参数的内积影响奖励。最近的研究开发了基于贪婪臂选择策略的不考虑稀疏性的算法。然而，对这些算法的分析需要对臂特征分布做出强假设，以确保贪婪选择的样本足够多样化；其中最常见的假设之一是放松对称性，对分布施加了近似原点对称性，这不允许具有原点不对称支持的分布。本文表明，贪婪算法适用于更广泛范围的臂特征分布有两个方面。首先，我们表明具有一个贪婪适用组件的混合分布也是贪婪适用的。其次，我们提出了新的分布类别，与高斯混合、离散和径向分布相关，适用于该类问题。

    arXiv:2312.12400v2 Announce Type: replace  Abstract: We consider the sparse contextual bandit problem where arm feature affects reward through the inner product of sparse parameters. Recent studies have developed sparsity-agnostic algorithms based on the greedy arm selection policy. However, the analysis of these algorithms requires strong assumptions on the arm feature distribution to ensure that the greedily selected samples are sufficiently diverse; One of the most common assumptions, relaxed symmetry, imposes approximate origin-symmetry on the distribution, which cannot allow distributions that has origin-asymmetric support. In this paper, we show that the greedy algorithm is applicable to a wider range of the arm feature distributions from two aspects. Firstly, we show that a mixture distribution that has a greedy-applicable component is also greedy-applicable. Second, we propose new distribution classes, related to Gaussian mixture, discrete, and radial distribution, for which th
    
[^14]: 基于图依赖性的学习泛化界限：一份调查

    Generalization bounds for learning under graph-dependence: A survey

    [https://arxiv.org/abs/2203.13534](https://arxiv.org/abs/2203.13534)

    通过收集各种图依赖性的集中界限，该研究推导出了用于基于图依赖性数据学习的Rademacher复杂度和稳定性的学习泛化界限。

    

    传统统计学习理论依赖于数据独立同分布（i.i.d.）的假设。然而，在许多现实应用中，这种假设往往不成立。本调查中，我们探讨了学习场景中示例之间存在依赖关系，并且这种依赖关系由依赖图描述，这是概率论和组合数学中常用的模型。我们收集了各种图依赖性的集中界限，然后用它们来推导基于Rademacher复杂度和稳定性的学习泛化界限，以适用于基于图依赖性数据的学习。我们通过实际学习任务来说明这一范式，并为未来的研究方向提供了一些建议。据我们所知，这份调查是该主题上第一份此类调查。

    arXiv:2203.13534v2 Announce Type: replace  Abstract: Traditional statistical learning theory relies on the assumption that data are identically and independently distributed (i.i.d.). However, this assumption often does not hold in many real-life applications. In this survey, we explore learning scenarios where examples are dependent and their dependence relationship is described by a dependency graph, a commonly utilized model in probability and combinatorics. We collect various graph-dependent concentration bounds, which are then used to derive Rademacher complexity and stability generalization bounds for learning from graph-dependent data. We illustrate this paradigm through practical learning tasks and provide some research directions for future work. To our knowledge, this survey is the first of this kind on this subject.
    
[^15]: 使用投影Wasserstein距离的双样本检验

    Two-sample Test using Projected Wasserstein Distance

    [https://arxiv.org/abs/2010.11970](https://arxiv.org/abs/2010.11970)

    提出了一种使用投影Wasserstein距离进行双样本检验的方法，可以避免高维度情况下的测试能力减弱问题，并通过最优投影和低维线性映射最大化Wasserstein距离来实现。

    

    我们开发了一种使用投影Wasserstein距离进行双样本检验的方法，这是统计学和机器学习中的一个基本问题：给定两组样本，确定它们是否来自同一分布。我们的目标是避免Wasserstein距离中的维度灾难：当维度很高时，它的测试能力会显著减弱，这主要是由于高维空间中Wasserstein度量的缓慢集中特性所致。一个关键贡献是将最优投影耦合在一起，找到低维线性映射以最大化投影概率分布之间的Wasserstein距离。我们刻画了IPM中有限样本收敛速率的理论特性，并提出了用于计算该度量的实际算法。数值实例验证了我们的理论结果。

    arXiv:2010.11970v4 Announce Type: replace-cross  Abstract: We develop a projected Wasserstein distance for the two-sample test, a fundamental problem in statistics and machine learning: given two sets of samples, to determine whether they are from the same distribution. In particular, we aim to circumvent the curse of dimensionality in Wasserstein distance: when the dimension is high, it has diminishing testing power, which is inherently due to the slow concentration property of Wasserstein metrics in the high dimension space. A key contribution is to couple optimal projection to find the low dimensional linear mapping to maximize the Wasserstein distance between projected probability distributions. We characterize the theoretical property of the finite-sample convergence rate on IPMs and present practical algorithms for computing this metric. Numerical examples validate our theoretical results.
    
[^16]: 在高斯混合模型空间中引入了类似于Gromov-Wassertein的距离

    Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space. (arXiv:2310.11256v1 [stat.ML])

    [http://arxiv.org/abs/2310.11256](http://arxiv.org/abs/2310.11256)

    本文介绍了两种在高斯混合模型空间中的Gromov-Wasserstein类型距离，分别用于评估分布之间的距离和推导最优的点分配方案。

    

    本文介绍了两种在高斯混合模型集合上的Gromov-Wasserstein类型距离。第一种距离是在高斯测度空间上两个离散分布的Gromov-Wasserstein距离。该距离可以作为Gromov-Wasserstein的替代，用于评估分布之间的距离，但不能直接推导出最优的运输方案。为了设计出这样的运输方案，我们引入了另一种在不可比较的空间中的测度之间的距离，该距离与Gromov-Wasserstein密切相关。当将允许的运输耦合限制为高斯混合模型时，这定义了另一种高斯混合模型之间的距离，可以作为Gromov-Wasserstein的另一种替代，并允许推导出最优的点分配方案。

    In this paper, we introduce two Gromov-Wasserstein-type distances on the set of Gaussian mixture models. The first one takes the form of a Gromov-Wasserstein distance between two discrete distributionson the space of Gaussian measures. This distance can be used as an alternative to Gromov-Wasserstein for applications which only require to evaluate how far the distributions are from each other but does not allow to derive directly an optimal transportation plan between clouds of points. To design a way to define such a transportation plan, we introduce another distance between measures living in incomparable spaces that turns out to be closely related to Gromov-Wasserstein. When restricting the set of admissible transportation couplings to be themselves Gaussian mixture models in this latter, this defines another distance between Gaussian mixture models that can be used as another alternative to Gromov-Wasserstein and which allows to derive an optimal assignment between points. Finally,
    
[^17]: GTA：一种面向几何的多视图Transformer的注意力机制

    GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers. (arXiv:2310.10375v1 [cs.CV])

    [http://arxiv.org/abs/2310.10375](http://arxiv.org/abs/2310.10375)

    提出了一种面向几何的注意力机制（GTA），用于将几何结构编码为相对变换，从而改进了多视图Transformer的学习效率和性能。

    

    随着transformers对输入标记的排列具有等变性，对标记的位置信息进行编码对许多任务是必要的。然而，由于现有的位置编码方案最初是为自然语言处理任务设计的，对于通常在其数据中表现出不同结构特性的视觉任务来说，它们的适用性值得怀疑。我们认为现有的位置编码方案对于3D视觉任务来说是次优的，因为它们不尊重其底层的3D几何结构。基于这个假设，我们提出了一种面向几何的注意力机制，它将标记的几何结构编码为由查询和键值对之间的几何关系所确定的相对变换。通过在稀疏宽基线多视图设置中评估多个新颖视图合成（NVS）数据集，我们展示了我们的注意力机制——几何变换注意力（GTA）如何提高了最先进的Transformer的学习效率和性能。

    As transformers are equivariant to the permutation of input tokens, encoding the positional information of tokens is necessary for many tasks. However, since existing positional encoding schemes have been initially designed for NLP tasks, their suitability for vision tasks, which typically exhibit different structural properties in their data, is questionable. We argue that existing positional encoding schemes are suboptimal for 3D vision tasks, as they do not respect their underlying 3D geometric structure. Based on this hypothesis, we propose a geometry-aware attention mechanism that encodes the geometric structure of tokens as relative transformation determined by the geometric relationship between queries and key-value pairs. By evaluating on multiple novel view synthesis (NVS) datasets in the sparse wide-baseline multi-view setting, we show that our attention, called Geometric Transform Attention (GTA), improves learning efficiency and performance of state-of-the-art transformer-b
    
[^18]: 用于计算深度神经网络正则化路径的多目标延续方法

    A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])

    [http://arxiv.org/abs/2308.12044](http://arxiv.org/abs/2308.12044)

    本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。

    

    稀疏性是深度神经网络(DNNs)中非常理想的特征，因为它确保了数值效率，提高了模型的可解释性(由于相关特征的数量较少)和鲁棒性。在基于线性模型的机器学习方法中，众所周知在$\ell^1$范数(即零权重)的最稀疏解和非正则化解之间存在一条连接路径，这条路径被称为正则化路径。最近，通过将经验损失和稀疏性($\ell^1$范数)作为两个冲突的标准，并解决由此产生的多目标优化问题，首次尝试将正则化路径的概念扩展到DNNs。然而，由于$\ell^1$范数的不光滑性和参数数量的高度，从计算的角度来看，这种方法并不是很有效。为了克服这个限制，我们提出了一种算法，可以近似计算整个帕累托曲线

    Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
    
[^19]: 水下航行器船体的样本高效和基于代理的设计优化

    Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls. (arXiv:2304.12420v1 [cs.LG])

    [http://arxiv.org/abs/2304.12420](http://arxiv.org/abs/2304.12420)

    该论文使用了高效的样本集优化和基于代理的方法来设计水下航行器船体，其中代理模型显著提高了计算效率，使优化更加快速准确。

    

    物理模拟是计算机辅助设计(CAD)优化过程中的一个计算瓶颈。因此，为了使精确(计算昂贵)的模拟可用于设计优化中，需要一个高样本效率的优化框架或快速的数据驱动代理(代理模型)来代替长时间运行的模拟。在这项工作中，我们利用最近优化和人工智能(AI)的进展来解决这两个潜在的解决方案，以设计一个最佳的无人水下航行器(UUV)。我们首先研究并比较了不同优化技术在优化循环中与标准计算流体力学(CFD)求解器相结合时的样本效率和收敛行为。然后，我们开发了一个基于深度神经网络(DNN)的代理模型来逼近否则通过CFD求解器进行计算的阻力。代理模型进而用于样本高效的优化框架中，该框架在不使用代理模型的情况下优于标准优化方法。

    Physics simulations are a computational bottleneck in computer-aided design (CAD) optimization processes. Hence, in order to make accurate (computationally expensive) simulations feasible for use in design optimization, one requires either an optimization framework that is highly sample-efficient or fast data-driven proxies (surrogate models) for long running simulations. In this work, we leverage recent advances in optimization and artificial intelligence (AI) to address both of these potential solutions, in the context of designing an optimal unmanned underwater vehicle (UUV). We first investigate and compare the sample efficiency and convergence behavior of different optimization techniques with a standard computational fluid dynamics (CFD) solver in the optimization loop. We then develop a deep neural network (DNN) based surrogate model to approximate drag forces that would otherwise be computed via direct numerical simulation with the CFD solver. The surrogate model is in turn use
    
[^20]: 基于多天线的双盲反卷积联合雷达通信的SoMAN最小化

    Multi-Antenna Dual-Blind Deconvolution for Joint Radar-Communications via SoMAN Minimization. (arXiv:2303.13609v1 [cs.IT])

    [http://arxiv.org/abs/2303.13609](http://arxiv.org/abs/2303.13609)

    本论文研究了多天线接收器版本的双盲反卷积问题，提出了使用多元原子范数最小化的方法来恢复雷达和通信信号和通道参数。

    

    联合雷达通信（JRC）已经成为一种有效利用有限电磁频谱的有前途的技术。在JRC应用中，如安全军用接收器中，雷达和通信信号经常叠加在接收信号中。在这些被动监听哨所中，雷达和通信的信号和通道对于接收器来说都是未知的。从叠加信号中恢复所有信号和通道参数的不适定问题被称为双盲反卷积（DBD）。在这项工作中，我们调查了更具挑战性的多天线接收器版本的DBD。我们用少数（稀疏）连续值参数，如时延、多普勒速度和到达方向（DoAs）来建模雷达和通信通道。为了解决这个高度不适定的DBD问题，我们建议最小化依赖于未知参数的多元原子范数（SoMAN）之和。为此，我们使用半定规划设计了一个精确的解。

    Joint radar-communications (JRC) has emerged as a promising technology for efficiently using the limited electromagnetic spectrum. In JRC applications such as secure military receivers, often the radar and communications signals are overlaid in the received signal. In these passive listening outposts, the signals and channels of both radar and communications are unknown to the receiver. The ill-posed problem of recovering all signal and channel parameters from the overlaid signal is terms as dual-blind deconvolution (DBD). In this work, we investigate a more challenging version of DBD with a multi-antenna receiver. We model the radar and communications channels with a few (sparse) continuous-valued parameters such as time delays, Doppler velocities, and directions-of-arrival (DoAs). To solve this highly ill-posed DBD, we propose to minimize the sum of multivariate atomic norms (SoMAN) that depends on the unknown parameters. To this end, we devise an exact semidefinite program using the
    

