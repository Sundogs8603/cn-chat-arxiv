# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Robust Causal Bandits for Linear Models.](http://arxiv.org/abs/2310.19794) | 本文研究了线性模型的鲁棒因果强化学习算法，在复杂系统的情况下，现有方法无法保持遗憾次线性。 |
| [^2] | [On Learning Gaussian Multi-index Models with Gradient Flow.](http://arxiv.org/abs/2310.19793) | 本研究探讨了在高维高斯数据的多索引回归问题中，通过梯度流学习低秩线性投影和低维连接函数，建立了全局收敛性和定量描述的算法。 |
| [^3] | [DiffEnc: Variational Diffusion with a Learned Encoder.](http://arxiv.org/abs/2310.19789) | DiffEnc是一种使用学习的编码器的变分扩散模型，通过引入数据和深度相关的均值函数和可调节的噪声方差比率，实现了最先进的可能性。 |
| [^4] | [Locally Optimal Best Arm Identification with a Fixed Budget.](http://arxiv.org/abs/2310.19788) | 该研究解决了识别具有最高预期效果的治疗方案的问题，并提出了具有固定预算的局部最优算法来降低错误识别的概率。 |
| [^5] | [$e^{\text{RPCA}}$: Robust Principal Component Analysis for Exponential Family Distributions.](http://arxiv.org/abs/2310.19787) | 本论文提出了一种针对指数族分布的鲁棒主成分分析方法$e^{\text{RPCA}}$，可以有效地恢复低秩结构并进行异常点的识别和处理。 |
| [^6] | [A Path to Simpler Models Starts With Noise.](http://arxiv.org/abs/2310.19726) | 本文研究了数据生成过程的机制和分析师的选择如何影响Rashomon比率，并介绍了一个称为模式多样性的指标来衡量不同分类器之间的预测差异。 |
| [^7] | [Support matrix machine: A review.](http://arxiv.org/abs/2310.19717) | 支持矩阵机器是一种新兴的方法，用于处理矩阵输入数据，并通过使用谱弹性网络性质保留了矩阵数据的结构信息。 |
| [^8] | [Causal Context Connects Counterfactual Fairness to Robust Prediction and Group Fairness.](http://arxiv.org/abs/2310.19691) | 本文通过使用因果背景来将反事实公平性、强健预测和群体公平性相连接。首先，通过合理条件下的研究，证明了反事实公平预测器在无偏目标分布中是准确性最优的。其次，发展了数据生成的因果图与强健预测和群体公平性之间的对应关系。 |
| [^9] | [Towards Practical Non-Adversarial Distribution Alignment via Variational Bounds.](http://arxiv.org/abs/2310.19690) | 本论文提出了一种非对抗的基于变分自动编码器的对齐方法，通过引入一组对齐上界，解决了先前方法中存在的不稳定性和限制。实验证明，这种新颖的对齐损失可以在不改变原始架构的情况下取代对抗损失，扩展了应用范围。 |
| [^10] | [An Online Bootstrap for Time Series.](http://arxiv.org/abs/2310.19683) | 本文提出了一种新型的在线自助法用于处理大规模的时间序列和相关数据流，通过考虑数据的依赖关系，该方法可以提供可靠的不确定性量化，填补了现有自助法在复杂数据依赖情况下的应用空白。 |
| [^11] | [Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes.](http://arxiv.org/abs/2310.19666) | 本论文提出了一种通过神经扩散反应过程实现动态张量分解的方法(DEMOTE)，该方法能够更好地利用时间信息和稀疏观测张量条目内的结构知识，以捕捉潜在的时态结构。 |
| [^12] | [Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion Models.](http://arxiv.org/abs/2310.19653) | 这项研究通过在预训练的扩散模型生成的样本上进行训练，有效减轻了VAE中编码器的过拟合问题。 |
| [^13] | [A Bayesian Methodology for Estimation for Sparse Canonical Correlation.](http://arxiv.org/abs/2310.19621) | 本文提出了一种新颖的贝叶斯方法，用于稀疏典型相关估计，通过在建模框架中的两个级别上鼓励稀疏，来实现对多视图高维数据的鲁棒建模。 |
| [^14] | [On Feynman--Kac training of partial Bayesian neural networks.](http://arxiv.org/abs/2310.19608) | 本文提出了一种将部分贝叶斯神经网络训练转化为模拟费曼-卡克模型的高效采样训练策略，并通过各种数据集的实验证明其在预测性能方面优于现有技术。 |
| [^15] | [Deep Kalman Filters Can Filter.](http://arxiv.org/abs/2310.19603) | 本研究展示了一类连续时间的深度卡尔曼滤波器（DKFs），可以近似实现一类非马尔可夫和条件高斯信号过程的条件分布律，从而具有在数学金融领域中传统模型基础上的滤波问题的应用潜力。 |
| [^16] | [Generator Identification for Linear SDEs with Additive and Multiplicative Noise.](http://arxiv.org/abs/2310.19491) | 本文介绍了从具有给定初始状态的解过程的分布中识别线性随机微分方程（SDE）的发生器的条件，并且提供了对于具有加性和乘性噪声的SDE的识别条件。 |
| [^17] | [Regret-Minimization Algorithms for Multi-Agent Cooperative Learning Systems.](http://arxiv.org/abs/2310.19468) | 本文研究了多智能体合作学习系统中的遗憾最小化算法。通过分析不同顺序决策问题下的MACL系统，本文提出了在合作多智能体多臂老虎机问题中使用全信息或信息有限反馈的方法，通过交换信息来改善学习效果。 |
| [^18] | [MMM and MMMSynth: Clustering of heterogeneous tabular data, and synthetic data generation.](http://arxiv.org/abs/2310.19454) | 该论文提出了MMM和MMMSynth算法，用于聚类异构表格数据和生成合成数据。MMM算法利用EM算法，在同类算法中表现更优，对于确定合成数据的聚类以及恢复真实数据的结构有较好的效果。 MMMSynth算法则用于从真实数据生成合成表格数据。 |
| [^19] | [Hodge-Compositional Edge Gaussian Processes.](http://arxiv.org/abs/2310.19450) | 本论文提出了一种新的方法用于对边缘集合上的函数进行建模，该方法基于Hodge分解开发了适用于不同应用场景的无散度和无旋度的高斯过程，并通过组合它们来表示任意边缘函数。实验结果表明这种方法在流动数据推断中具有潜在的实际应用价值。 |
| [^20] | [Ordinal classification for interval-valued data and interval-valued functional data.](http://arxiv.org/abs/2310.19433) | 首次将区间值数据和区间值函数数据作为输入考虑，在序数分类问题中提出了六种分类器，其中一种使用了核引导的序数随机森林方法，并与朴素方法进行了比较。 |
| [^21] | [Implicit Manifold Gaussian Process Regression.](http://arxiv.org/abs/2310.19390) | 本文提出了一种能够从数据中直接推断隐式结构的高斯过程回归技术，能够处理高维数据，并可能改善预测性能和校准。 |
| [^22] | [Deep anytime-valid hypothesis testing.](http://arxiv.org/abs/2310.19384) | 本文提出了一个通用框架，用于构建对非参数测试问题进行强大的顺序假设检验。与传统的批量测试相比，该框架可以持续监控在线数据流并有效地聚合反对零假设的证据，同时严格控制I型错误，并根据问题的困难程度调整样本大小要求。 |
| [^23] | [Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from a Minimax Game Perspective.](http://arxiv.org/abs/2310.19360) | 通过将对抗训练视为极小极大博弈，我们解释了学习率下降后对抗训练存在严重鲁棒过拟合问题的原因，并提出通过调整模型训练者能力或提高攻击强度来缓解这个问题。 |
| [^24] | [Dual-Directed Algorithm Design for Efficient Pure Exploration.](http://arxiv.org/abs/2310.19319) | 该论文研究了在有限备选方案集合中的纯探索问题。通过使用对偶变量，提出了一种新的算法设计原则，能够避免组合结构的复杂性，实现高效纯探索，从而准确回答查询问题。 |
| [^25] | [Stage-Aware Learning for Dynamic Treatments.](http://arxiv.org/abs/2310.19300) | 本论文提出了一种针对动态治疗的阶段感知学习方法，该方法通过估计DTR并优先考虑治疗轨迹与最佳治疗方案在决策阶段上的一致性，在提高样本效率和稳定性方面取得了重要进展。 |
| [^26] | [The Memory Perturbation Equation: Understanding Model's Sensitivity to Data.](http://arxiv.org/abs/2310.19273) | 这个论文介绍了记忆扰动方程（MPE），该方程通过应用贝叶斯原理将模型的敏感性与训练数据的扰动联系起来，并且能够准确预测模型在未见测试数据上的泛化能力。 |
| [^27] | [Invariant kernels on Riemannian symmetric spaces: a harmonic-analytic approach.](http://arxiv.org/abs/2310.19270) | 本文证明了在非欧几里德对称空间上定义的经典高斯核在任意参数选择下都不是正定的，通过发展新的几何和分析论证，并且给出了正定性的严格刻画以及L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement定理的必要和充分条件。 |
| [^28] | [Flow-based Distributionally Robust Optimization.](http://arxiv.org/abs/2310.19253) | 这项研究提出了一种称为FlowDRO的计算高效框架，用于解决基于流的分布鲁棒优化问题，通过使用流模型和Wasserstein近端梯度流类型的算法，实现了对具有更大样本大小的问题的可扩展性和更好的泛化能力。 |
| [^29] | [A spectral regularisation framework for latent variable models designed for single channel applications.](http://arxiv.org/abs/2310.19246) | 这个论文提出了一个用于单通道应用的潜变量模型的谱正则化框架，解决了源复制问题，并提供了一个一致的线性LVM优化框架。 |
| [^30] | [Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank Matrices.](http://arxiv.org/abs/2310.19214) | 本文研究了多级低秩矩阵中的因子拟合、秩分配和分割问题，提出了相应的解决方法，并开发了一个开源软件包。 |
| [^31] | [Conformal Normalization in Recurrent Neural Network of Grid Cells.](http://arxiv.org/abs/2310.19192) | 本文提出了一种循环神经网络中的共形归一化方法，用于处理网格细胞在2D物理空间中的自我位置信息。实验结果表明，该方法能够显著减小位置误差。 |
| [^32] | [Rare Event Probability Learning by Normalizing Flows.](http://arxiv.org/abs/2310.19167) | 通过标准化流辅助重要抽样（NOFIS）的方法，准确估计罕见事件的概率，通过学习一系列提议分布和重要抽样来实现，在多个定性和定量实验中得到了验证。 |
| [^33] | [Backward and Forward Inference in Interacting Independent-Cascade Processes: A Scalable and Convergent Message-Passing Approach.](http://arxiv.org/abs/2310.19138) | 该研究针对在网络中同时传播的两个扩散过程的过去和未来演变估计问题，提出了一种可扩展和收敛的消息传递方法，解决了后向推理和前向推理的问题。 |
| [^34] | [Gauge-optimal approximate learning for small data classification problems.](http://arxiv.org/abs/2310.19066) | 我们提出了一种规范最优近似学习（GOAL）算法，用于解决小样本学习问题。该算法通过减少和旋转特征空间，提供了一个可分析的联合解决方案，其中最优解是欧几里得空间中的分段线性函数。 |
| [^35] | [Revisiting the Learnability of Apple Tasting.](http://arxiv.org/abs/2310.19064) | 该论文重新审视了苹果品尝的可学习性，从组合角度研究了在线可学习性。作者通过引入Effective width参数，紧密量化了在可实现设置中的极小期望错误，并在可实现设置中建立了极小期望错误数量的三分法。 |
| [^36] | [Datasets and Benchmarks for Nanophotonic Structure and Parametric Design Simulations.](http://arxiv.org/abs/2310.19053) | 本研究提出了一种评估纳米光子结构的框架和基准，用于解决参数结构设计问题，并探究了电动力学模拟中网格大小的变化对结果的影响。 |
| [^37] | [Differentially Private Permutation Tests: Applications to Kernel Methods.](http://arxiv.org/abs/2310.19043) | 本文提出了差分隐私排列检验的框架，扩展了经典的非私有排列检验，以在私有环境中保持有限样本有效性和差分隐私性质。该检验的功率取决于检验统计量的选择，并建立了一般条件来保证一致性和非渐进均匀的功率。 |
| [^38] | [On Linear Separation Capacity of Self-Supervised Representation Learning.](http://arxiv.org/abs/2310.19041) | 本研究通过探究在多流形模型下，学习的表示何时可以线性分离流形，揭示了自监督学习在数据增强方面的额外好处，从而改善了线性分离能力的信息论最优速率。 |
| [^39] | [Does Invariant Graph Learning via Environment Augmentation Learn Invariance?.](http://arxiv.org/abs/2310.19035) | 环境增强无法根本性地学习到不变的图表示，因此我们提出了一组最小的假设，用于可行的不变图学习。我们还提出了一个新的框架GALA，该框架包含一个敏感于图环境变化的助理模型，通过代理预测准确性来区分变异。 |
| [^40] | [An Improved Relaxation for Oracle-Efficient Adversarial Contextual Bandits.](http://arxiv.org/abs/2310.19025) | 该论文提出了一种用于对抗性上下文赌博问题的面向Oracle高效的放松方法，通过调用离线优化Oracle来降低遗憾界限，并且在界限方面取得了显著的改进，达到了先前最佳界限，并与原始界限相匹配。 |
| [^41] | [A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning.](http://arxiv.org/abs/2310.18988) | 本研究重新思考了统计学习中参数计数的理论，挑战了双下降现象扩展传统复杂度-泛类关系界限的观点。 |
| [^42] | [Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU Networks on Nearly-orthogonal Data.](http://arxiv.org/abs/2310.18935) | 本文研究了两层ReLU和Leaky ReLU网络在几乎正交数据上梯度下降的隐式偏差。对于Leaky ReLU激活函数，梯度下降能找到收敛到1的稳定秩网络；对于ReLU激活函数，梯度下降能找到稳定秩上界为常数的神经网络。 |
| [^43] | [Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximation.](http://arxiv.org/abs/2310.18919) | 本研究解决了强化学习中延迟反馈对线性函数逼近的挑战，通过后验采样算法实现了在不同情况下的优越性能。 |
| [^44] | [Debiasing Algorithm through Model Adaptation.](http://arxiv.org/abs/2310.18913) | 本论文提出了一种通过模型适应来检测和减轻语言模型中性别偏见的方法，并证明了该方法能够显著减少偏见同时保持模型性能。 |
| [^45] | [InstanT: Semi-supervised Learning with Instance-dependent Thresholds.](http://arxiv.org/abs/2310.18910) | 本文提出了一种半监督学习方法，通过使用实例相关的阈值来选择有信心的未标记实例，并将其纳入训练集中。该方法利用实例级别的模糊度和实例相关的错误率来设计阈值函数，相比现有方法具有更高的自由度。 |
| [^46] | [Estimating the Rate-Distortion Function by Wasserstein Gradient Descent.](http://arxiv.org/abs/2310.18908) | 本文通过Wasserstein梯度下降方法，从最优传输的角度提出了一种估计速率-失真函数R(D)的新方法，该方法在低速率源上取得了与最先进的神经网络方法相当或更强的性能界限，并且需要较少的调整和计算工作。 |
| [^47] | [Simple and Asymmetric Graph Contrastive Learning without Augmentations.](http://arxiv.org/abs/2310.18884) | 本文提出了一种无需增强的简单非对称图对比学习方法GraphACL，通过考虑邻居节点的非对称视图，该方法能够有效地在同类和异类图上进行对比学习，对于建模异类图非常重要。 |
| [^48] | [Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization.](http://arxiv.org/abs/2310.18860) | 本文提出了一种基于贝叶斯公式的岭回归方法，通过期望最大化来调节正则化超参数，该方法不需要指定候选的λ并且在大样本下可以找到唯一的最优解。 |
| [^49] | [Intrinsic Gaussian Vector Fields on Manifolds.](http://arxiv.org/abs/2310.18824) | 本文提出了一种新型的在流形上处理矢量值信号的高斯过程模型，具有内在定义和考虑空间几何的特点，并为部署在二维球面和超曲面上的Hodge-Mat\'ern高斯向量场提供了计算基元。 |
| [^50] | [Stability of Random Forests and Coverage of Random-Forest Prediction Intervals.](http://arxiv.org/abs/2310.18814) | 本文证明了在平方响应（$Y^2$）没有重尾的温和条件下，随机森林具有稳定性。利用稳定性属性，我们证明了随机森林的预测区间的覆盖概率的非渐近下界，并讨论了比以前考虑的条件更弱的情况。 |
| [^51] | [High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise.](http://arxiv.org/abs/2310.18784) | 本研究探讨了一类非线性随机梯度下降方法的高概率收敛边界。对于具有Lipschitz连续梯度的强凸损失函数，即使噪声是重尾的，结果证明了对失败概率的对数依赖。这些结果适用于剪切、归一化和量化等任何具有有界输出的非线性函数。 |
| [^52] | [Reflection coupling for unadjusted generalized Hamiltonian Monte Carlo in the nonconvex stochastic gradient case.](http://arxiv.org/abs/2310.18774) | 该论文研究了非凸随机梯度情况下未调整的广义哈密尔顿蒙特卡罗中的反射耦合，证明了Wasserstein 1距离的收敛性，并提供了定量高斯集中界限，同时还给出了Wasserstein 2距离、总变差和相对熵的收敛性。 |
| [^53] | [Latent class analysis by regularized spectral clustering.](http://arxiv.org/abs/2310.18727) | 本文提出了两种新的算法用于分类数据的潜在类别模型，并通过新定义的正则化拉普拉斯矩阵计算潜在类别分析，结果表明算法具有理论收敛速度和稳定的一致性。同时提出了一个衡量潜在类别分析强度的度量标准及相关程序，通过模拟实验验证了算法的效率和准确性，并应用于实际分类数据。 |
| [^54] | [On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random Tensor Analysis.](http://arxiv.org/abs/2310.18717) | 本文通过随机张量理论研究了Hotelling型非对称张量除法在大维张量下的准确性，对除法过程中的奇异值和奇异向量进行了分析，可以用于构造信噪比和排列的估计。 |
| [^55] | [Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards.](http://arxiv.org/abs/2310.18715) | 本文提出的ROAM和ROOM算法框架通过将中位数法与离线强化学习策略相结合，提供了对重尾奖励的直接不确定性估计，从而增强了离线强化学习在现实应用中的鲁棒性。 |
| [^56] | [Causal discovery in a complex industrial system: A time series benchmark.](http://arxiv.org/abs/2310.18654) | 本文提供了一个工业子系统的时间序列数据集和由专家知识构建的因果图，为复杂系统的因果关系发现方法的发展提供了一个测试平台。 |
| [^57] | [Pessimistic Off-Policy Multi-Objective Optimization.](http://arxiv.org/abs/2310.18617) | 该论文提出了一种悲观的估计器，用于计算离线多目标优化中的策略值，并通过策略梯度进行优化。该估计器基于反向倾向性分数（IPS），在理论和实验中均表现出较好的性能。 |
| [^58] | [Temporally Disentangled Representation Learning under Unknown Nonstationarity.](http://arxiv.org/abs/2310.18615) | 本研究在非平稳情况下，探索了时间解缠表示学习的马尔可夫假设，并提出了一种无需辅助变量观测的方法来恢复独立的潜在分量。 |
| [^59] | [Online Decision Mediation.](http://arxiv.org/abs/2310.18601) | 这篇论文研究了在线决策调解的问题，即学习和评估中介策略来平衡专家行为和人类行为，并提供一个高效的接口，以处理人类错误和专家反馈。 |
| [^60] | [Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint.](http://arxiv.org/abs/2310.18593) | 该论文提出了公平流式主成分分析（PCA）算法，并且在理论和实践上解决了公平PCA的两个主要问题。 |
| [^61] | [Inverse Decision Modeling: Learning Interpretable Representations of Behavior.](http://arxiv.org/abs/2310.18591) | 这篇论文提出了一个反向决策建模的框架，用于学习序列决策行为的参数化表示。该框架能够提供透明的行为描述，并可以广泛应用于行为表示的研究问题。同时，通过一个示例，展示了该方法如何学习可解释的有限理性表示，并能捕捉到次优动作和偏见信仰等直观概念。 |
| [^62] | [Optimal Transport for Kernel Gaussian Mixture Models.](http://arxiv.org/abs/2310.18586) | 本研究提出了一种通过核技巧，在再生核希尔伯特空间中计算两个高斯混合模型之间距离的Wasserstein类型度量方法，解决了在核高斯混合模型中最优传输问题。 |
| [^63] | [Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion.](http://arxiv.org/abs/2310.18554) | 本论文通过遗憾到置信集转换方法改进了逻辑回归赌博机的遗憾界限，提出了一个基于在线学习算法的凸置信集，并应用于具有新的鞅集中步骤的遗憾分析。 |
| [^64] | [Causal disentanglement of multimodal data.](http://arxiv.org/abs/2310.18471) | 这篇论文介绍了一种可以利用多模态数据和已知物理学知识发现因果关系的因果表示学习算法。 |
| [^65] | [Minimax Optimal Submodular Optimization with Bandit Feedback.](http://arxiv.org/abs/2310.18465) | 这项工作研究了带有Bandit反馈的极小极大次模优化问题，在这个问题中，我们建立了第一个最小最大下限，并提出了一个能够与下限遗憾相匹配的算法。 |
| [^66] | [Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient Descent.](http://arxiv.org/abs/2310.18455) | 本文研究了离线（多遍）随机梯度下降中的重尾行为。通过展示离线SGD的稳态分布表现出“近似”幂律尾部，我们填补了在有限的训练数据量情况下重尾行为机制的空白。 |
| [^67] | [Bayesian Optimization with Hidden Constraints via Latent Decision Models.](http://arxiv.org/abs/2310.18449) | 本文介绍了一种基于潜在决策模型的贝叶斯优化方法，通过利用变分自编码器学习可行决策的分布，在原始空间和潜在空间之间实现了双向映射，从而解决了公共决策制定中的隐藏约束问题。 |
| [^68] | [Bridging Distributionally Robust Learning and Offline RL: An Approach to Mitigate Distribution Shift and Partial Data Coverage.](http://arxiv.org/abs/2310.18434) | 本论文介绍了一种将分布鲁棒学习（DRL）与离线强化学习（RL）相结合的方法，用于解决离线强化学习中的分布偏移问题。通过使用DRL方法，可以有效地缓解训练和测试环境之间的模型不匹配，并提出了两种离线强化学习算法。 |
| [^69] | [MCRAGE: Synthetic Healthcare Data for Fairness.](http://arxiv.org/abs/2310.18430) | MCRAGE是一种使用深度生成模型来增强不平衡的医疗数据集的方法，以解决少数群体在机器学习模型中的不公平问题。 |
| [^70] | [On the Fairness ROAD: Robust Optimization for Adversarial Debiasing.](http://arxiv.org/abs/2310.18413) | 本论文研究了在算法公平性领域中存在的局部差异问题，并提出了一种基于分布鲁棒优化的公平对抗学习方法，以实现针对局部特征空间的公平性标准。 |
| [^71] | [Overview of AdaBoost : Reconciling its views to better understand its dynamics.](http://arxiv.org/abs/2310.18323) | 本文概述了AdaBoost算法的不同视角，并通过统一的形式化方法将它们相互关联，帮助读者更好地理解AdaBoost的动态。 |
| [^72] | [Causal Q-Aggregation for CATE Model Selection.](http://arxiv.org/abs/2310.16945) | 该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率 |
| [^73] | [Approximate information maximization for bandit games.](http://arxiv.org/abs/2310.12563) | 本论文提出了一种基于近似信息最大化的强盗游戏算法，通过最大化关键变量的信息近似值来进行优化，在传统强盗设置中表现出很强的性能，并证明了其对于两臂强盗问题的渐近最优性。 |
| [^74] | [From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond.](http://arxiv.org/abs/2310.10121) | 本综述系统全面地回顾了利用连续动力学框架的图神经网络，以帮助从根本上理解和改进GNN的能力和缺陷。 |
| [^75] | [Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning.](http://arxiv.org/abs/2310.06793) | 该论文研究了低秩结构下的矩阵估计问题，并提出了基于频谱的方法，这些方法在估计奇异子空间方面表现出色，并且能够实现几乎最小的逐元素误差。这些新结果为充分利用低秩结构的强化学习算法的设计提供了可能性。 |
| [^76] | [Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds.](http://arxiv.org/abs/2309.10918) | 该论文研究了定义在紧致Riemannian流形上的内在Matern高斯过程和外在过程之间的收缩速率，并发现它们的速率在适当匹配平滑参数的情况下是相等的。 |
| [^77] | [Clustered Multi-Agent Linear Bandits.](http://arxiv.org/abs/2309.08710) | 本文研究了集群化的多智能体线性赌博机问题，提出了一种新颖的算法，通过智能体之间的协作来加速优化问题。通过理论分析和实证评估，证明了算法在遗憾最小化和聚类质量上的有效性。 |
| [^78] | [Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck.](http://arxiv.org/abs/2309.03800) | 本研究研究了深度学习算法设计中的微妙选择，特别关注计算统计差距。通过理论和实验，发现稀疏初始化和增加网络宽度可以提高样本效率，并且合成稀疏奇偶任务可以作为真实问题的代理。 |
| [^79] | [NAS-X: Neural Adaptive Smoothing via Twisting.](http://arxiv.org/abs/2308.14864) | NAS-X是一种基于扭曲的神经自适应平滑方法，通过重新加权的唤醒-睡眠算法来学习和推断顺序潜变量模型，并在离散和连续任务中取得了优于先前方法的推断和参数恢复效果。 |
| [^80] | [Cliqueful graphs as a means of calculating the maximal number of maximum cliques of simple graphs.](http://arxiv.org/abs/2307.14120) | 本论文研究了充满团图的概念，并且发现在简单图中，充满团图的最大数量取决于饱和复合充满团图。通过具体计算，我们得到了在n个顶点上具有最多最大团数量的图形式表达式。 |
| [^81] | [Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems.](http://arxiv.org/abs/2307.12975) | 该论文研究了基于偏好的政策学习方法在离线情境多臂赌博问题中的优势，并通过改进建模和分析，证明了这一方法相比其他政策学习方法具有更低的次优性。 |
| [^82] | [Complexity Matters: Rethinking the Latent Space for Generative Modeling.](http://arxiv.org/abs/2307.08283) | 本研究从模型复杂性的角度重新思考生成建模的潜在空间，提出了一种新的潜在与数据分布之间的“距离”，并通过该距离的最小化来优化生成器的复杂性。 |
| [^83] | [Embracing the chaos: analysis and diagnosis of numerical instability in variational flows.](http://arxiv.org/abs/2307.06957) | 本文研究了数值不稳定性对变分流中采样、密度评估和ELBO估计的可靠性的影响。通过理论保证和实验验证，我们发现尽管存在严重的数值不稳定性，变分流产生的结果在应用中常常足够准确。 |
| [^84] | [Differentially Private Statistical Inference through $\beta$-Divergence One Posterior Sampling.](http://arxiv.org/abs/2307.05194) | 通过对数据生成过程和模型之间的$\beta$-分解进行后验采样，我们提出了$\beta$D-Bayes，一种能够实现差分机器学习的方法。 |
| [^85] | [Optimal Learners for Realizable Regression: PAC Learning and Online Learning.](http://arxiv.org/abs/2307.03848) | 本论文研究了可实现回归问题的PAC学习和在线学习的统计复杂度，并提出了对于可学习性的必要条件和充分条件。 |
| [^86] | [Conditional independence testing under model misspecification.](http://arxiv.org/abs/2307.02520) | 该论文研究了模型错误下的条件独立性检验，在这种情况下提出了新的近似或上界来衡量基于回归的测试的测试误差，并引入了一种新颖的基于回归的CI检验方法RBPT，对模型错误具有鲁棒性。 |
| [^87] | [Fast Optimal Transport through Sliced Wasserstein Generalized Geodesics.](http://arxiv.org/abs/2307.01770) | 本文提出了一种快速计算最优输运的方法，通过切片Wasserstein广义测地线进行近似，得到了一个基于一维最优投影的代理距离min-SWGG，并提供了相关的传输计划。这种方法具有较低的计算复杂度，适用于优化算法。 |
| [^88] | [Adaptive Principal Component Regression with Applications to Panel Data.](http://arxiv.org/abs/2307.01357) | 本文提出了自适应主成分回归方法，并在面板数据中的应用中获得了均匀有限样本保证。该方法可以用于面板数据中的实验设计，特别是当干预方案是自适应分配的情况。 |
| [^89] | [Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations.](http://arxiv.org/abs/2306.11839) | 本文提出了针对于异质种群有害实验的早期停止方法CLASH，使用因果机器学习可以有效提前停止临床试验和A/B测试。 |
| [^90] | [Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent.](http://arxiv.org/abs/2306.11589) | 本文探索了使用随机梯度下降算法从高斯过程后验中采样的方法，该方法计算高效且能在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。 |
| [^91] | [Class-Conditional Conformal Prediction With Many Classes.](http://arxiv.org/abs/2306.09335) | 提出了一种叫做聚类符合性预测的方法，可以在多类条件下提供类别条件符合性预测，针对多个类别的图像数据集中经验评估结果表明其优于现有方法。 |
| [^92] | [MMD-FUSE: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting.](http://arxiv.org/abs/2306.08777) | 本文提出了MMD-FUSE方法，通过适应内核集合最大化基于MMD的双样本检验功率，避免数据分割，并在低维合成数据和高维实际数据上证明了其适用性和功率超过现有最先进的核检验方法。 |
| [^93] | [Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks.](http://arxiv.org/abs/2306.06155) | 本文提出了一种连续时间网络表示学习框架，涵盖核平滑的强度函数估计、最小化强度重构误差的投影学习和归纳构造节点表示。这种表示保留了网络结构和时间一致性。 |
| [^94] | [Prodigy: An Expeditiously Adaptive Parameter-Free Learner.](http://arxiv.org/abs/2306.06101) | 本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。 |
| [^95] | [Bayesian Optimisation of Functions on Graphs.](http://arxiv.org/abs/2306.05304) | 本论文提出了一种在通用的大规模和潜在未知图上定义函数的贝叶斯优化算法，并通过学习适当的图内核，适应目标函数行为。 |
| [^96] | [Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation.](http://arxiv.org/abs/2306.04924) | 本研究针对均值估计问题，探讨了在通信和本地差分隐私约束下的精确最优方法，提出了利用旋转对称的共享随机码书，并通过$k$-closest编码实现了随机旋转的单纯形$c$的精确最优。 |
| [^97] | [Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks.](http://arxiv.org/abs/2306.04251) | SGD在训练过度表达的网络时，会随机地将动态吸引到更简单的子网络，这种随机吸引性能够提高泛化能力。 |
| [^98] | [Random Distribution Shift in Refugee Placement: Strategies for Building Robust Models.](http://arxiv.org/abs/2306.02948) | 本文研究了难民安置中的随机分布转移问题，并提出并比较了三种建模策略，最终发现混合方法具有较强鲁棒性。 |
| [^99] | [Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity.](http://arxiv.org/abs/2306.02652) | 本文提出了一种在Early-Exit网络中实现条件单调性的方法，将深度模型转化为真正的随时分类器。 |
| [^100] | [Auditing for Human Expertise.](http://arxiv.org/abs/2306.01646) | 人类专家的价值超出了算法可捕捉范围，我们可以用一个简单的程序测试这个问题。 |
| [^101] | [Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions.](http://arxiv.org/abs/2306.00904) | 本文提出了一种用于高阶相互作用的测量方法和基于核的测试方法，并与格理论建立了数学联系，为增强相互作用模型提供了方法。 |
| [^102] | [Nonparametric Identifiability of Causal Representations from Unknown Interventions.](http://arxiv.org/abs/2306.00542) | 本文提出了一种新方法用于从未知干预数据中推断非参数因果表达式学习，并且证明了在两个因果变量的基本设置中，无法消除一些由干预数据引起的歧义问题。 |
| [^103] | [Replicability in Reinforcement Learning.](http://arxiv.org/abs/2305.19562) | 这篇论文研究了在强化学习中的可复制性，提出了可复制算法和松弛可复制算法，并给出了相应的时间和样本复杂度，这对于RL算法设计以及未来的可复制性研究具有影响。 |
| [^104] | [Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network.](http://arxiv.org/abs/2305.19366) | 本文提出了在单一生成流网络中联合建模贝叶斯网络结构和参数的方法，包括非离散样本空间，提高了贝叶斯网络局部概率模型的灵活性。 |
| [^105] | [Compression with Bayesian Implicit Neural Representations.](http://arxiv.org/abs/2305.19185) | 该论文提出了一种用Bayesian隐式神经表示来压缩数据的方法，通过最小化 $\beta$-ELBO 直接优化码-失真性能，并通过调整 $\beta$ 来针对给定的网络结构实现不同的码-失真平衡。 |
| [^106] | [On the impact of activation and normalization in obtaining isometric embeddings at initialization.](http://arxiv.org/abs/2305.18399) | 本论文研究了深度神经网络中的 Gram 矩阵结构，证明了激活函数和层规范化结合使用可以在初始化时偏向指数级深度等距，从而弥补了现有理论的空白。 |
| [^107] | [Implicit Transfer Operator Learning: Multiple Time-Resolution Surrogates for Molecular Dynamics.](http://arxiv.org/abs/2305.18046) | ITO Learning是一个学习分子动力学多时间分辨率代理的框架，可以生成自洽的随机动力学，节省数百倍的时间。 |
| [^108] | [Auditing Fairness by Betting.](http://arxiv.org/abs/2305.17570) | 本文提供了一种通过赌博的方式进行公平性审计的方法，相比之前的方法，这种方法具有更高的实用性和效率，能够对不断产生的数据进行连续的监控，并处理因分布漂移导致的公平性问题。 |
| [^109] | [Causal Component Analysis.](http://arxiv.org/abs/2305.17225) | 本文介绍了一个中间问题：因果成分分析(CauCA)，它是独立成分分析(ICA)和因果表示学习(CRL)的泛化和特例，其目标是学习解混函数和因果机制，预设了因果图的知识。 |
| [^110] | [Tree-Based Diffusion Schr\"odinger Bridge with Applications to Wasserstein Barycenters.](http://arxiv.org/abs/2305.16557) | 本文介绍了一种基于树的扩散薛定谔桥算法(TreeDSB)来解决多元最优输运(mOT)的问题，并可以应用于高维设置如图像插值和贝叶斯融合。 |
| [^111] | [DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method.](http://arxiv.org/abs/2305.16284) | 本文提出了一种名为DoWG的无参数梯度下降方法，它是第一个既高效又通用的算法，能够自适应于平稳和非平稳问题，并且无需回溯搜索过程。 |
| [^112] | [Incentivizing Honesty among Competitors in Collaborative Learning and Optimization.](http://arxiv.org/abs/2305.16272) | 这项研究提出了一个模型来描述在协作学习中竞争对手的不诚实行为，提出了机制来激励诚实沟通，并确保学习质量与全面合作相当。 |
| [^113] | [Trans-Dimensional Generative Modeling via Jump Diffusion Models.](http://arxiv.org/abs/2305.16261) | 本文通过跳跃扩散模型实现了一种跨维度生成建模方法，并证明其在处理不同维度数据时具有更好的兼容性和插值能力。 |
| [^114] | [Koopman Kernel Regression.](http://arxiv.org/abs/2305.16215) | 提出了一种基于Koopman核的回归方法，用于预测非线性动力系统的时间演变。该方法在机器人操作，视频预测和交通预测等各种应用中均有优异表现，并具有可证明的学习理论保证。 |
| [^115] | [Differentially Private Latent Diffusion Models.](http://arxiv.org/abs/2305.15759) | 本文提出使用差分隐私训练潜在扩散模型(LDMs)，通过预训练自编码器将高维像素空间转变为低维潜在空间实现更高效快速的DMs训练，并且通过只微调注意力模块减少了可训练参数的数量。 |
| [^116] | [Black-Box Variational Inference Converges.](http://arxiv.org/abs/2305.15349) | 通过对黑盒变分推断（BBVI）的分析，发现一些常见的算法设计选择可能会导致次优收敛速率，但使用带有近端随机梯度下降的BBVI可以实现最强收敛率保证。 |
| [^117] | [Training Energy-Based Normalizing Flow with Score-Matching Objectives.](http://arxiv.org/abs/2305.15267) | 本文提出一种新的基于能量的归一化流模型（EBFlow），通过得分匹配目标优化使其训练更高效，同时开发一些技术增强EBFlow的训练稳定性和实证表现。 |
| [^118] | [Discriminative calibration.](http://arxiv.org/abs/2305.14593) | 这篇论文提出了一种替代基于排序的模拟校准（SBC）的灵活分类方法，该方法可以从数据中学习测试统计量，并计算出从分类准确度中计算出的误校准发散度度量，具有更高的统计功效，可以解决多重检验的挑战。 |
| [^119] | [Optimal Preconditioning and Fisher Adaptive Langevin Sampling.](http://arxiv.org/abs/2305.14442) | 通过最优预条件和费舍尔自适应 Langevin 采样，提出了一种计算有效且在高维中非常强健的自适应 MCMC 方案。 |
| [^120] | [Towards Understanding the Dynamics of Gaussian--Stein Variational Gradient Descent.](http://arxiv.org/abs/2305.14076) | 本文探究了高斯-斯坦变分梯度下降动态性。对于从高斯目标中采样，只要初始值是高斯的，具有双线性核的SVGD动态将保持高斯状态。当目标函数呈现出强对数凹性时，证明了均场高斯-SVGD动态会线性收敛于KL散度下最接近目标高斯分布。在有限粒子设置中，存在对均场极限的时间微步一致收敛以及线性收敛至目标高斯分布。 |
| [^121] | [Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent.](http://arxiv.org/abs/2305.12056) | 本文通过建立学习理论和应用概率之间的联系，提出了一种证明随机优化算法Wasserstein稳定性界限的统一指南，并在随机梯度下降上验证了该方法的有效性，包括强凸损失和带添加噪声的非凸损失。 |
| [^122] | [Attacks on Online Learners: a Teacher-Student Analysis.](http://arxiv.org/abs/2305.11132) | 本文利用控制理论的视角研究了在线学习环境下可能遭受到的标签扰动攻击情况，得出攻击强度超过临界阈值时学习准确率将出现不连续转变的结论，并验证了理论在复杂结构学习器上的适用性。 |
| [^123] | [Information Design in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2305.06807) | 本文探究了多智能体强化学习中的信息设计问题及其挑战，提出了“马尔科夫信令博弈”的概念。 |
| [^124] | [Demystifying Softmax Gating in Gaussian Mixture of Experts.](http://arxiv.org/abs/2305.03288) | 本文提出了新的参数Vononoi损失函数并建立了MLE的收敛速度来解决高斯混合专家模型中的Softmax门控问题，研究表明该门控与高斯分布中的专家函数通过偏微分方程相互作用，是一个复杂依赖关系。 |
| [^125] | [Domain Agnostic Fourier Neural Operators.](http://arxiv.org/abs/2305.00478) | 介绍了一种新的神经算子架构 DAFNO，可以学习带有不规则几何和不断变化的域的代理。通过将平滑化的特征函数纳入 FNOs 的积分层架构中，并利用 FFT 来实现快速计算，以明确的方式将几何信息编码到架构中，DAFNO 相对于基线神经算子模型具有最先进的精度。 |
| [^126] | [Towards Understanding Feature Learning in Out-of-Distribution Generalization.](http://arxiv.org/abs/2304.11327) | 研究发现，ERM本质上同时学习了具有误导性的特征和不变特征，在ERM预训练期间学习到的特征质量影响了最终的OOD性能，未能捕获所有潜在的有用特征将限制最终的OOD性能。 |
| [^127] | [Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis.](http://arxiv.org/abs/2304.07504) | 本文提出了两种新算法SVRS和AccSVRS，针对分布式优化问题，实现了卓越的通信复杂度。其中，AccSVRS算法实现了完全无平滑性，通信复杂度更是优于现有算法。 |
| [^128] | [Complexity of Gibbs samplers through Bayesian asymptotics.](http://arxiv.org/abs/2304.06993) | 本文介绍了一种基于贝叶斯渐近性工具的方法，用于分析Gibbs抽样器的混合时间的渐近行为，并在随机数据生成假设下获得了对于具有通用似然函数的广泛的二级模型的无维度收敛结果。 |
| [^129] | [Query lower bounds for log-concave sampling.](http://arxiv.org/abs/2304.02599) | 该论文研究了对数凹采样的查询下界，在强对数凹和对数光滑分布中采样需要 $\Omega(\log \kappa)$ 查询，在采样高斯分布中需要 $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ 查询。 |
| [^130] | [Diffusion map particle systems for generative modeling.](http://arxiv.org/abs/2304.00200) | 本文提出一种新型扩散映射粒子系统(DMPS)，可以用于高效生成建模，实验表明在包含流形结构的合成数据集上取得了比其他方法更好的效果。 |
| [^131] | [Efficient distributed representations beyond negative sampling.](http://arxiv.org/abs/2303.17475) | 本文介绍了一种高效的分布式表示（嵌入）学习方法，通过线性时间估计softmax归一化常数来实现学习过程，该方法优于负采样方法并在多项测试中验证了其有效性。 |
| [^132] | [Optimal approximation of $C^k$-functions using shallow complex-valued neural networks.](http://arxiv.org/abs/2303.16813) | 本文证明了对于$C^k$（在实变量意义下）的函数，使用具有单层隐藏层和$m$个神经元的神经网络可以以错误率$m^{-k/(2n)}$将其逼近。此外，如果选取权值$\sigma_j,b_j\in\mathbb{C}$和$\rho_j\in\mathbb{C}^n$对$f$连续，那么获得的逼近速率是最优的。 |
| [^133] | [Probabilistic inverse optimal control with local linearization for non-linear partially observable systems.](http://arxiv.org/abs/2303.16698) | 本文介绍了一种针对非线性部分可观测系统的局部线性化概率逆优化控制方法，可用于特征化顺序决策任务中的行为，并且具有广泛的适用性。 |
| [^134] | [PDExplain: Contextual Modeling of PDEs in the Wild.](http://arxiv.org/abs/2303.15827) | 我们提出了PDExplain，一种解释性的方法来解决偏微分方程。该算法能够通过提供少量样本的方式，预测未来时间步的PDE解，极大地协助了建立物理科学中基于数据的现象建模。 |
| [^135] | [Clustering with minimum spanning trees: How good can it be?.](http://arxiv.org/abs/2303.05679) | 本文研究了使用最小生成树（MST）进行分区数据聚类任务的意义程度，并发现MST方法在总体上具有很强的竞争力。此外，通过回顾、研究、扩展和推广现有的MST-based划分方案，我们提出了一些新的和值得注意的方法。总体上，Genie和信息论方法往往优于其他非MST算法，在某些情况下MST方法可能不如其他算法。 |
| [^136] | [Towards better traffic volume estimation: Tackling both underdetermined and non-equilibrium problems via a correlation-adaptive graph convolution network.](http://arxiv.org/abs/2303.05660) | 本研究提出基于图卷积网络的方法，解决交通量估计中的不确定和非平衡问题，实现准确的全面交通量估计。 |
| [^137] | [A General Theory of Correct, Incorrect, and Extrinsic Equivariance.](http://arxiv.org/abs/2303.04745) | 该论文提出了一个关于正确、错误和外在等变性的普遍理论，通过逐点定义量化了函数表现的每种类型等变性的程度，并研究了不正确或外在对称性对模型错误的影响。实验证实了这些结果。 (230字符) |
| [^138] | [On Calibrating Diffusion Probabilistic Models.](http://arxiv.org/abs/2302.10688) | 本文发现了数据分数随机反向过程是一个鞅，提出了一种简单的方法，用于校准任意预先训练的DPM，有效减小模型的得分匹配损失，增加模型似然的下限，并提供了一般校准指南。 |
| [^139] | [Near-optimal learning with average H\"older smoothness.](http://arxiv.org/abs/2302.06005) | 通过推广平均Lipschitz平滑性到Hölder平滑性，得到了关于平均Hölder平滑性的上下风险界，最优的下界对数因子最多差一个，提供了独立的学习算法。 |
| [^140] | [Star-Shaped Denoising Diffusion Probabilistic Models.](http://arxiv.org/abs/2302.05259) | 创新点在于提出了一种非马尔可夫扩散噪声过程的星形降噪扩散概率模型，能够广泛适用于指数族中的多种分布，特别适用于约束流形上的数据。 |
| [^141] | [Outlier-Robust Gromov-Wasserstein for Graph Data.](http://arxiv.org/abs/2302.04610) | 本论文提出了一种针对图数据的异常稳健Gromov-Wasserstein方法（RGW），通过引入乐观扰动的边际约束和使用Bregman近端交替线性化最小化算法，解决了GW距离对异常值敏感的问题。 |
| [^142] | [Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US.](http://arxiv.org/abs/2302.02560) | 本研究提出了一种神经网络方法，利用其理论基础和实施的可行性，从而估计连续暴露/治疗的分布对政策相关结果的因果效应。我们将此方法应用于包含6800万个个体和2700万个美国境内死亡事件的数据中，通过评估美国国家环境保护局（EPA）对PM2.5的国家环境空气质量标准（NAAQS）进行修订后的健康效益。 |
| [^143] | [Nonparametric Density Estimation under Distribution Drift.](http://arxiv.org/abs/2302.02460) | 该论文研究了非参数密度估计在分布漂移下的问题，证明了紧密极小风险界，并推广了先前关于对漂移的无知学习的结果。 |
| [^144] | [The contextual lasso: Sparse linear models via deep neural networks.](http://arxiv.org/abs/2302.00878) | 本论文提出了一种新的统计估计器——上下文套索，可以通过深度神经网络的方法解决解释性和拟合能力的矛盾问题，实现对可解释特征的稀疏拟合，并且稀疏模式和系数会随着上下文特征的变化而发生变化。 |
| [^145] | [The geometry of hidden representations of large transformer models.](http://arxiv.org/abs/2302.00294) | 大型Transformer模型中的隐藏表示具有类似的几何和统计特性，随着层级的移动，它们在最初的几层中变得高维，然后在中间层中显著收缩，在模型的最后部分，保持恒定或形成第二个浅峰。在第一个峰值结束时，数据集的语义信息被更好地表达。 |
| [^146] | [Kernelized Cumulants: Beyond Kernel Mean Embeddings.](http://arxiv.org/abs/2301.12466) | 本文通过核技巧将累计量扩展到再生核希尔伯特空间（RKHS），提供了一组新的通用统计量。超越一阶具有几个优势，并且在计算上具有相同的复杂度和最小的开销。 |
| [^147] | [Alignment with human representations supports robust few-shot learning.](http://arxiv.org/abs/2301.11990) | 论文提出少样本学习的表现与人类表征的一致性存在U形关系，并通过计算机视觉模型的实验进行了验证。高度对齐的模型更加鲁棒，对数据的利用更加有效，但与人类对齐并非必要条件。 |
| [^148] | [Characterization and Learning of Causal Graphs with Small Conditioning Sets.](http://arxiv.org/abs/2301.09028) | 本研究提出了一种使用小的条件集来表征和学习因果图的方法，用于解决约束性因果发现算法在数据有限和条件集较大时的困难。我们定义了k-马尔可夫等价的概念，该概念在不能利用所有条件独立性语句时仍然适用。 |
| [^149] | [Invertible normalizing flow neural networks by JKO scheme.](http://arxiv.org/abs/2212.14424) | 本文提出了一种基于JKO方案的可逆归一化流神经网络，通过按块进行残差块的训练，减少了内存负载和深度流网络训练的难度。并且通过自适应时间重新参数化的流网络，在概率空间中逐步细化轨迹，从而提高了模型的训练效率和准确性。 |
| [^150] | [Doubly Smoothed GDA: Global Convergent Algorithm for Constrained Nonconvex-Nonconcave Minimax Optimization.](http://arxiv.org/abs/2212.12978) | 本文提出了一种双重平滑梯度下降上升法 (DSGDA)，该算法可以应用于非凸-非凹极小极大优化，并且能够全局收敛并消除极限环。在一定条件下，DSGDA 的迭代复杂度达到了文献中单循环算法的最佳结果。 |
| [^151] | [Physics-Informed Gaussian Process Regression Generalizes Linear PDE Solvers.](http://arxiv.org/abs/2212.12474) | 本文使用物理学知识指导的高斯过程回归方法，解决线性偏微分方程求解器无法量化近似误差的问题。 |
| [^152] | [Beurling-Selberg Extremization for Dual-Blind Deconvolution Recovery in Joint Radar-Communications.](http://arxiv.org/abs/2211.09253) | 本文提出了在联合雷达通信中通过Beurling-Selberg极大化方法用于双盲反卷积恢复的优化分离条件。 |
| [^153] | [Unbiased constrained sampling with Self-Concordant Barrier Hamiltonian Monte Carlo.](http://arxiv.org/abs/2210.11925) | 本文提出了一种名为BHMC的新的蒙特卡罗采样算法，能够从定义了约束的黎曼流形中进行无偏采样，其中包含一种新的过滤步骤involution checking step。 |
| [^154] | [Online Convex Optimization with Unbounded Memory.](http://arxiv.org/abs/2210.09903) | 本论文提出了一种新的在线凸优化框架，可以处理决策历史的长期依赖关系，并介绍了用于量化依赖程度的$p$-有效内存容量的概念。 |
| [^155] | [A Spectral Approach to Item Response Theory.](http://arxiv.org/abs/2210.04317) | 本文提出了一种基于谱方法的项目反应理论算法，通过计算马尔科夫链的平稳分布来估计模型参数，具有良好的优化性能和有限样本误差保证。 |
| [^156] | [Many-body Approximation for Non-negative Tensors.](http://arxiv.org/abs/2209.15338) | 提出了一种名为多体逼近的方法来分解非负张量，通过能量建模来避免全局优化和目标秩选择的困难，可通过考虑模式之间的交互进行全局优化; 在许多任务中都展示了其有效性。 |
| [^157] | [Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses.](http://arxiv.org/abs/2209.07403) | 本论文研究了具有大的最坏情况Lipschitz参数的差分隐私随机优化问题，并提供了一种不依赖于统一Lipschitz参数的接近最优的过量风险界限方法。 |
| [^158] | [Pattern reconstruction with restricted Boltzmann machines.](http://arxiv.org/abs/2205.07087) | 该论文研究了限制玻尔兹曼机在模式重构中的能力，发现隐藏层先验分布的尾部行为对于恢复随机模式的效果有关键影响。 |
| [^159] | [Compositional Generalization and Decomposition in Neural Program Synthesis.](http://arxiv.org/abs/2204.03758) | 本文探讨了神经程序综合方法在组合泛化和分解方面的能力，并提出了一套基准任务来评估这些能力。 |
| [^160] | [CrossBeam: Learning to Search in Bottom-Up Program Synthesis.](http://arxiv.org/abs/2203.10452) | CrossBeam是一种在自底向上程序合成中学习搜索策略的方法，通过训练神经模型来选择如何合并先前探索的程序，以控制搜索空间的膨胀。 |
| [^161] | [Distributionally Robust Bayesian Optimization with $\phi$-divergences.](http://arxiv.org/abs/2203.02128) | 本研究提出了一种基于$\phi$-离散度的分布鲁棒贝叶斯优化算法。 |
| [^162] | [Learning with Subset Stacking.](http://arxiv.org/abs/2112.06251) | 提出了一种新的回归算法LESS，通过生成以随机点为中心的子集并训练局部预测器，然后以新颖的方式组合预测器得到整体预测器。在多个数据集上测试表明，LESS是一种有竞争力且高效的监督学习方法。 |
| [^163] | [Minimax Rates for High-Dimensional Random Tessellation Forests.](http://arxiv.org/abs/2109.10541) | 本研究展示了一大类具有一般分割方向的随机森林能够在任意维度上实现极小极大的收敛率，包括STIT森林和源自泊松超平面镶嵌的随机森林。 |
| [^164] | [Continuous Conditional Generative Adversarial Networks: Novel Empirical Losses and Label Input Mechanisms.](http://arxiv.org/abs/2011.07466) | 本文提出了连续条件生成对抗网络（CcGAN），首个用于基于连续标量条件的图像生成的生成模型。通过重新构建经验cGAN损失和提出新的标签输入方法，解决了在回归标签条件生成中存在的问题。 |
| [^165] | [BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase Generation.](http://arxiv.org/abs/1909.09485) | 本研究提出了一种基于注意力奖励的束搜索解码策略，用于解决神经关键词生成中的序列长度偏差和束多样性问题，该方法显著提高了生成关键词的解码性能。 |
| [^166] | [Testing Robustness Against Unforeseen Adversaries.](http://arxiv.org/abs/1908.08016) | 该论文提出了18种新的对抗攻击，并使用这些攻击创建了一个用于评估对各种未预料到的对手的鲁棒性的新基准。作者还发现了一系列防御策略，可以帮助克服训练期间未考虑到的对手的泛化差距。该研究的结果将为研究现实世界最坏情况下的鲁棒性提供有用工具，促进开发更强大的防御措施。 |
| [^167] | [Weighted bandits or: How bandits learn distorted values that are not expected.](http://arxiv.org/abs/1611.10283) | 本论文研究了带有扭曲概率的随机多臂赌博机问题，并提出了以UCB算法为基础、考虑了奖励扭曲并具有次线性后悔的算法。 |

# 详细

[^1]: 线性模型的鲁棒因果强化学习算法

    Robust Causal Bandits for Linear Models. (arXiv:2310.19794v1 [stat.ML])

    [http://arxiv.org/abs/2310.19794](http://arxiv.org/abs/2310.19794)

    本文研究了线性模型的鲁棒因果强化学习算法，在复杂系统的情况下，现有方法无法保持遗憾次线性。

    

    在因果系统中，优化回报函数的顺序实验设计可以有效地建模为因果强化学习中的顺序干预设计。在已有的因果强化学习文献中，一个重要的假设是因果模型在时间上保持不变。然而，在复杂系统中，数学模型常常发生时间上的波动，这个假设不一定成立。本文研究了因果强化学习在模型波动存在下的鲁棒性。重点研究了具有线性结构方程模型 (SEMs) 的因果系统。SEMs 和时间变化的干预前后统计模型均为未知。以累计遗憾为设计指标，在知道整个因果模型及其波动情况的神谕的基础上，设计一系列干预使得累计遗憾最小化。首先，通过实验证明了现有方法无法保持遗憾次线性。

    Sequential design of experiments for optimizing a reward function in causal systems can be effectively modeled by the sequential design of interventions in causal bandits (CBs). In the existing literature on CBs, a critical assumption is that the causal models remain constant over time. However, this assumption does not necessarily hold in complex systems, which constantly undergo temporal model fluctuations. This paper addresses the robustness of CBs to such model fluctuations. The focus is on causal systems with linear structural equation models (SEMs). The SEMs and the time-varying pre- and post-interventional statistical models are all unknown. Cumulative regret is adopted as the design criteria, based on which the objective is to design a sequence of interventions that incur the smallest cumulative regret with respect to an oracle aware of the entire causal model and its fluctuations. First, it is established that the existing approaches fail to maintain regret sub-linearity with 
    
[^2]: 关于使用梯度流学习高斯多索引模型的研究

    On Learning Gaussian Multi-index Models with Gradient Flow. (arXiv:2310.19793v1 [stat.ML])

    [http://arxiv.org/abs/2310.19793](http://arxiv.org/abs/2310.19793)

    本研究探讨了在高维高斯数据的多索引回归问题中，通过梯度流学习低秩线性投影和低维连接函数，建立了全局收敛性和定量描述的算法。

    

    我们研究了高维高斯数据的多索引回归问题中的梯度流。多索引函数由未知的低秩线性投影和任意未知的低维连接函数组成。因此，它们构成了神经网络中特征学习的自然模板。我们考虑了一个两时间尺度的算法，其中低维连接函数通过非参数模型比参数化低秩投影的低维空间更快地学习。通过适当地利用框架的相关矩阵上的矩阵半群结构，我们建立了由Grassmannian人口梯度流动力学引起的全局收敛性，并对其相关的“鞍点到鞍点”动力学提供了定量描述。值得注意的是，每个鞍的时间尺度可以明确地用目标连接函数的适当Hermite分解来表征。与这些位置相反的是。

    We study gradient flow on the multi-index regression problem for high-dimensional Gaussian data. Multi-index functions consist of a composition of an unknown low-rank linear projection and an arbitrary unknown, low-dimensional link function. As such, they constitute a natural template for feature learning in neural networks.  We consider a two-timescale algorithm, whereby the low-dimensional link function is learnt with a non-parametric model infinitely faster than the subspace parametrizing the low-rank projection. By appropriately exploiting the matrix semigroup structure arising over the subspace correlation matrices, we establish global convergence of the resulting Grassmannian population gradient flow dynamics, and provide a quantitative description of its associated `saddle-to-saddle' dynamics. Notably, the timescales associated with each saddle can be explicitly characterized in terms of an appropriate Hermite decomposition of the target link function. In contrast with these pos
    
[^3]: DiffEnc: 使用学习的编码器的变分扩散模型

    DiffEnc: Variational Diffusion with a Learned Encoder. (arXiv:2310.19789v1 [cs.LG])

    [http://arxiv.org/abs/2310.19789](http://arxiv.org/abs/2310.19789)

    DiffEnc是一种使用学习的编码器的变分扩散模型，通过引入数据和深度相关的均值函数和可调节的噪声方差比率，实现了最先进的可能性。

    

    扩散模型可以看作是具有两种改进的分层变分自编码器（VAEs）：在生成过程中参数共享的条件分布和在层次结构上独立计算损失。我们对扩散模型进行了两个变化，保留了这些优势的同时增加了模型的灵活性。首先，我们在扩散过程中引入了一个与数据和深度相关的均值函数，从而导致了修改后的扩散损失。我们提出的框架DiffEnc在CIFAR-10上实现了最先进的可能性。其次，我们让反向编码过程的噪声方差与生成过程的比率成为一个自由的权重参数，而不是固定为1。这带来了理论上的洞察力：对于有限深度层次，证据下界（ELBO）可以用作加权扩散损失方法的目标，并用于专门为推理而优化噪声调度。

    Diffusion models may be viewed as hierarchical variational autoencoders (VAEs) with two improvements: parameter sharing for the conditional distributions in the generative process and efficient computation of the loss as independent terms over the hierarchy. We consider two changes to the diffusion model that retain these advantages while adding flexibility to the model. Firstly, we introduce a data- and depth-dependent mean function in the diffusion process, which leads to a modified diffusion loss. Our proposed framework, DiffEnc, achieves state-of-the-art likelihood on CIFAR-10. Secondly, we let the ratio of the noise variance of the reverse encoder process and the generative process be a free weight parameter rather than being fixed to 1. This leads to theoretical insights: For a finite depth hierarchy, the evidence lower bound (ELBO) can be used as an objective for a weighted diffusion loss approach and for optimizing the noise schedule specifically for inference. For the infinite
    
[^4]: 具有固定预算的局部最优最佳臂识别算法

    Locally Optimal Best Arm Identification with a Fixed Budget. (arXiv:2310.19788v1 [math.ST])

    [http://arxiv.org/abs/2310.19788](http://arxiv.org/abs/2310.19788)

    该研究解决了识别具有最高预期效果的治疗方案的问题，并提出了具有固定预算的局部最优算法来降低错误识别的概率。

    

    本研究探讨了识别最佳治疗方案的问题，即具有最高预期效果的治疗方案。我们旨在通过降低错误识别的概率来确定最佳治疗方案，这一问题在许多研究领域中已被探索，包括最佳臂识别（Best Arm Identification，BAI）和序列优化。在我们的实验中，治疗分配的轮数是固定的。在每一轮中，决策者将一种治疗方案分配给一个实验单元，并观察相应的结果，该结果遵循不同治疗方案之间方差不同的高斯分布。在实验结束时，我们根据观察结果推荐一种治疗方案作为最佳治疗方案的估计值。决策者的目标是设计一个实验，使错误识别最佳治疗方案的概率最小化。基于这一目标，我们开发了误识别概率的下界。

    This study investigates the problem of identifying the best treatment arm, a treatment arm with the highest expected outcome. We aim to identify the best treatment arm with a lower probability of misidentification, which has been explored under various names across numerous research fields, including \emph{best arm identification} (BAI) and ordinal optimization. In our experiments, the number of treatment-allocation rounds is fixed. In each round, a decision-maker allocates a treatment arm to an experimental unit and observes a corresponding outcome, which follows a Gaussian distribution with a variance different among treatment arms. At the end of the experiment, we recommend one of the treatment arms as an estimate of the best treatment arm based on the observations. The objective of the decision-maker is to design an experiment that minimizes the probability of misidentifying the best treatment arm. With this objective in mind, we develop lower bounds for the probability of misident
    
[^5]: $e^{\text{RPCA}}$：针对指数族分布的鲁棒主成分分析

    $e^{\text{RPCA}}$: Robust Principal Component Analysis for Exponential Family Distributions. (arXiv:2310.19787v1 [stat.ME])

    [http://arxiv.org/abs/2310.19787](http://arxiv.org/abs/2310.19787)

    本论文提出了一种针对指数族分布的鲁棒主成分分析方法$e^{\text{RPCA}}$，可以有效地恢复低秩结构并进行异常点的识别和处理。

    

    鲁棒主成分分析(RPCA)是一种广泛应用的方法，用于从受到显著和稀疏异常数据干扰的数据矩阵中恢复低秩结构。这些异常可能来自遮挡、恶意篡改或其他异常原因，对于过程监测和诊断，联合识别这些异常与低秩背景至关重要。然而，现有的RPCA方法及其扩展在很大程度上未考虑数据矩阵的概率分布，而在许多应用中，这些分布是已知的且可能高度非高斯的。因此，我们提出了一种新的方法，称为面向指数族分布的鲁棒主成分分析($e^{\text{RPCA}}$)，可以在指数族分布内进行所需的低秩和稀疏矩阵分解。我们提出了一种新颖的交替方向乘子优化算法，用于高效的$e^{\text{RPCA}}$分解。

    Robust Principal Component Analysis (RPCA) is a widely used method for recovering low-rank structure from data matrices corrupted by significant and sparse outliers. These corruptions may arise from occlusions, malicious tampering, or other causes for anomalies, and the joint identification of such corruptions with low-rank background is critical for process monitoring and diagnosis. However, existing RPCA methods and their extensions largely do not account for the underlying probabilistic distribution for the data matrices, which in many applications are known and can be highly non-Gaussian. We thus propose a new method called Robust Principal Component Analysis for Exponential Family distributions ($e^{\text{RPCA}}$), which can perform the desired decomposition into low-rank and sparse matrices when such a distribution falls within the exponential family. We present a novel alternating direction method of multiplier optimization algorithm for efficient $e^{\text{RPCA}}$ decomposition
    
[^6]: 起始于噪声的简化模型之路

    A Path to Simpler Models Starts With Noise. (arXiv:2310.19726v1 [cs.LG])

    [http://arxiv.org/abs/2310.19726](http://arxiv.org/abs/2310.19726)

    本文研究了数据生成过程的机制和分析师的选择如何影响Rashomon比率，并介绍了一个称为模式多样性的指标来衡量不同分类器之间的预测差异。

    

    Rashomon集合是在给定数据集上表现近乎相等的模型集合，Rashomon比率是在给定假设空间中处于Rashomon集合中的模型所占比例。在刑事司法、医疗保健、贷款、教育等领域的表格型数据集中，Rashomon比率通常很高，这对于简单模型是否能达到与更复杂模型相同的准确性具有实际影响。一个开放的问题是为什么Rashomon比率通常倾向于很高。在这项研究中，我们提出并研究了数据生成过程的机制，以及分析师在学习过程中通常进行的选择，这决定了Rashomon比率的大小。具体而言，我们证明了更嘈杂的数据集会通过从业者训练模型的方式导致更高的Rashomon比率。此外，我们引入了一种称为模式多样性的指标，该指标捕捉了不同分类器之间预测的平均差异。

    The Rashomon set is the set of models that perform approximately equally well on a given dataset, and the Rashomon ratio is the fraction of all models in a given hypothesis space that are in the Rashomon set. Rashomon ratios are often large for tabular datasets in criminal justice, healthcare, lending, education, and in other areas, which has practical implications about whether simpler models can attain the same level of accuracy as more complex models. An open question is why Rashomon ratios often tend to be large. In this work, we propose and study a mechanism of the data generation process, coupled with choices usually made by the analyst during the learning process, that determines the size of the Rashomon ratio. Specifically, we demonstrate that noisier datasets lead to larger Rashomon ratios through the way that practitioners train models. Additionally, we introduce a measure called pattern diversity, which captures the average difference in predictions between distinct classifi
    
[^7]: 支持矩阵机器：评论

    Support matrix machine: A review. (arXiv:2310.19717v1 [cs.LG])

    [http://arxiv.org/abs/2310.19717](http://arxiv.org/abs/2310.19717)

    支持矩阵机器是一种新兴的方法，用于处理矩阵输入数据，并通过使用谱弹性网络性质保留了矩阵数据的结构信息。

    

    支持向量机（SVM）是机器学习领域中最受研究的范式之一，用于分类和回归问题。它依赖于向量化的输入数据。然而，现实世界中的许多数据存在于矩阵格式中，这些数据通过将矩阵重新整形为向量的方式输入到SVM中。重新整形的过程破坏了矩阵数据中固有的空间相关性。此外，将矩阵转换为向量会导致输入数据的维度很高，引入了显着的计算复杂性。为了解决分类矩阵输入数据的这些问题，提出了支持矩阵机器（SMM）。它代表了专门用于处理矩阵输入数据的新兴方法之一。SMM方法通过使用谱弹性网络性质（核范数和Frobenius范数的组合）保留了矩阵数据的结构信息。本文首次对支持矩阵机器的发展进行了深入分析。

    Support vector machine (SVM) is one of the most studied paradigms in the realm of machine learning for classification and regression problems. It relies on vectorized input data. However, a significant portion of the real-world data exists in matrix format, which is given as input to SVM by reshaping the matrices into vectors. The process of reshaping disrupts the spatial correlations inherent in the matrix data. Also, converting matrices into vectors results in input data with a high dimensionality, which introduces significant computational complexity. To overcome these issues in classifying matrix input data, support matrix machine (SMM) is proposed. It represents one of the emerging methodologies tailored for handling matrix input data. The SMM method preserves the structural information of the matrix data by using the spectral elastic net property which is a combination of the nuclear norm and Frobenius norm. This article provides the first in-depth analysis of the development of 
    
[^8]: 因果背景将反事实公平性与强健预测和群体公平性相连接

    Causal Context Connects Counterfactual Fairness to Robust Prediction and Group Fairness. (arXiv:2310.19691v1 [cs.LG])

    [http://arxiv.org/abs/2310.19691](http://arxiv.org/abs/2310.19691)

    本文通过使用因果背景来将反事实公平性、强健预测和群体公平性相连接。首先，通过合理条件下的研究，证明了反事实公平预测器在无偏目标分布中是准确性最优的。其次，发展了数据生成的因果图与强健预测和群体公平性之间的对应关系。

    

    反事实公平性要求如果一个人属于不同的受保护类别，如不同的种族或性别，那么该人在人工智能或其他算法系统中将被分类为相同类别。这是一种直观的标准，反映在美国的法律体系中，但由于反事实在真实世界的数据中无法直接观察到，其使用受限。另一方面，群体公平性度量（如人口平衡或平等赔率）较少直观，但更容易观察到。在本文中，我们使用“因果背景”来弥合反事实公平性、强健预测和群体公平性之间的差距。首先，我们通过展示在合理的条件下，反事实公平预测器实际上在无偏目标分布中是最优准确性的，从而激发了反事实公平性的动机。其次，我们发展了数据生成的因果图与强健预测和群体公平性之间的对应关系。

    Counterfactual fairness requires that a person would have been classified in the same way by an AI or other algorithmic system if they had a different protected class, such as a different race or gender. This is an intuitive standard, as reflected in the U.S. legal system, but its use is limited because counterfactuals cannot be directly observed in real-world data. On the other hand, group fairness metrics (e.g., demographic parity or equalized odds) are less intuitive but more readily observed. In this paper, we use $\textit{causal context}$ to bridge the gaps between counterfactual fairness, robust prediction, and group fairness. First, we motivate counterfactual fairness by showing that there is not necessarily a fundamental trade-off between fairness and accuracy because, under plausible conditions, the counterfactually fair predictor is in fact accuracy-optimal in an unbiased target distribution. Second, we develop a correspondence between the causal graph of the data-generating 
    
[^9]: 通过变分界限实现实用的非对抗分布对齐

    Towards Practical Non-Adversarial Distribution Alignment via Variational Bounds. (arXiv:2310.19690v1 [cs.LG])

    [http://arxiv.org/abs/2310.19690](http://arxiv.org/abs/2310.19690)

    本论文提出了一种非对抗的基于变分自动编码器的对齐方法，通过引入一组对齐上界，解决了先前方法中存在的不稳定性和限制。实验证明，这种新颖的对齐损失可以在不改变原始架构的情况下取代对抗损失，扩展了应用范围。

    

    分布对齐可用于学习具有公平性和鲁棒性应用的不变表示。大多数先前的工作都采用对抗对齐方法，但由此产生的极小极大问题不稳定且难以优化。非对抗的基于似然的方法要么需要模型可逆性，要么对潜在先验施加约束，要么缺乏通用的对齐框架。为了克服这些限制，我们提出了一种非对抗的基于变分自动编码器的对齐方法，可应用于任何模型管道。我们开发了一组对齐上界（包括一个含噪音的上界），其具有类似变分自动编码器的目标但具有不同的视角。我们在理论上和实证上仔细比较了我们的方法与先前的基于变分自动编码器的对齐方法。最后，我们证明我们的新颖对齐损失可以在标准的不变表示学习管道中取代对抗损失，而无需修改原始架构，从而显著拓展了应用范围。

    Distribution alignment can be used to learn invariant representations with applications in fairness and robustness. Most prior works resort to adversarial alignment methods but the resulting minimax problems are unstable and challenging to optimize. Non-adversarial likelihood-based approaches either require model invertibility, impose constraints on the latent prior, or lack a generic framework for alignment. To overcome these limitations, we propose a non-adversarial VAE-based alignment method that can be applied to any model pipeline. We develop a set of alignment upper bounds (including a noisy bound) that have VAE-like objectives but with a different perspective. We carefully compare our method to prior VAE-based alignment approaches both theoretically and empirically. Finally, we demonstrate that our novel alignment losses can replace adversarial losses in standard invariant representation learning pipelines without modifying the original architectures -- thereby significantly bro
    
[^10]: 时间序列的在线自助法

    An Online Bootstrap for Time Series. (arXiv:2310.19683v1 [stat.ML])

    [http://arxiv.org/abs/2310.19683](http://arxiv.org/abs/2310.19683)

    本文提出了一种新型的在线自助法用于处理大规模的时间序列和相关数据流，通过考虑数据的依赖关系，该方法可以提供可靠的不确定性量化，填补了现有自助法在复杂数据依赖情况下的应用空白。

    

    如何处理大规模的相关数据流（如时间序列或空间相关观测数据）时，传统的自助法受限制。本文提出了一种可以在线执行的新型自助法，专门用于考虑数据的依赖关系，使其特别适用于实时应用。这种方法基于一个自回归序列，其中包含越来越相关的重采样权重。我们证明了在一般条件下提出的自助法的理论有效性。通过大量的模拟实验，我们证明了我们的方法的有效性，并显示它在复杂数据依赖存在的情况下提供可靠的不确定性量化。我们的工作填补了传统重采样技术与现代数据分析需求之间的鸿沟，为研究人员和从业者提供了一种有价值的工具。

    Resampling methods such as the bootstrap have proven invaluable in the field of machine learning. However, the applicability of traditional bootstrap methods is limited when dealing with large streams of dependent data, such as time series or spatially correlated observations. In this paper, we propose a novel bootstrap method that is designed to account for data dependencies and can be executed online, making it particularly suitable for real-time applications. This method is based on an autoregressive sequence of increasingly dependent resampling weights. We prove the theoretical validity of the proposed bootstrap scheme under general conditions. We demonstrate the effectiveness of our approach through extensive simulations and show that it provides reliable uncertainty quantification even in the presence of complex data dependencies. Our work bridges the gap between classical resampling techniques and the demands of modern data analysis, providing a valuable tool for researchers and
    
[^11]: 通过神经扩散反应过程实现动态张量分解

    Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes. (arXiv:2310.19666v1 [cs.LG])

    [http://arxiv.org/abs/2310.19666](http://arxiv.org/abs/2310.19666)

    本论文提出了一种通过神经扩散反应过程实现动态张量分解的方法(DEMOTE)，该方法能够更好地利用时间信息和稀疏观测张量条目内的结构知识，以捕捉潜在的时态结构。

    

    张量分解是多维数据分析的重要工具。在实践中，数据往往稀疏但与丰富的时间信息相关。然而，现有方法常常未充分利用时间信息，并忽视稀疏观测张量条目内的结构知识。为了克服这些限制，更好地捕捉潜在的时态结构，我们提出了动态张量分解方法Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE)。我们开发了一种神经扩散反应过程来估计每个张量模式中实体的动态嵌入。具体而言，基于观测到的张量条目，我们构建了一个多部分图来编码实体之间的相关性。我们构建了一个图扩散过程来共同演化相关实体的嵌入轨迹，并使用神经网络为每个单独的实体构建了一个反应过程。通过这种方式，我们的模型能够在演化过程中捕捉到共性和个性。

    Tensor decomposition is an important tool for multiway data analysis. In practice, the data is often sparse yet associated with rich temporal information. Existing methods, however, often under-use the time information and ignore the structural knowledge within the sparsely observed tensor entries. To overcome these limitations and to better capture the underlying temporal structure, we propose Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE). We develop a neural diffusion-reaction process to estimate dynamic embeddings for the entities in each tensor mode. Specifically, based on the observed tensor entries, we build a multi-partite graph to encode the correlation between the entities. We construct a graph diffusion process to co-evolve the embedding trajectories of the correlated entities and use a neural network to construct a reaction process for each individual entity. In this way, our model can capture both the commonalities and personalities during the evolution of the
    
[^12]: 使用扩散模型提供的无限数据计划升级VAE训练

    Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion Models. (arXiv:2310.19653v1 [stat.ML])

    [http://arxiv.org/abs/2310.19653](http://arxiv.org/abs/2310.19653)

    这项研究通过在预训练的扩散模型生成的样本上进行训练，有效减轻了VAE中编码器的过拟合问题。

    

    变分自编码器（VAE）是一种常用的表示学习模型，但其编码器容易过拟合，因为它们是在有限的训练集上进行训练，而不是真实（连续）数据分布$p_{\mathrm{data}}(\mathbf{x})$。与之相反，扩散模型通过固定编码器避免了这个问题。这使得它们的表示不太可解释，但简化了训练，可以精确和连续地逼近$p_{\mathrm{data}}(\mathbf{x})$。在本文中，我们展示了通过在预训练的扩散模型生成的样本上训练，可以有效减轻VAE中编码器的过拟合问题。这些结果有些出人意料，因为最近的研究发现，在使用另一个生成模型生成的数据上训练时，生成性能会下降。我们分析了使用我们的方法训练的VAE的泛化性能、分摊差距和鲁棒性。

    Variational autoencoders (VAEs) are popular models for representation learning but their encoders are susceptible to overfitting (Cremer et al., 2018) because they are trained on a finite training set instead of the true (continuous) data distribution $p_{\mathrm{data}}(\mathbf{x})$. Diffusion models, on the other hand, avoid this issue by keeping the encoder fixed. This makes their representations less interpretable, but it simplifies training, enabling accurate and continuous approximations of $p_{\mathrm{data}}(\mathbf{x})$. In this paper, we show that overfitting encoders in VAEs can be effectively mitigated by training on samples from a pre-trained diffusion model. These results are somewhat unexpected as recent findings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in generative performance when models are trained on data generated by another generative model. We analyze generalization performance, amortization gap, and robustness of VAEs trained with our pro
    
[^13]: 一种用于稀疏典型相关估计的贝叶斯方法

    A Bayesian Methodology for Estimation for Sparse Canonical Correlation. (arXiv:2310.19621v1 [stat.ME])

    [http://arxiv.org/abs/2310.19621](http://arxiv.org/abs/2310.19621)

    本文提出了一种新颖的贝叶斯方法，用于稀疏典型相关估计，通过在建模框架中的两个级别上鼓励稀疏，来实现对多视图高维数据的鲁棒建模。

    

    在对参与联合研究的每个被试所获取的来自不同实验的多视图高维数据进行综合统计分析时，可能很具有挑战性。典型相关分析(CCA)是一种用于确定这些数据集之间关系的统计过程。在这个背景下，结构稀疏CCA(ScSCCA)是一种快速崛起的方法论领域，旨在通过假设相应的CCA方向向量是稀疏的，来对不同数据模态之间的相互关系进行鲁棒建模。虽然这是一个快速发展的统计方法学领域，但在贝叶斯范式下仍需要开发相关方法。在本文中，我们提出了一种新颖的ScSCCA方法，我们采用贝叶斯无穷因子模型，并通过在建模框架的两个不同级别上鼓励稀疏来实现鲁棒估计。首先，我们利用一个乘法半-Cauchy过程先验来实现稀疏建模。

    It can be challenging to perform an integrative statistical analysis of multi-view high-dimensional data acquired from different experiments on each subject who participated in a joint study. Canonical Correlation Analysis (CCA) is a statistical procedure for identifying relationships between such data sets. In that context, Structured Sparse CCA (ScSCCA) is a rapidly emerging methodological area that aims for robust modeling of the interrelations between the different data modalities by assuming the corresponding CCA directional vectors to be sparse. Although it is a rapidly growing area of statistical methodology development, there is a need for developing related methodologies in the Bayesian paradigm. In this manuscript, we propose a novel ScSCCA approach where we employ a Bayesian infinite factor model and aim to achieve robust estimation by encouraging sparsity in two different levels of the modeling framework. Firstly, we utilize a multiplicative Half-Cauchy process prior to enc
    
[^14]: 论费曼-卡克训练部分贝叶斯神经网络

    On Feynman--Kac training of partial Bayesian neural networks. (arXiv:2310.19608v1 [cs.LG])

    [http://arxiv.org/abs/2310.19608](http://arxiv.org/abs/2310.19608)

    本文提出了一种将部分贝叶斯神经网络训练转化为模拟费曼-卡克模型的高效采样训练策略，并通过各种数据集的实验证明其在预测性能方面优于现有技术。

    

    最近，部分贝叶斯神经网络(pBNNs)被证明与全贝叶斯神经网络具有竞争力，但pBNNs在潜变量空间中往往是多峰的，因此用参数模型来近似是具有挑战性的。为了解决这个问题，我们提出了一种高效的基于采样的训练策略，即将pBNN的训练转化为模拟费曼-卡克模型。我们还描述了序贯蒙特卡洛采样器的变种，使我们能够以可行的计算成本同时估计参数和该模型的潜在后验分布。我们在各种合成和真实世界的数据集上展示了我们提出的训练方案在预测性能方面优于现有技术。

    Recently, partial Bayesian neural networks (pBNNs), which only consider a subset of the parameters to be stochastic, were shown to perform competitively with full Bayesian neural networks. However, pBNNs are often multi-modal in the latent-variable space and thus challenging to approximate with parametric models. To address this problem, we propose an efficient sampling-based training strategy, wherein the training of a pBNN is formulated as simulating a Feynman--Kac model. We then describe variations of sequential Monte Carlo samplers that allow us to simultaneously estimate the parameters and the latent posterior distribution of this model at a tractable computational cost. We show on various synthetic and real-world datasets that our proposed training scheme outperforms the state of the art in terms of predictive performance.
    
[^15]: 深度卡尔曼滤波器可以进行滤波

    Deep Kalman Filters Can Filter. (arXiv:2310.19603v1 [cs.LG])

    [http://arxiv.org/abs/2310.19603](http://arxiv.org/abs/2310.19603)

    本研究展示了一类连续时间的深度卡尔曼滤波器（DKFs），可以近似实现一类非马尔可夫和条件高斯信号过程的条件分布律，从而具有在数学金融领域中传统模型基础上的滤波问题的应用潜力。

    

    深度卡尔曼滤波器（DKFs）是一类神经网络模型，可以从序列数据中生成高斯概率测度。虽然DKFs受卡尔曼滤波器的启发，但它们缺乏与随机滤波问题的具体理论关联，从而限制了它们在传统模型基础上的滤波问题的应用，例如数学金融中的债券和期权定价模型校准。我们通过展示一类连续时间DKFs，可以近似实现一类非马尔可夫和条件高斯信号过程的条件分布律，从而解决了深度学习数学基础中的这个问题。我们的近似结果在路径的足够规则的紧致子集上一致成立，其中近似误差由在给定紧致路径集上均一地计算的最坏情况2-Wasserstein距离量化。

    Deep Kalman filters (DKFs) are a class of neural network models that generate Gaussian probability measures from sequential data. Though DKFs are inspired by the Kalman filter, they lack concrete theoretical ties to the stochastic filtering problem, thus limiting their applicability to areas where traditional model-based filters have been used, e.g.\ model calibration for bond and option prices in mathematical finance. We address this issue in the mathematical foundations of deep learning by exhibiting a class of continuous-time DKFs which can approximately implement the conditional law of a broad class of non-Markovian and conditionally Gaussian signal processes given noisy continuous-times measurements. Our approximation results hold uniformly over sufficiently regular compact subsets of paths, where the approximation error is quantified by the worst-case 2-Wasserstein distance computed uniformly over the given compact set of paths.
    
[^16]: 具有加性和乘性噪声的线性随机微分方程的发生器识别

    Generator Identification for Linear SDEs with Additive and Multiplicative Noise. (arXiv:2310.19491v1 [math.ST])

    [http://arxiv.org/abs/2310.19491](http://arxiv.org/abs/2310.19491)

    本文介绍了从具有给定初始状态的解过程的分布中识别线性随机微分方程（SDE）的发生器的条件，并且提供了对于具有加性和乘性噪声的SDE的识别条件。

    

    本文提出了一种从具有给定固定初始状态的解过程的分布中识别线性随机微分方程（SDE）的发生器的条件。这些可识别性条件在使用线性SDE进行因果推断时至关重要，因为它们使得可以从其观测分布中识别出干预后的分布。我们具体推导出了识别具有加性噪声的线性SDE的发生器的充分必要条件，以及识别具有乘性噪声的线性SDE的发生器的充分条件。我们证明了对于两种类型的SDE，得到的条件是一般性的。此外，我们提供了对得到的可识别性条件的几何解释，以增强对其的理解。为了验证我们的理论结果，我们进行了一系列的模拟实验，这些实验支持并证实了我们所得到的结果。

    In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.
    
[^17]: 多智能体合作学习系统中的遗憾最小化算法

    Regret-Minimization Algorithms for Multi-Agent Cooperative Learning Systems. (arXiv:2310.19468v1 [cs.LG])

    [http://arxiv.org/abs/2310.19468](http://arxiv.org/abs/2310.19468)

    本文研究了多智能体合作学习系统中的遗憾最小化算法。通过分析不同顺序决策问题下的MACL系统，本文提出了在合作多智能体多臂老虎机问题中使用全信息或信息有限反馈的方法，通过交换信息来改善学习效果。

    

    多智能体合作学习(MACL)系统是一种人工智能系统，多个学习智能体共同完成一个共同任务。最近在各个领域（如交通控制、云计算、机器人技术）中，MACL系统取得了良好的实证成功，这激发了对设计和分析用于顺序决策问题的MACL系统的研究。决策问题中学习算法的重要指标是遗憾，即算法实际获得的奖励与最高可达奖励之间的差异。设计和开发具有低遗憾学习算法的MACL系统可以创造巨大的经济价值。本文分析了不同顺序决策问题下的MACL系统。具体而言，第3章和第4章研究了具有全信息或者信息有限反馈的合作多智能体多臂老虎机问题，在这些问题中，多个学习智能体可以通过交换信息来改善学习效果。

    A Multi-Agent Cooperative Learning (MACL) system is an artificial intelligence (AI) system where multiple learning agents work together to complete a common task. Recent empirical success of MACL systems in various domains (e.g. traffic control, cloud computing, robotics) has sparked active research into the design and analysis of MACL systems for sequential decision making problems. One important metric of the learning algorithm for decision making problems is its regret, i.e. the difference between the highest achievable reward and the actual reward that the algorithm gains. The design and development of a MACL system with low-regret learning algorithms can create huge economic values. In this thesis, I analyze MACL systems for different sequential decision making problems. Concretely, the Chapter 3 and 4 investigate the cooperative multi-agent multi-armed bandit problems, with full-information or bandit feedback, in which multiple learning agents can exchange their information throu
    
[^18]: MMM和MMMSynth：异构表格数据的聚类和合成数据生成

    MMM and MMMSynth: Clustering of heterogeneous tabular data, and synthetic data generation. (arXiv:2310.19454v1 [cs.LG])

    [http://arxiv.org/abs/2310.19454](http://arxiv.org/abs/2310.19454)

    该论文提出了MMM和MMMSynth算法，用于聚类异构表格数据和生成合成数据。MMM算法利用EM算法，在同类算法中表现更优，对于确定合成数据的聚类以及恢复真实数据的结构有较好的效果。 MMMSynth算法则用于从真实数据生成合成表格数据。

    

    我们提出了两个与异构表格数据相关的任务的新算法：聚类和合成数据生成。表格数据集通常由列中的异构数据类型（数值、有序、分类）组成，但行中可能还存在隐藏的聚类结构：例如，它们可能来自异构的（地理、社会经济、方法论）来源，因此所描述的结果变量（如疾病的存在）可能不仅依赖其他变量，还依赖于聚类上下文。此外，医学数据的共享通常受到患者隐私法律的限制，因此目前对于通过深度学习等方法从真实数据生成合成表格数据的算法非常感兴趣。我们展示了一种新颖的基于EM的聚类算法MMM（“Madras混合模型”），它在确定合成异构数据的聚类和恢复真实数据结构方面优于标准算法。基于此，我们可将MMM应用于数据合成任务的MMMSynth算法。

    We provide new algorithms for two tasks relating to heterogeneous tabular datasets: clustering, and synthetic data generation. Tabular datasets typically consist of heterogeneous data types (numerical, ordinal, categorical) in columns, but may also have hidden cluster structure in their rows: for example, they may be drawn from heterogeneous (geographical, socioeconomic, methodological) sources, such that the outcome variable they describe (such as the presence of a disease) may depend not only on the other variables but on the cluster context. Moreover, sharing of biomedical data is often hindered by patient confidentiality laws, and there is current interest in algorithms to generate synthetic tabular data from real data, for example via deep learning.  We demonstrate a novel EM-based clustering algorithm, MMM (``Madras Mixture Model''), that outperforms standard algorithms in determining clusters in synthetic heterogeneous data, and recovers structure in real data. Based on this, we
    
[^19]: Hodge-Compositional 边缘高斯过程

    Hodge-Compositional Edge Gaussian Processes. (arXiv:2310.19450v1 [stat.ML])

    [http://arxiv.org/abs/2310.19450](http://arxiv.org/abs/2310.19450)

    本论文提出了一种新的方法用于对边缘集合上的函数进行建模，该方法基于Hodge分解开发了适用于不同应用场景的无散度和无旋度的高斯过程，并通过组合它们来表示任意边缘函数。实验结果表明这种方法在流动数据推断中具有潜在的实际应用价值。

    

    我们提出了一种基于边缘集合的2-复形结构（类似于图形，其中边缘可形成三角面）的函数建模的有原则的高斯过程（GPs）。这种方法适用于学习网络上的流动类型数据，其中边缘流可以通过离散的散度和旋度来表征。借鉴Hodge分解，我们首先开发了适用于各种应用的无散度和无旋游的边缘GPs。然后将它们组合起来创建Hodge-组合边缘GPs，这些GPs足够表达任何边缘函数。这些GPs便于对边缘函数的不同Hodge分量进行直接和独立的学习，使我们能够在超参数优化过程中捕捉它们的相关性。为了突显它们的实际潜力，我们将它们应用于货币兑换、海洋流动和供水网络中的流动数据推断，并将其与替代模型进行比较。

    We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create \emph{Hodge-compositional edge GPs} that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean flows and water supply networks, comparing them to alternative models.
    
[^20]: 区间值数据和区间值函数数据的序数分类

    Ordinal classification for interval-valued data and interval-valued functional data. (arXiv:2310.19433v1 [stat.ME])

    [http://arxiv.org/abs/2310.19433](http://arxiv.org/abs/2310.19433)

    首次将区间值数据和区间值函数数据作为输入考虑，在序数分类问题中提出了六种分类器，其中一种使用了核引导的序数随机森林方法，并与朴素方法进行了比较。

    

    序数分类的目标是从一组观察到的输入中预测输出的有序标签。区间值数据指的是以区间形式表示的数据。首次将区间值数据和区间值函数数据作为序数分类问题的输入考虑。提出了六种用于区间数据和区间值函数数据的序数分类器。其中三种是参数化的，一种基于序数二元分解，另外两种基于有序逻辑回归。另外三种方法基于区间数据之间的距离和区间数据上的核函数。其中一种方法使用加权$k$最近邻技术进行序数分类。另一种方法考虑了核主成分分析和一个序数分类器。而表现最好的第六种方法使用了基于核的序数随机森林。它们与朴素方法在一个实验中进行了比较。

    The aim of ordinal classification is to predict the ordered labels of the output from a set of observed inputs. Interval-valued data refers to data in the form of intervals. For the first time, interval-valued data and interval-valued functional data are considered as inputs in an ordinal classification problem. Six ordinal classifiers for interval data and interval-valued functional data are proposed. Three of them are parametric, one of them is based on ordinal binary decompositions and the other two are based on ordered logistic regression. The other three methods are based on the use of distances between interval data and kernels on interval data. One of the methods uses the weighted $k$-nearest-neighbor technique for ordinal classification. Another method considers kernel principal component analysis plus an ordinal classifier. And the sixth method, which is the method that performs best, uses a kernel-induced ordinal random forest. They are compared with na\"ive approaches in an 
    
[^21]: 隐式流形高斯过程回归

    Implicit Manifold Gaussian Process Regression. (arXiv:2310.19390v1 [stat.ML])

    [http://arxiv.org/abs/2310.19390](http://arxiv.org/abs/2310.19390)

    本文提出了一种能够从数据中直接推断隐式结构的高斯过程回归技术，能够处理高维数据，并可能改善预测性能和校准。

    

    高斯过程回归因其能够提供良好校准的不确定性估计和处理小型或稀疏数据集的能力而被广泛应用。然而，对于高维数据，它存在一定困难。一种将这种技术扩展到更高维度的可能途径是利用数据实际所处的隐式低维流形，这是流形假设所假定的。先前的工作通常要求显式提供流形结构，即由网格或已知为众所周知的流形之一（如球体）给出。相比之下，在本文中，我们提出了一种能够以完全可微的方式从数据（标记和未标记的）中推断出隐式结构的高斯过程回归技术。对于得到的模型，我们讨论了其在假设流形上收敛于Matérn高斯过程。我们的技术可扩展到数十万个数据点，并且可能改善预测性能和校准。

    Gaussian process regression is widely used because of its ability to provide well-calibrated uncertainty estimates and handle small or sparse datasets. However, it struggles with high-dimensional data. One possible way to scale this technique to higher dimensions is to leverage the implicit low-dimensional manifold upon which the data actually lies, as postulated by the manifold hypothesis. Prior work ordinarily requires the manifold structure to be explicitly provided though, i.e. given by a mesh or be known to be one of the well-known manifolds like the sphere. In contrast, in this paper we propose a Gaussian process regression technique capable of inferring implicit structure directly from data (labeled and unlabeled) in a fully differentiable way. For the resulting model, we discuss its convergence to the Mat\'ern Gaussian process on the assumed manifold. Our technique scales up to hundreds of thousands of data points, and may improve the predictive performance and calibration of t
    
[^22]: 深度实时有效的假设检验

    Deep anytime-valid hypothesis testing. (arXiv:2310.19384v1 [stat.ML])

    [http://arxiv.org/abs/2310.19384](http://arxiv.org/abs/2310.19384)

    本文提出了一个通用框架，用于构建对非参数测试问题进行强大的顺序假设检验。与传统的批量测试相比，该框架可以持续监控在线数据流并有效地聚合反对零假设的证据，同时严格控制I型错误，并根据问题的困难程度调整样本大小要求。

    

    我们提出了一个通用框架，用于构建非参数测试问题的强大的顺序假设检验。这些问题的零假设使用两个已知操作符对数据分布进行抽象定义。这种抽象允许对多个经典任务（如两样本检验、独立性检验和条件独立性检验）以及现代问题（如机器学习模型的对抗性鲁棒性检验）进行统一处理。我们提出的框架相对于经典批量测试具有以下优势：1）它持续监控在线数据流并有效地聚合反对零假设的证据，2）它在不需要多重测试修正的情况下对I型错误有严格控制，3）它将样本大小的要求调整到问题的未知困难程度。我们开发了一种基于机器学习模型的表示能力的原则性方法，以……

    We propose a general framework for constructing powerful, sequential hypothesis tests for a large class of nonparametric testing problems. The null hypothesis for these problems is defined in an abstract form using the action of two known operators on the data distribution. This abstraction allows for a unified treatment of several classical tasks, such as two-sample testing, independence testing, and conditional-independence testing, as well as modern problems, such as testing for adversarial robustness of machine learning (ML) models. Our proposed framework has the following advantages over classical batch tests: 1) it continuously monitors online data streams and efficiently aggregates evidence against the null, 2) it provides tight control over the type I error without the need for multiple testing correction, 3) it adapts the sample size requirement to the unknown hardness of the problem. We develop a principled approach of leveraging the representation capability of ML models wit
    
[^23]: 平衡、失衡和再平衡：从极小极大博弈的角度理解鲁棒过拟合

    Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from a Minimax Game Perspective. (arXiv:2310.19360v1 [cs.LG])

    [http://arxiv.org/abs/2310.19360](http://arxiv.org/abs/2310.19360)

    通过将对抗训练视为极小极大博弈，我们解释了学习率下降后对抗训练存在严重鲁棒过拟合问题的原因，并提出通过调整模型训练者能力或提高攻击强度来缓解这个问题。

    

    对抗训练（AT）已成为提取鲁棒特征的技术典范，然而研究人员最近发现，AT在学习率下降后存在严重的鲁棒过拟合问题。本文通过将对抗训练视为模型训练者和攻击者之间的动态极小极大博弈，解释了这一现象。具体地，我们分析了学习率下降如何破坏了极小极大博弈的平衡，使得模型训练者获得了更强的记忆能力，而这种失衡导致了非鲁棒特征的过拟合现象。通过大量实验证实了这一理解，并从两个博弈参与者的角度提供了鲁棒过拟合的全面观点。这一理解进一步启发我们通过调整模型训练者的能力或提高攻击强度来缓解鲁棒过拟合问题。实验表明，

    Adversarial Training (AT) has become arguably the state-of-the-art algorithm for extracting robust features. However, researchers recently notice that AT suffers from severe robust overfitting problems, particularly after learning rate (LR) decay. In this paper, we explain this phenomenon by viewing adversarial training as a dynamic minimax game between the model trainer and the attacker. Specifically, we analyze how LR decay breaks the balance between the minimax game by empowering the trainer with a stronger memorization ability, and show such imbalance induces robust overfitting as a result of memorizing non-robust features. We validate this understanding with extensive experiments, and provide a holistic view of robust overfitting from the dynamics of both the two game players. This understanding further inspires us to alleviate robust overfitting by rebalancing the two players by either regularizing the trainer's capacity or improving the attack strength. Experiments show that the
    
[^24]: 高效纯探索的双向算法设计

    Dual-Directed Algorithm Design for Efficient Pure Exploration. (arXiv:2310.19319v1 [stat.ML])

    [http://arxiv.org/abs/2310.19319](http://arxiv.org/abs/2310.19319)

    该论文研究了在有限备选方案集合中的纯探索问题。通过使用对偶变量，提出了一种新的算法设计原则，能够避免组合结构的复杂性，实现高效纯探索，从而准确回答查询问题。

    

    我们考虑在有限的备选方案集合中的随机顺序自适应实验的纯探索问题。决策者的目标是通过最小的测量工作以高置信度准确回答与备选方案相关的查询问题。一个典型的查询问题是确定表现最佳的备选方案，这在排名和选择问题以及机器学习文献中称为最佳臂识别问题。我们专注于固定精度的设定，并导出了一个与样本最优分配有强收敛性概念相关的优化条件的充分条件。使用对偶变量，我们刻画了一个分配是否最优的必要和充分条件。对偶变量的使用使我们能够绕过完全依赖于原始变量的最优条件的组合结构。值得注意的是，这些最优条件使得双向算法设计原则的扩展成为可能。

    We consider pure-exploration problems in the context of stochastic sequential adaptive experiments with a finite set of alternative options. The goal of the decision-maker is to accurately answer a query question regarding the alternatives with high confidence with minimal measurement efforts. A typical query question is to identify the alternative with the best performance, leading to ranking and selection problems, or best-arm identification in the machine learning literature. We focus on the fixed-precision setting and derive a sufficient condition for optimality in terms of a notion of strong convergence to the optimal allocation of samples. Using dual variables, we characterize the necessary and sufficient conditions for an allocation to be optimal. The use of dual variables allow us to bypass the combinatorial structure of the optimality conditions that relies solely on primal variables. Remarkably, these optimality conditions enable an extension of top-two algorithm design princ
    
[^25]: 针对动态治疗的阶段感知学习

    Stage-Aware Learning for Dynamic Treatments. (arXiv:2310.19300v1 [stat.ML])

    [http://arxiv.org/abs/2310.19300](http://arxiv.org/abs/2310.19300)

    本论文提出了一种针对动态治疗的阶段感知学习方法，该方法通过估计DTR并优先考虑治疗轨迹与最佳治疗方案在决策阶段上的一致性，在提高样本效率和稳定性方面取得了重要进展。

    

    最近对动态治疗方案（DTRs）的研究取得了重要进展，提出了强大的优化治疗搜索算法，根据个体具体需求量身定制，并能最大化其预期的临床效益。然而，现有算法在优化治疗下可能会受到样本量不足的困扰，尤其是在涉及长时间决策阶段的慢性疾病中。为了解决这些挑战，我们提出了一种新颖的个体化学习方法，重点是估计DTR，并优先考虑观察到的治疗轨迹与最佳治疗方案在决策阶段上的一致性。通过放宽观察到的轨迹必须完全与最佳治疗一致的限制，我们的方法大大提高了基于倒数概率加权方法的样本效率和稳定性。具体而言，所提出的学习方案构建了一个更通用的框架，包括了流行的结果加权学习框架。

    Recent advances in dynamic treatment regimes (DTRs) provide powerful optimal treatment searching algorithms, which are tailored to individuals' specific needs and able to maximize their expected clinical benefits. However, existing algorithms could suffer from insufficient sample size under optimal treatments, especially for chronic diseases involving long stages of decision-making. To address these challenges, we propose a novel individualized learning method which estimates the DTR with a focus on prioritizing alignment between the observed treatment trajectory and the one obtained by the optimal regime across decision stages. By relaxing the restriction that the observed trajectory must be fully aligned with the optimal treatments, our approach substantially improves the sample efficiency and stability of inverse probability weighted based methods. In particular, the proposed learning scheme builds a more general framework which includes the popular outcome weighted learning framewo
    
[^26]: The Memory Perturbation Equation: Understanding Model's Sensitivity to Data（理解模型对数据的敏感性的记忆扰动方程）

    The Memory Perturbation Equation: Understanding Model's Sensitivity to Data. (arXiv:2310.19273v1 [cs.LG])

    [http://arxiv.org/abs/2310.19273](http://arxiv.org/abs/2310.19273)

    这个论文介绍了记忆扰动方程（MPE），该方程通过应用贝叶斯原理将模型的敏感性与训练数据的扰动联系起来，并且能够准确预测模型在未见测试数据上的泛化能力。

    

    理解模型对其训练数据的敏感性对于训练过程至关重要，但也可能具有挑战性和成本高昂。为了简化这类问题，我们提出了记忆扰动方程（MPE），它将模型的敏感性与其训练数据的扰动联系起来。使用贝叶斯原理导出的MPE将现有的敏感性度量统一起来，泛化到各种模型和算法，并揭示了有关敏感性的有用性质。我们的实证结果表明，训练过程中获得的敏感性估计可以准确预测在未见测试数据上的泛化能力。该提出的方程预计将对未来的鲁棒和自适应学习研究有用。

    Understanding model's sensitivity to its training data is crucial but can also be challenging and costly, especially during training. To simplify such issues, we present the Memory-Perturbation Equation (MPE) which relates model's sensitivity to perturbation in its training data. Derived using Bayesian principles, the MPE unifies existing sensitivity measures, generalizes them to a wide-variety of models and algorithms, and unravels useful properties regarding sensitivities. Our empirical results show that sensitivity estimates obtained during training can be used to faithfully predict generalization on unseen test data. The proposed equation is expected to be useful for future research on robust and adaptive learning.
    
[^27]: 在黎曼对称空间上的不变核：一种谐波分析方法

    Invariant kernels on Riemannian symmetric spaces: a harmonic-analytic approach. (arXiv:2310.19270v1 [cs.LG])

    [http://arxiv.org/abs/2310.19270](http://arxiv.org/abs/2310.19270)

    本文证明了在非欧几里德对称空间上定义的经典高斯核在任意参数选择下都不是正定的，通过发展新的几何和分析论证，并且给出了正定性的严格刻画以及L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement定理的必要和充分条件。

    

    本文旨在证明经典的高斯核，在非欧几里德对称空间上定义时，对于任意参数选择都不是正定的。为了实现这一目标，本文发展了新的几何和分析论证。这些论证提供了高斯核正定性的严格刻画，但仅限于在低维中通过数值计算处理的有限情况。其中最重要的结果是L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement定理（其中$p = 1,2$），它提供了定义在非紧型对称空间上的核是正定的可验证的必要和充分条件。一种著名的定理，有时被称为Bochner-Godement定理，已经给出了这样的条件，并且在适用范围上更加广泛，但应用起来尤为困难。除了与高斯核的关联外，在本文中的新结果为s提供了一个蓝图。

    This work aims to prove that the classical Gaussian kernel, when defined on a non-Euclidean symmetric space, is never positive-definite for any choice of parameter. To achieve this goal, the paper develops new geometric and analytical arguments. These provide a rigorous characterization of the positive-definiteness of the Gaussian kernel, which is complete but for a limited number of scenarios in low dimensions that are treated by numerical computations. Chief among these results are the L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement theorems (where $p = 1,2$), which provide verifiable necessary and sufficient conditions for a kernel defined on a symmetric space of non-compact type to be positive-definite. A celebrated theorem, sometimes called the Bochner-Godement theorem, already gives such conditions and is far more general in its scope, but is especially hard to apply. Beyond the connection with the Gaussian kernel, the new results in this work lay out a blueprint for the s
    
[^28]: 基于流的分布鲁棒优化

    Flow-based Distributionally Robust Optimization. (arXiv:2310.19253v1 [cs.LG])

    [http://arxiv.org/abs/2310.19253](http://arxiv.org/abs/2310.19253)

    这项研究提出了一种称为FlowDRO的计算高效框架，用于解决基于流的分布鲁棒优化问题，通过使用流模型和Wasserstein近端梯度流类型的算法，实现了对具有更大样本大小的问题的可扩展性和更好的泛化能力。

    

    我们提出了一种称为FlowDRO的计算高效框架，用于解决基于流的分布鲁棒优化（DRO）问题，其中要求最坏情况分布（也称为最不利分布，LFD）是连续的，从而使得算法能够可扩展到具有更大样本大小的问题，并实现对诱导的鲁棒算法的更好泛化能力。为了解决计算上具有挑战性的无限维优化问题，我们利用基于流的模型，在数据分布和目标分布之间进行连续时间可逆传输映射，并开发了一种Wasserstein近端梯度流类型的算法。在实践中，我们通过梯度下降逐步训练块内的神经网络序列来参数化传输映射。我们的计算框架通用，能够处理高维数据和大样本大小，并可用于各种应用。

    We present a computationally efficient framework, called \texttt{FlowDRO}, for solving flow-based distributionally robust optimization (DRO) problems with Wasserstein uncertainty sets, when requiring the worst-case distribution (also called the Least Favorable Distribution, LFD) to be continuous so that the algorithm can be scalable to problems with larger sample sizes and achieve better generalization capability for the induced robust algorithms. To tackle the computationally challenging infinitely dimensional optimization problem, we leverage flow-based models, continuous-time invertible transport maps between the data distribution and the target distribution, and develop a Wasserstein proximal gradient flow type of algorithm. In practice, we parameterize the transport maps by a sequence of neural networks progressively trained in blocks by gradient descent. Our computational framework is general, can handle high-dimensional data with large sample sizes, and can be useful for various
    
[^29]: 用于单通道应用的潜变量模型的谱正则化框架

    A spectral regularisation framework for latent variable models designed for single channel applications. (arXiv:2310.19246v1 [stat.ML])

    [http://arxiv.org/abs/2310.19246](http://arxiv.org/abs/2310.19246)

    这个论文提出了一个用于单通道应用的潜变量模型的谱正则化框架，解决了源复制问题，并提供了一个一致的线性LVM优化框架。

    

    潜变量模型（LVMs）常用于捕捉观测数据中的潜在依赖关系、模式和隐藏结构。数据hankel化的预处理步骤导致源复制，这是单通道LVM应用中的一个副产品，阻碍了实际的LVM利用。本文介绍了一个名为spectrally-regularised-LVMs的Python包。该包通过引入一项新的谱正则化项来解决源复制问题。该包提供了一个用于单通道LVM应用的谱正则化框架，从而更容易地研究和利用带有谱正则化的LVMs。这通过将潜变量模型目标函数的符号或显式表示纳入到一个框架中，在LVM参数估计过程中使用谱正则化来实现。该包的目标是提供一种一致的线性LVM优化框架。

    Latent variable models (LVMs) are commonly used to capture the underlying dependencies, patterns, and hidden structure in observed data. Source duplication is a by-product of the data hankelisation pre-processing step common to single channel LVM applications, which hinders practical LVM utilisation. In this article, a Python package titled spectrally-regularised-LVMs is presented. The proposed package addresses the source duplication issue via the addition of a novel spectral regularisation term. This package provides a framework for spectral regularisation in single channel LVM applications, thereby making it easier to investigate and utilise LVMs with spectral regularisation. This is achieved via the use of symbolic or explicit representations of potential LVM objective functions which are incorporated into a framework that uses spectral regularisation during the LVM parameter estimation process. The objective of this package is to provide a consistent linear LVM optimisation framew
    
[^30]: 在多级低秩矩阵中进行因子拟合、秩分配和分割

    Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank Matrices. (arXiv:2310.19214v1 [stat.ML])

    [http://arxiv.org/abs/2310.19214](http://arxiv.org/abs/2310.19214)

    本文研究了多级低秩矩阵中的因子拟合、秩分配和分割问题，提出了相应的解决方法，并开发了一个开源软件包。

    

    我们考虑多级低秩（MLR）矩阵，定义为一系列矩阵的行和列的排列，每个矩阵都是前一个矩阵的块对角修正，所有块以因子形式给出低秩矩阵。MLR矩阵扩展了低秩矩阵的概念，但它们共享许多特性，例如所需总存储空间和矩阵向量乘法的复杂度。我们解决了用Frobenius范数拟合给定矩阵到MLR矩阵的三个问题。第一个问题是因子拟合，通过调整MLR矩阵的因子来解决。第二个问题是秩分配，在每个级别中选择块的秩，满足总秩的给定值，以保持MLR矩阵所需的总存储空间。最后一个问题是选择行和列的层次分割，以及秩和因子。本文附带了一个开源软件包，实现了所提出的方法。

    We consider multilevel low rank (MLR) matrices, defined as a row and column permutation of a sum of matrices, each one a block diagonal refinement of the previous one, with all blocks low rank given in factored form. MLR matrices extend low rank matrices but share many of their properties, such as the total storage required and complexity of matrix-vector multiplication. We address three problems that arise in fitting a given matrix by an MLR matrix in the Frobenius norm. The first problem is factor fitting, where we adjust the factors of the MLR matrix. The second is rank allocation, where we choose the ranks of the blocks in each level, subject to the total rank having a given value, which preserves the total storage needed for the MLR matrix. The final problem is to choose the hierarchical partition of rows and columns, along with the ranks and factors. This paper is accompanied by an open source package that implements the proposed methods.
    
[^31]: 网格细胞中的循环神经网络中的共形归一化

    Conformal Normalization in Recurrent Neural Network of Grid Cells. (arXiv:2310.19192v1 [q-bio.NC])

    [http://arxiv.org/abs/2310.19192](http://arxiv.org/abs/2310.19192)

    本文提出了一种循环神经网络中的共形归一化方法，用于处理网格细胞在2D物理空间中的自我位置信息。实验结果表明，该方法能够显著减小位置误差。

    

    哺乳动物大脑中颞叶皮层的网格细胞在2D开放环境中以惊人的六角形发射模式展示出反应图。网格细胞群体的反应在高维神经活动空间中形成一个向量，这个向量表示代理在2D物理空间中的自我位置。当代理移动时，这个向量被一个循环神经网络转换，该网络将代理的速度作为输入。本文中，我们提出了对循环神经网络输入速度进行简单而通用的共形归一化，使得高维神经空间中位置向量的局部位移与2D物理空间中代理的局部位移成比例，无论输入速度的方向如何。我们在最简单的线性和非线性循环网络上进行了数值实验，结果显示共形归一化导致数量级较小的位置误差。

    Grid cells in the entorhinal cortex of the mammalian brain exhibit striking hexagon firing patterns in their response maps as the animal (e.g., a rat) navigates in a 2D open environment. The responses of the population of grid cells collectively form a vector in a high-dimensional neural activity space, and this vector represents the self-position of the agent in the 2D physical space. As the agent moves, the vector is transformed by a recurrent neural network that takes the velocity of the agent as input. In this paper, we propose a simple and general conformal normalization of the input velocity for the recurrent neural network, so that the local displacement of the position vector in the high-dimensional neural space is proportional to the local displacement of the agent in the 2D physical space, regardless of the direction of the input velocity. Our numerical experiments on the minimally simple linear and non-linear recurrent networks show that conformal normalization leads to the 
    
[^32]: 通过标准化流进行罕见事件概率学习

    Rare Event Probability Learning by Normalizing Flows. (arXiv:2310.19167v1 [cs.LG])

    [http://arxiv.org/abs/2310.19167](http://arxiv.org/abs/2310.19167)

    通过标准化流辅助重要抽样（NOFIS）的方法，准确估计罕见事件的概率，通过学习一系列提议分布和重要抽样来实现，在多个定性和定量实验中得到了验证。

    

    罕见事件被定义为发生概率较低。准确估计这种小概率在各个领域中至关重要。传统的蒙特卡洛方法效率低下，需要大量样本才能得到可靠的估计。受标准化流的精确采样能力的启发，我们重新思考了这个挑战，并提出了标准化流辅助重要抽样（NOFIS）方法。NOFIS首先通过最小化KL散度损失来学习与预定义的嵌套子集事件相关的一系列提议分布。然后，它利用重要抽样和最后一个提议分布来估计罕见事件的概率。通过全面的定性可视化验证了我们NOFIS方法的有效性，证实了学习提议分布的最优性，以及一系列包括10个不同测试案例的定量实验证明了NOFIS在基准方法上的优越性。

    A rare event is defined by a low probability of occurrence. Accurate estimation of such small probabilities is of utmost importance across diverse domains. Conventional Monte Carlo methods are inefficient, demanding an exorbitant number of samples to achieve reliable estimates. Inspired by the exact sampling capabilities of normalizing flows, we revisit this challenge and propose normalizing flow assisted importance sampling, termed NOFIS. NOFIS first learns a sequence of proposal distributions associated with predefined nested subset events by minimizing KL divergence losses. Next, it estimates the rare event probability by utilizing importance sampling in conjunction with the last proposal. The efficacy of our NOFIS method is substantiated through comprehensive qualitative visualizations, affirming the optimality of the learned proposal distribution, as well as a series of quantitative experiments encompassing $10$ distinct test cases, which highlight NOFIS's superiority over baselin
    
[^33]: 相互作用独立级联过程中的后向和前向推理：一种可扩展和收敛的消息传递方法

    Backward and Forward Inference in Interacting Independent-Cascade Processes: A Scalable and Convergent Message-Passing Approach. (arXiv:2310.19138v1 [cs.SI])

    [http://arxiv.org/abs/2310.19138](http://arxiv.org/abs/2310.19138)

    该研究针对在网络中同时传播的两个扩散过程的过去和未来演变估计问题，提出了一种可扩展和收敛的消息传递方法，解决了后向推理和前向推理的问题。

    

    我们研究了在网络上同时传播的两个扩散过程的过去和未来演变估计问题。具体而言，给定一个已知的网络$ G =（V，\overrightarrow {E}）$和（可能是嘈杂的）在（可能未知的）时间$ W $拍摄的其状态的快照$ \mathcal {O} _n $，我们希望确定网络的初始状态和其节点的感染时间的后验分布。这些分布在查找流行病和谣言的源节点以及估计固定源节点的传播方面非常有用。为了建模两个过程之间的相互作用，我们研究了独立级联（IC）模型的扩展，其中当一个节点被其中一个过程感染时，其对另一个过程的易感性发生变化。首先，我们导出了网络初始状态和观察快照$ \mathcal {O} _n $的准确联合概率。然后，通过fact的机制投入到...（文献没有给出后续部分）

    We study the problems of estimating the past and future evolutions of two diffusion processes that spread concurrently on a network. Specifically, given a known network $G=(V, \overrightarrow{E})$ and a (possibly noisy) snapshot $\mathcal{O}_n$ of its state taken at (a possibly unknown) time $W$, we wish to determine the posterior distributions of the initial state of the network and the infection times of its nodes. These distributions are useful in finding source nodes of epidemics and rumors -- $\textit{backward inference}$ -- , and estimating the spread of a fixed set of source nodes -- $\textit{forward inference}$.  To model the interaction between the two processes, we study an extension of the independent-cascade (IC) model where, when a node gets infected with either process, its susceptibility to the other one changes. First, we derive the exact joint probability of the initial state of the network and the observation-snapshot $\mathcal{O}_n$. Then, using the machinery of fact
    
[^34]: 小样本分类问题的规范最优近似学习

    Gauge-optimal approximate learning for small data classification problems. (arXiv:2310.19066v1 [cs.LG])

    [http://arxiv.org/abs/2310.19066](http://arxiv.org/abs/2310.19066)

    我们提出了一种规范最优近似学习（GOAL）算法，用于解决小样本学习问题。该算法通过减少和旋转特征空间，提供了一个可分析的联合解决方案，其中最优解是欧几里得空间中的分段线性函数。

    

    小样本学习问题的特点是有限的响应变量观测和庞大的特征空间维度之间存在显著的差异。在这种情况下，常见的学习工具难以确定对分类任务重要的特征和不相关信息的特征，并且无法推导出适当的学习规则来区分不同的类别。作为解决这个问题的潜在方法，我们利用减少和旋转特征空间的思想，在一个低维度规范中提出了规范最优近似学习（GOAL）算法，为小样本学习问题的维度缩减、特征分割和分类问题提供了一个可分析的联合解决方案。我们证明，GOAL算法的最优解是欧几里得空间中的分段线性函数，并且可以通过单调收敛逼近。

    Small data learning problems are characterized by a significant discrepancy between the limited amount of response variable observations and the large feature space dimension. In this setting, the common learning tools struggle to identify the features important for the classification task from those that bear no relevant information, and cannot derive an appropriate learning rule which allows to discriminate between different classes. As a potential solution to this problem, here we exploit the idea of reducing and rotating the feature space in a lower-dimensional gauge and propose the Gauge-Optimal Approximate Learning (GOAL) algorithm, which provides an analytically tractable joint solution to the dimension reduction, feature segmentation and classification problems for small data learning problems. We prove that the optimal solution of the GOAL algorithm consists in piecewise-linear functions in the Euclidean space, and that it can be approximated through a monotonically convergent
    
[^35]: 重新审视苹果品尝的可学习性

    Revisiting the Learnability of Apple Tasting. (arXiv:2310.19064v1 [cs.LG])

    [http://arxiv.org/abs/2310.19064](http://arxiv.org/abs/2310.19064)

    该论文重新审视了苹果品尝的可学习性，从组合角度研究了在线可学习性。作者通过引入Effective width参数，紧密量化了在可实现设置中的极小期望错误，并在可实现设置中建立了极小期望错误数量的三分法。

    

    在在线二元分类中，学习者只有在预测为"1"时观察到真实标签。本文重新研究了这种经典的部分反馈设置，并从组合角度研究了在线可学习性。我们证明了在不可知设置下，Littlestone维度仍然是苹果品尝的紧密定量刻画，解决了\cite{helmbold2000apple}提出的一个悬而未决的问题。此外，我们给出了一个新的组合参数，称为有效宽度，紧密量化了在可实现设置中的极小期望错误。作为推论，我们使用有效宽度在可实现设置中建立了极小期望错误数量的三分法。特别地，我们证明了在可实现设置中，任何学习者在苹果品尝反馈下的期望错误数量只能是$\Theta(1), \Theta(\sqrt{T})$, 或 $\Theta(T)$。

    In online binary classification under \textit{apple tasting} feedback, the learner only observes the true label if it predicts "1". First studied by \cite{helmbold2000apple}, we revisit this classical partial-feedback setting and study online learnability from a combinatorial perspective. We show that the Littlestone dimension continues to prove a tight quantitative characterization of apple tasting in the agnostic setting, closing an open question posed by \cite{helmbold2000apple}. In addition, we give a new combinatorial parameter, called the Effective width, that tightly quantifies the minimax expected mistakes in the realizable setting. As a corollary, we use the Effective width to establish a \textit{trichotomy} of the minimax expected number of mistakes in the realizable setting. In particular, we show that in the realizable setting, the expected number of mistakes for any learner under apple tasting feedback can only be $\Theta(1), \Theta(\sqrt{T})$, or $\Theta(T)$.
    
[^36]: 纳米光子结构和参数设计模拟的数据集和基准

    Datasets and Benchmarks for Nanophotonic Structure and Parametric Design Simulations. (arXiv:2310.19053v1 [cs.LG])

    [http://arxiv.org/abs/2310.19053](http://arxiv.org/abs/2310.19053)

    本研究提出了一种评估纳米光子结构的框架和基准，用于解决参数结构设计问题，并探究了电动力学模拟中网格大小的变化对结果的影响。

    

    纳米光子结构具有广泛的应用，包括太阳能电池、防反射涂层、电磁干扰屏蔽、光学滤波器和发光二极管。为了设计和理解这些纳米光子结构，电动力学模拟是必不可少的。这些模拟使我们能够模拟随时间变化的电磁场并计算光学性质。在这项工作中，我们介绍了用于评估纳米光子结构的框架和基准，以解决参数结构设计问题。这些基准在评估优化算法性能和基于目标光学性质确定最佳结构方面起着重要作用。此外，我们还探讨了电动力学模拟中网格大小的变化对结果的影响，揭示了如何在增强结构设计方面巧妙地利用评估精度。

    Nanophotonic structures have versatile applications including solar cells, anti-reflective coatings, electromagnetic interference shielding, optical filters, and light emitting diodes. To design and understand these nanophotonic structures, electrodynamic simulations are essential. These simulations enable us to model electromagnetic fields over time and calculate optical properties. In this work, we introduce frameworks and benchmarks to evaluate nanophotonic structures in the context of parametric structure design problems. The benchmarks are instrumental in assessing the performance of optimization algorithms and identifying an optimal structure based on target optical properties. Moreover, we explore the impact of varying grid sizes in electrodynamic simulations, shedding light on how evaluation fidelity can be strategically leveraged in enhancing structure designs.
    
[^37]: 差分隐私排列检验：应用于核方法

    Differentially Private Permutation Tests: Applications to Kernel Methods. (arXiv:2310.19043v1 [math.ST])

    [http://arxiv.org/abs/2310.19043](http://arxiv.org/abs/2310.19043)

    本文提出了差分隐私排列检验的框架，扩展了经典的非私有排列检验，以在私有环境中保持有限样本有效性和差分隐私性质。该检验的功率取决于检验统计量的选择，并建立了一般条件来保证一致性和非渐进均匀的功率。

    

    近年来，人们对敏感数据的隐私问题越来越关注。为了应对这些问题，差分隐私作为一种严格的隐私保护框架应运而生，在学术界和工业界广泛认可。尽管在私有数据分析方面取得了相当大的进展，但现有的方法往往存在不实用或明显的统计效率损失。本文旨在通过引入差分隐私排列检验来缓解这些担忧。所提出的框架将经典的非私有排列检验扩展到私有环境中，以严格的方式保持有限样本有效性和差分隐私性质。所提出的检验的功率取决于一个检验统计量的选择，并建立了一般条件保证了一致性和非渐进均匀的功率。为了证明我们框架的实用性和可行性，我们重点关注重现核方法。

    Recent years have witnessed growing concerns about the privacy of sensitive data. In response to these concerns, differential privacy has emerged as a rigorous framework for privacy protection, gaining widespread recognition in both academic and industrial circles. While substantial progress has been made in private data analysis, existing methods often suffer from impracticality or a significant loss of statistical efficiency. This paper aims to alleviate these concerns in the context of hypothesis testing by introducing differentially private permutation tests. The proposed framework extends classical non-private permutation tests to private settings, maintaining both finite-sample validity and differential privacy in a rigorous manner. The power of the proposed test depends on the choice of a test statistic, and we establish general conditions for consistency and non-asymptotic uniform power. To demonstrate the utility and practicality of our framework, we focus on reproducing kerne
    
[^38]: 自监督表示学习的线性分离能力研究

    On Linear Separation Capacity of Self-Supervised Representation Learning. (arXiv:2310.19041v1 [stat.ML])

    [http://arxiv.org/abs/2310.19041](http://arxiv.org/abs/2310.19041)

    本研究通过探究在多流形模型下，学习的表示何时可以线性分离流形，揭示了自监督学习在数据增强方面的额外好处，从而改善了线性分离能力的信息论最优速率。

    

    自监督学习的最新进展强调了数据增强在从无标签数据中学习数据表示中的有效性。在这些增强表示之上训练线性模型可以得到一个熟练的分类器。尽管在实践中表现出色，但是数据增强如何将非线性数据结构解开为线性可分离表示的机制仍然不清楚。本文旨在通过研究在从多流形模型中绘制数据时，学习到的表示在何种条件下可以线性分离流形来填补这一差距。我们的研究揭示了数据增强除了提供观察数据外，还提供了额外的信息，从而可以改善线性分离容量的信息论最优速率。特别是，我们证明自监督学习可以以比无监督学习更小的距离线性分离流形，突显了数据增强的额外好处。

    Recent advances in self-supervised learning have highlighted the efficacy of data augmentation in learning data representation from unlabeled data. Training a linear model atop these enhanced representations can yield an adept classifier. Despite the remarkable empirical performance, the underlying mechanisms that enable data augmentation to unravel nonlinear data structures into linearly separable representations remain elusive. This paper seeks to bridge this gap by investigating under what conditions learned representations can linearly separate manifolds when data is drawn from a multi-manifold model. Our investigation reveals that data augmentation offers additional information beyond observed data and can thus improve the information-theoretic optimal rate of linear separation capacity. In particular, we show that self-supervised learning can linearly separate manifolds with a smaller distance than unsupervised learning, underscoring the additional benefits of data augmentation. 
    
[^39]: 使用环境增强的不变图学习能够学习到不变性吗？

    Does Invariant Graph Learning via Environment Augmentation Learn Invariance?. (arXiv:2310.19035v1 [cs.LG])

    [http://arxiv.org/abs/2310.19035](http://arxiv.org/abs/2310.19035)

    环境增强无法根本性地学习到不变的图表示，因此我们提出了一组最小的假设，用于可行的不变图学习。我们还提出了一个新的框架GALA，该框架包含一个敏感于图环境变化的助理模型，通过代理预测准确性来区分变异。

    

    不变图表示学习旨在学习不同环境下数据的不变性，以实现对图的超出分布的泛化。由于图环境划分通常很昂贵，增强环境信息已成为事实上的方法。然而，增强的环境信息的有效性还没有被验证过。在这项工作中，我们发现在没有额外假设的情况下，通过环境增强无法根本性地学习到不变的图表示。因此，我们提出了一组最小的假设，包括变化充分性和变化一致性，用于可行的不变图学习。然后，我们提出了一个新的框架 Graph invAriant LearningAssistant (GALA)。GALA包含一个助理模型，需要对图环境的变化或分布的变化敏感。因此，助理模型的代理预测的准确性可以区分变异。

    Invariant graph representation learning aims to learn the invariance among data from different environments for out-of-distribution generalization on graphs. As the graph environment partitions are usually expensive to obtain, augmenting the environment information has become the de facto approach. However, the usefulness of the augmented environment information has never been verified. In this work, we find that it is fundamentally impossible to learn invariant graph representations via environment augmentation without additional assumptions. Therefore, we develop a set of minimal assumptions, including variation sufficiency and variation consistency, for feasible invariant graph learning. We then propose a new framework Graph invAriant Learning Assistant (GALA). GALA incorporates an assistant model that needs to be sensitive to graph environment changes or distribution shifts. The correctness of the proxy predictions by the assistant model hence can differentiate the variations in sp
    
[^40]: 《一种改进的面向Oracle高效的对抗性上下文赌博问题的放松方法》

    An Improved Relaxation for Oracle-Efficient Adversarial Contextual Bandits. (arXiv:2310.19025v1 [cs.LG])

    [http://arxiv.org/abs/2310.19025](http://arxiv.org/abs/2310.19025)

    该论文提出了一种用于对抗性上下文赌博问题的面向Oracle高效的放松方法，通过调用离线优化Oracle来降低遗憾界限，并且在界限方面取得了显著的改进，达到了先前最佳界限，并与原始界限相匹配。

    

    我们提出了一种面向Oracle高效的放松方法，用于处理对抗性上下文赌博问题，其中上下文是从已知分布中顺序独立抽取的，而成本序列则由在线对手选择。我们的算法具有一个$O(T^{\frac{2}{3}}(K\log(|\Pi|))^{\frac{1}{3}})$的遗憾界限，并且每轮最多调用$O(K)$次离线优化Oracle，其中$K$表示动作的数量，$T$表示轮数，$\Pi$表示策略集。这是第一个改进Syrgkanis等人在NeurIPS 2016中获得的$O((TK)^{\frac{2}{3}}(\log(|\Pi|))^{\frac{1}{3}})$界限的结果，并且也是与Langford和Zhang在NeurIPS 2007中为随机情况提出的原始界限相匹配的结果。

    We present an oracle-efficient relaxation for the adversarial contextual bandits problem, where the contexts are sequentially drawn i.i.d from a known distribution and the cost sequence is chosen by an online adversary. Our algorithm has a regret bound of $O(T^{\frac{2}{3}}(K\log(|\Pi|))^{\frac{1}{3}})$ and makes at most $O(K)$ calls per round to an offline optimization oracle, where $K$ denotes the number of actions, $T$ denotes the number of rounds and $\Pi$ denotes the set of policies. This is the first result to improve the prior best bound of $O((TK)^{\frac{2}{3}}(\log(|\Pi|))^{\frac{1}{3}})$ as obtained by Syrgkanis et al. at NeurIPS 2016, and the first to match the original bound of Langford and Zhang at NeurIPS 2007 which was obtained for the stochastic case.
    
[^41]: 对统计学习中参数计数的重新思考：对双下降的转变

    A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning. (arXiv:2310.18988v1 [stat.ML])

    [http://arxiv.org/abs/2310.18988](http://arxiv.org/abs/2310.18988)

    本研究重新思考了统计学习中参数计数的理论，挑战了双下降现象扩展传统复杂度-泛类关系界限的观点。

    

    传统的统计学智慧确立了模型复杂度和预测误差之间的关系，通常以一个U形曲线来表示，反映了欠拟合和过拟合之间的转变。然而，受到过参数化神经网络的成功的启发，最近有一些有影响力的工作认为这个理论通常是不完整的，并引入了一个额外的区域，即在参数个数p超过样本大小n时，测试误差会出现第二次下降的现象，被称为双下降。虽然大部分关注自然而然地集中在深度学习的设置上，但双下降现象已经在非神经网络模型中更一般地出现，已知的案例包括线性回归、树和Boosting。在这项工作中，我们对围绕这些更经典的统计机器学习方法的证据进行了更详细的分析，并质疑了双下降现象扩展了传统U形复杂度-泛类关系的界限的说法。

    Conventional statistical wisdom established a well-understood relationship between model complexity and prediction error, typically presented as a U-shaped curve reflecting a transition between under- and overfitting regimes. However, motivated by the success of overparametrized neural networks, recent influential work has suggested this theory to be generally incomplete, introducing an additional regime that exhibits a second descent in test error as the parameter count p grows past sample size n - a phenomenon dubbed double descent. While most attention has naturally been given to the deep-learning setting, double descent was shown to emerge more generally across non-neural models: known cases include linear regression, trees, and boosting. In this work, we take a closer look at evidence surrounding these more classical statistical machine learning methods and challenge the claim that observed cases of double descent truly extend the limits of a traditional U-shaped complexity-genera
    
[^42]: 对于几乎正交数据的两层ReLU和Leaky ReLU网络，梯度下降的隐式偏差

    Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU Networks on Nearly-orthogonal Data. (arXiv:2310.18935v1 [cs.LG])

    [http://arxiv.org/abs/2310.18935](http://arxiv.org/abs/2310.18935)

    本文研究了两层ReLU和Leaky ReLU网络在几乎正交数据上梯度下降的隐式偏差。对于Leaky ReLU激活函数，梯度下降能找到收敛到1的稳定秩网络；对于ReLU激活函数，梯度下降能找到稳定秩上界为常数的神经网络。

    

    由于其对有利特性解的隐式偏好，基于梯度优化训练的神经网络能够很好地泛化。虽然梯度流的隐式偏差已经被广泛研究了均匀神经网络（包括ReLU和Leaky ReLU网络），但对于梯度下降的隐式偏差目前只了解了平滑神经网络。因此，对于通过梯度下降训练的非平滑神经网络的隐式偏差仍然是一个开放问题。本文通过研究梯度下降在训练两层全连接(Leaky) ReLU神经网络时的隐式偏差来回答这个问题。我们证明了当训练数据几乎正交时，对于Leaky ReLU激活函数，梯度下降将找到一个收敛到1的稳定秩网络，而对于ReLU激活函数，梯度下降将找到一个稳定秩上界为常数的神经网络。

    The implicit bias towards solutions with favorable properties is believed to be a key reason why neural networks trained by gradient-based optimization can generalize well. While the implicit bias of gradient flow has been widely studied for homogeneous neural networks (including ReLU and leaky ReLU networks), the implicit bias of gradient descent is currently only understood for smooth neural networks. Therefore, implicit bias in non-smooth neural networks trained by gradient descent remains an open question. In this paper, we aim to answer this question by studying the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks. We showed that when the training data are nearly-orthogonal, for leaky ReLU activation function, gradient descent will find a network with a stable rank that converges to $1$, whereas for ReLU activation function, gradient descent will find a neural network with a stable rank that is upper bounded by a constant. Addit
    
[^43]: 延迟反馈的线性函数逼近强化学习中的后验采样

    Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximation. (arXiv:2310.18919v1 [cs.LG])

    [http://arxiv.org/abs/2310.18919](http://arxiv.org/abs/2310.18919)

    本研究解决了强化学习中延迟反馈对线性函数逼近的挑战，通过后验采样算法实现了在不同情况下的优越性能。

    

    运用函数逼近在强化学习中取得了显著进展，但现有的高效算法通常依赖于即时反馈。本文通过采用后验采样来解决延迟反馈对强化学习中线性函数逼近的挑战，首先介绍了Delayed-PSVI算法，通过后验采样中的噪声扰动有效地探索价值函数空间。我们提供了延迟反馈强化学习中后验采样算法的首次分析，并展示了我们的算法在一系列情况下的优越性。

    Recent studies in reinforcement learning (RL) have made significant progress by leveraging function approximation to alleviate the sample complexity hurdle for better performance. Despite the success, existing provably efficient algorithms typically rely on the accessibility of immediate feedback upon taking actions. The failure to account for the impact of delay in observations can significantly degrade the performance of real-world systems due to the regret blow-up. In this work, we tackle the challenge of delayed feedback in RL with linear function approximation by employing posterior sampling, which has been shown to empirically outperform the popular UCB algorithms in a wide range of regimes. We first introduce Delayed-PSVI, an optimistic value-based algorithm that effectively explores the value function space via noise perturbation with posterior sampling. We provide the first analysis for posterior sampling algorithms with delayed feedback in RL and show our algorithm achieves $
    
[^44]: 通过模型适应来去除偏见算法

    Debiasing Algorithm through Model Adaptation. (arXiv:2310.18913v1 [cs.CL])

    [http://arxiv.org/abs/2310.18913](http://arxiv.org/abs/2310.18913)

    本论文提出了一种通过模型适应来检测和减轻语言模型中性别偏见的方法，并证明了该方法能够显著减少偏见同时保持模型性能。

    

    大型语言模型正在成为各种语言任务的首选解决方案。然而，随着容量的增长，模型很容易依赖训练数据中存在的偏见和刻板印象所产生的虚假相关性。本研究提出了一种新颖的方法来检测和减轻语言模型中的性别偏见。我们进行因果分析，以识别问题模型组件，并发现中上层前馈层最容易传递偏见。根据分析结果，我们通过线性投影将这些层乘以模型进行适应。我们的方法DAMA通过各种度量指标明显减少了偏见，同时保持模型在后续任务中的性能。我们发布了我们的方法和模型的代码，通过重新训练，保持了LLaMA的最先进性能，同时偏见显著减少。

    Large language models are becoming the go-to solution for various language tasks. However, with growing capacity, models are prone to rely on spurious correlations stemming from biases and stereotypes present in the training data. This work proposes a novel method for detecting and mitigating gender bias in language models. We perform causal analysis to identify problematic model components and discover that mid-upper feed-forward layers are most prone to convey biases. Based on the analysis results, we adapt the model by multiplying these layers by a linear projection. Our titular method, DAMA, significantly decreases bias as measured by diverse metrics while maintaining the model's performance on downstream tasks. We release code for our method and models, which retrain LLaMA's state-of-the-art performance while being significantly less biased.
    
[^45]: InstanT: 基于实例相关阈值的半监督学习

    InstanT: Semi-supervised Learning with Instance-dependent Thresholds. (arXiv:2310.18910v1 [cs.LG])

    [http://arxiv.org/abs/2310.18910](http://arxiv.org/abs/2310.18910)

    本文提出了一种半监督学习方法，通过使用实例相关的阈值来选择有信心的未标记实例，并将其纳入训练集中。该方法利用实例级别的模糊度和实例相关的错误率来设计阈值函数，相比现有方法具有更高的自由度。

    

    半监督学习一直是机器学习中的一个基本挑战。伪标记算法是主要的半监督学习算法之一，它涉及将伪标签分配给有信心的未标记实例并将其纳入训练集中。因此，有信心实例的选择标准对半监督学习的成功至关重要。最近，对使用动态或自适应阈值的半监督学习方法的发展越来越感兴趣。然而，这些方法通常将相同的阈值应用于所有样本，或者对属于某个类的实例使用类相关阈值，而忽略实例级别的信息。本文提出了研究实例相关阈值的方法，与现有方法相比具有最高的自由度。具体来说，我们利用实例级别的模糊度和实例相关的错误率，为所有未标记实例设计了一种新颖的实例相关阈值函数。

    Semi-supervised learning (SSL) has been a fundamental challenge in machine learning for decades. The primary family of SSL algorithms, known as pseudo-labeling, involves assigning pseudo-labels to confident unlabeled instances and incorporating them into the training set. Therefore, the selection criteria of confident instances are crucial to the success of SSL. Recently, there has been growing interest in the development of SSL methods that use dynamic or adaptive thresholds. Yet, these methods typically apply the same threshold to all samples, or use class-dependent thresholds for instances belonging to a certain class, while neglecting instance-level information. In this paper, we propose the study of instance-dependent thresholds, which has the highest degree of freedom compared with existing methods. Specifically, we devise a novel instance-dependent threshold function for all unlabeled instances by utilizing their instance-level ambiguity and the instance-dependent error rates of
    
[^46]: 通过Wasserstein梯度下降估计速率-失真函数

    Estimating the Rate-Distortion Function by Wasserstein Gradient Descent. (arXiv:2310.18908v1 [cs.IT])

    [http://arxiv.org/abs/2310.18908](http://arxiv.org/abs/2310.18908)

    本文通过Wasserstein梯度下降方法，从最优传输的角度提出了一种估计速率-失真函数R(D)的新方法，该方法在低速率源上取得了与最先进的神经网络方法相当或更强的性能界限，并且需要较少的调整和计算工作。

    

    在无损压缩理论中，速率-失真（R-D）函数R(D)描述了在任何给定的保真度（失真）水平下，数据源可以被压缩的程度（比特率）。从最优传输的角度提出了一种估计R(D)的新方法。与经典的Blahut-Arimoto算法在先固定复制分布的支持的基础上不同，我们的Wasserstein梯度下降算法通过移动粒子学习最优复制分布的支持。证明了其局部收敛性，并通过与熵最优传输的联系分析了我们的R-D估计器的样本复杂度。在低速率源上，我们实验上获得了与最先进的神经网络方法相当或更强的界限，同时需要较少的调整和计算工作。我们还强调了与最大似然方法的联系。

    In the theory of lossy compression, the rate-distortion (R-D) function $R(D)$ describes how much a data source can be compressed (in bit-rate) at any given level of fidelity (distortion). Obtaining $R(D)$ for a given data source establishes the fundamental performance limit for all compression algorithms. We propose a new method to estimate $R(D)$ from the perspective of optimal transport. Unlike the classic Blahut--Arimoto algorithm which fixes the support of the reproduction distribution in advance, our Wasserstein gradient descent algorithm learns the support of the optimal reproduction distribution by moving particles. We prove its local convergence and analyze the sample complexity of our R-D estimator based on a connection to entropic optimal transport. Experimentally, we obtain comparable or tighter bounds than state-of-the-art neural network methods on low-rate sources while requiring considerably less tuning and computation effort. We also highlight a connection to maximum-lik
    
[^47]: 无需增强的简单非对称图对比学习

    Simple and Asymmetric Graph Contrastive Learning without Augmentations. (arXiv:2310.18884v1 [cs.LG])

    [http://arxiv.org/abs/2310.18884](http://arxiv.org/abs/2310.18884)

    本文提出了一种无需增强的简单非对称图对比学习方法GraphACL，通过考虑邻居节点的非对称视图，该方法能够有效地在同类和异类图上进行对比学习，对于建模异类图非常重要。

    

    图对比学习（GCL）在图结构数据的表示学习中显示出了优越的性能。尽管取得了成功，但大多数现有的GCL方法依赖于预制的图增强和同类假设。因此，它们在连通节点可能具有不同类标签和不相似特征的异类图上无法很好地推广。在本文中，我们研究了在同类和异类图上进行对比学习的问题。我们发现，通过考虑邻居节点的非对称视图，我们可以实现有希望的性能。由此产生的简单算法，称为图的非对称对比学习(GraphACL)，易于实现，不依赖于图增强和同类假设。我们提供了理论和实证证据，证明GraphACL能够捕捉单跳本地邻域信息和双跳单一相似性，这两者对于建模异类图非常重要。

    Graph Contrastive Learning (GCL) has shown superior performance in representation learning in graph-structured data. Despite their success, most existing GCL methods rely on prefabricated graph augmentation and homophily assumptions. Thus, they fail to generalize well to heterophilic graphs where connected nodes may have different class labels and dissimilar features. In this paper, we study the problem of conducting contrastive learning on homophilic and heterophilic graphs. We find that we can achieve promising performance simply by considering an asymmetric view of the neighboring nodes. The resulting simple algorithm, Asymmetric Contrastive Learning for Graphs (GraphACL), is easy to implement and does not rely on graph augmentations and homophily assumptions. We provide theoretical and empirical evidence that GraphACL can capture one-hop local neighborhood information and two-hop monophily similarity, which are both important for modeling heterophilic graphs. Experimental results s
    
[^48]: Bayes战胜交叉验证：通过期望最大化实现高效准确的岭回归

    Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization. (arXiv:2310.18860v1 [stat.ML])

    [http://arxiv.org/abs/2310.18860](http://arxiv.org/abs/2310.18860)

    本文提出了一种基于贝叶斯公式的岭回归方法，通过期望最大化来调节正则化超参数，该方法不需要指定候选的λ并且在大样本下可以找到唯一的最优解。

    

    我们提出了一种新的方法来调节岭回归的正则化超参数λ，该方法的计算速度比留一交叉验证(LOOCV)快，同时在稀疏协变量的情况下可以获得与LOOCV相等或更好的回归参数估计。对于有限的n，LOOCV风险可能受到多个和不好的局部最小值的影响，因此需要指定一组候选的λ，这可能无法提供良好的解决方案。相反，我们证明了所提出的方法在足够大的n下可以找到唯一的最优解，并且不需要指定任何难以确定的超参数。这是基于岭回归的贝叶斯公式，我们证明了对于足够大的n，后验是单峰的，可以同时学习最优的λ和回归系数。

    We present a novel method for tuning the regularization hyper-parameter, $\lambda$, of a ridge regression that is faster to compute than leave-one-out cross-validation (LOOCV) while yielding estimates of the regression parameters of equal, or particularly in the setting of sparse covariates, superior quality to those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from multiple and bad local minima for finite $n$ and thus requires the specification of a set of candidate $\lambda$, which can fail to provide good solutions. In contrast, we show that the proposed method is guaranteed to find a unique optimal solution for large enough $n$, under relatively mild conditions, without requiring the specification of any difficult to determine hyper-parameters. This is based on a Bayesian formulation of ridge regression that we prove to have a unimodal posterior for large enough $n$, allowing for both the optimal $\lambda$ and the regression coefficients to be jointly learned wi
    
[^49]: 球面上的内在高斯向量场

    Intrinsic Gaussian Vector Fields on Manifolds. (arXiv:2310.18824v1 [stat.ML])

    [http://arxiv.org/abs/2310.18824](http://arxiv.org/abs/2310.18824)

    本文提出了一种新型的在流形上处理矢量值信号的高斯过程模型，具有内在定义和考虑空间几何的特点，并为部署在二维球面和超曲面上的Hodge-Mat\'ern高斯向量场提供了计算基元。

    

    从机器人技术到气候科学等各种应用都需要对非欧几里得域（如球面）上的信号进行建模。最近，在流行度量空间上提出了高斯过程模型，尤其是在需要进行不确定性量化的任务中。在流形设置中，与标量值信号相比，矢量值信号可能表现出截然不同的行为，迄今为止的大部分进展都集中在对前者进行建模。然而，对于许多应用，如对未知动力系统的风速或力场进行建模，后者至关重要。本文提出了一种在流形上为矢量值信号提供内在定义并考虑空间几何的新型高斯过程模型。我们提供了部署所得到的Hodge-Mat\'ern高斯向量场在二维球面和超曲面上所需的计算基元。此外，我们还强调了两个推广方向：离散的二维网格和”ide“（暂且译为：想法）。

    Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\'ern Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and "ide
    
[^50]: 随机森林的稳定性和随机森林预测区间的覆盖率

    Stability of Random Forests and Coverage of Random-Forest Prediction Intervals. (arXiv:2310.18814v1 [stat.ML])

    [http://arxiv.org/abs/2310.18814](http://arxiv.org/abs/2310.18814)

    本文证明了在平方响应（$Y^2$）没有重尾的温和条件下，随机森林具有稳定性。利用稳定性属性，我们证明了随机森林的预测区间的覆盖概率的非渐近下界，并讨论了比以前考虑的条件更弱的情况。

    

    我们在平方响应（$Y^2$）没有重尾的温和条件下，确立了随机森林的稳定性。特别地，我们的分析适用于在流行软件包（如R中的randomForest）中实现的实际版本的随机森林。实证结果表明，稳定性可能会超出我们的假设，并对重尾的$Y^2$有效。利用稳定性属性，我们证明了随机森林的out-of-bag误差构建的预测区间的覆盖概率的非渐近下界。在$Y$连续时通常满足的其他温和条件下，我们还建立了一个补充的上界，这个上界也可以类似地建立在任意稳定算法构建的jackknife预测区间上。我们还讨论了在比以前文献考虑的条件更弱的假设下的渐近覆盖概率。我们的工作表明，随机森林在稳定性和覆盖率方面是有效的。

    We establish stability of random forests under the mild condition that the squared response ($Y^2$) does not have a heavy tail. In particular, our analysis holds for the practical version of random forests that is implemented in popular packages like \texttt{randomForest} in \texttt{R}. Empirical results show that stability may persist even beyond our assumption and hold for heavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests. With another mild condition that is typically satisfied when $Y$ is continuous, we also establish a complementary upper bound, which can be similarly established for the jackknife prediction interval constructed from an arbitrary stable algorithm. We also discuss the asymptotic coverage probability under assumptions weaker than those considered in previous literature. Our work implies that random forests, with its stabil
    
[^51]: 高概率收敛边界下的非线性随机梯度下降在重尾噪声下的研究

    High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise. (arXiv:2310.18784v1 [cs.LG])

    [http://arxiv.org/abs/2310.18784](http://arxiv.org/abs/2310.18784)

    本研究探讨了一类非线性随机梯度下降方法的高概率收敛边界。对于具有Lipschitz连续梯度的强凸损失函数，即使噪声是重尾的，结果证明了对失败概率的对数依赖。这些结果适用于剪切、归一化和量化等任何具有有界输出的非线性函数。

    

    最近几个研究工作研究了随机梯度下降（SGD）及其剪切变体的高概率收敛。与普通的SGD相比，剪切SGD在实际中更加稳定，并且在理论上有对数依赖于失败概率的额外好处。然而，其他实际非线性SGD变体（如符号SGD、量化SGD和归一化SGD）的收敛性理解要少得多，这些方法实现了改进的通信效率或加速收敛。在本工作中，我们研究了一类广义非线性SGD方法的高概率收敛边界。对于具有Lipschitz连续梯度的强凸损失函数，即使噪声是重尾的，我们证明了对失败概率的对数依赖。与剪切SGD的结果相比，我们的结果更为一般，适用于具有有界输出的任何非线性函数，如剪切、归一化和量化。

    Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantizati
    
[^52]: 非凸随机梯度情况下未调整的广义哈密尔顿蒙特卡罗中的反射耦合

    Reflection coupling for unadjusted generalized Hamiltonian Monte Carlo in the nonconvex stochastic gradient case. (arXiv:2310.18774v1 [math.PR])

    [http://arxiv.org/abs/2310.18774](http://arxiv.org/abs/2310.18774)

    该论文研究了非凸随机梯度情况下未调整的广义哈密尔顿蒙特卡罗中的反射耦合，证明了Wasserstein 1距离的收敛性，并提供了定量高斯集中界限，同时还给出了Wasserstein 2距离、总变差和相对熵的收敛性。

    

    在可能非凸的条件下，建立了具有随机梯度的广义哈密尔顿蒙特卡罗的Wasserstein 1距离的收敛性，其中包括动力学Langevin扩散的分裂方案算法。作为结果，提供了经验平均值的定量高斯集中界限。此外，还给出了Wasserstein 2距离、总变差和相对熵的收敛性，以及数值偏差估计。

    Contraction in Wasserstein 1-distance with explicit rates is established for generalized Hamiltonian Monte Carlo with stochastic gradients under possibly nonconvex conditions. The algorithms considered include splitting schemes of kinetic Langevin diffusion. As consequence, quantitative Gaussian concentration bounds are provided for empirical averages. Convergence in Wasserstein 2-distance, total variation and relative entropy are also given, together with numerical bias estimates.
    
[^53]: 通过正则化谱聚类进行潜在类别分析

    Latent class analysis by regularized spectral clustering. (arXiv:2310.18727v1 [cs.LG])

    [http://arxiv.org/abs/2310.18727](http://arxiv.org/abs/2310.18727)

    本文提出了两种新的算法用于分类数据的潜在类别模型，并通过新定义的正则化拉普拉斯矩阵计算潜在类别分析，结果表明算法具有理论收敛速度和稳定的一致性。同时提出了一个衡量潜在类别分析强度的度量标准及相关程序，通过模拟实验验证了算法的效率和准确性，并应用于实际分类数据。

    

    潜在类别模型是在社会、心理和行为科学领域识别具有共同特征的潜在类别的强大工具。在本文中，我们提出了两种新的算法来估计用于分类数据的潜在类别模型。我们的算法利用响应矩阵计算出的新定义的正则化拉普拉斯矩阵进行开发。我们通过考虑稀疏参数给出了算法的理论收敛速度，并表明在适度条件下我们的算法稳定地产生一致的潜在类别分析结果。此外，我们提出了一个衡量潜在类别分析强度的度量标准，并基于该度量标准设计了几个推断在实际分类数据中应该使用多少潜在类别的程序。通过广泛的模拟实验验证了我们算法的效率和准确性，同时将我们的算法进一步应用于实际分类数据。

    The latent class model is a powerful tool for identifying latent classes within populations that share common characteristics for categorical data in social, psychological, and behavioral sciences. In this article, we propose two new algorithms to estimate a latent class model for categorical data. Our algorithms are developed by using a newly defined regularized Laplacian matrix calculated from the response matrix. We provide theoretical convergence rates of our algorithms by considering a sparsity parameter and show that our algorithms stably yield consistent latent class analysis under mild conditions. Additionally, we propose a metric to capture the strength of latent class analysis and several procedures designed based on this metric to infer how many latent classes one should use for real-world categorical data. The efficiency and accuracy of our algorithms are verified by extensive simulated experiments, and we further apply our algorithms to real-world categorical data with pro
    
[^54]: 关于Hotelling型非对称张量除法的准确性：随机张量分析的研究

    On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random Tensor Analysis. (arXiv:2310.18717v1 [stat.ML])

    [http://arxiv.org/abs/2310.18717](http://arxiv.org/abs/2310.18717)

    本文通过随机张量理论研究了Hotelling型非对称张量除法在大维张量下的准确性，对除法过程中的奇异值和奇异向量进行了分析，可以用于构造信噪比和排列的估计。

    

    本文在大维张量的情况下，介绍了在噪声存在时Hotelling型张量除法的渐近研究。具体而言，我们考虑了一个低秩非对称张量模型，形式为$\sum_{i=1}^r \beta_i{\mathcal{A}}_i + {\mathcal{W}}$，其中$\beta_i\geq 0$，${\mathcal{A}}_i$是单位范数秩一张量，满足对于$i\neq j$，$\left| \langle {\mathcal{A}}_i, {\mathcal{A}}_j \rangle \right| \in [0, 1]$，${\mathcal{W}}$是一个附加的噪声项。假设主导的分量从噪声观测中逐步估计并逐步减去，我们利用最近在渐近大维张量的随机张量理论方面的进展，对于除法过程中每一步的估计奇异值和估计的真实奇异向量的排列进行了解析表征。此外，该结果可用于构造信噪比$\beta_i$的估计器以及排列的估计。

    This work introduces an asymptotic study of Hotelling-type tensor deflation in the presence of noise, in the regime of large tensor dimensions. Specifically, we consider a low-rank asymmetric tensor model of the form $\sum_{i=1}^r \beta_i{\mathcal{A}}_i + {\mathcal{W}}$ where $\beta_i\geq 0$ and the ${\mathcal{A}}_i$'s are unit-norm rank-one tensors such that $\left| \langle {\mathcal{A}}_i, {\mathcal{A}}_j \rangle \right| \in [0, 1]$ for $i\neq j$ and ${\mathcal{W}}$ is an additive noise term. Assuming that the dominant components are successively estimated from the noisy observation and subsequently subtracted, we leverage recent advances in random tensor theory in the regime of asymptotically large tensor dimensions to analytically characterize the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure. Furthermore, this result can be used to construct estimators of the signal-to-noise ratios $\beta_i$ and the align
    
[^55]: 具有重尾奖励的强化学习离线策略评估和优化的鲁棒性提升

    Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards. (arXiv:2310.18715v1 [cs.LG])

    [http://arxiv.org/abs/2310.18715](http://arxiv.org/abs/2310.18715)

    本文提出的ROAM和ROOM算法框架通过将中位数法与离线强化学习策略相结合，提供了对重尾奖励的直接不确定性估计，从而增强了离线强化学习在现实应用中的鲁棒性。

    

    本文旨在增强离线强化学习在现实世界应用中普遍存在的重尾奖励情况下的鲁棒性。我们提出了两个算法框架，ROAM和ROOM，用于鲁棒的离线策略评估和离线策略优化。我们的框架的核心是将中位数法与离线强化学习策略相结合，能够对值函数估计器进行直接的不确定性估计。这不仅符合离线策略优化中的保守主义原则，而且灵活处理重尾奖励。理论结果和广泛的实验证明，我们的两个框架在记录的数据集中展示了具有重尾奖励分布时超越现有方法的性能。

    This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions.
    
[^56]: 复杂工业系统中的因果关系发现：一个时间序列基准研究

    Causal discovery in a complex industrial system: A time series benchmark. (arXiv:2310.18654v1 [stat.ML])

    [http://arxiv.org/abs/2310.18654](http://arxiv.org/abs/2310.18654)

    本文提供了一个工业子系统的时间序列数据集和由专家知识构建的因果图，为复杂系统的因果关系发现方法的发展提供了一个测试平台。

    

    因果关系发现通过观测数据输出一个由图形表示的因果结构。针对时间序列数据，存在各种方法，然而，评估这些方法在真实数据上很困难，因为现实应用场景很少会有一个已知的因果图来进行比较。本文提供了来自欧洲散裂源的一个工业子系统的数据集以及由专家知识构建的因果图。这为从复杂系统的时间序列观测中进行因果关系发现提供了一个测试平台，我们相信这可以帮助推动因果关系发现方法的发展。

    Causal discovery outputs a causal structure, represented by a graph, from observed data. For time series data, there is a variety of methods, however, it is difficult to evaluate these on real data as realistic use cases very rarely come with a known causal graph to which output can be compared. In this paper, we present a dataset from an industrial subsystem at the European Spallation Source along with its causal graph which has been constructed from expert knowledge. This provides a testbed for causal discovery from time series observations of complex systems, and we believe this can help inform the development of causal discovery methodology.
    
[^57]: 悲观的离线多目标优化

    Pessimistic Off-Policy Multi-Objective Optimization. (arXiv:2310.18617v1 [cs.LG])

    [http://arxiv.org/abs/2310.18617](http://arxiv.org/abs/2310.18617)

    该论文提出了一种悲观的估计器，用于计算离线多目标优化中的策略值，并通过策略梯度进行优化。该估计器基于反向倾向性分数（IPS），在理论和实验中均表现出较好的性能。

    

    多目标优化是一类决策问题，其中对多个相互冲突的目标进行优化。我们研究了从现有策略收集的数据中进行离线优化的多目标策略。我们提出了一种悲观的估计器，用于计算多目标策略值，并可以轻松地插入到现有的超体积计算和优化公式中。该估计器基于反向倾向性分数（IPS），在理论和实验中均改进了朴素的IPS估计器。我们的分析是一般的，适用于超出IPS估计器和优化方法的范围。悲观的估计器可以通过策略梯度进行优化，并在我们的所有实验中表现良好。

    Multi-objective optimization is a type of decision making problems where multiple conflicting objectives are optimized. We study offline optimization of multi-objective policies from data collected by an existing policy. We propose a pessimistic estimator for the multi-objective policy values that can be easily plugged into existing formulas for hypervolume computation and optimized. The estimator is based on inverse propensity scores (IPS), and improves upon a naive IPS estimator in both theory and experiments. Our analysis is general, and applies beyond our IPS estimators and methods for optimizing them. The pessimistic estimator can be optimized by policy gradients and performs well in all of our experiments.
    
[^58]: 未知非平稳情况下的时间解缠表示学习

    Temporally Disentangled Representation Learning under Unknown Nonstationarity. (arXiv:2310.18615v1 [cs.LG])

    [http://arxiv.org/abs/2310.18615](http://arxiv.org/abs/2310.18615)

    本研究在非平稳情况下，探索了时间解缠表示学习的马尔可夫假设，并提出了一种无需辅助变量观测的方法来恢复独立的潜在分量。

    

    在具有时延潜在因果影响的时序数据的无监督因果表示学习中，通过利用时间结构在稳态情况下已经建立了有关因果相关潜在变量解缠的强可识别性结果。然而，在非平稳情况下，现有研究只部分解决了这个问题，要么利用观测到的辅助变量（如类别标签和/或域索引）作为辅助信息，要么假设简化的潜在因果动力学。这两者限制了方法的适用范围。在本研究中，我们进一步探索了非平稳环境中时间延迟相关过程的马尔可夫假设，并证明了在温和条件下，可以在不观察辅助变量的情况下从非线性混合中恢复独立的潜在分量，但可能存在排列和分量级转换。然后，我们引入了一个有原则的估计框架NCTRL来实现。

    In unsupervised causal representation learning for sequential data with time-delayed latent causal influences, strong identifiability results for the disentanglement of causally-related latent variables have been established in stationary settings by leveraging temporal structure. However, in nonstationary setting, existing work only partially addressed the problem by either utilizing observed auxiliary variables (e.g., class labels and/or domain indexes) as side information or assuming simplified latent causal dynamics. Both constrain the method to a limited range of scenarios. In this study, we further explored the Markov Assumption under time-delayed causally related process in nonstationary setting and showed that under mild conditions, the independent latent components can be recovered from their nonlinear mixture up to a permutation and a component-wise transformation, without the observation of auxiliary variables. We then introduce NCTRL, a principled estimation framework, to r
    
[^59]: 在线决策调解

    Online Decision Mediation. (arXiv:2310.18601v1 [stat.ML])

    [http://arxiv.org/abs/2310.18601](http://arxiv.org/abs/2310.18601)

    这篇论文研究了在线决策调解的问题，即学习和评估中介策略来平衡专家行为和人类行为，并提供一个高效的接口，以处理人类错误和专家反馈。

    

    考虑学习一个决策支持助手，作为(oracle)专家行为和(不完美)人类行为之间的中介：每次算法观察到一个由易出错的代理选择的动作，并决定是否接受代理的决策，干预替代，或要求专家的意见。在临床诊断中，完全自主的机器行为往往超出了伦理上的承受范围，因此现实世界中的决策支持往往只限于监测和预测。相反，这样的中介能够在纯指导性方法和纯描述性方法之间取得谨慎的平衡，同时提供人类错误和专家反馈之间的高效接口。在这项工作中，我们首先形式化了“在线决策调解”的顺序问题 - 即从头开始同时学习和评估中介策略，使用“缺失反馈”：在每一轮中，遵循oracle的建议

    Consider learning a decision support assistant to serve as an intermediary between (oracle) expert behavior and (imperfect) human behavior: At each time, the algorithm observes an action chosen by a fallible agent, and decides whether to *accept* that agent's decision, *intervene* with an alternative, or *request* the expert's opinion. For instance, in clinical diagnosis, fully-autonomous machine behavior is often beyond ethical affordances, thus real-world decision support is often limited to monitoring and forecasting. Instead, such an intermediary would strike a prudent balance between the former (purely prescriptive) and latter (purely descriptive) approaches, while providing an efficient interface between human mistakes and expert feedback. In this work, we first formalize the sequential problem of *online decision mediation* -- that is, of simultaneously learning and evaluating mediator policies from scratch with *abstentive feedback*: In each round, deferring to the oracle obvia
    
[^60]: 公平的流式主成分分析：统计学和算法视角

    Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint. (arXiv:2310.18593v1 [stat.ML])

    [http://arxiv.org/abs/2310.18593](http://arxiv.org/abs/2310.18593)

    该论文提出了公平流式主成分分析（PCA）算法，并且在理论和实践上解决了公平PCA的两个主要问题。

    

    公平主成分分析（PCA）是一个问题设置，我们的目标是在执行PCA的同时使得得到的表示公平，即在敏感属性条件下，投影分布相匹配。然而，现有的公平PCA方法存在两个主要问题：从理论上讲，没有以可学习性为基础的公平PCA统计学依据；从实践上讲，有限的内存使得我们无法使用现有方法，因为它们明确依赖于对整个数据的完全访问。在理论方面，我们使用一种称为“可能近似公平和最优”（PAFO）可学习性的新概念，严格地制定了公平PCA。在实践方面，受到解决内存限制的流式算法的最新进展的启发，我们提出了一个新的设置，称为“公平流式PCA”，以及一个内存高效的算法，公平噪声功率方法（FNPM）。然后，我们提供了其在PAFO可学习性方面的统计保证。

    Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called \emph{probably approximately fair and optimal} (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called \emph{fair streaming PCA} along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its {\it statistical} guarantee in terms of PAFO-learnability, which
    
[^61]: 反向决策建模：学习可解释行为的表示

    Inverse Decision Modeling: Learning Interpretable Representations of Behavior. (arXiv:2310.18591v1 [stat.ML])

    [http://arxiv.org/abs/2310.18591](http://arxiv.org/abs/2310.18591)

    这篇论文提出了一个反向决策建模的框架，用于学习序列决策行为的参数化表示。该框架能够提供透明的行为描述，并可以广泛应用于行为表示的研究问题。同时，通过一个示例，展示了该方法如何学习可解释的有限理性表示，并能捕捉到次优动作和偏见信仰等直观概念。

    

    决策分析涉及建模和增强决策过程。在改善行为方面的一个主要挑战是首先获得现有行为的透明描述。在本文中，我们发展了一个表达丰富的逆向决策建模的统一视角：一个学习参数化顺序决策行为表示的框架。首先，我们规范化了前向问题（作为规范标准），包含了常见的控制行为类别。其次，我们使用这个框架来规范化逆向问题（作为一个描述性模型），广义上推广了现有关于模仿/奖励学习的工作，同时打开了更广泛的行为表示研究问题类别。最后，我们通过一个例子（逆向有限理性控制）实例化了这个方法，说明了这个结构如何能够学习（可解释的）有限理性表示-同时自然地捕捉到次优动作、偏见信仰等直观概念。

    Decision analysis deals with modeling and enhancing decision processes. A principal challenge in improving behavior is in obtaining a transparent description of existing behavior in the first place. In this paper, we develop an expressive, unifying perspective on inverse decision modeling: a framework for learning parameterized representations of sequential decision behavior. First, we formalize the forward problem (as a normative standard), subsuming common classes of control behavior. Second, we use this to formalize the inverse problem (as a descriptive model), generalizing existing work on imitation/reward learning -- while opening up a much broader class of research problems in behavior representation. Finally, we instantiate this approach with an example (inverse bounded rational control), illustrating how this structure enables learning (interpretable) representations of (bounded) rationality -while naturally capturing intuitive notions of suboptimal actions, biased beliefs, a
    
[^62]: 用于核高斯混合模型的最优传输

    Optimal Transport for Kernel Gaussian Mixture Models. (arXiv:2310.18586v1 [cs.LG])

    [http://arxiv.org/abs/2310.18586](http://arxiv.org/abs/2310.18586)

    本研究提出了一种通过核技巧，在再生核希尔伯特空间中计算两个高斯混合模型之间距离的Wasserstein类型度量方法，解决了在核高斯混合模型中最优传输问题。

    

    来自最优质量传输（OMT）的Wasserstein距离是一种强大的数学工具，具有众多应用，提供了两个概率分布之间距离的自然度量。已开发了几种将OMT纳入广泛使用的概率模型（如高斯或高斯混合模型）的方法，以增强建模复杂多模态真实数据集密度的能力。然而，很少有研究探讨了在再生核希尔伯特空间（RKHS）中的OMT问题，在其中利用了核技巧，避免了需要显式映射输入数据到高维特征空间的需求。在本研究中，我们提出了一种通过核技巧，在RKHS中计算两个高斯混合模型之间距离的Wasserstein类型度量，即核高斯混合模型。

    The Wasserstein distance from optimal mass transport (OMT) is a powerful mathematical tool with numerous applications that provides a natural measure of the distance between two probability distributions. Several methods to incorporate OMT into widely used probabilistic models, such as Gaussian or Gaussian mixture, have been developed to enhance the capability of modeling complex multimodal densities of real datasets. However, very few studies have explored the OMT problems in a reproducing kernel Hilbert space (RKHS), wherein the kernel trick is utilized to avoid the need to explicitly map input data into a high-dimensional feature space. In the current study, we propose a Wasserstein-type metric to compute the distance between two Gaussian mixtures in a RKHS via the kernel trick, i.e., kernel Gaussian mixture models.
    
[^63]: 通过遗憾到置信集转换改进（多项式）逻辑回归赌博机的遗憾界限

    Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion. (arXiv:2310.18554v1 [stat.ML])

    [http://arxiv.org/abs/2310.18554](http://arxiv.org/abs/2310.18554)

    本论文通过遗憾到置信集转换方法改进了逻辑回归赌博机的遗憾界限，提出了一个基于在线学习算法的凸置信集，并应用于具有新的鞅集中步骤的遗憾分析。

    

    逻辑回归赌博机是建模用户选择的普遍框架，例如广告推荐系统中的点击与否。我们观察到先前的工作忽视或忽略了$S \geq \lVert \theta_\star \rVert_2$中的依赖关系，其中$\theta_\star \in \mathbb{R}^d$是未知的参数向量，当$S$较大时，例如$S \geq d$，这会产生问题。在这项工作中，我们通过一种称为“遗憾到置信集转换（R2CS）”的新方法改善了对$S$的依赖关系，该方法允许我们构建一个基于在线学习算法存在性的凸置信集。使用R2CS，我们在逻辑回归赌博机的遗憾界限方面获得了严格的改进，同时保持了计算可行性和对其他因素（如$d$和$T$）的依赖。我们将我们的新置信集应用于具有新的鞅集中步骤的逻辑回归赌博机的遗憾分析，从而避免了额外的因素。

    Logistic bandit is a ubiquitous framework of modeling users' choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \geq \lVert \theta_\star \rVert_2$, where $\theta_\star \in \mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor
    
[^64]: 多模态数据的因果分解

    Causal disentanglement of multimodal data. (arXiv:2310.18471v1 [cs.LG])

    [http://arxiv.org/abs/2310.18471](http://arxiv.org/abs/2310.18471)

    这篇论文介绍了一种可以利用多模态数据和已知物理学知识发现因果关系的因果表示学习算法。

    

    因果表示学习算法发现了数据的较低维度表示，可以对因果关系进行可解释的解释；由于实现这样的可解释表示很具挑战性，许多因果学习算法利用了指示先验信息的元素，例如（线性）结构因果模型、干预数据或弱监督。然而，在探索性因果表示学习中，这些元素和先验信息可能不可用或不合适。相反，科学数据集通常具有多个模态或基于物理学的约束，并且已经证明在完全无监督的设置中使用这种科学的多模态数据可以改善因果分解。因此，我们引入了一种因果表示学习算法（causalPIMA），它可以利用多模态数据和已知的物理学知识发现具有因果关系的重要特征。我们的创新算法利用新的可微参数化来学习这种因果关系。

    Causal representation learning algorithms discover lower-dimensional representations of data that admit a decipherable interpretation of cause and effect; as achieving such interpretable representations is challenging, many causal learning algorithms utilize elements indicating prior information, such as (linear) structural causal models, interventional data, or weak supervision. Unfortunately, in exploratory causal representation learning, such elements and prior information may not be available or warranted. Alternatively, scientific datasets often have multiple modalities or physics-based constraints, and the use of such scientific, multimodal data has been shown to improve disentanglement in fully unsupervised settings. Consequently, we introduce a causal representation learning algorithm (causalPIMA) that can use multimodal data and known physics to discover important features with causal relationships. Our innovative algorithm utilizes a new differentiable parametrization to lear
    
[^65]: 带有Bandit反馈的极小极大次模优化问题

    Minimax Optimal Submodular Optimization with Bandit Feedback. (arXiv:2310.18465v1 [cs.LG])

    [http://arxiv.org/abs/2310.18465](http://arxiv.org/abs/2310.18465)

    这项工作研究了带有Bandit反馈的极小极大次模优化问题，在这个问题中，我们建立了第一个最小最大下限，并提出了一个能够与下限遗憾相匹配的算法。

    

    我们考虑在随机Bandit反馈下，最大化一个单调次模集函数$f：2 ^ {[n]} \rightarrow [0,1]$。具体来说，$f$对于学习者是未知的，但是在每个时间$t=1,\dots,T$，学习者选择一个集合$S_t \subset [n]$，其中$|S_t|\leq k$，并接收奖励$f(S_t)+\eta_t$，其中$\eta_t$是均值为零的次高斯噪声。目标是在$T$次中使得学习者对于带有$|S_*|=k$的最大$f(S_*)$的($1-e^{-1}$)近似的最小遗憾，通过对$f$的贪婪最大化来达到。到目前为止，文献中最好的遗憾边界按照$k n^{1/3} T^{2/3}$的比例缩放。通过将每个集合简单地视为一个唯一的arm，可以推断出$\sqrt{{n \choose k} T}$也是可实现的。在这项工作中，我们建立了这种情况下的第一个极小极大下限，其按照$\mathcal{O}(\min_{i \le k}(in^{1/3}T^{2/3} + \sqrt{n^{k-i}T}))$的比例缩放。此外，我们提出了一个能够与下限遗憾相匹配的算法。

    We consider maximizing a monotonic, submodular set function $f: 2^{[n]} \rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is unknown to the learner but at each time $t=1,\dots,T$ the learner chooses a set $S_t \subset [n]$ with $|S_t| \leq k$ and receives reward $f(S_t) + \eta_t$ where $\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize the learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation of maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of $f$. To date, the best regret bound in the literature scales as $k n^{1/3} T^{2/3}$. And by trivially treating every set as a unique arm one deduces that $\sqrt{ {n \choose k} T }$ is also achievable. In this work, we establish the first minimax lower bound for this setting that scales like $\mathcal{O}(\min_{i \le k}(in^{1/3}T^{2/3} + \sqrt{n^{k-i}T}))$. Moreover, we propose an algorithm that is capable of matching the lower bound regret.
    
[^66]: 离线（多遍）随机梯度下降中的近似重尾行为

    Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient Descent. (arXiv:2310.18455v1 [cs.LG])

    [http://arxiv.org/abs/2310.18455](http://arxiv.org/abs/2310.18455)

    本文研究了离线（多遍）随机梯度下降中的重尾行为。通过展示离线SGD的稳态分布表现出“近似”幂律尾部，我们填补了在有限的训练数据量情况下重尾行为机制的空白。

    

    最近的一系列实证研究表明，在实际情况下，SGD可能表现出重尾行为，尾部的重度可能与整体性能相关。本文研究了这种重尾行为的出现。之前的工作只考虑了在线（也称为单遍）SGD，在理论发现中，重尾现象的出现取决于对无限量数据的访问。因此，在训练数据量有限的实际情况下，产生报告的重尾行为的机制仍不清楚。我们的贡献旨在填补这一空白。特别地，我们展示离线（也称为多遍）SGD的稳态分布表现出“近似”幂律尾部，而近似误差由训练数据的经验分布如何快速收敛于真实的基本数据分布所控制。

    A recent line of empirical studies has demonstrated that SGD might exhibit a heavy-tailed behavior in practical settings, and the heaviness of the tails might correlate with the overall performance. In this paper, we investigate the emergence of such heavy tails. Previous works on this problem only considered, up to our knowledge, online (also called single-pass) SGD, in which the emergence of heavy tails in theoretical findings is contingent upon access to an infinite amount of data. Hence, the underlying mechanism generating the reported heavy-tailed behavior in practical settings, where the amount of training data is finite, is still not well-understood. Our contribution aims to fill this gap. In particular, we show that the stationary distribution of offline (also called multi-pass) SGD exhibits 'approximate' power-law tails and the approximation error is controlled by how fast the empirical distribution of the training data converges to the true underlying data distribution in the
    
[^67]: 基于潜在决策模型的具有隐藏约束的贝叶斯优化方法

    Bayesian Optimization with Hidden Constraints via Latent Decision Models. (arXiv:2310.18449v1 [stat.ML])

    [http://arxiv.org/abs/2310.18449](http://arxiv.org/abs/2310.18449)

    本文介绍了一种基于潜在决策模型的贝叶斯优化方法，通过利用变分自编码器学习可行决策的分布，在原始空间和潜在空间之间实现了双向映射，从而解决了公共决策制定中的隐藏约束问题。

    

    贝叶斯优化（BO）已经成为解决复杂决策问题的强大工具，尤其在公共政策领域如警察划区方面。然而，由于定义可行区域的复杂性和决策的高维度，其在公共决策制定中的广泛应用受到了阻碍。本文介绍了一种新的贝叶斯优化方法——隐藏约束潜在空间贝叶斯优化（HC-LSBO），该方法集成了潜在决策模型。该方法利用变分自编码器来学习可行决策的分布，实现了原始决策空间与较低维度的潜在空间之间的双向映射。通过这种方式，HC-LSBO捕捉了公共决策制定中固有的隐藏约束的细微差别，在潜在空间中进行优化的同时，在原始空间中评估目标。我们通过对合成数据集和真实数据集进行数值实验来验证我们的方法，特别关注大规模问题。

    Bayesian optimization (BO) has emerged as a potent tool for addressing intricate decision-making challenges, especially in public policy domains such as police districting. However, its broader application in public policymaking is hindered by the complexity of defining feasible regions and the high-dimensionality of decisions. This paper introduces the Hidden-Constrained Latent Space Bayesian Optimization (HC-LSBO), a novel BO method integrated with a latent decision model. This approach leverages a variational autoencoder to learn the distribution of feasible decisions, enabling a two-way mapping between the original decision space and a lower-dimensional latent space. By doing so, HC-LSBO captures the nuances of hidden constraints inherent in public policymaking, allowing for optimization in the latent space while evaluating objectives in the original space. We validate our method through numerical experiments on both synthetic and real data sets, with a specific focus on large-scal
    
[^68]: 分布鲁棒学习和离线强化学习的桥梁：缓解分布偏移和部分数据覆盖的方法

    Bridging Distributionally Robust Learning and Offline RL: An Approach to Mitigate Distribution Shift and Partial Data Coverage. (arXiv:2310.18434v1 [cs.LG])

    [http://arxiv.org/abs/2310.18434](http://arxiv.org/abs/2310.18434)

    本论文介绍了一种将分布鲁棒学习（DRL）与离线强化学习（RL）相结合的方法，用于解决离线强化学习中的分布偏移问题。通过使用DRL方法，可以有效地缓解训练和测试环境之间的模型不匹配，并提出了两种离线强化学习算法。

    

    离线强化学习算法的目标是使用历史（离线）数据学习最优策略，而无需访问环境进行在线探索。离线强化学习的主要挑战之一是分布偏移，即数据生成策略的状态-动作访问分布与学习策略的差异。许多最新的研究利用悲观主义的思想开发离线强化学习算法，并在相对较弱的单一策略集中性假设下表征其样本复杂性。与离线强化学习文献不同，分布鲁棒学习（DRL）的领域提供了一个原则性框架，采用极小极大形式来解决训练和测试环境之间的模型不匹配问题。在这项工作中，我们旨在通过展示DRL方法可以用来解决离线强化学习中的分布偏移问题。特别地，我们提出了两种离线强化学习算法

    The goal of an offline reinforcement learning (RL) algorithm is to learn optimal polices using historical (offline) data, without access to the environment for online exploration. One of the main challenges in offline RL is the distribution shift which refers to the difference between the state-action visitation distribution of the data generating policy and the learning policy. Many recent works have used the idea of pessimism for developing offline RL algorithms and characterizing their sample complexity under a relatively weak assumption of single policy concentrability. Different from the offline RL literature, the area of distributionally robust learning (DRL) offers a principled framework that uses a minimax formulation to tackle model mismatch between training and testing environments. In this work, we aim to bridge these two areas by showing that the DRL approach can be used to tackle the distributional shift problem in offline RL. In particular, we propose two offline RL algor
    
[^69]: MCRAGE: 公平性的合成医疗数据

    MCRAGE: Synthetic Healthcare Data for Fairness. (arXiv:2310.18430v1 [stat.ML])

    [http://arxiv.org/abs/2310.18430](http://arxiv.org/abs/2310.18430)

    MCRAGE是一种使用深度生成模型来增强不平衡的医疗数据集的方法，以解决少数群体在机器学习模型中的不公平问题。

    

    在医疗领域，电子健康记录（EHR）是开发诊断、治疗和管理医疗资源的机器学习模型的关键训练数据。然而，医疗数据集在种族/民族、性别和年龄等敏感属性方面往往存在不平衡。在类不平衡的EHR数据集上训练的机器学习模型在部署时，对于少数群体的个体而言，表现显著不如多数群体的样本，这可能导致少数群体的不公平医疗结果。为了解决这个挑战，我们提出了一种名为Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE)的新方法，通过由深度生成模型生成的样本来增强不平衡的数据集。MCRAGE过程包括训练一个能够从少数群体中产生高质量合成EHR样本的条件去噪扩散概率模型（CDDPM）。

    In the field of healthcare, electronic health records (EHR) serve as crucial training data for developing machine learning models for diagnosis, treatment, and the management of healthcare resources. However, medical datasets are often imbalanced in terms of sensitive attributes such as race/ethnicity, gender, and age. Machine learning models trained on class-imbalanced EHR datasets perform significantly worse in deployment for individuals of the minority classes compared to samples from majority classes, which may lead to inequitable healthcare outcomes for minority groups. To address this challenge, we propose Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE), a novel approach to augment imbalanced datasets using samples generated by a deep generative model. The MCRAGE process involves training a Conditional Denoising Diffusion Probabilistic Model (CDDPM) capable of generating high-quality synthetic EHR samples from underrepresented classes. We use this 
    
[^70]: 关于道路公平性的研究：针对对抗去偏的鲁棒优化

    On the Fairness ROAD: Robust Optimization for Adversarial Debiasing. (arXiv:2310.18413v1 [cs.LG])

    [http://arxiv.org/abs/2310.18413](http://arxiv.org/abs/2310.18413)

    本论文研究了在算法公平性领域中存在的局部差异问题，并提出了一种基于分布鲁棒优化的公平对抗学习方法，以实现针对局部特征空间的公平性标准。

    

    在算法公平性领域，人们一直关注群体公平性准则，如人口统计学平价和平等赔率。然而，这些以全局平均值衡量的目标引发了有关敏感群体之间持续局部差异的担忧。本研究解决了局部公平性问题，即确保预测器在整个人群中的期望值以及在训练时未知的任何特征空间的子区域内均无偏见。为了实现这个目标，我们引入了ROAD，这是一种新颖的方法，利用分布鲁棒优化（DRO）框架来进行公平对抗学习，其中对手试图从预测中推断出敏感属性。通过实例级重新加权策略，ROAD被设计为优先考虑可能出现局部不公平的输入，即对手在重建敏感属性时最困难的情况。

    In the field of algorithmic fairness, significant attention has been put on group fairness criteria, such as Demographic Parity and Equalized Odds. Nevertheless, these objectives, measured as global averages, have raised concerns about persistent local disparities between sensitive groups. In this work, we address the problem of local fairness, which ensures that the predictor is unbiased not only in terms of expectations over the whole population, but also within any subregion of the feature space, unknown at training time. To enforce this objective, we introduce ROAD, a novel approach that leverages the Distributionally Robust Optimization (DRO) framework within a fair adversarial learning objective, where an adversary tries to infer the sensitive attribute from the predictions. Using an instance-level re-weighting strategy, ROAD is designed to prioritize inputs that are likely to be locally unfair, i.e. where the adversary faces the least difficulty in reconstructing the sensitive a
    
[^71]: AdaBoost概述：调和不同视角以更好地理解其动态

    Overview of AdaBoost : Reconciling its views to better understand its dynamics. (arXiv:2310.18323v1 [cs.LG])

    [http://arxiv.org/abs/2310.18323](http://arxiv.org/abs/2310.18323)

    本文概述了AdaBoost算法的不同视角，并通过统一的形式化方法将它们相互关联，帮助读者更好地理解AdaBoost的动态。

    

    提升方法于20世纪80年代末引入，其产生是基于PAC学习的理论方面。提升方法的主要思想是通过组合弱学习器来获得强学习器。弱学习器通过启发式算法迭代地纠正上一个弱学习器的错误而获得。1995年，Freund和Schapire [18]引入了AdaBoost，这是一个至今仍广泛使用的提升算法。自那以后，针对该算法的许多视角被提出来以更好地调控其动态。在本文中，我们将尝试涵盖对于AdaBoost可能存在的所有视角。我们将从Freund和Schapire的原始视角开始，然后涵盖不同视角，并使用相同的形式化方法将它们统一起来。我们希望本文能帮助非专业读者更好地理解AdaBoost的动态以及不同视角之间的等价性和相关性。

    Boosting methods have been introduced in the late 1980's. They were born following the theoritical aspect of PAC learning. The main idea of boosting methods is to combine weak learners to obtain a strong learner. The weak learners are obtained iteratively by an heuristic which tries to correct the mistakes of the previous weak learner. In 1995, Freund and Schapire [18] introduced AdaBoost, a boosting algorithm that is still widely used today. Since then, many views of the algorithm have been proposed to properly tame its dynamics. In this paper, we will try to cover all the views that one can have on AdaBoost. We will start with the original view of Freund and Schapire before covering the different views and unify them with the same formalism. We hope this paper will help the non-expert reader to better understand the dynamics of AdaBoost and how the different views are equivalent and related to each other.
    
[^72]: Causal Q-Aggregation for CATE Model Selection（CATE模型选择中的因果Q集成）

    Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])

    [http://arxiv.org/abs/2310.16945](http://arxiv.org/abs/2310.16945)

    该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率

    

    准确估计条件平均处理效应（CATE）是个性化决策的核心。尽管有大量用于CATE估计的模型，但由于因果推断的基本问题，模型选择是一项非常棘手的任务。最近的实证工作提供了有利于具有双重鲁棒性质的代理损失度量和模型集成的证据。然而，对于这些模型的理论理解还不够。直接应用先前的理论工作会由于模型选择问题的非凸性而导致次优的预测模型选择率。我们提供了现有主要CATE集成方法的遗憾率，并提出了一种基于双重鲁棒损失的Q集成的新的CATE模型集成方法。我们的主要结果表明，因果Q集成在预测模型选择的遗憾率上达到了统计上的最优值为$\frac{\log(M)}{n}$（其中$M$为模型数，$n$为样本数），加上高阶估计误差项

    Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
    
[^73]: 适用于强盗游戏的近似信息最大化方法

    Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])

    [http://arxiv.org/abs/2310.12563](http://arxiv.org/abs/2310.12563)

    本论文提出了一种基于近似信息最大化的强盗游戏算法，通过最大化关键变量的信息近似值来进行优化，在传统强盗设置中表现出很强的性能，并证明了其对于两臂强盗问题的渐近最优性。

    

    熵最大化和自由能最小化是用于模拟各种物理系统动态的一般物理原理。其中包括使用自由能原理对大脑内的决策进行建模，使用信息瓶颈原理对访问隐藏变量时优化准确性和复杂性的权衡，以及使用信息最大化进行随机环境导航。基于这一原理，我们提出了一种新的强盗算法类别，通过最大化系统中一个关键变量的信息近似来进行优化。为此，我们开发了一个基于物理的近似分析熵的表示方法，以预测每个动作的信息增益，并贪婪地选择信息增益最大的动作。这种方法在传统强盗设置中表现出很强的性能。受到其经验性成功的启发，我们证明了其对于两臂强盗问题的渐近最优性。

    Entropy maximization and free energy minimization are general physical principles for modeling the dynamics of various physical systems. Notable examples include modeling decision-making within the brain using the free-energy principle, optimizing the accuracy-complexity trade-off when accessing hidden variables with the information bottleneck principle (Tishby et al., 2000), and navigation in random environments using information maximization (Vergassola et al., 2007). Built on this principle, we propose a new class of bandit algorithms that maximize an approximation to the information of a key variable within the system. To this end, we develop an approximated analytical physics-based representation of an entropy to forecast the information gain of each action and greedily choose the one with the largest information gain. This method yields strong performances in classical bandit settings. Motivated by its empirical success, we prove its asymptotic optimality for the two-armed bandit
    
[^74]: 从连续动力学到图神经网络：神经扩散与更多

    From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond. (arXiv:2310.10121v1 [cs.LG])

    [http://arxiv.org/abs/2310.10121](http://arxiv.org/abs/2310.10121)

    本综述系统全面地回顾了利用连续动力学框架的图神经网络，以帮助从根本上理解和改进GNN的能力和缺陷。

    

    图神经网络（GNN）在建模关系数据方面表现出显著的潜力，并在各个领域得到广泛应用。GNN背后的关键机制是所谓的消息传递，它通过从邻居节点中集中地聚合信息来进行迭代。这种方案与称为热传导的物理过程密切相关，其中GNN的传播自然对应于热密度的演化。将消息传递过程类比为热动力学可以从根本上理解GNN的能力和缺陷，从而有助于更好地设计模型。最近出现了大量旨在减轻GNN已知限制（如过度平滑和过度压缩）的GNN提出作品，这些作品受到连续动力学的启发。在本综述中，我们首次系统全面地回顾了利用连续动力学框架的研究。

    Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuou
    
[^75]: 低秩强化学习的频谱逐元素矩阵估计

    Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning. (arXiv:2310.06793v1 [cs.LG])

    [http://arxiv.org/abs/2310.06793](http://arxiv.org/abs/2310.06793)

    该论文研究了低秩结构下的矩阵估计问题，并提出了基于频谱的方法，这些方法在估计奇异子空间方面表现出色，并且能够实现几乎最小的逐元素误差。这些新结果为充分利用低秩结构的强化学习算法的设计提供了可能性。

    

    我们研究强化学习中出现的低秩结构的矩阵估计问题。在低秩赌博机中，需要恢复的矩阵指定了预期的臂奖励，而在低秩马尔可夫决策过程(MDP)中，它可以描述MDP的转换核。在这两种情况下，矩阵的每个元素都承载重要信息，我们寻求具有低逐元素误差的估计方法。重要的是，这些方法还需要适应可用数据中的固有相关性（例如，对于MDPs，数据由系统轨迹组成）。我们研究了简单的基于频谱的矩阵估计方法的性能：我们展示了它们有效地恢复了矩阵的奇异子空间，并且具有几乎最小的逐元素误差。这些关于低秩矩阵估计的新结果使得设计完全利用底层低秩结构的强化学习算法成为可能。我们提供了两个这样的算法示例。

    We study matrix estimation problems arising in reinforcement learning (RL) with low-rank structure. In low-rank bandits, the matrix to be recovered specifies the expected arm rewards, and for low-rank Markov Decision Processes (MDPs), it may for example characterize the transition kernel of the MDP. In both cases, each entry of the matrix carries important information, and we seek estimation methods with low entry-wise error. Importantly, these methods further need to accommodate for inherent correlations in the available data (e.g. for MDPs, the data consists of system trajectories). We investigate the performance of simple spectral-based matrix estimation approaches: we show that they efficiently recover the singular subspaces of the matrix and exhibit nearly-minimal entry-wise error. These new results on low-rank matrix estimation make it possible to devise reinforcement learning algorithms that fully exploit the underlying low-rank structure. We provide two examples of such algorit
    
[^76]: Riemannian流形上Matern高斯过程的后验收缩速率

    Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds. (arXiv:2309.10918v1 [stat.ML])

    [http://arxiv.org/abs/2309.10918](http://arxiv.org/abs/2309.10918)

    该论文研究了定义在紧致Riemannian流形上的内在Matern高斯过程和外在过程之间的收缩速率，并发现它们的速率在适当匹配平滑参数的情况下是相等的。

    

    高斯过程在许多依赖于不确定性量化的机器学习应用中被使用。最近，已经开发了在几何设置下处理这些模型的计算工具，例如，当输入位于Riemannian流形上时。这引出了一个问题：这些内在模型在理论上是否可以证明相比于将所有相关量嵌入到$\mathbb{R}^d$并使用普通欧几里德高斯过程的限制，可以带来更好的性能？为了研究这个问题，我们证明了定义在紧致Riemannian流形上的内在Matern高斯过程的最优收缩速率。我们还通过流形和环境Sobolev空间之间的迹和扩展定理证明了外在过程的类似速率：令人惊讶的是，所得到的速率与内在过程的速率相符，前提是它们的平滑参数适当匹配。我们在一些实证数据上进行了对这些速率的演示。

    Gaussian processes are used in many machine learning applications that rely on uncertainty quantification. Recently, computational tools for working with these models in geometric settings, such as when inputs lie on a Riemannian manifold, have been developed. This raises the question: can these intrinsic models be shown theoretically to lead to better performance, compared to simply embedding all relevant quantities into $\mathbb{R}^d$ and using the restriction of an ordinary Euclidean Gaussian process? To study this, we prove optimal contraction rates for intrinsic Mat\'ern Gaussian processes defined on compact Riemannian manifolds. We also prove analogous rates for extrinsic processes using trace and extension theorems between manifold and ambient Sobolev spaces: somewhat surprisingly, the rates obtained turn out to coincide with those of the intrinsic processes, provided that their smoothness parameters are matched appropriately. We illustrate these rates empirically on a number of
    
[^77]: 集群化的多智能体线性赌博机

    Clustered Multi-Agent Linear Bandits. (arXiv:2309.08710v1 [cs.LG])

    [http://arxiv.org/abs/2309.08710](http://arxiv.org/abs/2309.08710)

    本文研究了集群化的多智能体线性赌博机问题，提出了一种新颖的算法，通过智能体之间的协作来加速优化问题。通过理论分析和实证评估，证明了算法在遗憾最小化和聚类质量上的有效性。

    

    本文针对多智能体线性随机赌博问题的一个特定实例，即集群化的多智能体线性赌博机进行了研究。在这个设置中，我们提出了一种新颖的算法，通过智能体之间的有效协作来加速整体优化问题。在这一贡献中，网络控制器负责估计网络的基本集群结构并优化同一组中智能体之间的经验分享。我们对遗憾最小化问题和聚类质量进行了理论分析。通过对合成数据和真实数据进行与最先进算法的实证评估，我们证明了我们方法的有效性：我们的算法显著改善了遗憾最小化，并成功恢复了真实的基本集群划分。

    We address in this paper a particular instance of the multi-agent linear stochastic bandit problem, called clustered multi-agent linear bandits. In this setting, we propose a novel algorithm leveraging an efficient collaboration between the agents in order to accelerate the overall optimization problem. In this contribution, a network controller is responsible for estimating the underlying cluster structure of the network and optimizing the experiences sharing among agents within the same groups. We provide a theoretical analysis for both the regret minimization problem and the clustering quality. Through empirical evaluation against state-of-the-art algorithms on both synthetic and real data, we demonstrate the effectiveness of our approach: our algorithm significantly improves regret minimization while managing to recover the true underlying cluster partitioning.
    
[^78]: 神经特征学习中的帕累托前沿：数据、计算、宽度和运气

    Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. (arXiv:2309.03800v1 [cs.LG])

    [http://arxiv.org/abs/2309.03800](http://arxiv.org/abs/2309.03800)

    本研究研究了深度学习算法设计中的微妙选择，特别关注计算统计差距。通过理论和实验，发现稀疏初始化和增加网络宽度可以提高样本效率，并且合成稀疏奇偶任务可以作为真实问题的代理。

    

    本研究探讨了在计算统计差距存在的情况下，深度学习中微妙的算法设计选择。我们首先考虑了离线稀疏奇偶学习，这是一个有关多层感知器梯度训练的监督分类问题，其具有统计查询下界。这个下界可以解释为多资源的权衡前沿：成功学习只有在一个足够丰富（大型模型）、知识渊博（大规模数据集）、耐心（训练迭代次数多）或幸运（随机猜测次数多）的情况下才能发生。我们通过理论和实验表明，在这种情况下，稀疏初始化和增加网络宽度可以显著提高样本效率。在这里，宽度起到了并行搜索的作用：它增加了找到“幸运神经元”的概率，这些神经元可以更高效地学习稀疏特征。最后，我们表明合成稀疏奇偶任务可以作为真实问题的代理。

    This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding "lottery ticket" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real pro
    
[^79]: NAS-X: 基于扭曲的神经自适应平滑方法

    NAS-X: Neural Adaptive Smoothing via Twisting. (arXiv:2308.14864v1 [cs.LG])

    [http://arxiv.org/abs/2308.14864](http://arxiv.org/abs/2308.14864)

    NAS-X是一种基于扭曲的神经自适应平滑方法，通过重新加权的唤醒-睡眠算法来学习和推断顺序潜变量模型，并在离散和连续任务中取得了优于先前方法的推断和参数恢复效果。

    

    本文提出了一种名为NAS-X的神经自适应平滑方法，该方法基于重新加权的唤醒-睡眠算法进行顺序潜变量模型的学习和推断。NAS-X适用于离散和连续潜变量，并利用平滑SMC方法来拟合比传统的重新加权唤醒-睡眠方法更广泛的模型。我们在离散和连续任务上测试了NAS-X，并发现在推断和参数恢复方面，它明显优于先前的变分和基于重新加权唤醒-睡眠方法。

    We present Neural Adaptive Smoothing via Twisting (NAS-X), a method for learning and inference in sequential latent variable models based on reweighted wake-sleep (RWS). NAS-X works with both discrete and continuous latent variables, and leverages smoothing SMC to fit a broader range of models than traditional RWS methods. We test NAS-X on discrete and continuous tasks and find that it substantially outperforms previous variational and RWS-based methods in inference and parameter recovery.
    
[^80]: 作为计算简单图的最大团的最大数量的手段的充满团图

    Cliqueful graphs as a means of calculating the maximal number of maximum cliques of simple graphs. (arXiv:2307.14120v1 [math.CO])

    [http://arxiv.org/abs/2307.14120](http://arxiv.org/abs/2307.14120)

    本论文研究了充满团图的概念，并且发现在简单图中，充满团图的最大数量取决于饱和复合充满团图。通过具体计算，我们得到了在n个顶点上具有最多最大团数量的图形式表达式。

    

    一个简单图在n个顶点上可能包含许多最大团。但它可能包含多少个呢？我们将展示最大团的最大数量取决于所谓的充满团图，具体地说，如果n≥15，我们将展示它取决于饱和复合充满团图。利用这一点，我们将展示包含3^{⌊n/3⌋}c个最大团的图在n个顶点上具有最多的最大团数量，其中c∈{1,4/3,2}，取决于n模3的值。

    A simple graph on $n$ vertices may contain a lot of maximum cliques. But how many can it potentially contain? We will show that the maximum number of maximum cliques is taken over so-called cliqueful graphs, more specifically, later we will show that it is taken over saturated composite cliqueful graphs, if $n \ge 15$. Using this we will show that the graph that contains $3^{\lfloor n/3 \rfloor}c$ maxcliques has the most number of maxcliques on $n$ vertices, where $c\in\{1,\frac{4}{3},2\}$, depending on $n \text{ mod } 3$.
    
[^81]: 从人类偏好中学习的政策在情境多臂赌博问题中的可证明优势

    Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems. (arXiv:2307.12975v1 [cs.LG])

    [http://arxiv.org/abs/2307.12975](http://arxiv.org/abs/2307.12975)

    该论文研究了基于偏好的政策学习方法在离线情境多臂赌博问题中的优势，并通过改进建模和分析，证明了这一方法相比其他政策学习方法具有更低的次优性。

    

    在决策问题中，奖励工程是一个关键的任务。在实践中，往往不存在明显的奖励函数选择。因此，一种常见的方法是在训练过程中引入人类反馈，并利用这种反馈来学习奖励函数。在使用人类反馈的所有政策学习方法中，基于偏好的方法在最近的实证应用中取得了显著的成功，如InstructGPT。在这项工作中，我们开发了一个理论，可以证明在离线情境多臂赌博问题中，基于偏好的方法具有显著的优势。具体而言，我们改进了在人类评分样本上运行政策学习方法的建模和次优性分析。然后，我们将其与基于偏好的方法的次优性保证进行比较，并表明基于偏好的方法享有更低的次优性。

    A crucial task in decision-making problems is reward engineering. It is common in practice that no obvious choice of reward function exists. Thus, a popular approach is to introduce human feedback during training and leverage such feedback to learn a reward function. Among all policy learning methods that use human feedback, preference-based methods have demonstrated substantial success in recent empirical applications such as InstructGPT. In this work, we develop a theory that provably shows the benefits of preference-based methods in offline contextual bandits. In particular, we improve the modeling and suboptimality analysis for running policy learning methods on human-scored samples directly. Then, we compare it with the suboptimality guarantees of preference-based methods and show that preference-based methods enjoy lower suboptimality.
    
[^82]: 复杂性至关重要：重新思考生成建模的潜在空间

    Complexity Matters: Rethinking the Latent Space for Generative Modeling. (arXiv:2307.08283v1 [cs.LG])

    [http://arxiv.org/abs/2307.08283](http://arxiv.org/abs/2307.08283)

    本研究从模型复杂性的角度重新思考生成建模的潜在空间，提出了一种新的潜在与数据分布之间的“距离”，并通过该距离的最小化来优化生成器的复杂性。

    

    在生成建模中，许多成功的方法利用低维潜在空间，例如，稳定扩散模型通过编码器引导的潜在空间生成图像，并通过配对的解码器进行生成。尽管潜在空间的选择在实践中非常重要，但确定最优选择和识别过程仍不清楚。在本研究中，我们旨在从模型复杂性的角度重新思考潜在空间，来揭示这个未被充分探索的话题。我们的调查从经典的生成对抗网络（GANs）开始。受到GAN训练目标的启发，我们提出了一种新的潜在与数据分布之间的“距离”，其最小化与生成器的复杂性最小化相一致。这个距离的最小化者被描述为能够最有效地利用生成器容量的最佳数据相关的潜在。然后，我们考虑通过编码器网络对这样的潜在分布进行参数化，并提出了一个方法...

    In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel "distance" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propo
    
[^83]: 拥抱混乱：数值不稳定性在变分流中的分析和诊断

    Embracing the chaos: analysis and diagnosis of numerical instability in variational flows. (arXiv:2307.06957v1 [stat.ML])

    [http://arxiv.org/abs/2307.06957](http://arxiv.org/abs/2307.06957)

    本文研究了数值不稳定性对变分流中采样、密度评估和ELBO估计的可靠性的影响。通过理论保证和实验验证，我们发现尽管存在严重的数值不稳定性，变分流产生的结果在应用中常常足够准确。

    

    本文研究了数值不稳定性对变分流中采样、密度评估和证据下界（ELBO）估计的可靠性的影响。我们首先通过实证验证了常见流可能出现严重的错误累积：数值流映射与精确映射的偏差显著，影响采样；数值逆流映射无法准确恢复初始输入，影响密度和ELBO计算。然而，我们惊讶地发现，尽管存在严重的数值不稳定性，流产生的结果常常足够准确应对应用需求。在这项工作中，我们将变分流视为动力系统，并利用阴影理论通过理论保证对采样、密度评估和ELBO估计的错误来阐明这种行为。最后，我们开发并经验性地测试了一种可以用于验证数值结果的诊断程序。

    In this paper, we investigate the impact of numerical instability on the reliability of sampling, density evaluation, and evidence lower bound (ELBO) estimation in variational flows. We first empirically demonstrate that common flows can exhibit a catastrophic accumulation of error: the numerical flow map deviates significantly from the exact map -- which affects sampling -- and the numerical inverse flow map does not accurately recover the initial input -which affects density and ELBO computations. Surprisingly though, we find that results produced by flows are often accurate enough for applications despite the presence of serious numerical instability. In this work, we treat variational flows as dynamical systems, and leverage shadowing theory to elucidate this behavior via theoretical guarantees on the error of sampling, density evaluation, and ELBO estimation. Finally, we develop and empirically test a diagnostic procedure that can be used to validate results produced by numerica
    
[^84]: 通过$\beta$-分解一后验采样实现差分计算机学习

    Differentially Private Statistical Inference through $\beta$-Divergence One Posterior Sampling. (arXiv:2307.05194v1 [stat.ML])

    [http://arxiv.org/abs/2307.05194](http://arxiv.org/abs/2307.05194)

    通过对数据生成过程和模型之间的$\beta$-分解进行后验采样，我们提出了$\beta$D-Bayes，一种能够实现差分机器学习的方法。

    

    差分私密性确保了包含敏感数据的统计分析结果可以在不损害任何个体隐私的情况下进行发布。实现这种保证通常需要在参数估计或估计过程中直接注入噪音。而采样来自贝叶斯后验分布已被证明是指数机制的一种特殊情况，可以产生一致且高效的私密估计，而不会改变数据生成过程。然而，当前方法的应用受到较强的边界假设的限制，这些假设对于基本模型（如简单的线性回归器）并不成立。为了改善这一点，我们提出了$\beta$D-Bayes，一种从广义后验中进行后验采样的方案，目标是最小化模型与数据生成过程之间的$\beta$-分解。这提供了私密估计的方法。

    Differential privacy guarantees allow the results of a statistical analysis involving sensitive data to be released without compromising the privacy of any individual taking part. Achieving such guarantees generally requires the injection of noise, either directly into parameter estimates or into the estimation process. Instead of artificially introducing perturbations, sampling from Bayesian posterior distributions has been shown to be a special case of the exponential mechanism, producing consistent, and efficient private estimates without altering the data generative process. The application of current approaches has, however, been limited by their strong bounding assumptions which do not hold for basic models, such as simple linear regressors. To ameliorate this, we propose $\beta$D-Bayes, a posterior sampling scheme from a generalised posterior targeting the minimisation of the $\beta$-divergence between the model and the data generating process. This provides private estimation t
    
[^85]: 可实现回归的最优学习算法：PAC学习和在线学习

    Optimal Learners for Realizable Regression: PAC Learning and Online Learning. (arXiv:2307.03848v1 [cs.LG])

    [http://arxiv.org/abs/2307.03848](http://arxiv.org/abs/2307.03848)

    本论文研究了可实现回归问题的PAC学习和在线学习的统计复杂度，并提出了对于可学习性的必要条件和充分条件。

    

    本研究旨在对可实现回归在PAC学习和在线学习的统计复杂度进行刻画。先前的研究已经证明了有限的fat shattering维度对于PAC学习的充分性以及有限的scaled Natarajan维度对于必要性的存在，但自从Simon 1997（SICOMP '97）的工作以来，对于更完整的刻画的进展甚少。为此，我们首先引入了一种最小化实例最优学习算法来对可实现回归进行学习，并提出了一种既定性又定量地刻画了哪些类的实数预测器可以被学习的新颖维度。然后，我们确定了一个与图维度相关的组合维度，该维度刻画了在可实现设置中的ERM可学习性。最后，我们根据与DS维度相关的组合维度建立了学习可行性的必要条件，并猜测它也可能是充分的。

    In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting.  Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in 
    
[^86]: 模型错误下的条件独立性检验

    Conditional independence testing under model misspecification. (arXiv:2307.02520v1 [stat.ML])

    [http://arxiv.org/abs/2307.02520](http://arxiv.org/abs/2307.02520)

    该论文研究了模型错误下的条件独立性检验，在这种情况下提出了新的近似或上界来衡量基于回归的测试的测试误差，并引入了一种新颖的基于回归的CI检验方法RBPT，对模型错误具有鲁棒性。

    

    条件独立性（CI）检验是现代统计学和机器学习中基础且具有挑战性的问题。许多现代的CI检验方法依赖于强大的监督学习方法来学习回归函数或贝叶斯预测器作为中间步骤。尽管这些方法在监督学习方法准确估计回归函数或贝叶斯预测器时保证了控制第一类错误，但它们在模型错误导致失败时的行为尚不清楚。从更广泛的意义上讲，即使使用了通用逼近器（例如深度神经网络），模型错误也可能出现。因此，我们研究了在模型错误下的基于回归的CI检验的性能。具体地，我们提出了新的近似或上界来衡量依赖于错误的三个基于回归的测试的测试误差。此外，我们引入了Rao-Blackwellized Predictor Test（RBPT），这是一种新颖的基于回归的CI检验，对模型错误具有鲁棒性。

    Conditional independence (CI) testing is fundamental and challenging in modern statistics and machine learning. Many modern methods for CI testing rely on powerful supervised learning methods to learn regression functions or Bayes predictors as an intermediate step. Although the methods are guaranteed to control Type-I error when the supervised learning methods accurately estimate the regression functions or Bayes predictors, their behavior is less understood when they fail due to model misspecification. In a broader sense, model misspecification can arise even when universal approximators (e.g., deep neural nets) are employed. Then, we study the performance of regression-based CI tests under model misspecification. Namely, we propose new approximations or upper bounds for the testing errors of three regression-based tests that depend on misspecification errors. Moreover, we introduce the Rao-Blackwellized Predictor Test (RBPT), a novel regression-based CI test robust against model mis
    
[^87]: 快速通过切片Wasserstein广义测地线实现最优输运

    Fast Optimal Transport through Sliced Wasserstein Generalized Geodesics. (arXiv:2307.01770v1 [stat.ML])

    [http://arxiv.org/abs/2307.01770](http://arxiv.org/abs/2307.01770)

    本文提出了一种快速计算最优输运的方法，通过切片Wasserstein广义测地线进行近似，得到了一个基于一维最优投影的代理距离min-SWGG，并提供了相关的传输计划。这种方法具有较低的计算复杂度，适用于优化算法。

    

    Wassserstein距离和相关的最优输运计划在许多涉及概率度量的应用中被证明是有用的。在本文中，我们提出了一个新的平方Wasserstein距离的代理，称为min-SWGG，它基于两个输入分布的一维最优投影引导的运输映射。我们在min-SWGG和Wasserstein广义测地线之间建立了联系，其中枢纽测度在一条直线上得到支持。我们特别提供了一个新的闭合形式的精确Wasserstein距离，在其中一个分布支持在一条直线上的特殊情况下，使我们能够推导出一种适用于梯度下降优化的快速计算方案。我们表明min-SWGG是WD的上界，并且它具有与Sliced-Wasserstein类似的复杂度，同时提供了一个相关的输运计划。我们还研究了一些理论性质，如距离性、弱收敛、计算和拓扑性质等。

    Wasserstein distance (WD) and the associated optimal transport plan have been proven useful in many applications where probability measures are at stake. In this paper, we propose a new proxy of the squared WD, coined min-SWGG, that is based on the transport map induced by an optimal one-dimensional projection of the two input distributions. We draw connections between min-SWGG and Wasserstein generalized geodesics in which the pivot measure is supported on a line. We notably provide a new closed form for the exact Wasserstein distance in the particular case of one of the distributions supported on a line allowing us to derive a fast computational scheme that is amenable to gradient descent optimization. We show that min-SWGG is an upper bound of WD and that it has a complexity similar to as Sliced-Wasserstein, with the additional feature of providing an associated transport plan. We also investigate some theoretical properties such as metricity, weak convergence, computational and top
    
[^88]: 自适应主成分回归在面板数据中的应用

    Adaptive Principal Component Regression with Applications to Panel Data. (arXiv:2307.01357v1 [cs.LG])

    [http://arxiv.org/abs/2307.01357](http://arxiv.org/abs/2307.01357)

    本文提出了自适应主成分回归方法，并在面板数据中的应用中获得了均匀有限样本保证。该方法可以用于面板数据中的实验设计，特别是当干预方案是自适应分配的情况。

    

    主成分回归(PCR)是一种流行的固定设计误差变量回归技术，它是线性回归的推广，观测的协变量受到随机噪声的污染。我们在数据收集时提供了在线（正则化）PCR的第一次均匀有限样本保证。由于分析固定设计中PCR的证明技术无法很容易地扩展到在线设置，我们的结果依赖于将现代鞅浓度的工具适应到误差变量设置中。作为我们界限的应用，我们在面板数据设置中提供了实验设计框架，当干预被自适应地分配时。我们的框架可以被认为是合成控制和合成干预框架的泛化，其中数据是通过自适应干预分配策略收集的。

    Principal component regression (PCR) is a popular technique for fixed-design error-in-variables regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected adaptively. Since the proof techniques for analyzing PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for experiment design in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic control and synthetic interventions frameworks, where data is collected via an adaptive intervention assignment policy.
    
[^89]: 是否应该停止：具有异质种群的早期停止方法

    Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations. (arXiv:2306.11839v1 [stat.ME])

    [http://arxiv.org/abs/2306.11839](http://arxiv.org/abs/2306.11839)

    本文提出了针对于异质种群有害实验的早期停止方法CLASH，使用因果机器学习可以有效提前停止临床试验和A/B测试。

    

    随机实验由于治疗造成意外的有害影响，因此往往需要提前停止。目前确定何时提前终止实验的现有方法通常适用于总体数据，不考虑治疗效应的异质性。本文研究了针对异质种群有害实验的早期停止方法。我们首先确定现有方法在治疗对少数参与者造成伤害时往往无法停止实验。然后使用因果机器学习开发了CLASH，这是首个广泛适用于异质早期停止的方法。我们在模拟和实际数据上展示了CLASH的表现，并证明它在临床试验和A/B测试中都能有效提前停止。

    Randomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests.
    
[^90]: 使用随机梯度下降从高斯过程后验中采样

    Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent. (arXiv:2306.11589v1 [cs.LG])

    [http://arxiv.org/abs/2306.11589](http://arxiv.org/abs/2306.11589)

    本文探索了使用随机梯度下降算法从高斯过程后验中采样的方法，该方法计算高效且能在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。

    

    高斯过程是用于量化不确定性和顺序决策的强大框架，但其需要求解线性系统，每当数据集大小增加时代价是立方级别的且对条件敏感。本文探索了随机梯度算法作为一种计算高效的方法来近似解决这些线性系统：我们开发了低方差的最优化目标以从后验中进行采样，并将其扩展到引入点。令人意想不到的是，即使在不快速收敛到最优解的情况下，随机梯度下降通常也会产生准确的预测。我们通过非收敛的隐式偏置的谱特征来解释这一点。我们表明，随机梯度下降会在足够覆盖数据的区域和足够远离数据的区域中产生接近真实后验的预测分布。在实验中，随机梯度下降实现了

    Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves sta
    
[^91]: 多类条件下的类别条件符合性预测

    Class-Conditional Conformal Prediction With Many Classes. (arXiv:2306.09335v1 [stat.ML])

    [http://arxiv.org/abs/2306.09335](http://arxiv.org/abs/2306.09335)

    提出了一种叫做聚类符合性预测的方法，可以在多类条件下提供类别条件符合性预测，针对多个类别的图像数据集中经验评估结果表明其优于现有方法。

    

    标准符合性预测方法提供边缘覆盖保证，这意味着对于一个随机的测试点，符合性预测集合以用户选择的概率包含真实标签。在许多分类问题中，我们希望获得更强的保证——对于特定类别的测试点，预测集以相同的用户选择概率包含真实标签。现有的符合性预测方法在每个类别有限的标记数据的情况下表现不佳，而这在实际应用中往往是大量类别的情况。我们提出了一种称为聚类符合性预测的方法，它将具有“相似”符合性分数的类别聚类在一起，然后在聚类级别上执行符合性预测。在针对多个（多达1000）类别的四个图像数据集的经验评估中，我们发现，聚类符合性通常在类条件覆盖和集合方面优于现有方法。

    Standard conformal prediction methods provide a marginal coverage guarantee, which means that for a random test point, the conformal prediction set contains the true label with a user-chosen probability. In many classification problems, we would like to obtain a stronger guarantee -- that for test points of a specific class, the prediction set contains the true label with the same user-chosen probability. Existing conformal prediction methods do not work well when there is a limited amount of labeled data per class, as is often the case in real applications where the number of classes is large. We propose a method called clustered conformal prediction, which clusters together classes that have "similar" conformal scores and then performs conformal prediction at the cluster level. Based on empirical evaluation across four image data sets with many (up to 1000) classes, we find that clustered conformal typically outperforms existing methods in terms of class-conditional coverage and set 
    
[^92]: MMD-FUSE: 在不分割数据的情况下学习和组合内核进行双样本检验

    MMD-FUSE: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting. (arXiv:2306.08777v1 [stat.ML])

    [http://arxiv.org/abs/2306.08777](http://arxiv.org/abs/2306.08777)

    本文提出了MMD-FUSE方法，通过适应内核集合最大化基于MMD的双样本检验功率，避免数据分割，并在低维合成数据和高维实际数据上证明了其适用性和功率超过现有最先进的核检验方法。

    

    本文提出了一种新的统计方法，通过适应定义该方法的内核集合，最大化基于最大平均偏差（MMD）的双样本检验的功率。 对于有限集合，这就缩小了通过加权软最大值组合（标准化的）每个内核下的MMD值。 对于零假设和备择假设，证明了我们提出的统计量的指数浓度上限。 我们进一步展示了如何通过数据依赖但与排列独立的方式选择这些内核，在一个经过良好校准的测试中避免数据分割。 这种技术更广泛地适用于基于一般排列的MMD测试，并且包括使用使用自编码器等无监督模型学习的深度内核。 我们强调了我们的MMD-FUSE测试在合成低维数据和现实世界高维数据方面的适用性，并比较了其功率表现与当前最先进的内核检验。

    We propose novel statistics which maximise the power of a two-sample test based on the Maximum Mean Discrepancy (MMD), by adapting over the set of kernels used in defining it. For finite sets, this reduces to combining (normalised) MMD values under each of these kernels via a weighted soft maximum. Exponential concentration bounds are proved for our proposed statistics under the null and alternative. We further show how these kernels can be chosen in a data-dependent but permutation-independent way, in a well-calibrated test, avoiding data splitting. This technique applies more broadly to general permutation-based MMD testing, and includes the use of deep kernels with features learnt using unsupervised models such as auto-encoders. We highlight the applicability of our MMD-FUSE test on both synthetic low-dimensional and real-world high-dimensional data, and compare its performance in terms of power against current state-of-the-art kernel tests.
    
[^93]: 强度轮廓投影：用于动态网络的连续时间表示学习框架。

    Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks. (arXiv:2306.06155v1 [cs.LG])

    [http://arxiv.org/abs/2306.06155](http://arxiv.org/abs/2306.06155)

    本文提出了一种连续时间网络表示学习框架，涵盖核平滑的强度函数估计、最小化强度重构误差的投影学习和归纳构造节点表示。这种表示保留了网络结构和时间一致性。

    

    我们提出了一种名为“强度轮廓投影”的新算法框架，用于学习动态网络节点的连续时间表示，该动态网络由节点集和在连续时间内发生的瞬时交互事件的集合所特征化。我们的框架包括三个阶段：通过核平滑等方法估计节点对之间交互的强度函数；学习一个最小化某种强度重构误差的投影；通过学习的投影归纳构造出不断发展的节点表示。我们展示了我们的表示保留了网络的基本结构，并具有时间一致性，这意味着节点表示可以在不同的时间点上进行有意义的比较。同时，我们也构建了估计理论来阐明平滑作为偏差方差折衷的作用，并展示了如何随着信噪比的增加而减少平滑程度以获得更好的性能。

    We present a new algorithmic framework, Intensity Profile Projection, for learning continuous-time representations of the nodes of a dynamic network, characterised by a node set and a collection of instantaneous interaction events which occur in continuous time. Our framework consists of three stages: estimating the intensity functions underlying the interactions between pairs of nodes, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and inductively constructing evolving node representations via the learned projection. We show that our representations preserve the underlying structure of the network, and are temporally coherent, meaning that node representations can be meaningfully compared at different points in time. We develop estimation theory which elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce smoothing as the signal-to-noise ratio increases on account of the algorithm `borrow
    
[^94]: Prodigy: 一种快速自适应零参数学习算法

    Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])

    [http://arxiv.org/abs/2306.06101](http://arxiv.org/abs/2306.06101)

    本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。

    

    本文研究自适应算法(如Adagrad和Adam)中的学习率估计问题，描述了两种技术Prodigy和Resetting，可以证明地估计到达解决方案所需的距离D，以便最优设置学习率。我们的技术是基于学习率自由的D-Adaptation方法的修改，并通过$O(\sqrt{\log(D/d_0)})$的因子提高了D-Adaptation的收敛速度，其中$d_0$是$D$的初始估计值。我们在12个常见的逻辑回归基准数据集、在CIFAR10上训练的VGG11和ResNet-50、在Imagenet上训练的ViT、在IWSLT14上训练的LSTM、在Criteo数据集上训练的DLRM、在Knee MRI数据集上的VarNet，以及在BookWiki上训练的RoBERTa和GPT transformer上测试了我们的方法。我们的实验结果表明，我们的方法始终优于D-Adaptation，并达到手动调整Adam的测试准确度值。

    We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
    
[^95]: 图上函数的贝叶斯优化

    Bayesian Optimisation of Functions on Graphs. (arXiv:2306.05304v1 [cs.LG])

    [http://arxiv.org/abs/2306.05304](http://arxiv.org/abs/2306.05304)

    本论文提出了一种在通用的大规模和潜在未知图上定义函数的贝叶斯优化算法，并通过学习适当的图内核，适应目标函数行为。

    

    图结构数据的不断涌现推动了在图节点集上定义函数的优化任务。传统的图搜索算法可用于此，但它们可能样本效率低下，并且不利用关于函数值的信息；另一方面，贝叶斯优化是一类有前途的黑盒求解器，具有更高的样本效率，但它很少被应用于这样的新颖设置。为了填补这一空白，我们提出了一种新颖的贝叶斯优化框架，该框架优化在通用，大规模和潜在的未知图上定义的函数。通过学习适当的图内核，我们的框架具有适应目标函数行为的优点。局部建模方法进一步保证了我们方法的效率。在合成和真实世界图上的大量实验表明了所提出的优化框架的有效性。

    The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has been scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.
    
[^96]: 分布式均值估计中的通信隐私效用权衡的精确最优性研究

    Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation. (arXiv:2306.04924v1 [cs.LG])

    [http://arxiv.org/abs/2306.04924](http://arxiv.org/abs/2306.04924)

    本研究针对均值估计问题，探讨了在通信和本地差分隐私约束下的精确最优方法，提出了利用旋转对称的共享随机码书，并通过$k$-closest编码实现了随机旋转的单纯形$c$的精确最优。

    

    本文研究了在通信和本地差分隐私约束下的均值估计问题。虽然以前的研究已经提出了相同问题的\emph{阶}-最优算法（即当我们花费更多比特时渐进最优），但在非渐进设置下仍然没有实现\emph{精确}最优性。在本文中，我们迈出了一步，描述了在共享随机性存在的情况下的\emph{精确}-最优方法，并确定了几个\emph{精确}最优的必要条件。我们证明了其中一个必要条件是利用旋转对称的共享随机码书。基于此，我们提出了一种随机化机制，其中码书是随机旋转的单纯形——满足\emph{精确}-最优码书的必要属性。该机制基于我们证明的$k$最近编码，对于随机旋转的单纯形$c$来说是\emph{精确}-最优的。

    We study the mean estimation problem under communication and local differential privacy constraints. While previous work has proposed \emph{order}-optimal algorithms for the same problem (i.e., asymptotically optimal as we spend more bits), \emph{exact} optimality (in the non-asymptotic setting) still has not been achieved. In this work, we take a step towards characterizing the \emph{exact}-optimal approach in the presence of shared randomness (a random variable shared between the server and the user) and identify several necessary conditions for \emph{exact} optimality. We prove that one of the necessary conditions is to utilize a rotationally symmetric shared random codebook. Based on this, we propose a randomization mechanism where the codebook is a randomly rotated simplex -- satisfying the necessary properties of the \emph{exact}-optimal codebook. The proposed mechanism is based on a $k$-closest encoding which we prove to be \emph{exact}-optimal for the randomly rotated simplex c
    
[^97]: 随机坍缩：如何利用梯度噪声使SGD动态趋向更简单的子网络

    Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks. (arXiv:2306.04251v1 [cs.LG])

    [http://arxiv.org/abs/2306.04251](http://arxiv.org/abs/2306.04251)

    SGD在训练过度表达的网络时，会随机地将动态吸引到更简单的子网络，这种随机吸引性能够提高泛化能力。

    

    本文揭示了随机梯度下降（SGD）的一个强烈隐式偏好，它将过度表达的网络驱动到更简单的子网络，从而大大减少了独立参数的数量，并提高了泛化能力。为了揭示这个偏好，我们识别了不变集，或者说是SGD未修改的参数空间的子集。我们专注于两类不变集，它们对应于现代架构中常见的更简单的子网络。我们的分析揭示了SGD在这些简单不变集方面具有随机吸引性的特性。我们根据损失景观在不变集周围的曲率和随机梯度引入的噪声之间的竞争建立了一种随机吸引性的充分条件。值得注意的是，我们发现增加噪声水平会增强吸引力，导致与鞍点或训练损失的局部极大值相关的吸引不变集的出现。

    In this work, we reveal a strong implicit bias of stochastic gradient descent (SGD) that drives overly expressive networks to much simpler subnetworks, thereby dramatically reducing the number of independent parameters, and improving generalization. To reveal this bias, we identify invariant sets, or subsets of parameter space that remain unmodified by SGD. We focus on two classes of invariant sets that correspond to simpler subnetworks and commonly appear in modern architectures. Our analysis uncovers that SGD exhibits a property of stochastic attractivity towards these simpler invariant sets. We establish a sufficient condition for stochastic attractivity based on a competition between the loss landscape's curvature around the invariant set and the noise introduced by stochastic gradients. Remarkably, we find that an increased level of noise strengthens attractivity, leading to the emergence of attractive invariant sets associated with saddle-points or local maxima of the train loss.
    
[^98]: 难民安置中的随机分布转移: 建立健壮模型的策略。

    Random Distribution Shift in Refugee Placement: Strategies for Building Robust Models. (arXiv:2306.02948v1 [stat.ML])

    [http://arxiv.org/abs/2306.02948](http://arxiv.org/abs/2306.02948)

    本文研究了难民安置中的随机分布转移问题，并提出并比较了三种建模策略，最终发现混合方法具有较强鲁棒性。

    

    近年来，算法分配难民和寻求庇护者到主机国家的地点已经引起了关注，在美国和瑞士实施。这些方法使用过去抵达的数据生成可以用于匹配家庭到位置的机器学习模型（与分配算法一起使用），目标是最大化政策相关的整合结果，如在一定时间后的就业状态。现有的实现和研究通过直接预测政策结果来训练模型，并将这些预测用于分配过程。然而，这种方法的优点，特别是在非稳态环境下，尚未被先前探讨。本研究提出并比较了三种不同的建模策略：上述的标准方法、使用更新数据和代理结果的方法以及混合方法。我们证明混合方法在分布转移和弱代理关系方面具有鲁棒性-

    Algorithmic assignment of refugees and asylum seekers to locations within host countries has gained attention in recent years, with implementations in the US and Switzerland. These approaches use data on past arrivals to generate machine learning models that can be used (along with assignment algorithms) to match families to locations, with the goal of maximizing a policy-relevant integration outcome such as employment status after a certain duration. Existing implementations and research train models to predict the policy outcome directly, and use these predictions in the assignment procedure. However, the merits of this approach, particularly in non-stationary settings, has not been previously explored. This study proposes and compares three different modeling strategies: the standard approach described above, an approach that uses newer data and proxy outcomes, and a hybrid approach. We show that the hybrid approach is robust to both distribution shift and weak proxy relationships -
    
[^99]: 通过强制条件单调性在Early-Exit结构中实现随时分类

    Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity. (arXiv:2306.02652v1 [cs.LG])

    [http://arxiv.org/abs/2306.02652](http://arxiv.org/abs/2306.02652)

    本文提出了一种在Early-Exit网络中实现条件单调性的方法，将深度模型转化为真正的随时分类器。

    

    现代预测模型通常部署在计算预算动态的环境中。随时算法非常适用于这种环境，因为它们在计算的任何时候都可以输出预测值，其质量是计算时间的函数。由于其能够在网络各个阶段提供中间预测结果的能力，Early-Exit神经网络在随时计算的背景下引起了人们的关注。然而，我们证明当前的Early-Exit网络并不直接适用于任何时候的设置，因为单个数据点的预测质量不能保证随着计算时间的增加而提高。为了解决这个缺陷，我们提出了一种优雅的事后修改，基于专家乘积，鼓励Early-Exit网络逐渐变得自信。这赋予了我们的深度模型条件单调性的特性——这是实现真正随时分类的重要基石。

    Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of conditional monotonicity in the prediction quality -- an essential stepping stone towards truly an
    
[^100]: 人类专家审核研究

    Auditing for Human Expertise. (arXiv:2306.01646v1 [stat.ML])

    [http://arxiv.org/abs/2306.01646](http://arxiv.org/abs/2306.01646)

    人类专家的价值超出了算法可捕捉范围，我们可以用一个简单的程序测试这个问题。

    

    高风险预测任务（例如患者诊断）通常由接受培训的人类专家处理。在这些设置中，自动化的一个常见问题是，专家可能运用很难建模的直觉，并且/或者可以获取信息（例如与患者的交谈），这些信息对于算法来说是不可用的。这引发了一个自然的问题，人类专家是否增加了无法被算法预测器捕捉到的价值。我们开发了一个统计框架，可以将这个问题提出为一个自然的假设检验。正如我们的框架所强调的那样，检测人类专业知识比简单比较专家预测准确性与特定学习算法做出的准确性更加微妙。而是提出了一个简单的程序，测试专家预测是否在“特征”可用而条件下是否与感兴趣的结果统计上独立。因此，我们测试的拒绝表明了人类专业知识确实增加了超出算法可捕捉范围的价值。

    High-stakes prediction tasks (e.g., patient diagnosis) are often handled by trained human experts. A common source of concern about automation in these settings is that experts may exercise intuition that is difficult to model and/or have access to information (e.g., conversations with a patient) that is simply unavailable to a would-be algorithm. This raises a natural question whether human experts add value which could not be captured by an algorithmic predictor. We develop a statistical framework under which we can pose this question as a natural hypothesis test. Indeed, as our framework highlights, detecting human expertise is more subtle than simply comparing the accuracy of expert predictions to those made by a particular learning algorithm. Instead, we propose a simple procedure which tests whether expert predictions are statistically independent from the outcomes of interest after conditioning on the available inputs (`features'). A rejection of our test thus suggests that huma
    
[^101]: 相互作用测量，分区格和核测试用于高阶相互作用

    Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions. (arXiv:2306.00904v1 [stat.ML])

    [http://arxiv.org/abs/2306.00904](http://arxiv.org/abs/2306.00904)

    本文提出了一种用于高阶相互作用的测量方法和基于核的测试方法，并与格理论建立了数学联系，为增强相互作用模型提供了方法。

    

    仅依赖于成对关系的模型往往无法捕捉到各种领域（如社会经济、生态或生物医学系统）中找到的复杂多变量数据的完整统计结构。两个以上变量组之间的非平凡依赖关系在这些系统的分析和建模中可以发挥重要作用，但从数据中提取这样的高阶相互作用仍然具有挑战性。本文引入了一系列$d$-order ($d \geq 2$)相互作用测量，依次包括可能的联合概率分布分解，并定义了非参数、基于核的测试，以系统地确定$d$-order相互作用的统计显着性。同时，我们建立了与格理论的数学联系，阐明了相互作用度量的导出及其复合排列测试的涵义；澄清了单纯复合体与核矩阵中心化的联系；并提供了一种增强相互作用模型的方法。

    Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhan
    
[^102]: 未知干预的因果表达式的非参数识别

    Nonparametric Identifiability of Causal Representations from Unknown Interventions. (arXiv:2306.00542v1 [stat.ML])

    [http://arxiv.org/abs/2306.00542](http://arxiv.org/abs/2306.00542)

    本文提出了一种新方法用于从未知干预数据中推断非参数因果表达式学习，并且证明了在两个因果变量的基本设置中，无法消除一些由干预数据引起的歧义问题。

    

    我们研究因果表达式学习，即从变量的高维函数（“混合物”）中推断潜在的因果变量及其因果关系的任务。以前的工作依赖于弱监督，如反事实的干预观察或时间结构；对混合函数或潜在因果模型施加限制，如线性；或需要部分了解生成过程，如因果图或干预目标。我们考虑到因果模型和混合函数都是非参数的一般情况。学习信号采用来自基础因果模型中未知干预的多个数据集或环境的形式。我们的目标是将地面真实潜变量及其因果图鉴定出来，同时解决一组从干预数据无法消除的歧义问题。我们研究了两个因果变量的基本设置，并证明了...

    We study causal representation learning, the task of inferring latent causal variables and their causal relations from high-dimensional functions ("mixtures") of the variables. Prior work relies on weak supervision, in the form of counterfactual pre- and post-intervention views or temporal structure; places restrictive assumptions, such as linearity, on the mixing function or latent causal model; or requires partial knowledge of the generative process, such as the causal graph or the intervention targets. We instead consider the general setting in which both the causal model and the mixing function are nonparametric. The learning signal takes the form of multiple datasets, or environments, arising from unknown interventions in the underlying causal model. Our goal is to identify both the ground truth latents and their causal graph up to a set of ambiguities which we show to be irresolvable from interventional data. We study the fundamental setting of two causal variables and prove that
    
[^103]: 强化学习中的可复现性研究

    Replicability in Reinforcement Learning. (arXiv:2305.19562v1 [cs.LG])

    [http://arxiv.org/abs/2305.19562](http://arxiv.org/abs/2305.19562)

    这篇论文研究了在强化学习中的可复制性，提出了可复制算法和松弛可复制算法，并给出了相应的时间和样本复杂度，这对于RL算法设计以及未来的可复制性研究具有影响。

    

    我们在强化学习 (RL) 的背景下，将可复现性作为算法属性进行了数学研究。我们关注的是具有生成模型访问权的带折扣表格MDP的基本设置。受Impagliazzo等人 [2022]的启发，如果在内部随机性相同时，RL算法在从生成器抽取的两个独立和同分布的样本上执行两次并输出完全相同的策略，则表示该RL算法是可复制的。我们首先提供一个有效的$\rho$-可复制算法，用于$(\varepsilon,\delta)$-最优策略估计，其样本和时间复杂度为 $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$，其中$N$是状态-动作对的数量。然后，对于确定性算法的子类，我们提供了 $ \Omega\left(\frac {N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right) $ 阶的下限。接下来，我们研究了Kalavasis等人[2019]提出的可复制性的松弛版本，其中仅要求算法的输出接近复制算法的输出，而不是相同。我们提供了一种有效算法，其时间和样本复杂度为 $\widetilde O\left(\frac{N^5\cdot\log(1/\delta)}{(1-\gamma)^9\cdot\varepsilon^4\cdot\rho^2}\right)$，用于$(\varepsilon,\delta)$意义下的可复制性，这比先前与相关问题的界限更好。最后，我们讨论了我们的结果对RL算法设计和可重复性研究的未来方向的影响。

    We initiate the mathematical study of replicability as an algorithmic property in the context of reinforcement learning (RL). We focus on the fundamental setting of discounted tabular MDPs with access to a generative model. Inspired by Impagliazzo et al. [2022], we say that an RL algorithm is replicable if, with high probability, it outputs the exact same policy after two executions on i.i.d. samples drawn from the generator when its internal randomness is the same. We first provide an efficient $\rho$-replicable algorithm for $(\varepsilon, \delta)$-optimal policy estimation with sample and time complexity $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$, where $N$ is the number of state-action pairs. Next, for the subclass of deterministic algorithms, we provide a lower bound of order $\Omega\left(\frac{N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right)$. Then, we study a relaxed version of replicability proposed by Kalavasis et 
    
[^104]: 单一生成流网络中的图结构与参数的联合贝叶斯推理

    Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network. (arXiv:2305.19366v1 [cs.LG])

    [http://arxiv.org/abs/2305.19366](http://arxiv.org/abs/2305.19366)

    本文提出了在单一生成流网络中联合建模贝叶斯网络结构和参数的方法，包括非离散样本空间，提高了贝叶斯网络局部概率模型的灵活性。

    

    生成流网络是一类对离散和结构化样本空间进行建模的生成模型。先前的研究已将其应用于推断给定观测数据的贝叶斯网络的有向无环图（DAG）的边缘后验分布。本文基于最近的研究进展，在非离散样本空间上将此框架扩展到联合后验分布的建模，不仅包括贝叶斯网络的结构，还考虑了其条件概率分布的参数。

    Generative Flow Networks (GFlowNets), a class of generative models over discrete and structured sample spaces, have been previously applied to the problem of inferring the marginal posterior distribution over the directed acyclic graph (DAG) of a Bayesian Network, given a dataset of observations. Based on recent advances extending this framework to non-discrete sample spaces, we propose in this paper to approximate the joint posterior over not only the structure of a Bayesian Network, but also the parameters of its conditional probability distributions. We use a single GFlowNet whose sampling policy follows a two-phase process: the DAG is first generated sequentially one edge at a time, and then the corresponding parameters are picked once the full structure is known. Since the parameters are included in the posterior distribution, this leaves more flexibility for the local probability models of the Bayesian Network, making our approach applicable even to non-linear models parametrized
    
[^105]: Bayesian隐式神经表示下的压缩

    Compression with Bayesian Implicit Neural Representations. (arXiv:2305.19185v1 [cs.LG])

    [http://arxiv.org/abs/2305.19185](http://arxiv.org/abs/2305.19185)

    该论文提出了一种用Bayesian隐式神经表示来压缩数据的方法，通过最小化 $\beta$-ELBO 直接优化码-失真性能，并通过调整 $\beta$ 来针对给定的网络结构实现不同的码-失真平衡。

    

    许多常见类型的数据可以表示为将坐标映射到信号值的函数，例如图像中的像素位置到RGB值。基于这个观点，可以通过对数据的功能表示进行超拟合，然后编码网络权重来压缩数据。然而，大多数当前的解决方案都效率低下，因为将精度量化到低比特会大幅降低重构质量。为解决这个问题，我们提出了过度拟合变分贝叶斯神经网络来压缩近似后验权重样本，而不是量化和熵编码它。该策略通过最小化 $\beta$-ELBO 直接优化码-失真性能，并通过调整 $\beta$ 来针对给定的网络结构实现不同的码-失真平衡。此外，我们引入了一种学习先验权重分布的迭代算法，并采用主动尺寸调整来进一步提高效率。

    Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a pro
    
[^106]: 关于激活函数和规范化对初始化等距嵌入的影响

    On the impact of activation and normalization in obtaining isometric embeddings at initialization. (arXiv:2305.18399v1 [cs.LG])

    [http://arxiv.org/abs/2305.18399](http://arxiv.org/abs/2305.18399)

    本论文研究了深度神经网络中的 Gram 矩阵结构，证明了激活函数和层规范化结合使用可以在初始化时偏向指数级深度等距，从而弥补了现有理论的空白。

    

    本文探讨了深度神经网络中倒数第二个 Gram 矩阵的结构，该矩阵包含与一批输入对应的输出之间的成对内积。在几种架构中，观察到在初始化时该 Gram 矩阵会随着深度变得退化，从而严重减缓训练速度。规范化层如批处理规范化或层规范化，在防止秩崩溃问题方面起着关键作用。然而现有的理论结果无法全面覆盖广泛用于 transformer 中的层规范化和有限深度下规范化的量化偏差。为了解决这个问题，我们证明了在初始化时，结合激活函数层使用的层规范化可以使多层感知机的 Gram 矩阵偏向指数级深度等距，并使用激活函数的 Hermite 展开来量化这个速度，从而填补了现有理论的空白。

    In this paper, we explore the structure of the penultimate Gram matrix in deep neural networks, which contains the pairwise inner products of outputs corresponding to a batch of inputs. In several architectures it has been observed that this Gram matrix becomes degenerate with depth at initialization, which dramatically slows training. Normalization layers, such as batch or layer normalization, play a pivotal role in preventing the rank collapse issue. Despite promising advances, the existing theoretical results (i) do not extend to layer normalization, which is widely used in transformers, (ii) can not characterize the bias of normalization quantitatively at finite depth.  To bridge this gap, we provide a proof that layer normalization, in conjunction with activation layers, biases the Gram matrix of a multilayer perceptron towards isometry at an exponential rate with depth at initialization. We quantify this rate using the Hermite expansion of the activation function, highlighting th
    
[^107]: 隐式转移算子学习：分子动力学多时间分辨率代理

    Implicit Transfer Operator Learning: Multiple Time-Resolution Surrogates for Molecular Dynamics. (arXiv:2305.18046v1 [physics.chem-ph])

    [http://arxiv.org/abs/2305.18046](http://arxiv.org/abs/2305.18046)

    ITO Learning是一个学习分子动力学多时间分辨率代理的框架，可以生成自洽的随机动力学，节省数百倍的时间。

    

    计算分子系统的性质需要估计（未归一化的）玻尔兹曼分布的期望值。分子动力学（MD）是一种广泛采用的技术，用于近似这种量。然而，稳定的模拟需要非常小的积分时间步长（$10^{-15}$秒），而一些矩的收敛性，例如结合自由能或速率，可能依赖于长达$10^{-1}$秒的时间尺度上的采样过程，并且必须对每个分子系统进行独立模拟。在这里，我们提出了隐式转移算子（ITO）学习，这是一个学习具有多个时间分辨率的模拟过程代理的框架。我们使用具有新SE（3）等变体系结构的去噪扩散概率模型实现ITO，并展示结果模型可以在多个时间尺度上生成自洽的随机动力学，即使只有部分观测到系统。最后，我们提出了粗粒化的CG-SE3-ITO模型，并展示它可以在模拟过程中节省数百倍的时间。

    Computing properties of molecular systems rely on estimating expectations of the (unnormalized) Boltzmann distribution. Molecular dynamics (MD) is a broadly adopted technique to approximate such quantities. However, stable simulations rely on very small integration time-steps ($10^{-15}\,\mathrm{s}$), whereas convergence of some moments, e.g. binding free energy or rates, might rely on sampling processes on time-scales as long as $10^{-1}\, \mathrm{s}$, and these simulations must be repeated for every molecular system independently. Here, we present Implict Transfer Operator (ITO) Learning, a framework to learn surrogates of the simulation process with multiple time-resolutions. We implement ITO with denoising diffusion probabilistic models with a new SE(3) equivariant architecture and show the resulting models can generate self-consistent stochastic dynamics across multiple time-scales, even when the system is only partially observed. Finally, we present a coarse-grained CG-SE3-ITO mo
    
[^108]: 通过赌博进行公平性审计

    Auditing Fairness by Betting. (arXiv:2305.17570v1 [stat.ML])

    [http://arxiv.org/abs/2305.17570](http://arxiv.org/abs/2305.17570)

    本文提供了一种通过赌博的方式进行公平性审计的方法，相比之前的方法，这种方法具有更高的实用性和效率，能够对不断产生的数据进行连续的监控，并处理因分布漂移导致的公平性问题。

    

    我们提供了实用、高效、非参数方法，用于审计已部署的分类和回归模型的公平性。相比之前依赖于固定样本量的方法，我们的方法是序贯的，并允许对不断产生的数据进行连续的监控，因此非常适用于跟踪现实世界系统的公平性。我们也允许数据通过概率策略进行收集，而不是从人口中均匀采样。这使得审计可以在为其他目的收集的数据上进行。此外，该策略可以随时间改变，并且不同的子人群可以使用不同的策略。最后，我们的方法可以处理因模型变更或基础人群变更导致的分布漂移。我们的方法基于最近关于 anytime-valid 推断和博弈统计学的进展，尤其是"通过赌博进行测试"框架。这些联系确保了我们的方法具有可解释性、快速和提供统计保证。

    We provide practical, efficient, and nonparametric methods for auditing the fairness of deployed classification and regression models. Whereas previous work relies on a fixed-sample size, our methods are sequential and allow for the continuous monitoring of incoming data, making them highly amenable to tracking the fairness of real-world systems. We also allow the data to be collected by a probabilistic policy as opposed to sampled uniformly from the population. This enables auditing to be conducted on data gathered for another purpose. Moreover, this policy may change over time and different policies may be used on different subpopulations. Finally, our methods can handle distribution shift resulting from either changes to the model or changes in the underlying population. Our approach is based on recent progress in anytime-valid inference and game-theoretic statistics-the "testing by betting" framework in particular. These connections ensure that our methods are interpretable, fast, 
    
[^109]: 因果成分分析

    Causal Component Analysis. (arXiv:2305.17225v1 [stat.ML])

    [http://arxiv.org/abs/2305.17225](http://arxiv.org/abs/2305.17225)

    本文介绍了一个中间问题：因果成分分析(CauCA)，它是独立成分分析(ICA)和因果表示学习(CRL)的泛化和特例，其目标是学习解混函数和因果机制，预设了因果图的知识。

    

    独立成分分析(ICA)的目标是从混合观测到的变量中恢复独立的潜在变量。而因果表示学习(CRL)的目标是推断因果关系强相关性的潜在变量，以及编码它们的因果关系的未知图。我们引入了一个中间问题，称为因果成分分析(CauCA)。CauCA可以被看作是ICA的一种推广，对潜在成分之间的因果依赖建模，也是CRL的一个特例。与CRL不同的是，它预设了因果图的知识，仅关注于学习解混函数和因果机制。所有关于CauCA回收基础真相的不可能结果也适用于CRL，而可能性结果可以作为扩展CRL的基础。我们将从对潜在因果变量实施不同类型干预的多个数据集中表征CauCA的可识别性。

    Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically dependent) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed Causal Component Analysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a
    
[^110]: 基于树的扩散薛定谔桥算法在Wasserstein重心中的应用

    Tree-Based Diffusion Schr\"odinger Bridge with Applications to Wasserstein Barycenters. (arXiv:2305.16557v1 [stat.ML])

    [http://arxiv.org/abs/2305.16557](http://arxiv.org/abs/2305.16557)

    本文介绍了一种基于树的扩散薛定谔桥算法(TreeDSB)来解决多元最优输运(mOT)的问题，并可以应用于高维设置如图像插值和贝叶斯融合。

    

    多元最优输运(mOT)是最优输运(OT)的一种推广，其旨在最小化成本函数相对于某些预先指定的边际分布的积分。本文考虑了一个树形二次成本的熵版本，即一种可以写作树节点之间成对成本函数之和的函数。为了解决这个问题，我们开发了Tree-based Diffusion Schr\"odinger Bridge(TreeDSB)，这是扩展了扩散薛定谔桥(DSB)算法的算法。TreeDSB对应于多元Sinkhorn算法的动态连续状态空间。我们方法的一个显著应用是计算Wasserstein重心，它可以被重新转化为基于星形树的mOT问题的解决方案。我们证明了我们的方法可以应用于高维设置，如图像插值和贝叶斯融合。

    Multi-marginal Optimal Transport (mOT), a generalization of OT, aims at minimizing the integral of a cost function with respect to a distribution with some prescribed marginals. In this paper, we consider an entropic version of mOT with a tree-structured quadratic cost, i.e., a function that can be written as a sum of pairwise cost functions between the nodes of a tree. To address this problem, we develop Tree-based Diffusion Schr\"odinger Bridge (TreeDSB), an extension of the Diffusion Schr\"odinger Bridge (DSB) algorithm. TreeDSB corresponds to a dynamic and continuous state-space counterpart of the multimarginal Sinkhorn algorithm. A notable use case of our methodology is to compute Wasserstein barycenters which can be recast as the solution of a mOT problem on a star-shaped tree. We demonstrate that our methodology can be applied in high-dimensional settings such as image interpolation and Bayesian fusion.
    
[^111]: DoWG展示：一种高效的通用无参数梯度下降方法

    DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method. (arXiv:2305.16284v1 [cs.LG])

    [http://arxiv.org/abs/2305.16284](http://arxiv.org/abs/2305.16284)

    本文提出了一种名为DoWG的无参数梯度下降方法，它是第一个既高效又通用的算法，能够自适应于平稳和非平稳问题，并且无需回溯搜索过程。

    

    本文提出了一种新的易于实现的无参数梯度优化器：DoWG（Weighted Gradients的距离）。我们证明了该方法是高效的——在不调整任何参数的情况下，匹配优化凸优化中最优调的梯度下降的收敛速度，直到对数因子，并且是通用的——自动适应平滑和非平滑问题。与AdaGrad，Adam或DoG等流行算法计算平方梯度的运行平均值不同，DoWG保持运行平均值的一种新的基于距离的加权版本，这对于实现所需的性质至关重要。据我们所知，DoWG是第一个不需要回溯搜索过程的无参数，高效和通用算法。它还是第一个适应于平稳优化的无参数AdaGrad样式算法。为了补充我们的理论，我们还通过实验证明DoWG在稳定的边缘训练，并证明其在实践中的有效性。

    This paper proposes a new easy-to-implement parameter-free gradient-based optimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG is efficient -- matching the convergence rate of optimally tuned gradient descent in convex optimization up to a logarithmic factor without tuning any parameters, and universal -- automatically adapting to both smooth and nonsmooth problems. While popular algorithms such as AdaGrad, Adam, or DoG compute a running average of the squared gradients, DoWG maintains a new distance-based weighted version of the running average, which is crucial to achieve the desired properties. To our best knowledge, DoWG is the first parameter-free, efficient, and universal algorithm that does not require backtracking search procedures. It is also the first parameter-free AdaGrad style algorithm that adapts to smooth optimization. To complement our theory, we also show empirically that DoWG trains at the edge of stability, and validate its effectiveness on practic
    
[^112]: 在协同学习和优化中激励竞争对手诚实行为的研究

    Incentivizing Honesty among Competitors in Collaborative Learning and Optimization. (arXiv:2305.16272v1 [cs.LG])

    [http://arxiv.org/abs/2305.16272](http://arxiv.org/abs/2305.16272)

    这项研究提出了一个模型来描述在协作学习中竞争对手的不诚实行为，提出了机制来激励诚实沟通，并确保学习质量与全面合作相当。

    

    协同学习技术能够让机器学习模型的训练比仅利用单一数据源的模型效果更好。然而，在许多情况下，潜在的参与者是下游任务中的竞争对手，如每个都希望通过提供最佳推荐来吸引客户的公司。这可能会激励不诚实的更新，损害其他参与者的模型，从而可能破坏协作的好处。在这项工作中，我们制定了一个模型来描述这种交互，并在该框架内研究了两个学习任务：单轮均值估计和强凸目标的多轮 SGD。对于一类自然的参与者行为，我们发现理性的客户会被激励强烈地操纵他们的更新，从而防止学习。然后，我们提出了机制来激励诚实沟通，并确保学习质量与全面合作相当。最后，我们通过实验证明了这一点。

    Collaborative learning techniques have the potential to enable training machine learning models that are superior to models trained on a single entity's data. However, in many cases, potential participants in such collaborative schemes are competitors on a downstream task, such as firms that each aim to attract customers by providing the best recommendations. This can incentivize dishonest updates that damage other participants' models, potentially undermining the benefits of collaboration. In this work, we formulate a game that models such interactions and study two learning tasks within this framework: single-round mean estimation and multi-round SGD on strongly-convex objectives. For a natural class of player actions, we show that rational clients are incentivized to strongly manipulate their updates, preventing learning. We then propose mechanisms that incentivize honest communication and ensure learning quality comparable to full cooperation. Lastly, we empirically demonstrate the
    
[^113]: 跳跃扩散模型实现的跨维度生成建模

    Trans-Dimensional Generative Modeling via Jump Diffusion Models. (arXiv:2305.16261v1 [stat.ML])

    [http://arxiv.org/abs/2305.16261](http://arxiv.org/abs/2305.16261)

    本文通过跳跃扩散模型实现了一种跨维度生成建模方法，并证明其在处理不同维度数据时具有更好的兼容性和插值能力。

    

    本文提出了一种新的生成模型，通过联合建模每个数据点的状态和尺寸，自然地处理不同维度的数据。该生成过程被定义为在不同维度空间之间进行跳跃扩散的过程。我们首先定义了一个破坏尺寸的前向噪声过程，然后推导出一个创造尺寸的逆向生成过程，以及一个新颖的证据下界训练目标来学习逼近该生成过程。通过模拟我们学习到的逆向生成过程的近似值，可以有效地联合生成状态值和尺寸，从而提供一种处理不同维度数据的有效方法。我们在分子和视频数据集上展示了我们的方法，相较于固定维度的模型，我们报告了更好的与测试时扩散引导插值任务兼容性和改进的插值能力。

    We propose a new class of generative models that naturally handle data of varying dimensionality by jointly modeling the state and dimension of each datapoint. The generative process is formulated as a jump diffusion process that makes jumps between different dimensional spaces. We first define a dimension destroying forward noising process, before deriving the dimension creating time-reversed generative process along with a novel evidence lower bound training objective for learning to approximate it. Simulating our learned approximation to the time-reversed generative process then provides an effective way of sampling data of varying dimensionality by jointly generating state values and dimensions. We demonstrate our approach on molecular and video datasets of varying dimensionality, reporting better compatibility with test-time diffusion guidance imputation tasks and improved interpolation capabilities versus fixed dimensional models that generate state values and dimensions separate
    
[^114]: Koopman核回归

    Koopman Kernel Regression. (arXiv:2305.16215v1 [cs.LG])

    [http://arxiv.org/abs/2305.16215](http://arxiv.org/abs/2305.16215)

    提出了一种基于Koopman核的回归方法，用于预测非线性动力系统的时间演变。该方法在机器人操作，视频预测和交通预测等各种应用中均有优异表现，并具有可证明的学习理论保证。

    

    许多决策制定的机器学习方法，如强化学习，依赖于模拟器或预测模型来预测感兴趣的量的时间演变，例如智能体的状态或策略的奖励。这些复杂现象的预测通常由高度非线性的动力系统描述，使得它们在基于优化的决策制定中的使用具有挑战性。Koopman算子理论通过通过线性动态系统描述预测来解决这个问题。这使得系统分析和长期预测变得简单--只涉及矩阵乘法。然而，将其转化为线性系统通常是非平凡的和未知的，需要基于学习的方法。虽然存在各种方法，但它们通常缺乏关键的学习理论保证，因此所获得的模型在数据和维度增加时的行为通常不清楚。通过提出一种新颖的基于Koopman核的回归方法，我们解决了上述挑战，该方法直接从历史观察中学习到未来预测在Koopman算子空间中的映射。我们的方法享有可证明的学习理论保证，并在广泛的应用中与现有的最先进方法匹配（或优于），包括机器人操作，视频预测和交通预测。

    Many machine learning approaches for decision making, such as reinforcement learning, rely on simulators or predictive models to forecast the time-evolution of quantities of interest, e.g., the state of an agent or the reward of a policy. Forecasts of such complex phenomena are commonly described by highly nonlinear dynamical systems, making their use in optimization-based decision-making challenging. Koopman operator theory offers a beneficial paradigm for addressing this problem by characterizing forecasts via linear dynamical systems. This makes system analysis and long-term predictions simple -- involving only matrix multiplications. However, the transformation to a linear system is generally non-trivial and unknown, requiring learning-based approaches. While there exists a variety of approaches, they usually lack crucial learning-theoretic guarantees, such that the behavior of the obtained models with increasing data and dimensionality is often unclear. We address the aforemention
    
[^115]: 差分隐私潜在扩散模型

    Differentially Private Latent Diffusion Models. (arXiv:2305.15759v1 [stat.ML])

    [http://arxiv.org/abs/2305.15759](http://arxiv.org/abs/2305.15759)

    本文提出使用差分隐私训练潜在扩散模型(LDMs)，通过预训练自编码器将高维像素空间转变为低维潜在空间实现更高效快速的DMs训练，并且通过只微调注意力模块减少了可训练参数的数量。

    

    扩散模型(DMs)被广泛用于生成高质量图像数据集。然而，由于它们直接在高维像素空间中运行，DMs的优化计算成本高，需要长时间的训练。这导致由于差分隐私的可组合性属性，大量噪音注入到差分隐私学习过程中。为了解决这个挑战，我们提出使用差分隐私训练潜在扩散模型(LDMs)。LDMs使用强大的预训练自编码器将高维像素空间减少到更低维的潜在空间，使训练DMs更加高效和快速。与[Ghalebikesabi等人，2023]预先用公共数据预训练DMs，然后再用隐私数据进行微调不同，我们仅微调LDMs中不同层的注意力模块以获得隐私敏感数据，相对于整个DM微调，可减少大约96%的可训练参数数量。

    Diffusion models (DMs) are widely used for generating high-quality image datasets. However, since they operate directly in the high-dimensional pixel space, optimization of DMs is computationally expensive, requiring long training times. This contributes to large amounts of noise being injected into the differentially private learning process, due to the composability property of differential privacy. To address this challenge, we propose training Latent Diffusion Models (LDMs) with differential privacy. LDMs use powerful pre-trained autoencoders to reduce the high-dimensional pixel space to a much lower-dimensional latent space, making training DMs more efficient and fast. Unlike [Ghalebikesabi et al., 2023] that pre-trains DMs with public data then fine-tunes them with private data, we fine-tune only the attention modules of LDMs at varying layers with privacy-sensitive data, reducing the number of trainable parameters by approximately 96% compared to fine-tuning the entire DM. We te
    
[^116]: 黑盒变分推断收敛性分析

    Black-Box Variational Inference Converges. (arXiv:2305.15349v1 [cs.LG])

    [http://arxiv.org/abs/2305.15349](http://arxiv.org/abs/2305.15349)

    通过对黑盒变分推断（BBVI）的分析，发现一些常见的算法设计选择可能会导致次优收敛速率，但使用带有近端随机梯度下降的BBVI可以实现最强收敛率保证。

    

    我们提供了第一个完整的黑盒变分推断（BBVI）的收敛保证，也称为蒙特卡罗变分推断。尽管早期的研究只针对简化版本的BBVI进行了研究（例如，有界域、有界支持、仅针对尺度进行优化等），但我们的设置不需要任何这样的算法修改。我们的结果适用于对数平滑后验密度，无论是否强对数凹性以及位置-尺度变分族。此外，我们的分析揭示出了一些常见的算法设计选择，特别是变分近似尺度的非线性参数化，可能会导致次优收敛速率。幸运的是，运行带有近端随机梯度下降的BBVI可以纠正这些限制，从而实现已知的最强收敛率保证。我们通过将近端SGD与其他标准的BBVI实现进行比较，验证了这一理论结论在大规模数据集上的有效性。

    We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale
    
[^117]: 训练基于能量的归一化流模型的得分匹配目标

    Training Energy-Based Normalizing Flow with Score-Matching Objectives. (arXiv:2305.15267v1 [cs.LG])

    [http://arxiv.org/abs/2305.15267](http://arxiv.org/abs/2305.15267)

    本文提出一种新的基于能量的归一化流模型（EBFlow），通过得分匹配目标优化使其训练更高效，同时开发一些技术增强EBFlow的训练稳定性和实证表现。

    

    本文建立了流模型和能量模型参数化之间的联系，并提出了一种新的基于能量的归一化流建模方法（EBFlow）。我们展示了通过得分匹配目标优化EBFlow，可以完全避开线性变换的雅可比行列式计算。这使得EBFlow在构建基于流的模型时使用任意线性层，而不会使每个训练迭代的计算时间复杂度从$\mathcal{O}(D^2L)$增加到$\mathcal{O}(D^3L)$，其中$L$为层数，$D$为输入维度。这使得EBFlow的训练比常用的最大似然训练方法更高效。除了减少运行时间外，我们通过基于分值匹配方法的分析开发了一些技术，以增强EBFlow的训练稳定性和实证表现。

    In this paper, we establish a connection between the parameterization of flow-based and energy-based generative models, and present a new flow-based modeling approach called energy-based normalizing flow (EBFlow). We demonstrate that by optimizing EBFlow with score-matching objectives, the computation of Jacobian determinants for linear transformations can be entirely bypassed. This feature enables the use of arbitrary linear layers in the construction of flow-based models without increasing the computational time complexity of each training iteration from $\mathcal{O}(D^2L)$ to $\mathcal{O}(D^3L)$ for an $L$-layered model that accepts $D$-dimensional inputs. This makes the training of EBFlow more efficient than the commonly-adopted maximum likelihood training method. In addition to the reduction in runtime, we enhance the training stability and empirical performance of EBFlow through a number of techniques developed based on our analysis on the score-matching methods. The experimental
    
[^118]: 判别校准

    Discriminative calibration. (arXiv:2305.14593v1 [stat.ML])

    [http://arxiv.org/abs/2305.14593](http://arxiv.org/abs/2305.14593)

    这篇论文提出了一种替代基于排序的模拟校准（SBC）的灵活分类方法，该方法可以从数据中学习测试统计量，并计算出从分类准确度中计算出的误校准发散度度量，具有更高的统计功效，可以解决多重检验的挑战。

    

    为了检验贝叶斯计算的准确性，常常使用基于排序的模拟校准（SBC）。然而，SBC 存在一些缺点：测试统计量略显随意，交互性难以检查，多重检验是一个挑战，并且得到的 P 值不是一种发散度度量。我们提出用一种灵活的分类方法替换边缘排序检验，该方法可以从数据中学习测试统计量。该度量通常具有比 SBC 排名检验更高的统计功效，并返回从分类准确度计算出的可解释的误校准发散度度量。此方法可以与不同的数据生成过程一起使用，以应对无需似然推断或传统推断方法（如马尔科夫链蒙特卡罗或变分推断）。我们使用神经网络和统计学启发式特征演示了一种自动化实现，并用数值和真实数据实验验证了该方法。

    To check the accuracy of Bayesian computations, it is common to use rank-based simulation-based calibration (SBC). However, SBC has drawbacks: The test statistic is somewhat ad-hoc, interactions are difficult to examine, multiple testing is a challenge, and the resulting p-value is not a divergence metric. We propose to replace the marginal rank test with a flexible classification approach that learns test statistics from data. This measure typically has a higher statistical power than the SBC rank test and returns an interpretable divergence measure of miscalibration, computed from classification accuracy. This approach can be used with different data generating processes to address likelihood-free inference or traditional inference methods like Markov chain Monte Carlo or variational inference. We illustrate an automated implementation using neural networks and statistically-inspired features, and validate the method with numerical and real data experiments.
    
[^119]: 最优预条件和费舍尔自适应 Langevin 采样

    Optimal Preconditioning and Fisher Adaptive Langevin Sampling. (arXiv:2305.14442v1 [stat.ML])

    [http://arxiv.org/abs/2305.14442](http://arxiv.org/abs/2305.14442)

    通过最优预条件和费舍尔自适应 Langevin 采样，提出了一种计算有效且在高维中非常强健的自适应 MCMC 方案。

    

    我们通过分析最大化预期平方跳跃距离，为 Langevin 扩散定义了最优预条件。这导致最优预条件为反费舍尔信息协方差矩阵，其中协方差矩阵是在目标下平均对数目标梯度的外积。我们将此结果应用于 Metropolis 调整 Langevin 算法 (MALA)，并推导出一种从算法运行产生的梯度历史中学习预条件的计算有效的自适应 MCMC 方案。我们在几个实验中展示了所提出的算法在高维中非常强健，并且明显优于其他方法，包括使用标准自适应 MCMC 学习预条件和位置相关的 Riemann 流形 MALA 采样器的密切相关的自适应 MALA 方案。

    We define an optimal preconditioning for the Langevin diffusion by analytically maximizing the expected squared jumped distance. This yields as the optimal preconditioning an inverse Fisher information covariance matrix, where the covariance matrix is computed as the outer product of log target gradients averaged under the target. We apply this result to the Metropolis adjusted Langevin algorithm (MALA) and derive a computationally efficient adaptive MCMC scheme that learns the preconditioning from the history of gradients produced as the algorithm runs. We show in several experiments that the proposed algorithm is very robust in high dimensions and significantly outperforms other methods, including a closely related adaptive MALA scheme that learns the preconditioning with standard adaptive MCMC as well as the position-dependent Riemannian manifold MALA sampler.
    
[^120]: 关于高斯-斯坦变分梯度下降动态性的探究

    Towards Understanding the Dynamics of Gaussian--Stein Variational Gradient Descent. (arXiv:2305.14076v1 [math.ST])

    [http://arxiv.org/abs/2305.14076](http://arxiv.org/abs/2305.14076)

    本文探究了高斯-斯坦变分梯度下降动态性。对于从高斯目标中采样，只要初始值是高斯的，具有双线性核的SVGD动态将保持高斯状态。当目标函数呈现出强对数凹性时，证明了均场高斯-SVGD动态会线性收敛于KL散度下最接近目标高斯分布。在有限粒子设置中，存在对均场极限的时间微步一致收敛以及线性收敛至目标高斯分布。

    

    Stein Variational Gradient Descent (SVGD)是一种非参数基于粒子的确定性采样算法。尽管其被广泛使用，但理解SVGD的理论属性一直是一个具有挑战性的问题。对于从高斯目标中采样，只要初始值是高斯的，具有双线性核的SVGD动态将保持高斯状态。受此事实的启发，我们通过双线性核将SVGD投影到高斯分布族中，即高斯变分推断 (GVI) 与 SVGD。我们通过考虑均场 PDE 和离散粒子系统，提供了一个完整的图像。当目标函数呈现出强对数凹性时，证明了均场高斯-SVGD动态会线性收敛于KL散度下最接近目标高斯分布。在有限粒子设置中，存在对均场极限的时间微步一致收敛以及线性收敛至目标高斯分布。我们的分析基于一个新的代数恒等式，该等式将目标高斯分布的费希尔信息矩阵与粒子均匀分布的费希尔信息矩阵相关联。这个等式为我们提供了透视 GVI with SVGD 在均场和粒子设置中的动态性的统一视角。

    Stein Variational Gradient Descent (SVGD) is a nonparametric particle-based deterministic sampling algorithm. Despite its wide usage, understanding the theoretical properties of SVGD has remained a challenging problem. For sampling from a Gaussian target, the SVGD dynamics with a bilinear kernel will remain Gaussian as long as the initializer is Gaussian. Inspired by this fact, we undertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGD projected to the family of Gaussian distributions via the bilinear kernel, or equivalently Gaussian variational inference (GVI) with SVGD. We present a complete picture by considering both the mean-field PDE and discrete particle systems. When the target is strongly log-concave, the mean-field Gaussian-SVGD dynamics is proven to converge linearly to the Gaussian distribution closest to the target in KL divergence. In the finite-particle setting, there is both uniform in time convergence to the mean-field limit and linear convergence in ti
    
[^121]: （带噪声的）随机梯度下降的时间均匀Wasserstein稳定性界限

    Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent. (arXiv:2305.12056v1 [stat.ML])

    [http://arxiv.org/abs/2305.12056](http://arxiv.org/abs/2305.12056)

    本文通过建立学习理论和应用概率之间的联系，提出了一种证明随机优化算法Wasserstein稳定性界限的统一指南，并在随机梯度下降上验证了该方法的有效性，包括强凸损失和带添加噪声的非凸损失。

    

    算法稳定性是一个重要的概念，对于推导实践算法的泛化界限已被证明是有用的。过去十年已经见证了不同损失函数所应用的不同算法的稳定性界限的增加。虽然这些界限照亮了优化算法的各种属性，但每个案例的分析通常需要不同的证明技术和显著不同的数学工具。在本研究中，我们在学习理论和应用概率之间建立了新的联系，并介绍了一种证明随机优化算法的Wasserstein稳定性界限的统一指南。我们在随机梯度下降（SGD）上阐述了我们的方法，并获得了强凸损失和带添加噪声的非凸损失的时间均匀稳定性界限（即，界限不随迭代次数增加而增加），在这些情况下，我们恢复了与先前文献相似的结果或将它们扩展到更广泛。

    Algorithmic stability is an important notion that has proven powerful for deriving generalization bounds for practical algorithms. The last decade has witnessed an increasing number of stability bounds for different algorithms applied on different classes of loss functions. While these bounds have illuminated various properties of optimization algorithms, the analysis of each case typically required a different proof technique with significantly different mathematical tools. In this study, we make a novel connection between learning theory and applied probability and introduce a unified guideline for proving Wasserstein stability bounds for stochastic optimization algorithms. We illustrate our approach on stochastic gradient descent (SGD) and we obtain time-uniform stability bounds (i.e., the bound does not increase with the number of iterations) for strongly convex losses and non-convex losses with additive noise, where we recover similar results to the prior art or extend them to mor
    
[^122]: 在线学习者的攻击：一项教师-学生分析

    Attacks on Online Learners: a Teacher-Student Analysis. (arXiv:2305.11132v1 [stat.ML])

    [http://arxiv.org/abs/2305.11132](http://arxiv.org/abs/2305.11132)

    本文利用控制理论的视角研究了在线学习环境下可能遭受到的标签扰动攻击情况，得出攻击强度超过临界阈值时学习准确率将出现不连续转变的结论，并验证了理论在复杂结构学习器上的适用性。

    

    机器学习模型通常容易受到对抗性攻击：数据的微小扰动可能会使模型的预测结果产生灾难性的影响。虽然大量的文献研究了对已经预先训练的模型进行测试时的攻击情况，但在线学习环境下的攻击情况却鲜有研究。本文使用控制理论的视角研究了在线学习者可能存在的标签扰动攻击情况，考虑了不同的攻击策略，并针对简单线性学习器的稳态获得了分析结果。这些结果可以证明，当攻击强度超过临界阈值时，学习器的准确率会出现不连续的转变。然后我们使用真实数据对复杂结构的学习器进行了实证分析，验证了理论分析的洞见并揭示了遭受攻击的学习器的新行为。

    Machine learning models are famously vulnerable to adversarial attacks: small ad-hoc perturbations of the data that can catastrophically alter the model predictions. While a large literature has studied the case of test-time attacks on pre-trained models, the important case of attacks in an online learning setting has received little attention so far. In this work, we use a control-theoretical perspective to study the scenario where an attacker may perturb data labels to manipulate the learning dynamics of an online learner. We perform a theoretical analysis of the problem in a teacher-student setup, considering different attack strategies, and obtaining analytical results for the steady state of simple linear learners. These results enable us to prove that a discontinuous transition in the learner's accuracy occurs when the attack strength exceeds a critical threshold. We then study empirically attacks on learners with complex architectures using real data, confirming the insights of 
    
[^123]: 多智能体强化学习中的信息设计

    Information Design in Multi-Agent Reinforcement Learning. (arXiv:2305.06807v1 [cs.GT])

    [http://arxiv.org/abs/2305.06807](http://arxiv.org/abs/2305.06807)

    本文探究了多智能体强化学习中的信息设计问题及其挑战，提出了“马尔科夫信令博弈”的概念。

    

    强化学习（RL）模仿人类和动物与环境交互的方式。然而实际环境中存在其他有自己目标的智能体，它们会适应地与自己相互作用。因此，为了在这些环境中成功，自主智能体需要影响其他智能体以使它们的行为更有益。信息设计是影响其他智能体行为的一种方法。本文探讨了针对一组RL代理的信息设计问题，并提出了“马尔科夫信令博弈”的概念。

    Reinforcement learning (RL) mimics how humans and animals interact with the environment. The setting is somewhat idealized because, in actual tasks, other agents in the environment have their own goals and behave adaptively to the ego agent. To thrive in those environments, the agent needs to influence other agents so their actions become more helpful and less harmful. Research in computational economics distills two ways to influence others directly: by providing tangible goods (mechanism design) and by providing information (information design). This work investigates information design problems for a group of RL agents. The main challenges are two-fold. One is the information provided will immediately affect the transition of the agent trajectories, which introduces additional non-stationarity. The other is the information can be ignored, so the sender must provide information that the receivers are willing to respect. We formulate the Markov signaling game, and develop the notions 
    
[^124]: 解密高斯混合专家模型中的Softmax门控问题

    Demystifying Softmax Gating in Gaussian Mixture of Experts. (arXiv:2305.03288v1 [stat.ML])

    [http://arxiv.org/abs/2305.03288](http://arxiv.org/abs/2305.03288)

    本文提出了新的参数Vononoi损失函数并建立了MLE的收敛速度来解决高斯混合专家模型中的Softmax门控问题，研究表明该门控与高斯分布中的专家函数通过偏微分方程相互作用，是一个复杂依赖关系。

    

    理解Softmax门控高斯混合专家模型的参数估计一直是文献中长期未解决的问题。这主要是由于三个基本理论挑战与Softmax门控相关：（i）只能识别参数的平移；（ii）Softmax门控和高斯分布中专家函数之间通过偏微分方程的内在相互作用；（iii）Softmax门控高斯混合专家模型的条件密度的分子和分母之间的复杂依赖关系。我们通过提出新的参数Vononoi损失函数并建立MLE的收敛速度来解决这些挑战，用于解决这些模型的参数估计。当专家数量未知且超额指定时，我们的发现表明MLE的速率与一组多项式方程的可解性问题有关。

    Understanding parameter estimation of softmax gating Gaussian mixture of experts has remained a long-standing open problem in the literature. It is mainly due to three fundamental theoretical challenges associated with the softmax gating: (i) the identifiability only up to the translation of the parameters; (ii) the intrinsic interaction via partial differential equation between the softmax gating and the expert functions in Gaussian distribution; (iii) the complex dependence between the numerator and denominator of the conditional density of softmax gating Gaussian mixture of experts. We resolve these challenges by proposing novel Vononoi loss functions among parameters and establishing the convergence rates of the maximum likelihood estimator (MLE) for solving parameter estimation in these models. When the number of experts is unknown and over-specified, our findings show a connection between the rate of MLE and a solvability problem of a system of polynomial equations.
    
[^125]: 域不可知傅里叶神经算子

    Domain Agnostic Fourier Neural Operators. (arXiv:2305.00478v1 [cs.LG])

    [http://arxiv.org/abs/2305.00478](http://arxiv.org/abs/2305.00478)

    介绍了一种新的神经算子架构 DAFNO，可以学习带有不规则几何和不断变化的域的代理。通过将平滑化的特征函数纳入 FNOs 的积分层架构中，并利用 FFT 来实现快速计算，以明确的方式将几何信息编码到架构中，DAFNO 相对于基线神经算子模型具有最先进的精度。

    

    傅里叶神经算子（FNOs）能够学习在函数空间之间高度非线性的映射，最近已成为学习复杂物理系统响应的热门工具。然而，为了实现良好的精度和效率，FNOs 依赖于快速傅里叶变换 (FFT)，该变换仅限于矩形域上的建模问题。为了消除这样的限制，允许 FFT 在不规则几何以及拓扑变化中使用，我们引入了域不可知傅里叶神经算子 (DAFNO)，一种用于学习带有不规则几何和不断变化的域的代理的新的神经算子架构。关键思想是将平滑化的特征函数纳入 FNOs 的积分层架构中，并利用 FFT 来实现快速计算，以便以明确的方式将几何信息编码到架构中。在我们的实证评估中，DAFNO 相对于基线神经算子模型具有最先进的精度。

    Fourier neural operators (FNOs) can learn highly nonlinear mappings between function spaces, and have recently become a popular tool for learning responses of complex physical systems. However, to achieve good accuracy and efficiency, FNOs rely on the Fast Fourier transform (FFT), which is restricted to modeling problems on rectangular domains. To lift such a restriction and permit FFT on irregular geometries as well as topology changes, we introduce domain agnostic Fourier neural operator (DAFNO), a novel neural operator architecture for learning surrogates with irregular geometries and evolving domains. The key idea is to incorporate a smoothed characteristic function in the integral layer architecture of FNOs, and leverage FFT to achieve rapid computations, in such a way that the geometric information is explicitly encoded in the architecture. In our empirical evaluation, DAFNO has achieved state-of-the-art accuracy as compared to baseline neural operator models on two benchmark dat
    
[^126]: 探索外部分布广义化中的特征学习

    Towards Understanding Feature Learning in Out-of-Distribution Generalization. (arXiv:2304.11327v1 [cs.LG])

    [http://arxiv.org/abs/2304.11327](http://arxiv.org/abs/2304.11327)

    研究发现，ERM本质上同时学习了具有误导性的特征和不变特征，在ERM预训练期间学习到的特征质量影响了最终的OOD性能，未能捕获所有潜在的有用特征将限制最终的OOD性能。

    

    对于外部分布（OOD）广义化的失败，常见的解释是使用经验风险最小化（ERM）模型学习到具有误导性的特征而不是期望的不变特征。然而，最近的几项研究挑战了这种解释，发现深度网络可能已经学到了足够好的特征进行OOD广义化。这场辩论扩展到了许多OOD广义化任务的训练或微调神经网络的内部组织和OOD性能相关性中。为了理解这些似乎相互矛盾的现象，我们进行了理论研究，发现ERM本质上同时学习了具有误导性的特征和不变特征。另一方面，在ERM预训练期间学习到的特征质量显著影响了最终的OOD性能，因为OOD对象很少学习到新功能。未能在预训练期间捕获所有潜在的有用特征将进一步限制最终的OOD性能。

    A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of the desired invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. The debate extends to the in-distribution and OOD performance correlations along with training or fine-tuning neural nets across a variety of OOD generalization tasks. To understand these seemingly contradicting phenomena, we conduct a theoretical investigation and find that ERM essentially learns both spurious features and invariant features. On the other hand, the quality of learned features during ERM pre-training significantly affects the final OOD performance, as OOD objectives rarely learn new features. Failing to capture all the underlying useful features during pre-training will further limit the final OOD
    
[^127]: 基于平均二阶相似性的随机分布式优化：算法与分析

    Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis. (arXiv:2304.07504v1 [cs.LG])

    [http://arxiv.org/abs/2304.07504](http://arxiv.org/abs/2304.07504)

    本文提出了两种新算法SVRS和AccSVRS，针对分布式优化问题，实现了卓越的通信复杂度。其中，AccSVRS算法实现了完全无平滑性，通信复杂度更是优于现有算法。

    

    本文研究了具有$n$个客户端的有限和分布式优化问题，满足流行的$\delta$-相似性条件和$\mu$-强凸性。我们提出了两种新算法：SVRS和AccSVRS，启发自先前的工作。非加速的SVRS方法结合了梯度滑动和方差缩减技术，实现了卓越的通信复杂度$\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$，与现有的非加速算法相比有所提高。应用Katyusha X提出的框架，我们还建立了一个名为AccSVRS的直接加速实际版本，其完全无平滑性，通信复杂度为$\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$，在病态情况下优于现有算法。此外，我们展示了一种接近匹配的下界，以验证我们的AccSVRS方法的紧密程度。

    We study finite-sum distributed optimization problems with $n$-clients under popular $\delta$-similarity condition and $\mu$-strong convexity. We propose two new algorithms: SVRS and AccSVRS motivated by previous works. The non-accelerated SVRS method combines the techniques of gradient-sliding and variance reduction, which achieves superior communication complexity $\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$ compared to existing non-accelerated algorithms. Applying the framework proposed in Katyusha X, we also build a direct accelerated practical version named AccSVRS with totally smoothness-free $\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$ communication complexity that improves upon existing algorithms on ill-conditioning cases. Furthermore, we show a nearly matched lower bound to verify the tightness of our AccSVRS method.
    
[^128]: 基于贝叶斯渐近性的Gibbs抽样器复杂性

    Complexity of Gibbs samplers through Bayesian asymptotics. (arXiv:2304.06993v1 [stat.CO])

    [http://arxiv.org/abs/2304.06993](http://arxiv.org/abs/2304.06993)

    本文介绍了一种基于贝叶斯渐近性工具的方法，用于分析Gibbs抽样器的混合时间的渐近行为，并在随机数据生成假设下获得了对于具有通用似然函数的广泛的二级模型的无维度收敛结果。

    

    Gibbs抽样器是用于近似来自贝叶斯分层模型的后验分布的流行算法。尽管它们非常流行且表现良好，但是关于它们的可扩展性或不可扩展性的定量理论结果相对较少，例如，比基于梯度的抽样方法要少得多。本文介绍了一种基于贝叶斯渐近性工具的新技术，用于分析Gibbs抽样器的混合时间的渐近行为。我们将我们的方法应用于高维分层模型，并在随机数据生成假设下获得了对于具有通用似然函数的广泛的二级模型的无维度收敛结果。讨论了具有高斯、二项式和分类似然的具体示例。

    Gibbs samplers are popular algorithms to approximate posterior distributions arising from Bayesian hierarchical models. Despite their popularity and good empirical performances, however, there are still relatively few quantitative theoretical results on their scalability or lack thereof, e.g. much less than for gradient-based sampling methods. We introduce a novel technique to analyse the asymptotic behaviour of mixing times of Gibbs Samplers, based on tools of Bayesian asymptotics. We apply our methodology to high dimensional hierarchical models, obtaining dimension-free convergence results for Gibbs samplers under random data-generating assumptions, for a broad class of two-level models with generic likelihood function. Specific examples with Gaussian, binomial and categorical likelihoods are discussed.
    
[^129]: 对数凹采样的查询下界

    Query lower bounds for log-concave sampling. (arXiv:2304.02599v1 [math.ST])

    [http://arxiv.org/abs/2304.02599](http://arxiv.org/abs/2304.02599)

    该论文研究了对数凹采样的查询下界，在强对数凹和对数光滑分布中采样需要 $\Omega(\log \kappa)$ 查询，在采样高斯分布中需要 $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ 查询。

    

    最近几年，对数凹采样在算法方面取得了显著的进展，但相应的证明此任务的下界的问题仍然很难，以前只知道在一维中存在较小的下界。在这项工作中，我们建立了以下查询下界：（1）在维度 $d\ge 2$中从强对数凹和对数光滑分布中采样需要 $\Omega(\log \kappa)$ 查询，这在任何固定维度上都是最优的，（2）从高斯分布中采样需要 $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ 查询（因此也适用于在维数 $d$ 中采样一般的对数凹和光滑分布），这对于高斯类几乎是最优的。这里 $\kappa$ 是目标分布的条件数。我们的证明依赖于（1）一种多尺度构造，受到了关于谐振分析中的Kakeya猜想的工作的启发，以及（2）一种新颖的约简，证明了块Krylov算法在此问题中是最佳的。

    Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one. In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\ge 2$ requires $\Omega(\log \kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ queries, which is nearly sharp for the class of Gaussians. Here $\kappa$ denotes the condition number of the target distribution. Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this probl
    
[^130]: 基于扩散映射的粒子系统用于生成模型

    Diffusion map particle systems for generative modeling. (arXiv:2304.00200v1 [stat.ML])

    [http://arxiv.org/abs/2304.00200](http://arxiv.org/abs/2304.00200)

    本文提出一种新型扩散映射粒子系统(DMPS)，可以用于高效生成建模，实验表明在包含流形结构的合成数据集上取得了比其他方法更好的效果。

    

    本文提出了一种新颖的扩散映射粒子系统(DMPS)，用于生成建模，该方法基于扩散映射和Laplacian调整的Wasserstein梯度下降（LAWGD）。扩散映射被用来从样本中近似Langevin扩散过程的生成器，从而学习潜在的数据生成流形。另一方面，LAWGD能够在合适的核函数选择下高效地从目标分布中抽样，我们在这里通过扩散映射计算生成器的谱逼近来构造核函数。数值实验表明，我们的方法在包括具有流形结构的合成数据集上优于其他方法。

    We propose a novel diffusion map particle system (DMPS) for generative modeling, based on diffusion maps and Laplacian-adjusted Wasserstein gradient descent (LAWGD). Diffusion maps are used to approximate the generator of the Langevin diffusion process from samples, and hence to learn the underlying data-generating manifold. On the other hand, LAWGD enables efficient sampling from the target distribution given a suitable choice of kernel, which we construct here via a spectral approximation of the generator, computed with diffusion maps. Numerical experiments show that our method outperforms others on synthetic datasets, including examples with manifold structure.
    
[^131]: 超越负采样的高效分布式表示方法

    Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])

    [http://arxiv.org/abs/2303.17475](http://arxiv.org/abs/2303.17475)

    本文介绍了一种高效的分布式表示（嵌入）学习方法，通过线性时间估计softmax归一化常数来实现学习过程，该方法优于负采样方法并在多项测试中验证了其有效性。

    

    本文介绍了一种高效的学习分布式表示（也称为嵌入）的方法。该方法通过最小化一个类似于Word2Vec算法中引入并在多个工作中采用的目标函数来实现。优化计算的瓶颈是softmax归一化常数的计算，这需要与样本大小呈二次比例的操作数。这种复杂度不适用于大型数据集，所以负采样是一个常见的解决方法，可以在与样本大小线性相关的时间内获得分布式表示。然而，负采样会改变损失函数，因此解决的是与最初提出的不同的优化问题。我们的贡献在于展示如何通过线性时间估计softmax归一化常数，从而设计了一种有效的优化策略来学习分布式表示。我们使用不同的数据集进行测试，并展示了我们的方法在嵌入质量和训练时间方面优于负采样。

    This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
    
[^132]: 浅层复值神经网络对$C^k$-函数的最优逼近

    Optimal approximation of $C^k$-functions using shallow complex-valued neural networks. (arXiv:2303.16813v1 [math.FA])

    [http://arxiv.org/abs/2303.16813](http://arxiv.org/abs/2303.16813)

    本文证明了对于$C^k$（在实变量意义下）的函数，使用具有单层隐藏层和$m$个神经元的神经网络可以以错误率$m^{-k/(2n)}$将其逼近。此外，如果选取权值$\sigma_j,b_j\in\mathbb{C}$和$\rho_j\in\mathbb{C}^n$对$f$连续，那么获得的逼近速率是最优的。

    

    本文证明了使用浅层复值神经网络对复立方体上$C^k$（在实变量意义下）的函数进行逼近的量化结果。具体而言，我们考虑具有单层隐藏层和$m$个神经元的神经网络，即形如$z \mapsto \sum_{j=1}^m \sigma_j \cdot \phi\big(\rho_j^T z + b_j\big)$的网络，并且证明了可以使用这种形式的函数逼近$C^k \left(\Omega_n;\mathbb{C}\right)$中的任何函数，当$m\to\infty$时误差为$m^{-k/(2n)}$.此外，我们还证明选取权值$\sigma_j,b_j\in\mathbb{C}$和$\rho_j\in\mathbb{C}^n$对$f$连续并且在这种连续性假设下获得的逼近速率是最优的。

    We prove a quantitative result for the approximation of functions of regularity $C^k$ (in the sense of real variables) defined on the complex cube $\Omega_n := [-1,1]^n +i[-1,1]^n\subseteq \mathbb{C}^n$ using shallow complex-valued neural networks. Precisely, we consider neural networks with a single hidden layer and $m$ neurons, i.e., networks of the form $z \mapsto \sum_{j=1}^m \sigma_j \cdot \phi\big(\rho_j^T z + b_j\big)$ and show that one can approximate every function in $C^k \left( \Omega_n; \mathbb{C}\right)$ using a function of that form with error of the order $m^{-k/(2n)}$ as $m \to \infty$, provided that the activation function $\phi: \mathbb{C} \to \mathbb{C}$ is smooth but not polyharmonic on some non-empty open set. Furthermore, we show that the selection of the weights $\sigma_j, b_j \in \mathbb{C}$ and $\rho_j \in \mathbb{C}^n$ is continuous with respect to $f$ and prove that the derived rate of approximation is optimal under this continuity assumption. We also discuss
    
[^133]: 针对非线性部分可观测系统的局部线性化概率逆优化控制方法

    Probabilistic inverse optimal control with local linearization for non-linear partially observable systems. (arXiv:2303.16698v1 [cs.LG])

    [http://arxiv.org/abs/2303.16698](http://arxiv.org/abs/2303.16698)

    本文介绍了一种针对非线性部分可观测系统的局部线性化概率逆优化控制方法，可用于特征化顺序决策任务中的行为，并且具有广泛的适用性。

    

    逆优化控制方法可以用于特征化顺序决策任务中的行为。然而，大多数现有的工作要求已知控制信号，或者仅限于完全可观测或线性系统。本文介绍了一种概率逆优化控制方法，用于非线性随机系统的丢失控制信号和部分可观测性，该方法统一了现有方法。通过使用代理的感觉和控制系统的噪声特征的显式模型以及局部线性化技术，我们推导出了模型参数的近似似然函数，可以在单个正向传递中计算。我们在随机和部分可观测版本的经典控制任务，导航任务和手动达到任务上评估了我们提出的方法。该方法具有广泛的适用性，可用于模仿学习到感觉运动神经科学。

    Inverse optimal control methods can be used to characterize behavior in sequential decision-making tasks. Most existing work, however, requires the control signals to be known, or is limited to fully-observable or linear systems. This paper introduces a probabilistic approach to inverse optimal control for stochastic non-linear systems with missing control signals and partial observability that unifies existing approaches. By using an explicit model of the noise characteristics of the sensory and control systems of the agent in conjunction with local linearization techniques, we derive an approximate likelihood for the model parameters, which can be computed within a single forward pass. We evaluate our proposed method on stochastic and partially observable version of classic control tasks, a navigation task, and a manual reaching task. The proposed method has broad applicability, ranging from imitation learning to sensorimotor neuroscience.
    
[^134]: PDExplain：PDEs 在实际应用中的情境建模

    PDExplain: Contextual Modeling of PDEs in the Wild. (arXiv:2303.15827v1 [cs.LG])

    [http://arxiv.org/abs/2303.15827](http://arxiv.org/abs/2303.15827)

    我们提出了PDExplain，一种解释性的方法来解决偏微分方程。该算法能够通过提供少量样本的方式，预测未来时间步的PDE解，极大地协助了建立物理科学中基于数据的现象建模。

    

    我们提出了一种解释性的方法PDExplain用于解决偏微分方程。在训练阶段，我们的方法通过一个操作员定义的PDE家族的数据以及这个家族的一般形式进行馈送。在推断阶段，提供了一个从现象中收集到的最小样本，其中样本与 PDE 家族相关，但不一定属于训练阶段看到的具体 PDE 集合。我们展示了算法如何预测未来时间步的PDE解。此外，我们的方法提供了PDE的可解释形式，这种特征可以协助通过物理科学数据来对现象进行建模。为了验证我们的方法，我们进行了大量实验，考察了其在预测误差和可解释性方面的质量。

    We propose an explainable method for solving Partial Differential Equations by using a contextual scheme called PDExplain. During the training phase, our method is fed with data collected from an operator-defined family of PDEs accompanied by the general form of this family. In the inference phase, a minimal sample collected from a phenomenon is provided, where the sample is related to the PDE family but not necessarily to the set of specific PDEs seen in the training phase. We show how our algorithm can predict the PDE solution for future timesteps. Moreover, our method provides an explainable form of the PDE, a trait that can assist in modelling phenomena based on data in physical sciences. To verify our method, we conduct extensive experimentation, examining its quality both in terms of prediction error and explainability.
    
[^135]: 使用最小生成树进行聚类：能有多好？

    Clustering with minimum spanning trees: How good can it be?. (arXiv:2303.05679v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.05679](http://arxiv.org/abs/2303.05679)

    本文研究了使用最小生成树（MST）进行分区数据聚类任务的意义程度，并发现MST方法在总体上具有很强的竞争力。此外，通过回顾、研究、扩展和推广现有的MST-based划分方案，我们提出了一些新的和值得注意的方法。总体上，Genie和信息论方法往往优于其他非MST算法，在某些情况下MST方法可能不如其他算法。

    

    最小生成树（MST）在许多模式识别任务中可以提供方便的数据集表示，并且计算相对较快。本文中，我们量化了MST在低维空间的分区数据聚类任务中的意义程度。通过识别最佳（oracle）算法与大量基准数据的专家标签之间的一致性上限，我们发现MST方法在总体上具有很强的竞争力。接下来，我们不是提出另一个只在有限的示例上表现良好的算法，而是回顾、研究、扩展和推广现有的最新MST-based划分方案。这导致了一些新的和值得注意的方法。总体上，Genie和信息论方法往往优于非MST算法，如k-means，高斯混合，谱聚类，Birch，基于密度和经典层次聚类程序。尽管如此，我们还是发现MST方法在某些情况下可能不如其他算法。

    Minimum spanning trees (MSTs) provide a convenient representation of datasets in numerous pattern recognition activities. Moreover, they are relatively fast to compute. In this paper, we quantify the extent to which they can be meaningful in partitional data clustering tasks in low-dimensional spaces. By identifying the upper bounds for the agreement between the best (oracle) algorithm and the expert labels from a large battery of benchmark data, we discover that MST methods are overall very competitive. Next, instead of proposing yet another algorithm that performs well on a limited set of examples, we review, study, extend, and generalise existing, state-of-the-art MST-based partitioning schemes. This leads to a few new and noteworthy approaches. Overall, Genie and the information-theoretic methods often outperform the non-MST algorithms such as k-means, Gaussian mixtures, spectral clustering, Birch, density-based, and classical hierarchical agglomerative procedures. Nevertheless, we
    
[^136]: 基于自适应相关图卷积网络，实现交通量估计更好的性能：解决不确定和非平衡问题

    Towards better traffic volume estimation: Tackling both underdetermined and non-equilibrium problems via a correlation-adaptive graph convolution network. (arXiv:2303.05660v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.05660](http://arxiv.org/abs/2303.05660)

    本研究提出基于图卷积网络的方法，解决交通量估计中的不确定和非平衡问题，实现准确的全面交通量估计。

    

    交通量是交通管理和控制提供细粒度信息不可或缺的因素。然而，由于交通传感器的有限部署，获取全面的交通量信息并不容易。现有研究主要集中在提高特定方法的整体估计准确性上，忽略了交通量估计的基本挑战，因此在一些关键任务上表现较差。本文研究了交通量估计中的两个关键问题: (1) 由未检测到的行动引起的不确定交通流，以及 (2) 由拥堵传播引起的非平衡交通流。我们提出了一种基于图形的深度学习方法，可以提供数据驱动的、无模型的和相关自适应方法来解决上述问题，并进行准确的全面交通量估计。特别地，为了量化交通速度和流量之间的动态和非线性关系，本文介绍了用于建立交通流图的相关图卷积网络。

    Traffic volume is an indispensable ingredient to provide fine-grained information for traffic management and control. However, due to limited deployment of traffic sensors, obtaining full-scale volume information is far from easy. Existing works on this topic primarily focus on improving the overall estimation accuracy of a particular method and ignore the underlying challenges of volume estimation, thereby having inferior performances on some critical tasks. This paper studies two key problems with regard to traffic volume estimation: (1) underdetermined traffic flows caused by undetected movements, and (2) non-equilibrium traffic flows arise from congestion propagation. Here we demonstrate a graph-based deep learning method that can offer a data-driven, model-free and correlation adaptive approach to tackle the above issues and perform accurate network-wide traffic volume estimation. Particularly, in order to quantify the dynamic and nonlinear relationships between traffic speed and 
    
[^137]: 一个关于正确、错误和外在等变性的普遍理论

    A General Theory of Correct, Incorrect, and Extrinsic Equivariance. (arXiv:2303.04745v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04745](http://arxiv.org/abs/2303.04745)

    该论文提出了一个关于正确、错误和外在等变性的普遍理论，通过逐点定义量化了函数表现的每种类型等变性的程度，并研究了不正确或外在对称性对模型错误的影响。实验证实了这些结果。 (230字符)

    

    尽管等变机器学习在许多任务中证明是有效的，但成功很大程度上依赖于假设地面真相函数在整个域上是对称的，与等变神经网络的对称性匹配。等变学习文献中缺少的一块是在域中仅部分存在对称性时等变网络的分析。在这项工作中，我们提出了一个适用于这种情况的普遍理论。我们提出了正确、错误和外在等变性的逐点定义，这使我们能够连续地量化函数显示的每种类型等变性的程度。然后，我们研究了不正确或外在对称性的各种程度对模型错误的影响。我们证明了在部分不正确对称性的分类或回归设置中不变或等变网络存在错误的下界。我们还分析了外在等变性的潜在有害影响。实验证实了这些结果在三种不同的实验中。

    Although equivariant machine learning has proven effective at many tasks, success depends heavily on the assumption that the ground truth function is symmetric over the entire domain matching the symmetry in an equivariant neural network. A missing piece in the equivariant learning literature is the analysis of equivariant networks when symmetry exists only partially in the domain. In this work, we present a general theory for such a situation. We propose pointwise definitions of correct, incorrect, and extrinsic equivariance, which allow us to quantify continuously the degree of each type of equivariance a function displays. We then study the impact of various degrees of incorrect or extrinsic symmetry on model error. We prove error lower bounds for invariant or equivariant networks in classification or regression settings with partially incorrect symmetry. We also analyze the potentially harmful effects of extrinsic equivariance. Experiments validate these results in three different 
    
[^138]: 关于校准扩散概率模型

    On Calibrating Diffusion Probabilistic Models. (arXiv:2302.10688v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10688](http://arxiv.org/abs/2302.10688)

    本文发现了数据分数随机反向过程是一个鞅，提出了一种简单的方法，用于校准任意预先训练的DPM，有效减小模型的得分匹配损失，增加模型似然的下限，并提供了一般校准指南。

    

    最近，扩散概率模型（DPM）在各种生成性任务中取得了有希望的结果。一个典型的DPM框架包括一个逐渐扩散数据分布的正向过程和一个从时间相关数据分数中恢复数据分布的随机反向过程。本文观察到数据分数的随机反向过程是一个鞅，从中可以导出数据分数的集中界和随机停止定理。然后，我们发现一种简单的方法，用于校准任意预先训练的DPM，以减小得分匹配损失，并因此增加模型似然的下限。我们提供了各种模型参数化下的一般校准指南。我们的校准方法仅执行一次，并且可以重复使用所得到的模型进行采样。我们在多个数据集上进行实验，以经验性地验证我们的提议。我们的代码位于https://github.com/thudzj/Cal。

    Recently, diffusion probabilistic models (DPMs) have achieved promising results in diverse generative tasks. A typical DPM framework includes a forward process that gradually diffuses the data distribution and a reverse process that recovers the data distribution from time-dependent data scores. In this work, we observe that the stochastic reverse process of data scores is a martingale, from which concentration bounds and the optional stopping theorem for data scores can be derived. Then, we discover a simple way for calibrating an arbitrary pretrained DPM, with which the score matching loss can be reduced and the lower bounds of model likelihood can consequently be increased. We provide general calibration guidelines under various model parametrizations. Our calibration method is performed only once and the resulting models can be used repeatedly for sampling. We conduct experiments on multiple datasets to empirically validate our proposal. Our code is at https://github.com/thudzj/Cal
    
[^139]: 平均Hölder平滑度下的近似最优学习

    Near-optimal learning with average H\"older smoothness. (arXiv:2302.06005v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06005](http://arxiv.org/abs/2302.06005)

    通过推广平均Lipschitz平滑性到Hölder平滑性，得到了关于平均Hölder平滑性的上下风险界，最优的下界对数因子最多差一个，提供了独立的学习算法。

    

    我们将Ashlagi等人（COLT 2021）提出的平均Lipschitz平滑性概念推广到Hölder平滑性，并证明了关于平均Hölder平滑性的上下风险界，这些界的速率甚至在平均Lipschitz平滑性的特殊情况下也优于之前已知界。此外，我们的下界在可实现情况下是最优的，最多差一个对数因子，从而建立了极小值率。从算法的角度来看，由于我们对平均平滑度的定义是针对未知的基础分布的，因此学习者没有函数类的显式表示，无法执行ERM。尽管如此，我们提供了独立的学习算法。

    We generalize the notion of average Lipschitz smoothness proposed by Ashlagi et al. (COLT 2021) by extending it to H\"older smoothness. This measure of the "effective smoothness" of a function is sensitive to the underlying distribution and can be dramatically smaller than its classic "worst-case H\"older constant. We consider both the realizable and the agnostic (noisy) regression settings, proving upper and lower risk bounds in terms of the average H\"older smoothness; these rates improve upon both previously known rates even in the special case of average Lipschitz smoothness. Moreover, our lower bound is tight in the realizable setting up to log factors, thus we establish the minimax rate. From an algorithmic perspective, since our notion of average smoothness is defined with respect to the unknown underlying distribution, the learner does not have an explicit representation of the function class, hence is unable to execute ERM. Nevertheless, we provide distinct learning algorithms
    
[^140]: 星形降噪扩散概率模型

    Star-Shaped Denoising Diffusion Probabilistic Models. (arXiv:2302.05259v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.05259](http://arxiv.org/abs/2302.05259)

    创新点在于提出了一种非马尔可夫扩散噪声过程的星形降噪扩散概率模型，能够广泛适用于指数族中的多种分布，特别适用于约束流形上的数据。

    

    基于降噪扩散概率模型（DDPM）的方法已经成为生成模型中无处不在的工具。但是，它们大多局限于高斯和离散扩散过程。我们提出了星形降噪扩散概率模型（SS-DDPM），一种具有非马尔可夫扩散噪声过程的模型。在高斯分布的情况下，该模型等效于马尔可夫DDPM。然而，它可以定义和适用于任意噪声分布，并且对于落在指数族中的广泛分布，它采用了高效的训练和采样算法。我们提供了一个简单的配方，用于设计具有Beta，von Mises-Fisher，Dirichlet，Wishart等分布的扩散样式模型，当数据位于约束流形上时特别有用，例如单位球，正半定矩阵的空间，概率单纯形等。我们在不同的设置中评估了该模型，并发现它很有竞争力。

    Methods based on Denoising Diffusion Probabilistic Models (DDPM) became a ubiquitous tool in generative modeling. However, they are mostly limited to Gaussian and discrete diffusion processes. We propose Star-Shaped Denoising Diffusion Probabilistic Models (SS-DDPM), a model with a non-Markovian diffusion-like noising process. In the case of Gaussian distributions, this model is equivalent to Markovian DDPMs. However, it can be defined and applied with arbitrary noising distributions, and admits efficient training and sampling algorithms for a wide range of distributions that lie in the exponential family. We provide a simple recipe for designing diffusion-like models with distributions like Beta, von Mises--Fisher, Dirichlet, Wishart and others, which can be especially useful when data lies on a constrained manifold such as the unit sphere, the space of positive semi-definite matrices, the probabilistic simplex, etc. We evaluate the model in different settings and find it competitive 
    
[^141]: 针对图数据的异常稳健Gromov-Wasserstein方法

    Outlier-Robust Gromov-Wasserstein for Graph Data. (arXiv:2302.04610v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04610](http://arxiv.org/abs/2302.04610)

    本论文提出了一种针对图数据的异常稳健Gromov-Wasserstein方法（RGW），通过引入乐观扰动的边际约束和使用Bregman近端交替线性化最小化算法，解决了GW距离对异常值敏感的问题。

    

    Gromov-Wasserstein（GW）距离是一种在不同度量空间上比较和对齐概率分布的强大工具。最近，GW已成为广泛应用于图学习任务中对齐异构数据的主要建模技术。然而，已知GW距离对异常值非常敏感，如果在目标函数中将异常值与其他样本赋予相同的权重，可能会导致较大的不准确性。为了缓解这个问题，我们引入了一种新的、稳健的GW距离称为RGW。RGW在基于Kullback-Leibler散度的模糊集合中引入了乐观扰动的边际约束。为了更方便地在实践中使用RGW的好处，我们利用Bregman近端交替线性化最小化算法开发了一个计算高效且理论可证的过程。通过大量实验证实了我们的理论结果，并展示了RGW的有效性。

    Gromov-Wasserstein (GW) distance is a powerful tool for comparing and aligning probability distributions supported on different metric spaces. Recently, GW has become the main modeling technique for aligning heterogeneous data for a wide range of graph learning tasks. However, the GW distance is known to be highly sensitive to outliers, which can result in large inaccuracies if the outliers are given the same weight as other samples in the objective function. To mitigate this issue, we introduce a new and robust version of the GW distance called RGW. RGW features optimistically perturbed marginal constraints within a Kullback-Leibler divergence-based ambiguity set. To make the benefits of RGW more accessible in practice, we develop a computationally efficient and theoretically provable procedure using Bregman proximal alternating linearized minimization algorithm. Through extensive experimentation, we validate our theoretical results and demonstrate the effectiveness of RGW on real-wor
    
[^142]: 神经网络在因果估计中的应用: 在美国评估更严格的空气质量标准的健康效益

    Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US. (arXiv:2302.02560v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02560](http://arxiv.org/abs/2302.02560)

    本研究提出了一种神经网络方法，利用其理论基础和实施的可行性，从而估计连续暴露/治疗的分布对政策相关结果的因果效应。我们将此方法应用于包含6800万个个体和2700万个美国境内死亡事件的数据中，通过评估美国国家环境保护局（EPA）对PM2.5的国家环境空气质量标准（NAAQS）进行修订后的健康效益。

    

    在政策研究中，估计连续性暴露/治疗的分布对感兴趣的结果的因果效应是最关键的分析任务之一。我们称之为偏移-响应函数（SRF）估计问题。现有的涉及强健因果效应估计器的神经网络方法缺乏理论保证和实际实现，用于SRF估计。受公共卫生中的关键政策问题的启发，我们开发了一种神经网络方法及其理论基础，以提供具有强健性和效率保证的SRF估计。然后，我们将我们的方法应用于包含6800万个个体和2700万个美国境内死亡事件的数据中，以估计将美国国家环境保护局（EPA）最近提议从12 μg/m³改为9 μg/m³的PM2.5的美国国家环境空气质量标准（NAAQS）的修订对结果的因果效应。我们的目标是首次估计

    In policy research, one of the most critical analytic tasks is to estimate the causal effect of a policy-relevant shift to the distribution of a continuous exposure/treatment on an outcome of interest. We call this problem shift-response function (SRF) estimation. Existing neural network methods involving robust causal-effect estimators lack theoretical guarantees and practical implementations for SRF estimation. Motivated by a key policy-relevant question in public health, we develop a neural network method and its theoretical underpinnings to estimate SRFs with robustness and efficiency guarantees. We then apply our method to data consisting of 68 million individuals and 27 million deaths across the U.S. to estimate the causal effect from revising the US National Ambient Air Quality Standards (NAAQS) for PM 2.5 from 12 $\mu g/m^3$ to 9 $\mu g/m^3$. This change has been recently proposed by the US Environmental Protection Agency (EPA). Our goal is to estimate, for the first time, the 
    
[^143]: 非参数密度估计在分布漂移下的研究

    Nonparametric Density Estimation under Distribution Drift. (arXiv:2302.02460v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02460](http://arxiv.org/abs/2302.02460)

    该论文研究了非参数密度估计在分布漂移下的问题，证明了紧密极小风险界，并推广了先前关于对漂移的无知学习的结果。

    

    我们研究了非驻点漂移设置下的非参数密度估计。给定来自一系列随时间逐渐变化的分布的独立样本序列，目标是计算当前分布的最佳估计。我们证明了离散和连续平滑密度的紧密极小风险界，其中极小值是对所有可能估计的最小值，而极大值是对满足漂移约束的所有可能分布的最大值。我们的技术适用于广泛的漂移模型，并推广了先前关于对漂移的无知学习的结果。

    We study nonparametric density estimation in non-stationary drift settings. Given a sequence of independent samples taken from a distribution that gradually changes in time, the goal is to compute the best estimate for the current distribution. We prove tight minimax risk bounds for both discrete and continuous smooth densities, where the minimum is over all possible estimates and the maximum is over all possible distributions that satisfy the drift constraints. Our technique handles a broad class of drift models, and generalizes previous results on agnostic learning under drift.
    
[^144]: 上下文套索：通过深度神经网络的方法实现稀疏线性模型

    The contextual lasso: Sparse linear models via deep neural networks. (arXiv:2302.00878v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00878](http://arxiv.org/abs/2302.00878)

    本论文提出了一种新的统计估计器——上下文套索，可以通过深度神经网络的方法解决解释性和拟合能力的矛盾问题，实现对可解释特征的稀疏拟合，并且稀疏模式和系数会随着上下文特征的变化而发生变化。

    

    稀疏线性模型是可解释机器学习的黄金标准工具，本论文通过使用深度神经网络对稀疏线性模型进行改进，实现了可解释性和强大的拟合能力。上下文套索是一种新的统计估计器，它将输入特征分成可解释特征和上下文特征两组，并对可解释特征进行稀疏拟合，同时其稀疏模式和系数会随着上下文特征的变化而发生变化，这个过程通过深度神经网络无需参数地进行学习。

    Sparse linear models are a gold standard tool for interpretable machine learning, a field of emerging importance as predictive models permeate decision-making in many domains. Unfortunately, sparse linear models are far less flexible as functions of their input features than black-box models like deep neural networks. With this capability gap in mind, we study a not-uncommon situation where the input features dichotomize into two groups: explanatory features, which are candidates for inclusion as variables in an interpretable model, and contextual features, which select from the candidate variables and determine their effects. This dichotomy leads us to the contextual lasso, a new statistical estimator that fits a sparse linear model to the explanatory features such that the sparsity pattern and coefficients vary as a function of the contextual features. The fitting process learns this function nonparametrically via a deep neural network. To attain sparse coefficients, we train the net
    
[^145]: 大型Transformer模型的隐藏表示的几何学

    The geometry of hidden representations of large transformer models. (arXiv:2302.00294v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00294](http://arxiv.org/abs/2302.00294)

    大型Transformer模型中的隐藏表示具有类似的几何和统计特性，随着层级的移动，它们在最初的几层中变得高维，然后在中间层中显著收缩，在模型的最后部分，保持恒定或形成第二个浅峰。在第一个峰值结束时，数据集的语义信息被更好地表达。

    

    大型Transformer模型是用于自监督数据分析的强大架构，可以处理包括蛋白质序列、图像和文本在内的各种数据类型。在这些模型中，数据集的语义结构通过一个表示与下一个表示之间的一系列变换而出现。我们表征了这些表示的几何和统计特性，以及它们在层级移动时的变化。通过分析内在维度（ID）和邻居组成，我们发现在训练在蛋白质语言任务和图像重建任务上的Transformer模型中，表示以相似的方式演化。在最初的几层中，数据流形扩展，变得高维，然后在中间层中显著收缩。在模型的最后部分，ID保持大致恒定或形成第二个浅峰。我们展示了数据集的语义信息在第一个峰值结束时更好地表达，这一现象可以被观察到。

    Large transformers are powerful architectures used for self-supervised data analysis across various data types, including protein sequences, images, and text. In these models, the semantic structure of the dataset emerges from a sequence of transformations between one representation and the next. We characterize the geometric and statistical properties of these representations and how they change as we move through the layers. By analyzing the intrinsic dimension (ID) and neighbor composition, we find that the representations evolve similarly in transformers trained on protein language tasks and image reconstruction tasks. In the first layers, the data manifold expands, becoming high-dimensional, and then contracts significantly in the intermediate layers. In the last part of the model, the ID remains approximately constant or forms a second shallow peak. We show that the semantic information of the dataset is better expressed at the end of the first peak, and this phenomenon can be ob
    
[^146]: 核化累计量：超越核均值嵌入

    Kernelized Cumulants: Beyond Kernel Mean Embeddings. (arXiv:2301.12466v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.12466](http://arxiv.org/abs/2301.12466)

    本文通过核技巧将累计量扩展到再生核希尔伯特空间（RKHS），提供了一组新的通用统计量。超越一阶具有几个优势，并且在计算上具有相同的复杂度和最小的开销。

    

    在$d$维实数空间中，众所周知，累计量是一种替代矩的方法，可以以较低的方差估计达到相同的目标。本文利用张量代数的工具将累计量扩展到再生核希尔伯特空间（RKHS），并通过核技巧证明了它们在计算上是可行的。这些核化累计量提供了一组新的通用统计量；经典的最大均值差异和希尔伯特-施密特独立性准则是我们一般构造中的一阶对象。我们在理论上和实证上（使用合成、环境和流量数据分析）论证了超越一阶具有几个优势，并且在我们的实验中可以以相同的计算复杂度和最小的额外开销实现。

    In $\mathbb R^d$, it is well-known that cumulants provide an alternative to moments that can achieve the same goals with numerous benefits such as lower variance estimators. In this paper we extend cumulants to reproducing kernel Hilbert spaces (RKHS) using tools from tensor algebras and show that they are computationally tractable by a kernel trick. These kernelized cumulants provide a new set of all-purpose statistics; the classical maximum mean discrepancy and Hilbert-Schmidt independence criterion arise as the degree one objects in our general construction. We argue both theoretically and empirically (on synthetic, environmental, and traffic data analysis) that going beyond degree one has several advantages and can be achieved with the same computational complexity and minimal overhead in our experiments.
    
[^147]: 与人类表征的一致性支持鲁棒的少样本学习

    Alignment with human representations supports robust few-shot learning. (arXiv:2301.11990v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11990](http://arxiv.org/abs/2301.11990)

    论文提出少样本学习的表现与人类表征的一致性存在U形关系，并通过计算机视觉模型的实验进行了验证。高度对齐的模型更加鲁棒，对数据的利用更加有效，但与人类对齐并非必要条件。

    

    我们是否应该关心AI系统是否具有与人类相似的世界表征？我们提供了一个信息论分析，建议在少样本学习任务的表现度与人类表征的一致性之间应该存在一个U形关系。我们通过对491个计算机视觉模型的性能分析验证了这个预测的可行性，并且表明高度对齐的模型更加鲁棒于对抗攻击和域偏移。我们的结果表明，与人类对齐往往是模型有效利用有限数据、鲁棒性 以及泛化能力的充分但不必要条件。

    Should we care whether AI systems have representations of the world that are similar to those of humans? We provide an information-theoretic analysis that suggests that there should be a U-shaped relationship between the degree of representational alignment with humans and performance on few-shot learning tasks. We confirm this prediction empirically, finding such a relationship in an analysis of the performance of 491 computer vision models. We also show that highly-aligned models are more robust to both adversarial attacks and domain shifts. Our results suggest that human-alignment is often a sufficient, but not necessary, condition for models to make effective use of limited data, be robust, and generalize well.
    
[^148]: 用小的条件集表征和学习因果图

    Characterization and Learning of Causal Graphs with Small Conditioning Sets. (arXiv:2301.09028v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.09028](http://arxiv.org/abs/2301.09028)

    本研究提出了一种使用小的条件集来表征和学习因果图的方法，用于解决约束性因果发现算法在数据有限和条件集较大时的困难。我们定义了k-马尔可夫等价的概念，该概念在不能利用所有条件独立性语句时仍然适用。

    

    约束性因果发现算法通过系统地测试数据中观察到的条件独立性来学习因果图的一部分结构。这些算法，如PC算法及其变体，依赖于由Pearl提出的所谓因果图等价类的图形表征。然而，当数据有限时，约束性因果发现算法往往面临困难，因为条件独立性检验很快失去统计能力，尤其是当条件集很大时。为了解决这个问题，我们提出使用条件独立性检验，在鲁棒的因果发现中将条件集的大小上限设置为某个整数 k。然而，现有的因果图等价类的图形表征在我们不能利用所有的条件独立性语句时不适用。我们首先定义了 k-马尔可夫等价的概念：如果两个因果图得到相同的条件独立性语句，它们是 k-马尔可夫等价的。

    Constraint-based causal discovery algorithms learn part of the causal graph structure by systematically testing conditional independences observed in the data. These algorithms, such as the PC algorithm and its variants, rely on graphical characterizations of the so-called equivalence class of causal graphs proposed by Pearl. However, constraint-based causal discovery algorithms struggle when data is limited since conditional independence tests quickly lose their statistical power, especially when the conditioning set is large. To address this, we propose using conditional independence tests where the size of the conditioning set is upper bounded by some integer $k$ for robust causal discovery. The existing graphical characterizations of the equivalence classes of causal graphs are not applicable when we cannot leverage all the conditional independence statements. We first define the notion of $k$-Markov equivalence: Two causal graphs are $k$-Markov equivalent if they entail the same c
    
[^149]: 基于JKO方案的可逆归一化流神经网络

    Invertible normalizing flow neural networks by JKO scheme. (arXiv:2212.14424v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.14424](http://arxiv.org/abs/2212.14424)

    本文提出了一种基于JKO方案的可逆归一化流神经网络，通过按块进行残差块的训练，减少了内存负载和深度流网络训练的难度。并且通过自适应时间重新参数化的流网络，在概率空间中逐步细化轨迹，从而提高了模型的训练效率和准确性。

    

    归一化流是一类用于高效采样和密度估计的深度生成模型。实际中，流通常表示为一系列可逆的神经网络模块链; 为了便于训练，现有的工作对流轨迹进行了正则化，并设计了特殊的网络架构。本文提出了受Jordan-Kinderleherer-Otto (JKO)方案启发的神经ODE流网络，它允许有效地按块进行残差块的训练，无需采样SDE轨迹或分数匹配或变分学习的内循环。由于JKO方案展开了梯度流的动态，所提出的模型自然地逐个堆叠残差网络块，降低了内存负载和进行端到端深度流网络训练的难度。我们还开发了自适应时间重新参数化的流网络，通过在概率空间中逐步细化轨迹，提高了模型的训练效率和准确性。

    Normalizing flow is a class of deep generative models for efficient sampling and density estimation. In practice, the flow often appears as a chain of invertible neural network blocks; to facilitate training, existing works have regularized flow trajectories and designed special network architectures. The current paper develops a neural ODE flow network inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which allows efficient block-wise training of the residual blocks without sampling SDE trajectories or inner loops of score matching or variational learning. As the JKO scheme unfolds the dynamic of gradient flow, the proposed model naturally stacks residual network blocks one by one, reducing the memory load and difficulty in performing end-to-end deep flow network training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the trajectory in probability space, which improves the model training efficiency and accuracy in practice.
    
[^150]: 双重平滑GDA：用于非凸-非凹极小极大优化的全局收敛算法

    Doubly Smoothed GDA: Global Convergent Algorithm for Constrained Nonconvex-Nonconcave Minimax Optimization. (arXiv:2212.12978v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2212.12978](http://arxiv.org/abs/2212.12978)

    本文提出了一种双重平滑梯度下降上升法 (DSGDA)，该算法可以应用于非凸-非凹极小极大优化，并且能够全局收敛并消除极限环。在一定条件下，DSGDA 的迭代复杂度达到了文献中单循环算法的最佳结果。

    

    非凸-非凹极小极大优化近年来受到了广泛的关注，其在机器学习中具有广泛的应用。然而，大多数现有算法不能保证全局收敛，甚至会遭受极限环的困扰。为了解决这个问题，我们提出了一种新颖的单循环算法，称为双重平滑梯度下降上升法 (DSGDA)，它能够自然地平衡原始与对偶更新，并且将极其具有挑战性的非凸-非凹例子中的极限环消除，包括 Forsaken，Bilinearly-coupled minimax，Sixth-order polynomial 和 PolarGame。我们进一步证明，在一个单侧的 $\theta\in(0,1)$ Kurdyka-\L{}ojasiewicz条件（或凸原始/凹对偶函数）下，DSGDA 可以找到一个游戏平衡点，并且具有迭代复杂度 $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$（或 $\mathcal{O}(\epsilon^{-4})$），这些与文献中单循环算法的最佳结果相匹配。

    Nonconvex-nonconcave minimax optimization has received intense attention over the last decade due to its broad applications in machine learning. Unfortunately, most existing algorithms cannot be guaranteed to converge globally and even suffer from limit cycles. To address this issue, we propose a novel single-loop algorithm called doubly smoothed gradient descent ascent method (DSGDA), which naturally balances the primal and dual updates. The proposed DSGDA can get rid of limit cycles in various challenging nonconvex-nonconcave examples in the literature, including Forsaken, Bilinearly-coupled minimax, Sixth-order polynomial, and PolarGame. We further show that under an one-sided Kurdyka-\L{}ojasiewicz condition with exponent $\theta\in(0,1)$ (resp. convex primal/concave dual function), DSGDA can find a game-stationary point with an iteration complexity of $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$ (resp. $\mathcal{O}(\epsilon^{-4})$). These match the best results for single-loop al
    
[^151]: 物理学知识指导的高斯过程回归应用于解决线性偏微分方程

    Physics-Informed Gaussian Process Regression Generalizes Linear PDE Solvers. (arXiv:2212.12474v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12474](http://arxiv.org/abs/2212.12474)

    本文使用物理学知识指导的高斯过程回归方法，解决线性偏微分方程求解器无法量化近似误差的问题。

    

    线性偏微分方程是一类重要且广泛应用的机械模型，描述了物理过程，例如热传导、电磁学和波传播等。实践中，通常使用基于离散化的专门数值方法来解决偏微分方程。这些求解器通常使用未知模型参数的估计值以及如果可用的话，物理测量值用于初始化。这些求解器经常嵌入到具有下游应用的更大的科学模型中，因此误差量化起着关键作用。然而，经典的偏微分方程求解器忽略参数和测量不确定性，可能无法产生一致性的估计值，以用于计算其固有的逼近误差。本文通过将求解线性偏微分方程解释为物理学知识指导的高斯过程回归来解决这个问题。我们的框架基于高斯过程推理定理的一个关键推广，该定理适用于通过任意界面进行观察的情况。

    Linear partial differential equations (PDEs) are an important, widely applied class of mechanistic models, describing physical processes such as heat transfer, electromagnetism, and wave propagation. In practice, specialized numerical methods based on discretization are used to solve PDEs. They generally use an estimate of the unknown model parameters and, if available, physical measurements for initialization. Such solvers are often embedded into larger scientific models with a downstream application and thus error quantification plays a key role. However, by ignoring parameter and measurement uncertainty, classical PDE solvers may fail to produce consistent estimates of their inherent approximation error. In this work, we approach this problem in a principled fashion by interpreting solving linear PDEs as physics-informed Gaussian process (GP) regression. Our framework is based on a key generalization of the Gaussian process inference theorem to observations made via an arbitrary bou
    
[^152]: Beurling-Selberg极大化用于联合雷达通信中的双盲反卷积恢复

    Beurling-Selberg Extremization for Dual-Blind Deconvolution Recovery in Joint Radar-Communications. (arXiv:2211.09253v3 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2211.09253](http://arxiv.org/abs/2211.09253)

    本文提出了在联合雷达通信中通过Beurling-Selberg极大化方法用于双盲反卷积恢复的优化分离条件。

    

    最近对综合感知和通信的兴趣导致了设计新的信号处理技术来从叠加的雷达通信信号中恢复信息。在这里，我们关注的是一个谱共存的情况，在这种情况下，雷达和通信系统的信道和发送信号对于普通接收器来说都是未知的。在这个双盲反卷积问题中，接收器接收一个多载波无线通信信号，该信号与从多个目标反射回来的雷达信号相叠加。通信和雷达信道分别由多个传输路径和目标所对应的连续值范围时间或延迟表示。之前的研究通过原子泛函最小化来解决这个不适定的双盲反卷积问题中未知信道和信号的恢复，但是需要雷达和通信信道的各自最小分离条件。在本文中，我们提供了一个最优的联合分离条件。

    Recent interest in integrated sensing and communications has led to the design of novel signal processing techniques to recover information from an overlaid radar-communications signal. Here, we focus on a spectral coexistence scenario, wherein the channels and transmit signals of both radar and communications systems are unknown to the common receiver. In this dual-blind deconvolution (DBD) problem, the receiver admits a multi-carrier wireless communications signal that is overlaid with the radar signal reflected off multiple targets. The communications and radar channels are represented by continuous-valued range-times or delays corresponding to multiple transmission paths and targets, respectively. Prior works addressed recovery of unknown channels and signals in this ill-posed DBD problem through atomic norm minimization but contingent on individual minimum separation conditions for radar and communications channels. In this paper, we provide an optimal joint separation condition u
    
[^153]: 自共轭障碍哈密尔顿蒙特卡洛的无偏约束采样

    Unbiased constrained sampling with Self-Concordant Barrier Hamiltonian Monte Carlo. (arXiv:2210.11925v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.11925](http://arxiv.org/abs/2210.11925)

    本文提出了一种名为BHMC的新的蒙特卡罗采样算法，能够从定义了约束的黎曼流形中进行无偏采样，其中包含一种新的过滤步骤involution checking step。

    

    本文提出了障碍哈密尔顿蒙特卡罗(BHMC)，它是HMC算法的一种变体，旨在从带有自共轭障碍度量的流形中的Gibbs分布π中进行采样。该方法依赖于包含度量的Hamiltonian动力学。因此，它包含定义流形的约束，并能够利用其底层几何形状。然而，相应的Hamilton动力学是通过不可分离的常微分方程来定义的，与欧几里得情况相反。这意味着将HMC推广到黎曼流形中会产生不可避免的偏差。为解决这个问题，我们提出了一种新的过滤步骤，称为“involution检查步骤”。该步骤在两个BHMC版本——连续BHMC(c-BHMC)和数值BHMC(n-BHMC)中实现。我们的主要结果表明，这两个新算法生成可逆Markov链且无偏。

    In this paper, we propose Barrier Hamiltonian Monte Carlo (BHMC), a version of the HMC algorithm which aims at sampling from a Gibbs distribution $\pi$ on a manifold $\mathrm{M}$, endowed with a Hessian metric $\mathfrak{g}$ derived from a self-concordant barrier. Our method relies on Hamiltonian dynamics which comprises $\mathfrak{g}$. Therefore, it incorporates the constraints defining $\mathrm{M}$ and is able to exploit its underlying geometry. However, the corresponding Hamiltonian dynamics is defined via non separable Ordinary Differential Equations (ODEs) in contrast to the Euclidean case. It implies unavoidable bias in existing generalization of HMC to Riemannian manifolds. In this paper, we propose a new filter step, called "involution checking step", to address this problem. This step is implemented in two versions of BHMC, coined continuous BHMC (c-BHMC) and numerical BHMC (n-BHMC) respectively. Our main results establish that these two new algorithms generate reversible Mark
    
[^154]: 具有无限制内存的在线凸优化

    Online Convex Optimization with Unbounded Memory. (arXiv:2210.09903v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09903](http://arxiv.org/abs/2210.09903)

    本论文提出了一种新的在线凸优化框架，可以处理决策历史的长期依赖关系，并介绍了用于量化依赖程度的$p$-有效内存容量的概念。

    

    在线凸优化（OCO）是在线学习中广泛使用的框架。然而，在很多应用中，学习者的损失不仅取决于当前的决策，还取决于直到那个时间点的所有决策历史。本文引入了一种OCO的扩展框架，“具有无限制内存的在线凸优化”，来捕捉对过去决策的长期依赖关系，并介绍了$p$-有效内存容量的概念，$H_p$，它量化了$p$阶影响的最大值。

    Online convex optimization (OCO) is a widely used framework in online learning. In each round, the learner chooses a decision in a convex set and an adversary chooses a convex loss function, and then the learner suffers the loss associated with their current decision. However, in many applications the learner's loss depends not only on the current decision but on the entire history of decisions until that point. The OCO framework and its existing generalizations do not capture this, and they can only be applied to many settings of interest after a long series of approximation arguments. They also leave open the question of whether the dependence on memory is tight because there are no non-trivial lower bounds. In this work we introduce a generalization of the OCO framework, ``Online Convex Optimization with Unbounded Memory'', that captures long-term dependence on past decisions. We introduce the notion of $p$-effective memory capacity, $H_p$, that quantifies the maximum influence of p
    
[^155]: 基于谱方法的项目反应理论

    A Spectral Approach to Item Response Theory. (arXiv:2210.04317v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04317](http://arxiv.org/abs/2210.04317)

    本文提出了一种基于谱方法的项目反应理论算法，通过计算马尔科夫链的平稳分布来估计模型参数，具有良好的优化性能和有限样本误差保证。

    

    Rasch模型是项目反应理论中最基础的模型之一，广泛应用于教育测试和推荐系统。本文提出了一种新的项目估计算法，核心是计算在项目-项目图上定义的马尔科夫链的平稳分布。

    The Rasch model is one of the most fundamental models in \emph{item response theory} and has wide-ranging applications from education testing to recommendation systems. In a universe with $n$ users and $m$ items, the Rasch model assumes that the binary response $X_{li} \in \{0,1\}$ of a user $l$ with parameter $\theta^*_l$ to an item $i$ with parameter $\beta^*_i$ (e.g., a user likes a movie, a student correctly solves a problem) is distributed as $\Pr(X_{li}=1) = 1/(1 + \exp{-(\theta^*_l - \beta^*_i)})$. In this paper, we propose a \emph{new item estimation} algorithm for this celebrated model (i.e., to estimate $\beta^*$). The core of our algorithm is the computation of the stationary distribution of a Markov chain defined on an item-item graph. We complement our algorithmic contributions with finite-sample error guarantees, the first of their kind in the literature, showing that our algorithm is consistent and enjoys favorable optimality properties. We discuss practical modification
    
[^156]: 非负张量的多体逼近

    Many-body Approximation for Non-negative Tensors. (arXiv:2209.15338v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.15338](http://arxiv.org/abs/2209.15338)

    提出了一种名为多体逼近的方法来分解非负张量，通过能量建模来避免全局优化和目标秩选择的困难，可通过考虑模式之间的交互进行全局优化; 在许多任务中都展示了其有效性。

    

    我们提出了一种替代方法来分解非负张量，称为多体逼近。传统的分解方法假设表示具有低秩性，导致全局优化和目标秩选择的困难。我们通过张量的能量建模避免了这些问题，其中张量和其模式分别对应于概率分布和随机变量。我们的模型可以通过考虑模式之间的交互来进行全局优化，可以比秩更直观地进行调整。此外，我们将模式之间的相互作用可视化为张量网络，揭示了多体逼近和低秩逼近之间的非平凡关系。我们在张量完成和逼近中展示了我们方法的有效性。

    We present an alternative approach to decompose non-negative tensors, called many-body approximation. Traditional decomposition methods assume low-rankness in the representation, resulting in difficulties in global optimization and target rank selection. We avoid these problems by energy-based modeling of tensors, where a tensor and its mode correspond to a probability distribution and a random variable, respectively. Our model can be globally optimized in terms of the KL divergence minimization by taking the interaction between variables, i.e. modes, into account that can be tuned more intuitively than ranks. Furthermore, we visualize interactions between modes as tensor networks and reveal a nontrivial relationship between many-body approximation and low-rank approximation. We demonstrate the effectiveness of our approach in tensor completion and approximation.
    
[^157]: 具有大的最坏情况Lipschitz参数的私有随机优化：（非光滑）凸损失的最优速率及其对非凸损失的扩展

    Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.07403](http://arxiv.org/abs/2209.07403)

    本论文研究了具有大的最坏情况Lipschitz参数的差分隐私随机优化问题，并提供了一种不依赖于统一Lipschitz参数的接近最优的过量风险界限方法。

    

    我们研究了具有最坏情况Lipschitz参数可能非常大的损失函数的差分隐私（DP）随机优化（SO）。迄今为止，大部分关于DP SO的工作都假设损失在所有数据点上是均匀Lipschitz连续的（即随机梯度在所有数据点上都有界）。虽然这种假设很方便，但通常会导致悲观的过量风险界限。在许多实际问题中，由于异常值，损失在所有数据点上的最坏情况（统一）Lipschitz参数可能非常大。在这种情况下，DP SO的误差界限与损失的最坏情况Lipschitz参数成比例，将会是空洞的。为了解决这些限制，本工作提供了一种接近最优的过量风险界限，不依赖于损失的统一Lipschitz参数。在最近的工作（Wang等人，2020; Kamath等人，2022）的基础上，我们假设随机梯度具有有界的k阶矩

    We study differentially private (DP) stochastic optimization (SO) with loss functions whose worst-case Lipschitz parameter over all data points may be extremely large. To date, the vast majority of work on DP SO assumes that the loss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are uniformly bounded over all data points). While this assumption is convenient, it often leads to pessimistic excess risk bounds. In many practical problems, the worst-case (uniform) Lipschitz parameter of the loss over all data points may be extremely large due to outliers. In such cases, the error bounds for DP SO, which scale with the worst-case Lipschitz parameter of the loss, are vacuous. To address these limitations, this work provides near-optimal excess risk bounds that do not depend on the uniform Lipschitz parameter of the loss. Building on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we assume that stochastic gradients have bounded $k$-th order moments fo
    
[^158]: 限制玻尔兹曼机的模式重构

    Pattern reconstruction with restricted Boltzmann machines. (arXiv:2205.07087v3 [math.PR] UPDATED)

    [http://arxiv.org/abs/2205.07087](http://arxiv.org/abs/2205.07087)

    该论文研究了限制玻尔兹曼机在模式重构中的能力，发现隐藏层先验分布的尾部行为对于恢复随机模式的效果有关键影响。

    

    限制玻尔兹曼机是由可见层和隐藏层组成的能量模型。我们找到了描述可见单元上零温度状态的有效能量函数，该函数只依赖于隐藏层先验分布的尾部行为。通过研究该能量函数的局部极小值的位置，我们表明限制玻尔兹曼机重构随机模式的能力确实只取决于隐藏先验分布的尾部。我们发现，具有严格超高斯尾部的隐藏先验仅导致对模式恢复的对数损失，而具有严格次高斯尾部的隐藏单元则导致更难进行有效的恢复；如果隐藏先验具有高斯尾部，恢复能力取决于隐藏单元的数量（与霍普菲尔德模型类似）。

    Restricted Boltzmann machines are energy models made of a visible and a hidden layer. We identify an effective energy function describing the zero-temperature landscape on the visible units and depending only on the tail behaviour of the hidden layer prior distribution. Studying the location of the local minima of such an energy function, we show that the ability of a restricted Boltzmann machine to reconstruct a random pattern depends indeed only on the tail of the hidden prior distribution. We find that hidden priors with strictly super-Gaussian tails give only a logarithmic loss in pattern retrieval, while an efficient retrieval is much harder with hidden units with strictly sub-Gaussian tails; if the hidden prior has Gaussian tails, the retrieval capability is determined by the number of hidden units (as in the Hopfield model).
    
[^159]: 在神经程序综合中的组合泛化和分解

    Compositional Generalization and Decomposition in Neural Program Synthesis. (arXiv:2204.03758v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2204.03758](http://arxiv.org/abs/2204.03758)

    本文探讨了神经程序综合方法在组合泛化和分解方面的能力，并提出了一套基准任务来评估这些能力。

    

    当人们编写程序时，他们有能力通过将复杂的任务分解为更小、更熟悉的子任务来解决。虽然测量神经程序综合方法是否具有类似的能力是困难的，但我们可以测量的是它们是否可以以组合方式泛化，即在训练过程中已经训练过简单子任务的模型是否能够解决更复杂的任务。在本文中，我们着重测量了学习的程序综合器以组合泛化的能力。我们首先刻画了程序综合方法应该以不同轴曲线泛化，例如长度泛化，或者结合在训练数据中不存在的新方法组合已知子例程的能力。根据这一刻画，我们根据两个流行的现有数据集SCAN和RobustFill引入了一套任务基准来评估这些能力。最后，我们首次尝试改进组合泛化的方法。

    When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, what we can measure is whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we focus on measuring the ability of learned program synthesizers to compositionally generalize. We first characterize several different axes along which program synthesis methods would be desired to generalize, e.g., length generalization, or the ability to combine known subroutines in new ways that do not occur in the training data. Based on this characterization, we introduce a benchmark suite of tasks to assess these abilities based on two popular existing datasets, SCAN and RobustFill. Finally, we make first attempts to improve the compositional general
    
[^160]: CrossBeam: 在自底向上程序合成中学习搜索

    CrossBeam: Learning to Search in Bottom-Up Program Synthesis. (arXiv:2203.10452v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2203.10452](http://arxiv.org/abs/2203.10452)

    CrossBeam是一种在自底向上程序合成中学习搜索策略的方法，通过训练神经模型来选择如何合并先前探索的程序，以控制搜索空间的膨胀。

    

    许多程序合成方法在庞大的程序空间中进行搜索，以找到满足给定规范的程序。先前的工作使用神经模型来指导组合搜索算法，但是这样的方法仍然探索了搜索空间的很大部分，并且随着所需程序的大小增加，很快变得难以处理。为了控制搜索空间的膨胀问题，我们提出了一种训练神经模型来学习自底向上合成中的搜索策略的方法，而不是依赖于组合搜索算法。我们的方法称为CrossBeam，使用神经模型来选择如何将先前探索的程序组合成新的程序，考虑到搜索历史和部分程序的执行。受结构化预测中学习搜索的相关工作的启发，CrossBeam在训练任务上使用从自己的自底向上搜索中提取的数据来进行有策略的训练。我们在两个非常不同的领域，字符串操作和逻辑编程中评估了CrossBeam。

    Many approaches to program synthesis perform a search within an enormous space of programs to find one that satisfies a given specification. Prior works have used neural models to guide combinatorial search algorithms, but such approaches still explore a huge portion of the search space and quickly become intractable as the size of the desired program increases. To tame the search space blowup, we propose training a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm. Our approach, called CrossBeam, uses the neural model to choose how to combine previously-explored programs into new programs, taking into account the search history and partial program executions. Motivated by work in structured prediction on learning to search, CrossBeam is trained on-policy using data extracted from its own bottom-up searches on training tasks. We evaluate CrossBeam in two very different domains, string manipulation and logic pr
    
[^161]: 基于$\phi$-离散度的分布鲁棒贝叶斯优化

    Distributionally Robust Bayesian Optimization with $\phi$-divergences. (arXiv:2203.02128v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.02128](http://arxiv.org/abs/2203.02128)

    本研究提出了一种基于$\phi$-离散度的分布鲁棒贝叶斯优化算法。

    

    鲁棒性研究因其在面对不确定性的许多系统中不可避免而受到广泛关注。其中一个例子是贝叶斯优化，它面临着多方面的不确定性，但仅有少量的研究致力于这个方向。在现有研究的基础上，我们提出了一种基于$\phi$-离散度的分布鲁棒贝叶斯优化算法。

    The study of robustness has received much attention due to its inevitability in data-driven settings where many systems face uncertainty. One such example of concern is Bayesian Optimization (BO), where uncertainty is multi-faceted, yet there only exists a limited number of works dedicated to this direction. In particular, there is the work of Kirschner et al. (2020), which bridges the existing literature of Distributionally Robust Optimization (DRO) by casting the BO problem from the lens of DRO. While this work is pioneering, it admittedly suffers from various practical shortcomings such as finite contexts assumptions, leaving behind the main question Can one devise a computationally tractable algorithm for solving this DRO-BO problem? In this work, we tackle this question to a large degree of generality by considering robustness against data-shift in $\phi$-divergences, which subsumes many popular choices, such as the $\chi^2$-divergence, Total Variation, and the extant Kullback-Lei
    
[^162]: 学习与子集叠加

    Learning with Subset Stacking. (arXiv:2112.06251v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.06251](http://arxiv.org/abs/2112.06251)

    提出了一种新的回归算法LESS，通过生成以随机点为中心的子集并训练局部预测器，然后以新颖的方式组合预测器得到整体预测器。在多个数据集上测试表明，LESS是一种有竞争力且高效的监督学习方法。

    

    我们提出了一种新的回归算法，该算法从一组输入-输出对中进行学习。我们的算法适用于输入变量与输出变量之间的关系在预测空间中表现出异质行为的群体。该算法首先生成以输入空间中的随机点为中心的子集，然后为每个子集训练一个局部预测器。然后这些预测器以一种新颖的方式组合在一起，形成一个整体预测器。我们将此算法称为“学习与子集叠加”或LESS，因为它类似于叠加回归器的方法。我们将LESS与多个数据集上的最先进方法进行测试性能比较。我们的比较结果表明，LESS是一种有竞争力的监督学习方法。此外，我们观察到LESS在计算时间上也非常高效，并且可以直接进行并行实现。

    We propose a new regression algorithm that learns from a set of input-output pairs. Our algorithm is designed for populations where the relation between the input variables and the output variable exhibits a heterogeneous behavior across the predictor space. The algorithm starts with generating subsets that are concentrated around random points in the input space. This is followed by training a local predictor for each subset. Those predictors are then combined in a novel way to yield an overall predictor. We call this algorithm ``LEarning with Subset Stacking'' or LESS, due to its resemblance to the method of stacking regressors. We compare the testing performance of LESS with state-of-the-art methods on several datasets. Our comparison shows that LESS is a competitive supervised learning method. Moreover, we observe that LESS is also efficient in terms of computation time and it allows a straightforward parallel implementation.
    
[^163]: 高维随机镶嵌森林的极小极大率

    Minimax Rates for High-Dimensional Random Tessellation Forests. (arXiv:2109.10541v5 [math.ST] UPDATED)

    [http://arxiv.org/abs/2109.10541](http://arxiv.org/abs/2109.10541)

    本研究展示了一大类具有一般分割方向的随机森林能够在任意维度上实现极小极大的收敛率，包括STIT森林和源自泊松超平面镶嵌的随机森林。

    

    随机森林是一种常用于回归和分类的算法类。这个算法由Breiman于2001年引入，许多变体都是由特征空间的轴对齐区域划分构建的随机决策树的集合。其中一种变体称为Mondrian森林，用于处理在线设置，并且是第一个在任意维度上获得最小极大率的随机森林类别。然而，对于轴对齐分割的限制无法捕捉特征之间的依赖关系，并且使用斜切分割的随机森林在许多任务上显示出了改进的经验性能。在这项工作中，我们展示了一大类具有一般分割方向的随机森林也能在任意维度上实现极小极大收敛率。这类随机森林包括STIT森林，它是Mondrian森林到任意分割方向的推广，以及源自泊松超平面镶嵌的随机森林。

    Random forests are a popular class of algorithms used for regression and classification. The algorithm introduced by Breiman in 2001 and many of its variants are ensembles of randomized decision trees built from axis-aligned partitions of the feature space. One such variant, called Mondrian forests, was proposed to handle the online setting and is the first class of random forests for which minimax rates were obtained in arbitrary dimension. However, the restriction to axis-aligned splits fails to capture dependencies between features, and random forests that use oblique splits have shown improved empirical performance for many tasks. In this work, we show that a large class of random forests with general split directions also achieve minimax optimal convergence rates in arbitrary dimension. This class includes STIT forests, a generalization of Mondrian forests to arbitrary split directions, as well as random forests derived from Poisson hyperplane tessellations. These are the first re
    
[^164]: 连续条件生成对抗网络：创新的经验损失和标签输入机制

    Continuous Conditional Generative Adversarial Networks: Novel Empirical Losses and Label Input Mechanisms. (arXiv:2011.07466v9 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2011.07466](http://arxiv.org/abs/2011.07466)

    本文提出了连续条件生成对抗网络（CcGAN），首个用于基于连续标量条件的图像生成的生成模型。通过重新构建经验cGAN损失和提出新的标签输入方法，解决了在回归标签条件生成中存在的问题。

    

    本文提出了连续条件生成对抗网络（CcGAN），这是首个用于基于连续标量条件（称为回归标签）的图像生成的生成模型。现有的条件GAN（cGAN）主要设计用于分类条件（例如类标签）；对于回归标签的条件生成则在数学上有所不同，引发了两个基本问题：（P1）由于某些回归标签可能没有真实图像，最小化现有的经验cGAN损失（也称为经验cGAN损失）在实践中通常不起作用；（P2）由于回归标签是连续的且无限多，传统的标签输入方法不适用。所提出的CcGAN通过分别（S1）重新构建现有的经验cGAN损失以适应连续场景；以及（S2）提出一种简单的标签输入（NLI）方法和一种改进的标签输入（ILI）方法将回归标签融入模型，解决了上述问题。

    This work proposes the continuous conditional generative adversarial network (CcGAN), the first generative model for image generation conditional on continuous, scalar conditions (termed regression labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (eg, class labels); conditioning on regression labels is mathematically distinct and raises two fundamental problems:(P1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses (aka empirical cGAN losses) often fails in practice;(P2) Since regression labels are scalar and infinitely many, conventional label input methods are not applicable. The proposed CcGAN solves the above problems, respectively, by (S1) reformulating existing empirical cGAN losses to be appropriate for the continuous scenario; and (S2) proposing a naive label input (NLI) method and an improved label input (ILI) method to incorporate regression labels into
    
[^165]: BSDAR: 基于注意力奖励的神经关键词生成中的束搜索解码

    BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase Generation. (arXiv:1909.09485v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/1909.09485](http://arxiv.org/abs/1909.09485)

    本研究提出了一种基于注意力奖励的束搜索解码策略，用于解决神经关键词生成中的序列长度偏差和束多样性问题，该方法显著提高了生成关键词的解码性能。

    

    本研究主要研究神经关键词生成中的两个常见解码问题：序列长度偏差和束多样性。为了解决这些问题，我们引入了一种基于词级和ngram级奖励函数的束搜索解码策略，以在测试时约束和优化Seq2Seq推理过程。结果表明，我们简单的提案可以克服算法对较短和几乎相同的序列的偏好，从而显著提高生成源文本中存在和不存在的关键词的解码性能。

    This study mainly investigates two common decoding problems in neural keyphrase generation: sequence length bias and beam diversity. To tackle the problems, we introduce a beam search decoding strategy based on word-level and ngram-level reward function to constrain and refine Seq2Seq inference at test time. Results show that our simple proposal can overcome the algorithm bias to shorter and nearly identical sequences, resulting in a significant improvement of the decoding performance on generating keyphrases that are present and absent in source text.
    
[^166]: 针对未预料到的对手测试鲁棒性

    Testing Robustness Against Unforeseen Adversaries. (arXiv:1908.08016v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1908.08016](http://arxiv.org/abs/1908.08016)

    该论文提出了18种新的对抗攻击，并使用这些攻击创建了一个用于评估对各种未预料到的对手的鲁棒性的新基准。作者还发现了一系列防御策略，可以帮助克服训练期间未考虑到的对手的泛化差距。该研究的结果将为研究现实世界最坏情况下的鲁棒性提供有用工具，促进开发更强大的防御措施。

    

    在考虑现实世界的对抗环境时，防御者在训练期间不太可能对所有可能的对手进行训练，并且对手很可能使用逼真的对抗扭曲，而不限于小的L_p约束扰动。为了缩小研究和现实之间的差距，我们介绍了18种新的对抗攻击，并使用它们创建了ImageNet-UA，这是一个用于评估模型对各种未预料到的对手的鲁棒性的新基准。我们利用这个基准来识别一系列能够帮助克服这种泛化差距的防御策略，发现了可以提高对未预料到的攻击的鲁棒性的技术的丰富空间。我们希望ImageNet-UA的更多样性和逼真性将成为那些研究现实世界最坏情况的鲁棒性的人的有用工具，从而促进开发能够在训练期间看不到的攻击中进行泛化的更强大的防御措施。

    When considering real-world adversarial settings, defenders are unlikely to have access to the full range of deployment-time adversaries during training, and adversaries are likely to use realistic adversarial distortions that will not be limited to small L_p-constrained perturbations. To narrow in on this discrepancy between research and reality we introduce eighteen novel adversarial attacks, which we use to create ImageNet-UA, a new benchmark for evaluating model robustness against a wide range of unforeseen adversaries. We make use of our benchmark to identify a range of defense strategies which can help overcome this generalization gap, finding a rich space of techniques which can improve unforeseen robustness. We hope the greater variety and realism of ImageNet-UA will make it a useful tool for those working on real-world worst-case robustness, enabling development of more robust defenses which can generalize beyond attacks seen during training.
    
[^167]: 加权赌博机或者：赌博机如何学习预期之外的扭曲价值

    Weighted bandits or: How bandits learn distorted values that are not expected. (arXiv:1611.10283v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1611.10283](http://arxiv.org/abs/1611.10283)

    本论文研究了带有扭曲概率的随机多臂赌博机问题，并提出了以UCB算法为基础、考虑了奖励扭曲并具有次线性后悔的算法。

    

    受到用于解释常见偏离传统预期价值偏好的人类决策模型的启发，我们提出了两个带有扭曲概率的随机多臂赌博机问题：经典的K臂赌博机和线性参数化赌博机设置。我们在对多臂赌博机的后悔最小化和最佳臂识别框架下研究了上述问题。对于K臂赌博机以及线性赌博机问题的后悔最小化设置，我们提出了受到上置信界(UCB)算法启发、包含奖励扭曲并且具有次线性后悔的算法。对于K臂赌博机设置，我们得出了对我们提出的算法的预期后悔的上界，然后我们证明了一个匹配的下界，以验证我们算法的次线性优化顺序。对于线性参数化设置，我们的算法实现了一个后悔上界，该上界是次线性的。

    Motivated by models of human decision making proposed to explain commonly observed deviations from conventional expected value preferences, we formulate two stochastic multi-armed bandit problems with distorted probabilities on the reward distributions: the classic $K$-armed bandit and the linearly parameterized bandit settings. We consider the aforementioned problems in the regret minimization as well as best arm identification framework for multi-armed bandits. For the regret minimization setting in $K$-armed as well as linear bandit problems, we propose algorithms that are inspired by Upper Confidence Bound (UCB) algorithms, incorporate reward distortions, and exhibit sublinear regret. For the $K$-armed bandit setting, we derive an upper bound on the expected regret for our proposed algorithm, and then we prove a matching lower bound to establish the order-optimality of our algorithm. For the linearly parameterized setting, our algorithm achieves a regret upper bound that is of the 
    

