# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://arxiv.org/abs/2402.18571) | 提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。 |
| [^2] | [Implicit Bias of Next-Token Prediction](https://arxiv.org/abs/2402.18551) | 在基于梯度的优化器训练下的线性NTP模型中，确定了NTP可分离条件，并证明梯度下降能够实现其下界；同时证明了这些条件在过参数化时仍然成立。 |
| [^3] | [RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval](https://arxiv.org/abs/2402.18510) | 本文研究了RNNs和Transformer在处理算法问题时的表现能力差距，发现RNNs存在关键瓶颈，即无法完美地从上下文中检索信息，导致无法像Transformer那样轻松解决需要这种能力的任务。 |
| [^4] | [Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes](https://arxiv.org/abs/2402.18477) | 本文在随机过程中开发了一种基于签名核的条件独立性测试，实现了对因果关系的推断，以及开发了约束条件的因果发现算法用于恢复整个有向图。 |
| [^5] | [Unveiling the Potential of Robustness in Evaluating Causal Inference Models](https://arxiv.org/abs/2402.18392) | 介绍了一种新颖的分布式健壮度量（DRM）方法，以解决选择理想因果推断模型中健壮估计器的挑战。 |
| [^6] | [A network-constrain Weibull AFT model for biomarkers discovery](https://arxiv.org/abs/2402.18242) | 提出了一种基于网络约束的Weibull AFT模型，在变量选择和估计方面采用惩罚似然方法，同时结合了稀疏性和分组效应，具有理论一致性和高效的计算算法。 |
| [^7] | [Multi-objective Differentiable Neural Architecture Search](https://arxiv.org/abs/2402.18213) | 提出了一种新颖的NAS算法，可以在一个搜索运行中编码用户对性能和硬件指标之间的权衡偏好，生成精心选择的多设备架构。 |
| [^8] | [Provably Efficient Partially Observable Risk-Sensitive Reinforcement Learning with Hindsight Observation](https://arxiv.org/abs/2402.18149) | 本研究提出了一种在部分可观察环境中带有事后观察的风险敏感强化学习的新方法，设计了第一个特定算法并证明其在此设置下取得了高效性能。 |
| [^9] | [Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach](https://arxiv.org/abs/2402.17987) | 提出了一种完全贝叶斯雷达自动目标识别的框架，采用最优贝叶斯融合来有效地汇总多个雷达的分类概率向量，以改进无人机雷达截面识别效果。 |
| [^10] | [Sequential transport maps using SoS density estimation and $\alpha$-divergences](https://arxiv.org/abs/2402.17943) | 本研究探讨了使用SoS密度和α-离散度来近似中间密度的顺序传输映射框架，通过将两者结合，可以有效地解决凸优化问题，进而实现从未标准化的密度生成样本。 |
| [^11] | [Certain and Approximately Certain Models for Statistical Learning](https://arxiv.org/abs/2402.17926) | 可以直接从带有缺失值的数据中学习准确模型，构建了检查数据填充必要性的高效算法，并在不需要填充的情况下返回准确模型，显著减少数据填充所需的时间和精力 |
| [^12] | [Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion](https://arxiv.org/abs/2402.17886) | 本文提出了一种基于去噪扩散过程的零阶扩散蒙特卡洛算法，克服了非对数凹分布采样中的亚稳定性问题，并证明其采样精度具有倒多项式依赖。 |
| [^13] | [Stochastic Approximation with Biased MCMC for Expectation Maximization](https://arxiv.org/abs/2402.17870) | 本研究分析了使用偏置MCMC步骤的SAEM的渐近性和非渐近性，特别关注偏置的影响，并填补了这一领域的理论空白。 |
| [^14] | [Stable LM 2 1.6B Technical Report](https://arxiv.org/abs/2402.17834) | 稳定LM 2 1.6B是语言模型系列中的新一代产品，在该报告中详细介绍了其数据、训练过程和性能评估，该模型在发布时是2B参数范围内最先进的开源模型之一，并提供了下载链接和性能对比数据。 |
| [^15] | [Prediction-Powered Ranking of Large Language Models](https://arxiv.org/abs/2402.17826) | 该研究提出了一种统计框架，可以衡量人类与模型偏好之间的不确定性，从而进行大型语言模型的预测排名。 |
| [^16] | [Material Microstructure Design Using VAE-Regression with Multimodal Prior](https://arxiv.org/abs/2402.17806) | 该论文提出了一种使用VAE-回归与多模态先验设计材料微结构的模型，通过将VAE与回归相结合，并通过双层先验来链接这两个模型，学习了微结构特征，可用于正向和逆向预测。 |
| [^17] | [DAGnosis: Localized Identification of Data Inconsistencies using Structures](https://arxiv.org/abs/2402.17599) | DAGnosis使用有向无环图(DAGs)来解决数据一致性检测中的两个关键限制，并能够准确定位为何样本会被标记为不一致。 |
| [^18] | [Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control](https://arxiv.org/abs/2402.15194) | 扩散模型的微调方法可以通过最大化奖励函数的价值来以目标导向方式进行微调，但可能会面临奖励崩溃的挑战。 |
| [^19] | [HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments](https://arxiv.org/abs/2402.10228) | HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。 |
| [^20] | [Stein Boltzmann Sampling: A Variational Approach for Global Optimization](https://arxiv.org/abs/2402.04689) | Stein Boltzmann抽样（SBS）是一种全局优化的变分方法，通过从Boltzmann分布中采样，由Stein Variational Gradient Descent算法实现，具有渐近收敛性，并在各种基准函数上比较了几种最先进的全局优化算法，尤其适合作为高效全局优化方法的延续，能够产生更好的解决方案并有效利用预算。 |
| [^21] | [Consistency Models for Scalable and Fast Simulation-Based Inference](https://arxiv.org/abs/2312.05440) | 提出了一种新的神经后验估计的一致性模型，结合了标准化流和流匹配方法的优点，用于可扩展、快速和摊销推断，在多个实验中展示出优越性能。 |
| [^22] | [Detecting algorithmic bias in medical AI-models](https://arxiv.org/abs/2312.02959) | 本文提出了一种创新的框架，用于检测医疗AI决策支持系统中的算法偏倚，通过采用CART算法有效地识别医疗AI模型中的潜在偏倚，并在合成数据实验和真实临床环境中验证了其有效性。 |
| [^23] | [Learning in Deep Factor Graphs with Gaussian Belief Propagation](https://arxiv.org/abs/2311.14649) | 提出了一种在高斯因子图中进行学习的方法，利用置信传播解决训练和预测问题，支持分布式和异步训练，可扩展至深度网络，提供持续学习的自然方式，并展示了在视频去噪和图像分类任务中的优势。 |
| [^24] | [Streaming data recovery via Bayesian tensor train decomposition](https://arxiv.org/abs/2302.12148) | 通过贝叶斯张量列车分解方法，在高阶、不完整和嘈杂的流数据中，实现了流数据的恢复和准确性 |
| [^25] | [The good, the bad and the ugly sides of data augmentation: An implicit spectral regularization perspective](https://arxiv.org/abs/2210.05021) | 数据增强在机器学习中扮演着重要作用，而该研究提出了一个新的理论框架，揭示了数据增强通过隐式谱正则化对线性模型泛化的影响。 |
| [^26] | [Inference for Heteroskedastic PCA with Missing Data](https://arxiv.org/abs/2107.12365) | 该研究提出了一种针对高维度下主成分分析（PCA）的置信区间构建方法，特别解决了缺失数据和异方差噪声的挑战。 |
| [^27] | [Efficient local linearity regularization to overcome catastrophic overfitting.](http://arxiv.org/abs/2401.11618) | 本研究引入了一种名为ELLE的正则化项，用于高效地减轻单步对抗性训练中的灾难性过拟合。它能够保持损失函数在输入上的局部线性性，与传统的正则化方法相比，ELLE更加高效，能够有效应对大对抗性扰动和长训练计划等困难情况。 |
| [^28] | [Bayesian Prognostic Covariate Adjustment With Additive Mixture Priors.](http://arxiv.org/abs/2310.18027) | 提出了一种新的贝叶斯预后协变量调整方法，结合了协变量调整和历史对照信息利用的策略，在随机对照试验中用于有效和快速决策。通过生成型人工智能算法构建数字孪生生成器，利用历史对照数据产生数字孪生概率分布，从而进行单一协变量调整。 |
| [^29] | [Looping in the Human: Collaborative and Explainable Bayesian Optimization.](http://arxiv.org/abs/2310.17273) | 协作和可解释的贝叶斯优化框架(CoExBO)在贝叶斯优化中引入了循环，平衡了人工智能和人类的合作关系。它利用偏好学习将用户见解融合到优化中，解释每次迭代的候选选择，从而增强用户对优化过程的信任，并提供无害保证。 |
| [^30] | [On the different regimes of Stochastic Gradient Descent.](http://arxiv.org/abs/2309.10688) | 这项研究解决了对于随机梯度下降（SGD）中不同模式的追踪和理解的问题，提供了一个相位图来区分噪声主导的SGD和大步骤主导的SGD。 |
| [^31] | [Outlier-Robust Tensor Low-Rank Representation for Data Clustering.](http://arxiv.org/abs/2307.09055) | 本文提出了一种异常鲁棒张量低秩表示方法，用于同时检测异常值和进行数据聚类。该方法基于张量奇异值分解（t-SVD）代数框架，并在较弱条件下具有恢复干净数据的行空间和检测异常值的可证明性能保证。此外，还提出了扩展方法以处理数据部分缺失的情况。 |
| [^32] | [Fast and Minimax Optimal Estimation of Low-Rank Matrices via Non-Convex Gradient Descent.](http://arxiv.org/abs/2305.17224) | 本文提出一种针对低秩矩阵估计的方法，在保证极小极值优化性能的同时，解决了非凸梯度下降收敛缓慢的问题。 |
| [^33] | [Semi-Supervised Clustering of Sparse Graphs: Crossing the Information-Theoretic Threshold.](http://arxiv.org/abs/2205.11677) | 该论文提出了两种有效的算法来将标签信息与稀疏图结构相结合，解决了基于网络拓扑的聚类在稀疏图上的问题。 |

# 详细

[^1]: 用于满足多样用户偏好的算术控制LLMs：具有多目标奖励的方向偏好对齐

    Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards

    [https://arxiv.org/abs/2402.18571](https://arxiv.org/abs/2402.18571)

    提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。

    

    针对大型语言模型（LLMs）的精细控制仍然是一个重要挑战，阻碍了它们适应各种用户需求。本文提出了方向偏好对齐（DPA）框架，通过多目标奖励建模来表示多样化的偏好配置，将用户偏好建模为奖励空间中的方向（即单位向量）以实现用户相关的偏好控制。

    arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
    
[^2]: 隐性偏见的下一个标记预测

    Implicit Bias of Next-Token Prediction

    [https://arxiv.org/abs/2402.18551](https://arxiv.org/abs/2402.18551)

    在基于梯度的优化器训练下的线性NTP模型中，确定了NTP可分离条件，并证明梯度下降能够实现其下界；同时证明了这些条件在过参数化时仍然成立。

    

    下一个标记预测（NTP）是训练大型语言模型的首选范式，它涉及预测序列中的下一个标记。与传统的独热分类不同，在NTP中，多个具有不同频率的标记在给定上下文后继。本文将NTP训练框架化为跨不同上下文的交叉熵最小化，每个上下文都与有限词汇表中的稀疏经验概率向量相关联。然后，它探讨了以下问题：当NTP训练损失达到其下界（熵）时，基于梯度的优化器是否会对具有特定结构的解决方案存在偏见？具体地，对于使用梯度下降（GD）训练的线性NTP模型，我们做出以下贡献：首先，我们确定了数据上的NTP可分离条件，在这些条件下，GD能够达到其下界。我们还证明了这些条件在过参数化时仍成立。

    arXiv:2402.18551v1 Announce Type: cross  Abstract: Next-token prediction (NTP), the go-to training paradigm in training large language models, involves predicting the next token in a sequence. Departing from traditional one-hot classification, in NTP, multiple tokens with varying frequencies follow each given context. This work frames NTP training as cross-entropy minimization over distinct contexts, each associated with a sparse empirical probability vector across a finite vocabulary. It then addresses the following question: do gradient-based optimizers exhibit a bias towards solutions with specific structure as the NTP training loss reaches its lower bound (entropy)? Specifically, for linear NTP models trained using gradient descent (GD), we make the following contributions: Firstly, we determine NTP-separability conditions on the data, under which GD can attain its lower bound. We also demonstrate that these conditions hold under overparameterization. Secondly, we establish that th
    
[^3]: RNNs还不是Transformer：在上下文检索中的关键瓶颈

    RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval

    [https://arxiv.org/abs/2402.18510](https://arxiv.org/abs/2402.18510)

    本文研究了RNNs和Transformer在处理算法问题时的表现能力差距，发现RNNs存在关键瓶颈，即无法完美地从上下文中检索信息，导致无法像Transformer那样轻松解决需要这种能力的任务。

    

    本文探讨循环神经网络（RNNs）和Transformer在解决算法问题时的表示能力差距。我们重点关注RNNs是否能在处理长序列时，通过Chain-of-Thought (CoT)提示，与Transformer的性能相匹配。我们的理论分析显示CoT可以改进RNNs，但无法弥补与Transformer之间的差距。关键瓶颈在于RNNs无法完全从上下文中检索信息，即使经过CoT的增强：对于几个明确或隐式需要这种能力的任务，如联想召回和确定图是否为树，我们证明RNNs表达能力不足以解决这些任务，而Transformer可以轻松解决。相反，我们证明采用增强RNNs上下文检索能力的技术，包括

    arXiv:2402.18510v1 Announce Type: cross  Abstract: This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, inclu
    
[^4]: 在因果发现中的签名核条件独立性测试用于随机过程

    Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes

    [https://arxiv.org/abs/2402.18477](https://arxiv.org/abs/2402.18477)

    本文在随机过程中开发了一种基于签名核的条件独立性测试，实现了对因果关系的推断，以及开发了约束条件的因果发现算法用于恢复整个有向图。

    

    从观测数据中推断随机动力系统背后的因果结构在科学、健康和金融等领域具有巨大潜力。本文通过利用最近签名核技术的进展，开发了一种基于内核的“路径空间”上条件独立性（CI）测试，用于随机微分方程的解。我们展示了相较于现有方法，在路径空间上，我们提出的CI测试表现出严格更好的性能。此外，我们还为非循环随机动力系统开发了基于约束的因果发现算法，利用时间信息来恢复整个有向图。在假设忠实性和CI预言机的情况下，我们的算法是完备且正确的。

    arXiv:2402.18477v1 Announce Type: cross  Abstract: Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via "which variables enter the differential of which other variables". In this paper, we develop a kernel-based test of conditional independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirical
    
[^5]: 揭示健壮性在评估因果推断模型中的潜力

    Unveiling the Potential of Robustness in Evaluating Causal Inference Models

    [https://arxiv.org/abs/2402.18392](https://arxiv.org/abs/2402.18392)

    介绍了一种新颖的分布式健壮度量（DRM）方法，以解决选择理想因果推断模型中健壮估计器的挑战。

    

    越来越多对个性化决策制定的需求导致人们对估计条件平均处理效应（CATE）产生了兴趣。机器学习和因果推断的交叉领域已经产生了各种有效的CATE估计器。然而，在实践中使用这些估计器通常受制于缺乏反事实标签，因此使用传统的交叉验证等模型选择程序来选择理想的CATE估计器变得具有挑战性。现有的CATE估计器选择方法，如插值和伪结果度量，面临着两个固有挑战。首先，它们需要确定度量形式和拟合干扰参数或插件学习者的基础机器学习模型。其次，它们缺乏针对选择健壮估计器的特定重点。为解决这些挑战，本文引入了一种新颖的方法，分布式健壮度量（DRM）。

    arXiv:2402.18392v1 Announce Type: cross  Abstract: The growing demand for personalized decision-making has led to a surge of interest in estimating the Conditional Average Treatment Effect (CATE). The intersection of machine learning and causal inference has yielded various effective CATE estimators. However, deploying these estimators in practice is often hindered by the absence of counterfactual labels, making it challenging to select the desirable CATE estimator using conventional model selection procedures like cross-validation. Existing approaches for CATE estimator selection, such as plug-in and pseudo-outcome metrics, face two inherent challenges. Firstly, they are required to determine the metric form and the underlying machine learning models for fitting nuisance parameters or plug-in learners. Secondly, they lack a specific focus on selecting a robust estimator. To address these challenges, this paper introduces a novel approach, the Distributionally Robust Metric (DRM), for 
    
[^6]: 基于网络约束的Weibull AFT模型用于生物标志物发现

    A network-constrain Weibull AFT model for biomarkers discovery

    [https://arxiv.org/abs/2402.18242](https://arxiv.org/abs/2402.18242)

    提出了一种基于网络约束的Weibull AFT模型，在变量选择和估计方面采用惩罚似然方法，同时结合了稀疏性和分组效应，具有理论一致性和高效的计算算法。

    

    我们提出了AFTNet，一种新颖的基于Weibull加速失效时间（AFT）模型的网络约束生存分析方法，通过惩罚似然方法进行变量选择和估计。当使用对数线性表示时，推断问题变成了一个结构稀疏回归问题，我们明确地结合了预测因子之间的相关模式，使用双重惩罚促进稀疏性和分组效应。此外，我们为AFTNet估计器建立了理论一致性，并提出了基于近端梯度下降方法的高效迭代计算算法。最后，我们在合成和真实数据示例上评估了AFTNet的性能。

    arXiv:2402.18242v1 Announce Type: new  Abstract: We propose AFTNet, a novel network-constraint survival analysis method based on the Weibull accelerated failure time (AFT) model solved by a penalized likelihood approach for variable selection and estimation. When using the log-linear representation, the inference problem becomes a structured sparse regression problem for which we explicitly incorporate the correlation patterns among predictors using a double penalty that promotes both sparsity and grouping effect. Moreover, we establish the theoretical consistency for the AFTNet estimator and present an efficient iterative computational algorithm based on the proximal gradient descent method. Finally, we evaluate AFTNet performance both on synthetic and real data examples.
    
[^7]: 多目标可微神经架构搜索

    Multi-objective Differentiable Neural Architecture Search

    [https://arxiv.org/abs/2402.18213](https://arxiv.org/abs/2402.18213)

    提出了一种新颖的NAS算法，可以在一个搜索运行中编码用户对性能和硬件指标之间的权衡偏好，生成精心选择的多设备架构。

    

    多目标优化（MOO）中的Pareto前沿轮廓剖析是具有挑战性的，尤其是在像神经网络训练这样的昂贵目标中。 相对于传统的NAS方法，我们提出了一种新颖的NAS算法，该算法在一个搜索运行中编码用户对性能和硬件指标之间的权衡偏好，并生成精心选择的多设备架构。为此，我们通过一个超网络参数化跨多个设备和多个目标的联合架构分布，超网络可以根据硬件特征和偏好向量进行条件化，实现零次搜索。

    arXiv:2402.18213v1 Announce Type: new  Abstract: Pareto front profiling in multi-objective optimization (MOO), i.e. finding a diverse set of Pareto optimal solutions, is challenging, especially with expensive objectives like neural network training. Typically, in MOO neural architecture search (NAS), we aim to balance performance and hardware metrics across devices. Prior NAS approaches simplify this task by incorporating hardware constraints into the objective function, but profiling the Pareto front necessitates a search for each constraint. In this work, we propose a novel NAS algorithm that encodes user preferences for the trade-off between performance and hardware metrics, and yields representative and diverse architectures across multiple devices in just one search run. To this end, we parameterize the joint architectural distribution across devices and multiple objectives via a hypernetwork that can be conditioned on hardware features and preference vectors, enabling zero-shot t
    
[^8]: 在具有事后观察的部分可观察风险敏感强化学习中具有可证的高效性

    Provably Efficient Partially Observable Risk-Sensitive Reinforcement Learning with Hindsight Observation

    [https://arxiv.org/abs/2402.18149](https://arxiv.org/abs/2402.18149)

    本研究提出了一种在部分可观察环境中带有事后观察的风险敏感强化学习的新方法，设计了第一个特定算法并证明其在此设置下取得了高效性能。

    

    这项工作在带有事后观察的部分可观察环境中探索了风险敏感强化学习的后悔分析，填补了理论探索中的空白。我们引入了一种新颖的方案，将事后观察整合到部分可观察马尔可夫决策过程（POMDP）框架中，目标是在熵风险度量下优化累积奖励。我们开发了针对这种情况的第一个可证高效RL算法。我们还通过严格分析证明，我们的算法实现了多项式后悔$\tilde{O}\left(\frac{e^{|{\gamma}|H}-1}{|{\gamma}|H}H^2\sqrt{KHS^2OA}\right)$，当模型退化为风险中性或完全可观测设置时，它超越或匹配现有的上限。我们采用变换测度方法，并开发了一种新颖的beta向量分析工具来简化数学推导。这些技术特别引人注目。

    arXiv:2402.18149v1 Announce Type: new  Abstract: This work pioneers regret analysis of risk-sensitive reinforcement learning in partially observable environments with hindsight observation, addressing a gap in theoretical exploration. We introduce a novel formulation that integrates hindsight observations into a Partially Observable Markov Decision Process (POMDP) framework, where the goal is to optimize accumulated reward under the entropic risk measure. We develop the first provably efficient RL algorithm tailored for this setting. We also prove by rigorous analysis that our algorithm achieves polynomial regret $\tilde{O}\left(\frac{e^{|{\gamma}|H}-1}{|{\gamma}|H}H^2\sqrt{KHS^2OA}\right)$, which outperforms or matches existing upper bounds when the model degenerates to risk-neutral or fully observable settings. We adopt the method of change-of-measure and develop a novel analytical tool of beta vectors to streamline mathematical derivations. These techniques are of particular interes
    
[^9]: 多态雷达对空中飞行器雷达截面识别：一种贝叶斯融合方法

    Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach

    [https://arxiv.org/abs/2402.17987](https://arxiv.org/abs/2402.17987)

    提出了一种完全贝叶斯雷达自动目标识别的框架，采用最优贝叶斯融合来有效地汇总多个雷达的分类概率向量，以改进无人机雷达截面识别效果。

    

    arXiv:2402.17987v1 公告类型：跨领域 摘要：无人机的雷达自动目标识别（RATR）涉及发射电磁波并对接收到的雷达回波执行目标类型识别，对国防和航空航天应用至关重要。先前的研究突出了多态雷达配置在RATR中优于单态雷达的优势。然而，多态雷达配置中的融合方法通常以概率方式次优地组合来自各个雷达的分类向量。为了解决这个问题，我们提出了一个完全贝叶斯RATR框架，采用最优贝叶斯融合（OBF）来聚合来自多个雷达的分类概率向量。OBF基于期望0-1损失，根据多个时间步骤的历史观测更新目标无人机类型的递归贝叶斯分类（RBC）后验分布。我们使用模拟的随机行走轨迹评估了这种方法，共涉及七种机动目标。

    arXiv:2402.17987v1 Announce Type: cross  Abstract: Radar Automated Target Recognition (RATR) for Unmanned Aerial Vehicles (UAVs) involves transmitting Electromagnetic Waves (EMWs) and performing target type recognition on the received radar echo, crucial for defense and aerospace applications. Previous studies highlighted the advantages of multistatic radar configurations over monostatic ones in RATR. However, fusion methods in multistatic radar configurations often suboptimally combine classification vectors from individual radars probabilistically. To address this, we propose a fully Bayesian RATR framework employing Optimal Bayesian Fusion (OBF) to aggregate classification probability vectors from multiple radars. OBF, based on expected 0-1 loss, updates a Recursive Bayesian Classification (RBC) posterior distribution for target UAV type, conditioned on historical observations across multiple time steps. We evaluate the approach using simulated random walk trajectories for seven dro
    
[^10]: 使用SoS密度估计和α-离散度的顺序传输映射

    Sequential transport maps using SoS density estimation and $\alpha$-divergences

    [https://arxiv.org/abs/2402.17943](https://arxiv.org/abs/2402.17943)

    本研究探讨了使用SoS密度和α-离散度来近似中间密度的顺序传输映射框架，通过将两者结合，可以有效地解决凸优化问题，进而实现从未标准化的密度生成样本。

    

    基于传输的密度估计方法因其能够有效地从近似密度生成样本而受到越来越多的关注。我们进一步调查了提出的顺序传输映射框架，该框架建立在一系列组成的Knothe-Rosenblatt（KR）映射之上。其中每个映射都是通过首先估计中等复杂度的中间密度，然后通过计算从参考密度到预计算近似密度的精确KR映射而构建的。在我们的工作中，我们探索了使用SoS密度和α-离散度来近似中间密度。有趣的是，将SoS密度与α-离散度相结合产生了凸优化问题，可以通过半定编程有效地解决。α-离散度的主要优势在于使得能够处理未标准化的密度，从而提供...

    arXiv:2402.17943v1 Announce Type: cross  Abstract: Transport-based density estimation methods are receiving growing interest because of their ability to efficiently generate samples from the approximated density. We further invertigate the sequential transport maps framework proposed from arXiv:2106.04170 arXiv:2303.02554, which builds on a sequence of composed Knothe-Rosenblatt (KR) maps. Each of those maps are built by first estimating an intermediate density of moderate complexity, and then by computing the exact KR map from a reference density to the precomputed approximate density. In our work, we explore the use of Sum-of-Squares (SoS) densities and $\alpha$-divergences for approximating the intermediate densities. Combining SoS densities with $\alpha$-divergence interestingly yields convex optimization problems which can be efficiently solved using semidefinite programming. The main advantage of $\alpha$-divergences is to enable working with unnormalized densities, which provide
    
[^11]: 统计学习的确定性和近似确定性模型

    Certain and Approximately Certain Models for Statistical Learning

    [https://arxiv.org/abs/2402.17926](https://arxiv.org/abs/2402.17926)

    可以直接从带有缺失值的数据中学习准确模型，构建了检查数据填充必要性的高效算法，并在不需要填充的情况下返回准确模型，显著减少数据填充所需的时间和精力

    

    现实世界中的数据通常是不完整的，并且包含缺失值。为了在真实世界的数据集上训练准确的模型，用户需要花费大量时间和资源填充和找到缺失数据项的正确值。本文表明，对于某些训练数据和目标模型，可以直接从具有缺失值的数据中学习准确的模型。我们提出了一种统一的方法，可以检查数据填充的必要性，以便在各种广泛使用的机器学习范例中学习准确的模型。我们构建了具有理论保证的高效算法来检查此必要性，并在不需要填充的情况下返回准确的模型。我们广泛的实验证明，我们提出的算法显著减少了数据填充所需的时间和精力，而没有带来相当大的计算开销。

    arXiv:2402.17926v1 Announce Type: cross  Abstract: Real-world data is often incomplete and contains missing values. To train accurate models over real-world datasets, users need to spend a substantial amount of time and resources imputing and finding proper values for missing data items. In this paper, we demonstrate that it is possible to learn accurate models directly from data with missing values for certain training data and target models. We propose a unified approach for checking the necessity of data imputation to learn accurate models across various widely-used machine learning paradigms. We build efficient algorithms with theoretical guarantees to check this necessity and return accurate models in cases where imputation is unnecessary. Our extensive experiments indicate that our proposed algorithms significantly reduce the amount of time and effort needed for data imputation without imposing considerable computational overhead.
    
[^12]: 用于非对数凹分布的零阶采样方法：通过去噪扩散缓解亚稳定性

    Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion

    [https://arxiv.org/abs/2402.17886](https://arxiv.org/abs/2402.17886)

    本文提出了一种基于去噪扩散过程的零阶扩散蒙特卡洛算法，克服了非对数凹分布采样中的亚稳定性问题，并证明其采样精度具有倒多项式依赖。

    

    这篇论文考虑了基于其非对数凹分布未归一化密度查询的采样问题。首先描述了一个基于模拟去噪扩散过程的框架，即扩散蒙特卡洛（DMC），其得分函数通过通用蒙特卡洛估计器逼近。DMC是一个基于神谕的元算法，其中神谕是假设可以访问生成蒙特卡洛分数估计器的样本的访问。然后，我们提供了一个基于拒绝采样的这个神谕的实现，这将DMC转化为一个真正的算法，称为零阶扩散蒙特卡洛（ZOD-MC）。我们通过首先构建一个通用框架，即DMC的性能保证，而不假设目标分布为对数凹或满足任何等周不等式，提供了收敛分析。然后我们证明ZOD-MC对所需采样精度具有倒多项式依赖，尽管仍然受到...

    arXiv:2402.17886v1 Announce Type: cross  Abstract: This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Diffusion Monte Carlo (DMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit sti
    
[^13]: 使用偏置MCMC进行随机逼近的期望最大化

    Stochastic Approximation with Biased MCMC for Expectation Maximization

    [https://arxiv.org/abs/2402.17870](https://arxiv.org/abs/2402.17870)

    本研究分析了使用偏置MCMC步骤的SAEM的渐近性和非渐近性，特别关注偏置的影响，并填补了这一领域的理论空白。

    

    arXiv:2402.17870v1 通告类型：跨领域 摘要：期望最大化（EM）算法是一种广泛用于经验贝叶斯推断的方法，但其期望步骤（E步骤）经常难以处理。采用带有马尔可夫链蒙特卡洛（MCMC）的随机逼近方案可以避开这个问题，得到一种称为MCMC-SAEM的算法。虽然先前已经确立了MCMC-SAEM的理论保证，但这些结果仅适用于使用渐近无偏MCMC算法的情况。在实践中，MCMC-SAEM经常使用渐近有偏的MCMC运行，对于这种情况，其理论后果尚不为人了解。在这项工作中，我们通过分析带有偏置MCMC步骤的SAEM的渐近性和非渐近性，特别是偏置的影响来填补这一空白。我们还提供了比较Metropolis调整的朗维新算法（MALA）和未经调整的朗维新算法（ULA）的数值实验。

    arXiv:2402.17870v1 Announce Type: cross  Abstract: The expectation maximization (EM) algorithm is a widespread method for empirical Bayesian inference, but its expectation step (E-step) is often intractable. Employing a stochastic approximation scheme with Markov chain Monte Carlo (MCMC) can circumvent this issue, resulting in an algorithm known as MCMC-SAEM. While theoretical guarantees for MCMC-SAEM have previously been established, these results are restricted to the case where asymptotically unbiased MCMC algorithms are used. In practice, MCMC-SAEM is often run with asymptotically biased MCMC, for which the consequences are theoretically less understood. In this work, we fill this gap by analyzing the asymptotics and non-asymptotics of SAEM with biased MCMC steps, particularly the effect of bias. We also provide numerical experiments comparing the Metropolis-adjusted Langevin algorithm (MALA), which is asymptotically unbiased, and the unadjusted Langevin algorithm (ULA), which is a
    
[^14]: 稳定LM 2 1.6B技术报告

    Stable LM 2 1.6B Technical Report

    [https://arxiv.org/abs/2402.17834](https://arxiv.org/abs/2402.17834)

    稳定LM 2 1.6B是语言模型系列中的新一代产品，在该报告中详细介绍了其数据、训练过程和性能评估，该模型在发布时是2B参数范围内最先进的开源模型之一，并提供了下载链接和性能对比数据。

    

    我们介绍了稳定LM 2 1.6B，这是我们语言模型系列的新一代产品。在这份技术报告中，我们详细介绍了导致StableLM 2 1.6B基础版本和指导调优版本的数据和训练过程。这两个模型的权重均可通过Hugging Face下载和使用。该报告包含了对这些模型的彻底评估，包括零 shot 和少 shot 基准测试，多语言基准测试，以及重点放在多轮对话的 MT 基准测试上。在发布本报告时，StableLM 2 1.6B是具有显著优势的 2B 参数范围内最先进的开源模型。鉴于其吸引人的小尺寸，我们还提供了在多种边缘设备上的吞吐量测试。此外，我们开源了几个量化检查点，并提供了它们与原始模型的性能指标比较。

    arXiv:2402.17834v1 Announce Type: new  Abstract: We introduce StableLM 2 1.6B, the first in a new generation of our language model series. In this technical report, we present in detail the data and training procedure leading to the base and instruction-tuned versions of StableLM 2 1.6B. The weights for both models are available via Hugging Face for anyone to download and use. The report contains thorough evaluations of these models, including zero- and few-shot benchmarks, multilingual benchmarks, and the MT benchmark focusing on multi-turn dialogues. At the time of publishing this report, StableLM 2 1.6B was the state-of-the-art open model under 2B parameters by a significant margin. Given its appealing small size, we also provide throughput measurements on a number of edge devices. In addition, we open source several quantized checkpoints and provide their performance metrics compared to the original model.
    
[^15]: 大型语言模型的预测排名

    Prediction-Powered Ranking of Large Language Models

    [https://arxiv.org/abs/2402.17826](https://arxiv.org/abs/2402.17826)

    该研究提出了一种统计框架，可以衡量人类与模型偏好之间的不确定性，从而进行大型语言模型的预测排名。

    

    大型语言模型通常根据其与人类偏好的一致性水平进行排名--如果一个模型的输出更受人类偏好，那么它就比其他模型更好。本文提出了一种统计框架来弥合人类与模型偏好之间可能引入的不一致性。

    arXiv:2402.17826v1 Announce Type: cross  Abstract: Large language models are often ranked according to their level of alignment with human preferences -- a model is better than other models if its outputs are more frequently preferred by humans. One of the most popular ways to elicit human preferences utilizes pairwise comparisons between the outputs provided by different models to the same inputs. However, since gathering pairwise comparisons by humans is costly and time-consuming, it has become a very common practice to gather pairwise comparisons by a strong large language model -- a model strongly aligned with human preferences. Surprisingly, practitioners cannot currently measure the uncertainty that any mismatch between human and model preferences may introduce in the constructed rankings. In this work, we develop a statistical framework to bridge this gap. Given a small set of pairwise comparisons by humans and a large set of pairwise comparisons by a model, our framework provid
    
[^16]: 使用VAE-回归与多模态先验设计材料微结构

    Material Microstructure Design Using VAE-Regression with Multimodal Prior

    [https://arxiv.org/abs/2402.17806](https://arxiv.org/abs/2402.17806)

    该论文提出了一种使用VAE-回归与多模态先验设计材料微结构的模型，通过将VAE与回归相结合，并通过双层先验来链接这两个模型，学习了微结构特征，可用于正向和逆向预测。

    

    我们提出了一个基于变分自动编码器（VAE）的模型，用于构建正向和逆向结构-性能链接，在计算材料科学中具有至关重要的问题。我们的模型系统地将VAE与回归相结合，通过一个双层先验来链接这两个模型，该先验受到回归变量的条件约束。回归损失与变分自动编码器的重构损失一起优化，学习与性能预测和重构相关的微结构特征。由此产生的模型可用于正向和逆向预测，即用于预测给定微结构的性能，以及用于预测获取给定性能所需的微结构。由于逆问题是不适定的（一对多），我们使用多模态高斯混合先验推导出目标函数，使模型能够推断出目标性能集合的多个微结构。

    arXiv:2402.17806v1 Announce Type: new  Abstract: We propose a variational autoencoder (VAE)-based model for building forward and inverse structure-property linkages, a problem of paramount importance in computational materials science. Our model systematically combines VAE with regression, linking the two models through a two-level prior conditioned on the regression variables. The regression loss is optimized jointly with the reconstruction loss of the variational autoencoder, learning microstructure features relevant for property prediction and reconstruction. The resultant model can be used for both forward and inverse prediction i.e., for predicting the properties of a given microstructure as well as for predicting the microstructure required to obtain given properties. Since the inverse problem is ill-posed (one-to-many), we derive the objective function using a multi-modal Gaussian mixture prior enabling the model to infer multiple microstructures for a target set of properties. 
    
[^17]: DAGnosis：使用结构进行数据不一致性的局部识别

    DAGnosis: Localized Identification of Data Inconsistencies using Structures

    [https://arxiv.org/abs/2402.17599](https://arxiv.org/abs/2402.17599)

    DAGnosis使用有向无环图(DAGs)来解决数据一致性检测中的两个关键限制，并能够准确定位为何样本会被标记为不一致。

    

    在部署时识别和适当处理数据中的不一致性对可靠地使用机器学习模型至关重要。近期的数据中心方法能够识别与训练集相关的这种不一致性，但存在两个关键限制：（1）在特征展现统计独立性的情况下表现不佳，因为它们使用压缩表示；（2）缺乏局部化，无法准确定位样本为何被标记为不一致，这对指导未来数据收集至关重要。我们使用有向无环图（DAGs）来编码训练集的特征概率分布和独立性作为结构，从而解决了这两个基本限制。我们的方法被称为DAGnosis，利用这些结构交互带来有价值的、深刻的数据中心结论。DAGnosis解锁了在DAG上定位不一致性原因的能力，

    arXiv:2402.17599v1 Announce Type: cross  Abstract: Identification and appropriate handling of inconsistencies in data at deployment time is crucial to reliably use machine learning models. While recent data-centric methods are able to identify such inconsistencies with respect to the training set, they suffer from two key limitations: (1) suboptimality in settings where features exhibit statistical independencies, due to their usage of compressive representations and (2) lack of localization to pin-point why a sample might be flagged as inconsistent, which is important to guide future data collection. We solve these two fundamental limitations using directed acyclic graphs (DAGs) to encode the training set's features probability distribution and independencies as a structure. Our method, called DAGnosis, leverages these structural interactions to bring valuable and insightful data-centric conclusions. DAGnosis unlocks the localization of the causes of inconsistencies on a DAG, an aspec
    
[^18]: 连续时间扩散模型的微调作为熵正则化控制

    Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control

    [https://arxiv.org/abs/2402.15194](https://arxiv.org/abs/2402.15194)

    扩散模型的微调方法可以通过最大化奖励函数的价值来以目标导向方式进行微调，但可能会面临奖励崩溃的挑战。

    

    扩散模型在捕捉复杂数据分布方面表现出色，例如自然图像和蛋白质的分布。虽然扩散模型经过训练可代表训练数据集中的分布，但我们通常更关注其他属性，例如生成图像的美学质量或生成蛋白质的功能属性。扩散模型可以通过最大化某些奖励函数的价值（例如图像的美学质量）以目标导向的方式进行微调。然而，这些方法可能会导致样本多样性减少，与训练数据分布出现显著偏差，甚至由于利用不完美的奖励函数而导致样本质量较差。在许多实际应用中奖励函数是用于近似真实“真实”奖励的学习模型时，最后一个问题经常会产生。这些挑战总称为“奖励崩溃”。

    arXiv:2402.15194v1 Announce Type: cross  Abstract: Diffusion models excel at capturing complex data distributions, such as those of natural images and proteins. While diffusion models are trained to represent the distribution in the training dataset, we often are more concerned with other properties, such as the aesthetic quality of the generated images or the functional properties of generated proteins. Diffusion models can be finetuned in a goal-directed way by maximizing the value of some reward function (e.g., the aesthetic quality of an image). However, these approaches may lead to reduced sample diversity, significant deviations from the training data distribution, and even poor sample quality due to the exploitation of an imperfect reward function. The last issue often occurs when the reward function is a learned model meant to approximate a ground-truth "genuine" reward, as is the case in many practical applications. These challenges, collectively termed "reward collapse," pose
    
[^19]: HyperAgent：一种简单、可扩展、高效且可证明用于复杂环境的强化学习框架

    HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments

    [https://arxiv.org/abs/2402.10228](https://arxiv.org/abs/2402.10228)

    HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    

    为了在资源约束下解决复杂任务，强化学习（RL）代理需要简单、高效、可扩展、具有大状态空间和不断积累的交互数据。我们提出了HyperAgent，这是一个具有超模型、索引抽样方案和增量更新机制的RL框架，可以在一般价值函数逼近中进行计算高效的顺序后验逼近和数据高效的动作选择，超越了共轭性。HyperAgent的实现简单，只需要在DDQN中添加一个模块和一行额外代码。在实践中，HyperAgent在大规模深度RL基准测试中表现出稳健的性能，无论是在数据还是计算方面都获得了显着的效率提升。在理论上，在实际可扩展的算法中，HyperAgent是第一个能够实现可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
    
[^20]: Stein Boltzmann抽样：一种全局优化的变分方法

    Stein Boltzmann Sampling: A Variational Approach for Global Optimization

    [https://arxiv.org/abs/2402.04689](https://arxiv.org/abs/2402.04689)

    Stein Boltzmann抽样（SBS）是一种全局优化的变分方法，通过从Boltzmann分布中采样，由Stein Variational Gradient Descent算法实现，具有渐近收敛性，并在各种基准函数上比较了几种最先进的全局优化算法，尤其适合作为高效全局优化方法的延续，能够产生更好的解决方案并有效利用预算。

    

    在本文中，我们介绍了一种新的基于流的方法，用于Lipschitz函数的全局优化，称为Stein Boltzmann抽样（SBS）。我们的方法从Boltzmann分布中采样，该分布在优化函数的最小值集合上渐近均匀。候选解通过Stein Variational Gradient Descent算法进行采样。我们证明了我们方法的渐近收敛性，引入了两种SBS变体，并在各种基准函数上与几种最先进的全局优化算法进行了详细比较。我们方法的设计、理论结果和实验表明，SBS特别适合作为高效全局优化方法的延续，因为它可以在很好地利用预算的同时产生更好的解决方案。

    In this paper, we introduce a new flow-based method for global optimization of Lipschitz functions, called Stein Boltzmann Sampling (SBS). Our method samples from the Boltzmann distribution that becomes asymptotically uniform over the set of the minimizers of the function to be optimized. Candidate solutions are sampled via the \emph{Stein Variational Gradient Descent} algorithm. We prove the asymptotic convergence of our method, introduce two SBS variants, and provide a detailed comparison with several state-of-the-art global optimization algorithms on various benchmark functions. The design of our method, the theoretical results, and our experiments, suggest that SBS is particularly well-suited to be used as a continuation of efficient global optimization methods as it can produce better solutions while making a good use of the budget.
    
[^21]: 可扩展和快速模拟推断的一致性模型

    Consistency Models for Scalable and Fast Simulation-Based Inference

    [https://arxiv.org/abs/2312.05440](https://arxiv.org/abs/2312.05440)

    提出了一种新的神经后验估计的一致性模型，结合了标准化流和流匹配方法的优点，用于可扩展、快速和摊销推断，在多个实验中展示出优越性能。

    

    仿真推断（SBI）不断寻找更具表现力的算法，以准确推断复杂模型的参数从嘈杂数据中。我们提出了神经后验估计的一致性模型（CMPE），这是一个用于可扩展、快速和摊销推断的新自由形式条件采样器，利用生成性神经网络。CMPE将标准化流和流匹配方法的优点结合到单个生成架构中：它本质上提炼了连续概率流，并能够利用无约束的结构快速进行少射推断，该结构可以定制到估计问题的结构。我们的实证评估表明，CMPE不仅在三个困难的低维问题上优于当前的最先进算法，而且在高维贝叶斯去噪实验和估计计算密集型多尺度中表现出有竞争力的性能。

    arXiv:2312.05440v2 Announce Type: replace-cross  Abstract: Simulation-based inference (SBI) is constantly in search of more expressive algorithms for accurately inferring the parameters of complex models from noisy data. We present consistency models for neural posterior estimation (CMPE), a new free-form conditional sampler for scalable, fast, and amortized SBI with generative neural networks. CMPE combines the advantages of normalizing flows and flow matching methods into a single generative architecture: It essentially distills a continuous probability flow and enables rapid few-shot inference with an unconstrained architecture that can be tailored to the structure of the estimation problem. Our empirical evaluation demonstrates that CMPE not only outperforms current state-of-the-art algorithms on three hard low-dimensional problems but also achieves competitive performance in a high-dimensional Bayesian denoising experiment and in estimating a computationally demanding multi-scale 
    
[^22]: 在医疗AI模型中检测算法偏倚

    Detecting algorithmic bias in medical AI-models

    [https://arxiv.org/abs/2312.02959](https://arxiv.org/abs/2312.02959)

    本文提出了一种创新的框架，用于检测医疗AI决策支持系统中的算法偏倚，通过采用CART算法有效地识别医疗AI模型中的潜在偏倚，并在合成数据实验和真实临床环境中验证了其有效性。

    

    随着机器学习和人工智能医疗决策支持系统日益普及，确保这些系统以公平、公正的方式提供患者结果变得同样重要。本文提出了一种创新的框架，用于检测医疗AI决策支持系统中的算法偏倚区域。我们的方法通过采用分类与回归树（CART）算法，在脓毒症预测背景下有效地识别医疗AI模型中的潜在偏倚。我们通过进行一系列合成数据实验验证了我们的方法，展示了其在受控环境中准确估计偏倚区域的能力。这一概念的有效性通过使用亚特兰大乔治亚州格雷迪纪念医院的电子病历进行实验进一步得到验证。这些测试展示了我们策略在临床中的实际应用。

    arXiv:2312.02959v3 Announce Type: replace-cross  Abstract: With the growing prevalence of machine learning and artificial intelligence-based medical decision support systems, it is equally important to ensure that these systems provide patient outcomes in a fair and equitable fashion. This paper presents an innovative framework for detecting areas of algorithmic bias in medical-AI decision support systems. Our approach efficiently identifies potential biases in medical-AI models, specifically in the context of sepsis prediction, by employing the Classification and Regression Trees (CART) algorithm. We verify our methodology by conducting a series of synthetic data experiments, showcasing its ability to estimate areas of bias in controlled settings precisely. The effectiveness of the concept is further validated by experiments using electronic medical records from Grady Memorial Hospital in Atlanta, Georgia. These tests demonstrate the practical implementation of our strategy in a clini
    
[^23]: 在具有高斯置信传播的深度因子图中进行学习

    Learning in Deep Factor Graphs with Gaussian Belief Propagation

    [https://arxiv.org/abs/2311.14649](https://arxiv.org/abs/2311.14649)

    提出了一种在高斯因子图中进行学习的方法，利用置信传播解决训练和预测问题，支持分布式和异步训练，可扩展至深度网络，提供持续学习的自然方式，并展示了在视频去噪和图像分类任务中的优势。

    

    我们提出了一种在高斯因子图中进行学习的方法。我们将所有相关数量（输入、输出、参数、潜变量）视为图模型中的随机变量，并将训练和预测都视为具有不同观察节点的推理问题。我们的实验表明，这些问题可以通过置信传播（BP）有效地解决，其更新本质上是本地的，为分布式和异步训练提供了令人兴奋的机会。我们的方法可以扩展到深层网络，并提供了一种自然的持续学习方式：使用当前任务的BP估计参数边际作为下一个任务的参数先验。在视频去噪任务上，我们展示了可学习参数相对于传统因子图方法的优势，同时展示了深度因子图在持续图像分类方面的鼓舞人心的性能。

    arXiv:2311.14649v2 Announce Type: replace  Abstract: We propose an approach to do learning in Gaussian factor graphs. We treat all relevant quantities (inputs, outputs, parameters, latents) as random variables in a graphical model, and view both training and prediction as inference problems with different observed nodes. Our experiments show that these problems can be efficiently solved with belief propagation (BP), whose updates are inherently local, presenting exciting opportunities for distributed and asynchronous training. Our approach can be scaled to deep networks and provides a natural means to do continual learning: use the BP-estimated parameter marginals of the current task as parameter priors for the next. On a video denoising task we demonstrate the benefit of learnable parameters over a classical factor graph approach and we show encouraging performance of deep factor graphs for continual image classification.
    
[^24]: 通过贝叶斯张量列车分解进行流数据恢复

    Streaming data recovery via Bayesian tensor train decomposition

    [https://arxiv.org/abs/2302.12148](https://arxiv.org/abs/2302.12148)

    通过贝叶斯张量列车分解方法，在高阶、不完整和嘈杂的流数据中，实现了流数据的恢复和准确性

    

    在本文中，我们研究了一种贝叶斯张量列车(TT)分解方法，通过近似高阶流数据中的潜在结构来恢复流数据。借鉴流变分贝叶斯方法，我们将TT格式引入贝叶斯张量分解方法以用于流数据，并构建TT核的后验概率。由于TT格式的贝叶斯框架，所提出的算法(SPTT)在恢复具有高阶、不完整和嘈杂特性的流数据方面表现出色。合成和真实世界数据集中的实验证明了我们的方法相对于流数据的最新贝叶斯张量分解方法的准确性。

    arXiv:2302.12148v2 Announce Type: replace  Abstract: In this paper, we study a Bayesian tensor train (TT) decomposition method to recover streaming data by approximating the latent structure in high-order streaming data. Drawing on the streaming variational Bayes method, we introduce the TT format into Bayesian tensor decomposition methods for streaming data, and formulate posteriors of TT cores. Thanks to the Bayesian framework of the TT format, the proposed algorithm (SPTT) excels in recovering streaming data with high-order, incomplete, and noisy properties. The experiments in synthetic and real-world datasets show the accuracy of our method compared to state-of-the-art Bayesian tensor decomposition methods for streaming data.
    
[^25]: 数据增强的好坏与丑陋面：隐式谱正则化的视角

    The good, the bad and the ugly sides of data augmentation: An implicit spectral regularization perspective

    [https://arxiv.org/abs/2210.05021](https://arxiv.org/abs/2210.05021)

    数据增强在机器学习中扮演着重要作用，而该研究提出了一个新的理论框架，揭示了数据增强通过隐式谱正则化对线性模型泛化的影响。

    

    数据增强（DA）是在现代机器学习中增强性能的强大工具。传统上认为，在计算机视觉中的特定增强，比如平移和缩放，可以通过从相同分布生成新的（人工）数据来改善泛化能力。然而，这种传统观点不能解释现代机器学习中流行增强的成功（例如随机遮挡、cutout、mixup），这些增强大大改变了训练数据分布。在这项工作中，我们开发了一个新的理论框架，以表征一般类别的数据增强对欠参数化和过参数化线性模型泛化的影响。我们的框架揭示了数据增强通过两种不同效应的组合：a)以训练数据为基础操纵数据协方差矩阵的特征值的相对比例，b)统一增强

    arXiv:2210.05021v3 Announce Type: replace  Abstract: Data augmentation (DA) is a powerful workhorse for bolstering performance in modern machine learning. Specific augmentations like translations and scaling in computer vision are traditionally believed to improve generalization by generating new (artificial) data from the same distribution. However, this traditional viewpoint does not explain the success of prevalent augmentations in modern machine learning (e.g. randomized masking, cutout, mixup), that greatly alter the training data distribution. In this work, we develop a new theoretical framework to characterize the impact of a general class of DA on underparameterized and overparameterized linear model generalization. Our framework reveals that DA induces implicit spectral regularization through a combination of two distinct effects: a) manipulating the relative proportion of eigenvalues of the data covariance matrix in a training-data-dependent manner, and b) uniformly boosting 
    
[^26]: 具有缺失数据的异方差PCA的推断

    Inference for Heteroskedastic PCA with Missing Data

    [https://arxiv.org/abs/2107.12365](https://arxiv.org/abs/2107.12365)

    该研究提出了一种针对高维度下主成分分析（PCA）的置信区间构建方法，特别解决了缺失数据和异方差噪声的挑战。

    

    本文研究了如何在高维度中构建主成分分析（PCA）的置信区间，这是一个广泛未被探索的问题。在高维度中计算非线性/非凸估计量的不确定性度量通常是困难的，而这一挑战更加复杂，因为缺失数据和异方差噪声普遍存在。我们提出了一种新颖的方法，用于在带有缺失数据的尖峰协方差模型下对主子空间进行有效推断，基于一种名为HeteroPCA的估计量（Zhang等人，2022年）。我们为HeteroPCA开发了非渐近分布保证，并展示了如何利用这些保证来计算主子空间的置信区间以及尖峰协方差矩阵的条目置信区间。我们的推断程序完全是数据驱动的，并且能够适应异方差随机噪声，而无需先验要求。

    arXiv:2107.12365v2 Announce Type: replace-cross  Abstract: This paper studies how to construct confidence regions for principal component analysis (PCA) in high dimension, a problem that has been vastly under-explored. While computing measures of uncertainty for nonlinear/nonconvex estimators is in general difficult in high dimension, the challenge is further compounded by the prevalent presence of missing data and heteroskedastic noise. We propose a novel approach to performing valid inference on the principal subspace under a spiked covariance model with missing data, on the basis of an estimator called HeteroPCA (Zhang et al., 2022). We develop non-asymptotic distributional guarantees for HeteroPCA, and demonstrate how these can be invoked to compute both confidence regions for the principal subspace and entrywise confidence intervals for the spiked covariance matrix. Our inference procedures are fully data-driven and adaptive to heteroskedastic random noise, without requiring prior
    
[^27]: 用于克服灾难性过拟合的高效本地线性正则化

    Efficient local linearity regularization to overcome catastrophic overfitting. (arXiv:2401.11618v1 [cs.LG])

    [http://arxiv.org/abs/2401.11618](http://arxiv.org/abs/2401.11618)

    本研究引入了一种名为ELLE的正则化项，用于高效地减轻单步对抗性训练中的灾难性过拟合。它能够保持损失函数在输入上的局部线性性，与传统的正则化方法相比，ELLE更加高效，能够有效应对大对抗性扰动和长训练计划等困难情况。

    

    单步对抗性训练中的灾难性过拟合 (CO) 导致对抗性测试准确率突然下降（甚至降至0%）。对于使用多步对抗性训练训练的模型，已观察到损失函数在输入上具有局部线性性，但这种特性在单步对抗性训练中丢失。为了解决单步对抗性训练中的CO问题，提出了几种通过正则化来强制损失函数局部线性性的方法。然而，由于双重反向传播，这些正则化项会显著减慢训练速度。与之相反，在本研究中，我们引入一种称为ELLE的正则化项，以在经典对抗性训练评估中有效且高效地减轻CO问题，在一些更困难的情况下也能起作用，例如大对抗性扰动和长训练计划。我们的正则化项在理论上与损失函数的曲率有联系，并且通过避免双重反向传播而具有比先前方法更低的计算成本。通过彻底的实验研究...

    Catastrophic overfitting (CO) in single-step adversarial training (AT) results in abrupt drops in the adversarial test accuracy (even down to 0%). For models trained with multi-step AT, it has been observed that the loss function behaves locally linearly with respect to the input, this is however lost in single-step AT. To address CO in single-step AT, several methods have been proposed to enforce local linearity of the loss via regularization. However, these regularization terms considerably slow down training due to Double Backpropagation. Instead, in this work, we introduce a regularization term, called ELLE, to mitigate CO effectively and efficiently in classical AT evaluations, as well as some more difficult regimes, e.g., large adversarial perturbations and long training schedules. Our regularization term can be theoretically linked to curvature of the loss function and is computationally cheaper than previous methods by avoiding Double Backpropagation. Our thorough experimental 
    
[^28]: 具有叠加混合先验的贝叶斯预后协变量调整方法

    Bayesian Prognostic Covariate Adjustment With Additive Mixture Priors. (arXiv:2310.18027v1 [stat.ME])

    [http://arxiv.org/abs/2310.18027](http://arxiv.org/abs/2310.18027)

    提出了一种新的贝叶斯预后协变量调整方法，结合了协变量调整和历史对照信息利用的策略，在随机对照试验中用于有效和快速决策。通过生成型人工智能算法构建数字孪生生成器，利用历史对照数据产生数字孪生概率分布，从而进行单一协变量调整。

    

    从随机对照试验（RCTs）中进行有效和快速的决策需要无偏和准确的治疗效果推断。为了满足这一要求，有两种策略：调整与结果高度相关的协变量，以及通过贝叶斯定理利用历史对照信息。我们提出了一种新的贝叶斯预后协变量调整方法，称为贝叶斯PROCOVA，将这两种策略结合起来。协变量调整基于生成型人工智能（AI）算法，构建了随机对照试验参与者的数字孪生生成器（DTG）。DTG通过历史对照数据进行训练，为每个参与者的对照结果产生了一个数字孪生（DT）概率分布。DT分布的期望定义了用于调整的单一协变量。历史对照信息通过具有两个组成部分的叠加混合先验进行利用：基于先验信息确定的一个信息先验概率分布。

    Effective and rapid decision-making from randomized controlled trials (RCTs) requires unbiased and precise treatment effect inferences. Two strategies to address this requirement are to adjust for covariates that are highly correlated with the outcome, and to leverage historical control information via Bayes' theorem. We propose a new Bayesian prognostic covariate adjustment methodology, referred to as Bayesian PROCOVA, that combines these two strategies. Covariate adjustment is based on generative artificial intelligence (AI) algorithms that construct a digital twin generator (DTG) for RCT participants. The DTG is trained on historical control data and yields a digital twin (DT) probability distribution for each participant's control outcome. The expectation of the DT distribution defines the single covariate for adjustment. Historical control information are leveraged via an additive mixture prior with two components: an informative prior probability distribution specified based on h
    
[^29]: 将循环引入人类：协作和可解释的贝叶斯优化

    Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])

    [http://arxiv.org/abs/2310.17273](http://arxiv.org/abs/2310.17273)

    协作和可解释的贝叶斯优化框架(CoExBO)在贝叶斯优化中引入了循环，平衡了人工智能和人类的合作关系。它利用偏好学习将用户见解融合到优化中，解释每次迭代的候选选择，从而增强用户对优化过程的信任，并提供无害保证。

    

    像许多优化器一样，贝叶斯优化在获得用户信任方面常常存在不足，因为其不透明性。虽然已经尝试开发面向人类的优化器，但它们通常假设用户知识是明确且无误的，并主要将用户作为优化过程的监督者。我们放宽了这些假设，提出了一种更平衡的人工智能和人类合作伙伴关系，即我们的协作和可解释的贝叶斯优化（CoExBO）框架。CoExBO使用偏好学习来无缝地将人类见解整合到优化中，从而产生与用户使用偏好一致的算法建议。CoExBO解释其每次迭代的候选选择，以培养信任，使用户更清楚地掌握优化的过程。此外，CoExBO提供无害保证，允许用户犯错误；即使在极端对抗性干扰下，算法也会渐进地收敛。

    Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to
    
[^30]: 关于随机梯度下降的不同模式

    On the different regimes of Stochastic Gradient Descent. (arXiv:2309.10688v1 [cs.LG])

    [http://arxiv.org/abs/2309.10688](http://arxiv.org/abs/2309.10688)

    这项研究解决了对于随机梯度下降（SGD）中不同模式的追踪和理解的问题，提供了一个相位图来区分噪声主导的SGD和大步骤主导的SGD。

    

    现代深度网络通过随机梯度下降（SGD）进行训练，其关键参数是每个步骤考虑的数据量或批量大小B以及步长或学习率η。对于小的B和大的η，SGD对应于参数的随机演化，其噪声幅度由“温度”T=η/B控制。然而当批量大小B≥B^*足够大时，这种描述被观察到失效，或者在温度足够小时简化为梯度下降（GD）。理解这些交叉发生的位置仍然是一个中心挑战。在这里，我们解决了这些问题，在一个教师-学生感知器分类模型中，我们展示了我们的关键预测仍适用于深度网络。具体来说，我们在B-η平面上获得了一个相位图，将三个动态阶段分开：（i）受温度控制的噪声主导的SGD，（ii）大步骤主导的SGD和

    Modern deep networks are trained with stochastic gradient descent (SGD) whose key parameters are the number of data considered at each step or batch size $B$, and the step size or learning rate $\eta$. For small $B$ and large $\eta$, SGD corresponds to a stochastic evolution of the parameters, whose noise amplitude is governed by the `temperature' $T\equiv \eta/B$. Yet this description is observed to break down for sufficiently large batches $B\geq B^*$, or simplifies to gradient descent (GD) when the temperature is sufficiently small. Understanding where these cross-overs take place remains a central challenge. Here we resolve these questions for a teacher-student perceptron classification model, and show empirically that our key predictions still apply to deep networks. Specifically, we obtain a phase diagram in the $B$-$\eta$ plane that separates three dynamical phases: $\textit{(i)}$ a noise-dominated SGD governed by temperature, $\textit{(ii)}$ a large-first-step-dominated SGD and
    
[^31]: 异常鲁棒张量低秩表示用于数据聚类

    Outlier-Robust Tensor Low-Rank Representation for Data Clustering. (arXiv:2307.09055v1 [stat.ML])

    [http://arxiv.org/abs/2307.09055](http://arxiv.org/abs/2307.09055)

    本文提出了一种异常鲁棒张量低秩表示方法，用于同时检测异常值和进行数据聚类。该方法基于张量奇异值分解（t-SVD）代数框架，并在较弱条件下具有恢复干净数据的行空间和检测异常值的可证明性能保证。此外，还提出了扩展方法以处理数据部分缺失的情况。

    

    低秩张量分析在许多实际应用中受到广泛关注。然而，张量数据经常受到异常值或样本特定的污染。如何恢复被异常值损坏的张量数据并进行数据聚类仍然是一个具有挑战性的问题。本文基于张量奇异值分解（t-SVD）代数框架，提出了一种用于同时检测异常值和张量数据聚类的异常鲁棒张量低秩表示（OR-TLRR）方法。该方法受到最近提出的满足一定条件的可逆线性变换引起的张量张量积的启发。对于带有任意异常值污染的张量观测，OR-TLRR在较弱条件下能够确切恢复干净数据的行空间并检测异常值。此外，还提出了OR-TLRR的扩展来处理数据部分缺失的情况。

    Low-rank tensor analysis has received widespread attention with many practical applications. However, the tensor data are often contaminated by outliers or sample-specific corruptions. How to recover the tensor data that are corrupted by outliers and perform data clustering remains a challenging problem. This paper develops an outlier-robust tensor low-rank representation (OR-TLRR) method for simultaneous outlier detection and tensor data clustering based on the tensor singular value decomposition (t-SVD) algebraic framework. It is motivated by the recently proposed tensor-tensor product induced by invertible linear transforms that satisfy certain conditions. For tensor observations with arbitrary outlier corruptions, OR-TLRR has provable performance guarantee for exactly recovering the row space of clean data and detecting outliers under mild conditions. Moreover, an extension of OR-TLRR is also proposed to handle the case when parts of the data are missing. Finally, extensive experim
    
[^32]: 非凸梯度下降法快速极小化低秩矩阵估计

    Fast and Minimax Optimal Estimation of Low-Rank Matrices via Non-Convex Gradient Descent. (arXiv:2305.17224v1 [math.OC])

    [http://arxiv.org/abs/2305.17224](http://arxiv.org/abs/2305.17224)

    本文提出一种针对低秩矩阵估计的方法，在保证极小极值优化性能的同时，解决了非凸梯度下降收敛缓慢的问题。

    

    本文研究了从噪声测量中估计低秩矩阵的问题，特别是旨在实现极小极值误差。在实践中，由于非凸梯度下降的能力可以扩展到大规模真实世界数据集，这个问题通常使用非凸梯度下降来解决。理论上，非凸梯度下降能够实现极小极值误差。但在实践中，它经常收敛得非常缓慢，以至于甚至无法在合理的时间内提供适度准确的估计值。另一方面，通过重新缩放或预处理改进非凸梯度下降的收敛方法也会大大放大测量误差，导致得到的估计比理论上可实现的极小极值误差少几个数量级的准确性。在本文中，我们提出了一种对通常的非凸梯度下降方法进行轻微修改的方法，解决了收敛缓慢的问题，同时可证明保留其极小极值优化性能。

    We study the problem of estimating a low-rank matrix from noisy measurements, with the specific goal of achieving minimax optimal error. In practice, the problem is commonly solved using non-convex gradient descent, due to its ability to scale to large-scale real-world datasets. In theory, non-convex gradient descent is capable of achieving minimax error. But in practice, it often converges extremely slowly, such that it cannot even deliver estimations of modest accuracy within reasonable time. On the other hand, methods that improve the convergence of non-convex gradient descent, through rescaling or preconditioning, also greatly amplify the measurement noise, resulting in estimations that are orders of magnitude less accurate than what is theoretically achievable with minimax optimal error. In this paper, we propose a slight modification to the usual non-convex gradient descent method that remedies the issue of slow convergence, while provably preserving its minimax optimality. Our p
    
[^33]: 稀疏图的半监督聚类：跨越了信息理论门槛

    Semi-Supervised Clustering of Sparse Graphs: Crossing the Information-Theoretic Threshold. (arXiv:2205.11677v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.11677](http://arxiv.org/abs/2205.11677)

    该论文提出了两种有效的算法来将标签信息与稀疏图结构相结合，解决了基于网络拓扑的聚类在稀疏图上的问题。

    

    随机块模型是一种用于网络结构数据聚类和社区检测的基本随机图模型。数十年来对该问题的广泛研究已经建立了许多深刻的结果，其中Kesten-Stigum门槛处的相变现象特别有趣，从数学和应用角度都具有重要意义。它表明，如果模型参数在某个门槛以下，基于网络拓扑的任何估计器在稀疏图上都不能比随机猜测更好。然而，如果我们稍微扩展视野到普遍存在的半监督设置，这样的基本限制将完全消失。我们证明，通过揭示出任意一部分标记，可以在整个参数域内对检测问题进行处理。此外，我们引入了两种有效的算法，一种是基于组合的，一种是基于优化的，用于将标签信息与图结构相结合。我们的工作为随机块模型和半监督学习带来了全新的视角，标志着稀疏图聚类领域的重大突破。

    The stochastic block model is a canonical random graph model for clustering and community detection on network-structured data. Decades of extensive study on the problem have established many profound results, among which the phase transition at the Kesten-Stigum threshold is particularly interesting both from a mathematical and an applied standpoint. It states that no estimator based on the network topology can perform substantially better than chance on sparse graphs if the model parameter is below certain threshold. Nevertheless, if we slightly extend the horizon to the ubiquitous semi-supervised setting, such a fundamental limitation will disappear completely. We prove that with arbitrary fraction of the labels revealed, the detection problem is feasible throughout the parameter domain. Moreover, we introduce two efficient algorithms, one combinatorial and one based on optimization, to integrate label information with graph structures. Our work brings a new perspective to stochasti
    

