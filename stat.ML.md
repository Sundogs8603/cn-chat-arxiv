# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Flow Annealed Kalman Inversion for Gradient-Free Inference in Bayesian Inverse Problems.](http://arxiv.org/abs/2309.11490) | 本论文提出了流退火卡尔曼反演（FAKI）算法，在贝叶斯反问题中应用，该算法利用流动退火和正规化流技术，能够以更高的准确度近似非高斯目标，相比于标准集合卡尔曼反演（EKI）有显著的改进。 |
| [^2] | [Distribution and volume based scoring for Isolation Forests.](http://arxiv.org/abs/2309.11450) | 本文在Isolation Forest方法中提出了两个贡献，分别是对评分函数的信息理论推广和在个体树估计器层面上使用基于超体积的评分函数。这两种方法均对一些数据集相对于标准Isolation Forest表现出显著改进，并且其中一种方法在所有数据集上平均表现出改进。 |
| [^3] | [Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models.](http://arxiv.org/abs/2309.11420) | 深度神经网络可以作为降噪算法在高维图形模型中学习扩散模型，为生成建模提供了高效的逼近方法。 |
| [^4] | [Using Property Elicitation to Understand the Impacts of Fairness Constraints.](http://arxiv.org/abs/2309.11343) | 这项研究使用属性引导方法来探索损失函数和正则化函数与最优决策之间的关系，特别是在公平机器学习中的应用。它提供了损失函数和正则化函数成对时属性改变的必要和充分条件，并通过实验证明了算法决策与数据分布变化和约束难度的相关性。 |
| [^5] | [Optimize-via-Predict: Realizing out-of-sample optimality in data-driven optimization.](http://arxiv.org/abs/2309.11147) | 这项研究提出了一种基于预测的数据驱动优化方法，通过局部平均和采样分布来实现样本外最优解，并且提供了充分条件和高效算法。在新供应商模型中的实验证明了该方法的有效性。 |
| [^6] | [Ano-SuPs: Multi-size anomaly detection for manufactured products by identifying suspected patches.](http://arxiv.org/abs/2309.11120) | Ano-SuPs是一种通过识别可疑区块来进行制造产品的多尺度异常检测的两阶段策略方法。它可以解决图像背景复杂性和异常模式的挑战，并具有较高的准确性和鲁棒性。 |
| [^7] | [Extreme Scenario Selection in Day-Ahead Power Grid Operational Planning.](http://arxiv.org/abs/2309.11067) | 本文提出并分析了一种在天然电网规划中选择极端情景的方法，通过统计功能深度度量来筛选出最重要的情景以减轻运营风险。研究结果表明该方法在真实的Texas-7k电网上具有良好的效果。 |
| [^8] | [Fake News BR: A Fake News Detection Platform for Brazilian Portuguese.](http://arxiv.org/abs/2309.11052) | 本研究提出了一个用于巴西葡萄牙语的假新闻检测平台，采用机器学习和自然语言处理技术，能够高效准确地识别假新闻，同时提供实时分析和验证新闻文章真实性的用户友好平台。 |
| [^9] | [PAGER: A Framework for Failure Analysis of Deep Regression Models.](http://arxiv.org/abs/2309.10977) | PAGER提出了一种用于深度回归模型故障分析的框架，通过综合利用认识不确定性和不一致分数，对样本进行分组并提供全面的分析。 |
| [^10] | [SPFQ: A Stochastic Algorithm and Its Error Analysis for Neural Network Quantization.](http://arxiv.org/abs/2309.10975) | SPFQ是一种用于神经网络量化的快速随机算法，通过贪婪的路径跟踪和随机量化器有效地减少网络中的冗余并提高量化效率。在本文中，我们首次建立了全网络的误差界，并通过应用于具有高斯权重的多层网络的量化证明了结果的有效性。 |
| [^11] | [DPpack: An R Package for Differentially Private Statistical Analysis and Machine Learning.](http://arxiv.org/abs/2309.10965) | DPpack是一个开源的R包，提供了差分隐私统计分析和机器学习的工具集合，包括不同的保护机制和描述性统计函数。它还提供了隐私保护版本的逻辑回归、支持向量机和线性回归的实现，以及对每个模型的差分隐私超参数调整。 |
| [^12] | [Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds.](http://arxiv.org/abs/2309.10918) | 该论文研究了定义在紧致Riemannian流形上的内在Matern高斯过程和外在过程之间的收缩速率，并发现它们的速率在适当匹配平滑参数的情况下是相等的。 |
| [^13] | [Context $\approx$ Environment.](http://arxiv.org/abs/2309.09888) | 在这篇论文中，作者通过理论与实验证明了将注意力放在上下文-未标记样本上，可以实现更好的领域泛化。 |
| [^14] | [Inverse classification with logistic and softmax classifiers: efficient optimization.](http://arxiv.org/abs/2309.08945) | 本文研究了逻辑回归和softmax分类器中的逆向分类问题，并提出了高效的解决方法，可以在交互式或实时应用中获得准确解。 |
| [^15] | [Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization.](http://arxiv.org/abs/2309.04810) | 本论文提出了神经潜在几何搜索(NLGS)的概念，旨在通过格罗莫夫-豪斯多夫距离来自动识别下游任务的最佳潜在几何结构，以提高机器学习模型的性能。 |
| [^16] | [Dyadic Reinforcement Learning.](http://arxiv.org/abs/2308.07843) | 该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。 |
| [^17] | [Multiclass Online Learnability under Bandit Feedback.](http://arxiv.org/abs/2308.04620) | Bandit反馈下的在线多类学习的关键在于Bandit Littlestone维度的有限性，无论标签空间是否无界。 |
| [^18] | [In-Context Operator Learning for Differential Equation Problems.](http://arxiv.org/abs/2304.07993) | 本文提出了一种新的神经网络方法INDEED，它可以同时学习不同微分方程问题的操作符，而无需重新训练，且只需要极少的演示。 |
| [^19] | [Analyzing And Improving Neural Speaker Embeddings for ASR.](http://arxiv.org/abs/2301.04571) | 该论文研究了将神经说话人嵌入应用于ASR系统中，并提出了改进的嵌入提取流程和集成方法，通过改进的声学模型和添加神经说话人嵌入，获得了显著的WER性能提升。 |
| [^20] | [Statistical and Computational Guarantees for Influence Diagnostics.](http://arxiv.org/abs/2212.04014) | 本论文提出了统计和计算边界来保证影响诊断的有效性，通过使用高效的逆-Hessian-向量乘积实现的方法，我们可以在机器学习和人工智能领域的应用中准确识别有影响力的数据点或子集。 |
| [^21] | [Toward Unlimited Self-Learning MCMC with Parallel Adaptive Annealing.](http://arxiv.org/abs/2211.14024) | 提出了一种并行自适应退火的方法，将自学习Monte Carlo（SLMC）方法应用于多峰分布，实现了高效的Monte Carlo更新，并解决了建议模型的模式崩溃问题。 |
| [^22] | [Neural Superstatistics for Bayesian Estimation of Dynamic Cognitive Model.](http://arxiv.org/abs/2211.13165) | 本研究提出了一种神经超统计学方法，用于贝叶斯估计动态认知模型。通过引入时间维度和超统计视角，可以有效地估计系统中的动态性质，并利用仿真和深度学习方法进行贝叶斯推理。该方法能够恢复时变和时不变参数，并在实验证明其有效性。 |
| [^23] | [Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees.](http://arxiv.org/abs/2210.07893) | 本文针对高斯过程模型的数值稳定性进行了研究，通过感兴趣点的选择和计算，提供了稳定可靠的稀疏逼近方法。 |
| [^24] | [Conformal Prediction is Robust to Dispersive Label Noise.](http://arxiv.org/abs/2209.14295) | 本研究研究了Conformal Prediction方法对于标签噪声具有鲁棒性。我们找出了构建可以正确覆盖无噪声真实标签的不确定性集合的条件，并提出了对具有噪声标签的一般损失函数进行正确控制的要求。实验证明，在对抗性案例之外，使用Conformal Prediction和风险控制技术可以实现对干净真实标签的保守风险。我们还提出了一种有界尺寸噪声修正的方法，以确保实现正确的真实标签风险。 |
| [^25] | [Adaptive deep learning for nonlinear time series models.](http://arxiv.org/abs/2207.02546) | 本文提出了一种自适应深度学习方法用于非线性时间序列模型的均值函数估计，证明了稀疏惩罚的深度神经网络估计器在许多非线性自回归模型中达到了极小下界的最优速率。 |
| [^26] | [Optimal subgroup selection.](http://arxiv.org/abs/2109.01077) | 在回归设置中，我们提出了一个子群选择挑战，以确定回归函数超过预设阈值的特征空间区域。我们的主要贡献是确定了在样本规模和类型I错误概率上遗憾的最佳速率。 |
| [^27] | [A Pragmatic Look at Deep Imitation Learning.](http://arxiv.org/abs/2108.01867) | 本文在深度模仿学习领域以实际的视角进行了研究，重新实现了6种不同的模仿学习算法，并使用共同的离线策略算法进行了评估。通过对专家轨迹数据进行测试，比较了这些算法的性能。 |
| [^28] | [Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning.](http://arxiv.org/abs/2106.12059) | 研究了一种简单的随机策略，用于将单点获取函数适应于批量主动学习，与计算密集型的批量采集函数相比，性能相当，但使用的计算资源更少。 |
| [^29] | [Measure of Strength of Evidence for Visually Observed Differences between Subpopulations.](http://arxiv.org/abs/2101.00362) | 本文介绍了一种衡量视觉观察到的子群差异的证据强度的方法，并提出了"人群差异准则"来评估其统计显著性。研究发现在高维和高信号环境下，传统方法存在局限性，因此提出了新的平衡置换方法和自助法置信区间来解决这些问题。在现代癌症数据的比较中，这些方法展示出了实用性和有效性。 |
| [^30] | [Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Connections to Evolvability.](http://arxiv.org/abs/2006.04787) | 本文解决了半空间在Massart噪声下的错配学习问题，提出了一个简化的算法并回答了一些开放问题。通过黑盒知识蒸馏过程，将复杂分类器转换为同样好的合适分类器。此外，我们还提出了一个小样本的合适学习算法，并将其与矩感知技术相结合，得到了一个具有多项式时间复杂性的学习算法。 |
| [^31] | [On the Ambiguity of Rank-Based Evaluation of Entity Alignment or Link Prediction Methods.](http://arxiv.org/abs/2002.06914) | 本研究研究了实体对齐或链接预测方法的排名评估的歧义性。分析了当前评估指标的不足之处，提出了评估方法的调整，以实现对模型性能的公平、可比和可解释的评估。 |

# 详细

[^1]: 无梯度推断中的流退火卡尔曼反演算法在贝叶斯反问题中的应用

    Flow Annealed Kalman Inversion for Gradient-Free Inference in Bayesian Inverse Problems. (arXiv:2309.11490v1 [stat.CO])

    [http://arxiv.org/abs/2309.11490](http://arxiv.org/abs/2309.11490)

    本论文提出了流退火卡尔曼反演（FAKI）算法，在贝叶斯反问题中应用，该算法利用流动退火和正规化流技术，能够以更高的准确度近似非高斯目标，相比于标准集合卡尔曼反演（EKI）有显著的改进。

    

    对于许多科学反问题，我们需要评估一个昂贵的前向模型。此外，该模型通常以一种无法访问其梯度的形式给出。在这种情况下，标准的马尔可夫链蒙特卡洛算法很快变得不切实际，需要大量的串行模型评估才能收敛到目标分布。在本文中，我们引入了流退火卡尔曼反演（FAKI）。这是对集合卡尔曼反演（EKI）的一般化，我们将卡尔曼滤波更新嵌入到温度退火方案中，并使用正规化流（NF）将与每个温度级别对应的中间测度映射到标准高斯分布。通过这样做，我们放宽了标准EKI中使用的中间测度理论上为高斯分布的假设，从而能够更准确地近似非高斯目标。我们在两个数值基准测试上展示了FAKI的性能，表明与标准EKI相比有显著的改进。

    For many scientific inverse problems we are required to evaluate an expensive forward model. Moreover, the model is often given in such a form that it is unrealistic to access its gradients. In such a scenario, standard Markov Chain Monte Carlo algorithms quickly become impractical, requiring a large number of serial model evaluations to converge on the target distribution. In this paper we introduce Flow Annealed Kalman Inversion (FAKI). This is a generalization of Ensemble Kalman Inversion (EKI), where we embed the Kalman filter updates in a temperature annealing scheme, and use normalizing flows (NF) to map the intermediate measures corresponding to each temperature level to the standard Gaussian. In doing so, we relax the Gaussian ansatz for the intermediate measures used in standard EKI, allowing us to achieve higher fidelity approximations to non-Gaussian targets. We demonstrate the performance of FAKI on two numerical benchmarks, showing dramatic improvements over standard EKI i
    
[^2]: Isolation Forest的分布和容量基准评分方法

    Distribution and volume based scoring for Isolation Forests. (arXiv:2309.11450v1 [stat.ML])

    [http://arxiv.org/abs/2309.11450](http://arxiv.org/abs/2309.11450)

    本文在Isolation Forest方法中提出了两个贡献，分别是对评分函数的信息理论推广和在个体树估计器层面上使用基于超体积的评分函数。这两种方法均对一些数据集相对于标准Isolation Forest表现出显著改进，并且其中一种方法在所有数据集上平均表现出改进。

    

    我们对异常和离群值检测方法Isolation Forest做出了两项贡献。第一个贡献是对用于聚合随机树估计器的得分函数进行了信息理论上的推广。这个推广允许考虑整个分布，而不仅仅是树的集成平均值。第二个贡献是在单个树估计器层面上替换了Isolation Forest基于深度的得分方法，改为基于隔离树叶节点的超体积的得分方法。我们通过生成的数据对这两种方法进行了验证，并在来自最近和详尽的“ADBench”基准的34个数据集上进行了评估，在某些数据集上两种变体相对于标准的Isolation Forest表现出显著的改进，并在所有数据集上对其中一种变体平均显示出改进。代码可复现。

    We make two contributions to the Isolation Forest method for anomaly and outlier detection. The first contribution is an information-theoretically motivated generalisation of the score function that is used to aggregate the scores across random tree estimators. This generalisation allows one to take into account not just the ensemble average across trees but instead the whole distribution. The second contribution is an alternative scoring function at the level of the individual tree estimator, in which we replace the depth-based scoring of the Isolation Forest with one based on hyper-volumes associated to an isolation tree's leaf nodes.  We motivate the use of both of these methods on generated data and also evaluate them on 34 datasets from the recent and exhaustive ``ADBench'' benchmark, finding significant improvement over the standard isolation forest for both variants on some datasets and improvement on average across all datasets for one of the two variants. The code to reproduce
    
[^3]: 深度神经网络作为降噪算法：高维图形模型中扩散模型的高效学习

    Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models. (arXiv:2309.11420v1 [cs.LG])

    [http://arxiv.org/abs/2309.11420](http://arxiv.org/abs/2309.11420)

    深度神经网络可以作为降噪算法在高维图形模型中学习扩散模型，为生成建模提供了高效的逼近方法。

    

    我们研究了深度神经网络在基于扩散的生成建模中通过评分函数的逼近效率。尽管现有的近似理论利用了评分函数的平滑性，但它们在本质上高维数据中受到维度灾难的困扰。这种限制在图形模型（如马尔可夫随机场）中尤为明显，这是图像分布常见的类型，评分函数的近似效率尚未确立。为了解决这个问题，我们观察到评分函数在图形模型中通常可以通过变分推断降噪算法进行较好的逼近。此外，这些算法适用于高效的神经网络表示。我们在图形模型的例子中进行了演示，包括伊辛模型、条件伊辛模型、受限玻尔兹曼机和稀疏编码模型。结合基于扩散采样的现成离散化误差界限，我们提供了一种高效的样本方法。

    We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling. While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data. This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished.  To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms. Furthermore, these algorithms are amenable to efficient neural network representation. We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models. Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample com
    
[^4]: 使用属性引导方法来理解公平性约束的影响

    Using Property Elicitation to Understand the Impacts of Fairness Constraints. (arXiv:2309.11343v1 [cs.LG])

    [http://arxiv.org/abs/2309.11343](http://arxiv.org/abs/2309.11343)

    这项研究使用属性引导方法来探索损失函数和正则化函数与最优决策之间的关系，特别是在公平机器学习中的应用。它提供了损失函数和正则化函数成对时属性改变的必要和充分条件，并通过实验证明了算法决策与数据分布变化和约束难度的相关性。

    

    预测算法通常通过优化某个损失函数进行训练，并添加正则化函数来施加违反约束的惩罚。预期地，添加这样的正则化函数可以改变目标函数的最小化值。目前还不清楚哪些正则化函数会改变损失函数的最小化值，以及当最小化值发生变化时，它会如何变化。我们使用属性引导方法来初步了解损失函数和正则化函数与给定问题实例的最优决策之间的联合关系。具体而言，我们给出了损失函数和正则化函数成对时，属性改变的必要和充分条件，并研究了一些满足这个条件的正则化函数在公平机器学习文献中的标准。我们通过实验证明了算法决策如何随着数据分布的变化和约束的难度而改变。

    Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints. As expected, the addition of such regularization functions can change the minimizer of the objective. It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes. We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance. In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature. We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraint
    
[^5]: 基于预测优化：在数据驱动优化中实现样本外最优

    Optimize-via-Predict: Realizing out-of-sample optimality in data-driven optimization. (arXiv:2309.11147v1 [math.OC])

    [http://arxiv.org/abs/2309.11147](http://arxiv.org/abs/2309.11147)

    这项研究提出了一种基于预测的数据驱动优化方法，通过局部平均和采样分布来实现样本外最优解，并且提供了充分条件和高效算法。在新供应商模型中的实验证明了该方法的有效性。

    

    我们研究了一种数据驱动优化的随机形式，其中决策者不知道真实分布，但知道它属于某个假设集，并拥有一个历史数据集，可以从中获取关于其的信息。我们将预定方案定义为将这样的数据集映射到决策的决策规则。由于不存在能够泛化到整个假设集的预定方案，我们将样本外最优定义为在假设集的邻域内局部平均，并在采样分布上进行平均。我们证明了局部样本外最优的充分条件，这归结为假设族的充分统计函数。我们提出了一个优化问题，可以解出这样的样本外最优解，并通过采样和二分搜索算法高效地实现。最后，我们在新供应商模型上展示了我们的模型，并找到了较强的总结。

    We examine a stochastic formulation for data-driven optimization wherein the decision-maker is not privy to the true distribution, but has knowledge that it lies in some hypothesis set and possesses a historical data set, from which information about it can be gleaned. We define a prescriptive solution as a decision rule mapping such a data set to decisions. As there does not exist prescriptive solutions that are generalizable over the entire hypothesis set, we define out-of-sample optimality as a local average over a neighbourhood of hypotheses, and averaged over the sampling distribution. We prove sufficient conditions for local out-of-sample optimality, which reduces to functions of the sufficient statistic of the hypothesis family. We present an optimization problem that would solve for such an out-of-sample optimal solution, and does so efficiently by a combination of sampling and bisection search algorithms. Finally, we illustrate our model on the newsvendor model, and find stron
    
[^6]: Ano-SuPs: 通过识别可疑的区块进行制造产品的多尺度异常检测

    Ano-SuPs: Multi-size anomaly detection for manufactured products by identifying suspected patches. (arXiv:2309.11120v1 [stat.ML])

    [http://arxiv.org/abs/2309.11120](http://arxiv.org/abs/2309.11120)

    Ano-SuPs是一种通过识别可疑区块来进行制造产品的多尺度异常检测的两阶段策略方法。它可以解决图像背景复杂性和异常模式的挑战，并具有较高的准确性和鲁棒性。

    

    基于图像的系统因其提供丰富的制造状态信息、低实施成本和高采集速度而受到欢迎。然而，图像背景的复杂性和各种异常模式给现有的矩阵分解方法带来了新的挑战，这些方法不足以满足建模需求。此外，异常的不确定性可能导致异常的污染问题，使得设计的模型和方法对外部干扰非常敏感。为了解决这些挑战，我们提出了一种通过识别可疑区块（Ano-SuPs）来检测异常的两阶段策略异常检测方法。具体来说，我们提出了通过两次重建输入图像来检测带有异常的区块的方法：第一步是通过去除那些可疑区块来获得一组正常区块，第二步是使用这些正常区块来优化对带有异常区块的识别。我们通过实验证明了这种方法的效果。

    Image-based systems have gained popularity owing to their capacity to provide rich manufacturing status information, low implementation costs and high acquisition rates. However, the complexity of the image background and various anomaly patterns pose new challenges to existing matrix decomposition methods, which are inadequate for modeling requirements. Moreover, the uncertainty of the anomaly can cause anomaly contamination problems, making the designed model and method highly susceptible to external disturbances. To address these challenges, we propose a two-stage strategy anomaly detection method that detects anomalies by identifying suspected patches (Ano-SuPs). Specifically, we propose to detect the patches with anomalies by reconstructing the input image twice: the first step is to obtain a set of normal patches by removing those suspected patches, and the second step is to use those normal patches to refine the identification of the patches with anomalies. To demonstrate its ef
    
[^7]: 天然电网运营计划中的极端情景选择

    Extreme Scenario Selection in Day-Ahead Power Grid Operational Planning. (arXiv:2309.11067v1 [stat.ML])

    [http://arxiv.org/abs/2309.11067](http://arxiv.org/abs/2309.11067)

    本文提出并分析了一种在天然电网规划中选择极端情景的方法，通过统计功能深度度量来筛选出最重要的情景以减轻运营风险。研究结果表明该方法在真实的Texas-7k电网上具有良好的效果。

    

    我们提出并分析了在提前一天的电网规划中应用统计功能深度度量来选择极端情景的方法。我们的主要目的是筛选针对实际负载和可再生能源生成的概率情景，以识别对运营风险缓解最重要的情景。为了处理资产类别和日内时段的场景高维度情况，我们使用功能深度度量来子选择最有可能对电网运营风险最高的异常情景。我们研究了一系列功能深度度量以及一系列运营风险，包括负荷削减、运营成本、备用不足和可变可再生能源削减。通过对现实的Texas-7k电网进行案例研究，证明了所提出的筛选方法的有效性。

    We propose and analyze the application of statistical functional depth metrics for the selection of extreme scenarios in day-ahead grid planning. Our primary motivation is screening of probabilistic scenarios for realized load and renewable generation, in order to identify scenarios most relevant for operational risk mitigation. To handle the high-dimensionality of the scenarios across asset classes and intra-day periods, we employ functional measures of depth to sub-select outlying scenarios that are most likely to be the riskiest for the grid operation. We investigate a range of functional depth measures, as well as a range of operational risks, including load shedding, operational costs, reserves shortfall and variable renewable energy curtailment. The effectiveness of the proposed screening approach is demonstrated through a case study on the realistic Texas-7k grid.
    
[^8]: Fake News BR: 一种用于巴西葡萄牙语的假新闻检测平台

    Fake News BR: A Fake News Detection Platform for Brazilian Portuguese. (arXiv:2309.11052v1 [cs.CL])

    [http://arxiv.org/abs/2309.11052](http://arxiv.org/abs/2309.11052)

    本研究提出了一个用于巴西葡萄牙语的假新闻检测平台，采用机器学习和自然语言处理技术，能够高效准确地识别假新闻，同时提供实时分析和验证新闻文章真实性的用户友好平台。

    

    由于假新闻传播误导公众舆论的潜力，其传播已成为近期关注的一个重要问题。本文对巴西葡萄牙语中的假新闻检测进行了全面的研究，重点关注新闻类型。我们提出了一种基于机器学习的方法，利用自然语言处理技术，包括TF-IDF和Word2Vec，从文本数据中提取特征。我们评估了各种分类算法的性能，如逻辑回归、支持向量机、随机森林、AdaBoost和LightGBM，使用包含真实和假新闻文章的数据集。所提出的方法在准确率和F1得分上都取得了高水平，证明了其识别假新闻的有效性。此外，我们开发了一个用户友好的网站平台FAKENEWSBR.COM，以便验证新闻文章的真实性。我们的平台提供实时分析，允许用户检查新闻文章的真实性。

    The proliferation of fake news has become a significant concern in recent times due to its potential to spread misinformation and manipulate public opinion. In this paper, we present a comprehensive study on the detection of fake news in Brazilian Portuguese, focusing on journalistic-type news. We propose a machine learning-based approach that leverages natural language processing techniques, including TF-IDF and Word2Vec, to extract features from textual data. We evaluate the performance of various classification algorithms, such as logistic regression, support vector machine, random forest, AdaBoost, and LightGBM, on a dataset containing both true and fake news articles. The proposed approach achieves a high level of accuracy and F1-Score, demonstrating its effectiveness in identifying fake news. Additionally, we develop a user-friendly web platform, FAKENEWSBR.COM, to facilitate the verification of news articles' veracity. Our platform provides real-time analysis, allowing users to 
    
[^9]: PAGER: 一种用于深度回归模型故障分析的框架

    PAGER: A Framework for Failure Analysis of Deep Regression Models. (arXiv:2309.10977v1 [cs.LG])

    [http://arxiv.org/abs/2309.10977](http://arxiv.org/abs/2309.10977)

    PAGER提出了一种用于深度回归模型故障分析的框架，通过综合利用认识不确定性和不一致分数，对样本进行分组并提供全面的分析。

    

    安全部署AI模型需要主动检测潜在的预测故障，以防止昂贵的错误。尽管分类问题的故障检测已经引起了广泛关注，但在回归任务中表征故障模式更加复杂且较少研究。现有方法依赖于认识不确定性或与训练分布的特征不一致来表征模型风险。然而，我们表明，仅靠不确定性无法准确表征故障，这是由于各种误差源的存在。在本文中，我们提出了PAGER（回归器的原则性泛化错误分析），这是一个系统检测和表征深度回归模型故障的框架。基于最近提出的深度模型锚定思想，PAGER将认识不确定性和新颖的、互补的不一致分数统一起来，将样本组织成不同的风险区域，从而提供全面的分析。

    Safe deployment of AI models requires proactive detection of potential prediction failures to prevent costly errors. While failure detection in classification problems has received significant attention, characterizing failure modes in regression tasks is more complicated and less explored. Existing approaches rely on epistemic uncertainties or feature inconsistency with the training distribution to characterize model risk. However, we show that uncertainties are necessary but insufficient to accurately characterize failure, owing to the various sources of error. In this paper, we propose PAGER (Principled Analysis of Generalization Errors in Regressors), a framework to systematically detect and characterize failures in deep regression models. Built upon the recently proposed idea of anchoring in deep models, PAGER unifies both epistemic uncertainties and novel, complementary non-conformity scores to organize samples into different risk regimes, thereby providing a comprehensive analys
    
[^10]: SPFQ:一种用于神经网络量化的随机算法及其误差分析

    SPFQ: A Stochastic Algorithm and Its Error Analysis for Neural Network Quantization. (arXiv:2309.10975v1 [cs.LG])

    [http://arxiv.org/abs/2309.10975](http://arxiv.org/abs/2309.10975)

    SPFQ是一种用于神经网络量化的快速随机算法，通过贪婪的路径跟踪和随机量化器有效地减少网络中的冗余并提高量化效率。在本文中，我们首次建立了全网络的误差界，并通过应用于具有高斯权重的多层网络的量化证明了结果的有效性。

    

    量化是一种广泛使用的压缩方法，可以有效减少过参数化神经网络中的冗余。然而，由于存在非凸损失函数和非线性激活函数，现有的深度神经网络量化技术往往缺乏全面的误差分析。在本文中，我们提出了一种快速随机算法，用于量化完全训练好的神经网络的权重。我们的方法利用贪婪的路径跟踪机制结合随机量化器。其计算复杂度只与网络中的权重数量呈线性关系，从而实现了大型网络的高效量化。重要的是，我们首次在无穷字母条件和最小的权重和输入数据假设下建立了全网络的误差界。作为这一结果的一个应用，我们证明了当量化具有高斯权重的多层网络时，相对平方量化误差e的要点

    Quantization is a widely used compression method that effectively reduces redundancies in over-parameterized neural networks. However, existing quantization techniques for deep neural networks often lack a comprehensive error analysis due to the presence of non-convex loss functions and nonlinear activations. In this paper, we propose a fast stochastic algorithm for quantizing the weights of fully trained neural networks. Our approach leverages a greedy path-following mechanism in combination with a stochastic quantizer. Its computational complexity scales only linearly with the number of weights in the network, thereby enabling the efficient quantization of large networks. Importantly, we establish, for the first time, full-network error bounds, under an infinite alphabet condition and minimal assumptions on the weights and input data. As an application of this result, we prove that when quantizing a multi-layer network having Gaussian weights, the relative square quantization error e
    
[^11]: DPpack：一个用于差分隐私统计分析和机器学习的R包

    DPpack: An R Package for Differentially Private Statistical Analysis and Machine Learning. (arXiv:2309.10965v1 [stat.ML])

    [http://arxiv.org/abs/2309.10965](http://arxiv.org/abs/2309.10965)

    DPpack是一个开源的R包，提供了差分隐私统计分析和机器学习的工具集合，包括不同的保护机制和描述性统计函数。它还提供了隐私保护版本的逻辑回归、支持向量机和线性回归的实现，以及对每个模型的差分隐私超参数调整。

    

    差分隐私（DP）是目前用于保护个人隐私的最先进的框架，可用于发布聚合统计数据或从数据中构建统计/机器学习模型。我们开发了开源的R包DPpack，提供了大量的差分隐私分析工具。当前版本的DPpack实现了三种常用的DP保护机制：拉普拉斯，高斯和指数。此外，DPpack还提供了一个易于访问的隐私保护描述性统计函数工具包。其中包括均值、方差、协方差和分位数，以及直方图和列联表。最后，DPpack提供了基于隐私保护的逻辑回归、支持向量机和线性回归的用户友好实现，以及针对每个模型的差分隐私超参数调整。这个大量实现的差分隐私统计和模型集合允许无麻烦地利用差异化。

    Differential privacy (DP) is the state-of-the-art framework for guaranteeing privacy for individuals when releasing aggregated statistics or building statistical/machine learning models from data. We develop the open-source R package DPpack that provides a large toolkit of differentially private analysis. The current version of DPpack implements three popular mechanisms for ensuring DP: Laplace, Gaussian, and exponential. Beyond that, DPpack provides a large toolkit of easily accessible privacy-preserving descriptive statistics functions. These include mean, variance, covariance, and quantiles, as well as histograms and contingency tables. Finally, DPpack provides user-friendly implementation of privacy-preserving versions of logistic regression, SVM, and linear regression, as well as differentially private hyperparameter tuning for each of these models. This extensive collection of implemented differentially private statistics and models permits hassle-free utilization of differential
    
[^12]: Riemannian流形上Matern高斯过程的后验收缩速率

    Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds. (arXiv:2309.10918v1 [stat.ML])

    [http://arxiv.org/abs/2309.10918](http://arxiv.org/abs/2309.10918)

    该论文研究了定义在紧致Riemannian流形上的内在Matern高斯过程和外在过程之间的收缩速率，并发现它们的速率在适当匹配平滑参数的情况下是相等的。

    

    高斯过程在许多依赖于不确定性量化的机器学习应用中被使用。最近，已经开发了在几何设置下处理这些模型的计算工具，例如，当输入位于Riemannian流形上时。这引出了一个问题：这些内在模型在理论上是否可以证明相比于将所有相关量嵌入到$\mathbb{R}^d$并使用普通欧几里德高斯过程的限制，可以带来更好的性能？为了研究这个问题，我们证明了定义在紧致Riemannian流形上的内在Matern高斯过程的最优收缩速率。我们还通过流形和环境Sobolev空间之间的迹和扩展定理证明了外在过程的类似速率：令人惊讶的是，所得到的速率与内在过程的速率相符，前提是它们的平滑参数适当匹配。我们在一些实证数据上进行了对这些速率的演示。

    Gaussian processes are used in many machine learning applications that rely on uncertainty quantification. Recently, computational tools for working with these models in geometric settings, such as when inputs lie on a Riemannian manifold, have been developed. This raises the question: can these intrinsic models be shown theoretically to lead to better performance, compared to simply embedding all relevant quantities into $\mathbb{R}^d$ and using the restriction of an ordinary Euclidean Gaussian process? To study this, we prove optimal contraction rates for intrinsic Mat\'ern Gaussian processes defined on compact Riemannian manifolds. We also prove analogous rates for extrinsic processes using trace and extension theorems between manifold and ambient Sobolev spaces: somewhat surprisingly, the rates obtained turn out to coincide with those of the intrinsic processes, provided that their smoothness parameters are matched appropriately. We illustrate these rates empirically on a number of
    
[^13]: 上下文≈环境。

    Context $\approx$ Environment. (arXiv:2309.09888v1 [cs.LG])

    [http://arxiv.org/abs/2309.09888](http://arxiv.org/abs/2309.09888)

    在这篇论文中，作者通过理论与实验证明了将注意力放在上下文-未标记样本上，可以实现更好的领域泛化。

    

    AI研究的中心在于两个方面。一方面，社区正在努力构建能够丢弃虚假相关性并在新颖的测试环境中更好地进行泛化的模型。不幸的是，到目前为止，没有任何提案能够令人信服地超越简单的经验风险最小化基线。另一方面，大型语言模型(LLMs)已经成为能够在上下文中学习、根据用户通过提示施加的多种上下文背景灵活泛化的算法。本文认为上下文≈环境，并假设在上下文学习中隐藏着更好的领域泛化之钥。通过广泛的理论与实验，我们展示了注意上下文-未标记的样本的重要性，这种注意可以使我们提出的In-Context Risk Minimization (ICRM)算法聚焦于测试环境风险最小化。

    Two lines of work are taking the central stage in AI research. On the one hand, the community is making increasing efforts to build models that discard spurious correlations and generalize better in novel test environments. Unfortunately, the bitter lesson so far is that no proposal convincingly outperforms a simple empirical risk minimization baseline. On the other hand, large language models (LLMs) have erupted as algorithms able to learn in-context, generalizing on-the-fly to the eclectic contextual circumstances that users enforce by means of prompting. In this paper, we argue that context $\approx$ environment, and posit that in-context learning holds the key to better domain generalization. Via extensive theory and experiments, we show that paying attention to context$\unicode{x2013}\unicode{x2013}$unlabeled examples as they arrive$\unicode{x2013}\unicode{x2013}$allows our proposed In-Context Risk Minimization (ICRM) algorithm to zoom-in on the test environment risk minimizer, le
    
[^14]: 逻辑回归和softmax分类器的逆向分类：高效优化

    Inverse classification with logistic and softmax classifiers: efficient optimization. (arXiv:2309.08945v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2309.08945](http://arxiv.org/abs/2309.08945)

    本文研究了逻辑回归和softmax分类器中的逆向分类问题，并提出了高效的解决方法，可以在交互式或实时应用中获得准确解。

    

    近年来，一种特定类型的问题引起了人们的兴趣，即在训练好的分类器上进行查询。具体而言，我们希望找到与给定输入实例最接近的实例，以使分类器的预测标签以所需的方式改变。这类问题包括反事实解释，对抗性示例和模型反演。所有这些问题实质上都是涉及输入实例向量上的固定分类器的优化问题，我们希望能够快速解决以用于交互式或实时应用。本文重点在于对逻辑回归和softmax分类器这两种广泛使用的分类器进行高效解决这一问题。由于这些模型的特殊性质，我们证明了对于逻辑回归问题，优化问题可以用闭式解求解，对于softmax分类器，可以通过迭代但非常快速地求解。这使我们能够精确地解决任一情况（接近机器精度）。

    In recent years, a certain type of problems have become of interest where one wants to query a trained classifier. Specifically, one wants to find the closest instance to a given input instance such that the classifier's predicted label is changed in a desired way. Examples of these ``inverse classification'' problems are counterfactual explanations, adversarial examples and model inversion. All of them are fundamentally optimization problems over the input instance vector involving a fixed classifier, and it is of interest to achieve a fast solution for interactive or real-time applications. We focus on solving this problem efficiently for two of the most widely used classifiers: logistic regression and softmax classifiers. Owing to special properties of these models, we show that the optimization can be solved in closed form for logistic regression, and iteratively but extremely fast for the softmax classifier. This allows us to solve either case exactly (to nearly machine precision)
    
[^15]: 神经潜在几何搜索：通过格罗莫夫-豪斯多夫信息驱动的贝叶斯优化来进行乘积流形推断

    Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization. (arXiv:2309.04810v1 [cs.LG])

    [http://arxiv.org/abs/2309.04810](http://arxiv.org/abs/2309.04810)

    本论文提出了神经潜在几何搜索(NLGS)的概念，旨在通过格罗莫夫-豪斯多夫距离来自动识别下游任务的最佳潜在几何结构，以提高机器学习模型的性能。

    

    最近的研究表明，通过将潜在空间的几何结构与底层数据结构对齐，可以提高机器学习模型的性能。研究人员提出使用具有恒定曲率的双曲和球形空间，或者它们的组合，来更好地建模潜在空间并增强模型性能，而不仅仅依赖于欧几里得空间。然而，目前对自动识别下游任务的最佳潜在几何结构问题还没有给予足够关注。我们在数学上定义了这个新颖的问题，并将其称为神经潜在几何搜索(NLGS)。具体而言，我们引入了一种基于格罗莫夫-豪斯多夫距离的候选潜在几何结构之间的新概念距离，以实现这一目标。为了计算格罗莫夫-豪斯多夫距离，我们提出了一种通过最小查询评估搜索由恒定曲率模型空间乘积组成的潜在几何结构的原则方法。

    Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Ha
    
[^16]: Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) 该论文标题已翻译：二元强化学习。

    Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])

    [http://arxiv.org/abs/2308.07843](http://arxiv.org/abs/2308.07843)

    该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。

    

    移动医疗旨在通过在个人日常生活中提供干预来提高健康结果。照顾伴侣和社会支持网络的参与经常在帮助个人管理繁重的医疗条件方面起着关键作用。这为移动医疗提供了机会，设计针对二元关系——目标人和其照顾伴侣之间关系——以提高社会支持的干预措施。在本文中，我们开发了二元强化学习（Dyadic RL），这是一种基于环境因素和目标人及其照顾伴侣的过去反馈个性化干预措施的在线强化学习算法。在这里，多组干预措施影响着二元关系在多个时间间隔内。开发的二元强化学习是贝叶斯和层次的。我们正式介绍了问题设定，开发了二元强化学习并确定了遗憾边界。通过模拟，我们展示了二元强化学习的实证效果。

    Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
    
[^17]: 多类在线学习在Bandit反馈下的研究

    Multiclass Online Learnability under Bandit Feedback. (arXiv:2308.04620v1 [cs.LG])

    [http://arxiv.org/abs/2308.04620](http://arxiv.org/abs/2308.04620)

    Bandit反馈下的在线多类学习的关键在于Bandit Littlestone维度的有限性，无论标签空间是否无界。

    

    我们研究了在Bandit反馈下的多类在线分类问题。我们扩展了(daniely2013price)的结果，通过展示Bandit Littlestone维度的有限性是多类在线学习的必要且充分条件，即使标签空间是无界的。我们的结果补充了(hanneke2023multiclass)的最近工作，他们在标签空间无界的全信息设置中，展示了Littlestone维度刻画了在线多类学习的能力。

    We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.
    
[^18]: 内在上下文算子学习用于微分方程问题

    In-Context Operator Learning for Differential Equation Problems. (arXiv:2304.07993v1 [cs.LG])

    [http://arxiv.org/abs/2304.07993](http://arxiv.org/abs/2304.07993)

    本文提出了一种新的神经网络方法INDEED，它可以同时学习不同微分方程问题的操作符，而无需重新训练，且只需要极少的演示。

    

    本文介绍了一种新的基于神经网络的方法——IN-context Differential Equation Encoder-Decoder（INDEED），用于从数据中同时学习操作符并在推理阶段将其应用于新问题，而无需进行任何权重更新。现有方法局限于使用神经网络来逼近特定的方程解或特定的操作符，需要重新训练来处理具有不同方程的新问题。通过训练单个神经网络作为操作符学习器，我们不仅可以摆脱为新问题重新训练（甚至微调）神经网络的困扰，还可以利用操作符之间共享的共同点，这样在学习新的操作符时只需要极少的演示即可。我们的数值结果显示了神经网络作为少样本学习器的能力，用于各种不同类型的微分方程问题，包括ODE和PDE的正向和反向问题，同时显示它可以推广学习能力。

    This paper introduces a new neural-network-based approach, namely IN-context Differential Equation Encoder-Decoder (INDEED), to simultaneously learn operators from data and apply it to new questions during the inference stage, without any weight update. Existing methods are limited to using a neural network to approximate a specific equation solution or a specific operator, requiring retraining when switching to a new problem with different equations. By training a single neural network as an operator learner, we can not only get rid of retraining (even fine-tuning) the neural network for new problems, but also leverage the commonalities shared across operators so that only a few demos are needed when learning a new operator. Our numerical results show the neural network's capability as a few-shot operator learner for a diversified type of differential equation problems, including forward and inverse problems of ODEs and PDEs, and also show that it can generalize its learning capabilit
    
[^19]: 分析和改进神经说话人嵌入用于ASR

    Analyzing And Improving Neural Speaker Embeddings for ASR. (arXiv:2301.04571v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04571](http://arxiv.org/abs/2301.04571)

    该论文研究了将神经说话人嵌入应用于ASR系统中，并提出了改进的嵌入提取流程和集成方法，通过改进的声学模型和添加神经说话人嵌入，获得了显著的WER性能提升。

    

    神经说话人嵌入通过DNN模型编码说话者的语音特征，被广泛用于说话者验证任务。然而，很少有研究探讨神经说话人嵌入在ASR系统中的使用。在这项工作中，我们将神经说话人嵌入集成到基于Conformer的混合HMM ASR系统中，并进行改进。对于ASR，我们改进了嵌入提取流程，并结合加权简单加法集成方法，使得x-vector和c-vector达到与i-vector相当的性能。我们进一步比较和分析不同的说话人嵌入。我们通过从newbob学习率调度转换为单周期学习调度来改进声学模型，在Switchboard上相对WER降低了约3%，同时减少了整体训练时间17%。通过进一步添加神经说话人嵌入，我们在Hub5'00上获得了额外约3%的相对WER改进。我们最好的基于Conformer的混合A

    Neural speaker embeddings encode the speaker's speech characteristics through a DNN model and are prevalent for speaker verification tasks. However, few studies have investigated the usage of neural speaker embeddings for an ASR system. In this work, we present our efforts w.r.t integrating neural speaker embeddings into a conformer based hybrid HMM ASR system. For ASR, our improved embedding extraction pipeline in combination with the Weighted-Simple-Add integration method results in x-vector and c-vector reaching on par performance with i-vectors. We further compare and analyze different speaker embeddings. We present our acoustic model improvements obtained by switching from newbob learning rate schedule to one cycle learning schedule resulting in a ~3% relative WER reduction on Switchboard, additionally reducing the overall training time by 17%. By further adding neural speaker embeddings, we gain additional ~3% relative WER improvement on Hub5'00. Our best Conformer-based hybrid A
    
[^20]: 统计和计算保证了影响诊断的有效性

    Statistical and Computational Guarantees for Influence Diagnostics. (arXiv:2212.04014v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.04014](http://arxiv.org/abs/2212.04014)

    本论文提出了统计和计算边界来保证影响诊断的有效性，通过使用高效的逆-Hessian-向量乘积实现的方法，我们可以在机器学习和人工智能领域的应用中准确识别有影响力的数据点或子集。

    

    影响诊断，如影响函数和近似最大影响扰动，在机器学习和人工智能领域的应用中很受欢迎。影响诊断是用于识别有影响力的数据点或数据子集的强大统计工具。我们使用高效的逆-Hessian-向量乘积实现建立了影响函数和近似最大影响扰动的有限样本统计界限和计算复杂度界限。我们使用广义线性模型和基于大规模注意力机制的模型在合成和真实数据上进行了实验验证。

    Influence diagnostics such as influence functions and approximate maximum influence perturbations are popular in machine learning and in AI domain applications. Influence diagnostics are powerful statistical tools to identify influential datapoints or subsets of datapoints. We establish finite-sample statistical bounds, as well as computational complexity bounds, for influence functions and approximate maximum influence perturbations using efficient inverse-Hessian-vector product implementations. We illustrate our results with generalized linear models and large attention based models on synthetic and real data.
    
[^21]: 迈向无限自学习的并行自适应退火的MCMC方法

    Toward Unlimited Self-Learning MCMC with Parallel Adaptive Annealing. (arXiv:2211.14024v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.14024](http://arxiv.org/abs/2211.14024)

    提出了一种并行自适应退火的方法，将自学习Monte Carlo（SLMC）方法应用于多峰分布，实现了高效的Monte Carlo更新，并解决了建议模型的模式崩溃问题。

    

    自学习Monte Carlo（SLMC）方法是最近提出的使用机器学习模型加速Markov链Monte Carlo（MCMC）方法的方法。通过潜在生成模型，SLMC方法实现了具有较少自相关性的高效Monte Carlo更新。然而，SLMC方法难以直接应用于多峰分布，其中难以获得训练数据。为了解决这个限制，我们提出了并行自适应退火方法，它使SLMC方法直接应用于具有逐渐训练的建议分布的多峰分布。并行自适应退火基于（i）带有退火的顺序学习，以继承和更新模型参数，（ii）自适应退火，以自动检测欠学习，（iii）并行退火，以减轻建议模型的模式崩溃。我们还提出了使用变分自动编码器（VAE）作为SLMC建议的VAE-SLMC方法，以实现高效的并行建议。

    Self-learning Monte Carlo (SLMC) methods are recently proposed to accelerate Markov chain Monte Carlo (MCMC) methods using a machine learning model. With latent generative models, SLMC methods realize efficient Monte Carlo updates with less autocorrelation. However, SLMC methods are difficult to directly apply to multimodal distributions for which training data are difficult to obtain. To solve the limitation, we propose parallel adaptive annealing, which makes SLMC methods directly apply to multimodal distributions with a gradually trained proposal while annealing target distribution. Parallel adaptive annealing is based on (i) sequential learning with annealing to inherit and update the model parameters, (ii) adaptive annealing to automatically detect under-learning, and (iii) parallel annealing to mitigate mode collapse of proposal models. We also propose VAE-SLMC method which utilizes a variational autoencoder (VAE) as a proposal of SLMC to make efficient parallel proposals indepen
    
[^22]: 神经超统计学用于贝叶斯估计动态认知模型

    Neural Superstatistics for Bayesian Estimation of Dynamic Cognitive Model. (arXiv:2211.13165v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2211.13165](http://arxiv.org/abs/2211.13165)

    本研究提出了一种神经超统计学方法，用于贝叶斯估计动态认知模型。通过引入时间维度和超统计视角，可以有效地估计系统中的动态性质，并利用仿真和深度学习方法进行贝叶斯推理。该方法能够恢复时变和时不变参数，并在实验证明其有效性。

    

    认知的数学模型通常是无记忆的，忽略了参数的潜在波动。然而，人类认知本质上是动态的。因此，我们提出在机械认知模型中引入时间维度，并从超统计学的角度估计所得到的动态性质。这样的模型包括了一个低级观测模型和一个高级转换模型之间的层次结构。观测模型描述了系统的局部行为，转换模型规定了观测模型参数随时间演化的方式。为了克服超统计模型复杂性带来的估计挑战，我们开发并验证了一种基于仿真的深度学习方法，用于贝叶斯推理，可以恢复时变和时不变参数。我们首先将我们的方法与两个已有的能够估计时变参数的框架进行基准测试。然后，我们将我们的方法应用于拟合动态版本的差分方程模型。

    Mathematical models of cognition are often memoryless and ignore potential fluctuations of their parameters. However, human cognition is inherently dynamic. Thus, we propose to augment mechanistic cognitive models with a temporal dimension and estimate the resulting dynamics from a superstatistics perspective. Such a model entails a hierarchy between a low-level observation model and a high-level transition model. The observation model describes the local behavior of a system, and the transition model specifies how the parameters of the observation model evolve over time. To overcome the estimation challenges resulting from the complexity of superstatistical models, we develop and validate a simulation-based deep learning method for Bayesian inference, which can recover both time-varying and time-invariant parameters. We first benchmark our method against two existing frameworks capable of estimating time-varying parameters. We then apply our method to fit a dynamic version of the diff
    
[^23]: 通过使用Cover Trees的最小间隔实现数值稳定的稀疏高斯过程

    Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees. (arXiv:2210.07893v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.07893](http://arxiv.org/abs/2210.07893)

    本文针对高斯过程模型的数值稳定性进行了研究，通过感兴趣点的选择和计算，提供了稳定可靠的稀疏逼近方法。

    

    高斯过程常用于较大的机器学习和决策系统中，例如地理空间建模、贝叶斯优化或潜在高斯模型中。在一个系统中，高斯过程模型需要以稳定可靠的方式运行，以确保与系统的其他部分正确交互。本文研究了基于感兴趣点的可扩展稀疏逼近的数值稳定性。为此，我们首先回顾了数值稳定性，并阐述了高斯过程模型可能不稳定的典型情况。在插值文献中原始开发的稳定性理论的基础上，我们导出了对感兴趣点进行计算的数值稳定性的充分条件和某些情况下的必要条件。对于地理空间建模等低维任务，我们提出了一种自动计算满足这些条件的感兴趣点的方法。

    Gaussian processes are frequently deployed as part of larger machine learning and decision-making systems, for instance in geospatial modeling, Bayesian optimization, or in latent Gaussian models. Within a system, the Gaussian process model needs to perform in a stable and reliable manner to ensure it interacts correctly with other parts of the system. In this work, we study the numerical stability of scalable sparse approximations based on inducing points. To do so, we first review numerical stability, and illustrate typical situations in which Gaussian process models can be unstable. Building on stability theory originally developed in the interpolation literature, we derive sufficient and in certain cases necessary conditions on the inducing points for the computations performed to be numerically stable. For low-dimensional tasks such as geospatial modeling, we propose an automated method for computing inducing points satisfying these conditions. This is done via a modification of t
    
[^24]: Conformal Prediction对分散标签噪声具有稳健性

    Conformal Prediction is Robust to Dispersive Label Noise. (arXiv:2209.14295v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14295](http://arxiv.org/abs/2209.14295)

    本研究研究了Conformal Prediction方法对于标签噪声具有鲁棒性。我们找出了构建可以正确覆盖无噪声真实标签的不确定性集合的条件，并提出了对具有噪声标签的一般损失函数进行正确控制的要求。实验证明，在对抗性案例之外，使用Conformal Prediction和风险控制技术可以实现对干净真实标签的保守风险。我们还提出了一种有界尺寸噪声修正的方法，以确保实现正确的真实标签风险。

    

    我们研究了对标签噪声具有鲁棒性的Conformal Prediction方法，该方法是一种用于不确定性量化的强大工具。我们的分析涵盖了回归和分类问题，对于如何构建能够正确覆盖未观察到的无噪声真实标签的不确定性集合进行了界定。我们进一步扩展了我们的理论，并提出了对于带有噪声标签正确控制一般损失函数（如假阴性比例）的要求。我们的理论和实验表明，在带有噪声标签的情况下，Conformal Prediction和风险控制技术能够实现对干净真实标签的保守风险，除了在对抗性案例中。在这种情况下，我们还可以通过对Conformal Prediction算法进行有界尺寸的噪声修正，以确保实现正确的真实标签风险，而无需考虑分数或数据的规则性。

    We study the robustness of conformal prediction, a powerful tool for uncertainty quantification, to label noise. Our analysis tackles both regression and classification problems, characterizing when and how it is possible to construct uncertainty sets that correctly cover the unobserved noiseless ground truth labels. We further extend our theory and formulate the requirements for correctly controlling a general loss function, such as the false negative proportion, with noisy labels. Our theory and experiments suggest that conformal prediction and risk-controlling techniques with noisy labels attain conservative risk over the clean ground truth labels except in adversarial cases. In such cases, we can also correct for noise of bounded size in the conformal prediction algorithm in order to ensure achieving the correct risk of the ground truth labels without score or data regularity.
    
[^25]: 自适应深度学习用于非线性时间序列模型

    Adaptive deep learning for nonlinear time series models. (arXiv:2207.02546v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2207.02546](http://arxiv.org/abs/2207.02546)

    本文提出了一种自适应深度学习方法用于非线性时间序列模型的均值函数估计，证明了稀疏惩罚的深度神经网络估计器在许多非线性自回归模型中达到了极小下界的最优速率。

    

    本文提出了一种基于深度神经网络的非参数自适应估计理论，用于非平稳和非线性的时间序列模型的均值函数估计。我们首先考虑了两种类型的深度神经网络估计器，即非惩罚和稀疏惩罚的估计器，并为一般的非平稳时间序列建立了它们的泛化误差界限。然后，我们推导了估计属于广泛类别的非线性自回归模型（包括非线性广义可加自回归、单指数和阈值自回归模型）均值函数的极小下界。在这些结果的基础上，我们展示了稀疏惩罚的深度神经网络估计器在许多非线性自回归模型中是自适应的，并达到极小下界的最优速率，仅有多对数因子的差距。通过数值模拟，我们证明了深度神经网络方法在估计具有内在低维结构和不连续或粗糙均值函数的非线性自回归模型中的实用性。

    In this paper, we develop a general theory for adaptive nonparametric estimation of the mean function of a non-stationary and nonlinear time series model using deep neural networks (DNNs). We first consider two types of DNN estimators, non-penalized and sparse-penalized DNN estimators, and establish their generalization error bounds for general non-stationary time series. We then derive minimax lower bounds for estimating mean functions belonging to a wide class of nonlinear autoregressive (AR) models that include nonlinear generalized additive AR, single index, and threshold AR models. Building upon the results, we show that the sparse-penalized DNN estimator is adaptive and attains the minimax optimal rates up to a poly-logarithmic factor for many nonlinear AR models. Through numerical simulations, we demonstrate the usefulness of the DNN methods for estimating nonlinear AR models with intrinsic low-dimensional structures and discontinuous or rough mean functions, which is consistent
    
[^26]: 最佳子群选择

    Optimal subgroup selection. (arXiv:2109.01077v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2109.01077](http://arxiv.org/abs/2109.01077)

    在回归设置中，我们提出了一个子群选择挑战，以确定回归函数超过预设阈值的特征空间区域。我们的主要贡献是确定了在样本规模和类型I错误概率上遗憾的最佳速率。

    

    在临床试验和其他应用中，我们经常看到特征空间中出现了有趣的行为区域，但不清楚这些观察到的现象是否在总体水平上有所反映。针对回归设置，我们考虑子群选择挑战，即识别一个特征空间的区域，在该区域上，回归函数超过了预设的阈值。我们将这个问题形式化为一种约束优化问题，通过寻找一个低复杂度、数据相关的选择集，在这个选择集上，回归函数有至少与阈值一样大的概率，同时要求该区域在边缘特征分布下的质量尽可能大。这导致了一种自然的遗憾概念，我们的主要贡献是确定了遗憾在样本规模和第一类错误概率上的最优值。这个最优值涉及到样本大小和类型I错误概率的微妙相互影响。

    In clinical trials and other applications, we often see regions of the feature space that appear to exhibit interesting behaviour, but it is unclear whether these observed phenomena are reflected at the population level. Focusing on a regression setting, we consider the subgroup selection challenge of identifying a region of the feature space on which the regression function exceeds a pre-determined threshold. We formulate the problem as one of constrained optimisation, where we seek a low-complexity, data-dependent selection set on which, with a guaranteed probability, the regression function is uniformly at least as large as the threshold; subject to this constraint, we would like the region to contain as much mass under the marginal feature distribution as possible. This leads to a natural notion of regret, and our main contribution is to determine the minimax optimal rate for this regret in both the sample size and the Type I error probability. The rate involves a delicate interpla
    
[^27]: 深度模仿学习的实用视角

    A Pragmatic Look at Deep Imitation Learning. (arXiv:2108.01867v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.01867](http://arxiv.org/abs/2108.01867)

    本文在深度模仿学习领域以实际的视角进行了研究，重新实现了6种不同的模仿学习算法，并使用共同的离线策略算法进行了评估。通过对专家轨迹数据进行测试，比较了这些算法的性能。

    

    生成对抗模仿学习（GAIL）算法的引入推动了使用深度神经网络进行可扩展模仿学习方法的发展。许多后续算法使用了类似的过程，将在线策略演员-评论家算法与逆向强化学习相结合。最近出现了更多种类的方法，大多数使用离线策略算法。然而，由于算法的广泛性，从数据集到基础强化学习算法再到评估设置都可能有所变化，这使得公正比较它们变得困难。在这项工作中，我们重新实现了6种不同的模仿学习算法，将其中3种更新为离线策略，将它们基于一个常用的离线策略算法（SAC），并在一个广泛使用的专家轨迹数据集（D4RL）上对它们进行评估，以进行最常见的基准测试（MuJoCo）。在给所有算法相同的超参数优化预算之后，我们比较了它们在一系列专家轨迹测试上的结果。

    The introduction of the generative adversarial imitation learning (GAIL) algorithm has spurred the development of scalable imitation learning approaches using deep neural networks. Many of the algorithms that followed used a similar procedure, combining on-policy actor-critic algorithms with inverse reinforcement learning. More recently there have been an even larger breadth of approaches, most of which use off-policy algorithms. However, with the breadth of algorithms, everything from datasets to base reinforcement learning algorithms to evaluation settings can vary, making it difficult to fairly compare them. In this work we re-implement 6 different IL algorithms, updating 3 of them to be off-policy, base them on a common off-policy algorithm (SAC), and evaluate them on a widely-used expert trajectory dataset (D4RL) for the most common benchmark (MuJoCo). After giving all algorithms the same hyperparameter optimisation budget, we compare their results for a range of expert trajectori
    
[^28]: 随机批量获取：深度主动学习的简单基准方法

    Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning. (arXiv:2106.12059v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.12059](http://arxiv.org/abs/2106.12059)

    研究了一种简单的随机策略，用于将单点获取函数适应于批量主动学习，与计算密集型的批量采集函数相比，性能相当，但使用的计算资源更少。

    

    本文研究了一种简单的随机策略，用于将众所周知的单点获取函数适应于批量主动学习。与从池集合中获取前K个点不同，基于分数或排名的采样考虑到获取数据后采集分数的变化。这种简单的策略可以与计算密集型的最新批量采集函数（如BatchBALD或BADGE）一样表现出色，并且使用的计算资源数量级较少。除了为机器学习从业者提供了一个实用选项外，在各种实验环境中提出的方法的意外成功还为这个领域提出了一个困难的问题：这些昂贵的批量采集方法何时才能发挥作用？

    We examine a simple stochastic strategy for adapting well-known single-point acquisition functions to allow batch active learning. Unlike acquiring the top-K points from the pool set, score- or rank-based sampling takes into account that acquisition scores change as new data are acquired. This simple strategy for adapting standard single-sample acquisition strategies can even perform just as well as compute-intensive state-of-the-art batch acquisition functions, like BatchBALD or BADGE, while using orders of magnitude less compute. In addition to providing a practical option for machine learning practitioners, the surprising success of the proposed method in a wide range of experimental settings raises a difficult question for the field: when are these expensive batch acquisition methods pulling their weight?
    
[^29]: 衡量视觉观察到的子群差异的证据强度的方法

    Measure of Strength of Evidence for Visually Observed Differences between Subpopulations. (arXiv:2101.00362v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2101.00362](http://arxiv.org/abs/2101.00362)

    本文介绍了一种衡量视觉观察到的子群差异的证据强度的方法，并提出了"人群差异准则"来评估其统计显著性。研究发现在高维和高信号环境下，传统方法存在局限性，因此提出了新的平衡置换方法和自助法置信区间来解决这些问题。在现代癌症数据的比较中，这些方法展示出了实用性和有效性。

    

    为了衡量视觉上观察到的子群差异的强度，提出了“人群差异准则”来评估视觉上观察到的子群差异的统计显著性。它解决了以下挑战：在高维环境中，分布模型可能是可疑的；在高信号环境中，传统的置换检验在配对比较方面效果不佳。我们还做出了两项其他贡献：基于仔细的分析，我们发现在高信号环境中，平衡的置换方法比传统的置换方法更强大。另一个贡献是通过自助法置换变化的不确定性进行量化，得到一个自助法置信区间。这些想法的实用性在对现代癌症数据的子群比较中得到了说明。

    For measuring the strength of visually-observed subpopulation differences, the Population Difference Criterion is proposed to assess the statistical significance of visually observed subpopulation differences. It addresses the following challenges: in high-dimensional contexts, distributional models can be dubious; in high-signal contexts, conventional permutation tests give poor pairwise comparisons. We also make two other contributions: Based on a careful analysis we find that a balanced permutation approach is more powerful in high-signal contexts than conventional permutations. Another contribution is the quantification of uncertainty due to permutation variation via a bootstrap confidence interval. The practical usefulness of these ideas is illustrated in the comparison of subpopulations of modern cancer data.
    
[^30]: 在错配情况下的分类：半空间、广义线性模型和与可进化性的联系

    Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Connections to Evolvability. (arXiv:2006.04787v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.04787](http://arxiv.org/abs/2006.04787)

    本文解决了半空间在Massart噪声下的错配学习问题，提出了一个简化的算法并回答了一些开放问题。通过黑盒知识蒸馏过程，将复杂分类器转换为同样好的合适分类器。此外，我们还提出了一个小样本的合适学习算法，并将其与矩感知技术相结合，得到了一个具有多项式时间复杂性的学习算法。

    

    本文重新审视了一些关于错配情况下的分类的经典问题。特别是，我们研究了在Massart噪声下以速率$\eta$学习半空间的问题。在最近的一项工作中，Diakonikolas、Goulekakis和Tzamos通过提供第一个有效的算法来解决了一个长期存在的问题，该算法可以学习到准确度$\eta + \epsilon$，其中$\epsilon > 0$。然而，他们的算法输出了一个复杂的假设，将空间分割为$\text{poly}(d,1/\epsilon)$个区域。这里我们给出了一个更简单的算法，并在此过程中解决了一些悬而未决的开放问题：(1)我们提供了第一个可以实现$\eta + \epsilon$的Massart半空间合适学习器。我们还给出了多项式时间算法可以实现的样本复杂性的改进界限。(2)基于(1)，我们开发了一个黑盒知识蒸馏过程，将任意复杂的分类器转换为同样好的合适的分类器。(3)通过利用一个简单但被忽视的机制，我们在没有任何额外假设的情况下，构造了一个小样本的合适学习算法，并将其与基于矩感知的技术相结合，得到一个具有多项式时间复杂性的学习算法。

    In this paper we revisit some classic problems on classification under misspecification. In particular, we study the problem of learning halfspaces under Massart noise with rate $\eta$. In a recent work, Diakonikolas, Goulekakis, and Tzamos resolved a long-standing problem by giving the first efficient algorithm for learning to accuracy $\eta + \epsilon$ for any $\epsilon > 0$. However, their algorithm outputs a complicated hypothesis, which partitions space into $\text{poly}(d,1/\epsilon)$ regions. Here we give a much simpler algorithm and in the process resolve a number of outstanding open questions:  (1) We give the first proper learner for Massart halfspaces that achieves $\eta + \epsilon$. We also give improved bounds on the sample complexity achievable by polynomial time algorithms.  (2) Based on (1), we develop a blackbox knowledge distillation procedure to convert an arbitrarily complex classifier to an equally good proper classifier.  (3) By leveraging a simple but overlooked 
    
[^31]: 关于实体对齐或链接预测方法排名评估的歧义性研究

    On the Ambiguity of Rank-Based Evaluation of Entity Alignment or Link Prediction Methods. (arXiv:2002.06914v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2002.06914](http://arxiv.org/abs/2002.06914)

    本研究研究了实体对齐或链接预测方法的排名评估的歧义性。分析了当前评估指标的不足之处，提出了评估方法的调整，以实现对模型性能的公平、可比和可解释的评估。

    

    本研究针对两种从知识图谱中增强信息的方法：链接预测和实体对齐，对其评估方法进行了深入研究。当前实验设置中，采用多个不同的评估指标来评估模型性能的不同方面。我们分析了这些评估指标的信息性，并发现了一些问题。特别地，我们证明了所有现有的评估指标几乎不能用于在不同数据集之间比较结果。此外，我们还证明了测试集大小的变化会对相同模型的性能产生影响，这是基于实体对齐任务常用度量标准的结果。我们展示了这导致了结果解释上的各种问题，可能支持误导性的结论。因此，我们提出了对评估方法的调整，并通过实验证明了如何实现对模型性能的公平、可比和可解释的评估。我们的代码可供使用。

    In this work, we take a closer look at the evaluation of two families of methods for enriching information from knowledge graphs: Link Prediction and Entity Alignment. In the current experimental setting, multiple different scores are employed to assess different aspects of model performance. We analyze the informativeness of these evaluation measures and identify several shortcomings. In particular, we demonstrate that all existing scores can hardly be used to compare results across different datasets. Moreover, we demonstrate that varying size of the test size automatically has impact on the performance of the same model based on commonly used metrics for the Entity Alignment task. We show that this leads to various problems in the interpretation of results, which may support misleading conclusions. Therefore, we propose adjustments to the evaluation and demonstrate empirically how this supports a fair, comparable, and interpretable assessment of model performance. Our code is availa
    

