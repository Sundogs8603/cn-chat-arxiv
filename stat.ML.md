# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Choosing a Proxy Metric from Past Experiments.](http://arxiv.org/abs/2309.07893) | 本文介绍了一种新的统计框架，用于在同质种群的随机实验中选择最优的代理指标。该方法通过投资组合优化问题将最优代理指标的构建进行了归约，并对观察到的治疗效果进行了降噪处理。 |
| [^2] | [Scalable Model-Based Gaussian Process Clustering.](http://arxiv.org/abs/2309.07882) | 本论文提出了一种可扩展的基于模型的高斯过程聚类方法，通过在聚类任务中引入Vecchia逼近方法，提供了关键的理论支持，并开发了一个高效的EM算法，通过模拟和分析验证了其实用性。 |
| [^3] | [Beta Diffusion.](http://arxiv.org/abs/2309.07867) | beta扩散是一种新型生成模型方法，通过引入去掩盖和去噪的技术，利用缩放和偏移的beta分布进行乘法转换，实现在有界范围内生成数据。相比于传统的基于扩散的生成模型，它通过KL散度上界进行优化，证明了效果更好。 |
| [^4] | [Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression.](http://arxiv.org/abs/2309.07810) | 这项研究介绍了一种新的去偏方法框架，用于解决高维线性回归中现有技术对协变量分布的限制问题。研究者们发现，现有方法在处理非高斯分布、异质性设计矩阵和缺乏可靠特征协方差估计时遇到困难。为了解决这些问题，他们提出了一种新的策略，该策略利用缩放的梯度下降步骤进行去偏校正。 |
| [^5] | [Convergence analysis of online algorithms for vector-valued kernel regression.](http://arxiv.org/abs/2309.07779) | 本文考虑了在线学习算法在向量值内核回归问题中的收敛性能，证明了在RKHS范数中的期望平方误差可以被一个特定公式所限制。 |
| [^6] | [Causal Entropy and Information Gain for Measuring Causal Control.](http://arxiv.org/abs/2309.07703) | 本文提出了一种考虑因果结构的信息论量，用于评估某个特定结果变量的因果重要性，解决了因果可解释性的挑战。 |
| [^7] | [Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning.](http://arxiv.org/abs/2309.07666) | 本文介绍了一个新问题，称为多源领域适应通过数据集字典学习遇见数据集蒸馏（MSDA-DD），通过适应先前的方法以及分配匹配方法，我们实现了仅使用每类1个样本即可实现最先进的适应性能。 |
| [^8] | [Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE.](http://arxiv.org/abs/2309.07663) | 本文通过分析在高维限制下的最简化的VAE，提出了一个闭式表达式，评估了beta与VAE中数据集大小、后验坍缩和率失真曲线之间的关系。结果显示，随着beta的增加，产生较大的广义误差平台，并且选择一个小于特定阈值的beta值可以提高模型性能。 |
| [^9] | [Statistically Valid Variable Importance Assessment through Conditional Permutations.](http://arxiv.org/abs/2309.07593) | 本论文提出了一种通过条件置换进行统计有效的变量重要性评估的方法。实证结果表明，这种方法克服了标准置换重要性的局限性，并在深度神经网络中表现出最高的准确性。 |
| [^10] | [SC-MAD: Mixtures of Higher-order Networks for Data Augmentation.](http://arxiv.org/abs/2309.07453) | 本论文提出了一种名为SC-MAD的方法，利用混合高阶网络对数据进行增强。通过线性和非线性混合机制返回现有标记样本的混合物，以及一种凸聚类混合方法用于描述多个复形复杂网络之间的数据驱动关系。这种方法在复形复杂分类中表现出良好的性能。 |
| [^11] | [A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time.](http://arxiv.org/abs/2309.07418) | 在本文中，我们使用张量和SVM Trick重新构建了单层LLM注意力机制，并提供了对应的优化视角。我们的工作可以在矩阵乘法时间内解决注意力回归问题。 |
| [^12] | [Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining.](http://arxiv.org/abs/2309.07332) | 创新点：提出了一种基于可靠性的训练数据清洗方法，利用归纳性符合预测来纠正噪声训练数据中的错误标记和异常值。该方法在多个分类任务中验证有效性，并显著提升了分类性能。 |
| [^13] | [Simultaneous inference for generalized linear models with unmeasured confounders.](http://arxiv.org/abs/2309.07261) | 本文研究了存在混淆效应时的广义线性模型的大规模假设检验问题，并提出了一种利用正交结构和线性投影的统计估计和推断框架，解决了由于未测混淆因素引起的偏差问题。 |
| [^14] | [All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks.](http://arxiv.org/abs/2309.07250) | 本文提出使用自旋网络构建SU(2)等价量子电路，通过编码群结构来限制优化空间， 具有旋转对称性，比其他已知的构造更直接实现在量子硬件上。 |
| [^15] | [Optimal and Fair Encouragement Policy Evaluation and Learning.](http://arxiv.org/abs/2309.07176) | 本研究探讨了在关键领域中针对鼓励政策的最优和公平评估以及学习的问题，研究发现在人类不遵循治疗建议的情况下，最优策略规则只是建议。同时，针对治疗的异质性和公平考虑因素，决策者的权衡和决策规则也会发生变化。在社会服务领域，研究显示存在一个使用差距问题，那些最有可能受益的人却无法获得这些益服务。 |
| [^16] | [Physics-informed Bayesian inference of external potentials in classical density-functional theory.](http://arxiv.org/abs/2309.07065) | 这项研究将物理信息与贝叶斯推断方法相结合，提出了一种统计学习框架，用于推断经典密度泛函理论中多粒子系统的外部势能。该框架在具有排除体积相互作用的受限几何中进行了实验证明。 |
| [^17] | [Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense.](http://arxiv.org/abs/2309.06724) | 该论文提出了一种使用深度非参数凸化滤波（DNCF）的通用框架，用于计算摄影领域中的图像恢复。DNCF具有强大的泛化性和对抗性图像处理的鲁棒性，同时能够实现实时的对抗性图像分类网络防御。 |
| [^18] | [Learning nonparametric DAGs with incremental information via high-order HSIC.](http://arxiv.org/abs/2308.05969) | 本文提出了一个基于高阶HSIC的方法，在学习Bayesian网络中解决了局部变量同时具有直接和间接依赖关系的问题，通过确定子集和两阶段算法来进行局部修正，取得了良好的效果。 |
| [^19] | [Trajectory-oriented optimization of stochastic epidemiological models.](http://arxiv.org/abs/2305.03926) | 本论文提出了一个基于轨迹的优化方法来处理随机流行病学模型，可以找到与实际观测值接近的实际轨迹，而不是仅使平均模拟结果与实测数据相符。 |
| [^20] | [Fixed points of arbitrarily deep 1-dimensional neural networks.](http://arxiv.org/abs/2303.12814) | 本研究发现，具有对数S型激活函数的任意深度的一维神经网络最多只有三个不动点，为深度神经网络的应用和理论之间构建了一个必要的桥梁。 |
| [^21] | [Kernel Conditional Moment Constraints for Confounding Robust Inference.](http://arxiv.org/abs/2302.13348) | 本文提出了一种应对混淆因素的核条件矩约束方法，通过利用核方法得到的条件矩约束的近似估计器，实现了对政策评估的尖锐下界估计，并能对经典边际敏感度模型进行新颖扩展。 |
| [^22] | [Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks.](http://arxiv.org/abs/2302.07260) | 本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。 |
| [^23] | [On a continuous time model of gradient descent dynamics and instability in deep learning.](http://arxiv.org/abs/2302.01952) | 本文提出了一个连续时间流模型——主要流（PF），通过对Hessian矩阵特征分解的依赖，捕捉到了梯度下降中的发散和振荡行为、逃逸局部极小值和鞍点的连续性流，并解释了深度学习中的稳定边缘现象。通过对不稳定性的新理解，提出了一种学习率适应方法，可以控制训练稳定性和测试集评估性能之间的权衡。 |
| [^24] | [Gaussian Process Surrogate Models for Neural Networks.](http://arxiv.org/abs/2208.06028) | 通过利用高斯过程构建神经网络的代理模型，我们解决了深度学习系统行为预测和架构算法选择的问题，并展示了模型在捕捉现象、确定关键数据点和预测泛化能力方面的实际应用价值。 |
| [^25] | [Random Feature Amplification: Feature Learning and Generalization in Neural Networks.](http://arxiv.org/abs/2202.07626) | 本文通过分析在随机初始化后通过逻辑损失函数进行梯度下降训练的两层ReLU网络在特征学习过程中的表征，证明了对于具有二元标签的由XOR-like函数生成的数据，尽管线性分类器在该分布上无法更好地工作，但该网络的泛化误差接近于标签噪声率。通过一种新颖的证明技巧，揭示了初始化时大多数神经元作为随机特征，随后通过梯度下降动力学将这些弱的随机特征放大为有用的特征。 |
| [^26] | [Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data.](http://arxiv.org/abs/2202.05928) | 本文研究了使用梯度下降训练的神经网络在泛化时能够很好应对噪声数据的良性过拟合现象。研究表明，在特定条件下，神经网络能够将训练误差降至零并完美地适应带有噪声标签的数据，并同时达到最优的测试误差。 |
| [^27] | [Speeding up Learning Quantum States through Group Equivariant Convolutional Quantum Ans\"atze.](http://arxiv.org/abs/2112.07611) | 通过建立$S_n$-等变卷积量子Ansatze，我们证明了其能够在具有SU($d$)对称性的广泛量子机器学习问题中生成任意幺正矩阵，同时验证了4-local SU($d$)对称幺正矩阵的可实现性。 |
| [^28] | [Joint Community Detection and Rotational Synchronization via Semidefinite Programming.](http://arxiv.org/abs/2105.06031) | 本文提出了一种通过半定规划来联合社区检测和旋转同步的方法，在存在异构数据的情况下，能够准确恢复出旋转和聚类身份，并通过数值实验证明了其有效性和准确恢复性的相变现象。 |
| [^29] | [Survival Estimation for Missing not at Random Censoring Indicators based on Copula Models.](http://arxiv.org/abs/2009.01726) | 本论文提出了一种基于Copula模型的新的估计器，用于处理缺失非随机截尾指标下的条件生存函数估计问题。通过模拟实验和真实数据分析，我们验证了该估计器的实用性。 |
| [^30] | [On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems.](http://arxiv.org/abs/1906.00331) | 该论文提出了一种用于解决非凸-凹极小极大问题的梯度下降算法，并进行了复杂性分析，证明了该算法可以高效地找到函数的稳定点。该研究对于非凸-凹极小极大问题的非渐进分析是首次进行的。 |

# 详细

[^1]: 从过去的实验中选择代理指标

    Choosing a Proxy Metric from Past Experiments. (arXiv:2309.07893v1 [stat.ME])

    [http://arxiv.org/abs/2309.07893](http://arxiv.org/abs/2309.07893)

    本文介绍了一种新的统计框架，用于在同质种群的随机实验中选择最优的代理指标。该方法通过投资组合优化问题将最优代理指标的构建进行了归约，并对观察到的治疗效果进行了降噪处理。

    

    在许多随机实验中，往往很难或不可行地测量长期指标（即感兴趣的主要结果）。这些长期指标往往反应变化较慢，且噪声较大，使得在短期实验中难以准确估计。一种常见的替代方法是测量几个短期代理指标，希望它们能够紧密追踪长期指标，从而在近期有效地指导决策。我们引入了一个新的统计框架，用于定义和构建一个适用于同质种群随机实验的最优代理指标。我们的方法首先将给定实验中最优代理指标的构建归约为一个投资组合优化问题，该问题取决于考虑中实验的真实潜在治疗效果和噪声水平。然后我们对长期指标和一组代理的观察到的治疗效果进行降噪处理。

    In many randomized experiments, the treatment effect of the long-term metric (i.e. the primary outcome of interest) is often difficult or infeasible to measure. Such long-term metrics are often slow to react to changes and sufficiently noisy they are challenging to faithfully estimate in short-horizon experiments. A common alternative is to measure several short-term proxy metrics in the hope they closely track the long-term metric -- so they can be used to effectively guide decision-making in the near-term. We introduce a new statistical framework to both define and construct an optimal proxy metric for use in a homogeneous population of randomized experiments. Our procedure first reduces the construction of an optimal proxy metric in a given experiment to a portfolio optimization problem which depends on the true latent treatment effects and noise level of experiment under consideration. We then denoise the observed treatment effects of the long-term metric and a set of proxies in a 
    
[^2]: 可扩展的基于模型的高斯过程聚类

    Scalable Model-Based Gaussian Process Clustering. (arXiv:2309.07882v1 [stat.CO])

    [http://arxiv.org/abs/2309.07882](http://arxiv.org/abs/2309.07882)

    本论文提出了一种可扩展的基于模型的高斯过程聚类方法，通过在聚类任务中引入Vecchia逼近方法，提供了关键的理论支持，并开发了一个高效的EM算法，通过模拟和分析验证了其实用性。

    

    高斯过程在聚类功能数据中是不可或缺的工具，因其灵活性和内在的不确定性量化。然而，当功能数据在一个大的网格上观测到时（比如长度为p），高斯过程聚类很快变得不可行，每次迭代的空间复杂度为O（p^2）和时间复杂度为O(p^3)；因此，阻碍了其在大型环境应用中的自然适应性。为了确保在这些应用中高斯过程聚类的可扩展性，我们提出将广泛采用的Vecchia逼近方法嵌入到聚类任务的核心，提供对算法设计的关键理论洞见，最终开发出计算效率高的期望最大化（EM）算法。通过模拟和极地温度异常分析，我们提供了我们的提案的实证证据。

    Gaussian process is an indispensable tool in clustering functional data, owing to it's flexibility and inherent uncertainty quantification. However, when the functional data is observed over a large grid (say, of length $p$), Gaussian process clustering quickly renders itself infeasible, incurring $O(p^2)$ space complexity and $O(p^3)$ time complexity per iteration; and thus prohibiting it's natural adaptation to large environmental applications. To ensure scalability of Gaussian process clustering in such applications, we propose to embed the popular Vecchia approximation for Gaussian processes at the heart of the clustering task, provide crucial theoretical insights towards algorithmic design, and finally develop a computationally efficient expectation maximization (EM) algorithm. Empirical evidence of the utility of our proposal is provided via simulations and analysis of polar temperature anomaly (\href{https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/global/time-ser
    
[^3]: Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])

    Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])

    [http://arxiv.org/abs/2309.07867](http://arxiv.org/abs/2309.07867)

    beta扩散是一种新型生成模型方法，通过引入去掩盖和去噪的技术，利用缩放和偏移的beta分布进行乘法转换，实现在有界范围内生成数据。相比于传统的基于扩散的生成模型，它通过KL散度上界进行优化，证明了效果更好。

    

    我们引入了beta扩散，一种将去掩盖和去噪集成到一起的新型生成建模方法，用于在有界范围内生成数据。使用了缩放和偏移的beta分布，beta扩散利用了随时间的乘法转换来创建正向和反向的扩散过程，同时维持着正向边缘分布和反向条件分布，给定任意时间点的数据。与传统的基于扩散的生成模型不同，传统模型依赖于加性高斯噪声和重新加权的证据下界（ELBO），beta扩散是乘法的，并且通过从KL散度的凸性推导出来的KL散度上界（KLUB）进行优化。我们证明了所提出的KLUB相对于负ELBO来说对于优化beta扩散更加有效，负ELBO也可以作为相同KL散度的KLUB，只是其两个参数交换了位置。beta扩散的损失函数以Bregman散度为指标来表示。

    We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, furt
    
[^4]: Spectrum-Aware Adjustment: 一种新的去偏方法框架及其在主成分回归中的应用

    Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])

    [http://arxiv.org/abs/2309.07810](http://arxiv.org/abs/2309.07810)

    这项研究介绍了一种新的去偏方法框架，用于解决高维线性回归中现有技术对协变量分布的限制问题。研究者们发现，现有方法在处理非高斯分布、异质性设计矩阵和缺乏可靠特征协方差估计时遇到困难。为了解决这些问题，他们提出了一种新的策略，该策略利用缩放的梯度下降步骤进行去偏校正。

    

    我们引入了一个新的去偏方法框架，用于解决高维线性回归中现代去偏技术对协变量分布的约束问题。我们研究了特征数和样本数都很大且相近的普遍情况。在这种情况下，现代去偏技术使用自由度校正来除去正则化估计量的收缩偏差并进行推断。然而，该方法要求观测样本是独立同分布的，协变量遵循均值为零的高斯分布，并且能够获得可靠的特征协方差矩阵估计。当（i）协变量具有非高斯分布、重尾或非对称分布，（ii）设计矩阵的行呈异质性或存在依赖性，以及（iii）缺乏可靠的特征协方差估计时，这种方法就会遇到困难。为了应对这些问题，我们提出了一种新的策略，其中去偏校正是一步缩放的梯度下降步骤（适当缩放）。

    We introduce a new debiasing framework for high-dimensional linear regression that bypasses the restrictions on covariate distributions imposed by modern debiasing technology. We study the prevalent setting where the number of features and samples are both large and comparable. In this context, state-of-the-art debiasing technology uses a degrees-of-freedom correction to remove shrinkage bias of regularized estimators and conduct inference. However, this method requires that the observed samples are i.i.d., the covariates follow a mean zero Gaussian distribution, and reliable covariance matrix estimates for observed features are available. This approach struggles when (i) covariates are non-Gaussian with heavy tails or asymmetric distributions, (ii) rows of the design exhibit heterogeneity or dependencies, and (iii) reliable feature covariance estimates are lacking.  To address these, we develop a new strategy where the debiasing correction is a rescaled gradient descent step (suitably
    
[^5]: 在向量值内核回归的在线算法的收敛分析

    Convergence analysis of online algorithms for vector-valued kernel regression. (arXiv:2309.07779v1 [stat.ML])

    [http://arxiv.org/abs/2309.07779](http://arxiv.org/abs/2309.07779)

    本文考虑了在线学习算法在向量值内核回归问题中的收敛性能，证明了在RKHS范数中的期望平方误差可以被一个特定公式所限制。

    

    我们考虑使用适当的再生核希尔伯特空间（RKHS）作为先验，通过在线学习算法从噪声向量值数据中逼近回归函数的问题。在在线算法中，独立同分布的样本通过随机过程逐个可用，并依次处理以构建对回归函数的近似。我们关注这种在线逼近算法的渐近性能，并证明了在RKHS范数中的期望平方误差可以被$C^2(m+1)^{-s/(2+s)}$绑定，其中$m$为当下处理的数据数量，参数$0<s\leq 1$表示对回归函数的额外光滑性假设，常数$C$取决于输入噪声的方差、回归函数的光滑性以及算法的其他参数。

    We consider the problem of approximating the regression function from noisy vector-valued data by an online learning algorithm using an appropriate reproducing kernel Hilbert space (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one by a random process and are successively processed to build approximations to the regression function. We are interested in the asymptotic performance of such online approximation algorithms and show that the expected squared error in the RKHS norm can be bounded by $C^2 (m+1)^{-s/(2+s)}$, where $m$ is the current number of processed data, the parameter $0<s\leq 1$ expresses an additional smoothness assumption on the regression function and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function and further parameters of the algorithm.
    
[^6]: 测量因果控制的因果熵和信息增益

    Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])

    [http://arxiv.org/abs/2309.07703](http://arxiv.org/abs/2309.07703)

    本文提出了一种考虑因果结构的信息论量，用于评估某个特定结果变量的因果重要性，解决了因果可解释性的挑战。

    

    人工智能模型和方法通常缺乏因果可解释性。尽管解释性机器学习（IML）方法取得了进展，但它们经常将重要性赋予那些对结果变量没有因果影响的特征。在模型训练之前或之后，选择因果相关的特征将提供一种解决方案。利用信息论量进行特征选择的方法在识别统计相关特征方面非常成功。然而，它们所基于的信息论量不包含因果关系，因此在这种情况下不适用。为了解决这个挑战，本文提出了能够考虑系统因果结构的信息论量，可以用于评估某个给定结果变量的因果重要性。具体来说，我们引入了因果熵和因果互信息的因果版本。

    Artificial intelligence models and methods commonly lack causal interpretability. Despite the advancements in interpretable machine learning (IML) methods, they frequently assign importance to features which lack causal influence on the outcome variable. Selecting causally relevant features among those identified as relevant by these methods, or even before model training, would offer a solution. Feature selection methods utilizing information theoretical quantities have been successful in identifying statistically relevant features. However, the information theoretical quantities they are based on do not incorporate causality, rendering them unsuitable for such scenarios. To address this challenge, this article proposes information theoretical quantities that incorporate the causal structure of the system, which can be used to evaluate causal importance of features for some given outcome variable. Specifically, we introduce causal versions of entropy and mutual information, termed cau
    
[^7]: 多源领域适应通过数据集字典学习遇见数据集蒸馏

    Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning. (arXiv:2309.07666v1 [cs.LG])

    [http://arxiv.org/abs/2309.07666](http://arxiv.org/abs/2309.07666)

    本文介绍了一个新问题，称为多源领域适应通过数据集字典学习遇见数据集蒸馏（MSDA-DD），通过适应先前的方法以及分配匹配方法，我们实现了仅使用每类1个样本即可实现最先进的适应性能。

    

    本文考虑了机器学习中两个问题的交集：多源领域适应（MSDA）和数据集蒸馏（DD）。一方面，前者考虑了将多个异质的标注源领域适应到一个未标注的目标领域。另一方面，后者攻击了关于合成一个包含有关数据集的所有信息的小摘要的问题。因此，我们提出了一个新问题称为MSDA-DD。为了解决这个问题，我们适应了MSDA文献中的先前作品，如Wasserstein Barycenter Transport和数据集字典学习，以及DD方法Distribution Matching。我们在四个基准测试集上对这个新问题进行了彻底的实验（Caltech-Office 10， Tennessee-Eastman Process， Continuous Stirred Tank Reactor和Case Western Reserve University），在这些实验中，我们展示了即使每类只有1个样本，我们也达到了最先进的适应性能。

    In this paper, we consider the intersection of two problems in machine learning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD). On the one hand, the first considers adapting multiple heterogeneous labeled source domains to an unlabeled target domain. On the other hand, the second attacks the problem of synthesizing a small summary containing all the information about the datasets. We thus consider a new problem called MSDA-DD. To solve it, we adapt previous works in the MSDA literature, such as Wasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD method Distribution Matching. We thoroughly experiment with this novel problem on four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous Stirred Tank Reactor, and Case Western Reserve University), where we show that, even with as little as 1 sample per class, one achieves state-of-the-art adaptation performance.
    
[^8]: 线性变分自编码器中数据集大小对率失真曲线和后验坍缩阈值的影响

    Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE. (arXiv:2309.07663v1 [stat.ML])

    [http://arxiv.org/abs/2309.07663](http://arxiv.org/abs/2309.07663)

    本文通过分析在高维限制下的最简化的VAE，提出了一个闭式表达式，评估了beta与VAE中数据集大小、后验坍缩和率失真曲线之间的关系。结果显示，随着beta的增加，产生较大的广义误差平台，并且选择一个小于特定阈值的beta值可以提高模型性能。

    

    在变分自编码器（VAE）中，变分后验经常与先验密切吻合，这被称为后验坍缩，影响了表示学习的质量。为了缓解这个问题，VAE中引入了一个可调节的超参数beta。本文通过在高维限制下分析最简化的VAE，提出了一个闭式表达式，评估了beta与VAE中数据集大小、后验坍缩和率失真曲线之间的关系。这些结果表明，一个较大的beta会产生一个长的广义误差平台。随着beta的增加，平台的长度延长，超过一定的阈值后变为无穷。这意味着与通常的正则化参数不同，beta的选择可能会导致后验坍缩，而与数据集大小无关。因此，beta是一个需要谨慎调整的风险参数。此外，考虑到数据集大小对率失真曲线的依赖性，我们发现存在一个与数据集大小相关的阈值，选择小于这个阈值的beta值可以提高模型的性能。

    In the Variational Autoencoder (VAE), the variational posterior often aligns closely with the prior, which is known as posterior collapse and hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter beta has been introduced in the VAE. This paper presents a closed-form expression to assess the relationship between the beta in VAE, the dataset size, the posterior collapse, and the rate-distortion curve by analyzing a minimal VAE in a high-dimensional limit. These results clarify that a long plateau in the generalization error emerges with a relatively larger beta. As the beta increases, the length of the plateau extends and then becomes infinite beyond a certain beta threshold. This implies that the choice of beta, unlike the usual regularization parameters, can induce posterior collapse regardless of the dataset size. Thus, beta is a risky parameter that requires careful tuning. Furthermore, considering the dataset-size dependence on the ra
    
[^9]: 通过条件置换进行统计有效的变量重要性评估

    Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])

    [http://arxiv.org/abs/2309.07593](http://arxiv.org/abs/2309.07593)

    本论文提出了一种通过条件置换进行统计有效的变量重要性评估的方法。实证结果表明，这种方法克服了标准置换重要性的局限性，并在深度神经网络中表现出最高的准确性。

    

    在使用复杂学习器（如深度神经网络）处理大规模数据时，变量重要性评估已成为机器学习应用中的关键步骤。目前，基于移除的重要性评估是参考方法，特别是在需要统计保证来验证变量包含性时。通常，它们使用变量置换方案来实现。然而，这些方法在存在协变量之间的相关性时容易将不重要的变量误识别为重要变量。本文提出了一种系统方法来研究条件置换重要性（Conditional Permutation Importance，CPI），它是模型无关且计算效率高的方法，并提供了基准测试，用于评估当前最先进的变量重要性估计器。理论和实证结果表明，CPI通过提供准确的I型错误控制，克服了标准置换重要性的局限性。当与深度神经网络一起使用时，CPI始终显示出最高的准确性。

    Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that $\textit{CPI}$ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, $\textit{CPI}$ consistently showed top accuracy ac
    
[^10]: SC-MAD: 混合高阶网络用于数据增强

    SC-MAD: Mixtures of Higher-order Networks for Data Augmentation. (arXiv:2309.07453v1 [stat.ML])

    [http://arxiv.org/abs/2309.07453](http://arxiv.org/abs/2309.07453)

    本论文提出了一种名为SC-MAD的方法，利用混合高阶网络对数据进行增强。通过线性和非线性混合机制返回现有标记样本的混合物，以及一种凸聚类混合方法用于描述多个复形复杂网络之间的数据驱动关系。这种方法在复形复杂分类中表现出良好的性能。

    

    众多复杂系统中存在着多维交互，这促使我们将基于图的成对连接拓展到高阶关系。特别地，复形复杂网络已经启发了基于复形复杂模型的图神经网络的泛化。在这种系统上的学习需要大量的数据，而这些数据可能难以获取或者成本高昂。我们提出了通过线性和非线性混合机制对复形复杂网络进行数据增强的方法，返回现有标记样本的混合物。除了传统的成对混合，我们还提出了一种凸聚类混合方法，用于描述多个复形复杂网络之间的数据驱动关系。我们在理论上证明了生成的合成复形复杂网络在同态密度方面插值了现有数据。我们的方法在合成和真实数据集上进行了复形复杂分类的实证研究。

    The myriad complex systems with multiway interactions motivate the extension of graph-based pairwise connections to higher-order relations. In particular, the simplicial complex has inspired generalizations of graph neural networks (GNNs) to simplicial complex-based models. Learning on such systems requires large amounts of data, which can be expensive or impossible to obtain. We propose data augmentation of simplicial complexes through both linear and nonlinear mixup mechanisms that return mixtures of existing labeled samples. In addition to traditional pairwise mixup, we present a convex clustering mixup approach for a data-driven relationship among several simplicial complexes. We theoretically demonstrate that the resultant synthetic simplicial complexes interpolate among existing data with respect to homomorphism densities. Our method is demonstrated on both synthetic and real-world datasets for simplicial complex classification.
    
[^11]: 在张量和SVM Trick基础上重新构建单层LLM注意力机制，并在矩阵乘法时间内解决它的快速优化视角

    A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time. (arXiv:2309.07418v1 [cs.DS])

    [http://arxiv.org/abs/2309.07418](http://arxiv.org/abs/2309.07418)

    在本文中，我们使用张量和SVM Trick重新构建了单层LLM注意力机制，并提供了对应的优化视角。我们的工作可以在矩阵乘法时间内解决注意力回归问题。

    

    大型语言模型(LLMs)在我们日常生活的各个方面都发挥着重要作用。解决LLMs中的注意力回归是优化LLMs的基本任务。本文致力于为一层注意力网络目标函数 $L(X,Y) = \sum_{j_0 = 1}^n \sum_{i_0 = 1}^d ( \langle \langle \exp( \mathsf{A}_{j_0} x ) , {\bf 1}_n \rangle^{-1} \exp( \mathsf{A}_{j_0} x ), A_{3} Y_{*,i_0} \rangle - b_{j_0,i_0} )^2$ 提供可证明的保证。这里 $\mathsf{A} \in \mathbb{R}^{n^2 \times d^2}$ 是$A_1 \in \mathbb{R}^{n \times d}$ 和 $A_2 \in \mathbb{R}^{n \times d}$ 的Kronecker积。$A_3$ 是$\mathbb{R}^{n \times d}$ 中的一个矩阵，$\mathsf{A}_{j_0} \in \mathbb{R}^{n \times d^2}$ 是$\mathsf{A}$ 的第$j_0$个块。$X, Y \in \mathbb{R}^{d \times d}$ 是我们要学习的变量。$B \in \mathbb{R}^{n \times d}$ 和 $b_{j_0,i_0} \in \mathbb{R}$ 是$B$ 的第$j_0$行和第$i_0$列的一个元素，$Y_{*,i_0} \in \mathbb{R}^d$ 是$Y$ 的第$i_0$列。

    Large language models (LLMs) have played a pivotal role in revolutionizing various facets of our daily existence. Solving attention regression is a fundamental task in optimizing LLMs. In this work, we focus on giving a provable guarantee for the one-layer attention network objective function $L(X,Y) = \sum_{j_0 = 1}^n \sum_{i_0 = 1}^d ( \langle \langle \exp( \mathsf{A}_{j_0} x ) , {\bf 1}_n \rangle^{-1} \exp( \mathsf{A}_{j_0} x ), A_{3} Y_{*,i_0} \rangle - b_{j_0,i_0} )^2$. Here $\mathsf{A} \in \mathbb{R}^{n^2 \times d^2}$ is Kronecker product between $A_1 \in \mathbb{R}^{n \times d}$ and $A_2 \in \mathbb{R}^{n \times d}$. $A_3$ is a matrix in $\mathbb{R}^{n \times d}$, $\mathsf{A}_{j_0} \in \mathbb{R}^{n \times d^2}$ is the $j_0$-th block of $\mathsf{A}$. The $X, Y \in \mathbb{R}^{d \times d}$ are variables we want to learn. $B \in \mathbb{R}^{n \times d}$ and $b_{j_0,i_0} \in \mathbb{R}$ is one entry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \in \mathbb{R}^d$ is the $i_
    
[^12]: 多模态生物医学数据挖掘中的基于可靠性的噪声训练标签清洗方法与归纳性符合预测

    Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining. (arXiv:2309.07332v1 [cs.LG])

    [http://arxiv.org/abs/2309.07332](http://arxiv.org/abs/2309.07332)

    创新点：提出了一种基于可靠性的训练数据清洗方法，利用归纳性符合预测来纠正噪声训练数据中的错误标记和异常值。该方法在多个分类任务中验证有效性，并显著提升了分类性能。

    

    准确标记生物医学数据是一个挑战。传统的半监督学习方法通常没有充分利用可用的未标记数据。为了解决这个问题，我们提出了一种新的基于可靠性的训练数据清洗方法，采用了归纳性符合预测（ICP）。该方法利用一小部分准确标记的训练数据，并利用ICP计算的可靠性指标来纠正海量噪声训练数据中的错误标记和异常值。该方法的有效性在三个分类任务中得到了验证：使用标题和摘要对药物诱导的肝损伤（DILI）文献进行过滤，通过CT影像学和电子健康记录预测COVID-19患者的重症监护病房（ICU）入院情况，以及使用RNA测序数据对乳腺癌进行亚型分型。通过标签排列引入了不同程度的训练标签噪声。结果显示分类性能显著提升：准确度提高

    Accurately labeling biomedical data presents a challenge. Traditional semi-supervised learning methods often under-utilize available unlabeled data. To address this, we propose a novel reliability-based training data cleaning method employing inductive conformal prediction (ICP). This method capitalizes on a small set of accurately labeled training data and leverages ICP-calculated reliability metrics to rectify mislabeled data and outliers within vast quantities of noisy training data. The efficacy of the method is validated across three classification tasks within distinct modalities: filtering drug-induced-liver-injury (DILI) literature with title and abstract, predicting ICU admission of COVID-19 patients through CT radiomics and electronic health records, and subtyping breast cancer using RNA-sequencing data. Varying levels of noise to the training labels were introduced through label permutation. Results show significant enhancements in classification performance: accuracy enhanc
    
[^13]: 具有未测混淆因素的广义线性模型的同时推断

    Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])

    [http://arxiv.org/abs/2309.07261](http://arxiv.org/abs/2309.07261)

    本文研究了存在混淆效应时的广义线性模型的大规模假设检验问题，并提出了一种利用正交结构和线性投影的统计估计和推断框架，解决了由于未测混淆因素引起的偏差问题。

    

    在基因组研究中，常常进行成千上万个同时假设检验，以确定差异表达的基因。然而，由于存在未测混淆因素，许多标准统计方法可能存在严重的偏差。本文研究了存在混淆效应时的多元广义线性模型的大规模假设检验问题。在任意混淆机制下，我们提出了一个统一的统计估计和推断方法，利用正交结构并将线性投影整合到三个关键阶段中。首先，利用多元响应变量分离边际和不相关的混淆效应，恢复混淆系数的列空间。随后，利用$\ell_1$正则化进行稀疏性估计，并强加正交性限制于混淆系数，联合估计潜在因子和主要效应。最后，我们结合投影和加权偏差校正步骤。

    Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
    
[^14]: 你所需要的只是旋转：基于自旋网络的SU(2)等价变分量子电路

    All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks. (arXiv:2309.07250v1 [quant-ph])

    [http://arxiv.org/abs/2309.07250](http://arxiv.org/abs/2309.07250)

    本文提出使用自旋网络构建SU(2)等价量子电路，通过编码群结构来限制优化空间， 具有旋转对称性，比其他已知的构造更直接实现在量子硬件上。

    

    变分算法要求将优化空间自然地限制在一个有效的范围内。在几何量子机器学习中，将群结构编码到参数化的量子电路中，将问题的对称性作为归纳偏置来考虑，可以实现这一点。然而，构建这样的电路是有挑战性的，因为尚未出现明确的指导原则。在本文中，我们提出使用自旋网络，一种在群变换下保持不变的有向张量网络形式，来设计SU(2)等价量子电路ansatz - 具有旋转对称性的电路。通过改变使SU(2)群作用块对角化的基础，这些网络为构建参数化等价量子电路提供了一个自然的构建模块。我们证明了我们的构造在数学上等效于其他已知的构造，例如基于交错和广义排列的构造，但在量子硬件上实现更直接。

    Variational algorithms require architectures that naturally constrain the optimisation space to run efficiently. In geometric quantum machine learning, one achieves this by encoding group structure into parameterised quantum circuits to include the symmetries of a problem as an inductive bias. However, constructing such circuits is challenging as a concrete guiding principle has yet to emerge. In this paper, we propose the use of spin networks, a form of directed tensor network invariant under a group transformation, to devise SU(2) equivariant quantum circuit ans\"atze -- circuits possessing spin rotation symmetry. By changing to the basis that block diagonalises SU(2) group action, these networks provide a natural building block for constructing parameterised equivariant quantum circuits. We prove that our construction is mathematically equivalent to other known constructions, such as those based on twirling and generalised permutations, but more direct to implement on quantum hardwa
    
[^15]: 最优和公平的鼓励政策评估与学习

    Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])

    [http://arxiv.org/abs/2309.07176](http://arxiv.org/abs/2309.07176)

    本研究探讨了在关键领域中针对鼓励政策的最优和公平评估以及学习的问题，研究发现在人类不遵循治疗建议的情况下，最优策略规则只是建议。同时，针对治疗的异质性和公平考虑因素，决策者的权衡和决策规则也会发生变化。在社会服务领域，研究显示存在一个使用差距问题，那些最有可能受益的人却无法获得这些益服务。

    

    在关键领域中，强制个体接受治疗通常是不可能的，因此在人类不遵循治疗建议的情况下，最优策略规则只是建议。在这些领域中，接受治疗的个体可能存在异质性，治疗效果也可能存在异质性。虽然最优治疗规则可以最大化整个人群的因果结果，但在鼓励的情况下，对于访问平等限制或其他公平考虑因素可能是相关的。例如，在社会服务领域，一个持久的难题是那些最有可能从中受益的人中那些获益服务的使用差距。当决策者对访问和平均结果都有分配偏好时，最优决策规则会发生变化。我们研究了因果识别、统计方差减少估计和稳健估计的最优治疗规则，包括在违反阳性条件的情况下。

    In consequential domains, it is often impossible to compel individuals to take treatment, so that optimal policy rules are merely suggestions in the presence of human non-adherence to treatment recommendations. In these same domains, there may be heterogeneity both in who responds in taking-up treatment, and heterogeneity in treatment efficacy. While optimal treatment rules can maximize causal outcomes across the population, access parity constraints or other fairness considerations can be relevant in the case of encouragement. For example, in social services, a persistent puzzle is the gap in take-up of beneficial services among those who may benefit from them the most. When in addition the decision-maker has distributional preferences over both access and average outcomes, the optimal decision rule changes. We study causal identification, statistical variance-reduced estimation, and robust estimation of optimal treatment rules, including under potential violations of positivity. We c
    
[^16]: 经典密度泛函理论中基于物理信息的贝叶斯推断外部势能

    Physics-informed Bayesian inference of external potentials in classical density-functional theory. (arXiv:2309.07065v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2309.07065](http://arxiv.org/abs/2309.07065)

    这项研究将物理信息与贝叶斯推断方法相结合，提出了一种统计学习框架，用于推断经典密度泛函理论中多粒子系统的外部势能。该框架在具有排除体积相互作用的受限几何中进行了实验证明。

    

    机器学习技术在统计力学领域中已经取得了快速发展。机器学习技术吸引了经典密度泛函理论（DFT）社区的注意，因为它们能够发现自由能泛函，以确定多粒子系统的平衡密度分布。在DFT中，外部势能考虑了多粒子系统与外部场的相互作用，从而影响密度分布。在这个背景下，我们引入了一种统计学习框架，用于推断作用于多粒子系统的外部势能。我们将贝叶斯推断方法与经典的DFT工具结合起来，重构外部势能，得到具有内在不确定性量化的外部势能的概率描述形式。我们的框架以在受限几何中具有排除体积相互作用的巨正则一维粒子集合为例进行了说明。

    The swift progression of machine learning (ML) have not gone unnoticed in the realm of statistical mechanics. ML techniques have attracted attention by the classical density-functional theory (DFT) community, as they enable discovery of free-energy functionals to determine the equilibrium-density profile of a many-particle system. Within DFT, the external potential accounts for the interaction of the many-particle system with an external field, thus, affecting the density distribution. In this context, we introduce a statistical-learning framework to infer the external potential exerted on a many-particle system. We combine a Bayesian inference approach with the classical DFT apparatus to reconstruct the external potential, yielding a probabilistic description of the external potential functional form with inherent uncertainty quantification. Our framework is exemplified with a grand-canonical one-dimensional particle ensemble with excluded volume interactions in a confined geometry. T
    
[^17]: 深度非参数凸化滤波在计算摄影，图像合成和对抗性防御中的应用

    Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense. (arXiv:2309.06724v1 [cs.CV])

    [http://arxiv.org/abs/2309.06724](http://arxiv.org/abs/2309.06724)

    该论文提出了一种使用深度非参数凸化滤波（DNCF）的通用框架，用于计算摄影领域中的图像恢复。DNCF具有强大的泛化性和对抗性图像处理的鲁棒性，同时能够实现实时的对抗性图像分类网络防御。

    

    我们旨在提供一个通用框架，用于从不完美的图像中恢复真实场景的计算摄影，通过深度非参数凸化滤波（DNCF）。它由一个非参数深度网络组成，以模拟图像形成背后的物理方程，如降噪、超分辨率、修复和闪光。DNCF没有依赖于训练数据的参数化，因此具有强大的泛化性和对抗性图像处理的鲁棒性。在推理过程中，我们还鼓励网络参数为非负，并在输入和参数上创建一个双凸函数，这适应于运行时间不足的二阶优化算法，相对于Deep Image Prior有10倍的加速。通过这些工具，我们在实时中实验证明了其对抗图像分类深度网络攻击算法的能力。

    We aim to provide a general framework of for computational photography that recovers the real scene from imperfect images, via the Deep Nonparametric Convexified Filtering (DNCF). It is consists of a nonparametric deep network to resemble the physical equations behind the image formation, such as denoising, super-resolution, inpainting, and flash. DNCF has no parameterization dependent on training data, therefore has a strong generalization and robustness to adversarial image manipulation. During inference, we also encourage the network parameters to be nonnegative and create a bi-convex function on the input and parameters, and this adapts to second-order optimization algorithms with insufficient running time, having 10X acceleration over Deep Image Prior. With these tools, we empirically verify its capability to defend image classification deep networks against adversary attack algorithms in real-time.
    
[^18]: 通过高阶HSIC学习具有增量信息的非参数DAGs

    Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v1 [cs.LG])

    [http://arxiv.org/abs/2308.05969](http://arxiv.org/abs/2308.05969)

    本文提出了一个基于高阶HSIC的方法，在学习Bayesian网络中解决了局部变量同时具有直接和间接依赖关系的问题，通过确定子集和两阶段算法来进行局部修正，取得了良好的效果。

    

    针对学习贝叶斯网络（BN）的基于评分的方法，目标是最大化全局评分函数。然而，如果局部变量同时具有直接和间接依赖关系，那么基于评分函数的全局优化将忽略具有间接依赖关系的变量之间的边缘，其得分小于具有直接依赖关系的边缘。本文提出了一个基于确定子集的可辨识性条件，以识别潜在的DAG。通过可辨识性条件，我们开发了一个两阶段算法，即最优调整（OT）算法，以在全局优化的基础上进行局部修正。在最优阶段，基于一阶Hilbert-Schmidt独立性准则（HSIC）的优化问题给出了一个估计的骨架作为初始确定的父节点子集。在调整阶段，根据高阶HSIC的理论证明增量特性，对骨架进行局部调整，包括删除、添加和DAG格式化策略。

    Score-based methods for learning Bayesain networks(BN) aim to maximizing the global score functions. However, if local variables have direct and indirect dependence simultaneously, the global optimization on score functions misses edges between variables with indirect dependent relationship, of which scores are smaller than those with direct dependent relationship. In this paper, we present an identifiability condition based on a determined subset of parents to identify the underlying DAG. By the identifiability condition, we develop a two-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the global optimization. In the optimal phase, an optimization problem based on first-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated skeleton as the initial determined parents subset. In the tuning phase, the skeleton is locally tuned by deletion, addition and DAG-formalization strategies using the theoretically proved incremental properties of high-order HS
    
[^19]: 基于轨迹的随机流行病学模型优化

    Trajectory-oriented optimization of stochastic epidemiological models. (arXiv:2305.03926v1 [stat.AP])

    [http://arxiv.org/abs/2305.03926](http://arxiv.org/abs/2305.03926)

    本论文提出了一个基于轨迹的优化方法来处理随机流行病学模型，可以找到与实际观测值接近的实际轨迹，而不是仅使平均模拟结果与实测数据相符。

    

    针对随机模型，为了进行预测和运行模拟，需要进行地面实测标定。由于输出结果通常是通过集成或分布来描述，因此需要对每个成员进行标定。本文提出了一种基于高斯过程代理和Thompson采样的优化策略来寻找与事实相一致的输入参数设置和随机数种子，该Trajectory Oriented Optimization（TOO）方法可以产生与实际观测值接近的实际轨迹，而不是仅虽然模拟的平均行为与事实相符。

    Epidemiological models must be calibrated to ground truth for downstream tasks such as producing forward projections or running what-if scenarios. The meaning of calibration changes in case of a stochastic model since output from such a model is generally described via an ensemble or a distribution. Each member of the ensemble is usually mapped to a random number seed (explicitly or implicitly). With the goal of finding not only the input parameter settings but also the random seeds that are consistent with the ground truth, we propose a class of Gaussian process (GP) surrogates along with an optimization strategy based on Thompson sampling. This Trajectory Oriented Optimization (TOO) approach produces actual trajectories close to the empirical observations instead of a set of parameter settings where only the mean simulation behavior matches with the ground truth.
    
[^20]: 任意深度的一维神经网络的不动点

    Fixed points of arbitrarily deep 1-dimensional neural networks. (arXiv:2303.12814v1 [stat.ML])

    [http://arxiv.org/abs/2303.12814](http://arxiv.org/abs/2303.12814)

    本研究发现，具有对数S型激活函数的任意深度的一维神经网络最多只有三个不动点，为深度神经网络的应用和理论之间构建了一个必要的桥梁。

    

    本文介绍了一个在$\mathbb{R}$上具有合成性且包含对数S型函数的新函数类。我们使用这个类来证明具有对数S型激活函数的任意深度的一维神经网络最多只有三个不动点。虽然这样的神经网络远离实际应用，但我们能够完全理解它们的不动点，并为深度神经网络的应用和理论之间构建了一个必要的桥梁。

    In this paper, we introduce a new class of functions on $\mathbb{R}$ that is closed under composition, and contains the logistic sigmoid function. We use this class to show that any 1-dimensional neural network of arbitrary depth with logistic sigmoid activation functions has at most three fixed points. While such neural networks are far from real world applications, we are able to completely understand their fixed points, providing a foundation to the much needed connection between application and theory of deep neural networks.
    
[^21]: Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)

    Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.13348](http://arxiv.org/abs/2302.13348)

    本文提出了一种应对混淆因素的核条件矩约束方法，通过利用核方法得到的条件矩约束的近似估计器，实现了对政策评估的尖锐下界估计，并能对经典边际敏感度模型进行新颖扩展。

    

    我们研究离线情境推断中未观察到的混淆因素对政策评估的影响。敏感性分析方法通常用于在给定不确定性集上估计最坏混淆情况下的政策价值。然而，现有的工作往往为了可行性而采用一些粗略的不确定性集的放松，导致对政策价值的过度保守估计。在本文中，我们提出了一种通用的估计器，它提供了政策价值的尖锐下界。可以证明我们的估计器包含了Dorn和Guo（2022年）最近提出的尖锐估计器作为一个特例，而我们的方法则利用f-散度来实现对经典边际敏感度模型的新颖扩展。为了构建我们的估计器，我们利用核方法得到了条件矩约束的可行近似，而传统的非尖锐估计器则未能考虑到这一点。在理论分析中，我们提供了一个条件，用于降低传统非尖锐估计器受混淆因素影响的程度。

    We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value. It can be shown that our estimator contains the recently proposed sharp estimator by Dorn and Guo (2022) as a special case, and our method enables a novel extension of the classical marginal sensitivity model using f-divergence. To construct our estimator, we leverage the kernel method to obtain a tractable approximation to the conditional moment constraints, which traditional non-sharp estimators failed to take into account. In the theoretical analysis, we provide a condition for the
    
[^22]: 基于随机先验网络的高维输出可扩展贝叶斯优化

    Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07260](http://arxiv.org/abs/2302.07260)

    本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。

    

    科学和工程中的一些基本问题涉及到未知的高维度映射一组可控变量到昂贵实验结果的黑盒函数的全局优化任务。贝叶斯优化（BO）技术已被证明在使用相对较少的目标函数评估时处理全局优化问题时非常有效，但当处理高维输出时，其性能受到影响。为克服维度主要挑战，本文提出了一个基于带随机先验的神经网络的自举集成的BO和序贯决策制定的深度学习框架。使用适当的体系结构选择，我们证明了所提出的框架可以近似设计变量和感兴趣量之间的功能关系，即使在后者取值于高维向量空间或甚至无限维函数空间的情况下。在贝叶斯优化的背景下，该方法允许高效和可扩展的处理高维度黑盒函数的全局优化。

    Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
    
[^23]: 关于梯度下降动态和深度学习不稳定性的连续时间模型研究

    On a continuous time model of gradient descent dynamics and instability in deep learning. (arXiv:2302.01952v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.01952](http://arxiv.org/abs/2302.01952)

    本文提出了一个连续时间流模型——主要流（PF），通过对Hessian矩阵特征分解的依赖，捕捉到了梯度下降中的发散和振荡行为、逃逸局部极小值和鞍点的连续性流，并解释了深度学习中的稳定边缘现象。通过对不稳定性的新理解，提出了一种学习率适应方法，可以控制训练稳定性和测试集评估性能之间的权衡。

    

    深度学习成功的秘诀在于神经网络和基于梯度的优化的结合。然而，理解梯度下降的行为，特别是其不稳定性，落后于其经验成功。为了增加研究梯度下降的理论工具，我们提出了主要流（PF），一种近似梯度下降动态的连续时间流。据我们所知，PF是唯一捕捉到梯度下降的发散和振荡行为，包括逃逸局部极小值和鞍点的连续性流。通过其对于Hessian特征分解的依赖，PF解释了深度学习中最近观察到的稳定边缘现象。通过对不稳定性的新理解，我们提出了一种学习率适应方法，使我们能够控制训练稳定性和测试集评估性能之间的权衡。

    The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.
    
[^24]: 高斯过程代理模型用于神经网络

    Gaussian Process Surrogate Models for Neural Networks. (arXiv:2208.06028v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.06028](http://arxiv.org/abs/2208.06028)

    通过利用高斯过程构建神经网络的代理模型，我们解决了深度学习系统行为预测和架构算法选择的问题，并展示了模型在捕捉现象、确定关键数据点和预测泛化能力方面的实际应用价值。

    

    无法理解和预测深度学习系统的行为使得很难决定针对给定问题使用什么架构和算法。在科学和工程中，建模是一种用于理解复杂系统的方法论，其内部过程是不透明的。建模用简化的、可解释的替代简化系统。受此启发，我们使用高斯过程构建了一类神经网络的代理模型。我们不是从无限神经网络推导内核，而是从有限神经网络的自然行为中经验性地学习内核。我们展示了我们的方法捕捉到了与神经网络频谱偏差相关的现象，并且展示了我们的代理模型可以用于解决实际问题，如确定哪些点对特定神经网络的行为影响最大，并预测哪些架构和算法对特定数据集具有良好的泛化能力。

    Not being able to understand and predict the behavior of deep learning systems makes it hard to decide what architecture and algorithm to use for a given problem. In science and engineering, modeling is a methodology used to understand complex systems whose internal processes are opaque. Modeling replaces a complex system with a simpler, more interpretable surrogate. Drawing inspiration from this, we construct a class of surrogate models for neural networks using Gaussian processes. Rather than deriving kernels for infinite neural networks, we learn kernels empirically from the naturalistic behavior of finite neural networks. We demonstrate our approach captures existing phenomena related to the spectral bias of neural networks, and then show that our surrogate models can be used to solve practical problems such as identifying which points most influence the behavior of specific neural networks and predicting which architectures and algorithms will generalize well for specific datasets
    
[^25]: 随机特征放大：神经网络中的特征学习和泛化

    Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.07626](http://arxiv.org/abs/2202.07626)

    本文通过分析在随机初始化后通过逻辑损失函数进行梯度下降训练的两层ReLU网络在特征学习过程中的表征，证明了对于具有二元标签的由XOR-like函数生成的数据，尽管线性分类器在该分布上无法更好地工作，但该网络的泛化误差接近于标签噪声率。通过一种新颖的证明技巧，揭示了初始化时大多数神经元作为随机特征，随后通过梯度下降动力学将这些弱的随机特征放大为有用的特征。

    

    在这项工作中，我们提供了对由梯度下降训练的两层ReLU网络在随机初始化后，通过逻辑损失函数对特征学习过程的表征。我们考虑由输入特征的XOR-like函数生成的具有二元标签的数据。我们允许一个固定比例的训练标签被对手损坏。我们证明，尽管线性分类器对于我们考虑的分布而言不比随机猜测更好，但通过梯度下降训练的两层ReLU网络的泛化误差接近于标签噪声率。我们开发了一种新颖的证明技巧，表明在初始化时，绝大多数神经元作为仅与有用特征弱相关的随机特征，而梯度下降动力学将这些弱的随机特征放大为强有用的特征。

    In this work, we provide a characterization of the feature-learning process in two-layer ReLU networks trained by gradient descent on the logistic loss following random initialization. We consider data with binary labels that are generated by an XOR-like function of the input features. We permit a constant fraction of the training labels to be corrupted by an adversary. We show that, although linear classifiers are no better than random guessing for the distribution we consider, two-layer ReLU networks trained by gradient descent achieve generalization error close to the label noise rate. We develop a novel proof technique that shows that at initialization, the vast majority of neurons function as random features that are only weakly correlated with useful features, and the gradient descent dynamics 'amplify' these weak, random features to strong, useful features.
    
[^26]: 不需要线性关系的良性过拟合：通过梯度下降训练的神经网络分类器用于噪声线性数据

    Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. (arXiv:2202.05928v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.05928](http://arxiv.org/abs/2202.05928)

    本文研究了使用梯度下降训练的神经网络在泛化时能够很好应对噪声数据的良性过拟合现象。研究表明，在特定条件下，神经网络能够将训练误差降至零并完美地适应带有噪声标签的数据，并同时达到最优的测试误差。

    

    良性过拟合是指插值模型在存在噪声数据的情况下能够很好地泛化的现象，最早出现在使用梯度下降训练的神经网络模型中。为了更好地理解这一实证观察，我们考虑了两层神经网络在随机初始化后通过梯度下降在逻辑损失函数上进行插值训练的泛化误差。我们假设数据来自于明显分离的类条件对数凹分布，并允许训练标签中的一定比例被对手篡改。我们证明在这种情况下，神经网络表现出良性过拟合的特点：它们可以被驱动到零训练误差，完美地拟合任何有噪声的训练标签，并同时达到极小化最大化最优测试误差。与之前关于良性过拟合需要线性或基于核的预测器的工作相比，我们的分析在模型和学习动态都是基本非线性的情况下成立。

    Benign overfitting, the phenomenon where interpolating models generalize well in the presence of noisy data, was first observed in neural network models trained with gradient descent. To better understand this empirical observation, we consider the generalization error of two-layer neural networks trained to interpolation by gradient descent on the logistic loss following random initialization. We assume the data comes from well-separated class-conditional log-concave distributions and allow for a constant fraction of the training labels to be corrupted by an adversary. We show that in this setting, neural networks exhibit benign overfitting: they can be driven to zero training error, perfectly fitting any noisy training labels, and simultaneously achieve minimax optimal test error. In contrast to previous work on benign overfitting that require linear or kernel-based predictors, our analysis holds in a setting where both the model and learning dynamics are fundamentally nonlinear.
    
[^27]: 通过群等变卷积量子Ansatze加速学习量子态

    Speeding up Learning Quantum States through Group Equivariant Convolutional Quantum Ans\"atze. (arXiv:2112.07611v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2112.07611](http://arxiv.org/abs/2112.07611)

    通过建立$S_n$-等变卷积量子Ansatze，我们证明了其能够在具有SU($d$)对称性的广泛量子机器学习问题中生成任意幺正矩阵，同时验证了4-local SU($d$)对称幺正矩阵的可实现性。

    

    我们基于Schur-Weyl对偶，建立了一个理论框架，用于$S_n$-等变卷积量子电路和SU$(d)$对称性，将Jordan的置换量子计算(PQC)形式主义扩展和泛化。我们利用Okounkov-Vershik方法来证明Harrow在奇异边表示基之间的等价性，并利用Young-Jucys-Murphy(YJM)元素建立了$S_n$-等变卷积量子交替Ansatze($S_n$-CQA)。我们证明了$S_n$-CQA能够在任何给定的$S_n$ irrep扇区中生成任意幺正矩阵，这可以作为具有SU($d$)对称性的广泛量子机器学习问题的通用模型。我们的方法提供了另一种证明量子近似优化算法(QAOA)的普适性的方式，并验证了4-local SU($d$)对称幺正矩阵是可实现的。

    We develop a theoretical framework for $S_n$-equivariant convolutional quantum circuits with SU$(d)$-symmetry, building on and significantly generalizing Jordan's Permutational Quantum Computing (PQC) formalism based on Schur-Weyl duality connecting both SU$(d)$ and $S_n$ actions on qudits. In particular, we utilize the Okounkov-Vershik approach to prove Harrow's statement (Ph.D. Thesis 2005 p.160) on the equivalence between $\operatorname{SU}(d)$ and $S_n$ irrep bases and to establish the $S_n$-equivariant Convolutional Quantum Alternating Ans\"atze ($S_n$-CQA) using Young-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA is able to generate any unitary in any given $S_n$ irrep sector, which may serve as a universal model for a wide array of quantum machine learning problems with the presence of SU($d$) symmetry. Our method provides another way to prove the universality of Quantum Approximate Optimization Algorithm (QAOA) and verifies that 4-local SU($d$) symmetric unitaries are su
    
[^28]: 通过半定规划，联合社区检测和旋转同步

    Joint Community Detection and Rotational Synchronization via Semidefinite Programming. (arXiv:2105.06031v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2105.06031](http://arxiv.org/abs/2105.06031)

    本文提出了一种通过半定规划来联合社区检测和旋转同步的方法，在存在异构数据的情况下，能够准确恢复出旋转和聚类身份，并通过数值实验证明了其有效性和准确恢复性的相变现象。

    

    在存在异构数据的情况下，随机旋转的对象落入多个潜在类别中，同时对它们进行聚类和基于两两关系进行同步是具有挑战性的。这导致了社区检测和同步的联合问题。我们提出了一系列半定松弛，并证明了它们在将著名的随机块模型扩展到旋转和聚类身份都需要确定的新情况时的精确恢复性。数值实验证明了我们提出的算法的有效性，并证实了我们的理论结果，表明了准确恢复性的明显相变。

    In the presence of heterogeneous data, where randomly rotated objects fall into multiple underlying categories, it is challenging to simultaneously classify them into clusters and synchronize them based on pairwise relations. This gives rise to the joint problem of community detection and synchronization. We propose a series of semidefinite relaxations, and prove their exact recovery when extending the celebrated stochastic block model to this new setting where both rotations and cluster identities are to be determined. Numerical experiments demonstrate the efficacy of our proposed algorithms and confirm our theoretical result which indicates a sharp phase transition for exact recovery.
    
[^29]: 基于Copula模型的缺失非随机截尾指标的生存估计

    Survival Estimation for Missing not at Random Censoring Indicators based on Copula Models. (arXiv:2009.01726v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2009.01726](http://arxiv.org/abs/2009.01726)

    本论文提出了一种基于Copula模型的新的估计器，用于处理缺失非随机截尾指标下的条件生存函数估计问题。通过模拟实验和真实数据分析，我们验证了该估计器的实用性。

    

    在具有协变量的右截尾数据中，条件Kaplan-Meier估计器（也称为Beran估计器）一致估计感兴趣事件的随机追踪的条件生存函数。然而，必要条件是对每个个体是否被截尾有明确的了解，而在实践中可能是不完整的。因此，我们提出了当截尾指标是一般随机变量时对Beran估计器进行研究，并讨论了Beran估计器效率的必要条件。基于缺失非随机（MNAR）截尾指标的条件Copula模型，我们提供了一种新的条件生存函数估计器。除了理论结果，我们通过模拟研究对小样本中的估计器进行了演示，并通过分析合成和真实数据展示了它们的实际适用性。

    In the presence of right-censored data with covariates, the conditional Kaplan-Meier estimator (also known as the Beran estimator) consistently estimates the conditional survival function of the random follow-up for the event of interest. However, a necessary condition is the unambiguous knowledge of whether each individual is censored or not, which may be incomplete in practice. We therefore propose a study of the Beran estimator when the censoring indicators are generic random variables and discuss necessary conditions for the efficiency of the Beran estimator. From this, we provide a new estimator for the conditional survival function with missing not at random (MNAR) censoring indicators based on a conditional copula model for the missingness mechanism. In addition to the theoretical results, we illustrate how the estimators work for small samples through a simulation study and show their practical applicability by analyzing synthetic and real data.
    
[^30]: 关于非凸-凹极小极大问题的梯度下降算法

    On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. (arXiv:1906.00331v9 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1906.00331](http://arxiv.org/abs/1906.00331)

    该论文提出了一种用于解决非凸-凹极小极大问题的梯度下降算法，并进行了复杂性分析，证明了该算法可以高效地找到函数的稳定点。该研究对于非凸-凹极小极大问题的非渐进分析是首次进行的。

    

    我们考虑非凸-凹极小极大问题，即$\min_{\mathbf{x}} \max_{\mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y})$，其中$f$在$\mathbf{x}$上是非凸的但在$\mathbf{y}$上是凹的，$\mathcal{Y}$是一个凸且有界的集合。解决这个问题最常用的算法之一是著名的梯度下降上升（GDA）算法，在机器学习、控制理论和经济学中得到了广泛应用。尽管凸-凹设置下有着广泛的收敛结果，但在一般情况下，相同步长的GDA可能会收敛到极限环，甚至发散。本文介绍了解决非凸-凹极小极大问题的两时间尺度GDA的复杂度结果，并证明了该算法可以高效地找到函数$\Phi(\cdot) := \max_{\mathbf{y} \in \mathcal{Y}} f(\cdot, \mathbf{y})$的一个稳定点。据我们所知，这是第一个在这个设置中的非渐进分析结果，揭示了有关两时间尺度GDA的性质。

    We consider nonconvex-concave minimax problems, $\min_{\mathbf{x}} \max_{\mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y})$, where $f$ is nonconvex in $\mathbf{x}$ but concave in $\mathbf{y}$ and $\mathcal{Y}$ is a convex and bounded set. One of the most popular algorithms for solving this problem is the celebrated gradient descent ascent (GDA) algorithm, which has been widely used in machine learning, control theory and economics. Despite the extensive convergence results for the convex-concave setting, GDA with equal stepsize can converge to limit cycles or even diverge in a general setting. In this paper, we present the complexity results on two-time-scale GDA for solving nonconvex-concave minimax problems, showing that the algorithm can find a stationary point of the function $\Phi(\cdot) := \max_{\mathbf{y} \in \mathcal{Y}} f(\cdot, \mathbf{y})$ efficiently. To the best our knowledge, this is the first nonasymptotic analysis for two-time-scale GDA in this setting, shedding lig
    

