# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single.](http://arxiv.org/abs/2304.11153) | ES-Single是一种用于估计展开的计算图中梯度的进化策略算法，其简单实现、方差较低，在各种任务中表现优异。 |
| [^2] | [Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs.](http://arxiv.org/abs/2304.11140) | 本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。 |
| [^3] | [Plug-and-Play split Gibbs sampler: embedding deep generative priors in Bayesian inference.](http://arxiv.org/abs/2304.11134) | 本文介绍一种插拔式分割 Gibbs 采样算法，将后验采样任务分为两个较简单的子问题，其中第二个子问题可以用深度生成模型轻松地解决，从而实现了在贝叶斯推断中嵌入深度生成先验以及自动适应后验分布的复杂性。 |
| [^4] | [Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions.](http://arxiv.org/abs/2304.11059) | 本文介绍了一种新的通用算法，利用尺度敏感的Vapnik维度来学习$[0,1]$值函数类，并获得了关于期望绝对误差的一般上限。文中证明该上限不能在一般情况下进一步改善一个常数因子。这篇论文对无偏学习样本复杂度的提高具有重要的意义。 |
| [^5] | [Self-Correcting Bayesian Optimization through Bayesian Active Learning.](http://arxiv.org/abs/2304.11005) | 该论文提出了SAL和SCoreBO两种方法，用于提高高斯过程模型的超参数选择和贝叶斯优化的表现。 |
| [^6] | [Balancing Simulation-based Inference for Conservative Posteriors.](http://arxiv.org/abs/2304.10978) | 本研究将平衡技术扩展到后验密度算法，提出了神经后验估计和对比神经比率估计的平衡版本，可有效缓解保守推断问题。 |
| [^7] | [Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition.](http://arxiv.org/abs/2304.10977) | 本文评估了使用数字分解技术进行微调后的变形金刚语言模型在执行算术运算时的表现。结果显示，这种方法在五位数字加法任务中的准确度提高了63%。 |
| [^8] | [A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning.](http://arxiv.org/abs/2304.10951) | 本文提出了两种三次正则化策略牛顿算法，其使用似然比方法形成价值函数梯度和黑塞矩阵的估计。我们证明了算法收敛到价值函数的二阶稳定点，从而避免了类型为鞍点的陷阱。 |
| [^9] | [Auditing and Generating Synthetic Data with Controllable Trust Trade-offs.](http://arxiv.org/abs/2304.10819) | 本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。 |
| [^10] | [Persistently Trained, Diffusion-assisted Energy-based Models.](http://arxiv.org/abs/2304.10707) | 本文提出了一种新的持续训练方法，命名为扩散辅助 EBM，可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。 |
| [^11] | [Ellipsoid fitting with the Cayley transform.](http://arxiv.org/abs/2304.10630) | 介绍了一种使用Cayley变换在任意维度上将椭球拟合到嘈杂数据中的新算法CTEF，可以拟合任意的椭球，并且能提取其他方法无法识别的数据中的非线性特征，可用于降维、数据可视化和聚类，相比其他方法更优。 |
| [^12] | [Debiasing Conditional Stochastic Optimization.](http://arxiv.org/abs/2304.10613) | 本文提出了一种通用的随机外推技术，用于降低条件随机优化问题中的偏差，并证明在非凸光滑目标函数中，将外推与方差缩减技术相结合可以显著改善样本复杂度。 |
| [^13] | [B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding.](http://arxiv.org/abs/2304.10577) | 本文提出了一种元学习器 B-Learner，它可以在限制隐藏混淆水平的情况下高效地学习 CATE 函数的尖锐界限。 |
| [^14] | [Interpolation property of shallow neural networks.](http://arxiv.org/abs/2304.10552) | 本文证明了浅层神经网络可以插值任何数据集，即损失函数具有全局最小值为零的性质，此外还给出了该全局最小值处的惯性矩阵的表征，并提供了一种实用的概率方法来寻找插值点。 |
| [^15] | [Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?.](http://arxiv.org/abs/2304.09868) | 本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。 |
| [^16] | [Applications of No-Collision Transportation Maps in Manifold Learning.](http://arxiv.org/abs/2304.00199) | 本文研究了在流形学习中应用无碰撞运输图的方法，其可以比OT图更便宜地计算距离，并提供单个概率测度的平移和伸缩的等距性。 |
| [^17] | [From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets.](http://arxiv.org/abs/2212.00394) | 论文提出了一种消除OCV（Aliasing）的方法，该方法基于复数卷积，同时采用Gabor样式的卷积核，可以提高卷积神经网络的分类准确性。 |
| [^18] | [Implications of sparsity and high triangle density for graph representation learning.](http://arxiv.org/abs/2210.15277) | 稀疏图中的大量三角形可使用无限维度内积模型进行复现，其中节点表示位于低维流形上。虽然全局表示是不可能的，但我们可以在本地邻域缩小规模，以获取较低维度的表示。 |
| [^19] | [Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition.](http://arxiv.org/abs/2210.12256) | 本文介绍了一种通用的偏差-方差分解方法，用于估计模型预测的不确定性，这种方法可以用于大多数预测任务，并且可以在多个下游任务中实际使用。 |
| [^20] | [Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies.](http://arxiv.org/abs/2210.06140) | 本文研究了一种差分隐私引导采样方法，提供了隐私成本的新结果，可用于推断样本分布并构建置信区间，同时指出了现有文献中的误用。随着采样次数趋近无限大，此方法逐渐满足更严格的差分隐私要求。 |
| [^21] | [Active learning-assisted neutron spectroscopy with log-Gaussian processes.](http://arxiv.org/abs/2209.00980) | 本文介绍了一种基于对数高斯过程的概率主动学习方法，该方法可以自主运行并找到具有信息的测量位置，提高中子谱学实验的效率。 |
| [^22] | [Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification.](http://arxiv.org/abs/2206.03345) | 本文提出了一种预条件梯度下降方法，使得超参数化情况下梯度下降的收敛速度恢复到线性，并在保证全局最优性证明有效的同时保持低廉的计算代价，该方法适用于强凸的代价函数 $\phi$。 |
| [^23] | [Topological Deep Learning: Going Beyond Graph Data.](http://arxiv.org/abs/2206.00606) | 本文提出了一个拓扑深度学习的框架，其中包含组合复合体这一新型拓扑域。组合复合体结合了超图和胞腔复合体的优点，允许构建分层高阶关系。 |
| [^24] | [Variational inference via Wasserstein gradient flows.](http://arxiv.org/abs/2205.15902) | 本文提出了一种基于Wasserstein梯度流的变分推断方法，该方法使用高斯或高斯混合分布并在处理对数凹 $\pi$ 时具有强大的理论保证。 |
| [^25] | [Pre-trained Perceptual Features Improve Differentially Private Image Generation.](http://arxiv.org/abs/2205.12900) | 该论文提出了一种利用预先训练的感知特征，通过最小化MMD（最大均值差异）来提高差分隐私图像生成的性能，并成功地生成了CIFAR10级别的图像。 |
| [^26] | [Regression-based projection for learning Mori-Zwanzig operators.](http://arxiv.org/abs/2205.05135) | 本文提出了一种采用回归投影方法学习Mori-Zwanzig算子的数据驱动学习方法，具有灵活性强、应用范围广等优点。 |
| [^27] | [Graph-Relational Domain Adaptation.](http://arxiv.org/abs/2202.03628) | 本研究使用领域图对领域相邻性进行编码，放宽了领域适应的统一对齐方法，实现了非平凡的对齐，并成功地融合了领域信息。 |
| [^28] | [Smoothed Separable Nonnegative Matrix Factorization.](http://arxiv.org/abs/2110.05528) | 该算法基于平滑的可分离性假设，提出一种新的平滑可分非负矩阵分解（SSNMF）算法，能够有效地抵抗在‘纯像素假设’存在的噪声干扰 |
| [^29] | [On Frequentist Regret of Linear Thompson Sampling.](http://arxiv.org/abs/2006.06790) | 本文研究了线性汤普森抽样的频率后悔问题，证明了后验方差膨胀是必需的，并确定了频率后悔的最低下限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$ 。 |
| [^30] | [On Newton Screening.](http://arxiv.org/abs/2001.10616) | 本文提出了一种称为牛顿筛选法的新型Broad-Newton方法，它带有一个内置的较小的工作集，可用于加速解决大规模稀疏学习问题的一阶方法。 |

# 详细

[^1]: ES-Single：在展开的计算图中实现低方差梯度估计

    Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single. (arXiv:2304.11153v1 [cs.LG])

    [http://arxiv.org/abs/2304.11153](http://arxiv.org/abs/2304.11153)

    ES-Single是一种用于估计展开的计算图中梯度的进化策略算法，其简单实现、方差较低，在各种任务中表现优异。

    

    我们提出了一种基于进化策略的算法ES-Single，用于估计展开的计算图中的梯度。与最近提出的持久进化策略（PES）类似，ES-Single是无偏的，并通过平滑元损失函数来克服由于递归函数应用而产生的混沌。ES-Single对于每个粒子采样一个单一扰动，并在内部问题的过程中保持不变（例如，对于每个部分未展开，不会重新采样扰动）。与PES相比，ES-Single实现更简单，方差更低：ES-Single的方差与截断展开次数的数量无关，消除了使用短截断来解决长内部问题所带来的关键障碍。我们展示了ES-Single对于二次内部问题是无偏的，并且通过实验证明了它的方差可以显著地低于PES。ES-Single在多项任务中持续优于PES，包括合成基准测试。

    We propose an evolution strategies-based algorithm for estimating gradients in unrolled computation graphs, called ES-Single. Similarly to the recently-proposed Persistent Evolution Strategies (PES), ES-Single is unbiased, and overcomes chaos arising from recursive function applications by smoothing the meta-loss landscape. ES-Single samples a single perturbation per particle, that is kept fixed over the course of an inner problem (e.g., perturbations are not re-sampled for each partial unroll). Compared to PES, ES-Single is simpler to implement and has lower variance: the variance of ES-Single is constant with respect to the number of truncated unrolls, removing a key barrier in applying ES to long inner problems using short truncations. We show that ES-Single is unbiased for quadratic inner problems, and demonstrate empirically that its variance can be substantially lower than that of PES. ES-Single consistently outperforms PES on a variety of tasks, including a synthetic benchmark t
    
[^2]: 基于消息传递的图神经网络在大规模随机图上的通用聚合收敛性研究

    Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])

    [http://arxiv.org/abs/2304.11140](http://arxiv.org/abs/2304.11140)

    本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。

    

    本文研究了消息传递图神经网络在随机图模型上的收敛性，当节点数量趋近于无限时，该网络模型能收敛于其连续模型。迄今为止，该收敛性结果只适用于聚合函数采用度规范化平均值形式的网络结构。我们将此结果扩展到包含所有传统消息传递图神经网络的大类聚合函数上，例如基于注意力和最大卷积的网络。在一定假设下，我们给出了高概率的非渐进上限来量化这种收敛性。我们的主要结果基于McDiarmid不等式。有趣的是，我们特别处理了聚合函数采用逐个坐标最大值的情况，因为它需要非常不同的证明技巧，并产生了定性不同的收敛率。

    We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
    
[^3]: 插拔式分割 Gibbs 采样: 在贝叶斯推断中嵌入深度生成先验

    Plug-and-Play split Gibbs sampler: embedding deep generative priors in Bayesian inference. (arXiv:2304.11134v1 [stat.ML])

    [http://arxiv.org/abs/2304.11134](http://arxiv.org/abs/2304.11134)

    本文介绍一种插拔式分割 Gibbs 采样算法，将后验采样任务分为两个较简单的子问题，其中第二个子问题可以用深度生成模型轻松地解决，从而实现了在贝叶斯推断中嵌入深度生成先验以及自动适应后验分布的复杂性。

    

    本文介绍了一种基于变量分离的随机插拔式(Plug-and-Play)采样算法，以有效地从后验分布中采样。该算法基于分割Gibbs采样(split Gibbs sampling, SGS)，灵感来自于交替方向乘子法(alternating direction method of multipliers, ADMM)。它将后验采样的挑战任务分为两个较简单的采样问题。第一个问题依赖于似然函数，而第二个问题被解释为一个贝叶斯降噪问题，可以通过深度生成模型轻松地完成。具体而言，为了说明目的，本文所提出的方法使用了最先进的基于扩散的生成模型进行了实现。与其确定性的插拔式(Plug-and-Play)类似，所提出的方法具有不需要显式选择先验分布的巨大优势，而是将其编码到预训练的生成模型中。然而，与需要谨慎调整调整参数的优化方法(PnP-ADMM)不同，所提出的插拔式分割 Gibbs 采样算法可以在采样过程中自动适应后验分布的复杂性。

    This paper introduces a stochastic plug-and-play (PnP) sampling algorithm that leverages variable splitting to efficiently sample from a posterior distribution. The algorithm based on split Gibbs sampling (SGS) draws inspiration from the alternating direction method of multipliers (ADMM). It divides the challenging task of posterior sampling into two simpler sampling problems. The first problem depends on the likelihood function, while the second is interpreted as a Bayesian denoising problem that can be readily carried out by a deep generative model. Specifically, for an illustrative purpose, the proposed method is implemented in this paper using state-of-the-art diffusion-based generative models. Akin to its deterministic PnP-based counterparts, the proposed method exhibits the great advantage of not requiring an explicit choice of the prior distribution, which is rather encoded into a pre-trained generative model. However, unlike optimization methods (e.g., PnP-ADMM) which generally
    
[^4]: 预测、学习、一致收敛和尺度敏感维度

    Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions. (arXiv:2304.11059v1 [cs.LG])

    [http://arxiv.org/abs/2304.11059](http://arxiv.org/abs/2304.11059)

    本文介绍了一种新的通用算法，利用尺度敏感的Vapnik维度来学习$[0,1]$值函数类，并获得了关于期望绝对误差的一般上限。文中证明该上限不能在一般情况下进一步改善一个常数因子。这篇论文对无偏学习样本复杂度的提高具有重要的意义。

    

    我们提出了一种新的通用算法，用于在预测模型的推广中学习$[0,1]$值函数类，并证明了一般性的上限，该上限反映了由Alon、Ben-David、Cesa-Bianchi和Haussler提出的尺度敏感的Vapnik维度的推广。我们给出了下限，这表明我们的上限不能在一般情况下进一步改善一个常数因子。我们应用此结果和Haussler以及Benedek和Itai的技术，以利用这种尺度敏感的维度概念获得新的填充数上限。我们利用不同的技术，利用Kearns和Schapire的fat-shattering函数得到了新的填充数上限。我们展示了如何应用这两种填充上限来获得对无偏学习样本复杂度的改进一般性上限。对于每个$\epsilon > 0$，我们建立了一个类的足够条件和必要条件。

    We present a new general-purpose algorithm for learning classes of $[0,1]$-valued functions in a generalization of the prediction model, and prove a general upper bound on the expected absolute error of this algorithm in terms of a scale-sensitive generalization of the Vapnik dimension proposed by Alon, Ben-David, Cesa-Bianchi and Haussler. We give lower bounds implying that our upper bounds cannot be improved by more than a constant factor in general. We apply this result, together with techniques due to Haussler and to Benedek and Itai, to obtain new upper bounds on packing numbers in terms of this scale-sensitive notion of dimension. Using a different technique, we obtain new bounds on packing numbers in terms of Kearns and Schapire's fat-shattering function. We show how to apply both packing bounds to obtain improved general bounds on the sample complexity of agnostic learning. For each $\epsilon > 0$, we establish weaker sufficient and stronger necessary conditions for a class of 
    
[^5]: 通过贝叶斯主动学习实现自校正贝叶斯优化

    Self-Correcting Bayesian Optimization through Bayesian Active Learning. (arXiv:2304.11005v1 [cs.LG])

    [http://arxiv.org/abs/2304.11005](http://arxiv.org/abs/2304.11005)

    该论文提出了SAL和SCoreBO两种方法，用于提高高斯过程模型的超参数选择和贝叶斯优化的表现。

    

    高斯过程已成为贝叶斯优化和主动学习中的首选模型。然而，高斯过程的完全发挥需要巧妙选择超参数，而在文献中很少有关于找到正确超参数的努力。我们演示了选择好的超参数对于高斯过程的影响，并提出了两个明确优先考虑此目标的收购函数。统计距离主动学习（SAL）考虑后验样本的平均不一致性，由统计距离测量。结果显示，在许多测试函数上，它胜过了贝叶斯主动学习的最新结果。然后，我们引入了自校正贝叶斯优化（SCoreBO），它将SAL扩展到同时执行贝叶斯优化和主动超参数学习。相比传统BO，SCoreBO以改进的速度学习模型超参数，同时在最新的贝叶斯优化搜索中取得更好的表现。

    Gaussian processes are cemented as the model of choice in Bayesian optimization and active learning. Yet, they are severely dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding the right hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize this goal. Statistical distance-based Active Learning (SAL) considers the average disagreement among samples from the posterior, as measured by a statistical distance. It is shown to outperform the state-of-the-art in Bayesian active learning on a number of test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and active hyperparameter learning simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization met
    
[^6]: 平衡模拟推断，得到保守的后验分布

    Balancing Simulation-based Inference for Conservative Posteriors. (arXiv:2304.10978v1 [stat.ML])

    [http://arxiv.org/abs/2304.10978](http://arxiv.org/abs/2304.10978)

    本研究将平衡技术扩展到后验密度算法，提出了神经后验估计和对比神经比率估计的平衡版本，可有效缓解保守推断问题。

    

    保守推断是模拟推断中的一个重要问题。已经证明常用算法可能会产生过于自信的后验分布。实验证明，平衡可以有效缓解这个问题，但其应用仍限于神经比率估计。在这项工作中，我们将平衡扩展到提供后验密度的任何算法。特别地，我们引入了神经后验估计和对比神经比率估计的平衡版本。实验表明，平衡版本倾向于在广泛的基准测试上产生保守的后验分布逼近。此外，我们提供了平衡条件的另一种解释，即$ \chi^2$ 隔离度。

    Conservative inference is a major concern in simulation-based inference. It has been shown that commonly used algorithms can produce overconfident posterior approximations. Balancing has empirically proven to be an effective way to mitigate this issue. However, its application remains limited to neural ratio estimation. In this work, we extend balancing to any algorithm that provides a posterior density. In particular, we introduce a balanced version of both neural posterior estimation and contrastive neural ratio estimation. We show empirically that the balanced versions tend to produce conservative posterior approximations on a wide variety of benchmarks. In addition, we provide an alternative interpretation of the balancing condition in terms of the $\chi^2$ divergence.
    
[^7]: 使用数字分解评估变形金刚语言模型在算术运算上的表现

    Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition. (arXiv:2304.10977v1 [cs.CL])

    [http://arxiv.org/abs/2304.10977](http://arxiv.org/abs/2304.10977)

    本文评估了使用数字分解技术进行微调后的变形金刚语言模型在执行算术运算时的表现。结果显示，这种方法在五位数字加法任务中的准确度提高了63%。

    

    近年来，像GPT-3这样的大型语言模型在零和少量样本的NLP任务中展现出了非凡的能力。然而，实验突显出GPT-3在需要一定推理能力的任务，如算术运算中的困难。本文通过一个流程来评估变形金刚语言模型在执行算术运算时的能力，在这个流程中，数字会在计算之前被分解为个位、十位等。我们称使用这个流程微调后的模型为Calculon，并在GPT-3的同一测试数据集上测试了它们在执行加、减和乘法任务时的表现。结果显示，在五位数字加法任务中，准确度提高了63%。此外，我们还展示了引入分解流程的重要性，因为将相同的语言模型进行微调，但没有进行数字分解，其在五位数字加法任务中的准确度为0%。

    In recent years, Large Language Models such as GPT-3 showed remarkable capabilities in performing NLP tasks in the zero and few shot settings. On the other hand, the experiments highlighted the difficulty of GPT-3 in carrying out tasks that require a certain degree of reasoning, such as arithmetic operations. In this paper we evaluate the ability of Transformer Language Models to perform arithmetic operations following a pipeline that, before performing computations, decomposes numbers in units, tens, and so on. We denote the models fine-tuned with this pipeline with the name Calculon and we test them in the task of performing additions, subtractions and multiplications on the same test sets of GPT-3. Results show an increase of accuracy of 63% in the five-digit addition task. Moreover, we demonstrate the importance of the decomposition pipeline introduced, since fine-tuning the same Language Model without decomposing numbers results in 0% accuracy in the five-digit addition task.
    
[^8]: 强化学习中的三次正则化策略牛顿算法

    A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning. (arXiv:2304.10951v1 [cs.LG])

    [http://arxiv.org/abs/2304.10951](http://arxiv.org/abs/2304.10951)

    本文提出了两种三次正则化策略牛顿算法，其使用似然比方法形成价值函数梯度和黑塞矩阵的估计。我们证明了算法收敛到价值函数的二阶稳定点，从而避免了类型为鞍点的陷阱。

    

    本文研究了在没有模型信息的强化学习（RL）环境下的控制问题。针对这个问题，我们提出了两种策略牛顿算法，其中包含了三次正则化。这两种算法采用似然比方法使用样本轨迹形成价值函数梯度和黑塞矩阵的估计。第一种算法在每次迭代中需要三次正则化问题的精确解，而第二种算法则使用了一种高效的梯度下降近似方法。我们证明了所提出的算法收敛到价值函数的二阶稳定点（SOSP），从而避免了类型为鞍点的陷阱。特别地，我们的算法的样本复杂度为$\epsilon$

    We consider the problem of control in the setting of reinforcement learning (RL), where model information is not available. Policy gradient algorithms are a popular solution approach for this problem and are usually shown to converge to a stationary point of the value function. In this paper, we propose two policy Newton algorithms that incorporate cubic regularization. Both algorithms employ the likelihood ratio method to form estimates of the gradient and Hessian of the value function using sample trajectories. The first algorithm requires an exact solution of the cubic regularized problem in each iteration, while the second algorithm employs an efficient gradient descent-based approximation to the cubic regularized problem. We establish convergence of our proposed algorithms to a second-order stationary point (SOSP) of the value function, which results in the avoidance of traps in the form of saddle points. In particular, the sample complexity of our algorithms to find an $\epsilon$
    
[^9]: 可控的信任权衡下的合成数据审计与生成

    Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])

    [http://arxiv.org/abs/2304.10819](http://arxiv.org/abs/2304.10819)

    本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。

    

    现实中收集的数据往往存在偏差、不平衡，并且有泄露敏感和隐私信息的风险。这一事实引发了创建合成数据集的想法，以减轻真实数据中固有的风险、偏见、伤害和隐私问题。这个概念依赖于生成AI模型，以产生不偏执、保护隐私的合成数据，同时忠实于真实数据。在这种新范式中，我们如何知道这种方法是否兑现了其承诺？我们提出了一个审计框架，提供了对合成数据集和基于它们训练的AI模型的全面评估，围绕偏见和歧视的预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。我们通过审计多个生成模型在不同用例中展示了我们的框架，包括教育、医疗保健、银行、人力资源，以及从表格，时间序列到自然语言的不同模态。我们的用例展示了在合成数据生成中平衡信任和效用的权衡的重要性。

    Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
    
[^10]: 基于扩散的能量模型的持续训练

    Persistently Trained, Diffusion-assisted Energy-based Models. (arXiv:2304.10707v1 [stat.ML])

    [http://arxiv.org/abs/2304.10707](http://arxiv.org/abs/2304.10707)

    本文提出了一种新的持续训练方法，命名为扩散辅助 EBM，可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。

    

    能量模型 (EBMs) 的最大似然 (ML) 学习很具有挑战性，部分原因在于马尔可夫链蒙特卡罗的不收敛。虽然已经提出了几种 ML 学习的变体，但现有方法都未能同时实现训练后的图像生成和合适的密度估计。我们提出了引入扩散数据，并通过使用增强的采样算法进行持续训练 (即使用持续的对比散度)，来学习一个称为扩散辅助 EBM 的联合 EBM，以便从复杂的、多峰的分布中进行适当的采样。我们在二维的示例实验和图像实验中展示了结果，并证明了针对图像数据，持续训练的 EBM 可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。

    Maximum likelihood (ML) learning for energy-based models (EBMs) is challenging, partly due to non-convergence of Markov chain Monte Carlo.Several variations of ML learning have been proposed, but existing methods all fail to achieve both post-training image generation and proper density estimation. We propose to introduce diffusion data and learn a joint EBM, called diffusion assisted-EBMs, through persistent training (i.e., using persistent contrastive divergence) with an enhanced sampling algorithm to properly sample from complex, multimodal distributions. We present results from a 2D illustrative experiment and image experiments and demonstrate that, for the first time for image data, persistently trained EBMs can {\it simultaneously} achieve long-run stability, post-training image generation, and superior out-of-distribution detection.
    
[^11]: 用Cayley变换拟合椭球

    Ellipsoid fitting with the Cayley transform. (arXiv:2304.10630v1 [stat.ML])

    [http://arxiv.org/abs/2304.10630](http://arxiv.org/abs/2304.10630)

    介绍了一种使用Cayley变换在任意维度上将椭球拟合到嘈杂数据中的新算法CTEF，可以拟合任意的椭球，并且能提取其他方法无法识别的数据中的非线性特征，可用于降维、数据可视化和聚类，相比其他方法更优。

    

    我们引入了一种算法，Cayley变换椭球拟合(CTEF)，它使用Cayley变换在任意维度上将椭球拟合到嘈杂的数据中。与许多椭球拟合方法不同，CTEF是椭球特定的——意味着它总是返回椭圆解——并且可以拟合任意的椭球。当数据不均匀地分布在椭球表面上时，它也优于其他拟合方法。受机器学习中可解释和可重复方法的呼吁启发，我们将CTEF应用于降维、数据可视化和聚类。由于CTEF捕捉全局曲率，因此它能够提取其他方法无法识别的数据中的非线性特征。这在人类细胞周期数据的降维和在经典玩具例子的聚类的背景下得到了说明。在后一种情况下，CTEF优于10种流行的聚类算法。

    We introduce an algorithm, Cayley transform ellipsoid fitting (CTEF), that uses the Cayley transform to fit ellipsoids to noisy data in any dimension. Unlike many ellipsoid fitting methods, CTEF is ellipsoid specific -- meaning it always returns elliptic solutions -- and can fit arbitrary ellipsoids. It also outperforms other fitting methods when data are not uniformly distributed over the surface of an ellipsoid. Inspired by calls for interpretable and reproducible methods in machine learning, we apply CTEF to dimension reduction, data visualization, and clustering. Since CTEF captures global curvature, it is able to extract nonlinear features in data that other methods fail to identify. This is illustrated in the context of dimension reduction on human cell cycle data, and in the context of clustering on classical toy examples. In the latter case, CTEF outperforms 10 popular clustering algorithms.
    
[^12]: 消除条件随机优化偏差

    Debiasing Conditional Stochastic Optimization. (arXiv:2304.10613v1 [cs.LG])

    [http://arxiv.org/abs/2304.10613](http://arxiv.org/abs/2304.10613)

    本文提出了一种通用的随机外推技术，用于降低条件随机优化问题中的偏差，并证明在非凸光滑目标函数中，将外推与方差缩减技术相结合可以显著改善样本复杂度。

    

    本文研究了覆盖了多个应用领域，包括投资组合选择、强化学习、鲁棒学习、因果推断等的条件随机优化（CSO）问题。由于其嵌套结构，CSO目标的样本平均梯度存在偏差，因此需要较高的样本复杂度才能达到收敛。我们引入了一种有效降低偏差的通用随机外推技术。我们证明，在非凸光滑目标函数中，将这种外推与方差缩减技术相结合，可以达到比现有界限更好的样本复杂度。我们还开发了用于有限和变量的CSO的新算法，也显著改进了现有结果。最后，我们认为我们的去偏技术也可能是适用于其他随机优化问题的有趣工具。

    In this paper, we study the conditional stochastic optimization (CSO) problem which covers a variety of applications including portfolio selection, reinforcement learning, robust learning, causal inference, etc. The sample-averaged gradient of the CSO objective is biased due to its nested structure and therefore requires a high sample complexity to reach convergence. We introduce a general stochastic extrapolation technique that effectively reduces the bias. We show that for nonconvex smooth objectives, combining this extrapolation with variance reduction techniques can achieve a significantly better sample complexity than existing bounds. We also develop new algorithms for the finite-sum variant of CSO that also significantly improve upon existing results. Finally, we believe that our debiasing technique could be an interesting tool applicable to other stochastic optimization problems too.
    
[^13]: B-Learner：隐藏混淆下异质因果效应的准神谕界限

    B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding. (arXiv:2304.10577v1 [cs.LG])

    [http://arxiv.org/abs/2304.10577](http://arxiv.org/abs/2304.10577)

    本文提出了一种元学习器 B-Learner，它可以在限制隐藏混淆水平的情况下高效地学习 CATE 函数的尖锐界限。

    

    从观察数据中估计异质治疗效应是许多领域中的重要任务，有助于政策和决策者做出更好的行动。近年来，在估计条件平均治疗效应（CATE）函数方面取得了鲁棒且高效的方法，但这些方法通常未考虑隐藏混淆的风险，这可能会对基于观察数据的任何因果估计造成任意和不知情的偏差。我们提出了一种名为B-Learner的元学习器，它可以在限制隐藏混淆水平的情况下高效地学习CATE函数的尖锐界限。我们通过将最近针对平均治疗效应的尖锐且有效边界结果（Dorn等人，2021）调整为Kallus＆Oprescu（2022）所提供的稳健和模型无关的分布式治疗效应学习框架，派生出B-Learner。B-Learner可以使用任何函数估计器，例如随机森林和深度神经网络，我们证明了它的。

    Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus & Oprescu (2022) for robust and model-agnostic learning of distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its 
    
[^14]: 浅层神经网络的插值性质

    Interpolation property of shallow neural networks. (arXiv:2304.10552v1 [cs.LG])

    [http://arxiv.org/abs/2304.10552](http://arxiv.org/abs/2304.10552)

    本文证明了浅层神经网络可以插值任何数据集，即损失函数具有全局最小值为零的性质，此外还给出了该全局最小值处的惯性矩阵的表征，并提供了一种实用的概率方法来寻找插值点。

    

    我们研究了超参数化神经网络的损失函数全局最小值的几何性质。在大多数优化问题中，损失函数是凸函数，这种情况下我们只有一个全局最小值，或者是非凸函数，在这种情况下我们有一个有限的全局最小值。在本文中，我们证明了在超参数化范围内，对于非小次数多项式的激活函数，浅层神经网络可以插值任何数据集，即损失函数具有全局最小值为零的性质。此外，如果存在这样的全局最小值，则全局最小值的轮廓有无穷多个点。此外，我们给出了在全局最小值处求解损失函数的海塞矩阵的表征，并在最后一节中，我们提供了一种实用的概率方法来寻找插值点。

    We study the geometry of global minima of the loss landscape of overparametrized neural networks. In most optimization problems, the loss function is convex, in which case we only have a global minima, or nonconvex, with a discrete number of global minima. In this paper, we prove that in the overparametrized regime, a shallow neural network can interpolate any data set, i.e. the loss function has a global minimum value equal to zero as long as the activation function is not a polynomial of small degree. Additionally, if such a global minimum exists, then the locus of global minima has infinitely many points. Furthermore, we give a characterization of the Hessian of the loss function evaluated at the global minima, and in the last section, we provide a practical probabilistic method of finding the interpolation point.
    
[^15]: 通过保留谱的数据压缩加速支持向量聚类

    Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])

    [http://arxiv.org/abs/2304.09868](http://arxiv.org/abs/2304.09868)

    本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。

    

    支持向量聚类是一种重要的聚类方法，但是由于其计算昂贵的簇分配步骤，它面临着可伸缩性问题。在本文中，我们通过保留谱的数据压缩来加速支持向量聚类。具体而言，我们将原始数据集压缩成少量谱表示的聚合数据点，然后在压缩后的数据集上执行标准的支持向量聚类，最后将压缩数据集的聚类结果映射回原始数据集以发现簇。我们在真实数据集上的大量实验结果表明，相较于标准支持向量聚类，我们的方法大大提高了速度，而不会损失聚类质量。

    Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
    
[^16]: 无碰撞运输图在流行学习中的应用

    Applications of No-Collision Transportation Maps in Manifold Learning. (arXiv:2304.00199v1 [cs.LG])

    [http://arxiv.org/abs/2304.00199](http://arxiv.org/abs/2304.00199)

    本文研究了在流形学习中应用无碰撞运输图的方法，其可以比OT图更便宜地计算距离，并提供单个概率测度的平移和伸缩的等距性。

    

    本文研究了引入于[Nurbekyan et al.，2020]的无碰撞运输图在图像数据的流形学习中的应用。近年来，在表示类似运动或变形现象的数据中，应用基于运输的距离和特征的研究大幅增加。事实上，固定位置比较强度通常无法显示数据结构。在[Nurbekyan et al.，2020]中开发的无碰撞图和距离类似于最优传输(OT)图的几何特征但由于无需优化，计算成本要便宜得多。本文证明无碰撞距离提供单个概率测度的平移(分别是伸缩)和装备欧几里得距离的平移(分别是伸缩)向量之间的等距性。此外，我们证明，无碰撞运输图以及OT和线性OT图，一般来说不能为旋转提供等距性。

    In this work, we investigate applications of no-collision transportation maps introduced in [Nurbekyan et. al., 2020] in manifold learning for image data. Recently, there has been a surge in applying transportation-based distances and features for data representing motion-like or deformation-like phenomena. Indeed, comparing intensities at fixed locations often does not reveal the data structure. No-collision maps and distances developed in [Nurbekyan et. al., 2020] are sensitive to geometric features similar to optimal transportation (OT) maps but much cheaper to compute due to the absence of optimization. In this work, we prove that no-collision distances provide an isometry between translations (respectively dilations) of a single probability measure and the translation (respectively dilation) vectors equipped with a Euclidean distance. Furthermore, we prove that no-collision transportation maps, as well as OT and linearized OT maps, do not in general provide an isometry for rotatio
    
[^17]: 从CNN到基于复小波的平移不变双模型

    From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets. (arXiv:2212.00394v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00394](http://arxiv.org/abs/2212.00394)

    论文提出了一种消除OCV（Aliasing）的方法，该方法基于复数卷积，同时采用Gabor样式的卷积核，可以提高卷积神经网络的分类准确性。

    

    我们提出了一种新颖的抗混叠方法来增加卷积神经网络中的平移不变性和预测准确性。具体来说，我们用“复值卷积+模运算”（$\mathbb{C}$Mod）代替第一层的“实值卷积+最大池化”（$\mathbb{R}$Max），因为它稳定于平移。为了证明我们的方法，我们声称当卷积核是带通和定向的（类似于Gabor滤波器）时，$\mathbb{C}$Mod和$\mathbb{R}$Max产生可比较的输出。在这种情况下，$\mathbb{C}$Mod可以被认为是$\mathbb{R}$Max的稳定替代品。因此，在抗混叠之前，我们强制卷积核采用这种Gabor样式的结构。相应的架构称为数学双模型，因为它使用一个明确定义的数学运算符来模拟原始的自由训练模型的行为。我们的抗混叠方法在Imagenet和CIFAR-10分类任务上实现了比之前更高的准确性。

    We propose a novel antialiasing method to increase shift invariance and prediction accuracy in convolutional neural networks. Specifically, we replace the first-layer combination "real-valued convolutions + max pooling" ($\mathbb{R}$Max) by "complex-valued convolutions + modulus" ($\mathbb{C}$Mod), which is stable to translations. To justify our approach, we claim that $\mathbb{C}$Mod and $\mathbb{R}$Max produce comparable outputs when the convolution kernel is band-pass and oriented (Gabor-like filter). In this context, $\mathbb{C}$Mod can be considered as a stable alternative to $\mathbb{R}$Max. Thus, prior to antialiasing, we force the convolution kernels to adopt such a Gabor-like structure. The corresponding architecture is called mathematical twin, because it employs a well-defined mathematical operator to mimic the behavior of the original, freely-trained model. Our antialiasing approach achieves superior accuracy on ImageNet and CIFAR-10 classification tasks, compared to prior 
    
[^18]: 稀疏与高三角密度对于图表示学习的影响

    Implications of sparsity and high triangle density for graph representation learning. (arXiv:2210.15277v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.15277](http://arxiv.org/abs/2210.15277)

    稀疏图中的大量三角形可使用无限维度内积模型进行复现，其中节点表示位于低维流形上。虽然全局表示是不可能的，但我们可以在本地邻域缩小规模，以获取较低维度的表示。

    

    最近的研究表明，在包含许多三角形的稀疏图中，无法使用节点的有限维度表示来重现，其中连结概率是内积。在这里，我们展示了这样的图可以使用无限维度的内积模型来复现，其中节点表示位于低维流形上。在稀疏的情况下，恢复流形的全局表示是不可能的。然而，我们可以缩小到本地邻域，在那里较低维度的表示是可能的。由于我们的构造允许点均匀分布在流形上，因此我们发现了反对通常的看法——三角形意味着社区结构。

    Recent work has shown that sparse graphs containing many triangles cannot be reproduced using a finite-dimensional representation of the nodes, in which link probabilities are inner products. Here, we show that such graphs can be reproduced using an infinite-dimensional inner product model, where the node representations lie on a low-dimensional manifold. Recovering a global representation of the manifold is impossible in a sparse regime. However, we can zoom in on local neighbourhoods, where a lower-dimensional representation is possible. As our constructions allow the points to be uniformly distributed on the manifold, we find evidence against the common perception that triangles imply community structure.
    
[^19]: 一种通用偏差-方差分解方法用于预测的不确定性估计

    Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition. (arXiv:2210.12256v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12256](http://arxiv.org/abs/2210.12256)

    本文介绍了一种通用的偏差-方差分解方法，用于估计模型预测的不确定性，这种方法可以用于大多数预测任务，并且可以在多个下游任务中实际使用。

    

    在许多安全关键的应用中，可靠地估计模型生命周期内的预测不确定性至关重要。最常用的衡量方法是通过预测置信度来衡量。虽然这种方法在领域内样本中表现良好，但在领域漂移时这些估计是不可靠的，并且仅限于分类。相反，对于大多数预测任务，可以使用适当的得分，但是当前文献中不存在用于模型不确定性的偏差-方差分解方法。在这项工作中，我们引入了适用于适当得分的通用偏差-方差分解方法，由此引出Bregman信息作为方差项。我们发现指数族和分类对数似然是特殊情况，并提供了新的公式。令人惊讶的是，我们可以纯粹地在logit空间中表示分类情况。我们展示了这种分解方法在多个下游任务中的实际相关性，包括模型集成和置信区间。

    Reliably estimating the uncertainty of a prediction throughout the model lifecycle is crucial in many safety-critical applications. The most common way to measure this uncertainty is via the predicted confidence. While this tends to work well for in-domain samples, these estimates are unreliable under domain drift and restricted to classification. Alternatively, proper scores can be used for most predictive tasks but a bias-variance decomposition for model uncertainty does not exist in the current literature. In this work we introduce a general bias-variance decomposition for proper scores, giving rise to the Bregman Information as the variance term. We discover how exponential families and the classification log-likelihood are special cases and provide novel formulations. Surprisingly, we can express the classification case purely in the logit space. We showcase the practical relevance of this decomposition on several downstream tasks, including model ensembles and confidence regions.
    
[^20]: 差分隐私引导采样：新的隐私分析与推断策略

    Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies. (arXiv:2210.06140v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.06140](http://arxiv.org/abs/2210.06140)

    本文研究了一种差分隐私引导采样方法，提供了隐私成本的新结果，可用于推断样本分布并构建置信区间，同时指出了现有文献中的误用。随着采样次数趋近无限大，此方法逐渐满足更严格的差分隐私要求。

    

    差分隐私机制通过引入随机性来保护个人信息，但在应用中，统计推断仍然缺乏通用技术。本文研究了一个差分隐私引导采样方法，通过发布多个私有引导采样估计来推断样本分布并构建置信区间。我们的隐私分析提供了单个差分隐私引导采样估计的隐私成本新结果，适用于任何差分隐私机制，并指出了现有文献中引导采样的一些误用。使用Gaussian-DP（GDP）框架，我们证明从满足 $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP 的机制中释放 $B$ 个差分隐私引导采样估计，在 $B$ 趋近无限大时渐近地满足 $\mu$-GDP。此外，我们使用差分隐私引导采样估计的反卷积对样本分布进行准确推断。

    Differentially private (DP) mechanisms protect individual-level information by introducing randomness into the statistical analysis procedure. Despite the availability of numerous DP tools, there remains a lack of general techniques for conducting statistical inference under DP. We examine a DP bootstrap procedure that releases multiple private bootstrap estimates to infer the sampling distribution and construct confidence intervals (CIs). Our privacy analysis presents new results on the privacy cost of a single DP bootstrap estimate, applicable to any DP mechanisms, and identifies some misapplications of the bootstrap in the existing literature. Using the Gaussian-DP (GDP) framework (Dong et al.,2022), we show that the release of $B$ DP bootstrap estimates from mechanisms satisfying $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP asymptotically satisfies $\mu$-GDP as $B$ goes to infinity. Moreover, we use deconvolution with the DP bootstrap estimates to accurately infer the sampling distribution
    
[^21]: 基于对数高斯过程的主动学习辅助中子谱学研究

    Active learning-assisted neutron spectroscopy with log-Gaussian processes. (arXiv:2209.00980v3 [physics.data-an] UPDATED)

    [http://arxiv.org/abs/2209.00980](http://arxiv.org/abs/2209.00980)

    本文介绍了一种基于对数高斯过程的概率主动学习方法，该方法可以自主运行并找到具有信息的测量位置，提高中子谱学实验的效率。

    

    三轴谱仪中子散射实验通过测量强度分布来研究磁性和晶格激发，以了解材料特性的来源。由于对TAS实验的高需求和有限可用性，引出了一个自然的问题，即我们是否可以提高其效率，并更好地利用实验者的时间。实际上，有许多科学问题需要寻找信号，如果在不具有信息的区域进行手动测量，则可能耗时且效率低下。本文描述了一种概率主动学习方法，不仅可以自主运行，即无需人工干预，而且可以利用对数高斯过程在数学上和方法上提供具有信息的测量位置。最终，这些成果可以在真实的TAS实验和多种不同基准测试中得到证明。

    Neutron scattering experiments at three-axes spectrometers (TAS) investigate magnetic and lattice excitations by measuring intensity distributions to understand the origins of materials properties. The high demand and limited availability of beam time for TAS experiments however raise the natural question whether we can improve their efficiency and make better use of the experimenter's time. In fact, there are a number of scientific problems that require searching for signals, which may be time consuming and inefficient if done manually due to measurements in uninformative regions. Here, we describe a probabilistic active learning approach that not only runs autonomously, i.e., without human interference, but can also directly provide locations for informative measurements in a mathematically sound and methodologically robust way by exploiting log-Gaussian processes. Ultimately, the resulting benefits can be demonstrated on a real TAS experiment and a benchmark including numerous diffe
    
[^22]: 针对超参数化的非凸Burer-Monteiro分解的预条件梯度下降与全局最优性证明

    Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification. (arXiv:2206.03345v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2206.03345](http://arxiv.org/abs/2206.03345)

    本文提出了一种预条件梯度下降方法，使得超参数化情况下梯度下降的收敛速度恢复到线性，并在保证全局最优性证明有效的同时保持低廉的计算代价，该方法适用于强凸的代价函数 $\phi$。

    

    本文探讨了使用梯度下降优化非凸函数$f(X)=\phi(XX^{T})$的方法，其中 $\phi$是一个平滑凸的$n\times n$矩阵上下文的代价函数。虽然仅有二阶停留点可以在合理时间内被证明找到，但如果 $X$ 的秩缺失，那么它的秩缺失将证明它是全局最优的。这种认证全局最优性的方法必然需要当前迭代$X$的搜索秩 $r$ 超过全局最小化器$X^{\star}$ 的秩$r^{\star}$。不幸的是，超参数化显著减慢了梯度下降的收敛速度，从 $r=r^{\star}$ 时的线性速度降为 $r>r^{\star}$ 时的亚线性速度，即使 $\phi$ 是强凸的情况下也是如此。在本文中，我们提出了一种廉价的预条件梯度下降方法，将超参数化情况下梯度下降的收敛速度恢复到线性，同时保证全局最优性证明依旧有效。这种方法只需要进行简单的矩阵乘法和求逆，并且适用于强凸的$φ$。我们通过仿真实验在合成数据和现实应用中验证了我们提出的方法。

    We consider using gradient descent to minimize the nonconvex function $f(X)=\phi(XX^{T})$ over an $n\times r$ factor matrix $X$, in which $\phi$ is an underlying smooth convex cost function defined over $n\times n$ matrices. While only a second-order stationary point $X$ can be provably found in reasonable time, if $X$ is additionally rank deficient, then its rank deficiency certifies it as being globally optimal. This way of certifying global optimality necessarily requires the search rank $r$ of the current iterate $X$ to be overparameterized with respect to the rank $r^{\star}$ of the global minimizer $X^{\star}$. Unfortunately, overparameterization significantly slows down the convergence of gradient descent, from a linear rate with $r=r^{\star}$ to a sublinear rate when $r>r^{\star}$, even when $\phi$ is strongly convex. In this paper, we propose an inexpensive preconditioner that restores the convergence rate of gradient descent back to linear in the overparameterized case, while
    
[^23]: 拓扑深度学习：超越图数据

    Topological Deep Learning: Going Beyond Graph Data. (arXiv:2206.00606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00606](http://arxiv.org/abs/2206.00606)

    本文提出了一个拓扑深度学习的框架，其中包含组合复合体这一新型拓扑域。组合复合体结合了超图和胞腔复合体的优点，允许构建分层高阶关系。

    

    拓扑深度学习是一个快速发展的领域，与开发支持于拓扑域上的深度学习模型有关，例如单纯复合体、胞腔复合体和超图。这些拓扑域在科学计算中广泛应用。在本文中，我们提出了一个建立在更丰富数据结构之上的统一深度学习框架，包括拓扑域。我们首先介绍组合复合体，这是一种新型的拓扑域。组合复合体可以看作是保持某些理想性质的图的推广。类似于超图，组合复合体对关系集合不施加任何约束。此外，组合复合体允许构建分层高阶关系，类似于单纯和胞腔复合体中的关系。因此，组合复合体推广并结合了超图和胞腔复合体的有用特性。

    Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations. In this paper, we present a unifying deep learning framework built upon a richer data structure that includes widely adopted topological domains.  Specifically, we first introduce combinatorial complexes, a novel type of topological domain. Combinatorial complexes can be seen as generalizations of graphs that maintain certain desirable properties. Similar to hypergraphs, combinatorial complexes impose no constraints on the set of relations. In addition, combinatorial complexes permit the construction of hierarchical higher-order relations, analogous to those found in simplicial and cell complexes. Thus, combinatorial complexes generalize and combine useful traits of both hypergraphs and cell complexes, whi
    
[^24]: 基于Wasserstein梯度流的变分推断

    Variational inference via Wasserstein gradient flows. (arXiv:2205.15902v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.15902](http://arxiv.org/abs/2205.15902)

    本文提出了一种基于Wasserstein梯度流的变分推断方法，该方法使用高斯或高斯混合分布并在处理对数凹 $\pi$ 时具有强大的理论保证。

    

    随着马尔可夫链蒙特卡洛 (MCMC) 方法一起，变分推断（VI）已经成为大规模贝叶斯推断的中心计算方法。VI 不是从真实后验 $\pi$ 中进行采样，而是旨在生成一个简单而有效的近似 $\hat \pi$，使得摘要统计量易于计算。然而，与广为研究的 MCMC 方法不同，VI 的算法保证仍然相对较少被理解。在本工作中，我们提出了基于高斯或高斯混合分布的变分推断方法，这些方法基于高斯测度的Bures-Wasserstein 空间上的梯度流理论。当 $\pi$ 是对数凹的时候，与MCMC类似，该方法具有强大的理论保证。

    Along with Markov chain Monte Carlo (MCMC) methods, variational inference (VI) has emerged as a central computational approach to large-scale Bayesian inference. Rather than sampling from the true posterior $\pi$, VI aims at producing a simple but effective approximation $\hat \pi$ to $\pi$ for which summary statistics are easy to compute. However, unlike the well-studied MCMC methodology, algorithmic guarantees for VI are still relatively less well-understood. In this work, we propose principled methods for VI, in which $\hat \pi$ is taken to be a Gaussian or a mixture of Gaussians, which rest upon the theory of gradient flows on the Bures--Wasserstein space of Gaussian measures. Akin to MCMC, it comes with strong theoretical guarantees when $\pi$ is log-concave.
    
[^25]: 预先训练的感知特征提高差分隐私图像生成的性能

    Pre-trained Perceptual Features Improve Differentially Private Image Generation. (arXiv:2205.12900v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.12900](http://arxiv.org/abs/2205.12900)

    该论文提出了一种利用预先训练的感知特征，通过最小化MMD（最大均值差异）来提高差分隐私图像生成的性能，并成功地生成了CIFAR10级别的图像。

    

    使用差分隐私随机梯度下降（DP-SGD）进行中等规模生成模型的训练非常困难：为了保持合理的隐私水平所需的噪声水平过大。相反，我们建议利用信息丰富的公共数据集上的良好相关表征，然后学习使用该表征模型化私有数据。特别的，我们使用从公共数据集中学习的感知特征的核函数，最小化私有目标数据与生成器分布之间的最大均值差异（MMD）。使用MMD，我们可以一次性对数据相关项进行隐私处理，而无需像DP-SGD一样在优化每一步中引入噪声。我们的算法使我们能够生成CIFAR10级别的图像，其 $\epsilon \approx 2$，捕捉了分布中的独特特征，远远超过当前的技术水平，主要集中于数据集，如MNIST和FashionMNIST 以较大的 $\epsilon$。

    Training even moderately-sized generative models with differentially-private stochastic gradient descent (DP-SGD) is difficult: the required level of noise for reasonable levels of privacy is simply too large. We advocate instead building off a good, relevant representation on an informative public dataset, then learning to model the private data with that representation. In particular, we minimize the maximum mean discrepancy (MMD) between private target data and a generator's distribution, using a kernel based on perceptual features learned from a public dataset. With the MMD, we can simply privatize the data-dependent term once and for all, rather than introducing noise at each step of optimization as in DP-SGD. Our algorithm allows us to generate CIFAR10-level images with $\epsilon \approx 2$ which capture distinctive features in the distribution, far surpassing the current state of the art, which mostly focuses on datasets such as MNIST and FashionMNIST at a large $\epsilon \appro
    
[^26]: 基于回归的投影方法学习Mori-Zwanzig算子

    Regression-based projection for learning Mori-Zwanzig operators. (arXiv:2205.05135v3 [math.DS] UPDATED)

    [http://arxiv.org/abs/2205.05135](http://arxiv.org/abs/2205.05135)

    本文提出了一种采用回归投影方法学习Mori-Zwanzig算子的数据驱动学习方法，具有灵活性强、应用范围广等优点。

    

    我们提出采用统计回归作为投影算子，以实现Mori-Zwanzig形式中算子的数据驱动学习。我们提出了一种提取任何回归模型的马尔可夫和记忆算子的原则性方法。我们展示了线性回归的选择导致一种基于Mori投影算子的高阶近似Koopman学习方法的最近提出的基于数据驱动学习的算法。我们展示了更有表现力的非线性回归模型自然地填补了高度理想化和计算上高效的Mori投影算子与最优但计算不可行的Zwanzig投影算子之间的差距。我们进行了数值实验并提取了一系列基于回归的投影算子的算子，包括线性、多项式、样条和神经网络回归，显示随着回归模型复杂度的提高逐渐改进。我们的方法提供了一种新的灵活的框架，可以用于动力系统和统计物理学中Mori-Zwanzig算子的数据驱动学习，并能应用于广泛领域。

    We propose to adopt statistical regression as the projection operator to enable data-driven learning of the operators in the Mori--Zwanzig formalism. We present a principled method to extract the Markov and memory operators for any regression models. We show that the choice of linear regression results in a recently proposed data-driven learning algorithm based on Mori's projection operator, which is a higher-order approximate Koopman learning method. We show that more expressive nonlinear regression models naturally fill in the gap between the highly idealized and computationally efficient Mori's projection operator and the most optimal yet computationally infeasible Zwanzig's projection operator. We performed numerical experiments and extracted the operators for an array of regression-based projections, including linear, polynomial, spline, and neural-network-based regressions, showing a progressive improvement as the complexity of the regression model increased. Our proposition prov
    
[^27]: 图关系领域适应

    Graph-Relational Domain Adaptation. (arXiv:2202.03628v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.03628](http://arxiv.org/abs/2202.03628)

    本研究使用领域图对领域相邻性进行编码，放宽了领域适应的统一对齐方法，实现了非平凡的对齐，并成功地融合了领域信息。

    

    现有的领域适应方法往往将每个领域等同对待并完美对齐，忽略了不同领域之间的拓扑结构，因此对于相邻领域可能有利，但对于远离领域则可能无益。本文通过使用领域图对领域相邻性进行编码，例如以美国不同州为领域创建的状态图，使得领域可以根据图结构灵活对齐，从而放宽了这种统一的对齐方法。我们使用一种新的图判别器将现有的对抗学习框架进行了推广，并使用编码条件图嵌入。理论分析表明，在均衡状态下，当图是一个团时，我们的方法会恢复经典的领域适应方法，并为其他类型的图实现了非平凡的对齐。实证结果表明，我们的方法可以成功地推广统一的对齐方法，并自然地融合了领域信息。

    Existing domain adaptation methods tend to treat every domain equally and align them all perfectly. Such uniform alignment ignores topological structures among different domains; therefore it may be beneficial for nearby domains, but not necessarily for distant domains. In this work, we relax such uniform alignment by using a domain graph to encode domain adjacency, e.g., a graph of states in the US with each state as a domain and each edge indicating adjacency, thereby allowing domains to align flexibly based on the graph structure. We generalize the existing adversarial learning framework with a novel graph discriminator using encoding-conditioned graph embeddings. Theoretical analysis shows that at equilibrium, our method recovers classic domain adaptation when the graph is a clique, and achieves non-trivial alignment for other types of graphs. Empirical results show that our approach successfully generalizes uniform alignment, naturally incorporates domain information represented b
    
[^28]: 平滑可分非负矩阵分解

    Smoothed Separable Nonnegative Matrix Factorization. (arXiv:2110.05528v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2110.05528](http://arxiv.org/abs/2110.05528)

    该算法基于平滑的可分离性假设，提出一种新的平滑可分非负矩阵分解（SSNMF）算法，能够有效地抵抗在‘纯像素假设’存在的噪声干扰

    

    该论文提出了一种新算法--平滑可分非负矩阵分解（SSNMF），该算法基于一个经过平滑的可分离性假设，被制定为一个凸优化问题来抵抗在‘纯像素假设’存在的情况下噪声的干扰。该算法的有效实施和广泛实验表明，它可以保证在特定噪声水平内收敛到非负矩阵分解，且得出真实顶点。

    Given a set of data points belonging to the convex hull of a set of vertices, a key problem in linear algebra, signal processing, data analysis and machine learning is to estimate these vertices in the presence of noise. Many algorithms have been developed under the assumption that there is at least one nearby data point to each vertex; two of the most widely used ones are vertex component analysis (VCA) and the successive projection algorithm (SPA). This assumption is known as the pure-pixel assumption in blind hyperspectral unmixing, and as the separability assumption in nonnegative matrix factorization. More recently, Bhattacharyya and Kannan (ACM-SIAM Symposium on Discrete Algorithms, 2020) proposed an algorithm for learning a latent simplex (ALLS) that relies on the assumption that there is more than one nearby data point to each vertex. In that scenario, ALLS is probalistically more robust to noise than algorithms based on the separability assumption. In this paper, inspired by A
    
[^29]: 关于线性汤普森抽样的频率后悔问题

    On Frequentist Regret of Linear Thompson Sampling. (arXiv:2006.06790v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.06790](http://arxiv.org/abs/2006.06790)

    本文研究了线性汤普森抽样的频率后悔问题，证明了后验方差膨胀是必需的，并确定了频率后悔的最低下限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$ 。

    

    本文研究随机线性赌博机问题，其中决策者从可能时变的$\mathbb{R}^d$向量集中选择行动并获得噪声奖励。目标是在一系列$T$个决策中最小化后悔，即决策者的累积预期奖励与能够访问每个行动预期奖励的神谕之间的差异。线性汤普森抽样(LinTS)是一种流行的贝叶斯启发式算法，通过理论分析表明其贝叶斯后悔受到$\widetilde{\mathcal{O}}(d\sqrt{T})$的界限约束，达到极小值下限。然而，先前的研究表明，LinTS的频率后悔界限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$，需要后验方差膨胀，并且比最佳基于乐观主义的算法差一个$\sqrt{d}$的因子。我们证明了这种膨胀是基本的，并且频率界限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$是最佳的。

    This paper studies the stochastic linear bandit problem, where a decision-maker chooses actions from possibly time-dependent sets of vectors in $\mathbb{R}^d$ and receives noisy rewards. The objective is to minimize regret, the difference between the cumulative expected reward of the decision-maker and that of an oracle with access to the expected reward of each action, over a sequence of $T$ decisions. Linear Thompson Sampling (LinTS) is a popular Bayesian heuristic, supported by theoretical analysis that shows its Bayesian regret is bounded by $\widetilde{\mathcal{O}}(d\sqrt{T})$, matching minimax lower bounds. However, previous studies demonstrate that the frequentist regret bound for LinTS is $\widetilde{\mathcal{O}}(d\sqrt{dT})$, which requires posterior variance inflation and is by a factor of $\sqrt{d}$ worse than the best optimism-based algorithms. We prove that this inflation is fundamental and that the frequentist bound of $\widetilde{\mathcal{O}}(d\sqrt{dT})$ is the best pos
    
[^30]: 论牛顿筛选法

    On Newton Screening. (arXiv:2001.10616v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2001.10616](http://arxiv.org/abs/2001.10616)

    本文提出了一种称为牛顿筛选法的新型Broad-Newton方法，它带有一个内置的较小的工作集，可用于加速解决大规模稀疏学习问题的一阶方法。

    

    筛选和工作集技术是减小优化问题规模的重要方法，已广泛应用于加速解决大规模稀疏学习问题的一阶方法中。本文提出了一种新的筛选方法，称为牛顿筛选法（NS），它是一种带有内置筛选机制的广义牛顿方法。我们推导了基于等效KKT系统的Lasso模型，利用广义牛顿方法来求解KKT方程组。基于这个KKT系统，首先利用上一次迭代生成的原始和对偶变量之和确定一个具有相对较小大小的内置工作集，然后通过在工作集上求解最小二乘问题来更新原始变量，并基于闭式表达式更新对偶变量。此外，我们提出了一个带有热启动策略的牛顿筛选法的连续版本。我们证明了NS在最优收敛性方面具有优异的性质。

    Screening and working set techniques are important approaches to reducing the size of an optimization problem. They have been widely used in accelerating first-order methods for solving large-scale sparse learning problems. In this paper, we develop a new screening method called Newton screening (NS) which is a generalized Newton method with a built-in screening mechanism. We derive an equivalent KKT system for the Lasso and utilize a generalized Newton method to solve the KKT equations. Based on this KKT system, a built-in working set with a relatively small size is first determined using the sum of primal and dual variables generated from the previous iteration, then the primal variable is updated by solving a least-squares problem on the working set and the dual variable updated based on a closed-form expression. Moreover, we consider a sequential version of Newton screening (SNS) with a warm-start strategy. We show that NS possesses an optimal convergence property in the sense that
    

