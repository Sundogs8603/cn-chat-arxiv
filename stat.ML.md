# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond.](http://arxiv.org/abs/2307.08643) | 该研究提出了一个通用框架，在分布层面上对不同类型的数据污染模型进行了形式化分析，并通过分析贝叶斯风险的变化展示了这些污染对标准监督学习的影响。这些发现为进一步研究提供了新的方向和基础。 |
| [^2] | [Overlapping Batch Confidence Intervals on Statistical Functionals Constructed from Time Series: Application to Quantiles, Optimization, and Estimation.](http://arxiv.org/abs/2307.08609) | 该论文提出了一种基于重叠批次的置信区间过程，适用于构建统计功能，并可以应用于分位数、优化和估计等多种领域。通过假设统计功能的点估计满足中心极限定理，本方法能够识别批次学生化统计量的弱渐近性。 |
| [^3] | [Machine-Learning-based Colorectal Tissue Classification via Acoustic Resolution Photoacoustic Microscopy.](http://arxiv.org/abs/2307.08556) | 通过采用声学分辨率光声显微镜，我们研究了一种基于机器学习的结直肠组织分类方法，能够有效地将良性和恶性组织区分开来。 |
| [^4] | [Results on Counterfactual Invariance.](http://arxiv.org/abs/2307.08519) | 本文对反事实不变性进行了理论分析，研究了其定义、关系及图形意义。研究发现，反事实不变性蕴含条件独立性，而条件独立性对满足反事实不变性的程度或可能性没有影响。离散因果模型中的反事实不变函数通常受到特定变量的限制。 |
| [^5] | [Covariate shift in nonparametric regression with Markovian design.](http://arxiv.org/abs/2307.08517) | 这篇论文通过扩展最近的非参数收敛速度结果，研究了马尔可夫设计下的非参数回归问题中的协变量偏移。作者证明了在回归函数具有H\"older平滑性假设的情况下，Nadaraya-Watson核估计器的泛化风险的收敛速度取决于源和目标马尔可夫链的固有分布之间的相似性，并提出了一个带宽相关的相似性度量来捕捉这种相似性。作者还导出了有限马尔可夫链和谱间隙马尔可夫链的精确收敛速度。 |
| [^6] | [Kernel-Based Testing for Single-Cell Differential Analysis.](http://arxiv.org/abs/2307.08509) | 本论文提出了一种基于核方法的单细胞差异分析测试框架，可以非线性比较复杂的细胞间分子特征分布。通过利用核嵌入的变异性，我们的方法能够揭示细胞群体中隐蔽的异质性。我们展示了核测试如何克服单细胞差异分析方法的局限性，并应用于研究分化逆转的过程。 |
| [^7] | [Can We Trust Race Prediction?.](http://arxiv.org/abs/2307.08496) | 本文研究了在没有敏感的种族和族裔数据的情况下，使用代理模型进行种族预测的问题。研究者训练了一个双向长短时记忆（BiLSTM）模型，并创建了一个集成模型，其在外样本（OOS）F1得分上比文献中表现最好的机器学习模型高出36.8%。此外，还构建了美国最全面的姓氏和名字分布数据库，并提供了第一个高质量的基准数据集，以公正比较现有模型，并帮助未来的模型开发者。 |
| [^8] | [Cross Feature Selection to Eliminate Spurious Interactions and Single Feature Dominance Explainable Boosting Machines.](http://arxiv.org/abs/2307.08485) | 本论文提出了一种交叉特征选择的方法，以消除可解释性增强机器中的虚假相互作用和单个特征主导问题。 |
| [^9] | [Near-Optimal Bounds for Learning Gaussian Halfspaces with Random Classification Noise.](http://arxiv.org/abs/2307.08438) | 该论文研究了在高斯分布下学习具有随机分类噪声的一般半空间的问题，提出了一个近乎最优的算法和统计查询的下界，发现了该问题中的信息计算间隙，并给出了具有两项平方依赖的样本复杂度的计算上高效的学习算法。 |
| [^10] | [Predicting Battery Lifetime Under Varying Usage Conditions from Early Aging Data.](http://arxiv.org/abs/2307.08382) | 本研究通过提取早期寿命中的容量-电压数据的新特征，成功预测了在不同使用条件下的电池寿命。我们的研究结果表明，这些早期特征能够很好地捕捉电池的健康状态和老化模式的变化速率，为电池寿命预测提供了有希望的途径。 |
| [^11] | [Statistical Mechanics of Learning via Reverberation in Bidirectional Associative Memories.](http://arxiv.org/abs/2307.08365) | 通过回声实现异联想学习的统计力学图像，并提供了学习阈值和基态图像的解析相图，恢复了Kosko的存储规则的结果。 |
| [^12] | [Universal Online Learning with Gradual Variations: A Multi-layer Online Ensemble Approach.](http://arxiv.org/abs/2307.08360) | 该论文提出了一种具有两个不同级别自适应性的在线凸优化方法，对不同类型的损失函数具有多种遗憾界，并在分析中直接应用于小损失界。同时，它与对抗性/随机凸优化和博弈论有着深刻的联系。 |
| [^13] | [Zero-th Order Algorithm for Softmax Attention Optimization.](http://arxiv.org/abs/2307.08352) | 这篇论文介绍了一个针对Softmax优化的零阶算法，能够有效地计算大规模语言模型的梯度。 |
| [^14] | [Gaussian processes for Bayesian inverse problems associated with linear partial differential equations.](http://arxiv.org/abs/2307.08343) | 本文针对线性偏微分方程相关的贝叶斯逆问题，提出了使用高斯代理模型的方法，并拓展了Raissi等人（2017）的框架，构建了依赖方程信息的高斯先验，实验证明了其在贝叶斯反演中的优越性。 |
| [^15] | [Complexity Matters: Rethinking the Latent Space for Generative Modeling.](http://arxiv.org/abs/2307.08283) | 本研究从模型复杂性的角度重新思考生成建模的潜在空间，提出了一种新的潜在与数据分布之间的“距离”，并通过该距离的最小化来优化生成器的复杂性。 |
| [^16] | [A Look into Causal Effects under Entangled Treatment in Graphs: Investigating the Impact of Contact on MRSA Infection.](http://arxiv.org/abs/2307.08237) | 本文研究了在图中纠缠治疗的情况下如何估计接触对MRSA感染的因果效应。以往的观察性研究方法忽略了纠缠治疗可能导致因果效应估计的错误。 |
| [^17] | [Learning for Counterfactual Fairness from Observational Data.](http://arxiv.org/abs/2307.08232) | 该论文提出了一种从观测数据中学习反事实公平性的方法。现有方法需要先验人类知识来实现反事实公平性，但在实际场景中，获取这样的知识往往非常困难。这项研究为解决这一问题提供了新的思路。 |
| [^18] | [Multi-Objective Optimization of Performance and Interpretability of Tabular Supervised Machine Learning Models.](http://arxiv.org/abs/2307.08175) | 这个研究提出了一个模型无关的框架，用于优化表格数据的监督式机器学习模型的性能和可解释性。通过将机器学习算法的超参数优化视为多目标优化问题，该框架生成了同时具有高性能和易解释性权衡的多样模型。 |
| [^19] | [Flexible and efficient spatial extremes emulation via variational autoencoders.](http://arxiv.org/abs/2307.08079) | 本文提出了一种新的空间极端值模型，通过集成在变分自动编码器的结构中，可以灵活、高效地模拟具有非平稳相关性的极端事件。实验证明，在时间效率和性能上，相对于传统的贝叶斯推断和许多具有平稳相关性的空间极端值模型，我们的方法具有优势。 |
| [^20] | [Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression.](http://arxiv.org/abs/2307.08044) | 本研究提出了一种深度AFT排名回归模型，用于灵活地进行时间事件建模，从而改善预测性能并减轻严格的假设。 |
| [^21] | [Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields.](http://arxiv.org/abs/2307.08038) | 本文提出了一种名为双变量深度克里金的方法，它利用空间相关的深度神经网络(DNN)和嵌入层以及基于自助法和集成DNN的无分布不确定性量化方法，用于大规模空间插值风场的预测和估计。 |
| [^22] | [Variational Inference with Gaussian Score Matching.](http://arxiv.org/abs/2307.07849) | 本文提出了一种用高斯评分匹配的方法来进行变分推理，通过迭代算法将变分近似与精确后验的评分匹配。当变分分布是高斯分布时，内部优化问题有闭式解。 |
| [^23] | [Minimal Random Code Learning with Mean-KL Parameterization.](http://arxiv.org/abs/2307.07816) | 本文研究了最小随机编码学习（MIRACLE）的两个变体，提出了一种新的参数化方法Mean-KL，在压缩变分贝叶斯神经网络中实现了更快的收敛和良好的预测性能。 |
| [^24] | [Graph Automorphism Group Equivariant Neural Networks.](http://arxiv.org/abs/2307.07810) | 本论文提供了图自同态群等变神经网络的完整特征化，找到了可学习的、线性的层函数之间的矩阵的生成集。 |
| [^25] | [The Interpolating Information Criterion for Overparameterized Models.](http://arxiv.org/abs/2307.07785) | 本文提出了一个插值信息准则，用于过参数化模型的模型选择问题。通过建立贝叶斯对偶形式，该准则将先验选择纳入模型评估，并考虑了先验误设、模型的几何和谱特性。该准则在实证和理论行为方面与已知结果一致。 |
| [^26] | [Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks.](http://arxiv.org/abs/2307.07753) | 本文提出了一种用于神经网络的先验学习方法，通过利用可扩展和结构化的神经网络后验作为推广的信息先验，提高了神经网络的推广和不确定性估计能力。我们的方法在大规模上提供了表达性的概率表示，并产生了非空推广界限。我们的技术贡献是推导出可处理的目标函数，并提出了改进的推广界限计算方法。在经验上，我们证明了该方法在不确定性估计和推广方面的有效性。 |
| [^27] | [A Nearly-Linear Time Algorithm for Structured Support Vector Machines.](http://arxiv.org/abs/2307.07735) | 这篇论文提出了针对结构化支持向量机的接近线性时间算法，解决了二次规划输入规模和解决时间的问题。 |
| [^28] | [Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection.](http://arxiv.org/abs/2307.07726) | 本文通过揭示神经网络模型构建中的样本拆分方法的奥秘，构建了一个理论框架来解释神经网络的有效性。我们的研究结果表明，从样本拆分中得到的最优超参数可以使得神经网络模型最小化预测风险。 |
| [^29] | [Sharp Convergence Rates for Matching Pursuit.](http://arxiv.org/abs/2307.07679) | 本文通过提升现有的下界来匹配最佳上界，对匹配追踪的性能进行了精确描述，并构造了一个最坏情况的字典来证明现有上界的无法改进。 |
| [^30] | [On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms.](http://arxiv.org/abs/2307.07675) | 本研究展示了在多Agent上下文赌博机制中，最突出的上下文赌博算法$\epsilon$-greedy可以进行扩展，以解决同时存在的激励因素、上下文和损坏问题 |
| [^31] | [Efficiently Factorizing Boolean Matrices using Proximal Gradient Descent.](http://arxiv.org/abs/2307.07615) | 通过使用连续松弛和弹性二元正则化器，我们提出了一种用近端梯度下降有效地分解布尔矩阵的方法。我们在合成数据和实际数据上进行了广泛的实验，证明了方法的快速收敛和准确性，优于现有技术，结果易于解释和语义有意义。 |
| [^32] | [Training Discrete Energy-Based Models with Energy Discrepancy.](http://arxiv.org/abs/2307.07595) | 该论文提出了一种用能量差异训练离散能量模型的方法，该方法不依赖于采样策略，通过评估数据点及其扰动对应点的能量函数来实现，能够为各种扰动过程提供理论保证，并在不同数据集上展示了其相对性能。 |
| [^33] | [Sparsified Simultaneous Confidence Intervals for High-Dimensional Linear Models.](http://arxiv.org/abs/2307.07574) | 提出了一种稀疏化同时置信区间的方法，用于高维线性模型的统计推断。通过将某些区间的上下界收缩为零，该方法能够确定不重要的协变量并将其排除在最终模型之外，同时通过其他区间判断出可信和显著的协变量。 |
| [^34] | [Variational Prediction.](http://arxiv.org/abs/2307.07568) | 本文介绍了变分预测这一技术，通过使用变分界直接学习后验预测分布，避免了边缘化成本，并展示了在玩具例子上的实验结果。 |
| [^35] | [Improved Self-Normalized Concentration in Hilbert Spaces: Sublinear Regret for GP-UCB.](http://arxiv.org/abs/2307.07539) | 本文提出了对GP-UCB算法进行改进，使其具有几乎最优的次线性遗憾，并解决了关于遗憾分析的开放问题。 |
| [^36] | [Newell's theory based feature transformations for spatio-temporal traffic prediction.](http://arxiv.org/abs/2307.05949) | 本文提出了一种基于Newell理论的特征转换方法用于时空交通预测，用于改善模型在不同位置的迁移性问题。 |
| [^37] | [Hybrid hidden Markov LSTM for short-term traffic flow prediction.](http://arxiv.org/abs/2307.04954) | 该论文介绍了一种混合隐马尔可夫LSTM模型，用于短期交通流量预测。研究发现，深度学习方法在预测交通变量方面优于传统的参数模型。这种模型结合了循环神经网络和隐马尔可夫模型的优势，能够捕捉交通系统的复杂动态模式和非平稳性。 |
| [^38] | [Beyond Intuition, a Framework for Applying GPs to Real-World Data.](http://arxiv.org/abs/2307.03093) | 提出了一个框架，用于确定高斯过程在实际问题中的适用性，并建立一个稳健且明确的模型。通过对核函数设计和计算可扩展性选项的指导，该框架在冰川高程变化的案例研究中实现了更准确的结果。 |
| [^39] | [Unconstrained Online Learning with Unbounded Losses.](http://arxiv.org/abs/2306.04923) | 本论文提出了一种算法，可用于解决无界域和非Lipschitz损失的在线学习问题，并提供了一个遗憾的度量，以衡量该算法的性能。此外，我们还利用该算法开发了一种新的鞍点优化算法，即使在没有有意义的曲率的情况下，也能够在无界领域中收敛于对偶间隙。最后，我们提供了一种算法，在无界域和非Lipschitz损失的情况下实现了非平凡的动态遗憾，以及相匹配的下界。 |
| [^40] | [Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya.](http://arxiv.org/abs/2305.19779) | 本研究提出了一种利用aggVAE进行深度学习和MCMC处理行政边界变化的解决方案，可以更准确地映射以县为层级的聚合级别数据，并处理行政边界的变化，相比最先进的模型表现更好。 |
| [^41] | [Optimal Preconditioning and Fisher Adaptive Langevin Sampling.](http://arxiv.org/abs/2305.14442) | 通过最优预条件和费舍尔自适应 Langevin 采样，提出了一种计算有效且在高维中非常强健的自适应 MCMC 方案。 |
| [^42] | [Sustainable Edge Intelligence Through Energy-Aware Early Exiting.](http://arxiv.org/abs/2305.14094) | 本文提出了能量自适应动态早期退出机制，通过能量感知的策略，在EH边缘设备中实现了高效准确推理。 |
| [^43] | [Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation.](http://arxiv.org/abs/2304.13016) | 研究了比例渐近情形下的子采样岭回归集成，证明了最优全岭回归集成的风险与最优岭预测器的风险相匹配，并证明了GCV在估计岭回归集合的预测风险方面的强一致性。 |
| [^44] | [Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness.](http://arxiv.org/abs/2303.17765) | 本文提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置。 |
| [^45] | [Batch Updating of a Posterior Tree Distribution over a Meta-Tree.](http://arxiv.org/abs/2303.09705) | 本文提出了一个更高效的批量更新方法，用于在元树上计算后验分布。 |
| [^46] | [Learning to Reconstruct Signals From Binary Measurements.](http://arxiv.org/abs/2303.08691) | 该论文提出了一种新的自监督学习方法SSBM，它只需要二进制数据进行训练，并探索了从不完整的二进制观察中学习的极端情况。这为从二进制测量中恢复信号提供了必要和充分条件，并在一系列真实数据集上展示了SSBM的卓越表现。 |
| [^47] | [Modulated Neural ODEs.](http://arxiv.org/abs/2302.13262) | 变调神经ODEs （MoNODEs）是一种新的框架，能够将动力学状态与基础静态变化因素分开，并改进了现有的神经ODE方法。该方法通过引入时间不变的调制变量来捕捉轨迹间的变化，并在测试中展现出在振荡系统、视频和人类行走轨迹等方面具有提高模型泛化能力的效果。 |
| [^48] | [Stochastic Approximation Beyond Gradient for Signal Processing and Machine Learning.](http://arxiv.org/abs/2302.11147) | 本文介绍了随机逼近算法在信号处理和机器学习中的非随机梯度视角，提出了一个通用框架来统一现有的SA理论，包括非渐近和渐近收敛结果。 |
| [^49] | [Free-Form Variational Inference for Gaussian Process State-Space Models.](http://arxiv.org/abs/2302.09921) | 本文提出了一种自由形式的变分推断方法，用于高斯过程状态空间模型（GPSSMs）。该方法克服了以前方法的缺点，并展示了在计算效率和推断准确性上的优势。 |
| [^50] | [PAC-Bayesian Generalization Bounds for Adversarial Generative Models.](http://arxiv.org/abs/2302.08942) | 将PAC-Bayesian理论扩展到生成模型，为基于Wasserstein距离和总变差距离的模型提供了泛化界，为Wasserstein GAN和Energy-Based GAN提供了新的训练目标，并在合成数据集上展示出非虚空泛化界。 |
| [^51] | [A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models.](http://arxiv.org/abs/2302.06235) | 这项工作提出了一种简单的零样本提示加权技术，通过提示集成来自动化提示工程，从而提高文本-图像模型的零样本分类准确性。 |
| [^52] | [Robust empirical risk minimization via Newton's method.](http://arxiv.org/abs/2301.13192) | 本研究提出了一种鲁棒经验风险最小化的新的牛顿方法变种，并通过使用鲁棒估计方法来替换梯度和海森矩阵，证明了连续迭代收敛到种群水平最小化器周围小球。该方法在广义线性模型中的应用具有潜在的优势，并提出了一种基于共轭梯度方法的算法来获取鲁棒牛顿方向。 |
| [^53] | [Understanding Best Subset Selection: A Tale of Two C(omplex)ities.](http://arxiv.org/abs/2301.06259) | 本文研究了最佳子集选择在高维稀疏线性回归设置中的变量选择性质，通过研究残差化特征和虚假投影的复杂性来揭示模型一致性的边界条件。 |
| [^54] | [Near-Optimal Non-Parametric Sequential Tests and Confidence Sequences with Possibly Dependent Observations.](http://arxiv.org/abs/2212.14411) | 本文研究了非参数顺序检验和置信区间，在一般非参数数据生成过程下提供了类型I错误和期望拒绝时间保证，提高了其灵活性和性能。 |
| [^55] | [PAC-Bayes Bounds for Bandit Problems: A Survey and Experimental Comparison.](http://arxiv.org/abs/2211.16110) | 这项调查研究了PAC-Bayes在Bandit问题中的应用，提供了界限的概述，并进行了实验比较。研究发现，PAC-Bayes界限是设计具有性能保证的离线Bandit算法的有用工具，但在线Bandit算法缺乏足够的数据以产生强大的性能保证。 |
| [^56] | [Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov Spaces.](http://arxiv.org/abs/2211.14400) | 该论文研究了在Sobolev和Besov空间中，使用ReLU激活函数的深度神经网络能够以怎样的参数效率逼近函数，包括$L_p(\Omega)$范数下的误差度量。我们提供了所有$1\leq p,q \leq \infty$和$s>0$的完整解决方案，并引入了一种新的位提取技术来获得尖锐的上界。 |
| [^57] | [A Unified Perspective on Natural Gradient Variational Inference with Gaussian Mixture Models.](http://arxiv.org/abs/2209.11533) | 本论文提出了一种统一的视角来理解使用高斯混合模型进行自然梯度变分推断的方法。研究发现，VIPS和iBayes-GMM这两种目前最有效的方法，在更新各个组件和权重时使用的自然梯度更新是等价的，但其实现和理论保证存在差异。研究还发现，这两种方法在样本选择、自然梯度估计、步长适应以及可信区域或组件数量的调整等设计选择上存在区别，对于学习近似的质量有重要影响。 |
| [^58] | [Kernel Learning for Explainable Climate Science.](http://arxiv.org/abs/2209.04947) | 本文通过使用具有结构化非平稳核的高斯过程来模拟上游印度河流域的降水模式，解决了对该地区复杂时空降水分布的理解不足的问题。 |
| [^59] | [A Bayesian Bradley-Terry model to compare multiple ML algorithms on multiple data sets.](http://arxiv.org/abs/2208.04935) | 本文提出了一种基于贝叶斯模型的Bradley-Terry模型，用于比较多个机器学习算法在多个数据集上的性能，与传统方法不同，贝叶斯方法能提供更细致的算法之间差异描述，并允许对等效性进行定义。 |
| [^60] | [Predicting Out-of-Domain Generalization with Neighborhood Invariance.](http://arxiv.org/abs/2207.02093) | 提出了一种测量分类器输出在局部转换邻域中不变性的方法，用于描述模型的泛化能力，不依赖于数据分布或模型假设，可应用于域外环境。 |
| [^61] | [SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks.](http://arxiv.org/abs/2206.05794) | 使用SGD和权重衰减训练深度ReLU神经网络会导致对于权重矩阵的秩最小化的偏差，特别是在使用较小批量大小、更高学习率或增加权重衰减时更为显著。此外，在中间神经网络崩溃时，学习的权重特别低秩。这种偏差与泛化之间存在关系。 |
| [^62] | [Information-Directed Selection for Top-Two Algorithms.](http://arxiv.org/abs/2205.12086) | 本文研究了多臂赌博机中最佳k臂识别问题，提出了一种信息导向选择的算法（IDS），并证明了与IDS集成的顶部两个汤姆逊采样在高斯最佳臂识别中达到了最优。 |
| [^63] | [Logarithmic regret bounds for continuous-time average-reward Markov decision processes.](http://arxiv.org/abs/2205.11168) | 这项研究考虑了连续时间马尔可夫决策过程（MDPs）的平均奖励设置下的强化学习问题，并找到了实例相关的对数遗憾下界，并设计出了一个能够实现对数增长速率的学习算法。 |
| [^64] | [Non-Stationary Bandit Learning via Predictive Sampling.](http://arxiv.org/abs/2205.01970) | 本文提出了一种预测抽样算法，用于解决非平稳赌博机学习问题。该算法通过降低获取信息的优先级，解决了Thompson抽样在非平稳环境下表现不佳的问题，并在所有非平稳环境中优于Thompson抽样。 |
| [^65] | [A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit.](http://arxiv.org/abs/2202.05767) | 本研究通过关联线性热方程的解，得到了对称双臂伯努利赌博机问题的minmax最优遗憾和伪遗憾的领先项。新的结果改进了先前的研究，并提供了新的非渐近边界。 |
| [^66] | [Conjecturing-Based Discovery of Patterns in Data.](http://arxiv.org/abs/2011.11576) | 本研究提出了一种基于猜想的数据模式发现方法，在数值特征和分类特征之间建立了非线性和布尔关系，并应用于COVID-19患者级别数据，揭示了可能的风险因素。 |
| [^67] | [Semi-Supervised Learning: the Case When Unlabeled Data is Equally Useful.](http://arxiv.org/abs/2005.11018) | 本文研究了半监督学习中未标记数据与标记数据在学习速度方面的关系，并发现在特定条件下，未标记数据在学习速度上同样有用。 |
| [^68] | [MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning.](http://arxiv.org/abs/1909.07750) | MDP Playground是一个用于强化学习的测试平台，可以根据不同维度的难度控制方式，挑战代理在各种环境中的表现。它提供了参数化的玩具环境集合，并通过实验揭示了这些环境对代理的影响。 |
| [^69] | [Stochastic Gradient MCMC for Nonlinear State Space Models.](http://arxiv.org/abs/1901.10568) | 该论文提出了一种针对非线性状态空间模型的随机梯度MCMC方法，通过扩展已有方法，利用粒子缓冲随机梯度估计量解决了长时间序列下计算和粒子退化的问题。 |

# 详细

[^1]: 一个学习受到污染的通用框架：标签噪声、属性噪声等等

    A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond. (arXiv:2307.08643v1 [cs.LG])

    [http://arxiv.org/abs/2307.08643](http://arxiv.org/abs/2307.08643)

    该研究提出了一个通用框架，在分布层面上对不同类型的数据污染模型进行了形式化分析，并通过分析贝叶斯风险的变化展示了这些污染对标准监督学习的影响。这些发现为进一步研究提供了新的方向和基础。

    

    数据中的污染现象很常见，并且已经在不同的污染模型下进行了广泛研究。尽管如此，对于这些模型之间的关系仍然了解有限，缺乏对污染及其对学习的影响的统一视角。在本研究中，我们通过基于马尔可夫核的一般性和详尽的框架，在分布层面上正式分析了污染模型。我们强调了标签和属性上存在的复杂联合和依赖性污染，这在现有研究中很少触及。此外，我们通过分析贝叶斯风险变化来展示这些污染如何影响标准的监督学习。我们的发现提供了对于“更复杂”污染对学习问题影响的定性洞察，并为未来的定量比较提供了基础。该框架的应用包括污染校正学习，其中包含一个子案例。

    Corruption is frequently observed in collected data and has been extensively studied in machine learning under different corruption models. Despite this, there remains a limited understanding of how these models relate such that a unified view of corruptions and their consequences on learning is still lacking. In this work, we formally analyze corruption models at the distribution level through a general, exhaustive framework based on Markov kernels. We highlight the existence of intricate joint and dependent corruptions on both labels and attributes, which are rarely touched by existing research. Further, we show how these corruptions affect standard supervised learning by analyzing the resulting changes in Bayes Risk. Our findings offer qualitative insights into the consequences of "more complex" corruptions on the learning problem, and provide a foundation for future quantitative comparisons. Applications of the framework include corruption-corrected learning, a subcase of which we 
    
[^2]: 时间序列构建的统计功能的重叠批次置信区间：应用于分位数、优化和估计

    Overlapping Batch Confidence Intervals on Statistical Functionals Constructed from Time Series: Application to Quantiles, Optimization, and Estimation. (arXiv:2307.08609v1 [math.ST])

    [http://arxiv.org/abs/2307.08609](http://arxiv.org/abs/2307.08609)

    该论文提出了一种基于重叠批次的置信区间过程，适用于构建统计功能，并可以应用于分位数、优化和估计等多种领域。通过假设统计功能的点估计满足中心极限定理，本方法能够识别批次学生化统计量的弱渐近性。

    

    我们提出了一种基于平稳时间序列数据构建的统计功能的通用置信区间过程（CIP）。我们提出的方法是基于推导出的$\chi^2$和学生t分布的统计功能上的无分布模拟的变量，因此适用于包括分位数估计、梯度估计、M估计、CVAR估计和到达过程速率估计在内的各种设置，除了传统的统计设置。与次抽样方法类似，我们使用重叠的时间序列批次来估计潜在的方差参数；然而，与次抽样和自助法不同，我们假设统计功能的暗指点估计符合中心极限定理（CLT），以帮助识别批量学生化统计量的弱渐近性（称为OB-x极限，x=I,II,III）。OB-x极限是由Wiener过程的某些功能参数化所得。

    We propose a general purpose confidence interval procedure (CIP) for statistical functionals constructed using data from a stationary time series. The procedures we propose are based on derived distribution-free analogues of the $\chi^2$ and Student's $t$ random variables for the statistical functional context, and hence apply in a wide variety of settings including quantile estimation, gradient estimation, M-estimation, CVAR-estimation, and arrival process rate estimation, apart from more traditional statistical settings. Like the method of subsampling, we use overlapping batches of time series data to estimate the underlying variance parameter; unlike subsampling and the bootstrap, however, we assume that the implied point estimator of the statistical functional obeys a central limit theorem (CLT) to help identify the weak asymptotics (called OB-x limits, x=I,II,III) of batched Studentized statistics. The OB-x limits, certain functionals of the Wiener process parameterized by the siz
    
[^3]: 基于机器学习的声学分辨率光声显微镜的结直肠组织分类

    Machine-Learning-based Colorectal Tissue Classification via Acoustic Resolution Photoacoustic Microscopy. (arXiv:2307.08556v1 [stat.ML])

    [http://arxiv.org/abs/2307.08556](http://arxiv.org/abs/2307.08556)

    通过采用声学分辨率光声显微镜，我们研究了一种基于机器学习的结直肠组织分类方法，能够有效地将良性和恶性组织区分开来。

    

    结直肠癌是一种致命的疾病，在近年来日益普遍。早期检测对于挽救生命至关重要，但传统的诊断方法如结肠镜检查和活检存在局限性。结肠镜无法提供癌症影响组织内详细信息，而活检涉及组织切除，可能引起疼痛和侵袭性。为了提高诊断效率和减少患者痛苦，我们研究了一种基于机器学习的声学分辨率光声显微镜 (ARPAM) 的结直肠组织分类方法。使用这种工具，我们能够使用多种机器学习方法对良性和恶性组织进行分类。我们的结果通过定量和定性分析，评估了我们方法的有效性。

    Colorectal cancer is a deadly disease that has become increasingly prevalent in recent years. Early detection is crucial for saving lives, but traditional diagnostic methods such as colonoscopy and biopsy have limitations. Colonoscopy cannot provide detailed information within the tissues affected by cancer, while biopsy involves tissue removal, which can be painful and invasive. In order to improve diagnostic efficiency and reduce patient suffering, we studied machine-learningbased approach for colorectal tissue classification that uses acoustic resolution photoacoustic microscopy (ARPAM). With this tool, we were able to classify benign and malignant tissue using multiple machine learning methods. Our results were analyzed both quantitatively and qualitatively to evaluate the effectiveness of our approach.
    
[^4]: 关于反事实不变性的结果

    Results on Counterfactual Invariance. (arXiv:2307.08519v1 [cs.LG])

    [http://arxiv.org/abs/2307.08519](http://arxiv.org/abs/2307.08519)

    本文对反事实不变性进行了理论分析，研究了其定义、关系及图形意义。研究发现，反事实不变性蕴含条件独立性，而条件独立性对满足反事实不变性的程度或可能性没有影响。离散因果模型中的反事实不变函数通常受到特定变量的限制。

    

    本文对反事实不变性进行了理论分析。我们介绍了各种现有定义，研究了它们之间的关系以及它们的图形意义。然后我们转向反事实不变性围绕的主要问题，即它与条件独立性的关系如何？我们显示，虽然反事实不变性蕴含条件独立性，但条件独立性对满足反事实不变性的程度或可能性没有任何影响。此外，我们还显示对于离散因果模型，反事实不变的函数通常受到特定变量的限制，甚至是常数函数。

    In this paper we provide a theoretical analysis of counterfactual invariance. We present a variety of existing definitions, study how they relate to each other and what their graphical implications are. We then turn to the current major question surrounding counterfactual invariance, how does it relate to conditional independence? We show that whilst counterfactual invariance implies conditional independence, conditional independence does not give any implications about the degree or likelihood of satisfying counterfactual invariance. Furthermore, we show that for discrete causal models counterfactually invariant functions are often constrained to be functions of particular variables, or even constant.
    
[^5]: 非参数回归中具有马尔可夫设计的协变量偏移

    Covariate shift in nonparametric regression with Markovian design. (arXiv:2307.08517v1 [math.ST])

    [http://arxiv.org/abs/2307.08517](http://arxiv.org/abs/2307.08517)

    这篇论文通过扩展最近的非参数收敛速度结果，研究了马尔可夫设计下的非参数回归问题中的协变量偏移。作者证明了在回归函数具有H\"older平滑性假设的情况下，Nadaraya-Watson核估计器的泛化风险的收敛速度取决于源和目标马尔可夫链的固有分布之间的相似性，并提出了一个带宽相关的相似性度量来捕捉这种相似性。作者还导出了有限马尔可夫链和谱间隙马尔可夫链的精确收敛速度。

    

    在机器学习中，回归问题中的协变量偏移和训练数据与测试数据之间的分布不匹配是一种常见现象。在本文中，我们将最近关于独立同分布数据的非参数收敛速度结果扩展到马尔可夫依赖结构。我们证明，在对回归函数进行H\"older平滑性假设的情况下，Nadaraya-Watson核估计器的泛化风险的收敛速度由源和目标马尔可夫链的固有分布之间的相似性决定。这种相似性可以明确地用最近Pathak、Ma和Wainwright [ICML，2022]中引入的一个依赖于带宽的相似性度量来捕捉。对于有限马尔可夫链和谱间隙马尔可夫链的特殊情况，导出了精确的收敛速度，其中其固有分布之间的相似性度量随着带宽的减小而多项式增长。对于后者，我们扩展了...

    Covariate shift in regression problems and the associated distribution mismatch between training and test data is a commonly encountered phenomenon in machine learning. In this paper, we extend recent results on nonparametric convergence rates for i.i.d. data to Markovian dependence structures. We demonstrate that under H\"older smoothness assumptions on the regression function, convergence rates for the generalization risk of a Nadaraya-Watson kernel estimator are determined by the similarity between the invariant distributions associated to source and target Markov chains. The similarity is explicitly captured in terms of a bandwidth-dependent similarity measure recently introduced in Pathak, Ma and Wainwright [ICML, 2022]. Precise convergence rates are derived for the particular cases of finite Markov chains and spectral gap Markov chains for which the similarity measure between their invariant distributions grows polynomially with decreasing bandwidth. For the latter, we extend the
    
[^6]: 基于核方法的单细胞差异分析测试

    Kernel-Based Testing for Single-Cell Differential Analysis. (arXiv:2307.08509v1 [stat.ML])

    [http://arxiv.org/abs/2307.08509](http://arxiv.org/abs/2307.08509)

    本论文提出了一种基于核方法的单细胞差异分析测试框架，可以非线性比较复杂的细胞间分子特征分布。通过利用核嵌入的变异性，我们的方法能够揭示细胞群体中隐蔽的异质性。我们展示了核测试如何克服单细胞差异分析方法的局限性，并应用于研究分化逆转的过程。

    

    单细胞技术为我们提供了关于基因表达和表观遗传修饰等分子特征的宝贵信息。然而，以控制和强有力的方式比较这些复杂分布面临着方法论上的挑战。本文提出利用基于核嵌入的核测试框架来非线性比较细胞间复杂分子特征的分布。我们的框架不仅允许对特征进行分析，还能在考虑了它们之间复杂依赖关系的情况下进行转录组或表观组的全局比较。通过使用分类器基于核嵌入的变异性来区分细胞，我们的方法可以发现在细胞群体中原本无法察觉到的异质性。我们展示了核测试方法如何克服专门用于单细胞的差异分析方法的局限性。我们还将核测试应用于研究分化逆转的过程。

    Single-cell technologies have provided valuable insights into the distribution of molecular features, such as gene expression and epigenomic modifications. However, comparing these complex distributions in a controlled and powerful manner poses methodological challenges. Here we propose to benefit from the kernel-testing framework to compare the complex cell-wise distributions of molecular features in a non-linear manner based on their kernel embedding. Our framework not only allows for feature-wise analyses but also enables global comparisons of transcriptomes or epigenomes, considering their intricate dependencies. By using a classifier to discriminate cells based on the variability of their embedding, our method uncovers heterogeneities in cell populations that would otherwise go undetected. We show that kernel testing overcomes the limitations of differential analysis methods dedicated to single-cell. Kernel testing is applied to investigate the reversion process of differentiating
    
[^7]: 我们能相信种族预测吗？

    Can We Trust Race Prediction?. (arXiv:2307.08496v1 [cs.LG])

    [http://arxiv.org/abs/2307.08496](http://arxiv.org/abs/2307.08496)

    本文研究了在没有敏感的种族和族裔数据的情况下，使用代理模型进行种族预测的问题。研究者训练了一个双向长短时记忆（BiLSTM）模型，并创建了一个集成模型，其在外样本（OOS）F1得分上比文献中表现最好的机器学习模型高出36.8%。此外，还构建了美国最全面的姓氏和名字分布数据库，并提供了第一个高质量的基准数据集，以公正比较现有模型，并帮助未来的模型开发者。

    

    在没有敏感的种族和族裔数据的情况下，研究人员、监管机构和公司都借助代理模型。在本文中，我使用来自美国50个州的选民注册数据训练了一个双向长短时记忆（BiLSTM）模型，并创建了一个集成模型，其在外样本（OOS）F1得分上比文献中表现最好的机器学习模型高出36.8%。此外，我构建了美国最全面的姓氏和名字分布数据库，以改进贝叶斯改进姓氏地理编码（BISG）和贝叶斯改进名字姓氏地理编码（BIFSG）的覆盖和准确性。最后，我提供了第一个高质量的基准数据集，以公正比较现有模型，并帮助未来的模型开发者。

    In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies. In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature. Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG). Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers.
    
[^8]: 交叉特征选择以消除虚假相互作用和单个特征主导的可解释性增强机器

    Cross Feature Selection to Eliminate Spurious Interactions and Single Feature Dominance Explainable Boosting Machines. (arXiv:2307.08485v1 [stat.ML])

    [http://arxiv.org/abs/2307.08485](http://arxiv.org/abs/2307.08485)

    本论文提出了一种交叉特征选择的方法，以消除可解释性增强机器中的虚假相互作用和单个特征主导问题。

    

    解释性是机器学习模型的一个重要方面，它使人们能够理解和信任这些模型的决策过程。在许多现实应用中，模型的解释性对于法律、道德和实际原因来说都是至关重要的。例如，在银行领域，解释性对于借款人和贷款人来理解贷款申请的接受或拒绝背后的原因至关重要，因为这涉及到公平贷款法。然而，在复杂的高性能模型中实现解释性是具有挑战性的。因此，可解释性增强机器（EBM）由于其可解释性和高性能在各种预测任务中变得越来越受欢迎。然而，这些模型可能存在与冗余特征的虚假相互作用和单个特征在所有相互作用中的主导地位等问题，这可能影响模型预测的解释性和可靠性。

    Interpretability is a crucial aspect of machine learning models that enables humans to understand and trust the decision-making process of these models. In many real-world applications, the interpretability of models is essential for legal, ethical, and practical reasons. For instance, in the banking domain, interpretability is critical for lenders and borrowers to understand the reasoning behind the acceptance or rejection of loan applications as per fair lending laws. However, achieving interpretability in machine learning models is challenging, especially for complex high-performance models. Hence Explainable Boosting Machines (EBMs) have been gaining popularity due to their interpretable and high-performance nature in various prediction tasks. However, these models can suffer from issues such as spurious interactions with redundant features and single-feature dominance across all interactions, which can affect the interpretability and reliability of the model's predictions. In this
    
[^9]: 学习具有随机分类噪声的高斯半空间的近似最优界限

    Near-Optimal Bounds for Learning Gaussian Halfspaces with Random Classification Noise. (arXiv:2307.08438v1 [cs.LG])

    [http://arxiv.org/abs/2307.08438](http://arxiv.org/abs/2307.08438)

    该论文研究了在高斯分布下学习具有随机分类噪声的一般半空间的问题，提出了一个近乎最优的算法和统计查询的下界，发现了该问题中的信息计算间隙，并给出了具有两项平方依赖的样本复杂度的计算上高效的学习算法。

    

    我们研究了在高斯分布下学习一般（不一定是齐次的）具有随机分类噪声的半空间的问题。我们建立了一致的算法性和统计查询（SQ）下界结果，揭示了这个基本问题中令人惊讶的信息计算间隙。具体而言，这个学习问题的样本复杂度是$\widetilde{\Theta}(d/\epsilon)$，其中$d$是维度，$\epsilon$是过量误差。我们的正面结果是一个计算上高效的学习算法，样本复杂度为$\tilde{O}(d/\epsilon + d/(\max\{p, \epsilon\})^2)$，其中$p$量化了目标半空间的偏差。在下界方面，我们表明任何有效的SQ算法（或低次检验）对于该问题至少需要样本复杂度为$\Omega(d^{1/2}/(\max\{p, \epsilon\})^2)$。我们的下界结果表明，这种对$1/\epsilon$的二次依赖性在有效算法中是固有的。

    We study the problem of learning general (i.e., not necessarily homogeneous) halfspaces with Random Classification Noise under the Gaussian distribution. We establish nearly-matching algorithmic and Statistical Query (SQ) lower bound results revealing a surprising information-computation gap for this basic problem. Specifically, the sample complexity of this learning problem is $\widetilde{\Theta}(d/\epsilon)$, where $d$ is the dimension and $\epsilon$ is the excess error. Our positive result is a computationally efficient learning algorithm with sample complexity $\tilde{O}(d/\epsilon + d/(\max\{p, \epsilon\})^2)$, where $p$ quantifies the bias of the target halfspace. On the lower bound side, we show that any efficient SQ algorithm (or low-degree test) for the problem requires sample complexity at least $\Omega(d^{1/2}/(\max\{p, \epsilon\})^2)$. Our lower bound suggests that this quadratic dependence on $1/\epsilon$ is inherent for efficient algorithms.
    
[^10]: 从早期老化数据中预测不同使用条件下的电池寿命

    Predicting Battery Lifetime Under Varying Usage Conditions from Early Aging Data. (arXiv:2307.08382v1 [cs.LG])

    [http://arxiv.org/abs/2307.08382](http://arxiv.org/abs/2307.08382)

    本研究通过提取早期寿命中的容量-电压数据的新特征，成功预测了在不同使用条件下的电池寿命。我们的研究结果表明，这些早期特征能够很好地捕捉电池的健康状态和老化模式的变化速率，为电池寿命预测提供了有希望的途径。

    

    精确的电池寿命预测对于预防性维护、保修和改进的电池设计和制造非常重要。然而，制造可变性和使用依赖性降解使得寿命预测变得具有挑战性。本研究通过从早期寿命中提取的容量-电压数据的新特征来预测在充电速率、放电速率和放电深度差异较大的电池的寿命。这些特征是从定期安排的参考性能测试中提取的（即低速完全循环）。早期生命周期特征捕捉到了电池的健康状态和各组件级别老化模式的变化速率，其中一些与电池寿命呈强相关性。通过对由225个镍-锰-钴/石墨锂离子电池在广泛条件下老化产生的新数据集的使用，我们证明了在分布内的电池的寿命预测能够达到15.1%的平均绝对百分比误差，并且只使用了前15%的数据。

    Accurate battery lifetime prediction is important for preventative maintenance, warranties, and improved cell design and manufacturing. However, manufacturing variability and usage-dependent degradation make life prediction challenging. Here, we investigate new features derived from capacity-voltage data in early life to predict the lifetime of cells cycled under widely varying charge rates, discharge rates, and depths of discharge. Features were extracted from regularly scheduled reference performance tests (i.e., low rate full cycles) during cycling. The early-life features capture a cell's state of health and the rate of change of component-level degradation modes, some of which correlate strongly with cell lifetime. Using a newly generated dataset from 225 nickel-manganese-cobalt/graphite Li-ion cells aged under a wide range of conditions, we demonstrate a lifetime prediction of in-distribution cells with 15.1% mean absolute percentage error using no more than the first 15% of data
    
[^11]: 通过回声在双向关联记忆中学习的统计力学

    Statistical Mechanics of Learning via Reverberation in Bidirectional Associative Memories. (arXiv:2307.08365v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2307.08365](http://arxiv.org/abs/2307.08365)

    通过回声实现异联想学习的统计力学图像，并提供了学习阈值和基态图像的解析相图，恢复了Kosko的存储规则的结果。

    

    我们研究了双向关联神经网络，在暴露于大量随机原型的噪声示例时，学习这些原型（有或无教师的情况下）时，当提供的信息足够时：在这种设置中，学习是异联想的 - 包括模式对 - 并通过将从示例中描绘的信息通过网络的层次进行回声实现。通过调整Guerra的插值技术，我们在复制对称的描述级别上提供了一个完整的统计力学图像，获得了解析相图、学习的阈值、与Monte Carlo模拟和信噪比结果完全一致的基态图像。在大数据集限制下，Kosko的存储规则以及Kurchan、Peliti和Saber在80年代提供的统计力学图像得到了完全恢复。计算优势在...

    We study bi-directional associative neural networks that, exposed to noisy examples of an extensive number of random archetypes, learn the latter (with or without the presence of a teacher) when the supplied information is enough: in this setting, learning is heteroassociative -- involving couples of patterns -and it is achieved by reverberating the information depicted from the examples through the layers of the network. By adapting Guerra's interpolation technique, we provide a full statistical mechanical picture of supervised and unsupervised learning processes (at the replica symmetric level of description) obtaining analytically phase diagrams, thresholds for learning, a picture of the ground-state in plain agreement with Monte Carlo simulations and signal-to-noise outcomes. In the large dataset limit, the Kosko storage prescription as well as its statistical mechanical picture provided by Kurchan, Peliti, and Saber in the eighties is fully recovered. Computational advantages in
    
[^12]: 具有逐渐变化的通用在线学习：一种多层在线集成方法

    Universal Online Learning with Gradual Variations: A Multi-layer Online Ensemble Approach. (arXiv:2307.08360v1 [cs.LG])

    [http://arxiv.org/abs/2307.08360](http://arxiv.org/abs/2307.08360)

    该论文提出了一种具有两个不同级别自适应性的在线凸优化方法，对不同类型的损失函数具有多种遗憾界，并在分析中直接应用于小损失界。同时，它与对抗性/随机凸优化和博弈论有着深刻的联系。

    

    在本文中，我们提出了一种具有两个不同级别自适应性的在线凸优化方法。在更高级别上，我们的方法对损失函数的具体类型和曲率不知情，而在更低级别上，它可以利用环境的良好性质并获得问题相关保证。具体而言，对于强凸、指数凹和凸损失函数，我们分别获得了$O(\ln V_T)$、$O(d \ln V_T)$和$\hat{O}(\sqrt{V_T})$的遗憾界，其中$d$是维度，$V_T$表示问题相关的梯度变化，$\hat{O}(\cdot)$表示在$V_T$上省略对数因子。我们的结果具有广泛的影响和应用。它不仅保证了最坏情况下的性能，还直接导出了分析中的小损失界。此外，它与对抗性/随机凸优化和博弈论有着深刻的联系，进一步验证了其实际潜力。我们的方法基于...

    In this paper, we propose an online convex optimization method with two different levels of adaptivity. On a higher level, our method is agnostic to the specific type and curvature of the loss functions, while at a lower level, it can exploit the niceness of the environments and attain problem-dependent guarantees. To be specific, we obtain $\mathcal{O}(\ln V_T)$, $\mathcal{O}(d \ln V_T)$ and $\hat{\mathcal{O}}(\sqrt{V_T})$ regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where $d$ is the dimension, $V_T$ denotes problem-dependent gradient variations and $\hat{\mathcal{O}}(\cdot)$-notation omits logarithmic factors on $V_T$. Our result finds broad implications and applications. It not only safeguards the worst-case guarantees, but also implies the small-loss bounds in analysis directly. Besides, it draws deep connections with adversarial/stochastic convex optimization and game theory, further validating its practical potential. Our method is based
    
[^13]: 针对Softmax注意力优化的零阶算法

    Zero-th Order Algorithm for Softmax Attention Optimization. (arXiv:2307.08352v1 [cs.LG])

    [http://arxiv.org/abs/2307.08352](http://arxiv.org/abs/2307.08352)

    这篇论文介绍了一个针对Softmax优化的零阶算法，能够有效地计算大规模语言模型的梯度。

    

    大规模语言模型（LLM）在人类社会中带来了重大的变革。在LLMs中，softmax单元的计算非常重要。它帮助模型在一系列输入单词中生成潜在的下一个单词或短语的概率分布。通过利用这个分布，模型根据分配的概率选择最有可能的下一个单词或短语。softmax单元在LLM训练中起到关键作用，因为它通过调整神经网络的权重和偏差来实现从数据中学习。随着LLMs的规模的发展，计算梯度变得昂贵。然而，零阶方法可以通过仅进行前向传递来近似计算梯度。在本文中，我们提出了一个专门针对Softmax优化的零阶算法。我们证明了我们的算法的收敛性，并强调其在高效计算大规模语言模型的梯度方面的有效性。

    Large language models (LLMs) have brought about significant transformations in human society. Among the crucial computations in LLMs, the softmax unit holds great importance. Its helps the model generating a probability distribution on potential subsequent words or phrases, considering a series of input words. By utilizing this distribution, the model selects the most probable next word or phrase, based on the assigned probabilities. The softmax unit assumes a vital function in LLM training as it facilitates learning from data through the adjustment of neural network weights and biases.  With the development of the size of LLMs, computing the gradient becomes expensive. However, Zero-th Order method can approximately compute the gradient with only forward passes. In this paper, we present a Zero-th Order algorithm specifically tailored for Softmax optimization. We demonstrate the convergence of our algorithm, highlighting its effectiveness in efficiently computing gradients for large-s
    
[^14]: 高斯过程用于与线性偏微分方程相关的贝叶斯逆问题

    Gaussian processes for Bayesian inverse problems associated with linear partial differential equations. (arXiv:2307.08343v1 [stat.ML])

    [http://arxiv.org/abs/2307.08343](http://arxiv.org/abs/2307.08343)

    本文针对线性偏微分方程相关的贝叶斯逆问题，提出了使用高斯代理模型的方法，并拓展了Raissi等人（2017）的框架，构建了依赖方程信息的高斯先验，实验证明了其在贝叶斯反演中的优越性。

    

    本文研究了在与线性偏微分方程相关的贝叶斯逆问题中使用高斯代理模型的方法。我们特别关注的是在只有少量训练数据可用的情况下，高斯先验的类型对于用于贝叶斯反演的代理模型的性能的关键重要性。我们扩展了Raissi等人（2017）的框架，以构建PDE-informed高斯先验，并用它们构建不同的近似后验分布。多个不同的数值实验证明了PDE-informed高斯先验在传统先验上的优越性。

    This work is concerned with the use of Gaussian surrogate models for Bayesian inverse problems associated with linear partial differential equations. A particular focus is on the regime where only a small amount of training data is available. In this regime the type of Gaussian prior used is of critical importance with respect to how well the surrogate model will perform in terms of Bayesian inversion. We extend the framework of Raissi et. al. (2017) to construct PDE-informed Gaussian priors that we then use to construct different approximate posteriors. A number of different numerical experiments illustrate the superiority of the PDE-informed Gaussian priors over more traditional priors.
    
[^15]: 复杂性至关重要：重新思考生成建模的潜在空间

    Complexity Matters: Rethinking the Latent Space for Generative Modeling. (arXiv:2307.08283v1 [cs.LG])

    [http://arxiv.org/abs/2307.08283](http://arxiv.org/abs/2307.08283)

    本研究从模型复杂性的角度重新思考生成建模的潜在空间，提出了一种新的潜在与数据分布之间的“距离”，并通过该距离的最小化来优化生成器的复杂性。

    

    在生成建模中，许多成功的方法利用低维潜在空间，例如，稳定扩散模型通过编码器引导的潜在空间生成图像，并通过配对的解码器进行生成。尽管潜在空间的选择在实践中非常重要，但确定最优选择和识别过程仍不清楚。在本研究中，我们旨在从模型复杂性的角度重新思考潜在空间，来揭示这个未被充分探索的话题。我们的调查从经典的生成对抗网络（GANs）开始。受到GAN训练目标的启发，我们提出了一种新的潜在与数据分布之间的“距离”，其最小化与生成器的复杂性最小化相一致。这个距离的最小化者被描述为能够最有效地利用生成器容量的最佳数据相关的潜在。然后，我们考虑通过编码器网络对这样的潜在分布进行参数化，并提出了一个方法...

    In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel "distance" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propo
    
[^16]: 深入探究图中纠缠治疗的因果效应：研究接触对MRSA感染的影响

    A Look into Causal Effects under Entangled Treatment in Graphs: Investigating the Impact of Contact on MRSA Infection. (arXiv:2307.08237v1 [cs.LG])

    [http://arxiv.org/abs/2307.08237](http://arxiv.org/abs/2307.08237)

    本文研究了在图中纠缠治疗的情况下如何估计接触对MRSA感染的因果效应。以往的观察性研究方法忽略了纠缠治疗可能导致因果效应估计的错误。

    

    甲氧西林耐药金黄色葡萄球菌（MRSA）是一种对某些抗生素具有耐药性的细菌，使得预防MRSA感染变得困难。在数十年的努力中，已经提出了许多研究以从观察数据中估计亲密接触（治疗）对MRSA感染（结果）的因果效应。在这个问题中，治疗分配机制起着关键作用，因为它决定了缺失反事实的模式，这是因果效应估计的基本挑战。大多数现有的用于因果效应学习的观察性研究假设每个单位的治疗都是个体分配的。但是，在许多情况下，治疗是对图中连接的单位进行成对分配的，即不同单位的治疗是纠缠的。忽视纠缠的治疗可能妨碍因果效应的估计。在本文中，我们研究了在图中纠缠治疗的情况下的因果效应估计问题。

    Methicillin-resistant Staphylococcus aureus (MRSA) is a type of bacteria resistant to certain antibiotics, making it difficult to prevent MRSA infections. Among decades of efforts to conquer infectious diseases caused by MRSA, many studies have been proposed to estimate the causal effects of close contact (treatment) on MRSA infection (outcome) from observational data. In this problem, the treatment assignment mechanism plays a key role as it determines the patterns of missing counterfactuals -- the fundamental challenge of causal effect estimation. Most existing observational studies for causal effect learning assume that the treatment is assigned individually for each unit. However, on many occasions, the treatments are pairwisely assigned for units that are connected in graphs, i.e., the treatments of different units are entangled. Neglecting the entangled treatments can impede the causal effect estimation. In this paper, we study the problem of causal effect estimation with treatme
    
[^17]: 从观测数据中学习反事实公平性

    Learning for Counterfactual Fairness from Observational Data. (arXiv:2307.08232v1 [cs.LG])

    [http://arxiv.org/abs/2307.08232](http://arxiv.org/abs/2307.08232)

    该论文提出了一种从观测数据中学习反事实公平性的方法。现有方法需要先验人类知识来实现反事实公平性，但在实际场景中，获取这样的知识往往非常困难。这项研究为解决这一问题提供了新的思路。

    

    公平性感知机器学习在许多领域引起了广泛关注，如在线广告、个性化推荐和社交媒体分析。公平性感知机器学习旨在消除学习模型对特定子群体的偏见，这些子群体由特定的保护（敏感）属性描述，例如种族、性别和年龄。在许多现有的公平性概念中，反事实公平性是从因果透视定义的一种流行概念。它通过比较原始世界中每个个体的预测和在修改敏感属性值的反事实世界中的预测来衡量预测器的公平性。现有方法实现反事实公平性的先决条件是掌握关于数据的因果模型的先验人类知识。然而，在现实世界的场景中，潜在的因果模型通常是未知的，并且获取这样的人类知识可能非常困难。在这些情况下，实现反事实公平性是非常具有挑战性的。

    Fairness-aware machine learning has attracted a surge of attention in many domains, such as online advertising, personalized recommendation, and social media analysis in web applications. Fairness-aware machine learning aims to eliminate biases of learning models against certain subgroups described by certain protected (sensitive) attributes such as race, gender, and age. Among many existing fairness notions, counterfactual fairness is a popular notion defined from a causal perspective. It measures the fairness of a predictor by comparing the prediction of each individual in the original world and that in the counterfactual worlds in which the value of the sensitive attribute is modified. A prerequisite for existing methods to achieve counterfactual fairness is the prior human knowledge of the causal model for the data. However, in real-world scenarios, the underlying causal model is often unknown, and acquiring such human knowledge could be very difficult. In these scenarios, it is ri
    
[^18]: 在表格化监督式机器学习模型中多目标优化性能和可解释性

    Multi-Objective Optimization of Performance and Interpretability of Tabular Supervised Machine Learning Models. (arXiv:2307.08175v1 [cs.LG])

    [http://arxiv.org/abs/2307.08175](http://arxiv.org/abs/2307.08175)

    这个研究提出了一个模型无关的框架，用于优化表格数据的监督式机器学习模型的性能和可解释性。通过将机器学习算法的超参数优化视为多目标优化问题，该框架生成了同时具有高性能和易解释性权衡的多样模型。

    

    我们提出了一个模型无关的框架，用于同时优化表格数据的监督式机器学习模型的预测性能和可解释性。可解释性通过三个指标进行量化：特征稀疏性、特征交互稀疏性和非单调特征影响的稀疏性。通过将机器学习算法的超参数优化视为多目标优化问题，我们的框架允许在单次优化运行中生成高性能和易解释性权衡的多样模型。通过将特征选择、交互和单调性约束集成到超参数搜索空间中，实现了高效的优化。我们证明了优化问题有效地转化为找到被允许在模型中交互的选定特征组的 Pareto 最优集，并找到它们的最佳单调性。

    We present a model-agnostic framework for jointly optimizing the predictive performance and interpretability of supervised machine learning models for tabular data. Interpretability is quantified via three measures: feature sparsity, interaction sparsity of features, and sparsity of non-monotone feature effects. By treating hyperparameter optimization of a machine learning algorithm as a multi-objective optimization problem, our framework allows for generating diverse models that trade off high performance and ease of interpretability in a single optimization run. Efficient optimization is achieved via augmentation of the search space of the learning algorithm by incorporating feature selection, interaction and monotonicity constraints into the hyperparameter search space. We demonstrate that the optimization problem effectively translates to finding the Pareto optimal set of groups of selected features that are allowed to interact in a model, along with finding their optimal monotonic
    
[^19]: 通过变分自动 编码器实现灵活高效的空间极端值模拟

    Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v1 [stat.ML])

    [http://arxiv.org/abs/2307.08079](http://arxiv.org/abs/2307.08079)

    本文提出了一种新的空间极端值模型，通过集成在变分自动编码器的结构中，可以灵活、高效地模拟具有非平稳相关性的极端事件。实验证明，在时间效率和性能上，相对于传统的贝叶斯推断和许多具有平稳相关性的空间极端值模型，我们的方法具有优势。

    

    许多现实世界的过程具有复杂的尾依赖结构，这种结构无法使用传统的高斯过程来描述。更灵活的空间极端值模型， 如高斯尺度混合模型和单站点调节模型，具有吸引人的极端依赖性质，但往往难以拟合和模拟。本文中，我们提出了一种新的空间极端值模型，具有灵活和非平稳的相关性属性，并将其集成到变分自动编码器 (extVAE) 的编码-解码结构中。 extVAE 可以作为一个时空模拟器，对潜在的机制模型输出状态的分布进行建模，并产生具有与输入相同属性的输出，尤其是在尾部区域。通过广泛的模拟研究，我们证明我们的extVAE比传统的贝叶斯推断更高效，并且在具有 平稳相关性结构的许多空间极端值模型中表现 更好。

    Many real-world processes have complex tail dependence structures that cannot be characterized using classical Gaussian processes. More flexible spatial extremes models such as Gaussian scale mixtures and single-station conditioning models exhibit appealing extremal dependence properties but are often exceedingly prohibitive to fit and simulate from. In this paper, we develop a new spatial extremes model that has flexible and non-stationary dependence properties, and we integrate it in the encoding-decoding structure of a variational autoencoder (extVAE). The extVAE can be used as a spatio-temporal emulator that characterizes the distribution of potential mechanistic model output states and produces outputs that have the same properties as the inputs, especially in the tail. Through extensive simulation studies, we show that our extVAE is vastly more time-efficient than traditional Bayesian inference while also outperforming many spatial extremes models with a stationary dependence str
    
[^20]: 柔性时间事件建模：通过排名回归优化神经网络

    Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression. (arXiv:2307.08044v1 [cs.LG])

    [http://arxiv.org/abs/2307.08044](http://arxiv.org/abs/2307.08044)

    本研究提出了一种深度AFT排名回归模型，用于灵活地进行时间事件建模，从而改善预测性能并减轻严格的假设。

    

    时间事件分析，也被称为生存分析，旨在根据一组特征预测事件发生的时间。这个领域面临的一个主要挑战是处理被截尾的数据，这可能使学习算法更加复杂。传统方法如Cox比例风险模型和加速失效时间（AFT）模型在这个领域很受欢迎，但它们经常需要一些假设，如比例风险和线性。特别是，AFT模型通常需要预先指定的参数分布假设。为了提高预测性能和减轻严格的假设，近年来出现了许多基于深度学习的危险模型方法。然而，神经网络文献中对于AFT的表示学习尚未广泛探索，尽管相对于以危险为重点的方法而言，它更加简单和可解释。在这项工作中，我们引入了深度AFT排名回归模型来进行时间事件预测。

    Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event predic
    
[^21]: 大规模空间插值风场的双变量深度克里金方法

    Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields. (arXiv:2307.08038v1 [stat.ML])

    [http://arxiv.org/abs/2307.08038](http://arxiv.org/abs/2307.08038)

    本文提出了一种名为双变量深度克里金的方法，它利用空间相关的深度神经网络(DNN)和嵌入层以及基于自助法和集成DNN的无分布不确定性量化方法，用于大规模空间插值风场的预测和估计。

    

    高空间分辨率的风场数据对于气候、海洋和气象研究中的各种应用至关重要。由于风数据往往具有非高斯分布、高空间变异性和异质性，因此对具有两个维度速度的双变量风场进行大规模空间插值或下缩放是一项具有挑战性的任务。在空间统计学中，常用cokriging来预测双变量空间场。然而，cokriging预测器除了对高斯过程有效外，并不是最优的。此外，对于大型数据集，cokriging计算量巨大。在本文中，我们提出了一种称为双变量深度克里金的方法，它是一个由空间径向基函数构建的空间相关的深度神经网络(DNN)和嵌入层，用于双变量空间数据预测。然后，我们基于自助法和集成DNN开发了一种无分布不确定性量化方法。我们提出的方法优于传统的cokriging方法。

    High spatial resolution wind data are essential for a wide range of applications in climate, oceanographic and meteorological studies. Large-scale spatial interpolation or downscaling of bivariate wind fields having velocity in two dimensions is a challenging task because wind data tend to be non-Gaussian with high spatial variability and heterogeneity. In spatial statistics, cokriging is commonly used for predicting bivariate spatial fields. However, the cokriging predictor is not optimal except for Gaussian processes. Additionally, cokriging is computationally prohibitive for large datasets. In this paper, we propose a method, called bivariate DeepKriging, which is a spatially dependent deep neural network (DNN) with an embedding layer constructed by spatial radial basis functions for bivariate spatial data prediction. We then develop a distribution-free uncertainty quantification method based on bootstrap and ensemble DNN. Our proposed approach outperforms the traditional cokriging 
    
[^22]: 用高斯评分匹配进行变分推理

    Variational Inference with Gaussian Score Matching. (arXiv:2307.07849v1 [stat.ML])

    [http://arxiv.org/abs/2307.07849](http://arxiv.org/abs/2307.07849)

    本文提出了一种用高斯评分匹配的方法来进行变分推理，通过迭代算法将变分近似与精确后验的评分匹配。当变分分布是高斯分布时，内部优化问题有闭式解。

    

    变分推理（VI）是一种逼近贝叶斯统计中的计算困难后验分布的方法。通常，VI通过最小化适当的目标函数（例如证据下界ELBO）将简单的参数分布拟合到目标后验分布中。在本文中，我们提出了一种基于评分匹配原理的新型VI方法，即如果两个分布相等，则它们的评分函数（即对数密度的梯度）在其支持集的每个点上都相等。基于这一原理，我们开发了评分匹配VI，这是一个迭代算法，旨在匹配变分近似与精确后验之间的评分。在每次迭代中，评分匹配VI解决了一个内部优化问题，即最小调整当前变分估计，使其与新抽取的潜变量值处的评分匹配。我们证明，当变分分布是高斯分布时，这个内部优化问题有一个闭式解。

    Variational inference (VI) is a method to approximate the computationally intractable posterior distributions that arise in Bayesian statistics. Typically, VI fits a simple parametric distribution to the target posterior by minimizing an appropriate objective such as the evidence lower bound (ELBO). In this work, we present a new approach to VI based on the principle of score matching, that if two distributions are equal then their score functions (i.e., gradients of the log density) are equal at every point on their support. With this, we develop score matching VI, an iterative algorithm that seeks to match the scores between the variational approximation and the exact posterior. At each iteration, score matching VI solves an inner optimization, one that minimally adjusts the current variational estimate to match the scores at a newly sampled value of the latent variables. We show that when the variational family is a Gaussian, this inner optimization enjoys a closed form solution, wh
    
[^23]: 带有Mean-KL参数化的最小随机编码学习

    Minimal Random Code Learning with Mean-KL Parameterization. (arXiv:2307.07816v1 [cs.LG])

    [http://arxiv.org/abs/2307.07816](http://arxiv.org/abs/2307.07816)

    本文研究了最小随机编码学习（MIRACLE）的两个变体，提出了一种新的参数化方法Mean-KL，在压缩变分贝叶斯神经网络中实现了更快的收敛和良好的预测性能。

    

    本文研究了最小随机编码学习（MIRACLE）的两个变体在压缩变分贝叶斯神经网络中的定性行为和鲁棒性。MIRACLE实现了强大的条件高斯变分近似权重后验$Q_{\mathbf{w}}$，并使用相对熵编码来压缩从后验中抽样的权重，使用高斯编码分布$P_{\mathbf{w}}$。为了达到所需的压缩率，必须对$Q_{\mathbf{w}} \Vert P_{\mathbf{w}}$进行约束，这需要在传统的均值-方差（Mean-Var）参数化下进行计算上昂贵的退火过程。相反，我们通过其平均值和KL散度来参数化$Q_{\mathbf{w}}$，以通过构造将压缩成本约束为所需值。我们证明了使用Mean-KL参数化的变分训练收敛速度是传统方法的两倍，并且在训练后保持了预测性能。

    This paper studies the qualitative behavior and robustness of two variants of Minimal Random Code Learning (MIRACLE) used to compress variational Bayesian neural networks. MIRACLE implements a powerful, conditionally Gaussian variational approximation for the weight posterior $Q_{\mathbf{w}}$ and uses relative entropy coding to compress a weight sample from the posterior using a Gaussian coding distribution $P_{\mathbf{w}}$. To achieve the desired compression rate, $D_{\mathrm{KL}}[Q_{\mathbf{w}} \Vert P_{\mathbf{w}}]$ must be constrained, which requires a computationally expensive annealing procedure under the conventional mean-variance (Mean-Var) parameterization for $Q_{\mathbf{w}}$. Instead, we parameterize $Q_{\mathbf{w}}$ by its mean and KL divergence from $P_{\mathbf{w}}$ to constrain the compression cost to the desired value by construction. We demonstrate that variational training with Mean-KL parameterization converges twice as fast and maintains predictive performance after 
    
[^24]: 图自同态群等变神经网络

    Graph Automorphism Group Equivariant Neural Networks. (arXiv:2307.07810v1 [cs.LG])

    [http://arxiv.org/abs/2307.07810](http://arxiv.org/abs/2307.07810)

    本论文提供了图自同态群等变神经网络的完整特征化，找到了可学习的、线性的层函数之间的矩阵的生成集。

    

    对于任何具有n个顶点和其自同态群Aut(G)的图G，我们提供了所有可能的Aut(G)-等变神经网络的完整特征化，其层是n维实数张量的某些张量幂次。特别地，我们在n维实数空间的标准基下找到了可学习的、线性的Aut(G)-等变层函数之间的矩阵的生成集。

    For any graph $G$ having $n$ vertices and its automorphism group $\textrm{Aut}(G)$, we provide a full characterisation of all of the possible $\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a spanning set of matrices for the learnable, linear, $\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$.
    
[^25]: 过参数化模型的插值信息准则

    The Interpolating Information Criterion for Overparameterized Models. (arXiv:2307.07785v1 [stat.ML])

    [http://arxiv.org/abs/2307.07785](http://arxiv.org/abs/2307.07785)

    本文提出了一个插值信息准则，用于过参数化模型的模型选择问题。通过建立贝叶斯对偶形式，该准则将先验选择纳入模型评估，并考虑了先验误设、模型的几何和谱特性。该准则在实证和理论行为方面与已知结果一致。

    

    本文考虑了过参数化估计器的模型选择问题，其中模型参数的数量超过数据集的大小。传统的信息准则通常考虑大数据极限，对模型大小进行惩罚。然而，在现代设置中，这些准则不适用，因为过参数化模型往往表现良好。对于任何过参数化模型，我们证明存在一个对偶的欠参数化模型，具有相同的边缘似然性，从而建立了贝叶斯对偶形式。这使得过参数化设置中可以使用更多经典方法，揭示了插值信息准则，一种自然地将先验选择纳入模型选择的模型质量度量。我们的新信息准则考虑了先验误设、模型的几何和谱特性，并且在该区域与已知的经验和理论行为一致。

    The problem of model selection is considered for the setting of interpolating estimators, where the number of model parameters exceeds the size of the dataset. Classical information criteria typically consider the large-data limit, penalizing model size. However, these criteria are not appropriate in modern settings where overparameterized models tend to perform well. For any overparameterized model, we show that there exists a dual underparameterized model that possesses the same marginal likelihood, thus establishing a form of Bayesian duality. This enables more classical methods to be used in the overparameterized setting, revealing the Interpolating Information Criterion, a measure of model quality that naturally incorporates the choice of prior into the model selection. Our new information criterion accounts for prior misspecification, geometric and spectral properties of the model, and is numerically consistent with known empirical and theoretical behavior in this regime.
    
[^26]: 学习神经网络中的表达性先验，提高推广和不确定性估计

    Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks. (arXiv:2307.07753v1 [cs.LG])

    [http://arxiv.org/abs/2307.07753](http://arxiv.org/abs/2307.07753)

    本文提出了一种用于神经网络的先验学习方法，通过利用可扩展和结构化的神经网络后验作为推广的信息先验，提高了神经网络的推广和不确定性估计能力。我们的方法在大规模上提供了表达性的概率表示，并产生了非空推广界限。我们的技术贡献是推导出可处理的目标函数，并提出了改进的推广界限计算方法。在经验上，我们证明了该方法在不确定性估计和推广方面的有效性。

    

    在这项工作中，我们提出了一种新的先验学习方法，用于提高深度神经网络中的推广和不确定性估计。关键思想是利用可扩展和结构化的神经网络后验作为具有推广保证的信息先验。我们学习到的先验在大规模上提供了表达性的概率表示，类似于在ImageNet上预训练模型的贝叶斯对应物，并进一步产生了非空推广界限。我们还将这个想法扩展到连续学习框架中，我们的先验的有利特性是可取的。主要的推动因素是我们的技术贡献：(1) Kronecker积求和的计算，(2) 推导和优化可处理的目标函数，从而导致改进的推广界限。在经验上，我们详尽地展示了该方法在不确定性估计和推广方面的有效性。

    In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.
    
[^27]: 结构化支持向量机的接近线性时间算法

    A Nearly-Linear Time Algorithm for Structured Support Vector Machines. (arXiv:2307.07735v1 [math.OC])

    [http://arxiv.org/abs/2307.07735](http://arxiv.org/abs/2307.07735)

    这篇论文提出了针对结构化支持向量机的接近线性时间算法，解决了二次规划输入规模和解决时间的问题。

    

    二次规划是凸优化领域中的基本问题。许多实际任务可以表示为二次规划，例如支持向量机（SVM）。在深度学习方法盛行之前，线性SVM是过去三十年来最流行的机器学习工具之一。一般来说，一个二次规划的输入规模为Θ(n^2)（其中n是变量的数量），因此解决该问题需要Ω(n^2)的时间。然而，SVM产生的二次规划的输入规模为O(n)，这使得设计接近线性时间算法成为可能。两个重要的SVM类别是具有低秩核因式分解和低树宽规模的程序。低树宽凸优化在过去几年中引起了越来越多的关注（例如线性规划[Dong, Lee and Ye 2021]和半定规划[Gu and Song 2022]）。因此，一个重要的开放问题是是否存在接近线性时间算法。

    Quadratic programming is a fundamental problem in the field of convex optimization. Many practical tasks can be formulated as quadratic programming, for example, the support vector machine (SVM). Linear SVM is one of the most popular tools over the last three decades in machine learning before deep learning method dominating.  In general, a quadratic program has input size $\Theta(n^2)$ (where $n$ is the number of variables), thus takes $\Omega(n^2)$ time to solve. Nevertheless, quadratic programs coming from SVMs has input size $O(n)$, allowing the possibility of designing nearly-linear time algorithms. Two important classes of SVMs are programs admitting low-rank kernel factorizations and low-treewidth programs. Low-treewidth convex optimization has gained increasing interest in the past few years (e.g.~linear programming [Dong, Lee and Ye 2021] and semidefinite programming [Gu and Song 2022]). Therefore, an important open question is whether there exist nearly-linear time algorithms
    
[^28]: 迈向最优神经网络：样本拆分在超参数选择中的作用

    Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v1 [stat.ML])

    [http://arxiv.org/abs/2307.07726](http://arxiv.org/abs/2307.07726)

    本文通过揭示神经网络模型构建中的样本拆分方法的奥秘，构建了一个理论框架来解释神经网络的有效性。我们的研究结果表明，从样本拆分中得到的最优超参数可以使得神经网络模型最小化预测风险。

    

    当人工神经网络在各个领域展现出卓越的实践成功时，关于它们的理论特性，如逼近能力、统计性质和泛化性能等的研究也取得了显著进展。在本文中，我们通过揭示神经网络模型构建中一种常见实践背后的奥秘：样本拆分，构建了一个新颖的理论来理解神经网络的有效性。我们的理论证明，从样本拆分中得到的最优超参数可以使得神经网络模型渐进地最小化预测风险。我们在不同的应用场景和网络结构中进行了大量实验，实验结果证实了我们的理论的有效性。

    When artificial neural networks have demonstrated exceptional practical success in a variety of domains, investigations into their theoretical characteristics, such as their approximation power, statistical properties, and generalization performance, have made significant strides. In this paper, we construct a novel theory for understanding the effectiveness of neural networks by discovering the mystery underlying a common practice during neural network model construction: sample splitting. Our theory demonstrates that, the optimal hyperparameters derived from sample splitting can enable a neural network model that asymptotically minimizes the prediction risk. We conduct extensive experiments across different application scenarios and network architectures, and the results manifest our theory's effectiveness.
    
[^29]: 匹配追踪的快速收敛速度

    Sharp Convergence Rates for Matching Pursuit. (arXiv:2307.07679v1 [stat.ML])

    [http://arxiv.org/abs/2307.07679](http://arxiv.org/abs/2307.07679)

    本文通过提升现有的下界来匹配最佳上界，对匹配追踪的性能进行了精确描述，并构造了一个最坏情况的字典来证明现有上界的无法改进。

    

    本文研究了匹配追踪的基本限制，即通过字典中的元素的稀疏线性组合来近似目标函数的纯贪婪算法。当目标函数包含在对应于字典的变化空间中时，许多令人印象深刻的研究在过去几十年中获得了匹配追踪的收敛速度的上界和下界，但它们并不匹配。本文的主要贡献是填补这一差距，并获得匹配追踪性能的精确描述。我们通过改进现有的下界以匹配最佳上界来实现这一目标。具体来说，我们构造了一个最坏情况的字典，证明了现有的上界不能改进。事实证明，与其他贪婪算法变体不同，收敛速度是次优的，并且由解某个非线性方程的解决方案决定。这使我们得出结论，任意程度的收缩都会改善匹配追踪效果。

    We study the fundamental limits of matching pursuit, or the pure greedy algorithm, for approximating a target function by a sparse linear combination of elements from a dictionary. When the target function is contained in the variation space corresponding to the dictionary, many impressive works over the past few decades have obtained upper and lower bounds on the convergence rate of matching pursuit, but they do not match. The main contribution of this paper is to close this gap and obtain a sharp characterization of the performance of matching pursuit. We accomplish this by improving the existing lower bounds to match the best upper bound. Specifically, we construct a worst case dictionary which proves that the existing upper bound cannot be improved. It turns out that, unlike other greedy algorithm variants, the converge rate is suboptimal and is determined by the solution to a certain non-linear equation. This enables us to conclude that any amount of shrinkage improves matching pu
    
[^30]: 关于多节点上下文赌博机制中Epoch-Greedy的鲁棒性

    On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms. (arXiv:2307.07675v1 [cs.LG])

    [http://arxiv.org/abs/2307.07675](http://arxiv.org/abs/2307.07675)

    本研究展示了在多Agent上下文赌博机制中，最突出的上下文赌博算法$\epsilon$-greedy可以进行扩展，以解决同时存在的激励因素、上下文和损坏问题

    

    在像点击付费(Pay-Per-Click)拍卖这样的多臂赌博机制中进行高效学习通常涉及三个挑战：1)引导真实出价行为(激励因素)，2)在用户个性化上下文中使用个性化(上下文)，3)规避点击模式中的操纵(损坏行为)。过去文献中每个挑战都被独立研究过；激励因素已在一系列研究中得到解决，上下文问题已通过上下文赌博算法得到广泛解决，而损坏问题则通过最近的关于具有对抗性损坏的赌博机制工作进行讨论。由于这些挑战同时存在，重要的是了解每种方法在解决其他挑战时的鲁棒性，提供可以同时处理所有挑战的算法，并突出这种组合中的固有局限性。在这项工作中，我们展示了最突出的上下文赌博算法$\epsilon$-greedy可以进行扩展，以解决同时存在的激励因素、上下文和损坏问题。

    Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\epsilon$-greedy can be extended to
    
[^31]: 用近端梯度下降有效地分解布尔矩阵

    Efficiently Factorizing Boolean Matrices using Proximal Gradient Descent. (arXiv:2307.07615v1 [cs.LG])

    [http://arxiv.org/abs/2307.07615](http://arxiv.org/abs/2307.07615)

    通过使用连续松弛和弹性二元正则化器，我们提出了一种用近端梯度下降有效地分解布尔矩阵的方法。我们在合成数据和实际数据上进行了广泛的实验，证明了方法的快速收敛和准确性，优于现有技术，结果易于解释和语义有意义。

    

    为了解决非负矩阵分解在布尔数据上的可解释性问题，布尔矩阵分解（BMF）使用布尔代数将输入分解为低秩布尔因子矩阵。这些矩阵具有很高的可解释性，在实践中非常有用，但需要解决一个NP难的组合优化问题，计算成本较高。为了减轻计算负担，我们提出了一种通过连续松弛BMF的新型弹性二元正则化器，从中推导出一种近端梯度算法。通过大量的实验，我们证明我们的方法在实践中表现良好：在合成数据上，我们展示了它快速收敛，精确恢复了真实值，并准确估计了模拟秩。在实际数据上，我们在召回率、损失和运行时间方面优于现有技术，并且来自医学领域的案例研究证实了我们的结果易于解释和语义有意义。

    Addressing the interpretability problem of NMF on Boolean data, Boolean Matrix Factorization (BMF) uses Boolean algebra to decompose the input into low-rank Boolean factor matrices. These matrices are highly interpretable and very useful in practice, but they come at the high computational cost of solving an NP-hard combinatorial optimization problem. To reduce the computational burden, we propose to relax BMF continuously using a novel elastic-binary regularizer, from which we derive a proximal gradient algorithm. Through an extensive set of experiments, we demonstrate that our method works well in practice: On synthetic data, we show that it converges quickly, recovers the ground truth precisely, and estimates the simulated rank exactly. On real-world data, we improve upon the state of the art in recall, loss, and runtime, and a case study from the medical domain confirms that our results are easily interpretable and semantically meaningful.
    
[^32]: 用能量差异训练离散能量模型

    Training Discrete Energy-Based Models with Energy Discrepancy. (arXiv:2307.07595v1 [stat.ML])

    [http://arxiv.org/abs/2307.07595](http://arxiv.org/abs/2307.07595)

    该论文提出了一种用能量差异训练离散能量模型的方法，该方法不依赖于采样策略，通过评估数据点及其扰动对应点的能量函数来实现，能够为各种扰动过程提供理论保证，并在不同数据集上展示了其相对性能。

    

    在离散空间上训练能量模型（EBMs）充满挑战，因为对这样的空间进行采样可能很困难。我们提出使用能量差异（ED）来训练离散EBMs，这是一种新型的对比损失函数，只需要评估数据点及其扰动对应点的能量函数，因此不依赖于像马尔可夫链蒙特卡洛（MCMC）这样的采样策略。能量差异为一类广泛的扰动过程提供了理论保证，我们研究了三种类型的扰动：基于伯努利噪声的扰动，基于确定性变换的扰动，以及基于邻域结构的扰动。我们在晶格伊辛模型、二值合成数据和离散图像数据集上展示了它们的相对性能。

    Training energy-based models (EBMs) on discrete spaces is challenging because sampling over such spaces can be difficult. We propose to train discrete EBMs with energy discrepancy (ED), a novel type of contrastive loss functional which only requires the evaluation of the energy function at data points and their perturbed counter parts, thus not relying on sampling strategies like Markov chain Monte Carlo (MCMC). Energy discrepancy offers theoretical guarantees for a broad class of perturbation processes of which we investigate three types: perturbations based on Bernoulli noise, based on deterministic transforms, and based on neighbourhood structures. We demonstrate their relative performance on lattice Ising models, binary synthetic data, and discrete image data sets.
    
[^33]: 高维线性模型的稀疏化同时置信区间

    Sparsified Simultaneous Confidence Intervals for High-Dimensional Linear Models. (arXiv:2307.07574v1 [stat.ME])

    [http://arxiv.org/abs/2307.07574](http://arxiv.org/abs/2307.07574)

    提出了一种稀疏化同时置信区间的方法，用于高维线性模型的统计推断。通过将某些区间的上下界收缩为零，该方法能够确定不重要的协变量并将其排除在最终模型之外，同时通过其他区间判断出可信和显著的协变量。

    

    鉴于模型选择过程引入的不确定性难以考虑，对高维回归系数的统计推断具有挑战性。一个关键问题仍未解决，即是否可能以及如何将模型的推断嵌入到系数的同时推断中？为此，我们提出了一种称为稀疏化同时置信区间的概念。我们的区间在某些上下界上进行了稀疏，即缩小为零（例如，$[0,0]$），表示相应协变量的不重要性。这些协变量应该从最终模型中排除。其余的区间，无论是包含零（例如，$[-1,1]$或$[0,1]$）还是不包含零（例如，$[2,3]$），分别表示可信和显著的协变量。所提出的方法可以与各种选择过程相结合，使其非常适合比较它们的使用。

    Statistical inference of the high-dimensional regression coefficients is challenging because the uncertainty introduced by the model selection procedure is hard to account for. A critical question remains unsettled; that is, is it possible and how to embed the inference of the model into the simultaneous inference of the coefficients? To this end, we propose a notion of simultaneous confidence intervals called the sparsified simultaneous confidence intervals. Our intervals are sparse in the sense that some of the intervals' upper and lower bounds are shrunken to zero (i.e., $[0,0]$), indicating the unimportance of the corresponding covariates. These covariates should be excluded from the final model. The rest of the intervals, either containing zero (e.g., $[-1,1]$ or $[0,1]$) or not containing zero (e.g., $[2,3]$), indicate the plausible and significant covariates, respectively. The proposed method can be coupled with various selection procedures, making it ideal for comparing their u
    
[^34]: 变分预测

    Variational Prediction. (arXiv:2307.07568v1 [cs.LG])

    [http://arxiv.org/abs/2307.07568](http://arxiv.org/abs/2307.07568)

    本文介绍了变分预测这一技术，通过使用变分界直接学习后验预测分布，避免了边缘化成本，并展示了在玩具例子上的实验结果。

    

    贝叶斯推断相比最大似然具有优势，但也伴随着计算成本。计算后验通常是难以处理的，而将后验边缘化形成后验预测分布也是如此。在本文中，我们提出了变分预测，一种使用变分界直接学习后验预测分布的技术。这种方法可以在没有测试时间边缘化成本的情况下提供良好的预测分布。我们在一个说明性的玩具例子上演示了变分预测。

    Bayesian inference offers benefits over maximum likelihood, but it also comes with computational costs. Computing the posterior is typically intractable, as is marginalizing that posterior to form the posterior predictive distribution. In this paper, we present variational prediction, a technique for directly learning a variational approximation to the posterior predictive distribution using a variational bound. This approach can provide good predictive distributions without test time marginalization costs. We demonstrate Variational Prediction on an illustrative toy example.
    
[^35]: 在希尔伯特空间中改进自标准化浓度：对GP-UCB算法的次线性遗憾

    Improved Self-Normalized Concentration in Hilbert Spaces: Sublinear Regret for GP-UCB. (arXiv:2307.07539v1 [cs.LG])

    [http://arxiv.org/abs/2307.07539](http://arxiv.org/abs/2307.07539)

    本文提出了对GP-UCB算法进行改进，使其具有几乎最优的次线性遗憾，并解决了关于遗憾分析的开放问题。

    

    在核化赌博机问题中，学习器旨在通过仅在顺序选择的点处进行噪声评估，顺序计算位于再生核希尔伯特空间中的函数的最优解。特别地，学习器旨在最小化遗憾，遗憾是所做选择的次优性度量。可以说最受欢迎的算法是高斯过程上界置信区间（GP-UCB）算法，它涉及根据未知函数的简单线性估计器进行行动。尽管它很受欢迎，但现有的GP-UCB遗憾分析给出了次优遗憾率，对于许多常用的内核（如Matérn内核）而言，遗憾率并不次线性。这引发了一个长期存在的问题：现有的GP-UCB遗憾分析是否紧密，或者是否可以通过使用更复杂的分析技术改进界限？在这项工作中，我们解决了这个开放问题，并证明了GP-UCB具有几乎最优的遗憾。特别地，我们的结果直接暗示了次线性遗憾率。

    In the kernelized bandit problem, a learner aims to sequentially compute the optimum of a function lying in a reproducing kernel Hilbert space given only noisy evaluations at sequentially chosen points. In particular, the learner aims to minimize regret, which is a measure of the suboptimality of the choices made. Arguably the most popular algorithm is the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm, which involves acting based on a simple linear estimator of the unknown function. Despite its popularity, existing analyses of GP-UCB give a suboptimal regret rate, which fails to be sublinear for many commonly used kernels such as the Mat\'ern kernel. This has led to a longstanding open question: are existing regret analyses for GP-UCB tight, or can bounds be improved by using more sophisticated analytical techniques? In this work, we resolve this open question and show that GP-UCB enjoys nearly optimal regret. In particular, our results directly imply sublinear regret rate
    
[^36]: 基于Newell理论的特征转换用于时空交通预测

    Newell's theory based feature transformations for spatio-temporal traffic prediction. (arXiv:2307.05949v1 [cs.LG])

    [http://arxiv.org/abs/2307.05949](http://arxiv.org/abs/2307.05949)

    本文提出了一种基于Newell理论的特征转换方法用于时空交通预测，用于改善模型在不同位置的迁移性问题。

    

    深度学习模型在时空交通流预测中使用卷积或图卷积过滤器以及循环神经网络来捕捉交通数据的空间和时间依赖关系。这些模型, 如CNN-LSTM, 利用邻近检测站的交通流来预测特定位置的流量。然而, 这些模型在捕捉交通系统的更广泛动态方面具有局限性, 因为它们主要学习特定于检测配置和目标位置交通特征的特征。因此, 当在新的位置缺少用于模型训练的数据时, 这些模型的可迁移性变得具有挑战性。为了解决这个问题, 我们提出了一个基于交通流物理学的特征转换方法用于时空深度学习模型。

    Deep learning (DL) models for spatio-temporal traffic flow forecasting employ convolutional or graph-convolutional filters along with recurrent neural networks to capture spatial and temporal dependencies in traffic data. These models, such as CNN-LSTM, utilize traffic flows from neighboring detector stations to predict flows at a specific location of interest. However, these models are limited in their ability to capture the broader dynamics of the traffic system, as they primarily learn features specific to the detector configuration and traffic characteristics at the target location. Hence, the transferability of these models to different locations becomes challenging, particularly when data is unavailable at the new location for model training. To address this limitation, we propose a traffic flow physics-based feature transformation for spatio-temporal DL models. This transformation incorporates Newell's uncongested and congested-state estimators of traffic flows at the target loc
    
[^37]: 混合隐马尔可夫LSTM用于短期交通流量预测

    Hybrid hidden Markov LSTM for short-term traffic flow prediction. (arXiv:2307.04954v1 [cs.LG])

    [http://arxiv.org/abs/2307.04954](http://arxiv.org/abs/2307.04954)

    该论文介绍了一种混合隐马尔可夫LSTM模型，用于短期交通流量预测。研究发现，深度学习方法在预测交通变量方面优于传统的参数模型。这种模型结合了循环神经网络和隐马尔可夫模型的优势，能够捕捉交通系统的复杂动态模式和非平稳性。

    

    深度学习方法在预测交通变量的短期和近短期未来方面已经优于参数模型，如历史平均、ARIMA和其变体，这对于交通管理至关重要。具体来说，循环神经网络（RNN）及其变体（例如长短期记忆）被设计用于保留长期时序相关性，因此非常适用于建模序列。然而，多制度模型假设交通系统以不同特征的多个状态（例如畅通、拥堵）演变，因此需要训练不同模型以表征每个制度内的交通动态。例如，使用隐马尔可夫模型进行制度识别的马尔可夫切换模型能够捕捉复杂的动态模式和非平稳性。有趣的是，隐马尔可夫模型和LSTM都可以用于建模从一组潜在的或隐藏状态变量中的观察序列。在LSTM中，潜在变量可以从上一个时间步的隐藏状态变量传递过来。

    Deep learning (DL) methods have outperformed parametric models such as historical average, ARIMA and variants in predicting traffic variables into short and near-short future, that are critical for traffic management. Specifically, recurrent neural network (RNN) and its variants (e.g. long short-term memory) are designed to retain long-term temporal correlations and therefore are suitable for modeling sequences. However, multi-regime models assume the traffic system to evolve through multiple states (say, free-flow, congestion in traffic) with distinct characteristics, and hence, separate models are trained to characterize the traffic dynamics within each regime. For instance, Markov-switching models with a hidden Markov model (HMM) for regime identification is capable of capturing complex dynamic patterns and non-stationarity. Interestingly, both HMM and LSTM can be used for modeling an observation sequence from a set of latent or, hidden state variables. In LSTM, the latent variable 
    
[^38]: 超越直觉，将高斯过程应用于实际数据的框架

    Beyond Intuition, a Framework for Applying GPs to Real-World Data. (arXiv:2307.03093v1 [cs.LG])

    [http://arxiv.org/abs/2307.03093](http://arxiv.org/abs/2307.03093)

    提出了一个框架，用于确定高斯过程在实际问题中的适用性，并建立一个稳健且明确的模型。通过对核函数设计和计算可扩展性选项的指导，该框架在冰川高程变化的案例研究中实现了更准确的结果。

    

    高斯过程（GPs）提供了一种用于小型、结构化和相关数据集的回归的吸引人的方法。然而，它们的应用受到计算成本的限制，并且对于如何将GPs应用于复杂的高维数据集的指导有限。我们提出了一个框架，用于确定GPs在给定问题中的适用性以及如何建立一个强大且明确的GP模型。指导方针形式化了经验丰富的GP实践者的决策，特别强调了核函数设计和计算可扩展性选项。然后，我们将该框架应用于冰川高程变化的案例研究中，在测试时产生了更准确的结果。

    Gaussian Processes (GPs) offer an attractive method for regression over small, structured and correlated datasets. However, their deployment is hindered by computational costs and limited guidelines on how to apply GPs beyond simple low-dimensional datasets. We propose a framework to identify the suitability of GPs to a given problem and how to set up a robust and well-specified GP model. The guidelines formalise the decisions of experienced GP practitioners, with an emphasis on kernel design and options for computational scalability. The framework is then applied to a case study of glacier elevation change yielding more accurate results at test time.
    
[^39]: 无约束在线学习和无界损失的算法

    Unconstrained Online Learning with Unbounded Losses. (arXiv:2306.04923v1 [cs.LG])

    [http://arxiv.org/abs/2306.04923](http://arxiv.org/abs/2306.04923)

    本论文提出了一种算法，可用于解决无界域和非Lipschitz损失的在线学习问题，并提供了一个遗憾的度量，以衡量该算法的性能。此外，我们还利用该算法开发了一种新的鞍点优化算法，即使在没有有意义的曲率的情况下，也能够在无界领域中收敛于对偶间隙。最后，我们提供了一种算法，在无界域和非Lipschitz损失的情况下实现了非平凡的动态遗憾，以及相匹配的下界。

    

    在线学习算法通常需要一个或多个有界性假设：即域是有界的，损失是Lipschitz的或两者都有。在本文中，我们为具有无界域和非Lipschitz损失的在线学习开发了一个新的设置。针对该场景，我们提供了一种算法，可以保证在任何满足子梯度满足$\|g_{t}\|\le G+L\|w_{t}\|$的问题中，其遗憾的度量值$R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$，并且表明除非有进一步 假设，否则该界限是不能进一步改进的。

    Algorithms for online learning typically require one or more boundedness assumptions: that the domain is bounded, that the losses are Lipschitz, or both. In this paper, we develop a new setting for online learning with unbounded domains and non-Lipschitz losses. For this setting we provide an algorithm which guarantees $R_{T}(u)\le \tilde O(G\|u\|\sqrt{T}+L\|u\|^{2}\sqrt{T})$ regret on any problem where the subgradients satisfy $\|g_{t}\|\le G+L\|w_{t}\|$, and show that this bound is unimprovable without further assumptions. We leverage this algorithm to develop new saddle-point optimization algorithms that converge in duality gap in unbounded domains, even in the absence of meaningful curvature. Finally, we provide the first algorithm achieving non-trivial dynamic regret in an unbounded domain for non-Lipschitz losses, as well as a matching lower bound. The regret of our dynamic regret algorithm automatically improves to a novel $L^{*}$ bound when the losses are smooth.
    
[^40]: 利用aggVAE进行深度学习和MCMC以处理行政边界变化：以肯尼亚的疟疾患病率为例

    Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya. (arXiv:2305.19779v1 [cs.LG])

    [http://arxiv.org/abs/2305.19779](http://arxiv.org/abs/2305.19779)

    本研究提出了一种利用aggVAE进行深度学习和MCMC处理行政边界变化的解决方案，可以更准确地映射以县为层级的聚合级别数据，并处理行政边界的变化，相比最先进的模型表现更好。

    

    基于模型的疾病映射是公共卫生和疾病监测中基本的政策信息工具，分层贝叶斯模型是当前最先进的方法。当处理区域数据，如行政区划单位（例如县或省）的聚合数据时，常用的模型依赖于区域单元的相邻结构以考虑空间相关性。疾病监测系统的目标是随时间跟踪疾病结果，但在危机情况下（例如政治变化导致行政边界更改），这将带来挑战。我们提出了一种新颖、实用和易于实施的解决方案，该方案依赖于组合深层生成模型和全贝叶斯推断。我们建立在现有的变分自编码器(VAE) 工作上，并展示我们提出的聚合VAE(aggVAE)体系结构可用于在以县为层级的聚合级别处理数据，以映射肯尼亚的疟疾患病率。我们的模型可以以连续的方式考虑空间相关性，而不依赖于相邻性假设，并且能够处理行政边界的变化。结果表明，相比最先进的模型，我们的模型表现出更好的性能和更准确的疟疾患病率映射。

    Model-based disease mapping remains a fundamental policy-informing tool in public health and disease surveillance with hierarchical Bayesian models being the current state-of-the-art approach. When working with areal data, e.g. aggregates at the administrative unit level such as district or province, routinely used models rely on the adjacency structure of areal units to account for spatial correlations. The goal of disease surveillance systems is to track disease outcomes over time, but this provides challenging in situations of crises, such as political changes, leading to changes of administrative boundaries. Kenya is an example of such country. Moreover, adjacency-based approach ignores the continuous nature of spatial processes and cannot solve the change-of-support problem, i.e. when administrative boundaries change. We present a novel, practical, and easy to implement solution relying on a methodology combining deep generative modelling and fully Bayesian inference. We build on 
    
[^41]: 最优预条件和费舍尔自适应 Langevin 采样

    Optimal Preconditioning and Fisher Adaptive Langevin Sampling. (arXiv:2305.14442v1 [stat.ML])

    [http://arxiv.org/abs/2305.14442](http://arxiv.org/abs/2305.14442)

    通过最优预条件和费舍尔自适应 Langevin 采样，提出了一种计算有效且在高维中非常强健的自适应 MCMC 方案。

    

    我们通过分析最大化预期平方跳跃距离，为 Langevin 扩散定义了最优预条件。这导致最优预条件为反费舍尔信息协方差矩阵，其中协方差矩阵是在目标下平均对数目标梯度的外积。我们将此结果应用于 Metropolis 调整 Langevin 算法 (MALA)，并推导出一种从算法运行产生的梯度历史中学习预条件的计算有效的自适应 MCMC 方案。我们在几个实验中展示了所提出的算法在高维中非常强健，并且明显优于其他方法，包括使用标准自适应 MCMC 学习预条件和位置相关的 Riemann 流形 MALA 采样器的密切相关的自适应 MALA 方案。

    We define an optimal preconditioning for the Langevin diffusion by analytically maximizing the expected squared jumped distance. This yields as the optimal preconditioning an inverse Fisher information covariance matrix, where the covariance matrix is computed as the outer product of log target gradients averaged under the target. We apply this result to the Metropolis adjusted Langevin algorithm (MALA) and derive a computationally efficient adaptive MCMC scheme that learns the preconditioning from the history of gradients produced as the algorithm runs. We show in several experiments that the proposed algorithm is very robust in high dimensions and significantly outperforms other methods, including a closely related adaptive MALA scheme that learns the preconditioning with standard adaptive MCMC as well as the position-dependent Riemannian manifold MALA sampler.
    
[^42]: 通过能量感知的早期退出实现可持续的边缘智能

    Sustainable Edge Intelligence Through Energy-Aware Early Exiting. (arXiv:2305.14094v1 [eess.SY])

    [http://arxiv.org/abs/2305.14094](http://arxiv.org/abs/2305.14094)

    本文提出了能量自适应动态早期退出机制，通过能量感知的策略，在EH边缘设备中实现了高效准确推理。

    

    深度学习模型已成为物联网应用的一种有前途的解决方案。然而，由于其计算复杂性，深度学习模型消耗大量能量，这可能会快速耗尽电池并影响物联网设备的性能。为了实现可持续运行，本文考虑一个带有可充电电池和能量收获能力的边缘设备。除了环境能源的随机性外，收获速率通常不足以满足推理能源需求，在能源不可知的设备中会导致严重的性能降低。为了解决这个问题，我们提出了能量自适应动态早期退出机制，以实现在充满环境能源情况下的高效准确推理。

    Deep learning (DL) models have emerged as a promising solution for Internet of Things (IoT) applications. However, due to their computational complexity, DL models consume significant amounts of energy, which can rapidly drain the battery and compromise the performance of IoT devices. For sustainable operation, we consider an edge device with a rechargeable battery and energy harvesting (EH) capabilities. In addition to the stochastic nature of the ambient energy source, the harvesting rate is often insufficient to meet the inference energy requirements, leading to drastic performance degradation in energy-agnostic devices. To mitigate this problem, we propose energy-adaptive dynamic early exiting (EE) to enable efficient and accurate inference in an EH edge intelligence system. Our approach derives an energy-aware EE policy that determines the optimal amount of computational processing on a per-sample basis. The proposed policy balances the energy consumption to match the limited inco
    
[^43]: 子采样岭回归集成：等效性和广义交叉验证

    Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation. (arXiv:2304.13016v1 [math.ST])

    [http://arxiv.org/abs/2304.13016](http://arxiv.org/abs/2304.13016)

    研究了比例渐近情形下的子采样岭回归集成，证明了最优全岭回归集成的风险与最优岭预测器的风险相匹配，并证明了GCV在估计岭回归集合的预测风险方面的强一致性。

    

    我们研究了比例渐近情形下的子采样岭回归集成，其中特征大小与样本大小成比例增长，使得它们的比率收敛到一个常数。通过分析岭回归集合的平方预测风险作为显式惩罚$\lambda$和极限子样本方面比$\phi_s$（特征大小与子样本大小的比率）的函数，我们表征了在任何可达风险下的$(\lambda, \phi_s)$-平面上的轮廓。因此，我们证明最优全岭回归集成（适合于所有可能的子样本）的风险与最优岭预测器的风险相匹配。此外，我们证明对于估计岭回归集合的预测风险，基于广义交叉验证（GCV）的子样本大小强一致性。这允许无需样本拆分基于GCV优化全局岭回归集成，并产生一个风险与最优岭回归风险相匹配的预测器。

    We study subsampling-based ridge ensembles in the proportional asymptotics regime, where the feature size grows proportionally with the sample size such that their ratio converges to a constant. By analyzing the squared prediction risk of ridge ensembles as a function of the explicit penalty $\lambda$ and the limiting subsample aspect ratio $\phi_s$ (the ratio of the feature size to the subsample size), we characterize contours in the $(\lambda, \phi_s)$-plane at any achievable risk. As a consequence, we prove that the risk of the optimal full ridgeless ensemble (fitted on all possible subsamples) matches that of the optimal ridge predictor. In addition, we prove strong uniform consistency of generalized cross-validation (GCV) over the subsample sizes for estimating the prediction risk of ridge ensembles. This allows for GCV-based tuning of full ridgeless ensembles without sample splitting and yields a predictor whose risk matches optimal ridge risk.
    
[^44]: 学习相似的线性表示：适应性、极小化、以及稳健性

    Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness. (arXiv:2303.17765v1 [stat.ML])

    [http://arxiv.org/abs/2303.17765](http://arxiv.org/abs/2303.17765)

    本文提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置。

    

    表示多任务学习和迁移学习在实践中取得了巨大的成功，然而对这些方法的理论理解仍然欠缺。本文旨在理解从具有相似但并非完全相同的线性表示的任务中学习，同时处理异常值任务。我们提出了两种算法，适应相似性结构并对异常值任务具有稳健性，适用于表示多任务学习和迁移学习设置，我们的算法在单任务或仅目标学习时表现优异。

    Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \textit{adaptive} to the similarity structure and \textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when
    
[^45]: 在元树上批量更新后验树分布。

    Batch Updating of a Posterior Tree Distribution over a Meta-Tree. (arXiv:2303.09705v1 [cs.LG])

    [http://arxiv.org/abs/2303.09705](http://arxiv.org/abs/2303.09705)

    本文提出了一个更高效的批量更新方法，用于在元树上计算后验分布。

    

    以前，我们提出了一个由不可观察的树和一个序列更新方法表示的概率数据生成模型，用于计算一组树上的后验分布。该集合称为元树。在本文中，我们提出了一种更高效的批量更新方法。

    Previously, we proposed a probabilistic data generation model represented by an unobservable tree and a sequential updating method to calculate a posterior distribution over a set of trees. The set is called a meta-tree. In this paper, we propose a more efficient batch updating method.
    
[^46]: 从二进制测量中学习信号重构

    Learning to Reconstruct Signals From Binary Measurements. (arXiv:2303.08691v1 [eess.SP])

    [http://arxiv.org/abs/2303.08691](http://arxiv.org/abs/2303.08691)

    该论文提出了一种新的自监督学习方法SSBM，它只需要二进制数据进行训练，并探索了从不完整的二进制观察中学习的极端情况。这为从二进制测量中恢复信号提供了必要和充分条件，并在一系列真实数据集上展示了SSBM的卓越表现。

    

    无监督学习的最新进展突出了仅从噪声和不完整的线性测量中学习信号重构的可能性。这些方法在医学和科学成像以及传感中起到关键作用，其中地面真实数据经常稀缺或难以获得。然而，在实践中，测量不仅噪声和不完整，而且还被量化。在这里，我们探索从二进制观察中学习的极端情况，并提供了关于从不完整二进制数据中识别一组信号所需的测量数量的必要和充分条件。我们的结果是对从二进制测量中信号恢复现有界限的补充。此外，我们引入了一种新颖的自监督学习方法，我们将其命名为“SSBM”，它仅需要二进制数据进行训练。我们在一系列真实数据集上的实验证明SSBM与监督学习相当，并优于稀疏重构方法。

    Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice, measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods wit
    
[^47]: 变调神经ODEs

    Modulated Neural ODEs. (arXiv:2302.13262v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13262](http://arxiv.org/abs/2302.13262)

    变调神经ODEs （MoNODEs）是一种新的框架，能够将动力学状态与基础静态变化因素分开，并改进了现有的神经ODE方法。该方法通过引入时间不变的调制变量来捕捉轨迹间的变化，并在测试中展现出在振荡系统、视频和人类行走轨迹等方面具有提高模型泛化能力的效果。

    

    神经常微分方程（NODEs）已被证明对于学习任意轨迹的非线性动力学很有用。然而，当前的NODE方法仅通过初始状态值或自回归编码器更新来捕捉轨迹间的变化。在这项工作中，我们引入了变调神经ODEs（MoNODEs），这是一个将动力学状态与基础静态变化因素分开并改进现有NODE方法的新框架。特别地，我们引入了从数据中学习的“时间不变调制变量”。我们将我们提出的框架结合到四种现有的NODE变体中。我们在振荡系统、视频和人类行走轨迹上对MoNODE进行了测试，其中每个轨迹都具有轨迹特定的调制。我们的框架始终提高了现有模型的泛化能力，使其能够适应新的动态参数化并进行远期预测。此外，我们验证了提出的调制变量的信息量。

    Neural ordinary differential equations (NODEs) have been proven useful for learning non-linear dynamics of arbitrary trajectories. However, current NODE methods capture variations across trajectories only via the initial state value or by auto-regressive encoder updates. In this work, we introduce Modulated Neural ODEs (MoNODEs), a novel framework that sets apart dynamics states from underlying static factors of variation and improves the existing NODE methods. In particular, we introduce $\textit{time-invariant modulator variables}$ that are learned from the data. We incorporate our proposed framework into four existing NODE variants. We test MoNODE on oscillating systems, videos and human walking trajectories, where each trajectory has trajectory-specific modulation. Our framework consistently improves the existing model ability to generalize to new dynamic parameterizations and to perform far-horizon forecasting. In addition, we verify that the proposed modulator variables are infor
    
[^48]: 信号处理和机器学习中超越梯度的随机逼近

    Stochastic Approximation Beyond Gradient for Signal Processing and Machine Learning. (arXiv:2302.11147v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2302.11147](http://arxiv.org/abs/2302.11147)

    本文介绍了随机逼近算法在信号处理和机器学习中的非随机梯度视角，提出了一个通用框架来统一现有的SA理论，包括非渐近和渐近收敛结果。

    

    随机逼近（SA）是一个经典的算法，在信号处理方面从早期就产生了巨大的影响，现在在机器学习中也因处理大量带有不确定性的数据而变得重要。一个典型的SA特例是流行的随机（子）梯度算法，它是许多重要应用的关键。一个较少人知道的事实是，SA方案也适用于非随机梯度算法，如压缩随机梯度、随机期望最大化和一些强化学习算法。本文的目的是通过提供支持理论的SA算法设计指南，概述和介绍SA的非随机梯度视角，以便吸引信号处理和机器学习研究者的注意。我们的核心主题是提出一个统一现有SA理论的通用框架，包括其非渐近和渐近收敛结果。

    Stochastic Approximation (SA) is a classical algorithm that has had since the early days a huge impact on signal processing, and nowadays on machine learning, due to the necessity to deal with a large amount of data observed with uncertainties. An exemplar special case of SA pertains to the popular stochastic (sub)gradient algorithm which is the working horse behind many important applications. A lesser-known fact is that the SA scheme also extends to non-stochastic-gradient algorithms such as compressed stochastic gradient, stochastic expectation-maximization, and a number of reinforcement learning algorithms. The aim of this article is to overview and introduce the non-stochastic-gradient perspectives of SA to the signal processing and machine learning audiences through presenting a design guideline of SA algorithms backed by theories. Our central theme is to propose a general framework that unifies existing theories of SA, including its non-asymptotic and asymptotic convergence resu
    
[^49]: 自由形式的高斯过程状态空间模型的变分推断

    Free-Form Variational Inference for Gaussian Process State-Space Models. (arXiv:2302.09921v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09921](http://arxiv.org/abs/2302.09921)

    本文提出了一种自由形式的变分推断方法，用于高斯过程状态空间模型（GPSSMs）。该方法克服了以前方法的缺点，并展示了在计算效率和推断准确性上的优势。

    

    高斯过程状态空间模型（GPSSMs）为建模潜在状态的动态提供了一种有原则和灵活的方法，通过似然模型以离散时间点观测。然而，由于模型中潜在变量的数量较大且它们之间存在强时序依赖性，因此在 GPSSMs 中进行推断是计算上和统计上具有挑战性的。在本文中，我们提出了一种在贝叶斯 GPSSMs 中进行推断的新方法，克服了以前方法的缺点，即过于简化的假设和高计算要求。我们的方法基于在诱导变量形式主义内通过随机梯度哈密顿蒙特卡罗进行自由形式的变分推断。此外，通过利用我们提出的变分分布，我们提供了一种折叠扩展方法，其中诱导变量在解析上进行边际化。我们还展示了将我们的框架与粒子 MCMC 方法相结合的结果。我们展示了在s上的结果表明，我们的方法在计算效率和推断准确性上都具有优势。

    Gaussian process state-space models (GPSSMs) provide a principled and flexible approach to modeling the dynamics of a latent state, which is observed at discrete-time points via a likelihood model. However, inference in GPSSMs is computationally and statistically challenging due to the large number of latent variables in the model and the strong temporal dependencies between them. In this paper, we propose a new method for inference in Bayesian GPSSMs, which overcomes the drawbacks of previous approaches, namely over-simplified assumptions, and high computational requirements. Our method is based on free-form variational inference via stochastic gradient Hamiltonian Monte Carlo within the inducing-variable formalism. Furthermore, by exploiting our proposed variational distribution, we provide a collapsed extension of our method where the inducing variables are marginalized analytically. We also showcase results when combining our framework with particle MCMC methods. We show that, on s
    
[^50]: 面向对抗生成模型的PAC-Bayesian泛化界

    PAC-Bayesian Generalization Bounds for Adversarial Generative Models. (arXiv:2302.08942v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08942](http://arxiv.org/abs/2302.08942)

    将PAC-Bayesian理论扩展到生成模型，为基于Wasserstein距离和总变差距离的模型提供了泛化界，为Wasserstein GAN和Energy-Based GAN提供了新的训练目标，并在合成数据集上展示出非虚空泛化界。

    

    我们将PAC-Bayesian理论扩展到生成模型，并为基于Wasserstein距离和总变差距离的模型开发了泛化界。我们第一个关于Wasserstein距离的结果假设实例空间是有界的，而我们的第二个结果利用了降维的优势。我们的结果自然适用于Wasserstein GAN和Energy-Based GAN，而我们的界限为这两种GAN提供了新的训练目标。尽管我们的工作主要是理论性的，但我们进行了数值实验，展示了Wasserstein GAN在合成数据集上的非虚空泛化界。

    We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.
    
[^51]: 一种简单的零样本提示加权技术，以改善文本-图像模型中的提示集成

    A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models. (arXiv:2302.06235v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06235](http://arxiv.org/abs/2302.06235)

    这项工作提出了一种简单的零样本提示加权技术，通过提示集成来自动化提示工程，从而提高文本-图像模型的零样本分类准确性。

    

    对比训练的文本-图像模型具有显著的零样本分类能力，即将以前未见过的图像分类为模型从未明确训练过的类别。然而，这些零样本分类器需要提示工程来达到高准确性。提示工程通常需要手工创建一组用于个别下游任务的提示。在这项工作中，我们的目标是通过提示集成来自动化这个提示工程，并提高零样本准确性。具体而言，我们提出了一个问题：“给定大量的提示，我们是否可以自动评分提示并集成那些对特定下游数据集最合适的提示，而无需访问有标签的验证数据？”我们证明这是可能的。在这样做的过程中，我们确定了一个天真的提示评分方法中的几个病理问题，其中分数很容易因预训练和测试数据中的偏见而过于自信，我们提出了一种新颖的提示评分方法。

    Contrastively trained text-image models have the remarkable ability to perform zero-shot classification, that is, classifying previously unseen images into categories that the model has never been explicitly trained to identify. However, these zero-shot classifiers need prompt engineering to achieve high accuracy. Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks. In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling. In particular, we ask "Given a large pool of prompts, can we automatically score the prompts and ensemble those that are most suitable for a particular downstream dataset, without needing access to labeled validation data?". We demonstrate that this is possible. In doing so, we identify several pathologies in a naive prompt scoring method where the score can be easily overconfident due to biases in pre-training and test data, and we propose a novel prompt scoring
    
[^52]: 通过牛顿方法实现鲁棒经验风险最小化研究

    Robust empirical risk minimization via Newton's method. (arXiv:2301.13192v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.13192](http://arxiv.org/abs/2301.13192)

    本研究提出了一种鲁棒经验风险最小化的新的牛顿方法变种，并通过使用鲁棒估计方法来替换梯度和海森矩阵，证明了连续迭代收敛到种群水平最小化器周围小球。该方法在广义线性模型中的应用具有潜在的优势，并提出了一种基于共轭梯度方法的算法来获取鲁棒牛顿方向。

    

    本文研究了一种新的牛顿方法变种，用于经验风险最小化。在优化算法的每次迭代中，目标函数的梯度和海森矩阵被替换为现有文献中针对多变量数据的鲁棒估计方法。在证明了连续迭代收敛到种群水平最小化器周围小球的一般定理之后，研究了当数据来自Huber的epsilon污染模型和/或重尾分布时，该理论在广义线性模型中的后果。还提出了一种基于共轭梯度方法获取鲁棒牛顿方向的算法，这可能更适用于高维情况，并提出了关于结果算法收敛性的猜想。与鲁棒梯度下降相比，所提出的算法能够实现更快的收敛速度。

    A new variant of Newton's method for empirical risk minimization is studied, where at each iteration of the optimization algorithm, the gradient and Hessian of the objective function are replaced by robust estimators taken from existing literature on robust mean estimation for multivariate data. After proving a general theorem about the convergence of successive iterates to a small ball around the population-level minimizer, consequences of the theory in generalized linear models are studied when data are generated from Huber's epsilon-contamination model and/or heavytailed distributions. An algorithm for obtaining robust Newton directions based on the conjugate gradient method is also proposed, which may be more appropriate for high-dimensional settings, and conjectures about the convergence of the resulting algorithm are offered. Compared to robust gradient descent, the proposed algorithm enjoys the faster rates of convergence for successive iterates often achieved by second-order al
    
[^53]: 了解最佳子集选择: 两种复杂性的故事

    Understanding Best Subset Selection: A Tale of Two C(omplex)ities. (arXiv:2301.06259v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2301.06259](http://arxiv.org/abs/2301.06259)

    本文研究了最佳子集选择在高维稀疏线性回归设置中的变量选择性质，通过研究残差化特征和虚假投影的复杂性来揭示模型一致性的边界条件。

    

    几十年来，最佳子集选择(BSS)主要由于计算瓶颈而困扰统计学家。然而，直到最近，现代计算突破重新点燃了对BSS的理论兴趣并导致了新的发现。最近，Guo等人表明，BSS的模型选择性能受到了鲁棒性设计依赖的边界量的控制，不像LASSO、SCAD、MCP等现代方法。在他们的理论结果的激励下，本文还研究了高维稀疏线性回归设置下最佳子集选择的变量选择性质。我们展示了除了可辨识性边界以外，下列两种复杂性度量在表征模型一致性边界条件中起着基本的作用：(a)“残差化特征”的复杂性，(b)“虚假投影”的复杂性。特别地，我们建立了一个仅依赖于可辨识性边界的简单边界条件。

    For decades, best subset selection (BSS) has eluded statisticians mainly due to its computational bottleneck. However, until recently, modern computational breakthroughs have rekindled theoretical interest in BSS and have led to new findings. Recently, \cite{guo2020best} showed that the model selection performance of BSS is governed by a margin quantity that is robust to the design dependence, unlike modern methods such as LASSO, SCAD, MCP, etc. Motivated by their theoretical results, in this paper, we also study the variable selection properties of best subset selection for high-dimensional sparse linear regression setup. We show that apart from the identifiability margin, the following two complexity measures play a fundamental role in characterizing the margin condition for model consistency: (a) complexity of \emph{residualized features}, (b) complexity of \emph{spurious projections}. In particular, we establish a simple margin condition that depends only on the identifiability mar
    
[^54]: 近似最优的非参数顺序检验和具有可能相关观测的置信区间

    Near-Optimal Non-Parametric Sequential Tests and Confidence Sequences with Possibly Dependent Observations. (arXiv:2212.14411v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2212.14411](http://arxiv.org/abs/2212.14411)

    本文研究了非参数顺序检验和置信区间，在一般非参数数据生成过程下提供了类型I错误和期望拒绝时间保证，提高了其灵活性和性能。

    

    顺序检验和其隐含的置信区间在任意停止时间下都能提供灵活的统计推断和即时决策。然而，强有力的保证仅适用于在实践中低估或浓度界限为基础的顺序序列，而这些序列具有次优的拒绝时间。在本文中，我们考虑罗宾斯（Robbins）1970年的延迟启动正态混合顺序概率比检验，并在一般非参数数据生成过程下提供了首个渐近类型I错误和期望拒绝时间保证，其中渐近性质由测试的烧入时间确定。类型I错误的结果主要依赖于鞅强不变原理，并证明这些检验（及其隐含的置信区间）具有接近所需α水平的类型I错误率。期望拒绝时间的结果主要利用了一种受伊藤引理启发的恒等式。

    Sequential tests and their implied confidence sequences, which are valid at arbitrary stopping times, promise flexible statistical inference and on-the-fly decision making. However, strong guarantees are limited to parametric sequential tests that under-cover in practice or concentration-bound-based sequences that over-cover and have suboptimal rejection times. In this work, we consider \cite{robbins1970boundary}'s delayed-start normal-mixture sequential probability ratio tests, and we provide the first asymptotic type-I-error and expected-rejection-time guarantees under general non-parametric data generating processes, where the asymptotics are indexed by the test's burn-in time. The type-I-error results primarily leverage a martingale strong invariance principle and establish that these tests (and their implied confidence sequences) have type-I error rates approaching a desired $\alpha$-level. The expected-rejection-time results primarily leverage an identity inspired by It\^o's lemm
    
[^55]: PAC-Bayes定理在Bandit问题中的应用：一项调查与实验比较

    PAC-Bayes Bounds for Bandit Problems: A Survey and Experimental Comparison. (arXiv:2211.16110v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16110](http://arxiv.org/abs/2211.16110)

    这项调查研究了PAC-Bayes在Bandit问题中的应用，提供了界限的概述，并进行了实验比较。研究发现，PAC-Bayes界限是设计具有性能保证的离线Bandit算法的有用工具，但在线Bandit算法缺乏足够的数据以产生强大的性能保证。

    

    PAC-Bayes最近重新出现作为一种有效的理论，可以用来推导出具有紧密性能保证的有原则的学习算法。然而，PAC-Bayes在Bandit问题中的应用相对较少，这是一个很大的遗憾。在医疗保健、金融和自然科学等许多决策问题中，都可以将其建模为Bandit问题。在许多这些应用中，带有强大性能保证的有原则算法将会受到很高的赞赏。本调查提供了关于Bandit问题的PAC-Bayes界限的概述，并进行了这些界限的实验比较。一方面，我们发现PAC-Bayes界限是设计具有性能保证的离线Bandit算法的有用工具。在我们的实验中，一种PAC-Bayesian离线上下文Bandit算法能够学习具有竞争性预期奖励和非空性能保证的随机化神经网络策略。另一方面，PAC-Bayesian在线Bandit算法则缺乏足够的数据以产生强大的性能保证。

    PAC-Bayes has recently re-emerged as an effective theory with which one can derive principled learning algorithms with tight performance guarantees. However, applications of PAC-Bayes to bandit problems are relatively rare, which is a great misfortune. Many decision-making problems in healthcare, finance and natural sciences can be modelled as bandit problems. In many of these applications, principled algorithms with strong performance guarantees would be very much appreciated. This survey provides an overview of PAC-Bayes bounds for bandit problems and an experimental comparison of these bounds. On the one hand, we found that PAC-Bayes bounds are a useful tool for designing offline bandit algorithms with performance guarantees. In our experiments, a PAC-Bayesian offline contextual bandit algorithm was able to learn randomised neural network polices with competitive expected reward and non-vacuous performance guarantees. On the other hand, the PAC-Bayesian online bandit algorithms that
    
[^56]: 在Sobolev和Besov空间上，关于深度ReLU神经网络的最佳逼近速率研究

    Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov Spaces. (arXiv:2211.14400v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.14400](http://arxiv.org/abs/2211.14400)

    该论文研究了在Sobolev和Besov空间中，使用ReLU激活函数的深度神经网络能够以怎样的参数效率逼近函数，包括$L_p(\Omega)$范数下的误差度量。我们提供了所有$1\leq p,q \leq \infty$和$s>0$的完整解决方案，并引入了一种新的位提取技术来获得尖锐的上界。

    

    本文研究了使用ReLU激活函数的深度神经网络在Sobolev空间$W^s(L_q(\Omega))$和Besov空间$B^s_r(L_q(\Omega))$中以$L_p(\Omega)$范数度量误差的参数效率问题。我们的研究对于在科学计算和信号处理等领域中应用神经网络非常重要，在过去只有当$p=q=\infty$时才完全解决。我们的贡献是提供了所有$1\leq p,q\leq \infty$和$s>0$的完整解决方案，包括渐近匹配的上下界。关键的技术工具是一种新的位提取技术，它提供了稀疏向量的最佳编码。这使我们能够在$p>q$的非线性区域获得尖锐的上界。我们还提供了一种基于的$L_p$逼近下界推导的新方法。

    Let $\Omega = [0,1]^d$ be the unit cube in $\mathbb{R}^d$. We study the problem of how efficiently, in terms of the number of parameters, deep neural networks with the ReLU activation function can approximate functions in the Sobolev spaces $W^s(L_q(\Omega))$ and Besov spaces $B^s_r(L_q(\Omega))$, with error measured in the $L_p(\Omega)$ norm. This problem is important when studying the application of neural networks in a variety of fields, including scientific computing and signal processing, and has previously been completely solved only when $p=q=\infty$. Our contribution is to provide a complete solution for all $1\leq p,q\leq \infty$ and $s > 0$, including asymptotically matching upper and lower bounds. The key technical tool is a novel bit-extraction technique which gives an optimal encoding of sparse vectors. This enables us to obtain sharp upper bounds in the non-linear regime where $p > q$. We also provide a novel method for deriving $L_p$-approximation lower bounds based upon
    
[^57]: 使用高斯混合模型的自然梯度变分推断的统一视角

    A Unified Perspective on Natural Gradient Variational Inference with Gaussian Mixture Models. (arXiv:2209.11533v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.11533](http://arxiv.org/abs/2209.11533)

    本论文提出了一种统一的视角来理解使用高斯混合模型进行自然梯度变分推断的方法。研究发现，VIPS和iBayes-GMM这两种目前最有效的方法，在更新各个组件和权重时使用的自然梯度更新是等价的，但其实现和理论保证存在差异。研究还发现，这两种方法在样本选择、自然梯度估计、步长适应以及可信区域或组件数量的调整等设计选择上存在区别，对于学习近似的质量有重要影响。

    

    使用高斯混合模型（GMM）进行变分推断能够以高度可行但多模态的方式学习难以处理的目标分布，具有最多几百个维度。目前对于基于GMM的变分推断来说，VIPS和iBayes-GMM是最有效的两种方法，它们都使用独立的自然梯度更新来更新各个组件及其权重。我们首次证明了它们派生的更新是等价的，尽管它们的实际实现和理论保证有所不同。我们确定了几个区分这两种方法的设计选择，包括样本选择、自然梯度估计、步长适应以及是否强制实施可信区域或调整组件的数量。我们认为，对于这两种方法，所学近似的质量可能会受到相应设计选择的严重影响：通过使用混合模型中的样本来更新各个组件，iBayes-GMM的学习近似质量可能受到更严重影响。

    Variational inference with Gaussian mixture models (GMMs) enables learning of highly tractable yet multi-modal approximations of intractable target distributions with up to a few hundred dimensions. The two currently most effective methods for GMM-based variational inference, VIPS and iBayes-GMM, both employ independent natural gradient updates for the individual components and their weights. We show for the first time, that their derived updates are equivalent, although their practical implementations and theoretical guarantees differ. We identify several design choices that distinguish both approaches, namely with respect to sample selection, natural gradient estimation, stepsize adaptation, and whether trust regions are enforced or the number of components adapted. We argue that for both approaches, the quality of the learned approximations can heavily suffer from the respective design choices: By updating the individual components using samples from the mixture model, iBayes-GMM of
    
[^58]: 可解释的气候科学的核心学习

    Kernel Learning for Explainable Climate Science. (arXiv:2209.04947v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.04947](http://arxiv.org/abs/2209.04947)

    本文通过使用具有结构化非平稳核的高斯过程来模拟上游印度河流域的降水模式，解决了对该地区复杂时空降水分布的理解不足的问题。

    

    喜马拉雅山上游印度河流域为2.7亿人口和无数生态系统提供水资源。然而，降水作为水文模拟的关键组成部分，在这个地区的理解还很有限。这种不确定性围绕在河流域的复杂时空降水分布。本文提出使用具有结构化非平稳核的高斯过程来模拟上游印度河流域的降水模式。以往在印度喜马拉雅山区量化或模拟降水的尝试往往是定性的，包括了粗糙的假设和简化，无法解决低分辨率下的问题。此外，这些研究几乎没有考虑误差传播。我们利用非平稳的吉布斯核和依赖输入的长度参数来考虑降水的空间变化，使得后验函数样本能够适应这一区域固有的降水模式的多样性。

    The Upper Indus Basin, Himalayas provides water for 270 million people and countless ecosystems. However, precipitation, a key component to hydrological modelling, is poorly understood in this area. A key challenge surrounding this uncertainty comes from the complex spatial-temporal distribution of precipitation across the basin. In this work we propose Gaussian processes with structured non-stationary kernels to model precipitation patterns in the UIB. Previous attempts to quantify or model precipitation in the Hindu Kush Karakoram Himalayan region have often been qualitative or include crude assumptions and simplifications which cannot be resolved at lower resolutions. This body of research also provides little to no error propagation. We account for the spatial variation in precipitation with a non-stationary Gibbs kernel parameterised with an input dependent lengthscale. This allows the posterior function samples to adapt to the varying precipitation patterns inherent in the distin
    
[^59]: 一种比较多个机器学习算法在多个数据集上的贝叶斯Bradley-Terry模型

    A Bayesian Bradley-Terry model to compare multiple ML algorithms on multiple data sets. (arXiv:2208.04935v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.04935](http://arxiv.org/abs/2208.04935)

    本文提出了一种基于贝叶斯模型的Bradley-Terry模型，用于比较多个机器学习算法在多个数据集上的性能，与传统方法不同，贝叶斯方法能提供更细致的算法之间差异描述，并允许对等效性进行定义。

    

    本文提出了一种基于贝叶斯模型的方法，用于比较多个算法在多个数据集上的表现。该模型基于Bradley-Terry模型，统计了一个算法在不同数据集上优于另一个算法的次数。与频率派方法（如Demsar（2006）的平均排名比较测试和Benavoli等人（2016）的多个配对Wilcoxon测试与p调整过程）相比，基于贝叶斯的Bradley-Terry模型（BBT）具有不同的特点。特别是，贝叶斯方法允许对算法进行更加细致的描述，而不仅仅声称差异具有或不具有统计显著性。贝叶斯方法还允许定义两个算法在实际目的下是否等效，或实际等效区域（ROPE）。与Benavoli等人（2017）提出的贝叶斯符号秩比较方法不同，我们的方法具有一些独特的特点。

    This paper proposes a Bayesian model to compare multiple algorithms on multiple data sets, on any metric. The model is based on the Bradley-Terry model, that counts the number of times one algorithm performs better than another on different data sets. Because of its Bayesian foundations, the Bayesian Bradley Terry model (BBT) has different characteristics than frequentist approaches to comparing multiple algorithms on multiple data sets, such as Demsar (2006) tests on mean rank, and Benavoli et al. (2016) multiple pairwise Wilcoxon tests with p-adjustment procedures. In particular, a Bayesian approach allows for more nuanced statements regarding the algorithms beyond claiming that the difference is or it is not statistically significant. Bayesian approaches also allow to define when two algorithms are equivalent for practical purposes, or the region of practical equivalence (ROPE). Different than a Bayesian signed rank comparison procedure proposed by Benavoli et al. (2017), our approa
    
[^60]: 使用邻域不变性预测域外泛化

    Predicting Out-of-Domain Generalization with Neighborhood Invariance. (arXiv:2207.02093v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.02093](http://arxiv.org/abs/2207.02093)

    提出了一种测量分类器输出在局部转换邻域中不变性的方法，用于描述模型的泛化能力，不依赖于数据分布或模型假设，可应用于域外环境。

    

    安全地开发和部署机器学习模型取决于对其泛化能力在新环境中的特征和比较能力。尽管最近的工作提出了一系列可以直接预测或理论上限制模型的泛化能力的方法，但它们都依赖于匹配的训练/测试分布和访问模型梯度等强假设。为了在这些假设不满足时描述泛化能力，我们提出了邻域不变性，一种分类器在局部转换邻域中输出不变的度量。具体而言，我们采样一组转换，对于一个输入测试点，计算不变性作为被分类为同一类别的转换点的最大比例。关键的是，我们的度量方法简单易计算，不依赖于测试点的真实标签，不对数据分布或模型做任何假设，甚至可以在域外环境下应用。

    Developing and deploying machine learning models safely depends on the ability to characterize and compare their abilities to generalize to new environments. Although recent work has proposed a variety of methods that can directly predict or theoretically bound the generalization capacity of a model, they rely on strong assumptions such as matching train/test distributions and access to model gradients. In order to characterize generalization when these assumptions are not satisfied, we propose neighborhood invariance, a measure of a classifier's output invariance in a local transformation neighborhood. Specifically, we sample a set of transformations and given an input test point, calculate the invariance as the largest fraction of transformed points classified into the same class. Crucially, our measure is simple to calculate, does not depend on the test point's true label, makes no assumptions about the data distribution or model, and can be applied even in out-of-domain (OOD) setti
    
[^61]: SGD和权重衰减在神经网络中被证明会引入低秩偏差

    SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks. (arXiv:2206.05794v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.05794](http://arxiv.org/abs/2206.05794)

    使用SGD和权重衰减训练深度ReLU神经网络会导致对于权重矩阵的秩最小化的偏差，特别是在使用较小批量大小、更高学习率或增加权重衰减时更为显著。此外，在中间神经网络崩溃时，学习的权重特别低秩。这种偏差与泛化之间存在关系。

    

    我们研究了使用随机梯度下降（SGD）在训练深度ReLU神经网络时学习低秩权重矩阵的偏差。我们的结果表明，使用小批量SGD和权重衰减来训练神经网络会导致对于权重矩阵的秩最小化的偏差。具体而言，我们通过理论和实验证明，当使用较小的批量大小、更高的学习率或增加的权重衰减时，这种偏差更加显著。此外，我们预测并通过实验证明，权重衰减是实现这种偏差的必要条件。此外，我们还发现在中间神经网络崩溃的情况下，学习的权重特别低秩。与先前的文献不同，我们的分析不依赖于关于数据、收敛性或权重矩阵优化的假设。此外，它适用于任意宽度或深度的各种神经网络结构。最后，我们通过实验证明了这种偏差与泛化之间的关系。

    We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank weight matrices when training deep ReLU neural networks. Our results show that training neural networks with mini-batch SGD and weight decay causes a bias towards rank minimization over the weight matrices. Specifically, we show, both theoretically and empirically, that this bias is more pronounced when using smaller batch sizes, higher learning rates, or increased weight decay. Additionally, we predict and observe empirically that weight decay is necessary to achieve this bias. In addition, we show that in the presence of intermediate neural collapse, the learned weights are particularly low-rank. Unlike previous literature, our analysis does not rely on assumptions about the data, convergence, or optimality of the weight matrices. Furthermore, it applies to a wide range of neural network architectures of any width or depth. Finally, we empirically investigate the connection between this bias and generalization, 
    
[^62]: 信息导向选择的前两个算法

    Information-Directed Selection for Top-Two Algorithms. (arXiv:2205.12086v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.12086](http://arxiv.org/abs/2205.12086)

    本文研究了多臂赌博机中最佳k臂识别问题，提出了一种信息导向选择的算法（IDS），并证明了与IDS集成的顶部两个汤姆逊采样在高斯最佳臂识别中达到了最优。

    

    我们考虑多臂赌博机的最佳k臂识别问题，其目标是通过顺序分配测量努力来选择具有最高平均奖励的k臂准确集合。我们使用对偶变量来表征最优分配的必要和充分条件。值得注意的是，这些最优性条件导致了顶部两个算法设计原则（Russo, 2020）的扩展，这最初是为了最佳臂识别而提出的。此外，我们的最优性条件引出了一种简单而有效的选择规则，称为信息导向选择（IDS），它根据信息增益的度量选择前两个候选中的一个。作为理论保证，我们证明了与IDS集成的顶部两个汤姆逊采样在高斯最佳臂识别中（渐近地）达到了最优，从而解决了纯探索文献中突出的一个未解决问题（Russo, 2020）。作为副产品，我们还表明，对于k > 1，顶部两个算法无法实现最优化。

    We consider the best-k-arm identification problem for multi-armed bandits, where the objective is to select the exact set of k arms with the highest mean rewards by sequentially allocating measurement effort. We characterize the necessary and sufficient conditions for the optimal allocation using dual variables. Remarkably these optimality conditions lead to the extension of top-two algorithm design principle (Russo, 2020), initially proposed for best-arm identification. Furthermore, our optimality conditions induce a simple and effective selection rule dubbed information-directed selection (IDS) that selects one of the top-two candidates based on a measure of information gain. As a theoretical guarantee, we prove that integrated with IDS, top-two Thompson sampling is (asymptotically) optimal for Gaussian best-arm identification, solving a glaring open problem in the pure exploration literature (Russo, 2020). As a by-product, we show that for k > 1, top-two algorithms cannot achieve op
    
[^63]: 连续时间平均奖励马尔可夫决策过程的对数遗憾界限

    Logarithmic regret bounds for continuous-time average-reward Markov decision processes. (arXiv:2205.11168v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11168](http://arxiv.org/abs/2205.11168)

    这项研究考虑了连续时间马尔可夫决策过程（MDPs）的平均奖励设置下的强化学习问题，并找到了实例相关的对数遗憾下界，并设计出了一个能够实现对数增长速率的学习算法。

    

    我们考虑了在无限时间跨度、平均奖励设定下的连续时间马尔可夫决策过程（MDPs）的强化学习。与离散时间MDPs不同，连续时间过程在采取行动后会移动到一个状态并在此停留一个随机持续时间。在未知的转移概率和指数持续时间变化率下，我们得到了一个与时间跨度对数相关的实例相关遗憾下界。此外，我们设计了一个学习算法，并建立了一个有限时间的遗憾界限，能够实现对数增长速率。我们的分析建立在上限置信增强学习、均值持续时间的精细估计以及点过程的随机比较之上。

    We consider reinforcement learning for continuous-time Markov decision processes (MDPs) in the infinite-horizon, average-reward setting. In contrast to discrete-time MDPs, a continuous-time process moves to a state and stays there for a random holding time after an action is taken. With unknown transition probabilities and rates of exponential holding times, we derive instance-dependent regret lower bounds that are logarithmic in the time horizon. Moreover, we design a learning algorithm and establish a finite-time regret bound that achieves the logarithmic growth rate. Our analysis builds upon upper confidence reinforcement learning, a delicate estimation of the mean holding times, and stochastic comparison of point processes.
    
[^64]: 非平稳赌博机学习的预测抽样方法

    Non-Stationary Bandit Learning via Predictive Sampling. (arXiv:2205.01970v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.01970](http://arxiv.org/abs/2205.01970)

    本文提出了一种预测抽样算法，用于解决非平稳赌博机学习问题。该算法通过降低获取信息的优先级，解决了Thompson抽样在非平稳环境下表现不佳的问题，并在所有非平稳环境中优于Thompson抽样。

    This paper proposes a predictive sampling algorithm to solve the non-stationary bandit learning problem. By deprioritizing the acquisition of information that quickly loses usefulness, the algorithm outperforms Thompson sampling in all non-stationary environments examined.

    Thompson抽样已经在广泛的平稳赌博机环境中证明了其有效性。然而，正如我们在本文中所展示的，当应用于非平稳环境时，它的表现可能很差。我们表明，这样的失败是由于在探索时，算法没有根据由于非平稳性导致信息快速失去有用性的速度区分行动。基于这一洞见，我们提出了预测抽样算法，该算法降低了获取信息的优先级，这些信息由于快速失去有用性而不再重要。通过贝叶斯遗憾界，我们建立了预测抽样性能的理论保证。我们提供了预测抽样的版本，其计算可扩展到实际感兴趣的复杂赌博机环境。通过数值模拟，我们证明了预测抽样在所有非平稳环境中都优于Thompson抽样。

    Thompson sampling has proven effective across a wide range of stationary bandit environments. However, as we demonstrate in this paper, it can perform poorly when applied to non-stationary environments. We show that such failures are attributed to the fact that, when exploring, the algorithm does not differentiate actions based on how quickly the information acquired loses its usefulness due to non-stationarity. Building upon this insight, we propose predictive sampling, an algorithm that deprioritizes acquiring information that quickly loses usefulness. Theoretical guarantee on the performance of predictive sampling is established through a Bayesian regret bound. We provide versions of predictive sampling for which computations tractably scale to complex bandit environments of practical interest. Through numerical simulations, we demonstrate that predictive sampling outperforms Thompson sampling in all non-stationary environments examined.
    
[^65]: 基于PDE的对称双臂伯努利赌博机的分析

    A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit. (arXiv:2202.05767v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.05767](http://arxiv.org/abs/2202.05767)

    本研究通过关联线性热方程的解，得到了对称双臂伯努利赌博机问题的minmax最优遗憾和伪遗憾的领先项。新的结果改进了先前的研究，并提供了新的非渐近边界。

    

    本研究探讨了一个版本的双臂伯努利赌博机问题，其中两个臂的平均值之和为1（即对称的双臂伯努利赌博机）。在臂之间的差距趋近于零且预测期数趋近于无穷大的情况下，我们通过将每个解与线性热方程的解关联，得到了该问题的minmax最优遗憾和伪遗憾的领先项。我们的结果改进了先前已知的结果；具体而言，在三种不同的差距缩放模式下，我们明确计算了这些领先项。此外，我们还得到了任何给定时间范围的新的非渐近边界。

    This work addresses a version of the two-armed Bernoulli bandit problem where the sum of the means of the arms is one (the symmetric two-armed Bernoulli bandit). In a regime where the gap between these means goes to zero and the number of prediction periods approaches infinity, we obtain the leading order terms of the minmax optimal regret and pseudoregret for this problem by associating each of them with a solution of a linear heat equation. Our results improve upon the previously known results; specifically, we explicitly compute these leading order terms in three different scaling regimes for the gap. Additionally, we obtain new non-asymptotic bounds for any given time horizon.
    
[^66]: 基于猜想的数据模式发现

    Conjecturing-Based Discovery of Patterns in Data. (arXiv:2011.11576v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2011.11576](http://arxiv.org/abs/2011.11576)

    本研究提出了一种基于猜想的数据模式发现方法，在数值特征和分类特征之间建立了非线性和布尔关系，并应用于COVID-19患者级别数据，揭示了可能的风险因素。

    

    我们提出了一种猜想机器，它以非线性项的边界以及分类特征的布尔表达式的形式建议特征之间的关系。所提出的猜想框架可以从数据中恢复已知的非线性和布尔关系。在两种情况下，真实的基础关系被揭示出来。然后，我们将该方法与先前提出的符号回归框架进行比较，以确定在数据集中满足的方程恢复的能力。然后，该框架应用于COVID-19结果的患者级别数据，以提供可能与医学文献中确认的风险因素。

    We propose the use of a conjecturing machine that suggests feature relationships in the form of bounds involving nonlinear terms for numerical features and boolean expressions for categorical features. The proposed Conjecturing framework recovers known nonlinear and boolean relationships among features from data. In both settings, true underlying relationships are revealed. We then compare the method to a previously-proposed framework for symbolic regression on the ability to recover equations that are satisfied among features in a dataset. The framework is then applied to patient-level data regarding COVID-19 outcomes to suggest possible risk factors that are confirmed in the medical literature.
    
[^67]: 半监督学习：当未标记数据同样有用时的情况

    Semi-Supervised Learning: the Case When Unlabeled Data is Equally Useful. (arXiv:2005.11018v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.11018](http://arxiv.org/abs/2005.11018)

    本文研究了半监督学习中未标记数据与标记数据在学习速度方面的关系，并发现在特定条件下，未标记数据在学习速度上同样有用。

    

    半监督学习算法试图利用较便宜的未标记数据来提高学习性能。本文考虑了数据分布可以由连续参数来描述的统计模型。我们展示了在分布满足一定条件的情况下，未标记数据在学习速度方面与标记数据同样有用。具体而言，设$n，m$分别为标记和未标记数据的数量。研究表明，如果$m\sim n$，半监督学习的学习速度按$O(1/n)$缩放；如果$m\sim n^{1+\gamma}$，半监督学习的学习速度按$O(1/n^{1+\gamma})$缩放，其中$\gamma>0$，而监督学习的学习速度按$O(1/n)$缩放。

    Semi-supervised learning algorithms attempt to take advantage of relatively inexpensive unlabeled data to improve learning performance. In this work, we consider statistical models where the data distributions can be characterized by continuous parameters. We show that under certain conditions on the distribution, unlabeled data is equally useful as labeled date in terms of learning rate. Specifically, let $n, m$ be the number of labeled and unlabeled data, respectively. It is shown that the learning rate of semi-supervised learning scales as $O(1/n)$ if $m\sim n$, and scales as $O(1/n^{1+\gamma})$ if $m\sim n^{1+\gamma}$ for some $\gamma>0$, whereas the learning rate of supervised learning scales as $O(1/n)$.
    
[^68]: MDP Playground: 一种用于强化学习的分析和调试测试平台

    MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning. (arXiv:1909.07750v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1909.07750](http://arxiv.org/abs/1909.07750)

    MDP Playground是一个用于强化学习的测试平台，可以根据不同维度的难度控制方式，挑战代理在各种环境中的表现。它提供了参数化的玩具环境集合，并通过实验揭示了这些环境对代理的影响。

    

    我们提出了MDP Playground，一个用于强化学习代理的测试平台，可以根据难度的不同维度进行控制，以挑战代理并在玩具和复杂的强化学习环境中获得不同程度的难度。我们考虑并允许对各种维度进行控制，包括延迟奖励、序列长度、奖励密度、随机性、图像表示、无关特征、时间单位、动作范围等。我们通过在OpenAI Gym中变化这些维度来定义一个参数化的快速运行的玩具环境集合，并建议使用这些环境来更好地了解代理。然后，我们展示了如何使用MDP Playground设计实验，以深入了解玩具环境。我们还提供了可以将许多这些维度注入到任何Gym环境中的包装器。我们在Atari和Mujoco上使用这些包装器进行实验，以了解这些维度对比玩具环境更复杂的环境的影响。

    We present MDP Playground, a testbed for Reinforcement Learning (RL) agents with dimensions of hardness that can be controlled independently to challenge agents in different ways and obtain varying degrees of hardness in toy and complex RL environments. We consider and allow control over a wide variety of dimensions, including delayed rewards, sequence lengths, reward density, stochasticity, image representations, irrelevant features, time unit, action range and more. We define a parameterised collection of fast-to-run toy environments in OpenAI Gym by varying these dimensions and propose to use these to understand agents better. We then show how to design experiments using MDP Playground to gain insights on the toy environments. We also provide wrappers that can inject many of these dimensions into any Gym environment. We experiment with these wrappers on Atari and Mujoco to allow for understanding the effects of these dimensions on environments that are more complex than the toy envi
    
[^69]: 非线性状态空间模型的随机梯度MCMC方法

    Stochastic Gradient MCMC for Nonlinear State Space Models. (arXiv:1901.10568v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1901.10568](http://arxiv.org/abs/1901.10568)

    该论文提出了一种针对非线性状态空间模型的随机梯度MCMC方法，通过扩展已有方法，利用粒子缓冲随机梯度估计量解决了长时间序列下计算和粒子退化的问题。

    

    状态空间模型（SSM）通过潜在的随机过程提供了建模复杂时间序列的灵活框架。对于非线性、非高斯的SSM推断通常使用粒子方法，但这些方法在处理长时间序列时不具备良好的可扩展性。挑战有两方面：计算与时间线性扩展，粒子滤波器在长序列中还会出现逐渐退化的问题。已经开发了使用缓冲随机梯度估计量来应对时序依赖性的有限状态隐马尔可夫模型和线性SSM的随机梯度MCMC方法，我们将这些方法扩展到了非线性SSM，并提出了误差界限，考虑了缓冲误差和粒子误差，适用于在潜在过程中具有对数凹性的非线性SSM情况。我们使用随机梯度MCMC方法评估了我们提出的粒子缓冲随机梯度方法。

    State space models (SSMs) provide a flexible framework for modeling complex time series via a latent stochastic process. Inference for nonlinear, non-Gaussian SSMs is often tackled with particle methods that do not scale well to long time series. The challenge is two-fold: not only do computations scale linearly with time, as in the linear case, but particle filters additionally suffer from increasing particle degeneracy with longer series. Stochastic gradient MCMC methods have been developed to scale Bayesian inference for finite-state hidden Markov models and linear SSMs using buffered stochastic gradient estimates to account for temporal dependencies. We extend these stochastic gradient estimators to nonlinear SSMs using particle methods. We present error bounds that account for both buffering error and particle error in the case of nonlinear SSMs that are log-concave in the latent process. We evaluate our proposed particle buffered stochastic gradient using stochastic gradient MCMC
    

