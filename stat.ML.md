# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type](https://rss.arxiv.org/abs/2402.01632) | 这篇论文提出了一种新的贝叶斯优化算法，可以处理具有任意类型未知超参数的情况，并具有无遗憾特性。 |
| [^2] | [Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees](https://rss.arxiv.org/abs/2402.00899) | 这项工作提出了使用具有可证明性能保证的弱监督AI错误修正器来处理AI错误。修正器通过批准或拒绝底层分类器的决策来提升性能，并通过概率界限保证其性能。实验证明该方法在训练数据稀缺的真实世界任务中提升图像分类器的性能。 |
| [^3] | [Target Score Matching](https://arxiv.org/abs/2402.08667) | 本文提出了目标分数匹配方法，通过最小化回归损失来估计目标分布的噪声版本的分数。与传统的噪声分数匹配方法不同，该方法在低噪声水平下能够获得更准确的分数估计。 |
| [^4] | [A Generalized Approach to Online Convex Optimization](https://arxiv.org/abs/2402.08621) | 这是一篇关于在线凸优化的论文，作者分析了不同环境下的问题并提出了一种通用的解决方法，该方法可以转化为相应的线性优化算法，并可以在面对不同类型对手时获得可比较的遗憾界限。 |
| [^5] | [Adjustment Identification Distance: A gadjid for Causal Structure Learning](https://arxiv.org/abs/2402.08616) | gadjid软件包提供了一种用于因果结构学习的调整识别距离，通过引入框架来计算因果距离，这些距离能够高效评估因果发现算法学习的图形，并且在处理大规模图形时具有较高的性能。 |
| [^6] | [Globally-Optimal Greedy Experiment Selection for Active Sequential Estimation](https://arxiv.org/abs/2402.08602) | 这项研究提出一种全局优化的贪婪实验选择方法，以解决主动顺序估计问题中的多维情况。这种方法具有计算方便、适应上下文变化和广泛适用性的特点。 |
| [^7] | [Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings](https://arxiv.org/abs/2402.08543) | 本文在高维环境下，针对非可微惩罚项（如推广的LASSO和核范数），通过研究LOOCV在估计外样本风险时的有限样本上界，解决了这个理论缺失的问题。 |
| [^8] | [A Distributional Analogue to the Successor Representation](https://arxiv.org/abs/2402.08530) | 本文提出了一种新的分布式强化学习方法，它通过分离转换结构和奖励，引入了分布式后继度量来描述行为的分布式后果。在实验中展示了该方法的实用性，特别是在零样本风险敏感策略评估方面。 |
| [^9] | [A PAC-Bayesian Link Between Generalisation and Flat Minima](https://arxiv.org/abs/2402.08508) | 本研究结合了PAC-Bayes工具箱和Poincaré与Log-Sobolev不等式，提供了新的梯度项泛化界限，并突出了平坦最小值对泛化性能的积极影响。 |
| [^10] | [Sparsity via Sparse Group $k$-max Regularization](https://arxiv.org/abs/2402.08493) | 本文提出了一种新颖简洁的稀疏分组k最大规则化方法，可以同时增强分组内和分组间的稀疏性，更接近l0范数。 |
| [^11] | [Transfer Operators from Batches of Unpaired Points via Entropic Transport Kernels](https://arxiv.org/abs/2402.08425) | 本文提出了一种通过熵传输核从批次的未配对点估计随机变量$X$和$Y$的联合概率的方法，并在理论上证明了其收敛性质。 |
| [^12] | [Interacting Particle Systems on Networks: joint inference of the network and the interaction kernel](https://arxiv.org/abs/2402.08412) | 本文研究了在网络上建模多智体系统的方法，提出了联合推断网络的权重矩阵和相互作用核的估计器，通过解决非凸优化问题并使用交替最小二乘（ALS）算法和交替最小二乘算子回归（ORALS）算法进行求解。在保证可识别性和良定义性的条件下，ALS算法表现出统计效率和鲁棒性，而ORALS算法是一致的，并且在渐近情况下具有正态性。 |
| [^13] | [Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training](https://arxiv.org/abs/2402.08344) | 通过使用带有差分隐私训练的Noisy-SGD方法，我们发现随机性而非剪裁梯度是导致训练过程中的隐式偏差的原因，并且这种偏差会被加剧，这对于使用巨大批量数据的强差分隐私保证构成重要挑战。 |
| [^14] | [Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret with Adversarial Robustness in Partial Monitoring](https://arxiv.org/abs/2402.08321) | 这篇论文介绍了一种在部分监测问题中探索优化的方法，通过使用混合正则化器可以提高在随机和对抗环境中的遗憾界限。 |
| [^15] | [Classification Using Global and Local Mahalanobis Distances](https://arxiv.org/abs/2402.08283) | 本论文提出了一种使用全局和局部马氏距离的分类方法，适用于椭圆形分布的竞争类别，该方法相比流行的参数化和非参数化分类器具有更好的灵活性和性能。 |
| [^16] | [Causal Discovery under Off-Target Interventions](https://arxiv.org/abs/2402.08229) | 本文研究了非目标干预下的因果发现问题，提出了一个随机干预模型来尽量减少干预次数。通过验证和搜索两个基本问题，提供了多对数复杂度的近似算法。 |
| [^17] | [Off-Policy Evaluation in Markov Decision Processes under Weak Distributional Overlap](https://arxiv.org/abs/2402.08201) | 本文研究了弱分布重叠下马尔可夫决策过程中的离策略评估问题，并提出了一种截断双重稳健（TDR）估计器，在这种情况下表现良好。 |
| [^18] | [Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional Systems](https://arxiv.org/abs/2402.08193) | 高斯模型集成置信传播算法（GEnBP）是一种用于高维系统中高效推断的方法，通过集成卡尔曼滤波器和高斯置信传播等技术相结合，能有效处理高维状态、参数和复杂的依赖结构。 |
| [^19] | [Variational Continual Test-Time Adaptation](https://arxiv.org/abs/2402.08182) | 本文介绍了VCoTTA，一种变分贝叶斯方法用于测量连续测试时适应性中的不确定性。采用变分预热策略将预训练的模型转为贝叶斯神经网络，在测试时通过均值教师更新策略来更新学生模型，结合源模型和教师模型的先验。实验证明该方法在减轻先验偏移方面有效。 |
| [^20] | [On Limitations of the Transformer Architecture](https://arxiv.org/abs/2402.08164) | 本论文通过通信复杂性证明了Transformer层在处理函数组合任务时的局限性，指出对于大型定义域和某些数学任务，Transformers可能无法解决。 |
| [^21] | [Learning Cartesian Product Graphs with Laplacian Constraints](https://arxiv.org/abs/2402.08105) | 本文研究了在Laplacian约束下学习笛卡尔乘积图的问题，建立了笛卡尔乘积Laplacian的统计一致性，并提出了一种有效的算法。实验证明了方法的有效性。 |
| [^22] | [An Accelerated Gradient Method for Simple Bilevel Optimization with Convex Lower-level Problem](https://arxiv.org/abs/2402.08097) | 本文提出了一种加速梯度方法来解决具有凸下层问题的简单双层优化问题，通过局部逼近下层问题的解集和加速梯度更新方法，在有限次迭代内找到一个具有一定精度的最优解。 |
| [^23] | [Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization](https://arxiv.org/abs/2402.08095) | 本文通过均匀化的方式确切实现了离散扩散模型，研究了其理论性质，并提供了关于采样的总变差距离和KL散度保证。这一方法在建模离散数据方面具有重要的应用价值。 |
| [^24] | [Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions](https://arxiv.org/abs/2402.08082) | 基于分数的生成模型在学习一个子高斯概率分布族中突破了维数灾难，通过分数匹配生成的分布以维度无关的速率逼近目标分布的总变差。 |
| [^25] | [Diffeomorphic Measure Matching with Kernels for Generative Modeling](https://arxiv.org/abs/2402.08077) | 该研究提出了使用核函数进行同胚度量匹配的方法，在生成建模中实现了概率测度的传输。通过理论分析和数值实验，本文展示了该方法的性能和适用性。 |
| [^26] | [Nearest Neighbour Score Estimators for Diffusion Generative Models](https://arxiv.org/abs/2402.08018) | 本论文提出了一种新颖的最近邻评分函数估计器，通过利用训练集中的多个样本大大降低了估计器的方差，可用于训练一致性模型和扩散模型，提高收敛速度、样本质量，并为进一步的研究提供了新的可能性。 |
| [^27] | [Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning](https://arxiv.org/abs/2402.08010) | 本文描述了CNN中卷积瓶颈（CBN）结构的出现，网络在前几层将输入表示转换为在少数频率和通道上受支持的表示，然后通过最后几层映射回输出。CBN秩定义了保留在瓶颈中的频率的数量和类型，并部分证明了参数范数与深度和CBN秩的比例成正比。此外，我们还展示了网络的参数范数依赖于函数的规则性。我们发现任何具有接近最优参数范数的网络都会展示出CBN结构，这解释了下采样的常见实践；我们还验证了CBN结构在下采样下仍然成立。最后，我们使用CBN结构来解释...（摘要完整内容请见正文） |
| [^28] | [Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism](https://arxiv.org/abs/2402.07735) | 本论文提出了一种利用BAM进行图结构推断的方法。通过神经网络模型，通过变形的耦合模拟输入数据进行训练，仅需通过一次前向传递即可进行推断。通过利用结构方程模型和随机生成的多变量切比雪夫多项式来模拟训练数据，方法能够泛化到线性和各种非线性依赖关系。引入了双线性注意机制（BAM）来处理依赖关系，该机制在转换数据的协方差矩阵水平上运行，并尊重对称正定矩阵流形的几何特性。实证评估证明了方法的有效性和性能。 |
| [^29] | [Regression Trees for Fast and Adaptive Prediction Intervals](https://arxiv.org/abs/2402.07357) | 该论文提出了一种新的、与模型无关的方法族，用于校准具有局部覆盖保证的回归问题的预测区间。这种方法利用回归树和随机森林训练来创建最粗糙的特征空间划分，以近似条件覆盖，提供了准确、快速和自适应的预测区间。 |
| [^30] | [Sampling from the Mean-Field Stationary Distribution](https://arxiv.org/abs/2402.07355) | 本文研究了从均场随机微分方程 (SDE) 的稳态分布中采样的复杂性，并提出了一种解耦的方法。该方法能够在多种情况下提供改进的保证，包括在均场区域优化某些双层神经网络的更好保证。 |
| [^31] | [HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs](https://arxiv.org/abs/2402.07309) | 本文提出了HyperBERT模型，通过在预训练的BERT模型中引入超图感知层，克服了现有方法在节点分类任务上难以捕捉超图结构信息和文本属性的局限性，提高了模型的效果和泛化能力。 |
| [^32] | [Towards Fast Stochastic Sampling in Diffusion Generative Models](https://arxiv.org/abs/2402.07211) | 本文提出了一种在扩散生成模型中进行快速随机采样的方法，通过对分裂积分器进行原则性修改，实现了更高的采样效率。在CIFAR-10数据集上进行实验，100次网络函数评估下的FID分数为2.36。 |
| [^33] | [On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling](https://arxiv.org/abs/2402.05098) | 本研究探讨了训练扩散模型以从给定分布中采样的问题，并针对随机控制和采样提出了一种新的探索策略，通过基准测试比较了不同推断方法的相对优劣，并对过去的工作提出了质疑。 |
| [^34] | [Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces](https://arxiv.org/abs/2402.04691) | 本研究在一般希尔伯特空间中使用随机梯度下降（SGD）学习算子，提出了适用于目标算子的规则条件，并建立了SGD算法的收敛速度上界，同时展示了对于非线性算子学习的有效性及线性近似收敛特性。 |
| [^35] | [Stochastic Gradient Descent for Additive Nonparametric Regression](https://arxiv.org/abs/2401.00691) | 本文介绍了一种用于训练加性模型的随机梯度下降算法，具有良好的内存存储和计算要求。在规范很好的情况下，通过仔细选择学习率，可以实现最小和最优的风险。 |
| [^36] | [Non-Vacuous Generalization Bounds for Large Language Models](https://arxiv.org/abs/2312.17173) | 这项研究提供了首个针对预训练大语言模型的非平凡泛化界限，表明语言模型能够发现适用于未见数据的规律性。建立了有效的压缩界限，证明较大的模型具有更好的泛化界限并更易压缩。 |
| [^37] | [Bagged Regularized $k$-Distances for Anomaly Detection](https://arxiv.org/abs/2312.01046) | 本文提出了一种称为Bagged Regularized $k$-Distances for Anomaly Detection (BRDAD)的基于距离的算法，通过将非监督异常检测问题转化为凸优化问题，成功解决了基于距离算法中超参数选择的敏感性挑战，并通过包集成方法解决了处理大规模数据集时的效率问题。 |
| [^38] | [MFAI: A Scalable Bayesian Matrix Factorization Approach to Leveraging Auxiliary Information](https://arxiv.org/abs/2303.02566) | MFAI是一种可扩展的贝叶斯矩阵分解方法，通过利用辅助信息来克服由于数据质量差导致的挑战，具有灵活建模非线性关系和对辅助信息的鲁棒性。 |
| [^39] | [A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence](https://arxiv.org/abs/2301.13139) | 我们提出了一种新的政策优化框架，通过镜面下降自然地适应通用参数化，并获得了应用于通用参数化的基于政策梯度的方法的线性收敛保证。 |
| [^40] | [Subset verification and search algorithms for causal DAGs](https://arxiv.org/abs/2301.03180) | 本文研究了在学习因果DAG的子集关系时，识别所需最小干预集的问题，提出了两种有效算法进行解决。在子集验证问题上，我们提供了一种计算最小干预集的高效算法。在子集搜索问题上，我们提出了两种解决方法。 |
| [^41] | [Probabilistic Forecasting with Generative Networks via Scoring Rule Minimization](https://arxiv.org/abs/2112.08217) | 本论文提出了一种使用生成神经网络进行概率预测的方法，通过预测序列打分规则进行训练，避免了繁琐的超参数调整和不稳定的对抗训练，从而在概率预测中可靠地使用生成网络。 |
| [^42] | [Stochastic Low-rank Tensor Bandits for Multi-dimensional Online Decision Making](https://arxiv.org/abs/2007.15788) | 这项研究提出了一种针对多维度在线决策的随机低秩张量赌博算法。通过考虑有上下文和没有上下文的情况，提出了两种学习算法，并推导了有限时间的遗憾界限。 |
| [^43] | [Age-structured estimation of COVID-19 ICU demand from low quality data](https://arxiv.org/abs/2006.06530) | 本研究提出了一种基于低质量数据的方法，通过年龄结构估计 COVID-19 ICU 的需求量，并使用重症监护病房占用数据和通报因子进行校正，预测未来 ICU 床位的需求情况。 |
| [^44] | [Input Validation for Neural Networks via Runtime Local Robustness Verification](https://arxiv.org/abs/2002.03339) | 本文提出了通过运行时本地鲁棒性验证来验证神经网络输入的方法。实验证明，这种方法可以保护神经网络免受对抗性样本的影响，并提高准确性。 |
| [^45] | [Leveraging tensor kernels to reduce objective function mismatch in deep clustering](https://arxiv.org/abs/2001.07026) | 本文研究了深度聚类中的目标函数不匹配（OFM）问题，并发现基于自编码器的方法容易导致降低聚类性能和重构与聚类目标之间的不匹配。为了解决这个问题，我们提出了一种新的辅助目标方法，称为无监督伴随对象（UCO），通过核函数在网络的中间表示上制定聚类目标。 |
| [^46] | [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.](http://arxiv.org/abs/2401.01335) | 本文提出了一种名为自我对弱语言模型进行细调（SPIN）的方法，通过模型自我对弈生成训练数据，并从中优化模型策略，从而将弱语言模型转化为强语言模型，无需额外的人类标注数据。 |
| [^47] | [Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around Exposure-Outcome Pairs.](http://arxiv.org/abs/2310.17816) | 在有限先验知识下，通过局部分区发现算法（LDP），该研究解决了自动变量选择的问题。LDP根据与曝光-结果对{X,Y}相关的子集将变量集合Z进行分区，并区分混淆因素和其他变量类型。该算法具有理论保证，并在实践中观察到次二次的运行时间。 |
| [^48] | [Compositional Deep Probabilistic Models of DNA Encoded Libraries.](http://arxiv.org/abs/2310.13769) | 本研究提出了一种组合深度概率模型DEL-Compose，用于对DNA编码库的数据进行建模和分析，以发现潜在的结构和信息，并通过改进观察模型来更好地处理数据噪声。 |
| [^49] | [Optimal Sample Complexity for Average Reward Markov Decision Processes.](http://arxiv.org/abs/2310.08833) | 本论文解决了对于均匀收敛的马尔可夫决策过程的长期平均奖励最大化策略学习的样本复杂度问题，并建立了一个样本复杂度为$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$的优化策略估计器。 |
| [^50] | [Efficient Agnostic Learning with Average Smoothness.](http://arxiv.org/abs/2309.17016) | 该论文研究了基于平均光滑度的无参回归问题，提出了无分布限制下的统一收敛界限和高效无偏学习算法。 |
| [^51] | [Les Houches Lectures on Deep Learning at Large & Infinite Width.](http://arxiv.org/abs/2309.01592) | 本论文主要以无穷宽度和大宽度范围内的深度神经网络为研究对象，讨论了这些网络的各种统计和动力学特性，包括随机网络的性质、训练后的网络与线性模型、核函数和高斯过程之间的关系，以及对大但有限宽度网络在初始化和训练后的摄动和非摄动处理。 |
| [^52] | [Amortized Variational Inference: When and Why?.](http://arxiv.org/abs/2307.11018) | 本文研究了分期变分推断作为近似后验推断的一种通用替代方法，探讨了何时能够达到与传统的因子化变分推断相同的最优解。 |
| [^53] | [Interpreting and Improving Diffusion Models Using the Euclidean Distance Function.](http://arxiv.org/abs/2306.04848) | 本文利用欧几里得距离函数解释去噪扩散模型，并提出了一种新的采样器。采样器表现出了最先进的FID得分，并能够生成高质量的样本。 |
| [^54] | [How does over-squashing affect the power of GNNs?.](http://arxiv.org/abs/2306.03589) | 本文通过测量节点之间成对交互的水平，提供了严格的分析，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。结果表明，为了保证节点对之间的充分通信，MPNN的容量必须是... |
| [^55] | [Stability-penalty-adaptive Follow-the-regularized-leader: Sparsity, Game-dependency, and Best-of-both-worlds.](http://arxiv.org/abs/2305.17301) | 本文开发了一种稳定性惩罚自适应（SPA）学习率，该学习率使FTRL具有稀疏性、游戏依赖性和最佳世界（BOBW）三种适应性类型，其中SPA-sparse算法可适应于未知的稀疏级别，SPA-game-dependency算法可根据所玩的游戏自适应地改变其行为，BOBW算法则是既具有稀疏性又具有游戏依赖性的适应性算法。 |
| [^56] | [Cost-aware learning of relevant contextual variables within Bayesian optimization.](http://arxiv.org/abs/2305.14120) | 本文提出一种基于代价感知的模型选择BO方法SADCBO，通过对后验代理模型的敏感性分析来学习关于环境的相关情境信息，并通过平均模型预测来最小化优化代价，在实验中表现出卓越的性能。 |
| [^57] | [Correlation Clustering with Active Learning of Pairwise Similarities.](http://arxiv.org/abs/2302.10295) | 本文研究了相关聚类中成对相似性不事先给出的情况，并开发了一个通用的主动学习框架，适应各种相关聚类算法和查询策略，同时具有适应性灵活、噪声鲁棒性等优势。 |

# 详细

[^1]: 超越尺度：具有任意类型未知超参数的无遗憾贝叶斯优化

    Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type

    [https://rss.arxiv.org/abs/2402.01632](https://rss.arxiv.org/abs/2402.01632)

    这篇论文提出了一种新的贝叶斯优化算法，可以处理具有任意类型未知超参数的情况，并具有无遗憾特性。

    

    贝叶斯优化需要拟合高斯过程模型，而拟合高斯过程模型需要指定超参数 - 大部分理论文献假设这些超参数是已知的。之前的理论研究通常假设数据在空间中均匀填充，而常用的高斯过程超参数的最大似然估计器只有在这种情况下才是一致的。然而，在贝叶斯优化中，数据不一定满足这种均匀填充的条件。由于无法保证超参数估计的正确性，并且这些超参数可以显著影响高斯过程拟合，因此对具有未知超参数的贝叶斯优化进行理论分析非常具有挑战性。之前提出的具有无遗憾特性的算法仅能处理特殊情况下的未知长度尺度、再生核希尔伯特空间范数，并且仅适用于频率派的情况。我们提出了一种新的算法，命名为HE-GP-UCB，它是第一个具有无遗憾特性的算法，在具有未知超参数的情况下实现了贝叶斯优化。

    Bayesian optimisation requires fitting a Gaussian process model, which in turn requires specifying hyperparameters - most of the theoretical literature assumes those hyperparameters are known. The commonly used maximum likelihood estimator for hyperparameters of the Gaussian process is consistent only if the data fills the space uniformly, which does not have to be the case in Bayesian optimisation. Since no guarantees exist regarding the correctness of hyperparameter estimation, and those hyperparameters can significantly affect the Gaussian process fit, theoretical analysis of Bayesian optimisation with unknown hyperparameters is very challenging. Previously proposed algorithms with the no-regret property were only able to handle the special case of unknown lengthscales, reproducing kernel Hilbert space norm and applied only to the frequentist case. We propose a novel algorithm, HE-GP-UCB, which is the first algorithm enjoying the no-regret property in the case of unknown hyperparame
    
[^2]: 弱监督学习器实现具有可证明性能保证的AI错误修正

    Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees

    [https://rss.arxiv.org/abs/2402.00899](https://rss.arxiv.org/abs/2402.00899)

    这项工作提出了使用具有可证明性能保证的弱监督AI错误修正器来处理AI错误。修正器通过批准或拒绝底层分类器的决策来提升性能，并通过概率界限保证其性能。实验证明该方法在训练数据稀缺的真实世界任务中提升图像分类器的性能。

    

    我们提出了一种新的方法来处理AI错误，通过引入具有先验性能保证的弱监督AI错误修正器。这些AI修正器是辅助映射，其作用是通过批准或拒绝以调节之前构建的底层分类器的决策。拒绝一个决策可以用作建议放弃做出决策的信号。该工作的一个关键技术重点是通过对错误决策的概率界限提供这些新的AI修正器的性能保证。这些界限是分布不可知的，并且不依赖于对数据维度的假设。我们的实证示例说明了该框架如何应用于改善在训练数据稀缺的具有挑战性的真实世界任务中图像分类器的性能。

    We present a new methodology for handling AI errors by introducing weakly supervised AI error correctors with a priori performance guarantees. These AI correctors are auxiliary maps whose role is to moderate the decisions of some previously constructed underlying classifier by either approving or rejecting its decisions. The rejection of a decision can be used as a signal to suggest abstaining from making a decision. A key technical focus of the work is in providing performance guarantees for these new AI correctors through bounds on the probabilities of incorrect decisions. These bounds are distribution agnostic and do not rely on assumptions on the data dimension. Our empirical example illustrates how the framework can be applied to improve the performance of an image classifier in a challenging real-world task where training data are scarce.
    
[^3]: 目标分数匹配

    Target Score Matching

    [https://arxiv.org/abs/2402.08667](https://arxiv.org/abs/2402.08667)

    本文提出了目标分数匹配方法，通过最小化回归损失来估计目标分布的噪声版本的分数。与传统的噪声分数匹配方法不同，该方法在低噪声水平下能够获得更准确的分数估计。

    

    噪声分数匹配通过最小化回归损失来估计目标分布的噪声版本的分数，并广泛用于训练流行的去噪扩散模型。然而，众所周知，噪声分数匹配的一个局限性是在低噪声水平下会产生较差的分数估计。这个问题在物理科学和对于已知干净的原始目标分数的蒙特卡洛抽样任务中特别不利。直观地说，在这些情况下，估计目标稍有噪声版本的分数应该是一个简单的任务。在本文中，我们解决了这个缺点，并展示了利用目标分数的知识确实可以实现。我们提出了目标分数身份和相应的目标分数匹配回归损失，这使我们能够在低噪声水平下获得具有有利属性的分数估计。

    Denoising Score Matching estimates the score of a noised version of a target distribution by minimizing a regression loss and is widely used to train the popular class of Denoising Diffusion Models. A well known limitation of Denoising Score Matching, however, is that it yields poor estimates of the score at low noise levels. This issue is particularly unfavourable for problems in the physical sciences and for Monte Carlo sampling tasks for which the score of the clean original target is known. Intuitively, estimating the score of a slightly noised version of the target should be a simple task in such cases. In this paper, we address this shortcoming and show that it is indeed possible to leverage knowledge of the target score. We present a Target Score Identity and corresponding Target Score Matching regression loss which allows us to obtain score estimates admitting favourable properties at low noise levels.
    
[^4]: 一种广义的在线凸优化方法

    A Generalized Approach to Online Convex Optimization

    [https://arxiv.org/abs/2402.08621](https://arxiv.org/abs/2402.08621)

    这是一篇关于在线凸优化的论文，作者分析了不同环境下的问题并提出了一种通用的解决方法，该方法可以转化为相应的线性优化算法，并可以在面对不同类型对手时获得可比较的遗憾界限。

    

    在本文中，我们分析了不同环境下的在线凸优化问题。我们证明了任何用于具有完全自适应对手的在线线性优化的算法都是用于在线凸优化的算法。我们还证明了任何需要全信息反馈的算法都可以转化为具有可比较的遗憾界限的半匹配反馈算法。此外，我们还证明了使用确定性半匹配反馈的全自适应对手设计的算法在面对无知对手时可以使用只有随机半匹配反馈的算法获得相似的界限。我们利用这一结果描述了将一阶算法转化为零阶算法的通用元算法，这些算法具有可比较的遗憾界限。我们的框架使我们能够分析各种设置中的在线优化问题，包括全信息反馈、半匹配反馈、随机遗憾、对抗遗憾和各种形式的非平稳遗憾。利用我们的分析结果，

    In this paper, we analyze the problem of online convex optimization in different settings. We show that any algorithm for online linear optimization with fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, such full-information feedback, bandit feedback, stochastic regret, adversarial regret and various forms of non-stationary regret. Using our analysis, we provide
    
[^5]: Adjustment Identification Distance: 一种用于因果结构学习的调整识别距离

    Adjustment Identification Distance: A gadjid for Causal Structure Learning

    [https://arxiv.org/abs/2402.08616](https://arxiv.org/abs/2402.08616)

    gadjid软件包提供了一种用于因果结构学习的调整识别距离，通过引入框架来计算因果距离，这些距离能够高效评估因果发现算法学习的图形，并且在处理大规模图形时具有较高的性能。

    

    通过因果发现算法学习的图形的评估是困难的：两个图形之间不同的边的数量不能反映出它们在建议因果效应的识别公式方面有何不同。我们引入了一个框架，用于开发图形之间的因果距离，其中包括有向无环图的结构干预距离作为一种特殊情况。我们利用这个框架开发了改进的基于调整的距离，以及对完成的部分有向无环图和因果序列的扩展。我们开发了多项式时间可达性算法来高效计算距离。在我们的gadjid软件包中（在https://github.com/CausalDisco/gadjid上开源），我们提供了我们的距离实现；它们的运行速度比结构干预距离快几个数量级，从而为以前无法扩展的图形尺寸提供了一个因果发现的成功指标。

    Evaluating graphs learned by causal discovery algorithms is difficult: The number of edges that differ between two graphs does not reflect how the graphs differ with respect to the identifying formulas they suggest for causal effects. We introduce a framework for developing causal distances between graphs which includes the structural intervention distance for directed acyclic graphs as a special case. We use this framework to develop improved adjustment-based distances as well as extensions to completed partially directed acyclic graphs and causal orders. We develop polynomial-time reachability algorithms to compute the distances efficiently. In our package gadjid (open source at https://github.com/CausalDisco/gadjid), we provide implementations of our distances; they are orders of magnitude faster than the structural intervention distance and thereby provide a success metric for causal discovery that scales to graph sizes that were previously prohibitive.
    
[^6]: 全局优化的贪婪实验选择方法用于主动顺序估计

    Globally-Optimal Greedy Experiment Selection for Active Sequential Estimation

    [https://arxiv.org/abs/2402.08602](https://arxiv.org/abs/2402.08602)

    这项研究提出一种全局优化的贪婪实验选择方法，以解决主动顺序估计问题中的多维情况。这种方法具有计算方便、适应上下文变化和广泛适用性的特点。

    

    在计算机自适应测试、顺序排名聚合和异构数据源选择等现代应用的推动下，我们研究了主动顺序估计问题，该问题涉及逐步选择实验来采集数据。目标是设计实验选择规则以获得更准确的模型估计。由于计算方便、能够适应上下文或任务变化并具有广泛适用性，基于信息增益的贪婪实验选择方法已在实践中被采用。然而，由于问题的组合性质和贪婪算法的表面上有限的能力，统计分析仅限于一维情况，使得多维问题仍然未解决。在本研究中，我们解决了多维问题的差距。具体而言，我们提出采用一类贪婪实验选择方法，并提供了统计分析。

    Motivated by modern applications such as computerized adaptive testing, sequential rank aggregation, and heterogeneous data source selection, we study the problem of active sequential estimation, which involves adaptively selecting experiments for sequentially collected data. The goal is to design experiment selection rules for more accurate model estimation. Greedy information-based experiment selection methods, optimizing the information gain for one-step ahead, have been employed in practice thanks to their computational convenience, flexibility to context or task changes, and broad applicability. However, statistical analysis is restricted to one-dimensional cases due to the problem's combinatorial nature and the seemingly limited capacity of greedy algorithms, leaving the multidimensional problem open.   In this study, we close the gap for multidimensional problems. In particular, we propose adopting a class of greedy experiment selection methods and provide statistical analysis f
    
[^7]: 在高维环境下，关于非可微惩罚项的LOOCV的理论分析

    Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings

    [https://arxiv.org/abs/2402.08543](https://arxiv.org/abs/2402.08543)

    本文在高维环境下，针对非可微惩罚项（如推广的LASSO和核范数），通过研究LOOCV在估计外样本风险时的有限样本上界，解决了这个理论缺失的问题。

    

    尽管在高维情况下，关于正则化模型的非样条惩罚项（如推广的LASSO和核范数）的外样本风险估计有大量的重要工作，但对于这个问题的理论理解仍然缺失。在本文中，我们解决了这个挑战。我们在比例高维情况下研究了这个问题，其中样本量n和特征数p都很大，且n/p和信噪比（每个观测）保持有限。我们给出了LOOCV在估计外样本风险时的有限样本上界。本文提出的理论框架为阐明LOOCV的准确性提供了坚实的基础。

    Despite a large and significant body of recent work focused on estimating the out-of-sample risk of regularized models in the high dimensional regime, a theoretical understanding of this problem for non-differentiable penalties such as generalized LASSO and nuclear norm is missing. In this paper we resolve this challenge. We study this problem in the proportional high dimensional regime where both the sample size n and number of features p are large, and n/p and the signal-to-noise ratio (per observation) remain finite. We provide finite sample upper bounds on the expected squared error of leave-one-out cross-validation (LO) in estimating the out-of-sample risk. The theoretical framework presented here provides a solid foundation for elucidating empirical findings that show the accuracy of LO.
    
[^8]: 分布式后续表示的分布式类比

    A Distributional Analogue to the Successor Representation

    [https://arxiv.org/abs/2402.08530](https://arxiv.org/abs/2402.08530)

    本文提出了一种新的分布式强化学习方法，它通过分离转换结构和奖励，引入了分布式后继度量来描述行为的分布式后果。在实验中展示了该方法的实用性，特别是在零样本风险敏感策略评估方面。

    

    本文提出了一种新的分布式强化学习方法，它将转换结构和奖励在学习过程中进行了明确的分离。与后续表示（SR）描述按照给定策略行为的期望后果类似，我们的分布式后继度量（SM）描述了这种行为的分布式结果。我们将分布式SM构建为一个分布的分布，并提供了与分布式和基于模型的强化学习相关的理论。此外，我们提出了一种从数据中学习分布式SM的算法，通过最小化两个层次的最大均值差异来实现。我们方法的关键是一些独立有价值的学习状态生成模型的算法技术。作为分布式SM有用性的例证，我们展示了它使得零样本风险敏感策略评估成为可能，这在以前是不可能的。

    This paper contributes a new approach for distributional reinforcement learning which elucidates a clean separation of transition structure and reward in the learning process. Analogous to how the successor representation (SR) describes the expected consequences of behaving according to a given policy, our distributional successor measure (SM) describes the distributional consequences of this behaviour. We formulate the distributional SM as a distribution over distributions and provide theory connecting it with distributional and model-based reinforcement learning. Moreover, we propose an algorithm that learns the distributional SM from data by minimizing a two-level maximum mean discrepancy. Key to our method are a number of algorithmic techniques that are independently valuable for learning generative models of state. As an illustration of the usefulness of the distributional SM, we show that it enables zero-shot risk-sensitive policy evaluation in a way that was not previously possi
    
[^9]: 广义和平均容量之间的PAC-Bayes联结

    A PAC-Bayesian Link Between Generalisation and Flat Minima

    [https://arxiv.org/abs/2402.08508](https://arxiv.org/abs/2402.08508)

    本研究结合了PAC-Bayes工具箱和Poincaré与Log-Sobolev不等式，提供了新的梯度项泛化界限，并突出了平坦最小值对泛化性能的积极影响。

    

    现代机器学习通常使用超参数设置（训练参数数量大于数据集大小）中的预测器，它们的训练不仅产生良好的训练数据性能，而且具有良好的泛化能力。这一现象挑战了许多理论结果，并且仍然是一个未解决的问题。为了更好地理解这一现象，我们提供了涉及梯度项的新型泛化界限。为此，我们将PAC-Bayes工具箱与Poincaré和Log-Sobolev不等式相结合，避免了对预测器空间维数的显式依赖。我们的结果突出了“平坦最小值”（几乎能够最小化学习问题的邻近最小值）对泛化性能的积极影响，直接涉及到优化阶段的好处。

    Modern machine learning usually involves predictors in the overparametrised setting (number of trained parameters greater than dataset size), and their training yield not only good performances on training data, but also good generalisation capacity. This phenomenon challenges many theoretical results, and remains an open problem. To reach a better understanding, we provide novel generalisation bounds involving gradient terms. To do so, we combine the PAC-Bayes toolbox with Poincar\'e and Log-Sobolev inequalities, avoiding an explicit dependency on dimension of the predictor space. Our results highlight the positive influence of \emph{flat minima} (being minima with a neighbourhood nearly minimising the learning problem as well) on generalisation performances, involving directly the benefits of the optimisation phase.
    
[^10]: 通过稀疏分组k最大规则化实现稀疏性

    Sparsity via Sparse Group $k$-max Regularization

    [https://arxiv.org/abs/2402.08493](https://arxiv.org/abs/2402.08493)

    本文提出了一种新颖简洁的稀疏分组k最大规则化方法，可以同时增强分组内和分组间的稀疏性，更接近l0范数。

    

    对于具有稀疏约束的线性逆问题，l0正则化问题是NP困难的，现有方法要么利用贪婪算法找到近似最优解，要么用凸映射来逼近l0正则化。本文提出了一种新颖简洁的正则化方法，即稀疏分组k最大规则化，其不仅可以同时增强分组内和分组间的稀疏性，而且对每个分组中的变量的大小没有额外的限制，这对于不同尺度的变量尤为重要，以更接近l0范数。我们还提出了一种带有局部最优性条件和复杂性分析的迭代软阈值算法。通过在合成和真实数据集上的数值实验证明了所提方法的有效性和灵活性。

    For the linear inverse problem with sparsity constraints, the $l_0$ regularized problem is NP-hard, and existing approaches either utilize greedy algorithms to find almost-optimal solutions or to approximate the $l_0$ regularization with its convex counterparts. In this paper, we propose a novel and concise regularization, namely the sparse group $k$-max regularization, which can not only simultaneously enhance the group-wise and in-group sparsity, but also casts no additional restraints on the magnitude of variables in each group, which is especially important for variables at different scales, so that it approximate the $l_0$ norm more closely. We also establish an iterative soft thresholding algorithm with local optimality conditions and complexity analysis provided. Through numerical experiments on both synthetic and real-world datasets, we verify the effectiveness and flexibility of the proposed method.
    
[^11]: 通过熵传输核将未配对点的批次转移算子进行估计

    Transfer Operators from Batches of Unpaired Points via Entropic Transport Kernels

    [https://arxiv.org/abs/2402.08425](https://arxiv.org/abs/2402.08425)

    本文提出了一种通过熵传输核从批次的未配对点估计随机变量$X$和$Y$的联合概率的方法，并在理论上证明了其收敛性质。

    

    本文关注于通过$N$个独立观测块$(\boldsymbol{x}^i,\boldsymbol{y}^i)$（$i=1,\ldots,N$）来估计随机变量$X$和$Y$的联合概率，每个观测块包含$M$个样本$(\boldsymbol{x}^i,\boldsymbol{y}^i) = \bigl((x^i_j, y^i_{\sigma^i(j)}) \bigr)_{j=1}^M$，其中$\sigma^i$表示一个未知的排列，用于对$i.i.d.$采样的对$(x^i_j,y_j^i)$进行重新排序，$j=1,\ldots,M$。这意味着观测块内部样本的顺序是未知的。我们推导了一个最大似然推断函数，并提出了一个可计算的近似方法，并分析了它们的性质。特别是，我们证明了一个$\Gamma$-收敛结果，说明我们可以在块数$N$趋向于无穷大时，从经验近似中恢复出真实的密度。使用熵最优传输核，我们对一类假设空间建模，该空间的密度函数可以最小化推断函数。

    In this paper, we are concerned with estimating the joint probability of random variables $X$ and $Y$, given $N$ independent observation blocks $(\boldsymbol{x}^i,\boldsymbol{y}^i)$, $i=1,\ldots,N$, each of $M$ samples $(\boldsymbol{x}^i,\boldsymbol{y}^i) = \bigl((x^i_j, y^i_{\sigma^i(j)}) \bigr)_{j=1}^M$, where $\sigma^i$ denotes an unknown permutation of i.i.d. sampled pairs $(x^i_j,y_j^i)$, $j=1,\ldots,M$. This means that the internal ordering of the $M$ samples within an observation block is not known. We derive a maximum-likelihood inference functional, propose a computationally tractable approximation and analyze their properties. In particular, we prove a $\Gamma$-convergence result showing that we can recover the true density from empirical approximations as the number $N$ of blocks goes to infinity. Using entropic optimal transport kernels, we model a class of hypothesis spaces of density functions over which the inference functional can be minimized. This hypothesis class is 
    
[^12]: 在网络上相互作用的粒子系统: 网络和相互作用核的联合推断

    Interacting Particle Systems on Networks: joint inference of the network and the interaction kernel

    [https://arxiv.org/abs/2402.08412](https://arxiv.org/abs/2402.08412)

    本文研究了在网络上建模多智体系统的方法，提出了联合推断网络的权重矩阵和相互作用核的估计器，通过解决非凸优化问题并使用交替最小二乘（ALS）算法和交替最小二乘算子回归（ORALS）算法进行求解。在保证可识别性和良定义性的条件下，ALS算法表现出统计效率和鲁棒性，而ORALS算法是一致的，并且在渐近情况下具有正态性。

    

    在各种学科中，对网络上的多智体系统进行建模是一个基本的挑战。我们从由多条轨迹组成的数据中联合推断网络的权重矩阵和相互作用核，分别确定哪些智体与哪些其他智体相互作用以及这种相互作用的规则。我们提出的估计器自然地导致一个非凸优化问题，并研究了两种解决方案：一种基于交替最小二乘（ALS）算法，另一种基于一种名为交替最小二乘的算子回归（ORALS）的新算法。这两种算法都可扩展到大量数据轨迹。我们建立了保证可识别性和良定义性的强制性条件。尽管ALS算法在小数据情况下缺乏性能和收敛性保证，但表现出统计效率和鲁棒性。在强制性条件下，ORALS估计器是一致的，并且在渐近情况下具有正态性。

    Modeling multi-agent systems on networks is a fundamental challenge in a wide variety of disciplines. We jointly infer the weight matrix of the network and the interaction kernel, which determine respectively which agents interact with which others and the rules of such interactions from data consisting of multiple trajectories. The estimator we propose leads naturally to a non-convex optimization problem, and we investigate two approaches for its solution: one is based on the alternating least squares (ALS) algorithm; another is based on a new algorithm named operator regression with alternating least squares (ORALS). Both algorithms are scalable to large ensembles of data trajectories. We establish coercivity conditions guaranteeing identifiability and well-posedness. The ALS algorithm appears statistically efficient and robust even in the small data regime but lacks performance and convergence guarantees. The ORALS estimator is consistent and asymptotically normal under a coercivity
    
[^13]: 在带有差分隐私训练的Noisy-SGD中的隐式偏差：及其在训练中的应用

    Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training

    [https://arxiv.org/abs/2402.08344](https://arxiv.org/abs/2402.08344)

    通过使用带有差分隐私训练的Noisy-SGD方法，我们发现随机性而非剪裁梯度是导致训练过程中的隐式偏差的原因，并且这种偏差会被加剧，这对于使用巨大批量数据的强差分隐私保证构成重要挑战。

    

    使用随机梯度下降(SGD)以小批量训练深度神经网络(DNN)相较于大批量训练能够获得更好的测试性能。SGD特定的噪声结构被认为是导致这种隐式偏差的原因。用于确保DNN训练中的差异隐私(DP)的DP-SGD会给剪裁梯度添加高斯噪声。令人惊讶的是，大批量训练仍然会导致显著的性能下降，这是一个重要的挑战，因为强DP保证需要使用大批量数据。我们首先展示了现象在Noisy-SGD（没有剪裁的DP-SGD）中的存在，这表明随机性（而不是剪裁）是这种隐式偏差的原因，即使加入了额外的各向同性高斯噪声。我们在线性最小二乘和对角线线性网络设置上对使用连续版本的Noisy-SGD获得的解进行了理论分析，并揭示了隐式偏差确实被加剧了。

    Training Deep Neural Networks (DNNs) with small batches using Stochastic Gradient Descent (SGD) yields superior test performance compared to larger batches. The specific noise structure inherent to SGD is known to be responsible for this implicit bias. DP-SGD, used to ensure differential privacy (DP) in DNNs' training, adds Gaussian noise to the clipped gradients. Surprisingly, large-batch training still results in a significant decrease in performance, which poses an important challenge because strong DP guarantees necessitate the use of massive batches. We first show that the phenomenon extends to Noisy-SGD (DP-SGD without clipping), suggesting that the stochasticity (and not the clipping) is the cause of this implicit bias, even with additional isotropic Gaussian noise. We theoretically analyse the solutions obtained with continuous versions of Noisy-SGD for the Linear Least Square and Diagonal Linear Network settings, and reveal that the implicit bias is indeed amplified by the add
    
[^14]: 使用混合正则化器的优化探索：在部分监测中具有对抗鲁棒性的对数遗憾

    Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret with Adversarial Robustness in Partial Monitoring

    [https://arxiv.org/abs/2402.08321](https://arxiv.org/abs/2402.08321)

    这篇论文介绍了一种在部分监测问题中探索优化的方法，通过使用混合正则化器可以提高在随机和对抗环境中的遗憾界限。

    

    部分监测是一种具有有限观测的在线决策问题的通用框架。为了从这种有限观测中做出决策，需要找到一个适当的探索分布。最近，提出了一种用于此目的的强大方法，即通过优化进行探索（ExO），它利用追踪正则化最优方法，在广泛的在线决策问题中实现对抗环境下的最优界限。然而，在随机环境中纯粹应用ExO会显著降低遗憾界限。为了解决这个局部可观测游戏中的问题，我们首先建立了一个新颖的ExO与混合正则化器的框架和分析。这个发展使我们能够显著改进最佳双赢算法（BOBW）的现有遗憾界限，在随机和对抗环境中都实现了几乎最优的界限。特别地，我们得出了一个随机遗憾界限为$O(\sum_{a \neq a^*} k^2 m^2$

    Partial monitoring is a generic framework of online decision-making problems with limited observations. To make decisions from such limited observations, it is necessary to find an appropriate distribution for exploration. Recently, a powerful approach for this purpose, exploration by optimization (ExO), was proposed, which achieves the optimal bounds in adversarial environments with follow-the-regularized-leader for a wide range of online decision-making problems. However, a naive application of ExO in stochastic environments significantly degrades regret bounds. To resolve this problem in locally observable games, we first establish a novel framework and analysis for ExO with a hybrid regularizer. This development allows us to significantly improve the existing regret bounds of best-of-both-worlds (BOBW) algorithms, which achieves nearly optimal bounds both in stochastic and adversarial environments. In particular, we derive a stochastic regret bound of $O(\sum_{a \neq a^*} k^2 m^2 \
    
[^15]: 使用全局和局部马氏距离的分类方法

    Classification Using Global and Local Mahalanobis Distances

    [https://arxiv.org/abs/2402.08283](https://arxiv.org/abs/2402.08283)

    本论文提出了一种使用全局和局部马氏距离的分类方法，适用于椭圆形分布的竞争类别，该方法相比流行的参数化和非参数化分类器具有更好的灵活性和性能。

    

    我们提出了一种基于来自不同类别的观察值的马氏距离的新型半参数分类器。我们的工具是一个具有逻辑链接函数的广义加性模型，它使用这些距离作为特征来估计不同类别的后验概率。尽管流行的参数化分类器如线性和二次判别分析主要基于基础分布的正态性，但所提出的分类器更加灵活，不受此类参数化假设的限制。由于椭圆分布的密度是马氏距离的函数，当竞争类别是（几乎）椭圆形时，该分类器的效果很好。在这种情况下，它经常胜过流行的非参数化分类器，特别是当样本量相对于数据维数较小时。为了应对非椭圆和可能多峰的分布，我们提出了马氏距离的局部版本。随后，我们提出了

    We propose a novel semi-parametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of the different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose 
    
[^16]: 非目标干预下的因果发现

    Causal Discovery under Off-Target Interventions

    [https://arxiv.org/abs/2402.08229](https://arxiv.org/abs/2402.08229)

    本文研究了非目标干预下的因果发现问题，提出了一个随机干预模型来尽量减少干预次数。通过验证和搜索两个基本问题，提供了多对数复杂度的近似算法。

    

    因果图发现是一个在各个学科中具有重要应用的问题。然而，仅凭观察数据，只能恢复到其马尔可夫等价类的潜在因果图，并且需要进一步的假设或干预来缩小真实图的范围。本研究解决了在随机干预设置下的因果发现问题，目标是尽量减少干预次数。我们提出了以下随机干预模型，它包含了现有文献中的自适应无噪声干预，并能捕捉到脂肪手干预和CRISPR基因敲除等情况：任何干预尝试都会导致对一个随机顶点子集的实际干预，这个子集的选择是依赖于尝试的动作的分布。在这个模型下，我们研究了因果发现中的验证和搜索两个基本问题，并提供了具有多对数复杂度的近似算法。

    Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fat-hand interventions and CRISPR gene knockouts: any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a distribution dependent on attempted action. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic c
    
[^17]: 弱分布重叠下马尔可夫决策过程中的离策略评估

    Off-Policy Evaluation in Markov Decision Processes under Weak Distributional Overlap

    [https://arxiv.org/abs/2402.08201](https://arxiv.org/abs/2402.08201)

    本文研究了弱分布重叠下马尔可夫决策过程中的离策略评估问题，并提出了一种截断双重稳健（TDR）估计器，在这种情况下表现良好。

    

    在马尔可夫决策过程（MDP）中，双重稳健方法在序列可忽略性下对离策略评估具有很大的潜力：它们已经证明了随着时长T的收敛速度为$1/\sqrt{T}$，在大样本中具有统计效率，并且可以通过标准强化学习技术执行预估任务，具有模块化实现的能力。然而，现有结果在很大程度上使用了强分布重叠假设，即目标政策和数据收集政策的稳态分布相差在有限因子内，而这个假设通常只在MDP的状态空间有界时才可信。在本文中，我们重新审视了在弱分布重叠概念下的MDP离策略评估任务，并引入了一类截断双重稳健（TDR）估计器，在这种情况下表现良好。当目标和数据收集的分布比率有界时，我们证明了这些估计器的一致性。

    Doubly robust methods hold considerable promise for off-policy evaluation in Markov decision processes (MDPs) under sequential ignorability: They have been shown to converge as $1/\sqrt{T}$ with the horizon $T$, to be statistically efficient in large samples, and to allow for modular implementation where preliminary estimation tasks can be executed using standard reinforcement learning techniques. Existing results, however, make heavy use of a strong distributional overlap assumption whereby the stationary distributions of the target policy and the data-collection policy are within a bounded factor of each other -- and this assumption is typically only credible when the state space of the MDP is bounded. In this paper, we re-visit the task of off-policy evaluation in MDPs under a weaker notion of distributional overlap, and introduce a class of truncated doubly robust (TDR) estimators which we find to perform well in this setting. When the distribution ratio of the target and data-coll
    
[^18]: 高斯模型集成置信传播用于高维系统中的高效推断

    Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional Systems

    [https://arxiv.org/abs/2402.08193](https://arxiv.org/abs/2402.08193)

    高斯模型集成置信传播算法（GEnBP）是一种用于高维系统中高效推断的方法，通过集成卡尔曼滤波器和高斯置信传播等技术相结合，能有效处理高维状态、参数和复杂的依赖结构。

    

    高维模型中的高效推断仍然是机器学习中的一个核心挑战。本文介绍了一种名为高斯模型集成置信传播（GEnBP）算法的方法，该方法是集成卡尔曼滤波器和高斯置信传播（GaBP）方法的结合。GEnBP通过在图模型结构中传递低秩本地信息来更新集成模型。这种组合继承了每种方法的有利特性。集成技术使得GEnBP能够处理高维状态、参数和复杂的、嘈杂的黑箱生成过程。在图模型结构中使用本地信息确保了该方法适用于分布式计算，并能高效地处理复杂的依赖结构。当集成大小远小于推断维度时，GEnBP特别有优势。这种情况在空时建模、图像处理和物理模型反演等领域经常出现。GEnBP可以应用于一般性问题。

    Efficient inference in high-dimensional models remains a central challenge in machine learning. This paper introduces the Gaussian Ensemble Belief Propagation (GEnBP) algorithm, a fusion of the Ensemble Kalman filter and Gaussian belief propagation (GaBP) methods. GEnBP updates ensembles by passing low-rank local messages in a graphical model structure. This combination inherits favourable qualities from each method. Ensemble techniques allow GEnBP to handle high-dimensional states, parameters and intricate, noisy, black-box generation processes. The use of local messages in a graphical model structure ensures that the approach is suited to distributed computing and can efficiently handle complex dependence structures. GEnBP is particularly advantageous when the ensemble size is considerably smaller than the inference dimension. This scenario often arises in fields such as spatiotemporal modelling, image processing and physical model inversion. GEnBP can be applied to general problem s
    
[^19]: 变分连续测试时适应性

    Variational Continual Test-Time Adaptation

    [https://arxiv.org/abs/2402.08182](https://arxiv.org/abs/2402.08182)

    本文介绍了VCoTTA，一种变分贝叶斯方法用于测量连续测试时适应性中的不确定性。采用变分预热策略将预训练的模型转为贝叶斯神经网络，在测试时通过均值教师更新策略来更新学生模型，结合源模型和教师模型的先验。实验证明该方法在减轻先验偏移方面有效。

    

    先验偏移在只使用无标签测试数据的连续测试时适应性（CTTA）方法中至关重要，因为它可能导致严重的误差传播。在本文中，我们介绍了VCoTTA，一种用于测量CTTA中不确定性的变分贝叶斯方法。在源阶段，我们通过变分预热策略将预训练的确定性模型转化为贝叶斯神经网络（BNN），将不确定性注入模型中。在测试时，我们采用变分推断的均值教师更新策略，将学生模型和指数移动平均法用于教师模型。我们的新方法通过结合源模型和教师模型的先验来更新学生模型。证据下界被制定为学生模型和教师模型之间的交叉熵，以及先验混合的Kullback-Leibler（KL）散度。在三个数据集上的实验结果表明该方法在减轻在CTTA中的先验偏移方面的有效性。

    The prior drift is crucial in Continual Test-Time Adaptation (CTTA) methods that only use unlabeled test data, as it can cause significant error propagation. In this paper, we introduce VCoTTA, a variational Bayesian approach to measure uncertainties in CTTA. At the source stage, we transform a pre-trained deterministic model into a Bayesian Neural Network (BNN) via a variational warm-up strategy, injecting uncertainties into the model. During the testing time, we employ a mean-teacher update strategy using variational inference for the student model and exponential moving average for the teacher model. Our novel approach updates the student model by combining priors from both the source and teacher models. The evidence lower bound is formulated as the cross-entropy between the student and teacher models, along with the Kullback-Leibler (KL) divergence of the prior mixture. Experimental results on three datasets demonstrate the method's effectiveness in mitigating prior drift within th
    
[^20]: 关于Transformer架构的限制

    On Limitations of the Transformer Architecture

    [https://arxiv.org/abs/2402.08164](https://arxiv.org/abs/2402.08164)

    本论文通过通信复杂性证明了Transformer层在处理函数组合任务时的局限性，指出对于大型定义域和某些数学任务，Transformers可能无法解决。

    

    大型语言模型（LLMs）中幻觉的根本原因是什么？我们使用通信复杂性来证明，如果函数的定义域足够大，Transformer层无法组合函数（例如，在家谱中查找一个人的祖父）；我们通过示例显示，当定义域相当小的时候，这种能力的缺乏已经在经验上存在。我们还指出，许多在所谓的组合任务中的数学任务，认为它们对LLMs来说很难解决，对于足够大的实例来说，且假设计算复杂性领域的某些被广泛接受的猜想是正确的，Transformers也不太可能解决。

    What are the root causes of hallucinations in large language models (LLMs)? We use Communication Complexity to prove that the Transformer layer is incapable of composing functions (e.g., identify a grandparent of a person in a genealogy) if the domains of the functions are large enough; we show through examples that this inability is already empirically present when the domains are quite small. We also point out that several mathematical tasks that are at the core of the so-called compositional tasks thought to be hard for LLMs are unlikely to be solvable by Transformers, for large enough instances and assuming that certain well accepted conjectures in the field of Computational Complexity are true.
    
[^21]: 学习具有Laplacian约束的笛卡尔乘积图

    Learning Cartesian Product Graphs with Laplacian Constraints

    [https://arxiv.org/abs/2402.08105](https://arxiv.org/abs/2402.08105)

    本文研究了在Laplacian约束下学习笛卡尔乘积图的问题，建立了笛卡尔乘积Laplacian的统计一致性，并提出了一种有效的算法。实验证明了方法的有效性。

    

    图Laplacian学习，也被称为网络拓扑推断，是一个吸引多个领域兴趣的问题。在高斯图模型（GM）中，图学习等价于向协方差选择添加Laplacian结构。在图信号处理（GSP）中，从过滤系统的输出中推断未观察到的图是至关重要的。在本文中，我们研究了在Laplacian约束下学习笛卡尔乘积图的问题。笛卡尔图乘积是建模高阶条件依赖的一种自然方法，也是将GSP推广到多路张量的关键。我们建立了笛卡尔乘积Laplacian的惩罚最大似然估计（MLE）的统计一致性，并提出了一种有效的算法来解决这个问题。我们还扩展了我们的方法，以在存在结构性缺失值的情况下进行高效的联合图学习和插补。对合成和真实世界数据集的实验证明了我们的方法的有效性。

    Graph Laplacian learning, also known as network topology inference, is a problem of great interest to multiple communities. In Gaussian graphical models (GM), graph learning amounts to endowing covariance selection with the Laplacian structure. In graph signal processing (GSP), it is essential to infer the unobserved graph from the outputs of a filtering system. In this paper, we study the problem of learning Cartesian product graphs under Laplacian constraints. The Cartesian graph product is a natural way for modeling higher-order conditional dependencies and is also the key for generalizing GSP to multi-way tensors. We establish statistical consistency for the penalized maximum likelihood estimation (MLE) of a Cartesian product Laplacian, and propose an efficient algorithm to solve the problem. We also extend our method for efficient joint graph learning and imputation in the presence of structural missing values. Experiments on synthetic and real-world datasets demonstrate that our 
    
[^22]: 一种加速梯度方法求解具有凸下层问题的简单双层优化问题

    An Accelerated Gradient Method for Simple Bilevel Optimization with Convex Lower-level Problem

    [https://arxiv.org/abs/2402.08097](https://arxiv.org/abs/2402.08097)

    本文提出了一种加速梯度方法来解决具有凸下层问题的简单双层优化问题，通过局部逼近下层问题的解集和加速梯度更新方法，在有限次迭代内找到一个具有一定精度的最优解。

    

    本文主要研究简单的双层优化问题，即在另一个凸光滑约束优化问题的最优解集上最小化一个凸光滑目标函数。我们提出了一种新颖的双层优化方法，通过切平面方法局部逼近下层问题的解集，并采用加速梯度更新方法降低近似解集上的上层目标函数。我们通过子最优解和不可行误差度量我们方法的性能，并提供了对两个误差标准的非渐进收敛性保证。特别地，当可行集是紧致的时候，我们证明了我们的方法最多需要$\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$次迭代才能找到一个$\epsilon_f$-子最优且$\epsilon_g$-不可行的解。此外，在额外假设下，下层目标满足$r$阶H\"olderian误差时，我们给出了解的收敛速度估计。

    In this paper, we focus on simple bilevel optimization problems, where we minimize a convex smooth objective function over the optimal solution set of another convex smooth constrained optimization problem. We present a novel bilevel optimization method that locally approximates the solution set of the lower-level problem using a cutting plane approach and employs an accelerated gradient-based update to reduce the upper-level objective function over the approximated solution set. We measure the performance of our method in terms of suboptimality and infeasibility errors and provide non-asymptotic convergence guarantees for both error criteria. Specifically, when the feasible set is compact, we show that our method requires at most $\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$ iterations to find a solution that is $\epsilon_f$-suboptimal and $\epsilon_g$-infeasible. Moreover, under the additional assumption that the lower-level objective satisfies the $r$-th H\"olderian err
    
[^23]: 离散扩散模型的收敛分析：通过均匀化的确切实现

    Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization

    [https://arxiv.org/abs/2402.08095](https://arxiv.org/abs/2402.08095)

    本文通过均匀化的方式确切实现了离散扩散模型，研究了其理论性质，并提供了关于采样的总变差距离和KL散度保证。这一方法在建模离散数据方面具有重要的应用价值。

    

    扩散模型在数据生成任务中取得了巨大的经验成功。最近，一些努力已经被做出来，将扩散模型的框架适应到离散状态空间，为建模本质上是离散数据（如语言和图形）提供了一种更自然的方法。这通过将前向噪声过程和相应的逆过程都构建为连续时间马尔可夫链（CTMC）来实现。在本文中，我们研究了离散扩散模型的理论性质。具体而言，我们介绍了一种利用连续马尔可夫链均匀化的算法，在随机时间点上实现转移。在关于离散得分函数学习的合理假设下，我们得到了从超立方体上的任何分布进行采样所需的总变差距离和KL散度保证。我们的结果与在$\mathbb{R}^d$中的扩散模型的最新成就相一致，并进一步强调了d的优势。

    Diffusion models have achieved huge empirical success in data generation tasks. Recently, some efforts have been made to adapt the framework of diffusion models to discrete state space, providing a more natural approach for modeling intrinsically discrete data, such as language and graphs. This is achieved by formulating both the forward noising process and the corresponding reversed process as Continuous Time Markov Chains (CTMCs). In this paper, we investigate the theoretical properties of the discrete diffusion model. Specifically, we introduce an algorithm leveraging the uniformization of continuous Markov chains, implementing transitions on random time points. Under reasonable assumptions on the learning of the discrete score function, we derive Total Variation distance and KL divergence guarantees for sampling from any distribution on a hypercube. Our results align with state-of-the-art achievements for diffusion models in $\mathbb{R}^d$ and further underscore the advantages of d
    
[^24]: 基于分数的生成模型在学习一个子高斯概率分布族中突破了维数灾难

    Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions

    [https://arxiv.org/abs/2402.08082](https://arxiv.org/abs/2402.08082)

    基于分数的生成模型在学习一个子高斯概率分布族中突破了维数灾难，通过分数匹配生成的分布以维度无关的速率逼近目标分布的总变差。

    

    尽管基于分数的生成模型（SGMs）在巨大的图像生成任务中取得了显著的成功，但它们的数学基础仍然有限。在本文中，我们分析了SGMs在学习一个子高斯概率分布族中的近似和泛化。我们引入了一种关于概率分布复杂性的概念，即相对密度与标准高斯测度的相对密度。我们证明，如果对数相对密度可以通过神经网络进行局部逼近，并且网络参数可以适当地受限，那么通过经验分数匹配生成的分布以维度无关的速率逼近目标分布的总变差。我们通过示例说明了我们的理论，其中包括某些高斯混合分布。我们证明的一个关键点是推导出与正向过程相关的真实得分函数的维度无关的深度神经网络逼近速率。

    While score-based generative models (SGMs) have achieved remarkable success in enormous image generation tasks, their mathematical foundations are still limited. In this paper, we analyze the approximation and generalization of SGMs in learning a family of sub-Gaussian probability distributions. We introduce a notion of complexity for probability distributions in terms of their relative density with respect to the standard Gaussian measure. We prove that if the log-relative density can be locally approximated by a neural network whose parameters can be suitably bounded, then the distribution generated by empirical score matching approximates the target distribution in total variation with a dimension-independent rate. We illustrate our theory through examples, which include certain mixtures of Gaussians. An essential ingredient of our proof is to derive a dimension-free deep neural network approximation rate for the true score function associated with the forward process, which is inte
    
[^25]: 使用核函数的同胚度量匹配在生成建模中的应用

    Diffeomorphic Measure Matching with Kernels for Generative Modeling

    [https://arxiv.org/abs/2402.08077](https://arxiv.org/abs/2402.08077)

    该研究提出了使用核函数进行同胚度量匹配的方法，在生成建模中实现了概率测度的传输。通过理论分析和数值实验，本文展示了该方法的性能和适用性。

    

    本文提出了一个通用框架，通过普通微分方程(ODEs)和再生核希尔伯特空间(RKHSs)实现概率测度的传输，以达到最小差异的生成建模和采样。该框架受同胚匹配和图像配准思想的启发。文中通过理论分析，给出了该方法的先验误差界限，该界限与模型的复杂性、训练集中样本的数量和模型规范性有关。通过大量的数值实验进一步展示了该方法的特性、优势和弱点，并扩展了其在条件模拟和推断等其他任务中的适用性。

    This article presents a general framework for the transport of probability measures towards minimum divergence generative modeling and sampling using ordinary differential equations (ODEs) and Reproducing Kernel Hilbert Spaces (RKHSs), inspired by ideas from diffeomorphic matching and image registration. A theoretical analysis of the proposed method is presented, giving a priori error bounds in terms of the complexity of the model, the number of samples in the training set, and model misspecification. An extensive suite of numerical experiments further highlights the properties, strengths, and weaknesses of the method and extends its applicability to other tasks, such as conditional simulation and inference.
    
[^26]: 扩散生成模型的最近邻评分估计器

    Nearest Neighbour Score Estimators for Diffusion Generative Models

    [https://arxiv.org/abs/2402.08018](https://arxiv.org/abs/2402.08018)

    本论文提出了一种新颖的最近邻评分函数估计器，通过利用训练集中的多个样本大大降低了估计器的方差，可用于训练一致性模型和扩散模型，提高收敛速度、样本质量，并为进一步的研究提供了新的可能性。

    

    评分函数估计是训练和采样扩散生成模型的基础。尽管如此，最常用的估计器要么是有偏的神经网络逼近，要么是基于条件评分的高方差蒙特卡洛估计器。我们引入了一种创新的最近邻评分函数估计器，利用训练集中的多个样本大大降低了估计器的方差。我们在两个引人注目的应用中利用了低方差估计器。在使用我们的估计器进行训练一致性模型时，我们报告了收敛速度和样本质量显著提高。在扩散模型中，我们展示了我们的估计器可以替代学习网络进行概率流ODE积分，为未来研究开辟了有前景的新方向。

    Score function estimation is the cornerstone of both training and sampling from diffusion generative models. Despite this fact, the most commonly used estimators are either biased neural network approximations or high variance Monte Carlo estimators based on the conditional score. We introduce a novel nearest neighbour score function estimator which utilizes multiple samples from the training set to dramatically decrease estimator variance. We leverage our low variance estimator in two compelling applications. Training consistency models with our estimator, we report a significant increase in both convergence speed and sample quality. In diffusion models, we show that our estimator can replace a learned network for probability-flow ODE integration, opening promising new avenues of future research.
    
[^27]: CNN需要哪些频率？特征学习中的紧急瓶颈结构的出现

    Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning

    [https://arxiv.org/abs/2402.08010](https://arxiv.org/abs/2402.08010)

    本文描述了CNN中卷积瓶颈（CBN）结构的出现，网络在前几层将输入表示转换为在少数频率和通道上受支持的表示，然后通过最后几层映射回输出。CBN秩定义了保留在瓶颈中的频率的数量和类型，并部分证明了参数范数与深度和CBN秩的比例成正比。此外，我们还展示了网络的参数范数依赖于函数的规则性。我们发现任何具有接近最优参数范数的网络都会展示出CBN结构，这解释了下采样的常见实践；我们还验证了CBN结构在下采样下仍然成立。最后，我们使用CBN结构来解释...（摘要完整内容请见正文）

    

    我们描述了CNN中卷积瓶颈（CBN）结构的出现，网络使用其前几层将输入表示转换为仅在几个频率和通道上受支持的表示，然后使用最后几层将其映射回输出。我们定义了CBN秩，描述了保留在瓶颈内的频率的数量和类型，并在一定程度上证明了表示函数$f$所需的参数范数按深度乘以CBN秩$f$的比例缩放。我们还展示了参数范数在下一阶中依赖于$f$的正则性。我们展示了任何具有近乎最优参数范数的网络都会在权重和（在网络对大学习率稳定的假设下）激活中表现出CBN结构，这促使了下采样的常见做法；并且我们验证了CBN结构在下采样下仍然成立。最后，我们使用CBN结构来解释...

    We describe the emergence of a Convolution Bottleneck (CBN) structure in CNNs, where the network uses its first few layers to transform the input representation into a representation that is supported only along a few frequencies and channels, before using the last few layers to map back to the outputs. We define the CBN rank, which describes the number and type of frequencies that are kept inside the bottleneck, and partially prove that the parameter norm required to represent a function $f$ scales as depth times the CBN rank $f$. We also show that the parameter norm depends at next order on the regularity of $f$. We show that any network with almost optimal parameter norm will exhibit a CBN structure in both the weights and - under the assumption that the network is stable under large learning rate - the activations, which motivates the common practice of down-sampling; and we verify that the CBN results still hold with down-sampling. Finally we use the CBN structure to interpret the
    
[^28]: 用BAM进行图结构推断：引入双线性注意机制

    Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism

    [https://arxiv.org/abs/2402.07735](https://arxiv.org/abs/2402.07735)

    本论文提出了一种利用BAM进行图结构推断的方法。通过神经网络模型，通过变形的耦合模拟输入数据进行训练，仅需通过一次前向传递即可进行推断。通过利用结构方程模型和随机生成的多变量切比雪夫多项式来模拟训练数据，方法能够泛化到线性和各种非线性依赖关系。引入了双线性注意机制（BAM）来处理依赖关系，该机制在转换数据的协方差矩阵水平上运行，并尊重对称正定矩阵流形的几何特性。实证评估证明了方法的有效性和性能。

    

    在统计学和机器学习中，检测数据集中的依赖关系是一个核心挑战。我们提出了一种新颖的神经网络模型，用于监督图结构学习，即学习观测数据和它们的基本依赖结构之间的映射。该模型通过变形的耦合模拟输入数据进行训练，并且仅需通过训练网络进行一次前向传递即可进行推断。通过利用结构方程模型，并通过随机生成的多变量切比雪夫多项式来模拟训练数据，我们的方法展示了在线性和各种非线性依赖关系之间的强大泛化能力。我们引入了一种新的双线性注意机制（BAM），用于显式处理依赖信息，该机制在转换数据的协方差矩阵水平上运行，并尊重对称正定矩阵流形的几何特性。实证评估展示了方法的有效性和性能。

    In statistics and machine learning, detecting dependencies in datasets is a central challenge. We propose a novel neural network model for supervised graph structure learning, i.e., the process of learning a mapping between observational data and their underlying dependence structure. The model is trained with variably shaped and coupled simulated input data and requires only a single forward pass through the trained network for inference. By leveraging structural equation models and employing randomly generated multivariate Chebyshev polynomials for the simulation of training data, our method demonstrates robust generalizability across both linear and various types of non-linear dependencies. We introduce a novel bilinear attention mechanism (BAM) for explicit processing of dependency information, which operates on the level of covariance matrices of transformed data and respects the geometry of the manifold of symmetric positive definite matrices. Empirical evaluation demonstrates th
    
[^29]: 回归树用于快速和自适应的预测区间

    Regression Trees for Fast and Adaptive Prediction Intervals

    [https://arxiv.org/abs/2402.07357](https://arxiv.org/abs/2402.07357)

    该论文提出了一种新的、与模型无关的方法族，用于校准具有局部覆盖保证的回归问题的预测区间。这种方法利用回归树和随机森林训练来创建最粗糙的特征空间划分，以近似条件覆盖，提供了准确、快速和自适应的预测区间。

    

    预测模型会犯错，因此需要量化与其预测相关的不确定性。符合性推断已经成为一种强大的工具，可以在点预测周围创建统计上有效的预测区域，但是它在回归问题上的朴素应用会产生非自适应的区域。新的符合性得分，通常依赖于分位数回归器或条件密度估计器，旨在解决这个限制。虽然它们在创建预测带方面很有用，但这些得分与量化任意预测模型周围的不确定性的原始目标脱节。本文提出了一种新的、与模型无关的方法族，用于校准具有局部覆盖保证的回归问题的预测区间。我们的方法是基于追求最粗糙的特征空间划分来近似条件覆盖。我们通过对符合性得分进行回归树和随机森林的训练来创建这个划分。我们的提议将回归树和随机森林应用于符合性推断的新领域，以提供准确、快速和自适应的预测区间。

    Predictive models make mistakes. Hence, there is a need to quantify the uncertainty associated with their predictions. Conformal inference has emerged as a powerful tool to create statistically valid prediction regions around point predictions, but its naive application to regression problems yields non-adaptive regions. New conformal scores, often relying upon quantile regressors or conditional density estimators, aim to address this limitation. Although they are useful for creating prediction bands, these scores are detached from the original goal of quantifying the uncertainty around an arbitrary predictive model. This paper presents a new, model-agnostic family of methods to calibrate prediction intervals for regression problems with local coverage guarantees. Our approach is based on pursuing the coarsest partition of the feature space that approximates conditional coverage. We create this partition by training regression trees and Random Forests on conformity scores. Our proposal
    
[^30]: 从均场稳态分布中采样

    Sampling from the Mean-Field Stationary Distribution

    [https://arxiv.org/abs/2402.07355](https://arxiv.org/abs/2402.07355)

    本文研究了从均场随机微分方程 (SDE) 的稳态分布中采样的复杂性，并提出了一种解耦的方法。该方法能够在多种情况下提供改进的保证，包括在均场区域优化某些双层神经网络的更好保证。

    

    我们研究了从均场随机微分方程 (SDE) 的稳态分布中采样的复杂性，或者等价地，即包含交互项的概率测度空间上的最小化函数的复杂性。我们的主要洞察是将这个问题的两个关键方面解耦：(1) 通过有限粒子系统逼近均场SDE，通过时间均匀传播混沌，和(2) 通过标准对数凹抽样器从有限粒子稳态分布中采样。我们的方法在概念上更简单，其灵活性允许结合用于算法和理论的最新技术。这导致在许多设置中提供了改进的保证，包括在均场区域优化某些双层神经网络的更好保证。

    We study the complexity of sampling from the stationary distribution of a mean-field SDE, or equivalently, the complexity of minimizing a functional over the space of probability measures which includes an interaction term.   Our main insight is to decouple the two key aspects of this problem: (1) approximation of the mean-field SDE via a finite-particle system, via uniform-in-time propagation of chaos, and (2) sampling from the finite-particle stationary distribution, via standard log-concave samplers. Our approach is conceptually simpler and its flexibility allows for incorporating the state-of-the-art for both algorithms and theory. This leads to improved guarantees in numerous settings, including better guarantees for optimizing certain two-layer neural networks in the mean-field regime.
    
[^31]: HyperBERT:将混合超图感知层与语言模型用于文本属性超图上的节点分类

    HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs

    [https://arxiv.org/abs/2402.07309](https://arxiv.org/abs/2402.07309)

    本文提出了HyperBERT模型，通过在预训练的BERT模型中引入超图感知层，克服了现有方法在节点分类任务上难以捕捉超图结构信息和文本属性的局限性，提高了模型的效果和泛化能力。

    

    超图通过复杂的拓扑结构标记，表达多个实体之间的高阶相互作用，其中超边扮演重要角色。最近，基于超图的深度学习方法在学习文本属性超图上的节点分类问题中引起了越来越多的研究关注。然而，现有方法往往难以同时捕捉超图结构信息的全部内容和节点属性中的丰富语言属性，这在很大程度上影响了它们的效果和泛化能力。为了克服这些挑战，我们探索了如何通过为节点分类任务进一步增强预训练的BERT模型，引入专门的超图感知层。这些层将高阶结构归纳偏差引入语言模型中，从而提高模型利用超图结构中的高阶上下文信息和文本中的语义信息的能力。

    Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple entities with hyperedges. Lately, hypergraph-based deep learning methods to learn informative data representations for the problem of node classification on text-attributed hypergraphs have garnered increasing research attention. However, existing methods struggle to simultaneously capture the full extent of hypergraph structural information and the rich linguistic attributes inherent in the nodes attributes, which largely hampers their effectiveness and generalizability. To overcome these challenges, we explore ways to further augment a pretrained BERT model with specialized hypergraph-aware layers for the task of node classification. Such layers introduce higher-order structural inductive bias into the language model, thus improving the model's capacity to harness both higher-order context information from the hypergraph structure and semantic information present in text. In this paper, we
    
[^32]: 面向扩散生成模型的快速随机采样方法

    Towards Fast Stochastic Sampling in Diffusion Generative Models

    [https://arxiv.org/abs/2402.07211](https://arxiv.org/abs/2402.07211)

    本文提出了一种在扩散生成模型中进行快速随机采样的方法，通过对分裂积分器进行原则性修改，实现了更高的采样效率。在CIFAR-10数据集上进行实验，100次网络函数评估下的FID分数为2.36。

    

    扩散模型在推理时生成样本的速度较慢。尽管最近有一些努力在改善扩散模型的随机采样效率，但仍然有待改进。我们提出了基于分裂积分器的预训练扩散模型的快速随机采样方法。分裂积分器通常在分子动力学中使用，通过巧妙地在涉及数据、辅助或噪声变量的数值更新之间交替来提高采样效率。然而，我们发现对于快速采样，简单应用分裂积分器是次优的。因此，我们提出了几种原则上修改了简单分裂采样器以提高采样效率的方法，并将得到的采样器称为减小分裂积分器。在CIFAR-10数据集上使用相空间朗之万扩散 (PSLD) [Pandey \& Mandt, 2023] 的背景下，我们的随机采样器在仅进行100次网络函数评估后，实现了2.36的FID分数。

    Diffusion models suffer from slow sample generation at inference time. Despite recent efforts, improving the sampling efficiency of stochastic samplers for diffusion models remains a promising direction. We propose Splitting Integrators for fast stochastic sampling in pre-trained diffusion models in augmented spaces. Commonly used in molecular dynamics, splitting-based integrators attempt to improve sampling efficiency by cleverly alternating between numerical updates involving the data, auxiliary, or noise variables. However, we show that a naive application of splitting integrators is sub-optimal for fast sampling. Consequently, we propose several principled modifications to naive splitting samplers for improving sampling efficiency and denote the resulting samplers as Reduced Splitting Integrators. In the context of Phase Space Langevin Diffusion (PSLD) [Pandey \& Mandt, 2023] on CIFAR-10, our stochastic sampler achieves an FID score of 2.36 in only 100 network function evaluations 
    
[^33]: 关于分散推断模型的扩散模型：基准测试和改进随机控制和采样

    On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling

    [https://arxiv.org/abs/2402.05098](https://arxiv.org/abs/2402.05098)

    本研究探讨了训练扩散模型以从给定分布中采样的问题，并针对随机控制和采样提出了一种新的探索策略，通过基准测试比较了不同推断方法的相对优劣，并对过去的工作提出了质疑。

    

    我们研究了训练扩散模型以从给定的非标准化密度或能量函数分布中采样的问题。我们对几种扩散结构推断方法进行了基准测试，包括基于模拟的变分方法和离策略方法（连续生成流网络）。我们的结果揭示了现有算法的相对优势，同时对过去的研究提出了一些质疑。我们还提出了一种新颖的离策略方法探索策略，基于目标空间中的局部搜索和回放缓冲区的使用，并证明它可以改善各种目标分布上的样本质量。我们研究的采样方法和基准测试的代码已公开在https://github.com/GFNOrg/gfn-diffusion，作为未来在分散推断模型上工作的基础。

    We study the problem of training diffusion models to sample from a distribution with a given unnormalized density or energy function. We benchmark several diffusion-structured inference methods, including simulation-based variational approaches and off-policy methods (continuous generative flow networks). Our results shed light on the relative advantages of existing algorithms while bringing into question some claims from past work. We also propose a novel exploration strategy for off-policy methods, based on local search in the target space with the use of a replay buffer, and show that it improves the quality of samples on a variety of target distributions. Our code for the sampling methods and benchmarks studied is made public at https://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusion models for amortized inference.
    
[^34]: 在一般希尔伯特空间中使用随机梯度下降学习算子

    Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces

    [https://arxiv.org/abs/2402.04691](https://arxiv.org/abs/2402.04691)

    本研究在一般希尔伯特空间中使用随机梯度下降（SGD）学习算子，提出了适用于目标算子的规则条件，并建立了SGD算法的收敛速度上界，同时展示了对于非线性算子学习的有效性及线性近似收敛特性。

    

    本研究探讨了利用随机梯度下降（SGD）在一般希尔伯特空间中学习算子的方法。我们提出了针对目标算子的弱和强规则条件，以描述其内在结构和复杂性。在这些条件下，我们建立了SGD算法的收敛速度的上界，并进行了极小值下界分析，进一步说明我们的收敛分析和规则条件定量地刻画了使用SGD算法解决算子学习问题的可行性。值得强调的是，我们的收敛分析对于非线性算子学习仍然有效。我们证明了SGD估计器将收敛于非线性目标算子的最佳线性近似。此外，将我们的分析应用于基于矢量值和实值再生核希尔伯特空间的算子学习问题，产生了新的收敛结果，从而完善了现有文献的结论。

    This study investigates leveraging stochastic gradient descent (SGD) to learn operators between general Hilbert spaces. We propose weak and strong regularity conditions for the target operator to depict its intrinsic structure and complexity. Under these conditions, we establish upper bounds for convergence rates of the SGD algorithm and conduct a minimax lower bound analysis, further illustrating that our convergence analysis and regularity conditions quantitatively characterize the tractability of solving operator learning problems using the SGD algorithm. It is crucial to highlight that our convergence analysis is still valid for nonlinear operator learning. We show that the SGD estimator will converge to the best linear approximation of the nonlinear target operator. Moreover, applying our analysis to operator learning problems based on vector-valued and real-valued reproducing kernel Hilbert spaces yields new convergence results, thereby refining the conclusions of existing litera
    
[^35]: 添加非参数回归的随机梯度下降

    Stochastic Gradient Descent for Additive Nonparametric Regression

    [https://arxiv.org/abs/2401.00691](https://arxiv.org/abs/2401.00691)

    本文介绍了一种用于训练加性模型的随机梯度下降算法，具有良好的内存存储和计算要求。在规范很好的情况下，通过仔细选择学习率，可以实现最小和最优的风险。

    

    本文介绍了一种用于训练加性模型的迭代算法，该算法具有良好的内存存储和计算要求。该算法可以看作是对组件函数的截断基扩展的系数应用随机梯度下降的函数对应物。我们证明了得到的估计量满足一个奥拉克不等式，允许模型错误规范。在规范很好的情况下，通过在训练的三个不同阶段仔细选择学习率，我们证明了其风险在数据维度和训练样本大小的依赖方面是最小和最优的。通过在两个实际数据集上将该方法与传统的反向拟合进行比较，我们进一步说明了计算优势。

    This paper introduces an iterative algorithm for training additive models that enjoys favorable memory storage and computational requirements. The algorithm can be viewed as the functional counterpart of stochastic gradient descent, applied to the coefficients of a truncated basis expansion of the component functions. We show that the resulting estimator satisfies an oracle inequality that allows for model mis-specification. In the well-specified setting, by choosing the learning rate carefully across three distinct stages of training, we demonstrate that its risk is minimax optimal in terms of the dependence on the dimensionality of the data and the size of the training sample. We further illustrate the computational benefits by comparing the approach with traditional backfitting on two real-world datasets.
    
[^36]: 大语言模型的非平凡泛化界限

    Non-Vacuous Generalization Bounds for Large Language Models

    [https://arxiv.org/abs/2312.17173](https://arxiv.org/abs/2312.17173)

    这项研究提供了首个针对预训练大语言模型的非平凡泛化界限，表明语言模型能够发现适用于未见数据的规律性。建立了有效的压缩界限，证明较大的模型具有更好的泛化界限并更易压缩。

    

    现代语言模型可以包含数十亿个参数，这引发了一个问题，它们是否可以在训练数据之外进行泛化，或者只是重复它们的训练语料库。我们提供了首个针对预训练大语言模型（LLM）的非平凡泛化界限，表明语言模型能够发现适用于未见数据的规律性。具体而言，我们使用预测平滑导出了一个适用于无界对数似然损失的压缩界限，并且我们扩展了该界限以处理子采样，加速对大规模数据集的界限计算。为了实现非平凡泛化界限所需的极端压缩程度，我们设计了SubLoRA，这是一种低维非线性参数化方法。使用这种方法，我们发现较大的模型具有更好的泛化界限，并且比较小的模型更易压缩。

    Modern language models can contain billions of parameters, raising the question of whether they can generalize beyond the training data or simply regurgitate their training corpora. We provide the first non-vacuous generalization bounds for pretrained large language models (LLMs), indicating that language models are capable of discovering regularities that generalize to unseen data. In particular, we derive a compression bound that is valid for the unbounded log-likelihood loss using prediction smoothing, and we extend the bound to handle subsampling, accelerating bound computation on massive datasets. To achieve the extreme level of compression required for non-vacuous generalization bounds, we devise SubLoRA, a low-dimensional non-linear parameterization. Using this approach, we find that larger models have better generalization bounds and are more compressible than smaller models.
    
[^37]: Bagged Regularized $k$-Distances用于异常检测

    Bagged Regularized $k$-Distances for Anomaly Detection

    [https://arxiv.org/abs/2312.01046](https://arxiv.org/abs/2312.01046)

    本文提出了一种称为Bagged Regularized $k$-Distances for Anomaly Detection (BRDAD)的基于距离的算法，通过将非监督异常检测问题转化为凸优化问题，成功解决了基于距离算法中超参数选择的敏感性挑战，并通过包集成方法解决了处理大规模数据集时的效率问题。

    

    本文考虑非监督异常检测的范式，即在没有标记的情况下识别数据集中的异常值。尽管基于距离的方法对于非监督异常检测具有较好的性能，但它们对最近邻数量的选择非常敏感。为此，我们提出了一种新的基于距离的算法，称为Bagged Regularized $k$-Distances for Anomaly Detection (BRDAD)，将非监督异常检测问题转化为凸优化问题。我们的BRDAD算法通过最小化替代风险（即经验风险的有限样本上界）来选择权重，以用于密度估计的带权重的$k$-distances。这种方法成功解决了基于距离算法中超参数选择的敏感性挑战。此外，在处理大规模数据集时，我们还可以通过包集成的方法来解决效率问题。

    We consider the paradigm of unsupervised anomaly detection, which involves the identification of anomalies within a dataset in the absence of labeled examples. Though distance-based methods are top-performing for unsupervised anomaly detection, they suffer heavily from the sensitivity to the choice of the number of the nearest neighbors. In this paper, we propose a new distance-based algorithm called bagged regularized $k$-distances for anomaly detection (BRDAD) converting the unsupervised anomaly detection problem into a convex optimization problem. Our BRDAD algorithm selects the weights by minimizing the surrogate risk, i.e., the finite sample bound of the empirical risk of the bagged weighted $k$-distances for density estimation (BWDDE). This approach enables us to successfully address the sensitivity challenge of the hyperparameter choice in distance-based algorithms. Moreover, when dealing with large-scale datasets, the efficiency issues can be addressed by the incorporated baggi
    
[^38]: MFAI:一种可扩展的贝叶斯矩阵分解方法来利用辅助信息

    MFAI: A Scalable Bayesian Matrix Factorization Approach to Leveraging Auxiliary Information

    [https://arxiv.org/abs/2303.02566](https://arxiv.org/abs/2303.02566)

    MFAI是一种可扩展的贝叶斯矩阵分解方法，通过利用辅助信息来克服由于数据质量差导致的挑战，具有灵活建模非线性关系和对辅助信息的鲁棒性。

    

    在各种实际情况下，矩阵分解方法在数据质量差的情况下往往表现不佳，例如数据稀疏性高和信噪比低。在这里，我们考虑利用辅助信息的矩阵分解问题，辅助信息在实际应用中是大量可用的，以克服由于数据质量差引起的挑战。与现有方法主要依赖于简单线性模型将辅助信息与主数据矩阵结合不同，我们提出将梯度增强树集成到概率矩阵分解框架中以有效地利用辅助信息(MFAI)。因此，MFAI自然地继承了梯度增强树的几个显著特点，如灵活建模非线性关系、对辅助信息中的不相关特征和缺失值具有鲁棒性。MFAI中的参数可以在经验贝叶斯框架下自动确定，使其适应于利用辅助信息。

    In various practical situations, matrix factorization methods suffer from poor data quality, such as high data sparsity and low signal-to-noise ratio (SNR). Here, we consider a matrix factorization problem by utilizing auxiliary information, which is massively available in real-world applications, to overcome the challenges caused by poor data quality. Unlike existing methods that mainly rely on simple linear models to combine auxiliary information with the main data matrix, we propose to integrate gradient boosted trees in the probabilistic matrix factorization framework to effectively leverage auxiliary information (MFAI). Thus, MFAI naturally inherits several salient features of gradient boosted trees, such as the capability of flexibly modeling nonlinear relationships and robustness to irrelevant features and missing values in auxiliary information. The parameters in MFAI can be automatically determined under the empirical Bayes framework, making it adaptive to the utilization of a
    
[^39]: 一种具有通用参数化和线性收敛的政策镜面下降新框架

    A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence

    [https://arxiv.org/abs/2301.13139](https://arxiv.org/abs/2301.13139)

    我们提出了一种新的政策优化框架，通过镜面下降自然地适应通用参数化，并获得了应用于通用参数化的基于政策梯度的方法的线性收敛保证。

    

    强化学习中现代政策优化方法（如TRPO和PPO）的成功归功于参数化政策的使用。然而，尽管已经为这类算法在标签设置中建立了理论保证，但对于通用参数化方案的使用仍然没有得到充分证明。在这项工作中，我们介绍了一种基于镜面下降的政策优化新框架，可以自然地适应通用参数化。我们方案所产生的政策类可以恢复已知的类，如softmax，并根据镜面映射的选择生成新类。使用我们的框架，我们获得了关于涉及通用参数化的基于政策梯度的方法的线性收敛的首个结果。为了展示我们的框架适应通用参数化方案的能力，我们提供了使用浅层神经网络时的样本复杂性，并展示它相对于先前方法的改进。

    Modern policy optimization methods in reinforcement learning, such as TRPO and PPO, owe their success to the use of parameterized policies. However, while theoretical guarantees have been established for this class of algorithms, especially in the tabular setting, the use of general parameterization schemes remains mostly unjustified. In this work, we introduce a novel framework for policy optimization based on mirror descent that naturally accommodates general parameterizations. The policy class induced by our scheme recovers known classes, e.g., softmax, and generates new ones depending on the choice of mirror map. Using our framework, we obtain the first result that guarantees linear convergence for a policy-gradient-based method involving general parameterization. To demonstrate the ability of our framework to accommodate general parameterization schemes, we provide its sample complexity when using shallow neural networks, show that it represents an improvement upon the previous be
    
[^40]: 因果DAG的子集验证和搜索算法

    Subset verification and search algorithms for causal DAGs

    [https://arxiv.org/abs/2301.03180](https://arxiv.org/abs/2301.03180)

    本文研究了在学习因果DAG的子集关系时，识别所需最小干预集的问题，提出了两种有效算法进行解决。在子集验证问题上，我们提供了一种计算最小干预集的高效算法。在子集搜索问题上，我们提出了两种解决方法。

    

    学习变量之间的因果关系是因果推断中的一项基本任务，有向无环图（DAGs）是表示因果关系的常见选择。由于我们只能从观测数据中恢复因果图的 Markov 等价类，因此通常需要使用干预来进行恢复任务。干预通常是昂贵的，因此设计能够最小化干预次数的算法非常重要。在这项工作中，我们研究了在学习一组边缘（目标边缘）之间的因果关系时，识别所需最小干预集的问题。在假设忠实性、因果充分性和理想干预的条件下，我们在两个设置下研究了这个问题：当底层真实因果图已知时（子集验证），以及当其未知时（子集搜索）。对于子集验证问题，我们提供了一个有效的算法来计算最小干预集；我们进一步解决了子集搜索问题，并提出了两种算法进行解决。

    Learning causal relationships between variables is a fundamental task in causal inference and directed acyclic graphs (DAGs) are a popular choice to represent the causal relationships. As one can recover a causal graph only up to its Markov equivalence class from observations, interventions are often used for the recovery task. Interventions are costly in general and it is important to design algorithms that minimize the number of interventions performed. In this work, we study the problem of identifying the smallest set of interventions required to learn the causal relationships between a subset of edges (target edges). Under the assumptions of faithfulness, causal sufficiency, and ideal interventions, we study this problem in two settings: when the underlying ground truth causal graph is known (subset verification) and when it is unknown (subset search). For the subset verification problem, we provide an efficient algorithm to compute a minimum sized interventional set; we further ex
    
[^41]: 通过打分规则最小化实现生成网络的概率预测

    Probabilistic Forecasting with Generative Networks via Scoring Rule Minimization

    [https://arxiv.org/abs/2112.08217](https://arxiv.org/abs/2112.08217)

    本论文提出了一种使用生成神经网络进行概率预测的方法，通过预测序列打分规则进行训练，避免了繁琐的超参数调整和不稳定的对抗训练，从而在概率预测中可靠地使用生成网络。

    

    概率预测依赖于过去的观察结果，以提供未来结果的概率分布，并通过打分规则与实际结果进行评估。在这里，我们使用生成神经网络进行概率预测，通过转换潜在变量的抽样来参数化高维空间上的分布。生成网络通常在对抗性框架中进行训练。相比之下，我们提出使用预测序列打分规则在记录的时间序列中训练生成网络，这种方法与常规评估预测系统的方式相一致。对于某些打分规则，可以实现无对抗的最小化；因此，我们的框架避免了繁琐的超参数调整和由于不稳定的对抗训练而导致的不确定性低估，从而在概率预测中可靠地使用生成网络。

    Probabilistic forecasting relies on past observations to provide a probability distribution for a future outcome, which is often evaluated against the realization using a scoring rule. Here, we perform probabilistic forecasting with generative neural networks, which parametrize distributions on high-dimensional spaces by transforming draws from a latent variable. Generative networks are typically trained in an adversarial framework. In contrast, we propose to train generative networks to minimize a predictive-sequential (or prequential) scoring rule on a recorded temporal sequence of the phenomenon of interest, which is appealing as it corresponds to the way forecasting systems are routinely evaluated. Adversarial-free minimization is possible for some scoring rules; hence, our framework avoids the cumbersome hyperparameter tuning and uncertainty underestimation due to unstable adversarial training, thus unlocking reliable use of generative networks in probabilistic forecasting. Furthe
    
[^42]: 面向多维度在线决策的随机低秩张量赌博算法

    Stochastic Low-rank Tensor Bandits for Multi-dimensional Online Decision Making

    [https://arxiv.org/abs/2007.15788](https://arxiv.org/abs/2007.15788)

    这项研究提出了一种针对多维度在线决策的随机低秩张量赌博算法。通过考虑有上下文和没有上下文的情况，提出了两种学习算法，并推导了有限时间的遗憾界限。

    

    多维度在线决策在在线推荐和数字营销等实际应用中起着关键作用。在这些问题中，每个时间点的决策是来自不同类型实体的选择的组合。为了解决这个问题，我们引入了随机低秩张量赌博算法，一类其均值收益可表示为低秩张量的赌博算法。我们考虑了两种情况，即没有上下文的张量赌博和有上下文的张量赌博。在第一种情况中，平台旨在找到具有最高期望回报的最佳决策，即真实回报张量的最大条目。在第二种情况中，张量的某些模式是上下文，其余模式是决策，目标是在给定上下文信息的情况下找到最佳决策。我们提出了两种学习算法：张量消除和张量时代贪婪算法，用于没有上下文的张量赌博，并为它们推导了有限时间的遗憾界限。与现有的竞争算法相比，我们的算法表现更好。

    Multi-dimensional online decision making plays a crucial role in many real applications such as online recommendation and digital marketing. In these problems, a decision at each time is a combination of choices from different types of entities. To solve it, we introduce stochastic low-rank tensor bandits, a class of bandits whose mean rewards can be represented as a low-rank tensor. We consider two settings, tensor bandits without context and tensor bandits with context. In the first setting, the platform aims to find the optimal decision with the highest expected reward, a.k.a, the largest entry of true reward tensor. In the second setting, some modes of the tensor are contexts and the rest modes are decisions, and the goal is to find the optimal decision given the contextual information. We propose two learning algorithms tensor elimination and tensor epoch-greedy for tensor bandits without context, and derive finite-time regret bounds for them. Comparing with existing competitive m
    
[^43]: COVID-19 ICU需求的年龄结构估计：基于低质量数据的方法

    Age-structured estimation of COVID-19 ICU demand from low quality data

    [https://arxiv.org/abs/2006.06530](https://arxiv.org/abs/2006.06530)

    本研究提出了一种基于低质量数据的方法，通过年龄结构估计 COVID-19 ICU 的需求量，并使用重症监护病房占用数据和通报因子进行校正，预测未来 ICU 床位的需求情况。

    

    我们通过对确诊病例进行年龄结构概率抽样，使用重症监护病房占用数据来确定一个未通报因子。然后，我们使用来自达到平台阶段的地区的情景，采用 logistic 拟合来预测 COVID-19 疫情的进展。最后，通过未通报因子，对找到的逻辑曲线进行校正，并对未来 ICU 床位需求进行抽样预测。

    We sample aggravated cases following age-structured probabilities from confirmed cases and use ICU occupation data to find a subnotification factor. A logistic fit is then employed to project the progression of the COVID-19 epidemic with plateau scenarios taken from locations that have reached this stage. Finally, the logistic curve found is corrected by the subnotification factor and sampled to project the future demand for ICU beds.
    
[^44]: 通过运行时本地鲁棒性验证进行神经网络的输入验证

    Input Validation for Neural Networks via Runtime Local Robustness Verification

    [https://arxiv.org/abs/2002.03339](https://arxiv.org/abs/2002.03339)

    本文提出了通过运行时本地鲁棒性验证来验证神经网络输入的方法。实验证明，这种方法可以保护神经网络免受对抗性样本的影响，并提高准确性。

    

    本地鲁棒性验证可以验证神经网络对特定输入的扰动在一定距离内的鲁棒性。我们将这个距离称为鲁棒性半径。我们观察到，正确分类的输入的鲁棒性半径要比错误分类的输入（包括对抗性样本，特别是来自强对抗性攻击的样本）要大得多。另一个观察是，正确分类的输入的鲁棒性半径通常符合正态分布。基于这两个观察，我们提出通过运行时本地鲁棒性验证来验证神经网络的输入。实验证明，我们的方法可以保护神经网络免受对抗性样本的影响，并提高其准确性。

    Local robustness verification can verify that a neural network is robust wrt. any perturbation to a specific input within a certain distance. We call this distance Robustness Radius. We observe that the robustness radii of correctly classified inputs are much larger than that of misclassified inputs which include adversarial examples, especially those from strong adversarial attacks. Another observation is that the robustness radii of correctly classified inputs often follow a normal distribution. Based on these two observations, we propose to validate inputs for neural networks via runtime local robustness verification. Experiments show that our approach can protect neural networks from adversarial examples and improve their accuracies.
    
[^45]: 利用张量核减少深度聚类中的目标函数不匹配

    Leveraging tensor kernels to reduce objective function mismatch in deep clustering

    [https://arxiv.org/abs/2001.07026](https://arxiv.org/abs/2001.07026)

    本文研究了深度聚类中的目标函数不匹配（OFM）问题，并发现基于自编码器的方法容易导致降低聚类性能和重构与聚类目标之间的不匹配。为了解决这个问题，我们提出了一种新的辅助目标方法，称为无监督伴随对象（UCO），通过核函数在网络的中间表示上制定聚类目标。

    

    目标函数不匹配（OFM）指的是一个目标的优化对另一个目标的优化产生负面影响。在本研究中，我们研究了深度聚类中的OFM，并发现流行的基于自编码器的深度聚类方法既会降低聚类性能，又会导致重构目标和聚类目标之间存在显著的OFM。为了减少不匹配，同时保持辅助目标的结构保持特性，我们提出了一组新的用于深度聚类的辅助目标，称为无监督伴随对象（UCO）。UCOs依赖于核函数，在网络的中间表示上制定聚类目标。一般而言，中间表示可以包括除特征维度之外的其他维度，例如空间或时间。因此，我们认为简单地将其向量化并应用向量核对此类问题并不理想。

    Objective Function Mismatch (OFM) occurs when the optimization of one objective has a negative impact on the optimization of another objective. In this work we study OFM in deep clustering, and find that the popular autoencoder-based approach to deep clustering can lead to both reduced clustering performance, and a significant amount of OFM between the reconstruction and clustering objectives. To reduce the mismatch, while maintaining the structure-preserving property of an auxiliary objective, we propose a set of new auxiliary objectives for deep clustering, referred to as the Unsupervised Companion Objectives (UCOs). The UCOs rely on a kernel function to formulate a clustering objective on intermediate representations in the network. Generally, intermediate representations can include other dimensions, for instance spatial or temporal, in addition to the feature dimension. We therefore argue that the na\"ive approach of vectorizing and applying a vector kernel is suboptimal for such 
    
[^46]: 自我对弱语言模型进行细调可以将其转化为强语言模型

    Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. (arXiv:2401.01335v1 [cs.LG])

    [http://arxiv.org/abs/2401.01335](http://arxiv.org/abs/2401.01335)

    本文提出了一种名为自我对弱语言模型进行细调（SPIN）的方法，通过模型自我对弈生成训练数据，并从中优化模型策略，从而将弱语言模型转化为强语言模型，无需额外的人类标注数据。

    

    通过监督细调（SFT）利用人类标注数据的力量对于推进大型语言模型（LLMs）至关重要。本文探讨了在不需要获取额外人类标注数据的情况下，将弱语言模型发展成为强语言模型的可能性。我们提出了一种名为自我对弱语言模型进行细调（SPIN）的新的细调方法，该方法从一个经过监督细调的模型开始。SPIN的核心是自我对弱语言模型的机制，其中弱语言模型通过与自身的实例对弈来提升自己的能力。具体而言，弱语言模型通过生成自己的训练数据来优化自身策略，通过区分自我生成的回应与来自人类标注数据的回应来改进。我们的方法逐步将弱语言模型提升为强大的模型，充分发掘人类标注示范数据在SFT中的潜力。在理论上，我们证明了该方法的训练目标函数的全局最优解是可以达到的。

    Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achiev
    
[^47]: Local Discovery by Partitioning: 在有限先验知识下的多项式时间因果发现方法

    Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around Exposure-Outcome Pairs. (arXiv:2310.17816v1 [stat.ML])

    [http://arxiv.org/abs/2310.17816](http://arxiv.org/abs/2310.17816)

    在有限先验知识下，通过局部分区发现算法（LDP），该研究解决了自动变量选择的问题。LDP根据与曝光-结果对{X,Y}相关的子集将变量集合Z进行分区，并区分混淆因素和其他变量类型。该算法具有理论保证，并在实践中观察到次二次的运行时间。

    

    该研究解决了在有限先验知识下自动变量选择的问题。给定一个{X,Y}的曝光-结果对和一个未知因果结构的变量集合Z，局部分区发现（LDP）算法将Z划分成与{X,Y}相关的子集。我们列举了任意Z的8个穷举且互不重复的分区，并利用这个分类法区分混淆因素和其他变量类型。LDP的动机是有效的调整集识别，但避免了自动变量选择方法中常见的预处理假设。我们提供了理论保证，LDP对于满足足够图形条件的任何Z都返回一个有效的调整集。在更强的条件下，我们证明了分区标签的渐近正确性。总独立性测试在|Z|的最坏情况下是二次的，经验上观察到次二次的运行时间。我们在合成数据上对理论保证进行了数值验证。

    This work addresses the problem of automated covariate selection under limited prior knowledge. Given an exposure-outcome pair {X,Y} and a variable set Z of unknown causal structure, the Local Discovery by Partitioning (LDP) algorithm partitions Z into subsets defined by their relation to {X,Y}. We enumerate eight exhaustive and mutually exclusive partitions of any arbitrary Z and leverage this taxonomy to differentiate confounders from other variable types. LDP is motivated by valid adjustment set identification, but avoids the pretreatment assumption commonly made by automated covariate selection methods. We provide theoretical guarantees that LDP returns a valid adjustment set for any Z that meets sufficient graphical conditions. Under stronger conditions, we prove that partition labels are asymptotically correct. Total independence tests is worst-case quadratic in |Z|, with sub-quadratic runtimes observed empirically. We numerically validate our theoretical guarantees on synthetic 
    
[^48]: DNA编码库的组合深度概率模型

    Compositional Deep Probabilistic Models of DNA Encoded Libraries. (arXiv:2310.13769v1 [q-bio.QM])

    [http://arxiv.org/abs/2310.13769](http://arxiv.org/abs/2310.13769)

    本研究提出了一种组合深度概率模型DEL-Compose，用于对DNA编码库的数据进行建模和分析，以发现潜在的结构和信息，并通过改进观察模型来更好地处理数据噪声。

    

    DNA编码库（DEL）已被证明是一种利用组合构建的小分子进行高效筛选的强大工具。这些选择实验涉及多个阶段的洗涤、洗脱，并通过唯一的DNA条形码鉴定出强效结合物质，往往产生复杂的数据。这种复杂性可能掩盖了潜在的信号，因此需要应用机器学习等计算工具来发现有价值的见解。我们引入了一个DEL数据的组合深度概率模型DEL-Compose，它将分子表示分解为它们的单合子、二合子和三合子构建块，并通过模拟嵌入合成物之间的潜在反应来利用这些分子的内在分层结构。此外，我们还研究了改进DEL计数数据的观察模型的方法，如整合协变因子以更有效地解释数据噪声。

    DNA-Encoded Library (DEL) has proven to be a powerful tool that utilizes combinatorially constructed small molecules to facilitate highly-efficient screening assays. These selection experiments, involving multiple stages of washing, elution, and identification of potent binders via unique DNA barcodes, often generate complex data. This complexity can potentially mask the underlying signals, necessitating the application of computational tools such as machine learning to uncover valuable insights. We introduce a compositional deep probabilistic model of DEL data, DEL-Compose, which decomposes molecular representations into their mono-synthon, di-synthon, and tri-synthon building blocks and capitalizes on the inherent hierarchical structure of these molecules by modeling latent reactions between embedded synthons. Additionally, we investigate methods to improve the observation models for DEL count data such as integrating covariate factors to more effectively account for data noise. Acro
    
[^49]: 平均奖励马尔可夫决策过程的最优样本复杂度

    Optimal Sample Complexity for Average Reward Markov Decision Processes. (arXiv:2310.08833v1 [cs.LG])

    [http://arxiv.org/abs/2310.08833](http://arxiv.org/abs/2310.08833)

    本论文解决了对于均匀收敛的马尔可夫决策过程的长期平均奖励最大化策略学习的样本复杂度问题，并建立了一个样本复杂度为$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$的优化策略估计器。

    

    我们在假设有一个生成模型的情况下，解决了与均匀收敛的马尔可夫决策过程相关的长期平均奖励的策略学习的样本复杂性问题。在这个背景下，现有的文献提供了一个样本复杂度的上界，$ \widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$，和一个下界，$\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$。在这些表达式中，$|S|$和$|A|$分别表示状态空间和动作空间的势，$t_{\text{mix}}$作为总变异混合时间的统一上限，$\epsilon$表示误差容忍度。因此，$t_{\text{mix}}$仍然存在一个显着的差距需要填补。我们的主要贡献是建立一个优化策略的估计器，其样本复杂度为$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$，有效地达到了文献中的下界。这是通过结合算法思想实现的。

    We settle the sample complexity of policy learning for the maximization of the long run average reward associated with a uniformly ergodic Markov decision process (MDP), assuming a generative model. In this context, the existing literature provides a sample complexity upper bound of $\widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$ and a lower bound of $\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$. In these expressions, $|S|$ and $|A|$ denote the cardinalities of the state and action spaces respectively, $t_{\text{mix}}$ serves as a uniform upper limit for the total variation mixing times, and $\epsilon$ signifies the error tolerance. Therefore, a notable gap of $t_{\text{mix}}$ still remains to be bridged. Our primary contribution is to establish an estimator for the optimal policy of average reward MDPs with a sample complexity of $\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$, effectively reaching the lower bound in the literature. This is achieved by combining algorithmic idea
    
[^50]: 具有平均光滑度的高效无偏学习

    Efficient Agnostic Learning with Average Smoothness. (arXiv:2309.17016v1 [cs.LG])

    [http://arxiv.org/abs/2309.17016](http://arxiv.org/abs/2309.17016)

    该论文研究了基于平均光滑度的无参回归问题，提出了无分布限制下的统一收敛界限和高效无偏学习算法。

    

    我们研究了在非参数回归中无分布限制的平均光滑度概念，该概念由Ashlagi等人（2021）提出，用于衡量函数相对于任意未知潜在分布的"有效"光滑度。最近的Hanneke等人（2023）的研究在可实现情况下建立了平均光滑函数的紧密一致收敛界限，并提供了具有高效可实现性的学习算法，但这些结果目前在普遍无偏（即有噪声）情况下尚缺乏类似结果。在这项工作中，我们完全填补了这些差距。首先，我们为无偏设置中的平均光滑类提供了一个无分布一致收敛界限。其次，我们将所得到的样本复杂度与一个具有高效无偏学习算法相匹配。我们的结果以数据的内在几何形状为基础，适用于任何全有界度量空间，并展示了最近在可实现情况下获得的保证。

    We study distribution-free nonparametric regression following a notion of average smoothness initiated by Ashlagi et al. (2021), which measures the "effective" smoothness of a function with respect to an arbitrary unknown underlying distribution. While the recent work of Hanneke et al. (2023) established tight uniform convergence bounds for average-smooth functions in the realizable case and provided a computationally efficient realizable learning algorithm, both of these results currently lack analogs in the general agnostic (i.e. noisy) case.  In this work, we fully close these gaps. First, we provide a distribution-free uniform convergence bound for average-smoothness classes in the agnostic setting. Second, we match the derived sample complexity with a computationally efficient agnostic learning algorithm. Our results, which are stated in terms of the intrinsic geometry of the data and hold over any totally bounded metric space, show that the guarantees recently obtained for realiz
    
[^51]: 大尺度和无穷宽度下的深度学习勒让演讲

    Les Houches Lectures on Deep Learning at Large & Infinite Width. (arXiv:2309.01592v1 [stat.ML])

    [http://arxiv.org/abs/2309.01592](http://arxiv.org/abs/2309.01592)

    本论文主要以无穷宽度和大宽度范围内的深度神经网络为研究对象，讨论了这些网络的各种统计和动力学特性，包括随机网络的性质、训练后的网络与线性模型、核函数和高斯过程之间的关系，以及对大但有限宽度网络在初始化和训练后的摄动和非摄动处理。

    

    这些演讲是在2022年勒让夏季学校统计物理和机器学习课程上展示的，着重探讨了深度神经网络在无限宽度和大宽度范围内的情况。涵盖的主题包括这些网络的各种统计和动力学特性。特别是，讲师们讨论了随机深度神经网络的特性；训练过的深度神经网络，线性模型，核函数和高斯过程之间的联系，这些联系在无穷宽度的极限下出现；以及在初始化和训练后对大但有限宽度网络的摄动和非摄动处理。

    These lectures, presented at the 2022 Les Houches Summer School on Statistical Physics and Machine Learning, focus on the infinite-width limit and large-width regime of deep neural networks. Topics covered include various statistical and dynamical properties of these networks. In particular, the lecturers discuss properties of random deep neural networks; connections between trained deep neural networks, linear models, kernels, and Gaussian processes that arise in the infinite-width limit; and perturbative and non-perturbative treatments of large but finite-width networks, at initialization and after training.
    
[^52]: 分期变分推断：何时以及为什么使用？

    Amortized Variational Inference: When and Why?. (arXiv:2307.11018v1 [stat.ML])

    [http://arxiv.org/abs/2307.11018](http://arxiv.org/abs/2307.11018)

    本文研究了分期变分推断作为近似后验推断的一种通用替代方法，探讨了何时能够达到与传统的因子化变分推断相同的最优解。

    

    分期变分推断（A-VI）是一种近似处理概率模型中的难以计算的后验分布的方法。A-VI的定义特点是学习一个全局推断函数，将每个观察映射到其局部潜变量的近似后验分布。这与更传统的分解（或均场）变分推断（F-VI）形成对比，后者直接学习每个潜变量的近似分布的参数。在深度生成模型中，A-VI用作加速局部潜变量推断的计算技巧。本文研究A-VI作为近似后验推断的一种通用替代方法。由于分期家族是分解家族的子集，A-VI无法产生比F-VI最优解更低的Kullback-Leibler散度的近似值。因此，一个核心的理论问题是刻画A-VI何时仍然达到F-VI的最优解。

    Amortized variational inference (A-VI) is a method for approximating the intractable posterior distributions that arise in probabilistic models. The defining feature of A-VI is that it learns a global inference function that maps each observation to its local latent variable's approximate posterior. This stands in contrast to the more classical factorized (or mean-field) variational inference (F-VI), which directly learns the parameters of the approximating distribution for each latent variable. In deep generative models, A-VI is used as a computational trick to speed up inference for local latent variables. In this paper, we study A-VI as a general alternative to F-VI for approximate posterior inference. A-VI cannot produce an approximation with a lower Kullback-Leibler divergence than F-VI's optimal solution, because the amortized family is a subset of the factorized family. Thus a central theoretical problem is to characterize when A-VI still attains F-VI's optimal solution. We deri
    
[^53]: 利用欧几里得距离函数解释和改进扩散模型

    Interpreting and Improving Diffusion Models Using the Euclidean Distance Function. (arXiv:2306.04848v1 [cs.LG])

    [http://arxiv.org/abs/2306.04848](http://arxiv.org/abs/2306.04848)

    本文利用欧几里得距离函数解释去噪扩散模型，并提出了一种新的采样器。采样器表现出了最先进的FID得分，并能够生成高质量的样本。

    

    去噪直觉上与投影有关。事实上，在流形假设下，添加随机噪声近似等价于正交扰动。因此，学习去噪近似于学习投影。本文利用这一观察结果，将去噪扩散模型解释为应用于欧几里得距离函数的近似梯度下降。随后，我们基于对去噪器投影误差的简单假设，提供DDIM（Denoising Diffusion Implicit Models）采样器的简单收敛分析。最后，我们基于理论结果的洞见提出一种基于对DDIM的两个简单修改的新采样器。仅需要5-10个函数评估，我们的采样器就能在预训练的CIFAR-10和CelebA模型上达到最先进的FID得分，并且可以在潜在扩散模型上生成高质量的样本。

    Denoising is intuitively related to projection. Indeed, under the manifold hypothesis, adding random noise is approximately equivalent to orthogonal perturbation. Hence, learning to denoise is approximately learning to project. In this paper, we use this observation to reinterpret denoising diffusion models as approximate gradient descent applied to the Euclidean distance function. We then provide straight-forward convergence analysis of the DDIM sampler under simple assumptions on the projection-error of the denoiser. Finally, we propose a new sampler based on two simple modifications to DDIM using insights from our theoretical results. In as few as 5-10 function evaluations, our sampler achieves state-of-the-art FID scores on pretrained CIFAR-10 and CelebA models and can generate high quality samples on latent diffusion models.
    
[^54]: 过度压缩如何影响GNN的能力？

    How does over-squashing affect the power of GNNs?. (arXiv:2306.03589v1 [cs.LG])

    [http://arxiv.org/abs/2306.03589](http://arxiv.org/abs/2306.03589)

    本文通过测量节点之间成对交互的水平，提供了严格的分析，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。结果表明，为了保证节点对之间的充分通信，MPNN的容量必须是...

    

    图神经网络（GNN）是处理图结构数据的机器学习的最先进模型。最流行的GNN类别是通过相邻节点间的信息交换来操作的，称为消息传递神经网络（MPNN）。鉴于它们的广泛应用，了解MPNN的表达能力是一个关键问题。然而，现有结果通常考虑具有无信息节点特征的环境。在本文中，我们提供了一种严格的分析方法，以确定具有一定容量的MPNN可以学习哪些节点特征的函数类别。我们通过测量MPNN允许的节点之间的成对交互水平来实现此目的。该测量提供了一种新的量化特性，即所谓的过度压缩效应，该效应被观察到是当大量的信息聚合成固定大小的向量时发生的。使用我们的测量，我们证明，为了保证节点对之间的充分通信，MPNN的容量必须是...

    Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). Given their widespread use, understanding the expressive power of MPNNs is a key question. However, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of pairwise interactions between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be l
    
[^55]: 稳定性惩罚自适应跟随正则化领袖：稀疏性、游戏依赖性和最佳世界的并存

    Stability-penalty-adaptive Follow-the-regularized-leader: Sparsity, Game-dependency, and Best-of-both-worlds. (arXiv:2305.17301v1 [cs.LG])

    [http://arxiv.org/abs/2305.17301](http://arxiv.org/abs/2305.17301)

    本文开发了一种稳定性惩罚自适应（SPA）学习率，该学习率使FTRL具有稀疏性、游戏依赖性和最佳世界（BOBW）三种适应性类型，其中SPA-sparse算法可适应于未知的稀疏级别，SPA-game-dependency算法可根据所玩的游戏自适应地改变其行为，BOBW算法则是既具有稀疏性又具有游戏依赖性的适应性算法。

    

    在顺序决策问题中，适应问题的困难程度是扩展算法适用性的关键属性。跟随正则化领袖近年来成为获取淘汰法中各种类型适应性的最有前途的方法之一。为了进一步推广这种适应性，我们为FTRL开发了一个通用的自适应学习率，称为稳定性惩罚自适应（SPA）学习率。该学习率产生的遗憾界共同取决于算法的稳定性和惩罚，其中FTRL的遗憾通常被分解。凭借这个结果，我们建立了几个具有三种适应性类型的算法：稀疏性、游戏依赖性和最佳世界（BOBW）。稀疏性经常出现在真实世界的问题中，但是，现有的稀疏多臂赌博算法$k$-arms假定事先已知稀疏级别$s \leq k$，而这在真实世界的情况下通常不是情况。为了适应未知的稀疏级别，我们提出了一种新算法SPA-sparse，该算法显示比现有稀疏算法的性能提高了。游戏依赖性是另一种适应性类型，当用于生成数据的游戏发生变化时，即必需的。我们提出了一种新算法SPA-game-dependency，该算法根据所玩的游戏自适应地改变其行为，并表明它比非自适应算法的性能更好。最后，我们提出了一个既具有稀疏性又具有游戏依赖性适应性的BOBW算法，并显示它比仅集中于一种适应性类型的算法表现更好。

    Adaptivity to the difficulties of a problem is a key property in sequential decision-making problems to broaden the applicability of algorithms. Follow-the-Regularized-Leader (FTRL) has recently emerged as one of the most promising approaches for obtaining various types of adaptivity in bandit problems. Aiming to further generalize this adaptivity, we develop a generic adaptive learning rate, called Stability-Penalty-Adaptive (SPA) learning rate for FTRL. This learning rate yields a regret bound jointly depending on stability and penalty of the algorithm, into which the regret of FTRL is typically decomposed. With this result, we establish several algorithms with three types of adaptivity: sparsity, game-dependency, and Best-of-Both-Worlds (BOBW). Sparsity frequently appears in real-world problems. However, existing sparse multi-armed bandit algorithms with $k$-arms assume that the sparsity level $s \leq k$ is known in advance, which is often not the case in real-world scenarios. To ad
    
[^56]: 基于代价感知的情境变量在贝叶斯优化中的学习

    Cost-aware learning of relevant contextual variables within Bayesian optimization. (arXiv:2305.14120v1 [cs.LG])

    [http://arxiv.org/abs/2305.14120](http://arxiv.org/abs/2305.14120)

    本文提出一种基于代价感知的模型选择BO方法SADCBO，通过对后验代理模型的敏感性分析来学习关于环境的相关情境信息，并通过平均模型预测来最小化优化代价，在实验中表现出卓越的性能。

    

    情境贝叶斯优化(CBO)是一种强大的框架，可针对设计变量优化黑盒昂贵的评估函数，并同时有效地整合关于环境的相关情境信息，如实验条件。然而，在许多实际场景中，情境变量的相关性不一定是预先已知的。此外，有时还可以最优化情境变量本身，这是当前CBO算法未考虑的设置。优化情境变量可能是昂贵的，这引出了确定一个最小相关子集的问题。在本文中，我们将这个问题作为一个代价感知的模型选择BO任务来构架，采用一种新方法，即基于敏感性分析的情境BO (SADCBO) 来解决这个问题。我们通过对特定输入点后验代理模型的敏感性分析来学习情境变量的相关性，同时通过平均模型预测来最小化优化的代价。SADCBO在多个合成和真实基准问题上进行了实证评估，显示出优于现有算法的性能。

    Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions with respect to design variables, while simultaneously efficiently integrating relevant contextual information regarding the environment, such as experimental conditions. However, in many practical scenarios, the relevance of contextual variables is not necessarily known beforehand. Moreover, the contextual variables can sometimes be optimized themselves, a setting that current CBO algorithms do not take into account. Optimizing contextual variables may be costly, which raises the question of determining a minimal relevant subset. In this paper, we frame this problem as a cost-aware model selection BO task and address it using a novel method, Sensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of context variables by sensitivity analysis of the posterior surrogate model at specific input points, whilst minimizing the cost of optimization by lev
    
[^57]: 使用主动学习方法的相关聚类

    Correlation Clustering with Active Learning of Pairwise Similarities. (arXiv:2302.10295v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10295](http://arxiv.org/abs/2302.10295)

    本文研究了相关聚类中成对相似性不事先给出的情况，并开发了一个通用的主动学习框架，适应各种相关聚类算法和查询策略，同时具有适应性灵活、噪声鲁棒性等优势。

    

    相关聚类是一个众所周知的无监督学习设置，处理正负相似性对。在本文中，我们研究了一种情况，即成对相似性不事先给出，必须以高效的方式查询。为此，我们开发了一个通用的主动学习框架，针对这个任务具有多种优势，例如，用户/注释者可以提供各种反馈类型、适应任何相关聚类算法和查询策略以及对噪声具有鲁棒性。此外，我们还提出和分析了一些适合这种设置的新的查询策略。通过几个实验研究，我们展示了我们框架和所提出的查询策略的有效性。

    Correlation clustering is a well-known unsupervised learning setting that deals with positive and negative pairwise similarities. In this paper, we study the case where the pairwise similarities are not given in advance and must be queried in a cost-efficient way. Thereby, we develop a generic active learning framework for this task that benefits from several advantages, e.g., flexibility in the type of feedback that a user/annotator can provide, adaptation to any correlation clustering algorithm and query strategy, and robustness to noise. In addition, we propose and analyze a number of novel query strategies suited to this setting. We demonstrate the effectiveness of our framework and the proposed query strategies via several experimental studies.
    

