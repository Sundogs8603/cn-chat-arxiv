# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator.](http://arxiv.org/abs/2308.03730) | 提出了一种名为SurvBeX的机器学习生存模型解释方法，通过使用改进的Beran估计器作为替代解释模型，来解释机器学习生存黑盒模型的预测。实验结果表明SurvBeX的效果。 |
| [^2] | [Linear Convergence Bounds for Diffusion Models via Stochastic Localization.](http://arxiv.org/abs/2308.03686) | 通过随机定位方法，我们提供了一种解决扩散模型中线性收敛界限问题的方法，并证明了这种方法可以在有限二阶矩条件下达到可接受的精度。 |
| [^3] | [Diffusion Model in Causal Inference with Unmeasured Confounders.](http://arxiv.org/abs/2308.03669) | 本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。 |
| [^4] | [Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness.](http://arxiv.org/abs/2308.03666) | 该论文探索了一种神经方法，用于解决当前人工智能系统存在的可信度问题，包括预测结果解释不足、学习模型泛化性不足和不适应不确定环境的问题，以提高可信度网络的设计级可解释性和泛化性能。 |
| [^5] | [Generalized Early Stopping in Evolutionary Direct Policy Search.](http://arxiv.org/abs/2308.03574) | 本文提出了一种适用于直接策略搜索的早停止方法，通过观察每个时间步骤的目标值来决定是否停止评估，而无需问题特定的知识。在测试中，该方法在游戏、机器人和经典控制领域中表现出节省计算时间的优势。 |
| [^6] | [Partial identification of kernel based two sample tests with mismeasured data.](http://arxiv.org/abs/2308.03570) | 这项研究提出了一种基于核的两样本测试方法，考虑了样本数据中的误差问题，并通过部分标识方法给出了MMD的尖锐上下界估计。该方法在样本大小增加时收敛速度更快，并在实证验证中得到了验证。 |
| [^7] | [Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces.](http://arxiv.org/abs/2308.03443) | 本文提出了一种用于具有大动作空间的离策略评估的双重稳健估计器（MDR）。与现有的基准估计器相比，MDR能够在减小方差的同时保持无偏性，从而提高了估计的准确性。实验结果证实了MDR相对于现有估计器的优越性。 |
| [^8] | [Variable importance for causal forests: breaking down the heterogeneity of treatment effects.](http://arxiv.org/abs/2308.03369) | 本文提出了一种新的因果森林变量重要性算法，用于量化每个输入对处理效果异质性的影响，解决了因果随机森林的黑匣子性质带来的实际限制，同时解决了没有混杂变量和有混杂变量的情况。 |
| [^9] | [Studying Large Language Model Generalization with Influence Functions.](http://arxiv.org/abs/2308.03296) | 通过使用特征值修正的Kronecker-Factored Approximate Curvature (EK-FAC) 近似方法，这篇论文研究了如何使用影响函数来研究大型语言模型的泛化能力。实验证明，EK-FAC能够在计算速度更快的情况下，实现与传统影响函数估计器相似的准确性。 |
| [^10] | [The Effect of SGD Batch Size on Autoencoder Learning: Sparsity, Sharpness, and Feature Learning.](http://arxiv.org/abs/2308.03215) | 研究发现在非凸问题中，SGD使用不同的批量大小能找到不同类型的全局最小值，批量大小较大时解决方案较密集且与初始化方向高度一致，批量大小较小时解决方案较稀疏且几乎与初始化正交。此外，使用较小批量大小找到的最小值较锐利。 |
| [^11] | [Detection of Anomalies in Multivariate Time Series Using Ensemble Techniques.](http://arxiv.org/abs/2308.03171) | 该论文提出了一种使用集成技术检测多元时间序列中的异常的方法。通过使用特征装袋技术和基于PCA的嵌套旋转转换，该方法提高了基本模型的性能和泛化能力。 |
| [^12] | [Self-Directed Linear Classification.](http://arxiv.org/abs/2308.03142) | 这项研究首次在自主线性分类任务中研究了选择预测顺序的能力，并提出了两个主要结果，针对不同类型的数据集，设计了高效的自主学习器，最少只产生$O(d \log \log(n))$个错误。 |
| [^13] | [Iterative Magnitude Pruning as a Renormalisation Group: A Study in The Context of The Lottery Ticket Hypothesis.](http://arxiv.org/abs/2308.03128) | 本论文研究了深度神经网络中彩票假设的概念，通过迭代幅度修剪逐步优化模型，并探索了中彩票的普遍性。同时，本论文还提出了IMP与RG理论的联系，促进对IMP的更深入理解。 |
| [^14] | [Visualization of Extremely Sparse Contingency Table by Taxicab Correspondence Analysis: A Case Study of Textual Data.](http://arxiv.org/abs/2308.03079) | 出租车对应分析是一种可视化非常稀疏的列联表的方法，我们在一个涉及文本数据的案例研究中进行了应用，研究了Sah和Fokou\'e（2019）引入的8本圣书片段，并使用多种维度约减方法进行了详细研究。 |
| [^15] | [Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory.](http://arxiv.org/abs/2308.02966) | 本文提出了一种广义过采样算法GOLIATH，基于核密度估计，可用于不平衡分类和回归任务。同时提供了这些机器学习算法的显式形式和条件密度表达式，为SMOTE等新的合成数据生成器提供了理论依据。 |
| [^16] | [Structured Low-Rank Tensors for Generalized Linear Models.](http://arxiv.org/abs/2308.02922) | 结构化低秩张量在广义线性模型中的应用能够更可靠地估计参数和降低样本复杂性。 |
| [^17] | [Spectral Ranking Inferences based on General Multiway Comparisons.](http://arxiv.org/abs/2308.02918) | 本文研究了使用光谱方法在广义多维比较中估计和量化未观察到的比较实体的偏好分数的性能，并揭示了光谱估计量与最大似然估计量之间的关系。 |
| [^18] | [Physics-informed Gaussian process model for Euler-Bernoulli beam elements.](http://arxiv.org/abs/2308.02894) | 该论文介绍了一种基于物理信息的高斯过程模型，通过欧拉-伯努利梁方程建模，并应用于结构的弯曲刚度回归、响应插值和概率推断。该模型在悬臂梁上进行了实际应用，并用于结构健康监测。实验结果验证了该框架的有效性。 |
| [^19] | [Approximating Positive Homogeneous Functions with Scale Invariant Neural Networks.](http://arxiv.org/abs/2308.02836) | 本文研究使用尺度不变神经网络近似解决线性反问题的可行性，证明了单隐藏层ReLU网络无法恢复稀疏向量，但通过两个隐藏层可以稳定且精确地恢复任意稀疏程度的向量，此外还推广到了其他恢复问题。 |
| [^20] | [Scalable Computation of Causal Bounds.](http://arxiv.org/abs/2308.02709) | 本论文研究了在存在未观测混淆变量和离散值观测变量的因果图上计算因果查询的界限的问题，并提出了修剪方法来显著减少计算负担，使得可以计算更大规模的因果推断问题的界限，在特殊问题情况下可以以闭合形式计算界限，并将方法扩展到分数线性规划进行计算 |
| [^21] | [FPR Estimation for Fraud Detection in the Presence of Class-Conditional Label Noise.](http://arxiv.org/abs/2308.02695) | 该论文提出了在存在标签噪音的情况下，估计二分类模型的FPR以及TPR的方法，这对于欺诈检测中的准确性至关重要。作者发现，现有的方法虽然减小了总误差，却不能保证模型对FPR和TPR的估计准确，因此提出了一种使清理误差与模型分数解耦的方法。 |
| [^22] | [An Intrinsic Approach to Scalar-Curvature Estimation for Point Clouds.](http://arxiv.org/abs/2308.02615) | 我们提出了一种内在的方法来估计点云的标量曲率，该方法仅依赖于数据的度量结构，而不依赖于其在n维实数空间中的嵌入。我们通过理论分析和实验证明了该方法的一致性和稳定性。 |
| [^23] | [Intensity-free Integral-based Learning of Marked Temporal Point Processes.](http://arxiv.org/abs/2308.02360) | 该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。 |
| [^24] | [LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs.](http://arxiv.org/abs/2308.01157) | LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。 |
| [^25] | [Tackling the Curse of Dimensionality with Physics-Informed Neural Networks.](http://arxiv.org/abs/2307.12306) | 本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。 |
| [^26] | [Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression.](http://arxiv.org/abs/2306.08432) | 本文研究了将数据分成批次的学习算法，在高维超参数线性回归模型中提供了隐式正则化，通过适当的批量大小选择，稳定了风险行为，消除了插值点处的膨胀和双峰现象 |
| [^27] | [Symmetry & Critical Points for Symmetric Tensor Decompositions Problems.](http://arxiv.org/abs/2306.07886) | 本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。 |
| [^28] | [Estimate-Then-Optimize Versus Integrated-Estimation-Optimization: A Stochastic Dominance Perspective.](http://arxiv.org/abs/2304.06833) | 本文提出，当模型类足够丰富以涵盖真实情况时，非线性问题的“先估计再优化”方法优于集成方法，包括优化间隙的渐进优势的均值，所有其他时刻和整个渐进分布。 |
| [^29] | [Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling.](http://arxiv.org/abs/2304.05365) | 本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。 |
| [^30] | [Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model.](http://arxiv.org/abs/2303.08613) | 本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。 |
| [^31] | [Expectation consistency for calibration of neural networks.](http://arxiv.org/abs/2303.02644) | 本文介绍了一种名为期望一致性（EC）的新型校准技术，该方法通过对最后一层权重进行后训练重新缩放，使平均验证置信度与平均正确标签比例相一致，在不同神经网络架构和数据集上实现了类似温度缩放（TS）的校准性能。 |
| [^32] | [On the Within-Group Fairness of Screening Classifiers.](http://arxiv.org/abs/2302.00025) | 本文探讨了筛选分类器的组内公平性问题，指出使用校准的分类器可能存在对感兴趣的人口群体内的合格成员存在不公平对待的问题，并提出了一种基于动态规划的高效后处理算法来最小化修改分类器，以实现组内公平性。 |
| [^33] | [Sliced Optimal Partial Transport.](http://arxiv.org/abs/2212.08049) | 本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。 |
| [^34] | [Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio.](http://arxiv.org/abs/2209.04512) | 本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的方法不仅适用于金融市场典型的低信噪比环境，还与弱因子兼容，并且通过理论分析建立了统一的界限，同时提供了基于数据的一致误差协方差估计方法。模拟和实证结果显示我们的模型具有卓越的准确性。 |
| [^35] | [Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection.](http://arxiv.org/abs/2207.11208) | 本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。在高斯推理模型中，我们发现，低秩推断模型在固定计算预算下产生了更高的统计近似误差，但较低的计算误差。 |
| [^36] | [Transfer Learning with Deep Tabular Models.](http://arxiv.org/abs/2206.15306) | 深度表格模型的迁移学习在医学诊断等领域展现出了比传统方法更优异的性能，并且提出了应对上下游特征集不同情况的解决方法。 |
| [^37] | [Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees.](http://arxiv.org/abs/2206.02659) | 本文通过Hessian-based分析，提出一种基于距离的泛化度量方法，用于理解深度神经网络微调的泛化特性。通过PAC-Bayesian分析，给出了基于Hessian距离的微调模型泛化界。此外，还对微调面对标签噪声的问题进行了研究，并提出了一种相关算法和泛化误差保证。 |
| [^38] | [Persistent Homology of Coarse Grained State Space Networks.](http://arxiv.org/abs/2206.02530) | 本研究利用持续同调分析复杂过渡网络，发现粗粒化状态空间网络能够更好地捕捉底层动态系统的丰富信息，提高动态状态检测和噪声鲁棒性。 |
| [^39] | [Variational Inference for Bayesian Bridge Regression.](http://arxiv.org/abs/2205.09515) | 本文研究了自动微分变分推断在具有桥惩罚的回归模型上的应用，该方法通过使用小批量数据并提供全贝叶斯推断结果来加速计算时间。通过在B样条非参数回归模型上进行的模拟研究，验证了该方法的性能。 |
| [^40] | [Kernel Robust Hypothesis Testing.](http://arxiv.org/abs/2203.12777) | 本文使用核方法构造不确定性集，在贝叶斯设置和Neyman-Pearson设置中分别研究了最小化最坏情况下错误概率和控制错误概率的问题，并提出了基于MMD的一系列测试。 |
| [^41] | [KINet: Unsupervised Forward Models for Robotic Pushing Manipulation.](http://arxiv.org/abs/2202.09006) | 本文介绍了一种名为KINet的无监督框架，用于推理对象之间的相互作用。通过学习关键点表示和关系，该模型可以自动推广到不同场景中，并成功预测未来的关键点状态。 |
| [^42] | [Lazy OCO: Online Convex Optimization on a Switching Budget.](http://arxiv.org/abs/2102.03803) | 本研究提出了一种懒惰型在线凸优化的算法，其在切换次数有限的情况下达到了近似最优的遗憾上界，并且在连续设置中呈现出高效的计算性能。 |
| [^43] | [Spike and slab Bayesian sparse principal component analysis.](http://arxiv.org/abs/2102.00305) | 本论文提出了一种采用峰值和板条先验的参数扩展坐标上升变分推断算法，用于解决贝叶斯稀疏主成分分析中的正交性约束问题。通过广泛的数值模拟，证明了该算法在性能上优于其他SPCA方法。 |
| [^44] | [Nonparametric approximation of conditional expectation operators.](http://arxiv.org/abs/2012.12917) | 本文研究了在最小假设下对条件期望算子的统计逼近问题，并通过修改其定义域证明了该算子可以被再现核希尔伯特空间上的希尔伯特-施密特算子任意好地逼近。这为非参数估计提供了一种优于传统参数投影方法的方法，并揭示了非参数估计的极限对象。 |
| [^45] | [Introduction to Online Convex Optimization.](http://arxiv.org/abs/1909.05207) | 本文将优化描述为一个过程，在实际应用中，采用在线学习的优化方法对复杂环境进行优化建模，并取得了引人注目的成就。 |
| [^46] | [Counterfactual Inference for Consumer Choice Across Many Product Categories.](http://arxiv.org/abs/1906.02635) | 本文提出了一种方法用于估计消费者在多个产品类别中的偏好选择。我们利用机器学习的概率模型，考虑了时变产品属性和产品缺货的情况，并展示了我们的模型相较于传统方法的改进之处在于能够准确估计偏好的异质性。 |

# 详细

[^1]: SurvBeX:一种基于Beran估计器的机器学习生存模型解释方法

    SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator. (arXiv:2308.03730v1 [cs.LG])

    [http://arxiv.org/abs/2308.03730](http://arxiv.org/abs/2308.03730)

    提出了一种名为SurvBeX的机器学习生存模型解释方法，通过使用改进的Beran估计器作为替代解释模型，来解释机器学习生存黑盒模型的预测。实验结果表明SurvBeX的效果。

    

    提出了一种名为SurvBeX的解释方法，用于解释机器学习生存黑盒模型的预测。该方法的主要思想是使用改进的Beran估计器作为替代解释模型。合并到Beran估计器中的系数可以被视为特征对黑盒模型预测的影响值。通过在感兴趣的示例周围的局部区域生成许多点，按照著名的LIME方法，为每个生成的示例计算黑盒模型的生存函数，并构建替代模型（Beran估计器）的生存函数，作为解释系数的函数。为了找到解释系数，建议通过最小化生成示例产生的黑盒模型和Beran估计器的生存函数之间的平均距离来实现。许多使用合成和真实生存数据的数值实验证明了SurvBeX的效果。

    An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models. The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model. Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction. Following the well-known LIME method, many points are generated in a local area around an example of interest. For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients. In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples. Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficienc
    
[^2]: 通过随机定位方法获得扩散模型的线性收敛界限

    Linear Convergence Bounds for Diffusion Models via Stochastic Localization. (arXiv:2308.03686v1 [stat.ML])

    [http://arxiv.org/abs/2308.03686](http://arxiv.org/abs/2308.03686)

    通过随机定位方法，我们提供了一种解决扩散模型中线性收敛界限问题的方法，并证明了这种方法可以在有限二阶矩条件下达到可接受的精度。

    

    扩散模型是从高维数据分布中生成近似样本的有效方法。最近的一些研究结果提供了关于这种模型的收敛速度的多项式界限，假设$L^2$准确的得分估计器。然而，到目前为止，已知的最佳界限要么对数据维度是超线性的，要么需要强平滑性假设。我们提供了第一个假设只需要数据分布有有限二阶矩的收敛界限，这些界限对于数据维度是线性的（乘以对数因子）。我们证明了扩散模型最多需要$\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$步，就可以将带有方差为$\delta$的高斯噪声损坏的任意数据分布在Kullback--Leibler散度下近似到$\varepsilon^2$。我们的证明依赖于前人的Girsanov方法。我们引入了对于反向SD离散化误差的精细处理。

    Diffusion models are a powerful method for generating approximate samples from high-dimensional data distributions. Several recent results have provided polynomial bounds on the convergence rate of such models, assuming $L^2$-accurate score estimators. However, up until now the best known such bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to approximate an arbitrary data distribution on $\mathbb{R}^d$ corrupted with Gaussian noise of variance $\delta$ to within $\varepsilon^2$ in Kullback--Leibler divergence. Our proof builds on the Girsanov-based methods of previous works. We introduce a refined treatment of the error arising from the discretization of the reverse SD
    
[^3]: 无法测量混淆因素下因果推断中的扩散模型

    Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])

    [http://arxiv.org/abs/2308.03669](http://arxiv.org/abs/2308.03669)

    本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。

    

    我们研究了如何在无法测量的混淆因素存在的情况下，扩展扩散模型的使用，以从观测数据中回答因果问题。在Pearl的使用有向无环图（DAG）捕捉因果干预的框架中，提出了一种基于扩散模型的因果模型（DCM），可以更准确地回答因果问题，假设所有混淆因素都是可以观察到的。然而，实际中存在无法测量的混淆因素，这使得DCM无法应用。为了缓解DCM的这一局限性，我们提出了一个扩展模型，称为基于反门准则的DCM（BDCM），其思想根植于在DAG中找到要包括在扩散模型解码过程中的变量的反门准则，这样我们可以将DCM扩展到存在无法测量的混淆因素的情况。合成数据实验表明，我们提出的模型在无法测量混淆因素的情况下更精确地捕捉到了反事实分布。

    We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
    
[^4]: 架起可信度与开放世界学习的桥梁：一种探索性神经方法，用于增强可解释性、泛化性和鲁棒性

    Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v1 [stat.ML])

    [http://arxiv.org/abs/2308.03666](http://arxiv.org/abs/2308.03666)

    该论文探索了一种神经方法，用于解决当前人工智能系统存在的可信度问题，包括预测结果解释不足、学习模型泛化性不足和不适应不确定环境的问题，以提高可信度网络的设计级可解释性和泛化性能。

    

    随着研究人员努力缩小机器智能与人类之间的差距，通过发展人工智能技术，我们必须认识到可信度在开放世界中的关键重要性，在日常生活的各个方面对每个人都已经无处不在。然而，目前的人工智能系统存在几个挑战，可能会导致信任危机：1）对预测结果的解释不足；2）学习模型的泛化性不足；3）对不确定环境的适应能力差。因此，我们探索了一种神经程序，用于架起可信度与开放世界学习之间的桥梁，从单模态扩展到多模态场景，以供读者使用。1）为了增强设计级可解释性，我们首先定制了具有特定物理含义的可信网络；2）然后，通过灵活的学习正则化器设计环境福祉任务接口，以改善可信网络的泛化性能。

    As researchers strive to narrow the gap between machine intelligence and human through the development of artificial intelligence technologies, it is imperative that we recognize the critical importance of trustworthiness in open-world, which has become ubiquitous in all aspects of daily life for everyone. However, several challenges may create a crisis of trust in current artificial intelligence systems that need to be bridged: 1) Insufficient explanation of predictive results; 2) Inadequate generalization for learning models; 3) Poor adaptability to uncertain environments. Consequently, we explore a neural program to bridge trustworthiness and open-world learning, extending from single-modal to multi-modal scenarios for readers. 1) To enhance design-level interpretability, we first customize trustworthy networks with specific physical meanings; 2) We then design environmental well-being task-interfaces via flexible learning regularizers for improving the generalization of trustworthy
    
[^5]: 演化直接策略搜索中的广义早停止方法

    Generalized Early Stopping in Evolutionary Direct Policy Search. (arXiv:2308.03574v1 [stat.ML])

    [http://arxiv.org/abs/2308.03574](http://arxiv.org/abs/2308.03574)

    本文提出了一种适用于直接策略搜索的早停止方法，通过观察每个时间步骤的目标值来决定是否停止评估，而无需问题特定的知识。在测试中，该方法在游戏、机器人和经典控制领域中表现出节省计算时间的优势。

    

    在许多优化问题中，尤其是涉及在物理世界中进行评估的直接策略搜索任务中，评估时间通常较长。当在固定时间段内评估解决方案时，往往会明确无法通过增加计算时间来提高目标值（例如，当两轮机器人持续在原地旋转时）。在这种情况下，及早停止评估以节省计算时间是有意义的。然而，大多数评估停止方法都是问题特定的，并且需要专门为当前任务设计。因此，我们提出了一种直接策略搜索的早停止方法。该方法只查看每个时间步骤的目标值，不需要任何问题特定的知识。我们在五个来自游戏、机器人和经典控制领域的直接策略搜索环境中测试了引入的停止准则，并展示了其节省了计算时间的优势。

    Lengthy evaluation times are common in many optimization problems such as direct policy search tasks, especially when they involve conducting evaluations in the physical world, e.g. in robotics applications. Often, when evaluating a solution over a fixed time period, it becomes clear that the objective value will not increase with additional computation time (for example, when a two-wheeled robot continuously spins on the spot). In such cases, it makes sense to stop the evaluation early to save computation time. However, most approaches to stop the evaluation are problem-specific and need to be specifically designed for the task at hand. Therefore, we propose an early stopping method for direct policy search. The proposed method only looks at the objective value at each time step and requires no problem-specific knowledge.  We test the introduced stopping criterion in five direct policy search environments drawn from games, robotics, and classic control domains, and show that it can sa
    
[^6]: 基于核的两样本测试中的部分标识和测量数据

    Partial identification of kernel based two sample tests with mismeasured data. (arXiv:2308.03570v1 [stat.ML])

    [http://arxiv.org/abs/2308.03570](http://arxiv.org/abs/2308.03570)

    这项研究提出了一种基于核的两样本测试方法，考虑了样本数据中的误差问题，并通过部分标识方法给出了MMD的尖锐上下界估计。该方法在样本大小增加时收敛速度更快，并在实证验证中得到了验证。

    

    非参数的两样本测试方法，例如最大均值差异(MMD)，在机器学习应用中经常用于检测两个分布之间的差异。然而，大部分现有文献假设两个感兴趣分布的无误差样本是可用的。我们放松这一假设，研究在ε-污染下估计MMD，其中可能非随机的ε比例一个分布错误地与另一个分布混杂在一起。我们证明，在ε-污染下，MMD的典型估计不可靠。相反，我们研究了MMD的部分标识，并确定了包含真实、未知MMD的尖锐上下界。我们提出了一种估计这些界限的方法，并证明随着样本大小增加，它给出了收敛速度比替代方法更快的对MMD的最尖锐界限的估计。通过三个数据集的实证验证，我们验证了这一方法。

    Nonparametric two-sample tests such as the Maximum Mean Discrepancy (MMD) are often used to detect differences between two distributions in machine learning applications. However, the majority of existing literature assumes that error-free samples from the two distributions of interest are available.We relax this assumption and study the estimation of the MMD under $\epsilon$-contamination, where a possibly non-random $\epsilon$ proportion of one distribution is erroneously grouped with the other. We show that under $\epsilon$-contamination, the typical estimate of the MMD is unreliable. Instead, we study partial identification of the MMD, and characterize sharp upper and lower bounds that contain the true, unknown MMD. We propose a method to estimate these bounds, and show that it gives estimates that converge to the sharpest possible bounds on the MMD as sample size increases, with a convergence rate that is faster than alternative approaches. Using three datasets, we empirically val
    
[^7]: 用于具有大动作空间的离策略评估的双重稳健估计器

    Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v1 [stat.ML])

    [http://arxiv.org/abs/2308.03443](http://arxiv.org/abs/2308.03443)

    本文提出了一种用于具有大动作空间的离策略评估的双重稳健估计器（MDR）。与现有的基准估计器相比，MDR能够在减小方差的同时保持无偏性，从而提高了估计的准确性。实验结果证实了MDR相对于现有估计器的优越性。

    

    本文研究了在具有大动作空间的背景下的离策略评估（OPE）。现有的基准估计器存在严重的偏差和方差折衷问题。参数化方法由于很难确定正确的模型而导致偏差，而重要性加权方法由于方差而产生问题。为了克服这些限制，本文提出了基于判别式的不良行为抑制器（MIPS）来通过对动作的嵌入来减小估计器的方差。为了使估计器更准确，我们提出了MIPS的双重稳健估计器——边际化双重稳健（MDR）估计器。理论分析表明，所提出的估计器在比MIPS更弱的假设下是无偏的，同时保持了对IPS的方差减小，这是MIPS的主要优势。经验实验证实了MDR相对于现有估计器的优越性。

    We study Off-Policy Evaluation (OPE) in contextual bandit settings with large action spaces. The benchmark estimators suffer from severe bias and variance tradeoffs. Parametric approaches suffer from bias due to difficulty specifying the correct model, whereas ones with importance weight suffer from variance. To overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was proposed to mitigate the estimator's variance via embeddings of an action. To make the estimator more accurate, we propose the doubly robust estimator of MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical analysis shows that the proposed estimator is unbiased under weaker assumptions than MIPS while maintaining variance reduction against IPS, which was the main advantage of MIPS. The empirical experiment verifies the supremacy of MDR against existing estimators.
    
[^8]: 变量重要性对因果森林的影响：解析处理效果的异质性

    Variable importance for causal forests: breaking down the heterogeneity of treatment effects. (arXiv:2308.03369v1 [stat.ML])

    [http://arxiv.org/abs/2308.03369](http://arxiv.org/abs/2308.03369)

    本文提出了一种新的因果森林变量重要性算法，用于量化每个输入对处理效果异质性的影响，解决了因果随机森林的黑匣子性质带来的实际限制，同时解决了没有混杂变量和有混杂变量的情况。

    

    因果随机森林提供了处理效果异质性的有效估计。然而，森林算法以其黑匣子性质而闻名，因此无法表征输入变量在处理效果异质性中的参与情况，这是一个很大的实际限制。在本文中，我们开发了一种新的因果森林变量重要性算法，用于量化每个输入对处理效果异质性的影响。所提出的方法受到了用于回归问题的丢弃和重新学习原则的启发。重要的是，我们展示了如何处理没有混杂变量的森林重训练。如果混杂因素不涉及处理效果的异质性，局部居中步骤可以保证重要性度量的一致性。否则，当混杂因素也影响异质性时，我们在重新训练的因果森林中引入一个校正项以恢复一致性。此外，我们进行了对模拟和半合成数据的实验。

    Causal random forests provide efficient estimates of heterogeneous treatment effects. However, forest algorithms are also well-known for their black-box nature, and therefore, do not characterize how input variables are involved in treatment effect heterogeneity, which is a strong practical limitation. In this article, we develop a new importance variable algorithm for causal forests, to quantify the impact of each input on the heterogeneity of treatment effects. The proposed approach is inspired from the drop and relearn principle, widely used for regression problems. Importantly, we show how to handle the forest retrain without a confounding variable. If the confounder is not involved in the treatment effect heterogeneity, the local centering step enforces consistency of the importance measure. Otherwise, when a confounder also impacts heterogeneity, we introduce a corrective term in the retrained causal forest to recover consistency. Additionally, experiments on simulated, semi-synt
    
[^9]: 使用影响函数研究大型语言模型的泛化能力

    Studying Large Language Model Generalization with Influence Functions. (arXiv:2308.03296v1 [cs.LG])

    [http://arxiv.org/abs/2308.03296](http://arxiv.org/abs/2308.03296)

    通过使用特征值修正的Kronecker-Factored Approximate Curvature (EK-FAC) 近似方法，这篇论文研究了如何使用影响函数来研究大型语言模型的泛化能力。实验证明，EK-FAC能够在计算速度更快的情况下，实现与传统影响函数估计器相似的准确性。

    

    在努力提高对机器学习模型的可见性以理解和减轻相关风险时，一个潜在有价值的证据来源是：哪些训练样本最大程度地影响了给定的行为？影响函数旨在回答一个反事实问题：如果将给定的序列添加到训练集中，模型的参数（因此也是模型的输出）将如何改变？尽管影响函数对小型模型产生了洞见，但由于计算逆Hessian-向量乘积（IHVP）的困难，它们很难扩展到大型语言模型（LLMs）。我们使用特征值修正的Kronecker-Factored Approximate Curvature（EK-FAC）近似方法，将影响函数扩展到具有520亿参数的LLMs。在我们的实验中，EK-FAC在IHVP计算速度快了数个数量级的情况下，实现了与传统影响函数估计器相似的准确性。我们研究了两种算法技术来减少成本

    When trying to gain better visibility into a machine learning model in order to understand and mitigate the associated risks, a potentially valuable source of evidence is: which training examples most contribute to a given behavior? Influence functions aim to answer a counterfactual: how would the model's parameters (and hence its outputs) change if a given sequence were added to the training set? While influence functions have produced insights for small models, they are difficult to scale to large language models (LLMs) due to the difficulty of computing an inverse-Hessian-vector product (IHVP). We use the Eigenvalue-corrected Kronecker-Factored Approximate Curvature (EK-FAC) approximation to scale influence functions up to LLMs with up to 52 billion parameters. In our experiments, EK-FAC achieves similar accuracy to traditional influence function estimators despite the IHVP computation being orders of magnitude faster. We investigate two algorithmic techniques to reduce the cost of 
    
[^10]: SGD批量大小对自编码器学习的影响：稀疏性、锐度和特征学习

    The Effect of SGD Batch Size on Autoencoder Learning: Sparsity, Sharpness, and Feature Learning. (arXiv:2308.03215v1 [stat.ML])

    [http://arxiv.org/abs/2308.03215](http://arxiv.org/abs/2308.03215)

    研究发现在非凸问题中，SGD使用不同的批量大小能找到不同类型的全局最小值，批量大小较大时解决方案较密集且与初始化方向高度一致，批量大小较小时解决方案较稀疏且几乎与初始化正交。此外，使用较小批量大小找到的最小值较锐利。

    

    本研究探讨了随机梯度下降（SGD）在训练具有线性或ReLU激活的单神经元自编码器时的动态特性，使用正交数据进行实验。我们发现，在这个非凸问题中，对于任何批量大小选择，随机初始化的SGD使用恒定步长能够成功找到全局最小值。然而，找到的特定全局最小值取决于批量大小。在全批量设置下，我们发现解决方案是密集的（即非稀疏的），并且与其初始化方向高度一致，表明相对较少的特征学习发生。另一方面，对于任何小于样本数的批量大小，SGD能够找到一个稀疏且几乎与初始化正交的全局最小值，这表明随机梯度的随机性在这种情况下引发了一种不同类型的“特征选择”。此外，如果通过海森矩阵的迹来衡量最小值的锐度，那么使用更小的批量大小找到的最小值较锐利。

    In this work, we investigate the dynamics of stochastic gradient descent (SGD) when training a single-neuron autoencoder with linear or ReLU activation on orthogonal data. We show that for this non-convex problem, randomly initialized SGD with a constant step size successfully finds a global minimum for any batch size choice. However, the particular global minimum found depends upon the batch size. In the full-batch setting, we show that the solution is dense (i.e., not sparse) and is highly aligned with its initialized direction, showing that relatively little feature learning occurs. On the other hand, for any batch size strictly smaller than the number of samples, SGD finds a global minimum which is sparse and nearly orthogonal to its initialization, showing that the randomness of stochastic gradients induces a qualitatively different type of "feature selection" in this setting. Moreover, if we measure the sharpness of the minimum by the trace of the Hessian, the minima found with f
    
[^11]: 使用集成技术检测多元时间序列中的异常

    Detection of Anomalies in Multivariate Time Series Using Ensemble Techniques. (arXiv:2308.03171v1 [cs.LG])

    [http://arxiv.org/abs/2308.03171](http://arxiv.org/abs/2308.03171)

    该论文提出了一种使用集成技术检测多元时间序列中的异常的方法。通过使用特征装袋技术和基于PCA的嵌套旋转转换，该方法提高了基本模型的性能和泛化能力。

    

    在许多领域中，多元时间序列中的异常检测是一个重要问题。由于异常在真实数据中的稀疏性，使得分类算法在解决异常检测问题时面临挑战。基于深度神经网络（如LSTM、自编码器、卷积自编码器等）的方法在这种不平衡数据中取得了积极的结果。然而，当应用于多元时间序列时，算法面临的主要挑战是异常可能来自特征集的一个小子集。为了提高这些基本模型的性能，我们提出了一种特征装袋技术，每次只考虑特征的一个子集，并且我们进一步应用了基于主成分分析（PCA）计算的嵌套旋转的转换来改善方法的有效性和泛化能力。为了进一步提高预测性能，我们提出了一种集成技术，将多个基本模型结合在一起。

    Anomaly Detection in multivariate time series is a major problem in many fields. Due to their nature, anomalies sparsely occur in real data, thus making the task of anomaly detection a challenging problem for classification algorithms to solve. Methods that are based on Deep Neural Networks such as LSTM, Autoencoders, Convolutional Autoencoders etc., have shown positive results in such imbalanced data. However, the major challenge that algorithms face when applied to multivariate time series is that the anomaly can arise from a small subset of the feature set. To boost the performance of these base models, we propose a feature-bagging technique that considers only a subset of features at a time, and we further apply a transformation that is based on nested rotation computed from Principal Component Analysis (PCA) to improve the effectiveness and generalization of the approach. To further enhance the prediction performance, we propose an ensemble technique that combines multiple base mo
    
[^12]: 自主线性分类

    Self-Directed Linear Classification. (arXiv:2308.03142v1 [cs.LG])

    [http://arxiv.org/abs/2308.03142](http://arxiv.org/abs/2308.03142)

    这项研究首次在自主线性分类任务中研究了选择预测顺序的能力，并提出了两个主要结果，针对不同类型的数据集，设计了高效的自主学习器，最少只产生$O(d \log \log(n))$个错误。

    

    在在线分类中，学习器被呈现一系列的示例，并旨在以在线方式预测其标签，以最小化错误的总数。在自主变体中，学习器事先了解示例池，并能够自适应地选择预测顺序。在这里，我们研究了选择预测顺序的能力，并为线性分类的基本任务建立了最坏顺序和随机顺序学习之间的第一个强分离。在我们的工作之前，只在非常受限的概念类中才知道这样的分离，例如一维门限或轴对齐矩形。我们提出了两个主要结果。如果$X$是从$d$维单位球中均匀随机抽取的$n$个点的数据集，则我们设计了一个高效的自主学习器，可做出$O(d \log \log(n))$个错误并分类整个数据集。如果$X$是一个任意的$d$维数据集，大小为$n$，我们设计了一个高效的自主学习器，使得其在分类整个数据集时总共也只会产生$O(d \log \log(n))$个错误。

    In online classification, a learner is presented with a sequence of examples and aims to predict their labels in an online fashion so as to minimize the total number of mistakes. In the self-directed variant, the learner knows in advance the pool of examples and can adaptively choose the order in which predictions are made. Here we study the power of choosing the prediction order and establish the first strong separation between worst-order and random-order learning for the fundamental task of linear classification. Prior to our work, such a separation was known only for very restricted concept classes, e.g., one-dimensional thresholds or axis-aligned rectangles.  We present two main results. If $X$ is a dataset of $n$ points drawn uniformly at random from the $d$-dimensional unit sphere, we design an efficient self-directed learner that makes $O(d \log \log(n))$ mistakes and classifies the entire dataset. If $X$ is an arbitrary $d$-dimensional dataset of size $n$, we design an efficie
    
[^13]: 迭代幅度修剪作为重整化群的研究：基于中彩票假设的探索

    Iterative Magnitude Pruning as a Renormalisation Group: A Study in The Context of The Lottery Ticket Hypothesis. (arXiv:2308.03128v1 [cs.LG])

    [http://arxiv.org/abs/2308.03128](http://arxiv.org/abs/2308.03128)

    本论文研究了深度神经网络中彩票假设的概念，通过迭代幅度修剪逐步优化模型，并探索了中彩票的普遍性。同时，本论文还提出了IMP与RG理论的联系，促进对IMP的更深入理解。

    

    本论文深入研究了深度神经网络（DNN）中令人激动的中彩票假设（LTH）的复杂世界。LTH认为，在庞大的DNN中，较小的可训练子网络（称为"中彩票"）可以达到与完整模型相媲美的性能。LTH的关键过程是迭代幅度修剪（IMP），它逐步消除最小权重，模拟DNN中的逐步学习。一旦我们确定了这些中彩票，我们进一步研究它们的"普遍性"。换句话说，我们检查一种在一个特定问题上表现良好的中彩票是否也能在其他类似问题上表现良好。我们还建立了IMP与物理学中的重整化群（RG）理论之间的桥梁，推动对IMP的更严谨理解。

    This thesis delves into the intricate world of Deep Neural Networks (DNNs), focusing on the exciting concept of the Lottery Ticket Hypothesis (LTH). The LTH posits that within extensive DNNs, smaller, trainable subnetworks termed "winning tickets", can achieve performance comparable to the full model. A key process in LTH, Iterative Magnitude Pruning (IMP), incrementally eliminates minimal weights, emulating stepwise learning in DNNs. Once we identify these winning tickets, we further investigate their "universality". In other words, we check if a winning ticket that works well for one specific problem could also work well for other, similar problems. We also bridge the divide between the IMP and the Renormalisation Group (RG) theory in physics, promoting a more rigorous understanding of IMP.
    
[^14]: 对于非常稀疏的列联表的出租车对应分析的可视化：一个文本数据的案例研究

    Visualization of Extremely Sparse Contingency Table by Taxicab Correspondence Analysis: A Case Study of Textual Data. (arXiv:2308.03079v1 [stat.ML])

    [http://arxiv.org/abs/2308.03079](http://arxiv.org/abs/2308.03079)

    出租车对应分析是一种可视化非常稀疏的列联表的方法，我们在一个涉及文本数据的案例研究中进行了应用，研究了Sah和Fokou\'e（2019）引入的8本圣书片段，并使用多种维度约减方法进行了详细研究。

    

    我们介绍了一种鲁棒的对应分析变体——出租车对应分析，用于可视化非常稀疏的列联表。具体来说，我们可视化了一个尺寸为590 × 8265的非常稀疏文本数据集，其中涉及最近由Sah和Fokou\'e（2019）引入的8本圣书的片段，并由Ma，Sun和Zou（2022）使用（12 + 1）维度约减方法（t-SNE, UMAP, PHATE,...）进行详细研究。

    We present an overview of taxicab correspondence analysis, a robust variant of correspondence analysis, for visualization of extremely sparse ontingency tables. In particular we visualize an extremely sparse textual data set of size 590 by 8265 concerning fragments of 8 sacred books recently introduced by Sah and Fokou\'e (2019) and studied quite in detail by (12 + 1) dimension reduction methods (t-SNE, UMAP, PHATE,...) by Ma, Sun and Zou (2022).
    
[^15]: 广义过采样用于从不平衡数据集中学习以及相关理论

    Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory. (arXiv:2308.02966v1 [stat.ML])

    [http://arxiv.org/abs/2308.02966](http://arxiv.org/abs/2308.02966)

    本文提出了一种广义过采样算法GOLIATH，基于核密度估计，可用于不平衡分类和回归任务。同时提供了这些机器学习算法的显式形式和条件密度表达式，为SMOTE等新的合成数据生成器提供了理论依据。

    

    在监督学习中，经常会遇到真实的不平衡数据集。这种情况对于标准算法来说是一个学习难题。不平衡学习的研究和解决方案主要集中在分类任务上。尽管其重要性，但几乎没有关于不平衡回归的解决方案存在。在本文中，我们提出了一种基于核密度估计的数据增强程序，即GOLIATH算法，它可以用于分类和回归。这种通用方法包括两大类合成过采样方法：基于扰动的方法，如高斯噪声，以及基于插值的方法，如SMOTE。它还提供了这些机器学习算法的显式形式和它们的条件密度表达式，尤其是对于SMOTE。新的合成数据生成器被推导出来。我们将GOLIATH应用于不平衡回归，将这些生成器过程与一种野生引导重采样技术相结合。

    In supervised learning, it is quite frequent to be confronted with real imbalanced datasets. This situation leads to a learning difficulty for standard algorithms. Research and solutions in imbalanced learning have mainly focused on classification tasks. Despite its importance, very few solutions exist for imbalanced regression. In this paper, we propose a data augmentation procedure, the GOLIATH algorithm, based on kernel density estimates which can be used in classification and regression. This general approach encompasses two large families of synthetic oversampling: those based on perturbations, such as Gaussian Noise, and those based on interpolations, such as SMOTE. It also provides an explicit form of these machine learning algorithms and an expression of their conditional densities, in particular for SMOTE. New synthetic data generators are deduced. We apply GOLIATH in imbalanced regression combining such generator procedures with a wild-bootstrap resampling technique for the t
    
[^16]: 结构化低秩张量用于广义线性模型

    Structured Low-Rank Tensors for Generalized Linear Models. (arXiv:2308.02922v1 [stat.ML])

    [http://arxiv.org/abs/2308.02922](http://arxiv.org/abs/2308.02922)

    结构化低秩张量在广义线性模型中的应用能够更可靠地估计参数和降低样本复杂性。

    

    最近的研究表明，在回归问题中强加张量结构在参数估计和样本复杂性方面比基于向量的方法更可靠。本研究在广义线性模型问题中研究一种新的低秩张量模型，称为低分离秩（LSR）模型。LSR模型推广了著名的Tucker和CANDECOMP / PARAFAC（CP）模型，并且是块张量分解（BTD）模型的一个特例。本研究在GLM模型中对参数张量施加LSR结构，并提出了一种块坐标下降算法用于LSR结构张量GLM的参数估计。最重要的是，它推导出了在LSR张量GLM问题中估计系数张量的误差阈值的极小化下界。这个极小化下界与LSR张量GLM问题中的固有自由度成正比，表明其样本复杂性可能明显低于向量方法。

    Recent works have shown that imposing tensor structures on the coefficient tensor in regression problems can lead to more reliable parameter estimation and lower sample complexity compared to vector-based methods. This work investigates a new low-rank tensor model, called Low Separation Rank (LSR), in Generalized Linear Model (GLM) problems. The LSR model -- which generalizes the well-known Tucker and CANDECOMP/PARAFAC (CP) models, and is a special case of the Block Tensor Decomposition (BTD) model -- is imposed onto the coefficient tensor in the GLM model. This work proposes a block coordinate descent algorithm for parameter estimation in LSR-structured tensor GLMs. Most importantly, it derives a minimax lower bound on the error threshold on estimating the coefficient tensor in LSR tensor GLM problems. The minimax bound is proportional to the intrinsic degrees of freedom in the LSR tensor GLM problem, suggesting that its sample complexity may be significantly lower than that of vector
    
[^17]: 基于广义多维比较的光谱排名推断

    Spectral Ranking Inferences based on General Multiway Comparisons. (arXiv:2308.02918v1 [stat.ME])

    [http://arxiv.org/abs/2308.02918](http://arxiv.org/abs/2308.02918)

    本文研究了使用光谱方法在广义多维比较中估计和量化未观察到的比较实体的偏好分数的性能，并揭示了光谱估计量与最大似然估计量之间的关系。

    

    本文研究了在一个非常普遍和更加真实的情景中，使用光谱方法对未观察到的比较实体的偏好分数进行估计和不确定性量化的性能。在这种情况下，比较图由可能具有异构大小的超边组成，对于给定的超边，比较数量可能仅为1。这种设置在实际应用中普遍存在，避免了需要指定图的随机性以及在常用的Bradley-Terry-Luce (BTL)或Plackett-Luce (PL)模型中施加的限制性均匀采样假设。此外，在适用BTL或PL模型的情况下，我们揭示了光谱估计量与最大似然估计量（MLE）之间的关系。我们发现，通过应用从等权重传统光谱方法估计得到的最佳加权，可以实现与MLE相同的渐近效率的双步光谱方法。考虑到渐近情况，

    This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a very general and more realistic setup in which the comparison graph consists of hyper-edges of possible heterogeneous sizes and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly-used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in the scenarios when the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptot
    
[^18]: 物理信息的高斯过程模型用于欧拉-伯努利梁元素

    Physics-informed Gaussian process model for Euler-Bernoulli beam elements. (arXiv:2308.02894v1 [stat.ML])

    [http://arxiv.org/abs/2308.02894](http://arxiv.org/abs/2308.02894)

    该论文介绍了一种基于物理信息的高斯过程模型，通过欧拉-伯努利梁方程建模，并应用于结构的弯曲刚度回归、响应插值和概率推断。该模型在悬臂梁上进行了实际应用，并用于结构健康监测。实验结果验证了该框架的有效性。

    

    通过使用欧拉-伯努利梁方程，构建了一种以多输出高斯过程形式的物理信息机器学习模型。在合适的数据集下，该模型可以用于回归结构的弯曲刚度的解析值、插值响应以及对潜在物理量进行概率推断。该模型被应用于数值模拟的悬臂梁上，评估了回归的弯曲刚度，并研究了预测质量受测量噪声的影响。此外，利用回归得到的概率刚度分布，在结构健康监测背景下，采用马氏距离来推断结构系统中可能的损伤位置和范围。为了验证开发的框架，进行了一项实验，使用测量的异质数据集来更新假定的解析结构模型。

    A physics-informed machine learning model, in the form of a multi-output Gaussian process, is formulated using the Euler-Bernoulli beam equation. Given appropriate datasets, the model can be used to regress the analytical value of the structure's bending stiffness, interpolate responses, and make probabilistic inferences on latent physical quantities. The developed model is applied on a numerically simulated cantilever beam, where the regressed bending stiffness is evaluated and the influence measurement noise on the prediction quality is investigated. Further, the regressed probabilistic stiffness distribution is used in a structural health monitoring context, where the Mahalanobis distance is employed to reason about the possible location and extent of damage in the structural system. To validate the developed framework, an experiment is conducted and measured heterogeneous datasets are used to update the assumed analytical structural model.
    
[^19]: 使用尺度不变神经网络逼近正齐次函数

    Approximating Positive Homogeneous Functions with Scale Invariant Neural Networks. (arXiv:2308.02836v1 [cs.LG])

    [http://arxiv.org/abs/2308.02836](http://arxiv.org/abs/2308.02836)

    本文研究使用尺度不变神经网络近似解决线性反问题的可行性，证明了单隐藏层ReLU网络无法恢复稀疏向量，但通过两个隐藏层可以稳定且精确地恢复任意稀疏程度的向量，此外还推广到了其他恢复问题。

    

    本文研究使用ReLU网络解决线性反问题的可能性。由于线性关系带来的尺度不变性，对于这类问题的最优重构函数f是正齐次函数，即满足对于所有非负的λ，有f(λx) = λf(x)。在ReLU网络中，这个条件转化为在网络中不考虑偏置项。我们首先考虑从少量线性测量中恢复稀疏向量的问题。我们证明单隐藏层的ReLU网络无法恢复1-稀疏向量，即使是近似恢复，而且不论网络的宽度如何。然而，通过两个隐藏层，可以以稳定的方式近似地恢复任意精度的、任意稀疏程度为s的向量。然后，我们将结果推广到包括低秩矩阵恢复和相位恢复在内的更广泛的恢复问题。此外，我们还考虑了对一般正齐次函数的逼近问题。

    We investigate to what extent it is possible to solve linear inverse problems with $ReLu$ networks. Due to the scaling invariance arising from the linearity, an optimal reconstruction function $f$ for such a problem is positive homogeneous, i.e., satisfies $f(\lambda x) = \lambda f(x)$ for all non-negative $\lambda$. In a $ReLu$ network, this condition translates to considering networks without bias terms. We first consider recovery of sparse vectors from few linear measurements. We prove that $ReLu$- networks with only one hidden layer cannot even recover $1$-sparse vectors, not even approximately, and regardless of the width of the network. However, with two hidden layers, approximate recovery with arbitrary precision and arbitrary sparsity level $s$ is possible in a stable way. We then extend our results to a wider class of recovery problems including low-rank matrix recovery and phase retrieval. Furthermore, we also consider the approximation of general positive homogeneous functio
    
[^20]: 可伸缩的因果界限计算

    Scalable Computation of Causal Bounds. (arXiv:2308.02709v1 [cs.LG])

    [http://arxiv.org/abs/2308.02709](http://arxiv.org/abs/2308.02709)

    本论文研究了在存在未观测混淆变量和离散值观测变量的因果图上计算因果查询的界限的问题，并提出了修剪方法来显著减少计算负担，使得可以计算更大规模的因果推断问题的界限，在特殊问题情况下可以以闭合形式计算界限，并将方法扩展到分数线性规划进行计算

    

    我们考虑在存在未观测混淆变量和离散值观测变量的因果图上计算因果查询的界限的问题，其中不满足可辨识性。现有的非参数方法用于计算这些界限的线性规划（LP）公式由于线性规划的大小随着因果图中的边的数量呈指数级增长而很快变得不可解。我们展示了这个LP公式可以被显著修剪，使我们能够计算较大因果推断问题的界限，相比现有技术，这个修剪过程允许我们以闭合形式计算一类特殊问题的界限，包括多个混淆处理影响结果的广为研究的问题族。我们将修剪方法扩展到分数线性规划（fractional LP），这些规划公式用于计算包含有关个体的附加观测的因果查询的界限。我们证明了我们的方法提供了显著的运行时间

    We consider the problem of computing bounds for causal queries on causal graphs with unobserved confounders and discrete valued observed variables, where identifiability does not hold. Existing non-parametric approaches for computing such bounds use linear programming (LP) formulations that quickly become intractable for existing solvers because the size of the LP grows exponentially in the number of edges in the causal graph. We show that this LP can be significantly pruned, allowing us to compute bounds for significantly larger causal inference problems compared to existing techniques. This pruning procedure allows us to compute bounds in closed form for a special class of problems, including a well-studied family of problems where multiple confounded treatments influence an outcome. We extend our pruning methodology to fractional LPs which compute bounds for causal queries which incorporate additional observations about the unit. We show that our methods provide significant runtime 
    
[^21]: 存在类条件标签噪音下的欺诈检测中的FPR估计

    FPR Estimation for Fraud Detection in the Presence of Class-Conditional Label Noise. (arXiv:2308.02695v1 [cs.LG])

    [http://arxiv.org/abs/2308.02695](http://arxiv.org/abs/2308.02695)

    该论文提出了在存在标签噪音的情况下，估计二分类模型的FPR以及TPR的方法，这对于欺诈检测中的准确性至关重要。作者发现，现有的方法虽然减小了总误差，却不能保证模型对FPR和TPR的估计准确，因此提出了一种使清理误差与模型分数解耦的方法。

    

    我们考虑了在验证集中存在错误标签（标签噪音）的情况下，对二分类模型的假阳性率（FPR）/真阳性率（TPR）的估计问题。我们的动机应用是欺诈预防，在这种情况下，准确估计FPR对于保护好客户的体验至关重要，而标签噪音具有高度的不对称性。现有方法旨在最小化清理过程中的总误差 - 避免清理非噪音的示例，并确保清理噪音示例。这是一个重要的准确性度量，但不足以保证模型的真实FPR或TPR的良好估计，我们表明，即使总误差较低，使用模型直接清理自己的验证数据也会导致低估。这表明，研究人员需要追求不仅减少总误差，还需要寻求使清理误差与模型分数解耦的方法。

    We consider the problem of estimating the false-/ true-positive-rate (FPR/TPR) for a binary classification model when there are incorrect labels (label noise) in the validation set. Our motivating application is fraud prevention where accurate estimates of FPR are critical to preserving the experience for good customers, and where label noise is highly asymmetric. Existing methods seek to minimize the total error in the cleaning process - to avoid cleaning examples that are not noise, and to ensure cleaning of examples that are. This is an important measure of accuracy but insufficient to guarantee good estimates of the true FPR or TPR for a model, and we show that using the model to directly clean its own validation data leads to underestimates even if total error is low. This indicates a need for researchers to pursue methods that not only reduce total error but also seek to de-correlate cleaning error with model scores.
    
[^22]: 对于点云的标量曲率估计的内在方法

    An Intrinsic Approach to Scalar-Curvature Estimation for Point Clouds. (arXiv:2308.02615v1 [stat.ML])

    [http://arxiv.org/abs/2308.02615](http://arxiv.org/abs/2308.02615)

    我们提出了一种内在的方法来估计点云的标量曲率，该方法仅依赖于数据的度量结构，而不依赖于其在n维实数空间中的嵌入。我们通过理论分析和实验证明了该方法的一致性和稳定性。

    

    我们引入了一种内在的估计方法，用于对作为有限度量空间呈现的数据集的标量曲率。我们的估计方法仅依赖于数据的度量结构，而不依赖于其在n维实数空间中的嵌入。我们证明了该估计方法是一致的，即对于从紧致黎曼流形上的概率测度中采样的点，随着点的数量增加，估计结果会收敛到标量曲率。为了证明其在应用中的可行性，我们还展示了该估计方法对度量结构的扰动具有稳定性，例如样本中的噪声或估计内在度量误差。我们在从具有指定曲率的流形中采样的合成数据上进行了实验验证。

    We introduce an intrinsic estimator for the scalar curvature of a data set presented as a finite metric space. Our estimator depends only on the metric structure of the data and not on an embedding in $\mathbb{R}^n$. We show that the estimator is consistent in the sense that for points sampled from a probability measure on a compact Riemannian manifold, the estimator converges to the scalar curvature as the number of points increases. To justify its use in applications, we show that the estimator is stable with respect to perturbations of the metric structure, e.g., noise in the sample or error estimating the intrinsic metric. We validate our estimator experimentally on synthetic data that is sampled from manifolds with specified curvature.
    
[^23]: 基于积分的无强度积分化学能的学习

    Intensity-free Integral-based Learning of Marked Temporal Point Processes. (arXiv:2308.02360v1 [cs.LG])

    [http://arxiv.org/abs/2308.02360](http://arxiv.org/abs/2308.02360)

    该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。

    

    在标记的时间点过程（MTPP）中，一个核心问题是为条件联合概率密度函数（PDF）$p^*（m，t）$参数化插值时间t和标记m在历史条件下。现有研究大多预先定义强度函数。它们的实用性受到指定强度函数正确形式的挑战，这对于平衡表达能力和处理效率至关重要。最近，有研究摆脱预定义强度函数，一个模型$p^*（t）$和$p^*（m）$分开，另一个侧重于不考虑标记的时间点过程（TPP）。本研究旨在开发高保真度的$p^*（m，t）$，适用于事件标记在多维连续空间中具有分类或数值属性的离散事件。我们提出了一个解决方案框架IFIB（无强度积分化学能过程），直接建模条件联合概率密度函数$p^*（m，t）$。

    In the marked temporal point processes (MTPP), a core problem is to parameterize the conditional joint PDF (probability distribution function) $p^*(m,t)$ for inter-event time $t$ and mark $m$, conditioned on the history. The majority of existing studies predefine intensity functions. Their utility is challenged by specifying the intensity function's proper form, which is critical to balance expressiveness and processing efficiency. Recently, there are studies moving away from predefining the intensity function -- one models $p^*(t)$ and $p^*(m)$ separately, while the other focuses on temporal point processes (TPPs), which do not consider marks. This study aims to develop high-fidelity $p^*(m,t)$ for discrete events where the event marks are either categorical or numeric in a multi-dimensional continuous space. We propose a solution framework IFIB (\underline{I}ntensity-\underline{f}ree \underline{I}ntegral-\underline{b}ased process) that models conditional joint PDF $p^*(m,t)$ directly
    
[^24]: LLMs理解玻璃盒模型，发现惊喜并提出修复建议。

    LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs. (arXiv:2308.01157v1 [stat.ML])

    [http://arxiv.org/abs/2308.01157](http://arxiv.org/abs/2308.01157)

    LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。

    

    我们展示了大型语言模型(LLMs)在处理可解释模型方面的出色表现，这些模型可以将复杂结果分解为单一变量的图表示组件。通过采用层次推理的方法，LLMs能够在不需要整个模型适应上下文的情况下提供全面的模型级总结。这种方法使LLMs能够应用其广泛的背景知识来自动完成数据科学中的常见任务，如检测与先前知识相矛盾的异常，描述异常的潜在原因，并提出去除异常的修复建议。我们使用医疗保健领域的多个示例来证明LLMs的这些新能力的实用性，特别强调广义可加模型(GAMs)。最后，我们将$\texttt{TalkToEBM}$包作为一个开源的LLM-GAM接口进行介绍。

    We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
    
[^25]: 用物理信知的神经网络解决维度诅咒问题

    Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])

    [http://arxiv.org/abs/2307.12306](http://arxiv.org/abs/2307.12306)

    本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。

    

    维度诅咒(CoD)随着维度的增加，以指数级增长的计算成本来极度税费计算资源。这在解决高维偏微分方程(PDEs)中面临极大挑战，正如Richard Bellman在60年前首次指出的那样。尽管近年来在高维度上数值解决偏微分方程(PDEs)取得了一些成功，但这样的计算代价过高，而将一般非线性PDEs扩展到高维度从未实现过。本文提出了一种新方法，将物理信知的神经网络(PINNs)扩展到解决任意高维PDEs。该新方法称为随机维度梯度下降(SDGD)，将PDE的梯度分解为与不同维度对应的部分，并在训练PINNs的每次迭代中随机选择这些维度部分的子集进行采样。我们在理论上证明了所提出方法的收敛保证和其他期望属性。

    The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
    
[^26]: 批次使高维超参数线性回归的最小规范风险稳定

    Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression. (arXiv:2306.08432v1 [cs.LG])

    [http://arxiv.org/abs/2306.08432](http://arxiv.org/abs/2306.08432)

    本文研究了将数据分成批次的学习算法，在高维超参数线性回归模型中提供了隐式正则化，通过适当的批量大小选择，稳定了风险行为，消除了插值点处的膨胀和双峰现象

    

    将数据分成批次的学习算法在许多机器学习应用中很常见，通常在计算效率和性能之间提供有用的权衡。本文通过具有各向同性高斯特征的最小规范超参数线性回归模型的视角来研究批量分区的好处。我们建议最小规范估计量的自然小批量版本，并推导出其二次风险的上界，表明其与噪声水平以及过度参数化比例成反比，对于最佳批量大小的选择。与最小规范相比，我们的估计器具有稳定的风险行为，其在过度参数化比例上单调递增，消除了插值点处的膨胀和双峰现象。有趣的是，我们观察到批处理所提供的隐式正则化在一定程度上可以通过特征重叠来解释。

    Learning algorithms that divide the data into batches are prevalent in many machine-learning applications, typically offering useful trade-offs between computational efficiency and performance. In this paper, we examine the benefits of batch-partitioning through the lens of a minimum-norm overparameterized linear regression model with isotropic Gaussian features. We suggest a natural small-batch version of the minimum-norm estimator, and derive an upper bound on its quadratic risk, showing it is inversely proportional to the noise level as well as to the overparameterization ratio, for the optimal choice of batch size. In contrast to minimum-norm, our estimator admits a stable risk behavior that is monotonically increasing in the overparameterization ratio, eliminating both the blowup at the interpolation point and the double-descent phenomenon. Interestingly, we observe that this implicit regularization offered by the batch partition is partially explained by feature overlap between t
    
[^27]: 对称张量分解问题的对称性与临界点

    Symmetry & Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])

    [http://arxiv.org/abs/2306.07886](http://arxiv.org/abs/2306.07886)

    本文研究了将一个实对称张量分解成秩为1项之和的非凸优化问题，得到了精确的分析估计，并发现了各种阻碍局部优化方法的几何障碍和由于对称性导致的丰富的临界点集合。

    

    本文考虑了将一个实对称张量分解成秩为1项之和的非凸优化问题。利用其丰富的对称结构，导出Puiseux级数表示的一系列临界点，并获得了关于临界值和Hessian谱的精确分析估计。这些结果揭示了各种几何障碍，阻碍了局部优化方法的使用，最后，利用一个牛顿多面体论证了固定对称性的所有临界点的完全枚举，并证明了与全局最小值的集合相比，由于对称性的存在，临界点的集合可能会显示出组合的丰富性。

    We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
    
[^28]: 评估-优化方法与集成评估优化法：基于随机优势的观点

    Estimate-Then-Optimize Versus Integrated-Estimation-Optimization: A Stochastic Dominance Perspective. (arXiv:2304.06833v1 [stat.ML])

    [http://arxiv.org/abs/2304.06833](http://arxiv.org/abs/2304.06833)

    本文提出，当模型类足够丰富以涵盖真实情况时，非线性问题的“先估计再优化”方法优于集成方法，包括优化间隙的渐进优势的均值，所有其他时刻和整个渐进分布。

    

    在数据驱动的随机优化中，除了需要优化任务，还需要从数据中估计潜在分布的模型参数。最近的文献表明，通过选择导致最佳经验目标性能的模型参数，可以集成估计和优化过程。当模型被错误地指定时，这种集成方法可以很容易地显示出优于简单的“先估计再优化”的方法。本文认为，在模型类足够丰富以涵盖真实情况的情况下，对于非线性问题，两种方法之间的性能排序在强烈的意义下被颠倒。在受限条件和当上下文特征可用时，类似的结果也成立。

    In data-driven stochastic optimization, model parameters of the underlying distribution need to be estimated from data in addition to the optimization task. Recent literature suggests the integration of the estimation and optimization processes, by selecting model parameters that lead to the best empirical objective performance. Such an integrated approach can be readily shown to outperform simple ``estimate then optimize" when the model is misspecified. In this paper, we argue that when the model class is rich enough to cover the ground truth, the performance ordering between the two approaches is reversed for nonlinear problems in a strong sense. Simple ``estimate then optimize" outperforms the integrated approach in terms of stochastic dominance of the asymptotic optimality gap, i,e, the mean, all other moments, and the entire asymptotic distribution of the optimality gap is always better. Analogous results also hold under constrained settings and when contextual features are availa
    
[^29]: 我们实现了个性化治疗吗？使用重复采样的在线强化学习算法进行个性化评估

    Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])

    [http://arxiv.org/abs/2304.05365](http://arxiv.org/abs/2304.05365)

    本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。

    

    在数字健康中，使用强化学习（RL）个性化治疗序列以支持用户采取更健康的行为越来越受到关注。这种连续决策问题涉及到基于用户的上下文（例如，先前的活动水平、位置等）在何时治疗以及如何治疗的决定。在线RL算法是这个问题的一个有前途的数据驱动方法，因为它基于每个用户的历史反馈进行学习，并利用这些知识个性化这些决策。然而，要决定是否应在实际部署的“优化”干预中包含RL算法，我们必须评估数据证据，表明RL算法实际上正在将治疗个性化适应其用户。由于RL算法中的随机性，人们可能会对其在某些状态下的学习并使用此学习来提供特定治疗的能力产生误解。我们使用工作定义的个性化，并介绍了一种重复采样政策评估方法来评估在线RL算法实现的个性化水平。我们使用模拟评估了我们提出的方法，并展示了我们的方法可以准确地识别个性化的策略。我们提出的方法在优化数字健康的个性化干预方面具有潜在应用。

    There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
    
[^30]: 学习奖励信息获取：正确计分规则遇到委托代理模型

    Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model. (arXiv:2303.08613v1 [cs.LG])

    [http://arxiv.org/abs/2303.08613](http://arxiv.org/abs/2303.08613)

    本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。

    

    本文研究委托代理模型中的激励信息获取问题。此问题被建模为委托方和代理方之间的 Stackelberg 博弈，其中委托人宣布了一条得分规则来指定付款，然后代理方选择最大化其自身利润和报告信息的努力水平。我们从委托方的角度研究这个问题的在线设置，即通过与策略代理多次交互来设计最优计分规则。我们设计了一种可证明的样本高效算法，将 UCB 算法 (Auer et al., 2002) 量身定制到我们的模型中，其在 T 次迭代后实现了次线性 $T^{2/3}$-遗憾。我们的算法具有对委托方最优利润进行精细估计的过程以及保守纠正方案，以确保代理方的行动得到有效激励。此外，我们的遗憾界的一个关键特征是它是渐进最小可实现的。

    We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a sublinear $T^{2/3}$-regret after $T$ iterations. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is i
    
[^31]: 神经网络校准的期望一致性

    Expectation consistency for calibration of neural networks. (arXiv:2303.02644v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02644](http://arxiv.org/abs/2303.02644)

    本文介绍了一种名为期望一致性（EC）的新型校准技术，该方法通过对最后一层权重进行后训练重新缩放，使平均验证置信度与平均正确标签比例相一致，在不同神经网络架构和数据集上实现了类似温度缩放（TS）的校准性能。

    

    尽管深度神经网络有着出色的性能，但已经有报道指出它们在预测置信度方面往往存在过度乐观的问题。寻找有效和高效的神经网络校准方法对于深度学习中更好地量化不确定性是一项重要的努力。在本文中，我们介绍了一种名为期望一致性（EC）的新型校准技术，它通过对最后一层权重进行后训练重新缩放，强制要求平均验证置信度与平均正确标签比例相一致。首先，我们证明了EC方法在不同神经网络架构和数据集上实现了与温度缩放（TS）相似的校准性能，同时需要类似的验证样本和计算资源。然而，我们认为EC提供了一种基于贝叶斯最优性原理（即Nishimori恒等式）的原则性方法。接下来，我们提供了一个渐近定义。

    Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characteri
    
[^32]: 关于筛选分类器的组内公平性

    On the Within-Group Fairness of Screening Classifiers. (arXiv:2302.00025v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00025](http://arxiv.org/abs/2302.00025)

    本文探讨了筛选分类器的组内公平性问题，指出使用校准的分类器可能存在对感兴趣的人口群体内的合格成员存在不公平对待的问题，并提出了一种基于动态规划的高效后处理算法来最小化修改分类器，以实现组内公平性。

    

    筛选分类器越来越多地用于各种选择过程中的候选人识别。在这个背景下，最近的研究表明，如果一个分类器被校准，可以使用一个阈值决策规则识别出期望数目的合格候选人的最小集合。这支持将校准作为筛选分类器的唯一要求。本文中，我们认为使用校准的分类器的筛选策略可能存在一种鲜为人知的组内不公平类型——它们可能不公平地对待感兴趣的人口群体中的合格成员。此外，我们认为如果分类器满足组内单调性，这种不公平性可以避免，组内单调性是每个群体内的一种自然单调性属性。然后，我们介绍了一种基于动态规划的高效后处理算法，可以最小化修改给定的校准分类器，以便其概率。

    Screening classifiers are increasingly used to identify qualified candidates in a variety of selection processes. In this context, it has been recently shown that, if a classifier is calibrated, one can identify the smallest set of candidates which contains, in expectation, a desired number of qualified candidates using a threshold decision rule. This lends support to focusing on calibration as the only requirement for screening classifiers. In this paper, we argue that screening policies that use calibrated classifiers may suffer from an understudied type of within-group unfairness -- they may unfairly treat qualified members within demographic groups of interest. Further, we argue that this type of unfairness can be avoided if classifiers satisfy within-group monotonicity, a natural monotonicity property within each of the groups. Then, we introduce an efficient post-processing algorithm based on dynamic programming to minimally modify a given calibrated classifier so that its probab
    
[^33]: 切片最优偏转运输

    Sliced Optimal Partial Transport. (arXiv:2212.08049v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08049](http://arxiv.org/abs/2212.08049)

    本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。

    

    最优传输（OT）已经在机器学习、数据科学和计算机视觉中变得极其流行。OT问题的核心假设是源和目标测度的总质量相等，这限制了它的应用。最优偏转运输（OPT）是最近提出的解决这个限制的方法。与OT问题类似，OPT的计算依赖于解决线性规划问题（通常在高维度中），这可能会变得计算上困难。在本文中，我们提出了一种计算一维非负测度之间OPT问题的有效算法。接下来，遵循切片OT距离的思想，我们利用切片定义了切片OPT距离。最后，我们展示了切片OPT-based方法在各种数值实验中的计算和精度优势。特别是，我们展示了我们提出的Sliced-OPT在噪声点云配准中的应用。

    Optimal transport (OT) has become exceedingly popular in machine learning, data science, and computer vision. The core assumption in the OT problem is the equal total amount of mass in source and target measures, which limits its application. Optimal Partial Transport (OPT) is a recently proposed solution to this limitation. Similar to the OT problem, the computation of OPT relies on solving a linear programming problem (often in high dimensions), which can become computationally prohibitive. In this paper, we propose an efficient algorithm for calculating the OPT problem between two non-negative measures in one dimension. Next, following the idea of sliced OT distances, we utilize slicing to define the sliced OPT distance. Finally, we demonstrate the computational and accuracy benefits of the sliced OPT-based method in various numerical experiments. In particular, we show an application of our proposed Sliced-OPT in noisy point cloud registration.
    
[^34]: 基于深度学习的非线性因子模型中的残差：低信噪比下资产回报的精确矩阵估计

    Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio. (arXiv:2209.04512v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.04512](http://arxiv.org/abs/2209.04512)

    本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的方法不仅适用于金融市场典型的低信噪比环境，还与弱因子兼容，并且通过理论分析建立了统一的界限，同时提供了基于数据的一致误差协方差估计方法。模拟和实证结果显示我们的模型具有卓越的准确性。

    

    本文介绍了在深度学习框架中使用非线性因子模型对大型投资组合中资产回报的精确矩阵进行一致估计和收敛速度。我们的估计方法即使在金融市场典型的信噪比低的环境中仍然有效，并且与弱因子兼容。我们的理论分析对于不断增加的资产数量，基于深度神经网络的预期估计风险建立了统一的界限。此外，我们提供了深度神经网络中基于数据的一致误差协方差估计方法。我们的模型在广泛的模拟和实证中表现出卓越的准确性。

    This paper introduces a consistent estimator and rate of convergence for the precision matrix of asset returns in large portfolios using a non-linear factor model within the deep learning framework. Our estimator remains valid even in low signal-to-noise ratio environments typical for financial markets and is compatible with weak factors. Our theoretical analysis establishes uniform bounds on expected estimation risk based on deep neural networks for an expanding number of assets. Additionally, we provide a new consistent data-dependent estimator of error covariance in deep neural networks. Our models demonstrate superior accuracy in extensive simulations and the empirics.
    
[^35]: 变分推断中的统计和计算权衡：推理模型选择中的案例研究

    Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection. (arXiv:2207.11208v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.11208](http://arxiv.org/abs/2207.11208)

    本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。在高斯推理模型中，我们发现，低秩推断模型在固定计算预算下产生了更高的统计近似误差，但较低的计算误差。

    

    变分推断最近在大规模贝叶斯推断中成为了传统马尔可夫链蒙特卡洛(MCMC)的热门替代方法。其核心思想是通过权衡统计准确性和计算效率。本文通过一个推理模型选择的案例研究，研究了变分推断中的统计和计算权衡。我们着重研究了具有对角加低秩精度矩阵的高斯推理模型（或变分逼近家族）中的这种权衡的两个方面：贝叶斯后验推断误差和频率主义不确定性量化误差。从贝叶斯后验推断的角度，我们表征了变分后验相对于精确后验的误差。我们证明，在固定的计算预算下，低秩推断模型产生具有更高统计逼近误差但更低计算误差的变分后验。

    Variational inference has recently emerged as a popular alternative to the classical Markov chain Monte Carlo (MCMC) in large-scale Bayesian inference. The core idea is to trade statistical accuracy for computational efficiency. In this work, we study these statistical and computational trade-offs in variational inference via a case study in inferential model selection. Focusing on Gaussian inferential models (or variational approximating families) with diagonal plus low-rank precision matrices, we initiate a theoretical study of the trade-offs in two aspects, Bayesian posterior inference error and frequentist uncertainty quantification error. From the Bayesian posterior inference perspective, we characterize the error of the variational posterior relative to the exact posterior. We prove that, given a fixed computation budget, a lower-rank inferential model produces variational posteriors with a higher statistical approximation error, but a lower computational error; it reduces varian
    
[^36]: 深度表格模型的迁移学习

    Transfer Learning with Deep Tabular Models. (arXiv:2206.15306v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.15306](http://arxiv.org/abs/2206.15306)

    深度表格模型的迁移学习在医学诊断等领域展现出了比传统方法更优异的性能，并且提出了应对上下游特征集不同情况的解决方法。

    

    最近的关于深度学习用于表格数据的研究表明，深度表格模型展现了强大的性能，通常填补了梯度提升决策树和神经网络之间的差距。除了准确性之外，神经模型的一个主要优势是它们学习了可重复使用的特征，并且在新领域中可以很容易地进行微调。这种特性在计算机视觉和自然语言应用中经常被利用，尤其是在任务特定的训练数据稀缺时，迁移学习变得不可或缺。在这项工作中，我们证明了上游数据为表格神经网络带来了比广泛使用的GBDT模型更具决定性的优势。我们提出了一个适用于表格迁移学习的现实医学诊断基准，并提供了一份使用上游数据提高各种表格神经网络架构性能的指南。最后，我们提出了一种伪特征方法，用于处理上游和下游特征集不同的情况，这是现实世界中广泛存在的表格特定问题。

    Recent work on deep learning for tabular data demonstrates the strong performance of deep tabular models, often bridging the gap between gradient boosted decision trees and neural networks. Accuracy aside, a major advantage of neural models is that they learn reusable features and are easily fine-tuned in new domains. This property is often exploited in computer vision and natural language applications, where transfer learning is indispensable when task-specific training data is scarce. In this work, we demonstrate that upstream data gives tabular neural networks a decisive advantage over widely used GBDT models. We propose a realistic medical diagnosis benchmark for tabular transfer learning, and we present a how-to guide for using upstream data to boost performance with a variety of tabular neural network architectures. Finally, we propose a pseudo-feature method for cases where the upstream and downstream feature sets differ, a tabular-specific problem widespread in real-world appli
    
[^37]: 具有基于Hessian的泛化保证的深度神经网络鲁棒微调

    Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees. (arXiv:2206.02659v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02659](http://arxiv.org/abs/2206.02659)

    本文通过Hessian-based分析，提出一种基于距离的泛化度量方法，用于理解深度神经网络微调的泛化特性。通过PAC-Bayesian分析，给出了基于Hessian距离的微调模型泛化界。此外，还对微调面对标签噪声的问题进行了研究，并提出了一种相关算法和泛化误差保证。

    

    本文考虑在目标任务上对预训练的深度神经网络进行微调。我们研究微调的泛化特性，以理解过拟合问题，这在目标数据集较小或训练标签噪声时经常观察到。现有的深度网络泛化度量依赖于与微调模型的初始化（即预训练网络）距离和深度网络的噪声稳定性等概念。本文通过PAC-Bayesian分析确定了一种基于Hessian的距离度量，它与微调模型的观察到的泛化差距相关性很强。从理论上我们证明了基于Hessian距离的微调模型的泛化界。我们还对微调对抗标签噪声进行了扩展研究，过拟合是一个关键问题；我们提出了一种算法，并在类条件独立假设下给出了该算法的泛化误差保证。

    We consider fine-tuning a pretrained deep neural network on a target task. We study the generalization properties of fine-tuning to understand the problem of overfitting, which has often been observed (e.g., when the target dataset is small or when the training labels are noisy). Existing generalization measures for deep networks depend on notions such as distance from the initialization (i.e., the pretrained network) of the fine-tuned model and noise stability properties of deep networks. This paper identifies a Hessian-based distance measure through PAC-Bayesian analysis, which is shown to correlate well with observed generalization gaps of fine-tuned models. Theoretically, we prove Hessian distance-based generalization bounds for fine-tuned models. We also describe an extended study of fine-tuning against label noise, where overfitting is against a critical problem; We present an algorithm and a generalization error guarantee for this algorithm under a class conditional independent 
    
[^38]: 粗粒化状态空间网络的持续同调

    Persistent Homology of Coarse Grained State Space Networks. (arXiv:2206.02530v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.02530](http://arxiv.org/abs/2206.02530)

    本研究利用持续同调分析复杂过渡网络，发现粗粒化状态空间网络能够更好地捕捉底层动态系统的丰富信息，提高动态状态检测和噪声鲁棒性。

    

    本研究致力于对动态状态检测的复杂过渡网络进行拓扑分析。过渡网络由时间序列数据构成，并利用图论工具揭示底层动态系统的信息。然而，传统工具在总结这种图中的复杂拓扑时可能失败。在这项工作中，我们利用拓扑数据分析中的持续同调来研究这些网络的结构。我们将使用粗粒化状态空间网络（CGSSN）和拓扑数据分析（TDA）对时间序列进行动态状态检测与两种先进方法进行对比：使用TDA结合序数分区网络（OPNs）和将持续同调标准应用于信号的时滞嵌入。我们展示了CGSSN捕捉到底层动态系统的丰富信息，表现为动态状态检测和噪声鲁棒性显著提高。

    This work is dedicated to the topological analysis of complex transitional networks for dynamic state detection. Transitional networks are formed from time series data and they leverage graph theory tools to reveal information about the underlying dynamic system. However, traditional tools can fail to summarize the complex topology present in such graphs. In this work, we leverage persistent homology from topological data analysis to study the structure of these networks. We contrast dynamic state detection from time series using a coarse-grained state-space network (CGSSN) and topological data analysis (TDA) to two state of the art approaches: ordinal partition networks (OPNs) combined with TDA and the standard application of persistent homology to the time-delay embedding of the signal. We show that the CGSSN captures rich information about the dynamic state of the underlying dynamical system as evidenced by a significant improvement in dynamic state detection and noise robustness in
    
[^39]: 变分推断用于贝叶斯桥回归

    Variational Inference for Bayesian Bridge Regression. (arXiv:2205.09515v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.09515](http://arxiv.org/abs/2205.09515)

    本文研究了自动微分变分推断在具有桥惩罚的回归模型上的应用，该方法通过使用小批量数据并提供全贝叶斯推断结果来加速计算时间。通过在B样条非参数回归模型上进行的模拟研究，验证了该方法的性能。

    

    我们研究了自动微分变分推断在具有桥惩罚的回归模型上的贝叶斯推断实现。桥方法使用$\ell_{\alpha}$范数，其中$\alpha \in (0, +\infty)$，对回归系数的大值进行惩罚，包括Lasso ($\alpha = 1$)和岭回归$(\alpha = 2)$惩罚作为特殊情况。全贝叶斯推断无缝地提供了所有模型参数的联合不确定性估计。尽管桥回归的MCMC方法可用，但对于大规模数据集，特别是在高维情况下，可能较慢。ADVI实现允许在每次迭代中使用小批量数据（由于基于随机梯度的算法），从而加速计算时间与MCMC相比。我们通过对B样条非参数回归模型进行了方法说明，尽管该方法对于其他基础函数的选择也可以无缝使用。模拟研究说明了方法的性能。

    We study the implementation of Automatic Differentiation Variational inference (ADVI) for Bayesian inference on regression models with bridge penalization. The bridge approach uses $\ell_{\alpha}$ norm, with $\alpha \in (0, +\infty)$ to define a penalization on large values of the regression coefficients, which includes the Lasso ($\alpha = 1$) and ridge $(\alpha = 2)$ penalizations as special cases. Full Bayesian inference seamlessly provides joint uncertainty estimates for all model parameters. Although MCMC aproaches are available for bridge regression, it can be slow for large dataset, specially in high dimensions. The ADVI implementation allows the use of small batches of data at each iteration (due to stochastic gradient based algorithms), therefore speeding up computational time in comparison with MCMC. We illustrate the approach on non-parametric regression models with B-splines, although the method works seamlessly for other choices of basis functions. A simulation study shows
    
[^40]: 核鲁棒假设检验

    Kernel Robust Hypothesis Testing. (arXiv:2203.12777v2 [eess.SP] CROSS LISTED)

    [http://arxiv.org/abs/2203.12777](http://arxiv.org/abs/2203.12777)

    本文使用核方法构造不确定性集，在贝叶斯设置和Neyman-Pearson设置中分别研究了最小化最坏情况下错误概率和控制错误概率的问题，并提出了基于MMD的一系列测试。

    

    本论文研究了鲁棒假设检验问题，在零假设和备择假设下，数据生成分布被假设在某些不确定性集合中，并旨在设计一种测试，在不确定性集合中表现最优。本文将使用核方法以数据驱动的方式构造不确定性集，即以来自零假设和备择假设的训练样本的经验分布为中心，并通过核均值嵌入的距离来约束，即最大平均差异（MMD）。同时，本文还研究了贝叶斯设置和Neyman-Pearson设置。对于贝叶斯设置，即目标是最小化最坏情况下的错误概率，当字母表是有限的时，首先得到了最佳测试。当字母表是无限的时，提出了一种可行的近似方法来量化最坏情况下的错误概率。对于Neyman-Pearson设置，即目标是在最小化第二类错误概率的同时控制在给定水平下的第一类错误概率，提出了一系列基于MMD的测试，并研究了它们的渐近特性。

    The problem of robust hypothesis testing is studied, where under the null and the alternative hypotheses, the data-generating distributions are assumed to be in some uncertainty sets, and the goal is to design a test that performs well under the worst-case distributions over the uncertainty sets. In this paper, uncertainty sets are constructed in a data-driven manner using kernel method, i.e., they are centered around empirical distributions of training samples from the null and alternative hypotheses, respectively; and are constrained via the distance between kernel mean embeddings of distributions in the reproducing kernel Hilbert space, i.e., maximum mean discrepancy (MMD). The Bayesian setting and the Neyman-Pearson setting are investigated. For the Bayesian setting where the goal is to minimize the worst-case error probability, an optimal test is firstly obtained when the alphabet is finite. When the alphabet is infinite, a tractable approximation is proposed to quantify the worst
    
[^41]: KINet：用于机器人推动操作的无监督前向模型

    KINet: Unsupervised Forward Models for Robotic Pushing Manipulation. (arXiv:2202.09006v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.09006](http://arxiv.org/abs/2202.09006)

    本文介绍了一种名为KINet的无监督框架，用于推理对象之间的相互作用。通过学习关键点表示和关系，该模型可以自动推广到不同场景中，并成功预测未来的关键点状态。

    

    对象为中心的表示是前向预测的重要抽象。大多数现有的前向模型通过广泛的监督学习这种表示（例如对象类别和边界框），尽管在现实中很难获得这样的真实信息。为了解决这个问题，我们引入了KINet（关键点交互网络）--一种基于关键点表示的端到端无监督框架，用于推理对象之间的相互作用。使用视觉观测，我们的模型学习将对象与关键点坐标关联起来，并发现系统的图表达，其中包括一组关键点嵌入和它们之间的关系。然后，它使用对比估计学习一个动作条件的前向模型，以预测未来的关键点状态。通过在关键点空间中学习进行物理推理，我们的模型可以自动推广到具有不同数量的对象，新颖的背景和未见过的对象几何形状的情况。实验证明了该方法的效果。

    Object-centric representation is an essential abstraction for forward prediction. Most existing forward models learn this representation through extensive supervision (e.g., object class and bounding box) although such ground-truth information is not readily accessible in reality. To address this, we introduce KINet (Keypoint Interaction Network) -- an end-to-end unsupervised framework to reason about object interactions based on a keypoint representation. Using visual observations, our model learns to associate objects with keypoint coordinates and discovers a graph representation of the system as a set of keypoint embeddings and their relations. It then learns an action-conditioned forward model using contrastive estimation to predict future keypoint states. By learning to perform physical reasoning in the keypoint space, our model automatically generalizes to scenarios with a different number of objects, novel backgrounds, and unseen object geometries. Experiments demonstrate the ef
    
[^42]: 懒惰型在线凸优化: 切换预算下的研究

    Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.03803](http://arxiv.org/abs/2102.03803)

    本研究提出了一种懒惰型在线凸优化的算法，其在切换次数有限的情况下达到了近似最优的遗憾上界，并且在连续设置中呈现出高效的计算性能。

    

    我们研究了一种在线凸优化的变种，其中玩家在T轮中的期望切换决策不超过S次。之前的研究已经解决了离散决策设置中的类似问题，最近也在连续设置中使用自适应对手进行了研究。在本研究中，我们旨在填补这一空白，并在普遍存在的无知设置中提出计算有效的算法，为一般凸损失建立了O(T/S)的遗憾上界以及强凸损失的近似O(T/S^2)的遗憾上界。此外，对于随机独立同分布的损失，我们提出了一种简单的算法，在一般和强凸设置中遗憾仅有对数因子的乘法log T的情况下进行了log T次切换。最后，我们补充了与我们考虑的一些情况相匹配的下界来补充我们的算法。

    We study a variant of online convex optimization where the player is permitted to switch decisions at most $S$ times in expectation throughout $T$ rounds. Similar problems have been addressed in prior work for the discrete decision set setting, and more recently in the continuous setting but only with an adaptive adversary. In this work, we aim to fill the gap and present computationally efficient algorithms in the more prevalent oblivious setting, establishing a regret bound of $O(T/S)$ for general convex losses and $\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches with only a multiplicative $\log T$ factor overhead in its regret in both the general and strongly convex settings. Finally, we complement our algorithms with lower bounds that match our upper bounds in some of the cases we consider.
    
[^43]: 峰值和板条贝叶斯稀疏主成分分析

    Spike and slab Bayesian sparse principal component analysis. (arXiv:2102.00305v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2102.00305](http://arxiv.org/abs/2102.00305)

    本论文提出了一种采用峰值和板条先验的参数扩展坐标上升变分推断算法，用于解决贝叶斯稀疏主成分分析中的正交性约束问题。通过广泛的数值模拟，证明了该算法在性能上优于其他SPCA方法。

    

    稀疏主成分分析（SPCA）是高维数据降维的常用工具。然而，目前仍缺乏理论上合理且具有良好计算可扩展性的贝叶斯SPCA方法。贝叶斯SPCA面临的主要挑战之一是选择适当的先验分布用于载荷矩阵，考虑到主成分之间相互正交。我们提出了一种新颖的参数扩展坐标上升变分推断（PX-CAVI）算法。该算法利用峰值和板条先验分布，通过参数扩展来处理正交性约束。除了与两种流行的SPCA方法进行比较外，我们还介绍了PX-EM算法作为PX-CAVI算法的EM类比进行比较。通过广泛的数值模拟，我们证明了PX-CAVI算法胜过这些SPCA方法，展示了其在性能方面的优越性。我们研究了变分后验收缩速度。

    Sparse principal component analysis (SPCA) is a popular tool for dimensionality reduction in high-dimensional data. However, there is still a lack of theoretically justified Bayesian SPCA methods that can scale well computationally. One of the major challenges in Bayesian SPCA is selecting an appropriate prior for the loadings matrix, considering that principal components are mutually orthogonal. We propose a novel parameter-expanded coordinate ascent variational inference (PX-CAVI) algorithm. This algorithm utilizes a spike and slab prior, which incorporates parameter expansion to cope with the orthogonality constraint. Besides comparing to two popular SPCA approaches, we introduce the PX-EM algorithm as an EM analogue to the PX-CAVI algorithm for comparison. Through extensive numerical simulations, we demonstrate that the PX-CAVI algorithm outperforms these SPCA approaches, showcasing its superiority in terms of performance. We study the posterior contraction rate of the variational 
    
[^44]: 非参数逼近条件期望算子

    Nonparametric approximation of conditional expectation operators. (arXiv:2012.12917v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2012.12917](http://arxiv.org/abs/2012.12917)

    本文研究了在最小假设下对条件期望算子的统计逼近问题，并通过修改其定义域证明了该算子可以被再现核希尔伯特空间上的希尔伯特-施密特算子任意好地逼近。这为非参数估计提供了一种优于传统参数投影方法的方法，并揭示了非参数估计的极限对象。

    

    给定二元随机变量X，Y在某个二可数局部紧致哈斯多夫空间上的联合分布，我们研究了在最小假设下对由[Pf](x) := E[ f(Y) | X = x ]定义的L^2算子的统计逼近。通过修改其定义域，我们证明了P可以在算子范数下通过在一个再现核希尔伯特空间上作用的希尔伯特-施密特算子任意好地逼近。这一事实意味着即使P不是紧致的，我们也可以通过一个稠密子空间上的有限秩算子来统一估计P。在收敛模式方面，这样我们就得到了基于核的技术相对于传统的参数投影方法如Galerkin方法的优势。这也为非参数估计的P收敛到了哪种极限对象提供了新的视角。作为应用，我们展示了这些结果对马尔科夫过渡算子的大家族的谱分析技术是特别重要的。

    Given the joint distribution of two random variables $X,Y$ on some second countable locally compact Hausdorff space, we investigate the statistical approximation of the $L^2$-operator defined by $[Pf](x) := \mathbb{E}[ f(Y) \mid X = x ]$ under minimal assumptions. By modifying its domain, we prove that $P$ can be arbitrarily well approximated in operator norm by Hilbert-Schmidt operators acting on a reproducing kernel Hilbert space. This fact allows to estimate $P$ uniformly by finite-rank operators over a dense subspace even when $P$ is not compact. In terms of modes of convergence, we thereby obtain the superiority of kernel-based techniques over classically used parametric projection approaches such as Galerkin methods. This also provides a novel perspective on which limiting object the nonparametric estimate of $P$ converges to. As an application, we show that these results are particularly important for a large family of spectral analysis techniques for Markov transition operators
    
[^45]: 在线凸优化导论

    Introduction to Online Convex Optimization. (arXiv:1909.05207v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1909.05207](http://arxiv.org/abs/1909.05207)

    本文将优化描述为一个过程，在实际应用中，采用在线学习的优化方法对复杂环境进行优化建模，并取得了引人注目的成就。

    

    本文将优化描述为一个过程。在许多实际应用中，环境太复杂，无法建立全面的理论模型并使用经典算法和数学优化。因此，采用一种学习的优化方法，在观察到问题的更多方面时通过经验进行学习是必要且有益的。将优化视为一个过程的观点在各个领域变得突出，并在建模和成为我们日常生活一部分的系统中取得了一些引人注目的成就。

    This manuscript portrays optimization as a process. In many practical applications the environment is so complex that it is infeasible to lay out a comprehensive theoretical model and use classical algorithmic theory and mathematical optimization. It is necessary as well as beneficial to take a robust approach, by applying an optimization method that learns as one goes along, learning from experience as more aspects of the problem are observed. This view of optimization as a process has become prominent in varied fields and has led to some spectacular success in modeling and systems that are now part of our daily lives.
    
[^46]: 在多个产品类别中进行消费者选择的反事实推断

    Counterfactual Inference for Consumer Choice Across Many Product Categories. (arXiv:1906.02635v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1906.02635](http://arxiv.org/abs/1906.02635)

    本文提出了一种方法用于估计消费者在多个产品类别中的偏好选择。我们利用机器学习的概率模型，考虑了时变产品属性和产品缺货的情况，并展示了我们的模型相较于传统方法的改进之处在于能够准确估计偏好的异质性。

    

    本文提出了一种用于估计离散选择中消费者偏好的方法，其中消费者在一个类别中选择至多一个产品，但在多个类别中并行选择。消费者的效用对不同类别是可加性的。她对产品属性的偏好以及她对价格的敏感度在不同产品间有所变化，并且在一般情况下在产品间是相关的。我们借鉴了机器学习文献中关于概率模型中矩阵分解的技术，将这些方法扩展到考虑时变产品属性和产品缺货的情况。我们使用含有价格变动或缺货产品的留存数据来评估模型的性能。我们展示了我们的模型相较于考虑每个类别的传统建模方法的改进。模型的改进之一是能够准确估计偏好的异质性（通过跨类别汇总信息）。

    This paper proposes a method for estimating consumer preferences among discrete choices, where the consumer chooses at most one product in a category, but selects from multiple categories in parallel. The consumer's utility is additive in the different categories. Her preferences about product attributes as well as her price sensitivity vary across products and are in general correlated across products. We build on techniques from the machine learning literature on probabilistic models of matrix factorization, extending the methods to account for time-varying product attributes and products going out of stock. We evaluate the performance of the model using held-out data from weeks with price changes or out of stock products. We show that our model improves over traditional modeling approaches that consider each category in isolation. One source of the improvement is the ability of the model to accurately estimate heterogeneity in preferences (by pooling information across categories); 
    

