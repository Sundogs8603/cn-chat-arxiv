# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generative Entropic Neural Optimal Transport To Map Within and Across Spaces.](http://arxiv.org/abs/2310.09254) | 该论文介绍了生成熵神经最优传输在测度到测度映射中的应用，解决了处理非平方欧氏距离成本、确定性蒙格映射、映射跨不可比较空间和质量守恒约束等实际挑战。 |
| [^2] | [It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep Models.](http://arxiv.org/abs/2310.09250) | 在基于深度学习的分类模型集合中，对于正确分类的样本点，偏差和方差在样本级别上是对齐的。 |
| [^3] | [The Computational Complexity of Finding Stationary Points in Non-Convex Optimization.](http://arxiv.org/abs/2310.09157) | 本文研究了在非凸优化中找到光滑目标函数的近似稳定点的计算复杂性和查询复杂性，并给出了相应的结果。对于$d=2$的情况，提供了一种零阶算法，只需要少量的函数值查询即可找到$\varepsilon$-近似稳定点。 |
| [^4] | [Lattice Approximations in Wasserstein Space.](http://arxiv.org/abs/2310.09149) | 本论文研究了在Wasserstein空间中通过离散和分段常数测度进行的结构逼近方法。结果表明，对于满秩的格点按比例缩放后得到的Voronoi分割逼近的测度误差是$O(h)$，逼近的$N$项误差为$O(N^{-\frac1d})$，并且可以推广到非紧支撑测度。 |
| [^5] | [Automatic Music Playlist Generation via Simulation-based Reinforcement Learning.](http://arxiv.org/abs/2310.09123) | 本文提出了一个使用模拟环境的强化学习框架，通过直接优化用户满意度指标，实现个性化音乐播放列表的自动生成。我们使用修改版的深度Q网络训练出的策略能够从大型和动态的候选项目集中进行推荐，以最大化消费指标。 |
| [^6] | [MINDE: Mutual Information Neural Diffusion Estimation.](http://arxiv.org/abs/2310.09031) | MINDE是一种基于得分函数扩散模型的新方法，用于估计随机变量之间的互信息。该方法在准确性和自一致性测试方面优于其他文献中的主要替代方法。 |
| [^7] | [Subspace Adaptation Prior for Few-Shot Learning.](http://arxiv.org/abs/2310.09028) | 提出了少样本学习的子空间适应先验算法，通过同时学习初始化参数和参数子空间，可以基于任务分布决定使用梯度下降调整哪些操作子集，从而提高学习效率并降低过拟合风险。 |
| [^8] | [Fast Screening Rules for Optimal Design via Quadratic Lasso Reformulation.](http://arxiv.org/abs/2310.08939) | 通过二次Lasso重构，我们提出了用于最优设计的快速筛选规则，可以动态地在任何迭代求解器中使用。这些规则能够快速计算，并且在问题涉及高维参数空间时尤为有效。 |
| [^9] | [Adam-family Methods with Decoupled Weight Decay in Deep Learning.](http://arxiv.org/abs/2310.08858) | 本文研究了一类广泛的Adam-family方法在训练非光滑神经网络中的收敛性质，提出了一种使用分离权重衰减的新框架，并证明了其收敛性。该框架包含了许多已知的Adam-family方法，并对这些方法在训练非光滑神经网络时提供了收敛性保证。 |
| [^10] | [Leveraging Optimal Transport for Enhanced Offline Reinforcement Learning in Surgical Robotic Environments.](http://arxiv.org/abs/2310.08841) | 本论文介绍了一种利用最优输运奖励标签的算法，可以在离线情况下分配奖励给轨迹，从而减少对资源密集型实时交互的需求。 |
| [^11] | [Optimal Sample Complexity for Average Reward Markov Decision Processes.](http://arxiv.org/abs/2310.08833) | 本论文解决了对于均匀收敛的马尔可夫决策过程的长期平均奖励最大化策略学习的样本复杂度问题，并建立了一个样本复杂度为$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$的优化策略估计器。 |
| [^12] | [Confounding-Robust Policy Improvement with Human-AI Teams.](http://arxiv.org/abs/2310.08824) | 本文提出了一种通过采用边际灵敏度模型来解决人工智能与人类合作中未被观察到的混淆问题的新方法。该方法结合了领域专业知识和基于人工智能的统计建模，以控制潜在的混淆因素的影响，并通过推迟合作系统来利用不同决策者的专业知识。 |
| [^13] | [Alteration Detection of Tensor Dependence Structure via Sparsity-Exploited Reranking Algorithm.](http://arxiv.org/abs/2310.08798) | 本文提出了一种通过稀疏利用的重新排序算法来检测张量的依赖结构改变，并应用于两个样本的相关性/偏相关性比较，以提高测试效率。 |
| [^14] | [PhyloGFN: Phylogenetic inference with generative flow networks.](http://arxiv.org/abs/2310.08774) | PhyloGFN是一种基于生成流网络的系统发育推断方法，通过采样复杂的组合结构，能够产生多样且高质量的进化假设，并在边缘似然估计方面具有竞争力。 |
| [^15] | [Stabilizing Subject Transfer in EEG Classification with Divergence Estimation.](http://arxiv.org/abs/2310.08762) | 本研究在EEG分类中使用新的正则化技术减少了在未见测试对象上的性能下降。通过设计正则化惩罚和发散估计算法，我们成功地在模型训练中强制执行了统计关系，并在大量计算实验中验证了我们的方法的有效性。 |
| [^16] | [An adaptive ensemble filter for heavy-tailed distributions: tuning-free inflation and localization.](http://arxiv.org/abs/2310.08741) | 我们提出了一种自适应的集合滤波器，能够处理重尾分布，并且不需要调节膨胀和定位参数。这个滤波器通过将先验和后验更新与t-分布的精确推断相结合，提供了更好的性能和对离群观测值的鲁棒性。 |
| [^17] | [Machine Learning Who to Nudge: Causal vs Predictive Targeting in a Field Experiment on Student Financial Aid Renewal.](http://arxiv.org/abs/2310.08672) | 通过对学生进行因果与预测性定位的比较，研究探讨了在学生助学金续签领域实验中鼓励对象选择的价值。这项大规模实地实验揭示了定位干预对于不同学生的效果，为干预策略的优化提供了参考。 |
| [^18] | [Time-vectorized numerical integration for systems of ODEs.](http://arxiv.org/abs/2310.08649) | 本文介绍了一种时间向量化的数值积分方法，用于积分刚性常微分方程组，并通过伴随方法计算参数梯度。该方法在独立时间序列和连续时间步骤的批次上进行向量化，提供了更高的计算带宽，能够充分利用现代GPU并实现超过100倍的加速。 |
| [^19] | [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks.](http://arxiv.org/abs/2310.03684) | SmoothLLM是第一个用于减轻大型语言模型上越狱攻击的算法，通过在输入提示上随机扰动并汇总预测结果来检测对抗性输入，将攻击成功率降低至不到一个百分点，并提供了可证明的保证。 |
| [^20] | [Ensemble Differential Evolution with Simulation-Based Hybridization and Self-Adaptation for Inventory Management Under Uncertainty.](http://arxiv.org/abs/2309.12852) | 提出了一种集成差分进化算法，通过模拟混合和自适应机制来解决不确定条件下的库存管理问题。实证研究结果表明该方法可以提高库存管理的财务绩效和优化大搜索空间。 |
| [^21] | [Locally Adaptive and Differentiable Regression.](http://arxiv.org/abs/2308.07418) | 本文提出了一种本地自适应可微回归模型，通过对局部学习模型进行加权平均，在不同本地区域处理数据时具有竞争力，并在理论上实现更快的统计收敛以及在实际应用中改善了性能。 |
| [^22] | [OpenDataVal: a Unified Benchmark for Data Valuation.](http://arxiv.org/abs/2306.10577) | 本文介绍了一种名为OpenDataVal的基准测试框架，该框架整合了多种数据集和九种最先进的数据估值算法实现，并提供了四个下游机器学习任务来评估数据价值的质量。 |
| [^23] | [Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff.](http://arxiv.org/abs/2305.19008) | 本研究揭示了深度学习神经网路学习输入低维度表示和最小化特征映射中的复杂性/不规则性之间的权衡，控制了规律性，并利用理论工具证明了瓶颈结构的存在。 |
| [^24] | [Counterfactual Generative Models for Time-Varying Treatments.](http://arxiv.org/abs/2305.15742) | 本文研究了时间变量处理情况下的反事实生成模型，能够捕捉整个反事实分布，并且能够有效推断反事实分布的某些统计量，适用于医疗保健和公共政策制定领域。 |
| [^25] | [Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control.](http://arxiv.org/abs/2305.00700) | 本文考虑了高度过参数化的因果推断模型，探讨了多个控制单元的高维合成控制估计性能，发现增加控制单元可以帮助提高填充性能，甚至超过了预处理拟合完美的点。 |
| [^26] | [DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference.](http://arxiv.org/abs/2303.06171) | 本文提出了一种新的DP-Fast MH算法，用于大规模贝叶斯推断，具有精确、快速和隐私保护的特点。 |
| [^27] | [Statistical Learning under Heterogenous Distribution Shift.](http://arxiv.org/abs/2302.13934) | 本文研究了异质分布偏移下的统计学习问题，通过研究经验风险最小化(ERM)在不同类别的复杂性下的表现，我们发现当类别$F$相比类别$G$更“简单”时，我们的预测器对于协变量偏移具有更强的鲁棒性，尤其在$\textbf{y}$的偏移远小于$\textbf{x}$的情况下。同时，我们发现ERM的行为与正交机器学习具有类似的特性。 |
| [^28] | [Learning Graph ARMA Processes from Time-Vertex Spectra.](http://arxiv.org/abs/2302.06887) | 本研究提出了一种基于学习过程谱密度的算法，用于推断缺失的信号值和进行信号插值，实验结果显示其在时间-顶点信号估计问题中具有高准确性。 |
| [^29] | [Learning Counterfactually Invariant Predictors.](http://arxiv.org/abs/2207.09768) | 通过提出图形标准和模型无关框架CIP，我们能够学习反事实不变的预测器，以实现在现实世界中的公平性、强健性和普适性。 |
| [^30] | [Revisiting minimum description length complexity in overparameterized models.](http://arxiv.org/abs/2006.10189) | 本文重审了超参数模型中的最小描述长度复杂度。通过定义一个新的基于MDL的复杂度度量，我们发现复杂度不仅取决于参数数量，还与设计矩阵或核矩阵的奇异值和信噪比有关。 |

# 详细

[^1]: 生成熵神经最优传输在空间内外映射中的应用

    Generative Entropic Neural Optimal Transport To Map Within and Across Spaces. (arXiv:2310.09254v1 [stat.ML])

    [http://arxiv.org/abs/2310.09254](http://arxiv.org/abs/2310.09254)

    该论文介绍了生成熵神经最优传输在测度到测度映射中的应用，解决了处理非平方欧氏距离成本、确定性蒙格映射、映射跨不可比较空间和质量守恒约束等实际挑战。

    

    学习测度到测度的映射是机器学习中的一个关键任务，尤其在生成建模中占据重要地位。近年来，受最优传输理论启发的技术不断涌现。结合神经网络模型，这些方法统称为"神经最优传输"，将最优传输作为归纳偏好：这些映射应该针对给定的成本函数是最优的，能以节约的方式（通过最小化位移）在空间内或空间间移动点。这一原则在直观上是合理的，但往往面临几个实际挑战，需要调整最优传输工具箱：处理其他非平方欧氏距离成本的挑战，确定性状况下的蒙格映射公式会限制灵活性，映射在不可比较的空间中会带来多个挑战，最优传输固有的质量守恒约束可能对异常数据给予过多的重视。

    Learning measure-to-measure mappings is a crucial task in machine learning, featured prominently in generative modeling. Recent years have witnessed a surge of techniques that draw inspiration from optimal transport (OT) theory. Combined with neural network models, these methods collectively known as \textit{Neural OT} use optimal transport as an inductive bias: such mappings should be optimal w.r.t. a given cost function, in the sense that they are able to move points in a thrifty way, within (by minimizing displacements) or across spaces (by being isometric). This principle, while intuitive, is often confronted with several practical challenges that require adapting the OT toolbox: cost functions other than the squared-Euclidean cost can be challenging to handle, the deterministic formulation of Monge maps leaves little flexibility, mapping across incomparable spaces raises multiple challenges, while the mass conservation constraint inherent to OT can provide too much credit to outli
    
[^2]: 它是一种对齐，而不是权衡：重新审视深度模型中的偏差和方差

    It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep Models. (arXiv:2310.09250v1 [cs.LG])

    [http://arxiv.org/abs/2310.09250](http://arxiv.org/abs/2310.09250)

    在基于深度学习的分类模型集合中，对于正确分类的样本点，偏差和方差在样本级别上是对齐的。

    

    传统的机器学习智慧认为泛化误差可以分解为偏差和方差，并且这两个术语之间存在着"权衡"。然而，在本文中，我们展示了在基于深度学习的分类模型集合中，偏差和方差在样本级别上是"对齐"的，其中对于正确分类的样本点，均方偏差大约等于方差。我们提供了经验证据来证实这一现象在各种深度学习模型和数据集中存在。此外，我们从校准和神经崩溃的两个理论视角研究了该现象。首先，我们理论上证明在模型良好校准的假设下，我们可以观察到偏差-方差的对齐。其次，在神经崩溃理论提供的图景下，我们展示了偏差和方差之间的近似相关性。

    Classical wisdom in machine learning holds that the generalization error can be decomposed into bias and variance, and these two terms exhibit a \emph{trade-off}. However, in this paper, we show that for an ensemble of deep learning based classification models, bias and variance are \emph{aligned} at a sample level, where squared bias is approximately \emph{equal} to variance for correctly classified sample points. We present empirical evidence confirming this phenomenon in a variety of deep learning models and datasets. Moreover, we study this phenomenon from two theoretical perspectives: calibration and neural collapse. We first show theoretically that under the assumption that the models are well calibrated, we can observe the bias-variance alignment. Second, starting from the picture provided by the neural collapse theory, we show an approximate correlation between bias and variance.
    
[^3]: 寻找非凸优化中的稳定点的计算复杂性

    The Computational Complexity of Finding Stationary Points in Non-Convex Optimization. (arXiv:2310.09157v1 [math.OC])

    [http://arxiv.org/abs/2310.09157](http://arxiv.org/abs/2310.09157)

    本文研究了在非凸优化中找到光滑目标函数的近似稳定点的计算复杂性和查询复杂性，并给出了相应的结果。对于$d=2$的情况，提供了一种零阶算法，只需要少量的函数值查询即可找到$\varepsilon$-近似稳定点。

    

    寻找非凸但光滑目标函数$f$在无限制的$d$维域上的近似稳定点，即梯度近似为零的点，是经典非凸优化中最基本的问题之一。然而，当问题的维度$d$与近似误差独立时，这个问题的计算复杂性和查询复杂性仍不十分清楚。在本文中，我们展示了以下计算复杂性和查询复杂性结果：1.在无限制的域中寻找近似稳定点的问题是PLS完全问题。2.对于$d=2$，我们提供了一种零阶算法，用于寻找$\varepsilon$-近似稳定点，只需要对目标函数进行最多$O(1/\varepsilon)$次函数值查询。3.我们证明当$d=2$时，任何算法至少需要$\Omega(1/\varepsilon)$次对目标函数和/或梯度的查询来找到$\varepsilon$-近似稳定点。

    Finding approximate stationary points, i.e., points where the gradient is approximately zero, of non-convex but smooth objective functions $f$ over unrestricted $d$-dimensional domains is one of the most fundamental problems in classical non-convex optimization. Nevertheless, the computational and query complexity of this problem are still not well understood when the dimension $d$ of the problem is independent of the approximation error. In this paper, we show the following computational and query complexity results:  1. The problem of finding approximate stationary points over unrestricted domains is PLS-complete.  2. For $d = 2$, we provide a zero-order algorithm for finding $\varepsilon$-approximate stationary points that requires at most $O(1/\varepsilon)$ value queries to the objective function.  3. We show that any algorithm needs at least $\Omega(1/\varepsilon)$ queries to the objective function and/or its gradient to find $\varepsilon$-approximate stationary points when $d=2$.
    
[^4]: 微分水平空间中的格点逼近

    Lattice Approximations in Wasserstein Space. (arXiv:2310.09149v1 [stat.ML])

    [http://arxiv.org/abs/2310.09149](http://arxiv.org/abs/2310.09149)

    本论文研究了在Wasserstein空间中通过离散和分段常数测度进行的结构逼近方法。结果表明，对于满秩的格点按比例缩放后得到的Voronoi分割逼近的测度误差是$O(h)$，逼近的$N$项误差为$O(N^{-\frac1d})$，并且可以推广到非紧支撑测度。

    

    我们考虑在Wasserstein空间$W_p(\mathbb{R}^d)$中通过离散和分段常数测度来对测度进行结构逼近。我们证明，如果一个满秩的格点$\Lambda$按照$h\in(0,1]$的比例进行缩放，那么基于$h\Lambda$的Voronoi分割得到的测度逼近是$O(h)$，不论$d$或$p$的取值。之后，我们使用覆盖论证证明，对于紧支撑的测度的$N$项逼近是$O(N^{-\frac1d})$，这与最优量化器和经验测度逼近在大多数情况下已知的速率相匹配。最后，我们将这些结果推广到非紧支撑测度，要求其具有足够的衰减性质。

    We consider structured approximation of measures in Wasserstein space $W_p(\mathbb{R}^d)$ for $p\in[1,\infty)$ by discrete and piecewise constant measures based on a scaled Voronoi partition of $\mathbb{R}^d$. We show that if a full rank lattice $\Lambda$ is scaled by a factor of $h\in(0,1]$, then approximation of a measure based on the Voronoi partition of $h\Lambda$ is $O(h)$ regardless of $d$ or $p$. We then use a covering argument to show that $N$-term approximations of compactly supported measures is $O(N^{-\frac1d})$ which matches known rates for optimal quantizers and empirical measure approximation in most instances. Finally, we extend these results to noncompactly supported measures with sufficient decay.
    
[^5]: 基于模拟的强化学习自动生成音乐播放列表

    Automatic Music Playlist Generation via Simulation-based Reinforcement Learning. (arXiv:2310.09123v1 [stat.ML])

    [http://arxiv.org/abs/2310.09123](http://arxiv.org/abs/2310.09123)

    本文提出了一个使用模拟环境的强化学习框架，通过直接优化用户满意度指标，实现个性化音乐播放列表的自动生成。我们使用修改版的深度Q网络训练出的策略能够从大型和动态的候选项目集中进行推荐，以最大化消费指标。

    

    个性化音乐播放列表是音乐流媒体服务中常见的功能，但传统的技术，如协同过滤，依赖于对内容质量的明确假设，以学习如何进行推荐。这些假设往往导致离线模型目标和在线用户满意度指标之间的不一致。在本文中，我们提出了一个强化学习框架，通过使用模拟的播放列表生成环境直接优化用户满意度指标，解决了这些限制。我们使用这个模拟器开发和训练了一个修改版的深度Q网络，称为AH-DQN，在处理我们的强化学习问题的大状态和动作空间时能够解决挑战。由此产生的策略能够从大型和动态的候选项目集中进行推荐，以最大化消费指标。我们通过使用环境模拟进行离线评估和分析代理。

    Personalization of playlists is a common feature in music streaming services, but conventional techniques, such as collaborative filtering, rely on explicit assumptions regarding content quality to learn how to make recommendations. Such assumptions often result in misalignment between offline model objectives and online user satisfaction metrics. In this paper, we present a reinforcement learning framework that solves for such limitations by directly optimizing for user satisfaction metrics via the use of a simulated playlist-generation environment. Using this simulator we develop and train a modified Deep Q-Network, the action head DQN (AH-DQN), in a manner that addresses the challenges imposed by the large state and action space of our RL formulation. The resulting policy is capable of making recommendations from large and dynamic sets of candidate items with the expectation of maximizing consumption metrics. We analyze and evaluate agents offline via simulations that use environmen
    
[^6]: MINDE: 互信息神经扩散估计

    MINDE: Mutual Information Neural Diffusion Estimation. (arXiv:2310.09031v1 [cs.LG])

    [http://arxiv.org/abs/2310.09031](http://arxiv.org/abs/2310.09031)

    MINDE是一种基于得分函数扩散模型的新方法，用于估计随机变量之间的互信息。该方法在准确性和自一致性测试方面优于其他文献中的主要替代方法。

    

    在这项工作中，我们提出了一种估计随机变量之间互信息（MI）的新方法。我们的方法基于Girsanov定理的原创解释，允许我们使用基于得分的扩散模型来估计两个密度函数之间的Kullback-Leibler散度，该估计是它们得分函数之间的差异。作为副产品，我们的方法还能够估计随机变量的熵。借助这样的构建模块，我们提出了一种通用的测量MI的方法，该方法分为两个方向展开：一个使用条件扩散过程，另一个使用联合扩散过程，可以同时对两个随机变量进行建模。我们的结果来自于对我们方法的各种变体进行彻底的实验协议，表明我们的方法比文献中的主要替代方法更准确，尤其是对于具有挑战性的分布。此外，我们的方法通过了MI自一致性测试，包括...

    In this work we present a new method for the estimation of Mutual Information (MI) between random variables. Our approach is based on an original interpretation of the Girsanov theorem, which allows us to use score-based diffusion models to estimate the Kullback Leibler divergence between two densities as a difference between their score functions. As a by-product, our method also enables the estimation of the entropy of random variables. Armed with such building blocks, we present a general recipe to measure MI, which unfolds in two directions: one uses conditional diffusion process, whereas the other uses joint diffusion processes that allow simultaneous modelling of two random variables. Our results, which derive from a thorough experimental protocol over all the variants of our approach, indicate that our method is more accurate than the main alternatives from the literature, especially for challenging distributions. Furthermore, our methods pass MI self-consistency tests, includin
    
[^7]: 少样本学习的子空间适应先验

    Subspace Adaptation Prior for Few-Shot Learning. (arXiv:2310.09028v1 [cs.LG])

    [http://arxiv.org/abs/2310.09028](http://arxiv.org/abs/2310.09028)

    提出了少样本学习的子空间适应先验算法，通过同时学习初始化参数和参数子空间，可以基于任务分布决定使用梯度下降调整哪些操作子集，从而提高学习效率并降低过拟合风险。

    

    梯度基于的元学习技术旨在从一系列训练任务中提取有用的先验知识，以便使用梯度下降更高效地学习新任务。尽管这些方法在各种情况下取得了成功，但它们通常在学习新任务时适应可训练层的所有参数。这忽略了对于给定任务分布来说可能更高效的学习策略，并且可能容易过拟合，特别是在少样本学习中，其中必须从有限数量的示例中学习任务。为了解决这些问题，我们提出了子空间适应先验(SAP)，这是一种新颖的基于梯度的元学习算法，它同时学习良好的初始化参数(先验知识)和参数子空间，以操作子集的形式表示应该是可适应的。通过这种方式，SAP可以根据潜在的任务分布学习应该使用梯度下降调整的操作子集，同时降低过拟合的风险。

    Gradient-based meta-learning techniques aim to distill useful prior knowledge from a set of training tasks such that new tasks can be learned more efficiently with gradient descent. While these methods have achieved successes in various scenarios, they commonly adapt all parameters of trainable layers when learning new tasks. This neglects potentially more efficient learning strategies for a given task distribution and may be susceptible to overfitting, especially in few-shot learning where tasks must be learned from a limited number of examples. To address these issues, we propose Subspace Adaptation Prior (SAP), a novel gradient-based meta-learning algorithm that jointly learns good initialization parameters (prior knowledge) and layer-wise parameter subspaces in the form of operation subsets that should be adaptable. In this way, SAP can learn which operation subsets to adjust with gradient descent based on the underlying task distribution, simultaneously decreasing the risk of over
    
[^8]: 通过二次Lasso重构，用于最优设计的快速筛选规则

    Fast Screening Rules for Optimal Design via Quadratic Lasso Reformulation. (arXiv:2310.08939v1 [stat.ME])

    [http://arxiv.org/abs/2310.08939](http://arxiv.org/abs/2310.08939)

    通过二次Lasso重构，我们提出了用于最优设计的快速筛选规则，可以动态地在任何迭代求解器中使用。这些规则能够快速计算，并且在问题涉及高维参数空间时尤为有效。

    

    Lasso回归和最优实验设计问题都具有一个重要特性：它们的最优解通常是"稀疏的"，即只有很少一部分变量是非零的。因此，确定最优解的支持集会降低问题的维度并且能够大大简化计算。最近的研究表明，使用"平方"的$\ell_1$-范数罚项的线性回归问题等价于最优实验设计问题。本文利用这种等价关系，推导出可以用于排除无关样本的安全筛选规则。与先前存在的规则相比，新的测试方法计算速度更快，特别适用于涉及高维参数空间的问题，并可以在任何迭代求解器中动态使用，且计算开销很小。此外，我们展示了如何使用现有的路径追踪算法来计算正则化参数值的路径，并进行了数值实验证明了我们的方法的有效性。

    The problems of Lasso regression and optimal design of experiments share a critical property: their optimal solutions are typically \emph{sparse}, i.e., only a small fraction of the optimal variables are non-zero. Therefore, the identification of the support of an optimal solution reduces the dimensionality of the problem and can yield a substantial simplification of the calculations. It has recently been shown that linear regression with a \emph{squared} $\ell_1$-norm sparsity-inducing penalty is equivalent to an optimal experimental design problem. In this work, we use this equivalence to derive safe screening rules that can be used to discard inessential samples. Compared to previously existing rules, the new tests are much faster to compute, especially for problems involving a parameter space of high dimension, and can be used dynamically within any iterative solver, with negligible computational overhead. Moreover, we show how an existing homotopy algorithm to compute the regulari
    
[^9]: 使用分离权重衰减的Adam-family方法在深度学习中

    Adam-family Methods with Decoupled Weight Decay in Deep Learning. (arXiv:2310.08858v1 [math.OC])

    [http://arxiv.org/abs/2310.08858](http://arxiv.org/abs/2310.08858)

    本文研究了一类广泛的Adam-family方法在训练非光滑神经网络中的收敛性质，提出了一种使用分离权重衰减的新框架，并证明了其收敛性。该框架包含了许多已知的Adam-family方法，并对这些方法在训练非光滑神经网络时提供了收敛性保证。

    

    本文研究了一类广泛的Adam-family方法在最小化二次正则化非光滑非凸优化问题中的收敛性质，特别是在训练具有权重衰减的非光滑神经网络的情况下。受到AdamW方法的启发，我们提出了一种使用分离权重衰减的Adam-family方法的新框架。在我们的框架内，随机子梯度的一阶和二阶矩估计分别独立于权重衰减项进行更新。在合理的假设下，并且在更新主要优化变量时采用非递减步长，我们证明了我们提出的框架的收敛性质。此外，我们还展示了我们提出的框架包含了许多众所周知的Adam-family方法，从而为这些方法在训练非光滑神经网络时提供了收敛性保证。更重要的是，我们还展示了我们提出的框架渐近近似了一类次优点。

    In this paper, we investigate the convergence properties of a wide class of Adam-family methods for minimizing quadratically regularized nonsmooth nonconvex optimization problems, especially in the context of training nonsmooth neural networks with weight decay. Motivated by the AdamW method, we propose a novel framework for Adam-family methods with decoupled weight decay. Within our framework, the estimators for the first-order and second-order moments of stochastic subgradients are updated independently of the weight decay term. Under mild assumptions and with non-diminishing stepsizes for updating the primary optimization variables, we establish the convergence properties of our proposed framework. In addition, we show that our proposed framework encompasses a wide variety of well-known Adam-family methods, hence offering convergence guarantees for these methods in the training of nonsmooth neural networks. More importantly, we show that our proposed framework asymptotically approxi
    
[^10]: 在外科机器人环境中利用最优输运增强离线强化学习

    Leveraging Optimal Transport for Enhanced Offline Reinforcement Learning in Surgical Robotic Environments. (arXiv:2310.08841v1 [cs.AI])

    [http://arxiv.org/abs/2310.08841](http://arxiv.org/abs/2310.08841)

    本论文介绍了一种利用最优输运奖励标签的算法，可以在离线情况下分配奖励给轨迹，从而减少对资源密集型实时交互的需求。

    

    大多数强化学习方法通常在主动学习环境中进行研究，代理直接与环境互动，观察行动结果，并通过试错学习。然而，允许部分训练代理与真实物理系统交互会带来显著的挑战，包括高成本、安全风险和需要持续监督。离线强化学习通过利用现有数据集并减少对资源密集型实时交互的需求来解决这些成本和安全问题。然而，一个重要的挑战在于需要精心注释这些数据集的奖励。在本文中，我们介绍了一种创新的算法，即最优输运奖励（OTR）标签，用于对离线轨迹分配奖励，使用少量高质量的专家演示。OTR的核心原理是利用最优输运计算无标签轨迹与专家演示之间的最优对齐方式。

    Most Reinforcement Learning (RL) methods are traditionally studied in an active learning setting, where agents directly interact with their environments, observe action outcomes, and learn through trial and error. However, allowing partially trained agents to interact with real physical systems poses significant challenges, including high costs, safety risks, and the need for constant supervision. Offline RL addresses these cost and safety concerns by leveraging existing datasets and reducing the need for resource-intensive real-time interactions. Nevertheless, a substantial challenge lies in the demand for these datasets to be meticulously annotated with rewards. In this paper, we introduce Optimal Transport Reward (OTR) labelling, an innovative algorithm designed to assign rewards to offline trajectories, using a small number of high-quality expert demonstrations. The core principle of OTR involves employing Optimal Transport (OT) to calculate an optimal alignment between an unlabele
    
[^11]: 平均奖励马尔可夫决策过程的最优样本复杂度

    Optimal Sample Complexity for Average Reward Markov Decision Processes. (arXiv:2310.08833v1 [cs.LG])

    [http://arxiv.org/abs/2310.08833](http://arxiv.org/abs/2310.08833)

    本论文解决了对于均匀收敛的马尔可夫决策过程的长期平均奖励最大化策略学习的样本复杂度问题，并建立了一个样本复杂度为$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$的优化策略估计器。

    

    我们在假设有一个生成模型的情况下，解决了与均匀收敛的马尔可夫决策过程相关的长期平均奖励的策略学习的样本复杂性问题。在这个背景下，现有的文献提供了一个样本复杂度的上界，$ \widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$，和一个下界，$\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$。在这些表达式中，$|S|$和$|A|$分别表示状态空间和动作空间的势，$t_{\text{mix}}$作为总变异混合时间的统一上限，$\epsilon$表示误差容忍度。因此，$t_{\text{mix}}$仍然存在一个显着的差距需要填补。我们的主要贡献是建立一个优化策略的估计器，其样本复杂度为$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$，有效地达到了文献中的下界。这是通过结合算法思想实现的。

    We settle the sample complexity of policy learning for the maximization of the long run average reward associated with a uniformly ergodic Markov decision process (MDP), assuming a generative model. In this context, the existing literature provides a sample complexity upper bound of $\widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$ and a lower bound of $\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$. In these expressions, $|S|$ and $|A|$ denote the cardinalities of the state and action spaces respectively, $t_{\text{mix}}$ serves as a uniform upper limit for the total variation mixing times, and $\epsilon$ signifies the error tolerance. Therefore, a notable gap of $t_{\text{mix}}$ still remains to be bridged. Our primary contribution is to establish an estimator for the optimal policy of average reward MDPs with a sample complexity of $\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$, effectively reaching the lower bound in the literature. This is achieved by combining algorithmic idea
    
[^12]: 带有人工智能团队的混淆鲁棒的策略改进

    Confounding-Robust Policy Improvement with Human-AI Teams. (arXiv:2310.08824v1 [cs.HC])

    [http://arxiv.org/abs/2310.08824](http://arxiv.org/abs/2310.08824)

    本文提出了一种通过采用边际灵敏度模型来解决人工智能与人类合作中未被观察到的混淆问题的新方法。该方法结合了领域专业知识和基于人工智能的统计建模，以控制潜在的混淆因素的影响，并通过推迟合作系统来利用不同决策者的专业知识。

    

    人工智能与人类的合作有可能通过充分发挥人类专家和人工智能系统的相互补充优势来改变各个领域。然而，未被观察到的混淆可能会破坏这种合作的有效性，导致偏见和不可靠的结果。本文提出了一种解决人工智能与人类合作中未被观察到的混淆问题的新方法，即采用边际灵敏度模型（MSM）。我们的方法将领域专业知识与基于人工智能的统计建模相结合，以考虑潜在的可能会隐藏的混淆因素。我们提出了一个推迟合作框架，将边际灵敏度模型纳入观测数据中的策略学习，使系统能够控制未被观察到的混淆因素的影响。此外，我们提出了一个个性化的推迟合作系统，以利用不同人类决策者的多样化专业知识。通过调整潜在的偏见，我们的解决方案能够提高合作结果的可靠性。

    Human-AI collaboration has the potential to transform various domains by leveraging the complementary strengths of human experts and Artificial Intelligence (AI) systems. However, unobserved confounding can undermine the effectiveness of this collaboration, leading to biased and unreliable outcomes. In this paper, we propose a novel solution to address unobserved confounding in human-AI collaboration by employing the marginal sensitivity model (MSM). Our approach combines domain expertise with AI-driven statistical modeling to account for potential confounders that may otherwise remain hidden. We present a deferral collaboration framework for incorporating the MSM into policy learning from observational data, enabling the system to control for the influence of unobserved confounding factors. In addition, we propose a personalized deferral collaboration system to leverage the diverse expertise of different human decision-makers. By adjusting for potential biases, our proposed solution e
    
[^13]: 通过稀疏利用的重新排序算法检测张量依赖结构的改变

    Alteration Detection of Tensor Dependence Structure via Sparsity-Exploited Reranking Algorithm. (arXiv:2310.08798v1 [stat.ME])

    [http://arxiv.org/abs/2310.08798](http://arxiv.org/abs/2310.08798)

    本文提出了一种通过稀疏利用的重新排序算法来检测张量的依赖结构改变，并应用于两个样本的相关性/偏相关性比较，以提高测试效率。

    

    张量值数据经常出现在各种科学应用中，其中许多可以转化为张量依赖结构的改变检测问题。本文通过使用流行的张量正态分布来制定问题，并旨在比较张量观测值的两个样本的相关性/偏相关性。通过去相关和中心化，采用可分离的协方差结构来汇集来自不同张量模式的样本信息，以增强测试的能力。此外，我们提出了一种新颖的稀疏利用的重新排序算法(SERA)来进一步提高多重检验效率。该算法通过重新排序从主要测试统计量中导出的p值来实现，通过引入精心构造的辅助张量序列。除了张量框架外，SERA还适用于广泛的两个样本大规模推断问题与稀疏性。

    Tensor-valued data arise frequently from a wide variety of scientific applications, and many among them can be translated into an alteration detection problem of tensor dependence structures. In this article, we formulate the problem under the popularly adopted tensor-normal distributions and aim at two-sample correlation/partial correlation comparisons of tensor-valued observations. Through decorrelation and centralization, a separable covariance structure is employed to pool sample information from different tensor modes to enhance the power of the test. Additionally, we propose a novel Sparsity-Exploited Reranking Algorithm (SERA) to further improve the multiple testing efficiency. The algorithm is approached through reranking of the p-values derived from the primary test statistics, by incorporating a carefully constructed auxiliary tensor sequence. Besides the tensor framework, SERA is also generally applicable to a wide range of two-sample large-scale inference problems with spar
    
[^14]: PhyloGFN: 基于生成流网络的系统发育推断

    PhyloGFN: Phylogenetic inference with generative flow networks. (arXiv:2310.08774v1 [q-bio.PE])

    [http://arxiv.org/abs/2310.08774](http://arxiv.org/abs/2310.08774)

    PhyloGFN是一种基于生成流网络的系统发育推断方法，通过采样复杂的组合结构，能够产生多样且高质量的进化假设，并在边缘似然估计方面具有竞争力。

    

    系统发育学是计算生物学的一个分支，研究生物实体之间的进化关系。尽管有着悠久的历史和众多应用，但从序列数据推断系统发育树仍然具有挑战性：树空间的高复杂性对当前的组合和概率技术构成了重要障碍。在本文中，我们采用生成流网络（GFlowNets）的框架来解决系统发育学中的两个核心问题：基于最简原则的和贝叶斯的系统发育推断。由于GFlowNets适用于采样复杂的组合结构，它们是探索和采样树拓扑和进化距离的多模态后验分布的自然选择。我们证明了我们的摊还后验采样器PhyloGFN在真实基准数据集上产生多样且高质量的进化假设。PhyloGFN在边缘似然估计方面与之前的工作相比具有竞争力。

    Phylogenetics is a branch of computational biology that studies the evolutionary relationships among biological entities. Its long history and numerous applications notwithstanding, inference of phylogenetic trees from sequence data remains challenging: the high complexity of tree space poses a significant obstacle for the current combinatorial and probabilistic techniques. In this paper, we adopt the framework of generative flow networks (GFlowNets) to tackle two core problems in phylogenetics: parsimony-based and Bayesian phylogenetic inference. Because GFlowNets are well-suited for sampling complex combinatorial structures, they are a natural choice for exploring and sampling from the multimodal posterior distribution over tree topologies and evolutionary distances. We demonstrate that our amortized posterior sampler, PhyloGFN, produces diverse and high-quality evolutionary hypotheses on real benchmark datasets. PhyloGFN is competitive with prior works in marginal likelihood estimat
    
[^15]: EEG分类中采用发散估计稳定主体迁移

    Stabilizing Subject Transfer in EEG Classification with Divergence Estimation. (arXiv:2310.08762v1 [cs.LG])

    [http://arxiv.org/abs/2310.08762](http://arxiv.org/abs/2310.08762)

    本研究在EEG分类中使用新的正则化技术减少了在未见测试对象上的性能下降。通过设计正则化惩罚和发散估计算法，我们成功地在模型训练中强制执行了统计关系，并在大量计算实验中验证了我们的方法的有效性。

    

    电encephalogram(EEG)数据的分类模型在未见测试对象上的表现大幅下降。我们通过新的正则化技术减少性能下降问题。我们提出了几个图模型来描述EEG分类任务。从每个模型中，我们确定了在理想的训练场景下（具有无限数据和全局最优模型），应该成立但在实践中可能不成立的统计关系。我们设计了正则化惩罚来强制执行这些关系。首先，我们确定了适用作为代理数量的合适的发散（如互信息和Wasserstein-1），可以用来测量统计独立和相关关系。其次，我们提供了使用二次神经网络模型在训练过程中高效估计这些数量的算法。我们使用大型基准EEG数据集进行了大量的计算实验，比较了我们的方法与其他方法。

    Classification models for electroencephalogram (EEG) data show a large decrease in performance when evaluated on unseen test sub jects. We reduce this performance decrease using new regularization techniques during model training. We propose several graphical models to describe an EEG classification task. From each model, we identify statistical relationships that should hold true in an idealized training scenario (with infinite data and a globally-optimal model) but that may not hold in practice. We design regularization penalties to enforce these relationships in two stages. First, we identify suitable proxy quantities (divergences such as Mutual Information and Wasserstein-1) that can be used to measure statistical independence and dependence relationships. Second, we provide algorithms to efficiently estimate these quantities during training using secondary neural network models. We conduct extensive computational experiments using a large benchmark EEG dataset, comparing our propo
    
[^16]: 自适应集合滤波器对重尾分布的应用：免调节膨胀和定位

    An adaptive ensemble filter for heavy-tailed distributions: tuning-free inflation and localization. (arXiv:2310.08741v1 [stat.CO])

    [http://arxiv.org/abs/2310.08741](http://arxiv.org/abs/2310.08741)

    我们提出了一种自适应的集合滤波器，能够处理重尾分布，并且不需要调节膨胀和定位参数。这个滤波器通过将先验和后验更新与t-分布的精确推断相结合，提供了更好的性能和对离群观测值的鲁棒性。

    

    重尾分布是由非线性动力学和观测过程以及物理传感器的不确定性造成的滤波分布的常见特征。在这些情况下，基于高斯假设的卡尔曼滤波器及其集合版本 - 集合卡尔曼滤波器 (EnKF) - 的性能会下降。t-分布是一个参数化的分布族，其尾部重度由自由度 $\nu$ 调制。有趣的是，Cauchy分布和高斯分布分别对应于 $\nu = 1$ 和 $\nu = \infty$ 的t-分布的极端情况。借助于测量传输的工具 (Spantini et al., SIAM Review, 2022)，我们提出了EnKF的一般化版本，其先验到后验更新能够对t-分布进行精确推断。我们证明，这个滤波器对由观测模型生成的离群合成观测值的敏感性较小，尤其在较小的 $\nu$ 值下。此外，它恢复了卡尔曼滤波器的性能。

    Heavy tails is a common feature of filtering distributions that results from the nonlinear dynamical and observation processes as well as the uncertainty from physical sensors. In these settings, the Kalman filter and its ensemble version - the ensemble Kalman filter (EnKF) - that have been designed under Gaussian assumptions result in degraded performance. t-distributions are a parametric family of distributions whose tail-heaviness is modulated by a degree of freedom $\nu$. Interestingly, Cauchy and Gaussian distributions correspond to the extreme cases of a t-distribution for $\nu = 1$ and $\nu = \infty$, respectively. Leveraging tools from measure transport (Spantini et al., SIAM Review, 2022), we present a generalization of the EnKF whose prior-to-posterior update leads to exact inference for t-distributions. We demonstrate that this filter is less sensitive to outlying synthetic observations generated by the observation model for small $\nu$. Moreover, it recovers the Kalman filt
    
[^17]: 机器学习中的鼓励对象选择：在学生助学金续签领域实验中的因果与预测性目标定位

    Machine Learning Who to Nudge: Causal vs Predictive Targeting in a Field Experiment on Student Financial Aid Renewal. (arXiv:2310.08672v1 [econ.EM])

    [http://arxiv.org/abs/2310.08672](http://arxiv.org/abs/2310.08672)

    通过对学生进行因果与预测性定位的比较，研究探讨了在学生助学金续签领域实验中鼓励对象选择的价值。这项大规模实地实验揭示了定位干预对于不同学生的效果，为干预策略的优化提供了参考。

    

    在许多情境下，干预可能对某些人比其他人更有效，因此定位干预可能是有益的。我们通过一个规模庞大的实地实验（超过53,000名大学生）来分析在学生助学金续签前使用“鼓励”策略的价值。我们首先使用基线方法进行定位。首先，我们基于一个估计异质处理效应的因果森林进行定位，并根据估计出的拥有最高处理效应的学生来进行处理。接下来，我们评估两种替代的定位策略，一种是针对在没有干预的情况下预测到低助学金续签概率的学生，另一种是针对预测到高概率的学生。预测的基线结果并不是定位的理想标准，而且在先验上也不清楚是优先考虑低、高还是中间的预测。

    In many settings, interventions may be more effective for some individuals than others, so that targeting interventions may be beneficial. We analyze the value of targeting in the context of a large-scale field experiment with over 53,000 college students, where the goal was to use "nudges" to encourage students to renew their financial-aid applications before a non-binding deadline. We begin with baseline approaches to targeting. First, we target based on a causal forest that estimates heterogeneous treatment effects and then assigns students to treatment according to those estimated to have the highest treatment effects. Next, we evaluate two alternative targeting policies, one targeting students with low predicted probability of renewing financial aid in the absence of the treatment, the other targeting those with high probability. The predicted baseline outcome is not the ideal criterion for targeting, nor is it a priori clear whether to prioritize low, high, or intermediate predic
    
[^18]: 时间向量化数值积分用于ODE系统

    Time-vectorized numerical integration for systems of ODEs. (arXiv:2310.08649v1 [math.NA])

    [http://arxiv.org/abs/2310.08649](http://arxiv.org/abs/2310.08649)

    本文介绍了一种时间向量化的数值积分方法，用于积分刚性常微分方程组，并通过伴随方法计算参数梯度。该方法在独立时间序列和连续时间步骤的批次上进行向量化，提供了更高的计算带宽，能够充分利用现代GPU并实现超过100倍的加速。

    

    在科学问题中，刚性的常微分方程组和稀疏训练数据是很常见的。本文描述了用于积分刚性常微分方程组的高效隐式向量化方法，并通过伴随方法计算参数梯度。主要创新是在独立时间序列的数量和连续时间步骤的批次或“块”上向量化问题，从而有效地向量化隐式ODE系统的组装。后向Euler方法的线性化隐式系统的块双对角结构允许进一步使用并行循环约化（PCR）进行向量化。在输入数据的两个轴上进行向量化，为计算设备提供了更高的计算带宽，使得即使是相对稀疏的问题也能充分利用现代GPU，并实现了超过100倍的加速，与标准的顺序时间积分相比。

    Stiff systems of ordinary differential equations (ODEs) and sparse training data are common in scientific problems. This paper describes efficient, implicit, vectorized methods for integrating stiff systems of ordinary differential equations through time and calculating parameter gradients with the adjoint method. The main innovation is to vectorize the problem both over the number of independent times series and over a batch or "chunk" of sequential time steps, effectively vectorizing the assembly of the implicit system of ODEs. The block-bidiagonal structure of the linearized implicit system for the backward Euler method allows for further vectorization using parallel cyclic reduction (PCR). Vectorizing over both axes of the input data provides a higher bandwidth of calculations to the computing device, allowing even problems with comparatively sparse data to fully utilize modern GPUs and achieving speed ups of greater than 100x, compared to standard, sequential time integration. We 
    
[^19]: SmoothLLM：防御大型语言模型免受越狱攻击

    SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])

    [http://arxiv.org/abs/2310.03684](http://arxiv.org/abs/2310.03684)

    SmoothLLM是第一个用于减轻大型语言模型上越狱攻击的算法，通过在输入提示上随机扰动并汇总预测结果来检测对抗性输入，将攻击成功率降低至不到一个百分点，并提供了可证明的保证。

    

    尽管努力将大型语言模型（LLM）与人类价值观保持一致，但广泛使用的LLM（如GPT、Llama、Claude和PaLM）仍然容易受到越狱攻击，即对目标LLM进行欺骗，以生成不合适的内容。为了解决这个漏洞，我们提出了SmoothLLM，这是第一个旨在减轻LLM上的越狱攻击的算法。基于我们的发现，对抗性生成的提示对字符级别的改变很脆弱，我们的防御首先随机扰动给定输入提示的多个副本，然后汇总相应的预测结果来检测对抗性输入。SmoothLLM将众多热门LLM的攻击成功率降低至不到一个百分点，避免了不必要的保守性，并对攻击缓解提供了可证明的保证。此外，我们的防御使用的查询数量比现有的攻击方法少得多，并且与任何LLM兼容。

    Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.
    
[^20]: 基于模拟混合和自适应的集成差分进化算法用于不确定条件下的库存管理

    Ensemble Differential Evolution with Simulation-Based Hybridization and Self-Adaptation for Inventory Management Under Uncertainty. (arXiv:2309.12852v1 [math.OC])

    [http://arxiv.org/abs/2309.12852](http://arxiv.org/abs/2309.12852)

    提出了一种集成差分进化算法，通过模拟混合和自适应机制来解决不确定条件下的库存管理问题。实证研究结果表明该方法可以提高库存管理的财务绩效和优化大搜索空间。

    

    本研究提出了一种基于模拟混合和自适应的集成差分进化算法（EDESH-SA）来解决不确定条件下的库存管理问题。该算法将差分进化算法与模拟混合方法相结合，并通过自适应机制动态地改变变异率和交叉率。由于其适应性，该算法能够处理库存管理中的复杂性和不确定性。通过使用蒙特卡洛模拟（MCS），本研究考虑了连续审查（CR）库存策略，并考虑了随机性和不同的需求情景。这种基于模拟的方法可以真实地评估所提算法在实际环境中解决库存管理挑战的适用性。实证研究的结果显示了所提方法在提高库存管理的财务绩效和优化大搜索空间方面的潜力。

    This study proposes an Ensemble Differential Evolution with Simula-tion-Based Hybridization and Self-Adaptation (EDESH-SA) approach for inven-tory management (IM) under uncertainty. In this study, DE with multiple runs is combined with a simulation-based hybridization method that includes a self-adaptive mechanism that dynamically alters mutation and crossover rates based on the success or failure of each iteration. Due to its adaptability, the algorithm is able to handle the complexity and uncertainty present in IM. Utilizing Monte Carlo Simulation (MCS), the continuous review (CR) inventory strategy is ex-amined while accounting for stochasticity and various demand scenarios. This simulation-based approach enables a realistic assessment of the proposed algo-rithm's applicability in resolving the challenges faced by IM in practical settings. The empirical findings demonstrate the potential of the proposed method to im-prove the financial performance of IM and optimize large search spa
    
[^21]: 本地自适应可微回归

    Locally Adaptive and Differentiable Regression. (arXiv:2308.07418v1 [cs.LG])

    [http://arxiv.org/abs/2308.07418](http://arxiv.org/abs/2308.07418)

    本文提出了一种本地自适应可微回归模型，通过对局部学习模型进行加权平均，在不同本地区域处理数据时具有竞争力，并在理论上实现更快的统计收敛以及在实际应用中改善了性能。

    

    过度参数化模型，如深度神经网络和随机森林，在机器学习中变得非常受欢迎。然而，在现代超参数化的本地自适应模型中，常见的连续性和可微性目标往往被忽视。我们提出了一个通用框架，通过在对应的本地区域中对局部学习模型进行加权平均来构建全局连续可微模型。该模型在处理具有不同密度或不同本地区域中的函数值尺度的数据时具有竞争力。我们证明，当我们在本地模型中混合使用核岭和多项式回归项，并对它们进行连续拼接时，在理论上实现更快的统计收敛，并在各种实际环境中实现改进的性能。

    Over-parameterized models like deep nets and random forests have become very popular in machine learning. However, the natural goals of continuity and differentiability, common in regression models, are now often ignored in modern overparametrized, locally-adaptive models. We propose a general framework to construct a global continuous and differentiable model based on a weighted average of locally learned models in corresponding local regions. This model is competitive in dealing with data with different densities or scales of function values in different local regions. We demonstrate that when we mix kernel ridge and polynomial regression terms in the local models, and stitch them together continuously, we achieve faster statistical convergence in theory and improved performance in various practical settings.
    
[^22]: OpenDataVal：一种数据价值评估的统一基准测试

    OpenDataVal: a Unified Benchmark for Data Valuation. (arXiv:2306.10577v1 [cs.LG])

    [http://arxiv.org/abs/2306.10577](http://arxiv.org/abs/2306.10577)

    本文介绍了一种名为OpenDataVal的基准测试框架，该框架整合了多种数据集和九种最先进的数据估值算法实现，并提供了四个下游机器学习任务来评估数据价值的质量。

    

    评估单个数据点的质量和影响对于提高模型性能和减轻训练数据集中不良偏差至关重要。尽管已经提出了几个数据估值算法来量化数据质量，但还缺乏一个系统化和标准化的数据估值基准测试系统。本文介绍了OpenDataVal，一种易于使用和统一的基准测试框架，使研究人员和从业者能够应用和比较各种数据估值算法。OpenDataVal提供了一个综合环境，包括（i）各种图像，自然语言和表格数据集，（ii）九种不同的最先进的数据估值算法的实现，以及（iii）可以导入任何scikit-learn模型的预测模型API。此外，我们提出了四个下游机器学习任务，用于评估数据值的质量。我们使用OpenDataVal进行基准测试分析，量化并比较不同数据估值算法在不同数据集上的表现。

    Assessing the quality and impact of individual data points is critical for improving model performance and mitigating undesirable biases within the training dataset. Several data valuation algorithms have been proposed to quantify data quality, however, there lacks a systemic and standardized benchmarking system for data valuation. In this paper, we introduce OpenDataVal, an easy-to-use and unified benchmark framework that empowers researchers and practitioners to apply and compare various data valuation algorithms. OpenDataVal provides an integrated environment that includes (i) a diverse collection of image, natural language, and tabular datasets, (ii) implementations of nine different state-of-the-art data valuation algorithms, and (iii) a prediction model API that can import any models in scikit-learn. Furthermore, we propose four downstream machine learning tasks for evaluating the quality of data values. We perform benchmarking analysis using OpenDataVal, quantifying and comparin
    
[^23]: 学习特征中的瓶颈结构：低维度与规律性的权衡

    Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff. (arXiv:2305.19008v1 [cs.LG])

    [http://arxiv.org/abs/2305.19008](http://arxiv.org/abs/2305.19008)

    本研究揭示了深度学习神经网路学习输入低维度表示和最小化特征映射中的复杂性/不规则性之间的权衡，控制了规律性，并利用理论工具证明了瓶颈结构的存在。

    

    先前研究表明，具有大深度$L$和$L_{2}$正则化的DNN偏向于学习输入的低维表示，可以解释为最小化学习函数$f$的秩$R^{(0)}(f)$的概念，其被推测为瓶颈秩。我们计算了这个结果的有限深度修正，揭示了一个度量$R^{(1)}$的规律性，它控制了雅可比矩阵$\left|Jf(x)\right|_{+}$的伪行列式并在组合和加法下是次可加的。这使得网络可以在学习低维表示和最小化特征映射中的复杂性/不规则性之间保持平衡，从而学习“正确”的内部尺寸。我们还展示了大学习速率如何控制学习函数的规律性。最后，我们使用这些理论工具证明了瓶颈结构在$L\to\infty$时在学习特征中的猜想：对于大深度，几乎所有的隐藏表示都集中在...

    Previous work has shown that DNNs with large depth $L$ and $L_{2}$-regularization are biased towards learning low-dimensional representations of the inputs, which can be interpreted as minimizing a notion of rank $R^{(0)}(f)$ of the learned function $f$, conjectured to be the Bottleneck rank. We compute finite depth corrections to this result, revealing a measure $R^{(1)}$ of regularity which bounds the pseudo-determinant of the Jacobian $\left|Jf(x)\right|_{+}$ and is subadditive under composition and addition. This formalizes a balance between learning low-dimensional representations and minimizing complexity/irregularity in the feature maps, allowing the network to learn the `right' inner dimension. We also show how large learning rates also control the regularity of the learned function. Finally, we use these theoretical tools to prove the conjectured bottleneck structure in the learned features as $L\to\infty$: for large depths, almost all hidden representations concentrates aroun
    
[^24]: 时间变化处理的反事实生成模型

    Counterfactual Generative Models for Time-Varying Treatments. (arXiv:2305.15742v1 [stat.ML])

    [http://arxiv.org/abs/2305.15742](http://arxiv.org/abs/2305.15742)

    本文研究了时间变量处理情况下的反事实生成模型，能够捕捉整个反事实分布，并且能够有效推断反事实分布的某些统计量，适用于医疗保健和公共政策制定领域。

    

    估计平均因果效应是测试新疗法的常用做法。然而，平均效应会掩盖反事实分布中重要的个体特征，可能会引起安全、公平和道德方面的担忧。这个问题在时间设置中更加严重，因为处理是时序的和时变的，对反事实分布产生了错综复杂的影响。本文提出了一种新的条件生成建模方法，以捕获整个反事实分布，允许对反事实分布的某些统计量进行有效推断。这使得所提出的方法尤其适用于医疗保健和公共政策制定领域。我们的生成建模方法通过边际结构模型谨慎地解决了观察数据和目标反事实分布之间的分布不匹配。在合成和真实数据上，我们的方法优于现有的基线方法。

    Estimating average causal effects is a common practice to test new treatments. However, the average effect ''masks'' important individual characteristics in the counterfactual distribution, which may lead to safety, fairness, and ethical concerns. This issue is exacerbated in the temporal setting, where the treatment is sequential and time-varying, leading to an intricate influence on the counterfactual distribution. In this paper, we propose a novel conditional generative modeling approach to capture the whole counterfactual distribution, allowing efficient inference on certain statistics of the counterfactual distribution. This makes the proposed approach particularly suitable for healthcare and public policy making. Our generative modeling approach carefully tackles the distribution mismatch in the observed data and the targeted counterfactual distribution via a marginal structural model. Our method outperforms state-of-the-art baselines on both synthetic and real data.
    
[^25]: 因果推断中的双重和单一下降现象，及其在高维合成控制中的应用。

    Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control. (arXiv:2305.00700v1 [econ.EM])

    [http://arxiv.org/abs/2305.00700](http://arxiv.org/abs/2305.00700)

    本文考虑了高度过参数化的因果推断模型，探讨了多个控制单元的高维合成控制估计性能，发现增加控制单元可以帮助提高填充性能，甚至超过了预处理拟合完美的点。

    

    本文针对机器学习中的双重下降现象，考虑了高度过参数化的因果推断模型，包括多个控制单元的合成控制。在这种模型中，可能存在太多的自由参数，以至于模型可以完美地拟合训练数据。本文首先以高维线性回归模型为例，研究薪资数据的填充，发现比简单模型更多的协变量对于模型性能的提升很有效。本文的主要贡献在于探讨了多个控制单元的高维合成控制估计性能，发现增加控制单元可以帮助提高填充性能，甚至超过了预处理拟合完美的点。此外，本文提出一种统一的理论视角来解释这些高维模型的性能，即将更复杂的模型视为对简单模型的模型平均估计。

    Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parametrized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. As a motivating example, we first investigate high-dimensional linear regression for imputing wage data, where we find that models with many more covariates than sample size can outperform simple ones. As our main contribution, we document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We then provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we 
    
[^26]: DP-Fast MH: 大规模贝叶斯推断的私有、快速、准确的Metropolis-Hastings算法

    DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference. (arXiv:2303.06171v1 [cs.LG])

    [http://arxiv.org/abs/2303.06171](http://arxiv.org/abs/2303.06171)

    本文提出了一种新的DP-Fast MH算法，用于大规模贝叶斯推断，具有精确、快速和隐私保护的特点。

    This paper proposes a new DP-Fast MH algorithm for large-scale Bayesian inference, which is accurate, fast, and privacy-preserving.

    贝叶斯推断提供了一个从复杂数据中学习和在不确定性下推理的原则性框架。它已经广泛应用于机器学习任务，如医学诊断、药物设计和政策制定。在这些常见应用中，数据可能非常敏感。差分隐私（DP）提供了具有强大最坏情况隐私保证的数据分析工具，并已发展成为隐私保护数据分析的主要方法。在本文中，我们研究了Metropolis-Hastings（MH）算法，这是最基本的MCMC方法之一，用于差分隐私下的大规模贝叶斯推断。虽然大多数现有的私有MCMC算法为了获得隐私而牺牲了准确性和效率，但我们提供了第一个精确且快速的DP MH算法，大多数迭代中仅使用一个小批量的数据。我们进一步揭示了隐私、可扩展性（即批量大小）和效率（即收敛速度）之间的三重权衡，从理论上说明了这一点。

    Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, the data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically char
    
[^27]: 异质分布偏移下的统计学习

    Statistical Learning under Heterogenous Distribution Shift. (arXiv:2302.13934v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13934](http://arxiv.org/abs/2302.13934)

    本文研究了异质分布偏移下的统计学习问题，通过研究经验风险最小化(ERM)在不同类别的复杂性下的表现，我们发现当类别$F$相比类别$G$更“简单”时，我们的预测器对于协变量偏移具有更强的鲁棒性，尤其在$\textbf{y}$的偏移远小于$\textbf{x}$的情况下。同时，我们发现ERM的行为与正交机器学习具有类似的特性。

    

    本文研究了从随机变量对$(\mathbf{x},\mathbf{y})$中预测目标$\mathbf{z}$, 其中真实的预测器是加法的$\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$。我们研究了在给定训练分布上拟合的函数$f+g$, $f \in F$和$g \in G$上的经验风险最小化(ERM)在表现上的差异，但在测试分布上得到评估时会显示出协变量偏移。我们的研究表明，当类别$F$比$G$更“简单”（例如，以度量熵为衡量标准）时，我们的预测器对于协变量偏移的抗干扰能力更强，其中$\textbf{y}$的偏移要远小于$\textbf{x}$的偏移。我们的分析表明，ERM的行为与正交机器学习$\textbf{ qualitatively similarly}$：ERM恢复预测器中的$f$成分的速率仅对于类别$G$的复杂性具有较低阶的依赖性，调整后...

    This paper studies the prediction of a target $\mathbf{z}$ from a pair of random variables $(\mathbf{x},\mathbf{y})$, where the ground-truth predictor is additive $\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$. We study the performance of empirical risk minimization (ERM) over functions $f+g$, $f \in F$ and $g \in G$, fit on a given training distribution, but evaluated on a test distribution which exhibits covariate shift. We show that, when the class $F$ is "simpler" than $G$ (measured, e.g., in terms of its metric entropy), our predictor is more resilient to $\textbf{heterogenous covariate shifts}$ in which the shift in $\mathbf{x}$ is much greater than that in $\mathbf{y}$. Our analysis proceeds by demonstrating that ERM behaves $\textbf{qualitatively similarly to orthogonal machine learning}$: the rate at which ERM recovers the $f$-component of the predictor has only a lower-order dependence on the complexity of the class $G$, adjus
    
[^28]: 从时间-顶点谱学习图ARMA过程

    Learning Graph ARMA Processes from Time-Vertex Spectra. (arXiv:2302.06887v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.06887](http://arxiv.org/abs/2302.06887)

    本研究提出了一种基于学习过程谱密度的算法，用于推断缺失的信号值和进行信号插值，实验结果显示其在时间-顶点信号估计问题中具有高准确性。

    

    将时间变化的图信号建模为稳态时间-顶点随机过程，可以通过有效地利用过程在不同图节点和时间瞬间之间的相关性模式来推断缺失的信号值。在这项研究中，我们提出了一种算法，用于基于学习过程的不完整实现的联合时间-顶点功率谱密度来计算图自回归移动平均（图ARMA）过程，以用于信号插值任务。我们的解决方案首先通过部分观察到的实现粗略估计过程的联合谱，然后通过凸松弛将其投影到图ARMA过程的谱流形上来改进这个估计。然后，基于学习的模型估计最初缺失的信号值。实验结果表明，所提出的方法在时间-顶点信号估计问题中达到了很高的准确度。

    The modeling of time-varying graph signals as stationary time-vertex stochastic processes permits the inference of missing signal values by efficiently employing the correlation patterns of the process across different graph nodes and time instants. In this study, we propose an algorithm for computing graph autoregressive moving average (graph ARMA) processes based on learning the joint time-vertex power spectral density of the process from its incomplete realizations for the task of signal interpolation. Our solution relies on first roughly estimating the joint spectrum of the process from partially observed realizations and then refining this estimate by projecting it onto the spectrum manifold of the graph ARMA process through convex relaxations. The initially missing signal values are then estimated based on the learnt model. Experimental results show that the proposed approach achieves high accuracy in time-vertex signal estimation problems.
    
[^29]: 学习反事实不变的预测器

    Learning Counterfactually Invariant Predictors. (arXiv:2207.09768v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.09768](http://arxiv.org/abs/2207.09768)

    通过提出图形标准和模型无关框架CIP，我们能够学习反事实不变的预测器，以实现在现实世界中的公平性、强健性和普适性。

    

    反事实不变性（CI）的概念对于在现实世界中公平、强健和具有普适性的预测器至关重要。我们提出了一种图形标准，它以观测分布的条件独立性作为预测器反事实不变的充分条件。为了学习这样的预测器，我们提出了一个称为Counterfactually Invariant Prediction（CIP）的模型无关框架，基于Hilbert-Schmidt条件独立准则（HSCIC），一种基于核的条件依赖度量。我们的实验结果在包括标量和多变量设置在内的各种模拟和真实世界数据集上证明了CIP在强制反事实不变性方面的有效性。

    Notions of counterfactual invariance (CI) have proven essential for predictors that are fair, robust, and generalizable in the real world. We propose graphical criteria that yield a sufficient condition for a predictor to be counterfactually invariant in terms of a conditional independence in the observational distribution. In order to learn such predictors, we propose a model-agnostic framework, called Counterfactually Invariant Prediction (CIP), building on the Hilbert-Schmidt Conditional Independence Criterion (HSCIC), a kernel-based conditional dependence measure. Our experimental results demonstrate the effectiveness of CIP in enforcing counterfactual invariance across various simulated and real-world datasets including scalar and multi-variate settings.
    
[^30]: 重审超参数模型中的最小描述长度复杂度

    Revisiting minimum description length complexity in overparameterized models. (arXiv:2006.10189v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.10189](http://arxiv.org/abs/2006.10189)

    本文重审了超参数模型中的最小描述长度复杂度。通过定义一个新的基于MDL的复杂度度量，我们发现复杂度不仅取决于参数数量，还与设计矩阵或核矩阵的奇异值和信噪比有关。

    

    复杂度是统计学习理论中的一个基本概念，旨在提供有关泛化性能的信息。在低维度情况下，参数数量在一定程度上是成功的，但在超参数模型中，当参数数量超过训练样本数量时，其合理性不足。我们重新审视了基于Rissanen最小描述长度（MDL）原理的复杂度度量，并定义了一种新的适用于超参数模型的基于MDL的复杂度（MDL-COMP）。MDL-COMP通过对一个良好的Ridge估计类所引起的编码而定义出来的最优性准则。我们对线性模型和核方法的MDL-COMP进行了广泛的理论刻画，并表明它不仅是参数数量的函数，而是设计或核矩阵的奇异值和信噪比的函数。对于具有n个观测值，d个参数和独立同分布的高斯预测因子的线性模型，MDL-COMP的尺度是线性的。

    Complexity is a fundamental concept underlying statistical learning theory that aims to inform generalization performance. Parameter count, while successful in low-dimensional settings, is not well-justified for overparameterized settings when the number of parameters is more than the number of training samples. We revisit complexity measures based on Rissanen's principle of minimum description length (MDL) and define a novel MDL-based complexity (MDL-COMP) that remains valid for overparameterized models. MDL-COMP is defined via an optimality criterion over the encodings induced by a good Ridge estimator class. We provide an extensive theoretical characterization of MDL-COMP for linear models and kernel methods and show that it is not just a function of parameter count, but rather a function of the singular values of the design or the kernel matrix and the signal-to-noise ratio. For a linear model with $n$ observations, $d$ parameters, and i.i.d. Gaussian predictors, MDL-COMP scales li
    

