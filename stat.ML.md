# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Fast and Accurate Reduced-Order Modeling of a MOOSE-based Additive Manufacturing Model with Operator Learning.](http://arxiv.org/abs/2308.02462) | 本研究利用运算学习方法，在MOOSE框架中开发了一个快速准确的减阶模型，用于增材制造中的控制和优化过程，通过改变过程变量来学习微分方程，使用Fourier神经运算器和深度运算器网络开发了时间相关响应的减阶模型。 |
| [^2] | [Generative Modelling of L\'{e}vy Area for High Order SDE Simulation.](http://arxiv.org/abs/2308.02452) | 本文提出了一种基于深度学习的模型LévyGAN，用于生成条件于布朗增量的Lévy区域的近似样本。通过“桥翻转”操作，输出的样本可以精确匹配所有奇数阶矩，解决了非高斯性质下的抽样困难问题。 |
| [^3] | [Pruning a neural network using Bayesian inference.](http://arxiv.org/abs/2308.02451) | 使用贝叶斯推断修剪神经网络的新方法可以实现理想的稀疏程度，同时保持竞争力的准确性。 |
| [^4] | [Differentiable short-time Fourier transform with respect to the hop length.](http://arxiv.org/abs/2308.02421) | 本文提出了一种基于跳步长度可微分的短时傅里叶变换，通过使跳步长度连续，实现了梯度优化的时间定位控制，提供了更好的优化效果和更高的计算效率。该方法可以轻松集成到现有算法和神经网络中。 |
| [^5] | [A State-Space Perspective on Modelling and Inference for Online Skill Rating.](http://arxiv.org/abs/2308.02414) | 本文提供了对竞技体育技能评级主要方法的全面回顾，并提出了采用状态空间模型视角的建议。通过使用状态空间模型视角，玩家的技能可以表示为随时间变化的变量，而比赛结果则是唯一的观测量。该视角有助于解耦建模和推理，并促进通用推理工具的发展。在构建技能评级的状态空间模型方面，本文探讨了基本步骤，同时还讨论了滤波、平滑和参数估计等推理阶段。在面对高维场景中的计算挑战时，本文强调了所采用的近似和简化方法。该文提供了对记录的流行方法的简明总结。 |
| [^6] | [Classifying Causal Structures: Ascertaining when Classical Correlations are Constrained by Inequalities.](http://arxiv.org/abs/2308.02380) | 本研究发展了一种方法，通过使用d分离、e分离和不相容支持来检测不同的因果场景，从而将具有不等式约束和不具有不等式约束的场景进行分类。 |
| [^7] | [Intensity-free Integral-based Learning of Marked Temporal Point Processes.](http://arxiv.org/abs/2308.02360) | 该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。 |
| [^8] | [Learning Networks from Gaussian Graphical Models and Gaussian Free Fields.](http://arxiv.org/abs/2308.02344) | 本文研究了从重复测量的高斯自由场中估计加权网络结构的问题，并提出了一种基于高斯分布傅里叶分析特性的新型估计器。该方法利用了从观测数据中构造的复数值统计量，具有研究价值。 |
| [^9] | [A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation.](http://arxiv.org/abs/2308.02293) | 通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。 |
| [^10] | [Adaptive Proximal Gradient Method for Convex Optimization.](http://arxiv.org/abs/2308.02261) | 本文提出了自适应版本的梯度下降（GD）和近端梯度方法（ProxGD），通过利用局部曲率信息完全自适应。所提出的方法具有收敛性，且允许使用更大的步长。 |
| [^11] | [Likelihood-ratio-based confidence intervals for neural networks.](http://arxiv.org/abs/2308.02221) | 本文介绍了一种新颖的基于似然比的方法，用于构建神经网络的置信区间。该方法能够构建不对称区间，考虑了训练时间、网络架构和正则化技术等因素。尽管方法实现昂贵，但在特定领域中具有重要应用潜力。 |
| [^12] | [Incorporating Recklessness to Collaborative Filtering based Recommender Systems.](http://arxiv.org/abs/2308.02058) | 本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。 |
| [^13] | [Robust Independence Tests with Finite Sample Guarantees for Synchronous Stochastic Linear Systems.](http://arxiv.org/abs/2308.02054) | 本文介绍了一种针对同步随机线性系统的鲁棒独立性检验方法，可以提供非渐近性保证的显著水平。该方法结合了置信区间估计、排列检验以及一般的依赖度量，以检测系统之间的任何非线性依赖关系。 |
| [^14] | [Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods.](http://arxiv.org/abs/2308.01938) | 本文提出了两种新的在线多任务学习方法，分别基于递归最小二乘和递归核方法。与基于梯度下降或不精确逼近的方法不同，我们的方法在每个实例的代价上具有二次复杂度。我们将这些方法应用于风力短期预测挑战，并与其他竞争者进行了比较。 |
| [^15] | [On Interpolating Experts and Multi-Armed Bandits.](http://arxiv.org/abs/2307.07264) | 学习专家建议和多臂赌博是两个经典的在线决策问题，我们研究了两者之间的插值问题。我们提出了$\mathbf{m}$-MAB的极小后悔界并设计了$\mathbf{m}$-BAI的最优PAC算法，该算法旨在以尽可能少的轮数确定损失最小的臂。 |
| [^16] | [Learned harmonic mean estimation of the marginal likelihood with normalizing flows.](http://arxiv.org/abs/2307.00048) | 本文研究使用归一化流学习边缘似然的调和平均估计，在贝叶斯模型选择中解决了原始方法中的方差爆炸问题。 |
| [^17] | [Estimation of Ridge Using Nonlinear Transformation on Density Function.](http://arxiv.org/abs/2306.05722) | 本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。 |
| [^18] | [Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise.](http://arxiv.org/abs/2305.13498) | 本文研究了带有测量噪声的Ornstein-Uhlenbeck过程参数估计，提出了算法和方法能够分离热噪声和乘性噪声，并改善数据分析的参数估计精度。 |
| [^19] | [Universal Morphology Control via Contextual Modulation.](http://arxiv.org/abs/2302.11070) | 本文提出了通过上下文调节实现通用形态控制的方法，包括使用超网络生成形态相关的控制参数以及利用固定的注意机制调节机器人中不同肢体之间的交互作用。这种方法可以提高学习效率和泛化能力。 |
| [^20] | [Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior: From Theory to Practice.](http://arxiv.org/abs/2211.07206) | 本研究使用PAC-Bayesian理论提供了元学习的泛化界限，并推导出了最佳性能保证的闭式优化超后验(PACOH)。通过理论分析和案例研究，我们展示了这些保证在元学习中相对于PAC-Bayesian每个任务学习界限的改进。 |
| [^21] | [Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS).](http://arxiv.org/abs/2210.08549) | 该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。 |
| [^22] | [Exponential Concentration of Stochastic Approximation with Non-vanishing Gradient.](http://arxiv.org/abs/2208.07243) | 本研究分析了非零梯度的随机逼近算法的行为，并证明了指数级的集中性界限，这对于投影随机梯度下降算法的收敛速度有重要意义。 |
| [^23] | [Inference-Based Quantum Sensing.](http://arxiv.org/abs/2206.09919) | 这项工作提出了一种基于推理的量子感知方案，可以通过测量系统响应来推断未知参数的值，并确定方案的敏感性。 |
| [^24] | [Improved Algorithms for Bandit with Graph Feedback via Regret Decomposition.](http://arxiv.org/abs/2205.15076) | 通过遗憾分解，我们提出了一种基于反馈图划分的新算法框架，该框架统一了多臂赌博机和学习与专家建议的最优算法，对包括许多图类族在内的范围更广的图家族得到了改进和最优遗憾界限。 |
| [^25] | [Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming.](http://arxiv.org/abs/2205.13687) | 本篇论文提出了一种用于等式约束的随机非线性优化问题的统计推断方法，通过基于草图的顺序二次规划（StoSQP）进行求解，并且允许自适应选择随机步长和使用高效随机迭代求解器来降低计算成本。 |
| [^26] | [A New Basis for Sparse Principal Component Analysis.](http://arxiv.org/abs/2007.00596) | 我们提出了一种新的方法来进行稀疏主成分分析，该方法使用正交旋转来获得近似稀疏的特征值基。与以往方法不同的是，我们的方法使稀疏成分不需要是主特征向量，而可以是它们的混合。这一方法不需要进行“缩减”操作或使用多个调参参数。 |

# 详细

[^1]: 基于MOOSE框架的快速准确的减阶建模在增材制造中的运算学习

    Fast and Accurate Reduced-Order Modeling of a MOOSE-based Additive Manufacturing Model with Operator Learning. (arXiv:2308.02462v1 [cs.LG])

    [http://arxiv.org/abs/2308.02462](http://arxiv.org/abs/2308.02462)

    本研究利用运算学习方法，在MOOSE框架中开发了一个快速准确的减阶模型，用于增材制造中的控制和优化过程，通过改变过程变量来学习微分方程，使用Fourier神经运算器和深度运算器网络开发了时间相关响应的减阶模型。

    

    增材制造中的一个主要挑战是在运行时通过调整制造过程参数来达到特定的材料属性。这种调整往往增加了用于增材制造中的现有模拟工具的计算负荷。本研究的目标是为在多物理面向对象模拟环境（MOOSE）框架中开发的增材制造模型构建一个快速准确的减阶模型（ROM），从而最终减少增材制造控制和优化过程的时间/成本。我们采用了运算学习（OL）方法，通过改变激光的高斯点热源中的过程变量，学习了一系列微分方程。具体而言，我们使用了Fourier神经运算器（FNO）和深度运算器网络（DeepONet）来开发时间相关响应的减阶模型。此外，我们将这些OL方法的性能与传统深度神经网络（DNN）进行了基准测试。

    One predominant challenge in additive manufacturing (AM) is to achieve specific material properties by manipulating manufacturing process parameters during the runtime. Such manipulation tends to increase the computational load imposed on existing simulation tools employed in AM. The goal of the present work is to construct a fast and accurate reduced-order model (ROM) for an AM model developed within the Multiphysics Object-Oriented Simulation Environment (MOOSE) framework, ultimately reducing the time/cost of AM control and optimization processes. Our adoption of the operator learning (OL) approach enabled us to learn a family of differential equations produced by altering process variables in the laser's Gaussian point heat source. More specifically, we used the Fourier neural operator (FNO) and deep operator network (DeepONet) to develop ROMs for time-dependent responses. Furthermore, we benchmarked the performance of these OL methods against a conventional deep neural network (DNN
    
[^2]: 对高阶SDE模拟的Lévy区域进行生成建模

    Generative Modelling of L\'{e}vy Area for High Order SDE Simulation. (arXiv:2308.02452v1 [stat.ML])

    [http://arxiv.org/abs/2308.02452](http://arxiv.org/abs/2308.02452)

    本文提出了一种基于深度学习的模型LévyGAN，用于生成条件于布朗增量的Lévy区域的近似样本。通过“桥翻转”操作，输出的样本可以精确匹配所有奇数阶矩，解决了非高斯性质下的抽样困难问题。

    

    众所周知，当数值模拟SDE的解时，要实现强收敛速率超过O(\sqrt{h})（其中h为步长），需要使用某些布朗运动的迭代积分，通常称为其“Lévy区域”。然而，由于其非高斯性质，对于d维布朗运动（d>2），目前没有快速近似抽样算法。本文提出了LévyGAN，一种基于深度学习的模型，用于生成条件于布朗增量的Lévy区域的近似样本。通过“桥翻转”操作，输出的样本可以精确匹配所有奇数阶矩。我们的生成器采用经过量身定制的GNN-inspired架构，强制输出分布与条件变量之间的正确依赖结构。此外，我们还结合了基于特征函数的数学原理的判别性归一化操作。

    It is well known that, when numerically simulating solutions to SDEs, achieving a strong convergence rate better than O(\sqrt{h}) (where h is the step size) requires the use of certain iterated integrals of Brownian motion, commonly referred to as its "L\'{e}vy areas". However, these stochastic integrals are difficult to simulate due to their non-Gaussian nature and for a d-dimensional Brownian motion with d > 2, no fast almost-exact sampling algorithm is known.  In this paper, we propose L\'{e}vyGAN, a deep-learning-based model for generating approximate samples of L\'{e}vy area conditional on a Brownian increment. Due to our "Bridge-flipping" operation, the output samples match all joint and conditional odd moments exactly. Our generator employs a tailored GNN-inspired architecture, which enforces the correct dependency structure between the output distribution and the conditioning variable. Furthermore, we incorporate a mathematically principled characteristic-function based discrim
    
[^3]: 使用贝叶斯推断修剪神经网络

    Pruning a neural network using Bayesian inference. (arXiv:2308.02451v1 [stat.ML])

    [http://arxiv.org/abs/2308.02451](http://arxiv.org/abs/2308.02451)

    使用贝叶斯推断修剪神经网络的新方法可以实现理想的稀疏程度，同时保持竞争力的准确性。

    

    神经网络修剪是一种非常有效的技术，旨在减少大型神经网络的计算和内存需求。在这篇研究论文中，我们提出了一种利用贝叶斯推断修剪神经网络的新方法，它可以无缝地集成到训练过程中。我们提出的方法利用修剪前后的神经网络的后验概率，从而计算贝叶斯因子。计算的贝叶斯因子指导着迭代修剪过程。通过对多个基准进行全面评估，我们证明了我们的方法在保持竞争力的准确性的同时实现了理想的稀疏程度。

    Neural network pruning is a highly effective technique aimed at reducing the computational and memory demands of large neural networks. In this research paper, we present a novel approach to pruning neural networks utilizing Bayesian inference, which can seamlessly integrate into the training procedure. Our proposed method leverages the posterior probabilities of the neural network prior to and following pruning, enabling the calculation of Bayes factors. The calculated Bayes factors guide the iterative pruning. Through comprehensive evaluations conducted on multiple benchmarks, we demonstrate that our method achieves desired levels of sparsity while maintaining competitive accuracy.
    
[^4]: 基于跳步长度可微分的短时傅里叶变换

    Differentiable short-time Fourier transform with respect to the hop length. (arXiv:2308.02421v1 [eess.SP])

    [http://arxiv.org/abs/2308.02421](http://arxiv.org/abs/2308.02421)

    本文提出了一种基于跳步长度可微分的短时傅里叶变换，通过使跳步长度连续，实现了梯度优化的时间定位控制，提供了更好的优化效果和更高的计算效率。该方法可以轻松集成到现有算法和神经网络中。

    

    在本文中，我们提出了一种基于跳步长度可微分的短时傅里叶变换（STFT），通过使这些参数连续，使跳步长度或帧时间位置可以基于梯度进行优化。我们的方法提供了对帧的时间定位更好的控制，因为跳步长度的连续性允许进行更精细的优化。此外，我们的贡献还可以使用诸如梯度下降之类的优化方法，这些方法比传统的离散优化方法更加高效。我们的可微分STFT也可以轻松集成到现有的算法和神经网络中。我们展示了一个模拟实例，以展示我们方法的有效性，并引起研究界的兴趣。

    In this paper, we propose a differentiable version of the short-time Fourier transform (STFT) that allows for gradient-based optimization of the hop length or the frame temporal position by making these parameters continuous. Our approach provides improved control over the temporal positioning of frames, as the continuous nature of the hop length allows for a more finely-tuned optimization. Furthermore, our contribution enables the use of optimization methods such as gradient descent, which are more computationally efficient than conventional discrete optimization methods. Our differentiable STFT can also be easily integrated into existing algorithms and neural networks. We present a simulated illustration to demonstrate the efficacy of our approach and to garner interest from the research community.
    
[^5]: 对在线技能评级建模和推理的状态空间视角的研究

    A State-Space Perspective on Modelling and Inference for Online Skill Rating. (arXiv:2308.02414v1 [stat.AP])

    [http://arxiv.org/abs/2308.02414](http://arxiv.org/abs/2308.02414)

    本文提供了对竞技体育技能评级主要方法的全面回顾，并提出了采用状态空间模型视角的建议。通过使用状态空间模型视角，玩家的技能可以表示为随时间变化的变量，而比赛结果则是唯一的观测量。该视角有助于解耦建模和推理，并促进通用推理工具的发展。在构建技能评级的状态空间模型方面，本文探讨了基本步骤，同时还讨论了滤波、平滑和参数估计等推理阶段。在面对高维场景中的计算挑战时，本文强调了所采用的近似和简化方法。该文提供了对记录的流行方法的简明总结。

    

    本文全面回顾了用于竞技体育技能评级的主要方法。我们提倡采用状态空间模型视角，将玩家的技能表示为随时间变化的，比赛结果作为唯一的观测量。状态空间模型视角有助于解耦建模和推理，从而使得更加注重模型假设的方法得以突出，并促进了通用推理工具的发展。我们探讨了构建技能评级的状态空间模型的基本步骤，并讨论了推理的三个阶段：滤波、平滑和参数估计。在整个过程中，我们研究了在涉及大量玩家和比赛的高维场景中进行规模扩展的计算挑战，强调了用于有效应对这些挑战的近似和简化方法。我们提供了文献中记录的流行方法的简明总结。

    This paper offers a comprehensive review of the main methodologies used for skill rating in competitive sports. We advocate for a state-space model perspective, wherein players' skills are represented as time-varying, and match results serve as the sole observed quantities. The state-space model perspective facilitates the decoupling of modeling and inference, enabling a more focused approach highlighting model assumptions, while also fostering the development of general-purpose inference tools. We explore the essential steps involved in constructing a state-space model for skill rating before turning to a discussion on the three stages of inference: filtering, smoothing and parameter estimation. Throughout, we examine the computational challenges of scaling up to high-dimensional scenarios involving numerous players and matches, highlighting approximations and reductions used to address these challenges effectively. We provide concise summaries of popular methods documented in the lit
    
[^6]: 分类因果结构：确定经典相关性何时受不等式限制

    Classifying Causal Structures: Ascertaining when Classical Correlations are Constrained by Inequalities. (arXiv:2308.02380v1 [quant-ph])

    [http://arxiv.org/abs/2308.02380](http://arxiv.org/abs/2308.02380)

    本研究发展了一种方法，通过使用d分离、e分离和不相容支持来检测不同的因果场景，从而将具有不等式约束和不具有不等式约束的场景进行分类。

    

    一组变量之间的经典因果关系可以在观察变量和潜在变量之间导致相等约束（通常是条件独立）和不等约束（仪器不等式和贝尔不等式是典型示例），从而使它们之间的分布在观察变量上具有一定的约束性。列举一个因果结构所隐含的不等式约束通常比列举它的等式约束更困难。此外，只有不等式约束才能被量子相关性违反。由于这两个原因，将因果场景分类为具有不等式约束和不具有不等式约束的场景是重要的。在这里，我们通过使用d分离、e分离和不相容支持的方法来检测这些场景。许多（也许全部？）仅具有等式约束的场景可以通过Henson，Lal和Pusey（HLP）提出的条件来检测。考虑到最多4个被观察到的场景。

    The classical causal relations between a set of variables, some observed and some latent, can induce both equality constraints (typically conditional independences) as well as inequality constraints (Instrumental and Bell inequalities being prototypical examples) on their compatible distribution over the observed variables. Enumerating a causal structure's implied inequality constraints is generally far more difficult than enumerating its equalities. Furthermore, only inequality constraints ever admit violation by quantum correlations. For both those reasons, it is important to classify causal scenarios into those which impose inequality constraints versus those which do not. Here we develop methods for detecting such scenarios by appealing to d-separation, e-separation, and incompatible supports. Many (perhaps all?) scenarios with exclusively equality constraints can be detected via a condition articulated by Henson, Lal and Pusey (HLP). Considering all scenarios with up to 4 observed
    
[^7]: 基于积分的无强度积分化学能的学习

    Intensity-free Integral-based Learning of Marked Temporal Point Processes. (arXiv:2308.02360v1 [cs.LG])

    [http://arxiv.org/abs/2308.02360](http://arxiv.org/abs/2308.02360)

    该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。

    

    在标记的时间点过程（MTPP）中，一个核心问题是为条件联合概率密度函数（PDF）$p^*（m，t）$参数化插值时间t和标记m在历史条件下。现有研究大多预先定义强度函数。它们的实用性受到指定强度函数正确形式的挑战，这对于平衡表达能力和处理效率至关重要。最近，有研究摆脱预定义强度函数，一个模型$p^*（t）$和$p^*（m）$分开，另一个侧重于不考虑标记的时间点过程（TPP）。本研究旨在开发高保真度的$p^*（m，t）$，适用于事件标记在多维连续空间中具有分类或数值属性的离散事件。我们提出了一个解决方案框架IFIB（无强度积分化学能过程），直接建模条件联合概率密度函数$p^*（m，t）$。

    In the marked temporal point processes (MTPP), a core problem is to parameterize the conditional joint PDF (probability distribution function) $p^*(m,t)$ for inter-event time $t$ and mark $m$, conditioned on the history. The majority of existing studies predefine intensity functions. Their utility is challenged by specifying the intensity function's proper form, which is critical to balance expressiveness and processing efficiency. Recently, there are studies moving away from predefining the intensity function -- one models $p^*(t)$ and $p^*(m)$ separately, while the other focuses on temporal point processes (TPPs), which do not consider marks. This study aims to develop high-fidelity $p^*(m,t)$ for discrete events where the event marks are either categorical or numeric in a multi-dimensional continuous space. We propose a solution framework IFIB (\underline{I}ntensity-\underline{f}ree \underline{I}ntegral-\underline{b}ased process) that models conditional joint PDF $p^*(m,t)$ directly
    
[^8]: 从高斯图模型和高斯自由场学习网络

    Learning Networks from Gaussian Graphical Models and Gaussian Free Fields. (arXiv:2308.02344v1 [math.ST])

    [http://arxiv.org/abs/2308.02344](http://arxiv.org/abs/2308.02344)

    本文研究了从重复测量的高斯自由场中估计加权网络结构的问题，并提出了一种基于高斯分布傅里叶分析特性的新型估计器。该方法利用了从观测数据中构造的复数值统计量，具有研究价值。

    

    我们研究了从网络上的高斯图模型（Gaussian Graphical Model，简称GGM）的重复测量中估计加权网络结构的问题。在这个方面，我们考虑了与基于其上加权网络的几何结构相一致的GGM的协方差结构。这种GGM在统计物理学中一直受到关注，并被称为高斯自由场（Gaussian Free Field，简称GFF）。近年来，它们在机器学习和理论计算机科学领域引起了广泛的兴趣。在这项工作中，我们提出了一种基于高斯分布的傅里叶分析特性的重复测量的GFF来估计加权网络（等价地，其拉普拉斯矩阵）的新型估计量。在这个过程中，我们的方法利用了从观测数据中构造的复数值统计量，这些统计量本身就具有研究价值。我们通过具体的恢复保证和对所需采样的界限来证明我们的估计器的有效性。

    We investigate the problem of estimating the structure of a weighted network from repeated measurements of a Gaussian Graphical Model (GGM) on the network. In this vein, we consider GGMs whose covariance structures align with the geometry of the weighted network on which they are based. Such GGMs have been of longstanding interest in statistical physics, and are referred to as the Gaussian Free Field (GFF). In recent years, they have attracted considerable interest in the machine learning and theoretical computer science. In this work, we propose a novel estimator for the weighted network (equivalently, its Laplacian) from repeated measurements of a GFF on the network, based on the Fourier analytic properties of the Gaussian distribution. In this pursuit, our approach exploits complex-valued statistics constructed from observed data, that are of interest on their own right. We demonstrate the effectiveness of our estimator with concrete recovery guarantees and bounds on the required sa
    
[^9]: 用正则化高阶总变差的随机优化方法训练非线性神经网络

    A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])

    [http://arxiv.org/abs/2308.02293](http://arxiv.org/abs/2308.02293)

    通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。

    

    尽管包括深度神经网络在内的高度表达的参数模型可以更好地建模复杂概念，但训练这种高度非线性模型已知会导致严重的过拟合风险。针对这个问题，本研究考虑了一种k阶总变差（k-TV）正则化，它被定义为要训练的参数模型的k阶导数的平方积分，通过惩罚k-TV来产生一个更平滑的函数，从而避免过拟合。尽管将k-TV项应用于一般的参数模型由于积分而导致计算复杂，本研究提供了一种随机优化算法，可以高效地训练带有k-TV正则化的一般模型，而无需进行显式的数值积分。这种方法可以应用于结构任意的深度神经网络的训练，因为它只需要进行简单的随机梯度优化即可实现。

    While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
    
[^10]: 自适应近端梯度方法的凸优化

    Adaptive Proximal Gradient Method for Convex Optimization. (arXiv:2308.02261v1 [math.OC])

    [http://arxiv.org/abs/2308.02261](http://arxiv.org/abs/2308.02261)

    本文提出了自适应版本的梯度下降（GD）和近端梯度方法（ProxGD），通过利用局部曲率信息完全自适应。所提出的方法具有收敛性，且允许使用更大的步长。

    

    在本文中，我们探讨了凸优化中的两个基本一阶算法，即梯度下降（GD）和近端梯度方法（ProxGD）。我们的重点是通过利用平滑函数的局部曲率信息，使这些算法完全自适应。我们提出了基于观察到的梯度差异的自适应版本的GD和ProxGD，因此不会增加计算成本。此外，我们在仅假设梯度的局部Lipschitz性的情况下，证明了我们方法的收敛性。另外，所提出的版本允许使用比[MM20]最初建议的更大的步长。

    In this paper, we explore two fundamental first-order algorithms in convex optimization, namely, gradient descent (GD) and proximal gradient method (ProxGD). Our focus is on making these algorithms entirely adaptive by leveraging local curvature information of smooth functions. We propose adaptive versions of GD and ProxGD that are based on observed gradient differences and, thus, have no added computational costs. Moreover, we prove convergence of our methods assuming only local Lipschitzness of the gradient. In addition, the proposed versions allow for even larger stepsizes than those initially suggested in [MM20].
    
[^11]: 基于似然比的置信区间在神经网络中的应用

    Likelihood-ratio-based confidence intervals for neural networks. (arXiv:2308.02221v1 [stat.ML])

    [http://arxiv.org/abs/2308.02221](http://arxiv.org/abs/2308.02221)

    本文介绍了一种新颖的基于似然比的方法，用于构建神经网络的置信区间。该方法能够构建不对称区间，考虑了训练时间、网络架构和正则化技术等因素。尽管方法实现昂贵，但在特定领域中具有重要应用潜力。

    

    本文介绍了一种新颖的基于似然比的方法，用于构建神经网络的置信区间。我们的方法名为DeepLR，具有许多优点，其中最重要的是能够构建在数据有限的区域中扩展的不对称区间，并固有地考虑了训练时间、网络架构和正则化技术等因素。尽管承认目前的方法实现对于许多深度学习应用来说过于昂贵，但在诸如医学预测或天体物理学等特定领域中，可靠的单个预测的不确定性估计可能已经合理。这项工作突出了基于似然比的不确定性估计的重要潜力，并为未来的研究开辟了有希望的途径。

    This paper introduces a first implementation of a novel likelihood-ratio-based approach for constructing confidence intervals for neural networks. Our method, called DeepLR, offers several qualitative advantages: most notably, the ability to construct asymmetric intervals that expand in regions with a limited amount of data, and the inherent incorporation of factors such as the amount of training time, network architecture, and regularization techniques. While acknowledging that the current implementation of the method is prohibitively expensive for many deep-learning applications, the high cost may already be justified in specific fields like medical predictions or astrophysics, where a reliable uncertainty estimate for a single prediction is essential. This work highlights the significant potential of a likelihood-ratio-based uncertainty estimate and establishes a promising avenue for future research.
    
[^12]: 整合鲁莽行为到基于协同过滤的推荐系统中

    Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])

    [http://arxiv.org/abs/2308.02058](http://arxiv.org/abs/2308.02058)

    本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。

    

    包含可靠性测量的推荐系统往往在预测中更加保守，因为它们需要保持可靠性。这导致了这些系统可以提供的覆盖范围和新颖性的显著下降。在本文中，我们提出了在矩阵分解型推荐系统的学习过程中加入一项新的项，称为鲁莽行为，它可以控制在做出关于预测可靠性的决策时所希望的风险水平。实验结果表明，鲁莽行为不仅允许进行风险调控，还提高了推荐系统提供的预测的数量和质量。

    Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
    
[^13]: 针对同步随机线性系统的鲁棒独立性检验及有限样本保证

    Robust Independence Tests with Finite Sample Guarantees for Synchronous Stochastic Linear Systems. (arXiv:2308.02054v1 [stat.ML])

    [http://arxiv.org/abs/2308.02054](http://arxiv.org/abs/2308.02054)

    本文介绍了一种针对同步随机线性系统的鲁棒独立性检验方法，可以提供非渐近性保证的显著水平。该方法结合了置信区间估计、排列检验以及一般的依赖度量，以检测系统之间的任何非线性依赖关系。

    

    本文介绍了一种针对随机线性时不变系统的鲁棒独立性检验方法，其在观测到的输出是同步的情况下可以提供非渐近性保证的显著水平。该方法提供了分布无关的第一类错误概率的界限，即创新项可以具有任意分布。该算法结合了置信区间估计、排列检验以及一般的依赖度量，如希尔伯特-施密特独立性准则和距离协方差，以检测观察到的系统之间的任何非线性依赖关系。我们还证明了在温和的假设下，我们的假设检验的一致性，并通过自回归系统的示例演示了这些思想。

    The paper introduces robust independence tests with non-asymptotically guaranteed significance levels for stochastic linear time-invariant systems, assuming that the observed outputs are synchronous, which means that the systems are driven by jointly i.i.d. noises. Our method provides bounds for the type I error probabilities that are distribution-free, i.e., the innovations can have arbitrary distributions. The algorithm combines confidence region estimates with permutation tests and general dependence measures, such as the Hilbert-Schmidt independence criterion and the distance covariance, to detect any nonlinear dependence between the observed systems. We also prove the consistency of our hypothesis tests under mild assumptions and demonstrate the ideas through the example of autoregressive systems.
    
[^14]: 在线多任务学习中基于递归最小二乘和递归核方法的应用

    Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods. (arXiv:2308.01938v1 [stat.ML])

    [http://arxiv.org/abs/2308.01938](http://arxiv.org/abs/2308.01938)

    本文提出了两种新的在线多任务学习方法，分别基于递归最小二乘和递归核方法。与基于梯度下降或不精确逼近的方法不同，我们的方法在每个实例的代价上具有二次复杂度。我们将这些方法应用于风力短期预测挑战，并与其他竞争者进行了比较。

    

    本文提出了两种新颖的在线多任务学习（MTL）回归问题的方法。我们采用高性能基于图的MTL公式，基于加权递归最小二乘（WRLS）和在线稀疏最小二乘支持向量回归（OSLSSVR）开发其递归版本。采用任务堆叠转换，我们展示了存在一个单矩阵，它融合了多任务之间的关系，并为MT-WRLS方法的初始化过程和MT-OSLSSVR的多任务核函数提供结构信息。与现有大部分基于在线梯度下降（OGD）或不精确立方逼近方法的文献相比，我们实现了精确和近似递归，其每个实例的代价在输入空间的维度（MT-WRLS）或实例字典的大小上是二次的。我们将我们的在线MTL方法与其他竞争者在实际风短期预测挑战上进行了比较。

    This paper introduces two novel approaches for Online Multi-Task Learning (MTL) Regression Problems. We employ a high performance graph-based MTL formulation and develop its recursive versions based on the Weighted Recursive Least Squares (WRLS) and the Online Sparse Least Squares Support Vector Regression (OSLSSVR). Adopting task-stacking transformations, we demonstrate the existence of a single matrix incorporating the relationship of multiple tasks and providing structural information to be embodied by the MT-WRLS method in its initialization procedure and by the MT-OSLSSVR in its multi-task kernel function. Contrasting the existing literature, which is mostly based on Online Gradient Descent (OGD) or cubic inexact approaches, we achieve exact and approximate recursions with quadratic per-instance cost on the dimension of the input space (MT-WRLS) or on the size of the dictionary of instances (MT-OSLSSVR). We compare our online MTL methods to other contenders in a real-world wind sp
    
[^15]: 关于插值专家和多臂赌博机的研究

    On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])

    [http://arxiv.org/abs/2307.07264](http://arxiv.org/abs/2307.07264)

    学习专家建议和多臂赌博是两个经典的在线决策问题，我们研究了两者之间的插值问题。我们提出了$\mathbf{m}$-MAB的极小后悔界并设计了$\mathbf{m}$-BAI的最优PAC算法，该算法旨在以尽可能少的轮数确定损失最小的臂。

    

    学习专家建议和多臂赌博是两个经典的在线决策问题，它们在每一轮观察信息的方式上有所不同。我们研究了这两者之间的插值问题。对于向量$\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$，$\mathbf{m}$-MAB的一个实例表示将臂分成$K$组，第$i$组包含$m_i$个臂。一旦拉动一个臂，同一组中所有臂的损失都被观察到。我们证明了$\mathbf{m}$-MAB的紧致极小后悔界，并为其纯探索版本$\mathbf{m}$-BAI设计了一个最优的PAC算法，其中目标是用尽可能少的轮数来识别损失最小的臂。我们证明了$\mathbf{m}$-MAB的极小后悔是$\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$，对于一个$(\epsilon,0.05)$-PAC算法的$\mathbf{m}$-BAI，拉动臂的最小次数是$\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$。

    Learning with expert advice and multi-armed bandit are two classic online decision problems which differ on how the information is observed in each round of the game. We study a family of problems interpolating the two. For a vector $\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$, an instance of $\mathbf{m}$-MAB indicates that the arms are partitioned into $K$ groups and the $i$-th group contains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same group are observed. We prove tight minimax regret bounds for $\mathbf{m}$-MAB and design an optimal PAC algorithm for its pure exploration version, $\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with as few rounds as possible. We show that the minimax regret of $\mathbf{m}$-MAB is $\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$ and the minimum number of pulls for an $(\epsilon,0.05)$-PAC algorithm of $\mathbf{m}$-BAI is $\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$. Bot
    
[^16]: 使用归一化流学习边缘似然的调和平均估计

    Learned harmonic mean estimation of the marginal likelihood with normalizing flows. (arXiv:2307.00048v1 [stat.ME])

    [http://arxiv.org/abs/2307.00048](http://arxiv.org/abs/2307.00048)

    本文研究使用归一化流学习边缘似然的调和平均估计，在贝叶斯模型选择中解决了原始方法中的方差爆炸问题。

    

    计算边缘似然（也称为贝叶斯模型证据）是贝叶斯模型选择中的一项重要任务，它提供了一种有原则的定量比较模型的方法。学习的调和平均估计器解决了原始调和平均估计边缘似然的方差爆炸问题。学习的调和平均估计器学习了一个重要性采样目标分布，该分布近似于最优分布。虽然近似不必非常准确，但确保学习分布的概率质量包含在后验分布中是至关重要的，以避免方差爆炸问题。在先前的工作中，为了确保满足这个性质，在训练模型时引入了一种专门的优化问题。在本文中，我们引入了使用归一化流来表示重要性采样目标分布。基于流的模型通过最大似然从后验样本中进行训练。

    Computing the marginal likelihood (also called the Bayesian model evidence) is an important task in Bayesian model selection, providing a principled quantitative way to compare models. The learned harmonic mean estimator solves the exploding variance problem of the original harmonic mean estimation of the marginal likelihood. The learned harmonic mean estimator learns an importance sampling target distribution that approximates the optimal distribution. While the approximation need not be highly accurate, it is critical that the probability mass of the learned distribution is contained within the posterior in order to avoid the exploding variance problem. In previous work a bespoke optimization problem is introduced when training models in order to ensure this property is satisfied. In the current article we introduce the use of normalizing flows to represent the importance sampling target distribution. A flow-based model is trained on samples from the posterior by maximum likelihood e
    
[^17]: 利用密度函数的非线性变换估计岭

    Estimation of Ridge Using Nonlinear Transformation on Density Function. (arXiv:2306.05722v1 [cs.LG])

    [http://arxiv.org/abs/2306.05722](http://arxiv.org/abs/2306.05722)

    本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。

    

    岭在准确近似流形的基础结构方面发挥着重要作用。本文通过将凹非线性变换应用于密度函数以探索岭的变化。通过对Hessian矩阵的推导和分析，我们发现非线性变换产生了Hessian矩阵的秩一修改。利用特征值问题的变分性质，我们建立了相应岭之间的偏序包含关系。我们直观地发现，通过Hessian矩阵的秩一修改，变换可以导致对切空间的估计改进。为验证我们的理论，我们在合成和真实世界数据集上进行了大量数值实验，证明了与其他流形拟合算法相比，我们的变换方法得到的岭在近似底层真实流形方面更加优越。

    Ridges play a vital role in accurately approximating the underlying structure of manifolds. In this paper, we explore the ridge's variation by applying a concave nonlinear transformation to the density function. Through the derivation of the Hessian matrix, we observe that nonlinear transformations yield a rank-one modification of the Hessian matrix. Leveraging the variational properties of eigenvalue problems, we establish a partial order inclusion relationship among the corresponding ridges. We intuitively discover that the transformation can lead to improved estimation of the tangent space via rank-one modification of the Hessian matrix. To validate our theories, we conduct extensive numerical experiments on synthetic and real-world datasets that demonstrate the superiority of the ridges obtained from our transformed approach in approximating the underlying truth manifold compared to other manifold fitting algorithms.
    
[^18]: 用于带测量噪声的Ornstein-Uhlenbeck过程参数估计

    Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise. (arXiv:2305.13498v1 [stat.ML])

    [http://arxiv.org/abs/2305.13498](http://arxiv.org/abs/2305.13498)

    本文研究了带有测量噪声的Ornstein-Uhlenbeck过程参数估计，提出了算法和方法能够分离热噪声和乘性噪声，并改善数据分析的参数估计精度。

    

    本文旨在研究噪声对Ornstein-Uhlenbeck过程参数拟合的影响，重点考察了乘性噪声和热噪声对信号分离精度的影响。为了解决这些问题，我们提出了有效区分热噪声和乘性噪声、改善参数估计精度的算法和方法，探讨了乘性和热噪声对实际信号混淆的影响，并提出了解决方法。首先，我们提出了一种可以有效分离热噪声的算法，其性能可与Hamilton Monte Carlo (HMC)相媲美，但速度显著提高。随后，我们分析了乘性噪声，并证明了HMC无法隔离热噪声和乘性噪声。然而，我们展示了，在额外了解热噪声和乘性噪声之间比率的情况下，我们可以精确地估计参数和分离信号。

    This article aims to investigate the impact of noise on parameter fitting for an Ornstein-Uhlenbeck process, focusing on the effects of multiplicative and thermal noise on the accuracy of signal separation. To address these issues, we propose algorithms and methods that can effectively distinguish between thermal and multiplicative noise and improve the precision of parameter estimation for optimal data analysis. Specifically, we explore the impact of both multiplicative and thermal noise on the obfuscation of the actual signal and propose methods to resolve them. Firstly, we present an algorithm that can effectively separate thermal noise with comparable performance to Hamilton Monte Carlo (HMC) but with significantly improved speed. Subsequently, we analyze multiplicative noise and demonstrate that HMC is insufficient for isolating thermal and multiplicative noise. However, we show that, with additional knowledge of the ratio between thermal and multiplicative noise, we can accuratel
    
[^19]: 通过上下文调控实现通用形态控制

    Universal Morphology Control via Contextual Modulation. (arXiv:2302.11070v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11070](http://arxiv.org/abs/2302.11070)

    本文提出了通过上下文调节实现通用形态控制的方法，包括使用超网络生成形态相关的控制参数以及利用固定的注意机制调节机器人中不同肢体之间的交互作用。这种方法可以提高学习效率和泛化能力。

    

    在连续控制中，学习一种适用于不同机器人形态的通用策略可以显著提高学习效率和泛化能力。然而，这会带来一个具有挑战性的多任务强化学习问题，因为最优策略可能在不同机器人之间有很大差异，并且严重依赖于形态。现有的方法利用图神经网络或transformers来处理不同形态之间的异构状态和动作空间，但对机器人的控制策略与形态上下文的依赖性关注较少。在本文中，我们提出了一种分层架构，通过上下文调节更好地建模这种依赖关系，其中包括两个关键子模块：（1）我们使用超网络生成形态相关的控制参数，而不是对机器人之间强制进行硬参数共享；（2）我们提出了一个固定的注意机制，仅依赖于形态，来调节机器人中不同肢体之间的交互作用。

    Learning a universal policy across different robot morphologies can significantly improve learning efficiency and generalization in continuous control. However, it poses a challenging multi-task reinforcement learning problem, as the optimal policy may be quite different across robots and critically depend on the morphology. Existing methods utilize graph neural networks or transformers to handle heterogeneous state and action spaces across different morphologies, but pay little attention to the dependency of a robot's control policy on its morphology context. In this paper, we propose a hierarchical architecture to better model this dependency via contextual modulation, which includes two key submodules: (1) Instead of enforcing hard parameter sharing across robots, we use hypernetworks to generate morphology-dependent control parameters; (2) We propose a fixed attention mechanism that solely depends on the morphology to modulate the interactions between different limbs in a robot. Ex
    
[^20]: 可扩展的PAC-Bayesian元学习：从理论到实践的PAC-Optimal超后验

    Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior: From Theory to Practice. (arXiv:2211.07206v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.07206](http://arxiv.org/abs/2211.07206)

    本研究使用PAC-Bayesian理论提供了元学习的泛化界限，并推导出了最佳性能保证的闭式优化超后验(PACOH)。通过理论分析和案例研究，我们展示了这些保证在元学习中相对于PAC-Bayesian每个任务学习界限的改进。

    

    元学习旨在通过从相关学习任务的数据集中获取有用的归纳偏好，加速对新任务的学习过程。然而，在实践中，可用的相关任务数量通常很小，大多数现有方法假设任务数量丰富，使它们不切实际且容易过拟合。元学习文献中的一个核心问题是如何进行正则化以确保对未见任务的泛化。在这项工作中，我们使用PAC-Bayesian理论提供了一种理论分析，并提出了元学习的泛化界限，这是由Rothfuss等人（2021）首次推导出来的。关键是，该界限使我们能够得到最佳性能保证的闭式优化超后验，称为PACOH。我们提供了一种理论分析和实证案例研究，在哪些条件下以及在多大程度上这些元学习的保证改进了PAC-Bayesian每个任务学习界限。

    Meta-Learning aims to speed up the learning process on new tasks by acquiring useful inductive biases from datasets of related learning tasks. While, in practice, the number of related tasks available is often small, most of the existing approaches assume an abundance of tasks; making them unrealistic and prone to overfitting. A central question in the meta-learning literature is how to regularize to ensure generalization to unseen tasks. In this work, we provide a theoretical analysis using the PAC-Bayesian theory and present a generalization bound for meta-learning, which was first derived by Rothfuss et al. (2021). Crucially, the bound allows us to derive the closed form of the optimal hyper-posterior, referred to as PACOH, which leads to the best performance guarantees. We provide a theoretical analysis and empirical case study under which conditions and to what extent these guarantees for meta-learning improve upon PAC-Bayesian per-task learning bounds. The closed-form PACOH inspi
    
[^21]: 国际空间站自动紧急无尘解决方案: 带有Bi-GRU的(AED-ISS)

    Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2210.08549](http://arxiv.org/abs/2210.08549)

    该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。

    

    随着对PM2.5或PM0.3问题的关注不断增加，颗粒物不仅对环境和人类构成潜在威胁，而且对国际空间站上的仪器也会产生不利影响。本研究团队旨在将各种颗粒物浓度与磁场、湿度、加速度、温度、压力和CO2浓度关联起来。我们的目标是建立一个早期预警系统(EWS)，能够预测颗粒物水平，并为宇航员提供充足的反应时间，以保护他们在某些实验中的仪器，或者提高测量的准确性；此外，所构建的模型还可以进一步发展为与火灾相关的遥感烟雾报警装置的原型。本文中，我们将实现Bi-GRU(双向门控循环单元)算法，收集过去90分钟的数据，并预测超过2.5微米的颗粒物水平。

    With a rising attention for the issue of PM2.5 or PM0.3, particulate matters have become not only a potential threat to both the environment and human, but also a harming existence to instruments onboard International Space Station (ISS). Our team is aiming to relate various concentration of particulate matters to magnetic fields, humidity, acceleration, temperature, pressure and CO2 concentration. Our goal is to establish an early warning system (EWS), which is able to forecast the levels of particulate matters and provides ample reaction time for astronauts to protect their instruments in some experiments or increase the accuracy of the measurements; In addition, the constructed model can be further developed into a prototype of a remote-sensing smoke alarm for applications related to fires. In this article, we will implement the Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for past 90 minutes and predict the levels of particulates which over 2.5 micromete
    
[^22]: 非零梯度的随机逼近的指数集中性分析

    Exponential Concentration of Stochastic Approximation with Non-vanishing Gradient. (arXiv:2208.07243v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.07243](http://arxiv.org/abs/2208.07243)

    本研究分析了非零梯度的随机逼近算法的行为，并证明了指数级的集中性界限，这对于投影随机梯度下降算法的收敛速度有重要意义。

    

    我们分析了随机逼近算法的行为，其中每一步迭代，期望中向目标取得进展。当进展与算法的步长成比例时，我们证明了指数级的集中性界限。这些尾部界限与更常见的随机逼近的渐近正态结果形成对比。我们开发的方法依赖于几何阻尼性证明。这扩展了Hajek（1982）对马尔可夫链的结果到随机逼近算法的领域。对于具有非零梯度的投影随机梯度下降算法，我们的结果可以用来证明$O(1/t)$和线性收敛速度。

    We analyze the behavior of stochastic approximation algorithms where iterates, in expectation, make progress towards an objective at each step. When progress is proportional to the step size of the algorithm, we prove exponential concentration bounds. These tail-bounds contrast asymptotic normality results which are more frequently associated with stochastic approximation. The methods that we develop rely on a geometric ergodicity proof. This extends a result on Markov chains due to Hajek (1982) to the area of stochastic approximation algorithms. For Projected Stochastic Gradient Descent with a non-vanishing gradient, our results can be used to prove $O(1/t)$ and linear convergence rates.
    
[^23]: 推理为基础的量子感知

    Inference-Based Quantum Sensing. (arXiv:2206.09919v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2206.09919](http://arxiv.org/abs/2206.09919)

    这项工作提出了一种基于推理的量子感知方案，可以通过测量系统响应来推断未知参数的值，并确定方案的敏感性。

    

    在标准的量子感知任务中，通过对系统的测量，目标是估计一个未知的参数θ，将其编码到一个n比特的探针态中。这个任务的成功取决于将参数的变化与系统响应Ρ（θ）的变化（即测量结果的变化）相关联的能力。对于简单情况，Ρ（θ）的形式是已知的，但对于现实场景来说，一般不存在闭合形式的表达式。在这项工作中，我们提出了一种基于推理的量子感知方案。我们展示了对于一类常规的编码的酉族系列，只需在2n+1个参数处测量系统响应，就可以完全表征Ρ（θ）。这使得我们能够根据测量的响应推断未知参数的值，以及确定该方案的敏感性，从而表征其整体性能。我们证明了推理误差在高概率下小于...

    In a standard Quantum Sensing (QS) task one aims at estimating an unknown parameter $\theta$, encoded into an $n$-qubit probe state, via measurements of the system. The success of this task hinges on the ability to correlate changes in the parameter to changes in the system response $\mathcal{R}(\theta)$ (i.e., changes in the measurement outcomes). For simple cases the form of $\mathcal{R}(\theta)$ is known, but the same cannot be said for realistic scenarios, as no general closed-form expression exists. In this work we present an inference-based scheme for QS. We show that, for a general class of unitary families of encoding, $\mathcal{R}(\theta)$ can be fully characterized by only measuring the system response at $2n+1$ parameters. This allows us to infer the value of an unknown parameter given the measured response, as well as to determine the sensitivity of the scheme, which characterizes its overall performance. We show that inference error is, with high probability, smaller than 
    
[^24]: 通过遗憾分解改进了带有图反馈的赌博机算法

    Improved Algorithms for Bandit with Graph Feedback via Regret Decomposition. (arXiv:2205.15076v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15076](http://arxiv.org/abs/2205.15076)

    通过遗憾分解，我们提出了一种基于反馈图划分的新算法框架，该框架统一了多臂赌博机和学习与专家建议的最优算法，对包括许多图类族在内的范围更广的图家族得到了改进和最优遗憾界限。

    

    带有图反馈的赌博机问题通过在有向图中编码损失向量在每轮游戏中的观测方式，将多臂赌博机问题和学习与专家建议问题进行了推广。最小最大遗憾与反馈图的结构密切相关，但二者的关系尚未完全理解。我们提出了一种基于反馈图划分的新算法框架。通过将遗憾分解为由小部分和它们之间相互作用引起的遗憾之和，我们的分析揭示了图的各个部分之间的相互作用。因此，我们的算法可以被看作是多臂赌博机和学习与专家建议的最优算法的插值和推广。我们的框架统一了先前针对强观测图和弱观测图的算法，对包括许多图类族在内的范围更广的图家族得到了改进和最优遗憾界限。

    The problem of bandit with graph feedback generalizes both the multi-armed bandit (MAB) problem and the learning with expert advice problem by encoding in a directed graph how the loss vector can be observed in each round of the game. The mini-max regret is closely related to the structure of the feedback graph and their connection is far from being fully understood. We propose a new algorithmic framework for the problem based on a partition of the feedback graph. Our analysis reveals the interplay between various parts of the graph by decomposing the regret to the sum of the regret caused by small parts and the regret caused by their interaction. As a result, our algorithm can be viewed as an interpolation and generalization of the optimal algorithms for MAB and learning with expert advice. Our framework unifies previous algorithms for both strongly observable graphs and weakly observable graphs, resulting in improved and optimal regret bounds on a wide range of graph families includi
    
[^25]: 通过基于草图的顺序二次规划对约束的随机优化进行统计推断

    Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming. (arXiv:2205.13687v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2205.13687](http://arxiv.org/abs/2205.13687)

    本篇论文提出了一种用于等式约束的随机非线性优化问题的统计推断方法，通过基于草图的顺序二次规划（StoSQP）进行求解，并且允许自适应选择随机步长和使用高效随机迭代求解器来降低计算成本。

    

    我们考虑对等式约束的随机非线性优化问题进行统计推断。我们开发了一种全在线随机顺序二次规划（StoSQP）方法来解决这些问题，可以将其视为将牛顿法应用于一阶最优性条件（即KKT条件）。受最近数值二阶方法设计的启发，我们允许StoSQP自适应地选择任意随机步长$ \bar {\ alpha} _t $，只要$ \ beta _t \ leq \ bar {\ alpha} _t \ leq \ beta _t + \ chi _t $，其中 $ \ beta_t $ 和 $ \ chi_t = o(\beta_t) $ 是某些控制序列。为了降低二阶方法的主要计算成本，我们还允许StoSQP通过使用草图技术的高效随机迭代求解器来不精确地解决二次规划问题。值得注意的是，我们不要求逼近误差随着迭代的进行而减小。对于开发的方法，我们证明在温和的假设（i）下，它的计算复杂度最多为$ O(1 / \ ep）$。

    We consider statistical inference of equality-constrained stochastic nonlinear optimization problems. We develop a fully online stochastic sequential quadratic programming (StoSQP) method to solve the problems, which can be regarded as applying Newton's method to the first-order optimality conditions (i.e., the KKT conditions). Motivated by recent designs of numerical second-order methods, we allow StoSQP to adaptively select any random stepsize $\bar{\alpha}_t$, as long as $\beta_t\leq \bar{\alpha}_t \leq \beta_t+\chi_t$, for some control sequences $\beta_t$ and $\chi_t=o(\beta_t)$. To reduce the dominant computational cost of second-order methods, we additionally allow StoSQP to inexactly solve quadratic programs via efficient randomized iterative solvers that utilize sketching techniques. Notably, we do not require the approximation error to diminish as iteration proceeds. For the developed method, we show that under mild assumptions (i) computationally, it can take at most $O(1/\ep
    
[^26]: 稀疏主成分分析的新基础

    A New Basis for Sparse Principal Component Analysis. (arXiv:2007.00596v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2007.00596](http://arxiv.org/abs/2007.00596)

    我们提出了一种新的方法来进行稀疏主成分分析，该方法使用正交旋转来获得近似稀疏的特征值基。与以往方法不同的是，我们的方法使稀疏成分不需要是主特征向量，而可以是它们的混合。这一方法不需要进行“缩减”操作或使用多个调参参数。

    

    之前的稀疏主成分分析方法假设特征值基（一个大小为$p \times k$的矩阵）近似稀疏。我们提出了一种方法，假设在进行$k \times k$旋转后，特征值基的稀疏性变得近似。算法的简单版本是以前$k$个主成分为初始值，然后使用$k \times k$正交旋转使主成分近似稀疏，最后对旋转后的主成分进行软阈值处理。该方法与以往方法不同之处在于使用正交旋转来近似稀疏基。一个结果是，稀疏成分不需要是主特征向量，而可以是它们的混合。因此，我们提出了一种新的（旋转后的）稀疏主成分分析基。此外，我们的方法避免了“缩减”和多个调参参数的需求。我们的稀疏主成分分析框架非常灵活，并且可以推广至...

    Previous versions of sparse principal component analysis (PCA) have presumed that the eigen-basis (a $p \times k$ matrix) is approximately sparse. We propose a method that presumes the $p \times k$ matrix becomes approximately sparse after a $k \times k$ rotation. The simplest version of the algorithm initializes with the leading $k$ principal components. Then, the principal components are rotated with an $k \times k$ orthogonal rotation to make them approximately sparse. Finally, soft-thresholding is applied to the rotated principal components. This approach differs from prior approaches because it uses an orthogonal rotation to approximate a sparse basis. One consequence is that a sparse component need not to be a leading eigenvector, but rather a mixture of them. In this way, we propose a new (rotated) basis for sparse PCA. In addition, our approach avoids "deflation" and multiple tuning parameters required for that. Our sparse PCA framework is versatile; for example, it extends nat
    

