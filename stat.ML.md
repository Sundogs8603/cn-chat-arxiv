# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [TRAK: Attributing Model Behavior at Scale.](http://arxiv.org/abs/2303.14186) | TRAK是一种适用于大规模、可微模型的数据归因方法，既有效又计算量可行。 |
| [^2] | [How many dimensions are required to find an adversarial example?.](http://arxiv.org/abs/2303.14173) | 本文研究了对抗性漏洞如何取决于受限于高维输入空间中的子空间维数，同时针对标准PGD攻击的对抗性成功率提出了单调递增函数表达式。 |
| [^3] | [Double Descent Demystified: Identifying, Interpreting & Ablating the Sources of a Deep Learning Puzzle.](http://arxiv.org/abs/2303.14151) | 双重下降是机器学习中一个令人惊讶的现象，数据量、数据维度和模型参数是影响双重下降的关键因素。研究者找到了制造双重下降的三个解释性因素，并证明这些因素可以在简单神经网络中关闭。 |
| [^4] | [Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter.](http://arxiv.org/abs/2303.14090) | 本文介绍了一种新的方法，将物理启发的神经网络应用于重建流体力学模拟中，通过将理论知识注入模型损失函数并结合新的性能评估指标，成功实现了对重子散射的重建。 |
| [^5] | [Differentially Private Synthetic Control.](http://arxiv.org/abs/2303.14084) | 本文提供了首个具有显式误差界限的差分隐私合成控制算法，具有广泛的应用前景。 |
| [^6] | [Forecasting Competitions with Correlated Events.](http://arxiv.org/abs/2303.13793) | 此论文研究了带有相关事件的预测竞赛，并引入了一个块相关的概念。证明了在具有块相关性的分布下，基于follow-the-regularized-leader(FTRL)的竞赛机制仍然保留了它的$\epsilon$-最优保证。 |
| [^7] | [Multi-Antenna Dual-Blind Deconvolution for Joint Radar-Communications via SoMAN Minimization.](http://arxiv.org/abs/2303.13609) | 本论文研究了多天线接收器版本的双盲反卷积问题，提出了使用多元原子范数最小化的方法来恢复雷达和通信信号和通道参数。 |
| [^8] | [Une comparaison des algorithmes d'apprentissage pour la survie avec donn\'ees manquantes.](http://arxiv.org/abs/2303.13590) | 本文研究了基于神经网络的生存任务学习算法在缺失数据处理方面的表现，结果显示对于所有情况没有单一的数据插补方法优于其他方法，提出的方法可用于比较其他缺失数据模式和(或)生存模型。 |
| [^9] | [A Closer Look at Scoring Functions and Generalization Prediction.](http://arxiv.org/abs/2303.13589) | 本文研究了广义误差预测器的有效性，探讨了置信度、局部流形平滑度和模型一致性评分函数的优缺点，发现在复杂机制缺失的情况下，最先进的评分无法在分布转移和损坏下超越简单的模型一致性。同时，在受损训练数据的情况下，模型一致性打分仍然表现良好，并且集成多样性有助于提高泛化性能。 |
| [^10] | [DBSCAN of Multi-Slice Clustering for three-order Tensor.](http://arxiv.org/abs/2303.07768) | 本文提出了 MSC-DBSCAN扩展算法，可以在三元聚类中从数据中提取不同子空间的不同切片聚类，并可以获得与 MSC 算法在处理秩一张量数据时相同的解决方案。 |
| [^11] | [Data thinning for convolution-closed distributions.](http://arxiv.org/abs/2301.07276) | 本文提出了数据稀疏化方法，适用于很多分布类型，包括高斯分布、泊松分布、负二项分布、伽玛分布和二项分布等。该方法具有广泛的应用，如在交叉验证方面提供了一种新的方法，能有效验证无监督学习算法的可靠性。 |
| [^12] | [Deep Conditional Measure Quantization.](http://arxiv.org/abs/2301.06907) | 提出了一种名为DCMQ的方法，该方法结合了基于Huber能量核的方法和深度神经网络架构，用于条件测度量化，并在多个实例中取得了有希望的结果。 |
| [^13] | [Towards Dynamic Causal Discovery with Rare Events: A Nonparametric Conditional Independence Test.](http://arxiv.org/abs/2211.16596) | 该论文提出了一种针对稀有事件的新的因果发现方法，基于收集到的时间不变动态系统的数据，构建了叠加数据集和条件独立性检验的方法。该方法能够揭示在变量第一次经历低概率实现时才会显现的因果关系，具有很好的可行性和可扩展性。 |
| [^14] | [Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions.](http://arxiv.org/abs/2209.15055) | 本文研究了全连接神经网络的表示成本和深度之间的关系，发现其会收敛到非线性函数的秩的概念。同时，发现在一定的深度范围内，全局最小值可以恢复真实的数据秩，并探讨了分类器秩对类边界拓扑结构的影响。 |
| [^15] | [Continuous Mixtures of Tractable Probabilistic Models.](http://arxiv.org/abs/2209.10584) | 本文研究了一种连续混合的方法，将可计算概率模型和基于连续潜空间的模型结合起来，从而实现了高效的概率推断。 |
| [^16] | [Euler State Networks: Non-dissipative Reservoir Computing.](http://arxiv.org/abs/2203.09382) | 本文提出了一种新型水库计算模型EuSN，其利用前向欧拉离散化和反对称循环矩阵来设计水库动力学，具有接近稳定边缘的饱和有效谱半径和零局部李雅普诺夫指数。在长期记忆任务和时间序列分类基准测试中表现出了优异的性能。 |
| [^17] | [Efficient Algorithms for Learning from Coarse Labels.](http://arxiv.org/abs/2108.09805) | 本文研究了从粗糙数据中学习的问题，提出了一种高效的算法，只需足够信息的粗标签即可在从细标签中学习的任何问题上进行学习。 |
| [^18] | [Dimension-agnostic inference using cross U-statistics.](http://arxiv.org/abs/2011.05068) | 该论文介绍了一种新的统计推断方法，它不依赖于对数据集维度的假设，可以在高维数据集上进行推断。 |
| [^19] | [Near Optimal Adversarial Attack on UCB Bandits.](http://arxiv.org/abs/2008.09312) | 本文提出了一种在对抗攻击下的UCB最优拉臂策略，成本为$\sqrt{\log T}$，并且证明了此攻击策略近乎是最优的。 |

# 详细

[^1]: TRAK: 刻画大规模模型行为

    TRAK: Attributing Model Behavior at Scale. (arXiv:2303.14186v1 [stat.ML])

    [http://arxiv.org/abs/2303.14186](http://arxiv.org/abs/2303.14186)

    TRAK是一种适用于大规模、可微模型的数据归因方法，既有效又计算量可行。

    

    数据归因的目标是追踪模型预测结果的原始训练数据。虽然已经有很多工作致力于实现这一目标，但现有方法往往要求用户在计算效率和准确性之间做出选择。也就是说，在非凸场景（例如，深度神经网络领域）中，计算量可行的方法可能难以准确地归因模型预测结果，而在这类场景中有效的方法则需要训练数千个模型，这使得它们在大型模型或数据集中实际应用具有不可行性。在本文中，我们介绍了TRAK（随机投影核追踪），这是一种数据归因方法，适用于大规模、可微模型，既有效又计算量可行。具体来说，通过仅使用少量训练模型，TRAK 可以匹配需要训练数千模型才能得到的归因方法的性能。我们论证了TRAK 在各种模式和规模上的实用性。

    The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets.  In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scal
    
[^2]: 找到对抗样本需要多少维度？

    How many dimensions are required to find an adversarial example?. (arXiv:2303.14173v1 [cs.LG])

    [http://arxiv.org/abs/2303.14173](http://arxiv.org/abs/2303.14173)

    本文研究了对抗性漏洞如何取决于受限于高维输入空间中的子空间维数，同时针对标准PGD攻击的对抗性成功率提出了单调递增函数表达式。

    

    过去探索对抗性漏洞的研究都着眼于对手可以扰动模型输入的所有维度的情况。另一方面，许多最近的研究考虑以下情况：（i）对手可以扰动有限数量的输入参数或（ii）多模态问题中的模态子集。在这两种情况下，对抗性样本有效地受限于高维输入空间中的子空间$V$。出于这个动机，我们在本文中研究了对抗性漏洞如何取决于$V$的维数。特别地，我们展示了标准PGD攻击的对抗性成功率如何表现为$\epsilon (\frac{\dim(V)}{\dim \mathcal{X}})^{\frac{1}{q}}$的单调递增函数，其中$\epsilon$是扰动预算，$\frac{1}{p}+\frac{q}{q}=1$，只要$p>1$（当$p=1$时会出现额外的细微差别，我们对此进行了详细的分析）。这个函数形式可以很容易地推导。

    Past work exploring adversarial vulnerability have focused on situations where an adversary can perturb all dimensions of model input. On the other hand, a range of recent works consider the case where either (i) an adversary can perturb a limited number of input parameters or (ii) a subset of modalities in a multimodal problem. In both of these cases, adversarial examples are effectively constrained to a subspace $V$ in the ambient input space $\mathcal{X}$. Motivated by this, in this work we investigate how adversarial vulnerability depends on $\dim(V)$. In particular, we show that the adversarial success of standard PGD attacks with $\ell^p$ norm constraints behaves like a monotonically increasing function of $\epsilon (\frac{\dim(V)}{\dim \mathcal{X}})^{\frac{1}{q}}$ where $\epsilon$ is the perturbation budget and $\frac{1}{p} + \frac{1}{q} =1$, provided $p > 1$ (the case $p=1$ presents additional subtleties which we analyze in some detail). This functional form can be easily deriv
    
[^3]: 双重下降的谜团：辨识、解释和消解深度学习之谜

    Double Descent Demystified: Identifying, Interpreting & Ablating the Sources of a Deep Learning Puzzle. (arXiv:2303.14151v1 [cs.LG])

    [http://arxiv.org/abs/2303.14151](http://arxiv.org/abs/2303.14151)

    双重下降是机器学习中一个令人惊讶的现象，数据量、数据维度和模型参数是影响双重下降的关键因素。研究者找到了制造双重下降的三个解释性因素，并证明这些因素可以在简单神经网络中关闭。

    

    双重下降是机器学习中一个令人惊讶的现象，即随着模型参数数量相对于数据量的增长，测试误差在模型不断扩大而进入高度超参数化（数据未充分采样）阶段时下降。测试误差下降的这种情况与传统的关于过度拟合的学习理论相悖，可谓承载了机器学习中大型模型的成功。这种非单调的测试误差变化行为取决于数据的数量、数据的维度和模型参数的数量。在本文中，我们简要描述了双重下降现象，然后用易于理解和接受的方式对为何出现双重下降进行了解释，只需要了解线性代数和概率论的知识。我们使用多项式回归提供可视化的直观感受，然后通过普通线性回归数学分析双重下降，确定了三个解释性因素，当同时存在时，可以共同制造双重下降现象。随后，我们展示了这些因素如何被关闭在输出单个标量的简单神经网络中。最后，我们通过控制消融实验测试了这些因素在现代深度神经网络中的重要性，并证明双重下降现象不仅仅是超参数化模型所特有的，也出现在欠参数化模型和插值阈值中。

    Double descent is a surprising phenomenon in machine learning, in which as the number of model parameters grows relative to the number of data, test error drops as models grow ever larger into the highly overparameterized (data undersampled) regime. This drop in test error flies against classical learning theory on overfitting and has arguably underpinned the success of large models in machine learning. This non-monotonic behavior of test loss depends on the number of data, the dimensionality of the data and the number of model parameters. Here, we briefly describe double descent, then provide an explanation of why double descent occurs in an informal and approachable manner, requiring only familiarity with linear algebra and introductory probability. We provide visual intuition using polynomial regression, then mathematically analyze double descent with ordinary linear regression and identify three interpretable factors that, when simultaneously all present, together create double des
    
[^4]: 物理启发的神经网络在利用暗物质重建流体力学模拟中的应用

    Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter. (arXiv:2303.14090v1 [astro-ph.CO])

    [http://arxiv.org/abs/2303.14090](http://arxiv.org/abs/2303.14090)

    本文介绍了一种新的方法，将物理启发的神经网络应用于重建流体力学模拟中，通过将理论知识注入模型损失函数并结合新的性能评估指标，成功实现了对重子散射的重建。

    

    物理启发的神经网络已经成为一个合理的框架，用于构建将统计模式与领域知识相结合的预测模型。其基本理念是通过已知关系来丰富优化损失函数以限制可能解决方案的空间。水动力学模拟是现代宇宙学的核心组成部分，而所需的计算既昂贵又耗时。与此同时，快速模拟暗物质需要更少的资源，这导致了机器学习算法成为研究的一个活跃领域;在这里，重建流体力学模拟中发现的散射是一个持续的挑战。本文提出了将物理启发的神经网络应用于重建流体力学模拟中的新方法，它结合了神经网络架构的进步和物理约束，将关于重子转化效率的理论注入模型损失函数。我们还介绍了一种新的性能评估指标，基于结果图像中动力学功率谱中的误差，这使得可以量化网络对宇宙学参数推断的适用性。

    Physics-informed neural networks have emerged as a coherent framework for building predictive models that combine statistical patterns with domain knowledge. The underlying notion is to enrich the optimization loss function with known relationships to constrain the space of possible solutions. Hydrodynamic simulations are a core constituent of modern cosmology, while the required computations are both expensive and time-consuming. At the same time, the comparatively fast simulation of dark matter requires fewer resources, which has led to the emergence of machine learning algorithms for baryon inpainting as an active area of research; here, recreating the scatter found in hydrodynamic simulations is an ongoing challenge. This paper presents the first application of physics-informed neural networks to baryon inpainting by combining advances in neural network architectures with physical constraints, injecting theory on baryon conversion efficiency into the model loss function. We also in
    
[^5]: 差分隐私合成控制

    Differentially Private Synthetic Control. (arXiv:2303.14084v1 [cs.LG])

    [http://arxiv.org/abs/2303.14084](http://arxiv.org/abs/2303.14084)

    本文提供了首个具有显式误差界限的差分隐私合成控制算法，具有广泛的应用前景。

    

    合成控制是一种因果推断工具，用于通过创建合成对照数据来估计干预的治疗效果。这种方法结合了来自其他相似观察（即，捐赠者池）的测量结果，通过分析干预前目标和捐赠者池之间的关系来预测感兴趣的反事实时间序列（即，目标单元）。随着合成控制工具被越来越应用于敏感或专有数据，形式化的隐私保护通常是必需的。在这项工作中，我们提供了首个具有显式误差界限的差分隐私合成控制算法。我们的方法基于非私有合成控制和差分隐私经验风险最小化的工具。我们提供关于合成控制查询敏感性的上下界，并提供有关我们的私有合成控制算法准确性的显式误差界限。我们展示了我们的算法产生准确的预测结果。

    Synthetic control is a causal inference tool used to estimate the treatment effects of an intervention by creating synthetic counterfactual data. This approach combines measurements from other similar observations (i.e., donor pool ) to predict a counterfactual time series of interest (i.e., target unit) by analyzing the relationship between the target and the donor pool before the intervention. As synthetic control tools are increasingly applied to sensitive or proprietary data, formal privacy protections are often required. In this work, we provide the first algorithms for differentially private synthetic control with explicit error bounds. Our approach builds upon tools from non-private synthetic control and differentially private empirical risk minimization. We provide upper and lower bounds on the sensitivity of the synthetic control query and provide explicit error bounds on the accuracy of our private synthetic control algorithms. We show that our algorithms produce accurate pre
    
[^6]: 带有相关事件的预测竞赛。

    Forecasting Competitions with Correlated Events. (arXiv:2303.13793v1 [cs.LG])

    [http://arxiv.org/abs/2303.13793](http://arxiv.org/abs/2303.13793)

    此论文研究了带有相关事件的预测竞赛，并引入了一个块相关的概念。证明了在具有块相关性的分布下，基于follow-the-regularized-leader(FTRL)的竞赛机制仍然保留了它的$\epsilon$-最优保证。

    

    针对常见的赢家通吃机制中存在的激励问题，最近的预测竞赛研究从Witkowski等人[2022]开始。Frongillo等人[2021]提出了一种基于follow-the-regularized-leader(FTRL)的竞赛机制，这是一种在线学习框架。他们证明他们的机制仅使用$O(\log(n)/\epsilon^2)$个事件就能高概率选择一个$\epsilon$-最优的预测者。这些工作以及之前针对这个问题的所有工作都假设事件是独立的。我们开始研究带有相关事件的预测竞赛。为了量化相关性，我们引入了一个块相关的概念，它允许每个事件与最多$b$个事件强相关。我们证明，在具有这种相关性的分布下，FTRL机制仍然使用$O(b^2 \log(n)/\epsilon^2)$个事件保留了它的$\epsilon$-最优保证。我们的证明涉及到一种新的相关随机变量浓度界，这可能是重要的。

    Beginning with Witkowski et al. [2022], recent work on forecasting competitions has addressed incentive problems with the common winner-take-all mechanism. Frongillo et al. [2021] propose a competition mechanism based on follow-the-regularized-leader (FTRL), an online learning framework. They show that their mechanism selects an $\epsilon$-optimal forecaster with high probability using only $O(\log(n)/\epsilon^2)$ events. These works, together with all prior work on this problem thus far, assume that events are independent. We initiate the study of forecasting competitions for correlated events. To quantify correlation, we introduce a notion of block correlation, which allows each event to be strongly correlated with up to $b$ others. We show that under distributions with this correlation, the FTRL mechanism retains its $\epsilon$-optimal guarantee using $O(b^2 \log(n)/\epsilon^2)$ events. Our proof involves a novel concentration bound for correlated random variables which may be of br
    
[^7]: 基于多天线的双盲反卷积联合雷达通信的SoMAN最小化

    Multi-Antenna Dual-Blind Deconvolution for Joint Radar-Communications via SoMAN Minimization. (arXiv:2303.13609v1 [cs.IT])

    [http://arxiv.org/abs/2303.13609](http://arxiv.org/abs/2303.13609)

    本论文研究了多天线接收器版本的双盲反卷积问题，提出了使用多元原子范数最小化的方法来恢复雷达和通信信号和通道参数。

    

    联合雷达通信（JRC）已经成为一种有效利用有限电磁频谱的有前途的技术。在JRC应用中，如安全军用接收器中，雷达和通信信号经常叠加在接收信号中。在这些被动监听哨所中，雷达和通信的信号和通道对于接收器来说都是未知的。从叠加信号中恢复所有信号和通道参数的不适定问题被称为双盲反卷积（DBD）。在这项工作中，我们调查了更具挑战性的多天线接收器版本的DBD。我们用少数（稀疏）连续值参数，如时延、多普勒速度和到达方向（DoAs）来建模雷达和通信通道。为了解决这个高度不适定的DBD问题，我们建议最小化依赖于未知参数的多元原子范数（SoMAN）之和。为此，我们使用半定规划设计了一个精确的解。

    Joint radar-communications (JRC) has emerged as a promising technology for efficiently using the limited electromagnetic spectrum. In JRC applications such as secure military receivers, often the radar and communications signals are overlaid in the received signal. In these passive listening outposts, the signals and channels of both radar and communications are unknown to the receiver. The ill-posed problem of recovering all signal and channel parameters from the overlaid signal is terms as dual-blind deconvolution (DBD). In this work, we investigate a more challenging version of DBD with a multi-antenna receiver. We model the radar and communications channels with a few (sparse) continuous-valued parameters such as time delays, Doppler velocities, and directions-of-arrival (DoAs). To solve this highly ill-posed DBD, we propose to minimize the sum of multivariate atomic norms (SoMAN) that depends on the unknown parameters. To this end, we devise an exact semidefinite program using the
    
[^8]: 缺失数据的生存学习算法比较研究

    Une comparaison des algorithmes d'apprentissage pour la survie avec donn\'ees manquantes. (arXiv:2303.13590v1 [stat.ML])

    [http://arxiv.org/abs/2303.13590](http://arxiv.org/abs/2303.13590)

    本文研究了基于神经网络的生存任务学习算法在缺失数据处理方面的表现，结果显示对于所有情况没有单一的数据插补方法优于其他方法，提出的方法可用于比较其他缺失数据模式和(或)生存模型。

    

    生存分析是研究健康数据的重要工具。然而，缺失数据是这种数据的固有组成部分。近年来，研究人员提出了基于神经网络的新型生存任务学习算法。本研究对采用不同缺失数据处理方法的此类算法在模拟数据上的预测能力进行了研究，这些数据反映了现实情况，即个体属于未被观察到的群体。我们研究了不同的缺失数据模式，结果显示，没有单一的数据插补方法能够适用于所有情况而不需要进一步的特征工程。所提出的方法可用于比较其他缺失数据模式和(或)生存模型。Python代码通过survivalsim包可以访问。

    Survival analysis is an essential tool for the study of health data. An inherent component of such data is the presence of missing values. In recent years, researchers proposed new learning algorithms for survival tasks based on neural networks. Here, we studied the predictive performance of such algorithms coupled with different methods for handling missing values on simulated data that reflect a realistic situation, i.e., when individuals belong to unobserved clusters. We investigated different patterns of missing data. The results show that, without further feature engineering, no single imputation method is better than the others in all cases. The proposed methodology can be used to compare other missing data patterns and/or survival models. The Python code is accessible via the package survivalsim.  - L'analyse de survie est un outil essentiel pour l'\'etude des donn\'ees de sant\'e. Une composante inh\'erente \`a ces donn\'ees est la pr\'esence de valeurs manquantes. Ces derni\
    
[^9]: Scoring Functions 和 Generalization Prediction 的详细研究

    A Closer Look at Scoring Functions and Generalization Prediction. (arXiv:2303.13589v1 [cs.LG])

    [http://arxiv.org/abs/2303.13589](http://arxiv.org/abs/2303.13589)

    本文研究了广义误差预测器的有效性，探讨了置信度、局部流形平滑度和模型一致性评分函数的优缺点，发现在复杂机制缺失的情况下，最先进的评分无法在分布转移和损坏下超越简单的模型一致性。同时，在受损训练数据的情况下，模型一致性打分仍然表现良好，并且集成多样性有助于提高泛化性能。

    

    本文研究了广义误差预测器（GEPs）的效果，这些 GEPs 旨在通过从样本级分数中推导出数据集级误差估计值，从而预测模型在未见分布上的表现。然而，GEPs 常常利用不同的机制（例如，回归器、阈值函数、校准数据集等），来推导这种误差估计值，这会混淆特定评分函数的优点。因此，本文在机制选择独立的情况下，深入研究了流行的评分函数的有效性（置信度、局部流形平滑度、模型一致性）。我们发现，在复杂机制缺失的情况下，当估计分布转移和损坏下的误差时，最先进的置信度和平滑度基础评分无法超越简单的模型一致性。此外，在实际情况下，当训练数据受到损害时（例如标签噪声、测量噪声、欠采样），我们发现模型一致性打分仍然表现良好，并且集成多样性有助于提高泛化性能。

    Generalization error predictors (GEPs) aim to predict model performance on unseen distributions by deriving dataset-level error estimates from sample-level scores. However, GEPs often utilize disparate mechanisms (e.g., regressors, thresholding functions, calibration datasets, etc), to derive such error estimates, which can obfuscate the benefits of a particular scoring function. Therefore, in this work, we rigorously study the effectiveness of popular scoring functions (confidence, local manifold smoothness, model agreement), independent of mechanism choice. We find, absent complex mechanisms, that state-of-the-art confidence- and smoothness- based scores fail to outperform simple model-agreement scores when estimating error under distribution shifts and corruptions. Furthermore, on realistic settings where the training data has been compromised (e.g., label noise, measurement noise, undersampling), we find that model-agreement scores continue to perform well and that ensemble diversi
    
[^10]: 多维数组的多切片聚类中的DBSCAN算法

    DBSCAN of Multi-Slice Clustering for three-order Tensor. (arXiv:2303.07768v1 [cs.LG])

    [http://arxiv.org/abs/2303.07768](http://arxiv.org/abs/2303.07768)

    本文提出了 MSC-DBSCAN扩展算法，可以在三元聚类中从数据中提取不同子空间的不同切片聚类，并可以获得与 MSC 算法在处理秩一张量数据时相同的解决方案。

    

    对于三维数据的三元聚类，现有的几种方法需要指定每个维度的聚类大小或聚类数量。为了解决这个问题，三元聚类(MSC)算法可以在低维子空间中找到保留信号的切片以便基于相似度阈值找到聚类。本文提出了 MSC-DBSCAN扩展算法以从数据中提取位于不同子空间的不同切片聚类(如果数据集是r个秩一张量(r>1)的总和)。我们的算法使用和 MSC 算法相同的输入，可以在处理秩一张量数据时与 MSC 算法获得相同的解决方案。

    Several methods for triclustering three-dimensional data require the cluster size or the number of clusters in each dimension to be specified. To address this issue, the Multi-Slice Clustering (MSC) for 3-order tensor finds signal slices that lie in a low dimensional subspace for a rank-one tensor dataset in order to find a cluster based on the threshold similarity. We propose an extension algorithm called MSC-DBSCAN to extract the different clusters of slices that lie in the different subspaces from the data if the dataset is a sum of r rank-one tensor (r > 1). Our algorithm uses the same input as the MSC algorithm and can find the same solution for rank-one tensor data as MSC.
    
[^11]: 数据稀疏化技术用于卷积封闭分布

    Data thinning for convolution-closed distributions. (arXiv:2301.07276v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2301.07276](http://arxiv.org/abs/2301.07276)

    本文提出了数据稀疏化方法，适用于很多分布类型，包括高斯分布、泊松分布、负二项分布、伽玛分布和二项分布等。该方法具有广泛的应用，如在交叉验证方面提供了一种新的方法，能有效验证无监督学习算法的可靠性。

    

    我们提出了一种称为数据稀疏化的方法，将一个观测值分成两个或更多个互相独立的部分，这些部分都加起来等于原始数据，并且与原始观测值相同的分布，只是经过一个已知参数调整。这个非常普适的方法适用于任何卷积封闭分布，包括高斯分布、泊松分布、负二项分布、伽玛分布和二项分布等。数据稀疏化在模型选择、评价和推理方面有多种应用。例如，通过数据稀疏化的交叉验证提供了一种吸引人的替代方法来进行交叉验证，特别是在无监督的情况下，传统方法的样本划分不适用。我们在模拟和应用于单细胞RNA测序数据的实验中展示了数据稀疏化的普遍性，可以用于验证无监督学习方法的结果，如k-means聚类和主成分分析。

    We propose data thinning, an approach for splitting an observation into two or more independent parts that sum to the original observation, and that follow the same distribution as the original observation, up to a (known) scaling of a parameter. This very general proposal is applicable to any convolution-closed distribution, a class that includes the Gaussian, Poisson, negative binomial, gamma, and binomial distributions, among others. Data thinning has a number of applications to model selection, evaluation, and inference. For instance, cross-validation via data thinning provides an attractive alternative to the usual approach of cross-validation via sample splitting, especially in unsupervised settings in which the latter is not applicable. In simulations and in an application to single-cell RNA-sequencing data, we show that data thinning can be used to validate the results of unsupervised learning approaches, such as k-means clustering and principal components analysis.
    
[^12]: 深度条件测度量化

    Deep Conditional Measure Quantization. (arXiv:2301.06907v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.06907](http://arxiv.org/abs/2301.06907)

    提出了一种名为DCMQ的方法，该方法结合了基于Huber能量核的方法和深度神经网络架构，用于条件测度量化，并在多个实例中取得了有希望的结果。

    

    概率测度的量化意味着使用一组有限的狄拉克分布来近似表示输入分布（在一些概率测度度量空间中）。有各种各样的方法可以实现这一点，但可能会存在条件法的量化需要探索的情况。我们提出了一种称为DCMQ的方法，它涉及到基于Huber能量核的方法和深度神经网络体系结构的耦合。该方法在多个实例上进行了测试，并获得了有希望的结果。

    Quantization of a probability measure means representing it with a finite set of Dirac masses that approximates the input distribution well enough (in some metric space of probability measures). Various methods exists to do so, but the situation of quantizing a conditional law has been less explored. We propose a method, called DCMQ, involving a Huber-energy kernel-based approach coupled with a deep neural network architecture. The method is tested on several examples and obtains promising results.
    
[^13]: 面向稀有事件的动态因果发现：一种非参数条件独立性检验

    Towards Dynamic Causal Discovery with Rare Events: A Nonparametric Conditional Independence Test. (arXiv:2211.16596v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.16596](http://arxiv.org/abs/2211.16596)

    该论文提出了一种针对稀有事件的新的因果发现方法，基于收集到的时间不变动态系统的数据，构建了叠加数据集和条件独立性检验的方法。该方法能够揭示在变量第一次经历低概率实现时才会显现的因果关系，具有很好的可行性和可扩展性。

    

    与稀有事件相关联的因果现象在许多工程问题中都存在，例如针对风险的安全分析、事故分析和预防以及极值理论等。然而，当前的因果发现方法往往无法发现在随机变量之间的原因联系，特别是在变动环境下，仅在变量第一次经历低概率实现时才会显现。为了解决这个问题，我们引入了一种新的统计独立性检验方法，用于从发生稀有但具有重要影响的时间不变动态系统收集的数据中进行因果探索。具体而言，我们利用底层数据的时间不变性来构建一个叠加的数据集，其中包括在不同时间步骤之前稀有事件发生前系统状态的数据。然后我们设计了一个在重新组织的数据上进行条件独立性检验的方法。我们提供了我们方法一致性的非渐近样本复杂度界限，并验证了它在各种模拟和真实世界数据集上的性能。

    Causal phenomena associated with rare events occur across a wide range of engineering problems, such as risk-sensitive safety analysis, accident analysis and prevention, and extreme value theory. However, current methods for causal discovery are often unable to uncover causal links, between random variables in a dynamic setting, that manifest only when the variables first experience low-probability realizations. To address this issue, we introduce a novel statistical independence test on data collected from time-invariant dynamical systems in which rare but consequential events occur. In particular, we exploit the time-invariance of the underlying data to construct a superimposed dataset of the system state before rare events happen at different timesteps. We then design a conditional independence test on the reorganized data. We provide non-asymptotic sample complexity bounds for the consistency of our method, and validate its performance across various simulated and real-world datase
    
[^14]: 大深度网络的隐式偏见：非线性函数的秩定义。

    Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions. (arXiv:2209.15055v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.15055](http://arxiv.org/abs/2209.15055)

    本文研究了全连接神经网络的表示成本和深度之间的关系，发现其会收敛到非线性函数的秩的概念。同时，发现在一定的深度范围内，全局最小值可以恢复真实的数据秩，并探讨了分类器秩对类边界拓扑结构的影响。

    

    我们展示了具有齐次非线性函数的全连接神经网络的表示成本——描述了具有$L_2$正则化或交叉熵等损失网络在函数空间中的隐式偏见——随着网络深度趋近于无穷大，会收敛到非线性函数的秩的概念。然后，我们探究了全局最小值在哪些条件下可以恢复“真实”数据秩：我们展示出，对于太大的深度，全局最小值会近似为秩1（低估秩）；我们随后论证了有一系列深度，随着数据点数量增加，可以恢复真实秩。最后，我们讨论了分类器秩对结果类边界的拓扑结构的影响，并展示了具有最佳非线性秩的自编码器具有自然去噪的特性。

    We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a notion of rank over nonlinear functions. We then inquire under which conditions the global minima of the loss recover the `true' rank of the data: we show that for too large depths the global minimum will be approximately rank 1 (underestimating the rank); we then argue that there is a range of depths which grows with the number of datapoints where the true rank is recovered. Finally, we discuss the effect of the rank of a classifier on the topology of the resulting class boundaries and show that autoencoders with optimal nonlinear rank are naturally denoising.
    
[^15]: 可计算概率模型的连续混合

    Continuous Mixtures of Tractable Probabilistic Models. (arXiv:2209.10584v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10584](http://arxiv.org/abs/2209.10584)

    本文研究了一种连续混合的方法，将可计算概率模型和基于连续潜空间的模型结合起来，从而实现了高效的概率推断。

    

    基于连续潜空间的概率模型，如变分自编码器，可以理解为在潜变量上连续依赖的不可数混合模型。它们已被证明是表达生成和概率建模的有效工具，但与能够计算所表示的概率分布的较为简单的可计算概率推断方法存在矛盾。与此同时，可计算概率模型，如概率电路(PCs)，可以理解为层次离散混合模型，因此能够高效地进行准确推断，但在与连续潜空间模型相比时通常表现不佳。在本文中，我们研究了一种混合方法，即具有小潜变量维度的可计算模型的连续混合。尽管这些模型在解析上是难以处理的，但它们适合于基于有限积分点集的数值积分方案。通过足够大的积分点集，我们可以紧密地近似概率模型并进行高效推断。

    Probabilistic models based on continuous latent spaces, such as variational autoencoders, can be understood as uncountable mixture models where components depend continuously on the latent code. They have proven to be expressive tools for generative and probabilistic modelling, but are at odds with tractable probabilistic inference, that is, computing marginals and conditionals of the represented probability distribution. Meanwhile, tractable probabilistic models such as probabilistic circuits (PCs) can be understood as hierarchical discrete mixture models, and thus are capable of performing exact inference efficiently but often show subpar performance in comparison to continuous latent-space models. In this paper, we investigate a hybrid approach, namely continuous mixtures of tractable models with a small latent dimension. While these models are analytically intractable, they are well amenable to numerical integration schemes based on a finite set of integration points. With a large 
    
[^16]: Euler State Networks: 非耗散性水库计算

    Euler State Networks: Non-dissipative Reservoir Computing. (arXiv:2203.09382v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.09382](http://arxiv.org/abs/2203.09382)

    本文提出了一种新型水库计算模型EuSN，其利用前向欧拉离散化和反对称循环矩阵来设计水库动力学，具有接近稳定边缘的饱和有效谱半径和零局部李雅普诺夫指数。在长期记忆任务和时间序列分类基准测试中表现出了优异的性能。

    

    本文受到常微分方程的数值解启发，提出了一种新型水库计算(EuSN)模型，该方法利用前向欧拉离散化和反对称循环矩阵来设计水库动力学。该模型的数学分析表明，其具有接近稳定边缘的饱和有效谱半径和零局部李雅普诺夫指数。对长期记忆任务的实验表明，与标准水库计算模型相比，所提出的方法在需要多个时步有效传播输入信息的问题上具有明显的优势。此外，时间序列分类基准测试结果表明，EuSN能够匹配甚至超过可训练循环神经网络的准确性，同时保持水库计算家族的训练效率。

    Inspired by the numerical solution of ordinary differential equations, in this paper we propose a novel Reservoir Computing (RC) model, called the Euler State Network (EuSN). The presented approach makes use of forward Euler discretization and antisymmetric recurrent matrices to design reservoir dynamics that are both stable and non-dissipative by construction.  Our mathematical analysis shows that the resulting model is biased towards a unitary effective spectral radius and zero local Lyapunov exponents, intrinsically operating near to the edge of stability. Experiments on long-term memory tasks show the clear superiority of the proposed approach over standard RC models in problems requiring effective propagation of input information over multiple time-steps. Furthermore, results on time-series classification benchmarks indicate that EuSN is able to match (or even exceed) the accuracy of trainable Recurrent Neural Networks, while retaining the training efficiency of the RC family, res
    
[^17]: 学习粗标签的高效算法

    Efficient Algorithms for Learning from Coarse Labels. (arXiv:2108.09805v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.09805](http://arxiv.org/abs/2108.09805)

    本文研究了从粗糙数据中学习的问题，提出了一种高效的算法，只需足够信息的粗标签即可在从细标签中学习的任何问题上进行学习。

    

    对于许多学习问题，我们可能无法访问细粒度标签信息；例如，根据注释者的专业知识，一幅图像可以被标记为哈士奇、狗甚至动物。本文对这些情况进行了形式化，并研究了从此类粗数据学习的问题。我们不是观察来自集合 $\mathcal{Z}$ 的实际标签，而是观察对应于 $\mathcal{Z}$ 的划分（或多种划分的混合）的粗标签。我们的主要算法结果是：几乎任何可从细粒度标签中学习的问题，当粗数据足够信息时也可以高效地学习。我们通过泛化减少回答统计查询（SQ) 的方式来获得结果，只给出粗标签而不是细标签。所需粗标签数量与粗糙化信息失真和细标签数量 $|\mathcal{Z}|$ 成多项式关系。我们还研究了（无限多个）实值标签的情况。

    For many learning problems one may not have access to fine grained label information; e.g., an image can be labeled as husky, dog, or even animal depending on the expertise of the annotator. In this work, we formalize these settings and study the problem of learning from such coarse data. Instead of observing the actual labels from a set $\mathcal{Z}$, we observe coarse labels corresponding to a partition of $\mathcal{Z}$ (or a mixture of partitions).  Our main algorithmic result is that essentially any problem learnable from fine grained labels can also be learned efficiently when the coarse data are sufficiently informative. We obtain our result through a generic reduction for answering Statistical Queries (SQ) over fine grained labels given only coarse labels. The number of coarse labels required depends polynomially on the information distortion due to coarsening and the number of fine labels $|\mathcal{Z}|$.  We also investigate the case of (infinitely many) real valued labels foc
    
[^18]: 使用交叉U统计量的维度不可知推断

    Dimension-agnostic inference using cross U-statistics. (arXiv:2011.05068v6 [math.ST] UPDATED)

    [http://arxiv.org/abs/2011.05068](http://arxiv.org/abs/2011.05068)

    该论文介绍了一种新的统计推断方法，它不依赖于对数据集维度的假设，可以在高维数据集上进行推断。

    

    经典的统计推断渐进理论通常涉及通过固定维度d来让样本量n趋向无穷，从而校准统计量。最近，人们大力研究了这些方法在高维情况下的表现，其中d和n都同时增加到无穷。这往往导致不同的推断过程，取决于对维度性的假设，让从业者感到为难：对于一个20维的100个样本的数据集，他们应该假设n>>d，还是d/n约为0.2？本文考虑了维度不可知推断的目标；开发出的方法的有效性不依赖于对d和n的任何假设。我们引入了一种方法，使用现有测试统计量的变分表示，结合样本拆分和自规范化，产生了一个精细的测试统计量，其高斯极限分布的有效性不取决于d和n的关系。我们证明了该方法的有效性，并研究了其在实际应用中的性能。

    Classical asymptotic theory for statistical inference usually involves calibrating a statistic by fixing the dimension $d$ while letting the sample size $n$ increase to infinity. Recently, much effort has been dedicated towards understanding how these methods behave in high-dimensional settings, where $d$ and $n$ both increase to infinity together. This often leads to different inference procedures, depending on the assumptions about the dimensionality, leaving the practitioner in a bind: given a dataset with 100 samples in 20 dimensions, should they calibrate by assuming $n \gg d$, or $d/n \approx 0.2$? This paper considers the goal of dimension-agnostic inference; developing methods whose validity does not depend on any assumption on $d$ versus $n$. We introduce an approach that uses variational representations of existing test statistics along with sample splitting and self-normalization to produce a refined test statistic with a Gaussian limiting distribution, regardless of how $d$
    
[^19]: UCB Bandits在对抗攻击中的近乎最优攻击策略

    Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2008.09312](http://arxiv.org/abs/2008.09312)

    本文提出了一种在对抗攻击下的UCB最优拉臂策略，成本为$\sqrt{\log T}$，并且证明了此攻击策略近乎是最优的。

    

    本文考虑了一种随机多臂赌博问题，其中奖励受到对抗性破坏。我们提出了一种新颖的攻击策略，通过操作UCB原则来拉动一些非最优目标臂$T-o(T)$次，累积成本的标度为$\sqrt{\log T}$，其中$T$为回合数。我们还证明了累积攻击成本的第一个下界。我们的下界与我们的上界匹配，除了$\log\log T$因子，表明我们的攻击策略近乎是最优的。

    We consider a stochastic multi-arm bandit problem where rewards are subject to adversarial corruption. We propose a novel attack strategy that manipulates a UCB principle into pulling some non-optimal target arm $T - o(T)$ times with a cumulative cost that scales as $\sqrt{\log T}$, where $T$ is the number of rounds. We also prove the first lower bound on the cumulative attack cost. Our lower bound matches our upper bound up to $\log \log T$ factors, showing our attack to be near optimal.
    

