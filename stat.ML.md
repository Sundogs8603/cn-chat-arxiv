# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Smoothing ADMM for Sparse-Penalized Quantile Regression with Non-Convex Penalties.](http://arxiv.org/abs/2309.03094) | 本文提出了一种适用于稀疏加权分位数回归的新型单循环平滑ADMM算法，名为SIAD，它在存在非凸和非光滑稀疏惩罚条件下能够加速收敛速度。 |
| [^2] | [Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks.](http://arxiv.org/abs/2309.03061) | 该论文提出了一种通过识别对神经网络输出具有最显著影响的参数方向构建低维子空间的方法，从而解决了贝叶斯深度学习中由于参数空间高维度而带来的计算复杂性问题。通过在显著减少的主动子空间上进行蒙特卡罗采样或变分推理，该方法实现了有效和可扩展的贝叶斯推理，并通过多个回归任务的实证验证了可靠的预测和鲁棒的不确定性估计。 |
| [^3] | [CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra.](http://arxiv.org/abs/2309.03060) | CoLA是一个用于机器学习中大规模线性代数问题的简单但通用的框架，通过组合调度规则和线性操作符抽象，自动构建了内存和运行时高效的数值算法，提供了内存高效的自动微分、低精度计算和GPU加速，同时可以适应下游软件包中的新对象、操作和规则。 |
| [^4] | [Amortised Inference in Bayesian Neural Networks.](http://arxiv.org/abs/2309.03018) | 本文提出了一种摊销推理的贝叶斯神经网络方法，通过对推理进行摊销，能够更有效地利用数据进行概率元学习。 |
| [^5] | [An Offline Learning Approach to Propagator Models.](http://arxiv.org/abs/2309.02994) | 本研究提出了一个离线学习方法，通过非参数估计传播模型，并引入悲观的损失功能来考虑估计的传播器的不确定性。 |
| [^6] | [The Curse of Memory in Stochastic Approximation: Extended Version.](http://arxiv.org/abs/2309.02944) | 本文研究了随机逼近中的记忆诅咒问题，并探讨了在不同情况下的结果。在具有几何遍历马尔可夫扰动的情况下，目标偏差一般非零。此外，当参数估计使用平均法时，估计值收敛到渐近无偏，且具有近似最优的渐近协方差。 |
| [^7] | [Generalised Mutual Information: a Framework for Discriminative Clustering.](http://arxiv.org/abs/2309.02858) | 本文介绍了通用互信息（GEMINI）作为一种辨别聚类的框架，相比互信息（MI），GEMINI在无监督神经网络训练过程中不需要正则化，其可以选择合适的聚类数量。 |
| [^8] | [Random postprocessing for combinatorial Bayesian optimization.](http://arxiv.org/abs/2309.02842) | 针对组合贝叶斯优化，我们研究了一种随机后处理方法，严格禁止数据集中的重复样本，结果表明此方法显著减少了顺序步骤数，特别是在最大后验估计的情况下，为解决高维问题中贝叶斯优化的收敛速度慢提供了一种简单但通用的策略。 |
| [^9] | [On the Effects of Heterogeneous Errors on Multi-fidelity Bayesian Optimization.](http://arxiv.org/abs/2309.02771) | 本文研究了异质误差对多保真贝叶斯优化的影响，并提出了解决现有假设不成立时性能下降的方法。 |
| [^10] | [Adaptive Consensus: A network pruning approach for decentralized optimization.](http://arxiv.org/abs/2309.02626) | 这项研究提出了一种自适应共识的方法来解决网络中的分散优化问题，利用周期性追踪不一致误差和精选有效边缘的策略来减少通信量，并在理论上证明了算法的收敛性和收敛速度的界限。 |
| [^11] | [Distributed Variational Inference for Online Supervised Learning.](http://arxiv.org/abs/2309.02606) | 本文提出了一种适用于智能传感器网络的分布式变分推断算法，可以解决连续变量、大规模实时数据和难以处理的后验概率的推断问题。通过推导出可分离的较低下界，实现了在传感器网络中进行一跳通信的分布式变分推断，并提出了处理二进制问题的方法。 |
| [^12] | [Data Aggregation for Hierarchical Clustering.](http://arxiv.org/abs/2309.02552) | 本研究介绍了如何利用数据聚合算法BETULA使得资源受限系统上的层次聚类方法HAC变得可行，从而允许对非常大的数据集进行探索性数据分析。 |
| [^13] | [Diffusion on the Probability Simplex.](http://arxiv.org/abs/2309.02530) | 本文提出了一种在概率单纯形上执行扩散的方法，通过使用softmax函数应用于阿恩斯坦-乌伦贝克过程，可以在处理连续性和离散性对象之间的紧张关系时取得良好效果。这种方法也可以扩展到单位立方体上，从而在有界图像生成方面具有应用前景。 |
| [^14] | [Optimal Sample Selection Through Uncertainty Estimation and Its Application in Deep Learning.](http://arxiv.org/abs/2309.02476) | 该论文提出了一种理论最优解——COPS（基于不确定性的最优子采样），用于解决深度学习中的核心集选择和主动学习问题，在减少标记数据集成本的同时最小化模型的期望损失。 |
| [^15] | [A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges.](http://arxiv.org/abs/2309.02473) | 这篇论文综述了模仿学习的算法、最新进展和挑战，指出在复杂和非结构化的环境中，通过模仿专家行为来学习所需行为更具吸引力。 |
| [^16] | [CONFIDERAI: a novel CONFormal Interpretable-by-Design score function forExplainable and Reliable Artificial Intelligence.](http://arxiv.org/abs/2309.01778) | 提出了一种新的可解释机器学习评分函数CONFIDERAI，它将一致性预测与规则模型相结合，利用规则的预测能力和点的几何位置，在特征空间中定义满足一致性保证的区域。 |
| [^17] | [Topological Ordering in Differentiable Bayesian Structure Learning with Guaranteed Acyclicity Constraint.](http://arxiv.org/abs/2309.01392) | 本研究提出了一种在贝叶斯结构学习中严格约束图的无环性的替代方法，通过整合拓扑排序知识，能够减少推理复杂性，并确保生成的图的结构是无环的。实证实验表明，该方法胜过相关的贝叶斯基于得分的方法。 |
| [^18] | [Interpretation of High-Dimensional Linear Regression: Effects of Nullspace and Regularization Demonstrated on Battery Data.](http://arxiv.org/abs/2309.00564) | 本文研究了高维线性回归在解释方面的挑战，发现空间零值和正则化对回归系数产生重要影响，并提出了一种优化公式来比较回归系数与物理工程知识得到的系数，从而实现解释性的回归结果。 |
| [^19] | [An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And Gaussian Mixture Embedding For Neural Network.](http://arxiv.org/abs/2308.09444) | 我们提出了一种高斯混合模型的学习算法，具有更好的鲁棒性和简单性，只需要进行1次迭代学习。我们的方法能更好地处理数据不确定性和逆问题，并且有潜力构建能够利用分布随机抽样进行随机变异和变异控制的应用。 |
| [^20] | [Causal thinking for decision making on Electronic Health Records: why and how.](http://arxiv.org/abs/2308.01605) | 本文介绍了在电子健康记录中使用因果思维进行决策的必要性和方法。通过模拟随机试验来个性化决策，以减少数据中的偏见。这对于分析电子健康记录或索赔数据以得出因果结论的最重要陷阱和考虑因素进行了重点强调。 |
| [^21] | [Manifold Filter-Combine Networks.](http://arxiv.org/abs/2307.04056) | 这篇论文介绍了一类称为流形滤波-组合网络的大型流形神经网络。作者提出了一种基于构建数据驱动图的方法来实现这种网络，并提供了收敛到连续极限的充分条件，其收敛速度不依赖于滤波器数量。 |
| [^22] | [Optimism and Adaptivity in Policy Optimization.](http://arxiv.org/abs/2306.10587) | 本文通过将看似无关的策略优化算法重新构造为共同的两个交错步骤，即乐观策略改进和后见适应，统一了强化学习中的策略优化方法，揭示了加速方法中的乐观性和适应性的共同理论属性。 |
| [^23] | [Kernel Random Projection Depth for Outlier Detection.](http://arxiv.org/abs/2306.07056) | 本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。 |
| [^24] | [Gibbs free energies via isobaric-isothermal flows.](http://arxiv.org/abs/2305.13233) | 采用机器学习模型利用等压等温流得到吉布斯自由能，并在单原子水的结晶中进行了测试，表现出优秀的性能。 |
| [^25] | [Neural-prior stochastic block model.](http://arxiv.org/abs/2303.09995) | 本研究提出了神经先验随机块模型，将社区建模为由节点属性决定。基于置信传递和近似消息传递的结合，可以在处理社交网络、图像分割，生物物种等方面发挥作用。 |
| [^26] | [A Topological Deep Learning Framework for Neural Spike Decoding.](http://arxiv.org/abs/2212.05037) | 这项工作开发了一个基于拓扑学的深度学习框架，用于解码神经突触输出，以更好地理解和表示大脑中的神经结构。 |
| [^27] | [Sample-Efficient Personalization: Modeling User Parameters as Low Rank Plus Sparse Components.](http://arxiv.org/abs/2210.03505) | 该论文提出了一种高效的个性化算法，通过将网络权重建模为低秩和稀疏分量的总和，既捕捉了多个用户间的共同信息，又能够捕捉用户个性化的特点。 |
| [^28] | [Understanding convolution on graphs via energies.](http://arxiv.org/abs/2206.10991) | 本论文结合能量的概念，证明了带对称滤波器的线性图卷积可以增强高频率，使图神经网络在同质和异质任务中表现更好。 |
| [^29] | [Strong posterior contraction rates via Wasserstein dynamics.](http://arxiv.org/abs/2203.10754) | 本文提出了一种新的方法来解决强强后验收缩速率的问题，在函数参数空间中使用动态的Wasserstein距离和后验分布的局部Lipschitz连续性，建立了PCR与数学分析、概率论和统计学中一些经典问题的联系。 |
| [^30] | [Error Scaling Laws for Kernel Classification under Source and Capacity Conditions.](http://arxiv.org/abs/2201.12655) | 本文研究了核分类问题中的错误缩放定律，针对满足源条件和容量条件的数据集类别，在高斯设计下导出了误差衰减率与源和容量系数的关系，并对比了最大化间隔支持向量机和岭分类两种方法。 |
| [^31] | [Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning.](http://arxiv.org/abs/2006.02482) | 本文提出了一种用于解释黑箱预测算法行为的因果学习方法，通过学习因果图表示来提供因果解释，弥补了现有方法的缺点，即解释单元更加可解释且考虑了宏观级特征和未测量的混淆。 |

# 详细

[^1]: 具有非凸惩罚的稀疏加权分位数回归的平滑ADMM

    Smoothing ADMM for Sparse-Penalized Quantile Regression with Non-Convex Penalties. (arXiv:2309.03094v1 [stat.ML])

    [http://arxiv.org/abs/2309.03094](http://arxiv.org/abs/2309.03094)

    本文提出了一种适用于稀疏加权分位数回归的新型单循环平滑ADMM算法，名为SIAD，它在存在非凸和非光滑稀疏惩罚条件下能够加速收敛速度。

    

    本文研究了在非凸和非光滑稀疏惩罚条件下的分位数回归，如最小最大凹惩罚（MCP）和平滑剪切绝对偏差（SCAD）。这些问题的非光滑和非凸特性经常导致许多算法的收敛困难。虽然迭代技术如坐标下降和局部线性近似可以促进收敛，但过程通常很慢。这种缓慢的速度主要是因为需要在每一步运行这些近似技术直到完全收敛，这是我们称之为\emph{二次收敛迭代}的要求。为了加速收敛速度，我们采用了交替方向乘法（ADMM）并引入了一种新的具有递增惩罚参数的单循环平滑ADMM算法，命名为SIAD，专门用于稀疏加权分位数回归。我们首先深入研究了所提出的SIAD算法的收敛性质和估计。

    This paper investigates quantile regression in the presence of non-convex and non-smooth sparse penalties, such as the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD). The non-smooth and non-convex nature of these problems often leads to convergence difficulties for many algorithms. While iterative techniques like coordinate descent and local linear approximation can facilitate convergence, the process is often slow. This sluggish pace is primarily due to the need to run these approximation techniques until full convergence at each step, a requirement we term as a \emph{secondary convergence iteration}. To accelerate the convergence speed, we employ the alternating direction method of multipliers (ADMM) and introduce a novel single-loop smoothing ADMM algorithm with an increasing penalty parameter, named SIAD, specifically tailored for sparse-penalized quantile regression. We first delve into the convergence properties of the proposed SIAD algorithm and est
    
[^2]: 学习主动子空间在深度神经网络的有效和可扩展的不确定性量化中

    Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks. (arXiv:2309.03061v1 [stat.ML])

    [http://arxiv.org/abs/2309.03061](http://arxiv.org/abs/2309.03061)

    该论文提出了一种通过识别对神经网络输出具有最显著影响的参数方向构建低维子空间的方法，从而解决了贝叶斯深度学习中由于参数空间高维度而带来的计算复杂性问题。通过在显著减少的主动子空间上进行蒙特卡罗采样或变分推理，该方法实现了有效和可扩展的贝叶斯推理，并通过多个回归任务的实证验证了可靠的预测和鲁棒的不确定性估计。

    

    贝叶斯推理用于神经网络或贝叶斯深度学习具有提供具有量化的不确定性和鲁棒性的良好校准预测的潜力。然而，贝叶斯深度学习的主要障碍是由于参数空间的高维度而造成的计算复杂性。在这项工作中，我们提出了一种新颖的方案，通过识别对神经网络输出具有最显著影响的参数方向，构建神经网络参数的低维子空间，即主动子空间。我们证明了显著减少的主动子空间通过蒙特卡罗（MC）采样方法（否则难以计算）或变分推理实现了有效和可扩展的贝叶斯推理。从实证上看，我们的方法为各种回归任务提供了可靠的预测和鲁棒的不确定性估计。

    Bayesian inference for neural networks, or Bayesian deep learning, has the potential to provide well-calibrated predictions with quantified uncertainty and robustness. However, the main hurdle for Bayesian deep learning is its computational complexity due to the high dimensionality of the parameter space. In this work, we propose a novel scheme that addresses this limitation by constructing a low-dimensional subspace of the neural network parameters-referred to as an active subspace-by identifying the parameter directions that have the most significant influence on the output of the neural network. We demonstrate that the significantly reduced active subspace enables effective and scalable Bayesian inference via either Monte Carlo (MC) sampling methods, otherwise computationally intractable, or variational inference. Empirically, our approach provides reliable predictions with robust uncertainty estimates for various regression tasks.
    
[^3]: CoLA: 深入利用组合结构实现自动和高效的数值线性代数

    CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra. (arXiv:2309.03060v1 [cs.LG])

    [http://arxiv.org/abs/2309.03060](http://arxiv.org/abs/2309.03060)

    CoLA是一个用于机器学习中大规模线性代数问题的简单但通用的框架，通过组合调度规则和线性操作符抽象，自动构建了内存和运行时高效的数值算法，提供了内存高效的自动微分、低精度计算和GPU加速，同时可以适应下游软件包中的新对象、操作和规则。

    

    许多机器学习和科学领域涉及到大规模的线性代数问题，如特征分解、解线性系统、计算矩阵指数和迹估计等。涉及的矩阵通常具有Krondor、卷积、块对角、求和或乘积等结构。在本文中，我们提出了一个简单但通用的机器学习大规模线性代数问题的框架，名为CoLA（组合线性代数）。通过将线性操作符抽象与组合调度规则相结合，CoLA能够自动构建内存和运行时高效的数值算法。此外，CoLA还提供内存高效的自动微分、低精度计算和JAX和PyTorch中的GPU加速，同时还能够通过多重调度适应下游软件包中的新对象、操作和规则。CoLA可以加速许多代数操作，同时也便于原型化矩阵结构和算法，提供了可行性的降低-

    Many areas of machine learning and science involve large linear algebra problems, such as eigendecompositions, solving linear systems, computing matrix exponentials, and trace estimation. The matrices involved often have Kronecker, convolutional, block diagonal, sum, or product structure. In this paper, we propose a simple but general framework for large-scale linear algebra problems in machine learning, named CoLA (Compositional Linear Algebra). By combining a linear operator abstraction with compositional dispatch rules, CoLA automatically constructs memory and runtime efficient numerical algorithms. Moreover, CoLA provides memory efficient automatic differentiation, low precision computation, and GPU acceleration in both JAX and PyTorch, while also accommodating new objects, operations, and rules in downstream packages via multiple dispatch. CoLA can accelerate many algebraic operations, while making it easy to prototype matrix structures and algorithms, providing an appealing drop-
    
[^4]: 贝叶斯神经网络的摊销推理

    Amortised Inference in Bayesian Neural Networks. (arXiv:2309.03018v1 [stat.ML])

    [http://arxiv.org/abs/2309.03018](http://arxiv.org/abs/2309.03018)

    本文提出了一种摊销推理的贝叶斯神经网络方法，通过对推理进行摊销，能够更有效地利用数据进行概率元学习。

    

    元学习是一种框架，机器学习模型在一组数据集上进行训练，以便在测试时对新数据集进行预测。近年来，概率元学习受到研究界的广泛关注，但许多现有的概率元模型存在一个共性问题，即需要大量数据集才能生成具有高质量预测和良好校准不确定性估计的模型。然而，在许多应用中，很难获取这么多数据。在本文中，我们通过在贝叶斯神经网络中对推理进行摊销，引入了摊销伪观测变分推理贝叶斯神经网络（APOVI-BNN），提出了一种更加高效利用数据的概率元学习方法。首先，我们展示了在我们的摊销方案下获取的近似后验与传统变分推理获取的近似后验具有相似或更好的质量。

    Meta-learning is a framework in which machine learning models train over a set of datasets in order to produce predictions on new datasets at test time. Probabilistic meta-learning has received an abundance of attention from the research community in recent years, but a problem shared by many existing probabilistic meta-models is that they require a very large number of datasets in order to produce high-quality predictions with well-calibrated uncertainty estimates. In many applications, however, such quantities of data are simply not available.  In this dissertation we present a significantly more data-efficient approach to probabilistic meta-learning through per-datapoint amortisation of inference in Bayesian neural networks, introducing the Amortised Pseudo-Observation Variational Inference Bayesian Neural Network (APOVI-BNN). First, we show that the approximate posteriors obtained under our amortised scheme are of similar or better quality to those obtained through traditional vari
    
[^5]: 一个离线学习方法用于传播模型

    An Offline Learning Approach to Propagator Models. (arXiv:2309.02994v1 [math.OC])

    [http://arxiv.org/abs/2309.02994](http://arxiv.org/abs/2309.02994)

    本研究提出了一个离线学习方法，通过非参数估计传播模型，并引入悲观的损失功能来考虑估计的传播器的不确定性。

    

    本文考虑了一个离线学习问题，其中一个代理首先从静态数据集中估计未知的价格冲击核，然后设计策略以平仓风险资产同时产生短暂的价格冲击。我们提出了一种新颖的方法，通过包含相关价格轨迹、交易信号和元订单的数据集对传播者进行非参数估计。我们使用一个取决于数据集的度量标准来量化估计传播器的准确性。我们表明，一个仅基于估计的传播者使用贪婪策略来尽量减少交易成本的交易者会由于交易策略与估计器之间所谓的伪相关性以及由于有偏成本功能引起的固有不确定性而遇到次优性。通过采用离线强化学习方法，我们引入了一个悲观的损失功能，将估计的传播器的不确定性考虑在内，并带有优化器。

    We consider an offline learning problem for an agent who first estimates an unknown price impact kernel from a static dataset, and then designs strategies to liquidate a risky asset while creating transient price impact. We propose a novel approach for a nonparametric estimation of the propagator from a dataset containing correlated price trajectories, trading signals and metaorders. We quantify the accuracy of the estimated propagator using a metric which depends explicitly on the dataset. We show that a trader who tries to minimise her execution costs by using a greedy strategy purely based on the estimated propagator will encounter suboptimality due to so-called spurious correlation between the trading strategy and the estimator and due to intrinsic uncertainty resulting from a biased cost functional. By adopting an offline reinforcement learning approach, we introduce a pessimistic loss functional taking the uncertainty of the estimated propagator into account, with an optimiser wh
    
[^6]: 随机逼近中的记忆诅咒：扩展版本

    The Curse of Memory in Stochastic Approximation: Extended Version. (arXiv:2309.02944v1 [math.ST])

    [http://arxiv.org/abs/2309.02944](http://arxiv.org/abs/2309.02944)

    本文研究了随机逼近中的记忆诅咒问题，并探讨了在不同情况下的结果。在具有几何遍历马尔可夫扰动的情况下，目标偏差一般非零。此外，当参数估计使用平均法时，估计值收敛到渐近无偏，且具有近似最优的渐近协方差。

    

    自适应控制的最早的日子以来，随机逼近（SA）的理论和应用在控制系统的社区中得到了快速发展。本文以新的视角重新审视了这个主题，受到最近的结果的启发，该结果证明使用（足够小的）恒定步长α>0的SA具有非凡的性能。如果采用平均法获取最终的参数估计，则估计值在渐近无偏和近似最优的渐近协方差下收敛。这些结果是针对具有独立同分布系数的随机线性SA递归获得的。本文在更常见的几何遍历马尔可夫扰动的情况下获得了非常不同的结论：（i）在非线性SA的情况下，识别出了“目标偏差”，并且一般上不为零。其余的结果是针对线性SA递归建立的：（ii）双变量参数扰动过程在拓扑意义上具有几何遍历性；（iii）偏差的表示具有简单的性质。

    Theory and application of stochastic approximation (SA) has grown within the control systems community since the earliest days of adaptive control. This paper takes a new look at the topic, motivated by recent results establishing remarkable performance of SA with (sufficiently small) constant step-size $\alpha>0$. If averaging is implemented to obtain the final parameter estimate, then the estimates are asymptotically unbiased with nearly optimal asymptotic covariance. These results have been obtained for random linear SA recursions with i.i.d.\ coefficients. This paper obtains very different conclusions in the more common case of geometrically ergodic Markovian disturbance: (i) The \textit{target bias} is identified, even in the case of non-linear SA, and is in general non-zero. The remaining results are established for linear SA recursions: (ii) the bivariate parameter-disturbance process is geometrically ergodic in a topological sense; (iii) the representation for bias has a simple
    
[^7]: 通用互信息：一种辨别聚类的框架

    Generalised Mutual Information: a Framework for Discriminative Clustering. (arXiv:2309.02858v1 [stat.ML])

    [http://arxiv.org/abs/2309.02858](http://arxiv.org/abs/2309.02858)

    本文介绍了通用互信息（GEMINI）作为一种辨别聚类的框架，相比互信息（MI），GEMINI在无监督神经网络训练过程中不需要正则化，其可以选择合适的聚类数量。

    

    在过去十年中，深度聚类的最新成果主要涉及作为无监督训练神经网络的客观函数的互信息（MI），并增加了正则项。尽管正则化的质量已经被广泛讨论以进行改进，但对于MI作为聚类目标的相关性却没有得到足够的关注。本文首先强调了最大化MI并不能得到令人满意的聚类结果。我们发现库尔巴克-莱布勒散度是这一行为的主要原因。因此，我们通过改变其核心差异，引入通用互信息（GEMINI）来推广互信息：一组用于无监督神经网络训练的度量。与MI不同的是，一些GEMINI在训练时不需要正则化，因为它们在数据空间中具有几何意识的距离或核函数。最后，我们强调，GEMINI可以自动选择相关数量的聚类，这是一个有意义的特性。

    In the last decade, recent successes in deep clustering majorly involved the Mutual Information (MI) as an unsupervised objective for training neural networks with increasing regularisations. While the quality of the regularisations have been largely discussed for improvements, little attention has been dedicated to the relevance of MI as a clustering objective. In this paper, we first highlight how the maximisation of MI does not lead to satisfying clusters. We identified the Kullback-Leibler divergence as the main reason of this behaviour. Hence, we generalise the mutual information by changing its core distance, introducing the Generalised Mutual Information (GEMINI): a set of metrics for unsupervised neural network training. Unlike MI, some GEMINIs do not require regularisations when training as they are geometry-aware thanks to distances or kernels in the data space. Finally, we highlight that GEMINIs can automatically select a relevant number of clusters, a property that has been
    
[^8]: 针对组合贝叶斯优化的随机后处理方法

    Random postprocessing for combinatorial Bayesian optimization. (arXiv:2309.02842v1 [cs.LG])

    [http://arxiv.org/abs/2309.02842](http://arxiv.org/abs/2309.02842)

    针对组合贝叶斯优化，我们研究了一种随机后处理方法，严格禁止数据集中的重复样本，结果表明此方法显著减少了顺序步骤数，特别是在最大后验估计的情况下，为解决高维问题中贝叶斯优化的收敛速度慢提供了一种简单但通用的策略。

    

    基于模型的顺序方法用于离散的“黑盒”优化问题，包括贝叶斯优化技术，通常会对给定的目标函数访问多次相同的点，导致需要很多步骤才能找到全局最优解。在这里，我们对贝叶斯优化中的一种后处理方法进行了数值研究，该方法严格禁止数据集中的重复样本。我们发现后处理方法显著减少了找到全局最优解所需的顺序步骤数，特别是当采样函数是最大后验估计时。我们的结果为解决高维问题中贝叶斯优化的收敛速度慢提供了一种简单但通用的策略。

    Model-based sequential approaches to discrete "black-box" optimization, including Bayesian optimization techniques, often access the same points multiple times for a given objective function in interest, resulting in many steps to find the global optimum. Here, we numerically study the effect of a postprocessing method on Bayesian optimization that strictly prohibits duplicated samples in the dataset. We find the postprocessing method significantly reduces the number of sequential steps to find the global optimum, especially when the acquisition function is of maximum a posterior estimation. Our results provide a simple but general strategy to solve the slow convergence of Bayesian optimization for high-dimensional problems.
    
[^9]: 关于异质误差对多保真贝叶斯优化的影响

    On the Effects of Heterogeneous Errors on Multi-fidelity Bayesian Optimization. (arXiv:2309.02771v1 [cs.LG])

    [http://arxiv.org/abs/2309.02771](http://arxiv.org/abs/2309.02771)

    本文研究了异质误差对多保真贝叶斯优化的影响，并提出了解决现有假设不成立时性能下降的方法。

    

    贝叶斯优化（BO）是一种连续优化策略，被广泛应用于包括材料设计在内的各个领域。在实际应用中，通过物理实验或高保真度模拟获取高保真度（HF）数据是BO的主要成本。为了缓解这个瓶颈，采用多保真度（MF）方法，通过查询与HF样本相关的廉价低保真度（LF）数据源，减少抽样成本。然而，现有的多保真度BO（MFBO）方法基于两个假设，这在实际应用中很少成立：（1）LF数据源在全局范围内与HF数据呈良好相关，（2）一个随机过程可以模拟融合数据的噪声。这些假设在LF数据源仅在局部与HF源相关或噪声方差在不同地方变化时，会显著降低MFBO的性能。

    Bayesian optimization (BO) is a sequential optimization strategy that is increasingly employed in a wide range of areas including materials design. In real world applications, acquiring high-fidelity (HF) data through physical experiments or HF simulations is the major cost component of BO. To alleviate this bottleneck, multi-fidelity (MF) methods are used to forgo the sole reliance on the expensive HF data and reduce the sampling costs by querying inexpensive low-fidelity (LF) sources whose data are correlated with HF samples. However, existing multi-fidelity BO (MFBO) methods operate under the following two assumptions that rarely hold in practical applications: (1) LF sources provide data that are well correlated with the HF data on a global scale, and (2) a single random process can model the noise in the fused data. These assumptions dramatically reduce the performance of MFBO when LF sources are only locally correlated with the HF source or when the noise variance varies across t
    
[^10]: 自适应共识：一种用于分散优化的网络修剪方法

    Adaptive Consensus: A network pruning approach for decentralized optimization. (arXiv:2309.02626v1 [math.OC])

    [http://arxiv.org/abs/2309.02626](http://arxiv.org/abs/2309.02626)

    这项研究提出了一种自适应共识的方法来解决网络中的分散优化问题，利用周期性追踪不一致误差和精选有效边缘的策略来减少通信量，并在理论上证明了算法的收敛性和收敛速度的界限。

    

    我们研究基于网络的分散优化问题，在这种问题中，网络中的每个节点都拥有一个本地函数，目标是协同获得一个最小化所有本地函数之和的共识解决方案。分散优化的一个主要挑战是依赖通信，在许多应用中仍然是一个相当大的瓶颈。为了解决这个挑战，我们提出了一种自适应的随机化通信效率算法框架，通过定期追踪不一致误差并精选每个节点中最有影响力和有效的边缘来减少通信量。在这个框架内，我们提出了两种算法：自适应共识（AC）解决共识问题和基于自适应共识的梯度跟踪（AC-GT）解决平滑强凸分散优化问题。我们对所提算法建立了强大的理论收敛保证，并量化了收敛速度和通信成本的界限。

    We consider network-based decentralized optimization problems, where each node in the network possesses a local function and the objective is to collectively attain a consensus solution that minimizes the sum of all the local functions. A major challenge in decentralized optimization is the reliance on communication which remains a considerable bottleneck in many applications. To address this challenge, we propose an adaptive randomized communication-efficient algorithmic framework that reduces the volume of communication by periodically tracking the disagreement error and judiciously selecting the most influential and effective edges at each node for communication. Within this framework, we present two algorithms: Adaptive Consensus (AC) to solve the consensus problem and Adaptive Consensus based Gradient Tracking (AC-GT) to solve smooth strongly convex decentralized optimization problems. We establish strong theoretical convergence guarantees for the proposed algorithms and quantify 
    
[^11]: 分布式变分推断用于在线监督学习

    Distributed Variational Inference for Online Supervised Learning. (arXiv:2309.02606v1 [cs.LG])

    [http://arxiv.org/abs/2309.02606](http://arxiv.org/abs/2309.02606)

    本文提出了一种适用于智能传感器网络的分布式变分推断算法，可以解决连续变量、大规模实时数据和难以处理的后验概率的推断问题。通过推导出可分离的较低下界，实现了在传感器网络中进行一跳通信的分布式变分推断，并提出了处理二进制问题的方法。

    

    在智能传感器网络中开发高效的推断问题解决方案对于下一代定位、跟踪和地图服务至关重要。本文提出了一种适用于连续变量、难以处理的后验概率和大规模实时数据的可扩展分布式概率推断算法。在集中式设置中，变分推断是一种执行近似贝叶斯估计的基本技术，其中将难以处理的后验密度用参数化密度来近似。我们的主要贡献在于推导出一个可分离的较低下界，用于集中式估计目标，从而实现了在传感器网络中进行一跳通信的分布式变分推断。我们的分布式证据较低下界 (DELBO) 包括观测似然和距离先验密度的差值的加权和，其与测量证据的差距是由于共识和建模误差造成的。为了解决二进制问题，我们提出了一种处理方法

    Developing efficient solutions for inference problems in intelligent sensor networks is crucial for the next generation of location, tracking, and mapping services. This paper develops a scalable distributed probabilistic inference algorithm that applies to continuous variables, intractable posteriors and large-scale real-time data in sensor networks. In a centralized setting, variational inference is a fundamental technique for performing approximate Bayesian estimation, in which an intractable posterior density is approximated with a parametric density. Our key contribution lies in the derivation of a separable lower bound on the centralized estimation objective, which enables distributed variational inference with one-hop communication in a sensor network. Our distributed evidence lower bound (DELBO) consists of a weighted sum of observation likelihood and divergence to prior densities, and its gap to the measurement evidence is due to consensus and modeling errors. To solve binary 
    
[^12]: 数据聚合用于层次聚类

    Data Aggregation for Hierarchical Clustering. (arXiv:2309.02552v1 [stat.ML])

    [http://arxiv.org/abs/2309.02552](http://arxiv.org/abs/2309.02552)

    本研究介绍了如何利用数据聚合算法BETULA使得资源受限系统上的层次聚类方法HAC变得可行，从而允许对非常大的数据集进行探索性数据分析。

    

    层次凝聚聚类（HAC）可能是最早和最灵活的聚类方法，因为它可以与许多距离、相似度和不同的链接策略一起使用。当数据集形成的聚类数量未知且数据中存在一定的层次结构时，通常使用HAC。大多数HAC算法在全距离矩阵上操作，因此需要二次存储。标准算法的运行时间也是立方级别的，用于生成完整的层次结构。在嵌入式或其他资源受限的系统中，存储和运行时间尤其成问题。在本节中，我们介绍了如何利用BETULA进行数据聚合，它是著名的BIRCH数据聚合算法的数值稳定版本，可使HAC在具有受限资源的系统上可行，只造成较小的聚类质量损失，从而允许对非常大的数据集进行探索性数据分析。

    Hierarchical Agglomerative Clustering (HAC) is likely the earliest and most flexible clustering method, because it can be used with many distances, similarities, and various linkage strategies. It is often used when the number of clusters the data set forms is unknown and some sort of hierarchy in the data is plausible. Most algorithms for HAC operate on a full distance matrix, and therefore require quadratic memory. The standard algorithm also has cubic runtime to produce a full hierarchy. Both memory and runtime are especially problematic in the context of embedded or otherwise very resource-constrained systems. In this section, we present how data aggregation with BETULA, a numerically stable version of the well known BIRCH data aggregation algorithm, can be used to make HAC viable on systems with constrained resources with only small losses on clustering quality, and hence allow exploratory data analysis of very large data sets.
    
[^13]: 概率单纯形上的扩散

    Diffusion on the Probability Simplex. (arXiv:2309.02530v1 [cs.LG])

    [http://arxiv.org/abs/2309.02530](http://arxiv.org/abs/2309.02530)

    本文提出了一种在概率单纯形上执行扩散的方法，通过使用softmax函数应用于阿恩斯坦-乌伦贝克过程，可以在处理连续性和离散性对象之间的紧张关系时取得良好效果。这种方法也可以扩展到单位立方体上，从而在有界图像生成方面具有应用前景。

    

    扩散模型通过学习逆转数据分布的逐渐噪声化来创建一个生成模型。然而，连续的噪声化过程与离散数据之间的期望不一致。为了解决连续性和离散性对象之间的紧张关系，我们提出了在概率单纯形上执行扩散的方法。使用概率单纯形自然地创建了一种解释，其中点对应于分类概率分布。我们的方法使用对阿恩斯坦-乌伦贝克过程之间进行softmax函数的应用，这是一个众所周知的随机微分方程。我们发现我们的方法也自然地扩展到包括对单位立方体的扩散，这对于有界图像生成应用具有意义。

    Diffusion models learn to reverse the progressive noising of a data distribution to create a generative model. However, the desired continuous nature of the noising process can be at odds with discrete data. To deal with this tension between continuous and discrete objects, we propose a method of performing diffusion on the probability simplex. Using the probability simplex naturally creates an interpretation where points correspond to categorical probability distributions. Our method uses the softmax function applied to an Ornstein-Unlenbeck Process, a well-known stochastic differential equation. We find that our methodology also naturally extends to include diffusion on the unit cube which has applications for bounded image generation.
    
[^14]: 通过不确定性估计实现优化样本选择及其在深度学习中的应用

    Optimal Sample Selection Through Uncertainty Estimation and Its Application in Deep Learning. (arXiv:2309.02476v1 [stat.ML])

    [http://arxiv.org/abs/2309.02476](http://arxiv.org/abs/2309.02476)

    该论文提出了一种理论最优解——COPS（基于不确定性的最优子采样），用于解决深度学习中的核心集选择和主动学习问题，在减少标记数据集成本的同时最小化模型的期望损失。

    

    现代深度学习在很大程度上依赖于大型标记数据集，但在手动标注和计算资源方面往往会带来高昂的成本。为了应对这些挑战，研究人员已经探索了一些信息性子集选择技术，包括核心集选择和主动学习。具体而言，核心集选择涉及到同时采样输入（$\bx$）和输出（$\by$）的数据，而主动学习仅关注输入数据（$\bx$）。在本研究中，我们提出了针对线性softmax回归背景下同时解决核心集选择和主动学习的理论最优解。我们提出的方法，COPS（基于不确定性的最优子采样），旨在最小化基于子采样数据训练的模型的期望损失。与现有的依赖于显式计算逆协方差矩阵的方法不同，这种方法在深度学习场景中不容易应用。COPS利用模型的逻辑回归值来估计采样的...

    Modern deep learning heavily relies on large labeled datasets, which often comse with high costs in terms of both manual labeling and computational resources. To mitigate these challenges, researchers have explored the use of informative subset selection techniques, including coreset selection and active learning. Specifically, coreset selection involves sampling data with both input ($\bx$) and output ($\by$), active learning focuses solely on the input data ($\bx$).  In this study, we present a theoretically optimal solution for addressing both coreset selection and active learning within the context of linear softmax regression. Our proposed method, COPS (unCertainty based OPtimal Sub-sampling), is designed to minimize the expected loss of a model trained on subsampled data. Unlike existing approaches that rely on explicit calculations of the inverse covariance matrix, which are not easily applicable to deep learning scenarios, COPS leverages the model's logits to estimate the sampl
    
[^15]: 模仿学习综述：算法、最新进展与挑战

    A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges. (arXiv:2309.02473v1 [cs.LG])

    [http://arxiv.org/abs/2309.02473](http://arxiv.org/abs/2309.02473)

    这篇论文综述了模仿学习的算法、最新进展和挑战，指出在复杂和非结构化的环境中，通过模仿专家行为来学习所需行为更具吸引力。

    

    近年来，机器人和人工智能系统的发展令人瞩目。随着这些系统的不断演进，它们越来越被应用于复杂和非结构化的环境中，如自动驾驶、空中机器人和自然语言处理。由于这些环境需要高度的灵活性和适应性，因此手动编程行为或通过奖励函数来定义行为（如强化学习中的做法）变得非常困难。在这样的环境中，通过模仿专家行为来学习更具吸引力。这就是模仿学习的作用 - 通过模仿专家的行为来学习所期望的行为，而这些行为是通过演示提供的。

    In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.  This paper a
    
[^16]: CONFIDERAI：一种新颖的CONFIRMAL可解释设计评分函数，用于可解释和可靠的人工智能

    CONFIDERAI: a novel CONFormal Interpretable-by-Design score function forExplainable and Reliable Artificial Intelligence. (arXiv:2309.01778v1 [cs.LG])

    [http://arxiv.org/abs/2309.01778](http://arxiv.org/abs/2309.01778)

    提出了一种新的可解释机器学习评分函数CONFIDERAI，它将一致性预测与规则模型相结合，利用规则的预测能力和点的几何位置，在特征空间中定义满足一致性保证的区域。

    

    每天的生活越来越受人工智能的影响，毫无疑问，机器学习算法必须为所有人设计成可靠和值得信赖的。具体来说，如果人工智能系统满足解释性、健壮性、透明性、公平性和隐私性这五个方面，计算机科学家认为它是安全和可信赖的。除了这五个方面，我们提出了第六个基本方面：一致性，即机器学习者对系统行为的概率性保证。在本文中，我们提出了一种方法，通过定义CONFIDERAI，一种基于规则的模型的新评分函数，将一致性预测与可解释的机器学习相结合，利用规则的预测能力和点在规则边界内的几何位置。我们还通过利用控制非一致性的数量的技术来解决在特征空间中定义满足一致性保证的区域的问题。

    Everyday life is increasingly influenced by artificial intelligence, and there is no question that machine learning algorithms must be designed to be reliable and trustworthy for everyone. Specifically, computer scientists consider an artificial intelligence system safe and trustworthy if it fulfills five pillars: explainability, robustness, transparency, fairness, and privacy. In addition to these five, we propose a sixth fundamental aspect: conformity, that is, the probabilistic assurance that the system will behave as the machine learner expects. In this paper, we propose a methodology to link conformal prediction with explainable machine learning by defining CONFIDERAI, a new score function for rule-based models that leverages both rules predictive ability and points geometrical position within rules boundaries. We also address the problem of defining regions in the feature space where conformal guarantees are satisfied by exploiting techniques to control the number of non-conforma
    
[^17]: 不同iable的贝叶斯结构学习中的拓扑排序与保证无环性的约束。

    Topological Ordering in Differentiable Bayesian Structure Learning with Guaranteed Acyclicity Constraint. (arXiv:2309.01392v1 [cs.LG])

    [http://arxiv.org/abs/2309.01392](http://arxiv.org/abs/2309.01392)

    本研究提出了一种在贝叶斯结构学习中严格约束图的无环性的替代方法，通过整合拓扑排序知识，能够减少推理复杂性，并确保生成的图的结构是无环的。实证实验表明，该方法胜过相关的贝叶斯基于得分的方法。

    

    基于得分的结构学习方法因其可扩展性而蓬勃发展。连续松弛是这一进展的关键原因。尽管取得了有希望的结果，但大多数方法仍然在通过最小化定义的得分来确保从潜在空间生成的图是无环的方面遇到困难。还存在另一种基于置换的方法，关注的是有向无环图（DAG）中变量的拓扑排序的搜索，以限制图的搜索空间。在本研究中，我们提出了一种利用拓扑排序知识来严格限制图的无环性的替代方法。我们的方法可以减少推理复杂性，同时确保生成的图的结构是无环的。我们对模拟和真实数据进行的实证实验表明，我们的方法可以胜过相关的贝叶斯基于得分的方法。

    Score-based approaches in the structure learning task are thriving because of their scalability. Continuous relaxation has been the key reason for this advancement. Despite achieving promising outcomes, most of these methods are still struggling to ensure that the graphs generated from the latent space are acyclic by minimizing a defined score. There has also been another trend of permutation-based approaches, which concern the search for the topological ordering of the variables in the directed acyclic graph (DAG) in order to limit the search space of the graph. In this study, we propose an alternative approach for strictly constraining the acyclicty of the graphs with an integration of the knowledge from the topological orderings. Our approach can reduce inference complexity while ensuring the structures of the generated graphs to be acyclic. Our empirical experiments with simulated and real-world data show that our approach can outperform related Bayesian score-based approaches.
    
[^18]: 高维线性回归的解释：空间零值和正则化在电池数据上的影响的演示

    Interpretation of High-Dimensional Linear Regression: Effects of Nullspace and Regularization Demonstrated on Battery Data. (arXiv:2309.00564v1 [stat.ML])

    [http://arxiv.org/abs/2309.00564](http://arxiv.org/abs/2309.00564)

    本文研究了高维线性回归在解释方面的挑战，发现空间零值和正则化对回归系数产生重要影响，并提出了一种优化公式来比较回归系数与物理工程知识得到的系数，从而实现解释性的回归结果。

    

    高维线性回归在许多科学领域中非常重要。本文考虑到从化学或生物系统中经常得到的基础平滑潜在过程的离散测量数据。在高维度中解释是具有挑战性的，因为空间零值及其与正则化的相互作用会塑造回归系数。数据的空间零值包含所有满足$\mathbf{Xw}=\mathbf{0}$的系数，从而允许非常不同的系数产生相同的预测。我们开发了一种优化公式来比较回归系数和通过物理工程知识得到的系数，以了解系数差异的哪些部分接近于空间零值。这种空间零值方法在一个合成示例和锂离子电池数据上进行了测试。案例研究表明，如果根据先前的物理知识选择合适的正则化和z-score处理，可以得到可解释的回归结果。

    High-dimensional linear regression is important in many scientific fields. This article considers discrete measured data of underlying smooth latent processes, as is often obtained from chemical or biological systems. Interpretation in high dimensions is challenging because the nullspace and its interplay with regularization shapes regression coefficients. The data's nullspace contains all coefficients that satisfy $\mathbf{Xw}=\mathbf{0}$, thus allowing very different coefficients to yield identical predictions. We developed an optimization formulation to compare regression coefficients and coefficients obtained by physical engineering knowledge to understand which part of the coefficient differences are close to the nullspace. This nullspace method is tested on a synthetic example and lithium-ion battery data. The case studies show that regularization and z-scoring are design choices that, if chosen corresponding to prior physical knowledge, lead to interpretable regression results. 
    
[^19]: 一种高斯混合模型和神经网络的高效一次迭代学习算法

    An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And Gaussian Mixture Embedding For Neural Network. (arXiv:2308.09444v1 [cs.LG])

    [http://arxiv.org/abs/2308.09444](http://arxiv.org/abs/2308.09444)

    我们提出了一种高斯混合模型的学习算法，具有更好的鲁棒性和简单性，只需要进行1次迭代学习。我们的方法能更好地处理数据不确定性和逆问题，并且有潜力构建能够利用分布随机抽样进行随机变异和变异控制的应用。

    

    我们提出了一种基于我们之前的GMM扩展思想的高斯混合模型（GMM）学习算法。新算法比传统的期望最大化（EM）算法更具鲁棒性和简单性。它还提高了准确性，并且只需要进行1次迭代学习。我们在理论上证明了这种新算法无论参数初始化如何都能保证收敛。我们将我们的GMM扩展方法与神经网络中的经典概率层进行了比较，结果表明我们的方法能更好地克服数据的不确定性和逆问题。最后，我们测试了基于GMM的生成器，显示出了进一步利用分布随机抽样进行随机变异和变异控制的潜力。

    We propose an Gaussian Mixture Model (GMM) learning algorithm, based on our previous work of GMM expansion idea. The new algorithm brings more robustness and simplicity than classic Expectation Maximization (EM) algorithm. It also improves the accuracy and only take 1 iteration for learning. We theoretically proof that this new algorithm is guarantee to converge regardless the parameters initialisation. We compare our GMM expansion method with classic probability layers in neural network leads to demonstrably better capability to overcome data uncertainty and inverse problem. Finally, we test GMM based generator which shows a potential to build further application that able to utilized distribution random sampling for stochastic variation as well as variation control.
    
[^20]: 用于决策的因果思维在电子健康记录中的应用：为什么以及如何

    Causal thinking for decision making on Electronic Health Records: why and how. (arXiv:2308.01605v1 [stat.ME])

    [http://arxiv.org/abs/2308.01605](http://arxiv.org/abs/2308.01605)

    本文介绍了在电子健康记录中使用因果思维进行决策的必要性和方法。通过模拟随机试验来个性化决策，以减少数据中的偏见。这对于分析电子健康记录或索赔数据以得出因果结论的最重要陷阱和考虑因素进行了重点强调。

    

    准确的预测，如同机器学习一样，可能无法为每个患者提供最佳医疗保健。确实，预测可能受到数据中的捷径（如种族偏见）的驱动。为数据驱动的决策需要因果思维。在这里，我们介绍关键要素，重点关注常规收集的数据，即电子健康记录（EHRs）和索赔数据。使用这些数据评估干预的价值需要谨慎：时间依赖性和现有实践很容易混淆因果效应。我们提供了一个逐步框架，帮助从真实患者记录中构建有效的决策，通过模拟随机试验来个性化决策，例如使用机器学习。我们的框架强调了分析EHRs或索赔数据以得出因果结论时最重要的陷阱和考虑因素。我们在用于重症医学信息市场中的肌酐对败血症死亡率的影响的研究中说明了各种选择。

    Accurate predictions, as with machine learning, may not suffice to provide optimal healthcare for every patient. Indeed, prediction can be driven by shortcuts in the data, such as racial biases. Causal thinking is needed for data-driven decisions. Here, we give an introduction to the key elements, focusing on routinely-collected data, electronic health records (EHRs) and claims data. Using such data to assess the value of an intervention requires care: temporal dependencies and existing practices easily confound the causal effect. We present a step-by-step framework to help build valid decision making from real-life patient records by emulating a randomized trial before individualizing decisions, eg with machine learning. Our framework highlights the most important pitfalls and considerations in analysing EHRs or claims data to draw causal conclusions. We illustrate the various choices in studying the effect of albumin on sepsis mortality in the Medical Information Mart for Intensive C
    
[^21]: 流形滤波-组合网络

    Manifold Filter-Combine Networks. (arXiv:2307.04056v1 [stat.ML])

    [http://arxiv.org/abs/2307.04056](http://arxiv.org/abs/2307.04056)

    这篇论文介绍了一类称为流形滤波-组合网络的大型流形神经网络。作者提出了一种基于构建数据驱动图的方法来实现这种网络，并提供了收敛到连续极限的充分条件，其收敛速度不依赖于滤波器数量。

    

    我们介绍了一类大型流形神经网络(MNNs)，我们称之为流形滤波-组合网络。这个类别包括了Wang、Ruiz和Ribeiro之前的研究中考虑的MNNs，流形散射变换(一种基于小波的神经网络模型)，以及其他有趣的之前在文献中未考虑的示例，如Kipf和Welling的图卷积网络的流形等效。然后，我们考虑了一种基于构建数据驱动图的方法，用于在没有对流形有全局知识的情况下实现这样的网络，而只能访问有限数量的样本点。我们提供了网络在样本点数趋于无穷大时能够保证收敛到其连续极限的充分条件。与之前的工作(主要关注特定的MNN结构和图构建)不同，我们的收敛速度并不依赖于使用的滤波器数量。而且，它表现出线性的收敛速度。

    We introduce a large class of manifold neural networks (MNNs) which we call Manifold Filter-Combine Networks. This class includes as special cases, the MNNs considered in previous work by Wang, Ruiz, and Ribeiro, the manifold scattering transform (a wavelet-based model of neural networks), and other interesting examples not previously considered in the literature such as the manifold equivalent of Kipf and Welling's graph convolutional network. We then consider a method, based on building a data-driven graph, for implementing such networks when one does not have global knowledge of the manifold, but merely has access to finitely many sample points. We provide sufficient conditions for the network to provably converge to its continuum limit as the number of sample points tends to infinity. Unlike previous work (which focused on specific MNN architectures and graph constructions), our rate of convergence does not explicitly depend on the number of filters used. Moreover, it exhibits line
    
[^22]: 策略优化中的乐观性和适应性

    Optimism and Adaptivity in Policy Optimization. (arXiv:2306.10587v1 [cs.LG])

    [http://arxiv.org/abs/2306.10587](http://arxiv.org/abs/2306.10587)

    本文通过将看似无关的策略优化算法重新构造为共同的两个交错步骤，即乐观策略改进和后见适应，统一了强化学习中的策略优化方法，揭示了加速方法中的乐观性和适应性的共同理论属性。

    

    本文致力于通过“乐观性”和“适应性”在强化学习中加速策略优化方法的统一范式。通过利用策略迭代和策略梯度方法之间的深刻联系，我们将一些看似无关的策略优化算法重新构造为两个交错步骤（i）乐观策略改进操作器使用“梯度上升预测”将先前的策略$\pi_t$映射到一个假设$\pi_{t+1}$，然后（ii）对$\pi_{t+1}$的性能进行部分评估，并基于此进行“后见适应”。我们使用这个共享的视角来共同表达其他众所周知的算法，包括软件和乐观策略迭代、自然演员-评论家方法、基于前向搜索的基于模型的策略改进和元学习算法。通过这样做，我们揭示了关于通过乐观性和适应性加速的共同理论属性。

    We work towards a unifying paradigm for accelerating policy optimization methods in reinforcement learning (RL) through \emph{optimism} \& \emph{adaptivity}. Leveraging the deep connection between policy iteration and policy gradient methods, we recast seemingly unrelated policy optimization algorithms as the repeated application of two interleaving steps (i) an \emph{optimistic policy improvement operator} maps a prior policy $\pi_t$ to a hypothesis $\pi_{t+1}$ using a \emph{gradient ascent prediction}, followed by (ii) a \emph{hindsight adaptation} of the optimistic prediction based on a partial evaluation of the performance of $\pi_{t+1}$. We use this shared lens to jointly express other well-known algorithms, including soft and optimistic policy iteration, natural actor-critic methods, model-based policy improvement based on forward search, and meta-learning algorithms. By doing so, we shed light on collective theoretical properties related to acceleration via optimism \& adaptivit
    
[^23]: 内核随机投影深度用于离群点检测

    Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])

    [http://arxiv.org/abs/2306.07056](http://arxiv.org/abs/2306.07056)

    本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。

    

    本文提出了一种扩展的随机投影深度（RPD）方法，用于处理数据云中的多模式和非凸性。在所提出的方法的框架中，RPD在再现核希尔伯特空间中计算。借助内核主成分分析，我们期望所提出的方法可以处理上述多种模式和非凸性。实验结果表明，所提出的方法优于RPD，并可与基准数据集上现有的检测模型相媲美，关于接收操作特征曲线（ROC）下的曲线下面积（AUC）。

    This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
    
[^24]: 通过等压等温流获得吉布斯自由能

    Gibbs free energies via isobaric-isothermal flows. (arXiv:2305.13233v1 [physics.comp-ph])

    [http://arxiv.org/abs/2305.13233](http://arxiv.org/abs/2305.13233)

    采用机器学习模型利用等压等温流得到吉布斯自由能，并在单原子水的结晶中进行了测试，表现出优秀的性能。

    

    我们提出了一种基于归一化流的机器学习模型，该模型经过训练可从等压等温（NPT）集合中进行采样。在我们的方法中，我们采用近似方法来得到完全灵活的三斜晶系统的联合分布和粒子坐标以达到所需的内部压力。我们对单原子水在立方和六角冰相中进行测试，并发现与已建立的基线相比，吉布斯自由能和其他可观测量的结果完全一致。

    We present a machine-learning model based on normalizing flows that is trained to sample from the isobaric-isothermal (NPT) ensemble. In our approach, we approximate the joint distribution of a fully-flexible triclinic simulation box and particle coordinates to achieve a desired internal pressure. We test our model on monatomic water in the cubic and hexagonal ice phases and find excellent agreement of Gibbs free energies and other observables compared with established baselines.
    
[^25]: 神经先验随机块模型

    Neural-prior stochastic block model. (arXiv:2303.09995v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2303.09995](http://arxiv.org/abs/2303.09995)

    本研究提出了神经先验随机块模型，将社区建模为由节点属性决定。基于置信传递和近似消息传递的结合，可以在处理社交网络、图像分割，生物物种等方面发挥作用。

    

    随机块模型（SBM）被广泛研究作为图聚类或社区检测的基准。在实践中，图数据通常带有节点属性，这些属性承载有关社区的附加信息。以前的研究通过考虑节点属性是由节点社区成员身份生成的来对这些数据进行建模。在本文中，受到使用深度神经网络作为先验的信号处理领域中一系列研究的启发，我们提出将社区建模为由节点属性决定而不是相反。我们定义了相应的模型，并将其称为神经先验SBM。我们提出了一种算法，来自于统计物理学，基于置信传递和近似消息传递的结合。我们分析了算法的性能以及贝叶斯最优性能。我们识别了可检测和精确恢复相变，以及一种算法难区域。所提出的模型和算法可以在处理诸如社交网络、图像分割，生物物种等方面发挥作用。

    The stochastic block model (SBM) is widely studied as a benchmark for graph clustering aka community detection. In practice, graph data often come with node attributes that bear additional information about the communities. Previous works modeled such data by considering that the node attributes are generated from the node community memberships. In this work, motivated by a recent surge of works in signal processing using deep neural networks as priors, we propose to model the communities as being determined by the node attributes rather than the opposite. We define the corresponding model; we call it the neural-prior SBM. We propose an algorithm, stemming from statistical physics, based on a combination of belief propagation and approximate message passing. We analyze the performance of the algorithm as well as the Bayes-optimal performance. We identify detectability and exact recovery phase transitions, as well as an algorithmically hard region. The proposed model and algorithm can b
    
[^26]: 基于拓扑学的神经突触解码的深度学习框架

    A Topological Deep Learning Framework for Neural Spike Decoding. (arXiv:2212.05037v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2212.05037](http://arxiv.org/abs/2212.05037)

    这项工作开发了一个基于拓扑学的深度学习框架，用于解码神经突触输出，以更好地理解和表示大脑中的神经结构。

    

    大脑的空间定位系统使用不同的神经元集合来辅助基于环境的导航。大脑通过头方向细胞和网格细胞两种方式编码空间信息。头方向细胞用于确定方向，而网格细胞由叠加的神经元层组成，提供基于环境的导航。这些神经元以集合的形式发放信号，多个神经元同时发放信号以激活单个头方向或网格。我们希望捕捉这种发放结构，并将其用于解码头方向和网格细胞数据。理解、表示和解码这些神经结构需要包含高阶连接性的模型，而不仅仅是传统基于图的模型提供的一维连接性。为此，我们在这项工作中开发了一个基于拓扑深度学习框架来解码神经突触输出的工具。我们的框架结合了无监督的简单复合体发现和深度学习的强大能力。

    The brain's spatial orientation system uses different neuron ensembles to aid in environment-based navigation. Two of the ways brains encode spatial information is through head direction cells and grid cells. Brains use head direction cells to determine orientation whereas grid cells consist of layers of decked neurons that overlay to provide environment-based navigation. These neurons fire in ensembles where several neurons fire at once to activate a single head direction or grid. We want to capture this firing structure and use it to decode head direction grid cell data. Understanding, representing, and decoding these neural structures requires models that encompass higher order connectivity, more than the 1-dimensional connectivity that traditional graph-based models provide. To that end, in this work, we develop a topological deep learning framework for neural spike train decoding. Our framework combines unsupervised simplicial complex discovery with the power of deep learning via 
    
[^27]: 高效个性化：将用户参数建模为低秩加稀疏分量

    Sample-Efficient Personalization: Modeling User Parameters as Low Rank Plus Sparse Components. (arXiv:2210.03505v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03505](http://arxiv.org/abs/2210.03505)

    该论文提出了一种高效的个性化算法，通过将网络权重建模为低秩和稀疏分量的总和，既捕捉了多个用户间的共同信息，又能够捕捉用户个性化的特点。

    

    个性化机器学习（ML）对个体用户/域/企业的预测至关重要，标准的个性化方法涉及学习一个用户/域特定的嵌入，然后将其馈入一个固定的全局模型，这种方法存在限制。另一方面，为每个用户/域自身个性化/微调模型本身，即元学习，具有高存储/基础架构成本。此外，对可扩展个性化方法的严格理论研究非常有限。为了解决上述问题，我们提出了一种新颖的元学习风格的方法，将网络权重建模为低秩和稀疏分量的总和。这在低秩部分捕捉了多个个体/用户的共同信息，而稀疏部分则捕捉了用户特定的特性。然后我们在线性设置中研究了该框架，其中问题简化为使用简单的方法估计秩为$r$和$k$列的稀疏矩阵的总和

    Personalization of machine learning (ML) predictions for individual users/domains/enterprises is critical for practical recommendation systems. Standard personalization approaches involve learning a user/domain specific embedding that is fed into a fixed global model which can be limiting. On the other hand, personalizing/fine-tuning model itself for each user/domain -a.k.a meta-learning -- has high storage/infrastructure cost. Moreover, rigorous theoretical studies of scalable personalization approaches have been very limited. To address the above issues, we propose a novel meta-learning style approach that models network weights as a sum of low-rank and sparse components. This captures common information from multiple individuals/users together in the low-rank part while sparse part captures user-specific idiosyncrasies. We then study the framework in the linear setting, where the problem reduces to that of estimating the sum of a rank-$r$ and a $k$-column sparse matrix using a sma
    
[^28]: 通过图上的能量理解卷积

    Understanding convolution on graphs via energies. (arXiv:2206.10991v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10991](http://arxiv.org/abs/2206.10991)

    本论文结合能量的概念，证明了带对称滤波器的线性图卷积可以增强高频率，使图神经网络在同质和异质任务中表现更好。

    

    图神经网络（GNN）通常通过消息传递操作，其中节点的状态是基于其邻居收到的信息进行更新的。大多数消息传递模型都是作为图卷积进行操作的，其中特征在被传播到边缘之前通过共享的线性变换混合。在节点分类任务中，图卷积已经表现出两个限制：在heterophilic图上表现欠佳，并且过度平滑。常见的看法是，这两种现象的发生是因为这种模型表现为低通滤波器，意味着在图层间特征的Dirichlet能量会减少，导致平滑效应，最终特征不再可区分。在这项工作中，我们严谨地证明了简单的图卷积模型实际上可以增强高频率甚至引导一种我们所称的过度锐化的渐近行为，与过度平滑相反。我们通过表明对称滤波器的线性图卷积可以被解释为在图形上的能量最小化问题来做到这一点。具体而言，能量函数惩罚高能信号，有效地抑制低频，同时促进相关的高频。我们的结果表明，精心设计的图卷积模型可以在同质和异质任务上提供更好的性能。

    Graph Neural Networks (GNNs) typically operate by message-passing, where the state of a node is updated based on the information received from its neighbours. Most message-passing models act as graph convolutions, where features are mixed by a shared, linear transformation before being propagated over the edges. On node-classification tasks, graph convolutions have been shown to suffer from two limitations: poor performance on heterophilic graphs, and over-smoothing. It is common belief that both phenomena occur because such models behave as low-pass filters, meaning that the Dirichlet energy of the features decreases along the layers incurring a smoothing effect that ultimately makes features no longer distinguishable. In this work, we rigorously prove that simple graph-convolutional models can actually enhance high frequencies and even lead to an asymptotic behaviour we refer to as over-sharpening, opposite to over-smoothing. We do so by showing that linear graph convolutions with sy
    
[^29]: 强强后验收缩速率的Wasserstein动力学翻译

    Strong posterior contraction rates via Wasserstein dynamics. (arXiv:2203.10754v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2203.10754](http://arxiv.org/abs/2203.10754)

    本文提出了一种新的方法来解决强强后验收缩速率的问题，在函数参数空间中使用动态的Wasserstein距离和后验分布的局部Lipschitz连续性，建立了PCR与数学分析、概率论和统计学中一些经典问题的联系。

    

    在贝叶斯统计学中，后验收缩速率（PCR）以适当的方式量化后验分布集中在真实模型的任意小邻域中的速度，当样本量趋于无穷时。在本文中，我们开发了一种新的PCR方法，其基于函数参数空间的强范数距离。我们的方法关键是将后验分布的局部Lipschitz连续性与Wasserstein距离的动态形式相结合，这使得PCR与数学分析、概率论和统计学中一些经典问题产生了有趣的联系，例如Laplace方法来近似积分，Wasserstein距离下的Sanov大偏差原理，均值Glivenko-Cantelli定理的收敛速率，以及加权Poincaré-Wirtinger常数的估计。我们首先给出了关于一个正则无限维指数模型的PCR的定理。

    In Bayesian statistics, posterior contraction rates (PCRs) quantify the speed at which the posterior distribution concentrates on arbitrarily small neighborhoods of a true model, in a suitable way, as the sample size goes to infinity. In this paper, we develop a new approach to PCRs, with respect to strong norm distances on parameter spaces of functions. Critical to our approach is the combination of a local Lipschitz-continuity for the posterior distribution with a dynamic formulation of the Wasserstein distance, which allows to set forth an interesting connection between PCRs and some classical problems arising in mathematical analysis, probability and statistics, e.g., Laplace methods for approximating integrals, Sanov's large deviation principles in the Wasserstein distance, rates of convergence of mean Glivenko-Cantelli theorems, and estimates of weighted Poincar\'e-Wirtinger constants. We first present a theorem on PCRs for a model in the regular infinite-dimensional exponential 
    
[^30]: 核分类问题下的错误缩放定律：源条件和容量条件下的研究

    Error Scaling Laws for Kernel Classification under Source and Capacity Conditions. (arXiv:2201.12655v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2201.12655](http://arxiv.org/abs/2201.12655)

    本文研究了核分类问题中的错误缩放定律，针对满足源条件和容量条件的数据集类别，在高斯设计下导出了误差衰减率与源和容量系数的关系，并对比了最大化间隔支持向量机和岭分类两种方法。

    

    我们考虑核分类问题。尽管某些分类器的最坏情况下样本数量与预测错误的衰减率的边界已知，但它们经常不能准确描述真实数据集的学习曲线。在这项工作中，我们考虑满足标准源条件和容量条件的重要数据集类别，其中包括一些实际数据集，我们通过数值分析证明了这一点。在高斯设计下，我们导出了错误分类（预测）误差的衰减率作为源和容量系数的函数。我们针对两种标准的核分类设置（即最大化间隔支持向量机和岭分类）进行了这样的推导，并对比了两种方法。我们发现我们的衰减率紧密地描述了这类数据集的学习曲线，并且也在实际数据上观察到。我们的结果也可以看作是对核分类的缩放定律指数的显式预测。

    We consider the problem of kernel classification. While worst-case bounds on the decay rate of the prediction error with the number of samples are known for some classifiers, they often fail to accurately describe the learning curves of real data sets. In this work, we consider the important class of data sets satisfying the standard source and capacity conditions, comprising a number of real data sets as we show numerically. Under the Gaussian design, we derive the decay rates for the misclassification (prediction) error as a function of the source and capacity coefficients. We do so for two standard kernel classification settings, namely margin-maximizing Support Vector Machines (SVM) and ridge classification, and contrast the two methods. We find that our rates tightly describe the learning curves for this class of data sets, and are also observed on real data. Our results can also be seen as an explicit prediction of the exponents of a scaling law for kernel classification that is 
    
[^31]: 用因果学习解释黑箱预测算法的行为

    Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.02482](http://arxiv.org/abs/2006.02482)

    本文提出了一种用于解释黑箱预测算法行为的因果学习方法，通过学习因果图表示来提供因果解释，弥补了现有方法的缺点，即解释单元更加可解释且考虑了宏观级特征和未测量的混淆。

    

    因果学方法在解释黑箱预测模型（例如基于图像像素数据训练的深度神经网络）方面越来越受欢迎。然而，现有方法存在两个重要缺点：（i）“解释单元”是相关预测模型的微观级输入，例如图像像素，而不是更有用于理解如何可能改变算法行为的可解释的宏观级特征；（ii）现有方法假设特征与目标模型预测之间不存在未测量的混淆，这在解释单元是宏观级变量时不成立。我们关注的是在分析人员无法访问目标预测算法内部工作原理的重要情况，而只能根据特定输入查询模型输出的能力。为了在这种情况下提供因果解释，我们提出学习因果图表示，允许更好地理解算法的行为。

    Causal approaches to post-hoc explainability for black-box prediction models (e.g., deep neural networks trained on image pixel data) have become increasingly popular. However, existing approaches have two important shortcomings: (i) the "explanatory units" are micro-level inputs into the relevant prediction model, e.g., image pixels, rather than interpretable macro-level features that are more useful for understanding how to possibly change the algorithm's behavior, and (ii) existing approaches assume there exists no unmeasured confounding between features and target model predictions, which fails to hold when the explanatory units are macro-level variables. Our focus is on the important setting where the analyst has no access to the inner workings of the target prediction algorithm, rather only the ability to query the output of the model in response to a particular input. To provide causal explanations in such a setting, we propose to learn causal graphical representations that allo
    

