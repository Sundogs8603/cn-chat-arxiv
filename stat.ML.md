# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures.](http://arxiv.org/abs/2309.14298) | 本研究提出了一种改进的随机线性Bandit算法，利用鞍点边界的马丁格尔混合构建了适用于随机Bandit的置信序列，并证明该算法能够以竞争性的最坏情况下遗憾保证实现更好的性能。 |
| [^2] | [A Weighted Prognostic Covariate Adjustment Method for Efficient and Powerful Treatment Effect Inferences in Randomized Controlled Trials.](http://arxiv.org/abs/2309.14256) | 一种新颖而高效的方法，将生成的人工智能算法预测纳入随机对照试验的协变量调整中，可以提高治疗效果推断的质量和可信度。 |
| [^3] | [Federated Learning Under Restricted User Availability.](http://arxiv.org/abs/2309.14176) | 本文研究了受限用户可用性下的联邦学习问题，提出了一种新的FL问题的公式化，并通过使用风险感知目标设计了一种高效训练算法，完全不受随机访问模型（RAM）的影响。 |
| [^4] | [Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach.](http://arxiv.org/abs/2309.14073) | 本研究提出了一种新的图形结构，用于在线性和高斯性假设下稳定的潜变量结构方程模型。我们证明了计算该模型的最大似然估计等价于训练一个神经网络，并实现了一个基于GPU的算法来进行计算。 |
| [^5] | [TomOpt: Differential optimisation for task- and constraint-aware design of particle detectors in the context of muon tomography.](http://arxiv.org/abs/2309.14027) | TomOpt是一个软件包，用于优化宇宙射线μ子断层扫描设计中的微粒探测器的几何布局和规格。它利用可微分编程模拟μ子与探测器和扫描体积的相互作用，并通过损失最小化的优化循环进行推断感知优化。 |
| [^6] | [Linked shrinkage to improve estimation of interaction effects in regression models.](http://arxiv.org/abs/2309.13998) | 本研究提出了一种在回归模型中添加交互作用的估计方法，通过使用局部收缩模型实现了对主效应和交互效应之间的较为灵活的关联，大大提高了回归系数的估计精度。 |
| [^7] | [Identification of Mixtures of Discrete Product Distributions in Near-Optimal Sample and Time Complexity.](http://arxiv.org/abs/2309.13993) | 本研究解决了识别离散随机变量混合产品分布的问题。通过组合经典的张量分解方法和一种新颖的条件数估计方法，我们实现了在样本复杂度和运行时复杂度上的改进，并扩展了已知的下界来匹配我们的上界。 |
| [^8] | [Pseudo Label Selection is a Decision Problem.](http://arxiv.org/abs/2309.13926) | 伪标签选择是半监督学习中的一种方法，通过嵌入决策理论，提出了BPLS框架来解决伪标签选择中的确认偏差问题。 |
| [^9] | [Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds.](http://arxiv.org/abs/2309.13915) | 本研究探讨了神经策略镜像梯度算法在低维流形上的样本复杂性。研究发现在每次迭代中，卷积神经网络可以很好地逼近价值函数和策略，且逼近误差受网络大小的影响，并且可以继承之前网络的平滑性。 |
| [^10] | [Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts.](http://arxiv.org/abs/2309.13896) | 通过引入后期服务上下文，我们设计了一种新算法poLinUCB以提高上下文推荐中的在线学习效率，并通过鲁棒化的椭圆潜力引理实现了严格的遗憾控制。 |
| [^11] | [Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts.](http://arxiv.org/abs/2309.13850) | 该论文研究前K稀疏softmax门控混合专家在密度和参数估计方面的作用，通过定义新的损失函数，探讨了输入区域的不同行为。研究发现，在真实专家数量已知的情况下，密度和参数估计的收敛速度与样本量成正比，但当真实模式未知时 |
| [^12] | [NSOTree: Neural Survival Oblique Tree.](http://arxiv.org/abs/2309.13825) | 本文介绍了一种名为NSOTree的神经存活斜树，该方法结合了神经网络和基于树的方法的优势，实现了对复杂函数的逼近能力和可解释性，用于存活分析。 |
| [^13] | [Distribution-Free Statistical Dispersion Control for Societal Applications.](http://arxiv.org/abs/2309.13786) | 提出了一个简单而灵活的框架，用于处理具有社会意义的无分布统计离散度控制，可以应用于高风险应用。 |
| [^14] | [The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance.](http://arxiv.org/abs/2309.13775) | 提出了一种新的变量重要性框架，该框架在数据分布上是稳定的，并可以与现有的模型类和全局变量重要性指标结合使用。 |
| [^15] | [Towards Tuning-Free Minimum-Volume Nonnegative Matrix Factorization.](http://arxiv.org/abs/2309.13733) | 本论文提出了一个无需调参的最小体积非负矩阵分解方法，通过引入平方根套索的启发和无需调参的特性，解决了既有方法在选择调节参数方面的依赖性问题。通过实验证明，该方法对数据中的噪声水平不敏感。 |
| [^16] | [Regularization and Optimal Multiclass Learning.](http://arxiv.org/abs/2309.13692) | 本研究旨在研究正则化在多类别学习中的作用，以及其在一些特定情景下的最优学习算法。我们使用一对一包含图(OIGs)展示了结构风险最小化、最大熵原则和贝叶斯推理等算法原则的最优学习算法。 |
| [^17] | [Fantastic Generalization Measures are Nowhere to be Found.](http://arxiv.org/abs/2309.13658) | 本论文研究了过参数化情况下的泛化界限问题，通过分析多个界限发现在这种情况下无法找到紧致的界限来解释神经网络的出色性能。 |
| [^18] | [On the Posterior Distribution in Denoising: Application to Uncertainty Quantification.](http://arxiv.org/abs/2309.13598) | 该论文研究了去噪中的后验分布及其与后验均值之间的关系，并应用于预训练去噪器的不确定性量化。提出了一种高效计算后验分布主成分和近似边际分布的方法。不需要显式计算高阶矩张量或进行训练或微调。 |
| [^19] | [Robust Principal Component Analysis using Density Power Divergence.](http://arxiv.org/abs/2309.13531) | 使用最小密度功率差异估计的鲁棒主成分分析方法在高维数据中具有理论优势且具备高鲁棒性保证。 |
| [^20] | [Enhancing Prediction and Analysis of UK Road Traffic Accident Severity Using AI: Integration of Machine Learning, Econometric Techniques, and Time Series Forecasting in Public Health Research.](http://arxiv.org/abs/2309.13483) | 本研究结合了机器学习、计量经济学和时间序列预测方法，对英国道路交通事故的严重程度进行了预测和分析。研究结果表明，优化后的模型在预测准确性方面优于传统方法，并识别出了影响事故严重程度的关键变量。 |
| [^21] | [A Unified Scheme of ResNet and Softmax.](http://arxiv.org/abs/2309.13482) | 这是一篇关于将softmax回归和ResNet相结合的统一方案的论文，提供了对回归问题的理论分析，并推导了梯度... |
| [^22] | [CA-PCA: Manifold Dimension Estimation, Adapted for Curvature.](http://arxiv.org/abs/2309.13478) | 本文提出了CA-PCA算法，它基于曲率校准的局部PCA版本，通过考虑底层流形的曲率，改进了维度估计器的性能。 |
| [^23] | [A Model-Agnostic Graph Neural Network for Integrating Local and Global Information.](http://arxiv.org/abs/2309.13459) | MaGNet是一种模型无关的图神经网络框架，能够顺序地整合不同顺序的信息，并通过识别有影响力的紧凑图结构提供有意义且可解释的结果。 |
| [^24] | [Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems.](http://arxiv.org/abs/2309.13349) | 本文提出了一种能够在进化算法执行中选择适当的近似函数成本的技术，用于加速解决黑盒优化问题。 |
| [^25] | [Independent projections of diffusions: Gradient flows for variational inference and optimal mean field approximations.](http://arxiv.org/abs/2309.13332) | 本文介绍了一种称为“独立投影”的构造，它在变分推断和最优均场逼近中具有最优的效果，可以实现高维扩散过程的独立坐标的最优逼近，并展示了其长时间收敛性和慢的路径增长率。 |
| [^26] | [C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior.](http://arxiv.org/abs/2309.13303) | 这篇论文提出了一种C$^2$VAE模型，通过联合学习非耦合且相关的隐藏因素，并通过自监督分类器消除耦合表示，以增强非耦合表示学习。该模型在不依赖先验知识和强建模假设的情况下，使用总相关驱动分解后验来学习因子化的非耦合表示，并利用神经高斯Copula模型提取隐藏特征之间的依赖关系来获得耦合表示。 |
| [^27] | [Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework.](http://arxiv.org/abs/2309.13278) | 本研究提出了一个对于强化学习非同策略评估问题的统一误差量化框架，并解决了分布偏移的挑战。通过在一个单一的区间内共同量化两个估计误差源，该框架揭示了之前隐藏的误差权衡，从而提高了置信区间的准确性。 |
| [^28] | [BART-SIMP: a novel framework for flexible spatial covariate modeling and prediction using Bayesian additive regression trees.](http://arxiv.org/abs/2309.13270) | BART-SIMP是一种灵活的空间协变建模和预测的新框架，通过结合高斯过程空间模型和贝叶斯加法回归树模型，可以提供可靠的不确定性估计，并成功应用于肯尼亚家庭集群样本中的人体测量响应预测。 |
| [^29] | [Statistical Hypothesis Testing for Information Value (IV).](http://arxiv.org/abs/2309.13183) | 该论文提出了信息价值（IV）的统计假设检验方法，为模型建立前的特征选择提供了理论框架，并通过实验证明了该方法的有效性。 |
| [^30] | [Model-based Clustering using Non-parametric Hidden Markov Models.](http://arxiv.org/abs/2309.12238) | 本文研究了使用非参数隐马尔可夫模型进行基于模型的聚类时的贝叶斯风险，并提出了相应的聚类方法。通过研究分类的贝叶斯风险和聚类的贝叶斯风险之间的关系，确定了聚类任务的难度。同时，在插值分类器和在线设置中的结果也得到了证明。模拟实验验证了这些发现。 |
| [^31] | [Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds.](http://arxiv.org/abs/2309.10918) | 该论文研究了定义在紧致Riemannian流形上的内在Matern高斯过程和外在过程之间的收缩速率，并发现它们的速率在适当匹配平滑参数的情况下是相等的。 |
| [^32] | [Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers.](http://arxiv.org/abs/2309.10639) | 本文提供了深度学习网络结构的几何解释，并且构建了全局最小化器族，该族能够全局最小化成本函数。此外，还确定了各种退化局部最小值。 |
| [^33] | [Projected Langevin dynamics and a gradient flow for entropic optimal transport.](http://arxiv.org/abs/2309.08598) | 本文提出了投影 Langevin 动力学和梯度流算法，用于从经熵正则化的优化输运中进行采样和求解。该方法在小的正则化参数下集中于最优输运耦合点，并且保持在约束条件下的解。对应的长时间极限是熵优化输运问题的唯一解。 |
| [^34] | [Tropical Geometric Tools for Machine Learning: the TML package.](http://arxiv.org/abs/2309.01082) | TML软件包是第一个包含一套全面工具和方法的R软件包，用于处理与热带凸性相关的基本计算和可视化，以及使用热带度量进行监督和无监督学习模型的统计推断。 |
| [^35] | [Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations.](http://arxiv.org/abs/2308.03882) | 本文提出了一种利用未见状态增强的策略，在离线强化学习中通过基于价值的扰动和过滤，实现了对离线数据之外的状态的利用和泛化。 |
| [^36] | [Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior.](http://arxiv.org/abs/2307.14619) | 本文提出了一个理论框架，研究了在非线性动态系统中模仿复杂专家演示的行为。通过稳定模仿策略并确保准确估计演示者分布，可以使模仿者与演示者的轨迹分布相近。 |
| [^37] | [Simulating counterfactuals.](http://arxiv.org/abs/2306.15328) | 该论文提出了一种算法，可以模拟反事实分布中的值，可对离散和连续变量设定条件，并应用于信用评分中的公平性分析。 |
| [^38] | [The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning.](http://arxiv.org/abs/2305.15703) | 通过小损失边界的视角，我们提供了分布式RL好处的一个解释，该边界与实例相关的最优成本成比例。如果最优成本很小，分布式方法优于非分布式方法。 |
| [^39] | [Black-Box Variational Inference Converges.](http://arxiv.org/abs/2305.15349) | 通过对黑盒变分推断（BBVI）的分析，发现一些常见的算法设计选择可能会导致次优收敛速率，但使用带有近端随机梯度下降的BBVI可以实现最强收敛率保证。 |
| [^40] | [Few-Shot Continual Learning for Conditional Generative Adversarial Networks.](http://arxiv.org/abs/2305.11400) | 本文提出了一种新的连续学习方法，适用于条件生成对抗网络，根据cGAN的判别器数据识别出最接近目标的现有模式，并通过扩展连续学习模型，使用回放生成的数据来训练目标模式的cGAN模型，以避免灾难性遗忘，提高了生成性能。 |
| [^41] | [On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation.](http://arxiv.org/abs/2305.11283) | 本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。 |
| [^42] | [A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions.](http://arxiv.org/abs/2304.06787) | 本论文提出了第一个多项式时间、纯差分隐私估计器，可以在$\{0,1\}^d$上准确估计二元积分布的均值，达到了最优的样本复杂度。 |
| [^43] | [Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models.](http://arxiv.org/abs/2303.16047) | 提出一种有效而准确地近似稀疏广义可加模型（GAMs）的Rashomon集的技术，并使用这些近似模型来解决实际应用的挑战。 |
| [^44] | [Penalized Deep Partially Linear Cox Models with Application to CT Scans of Lung Cancer Patients.](http://arxiv.org/abs/2303.05341) | 通过引入罚函数，我们提出了一种创新的深度部分线性Cox模型，用于在肺癌患者的CT扫描中分析死亡风险。该模型能有效地整合已知和新兴的风险因素，解决了参数维度超出样本大小和非参数建模中维度灾难的问题。 |
| [^45] | [Global Convergence Rate of Deep Equilibrium Models with General Activations.](http://arxiv.org/abs/2302.05797) | 该论文研究了具有一般激活函数的深度平衡模型（DEQ）的全局收敛速度，证明了梯度下降以线性收敛速度收敛到全局最优解，并解决了限制平衡点Gram矩阵最小特征值的挑战。 |
| [^46] | [High-dimensional variable clustering based on sub-asymptotic maxima of a weakly dependent random process.](http://arxiv.org/abs/2302.00934) | 我们提出了一种基于亚渐近极大值的高维变量聚类模型，该模型利用群集间多变量随机过程的极大值的独立性定义种群水平的群集，我们还开发了一种无需预先指定群集数量的算法来恢复变量的群集。该算法在特定条件下能够有效地识别数据中的群集，并能够以多项式复杂度进行计算。我们的工作对于理解依赖过程的块最大值的非参数学习有重要意义，并且在神经科学领域有着应用潜力。 |
| [^47] | [Randomized Block-Coordinate Optimistic Gradient Algorithms for Root-Finding Problems.](http://arxiv.org/abs/2301.03113) | 本文提出了两种新的随机乐观梯度算法来解决大规模情况下的根查找问题。第一种算法在底层算子满足一定条件时可以达到较好的收敛速度，第二种算法是一种加速算法，可以更快地收敛。算法的收敛性和解的存在性也得到了证明。 |
| [^48] | [REPAIR: REnormalizing Permuted Activations for Interpolation Repair.](http://arxiv.org/abs/2211.08403) | 作者发现仅使用神经元对齐方法不能有效解决线性插值中激活方差坍缩的问题，因此提出了REPAIR方法来修复插值的归一化置换激活。实验证明，在各种架构中将REPAIR与神经元对齐方法结合使用可以大幅降低障碍。 |
| [^49] | [p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images.](http://arxiv.org/abs/2210.10418) | 本文介绍了p$^3$VAE生成模型，它将一个完美的物理模型集成到模型中，并应用于高分辨率高光谱遥感图像的语义分割。模型具有更好的外推能力和可解释性，同时具有高度解缕能力。 |
| [^50] | [Fraud Dataset Benchmark and Applications.](http://arxiv.org/abs/2208.14417) | 欺诈数据集基准（FDB）是一个针对欺诈检测的公开可用数据集的汇编，涵盖了各种欺诈相关任务，为解决欺诈检测中的独特挑战提供了标准化的数据集和基准。 (arXiv:2208.14417v3 [cs.LG] UPDATED) |
| [^51] | [Inferential Theory for Granular Instrumental Variables in High Dimensions.](http://arxiv.org/abs/2201.06605) | 本文扩展了颗粒工具变量（GIV）方法，包括在大维度下的识别过程，处理未知的因子和加载，以及通过额外构建的工具变量过度识别结构参数，从而提高效率。 |
| [^52] | [On the Fairness of Machine-Assisted Human Decisions.](http://arxiv.org/abs/2110.15310) | 本研究通过形式模型和实验室实验考察了机器预测的性质如何影响人类最终决策。实验发现，包含有偏见的人类决策者可能逆转算法结构与决策质量之间的关系，并且排除受保护群体信息可能无法减少差异甚至可能增加差异。 |
| [^53] | [Brainstorming Generative Adversarial Networks (BGANs): Towards Multi-Agent Generative Models with Distributed Private Datasets.](http://arxiv.org/abs/2002.00306) | 提出了一种新颖的脑力风暴生成对抗网络（BGAN）架构，实现多个代理在完全分布式的方式下生成类似真实数据的样本，解决了多个代理共享有限且分布式数据集的问题。 |

# 详细

[^1]: 使用鞍点边界的马丁格尔混合改进随机线性Bandit算法

    Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures. (arXiv:2309.14298v1 [stat.ML])

    [http://arxiv.org/abs/2309.14298](http://arxiv.org/abs/2309.14298)

    本研究提出了一种改进的随机线性Bandit算法，利用鞍点边界的马丁格尔混合构建了适用于随机Bandit的置信序列，并证明该算法能够以竞争性的最坏情况下遗憾保证实现更好的性能。

    

    我们提出了一种对随机线性Bandit问题具有最坏情况下遗憾保证的改进算法。广泛使用的"面对不确定性时的乐观原则"可以将随机Bandit问题转化为对未知奖励函数构建置信序列的问题。结果算法的性能取决于置信序列的大小，置信集较小可提供更好的经验性能和更强的遗憾保证。本研究中，我们使用了一种对自适应马丁格尔混合的尾部边界来构建适用于随机Bandit的置信序列。这些置信序列允许通过凸规划进行高效的动作选择。我们证明了基于我们的置信序列的线性Bandit算法能够保证达到具有竞争力的最坏情况下遗憾。我们实证和理论上证明了我们的置信序列比竞争对手更紧致。最后，我们证明了我们的紧致置信序列可以提供和置信集比较容易配置的更好的性能。

    We present improved algorithms with worst-case regret guarantees for the stochastic linear bandit problem. The widely used "optimism in the face of uncertainty" principle reduces a stochastic bandit problem to the construction of a confidence sequence for the unknown reward function. The performance of the resulting bandit algorithm depends on the size of the confidence sequence, with smaller confidence sets yielding better empirical performance and stronger regret guarantees. In this work, we use a novel tail bound for adaptive martingale mixtures to construct confidence sequences which are suitable for stochastic bandits. These confidence sequences allow for efficient action selection via convex programming. We prove that a linear bandit algorithm based on our confidence sequences is guaranteed to achieve competitive worst-case regret. We show that our confidence sequences are tighter than competitors, both empirically and theoretically. Finally, we demonstrate that our tighter confi
    
[^2]: 一种在随机对照试验中实现高效和强大治疗效果推断的加权预后协变量调整方法

    A Weighted Prognostic Covariate Adjustment Method for Efficient and Powerful Treatment Effect Inferences in Randomized Controlled Trials. (arXiv:2309.14256v1 [stat.ME])

    [http://arxiv.org/abs/2309.14256](http://arxiv.org/abs/2309.14256)

    一种新颖而高效的方法，将生成的人工智能算法预测纳入随机对照试验的协变量调整中，可以提高治疗效果推断的质量和可信度。

    

    随机对照试验(RCT)的一个重要任务是确定一种能够产生高效估计和有力测试治疗效果的统计方法。一种新颖而有效的策略，以获得高效和强大的治疗效果推断，是将生成的人工智能(AI)算法的预测纳入到RCT的协变量调整中，以进行回归分析。训练生成式AI算法使用历史对照数据可以构建RCT参与者的数字孪生生成器(DTG)，它利用参与者的基线协变量生成潜在对照结果的概率分布。DTG的概率分布摘要对试验结果有很高的预测力，通过回归对这些特征进行调整可以提高治疗效果推断的质量，并满足RCT的统计分析方面的监管指导方针。然而，该方法的关键假设是...

    A crucial task for a randomized controlled trial (RCT) is to specify a statistical method that can yield an efficient estimator and powerful test for the treatment effect. A novel and effective strategy to obtain efficient and powerful treatment effect inferences is to incorporate predictions from generative artificial intelligence (AI) algorithms into covariate adjustment for the regression analysis of a RCT. Training a generative AI algorithm on historical control data enables one to construct a digital twin generator (DTG) for RCT participants, which utilizes a participant's baseline covariates to generate a probability distribution for their potential control outcome. Summaries of the probability distribution from the DTG are highly predictive of the trial outcome, and adjusting for these features via regression can thus improve the quality of treatment effect inferences, while satisfying regulatory guidelines on statistical analyses, for a RCT. However, a critical assumption in th
    
[^3]: 受限用户可用性下的联邦学习

    Federated Learning Under Restricted User Availability. (arXiv:2309.14176v1 [cs.LG])

    [http://arxiv.org/abs/2309.14176](http://arxiv.org/abs/2309.14176)

    本文研究了受限用户可用性下的联邦学习问题，提出了一种新的FL问题的公式化，并通过使用风险感知目标设计了一种高效训练算法，完全不受随机访问模型（RAM）的影响。

    

    联邦学习（FL）是一种分散的机器学习框架，可以在尊重数据隐私的同时进行协作模型训练。在各种应用中，由于不利或随机环境，用户的可用性或参与度不均匀是不可避免的，后者在学习期间往往是不可控制的。在这里，我们提出了一种通用的用户选择机制，实施可能是随机化的固定选择策略，暂时称为随机访问模型（RAM）。我们提出了FL问题的新的公式化，有效地捕捉并减轻源自不频繁或受限用户的数据有限参与的情况下，存在RAM的情况下。通过在（未知的）RAM分布上使用条件风险价值（CVaR），我们将期望损失FL目标扩展到风险感知目标，从而实现了一种完全不受RAM影响的高效训练算法的设计，并且复杂性与FedAvg基本相同。

    Federated Learning (FL) is a decentralized machine learning framework that enables collaborative model training while respecting data privacy. In various applications, non-uniform availability or participation of users is unavoidable due to an adverse or stochastic environment, the latter often being uncontrollable during learning. Here, we posit a generic user selection mechanism implementing a possibly randomized, stationary selection policy, suggestively termed as a Random Access Model (RAM). We propose a new formulation of the FL problem which effectively captures and mitigates limited participation of data originating from infrequent, or restricted users, at the presence of a RAM. By employing the Conditional Value-at-Risk (CVaR) over the (unknown) RAM distribution, we extend the expected loss FL objective to a risk-aware objective, enabling the design of an efficient training algorithm that is completely oblivious to the RAM, and with essentially identical complexity as FedAvg. O
    
[^4]: 潜变量结构方程模型的最大似然估计：一种神经网络方法

    Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v1 [stat.ML])

    [http://arxiv.org/abs/2309.14073](http://arxiv.org/abs/2309.14073)

    本研究提出了一种新的图形结构，用于在线性和高斯性假设下稳定的潜变量结构方程模型。我们证明了计算该模型的最大似然估计等价于训练一个神经网络，并实现了一个基于GPU的算法来进行计算。

    

    我们提出了一种在线性和高斯性假设下稳定的结构方程模型的图形结构。我们展示了计算这个模型的最大似然估计等价于训练一个神经网络。我们实现了一个基于GPU的算法来计算这些模型的最大似然估计。

    We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
    
[^5]: TomOpt：在宇宙射线μ子断层扫描中面向任务和约束感知设计的微粒探测器的差分优化

    TomOpt: Differential optimisation for task- and constraint-aware design of particle detectors in the context of muon tomography. (arXiv:2309.14027v1 [physics.ins-det])

    [http://arxiv.org/abs/2309.14027](http://arxiv.org/abs/2309.14027)

    TomOpt是一个软件包，用于优化宇宙射线μ子断层扫描设计中的微粒探测器的几何布局和规格。它利用可微分编程模拟μ子与探测器和扫描体积的相互作用，并通过损失最小化的优化循环进行推断感知优化。

    

    我们描述了一个名为TomOpt的软件包，用于优化几何布局和探测器规格，以进行宇宙射线μ子的散射断层扫描设计。该软件利用可微分编程来模拟μ子与探测器和扫描体积的相互作用，推断体积属性，并进行损失最小化的优化循环。通过这样做，我们首次演示了粒子物理仪器的端到端可微分和推断感知优化。我们研究了该软件在相关基准场景上的性能，并讨论了其潜在应用。

    We describe a software package, TomOpt, developed to optimise the geometrical layout and specifications of detectors designed for tomography by scattering of cosmic-ray muons. The software exploits differentiable programming for the modeling of muon interactions with detectors and scanned volumes, the inference of volume properties, and the optimisation cycle performing the loss minimisation. In doing so, we provide the first demonstration of end-to-end-differentiable and inference-aware optimisation of particle physics instruments. We study the performance of the software on a relevant benchmark scenarios and discuss its potential applications.
    
[^6]: 对线性回归模型中交互作用的估计进行连结收缩以改进 (arXiv:2309.13998v1 [stat.ME])

    Linked shrinkage to improve estimation of interaction effects in regression models. (arXiv:2309.13998v1 [stat.ME])

    [http://arxiv.org/abs/2309.13998](http://arxiv.org/abs/2309.13998)

    本研究提出了一种在回归模型中添加交互作用的估计方法，通过使用局部收缩模型实现了对主效应和交互效应之间的较为灵活的关联，大大提高了回归系数的估计精度。

    

    我们解决了统计学中一个经典问题：如何在回归模型中添加二阶交互项。随着协变量维度的平方增长，我们开发了一个适应这种增长的估计器，同时提供准确的估计和适当的推理。现有的方法通过仅允许相关主效应之间的交互来克服维度问题。在这一理念基础上，我们使用局部收缩模型在两种效应之间实现了较为灵活的关联。我们通过实验证明，为主效应和交互效应借用收缩的强度可以大大提高回归系数的估计精度。此外，我们评估了该模型在推理方面的潜力，对于选择策略来说这是一个明显困难的问题。我们使用大规模队列数据提供了真实的示例和评估，并与其他方法进行了比较。变量重要性的评估在回归方程中并不容易。

    We address a classical problem in statistics: adding two-way interaction terms to a regression model. As the covariate dimension increases quadratically, we develop an estimator that adapts well to this increase, while providing accurate estimates and appropriate inference. Existing strategies overcome the dimensionality problem by only allowing interactions between relevant main effects. Building on this philosophy, we implement a softer link between the two types of effects using a local shrinkage model. We empirically show that borrowing strength between the amount of shrinkage for main effects and their interactions can strongly improve estimation of the regression coefficients. Moreover, we evaluate the potential of the model for inference, which is notoriously hard for selection strategies. Large-scale cohort data are used to provide realistic illustrations and evaluations. Comparisons with other methods are provided. The evaluation of variable importance is not trivial in regres
    
[^7]: 在近似最优的样本和时间复杂度中识别离散产品分布的混合物

    Identification of Mixtures of Discrete Product Distributions in Near-Optimal Sample and Time Complexity. (arXiv:2309.13993v1 [cs.LG])

    [http://arxiv.org/abs/2309.13993](http://arxiv.org/abs/2309.13993)

    本研究解决了识别离散随机变量混合产品分布的问题。通过组合经典的张量分解方法和一种新颖的条件数估计方法，我们实现了在样本复杂度和运行时复杂度上的改进，并扩展了已知的下界来匹配我们的上界。

    

    我们考虑从统计学中识别离散随机变量$X_1,\ldots,X_n$的分布，该分布是$k$个乘积分布的混合物的问题。对于$n \in O(k)$，以前的最佳样本复杂度为$(1/\zeta)^{O(k^2 \log k)}$（在由$\zeta$参数化的轻微分离假设下）。已知最佳下界为$\exp(\Omega(k))$。已知$n\geq 2k-1$对于识别是必要且充分的。我们展示了对于任意$n\geq 2k-1$，如何实现样本复杂度和运行时复杂度$(1/\zeta)^{O(k)}$。我们还将已知的下界$e^{\Omega(k)}$扩展到了广泛范围的$\zeta$匹配我们的上界。我们的结果通过组合（a）一种用于强大张量分解的经典方法和（b）通过仅研究它们在扁平化秩为1的张量上的作用来估计被称为Hadamard扩展的关键矩阵的条件数的一种新颖方法获得。

    We consider the problem of identifying, from statistics, a distribution of discrete random variables $X_1,\ldots,X_n$ that is a mixture of $k$ product distributions. The best previous sample complexity for $n \in O(k)$ was $(1/\zeta)^{O(k^2 \log k)}$ (under a mild separation assumption parameterized by $\zeta$). The best known lower bound was $\exp(\Omega(k))$. It is known that $n\geq 2k-1$ is necessary and sufficient for identification. We show, for any $n\geq 2k-1$, how to achieve sample complexity and run-time complexity $(1/\zeta)^{O(k)}$. We also extend the known lower bound of $e^{\Omega(k)}$ to match our upper bound across a broad range of $\zeta$. Our results are obtained by combining (a) a classic method for robust tensor decomposition, (b) a novel way of bounding the condition number of key matrices called Hadamard extensions, by studying their action only on flattened rank-1 tensors.
    
[^8]: 伪标签选择是一个决策问题

    Pseudo Label Selection is a Decision Problem. (arXiv:2309.13926v1 [cs.LG])

    [http://arxiv.org/abs/2309.13926](http://arxiv.org/abs/2309.13926)

    伪标签选择是半监督学习中的一种方法，通过嵌入决策理论，提出了BPLS框架来解决伪标签选择中的确认偏差问题。

    

    伪标签选择是半监督学习中一种简单而有效的方法，它需要一些准则来指导伪标签数据的选择。这些准则被证明可以在实践中工作得相当好。然而，它们的性能往往取决于标记数据上初始模型的拟合情况。早期过拟合可能通过选择具有自信但错误预测的实例（通常被称为确认偏差）而传播到最终模型。在两项最近的工作中，我们证明了伪标签选择（PLS）可以自然地嵌入到决策理论中。这为BPLS铺平了道路，它是一种用于PLS的贝叶斯框架，可以缓解确认偏差的问题。其核心是一种新的选择准则：伪样本和标记数据的后验预测的解析近似。我们通过证明这个“伪POS”的贝叶斯最优性来推导出这个选择准则。

    Pseudo-Labeling is a simple and effective approach to semi-supervised learning. It requires criteria that guide the selection of pseudo-labeled data. The latter have been shown to crucially affect pseudo-labeling's generalization performance. Several such criteria exist and were proven to work reasonably well in practice. However, their performance often depends on the initial model fit on labeled data. Early overfitting can be propagated to the final model by choosing instances with overconfident but wrong predictions, often called confirmation bias. In two recent works, we demonstrate that pseudo-label selection (PLS) can be naturally embedded into decision theory. This paves the way for BPLS, a Bayesian framework for PLS that mitigates the issue of confirmation bias. At its heart is a novel selection criterion: an analytical approximation of the posterior predictive of pseudo-samples and labeled data. We derive this selection criterion by proving Bayes-optimality of this "pseudo pos
    
[^9]: 神经策略镜像梯度在低维流形上的策略优化的样本复杂性研究

    Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds. (arXiv:2309.13915v1 [cs.LG])

    [http://arxiv.org/abs/2309.13915](http://arxiv.org/abs/2309.13915)

    本研究探讨了神经策略镜像梯度算法在低维流形上的样本复杂性。研究发现在每次迭代中，卷积神经网络可以很好地逼近价值函数和策略，且逼近误差受网络大小的影响，并且可以继承之前网络的平滑性。

    

    在强化学习中，配备有深度神经网络的策略优化算法在解决高维度的问题中取得了巨大的成功。然而，目前的分析无法解释它们为何能抵抗维度诅咒。在本研究中，我们研究了具有卷积神经网络作为函数逼近器的神经策略镜像梯度（NPMD）算法的样本复杂性。受到许多高维环境具有低维结构的经验观察的启发，例如将图像作为状态，我们将状态空间视为嵌入在$D$维欧氏空间中的$d$维流形，其中$d\ll D$是内在维度。我们证明了在NPMD的每次迭代中，价值函数和策略都可以很好地由卷积神经网络进行逼近。逼近误差由网络的大小控制，并且前一个网络的平滑性可以保留。

    Policy-based algorithms equipped with deep neural networks have achieved great success in solving high-dimensional policy optimization problems in reinforcement learning. However, current analyses cannot explain why they are resistant to the curse of dimensionality. In this work, we study the sample complexity of the neural policy mirror descent (NPMD) algorithm with convolutional neural networks (CNN) as function approximators. Motivated by the empirical observation that many high-dimensional environments have state spaces possessing low-dimensional structures, such as those taking images as states, we consider the state space to be a $d$-dimensional manifold embedded in the $D$-dimensional Euclidean space with intrinsic dimension $d\ll D$. We show that in each iteration of NPMD, both the value function and the policy can be well approximated by CNNs. The approximation errors are controlled by the size of the networks, and the smoothness of the previous networks can be inherited. As a
    
[^10]: 后续也很重要：通过后期服务上下文改进上下文推荐

    Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts. (arXiv:2309.13896v1 [cs.LG])

    [http://arxiv.org/abs/2309.13896](http://arxiv.org/abs/2309.13896)

    通过引入后期服务上下文，我们设计了一种新算法poLinUCB以提高上下文推荐中的在线学习效率，并通过鲁棒化的椭圆潜力引理实现了严格的遗憾控制。

    

    标准的上下文推荐问题假设算法在选择一个选项之前观察到所有相关的上下文。然而，在处理一些问题时，这种建模方式通常不够用，因为在选择选项后可以观察到有价值的附加上下文。为了提高这些应用中的在线学习效率，我们研究了一种具有后期服务上下文的新型上下文推荐问题，并设计了一种新算法poLinUCB，该算法在标准假设下实现了严格的遗憾控制。我们的技术证明的核心是著名的椭圆潜力引理（EPL）的一个鲁棒化和广义化版本，它可以容纳数据中的噪声。这种鲁棒化对于解决我们的问题是必要的，我们相信它也可以应用于其他领域。

    Standard contextual bandit problem assumes that all the relevant contexts are observed before the algorithm chooses an arm. This modeling paradigm, while useful, often falls short when dealing with problems in which valuable additional context can be observed after arm selection. For example, content recommendation platforms like Youtube, Instagram, Tiktok also observe valuable follow-up information pertinent to the user's reward after recommendation (e.g., how long the user stayed, what is the user's watch speed, etc.). To improve online learning efficiency in these applications, we study a novel contextual bandit problem with post-serving contexts and design a new algorithm, poLinUCB, that achieves tight regret under standard assumptions. Core to our technical proof is a robustified and generalized version of the well-known Elliptical Potential Lemma (EPL), which can accommodate noise in data. Such robustification is necessary for tackling our problem, and we believe it could also be
    
[^11]: 统计角度下的前K稀疏Softmax门控混合专家

    Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts. (arXiv:2309.13850v1 [stat.ML])

    [http://arxiv.org/abs/2309.13850](http://arxiv.org/abs/2309.13850)

    该论文研究前K稀疏softmax门控混合专家在密度和参数估计方面的作用，通过定义新的损失函数，探讨了输入区域的不同行为。研究发现，在真实专家数量已知的情况下，密度和参数估计的收敛速度与样本量成正比，但当真实模式未知时

    

    前K稀疏softmax门控混合专家被广泛用于在不增加计算成本的情况下扩展大规模深度学习架构。尽管在现实应用中非常受欢迎，但对该门控函数的理论理解仍然是一个未解决的问题。主要挑战来自于前K稀疏softmax门控函数的结构，它将输入空间划分为具有不同行为的多个区域。通过专注于高斯混合专家，我们对前K稀疏softmax门控函数对密度和参数估计的影响建立了理论结果。我们的结果依赖于定义参数之间的新损失函数，以捕捉输入区域的不同行为。当真实专家数量$k_{\ast}$已知时，我们证明了密度和参数估计的收敛速度都与样本量成正比。然而，当$k_{\ast}$变为未知且真实模式时

    Top-K sparse softmax gating mixture of experts has been widely used for scaling up massive deep-learning architectures without increasing the computational cost. Despite its popularity in real-world applications, the theoretical understanding of that gating function has remained an open problem. The main challenge comes from the structure of the top-K sparse softmax gating function, which partitions the input space into multiple regions with distinct behaviors. By focusing on a Gaussian mixture of experts, we establish theoretical results on the effects of the top-K sparse softmax gating function on both density and parameter estimations. Our results hinge upon defining novel loss functions among parameters to capture different behaviors of the input regions. When the true number of experts $k_{\ast}$ is known, we demonstrate that the convergence rates of density and parameter estimations are both parametric on the sample size. However, when $k_{\ast}$ becomes unknown and the true mode
    
[^12]: NSOTree：神经存活斜树

    NSOTree: Neural Survival Oblique Tree. (arXiv:2309.13825v1 [stat.ML])

    [http://arxiv.org/abs/2309.13825](http://arxiv.org/abs/2309.13825)

    本文介绍了一种名为NSOTree的神经存活斜树，该方法结合了神经网络和基于树的方法的优势，实现了对复杂函数的逼近能力和可解释性，用于存活分析。

    

    存活分析是一种统计方法，用于研究特定事件发生之前的持续时间，称为以时间为事件信息为特征的检验状态。最近，基于深度学习的方法由于其表征能力和最先进的性能而在该领域占主导地位。然而，深度神经网络的黑盒性质阻碍了其可解释性，而在实际的存活应用中，可解释性是被期望的但是过去的工作基本上忽视了这一点。相反，传统的基于树的方法在可解释性方面具有优势，但由于贪婪扩展导致难以逼近全局最优解。在本文中，我们利用神经网络和基于树的方法的优势，利用它们逼近复杂函数的能力同时保持可解释性。为此，我们提出了一种神经存活斜树（NSOTree）用于存活分析。

    Survival analysis is a statistical method employed to scrutinize the duration until a specific event of interest transpires, known as time-to-event information characterized by censorship. Recently, deep learning-based methods have dominated this field due to their representational capacity and state-of-the-art performance. However, the black-box nature of the deep neural network hinders its interpretability, which is desired in real-world survival applications but has been largely neglected by previous works. In contrast, conventional tree-based methods are advantageous with respect to interpretability, while consistently grappling with an inability to approximate the global optima due to greedy expansion. In this paper, we leverage the strengths of both neural networks and tree-based methods, capitalizing on their ability to approximate intricate functions while maintaining interpretability. To this end, we propose a Neural Survival Oblique Tree (NSOTree) for survival analysis. Speci
    
[^13]: 社会应用的无分布统计离散度控制

    Distribution-Free Statistical Dispersion Control for Societal Applications. (arXiv:2309.13786v1 [cs.LG])

    [http://arxiv.org/abs/2309.13786](http://arxiv.org/abs/2309.13786)

    提出了一个简单而灵活的框架，用于处理具有社会意义的无分布统计离散度控制，可以应用于高风险应用。

    

    在负责任的机器学习中，对模型性能的显式有限样本统计保证是一个重要因素。之前的研究主要关注于界定预测器的期望损失或者个体预测将承受的损失值在一个指定范围内的概率。然而，对于许多高风险应用而言，理解和控制损失分布的离散度，或者说人群中不同个体对算法决策的影响程度是至关重要的。我们开始研究具有社会意义的无分布统计离散度控制，并提出了一个简单但灵活的框架，可以处理比以前的工作更丰富的统计功能类。我们通过在有毒评论检测、医学影像和电影推荐等实验中验证了我们的方法。

    Explicit finite-sample statistical guarantees on model performance are an important ingredient in responsible machine learning. Previous work has focused mainly on bounding either the expected loss of a predictor or the probability that an individual prediction will incur a loss value in a specified range. However, for many high-stakes applications, it is crucial to understand and control the dispersion of a loss distribution, or the extent to which different members of a population experience unequal effects of algorithmic decisions. We initiate the study of distribution-free control of statistical dispersion measures with societal implications and propose a simple yet flexible framework that allows us to handle a much richer class of statistical functionals beyond previous work. Our methods are verified through experiments in toxic comment detection, medical imaging, and film recommendation.
    
[^14]: 论文标题：The Rashomon Importance Distribution: 摆脱不稳定的基于单一模型的变量重要性

    The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance. (arXiv:2309.13775v1 [cs.LG])

    [http://arxiv.org/abs/2309.13775](http://arxiv.org/abs/2309.13775)

    提出了一种新的变量重要性框架，该框架在数据分布上是稳定的，并可以与现有的模型类和全局变量重要性指标结合使用。

    

    量化变量重要性对于回答遗传学、公共政策和医学等领域的重大问题至关重要。当前的方法通常计算给定数据集上训练的给定模型的变量重要性。然而，对于给定数据集，可能有许多模型同样能解释目标结果;如果不考虑所有可能的解释，不同的研究者可能会得出许多冲突但同样有效的结论。此外，即使考虑了给定数据集的所有可能解释，这些洞察力可能不具有普适性，因为并非所有好的解释在合理的数据扰动下都是稳定的。我们提出了一种新的变量重要性框架，该框架量化了在所有好的模型集合中的变量重要性，并且在数据分布上是稳定的。我们的框架非常灵活，可以与大多数现有的模型类和全局变量重要性指标结合使用。

    Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We d
    
[^15]: 无需调参的最小体积非负矩阵分解

    Towards Tuning-Free Minimum-Volume Nonnegative Matrix Factorization. (arXiv:2309.13733v1 [stat.ML])

    [http://arxiv.org/abs/2309.13733](http://arxiv.org/abs/2309.13733)

    本论文提出了一个无需调参的最小体积非负矩阵分解方法，通过引入平方根套索的启发和无需调参的特性，解决了既有方法在选择调节参数方面的依赖性问题。通过实验证明，该方法对数据中的噪声水平不敏感。

    

    非负矩阵分解（NMF）是一种多功能且强大的工具，用于发现数据矩阵中的潜在结构，在文献中提出了许多变体。最近，Leplat等人（2019年）引入了最小体积NMF，用于在存在噪声的情况下可识别地恢复秩缺失矩阵。然而，他们的模型性能需要选择一个调节参数，其最优值依赖于未知的噪声水平。在这项工作中，我们提出了一种受平方根套索启发并具有无需调参特性的最小体积NMF替代式。我们的替代式也需要选择一个调节参数，但其最优值不取决于噪声水平。为了拟合我们的NMF模型，我们提出了一种带有全局收敛性保证的主导最小化（MM）算法。我们通过实验证明，我们调节参数的最优选择对数据中的噪声水平不敏感。

    Nonnegative Matrix Factorization (NMF) is a versatile and powerful tool for discovering latent structures in data matrices, with many variations proposed in the literature. Recently, Leplat et al.\@ (2019) introduced a minimum-volume NMF for the identifiable recovery of rank-deficient matrices in the presence of noise. The performance of their formulation, however, requires the selection of a tuning parameter whose optimal value depends on the unknown noise level. In this work, we propose an alternative formulation of minimum-volume NMF inspired by the square-root lasso and its tuning-free properties. Our formulation also requires the selection of a tuning parameter, but its optimal value does not depend on the noise level. To fit our NMF model, we propose a majorization-minimization (MM) algorithm that comes with global convergence guarantees. We show empirically that the optimal choice of our tuning parameter is insensitive to the noise level in the data.
    
[^16]: 正则化与最优多类别学习

    Regularization and Optimal Multiclass Learning. (arXiv:2309.13692v1 [cs.LG])

    [http://arxiv.org/abs/2309.13692](http://arxiv.org/abs/2309.13692)

    本研究旨在研究正则化在多类别学习中的作用，以及其在一些特定情景下的最优学习算法。我们使用一对一包含图(OIGs)展示了结构风险最小化、最大熵原则和贝叶斯推理等算法原则的最优学习算法。

    

    以经验风险最小化（ERM）为代表的典型学习算法已被发现在一些学习非均匀收敛的情景中无法成功应用。因此，在机器学习实践中存在许多更丰富的算法技术来控制模型容量。然而，在这些更一般的情境中，没有一种技术或原则能够脱颖而出来描述最优学习的特征。本文旨在表征正则化在多类别学习中的作用，这可能是ERM失败的最简单情景，而标签集是任意的。我们利用一对一包含图（OIGs）展示了与传统算法原则相结合的最优学习算法：奥卡姆剃刀原则所体现的结构风险最小化（SRM），最大熵原则和贝叶斯推理。值得注意的是，我们引入了一种在结构风险最小化上进行放松的最优学习器。

    The quintessential learning algorithm of empirical risk minimization (ERM) is known to fail in various settings for which uniform convergence does not characterize learning. It is therefore unsurprising that the practice of machine learning is rife with considerably richer algorithmic techniques for successfully controlling model capacity. Nevertheless, no such technique or principle has broken away from the pack to characterize optimal learning in these more general settings.  The purpose of this work is to characterize the role of regularization in perhaps the simplest setting for which ERM fails: multiclass learning with arbitrary label sets. Using one-inclusion graphs (OIGs), we exhibit optimal learning algorithms that dovetail with tried-and-true algorithmic principles: Occam's Razor as embodied by structural risk minimization (SRM), the principle of maximum entropy, and Bayesian reasoning. Most notably, we introduce an optimal learner which relaxes structural risk minimization on
    
[^17]: 无法找到出色的泛化度量方法

    Fantastic Generalization Measures are Nowhere to be Found. (arXiv:2309.13658v1 [cs.LG])

    [http://arxiv.org/abs/2309.13658](http://arxiv.org/abs/2309.13658)

    本论文研究了过参数化情况下的泛化界限问题，通过分析多个界限发现在这种情况下无法找到紧致的界限来解释神经网络的出色性能。

    

    过去的文献中提出了许多泛化界限作为解释神经网络在过参数化情况下泛化能力的潜在方法。然而，这些界限都不是紧致的。例如，在他们的论文“Fantastic Generalization Measures and Where to Find Them”中，Jiang等人（2020）检查了十几个泛化界限，并通过实验证明没有一个能够解释神经网络卓越的性能。这引出了一个问题，即是否有可能找到紧致的泛化界限。我们考虑了文献中常见的两种泛化界限：（1）依赖于训练集和学习算法输出的界限。文献中有多个这种类型的界限（例如基于范数和基于间隔的界限），但我们证明在过参数化的情况下，没有这样的界限能够一致地紧致；（2）依赖于训练集和测试集的界限。

    Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, none of these bounds are tight. For instance, in their paper ``Fantastic Generalization Measures and Where to Find Them'', Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them imply guarantees that can explain the remarkable performance of neural networks. This raises the question of whether tight generalization bounds are at all possible. We consider two types of generalization bounds common in the literature: (1) bounds that depend on the training set and the output of the learning algorithm. There are multiple bounds of this type in the literature (e.g., norm-based and margin-based bounds), but we prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that depend on the training set and on the 
    
[^18]: 关于去噪中的后验分布：在不确定性量化中的应用

    On the Posterior Distribution in Denoising: Application to Uncertainty Quantification. (arXiv:2309.13598v1 [cs.CV])

    [http://arxiv.org/abs/2309.13598](http://arxiv.org/abs/2309.13598)

    该论文研究了去噪中的后验分布及其与后验均值之间的关系，并应用于预训练去噪器的不确定性量化。提出了一种高效计算后验分布主成分和近似边际分布的方法。不需要显式计算高阶矩张量或进行训练或微调。

    

    去噪算法在许多应用中起着核心作用，从降噪低级别成像传感器到提升基于评分的生成模型。后一类方法使用Tweedie公式，将高斯去噪的后验均值（即最小均方误差去噪器）与数据分布的评分链接起来。我们在这里推导了后验分布的高阶中心矩与后验均值的高阶导数之间的基本关系。我们利用这个结果进行预训练去噪器的不确定性量化。特别地，我们展示了如何高效计算图像任何所需区域的后验分布的主成分，以及如何近似沿这些（或任何其他）一维方向的完整边际分布。我们的方法快速且内存高效，因为它不需要显式计算或存储高阶矩张量，并且无需训练或微调。

    Denoisers play a central role in many applications, from noise suppression in low-grade imaging sensors, to empowering score-based generative models. The latter category of methods makes use of Tweedie's formula, which links the posterior mean in Gaussian denoising (i.e., the minimum MSE denoiser) with the score of the data distribution. Here, we derive a fundamental relation between the higher-order central moments of the posterior distribution, and the higher-order derivatives of the posterior mean. We harness this result for uncertainty quantification of pre-trained denoisers. Particularly, we show how to efficiently compute the principal components of the posterior distribution for any desired region of an image, as well as to approximate the full marginal distribution along those (or any other) one-dimensional directions. Our method is fast and memory efficient, as it does not explicitly compute or store the high-order moment tensors and it requires no training or fine tuning of t
    
[^19]: 使用密度功率差异的鲁棒主成分分析

    Robust Principal Component Analysis using Density Power Divergence. (arXiv:2309.13531v1 [stat.ME])

    [http://arxiv.org/abs/2309.13531](http://arxiv.org/abs/2309.13531)

    使用最小密度功率差异估计的鲁棒主成分分析方法在高维数据中具有理论优势且具备高鲁棒性保证。

    

    主成分分析是一种广泛使用的统计工具，主要用于降维。然而，已知样本中存在异常观测会对主成分分析产生不利影响，而这种情况相当普遍。使用M估计的鲁棒主成分分析方法具有理论上的优点，但在高维数据时其鲁棒性显著下降。另一方面，解决主成分追踪或类似优化问题的鲁棒主成分分析算法具有较高的鲁棒性，但缺乏理论丰富性，并且与M估计相比要求更高的计算能力。我们引入了一种基于最小密度功率差异估计的新型鲁棒主成分分析估计量，它结合了M估计和最小差异估计的理论优势，并且无论数据维度如何都具有很高的鲁棒性保证。我们提出了一种计算高效的算法来获取这个估计值。我们的理论发现得到了广泛的仿真支持。

    Principal component analysis (PCA) is a widely employed statistical tool used primarily for dimensionality reduction. However, it is known to be adversely affected by the presence of outlying observations in the sample, which is quite common. Robust PCA methods using M-estimators have theoretical benefits, but their robustness drop substantially for high dimensional data. On the other end of the spectrum, robust PCA algorithms solving principal component pursuit or similar optimization problems have high breakdown, but lack theoretical richness and demand high computational power compared to the M-estimators. We introduce a novel robust PCA estimator based on the minimum density power divergence estimator. This combines the theoretical strength of the M-estimators and the minimum divergence estimators with a high breakdown guarantee regardless of data dimension. We present a computationally efficient algorithm for this estimate. Our theoretical findings are supported by extensive simul
    
[^20]: 使用人工智能增强对英国道路交通事故严重程度的预测与分析：结合机器学习、计量经济学技术和时间序列预测的公共卫生研究

    Enhancing Prediction and Analysis of UK Road Traffic Accident Severity Using AI: Integration of Machine Learning, Econometric Techniques, and Time Series Forecasting in Public Health Research. (arXiv:2309.13483v1 [stat.ML])

    [http://arxiv.org/abs/2309.13483](http://arxiv.org/abs/2309.13483)

    本研究结合了机器学习、计量经济学和时间序列预测方法，对英国道路交通事故的严重程度进行了预测和分析。研究结果表明，优化后的模型在预测准确性方面优于传统方法，并识别出了影响事故严重程度的关键变量。

    

    本研究利用历史数据，使用机器学习、计量经济学和统计方法对英国道路交通事故的严重程度进行了调查。我们采用了相关性分析、回归模型、GMM处理误差项问题以及VAR和ARIMA模型进行时间序列预测等多种技术。我们的方法优于朴素预测，MASE为0.800，ME为-73.80。我们还构建了一个随机森林分类器，精确度为73%，召回率为78%，F1分数为73%。通过H2O AutoML进行优化后，我们得到了一个XGBoost模型，RMSE为0.176，MAE为0.087。因子分析确定了关键变量，我们使用SHAP进行可解释性人工智能分析，突出了Driver_Home_Area_Type和Road_Type等有影响力的因素。我们的研究提高了对事故严重程度的理解，并为基于证据的道路安全政策提供了启示。

    This research investigates road traffic accident severity in the UK, using a combination of machine learning, econometric, and statistical methods on historical data. We employed various techniques, including correlation analysis, regression models, GMM for error term issues, and time-series forecasting with VAR and ARIMA models. Our approach outperforms naive forecasting with an MASE of 0.800 and ME of -73.80. We also built a random forest classifier with 73% precision, 78% recall, and a 73% F1-score. Optimizing with H2O AutoML led to an XGBoost model with an RMSE of 0.176 and MAE of 0.087. Factor Analysis identified key variables, and we used SHAP for Explainable AI, highlighting influential factors like Driver_Home_Area_Type and Road_Type. Our study enhances understanding of accident severity and offers insights for evidence-based road safety policies.
    
[^21]: ResNet和Softmax的统一方案

    A Unified Scheme of ResNet and Softmax. (arXiv:2309.13482v1 [cs.LG])

    [http://arxiv.org/abs/2309.13482](http://arxiv.org/abs/2309.13482)

    这是一篇关于将softmax回归和ResNet相结合的统一方案的论文，提供了对回归问题的理论分析，并推导了梯度...

    

    大型语言模型（LLM）对人类社会带来了重大变革。Softmax回归和残差神经网络（ResNet）是深度学习中两个重要的技术：它们不仅作为支持LLM功能的重要理论组成部分，而且与许多其他机器学习和理论计算机科学领域相关，包括但不限于图像分类，目标检测，语义分割和张量。以往的研究对这两个概念进行了分别研究。本文提出了一个回归问题的理论分析：$\| \langle \exp(Ax) + A x , {\bf 1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b \|_2^2$，其中$A$是一个$n \times d$维实矩阵，$b$是一个$n$维实向量，${\bf 1}_n$是所有元素都为1的$n$维向量。这个回归问题是将softmax回归和ResNet相结合的统一方案，这在以前从未做过。我们推导了梯度...

    Large language models (LLMs) have brought significant changes to human society. Softmax regression and residual neural networks (ResNet) are two important techniques in deep learning: they not only serve as significant theoretical components supporting the functionality of LLMs but also are related to many other machine learning and theoretical computer science fields, including but not limited to image classification, object detection, semantic segmentation, and tensors.  Previous research works studied these two concepts separately. In this paper, we provide a theoretical analysis of the regression problem: $\| \langle \exp(Ax) + A x , {\bf 1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b \|_2^2$, where $A$ is a matrix in $\mathbb{R}^{n \times d}$, $b$ is a vector in $\mathbb{R}^n$, and ${\bf 1}_n$ is the $n$-dimensional vector whose entries are all $1$. This regression problem is a unified scheme that combines softmax regression and ResNet, which has never been done before. We derive the gra
    
[^22]: CA-PCA: 测量曲率的流形维度估计

    CA-PCA: Manifold Dimension Estimation, Adapted for Curvature. (arXiv:2309.13478v1 [stat.ML])

    [http://arxiv.org/abs/2309.13478](http://arxiv.org/abs/2309.13478)

    本文提出了CA-PCA算法，它基于曲率校准的局部PCA版本，通过考虑底层流形的曲率，改进了维度估计器的性能。

    

    高维数据分析算法的成功常归因于流形假设，即假设数据分布在或接近低维流形上。在进行维度约简之前，确定或估计该流形的维度通常是有用的。现有的维度估计方法使用平坦单位球进行校准。本文提出了CA-PCA，一种基于二次嵌入校准的局部PCA版本，以考虑底层流形的曲率。大量的精心实验表明，这种适应性改进了估计器在各种设置下的性能。

    The success of algorithms in the analysis of high-dimensional data is often attributed to the manifold hypothesis, which supposes that this data lie on or near a manifold of much lower dimension. It is often useful to determine or estimate the dimension of this manifold before performing dimension reduction, for instance. Existing methods for dimension estimation are calibrated using a flat unit ball. In this paper, we develop CA-PCA, a version of local PCA based instead on a calibration of a quadratic embedding, acknowledging the curvature of the underlying manifold. Numerous careful experiments show that this adaptation improves the estimator in a wide range of settings.
    
[^23]: 模型无关的图神经网络用于整合局部和全局信息的研究

    A Model-Agnostic Graph Neural Network for Integrating Local and Global Information. (arXiv:2309.13459v1 [stat.ML])

    [http://arxiv.org/abs/2309.13459](http://arxiv.org/abs/2309.13459)

    MaGNet是一种模型无关的图神经网络框架，能够顺序地整合不同顺序的信息，并通过识别有影响力的紧凑图结构提供有意义且可解释的结果。

    

    图神经网络（GNNs）在各种以图为重点的任务中取得了令人满意的性能。尽管取得了成功，但现有的GNN存在两个重要限制：由于黑盒特性，结果缺乏可解释性；无法学习不同顺序的表示。为了解决这些问题，我们提出了一种新的模型无关的图神经网络（MaGNet）框架，能够顺序地整合不同顺序的信息，从高阶邻居中提取知识，并通过识别有影响力的紧凑图结构提供有意义且可解释的结果。特别地，MaGNet由两个组件组成：图拓扑下复杂关系的潜在表示的估计模型和识别有影响力的节点、边和重要节点特征的解释模型。从理论上，我们通过经验Rademacher复杂度建立了MaGNet的泛化误差界，并展示了其强大的能力。

    Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its pow
    
[^24]: 加速演化算法解决黑盒优化问题

    Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems. (arXiv:2309.13349v1 [cs.NE])

    [http://arxiv.org/abs/2309.13349](http://arxiv.org/abs/2309.13349)

    本文提出了一种能够在进化算法执行中选择适当的近似函数成本的技术，用于加速解决黑盒优化问题。

    

    在处理计算复杂的黑盒优化问题时，常常使用基于群体的演化算法。它们通过选择机制从给定的群体中选择最佳解决方案，比较它们的目标值，然后用这些目标值生成下一代群体。这个迭代过程能够高效地探索解空间，逐步改善解决方案。然而，这些算法需要大量的评估才能提供一个优质的解决方案，当评估成本很高时，可能会造成计算上的负担。在某些情况下，可以用成本较低的不太准确的近似函数替换原始目标函数。这就引入了评估成本与准确性之间的权衡。在本文中，我们提出了一种能够在优化算法执行过程中选择适当的近似函数成本的技术。

    Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, these algorithms require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a trade-off between the evaluation cost and its accuracy.  In this paper, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which th
    
[^25]: 独立投影的扩散：变分推断和最优均场逼近的梯度流

    Independent projections of diffusions: Gradient flows for variational inference and optimal mean field approximations. (arXiv:2309.13332v1 [math.PR])

    [http://arxiv.org/abs/2309.13332](http://arxiv.org/abs/2309.13332)

    本文介绍了一种称为“独立投影”的构造，它在变分推断和最优均场逼近中具有最优的效果，可以实现高维扩散过程的独立坐标的最优逼近，并展示了其长时间收敛性和慢的路径增长率。

    

    如何用独立坐标的过程来最优地逼近高维扩散过程？本文介绍了一种称为“独立投影”的构造，它在两个自然准则下是最优的。首先，当原始扩散过程是可逆的且具有不变测度ρ∗时，独立投影作为独立坐标的空间上相对熵H(⋅|ρ∗)的Wasserstein梯度流。这与统计文献中关于均场变分推断的Langevin采样方案有关。此外，我们还提供了关于独立投影的长时间收敛的定性和定量结果，其中在对数凹情况下的定量结果是通过一种新的对数Sobolev不等式的变体推导出来的。其次，在所有具有独立坐标的过程中，独立投影显示出了路径增长率最慢。

    What is the optimal way to approximate a high-dimensional diffusion process by one in which the coordinates are independent? This paper presents a construction, called the \emph{independent projection}, which is optimal for two natural criteria. First, when the original diffusion is reversible with invariant measure $\rho_*$, the independent projection serves as the Wasserstein gradient flow for the relative entropy $H(\cdot\,|\,\rho_*)$ constrained to the space of product measures. This is related to recent Langevin-based sampling schemes proposed in the statistical literature on mean field variational inference. In addition, we provide both qualitative and quantitative results on the long-time convergence of the independent projection, with quantitative results in the log-concave case derived via a new variant of the logarithmic Sobolev inequality. Second, among all processes with independent coordinates, the independent projection is shown to exhibit the slowest growth rate of path-
    
[^26]: C$^2$VAE：基于高斯Copula的VAE与对比后验的非耦合与非耦合表示有差异的联合学习

    C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior. (arXiv:2309.13303v1 [cs.LG])

    [http://arxiv.org/abs/2309.13303](http://arxiv.org/abs/2309.13303)

    这篇论文提出了一种C$^2$VAE模型，通过联合学习非耦合且相关的隐藏因素，并通过自监督分类器消除耦合表示，以增强非耦合表示学习。该模型在不依赖先验知识和强建模假设的情况下，使用总相关驱动分解后验来学习因子化的非耦合表示，并利用神经高斯Copula模型提取隐藏特征之间的依赖关系来获得耦合表示。

    

    我们提出了一个自监督变分自动编码器（VAE），以联合学习非耦合且相关的隐藏因素，然后通过自监督分类器增强非耦合表示学习，以对比方式消除耦合表示。为此，引入了一种无需依赖先验知识和在神经架构中涉及后验的强建模假设的对比Copula VAE（C$^2$VAE）。C$^2$VAE使用总相关（TC）驱动分解来因子化后验（ELBO），以学习因子化的非耦合表示，并通过神经高斯Copula提取隐藏特征之间的依赖关系以获得耦合表示。然后，自监督对比分类器区分非耦合表示和耦合表示，其中对比损失用于正则化该对比分类。

    We present a self-supervised variational autoencoder (VAE) to jointly learn disentangled and dependent hidden factors and then enhance disentangled representation learning by a self-supervised classifier to eliminate coupled representations in a contrastive manner. To this end, a Contrastive Copula VAE (C$^2$VAE) is introduced without relying on prior knowledge about data in the probabilistic principle and involving strong modeling assumptions on the posterior in the neural architecture. C$^2$VAE simultaneously factorizes the posterior (evidence lower bound, ELBO) with total correlation (TC)-driven decomposition for learning factorized disentangled representations and extracts the dependencies between hidden features by a neural Gaussian copula for copula coupled representations. Then, a self-supervised contrastive classifier differentiates the disentangled representations from the coupled representations, where a contrastive loss regularizes this contrastive classification together wi
    
[^27]: 分布偏移感知的强化学习非同策略区间估计方法：一个统一的误差量化框架

    Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework. (arXiv:2309.13278v1 [stat.ML])

    [http://arxiv.org/abs/2309.13278](http://arxiv.org/abs/2309.13278)

    本研究提出了一个对于强化学习非同策略评估问题的统一误差量化框架，并解决了分布偏移的挑战。通过在一个单一的区间内共同量化两个估计误差源，该框架揭示了之前隐藏的误差权衡，从而提高了置信区间的准确性。

    

    本文研究了在无限时间马尔可夫决策过程中的高置信度非同策略评估问题，其目标是仅利用从未知行为策略预先收集的离线数据为目标策略的值建立一个置信区间（CI）。该任务面临两个主要挑战：在CI估计中提供全面且严格的误差量化，并解决由目标策略产生的分布偏移问题，该分布与离线数据生成过程之间存在差异。受到创新的统一误差分析的启发，我们在一个单一的区间内共同量化两个估计误差来源：在建模边际化重要性权重时的规范不准确误差和抽样导致的统计不确定性。这一统一的框架揭示了误差之间以前隐藏的权衡，从而削弱了CI的紧密性。通过依靠精心设计的判别函数，提出了一种新的解决方案来克服分布偏移问题。

    We study high-confidence off-policy evaluation in the context of infinite-horizon Markov decision processes, where the objective is to establish a confidence interval (CI) for the target policy value using only offline data pre-collected from unknown behavior policies. This task faces two primary challenges: providing a comprehensive and rigorous error quantification in CI estimation, and addressing the distributional shift that results from discrepancies between the distribution induced by the target policy and the offline data-generating process. Motivated by an innovative unified error analysis, we jointly quantify the two sources of estimation errors: the misspecification error on modeling marginalized importance weights and the statistical uncertainty due to sampling, within a single interval. This unified framework reveals a previously hidden tradeoff between the errors, which undermines the tightness of the CI. Relying on a carefully designed discriminator function, the proposed
    
[^28]: BART-SIMP：一种灵活的空间协变建模和预测的新框架使用贝叶斯加法回归树

    BART-SIMP: a novel framework for flexible spatial covariate modeling and prediction using Bayesian additive regression trees. (arXiv:2309.13270v1 [stat.ME])

    [http://arxiv.org/abs/2309.13270](http://arxiv.org/abs/2309.13270)

    BART-SIMP是一种灵活的空间协变建模和预测的新框架，通过结合高斯过程空间模型和贝叶斯加法回归树模型，可以提供可靠的不确定性估计，并成功应用于肯尼亚家庭集群样本中的人体测量响应预测。

    

    在空间统计学中，预测是一个经典的挑战，将空间协变量纳入具有潜在空间效应的模型中可以极大地提高预测性能。我们希望开发出灵活的回归模型，允许在协变量结构中存在非线性和交互作用。机器学习模型已经在空间环境中提出，允许残差中存在空间依赖性，但无法提供可靠的不确定性估计。在本文中，我们研究了高斯过程空间模型和贝叶斯加法回归树（BART）模型的新组合。通过将马尔可夫链蒙特卡洛（MCMC）与嵌套拉普拉斯近似（INLA）技术相结合，降低了方法的计算负担。我们通过模拟研究了该方法的性能，并使用该模型预测在肯尼亚家庭集群样本中收集的人体测量响应。

    Prediction is a classic challenge in spatial statistics and the inclusion of spatial covariates can greatly improve predictive performance when incorporated into a model with latent spatial effects. It is desirable to develop flexible regression models that allow for nonlinearities and interactions in the covariate structure. Machine learning models have been suggested in the spatial context, allowing for spatial dependence in the residuals, but fail to provide reliable uncertainty estimates. In this paper, we investigate a novel combination of a Gaussian process spatial model and a Bayesian Additive Regression Tree (BART) model. The computational burden of the approach is reduced by combining Markov chain Monte Carlo (MCMC) with the Integrated Nested Laplace Approximation (INLA) technique. We study the performance of the method via simulations and use the model to predict anthropometric responses, collected via household cluster samples in Kenya.
    
[^29]: 信息价值（IV）的统计假设检验

    Statistical Hypothesis Testing for Information Value (IV). (arXiv:2309.13183v1 [math.ST])

    [http://arxiv.org/abs/2309.13183](http://arxiv.org/abs/2309.13183)

    该论文提出了信息价值（IV）的统计假设检验方法，为模型建立前的特征选择提供了理论框架，并通过实验证明了该方法的有效性。

    

    信息价值（IV）是模型建立前进行特征选择的一种常用技术。目前存在一些实际标准，但基于IV的判断是否一个预测因子具有足够的预测能力的理论依据依然神秘且缺乏。然而，关于该技术的数学发展和统计推断方法在文献中几乎没有提及。在本研究中，我们提出了一个关于IV的理论框架，并提出了一种非参数假设检验方法来测试预测能力。我们展示了如何高效计算检验统计量，并在模拟数据上研究其表现。此外，我们将这一方法应用于银行欺诈数据，并提供了一个实现我们结果的Python库。

    Information value (IV) is a quite popular technique for feature selection prior to the modeling phase. There are practical criteria, but at the same time mysterious and lacking theoretical arguments, based on the IV, to decide if a predictor has sufficient predictive power to be considered in the modeling phase. However, the mathematical development and statistical inference methods for this technique is almost non-existent in the literature. In this work we present a theoretical framework for the IV and propose a non-parametric hypothesis test to test the predictive power. We show how to efficiently calculate the test statistic and study its performance on simulated data. Additionally, we apply our test on bank fraud data and provide a Python library where we implement our results.
    
[^30]: 使用非参数隐马尔可夫模型的基于模型的聚类

    Model-based Clustering using Non-parametric Hidden Markov Models. (arXiv:2309.12238v1 [math.ST])

    [http://arxiv.org/abs/2309.12238](http://arxiv.org/abs/2309.12238)

    本文研究了使用非参数隐马尔可夫模型进行基于模型的聚类时的贝叶斯风险，并提出了相应的聚类方法。通过研究分类的贝叶斯风险和聚类的贝叶斯风险之间的关系，确定了聚类任务的难度。同时，在插值分类器和在线设置中的结果也得到了证明。模拟实验验证了这些发现。

    

    非参数隐马尔可夫模型（HMM）由于其依赖结构，可以在不指定群组分布的情况下进行基于模型的聚类。本文研究了在使用HMM进行聚类时的贝叶斯风险，并提出了相应的聚类方法。首先，我们给出了将分类的贝叶斯风险与聚类的贝叶斯风险联系起来的结果，用以确定聚类任务的难度的关键数量。我们还在独立同分布的框架下证明了这一结果，这可能具有独立的兴趣。然后我们研究了插值分类器的过度风险。所有这些结果都被证明在在线设置中仍然有效，在该设置下，观测结果被顺序聚类。模拟实验证明了我们的发现。

    Thanks to their dependency structure, non-parametric Hidden Markov Models (HMMs) are able to handle model-based clustering without specifying group distributions. The aim of this work is to study the Bayes risk of clustering when using HMMs and to propose associated clustering procedures. We first give a result linking the Bayes risk of classification and the Bayes risk of clustering, which we use to identify the key quantity determining the difficulty of the clustering task. We also give a proof of this result in the i.i.d. framework, which might be of independent interest. Then we study the excess risk of the plugin classifier. All these results are shown to remain valid in the online setting where observations are clustered sequentially. Simulations illustrate our findings.
    
[^31]: Riemannian流形上Matern高斯过程的后验收缩速率

    Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds. (arXiv:2309.10918v1 [stat.ML])

    [http://arxiv.org/abs/2309.10918](http://arxiv.org/abs/2309.10918)

    该论文研究了定义在紧致Riemannian流形上的内在Matern高斯过程和外在过程之间的收缩速率，并发现它们的速率在适当匹配平滑参数的情况下是相等的。

    

    高斯过程在许多依赖于不确定性量化的机器学习应用中被使用。最近，已经开发了在几何设置下处理这些模型的计算工具，例如，当输入位于Riemannian流形上时。这引出了一个问题：这些内在模型在理论上是否可以证明相比于将所有相关量嵌入到$\mathbb{R}^d$并使用普通欧几里德高斯过程的限制，可以带来更好的性能？为了研究这个问题，我们证明了定义在紧致Riemannian流形上的内在Matern高斯过程的最优收缩速率。我们还通过流形和环境Sobolev空间之间的迹和扩展定理证明了外在过程的类似速率：令人惊讶的是，所得到的速率与内在过程的速率相符，前提是它们的平滑参数适当匹配。我们在一些实证数据上进行了对这些速率的演示。

    Gaussian processes are used in many machine learning applications that rely on uncertainty quantification. Recently, computational tools for working with these models in geometric settings, such as when inputs lie on a Riemannian manifold, have been developed. This raises the question: can these intrinsic models be shown theoretically to lead to better performance, compared to simply embedding all relevant quantities into $\mathbb{R}^d$ and using the restriction of an ordinary Euclidean Gaussian process? To study this, we prove optimal contraction rates for intrinsic Mat\'ern Gaussian processes defined on compact Riemannian manifolds. We also prove analogous rates for extrinsic processes using trace and extension theorems between manifold and ambient Sobolev spaces: somewhat surprisingly, the rates obtained turn out to coincide with those of the intrinsic processes, provided that their smoothness parameters are matched appropriately. We illustrate these rates empirically on a number of
    
[^32]: 深度学习网络的几何结构和全局${\mathcal L}^2$最小化器的构建

    Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers. (arXiv:2309.10639v1 [cs.LG])

    [http://arxiv.org/abs/2309.10639](http://arxiv.org/abs/2309.10639)

    本文提供了深度学习网络结构的几何解释，并且构建了全局最小化器族，该族能够全局最小化成本函数。此外，还确定了各种退化局部最小值。

    

    本文提供了对深度学习（DL）网络结构的几何解释，该网络具有$L$个隐藏层，斜坡激活函数，${\mathcal L}^2$ Schatten类（或Hilbert-Schmidt）成本函数，以及相等维度$Q\geq1$的输入和输出空间${\mathbb R}^Q$。隐藏层也定义在${\mathbb R}^{Q}$的空间上。我们利用我们最新的关于浅层神经网络的结果，在$L\geq Q$的情况下构造了一个明确的最小化器族，该族能够全局最小化成本函数，并且我们证明这个族是退化的。在这里提到的上下文中，DL网络的隐藏层通过对训练输入的递归截断映射的应用来“整理”训练输入，以最小化噪声与信号的比率。此外，我们确定了$2^Q-1$个不同的退化局部最小值。

    In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\mathbb R}^Q$ with equal dimension $Q\geq1$. The hidden layers are defined on spaces ${\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network "curate" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.
    
[^33]: 投影 Langevin 动力学和梯度流的熵优化输运

    Projected Langevin dynamics and a gradient flow for entropic optimal transport. (arXiv:2309.08598v1 [math.PR] CROSS LISTED)

    [http://arxiv.org/abs/2309.08598](http://arxiv.org/abs/2309.08598)

    本文提出了投影 Langevin 动力学和梯度流算法，用于从经熵正则化的优化输运中进行采样和求解。该方法在小的正则化参数下集中于最优输运耦合点，并且保持在约束条件下的解。对应的长时间极限是熵优化输运问题的唯一解。

    

    经典的（过阻尼的） Langevin 动力学为从其不变测度中采样提供了一种自然的算法，该测度在概率测度空间上唯一最小化一个能量泛函，并且在噪声参数很小时集中于相关势能的极小值点。我们引入了类似的扩散动力学，从经熵正则化的优化输运中进行采样，在两个给定边缘概率测度 $\mu$ 和 $\nu$ 上约束下唯一最小化相同的能量泛函，并在小的正则化参数下集中于最优输运耦合点。具体而言，我们的过程满足两个关键性质：首先，如果在其上初始化，解在每个时间点的分布都保持在 $\Pi(\mu,\nu)$ 中。其次，长时间极限是一个熵优化输运问题的唯一解。另外，我们通过一个新的 log-Sobolev 类型的结果证明...

    The classical (overdamped) Langevin dynamics provide a natural algorithm for sampling from its invariant measure, which uniquely minimizes an energy functional over the space of probability measures, and which concentrates around the minimizer(s) of the associated potential when the noise parameter is small. We introduce analogous diffusion dynamics that sample from an entropy-regularized optimal transport, which uniquely minimizes the same energy functional but constrained to the set $\Pi(\mu,\nu)$ of couplings of two given marginal probability measures $\mu$ and $\nu$ on $\mathbb{R}^d$, and which concentrates around the optimal transport coupling(s) for small regularization parameter. More specifically, our process satisfies two key properties: First, the law of the solution at each time stays in $\Pi(\mu,\nu)$ if it is initialized there. Second, the long-time limit is the unique solution of an entropic optimal transport problem. In addition, we show by means of a new log-Sobolev-typ
    
[^34]: 用于机器学习的热带几何工具：TML软件包

    Tropical Geometric Tools for Machine Learning: the TML package. (arXiv:2309.01082v1 [stat.ML])

    [http://arxiv.org/abs/2309.01082](http://arxiv.org/abs/2309.01082)

    TML软件包是第一个包含一套全面工具和方法的R软件包，用于处理与热带凸性相关的基本计算和可视化，以及使用热带度量进行监督和无监督学习模型的统计推断。

    

    在过去的十年中，热带几何学的发展提供了许多直接应用于统计学习问题的工具。TML软件包是第一个包含一套全面的工具和方法的R软件包，用于处理与热带凸性相关的基本计算、热带凸集的可视化，以及使用热带度量和热带投影环上的max-plus代数进行监督和无监督学习模型。主要的，TML软件包使用Hit and Run Markov chain Monte Carlo采样器与热带度量作为统计推断的主要工具。除了基本计算和热带HAR采样器的各种应用之外，我们还关注TML软件包中包含的几种监督和无监督方法，包括热带主成分分析、热带逻辑回归和热带核密度估计。

    In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
    
[^35]: 通过未见过的状态增强利用广义化在离线强化学习中

    Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations. (arXiv:2308.03882v1 [cs.LG])

    [http://arxiv.org/abs/2308.03882](http://arxiv.org/abs/2308.03882)

    本文提出了一种利用未见状态增强的策略，在离线强化学习中通过基于价值的扰动和过滤，实现了对离线数据之外的状态的利用和泛化。

    

    离线强化学习方法通过对未见过的状态和动作进行保守价值评估来平衡探索和利用。无模型方法会对所有未见过的动作进行惩罚，而有模型方法可以进一步通过模型展开对未见过的状态进行利用。然而，由于两个因素，这些方法在找到离线数据之外的未见过的状态时存在困难：(a)由于级联模型误差，模型的展开范围非常短，(b)模型展开仅以离线数据中观察到的状态为起点。我们放宽了第二个假设，并提出了一种新颖的未见过状态增强策略，以允许学得的模型和价值估计在未见状态中泛化。我们的策略通过对观察到的状态进行基于价值的扰动来找到未见过的状态，然后通过过滤具有过高的启发性不确定性估计（高误差）或过低的（过于相似）

    Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to
    
[^36]: 模仿复杂轨迹：桥接低层稳定性与高层行为

    Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])

    [http://arxiv.org/abs/2307.14619](http://arxiv.org/abs/2307.14619)

    本文提出了一个理论框架，研究了在非线性动态系统中模仿复杂专家演示的行为。通过稳定模仿策略并确保准确估计演示者分布，可以使模仿者与演示者的轨迹分布相近。

    

    我们提出了一个理论框架来研究在非线性动态系统中模仿随机、非马尔可夫、潜在多模态（即“复杂”）专家演示的行为。我们的框架使用低层控制器（无论是学习的还是隐含的）来稳定围绕专家演示的模仿策略。我们证明，在（a）合适的低层稳定性保证和（b）学习策略的随机连续性属性（我们称之为“总变差连续性”）（TVC）的情况下，一个精确估计演示者状态分布上的行动的模仿者会与演示者对整个轨迹的分布相近。然后，我们证明可以通过将流行的数据增强规则与一种新颖的算法技巧相结合（即在执行时添加增强噪声）来确保TVC并且最小程度上降低精度。我们将我们的保证实例化为由扩散模型参数化的策略，并证明如果学习者准确地估计了演示者的分布，则最终完成这种实例化。

    We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call "total variation continuity" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accuratel
    
[^37]: 模拟反事实情况

    Simulating counterfactuals. (arXiv:2306.15328v1 [stat.ML])

    [http://arxiv.org/abs/2306.15328](http://arxiv.org/abs/2306.15328)

    该论文提出了一种算法，可以模拟反事实分布中的值，可对离散和连续变量设定条件，并应用于信用评分中的公平性分析。

    

    反事实推断考虑了在与实际世界存在一些证据的平行世界中进行的假设性干预。如果证据在流形上指定了条件分布，反事实可能是解析难解的。我们提出了一种算法，用于从反事实分布中模拟值，其中可以对离散和连续变量设定条件。我们表明，所提出的算法可以被呈现为粒子滤波器，从而导致渐近有效的推断。该算法被应用于信用评分中的公平性分析。

    Counterfactual inference considers a hypothetical intervention in a parallel world that shares some evidence with the factual world. If the evidence specifies a conditional distribution on a manifold, counterfactuals may be analytically intractable. We present an algorithm for simulating values from a counterfactual distribution where conditions can be set on both discrete and continuous variables. We show that the proposed algorithm can be presented as a particle filter leading to asymptotically valid inference. The algorithm is applied to fairness analysis in credit scoring.
    
[^38]: 分布式强化学习的好处：小损失边界

    The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning. (arXiv:2305.15703v1 [cs.LG])

    [http://arxiv.org/abs/2305.15703](http://arxiv.org/abs/2305.15703)

    通过小损失边界的视角，我们提供了分布式RL好处的一个解释，该边界与实例相关的最优成本成比例。如果最优成本很小，分布式方法优于非分布式方法。

    

    虽然分布式强化学习已经取得了实证成果，但其何时何地有益的问题尚未得到回答。在这项工作中，通过小损失边界的视角，我们提供了分布式RL好处的一个解释，该边界与实例相关的最优成本成比例。如果最优成本很小，我们的边界会比非分布式方法更强。作为热身，我们展示了学习成本分布会在情境展开（CB）中导致小损失后悔边界，我们发现分布式CB在三个具有挑战性的任务上比最先进的技术在实证上表现更好。对于在线RL，我们提出了一个分布式版本空间算法，该算法使用最大似然估计构建置信区间，并证明了它在表格MDP中实现了小损失后悔，同时在潜变量模型中享有小损失PAC边界。以类似的见解为基础，我们提出了一个分布式离线RL算法

    While distributional reinforcement learning (RL) has demonstrated empirical success, the question of when and why it is beneficial has remained unanswered. In this work, we provide one explanation for the benefits of distributional RL through the lens of small-loss bounds, which scale with the instance-dependent optimal cost. If the optimal cost is small, our bounds are stronger than those from non-distributional approaches. As warmup, we show that learning the cost distribution leads to small-loss regret bounds in contextual bandits (CB), and we find that distributional CB empirically outperforms the state-of-the-art on three challenging tasks. For online RL, we propose a distributional version-space algorithm that constructs confidence sets using maximum likelihood estimation, and we prove that it achieves small-loss regret in the tabular MDPs and enjoys small-loss PAC bounds in latent variable models. Building on similar insights, we propose a distributional offline RL algorithm bas
    
[^39]: 黑盒变分推断收敛性分析

    Black-Box Variational Inference Converges. (arXiv:2305.15349v1 [cs.LG])

    [http://arxiv.org/abs/2305.15349](http://arxiv.org/abs/2305.15349)

    通过对黑盒变分推断（BBVI）的分析，发现一些常见的算法设计选择可能会导致次优收敛速率，但使用带有近端随机梯度下降的BBVI可以实现最强收敛率保证。

    

    我们提供了第一个完整的黑盒变分推断（BBVI）的收敛保证，也称为蒙特卡罗变分推断。尽管早期的研究只针对简化版本的BBVI进行了研究（例如，有界域、有界支持、仅针对尺度进行优化等），但我们的设置不需要任何这样的算法修改。我们的结果适用于对数平滑后验密度，无论是否强对数凹性以及位置-尺度变分族。此外，我们的分析揭示出了一些常见的算法设计选择，特别是变分近似尺度的非线性参数化，可能会导致次优收敛速率。幸运的是，运行带有近端随机梯度下降的BBVI可以纠正这些限制，从而实现已知的最强收敛率保证。我们通过将近端SGD与其他标准的BBVI实现进行比较，验证了这一理论结论在大规模数据集上的有效性。

    We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale
    
[^40]: 面向有条件生成对抗网络的少样本连续学习

    Few-Shot Continual Learning for Conditional Generative Adversarial Networks. (arXiv:2305.11400v1 [cs.LG])

    [http://arxiv.org/abs/2305.11400](http://arxiv.org/abs/2305.11400)

    本文提出了一种新的连续学习方法，适用于条件生成对抗网络，根据cGAN的判别器数据识别出最接近目标的现有模式，并通过扩展连续学习模型，使用回放生成的数据来训练目标模式的cGAN模型，以避免灾难性遗忘，提高了生成性能。

    

    在生成模型的少样本连续学习中，必须学习目标模式，并在不影响先前学习到的模式的情况下仅使用有限的样本。本文针对条件生成对抗网络提出了一种新的连续学习方法，基于一种新的用于生成建模的模式亲和力量度。我们的度量完全基于cGAN的判别器，可以识别最接近目标的现有模式。随后，我们通过包含基于最接近模式的加权标签来扩展连续学习模型。为了预防灾难性遗忘，我们首先使用cGAN的生成器生成带标签的数据样本，然后通过回放生成的数据来训练目标模式的cGAN模型。我们的实验结果证明了我们的方法在提高生成性能方面的有效性，超越了各种标准和最先进的方法。

    In few-shot continual learning for generative models, a target mode must be learned with limited samples without adversely affecting the previously learned modes. In this paper, we propose a new continual learning approach for conditional generative adversarial networks (cGAN) based on a new mode-affinity measure for generative modeling. Our measure is entirely based on the cGAN's discriminator and can identify the existing modes that are most similar to the target. Subsequently, we expand the continual learning model by including the target mode using a weighted label derived from those of the closest modes. To prevent catastrophic forgetting, we first generate labeled data samples using the cGAN's generator, and then train the cGAN model for the target mode while memory replaying with the generated data. Our experimental results demonstrate the efficacy of our approach in improving the generation performance over the baselines and the state-of-the-art approaches for various standard 
    
[^41]: 关于一般函数逼近下的均场强化学习的统计效率

    On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])

    [http://arxiv.org/abs/2305.11283](http://arxiv.org/abs/2305.11283)

    本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。

    

    本文研究了一般函数逼近下的均场控制（MFC）和均场博弈（MFG）中强化学习的统计效率。引入了一种称为Mean-Field Model-Based Eluder Dimension (MBED)的新概念，包含了一系列丰富的均场强化学习问题。此外，我们提出了基于乐观最大似然估计的算法，可以返回一个$\epsilon$优的策略，适用于MFC或$\epsilon$纳什均衡策略适用于MFG，样本复杂度多项式与相关参数无关，与状态、动作和代理数量无关。值得注意的是，我们的结果仅对转移动力学具有Lipschitz连续性的假设，避免了以前的强结构假设。最后，在tabular设置下，假设有一个生成模型，我们建立了一个指数级的下界支持MFC设置，同时提供了一种新颖的样本高效的模型消除算法以逼近最优策略。

    In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
    
[^42]: 二元积分布的多项式时间和纯差分隐私估计器

    A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v1 [cs.DS])

    [http://arxiv.org/abs/2304.06787](http://arxiv.org/abs/2304.06787)

    本论文提出了第一个多项式时间、纯差分隐私估计器，可以在$\{0,1\}^d$上准确估计二元积分布的均值，达到了最优的样本复杂度。

    

    我们提出了第一个ε-差分隐私、计算有效的算法，可以在总变化距离下准确地估计$\{0,1\}^d$上的乘积分布的均值，同时在多项式对数因子内获得了最优的样本复杂度。之前的工作要么在更弱的隐私概念下有效地解决了这个问题，要么在指数级运行时间内最优地解决了这个问题。

    We present the first $\varepsilon$-differentially private, computationally efficient algorithm that estimates the means of product distributions over $\{0,1\}^d$ accurately in total-variation distance, whilst attaining the optimal sample complexity to within polylogarithmic factors. The prior work had either solved this problem efficiently and optimally under weaker notions of privacy, or had solved it optimally while having exponential running times.
    
[^43]: 理解和探索稀疏广义可加模型的整个优秀集合

    Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models. (arXiv:2303.16047v1 [cs.LG])

    [http://arxiv.org/abs/2303.16047](http://arxiv.org/abs/2303.16047)

    提出一种有效而准确地近似稀疏广义可加模型（GAMs）的Rashomon集的技术，并使用这些近似模型来解决实际应用的挑战。

    

    在实际应用中，机器学习模型与领域专家之间的交互至关重要；然而，通常只生成单个模型的经典机器学习范式不利于此类交互。近似和探索Rashomon集，即所有近乎最优模型的集合，通过提供用户可搜索的空间包含多样性模型的方法，解决了这一实际挑战，领域专家可以从中选择。我们提出了一种有效而准确地近似稀疏广义可加模型（GAMs）的Rashomon集的技术。我们提供了用于近似具有固定支持集的GAMs的Rashomon集的椭球形算法，并使用这些椭球形近似了许多不同支持集的Rashomon集。近似的Rashomon集为解决实际挑战，例如（1）研究模型类的变量重要性；（2）在用户指定约束条件下查找模型，提供了重要的基础。

    In real applications, interaction between machine learning model and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present a technique to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models (GAMs). We present algorithms to approximate the Rashomon set of GAMs with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity
    
[^44]: 利用罚函数的深度部分线性Cox模型及其在肺癌患者CT扫描中的应用

    Penalized Deep Partially Linear Cox Models with Application to CT Scans of Lung Cancer Patients. (arXiv:2303.05341v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.05341](http://arxiv.org/abs/2303.05341)

    通过引入罚函数，我们提出了一种创新的深度部分线性Cox模型，用于在肺癌患者的CT扫描中分析死亡风险。该模型能有效地整合已知和新兴的风险因素，解决了参数维度超出样本大小和非参数建模中维度灾难的问题。

    

    肺癌是全球癌症死亡率的主要原因，突出了理解其死亡风险对设计有效的以患者为中心的治疗的重要性。国家肺部筛查试验（NLST）采用了计算机断层扫描纹理分析，提供了CT扫描上纹理模式的客观测量，用于量化肺癌患者的死亡风险。部分线性Cox模型通过将风险函数分解为参数和非参数分量，成为生存分析中备受青睐的方法，可以有效地将已知风险因素（如年龄和临床变量）和新兴风险因素（如图像特征）整合在一个统一的框架中。然而，当参数分量的维度超过样本大小时，模型拟合变得困难，而非参数建模则面临维度灾难的问题。我们提出了一种新颖的罚函数深度部分线性Cox模型（Penali

    Lung cancer is a leading cause of cancer mortality globally, highlighting the importance of understanding its mortality risks to design effective patient-centered therapies. The National Lung Screening Trial (NLST) employed computed tomography texture analysis, which provides objective measurements of texture patterns on CT scans, to quantify the mortality risks of lung cancer patients. Partially linear Cox models have gained popularity for survival analysis by dissecting the hazard function into parametric and nonparametric components, allowing for the effective incorporation of both well-established risk factors (such as age and clinical variables) and emerging risk factors (e.g., image features) within a unified framework. However, when the dimension of parametric components exceeds the sample size, the task of model fitting becomes formidable, while nonparametric modeling grapples with the curse of dimensionality. We propose a novel Penalized Deep Partially Linear Cox Model (Penali
    
[^45]: 具有一般激活函数的深度平衡模型的全局收敛速度

    Global Convergence Rate of Deep Equilibrium Models with General Activations. (arXiv:2302.05797v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.05797](http://arxiv.org/abs/2302.05797)

    该论文研究了具有一般激活函数的深度平衡模型（DEQ）的全局收敛速度，证明了梯度下降以线性收敛速度收敛到全局最优解，并解决了限制平衡点Gram矩阵最小特征值的挑战。

    

    在最近的一篇论文中，Ling等人研究了具有ReLU激活函数的过参数化深度平衡模型（DEQ）。他们证明了对于二次损失函数，梯度下降方法以线性收敛速度收敛到全局最优解。本文表明，对于具有任何具有有界一阶和二阶导数的激活函数的DEQ，该事实仍然成立。由于新的激活函数通常是非线性的，限制平衡点的Gram矩阵的最小特征值尤其具有挑战性。为了完成这个任务，我们需要创建一个新的总体Gram矩阵，并开发一种具有Hermite多项式展开的新形式的双重激活函数。

    In a recent paper, Ling et al. investigated the over-parametrized Deep Equilibrium Model (DEQ) with ReLU activation. They proved that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. This paper shows that this fact still holds for DEQs with any general activation that has bounded first and second derivatives. Since the new activation function is generally non-linear, bounding the least eigenvalue of the Gram matrix of the equilibrium point is particularly challenging. To accomplish this task, we need to create a novel population Gram matrix and develop a new form of dual activation with Hermite polynomial expansion.
    
[^46]: 基于弱相关随机过程的亚渐近极大值的高维变量聚类

    High-dimensional variable clustering based on sub-asymptotic maxima of a weakly dependent random process. (arXiv:2302.00934v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2302.00934](http://arxiv.org/abs/2302.00934)

    我们提出了一种基于亚渐近极大值的高维变量聚类模型，该模型利用群集间多变量随机过程的极大值的独立性定义种群水平的群集，我们还开发了一种无需预先指定群集数量的算法来恢复变量的群集。该算法在特定条件下能够有效地识别数据中的群集，并能够以多项式复杂度进行计算。我们的工作对于理解依赖过程的块最大值的非参数学习有重要意义，并且在神经科学领域有着应用潜力。

    

    我们提出了一种新的变量聚类模型，称为渐近独立块 (AI-block) 模型，该模型基于群集间多变量平稳混合随机过程的极大值的独立性来定义种群水平的群集。该模型类是可识别的，意味着存在一种偏序关系，允许进行统计推断。我们还提出了一种算法，无需事先指定群集的数量即可恢复变量的群集。我们的工作提供了一些理论洞察，证明了在某些条件下，我们的算法能够在计算复杂性在维度中是多项式的情况下有效地识别数据中的群集。这意味着可以非参数地学习出仅仅是亚渐近的依赖过程的块最大值的群组。为了进一步说明我们的工作的重要性，我们将我们的方法应用于神经科学数据集。

    We propose a new class of models for variable clustering called Asymptotic Independent block (AI-block) models, which defines population-level clusters based on the independence of the maxima of a multivariate stationary mixing random process among clusters. This class of models is identifiable, meaning that there exists a maximal element with a partial order between partitions, allowing for statistical inference. We also present an algorithm for recovering the clusters of variables without specifying the number of clusters \emph{a priori}. Our work provides some theoretical insights into the consistency of our algorithm, demonstrating that under certain conditions it can effectively identify clusters in the data with a computational complexity that is polynomial in the dimension. This implies that groups can be learned nonparametrically in which block maxima of a dependent process are only sub-asymptotic. To further illustrate the significance of our work, we applied our method to neu
    
[^47]: 随机块坐标乐观梯度算法解决根查找问题

    Randomized Block-Coordinate Optimistic Gradient Algorithms for Root-Finding Problems. (arXiv:2301.03113v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2301.03113](http://arxiv.org/abs/2301.03113)

    本文提出了两种新的随机乐观梯度算法来解决大规模情况下的根查找问题。第一种算法在底层算子满足一定条件时可以达到较好的收敛速度，第二种算法是一种加速算法，可以更快地收敛。算法的收敛性和解的存在性也得到了证明。

    

    本文提出了两种新的随机块坐标乐观梯度算法，用于在大规模情况下近似求解非线性方程，也称为根查找问题。第一种算法使用恒定的步长，非加速算法，在底层算子G满足Lipschitz连续性和弱Minty解条件时，它在数学期望E[||Gx^k||^2]上达到O(1/k)的最优迭代收敛速度，其中E[·]表示期望，k为迭代计数器。第二种方法是一种新的加速随机块坐标乐观梯度算法，在G的夹逼性条件下，该算法在E[||Gx^k||^2]和E[||x^{k+1} x^{k}||^2]上分别达到O(1/k^2)和o(1/k^2)的迭代收敛速度。此外，我们证明迭代序列{x^k}几乎必然收敛到一个解，以及在此解处Gx^k的模的平方在...

    In this paper, we develop two new randomized block-coordinate optimistic gradient algorithms to approximate a solution of nonlinear equations in large-scale settings, which are called root-finding problems. Our first algorithm is non-accelerated with constant stepsizes, and achieves $\mathcal{O}(1/k)$ best-iterate convergence rate on $\mathbb{E}[ \Vert Gx^k\Vert^2]$ when the underlying operator $G$ is Lipschitz continuous and satisfies a weak Minty solution condition, where $\mathbb{E}[\cdot]$ is the expectation and $k$ is the iteration counter. Our second method is a new accelerated randomized block-coordinate optimistic gradient algorithm. We establish both $\mathcal{O}(1/k^2)$ and $o(1/k^2)$ last-iterate convergence rates on both $\mathbb{E}[ \Vert Gx^k\Vert^2]$ and $\mathbb{E}[ \Vert x^{k+1} x^{k}\Vert^2]$ for this algorithm under the co-coerciveness of $G$. In addition, we prove that the iterate sequence $\{x^k\}$ converges to a solution almost surely, and $\Vert Gx^k\Vert^2$ at
    
[^48]: REPAIR: 修复插值的归一化置换激活

    REPAIR: REnormalizing Permuted Activations for Interpolation Repair. (arXiv:2211.08403v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.08403](http://arxiv.org/abs/2211.08403)

    作者发现仅使用神经元对齐方法不能有效解决线性插值中激活方差坍缩的问题，因此提出了REPAIR方法来修复插值的归一化置换激活。实验证明，在各种架构中将REPAIR与神经元对齐方法结合使用可以大幅降低障碍。

    

    本文探讨了Entezari等人（2021）的猜想，即如果考虑神经网络的置换不变性，那么线性插值之间可能没有损失障碍。首先，我们观察到仅使用神经元对齐方法无法建立低障碍线性连接的原因是一种我们称之为方差坍缩的现象：插值深层网络的激活方差崩溃，导致性能较差。其次，我们提出了REPAIR（修复插值的归一化置换激活）方法，通过重新缩放这些插值网络的预激活来缓解方差崩溃。我们探讨了我们方法与归一化层、网络宽度和深度选择之间的相互作用，并演示了在各种架构族中使用REPAIR作为神经元对齐方法的扩展，可以将障碍降低60%至100%。

    In this paper we look into the conjecture of Entezari et al. (2021) which states that if the permutation invariance of neural networks is taken into account, then there is likely no loss barrier to the linear interpolation between SGD solutions. First, we observe that neuron alignment methods alone are insufficient to establish low-barrier linear connectivity between SGD solutions due to a phenomenon we call variance collapse: interpolated deep networks suffer a collapse in the variance of their activations, causing poor performance. Next, we propose REPAIR (REnormalizing Permuted Activations for Interpolation Repair) which mitigates variance collapse by rescaling the preactivations of such interpolated networks. We explore the interaction between our method and the choice of normalization layer, network width, and depth, and demonstrate that using REPAIR on top of neuron alignment methods leads to 60%-100% relative barrier reduction across a wide variety of architecture families and t
    
[^49]: p$^3$VAE：一个物理集成的生成模型，应用于光学遥感图像的语义分割

    p$^3$VAE: a physics-integrated generative model. Application to the semantic segmentation of optical remote sensing images. (arXiv:2210.10418v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10418](http://arxiv.org/abs/2210.10418)

    本文介绍了p$^3$VAE生成模型，它将一个完美的物理模型集成到模型中，并应用于高分辨率高光谱遥感图像的语义分割。模型具有更好的外推能力和可解释性，同时具有高度解缕能力。

    

    将机器学习模型与物理模型相结合是学习强大数据表示的最新研究方向。本文介绍了p$^3$VAE，这是一个生成模型，它集成了一个完美的物理模型，部分解释了数据中真实的变化因素。为了充分利用我们的混合设计，我们提出了一种半监督优化过程和一种推断方案，同时伴随着有意义的不确定性估计。我们将p$^3$VAE应用于高分辨率高光谱遥感图像的语义分割。我们在一个模拟数据集上的实验表明，与传统的机器学习模型相比，我们的混合模型具有更好的外推能力和可解释性。特别是，我们展示了p$^3$VAE自然具有高度解缕能力。我们的代码和数据已在https://github.com/Romain3Ch216/p3VAE上公开发布。

    The combination of machine learning models with physical models is a recent research path to learn robust data representations. In this paper, we introduce p$^3$VAE, a generative model that integrates a perfect physical model which partially explains the true underlying factors of variation in the data. To fully leverage our hybrid design, we propose a semi-supervised optimization procedure and an inference scheme that comes along meaningful uncertainty estimates. We apply p$^3$VAE to the semantic segmentation of high-resolution hyperspectral remote sensing images. Our experiments on a simulated data set demonstrated the benefits of our hybrid model against conventional machine learning models in terms of extrapolation capabilities and interpretability. In particular, we show that p$^3$VAE naturally has high disentanglement capabilities. Our code and data have been made publicly available at https://github.com/Romain3Ch216/p3VAE.
    
[^50]: 欺诈数据集基准和应用

    Fraud Dataset Benchmark and Applications. (arXiv:2208.14417v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.14417](http://arxiv.org/abs/2208.14417)

    欺诈数据集基准（FDB）是一个针对欺诈检测的公开可用数据集的汇编，涵盖了各种欺诈相关任务，为解决欺诈检测中的独特挑战提供了标准化的数据集和基准。 (arXiv:2208.14417v3 [cs.LG] UPDATED)

    

    标准化的数据集和基准已经在计算机视觉、自然语言处理、多模态和表格设置方面推动了创新。我们发现，与其他研究领域相比，欺诈检测面临着独特的挑战：高级别的不平衡、多样化的特征类型、频繁变化的欺诈模式和问题的对抗性。由于这些挑战，对其他研究领域的数据集评估的建模方法可能对欺诈检测效果不佳。在本文中，我们介绍了欺诈数据集基准（FDB），它是一个针对欺诈检测的公开可用数据集的汇编，涵盖了各种欺诈相关任务，包括识别无卡交易、检测机器人攻击、分类恶意URL、估计贷款违约风险和内容审核等。基于Python的FDB库提供了一致的API用于数据加载和标准化的训练和测试集划分。我们演示了几种应用场景。

    Standardized datasets and benchmarks have spurred innovations in computer vision, natural language processing, multi-modal and tabular settings. We note that, as compared to other well researched fields, fraud detection has unique challenges: high-class imbalance, diverse feature types, frequently changing fraud patterns, and adversarial nature of the problem. Due to these, the modeling approaches evaluated on datasets from other research fields may not work well for the fraud detection. In this paper, we introduce Fraud Dataset Benchmark (FDB), a compilation of publicly available datasets catered to fraud detection FDB comprises variety of fraud related tasks, ranging from identifying fraudulent card-not-present transactions, detecting bot attacks, classifying malicious URLs, estimating risk of loan default to content moderation. The Python based library for FDB provides a consistent API for data loading with standardized training and testing splits. We demonstrate several application
    
[^51]: 高维度下颗粒工具变量的推断理论

    Inferential Theory for Granular Instrumental Variables in High Dimensions. (arXiv:2201.06605v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2201.06605](http://arxiv.org/abs/2201.06605)

    本文扩展了颗粒工具变量（GIV）方法，包括在大维度下的识别过程，处理未知的因子和加载，以及通过额外构建的工具变量过度识别结构参数，从而提高效率。

    

    颗粒工具变量（GIV）方法利用具有因子误差结构的面板数据构建工具变量，以估计即使在控制潜在因子后仍存在内生性的结构时间序列模型。我们在多个维度上扩展了GIV方法。首先，我们将识别过程扩展到大$N$和大$T$的框架中，这取决于$N$个截面单位规模分布的渐近Herfindahl指数。其次，我们将因子和加载视为未知，并且在考虑结构参数的极限分布时，证明了估计工具变量和因子的抽样误差可以忽略不计。第三，我们证明了在估计算法中高维度精度矩阵的抽样误差可以忽略不计。第四，我们通过额外构建的工具变量过度识别结构参数，从而实现效率的提高。提供蒙特卡洛证据来支持我们的渐近理论。

    The Granular Instrumental Variables (GIV) methodology exploits panels with factor error structures to construct instruments to estimate structural time series models with endogeneity even after controlling for latent factors. We extend the GIV methodology in several dimensions. First, we extend the identification procedure to a large $N$ and large $T$ framework, which depends on the asymptotic Herfindahl index of the size distribution of $N$ cross-sectional units. Second, we treat both the factors and loadings as unknown and show that the sampling error in the estimated instrument and factors is negligible when considering the limiting distribution of the structural parameters. Third, we show that the sampling error in the high-dimensional precision matrix is negligible in our estimation algorithm. Fourth, we overidentify the structural parameters with additional constructed instruments, which leads to efficiency gains. Monte Carlo evidence is presented to support our asymptotic theory
    
[^52]: 关于机器辅助人类决策的公正性研究

    On the Fairness of Machine-Assisted Human Decisions. (arXiv:2110.15310v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2110.15310](http://arxiv.org/abs/2110.15310)

    本研究通过形式模型和实验室实验考察了机器预测的性质如何影响人类最终决策。实验发现，包含有偏见的人类决策者可能逆转算法结构与决策质量之间的关系，并且排除受保护群体信息可能无法减少差异甚至可能增加差异。

    

    当机器学习算法在高风险决策中被使用时，我们希望确保它们的部署能够产生公平和公正的结果。这个关注点促使了一个迅速增长的文献，专注于诊断和解决机器预测中的差异性。然而，许多机器预测被部署来协助人类决策者保留最终决策权。因此，在本文中，我们在一个形式模型和实验室实验中考虑了机器预测的性质如何影响最终的人类决策。在我们的统计决策形式模型中，我们展示了包含一个有偏见的人类决策者可能逆转算法结构与最终决策质量之间的常规关系。具体地，我们记录了从预测中排除受保护群体信息可能无法减少甚至可能增加最终差异的情况。在实验室实验中，我们展示了如何...

    When machine-learning algorithms are used in high-stakes decisions, we want to ensure that their deployment leads to fair and equitable outcomes. This concern has motivated a fast-growing literature that focuses on diagnosing and addressing disparities in machine predictions. However, many machine predictions are deployed to assist in decisions where a human decision-maker retains the ultimate decision authority. In this article, we therefore consider in a formal model and in a lab experiment how properties of machine predictions affect the resulting human decisions. In our formal model of statistical decision-making, we show that the inclusion of a biased human decision-maker can revert common relationships between the structure of the algorithm and the qualities of resulting decisions. Specifically, we document that excluding information about protected groups from the prediction may fail to reduce, and may even increase, ultimate disparities. In the lab experiment, we demonstrate ho
    
[^53]: 基于脑力风暴的生成对抗网络（BGAN）：面向具有分布式私有数据集的多代理生成模型

    Brainstorming Generative Adversarial Networks (BGANs): Towards Multi-Agent Generative Models with Distributed Private Datasets. (arXiv:2002.00306v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2002.00306](http://arxiv.org/abs/2002.00306)

    提出了一种新颖的脑力风暴生成对抗网络（BGAN）架构，实现多个代理在完全分布式的方式下生成类似真实数据的样本，解决了多个代理共享有限且分布式数据集的问题。

    

    要实现高学习准确性，生成对抗网络（GANs）必须以充分代表数据空间的大型数据集作为输入。然而，在许多情况下，可用的数据集可能是有限的，并且分布在多个代理之间，每个代理都试图单独学习数据的分布。在这种情况下，代理通常不愿共享他们的本地数据，因为这可能导致大型数据集的通信开销。本文提出了一种新颖的脑力风暴生成对抗网络（BGAN）架构，用于解决这个多代理GAN问题，多个代理可以在完全分布式的方式下生成类似真实数据的样本。BGAN允许代理通过共享生成的数据样本而不是实际数据集进行“脑力风暴”来获取来自其他代理的信息。与现有的分布式GAN解决方案相比，所提出的BGAN架构被设计为完全分布式，并且不需要参与方彼此通信。

    To achieve a high learning accuracy, generative adversarial networks (GANs) must be fed by large datasets that adequately represent the data space. However, in many scenarios, the available datasets may be limited and distributed across multiple agents, each of which is seeking to learn the distribution of the data on its own. In such scenarios, the agents often do not wish to share their local data as it can cause communication overhead for large datasets. In this paper, to address this multi-agent GAN problem, a novel brainstorming GAN (BGAN) architecture is proposed using which multiple agents can generate real-like data samples while operating in a fully distributed manner. BGAN allows the agents to gain information from other agents without sharing their real datasets but by ``brainstorming'' via the sharing of their generated data samples. In contrast to existing distributed GAN solutions, the proposed BGAN architecture is designed to be fully distributed, and it does not need an
    

