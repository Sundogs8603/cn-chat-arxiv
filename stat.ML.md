# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Graph topological property recovery with heat and wave dynamics-based features on graphsD.](http://arxiv.org/abs/2309.09924) | 本文提出了一种名为图微分方程网络（GDeNet）的方法，利用热和波动方程动力学特征来恢复图的拓扑属性，能够在各种下游任务中获得优秀的表现，同时在实际应用中也展现了较好的性能。 |
| [^2] | [Learning Nonparametric High-Dimensional Generative Models: The Empirical-Beta-Copula Autoencoder.](http://arxiv.org/abs/2309.09916) | 该研究讨论了通过将自动编码器的潜在空间建模为一个可以获取样本的分布，从而将任何自动编码器转化为生成模型的技术。其中，研究了一种新的基于Copula的方法：经验Beta Copula自动编码器。这些结果对于捕捉高维数据的特征表示具有重要的意义。 |
| [^3] | [Walking fingerprinting.](http://arxiv.org/abs/2309.09897) | 本文研究了使用步态加速度数据进行个体身份预测的问题，提出了一种新颖的多元函数回归模型，避免了将预测器空间分成单元格，并进行了两个数据集的预测方法比较。 |
| [^4] | [Context $\approx$ Environment.](http://arxiv.org/abs/2309.09888) | 在这篇论文中，作者通过理论与实验证明了将注意力放在上下文-未标记样本上，可以实现更好的领域泛化。 |
| [^5] | [Error Reduction from Stacked Regressions.](http://arxiv.org/abs/2309.09880) | 本文提出了一种新的堆叠回归方法，通过最小化总体风险并受非负性约束，成功降低了误差。实验证明，堆叠估计器相比其中最佳的单个估计器具有更小的总体风险。 |
| [^6] | [Pivotal Estimation of Linear Discriminant Analysis in High Dimensions.](http://arxiv.org/abs/2309.09831) | PANDA是一种高维线性判别分析方法，对调参数需求小且达到最优收敛速率，与现有方法相比，其性能相当或更好，并且需要较少的参数调整工作。 |
| [^7] | [Convolutional Deep Kernel Machines.](http://arxiv.org/abs/2309.09814) | 这项研究介绍了一种称为卷积深度核机器的新型核方法，该方法纯粹使用核而不使用特征，通过高效的跨域诱导点近似方案和多种模型变体的设计，达到了在MNIST、CIFAR-10和CIFAR-100上接近甚至超过其他方法的测试准确率。 |
| [^8] | [Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss with Imbalanced Data.](http://arxiv.org/abs/2309.09725) | 在无约束特征模型的背景下，我们研究了交叉熵损失函数下不均衡数据的神经塌缩现象。 |
| [^9] | [New Bounds on the Accuracy of Majority Voting for Multi-Class Classification.](http://arxiv.org/abs/2309.09564) | 本论文研究了多数投票在多类别分类问题中的准确性，并推导出了新的准确性上界。研究发现，在满足一定条件的情况下，随着独立投票人数量的增加，多数投票函数的错误率将以指数方式趋向于零，否则将以指数方式增长。 |
| [^10] | [Multi-dimensional domain generalization with low-rank structures.](http://arxiv.org/abs/2309.09555) | 这项工作提出了一种新颖的方法来应对在健康相关研究中少数族群在训练数据中被忽视而导致的统计推断问题。通过将模型参数组织成张量，并研究结构化张量补全问题，我们实现了对具有有限或无可用数据的亚群体的鲁棒领域泛化，该方法利用了组标签的结构，可以产生更可靠和可解释的泛化结果。 |
| [^11] | [Exploring and Learning in Sparse Linear MDPs without Computationally Intractable Oracles.](http://arxiv.org/abs/2309.09457) | 本文研究了在稀疏线性MDP中探索和学习的问题，通过特征选择提出了一个多项式时间算法，以在与环境的交互中学习出近似最优策略。 |
| [^12] | [On the Use of the Kantorovich-Rubinstein Distance for Dimensionality Reduction.](http://arxiv.org/abs/2309.09442) | 这项研究研究了使用康托罗维奇-鲁宾斯坦距离来构建样本复杂性描述子，在分类问题中能够得出存在一个1-立切分类器的结论，并讨论了该距离的局限性。 |
| [^13] | [Mitigating Over-Smoothing and Over-Squashing using Augmentations of Forman-Ricci Curvature.](http://arxiv.org/abs/2309.09384) | 本文提出了一种使用Forman-Ricci曲率扩展的方法来减轻图神经网络中的过度平滑和过度压缩问题。通过观察离散曲率，可以添加或删除边以减轻这两种效应。 |
| [^14] | [Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets.](http://arxiv.org/abs/2309.09258) | 本文首次证明了在深度为2的神经网络上，适当正则化的逻辑回归代价函数通过随机梯度下降（SGD）能够收敛到全局极小值，这适用于任意数据和具有充分平滑且有界激活函数。同时，我们还证明了连续时间SGD的指数级快速收敛速度，该结果也适用于光滑无界的激活函数。 |
| [^15] | [Globally Convergent Accelerated Algorithms for Multilinear Sparse Logistic Regression with $\ell_0$-constraints.](http://arxiv.org/abs/2309.09239) | 本文提出了一种解决具有$\ell_0$约束的多线性稀疏逻辑回归模型的全局收敛加速算法。通过利用低秩张量分解的结构信息减少参数数量，该算法能够有效地进行特征选择和分析多维数据。该算法使用加速次梯度交替线性化最小化与自适应动量的方法来解决非凸和非光滑问题，并提供了收敛保证。 |
| [^16] | [Double Normalizing Flows: Flexible Bayesian Gaussian Process ODEs Learning.](http://arxiv.org/abs/2309.09222) | 这项研究将标准化流引入高斯过程常微分方程(ODE)模型，使其具备更灵活和表达性强的先验分布和非高斯的后验推断，从而提高了贝叶斯高斯过程ODE的准确性和不确定性估计。 |
| [^17] | [MFRL-BI: Design of a Model-free Reinforcement Learning Process Control Scheme by Using Bayesian Inference.](http://arxiv.org/abs/2309.09205) | 本论文提出了一种无模型强化学习（MFRL）方法来进行实时数据驱动的制造过程控制优化，通过使用贝叶斯推理来减少制造过程中扰动的大幅度变化。实验证明在未知过程模型的情况下，提出的MFRL控制器在非线性化学机械抛光（CMP）过程中表现良好。 |
| [^18] | [On the Connection Between Riemann Hypothesis and a Special Class of Neural Networks.](http://arxiv.org/abs/2309.09171) | 黎曼猜想是数学领域中一个历史悠久的未解问题，它假设黎曼函数的非平凡零点的实部均等于1/2。本文重新审视和扩展了一种旧分析准则，将黎曼猜想与涉及特殊类别神经网络的最小化问题联系起来。 |
| [^19] | [$L^1$ Estimation: On the Optimality of Linear Estimators.](http://arxiv.org/abs/2309.09129) | 该论文研究了在$L^1$保真度条件下，从噪声观测中估计随机变量$X$的问题。结果表明，唯一能够引入线性条件中位数的先验分布是高斯分布。此外，还研究了其他$L^p$损失，并观察到对于$p \in [1,2]$，高斯分布是唯一引入线性最优贝叶斯估计器的先验分布。扩展还涵盖了特定指数族条件分布的噪声模型。 |
| [^20] | [Reducing sequential change detection to sequential estimation.](http://arxiv.org/abs/2309.09111) | 这个论文将顺序变化检测简化为顺序估计，通过使用置信序列来检测数据流中的变化，并证明了该方法具有强大的保证。 |
| [^21] | [Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors.](http://arxiv.org/abs/2309.09032) | 本论文提出了一个方法，通过使用稀疏或生成的先验知识，解决了从全秩矩阵的二次系统中恢复信号的问题。其中，通过引入阈值Wirtinger流算法（TWF）来处理稀疏信号，并使用谱初始化和阈值梯度下降方法，在高维情况下实现了较小的测量数量。 |
| [^22] | [Data-driven Reachability using Christoffel Functions and Conformal Prediction.](http://arxiv.org/abs/2309.08976) | 这篇论文介绍了一种使用克里斯托费尔函数和共形预测进行数据驱动的可达性分析方法，能够有效估计复杂系统的可达集合，而不依赖于已知的数学模型。 |
| [^23] | [Fast Approximation of the Shapley Values Based on Order-of-Addition Experimental Designs.](http://arxiv.org/abs/2309.08923) | 该论文提出了一种基于加法顺序实验设计的方法，可以快速近似计算Shapley值。这解决了在计算Shapley值时的高计算负担问题。 |
| [^24] | [Efficient Methods for Non-stationary Online Learning.](http://arxiv.org/abs/2309.08911) | 这项工作提出了一种针对非平稳在线学习的高效方法，通过降低每轮投影的数量来优化动态遗憾和自适应遗憾的计算复杂性。 |
| [^25] | [Learning Linearized Models from Nonlinear Systems with Finite Data.](http://arxiv.org/abs/2309.08805) | 本论文提出了一种从有限数据的非线性系统中学习线性化模型的方法，并提供了有限样本误差界。误差界展示了非线性误差和噪声误差之间的权衡，表明在有足够多的样本时，可以学习到具有任意小误差的线性化动力学。 |
| [^26] | [Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm.](http://arxiv.org/abs/2309.08783) | 本文提出了一种解决高维度稀疏线性回归中异方差问题的方法，通过基于分区经验贝叶斯ECM算法的异方差高维度线性回归模型来实现。这个模型可以处理残差方差不恒定的情况，并且可以使用插值的经验贝叶斯估计超参数来灵活地调整方差模型。 |
| [^27] | [Clustered Multi-Agent Linear Bandits.](http://arxiv.org/abs/2309.08710) | 本文研究了集群化的多智能体线性赌博机问题，提出了一种新颖的算法，通过智能体之间的协作来加速优化问题。通过理论分析和实证评估，证明了算法在遗憾最小化和聚类质量上的有效性。 |
| [^28] | [Price of Safety in Linear Best Arm Identification.](http://arxiv.org/abs/2309.08709) | 该论文提出了一种具有线性反馈的安全最优臂识别框架，该框架通过利用线性结构来保证在每一轮中不违反阶段性安全约束，提出了一种基于间隙的算法来实现有意义的样本复杂性，并通过实验证明了算法的有效性。 |
| [^29] | [Doubly High-Dimensional Contextual Bandits: An Interpretable Model for Joint Assortment-Pricing.](http://arxiv.org/abs/2309.08634) | 本论文提出了一种双高维上下文强化学习算法，用于解决联合组合-定价问题，通过简单而灵活的模型捕捉协变量和行为之间的相互作用，同时保持可解释性。该方法兼容多种结构化的线性强化学习和定价模型，提供了一种计算可行的流程。 |
| [^30] | [The Curse of Memory in Stochastic Approximation: Extended Version.](http://arxiv.org/abs/2309.02944) | 本文研究了随机逼近中的记忆诅咒问题，并探讨了在不同情况下的结果。在具有几何遍历马尔可夫扰动的情况下，目标偏差一般非零。此外，当参数估计使用平均法时，估计值收敛到渐近无偏，且具有近似最优的渐近协方差。 |
| [^31] | [Tropical Geometric Tools for Machine Learning: the TML package.](http://arxiv.org/abs/2309.01082) | TML软件包是第一个包含一套全面工具和方法的R软件包，用于处理与热带凸性相关的基本计算和可视化，以及使用热带度量进行监督和无监督学习模型的统计推断。 |
| [^32] | [Exploration of Rashomon Set Assists Explanations for Medical Data.](http://arxiv.org/abs/2308.11446) | 本文提出了一种新的过程来探索和分析医疗数据中的拉舒蒙集合模型，从而超越传统单一模型选择的方法，并通过引入"拉舒蒙检测"算法识别出集合中最不同的模型。 |
| [^33] | [Dyadic Reinforcement Learning.](http://arxiv.org/abs/2308.07843) | 该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。 |
| [^34] | [Nonlinear Permuted Granger Causality.](http://arxiv.org/abs/2308.06220) | 这项研究提出了一种处理非线性数据的格兰杰因果性方法，通过在特征提取过程中使用人工神经网络，利用置换来度量功能连接性，并实现了每个置换的方差的一致估计。在与其他技术的比较中，该方法表现出良好的性能。 |
| [^35] | [Change Point Detection With Conceptors.](http://arxiv.org/abs/2308.06213) | 我们提出了一种使用概念器矩阵进行变点检测的方法，通过学习时间序列中的特征动态，并利用单变量量化来识别变点。该方法在条件和无条件的变点检测问题上进行了测试，可以提供潜在的需要进一步研究的感兴趣位置。 |
| [^36] | [RED CoMETS: An ensemble classifier for symbolically represented multivariate time series.](http://arxiv.org/abs/2307.13679) | 本文介绍了一种名为RED CoMETS的集成分类器，用于处理符号化表示的多变量时间序列数据。它在多变量设置中展现出竞争力的准确性，并在'HandMovementDirection'数据集上实现了最高的报告准确性。 |
| [^37] | [Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics.](http://arxiv.org/abs/2304.14094) | 本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。 |
| [^38] | [counterfactuals: An R Package for Counterfactual Explanation Methods.](http://arxiv.org/abs/2304.06569) | 该论文介绍了一个统一且模块化的 R6 接口，用于具体实现反事实解释方法。通过实现三种方法并推广到不同的情境中，结合真实用例，此方法能够快速准确地得出有关如何更改单个观测值的特征值以获得所需预测的信息。 |
| [^39] | [Combinatorial Causal Bandits without Graph Skeleton.](http://arxiv.org/abs/2301.13392) | 本文研究了在二值一般因果模型和BGLMs上不考虑图骨架的组合因果赌博机问题，提出了可在BGLMs上实现的无需图骨架的遗憾最小化算法，达到了与依赖于图结构的最先进算法相同的渐进遗憾率$O(\sqrt{T}\ln T)$。 |
| [^40] | [The Projected Covariance Measure for assumption-lean variable significance testing.](http://arxiv.org/abs/2211.02039) | 该论文介绍了一种假设简约的变量重要性检验方法，利用非参数或机器学习方法实现稳健的误差控制和高功效。 |
| [^41] | [Differential Privacy has Bounded Impact on Fairness in Classification.](http://arxiv.org/abs/2210.16242) | 本文理论上研究了差分隐私对分类公平性的影响。证明了在给定模型类的情况下，流行的群体公平度量是关于模型参数点值利普希茨连续的。非渐近界限表明，随着样本数量的增加，私有模型的公平度越来越接近于非私有模型的公平度，也突显了模型的置信边界对差分隐私的不对等影响的重要性。 |
| [^42] | [Mean-field neural networks: learning mappings on Wasserstein space.](http://arxiv.org/abs/2210.15179) | 本文研究了均场神经网络在学习概率测度的Wasserstein空间和函数空间之间的映射中的应用。提出了两类神经网络，通过通用逼近定理理论支持，并通过数值实验展示了其准确性和效率。此外，还提出了依赖于均场神经网络的算法来解决时间相关的均场问题。 |
| [^43] | [TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second.](http://arxiv.org/abs/2207.01848) | TabPFN是一种可以在不到一秒钟内完成小型表格数据集的监督分类的Transformer，无需超参数调整，并且具有竞争力。它使用先验适应网络（PFN）逼近基于先验的贝叶斯推断，先验融合了因果推理的思想。 |
| [^44] | [Sum-of-Squares Relaxations for Information Theory and Variational Inference.](http://arxiv.org/abs/2206.13285) | 本论文研究了基于平方和松弛方法在信息论和变分推断中的应用。通过使用这种方法，我们提出了计算$f$-divergences的凸松弛算法，其中涉及到从非局部协方差矩阵计算这些divergences的问题。这些结果对于数据科学中的多个应用具有重要意义。 |
| [^45] | [Multiple Testing Framework for Out-of-Distribution Detection.](http://arxiv.org/abs/2206.09522) | 本研究提出了一个多重检验框架用于离群分布检测的问题，包括了定义OOD概念和提供强有力保证的方法，与之前的基于阈值的测试相比，在不同类型的OOD实例中表现更一致。 |
| [^46] | [Addressing Strategic Manipulation Disparities in Fair Classification.](http://arxiv.org/abs/2205.10842) | 该论文研究了公平分类中存在的战略操纵差异问题，提出了一个受约束的优化框架来解决这个问题。 |
| [^47] | [Optimal Learning Rates for Regularized Least-Squares with a Fourier Capacity Condition.](http://arxiv.org/abs/2204.07856) | 本论文研究了具有傅立叶容量条件的正则化最小二乘问题的最优学习率，通过插值理论和新的傅立叶等容性条件，我们推导出了广泛类别的Tikhonov正则化学习问题的最小化自适应率，不需要回归函数包含在假设集中。 |
| [^48] | [When AUC meets DRO: Optimizing Partial AUC for Deep Learning with Non-Convex Convergence Guarantee.](http://arxiv.org/abs/2203.00176) | 本文提出了一种基于梯度的方法，通过分布鲁棒优化（DRO）来最大化深度学习中的局部AUC（pAUC），并提出了准确和平滑的pAUC估计量。实验证明了该方法在各种数据集上的有效性。 |
| [^49] | [Adaptive and Robust Multi-Task Learning.](http://arxiv.org/abs/2202.05250) | 本文提出一系列自适应方法，能够同时处理多任务学习的相似性和差异性，并具有统计保证和鲁棒性。 |
| [^50] | [A Class of Dimension-free Metrics for the Convergence of Empirical Measures.](http://arxiv.org/abs/2104.12036) | 本文提出了一类无维度度量，用于高维情况下经验测度的收敛性，解决了维度灾难问题，具有重要的实际应用。 |
| [^51] | [A General Framework for the Practical Disintegration of PAC-Bayesian Bounds.](http://arxiv.org/abs/2102.08649) | 该论文提出了一种新的PAC-Bayesian泛化界的框架，该框架能够提供解离界，相比现有框架在神经网络上有显著的实用改进。 |
| [^52] | [Lazy OCO: Online Convex Optimization on a Switching Budget.](http://arxiv.org/abs/2102.03803) | 本研究提出了一种懒惰型在线凸优化的算法，其在切换次数有限的情况下达到了近似最优的遗憾上界，并且在连续设置中呈现出高效的计算性能。 |
| [^53] | [Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds Globally Optimal Policy.](http://arxiv.org/abs/2012.14098) | 本文首次尝试在平均奖励设置下，通过方差风险准则研究风险敏感的深度强化学习。我们提出了一个方差约束的策略优化问题，并设计了一种演员-评论家算法来解决该问题。 |
| [^54] | [Advanced Capsule Networks via Context Awareness.](http://arxiv.org/abs/1903.07497) | 本研究通过增加池化层和重建层来改进胶囊网络（CN）的设计，以适应具有不同上下文的图像数据集，并与深度学习（DL）模型进行了性能对比。结果显示，CN在大大减少训练时间的同时表现出了与DL模型相当的性能。 |

# 详细

[^1]: 基于热和波动动力学特征的图拓扑属性恢复

    Graph topological property recovery with heat and wave dynamics-based features on graphsD. (arXiv:2309.09924v1 [cs.LG])

    [http://arxiv.org/abs/2309.09924](http://arxiv.org/abs/2309.09924)

    本文提出了一种名为图微分方程网络（GDeNet）的方法，利用热和波动方程动力学特征来恢复图的拓扑属性，能够在各种下游任务中获得优秀的表现，同时在实际应用中也展现了较好的性能。

    

    本文提出了一种名为图微分方程网络（GDeNet）的方法，利用图上的PDE解的表达能力，为各种下游任务获得连续的节点和图级表示。我们推导出了热和波动方程动力学与图的谱特性以及连续时间随机游走在图上行为之间的理论结果。我们通过恢复随机图生成参数、Ricci曲率和持久同调等方式实验证明了这些动力学能够捕捉到图形几何和拓扑的显著方面。此外，我们还展示了GDeNet在包括引用图、药物分子和蛋白质在内的真实世界数据集上的优越性能。

    In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.
    
[^2]: 学习非参数高维生成模型：经验Beta Copula自动编码器

    Learning Nonparametric High-Dimensional Generative Models: The Empirical-Beta-Copula Autoencoder. (arXiv:2309.09916v1 [stat.ML])

    [http://arxiv.org/abs/2309.09916](http://arxiv.org/abs/2309.09916)

    该研究讨论了通过将自动编码器的潜在空间建模为一个可以获取样本的分布，从而将任何自动编码器转化为生成模型的技术。其中，研究了一种新的基于Copula的方法：经验Beta Copula自动编码器。这些结果对于捕捉高维数据的特征表示具有重要的意义。

    

    通过从自动编码器的潜在空间中采样，并解码潜在空间样本到原始数据空间，任何自动编码器都可以简单地转化为生成模型。为了实现这一点，需要用一个可以获得样本的分布来建模自动编码器的潜在空间。可以考虑几种简单的可能性（核密度估计、高斯分布）和更复杂的方法（高斯混合模型、Copula模型、规范化流），并且近期已经尝试过。本研究旨在讨论、评估和比较可以用于捕捉潜在空间的各种技术，以便使自动编码器成为一个生成模型，并追求简单性。其中，考虑了一种新的基于Copula的方法，即经验Beta Copula自动编码器。此外，我们提供了关于这些方法的其他方面的深入见解，如有针对性的采样或合成具有特定特征的新数据。

    By sampling from the latent space of an autoencoder and decoding the latent space samples to the original data space, any autoencoder can simply be turned into a generative model. For this to work, it is necessary to model the autoencoder's latent space with a distribution from which samples can be obtained. Several simple possibilities (kernel density estimates, Gaussian distribution) and more sophisticated ones (Gaussian mixture models, copula models, normalization flows) can be thought of and have been tried recently. This study aims to discuss, assess, and compare various techniques that can be used to capture the latent space so that an autoencoder can become a generative model while striving for simplicity. Among them, a new copula-based method, the Empirical Beta Copula Autoencoder, is considered. Furthermore, we provide insights into further aspects of these methods, such as targeted sampling or synthesizing new data with specific features.
    
[^3]: 步行指纹识别

    Walking fingerprinting. (arXiv:2309.09897v1 [stat.AP])

    [http://arxiv.org/abs/2309.09897](http://arxiv.org/abs/2309.09897)

    本文研究了使用步态加速度数据进行个体身份预测的问题，提出了一种新颖的多元函数回归模型，避免了将预测器空间分成单元格，并进行了两个数据集的预测方法比较。

    

    本文考虑使用步态加速度数据来预测个体的身份。之前的研究中，我们提出了一种方法，将加速度时间序列转化为图像，通过构建完整的经验自相关分布来实现。通过将该图像分成网格单元，并使用逻辑回归产生的预测器，可以进行个体身份的预测。在本文中，我们：(1) 实施了使用基于网格单元的预测器进行预测的机器学习方法；(2) 推导了一种推断方法，以筛选出最具预测性的网格单元；(3) 发展了一种新颖的多元函数回归模型，避免了将预测器空间分成单元格。针对两个开源数据集进行了预测方法比较：(1)来自32个个体在1.06千米路径上行走的加速度数据；(2)在两个不同场合进行了六次重复行走的20米路径上收集的加速度数据，时间间隔至少为一周。

    We consider the problem of predicting an individual's identity from accelerometry data collected during walking. In a previous paper we introduced an approach that transforms the accelerometry time series into an image by constructing its complete empirical autocorrelation distribution. Predictors derived by partitioning this image into grid cells were used in logistic regression to predict individuals. Here we: (1) implement machine learning methods for prediction using the grid cell-derived predictors; (2) derive inferential methods to screen for the most predictive grid cells; and (3) develop a novel multivariate functional regression model that avoids partitioning of the predictor space into cells. Prediction methods are compared on two open source data sets: (1) accelerometry data collected from $32$ individuals walking on a $1.06$ kilometer path; and (2) accelerometry data collected from six repetitions of walking on a $20$ meter path on two separate occasions at least one week a
    
[^4]: 上下文≈环境。

    Context $\approx$ Environment. (arXiv:2309.09888v1 [cs.LG])

    [http://arxiv.org/abs/2309.09888](http://arxiv.org/abs/2309.09888)

    在这篇论文中，作者通过理论与实验证明了将注意力放在上下文-未标记样本上，可以实现更好的领域泛化。

    

    AI研究的中心在于两个方面。一方面，社区正在努力构建能够丢弃虚假相关性并在新颖的测试环境中更好地进行泛化的模型。不幸的是，到目前为止，没有任何提案能够令人信服地超越简单的经验风险最小化基线。另一方面，大型语言模型(LLMs)已经成为能够在上下文中学习、根据用户通过提示施加的多种上下文背景灵活泛化的算法。本文认为上下文≈环境，并假设在上下文学习中隐藏着更好的领域泛化之钥。通过广泛的理论与实验，我们展示了注意上下文-未标记的样本的重要性，这种注意可以使我们提出的In-Context Risk Minimization (ICRM)算法聚焦于测试环境风险最小化。

    Two lines of work are taking the central stage in AI research. On the one hand, the community is making increasing efforts to build models that discard spurious correlations and generalize better in novel test environments. Unfortunately, the bitter lesson so far is that no proposal convincingly outperforms a simple empirical risk minimization baseline. On the other hand, large language models (LLMs) have erupted as algorithms able to learn in-context, generalizing on-the-fly to the eclectic contextual circumstances that users enforce by means of prompting. In this paper, we argue that context $\approx$ environment, and posit that in-context learning holds the key to better domain generalization. Via extensive theory and experiments, we show that paying attention to context$\unicode{x2013}\unicode{x2013}$unlabeled examples as they arrive$\unicode{x2013}\unicode{x2013}$allows our proposed In-Context Risk Minimization (ICRM) algorithm to zoom-in on the test environment risk minimizer, le
    
[^5]: 由堆叠回归减少误差

    Error Reduction from Stacked Regressions. (arXiv:2309.09880v1 [stat.ML])

    [http://arxiv.org/abs/2309.09880](http://arxiv.org/abs/2309.09880)

    本文提出了一种新的堆叠回归方法，通过最小化总体风险并受非负性约束，成功降低了误差。实验证明，堆叠估计器相比其中最佳的单个估计器具有更小的总体风险。

    

    堆叠回归是一种集成技术，它通过形成不同回归估计器的线性组合来提高预测准确性。传统方法使用交叉验证数据来生成由构成估计器预测，并使用带非负性约束的最小二乘法学习组合权重。在本文中，我们类似地通过最小化一种估计的总体风险来学习这些权重，并受到非负性约束。当构成的估计器是通过至少三个维度分隔的嵌套子空间的线性最小二乘投影时，我们证明由于收缩效应，所得到的堆叠估计器的总体风险严格小于其中最佳的单个估计器。这里的“最佳”是指最小化选择准则如AIC或BIC的模型。换句话说，在这种情况下，最佳的单个估计器是不可接受的。因为优化问题可以重构为同信息回归，所以...

    Stacking regressions is an ensemble technique that forms linear combinations of different regression estimators to enhance predictive accuracy. The conventional approach uses cross-validation data to generate predictions from the constituent estimators, and least-squares with nonnegativity constraints to learn the combination weights. In this paper, we learn these weights analogously by minimizing an estimate of the population risk subject to a nonnegativity constraint. When the constituent estimators are linear least-squares projections onto nested subspaces separated by at least three dimensions, we show that thanks to a shrinkage effect, the resulting stacked estimator has strictly smaller population risk than best single estimator among them. Here ``best'' refers to a model that minimizes a selection criterion such as AIC or BIC. In other words, in this setting, the best single estimator is inadmissible. Because the optimization problem can be reformulated as isotonic regression, t
    
[^6]: 高维条件下线性判别分析的关键估计

    Pivotal Estimation of Linear Discriminant Analysis in High Dimensions. (arXiv:2309.09831v1 [math.ST])

    [http://arxiv.org/abs/2309.09831](http://arxiv.org/abs/2309.09831)

    PANDA是一种高维线性判别分析方法，对调参数需求小且达到最优收敛速率，与现有方法相比，其性能相当或更好，并且需要较少的参数调整工作。

    

    我们考虑在高维背景下的线性判别分析问题。在这项工作中，我们提出了PANDA（PivotAl liNear Discriminant Analysis），这是一种对调参数需求非常小的方法。此外，我们证明了PANDA在估计误差和错误分类率方面实现了最优的收敛速率。我们的理论结果得到了使用模拟数据和真实数据集的全面数值研究的支持。与现有方法相比，我们观察到我们提出的PANDA在性能上相等或更好，并且需要较少的参数调整工作。

    We consider the linear discriminant analysis problem in the high-dimensional settings. In this work, we propose PANDA(PivotAl liNear Discriminant Analysis), a tuning-insensitive method in the sense that it requires very little effort to tune the parameters. Moreover, we prove that PANDA achieves the optimal convergence rate in terms of both the estimation error and misclassification rate. Our theoretical results are backed up by thorough numerical studies using both simulated and real datasets. In comparison with the existing methods, we observe that our proposed PANDA yields equal or better performance, and requires substantially less effort in parameter tuning.
    
[^7]: 卷积深度核机器

    Convolutional Deep Kernel Machines. (arXiv:2309.09814v1 [stat.ML])

    [http://arxiv.org/abs/2309.09814](http://arxiv.org/abs/2309.09814)

    这项研究介绍了一种称为卷积深度核机器的新型核方法，该方法纯粹使用核而不使用特征，通过高效的跨域诱导点近似方案和多种模型变体的设计，达到了在MNIST、CIFAR-10和CIFAR-100上接近甚至超过其他方法的测试准确率。

    

    深度核机器(DKMs)是一种最近引入的具有其他深度模型灵活性的核方法，包括深度神经网络和深度高斯过程。DKMs纯粹使用核，而不使用特征，因此与其他方法（从神经网络到深度核学习甚至深度高斯过程）不同，后者都使用特征作为基本组成部分。在这里，我们引入了卷积DKMs，并配以一种高效的跨域诱导点近似方案。此外，我们还开发并实验评估了许多模型变体，包括9种不同类型的为卷积DKMs设计的归一化方法，两种似然函数和两种不同类型的顶层。尽管只在约28个GPU小时内训练（比完全的NNGP / NTK / Myrtle kernel快1-2个数量级），但得到的模型在MNIST上实现了约99％的测试准确性，在CIFAR-10上为92％，在CIFAR-100上为71％，同时达到可比较的性能。

    Deep kernel machines (DKMs) are a recently introduced kernel method with the flexibility of other deep models including deep NNs and deep Gaussian processes. DKMs work purely with kernels, never with features, and are therefore different from other methods ranging from NNs to deep kernel learning and even deep Gaussian processes, which all use features as a fundamental component. Here, we introduce convolutional DKMs, along with an efficient inter-domain inducing point approximation scheme. Further, we develop and experimentally assess a number of model variants, including 9 different types of normalisation designed for the convolutional DKMs, two likelihoods, and two different types of top-layer. The resulting models achieve around 99% test accuracy on MNIST, 92% on CIFAR-10 and 71% on CIFAR-100, despite training in only around 28 GPU hours, 1-2 orders of magnitude faster than full NNGP / NTK / Myrtle kernels, whilst achieving comparable performance.
    
[^8]: 无约束特征模型中的交叉熵损失下不受限的神经塌缩机制

    Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss with Imbalanced Data. (arXiv:2309.09725v1 [stat.ML])

    [http://arxiv.org/abs/2309.09725](http://arxiv.org/abs/2309.09725)

    在无约束特征模型的背景下，我们研究了交叉熵损失函数下不均衡数据的神经塌缩现象。

    

    近年来，深度神经网络（DNNs）在计算机视觉和文本处理的各种任务中取得了巨大的成功。有趣的是，这些具有大量参数的DNNs在训练的末期阶段（TPT）的特征表示和末层分类器具有相似的结构特性。具体而言，如果训练数据是平衡的（每个类别具有相同数量的样本），观察到来自同一类别的样本的特征向量收敛到相应的类内均值特征，并且它们的成对角度相同。这一迷人的现象被称为神经塌缩（NC），由Papyan，Han和Donoho在2019年首次提出。最近的许多工作通过采用所谓的无约束特征模型（UFM）在理论上解释了这一现象。在本文中，我们研究了在无约束特征模型的上下文中，弥补了NC现象对不均衡数据在交叉熵损失函数下的拓展。我们的贡献是

    Recent years have witnessed the huge success of deep neural networks (DNNs) in various tasks of computer vision and text processing. Interestingly, these DNNs with massive number of parameters share similar structural properties on their feature representation and last-layer classifier at terminal phase of training (TPT). Specifically, if the training data are balanced (each class shares the same number of samples), it is observed that the feature vectors of samples from the same class converge to their corresponding in-class mean features and their pairwise angles are the same. This fascinating phenomenon is known as Neural Collapse (N C), first termed by Papyan, Han, and Donoho in 2019. Many recent works manage to theoretically explain this phenomenon by adopting so-called unconstrained feature model (UFM). In this paper, we study the extension of N C phenomenon to the imbalanced data under cross-entropy loss function in the context of unconstrained feature model. Our contribution is
    
[^9]: 多类别分类的多数投票准确性的新界限

    New Bounds on the Accuracy of Majority Voting for Multi-Class Classification. (arXiv:2309.09564v1 [stat.ML])

    [http://arxiv.org/abs/2309.09564](http://arxiv.org/abs/2309.09564)

    本论文研究了多数投票在多类别分类问题中的准确性，并推导出了新的准确性上界。研究发现，在满足一定条件的情况下，随着独立投票人数量的增加，多数投票函数的错误率将以指数方式趋向于零，否则将以指数方式增长。

    

    多数投票是一种简单的数学函数，返回集合中出现最多的值。作为一种流行的决策融合技术，多数投票函数（MVF）在解决冲突、独立投票人就分类问题报告他们的观点方面有着各种应用。尽管它在集成学习、数据众包、遥感和区块链数据神谕等领域有重要应用，但多数投票函数在一般多类别分类问题上的准确性一直未知。在本文中，我们推导出多数投票函数在多类别分类问题上的新的准确性上界。具体而言，我们展示了在某些条件下，多数投票函数的错误率在独立投票人数量增加时以指数方式趋向于零。相反，如果不满足这些条件，多数投票函数的错误率将以指数方式增长。我们首先探讨了模型无偏性和独立投票人之间的关系，并进一步分析了多数投票函数在具体问题中的应用。

    Majority voting is a simple mathematical function that returns the value that appears most often in a set. As a popular decision fusion technique, the majority voting function (MVF) finds applications in resolving conflicts, where a number of independent voters report their opinions on a classification problem. Despite its importance and its various applications in ensemble learning, data crowd-sourcing, remote sensing, and data oracles for blockchains, the accuracy of the MVF for the general multi-class classification problem has remained unknown. In this paper, we derive a new upper bound on the accuracy of the MVF for the multi-class classification problem. More specifically, we show that under certain conditions, the error rate of the MVF exponentially decays toward zero as the number of independent voters increases. Conversely, the error rate of the MVF exponentially grows with the number of independent voters if these conditions are not met.  We first explore the problem for inde
    
[^10]: 具有低秩结构的多维度领域泛化

    Multi-dimensional domain generalization with low-rank structures. (arXiv:2309.09555v1 [stat.ME])

    [http://arxiv.org/abs/2309.09555](http://arxiv.org/abs/2309.09555)

    这项工作提出了一种新颖的方法来应对在健康相关研究中少数族群在训练数据中被忽视而导致的统计推断问题。通过将模型参数组织成张量，并研究结构化张量补全问题，我们实现了对具有有限或无可用数据的亚群体的鲁棒领域泛化，该方法利用了组标签的结构，可以产生更可靠和可解释的泛化结果。

    

    在传统的统计和机器学习方法中，通常假设测试数据与训练数据是同分布的。然而，在一些应用中，特定的族群可能在训练数据中被较少地表示，这个假设并不总是成立。这在健康相关研究中是一个值得注意的问题，因为少数族群可能在训练数据中被忽视，这给研究人员在对这些少数族群进行统计推断时带来了显著挑战。在这项工作中，我们提出了一种新颖的方法来应对线性回归模型中的这一问题。我们将所有亚群体的模型参数组织成一个张量。通过研究结构化张量补全问题，我们可以实现鲁棒的领域泛化，即学习对具有有限或无可用数据的亚群体的推断。我们的方法新颖地利用了组标签的结构，可以产生更可靠和可解释的泛化结果。

    In conventional statistical and machine learning methods, it is typically assumed that the test data are identically distributed with the training data. However, this assumption does not always hold, especially in applications where the target population are not well-represented in the training data. This is a notable issue in health-related studies, where specific ethnic populations may be underrepresented, posing a significant challenge for researchers aiming to make statistical inferences about these minority groups. In this work, we present a novel approach to addressing this challenge in linear regression models. We organize the model parameters for all the sub-populations into a tensor. By studying a structured tensor completion problem, we can achieve robust domain generalization, i.e., learning about sub-populations with limited or no available data. Our method novelly leverages the structure of group labels and it can produce more reliable and interpretable generalization resu
    
[^11]: 不需要计算复杂性无法解决的预言机，在稀疏线性MDP中探索和学习。

    Exploring and Learning in Sparse Linear MDPs without Computationally Intractable Oracles. (arXiv:2309.09457v1 [cs.LG])

    [http://arxiv.org/abs/2309.09457](http://arxiv.org/abs/2309.09457)

    本文研究了在稀疏线性MDP中探索和学习的问题，通过特征选择提出了一个多项式时间算法，以在与环境的交互中学习出近似最优策略。

    

    线性马尔可夫决策过程（MDPs）的基本假设是学习者可以访问已知的特征映射$ \phi（x，a）$，该映射将状态-动作对映射到$d$维向量，并且奖励和转换是此表示中的线性函数。但是这些特征从哪里来？在没有专家领域知识的情况下，一种诱人的策略是使用“厨房水槽”方法，并希望真实特征包含在一个更大的潜在特征集中。在本文中，我们从特征选择的角度重新审视线性MDP。在$k$-稀疏线性MDP中，存在一个未知的大小为$k$的子集$S \subset [d]$，其中包含所有相关特征，目标是在与环境的交互中仅经过poly$(k,\log d)$次学习，学习出近似最优策略。我们的主要结果是这个问题的第一个多项式时间算法。与此相反，早期的研究要么做出了明显的假设，使得探索无关紧要，要么提供了指数复杂度的算法。

    The key assumption underlying linear Markov Decision Processes (MDPs) is that the learner has access to a known feature map $\phi(x, a)$ that maps state-action pairs to $d$-dimensional vectors, and that the rewards and transitions are linear functions in this representation. But where do these features come from? In the absence of expert domain knowledge, a tempting strategy is to use the ``kitchen sink" approach and hope that the true features are included in a much larger set of potential features. In this paper we revisit linear MDPs from the perspective of feature selection. In a $k$-sparse linear MDP, there is an unknown subset $S \subset [d]$ of size $k$ containing all the relevant features, and the goal is to learn a near-optimal policy in only poly$(k,\log d)$ interactions with the environment. Our main result is the first polynomial-time algorithm for this problem. In contrast, earlier works either made prohibitively strong assumptions that obviated the need for exploration, o
    
[^12]: 关于使用康托罗维奇-鲁宾斯坦距离进行降维的研究

    On the Use of the Kantorovich-Rubinstein Distance for Dimensionality Reduction. (arXiv:2309.09442v1 [math.PR])

    [http://arxiv.org/abs/2309.09442](http://arxiv.org/abs/2309.09442)

    这项研究研究了使用康托罗维奇-鲁宾斯坦距离来构建样本复杂性描述子，在分类问题中能够得出存在一个1-立切分类器的结论，并讨论了该距离的局限性。

    

    本论文的目标是研究在分类问题中使用康托罗维奇-鲁宾斯坦距离来构建样本复杂性的描述子。我们的思想是利用康托罗维奇-鲁宾斯坦距离作为度量空间中度量和拓扑的一种方法。我们为每个类别的点关联一个度量，并研究可以从这些度量之间的康托罗维奇-鲁宾斯坦距离中获取的几何信息。我们证明了在这些度量之间存在大的康托罗维奇-鲁宾斯坦距离就可以得出存在一个能够良好分类点类别的1-立切分类器的结论。我们还讨论了康托罗维奇-鲁宾斯坦距离作为描述子的局限性。

    The goal of this thesis is to study the use of the Kantorovich-Rubinstein distance as to build a descriptor of sample complexity in classification problems. The idea is to use the fact that the Kantorovich-Rubinstein distance is a metric in the space of measures that also takes into account the geometry and topology of the underlying metric space. We associate to each class of points a measure and thus study the geometrical information that we can obtain from the Kantorovich-Rubinstein distance between those measures. We show that a large Kantorovich-Rubinstein distance between those measures allows to conclude that there exists a 1-Lipschitz classifier that classifies well the classes of points. We also discuss the limitation of the Kantorovich-Rubinstein distance as a descriptor.
    
[^13]: 使用Forman-Ricci曲率的扩展来减轻过度平滑和过度压缩问题

    Mitigating Over-Smoothing and Over-Squashing using Augmentations of Forman-Ricci Curvature. (arXiv:2309.09384v1 [cs.LG])

    [http://arxiv.org/abs/2309.09384](http://arxiv.org/abs/2309.09384)

    本文提出了一种使用Forman-Ricci曲率扩展的方法来减轻图神经网络中的过度平滑和过度压缩问题。通过观察离散曲率，可以添加或删除边以减轻这两种效应。

    

    虽然图神经网络（GNNs）在不同领域的图结构数据学习中取得了成功，但最近描述了几个潜在的陷阱。这些包括无法准确利用编码在长距离连接中的信息（过度压缩），以及在网络深度增加时难以区分附近节点的学习表示（过度平滑）。一种有效的表征这两种效应的方法是离散曲率：导致过度压缩效应的长距离连接具有低曲率，而导致过度平滑的边具有高曲率。这个观察引发了一些重连技术，通过增加或删除边来减轻过度平滑和过度压缩问题。已经提出了几种利用图特征（如曲率或图拉普拉斯算子的谱）的重连方法。然而，现有方法，特别是基于曲率的方法，通常需要昂贵的子图操作。

    While Graph Neural Networks (GNNs) have been successfully leveraged for learning on graph-structured data across domains, several potential pitfalls have been described recently. Those include the inability to accurately leverage information encoded in long-range connections (over-squashing), as well as difficulties distinguishing the learned representations of nearby nodes with growing network depth (over-smoothing). An effective way to characterize both effects is discrete curvature: Long-range connections that underlie over-squashing effects have low curvature, whereas edges that contribute to over-smoothing have high curvature. This observation has given rise to rewiring techniques, which add or remove edges to mitigate over-smoothing and over-squashing. Several rewiring approaches utilizing graph characteristics, such as curvature or the spectrum of the graph Laplacian, have been proposed. However, existing methods, especially those based on curvature, often require expensive subr
    
[^14]: 两层神经网络上逻辑回归代价函数的全局收敛性

    Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets. (arXiv:2309.09258v1 [cs.LG])

    [http://arxiv.org/abs/2309.09258](http://arxiv.org/abs/2309.09258)

    本文首次证明了在深度为2的神经网络上，适当正则化的逻辑回归代价函数通过随机梯度下降（SGD）能够收敛到全局极小值，这适用于任意数据和具有充分平滑且有界激活函数。同时，我们还证明了连续时间SGD的指数级快速收敛速度，该结果也适用于光滑无界的激活函数。

    

    在本文中，我们首次证明了随机梯度下降（SGD）对于适当正则化的深度为2的神经网络的逻辑回归代价函数能够收敛到全局极小值，对于任意数据和具有充分平滑且有界激活函数（如sigmoid和tanh）。我们还证明了连续时间SGD的指数级快速收敛速度，该结果也适用于光滑无界的激活函数（如SoftPlus）。我们的关键思想是证明了在恒定大小的神经网络上存在Frobenius范数正则化的逻辑回归代价函数，这些函数是"Villani函数"，从而能够构建在最近对于此类目标函数上分析SGD的研究进展上。

    In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates with adequately smooth and bounded activations like sigmoid and tanh. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence of Frobenius norm regularized logistic loss functions on constant-sized neural nets which are "Villani functions" and thus be able to build on recent progress with analyzing SGD on such objectives.
    
[^15]: 具有$\ell_0$约束的多线性稀疏逻辑回归的全局收敛加速算法。

    Globally Convergent Accelerated Algorithms for Multilinear Sparse Logistic Regression with $\ell_0$-constraints. (arXiv:2309.09239v1 [cs.LG])

    [http://arxiv.org/abs/2309.09239](http://arxiv.org/abs/2309.09239)

    本文提出了一种解决具有$\ell_0$约束的多线性稀疏逻辑回归模型的全局收敛加速算法。通过利用低秩张量分解的结构信息减少参数数量，该算法能够有效地进行特征选择和分析多维数据。该算法使用加速次梯度交替线性化最小化与自适应动量的方法来解决非凸和非光滑问题，并提供了收敛保证。

    

    张量数据表示多维数组。基于低秩张量分解的回归方法利用结构信息减少参数数量。多线性逻辑回归是分析多维数据的强大工具。为了提高其效果和可解释性，我们提出了一种具有$\ell_0$约束的多线性稀疏逻辑回归模型($\ell_0$-MLSR)。与$\ell_1$范数和$\ell_2$范数相比，$\ell_0$范数约束更适合特征选择。然而，由于其非凸和非光滑特性，求解它是具有挑战性且缺乏收敛保证。此外，$\ell_0$-MLSR中的多线性运算也带来了非凸性。为了解决这些挑战，我们提出了一种加速次梯度交替线性化最小化与自适应动量(APALM$^+$)方法来求解$\ell_0$-MLSR模型。我们证明了APALM$^+$能够确保目标函数的收敛。

    Tensor data represents a multidimensional array. Regression methods based on low-rank tensor decomposition leverage structural information to reduce the parameter count. Multilinear logistic regression serves as a powerful tool for the analysis of multidimensional data. To improve its efficacy and interpretability, we present a Multilinear Sparse Logistic Regression model with $\ell_0$-constraints ($\ell_0$-MLSR). In contrast to the $\ell_1$-norm and $\ell_2$-norm, the $\ell_0$-norm constraint is better suited for feature selection. However, due to its nonconvex and nonsmooth properties, solving it is challenging and convergence guarantees are lacking. Additionally, the multilinear operation in $\ell_0$-MLSR also brings non-convexity. To tackle these challenges, we propose an Accelerated Proximal Alternating Linearized Minimization with Adaptive Momentum (APALM$^+$) method to solve the $\ell_0$-MLSR model. We provide a proof that APALM$^+$ can ensure the convergence of the objective fu
    
[^16]: 双重标准化流：灵活的贝叶斯高斯过程ODE学习

    Double Normalizing Flows: Flexible Bayesian Gaussian Process ODEs Learning. (arXiv:2309.09222v1 [cs.LG])

    [http://arxiv.org/abs/2309.09222](http://arxiv.org/abs/2309.09222)

    这项研究将标准化流引入高斯过程常微分方程(ODE)模型，使其具备更灵活和表达性强的先验分布和非高斯的后验推断，从而提高了贝叶斯高斯过程ODE的准确性和不确定性估计。

    

    最近，高斯过程被用来建模连续动力系统的向量场。对于这样的模型，贝叶斯推断已经得到了广泛研究，并应用于时间序列预测等任务，提供不确定性估计。然而，先前的高斯过程常微分方程(ODE)模型在具有非高斯过程先验的数据集上可能表现不佳，因为它们的约束先验和均值场后验可能缺乏灵活性。为了解决这个限制，我们引入了标准化流来重新参数化ODE的向量场，从而得到一个更灵活、更表达性的先验分布。此外，由于标准化流的解析可计算的概率密度函数，我们将它们应用于GP ODE的后验推断，生成一个非高斯的后验。通过这些标准化流的双重应用，我们的模型在贝叶斯高斯过程ODE中提高了准确性和不确定性估计。

    Recently, Gaussian processes have been utilized to model the vector field of continuous dynamical systems. Bayesian inference for such models \cite{hegde2022variational} has been extensively studied and has been applied in tasks such as time series prediction, providing uncertain estimates. However, previous Gaussian Process Ordinary Differential Equation (ODE) models may underperform on datasets with non-Gaussian process priors, as their constrained priors and mean-field posteriors may lack flexibility. To address this limitation, we incorporate normalizing flows to reparameterize the vector field of ODEs, resulting in a more flexible and expressive prior distribution. Additionally, due to the analytically tractable probability density functions of normalizing flows, we apply them to the posterior inference of GP ODEs, generating a non-Gaussian posterior. Through these dual applications of normalizing flows, our model improves accuracy and uncertainty estimates for Bayesian Gaussian P
    
[^17]: MFRL-BI: 使用贝叶斯推理设计无模型强化学习过程控制方案

    MFRL-BI: Design of a Model-free Reinforcement Learning Process Control Scheme by Using Bayesian Inference. (arXiv:2309.09205v1 [cs.LG])

    [http://arxiv.org/abs/2309.09205](http://arxiv.org/abs/2309.09205)

    本论文提出了一种无模型强化学习（MFRL）方法来进行实时数据驱动的制造过程控制优化，通过使用贝叶斯推理来减少制造过程中扰动的大幅度变化。实验证明在未知过程模型的情况下，提出的MFRL控制器在非线性化学机械抛光（CMP）过程中表现良好。

    

    过程控制方案的设计对于减少制造系统中的变异性至关重要，以确保产品质量。以半导体制造为例，大量文献关注基于某些经过实验获得的过程模型（通常是线性模型）的控制优化。然而，在实际应用中，预定义的模型可能不准确，特别是对于复杂的制造系统。为了解决模型不准确的问题，我们提出了一种无模型强化学习（MFRL）方法，根据实时数据同时进行实验和优化控制。具体而言，我们设计了一种新颖的MFRL控制方案，通过使用贝叶斯推理来更新扰动的分布，以减少制造过程中的大幅度变化。结果显示，当过程模型未知时，所提出的MFRL控制器在非线性化学机械抛光（CMP）过程中表现良好。

    Design of process control scheme is critical for quality assurance to reduce variations in manufacturing systems. Taking semiconductor manufacturing as an example, extensive literature focuses on control optimization based on certain process models (usually linear models), which are obtained by experiments before a manufacturing process starts. However, in real applications, pre-defined models may not be accurate, especially for a complex manufacturing system. To tackle model inaccuracy, we propose a model-free reinforcement learning (MFRL) approach to conduct experiments and optimize control simultaneously according to real-time data. Specifically, we design a novel MFRL control scheme by updating the distribution of disturbances using Bayesian inference to reduce their large variations during manufacturing processes. As a result, the proposed MFRL controller is demonstrated to perform well in a nonlinear chemical mechanical planarization (CMP) process when the process model is unknow
    
[^18]: 关于黎曼猜想和一类特殊神经网络之间的关联

    On the Connection Between Riemann Hypothesis and a Special Class of Neural Networks. (arXiv:2309.09171v1 [stat.ML])

    [http://arxiv.org/abs/2309.09171](http://arxiv.org/abs/2309.09171)

    黎曼猜想是数学领域中一个历史悠久的未解问题，它假设黎曼函数的非平凡零点的实部均等于1/2。本文重新审视和扩展了一种旧分析准则，将黎曼猜想与涉及特殊类别神经网络的最小化问题联系起来。

    

    黎曼猜想（RH）是数学中一个历史悠久的未解问题，它假设黎曼函数的非平凡零点的实部均等于1/2。RH的后果影响广泛，涉及到诸如素数分布、算术函数增长、欧拉函数增长等领域。在本文中，我们重新审视和扩展了一种称为Nyman-Beurling准则的RH旧分析准则，该准则将RH与涉及特殊类别神经网络的最小化问题联系起来。本文旨在面向那些对RH不熟悉的读者，提供了一个温和的RH介绍。

    The Riemann hypothesis (RH) is a long-standing open problem in mathematics. It conjectures that non-trivial zeros of the zeta function all have real part equal to 1/2. The extent of the consequences of RH is far-reaching and touches a wide spectrum of topics including the distribution of prime numbers, the growth of arithmetic functions, the growth of Euler totient, etc. In this note, we revisit and extend an old analytic criterion of the RH known as the Nyman-Beurling criterion which connects the RH to a minimization problem that involves a special class of neural networks. This note is intended for an audience unfamiliar with RH. A gentle introduction to RH is provided.
    
[^19]: $L^1$估计：线性估计器的最优性

    $L^1$ Estimation: On the Optimality of Linear Estimators. (arXiv:2309.09129v1 [math.ST])

    [http://arxiv.org/abs/2309.09129](http://arxiv.org/abs/2309.09129)

    该论文研究了在$L^1$保真度条件下，从噪声观测中估计随机变量$X$的问题。结果表明，唯一能够引入线性条件中位数的先验分布是高斯分布。此外，还研究了其他$L^p$损失，并观察到对于$p \in [1,2]$，高斯分布是唯一引入线性最优贝叶斯估计器的先验分布。扩展还涵盖了特定指数族条件分布的噪声模型。

    

    在$L^1$保真度条件下，考虑从噪声观测$Y=X+Z$中估计随机变量$X$的问题，其中$Z$是标准正态分布。众所周知，在这种情况下，最优的贝叶斯估计器是条件中位数。本文表明，在条件中位数中引入线性的唯一先验分布是高斯分布。同时，还提供了其他几个结果。特别地，证明了如果对于所有$y$，条件分布$P_{X|Y=y}$都是对称的，则$X$必须服从高斯分布。此外，我们考虑了其他的$L^p$损失，并观察到以下现象：对于$p \in [1,2]$，高斯分布是唯一引入线性最优贝叶斯估计器的先验分布，对于$p \in (2,\infty)$，有无穷多个先验分布可以引入线性性。最后，还提供了扩展，以涵盖导致特定指数族条件分布的噪声模型。

    Consider the problem of estimating a random variable $X$ from noisy observations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity criterion. It is well known that the optimal Bayesian estimator in this setting is the conditional median. This work shows that the only prior distribution on $X$ that induces linearity in the conditional median is Gaussian.  Along the way, several other results are presented. In particular, it is demonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for all $y$, then $X$ must follow a Gaussian distribution. Additionally, we consider other $L^p$ losses and observe the following phenomenon: for $p \in [1,2]$, Gaussian is the only prior distribution that induces a linear optimal Bayesian estimator, and for $p \in (2,\infty)$, infinitely many prior distributions on $X$ can induce linearity. Finally, extensions are provided to encompass noise models leading to conditional distributions from certain exponential families.
    
[^20]: 将顺序变化检测简化为顺序估计

    Reducing sequential change detection to sequential estimation. (arXiv:2309.09111v1 [math.ST])

    [http://arxiv.org/abs/2309.09111](http://arxiv.org/abs/2309.09111)

    这个论文将顺序变化检测简化为顺序估计，通过使用置信序列来检测数据流中的变化，并证明了该方法具有强大的保证。

    

    本文考虑了顺序变化检测的问题，目标是设计一个能够检测数据流分布中参数或函数𝜃的任何变化的方案，该方案具有较小的检测延迟，但在没有变化的情况下能够保证假警报的频率受控。在本文中，我们使用置信序列描述了一种从顺序变化检测到顺序估计的简单约化方法：我们在每个时间步开始一个新的$(1-\alpha)$置信序列，并在所有活动置信序列的交集为空时宣布变化。我们证明了平均持续时间至少为$1/\alpha$，从而得到了具有最小结构假设的变化检测方案（因此允许可能相关的观测和非参数分布类），但却具有强大的保证。我们的方法与Lorden（1971）的变化检测到顺序测试的简化和Shin等人的e-detector有着有趣的相似之处。

    We consider the problem of sequential change detection, where the goal is to design a scheme for detecting any changes in a parameter or functional $\theta$ of the data stream distribution that has small detection delay, but guarantees control on the frequency of false alarms in the absence of changes. In this paper, we describe a simple reduction from sequential change detection to sequential estimation using confidence sequences: we begin a new $(1-\alpha)$-confidence sequence at each time step, and proclaim a change when the intersection of all active confidence sequences becomes empty. We prove that the average run length is at least $1/\alpha$, resulting in a change detection scheme with minimal structural assumptions~(thus allowing for possibly dependent observations, and nonparametric distribution classes), but strong guarantees. Our approach bears an interesting parallel with the reduction from change detection to sequential testing of Lorden (1971) and the e-detector of Shin e
    
[^21]: 使用稀疏或生成的先验解决全秩矩阵的二次系统

    Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors. (arXiv:2309.09032v1 [cs.IT])

    [http://arxiv.org/abs/2309.09032](http://arxiv.org/abs/2309.09032)

    本论文提出了一个方法，通过使用稀疏或生成的先验知识，解决了从全秩矩阵的二次系统中恢复信号的问题。其中，通过引入阈值Wirtinger流算法（TWF）来处理稀疏信号，并使用谱初始化和阈值梯度下降方法，在高维情况下实现了较小的测量数量。

    

    从具有全秩矩阵的二次系统中恢复信号x在应用中经常出现，比如未分配的距离几何和亚波长成像。本文通过引入对x的先验知识，针对高维情况（m << n），使用独立同分布的标准高斯矩阵解决了该问题。首先，考虑k-稀疏的x，引入了TWF算法，该算法不需要稀疏水平k。TWF包括两个步骤：谱初始化，当m = O(k^2log n)时，确定了一个距离x足够近的点（可能会有符号翻转），以及具有很好初始化的阈值梯度下降，该下降产生了一个线性收敛到x的序列，用m = O(klog n)个测量。

    The problem of recovering a signal $\boldsymbol{x} \in \mathbb{R}^n$ from a quadratic system $\{y_i=\boldsymbol{x}^\top\boldsymbol{A}_i\boldsymbol{x},\ i=1,\ldots,m\}$ with full-rank matrices $\boldsymbol{A}_i$ frequently arises in applications such as unassigned distance geometry and sub-wavelength imaging. With i.i.d. standard Gaussian matrices $\boldsymbol{A}_i$, this paper addresses the high-dimensional case where $m\ll n$ by incorporating prior knowledge of $\boldsymbol{x}$. First, we consider a $k$-sparse $\boldsymbol{x}$ and introduce the thresholded Wirtinger flow (TWF) algorithm that does not require the sparsity level $k$. TWF comprises two steps: the spectral initialization that identifies a point sufficiently close to $\boldsymbol{x}$ (up to a sign flip) when $m=O(k^2\log n)$, and the thresholded gradient descent (with a good initialization) that produces a sequence linearly converging to $\boldsymbol{x}$ with $m=O(k\log n)$ measurements. Second, we explore the generative p
    
[^22]: 基于克里斯托费尔函数和共形预测的数据驱动可达性分析

    Data-driven Reachability using Christoffel Functions and Conformal Prediction. (arXiv:2309.08976v1 [cs.LG])

    [http://arxiv.org/abs/2309.08976](http://arxiv.org/abs/2309.08976)

    这篇论文介绍了一种使用克里斯托费尔函数和共形预测进行数据驱动的可达性分析方法，能够有效估计复杂系统的可达集合，而不依赖于已知的数学模型。

    

    在动力系统分析中，一种重要的数学工具是近似可达集合，即从给定初始状态经过一定时间可以到达的状态集合。即使系统动力学已知且由已知系数的常微分方程组给出，对复杂系统来说，该集合很难计算。在实践中，参数常常是未知的，数学模型难以获得。数据驱动的方法通过基于状态样本估算可达集合来避免这些困难。如果有模型可用，可以通过数值模拟获得训练集。在没有模型的情况下，可以使用实际观测结果。最近提出的一种数据驱动可达集合近似方法使用克里斯托费尔函数来近似可达集合。在一定的假设下，这种近似方法可以收敛到真实解。在本文中，我们改进了这些结果，尤其是可达集合近似的准确性。

    An important mathematical tool in the analysis of dynamical systems is the approximation of the reach set, i.e., the set of states reachable after a given time from a given initial state. This set is difficult to compute for complex systems even if the system dynamics are known and given by a system of ordinary differential equations with known coefficients. In practice, parameters are often unknown and mathematical models difficult to obtain. Data-based approaches are promised to avoid these difficulties by estimating the reach set based on a sample of states. If a model is available, this training set can be obtained through numerical simulation. In the absence of a model, real-life observations can be used instead. A recently proposed approach for data-based reach set approximation uses Christoffel functions to approximate the reach set. Under certain assumptions, the approximation is guaranteed to converge to the true solution. In this paper, we improve upon these results by notabl
    
[^23]: 基于加法顺序实验设计的Shapley值快速近似计算方法

    Fast Approximation of the Shapley Values Based on Order-of-Addition Experimental Designs. (arXiv:2309.08923v1 [stat.ML])

    [http://arxiv.org/abs/2309.08923](http://arxiv.org/abs/2309.08923)

    该论文提出了一种基于加法顺序实验设计的方法，可以快速近似计算Shapley值。这解决了在计算Shapley值时的高计算负担问题。

    

    Shapley值最初是经济计量学中的一个概念，用于公平地分配联盟博弈中的收益和成本给玩家。近几十年来，它的应用已经扩展到营销、工程和机器学习等其他领域。然而，其计算负担较重一直被认识到但很少有研究。具体而言，在一个$d$-player联盟博弈中，计算Shapley值需要评估$d!$或$2^d$个边际贡献值，这取决于我们采用排列还是组合形式的Shapley值。因此，当$d$相对较大时，计算Shapley值变得不可行。通常的解决方法是对排列的随机采样来近似完整的排列列表。

    Shapley value is originally a concept in econometrics to fairly distribute both gains and costs to players in a coalition game. In the recent decades, its application has been extended to other areas such as marketing, engineering and machine learning. For example, it produces reasonable solutions for problems in sensitivity analysis, local model explanation towards the interpretable machine learning, node importance in social network, attribution models, etc. However, its heavy computational burden has been long recognized but rarely investigated. Specifically, in a $d$-player coalition game, calculating a Shapley value requires the evaluation of $d!$ or $2^d$ marginal contribution values, depending on whether we are taking the permutation or combination formulation of the Shapley value. Hence it becomes infeasible to calculate the Shapley value when $d$ is reasonably large. A common remedy is to take a random sample of the permutations to surrogate for the complete list of permutatio
    
[^24]: 非平稳在线学习的高效方法

    Efficient Methods for Non-stationary Online Learning. (arXiv:2309.08911v1 [cs.LG])

    [http://arxiv.org/abs/2309.08911](http://arxiv.org/abs/2309.08911)

    这项工作提出了一种针对非平稳在线学习的高效方法，通过降低每轮投影的数量来优化动态遗憾和自适应遗憾的计算复杂性。

    

    非平稳在线学习近年来引起了广泛关注。特别是在非平稳环境中，动态遗憾和自适应遗憾被提出作为在线凸优化的两个原则性性能度量。为了优化它们，通常采用两层在线集成，由于非平稳性的固有不确定性，其中维护一组基学习器，并采用元算法在运行过程中跟踪最佳学习器。然而，这种两层结构引发了关于计算复杂性的担忧 -这些方法通常同时维护$\mathcal{O}(\log T)$个基学习器，对于一个$T$轮在线游戏，因此每轮执行多次投影到可行域上，当域很复杂时，这成为计算瓶颈。在本文中，我们提出了优化动态遗憾和自适应遗憾的高效方法，将每轮的投影次数从$\mathcal{O}(\log T)$降低到...

    Non-stationary online learning has drawn much attention in recent years. In particular, dynamic regret and adaptive regret are proposed as two principled performance measures for online convex optimization in non-stationary environments. To optimize them, a two-layer online ensemble is usually deployed due to the inherent uncertainty of the non-stationarity, in which a group of base-learners are maintained and a meta-algorithm is employed to track the best one on the fly. However, the two-layer structure raises the concern about the computational complexity -- those methods typically maintain $\mathcal{O}(\log T)$ base-learners simultaneously for a $T$-round online game and thus perform multiple projections onto the feasible domain per round, which becomes the computational bottleneck when the domain is complicated. In this paper, we present efficient methods for optimizing dynamic regret and adaptive regret, which reduce the number of projections per round from $\mathcal{O}(\log T)$ t
    
[^25]: 从有限数据的非线性系统中学习线性化模型

    Learning Linearized Models from Nonlinear Systems with Finite Data. (arXiv:2309.08805v1 [eess.SY])

    [http://arxiv.org/abs/2309.08805](http://arxiv.org/abs/2309.08805)

    本论文提出了一种从有限数据的非线性系统中学习线性化模型的方法，并提供了有限样本误差界。误差界展示了非线性误差和噪声误差之间的权衡，表明在有足够多的样本时，可以学习到具有任意小误差的线性化动力学。

    

    在控制理论中，从数据中识别出线性系统模型具有广泛的应用。现有的有限样本分析方法通常使用来自单个系统轨迹的数据，并假设潜在的动力学是真正的线性。相反，我们考虑了当真实的潜在动力学是非线性时，识别线性化模型的问题。我们提供了一种基于多个轨迹的确定性数据采集算法，然后使用正则化最小二乘算法，得到了学习得到的线性化动力学的有限样本误差界。我们的误差界展示了非线性误差和噪声误差之间的权衡，并表明在有足够多的样本时，可以学习到具有任意小误差的线性化动力学。我们通过实验证实了我们的结果，并展示了使用单个轨迹进行线性系统识别的潜在不足。

    Identifying a linear system model from data has wide applications in control theory. The existing work on finite sample analysis for linear system identification typically uses data from a single system trajectory under i.i.d random inputs, and assumes that the underlying dynamics is truly linear. In contrast, we consider the problem of identifying a linearized model when the true underlying dynamics is nonlinear. We provide a multiple trajectories-based deterministic data acquisition algorithm followed by a regularized least squares algorithm, and provide a finite sample error bound on the learned linearized dynamics. Our error bound demonstrates a trade-off between the error due to nonlinearity and the error due to noise, and shows that one can learn the linearized dynamics with arbitrarily small error given sufficiently many samples. We validate our results through experiments, where we also show the potential insufficiency of linear system identification using a single trajectory w
    
[^26]: 高维度稀疏线性回归中的异方差问题及基于分区经验贝叶斯ECM算法的解决方法

    Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm. (arXiv:2309.08783v1 [stat.ME])

    [http://arxiv.org/abs/2309.08783](http://arxiv.org/abs/2309.08783)

    本文提出了一种解决高维度稀疏线性回归中异方差问题的方法，通过基于分区经验贝叶斯ECM算法的异方差高维度线性回归模型来实现。这个模型可以处理残差方差不恒定的情况，并且可以使用插值的经验贝叶斯估计超参数来灵活地调整方差模型。

    

    高维度数据的稀疏线性回归方法通常假设残差具有常数方差。当这一假设被违背时，会导致估计系数的偏差，预测区间长度不合适以及增加I型错误。本文提出一种基于分区经验贝叶斯期望条件最大化(H-PROBE)算法的异方差高维度线性回归模型。H-PROBE是一种计算效率高的最大后验估计方法，基于参数扩展的期望条件最大化(PX-ECM)算法。它通过插值的经验贝叶斯估计超参数，在回归参数上假设最小。方差模型使用了多元对数伽马分布理论的最新进展，并可以包含假设会影响异质性的协变量。我们的方法的动机是通过T2高分辨率神经影像研究与失语指数(AQ)相关性。

    Sparse linear regression methods for high-dimensional data often assume that residuals have constant variance. When this assumption is violated, it can lead to bias in estimated coefficients, prediction intervals with improper length, and increased type I errors. This paper proposes a heteroscedastic (H) high-dimensional linear regression model through a partitioned empirical Bayes Expectation Conditional Maximization (H-PROBE) algorithm. H-PROBE is a computationally efficient maximum a posteriori (MAP) estimation approach based on a Parameter-Expanded Expectation-Conditional-Maximization (PX-ECM) algorithm. It requires minimal prior assumptions on the regression parameters through plug-in empirical Bayes estimates of hyperparameters. The variance model uses recent advances in multivariate log-Gamma distribution theory and can include covariates hypothesized to impact heterogeneity. The motivation of our approach is a study relating Aphasia Quotient (AQ) to high-resolution T2 neuroimag
    
[^27]: 集群化的多智能体线性赌博机

    Clustered Multi-Agent Linear Bandits. (arXiv:2309.08710v1 [cs.LG])

    [http://arxiv.org/abs/2309.08710](http://arxiv.org/abs/2309.08710)

    本文研究了集群化的多智能体线性赌博机问题，提出了一种新颖的算法，通过智能体之间的协作来加速优化问题。通过理论分析和实证评估，证明了算法在遗憾最小化和聚类质量上的有效性。

    

    本文针对多智能体线性随机赌博问题的一个特定实例，即集群化的多智能体线性赌博机进行了研究。在这个设置中，我们提出了一种新颖的算法，通过智能体之间的有效协作来加速整体优化问题。在这一贡献中，网络控制器负责估计网络的基本集群结构并优化同一组中智能体之间的经验分享。我们对遗憾最小化问题和聚类质量进行了理论分析。通过对合成数据和真实数据进行与最先进算法的实证评估，我们证明了我们方法的有效性：我们的算法显著改善了遗憾最小化，并成功恢复了真实的基本集群划分。

    We address in this paper a particular instance of the multi-agent linear stochastic bandit problem, called clustered multi-agent linear bandits. In this setting, we propose a novel algorithm leveraging an efficient collaboration between the agents in order to accelerate the overall optimization problem. In this contribution, a network controller is responsible for estimating the underlying cluster structure of the network and optimizing the experiences sharing among agents within the same groups. We provide a theoretical analysis for both the regret minimization problem and the clustering quality. Through empirical evaluation against state-of-the-art algorithms on both synthetic and real data, we demonstrate the effectiveness of our approach: our algorithm significantly improves regret minimization while managing to recover the true underlying cluster partitioning.
    
[^28]: 线性最优臂识别中的安全代价

    Price of Safety in Linear Best Arm Identification. (arXiv:2309.08709v1 [stat.ML])

    [http://arxiv.org/abs/2309.08709](http://arxiv.org/abs/2309.08709)

    该论文提出了一种具有线性反馈的安全最优臂识别框架，该框架通过利用线性结构来保证在每一轮中不违反阶段性安全约束，提出了一种基于间隙的算法来实现有意义的样本复杂性，并通过实验证明了算法的有效性。

    

    我们引入了具有线性反馈的安全最优臂识别框架，其中代理受到一些阶段性安全约束的限制，该限制线性地依赖于未知的参数向量。代理必须以保守的方式采取行动，以确保在每一轮中不会高概率违反安全约束。已经研究了利用线性结构来确保安全性的方法，但据我们所知，还没有研究在最优臂识别中应用该方法。我们提出了一种基于间隙的算法，可以在确保阶段性安全性的同时实现有意义的样本复杂性。我们证明由于额外的安全约束导致的强制探索阶段，我们在样本复杂性上付出了额外的代价。我们提供了实验说明，以验证我们算法的设计。

    We introduce the safe best-arm identification framework with linear feedback, where the agent is subject to some stage-wise safety constraint that linearly depends on an unknown parameter vector. The agent must take actions in a conservative way so as to ensure that the safety constraint is not violated with high probability at each round. Ways of leveraging the linear structure for ensuring safety has been studied for regret minimization, but not for best-arm identification to the best our knowledge. We propose a gap-based algorithm that achieves meaningful sample complexity while ensuring the stage-wise safety. We show that we pay an extra term in the sample complexity due to the forced exploration phase incurred by the additional safety constraint. Experimental illustrations are provided to justify the design of our algorithm.
    
[^29]: 双高维上下文强化学习算法：用于联合组合-定价的可解释模型

    Doubly High-Dimensional Contextual Bandits: An Interpretable Model for Joint Assortment-Pricing. (arXiv:2309.08634v1 [stat.ML])

    [http://arxiv.org/abs/2309.08634](http://arxiv.org/abs/2309.08634)

    本论文提出了一种双高维上下文强化学习算法，用于解决联合组合-定价问题，通过简单而灵活的模型捕捉协变量和行为之间的相互作用，同时保持可解释性。该方法兼容多种结构化的线性强化学习和定价模型，提供了一种计算可行的流程。

    

    零售业务的关键挑战之一是如何选择要向消费者展示的产品（组合问题），以及如何定价产品（定价问题）以最大化收入或利润。我们提出了一种基于上下文强化学习的联合组合-定价方法，该方法同时考虑了组合和定价问题。我们的模型是双高维的，即上下文向量和行为都允许在高维空间中取值。为了克服维度灾难，我们提出了一个简单而灵活的模型，通过（近似）低秩表示矩阵来捕捉协变量和行为之间的相互作用。得到的模型类是相当表达力的，同时通过潜在因素保持可解释性，并包括不同结构化的线性强化学习和定价模型作为特殊情况。我们提出了一种计算可行的流程，将探索/利用协议与高效的低秩矩阵估计相结合。

    Key challenges in running a retail business include how to select products to present to consumers (the assortment problem), and how to price products (the pricing problem) to maximize revenue or profit. Instead of considering these problems in isolation, we propose a joint approach to assortment-pricing based on contextual bandits. Our model is doubly high-dimensional, in that both context vectors and actions are allowed to take values in high-dimensional spaces. In order to circumvent the curse of dimensionality, we propose a simple yet flexible model that captures the interactions between covariates and actions via a (near) low-rank representation matrix. The resulting class of models is reasonably expressive while remaining interpretable through latent factors, and includes various structured linear bandit and pricing models as particular cases. We propose a computationally tractable procedure that combines an exploration/exploitation protocol with an efficient low-rank matrix esti
    
[^30]: 随机逼近中的记忆诅咒：扩展版本

    The Curse of Memory in Stochastic Approximation: Extended Version. (arXiv:2309.02944v1 [math.ST])

    [http://arxiv.org/abs/2309.02944](http://arxiv.org/abs/2309.02944)

    本文研究了随机逼近中的记忆诅咒问题，并探讨了在不同情况下的结果。在具有几何遍历马尔可夫扰动的情况下，目标偏差一般非零。此外，当参数估计使用平均法时，估计值收敛到渐近无偏，且具有近似最优的渐近协方差。

    

    自适应控制的最早的日子以来，随机逼近（SA）的理论和应用在控制系统的社区中得到了快速发展。本文以新的视角重新审视了这个主题，受到最近的结果的启发，该结果证明使用（足够小的）恒定步长α>0的SA具有非凡的性能。如果采用平均法获取最终的参数估计，则估计值在渐近无偏和近似最优的渐近协方差下收敛。这些结果是针对具有独立同分布系数的随机线性SA递归获得的。本文在更常见的几何遍历马尔可夫扰动的情况下获得了非常不同的结论：（i）在非线性SA的情况下，识别出了“目标偏差”，并且一般上不为零。其余的结果是针对线性SA递归建立的：（ii）双变量参数扰动过程在拓扑意义上具有几何遍历性；（iii）偏差的表示具有简单的性质。

    Theory and application of stochastic approximation (SA) has grown within the control systems community since the earliest days of adaptive control. This paper takes a new look at the topic, motivated by recent results establishing remarkable performance of SA with (sufficiently small) constant step-size $\alpha>0$. If averaging is implemented to obtain the final parameter estimate, then the estimates are asymptotically unbiased with nearly optimal asymptotic covariance. These results have been obtained for random linear SA recursions with i.i.d.\ coefficients. This paper obtains very different conclusions in the more common case of geometrically ergodic Markovian disturbance: (i) The \textit{target bias} is identified, even in the case of non-linear SA, and is in general non-zero. The remaining results are established for linear SA recursions: (ii) the bivariate parameter-disturbance process is geometrically ergodic in a topological sense; (iii) the representation for bias has a simple
    
[^31]: 用于机器学习的热带几何工具：TML软件包

    Tropical Geometric Tools for Machine Learning: the TML package. (arXiv:2309.01082v1 [stat.ML])

    [http://arxiv.org/abs/2309.01082](http://arxiv.org/abs/2309.01082)

    TML软件包是第一个包含一套全面工具和方法的R软件包，用于处理与热带凸性相关的基本计算和可视化，以及使用热带度量进行监督和无监督学习模型的统计推断。

    

    在过去的十年中，热带几何学的发展提供了许多直接应用于统计学习问题的工具。TML软件包是第一个包含一套全面的工具和方法的R软件包，用于处理与热带凸性相关的基本计算、热带凸集的可视化，以及使用热带度量和热带投影环上的max-plus代数进行监督和无监督学习模型。主要的，TML软件包使用Hit and Run Markov chain Monte Carlo采样器与热带度量作为统计推断的主要工具。除了基本计算和热带HAR采样器的各种应用之外，我们还关注TML软件包中包含的几种监督和无监督方法，包括热带主成分分析、热带逻辑回归和热带核密度估计。

    In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
    
[^32]: 探索拉舒蒙集合有助于医疗数据的解释

    Exploration of Rashomon Set Assists Explanations for Medical Data. (arXiv:2308.11446v1 [cs.LG])

    [http://arxiv.org/abs/2308.11446](http://arxiv.org/abs/2308.11446)

    本文提出了一种新的过程来探索和分析医疗数据中的拉舒蒙集合模型，从而超越传统单一模型选择的方法，并通过引入"拉舒蒙检测"算法识别出集合中最不同的模型。

    

    机器学习建模过程通常以选择最大化某个性能指标的单一模型作为最终结果。然而，这种方法会导致对稍微差一些的模型进行更深入的分析被忽视。尤其在医疗和健康研究中，目标不仅仅是预测，还包括产生有价值的洞察，仅仅依赖性能指标可能会导致误导或不完整的结论。当处理一组性能接近最优的模型集合时，即所谓的"拉舒蒙集合"，这个问题尤为突出。这样的集合可能包含描述数据的不同方式的模型，需要进行全面的分析。本文引入了一种新的过程来探索拉舒蒙集合模型，扩展了传统建模方法。核心是通过引入的"拉舒蒙检测"算法来识别拉舒蒙集合中最不同的模型。

    The machine learning modeling process conventionally culminates in selecting a single model that maximizes a selected performance metric. However, this approach leads to abandoning a more profound analysis of slightly inferior models. Particularly in medical and healthcare studies, where the objective extends beyond predictions to valuable insight generation, relying solely on performance metrics can result in misleading or incomplete conclusions. This problem is particularly pertinent when dealing with a set of models with performance close to maximum one, known as $\textit{Rashomon set}$. Such a set can be numerous and may contain models describing the data in a different way, which calls for comprehensive analysis. This paper introduces a novel process to explore Rashomon set models, extending the conventional modeling approach. The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced $\texttt{Rashomon_DETECT}$ algorit
    
[^33]: Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) 该论文标题已翻译：二元强化学习。

    Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])

    [http://arxiv.org/abs/2308.07843](http://arxiv.org/abs/2308.07843)

    该论文介绍了一个称为二元强化学习的在线算法，用于根据上下文因素和目标人与其照顾伴侣的过去反馈，个性化地提供干预措施。该算法是贝叶斯和层次的，并通过模拟展示了良好的实证效果。

    

    移动医疗旨在通过在个人日常生活中提供干预来提高健康结果。照顾伴侣和社会支持网络的参与经常在帮助个人管理繁重的医疗条件方面起着关键作用。这为移动医疗提供了机会，设计针对二元关系——目标人和其照顾伴侣之间关系——以提高社会支持的干预措施。在本文中，我们开发了二元强化学习（Dyadic RL），这是一种基于环境因素和目标人及其照顾伴侣的过去反馈个性化干预措施的在线强化学习算法。在这里，多组干预措施影响着二元关系在多个时间间隔内。开发的二元强化学习是贝叶斯和层次的。我们正式介绍了问题设定，开发了二元强化学习并确定了遗憾边界。通过模拟，我们展示了二元强化学习的实证效果。

    Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
    
[^34]: 非线性置换格兰杰因果性

    Nonlinear Permuted Granger Causality. (arXiv:2308.06220v1 [stat.ME])

    [http://arxiv.org/abs/2308.06220](http://arxiv.org/abs/2308.06220)

    这项研究提出了一种处理非线性数据的格兰杰因果性方法，通过在特征提取过程中使用人工神经网络，利用置换来度量功能连接性，并实现了每个置换的方差的一致估计。在与其他技术的比较中，该方法表现出良好的性能。

    

    格兰杰因果推断是从经济学到神经科学等领域广泛使用的一种有争议的方法。原始定义基于指定模型条件下建立因果关系的时间序列概念。将格兰杰因果性应用于非线性数据仍然具有挑战性，许多方法使用样本内测试，不能纳入样本外的可预测性，导致模型过拟合的担忧。为了进行样本外比较，我们明确地定义了使用协变量集的置换来表示功能连接性的度量。人工神经网络作为数据的特征提取器，用于近似任何任意的非线性关系，并在特征提取过程和模型残差的一定条件下，证明对每个置换的方差进行了一致的估计。通过模拟比较了置换方法与惩罚目标、天真替代和遗漏技术的性能

    Granger causal inference is a contentious but widespread method used in fields ranging from economics to neuroscience. The original definition addresses the notion of causality in time series by establishing functional dependence conditional on a specified model. Adaptation of Granger causality to nonlinear data remains challenging, and many methods apply in-sample tests that do not incorporate out-of-sample predictability leading to concerns of model overfitting. To allow for out-of-sample comparison, we explicitly define a measure of functional connectivity using permutations of the covariate set. Artificial neural networks serve as featurizers of the data to approximate any arbitrary, nonlinear relationship, and under certain conditions on the featurization process and the model residuals, we prove consistent estimation of the variance for each permutation. Performance of the permutation method is compared to penalized objective, naive replacement, and omission techniques via simula
    
[^35]: 使用概念器进行变点检测

    Change Point Detection With Conceptors. (arXiv:2308.06213v1 [stat.ML])

    [http://arxiv.org/abs/2308.06213](http://arxiv.org/abs/2308.06213)

    我们提出了一种使用概念器矩阵进行变点检测的方法，通过学习时间序列中的特征动态，并利用单变量量化来识别变点。该方法在条件和无条件的变点检测问题上进行了测试，可以提供潜在的需要进一步研究的感兴趣位置。

    

    离线变点检测旨在识别时间序列中数据生成过程发生变化的点。对于单变量独立同分布数据，这个问题已经得到了较好的研究，但是随着维度和时间依赖性的增加，变得具有挑战性。针对至多一个变点的问题，我们提出使用概念器矩阵来学习时间序列中指定训练窗口的特征动态。相关的随机递归神经网络作为数据的特征提取器，并且通过计算特征化与代表性概念器矩阵所张成空间之间的距离的单变量量化来识别变点。这种模型无关的方法可以提示可能需要进一步研究的感兴趣的位置。我们证明，在温和的假设下，该方法提供了真实变点的一致估计，并通过对原始数据进行移动块自助法产生统计量的分位数估计。该方法在条件和无条件的变点检测问题上进行了测试。

    Offline change point detection seeks to identify points in a time series where the data generating process changes. This problem is well studied for univariate i.i.d. data, but becomes challenging with increasing dimension and temporal dependence. For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series. The associated random recurrent neural network acts as a featurizer of the data, and change points are identified from a univariate quantification of the distance between the featurization and the space spanned by a representative conceptor matrix. This model agnostic method can suggest potential locations of interest that warrant further study. We prove that, under mild assumptions, the method provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on si
    
[^36]: RED CoMETS: 一种用于符号化表示的多变量时间序列的集成分类器

    RED CoMETS: An ensemble classifier for symbolically represented multivariate time series. (arXiv:2307.13679v1 [cs.LG])

    [http://arxiv.org/abs/2307.13679](http://arxiv.org/abs/2307.13679)

    本文介绍了一种名为RED CoMETS的集成分类器，用于处理符号化表示的多变量时间序列数据。它在多变量设置中展现出竞争力的准确性，并在'HandMovementDirection'数据集上实现了最高的报告准确性。

    

    多变量时间序列分类是一个快速发展的研究领域，可在金融、医疗、工程等实际应用中使用。多变量时间序列数据的分类复杂性来自于其高维度、时间依赖性和长度不一致性。本文介绍了一种名为RED CoMETS（Random Enhanced Co-eye for Multivariate Time Series）的新型集成分类器，它解决了这些挑战。RED CoMETS基于Co-eye的成功，并将其能力扩展到处理多变量数据。使用UCR档案中的基准数据集对RED CoMETS的性能进行评估，在多变量设置中与最先进的技术相比，它显示出竞争力的准确性。值得注意的是，它在文献中对于'HandMovementDirection'数据集实现了最高的报告准确性。此外，该方法显著地改进了传统的Co-eye方法。

    Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more. The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths. This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges. RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data. The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings. Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset. Moreover, the proposed method signific
    
[^37]: 可解释人工智能的范畴基础：一种统一的结构和语义形式体系。

    Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics. (arXiv:2304.14094v1 [cs.AI])

    [http://arxiv.org/abs/2304.14094](http://arxiv.org/abs/2304.14094)

    本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。

    

    可解释人工智能（XAI）旨在回答与AI模型部署相关的伦理和法律问题。然而，相当数量的领域特定评论强调需要一个数学基础来定义领域中的关键概念，即使“解释”这个术语还缺乏精确定义。这些评论还主张建立一个健全而统一的可解释AI形式体系，以避免出现不良提出问题，帮助研究人员浏览一个快速增长的知识体系。据作者所知，该论文是填补该空白的首次尝试，通过形式化一个可解释AI的统一理论。采用范畴理论的框架，特别是反馈单调范畴，我们首先提供了可解释AI中所有重要术语的形式定义。然后，我们提出了一个遵循提出结构的领域分类法，展示了如何使用引入的理论来对当前研究的所有主要XAI系统类进行分类。

    Explainable AI (XAI) aims to answer ethical and legal questions associated with the deployment of AI models. However, a considerable number of domain-specific reviews highlight the need of a mathematical foundation for the key notions in the field, considering that even the term "explanation" still lacks a precise definition. These reviews also advocate for a sound and unifying formalism for explainable AI, to avoid the emergence of ill-posed questions, and to help researchers navigate a rapidly growing body of knowledge. To the authors knowledge, this paper is the first attempt to fill this gap by formalizing a unifying theory of XAI. Employing the framework of category theory, and feedback monoidal categories in particular, we first provide formal definitions for all essential terms in explainable AI. Then we propose a taxonomy of the field following the proposed structure, showing how the introduced theory can be used to categorize all the main classes of XAI systems currently studi
    
[^38]: counterfactuals: 用于反事实解释方法的 R 包

    counterfactuals: An R Package for Counterfactual Explanation Methods. (arXiv:2304.06569v1 [stat.ML])

    [http://arxiv.org/abs/2304.06569](http://arxiv.org/abs/2304.06569)

    该论文介绍了一个统一且模块化的 R6 接口，用于具体实现反事实解释方法。通过实现三种方法并推广到不同的情境中，结合真实用例，此方法能够快速准确地得出有关如何更改单个观测值的特征值以获得所需预测的信息。

    

    反事实解释方法提供有关如何更改单个观测值的特征值以获得所需预测的信息。尽管研究中提出了越来越多的方法，但只有少数具有广泛变化的接口和要求的实现存在。在本文中，我们介绍 counterfactuals R 包，它提供了一个基于 R6 的模块化和统一的接口，用于反事实解释方法。我们已经实现了三种现有的反事实解释方法，并提出了一些可选的方法学扩展，以将这些方法推广到不同的场景并使其更具可比性。我们使用真实用例解释了包的结构和工作流程，并展示了如何将其他反事实解释方法集成到包中。此外，我们针对各种模型和数据集比较了实施的方法，以评估其反事实解释的质量和运行时行为。

    Counterfactual explanation methods provide information on how feature values of individual observations must be changed to obtain a desired prediction. Despite the increasing amount of proposed methods in research, only a few implementations exist whose interfaces and requirements vary widely. In this work, we introduce the counterfactuals R package, which provides a modular and unified R6-based interface for counterfactual explanation methods. We implemented three existing counterfactual explanation methods and propose some optional methodological extensions to generalize these methods to different scenarios and to make them more comparable. We explain the structure and workflow of the package using real use cases and show how to integrate additional counterfactual explanation methods into the package. In addition, we compared the implemented methods for a variety of models and datasets with regard to the quality of their counterfactual explanations and their runtime behavior.
    
[^39]: 不考虑图骨架的组合因果赌博机

    Combinatorial Causal Bandits without Graph Skeleton. (arXiv:2301.13392v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13392](http://arxiv.org/abs/2301.13392)

    本文研究了在二值一般因果模型和BGLMs上不考虑图骨架的组合因果赌博机问题，提出了可在BGLMs上实现的无需图骨架的遗憾最小化算法，达到了与依赖于图结构的最先进算法相同的渐进遗憾率$O(\sqrt{T}\ln T)$。

    

    在组合因果赌博机问题中，学习代理在每一轮选择一组变量进行干预，收集观测变量的反馈以最小化期望遗憾或样本复杂度。先前的工作研究了一般因果模型和二值广义线性模型（BGLMs）中的问题。但是，它们都需要先验知识来构建因果关系图。本文研究了在二值一般因果模型和BGLMs上不考虑图骨架的组合因果赌博机问题。我们首先在一般因果模型上提供了累积遗憾的指数下限。然后，我们设计了一种无需图骨架来实现BGLMs的遗憾最小化算法，表明它仍然达到$O(\sqrt{T}\ln T)$的期望遗憾。这个渐进的遗憾率与依赖于图结构的最先进算法相同。

    In combinatorial causal bandits (CCB), the learning agent chooses a subset of variables in each round to intervene and collects feedback from the observed variables to minimize expected regret or sample complexity. Previous works study this problem in both general causal models and binary generalized linear models (BGLMs). However, all of them require prior knowledge of causal graph structure. This paper studies the CCB problem without the graph structure on binary general causal models and BGLMs. We first provide an exponential lower bound of cumulative regrets for the CCB problem on general causal models. To overcome the exponentially large space of parameters, we then consider the CCB problem on BGLMs. We design a regret minimization algorithm for BGLMs even without the graph skeleton and show that it still achieves $O(\sqrt{T}\ln T)$ expected regret. This asymptotic regret is the same as the state-of-art algorithms relying on the graph structure. Moreover, we sacrifice the regret t
    
[^40]: 假设简约的变量重要性检验的投影协方差测量

    The Projected Covariance Measure for assumption-lean variable significance testing. (arXiv:2211.02039v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2211.02039](http://arxiv.org/abs/2211.02039)

    该论文介绍了一种假设简约的变量重要性检验方法，利用非参数或机器学习方法实现稳健的误差控制和高功效。

    

    在统计学中，对于给定附加协变量Z，测试变量或变量组X对于预测响应Y的重要性是一项普遍任务。一种简单但常见的方法是指定一个线性模型，然后测试X的回归系数是否为非零。然而，当模型错误指定时，测试的功效可能很差，例如当X参与复杂的交互作用，或者导致许多错误拒绝。在这项工作中，我们研究了测试条件均值独立的无模型假设，即给定X和Z，Y的条件均值不依赖于X。我们提出了一个简单而通用的框架，可以利用灵活的非参数或机器学习方法，如加法模型或随机森林，实现稳健的误差控制和高功效。该过程包括使用这些方法进行回归，首先使用一半的数据估计以X和Z为基础的Y的一种投影形式。

    Testing the significance of a variable or group of variables $X$ for predicting a response $Y$, given additional covariates $Z$, is a ubiquitous task in statistics. A simple but common approach is to specify a linear model, and then test whether the regression coefficient for $X$ is non-zero. However, when the model is misspecified, the test may have poor power, for example when $X$ is involved in complex interactions, or lead to many false rejections. In this work we study the problem of testing the model-free null of conditional mean independence, i.e. that the conditional mean of $Y$ given $X$ and $Z$ does not depend on $X$. We propose a simple and general framework that can leverage flexible nonparametric or machine learning methods, such as additive models or random forests, to yield both robust error control and high power. The procedure involves using these methods to perform regressions, first to estimate a form of projection of $Y$ on $X$ and $Z$ using one half of the data, an
    
[^41]: 差分隐私对分类公平性的影响有限

    Differential Privacy has Bounded Impact on Fairness in Classification. (arXiv:2210.16242v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.16242](http://arxiv.org/abs/2210.16242)

    本文理论上研究了差分隐私对分类公平性的影响。证明了在给定模型类的情况下，流行的群体公平度量是关于模型参数点值利普希茨连续的。非渐近界限表明，随着样本数量的增加，私有模型的公平度越来越接近于非私有模型的公平度，也突显了模型的置信边界对差分隐私的不对等影响的重要性。

    

    我们在理论上研究了差分隐私对分类公平性的影响。我们证明，在给定模型类的情况下，流行的群体公平度量是关于模型参数点值利普希茨连续的。这个结果是一个更一般的关于在任意事件条件下（比如属于敏感群体）准确性的声明的结果，可能有独立的兴趣。我们利用这个利普希茨性质证明了一个非渐近界限，它表明随着样本数量的增加，私有模型的公平度越来越接近于非私有模型的公平度。这个界限还突显了模型的置信边界对差分隐私的不对等影响的重要性。

    We theoretically study the impact of differential privacy on fairness in classification. We prove that, given a class of models, popular group fairness measures are pointwise Lipschitz-continuous with respect to the parameters of the model. This result is a consequence of a more general statement on accuracy conditioned on an arbitrary event (such as membership to a sensitive group), which may be of independent interest. We use this Lipschitz property to prove a non-asymptotic bound showing that, as the number of samples increases, the fairness level of private models gets closer to the one of their non-private counterparts. This bound also highlights the importance of the confidence margin of a model on the disparate impact of differential privacy.
    
[^42]: 均场神经网络：学习Wasserstein空间上的映射

    Mean-field neural networks: learning mappings on Wasserstein space. (arXiv:2210.15179v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.15179](http://arxiv.org/abs/2210.15179)

    本文研究了均场神经网络在学习概率测度的Wasserstein空间和函数空间之间的映射中的应用。提出了两类神经网络，通过通用逼近定理理论支持，并通过数值实验展示了其准确性和效率。此外，还提出了依赖于均场神经网络的算法来解决时间相关的均场问题。

    

    我们研究了在概率测度的Wasserstein空间和函数空间之间进行映射的模型的机器学习任务，例如在均场博弈/控制问题中。提出了两类基于二进制密度和圆柱逼近的神经网络，用于学习这些所谓的均场函数，并在理论上获得了通用逼近定理的支持。我们进行了几个数值实验来训练这两个均场神经网络，并展示了它们在各种测试分布中的准确性和效率以及泛化误差。最后，我们提出了依赖于均场神经网络的不同算法来解决时间相关的均场问题，并通过数值测试在概率测度的Wasserstein空间中的半线性偏微分方程的例子来说明我们的结果。

    We study the machine learning task for models with operators mapping between the Wasserstein space of probability measures and a space of functions, like e.g. in mean-field games/control problems. Two classes of neural networks, based on bin density and on cylindrical approximation, are proposed to learn these so-called mean-field functions, and are theoretically supported by universal approximation theorems. We perform several numerical experiments for training these two mean-field neural networks, and show their accuracy and efficiency in the generalization error with various test distributions. Finally, we present different algorithms relying on mean-field neural networks for solving time-dependent mean-field problems, and illustrate our results with numerical tests for the example of a semi-linear partial differential equation in the Wasserstein space of probability measures.
    
[^43]: TabPFN：在一秒内解决小型表格分类问题的Transformer

    TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second. (arXiv:2207.01848v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.01848](http://arxiv.org/abs/2207.01848)

    TabPFN是一种可以在不到一秒钟内完成小型表格数据集的监督分类的Transformer，无需超参数调整，并且具有竞争力。它使用先验适应网络（PFN）逼近基于先验的贝叶斯推断，先验融合了因果推理的思想。

    

    本文提出了TabPFN，一种经过训练的Transformer，可以在不到一秒钟的时间内完成小型表格数据集的监督分类，无需超参数调整，并且在分类方法的最新状态下具有竞争力。TabPFN完全包含在我们网络的权重中，接受训练和测试样本作为设置值输入，并在单个前向传递中为整个测试集提供预测。TabPFN是一种先验适应网络（PFN），只需要线下训练一次，即可逼近基于我们的先验的合成数据集上的贝叶斯推断。这个先验融合了因果推理的思想：它包括一个大的结构因果模型空间，偏好于简单结构。在OpenML-CC18套件的18个包含最多1000个训练数据点、最多100个纯数值特征且无缺失值、最多10个类别的数据集中，我们展示了我们的方法明显优于提升树，与复杂的最新AutoM方法表现相当。

    We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoM
    
[^44]: 信息论和变分推断中的基于平方和松弛的方法

    Sum-of-Squares Relaxations for Information Theory and Variational Inference. (arXiv:2206.13285v3 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2206.13285](http://arxiv.org/abs/2206.13285)

    本论文研究了基于平方和松弛方法在信息论和变分推断中的应用。通过使用这种方法，我们提出了计算$f$-divergences的凸松弛算法，其中涉及到从非局部协方差矩阵计算这些divergences的问题。这些结果对于数据科学中的多个应用具有重要意义。

    

    我们考虑了香农相对熵的扩展，称为$f$-divergences。这些divergences通常与三个经典的相关计算问题相关联：（a）从矩估计，（b）计算归一化积分，以及（c）概率模型的变分推断。这些问题通过凸对偶性相互关联，对于所有这些问题，都有许多数据科学中的应用，并且我们旨在提出能够保持原始问题特性（如潜在凸性或单调性）的计算上可行的近似算法。为了实现这一目标，我们从与给定特征向量相关的非局部协方差矩阵计算这些divergences的一系列凸松弛开始：从通常不易处理的最优下界开始，我们考虑了一个额外的基于“平方和”的松弛，它现在作为半定规划可以在多项式时间内计算。

    We consider extensions of the Shannon relative entropy, referred to as $f$-divergences.Three classical related computational problems are typically associated with these divergences: (a) estimation from moments, (b) computing normalizing integrals, and (c) variational inference in probabilistic models. These problems are related to one another through convex duality, and for all them, there are many applications throughout data science, and we aim for computationally tractable approximation algorithms that preserve properties of the original problem such as potential convexity or monotonicity. In order to achieve this, we derive a sequence of convex relaxations for computing these divergences from non-centered covariance matrices associated with a given feature vector: starting from the typically non-tractable optimal lower-bound, we consider an additional relaxation based on ``sums-of-squares'', which is is now computable in polynomial time as a semidefinite program. We also provide c
    
[^45]: 多重检验框架用于离群分布检测

    Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.09522](http://arxiv.org/abs/2206.09522)

    本研究提出了一个多重检验框架用于离群分布检测的问题，包括了定义OOD概念和提供强有力保证的方法，与之前的基于阈值的测试相比，在不同类型的OOD实例中表现更一致。

    

    我们研究离群分布（OOD）检测的问题，即在推理时检测学习算法的输出是否可信。尽管之前的工作中提出了一些OOD检测的测试方法，但缺乏一个形式化的框架来研究这个问题。我们提出了一个OOD概念的定义，包括输入分布和学习算法，这为构建强大的OOD检测测试提供了启示。我们提出了一种多重假设检验启发的过程，使用符合性p值系统地结合学习算法中的任意数量的不同统计量。我们进一步对将入群样本错误分类为OOD的概率提供了强有力的保证。在实验中，我们发现之前工作中提出的基于阈值的测试在特定场景下表现良好，但在不同类型的OOD实例中的表现并不一致。相比之下，我们提出的方法结合了m个不同统计量。

    We study the problem of Out-of-Distribution (OOD) detection, that is, detecting whether a learning algorithm's output can be trusted at inference time. While a number of tests for OOD detection have been proposed in prior work, a formal framework for studying this problem is lacking. We propose a definition for the notion of OOD that includes both the input distribution and the learning algorithm, which provides insights for the construction of powerful tests for OOD detection. We propose a multiple hypothesis testing inspired procedure to systematically combine any number of different statistics from the learning algorithm using conformal p-values. We further provide strong guarantees on the probability of incorrectly classifying an in-distribution sample as OOD. In our experiments, we find that threshold-based tests proposed in prior work perform well in specific settings, but not uniformly well across different types of OOD instances. In contrast, our proposed method that combines m
    
[^46]: 解决公平分类中战略操纵的差异

    Addressing Strategic Manipulation Disparities in Fair Classification. (arXiv:2205.10842v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2205.10842](http://arxiv.org/abs/2205.10842)

    该论文研究了公平分类中存在的战略操纵差异问题，提出了一个受约束的优化框架来解决这个问题。

    

    在现实世界的分类环境中，如贷款申请评估或在线平台上的内容审查，个体通过战略性地更新其特征来增加其获得特定（积极）决策的可能性（以一定的成本）。然而，当不同人口群体具有不同的特征分布或支付不同的更新成本时，先前的研究表明，来自少数群体的个体付出更高的成本来更新其特征。公平分类旨在通过限制分类器满足统计公平性属性来解决此类分类器性能差异。然而，我们发现标准的公平性约束并不能确保受约束的分类器减少战略操纵成本的差异。为了解决战略环境中的这种偏差并为战略操纵提供平等机会，我们提出了一个受约束的优化框架，构建分类器。

    In real-world classification settings, such as loan application evaluation or content moderation on online platforms, individuals respond to classifier predictions by strategically updating their features to increase their likelihood of receiving a particular (positive) decision (at a certain cost). Yet, when different demographic groups have different feature distributions or pay different update costs, prior work has shown that individuals from minority groups often pay a higher cost to update their features. Fair classification aims to address such classifier performance disparities by constraining the classifiers to satisfy statistical fairness properties. However, we show that standard fairness constraints do not guarantee that the constrained classifier reduces the disparity in strategic manipulation cost. To address such biases in strategic settings and provide equal opportunities for strategic manipulation, we propose a constrained optimization framework that constructs classif
    
[^47]: 带有傅立叶容量条件的正则化最小二乘问题的最优学习率

    Optimal Learning Rates for Regularized Least-Squares with a Fourier Capacity Condition. (arXiv:2204.07856v4 [math.ST] UPDATED)

    [http://arxiv.org/abs/2204.07856](http://arxiv.org/abs/2204.07856)

    本论文研究了具有傅立叶容量条件的正则化最小二乘问题的最优学习率，通过插值理论和新的傅立叶等容性条件，我们推导出了广泛类别的Tikhonov正则化学习问题的最小化自适应率，不需要回归函数包含在假设集中。

    

    我们在Hilbert空间中的广泛类别的Tikhonov正则化学习问题中推导出最小化自适应率，不需要回归函数包含在假设集中，并且最重要的是不使用传统的内核特征衰减的先验假设。通过插值理论，我们证明了在适当的Hilbert空间的“紧”$L^{\infty}(\mathcal{X})$嵌入的情况下，可以推断出Mercer算子的频谱。我们的分析利用了一种新的傅立叶等容性条件，通过最优Hilbert尺度函数捕捉了内核Dirichlet容量和小球概率之间的相互作用。

    We derive minimax adaptive rates for a new, broad class of Tikhonov-regularized learning problems in Hilbert scales under general source conditions. Our analysis does not require the regression function to be contained in the hypothesis class, and most notably does not employ the conventional \textit{a priori} assumptions on kernel eigendecay. Using the theory of interpolation, we demonstrate that the spectrum of the Mercer operator can be inferred in the presence of ``tight'' $L^{\infty}(\mathcal{X})$ embeddings of suitable Hilbert scales. Our analysis utilizes a new Fourier isocapacitary condition, which captures the interplay of the kernel Dirichlet capacities and small ball probabilities via the optimal Hilbert scale function.
    
[^48]: 当AUC遇上DRO：基于非凸收敛保证的深度学习局部AUC优化

    When AUC meets DRO: Optimizing Partial AUC for Deep Learning with Non-Convex Convergence Guarantee. (arXiv:2203.00176v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.00176](http://arxiv.org/abs/2203.00176)

    本文提出了一种基于梯度的方法，通过分布鲁棒优化（DRO）来最大化深度学习中的局部AUC（pAUC），并提出了准确和平滑的pAUC估计量。实验证明了该方法在各种数据集上的有效性。

    

    本文提出了用于深度学习的一种系统且高效的基于梯度的一次性和二次性局部AUC（pAUC）最大化方法。我们通过使用分布鲁棒优化（DRO）来为每个单独的正数据定义损失，提出了pAUC替代目标的新公式。我们考虑了两种DRO的形式，一种基于条件风险值（CVaR），产生非平滑但准确的pAUC估计量；另一种基于KL散度正则化的DRO，产生不准确但平滑（软）的pAUC估计量。对于一次性和二次性pAUC最大化，我们分别提出了两种算法，并证明了它们对于优化各自的两种形式的收敛性。实验证明了提出的算法在各种数据集上对于深度学习中的pAUC最大化的有效性。

    In this paper, we propose systematic and efficient gradient-based methods for both one-way and two-way partial AUC (pAUC) maximization that are applicable to deep learning. We propose new formulations of pAUC surrogate objectives by using the distributionally robust optimization (DRO) to define the loss for each individual positive data. We consider two formulations of DRO, one of which is based on conditional-value-at-risk (CVaR) that yields a non-smooth but exact estimator for pAUC, and another one is based on a KL divergence regularized DRO that yields an inexact but smooth (soft) estimator for pAUC. For both one-way and two-way pAUC maximization, we propose two algorithms and prove their convergence for optimizing their two formulations, respectively. Experiments demonstrate the effectiveness of the proposed algorithms for pAUC maximization for deep learning on various datasets.
    
[^49]: 自适应鲁棒的多任务学习

    Adaptive and Robust Multi-Task Learning. (arXiv:2202.05250v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.05250](http://arxiv.org/abs/2202.05250)

    本文提出一系列自适应方法，能够同时处理多任务学习的相似性和差异性，并具有统计保证和鲁棒性。

    

    本论文研究了解决从不同来源收集的多个数据集并对每个数据集学习一个模型的多任务学习问题。我们提出了一系列自适应方法，自动利用任务之间的相似性，同时处理它们之间的差异。我们证明了这些方法的统计保证，并证明它们对异常任务具有鲁棒性。通过合成和实际数据集的数值实验，证明了我们的新方法的功效。

    We study the multi-task learning problem that aims to simultaneously analyze multiple datasets collected from different sources and learn one model for each of them. We propose a family of adaptive methods that automatically utilize possible similarities among those tasks while carefully handling their differences. We derive sharp statistical guarantees for the methods and prove their robustness against outlier tasks. Numerical experiments on synthetic and real datasets demonstrate the efficacy of our new methods.
    
[^50]: 一类无维度度量用于经验测度的收敛性

    A Class of Dimension-free Metrics for the Convergence of Empirical Measures. (arXiv:2104.12036v4 [math.PR] UPDATED)

    [http://arxiv.org/abs/2104.12036](http://arxiv.org/abs/2104.12036)

    本文提出了一类无维度度量，用于高维情况下经验测度的收敛性，解决了维度灾难问题，具有重要的实际应用。

    

    本文研究高维情况下经验测度的收敛性。我们提出了一种新的概率度量类，证明在这种度量下，收敛性不受维度灾难的影响。这种特性对于高维分析至关重要，与经典度量（如Wasserstein度量）形成对比。所提出的度量属于积分概率度量的范畴，我们指定了测试函数空间的准则，以确保不受维度灾难影响。所选测试函数空间的例子包括再生核希尔伯特空间、Barron空间和流诱导函数空间。我们提供了所提出度量的三个应用：1. 在随机变量情况下的经验测度收敛性；2. n粒子系统收敛于McKean-Vlasov随机微分方程的解；3. 构造齐次n-player的ε-Nash均衡。

    This paper concerns the convergence of empirical measures in high dimensions. We propose a new class of probability metrics and show that under such metrics, the convergence is free of the curse of dimensionality (CoD). Such a feature is critical for high-dimensional analysis and stands in contrast to classical metrics ({\it e.g.}, the Wasserstein metric). The proposed metrics fall into the category of integral probability metrics, for which we specify criteria of test function spaces to guarantee the property of being free of CoD. Examples of the selected test function spaces include the reproducing kernel Hilbert spaces, Barron space, and flow-induced function spaces. Three applications of the proposed metrics are presented: 1. The convergence of empirical measure in the case of random variables; 2. The convergence of $n$-particle system to the solution to McKean-Vlasov stochastic differential equation; 3. The construction of an $\varepsilon$-Nash equilibrium for a homogeneous $n$-pl
    
[^51]: 一个通用框架用于PAC-Bayesian界的实用解读

    A General Framework for the Practical Disintegration of PAC-Bayesian Bounds. (arXiv:2102.08649v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2102.08649](http://arxiv.org/abs/2102.08649)

    该论文提出了一种新的PAC-Bayesian泛化界的框架，该框架能够提供解离界，相比现有框架在神经网络上有显著的实用改进。

    

    PAC-Bayesian界在研究随机分类器的泛化能力时已被证明紧凑而且有信息量。然而，当应用于一些确定性模型家族（如神经网络）时，它们需要松弛且昂贵的去随机化步骤。作为替代步骤，我们引入了新的PAC-Bayesian泛化界，这些界独具创新性，能够提供解离界，即它们能够对一个单一假设提供保证，而不是通常的平均分析。我们的界易于优化，并可用于设计学习算法。我们在神经网络上展示了这种行为，并展示了与现有框架相比的显著实用改进。

    PAC-Bayesian bounds are known to be tight and informative when studying the generalization ability of randomized classifiers. However, they require a loose and costly derandomization step when applied to some families of deterministic models such as neural networks. As an alternative to this step, we introduce new PAC-Bayesian generalization bounds that have the originality to provide disintegrated bounds, i.e., they give guarantees over one single hypothesis instead of the usual averaged analysis. Our bounds are easily optimizable and can be used to design learning algorithms. We illustrate this behavior on neural networks, and we show a significant practical improvement over the state-of-the-art framework.
    
[^52]: 懒惰型在线凸优化: 切换预算下的研究

    Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.03803](http://arxiv.org/abs/2102.03803)

    本研究提出了一种懒惰型在线凸优化的算法，其在切换次数有限的情况下达到了近似最优的遗憾上界，并且在连续设置中呈现出高效的计算性能。

    

    我们研究了一种在线凸优化的变种，其中玩家在T轮中的期望切换决策不超过S次。之前的研究已经解决了离散决策设置中的类似问题，最近也在连续设置中使用自适应对手进行了研究。在本研究中，我们旨在填补这一空白，并在普遍存在的无知设置中提出计算有效的算法，为一般凸损失建立了O(T/S)的遗憾上界以及强凸损失的近似O(T/S^2)的遗憾上界。此外，对于随机独立同分布的损失，我们提出了一种简单的算法，在一般和强凸设置中遗憾仅有对数因子的乘法log T的情况下进行了log T次切换。最后，我们补充了与我们考虑的一些情况相匹配的下界来补充我们的算法。

    We study a variant of online convex optimization where the player is permitted to switch decisions at most $S$ times in expectation throughout $T$ rounds. Similar problems have been addressed in prior work for the discrete decision set setting, and more recently in the continuous setting but only with an adaptive adversary. In this work, we aim to fill the gap and present computationally efficient algorithms in the more prevalent oblivious setting, establishing a regret bound of $O(T/S)$ for general convex losses and $\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches with only a multiplicative $\log T$ factor overhead in its regret in both the general and strongly convex settings. Finally, we complement our algorithms with lower bounds that match our upper bounds in some of the cases we consider.
    
[^53]: 风险敏感的深度强化学习：方差约束的演员-评论家算法能够找到全局最优策略

    Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds Globally Optimal Policy. (arXiv:2012.14098v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.14098](http://arxiv.org/abs/2012.14098)

    本文首次尝试在平均奖励设置下，通过方差风险准则研究风险敏感的深度强化学习。我们提出了一个方差约束的策略优化问题，并设计了一种演员-评论家算法来解决该问题。

    

    尽管深度强化学习在各种应用中取得了巨大成功，但大多数现有工作仅关注最大化总回报的期望值，从而忽略了其固有的随机性。这种随机性也被称为不确定性，并与风险的概念密切相关。本文首次尝试在平均奖励设置下，通过方差风险准则研究风险敏感的深度强化学习。具体而言，我们关注一个方差约束的策略优化问题，目标是找到一个策略，最大化长期平均奖励的期望值，并且使得长期平均奖励的方差上界不超过某个阈值。利用Lagrange和Fenchel对偶性，我们将原始问题转化为一个无约束的鞍点策略优化问题，并提出了一种迭代和高效更新策略的演员-评论家算法。

    While deep reinforcement learning has achieved tremendous successes in various applications, most existing works only focus on maximizing the expected value of total return and thus ignore its inherent stochasticity. Such stochasticity is also known as the aleatoric uncertainty and is closely related to the notion of risk. In this work, we make the first attempt to study risk-sensitive deep reinforcement learning under the average reward setting with the variance risk criteria. In particular, we focus on a variance-constrained policy optimization problem where the goal is to find a policy that maximizes the expected value of the long-run average reward, subject to a constraint that the long-run variance of the average reward is upper bounded by a threshold. Utilizing Lagrangian and Fenchel dualities, we transform the original problem into an unconstrained saddle-point policy optimization problem, and propose an actor-critic algorithm that iteratively and efficiently updates the policy,
    
[^54]: 基于上下文感知的先进胶囊网络

    Advanced Capsule Networks via Context Awareness. (arXiv:1903.07497v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1903.07497](http://arxiv.org/abs/1903.07497)

    本研究通过增加池化层和重建层来改进胶囊网络（CN）的设计，以适应具有不同上下文的图像数据集，并与深度学习（DL）模型进行了性能对比。结果显示，CN在大大减少训练时间的同时表现出了与DL模型相当的性能。

    

    胶囊网络（CN）为深度学习（DL）社区提供了新的架构。尽管它的有效性已经在MNIST和smallNORB数据集中得到了证明，但是对于具有不同上下文的图像的数据集，该网络仍然面临挑战。在这项研究中，我们改进了CN（向量版本）的设计，具体来说，我们增加了更多的池化层来过滤图像背景，并增加了更多的重建层来实现更好的图像恢复。此外，我们进行了实验，比较了CN和DL模型的准确性和速度。在DL模型中，除了在强大的计算机上使用Inception V3和DenseNet V201外，我们还使用了NASNet、MobileNet V1和MobileNet V2来适用于小型和嵌入式设备。我们在美国手语（ASL）的手指拼写字母数据集上评估了我们的模型。结果表明，CN与DL模型相比，在大大减少训练时间的同时表现出了可比较的性能。我们还进行了演示，并提供了一个链接以进行说明。

    Capsule Networks (CN) offer new architectures for Deep Learning (DL) community. Though its effectiveness has been demonstrated in MNIST and smallNORB datasets, the networks still face challenges in other datasets for images with distinct contexts. In this research, we improve the design of CN (Vector version) namely we expand more Pooling layers to filter image backgrounds and increase Reconstruction layers to make better image restoration. Additionally, we perform experiments to compare accuracy and speed of CN versus DL models. In DL models, we utilize Inception V3 and DenseNet V201 for powerful computers besides NASNet, MobileNet V1 and MobileNet V2 for small and embedded devices. We evaluate our models on a fingerspelling alphabet dataset from American Sign Language (ASL). The results show that CNs perform comparably to DL models while dramatically reducing training time. We also make a demonstration and give a link for the purpose of illustration.
    

