# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Reduced Order Modeling of a MOOSE-based Advanced Manufacturing Model with Operator Learning.](http://arxiv.org/abs/2308.09691) | 本文旨在开发一个基于MOOSE的先进制造模型的准确且运行速度快的降阶模型（ROM），该模型可以在基于DRL的过程控制和优化方法中使用。使用运算符学习（OL）方法，学习一族由改变的过程变量产生的微分方程。 |
| [^2] | [Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction.](http://arxiv.org/abs/2308.09647) | 这篇论文介绍了一种名为MC-CP的新型混合不确定性量化方法，通过将自适应蒙特卡洛dropout方法与合规预测相结合，实现了节省资源和产生鲁棒预测集/区间的目标。实验证明MC-CP在分类任务中相比其他先进方法具有显著提升 |
| [^3] | [Solving PDEs on Spheres with Physics-Informed Convolutional Neural Networks.](http://arxiv.org/abs/2308.09605) | 本文严格分析了在球面上解决PDEs的物理信息卷积神经网络（PICNN），通过使用最新的逼近结果和球谐分析，证明了逼近误差与Sobolev范数的上界，并建立了快速收敛速率。实验结果也验证了理论分析的有效性。 |
| [^4] | [Normalization Is All You Need: Understanding Layer-Normalized Federated Learning under Extreme Label Shift.](http://arxiv.org/abs/2308.09565) | 本论文揭示了层归一化和联邦学习中的标签偏移问题之间的深刻联系，通过在联邦学习中应用特征归一化，使得对严重倾斜的数据集进行加速全局训练，从而在极端标签偏移下获得显著改进。 |
| [^5] | [A Principle for Global Optimization with Gradients.](http://arxiv.org/abs/2308.09556) | 该论文通过分析在具有许多次优局部最小值的可微函数的全局优化中利用梯度的原理，展示了梯度在全局优化中的实用性，并进行了相应的实验研究。 |
| [^6] | [Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling.](http://arxiv.org/abs/2308.09460) | 本文提出了一种加速贝叶斯推断方法，用于解决具有凸几何的成像逆问题。该方法通过随机弛缓纵坐标迭代实现，对于高斯目标是渐近无偏的，并且对于$\kappa$-强对数凹的任何目标都能以加速方式收敛。 |
| [^7] | [An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And Gaussian Mixture Embedding For Neural Network.](http://arxiv.org/abs/2308.09444) | 我们提出了一种高斯混合模型的学习算法，具有更好的鲁棒性和简单性，只需要进行1次迭代学习。我们的方法能更好地处理数据不确定性和逆问题，并且有潜力构建能够利用分布随机抽样进行随机变异和变异控制的应用。 |
| [^8] | [Noise Sensitivity and Stability of Deep Neural Networks for Binary Classification.](http://arxiv.org/abs/2308.09374) | 本文通过研究深度神经网络分类器的噪声敏感性和稳定性，对非鲁棒性现象进行了探索，并澄清了这些概念的定义和关系。 |
| [^9] | [A tailored Handwritten-Text-Recognition System for Medieval Latin.](http://arxiv.org/abs/2308.09368) | 这个论文提出了一个针对中世纪拉丁语词典的定制手写文本识别系统，通过引入端到端的流水线和最新的图像分割模型，成功地定位、提取和转录引文，并且通过使用Transformer模型和数据增强等方法，实现了优于现有技术的字符错误率。 |
| [^10] | [Path Signatures for Seizure Forecasting.](http://arxiv.org/abs/2308.09312) | 本研究以癫痫预测为目标，通过自动发现和量化患者特定的统计特征，特别是最新的路径签名算法，探索其在癫痫预测中的性能，为个性化的癫痫预测解决方案提供了参考。 |
| [^11] | [Active and Passive Causal Inference Learning.](http://arxiv.org/abs/2308.09248) | 这篇论文介绍了主动和被动因果推断学习的重要假设和技术，并以讨论因果推断的缺失方面结束，为读者提供了一个多样性起点。 |
| [^12] | [Path convergence of Markov chains on large graphs.](http://arxiv.org/abs/2308.09214) | 本文研究了大图上的马尔可夫链收敛性。通过研究欧几里德随机优化算法和Metropolis MCMC算法的改进版本在图上的表现，我们得出了随着图大小趋近于无穷大，随机过程的轨迹会收敛到确定性极限的结论。这些极限是测度值图上的曲线，通过引入新的度量，在这个空间中提供了自然的收敛概念。 |
| [^13] | [RTB Formulation Using Point Process.](http://arxiv.org/abs/2308.09122) | 本文提出了一种使用点过程进行实时投标（RTB）生态系统中重复拍卖建模的通用随机框架。该框架灵活性高，可应用于各种拍卖场景，并提出了可将该过程近似为泊松点过程的理论结果。此外，考虑效用和市场条件的联合分布是至关重要的。 |
| [^14] | [Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage.](http://arxiv.org/abs/2308.09113) | 多保真度傅里叶神经算子用于解决大规模地质碳储存问题，通过利用经济性更高的多保真度训练数据集，能够以与高保真度模型相当的准确性进行预测。 |
| [^15] | [Spectral information criterion for automatic elbow detection.](http://arxiv.org/abs/2308.09108) | 提出了一种谱信息准则（SIC），可以作为自动肘部检测器，提取了误差曲线的几何特征，并给出了选择唯一模型的实用规则。 |
| [^16] | [A comprehensive study of spike and slab shrinkage priors for structurally sparse Bayesian neural networks.](http://arxiv.org/abs/2308.09104) | 本论文研究了在贝叶斯神经网络中使用Lasso和Horseshoe两种缩减技术进行模型压缩的方法。为了实现结构稀疏，通过提出尖峰与块组稀疏Lasso和尖峰与块组Horseshoe先验，并开发了可计算的变分推断方法。该方法可以在保持推理效率的同时实现深度神经网络的模型压缩。 |
| [^17] | [Conditional Sampling of Variational Autoencoders via Iterated Approximate Ancestral Sampling.](http://arxiv.org/abs/2308.09078) | 本文提出了两种原始方法来解决变分自编码器（VAE）条件采样中的困难，并在采样任务中展示了改进性能。 |
| [^18] | [Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression.](http://arxiv.org/abs/2308.09065) | 本文提出了一种用于回归任务的广义AuxUE方案，目的是实现更鲁棒的不确定性量化。具体而言，该方案通过考虑不同的分布假设，选择Laplace分布来近似p，以实现更鲁棒的本质不确定性估计。 |
| [^19] | [Kernel-Based Tests for Likelihood-Free Hypothesis Testing.](http://arxiv.org/abs/2308.09043) | 本文介绍了一种基于核的无似然假设检验方法，解决了对已知属于两个类别的输入进行分类的问题，在无似然推断领域，通过将标记样本通过正向模拟获得，未标记样本通过实验收集，给出了一个权衡m和n的方法。 |
| [^20] | [Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models.](http://arxiv.org/abs/2308.08977) | 本文研究了应用于广义线性模型和多索引模型中的流式随机梯度下降（SGD）的学习动力学。通过建立了一个普通微分方程系统来描述风险和次优性度量等统计量，获得了稳定性学习率阈值和收敛保证。同时，引入了一个简化扩散系数的随机微分方程模型，用于分析SGD迭代的统计动力学。通过标准示例和数值模拟，验证了该理论的有效性。 |
| [^21] | [Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games.](http://arxiv.org/abs/2308.08858) | 本文提出了一种模型自由的算法，可以在零和马尔可夫博弈中实现与模型为基础算法相同的样本复杂度，首次证明了模型自由算法可以在时间段依赖性方面达到同样的优化效果。 |
| [^22] | [Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm.](http://arxiv.org/abs/2308.08852) | 通过双重交替方向乘子法 (ADMM) 和半平滑牛顿 (SSN) 基于增广对偶法 (ALM) 的方法，我们提出了一个高效算法来学习具有结构稀疏性的核心图形Lasso模型，该算法能够在大维度的任务中节省超过70\%的执行时间，并且具有较高的性能。 |
| [^23] | [Stochastic Controlled Averaging for Federated Learning with Communication Compression.](http://arxiv.org/abs/2308.08165) | 本文提出了两种压缩联邦学习算法(SCALLION和SCAFCOM)，通过重新审视经典的随机控制平均法并提出了等价但更高效/简化的形式，减少了上行通信成本。 |
| [^24] | [Properties of Discrete Sliced Wasserstein Losses.](http://arxiv.org/abs/2307.10352) | 本文研究了离散切割Wasserstein损失的性质，并探讨了其正则性和优化性质以及通过蒙特卡洛近似的方法。 |
| [^25] | [An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines.](http://arxiv.org/abs/2307.06542) | 本研究提出了一种通过受限玻尔兹曼机（RBMs）的二值图像去噪框架，该框架使用二次无约束二值优化（QUBO）形式的去噪目标，并且适用于量子退火。通过平衡训练的RBMs学习到的分布和噪声图像偏离的惩罚项，实现了去噪目标。通过进行实验，研究发现该方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。 |
| [^26] | [On Size-Independent Sample Complexity of ReLU Networks.](http://arxiv.org/abs/2306.01992) | 本文研究了ReLU神经网络的样本复杂度，给出了一个现有方法精细化的结果，实现了无深度依赖性的上界。 |
| [^27] | [Online Platt Scaling with Calibeating.](http://arxiv.org/abs/2305.00070) | 本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。 |
| [^28] | [Differential Good Arm Identification.](http://arxiv.org/abs/2303.07154) | 本文提出了DGAI算法，它可以在好手臂识别问题中通过深度学习的方式减少样本复杂性，并且在具有给定阈值的情况下进一步提高多臂赌博问题的性能。 |
| [^29] | [Denoising Diffusion Samplers.](http://arxiv.org/abs/2302.13834) | 去噪扩散采样器 (DDS) 近似地从非标准化概率密度函数中采样，并估计其标准化常数。 |
| [^30] | [Enhancement attacks in biomedical machine learning.](http://arxiv.org/abs/2301.01885) | 本研究针对生物医学机器学习中的可信度问题，通过开发增强攻击技术，成功地能够通过最小的特征改变显著提高分类器的预测性能，并保持原始数据和增强数据之间的高特征相似性。 |
| [^31] | [Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve.](http://arxiv.org/abs/2212.03905) | 本文介绍了一种名为多速率VAE（MR-VAE）的框架，可在单次训练中学习与不同β对应的最优参数，通过使用超网络将β映射到最优参数，以实现率失真曲线的完整训练。 |
| [^32] | [Neural Superstatistics for Bayesian Estimation of Dynamic Cognitive Model.](http://arxiv.org/abs/2211.13165) | 本研究提出了一种神经超统计学方法，用于贝叶斯估计动态认知模型。通过引入时间维度和超统计视角，可以有效地估计系统中的动态性质，并利用仿真和深度学习方法进行贝叶斯推理。该方法能够恢复时变和时不变参数，并在实验证明其有效性。 |
| [^33] | [The Geometry and Calculus of Losses.](http://arxiv.org/abs/2209.00238) | 本文从凸集的新角度系统地发展了损失函数理论，引入了一种自动合适的损失函数定义方法，并提供了损失和范数之间关系的新机会，以及凸集微积分下的损失插值方法。 |
| [^34] | [Forecasting Algorithms for Causal Inference with Panel Data.](http://arxiv.org/abs/2208.03489) | 该论文将深度神经网络算法应用于时间序列预测，以提高面板数据中的因果推断准确性。通过实验证明，该算法在各种情景下明显优于现有方法，为面板数据研究提供了新的方法和工具。 |
| [^35] | [Holistic Robust Data-Driven Decisions.](http://arxiv.org/abs/2207.09560) | 这篇论文提出了一种全面稳健的数据驱动公式，能够同时保护三个过拟合的源头：有限样本数据的统计误差、数据点的有限精度测量引起的数据噪声，以及被破坏的部分数据。 |
| [^36] | [Markovian Gaussian Process Variational Autoencoders.](http://arxiv.org/abs/2207.05543) | 本文提出了一种马尔科夫高斯过程变分自编码器（MGPVAE）模型，通过利用马尔科夫高斯过程的等效离散状态空间表示，并使用卡尔曼滤波和平滑技术实现了线性时间的GPVAE训练。在各种高维时间和时空任务中，该方法表现优异。 |
| [^37] | [High-dimensional limit theorems for SGD: Effective dynamics and critical scaling.](http://arxiv.org/abs/2206.04030) | 本文研究了高维极限下具有恒定步长的随机梯度下降算法（SGD）的可扩展极限，我们证明了当维度趋于无穷时，SGD的轨迹的极限定理。我们的方法允许选择要跟踪的总结统计量、初始化和步长，并且得到了球形（ODE）和扩散（SDE）极限。我们还展示了步长的临界尺度，这个尺度下，有效的球形动力学与梯度流相匹配，但是出现了一个新的修正项，改变了相图。这个有效动力学的不动点对应的扩散极限可能非常复杂。 |
| [^38] | [Locally Adaptive Algorithms for Multiple Testing with Network Structure, with Application to Genome-Wide Association Studies.](http://arxiv.org/abs/2203.11461) | 本文提出了一种基于网络结构的局部自适应结构学习算法，可将LD网络数据和多个样本的辅助数据整合起来，通过数据驱动的权重分配方法实现对多重检验的控制，并在网络数据具有信息量时具有更高的功效。 |
| [^39] | [Long-term Causal Inference Under Persistent Confounding via Data Combination.](http://arxiv.org/abs/2202.07234) | 本研究通过数据组合解决了长期治疗效果识别和估计中的持续未测量混淆因素挑战，并提出了三种新的识别策略和估计器。 |
| [^40] | [Minimax risk classifiers with 0-1 loss.](http://arxiv.org/abs/2201.06487) | 本论文介绍了最小化最大化风险分类器（MRCs），旨在通过最小化与可能包含基础分布的分布的不确定性集合相对应的最坏情况下的0-1损失来提供严格的性能保证。使用特征映射和特征核，MRCs在学习时具有强度普遍一致性，并且提供了高效的优化技术和准确的分类能力。 |
| [^41] | [A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit.](http://arxiv.org/abs/2011.14033) | 本文提供了一个新颖的、不需要调整指数参数的MNL-Contextual Bandit问题的简便在线学习算法。算法具有与该问题的最佳理论界限匹配的遗憾上界。 |
| [^42] | [Local Function Complexity for Active Learning via Mixture of Gaussian Processes.](http://arxiv.org/abs/1902.10664) | 本文通过利用局部函数复杂性（LFC）的估计，建立了一个局部结构复杂性的概念，并将其用于发展一个与模型无关的主动学习框架。通过使用基于高斯过程回归（GPR）的局部多项式平滑（LPS）模型的类比，使得该框架具有鲁棒性和可伸缩性。 |

# 详细

[^1]: 基于MOOSE的先进制造模型的降阶建模与运算符学习

    Reduced Order Modeling of a MOOSE-based Advanced Manufacturing Model with Operator Learning. (arXiv:2308.09691v1 [stat.ML])

    [http://arxiv.org/abs/2308.09691](http://arxiv.org/abs/2308.09691)

    本文旨在开发一个基于MOOSE的先进制造模型的准确且运行速度快的降阶模型（ROM），该模型可以在基于DRL的过程控制和优化方法中使用。使用运算符学习（OL）方法，学习一族由改变的过程变量产生的微分方程。

    

    先进制造（AM）因其在核材料领域的潜在应用而引起了核社区的广泛关注。一个挑战是通过在运行时控制制造过程来获得所需的材料性质。基于深度强化学习（DRL）的智能AM依赖于自动化的过程级控制机制，以生成用于改进最终产品性质的最佳设计变量和自适应系统设置。最近在爱达荷国家实验室（INL）的MOOSE框架中开发了一个用于直接能量沉积的高保真度热力机械模型。该工作的目标是为这个基于MOOSE的AM模型开发一个准确且运行速度快的降阶模型（ROM），以便在基于DRL的过程控制和优化方法中使用。由于它们能够学习一族由改变的过程变量产生的微分方程，因此将采用基于运算符学习（OL）的方法。

    Advanced Manufacturing (AM) has gained significant interest in the nuclear community for its potential application on nuclear materials. One challenge is to obtain desired material properties via controlling the manufacturing process during runtime. Intelligent AM based on deep reinforcement learning (DRL) relies on an automated process-level control mechanism to generate optimal design variables and adaptive system settings for improved end-product properties. A high-fidelity thermo-mechanical model for direct energy deposition has recently been developed within the MOOSE framework at the Idaho National Laboratory (INL). The goal of this work is to develop an accurate and fast-running reduced order model (ROM) for this MOOSE-based AM model that can be used in a DRL-based process control and optimization method. Operator learning (OL)-based methods will be employed due to their capability to learn a family of differential equations, in this work, produced by changing process variables 
    
[^2]: 使用合规的蒙特卡洛预测实现鲁棒的不确定性量化

    Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction. (arXiv:2308.09647v1 [cs.LG])

    [http://arxiv.org/abs/2308.09647](http://arxiv.org/abs/2308.09647)

    这篇论文介绍了一种名为MC-CP的新型混合不确定性量化方法，通过将自适应蒙特卡洛dropout方法与合规预测相结合，实现了节省资源和产生鲁棒预测集/区间的目标。实验证明MC-CP在分类任务中相比其他先进方法具有显著提升

    

    在安全关键应用中部署深度学习模型仍然是一项非常具有挑战性的任务，需要对这些模型的可靠运行提供保证。不确定性量化（UQ）方法估计每个预测的模型置信度，通过考虑随机性和模型错误规范化的影响来指导决策。尽管最先进的UQ方法取得了一些进展，但它们在计算上要么非常昂贵，要么产生保守的预测集/区间。我们引入了一种新的混合UQ方法MC-CP，它将一种新的自适应蒙特卡洛（MC）dropout方法与合规预测（CP）相结合。MC-CP在运行时自适应调节传统的MC dropout以节省内存和计算资源，使得预测可以被CP使用，得到鲁棒的预测集/区间。通过全面的实验，我们展示了MC-CP相比MC dropout、RAPS和CQR等先进的UQ方法能够显著改善分类性能

    Deploying deep learning models in safety-critical applications remains a very challenging task, mandating the provision of assurances for the dependable operation of these models. Uncertainty quantification (UQ) methods estimate the model's confidence per prediction, informing decision-making by considering the effect of randomness and model misspecification. Despite the advances of state-of-the-art UQ methods, they are computationally expensive or produce conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ method that combines a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP adaptively modulates the traditional MC dropout at runtime to save memory and computation resources, enabling predictions to be consumed by CP, yielding robust prediction sets/intervals. Throughout comprehensive experiments, we show that MC-CP delivers significant improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in classificati
    
[^3]: 使用物理信息卷积神经网络在球面上解决偏微分方程

    Solving PDEs on Spheres with Physics-Informed Convolutional Neural Networks. (arXiv:2308.09605v1 [math.NA])

    [http://arxiv.org/abs/2308.09605](http://arxiv.org/abs/2308.09605)

    本文严格分析了在球面上解决PDEs的物理信息卷积神经网络（PICNN），通过使用最新的逼近结果和球谐分析，证明了逼近误差与Sobolev范数的上界，并建立了快速收敛速率。实验结果也验证了理论分析的有效性。

    

    物理信息神经网络（PINNs）已被证明在解决各种实验角度中的偏微分方程（PDEs）方面非常高效。一些最近的研究还提出了针对表面，包括球面上的PDEs的PINN算法。然而，对于PINNs的数值性能，尤其是在表面或流形上的PINNs，仍然缺乏理论理解。本文中，我们对用于在球面上解决PDEs的物理信息卷积神经网络（PICNN）进行了严格分析。通过使用和改进深度卷积神经网络和球谐分析的最新逼近结果，我们证明了该逼近误差与Sobolev范数的上界。随后，我们将这一结果与创新的局部复杂度分析相结合，建立了PICNN的快速收敛速率。我们的理论结果也得到了实验的验证和补充。鉴于这些发现，

    Physics-informed neural networks (PINNs) have been demonstrated to be efficient in solving partial differential equations (PDEs) from a variety of experimental perspectives. Some recent studies have also proposed PINN algorithms for PDEs on surfaces, including spheres. However, theoretical understanding of the numerical performance of PINNs, especially PINNs on surfaces or manifolds, is still lacking. In this paper, we establish rigorous analysis of the physics-informed convolutional neural network (PICNN) for solving PDEs on the sphere. By using and improving the latest approximation results of deep convolutional neural networks and spherical harmonic analysis, we prove an upper bound for the approximation error with respect to the Sobolev norm. Subsequently, we integrate this with innovative localization complexity analysis to establish fast convergence rates for PICNN. Our theoretical results are also confirmed and supplemented by our experiments. In light of these findings, we expl
    
[^4]: 规范化就是你所需要的：理解极端标签偏移下的层归一化联邦学习

    Normalization Is All You Need: Understanding Layer-Normalized Federated Learning under Extreme Label Shift. (arXiv:2308.09565v1 [cs.LG])

    [http://arxiv.org/abs/2308.09565](http://arxiv.org/abs/2308.09565)

    本论文揭示了层归一化和联邦学习中的标签偏移问题之间的深刻联系，通过在联邦学习中应用特征归一化，使得对严重倾斜的数据集进行加速全局训练，从而在极端标签偏移下获得显著改进。

    

    层归一化（LN）是一个广泛采用的深度学习技术，特别在基础模型的时代。最近，已经证明LN在非独立同分布数据上的联邦学习（FL）中非常有效。然而，它为什么以及如何起作用仍然是个谜。在这项工作中，我们揭示了层归一化和联邦学习中的标签偏移问题之间的深刻联系。为了更好地理解FL中的层归一化，我们确定了规范化方法在FL中的关键贡献机制，称之为特征归一化（FN），它在分类器头之前将归一化应用于潜在特征表示。虽然LN和FN不会提高表达能力，但它们控制特征崩溃和局部过拟合，使得对严重倾斜的数据集进行加速全局训练。经验证明，规范化在极端标签偏移下可以引起标准基准的显著改进。此外，我们还进行了大量的割除研究。

    Layer normalization (LN) is a widely adopted deep learning technique especially in the era of foundation models. Recently, LN has been shown to be surprisingly effective in federated learning (FL) with non-i.i.d. data. However, exactly why and how it works remains mysterious. In this work, we reveal the profound connection between layer normalization and the label shift problem in federated learning. To understand layer normalization better in FL, we identify the key contributing mechanism of normalization methods in FL, called feature normalization (FN), which applies normalization to the latent feature representation before the classifier head. Although LN and FN do not improve expressive power, they control feature collapse and local overfitting to heavily skewed datasets, and thus accelerates global training. Empirically, we show that normalization leads to drastic improvements on standard benchmarks under extreme label shift. Moreover, we conduct extensive ablation studies to unde
    
[^5]: 具有梯度的全局优化原理

    A Principle for Global Optimization with Gradients. (arXiv:2308.09556v1 [math.OC])

    [http://arxiv.org/abs/2308.09556](http://arxiv.org/abs/2308.09556)

    该论文通过分析在具有许多次优局部最小值的可微函数的全局优化中利用梯度的原理，展示了梯度在全局优化中的实用性，并进行了相应的实验研究。

    

    这项工作展示了在具有许多次优局部最小值的可微函数的全局优化中，梯度的实用性。为此，分析了通过梯度生成非局部二次近似搜寻方向的原则。实验测量了非局部搜寻方向的质量以及提出的简化算法、协方差矩阵适应进化策略(CMA-ES)和随机重新初始化的Broyden-Fletcher-Goldfarb-Shanno(BFGS)方法的性能。

    This work demonstrates the utility of gradients for the global optimization of certain differentiable functions with many suboptimal local minima. To this end, a principle for generating search directions from non-local quadratic approximants based on gradients of the objective function is analyzed. Experiments measure the quality of non-local search directions as well as the performance of a proposed simplistic algorithm, of the covariance matrix adaptation evolution strategy (CMA-ES), and of a randomly reinitialized Broyden-Fletcher-Goldfarb-Shanno (BFGS) method.
    
[^6]: 加速贝叶斯成像的弛缓纵坐标兰氏抽样方法

    Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling. (arXiv:2308.09460v1 [stat.CO])

    [http://arxiv.org/abs/2308.09460](http://arxiv.org/abs/2308.09460)

    本文提出了一种加速贝叶斯推断方法，用于解决具有凸几何的成像逆问题。该方法通过随机弛缓纵坐标迭代实现，对于高斯目标是渐近无偏的，并且对于$\kappa$-强对数凹的任何目标都能以加速方式收敛。

    

    本文提出了一种新的加速贝叶斯推断方法，用于在具有凸几何的成像逆问题中进行贝叶斯推断。所提出的策略采用随机弛缓纵坐标迭代的形式，具有两种互补的解释方式。对于通过Moreau-Yosida平滑进行平滑或正则化的模型，该算法等价于目标后验分布上的隐式中点离散化过点兰氏扩散，对于高斯目标是渐近无偏的，并且对于$\kappa$-强对数凹（即需要大约$\sqrt{\kappa}$次迭代来收敛，类似于加速优化方案）的任何目标都收敛加速，与[M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935]相比，在高斯目标上只能证明加速。

    This paper presents a new accelerated proximal Markov chain Monte Carlo methodology to perform Bayesian inference in imaging inverse problems with an underlying convex geometry. The proposed strategy takes the form of a stochastic relaxed proximal-point iteration that admits two complementary interpretations. For models that are smooth or regularised by Moreau-Yosida smoothing, the algorithm is equivalent to an implicit midpoint discretisation of an overdamped Langevin diffusion targeting the posterior distribution of interest. This discretisation is asymptotically unbiased for Gaussian targets and shown to converge in an accelerated manner for any target that is $\kappa$-strongly log-concave (i.e., requiring in the order of $\sqrt{\kappa}$ iterations to converge, similarly to accelerated optimisation schemes), comparing favorably to [M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935] which is only provably accelerated for Gaussian target
    
[^7]: 一种高斯混合模型和神经网络的高效一次迭代学习算法

    An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And Gaussian Mixture Embedding For Neural Network. (arXiv:2308.09444v1 [cs.LG])

    [http://arxiv.org/abs/2308.09444](http://arxiv.org/abs/2308.09444)

    我们提出了一种高斯混合模型的学习算法，具有更好的鲁棒性和简单性，只需要进行1次迭代学习。我们的方法能更好地处理数据不确定性和逆问题，并且有潜力构建能够利用分布随机抽样进行随机变异和变异控制的应用。

    

    我们提出了一种基于我们之前的GMM扩展思想的高斯混合模型（GMM）学习算法。新算法比传统的期望最大化（EM）算法更具鲁棒性和简单性。它还提高了准确性，并且只需要进行1次迭代学习。我们在理论上证明了这种新算法无论参数初始化如何都能保证收敛。我们将我们的GMM扩展方法与神经网络中的经典概率层进行了比较，结果表明我们的方法能更好地克服数据的不确定性和逆问题。最后，我们测试了基于GMM的生成器，显示出了进一步利用分布随机抽样进行随机变异和变异控制的潜力。

    We propose an Gaussian Mixture Model (GMM) learning algorithm, based on our previous work of GMM expansion idea. The new algorithm brings more robustness and simplicity than classic Expectation Maximization (EM) algorithm. It also improves the accuracy and only take 1 iteration for learning. We theoretically proof that this new algorithm is guarantee to converge regardless the parameters initialisation. We compare our GMM expansion method with classic probability layers in neural network leads to demonstrably better capability to overcome data uncertainty and inverse problem. Finally, we test GMM based generator which shows a potential to build further application that able to utilized distribution random sampling for stochastic variation as well as variation control.
    
[^8]: 深度神经网络在二分类中的噪声敏感性和稳定性研究

    Noise Sensitivity and Stability of Deep Neural Networks for Binary Classification. (arXiv:2308.09374v1 [stat.ML])

    [http://arxiv.org/abs/2308.09374](http://arxiv.org/abs/2308.09374)

    本文通过研究深度神经网络分类器的噪声敏感性和稳定性，对非鲁棒性现象进行了探索，并澄清了这些概念的定义和关系。

    

    从布尔函数的角度出发，对深度神经网络（DNN）分类器的非鲁棒性现象进行了初步探索。通过研究常见DNN模型表示的布尔函数序列是否具有噪声敏感性或噪声稳定性，对这些概念进行了推广，并考虑了退火和淬火版本。本文澄清了这些定义之间的关系，并研究了两种常见DNN架构，即全连接和卷积模型，在初始化时使用高斯权重的特性。

    A first step is taken towards understanding often observed non-robustness phenomena of deep neural net (DNN) classifiers. This is done from the perspective of Boolean functions by asking if certain sequences of Boolean functions represented by common DNN models are noise sensitive or noise stable, concepts defined in the Boolean function literature. Due to the natural randomness in DNN models, these concepts are extended to annealed and quenched versions. Here we sort out the relation between these definitions and investigate the properties of two standard DNN architectures, the fully connected and convolutional models, when initiated with Gaussian weights.
    
[^9]: 针对中世纪拉丁语的定制手写文本识别系统

    A tailored Handwritten-Text-Recognition System for Medieval Latin. (arXiv:2308.09368v1 [cs.CV])

    [http://arxiv.org/abs/2308.09368](http://arxiv.org/abs/2308.09368)

    这个论文提出了一个针对中世纪拉丁语词典的定制手写文本识别系统，通过引入端到端的流水线和最新的图像分割模型，成功地定位、提取和转录引文，并且通过使用Transformer模型和数据增强等方法，实现了优于现有技术的字符错误率。

    

    巴伐利亚科学和人文学院旨在数字化其中世纪拉丁语词典。该词典包含了涉及中世纪拉丁语引文的记录卡片, 这是一种低资源语言。数字化过程的关键步骤是识别这些记录卡片上手写的引文的手写文本识别（HTR）。我们引入了一个端到端的流水线，专门针对中世纪拉丁语词典进行定制，用于定位、提取和转录引文。我们采用了两个最先进的图像分割模型来准备HTR任务的初始数据集。此外，我们尝试了不同的基于Transformer的模型，并进行了一系列实验，探索了不同组合的视觉编码器和GPT-2解码器的能力。此外，我们还应用了大量的数据增强，得到了一个竞争力极高的模型。最佳表现的配置实现了0.015的字符错误率（CER），甚至优于现有公认的技术。

    The Bavarian Academy of Sciences and Humanities aims to digitize its Medieval Latin Dictionary. This dictionary entails record cards referring to lemmas in medieval Latin, a low-resource language. A crucial step of the digitization process is the Handwritten Text Recognition (HTR) of the handwritten lemmas found on these record cards. In our work, we introduce an end-to-end pipeline, tailored to the medieval Latin dictionary, for locating, extracting, and transcribing the lemmas. We employ two state-of-the-art (SOTA) image segmentation models to prepare the initial data set for the HTR task. Furthermore, we experiment with different transformer-based models and conduct a set of experiments to explore the capabilities of different combinations of vision encoders with a GPT-2 decoder. Additionally, we also apply extensive data augmentation resulting in a highly competitive model. The best-performing setup achieved a Character Error Rate (CER) of 0.015, which is even superior to the comme
    
[^10]: 癫痫预测中的路径签名

    Path Signatures for Seizure Forecasting. (arXiv:2308.09312v1 [stat.ML])

    [http://arxiv.org/abs/2308.09312](http://arxiv.org/abs/2308.09312)

    本研究以癫痫预测为目标，通过自动发现和量化患者特定的统计特征，特别是最新的路径签名算法，探索其在癫痫预测中的性能，为个性化的癫痫预测解决方案提供了参考。

    

    从观测到的时间序列中预测系统状态是许多领域（如计算神经科学）的研究课题。在这里，从大脑测量中预测癫痫发作是一个尚未解决的问题。既没有完整的描述底层大脑动态的模型，也没有单个患者表现出单一的癫痫发作模式，这使得开发“一刀切”的解决方案变得复杂。基于纵向患者数据集，我们解决了自动发现和量化可用于以患者为中心的癫痫预测的统计特征（生物标志物）的问题。我们使用现有和新颖的特征提取算法，尤其是路径签名，即时间序列分析的最新发展。特别值得关注的是，与简单的线性特征相比，这组复杂的非线性特征在这个任务中的表现如何。我们的推断基于统计分类算法，并带有内置的子集选择功能。

    Forecasting the state of a system from an observed time series is the subject of research in many domains, such as computational neuroscience. Here, the prediction of epileptic seizures from brain measurements is an unresolved problem. There are neither complete models describing underlying brain dynamics, nor do individual patients exhibit a single seizure onset pattern, which complicates the development of a `one-size-fits-all' solution. Based on a longitudinal patient data set, we address the automated discovery and quantification of statistical features (biomarkers) that can be used to forecast seizures in a patient-specific way. We use existing and novel feature extraction algorithms, in particular the path signature, a recent development in time series analysis. Of particular interest is how this set of complex, nonlinear features performs compared to simpler, linear features on this task. Our inference is based on statistical classification algorithms with in-built subset select
    
[^11]: 主动和被动因果推断学习

    Active and Passive Causal Inference Learning. (arXiv:2308.09248v1 [cs.LG])

    [http://arxiv.org/abs/2308.09248](http://arxiv.org/abs/2308.09248)

    这篇论文介绍了主动和被动因果推断学习的重要假设和技术，并以讨论因果推断的缺失方面结束，为读者提供了一个多样性起点。

    

    这篇论文是机器学习研究人员、工程师和学生对因果推断感兴趣但尚未熟悉的一个起点。我们首先列举了一组重要的用于因果识别的假设，如可交换性、积极性、一致性和干扰的缺失。基于这些假设，我们构建了一套重要的因果推断技术，并将其分为两类：主动和被动方法。我们描述和讨论了主动方法中的随机对照试验和基于强化学习的方法。然后我们描述了被动方法中的经典方法，如匹配和逆概率加权，以及最近的基于深度学习的算法。通过介绍本文中一些因果推断的缺失方面，如碰撞偏差，我们期望本文为读者提供了一个多样性起点。

    This paper serves as a starting point for machine learning researchers, engineers and students who are interested in but not yet familiar with causal inference. We start by laying out an important set of assumptions that are collectively needed for causal identification, such as exchangeability, positivity, consistency and the absence of interference. From these assumptions, we build out a set of important causal inference techniques, which we do so by categorizing them into two buckets; active and passive approaches. We describe and discuss randomized controlled trials and bandit-based approaches from the active category. We then describe classical approaches, such as matching and inverse probability weighting, in the passive category, followed by more recent deep learning based algorithms. By finishing the paper with some of the missing aspects of causal inference from this paper, such as collider biases, we expect this paper to provide readers with a diverse set of starting points f
    
[^12]: 大图上马尔可夫链的路径收敛性

    Path convergence of Markov chains on large graphs. (arXiv:2308.09214v1 [math.PR])

    [http://arxiv.org/abs/2308.09214](http://arxiv.org/abs/2308.09214)

    本文研究了大图上的马尔可夫链收敛性。通过研究欧几里德随机优化算法和Metropolis MCMC算法的改进版本在图上的表现，我们得出了随着图大小趋近于无穷大，随机过程的轨迹会收敛到确定性极限的结论。这些极限是测度值图上的曲线，通过引入新的度量，在这个空间中提供了自然的收敛概念。

    

    我们研究了有限无标度图上的两类自然随机过程。这些过程包括在加权图的邻接矩阵上的欧几里德随机优化算法以及在无权图上的Metropolis MCMC算法的改进版本。在这两种情况下，我们证明随着图的规模趋近于无穷大，随机过程的随机轨迹收敛于确定性极限。这些确定性极限是测度值图上的曲线。由Lov\'{a}sz和Szegedy引入的测度值图是图构架概念的细化，能够区分使得相同图构架极限的两个无穷可交换数组。我们在这个空间上引入了新的度量，为我们的极限定理提供了自然的收敛概念。这个概念等价于无穷可交换数组的收敛。在适当的时间缩放下，Metropolis链具有扩散属性。

    We consider two classes of natural stochastic processes on finite unlabeled graphs. These are Euclidean stochastic optimization algorithms on the adjacency matrix of weighted graphs and a modified version of the Metropolis MCMC algorithm on stochastic block models over unweighted graphs. In both cases we show that, as the size of the graph goes to infinity, the random trajectories of the stochastic processes converge to deterministic limits. These deterministic limits are curves on the space of measure-valued graphons. Measure-valued graphons, introduced by Lov\'{a}sz and Szegedy, are a refinement of the concept of graphons that can distinguish between two infinite exchangeable arrays that give rise to the same graphon limit. We introduce new metrics on this space which provide us with a natural notion of convergence for our limit theorems. This notion is equivalent to the convergence of infinite-exchangeable arrays. Under a suitable time-scaling, the Metropolis chain admits a diffusio
    
[^13]: 使用点过程的RTB建模方法

    RTB Formulation Using Point Process. (arXiv:2308.09122v1 [stat.ML])

    [http://arxiv.org/abs/2308.09122](http://arxiv.org/abs/2308.09122)

    本文提出了一种使用点过程进行实时投标（RTB）生态系统中重复拍卖建模的通用随机框架。该框架灵活性高，可应用于各种拍卖场景，并提出了可将该过程近似为泊松点过程的理论结果。此外，考虑效用和市场条件的联合分布是至关重要的。

    

    我们提出了一个使用点过程进行建模的通用随机框架，用于模拟实时投标（RTB）生态系统中的重复拍卖。该框架的灵活性使得可以应用于各种拍卖场景，包括玩家提供的信息配置、确定拍卖的获胜者以及衡量每个拍卖所获得的效用。我们提出了关于如何将此过程的公式近似为泊松点过程的理论结果，从而使分析者能够利用已建立的性质。在这个框架下，我们确定了玩家在不同场景下的最优策略。我们还强调了考虑效用和市场条件的联合分布而不是独立估计边际分布的重要性。

    We propose a general stochastic framework for modelling repeated auctions in the Real Time Bidding (RTB) ecosystem using point processes. The flexibility of the framework allows a variety of auction scenarios including configuration of information provided to player, determination of auction winner and quantification of utility gained from each auctions. We propose theoretical results on how this formulation of process can be approximated to a Poisson point process, which enables the analyzer to take advantage of well-established properties. Under this framework, we specify the player's optimal strategy under various scenarios. We also emphasize that it is critical to consider the joint distribution of utility and market condition instead of estimating the marginal distributions independently.
    
[^14]: 多保真度傅里叶神经算子用于快速建模大规模地质碳储存

    Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v1 [stat.ML])

    [http://arxiv.org/abs/2308.09113](http://arxiv.org/abs/2308.09113)

    多保真度傅里叶神经算子用于解决大规模地质碳储存问题，通过利用经济性更高的多保真度训练数据集，能够以与高保真度模型相当的准确性进行预测。

    

    深度学习的代理模型已广泛应用于地质碳储存（GCS）问题，以加快预测储压和二氧化碳云层移动。然而，由于高计算成本，大规模三维问题的可用训练数据始终有限。因此，我们提出使用多保真度傅里叶神经算子来解决大规模GCS问题，利用更具经济性的多保真度训练数据集。傅里叶神经算子具有良好的网格不变性，简化了不同离散数据集之间的迁移学习过程。我们首先在一个GCS储层模型上进行模型有效性测试，该模型被划分为110,000个网格单元。多保真度模型的预测准确度可与高保真度模型的训练进行比较。

    Deep learning-based surrogate models have been widely applied in geological carbon storage (GCS) problems to accelerate the prediction of reservoir pressure and CO2 plume migration. Large amounts of data from physics-based numerical simulators are required to train a model to accurately predict the complex physical behaviors associated with this process. In practice, the available training data are always limited in large-scale 3D problems due to the high computational cost. Therefore, we propose to use a multi-fidelity Fourier Neural Operator to solve large-scale GCS problems with more affordable multi-fidelity training datasets. The Fourier Neural Operator has a desirable grid-invariant property, which simplifies the transfer learning procedure between datasets with different discretization. We first test the model efficacy on a GCS reservoir model being discretized into 110k grid cells. The multi-fidelity model can predict with accuracy comparable to a high-fidelity model trained wi
    
[^15]: 自动肘部检测的谱信息准则

    Spectral information criterion for automatic elbow detection. (arXiv:2308.09108v1 [stat.ME])

    [http://arxiv.org/abs/2308.09108](http://arxiv.org/abs/2308.09108)

    提出了一种谱信息准则（SIC），可以作为自动肘部检测器，提取了误差曲线的几何特征，并给出了选择唯一模型的实用规则。

    

    我们引入了一个广义的信息准则，其中包含其他众所周知的信息准则，如贝叶斯信息准则（BIC）和赤池信息准则（AIC），作为特殊情况。此外，所提出的谱信息准则（SIC）也比其他信息准则更通用，例如，不严格要求似然函数的知识。SIC提取了误差曲线的几何特征，因此可以被视为自动肘部检测器。SIC提供了可能模型的子集，其基数通常远小于可能模型的总数。该子集的元素是误差曲线的肘部。还提出了一个在肘部集合中选择唯一模型的实用规则。分析了SIC的理论不变性性质。此外，我们在理想情况下测试了SIC，在这些情况下始终提供最佳预期结果。我们还在几个数值实验中测试了SIC。

    We introduce a generalized information criterion that contains other well-known information criteria, such as Bayesian information Criterion (BIC) and Akaike information criterion (AIC), as special cases. Furthermore, the proposed spectral information criterion (SIC) is also more general than the other information criteria, e.g., since the knowledge of a likelihood function is not strictly required. SIC extracts geometric features of the error curve and, as a consequence, it can be considered an automatic elbow detector. SIC provides a subset of all possible models, with a cardinality that often is much smaller than the total number of possible models. The elements of this subset are elbows of the error curve. A practical rule for selecting a unique model within the sets of elbows is suggested as well. Theoretical invariance properties of SIC are analyzed. Moreover, we test SIC in ideal scenarios where provides always the optimal expected results. We also test SIC in several numerical 
    
[^16]: 基于尖峰与块缩减先验的结构稀疏贝叶斯神经网络的全面研究

    A comprehensive study of spike and slab shrinkage priors for structurally sparse Bayesian neural networks. (arXiv:2308.09104v1 [stat.ML])

    [http://arxiv.org/abs/2308.09104](http://arxiv.org/abs/2308.09104)

    本论文研究了在贝叶斯神经网络中使用Lasso和Horseshoe两种缩减技术进行模型压缩的方法。为了实现结构稀疏，通过提出尖峰与块组稀疏Lasso和尖峰与块组Horseshoe先验，并开发了可计算的变分推断方法。该方法可以在保持推理效率的同时实现深度神经网络的模型压缩。

    

    网络复杂度和计算效率已经成为深度学习中越来越重要的方面。稀疏深度学习通过减少过参数化的深度神经网络来恢复底层目标函数的稀疏表示，解决了这些挑战。具体而言，通过结构稀疏（如节点稀疏）压缩的深度神经架构提供了低延迟推理、更高的数据吞吐量和更低的能量消耗。在本文中，我们研究了两种广泛应用的缩减技术，Lasso和Horseshoe，在贝叶斯神经网络中进行模型压缩。为此，我们提出了基于尖峰与块组稀疏Lasso (SS-GL)和基于尖峰与块组Horseshoe (SS-GHS)先验的结构稀疏贝叶斯神经网络，并开发了可计算的变分推断，包括对伯努利变量的连续松弛。我们确定了变分推断的收缩速率。

    Network complexity and computational efficiency have become increasingly significant aspects of deep learning. Sparse deep learning addresses these challenges by recovering a sparse representation of the underlying target function by reducing heavily over-parameterized deep neural networks. Specifically, deep neural architectures compressed via structured sparsity (e.g. node sparsity) provide low latency inference, higher data throughput, and reduced energy consumption. In this paper, we explore two well-established shrinkage techniques, Lasso and Horseshoe, for model compression in Bayesian neural networks. To this end, we propose structurally sparse Bayesian neural networks which systematically prune excessive nodes with (i) Spike-and-Slab Group Lasso (SS-GL), and (ii) Spike-and-Slab Group Horseshoe (SS-GHS) priors, and develop computationally tractable variational inference including continuous relaxation of Bernoulli variables. We establish the contraction rates of the variational 
    
[^17]: 通过迭代近似祖先采样实现变分自编码器的条件采样

    Conditional Sampling of Variational Autoencoders via Iterated Approximate Ancestral Sampling. (arXiv:2308.09078v1 [cs.LG])

    [http://arxiv.org/abs/2308.09078](http://arxiv.org/abs/2308.09078)

    本文提出了两种原始方法来解决变分自编码器（VAE）条件采样中的困难，并在采样任务中展示了改进性能。

    

    在各种应用中，如缺失数据填充，需要对变分自编码器（VAE）进行条件采样，但这是计算上不可行的。渐近精确条件采样的原则选择是Metropolis-within-Gibbs（MWG）。然而，我们观察到VAE倾向于学习结构化潜变量空间，这是一个常见的期望特性，但却导致MWG采样器远离目标分布。本文克服了MWG的局限性：我们系统地概述了在VAE上上述局限性，并提出了两种原始方法来解决这些问题，并在一组采样任务上展示了所提方法的改进性能。

    Conditional sampling of variational autoencoders (VAEs) is needed in various applications, such as missing data imputation, but is computationally intractable. A principled choice for asymptotically exact conditional sampling is Metropolis-within-Gibbs (MWG). However, we observe that the tendency of VAEs to learn a structured latent space, a commonly desired property, can cause the MWG sampler to get "stuck" far from the target distribution. This paper mitigates the limitations of MWG: we systematically outline the pitfalls in the context of VAEs, propose two original methods that address these pitfalls, and demonstrate an improved performance of the proposed methods on a set of sampling tasks.
    
[^18]: 通过离散化引发的Dirichlet后验用于回归问题的鲁棒性不确定性量化

    Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression. (arXiv:2308.09065v1 [cs.CV])

    [http://arxiv.org/abs/2308.09065](http://arxiv.org/abs/2308.09065)

    本文提出了一种用于回归任务的广义AuxUE方案，目的是实现更鲁棒的不确定性量化。具体而言，该方案通过考虑不同的分布假设，选择Laplace分布来近似p，以实现更鲁棒的本质不确定性估计。

    

    在实际应用中，不确定性量化对于部署深度神经网络（DNNs）至关重要。辅助不确定性估计器（AuxUE）是一种在不修改主任务模型的情况下估计主任务预测不确定性的最有效手段之一。为了被认为是鲁棒的，AuxUE必须能够在遇到超出分布范围的输入时保持性能并引发更高的不确定性，即提供鲁棒的本质不确定性和认识不确定性。然而，对于视觉回归任务，当前的AuxUE设计主要用于本质不确定性估计，并且尚未探索AuxUE的鲁棒性。在这项工作中，我们提出了一种用于回归任务的更鲁棒不确定性量化的广义AuxUE方案。具体而言，为了实现更鲁棒的本质不确定性估计，在异方差噪声方面考虑了不同的分布假设，并最终选择Laplace分布来近似p

    Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the p
    
[^19]: 基于核的无似然假设检验方法

    Kernel-Based Tests for Likelihood-Free Hypothesis Testing. (arXiv:2308.09043v1 [stat.ML])

    [http://arxiv.org/abs/2308.09043](http://arxiv.org/abs/2308.09043)

    本文介绍了一种基于核的无似然假设检验方法，解决了对已知属于两个类别的输入进行分类的问题，在无似然推断领域，通过将标记样本通过正向模拟获得，未标记样本通过实验收集，给出了一个权衡m和n的方法。

    

    从两个平衡类别的n个观测中，考虑对额外m个已知属于其中一个类别的输入进行分类的任务。该问题的特殊情况已经被广泛研究：当完全了解类别分布时（n=∞），最优解是使用似然比检验；当m=1时，对应二分类问题；当m≈n时，等同于两样本检验。中间的情况出现在无似然推断领域，其中标记样本通过运行正向模拟获得，而未标记样本通过实验收集。最近的研究发现，m和n之间存在根本性的权衡：增加数据样本m会减少所需的训练/模拟数据量n。在本研究中，我们（a）引入了一个常常遇到的情况，即未标记样本来自两个类别的混合物；（b）研究了最小化风险的方法，其中风险定义为误分类概率的上界。

    Given $n$ observations from two balanced classes, consider the task of labeling an additional $m$ inputs that are known to all belong to \emph{one} of the two classes. Special cases of this problem are well-known: with complete knowledge of class distributions ($n=\infty$) the problem is solved optimally by the likelihood-ratio test; when $m=1$ it corresponds to binary classification; and when $m\approx n$ it is equivalent to two-sample testing. The intermediate settings occur in the field of likelihood-free inference, where labeled samples are obtained by running forward simulations and the unlabeled sample is collected experimentally. In recent work it was discovered that there is a fundamental trade-off between $m$ and $n$: increasing the data sample $m$ reduces the amount $n$ of training/simulation data needed. In this work we (a) introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice; (b) study the minimax 
    
[^20]: 打破高维音符：关于广义线性模型和多索引模型上 SGD 学习动力学的 ODE 分析

    Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models. (arXiv:2308.08977v1 [math.OC])

    [http://arxiv.org/abs/2308.08977](http://arxiv.org/abs/2308.08977)

    本文研究了应用于广义线性模型和多索引模型中的流式随机梯度下降（SGD）的学习动力学。通过建立了一个普通微分方程系统来描述风险和次优性度量等统计量，获得了稳定性学习率阈值和收敛保证。同时，引入了一个简化扩散系数的随机微分方程模型，用于分析SGD迭代的统计动力学。通过标准示例和数值模拟，验证了该理论的有效性。

    

    本文分析了在应用于具有一般数据协方差的广义线性模型和多索引模型（例如逻辑回归、相位恢复）时，流式随机梯度下降（SGD）在高维限制下的动力学。具体而言，我们证明了 SGD 的确定性等效形式，即一组描述风险和其他次优性度量的普通微分方程系统。当模型参数数量与数据数量成正比增长时，该等效性以极大概率发生。该框架使我们能够获得 SGD 稳定性的学习率阈值以及收敛保证。除了确定性等效性外，我们引入了一个具有简化扩散系数的 SDE（均匀化 SGD），它使我们能够分析 SGD 迭代的常规统计动力学。最后，我们在一些标准示例上演示了该理论，并展示了数值模拟结果。

    We analyze the dynamics of streaming stochastic gradient descent (SGD) in the high-dimensional limit when applied to generalized linear models and multi-index models (e.g. logistic regression, phase retrieval) with general data-covariance. In particular, we demonstrate a deterministic equivalent of SGD in the form of a system of ordinary differential equations that describes a wide class of statistics, such as the risk and other measures of sub-optimality. This equivalence holds with overwhelming probability when the model parameter count grows proportionally to the number of data. This framework allows us to obtain learning rate thresholds for stability of SGD as well as convergence guarantees. In addition to the deterministic equivalent, we introduce an SDE with a simplified diffusion coefficient (homogenized SGD) which allows us to analyze the dynamics of general statistics of SGD iterates. Finally, we illustrate this theory on some standard examples and show numerical simulations w
    
[^21]: 没有模型的算法在零和马尔可夫博弈中提高了样本效率

    Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games. (arXiv:2308.08858v1 [cs.LG])

    [http://arxiv.org/abs/2308.08858](http://arxiv.org/abs/2308.08858)

    本文提出了一种模型自由的算法，可以在零和马尔可夫博弈中实现与模型为基础算法相同的样本复杂度，首次证明了模型自由算法可以在时间段依赖性方面达到同样的优化效果。

    

    最近，两人零和马尔可夫博弈问题在多智能体强化学习的理论研究中引起了越来越多的兴趣。特别是对于有限时间段的马尔可夫决策过程，已经证明了模型为基础的算法可以通过样本复杂度为$O(H^3SAB/\epsilon^2)$找到$\epsilon$-最优的纳什均衡（NE），其中$H$是时间段，$S$是状态数量（$A$和$B$分别表示两个玩家的动作数量）。然而，目前没有一种现有的模型自由算法可以达到这样的优化效果。在这项工作中，我们提出了一种模型自由的阶段性Q学习算法，并展示它实现了与最佳模型为基础算法相同的样本复杂度，因此首次证明了模型自由算法可以在时间段依赖性方面享受与模型为基础算法相同的优化效果。对于$H$的依赖性的主要改进来源于...

    The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by
    
[^22]: 通过高效算法学习具有结构稀疏性的核心图形Lasso模型

    Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm. (arXiv:2308.08852v1 [math.OC])

    [http://arxiv.org/abs/2308.08852](http://arxiv.org/abs/2308.08852)

    通过双重交替方向乘子法 (ADMM) 和半平滑牛顿 (SSN) 基于增广对偶法 (ALM) 的方法，我们提出了一个高效算法来学习具有结构稀疏性的核心图形Lasso模型，该算法能够在大维度的任务中节省超过70\%的执行时间，并且具有较高的性能。

    

    图形模型在从生物分析到推荐系统等众多任务中展现出了良好的性能。然而，具有核心节点的图形模型在数据维度较大时计算上存在困难。为了高效估计核心图形模型，我们提出了一个两阶段算法。所提出的算法首先通过双重交替方向乘子法 (ADMM) 生成一个良好的初始点，然后使用半平滑牛顿 (SSN) 基于增广对偶法 (ALM) 的方法进行热启动，以计算出能够在实际任务中精确到足够程度的解。广义雅可比矩阵的稀疏结构确保了该算法能够非常高效地获得一个良好的解。在合成数据和真实数据的全面实验中，该算法明显优于现有的最先进算法。特别是在某些高维任务中，它可以节省超过70\%的执行时间，同时仍然可以达到很好的性能。

    Graphical models have exhibited their performance in numerous tasks ranging from biological analysis to recommender systems. However, graphical models with hub nodes are computationally difficult to fit, particularly when the dimension of the data is large. To efficiently estimate the hub graphical models, we introduce a two-phase algorithm. The proposed algorithm first generates a good initial point via a dual alternating direction method of multipliers (ADMM), and then warm starts a semismooth Newton (SSN) based augmented Lagrangian method (ALM) to compute a solution that is accurate enough for practical tasks. The sparsity structure of the generalized Jacobian ensures that the algorithm can obtain a nice solution very efficiently. Comprehensive experiments on both synthetic data and real data show that it obviously outperforms the existing state-of-the-art algorithms. In particular, in some high dimensional tasks, it can save more than 70\% of the execution time, meanwhile still ach
    
[^23]: 带有通信压缩的随机控制平均法在联邦学习中的应用

    Stochastic Controlled Averaging for Federated Learning with Communication Compression. (arXiv:2308.08165v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2308.08165](http://arxiv.org/abs/2308.08165)

    本文提出了两种压缩联邦学习算法(SCALLION和SCAFCOM)，通过重新审视经典的随机控制平均法并提出了等价但更高效/简化的形式，减少了上行通信成本。

    

    通信压缩是一种旨在减少通过无线传输的信息量的技术，在联邦学习中引起了极大的关注，因为它有潜力减轻通信开销。然而，通信压缩在联邦学习中带来了新的挑战，包括压缩引起的信息失真以及联邦学习的特性，如部分参与和数据异构性。尽管近年来有所发展，压缩联邦学习方法的性能尚未充分利用。现有方法要么不能适应任意的数据异构性或部分参与，要么要求对压缩有严格的条件。在本文中，我们重新审视了具有开销减半的上行通信成本的经典随机控制平均法，并提出了两种压缩联邦学习算法，SCALLION和SCAFCOM。

    Communication compression, a technique aiming to reduce the information volume to be transmitted over the air, has gained great interests in Federated Learning (FL) for the potential of alleviating its communication overhead. However, communication compression brings forth new challenges in FL due to the interplay of compression-incurred information distortion and inherent characteristics of FL such as partial participation and data heterogeneity. Despite the recent development, the performance of compressed FL approaches has not been fully exploited. The existing approaches either cannot accommodate arbitrary data heterogeneity or partial participation, or require stringent conditions on compression.  In this paper, we revisit the seminal stochastic controlled averaging method by proposing an equivalent but more efficient/simplified formulation with halved uplink communication costs. Building upon this implementation, we propose two compressed FL algorithms, SCALLION and SCAFCOM, to s
    
[^24]: 离散切割Wasserstein损失的性质

    Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])

    [http://arxiv.org/abs/2307.10352](http://arxiv.org/abs/2307.10352)

    本文研究了离散切割Wasserstein损失的性质，并探讨了其正则性和优化性质以及通过蒙特卡洛近似的方法。

    

    切割Wasserstein（SW）距离已成为比较概率测度的Wasserstein距离的一种流行替代方法。广泛应用包括图像处理、领域自适应和生成建模，常常需要优化一些参数以最小化SW，该参数充当离散概率测度之间的损失函数（因为具有密度的测度在数值上是无法实现的）。所有这些优化问题都存在相同的子问题，即最小化切割Wasserstein能量。在本文中，我们研究了$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$的属性，即两个具有与一个测度的支撑相同数量的离散均匀测度之间的SW距离作为支撑$Y \in \mathbb{R}^{n \times d}$函数的能量。我们研究了这个能量的正则性和优化性质，以及其通过蒙特卡洛近似$\mathcal{E}_p$（使用SW中的期望估计）。

    The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
    
[^25]: 量子退火中适合的图像去噪框架：QUBO和受限玻尔兹曼机

    An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines. (arXiv:2307.06542v1 [quant-ph])

    [http://arxiv.org/abs/2307.06542](http://arxiv.org/abs/2307.06542)

    本研究提出了一种通过受限玻尔兹曼机（RBMs）的二值图像去噪框架，该框架使用二次无约束二值优化（QUBO）形式的去噪目标，并且适用于量子退火。通过平衡训练的RBMs学习到的分布和噪声图像偏离的惩罚项，实现了去噪目标。通过进行实验，研究发现该方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。

    

    我们研究了一种通过受限玻尔兹曼机（RBMs）实现的二值图像去噪框架，该框架引入了一个二次无约束二值优化（QUBO）形式的去噪目标，并且非常适合量子退火。通过在训练的RBMs上学习到的分布与噪声图像偏离的惩罚项的平衡，实现了去噪目标。我们推导了在目标分布被良好近似的情况下，惩罚参数的统计最优选择，并进一步建议了一种经过经验证支持的修改方法，使该方法对于理想化假设具有鲁棒性。我们还在额外的假设下展示了，我们方法得到的去噪图像在期望意义下明显比噪声图像更接近无噪声图像。虽然我们将该模型构建为图像去噪模型，但它可以应用于任何二值数据。由于QUBO公式非常适合在量子退火器上实现，我们在一个数据集上对该模型进行了测试。

    We investigate a framework for binary image denoising via restricted Boltzmann machines (RBMs) that introduces a denoising objective in quadratic unconstrained binary optimization (QUBO) form and is well-suited for quantum annealing. The denoising objective is attained by balancing the distribution learned by a trained RBM with a penalty term for derivations from the noisy image. We derive the statistically optimal choice of the penalty parameter assuming the target distribution has been well-approximated, and further suggest an empirically supported modification to make the method robust to that idealistic assumption. We also show under additional assumptions that the denoised images attained by our method are, in expectation, strictly closer to the noise-free images than the noisy images are. While we frame the model as an image denoising model, it can be applied to any binary data. As the QUBO formulation is well-suited for implementation on quantum annealers, we test the model on a
    
[^26]: 关于ReLU网络的大小无关样本复杂度

    On Size-Independent Sample Complexity of ReLU Networks. (arXiv:2306.01992v1 [cs.LG])

    [http://arxiv.org/abs/2306.01992](http://arxiv.org/abs/2306.01992)

    本文研究了ReLU神经网络的样本复杂度，给出了一个现有方法精细化的结果，实现了无深度依赖性的上界。

    

    我们从泛化的角度研究了学习ReLU神经网络的样本复杂度。在权重矩阵上给定范数约束的情况下，一个常见的方法是估计相关函数类的Rademacher复杂度。之前Golowich-Rakhlin-Shamir (2020)获得了一个不依赖于网络大小的（与Frobenius范数的乘积成比例）上界，除了一个平方根深度的因子。我们给出了一个精细化的结果，通常根本没有明显的深度依赖性。

    We study the sample complexity of learning ReLU neural networks from the point of view of generalization. Given norm constraints on the weight matrices, a common approach is to estimate the Rademacher complexity of the associated function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound independent of the network size (scaling with a product of Frobenius norms) except for a factor of the square-root depth. We give a refinement which often has no explicit depth-dependence at all.
    
[^27]: 在线Platt缩放及其校准方法

    Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])

    [http://arxiv.org/abs/2305.00070](http://arxiv.org/abs/2305.00070)

    本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。

    

    我们提出了一种在线后校准方法，称为在线Platt缩放(OPS)，它将Platt缩放技术与在线逻辑回归相结合。我们展示了OPS如何在分布漂移的i.i.d.和非i.i.d.情况下平稳适应。此外，当最佳的Platt缩放模型本身被错误校准时，我们使用一种最近开发的称为calibeating的技术来增强OPS，使其更加鲁棒。理论上，我们得到的OPS+calibeating方法对于对抗性结果序列是保证校准的。在实验上，它在一系列合成和真实数据集上均表现出卓越的性能，无需超参数调整。最后，我们将所有OPS思想扩展到beta缩放方法。

    We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.
    
[^28]: 不同的好手臂识别

    Differential Good Arm Identification. (arXiv:2303.07154v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.07154](http://arxiv.org/abs/2303.07154)

    本文提出了DGAI算法，它可以在好手臂识别问题中通过深度学习的方式减少样本复杂性，并且在具有给定阈值的情况下进一步提高多臂赌博问题的性能。

    

    本文针对一种变体的随机多臂赌博问题，称之为好手臂识别（GAI）。 GAI是一个纯探索的赌博问题，其目标是在尽可能少的样本数下输出尽可能多的好手臂，其中好手臂被定义为其期望奖励大于给定阈值的手臂。 在这项工作中，我们提出DGAI-一种可微的好手臂识别算法，以数据驱动方式改进了现有技术HDoC算法的样本复杂性。 我们还展示了DGAI可以进一步提升通用多臂赌博（MAB）问题的性能，给定一个阈值作为先验知识应用于手臂集。 大量实验证实，我们的算法在合成数据集和真实世界数据集中的GAI和MAB任务中显著优于基线算法。

    This paper targets a variant of the stochastic multi-armed bandit problem called good arm identification (GAI). GAI is a pure-exploration bandit problem with the goal to output as many good arms using as few samples as possible, where a good arm is defined as an arm whose expected reward is greater than a given threshold. In this work, we propose DGAI - a differentiable good arm identification algorithm to improve the sample complexity of the state-of-the-art HDoC algorithm in a data-driven fashion. We also showed that the DGAI can further boost the performance of a general multi-arm bandit (MAB) problem given a threshold as a prior knowledge to the arm set. Extensive experiments confirm that our algorithm outperform the baseline algorithms significantly in both synthetic and real world datasets for both GAI and MAB tasks.
    
[^29]: 去噪扩散采样器

    Denoising Diffusion Samplers. (arXiv:2302.13834v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13834](http://arxiv.org/abs/2302.13834)

    去噪扩散采样器 (DDS) 近似地从非标准化概率密度函数中采样，并估计其标准化常数。

    

    去噪扩散模型是一种受欢迎的生成模型类别，在许多领域提供最先进的结果。通过使用扩散逐渐向数据添加噪声，将数据分布转化为高斯分布。生成模型的样本通过模拟该扩散的时间反演的近似，并初始化为高斯样本来获得。在实践中，通过使用评分匹配技术对时间反演过程中出现的棘手的评分项进行近似。我们在这里探索了一种类似的想法，用于近似采样非标准化概率密度函数并估计其标准化常数。我们考虑了一个目标密度向高斯扩散的过程。去噪扩散采样器 (DDS) 是通过近似相应的时间反演而获得的。尽管评分匹配在这种情况下不适用，但我们可以利用在 Monte Carlo 采样中引入的许多思想。

    Denoising diffusion models are a popular class of generative models providing state-of-the-art results in many domains. One adds gradually noise to data using a diffusion to transform the data distribution into a Gaussian distribution. Samples from the generative model are then obtained by simulating an approximation of the time-reversal of this diffusion initialized by Gaussian samples. Practically, the intractable score terms appearing in the time-reversed process are approximated using score matching techniques. We explore here a similar idea to sample approximately from unnormalized probability density functions and estimate their normalizing constants. We consider a process where the target density diffuses towards a Gaussian. Denoising Diffusion Samplers (DDS) are obtained by approximating the corresponding time-reversal. While score matching is not applicable in this context, we can leverage many of the ideas introduced in generative modeling for Monte Carlo sampling. Existing t
    
[^30]: 生物医学机器学习中的增强攻击

    Enhancement attacks in biomedical machine learning. (arXiv:2301.01885v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.01885](http://arxiv.org/abs/2301.01885)

    本研究针对生物医学机器学习中的可信度问题，通过开发增强攻击技术，成功地能够通过最小的特征改变显著提高分类器的预测性能，并保持原始数据和增强数据之间的高特征相似性。

    

    机器学习在生物医学研究中的应用日益增多，然而对于这些研究可信度的关注却往往被忽视。尽管一些先前的研究探讨了对医学图像模型性能进行破坏的对抗攻击的能力，但最近出现的“增强攻击”通过误导地提高模型性能可能会对生物医学机器学习构成更大的威胁。为了更好地了解可信度，我们开发了两种技术，可以通过极小的特征改变显著提高分类器的预测性能：1）普遍性能增强和2）某种方法相对于其他方法的增强。我们的增强框架可以将分类器的准确率从50％虚假提高到接近100％，同时保持原始数据和增强数据之间的高特征相似性（Pearson's r>0.99）。类似地，基于方法的增强框架有效地虚假提高了某种方法的预测性能。

    The prevalence of machine learning in biomedical research is rapidly growing, yet the trustworthiness of such research is often overlooked. While some previous works have investigated the ability of adversarial attacks to degrade model performance in medical imaging, the ability to falsely improve performance via recently-developed "enhancement attacks" may be a greater threat to biomedical machine learning. In the spirit of developing attacks to better understand trustworthiness, we developed two techniques to drastically enhance prediction performance of classifiers with minimal changes to features: 1) general enhancement of prediction performance, and 2) enhancement of a particular method over another. Our enhancement framework falsely improved classifiers' accuracy from 50% to almost 100% while maintaining high feature similarities between original and enhanced data (Pearson's r's>0.99). Similarly, the method-specific enhancement framework was effective in falsely improving the per
    
[^31]: 多速率变分自编码器：一次训练，得到完整的率失真曲线

    Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve. (arXiv:2212.03905v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03905](http://arxiv.org/abs/2212.03905)

    本文介绍了一种名为多速率VAE（MR-VAE）的框架，可在单次训练中学习与不同β对应的最优参数，通过使用超网络将β映射到最优参数，以实现率失真曲线的完整训练。

    

    变分自编码器（VAEs）是一种用于学习数据的潜在表示的强大工具，广泛应用于各种应用领域。在实践中，VAEs通常需要多次训练来选择潜在变量应该保留的信息量。重构误差（失真）和KL散度（率）之间的权衡通常由超参数β参数化。在本文中，我们引入了多速率VAE（MR-VAE），这是一个计算效率高的框架，可以在单次训练中学习与不同β对应的最优参数。关键思想是使用超网络明确地制定一个响应函数，将β映射到最优参数。MR-VAEs构建了一个紧凑的响应超网络，其中的预激活根据β进行有条件的门控。通过分析线性VAEs并展示它能够准确表示线性VAEs的响应函数，我们证明了所提出的架构的合理性。

    Variational autoencoders (VAEs) are powerful tools for learning latent representations of data used in a wide range of applications. In practice, VAEs usually require multiple training rounds to choose the amount of information the latent variable should retain. This trade-off between the reconstruction error (distortion) and the KL divergence (rate) is typically parameterized by a hyperparameter $\beta$. In this paper, we introduce Multi-Rate VAE (MR-VAE), a computationally efficient framework for learning optimal parameters corresponding to various $\beta$ in a single training run. The key idea is to explicitly formulate a response function that maps $\beta$ to the optimal parameters using hypernetworks. MR-VAEs construct a compact response hypernetwork where the pre-activations are conditionally gated based on $\beta$. We justify the proposed architecture by analyzing linear VAEs and showing that it can represent response functions exactly for linear VAEs. With the learned hypernetw
    
[^32]: 神经超统计学用于贝叶斯估计动态认知模型

    Neural Superstatistics for Bayesian Estimation of Dynamic Cognitive Model. (arXiv:2211.13165v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2211.13165](http://arxiv.org/abs/2211.13165)

    本研究提出了一种神经超统计学方法，用于贝叶斯估计动态认知模型。通过引入时间维度和超统计视角，可以有效地估计系统中的动态性质，并利用仿真和深度学习方法进行贝叶斯推理。该方法能够恢复时变和时不变参数，并在实验证明其有效性。

    

    认知的数学模型通常是无记忆的，忽略了参数的潜在波动。然而，人类认知本质上是动态的。因此，我们提出在机械认知模型中引入时间维度，并从超统计学的角度估计所得到的动态性质。这样的模型包括了一个低级观测模型和一个高级转换模型之间的层次结构。观测模型描述了系统的局部行为，转换模型规定了观测模型参数随时间演化的方式。为了克服超统计模型复杂性带来的估计挑战，我们开发并验证了一种基于仿真的深度学习方法，用于贝叶斯推理，可以恢复时变和时不变参数。我们首先将我们的方法与两个已有的能够估计时变参数的框架进行基准测试。然后，我们将我们的方法应用于拟合动态版本的差分方程模型。

    Mathematical models of cognition are often memoryless and ignore potential fluctuations of their parameters. However, human cognition is inherently dynamic. Thus, we propose to augment mechanistic cognitive models with a temporal dimension and estimate the resulting dynamics from a superstatistics perspective. Such a model entails a hierarchy between a low-level observation model and a high-level transition model. The observation model describes the local behavior of a system, and the transition model specifies how the parameters of the observation model evolve over time. To overcome the estimation challenges resulting from the complexity of superstatistical models, we develop and validate a simulation-based deep learning method for Bayesian inference, which can recover both time-varying and time-invariant parameters. We first benchmark our method against two existing frameworks capable of estimating time-varying parameters. We then apply our method to fit a dynamic version of the diff
    
[^33]: 损失的几何和微积分

    The Geometry and Calculus of Losses. (arXiv:2209.00238v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.00238](http://arxiv.org/abs/2209.00238)

    本文从凸集的新角度系统地发展了损失函数理论，引入了一种自动合适的损失函数定义方法，并提供了损失和范数之间关系的新机会，以及凸集微积分下的损失插值方法。

    

    统计决策问题是统计机器学习的核心。最简单的问题是二元和多类分类以及类概率估计。它们的定义的核心是选择损失函数，这是评估解决方案质量的手段。在本文中，我们从一种新颖的角度系统地发展了这类问题的损失函数理论，其基本要素是具有特定结构的凸集。损失函数被定义为凸集的支撑函数的次梯度。因此，它自动是合适的（用于概率估计）。这种视角提供了三个新颖的机会。它使得损失和(反)范数之间的基本关系的发展成为可能，这似乎以前没有被注意到。其次，它通过凸集的微积分使得损失的微积分的发展成为可能，从而允许在不同的损失之间进行插值。

    Statistical decision problems lie at the heart of statistical machine learning. The simplest problems are binary and multiclass classification and class probability estimation. Central to their definition is the choice of loss function, which is the means by which the quality of a solution is evaluated. In this paper we systematically develop the theory of loss functions for such problems from a novel perspective whose basic ingredients are convex sets with a particular structure. The loss function is defined as the subgradient of the support function of the convex set. It is consequently automatically proper (calibrated for probability estimation). This perspective provides three novel opportunities. It enables the development of a fundamental relationship between losses and (anti)-norms that appears to have not been noticed before. Second, it enables the development of a calculus of losses induced by the calculus of convex sets which allows the interpolation between different losses,
    
[^34]: 面板数据因果推断的预测算法

    Forecasting Algorithms for Causal Inference with Panel Data. (arXiv:2208.03489v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2208.03489](http://arxiv.org/abs/2208.03489)

    该论文将深度神经网络算法应用于时间序列预测，以提高面板数据中的因果推断准确性。通过实验证明，该算法在各种情景下明显优于现有方法，为面板数据研究提供了新的方法和工具。

    

    在社会科学研究中，使用面板数据进行因果推断是一项核心挑战。我们将一种深度神经架构用于时间序列预测（N-BEATS算法），以更准确地预测在未进行处理的情况下受治疗单位的反事实演变。在各种情境下，所得到的估计器（“SyNBEATS”）在性能上明显优于常用方法（合成对照法、双向固定效应），并且与最近提出的方法（合成差异法、矩阵补全）在准确性上达到了相当的水平或更高。我们的结果突显了如何利用预测文献的进展来改善面板数据环境下的因果推断。

    Conducting causal inference with panel data is a core challenge in social science research. We adapt a deep neural architecture for time series forecasting (the N-BEATS algorithm) to more accurately predict the counterfactual evolution of a treated unit had treatment not occurred. Across a range of settings, the resulting estimator ("SyNBEATS") significantly outperforms commonly employed methods (synthetic controls, two-way fixed effects), and attains comparable or more accurate performance compared to recently proposed methods (synthetic difference-in-differences, matrix completion). Our results highlight how advances in the forecasting literature can be harnessed to improve causal inference in panel data settings.
    
[^35]: 全面稳健的数据驱动决策

    Holistic Robust Data-Driven Decisions. (arXiv:2207.09560v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.09560](http://arxiv.org/abs/2207.09560)

    这篇论文提出了一种全面稳健的数据驱动公式，能够同时保护三个过拟合的源头：有限样本数据的统计误差、数据点的有限精度测量引起的数据噪声，以及被破坏的部分数据。

    

    设计具有良好样本外性能的机器学习和决策的数据驱动公式是一个关键的挑战。好的样本内性能不一定能保证好的样本外性能，这被普遍认为是过拟合问题。实际的过拟合通常不能归因于单一原因，而是由多个因素同时引起的。我们在这里考虑了三个过拟合的源头：（一）统计误差，由于使用有限的样本数据而产生的误差，（二）数据噪声，当数据点只用有限精度测量时产生的噪声，（三）数据错误，即全部数据中有一小部分数据被完全破坏。我们认为，尽管现有的数据驱动公式在单独处理这三个源头时可能是稳健的，但它们不能同时提供对所有过拟合源头的全面保护。我们设计了一种新颖的数据驱动公式，可以保证这种全面保护。

    The design of data-driven formulations for machine learning and decision-making with good out-of-sample performance is a key challenge. The observation that good in-sample performance does not guarantee good out-of-sample performance is generally known as overfitting. Practical overfitting can typically not be attributed to a single cause but instead is caused by several factors all at once. We consider here three overfitting sources: (i) statistical error as a result of working with finite sample data, (ii) data noise which occurs when the data points are measured only with finite precision, and finally (iii) data misspecification in which a small fraction of all data may be wholly corrupted. We argue that although existing data-driven formulations may be robust against one of these three sources in isolation they do not provide holistic protection against all overfitting sources simultaneously. We design a novel data-driven formulation which does guarantee such holistic protection an
    
[^36]: 马尔科夫高斯过程变分自编码器

    Markovian Gaussian Process Variational Autoencoders. (arXiv:2207.05543v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.05543](http://arxiv.org/abs/2207.05543)

    本文提出了一种马尔科夫高斯过程变分自编码器（MGPVAE）模型，通过利用马尔科夫高斯过程的等效离散状态空间表示，并使用卡尔曼滤波和平滑技术实现了线性时间的GPVAE训练。在各种高维时间和时空任务中，该方法表现优异。

    

    在许多高维时间序列建模问题中，序列VAE已经被广泛应用，其中许多变种模型依赖于离散时间机制，如循环神经网络（RNN）。另一方面，连续时间方法最近在非规则采样时间序列的背景下引起了人们的兴趣，在这种情况下，它们可以更好地处理数据。其中一种是高斯过程变分自编码器（GPVAEs），其中VAE先验被设置为高斯过程（GP）。然而，GPVAEs的一个主要限制是它继承了高斯过程的立方计算成本，使其对实际应用者不太吸引人。在这项工作中，我们利用马尔科夫高斯过程的等效离散状态空间表示，通过卡尔曼滤波和平滑来实现线性时间的GPVAE训练。对于我们的模型，马尔可夫高斯过程变分自编码器（MGPVAE），我们在各种高维时间和时空任务上展示了我们的方法的有利性能。

    Sequential VAEs have been successfully considered for many high-dimensional time series modelling problems, with many variant models relying on discrete-time mechanisms such as recurrent neural networks (RNNs). On the other hand, continuous-time methods have recently gained attraction, especially in the context of irregularly-sampled time series, where they can better handle the data than discrete-time methods. One such class are Gaussian process variational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian process (GP). However, a major limitation of GPVAEs is that it inherits the cubic computational cost as GPs, making it unattractive to practioners. In this work, we leverage the equivalent discrete state space representation of Markovian GPs to enable linear time GPVAE training via Kalman filtering and smoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of high-dimensional temporal and spatiotemporal tasks that our method performs favourably compar
    
[^37]: SGD的高维极限定理：有效动力学和临界尺度

    High-dimensional limit theorems for SGD: Effective dynamics and critical scaling. (arXiv:2206.04030v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.04030](http://arxiv.org/abs/2206.04030)

    本文研究了高维极限下具有恒定步长的随机梯度下降算法（SGD）的可扩展极限，我们证明了当维度趋于无穷时，SGD的轨迹的极限定理。我们的方法允许选择要跟踪的总结统计量、初始化和步长，并且得到了球形（ODE）和扩散（SDE）极限。我们还展示了步长的临界尺度，这个尺度下，有效的球形动力学与梯度流相匹配，但是出现了一个新的修正项，改变了相图。这个有效动力学的不动点对应的扩散极限可能非常复杂。

    

    我们研究了在高维极限下，具有恒定步长的随机梯度下降（SGD）的可扩展极限。我们证明了SGD的总结统计轨迹（即有限维函数）在维度趋于无穷大时的极限定理。我们的方法允许选择要跟踪的总结统计量、初始化和步长。它产生了一个在前述选择上极其依赖的球形（ODE）和扩散（SDE）极限。我们展示了步长的临界尺度，低于这个尺度，有效的球形动力学与人口损失的梯度流相匹配，但在这个尺度上，出现了一个新的修正项，改变了相图。关于这个有效动力学的不动点，相应的扩散极限可能非常复杂甚至退化。我们在一些流行的例子上展示了我们的方法，包括尖峰矩阵和张量模型的估计以及通过两层网络进行分类。

    We study the scaling limits of stochastic gradient descent (SGD) with constant step-size in the high-dimensional regime. We prove limit theorems for the trajectories of summary statistics (i.e., finite-dimensional functions) of SGD as the dimension goes to infinity. Our approach allows one to choose the summary statistics that are tracked, the initialization, and the step-size. It yields both ballistic (ODE) and diffusive (SDE) limits, with the limit depending dramatically on the former choices. We show a critical scaling regime for the step-size, below which the effective ballistic dynamics matches gradient flow for the population loss, but at which, a new correction term appears which changes the phase diagram. About the fixed points of this effective dynamics, the corresponding diffusive limits can be quite complex and even degenerate. We demonstrate our approach on popular examples including estimation for spiked matrix and tensor models and classification via two-layer networks fo
    
[^38]: 基于网络结构的局部自适应多重检验算法，及其在全基因组关联研究中的应用

    Locally Adaptive Algorithms for Multiple Testing with Network Structure, with Application to Genome-Wide Association Studies. (arXiv:2203.11461v4 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2203.11461](http://arxiv.org/abs/2203.11461)

    本文提出了一种基于网络结构的局部自适应结构学习算法，可将LD网络数据和多个样本的辅助数据整合起来，通过数据驱动的权重分配方法实现对多重检验的控制，并在网络数据具有信息量时具有更高的功效。

    

    链接分析在全基因组关联研究中起着重要作用，特别是在揭示与疾病表型相关的连锁不平衡（LD）的SNP共同影响方面。然而，LD网络数据的潜力在文献中往往被忽视或未充分利用。在本文中，我们提出了一个局部自适应结构学习算法（LASLA），为整合网络数据或来自相关源域的多个样本的辅助数据提供了一个有原则且通用的框架；可能具有不同的维度/结构和不同的人群。LASLA采用$p$值加权方法，利用结构洞察力为各个检验点分配数据驱动的权重。理论分析表明，当主要统计量独立或弱相关时，LASLA可以渐近地控制FDR，并在网络数据具有信息量时实现更高的功效。通过各种合成实验和一个应用案例，展示了LASLA的效率。

    Linkage analysis has provided valuable insights to the GWAS studies, particularly in revealing that SNPs in linkage disequilibrium (LD) can jointly influence disease phenotypes. However, the potential of LD network data has often been overlooked or underutilized in the literature. In this paper, we propose a locally adaptive structure learning algorithm (LASLA) that provides a principled and generic framework for incorporating network data or multiple samples of auxiliary data from related source domains; possibly in different dimensions/structures and from diverse populations. LASLA employs a $p$-value weighting approach, utilizing structural insights to assign data-driven weights to individual test points. Theoretical analysis shows that LASLA can asymptotically control FDR with independent or weakly dependent primary statistics, and achieve higher power when the network data is informative. Efficiency again of LASLA is illustrated through various synthetic experiments and an applica
    
[^39]: 长期持续混淆情况下的因果推断与数据组合研究

    Long-term Causal Inference Under Persistent Confounding via Data Combination. (arXiv:2202.07234v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2202.07234](http://arxiv.org/abs/2202.07234)

    本研究通过数据组合解决了长期治疗效果识别和估计中的持续未测量混淆因素挑战，并提出了三种新的识别策略和估计器。

    

    我们研究了当实验数据和观察数据同时存在时，长期治疗效果的识别和估计问题。由于长期结果仅在长时间延迟后才观察到，在实验数据中无法测量，但在观察数据中有记录。然而，这两种类型的数据都包含对一些短期结果的观察。在本文中，我们独特地解决了持续未测量混淆因素的挑战，即一些未测量混淆因素可以同时影响治疗、短期结果和长期结果，而这会使得之前文献中的识别策略无效。为了解决这个挑战，我们利用多个短期结果的连续结构，为平均长期治疗效果提出了三种新的识别策略。我们进一步提出了三种对应的估计器，并证明了它们的渐近一致性和渐近正态性。最后，我们将我们的方法应用于估计长期治疗效果。

    We study the identification and estimation of long-term treatment effects when both experimental and observational data are available. Since the long-term outcome is observed only after a long delay, it is not measured in the experimental data, but only recorded in the observational data. However, both types of data include observations of some short-term outcomes. In this paper, we uniquely tackle the challenge of persistent unmeasured confounders, i.e., some unmeasured confounders that can simultaneously affect the treatment, short-term outcomes and the long-term outcome, noting that they invalidate identification strategies in previous literature. To address this challenge, we exploit the sequential structure of multiple short-term outcomes, and develop three novel identification strategies for the average long-term treatment effect. We further propose three corresponding estimators and prove their asymptotic consistency and asymptotic normality. We finally apply our methods to esti
    
[^40]: 最小化最大化风险分类器与0-1损失

    Minimax risk classifiers with 0-1 loss. (arXiv:2201.06487v6 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2201.06487](http://arxiv.org/abs/2201.06487)

    本论文介绍了最小化最大化风险分类器（MRCs），旨在通过最小化与可能包含基础分布的分布的不确定性集合相对应的最坏情况下的0-1损失来提供严格的性能保证。使用特征映射和特征核，MRCs在学习时具有强度普遍一致性，并且提供了高效的优化技术和准确的分类能力。

    

    监督分类技术使用训练样本来学习一种具有小期望0-1损失（错误概率）的分类规则。传统方法通过使用代理损失而不是0-1损失，并考虑特定的规则族（假设类）来实现可计算的学习和样本外泛化。本文提出了最小化最大化风险分类器（MRCs），它们最小化与可以包含基础分布的分布的不确定性集合相对应的最坏情况下的0-1损失，具有可调的置信度。我们证明了MRCs可以在学习时提供严格的性能保证，并且使用由特征映射给出的特征核是强度普遍一致的。本文还提出了MRC学习的高效优化技术，并展示了所提出的方法在实践中可以提供准确的分类和严格的性能保证。

    Supervised classification techniques use training samples to learn a classification rule with small expected 0-1 loss (error probability). Conventional methods enable tractable learning and provide out-of-sample generalization by using surrogate losses instead of the 0-1 loss and considering specific families of rules (hypothesis classes). This paper presents minimax risk classifiers (MRCs) that minize the worst-case 0-1 loss with respect to uncertainty sets of distributions that can include the underlying distribution, with a tunable confidence. We show that MRCs can provide tight performance guarantees at learning and are strongly universally consistent using feature mappings given by characteristic kernels. The paper also proposes efficient optimization techniques for MRC learning and shows that the methods presented can provide accurate classification together with tight performance guarantees in practice.
    
[^41]: MNL上下文Bandit问题的简便在线学习算法

    A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit. (arXiv:2011.14033v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2011.14033](http://arxiv.org/abs/2011.14033)

    本文提供了一个新颖的、不需要调整指数参数的MNL-Contextual Bandit问题的简便在线学习算法。算法具有与该问题的最佳理论界限匹配的遗憾上界。

    

    本文考虑了MNL-Bandit问题的上下文变体。更具体地说，我们考虑了一个动态集合优化问题，其中决策者向消费者提供一组产品（购物清单），并在每个回合观察响应。消费者购买产品以最大化他们的效用。我们假设一组属性描述了产品，产品的平均效用与这些属性的值呈线性关系。我们使用广泛使用的Multinomial Logit（MNL）模型建模消费者选择行为，并考虑在优化销售周期$T$内累积收益的同时动态学习模型参数的决策者问题。尽管这个问题近来引起了相当大的关注，但许多现有方法通常涉及解决一个难以处理的非凸优化问题。他们的理论性能保证取决于一个可能非常大的问题相关参数。特别地，现有方法需要调整随着属性集规模指数增长的调整参数。本文提供了一种新颖的MNL-Contextual Bandit问题的简便在线学习算法，它不需要调整此类指数参数。我们展示我们的算法具有与该问题的最佳理论界限匹配的遗憾上界。我们还通过模拟和真实世界实验证明了我们算法的有效性。

    In this paper, we consider the contextual variant of the MNL-Bandit problem. More specifically, we consider a dynamic set optimization problem, where a decision-maker offers a subset (assortment) of products to a consumer and observes the response in every round. Consumers purchase products to maximize their utility. We assume that a set of attributes describe the products, and the mean utility of a product is linear in the values of these attributes. We model consumer choice behavior using the widely used Multinomial Logit (MNL) model and consider the decision maker problem of dynamically learning the model parameters while optimizing cumulative revenue over the selling horizon $T$. Though this problem has attracted considerable attention in recent times, many existing methods often involve solving an intractable non-convex optimization problem. Their theoretical performance guarantees depend on a problem-dependent parameter which could be prohibitively large. In particular, existing 
    
[^42]: 通过高斯过程混合实现主动学习中的局部函数复杂性

    Local Function Complexity for Active Learning via Mixture of Gaussian Processes. (arXiv:1902.10664v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1902.10664](http://arxiv.org/abs/1902.10664)

    本文通过利用局部函数复杂性（LFC）的估计，建立了一个局部结构复杂性的概念，并将其用于发展一个与模型无关的主动学习框架。通过使用基于高斯过程回归（GPR）的局部多项式平滑（LPS）模型的类比，使得该框架具有鲁棒性和可伸缩性。

    

    真实世界的数据的不均匀性，例如观测噪声水平的变化或源函数结构复杂性的变化，给统计推断带来了一系列独特的挑战。考虑到这些因素可以在物理资源或计算时间有限的情况下显著提高预测能力。本文借鉴了最近关于局部多项式平滑（LPS）领域中局部函数复杂性（LFC）的估计的理论结果，建立了一个局部结构复杂性的概念，并用它来开发一个与模型无关的主动学习（AL）框架。由于其依赖于点估计，LPS模型类在处理通常伴随真实世界问题的大输入空间维度时不具有鲁棒性和可伸缩性。在本文中，我们推导和估计基于高斯过程回归（GPR）的LPS-based LFC的类比，并将其作为以上框架的替代，使之具有鲁棒性和可伸缩性。

    Inhomogeneities in real-world data, e.g., due to changes in the observation noise level or variations in the structural complexity of the source function, pose a unique set of challenges for statistical inference. Accounting for them can greatly improve predictive power when physical resources or computation time is limited. In this paper, we draw on recent theoretical results on the estimation of local function complexity (LFC), derived from the domain of local polynomial smoothing (LPS), to establish a notion of local structural complexity, which is used to develop a model-agnostic active learning (AL) framework. Due to its reliance on pointwise estimates, the LPS model class is not robust and scalable concerning large input space dimensions that typically come along with real-world problems. Here, we derive and estimate the Gaussian process regression (GPR)-based analog of the LPS-based LFC and use it as a substitute in the above framework to make it robust and scalable. We assess t
    

