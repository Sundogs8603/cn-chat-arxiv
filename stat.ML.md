# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information.](http://arxiv.org/abs/2304.13646) | 本研究提出一种嵌入非凸分段仿射决策规则的经验风险最小化方法，用于学习特征与最优决策之间的直接映射。所提出的方法可用于广泛的非凸型SP问题，并且在数值研究中表现出优越的性能。 |
| [^2] | [Diffsurv: Differentiable sorting for censored time-to-event data.](http://arxiv.org/abs/2304.13594) | 为了处理带有审核任务的生存分析，我们提出了一种基于Diffsurv的新方法，通过预测可能组合矩阵，考虑到引入的标签不确定性，实现可区分的排序。 |
| [^3] | [Thompson Sampling Regret Bounds for Contextual Bandits with sub-Gaussian rewards.](http://arxiv.org/abs/2304.13593) | 本文研究了子高斯奖励情境下的 Thompson 抽样算法在情境 Bandit 问题中的性能，并引入了提高信息比率的新边界。 |
| [^4] | [Energy-Based Sliced Wasserstein Distance.](http://arxiv.org/abs/2304.13586) | 本文提出了一种能量为基础的切片Wasserstein距离，并将其参数化，以克服传统方法中的固定先验分布缺乏信息和优化最佳分布昂贵不稳定的局限。 |
| [^5] | [Improvements on Recommender System based on Mathematical Principles.](http://arxiv.org/abs/2304.13579) | 本文基于数学原理研究推荐系统算法的实现和改进方法，重要的概率算法是提高算法准确性和速度的关键，同时介绍两种不同数学距离的优缺点。 |
| [^6] | [A mean-field games laboratory for generative modeling.](http://arxiv.org/abs/2304.13534) | 本文提出了使用均场博弈作为实验室对生成模型进行设计和分析的方法，并建立了这种方法与主要流动和扩散型生成模型之间的关联。通过研究每个生成模型与它们相关的 MFG 的最优条件，本文提出了一个基于双人 MFG 的新的生成模型，该模型在提高样本多样性和逼真度的同时改善了解缠结和公平性。 |
| [^7] | [FLEX: an Adaptive Exploration Algorithm for Nonlinear Systems.](http://arxiv.org/abs/2304.13426) | FLEX是一种非线性系统的自适应探索算法，使用最优实验设计方法，需要最少的资源，并用于下游的基于模型的经典控制任务中。 |
| [^8] | [Mutual information of spin systems from autoregressive neural networks.](http://arxiv.org/abs/2304.13412) | 本论文介绍了一种基于自回归神经网络和Monte Carlo采样的直接方法来估算自旋系统的双部分互信息，可以研究任意子系统的几何形状，并且在Ising模型上演示了此方法的效果。 |
| [^9] | [Multi-Task Learning Regression via Convex Clustering.](http://arxiv.org/abs/2304.13342) | 本研究提出了一种基于凸聚类的多任务回归学习方法，该方法使用群组融合正则化方法对任务进行聚类，并使用聚类中心点参数代表任务聚类中心，从而避免了不同聚类之间信息的干扰。 |
| [^10] | [Evaluation of Regularization-based Continual Learning Approaches: Application to HAR.](http://arxiv.org/abs/2304.13327) | 本研究评估了基于正则化的连续学习方法在HAR领域的应用，并比较了三种方法的优缺点。实验证明，这些方法提高了模型学习新类别的能力，同时保持了模型在先前学习的类别上的准确性。 |
| [^11] | [Numerical Approximation of Andrews Plots with Optimal Spatial-Spectral Smoothing.](http://arxiv.org/abs/2304.13239) | 本文提出了一种用最小化程序计算空间谱平滑的Andrews图的方法，并证明了解集是一个流形。该方法可用于高维数据集的快速可视化。 |
| [^12] | [An Efficient Doubly-Robust Test for the Kernel Treatment Effect.](http://arxiv.org/abs/2304.13237) | 本文提出了一种高效的基于核的双重稳健检验方法，用于检验治疗的分布效应，保证了一类错误有效性。 |
| [^13] | [Kernel Methods are Competitive for Operator Learning.](http://arxiv.org/abs/2304.13202) | 本文提出了一个核方法算子学习框架，在对多组数据进行全面比较后，结果表明该方法在多种设置下都是一种具有竞争力的算子学习方法。 |
| [^14] | [Exact recovery for the non-uniform Hypergraph Stochastic Block Model.](http://arxiv.org/abs/2304.13139) | 本文首次建立了非均匀超图随机块模型（HSBM）下的精确恢复的尖锐阈值，提供了两种有效算法，并依赖于非均匀随机超图的邻接矩阵的集中和正则化进行理论分析。 |
| [^15] | [Genetically-inspired convective heat transfer enhancement.](http://arxiv.org/abs/2304.12618) | 本文研究了基于遗传算法的对流传热增强方法，通过对自由流相交的六个间隙喷气孔进行控制，优化了成本函数，最终实现了对对流传热速率的提高。 |
| [^16] | [Non-asymptotic analysis of Langevin-type Monte Carlo algorithms.](http://arxiv.org/abs/2303.12407) | 本文提出了一种新的Langevin型算法并应用于吉布斯分布。通过提出的2-Wasserstein距离上限，我们发现势函数的耗散性以及梯度 $\alpha>1/3$ 下的 $\alpha$-H\"{o}lder连续性可以保证算法具有接近零的误差。新的Langevin型算法还可以应用于无凸性或连续可微性的势函数。 |
| [^17] | [Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting.](http://arxiv.org/abs/2302.08635) | 该论文提出了一种生成因果表示学习方法，通过利用因果关系来实现分布转移下的知识迁移，主要应用于面向多样性预测的问题。 |
| [^18] | [One-vs-the-Rest Loss to Focus on Important Samples in Adversarial Training.](http://arxiv.org/abs/2207.10283) | 本文提出了一种名为SOVR的对抗训练损失函数，可以聚焦重要样本，增加对抗攻击下的对数几率间隔，从而在实验中表现出对抗攻击的有效性。 |
| [^19] | [Probabilistic Reconciliation of Count Time Series.](http://arxiv.org/abs/2207.09322) | 本文提出了一种新的概率计数时间序列调和方法，产生协调的概率质量函数，相比于概率高斯调和，能够带来显著的预测改进。 |
| [^20] | [Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation.](http://arxiv.org/abs/2203.11740) | 该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。 |
| [^21] | [Benchmarking Multivariate Time Series Classification Algorithms.](http://arxiv.org/abs/2007.13156) | 该论文比较了单变量时间序列分类（TSC）与多元TSC(MTSC)问题的算法。作者测试了基于深度学习、形状和单词袋方法的算法，并将其与维度无关的方法进行比较。 |
| [^22] | [A tale of two toolkits, report the third: on the usage and performance of HIVE-COTE v1.0.](http://arxiv.org/abs/2004.06069) | 介绍了用于时间序列分类的异构元集成算法 HIVE-COTE 的最新稳定版本 1.0，提供了使用指南，并通过实验评估了其性能和资源使用情况，并与三种近期提出的算法进行了比较。 |

# 详细

[^1]: 基于数据驱动的分段仿射决策规则用于带协变信息的随机规划

    Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information. (arXiv:2304.13646v1 [math.OC])

    [http://arxiv.org/abs/2304.13646](http://arxiv.org/abs/2304.13646)

    本研究提出一种嵌入非凸分段仿射决策规则的经验风险最小化方法，用于学习特征与最优决策之间的直接映射。所提出的方法可用于广泛的非凸型SP问题，并且在数值研究中表现出优越的性能。

    

    本文针对带协变信息的随机规划，提出了一种嵌入非凸分段仿射决策规则(PADR)的经验风险最小化(ERM)方法，旨在学习特征与最优决策之间的直接映射。我们建立了基于PADR的ERM模型的非渐近一致性结果，可用于无约束问题，以及约束问题的渐近一致性结果。为了解决非凸和非可微的ERM问题，我们开发了一个增强的随机主导下降算法，并建立了沿（复合强）方向稳定性的渐近收敛以及复杂性分析。我们表明，所提出的PADR-based ERM方法适用于广泛的非凸型SP问题，并具有理论一致性保证和计算可处理性。数值研究表明，在各种设置下，PADR-based ERM方法相对于最先进的方法具有优越的性能。

    Focusing on stochastic programming (SP) with covariate information, this paper proposes an empirical risk minimization (ERM) method embedded within a nonconvex piecewise affine decision rule (PADR), which aims to learn the direct mapping from features to optimal decisions. We establish the nonasymptotic consistency result of our PADR-based ERM model for unconstrained problems and asymptotic consistency result for constrained ones. To solve the nonconvex and nondifferentiable ERM problem, we develop an enhanced stochastic majorization-minimization algorithm and establish the asymptotic convergence to (composite strong) directional stationarity along with complexity analysis. We show that the proposed PADR-based ERM method applies to a broad class of nonconvex SP problems with theoretical consistency guarantees and computational tractability. Our numerical study demonstrates the superior performance of PADR-based ERM methods compared to state-of-the-art approaches under various settings,
    
[^2]: Diffsurv: 可区分的排序用于有审查时间的数据

    Diffsurv: Differentiable sorting for censored time-to-event data. (arXiv:2304.13594v1 [cs.LG])

    [http://arxiv.org/abs/2304.13594](http://arxiv.org/abs/2304.13594)

    为了处理带有审核任务的生存分析，我们提出了一种基于Diffsurv的新方法，通过预测可能组合矩阵，考虑到引入的标签不确定性，实现可区分的排序。

    

    生存分析是一项重要的半监督任务，在机器学习中具有很多现实世界的应用，尤其是在医疗领域。目前，生存分析最常见的方法是基于Cox的部分似然，可解释为在一致性指数的下限上优化的排序模型。这种排序模型和Cox的部分似然之间的关系仅考虑了成对比较。最近的工作发展了可区分排序的方法，放松了这种成对独立假设，使得能够对样本集进行排序。然而，当前的可区分排序方法不能考虑到许多真实世界数据中的关键因素——审查。为了解决这个限制，我们提出了一种新的方法Diffsurv。我们通过预测可能排列矩阵来扩展不同iable排序方法以处理审查任务，这些矩阵考虑到审查样本引入的标签不确定性。我们将这种方法与方法进行比较...

    Survival analysis is a crucial semi-supervised task in machine learning with numerous real-world applications, particularly in healthcare. Currently, the most common approach to survival analysis is based on Cox's partial likelihood, which can be interpreted as a ranking model optimized on a lower bound of the concordance index. This relation between ranking models and Cox's partial likelihood considers only pairwise comparisons. Recent work has developed differentiable sorting methods which relax this pairwise independence assumption, enabling the ranking of sets of samples. However, current differentiable sorting methods cannot account for censoring, a key factor in many real-world datasets. To address this limitation, we propose a novel method called Diffsurv. We extend differentiable sorting methods to handle censored tasks by predicting matrices of possible permutations that take into account the label uncertainty introduced by censored samples. We contrast this approach with meth
    
[^3]: 基于互信息比例的 Thompson 抽样算法在子高斯奖励情境下的遗憾界研究

    Thompson Sampling Regret Bounds for Contextual Bandits with sub-Gaussian rewards. (arXiv:2304.13593v1 [stat.ML])

    [http://arxiv.org/abs/2304.13593](http://arxiv.org/abs/2304.13593)

    本文研究了子高斯奖励情境下的 Thompson 抽样算法在情境 Bandit 问题中的性能，并引入了提高信息比率的新边界。

    

    本文研究了基于 Neu et al. 的框架和其提出的互信息比例概念的情境 Bandit 问题中的 Thompson 抽样算法表现。首先，我们证明了 Thompson 抽样期望累计遗憾的全面边界取决于环境参数和历史的互信息。然后，我们引入了对子高斯奖励成立的提高信息比率的新边界，从而推广了 Neu 等人的结果，其分析要求二进制奖励。最后，我们为非结构化有界情境 Bandit、结构化有界情境 Bandit（拉普拉斯似然函数）、结构化 Bernoulli Bandit 和有界线性情境 Bandit 提供了明确的遗憾界。

    In this work, we study the performance of the Thompson Sampling algorithm for Contextual Bandit problems based on the framework introduced by Neu et al. and their concept of lifted information ratio. First, we prove a comprehensive bound on the Thompson Sampling expected cumulative regret that depends on the mutual information of the environment parameters and the history. Then, we introduce new bounds on the lifted information ratio that hold for sub-Gaussian rewards, thus generalizing the results from Neu et al. which analysis requires binary rewards. Finally, we provide explicit regret bounds for the special cases of unstructured bounded contextual bandits, structured bounded contextual bandits with Laplace likelihood, structured Bernoulli bandits, and bounded linear contextual bandits.
    
[^4]: 能量为基础的切片Wasserstein距离

    Energy-Based Sliced Wasserstein Distance. (arXiv:2304.13586v1 [stat.ML])

    [http://arxiv.org/abs/2304.13586](http://arxiv.org/abs/2304.13586)

    本文提出了一种能量为基础的切片Wasserstein距离，并将其参数化，以克服传统方法中的固定先验分布缺乏信息和优化最佳分布昂贵不稳定的局限。

    

    切片Wasserstein（SW）距离被广泛认为是两个概率测度之间的一种统计有效且计算高效的度量。SW距离的一个关键部分是切片分布。目前有两种方法来选择这个分布。第一种方法是使用固定的先验分布。第二种是优化归属于参数分布族的最佳分布，并且可以最大化期望的距离。然而，这两种方法都有局限性。固定的先验分布在突出能够区分两个常规概率测度的投影方向方面缺乏信息。而优化最佳分布通常是昂贵和不稳定的。此外，设计候选分布的参数分布族可能会很容易被错误指定。为了解决这些问题，我们提出将切片分布设计为基于能量的分布，并将其参数化，从而使其更加通用而稳健。

    The sliced Wasserstein (SW) distance has been widely recognized as a statistically effective and computationally efficient metric between two probability measures. A key component of the SW distance is the slicing distribution. There are two existing approaches for choosing this distribution. The first approach is using a fixed prior distribution. The second approach is optimizing for the best distribution which belongs to a parametric family of distributions and can maximize the expected distance. However, both approaches have their limitations. A fixed prior distribution is non-informative in terms of highlighting projecting directions that can discriminate two general probability measures. Doing optimization for the best distribution is often expensive and unstable. Moreover, designing the parametric family of the candidate distribution could be easily misspecified. To address the issues, we propose to design the slicing distribution as an energy-based distribution that is parameter
    
[^5]: 基于数学原理的推荐系统改进

    Improvements on Recommender System based on Mathematical Principles. (arXiv:2304.13579v1 [cs.IR])

    [http://arxiv.org/abs/2304.13579](http://arxiv.org/abs/2304.13579)

    本文基于数学原理研究推荐系统算法的实现和改进方法，重要的概率算法是提高算法准确性和速度的关键，同时介绍两种不同数学距离的优缺点。

    

    本文将研究推荐系统的实现原理和算法。我们将基于数学原理解释推荐算法，并寻找可行的改进方法。概率算法在推荐系统中具有重要意义，我们将描述它们如何帮助提高算法的准确性和速度。本文还将详细阐述两种不同数学距离描述相似度的优缺点。

    In this article, we will research the Recommender System's implementation about how it works and the algorithms used. We will explain the Recommender System's algorithms based on mathematical principles, and find feasible methods for improvements. The algorithms based on probability have its significance in Recommender System, we will describe how they help to increase the accuracy and speed of the algorithms. Both the weakness and the strength of two different mathematical distance used to describe the similarity will be detailed illustrated in this article.
    
[^6]: 用均场博弈为生成模型搭建实验室

    A mean-field games laboratory for generative modeling. (arXiv:2304.13534v1 [stat.ML])

    [http://arxiv.org/abs/2304.13534](http://arxiv.org/abs/2304.13534)

    本文提出了使用均场博弈作为实验室对生成模型进行设计和分析的方法，并建立了这种方法与主要流动和扩散型生成模型之间的关联。通过研究每个生成模型与它们相关的 MFG 的最优条件，本文提出了一个基于双人 MFG 的新的生成模型，该模型在提高样本多样性和逼真度的同时改善了解缠结和公平性。

    

    本文展示了均场博弈 (MFGs) 作为一种数学框架用于解释、增强和设计生成模型的多功能性。我们建立了 MFGs 与主要流动和扩散型生成模型之间关联，并通过不同的粒子动力学和代价函数推导了这三个类别的生成模型。此外，我们通过研究它们相关的 MFG 的最优条件——一组耦合的非线性偏微分方程，来研究每个生成模型的数学结构和特性。本文还提出了一个新的基于双人 MFG 的生成模型，其中一个代理合成样本，另一个代理对样本进行识别，理论和实验结果表明，该模型生成的样本多样且逼真，同时与基准模型相比，改善了解缠结和公平性。总之，本文突显了 MFGs 作为设计和分析生成模型的实验室的潜力。

    In this paper, we demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. There is a pervasive sense in the generative modeling community that the various flow and diffusion-based generative models have some foundational common structure and interrelationships. We establish connections between MFGs and major classes of flow and diffusion-based generative models including continuous-time normalizing flows, score-based models, and Wasserstein gradient flows. We derive these three classes of generative models through different choices of particle dynamics and cost functions. Furthermore, we study the mathematical structure and properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled nonlinear partial differential equations (PDEs). The theory of MFGs, therefore, enables the study of generative models through the theory of nonlinear PDEs. Throu
    
[^7]: FLEX：一种适用于非线性系统的自适应探索算法

    FLEX: an Adaptive Exploration Algorithm for Nonlinear Systems. (arXiv:2304.13426v1 [cs.LG])

    [http://arxiv.org/abs/2304.13426](http://arxiv.org/abs/2304.13426)

    FLEX是一种非线性系统的自适应探索算法，使用最优实验设计方法，需要最少的资源，并用于下游的基于模型的经典控制任务中。

    

    基于模型的加强学习是一种强大的工具，但收集适合系统的精确模型的数据可能很昂贵。因此以样本有效的方式探索未知环境非常重要。然而，动力学的复杂性以及实际系统的计算限制使得这一任务具有挑战性。在本文中，我们介绍了FLEX，这是一种基于最优实验设计的非线性动力学探索算法。我们的策略最大化下一步信息，从而得到自适应探索算法，与通用参数化学习模型兼容，并且需要最少的资源。我们在涵盖不同设置的若干非线性环境中测试了我们的方法，包括时变动力学。牢记探索是为了服务于开发性目标，我们还将我们的算法应用于下游基于模型的经典控制任务，并将其与其他最先进的基于模型和模型自由方法进行了比较。

    Model-based reinforcement learning is a powerful tool, but collecting data to fit an accurate model of the system can be costly. Exploring an unknown environment in a sample-efficient manner is hence of great importance. However, the complexity of dynamics and the computational limitations of real systems make this task challenging. In this work, we introduce FLEX, an exploration algorithm for nonlinear dynamics based on optimal experimental design. Our policy maximizes the information of the next step and results in an adaptive exploration algorithm, compatible with generic parametric learning models and requiring minimal resources. We test our method on a number of nonlinear environments covering different settings, including time-varying dynamics. Keeping in mind that exploration is intended to serve an exploitation objective, we also test our algorithm on downstream model-based classical control tasks and compare it to other state-of-the-art model-based and model-free approaches. T
    
[^8]: 基于自回归神经网络的自旋系统互信息的估算

    Mutual information of spin systems from autoregressive neural networks. (arXiv:2304.13412v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2304.13412](http://arxiv.org/abs/2304.13412)

    本论文介绍了一种基于自回归神经网络和Monte Carlo采样的直接方法来估算自旋系统的双部分互信息，可以研究任意子系统的几何形状，并且在Ising模型上演示了此方法的效果。

    

    我们描述了一种基于Monte Carlo采样和自回归神经网络的直接方法来估算经典自旋系统的双部分互信息。它允许研究任意子系统的几何形状，并且可推广到经典场理论。我们用Ising模型的四个分区演示了它的效果，包括多重连接的偶奇分割。我们表明，当远离临界温度时，面积规律得到了满足：常数项是通用的，而比例系数对于偶奇分割是不同的。

    We describe a direct approach to estimate bipartite mutual information of a classical spin system based on Monte Carlo sampling enhanced by autoregressive neural networks. It allows studying arbitrary geometries of subsystems and can be generalized to classical field theories. We demonstrate it on the Ising model for four partitionings, including a multiply-connected even-odd division. We show that the area law is satisfied for temperatures away from the critical temperature: the constant term is universal, whereas the proportionality coefficient is different for the even-odd partitioning.
    
[^9]: 基于凸聚类的多任务回归学习

    Multi-Task Learning Regression via Convex Clustering. (arXiv:2304.13342v1 [stat.ME])

    [http://arxiv.org/abs/2304.13342](http://arxiv.org/abs/2304.13342)

    本研究提出了一种基于凸聚类的多任务回归学习方法，该方法使用群组融合正则化方法对任务进行聚类，并使用聚类中心点参数代表任务聚类中心，从而避免了不同聚类之间信息的干扰。

    

    多任务学习(MTL)是一种旨在通过共享相关任务的公共信息来提高估计和预测的性能的方法。在MTL中，有几个关于关系和方法的假设用于结合任务。在实际情况下，其中一个自然假设是将任务分类为具有特征的一些聚类。针对这种假设，群组融合正则化方法通过缩小任务之间的差异来执行任务聚类。这使我们能够转移同一聚类中的公共信息。然而，该方法也会在不同聚类之间转移信息，从而加剧估计和预测的错误。为了解决这个问题，我们提出了一种MTL方法，该方法具有代表任务聚类中心的中心点参数。由于该模型将参数分为回归参数和聚类参数，因此我们可以改善估计和预测。

    Multi-task learning (MTL) is a methodology that aims to improve the general performance of estimation and prediction by sharing common information among related tasks. In the MTL, there are several assumptions for the relationships and methods to incorporate them. One of the natural assumptions in the practical situation is that tasks are classified into some clusters with their characteristics. For this assumption, the group fused regularization approach performs clustering of the tasks by shrinking the difference among tasks. This enables us to transfer common information within the same cluster. However, this approach also transfers the information between different clusters, which worsens the estimation and prediction. To overcome this problem, we propose an MTL method with a centroid parameter representing a cluster center of the task. Because this model separates parameters into the parameters for regression and the parameters for clustering, we can improve estimation and predict
    
[^10]: 基于正则化的连续学习方法的评估：应用于HAR

    Evaluation of Regularization-based Continual Learning Approaches: Application to HAR. (arXiv:2304.13327v1 [cs.AI])

    [http://arxiv.org/abs/2304.13327](http://arxiv.org/abs/2304.13327)

    本研究评估了基于正则化的连续学习方法在HAR领域的应用，并比较了三种方法的优缺点。实验证明，这些方法提高了模型学习新类别的能力，同时保持了模型在先前学习的类别上的准确性。

    

    普适计算在许多重要的领域中提供服务，包括健康和福利这个相关且动态的领域。在这个领域中，人类活动识别（HAR）在近年来引起了很多关注。目前的解决方案依赖于机器学习（ML）模型并取得了令人印象深刻的结果。然而，这些模型的演进仍然很困难，除非进行完整的重新训练。为了解决这个问题，连续学习的概念在今天非常有前途，尤其是基于正则化的技术。这些技术非常有趣，因为它们很简单并且成本低。已经进行了初步的研究，并展示了有希望的结果。然而，它们仍然非常专业化并且难以比较。在本文中，我们提供了三种基于正则化的方法在HAR领域的全面比较，并突出它们的优点和局限性。我们的实验基于公开可用的数据集进行，结果表明这些方法提高了模型学习新类别的能力，同时保持了模型在先前学习的类别上的准确性。

    Pervasive computing allows the provision of services in many important areas, including the relevant and dynamic field of health and well-being. In this domain, Human Activity Recognition (HAR) has gained a lot of attention in recent years. Current solutions rely on Machine Learning (ML) models and achieve impressive results. However, the evolution of these models remains difficult, as long as a complete retraining is not performed. To overcome this problem, the concept of Continual Learning is very promising today and, more particularly, the techniques based on regularization. These techniques are particularly interesting for their simplicity and their low cost. Initial studies have been conducted and have shown promising outcomes. However, they remain very specific and difficult to compare. In this paper, we provide a comprehensive comparison of three regularization-based methods that we adapted to the HAR domain, highlighting their strengths and limitations. Our experiments were con
    
[^11]: 用最优空间谱平滑方法数值逼近Andrews图

    Numerical Approximation of Andrews Plots with Optimal Spatial-Spectral Smoothing. (arXiv:2304.13239v1 [math.NA])

    [http://arxiv.org/abs/2304.13239](http://arxiv.org/abs/2304.13239)

    本文提出了一种用最小化程序计算空间谱平滑的Andrews图的方法，并证明了解集是一个流形。该方法可用于高维数据集的快速可视化。

    

    Andrews图提供了高维数据集的美观可视化。本工作证明了Andrews图（在使用数据集的主成分分值定义时）平均上是最优“平滑”的，并且在从欧几里得数据空间到$L^2([0,1])$的线性等距映射集合上解决了一个无限维度二次最小化程序。通过建立技术性机器对线性等距映射上的一般无限维二次最小化程序的解进行了表征，我们进一步证明了解集（在通常情况下）是一个流形。为了避免这个解集合中出现的模棱两可，我们在无限维优化程序中添加“谱平滑”项，以引导具有最优空间谱平滑效果的Andrews图。我们表征了该程序的（通常）解集，证明了结果图能够进行高效的数值逼近。这些空间谱平滑的Andrews图可用于高维数据集的有效计算。

    Andrews plots provide aesthetically pleasant visualizations of high-dimensional datasets. This work proves that Andrews plots (when defined in terms of the principal component scores of a dataset) are optimally ``smooth'' on average, and solve an infinite-dimensional quadratic minimization program over the set of linear isometries from the Euclidean data space to $L^2([0,1])$. By building technical machinery that characterizes the solutions to general infinite-dimensional quadratic minimization programs over linear isometries, we further show that the solution set is (in the generic case) a manifold. To avoid the ambiguities presented by this manifold of solutions, we add ``spectral smoothing'' terms to the infinite-dimensional optimization program to induce Andrews plots with optimal spatial-spectral smoothing. We characterize the (generic) set of solutions to this program and prove that the resulting plots admit efficient numerical approximations. These spatial-spectral smooth Andrew
    
[^12]: 一种有效的双重稳健核处理效应检验方法

    An Efficient Doubly-Robust Test for the Kernel Treatment Effect. (arXiv:2304.13237v1 [stat.ME])

    [http://arxiv.org/abs/2304.13237](http://arxiv.org/abs/2304.13237)

    本文提出了一种高效的基于核的双重稳健检验方法，用于检验治疗的分布效应，保证了一类错误有效性。

    

    二分治疗下的预期反事实差异是因果推断中最受欢迎的目标效应之一。然而，治疗可能具有超出平均值的效应，例如降低或提高方差。本文提出了一种新的基于核的治疗效应分布检验方法。本文的方法是基于核的、稳健的，保证了一类错误的有效性。此外，我们提出的算法是高效的，避免了置换的使用。

    The average treatment effect, which is the difference in expectation of the counterfactuals, is probably the most popular target effect in causal inference with binary treatments. However, treatments may have effects beyond the mean, for instance decreasing or increasing the variance. We propose a new kernel-based test for distributional effects of the treatment. It is, to the best of our knowledge, the first kernel-based, doubly-robust test with provably valid type-I error. Furthermore, our proposed algorithm is efficient, avoiding the use of permutations.
    
[^13]: 核方法在算子学习中表现竞争力

    Kernel Methods are Competitive for Operator Learning. (arXiv:2304.13202v1 [stat.ML])

    [http://arxiv.org/abs/2304.13202](http://arxiv.org/abs/2304.13202)

    本文提出了一个核方法算子学习框架，在对多组数据进行全面比较后，结果表明该方法在多种设置下都是一种具有竞争力的算子学习方法。

    

    我们提出了一个基于核的算子学习框架，并提供了先验误差分析和与流行的神经网络方法（如Deep Operator Net（DeepONet）[Lu et al.]和Fourier神经算子（FNO）[Li et al.]）的全面数字比较。我们考虑目标算子$\mathcal{G}^\dagger:\mathcal{U}\to\mathcal{V}$的输入/输出空间是再生核希尔伯特空间（RKHS）的情况，数据以输入/输出函数的部分观测$\varphi(v_i),\phi(u_i)$的形式出现，其中$v_i=\mathcal{G}^\dagger(u_i)$（$i=1,\ldots,N$），测量算子$\varphi:\mathcal{V}\to\mathbb{R}^m$和$\phi:\mathcal{U}\to\mathbb{R}^n$是线性的。在写$\psi:\mathbb{R}^n\to\mathcal{U}$和$\chi:\mathbb{R}^m\to\mathcal{V}$作为与$\phi$和$\varphi$相关的最佳恢复映射时，我们使用$\bar{f}$ 核映射 $L^2(\mathcal{U},\mathbb{R}^n)$ 定义一个$k$ 类型的最小二乘模型， 然后用 $\bar{\mathcal{G}}=\chi\circ\bar{f}\circ\psi$ 来近似$\mathcal{G}^\dagger$。 我们的分析涉及多个例子，包括常见的偏微分方程的算子近似，结果表明在多种设置下核方法都是一种具有竞争力的算子学习方法。

    We present a general kernel-based framework for learning operators between Banach spaces along with a priori error analysis and comprehensive numerical comparisons with popular neural net (NN) approaches such as Deep Operator Net (DeepONet) [Lu et al.] and Fourier Neural Operator (FNO) [Li et al.]. We consider the setting where the input/output spaces of target operator $\mathcal{G}^\dagger\,:\, \mathcal{U}\to \mathcal{V}$ are reproducing kernel Hilbert spaces (RKHS), the data comes in the form of partial observations $\phi(u_i), \varphi(v_i)$ of input/output functions $v_i=\mathcal{G}^\dagger(u_i)$ ($i=1,\ldots,N$), and the measurement operators $\phi\,:\, \mathcal{U}\to \mathbb{R}^n$ and $\varphi\,:\, \mathcal{V} \to \mathbb{R}^m$ are linear. Writing $\psi\,:\, \mathbb{R}^n \to \mathcal{U}$ and $\chi\,:\, \mathbb{R}^m \to \mathcal{V}$ for the optimal recovery maps associated with $\phi$ and $\varphi$, we approximate $\mathcal{G}^\dagger$ with $\bar{\mathcal{G}}=\chi \circ \bar{f} \ci
    
[^14]: 非均匀超图随机块模型的精确恢复

    Exact recovery for the non-uniform Hypergraph Stochastic Block Model. (arXiv:2304.13139v1 [math.ST])

    [http://arxiv.org/abs/2304.13139](http://arxiv.org/abs/2304.13139)

    本文首次建立了非均匀超图随机块模型（HSBM）下的精确恢复的尖锐阈值，提供了两种有效算法，并依赖于非均匀随机超图的邻接矩阵的集中和正则化进行理论分析。

    

    考虑在非均匀超图随机块模型（HSBM）下的随机超图中的社区检测问题，其中每个超边独立地以某些给定概率出现，该概率仅取决于其顶点的标签。我们在本文中首次建立了在这种非均匀情况下实现精确恢复的尖锐阈值，受到次要约束；尤其是，我们考虑了具有K类别的模型和对称二进制模型（K=2）。关键点是通过聚合所有均匀层的信息，即使在考虑每个层时似乎不可能实现精确恢复，我们也可以获得精确恢复。我们提供了两种有效算法，成功地在阈值以上实现了精确恢复。我们算法的理论分析依赖于非均匀随机超图的邻接矩阵的集中和正则化，这可能具有独立的兴趣。我们还解决了一些实际问题

    Consider the community detection problem in random hypergraphs under the non-uniform hypergraph stochastic block model (HSBM), where each hyperedge appears independently with some given probability depending only on the labels of its vertices. We establish, for the first time in the literature, a sharp threshold for exact recovery under this non-uniform case, subject to minor constraints; in particular, we consider the model with $K$ classes as well as the symmetric binary model ($K=2$). One crucial point here is that by aggregating information from all the uniform layers, we may obtain exact recovery even in cases when this may appear impossible if each layer were considered alone. Two efficient algorithms that successfully achieve exact recovery above the threshold are provided. The theoretical analysis of our algorithms relies on the concentration and regularization of the adjacency matrix for non-uniform random hypergraphs, which could be of independent interest. We also address so
    
[^15]: 基于遗传算法的对流传热增强

    Genetically-inspired convective heat transfer enhancement. (arXiv:2304.12618v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2304.12618](http://arxiv.org/abs/2304.12618)

    本文研究了基于遗传算法的对流传热增强方法，通过对自由流相交的六个间隙喷气孔进行控制，优化了成本函数，最终实现了对对流传热速率的提高。

    

    本文在平板上的紊流边界层(TBL)上，采用基于线性遗传算法控制(LGAC)的人工智能方法实现对流传热的增强。该控制方法采用了一组与自由流相交的六个间隙喷气孔。通过对载波频率，占空比和执行器之间的相位差的控制参数定义开环最优周期性激励。根据无扰动TBL和稳态喷流的控制，对控制定律进行了优化。成本函数包括壁面对流传热速率和执行成本。采用红外热成像和粒子图像测速技术评估了控制器的性能。最优控制器产生了略微不对称的流场。LGAC算法收敛于所有执行器的相同频率和占空比。如此频率非常接近于特征频率的倒数。

    The convective heat transfer in a turbulent boundary layer (TBL) on a flat plate is enhanced using an artificial intelligence approach based on linear genetic algorithms control (LGAC). The actuator is a set of six slot jets in crossflow aligned with the freestream. An open-loop optimal periodic forcing is defined by the carrier frequency, the duty cycle and the phase difference between actuators as control parameters. The control laws are optimised with respect to the unperturbed TBL and to the actuation with a steady jet. The cost function includes the wall convective heat transfer rate and the cost of the actuation. The performance of the controller is assessed by infrared thermography and characterised also with particle image velocimetry measurements. The optimal controller yields a slightly asymmetric flow field. The LGAC algorithm converges to the same frequency and duty cycle for all the actuators. It is noted that such frequency is strikingly equal to the inverse of the charac
    
[^16]: Langevin型Monte Carlo算法的非渐进分析

    Non-asymptotic analysis of Langevin-type Monte Carlo algorithms. (arXiv:2303.12407v1 [math.ST])

    [http://arxiv.org/abs/2303.12407](http://arxiv.org/abs/2303.12407)

    本文提出了一种新的Langevin型算法并应用于吉布斯分布。通过提出的2-Wasserstein距离上限，我们发现势函数的耗散性以及梯度 $\alpha>1/3$ 下的 $\alpha$-H\"{o}lder连续性可以保证算法具有接近零的误差。新的Langevin型算法还可以应用于无凸性或连续可微性的势函数。

    

    本文研究了Langevin型算法应用于吉布斯分布的情况，其中势函数是耗散的，且其弱梯度具有有限的连续性模量。我们的主要结果是2-Wasserstein距离上限的非渐进性，它衡量了吉布斯分布与基于Liptser-Shiryaev理论和函数不等式的Langevin型算法的一般分布之间的距离。我们应用这个上限来展示势函数的耗散性以及梯度 $\alpha>1/3$ 下的 $\alpha$-H\"{o}lder连续性是充分的，可以通过适当控制参数来获得Langevin Monte Carlo算法的收敛性。我们还针对无凸性或连续可微性的势函数提出了球形平滑技术的Langevin型算法。

    We study the Langevin-type algorithms for Gibbs distributions such that the potentials are dissipative and their weak gradients have the finite moduli of continuity. Our main result is a non-asymptotic upper bound of the 2-Wasserstein distance between the Gibbs distribution and the law of general Langevin-type algorithms based on the Liptser--Shiryaev theory and functional inequalities. We apply this bound to show that the dissipativity of the potential and the $\alpha$-H\"{o}lder continuity of the gradient with $\alpha>1/3$ are sufficient for the convergence of the Langevin Monte Carlo algorithm with appropriate control of the parameters. We also propose Langevin-type algorithms with spherical smoothing for potentials without convexity or continuous differentiability.
    
[^17]: 面向多样性预测的生成因果表示学习

    Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting. (arXiv:2302.08635v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08635](http://arxiv.org/abs/2302.08635)

    该论文提出了一种生成因果表示学习方法，通过利用因果关系来实现分布转移下的知识迁移，主要应用于面向多样性预测的问题。

    

    传统的有监督学习方法通常假定样本是独立同分布的，但对于超出分布的数据很敏感。我们提出了利用因果关系实现分布转移下的知识迁移的生成因果表示学习方法。我们评估了该方法在人体轨迹预测模型中的有效性，并且该方法也可以应用于其他领域。

    Conventional supervised learning methods typically assume i.i.d samples and are found to be sensitive to out-of-distribution (OOD) data. We propose Generative Causal Representation Learning (GCRL) which leverages causality to facilitate knowledge transfer under distribution shifts. While we evaluate the effectiveness of our proposed method in human trajectory prediction models, GCRL can be applied to other domains as well. First, we propose a novel causal model that explains the generative factors in motion forecasting datasets using features that are common across all environments and with features that are specific to each environment. Selection variables are used to determine which parts of the model can be directly transferred to a new environment without fine-tuning. Second, we propose an end-to-end variational learning paradigm to learn the causal mechanisms that generate observations from features. GCRL is supported by strong theoretical results that imply identifiability of the
    
[^18]: 一对其余损失函数在对抗训练中聚焦重要样本的作用

    One-vs-the-Rest Loss to Focus on Important Samples in Adversarial Training. (arXiv:2207.10283v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.10283](http://arxiv.org/abs/2207.10283)

    本文提出了一种名为SOVR的对抗训练损失函数，可以聚焦重要样本，增加对抗攻击下的对数几率间隔，从而在实验中表现出对抗攻击的有效性。

    

    本文提出了一种新的对抗训练损失函数。由于对抗训练存在困难，如需要高模型容量，通过加权交叉熵损失关注重要数据点已引起广泛关注。然而，它们容易受到复杂攻击的影响，如Auto-Attack。本文实验表明，它们的易受攻击的原因是真实标签和其他标签之间的对数几率之间的较小间隔。由于神经网络是根据对数几率对数据点进行分类的，所以对数几率的间隔应该足够大，以避免攻击翻转最大的对数几率。重要性感知方法不会增加重要样本的对数几率间隔，但与交叉熵损失相比会减少较不重要样本的对数几率间隔。为了增加重要样本的对数几率间隔，我们提出了一种切换一对其余（SOVR）损失函数，该损失函数在具有较小对数几率间隔的重要样本中从交叉熵切换到一对其余损失。我们提供理论分析、消融研究和实验，证明SOVR对抗抗击和其他最先进的攻击方法的有效性。

    This paper proposes a new loss function for adversarial training. Since adversarial training has difficulties, e.g., necessity of high model capacity, focusing on important data points by weighting cross-entropy loss has attracted much attention. However, they are vulnerable to sophisticated attacks, e.g., Auto-Attack. This paper experimentally reveals that the cause of their vulnerability is their small margins between logits for the true label and the other labels. Since neural networks classify the data points based on the logits, logit margins should be large enough to avoid flipping the largest logit by the attacks. Importance-aware methods do not increase logit margins of important samples but decrease those of less-important samples compared with cross-entropy loss. To increase logit margins of important samples, we propose switching one-vs-the-rest loss (SOVR), which switches from cross-entropy to one-vs-the-rest loss for important samples that have small logit margins. We prov
    
[^19]: 计数时间序列的概率调和

    Probabilistic Reconciliation of Count Time Series. (arXiv:2207.09322v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2207.09322](http://arxiv.org/abs/2207.09322)

    本文提出了一种新的概率计数时间序列调和方法，产生协调的概率质量函数，相比于概率高斯调和，能够带来显著的预测改进。

    

    预测调和是一个重要的研究课题，但目前既没有形式化的框架，也没有针对概率计数时间序列调和的实用方法。在本文中，我们提出了一种适用于实值和计数变量的连贯性和协调的概率预测定义，同时提出了一种新的概率协调方法。它是基于贝叶斯规则的概括，并且可以协调实数和计数变量。当用于计数变量时，它会产生协调的概率质量函数。我们通过对计数变量的时间协调实验表明，与概率高斯调和相比，它对预测的改进非常大。

    Forecast reconciliation is an important research topic. Yet, there is currently neither formal framework nor practical method for the probabilistic reconciliation of count time series. In this paper we propose a definition of coherency and reconciled probabilistic forecast which applies to both real-valued and count variables and a novel method for probabilistic reconciliation. It is based on a generalization of Bayes' rule and it can reconcile both real-value and count variables. When applied to count variables, it yields a reconciled probability mass function. Our experiments with the temporal reconciliation of count variables show a major forecast improvement compared to the probabilistic Gaussian reconciliation.
    
[^20]: 基于星形细胞对关键期的神经可塑性神经网络，通过现有和记忆性的大脑可塑性和突触形成实现突触竞争和强度平衡。（arXiv: 2203.11740v12 [cs.NE] UPDATED）

    Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2203.11740](http://arxiv.org/abs/2203.11740)

    该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。

    

    除了突触共享连接权重之外，PNN还包括突触有效范围的权重[14-25]。PNN考虑突触强度平衡在突触吞噬的动态和长度常数之和的静态中[14]，并包含了鱼群行为的先导行为。突触形成在实验和模拟中会抑制树突生成[15]。类似于Spring Boot中的强制韧性，反向回路的记忆持久度梯度也存在。相对较好和较差的梯度信息存储在类似于脑褶的记忆痕迹细胞中，在反向回路的突触形成中。争议认为人类海马神经元的再生能力是否持续到老年，并可能在后期迭代中形成新的更长的回路[17,18]。关闭关键期会导致神经紊乱在实验和模拟中[19]。考虑到负面和正面记忆的持久性，有助于更好地激活突触。

    In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
    
[^21]: 多元时间序列分类算法基准测试

    Benchmarking Multivariate Time Series Classification Algorithms. (arXiv:2007.13156v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2007.13156](http://arxiv.org/abs/2007.13156)

    该论文比较了单变量时间序列分类（TSC）与多元TSC(MTSC)问题的算法。作者测试了基于深度学习、形状和单词袋方法的算法，并将其与维度无关的方法进行比较。

    

    时间序列分类（TSC）涉及从有序的实值属性中构建用于离散目标变量的预测模型。最近几年，一组新的TSC算法已经开发出来，这些算法在之前的技术水平上取得了重大进展。主要关注的是单变量TSC，即每个案例都有一个单一序列和一个类标签的问题。但实际上，更常见的是遇到多元TSC(MTSC)问题，其中多个序列与单一标签关联。然而，对于MTSC的考虑远不如单变量情况那么多。2018年推出了30个MTSC问题的UEA存档库，使算法之间的比较更容易。我们回顾了基于深度学习、形状和单词袋方法提出的定制MTSC算法。 MTSC的最简单方法是通过多元维度上的集成单变量分类器。我们将这些定制算法与这些维度无关方法进行比较。

    Time Series Classification (TSC) involved building predictive models for a discrete target variable from ordered, real valued, attributes. Over recent years, a new set of TSC algorithms have been developed which have made significant improvement over the previous state of the art. The main focus has been on univariate TSC, i.e. the problem where each case has a single series and a class label. In reality, it is more common to encounter multivariate TSC (MTSC) problems where multiple series are associated with a single label. Despite this, much less consideration has been given to MTSC than the univariate case. The UEA archive of 30 MTSC problems released in 2018 has made comparison of algorithms easier. We review recently proposed bespoke MTSC algorithms based on deep learning, shapelets and bag of words approaches. The simplest approach to MTSC is to ensemble univariate classifiers over the multivariate dimensions. We compare the bespoke algorithms to these dimension independent appro
    
[^22]: 两个工具箱的故事——第三次报告：关于HIVE-COTE v1.0的使用和性能

    A tale of two toolkits, report the third: on the usage and performance of HIVE-COTE v1.0. (arXiv:2004.06069v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2004.06069](http://arxiv.org/abs/2004.06069)

    介绍了用于时间序列分类的异构元集成算法 HIVE-COTE 的最新稳定版本 1.0，提供了使用指南，并通过实验评估了其性能和资源使用情况，并与三种近期提出的算法进行了比较。

    

    层次化转换集合法（HIVE-COTE）是一种用于时间序列分类的异构元集成算法。该算法最初于2016年提出，经历了一些小的改变，并在两个开源代码库中推出了可配置、可扩展和易于使用的版本。本文介绍了最新稳定的 HIVE-COTE 版本 1.0 的概述，并阐述了它与最初版本的区别。我们提供了一个使用该分类器的指南，并对其预测性能和资源使用情况进行了广泛的实验评估。我们使用 aeon 工具包比较了 HIVE-COTE 与三种近期提出的算法的性能。

    The Hierarchical Vote Collective of Transformation-based Ensembles (HIVE-COTE) is a heterogeneous meta ensemble for time series classification. Since it was first proposed in 2016, the algorithm has undergone some minor changes and there is now a configurable, scalable and easy to use version available in two open source repositories. We present an overview of the latest stable HIVE-COTE, version 1.0, and describe how it differs to the original. We provide a walkthrough guide of how to use the classifier, and conduct extensive experimental evaluation of its predictive performance and resource usage. We compare the performance of HIVE-COTE to three recently proposed algorithms using the aeon toolkit.
    

