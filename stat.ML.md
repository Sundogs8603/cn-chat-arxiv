# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning Narrow One-Hidden-Layer ReLU Networks.](http://arxiv.org/abs/2304.10524) | 本文提出了一个在多项式时间内成功的学习Narrow One-Hidden-Layer ReLU网络的算法，而不需要额外的假设，并使用了分析高阶矩张量的随机收缩的方法，使得可以发现单个神经元。 |
| [^2] | [Projective Proximal Gradient Descent for A Class of Nonconvex Nonsmooth Optimization Problems: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property.](http://arxiv.org/abs/2304.10499) | 本文提出了一个投影近端梯度下降算法(PPGD)，成功地解决了一类非凸非光滑优化问题。该算法可以实现局部快速收敛，当迭代次数 $k \geq k_0$ 时，PPGD 可以以 $\cO(1/k^2)$ 的快速收敛率收敛。 |
| [^3] | [Efficient Deep Reinforcement Learning Requires Regulating Overfitting.](http://arxiv.org/abs/2304.10466) | 深度强化学习的主要瓶颈在于高时间差误差的验证集上出现了严重过拟合问题。 |
| [^4] | [Optimal Activation of Halting Multi-Armed Bandit Models.](http://arxiv.org/abs/2304.10302) | 本文研究了新型的动态分配问题——停止赌博机模型，提出了对于经典的Gittins指数分解结果和最新结果的新证明。 |
| [^5] | [Is augmentation effective to improve prediction in imbalanced text datasets?.](http://arxiv.org/abs/2304.10283) | 本文研究发现，通过调整分类器截断点而不进行数据增强可以在不平衡数据集上得到类似于过采样技术的结果，为处理不平衡数据提供了一种新的思路。 |
| [^6] | [PED-ANOVA: Efficiently Quantifying Hyperparameter Importance in Arbitrary Subspaces.](http://arxiv.org/abs/2304.10255) | PED-ANOVA 提出了一个新的 f-ANOVA 公式，能够在任意子空间中高效地计算超参数的重要性，有助于深度学习中好的超参数空间设计。 |
| [^7] | [Hotelling Deflation on Large Symmetric Spiked Tensors.](http://arxiv.org/abs/2304.10248) | 本文研究了缩减算法在大规模对称尖峰张量上的应用，提供了在存在非平凡相关性情况下的精确表现，可用于设计更有效的信号估计方法。 |
| [^8] | [Linear Convergence of Reshuffling Kaczmarz Methods With Sparse Constraints.](http://arxiv.org/abs/2304.10123) | 本文提出了一种基于Kaczmarz的IHT（KZIHT）的混合方法，并在使用重洗数据采样方案时证明其线性收敛性，具有稀疏约束的系统的解。同时，还提出了Kaczmarz周期阈值（KZPT）方法推广了KZIHT的应用。 |
| [^9] | [Understanding Accelerated Gradient Methods: Lyapunov Analyses and Hamiltonian Assisted Interpretations.](http://arxiv.org/abs/2304.10063) | 本文提出了两类更广泛的一阶算法，通过新的离散李亚普诺夫分析建立足够条件，实现了与Nesterov方法类似的加速收敛速度。此外，还提出了哈密顿助理梯度方法来解释加速条件的意义。 |
| [^10] | [Optimality of Robust Online Learning.](http://arxiv.org/abs/2304.10060) | 本文提出了一种基于鲁棒损失函数 $\mathcal{L}_{\sigma}$ 的在线学习算法，可用作在线最小二乘回归的鲁棒替代方案。并证明了在适当选择参数的情况下，该算法具有无容量依赖的最优性收敛性以及强收敛的最优容量依赖速率。 |
| [^11] | [Optimal Kernel for Kernel-Based Modal Statistical Methods.](http://arxiv.org/abs/2304.10046) | 本文研究基于核函数的模态统计方法的最优核函数的选择问题，提出了一种（多元）最优核函数，在某个核函数类别中使得其解析得到的渐近误差准则最小化。 |
| [^12] | [Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance.](http://arxiv.org/abs/2304.10025) | 本文针对治疗不服从性提出了一种半参数框架来评估因果中介效应，提出了一组假设来识别自然中介效应并推导出成倍稳健估计器。 |
| [^13] | [Online Ensemble of Models for Optimal Predictive Performance with Applications to Sector Rotation Strategy.](http://arxiv.org/abs/2304.09947) | 通过机器学习模型和资产特定因素在预测行业回报和测量行业特定风险溢价方面获得更大经济收益，开发了一种新型在线集成算法来学习优化预测性能，特别适用于时间序列问题和可能的黑盒模型系统。 |
| [^14] | [Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?.](http://arxiv.org/abs/2304.09868) | 本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。 |
| [^15] | [A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions.](http://arxiv.org/abs/2304.06787) | 本论文提出了第一个多项式时间、纯差分隐私估计器，可以在$\{0,1\}^d$上准确估计二元积分布的均值，达到了最优的样本复杂度。 |
| [^16] | [Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery.](http://arxiv.org/abs/2304.05294) | 本文提出了一种多数据因果特征选择方法，它可以同时处理一组时间序列数据集，生成一个单一的因果驱动集，并且可以过滤掉因果虚假链接，最终输入到机器学习模型中预测目标。 |
| [^17] | [A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models.](http://arxiv.org/abs/2304.04916) | 本文提出了一种基于数据驱动的状态聚合方法来降低动态离散选择模型的估计计算和样本复杂度，首先利用反向强化学习估计代理Q函数，然后用聚类算法选择重要的状态聚合，最终利用嵌套固定点算法进行最大似然估计。 |
| [^18] | [Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases.](http://arxiv.org/abs/2303.15739) | 本研究针对深度ReLU神经网络，证明了过参数化情况下的Bayesian自由能是有界的，说明Bayesian广义误差不会增加。 |
| [^19] | [Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification.](http://arxiv.org/abs/2301.07609) | 该论文扩展了信息场理论(IFT)到物理信息场理论(PIFT)，将描述场的物理定律的信息编码为函数先验。从这个PIFT得出的后验与任何数值方案无关，并且可以捕捉多种模式。 |
| [^20] | [Reconstructing Kernel-based Machine Learning Force Fields with Super-linear Convergence.](http://arxiv.org/abs/2212.12737) | 本文提出了一种基于Nyström型方法的预处理器构建框架，实现了在低数据范围内高效重构核机器力场，并在带有数万个培训点的化学系统中获得了稳定和准确的结果。 |
| [^21] | [PowRL: A Reinforcement Learning Framework for Robust Management of Power Networks.](http://arxiv.org/abs/2212.02397) | 本论文提出了PowRL框架来通过强化学习来有效应对电力网络中的不确定情况，并保持电网的可靠运行。 |
| [^22] | [Model free variable importance for high dimensional data.](http://arxiv.org/abs/2211.08414) | 该论文提出了一种无模型的变量重要性方法，可以与任意预测函数一起使用，不需要访问预测函数，可用于研究模型残差。引入了Cohort Shapley的积分梯度版本（IGCS），使得在二元预测器情况下也可以使用IG方法。 |
| [^23] | [A Deep Learning Approach to Analyzing Continuous-Time Systems.](http://arxiv.org/abs/2209.12128) | 深度学习方法能够分析复杂自然过程的时间序列数据，放松了传统简化假设的限制，具备可解释性和灵活的函数逼近能力，能够应用于人类语言处理领域，改进数据解释力和探索性分析能力。 |
| [^24] | [Unsupervised representation learning with recognition-parametrised probabilistic models.](http://arxiv.org/abs/2209.05661) | 本文提出了一种基于识别参数模型的概率无监督学习新方法，可以灵活地学习识别模型，捕捉观测之间的潜在相关性，为图像分类和潜在分配问题提供了有效解决方案。 |
| [^25] | [On the Convergence of the ELBO to Entropy Sums.](http://arxiv.org/abs/2209.03077) | 本论文研究了 ELBO 收敛到熵和的问题，证明了对于一类广泛的生成模型，ELBO 在所有学习的稳定点处都等于一系列熵的和，为无监督学习的学习算法的基本属性提供了深入的洞察。 |
| [^26] | [Continuous Generative Neural Networks.](http://arxiv.org/abs/2205.14627) | 本文介绍了一种连续生成神经网络(CGNN)的模型，使用条件保证CGNN是单射的，其生成流形被用于求解反问题，并证明了其方法的有效性和稳健性。 |
| [^27] | [HOUDINI: Escaping from Moderately Constrained Saddles.](http://arxiv.org/abs/2205.13753) | 本文给出了第一个多项式时间算法，能在适度数量的约束下使梯度下降方法逃脱高维马鞍点。 |
| [^28] | [Communication-Efficient Adaptive Federated Learning.](http://arxiv.org/abs/2205.02719) | 本文提出了一种新的通信效率高的自适应联邦学习方法（FedCAMS），可以解决联邦学习中由于重复的服务器-客户端同步而产生的大量通信开销和基于 SGD 的模型更新缺乏适应性等诸多问题。 |
| [^29] | [A Manifold Two-Sample Test Study: Integral Probability Metric with Neural Networks.](http://arxiv.org/abs/2205.02043) | 文章提出了一种基于积分概率度量的两样本检验方法，适用于低维流形上支持的高维样本。实验结果表明，所提出的方法在统计功率方面优于最先进的方法。 |
| [^30] | [Kernel Robust Hypothesis Testing.](http://arxiv.org/abs/2203.12777) | 本文使用核方法构造不确定性集，在贝叶斯设置和Neyman-Pearson设置中分别研究了最小化最坏情况下错误概率和控制错误概率的问题，并提出了基于MMD的一系列测试。 |
| [^31] | [Byzantine-Robust Decentralized Learning via ClippedGossip.](http://arxiv.org/abs/2202.01545) | 本文提出的剪切Gossip算法是第一个能够在标准假设下证明收敛到非凸目标的$O(\delta_{max} \zeta^2 /\gamma^2)$邻域的算法，并在大量攻击下表现良好。 |
| [^32] | [Boundary Graph Neural Networks for 3D Simulations.](http://arxiv.org/abs/2106.11299) | 本文提出了一种新型边界图神经网络（BGNNs），能够有效地表示三维颗粒流动的复杂几何形状，从而实现了高效的预测和计算。 |
| [^33] | [Can a single neuron learn predictive uncertainty?.](http://arxiv.org/abs/2106.03702) | 本文介绍了一种基于单个神经元的新型非参数分位数估计方法，该方法在小样本大小和真实世界实验中的优越表现表明其可以消除与模型规范相关的自由度，并提供更好的预测不确定性估计。 |
| [^34] | [The ELBO of Variational Autoencoders Converges to a Sum of Three Entropies.](http://arxiv.org/abs/2010.14860) | 标准变分自编码器的ELBO在稳定点处可以以闭合形式计算，收敛于三个熵之和。（其中一个熵为先验分布的熵，一个为可观测分布的熵，一个为变分分布的平均熵，成果证明了ELBO在稳定点处等于熵。） |
| [^35] | [Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent.](http://arxiv.org/abs/2009.04709) | 本文提出了一种新的定义来描述对抗训练中梯度的优选方向，利用生成对抗网络的指标来评估对齐情况，并表明在对齐方向上的限制可以进一步提高模型的鲁棒性。 |
| [^36] | [FRMDN: Flow-based Recurrent Mixture Density Network.](http://arxiv.org/abs/2008.02144) | 本文提出了一种基于流的循环混合密度网络，通过在每个时间步上定义一个高斯混合模型，将循环混合密度网络推广到非线性变换的目标序列上，该模型在图像序列的拟合度上表现显著，具有显著的建模能力，在对数似然度量方面优于其他最先进的方法。 |

# 详细

[^1]: 学习窄的单隐藏层ReLU网络

    Learning Narrow One-Hidden-Layer ReLU Networks. (arXiv:2304.10524v1 [cs.LG])

    [http://arxiv.org/abs/2304.10524](http://arxiv.org/abs/2304.10524)

    本文提出了一个在多项式时间内成功的学习Narrow One-Hidden-Layer ReLU网络的算法，而不需要额外的假设，并使用了分析高阶矩张量的随机收缩的方法，使得可以发现单个神经元。

    

    本文考虑了一个经过充分研究的问题——关于在$d$维输入上的高斯分布中，学习$k$个ReLU激活的线性组合。我们提出了第一个在$k$为常数时成功的多项式时间算法。所有之前多项式时间的学习器都需要对网络进行额外的假设，比如正系数系合或隐藏权重向量的矩阵良好定义。我们的方法基于分析高阶矩张量的随机收缩。我们采用多尺度分析来证明足够接近的神经元可以被合并在一起，从而规避了以前工作中存在的定性问题。这使我们能够设计一个迭代过程来发现单个神经元。

    We consider the well-studied problem of learning a linear combination of $k$ ReLU activations with respect to a Gaussian distribution on inputs in $d$ dimensions. We give the first polynomial-time algorithm that succeeds whenever $k$ is a constant. All prior polynomial-time learners require additional assumptions on the network, such as positive combining coefficients or the matrix of hidden weight vectors being well-conditioned.  Our approach is based on analyzing random contractions of higher-order moment tensors. We use a multi-scale analysis to argue that sufficiently close neurons can be collapsed together, sidestepping the conditioning issues present in prior work. This allows us to design an iterative procedure to discover individual neurons.
    
[^2]: 一类非凸非光滑优化问题的投影近端梯度下降算法：不需要 Kurdyka-Lojasiewicz（KL）性质也能实现快速收敛

    Projective Proximal Gradient Descent for A Class of Nonconvex Nonsmooth Optimization Problems: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property. (arXiv:2304.10499v1 [math.OC])

    [http://arxiv.org/abs/2304.10499](http://arxiv.org/abs/2304.10499)

    本文提出了一个投影近端梯度下降算法(PPGD)，成功地解决了一类非凸非光滑优化问题。该算法可以实现局部快速收敛，当迭代次数 $k \geq k_0$ 时，PPGD 可以以 $\cO(1/k^2)$ 的快速收敛率收敛。

    

    非凸非光滑优化问题在统计学和机器学习中具有重要意义且具有挑战性。在本文中，我们提出了解决一类非凸非光滑优化问题的投影近端梯度下降算法(PPGD)，其中非凸性和非光滑性源自一个非凸但分段凸的非光滑正则化项。与现有基于 Kurdyka-\L{}ojasiewicz (K\L{}) 性质对非凸非光滑问题进行加速 PGD 方法的收敛分析不同，我们提供了一种新的理论分析，证明了 PPGD 在温和假设下在一类非凸非光滑问题中实现了快速局部收敛。证明了当迭代次数 $k \geq k_0$ 时，PPGD 可以以 $\cO(1/k^2)$ 的快速收敛率收敛，其中 $k_0$ 是一个有限的常数。该算法在光滑且凸目标函数的一阶方法具有利普希茨连续梯度的情况下实现了局部 Nesterov 的最优收敛速度。实验结果表明......（此处省略）。

    Nonconvex and nonsmooth optimization problems are important and challenging for statistics and machine learning. In this paper, we propose Projected Proximal Gradient Descent (PPGD) which solves a class of nonconvex and nonsmooth optimization problems, where the nonconvexity and nonsmoothness come from a nonsmooth regularization term which is nonconvex but piecewise convex. In contrast with existing convergence analysis of accelerated PGD methods for nonconvex and nonsmooth problems based on the Kurdyka-\L{}ojasiewicz (K\L{}) property, we provide a new theoretical analysis showing local fast convergence of PPGD. It is proved that PPGD achieves a fast convergence rate of $\cO(1/k^2)$ when the iteration number $k \ge k_0$ for a finite $k_0$ on a class of nonconvex and nonsmooth problems under mild assumptions, which is locally Nesterov's optimal convergence rate of first-order methods on smooth and convex objective function with Lipschitz continuous gradient. Experimental results demonst
    
[^3]: 高效深度强化学习需要抑制过拟合

    Efficient Deep Reinforcement Learning Requires Regulating Overfitting. (arXiv:2304.10466v1 [cs.LG])

    [http://arxiv.org/abs/2304.10466](http://arxiv.org/abs/2304.10466)

    深度强化学习的主要瓶颈在于高时间差误差的验证集上出现了严重过拟合问题。

    

    通过与环境的交互收集有限的数据进行策略学习的深度强化学习算法，需要正确的正则化技巧才能实现数据高效利用。本文通过检验几种假设，如非稳态性、过度动作分布偏移和过拟合等，试图理解在样本高效的深度强化学习中主要的瓶颈。我们对DeepMind控制套件（DMC）任务进行了彻底的实证分析，以一种有控制、系统的方式展示了对转换的验证集的高时间差（TD）误差是严重影响深度强化学习算法性能的主要罪魁祸首，而先前的方法......(未完整翻译)

    Deep reinforcement learning algorithms that learn policies by trial-and-error must learn from limited amounts of data collected by actively interacting with the environment. While many prior works have shown that proper regularization techniques are crucial for enabling data-efficient RL, a general understanding of the bottlenecks in data-efficient RL has remained unclear. Consequently, it has been difficult to devise a universal technique that works well across all domains. In this paper, we attempt to understand the primary bottleneck in sample-efficient deep RL by examining several potential hypotheses such as non-stationarity, excessive action distribution shift, and overfitting. We perform thorough empirical analysis on state-based DeepMind control suite (DMC) tasks in a controlled and systematic way to show that high temporal-difference (TD) error on the validation set of transitions is the main culprit that severely affects the performance of deep RL algorithms, and prior method
    
[^4]: 停止多臂赌博机模型的最优激活。

    Optimal Activation of Halting Multi-Armed Bandit Models. (arXiv:2304.10302v1 [stat.ML])

    [http://arxiv.org/abs/2304.10302](http://arxiv.org/abs/2304.10302)

    本文研究了新型的动态分配问题——停止赌博机模型，提出了对于经典的Gittins指数分解结果和最新结果的新证明。

    

    本文研究了一种新型的动态分配问题——停止赌博机模型。作为应用，我们获得了对于经典的Gittins指数分解结果和作者在“普遍折旧和承诺下的多臂赌博机”的最新结果的新证明。

    We study new types of dynamic allocation problems the {\sl Halting Bandit} models. As an application, we obtain new proofs for the classic Gittins index decomposition result and recent results of the authors in `Multi-armed bandits under general depreciation and commitment.'
    
[^5]: 数据增强对不平衡文本数据集预测的有效性研究

    Is augmentation effective to improve prediction in imbalanced text datasets?. (arXiv:2304.10283v1 [cs.CL])

    [http://arxiv.org/abs/2304.10283](http://arxiv.org/abs/2304.10283)

    本文研究发现，通过调整分类器截断点而不进行数据增强可以在不平衡数据集上得到类似于过采样技术的结果，为处理不平衡数据提供了一种新的思路。

    

    不平衡数据集对机器学习模型构成了重大挑战，往往导致预测有偏。为了解决这个问题，自然语言处理（NLP）中广泛使用数据增强技术为少数类生成新样本。然而，在本文中，我们质疑了数据增强总是必要来提高不平衡数据集预测的常见假设。相反，我们认为通过调整分类器截断点而不进行数据增强可以产生与过采样技术类似的结果。我们的研究提供了理论和实证证据支持这一主张。我们的发现有助于更好地了解处理不平衡数据的不同方法的优势和局限性，并帮助研究人员和实践者为给定任务做出明智的决策。

    Imbalanced datasets present a significant challenge for machine learning models, often leading to biased predictions. To address this issue, data augmentation techniques are widely used in natural language processing (NLP) to generate new samples for the minority class. However, in this paper, we challenge the common assumption that data augmentation is always necessary to improve predictions on imbalanced datasets. Instead, we argue that adjusting the classifier cutoffs without data augmentation can produce similar results to oversampling techniques. Our study provides theoretical and empirical evidence to support this claim. Our findings contribute to a better understanding of the strengths and limitations of different approaches to dealing with imbalanced data, and help researchers and practitioners make informed decisions about which methods to use for a given task.
    
[^6]: PED-ANOVA: 在任意子空间中高效量化超参数重要性

    PED-ANOVA: Efficiently Quantifying Hyperparameter Importance in Arbitrary Subspaces. (arXiv:2304.10255v1 [cs.LG])

    [http://arxiv.org/abs/2304.10255](http://arxiv.org/abs/2304.10255)

    PED-ANOVA 提出了一个新的 f-ANOVA 公式，能够在任意子空间中高效地计算超参数的重要性，有助于深度学习中好的超参数空间设计。

    

    深度学习中超参数优化的流行使得好的超参数空间设计对于训练强模型至关重要，而好的超参数空间设计又严重依赖于了解不同超参数的作用。这激发了关于超参数重要性的研究，例如使用功能方差分析 (f-ANOVA) 的流行方法。然而，原始的 f-ANOVA 公式不适用于算法设计师最相关的子空间，例如由最佳性能定义的子空间。为了解决这个问题，我们推导了一个新的针对任意子空间的 f-ANOVA 公式，并提出了一个算法，使用 Pearson 散度 (PED) 实现超参数重要性的闭式计算。我们证明，这个新算法，称为 PED-ANOVA，能够成功地识别不同子空间中重要的超参数，同时计算效率极高。

    The recent rise in popularity of Hyperparameter Optimization (HPO) for deep learning has highlighted the role that good hyperparameter (HP) space design can play in training strong models. In turn, designing a good HP space is critically dependent on understanding the role of different HPs. This motivates research on HP Importance (HPI), e.g., with the popular method of functional ANOVA (f-ANOVA). However, the original f-ANOVA formulation is inapplicable to the subspaces most relevant to algorithm designers, such as those defined by top performance. To overcome this problem, we derive a novel formulation of f-ANOVA for arbitrary subspaces and propose an algorithm that uses Pearson divergence (PED) to enable a closed-form computation of HPI. We demonstrate that this new algorithm, dubbed PED-ANOVA, is able to successfully identify important HPs in different subspaces while also being extremely computationally efficient.
    
[^7]: 大规模对称尖峰张量上的Hotelling缩减算法

    Hotelling Deflation on Large Symmetric Spiked Tensors. (arXiv:2304.10248v1 [stat.ML])

    [http://arxiv.org/abs/2304.10248](http://arxiv.org/abs/2304.10248)

    本文研究了缩减算法在大规模对称尖峰张量上的应用，提供了在存在非平凡相关性情况下的精确表现，可用于设计更有效的信号估计方法。

    

    本文研究了当应用于估计受加性高斯噪声污染的大张量中包含的低秩对称尖峰时的缩减算法。具体而言，我们在假定尖峰分量存在非平凡（固定）相关性的情况下，提供了对缩减算法在大维情况下表现的精确刻画，其中包括通过连续的秩-1逼近获得的向量的对齐情况及其估计的权重。我们的分析可让人们理解噪声干扰下的缩减机制，并可用于设计更有效的信号估计方法。

    This paper studies the deflation algorithm when applied to estimate a low-rank symmetric spike contained in a large tensor corrupted by additive Gaussian noise. Specifically, we provide a precise characterization of the large-dimensional performance of deflation in terms of the alignments of the vectors obtained by successive rank-1 approximation and of their estimated weights, assuming non-trivial (fixed) correlations among spike components. Our analysis allows an understanding of the deflation mechanism in the presence of noise and can be exploited for designing more efficient signal estimation methods.
    
[^8]: 稀疏约束下重洗Kaczmarz方法的线性收敛

    Linear Convergence of Reshuffling Kaczmarz Methods With Sparse Constraints. (arXiv:2304.10123v1 [stat.ML])

    [http://arxiv.org/abs/2304.10123](http://arxiv.org/abs/2304.10123)

    本文提出了一种基于Kaczmarz的IHT（KZIHT）的混合方法，并在使用重洗数据采样方案时证明其线性收敛性，具有稀疏约束的系统的解。同时，还提出了Kaczmarz周期阈值（KZPT）方法推广了KZIHT的应用。

    

    Kaczmarz方法（KZ）及其变体是一类随机梯度下降（SGD）方法，由于其简单高效地解决线性方程组而被广泛研究。迭代阈值（IHT）方法在多个研究领域中广受欢迎，包括压缩感知或稀疏线性回归，带有额外结构的机器学习以及带有非凸约束的优化。最近，提出了一种名为基于Kaczmarz的IHT（KZIHT）的混合方法，结合了两种方法的优点，但它的理论保证缺失。本文通过展示当使用重洗数据采样方案时，KZIHT线性地收敛到具有稀疏约束的系统的解，并提供了KZIHT的第一个理论收敛保证。我们还提出了Kaczmarz周期阈值（KZPT）方法，它通过应用阈值操作来推广KZIHT。

    The Kaczmarz method (KZ) and its variants, which are types of stochastic gradient descent (SGD) methods, have been extensively studied due to their simplicity and efficiency in solving linear equation systems. The iterative thresholding (IHT) method has gained popularity in various research fields, including compressed sensing or sparse linear regression, machine learning with additional structure, and optimization with nonconvex constraints. Recently, a hybrid method called Kaczmarz-based IHT (KZIHT) has been proposed, combining the benefits of both approaches, but its theoretical guarantees are missing. In this paper, we provide the first theoretical convergence guarantees for KZIHT by showing that it converges linearly to the solution of a system with sparsity constraints up to optimal statistical bias when the reshuffling data sampling scheme is used. We also propose the Kaczmarz with periodic thresholding (KZPT) method, which generalizes KZIHT by applying the thresholding operatio
    
[^9]: 理解加速梯度方法：李亚普诺夫分析和哈密顿助理解释

    Understanding Accelerated Gradient Methods: Lyapunov Analyses and Hamiltonian Assisted Interpretations. (arXiv:2304.10063v1 [math.OC])

    [http://arxiv.org/abs/2304.10063](http://arxiv.org/abs/2304.10063)

    本文提出了两类更广泛的一阶算法，通过新的离散李亚普诺夫分析建立足够条件，实现了与Nesterov方法类似的加速收敛速度。此外，还提出了哈密顿助理梯度方法来解释加速条件的意义。

    

    我们提出了两类比之前研究的更加广泛的一阶算法，用于最小化平滑且强凸或平滑凸函数。我们通过新的离散李亚普诺夫分析建立足够条件，使其达到加速收敛速度，这与在强和一般的凸设置中与Nesterov的方法相匹配。接下来，我们研究了极限普通微分方程的收敛性，并指出了相应算法和微分方程的收敛性质之间目前明显的差距。最后，我们提出了一种新型的离散算法——哈密顿助理梯度方法——该方法直接基于一个哈密顿函数和多个可解释的操作，然后演示了我们加速条件的有意义和统一的解释。

    We formulate two classes of first-order algorithms more general than previously studied for minimizing smooth and strongly convex or, respectively, smooth and convex functions. We establish sufficient conditions, via new discrete Lyapunov analyses, for achieving accelerated convergence rates which match Nesterov's methods in the strongly and general convex settings. Next, we study the convergence of limiting ordinary differential equations (ODEs) and point out currently notable gaps between the convergence properties of the corresponding algorithms and ODEs. Finally, we propose a novel class of discrete algorithms, called the Hamiltonian assisted gradient method, directly based on a Hamiltonian function and several interpretable operations, and then demonstrate meaningful and unified interpretations of our acceleration conditions.
    
[^10]: 鲁棒性在线学习算法的最优性分析

    Optimality of Robust Online Learning. (arXiv:2304.10060v1 [stat.ML])

    [http://arxiv.org/abs/2304.10060](http://arxiv.org/abs/2304.10060)

    本文提出了一种基于鲁棒损失函数 $\mathcal{L}_{\sigma}$ 的在线学习算法，可用作在线最小二乘回归的鲁棒替代方案。并证明了在适当选择参数的情况下，该算法具有无容量依赖的最优性收敛性以及强收敛的最优容量依赖速率。

    

    本文研究在再生核希尔伯特空间上使用鲁棒损失函数 $\mathcal{L}_{\sigma}$ 进行回归的在线学习算法。这个涉及到缩放参数 $\sigma>0$ 的损失函数可以覆盖一系列常用的鲁棒损失函数。提出的算法是针对在线最小二乘回归的鲁棒替代方案，旨在估计条件均值函数。在选择适当的 $\sigma$ 和步长的情况下，我们证明了该在线算法的最终迭代可以在均方距离上实现无容量依赖的收敛最优性。此外，如果已知底层函数空间的其他信息，则我们还建立了强收敛的最优容量依赖速率。据我们所知，这两个结果都是在线学习现有文献中的新结果。

    In this paper, we study an online learning algorithm with a robust loss function $\mathcal{L}_{\sigma}$ for regression over a reproducing kernel Hilbert space (RKHS). The loss function $\mathcal{L}_{\sigma}$ involving a scaling parameter $\sigma>0$ can cover a wide range of commonly used robust losses. The proposed algorithm is then a robust alternative for online least squares regression aiming to estimate the conditional mean function. For properly chosen $\sigma$ and step size, we show that the last iterate of this online algorithm can achieve optimal capacity independent convergence in the mean square distance. Moreover, if additional information on the underlying function space is known, we also establish optimal capacity dependent rates for strong convergence in RKHS. To the best of our knowledge, both of the two results are new to the existing literature of online learning.
    
[^11]: 基于核的模态统计方法的最优核函数

    Optimal Kernel for Kernel-Based Modal Statistical Methods. (arXiv:2304.10046v1 [stat.ML])

    [http://arxiv.org/abs/2304.10046](http://arxiv.org/abs/2304.10046)

    本文研究基于核函数的模态统计方法的最优核函数的选择问题，提出了一种（多元）最优核函数，在某个核函数类别中使得其解析得到的渐近误差准则最小化。

    

    基于核函数的模态统计方法包括模态估计、回归和聚类。这些方法的估计准确性取决于所使用的核函数和带宽。本文研究了核函数选择对这些方法估计准确性的影响。特别地，当使用最优带宽时，本文理论上展示了一种（多元）最优核函数，其在定义为其符号变化数量的某个核函数类别中，使得其解析得到的渐近误差准则最小化。

    Kernel-based modal statistical methods include mode estimation, regression, and clustering. Estimation accuracy of these methods depends on the kernel used as well as the bandwidth. We study effect of the selection of the kernel function to the estimation accuracy of these methods. In particular, we theoretically show a (multivariate) optimal kernel that minimizes its analytically-obtained asymptotic error criterion when using an optimal bandwidth, among a certain kernel class defined via the number of its sign changes.
    
[^12]: 用于因果中介分析中具有治疗不服从性的识别和倍增稳健估计

    Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance. (arXiv:2304.10025v1 [stat.ME])

    [http://arxiv.org/abs/2304.10025](http://arxiv.org/abs/2304.10025)

    本文针对治疗不服从性提出了一种半参数框架来评估因果中介效应，提出了一组假设来识别自然中介效应并推导出成倍稳健估计器。

    

    在实验和观察研究中，人们通常对了解干预方案如何改善最终结果的潜在机制感兴趣。因果中介分析旨在达到此目的，但主要限于治疗完全服从的情况，只有少数情况需要排除限制。在本文中，我们建立了一个半参数框架，用于在无需排除限制的情况下评估具有治疗不服从性的因果中介效应。我们提出了一组假设来识别整个研究人群的自然中介效应，并进一步针对由潜在服从行为特征化的亚人群中的主要自然中介效应进行识别。我们推导出了主要自然中介效应估计量的有效影响函数，这激励了一组倍增稳健估计器进行推论。这些被识别估计量的半参数效率理论。

    In experimental and observational studies, there is often interest in understanding the potential mechanism by which an intervention program improves the final outcome. Causal mediation analyses have been developed for this purpose but are primarily restricted to the case of perfect treatment compliance, with a few exceptions that require exclusion restriction. In this article, we establish a semiparametric framework for assessing causal mediation in the presence of treatment noncompliance without exclusion restriction. We propose a set of assumptions to identify the natural mediation effects for the entire study population and further, for the principal natural mediation effects within subpopulations characterized by the potential compliance behaviour. We derive the efficient influence functions for the principal natural mediation effect estimands, which motivate a set of multiply robust estimators for inference. The semiparametric efficiency theory for the identified estimands is der
    
[^13]: 在线模型集成对最优预测性能的应用和行业轮换策略

    Online Ensemble of Models for Optimal Predictive Performance with Applications to Sector Rotation Strategy. (arXiv:2304.09947v1 [q-fin.ST])

    [http://arxiv.org/abs/2304.09947](http://arxiv.org/abs/2304.09947)

    通过机器学习模型和资产特定因素在预测行业回报和测量行业特定风险溢价方面获得更大经济收益，开发了一种新型在线集成算法来学习优化预测性能，特别适用于时间序列问题和可能的黑盒模型系统。

    

    资产特定因素通常用于预测金融回报并量化资产特定风险溢价。我们使用各种机器学习模型证明，这些因素包含的信息可以在预测行业回报和测量行业特定风险溢价方面带来更大的经济收益。为了利用不同行业表现的单个模型的强预测结果，我们开发了一种新型在线集成算法，该算法学习优化预测性能。该算法随着时间的推移不断适应，通过分析它们最近的预测性能来确定个体模型的最佳组合。这使它特别适用于时间序列问题，滚动窗口回测程序和可能的黑盒模型系统。我们推导出最优增益函数，用样本外R平方度量表达相应的遗憾界，并推导出最优解。

    Asset-specific factors are commonly used to forecast financial returns and quantify asset-specific risk premia. Using various machine learning models, we demonstrate that the information contained in these factors leads to even larger economic gains in terms of forecasts of sector returns and the measurement of sector-specific risk premia. To capitalize on the strong predictive results of individual models for the performance of different sectors, we develop a novel online ensemble algorithm that learns to optimize predictive performance. The algorithm continuously adapts over time to determine the optimal combination of individual models by solely analyzing their most recent prediction performance. This makes it particularly suited for time series problems, rolling window backtesting procedures, and systems of potentially black-box models. We derive the optimal gain function, express the corresponding regret bounds in terms of the out-of-sample R-squared measure, and derive optimal le
    
[^14]: 通过保留谱的数据压缩加速支持向量聚类

    Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])

    [http://arxiv.org/abs/2304.09868](http://arxiv.org/abs/2304.09868)

    本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。

    

    支持向量聚类是一种重要的聚类方法，但是由于其计算昂贵的簇分配步骤，它面临着可伸缩性问题。在本文中，我们通过保留谱的数据压缩来加速支持向量聚类。具体而言，我们将原始数据集压缩成少量谱表示的聚合数据点，然后在压缩后的数据集上执行标准的支持向量聚类，最后将压缩数据集的聚类结果映射回原始数据集以发现簇。我们在真实数据集上的大量实验结果表明，相较于标准支持向量聚类，我们的方法大大提高了速度，而不会损失聚类质量。

    Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
    
[^15]: 二元积分布的多项式时间和纯差分隐私估计器

    A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v1 [cs.DS])

    [http://arxiv.org/abs/2304.06787](http://arxiv.org/abs/2304.06787)

    本论文提出了第一个多项式时间、纯差分隐私估计器，可以在$\{0,1\}^d$上准确估计二元积分布的均值，达到了最优的样本复杂度。

    

    我们提出了第一个ε-差分隐私、计算有效的算法，可以在总变化距离下准确地估计$\{0,1\}^d$上的乘积分布的均值，同时在多项式对数因子内获得了最优的样本复杂度。之前的工作要么在更弱的隐私概念下有效地解决了这个问题，要么在指数级运行时间内最优地解决了这个问题。

    We present the first $\varepsilon$-differentially private, computationally efficient algorithm that estimates the means of product distributions over $\{0,1\}^d$ accurately in total-variation distance, whilst attaining the optimal sample complexity to within polylogarithmic factors. The prior work had either solved this problem efficiently and optimally under weaker notions of privacy, or had solved it optimally while having exponential running times.
    
[^16]: 使用多数据因果推断选择机器学习应用的强健特征

    Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery. (arXiv:2304.05294v1 [stat.ML])

    [http://arxiv.org/abs/2304.05294](http://arxiv.org/abs/2304.05294)

    本文提出了一种多数据因果特征选择方法，它可以同时处理一组时间序列数据集，生成一个单一的因果驱动集，并且可以过滤掉因果虚假链接，最终输入到机器学习模型中预测目标。

    

    强健的特征选择对于创建可靠和可解释的机器学习（ML）模型至关重要。在领域知识有限、潜在交互未知的情况下设计统计预测模型时，选择最优特征集通常很困难。为了解决这个问题，我们引入了一种多数据（M）因果特征选择方法，它同时处理一组时间序列数据集，并生成一个单一的因果驱动集。该方法使用Tigramite Python包中实现的因果发现算法PC1或PCMCI。这些算法利用条件独立性测试推断因果图的部分。我们的因果特征选择方法在将剩余因果特征作为输入传递给ML模型（多元线性回归，随机森林）预测目标之前，过滤掉因果虚假链接。我们将该框架应用于预测西太平洋热带地区的地震强度。

    Robust feature selection is vital for creating reliable and interpretable Machine Learning (ML) models. When designing statistical prediction models in cases where domain knowledge is limited and underlying interactions are unknown, choosing the optimal set of features is often difficult. To mitigate this issue, we introduce a Multidata (M) causal feature selection approach that simultaneously processes an ensemble of time series datasets and produces a single set of causal drivers. This approach uses the causal discovery algorithms PC1 or PCMCI that are implemented in the Tigramite Python package. These algorithms utilize conditional independence tests to infer parts of the causal graph. Our causal feature selection approach filters out causally-spurious links before passing the remaining causal features as inputs to ML models (Multiple linear regression, Random Forest) that predict the targets. We apply our framework to the statistical intensity prediction of Western Pacific Tropical
    
[^17]: 一种基于数据驱动的状态聚合方法用于动态离散选择模型

    A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models. (arXiv:2304.04916v1 [cs.LG])

    [http://arxiv.org/abs/2304.04916](http://arxiv.org/abs/2304.04916)

    本文提出了一种基于数据驱动的状态聚合方法来降低动态离散选择模型的估计计算和样本复杂度，首先利用反向强化学习估计代理Q函数，然后用聚类算法选择重要的状态聚合，最终利用嵌套固定点算法进行最大似然估计。

    

    我们研究了动态离散选择模型，其中一个常见的问题是使用代理行为数据估计代理奖励函数（也称为“结构参数”）的参数。这种模型的最大似然估计需要动态规划，这受到维度灾难的限制。在本文中，我们提出了一种新颖的算法，提供了一种数据驱动的方法来选择和聚合状态，降低了估计的计算和样本复杂度。我们的方法分两个阶段。在第一阶段中，我们使用灵活的反向强化学习方法来估计代理Q函数。我们使用这些估计的Q函数，以及一个聚类算法，选择了一些最为重要的状态，这些状态对于驱动Q函数的变化最为关键。在第二阶段，利用这些被选择的“聚合”状态，我们使用常用的嵌套固定点算法进行最大似然估计。所提出的二阶段方法实现了...

    We study dynamic discrete choice models, where a commonly studied problem involves estimating parameters of agent reward functions (also known as "structural" parameters), using agent behavioral data. Maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. In the first stage, we use a flexible inverse reinforcement learning approach to estimate agent Q-functions. We use these estimated Q-functions, along with a clustering algorithm, to select a subset of states that are the most pivotal for driving changes in Q-functions. In the second stage, with these selected "aggregated" states, we conduct maximum likelihood estimation using a commonly used nested fixed-point algorithm. The proposed two-stage approach 
    
[^18]: 深度ReLU神经网络在过参数化情况下的贝叶斯自由能

    Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases. (arXiv:2303.15739v1 [cs.LG])

    [http://arxiv.org/abs/2303.15739](http://arxiv.org/abs/2303.15739)

    本研究针对深度ReLU神经网络，证明了过参数化情况下的Bayesian自由能是有界的，说明Bayesian广义误差不会增加。

    

    在人工智能的许多研究领域中，深度神经网络已被证明可用于估计高维输入空间中的未知函数。然而，它们的泛化性能尚未从理论角度完全澄清，因为它们是不可识别的和奇异的学习机器。此外，ReLU函数不可微，奇异学习理论中的代数或解析方法无法应用于它。本文研究了一种过参数化情况下的深度ReLU神经网络，并证明了Bayesian自由能是有界的，即使层数比估计未知数据生成函数所必需的层数更多。由于Bayesian广义误差等于样本大小的自由能增加，因此我们的结果也表明，Bayesian广义误差不会增加。

    In many research fields in artificial intelligence, it has been shown that deep neural networks are useful to estimate unknown functions on high dimensional input spaces. However, their generalization performance is not yet completely clarified from the theoretical point of view because they are nonidentifiable and singular learning machines. Moreover, a ReLU function is not differentiable, to which algebraic or analytic methods in singular learning theory cannot be applied. In this paper, we study a deep ReLU neural network in overparametrized cases and prove that the Bayesian free energy, which is equal to the minus log marginal likelihoodor the Bayesian stochastic complexity, is bounded even if the number of layers are larger than necessary to estimate an unknown data-generating function. Since the Bayesian generalization error is equal to the increase of the free energy as a function of a sample size, our result also shows that the Bayesian generalization error does not increase ev
    
[^19]: 物理学知识作为不确定性量化模型的信息场理论

    Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification. (arXiv:2301.07609v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.07609](http://arxiv.org/abs/2301.07609)

    该论文扩展了信息场理论(IFT)到物理信息场理论(PIFT)，将描述场的物理定律的信息编码为函数先验。从这个PIFT得出的后验与任何数值方案无关，并且可以捕捉多种模式。

    

    数据驱动的方法结合物理学知识是建模系统的强有力技术。此类模型的目标是通过将测量结果与已知物理定律相结合，高效地求解基本场。由于许多系统包含未知元素，如缺失参数、嘈杂数据或不完整的物理定律，因此这通常被视为一种不确定性量化问题。处理所有变量的常见技术通常取决于用于近似后验的数值方案，并且希望有一种不依赖于任何离散化的方法。信息场理论（IFT）提供了对不一定是高斯场的场进行统计学的工具。我们通过将描述场的物理定律的信息编码为函数先验来扩展IFT到物理信息场理论（PIFT）。从这个PIFT得出的后验与任何数值方案无关，并且可以捕捉多种模式。

    Data-driven approaches coupled with physical knowledge are powerful techniques to model systems. The goal of such models is to efficiently solve for the underlying field by combining measurements with known physical laws. As many systems contain unknown elements, such as missing parameters, noisy data, or incomplete physical laws, this is widely approached as an uncertainty quantification problem. The common techniques to handle all the variables typically depend on the numerical scheme used to approximate the posterior, and it is desirable to have a method which is independent of any such discretization. Information field theory (IFT) provides the tools necessary to perform statistics over fields that are not necessarily Gaussian. We extend IFT to physics-informed IFT (PIFT) by encoding the functional priors with information about the physical laws which describe the field. The posteriors derived from this PIFT remain independent of any numerical scheme and can capture multiple modes,
    
[^20]: 用超线性收敛重构基于核的机器学习力场

    Reconstructing Kernel-based Machine Learning Force Fields with Super-linear Convergence. (arXiv:2212.12737v2 [physics.chem-ph] UPDATED)

    [http://arxiv.org/abs/2212.12737](http://arxiv.org/abs/2212.12737)

    本文提出了一种基于Nyström型方法的预处理器构建框架，实现了在低数据范围内高效重构核机器力场，并在带有数万个培训点的化学系统中获得了稳定和准确的结果。

    

    核机器在量子化学领域持续取得进展，尤其在力场重构的低数据范围内已被证明成功。这是因为可以将许多针对物理对称性的等变性和不变性合并到核函数中以补偿更大的数据集。但是，核机器的可扩展性受到其二次内存和与训练点数成立方关系的限制。虽然已知迭代的Krylov子空间求解器可以克服这些负担，但它们的收敛关键取决于有效的预处理器，这在实践中很难实现。有效的预处理器需要以计算便宜和数值鲁棒的方式部分预解学习问题。在这里，我们考虑了Nyström型方法类的广泛方法，以基于最初核函数的越来越复杂的低秩近似构建预处理器。

    Kernel machines have sustained continuous progress in the field of quantum chemistry. In particular, they have proven to be successful in the low-data regime of force field reconstruction. This is because many equivariances and invariances due to physical symmetries can be incorporated into the kernel function to compensate for much larger datasets. So far, the scalability of kernel machines has however been hindered by its quadratic memory and cubical runtime complexity in the number of training points. While it is known, that iterative Krylov subspace solvers can overcome these burdens, their convergence crucially relies on effective preconditioners, which are elusive in practice. Effective preconditioners need to partially pre-solve the learning problem in a computationally cheap and numerically robust manner. Here, we consider the broad class of Nystr\"om-type methods to construct preconditioners based on successively more sophisticated low-rank approximations of the original kerne
    
[^21]: PowRL：用于稳健管理电力网络的强化学习框架

    PowRL: A Reinforcement Learning Framework for Robust Management of Power Networks. (arXiv:2212.02397v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.02397](http://arxiv.org/abs/2212.02397)

    本论文提出了PowRL框架来通过强化学习来有效应对电力网络中的不确定情况，并保持电网的可靠运行。

    

    世界各地的电力网络通过为多个行业、企业和家庭消费者提供不间断、可靠和无暂态电力发挥着重要的社会和经济作用。随着可再生能源和电动车产生的不确定发电和高度动态负载需求的出现，通过适当的瞬态稳定问题管理来确保电力网络的稳健运行变得越来越重要，并将停电事件限制在地方范围内。本文引入了一个名为PowRL的强化学习（RL）框架，以缓解意外网络事件的影响，并可靠地在网络上随时维持电力。PowRL利用新颖的超负荷管理启发式以及基于RL提供的最优拓扑选择决策，以确保电网在变化和不确定条件下安全、可靠地运行（无超载线路和无停电事件）。

    Power grids, across the world, play an important societal and economical role by providing uninterrupted, reliable and transient-free power to several industries, businesses and household consumers. With the advent of renewable power resources and EVs resulting into uncertain generation and highly dynamic load demands, it has become ever so important to ensure robust operation of power networks through suitable management of transient stability issues and localize the events of blackouts. In the light of ever increasing stress on the modern grid infrastructure and the grid operators, this paper presents a reinforcement learning (RL) framework, PowRL, to mitigate the effects of unexpected network events, as well as reliably maintain electricity everywhere on the network at all times. The PowRL leverages a novel heuristic for overload management, along with the RL-guided decision making on optimal topology selection to ensure that the grid is operated safely and reliably (with no overloa
    
[^22]: 高维数据的无模型变量重要性方法

    Model free variable importance for high dimensional data. (arXiv:2211.08414v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.08414](http://arxiv.org/abs/2211.08414)

    该论文提出了一种无模型的变量重要性方法，可以与任意预测函数一起使用，不需要访问预测函数，可用于研究模型残差。引入了Cohort Shapley的积分梯度版本（IGCS），使得在二元预测器情况下也可以使用IG方法。

    

    模型不可知的变量重要性方法可与任意预测函数一起使用。在这里，我们提供了一些无模型方法，不需要访问预测函数。这在预测函数是专有的且不可用或极其昂贵时很有用。当对模型的残差进行研究时也很有用。Cohort Shapley（CS）方法是无模型方法，但在输入空间的维数上具有指数成本。Frye等人（2020）的监督流形上Shapley方法也是无模型的，但要求输入第二个黑匣子模型，该模型必须为Shapley值问题进行训练。我们引入了Cohort Shapley的积分梯度（IG）版本，称为IGCS，成本为$\mathcal{O}(nd)$。我们表明，在绝大多数相关单元的立方体上，IGCS值函数接近多线性函数，其中IGCS匹配CS。IGCS的另一个好处是它允许使用二元预测器进行IG方法。我们使用一些面积...

    A model-agnostic variable importance method can be used with arbitrary prediction functions. Here we present some model-free methods that do not require access to the prediction function. This is useful when that function is proprietary and not available, or just extremely expensive. It is also useful when studying residuals from a model. The cohort Shapley (CS) method is model-free but has exponential cost in the dimension of the input space. A supervised on-manifold Shapley method from Frye et al. (2020) is also model free but requires as input a second black box model that has to be trained for the Shapley value problem. We introduce an integrated gradient (IG) version of cohort Shapley, called IGCS, with cost $\mathcal{O}(nd)$. We show that over the vast majority of the relevant unit cube that the IGCS value function is close to a multilinear function for which IGCS matches CS. Another benefit of IGCS is that is allows IG methods to be used with binary predictors. We use some area 
    
[^23]: 一种分析连续时间系统的深度学习方法

    A Deep Learning Approach to Analyzing Continuous-Time Systems. (arXiv:2209.12128v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.12128](http://arxiv.org/abs/2209.12128)

    深度学习方法能够分析复杂自然过程的时间序列数据，放松了传统简化假设的限制，具备可解释性和灵活的函数逼近能力，能够应用于人类语言处理领域，改进数据解释力和探索性分析能力。

    

    科学家通常使用时间序列数据来研究复杂的自然过程，但回归分析常常假设过于简单化的动力学。深度学习的最近进展，在复杂过程模型的性能上取得了惊人的提高，但深度学习通常不用于科学分析。在这里，我们展示了深度学习可以用于分析复杂的过程，提供灵活的函数逼近并具有可解释性。我们的方法放松了传统简化假设（如线性、平稳和同方差性），这些假设对许多自然系统而言是不可行的，可能会严重影响数据的解释。我们在人类语言处理方面进行了模型评估，这是一个具有复杂连续动力学的领域。我们证明了在行为和神经影像数据上有显著的改进，并且我们展示了我们的模型可以在控制多种混杂实验设置的混杂因素和缺失数据的情况下，发现探索性分析中的新模式。

    Scientists often use observational time series data to study complex natural processes, but regression analyses often assume simplistic dynamics. Recent advances in deep learning have yielded startling improvements to the performance of models of complex processes, but deep learning is generally not used for scientific analysis. Here we show that deep learning can be used to analyze complex processes, providing flexible function approximation while preserving interpretability. Our approach relaxes standard simplifying assumptions (e.g., linearity, stationarity, and homoscedasticity) that are implausible for many natural systems and may critically affect the interpretation of data. We evaluate our model on incremental human language processing, a domain with complex continuous dynamics. We demonstrate substantial improvements on behavioral and neuroimaging data, and we show that our model enables discovery of novel patterns in exploratory analyses, controls for diverse confounds in conf
    
[^24]: 无监督表征学习中的识别参数概率模型

    Unsupervised representation learning with recognition-parametrised probabilistic models. (arXiv:2209.05661v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.05661](http://arxiv.org/abs/2209.05661)

    本文提出了一种基于识别参数模型的概率无监督学习新方法，可以灵活地学习识别模型，捕捉观测之间的潜在相关性，为图像分类和潜在分配问题提供了有效解决方案。

    

    我们提出了一种基于识别参数模型（RPM）的概率无监督学习新方法：作为关于观察变量和潜在变量的联合分布的归一化半参数化假设类。在观察值在给定潜在变量的条件下是条件独立的关键假设下，RPM将参数先验和观测条件下的潜在分布与非参数观测边缘相结合。该方法可以得到灵活的学习识别模型，捕捉了观测之间的潜在相关性，而不需要显式的参数生成模型。对于离散潜变量，RPM允许进行精确的最大似然学习，即使是基于强大的神经网络识别。我们开发了适用于连续潜变量情况的有效近似方法。实验展示了RPM在高维数据上的有效性，学习从弱间接监督中的图像分类；直接图像级潜在狄利克雷分配的学习。

    We introduce a new approach to probabilistic unsupervised learning based on the recognition-parametrised model (RPM): a normalised semi-parametric hypothesis class for joint distributions over observed and latent variables. Under the key assumption that observations are conditionally independent given latents, the RPM combines parametric prior and observation-conditioned latent distributions with non-parametric observation marginals. This approach leads to a flexible learnt recognition model capturing latent dependence between observations, without the need for an explicit, parametric generative model. The RPM admits exact maximum-likelihood learning for discrete latents, even for powerful neural-network-based recognition. We develop effective approximations applicable in the continuous-latent case. Experiments demonstrate the effectiveness of the RPM on high-dimensional data, learning image classification from weak indirect supervision; direct image-level latent Dirichlet allocation; 
    
[^25]: 关于ELBO收敛到熵和的研究

    On the Convergence of the ELBO to Entropy Sums. (arXiv:2209.03077v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.03077](http://arxiv.org/abs/2209.03077)

    本论文研究了 ELBO 收敛到熵和的问题，证明了对于一类广泛的生成模型，ELBO 在所有学习的稳定点处都等于一系列熵的和，为无监督学习的学习算法的基本属性提供了深入的洞察。

    

    变分下界（又称ELBO或自由能）是许多经典和新颖的无监督学习算法的核心目标。学习算法可以改变模型参数，使变分下界增加。通常，学习进行到参数收敛到接近学习动态的稳定点值。在本文的理论贡献中，我们证明了（对于一类非常广泛的生成模型），变分下界在所有学习的稳定点处均等于一系列熵的和。对于具有一组潜在变量和一组观测变量的标准机器学习模型，这个和包括三个熵: (A) 变分分布的熵（平均熵），(B) 模型先验分布的负熵和 (C) 可观测分布的（期望）负熵。所得到的结果适用于包括：有限数量的数据点，在学习的任意阶段和各种不同的生成模型等真实条件。本研究为无监督学习的学习算法的基本属性提供了深入洞察，是对优化推理和学习的理论分析的第一步。

    The variational lower bound (a.k.a. ELBO or free energy) is the central objective for many established as well as many novel algorithms for unsupervised learning. Learning algorithms change model parameters such that the variational lower bound increases. Learning usually proceeds until parameters have converged to values close to a stationary point of the learning dynamics. In this purely theoretical contribution, we show that (for a very large class of generative models) the variational lower bound is at all stationary points of learning equal to a sum of entropies. For standard machine learning models with one set of latents and one set observed variables, the sum consists of three entropies: (A) the (average) entropy of the variational distributions, (B) the negative entropy of the model's prior distribution, and (C) the (expected) negative entropy of the observable distributions. The obtained result applies under realistic conditions including: finite numbers of data points, at an
    
[^26]: 连续生成神经网络

    Continuous Generative Neural Networks. (arXiv:2205.14627v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.14627](http://arxiv.org/abs/2205.14627)

    本文介绍了一种连续生成神经网络(CGNN)的模型，使用条件保证CGNN是单射的，其生成流形被用于求解反问题，并证明了其方法的有效性和稳健性。

    

    本文介绍了并研究了一种连续生成神经网络（CGNN），即连续情境下的生成模型：CGNN的输出属于无限维函数空间。该架构受DCGAN的启发，采用一个全连接层，多个卷积层和非线性激活函数。在连续的$L^2$情境下，每层空间的维度被紧支小波的多重分辨率分析的尺度所代替。我们提出了关于卷积滤波器和非线性的条件，保证CGNN是单射的。该理论应用于反问题，并允许导出一个CGNN生成流形的（可能非线性的）无限维反问题的Lipschitz稳定性估计。包括信号去模糊在内的多个数值模拟证明并验证了这一方法。

    In this work, we present and study Continuous Generative Neural Networks (CGNNs), namely, generative models in the continuous setting: the output of a CGNN belongs to an infinite-dimensional function space. The architecture is inspired by DCGAN, with one fully connected layer, several convolutional layers and nonlinear activation functions. In the continuous $L^2$ setting, the dimensions of the spaces of each layer are replaced by the scales of a multiresolution analysis of a compactly supported wavelet. We present conditions on the convolutional filters and on the nonlinearity that guarantee that a CGNN is injective. This theory finds applications to inverse problems, and allows for deriving Lipschitz stability estimates for (possibly nonlinear) infinite-dimensional inverse problems with unknowns belonging to the manifold generated by a CGNN. Several numerical simulations, including signal deblurring, illustrate and validate this approach.
    
[^27]: HOUDINI: 从适度约束的马鞍点中逃脱

    HOUDINI: Escaping from Moderately Constrained Saddles. (arXiv:2205.13753v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13753](http://arxiv.org/abs/2205.13753)

    本文给出了第一个多项式时间算法，能在适度数量的约束下使梯度下降方法逃脱高维马鞍点。

    

    我们给出了第一个在适度数量的约束下从高维马鞍点中逃脱的多项式时间算法。给定光滑函数$f \colon \mathbb R^d \to \mathbb R$的梯度访问权限，我们展示了（带噪声的）梯度下降方法可以在对数个不等式约束下逃脱马鞍点。这是对 Ge 等人的突破性工作的主要开放问题的首次有形进展（无需依赖 NP-Oracle 或改变定义来仅考虑特定约束）。我们的结果适用于正则梯度下降和随机梯度下降。

    We give the first polynomial time algorithms for escaping from high-dimensional saddle points under a moderate number of constraints. Given gradient access to a smooth function $f \colon \mathbb R^d \to \mathbb R$ we show that (noisy) gradient descent methods can escape from saddle points under a logarithmic number of inequality constraints. This constitutes the first tangible progress (without reliance on NP-oracles or altering the definitions to only account for certain constraints) on the main open question of the breakthrough work of Ge et al. who showed an analogous result for unconstrained and equality-constrained problems. Our results hold for both regular and stochastic gradient descent.
    
[^28]: 通信效率高的自适应联邦学习

    Communication-Efficient Adaptive Federated Learning. (arXiv:2205.02719v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.02719](http://arxiv.org/abs/2205.02719)

    本文提出了一种新的通信效率高的自适应联邦学习方法（FedCAMS），可以解决联邦学习中由于重复的服务器-客户端同步而产生的大量通信开销和基于 SGD 的模型更新缺乏适应性等诸多问题。

    

    联邦学习是一种机器学习训练方式，使得客户端可以在不共享本地数据的情况下共同训练模型。然而，实际中实现联邦学习仍面临许多挑战，如由于重复的服务器-客户端同步而产生的大量通信开销以及基于 SGD 的模型更新缺乏适应性。尽管已经提出了各种方法来通过梯度压缩或量化来减少通信成本，并提出了FedAdam等联邦版本的自适应优化器来增加更多的适应性，但当前的联邦学习框架仍无法同时解决上述所有挑战。本文提出了一种新的通信效率高的自适应联邦学习方法（FedCAMS），具有理论上的收敛保证。

    Federated learning is a machine learning training paradigm that enables clients to jointly train models without sharing their own localized data. However, the implementation of federated learning in practice still faces numerous challenges, such as the large communication overhead due to the repetitive server-client synchronization and the lack of adaptivity by SGD-based model updates. Despite that various methods have been proposed for reducing the communication cost by gradient compression or quantization, and the federated versions of adaptive optimizers such as FedAdam are proposed to add more adaptivity, the current federated learning framework still cannot solve the aforementioned challenges all at once. In this paper, we propose a novel communication-efficient adaptive federated learning method (FedCAMS) with theoretical convergence guarantees. We show that in the nonconvex stochastic optimization setting, our proposed FedCAMS achieves the same convergence rate of $O(\frac{1}{\s
    
[^29]: 流形两样本检验研究：神经网络的积分概率度量

    A Manifold Two-Sample Test Study: Integral Probability Metric with Neural Networks. (arXiv:2205.02043v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.02043](http://arxiv.org/abs/2205.02043)

    文章提出了一种基于积分概率度量的两样本检验方法，适用于低维流形上支持的高维样本。实验结果表明，所提出的方法在统计功率方面优于最先进的方法。

    

    两样本检验是一种重要的方法，旨在确定两个观测集合是否遵循相同的分布。我们提出了一种基于积分概率度量（IPM）的两样本检验，适用于低维流形上支持的高维样本。我们通过样本数$n$和流形内在维度$d$的结构表征了所提出的检验的特性。当给定一个图集时，我们提出了两步检验以识别一般分布之间的差异，其在$n^{-1/\max\{d,2\}}$的顺序中实现了第二类型风险。当未给出图集时，我们提出了H\"older IPM检验，适用于具有$(s,\beta)$‐H\"older密度的数据分布，其在$n^{-(s+\beta)/d}$的顺序中实现了第二类型风险。为了减轻评估H\"older IPM的重计算负担，我们使用神经网络来逼近H\"older函数类。基于神经网络的逼近理论，我们可以证明所提出的神经网络H\"older IPM测试具有一致的效率。实验结果表明，我们的提出的方法在统计功率方面优于最先进的方法。

    Two-sample tests are important areas aiming to determine whether two collections of observations follow the same distribution or not. We propose two-sample tests based on integral probability metric (IPM) for high-dimensional samples supported on a low-dimensional manifold. We characterize the properties of proposed tests with respect to the number of samples $n$ and the structure of the manifold with intrinsic dimension $d$. When an atlas is given, we propose two-step test to identify the difference between general distributions, which achieves the type-II risk in the order of $n^{-1/\max\{d,2\}}$. When an atlas is not given, we propose H\"older IPM test that applies for data distributions with $(s,\beta)$-H\"older densities, which achieves the type-II risk in the order of $n^{-(s+\beta)/d}$. To mitigate the heavy computation burden of evaluating the H\"older IPM, we approximate the H\"older function class using neural networks. Based on the approximation theory of neural networks, we
    
[^30]: 核鲁棒假设检验

    Kernel Robust Hypothesis Testing. (arXiv:2203.12777v2 [eess.SP] CROSS LISTED)

    [http://arxiv.org/abs/2203.12777](http://arxiv.org/abs/2203.12777)

    本文使用核方法构造不确定性集，在贝叶斯设置和Neyman-Pearson设置中分别研究了最小化最坏情况下错误概率和控制错误概率的问题，并提出了基于MMD的一系列测试。

    

    本论文研究了鲁棒假设检验问题，在零假设和备择假设下，数据生成分布被假设在某些不确定性集合中，并旨在设计一种测试，在不确定性集合中表现最优。本文将使用核方法以数据驱动的方式构造不确定性集，即以来自零假设和备择假设的训练样本的经验分布为中心，并通过核均值嵌入的距离来约束，即最大平均差异（MMD）。同时，本文还研究了贝叶斯设置和Neyman-Pearson设置。对于贝叶斯设置，即目标是最小化最坏情况下的错误概率，当字母表是有限的时，首先得到了最佳测试。当字母表是无限的时，提出了一种可行的近似方法来量化最坏情况下的错误概率。对于Neyman-Pearson设置，即目标是在最小化第二类错误概率的同时控制在给定水平下的第一类错误概率，提出了一系列基于MMD的测试，并研究了它们的渐近特性。

    The problem of robust hypothesis testing is studied, where under the null and the alternative hypotheses, the data-generating distributions are assumed to be in some uncertainty sets, and the goal is to design a test that performs well under the worst-case distributions over the uncertainty sets. In this paper, uncertainty sets are constructed in a data-driven manner using kernel method, i.e., they are centered around empirical distributions of training samples from the null and alternative hypotheses, respectively; and are constrained via the distance between kernel mean embeddings of distributions in the reproducing kernel Hilbert space, i.e., maximum mean discrepancy (MMD). The Bayesian setting and the Neyman-Pearson setting are investigated. For the Bayesian setting where the goal is to minimize the worst-case error probability, an optimal test is firstly obtained when the alphabet is finite. When the alphabet is infinite, a tractable approximation is proposed to quantify the worst
    
[^31]: 剪切Gossip在拜占庭鲁棒的分散式学习中的应用

    Byzantine-Robust Decentralized Learning via ClippedGossip. (arXiv:2202.01545v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.01545](http://arxiv.org/abs/2202.01545)

    本文提出的剪切Gossip算法是第一个能够在标准假设下证明收敛到非凸目标的$O(\delta_{max} \zeta^2 /\gamma^2)$邻域的算法，并在大量攻击下表现良好。

    

    本文研究了在任意通信图上进行拜占庭鲁棒的分散式训练的艰巨任务。与联邦学习通过服务器进行通信的方式不同，分散式环境中的workers只能与它们的邻居交流，这使得达成共识和协作训练更加困难。为了解决这些问题，我们提出了一种用于拜占庭鲁棒共识和优化的剪切Gossip算法，它是第一个在标准假设下可以证明收敛到非凸目标的$O(\delta_{max} \zeta^2 /\gamma^2)$邻域的算法。最后，我们在大量攻击下证明了剪切Gossip的鼓舞人心的实证表现。

    In this paper, we study the challenging task of Byzantine-robust decentralized training on arbitrary communication graphs. Unlike federated learning where workers communicate through a server, workers in the decentralized environment can only talk to their neighbors, making it harder to reach consensus and benefit from collaborative training. To address these issues, we propose a ClippedGossip algorithm for Byzantine-robust consensus and optimization, which is the first to provably converge to a $O(\delta_{\max}\zeta^2/\gamma^2)$ neighborhood of the stationary point for non-convex objectives under standard assumptions. Finally, we demonstrate the encouraging empirical performance of ClippedGossip under a large number of attacks.
    
[^32]: 边界图神经网络用于 3D 模拟

    Boundary Graph Neural Networks for 3D Simulations. (arXiv:2106.11299v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.11299](http://arxiv.org/abs/2106.11299)

    本文提出了一种新型边界图神经网络（BGNNs），能够有效地表示三维颗粒流动的复杂几何形状，从而实现了高效的预测和计算。

    

    大量数据的出现使得机器学习在自然科学和工程学方面具有了可观的动力，然而对物理过程进行建模通常很困难。其中一个特别棘手的问题是如何有效地表示几何边界。三角化的几何边界在工程应用中得到了广泛理解和使用。然而，基于它们的尺寸和方向的异质性，将它们集成到机器学习方法中通常十分困难。在本文中，我们引入了一种有效的理论来建模粒子与边界的相互作用，从而推导出了我们的新型边界图神经网络（BGNNs），该网络动态地修改图结构以满足边界条件。新的 BGNNs 在复杂的三维颗粒流动过程（如漏斗、旋转鼓和搅拌器）中进行了测试，这些过程都是现代工业机械的标准组件，但其几何形状仍然十分复杂。BGNNs 在计算效率和预测准确率方面都得到了评估。

    The abundance of data has given machine learning considerable momentum in natural sciences and engineering, though modeling of physical processes is often difficult. A particularly tough problem is the efficient representation of geometric boundaries. Triangularized geometric boundaries are well understood and ubiquitous in engineering applications. However, it is notoriously difficult to integrate them into machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce an effective theory to model particle-boundary interactions, which leads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify graph structures to obey boundary conditions. The new BGNNs are tested on complex 3D granular flow processes of hoppers, rotating drums and mixers, which are all standard components of modern industrial machinery but still have complicated geometry. BGNNs are evaluated in terms of computational efficiency as well as pre
    
[^33]: 单个神经元能否学习预测不确定性？

    Can a single neuron learn predictive uncertainty?. (arXiv:2106.03702v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.03702](http://arxiv.org/abs/2106.03702)

    本文介绍了一种基于单个神经元的新型非参数分位数估计方法，该方法在小样本大小和真实世界实验中的优越表现表明其可以消除与模型规范相关的自由度，并提供更好的预测不确定性估计。

    

    采用深度学习方法进行的不确定性估计旨在分离我们通过测量所观察到的世界状态的不确定性（客观终点）与模型规范和训练过程用于预测这种状态的方式相混淆的程度（主观手段）--例如神经元的数量，深度，连接，先验分布（如果模型是贝叶斯的），权重初始化等。这引出了一个问题，即在仍能捕获客观终点的前提下，能否消除与这些规范相关的自由度。本文介绍了一种基于最简单的神经网络结构—单个神经元—的连续随机变量的新型非参数分位数估计方法。首先，在合成实验中，该方法展现了它的优势，它将通过排序顺序统计量得到的分位数估计结果（特别是对于小样本大小）与分位回归进行了比较。在真实世界的实验中，该方法被证明可以通过降低超出分布范围的数据中预测方差的低估来为贝叶斯神经网络提供更好的预测不确定性估计。

    Uncertainty estimation methods using deep learning approaches strive against separating how uncertain the state of the world manifests to us via measurement (objective end) from the way this gets scrambled with the model specification and training procedure used to predict such state (subjective means) -- e.g., number of neurons, depth, connections, priors (if the model is bayesian), weight initialization, etc. This poses the question of the extent to which one can eliminate the degrees of freedom associated with these specifications and still being able to capture the objective end. Here, a novel non-parametric quantile estimation method for continuous random variables is introduced, based on the simplest neural network architecture with one degree of freedom: a single neuron. Its advantage is first shown in synthetic experiments comparing with the quantile estimation achieved from ranking the order statistics (specifically for small sample size) and with quantile regression. In real-
    
[^34]: 变分自编码器的ELBO收敛于三个熵之和。

    The ELBO of Variational Autoencoders Converges to a Sum of Three Entropies. (arXiv:2010.14860v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.14860](http://arxiv.org/abs/2010.14860)

    标准变分自编码器的ELBO在稳定点处可以以闭合形式计算，收敛于三个熵之和。（其中一个熵为先验分布的熵，一个为可观测分布的熵，一个为变分分布的平均熵，成果证明了ELBO在稳定点处等于熵。）

    

    变分自编码器(VAEs)的中心目标函数是其变分下界(ELBO)。我们展示了对于标准(即高斯)VAEs，ELBO收敛于由三个熵之和给出的值：(先验分布的负)熵、可观测分布的预期(负)熵以及变分分布的平均熵(后者已经是ELBO的一部分)。我们的推导结果精确，适用于编码器和解码器的小型和复杂深度网络，并适用于有限和无限数量的数据点以及任何稳定点(包括局部最大值和鞍点)。该结果意味着对于标准VAEs，ELBO在稳定点时通常可以以闭合形式计算，而原始ELBO需要数值积分近似。作为主要贡献，我们提供了VAEs的ELBO在稳定点处等于熵的证明。

    The central objective function of a variational autoencoder (VAE) is its variational lower bound (the ELBO). Here we show that for standard (i.e., Gaussian) VAEs the ELBO converges to a value given by the sum of three entropies: the (negative) entropy of the prior distribution, the expected (negative) entropy of the observable distribution, and the average entropy of the variational distributions (the latter is already part of the ELBO). Our derived analytical results are exact and apply for small as well as for intricate deep networks for encoder and decoder. Furthermore, they apply for finitely and infinitely many data points and at any stationary point (including local maxima and saddle points). The result implies that the ELBO can for standard VAEs often be computed in closed-form at stationary points while the original ELBO requires numerical approximations of integrals. As a main contribution, we provide the proof that the ELBO for VAEs is at stationary points equal to entropy su
    
[^35]: 基于投影梯度下降的对抗训练中梯度方向的量化研究

    Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent. (arXiv:2009.04709v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2009.04709](http://arxiv.org/abs/2009.04709)

    本文提出了一种新的定义来描述对抗训练中梯度的优选方向，利用生成对抗网络的指标来评估对齐情况，并表明在对齐方向上的限制可以进一步提高模型的鲁棒性。

    

    对抗训练，尤其是投影梯度下降（PGD），已被证明是提高对抗性攻击鲁棒性的有效方法。在对抗训练后，模型对其输入的梯度具有优选方向。然而，对齐方向并没有得到数学上的很好描述，这使得其难以进行定量评估。我们提出了一种新的定义，将其视为指向决策空间中最近错误类支持集的最近点的向量方向。为了评估对抗训练后模型与此方向的对齐情况，我们应用了一种指标，该指标使用生成对抗网络来产生最小残差，以改变图像中的类别。我们表明，PGD训练的模型相比基线具有更高的对齐度，而我们的指标呈现比竞争指标公式更高的对齐度值，并且在训练过程中强制执行这个对齐方向可以进一步提高模型的鲁棒性。

    Adversarial training, especially projected gradient descent (PGD), has proven to be a successful approach for improving robustness against adversarial attacks. After adversarial training, gradients of models with respect to their inputs have a preferential direction. However, the direction of alignment is not mathematically well established, making it difficult to evaluate quantitatively. We propose a novel definition of this direction as the direction of the vector pointing toward the closest point of the support of the closest inaccurate class in decision space. To evaluate the alignment with this direction after adversarial training, we apply a metric that uses generative adversarial networks to produce the smallest residual needed to change the class present in the image. We show that PGD-trained models have a higher alignment than the baseline according to our definition, that our metric presents higher alignment values than a competing metric formulation, and that enforcing this 
    
[^36]: FRMDN: 基于流的循环混合密度网络

    FRMDN: Flow-based Recurrent Mixture Density Network. (arXiv:2008.02144v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2008.02144](http://arxiv.org/abs/2008.02144)

    本文提出了一种基于流的循环混合密度网络，通过在每个时间步上定义一个高斯混合模型，将循环混合密度网络推广到非线性变换的目标序列上，该模型在图像序列的拟合度上表现显著，具有显著的建模能力，在对数似然度量方面优于其他最先进的方法。

    This paper proposes a flow-based recurrent mixture density network (FRMDN) that generalizes recurrent mixture density networks by defining a Gaussian mixture model on a non-linearly transformed target sequence in each time-step. The model significantly improves the fit to image sequences and outperforms other state-of-the-art methods in terms of the log-likelihood.

    循环混合密度网络是一类重要的概率模型，广泛应用于序列建模和序列到序列映射应用中。在这类模型中，目标序列在每个时间步的密度由具有循环神经网络参数的高斯混合模型建模。本文通过在每个时间步上定义一个高斯混合模型，将循环混合密度网络推广到非线性变换的目标序列上。非线性变换空间是通过归一化流创建的。我们观察到，该模型显著提高了图像序列的拟合度，用对数似然度量。我们还将所提出的模型应用于一些语音和图像数据，并观察到该模型具有显著的建模能力，在对数似然度量方面优于其他最先进的方法。

    The class of recurrent mixture density networks is an important class of probabilistic models used extensively in sequence modeling and sequence-to-sequence mapping applications. In this class of models, the density of a target sequence in each time-step is modeled by a Gaussian mixture model with the parameters given by a recurrent neural network. In this paper, we generalize recurrent mixture density networks by defining a Gaussian mixture model on a non-linearly transformed target sequence in each time-step. The non-linearly transformed space is created by normalizing flow. We observed that this model significantly improves the fit to image sequences measured by the log-likelihood. We also applied the proposed model on some speech and image data, and observed that the model has significant modeling power outperforming other state-of-the-art methods in terms of the log-likelihood.
    

