# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Borda Regret Minimization for Generalized Linear Dueling Bandits.](http://arxiv.org/abs/2303.08816) | 本文解决了通用广义线性对抗性排名问题中的博尔达后悔最小化问题，提出了高度表达力的模型，并使用一种新的“先探索再执行”算法避免了困难的后悔下限。 |
| [^2] | [Understanding Post-hoc Explainers: The Case of Anchors.](http://arxiv.org/abs/2303.08806) | 本文对Anchors进行了理论分析，这是一种基于规则的可解释性方法，用于解释文本分类器的决策。 |
| [^3] | [Distribution-free Deviation Bounds of Learning via Model Selection with Cross-validation Risk Estimation.](http://arxiv.org/abs/2303.08777) | 本文提出通过模型选择和交叉验证风险估计来学习的一般方法，并建立了无分布偏差界，比经验风险最小化方法更紧密，在一些情况下表现更优。 |
| [^4] | [Predicting Individualized Effects of Internet-Based Treatment for Genito-Pelvic Pain/Penetration Disorder: Development and Internal Validation of a Multivariable Decision Tree Model.](http://arxiv.org/abs/2303.08732) | 研究开发了一种多变量决策树模型，该模型可预测基于互联网的治疗对盆腔疼痛/穿透障碍患者的症状的多维综合评分的效果。 |
| [^5] | [Practicality of generalization guarantees for unsupervised domain adaptation with neural networks.](http://arxiv.org/abs/2303.08720) | 研究评估了现有文献中有潜力满足我们要求的域适应图像分类任务的界限，发现所有界限都是空泛的，样本泛化术语占据了观察到的松弛程度的很大部分，特别是当这些术语与域的度量互动时。 |
| [^6] | [Learning to Reconstruct Signals From Binary Measurements.](http://arxiv.org/abs/2303.08691) | 该论文提出了一种新的自监督学习方法SSBM，它只需要二进制数据进行训练，并探索了从不完整的二进制观察中学习的极端情况。这为从二进制测量中恢复信号提供了必要和充分条件，并在一系列真实数据集上展示了SSBM的卓越表现。 |
| [^7] | [Interpretable Ensembles of Hyper-Rectangles as Base Models.](http://arxiv.org/abs/2303.08625) | 本文提出了一种基于超矩形的可解释的集成模型，它将均匀生成的轴对齐超矩形作为基模型，并成功地避免了过拟合。 |
| [^8] | [Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer.](http://arxiv.org/abs/2303.08622) | 本文提出了一种适用于文本引导图像风格迁移中的零样本对比损失方法，可以在不需要额外训练的情况下生成具有相同语义内容的图像。 |
| [^9] | [Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model.](http://arxiv.org/abs/2303.08613) | 本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。 |
| [^10] | [Delay-SDE-net: A deep learning approach for time series modelling with memory and uncertainty estimates.](http://arxiv.org/abs/2303.08587) | 本研究提出了一种基于随机延迟微分方程的神经网络模型Delay-SDE-net，可以准确地建模具有记忆效应的时间序列，并且能够对模型的不确定性进行实时估计。 |
| [^11] | [Statistical learning on measures: an application to persistence diagrams.](http://arxiv.org/abs/2303.08456) | 本文提出了一个新的统计学习框架，用于处理紧致空间上的测度数据，并且向我们展示了如何使用拓扑信息进行分类。 |
| [^12] | [The Benefits of Mixup for Feature Learning.](http://arxiv.org/abs/2303.08433) | 本论文介绍了数据增强方法Mixup对于特征学习的益处。混合训练可以有效地从混合数据中学习罕见特征，相比之下，标准训练可能会漏掉这些罕见特征。 |
| [^13] | [Policy Gradient Converges to the Globally Optimal Policy for Nearly Linear-Quadratic Regulators.](http://arxiv.org/abs/2303.08431) | 本论文研究了强化学习方法在几乎线性二次型调节器系统中找到最优策略的问题，提出了一个策略梯度算法，可以以线性速率收敛于全局最优解。 |
| [^14] | [Optimal Sampling Designs for Multi-dimensional Streaming Time Series with Application to Power Grid Sensor Data.](http://arxiv.org/abs/2303.08242) | 本文提出针对多维流式时间序列的最优抽样设计方法，并应用于高速电力消耗数据的低成本实时分析，提高了计算效率。 |
| [^15] | [Bayesian Beta-Bernoulli Process Sparse Coding with Deep Neural Networks.](http://arxiv.org/abs/2303.08230) | 本文提出了一种基于Beta-Bernoulli过程和非参数迭代算法的深度稀疏编码模型，旨在学习具有尺度不变性的离散特征，并鼓励表示的稀疏性。 |
| [^16] | [Information-Theoretic Regret Bounds for Bandits with Fixed Expert Advice.](http://arxiv.org/abs/2303.08102) | 本文研究固定专家建议下的赌博机问题，提出了基于信息论的遗憾界限，可以使得某些算法的遗憾无限接近于零。此外，我们还提出了KL散度来描述专家之间的相似性界限，并给出了下限证明算法的最优性。 |
| [^17] | [Meta-learning Control Variates: Variance Reduction with Limited Data.](http://arxiv.org/abs/2303.04756) | 该论文提出了一种元学习控制变量的方法，可在有限数据的情况下减小蒙特卡罗估计器的方差，并对多个任务进行处理。 |
| [^18] | [Vector Quantized Time Series Generation with a Bidirectional Prior Model.](http://arxiv.org/abs/2303.04743) | 本文提出了一种新的时间序列生成方法，使用向量量化技术和双向变压器模型来生成质量更好、模块化变化更快的合成信号。 |
| [^19] | [Approximately optimal domain adaptation with Fisher's Linear Discriminant Analysis.](http://arxiv.org/abs/2302.14186) | 本文提出了一种基于Fisher线性判别的领域自适应模型，该模型是两个假设的凸组合，可以在不访问任何单个源任务的直接信息的情况下计算最优分类器，并在基于EEG和ECG的分类设置中展示了其有效性。 |
| [^20] | [Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift.](http://arxiv.org/abs/2302.10160) | 该论文提出了一种关于核岭回归的协变量转移策略，通过使用伪标签进行模型选择，能够适应不同特征分布下的学习，实现均方误差最小化。 |
| [^21] | [Understanding Multimodal Contrastive Learning and Incorporating Unpaired Data.](http://arxiv.org/abs/2302.06232) | 本论文研究了一般类的非线性损失函数进行多模式对比学习，揭示了其与奇异值分解的联系。并证明在错误匹配的情况下，多模式对比学习可以比单模式对比学习表现更佳，表现了其对嘈杂数据的鲁棒性。 |
| [^22] | [Robust online active learning.](http://arxiv.org/abs/2302.00422) | 本文提出了一种自适应方法，用于鲁棒的在线主动学习，并在受污染的数据流中证明了其性能表现优异，同时确保了稳定性并减少异常值的负面影响。 |
| [^23] | [Online Active Learning for Soft Sensor Development using Semi-Supervised Autoencoders.](http://arxiv.org/abs/2212.13067) | 本文介绍了一种使用半监督自编码器以及在线主动学习方法，以尽可能少的标记样本来开发软测量传感器，从而显著降低了成本。在实验中，作者表明这种方法能够取得好的预测效果。 |
| [^24] | [Policy learning "without'' overlap: Pessimism and generalized empirical Bernstein's inequality.](http://arxiv.org/abs/2212.09900) | 本文提出了一种新的离线策略学习算法，它不需要统一交叠假设，而是利用价值的下限置信区间（LCBs）优化策略，因此能够适应允许行为策略演变和倾向性减弱的情况。 |
| [^25] | [Recurrent Neural Networks and Universal Approximation of Bayesian Filters.](http://arxiv.org/abs/2211.00335) | 本文提出一个循环神经网络框架，用于直接从观测输入到所需的估计器统计量学习递归映射，可以近似估计潜在时间序列信号的条件统计量，在非紧致域中有误差界限，在长时间上有良好性能。 |
| [^26] | [Training Neural Networks for Sequential Change-point Detection.](http://arxiv.org/abs/2210.17312) | 本文介绍了一种使用神经网络进行在线变点检测的方法，通过训练神经网络逐步计算检测统计量的累积和来检测变点，并在合成和真实数据上证明了该方法的优越性和潜力。 |
| [^27] | [Gradient Gating for Deep Multi-Rate Learning on Graphs.](http://arxiv.org/abs/2210.00513) | G2是一种利用梯度门控机制的新型GNN框架，可缓解过度平滑问题，并实现了各种图学习任务上的最先进性能。 |
| [^28] | [Generalized Kernel Regularized Least Squares.](http://arxiv.org/abs/2209.14355) | 本论文提出了广义核正则化最小二乘法 (gKRLS)，解决了核正则化最小二乘法 (KRLS) 在当前使用中的两个限制：它的扩展能力不足，且即使在小规模数据集上，其计算代价也非常高昂。 |
| [^29] | [Lost in the Shuffle: Testing Power in the Presence of Errorful Network Vertex Labels.](http://arxiv.org/abs/2208.08638) | 研究了当网络中存在不匹配/标签混乱的顶点时，两个样本图假设检验中的功率损失，并通过多个实验加以验证。 |
| [^30] | [Probabilistic Reconciliation of Count Time Series.](http://arxiv.org/abs/2207.09322) | 本文提出了一种新的概率计数时间序列调和方法，产生协调的概率质量函数，相比于概率高斯调和，能够带来显著的预测改进。 |
| [^31] | [Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA Models.](http://arxiv.org/abs/2207.06950) | 本文提出了一种新算法GAMI-Tree，使用基于模型的树以及新的交互过滤方法，可以更好地拟合底层交互，具有更好的预测性能和更高的效率。 |
| [^32] | [Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity.](http://arxiv.org/abs/2204.06242) | 提出了一种新的基于修改过的马蹄蚌先验的多视角潜变量模型MuVI，用于建模结构稀疏性。它能够纳入有限且噪声的领域知识，以内在可解释的方式分析多视角数据，优于现有结构稀疏性建模方法。 |
| [^33] | [Learning Resilient Radio Resource Management Policies with Graph Neural Networks.](http://arxiv.org/abs/2203.11012) | 本文提出了一个使用图神经网络学习的具有弹性的无线电资源管理策略，以实现高聚合速率并确保所有用户的公平性，并使用可扩展的置换等变图神经网络（GNN）架构基于瞬时信道条件推导出的图形拓扑来参数化RRM策略 |
| [^34] | [Weisfeiler and Leman go Machine Learning: The Story so far.](http://arxiv.org/abs/2112.09992) | Weisfeiler-Leman算法被广泛应用于处理图和关系数据。本文全面介绍了该算法在监督学习中的应用，包括理论背景、扩展、与等变神经网格的联系、并列出了当前应用和未来研究方向。 |
| [^35] | [Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting.](http://arxiv.org/abs/2110.03135) | 该论文发现了对抗训练中存在的标签噪声，并解释了其对鲁棒过度拟合的普遍存在以及扰动半径和数据质量的依赖性。通过该论文提出的方法，可以自动校准标签以应对标签噪声和鲁棒过度拟合。 |
| [^36] | [Marginalising over Stationary Kernels with Bayesian Quadrature.](http://arxiv.org/abs/2106.07452) | 本文提出一种贝叶斯积分方案，用于边缘化高斯过程核族，以获得具有良好校准不确定性估计的灵活模型，比现有方法更高效实用。 |

# 详细

[^1]: Borda Regret Minimization for Generalized Linear Dueling Bandits (通用广义线性对抗性排名问题的博尔达后悔最小化算法)

    Borda Regret Minimization for Generalized Linear Dueling Bandits. (arXiv:2303.08816v1 [cs.LG])

    [http://arxiv.org/abs/2303.08816](http://arxiv.org/abs/2303.08816)

    本文解决了通用广义线性对抗性排名问题中的博尔达后悔最小化问题，提出了高度表达力的模型，并使用一种新的“先探索再执行”算法避免了困难的后悔下限。

    

    对抗性排名问题(Dueling bandits)常被用于机器学习应用，如推荐系统和排名问题。本文研究对抗性排名问题中博尔达后悔最小化问题，旨在确定具有最高博尔达得分的项目，并同时最小化累计的后悔。我们提出了一个新的、高度表达力的通用广义线性对抗性排名模型，它包括许多现有模型。 令人惊讶的是，博尔达后悔最小化问题是困难的。 我们证明了渐近时间复杂度的后悔下限是$\Omega(d^{2/3} T^{2/3})$，其中$d$是上下文向量的维数，$T$是时间跨度。为了达到下限，我们提出了一种"先探索再执行"的算法，它具有几乎匹配的上限回归误差$\tilde{O}(d^{2/3} T^{2/3})$。当项目数量$K$很小时，我们的算法可以通过适当选择超参数以达到更小的后悔$\tilde{O}((d\log K)^{1/3}T^{2/3})$。

    Dueling bandits are widely used to model preferential feedback that is prevalent in machine learning applications such as recommendation systems and ranking. In this paper, we study the Borda regret minimization problem for dueling bandits, which aims to identify the item with the highest Borda score while minimizing the cumulative regret. We propose a new and highly expressive generalized linear dueling bandits model, which covers many existing models. Surprisingly, the Borda regret minimization problem turns out to be difficult, as we prove a regret lower bound of order $\Omega(d^{2/3} T^{2/3})$, where $d$ is the dimension of contextual vectors and $T$ is the time horizon. To attain the lower bound, we propose an explore-then-commit type algorithm, which has a nearly matching regret upper bound $\tilde{O}(d^{2/3} T^{2/3})$. When the number of items/arms $K$ is small, our algorithm can achieve a smaller regret $\tilde{O}( (d \log K)^{1/3} T^{2/3})$ with proper choices of hyperparamete
    
[^2]: 理解事后解释器：以Anchors为例

    Understanding Post-hoc Explainers: The Case of Anchors. (arXiv:2303.08806v1 [stat.ML])

    [http://arxiv.org/abs/2303.08806](http://arxiv.org/abs/2303.08806)

    本文对Anchors进行了理论分析，这是一种基于规则的可解释性方法，用于解释文本分类器的决策。

    

    在许多情况下，机器学习模型可解释性是一项高度要求但难以实现的任务。为了解释这些模型的个体预测，已经提出了本地模型无关方法。然而，产生解释的过程对于用户来说可能与要解释的预测一样神秘。此外，可解释性方法经常缺乏理论保证，并且它们在简单模型上的行为通常是未知的。本文对Anchors（Ribeiro等人，2018）进行理论分析：一种流行的基于规则的可解释性方法，它强调一小组单词以解释文本分类器的决策。

    In many scenarios, the interpretability of machine learning models is a highly required but difficult task. To explain the individual predictions of such models, local model-agnostic approaches have been proposed. However, the process generating the explanations can be, for a user, as mysterious as the prediction to be explained. Furthermore, interpretability methods frequently lack theoretical guarantees, and their behavior on simple models is frequently unknown. While it is difficult, if not impossible, to ensure that an explainer behaves as expected on a cutting-edge model, we can at least ensure that everything works on simple, already interpretable models. In this paper, we present a theoretical analysis of Anchors (Ribeiro et al., 2018): a popular rule-based interpretability method that highlights a small set of words to explain a text classifier's decision. After formalizing its algorithm and providing useful insights, we demonstrate mathematically that Anchors produces meaningf
    
[^3]: 模型选择配合交叉验证风险估计的无分布偏差界学习方法

    Distribution-free Deviation Bounds of Learning via Model Selection with Cross-validation Risk Estimation. (arXiv:2303.08777v1 [stat.ML])

    [http://arxiv.org/abs/2303.08777](http://arxiv.org/abs/2303.08777)

    本文提出通过模型选择和交叉验证风险估计来学习的一般方法，并建立了无分布偏差界，比经验风险最小化方法更紧密，在一些情况下表现更优。

    

    交叉验证方法的风险估计和模型选择在统计学和机器学习中得到了广泛应用。然而，学习通过模型选择与交叉验证风险估计的理论性质的理解在其广泛使用面前相当缺乏。在这个背景下，本文将学习通过模型选择与交叉验证风险估计作为一种经典统计学习理论中的一般系统学习框架，并建立了基于VC维的无分布偏差边界，给出了结果的详细证明，并考虑了有界和无界的损失函数。我们还推导出在整个假设空间中，学习通过模型选择的偏差界比通过经验风险最小化学习的偏差界更紧密的条件，支持在一些情况下经验上观察到的模型选择框架的更好性能。

    Cross-validation techniques for risk estimation and model selection are widely used in statistics and machine learning. However, the understanding of the theoretical properties of learning via model selection with cross-validation risk estimation is quite low in face of its widespread use. In this context, this paper presents learning via model selection with cross-validation risk estimation as a general systematic learning framework within classical statistical learning theory and establishes distribution-free deviation bounds in terms of VC dimension, giving detailed proofs of the results and considering both bounded and unbounded loss functions. We also deduce conditions under which the deviation bounds of learning via model selection are tighter than that of learning via empirical risk minimization in the whole hypotheses space, supporting the better performance of model selection frameworks observed empirically in some instances.
    
[^4]: 针对盆腔疼痛/穿透障碍的基于互联网治疗的个体化预测：多变量决策树模型的开发和内部验证（arXiv：2303.08732v1 [stat.AP]）

    Predicting Individualized Effects of Internet-Based Treatment for Genito-Pelvic Pain/Penetration Disorder: Development and Internal Validation of a Multivariable Decision Tree Model. (arXiv:2303.08732v1 [stat.AP])

    [http://arxiv.org/abs/2303.08732](http://arxiv.org/abs/2303.08732)

    研究开发了一种多变量决策树模型，该模型可预测基于互联网的治疗对盆腔疼痛/穿透障碍患者的症状的多维综合评分的效果。

    

    盆腔疼痛/穿透-障碍（GPPPD）是一种常见的障碍，但在日常护理中很少得到治疗。先前的研究表明，可以使用基于互联网的心理干预有效地治疗GPPPD症状。然而，所有最先进的治疗方法仍然普遍存在未响应的情况，目前尚不清楚哪些患者群体最有望从基于互联网的干预中受益。多变量预测模型越来越多地用于确定异质性治疗效应的预测因子，并分配具有最大预期效益的治疗。在本研究中，我们开发了并内部验证了一种多变量决策树模型，该模型预测基于互联网的治疗对GPPPD症状的多维综合评分的效果。使用一项将基于互联网的干预与等待名单对照组进行比较的随机对照试验的数据（N = 200），利用基于模型的递归分区开发了一种决策树模型。

    Genito-Pelvic Pain/Penetration-Disorder (GPPPD) is a common disorder but rarely treated in routine care. Previous research documents that GPPPD symptoms can be treated effectively using internet-based psychological interventions. However, non-response remains common for all state-of-the-art treatments and it is unclear which patient groups are expected to benefit most from an internet-based intervention. Multivariable prediction models are increasingly used to identify predictors of heterogeneous treatment effects, and to allocate treatments with the greatest expected benefits. In this study, we developed and internally validated a multivariable decision tree model that predicts effects of an internet-based treatment on a multidimensional composite score of GPPPD symptoms. Data of a randomized controlled trial comparing the internet-based intervention to a waitlist control group (N =200) was used to develop a decision tree model using model-based recursive partitioning. Model performan
    
[^5]: 神经网络无监督域适应的泛化保证的实用性研究

    Practicality of generalization guarantees for unsupervised domain adaptation with neural networks. (arXiv:2303.08720v1 [cs.LG])

    [http://arxiv.org/abs/2303.08720](http://arxiv.org/abs/2303.08720)

    研究评估了现有文献中有潜力满足我们要求的域适应图像分类任务的界限，发现所有界限都是空泛的，样本泛化术语占据了观察到的松弛程度的很大部分，特别是当这些术语与域的度量互动时。

    

    理解泛化对于自信地设计和部署机器学习模型至关重要，特别是当部署意味着数据域的转移时。对于这样的域适应问题，我们寻求可计算和紧密的泛化界限。如果可以实现这些要求，这些界限可以作为部署中充足性能的保证。然而，在深度神经网络是首选模型的应用中，推导出满足这些要求的结果仍是一项未解决的挑战；大多数现有的界限要么是空泛的，要么有不可估计的术语，即使在有利条件下也是如此。在本文中，我们评估了现有文献中有潜力满足我们要求的域适应图像分类任务的界限，深度神经网络是首选。我们发现所有界限都是空泛的，并且样本泛化术语占据了观察到的松弛程度的很大部分，特别是当这些术语与域的度量互动时。

    Understanding generalization is crucial to confidently engineer and deploy machine learning models, especially when deployment implies a shift in the data domain. For such domain adaptation problems, we seek generalization bounds which are tractably computable and tight. If these desiderata can be reached, the bounds can serve as guarantees for adequate performance in deployment. However, in applications where deep neural networks are the models of choice, deriving results which fulfill these remains an unresolved challenge; most existing bounds are either vacuous or has non-estimable terms, even in favorable conditions. In this work, we evaluate existing bounds from the literature with potential to satisfy our desiderata on domain adaptation image classification tasks, where deep neural networks are preferred. We find that all bounds are vacuous and that sample generalization terms account for much of the observed looseness, especially when these terms interact with measures of domain
    
[^6]: 从二进制测量中学习信号重构

    Learning to Reconstruct Signals From Binary Measurements. (arXiv:2303.08691v1 [eess.SP])

    [http://arxiv.org/abs/2303.08691](http://arxiv.org/abs/2303.08691)

    该论文提出了一种新的自监督学习方法SSBM，它只需要二进制数据进行训练，并探索了从不完整的二进制观察中学习的极端情况。这为从二进制测量中恢复信号提供了必要和充分条件，并在一系列真实数据集上展示了SSBM的卓越表现。

    

    无监督学习的最新进展突出了仅从噪声和不完整的线性测量中学习信号重构的可能性。这些方法在医学和科学成像以及传感中起到关键作用，其中地面真实数据经常稀缺或难以获得。然而，在实践中，测量不仅噪声和不完整，而且还被量化。在这里，我们探索从二进制观察中学习的极端情况，并提供了关于从不完整二进制数据中识别一组信号所需的测量数量的必要和充分条件。我们的结果是对从二进制测量中信号恢复现有界限的补充。此外，我们引入了一种新颖的自监督学习方法，我们将其命名为“SSBM”，它仅需要二进制数据进行训练。我们在一系列真实数据集上的实验证明SSBM与监督学习相当，并优于稀疏重构方法。

    Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice, measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods wit
    
[^7]: 作为基础模型的超矩形可解释集成模型

    Interpretable Ensembles of Hyper-Rectangles as Base Models. (arXiv:2303.08625v1 [cs.LG])

    [http://arxiv.org/abs/2303.08625](http://arxiv.org/abs/2303.08625)

    本文提出了一种基于超矩形的可解释的集成模型，它将均匀生成的轴对齐超矩形作为基模型，并成功地避免了过拟合。

    

    本文提出了一种基于简单集成模型的新型模型，使用均匀生成的轴对齐超矩形作为基模型（HRBM）。研究了两种类型的HRBM：封闭矩形和角落。HRBM的主要思想是考虑并计算每个矩形内外的训练样例数量。提出将HRBM纳入梯度提升机（GBM）中。尽管HRBM很简单，但这些简单的基础模型允许我们构建有效的集成模型并避免过拟合。考虑了一种计算集成模型的最优正则化参数的简单方法，该方法可以在GBM的每次迭代中以显式方式修改。此外，研究了一种新的正则化，称为“阶梯高度惩罚”，除了标准的L1和L2正则化。提出了一种非常简单的方法来使用著名的SHAP方法对所提出的集成模型预测进行解释。结果显示，G

    A new extremely simple ensemble-based model with the uniformly generated axis-parallel hyper-rectangles as base models (HRBM) is proposed. Two types of HRBMs are studied: closed rectangles and corners. The main idea behind HRBM is to consider and count training examples inside and outside each rectangle. It is proposed to incorporate HRBMs into the gradient boosting machine (GBM). Despite simplicity of HRBMs, it turns out that these simple base models allow us to construct effective ensemble-based models and avoid overfitting. A simple method for calculating optimal regularization parameters of the ensemble-based model, which can be modified in the explicit way at each iteration of GBM, is considered. Moreover, a new regularization called the "step height penalty" is studied in addition to the standard L1 and L2 regularizations. An extremely simple approach to the proposed ensemble-based model prediction interpretation by using the well-known method SHAP is proposed. It is shown that G
    
[^8]: 零样本对比损失用于文本引导扩散图像风格迁移

    Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer. (arXiv:2303.08622v1 [cs.CV])

    [http://arxiv.org/abs/2303.08622](http://arxiv.org/abs/2303.08622)

    本文提出了一种适用于文本引导图像风格迁移中的零样本对比损失方法，可以在不需要额外训练的情况下生成具有相同语义内容的图像。

    

    扩散模型在文本引导图像风格迁移中表现出极大的潜力，但由于其随机性而存在风格转换和内容保护之间的权衡。现有方法需要计算密集的扩散模型微调或附加神经网络。为了解决这个问题，我们在扩散模型中提出了一种零样本对比损失，它不需要额外的微调或辅助网络。通过利用预训练的扩散模型中生成样本和原始图像嵌入之间的图块对比损失，我们的方法可以以零样本的方式生成具有与源图像相同语义内容的图像。我们的方法在保留内容且不需要额外训练的同时，在图像风格迁移、图像到图像的转换和操作中均优于现有方法。我们的实验结果证实了我们提出的方法的有效性。

    Diffusion models have shown great promise in text-guided image style transfer, but there is a trade-off between style transformation and content preservation due to their stochastic nature. Existing methods require computationally expensive fine-tuning of diffusion models or additional neural network. To address this, here we propose a zero-shot contrastive loss for diffusion models that doesn't require additional fine-tuning or auxiliary networks. By leveraging patch-wise contrastive loss between generated samples and original image embeddings in the pre-trained diffusion model, our method can generate images with the same semantic content as the source image in a zero-shot manner. Our approach outperforms existing methods while preserving content and requiring no additional training, not only for image style transfer but also for image-to-image translation and manipulation. Our experimental results validate the effectiveness of our proposed method.
    
[^9]: 学习奖励信息获取：正确计分规则遇到委托代理模型

    Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model. (arXiv:2303.08613v1 [cs.LG])

    [http://arxiv.org/abs/2303.08613](http://arxiv.org/abs/2303.08613)

    本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。

    

    本文研究委托代理模型中的激励信息获取问题。此问题被建模为委托方和代理方之间的 Stackelberg 博弈，其中委托人宣布了一条得分规则来指定付款，然后代理方选择最大化其自身利润和报告信息的努力水平。我们从委托方的角度研究这个问题的在线设置，即通过与策略代理多次交互来设计最优计分规则。我们设计了一种可证明的样本高效算法，将 UCB 算法 (Auer et al., 2002) 量身定制到我们的模型中，其在 T 次迭代后实现了次线性 $T^{2/3}$-遗憾。我们的算法具有对委托方最优利润进行精细估计的过程以及保守纠正方案，以确保代理方的行动得到有效激励。此外，我们的遗憾界的一个关键特征是它是渐进最小可实现的。

    We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a sublinear $T^{2/3}$-regret after $T$ iterations. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is i
    
[^10]: Delay-SDE-net：一种用于具有记忆和不确定性估计的时间序列建模的深度学习方法

    Delay-SDE-net: A deep learning approach for time series modelling with memory and uncertainty estimates. (arXiv:2303.08587v1 [cs.LG])

    [http://arxiv.org/abs/2303.08587](http://arxiv.org/abs/2303.08587)

    本研究提出了一种基于随机延迟微分方程的神经网络模型Delay-SDE-net，可以准确地建模具有记忆效应的时间序列，并且能够对模型的不确定性进行实时估计。

    

    在许多领域中，准确地建模时间序列非常重要。由于世界通常过于复杂以至无法准确地建模，因此评估动态系统处于特定状态的概率常常有意义。本文提出了Delay-SDE-net，这是一种基于随机延迟微分方程（SDDEs）的神经网络模型。使用具有多个延迟的SDDE作为建模框架，使其成为具有记忆效应的时间序列的合适模型，因为它通过系统之前的状态包括记忆。 Delay-SDE-net的随机部分提供了估计建模中不确定性的基础，并被分成两个神经网络以解释先验性和后验性不确定性。这种不确定性是实时提供的，使得该模型适用于时间匮乏的应用。我们推导了Delay-SDE-net的理论误差，并进行了数值收敛率分析。在与类似模型的比较中，Delay-SDE-net显示出更加稳定的性能。

    To model time series accurately is important within a wide range of fields. As the world is generally too complex to be modelled exactly, it is often meaningful to assess the probability of a dynamical system to be in a specific state. This paper presents the Delay-SDE-net, a neural network model based on stochastic delay differential equations (SDDEs). The use of SDDEs with multiple delays as modelling framework makes it a suitable model for time series with memory effects, as it includes memory through previous states of the system. The stochastic part of the Delay-SDE-net provides a basis for estimating uncertainty in modelling, and is split into two neural networks to account for aleatoric and epistemic uncertainty. The uncertainty is provided instantly, making the model suitable for applications where time is sparse. We derive the theoretical error of the Delay-SDE-net and analyze the convergence rate numerically. At comparisons with similar models, the Delay-SDE-net has consisten
    
[^11]: 应用于持续图的测度统计学习

    Statistical learning on measures: an application to persistence diagrams. (arXiv:2303.08456v1 [cs.CG])

    [http://arxiv.org/abs/2303.08456](http://arxiv.org/abs/2303.08456)

    本文提出了一个新的统计学习框架，用于处理紧致空间上的测度数据，并且向我们展示了如何使用拓扑信息进行分类。

    

    我们考虑了一个二元有监督学习分类问题，其中我们观察到紧致空间 $\mathcal{X}$ 上的测度，而不是在有限维欧几里得空间中观察到数据。更具体地说，我们观察到数据 $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ ，其中 $\mu_i$ 是 $\mathcal{X}$ 上的测度， $Y_i$ 是 $0$ 或 $1$ 中的标签。对于 $\mathcal{X}$ 上的基分类器的集合 $\mathcal{F}$ ，我们在测度空间中构建相应的分类器。我们提供了这种新分类器类的 Rademacher 复杂性的上下界，它可以简单地用 $\mathcal{F}$ 类相关量来表达。如果 $\mu_i$ 是有限集上的均匀分布，那么这个分类任务就会变成一个多实例学习问题。但是，我们的方法允许我们处理更具有灵活性和多样性的输入数据。虽然这种框架有许多可能的应用，但本文强调通过拓扑数据进行分类。

    We consider a binary supervised learning classification problem where instead of having data in a finite-dimensional Euclidean space, we observe measures on a compact space $\mathcal{X}$. Formally, we observe data $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ where $\mu_i$ is a measure on $\mathcal{X}$ and $Y_i$ is a label in $\{0, 1\}$. Given a set $\mathcal{F}$ of base-classifiers on $\mathcal{X}$, we build corresponding classifiers in the space of measures. We provide upper and lower bounds on the Rademacher complexity of this new class of classifiers that can be expressed simply in terms of corresponding quantities for the class $\mathcal{F}$. If the measures $\mu_i$ are uniform over a finite set, this classification task boils down to a multi-instance learning problem. However, our approach allows more flexibility and diversity in the input data we can deal with. While such a framework has many possible applications, this work strongly emphasizes on classifying data via topological d
    
[^12]: 混合数据增强方法Mixup对于特征学习的益处

    The Benefits of Mixup for Feature Learning. (arXiv:2303.08433v1 [cs.LG])

    [http://arxiv.org/abs/2303.08433](http://arxiv.org/abs/2303.08433)

    本论文介绍了数据增强方法Mixup对于特征学习的益处。混合训练可以有效地从混合数据中学习罕见特征，相比之下，标准训练可能会漏掉这些罕见特征。

    

    Mixup是一种简单的数据增强方法，通过线性插值随机混合两个数据点，已广泛应用于各种深度学习应用中，以获得更好的泛化效果。然而，其有效性的理论基础尚未完全被理解。本文旨在寻求对Mixup益处的基本理解。首先，我们展示Mixup在特征和标签使用不同的线性插值参数时仍可实现类似于标准Mixup的性能。这表明，Zhang等人（2018）提出的直观线性解释可能并不能完全解释Mixup的成功。然后，我们从特征学习的角度对Mixup进行理论研究。我们考虑一个特征噪声数据模型，并展示Mixup训练可以有效地从其与常见特征（出现在大部分数据中）混合中学习罕见特征（出现在少部分数据中）。相比之下，标准训练可能会漏掉这些罕见特征。

    Mixup, a simple data augmentation method that randomly mixes two data points via linear interpolation, has been extensively applied in various deep learning applications to gain better generalization. However, the theoretical underpinnings of its efficacy are not yet fully understood. In this paper, we aim to seek a fundamental understanding of the benefits of Mixup. We first show that Mixup using different linear interpolation parameters for features and labels can still achieve similar performance to the standard Mixup. This indicates that the intuitive linearity explanation in Zhang et al., (2018) may not fully explain the success of Mixup. Then we perform a theoretical study of Mixup from the feature learning perspective. We consider a feature-noise data model and show that Mixup training can effectively learn the rare features (appearing in a small fraction of data) from its mixture with the common features (appearing in a large fraction of data). In contrast, standard training ca
    
[^13]: 政策梯度算法收敛于几乎线性二次型调节器的全局最优策略

    Policy Gradient Converges to the Globally Optimal Policy for Nearly Linear-Quadratic Regulators. (arXiv:2303.08431v1 [cs.LG])

    [http://arxiv.org/abs/2303.08431](http://arxiv.org/abs/2303.08431)

    本论文研究了强化学习方法在几乎线性二次型调节器系统中找到最优策略的问题，提出了一个策略梯度算法，可以以线性速率收敛于全局最优解。

    

    决策者只获得了非完整信息的非线性控制系统在各种应用中普遍存在。本研究探索了强化学习方法，以找到几乎线性二次型调节器系统中最优策略。我们考虑一个动态系统，结合线性和非线性组成部分，并由相同结构的策略进行管理。在假设非线性组成部分包含具有小型Lipschitz系数的内核的情况下，我们对成本函数的优化进行了表征。虽然成本函数通常是非凸的，但我们确立了全局最优解附近局部的强凸性和光滑性。此外，我们提出了一种初始化机制，以利用这些属性。在此基础上，我们设计了一个策略梯度算法，可以保证以线性速率收敛于全局最优解。

    Nonlinear control systems with partial information to the decision maker are prevalent in a variety of applications. As a step toward studying such nonlinear systems, this work explores reinforcement learning methods for finding the optimal policy in the nearly linear-quadratic regulator systems. In particular, we consider a dynamic system that combines linear and nonlinear components, and is governed by a policy with the same structure. Assuming that the nonlinear component comprises kernels with small Lipschitz coefficients, we characterize the optimization landscape of the cost function. Although the cost function is nonconvex in general, we establish the local strong convexity and smoothness in the vicinity of the global optimizer. Additionally, we propose an initialization mechanism to leverage these properties. Building on the developments, we design a policy gradient algorithm that is guaranteed to converge to the globally optimal policy with a linear rate.
    
[^14]: 多维流式时间序列的最优抽样设计及在电力系统监测中的应用

    Optimal Sampling Designs for Multi-dimensional Streaming Time Series with Application to Power Grid Sensor Data. (arXiv:2303.08242v1 [stat.ML])

    [http://arxiv.org/abs/2303.08242](http://arxiv.org/abs/2303.08242)

    本文提出针对多维流式时间序列的最优抽样设计方法，并应用于高速电力消耗数据的低成本实时分析，提高了计算效率。

    

    物联网系统产生了大量高速时间相关的流式数据，并经常与计算或能源约束下的在线推断任务相连。对这些流式时间序列数据的在线分析经常面临统计效率和计算成本之间的权衡。解决这种权衡的一个重要方法是抽样，仅选择一小部分样本进行模型拟合和更新。为了满足物联网系统动态关系分析的需求，本文研究了面向多维流式时间序列的数据依赖抽样选择和在线推断问题，旨在提供高速电力消耗数据的低成本实时分析。受实验设计中D-效应准则的启发，我们提出了一类在线数据缩减方法，实现了最优抽样准则，并提高了在线分析的计算效率。我们展示了...

    The Internet of Things (IoT) system generates massive high-speed temporally correlated streaming data and is often connected with online inference tasks under computational or energy constraints. Online analysis of these streaming time series data often faces a trade-off between statistical efficiency and computational cost. One important approach to balance this trade-off is sampling, where only a small portion of the sample is selected for the model fitting and update. Motivated by the demands of dynamic relationship analysis of IoT system, we study the data-dependent sample selection and online inference problem for a multi-dimensional streaming time series, aiming to provide low-cost real-time analysis of high-speed power grid electricity consumption data. Inspired by D-optimality criterion in design of experiments, we propose a class of online data reduction methods that achieve an optimal sampling criterion and improve the computational efficiency of the online analysis. We show 
    
[^15]: 基于Beta-Bernoulli过程和深度神经网络的贝叶斯稀疏编码

    Bayesian Beta-Bernoulli Process Sparse Coding with Deep Neural Networks. (arXiv:2303.08230v1 [cs.LG])

    [http://arxiv.org/abs/2303.08230](http://arxiv.org/abs/2303.08230)

    本文提出了一种基于Beta-Bernoulli过程和非参数迭代算法的深度稀疏编码模型，旨在学习具有尺度不变性的离散特征，并鼓励表示的稀疏性。

    

    针对深度离散潜变量模型，已经提出了几种近似推断方法。然而，在经典稀疏编码模型中成功应用的非参数方法，在深度模型的上下文中很少被探索。我们提出了一种非参数迭代算法，用于学习此类深度模型中的离散潜在表示。此外，为了学习具有尺度不变性的离散特征，我们提出了本地数据缩放变量。最后，为了在我们的表示中鼓励稀疏性，我们在潜在因子上提出了Beta-Bernoulli过程先验。我们对耦合不同似然模型的稀疏编码模型进行了评估。我们在具有不同特征的数据集上评估我们的方法，并将结果与当前的摊销近似推断方法进行比较。

    Several approximate inference methods have been proposed for deep discrete latent variable models. However, non-parametric methods which have previously been successfully employed for classical sparse coding models have largely been unexplored in the context of deep models. We propose a non-parametric iterative algorithm for learning discrete latent representations in such deep models. Additionally, to learn scale invariant discrete features, we propose local data scaling variables. Lastly, to encourage sparsity in our representations, we propose a Beta-Bernoulli process prior on the latent factors. We evaluate our spare coding model coupled with different likelihood models. We evaluate our method across datasets with varying characteristics and compare our results to current amortized approximate inference methods.
    
[^16]: 基于信息理论的固定专家建议下赌博机的遗憾界限

    Information-Theoretic Regret Bounds for Bandits with Fixed Expert Advice. (arXiv:2303.08102v1 [cs.LG])

    [http://arxiv.org/abs/2303.08102](http://arxiv.org/abs/2303.08102)

    本文研究固定专家建议下的赌博机问题，提出了基于信息论的遗憾界限，可以使得某些算法的遗憾无限接近于零。此外，我们还提出了KL散度来描述专家之间的相似性界限，并给出了下限证明算法的最优性。

    

    本文研究了在专家是固定和已知的情况下，赌博机与专家建议的问题，这些专家是行动固定和已知分布。相比以前的分析，我们展示了这种情况下遗憾是由衡量专家之间相似性的信息论量所控制的。在一些自然特殊情况下，这使我们能够获得EXP4的第一个遗憾界限，如果专家足够相似，则可以无限接近于零。为另一种算法提供了可以用KL散度来描述专家之间相似性的另一种界限，并且在某些情况下，我们展示了这个界限可以比EXP4更小。此外，我们为某些专家类别提供了下限，展示了我们分析的算法在某些情况下是几乎最优的。

    We investigate the problem of bandits with expert advice when the experts are fixed and known distributions over the actions. Improving on previous analyses, we show that the regret in this setting is controlled by information-theoretic quantities that measure the similarity between experts. In some natural special cases, this allows us to obtain the first regret bound for EXP4 that can get arbitrarily close to zero if the experts are similar enough. While for a different algorithm, we provide another bound that describes the similarity between the experts in terms of the KL-divergence, and we show that this bound can be smaller than the one of EXP4 in some cases. Additionally, we provide lower bounds for certain classes of experts showing that the algorithms we analyzed are nearly optimal in some cases.
    
[^17]: 元学习控制变量：有限数据中方差缩减的方法

    Meta-learning Control Variates: Variance Reduction with Limited Data. (arXiv:2303.04756v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2303.04756](http://arxiv.org/abs/2303.04756)

    该论文提出了一种元学习控制变量的方法，可在有限数据的情况下减小蒙特卡罗估计器的方差，并对多个任务进行处理。

    

    控制变量是减小蒙特卡罗估计器方差的有力工具，但在样本数量较小的情况下构建有效的控制变量可能具有挑战性。本文表明，当需要计算大量相关积分时，即使每个任务的样本数很少，也可以利用这些积分任务之间的相似性来提高性能。我们所提出的元学习CV（Meta-CVs）方法可用于处理数百个或数千个任务，并通过实证评估表明，在这种情况下，Meta-CVs可以显著减小方差。我们的理论分析确定了Meta-CVs成功训练的一般条件。

    Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained.
    
[^18]: 带有双向先验模型的向量量化时间序列生成

    Vector Quantized Time Series Generation with a Bidirectional Prior Model. (arXiv:2303.04743v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04743](http://arxiv.org/abs/2303.04743)

    本文提出了一种新的时间序列生成方法，使用向量量化技术和双向变压器模型来生成质量更好、模块化变化更快的合成信号。

    

    时间序列生成研究主要集中在使用生成对抗网络（GAN）与递归神经网络（RNN）变体相结合。然而，训练 GAN 的基本限制和挑战仍然存在。此外，RNN族通常在远程时间步之间的时间一致性方面存在困难。受到图像生成领域成功的启发，我们提出 TimeVQVAE，这是我们所知道的第一个使用向量量化（VQ）技术解决 TSG 问题的工作。此外，离散潜在空间的先验使用双向变压器模型进行学习，可以更好地捕捉全局时间一致性。我们还提出在时间 - 频率域中进行 VQ 建模，分为低频（LF）和高频（HF）。这使我们能够保留时间序列的重要特征，并生成质量更好、模块性变化更快的新合成信号。

    Time series generation (TSG) studies have mainly focused on the use of Generative Adversarial Networks (GANs) combined with recurrent neural network (RNN) variants. However, the fundamental limitations and challenges of training GANs still remain. In addition, the RNN-family typically has difficulties with temporal consistency between distant timesteps. Motivated by the successes in the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our knowledge, that uses vector quantization (VQ) techniques to address the TSG problem. Moreover, the priors of the discrete latent spaces are learned with bidirectional transformer models that can better capture global temporal consistency. We also propose VQ modeling in a time-frequency domain, separated into low-frequency (LF) and high-frequency (HF). This allows us to retain important characteristics of the time series and, in turn, generate new synthetic signals that are of better quality, with sharper changes in modularity, t
    
[^19]: 带有Fisher线性判别分析的近似最优领域自适应

    Approximately optimal domain adaptation with Fisher's Linear Discriminant Analysis. (arXiv:2302.14186v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2302.14186](http://arxiv.org/abs/2302.14186)

    本文提出了一种基于Fisher线性判别的领域自适应模型，该模型是两个假设的凸组合，可以在不访问任何单个源任务的直接信息的情况下计算最优分类器，并在基于EEG和ECG的分类设置中展示了其有效性。

    

    我们提出了一类基于Fisher线性判别（FLD）的模型，用于领域自适应。该类模型是两个假设的凸组合：i）代表先前看到的源任务的平均假设和ii）在新的目标任务上训练的假设。对于特定的生成设置，我们在0-1损失下导出了两种模型的最优凸组合，提出了一种可计算的逼近，并研究了各种参数设置对最优假设、假设i）和假设ii）之间相对风险的影响。我们展示了所提出的最优分类器在基于EEG和ECG的分类设置中的有效性，并认为可以在不访问任何单个源任务的直接信息的情况下计算最优分类器。最后我们讨论了进一步的应用、限制和可能的未来方向。

    We propose a class of models based on Fisher's Linear Discriminant (FLD) in the context of domain adaptation. The class is the convex combination of two hypotheses: i) an average hypothesis representing previously seen source tasks and ii) a hypothesis trained on a new target task. For a particular generative setting we derive the optimal convex combination of the two models under 0-1 loss, propose a computable approximation, and study the effect of various parameter settings on the relative risks between the optimal hypothesis, hypothesis i), and hypothesis ii). We demonstrate the effectiveness of the proposed optimal classifier in the context of EEG- and ECG-based classification settings and argue that the optimal classifier can be computed without access to direct information from any of the individual source tasks. We conclude by discussing further applications, limitations, and possible future directions.
    
[^20]: 核岭回归下伪标签的协变量转移策略

    Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift. (arXiv:2302.10160v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2302.10160](http://arxiv.org/abs/2302.10160)

    该论文提出了一种关于核岭回归的协变量转移策略，通过使用伪标签进行模型选择，能够适应不同特征分布下的学习，实现均方误差最小化。

    

    我们提出并分析了一种基于协变量转移的核岭回归方法。我们的目标是在目标分布上学习一个均方误差最小的回归函数，基于从目标分布采样的未标记数据和可能具有不同特征分布的已标记数据。我们将已标记数据分成两个子集，并分别进行核岭回归，以获得候选模型集合和一个填充模型。我们使用后者填充缺失的标签，然后相应地选择最佳的候选模型。我们的非渐近性过量风险界表明，在相当一般的情况下，我们的估计器能够适应目标分布以及协变量转移的结构。它能够实现渐近正态误差率直到对数因子的最小极限优化。在模型选择中使用伪标签不会产生主要负面影响。

    We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate model accordingly. Our non-asymptotic excess risk bounds show that in quite general scenarios, our estimator adapts to the structure of the target distribution as well as the covariate shift. It achieves the minimax optimal error rate up to a logarithmic factor. The use of pseudo-labels in model selection does not have major negative impacts.
    
[^21]: 理解多模式对比学习及整合非配对数据

    Understanding Multimodal Contrastive Learning and Incorporating Unpaired Data. (arXiv:2302.06232v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06232](http://arxiv.org/abs/2302.06232)

    本论文研究了一般类的非线性损失函数进行多模式对比学习，揭示了其与奇异值分解的联系。并证明在错误匹配的情况下，多模式对比学习可以比单模式对比学习表现更佳，表现了其对嘈杂数据的鲁棒性。

    

    最近，语言监督的视觉模型在计算机视觉领域引起了广泛关注。构建这种模型的常见方法是使用对比学习方法在两种模态之间对配对数据进行学习，例如对比语言 - 图像预训练（CLIP）。在这篇论文中，我们在线性表示设置下，（i）启动了一个关于多模式对比学习（MMCL）的一般非线性Loss函数的调查，包括CLIP Loss，并展示了它与奇异值分解（SVD）之间的联系。即，我们展示了梯度下降每一步Loss最小化可以被视为对一个对比性协方差矩阵进行SVD。基于这个洞察，（ii）我们分析了MMCL的性能。我们定量地表明，在错误匹配的情况下，MMCL的特征学习能力可以比单模式对比学习应用于每种模式更好。这表征了MMCL对嘈杂数据的鲁棒性。

    Language-supervised vision models have recently attracted great attention in computer vision. A common approach to build such models is to use contrastive learning on paired data across the two modalities, as exemplified by Contrastive Language-Image Pre-Training (CLIP). In this paper, under linear representation settings, (i) we initiate the investigation of a general class of nonlinear loss functions for multimodal contrastive learning (MMCL) including CLIP loss and show its connection to singular value decomposition (SVD). Namely, we show that each step of loss minimization by gradient descent can be seen as performing SVD on a contrastive cross-covariance matrix. Based on this insight, (ii) we analyze the performance of MMCL. We quantitatively show that the feature learning ability of MMCL can be better than that of unimodal contrastive learning applied to each modality even under the presence of wrongly matched pairs. This characterizes the robustness of MMCL to noisy data. Furthe
    
[^22]: 鲁棒的在线主动学习策略

    Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00422](http://arxiv.org/abs/2302.00422)

    本文提出了一种自适应方法，用于鲁棒的在线主动学习，并在受污染的数据流中证明了其性能表现优异，同时确保了稳定性并减少异常值的负面影响。

    

    在许多工业应用中，获得标记的观测数据并不简单，通常需要人工专家干预或使用昂贵的测试设备。在这种情况下，主动学习可以大大提高拟合模型时最信息数据点的建议。减少模型开发所需的观测数据数量可以减轻训练所需的计算负担和标记相关的操作支出。特别是在线主动学习，在需要在极短时间内决定是否获取数据点标记的高容量生产过程中非常有用。然而，尽管最近致力于开发在线主动学习策略，但在存在异常值的情况下这些方法的行为仍未得到彻底研究。在这项工作中，我们调查了在线主动线性回归在受污染的数据流中的性能，并提出了一种自适应方法，用于鲁棒的在线主动学习，同时保证稳定性并减少异常值的负面影响。

    In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
    
[^23]: 使用半监督自编码器的在线主动学习进行软测量开发

    Online Active Learning for Soft Sensor Development using Semi-Supervised Autoencoders. (arXiv:2212.13067v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13067](http://arxiv.org/abs/2212.13067)

    本文介绍了一种使用半监督自编码器以及在线主动学习方法，以尽可能少的标记样本来开发软测量传感器，从而显著降低了成本。在实验中，作者表明这种方法能够取得好的预测效果。

    

    数据驱动的软测量在工业和化学过程中被广泛使用，以预测难以测量的过程变量。这些传感器使用的回归模型通常需要大量标记的样本，然而，由于质量检查需要高昂的时间和成本，获取标签信息可能非常昂贵。在这种情况下，主动学习方法可能非常有益，因为它们可以建议查询最具信息量的标签。然而，为回归提出的大多数主动学习策略都集中在离线场景。本文将其中一些方法适应于流式场景，并展示了如何使用基于正交自编码器的半监督架构学习低维空间中的显著特征。我们也演示了如何使用田纳西东曼过程比较预测结果。

    Data-driven soft sensors are extensively used in industrial and chemical processes to predict hard-to-measure process variables whose real value is difficult to track during routine operations. The regression models used by these sensors often require a large number of labeled examples, yet obtaining the label information can be very expensive given the high time and cost required by quality inspections. In this context, active learning methods can be highly beneficial as they can suggest the most informative labels to query. However, most of the active learning strategies proposed for regression focus on the offline setting. In this work, we adapt some of these approaches to the stream-based scenario and show how they can be used to select the most informative data points. We also demonstrate how to use a semi-supervised architecture based on orthogonal autoencoders to learn salient features in a lower dimensional space. The Tennessee Eastman Process is used to compare the predictive 
    
[^24]: 无交叠策略学习：悲观和广义经验Bernstein不等式

    Policy learning "without'' overlap: Pessimism and generalized empirical Bernstein's inequality. (arXiv:2212.09900v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.09900](http://arxiv.org/abs/2212.09900)

    本文提出了一种新的离线策略学习算法，它不需要统一交叠假设，而是利用价值的下限置信区间（LCBs）优化策略，因此能够适应允许行为策略演变和倾向性减弱的情况。

    

    本文研究了离线策略学习，旨在利用先前收集到的观测（来自于固定的或是适应演变的行为策略）来学习给定类别中的最优个性化决策规则。现有的策略学习方法依赖于一个统一交叠假设，即离线数据集中探索所有个性化特征的所有动作的倾向性下界。换句话说，这些方法的性能取决于离线数据集中最坏的倾向性。由于数据收集过程不受控制，在许多情况下，这种假设可能不太现实，特别是当允许行为策略随时间演变并且倾向性减弱时。为此，本文提出了一种新的算法，它优化策略价值的下限置信区间（LCBs）——而不是点估计。LCBs通过量化增强倒数倾向权重的估计不确定性来构建。

    This paper studies offline policy learning, which aims at utilizing observations collected a priori (from either fixed or adaptively evolving behavior policies) to learn the optimal individualized decision rule in a given class. Existing policy learning methods rely on a uniform overlap assumption, i.e., the propensities of exploring all actions for all individual characteristics are lower bounded in the offline dataset. In other words, the performance of these methods depends on the worst-case propensity in the offline dataset. As one has no control over the data collection process, this assumption can be unrealistic in many situations, especially when the behavior policies are allowed to evolve over time with diminishing propensities.  In this paper, we propose a new algorithm that optimizes lower confidence bounds (LCBs) -- instead of point estimates -- of the policy values. The LCBs are constructed by quantifying the estimation uncertainty of the augmented inverse propensity weight
    
[^25]: 循环神经网络和贝叶斯滤波器的通用逼近性

    Recurrent Neural Networks and Universal Approximation of Bayesian Filters. (arXiv:2211.00335v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.00335](http://arxiv.org/abs/2211.00335)

    本文提出一个循环神经网络框架，用于直接从观测输入到所需的估计器统计量学习递归映射，可以近似估计潜在时间序列信号的条件统计量，在非紧致域中有误差界限，在长时间上有良好性能。

    

    本文考虑贝叶斯最优滤波问题，即从观测序列中估计潜在时间序列信号的条件统计量。传统方法通常依赖于假定或估计的转移和观测模型。相反，我们制定了一个通用的循环神经网络框架，并试图直接从观测输入到所需的估计器统计量学习递归映射。本文的重点是此框架的逼近能力。我们提供了一般非紧致域的滤波逼近误差界限。我们还考虑了强时间一致的逼近误差界限，保证良好的长期性能。我们讨论和说明了这些结果的许多实际关注点和影响。

    We consider the Bayesian optimal filtering problem: i.e. estimating some conditional statistics of a latent time-series signal from an observation sequence. Classical approaches often rely on the use of assumed or estimated transition and observation models. Instead, we formulate a generic recurrent neural network framework and seek to learn directly a recursive mapping from observational inputs to the desired estimator statistics. The main focus of this article is the approximation capabilities of this framework. We provide approximation error bounds for filtering in general non-compact domains. We also consider strong time-uniform approximation error bounds that guarantee good long-time performance. We discuss and illustrate a number of practical concerns and implications of these results.
    
[^26]: 训练神经网络用于时序变点检测

    Training Neural Networks for Sequential Change-point Detection. (arXiv:2210.17312v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17312](http://arxiv.org/abs/2210.17312)

    本文介绍了一种使用神经网络进行在线变点检测的方法，通过训练神经网络逐步计算检测统计量的累积和来检测变点，并在合成和真实数据上证明了该方法的优越性和潜力。

    

    检测数据流中的突变分布转换，即所谓的变点检测，是统计学和机器学习中的一个基本问题。我们引入了一种新颖的方法，使用神经网络进行在线变点检测。具体而言，我们的方法是训练神经网络来逐步计算检测统计量的累积和，当发生变点时，该量会显著变化。我们使用合成和真实世界数据证明了所提出的方法在检测变点方面的优越性和潜力。

    Detecting an abrupt distributional shift of a data stream, known as change-point detection, is a fundamental problem in statistics and machine learning. We introduce a novel approach for online change-point detection using neural networks. To be specific, our approach is training neural networks to compute the cumulative sum of a detection statistic sequentially, which exhibits a significant change when a change-point occurs. We demonstrated the superiority and potential of the proposed method in detecting change-point using both synthetic and real-world data.
    
[^27]: 基于梯度门控机制的图深度多速率学习

    Gradient Gating for Deep Multi-Rate Learning on Graphs. (arXiv:2210.00513v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00513](http://arxiv.org/abs/2210.00513)

    G2是一种利用梯度门控机制的新型GNN框架，可缓解过度平滑问题，并实现了各种图学习任务上的最先进性能。

    

    我们提出了一种名为 Gradient Gating (G$^2$) 的新型框架，旨在改善图神经网络 (GNNs) 的性能。我们的框架基于对 GNN 层的输出进行门控，其中包含了一种跨本质图节点的消息传递信息的多速率流机制。本地梯度被利用来进一步调制消息传递的更新。我们的框架可以灵活地允许使用任何基本的 GNN 层作为包装器，以构建多速率梯度门控机制。我们严格证明 G$^2$ 缓解了过度平滑问题，并允许设计深度 GNNs。我们展示了实证结果，证明所提出的框架在各种图学习任务上实现了最先进的性能，包括大规模异质图上的任务。

    We present Gradient Gating (G$^2$), a novel framework for improving the performance of Graph Neural Networks (GNNs). Our framework is based on gating the output of GNN layers with a mechanism for multi-rate flow of message passing information across nodes of the underlying graph. Local gradients are harnessed to further modulate message passing updates. Our framework flexibly allows one to use any basic GNN layer as a wrapper around which the multi-rate gradient gating mechanism is built. We rigorously prove that G$^2$ alleviates the oversmoothing problem and allows the design of deep GNNs. Empirical results are presented to demonstrate that the proposed framework achieves state-of-the-art performance on a variety of graph learning tasks, including on large-scale heterophilic graphs.
    
[^28]: 广义核正则化最小二乘法

    Generalized Kernel Regularized Least Squares. (arXiv:2209.14355v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.14355](http://arxiv.org/abs/2209.14355)

    本论文提出了广义核正则化最小二乘法 (gKRLS)，解决了核正则化最小二乘法 (KRLS) 在当前使用中的两个限制：它的扩展能力不足，且即使在小规模数据集上，其计算代价也非常高昂。

    

    核正则化最小二乘法 (KRLS) 是一种流行的方法，用于灵活地估计具有复杂变量关系的模型。然而，其可用性因两个原因而受到许多研究人员的限制。首先，现有方法缺乏灵活性，不允许将KRLS与理论动机下的扩展如随机效应、未经正则化的固定效应或非高斯结果组合使用。其次，即使是规模较小的数据集，估计也非常计算密集。本文通过引入广义KRLS (gKRLS) 来解决这两个问题。我们指出，KRLS可以重新设定为分层模型，从而允许轻松推理和模块化模型构建，在其中KRLS可以与随机效应、样条和未经正则化的固定效应并用。在计算方面，我们还实现了随机草图方法，以极大地加速估计，并在估计质量上承担有限的惩罚。我们证明gKRLS可适用于具有大量样本的数据集的拟合。

    Kernel Regularized Least Squares (KRLS) is a popular method for flexibly estimating models that may have complex relationships between variables. However, its usefulness to many researchers is limited for two reasons. First, existing approaches are inflexible and do not allow KRLS to be combined with theoretically-motivated extensions such as random effects, unregularized fixed effects, or non-Gaussian outcomes. Second, estimation is extremely computationally intensive for even modestly sized datasets. Our paper addresses both concerns by introducing generalized KRLS (gKRLS). We note that KRLS can be re-formulated as a hierarchical model thereby allowing easy inference and modular model construction where KRLS can be used alongside random effects, splines, and unregularized fixed effects. Computationally, we also implement random sketching to dramatically accelerate estimation while incurring a limited penalty in estimation quality. We demonstrate that gKRLS can be fit on datasets with
    
[^29]: 在错误标记的网络顶点存在的情况下进行功耗测试

    Lost in the Shuffle: Testing Power in the Presence of Errorful Network Vertex Labels. (arXiv:2208.08638v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2208.08638](http://arxiv.org/abs/2208.08638)

    研究了当网络中存在不匹配/标签混乱的顶点时，两个样本图假设检验中的功率损失，并通过多个实验加以验证。

    

    许多两个样本的网络假设检验方法都是在顶点对应在网络之间的隐含假设下运行的。在本文中，我们考虑了当网络中存在不匹配/标签混乱的顶点时，两个样本图假设检验中的功率损失。在随机点乘积和随机块模型网络的背景下，我们在理论上探讨了由于混洗对基于估计的边缘概率矩阵或邻接矩阵之间的Frobenius范数差异的一对假设检验的功率损失。功耗测试的损失通过众多模拟和实验进一步加强，在文献中比较了多个最近提出的测试中的功率损失，在随机块模型和随机点乘积图模型中均有体现。最后，我们通过来自神经科学和社交网络分析的两个例子展示了混洗可能对真实数据测试的影响。

    Many two-sample network hypothesis testing methodologies operate under the implicit assumption that the vertex correspondence across networks is a priori known. In this paper, we consider the degradation of power in two-sample graph hypothesis testing when there are misaligned/label-shuffled vertices across networks. In the context of random dot product and stochastic block model networks, we theoretically explore the power loss due to shuffling for a pair of hypothesis tests based on Frobenius norm differences between estimated edge probability matrices or between adjacency matrices. The loss in testing power is further reinforced by numerous simulations and experiments, both in the stochastic block model and in the random dot product graph model, where we compare the power loss across multiple recently proposed tests in the literature. Lastly, we demonstrate the impact that shuffling can have in real-data testing in a pair of examples from neuroscience and from social network analysi
    
[^30]: 计数时间序列的概率调和

    Probabilistic Reconciliation of Count Time Series. (arXiv:2207.09322v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2207.09322](http://arxiv.org/abs/2207.09322)

    本文提出了一种新的概率计数时间序列调和方法，产生协调的概率质量函数，相比于概率高斯调和，能够带来显著的预测改进。

    

    预测调和是一个重要的研究课题，但目前既没有形式化的框架，也没有针对概率计数时间序列调和的实用方法。在本文中，我们提出了一种适用于实值和计数变量的连贯性和协调的概率预测定义，同时提出了一种新的概率协调方法。它是基于贝叶斯规则的概括，并且可以协调实数和计数变量。当用于计数变量时，它会产生协调的概率质量函数。我们通过对计数变量的时间协调实验表明，与概率高斯调和相比，它对预测的改进非常大。

    Forecast reconciliation is an important research topic. Yet, there is currently neither formal framework nor practical method for the probabilistic reconciliation of count time series. In this paper we propose a definition of coherency and reconciled probabilistic forecast which applies to both real-valued and count variables and a novel method for probabilistic reconciliation. It is based on a generalization of Bayes' rule and it can reconcile both real-value and count variables. When applied to count variables, it yields a reconciled probability mass function. Our experiments with the temporal reconciliation of count variables show a major forecast improvement compared to the probabilistic Gaussian reconciliation.
    
[^31]: 使用基于模型的树和提升方法拟合低阶函数ANOVA模型

    Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA Models. (arXiv:2207.06950v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.06950](http://arxiv.org/abs/2207.06950)

    本文提出了一种新算法GAMI-Tree，使用基于模型的树以及新的交互过滤方法，可以更好地拟合底层交互，具有更好的预测性能和更高的效率。

    

    低阶函数ANOVA模型已经被机器学习社区重新发现，并称之为内在可解释的机器学习。本文提出了一种新算法GAMI-Tree，类似于EBM，但具有一些趋向更好性能的特性。我们采用模型为基础的树，并融入一种新的交互过滤方法，提高了对底层交互的捕捉。此外，我们的迭代训练方法收敛于具有更好预测性能的模型，并确保相互作用在分层意义上正交于主效应。该算法不需要广泛的调整，并且实现快速高效。我们使用模拟和真实数据集进行比较。

    Low-order functional ANOVA (fANOVA) models have been rediscovered in the machine learning (ML) community under the guise of inherently interpretable machine learning. Explainable Boosting Machines or EBM (Lou et al. 2013) and GAMI-Net (Yang et al. 2021) are two recently proposed ML algorithms for fitting functional main effects and second-order interactions. We propose a new algorithm, called GAMI-Tree, that is similar to EBM, but has a number of features that lead to better performance. It uses model-based trees as base learners and incorporates a new interaction filtering method that is better at capturing the underlying interactions. In addition, our iterative training method converges to a model with better predictive performance, and the embedded purification ensures that interactions are hierarchically orthogonal to main effects. The algorithm does not need extensive tuning, and our implementation is fast and efficient. We use simulated and real datasets to compare the performanc
    
[^32]: 多视角潜变量模型中的领域知识编码:带结构稀疏贝叶斯方法

    Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity. (arXiv:2204.06242v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.06242](http://arxiv.org/abs/2204.06242)

    提出了一种新的基于修改过的马蹄蚌先验的多视角潜变量模型MuVI，用于建模结构稀疏性。它能够纳入有限且噪声的领域知识，以内在可解释的方式分析多视角数据，优于现有结构稀疏性建模方法。

    

    许多现实世界的系统不仅有来自单个数据源的数据，还有来自多个数据视角的数据。例如，在基因组医学中，患者可以通过来自不同分子层面的数据进行描述。利用具有结构稀疏性的潜变量模型是揭示数据视角内和跨视角变化的常用工具。然而，它们的可解释性较差，需要专家直接检查和解释每个要素。在这里，我们提出了MuVI，一种基于修改过的马蹄蚌先验的新型多视角潜变量模型，用于建模结构稀疏性。这有助于对有限的和噪声领域知识进行纳入，从而以内在可解释的方式分析多视角数据。我们证明了我们的模型在重建误差和精确度/召回方面优于现有的结构稀疏性建模方法，并且可以稳健地整合噪声领域专业知识。

    Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, patients can be characterized by data from different molecular layers. Latent variable models with structured sparsity are a commonly used tool for disentangling variation within and across data views. However, their interpretability is cumbersome since it requires a direct inspection and interpretation of each factor from domain experts. Here, we propose MuVI, a novel multi-view latent variable model based on a modified horseshoe prior for modeling structured sparsity. This facilitates the incorporation of limited and noisy domain knowledge, thereby allowing for an analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) outperforms state-of-the-art approaches for modeling structured sparsity in terms of the reconstruction error and the precision/recall, (ii) robustly integrates noisy domain expertise in t
    
[^33]: 使用图神经网络学习具有弹性的无线电资源管理策略

    Learning Resilient Radio Resource Management Policies with Graph Neural Networks. (arXiv:2203.11012v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2203.11012](http://arxiv.org/abs/2203.11012)

    本文提出了一个使用图神经网络学习的具有弹性的无线电资源管理策略，以实现高聚合速率并确保所有用户的公平性，并使用可扩展的置换等变图神经网络（GNN）架构基于瞬时信道条件推导出的图形拓扑来参数化RRM策略

    

    本文考虑在包含多个接入点和一组用户设备的无线干扰网络中，实现用户选择和功率控制，以实现高聚合速率并确保所有用户的公平性。我们通过可学习的松弛变量，将弹性无线电资源管理（RRM）策略优化问题与适应底层网络条件的每个用户最低容量约束相结合。我们在Lagrangian双重域中重新定义问题，并展示了我们可以使用有限的参数集来参数化RRM策略，通过一个经过证实的小偏差的无监督原始-双重方法进行训练。我们使用可扩展的置换等变图神经网络（GNN）架构来基于瞬时信道条件推导出的图形拓扑参数化RRM策略。

    We consider the problems of user selection and power control in wireless interference networks, comprising multiple access points (APs) communicating with a group of user equipment devices (UEs) over a shared wireless medium. To achieve a high aggregate rate, while ensuring fairness across all users, we formulate a resilient radio resource management (RRM) policy optimization problem with per-user minimum-capacity constraints that adapt to the underlying network conditions via learnable slack variables. We reformulate the problem in the Lagrangian dual domain, and show that we can parameterize the RRM policies using a finite set of parameters, which can be trained alongside the slack and dual variables via an unsupervised primal-dual approach thanks to a provably small duality gap. We use a scalable and permutation-equivariant graph neural network (GNN) architecture to parameterize the RRM policies based on a graph topology derived from the instantaneous channel conditions. Through exp
    
[^34]: Weisfeiler和Leman来做机器学习了：目前的研究进展。

    Weisfeiler and Leman go Machine Learning: The Story so far. (arXiv:2112.09992v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.09992](http://arxiv.org/abs/2112.09992)

    Weisfeiler-Leman算法被广泛应用于处理图和关系数据。本文全面介绍了该算法在监督学习中的应用，包括理论背景、扩展、与等变神经网格的联系、并列出了当前应用和未来研究方向。

    

    近年来，基于Weisfeiler-Leman算法的算法和神经架构已成为处理图和关系数据的机器学习的强大工具。本文全面介绍算法在机器学习环境中的使用情况，重点关注监督学习。我们讨论了理论背景，展示了如何将其用于监督图形和节点表示学习，讨论了最近的扩展，并概述了算法与（置换）等变神经网格的联系。此外，我们还概述了当前的应用和未来的研究方向以刺激进一步的研究。

    In recent years, algorithms and neural architectures based on the Weisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism problem, have emerged as a powerful tool for machine learning with graphs and relational data. Here, we give a comprehensive overview of the algorithm's use in a machine-learning setting, focusing on the supervised regime. We discuss the theoretical background, show how to use it for supervised graph and node representation learning, discuss recent extensions, and outline the algorithm's connection to (permutation-)equivariant neural architectures. Moreover, we give an overview of current applications and future directions to stimulate further research.
    
[^35]: 对抗训练中的标签噪声：研究鲁棒过度拟合的新视角

    Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting. (arXiv:2110.03135v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03135](http://arxiv.org/abs/2110.03135)

    该论文发现了对抗训练中存在的标签噪声，并解释了其对鲁棒过度拟合的普遍存在以及扰动半径和数据质量的依赖性。通过该论文提出的方法，可以自动校准标签以应对标签噪声和鲁棒过度拟合。

    

    我们展示了在对抗训练中存在标签噪声。这种标签噪声是由于对抗样本的真实标签分布与从干净样本继承的标签之间的不匹配造成的 - 真实标签分布被对抗扰动扭曲，但从干净样本继承标签的常见做法却忽略了这一点。认识到标签噪声有助于洞察对抗训练中鲁棒过度拟合的普遍存在，并解释了其对扰动半径和数据质量的奇特依赖性。此外，我们的标签噪声视角与我们对对抗训练中纪元双下降现象的观察相吻合。在我们的分析指导下，我们提出了一种方法来自动校准标签以应对标签噪声和鲁棒过度拟合。我们的方法在各种模型和数据集上实现了一致的性能提升，而不引入新的超参数或额外的调整。

    We show that label noise exists in adversarial training. Such label noise is due to the mismatch between the true label distribution of adversarial examples and the label inherited from clean examples - the true label distribution is distorted by the adversarial perturbation, but is neglected by the common practice that inherits labels from clean examples. Recognizing label noise sheds insights on the prevalence of robust overfitting in adversarial training, and explains its intriguing dependence on perturbation radius and data quality. Also, our label noise perspective aligns well with our observations of the epoch-wise double descent in adversarial training. Guided by our analyses, we proposed a method to automatically calibrate the label to address the label noise and robust overfitting. Our method achieves consistent performance improvements across various models and datasets without introducing new hyper-parameters or additional tuning.
    
[^36]: 用贝叶斯积分对平稳核进行边缘化

    Marginalising over Stationary Kernels with Bayesian Quadrature. (arXiv:2106.07452v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.07452](http://arxiv.org/abs/2106.07452)

    本文提出一种贝叶斯积分方案，用于边缘化高斯过程核族，以获得具有良好校准不确定性估计的灵活模型，比现有方法更高效实用。

    

    对高斯过程核族进行边缘化可以产生具有良好校准不确定性估计的灵活模型。现有方法需要评估许多核的似然性，使它们对于较大的数据集来说变得不切实际。我们提出了一种贝叶斯积分方案，使得这种边缘化更加高效，因此更加实用。通过使用分布之间的最大平均差异，我们定义一种捕捉谱混合（SM）核之间不变性的核。通过推广难以定义的变形贝叶斯积分取得样本核。我们展示了我们的框架比最先进的基线产生更准确的预测，尤其是当给出有限的（墙时钟）时间预算时具有更好的校准不确定性。

    Marginalising over families of Gaussian Process kernels produces flexible model classes with well-calibrated uncertainty estimates. Existing approaches require likelihood evaluations of many kernels, rendering them prohibitively expensive for larger datasets. We propose a Bayesian Quadrature scheme to make this marginalisation more efficient and thereby more practical. Through use of the maximum mean discrepancies between distributions, we define a kernel over kernels that captures invariances between Spectral Mixture (SM) Kernels. Kernel samples are selected by generalising an information-theoretic acquisition function for warped Bayesian Quadrature. We show that our framework achieves more accurate predictions with better calibrated uncertainty than state-of-the-art baselines, especially when given limited (wall-clock) time budgets.
    

