# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes.](http://arxiv.org/abs/2305.08841) | 本文提出了一种乐观的近端策略优化算法，用于解决带有全信息反馈的周期性对抗性线性MDP，在随机线性MDP和带有全信息的敌对线性MDP中，达到了最先进的后悔边界，并具有新颖的多批次更新机制。 |
| [^2] | [Fair Information Spread on Social Networks with Community Structure.](http://arxiv.org/abs/2305.08791) | 该论文提出了一种能够考虑社区结构的影响力最大化算法，在信息传播过程中，能够保证不同社区间的信息覆盖差异不会过大。 |
| [^3] | [On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights.](http://arxiv.org/abs/2305.08658) | 本研究在推广线性矩阵不等式框架的基础上，研究了微分方程和优化算法的联系，提出了针对一个两参数Nesterov优化方法家族新的李亚普诺夫函数并表征其收敛速度，在此基础上证明了有显著改进的Nesterov方法的收敛速度，并确定出产生最佳速度的系数选择。 |
| [^4] | [Encoding Domain Expertise into Multilevel Models for Source Location.](http://arxiv.org/abs/2305.08657) | 本文提出了一种基于贝叶斯多级模型的方法，可以将群体数据视为整体来考虑，并将领域专业知识和物理知识编码到模型中，以实现源位置的定位。 |
| [^5] | [Topological Interpretability for Deep-Learning.](http://arxiv.org/abs/2305.08642) | 本文提出了一种在临床和非临床文本上训练的深度学习分类模型中使用拓扑和几何数据分析技术推断主要特征的方法。 |
| [^6] | [Double-Weighting for Covariate Shift Adaptation.](http://arxiv.org/abs/2305.08637) | 本文提出了一种双重加权的最小极大风险分类方法，可以有效避免协变量漂移对监督学习的影响。 |
| [^7] | [Kernel-based Joint Independence Tests for Multivariate Stationary and Nonstationary Time-Series.](http://arxiv.org/abs/2305.08529) | 本文提出了一种基于核的多元时间序列联合独立性统计检验方法，可以用于平稳和非平稳随机过程，通过针对单个和多个实现时间序列的重采样技术，可以稳健地发现重要的高阶依赖关系。 |
| [^8] | [Label Smoothing is Robustification against Model Misspecification.](http://arxiv.org/abs/2305.08501) | 标签平滑是用于修改损失函数和一致的估计器的方法，它可以提高正确规定模型的效率，减小模型规范化不正确的影响。 |
| [^9] | [Convergence Analysis of Mean Shift.](http://arxiv.org/abs/2305.08463) | 本研究提出了均值漂移算法的模估计序列的收敛保证，并扩展了现有的涵盖解析核和Epanechnikov核的发现，意义在于涵盖了在基于KDE的模估计的渐近统计效率方面最优的非负核——双重核。 |
| [^10] | [Theoretical Analysis of Inductive Biases in Deep Convolutional Networks.](http://arxiv.org/abs/2305.08404) | 本文研究深卷积神经网络（CNN）中的归纳偏置，证明了$\mathcal{O}(\log d)$的深度就足以实现普适性，用CNN学习稀疏函数只需要$\tilde{\mathcal{O}}(\log^2d)$个样本。同时，通过局部连接网络（LCN）分析了权重共享和局部性的归纳偏置的区别，得出了它们在表示需要有限平移等变和高方向选择性的函数方面的优越性。 |
| [^11] | [Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs.](http://arxiv.org/abs/2305.08359) | 本文提出了第一种在对抗性RL中实现无地平线策略搜索的算法，并通过采用方差-不确定性感知加权最小二乘估计器和基于占用测量的技术解决了探索和对抗性奖励的挑战。算法达到了一个 $\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$ 的遗憾界。 |
| [^12] | [Uniform-PAC Guarantees for Model-Based RL with Bounded Eluder Dimension.](http://arxiv.org/abs/2305.08350) | 本研究提出了基于模型的强化学习算法，旨在针对具有有界Eluder维度的一般函数类，提供非线性bandits和基于模型的节目式RL的统一PAC保证。 |
| [^13] | [Neural Boltzmann Machines.](http://arxiv.org/abs/2305.08337) | 发布了一种新的条件生成模型——神经玻尔兹曼机(NBM)，其可通过将CRBM参数转换为神经网络将CRBM推广，并成功地解决了高斯-伯努利CRBM在模拟正常分布数据上的限制。 |
| [^14] | [Local Convergence of Gradient Descent-Ascent for Training Generative Adversarial Networks.](http://arxiv.org/abs/2305.08277) | 本论文研究了使用基于核函数的鉴别器训练GAN的梯度下降-上升算法的局部收敛性，揭示了学习率、正则化和带宽对其影响，同时展示了收敛、振荡或发散的相变现象。 |
| [^15] | [Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos.](http://arxiv.org/abs/2305.08074) | 本文在简单的混沌映射上证明了扩展动态模态分解（EDMD）对于多项式可观测字典有指数效率，从而有效处理了混沌动力学中的正则函数问题，并展示了在这种情况下使用EDMD产生的预测和Koopman谱数据收敛至物理上有意义的极限。 |
| [^16] | [Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling.](http://arxiv.org/abs/2305.08062) | 本研究提出了一个称为OffCEM的估计器，用于对大离散动作空间下上下文匹配策略进行离线策略评估。该估计器通过基于模型的奖励估计来处理残余因果效应，并在新的本地正确性条件下保持无偏性。结果表明，OffCEM在合成和实际大动作空间数据集上优于现有方法。 |
| [^17] | [DRew: Dynamically Rewired Message Passing with Delay.](http://arxiv.org/abs/2305.08018) | 本文提出了一种能够应用于任何MPNN结构的框架，执行基于层的动态重连来确保逐渐密集化的图形。同时引入了一种延迟机制，允许跨层节点之间的跳跃连接。 |
| [^18] | [Tight and fast generalization error bound of graph embedding in metric space.](http://arxiv.org/abs/2305.07971) | 本文提供了一个紧致快速的泛化误差上限，可以保证非欧几里得度量空间中的图嵌入在实际训练数据规模下的成功。 |
| [^19] | [Convergence and scaling of Boolean-weight optimization for hardware reservoirs.](http://arxiv.org/abs/2305.07908) | 给出了在随机水库模型上使用坐标下降法进行优化的收敛性分析和尺度定律，为硬件网络优化提供了坚实的基础。 |
| [^20] | [A Flow-Based Generative Model for Rare-Event Simulation.](http://arxiv.org/abs/2305.07863) | 本文提出了一种使用基于流的生成模型直接模拟罕见事件分布的方法，该方法可以结合重要性采样获得高精度的复杂积分和期望估计，有效地提高采样效率并为罕见事件分布提供致命见解。 |
| [^21] | [Depth Dependence of $\mu$P Learning Rates in ReLU MLPs.](http://arxiv.org/abs/2305.07810) | 本文研究了宽度为 $n$，深度为 $L$ 的随机全连接 ReLU 网络中 $\mu$P 学习率对 $n$ 和 $L$ 的依赖性，发现除第一层和最后一层以外，最大学习率与 $n$ 无关，但与 $L$ 按 $L^{-3/2}$ 缩放有关。 |
| [^22] | [Optimal signal propagation in ResNets through residual scaling.](http://arxiv.org/abs/2305.07715) | 本文为ResNets导出系统的有限尺寸理论，指出对于深层网络架构，缩放参数是优化信号传播和确保有效利用网络深度方面的关键。 |
| [^23] | [Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression.](http://arxiv.org/abs/2305.00608) | 该论文介绍了使用RePU激活函数的可微分神经网络，在近似$C^s$平滑函数及其导数的同时建立了下限误差界，并证明了其在降低维度灾难方面的能力，此外还提出了一种使用RePU网络的惩罚保序回归(PDIR)方法。 |
| [^24] | [Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?.](http://arxiv.org/abs/2304.09868) | 本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。 |
| [^25] | [Learning Empirical Bregman Divergence for Uncertain Distance Representation.](http://arxiv.org/abs/2304.07689) | 本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。 |
| [^26] | [Arbitrary Decisions are a Hidden Cost of Differentially Private Training.](http://arxiv.org/abs/2302.14517) | 差分隐私训练会产生预测多样性，即使对于相同输入，使用不同的随机性也会得到不同的输出，这一成本不仅未被研究还未被审核或传达给模型设计者和利益相关者。 |
| [^27] | [Guided Deep Kernel Learning.](http://arxiv.org/abs/2302.09574) | 本文提出了一种引导深度核学习的方法，利用无限宽度神经网络学习深度核，通过神经网络高斯过程模型在优化中指导深度核学习模型，在遇到新数据点时能够适应目标置信度，既利用了贝叶斯行为，又保持了深度核的泛化能力、可扩展性和灵活性。 |
| [^28] | [On the Richness of Calibration.](http://arxiv.org/abs/2302.04118) | 本文提出了一个新的校准评估框架，探索了校准分数设计中的不同选择，并研究了根据输入特征而不是预测结果对数据点进行分组的优势，从而帮助制定具有理想数学特性的新方法。 |
| [^29] | [Evaluating Self-Supervised Learning via Risk Decomposition.](http://arxiv.org/abs/2302.03068) | 通过风险分解，提出四个误差部分评估自监督学习对169个视觉模型的影响，为SSL的设计和使用提供宝贵的见解。 |
| [^30] | [LegendreTron: Uprising Proper Multiclass Loss Learning.](http://arxiv.org/abs/2301.11695) | 本文提出了一种新颖和实用的方法{\sc LegendreTron}，用于联合学习多类别问题的正确标准损失和概率。这种方法在基准测试中经常优于其他方法。 |
| [^31] | [Context-specific kernel-based hidden Markov model for time series analysis.](http://arxiv.org/abs/2301.09870) | 本文提出了一种可以捕获核依赖关系的基于核密度估计的隐马尔可夫模型。与传统模型和基于核密度估计的模型相比，该模型在具有依赖性的数据上具有更好的性能。 |
| [^32] | [Bayesian Interpolation with Deep Linear Networks.](http://arxiv.org/abs/2212.14457) | 本文在线性网络的情况下，使用贝叶斯推理找到了预测后验和贝叶斯模型证据的非渐近表达，并通过这些表达式得到深度、宽度和数据集大小的联合作用的新图像，同时证明了线性网络在无限深度时提供了可证明的最优预测，并推导了有限网络的尖锐大偏差边界。 |
| [^33] | [On the Relationship Between Explanation and Prediction: A Causal View.](http://arxiv.org/abs/2212.06925) | 本篇论文用因果推断的方法系统地评估了解释与预测的关系，结果表明这种关系远不如理想情况。 |
| [^34] | [The Past Does Matter: Correlation of Subsequent States in Trajectory Predictions of Gaussian Process Models.](http://arxiv.org/abs/2211.11103) | 高斯过程模型中，对预测轨迹的后续状态之间独立性的假设是错误的，本文提出了一种新的高斯过程分段线性近似方法来缓解这个问题。 |
| [^35] | [Environmental Sensor Placement with Convolutional Gaussian Neural Processes.](http://arxiv.org/abs/2211.10381) | 本论文提出了一种新的方式——卷积高斯神经过程（ConvGNP），用于提高环境传感器的放置效率。ConvGNP使用神经网络来参数化联合高斯分布，通过学习空间和季节性非平稳性，优于传统的非平稳高斯过程模型。 |
| [^36] | [Adaptive Bias Correction for Improved Subseasonal Forecasting.](http://arxiv.org/abs/2209.10666) | 本研究提出一种自适应偏差校正方法，应用于欧洲中期天气预报中心的亚季节模型，可以显著提高温度和降水预测精度。 |
| [^37] | [Graph Embeddings via Tensor Products and Approximately Orthonormal Codes.](http://arxiv.org/abs/2208.10917) | 本文介绍了一种嵌入图形到向量空间的方法，使用张量积以及球形码实现高效压缩和表征，在稀疏图表示和其他应用中具有潜在技术优势。 |
| [^38] | [Memory and Capacity of Graph Embedding Methods.](http://arxiv.org/abs/2208.08769) | 本文已失效，相关内容已被合并到另一篇论文中。 |
| [^39] | [A Nonparametric Approach with Marginals for Modeling Consumer Choice.](http://arxiv.org/abs/2208.06115) | 本文提出了一种基于边缘分布的简单而有效的非参数消费者选择建模方法，在任何选择集合中会把选择概率的集合一致地描述出来。 |
| [^40] | [Unveiling the Latent Space Geometry of Push-Forward Generative Models.](http://arxiv.org/abs/2207.10541) | 本文研究了深度生成模型的潜在空间及其与模型性能之间的关系。借助几何测量理论，我们发现了优化的充分条件。我们提出了一种截断方法，可以在潜在空间中强制实行一个简单的簇结构，并提高了模型的性能。 |
| [^41] | [Federated X-Armed Bandit.](http://arxiv.org/abs/2205.15268) | 本文提出了第一个联邦多臂赌博机算法，通过利用全局目标的拓扑结构以及层次分割和弱平滑特性，实现了与客户端数量和评估预算相关的次线性累计遗憾度，对数通信只在中央服务器和客户端之间进行，保护了客户端的隐私。 |
| [^42] | [A Ihara-Bass Formula for Non-Boolean Matrices and Strong Refutations of Random CSPs.](http://arxiv.org/abs/2204.10881) | 本文提出了一种新概念的“非回溯”矩阵并证明了相应的Ihara-Bass型公式，利用该理论证明了随机k-CSP实例的多项式时间强证明的新结果。 |
| [^43] | [On the Existence of the Adversarial Bayes Classifier (Extended Version).](http://arxiv.org/abs/2112.01694) | 本篇论文研究了对抗训练健壮性下Bayes最优分类器的存在性问题，提出了一般性的充分条件，并可以为研究对抗性代理损失和其一致性属性提供有用的工具。 |
| [^44] | [Autoregressive Asymmetric Linear Gaussian Hidden Markov Models.](http://arxiv.org/abs/2010.15604) | 本文提出了一个自回归非对称线性高斯隐马尔可夫模型，可以为每个过程状态拥有不同的推理模型，同时通过修改基础模型，使其具有非对称自回归分量，能够自动选择最大化给定训练集的惩罚似然的自回归阶数。 |
| [^45] | [On Low Rank Directed Acyclic Graphs and Causal Structure Learning.](http://arxiv.org/abs/2006.05691) | 本文提出了利用DAG因果模型的低秩假设来解决高维情况下学习因果结构的难题，并成功地将现有的低秩技术应用到了因果结构学习中，实验表明这种方法对于稠密图的数据模型具有实用性。 |
| [^46] | [A Unified Analysis of AdaGrad with Weighted Aggregation and Momentum Acceleration.](http://arxiv.org/abs/1808.03408) | 本论文提出了一种名为AdaUSM的AdaGrad变体，它采用了一种新的加权自适应学习率，可以统一AdaGrad、AccAdaGrad、Adam和RMSProp的学习率，同时通过使用统一动量方案，覆盖了重球动量和Nesterov加速梯度动量；在非凸随机设置中的收敛率为$\mathcal{O}(\log(T)/\sqrt{T})$。 |

# 详细

[^1]: 乐观的近端策略优化在线性马尔可夫决策过程中的理论分析

    A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes. (arXiv:2305.08841v1 [cs.LG])

    [http://arxiv.org/abs/2305.08841](http://arxiv.org/abs/2305.08841)

    本文提出了一种乐观的近端策略优化算法，用于解决带有全信息反馈的周期性对抗性线性MDP，在随机线性MDP和带有全信息的敌对线性MDP中，达到了最先进的后悔边界，并具有新颖的多批次更新机制。

    

    近端策略优化（PPO）算法是强化学习领域中最成功的方法之一。尽管PPO很成功，但是对于PPO及其乐观变种是否能有效解决线性马尔可夫决策过程(MDPs)的理论理解仍不足。为了填补这一空白，我们提出了一种乐观的近端策略优化算法，用于带有全信息反馈的周期敌对线性MDP，并为其建立了一个$\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$的后悔值。其中$d$是线性MDPs的环境维数，$H$是每个周期的长度，$K$是周期数。与现有的基于策略的算法相比，在随机线性MDP和带有全信息的敌对线性MDP中，我们实现了当今最先进的后悔边界。此外，我们的算法设计具有新颖的多批次更新机制。

    The proximal policy optimization (PPO) algorithm stands as one of the most prosperous methods in the field of reinforcement learning (RL). Despite its success, the theoretical understanding of PPO remains deficient. Specifically, it is unclear whether PPO or its optimistic variants can effectively solve linear Markov decision processes (MDPs), which are arguably the simplest models in RL with function approximation. To bridge this gap, we propose an optimistic variant of PPO for episodic adversarial linear MDPs with full-information feedback, and establish a $\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for it. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each episode, and $K$ is the number of episodes. Compared with existing policy-based algorithms, we achieve the state-of-the-art regret bound in both stochastic linear MDPs and adversarial linear MDPs with full information. Additionally, our algorithm design features a novel multi-batched updating mechanism
    
[^2]: 社交网络上带有社区结构的公平信息传播

    Fair Information Spread on Social Networks with Community Structure. (arXiv:2305.08791v1 [stat.ML])

    [http://arxiv.org/abs/2305.08791](http://arxiv.org/abs/2305.08791)

    该论文提出了一种能够考虑社区结构的影响力最大化算法，在信息传播过程中，能够保证不同社区间的信息覆盖差异不会过大。

    

    社交网络上的信息传播已经十分普遍。影响力最大化 (IM) 算法的目的是识别那些在获得信息后将在社交网络上产生最大传播的个体，并且这些算法主要是针对营销而开发的。在具有社区结构的社交网络中，IM 算法仅着眼于最大化传播，可能导致不同社区间信息覆盖差异显著，这在公共卫生传播等情境下是不利的。虽然有些 IM 算法旨在通过节点属性来解决信息覆盖的不平衡现象，但是没有使用网络本身的实验社区结构，而这可能是有益的，因为社区直接影响信息的传播。此外，使用实验网络结构可以利用社区检测技术，在没有相关节点属性可用时运行公平感知算法。

    Information spread through social networks is ubiquitous. Influence maximization (IM) algorithms aim to identify individuals who will generate the greatest spread through the social network if provided with information, and have been largely devel- oped with marketing in mind. In social networks with community structure, which are very common, IM algorithms focused solely on maximizing spread may yield signifi- cant disparities in information coverage between communities, which is problematic in settings such as public health messaging. While some IM algorithms aim to remedy disparity in information coverage using node attributes, none use the empirical com- munity structure within the network itself, which may be beneficial since communities directly affect the spread of information. Further, the use of empirical network struc- ture allows us to leverage community detection techniques, making it possible to run fair-aware algorithms when there are no relevant node attributes availab
    
[^3]: 关于优化算法、李亚普诺夫函数和微分方程的联系：理论与洞见研究

    On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights. (arXiv:2305.08658v1 [math.OC])

    [http://arxiv.org/abs/2305.08658](http://arxiv.org/abs/2305.08658)

    本研究在推广线性矩阵不等式框架的基础上，研究了微分方程和优化算法的联系，提出了针对一个两参数Nesterov优化方法家族新的李亚普诺夫函数并表征其收敛速度，在此基础上证明了有显著改进的Nesterov方法的收敛速度，并确定出产生最佳速度的系数选择。

    

    本研究通过推广Fazylab等人在2018年发展的线性矩阵不等式框架，研究了用李亚普诺夫函数研究$m$-强凸和$L$-光滑函数的微分方程和优化算法之间的联系。使用新框架，我们针对一个两参数Nesterov优化方法家族的新型（离散）李亚普诺夫函数进行了解析推导，并表征了其收敛速度。这使得我们能够证明对于标准系数的Nesterov方法的先前证明速度有了明显改进，并且表征了产生最佳速度的系数选择。我们为Polyak ODE获得了新的李亚普诺夫函数，并重新审视了此ODE与Nesterov算法之间的联系。此外，讨论了将Nesterov方法解释为加性Runge-Kutta离散化的新方法，并解释了离散化Polyak方程的结构条件。

    We study connections between differential equations and optimization algorithms for $m$-strongly and $L$-smooth convex functions through the use of Lyapunov functions by generalizing the Linear Matrix Inequality framework developed by Fazylab et al. in 2018. Using the new framework we derive analytically a new (discrete) Lyapunov function for a two-parameter family of Nesterov optimization methods and characterize their convergence rate. This allows us to prove a convergence rate that improves substantially on the previously proven rate of Nesterov's method for the standard choice of coefficients, as well as to characterize the choice of coefficients that yields the optimal rate. We obtain a new Lyapunov function for the Polyak ODE and revisit the connection between this ODE and the Nesterov's algorithms. In addition discuss a new interpretation of Nesterov method as an additive Runge-Kutta discretization and explain the structural conditions that discretizations of the Polyak equation
    
[^4]: 将领域专业知识编码到多级模型中用于源位置的定位。

    Encoding Domain Expertise into Multilevel Models for Source Location. (arXiv:2305.08657v1 [stat.ML])

    [http://arxiv.org/abs/2305.08657](http://arxiv.org/abs/2305.08657)

    本文提出了一种基于贝叶斯多级模型的方法，可以将群体数据视为整体来考虑，并将领域专业知识和物理知识编码到模型中，以实现源位置的定位。

    

    在许多工业应用中，群体数据是普遍存在的。机器和基础设施越来越多地配备了传感系统，发出具有复杂相互依赖关系的遥测数据流。实际上，数据中心的监测程序倾向于将这些资产（以及各自的模型）视为不同的实体 - 独立运行并与独立数据相关联。相反，这项工作捕捉了一组系统模型之间的统计相关性和相互依赖关系。利用贝叶斯多级方法，数据的价值可以得到扩展，因为可以将人群作为一个整体来考虑，而不是作为组成部分。最有趣的是，领域专业知识和基础物理知识可以在系统、子组或人群水平上编码到模型中。我们提供了一个声发射（到达时间）映射源位置的示例，以说明多级模型如何自然地适用于表示。

    Data from populations of systems are prevalent in many industrial applications. Machines and infrastructure are increasingly instrumented with sensing systems, emitting streams of telemetry data with complex interdependencies. In practice, data-centric monitoring procedures tend to consider these assets (and respective models) as distinct -- operating in isolation and associated with independent data. In contrast, this work captures the statistical correlations and interdependencies between models of a group of systems. Utilising a Bayesian multilevel approach, the value of data can be extended, since the population can be considered as a whole, rather than constituent parts. Most interestingly, domain expertise and knowledge of the underlying physics can be encoded in the model at the system, subgroup, or population level. We present an example of acoustic emission (time-of-arrival) mapping for source location, to illustrate how multilevel models naturally lend themselves to represent
    
[^5]: 深度学习的拓扑可解释性

    Topological Interpretability for Deep-Learning. (arXiv:2305.08642v1 [stat.ML])

    [http://arxiv.org/abs/2305.08642](http://arxiv.org/abs/2305.08642)

    本文提出了一种在临床和非临床文本上训练的深度学习分类模型中使用拓扑和几何数据分析技术推断主要特征的方法。

    

    随着基于人工智能的系统在日常生活中的应用越来越广泛，理解它们的决策机制的需求也相应加速。我们能够信任基于人工智能决策系统所做的统计推断的程度越来越成为一个越来越重要的问题，特别是在高风险的系统，例如刑事司法或医学诊断系统中，错误的推断可能会产生悲剧性的后果。尽管在解决涉及现实世界数据的问题方面取得了成功，但深度学习（DL）模型无法量化其预测的确定性。而且当其解决方案不正确时，通常仍然非常自信。本文介绍了一种方法，在临床和非临床文本上训练的两个DL分类模型中推断杰出特征，采用了拓扑和几何数据分析技术。我们创建了模型预测空间的图形，并通过特征和预测的相似性将输入聚类到图形的顶点中。

    With the increasing adoption of AI-based systems across everyday life, the need to understand their decision-making mechanisms is correspondingly accelerating. The level at which we can trust the statistical inferences made from AI-based decision systems is an increasing concern, especially in high-risk systems such as criminal justice or medical diagnosis, where incorrect inferences may have tragic consequences. Despite their successes in providing solutions to problems involving real-world data, deep learning (DL) models cannot quantify the certainty of their predictions. And are frequently quite confident, even when their solutions are incorrect.  This work presents a method to infer prominent features in two DL classification models trained on clinical and non-clinical text by employing techniques from topological and geometric data analysis. We create a graph of a model's prediction space and cluster the inputs into the graph's vertices by the similarity of features and prediction
    
[^6]: 为协变量漂移自适应引入双重加权方法

    Double-Weighting for Covariate Shift Adaptation. (arXiv:2305.08637v1 [stat.ML])

    [http://arxiv.org/abs/2305.08637](http://arxiv.org/abs/2305.08637)

    本文提出了一种双重加权的最小极大风险分类方法，可以有效避免协变量漂移对监督学习的影响。

    

    监督学习中常常受到协变量漂移影响，即训练样本和测试样本的实例边缘分布不同但标签条件相同。现有方法通过使用比率p_te（x）/p_tr（x）对训练样本进行加权（重新加权方法），或者使用比率p_tr（x）/p_te（x）对测试样本进行加权（鲁棒方法）来解决这种协变量漂移。然而，在支持不匹配或上述比率取大值时，这些方法的性能可能很差。我们提出了一种最小极大风险分类(MRC)方法，通过对训练样本和测试样本进行加权来避免这种限制。此外，我们开发了有效的技术来获得两组加权，并推广了传统的核均值匹配方法。我们提供了新的生成模型和实际数据集上的实验结果来证明我们方法的优越性。

    Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $\mathrm{p}_\text{tr}(x)$ and $\mathrm{p}_\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $\mathrm{p}_\text{te}(x)/\mathrm{p}_\text{tr}(x)$ to weight training samples (reweighting methods) or using the ratio $\mathrm{p}_\text{tr}(x)/\mathrm{p}_\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel genera
    
[^7]: 基于核的联合独立性检验用于多元、平稳和非平稳时间序列

    Kernel-based Joint Independence Tests for Multivariate Stationary and Nonstationary Time-Series. (arXiv:2305.08529v1 [stat.ME])

    [http://arxiv.org/abs/2305.08529](http://arxiv.org/abs/2305.08529)

    本文提出了一种基于核的多元时间序列联合独立性统计检验方法，可以用于平稳和非平稳随机过程，通过针对单个和多个实现时间序列的重采样技术，可以稳健地发现重要的高阶依赖关系。

    

    捕捉相互连接系统的时间演变的多元时间序列数据在各个领域中普遍存在。了解共同观察变量之间的复杂关系和潜在依赖关系是准确统计建模和分析此类系统至关重要。本文通过将 d 变量 Hilbert-Schmidt 独立性准则（dHSIC）扩展到包含平稳和非平稳随机过程，从而允许更广泛的实际应用，提出了基于核的多元时间序列联合独立性统计检验。通过利用针对单个和多个实现时间序列量身定制的重采样技术，我们展示了该方法如何在合成示例（包括频率混合数据）以及实际气候和社会经济数据中稳健地发现重要的高阶依赖关系。我们的方法为分析复杂高维时间序列数据集增加了数学工具箱。

    Multivariate time-series data that capture the temporal evolution of interconnected systems are ubiquitous in diverse areas. Understanding the complex relationships and potential dependencies among co-observed variables is crucial for the accurate statistical modelling and analysis of such systems. Here, we introduce kernel-based statistical tests of joint independence in multivariate time-series by extending the d-variable Hilbert-Schmidt independence criterion (dHSIC) to encompass both stationary and nonstationary random processes, thus allowing broader real-world applications. By leveraging resampling techniques tailored for both single- and multiple-realization time series, we show how the method robustly uncovers significant higher-order dependencies in synthetic examples, including frequency mixing data, as well as real-world climate and socioeconomic data. Our method adds to the mathematical toolbox for the analysis of complex high-dimensional time-series datasets.
    
[^8]: 标签平滑是对模型规范化的强化防御

    Label Smoothing is Robustification against Model Misspecification. (arXiv:2305.08501v1 [stat.ML])

    [http://arxiv.org/abs/2305.08501](http://arxiv.org/abs/2305.08501)

    标签平滑是用于修改损失函数和一致的估计器的方法，它可以提高正确规定模型的效率，减小模型规范化不正确的影响。

    

    标签平滑（LS）在分类任务中采用平滑目标。例如，在二元分类中，传统的逻辑回归（LR）使用独热目标$(1,0)^\top$，而使用标签平滑的LR（LSLR）使用平滑后的目标$(1-\frac{\alpha}{2},\frac{\alpha}{2})^\top$，其中$\alpha\in(0,1)$是平滑等级，它会导致logit值挤压。除了标签平滑的常见规范化解释导致不一致的概率估计器之外，我们将LSLR视为修改损失函数和一致的概率估计器。为了研究LSLR对这两种修改的重要性，我们引入了一个修改版的LSLR，即MLSLR，它使用与LSLR相同的损失函数和与LR相同的一致估计器，但不会挤压logit值。

    Label smoothing (LS) adopts smoothed targets in classification tasks. For example, in binary classification, instead of the one-hot target $(1,0)^\top$ used in conventional logistic regression (LR), LR with LS (LSLR) uses the smoothed target $(1-\frac{\alpha}{2},\frac{\alpha}{2})^\top$ with a smoothing level $\alpha\in(0,1)$, which causes squeezing of values of the logit. Apart from the common regularization-based interpretation of LS that leads to an inconsistent probability estimator, we regard LSLR as modifying the loss function and consistent estimator for probability estimation. In order to study the significance of each of these two modifications by LSLR, we introduce a modified LSLR (MLSLR) that uses the same loss function as LSLR and the same consistent estimator as LR, while not squeezing the logits. For the loss function modification, we theoretically show that MLSLR with a larger smoothing level has lower efficiency with correctly-specified models, while it exhibits higher r
    
[^9]: 均值漂移的收敛性分析

    Convergence Analysis of Mean Shift. (arXiv:2305.08463v1 [stat.ML])

    [http://arxiv.org/abs/2305.08463](http://arxiv.org/abs/2305.08463)

    本研究提出了均值漂移算法的模估计序列的收敛保证，并扩展了现有的涵盖解析核和Epanechnikov核的发现，意义在于涵盖了在基于KDE的模估计的渐近统计效率方面最优的非负核——双重核。

    

    均值漂移（MS）算法寻找核密度估计（KDE）的模。本研究提出了一种由MS算法产生的模估计序列的收敛保证，并在相当温和的条件下，借助于关于{\L}ojasiewicz不等式的论证，评估了收敛速度。我们的发现扩展了现有的涵盖解析核和Epanechnikov核的发现，意义在于涵盖了在基于KDE的模估计的渐近统计效率方面最优的非负核——双重核。

    The mean shift (MS) algorithm seeks a mode of the kernel density estimate (KDE). This study presents a convergence guarantee of the mode estimate sequence generated by the MS algorithm and an evaluation of the convergence rate, under fairly mild conditions, with the help of the argument concerning the {\L}ojasiewicz inequality. Our findings, which extend existing ones covering analytic kernels and the Epanechnikov kernel, are significant in that they cover the biweight kernel that is optimal among non-negative kernels in terms of the asymptotic statistical efficiency for the KDE-based mode estimation.
    
[^10]: 深卷积神经网络中归纳偏置的理论分析

    Theoretical Analysis of Inductive Biases in Deep Convolutional Networks. (arXiv:2305.08404v1 [cs.LG])

    [http://arxiv.org/abs/2305.08404](http://arxiv.org/abs/2305.08404)

    本文研究深卷积神经网络（CNN）中的归纳偏置，证明了$\mathcal{O}(\log d)$的深度就足以实现普适性，用CNN学习稀疏函数只需要$\tilde{\mathcal{O}}(\log^2d)$个样本。同时，通过局部连接网络（LCN）分析了权重共享和局部性的归纳偏置的区别，得出了它们在表示需要有限平移等变和高方向选择性的函数方面的优越性。

    

    本文研究卷积神经网络（CNN）中的归纳偏置，这被认为是CNN在视觉任务上表现异常出色的重要驱动因素。我们首先分析了CNN的普适性，即逼近连续函数的能力。我们证明了$\mathcal{O}(\log d)$的深度就足以实现普适性，其中$d$是输入维度。这相比于现有结果需要$\Omega(d)$的深度是一项重大改进。我们还证明了用CNN学习稀疏函数只需要$\tilde{\mathcal{O}}(\log^2d)$个样本，表明深度CNN可以有效地捕捉长程稀疏相关性。我们的研究还分析了共享权重和局部性的归纳偏置，通过对称性得出结论。为了区分这两种偏见，我们引入了局部连接网络（LCN）并证明了它们在表示需要有限平移等变和高方向选择性的函数方面的优越性。我们的结果为深CNN的成功提供了理论洞察力，同时更好地理解了它们的局限性。

    In this paper, we study the inductive biases in convolutional neural networks (CNNs), which are believed to be vital drivers behind CNNs' exceptional performance on vision-like tasks. We first analyze the universality of CNNs, i.e., the ability to approximate continuous functions. We prove that a depth of $\mathcal{O}(\log d)$ is sufficient for achieving universality, where $d$ is the input dimension. This is a significant improvement over existing results that required a depth of $\Omega(d)$. We also prove that learning sparse functions with CNNs needs only $\tilde{\mathcal{O}}(\log^2d)$ samples, indicating that deep CNNs can efficiently capture long-range sparse correlations. Note that all these are achieved through a novel combination of increased network depth and the utilization of multichanneling and downsampling.  Lastly, we study the inductive biases of weight sharing and locality through the lens of symmetry. To separate two biases, we introduce locally-connected networks (LCN
    
[^11]: 对抗性线性混合MDP中的无地平线强化学习

    Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs. (arXiv:2305.08359v1 [cs.LG])

    [http://arxiv.org/abs/2305.08359](http://arxiv.org/abs/2305.08359)

    本文提出了第一种在对抗性RL中实现无地平线策略搜索的算法，并通过采用方差-不确定性感知加权最小二乘估计器和基于占用测量的技术解决了探索和对抗性奖励的挑战。算法达到了一个 $\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$ 的遗憾界。

    

    最近的研究表明，当总奖励受到1的限制时，分集式强化学习(RL)并不比单臂匪徒问题更难，并证明了这种情况下在规划地平线H上的遗憾界具有对数多项式依赖性。然而，是否可以将这种结果推广到对抗性RL中的奖励被每集合控制的情况仍然是一个开放性问题。本文通过提出第一种无地平线策略搜索算法，肯定回答了这个问题。为了解决探索和对抗性奖励带来的挑战，我们的算法采用了(1)方差-不确定性感知加权最小二乘估计器用于转移核心的估计；和(2)一种基于占用测量的技术，用于在线搜索一个随机策略。我们证明了，在完全信息反馈下，我们的算法达到了一个$\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$的遗憾界。其中$d$是已知特征映射的维度。

    Recent studies have shown that episodic reinforcement learning (RL) is no harder than bandits when the total reward is bounded by $1$, and proved regret bounds that have a polylogarithmic dependence on the planning horizon $H$. However, it remains an open question that if such results can be carried over to adversarial RL, where the reward is adversarially chosen at each episode. In this paper, we answer this question affirmatively by proposing the first horizon-free policy search algorithm. To tackle the challenges caused by exploration and adversarially chosen reward, our algorithm employs (1) a variance-uncertainty-aware weighted least square estimator for the transition kernel; and (2) an occupancy measure-based technique for the online search of a \emph{stochastic} policy. We show that our algorithm achieves an $\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$ regret with full-information feedback, where $d$ is the dimension of a known feature mapping linearly 
    
[^12]: 有界Eluder维度下基于模型的强化学习的统一PAC保证

    Uniform-PAC Guarantees for Model-Based RL with Bounded Eluder Dimension. (arXiv:2305.08350v1 [cs.LG])

    [http://arxiv.org/abs/2305.08350](http://arxiv.org/abs/2305.08350)

    本研究提出了基于模型的强化学习算法，旨在针对具有有界Eluder维度的一般函数类，提供非线性bandits和基于模型的节目式RL的统一PAC保证。

    

    近年来，强化学习中的通用函数逼近取得了显着进展。然而，所有这些工作都仅提供遗憾或样本复杂度保证。一个更强的性能保证——统一概率近似正确性（Uniform-PAC）保证仍然是一个开放的问题，它可以同时暗示任何目标学习准确度的次线性遗憾界和多项式样本复杂度。本文通过提出使用具有有界Eluder维度的一般函数类的非线性bandits和基于模型的节目式RL的算法来研究这个问题。所提出算法的关键思想是将每个操作根据其相对于置信集的宽度分配到不同的级别中。实现的统一PAC样本复杂度是紧密匹配最先进的减小到线性情况下的遗憾界或样本复杂度保证。据我们所知，这是第一个使用具有有界Eluder维度的一般函数逼近提供非线性bandits和基于模型的节目式RL的统一PAC保证的工作。

    Recently, there has been remarkable progress in reinforcement learning (RL) with general function approximation. However, all these works only provide regret or sample complexity guarantees. It is still an open question if one can achieve stronger performance guarantees, i.e., the uniform probably approximate correctness (Uniform-PAC) guarantee that can imply both a sub-linear regret bound and a polynomial sample complexity for any target learning accuracy. We study this problem by proposing algorithms for both nonlinear bandits and model-based episodic RL using the general function class with a bounded eluder dimension. The key idea of the proposed algorithms is to assign each action to different levels according to its width with respect to the confidence set. The achieved uniform-PAC sample complexity is tight in the sense that it matches the state-of-the-art regret bounds or sample complexity guarantees when reduced to the linear case. To the best of our knowledge, this is the firs
    
[^13]: 神经玻尔兹曼机

    Neural Boltzmann Machines. (arXiv:2305.08337v1 [cs.LG])

    [http://arxiv.org/abs/2305.08337](http://arxiv.org/abs/2305.08337)

    发布了一种新的条件生成模型——神经玻尔兹曼机(NBM)，其可通过将CRBM参数转换为神经网络将CRBM推广，并成功地解决了高斯-伯努利CRBM在模拟正常分布数据上的限制。

    

    条件生成模型能够使用上下文信息作为输入来生成新的创造性输出。条件受限波尔兹曼机(CRBM)是一类条件生成模型，其已经被证明在建模嘈杂的离散或连续数据方面特别擅长，但CRBM的表达能力有限制限制了它们的广泛采用。在这里，我们引入了神经玻尔兹曼机(NBM)，通过将每个CRBM参数转换为自己的神经网络来将CRBM推广，这些网络允许是条件输入的函数。NBM是高度灵活的条件生成模型，可以通过随机梯度下降进行训练，以近似地最大化数据的对数似然。我们展示了NBM的实用性，特别是在通常造成高斯-伯努利CRBM问题的正常分布数据方面。可以在https://github.com/unlearnai/neural-boltzmann-machines找到用于重现我们结果的代码。

    Conditional generative models are capable of using contextual information as input to create new imaginative outputs. Conditional Restricted Boltzmann Machines (CRBMs) are one class of conditional generative models that have proven to be especially adept at modeling noisy discrete or continuous data, but the lack of expressivity in CRBMs have limited their widespread adoption. Here we introduce Neural Boltzmann Machines (NBMs) which generalize CRBMs by converting each of the CRBM parameters to their own neural networks that are allowed to be functions of the conditional inputs. NBMs are highly flexible conditional generative models that can be trained via stochastic gradient descent to approximately maximize the log-likelihood of the data. We demonstrate the utility of NBMs especially with normally distributed data which has historically caused problems for Gaussian-Bernoulli CRBMs. Code to reproduce our results can be found at https://github.com/unlearnai/neural-boltzmann-machines.
    
[^14]: 训练生成对抗网络的梯度下降-上升算法的局部收敛性研究

    Local Convergence of Gradient Descent-Ascent for Training Generative Adversarial Networks. (arXiv:2305.08277v1 [cs.LG])

    [http://arxiv.org/abs/2305.08277](http://arxiv.org/abs/2305.08277)

    本论文研究了使用基于核函数的鉴别器训练GAN的梯度下降-上升算法的局部收敛性，揭示了学习率、正则化和带宽对其影响，同时展示了收敛、振荡或发散的相变现象。

    

    生成对抗网络（GAN）是一种流行的复杂高维数据生成模型的训练方法。训练GAN的标准方法涉及对极小-极大优化问题进行梯度下降-上升（GDA）过程。由于动态的非线性性质，该过程通常很难分析。本研究重点研究了使用基于核函数的鉴别器训练GAN时的GDA局部动态。该收敛性分析是在[Becker et al. 2022]的“孤立点模型”假设下，对描述GDA迭代的非线性动力学系统进行线性化得到的。我们的分析揭示了学习率、正则化和核判别器的带宽对GDA局部收敛速度的影响。重要的是，我们展示了相变现象，表明系统何时收敛、振荡或发散。我们还提供了验证我们结论的数值模拟。

    Generative Adversarial Networks (GANs) are a popular formulation to train generative models for complex high dimensional data. The standard method for training GANs involves a gradient descent-ascent (GDA) procedure on a minimax optimization problem. This procedure is hard to analyze in general due to the nonlinear nature of the dynamics. We study the local dynamics of GDA for training a GAN with a kernel-based discriminator. This convergence analysis is based on a linearization of a non-linear dynamical system that describes the GDA iterations, under an \textit{isolated points model} assumption from [Becker et al. 2022]. Our analysis brings out the effect of the learning rates, regularization, and the bandwidth of the kernel discriminator, on the local convergence rate of GDA. Importantly, we show phase transitions that indicate when the system converges, oscillates, or diverges. We also provide numerical simulations that verify our claims.
    
[^15]: 正交多项式逼近和扩展动态模态分解在混沌中的应用

    Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos. (arXiv:2305.08074v1 [math.NA])

    [http://arxiv.org/abs/2305.08074](http://arxiv.org/abs/2305.08074)

    本文在简单的混沌映射上证明了扩展动态模态分解（EDMD）对于多项式可观测字典有指数效率，从而有效处理了混沌动力学中的正则函数问题，并展示了在这种情况下使用EDMD产生的预测和Koopman谱数据收敛至物理上有意义的极限。

    

    扩展动态模态分解（EDMD）是一种数据驱动的工具，用于动态的预测和模型简化，在物理科学领域得到广泛应用。虽然这种方法在概念上很简单，但在确定性混沌中，它的性质或者它的收敛性还不清楚。特别是，EDMD的最小二乘逼近如何处理需要描绘混沌动力学含义的正则函数的类别，这也是不清楚的。本文在分析上简单的一个圆环展开映射的最简单例子上，发展了关于EDMD的一般的、严格的理论。证明了一个新的关于在单位圆上的正交多项式（OPUC）的理论结果，我们证明在无限数据极限时，针对多项式的可观测字典的最小二乘投影具有指数效率。因此，我们展示了在这种情况下使用EDMD产生的预测和Koopman谱数据收敛到物理上有意义的极限的指数速率。

    Extended Dynamic Mode Decomposition (EDMD) is a data-driven tool for forecasting and model reduction of dynamics, which has been extensively taken up in the physical sciences. While the method is conceptually simple, in deterministic chaos it is unclear what its properties are or even what it converges to. In particular, it is not clear how EDMD's least-squares approximation treats the classes of regular functions needed to make sense of chaotic dynamics.  In this paper we develop a general, rigorous theory of EDMD on the simplest examples of chaotic maps: analytic expanding maps of the circle. Proving a new result in the theory of orthogonal polynomials on the unit circle (OPUC), we show that in the infinite-data limit, the least-squares projection is exponentially efficient for polynomial observable dictionaries. As a result, we show that the forecasts and Koopman spectral data produced using EDMD in this setting converge to the physically meaningful limits, at an exponential rate.  
    
[^16]: 基于连词效应建模的大动作空间离线策略评估

    Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling. (arXiv:2305.08062v1 [stat.ML])

    [http://arxiv.org/abs/2305.08062](http://arxiv.org/abs/2305.08062)

    本研究提出了一个称为OffCEM的估计器，用于对大离散动作空间下上下文匹配策略进行离线策略评估。该估计器通过基于模型的奖励估计来处理残余因果效应，并在新的本地正确性条件下保持无偏性。结果表明，OffCEM在合成和实际大动作空间数据集上优于现有方法。

    

    本文讨论了对于传统重要性加权方法方巨的大离散动作空间下的上下文匹配策略的离线策略评估（OPE）问题。为了解决方巨问题，我们提出了一个新的估计器OffCEM，该方法基于连词效应模型（CEM），这是一种新的因果效应分解方法，可以将效应分为群集效应和残差效应。OffCEM仅对行动群集应用重要性加权，通过基于模型的奖励估计来处理残余因果效应。我们表明，在新的本地正确性条件下，该估计器是无偏的，该条件仅要求残差效应模型保留每个群集中行动的相对期望奖励差异。为了充分利用CEM和本地正确性，我们还提出了一种新的两步过程，用于执行基于模型的估计，第一步最小化偏差，第二步最小化方差。我们发现，所得到的OPE估计器OffCEM在合成和实际大动作空间数据集上都明显优于现有的最先进方法。

    We study off-policy evaluation (OPE) of contextual bandit policies for large discrete action spaces where conventional importance-weighting approaches suffer from excessive variance. To circumvent this variance issue, we propose a new estimator, called OffCEM, that is based on the conjunct effect model (CEM), a novel decomposition of the causal effect into a cluster effect and a residual effect. OffCEM applies importance weighting only to action clusters and addresses the residual causal effect through model-based reward estimation. We show that the proposed estimator is unbiased under a new condition, called local correctness, which only requires that the residual-effect model preserves the relative expected reward differences of the actions within each cluster. To best leverage the CEM and local correctness, we also propose a new two-step procedure for performing model-based estimation that minimizes bias in the first step and variance in the second step. We find that the resulting O
    
[^17]: DRew：带延迟的动态重连消息传递

    DRew: Dynamically Rewired Message Passing with Delay. (arXiv:2305.08018v1 [cs.LG])

    [http://arxiv.org/abs/2305.08018](http://arxiv.org/abs/2305.08018)

    本文提出了一种能够应用于任何MPNN结构的框架，执行基于层的动态重连来确保逐渐密集化的图形。同时引入了一种延迟机制，允许跨层节点之间的跳跃连接。

    

    已经证明，消息传递神经网络（MPNN）存在过度压缩现象，导致长程相互作用任务表现不佳。这主要归因于只在节点的相邻居之间进行局部消息传递。试图使图形“更连通”并且更适合长程任务的重连方法通常会失去基于图形距离提供的归纳偏差，因为它们会使远程节点在每一层中立即通信。在本文中，我们提出了一个框架，可应用于任何MPNN架构，以执行基于层的重连，以确保逐渐加密图形。我们还提出了一种延迟机制，它允许根据层和它们的相互距离在节点之间进行跳跃连接。我们在几个长程任务上验证了我们的方法，并表明其优于图形变换器和多跳MPNN。

    Message passing neural networks (MPNNs) have been shown to suffer from the phenomenon of over-squashing that causes poor performance for tasks relying on long-range interactions. This can be largely attributed to message passing only occurring locally, over a node's immediate neighbours. Rewiring approaches attempting to make graphs `more connected', and supposedly better suited to long-range tasks, often lose the inductive bias provided by distance on the graph since they make distant nodes communicate instantly at every layer. In this paper we propose a framework, applicable to any MPNN architecture, that performs a layer-dependent rewiring to ensure gradual densification of the graph. We also propose a delay mechanism that permits skip connections between nodes depending on the layer and their mutual distance. We validate our approach on several long-range tasks and show that it outperforms graph Transformers and multi-hop MPNNs.
    
[^18]: 度量空间中图嵌入的紧致快速泛化误差界限

    Tight and fast generalization error bound of graph embedding in metric space. (arXiv:2305.07971v1 [stat.ML])

    [http://arxiv.org/abs/2305.07971](http://arxiv.org/abs/2305.07971)

    本文提供了一个紧致快速的泛化误差上限，可以保证非欧几里得度量空间中的图嵌入在实际训练数据规模下的成功。

    

    近期的研究实验证明，我们可以在非欧几里得度量空间中实现有效且高效的图嵌入，旨在获得在度量空间中反映图结构的顶点表示。特别地，在双曲空间中的图嵌入在嵌入具有分层树结构的图上，例如自然语言、社交网络和知识库中的数据，已经获得了实验成功。然而，最近的理论分析显示，非欧几里得图嵌入的泛化误差比欧几里得图嵌入的误差上限要高得多，高泛化误差表明数据中的不完整性和噪声可能会显著损坏学习性能。这意味着现有的界限不能保证实际训练数据规模下在非欧几里得度量空间中的图嵌入成功，这可能会阻止非欧几里得图嵌入在实际问题中的应用。本文提供了一个新的非欧几里得度量空间中图嵌入的泛化误差上限，该上限紧凑且快速，可以保证在实际训练数据规模下非欧几里得图嵌入的成功。

    Recent studies have experimentally shown that we can achieve in non-Euclidean metric space effective and efficient graph embedding, which aims to obtain the vertices' representations reflecting the graph's structure in the metric space. Specifically, graph embedding in hyperbolic space has experimentally succeeded in embedding graphs with hierarchical-tree structure, e.g., data in natural languages, social networks, and knowledge bases. However, recent theoretical analyses have shown a much higher upper bound on non-Euclidean graph embedding's generalization error than Euclidean one's, where a high generalization error indicates that the incompleteness and noise in the data can significantly damage learning performance. It implies that the existing bound cannot guarantee the success of graph embedding in non-Euclidean metric space in a practical training data size, which can prevent non-Euclidean graph embedding's application in real problems. This paper provides a novel upper bound of
    
[^19]: 布尔权重优化的收敛性和尺度在硬件水库中的应用

    Convergence and scaling of Boolean-weight optimization for hardware reservoirs. (arXiv:2305.07908v1 [stat.ML])

    [http://arxiv.org/abs/2305.07908](http://arxiv.org/abs/2305.07908)

    给出了在随机水库模型上使用坐标下降法进行优化的收敛性分析和尺度定律，为硬件网络优化提供了坚实的基础。

    

    实现神经网络的硬件化是实现下一代高效和强大人工智能解决方案的重要一步。除了实现并行、高效和可扩展的硬件架构外，用抽样有效的方法优化系统极大的参数空间也至关重要。本研究分析地导出了高效坐标下降法在优化随机复杂神经网络--水库的读出层所需的尺度定律。我们证明了收敛是指数级的，并且随着网络神经元数量的线性缩放。我们的研究完全复现了一个大规模的光子水库实验中的收敛性和尺度。因此，我们的工作为硬件网络优化提供了坚实的基础，并确定了有前途的优化收束速度的未来方向。

    Hardware implementation of neural network are an essential step to implement next generation efficient and powerful artificial intelligence solutions.  Besides the realization of a parallel, efficient and scalable hardware architecture, the optimization of the system's extremely large parameter space with sampling-efficient approaches is essential.  Here, we analytically derive the scaling laws for highly efficient Coordinate Descent applied to optimizing the readout layer of a random recurrently connection neural network, a reservoir.  We demonstrate that the convergence is exponential and scales linear with the network's number of neurons.  Our results perfectly reproduce the convergence and scaling of a large-scale photonic reservoir implemented in a proof-of-concept experiment.  Our work therefore provides a solid foundation for such optimization in hardware networks, and identifies future directions that are promising for optimizing convergence speed during learning leveraging mea
    
[^20]: 一种用于罕见事件模拟的基于流的生成模型

    A Flow-Based Generative Model for Rare-Event Simulation. (arXiv:2305.07863v1 [stat.ML])

    [http://arxiv.org/abs/2305.07863](http://arxiv.org/abs/2305.07863)

    本文提出了一种使用基于流的生成模型直接模拟罕见事件分布的方法，该方法可以结合重要性采样获得高精度的复杂积分和期望估计，有效地提高采样效率并为罕见事件分布提供致命见解。

    

    在复杂的随机环境中解决决策问题通常通过蒙特卡罗采样估计决策的期望结果来实现。然而，采样可能会忽略罕见但重要的事件，这可能会严重影响决策过程。我们提出一种方法，其中训练了一个归一化流生成模型，以直接从条件分布中模拟样本，前提是发生罕见事件。通过利用耦合流，我们的模型可以在原则上任意好地逼近任何采样分布。通过将逼近方法与重要性采样相结合，可以获得高精度的复杂积分和期望估计。我们包括了几个示例来演示如何在高维和罕见事件设置中使用该方法进行有效采样和估计。我们证明了通过直接从罕见事件分布中模拟可以获得关于罕见事件发生方式的重要见解。

    Solving decision problems in complex, stochastic environments is often achieved by estimating the expected outcome of decisions via Monte Carlo sampling. However, sampling may overlook rare, but important events, which can severely impact the decision making process. We present a method in which a Normalizing Flow generative model is trained to simulate samples directly from a conditional distribution given that a rare event occurs. By utilizing Coupling Flows, our model can, in principle, approximate any sampling distribution arbitrarily well. By combining the approximation method with Importance Sampling, highly accurate estimates of complicated integrals and expectations can be obtained. We include several examples to demonstrate how the method can be used for efficient sampling and estimation, even in high-dimensional and rare-event settings. We illustrate that by simulating directly from a rare-event distribution significant insight can be gained into the way rare events happen.
    
[^21]: ReLU MLPs 中 $\mu$P 学习速率的深度依赖性。

    Depth Dependence of $\mu$P Learning Rates in ReLU MLPs. (arXiv:2305.07810v1 [cs.LG])

    [http://arxiv.org/abs/2305.07810](http://arxiv.org/abs/2305.07810)

    本文研究了宽度为 $n$，深度为 $L$ 的随机全连接 ReLU 网络中 $\mu$P 学习率对 $n$ 和 $L$ 的依赖性，发现除第一层和最后一层以外，最大学习率与 $n$ 无关，但与 $L$ 按 $L^{-3/2}$ 缩放有关。

    

    在这篇简短的论文中，我们考虑了宽度为 $n$，深度为 $L$ 的随机全连接 ReLU 网络，并配备了平均场权重初始化。我们的目的是研究 $\mu$P 学习率对 $n$ 和 $L$ 的依赖性——在 $n,L$ 很大时 ，经过梯度下降一步后的预激活均方差变化仍保持均匀有界的最大学习率。与 Yang 等人关于 $\mu$P 的先前工作一样，我们发现除第一层和最后一层的权重外，这个最大更新学习率与 $n$ 无关。然而，我们发现它对 $L$ 有一个非平凡的依赖性，按 $L^{-3/2}$ 缩放。

    In this short note we consider random fully connected ReLU networks of width $n$ and depth $L$ equipped with a mean-field weight initialization. Our purpose is to study the dependence on $n$ and $L$ of the maximal update ($\mu$P) learning rate, the largest learning rate for which the mean squared change in pre-activations after one step of gradient descent remains uniformly bounded at large $n,L$. As in prior work on $\mu$P of Yang et. al., we find that this maximal update learning rate is independent of $n$ for all but the first and last layer weights. However, we find that it has a non-trivial dependence of $L$, scaling like $L^{-3/2}.$
    
[^22]: 通过残差缩放实现ResNets的信号最优传递

    Optimal signal propagation in ResNets through residual scaling. (arXiv:2305.07715v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2305.07715](http://arxiv.org/abs/2305.07715)

    本文为ResNets导出系统的有限尺寸理论，指出对于深层网络架构，缩放参数是优化信号传播和确保有效利用网络深度方面的关键。

    

    Residual网络（ResNets）在大深度上比前馈神经网络具有更好的训练能力和性能。引入跳过连接可以促进信号向更深层的传递。此外，先前的研究发现为残差分支添加缩放参数可以进一步提高泛化性能。尽管他们经验性地确定了这种缩放参数特别有利的取值范围，但其相关的性能提升及其在网络超参数上的普适性仍需要进一步理解。对于前馈神经网络（FFNets），有限尺寸理论在信号传播和超参数调节方面获得了重要洞见。我们在这里为ResNets导出了一个系统的有限尺寸理论，以研究信号传播及其对残差分支缩放的依赖性。我们导出响应函数的分析表达式，这是衡量网络对输入敏感性的一种指标，并表明对于深层网络架构，缩放参数在优化信号传播和确保有效利用网络深度方面发挥着至关重要的作用。

    Residual networks (ResNets) have significantly better trainability and thus performance than feed-forward networks at large depth. Introducing skip connections facilitates signal propagation to deeper layers. In addition, previous works found that adding a scaling parameter for the residual branch further improves generalization performance. While they empirically identified a particularly beneficial range of values for this scaling parameter, the associated performance improvement and its universality across network hyperparameters yet need to be understood. For feed-forward networks (FFNets), finite-size theories have led to important insights with regard to signal propagation and hyperparameter tuning. We here derive a systematic finite-size theory for ResNets to study signal propagation and its dependence on the scaling for the residual branch. We derive analytical expressions for the response function, a measure for the network's sensitivity to inputs, and show that for deep netwo
    
[^23]: 使用RePU激活函数的可微分神经网络：在得分估计和保序回归中的应用。

    Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression. (arXiv:2305.00608v1 [stat.ML])

    [http://arxiv.org/abs/2305.00608](http://arxiv.org/abs/2305.00608)

    该论文介绍了使用RePU激活函数的可微分神经网络，在近似$C^s$平滑函数及其导数的同时建立了下限误差界，并证明了其在降低维度灾难方面的能力，此外还提出了一种使用RePU网络的惩罚保序回归(PDIR)方法。

    

    我们研究了由修正后的幂单元（RePU）函数激活的可微分神经网络的属性。我们展示了RePU神经网络的偏导数可以由混合激活RePU网络来表示，并推导了导数RePU网络函数类的复杂度的上界。在使用RePU激活的深度神经网络中，我们建立了同时近似$C^s$平滑函数及其导数的误差界。此外，当数据具有近似低维支持时，我们推导出改进的逼近误差界，证明了RePU网络减缓维度灾难的能力。为了说明我们的结果的实用性，我们考虑了深度得分匹配估计器(DSME)，并提出了一种使用RePU网络的惩罚保序回归(PDIR)。我们在假定目标函数属于$C^s$平滑函数类的情况下为DSME和PDIR建立非渐近超额风险界。

    We study the properties of differentiable neural networks activated by rectified power unit (RePU) functions. We show that the partial derivatives of RePU neural networks can be represented by RePUs mixed-activated networks and derive upper bounds for the complexity of the function class of derivatives of RePUs networks. We establish error bounds for simultaneously approximating $C^s$ smooth functions and their derivatives using RePU-activated deep neural networks. Furthermore, we derive improved approximation error bounds when data has an approximate low-dimensional support, demonstrating the ability of RePU networks to mitigate the curse of dimensionality. To illustrate the usefulness of our results, we consider a deep score matching estimator (DSME) and propose a penalized deep isotonic regression (PDIR) using RePU networks. We establish non-asymptotic excess risk bounds for DSME and PDIR under the assumption that the target functions belong to a class of $C^s$ smooth functions. We 
    
[^24]: 通过保留谱的数据压缩加速支持向量聚类

    Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])

    [http://arxiv.org/abs/2304.09868](http://arxiv.org/abs/2304.09868)

    本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。

    

    支持向量聚类是一种重要的聚类方法，但是由于其计算昂贵的簇分配步骤，它面临着可伸缩性问题。在本文中，我们通过保留谱的数据压缩来加速支持向量聚类。具体而言，我们将原始数据集压缩成少量谱表示的聚合数据点，然后在压缩后的数据集上执行标准的支持向量聚类，最后将压缩数据集的聚类结果映射回原始数据集以发现簇。我们在真实数据集上的大量实验结果表明，相较于标准支持向量聚类，我们的方法大大提高了速度，而不会损失聚类质量。

    Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
    
[^25]: 学习经验Bregman散度用于不确定距离表示

    Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])

    [http://arxiv.org/abs/2304.07689](http://arxiv.org/abs/2304.07689)

    本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。

    

    深度度量学习技术已应用于各种监督和无监督学习任务，通过深度网络学习样本嵌入来进行视觉表示。然而，经典方法采用固定距离度量作为两个嵌入之间的相似性函数，可能导致捕捉复杂数据分布的亚最优性能。Bregman散度概括了各种距离度量的度量，并在许多深度度量学习领域中产生。本文首先展示了如何从Bregman散度获得深度度量学习损失。然后，我们介绍了一种直接从数据中学习经验Bregman散度的新方法，通过使用深度学习设置对Bregman散度下的凸函数进行参数化。我们进一步实验证明，与其他SOTA深度度量学习方法相比，我们的方法在五个流行公共数据集上表现出色，特别是在模式识别和聚类任务上。

    Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
    
[^26]: 差分隐私训练的任意决策是一个隐藏成本

    Arbitrary Decisions are a Hidden Cost of Differentially Private Training. (arXiv:2302.14517v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14517](http://arxiv.org/abs/2302.14517)

    差分隐私训练会产生预测多样性，即使对于相同输入，使用不同的随机性也会得到不同的输出，这一成本不仅未被研究还未被审核或传达给模型设计者和利益相关者。

    

    隐私保护的机器学习中使用的机制通常旨在在模型训练期间保证差分隐私(DP)。在将模型参数拟合到隐私敏感数据时，实践中使用随机化方法(例如，在截断的梯度上添加高斯噪声)以确保DP训练。我们证明了这种随机化会产生预测多样性：对于给定的输入示例，由同样DP-保证的模型预测的输出取决于训练中使用的随机性。因此，对于给定的输入，即使使用相同的训练数据集重新训练模型，预测输出也可能发生巨大变化。尚未研究由DP训练引起的多样性成本，并且目前还未经过审核或向模型设计者和利益相关者传达。我们得出了一种在可靠地估计预测多样性所需的重新训练次数的上限，并通过广泛的实验分析了三种DP-确保训练方法的预测多样性成本，包括理论和实验两个方面。

    Mechanisms used in privacy-preserving machine learning often aim to guarantee differential privacy (DP) during model training. Practical DP-ensuring training methods use randomization when fitting model parameters to privacy-sensitive data (e.g., adding Gaussian noise to clipped gradients). We demonstrate that such randomization incurs predictive multiplicity: for a given input example, the output predicted by equally-private models depends on the randomness used in training. Thus, for a given input, the predicted output can vary drastically if a model is re-trained, even if the same training dataset is used. The predictive-multiplicity cost of DP training has not been studied, and is currently neither audited for nor communicated to model designers and stakeholders. We derive a bound on the number of re-trainings required to estimate predictive multiplicity reliably. We analyze--both theoretically and through extensive experiments--the predictive-multiplicity cost of three DP-ensuring
    
[^27]: 引导深度核学习

    Guided Deep Kernel Learning. (arXiv:2302.09574v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09574](http://arxiv.org/abs/2302.09574)

    本文提出了一种引导深度核学习的方法，利用无限宽度神经网络学习深度核，通过神经网络高斯过程模型在优化中指导深度核学习模型，在遇到新数据点时能够适应目标置信度，既利用了贝叶斯行为，又保持了深度核的泛化能力、可扩展性和灵活性。

    

    现在通常通过深度核学习 (DKL) 将高斯过程与深度神经网络的表达能力结合起来。不幸的是，由于核优化过程，这种方法常常会失去它们的贝叶斯优势。在本研究中，我们提出了一种利用无限宽度神经网络学习深度核的新方法。我们提出使用神经网络高斯过程 (NNGP) 模型作为 DKl 模型在优化过程中的指导。我们的方法利用 NNGP 的可靠不确定性估计，以使 DKL 在遇到新数据点时能够适应目标置信度。因此，我们既利用了 NNGP 的贝叶斯行为 (即其抗过拟合性和准确的不确定性估计)，又保持了深度核的泛化能力，可扩展性和灵活性。在多个基准数据集上进行的实证分析表明，我们的方法在不同大小和维度的数据集上都取得了很好的效果。

    Combining Gaussian processes with the expressive power of deep neural networks is commonly done nowadays through deep kernel learning (DKL). Unfortunately, due to the kernel optimization process, this often results in losing their Bayesian benefits. In this study, we present a novel approach for learning deep kernels by utilizing infinite-width neural networks. We propose to use the Neural Network Gaussian Process (NNGP) model as a guide to the DKL model in the optimization process. Our approach harnesses the reliable uncertainty estimation of the NNGPs to adapt the DKL target confidence when it encounters novel data points. As a result, we get the best of both worlds, we leverage the Bayesian behavior of the NNGP, namely its robustness to overfitting, and accurate uncertainty estimation, while maintaining the generalization abilities, scalability, and flexibility of deep kernels. Empirically, we show on multiple benchmark datasets of varying sizes and dimensionality, that our method i
    
[^28]: 论校准的精细度

    On the Richness of Calibration. (arXiv:2302.04118v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04118](http://arxiv.org/abs/2302.04118)

    本文提出了一个新的校准评估框架，探索了校准分数设计中的不同选择，并研究了根据输入特征而不是预测结果对数据点进行分组的优势，从而帮助制定具有理想数学特性的新方法。

    

    通过与观测标签频率的比较，即通过校准的方法可以评估概率预测，最近，算法公平性方面的学者开始研究一个名为多校准的校准基准的不断增长的多样性，但还是比较局限的。在本文中，我们通过明确设计校准度量时涉及的选择，探索和分析了校准评估的各种形式。我们将这些选择分为三个分组选择和一个关于组错误合并的选择。这提供了一个框架，以比较以前提出的校准分数，并有助于制定具有理想数学特性的新方法。特别是，我们探讨了根据输入特征而不是预测对数据点进行分组的可能性，并正式展示这种方法的优点。我们还对适合的组错误合并函数的空间进行了表征。

    Probabilistic predictions can be evaluated through comparisons with observed label frequencies, that is, through the lens of calibration. Recent scholarship on algorithmic fairness has started to look at a growing variety of calibration-based objectives under the name of multi-calibration but has still remained fairly restricted. In this paper, we explore and analyse forms of evaluation through calibration by making explicit the choices involved in designing calibration scores. We organise these into three grouping choices and a choice concerning the agglomeration of group errors. This provides a framework for comparing previously proposed calibration scores and helps to formulate novel ones with desirable mathematical properties. In particular, we explore the possibility of grouping datapoints based on their input features rather than on predictions and formally demonstrate advantages of such approaches. We also characterise the space of suitable agglomeration functions for group erro
    
[^29]: 通过风险分解评估自监督学习

    Evaluating Self-Supervised Learning via Risk Decomposition. (arXiv:2302.03068v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03068](http://arxiv.org/abs/2302.03068)

    通过风险分解，提出四个误差部分评估自监督学习对169个视觉模型的影响，为SSL的设计和使用提供宝贵的见解。

    

    自监督学习（SSL）的流程设计涉及架构、增强和预训练数据等诸多选择。然而，SSL通常使用单一度量来评估，这并不能提供深入的洞察和改进方案。为解决这些问题，我们提出了一个SSL风险分解，从逼近、表示可用性、探针泛化和编码器泛化等角度对错误进行分解。我们分析了30个设计选择对169个在ImageNet上评估的SSL视觉模型的影响，并为每个组件提供了高效的估计器，为SSL模型的设计和使用提供宝贵的见解。

    Self-supervised learning (SSL) pipelines differ in many design choices such as the architecture, augmentations, or pretraining data. Yet SSL is typically evaluated using a single metric: linear probing on ImageNet. This does not provide much insight into why or when a model is better, now how to improve it. To address this, we propose an SSL risk decomposition, which generalizes the classical supervised approximation-estimation decomposition by considering errors arising from the representation learning step. Our decomposition consists of four error components: approximation, representation usability, probe generalization, and encoder generalization. We provide efficient estimators for each component and use them to analyze the effect of 30 design choices on 169 SSL vision models evaluated on ImageNet. Our analysis gives valuable insights for designing and using SSL models. For example, it highlights the main sources of error and shows how to improve SSL in specific settings (full- vs 
    
[^30]: LegendreTron：升级版多类别正确多项损失学习

    LegendreTron: Uprising Proper Multiclass Loss Learning. (arXiv:2301.11695v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.11695](http://arxiv.org/abs/2301.11695)

    本文提出了一种新颖和实用的方法{\sc LegendreTron}，用于联合学习多类别问题的正确标准损失和概率。这种方法在基准测试中经常优于其他方法。

    

    损失函数是监督学习的基础，通常在模型开发之前选择。为避免选择损失函数可能出现的特定选择，统计决策理论描述了损失的一种理想属性，称为“正确性”，它断言贝叶斯规则是最优的。最近的研究尝试联合学习损失和模型。现有方法通过拟合一个将$\mathbb{R}$单调映射到$[0,1]$的反解标准链接函数来估计二元问题的概率。本文通过使用凸函数梯度的单调性将单调性扩展到$\mathbb{R}^{C-1}$到概率的正投影$\tilde{\Delta}^{C-1}$的映射上。我们提出了一种新颖而实用的方法{\sc LegendreTron}，用于联合学习多类别问题的正确标准损失和概率。在最多1,000种类别的领域基准测试中，我们的实验结果表明，我们的方法始终优于其他基准方法。

    Loss functions serve as the foundation of supervised learning and are often chosen prior to model development. To avoid potentially ad hoc choices of losses, statistical decision theory describes a desirable property for losses known as \emph{properness}, which asserts that Bayes' rule is optimal. Recent works have sought to \emph{learn losses} and models jointly. Existing methods do this by fitting an inverse canonical link function which monotonically maps $\mathbb{R}$ to $[0,1]$ to estimate probabilities for binary problems. In this paper, we extend monotonicity to maps between $\mathbb{R}^{C-1}$ and the projected probability simplex $\tilde{\Delta}^{C-1}$ by using monotonicity of gradients of convex functions. We present {\sc LegendreTron} as a novel and practical method that jointly learns \emph{proper canonical losses} and probabilities for multiclass problems. Tested on a benchmark of domains with up to 1,000 classes, our experimental results show that our method consistently ou
    
[^31]: 上下文相关的基于核方法的隐马尔可夫模型用于时间序列分析

    Context-specific kernel-based hidden Markov model for time series analysis. (arXiv:2301.09870v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.09870](http://arxiv.org/abs/2301.09870)

    本文提出了一种可以捕获核依赖关系的基于核密度估计的隐马尔可夫模型。与传统模型和基于核密度估计的模型相比，该模型在具有依赖性的数据上具有更好的性能。

    

    传统的隐马尔可夫模型是理解和建模随机动态数据的有用工具；在非高斯数据的情况下，可以使用类似高斯混合隐马尔可夫模型的模型。但是，这些模型受到精度矩阵的计算以及具有很多不必要的参数的影响。因此，这样的模型在假定所有变量独立的情况下表现更好，这可能是不现实的假设。基于核密度估计的隐马尔可夫模型也能够建模非高斯数据，但它们假定变量之间是独立的。在本文中，我们引入了一种基于核密度估计的新型隐马尔可夫模型，能够利用上下文相关贝叶斯网络捕获核依赖关系。介绍了所提出模型及其基于期望最大化算法的学习算法。此外，还将该模型与相关的HMM在合成和实际数据上进行了比较。

    Traditional hidden Markov models have been a useful tool to understand and model stochastic dynamic data; in the case of non-Gaussian data, models such as mixture of Gaussian hidden Markov models can be used. However, these suffer from the computation of precision matrices and have a lot of unnecessary parameters. As a consequence, such models often perform better when it is assumed that all variables are independent, a hypothesis that may be unrealistic. Hidden Markov models based on kernel density estimation are also capable of modeling non-Gaussian data, but they assume independence between variables. In this article, we introduce a new hidden Markov model based on kernel density estimation, which is capable of capturing kernel dependencies using context-specific Bayesian networks. The proposed model is described, together with a learning algorithm based on the expectation-maximization algorithm. Additionally, the model is compared to related HMMs on synthetic and real data. From th
    
[^32]: 深度线性网络的贝叶斯插值

    Bayesian Interpolation with Deep Linear Networks. (arXiv:2212.14457v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.14457](http://arxiv.org/abs/2212.14457)

    本文在线性网络的情况下，使用贝叶斯推理找到了预测后验和贝叶斯模型证据的非渐近表达，并通过这些表达式得到深度、宽度和数据集大小的联合作用的新图像，同时证明了线性网络在无限深度时提供了可证明的最优预测，并推导了有限网络的尖锐大偏差边界。

    

    在深度学习理论中，表征神经网络的深度、宽度和数据集大小如何共同影响模型质量是一个核心问题。我们在线性网络的特殊情况下，使用具有高斯权重先验和平均平方误差的贝叶斯推理对单输出维度进行了完整的解决方案。对于任何训练数据集、网络深度和隐藏层宽度，我们找到了预测后验和贝叶斯模型证据的非渐近表达，这些表达式是一类关于Meijer-G函数的亚纯特殊函数。通过这些Meijer-G函数的新型渐近展开，我们得到了深度、宽度和数据集大小的联合作用的丰富新图像。我们表明，线性网络在无限深度时可以提供可证明的最优预测：具有数据不可知先验的无限深度线性网络的后验概率与具有最大化数据依赖先验信息的浅网络的后验概率相同，且后验概率集中于线性函数。当网络是有限的时，我们还推导了后验距离线性函数的尖锐大偏差边界，并表明这些边界以高度错综复杂的方式取决于网络深度、宽度和数据集大小。最后，在大数据集极限下提供了完整的贝叶斯模型证据的渐近展开，并证明了对于固定宽度，证据是深度和数据集大小的多项式。

    Characterizing how neural network depth, width, and dataset size jointly impact model quality is a central problem in deep learning theory. We give here a complete solution in the special case of linear networks with output dimension one trained using zero noise Bayesian inference with Gaussian weight priors and mean squared error as a negative log-likelihood. For any training dataset, network depth, and hidden layer widths, we find non-asymptotic expressions for the predictive posterior and Bayesian model evidence in terms of Meijer-G functions, a class of meromorphic special functions of a single complex variable. Through novel asymptotic expansions of these Meijer-G functions, a rich new picture of the joint role of depth, width, and dataset size emerges. We show that linear networks make provably optimal predictions at infinite depth: the posterior of infinitely deep linear networks with data-agnostic priors is the same as that of shallow networks with evidence-maximizing data-depe
    
[^33]: 论解释与预测的关系：一种因果视角

    On the Relationship Between Explanation and Prediction: A Causal View. (arXiv:2212.06925v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06925](http://arxiv.org/abs/2212.06925)

    本篇论文用因果推断的方法系统地评估了解释与预测的关系，结果表明这种关系远不如理想情况。

    

    提供模型决策解释的能力成为了机器学习模型开发、部署和应用的核心要求。然而，我们尚未理解解释方法的优缺点。数据、模型预测、超参数和随机初始化等上游因素如何影响下游的解释？虽然先前的研究提出了解释与预测之间关系较小的担忧，但缺乏确定性的研究来量化这种关系。我们的工作借鉴因果推断的方法系统地评估了这种关系。具体而言，我们通过干预解释和预测的因果祖先，在使用以显眼度为基础的解释或预测时对超参数和输入进行测量，来研究解释和预测之间的关系。我们的研究结果表明，解释和预测之间的关系远非理想。事实上，“理想”情况下的差距只会在更高的情况下增加。

    Being able to provide explanations for a model's decision has become a central requirement for the development, deployment, and adoption of machine learning models. However, we are yet to understand what explanation methods can and cannot do. How do upstream factors such as data, model prediction, hyperparameters, and random initialization influence downstream explanations? While previous work raised concerns that explanations (E) may have little relationship with the prediction (Y), there is a lack of conclusive study to quantify this relationship. Our work borrows tools from causal inference to systematically assay this relationship. More specifically, we study the relationship between E and Y by measuring the treatment effect when intervening on their causal ancestors, i.e., on hyperparameters and inputs used to generate saliency-based Es or Ys. Our results suggest that the relationships between E and Y is far from ideal. In fact, the gap between 'ideal' case only increase in higher
    
[^34]: 过去的事情很重要：高斯过程模型轨迹预测中后续状态的相关性

    The Past Does Matter: Correlation of Subsequent States in Trajectory Predictions of Gaussian Process Models. (arXiv:2211.11103v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.11103](http://arxiv.org/abs/2211.11103)

    高斯过程模型中，对预测轨迹的后续状态之间独立性的假设是错误的，本文提出了一种新的高斯过程分段线性近似方法来缓解这个问题。

    

    计算高斯过程模型中动态系统的轨迹分布是一个重要的挑战。在考虑到基于采样的方法的计算成本之后，我们考虑了模型输出和轨迹分布的近似方法。我们发现之前关于不确定性传播的工作，重点放在离散状态空间模型上，错误地包含了对预测轨迹的后续状态之间独立性的假设。将这些思想扩展到连续的常微分方程模型上，我们展示了这个假设的含义，并提出了一种新的高斯过程分段线性近似方法来缓解这个问题。

    Computing the distribution of trajectories from a Gaussian Process model of a dynamical system is an important challenge in utilizing such models. Motivated by the computational cost of sampling-based approaches, we consider approximations of the model's output and trajectory distribution. We show that previous work on uncertainty propagation, focussed on discrete state-space models, incorrectly included an independence assumption between subsequent states of the predicted trajectories. Expanding these ideas to continuous ordinary differential equation models, we illustrate the implications of this assumption and propose a novel piecewise linear approximation of Gaussian Processes to mitigate them.
    
[^35]: 带有卷积高斯神经过程的环境传感器放置

    Environmental Sensor Placement with Convolutional Gaussian Neural Processes. (arXiv:2211.10381v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.10381](http://arxiv.org/abs/2211.10381)

    本论文提出了一种新的方式——卷积高斯神经过程（ConvGNP），用于提高环境传感器的放置效率。ConvGNP使用神经网络来参数化联合高斯分布，通过学习空间和季节性非平稳性，优于传统的非平稳高斯过程模型。

    

    环境传感器对于监测天气和气候变化的影响至关重要。然而，在像南极这样的偏远地区，最大化测量信息和有效放置传感器是具有挑战性的。概率机器学习模型可以通过预测新传感器提供的不确定性减少来评估放置信息。高斯过程模型广泛用于此目的，但难以捕捉复杂的非平稳行为并缩放到大型数据集。本文提出使用卷积高斯神经过程（ConvGNP）来解决这些问题。ConvGNP使用神经网络来参数化任意目标位置的联合高斯分布，实现了灵活性和可扩展性。使用模拟的南极地区地面温度异常作为真实数据，ConvGNP学习了空间和季节性非平稳性，并优于非平稳GP基线。在模拟的s中，

    Environmental sensors are crucial for monitoring weather conditions and the impacts of climate change. However, it is challenging to maximise measurement informativeness and place sensors efficiently, particularly in remote regions like Antarctica. Probabilistic machine learning models can evaluate placement informativeness by predicting the uncertainty reduction provided by a new sensor. Gaussian process (GP) models are widely used for this purpose, but they struggle with capturing complex non-stationary behaviour and scaling to large datasets. This paper proposes using a convolutional Gaussian neural process (ConvGNP) to address these issues. A ConvGNP uses neural networks to parameterise a joint Gaussian distribution at arbitrary target locations, enabling flexibility and scalability. Using simulated surface air temperature anomaly over Antarctica as ground truth, the ConvGNP learns spatial and seasonal non-stationarities, outperforming a non-stationary GP baseline. In a simulated s
    
[^36]: 改进亚季节预测的自适应偏差校正方法

    Adaptive Bias Correction for Improved Subseasonal Forecasting. (arXiv:2209.10666v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10666](http://arxiv.org/abs/2209.10666)

    本研究提出一种自适应偏差校正方法，应用于欧洲中期天气预报中心的亚季节模型，可以显著提高温度和降水预测精度。

    

    亚季节预测是预测未来2到6周温度和降水的重要手段，对于有效的水资源分配、野火管理以及干旱和洪涝灾害的缓解至关重要。本研究提出了一种自适应偏差校正（ABC）方法，该方法将最先进的数值模型与机器学习结合，旨在对气象动力学和物理学模型中的固有误差进行修正。在美国连续区域，当我们将ABC方法应用于欧洲中期天气预报中心（ECMWF）的领先亚季节模型时，发现温度预测技巧提高了60-90％（基线技巧在0.18-0.25之间），降水预测技巧提高了40-69％（基线技巧在0.11-0.15之间）。

    Subseasonal forecasting -- predicting temperature and precipitation 2 to 6 weeks ahead -- is critical for effective water allocation, wildfire management, and drought and flood mitigation. Recent international research efforts have advanced the subseasonal capabilities of operational dynamical models, yet temperature and precipitation prediction skills remain poor, partly due to stubborn errors in representing atmospheric dynamics and physics inside dynamical models. Here, to counter these errors, we introduce an adaptive bias correction (ABC) method that combines state-of-the-art dynamical forecasts with observations using machine learning. We show that, when applied to the leading subseasonal model from the European Centre for Medium-Range Weather Forecasts (ECMWF), ABC improves temperature forecasting skill by 60-90% (over baseline skills of 0.18-0.25) and precipitation forecasting skill by 40-69% (over baseline skills of 0.11-0.15) in the contiguous U.S. We couple these performance
    
[^37]: 张量积与近似正交码的图嵌入方法

    Graph Embeddings via Tensor Products and Approximately Orthonormal Codes. (arXiv:2208.10917v4 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2208.10917](http://arxiv.org/abs/2208.10917)

    本文介绍了一种嵌入图形到向量空间的方法，使用张量积以及球形码实现高效压缩和表征，在稀疏图表示和其他应用中具有潜在技术优势。

    

    我们分析了一种以保持结构方式来嵌入图形的方法，展示了其丰富的表征能力并建立了一些理论性质。我们的过程属于绑定和求和方法，并且我们显示了张量积是尊重叠加原理的最一般的绑定操作。我们还建立了一些精确的结果对我们方法的行为进行了表征，并且我们证明我们使用的球形码实现了一个装箱上限。我们建立了与邻接矩阵的联系，表明我们的方法在某种意义上是一种邻接矩阵的压缩，具有稀疏图表示的应用。

    We analyze a method for embedding graphs as vectors in a structure-preserving manner, showcasing its rich representational capacity and establishing some of its theoretical properties. Our procedure falls under the bind-and-sum approach, and we show that the tensor product is the most general binding operation that respects the superposition principle. We also establish some precise results characterizing the behavior of our method, and we show that our use of spherical codes achieves a packing upper bound. We establish a link to adjacency matrices, showing that our method is, in some sense, a compression of adjacency matrices with applications towards sparse graph representations.
    
[^38]: 图嵌入方法的记忆与容量

    Memory and Capacity of Graph Embedding Methods. (arXiv:2208.08769v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.08769](http://arxiv.org/abs/2208.08769)

    本文已失效，相关内容已被合并到另一篇论文中。

    

    本文已失效：请查看“通过张量积和近似正交码实现图嵌入”的论文，其中已将本文合并为一篇论文。

    THIS PAPER IS NOW DEFUNCT: Check out "Graph Embeddings via Tensor Products and Approximately Orthonormal Codes", where it has been combined into one paper.
    
[^39]: 基于边缘分布的非参数消费者选择建模方法

    A Nonparametric Approach with Marginals for Modeling Consumer Choice. (arXiv:2208.06115v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.06115](http://arxiv.org/abs/2208.06115)

    本文提出了一种基于边缘分布的简单而有效的非参数消费者选择建模方法，在任何选择集合中会把选择概率的集合一致地描述出来。

    

    鉴于消费者在不同选择集合中作出选择的数据，开发描述和预测消费者选择行为的简洁模型是一个主要挑战。其中一种选择模型是边缘分布模型，该模型仅需要规定随机效用的边缘分布即可解释选项数据。在本文中，我们开发了一种精确的选择概率集合的特征化方法，该集合可以在任何集合中一致地通过边缘分布模型来描述。允许根据其效用的边缘分布将选择集合进行分组，我们展示了(a)验证这个模型与选择概率数据的一致性在多项式时间内是可能的，(b)最接近拟合的方法可以简化为解决混合整数凸规划问题。我们的结果表明，与多项式Logit模型和m相比，边缘分布模型提供了更好的表现能力。

    Given data on choices made by consumers for different assortments, a key challenge is to develop parsimonious models that describe and predict consumer choice behavior. One such choice model is the marginal distribution model which requires only the specification of the marginal distributions of the random utilities of the alternatives to explain choice data. In this paper, we develop an exact characterisation of the set of choice probabilities which are representable by the marginal distribution model consistently across any collection of assortments. Allowing for the possibility of alternatives to be grouped based on the marginal distribution of their utilities, we show (a) verifying consistency of choice probability data with this model is possible in polynomial time and (b) finding the closest fit reduces to solving a mixed integer convex program. Our results show that the marginal distribution model provides much better representational power as compared to multinomial logit and m
    
[^40]: 揭示推进生成模型的潜在空间几何结构

    Unveiling the Latent Space Geometry of Push-Forward Generative Models. (arXiv:2207.10541v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.10541](http://arxiv.org/abs/2207.10541)

    本文研究了深度生成模型的潜在空间及其与模型性能之间的关系。借助几何测量理论，我们发现了优化的充分条件。我们提出了一种截断方法，可以在潜在空间中强制实行一个简单的簇结构，并提高了模型的性能。

    

    许多深度生成模型都是通过连续生成器推进高斯测量而定义的，例如生成对抗网络（GAN）或变分自动编码器（VAE）。本文探究了这些深度生成模型的潜在空间。这些模型的一个关键问题是，在学习不连通分布时，它们往往输出超出目标分布支持范围的样本。我们研究了这些模型的性能与它们的潜在空间几何之间的关系。借助几何测量理论的最新发展，我们在潜在空间的维度大于模的数量的情况下证明了优化的充分条件。通过对GAN进行实验，我们证明了我们理论结果的可靠性，并对这些模型的潜在空间几何结构获得了新的见解。此外，我们提出了一种截断方法，可以在潜在空间中强制实行一个简单的簇结构，并提高了模型的性能。

    Many deep generative models are defined as a push-forward of a Gaussian measure by a continuous generator, such as Generative Adversarial Networks (GANs) or Variational Auto-Encoders (VAEs). This work explores the latent space of such deep generative models. A key issue with these models is their tendency to output samples outside of the support of the target distribution when learning disconnected distributions. We investigate the relationship between the performance of these models and the geometry of their latent space. Building on recent developments in geometric measure theory, we prove a sufficient condition for optimality in the case where the dimension of the latent space is larger than the number of modes. Through experiments on GANs, we demonstrate the validity of our theoretical results and gain new insights into the latent space geometry of these models. Additionally, we propose a truncation method that enforces a simplicial cluster structure in the latent space and improve
    
[^41]: 联邦多臂赌博机

    Federated X-Armed Bandit. (arXiv:2205.15268v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.15268](http://arxiv.org/abs/2205.15268)

    本文提出了第一个联邦多臂赌博机算法，通过利用全局目标的拓扑结构以及层次分割和弱平滑特性，实现了与客户端数量和评估预算相关的次线性累计遗憾度，对数通信只在中央服务器和客户端之间进行，保护了客户端的隐私。

    

    本文建立了第一个联邦 $\mathcal{X}$-armed bandit 框架，不同客户端面临在相同域上定义的异构局部目标函数，并需要协作地找出全局最优解。我们提出了针对此类问题的第一个联邦算法，称为 \texttt{Fed-PNE}。通过利用全局目标的拓扑结构以及层次分割和弱平滑特性，我们的算法实现了与客户端数量和评估预算相关的次线性累计遗憾度。同时，它只需要中央服务器和客户端之间的对数通信，保护了客户端的隐私。合成函数和真实数据集上的实验结果验证了 \texttt{Fed-PNE} 相对于各种集中式和联邦基线算法的优势。

    This work establishes the first framework of federated $\mathcal{X}$-armed bandit, where different clients face heterogeneous local objective functions defined on the same domain and are required to collaboratively figure out the global optimum. We propose the first federated algorithm for such problems, named \texttt{Fed-PNE}. By utilizing the topological structure of the global objective inside the hierarchical partitioning and the weak smoothness property, our algorithm achieves sublinear cumulative regret with respect to both the number of clients and the evaluation budget. Meanwhile, it only requires logarithmic communications between the central server and clients, protecting the client privacy. Experimental results on synthetic functions and real datasets validate the advantages of \texttt{Fed-PNE} over various centralized and federated baseline algorithms.
    
[^42]: 针对非布尔矩阵的Ihara-Bass公式及随机CSPs的强证明机制

    A Ihara-Bass Formula for Non-Boolean Matrices and Strong Refutations of Random CSPs. (arXiv:2204.10881v2 [cs.CC] UPDATED)

    [http://arxiv.org/abs/2204.10881](http://arxiv.org/abs/2204.10881)

    本文提出了一种新概念的“非回溯”矩阵并证明了相应的Ihara-Bass型公式，利用该理论证明了随机k-CSP实例的多项式时间强证明的新结果。

    

    我们定义了一种新颖的“非回溯”矩阵概念，可与任何对称矩阵相关，并证明了相应的Ihara-Bass型公式。我们利用这个理论证明了关于$k$个变量每约束的随机约束满足问题（k-CSPs）的多项式时间强证明的新结果。对于由一个由$p$分数的分配满足的约束构建的随机k-CSP实例，如果实例包含$n$个变量和$n^{k/2} / \epsilon^2$个约束，则我们可以有效地计算出最优解仅满足$p+O_k(\epsilon)$个约束的证书。以前，这仅对于偶数$k$是已知的，但对于奇数$k$，需要$n^{k/2} (\log n)^{O(1)} / \epsilon^2$个随机约束才能得出相同的结论。虽然改进仅是对数级别的，但它克服了这类结果的一个重要障碍。

    We define a novel notion of ``non-backtracking'' matrix associated to any symmetric matrix, and we prove a ``Ihara-Bass'' type formula for it.  We use this theory to prove new results on polynomial-time strong refutations of random constraint satisfaction problems with $k$ variables per constraints (k-CSPs). For a random k-CSP instance constructed out of a constraint that is satisfied by a $p$ fraction of assignments, if the instance contains $n$ variables and $n^{k/2} / \epsilon^2$ constraints, we can efficiently compute a certificate that the optimum satisfies at most a $p+O_k(\epsilon)$ fraction of constraints.  Previously, this was known for even $k$, but for odd $k$ one needed $n^{k/2} (\log n)^{O(1)} / \epsilon^2$ random constraints to achieve the same conclusion.  Although the improvement is only polylogarithmic, it overcomes a significant barrier to these types of results. Strong refutation results based on current approaches construct a certificate that a certain matrix associ
    
[^43]: 关于对抗性Bayes分类器存在性的研究（扩展版）

    On the Existence of the Adversarial Bayes Classifier (Extended Version). (arXiv:2112.01694v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.01694](http://arxiv.org/abs/2112.01694)

    本篇论文研究了对抗训练健壮性下Bayes最优分类器的存在性问题，提出了一般性的充分条件，并可以为研究对抗性代理损失和其一致性属性提供有用的工具。

    

    对抗训练健壮性在现代机器学习应用中至关重要。虽然最近已经有多项理论研究，但与对抗训练健壮性相关的许多重要问题仍然未被解决。本文研究了一个关于对抗训练健壮性下Bayes最优分类器存在性的基本问题。我们提出了一般的充分条件，以保证存在对抗训练健壮性下的Bayes最优分类器。我们的结果可以为对后续对抗训练健壮性下代理损失和它们的一致性属性的研究提供有用的工具。本文是“关于对抗性Bayes分类器存在性”的矫正和扩展版本，该稿件已发表在NeurIPS 2021上。原始论文中有两处定理错误，一处是对伪可证健壮性的定义，另一处是针对任意度量空间的$A^\e$可测性。

    Adversarial robustness is a critical property in a variety of modern machine learning applications. While it has been the subject of several recent theoretical studies, many important questions related to adversarial robustness are still open. In this work, we study a fundamental question regarding Bayes optimality for adversarial robustness. We provide general sufficient conditions under which the existence of a Bayes optimal classifier can be guaranteed for adversarial robustness. Our results can provide a useful tool for a subsequent study of surrogate losses in adversarial robustness and their consistency properties. This manuscript is the extended and corrected version of the paper \emph{On the Existence of the Adversarial Bayes Classifier} published in NeurIPS 2021. There were two errors in theorem statements in the original paper -- one in the definition of pseudo-certifiable robustness and the other in the measurability of $A^\e$ for arbitrary metric spaces. In this version we 
    
[^44]: 自回归非对称线性高斯隐马尔可夫模型

    Autoregressive Asymmetric Linear Gaussian Hidden Markov Models. (arXiv:2010.15604v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2010.15604](http://arxiv.org/abs/2010.15604)

    本文提出了一个自回归非对称线性高斯隐马尔可夫模型，可以为每个过程状态拥有不同的推理模型，同时通过修改基础模型，使其具有非对称自回归分量，能够自动选择最大化给定训练集的惩罚似然的自回归阶数。

    

    在一个随时间演变的真实过程中，相关变量之间的关系可能会改变。因此，为每个过程状态拥有不同的推理模型是有优势的。非对称隐马尔可夫模型满足这种动态要求，并提供一个框架，其中过程的趋势可以被表示为一个潜变量。在本文中，我们修改了这些最近的非对称隐马尔可夫模型，使其具有非对称自回归分量，使模型能够选择最大化给定训练集的惩罚似然的自回归阶数。此外，我们展示了必须如何调整推理、隐藏状态解码和参数学习来适应所提出的模型。最后，我们使用合成数据和实际数据进行实验，以展示这个新模型的能力。

    In a real life process evolving over time, the relationship between its relevant variables may change. Therefore, it is advantageous to have different inference models for each state of the process. Asymmetric hidden Markov models fulfil this dynamical requirement and provide a framework where the trend of the process can be expressed as a latent variable. In this paper, we modify these recent asymmetric hidden Markov models to have an asymmetric autoregressive component, allowing the model to choose the order of autoregression that maximizes its penalized likelihood for a given training set. Additionally, we show how inference, hidden states decoding and parameter learning must be adapted to fit the proposed model. Finally, we run experiments with synthetic and real data to show the capabilities of this new model.
    
[^45]: 低秩有向无环图与因果结构学习

    On Low Rank Directed Acyclic Graphs and Causal Structure Learning. (arXiv:2006.05691v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.05691](http://arxiv.org/abs/2006.05691)

    本文提出了利用DAG因果模型的低秩假设来解决高维情况下学习因果结构的难题，并成功地将现有的低秩技术应用到了因果结构学习中，实验表明这种方法对于稠密图的数据模型具有实用性。

    

    尽管近年来有了一些进展，但在高维情况下学习由有向无环图（DAG）表示的因果结构仍然是一项具有挑战性的任务，尤其是当要学习的图不是稀疏的情况下。在本文中，我们提出利用关于DAG因果模型的（加权）邻接矩阵的低秩假设来解决这个问题。我们利用现有的低秩技术来调整因果结构学习方法，以充分利用这个假设，并建立一些有用的结果，将可解释的图形条件与低秩假设相关联。具体而言，我们表明最大秩与中心节点高度相关，这表明在实践中经常遇到的无标度网络往往是低秩的。我们的实验证明了低秩适应对于各种数据模型的实用性，特别是对于相对大且密集的图。此外，通过验证过程，适应性方法始终保持卓越或比以前的方法更好的性能。

    Despite several advances in recent years, learning causal structures represented by directed acyclic graphs (DAGs) remains a challenging task in high dimensional settings when the graphs to be learned are not sparse. In this paper, we propose to exploit a low rank assumption regarding the (weighted) adjacency matrix of a DAG causal model to help address this problem. We utilize existing low rank techniques to adapt causal structure learning methods to take advantage of this assumption and establish several useful results relating interpretable graphical conditions to the low rank assumption. Specifically, we show that the maximum rank is highly related to hubs, suggesting that scale-free networks, which are frequently encountered in practice, tend to be low rank. Our experiments demonstrate the utility of the low rank adaptations for a variety of data models, especially with relatively large and dense graphs. Moreover, with a validation procedure, the adaptations maintain a superior or
    
[^46]: 一种带有权重聚集和动量加速的AdaGrad的统一分析

    A Unified Analysis of AdaGrad with Weighted Aggregation and Momentum Acceleration. (arXiv:1808.03408v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1808.03408](http://arxiv.org/abs/1808.03408)

    本论文提出了一种名为AdaUSM的AdaGrad变体，它采用了一种新的加权自适应学习率，可以统一AdaGrad、AccAdaGrad、Adam和RMSProp的学习率，同时通过使用统一动量方案，覆盖了重球动量和Nesterov加速梯度动量；在非凸随机设置中的收敛率为$\mathcal{O}(\log(T)/\sqrt{T})$。

    

    将自适应学习率和动量技术集成到SGD中会导致一类高效加速自适应随机算法，如AdaGrad，RMSProp，Adam，AccAdaGrad等。尽管它们在实践中有效，但它们的收敛理论仍存在很大差距，特别是在非凸随机设置中。为了填补这一差距，我们提出了“带有统一动量的加权AdaGrad”，称为AdaUSM，它具有以下主要特征：(1) 它融合了统一的动量方案，涵盖了重球动量和Nesterov加速梯度动量；(2) 它采用了一种新的加权自适应学习率，可以统一AdaGrad，AccAdaGrad，Adam和RMSProp的学习率。此外，当我们在AdaUSM中采用多项式增长的权重时，在非凸随机设置中可以得到其收敛率为$\mathcal{O}(\log(T)/\sqrt{T})$ 。我们还表明，Adam和RMSProp的自适应学习率在重加权的情况下是一致的。

    Integrating adaptive learning rate and momentum techniques into SGD leads to a large class of efficiently accelerated adaptive stochastic algorithms, such as AdaGrad, RMSProp, Adam, AccAdaGrad, \textit{etc}. In spite of their effectiveness in practice, there is still a large gap in their theories of convergences, especially in the difficult non-convex stochastic setting. To fill this gap, we propose \emph{weighted AdaGrad with unified momentum}, dubbed AdaUSM, which has the main characteristics that (1) it incorporates a unified momentum scheme which covers both the heavy ball momentum and the Nesterov accelerated gradient momentum; (2) it adopts a novel weighted adaptive learning rate that can unify the learning rates of AdaGrad, AccAdaGrad, Adam, and RMSProp. Moreover, when we take polynomially growing weights in AdaUSM, we obtain its $\mathcal{O}(\log(T)/\sqrt{T})$ convergence rate in the non-convex stochastic setting. We also show that the adaptive learning rates of Adam and RMSPro
    

