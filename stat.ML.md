# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The noise level in linear regression with dependent data.](http://arxiv.org/abs/2305.11165) | 本文研究了具有依赖数据的线性回归中的噪声水平，提出了上限界限，并在误差规范下表现出优雅的降低。 |
| [^2] | [Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study.](http://arxiv.org/abs/2305.11164) | 本论文通过分析Hugging Face上1,417个ML模型及相关数据集的碳足迹测量情况，提出了有关如何报告和优化ML模型的碳效率的见解和建议。 |
| [^3] | [Attacks on Online Learners: a Teacher-Student Analysis.](http://arxiv.org/abs/2305.11132) | 本文利用控制理论的视角研究了在线学习环境下可能遭受到的标签扰动攻击情况，得出攻击强度超过临界阈值时学习准确率将出现不连续转变的结论，并验证了理论在复杂结构学习器上的适用性。 |
| [^4] | [Statistical Foundations of Prior-Data Fitted Networks.](http://arxiv.org/abs/2305.11097) | 先验-数据拟合网络是一种新的机器学习范例，通过离线预训练固定的模型，然后在任意大小和分布的新训练集上推断类概率，并在与预训练所用大小相似的任务上实现了最先进的性能, 且准确性在推断过程中进一步提高。 |
| [^5] | [Small noise analysis for Tikhonov and RKHS regularizations.](http://arxiv.org/abs/2305.11055) | 该研究建立了一个小噪声分析框架，揭示了传统L2正则化范数的潜在不稳定性，并提出了一种自适应分数阶RKHS正则化器类来解决不稳定性，这些正则化器始终产生最佳的收敛速率。 |
| [^6] | [Difference of Submodular Minimization via DC Programming.](http://arxiv.org/abs/2305.11046) | 本文介绍了一种新的算法，利用DC规划算法来解决子模最小化问题，并证明收敛性质比现有算法更全面，同时在语音特征选择和文档摘要等应用中取得更好的性能。 |
| [^7] | [A unified framework for information-theoretic generalization bounds.](http://arxiv.org/abs/2305.11042) | 该论文提出了一种基于概率去相关引理和概率测度空间中一些其他技术的通用方法，可以得到新的学习算法的信息论泛化上限，并且能够恢复许多现有的泛化界，如基于互信息、条件互信息、随机chaining和PAC-Bayes不等式的界。 |
| [^8] | [High-dimensional Asymptotics of Denoising Autoencoders.](http://arxiv.org/abs/2305.11041) | 本文研究了去噪自编码器在高维极限下的性能表现，得出了去噪均方测试误差的闭式表达式，并揭示了有跳跃连接的自编码器相较于传统自编码器的优越性。 |
| [^9] | [Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework for Online RL.](http://arxiv.org/abs/2305.11032) | 本文提出了一种乐观自然策略梯度的在线强化学习策略优化框架，采用乐观策略评估子程序以鼓励探索，适用于线性MDP，样本复杂度具有最优维度依赖关系。 |
| [^10] | [Mode Connectivity in Auction Design.](http://arxiv.org/abs/2305.11005) | 该论文研究了拍卖设计领域的一个基本问题，即最优拍卖设计。在研究中，作者证明了神经网络在一定条件下可以通过简单的分段线性路径连接不同的局部最优解，并取得了成功。 |
| [^11] | [Dynamic Term Structure Models with Nonlinearities using Gaussian Processes.](http://arxiv.org/abs/2305.11001) | 本研究提出了一种广义建模方法，在动态期限结构模型中引入了高斯过程先验来建模非线性关联，以此进行预测和动态投资组合优化，相比过去仅考虑线性相互作用，反映了更加真实的经济关系。 |
| [^12] | [Estimation Beyond Data Reweighting: Kernel Method of Moments.](http://arxiv.org/abs/2305.10898) | 本论文提出了一种新的核矩法估计器，称为KMM，其用于超越数据重新加权的矩方法模型，解除了关于使用 $\varphi$-散度相关的限制。 |
| [^13] | [Minimum-Risk Recalibration of Classifiers.](http://arxiv.org/abs/2305.10886) | 本文介绍了最小风险重新校准的概念，在均方误差分解框架内提供了一种原则性方法，用于评估和重新校准概率分类器，并通过平衡校准和锐度确定了最优的桶数，从而产生了大约$O(n^{-2/3})$的风险上界。 |
| [^14] | [Discounted Thompson Sampling for Non-Stationary Bandit Problems.](http://arxiv.org/abs/2305.10718) | 该论文提出了一种针对非稳态多臂赌博机问题的折扣汤普森抽样算法（DS-TS），可以解决突然性变化和平滑性变化的问题，并且在两种情况下具有近乎最优的遗憾上限。 |
| [^15] | [The Blessing of Heterogeneity in Federated Q-learning: Linear Speedup and Beyond.](http://arxiv.org/abs/2305.10697) | 本文提出了异构群体强化学习中联邦Q学习的样本复杂度保证，讨论了同步和异步版本的线性加速，同时探究了等权重平均本地Q估计的缺陷。 |
| [^16] | [Posterior Inference on Infinitely Wide Bayesian Neural Networks under Weights with Unbounded Variance.](http://arxiv.org/abs/2305.10664) | 本文提出了一种新的方法进行关于具有无界方差权重的贝叶斯神经网络的后验推断，并表明后验分布集中在具有非标准超参数依赖性的稀疏促进和均值收缩先验周围。 |
| [^17] | [Augmented Message Passing Stein Variational Gradient Descent.](http://arxiv.org/abs/2305.10636) | 本文提出了一种增强的消息传递斯坦变分梯度下降法(AUMP-SVGD)来应对 Stein Variational Gradient Descent (SVGD)方法的方差崩溃问题，我们的算法能够提高SVGD在高维问题中的有效性。 |
| [^18] | [Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample Complexity for Learning Single Index Models.](http://arxiv.org/abs/2305.10633) | 本文提出了使用平滑化的损失来优化在线SGD的信号，可以使用$n \gtrsim d^{k^\star/2}$个样本学习单指数模型$w^\star$，并与张量PCA和小批量SGD的正则化效应有关。 |
| [^19] | [Tensor Products and Hyperdimensional Computing.](http://arxiv.org/abs/2305.10572) | 本文探索了张量积在超维计算中的数学关系，将其确定为中心表示，并发现它是最通用、最具表现力和最压缩的表示，同时具有无误差解绑和检测的能力。 |
| [^20] | [Counterfactually Comparing Abstaining Classifiers.](http://arxiv.org/abs/2305.10564) | 本文提出一种新的方法和视角来评估和比较放弃分类器，将放弃预测视为缺失数据。我们定义了放弃分类器的反事实得分，指的是分类器没有放弃预测时的预测性能期望。 |
| [^21] | [Learning Likelihood Ratios with Neural Network Classifiers.](http://arxiv.org/abs/2305.10500) | 该研究介绍了一种使用神经网络分类器参数化计算似然比的技巧，并详细比较了不同设置的性能。这对于许多数据或基于模拟的科学应用非常有用。 |
| [^22] | [A proof of imitation of Wasserstein inverse reinforcement learning for multi-objective optimization.](http://arxiv.org/abs/2305.10089) | 本文证明了Wasserstein反向强化学习模型适用于多目标优化问题，可让学习者的奖励值和最优解模仿专家，具有一定的实用价值。 |
| [^23] | [Learning from Aggregated Data: Curated Bags versus Random Bags.](http://arxiv.org/abs/2305.09557) | 本文研究了两种自然的聚合方法：基于共同特征将数据点分组的精选包和将数据点随机分组的随机包，对于精选包设置和广泛的损失函数范围内，我们展示了可以通过梯度下降学习而不会导致数据聚合导致性能下降的情况。 |
| [^24] | [DRew: Dynamically Rewired Message Passing with Delay.](http://arxiv.org/abs/2305.08018) | 本文提出了一种能够应用于任何MPNN结构的框架，执行基于层的动态重连来确保逐渐密集化的图形。同时引入了一种延迟机制，允许跨层节点之间的跳跃连接。 |
| [^25] | [A proof of convergence of inverse reinforcement learning for multi-objective optimization.](http://arxiv.org/abs/2305.06137) | 本论文证明了多目标优化的逆强化学习方法在理论层面上的收敛性，包括Wasserstein逆强化学习和常规逆强化学习方法。 |
| [^26] | [Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy.](http://arxiv.org/abs/2304.14762) | 本文提出了一种通过在样本中引入扰动，改进基于核化斯坦距的拟合优度检验方法的方法，以解决在同质但混合比例不同的情况下低功率的问题，并展示实验证据证明了该方法的功效。 |
| [^27] | [Sparse joint shift in multinomial classification.](http://arxiv.org/abs/2303.16971) | 该论文提出了一种稀疏联合偏移模型，用于解决整体数据集偏移问题，提供了传递SJS、修正类后验概率、SJS的可辨认性、SJS与协变量转移关系等新结果。 |
| [^28] | [List Online Classification.](http://arxiv.org/abs/2303.15383) | 本文研究了多标签列表的在线预测问题，提出了 $b$-ary Littlestone 维度可学习模型，并且在懵懂的情况下探索不同的情况。可以使用改编自 Littlestone 的 SOA 和 Rosenblatt 的感知器等算法进行预测，同时还建立了列表可学习的组合结果。 |
| [^29] | [Certified Robust Neural Networks: Generalization and Corruption Resistance.](http://arxiv.org/abs/2303.02251) | 该论文提出了一种新颖的分布鲁棒损失函数，该函数通过认证级别的鲁棒性对两种常见的污染类型进行抵抗，并确保泛化保证，从而解决了鲁棒性和泛化之间的矛盾，具有极高的实用性。 |
| [^30] | [Efficient Fraud Detection Using Deep Boosting Decision Trees.](http://arxiv.org/abs/2302.05918) | 本文提出了一种利用深度增强决策树的方法来进行欺诈检测，既可以利用决策树的可解释性，又可以提高神经网络的表示学习能力。同时，采用新的过采样策略来缓解数据不平衡的问题。 |
| [^31] | [Exploring Numerical Priors for Low-Rank Tensor Completion with Generalized CP Decomposition.](http://arxiv.org/abs/2302.05881) | 本文提出了一种新的方法框架GCDTC，利用数值先验和广义CP分解实现了更高的低秩张量补全精度；同时介绍了一个算法SPTC，作为该框架的一个实现。在实验中，该方法表现出比现有技术更好的性能。 |
| [^32] | [Reinforcement Learning with History-Dependent Dynamic Contexts.](http://arxiv.org/abs/2302.02061) | 介绍了一种称为DCMDPs的新型强化学习框架，用于处理依赖历史环境的情况。其中的逻辑DCMDPs通过利用聚合函数确定上下文转换，打破了对历史长度的指数依赖，并引入了一种实用的基于模型的算法。在推荐任务中展示了该方法的有效性。 |
| [^33] | [Expected Gradients of Maxout Networks and Consequences to Parameter Initialization.](http://arxiv.org/abs/2301.06956) | 本文研究了Maxout网络关于输入和参数的梯度，提出了避免梯度消失和爆炸的参数初始化策略，并在实验中证明了其有效性。 |
| [^34] | [Simple and Scalable Algorithms for Cluster-Aware Precision Medicine.](http://arxiv.org/abs/2211.16553) | 本文提出了基于聚类和嵌入的简单高效方法，用于克服精准医疗中的高维问题和聚类问题，经验证该方法较当前方法具有更高的有效性和可行性。 |
| [^35] | [EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search.](http://arxiv.org/abs/2210.06015) | 提出了一个能耗感知的神经架构搜索表格基准 EC-NAS，该基准通过添加能耗和碳足迹信息，支持设计能效高的深度学习模型，并降低总能耗。 |
| [^36] | [A Measure of the Complexity of Neural Representations based on Partial Information Decomposition.](http://arxiv.org/abs/2209.10438) | 本文提出了一种基于部分信息分解的“表示复杂度”度量，用于量化跨多个神经元扩散的信息访问难度，并证明了其实用性。 |
| [^37] | [The Selectively Adaptive Lasso.](http://arxiv.org/abs/2205.10697) | 本文提出了一种新算法——Selectively Adaptive Lasso（SAL），它基于HAL的理论构建，保留了无维度、非参数收敛速率的优点，同时也具有可扩展到大规模高维数据集的能力。这种算法将许多回归系数自动设置为零。 |
| [^38] | [PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks.](http://arxiv.org/abs/2204.05731) | PyDTS是一个用于离散时间生存数据半参数竞争风险模型的Python包，支持包括LASSO和弹性网等正则化回归方法。 |
| [^39] | [Optimality and complexity of classification by random projection.](http://arxiv.org/abs/2108.06339) | 本文研究了一组低复杂度分类器，该分类器可以近似于任意连续函数和布尔函数，且在给定类条件密度的情况下，其误差与最优误差相同。 |
| [^40] | [Epistemic Neural Networks.](http://arxiv.org/abs/2107.08924) | 该论文提出了一种能够通过适量级别的递增计算来估计神经网络不确定性的Epistemic神经网络框架，使得传统神经网络能够在计算成本大幅下降的情况下超越大型集成模型，为模型联合预测的方法提供了一种新的接口。 |
| [^41] | [Universal Approximation Properties for an ODENet and a ResNet: Mathematical Analysis and Numerical Experiments.](http://arxiv.org/abs/2101.10229) | 本论文证明了对于一类ODENet和一类ResNet，“宽度为n+m的ODENet可以逼近${\rm \mathbb{R}^n}$上紧致子集上的任何连续函数”，同时推导了损失函数对某个调整变量的梯度并用于构建ODENet的学习算法，并在MNIST上进行实验。 |
| [^42] | [Optimal No-regret Learning in Repeated First-price Auctions.](http://arxiv.org/abs/2003.09795) | 本文提出了重复首价拍卖的最优无悔学习算法，通过利用特定的反馈结构和支付函数，实现了接近最优的遗憾界限。 |
| [^43] | [Open-set learning with augmented category by exploiting unlabeled data (Open-LACU).](http://arxiv.org/abs/2002.01368) | Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。 |

# 详细

[^1]: 线性回归中依赖数据的噪声水平研究

    The noise level in linear regression with dependent data. (arXiv:2305.11165v1 [cs.LG])

    [http://arxiv.org/abs/2305.11165](http://arxiv.org/abs/2305.11165)

    本文研究了具有依赖数据的线性回归中的噪声水平，提出了上限界限，并在误差规范下表现出优雅的降低。

    

    我们从未做任何实现假设出发，对于具有依赖($\beta$-mixing)数据的随机设计线性回归，推导了其上限界限。与仅在可实现的鞅噪声范围内不可用尖锐的实例最优非渐近性相比，文献中没有可用的上限界限。在恰当的常数因素下，我们的分析正确地回归了中心极限定理预测的方差项 - 问题的噪声水平 - 并因此在引入错误规范时表现出逐渐降低的优雅性。在预燃条件下，我们的结果在中度偏差范围内是尖锐的，特别是不会膨胀引领项期限与混合时间因素。

    We derive upper bounds for random design linear regression with dependent ($\beta$-mixing) data absent any realizability assumptions. In contrast to the strictly realizable martingale noise regime, no sharp instance-optimal non-asymptotics are available in the literature. Up to constant factors, our analysis correctly recovers the variance term predicted by the Central Limit Theorem -- the noise level of the problem -- and thus exhibits graceful degradation as we introduce misspecification. Past a burn-in, our result is sharp in the moderate deviations regime, and in particular does not inflate the leading order term by mixing time factors.
    
[^2]: 探索抱抱脸ML模型的碳足迹：一项存储库挖掘研究

    Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study. (arXiv:2305.11164v1 [cs.LG])

    [http://arxiv.org/abs/2305.11164](http://arxiv.org/abs/2305.11164)

    本论文通过分析Hugging Face上1,417个ML模型及相关数据集的碳足迹测量情况，提出了有关如何报告和优化ML模型的碳效率的见解和建议。

    

    机器学习(ML)系统的崛起加剧了它们的碳足迹，这是由于其增加的能力和模型大小所致。然而，目前对ML模型的碳足迹如何实际测量、报告和评估的认识相对较少。因此，本论文旨在分析在Hugging Face上1,417个ML模型和相关数据集的碳足迹测量情况，Hugging Face是最受欢迎的预训练ML模型的存储库。目标是提供有关如何报告和优化ML模型的碳效率的见解和建议。该研究包括Hugging Face Hub API上有关碳排放的第一项存储库挖掘研究。本研究旨在回答两个研究问题：(1) ML模型的创建者如何在Hugging Face Hub上测量和报告碳排放？(2) 哪些方面影响了训练ML模型的碳排放？该研究得出了几个关键发现。其中包括碳排放报告模式比例的逐步下降等。

    The rise of machine learning (ML) systems has exacerbated their carbon footprint due to increased capabilities and model sizes. However, there is scarce knowledge on how the carbon footprint of ML models is actually measured, reported, and evaluated. In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models. The goal is to provide insights and recommendations on how to report and optimize the carbon efficiency of ML models. The study includes the first repository mining study on the Hugging Face Hub API on carbon emissions. This study seeks to answer two research questions: (1) how do ML model creators measure and report carbon emissions on Hugging Face Hub?, and (2) what aspects impact the carbon emissions of training ML models? The study yielded several key findings. These include a decreasing proportion of carbon emissions-reporting mode
    
[^3]: 在线学习者的攻击：一项教师-学生分析

    Attacks on Online Learners: a Teacher-Student Analysis. (arXiv:2305.11132v1 [stat.ML])

    [http://arxiv.org/abs/2305.11132](http://arxiv.org/abs/2305.11132)

    本文利用控制理论的视角研究了在线学习环境下可能遭受到的标签扰动攻击情况，得出攻击强度超过临界阈值时学习准确率将出现不连续转变的结论，并验证了理论在复杂结构学习器上的适用性。

    

    机器学习模型通常容易受到对抗性攻击：数据的微小扰动可能会使模型的预测结果产生灾难性的影响。虽然大量的文献研究了对已经预先训练的模型进行测试时的攻击情况，但在线学习环境下的攻击情况却鲜有研究。本文使用控制理论的视角研究了在线学习者可能存在的标签扰动攻击情况，考虑了不同的攻击策略，并针对简单线性学习器的稳态获得了分析结果。这些结果可以证明，当攻击强度超过临界阈值时，学习器的准确率会出现不连续的转变。然后我们使用真实数据对复杂结构的学习器进行了实证分析，验证了理论分析的洞见并揭示了遭受攻击的学习器的新行为。

    Machine learning models are famously vulnerable to adversarial attacks: small ad-hoc perturbations of the data that can catastrophically alter the model predictions. While a large literature has studied the case of test-time attacks on pre-trained models, the important case of attacks in an online learning setting has received little attention so far. In this work, we use a control-theoretical perspective to study the scenario where an attacker may perturb data labels to manipulate the learning dynamics of an online learner. We perform a theoretical analysis of the problem in a teacher-student setup, considering different attack strategies, and obtaining analytical results for the steady state of simple linear learners. These results enable us to prove that a discontinuous transition in the learner's accuracy occurs when the attack strength exceeds a critical threshold. We then study empirically attacks on learners with complex architectures using real data, confirming the insights of 
    
[^4]: 先验-数据拟合网络的统计学基础

    Statistical Foundations of Prior-Data Fitted Networks. (arXiv:2305.11097v1 [stat.ML])

    [http://arxiv.org/abs/2305.11097](http://arxiv.org/abs/2305.11097)

    先验-数据拟合网络是一种新的机器学习范例，通过离线预训练固定的模型，然后在任意大小和分布的新训练集上推断类概率，并在与预训练所用大小相似的任务上实现了最先进的性能, 且准确性在推断过程中进一步提高。

    

    先验-数据拟合网络 (PFNs) 最近被提出作为一种新的机器学习范例。与将网络训练到观察到的训练集不同，一个固定的模型在各种任务的小型模拟训练集上进行离线预训练。然后，预训练的模型用于在任意大小和分布的新训练集上推断类概率。从经验上来看，当用于与预训练所用大小相似的任务时，PFNs 实现了最先进的性能。令人惊讶的是，在推断过程中，当传递较大的数据集时，其准确性进一步提高。本文为 PFNs 建立了一个理论基础并阐明了控制它们行为的统计机制。虽然 PFNs 受贝叶斯思想的启发，但将 PFNs 完全解释为预调的未经训练的预测器的频率解释可以解释它们的行为。如果预测器对单个训练样本敏感性降低，那么其方差也会降为零，而偏差只有当误差和导致函数归于常数时才会消失。

    Prior-data fitted networks (PFNs) were recently proposed as a new paradigm for machine learning. Instead of training the network to an observed training set, a fixed model is pre-trained offline on small, simulated training sets from a variety of tasks. The pre-trained model is then used to infer class probabilities in-context on fresh training sets with arbitrary size and distribution. Empirically, PFNs achieve state-of-the-art performance on tasks with similar size to the ones used in pre-training. Surprisingly, their accuracy further improves when passed larger data sets during inference. This article establishes a theoretical foundation for PFNs and illuminates the statistical mechanisms governing their behavior. While PFNs are motivated by Bayesian ideas, a purely frequentistic interpretation of PFNs as pre-tuned, but untrained predictors explains their behavior. A predictor's variance vanishes if its sensitivity to individual training samples does and the bias vanishes only if it
    
[^5]: Tikhonov和RKHS正则化的小噪声分析

    Small noise analysis for Tikhonov and RKHS regularizations. (arXiv:2305.11055v1 [stat.ML])

    [http://arxiv.org/abs/2305.11055](http://arxiv.org/abs/2305.11055)

    该研究建立了一个小噪声分析框架，揭示了传统L2正则化范数的潜在不稳定性，并提出了一种自适应分数阶RKHS正则化器类来解决不稳定性，这些正则化器始终产生最佳的收敛速率。

    

    正则化在机器学习和反问题中起着至关重要的作用。然而，各种正则化范数的基本比较分析仍然未解决。我们建立了一个小噪声分析框架，以评估Tikhonov和RKHS正则化范数在高斯噪声的不适定线性反问题中的效果。该框架研究了正则化估计器在小噪声极限下的收敛速率，并揭示了传统L2正则化的潜在不稳定性。我们通过提出一种创新的自适应分数阶RKHS正则化器类来解决这种不稳定性，通过调整分数光滑度参数，该类覆盖了L2 Tikhonov和RKHS正则化器。一个令人惊奇的观点是，通过这些分数阶RKHS进行过度平滑始终产生最佳的收敛速率，但最佳的超参数可能衰减得太快而无法在实践中进行选择。

    Regularization plays a pivotal role in ill-posed machine learning and inverse problems. However, the fundamental comparative analysis of various regularization norms remains open. We establish a small noise analysis framework to assess the effects of norms in Tikhonov and RKHS regularizations, in the context of ill-posed linear inverse problems with Gaussian noise. This framework studies the convergence rates of regularized estimators in the small noise limit and reveals the potential instability of the conventional L2-regularizer. We solve such instability by proposing an innovative class of adaptive fractional RKHS regularizers, which covers the L2 Tikhonov and RKHS regularizations by adjusting the fractional smoothness parameter. A surprising insight is that over-smoothing via these fractional RKHSs consistently yields optimal convergence rates, but the optimal hyper-parameter may decay too fast to be selected in practice.
    
[^6]: DC规划算法在子模最小化问题上的应用

    Difference of Submodular Minimization via DC Programming. (arXiv:2305.11046v1 [cs.LG])

    [http://arxiv.org/abs/2305.11046](http://arxiv.org/abs/2305.11046)

    本文介绍了一种新的算法，利用DC规划算法来解决子模最小化问题，并证明收敛性质比现有算法更全面，同时在语音特征选择和文档摘要等应用中取得更好的性能。

    

    在各种机器学习问题中，最小化两个子模（DS）函数的差异是一个自然产生的问题。虽然已经有人知道DS问题可以等价地转化为两个凸（DC）函数的差异最小化问题，但现有算法并没有充分利用这种联系。对于DC问题，一个经典的算法叫做DC算法（DCA）。我们介绍了DCA及其完整形式（CDCA）的变体，并将其应用于对应于DS最小化的DC程序中。我们扩展了DCA的现有收敛性质，并将它们与DS问题的收敛性质联系起来。我们的DCA结果与现有的DS算法满足相同的理论保证，同时提供了更完整的收敛性质描述。对于CDCA的情况，我们获得了更强的局部最小保证。我们的数字实验结果表明，我们提出的算法在两个应用——语音语料库选择特征优化和文档摘要中均优于现有的基线算法。

    Minimizing the difference of two submodular (DS) functions is a problem that naturally occurs in various machine learning problems. Although it is well known that a DS problem can be equivalently formulated as the minimization of the difference of two convex (DC) functions, existing algorithms do not fully exploit this connection. A classical algorithm for DC problems is called the DC algorithm (DCA). We introduce variants of DCA and its complete form (CDCA) that we apply to the DC program corresponding to DS minimization. We extend existing convergence properties of DCA, and connect them to convergence properties on the DS problem. Our results on DCA match the theoretical guarantees satisfied by existing DS algorithms, while providing a more complete characterization of convergence properties. In the case of CDCA, we obtain a stronger local minimality guarantee. Our numerical results show that our proposed algorithms outperform existing baselines on two applications: speech corpus sel
    
[^7]: 一种信息论通用泛化界统一框架

    A unified framework for information-theoretic generalization bounds. (arXiv:2305.11042v1 [cs.LG])

    [http://arxiv.org/abs/2305.11042](http://arxiv.org/abs/2305.11042)

    该论文提出了一种基于概率去相关引理和概率测度空间中一些其他技术的通用方法，可以得到新的学习算法的信息论泛化上限，并且能够恢复许多现有的泛化界，如基于互信息、条件互信息、随机chaining和PAC-Bayes不等式的界。

    

    本文提出了一种通用的方法来导出学习算法的信息论泛化界。主要的技术工具是基于改变测度和松弛Young不等式在$L_{\psi_p}$Orlicz空间中的概率去相关性引理。采用去相关性引理与其他技术，如对称化、耦合和概率测度空间中的chaining，我们得到了新的泛化误差上限，包括期望和高概率，同时，我们也恢复了许多现有的泛化界，包括基于互信息、条件互信息、随机chaining和PAC-Bayes不等式的界。此外，Fernique-Talagrand上界也作为一种特殊情况呈现出来。

    This paper presents a general methodology for deriving information-theoretic generalization bounds for learning algorithms. The main technical tool is a probabilistic decorrelation lemma based on a change of measure and a relaxation of Young's inequality in $L_{\psi_p}$ Orlicz spaces. Using the decorrelation lemma in combination with other techniques, such as symmetrization, couplings, and chaining in the space of probability measures, we obtain new upper bounds on the generalization error, both in expectation and in high probability, and recover as special cases many of the existing generalization bounds, including the ones based on mutual information, conditional mutual information, stochastic chaining, and PAC-Bayes inequalities. In addition, the Fernique-Talagrand upper bound on the expected supremum of a subgaussian process emerges as a special case.
    
[^8]: 去噪自编码器的高维渐近分析

    High-dimensional Asymptotics of Denoising Autoencoders. (arXiv:2305.11041v1 [cs.LG])

    [http://arxiv.org/abs/2305.11041](http://arxiv.org/abs/2305.11041)

    本文研究了去噪自编码器在高维极限下的性能表现，得出了去噪均方测试误差的闭式表达式，并揭示了有跳跃连接的自编码器相较于传统自编码器的优越性。

    

    本文研究应用带有绑定权重和跳跃连接的二层非线性自编码器来去噪高斯混合数据的问题。我们在高维极限下考虑，其中训练样本数和输入维数共同趋向于无穷大，而隐藏单元数保持有限。我们提供了去噪均方测试误差的闭式表达式。基于这个结果，我们定量地表征了所考虑的架构在自编码器（没有关联到主成分分析）的跳跃连接相关性之上的优势。此外，我们进一步证明了我们的结果准确地捕捉了一系列真实数据集上的学习曲线。

    We address the problem of denoising data from a Gaussian mixture using a two-layer non-linear autoencoder with tied weights and a skip connection. We consider the high-dimensional limit where the number of training samples and the input dimension jointly tend to infinity while the number of hidden units remains bounded. We provide closed-form expressions for the denoising mean-squared test error. Building on this result, we quantitatively characterize the advantage of the considered architecture over the autoencoder without the skip connection that relates closely to principal component analysis. We further show that our results accurately capture the learning curves on a range of real data sets.
    
[^9]: 乐观自然策略梯度：一种简单高效的在线强化学习策略优化框架

    Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework for Online RL. (arXiv:2305.11032v1 [cs.LG])

    [http://arxiv.org/abs/2305.11032](http://arxiv.org/abs/2305.11032)

    本文提出了一种乐观自然策略梯度的在线强化学习策略优化框架，采用乐观策略评估子程序以鼓励探索，适用于线性MDP，样本复杂度具有最优维度依赖关系。

    

    尽管策略优化算法对于近期强化学习的实证成功发挥了重要作用，但策略优化的现有理论理解仍然相当有限 - 它们要么局限于表格MDP，要么在在线强化学习中存在高度亚最优的样本复杂度问题。本文提出了一种简单高效的在线强化学习策略优化框架 - 乐观自然策略梯度。乐观自然策略梯度可以看作是将经典自然策略梯度算法[Kakade，2001]与乐观策略评估子程序简单组合以鼓励探索。对于$d$-维线性MDP，乐观自然策略梯度具有计算效率，并且在$\tilde{O}(d^2/\varepsilon^3)$ 次采样内学习 $\varepsilon$ -最优策略，这是第一个具有最优维度依赖关系$\tilde {\Theta}(d^2)$样本复杂度的计算高效算法。它也超越了目前领先的一些状态of-the-art算法。

    While policy optimization algorithms have played an important role in recent empirical success of Reinforcement Learning (RL), the existing theoretical understanding of policy optimization remains rather limited -- they are either restricted to tabular MDPs or suffer from highly suboptimal sample complexity, especial in online RL where exploration is necessary. This paper proposes a simple efficient policy optimization framework -- Optimistic NPG for online RL. Optimistic NPG can be viewed as simply combining of the classic natural policy gradient (NPG) algorithm [Kakade, 2001] with optimistic policy evaluation subroutines to encourage exploration. For $d$-dimensional linear MDPs, Optimistic NPG is computationally efficient, and learns an $\varepsilon$-optimal policy within $\tilde{O}(d^2/\varepsilon^3)$ samples, which is the first computationally efficient algorithm whose sample complexity has the optimal dimension dependence $\tilde{\Theta}(d^2)$. It also improves over state-of-the-a
    
[^10]: 拍卖设计中的模式连通性

    Mode Connectivity in Auction Design. (arXiv:2305.11005v1 [cs.GT])

    [http://arxiv.org/abs/2305.11005](http://arxiv.org/abs/2305.11005)

    该论文研究了拍卖设计领域的一个基本问题，即最优拍卖设计。在研究中，作者证明了神经网络在一定条件下可以通过简单的分段线性路径连接不同的局部最优解，并取得了成功。

    

    最优拍卖设计是算法博弈论中的一个基本问题，即使在非常简单的情况下，这个问题也很难。最近不同的经济学可微分理论表明，神经网络可以有效地学习已知的最优拍卖机制，发现有趣的新机制。为了理论上证明它们的实证成功，我们聚焦于第一个这样的网络，RochetNet，并研究所谓的仿射极大化拍卖的广义版本。我们证明它们满足模式连通性，即局部最优解通过一个简单的分段线性路径连接，路径上的每个解都几乎和两个局部最优解之一一样好。模式连通性最近被证明是神经网络用于预测问题的一个有趣的经验和理论的属性。我们的结果是对可微分经济学领域中神经网络用于解决非线性设计问题的第一个这样的分析。

    Optimal auction design is a fundamental problem in algorithmic game theory. This problem is notoriously difficult already in very simple settings. Recent work in differentiable economics showed that neural networks can efficiently learn known optimal auction mechanisms and discover interesting new ones. In an attempt to theoretically justify their empirical success, we focus on one of the first such networks, RochetNet, and a generalized version for affine maximizer auctions. We prove that they satisfy mode connectivity, i.e., locally optimal solutions are connected by a simple, piecewise linear path such that every solution on the path is almost as good as one of the two local optima. Mode connectivity has been recently investigated as an intriguing empirical and theoretically justifiable property of neural networks used for prediction problems. Our results give the first such analysis in the context of differentiable economics, where neural networks are used directly for solving non-
    
[^11]: 利用高斯过程的非线性动态期限结构模型

    Dynamic Term Structure Models with Nonlinearities using Gaussian Processes. (arXiv:2305.11001v1 [stat.AP])

    [http://arxiv.org/abs/2305.11001](http://arxiv.org/abs/2305.11001)

    本研究提出了一种广义建模方法，在动态期限结构模型中引入了高斯过程先验来建模非线性关联，以此进行预测和动态投资组合优化，相比过去仅考虑线性相互作用，反映了更加真实的经济关系。

    

    文献中广泛讨论了宏观经济变量对动态期限结构模型的重要性。到目前为止，以往的研究仅考虑了DTSM中经济和利率实际动态之间的线性相互作用。我们提出了一种广义建模方法，利用高斯DTSM，允许两者之间的非线性关联。我们利用这种建模方式进行预测，并构建自定义的顺序蒙特卡洛估计和预测方案，引入高斯过程先验来建模非线性关联。建议的顺序方案也可用于动态投资组合优化，以评估为投资者创造的经济价值潜力。我们使用美国国债数据和选定的宏观经济指标，特别是核心通胀和真实经济活动来展示这种方法。我们将非线性模型的结果与仅考虑线性相互作用的模型的结果进行对比。

    The importance of unspanned macroeconomic variables for Dynamic Term Structure Models has been intensively discussed in the literature. To our best knowledge the earlier studies considered only linear interactions between the economy and the real-world dynamics of interest rates in DTSMs. We propose a generalized modelling setup for Gaussian DTSMs which allows for unspanned nonlinear associations between the two and we exploit it in forecasting. Specifically, we construct a custom sequential Monte Carlo estimation and forecasting scheme where we introduce Gaussian Process priors to model nonlinearities. Sequential scheme we propose can also be used with dynamic portfolio optimization to assess the potential of generated economic value to investors. The methodology is presented using US Treasury data and selected macroeconomic indices. Namely, we look at core inflation and real economic activity. We contrast the results obtained from the nonlinear model with those stemming from an appli
    
[^12]: 超越数据重新加权：核矩法估计

    Estimation Beyond Data Reweighting: Kernel Method of Moments. (arXiv:2305.10898v1 [cs.LG])

    [http://arxiv.org/abs/2305.10898](http://arxiv.org/abs/2305.10898)

    本论文提出了一种新的核矩法估计器，称为KMM，其用于超越数据重新加权的矩方法模型，解除了关于使用 $\varphi$-散度相关的限制。

    

    在机器学习与统计学等多个领域中都会出现矩约束和条件对应，其中，广义矩法（GMM）作为一个估计模型已经引起了人们的关注。然而，往往由于使用 $\varphi$-散度的相关限制将候选分布限制为数据样本的重新加权。而本论文提出了一种新的矩估计方法——基于最大均值偏差的经验似然估计器，即核矩法(KMM)，其实现超越了对数据的重新加权。

    Moment restrictions and their conditional counterparts emerge in many areas of machine learning and statistics ranging from causal inference to reinforcement learning. Estimators for these tasks, generally called methods of moments, include the prominent generalized method of moments (GMM) which has recently gained attention in causal inference. GMM is a special case of the broader family of empirical likelihood estimators which are based on approximating a population distribution by means of minimizing a $\varphi$-divergence to an empirical distribution. However, the use of $\varphi$-divergences effectively limits the candidate distributions to reweightings of the data samples. We lift this long-standing limitation and provide a method of moments that goes beyond data reweighting. This is achieved by defining an empirical likelihood estimator based on maximum mean discrepancy which we term the kernel method of moments (KMM). We provide a variant of our estimator for conditional moment
    
[^13]: 分类器最小风险重新校准

    Minimum-Risk Recalibration of Classifiers. (arXiv:2305.10886v1 [cs.LG])

    [http://arxiv.org/abs/2305.10886](http://arxiv.org/abs/2305.10886)

    本文介绍了最小风险重新校准的概念，在均方误差分解框架内提供了一种原则性方法，用于评估和重新校准概率分类器，并通过平衡校准和锐度确定了最优的桶数，从而产生了大约$O(n^{-2/3})$的风险上界。

    

    重新校准概率分类器对于提高预测模型的可靠性和准确性至关重要。尽管已经开发了许多重新校准算法，但仍缺乏一个综合的理论来整合校准和锐度（这对于保持预测力至关重要）。在本文中，我们在均方误差（MSE）分解框架内介绍了最小风险重新校准的概念，提供了一种评估和重新校准概率分类器的原则性方法。利用这个框架，我们分析了均匀质量分桶（UMB）重新校准方法，并建立了一个有限样本风险上界，其顺序为$\tilde{O}(B/n+1/B^2)$，其中$B$是桶的数量，$n$是样本大小。通过平衡校准和锐度，我们进一步确定了UMB的最优桶数与$n^{1/3}$成比例，从而产生了大约$O(n^{-2/3})$的风险界。此外，我们还应对了标签稀少问题。

    Recalibrating probabilistic classifiers is vital for enhancing the reliability and accuracy of predictive models. Despite the development of numerous recalibration algorithms, there is still a lack of a comprehensive theory that integrates calibration and sharpness (which is essential for maintaining predictive power). In this paper, we introduce the concept of minimum-risk recalibration within the framework of mean-squared-error (MSE) decomposition, offering a principled approach for evaluating and recalibrating probabilistic classifiers. Using this framework, we analyze the uniform-mass binning (UMB) recalibration method and establish a finite-sample risk upper bound of order $\tilde{O}(B/n + 1/B^2)$ where $B$ is the number of bins and $n$ is the sample size. By balancing calibration and sharpness, we further determine that the optimal number of bins for UMB scales with $n^{1/3}$, resulting in a risk bound of approximately $O(n^{-2/3})$. Additionally, we tackle the challenge of label
    
[^14]: 针对非稳态赌博机问题的折扣汤普森抽样算法

    Discounted Thompson Sampling for Non-Stationary Bandit Problems. (arXiv:2305.10718v1 [cs.LG])

    [http://arxiv.org/abs/2305.10718](http://arxiv.org/abs/2305.10718)

    该论文提出了一种针对非稳态多臂赌博机问题的折扣汤普森抽样算法（DS-TS），可以解决突然性变化和平滑性变化的问题，并且在两种情况下具有近乎最优的遗憾上限。

    

    近年来，非稳态多臂赌博机问题受到了显著关注。NS-MAB通常在两种情况下进行建模：突然性变化和平滑性变化。在本文中，我们提出了带有高斯先验的折扣汤普森采样算法（DS-TS）以解决这两个非稳态设置。我们的算法通过将折扣因子纳入汤普森采样来被动适应变化。DS-TS方法经过实验验证，但缺乏对遗憾上限的分析。在温和的假设下，我们证明了带有高斯先验的DS-TS可以在突然性变化的情况下实现近乎最优的遗憾上限（$\tilde{O} (\sqrt {TB_T})$），在平滑性变化的情况下实现 $\tilde{O}(T^{\beta})$ 的近乎最优遗憾上限，其中 $T$ 是时间步数，$B_T$ 是断点数，$\beta$ 与收益分布的平滑性有关，$\tilde{O}$ 是对数遗憾上限。

    Non-stationary multi-armed bandit (NS-MAB) problems have recently received significant attention. NS-MAB are typically modelled in two scenarios: abruptly changing, where reward distributions remain constant for a certain period and change at unknown time steps, and smoothly changing, where reward distributions evolve smoothly based on unknown dynamics. In this paper, we propose Discounted Thompson Sampling (DS-TS) with Gaussian priors to address both non-stationary settings. Our algorithm passively adapts to changes by incorporating a discounted factor into Thompson Sampling. DS-TS method has been experimentally validated, but analysis of the regret upper bound is currently lacking. Under mild assumptions, we show that DS-TS with Gaussian priors can achieve nearly optimal regret bound on the order of $\tilde{O}(\sqrt{TB_T})$ for abruptly changing and $\tilde{O}(T^{\beta})$ for smoothly changing, where $T$ is the number of time steps, $B_T$ is the number of breakpoints, $\beta$ is asso
    
[^15]: 异构群体强化学习中的福音：线性加速和更多可能

    The Blessing of Heterogeneity in Federated Q-learning: Linear Speedup and Beyond. (arXiv:2305.10697v1 [cs.LG])

    [http://arxiv.org/abs/2305.10697](http://arxiv.org/abs/2305.10697)

    本文提出了异构群体强化学习中联邦Q学习的样本复杂度保证，讨论了同步和异步版本的线性加速，同时探究了等权重平均本地Q估计的缺陷。

    

    当强化学习（RL）的数据由多个代理以分布式方式收集时，联邦RL算法允许协作学习，无需共享本地数据。本文考虑联邦Q学习，其目的是通过定期聚合仅在本地数据上训练的本地Q估计来学习最优Q函数。针对无限时间蒸馏标记决策过程，我们为同步和异步版本的联邦Q学习提供了样本复杂度保证。在两种情况下，我们的界限展示了与代理数量成线性加速以及其他显著问题参数的更尖锐的依赖关系。此外，现有的联邦Q学习方法采用等权重平均本地Q估计，这在异步设置中可能会高度次优，因为由于不同的本地行为策略，本地轨迹可能高度异构。现有的样本最优化策略在异步设置中存在巨大缺陷。

    When the data used for reinforcement learning (RL) are collected by multiple agents in a distributed manner, federated versions of RL algorithms allow collaborative learning without the need of sharing local data. In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning. In both cases, our bounds exhibit a linear speedup with respect to the number of agents and sharper dependencies on other salient problem parameters. Moreover, existing approaches to federated Q-learning adopt an equally-weighted averaging of local Q-estimates, which can be highly sub-optimal in the asynchronous setting since the local trajectories can be highly heterogeneous due to different local behavior policies. Existing sample com
    
[^16]: 权重具有无界方差的无限宽贝叶斯神经网络后验推断

    Posterior Inference on Infinitely Wide Bayesian Neural Networks under Weights with Unbounded Variance. (arXiv:2305.10664v1 [stat.ML])

    [http://arxiv.org/abs/2305.10664](http://arxiv.org/abs/2305.10664)

    本文提出了一种新的方法进行关于具有无界方差权重的贝叶斯神经网络的后验推断，并表明后验分布集中在具有非标准超参数依赖性的稀疏促进和均值收缩先验周围。

    

    由Neal（1996）的经典而有影响力的作品已知，具有一层隐藏层的贝叶斯神经网络的无限宽度标度极限是一个高斯过程，当网络权重具有有界先验方差时。Neal的结果已扩展到具有多个隐藏层和卷积神经网络的网络，也具有高斯过程标度极限。高斯过程的易处理属性允许直接的后验推断和不确定性量化，相比有限宽度的网络，极大地简化了极限过程的研究。然而，具有无界方差的神经网络权重面临着独特的挑战。在这种情况下，经典的中心极限定理失效，据适当条件下的稳定$\alpha$过程的标度极限的文献较多的是前向模拟，而在这些权重下的后验推断问题仍然是一个未解决的问题。在本文中，我们提出了关于具有无界方差权重的贝叶斯神经网络后验推断的新理论洞察力。具体而言，我们建立了一种新的后验收缩速率结果，并表明后验分布集中在具有非标准超参数依赖性的稀疏促进和均值收缩先验周围。

    From the classical and influential works of Neal (1996), it is known that the infinite width scaling limit of a Bayesian neural network with one hidden layer is a Gaussian process, \emph{when the network weights have bounded prior variance}. Neal's result has been extended to networks with multiple hidden layers and to convolutional neural networks, also with Gaussian process scaling limits. The tractable properties of Gaussian processes then allow straightforward posterior inference and uncertainty quantification, considerably simplifying the study of the limit process compared to a network of finite width. Neural network weights with unbounded variance, however, pose unique challenges. In this case, the classical central limit theorem breaks down and it is well known that the scaling limit is an $\alpha$-stable process under suitable conditions. However, current literature is primarily limited to forward simulations under these processes and the problem of posterior inference under s
    
[^17]: 增强的消息传递斯坦变分梯度下降法

    Augmented Message Passing Stein Variational Gradient Descent. (arXiv:2305.10636v1 [cs.LG])

    [http://arxiv.org/abs/2305.10636](http://arxiv.org/abs/2305.10636)

    本文提出了一种增强的消息传递斯坦变分梯度下降法(AUMP-SVGD)来应对 Stein Variational Gradient Descent (SVGD)方法的方差崩溃问题，我们的算法能够提高SVGD在高维问题中的有效性。

    

    Stein Variational Gradient Descent (SVGD)是一种用于贝叶斯推理的基于粒子的流行方法。然而，它的收敛性遭受方差崩溃的影响，这会降低估计的准确性和多样性。本文研究了收敛过程中有限粒子的等向性属性，表明有限粒子的SVGD无法在整个样本空间中传播。相反，所有粒子倾向于在一定范围内聚集在粒子中心周围，并且我们提供了此聚类的分析界限。为进一步改善SVGD在高维问题中的有效性，我们提出了增强消息传递斯坦变分梯度下降法(AUMP-SVGD)方法，这是一种两阶段优化过程，不需要目标分布的稀疏性，不像MP-SVGD方法。我们的算法在各种基准问题中实现了令人满意的准确性，并克服了方差崩溃问题。

    Stein Variational Gradient Descent (SVGD) is a popular particle-based method for Bayesian inference. However, its convergence suffers from the variance collapse, which reduces the accuracy and diversity of the estimation. In this paper, we study the isotropy property of finite particles during the convergence process and show that SVGD of finite particles cannot spread across the entire sample space. Instead, all particles tend to cluster around the particle center within a certain range and we provide an analytical bound for this cluster. To further improve the effectiveness of SVGD for high-dimensional problems, we propose the Augmented Message Passing SVGD (AUMP-SVGD) method, which is a two-stage optimization procedure that does not require sparsity of the target distribution, unlike the MP-SVGD method. Our algorithm achieves satisfactory accuracy and overcomes the variance collapse problem in various benchmark problems.
    
[^18]: 平滑化风景可提升SGD信号：学习单指数模型的最优样本复杂度研究

    Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample Complexity for Learning Single Index Models. (arXiv:2305.10633v1 [cs.LG])

    [http://arxiv.org/abs/2305.10633](http://arxiv.org/abs/2305.10633)

    本文提出了使用平滑化的损失来优化在线SGD的信号，可以使用$n \gtrsim d^{k^\star/2}$个样本学习单指数模型$w^\star$，并与张量PCA和小批量SGD的正则化效应有关。

    

    本文研究了在$d$维度上使用各向同性高斯分布来学习单指数模型$\sigma(w^\star \cdot x)$的任务。先前的研究表明，学习$w^\star$的样本复杂度是由链接函数$\sigma$的信息指数$k^\star$所决定的，它被定义为$\sigma$的第一个非零Hermite系数的指数。本文通过展示基于平滑损失的在线SGD使用$n \gtrsim d^{k^\star/2}$个样本可以学习$w^\star$，弥补了上下界之间的差距。作者还将其与张量PCA的统计分析和小批量SGD在经验损失上的隐式正则化效应联系起来。

    We focus on the task of learning a single index model $\sigma(w^\star \cdot x)$ with respect to the isotropic Gaussian distribution in $d$ dimensions. Prior work has shown that the sample complexity of learning $w^\star$ is governed by the information exponent $k^\star$ of the link function $\sigma$, which is defined as the index of the first nonzero Hermite coefficient of $\sigma$. Ben Arous et al. (2021) showed that $n \gtrsim d^{k^\star-1}$ samples suffice for learning $w^\star$ and that this is tight for online SGD. However, the CSQ lower bound for gradient based methods only shows that $n \gtrsim d^{k^\star/2}$ samples are necessary. In this work, we close the gap between the upper and lower bounds by showing that online SGD on a smoothed loss learns $w^\star$ with $n \gtrsim d^{k^\star/2}$ samples. We also draw connections to statistical analyses of tensor PCA and to the implicit regularization effects of minibatch SGD on empirical losses.
    
[^19]: 张量积与超维计算

    Tensor Products and Hyperdimensional Computing. (arXiv:2305.10572v1 [stat.ML])

    [http://arxiv.org/abs/2305.10572](http://arxiv.org/abs/2305.10572)

    本文探索了张量积在超维计算中的数学关系，将其确定为中心表示，并发现它是最通用、最具表现力和最压缩的表示，同时具有无误差解绑和检测的能力。

    

    在之前对图嵌入的分析基础上，我们将一些结果推广和拓展到向量符号结构 (VSA) 和超维计算 (HDC) 的一般设置中。重要的是，我们探索超叠加、正交和张量积之间的数学关系。我们将张量积表示确定为中心表示，并具有一套独特的属性。这包括它是最通用和最具表现力的表示，也是最压缩的表示，具有无误差解绑和检测的能力。

    Following up on a previous analysis of graph embeddings, we generalize and expand some results to the general setting of vector symbolic architectures (VSA) and hyperdimensional computing (HDC). Importantly, we explore the mathematical relationship between superposition, orthogonality, and tensor product. We establish the tensor product representation as the central representation, with a suite of unique properties. These include it being the most general and expressive representation, as well as being the most compressed representation that has errorrless unbinding and detection.
    
[^20]: 对放弃分类器进行反事实比较

    Counterfactually Comparing Abstaining Classifiers. (arXiv:2305.10564v1 [stat.ML])

    [http://arxiv.org/abs/2305.10564](http://arxiv.org/abs/2305.10564)

    本文提出一种新的方法和视角来评估和比较放弃分类器，将放弃预测视为缺失数据。我们定义了放弃分类器的反事实得分，指的是分类器没有放弃预测时的预测性能期望。

    

    放弃分类器可以选择在不确定时放弃对输入的预测。这些分类器在高风险决策问题中越来越受欢迎，因为它们可以保留不确定的预测，以提高其可靠性和安全性。然而，在评估黑盒放弃分类器时，我们缺乏一个原则性的方法来考虑分类器在它的放弃预测上的预测结果。当放射科医生不确定其诊断或当驾驶员在自动驾驶汽车中不注意时，这些缺失的预测结果至关重要。本文引入了一种新的方法和视角来评估和比较放弃分类器，将放弃预测视为缺失数据。我们的评估方法围绕着定义一个放弃分类器的反事实得分，即分类器没有放弃的情况下的预测性能的期望。我们指定了条件... (此处省略)

    Abstaining classifiers have the option to abstain from making predictions on inputs that they are unsure about. These classifiers are becoming increasingly popular in high-stake decision-making problems, as they can withhold uncertain predictions to improve their reliability and safety. When evaluating black-box abstaining classifier(s), however, we lack a principled approach that accounts for what the classifier would have predicted on its abstentions. These missing predictions are crucial when, e.g., a radiologist is unsure of their diagnosis or when a driver is inattentive in a self-driving car. In this paper, we introduce a novel approach and perspective to the problem of evaluating and comparing abstaining classifiers by treating abstentions as missing data. Our evaluation approach is centered around defining the counterfactual score of an abstaining classifier, defined as the expected performance of the classifier had it not been allowed to abstain. We specify the conditions unde
    
[^21]: 使用神经网络分类器学习似然比

    Learning Likelihood Ratios with Neural Network Classifiers. (arXiv:2305.10500v1 [hep-ph])

    [http://arxiv.org/abs/2305.10500](http://arxiv.org/abs/2305.10500)

    该研究介绍了一种使用神经网络分类器参数化计算似然比的技巧，并详细比较了不同设置的性能。这对于许多数据或基于模拟的科学应用非常有用。

    

    在科学中，似然比是统计推断的关键性量，它使得假设检验、置信区间构建、分布加权等成为可能。然而，许多现代科学应用使用基于数据或基于模拟的模型，而计算似然比可能非常困难甚至不可能。通过应用所谓的“似然比技巧”，可以使用聪明的神经网络分类器参数化来计算似然比的近似值。可以定义许多不同的神经网络设置来满足此过程，每个设置在使用有限训练数据时近似似然比的性能各异。我们提出了一系列经验研究，详细介绍了几种常见损失函数和分类器输出参数化在近似两个一元和多元高斯分布的似然比方面的表现以及模拟高能物理的信号和背景事件。

    The likelihood ratio is a crucial quantity for statistical inference in science that enables hypothesis testing, construction of confidence intervals, reweighting of distributions, and more. Many modern scientific applications, however, make use of data- or simulation-driven models for which computing the likelihood ratio can be very difficult or even impossible. By applying the so-called ``likelihood ratio trick,'' approximations of the likelihood ratio may be computed using clever parametrizations of neural network-based classifiers. A number of different neural network setups can be defined to satisfy this procedure, each with varying performance in approximating the likelihood ratio when using finite training data. We present a series of empirical studies detailing the performance of several common loss functionals and parametrizations of the classifier output in approximating the likelihood ratio of two univariate and multivariate Gaussian distributions as well as simulated high-e
    
[^22]: 一种多目标优化的Wasserstein反向强化学习模型的证明

    A proof of imitation of Wasserstein inverse reinforcement learning for multi-objective optimization. (arXiv:2305.10089v1 [cs.LG])

    [http://arxiv.org/abs/2305.10089](http://arxiv.org/abs/2305.10089)

    本文证明了Wasserstein反向强化学习模型适用于多目标优化问题，可让学习者的奖励值和最优解模仿专家，具有一定的实用价值。

    

    本文证明了Wasserstein反向强化学习模型可以在有限次迭代中让学习者的奖励值模仿专家的奖励值，并证明了在词典序的多目标优化中，Wasserstein反向强化学习模型可以让学习者的最优解模仿专家的最优解。

    We prove Wasserstein inverse reinforcement learning enables the learner's reward values to imitate the expert's reward values in a finite iteration for multi-objective optimizations. Moreover, we prove Wasserstein inverse reinforcement learning enables the learner's optimal solutions to imitate the expert's optimal solutions for multi-objective optimizations with lexicographic order.
    
[^23]: 大数据学习：精选包与随机包的对比研究

    Learning from Aggregated Data: Curated Bags versus Random Bags. (arXiv:2305.09557v1 [cs.LG])

    [http://arxiv.org/abs/2305.09557](http://arxiv.org/abs/2305.09557)

    本文研究了两种自然的聚合方法：基于共同特征将数据点分组的精选包和将数据点随机分组的随机包，对于精选包设置和广泛的损失函数范围内，我们展示了可以通过梯度下降学习而不会导致数据聚合导致性能下降的情况。

    

    保护用户隐私是许多机器学习系统部署的一个主要关注点，这些系统收集来自各种群体的数据。为了应对这种问题，一种方法是以聚合的形式收集和发布数据标签，从而可以将单个用户的信息与其他用户的信息组合起来。本文探讨了使用聚合数据标签而非单个标签来训练机器学习模型的可能性，具体来说，我们考虑了两种自然的聚合方法：基于共同特征将数据点分组的精选包和将数据点随机分组的随机包。对于精选包设置和广泛的损失函数范围内，我们展示了可以通过梯度下降学习而不会导致数据聚合导致性能下降的情况。我们的方法基于以下观察：损失函数的梯度之和可以表示为每个包的梯度的加权和，其中权重是包的大小。

    Protecting user privacy is a major concern for many machine learning systems that are deployed at scale and collect from a diverse set of population. One way to address this concern is by collecting and releasing data labels in an aggregated manner so that the information about a single user is potentially combined with others. In this paper, we explore the possibility of training machine learning models with aggregated data labels, rather than individual labels. Specifically, we consider two natural aggregation procedures suggested by practitioners: curated bags where the data points are grouped based on common features and random bags where the data points are grouped randomly in bag of similar sizes. For the curated bag setting and for a broad range of loss functions, we show that we can perform gradient-based learning without any degradation in performance that may result from aggregating data. Our method is based on the observation that the sum of the gradients of the loss functio
    
[^24]: DRew：带延迟的动态重连消息传递

    DRew: Dynamically Rewired Message Passing with Delay. (arXiv:2305.08018v1 [cs.LG])

    [http://arxiv.org/abs/2305.08018](http://arxiv.org/abs/2305.08018)

    本文提出了一种能够应用于任何MPNN结构的框架，执行基于层的动态重连来确保逐渐密集化的图形。同时引入了一种延迟机制，允许跨层节点之间的跳跃连接。

    

    已经证明，消息传递神经网络（MPNN）存在过度压缩现象，导致长程相互作用任务表现不佳。这主要归因于只在节点的相邻居之间进行局部消息传递。试图使图形“更连通”并且更适合长程任务的重连方法通常会失去基于图形距离提供的归纳偏差，因为它们会使远程节点在每一层中立即通信。在本文中，我们提出了一个框架，可应用于任何MPNN架构，以执行基于层的重连，以确保逐渐加密图形。我们还提出了一种延迟机制，它允许根据层和它们的相互距离在节点之间进行跳跃连接。我们在几个长程任务上验证了我们的方法，并表明其优于图形变换器和多跳MPNN。

    Message passing neural networks (MPNNs) have been shown to suffer from the phenomenon of over-squashing that causes poor performance for tasks relying on long-range interactions. This can be largely attributed to message passing only occurring locally, over a node's immediate neighbours. Rewiring approaches attempting to make graphs `more connected', and supposedly better suited to long-range tasks, often lose the inductive bias provided by distance on the graph since they make distant nodes communicate instantly at every layer. In this paper we propose a framework, applicable to any MPNN architecture, that performs a layer-dependent rewiring to ensure gradual densification of the graph. We also propose a delay mechanism that permits skip connections between nodes depending on the layer and their mutual distance. We validate our approach on several long-range tasks and show that it outperforms graph Transformers and multi-hop MPNNs.
    
[^25]: 多目标优化的逆强化学习的收敛性证明研究

    A proof of convergence of inverse reinforcement learning for multi-objective optimization. (arXiv:2305.06137v1 [cs.LG])

    [http://arxiv.org/abs/2305.06137](http://arxiv.org/abs/2305.06137)

    本论文证明了多目标优化的逆强化学习方法在理论层面上的收敛性，包括Wasserstein逆强化学习和常规逆强化学习方法。

    

    本文通过将等效于多目标优化的WIRL问题的逆问题与投影次梯度法相结合，证明了Wasserstein逆强化学习（WIRL）在多目标优化中的收敛性。此外，我们还证明了逆强化学习（最大熵逆强化学习，导引成本学习）在多目标优化中的收敛性。

    We show the convergence of Wasserstein inverse reinforcement learning (WIRL) for multi-objective optimizations with the projective subgradient method by formulating an inverse problem of the optimization problem that is equivalent to WIRL for multi-objective optimizations.  In addition, we prove convergence of inverse reinforcement learning (maximum entropy inverse reinforcement learning, guid cost learning) for multi-objective optimization with the projective subgradient method.
    
[^26]: 利用扰动来改善基于核化斯坦距的拟合优度检验

    Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy. (arXiv:2304.14762v1 [stat.ML])

    [http://arxiv.org/abs/2304.14762](http://arxiv.org/abs/2304.14762)

    本文提出了一种通过在样本中引入扰动，改进基于核化斯坦距的拟合优度检验方法的方法，以解决在同质但混合比例不同的情况下低功率的问题，并展示实验证据证明了该方法的功效。

    

    核化斯坦距（KSD）是一种广泛用于拟合优度检验的基于得分的差异度量。即使目标分布具有未知的标准化因子，例如在贝叶斯分析中，也可以应用它。我们理论上和实验证明，当目标分布和替代分布具有相同且相距较远的模式但在混合比例上有所不同时，KSD检验可能会出现低功率问题。我们提出通过马尔科夫转移核对观测样本进行扰动，使其相对于目标分布不变。这使我们可以在扰动样本上使用KSD检验。我们提供的数值证据表明，使用适当选择的核时，所提出的方法可以比KSD检验具有更高的功率。

    Kernelized Stein discrepancy (KSD) is a score-based discrepancy widely used in goodness-of-fit tests. It can be applied even when the target distribution has an unknown normalising factor, such as in Bayesian analysis. We show theoretically and empirically that the KSD test can suffer from low power when the target and the alternative distribution have the same well-separated modes but differ in mixing proportions. We propose to perturb the observed sample via Markov transition kernels, with respect to which the target distribution is invariant. This allows us to then employ the KSD test on the perturbed sample. We provide numerical evidence that with suitably chosen kernels the proposed approach can lead to a substantially higher power than the KSD test.
    
[^27]: 多项式分类中的稀疏联合偏移

    Sparse joint shift in multinomial classification. (arXiv:2303.16971v1 [stat.ML])

    [http://arxiv.org/abs/2303.16971](http://arxiv.org/abs/2303.16971)

    该论文提出了一种稀疏联合偏移模型，用于解决整体数据集偏移问题，提供了传递SJS、修正类后验概率、SJS的可辨认性、SJS与协变量转移关系等新结果。

    

    稀疏联合偏移（SJS）是一种针对数据集整体偏移的可处理模型，可能会导致特征和标签的边际分布以及后验概率和类条件特征分布的变化。在没有标签观测的情况下，为目标数据集拟合SJS可能会产生标签的有效预测和类先验概率的估计。我们在特征集之间传递SJS方面提供了新的结果，提出了一个基于目标分布的类后验概率的条件修正公式，确定性SJS的可辨认性以及SJS和协变量转移之间的关系。此外，我们指出了用于估计SJS特征的算法中的不一致性，因为它们可能会妨碍寻找最优解。

    Sparse joint shift (SJS) was recently proposed as a tractable model for general dataset shift which may cause changes to the marginal distributions of features and labels as well as the posterior probabilities and the class-conditional feature distributions. Fitting SJS for a target dataset without label observations may produce valid predictions of labels and estimates of class prior probabilities. We present new results on the transmission of SJS from sets of features to larger sets of features, a conditional correction formula for the class posterior probabilities under the target distribution, identifiability of SJS, and the relationship between SJS and covariate shift. In addition, we point out inconsistencies in the algorithms which were proposed for estimating the characteristics of SJS, as they could hamper the search for optimal solutions.
    
[^28]: 基于列表的在线分类

    List Online Classification. (arXiv:2303.15383v1 [cs.LG])

    [http://arxiv.org/abs/2303.15383](http://arxiv.org/abs/2303.15383)

    本文研究了多标签列表的在线预测问题，提出了 $b$-ary Littlestone 维度可学习模型，并且在懵懂的情况下探索不同的情况。可以使用改编自 Littlestone 的 SOA 和 Rosenblatt 的感知器等算法进行预测，同时还建立了列表可学习的组合结果。

    

    我们研究多分类在线预测，其中学习者可以使用多个标签的列表进行预测（与传统设置中仅使用一种标签不同）。我们使用 $b$-ary Littlestone 维度表征了该模型中的可学习性。该维度是经典 Littlestone 维度的变体，其中二进制错误树被替换为 $(k+1)$-ary 错误树，其中 k 是列表中标签的数量。在懵懂的场景中，我们根据比较类中是否包含单标签或多标签函数以及它与算法使用的列表大小之间的权衡来探索不同的情况。我们发现在某些情况下可以实现负悔，同时提供了什么情况下实现负悔的完整特性化。作为我们工作的一部分，我们改编了经典算法，如 Littlestone 的 SOA 和 Rosenblatt 的感知器，以使用标签列表进行预测。我们还为可以进行列表学习的组合结果建立了基础。

    We study multiclass online prediction where the learner can predict using a list of multiple labels (as opposed to just one label in the traditional setting). We characterize learnability in this model using the $b$-ary Littlestone dimension. This dimension is a variation of the classical Littlestone dimension with the difference that binary mistake trees are replaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in the list. In the agnostic setting, we explore different scenarios depending on whether the comparator class consists of single-labeled or multi-labeled functions and its tradeoff with the size of the lists the algorithm uses. We find that it is possible to achieve negative regret in some cases and provide a complete characterization of when this is possible. As part of our work, we adapt classical algorithms such as Littlestone's SOA and Rosenblatt's Perceptron to predict using lists of labels. We also establish combinatorial results for list-learnable c
    
[^29]: 论文标题：认证鲁棒神经网络：泛化和抗污染性

    Certified Robust Neural Networks: Generalization and Corruption Resistance. (arXiv:2303.02251v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.02251](http://arxiv.org/abs/2303.02251)

    该论文提出了一种新颖的分布鲁棒损失函数，该函数通过认证级别的鲁棒性对两种常见的污染类型进行抵抗，并确保泛化保证，从而解决了鲁棒性和泛化之间的矛盾，具有极高的实用性。

    

    最近的研究表明，鲁棒性（对“污染”的抵抗能力）可能与泛化存在矛盾。例如，对抗性训练旨在减少现代神经网络对小数据扰动的敏感性。令人惊讶的是，在对抗训练中，过拟合是一个主要问题，尽管在标准训练中几乎不存在。我们在这里提供了关于这种奇特的“鲁棒过拟合”现象的理论证据。随后，我们提出了一种新颖的分布鲁棒损失函数，将鲁棒性和泛化相结合。我们理论上和实证地证明了该损失具有认证级别的鲁棒性，可以抵抗两种常见的污染类型——数据逃避和攻击——同时确保泛化保证。通过精心设计的数字实验，我们展示了所得到的完整鲁棒（HR）训练程序具有SOTA的性能。最后，我们指出HR训练可以被解释为对抗性训练的直接扩展，并可以自然地应用于GAN和RL。

    Recent work have demonstrated that robustness (to "corruption") can be at odds with generalization. Adversarial training, for instance, aims to reduce the problematic susceptibility of modern neural networks to small data perturbations. Surprisingly, overfitting is a major concern in adversarial training despite being mostly absent in standard training. We provide here theoretical evidence for this peculiar "robust overfitting" phenomenon. Subsequently, we advance a novel distributionally robust loss function bridging robustness and generalization. We demonstrate both theoretically as well as empirically the loss to enjoy a certified level of robustness against two common types of corruption--data evasion and poisoning attacks--while ensuring guaranteed generalization. We show through careful numerical experiments that our resulting holistic robust (HR) training procedure yields SOTA performance. Finally, we indicate that HR training can be interpreted as a direct extension of adversar
    
[^30]: 利用深度增强决策树进行高效欺诈检测

    Efficient Fraud Detection Using Deep Boosting Decision Trees. (arXiv:2302.05918v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.05918](http://arxiv.org/abs/2302.05918)

    本文提出了一种利用深度增强决策树的方法来进行欺诈检测，既可以利用决策树的可解释性，又可以提高神经网络的表示学习能力。同时，采用新的过采样策略来缓解数据不平衡的问题。

    

    欺诈检测是识别、监控和预防复杂数据中的潜在欺诈活动。机器学习提供了一种新的数据驱动方法来处理欺诈行为。本文提出了一种基于梯度增强和神经网络的深度增强决策树（DBDT）方法，它首先构建了软决策树，然后将其嵌入神经网络框架用于最终分类，既可以利用决策树的可解释性，又可以提高神经网络的表示学习能力。此外，我们提出一种新的过采样策略来缓解数据不平衡带来的影响。实验结果表明，我们的方法在准确性、可解释性和效率方面优于现有的最先进方法。

    Fraud detection is to identify, monitor, and prevent potentially fraudulent activities from complex data. The recent development and success in AI, especially machine learning, provides a new data-driven way to deal with fraud. From a methodological point of view, machine learning based fraud detection can be divided into two categories, i.e., conventional methods (decision tree, boosting...) and deep learning, both of which have significant limitations in terms of the lack of representation learning ability for the former and interpretability for the latter. Furthermore, due to the rarity of detected fraud cases, the associated data is usually imbalanced, which seriously degrades the performance of classification algorithms. In this paper, we propose deep boosting decision trees (DBDT), a novel approach for fraud detection based on gradient boosting and neural networks. In order to combine the advantages of both conventional methods and deep learning, we first construct soft decision 
    
[^31]: 探索基于数值先验的广义CP分解低秩张量补全算法

    Exploring Numerical Priors for Low-Rank Tensor Completion with Generalized CP Decomposition. (arXiv:2302.05881v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05881](http://arxiv.org/abs/2302.05881)

    本文提出了一种新的方法框架GCDTC，利用数值先验和广义CP分解实现了更高的低秩张量补全精度；同时介绍了一个算法SPTC，作为该框架的一个实现。在实验中，该方法表现出比现有技术更好的性能。

    

    张量补全在计算机视觉、数据分析和信号处理等领域中具有重要意义。最近，低秩张量补全这一类别的方法得到了广泛研究，对补全张量施加低秩结构。虽然这些方法取得了巨大成功，但尚未考虑到张量元素的数值先验信息。忽略数值先验将导致丢失关于数据的重要信息，因此阻止算法达到最优精度。本研究试图构建一个新的方法框架，名为GCDTC（广义CP分解张量补全），以利用数值先验并实现更高的张量补全精度。在这个新引入的框架中，将广义的CP分解应用于低秩张量补全。本文还提出了一种名为SPTC（平滑泊松张量补全）的算法，用于非负整数张量补全，作为GCDTC框架的一个实现。通过对合成和真实世界数据集的大量实验，证明所提出的方法相比于现有技术具有更优的张量补全性能。

    Tensor completion is important to many areas such as computer vision, data analysis, and signal processing. Enforcing low-rank structures on completed tensors, a category of methods known as low-rank tensor completion has recently been studied extensively. While such methods attained great success, none considered exploiting numerical priors of tensor elements. Ignoring numerical priors causes loss of important information regarding the data, and therefore prevents the algorithms from reaching optimal accuracy. This work attempts to construct a new methodological framework called GCDTC (Generalized CP Decomposition Tensor Completion) for leveraging numerical priors and achieving higher accuracy in tensor completion. In this newly introduced framework, a generalized form of CP Decomposition is applied to low-rank tensor completion. This paper also proposes an algorithm known as SPTC (Smooth Poisson Tensor Completion) for nonnegative integer tensor completion as an instantiation of the G
    
[^32]: 历史依赖动态环境下的强化学习

    Reinforcement Learning with History-Dependent Dynamic Contexts. (arXiv:2302.02061v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02061](http://arxiv.org/abs/2302.02061)

    介绍了一种称为DCMDPs的新型强化学习框架，用于处理依赖历史环境的情况。其中的逻辑DCMDPs通过利用聚合函数确定上下文转换，打破了对历史长度的指数依赖，并引入了一种实用的基于模型的算法。在推荐任务中展示了该方法的有效性。

    

    我们引入了动态上下文马尔可夫决策过程（DCMDPs），这是一种新的强化学习框架，用于处理依赖历史环境的情况。它推广了上下文MDP框架，以处理非马尔可夫环境，其中上下文随时间变化。我们考虑了这个模型的特殊情况，着重于逻辑DCMDPs，它通过利用聚合函数确定上下文转换来打破对历史长度的指数依赖。这种特殊结构使我们能够推导出一种类似于上限置信界算法的算法，并建立了遗憾界。受我们的理论结果的启发，我们引入了一种实用的基于模型的算法，用于逻辑DCMDPs，这个算法在一个潜在空间中进行规划，并使用历史依赖特征上的乐观主义。我们在一个推荐任务上展示了我们方法的有效性（使用MovieLens数据集），其中用户行为动态地随着推荐的变化而演变。

    We introduce Dynamic Contextual Markov Decision Processes (DCMDPs), a novel reinforcement learning framework for history-dependent environments that generalizes the contextual MDP framework to handle non-Markov environments, where contexts change over time. We consider special cases of the model, with a focus on logistic DCMDPs, which break the exponential dependence on history length by leveraging aggregation functions to determine context transitions. This special structure allows us to derive an upper-confidence-bound style algorithm for which we establish regret bounds. Motivated by our theoretical results, we introduce a practical model-based algorithm for logistic DCMDPs that plans in a latent space and uses optimism over history-dependent features. We demonstrate the efficacy of our approach on a recommendation task (using MovieLens data) where user behavior dynamics evolve in response to recommendations.
    
[^33]: Maxout网络的期望梯度及其对参数初始化的影响

    Expected Gradients of Maxout Networks and Consequences to Parameter Initialization. (arXiv:2301.06956v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.06956](http://arxiv.org/abs/2301.06956)

    本文研究了Maxout网络关于输入和参数的梯度，提出了避免梯度消失和爆炸的参数初始化策略，并在实验中证明了其有效性。

    

    本文研究了Maxout网络相对于输入和参数的梯度，并根据网络结构和参数分布得出梯度的矩上界。我们观察到，输入输出Jacobian的分布取决于输入，这使得稳定的参数初始化变得复杂。基于梯度矩，我们提出了避免在宽网络中梯度消失和爆炸的参数初始化策略。在深度全连接和卷积神经网络上的实验表明，这种策略改善了Maxout网络的SGD和Adam训练。此外，我们还得到了关于期望线性区域数量、期望曲线长度失真和NTK的精细界限结果。

    We study the gradients of a maxout network with respect to inputs and parameters and obtain bounds for the moments depending on the architecture and the parameter distribution. We observe that the distribution of the input-output Jacobian depends on the input, which complicates a stable parameter initialization. Based on the moments of the gradients, we formulate parameter initialization strategies that avoid vanishing and exploding gradients in wide networks. Experiments with deep fully-connected and convolutional networks show that this strategy improves SGD and Adam training of deep maxout networks. In addition, we obtain refined bounds on the expected number of linear regions, results on the expected curve length distortion, and results on the NTK.
    
[^34]: 简单高效的基于聚类的精准医疗算法

    Simple and Scalable Algorithms for Cluster-Aware Precision Medicine. (arXiv:2211.16553v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16553](http://arxiv.org/abs/2211.16553)

    本文提出了基于聚类和嵌入的简单高效方法，用于克服精准医疗中的高维问题和聚类问题，经验证该方法较当前方法具有更高的有效性和可行性。

    

    利用人工智能实现数据驱动的个性化诊断、预后和治疗，为精准医疗带来了前所未有的变革。然而，生物医学数据的高维度和聚类结构使得在高维度、限制性观测的精准医疗领域中会遇到挑战。为了同时克服这两个问题，我们提出了一种简单高效的联合聚类和嵌入方法，将标准嵌入方法与凸聚类惩罚以模块化的方式结合。这种新颖的基于聚类的嵌入方法克服了当前联合嵌入和聚类方法的复杂性和局限性，我们通过层次聚类主成分分析（PCA）、局部线性嵌入（LLE）和规范相关分析（CCA）的简单实现进行了证明。通过数值实验和真实世界的案例，我们证明了我们方法的有效性。

    AI-enabled precision medicine promises a transformational improvement in healthcare outcomes by enabling data-driven personalized diagnosis, prognosis, and treatment. However, the well-known "curse of dimensionality" and the clustered structure of biomedical data together interact to present a joint challenge in the high dimensional, limited observation precision medicine regime. To overcome both issues simultaneously we propose a simple and scalable approach to joint clustering and embedding that combines standard embedding methods with a convex clustering penalty in a modular way. This novel, cluster-aware embedding approach overcomes the complexity and limitations of current joint embedding and clustering methods, which we show with straightforward implementations of hierarchically clustered principal component analysis (PCA), locally linear embedding (LLE), and canonical correlation analysis (CCA). Through both numerical experiments and real-world examples, we demonstrate that our 
    
[^35]: EC-NAS: 面向神经架构搜索的能耗感知表格基准

    EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search. (arXiv:2210.06015v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.06015](http://arxiv.org/abs/2210.06015)

    提出了一个能耗感知的神经架构搜索表格基准 EC-NAS，该基准通过添加能耗和碳足迹信息，支持设计能效高的深度学习模型，并降低总能耗。

    

    近年来，选择、训练和部署深度学习模型所需的能量消耗不断增加。本文旨在支持设计能效高、训练资源消耗较低、适用于实际边缘/移动计算环境并具有环境可持续性的深度学习模型。我们提出将能效作为神经架构搜索 (NAS) 的一项额外性能指标，并通过添加不同架构的能耗和碳足迹信息，提供更新的表格基准 EC-NAS 以在较低计算成本下评估 NAS 策略。EC-NAS 还包括用于预测能耗的代理模型，并有助于降低总能耗。

    Energy consumption from selecting, training and deploying deep learning models has continued to increase over the past few years. Our goal in this work is to support the design of energy-efficient deep learning models that are easier to train with lower compute resources, practical to deploy in real-world edge/mobile computing settings and environmentally sustainable. Tabular benchmarks for neural architecture search (NAS) allow the evaluation of NAS strategies at lower computational cost by providing pre-computed performance statistics. In this work, we suggest including energy efficiency as an additional performance criterion to NAS and present an updated tabular benchmark by including information on energy consumption and carbon footprint for different architectures. The benchmark called EC-NAS is made available open-source to support energy consumption-aware NAS research. EC-NAS also includes a surrogate model for predicting energy consumption, and helps us reduce the overall energ
    
[^36]: 基于部分信息分解的神经表示复杂度度量

    A Measure of the Complexity of Neural Representations based on Partial Information Decomposition. (arXiv:2209.10438v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2209.10438](http://arxiv.org/abs/2209.10438)

    本文提出了一种基于部分信息分解的“表示复杂度”度量，用于量化跨多个神经元扩散的信息访问难度，并证明了其实用性。

    

    在神经网络中，与任务相关的信息通常是由神经元群联合表示的。然而，关于这种分类标签的互信息如何在单个神经元之间分配的细节尚不清楚：虽然部分互信息只能从特定的单个神经元中获得，但其他部分则由多个神经元冗余或协同承载。本文展示了如何使用信息论的部分信息分解来分离这些不同的贡献，并提出了“表示复杂度”度量，用于量化跨多个神经元扩散的信息访问难度。我们证明了如何直接计算较小层的复杂度，并针对较大层提出了子抽样和粗粒化过程，并证明了对应的上限。在MNIST和CIFAR10任务上，我们在量化的深度神经网络中观察到表示复杂度，证明了我们方法的实用性。

    In neural networks, task-relevant information is represented jointly by groups of neurons. However, the specific way in which this mutual information about the classification label is distributed among the individual neurons is not well understood: While parts of it may only be obtainable from specific single neurons, other parts are carried redundantly or synergistically by multiple neurons. We show how Partial Information Decomposition (PID), a recent extension of information theory, can disentangle these different contributions. From this, we introduce the measure of "Representational Complexity", which quantifies the difficulty of accessing information spread across multiple neurons. We show how this complexity is directly computable for smaller layers. For larger layers, we propose subsampling and coarse-graining procedures and prove corresponding bounds on the latter. Empirically, for quantized deep neural networks solving the MNIST and CIFAR10 tasks, we observe that representati
    
[^37]: Selectively Adaptive Lasso选适应Lasso

    The Selectively Adaptive Lasso. (arXiv:2205.10697v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.10697](http://arxiv.org/abs/2205.10697)

    本文提出了一种新算法——Selectively Adaptive Lasso（SAL），它基于HAL的理论构建，保留了无维度、非参数收敛速率的优点，同时也具有可扩展到大规模高维数据集的能力。这种算法将许多回归系数自动设置为零。

    

    机器学习回归方法能够进行无需过多的参数假设的函数估计。虽然它们可以在预测误差方面表现出色，但大多数缺乏类半参数有效估计（例如，TMLE，AIPW）所需的理论收敛速度。高度自适应Lasso（HAL）是唯一经证明能够快速收敛到意义上的大类函数的回归方法，与预测变量的维度无关。不幸的是，HAL无法扩展计算。在本文中，我们在HAL理论的基础上构建选择自适应Lasso（SAL），一种新的算法，保留HAL的无维度、非参数收敛率，但也能扩展到大规模的高维数据集。为了实现这一目标，我们证明了一些与嵌套Donsker类中的经验损失最小化有关的一般理论结果。我们的算法是一种梯度下降形式，具有简单的分组规则，自动将许多回归系数设为零。

    Machine learning regression methods allow estimation of functions without unrealistic parametric assumptions. Although they can perform exceptionally in prediction error, most lack theoretical convergence rates necessary for semi-parametric efficient estimation (e.g. TMLE, AIPW) of parameters like average treatment effects. The Highly Adaptive Lasso (HAL) is the only regression method proven to converge quickly enough for a meaningfully large class of functions, independent of the dimensionality of the predictors. Unfortunately, HAL is not computationally scalable. In this paper we build upon the theory of HAL to construct the Selectively Adaptive Lasso (SAL), a new algorithm which retains HAL's dimension-free, nonparametric convergence rate but which also scales computationally to large high-dimensional datasets. To accomplish this, we prove some general theoretical results pertaining to empirical loss minimization in nested Donsker classes. Our resulting algorithm is a form of gradie
    
[^38]: PyDTS：用于离散时间竞争风险（正则化）回归的 Python 包

    PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks. (arXiv:2204.05731v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.05731](http://arxiv.org/abs/2204.05731)

    PyDTS是一个用于离散时间生存数据半参数竞争风险模型的Python包，支持包括LASSO和弹性网等正则化回归方法。

    

    时间至事件分析（生存分析）用于响应时间是指预定事件发生的时间。由于时间本身是离散的或由于将失败时间分组为间隔或舍入测量，因此时间至事件数据有时是离散的。此外，个体的失败可能是几种不同的失败类型之一，称为竞争风险（事件）。大多数生存回归分析的方法和软件包假定时间是在连续尺度上测量的。众所周知，将标准的连续时间模型应用于离散时间数据可能导致离散时间模型的估计器存在偏差。介绍了 Python 包 PyDTS，用于模拟，估计和评估离散时间生存数据的半参数竞争风险模型。该包实现了快速过程，使有效地包括正则化回归方法，如 LASSO 和弹性网络等。一个模拟

    Time-to-event analysis (survival analysis) is used when the response of interest is the time until a pre-specified event occurs. Time-to-event data are sometimes discrete either because time itself is discrete or due to grouping of failure times into intervals or rounding off measurements. In addition, the failure of an individual could be one of several distinct failure types, known as competing risks (events). Most methods and software packages for survival regression analysis assume that time is measured on a continuous scale. It is well-known that naively applying standard continuous-time models with discrete-time data may result in biased estimators of the discrete-time models. The Python package PyDTS, for simulating, estimating and evaluating semi-parametric competing-risks models for discrete-time survival data, is introduced. The package implements a fast procedure that enables including regularized regression methods, such as LASSO and elastic net, among others. A simulation 
    
[^39]: 随机投影分类的最优性和复杂度。

    Optimality and complexity of classification by random projection. (arXiv:2108.06339v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.06339](http://arxiv.org/abs/2108.06339)

    本文研究了一组低复杂度分类器，该分类器可以近似于任意连续函数和布尔函数，且在给定类条件密度的情况下，其误差与最优误差相同。

    

    分类器的泛化误差与选择分类器的函数集的复杂度有关。我们研究了一组低复杂度分类器，包括通过随机一维特征做阈值处理。该特征通过将数据嵌入到由高次单项式参数化的更高维空间中后在随机直线上进行投影而得到。具体而言，扩展的数据被投影n次，并从这n个中选出表现在训练数据上最好的分类器。我们证明了这种类型的分类器是极其灵活的，因为它有可能近似于任何在紧致集上的连续函数，以及将支撑集拆分为可测子集的任何布尔函数。特别地，如果给定类条件密度的完全知识，则这些低复杂度分类器的误差将在k和n趋近于无穷大时收敛到最优（贝叶斯）误差。

    The generalization error of a classifier is related to the complexity of the set of functions among which the classifier is chosen. We study a family of low-complexity classifiers consisting of thresholding a random one-dimensional feature. The feature is obtained by projecting the data on a random line after embedding it into a higher-dimensional space parametrized by monomials of order up to k. More specifically, the extended data is projected n-times and the best classifier among those n, based on its performance on training data, is chosen. We show that this type of classifier is extremely flexible, as it is likely to approximate, to an arbitrary precision, any continuous function on a compact set as well as any boolean function on a compact set that splits the support into measurable subsets. In particular, given full knowledge of the class conditional densities, the error of these low-complexity classifiers would converge to the optimal (Bayes) error as k and n go to infinity. On
    
[^40]: 认知神经网络

    Epistemic Neural Networks. (arXiv:2107.08924v8 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.08924](http://arxiv.org/abs/2107.08924)

    该论文提出了一种能够通过适量级别的递增计算来估计神经网络不确定性的Epistemic神经网络框架，使得传统神经网络能够在计算成本大幅下降的情况下超越大型集成模型，为模型联合预测的方法提供了一种新的接口。

    

    智能依赖于智能体对其不知道的事物的了解。智能体预测多个输入标签的质量可以评估其对这种能力的掌握程度。集成式方法在原则上可以产生有效的预测，但训练大规模的集成模型的计算成本很高，从而可能会变得禁止。我们引入了Epinet：一种可以加强任何传统神经网络（包括大型预训练模型）的架构，并且可以通过适量级别的递增计算训练来估计不确定性。用Epinet，传统神经网络可以在计算成本大幅下降的情况下胜过由数百个或更多粒子组成的大型集成，同时不需要符合贝叶斯神经网络的传统框架。为了适应超越BNN的方法的发展，例如Epinet，我们介绍了作为产生联合预测模型的接口的知识神经网络（ENN）。

    Intelligence relies on an agent's knowledge of what it does not know. This capability can be assessed based on the quality of joint predictions of labels across multiple inputs. In principle, ensemble-based approaches produce effective joint predictions, but the computational costs of training large ensembles can become prohibitive. We introduce the epinet: an architecture that can supplement any conventional neural network, including large pretrained models, and can be trained with modest incremental computation to estimate uncertainty. With an epinet, conventional neural networks outperform very large ensembles, consisting of hundreds or more particles, with orders of magnitude less computation. The epinet does not fit the traditional framework of Bayesian neural networks. To accommodate development of approaches beyond BNNs, such as the epinet, we introduce the epistemic neural network (ENN) as an interface for models that produce joint predictions.
    
[^41]: 一个ODENet和ResNet的通用逼近性质：数学分析与数值实验

    Universal Approximation Properties for an ODENet and a ResNet: Mathematical Analysis and Numerical Experiments. (arXiv:2101.10229v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2101.10229](http://arxiv.org/abs/2101.10229)

    本论文证明了对于一类ODENet和一类ResNet，“宽度为n+m的ODENet可以逼近${\rm \mathbb{R}^n}$上紧致子集上的任何连续函数”，同时推导了损失函数对某个调整变量的梯度并用于构建ODENet的学习算法，并在MNIST上进行实验。

    

    我们证明了一类ODENet和一类ResNet的通用逼近性质(UAP)，它们是具有跳跃连接的深度学习系统的简化数学模型。 UAP可以陈述如下:设$n$和$m$分别为输入数据和输出数据的维数，并假设$m\leq n$。然后我们证明了带有非多项式连续激活函数的宽度为$n+m$的ODENet可以逼近$\mathbb {R} ^ n$上紧致子集上的任何连续函数。我们还证明了当深度趋于无限时，ResNet具有相同的性质。此外，我们明确推导了损失函数对某个调整变量的梯度。 我们将其用于构建ODENet的学习算法。为了展示此算法的实用性，我们将其应用于MNIST上的回归问题、二分类和多项分类。

    We prove a universal approximation property (UAP) for a class of ODENet and a class of ResNet, which are simplified mathematical models for deep learning systems with skip connections. The UAP can be stated as follows. Let $n$ and $m$ be the dimension of input and output data, and assume $m\leq n$. Then we show that ODENet of width $n+m$ with any non-polynomial continuous activation function can approximate any continuous function on a compact subset on $\mathbb{R}^n$. We also show that ResNet has the same property as the depth tends to infinity. Furthermore, we derive the gradient of a loss function explicitly with respect to a certain tuning variable. We use this to construct a learning algorithm for ODENet. To demonstrate the usefulness of this algorithm, we apply it to a regression problem, a binary classification, and a multinomial classification in MNIST.
    
[^42]: 重复首价拍卖中的最优无悔学习

    Optimal No-regret Learning in Repeated First-price Auctions. (arXiv:2003.09795v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2003.09795](http://arxiv.org/abs/2003.09795)

    本文提出了重复首价拍卖的最优无悔学习算法，通过利用特定的反馈结构和支付函数，实现了接近最优的遗憾界限。

    

    本研究探讨了在重复首价拍卖中的在线学习问题，拍卖者只在每次拍卖结束后看到最高的出价，为了最大化收益，她必须进行适应性出价。然而，拍卖者只能面对被审查的反馈，如果她赢得出价，就无法观察到其他竞标者的最高出价，而其他竞标者的最高出价是从未知的分布中\textit{iid}抽取的。本文开发了第一个学习算法，通过利用首价拍卖的两个结构性质，即特定的反馈结构和支付函数，实现了接近最优的$\widetilde{O}(\sqrt{T})$遗憾界限。首价拍卖中的反馈机制结合了跨行动(出价)的图形反馈、跨上下文(私人价值)的交叉学习以及对上下文的部分排序，我们将其推广为部分排序情境赌博机。通过展示损失函数与优化结构之间的奇怪分离，我们建立了此框架的优点和缺点。我们的算法使用后验风险最小化的有效变体，称为“带有基于方差的正则化的连续调用正则化经验风险最小化器”。我们的分析利用了对问题本质结构和Kwon-Singer定理的仔细探索。

    We study online learning in repeated first-price auctions where a bidder, only observing the winning bid at the end of each auction, learns to adaptively bid in order to maximize her cumulative payoff. To achieve this goal, the bidder faces a censored feedback: if she wins the bid, then she is not able to observe the highest bid of the other bidders, which we assume is \textit{iid} drawn from an unknown distribution. In this paper, we develop the first learning algorithm that achieves a near-optimal $\widetilde{O}(\sqrt{T})$ regret bound, by exploiting two structural properties of first-price auctions, i.e. the specific feedback structure and payoff function.  The feedback in first-price auctions combines the graph feedback across actions (bids), the cross learning across contexts (private values), and a partial order over the contexts; we generalize it as the partially ordered contextual bandits. We establish both strengths and weaknesses of this framework, by showing a curious separa
    
[^43]: 利用未标记数据扩展类别的开放集学习（Open-LACU）

    Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2002.01368](http://arxiv.org/abs/2002.01368)

    Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。

    

    对于半监督学习（SSL）和开放式识别（OSR），已经进行了许多尝试以合成单个训练策略。然而，每次尝试都违反了开放集定义，因为这些方法在未标记的训练集中包含新颖的类别。本研究提出了一种新的学习策略，其中分类器能够在观察到的和未观察到的新颖类别之间进行推广，从而定义了观察到新颖类别的背景类别和未观察到新颖类别的未知类别。通过分类这两种新颖类别的方式，Open-LACU能够提高训练的成本效益性，并确保在存在未观察到的新颖类别时进行安全分类。

    Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
    

