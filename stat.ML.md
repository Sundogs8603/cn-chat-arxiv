# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Q-malizing flow and infinitesimal density ratio estimation.](http://arxiv.org/abs/2305.11857) | 研究提出了一种可以从一个数据分布P传输到任意访问通过有限样本的Q的流模型。这个模型通过神经ODE模型进行，可以进行无穷小DRE。 |
| [^2] | [Multimodal Web Navigation with Instruction-Finetuned Foundation Models.](http://arxiv.org/abs/2305.11854) | 本文研究使用视觉语言基础模型进行数据驱动离线训练的 Web 代理，提出了一个指令跟随多模态代理WebGUM，将微调指令微调语言模型和视觉转换器，能够有效提高代理的基于视觉感知、HTML 理解和多步推理的能力。 |
| [^3] | [Improving Multimodal Joint Variational Autoencoders through Normalizing Flows and Correlation Analysis.](http://arxiv.org/abs/2305.11832) | 本文提出了一种改进的多模态联合变分自编码器，利用正则化流和相关性分析技术，实现了更加连贯的跨模态生成，更多样化的数据生成，同时可扩展到任意数量的模态。 |
| [^4] | [The probability flow ODE is provably fast.](http://arxiv.org/abs/2305.11798) | 首次提供概率流ODE实现得到多项式时间收敛保证的证明，使用欠阻尼Langevin扩散的特殊选择的校正步骤，获得了更好的维度依赖性，凸显了ODE框架的潜在优势。 |
| [^5] | [Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability.](http://arxiv.org/abs/2305.11788) | 本文研究了逻辑回归常数步长梯度下降在稳定性边缘的收敛性和隐式偏差，证明了逻辑损失可以通过任何常数步长的梯度下降进行最小化，同时也发现了指数损失下的发散性问题，强调了稳定性边缘下梯度下降的不稳定性。 |
| [^6] | [Multi-Objective Optimization Using the R2 Utility.](http://arxiv.org/abs/2305.11774) | 本文提出将多目标优化问题转化为一组单目标问题进行解决，并介绍了R2效用函数作为适当的目标函数。该效用函数单调且次模，可以使用贪心优化算法计算全局最优解。 |
| [^7] | [Transfer operators on graphs: Spectral clustering and beyond.](http://arxiv.org/abs/2305.11766) | 本文介绍了在图上定义的转移算子及其谱特性，提出了基于广义转移算子的有向图聚类算法，并证明了算法有效性。 |
| [^8] | [Tester-Learners for Halfspaces: Universal Algorithms.](http://arxiv.org/abs/2305.11765) | 本文提出了第一个成功的通用半空间测试学习器，可以在广泛结构化的分布上工作，实现误差$ O（\mathrm {opt}）+\ \epsilon $。 |
| [^9] | [Moment Matching Denoising Gibbs Sampling.](http://arxiv.org/abs/2305.11650) | 本文提出了动量匹配去噪Gibbs采样方法，可以在给定‘嘈杂’的模型的情况下，从干净的模型中有效地进行采样。 |
| [^10] | [Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern.](http://arxiv.org/abs/2305.11640) | 本文提出了两种实用算法，能够在任意丢失模式下有效地保证覆盖率的有效性，并量化了缺失对预测精度的影响。 |
| [^11] | [Bayesian approach to Gaussian process regression with uncertain inputs.](http://arxiv.org/abs/2305.11586) | 本文提出了一种新的高斯过程回归技术，通过贝叶斯方法将输入数据的不确定性纳入回归模型预测中。在数值实验中展示了该方法具有普适性和不错的表现。 |
| [^12] | [The Deep Promotion Time Cure Model.](http://arxiv.org/abs/2305.11575) | 该研究提出了一种新方法，将灵活的生存模型集成进深度神经网络框架中，实现预测存在治愈分数时的时间至事件。该方法可适用于大规模应用，允许协变量和生存之间的非线性关系和高维交互，从而获得更好的预测性能和更真实的协变量效应。 |
| [^13] | [TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series.](http://arxiv.org/abs/2305.11567) | TSGM提供了一种生成合成时间序列数据的灵活框架，使研究人员能够快速实现自己的方法并在可共享的环境中进行比较，从而有助于生成大规模的合成时间序列数据集，以用于训练和验证各种机器学习模型。 |
| [^14] | [From Random Search to Bandit Learning in Metric Measure Spaces.](http://arxiv.org/abs/2305.11509) | 本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。 |
| [^15] | [Accelerating Convergence in Global Non-Convex Optimization with Reversible Diffusion.](http://arxiv.org/abs/2305.11493) | 本论文提出了一种基于可逆扩散的全局非凸优化方法，其通过在远离最优点时设置较大的扩散系数以及在附近时设置较小的扩散系数来加速收敛并调节离散误差，同时证明了其收敛性能。 |
| [^16] | [Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models.](http://arxiv.org/abs/2305.11475) | 本文提供了一种共曲抑制正则化器，用于应对广义加性模型易受共错性的问题，通过惩罚非线性转换的特征变量的成对相关性，增强了模型的解释性。 |
| [^17] | [Generative Sliced MMD Flows with Riesz Kernels.](http://arxiv.org/abs/2305.11463) | 本文使用Riesz核展示了生成式分割MMD流的高效计算方法，实现了在大规模应用中通过神经网络训练生成模型。 |
| [^18] | [Beyond Exponential Graph: Communication-Efficient Topologies for Decentralized Learning via Finite-time Convergence.](http://arxiv.org/abs/2305.11420) | 本文介绍了一种新型拓扑——基础$(k+1)$图，其中节点在有限的迭代次数后能达到确切的共识，具有快速共识率和小的最大度数，从而可以用于分散式SGD。 |
| [^19] | [Few-Shot Continual Learning for Conditional Generative Adversarial Networks.](http://arxiv.org/abs/2305.11400) | 本文提出了一种新的连续学习方法，适用于条件生成对抗网络，根据cGAN的判别器数据识别出最接近目标的现有模式，并通过扩展连续学习模型，使用回放生成的数据来训练目标模式的cGAN模型，以避免灾难性遗忘，提高了生成性能。 |
| [^20] | [Generalized Precision Matrix for Scalable Estimation of Nonparametric Markov Networks.](http://arxiv.org/abs/2305.11379) | 本文提出了一种广义精度矩阵（GPM）用于描述所有数据类型的条件独立结构，并允许变量之间的一般功能关系。同时，提出了一种马尔科夫网络结构学习算法，在处理大图时，使用了统一的正则化得分匹配框架以提高可伸缩性。 |
| [^21] | [Meta-learning for heterogeneous treatment effect estimation with closed-form solvers.](http://arxiv.org/abs/2305.11353) | 本文提出了一种元学习方法，用于从少量的观测数据中估计条件平均处理效应（CATE），该方法通过神经网络模型对CATE估计问题进行分解并使用闭式求解器获得参数，最终实现了任务之间的共享和优化CATE估计表现提升。 |
| [^22] | [Counterfactuals for Design: A Model-Agnostic Method For Design Recommendations.](http://arxiv.org/abs/2305.11308) | 本文介绍了一种多目标设计反事实(MCD)方法，可帮助设计师识别设计修改，提高功能性能。MCD通过支持多目标查询和解耦反事实搜索和采样过程来提高效率并改进现有的反事实搜索方法，证明其在自行车设计案例中的有效性。 |
| [^23] | [On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation.](http://arxiv.org/abs/2305.11283) | 本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。 |
| [^24] | [Real-Time Variational Method for Learning Neural Trajectory and its Dynamics.](http://arxiv.org/abs/2305.11278) | 本论文介绍了一种实时的递归贝叶斯方法用于推断神经轨迹及其动力学，能够广泛适用于任意似然，同时有效跟踪神经元中钙成像数据的动态。 |
| [^25] | [Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison.](http://arxiv.org/abs/2305.11241) | 本论文提出了一种名为证据网络的方法，能够在处理似然函数或先验函数与嵌套抽样无法胜任的情况下实现贝叶斯模型比较。与传统方法不同的是，该方法使用了新的损失函数，使得我们能够更快速地、更有效地估算贝叶斯因子。 |
| [^26] | [Massively Parallel Reweighted Wake-Sleep.](http://arxiv.org/abs/2305.11022) | 大规模并行重新加权唤醒-睡眠算法通过抽取$K^n$个可能的样本组合，避免了原方法中大量潜在变量数目导致有效性下降问题。 |
| [^27] | [Active Learning in Symbolic Regression Performance with Physical Constraints.](http://arxiv.org/abs/2305.10379) | 本文探讨了利用进化符号回归作为主动学习中的方法来提出哪些数据应该被采集，通过“委员会查询”来减少所需数据，并在重新发现已知方程所需的数据方面实现最新的结果。 |
| [^28] | [Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits.](http://arxiv.org/abs/2305.06743) | 本文提出了一种针对奖励分布重尾的MAB问题的隐式规范化预测器，证明该方法在线性和非线性重尾随机MAB问题上是最优的。 |
| [^29] | [Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics.](http://arxiv.org/abs/2304.14094) | 本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。 |
| [^30] | [Variational Diffusion Auto-encoder: Deep Latent Variable Model with Unconditional Diffusion Prior.](http://arxiv.org/abs/2304.12141) | 本文提出了一种基于扩散模型对条件数据分布进行建模的变分扩散自编码器方法，它避免了对参数形式做出强烈假设，可以显著提高生成图像的质量。 |
| [^31] | [Incorporating Unlabelled Data into Bayesian Neural Networks.](http://arxiv.org/abs/2304.01762) | 该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。 |
| [^32] | [On Statistical Properties of Sharpness-Aware Minimization: Provable Guarantees.](http://arxiv.org/abs/2302.11836) | SAM是一种优化框架，旨在通过获得更平坦（即更不锐利）的解来改善深度神经网络的泛化能力。我们研究两个统计问题，在某些条件下，证明了SAM在预测误差方面比梯度下降有更小的误差，并适用于非凸问题。此外，我们的设置表明，SAM的解更不锐利，证明了我们的结论。 |
| [^33] | [The Geometry of Neural Nets' Parameter Spaces Under Reparametrization.](http://arxiv.org/abs/2302.07384) | 研究了神经网络在重参数化下的不变性，如果显式地表示度量并使用正确的相关变换规则，则不变性是任何神经网络的固有属性。 |
| [^34] | [Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal.](http://arxiv.org/abs/2302.04963) | 本文证明了在凸优化中，实现最优 oracle 复杂性所必需要的内存为二次，并且在处理 1-Lipschitz 凸函数时，使用 $d^{2-\delta}$ 内存的任何算法都需要进行 $\tilde\Omega(d^{1+\delta/3})$ 次查询。此外，在可行性问题中，使用至多 $d^{2-\delta}$ 存储器容量的分离 oracle 需要进行 $\tilde\Omega(d^{1+\delta})$ 次查询。 |
| [^35] | [Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing.](http://arxiv.org/abs/2301.12930) | 通过引入异方差位置-尺度噪声函数模型，该论文在正确说明噪声分布的情况下，通过最大似然实现了最先进的准确性。但是，在用户错误指定噪声分布的形式时，分析表明因果推断的精度会急剧下降。因此，该论文提出通过因果模型选择实现稳定而准确的因果推断。 |
| [^36] | [Multilayer hypergraph clustering using the aggregate similarity matrix.](http://arxiv.org/abs/2301.11657) | 本文提出了一个半定规划方法来解决基于超图的多层聚类问题，同时在同配和非同配情况下保证了精确恢复。 |
| [^37] | [Your diffusion model secretly knows the dimension of the data manifold.](http://arxiv.org/abs/2212.12611) | 本研究提出了一种新的方法，利用扩散模型估算数据流形的维度并且在实验中表现出色。 |
| [^38] | [Distributionally Robust Bayesian Optimization with $\phi$-divergences.](http://arxiv.org/abs/2203.02128) | 本研究提出了一种基于$\phi$-离散度的分布鲁棒贝叶斯优化算法。 |
| [^39] | [Anticorrelated Noise Injection for Improved Generalization.](http://arxiv.org/abs/2202.02831) | 本文发现，在一些目标函数中，抗相关噪声的梯度下降方法比传统的梯度下降和常规扰动梯度下降有更好的泛化性能。理论分析证明了这是因为 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。 |

# 详细

[^1]: Q-malizing流和无穷小密度比估计

    Q-malizing flow and infinitesimal density ratio estimation. (arXiv:2305.11857v1 [stat.ML])

    [http://arxiv.org/abs/2305.11857](http://arxiv.org/abs/2305.11857)

    研究提出了一种可以从一个数据分布P传输到任意访问通过有限样本的Q的流模型。这个模型通过神经ODE模型进行，可以进行无穷小DRE。

    

    连续的正则化流在生成任务中被广泛使用，其中流网络从数据分布P传输到正态分布。一种能够从P传输到任意Q的流模型，其中P和Q都可通过有限样本访问，将在各种应用兴趣中使用，特别是在最近开发的望远镜密度比估计中（DRE），它需要构建中间密度以在P和Q之间建立桥梁。在这项工作中，我们提出了这样的“Q-malizing流”，通过神经ODE模型进行，该模型通过经验样本的可逆传输从P到Q（反之亦然），并通过最小化传输成本进行正则化。训练好的流模型使我们能够沿与时间参数化的log密度进行无穷小DRE，通过训练附加的连续时间流网络使用分类损失来估计log密度的时间偏导数。通过积分时间得分网络

    Continuous normalizing flows are widely used in generative tasks, where a flow network transports from a data distribution $P$ to a normal distribution. A flow model that can transport from $P$ to an arbitrary $Q$, where both $P$ and $Q$ are accessible via finite samples, would be of various application interests, particularly in the recently developed telescoping density ratio estimation (DRE) which calls for the construction of intermediate densities to bridge between $P$ and $Q$. In this work, we propose such a ``Q-malizing flow'' by a neural-ODE model which is trained to transport invertibly from $P$ to $Q$ (and vice versa) from empirical samples and is regularized by minimizing the transport cost. The trained flow model allows us to perform infinitesimal DRE along the time-parametrized $\log$-density by training an additional continuous-time flow network using classification loss, which estimates the time-partial derivative of the $\log$-density. Integrating the time-score network
    
[^2]: 使用指令微调基础模型的多模态 Web 导航。

    Multimodal Web Navigation with Instruction-Finetuned Foundation Models. (arXiv:2305.11854v1 [cs.LG])

    [http://arxiv.org/abs/2305.11854](http://arxiv.org/abs/2305.11854)

    本文研究使用视觉语言基础模型进行数据驱动离线训练的 Web 代理，提出了一个指令跟随多模态代理WebGUM，将微调指令微调语言模型和视觉转换器，能够有效提高代理的基于视觉感知、HTML 理解和多步推理的能力。

    

    自主 Web 导航的进展受到了依赖数十亿次在线强化学习的探索性交互和具有领域特定模型设计的影响，这使得难以利用来自丰富领域外数据的泛化。在本工作中，我们研究了基于数据驱动的脱机训练，用于使用视觉语言基础模型的 Web 代理。我们提出了一个指令跟随多模态代理， WebGUM，它观察了网页截图和 HTML 页面，并输出 Web 导航操作，如单击和输入。WebGUM 是通过联合微调指令微调语言模型和视觉转换器在大量的演示语料库上训练的。我们凭经验证明，这种方法可以提高代理的基于视觉感知、HTML 理解和多步推理的能力，明显优于之前的工作。在 MiniWoB 基准测试中，我们超过之前最佳脱机方法 31.9% 以上，接近实现在线交互的表现。

    The progress of autonomous web navigation has been hindered by the dependence on billions of exploratory interactions via online reinforcement learning, and domain-specific model designs that make it difficult to leverage generalization from rich out-of-domain data. In this work, we study data-driven offline training for web agents with vision-language foundation models. We propose an instruction-following multimodal agent, WebGUM, that observes both webpage screenshots and HTML pages and outputs web navigation actions, such as click and type. WebGUM is trained by jointly finetuning an instruction-finetuned language model and a vision transformer on a large corpus of demonstrations. We empirically demonstrate this recipe improves the agent's ability of grounded visual perception, HTML comprehension and multi-step reasoning, outperforming prior works by a significant margin. On the MiniWoB benchmark, we improve over the previous best offline methods by more than 31.9%, being close to re
    
[^3]: 通过正则化流和相关性分析改进多模态联合变分自编码器

    Improving Multimodal Joint Variational Autoencoders through Normalizing Flows and Correlation Analysis. (arXiv:2305.11832v1 [stat.ML])

    [http://arxiv.org/abs/2305.11832](http://arxiv.org/abs/2305.11832)

    本文提出了一种改进的多模态联合变分自编码器，利用正则化流和相关性分析技术，实现了更加连贯的跨模态生成，更多样化的数据生成，同时可扩展到任意数量的模态。

    

    我们提出了一种新的多模态变分自编码器，能够从联合分布生成并针对任意数量的复杂模态进行条件生成。单模后验分布是基于保留跨模态共享信息的深度典型相关分析嵌入进行条件生成的，从而实现了更连贯的跨模态生成。此外，我们使用正则化流来丰富单模后验分布，实现了更多样化的数据生成。最后，我们提出使用专家乘积来从多个模态中推断一个模态，从而使得模型可扩展到任意数量的模态。我们在几个数据集上证明了我们的方法改善了似然度估计、代表性的生成和在条件生成中特别是连贯性指标的性能。

    We propose a new multimodal variational autoencoder that enables to generate from the joint distribution and conditionally to any number of complex modalities. The unimodal posteriors are conditioned on the Deep Canonical Correlation Analysis embeddings which preserve the shared information across modalities leading to more coherent cross-modal generations. Furthermore, we use Normalizing Flows to enrich the unimodal posteriors and achieve more diverse data generation. Finally, we propose to use a Product of Experts for inferring one modality from several others which makes the model scalable to any number of modalities. We demonstrate that our method improves likelihood estimates, diversity of the generations and in particular coherence metrics in the conditional generations on several datasets.
    
[^4]: 概率流ODE可证明速度快

    The probability flow ODE is provably fast. (arXiv:2305.11798v1 [cs.LG])

    [http://arxiv.org/abs/2305.11798](http://arxiv.org/abs/2305.11798)

    首次提供概率流ODE实现得到多项式时间收敛保证的证明，使用欠阻尼Langevin扩散的特殊选择的校正步骤，获得了更好的维度依赖性，凸显了ODE框架的潜在优势。

    

    我们首次提供概率流ODE实现（连同校正步骤）得到多项式时间收敛保证的证明，用于基于分数生成建模。我们的分析是在最近的结果基础上进行的，该结果获得了基于SDE的实现（即去噪扩散概率建模或DDPM）的这样的保证，但需要开发新的技术来研究无收缩的确定性动态。通过使用基于欠阻尼Langevin扩散的特殊选择的校正步骤，我们获得了比DDPM之前作品更好的维度依赖性（假设数据分布平滑，为$ O（\sqrt {d}）$而不是$ O（d）$），凸显了ODE框架的潜在优势。

    We provide the first polynomial-time convergence guarantees for the probability flow ODE implementation (together with a corrector step) of score-based generative modeling. Our analysis is carried out in the wake of recent results obtaining such guarantees for the SDE-based implementation (i.e., denoising diffusion probabilistic modeling or DDPM), but requires the development of novel techniques for studying deterministic dynamics without contractivity. Through the use of a specially chosen corrector step based on the underdamped Langevin diffusion, we obtain better dimension dependence than prior works on DDPM ($O(\sqrt{d})$ vs. $O(d)$, assuming smoothness of the data distribution), highlighting potential advantages of the ODE framework.
    
[^5]: 稳定性边缘处的逻辑回归梯度下降的隐式偏差

    Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability. (arXiv:2305.11788v1 [cs.LG])

    [http://arxiv.org/abs/2305.11788](http://arxiv.org/abs/2305.11788)

    本文研究了逻辑回归常数步长梯度下降在稳定性边缘的收敛性和隐式偏差，证明了逻辑损失可以通过任何常数步长的梯度下降进行最小化，同时也发现了指数损失下的发散性问题，强调了稳定性边缘下梯度下降的不稳定性。

    

    最近的研究表明，在机器学习优化中，梯度下降 (GD) 经常在稳定性边缘 (EoS) [Cohen 等，2021] 运行，其中步长被设置为大，导致由 GD 迭代引起的非单调损失。本文研究在 EoS 区域内使用常数步长 GD 进行逻辑回归的收敛性和隐式偏差，对于线性可分的数据。尽管存在局部振荡，我们证明逻辑损失可以通过任何常数步长的 GD 在长时间尺度上进行最小化。此外，我们证明，在任何常数步长下，当投影到最大边际方向 (硬边 SVM 方向) 时，GD 迭代趋向于无穷大，并在投影到最大边缘的正交补空间时，收敛于最小化强凸势能的固定向量。相反，我们也表明，在 EoS 区域，GD 迭代可能在指数损失下发生灾难性发散，突显了 EoS 区域中 GD 的不稳定性。

    Recent research has observed that in machine learning optimization, gradient descent (GD) often operates at the edge of stability (EoS) [Cohen, et al., 2021], where the stepsizes are set to be large, resulting in non-monotonic losses induced by the GD iterates. This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime. Despite the presence of local oscillations, we prove that the logistic loss can be minimized by GD with any constant stepsize over a long time scale. Furthermore, we prove that with any constant stepsize, the GD iterates tend to infinity when projected to a max-margin direction (the hard-margin SVM direction) and converge to a fixed vector that minimizes a strongly convex potential when projected to the orthogonal complement of the max-margin direction. In contrast, we also show that in the EoS regime, GD iterates may diverge catastrophically under the exponential loss, highlighting t
    
[^6]: 使用R2效用的多目标优化

    Multi-Objective Optimization Using the R2 Utility. (arXiv:2305.11774v1 [math.OC])

    [http://arxiv.org/abs/2305.11774](http://arxiv.org/abs/2305.11774)

    本文提出将多目标优化问题转化为一组单目标问题进行解决，并介绍了R2效用函数作为适当的目标函数。该效用函数单调且次模，可以使用贪心优化算法计算全局最优解。

    

    多目标优化的目标是确定描述多目标之间最佳权衡的点集合。为了解决这个矢量值优化问题，从业者常常使用标量化函数将多目标问题转化为一组单目标问题。这组标量化问题可以使用传统的单目标优化技术来解决。在这项工作中，我们将这个约定形式化为一个通用的数学框架。我们展示了这种策略如何有效地将原始的多目标优化问题重新转化为定义在集合上的单目标优化问题。针对这个新问题的适当类别的目标函数是R2效用函数，它被定义为标量化优化问题的加权积分。我们证明了这个效用函数是单调的和次模的集合函数，可以通过贪心优化算法有效地计算出全局最优解。

    The goal of multi-objective optimization is to identify a collection of points which describe the best possible trade-offs between the multiple objectives. In order to solve this vector-valued optimization problem, practitioners often appeal to the use of scalarization functions in order to transform the multi-objective problem into a collection of single-objective problems. This set of scalarized problems can then be solved using traditional single-objective optimization techniques. In this work, we formalise this convention into a general mathematical framework. We show how this strategy effectively recasts the original multi-objective optimization problem into a single-objective optimization problem defined over sets. An appropriate class of objective functions for this new problem is the R2 utility function, which is defined as a weighted integral over the scalarized optimization problems. We show that this utility function is a monotone and submodular set function, which can be op
    
[^7]: 图上的转移算子：谱聚类及其扩展

    Transfer operators on graphs: Spectral clustering and beyond. (arXiv:2305.11766v1 [stat.ML])

    [http://arxiv.org/abs/2305.11766](http://arxiv.org/abs/2305.11766)

    本文介绍了在图上定义的转移算子及其谱特性，提出了基于广义转移算子的有向图聚类算法，并证明了算法有效性。

    

    图和网络在建模和分析复杂的相关系统中发挥着重要作用，例如交通网络，集成电路，电力网格，引文图以及生物和人工神经网络。本文在图上定义了转移算子，如Koopman算子和Perron-Frobenius算子，研究了它们的谱特性，引入了这些算子的Galerkin投影，并说明了如何从数据中估计降低表示。特别地，我们展示了无向图谱聚类可以被解释为Koopman算子的特征函数，并提出了基于广义转移算子的有向图聚类算法。我们在几个基准问题上证明了所得算法的有效性，并提供了不同聚类的解释。

    Graphs and networks play an important role in modeling and analyzing complex interconnected systems such as transportation networks, integrated circuits, power grids, citation graphs, and biological and artificial neural networks. Graph clustering algorithms can be used to detect groups of strongly connected vertices and to derive coarse-grained models. We define transfer operators such as the Koopman operator and the Perron-Frobenius operator on graphs, study their spectral properties, introduce Galerkin projections of these operators, and illustrate how reduced representations can be estimated from data. In particular, we show that spectral clustering of undirected graphs can be interpreted in terms of eigenfunctions of the Koopman operator and propose novel clustering algorithms for directed graphs based on generalized transfer operators. We demonstrate the efficacy of the resulting algorithms on several benchmark problems and provide different interpretations of clusters.
    
[^8]: 半空间的测试学习器：通用算法

    Tester-Learners for Halfspaces: Universal Algorithms. (arXiv:2305.11765v1 [cs.LG])

    [http://arxiv.org/abs/2305.11765](http://arxiv.org/abs/2305.11765)

    本文提出了第一个成功的通用半空间测试学习器，可以在广泛结构化的分布上工作，实现误差$ O（\mathrm {opt}）+\ \epsilon $。

    

    本文提出了第一个在广泛结构化分布上成功的半空间测试学习器，该通用测试学习器在完全多项式时间内运行，并具有以下保证：学习器在测试器接受的任何标记分布上实现错误$ O（\mathrm {opt}）+\  \epsilon $，此外，测试器在边缘分布是满足Poincar\'e不等式的任何分布时都可以接受。与之前在可测试学习方面的工作不同的是，我们的测试器没有针对任何单一目标分布进行调整，而是对一整个目标分布类成功。Poincar\'e分布类包括所有强对数凹分布，并且，如果假设Kannan-L\'{o}vasz-Simonovits（KLS）猜想，则包括所有对数凹分布。在标签噪声已知为Massart的特殊情况下，我们的测试学习器在不受条件限制的情况下接受所有对数凹分布，并实现误差$ \mathrm {opt} +\  \epsilon $。

    We give the first tester-learner for halfspaces that succeeds universally over a wide class of structured distributions. Our universal tester-learner runs in fully polynomial time and has the following guarantee: the learner achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that the tester accepts, and moreover, the tester accepts whenever the marginal is any distribution that satisfies a Poincar\'e inequality. In contrast to prior work on testable learning, our tester is not tailored to any single target distribution but rather succeeds for an entire target class of distributions. The class of Poincar\'e distributions includes all strongly log-concave distributions, and, assuming the Kannan--L\'{o}vasz--Simonovits (KLS) conjecture, includes all log-concave distributions. In the special case where the label noise is known to be Massart, our tester-learner achieves error $\mathrm{opt} + \epsilon$ while accepting all log-concave distributions unconditionally (withou
    
[^9]: 动量匹配去噪Gibbs采样

    Moment Matching Denoising Gibbs Sampling. (arXiv:2305.11650v1 [stat.ML])

    [http://arxiv.org/abs/2305.11650](http://arxiv.org/abs/2305.11650)

    本文提出了动量匹配去噪Gibbs采样方法，可以在给定‘嘈杂’的模型的情况下，从干净的模型中有效地进行采样。

    

    能量基模型（EBMs）为建模复杂数据分布提供了一个通用的框架。然而，EBMs 的训练和采样仍然面临重大挑战。用于可扩展 EBM 训练的广泛使用的去噪分数匹配（DSM）方法存在不一致性问题，导致能量模型学习到“嘈杂”的数据分布。在本文中，我们提出了一种有效的采样框架：（伪）Gibbs采样与动量匹配，可以在给定经过DSM训练良好的“嘈杂”模型的情况下，从基础“干净”模型中有效地进行采样。我们探讨了我们的方法相对于相关方法的优势，并展示了如何将该方法扩展到高维数据集。

    Energy-Based Models (EBMs) offer a versatile framework for modeling complex data distributions. However, training and sampling from EBMs continue to pose significant challenges. The widely-used Denoising Score Matching (DSM) method for scalable EBM training suffers from inconsistency issues, causing the energy model to learn a `noisy' data distribution. In this work, we propose an efficient sampling framework: (pseudo)-Gibbs sampling with moment matching, which enables effective sampling from the underlying clean model when given a `noisy' model that has been well-trained via DSM. We explore the benefits of our approach compared to related methods and demonstrate how to scale the method to high-dimensional datasets.
    
[^10]: 任意缺失模式下的无分布矩阵预测

    Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern. (arXiv:2305.11640v1 [cs.LG])

    [http://arxiv.org/abs/2305.11640](http://arxiv.org/abs/2305.11640)

    本文提出了两种实用算法，能够在任意丢失模式下有效地保证覆盖率的有效性，并量化了缺失对预测精度的影响。

    

    本文研究了在行/列可交换矩阵中预测缺失条目的问题。虽然矩阵设置提出了新颖和独特的挑战，但是在这个有趣的主题上存在很少的工作。我们精细地定义了问题，将其与密切相关的问题区分开来，并严格划分了可达成和不可能的目标的边界。然后我们提出了两种实用算法。第一种方法提供了全面的预测的快速仿真，而第二种方法利用算法稳定性技术加速计算。这两种方法计算效率高，能够在任意丢失模式下有效地保证覆盖率的有效性。此外，我们量化了缺失对预测精度的影响，并建立了基本的极限结果。来自合成和真实数据集的经验证据证实了我们提出的方法的卓越性能。

    This paper studies the open problem of conformalized entry prediction in a row/column-exchangeable matrix. The matrix setting presents novel and unique challenges, but there exists little work on this interesting topic. We meticulously define the problem, differentiate it from closely related problems, and rigorously delineate the boundary between achievable and impossible goals. We then propose two practical algorithms. The first method provides a fast emulation of the full conformal prediction, while the second method leverages the technique of algorithmic stability for acceleration. Both methods are computationally efficient and can effectively safeguard coverage validity in presence of arbitrary missing pattern. Further, we quantify the impact of missingness on prediction accuracy and establish fundamental limit results. Empirical evidence from synthetic and real-world data sets corroborates the superior performance of our proposed methods.
    
[^11]: 高斯过程回归的贝叶斯方法中融入不确定输入

    Bayesian approach to Gaussian process regression with uncertain inputs. (arXiv:2305.11586v1 [cs.LG])

    [http://arxiv.org/abs/2305.11586](http://arxiv.org/abs/2305.11586)

    本文提出了一种新的高斯过程回归技术，通过贝叶斯方法将输入数据的不确定性纳入回归模型预测中。在数值实验中展示了该方法具有普适性和不错的表现。

    

    传统高斯过程回归仅假设模型观测数据的输出具有噪声。然而，在许多科学和工程应用中，由于建模假设、测量误差等因素，观测数据的输入位置可能也存在不确定性。在本文中，我们提出了一种贝叶斯方法，将输入数据的可变性融入到高斯过程回归中。考虑两种可观测量——具有固定输入的噪声污染输出和具有先验分布定义的不确定输入，通过贝叶斯框架估计后验分布以推断不确定的数据位置。然后，利用边际化方法将这些输入的量化不确定性纳入高斯过程预测中。通过几个数值实验，展示了这种新回归技术的有效性，在其中观察到不同水平输入数据不确定性下的普适良好表现。

    Conventional Gaussian process regression exclusively assumes the existence of noise in the output data of model observations. In many scientific and engineering applications, however, the input locations of observational data may also be compromised with uncertainties owing to modeling assumptions, measurement errors, etc. In this work, we propose a Bayesian method that integrates the variability of input data into Gaussian process regression. Considering two types of observables -- noise-corrupted outputs with fixed inputs and those with prior-distribution-defined uncertain inputs, a posterior distribution is estimated via a Bayesian framework to infer the uncertain data locations. Thereafter, such quantified uncertainties of inputs are incorporated into Gaussian process predictions by means of marginalization. The effectiveness of this new regression technique is demonstrated through several numerical examples, in which a consistently good performance of generalization is observed, w
    
[^12]: 深度推进时间治愈模型

    The Deep Promotion Time Cure Model. (arXiv:2305.11575v1 [stat.ML])

    [http://arxiv.org/abs/2305.11575](http://arxiv.org/abs/2305.11575)

    该研究提出了一种新方法，将灵活的生存模型集成进深度神经网络框架中，实现预测存在治愈分数时的时间至事件。该方法可适用于大规模应用，允许协变量和生存之间的非线性关系和高维交互，从而获得更好的预测性能和更真实的协变量效应。

    

    我们提出了一种基于灵活的生存模型集成到深度神经网络框架中用于预测存在治愈分数时的时间至事件的新方法。我们的方法允许协变量和生存之间的非线性关系和高维交互，并适用于大规模应用。此外，我们允许该方法合并一个由可解释的线性和非线性效应的附加分解形成的已识别的预测器，并添加正交化层以捕获潜在的更高维交互。我们通过模拟证明了我们的方法的有用性和计算效率，并将其应用于大量的美国抵押贷款组合。在此，我们不仅发现了我们框架更好的预测性能，而且发现了更真实的协变量效应。

    We propose a novel method for predicting time-to-event in the presence of cure fractions based on flexible survivals models integrated into a deep neural network framework. Our approach allows for non-linear relationships and high-dimensional interactions between covariates and survival and is suitable for large-scale applications. Furthermore, we allow the method to incorporate an identified predictor formed of an additive decomposition of interpretable linear and non-linear effects and add an orthogonalization layer to capture potential higher dimensional interactions. We demonstrate the usefulness and computational efficiency of our method via simulations and apply it to a large portfolio of US mortgage loans. Here, we find not only a better predictive performance of our framework but also a more realistic picture of covariate effects.
    
[^13]: TSGM：一种生成合成时间序列数据的灵活框架

    TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series. (arXiv:2305.11567v1 [cs.LG])

    [http://arxiv.org/abs/2305.11567](http://arxiv.org/abs/2305.11567)

    TSGM提供了一种生成合成时间序列数据的灵活框架，使研究人员能够快速实现自己的方法并在可共享的环境中进行比较，从而有助于生成大规模的合成时间序列数据集，以用于训练和验证各种机器学习模型。

    

    时间序列数据在各个领域中非常重要，对机器学习研究者也很有兴趣。然而，时间序列数据通常很少或高度敏感，这使得数据在研究者和工业组织之间的共享以及现有和新的数据密集型 ML 方法的应用受到限制。解决这一难题的可能方法是生成合成数据。在这项工作中，我们介绍了时间序列生成模型（TSGM），这是一种用于生成合成时间序列数据的开源框架。TSGM包括广泛的机器学习方法：生成模型、概率模型和基于模拟器的方法。该框架使用户能够从不同的角度评估生成的数据的质量：相似性、下游效果、预测一致性、多样性和隐私。该框架是可扩展的，这使得研究人员能够快速实现自己的方法并在可共享的环境中进行比较。TSGM将有助于生成大规模的合成时间序列数据集，这些数据集可以用于训练和验证各种机器学习模型。

    Temporally indexed data are essential in a wide range of fields and of interest to machine learning researchers. Time series data, however, are often scarce or highly sensitive, which precludes the sharing of data between researchers and industrial organizations and the application of existing and new data-intensive ML methods. A possible solution to this bottleneck is to generate synthetic data. In this work, we introduce Time Series Generative Modeling (TSGM), an open-source framework for the generative modeling of synthetic time series. TSGM includes a broad repertoire of machine learning methods: generative models, probabilistic, and simulator-based approaches. The framework enables users to evaluate the quality of the produced data from different angles: similarity, downstream effectiveness, predictive consistency, diversity, and privacy. The framework is extensible, which allows researchers to rapidly implement their own methods and compare them in a shareable environment. TSGM w
    
[^14]: 从随机搜索到度量测度空间中的赌博学习

    From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])

    [http://arxiv.org/abs/2305.11509](http://arxiv.org/abs/2305.11509)

    本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。

    

    随机搜索是超参数优化中最常用的方法之一，对于深度学习模型的成功至关重要。尽管其性能令人惊叹，但很少有非启发式的理论用于描述其工作机制。本文给出了关于随机搜索的理论解释。我们引入了“散射维度”的概念，描述了底层函数的状态，并量化了随机搜索的性能。我们表明，当环境没有噪声时，随机搜索的输出以概率收敛到最优值，其速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $，其中$ d_s \ge 0 $是底层函数的散射维度。当观察到的函数值受到有界的独立同分布噪声影响时，随机搜索的输出以概率收敛到最优值，速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $。

    Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
    
[^15]: 可逆扩散加速全局非凸优化的收敛

    Accelerating Convergence in Global Non-Convex Optimization with Reversible Diffusion. (arXiv:2305.11493v1 [math.OC])

    [http://arxiv.org/abs/2305.11493](http://arxiv.org/abs/2305.11493)

    本论文提出了一种基于可逆扩散的全局非凸优化方法，其通过在远离最优点时设置较大的扩散系数以及在附近时设置较小的扩散系数来加速收敛并调节离散误差，同时证明了其收敛性能。

    

    在全局非凸优化中，由于在低温下其稳定分布集中在潜在函数的全局最小值点附近，Langevin动力学已被广泛地应用。在本文中，我们提出利用一类更为全面的随机过程——可逆扩散，以及应用欧拉-马鲁雅马分解进行全局非凸优化。我们设计的扩散系数在远离最优点时较大，在附近时较小，从而在调节离散误差的同时加速收敛，这种策略受到了景观修改的启发。我们提出的方法也可以看作是Langevin动力学的时间变换，并证明了收敛性就KL散度而言，研究了收敛速度和离散误差之间的权衡。我们通过数值实验证明了我们提出的方法的有效性。

    Langevin Dynamics has been extensively employed in global non-convex optimization due to the concentration of its stationary distribution around the global minimum of the potential function at low temperatures. In this paper, we propose to utilize a more comprehensive class of stochastic processes, known as reversible diffusion, and apply the Euler-Maruyama discretization for global non-convex optimization. We design the diffusion coefficient to be larger when distant from the optimum and smaller when near, thus enabling accelerated convergence while regulating discretization error, a strategy inspired by landscape modifications. Our proposed method can also be seen as a time change of Langevin Dynamics, and we prove convergence with respect to KL divergence, investigating the trade-off between convergence speed and discretization error. The efficacy of our proposed method is demonstrated through numerical experiments.
    
[^16]: 曲线上扬：在可微广义加性模型中的共曲抑制正则化

    Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models. (arXiv:2305.11475v1 [cs.LG])

    [http://arxiv.org/abs/2305.11475](http://arxiv.org/abs/2305.11475)

    本文提供了一种共曲抑制正则化器，用于应对广义加性模型易受共错性的问题，通过惩罚非线性转换的特征变量的成对相关性，增强了模型的解释性。

    

    最近，由于广义加性模型（GAM）可表达目标变量为特征的非线性变换和解释性，其再次受到欢迎。尽管GAM目前备受热捧，但其易受共错性，即特征之间的（可能是非线性的）依赖性迄今为止大多被忽视。在这里，我们展示了共错性如何严重破坏GAM的解释性，并提出了一个解决方法：一个在非线性转换的特征变量的成对相关性上进行惩罚的概念简单但有效的正则化器。该过程适用于任何可微的加性模型，如神经加性模型或神经预言。并且通过消除自我抵消的特征贡献的歧义，增强了解释性。我们在合成和真实时间序列和表格数据集上验证了我们的正则化器的有效性。

    Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity - i.e., (possibly non-linear) dependencies between the features - has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular d
    
[^17]: 利用Riesz核的生成式分割MMD流

    Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v1 [cs.LG])

    [http://arxiv.org/abs/2305.11463](http://arxiv.org/abs/2305.11463)

    本文使用Riesz核展示了生成式分割MMD流的高效计算方法，实现了在大规模应用中通过神经网络训练生成模型。

    

    在大规模计算中，最大平均差异度(MMD)流的计算成本很高。在本文中，我们展示了使用Riesz核$K(x,y)=-\|x-y\|^r$，$r \in (0,2)$的MMD流具有杰出的性质，可允许其进行高效计算。首先，Riesz核的MMD与其分割版本的MMD重合。因此，可以在一维设置中进行MMD梯度的计算。在此处，对于$r=1$，可以应用简单的排序算法将两个经验度量的复杂度从$O(MN+N^2)$降低到$O((M+N)\log(M+N))$，其中$M$和$N$是支持点。对于实现，我们通过仅使用有限数量的$P$个切片来近似分割MMD的梯度。我们展示了由此产生的误差具有$O(\sqrt{d/P})$的复杂度，其中$d$是数据维度。这些结果使我们能够通过神经网络近似MMD梯度流来训练生成模型，甚至用于大规模应用。

    Maximum mean discrepancy (MMD) flows suffer from high computational costs in large scale computations. In this paper, we show that MMD flows with Riesz kernels $K(x,y) = - \|x-y\|^r$, $r \in (0,2)$ have exceptional properties which allow for their efficient computation. First, the MMD of Riesz kernels coincides with the MMD of their sliced version. As a consequence, the computation of gradients of MMDs can be performed in the one-dimensional setting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce the complexity from $O(MN+N^2)$ to $O((M+N)\log(M+N))$ for two empirical measures with $M$ and $N$ support points. For the implementations we approximate the gradient of the sliced MMD by using only a finite number $P$ of slices. We show that the resulting error has complexity $O(\sqrt{d/P})$, where $d$ is the data dimension. These results enable us to train generative models by approximating MMD gradient flows by neural networks even for large scale applications. We demo
    
[^18]: 超越指数图：有限时间收敛的通信效率拓扑用于分散学习

    Beyond Exponential Graph: Communication-Efficient Topologies for Decentralized Learning via Finite-time Convergence. (arXiv:2305.11420v1 [cs.LG])

    [http://arxiv.org/abs/2305.11420](http://arxiv.org/abs/2305.11420)

    本文介绍了一种新型拓扑——基础$(k+1)$图，其中节点在有限的迭代次数后能达到确切的共识，具有快速共识率和小的最大度数，从而可以用于分散式SGD。

    

    近年来越来越多的研究关注于分散式学习在并行计算和隐私保护中的应用。许多最近的研究指出，具有更快共识率（即谱间隙）的底层网络拓扑可导致分散式学习的更好收敛速度和准确性。然而，具有快速共识率的拓扑，如指数图，通常具有较大的最大度数，这会导致重要的通信成本。因此，寻求既具有快速共识率又具有小的最大度数的拓扑是重要的。在本研究中，我们提出了一种结合快速共识率和小最大度的新型拓扑，称为基础$(k+1)$ 图。与现有的拓扑不同，基础$(k+1)$ 图使所有节点在有限的迭代次数后都能达到确切的共识，对于任何节点数和最大度k都适用。得益于这个有利的属性，基础$(k+1)$ 图赋予了分散式SGD

    Decentralized learning has recently been attracting increasing attention for its applications in parallel computation and privacy preservation. Many recent studies stated that the underlying network topology with a faster consensus rate (a.k.a. spectral gap) leads to a better convergence rate and accuracy for decentralized learning. However, a topology with a fast consensus rate, e.g., the exponential graph, generally has a large maximum degree, which incurs significant communication costs. Thus, seeking topologies with both a fast consensus rate and small maximum degree is important. In this study, we propose a novel topology combining both a fast consensus rate and small maximum degree called the Base-$(k + 1)$ Graph. Unlike the existing topologies, the Base-$(k + 1)$ Graph enables all nodes to reach the exact consensus after a finite number of iterations for any number of nodes and maximum degree k. Thanks to this favorable property, the Base-$(k + 1)$ Graph endows Decentralized SGD
    
[^19]: 面向有条件生成对抗网络的少样本连续学习

    Few-Shot Continual Learning for Conditional Generative Adversarial Networks. (arXiv:2305.11400v1 [cs.LG])

    [http://arxiv.org/abs/2305.11400](http://arxiv.org/abs/2305.11400)

    本文提出了一种新的连续学习方法，适用于条件生成对抗网络，根据cGAN的判别器数据识别出最接近目标的现有模式，并通过扩展连续学习模型，使用回放生成的数据来训练目标模式的cGAN模型，以避免灾难性遗忘，提高了生成性能。

    

    在生成模型的少样本连续学习中，必须学习目标模式，并在不影响先前学习到的模式的情况下仅使用有限的样本。本文针对条件生成对抗网络提出了一种新的连续学习方法，基于一种新的用于生成建模的模式亲和力量度。我们的度量完全基于cGAN的判别器，可以识别最接近目标的现有模式。随后，我们通过包含基于最接近模式的加权标签来扩展连续学习模型。为了预防灾难性遗忘，我们首先使用cGAN的生成器生成带标签的数据样本，然后通过回放生成的数据来训练目标模式的cGAN模型。我们的实验结果证明了我们的方法在提高生成性能方面的有效性，超越了各种标准和最先进的方法。

    In few-shot continual learning for generative models, a target mode must be learned with limited samples without adversely affecting the previously learned modes. In this paper, we propose a new continual learning approach for conditional generative adversarial networks (cGAN) based on a new mode-affinity measure for generative modeling. Our measure is entirely based on the cGAN's discriminator and can identify the existing modes that are most similar to the target. Subsequently, we expand the continual learning model by including the target mode using a weighted label derived from those of the closest modes. To prevent catastrophic forgetting, we first generate labeled data samples using the cGAN's generator, and then train the cGAN model for the target mode while memory replaying with the generated data. Our experimental results demonstrate the efficacy of our approach in improving the generation performance over the baselines and the state-of-the-art approaches for various standard 
    
[^20]: 广义精度矩阵用于可伸缩估计非参数马尔科夫网络

    Generalized Precision Matrix for Scalable Estimation of Nonparametric Markov Networks. (arXiv:2305.11379v1 [cs.LG])

    [http://arxiv.org/abs/2305.11379](http://arxiv.org/abs/2305.11379)

    本文提出了一种广义精度矩阵（GPM）用于描述所有数据类型的条件独立结构，并允许变量之间的一般功能关系。同时，提出了一种马尔科夫网络结构学习算法，在处理大图时，使用了统一的正则化得分匹配框架以提高可伸缩性。

    

    马尔科夫网络给出了一组随机变量的条件独立性结构，现有的工作侧重于特定的分布族（例如指数族）和/或特定的图结构，而且大多数只能处理同一种数据类型的变量（连续或离散）。在本文中，我们使用广义精度矩阵（GPM）在所有数据类型（即连续、离散和混合类型）的一般分布中描述条件独立结构。此外，我们还允许变量之间的一般功能关系，从而产生一种最一般的马尔科夫网络结构学习算法。为了处理问题的计算挑战，尤其是对于大图，我们将所有情况统一到一个正则化得分匹配框架下。我们验证了理论结果并在各种设置下演示了可伸缩性。

    A Markov network characterizes the conditional independence structure, or Markov property, among a set of random variables. Existing work focuses on specific families of distributions (e.g., exponential families) and/or certain structures of graphs, and most of them can only handle variables of a single data type (continuous or discrete). In this work, we characterize the conditional independence structure in general distributions for all data types (i.e., continuous, discrete, and mixed-type) with a Generalized Precision Matrix (GPM). Besides, we also allow general functional relations among variables, thus giving rise to a Markov network structure learning algorithm in one of the most general settings. To deal with the computational challenge of the problem, especially for large graphs, we unify all cases under the same umbrella of a regularized score matching framework. We validate the theoretical results and demonstrate the scalability empirically in various settings.
    
[^21]: 具有闭式求解器的异质性处理效应估计元学习方法

    Meta-learning for heterogeneous treatment effect estimation with closed-form solvers. (arXiv:2305.11353v1 [stat.ML])

    [http://arxiv.org/abs/2305.11353](http://arxiv.org/abs/2305.11353)

    本文提出了一种元学习方法，用于从少量的观测数据中估计条件平均处理效应（CATE），该方法通过神经网络模型对CATE估计问题进行分解并使用闭式求解器获得参数，最终实现了任务之间的共享和优化CATE估计表现提升。

    

    本文提出了一种元学习方法，用于从少量的观察数据中估计条件平均处理效应（CATE）。所提出的方法学习如何从多个任务中估计CATE，并使用这些知识来进行未见过的任务。在该方法中，基于元学习框架，我们将CATE估计问题分解为子问题。对于每个子问题，我们使用具有任务共享和任务特定参数的神经网络来构建我们的估计模型。通过我们的公式化，我们可以获得可微分的闭式的最优任务特定参数，这些参数能够相对于任务共享参数进行有效的元学习。我们训练任务共享参数，以使少示点设置下的CATE估计表现通过将使用大量数据估计的CATE与仅使用少量数据估计的CATE之间的差异最小化得到改善。我们的实验结果表明，我们的方法在CATE估计方面具有优越性。

    This article proposes a meta-learning method for estimating the conditional average treatment effect (CATE) from a few observational data. The proposed method learns how to estimate CATEs from multiple tasks and uses the knowledge for unseen tasks. In the proposed method, based on the meta-learner framework, we decompose the CATE estimation problem into sub-problems. For each sub-problem, we formulate our estimation models using neural networks with task-shared and task-specific parameters. With our formulation, we can obtain optimal task-specific parameters in a closed form that are differentiable with respect to task-shared parameters, making it possible to perform effective meta-learning. The task-shared parameters are trained such that the expected CATE estimation performance in few-shot settings is improved by minimizing the difference between a CATE estimated with a large amount of data and one estimated with just a few data. Our experimental results demonstrate that our method o
    
[^22]: 设计中的反事实：一种模型无关的设计建议方法

    Counterfactuals for Design: A Model-Agnostic Method For Design Recommendations. (arXiv:2305.11308v1 [cs.AI])

    [http://arxiv.org/abs/2305.11308](http://arxiv.org/abs/2305.11308)

    本文介绍了一种多目标设计反事实(MCD)方法，可帮助设计师识别设计修改，提高功能性能。MCD通过支持多目标查询和解耦反事实搜索和采样过程来提高效率并改进现有的反事实搜索方法，证明其在自行车设计案例中的有效性。

    

    本文介绍了一种新型的设计问题反事实优化方法——多目标设计反事实(MCD)。反事实是指可能导致不同决策或选择的假设情况。本文将反事实搜索问题框架化为设计建议工具，可以帮助识别对设计进行修改，从而提高功能性能。MCD通过支持多目标查询和解耦反事实搜索和采样过程来提高效率并促进目标权衡可视化，改进了现有的反事实搜索方法。本文使用二维测试案例证明了MCD的核心功能，然后通过三个自行车设计案例研究展示了MCD在实际设计问题中的有效性。在第一个案例研究中，MCD在推荐对查询设计进行修改方面表现出色，可以显著提高自行车的性能。

    We introduce Multi-Objective Counterfactuals for Design (MCD), a novel method for counterfactual optimization in design problems. Counterfactuals are hypothetical situations that can lead to a different decision or choice. In this paper, the authors frame the counterfactual search problem as a design recommendation tool that can help identify modifications to a design, leading to better functional performance. MCD improves upon existing counterfactual search methods by supporting multi-objective queries, which are crucial in design problems, and by decoupling the counterfactual search and sampling processes, thus enhancing efficiency and facilitating objective tradeoff visualization. The paper demonstrates MCD's core functionality using a two-dimensional test case, followed by three case studies of bicycle design that showcase MCD's effectiveness in real-world design problems. In the first case study, MCD excels at recommending modifications to query designs that can significantly enha
    
[^23]: 关于一般函数逼近下的均场强化学习的统计效率

    On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])

    [http://arxiv.org/abs/2305.11283](http://arxiv.org/abs/2305.11283)

    本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。

    

    本文研究了一般函数逼近下的均场控制（MFC）和均场博弈（MFG）中强化学习的统计效率。引入了一种称为Mean-Field Model-Based Eluder Dimension (MBED)的新概念，包含了一系列丰富的均场强化学习问题。此外，我们提出了基于乐观最大似然估计的算法，可以返回一个$\epsilon$优的策略，适用于MFC或$\epsilon$纳什均衡策略适用于MFG，样本复杂度多项式与相关参数无关，与状态、动作和代理数量无关。值得注意的是，我们的结果仅对转移动力学具有Lipschitz连续性的假设，避免了以前的强结构假设。最后，在tabular设置下，假设有一个生成模型，我们建立了一个指数级的下界支持MFC设置，同时提供了一种新颖的样本高效的模型消除算法以逼近最优策略。

    In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
    
[^24]: 实时变分方法学习神经轨迹及其动力学

    Real-Time Variational Method for Learning Neural Trajectory and its Dynamics. (arXiv:2305.11278v1 [stat.ML])

    [http://arxiv.org/abs/2305.11278](http://arxiv.org/abs/2305.11278)

    本论文介绍了一种实时的递归贝叶斯方法用于推断神经轨迹及其动力学，能够广泛适用于任意似然，同时有效跟踪神经元中钙成像数据的动态。

    

    潜变量模型在计算神经科学中已成为推理神经计算的重要工具。这促进了从神经记录中提取潜在神经轨迹的强大离线算法的发展。然而，尽管实时替代方案能够为实验者立即提供反馈并增强实验设计能力，但它们得到的关注要少得多。在本研究中，我们介绍了指数族变分卡尔曼滤波器（eVKF），这是一种在线递归贝叶斯方法，旨在推断潜在轨迹同时学习产生它们的动力系统。eVKF适用于任意似然，并利用常数基本测度指数族来模拟潜在状态的随机性。我们得出了卡尔曼滤波器预测步骤的闭式变分类比，它比另一种在线变分方法产生了可证明更紧的ELBO界限。我们在合成数据上验证了我们的方法，并展示了它在跟踪神经元中钙成像数据的动态方面的有效性。

    Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation. This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings. However, despite the potential of real time alternatives to give immediate feedback to experimentalists, and enhance experimental design, they have received markedly less attention. In this work, we introduce the exponential family variational Kalman filter (eVKF), an online recursive Bayesian method aimed at inferring latent trajectories while simultaneously learning the dynamical system generating them. eVKF works for arbitrary likelihoods and utilizes the constant base measure exponential family to model the latent state stochasticity. We derive a closed-form variational analogue to the predict step of the Kalman filter which leads to a provably tighter bound on the ELBO compared to another online variational method. We validate our metho
    
[^25]: 证据网络：用简单的损失函数快速、分摊式地进行神经贝叶斯模型比较

    Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison. (arXiv:2305.11241v1 [cs.LG])

    [http://arxiv.org/abs/2305.11241](http://arxiv.org/abs/2305.11241)

    本论文提出了一种名为证据网络的方法，能够在处理似然函数或先验函数与嵌套抽样无法胜任的情况下实现贝叶斯模型比较。与传统方法不同的是，该方法使用了新的损失函数，使得我们能够更快速地、更有效地估算贝叶斯因子。

    

    证据网络可在当现有的方法（如嵌套抽样）失败、似然函数或先验函数难以处理或不知道的情况下实现贝叶斯模型比较。贝叶斯模型比较可看作一个优化问题。虽然用贝叶斯法进行最优分类的解释已经众所周知，但在这里，我们改变了视角，提出了一系列损失函数，以产生快速、分摊式的神经估计器，直接估算方便的贝叶斯因子的函数。这减少了估算单个模型概率时的数字不准确性。我们介绍了渗漏奇 parity-odd power（l-POP）变换，引导了新的“l-Pop-Exponential”的损失函数。我们探讨了在不同模型中对数据概率进行神经密度估计，结果表明这种方法比证据网络的精度和可扩展性都要低。多种实际和人造例子证明了证据网络的优越性。

    Evidence Networks can enable Bayesian model comparison when state-of-the-art methods (e.g. nested sampling) fail and even when likelihoods or priors are intractable or unknown. Bayesian model comparison, i.e. the computation of Bayes factors or evidence ratios, can be cast as an optimization problem. Though the Bayesian interpretation of optimal classification is well-known, here we change perspective and present classes of loss functions that result in fast, amortized neural estimators that directly estimate convenient functions of the Bayes factor. This mitigates numerical inaccuracies associated with estimating individual model probabilities. We introduce the leaky parity-odd power (l-POP) transform, leading to the novel ``l-POP-Exponential'' loss function. We explore neural density estimation for data probability in different models, showing it to be less accurate and scalable than Evidence Networks. Multiple real-world and synthetic examples illustrate that Evidence Networks are e
    
[^26]: 大规模并行重新加权唤醒-睡眠

    Massively Parallel Reweighted Wake-Sleep. (arXiv:2305.11022v1 [cs.LG])

    [http://arxiv.org/abs/2305.11022](http://arxiv.org/abs/2305.11022)

    大规模并行重新加权唤醒-睡眠算法通过抽取$K^n$个可能的样本组合，避免了原方法中大量潜在变量数目导致有效性下降问题。

    

    重新加权唤醒-睡眠算法（RWS）是一种适用于非常通用的模型执行贝叶斯推断的机器学习方法。它从潜在近似后验概率中抽取$K$个样本，然后使用重要性加权来提供更好的真实后验概率估计。RWS然后更新其近似后验概率，向真实后验概率的重要性加权估计移动。然而，近期的研究表明，对于有效的重要性加权，所需样本数与潜在变量的数量呈指数关系。在所有但最小的模型中实现如此大数量的重要性样本是不可行的。 在这里，我们开发了大规模并行的RWS，通过抽取所有$n$个潜在变量的$K$个样本，并单独考虑所有$K^n$个可能的样本组合，避免了这个问题。虽然考虑$K^n$个组合似乎是不可行的，但所需的计算可以通过利用计算结构简化在多项式时间内完成。

    Reweighted wake-sleep (RWS) is a machine learning method for performing Bayesian inference in a very general class of models. RWS draws $K$ samples from an underlying approximate posterior, then uses importance weighting to provide a better estimate of the true posterior. RWS then updates its approximate posterior towards the importance-weighted estimate of the true posterior. However, recent work [Chattergee and Diaconis, 2018] indicates that the number of samples required for effective importance weighting is exponential in the number of latent variables. Attaining such a large number of importance samples is intractable in all but the smallest models. Here, we develop massively parallel RWS, which circumvents this issue by drawing $K$ samples of all $n$ latent variables, and individually reasoning about all $K^n$ possible combinations of samples. While reasoning about $K^n$ combinations might seem intractable, the required computations can be performed in polynomial time by exploiti
    
[^27]: 基于物理约束的符号回归中主动学习的表现

    Active Learning in Symbolic Regression Performance with Physical Constraints. (arXiv:2305.10379v1 [cs.LG])

    [http://arxiv.org/abs/2305.10379](http://arxiv.org/abs/2305.10379)

    本文探讨了利用进化符号回归作为主动学习中的方法来提出哪些数据应该被采集，通过“委员会查询”来减少所需数据，并在重新发现已知方程所需的数据方面实现最新的结果。

    

    进化符号回归（SR）是一种将符号方程拟合到数据中的方法，可以得到简洁易懂的模型。本文探讨使用SR作为主动学习中的方法来提出哪些数据应该被采集，在此过程中考虑物理约束。基于主动学习的SR通过“委员会查询”来提出下一步实验。物理约束可以在非常低的数据情况下改善所建议的方程。这些方法可以减少SR所需的数据，并在重新发现已知方程所需的数据方面实现最新的结果。

    Evolutionary symbolic regression (SR) fits a symbolic equation to data, which gives a concise interpretable model. We explore using SR as a method to propose which data to gather in an active learning setting with physical constraints. SR with active learning proposes which experiments to do next. Active learning is done with query by committee, where the Pareto frontier of equations is the committee. The physical constraints improve proposed equations in very low data settings. These approaches reduce the data required for SR and achieves state of the art results in data required to rediscover known equations.
    
[^28]: 针对线性和非线性重尾多臂老虎机的隐式范数预测器的修剪

    Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits. (arXiv:2305.06743v1 [cs.LG])

    [http://arxiv.org/abs/2305.06743](http://arxiv.org/abs/2305.06743)

    本文提出了一种针对奖励分布重尾的MAB问题的隐式规范化预测器，证明该方法在线性和非线性重尾随机MAB问题上是最优的。

    

    已知隐式范数预测器（在线镜像下降，以Tsallis熵作为prox函数）是对抗性多臂老虎机问题（MAB）的最佳算法。但是，大多数复杂性结果都依赖于有界奖励或其他限制性假设。最近有关最佳二者结合算法的研究已经针对对手性和随机重尾MAB设置进行了探讨。这个算法在这两种情况下都是最优的，但不能充分利用数据。在本文中，我们针对奖励分布重尾的MAB问题提出了带剪辑的隐式规范化预测器。我们在奖励分布上提出渐进收敛性结果，并证明所提出的方法对于线性和非线性重尾随机MAB问题是最优的。我们还证明了与最好的二者结合算法相比，该算法通常表现更好。

    Implicitly Normalized Forecaster (online mirror descent with Tsallis entropy as prox-function) is known to be an optimal algorithm for adversarial multi-armed problems (MAB). However, most of the complexity results rely on bounded rewards or other restrictive assumptions. Recently closely related best-of-both-worlds algorithm were proposed for both adversarial and stochastic heavy-tailed MAB settings. This algorithm is known to be optimal in both settings, but fails to exploit data fully. In this paper, we propose Implicitly Normalized Forecaster with clipping for MAB problems with heavy-tailed distribution on rewards. We derive convergence results under mild assumptions on rewards distribution and show that the proposed method is optimal for both linear and non-linear heavy-tailed stochastic MAB problems. Also we show that algorithm usually performs better compared to best-of-two-worlds algorithm.
    
[^29]: 可解释人工智能的范畴基础：一种统一的结构和语义形式体系。

    Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics. (arXiv:2304.14094v1 [cs.AI])

    [http://arxiv.org/abs/2304.14094](http://arxiv.org/abs/2304.14094)

    本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。

    

    可解释人工智能（XAI）旨在回答与AI模型部署相关的伦理和法律问题。然而，相当数量的领域特定评论强调需要一个数学基础来定义领域中的关键概念，即使“解释”这个术语还缺乏精确定义。这些评论还主张建立一个健全而统一的可解释AI形式体系，以避免出现不良提出问题，帮助研究人员浏览一个快速增长的知识体系。据作者所知，该论文是填补该空白的首次尝试，通过形式化一个可解释AI的统一理论。采用范畴理论的框架，特别是反馈单调范畴，我们首先提供了可解释AI中所有重要术语的形式定义。然后，我们提出了一个遵循提出结构的领域分类法，展示了如何使用引入的理论来对当前研究的所有主要XAI系统类进行分类。

    Explainable AI (XAI) aims to answer ethical and legal questions associated with the deployment of AI models. However, a considerable number of domain-specific reviews highlight the need of a mathematical foundation for the key notions in the field, considering that even the term "explanation" still lacks a precise definition. These reviews also advocate for a sound and unifying formalism for explainable AI, to avoid the emergence of ill-posed questions, and to help researchers navigate a rapidly growing body of knowledge. To the authors knowledge, this paper is the first attempt to fill this gap by formalizing a unifying theory of XAI. Employing the framework of category theory, and feedback monoidal categories in particular, we first provide formal definitions for all essential terms in explainable AI. Then we propose a taxonomy of the field following the proposed structure, showing how the introduced theory can be used to categorize all the main classes of XAI systems currently studi
    
[^30]: 变分扩散自编码器：具有无条件扩散先验的深层潜变量模型

    Variational Diffusion Auto-encoder: Deep Latent Variable Model with Unconditional Diffusion Prior. (arXiv:2304.12141v1 [cs.LG])

    [http://arxiv.org/abs/2304.12141](http://arxiv.org/abs/2304.12141)

    本文提出了一种基于扩散模型对条件数据分布进行建模的变分扩散自编码器方法，它避免了对参数形式做出强烈假设，可以显著提高生成图像的质量。

    

    变分自编码器是深度生成建模的一种最流行的方法。尽管取得了成功，但因为高度不现实的建模假设，即条件数据分布p(x|z)可以近似为各向同性高斯分布，所以由变分自编码器生成的图像是模糊的。在本文中，我们引入了一种基于扩散模型对条件数据分布p(x|z)进行建模的原则性方法。我们证明了可以创建类似变分自编码器的深潜变量模型，而无需对p(x|z)做高斯假设，甚至不需要训练解码器网络。通过Bayes'规则，可以将经过训练的编码器和无条件扩散模型组合到一起，以获得一个表达丰富的p(x|z)模型。我们的方法避免了对参数形式p(x|z)做出强烈假设，因此可以显著提高生成图像的质量。

    Variational auto-encoders (VAEs) are one of the most popular approaches to deep generative modeling. Despite their success, images generated by VAEs are known to suffer from blurriness, due to a highly unrealistic modeling assumption that the conditional data distribution $ p(\textbf{x} | \textbf{z})$ can be approximated as an isotropic Gaussian. In this work we introduce a principled approach to modeling the conditional data distribution $p(\textbf{x} | \textbf{z})$ by incorporating a diffusion model. We show that it is possible to create a VAE-like deep latent variable model without making the Gaussian assumption on $ p(\textbf{x} | \textbf{z}) $ or even training a decoder network. A trained encoder and an unconditional diffusion model can be combined via Bayes' rule for score functions to obtain an expressive model for $ p(\textbf{x} | \textbf{z}) $. Our approach avoids making strong assumptions on the parametric form of $ p(\textbf{x} | \textbf{z}) $, and thus allows to significant
    
[^31]: 将未标记数据纳入贝叶斯神经网络中

    Incorporating Unlabelled Data into Bayesian Neural Networks. (arXiv:2304.01762v1 [cs.LG])

    [http://arxiv.org/abs/2304.01762](http://arxiv.org/abs/2304.01762)

    该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。

    

    我们提出了一个对贝叶斯神经网络（BNNs）中先验分布进行学习的对比框架，利用未标记数据来优化。基于该框架，我们提出了一种实用的BNN算法，同时具备自监督学习的标签效率和贝叶斯方法中的根据原则的不确定性估计。最后，我们展示了我们的方法在半监督和低预算主动学习问题中的数据高效学习优势。

    We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.
    
[^32]: 关于锐度感知最小化的统计性质：可证明的保证

    On Statistical Properties of Sharpness-Aware Minimization: Provable Guarantees. (arXiv:2302.11836v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.11836](http://arxiv.org/abs/2302.11836)

    SAM是一种优化框架，旨在通过获得更平坦（即更不锐利）的解来改善深度神经网络的泛化能力。我们研究两个统计问题，在某些条件下，证明了SAM在预测误差方面比梯度下降有更小的误差，并适用于非凸问题。此外，我们的设置表明，SAM的解更不锐利，证明了我们的结论。

    

    锐度感知最小化 (SAM) 是一种旨在通过获得更平坦（即更不锐利）的解来改善深度神经网络泛化能力的最新优化框架。由于SAM在数值上十分成功，因此最近的论文研究了该框架的理论方面，并表明SAM的解确实是平坦的。然而，在SAM的统计性质方面，理论探索有限。本文直接研究SAM的统计性能，并提出了一个新的理论解释，解释了为什么SAM能够进行良好的泛化。为此，我们研究了两个统计问题，包括具有隐藏层的神经网络和核回归，并证明在某些条件下，SAM对于梯度下降(GD)相比有更小的预测误差。我们的结果涉及凸和非凸设置，并表明SAM特别适用于非凸问题。此外，我们还证明，在我们的设置中，SAM的解也更不锐利，证明了我们的结论。

    Sharpness-Aware Minimization (SAM) is a recent optimization framework aiming to improve the deep neural network generalization, through obtaining flatter (i.e. less sharp) solutions. As SAM has been numerically successful, recent papers have studied the theoretical aspects of the framework and have shown SAM solutions are indeed flat. However, there has been limited theoretical exploration regarding statistical properties of SAM. In this work, we directly study the statistical performance of SAM, and present a new theoretical explanation of why SAM generalizes well. To this end, we study two statistical problems, neural networks with a hidden layer and kernel regression, and prove under certain conditions, SAM has smaller prediction error over Gradient Descent (GD). Our results concern both convex and non-convex settings, and show that SAM is particularly well-suited for non-convex problems. Additionally, we prove that in our setup, SAM solutions are less sharp as well, showing our res
    
[^33]: 重参数化下神经网络参数空间的几何学

    The Geometry of Neural Nets' Parameter Spaces Under Reparametrization. (arXiv:2302.07384v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07384](http://arxiv.org/abs/2302.07384)

    研究了神经网络在重参数化下的不变性，如果显式地表示度量并使用正确的相关变换规则，则不变性是任何神经网络的固有属性。

    

    模型重参数化是改善神经网络训练的一种流行方法，但也可能存在问题，如在Hessian平坦度测量、优化轨迹和概率密度模式等方面引入不一致性。这使得下游分析变得更为复杂：例如，由于任意的重参数化都可以改变二者之间的关系，因此无法明确地将平坦度与泛化联系起来。在本文中，我们从黎曼几何的角度研究了神经网络在重参数化下的不变性。从这个角度来看，如果我们显式地表示度量并使用正确的相关变换规则，那么不变性是任何神经网络的固有属性。这一点很重要，因为尽管度量始终存在，但通常被隐式地假定为单位矩阵，并因此从符号中省略，然后在重参数化下丢失了。我们讨论了衡量平坦度所带来的启示。

    Model reparametrization, which follows the change-of-variable rule of calculus, is a popular way to improve the training of neural nets. But it can also be problematic since it can induce inconsistencies in, e.g., Hessian-based flatness measures, optimization trajectories, and modes of probability densities. This complicates downstream analyses: e.g. one cannot definitively relate flatness with generalization since arbitrary reparametrization changes their relationship. In this work, we study the invariance of neural nets under reparametrization from the perspective of Riemannian geometry. From this point of view, invariance is an inherent property of any neural net if one explicitly represents the metric and uses the correct associated transformation rules. This is important since although the metric is always present, it is often implicitly assumed as identity, and thus dropped from the notation, then lost under reparametrization. We discuss implications for measuring the flatness of
    
[^34]: 二次内存是实现凸优化最优查询复杂度所必需的：质心是帕累托优化

    Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal. (arXiv:2302.04963v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04963](http://arxiv.org/abs/2302.04963)

    本文证明了在凸优化中，实现最优 oracle 复杂性所必需要的内存为二次，并且在处理 1-Lipschitz 凸函数时，使用 $d^{2-\delta}$ 内存的任何算法都需要进行 $\tilde\Omega(d^{1+\delta/3})$ 次查询。此外，在可行性问题中，使用至多 $d^{2-\delta}$ 存储器容量的分离 oracle 需要进行 $\tilde\Omega(d^{1+\delta})$ 次查询。

    

    我们给出了凸优化及相关可行性问题的查询复杂性下界。我们表明，实现凸优化的一阶最优性的最优 oracle 复杂性所必需的内存是二次的。特别地，这表明在维度 $d$ 中使用 $\tilde O(d^2)$ 内存和 $\tilde O(d)$ 查询的质心切平面算法对凸优化和可行性问题来说都是帕累托最优的，精度为 $1/d^4$，上限为对数因子。确切地说，我们证明为了在单位球上将 $1$-Lipschitz 凸函数最小化到 $1/d^4$ 的精度，任何使用至多 $d^{2-\delta}$ 个内存位的确定性一阶算法都必须进行 $\tilde\Omega(d^{1+\delta/3})$ 次查询，其中 $\delta\in[0,1]$。对于可行性问题，在其只有访问分离 oracle 的情况下，我们展示了更强的权衡：对于至多 $d^{2-\delta}$ 的存储器容量，所需的查询数量为 $\tilde\Omega(d^{1+\delta})$。这解决了 COLT 2019 的一个未解决问题。

    We give query complexity lower bounds for convex optimization and the related feasibility problem. We show that quadratic memory is necessary to achieve the optimal oracle complexity for first-order convex optimization. In particular, this shows that center-of-mass cutting-planes algorithms in dimension $d$ which use $\tilde O(d^2)$ memory and $\tilde O(d)$ queries are Pareto-optimal for both convex optimization and the feasibility problem, up to logarithmic factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions over the unit ball to $1/d^4$ accuracy, any deterministic first-order algorithms using at most $d^{2-\delta}$ bits of memory must make $\tilde\Omega(d^{1+\delta/3})$ queries, for any $\delta\in[0,1]$. For the feasibility problem, in which an algorithm only has access to a separation oracle, we show a stronger trade-off: for at most $d^{2-\delta}$ memory, the number of queries required is $\tilde\Omega(d^{1+\delta})$. This resolves a COLT 2019 open problem 
    
[^35]: 位置-尺度噪声模型中因果推断的最大似然与独立性检验比较研究

    Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing. (arXiv:2301.12930v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12930](http://arxiv.org/abs/2301.12930)

    通过引入异方差位置-尺度噪声函数模型，该论文在正确说明噪声分布的情况下，通过最大似然实现了最先进的准确性。但是，在用户错误指定噪声分布的形式时，分析表明因果推断的精度会急剧下降。因此，该论文提出通过因果模型选择实现稳定而准确的因果推断。

    

    因果发现的一个基本问题是推断两个随机变量之间的正确因果方向。最近引入的异方差位置-尺度噪声函数模型 (LSNM) 结合了表达能力和可识别性保证，在正确指定噪声分布的情况下，通过最大似然实现了最先进的准确性。然而，我们通过广泛的实证评估表明，当用户错误指定噪声分布的形式时，精度会急剧下降。我们的分析表明，这种失败主要发生在反因果方向的条件方差小于因果方向的条件方差的情况下。作为一种替代方案，发现通过因果模型选择可以在缺乏噪声分布知识的情况下，实现稳定而准确的因果推断。

    A fundamental problem of causal discovery is cause-effect inference, learning the correct causal direction between two random variables. Significant progress has been made through modelling the effect as a function of its cause and a noise term, which allows us to leverage assumptions about the generating function class. The recently introduced heteroscedastic location-scale noise functional models (LSNMs) combine expressive power with identifiability guarantees. LSNM model selection based on maximizing likelihood achieves state-of-the-art accuracy, when the noise distributions are correctly specified. However, through an extensive empirical evaluation, we demonstrate that the accuracy deteriorates sharply when the form of the noise distribution is misspecified by the user. Our analysis shows that the failure occurs mainly when the conditional variance in the anti-causal direction is smaller than that in the causal direction. As an alternative, we find that causal model selection throu
    
[^36]: 使用聚合相似矩阵的多层超图聚类

    Multilayer hypergraph clustering using the aggregate similarity matrix. (arXiv:2301.11657v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2301.11657](http://arxiv.org/abs/2301.11657)

    本文提出了一个半定规划方法来解决基于超图的多层聚类问题，同时在同配和非同配情况下保证了精确恢复。

    

    本文考虑在超图的多层变体上执行社区恢复问题，每个层与 N 个顶点上的 d-均匀超图随机块模型 (HSBM) 的独立实现相关。给出包含与每对顶点相交的超边数量聚合的相似矩阵，目标是将 N 个顶点划分为不相交的社区。在本文中，我们研究了半定规划 (SDP) 方法，并获得了有关模型参数的信息论条件，保证在同配和非同配情况下均能确保精确恢复。

    We consider the community recovery problem on a multilayer variant of the hypergraph stochastic block model (HSBM). Each layer is associated with an independent realization of a d-uniform HSBM on N vertices. Given the similarity matrix containing the aggregated number of hyperedges incident to each pair of vertices, the goal is to obtain a partition of the N vertices into disjoint communities. In this work, we investigate a semidefinite programming (SDP) approach and obtain information-theoretic conditions on the model parameters that guarantee exact recovery both in the assortative and the disassortative cases.
    
[^37]: 扩散模型暗中识别数据流形的维度

    Your diffusion model secretly knows the dimension of the data manifold. (arXiv:2212.12611v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12611](http://arxiv.org/abs/2212.12611)

    本研究提出了一种新的方法，利用扩散模型估算数据流形的维度并且在实验中表现出色。

    

    本研究提出了一种使用训练过的扩散模型估算数据流形维度的新框架。扩散模型逐渐逼近目标分布的梯度，即噪声污染版本的对数密度的梯度，不同级别的污染程度对应不同的梯度。我们证明，如果数据集聚焦于高维环境空间中嵌入的流形，那么随着噪声污染程度的降低，梯度会指向流形，因为这个方向是最大似然增加的方向。因此，在污染程度较低时，扩散模型为我们提供了数据流形正常向量的逼近。这使我们能够估计切空间的维度，也就是数据流形的内在维度。据我们所知，我们的方法是基于扩散模型的数据流形维度的第一个估算器，并且胜过了已经成熟的统计方法。

    In this work, we propose a novel framework for estimating the dimension of the data manifold using a trained diffusion model. A diffusion model approximates the score function i.e. the gradient of the log density of a noise-corrupted version of the target distribution for varying levels of corruption. We prove that, if the data concentrates around a manifold embedded in the high-dimensional ambient space, then as the level of corruption decreases, the score function points towards the manifold, as this direction becomes the direction of maximal likelihood increase. Therefore, for small levels of corruption, the diffusion model provides us with access to an approximation of the normal bundle of the data manifold. This allows us to estimate the dimension of the tangent space, thus, the intrinsic dimension of the data manifold. To the best of our knowledge, our method is the first estimator of the data manifold dimension based on diffusion models and it outperforms well established statis
    
[^38]: 基于$\phi$-离散度的分布鲁棒贝叶斯优化

    Distributionally Robust Bayesian Optimization with $\phi$-divergences. (arXiv:2203.02128v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.02128](http://arxiv.org/abs/2203.02128)

    本研究提出了一种基于$\phi$-离散度的分布鲁棒贝叶斯优化算法。

    

    鲁棒性研究因其在面对不确定性的许多系统中不可避免而受到广泛关注。其中一个例子是贝叶斯优化，它面临着多方面的不确定性，但仅有少量的研究致力于这个方向。在现有研究的基础上，我们提出了一种基于$\phi$-离散度的分布鲁棒贝叶斯优化算法。

    The study of robustness has received much attention due to its inevitability in data-driven settings where many systems face uncertainty. One such example of concern is Bayesian Optimization (BO), where uncertainty is multi-faceted, yet there only exists a limited number of works dedicated to this direction. In particular, there is the work of Kirschner et al. (2020), which bridges the existing literature of Distributionally Robust Optimization (DRO) by casting the BO problem from the lens of DRO. While this work is pioneering, it admittedly suffers from various practical shortcomings such as finite contexts assumptions, leaving behind the main question Can one devise a computationally tractable algorithm for solving this DRO-BO problem? In this work, we tackle this question to a large degree of generality by considering robustness against data-shift in $\phi$-divergences, which subsumes many popular choices, such as the $\chi^2$-divergence, Total Variation, and the extant Kullback-Lei
    
[^39]: 抗相关噪声注入用于提高泛化性能

    Anticorrelated Noise Injection for Improved Generalization. (arXiv:2202.02831v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.02831](http://arxiv.org/abs/2202.02831)

    本文发现，在一些目标函数中，抗相关噪声的梯度下降方法比传统的梯度下降和常规扰动梯度下降有更好的泛化性能。理论分析证明了这是因为 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。

    

    将人工噪声注入梯度下降常常被用于改善机器学习模型的性能。通常，这种扰动的梯度下降方法使用的是不相关的噪声。然而，目前尚不清楚是否使用不同类型的噪声能够提供更好的泛化性能。本文聚焦于相关的扰动。我们研究了各种目标函数，发现带有抗相关扰动的梯度下降（"Anti-PGD"）比传统的梯度下降和常规的（不相关的）扰动梯度下降有着更好的泛化性能。为了支持这些实验结果，我们还进行了理论分析，证明了 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。这一新颖的抗相关噪声与泛化性能的联系为训练机器学习模型提供了新的方法。

    Injecting artificial noise into gradient descent (GD) is commonly employed to improve the performance of machine learning models. Usually, uncorrelated noise is used in such perturbed gradient descent (PGD) methods. It is, however, not known if this is optimal or whether other types of noise could provide better generalization performance. In this paper, we zoom in on the problem of correlating the perturbations of consecutive PGD steps. We consider a variety of objective functions for which we find that GD with anticorrelated perturbations ("Anti-PGD") generalizes significantly better than GD and standard (uncorrelated) PGD. To support these experimental findings, we also derive a theoretical analysis that demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge. This new connection between anticorrelated noise and generalization opens the field to novel ways to exploit noise for training machine learning models.
    

