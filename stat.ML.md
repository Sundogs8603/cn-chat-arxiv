# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A tree-based varying coefficient model.](http://arxiv.org/abs/2401.05982) | 本论文介绍了一种基于树的可变系数模型，使用循环梯度提升机进行建模，实现了逐维早停和特征重要性评分，该模型能够产生与基于神经网络的VCM相当的结果。 |
| [^2] | [Combining Normalizing Flows and Quasi-Monte Carlo.](http://arxiv.org/abs/2401.05934) | 本研究将正则化流和准蒙特卡洛方法相结合，通过使用准蒙特卡洛方法采样流的初始分布，实现了具有显著更低方差的估计。 |
| [^3] | [Feature Selection for Functional Data Classification.](http://arxiv.org/abs/2401.05765) | 本文介绍了一种名为FSFC的新方法，它解决了在具有分类响应和纵向特征的情况下同时进行功能数据特征选择和分类的挑战。 |
| [^4] | [Kernelized Normalizing Constant Estimation: Bridging Bayesian Quadrature and Bayesian Optimization.](http://arxiv.org/abs/2401.05716) | 本文研究了通过查询黑盒函数来估计归一化常数的问题，发现问题的难度取决于问题参数$\lambda$的大小，当$\lambda$趋近于零时类似于贝叶斯积分(BQ)，当$\lambda$趋近于无穷大时类似于贝叶斯优化(BO)，且这种模式适用于存在噪声的情况。结果得到了算法无关的下界和上界的支持，以及模拟研究的验证。 |
| [^5] | [An Augmented Surprise-guided Sequential Learning Framework for Predicting the Melt Pool Geometry.](http://arxiv.org/abs/2401.05579) | 本研究引入了一种新颖的增强惊喜引导的顺序学习框架SurpriseAF-BO，用于预测熔池几何形状。这种框架通过迭代自适应学习过程，模拟了工艺参数与熔池特性之间的动力学关系，并在有限数据集条件下进行了学习。 |
| [^6] | [A general theory for robust clustering via trimmed mean.](http://arxiv.org/abs/2401.05574) | 本文提出了一种通过使用修剪均值类型的中心点估计的混合聚类技术，用于在存在次高斯误差的中心点周围分布的弱初始化条件下产生最优错误标记保证，并且在存在敌对异常值的情况下仍然有效。 |
| [^7] | [Improving the Accuracy and Interpretability of Random Forests via Forest Pruning.](http://arxiv.org/abs/2401.05535) | 通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。 |
| [^8] | [HoloBeam: Learning Optimal Beamforming in Far-Field Holographic Metasurface Transceivers.](http://arxiv.org/abs/2401.05420) | Holographic Metasurface Transceivers (HMTs) are being used as cost-effective substitutes for large antenna arrays for beamforming in Millimeter and TeraHertz wave communication. In this work, a learning algorithm is developed to optimize beamforming in far-field regions, by using a fixed-budget multi-armed bandit framework to maximize received signal strength. The algorithm exploits the parametric form of channel gains and works with the discrete values of phase-shifting parameters. |
| [^9] | [Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery.](http://arxiv.org/abs/2401.05394) | 该论文介绍了一种新的迭代正则化算法IRKSN，它通过使用$k$支撑范数正则化实现稀疏恢复，并提供了条件。这是对基于$\ell_1$范数的迭代方法的一种重要补充。 |
| [^10] | [Bayesian ECG reconstruction using denoising diffusion generative models.](http://arxiv.org/abs/2401.05388) | 这项工作提出了一种使用健康心电图数据训练的去噪扩散生成模型，成功生成逼真的心电图信号，并且应用于心脏健康监测和诊断领域，实现了校正QT间期、噪声抑制、心电图导联恢复和异常读数识别等重要临床工具的开发。 |
| [^11] | [On the Correctness of the Generalized Isotonic Recursive Partitioning Algorithm.](http://arxiv.org/abs/2401.04847) | 本文通过深入分析广义等增递归分割算法（GIRP），在可分离凸损失和不可微损失的情况下，解决了等增回归问题的存在性和唯一性，并提出了递归二分分割的方法来找到解。 |
| [^12] | [Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT.](http://arxiv.org/abs/2401.03302) | 本研究利用深度学习技术在具有挑战性的情况下检测和分类脑肿瘤，并解决了在罕见情况下的肿瘤检测问题。研究使用了来自国家脑映射实验室的数据集，通过修改样本数量和患者分布，使模型能够应对真实世界场景中的异常情况。 |
| [^13] | [TaCo: Targeted Concept Removal in Output Embeddings for NLP via Information Theory and Explainability.](http://arxiv.org/abs/2312.06499) | 本论文提出了一种新颖的方法，通过对NLP模型的嵌入层级进行操作，借鉴了最新的解释性人工智能技术，通过嵌入转换来消除隐含的敏感信息，从而实现模型的公平性。 |
| [^14] | [Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures.](http://arxiv.org/abs/2311.00636) | 本篇论文提出了一种用于现代神经网络架构的克罗内克近似曲率算法，可以加速神经网络训练和减少计算成本。作者发现了两种具有线性权重共享层不同设置，并证明了相应设置下的K-FAC算法的精确性。K-FAC-reduce通常比K-FAC-expand更快，可以用于加速自动超参数选择。 |
| [^15] | [Trinary Decision Trees for missing value handling.](http://arxiv.org/abs/2309.03561) | 本文介绍了一种称为三值决策树的算法，用于改善决策树在处理缺失数据时的表现。与其他方法不同，该算法不假设缺失值包含任何关于响应的信息。实验证明，在特定缺失数据场景下，三值决策树在MCAR设置中表现优异，在IM设置中略逊一筹。同时，通过将三值决策树与缺失在属性方法相结合，可以获得更稳健的性能。尽管训练速度较慢，但三值决策树提供了一种有前途且更准确的方法。 |
| [^16] | [Deep graphical regression for jointly moderate and extreme Australian wildfires.](http://arxiv.org/abs/2308.14547) | 该论文介绍了一种利用深度图形回归方法来联合调节和预测澳大利亚野火的新方法。研究结果表明，对于火灾的全分布建模是非常关键的，因为极端野火可能导致巨大的影响，而小规模和中等规模火灾仍然会对当地社区和生态系统造成重大破坏。 |
| [^17] | [Gibbs Sampling the Posterior of Neural Networks.](http://arxiv.org/abs/2306.02729) | 这篇论文提出了一种添加噪声的神经网络模型，并使用Gibbs采样器从后验分布中进行采样，该方法在真实数据和合成数据中能够达到类似于马尔科夫链蒙特卡洛方法的性能。 |
| [^18] | [Resilient Constrained Learning.](http://arxiv.org/abs/2306.02426) | 本论文提出了一个名为“抗干扰约束学习”的方法来解决在部署机器学习解决方案时需要满足除了准确性以外的多个要求，并以平衡从放宽中获得的性能增益与用户定义的放宽成本之间的关系的方式放松学习约束。 |
| [^19] | [Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model.](http://arxiv.org/abs/2306.01424) | 本文研究了连续性结果的部分反事实识别问题，并提出了一种新颖的敏感性模型——曲率敏感模型，通过限制函数级集的曲率来获得信息边界。 |
| [^20] | [Black-Box Variational Inference Converges.](http://arxiv.org/abs/2305.15349) | 通过对黑盒变分推断（BBVI）的分析，发现一些常见的算法设计选择可能会导致次优收敛速率，但使用带有近端随机梯度下降的BBVI可以实现最强收敛率保证。 |
| [^21] | [A Log-Linear Non-Parametric Online Changepoint Detection Algorithm based on Functional Pruning.](http://arxiv.org/abs/2302.02718) | 提出了一个基于功能修剪的非参数在线变点检测算法，能够快速高效地检测高频数据流中的异常和变化，并且不依赖于违反实际应用中的参数假设。 |
| [^22] | [ARMA Cell: A Modular and Effective Approach for Neural Autoregressive Modeling.](http://arxiv.org/abs/2208.14919) | 本文介绍了ARMA单元，一种更简单、模块化和有效的神经网络时间序列建模方法，能够自然地处理多变量时间序列，并引入了ConvARMA单元作为一种解决方法。 |
| [^23] | [CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty.](http://arxiv.org/abs/2208.08626) | 本文提出了一种新的CP-PINNs模型，通过将PINNs与总变差惩罚相结合，实现了准确的变点检测和PDE的发现。我们还开发了一种元学习算法，能够在数据的连续批次上动态改进优化目标。实证结果表明，在存在变点的情况下，该方法能够准确估计参数和模型对齐，在没有变点的情况下能够数值上收敛到原始PINNs模型的解。 |
| [^24] | [An Explainable Stacked Ensemble Model for Static Route-Free Estimation of Time of Arrival.](http://arxiv.org/abs/2203.09438) | 本文提出了一种可解释的叠加集成模型，用于静态无路径估计到达时间。该模型将多个机器学习模型组合成一个新的集成结构，能够超越先前的最先进模型。 |
| [^25] | [GPEX, A Framework For Interpreting Artificial Neural Networks.](http://arxiv.org/abs/2112.09820) | 这篇论文提出了一种GPEX框架，用于解释深度人工神经网络，通过推导出一个证据下界来匹配神经网络的输出，而不对神经网络做出任何特定要求。实验证明，在一些理论假设下，只需要简单的网络结构即可达到良好性能。 |
| [^26] | [Adaptive variational Bayes: Optimality, computation and applications.](http://arxiv.org/abs/2109.03204) | 本文提出了一种新颖的自适应变分贝叶斯框架，可以在多个模型上运行。该方法能够自适应地实现最优的收缩速率，并提供了一种技术方法来保持可计算性和自适应最优性。 |

# 详细

[^1]: 基于树的可变系数模型介绍

    A tree-based varying coefficient model. (arXiv:2401.05982v1 [stat.ML])

    [http://arxiv.org/abs/2401.05982](http://arxiv.org/abs/2401.05982)

    本论文介绍了一种基于树的可变系数模型，使用循环梯度提升机进行建模，实现了逐维早停和特征重要性评分，该模型能够产生与基于神经网络的VCM相当的结果。

    

    本论文介绍了一种基于树的可变系数模型(VCM)，其中可变系数使用Delong等人(2023)的循环梯度提升机(CGBM)进行建模。使用CGBM对系数函数进行建模，可以进行逐维早停和特征重要性评分。逐维早停不仅可以减少维度特定的过拟合风险，还可以揭示维度之间模型复杂性的差异。使用特征重要性评分可以进行简单的特征选择和易于解释的模型解释。该模型在Richman和Wüthrich（2023）使用的相同的模拟和真实数据示例上进行评估，结果表明，它在样本外损失方面产生了与他们的基于神经网络的VCM LocalGLMnet相当的结果。

    The paper introduces a tree-based varying coefficient model (VCM) where the varying coefficients are modelled using the cyclic gradient boosting machine (CGBM) from Delong et al. (2023). Modelling the coefficient functions using a CGBM allows for dimension-wise early stopping and feature importance scores. The dimension-wise early stopping not only reduces the risk of dimension-specific overfitting, but also reveals differences in model complexity across dimensions. The use of feature importance scores allows for simple feature selection and easy model interpretation. The model is evaluated on the same simulated and real data examples as those used in Richman and W\"uthrich (2023), and the results show that it produces results in terms of out of sample loss that are comparable to those of their neural network-based VCM called LocalGLMnet.
    
[^2]: 结合正则化流和准蒙特卡洛方法

    Combining Normalizing Flows and Quasi-Monte Carlo. (arXiv:2401.05934v1 [stat.CO])

    [http://arxiv.org/abs/2401.05934](http://arxiv.org/abs/2401.05934)

    本研究将正则化流和准蒙特卡洛方法相结合，通过使用准蒙特卡洛方法采样流的初始分布，实现了具有显著更低方差的估计。

    

    机器学习的最新进展促使了改进蒙特卡洛方法（如马尔可夫链蒙特卡洛和重要性采样）的新方法的发展。其中一种方法是正则化流，它使用神经网络通过逐点评估来近似分布。正则化流已被证明可以提高马尔可夫链蒙特卡洛和重要性采样的性能。另一方面，（随机）准蒙特卡洛方法用于进行数值积分，它们用更均匀地覆盖超立方体的序列取代了蒙特卡洛的随机采样，从而使误差的收敛速度更快。在本研究中，我们通过使用准蒙特卡洛方法对流进行初始采样的方式结合了这两种方法。通过数值实验证明，与使用经典蒙特卡洛采样的流相比，这种组合可以导致具有显著更低方差的估计。

    Recent advances in machine learning have led to the development of new methods for enhancing Monte Carlo methods such as Markov chain Monte Carlo (MCMC) and importance sampling (IS). One such method is normalizing flows, which use a neural network to approximate a distribution by evaluating it pointwise. Normalizing flows have been shown to improve the performance of MCMC and IS. On the other side, (randomized) quasi-Monte Carlo methods are used to perform numerical integration. They replace the random sampling of Monte Carlo by a sequence which cover the hypercube more uniformly, resulting in better convergence rates for the error that plain Monte Carlo. In this work, we combine these two methods by using quasi-Monte Carlo to sample the initial distribution that is transported by the flow. We demonstrate through numerical experiments that this combination can lead to an estimator with significantly lower variance than if the flow was sampled with a classic Monte Carlo.
    
[^3]: 功能数据分类的特征选择

    Feature Selection for Functional Data Classification. (arXiv:2401.05765v1 [stat.ML])

    [http://arxiv.org/abs/2401.05765](http://arxiv.org/abs/2401.05765)

    本文介绍了一种名为FSFC的新方法，它解决了在具有分类响应和纵向特征的情况下同时进行功能数据特征选择和分类的挑战。

    

    功能数据分析已经成为许多需要整合和解释复杂数据的当代科学领域中的关键工具。此外，新技术的出现促进了大量纵向变量的收集，使得特征选择对于避免过拟合和提高预测性能至关重要。本文介绍了一种名为FSFC（功能分类特征选择）的新方法，它解决了在具有分类响应和纵向特征的情况下同时进行功能数据特征选择和分类的挑战。我们的方法解决了一个新定义的优化问题，将逻辑损失和功能特征结合起来，以识别用于分类的最关键特征。为了解决最小化过程，我们使用功能主成分，并开发了一种新的自适应版本的双增广Lagrange算法，利用了。。。

    Functional data analysis has emerged as a crucial tool in many contemporary scientific domains that require the integration and interpretation of complex data. Moreover, the advent of new technologies has facilitated the collection of a large number of longitudinal variables, making feature selection pivotal for avoiding overfitting and improving prediction performance. This paper introduces a novel methodology called FSFC (Feature Selection for Functional Classification), that addresses the challenge of jointly performing feature selection and classification of functional data in scenarios with categorical responses and longitudinal features. Our approach tackles a newly defined optimization problem that integrates logistic loss and functional features to identify the most crucial features for classification. To address the minimization procedure, we employ functional principal components and develop a new adaptive version of the Dual Augmented Lagrangian algorithm that leverages the 
    
[^4]: 基于核函数的归一化常数估计：连接贝叶斯积分和贝叶斯优化

    Kernelized Normalizing Constant Estimation: Bridging Bayesian Quadrature and Bayesian Optimization. (arXiv:2401.05716v1 [cs.LG])

    [http://arxiv.org/abs/2401.05716](http://arxiv.org/abs/2401.05716)

    本文研究了通过查询黑盒函数来估计归一化常数的问题，发现问题的难度取决于问题参数$\lambda$的大小，当$\lambda$趋近于零时类似于贝叶斯积分(BQ)，当$\lambda$趋近于无穷大时类似于贝叶斯优化(BO)，且这种模式适用于存在噪声的情况。结果得到了算法无关的下界和上界的支持，以及模拟研究的验证。

    

    本文研究通过黑盒函数查询来估计归一化常数$\int e^{-\lambda f(x)}dx$的问题，其中$f$属于再生核希尔伯特空间(RKHS)，而$\lambda$是一个问题参数。我们发现，为了在相对误差较小的情况下估计归一化常数，难度的级别取决于$\lambda$的值：当$\lambda$趋近于零时，问题类似于贝叶斯积分(BQ)，而当$\lambda$趋近于无穷大时，问题类似于贝叶斯优化(BO)。更一般地，问题在BQ和BO之间变化。我们发现，即使在函数评估存在噪声的情况下，这种模式仍然适用，为该主题带来了新的方面。我们的发现得到了算法无关的下界和算法上界的支持，以及在各种基准函数上进行的模拟研究。

    In this paper, we study the problem of estimating the normalizing constant $\int e^{-\lambda f(x)}dx$ through queries to the black-box function $f$, where $f$ belongs to a reproducing kernel Hilbert space (RKHS), and $\lambda$ is a problem parameter. We show that to estimate the normalizing constant within a small relative error, the level of difficulty depends on the value of $\lambda$: When $\lambda$ approaches zero, the problem is similar to Bayesian quadrature (BQ), while when $\lambda$ approaches infinity, the problem is similar to Bayesian optimization (BO). More generally, the problem varies between BQ and BO. We find that this pattern holds true even when the function evaluations are noisy, bringing new aspects to this topic. Our findings are supported by both algorithm-independent lower bounds and algorithmic upper bounds, as well as simulation studies conducted on a variety of benchmark functions.
    
[^5]: 针对预测熔池几何形状的增强惊喜引导的顺序学习框架

    An Augmented Surprise-guided Sequential Learning Framework for Predicting the Melt Pool Geometry. (arXiv:2401.05579v1 [cs.LG])

    [http://arxiv.org/abs/2401.05579](http://arxiv.org/abs/2401.05579)

    本研究引入了一种新颖的增强惊喜引导的顺序学习框架SurpriseAF-BO，用于预测熔池几何形状。这种框架通过迭代自适应学习过程，模拟了工艺参数与熔池特性之间的动力学关系，并在有限数据集条件下进行了学习。

    

    金属增材制造（MAM）已经重塑了制造业，提供了复杂设计、最小浪费、快速原型、材料多样性和定制解决方案等优势。然而，其在工业中的全面应用面临挑战，特别是在确保产品质量的一致性方面。MAM成功的关键因素是理解工艺参数与熔池特性之间的关系。将人工智能（AI）融入MAM是必不可少的。传统的机器学习方法虽然有效，却依赖于大数据集来捕捉复杂关系，而在MAM中，由于需要大量的时间和资源来创建数据集，这是一个重大挑战。我们的研究引入了一种新颖的增强惊喜引导的顺序学习框架SurpriseAF-BO，标志着MAM的重大转变。该框架采用迭代自适应学习过程，对工艺参数与熔池特性之间的动力学进行建模，并在有限数据集条件下进行学习。

    Metal Additive Manufacturing (MAM) has reshaped the manufacturing industry, offering benefits like intricate design, minimal waste, rapid prototyping, material versatility, and customized solutions. However, its full industry adoption faces hurdles, particularly in achieving consistent product quality. A crucial aspect for MAM's success is understanding the relationship between process parameters and melt pool characteristics. Integrating Artificial Intelligence (AI) into MAM is essential. Traditional machine learning (ML) methods, while effective, depend on large datasets to capture complex relationships, a significant challenge in MAM due to the extensive time and resources required for dataset creation. Our study introduces a novel surprise-guided sequential learning framework, SurpriseAF-BO, signaling a significant shift in MAM. This framework uses an iterative, adaptive learning process, modeling the dynamics between process parameters and melt pool characteristics with limited da
    
[^6]: 通过修剪均值的鲁棒聚类的一般理论

    A general theory for robust clustering via trimmed mean. (arXiv:2401.05574v1 [math.ST])

    [http://arxiv.org/abs/2401.05574](http://arxiv.org/abs/2401.05574)

    本文提出了一种通过使用修剪均值类型的中心点估计的混合聚类技术，用于在存在次高斯误差的中心点周围分布的弱初始化条件下产生最优错误标记保证，并且在存在敌对异常值的情况下仍然有效。

    

    在存在异质数据的统计机器学习中，聚类是一种基本工具。许多最近的结果主要关注在数据围绕带有次高斯误差的中心点分布时的最优错误标记保证。然而，限制性的次高斯模型在实践中常常无效，因为各种实际应用展示了围绕中心点的重尾分布或受到可能的敌对攻击，需要具有鲁棒数据驱动初始化的鲁棒聚类。在本文中，我们引入一种混合聚类技术，利用一种新颖的多变量修剪均值类型的中心点估计，在中心点周围的误差分布的弱初始化条件下产生错误标记保证。我们还给出了一个相匹配的下界，上界依赖于聚类的数量。此外，我们的方法即使在存在敌对异常值的情况下也能产生最优错误标记。我们的结果简化为亚高斯模型的情况。

    Clustering is a fundamental tool in statistical machine learning in the presence of heterogeneous data. Many recent results focus primarily on optimal mislabeling guarantees, when data are distributed around centroids with sub-Gaussian errors. Yet, the restrictive sub-Gaussian model is often invalid in practice, since various real-world applications exhibit heavy tail distributions around the centroids or suffer from possible adversarial attacks that call for robust clustering with a robust data-driven initialization. In this paper, we introduce a hybrid clustering technique with a novel multivariate trimmed mean type centroid estimate to produce mislabeling guarantees under a weak initialization condition for general error distributions around the centroids. A matching lower bound is derived, up to factors depending on the number of clusters. In addition, our approach also produces the optimal mislabeling even in the presence of adversarial outliers. Our results reduce to the sub-Gaus
    
[^7]: 通过森林修剪提高随机森林的准确性和可解释性

    Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])

    [http://arxiv.org/abs/2401.05535](http://arxiv.org/abs/2401.05535)

    通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。

    

    接近几十年的发展之后，随机森林仍然在各种学习问题中提供最先进的准确性，在这方面超越了决策树甚至神经网络等替代机器学习算法。然而，作为一种集成方法，随机森林在解释性方面往往比决策树表现不佳。在本研究中，我们提出了一种事后方法，旨在兼顾随机森林的准确性和决策树的可解释性。为此，我们提出了两种森林修剪方法，以在给定的随机森林内找到最佳子森林，然后在适用的情况下将选定的树合并为一棵。我们的第一种方法依赖于约束穷举搜索，而第二种方法基于LASSO方法的改进。在合成和真实世界数据集上进行的大量实验证明，在大多数情景下，这两种方法中至少有一种能够显著提高随机森林的准确性和可解释性。

    Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
    
[^8]: HoloBeam:学习远场全息元表面收发器中的最佳波束成型

    HoloBeam: Learning Optimal Beamforming in Far-Field Holographic Metasurface Transceivers. (arXiv:2401.05420v1 [eess.SP])

    [http://arxiv.org/abs/2401.05420](http://arxiv.org/abs/2401.05420)

    Holographic Metasurface Transceivers (HMTs) are being used as cost-effective substitutes for large antenna arrays for beamforming in Millimeter and TeraHertz wave communication. In this work, a learning algorithm is developed to optimize beamforming in far-field regions, by using a fixed-budget multi-armed bandit framework to maximize received signal strength. The algorithm exploits the parametric form of channel gains and works with the discrete values of phase-shifting parameters.

    

    全息元表面收发器（HMT）正以经济实惠的方式成为毫米和太赫兹波通信中波束成型的替代品。然而，在HMT中通过波束成型实现所需信道增益需要适当设置大量元素的相移，这是具有挑战性的。此外，这些最佳相移依赖于接收器位置，这可能是未知的。在本文中，我们使用{\it 固定预算多臂老虎机算法}开发了一个学习算法，以在远场区域进行波束成型并最大化接收信号强度。我们的算法名为 \Algo，利用了波束的通道增益参数形式，它可以用两个{\it 相移参数}表示。即使进行参数化，问题仍然具有挑战性，因为相移参数采用连续值。为了克服这个问题，\HB 使用相移参数的离散值并利用其子结构。

    Holographic Metasurface Transceivers (HMTs) are emerging as cost-effective substitutes to large antenna arrays for beamforming in Millimeter and TeraHertz wave communication. However, to achieve desired channel gains through beamforming in HMT, phase-shifts of a large number of elements need to be appropriately set, which is challenging. Also, these optimal phase-shifts depend on the location of the receivers, which could be unknown. In this work, we develop a learning algorithm using a {\it fixed-budget multi-armed bandit framework} to beamform and maximize received signal strength at the receiver for far-field regions. Our algorithm, named \Algo exploits the parametric form of channel gains of the beams, which can be expressed in terms of two {\it phase-shifting parameters}. Even after parameterization, the problem is still challenging as phase-shifting parameters take continuous values. To overcome this, {\it\HB} works with the discrete values of phase-shifting parameters and exploi
    
[^9]: 迭代正则化与k支撑范数：稀疏恢复的重要补充

    Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])

    [http://arxiv.org/abs/2401.05394](http://arxiv.org/abs/2401.05394)

    该论文介绍了一种新的迭代正则化算法IRKSN，它通过使用$k$支撑范数正则化实现稀疏恢复，并提供了条件。这是对基于$\ell_1$范数的迭代方法的一种重要补充。

    

    稀疏恢复在机器学习和信号处理中无处不在。由于稀疏恢复的NP困难性质，现有方法通常要么受限于适用条件（甚至未知），要么计算成本高。最近，迭代正则化方法作为一种快速方法出现，因为它们可以通过提前停止一次通过来实现稀疏恢复，而不是传统方法中繁琐的网格搜索。然而，大多数这些迭代方法都基于$\ell_1$范数，需要受限的适用条件，并且在许多情况下可能会失败。因此，迭代正则化方法在更广泛的条件下实现稀疏恢复仍需进一步探索。为了解决这个问题，我们提出了一种新的迭代正则化算法IRKSN，它基于$k$支撑范数正则化而不是$\ell_1$范数。我们提供了使用IRKSN进行稀疏恢复的条件，并进行了比较。

    Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar
    
[^10]: 使用去噪扩散生成模型的贝叶斯心电图重建

    Bayesian ECG reconstruction using denoising diffusion generative models. (arXiv:2401.05388v1 [eess.SP])

    [http://arxiv.org/abs/2401.05388](http://arxiv.org/abs/2401.05388)

    这项工作提出了一种使用健康心电图数据训练的去噪扩散生成模型，成功生成逼真的心电图信号，并且应用于心脏健康监测和诊断领域，实现了校正QT间期、噪声抑制、心电图导联恢复和异常读数识别等重要临床工具的开发。

    

    在这项工作中，我们提出了一种使用健康心电图数据训练的去噪扩散生成模型（DDGM），该模型关注心电图形态和导联间的相关性。我们的结果表明，这种创新的生成模型可以成功生成逼真的心电图信号。此外，我们还探索了使用DDGM解决线性反问题的最新突破在心电图重建中的应用，这为发展几种重要的临床工具提供了可能。这些工具包括校正QT间期(QTc)的计算、心电图信号的有效噪声抑制、丢失的心电图导联的恢复以及异常读数的识别，从而在心脏健康监测和诊断方面取得了重大进展。

    In this work, we propose a denoising diffusion generative model (DDGM) trained with healthy electrocardiogram (ECG) data that focuses on ECG morphology and inter-lead dependence. Our results show that this innovative generative model can successfully generate realistic ECG signals. Furthermore, we explore the application of recent breakthroughs in solving linear inverse Bayesian problems using DDGM. This approach enables the development of several important clinical tools. These include the calculation of corrected QT intervals (QTc), effective noise suppression of ECG signals, recovery of missing ECG leads, and identification of anomalous readings, enabling significant advances in cardiac health monitoring and diagnosis.
    
[^11]: 关于广义等增递归分割算法的正确性研究

    On the Correctness of the Generalized Isotonic Recursive Partitioning Algorithm. (arXiv:2401.04847v1 [stat.ML])

    [http://arxiv.org/abs/2401.04847](http://arxiv.org/abs/2401.04847)

    本文通过深入分析广义等增递归分割算法（GIRP），在可分离凸损失和不可微损失的情况下，解决了等增回归问题的存在性和唯一性，并提出了递归二分分割的方法来找到解。

    

    本文深入分析了广义等增递归分割算法（GIRP），该算法用于拟合可分离凸损失下的等增模型，该算法由Luss和Rosset提出 [J. Comput. Graph. Statist., 23 (2014), pp. 192--201] 并由Painsky和Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp. 308-321] 扩展适用于不可微损失。GIRP算法具有吸引人的特点，即在算法的每一步中，中间解满足等增约束。文章以一个例子开始，展示了文献中描述的GIRP算法可能无法产生等增模型的情况，表明必须仔细讨论等增回归问题的解的存在性和唯一性。文章接着展示，可能存在许多解之一，可以通过对观察数据集进行递归二分分割来找到解。一个小的修改

    This paper presents an in-depth analysis of the generalized isotonic recursive partitioning (GIRP) algorithm for fitting isotonic models under separable convex losses, proposed by Luss and Rosset [J. Comput. Graph. Statist., 23 (2014), pp. 192--201] for differentiable losses and extended by Painsky and Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp. 308-321] for nondifferentiable losses. The GIRP algorithm poseses an attractive feature that in each step of the algorithm, the intermediate solution satisfies the isotonicity constraint. The paper begins with an example showing that the GIRP algorithm as described in the literature may fail to produce an isotonic model, suggesting that the existence and uniqueness of the solution to the isotonic regression problem must be carefully addressed. It proceeds with showing that, among possibly many solutions, there indeed exists a solution that can be found by recursive binary partitioning of the set of observed data. A small mod
    
[^12]: 行动中的现实主义：使用YOLOv8和DeiT从医学图像中诊断脑肿瘤的异常感知

    Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT. (arXiv:2401.03302v1 [eess.IV])

    [http://arxiv.org/abs/2401.03302](http://arxiv.org/abs/2401.03302)

    本研究利用深度学习技术在具有挑战性的情况下检测和分类脑肿瘤，并解决了在罕见情况下的肿瘤检测问题。研究使用了来自国家脑映射实验室的数据集，通过修改样本数量和患者分布，使模型能够应对真实世界场景中的异常情况。

    

    在医学科学领域，由于脑肿瘤在患者中的罕见程度，可靠地检测和分类脑肿瘤仍然是一个艰巨的挑战。因此，在异常情况下检测肿瘤的能力对于确保及时干预和改善患者结果至关重要。本研究利用深度学习技术在具有挑战性的情况下检测和分类脑肿瘤。来自国家脑映射实验室（NBML）的精选数据集包括81名患者，其中包括30例肿瘤病例和51例正常病例。检测和分类流程被分为两个连续的任务。检测阶段包括全面的数据分析和预处理，以修改图像样本和每个类别的患者数量，以符合真实世界场景中的异常分布（9个正常样本对应1个肿瘤样本）。此外，在测试中除了常见的评估指标外，我们还采用了... [摘要长度已达到上限]

    In the field of medical sciences, reliable detection and classification of brain tumors from images remains a formidable challenge due to the rarity of tumors within the population of patients. Therefore, the ability to detect tumors in anomaly scenarios is paramount for ensuring timely interventions and improved patient outcomes. This study addresses the issue by leveraging deep learning (DL) techniques to detect and classify brain tumors in challenging situations. The curated data set from the National Brain Mapping Lab (NBML) comprises 81 patients, including 30 Tumor cases and 51 Normal cases. The detection and classification pipelines are separated into two consecutive tasks. The detection phase involved comprehensive data analysis and pre-processing to modify the number of image samples and the number of patients of each class to anomaly distribution (9 Normal per 1 Tumor) to comply with real world scenarios. Next, in addition to common evaluation metrics for the testing, we emplo
    
[^13]: TaCo：通过信息论和可解释性在NLP中的输出嵌入中实现有针对性的概念去除

    TaCo: Targeted Concept Removal in Output Embeddings for NLP via Information Theory and Explainability. (arXiv:2312.06499v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.06499](http://arxiv.org/abs/2312.06499)

    本论文提出了一种新颖的方法，通过对NLP模型的嵌入层级进行操作，借鉴了最新的解释性人工智能技术，通过嵌入转换来消除隐含的敏感信息，从而实现模型的公平性。

    

    自然语言处理（NLP）模型的公平性已成为一个关键问题。信息论表明，为了实现公平性，模型不应能够预测敏感变量，如性别、种族和年龄。然而，与这些变量相关的信息通常以隐式的方式出现在语言中，这给识别和减少偏见带来了挑战。为了解决这个问题，我们提出了一种新颖的方法，在NLP模型的嵌入层级上操作，独立于具体的架构。我们的方法借鉴了最近解释性人工智能技术的进展，并采用嵌入转换来消除选定变量中的隐式信息。通过直接操纵最后一层的嵌入，我们的方法能够无缝集成到现有模型中，而无需进行重大修改或重训练。在评估中，我们展示了该后处理方法显著降低了与性别相关的关联性。

    The fairness of Natural Language Processing (NLP) models has emerged as a crucial concern. Information theory indicates that to achieve fairness, a model should not be able to predict sensitive variables, such as gender, ethnicity, and age. However, information related to these variables often appears implicitly in language, posing a challenge in identifying and mitigating biases effectively. To tackle this issue, we present a novel approach that operates at the embedding level of an NLP model, independent of the specific architecture. Our method leverages insights from recent advances in XAI techniques and employs an embedding transformation to eliminate implicit information from a selected variable. By directly manipulating the embeddings in the final layer, our approach enables a seamless integration into existing models without requiring significant modifications or retraining. In evaluation, we show that the proposed post-hoc approach significantly reduces gender-related associati
    
[^14]: Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures（现代神经网络架构的克罗内克近似曲率）

    Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures. (arXiv:2311.00636v1 [cs.LG])

    [http://arxiv.org/abs/2311.00636](http://arxiv.org/abs/2311.00636)

    本篇论文提出了一种用于现代神经网络架构的克罗内克近似曲率算法，可以加速神经网络训练和减少计算成本。作者发现了两种具有线性权重共享层不同设置，并证明了相应设置下的K-FAC算法的精确性。K-FAC-reduce通常比K-FAC-expand更快，可以用于加速自动超参数选择。

    

    许多现代神经网络架构的核心组件，如transformers、卷积或图神经网络，可以表达为具有“权重共享”的线性层。克罗内克近似曲率（K-FAC）是一种二阶优化方法，已显示出加速神经网络训练并减少计算成本的潜力。然而，目前还没有将其应用于通用的架构的框架，特别是具有线性权重共享层的架构。在这项工作中，我们确定了具有线性权重共享层的两种不同设置，这促使了两种K-FAC的变体——“扩展”和“减少”。我们展示了对于具有相应设置的深度线性网络，它们是精确的。值得注意的是，K-FAC-reduce通常比K-FAC-expand更快，我们利用它来加速通过优化Wide ResNet的边际似然来选择自动超参数。最后，我们观察到在

    The core components of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimisation method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavours of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimising the marginal likelihood for a Wide ResNet. Finally, we observe little difference between 
    
[^15]: 缺失值处理的三值决策树

    Trinary Decision Trees for missing value handling. (arXiv:2309.03561v1 [stat.ML])

    [http://arxiv.org/abs/2309.03561](http://arxiv.org/abs/2309.03561)

    本文介绍了一种称为三值决策树的算法，用于改善决策树在处理缺失数据时的表现。与其他方法不同，该算法不假设缺失值包含任何关于响应的信息。实验证明，在特定缺失数据场景下，三值决策树在MCAR设置中表现优异，在IM设置中略逊一筹。同时，通过将三值决策树与缺失在属性方法相结合，可以获得更稳健的性能。尽管训练速度较慢，但三值决策树提供了一种有前途且更准确的方法。

    

    本文介绍了三值决策树，这是一种旨在改善决策树回归器和分类器中处理缺失数据的算法。与其他方法不同，三值决策树不假设缺失值包含有关响应的任何信息。本文通过理论计算和使用真实数据集的数值示例，比较了其在不同缺失数据场景（完全随机缺失（MCAR）和信息性缺失（IM））中与已建立算法的性能。值得注意的是，在MCAR设置中，三值树在只有样本外缺失数据时表现优于其同行，而在IM设置中落后。一个混合模型，即三值缺失在属性（MIA）方法和三值树相结合的TrinaryMIA树，在所有缺失类型中表现出强大的性能。尽管训练速度较慢可能是一个潜在的缺点，但三值决策树提供了一个有前途且更准确的方法。

    This paper introduces the Trinary decision tree, an algorithm designed to improve the handling of missing data in decision tree regressors and classifiers. Unlike other approaches, the Trinary decision tree does not assume that missing values contain any information about the response. Both theoretical calculations on estimator bias and numerical illustrations using real data sets are presented to compare its performance with established algorithms in different missing data scenarios (Missing Completely at Random (MCAR), and Informative Missingness (IM)). Notably, the Trinary tree outperforms its peers in MCAR settings, especially when data is only missing out-of-sample, while lacking behind in IM settings. A hybrid model, the TrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes (MIA) approach, shows robust performance in all types of missingness. Despite the potential drawback of slower training speed, the Trinary tree offers a promising and more accurate met
    
[^16]: 深度图形回归用于联合调节和极端澳大利亚野火

    Deep graphical regression for jointly moderate and extreme Australian wildfires. (arXiv:2308.14547v1 [stat.AP])

    [http://arxiv.org/abs/2308.14547](http://arxiv.org/abs/2308.14547)

    该论文介绍了一种利用深度图形回归方法来联合调节和预测澳大利亚野火的新方法。研究结果表明，对于火灾的全分布建模是非常关键的，因为极端野火可能导致巨大的影响，而小规模和中等规模火灾仍然会对当地社区和生态系统造成重大破坏。

    

    澳大利亚最近的野火造成了巨大的经济损失和财产破坏，人们越来越担心气候变化可能加剧其强度、持续时间和频率。对于极端野火的灾害评估是野火管理的重要组成部分，它有助于资源分配的高效性、负面影响的减轻和恢复工作的开展。然而，虽然极端野火通常具有最大的影响力，但小规模和中等规模的火灾仍然可以对当地社区和生态系统造成毁灭性的影响。因此，我们迫切需要开发稳健的统计方法来可靠地建模野火的全分布。我们对1999年至2019年的澳大利亚野火进行了新的数据集分析，并分析了大约相当于统计区域层次1和层次2（SA1/SA2）区域的火灾月度蔓延。鉴于野火点燃和蔓延的复杂性，我们利用了统计深度学习和外部信息的最新进展。

    Recent wildfires in Australia have led to considerable economic loss and property destruction, and there is increasing concern that climate change may exacerbate their intensity, duration, and frequency. hazard quantification for extreme wildfires is an important component of wildfire management, as it facilitates efficient resource distribution, adverse effect mitigation, and recovery efforts. However, although extreme wildfires are typically the most impactful, both small and moderate fires can still be devastating to local communities and ecosystems. Therefore, it is imperative to develop robust statistical methods to reliably model the full distribution of wildfire spread. We do so for a novel dataset of Australian wildfires from 1999 to 2019, and analyse monthly spread over areas approximately corresponding to Statistical Areas Level 1 and 2 (SA1/SA2) regions. Given the complex nature of wildfire ignition and spread, we exploit recent advances in statistical deep learning and extr
    
[^17]: Gibbs采样神经网络的后验分布

    Gibbs Sampling the Posterior of Neural Networks. (arXiv:2306.02729v1 [cs.LG])

    [http://arxiv.org/abs/2306.02729](http://arxiv.org/abs/2306.02729)

    这篇论文提出了一种添加噪声的神经网络模型，并使用Gibbs采样器从后验分布中进行采样，该方法在真实数据和合成数据中能够达到类似于马尔科夫链蒙特卡洛方法的性能。

    

    本文研究了从神经网络的后验分布中进行采样。我们提出了一种新的概率模型，该模型在网络的每个预激活和后激活中添加噪声，并认为使用有效的Gibbs采样器可以采样得到所得到的后验分布。在真实数据和合成数据上，Gibbs采样器能够达到类似于状态-of-the-art的马尔科夫链蒙特卡洛方法（如哈密顿蒙特卡洛或Metropolis调整Langevin算法）的性能。通过在师生设置中进行分析，我们引入了一个热化准则，该准则允许我们检测算法在使用合成标签的数据上运行时是否无法从后验分布中采样。该准则基于师生设置中的事实，我们可以直接在平衡点处初始化算法。

    In this paper, we study sampling from a posterior derived from a neural network. We propose a new probabilistic model consisting of adding noise at every pre- and post-activation in the network, arguing that the resulting posterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler attains similar performances as the state-of-the-art Monte Carlo Markov chain methods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted Langevin algorithm, both on real and synthetic data. By framing our analysis in the teacher-student setting, we introduce a thermalization criterion that allows us to detect when an algorithm, when run on data with synthetic labels, fails to sample from the posterior. The criterion is based on the fact that in the teacher-student setting we can initialize an algorithm directly at equilibrium.
    
[^18]: 抗干扰约束学习

    Resilient Constrained Learning. (arXiv:2306.02426v1 [cs.LG])

    [http://arxiv.org/abs/2306.02426](http://arxiv.org/abs/2306.02426)

    本论文提出了一个名为“抗干扰约束学习”的方法来解决在部署机器学习解决方案时需要满足除了准确性以外的多个要求，并以平衡从放宽中获得的性能增益与用户定义的放宽成本之间的关系的方式放松学习约束。

    

    在部署机器学习解决方案时，除了准确性之外，它们必须满足多个要求，如公平性、鲁棒性或安全性。这些要求可以通过使用惩罚来隐式地施加，或者通过基于Lagrangian对偶的约束优化方法来显式地施加。无论哪种方式，指定要求都受到妥协和有限的有关数据的先前知识的影响。此外，它们对性能的影响通常只能通过实际解决学习问题来评估。本文提出了一种约束学习方法，该方法在同时解决学习任务的同时调整要求。为此，它以平衡从放宽中获得的性能增益与用户定义的放宽成本之间的关系的方式放松了学习约束。我们将此方法称为具有弹性的约束学习，这是对用于描述生态系统的术语的一种借鉴。

    When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems tha
    
[^19]: 带曲率敏感模型的连续性结果的部分反事实识别

    Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model. (arXiv:2306.01424v1 [stat.ML])

    [http://arxiv.org/abs/2306.01424](http://arxiv.org/abs/2306.01424)

    本文研究了连续性结果的部分反事实识别问题，并提出了一种新颖的敏感性模型——曲率敏感模型，通过限制函数级集的曲率来获得信息边界。

    

    反事实推断旨在回答“如果”问题，因此属于Pearl因果关系阶梯中最精细的推理类型。现有的针对具有连续结果的反事实推断方法旨在进行点识别，因此对基础结构因果模型进行了强有力且不自然的假设。在本文中，我们放宽了这些假设，旨在进行连续结果的部分反事实识别，即当反事实查询存在具有信息边界的无知区间中时。我们证明了，在一般情况下，即使是连续可微的结构因果模型函数的级集的曲率也是非信息的，反事实查询的无知区间也是非信息的。因此，我们提出了一种新颖的敏感性模型称为曲率敏感模型来解决这个问题。它允许我们通过限制函数级集的曲率来获得信息边界。我们进一步展示了现有的点反事实识别方法可以视为我们提出框架的特定情况。

    Counterfactual inference aims to answer retrospective ''what if'' questions and thus belongs to the most fine-grained type of inference in Pearl's causality ladder. Existing methods for counterfactual inference with continuous outcomes aim at point identification and thus make strong and unnatural assumptions about the underlying structural causal model. In this paper, we relax these assumptions and aim at partial counterfactual identification of continuous outcomes, i.e., when the counterfactual query resides in an ignorance interval with informative bounds. We prove that, in general, the ignorance interval of the counterfactual queries has non-informative bounds, already when functions of structural causal models are continuously differentiable. As a remedy, we propose a novel sensitivity model called Curvature Sensitivity Model. This allows us to obtain informative bounds by bounding the curvature of level sets of the functions. We further show that existing point counterfactual ide
    
[^20]: 黑盒变分推断收敛性分析

    Black-Box Variational Inference Converges. (arXiv:2305.15349v1 [cs.LG])

    [http://arxiv.org/abs/2305.15349](http://arxiv.org/abs/2305.15349)

    通过对黑盒变分推断（BBVI）的分析，发现一些常见的算法设计选择可能会导致次优收敛速率，但使用带有近端随机梯度下降的BBVI可以实现最强收敛率保证。

    

    我们提供了第一个完整的黑盒变分推断（BBVI）的收敛保证，也称为蒙特卡罗变分推断。尽管早期的研究只针对简化版本的BBVI进行了研究（例如，有界域、有界支持、仅针对尺度进行优化等），但我们的设置不需要任何这样的算法修改。我们的结果适用于对数平滑后验密度，无论是否强对数凹性以及位置-尺度变分族。此外，我们的分析揭示出了一些常见的算法设计选择，特别是变分近似尺度的非线性参数化，可能会导致次优收敛速率。幸运的是，运行带有近端随机梯度下降的BBVI可以纠正这些限制，从而实现已知的最强收敛率保证。我们通过将近端SGD与其他标准的BBVI实现进行比较，验证了这一理论结论在大规模数据集上的有效性。

    We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale
    
[^21]: 一个基于功能修剪的非参数在线变点检测算法的对数线性实现

    A Log-Linear Non-Parametric Online Changepoint Detection Algorithm based on Functional Pruning. (arXiv:2302.02718v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2302.02718](http://arxiv.org/abs/2302.02718)

    提出了一个基于功能修剪的非参数在线变点检测算法，能够快速高效地检测高频数据流中的异常和变化，并且不依赖于违反实际应用中的参数假设。

    

    在线变点检测旨在实时检测高频数据流中的异常和变化，有时候带有有限的计算资源。这是一个重要的任务，根源于许多现实应用，包括但不限于网络安全、医学和天体物理学。虽然最近引入了快速高效的在线算法，但这些算法都依赖于常被在实际应用中违反的参数假设。受电信领域数据流的启发，我们构建了一种灵活的非参数方法来检测序列分布中的变化。我们的方法，NP-FOCuS，在数据的经验累积密度函数的一组点上构建了一个序列似然比检验，用于检测变化。通过跟踪超出或低于这些点的观测次数，实现了这一目标。由于功能修剪的思想，NP-FOCuS的计算成本与观测次数的对数成线性关系。

    Online changepoint detection aims to detect anomalies and changes in real-time in high-frequency data streams, sometimes with limited available computational resources. This is an important task that is rooted in many real-world applications, including and not limited to cybersecurity, medicine and astrophysics. While fast and efficient online algorithms have been recently introduced, these rely on parametric assumptions which are often violated in practical applications. Motivated by data streams from the telecommunications sector, we build a flexible nonparametric approach to detect a change in the distribution of a sequence. Our procedure, NP-FOCuS, builds a sequential likelihood ratio test for a change in a set of points of the empirical cumulative density function of our data. This is achieved by keeping track of the number of observations above or below those points. Thanks to functional pruning ideas, NP-FOCuS has a computational cost that is log-linear in the number of observat
    
[^22]: ARMA单元：神经自回归建模的模块化和有效方法

    ARMA Cell: A Modular and Effective Approach for Neural Autoregressive Modeling. (arXiv:2208.14919v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.14919](http://arxiv.org/abs/2208.14919)

    本文介绍了ARMA单元，一种更简单、模块化和有效的神经网络时间序列建模方法，能够自然地处理多变量时间序列，并引入了ConvARMA单元作为一种解决方法。

    

    自回归移动平均(ARMA)模型是一种经典的、被广泛研究的时间序列数据建模方法。它具有引人入胜的理论性质，在实践中被广泛应用。最近的深度学习方法普及了循环神经网络(RNN)，特别是长短期记忆(LSTM)单元，在神经时间序列建模中成为表现最好和最常见的构建模块之一。虽然复杂的RNN单元对于具有长期影响的时间序列数据或序列有优势，但并不总是必需的，有时甚至不如更简单的循环方法好。在本文中，我们引入了ARMA单元，这是一种更简单、模块化和有效的神经网络时间序列建模方法。这个单元可以在任何存在循环结构的神经网络架构中使用，并且可以自然地处理多变量时间序列，使用向量自回归技术。我们还介绍了ConvARMA单元作为一种自然的解决方法。

    The autoregressive moving average (ARMA) model is a classical, and arguably one of the most studied approaches to model time series data. It has compelling theoretical properties and is widely used among practitioners. More recent deep learning approaches popularize recurrent neural networks (RNNs) and, in particular, Long Short-Term Memory (LSTM) cells that have become one of the best performing and most common building blocks in neural time series modeling. While advantageous for time series data or sequences with long-term effects, complex RNN cells are not always a must and can sometimes even be inferior to simpler recurrent approaches. In this work, we introduce the ARMA cell, a simpler, modular, and effective approach for time series modeling in neural networks. This cell can be used in any neural network architecture where recurrent structures are present and naturally handles multivariate time series using vector autoregression. We also introduce the ConvARMA cell as a natural 
    
[^23]: CP-PINNs: 使用物理知识神经网络和总变差惩罚进行PDE中的变点检测

    CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty. (arXiv:2208.08626v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.08626](http://arxiv.org/abs/2208.08626)

    本文提出了一种新的CP-PINNs模型，通过将PINNs与总变差惩罚相结合，实现了准确的变点检测和PDE的发现。我们还开发了一种元学习算法，能够在数据的连续批次上动态改进优化目标。实证结果表明，在存在变点的情况下，该方法能够准确估计参数和模型对齐，在没有变点的情况下能够数值上收敛到原始PINNs模型的解。

    

    本文展示了在参数中存在未知变点的情况下，物理知识神经网络（PINNs）可能无法正确估计偏微分方程（PDE）的动态过程。为了解决这个问题，我们提出了一个新的CP-PINNs模型，将PINNs与总变差惩罚相结合，用于准确的变点检测和PDE的发现。为了在模型拟合、PDE发现和变点检测任务之间进行最优组合，我们开发了一种新的元学习算法，利用批量学习在数据的连续批次上动态改进优化目标。在实证方面，在动态过程中存在变点的情况下，我们的方法能够准确估计参数和模型对齐，在数据中没有变点的情况下，数值上收敛到原始PINNs模型的解。

    The paper shows that Physics-Informed Neural Networks (PINNs) can fail to estimate the correct Partial Differential Equations (PDEs) dynamics in cases of unknown changepoints in the parameters. To address this, we propose a new CP-PINNs model which integrates PINNs with Total-Variation penalty for accurate changepoints detection and PDEs discovery. In order to optimally combine the tasks of model fitting, PDEs discovery, and changepoints detection, we develop a new meta-learning algorithm that exploits batch learning to dynamically refines the optimization objective when moving over the consecutive batches of the data. Empirically, in case of changepoints in the dynamics, our approach demonstrates accurate parameter estimation and model alignment, and in case of no changepoints in the data, it converges numerically to the solution from the original PINNs model.
    
[^24]: 一种用于静态无路径估计到达时间的可解释叠加集成模型

    An Explainable Stacked Ensemble Model for Static Route-Free Estimation of Time of Arrival. (arXiv:2203.09438v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.09438](http://arxiv.org/abs/2203.09438)

    本文提出了一种可解释的叠加集成模型，用于静态无路径估计到达时间。该模型将多个机器学习模型组合成一个新的集成结构，能够超越先前的最先进模型。

    

    为了比较备选的出租车行程并计算它们，以及为驾驶员和乘客提供关于即将到来的出租车行程的见解，需要预测行程的持续时间或其预计到达时间（ETA）。为了达到较高的预测精度，ETA的机器学习模型是目前的技术水平。进一步提高预测精度的一个尚未开发的选项是将多个ETA模型组合成一个集成模型。尽管预测精度可能会增加，但这种集成模型的预测结果由于复杂的集成结构而变得不够透明。解决这个问题的一种方法是应用可解释人工智能（XAI）。本文的贡献有三个方面。首先，我们将我们先前工作中的多个机器学习模型组合成一个两层的集成模型- 一个叠加集成模型- 这本身就是一种创新；因此，我们可以超越先前的静态路径无关最先进的模型。

    To compare alternative taxi schedules and to compute them, as well as to provide insights into an upcoming taxi trip to drivers and passengers, the duration of a trip or its Estimated Time of Arrival (ETA) is predicted. To reach a high prediction precision, machine learning models for ETA are state of the art. One yet unexploited option to further increase prediction precision is to combine multiple ETA models into an ensemble. While an increase of prediction precision is likely, the main drawback is that the predictions made by such an ensemble become less transparent due to the sophisticated ensemble architecture. One option to remedy this drawback is to apply eXplainable Artificial Intelligence (XAI). The contribution of this paper is three-fold. First, we combine multiple machine learning models from our previous work for ETA into a two-level ensemble model - a stacked ensemble model - which on its own is novel; therefore, we can outperform previous state-of-the-art static route-fr
    
[^25]: GPEX，用于解释人工神经网络的框架

    GPEX, A Framework For Interpreting Artificial Neural Networks. (arXiv:2112.09820v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.09820](http://arxiv.org/abs/2112.09820)

    这篇论文提出了一种GPEX框架，用于解释深度人工神经网络，通过推导出一个证据下界来匹配神经网络的输出，而不对神经网络做出任何特定要求。实验证明，在一些理论假设下，只需要简单的网络结构即可达到良好性能。

    

    高斯过程（GPs）与深度人工神经网络（ANNs）之间的类比引起了广泛关注，并显示出揭示深度ANN的黑箱的潜力。现有的理论工作对ANN提出了严格的假设（例如，要求所有中间层为宽层，或使用特定的激活函数）。适应这些理论假设在最近的深层架构中很困难，并且随着新的深层架构的出现，这些理论条件需要进一步完善。在本文中，我们推导出一个证据下界，鼓励GP的后验与ANN的输出匹配，而不对ANN做任何要求。使用我们的方法，我们发现在5个数据集上，只有一部分理论假设就足够了。实际上，在我们的实验中，我们使用了一个普通的ResNet-18或前馈骨干网络，并在末端使用了一个宽层。训练GPs的一个局限性是在于与诱导点数量的可扩展性的缺乏。

    The analogy between Gaussian processes (GPs) and deep artificial neural networks (ANNs) has received a lot of interest, and has shown promise to unbox the blackbox of deep ANNs. Existing theoretical works put strict assumptions on the ANN (e.g. requiring all intermediate layers to be wide, or using specific activation functions). Accommodating those theoretical assumptions is hard in recent deep architectures, and those theoretical conditions need refinement as new deep architectures emerge. In this paper we derive an evidence lower-bound that encourages the GP's posterior to match the ANN's output without any requirement on the ANN. Using our method we find out that on 5 datasets, only a subset of those theoretical assumptions are sufficient. Indeed, in our experiments we used a normal ResNet-18 or feed-forward backbone with a single wide layer in the end. One limitation of training GPs is the lack of scalability with respect to the number of inducing points. We use novel computationa
    
[^26]: 自适应变分贝叶斯：优化性质，计算和应用

    Adaptive variational Bayes: Optimality, computation and applications. (arXiv:2109.03204v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2109.03204](http://arxiv.org/abs/2109.03204)

    本文提出了一种新颖的自适应变分贝叶斯框架，可以在多个模型上运行。该方法能够自适应地实现最优的收缩速率，并提供了一种技术方法来保持可计算性和自适应最优性。

    

    本文探讨了基于变分贝叶斯的自适应推断。虽然已经进行了一些研究来分析变分后验的收敛性质，但仍然缺乏一种通用且具有计算可行性的自适应变分贝叶斯方法。为填补这一空白，我们提出了一种新颖的自适应变分贝叶斯框架，可以在多个模型上运行。该框架首先分别计算每个单独模型的变分后验，然后将它们与一定的权重结合起来，产生整个模型的变分后验。结果表明，这个组合的变分后验是在预定义的一族近似分布中最接近整个模型的后验的成员。我们证明了在非常普遍的条件下，自适应变分贝叶斯可以自适应地实现最优的收缩速率。我们还提供了一种技术方法来保持可计算性和自适应最优性。

    In this paper, we explore adaptive inference based on variational Bayes. Although several studies have been conducted to analyze the contraction properties of variational posteriors, there is still a lack of a general and computationally tractable variational Bayes method that performs adaptive inference. To fill this gap, we propose a novel adaptive variational Bayes framework, which can operate on a collection of models. The proposed framework first computes a variational posterior over each individual model separately and then combines them with certain weights to produce a variational posterior over the entire model. It turns out that this combined variational posterior is the closest member to the posterior over the entire model in a predefined family of approximating distributions. We show that the adaptive variational Bayes attains optimal contraction rates adaptively under very general conditions. We also provide a methodology to maintain the tractability and adaptive optimalit
    

