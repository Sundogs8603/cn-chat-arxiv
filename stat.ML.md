# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Mapping-to-Parameter Nonlinear Functional Regression with Novel B-spline Free Knot Placement Algorithm.](http://arxiv.org/abs/2401.14989) | 提出了一种新的非线性函数回归方法，通过将函数数据映射到有限维参数空间，并使用新的自由节点放置算法来同时近似多个函数。该算法根据输入或输出函数的局部复杂性来决定节点位置，性能稳健。 |
| [^2] | [Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models.](http://arxiv.org/abs/2401.14973) | 通过分层的循环切换状态模型，我们可以无监督地同时解释系统级和个体级的动态，从而更好地建模同步时间序列中的群体动态。 |
| [^3] | [A structured regression approach for evaluating model performance across intersectional subgroups.](http://arxiv.org/abs/2401.14893) | 这项工作介绍了一种结构回归方法，用于评估模型在不同交叉子群体间的性能。它可以提供可靠的系统性能估计，即使对于很小的子群体。 |
| [^4] | [P3LS: Partial Least Squares under Privacy Preservation.](http://arxiv.org/abs/2401.14884) | P3LS是一种隐私保护的偏最小二乘回归技术，通过使用可移动的随机掩码保护每个数据持有者的隐私，实现了跨组织数据集成和过程建模。 |
| [^5] | [Particle-MALA and Particle-mGRAD: Gradient-based MCMC methods for high-dimensional state-space models.](http://arxiv.org/abs/2401.14868) | 粒子-MALA和粒子-mGRAD是基于梯度的MCMC方法，综合了条件顺序Monte Carlo (CSMC)算法的时间可扩展性和MALA或mGRAD的维度可扩展性。 |
| [^6] | [A Nonparametric Bayes Approach to Online Activity Prediction.](http://arxiv.org/abs/2401.14722) | 本研究提出了一种非参数贝叶斯方法，以准确预测在线活动的用户数量和达到所需用户参与门槛所需的时间轨迹。该方法通过捕捉用户参与的潜在异质性，提供了实验者在在线实验中重要的决策支持。 |
| [^7] | [Validating Climate Models with Spherical Convolutional Wasserstein Distance.](http://arxiv.org/abs/2401.14657) | 引入了球面卷积Wasserstein距离来验证气候模型，相比传统方法更全面地衡量气候模型和再分析数据之间的差异，并应用于评估CMIP成员的模型输出。此外，研究发现CMIP第6阶段模型相较于第5阶段有适度改进。 |
| [^8] | [Robust Estimation of Pareto's Scale Parameter from Grouped Data.](http://arxiv.org/abs/2401.14593) | 本文介绍了一种新的稳健估计方法（MTuM），用于从分组数据中估计Pareto分布的尾指数。该方法通过应用中心极限定理和模拟研究验证了其推理合理性。 |
| [^9] | [Ricci flow-guided autoencoders in learning time-dependent dynamics.](http://arxiv.org/abs/2401.14591) | 利用Ricci流引导的自编码器方法能够学习非线性动力学，尤其是偏微分方程。该方法通过在训练中学习流形，并使用Ricci流使流形潜空间逐步适应动力学的变化，从而获得更好的表示能力。在实验中，我们展示了该方法在具有周期性和随机性的PDE上的应用，并评估了在分布内和外推场景中的误差。 |
| [^10] | [Understanding Disparities in Post Hoc Machine Learning Explanation.](http://arxiv.org/abs/2401.14539) | 该研究通过模拟和实验评估了事后机器学习解释中的差异，并发现协变量偏移、概念转变和省略协变量会增加解释差异，对神经网络影响更大。 |
| [^11] | [Predictive Analysis for Optimizing Port Operations.](http://arxiv.org/abs/2401.14498) | 本研究开发了一种具有竞争预测和分类能力的港口运营解决方案，用于准确估计船舶在港口的总时间和延迟时间，填补了港口分析模型在这方面的空白，并为海事物流领域提供了有价值的贡献。 |
| [^12] | [Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret.](http://arxiv.org/abs/2401.14483) | 本文展示了校准和遗憾在评估预测中的概念等价性，将评估问题构建为一个预测者、一个赌徒和自然之间的博弈，并将预测的评估与结果的随机性联系起来。 |
| [^13] | [Improving Antibody Humanness Prediction using Patent Data.](http://arxiv.org/abs/2401.14442) | 本研究利用专利数据提高了抗体人性预测的能力，通过多阶段、多损失的训练过程以及弱监督对比学习的方法，成功地预测了抗体序列的人性评分。 |
| [^14] | [[Re] The Discriminative Kalman Filter for Bayesian Filtering with Nonlinear and Non-Gaussian Observation Models.](http://arxiv.org/abs/2401.14429) | 该论文提供了一种针对非线性和非高斯观测模型的贝叶斯滤波的判别式卡尔曼滤波器，并在神经科学背景下证明了其有效性。 |
| [^15] | [Multi-Agent Based Transfer Learning for Data-Driven Air Traffic Applications.](http://arxiv.org/abs/2401.14421) | 本文提出了一种基于多智能体的迁移学习方法，利用MA-BERT模型和预训练微调框架来解决空中交通管理中的长训练时间和大数据集需求的问题。该方法可以在具有少量数据或无历史数据的情况下实现高性能。 |
| [^16] | [Non-Exchangeable Conformal Risk Control.](http://arxiv.org/abs/2310.01262) | 本文提出了一种非交换式共形风险控制的框架，可以在数据不可交换的情况下控制任何单调损失函数的期望值。 |
| [^17] | [Causal Entropy and Information Gain for Measuring Causal Control.](http://arxiv.org/abs/2309.07703) | 本文提出了一种考虑因果结构的信息论量，用于评估某个特定结果变量的因果重要性，解决了因果可解释性的挑战。 |
| [^18] | [A multiobjective continuation method to compute the regularization path of deep neural networks.](http://arxiv.org/abs/2308.12044) | 本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。 |
| [^19] | [Optimal Low-Rank Matrix Completion: Semidefinite Relaxations and Eigenvector Disjunctions.](http://arxiv.org/abs/2305.12292) | 该论文通过重新表述低秩矩阵填补问题为投影矩阵的非凸问题，实现了能够确定最优解的分离分支定界方案，并且通过新颖和紧密的凸松弛方法，使得最优性差距相对于现有方法减少了两个数量级。 |
| [^20] | [A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions.](http://arxiv.org/abs/2304.06787) | 本论文提出了第一个多项式时间、纯差分隐私估计器，可以在$\{0,1\}^d$上准确估计二元积分布的均值，达到了最优的样本复杂度。 |
| [^21] | [Finite-time analysis of single-timescale actor-critic.](http://arxiv.org/abs/2210.09921) | 这项研究提出了一种在线单时间尺度演员-评论家方法，通过线性函数逼近和马尔可夫样本更新，在连续状态空间中找到了一个$\epsilon$-近似的稳定点，并且在样本复杂度为$\widetilde{\mathcal{O}}(\epsilon^{-2})$的情况下证明了其收敛性。 |
| [^22] | [Signature Methods in Machine Learning.](http://arxiv.org/abs/2206.14674) | 本综述介绍了机器学习中应用的签名方法，通过数学洞察力理解复杂的流式数据之间的交互，并提供了用于分析非规则、非平稳的流式数据的数值方法。 |
| [^23] | [Convergence Error Analysis of Reflected Gradient Langevin Dynamics for Globally Optimizing Non-Convex Constrained Problems.](http://arxiv.org/abs/2203.10215) | 本文将梯度 Langevin 动力学和反射梯度 Langevin 动力学扩展到非凸问题上，并通过使用边界反射和概率表示法，在非凸约束问题中提出了更快的收敛速度。 |
| [^24] | [Sparse random hypergraphs: Non-backtracking spectra and community detection.](http://arxiv.org/abs/2203.07346) | 该论文研究了稀疏随机超图中的社区检测问题，证明了基于非回退算子的谱方法能够高概率下达到猜测阈值，并提供了一个高效的维度约减过程。这是第一个能够证明并高效实现HSBM猜测阈值的谱算法。 |
| [^25] | [High-dimensional Functional Graphical Model Structure Learning via Neighborhood Selection Approach.](http://arxiv.org/abs/2105.02487) | 该论文提出了一种基于邻域选择方法的高维函数图模型结构学习方法，通过函数对函数回归估计节点邻域，然后结合这些估计的邻域恢复整个图结构，从而直接估计条件独立结构。 |

# 详细

[^1]: 使用新型B样条自由节点放置算法的映射到参数非线性函数回归

    Mapping-to-Parameter Nonlinear Functional Regression with Novel B-spline Free Knot Placement Algorithm. (arXiv:2401.14989v1 [cs.LG])

    [http://arxiv.org/abs/2401.14989](http://arxiv.org/abs/2401.14989)

    提出了一种新的非线性函数回归方法，通过将函数数据映射到有限维参数空间，并使用新的自由节点放置算法来同时近似多个函数。该算法根据输入或输出函数的局部复杂性来决定节点位置，性能稳健。

    

    我们提出了一种新颖的非线性函数回归方法，称为映射到参数函数模型，通过采用任何监督学习技术处理参数空间中的复杂和非线性函数回归问题。该模型的核心是将函数数据从无限维函数空间映射到有限维参数空间。这是通过使用一组公用的B样条基函数同时近似多个函数来实现的，其节点分布由迭代局部放置算法确定，这是一种新提出的自由节点放置算法。与传统的等距节点放置策略相比，后者根据输入或输出函数的局部复杂性来确定节点位置，而不是基于预定义的节点数均匀分布节点位置。我们的节点放置算法的性能在两个方面都表现出了稳健性。

    We propose a novel approach to nonlinear functional regression, called the Mapping-to-Parameter function model, which addresses complex and nonlinear functional regression problems in parameter space by employing any supervised learning technique. Central to this model is the mapping of function data from an infinite-dimensional function space to a finite-dimensional parameter space. This is accomplished by concurrently approximating multiple functions with a common set of B-spline basis functions by any chosen order, with their knot distribution determined by the Iterative Local Placement Algorithm, a newly proposed free knot placement algorithm. In contrast to the conventional equidistant knot placement strategy that uniformly distributes knot locations based on a predefined number of knots, our proposed algorithms determine knot location according to the local complexity of the input or output functions. The performance of our knot placement algorithms is shown to be robust in both 
    
[^2]: 通过分层循环切换状态模型发现同步时间序列中的群体动态

    Discovering group dynamics in synchronous time series via hierarchical recurrent switching-state models. (arXiv:2401.14973v1 [stat.ML])

    [http://arxiv.org/abs/2401.14973](http://arxiv.org/abs/2401.14973)

    通过分层的循环切换状态模型，我们可以无监督地同时解释系统级和个体级的动态，从而更好地建模同步时间序列中的群体动态。

    

    我们致力于对同一时间段内多个实体相互作用而产生的时间序列集合进行建模。最近的研究集中在建模个体时间序列方面对我们的预期应用是不足够的，其中集体系统级行为影响着个体实体的轨迹。为了解决这类问题，我们提出了一种新的分层切换状态模型，可以以无监督的方式训练，同时解释系统级和个体级的动态。我们采用了一个隐含的系统级离散状态马尔可夫链，驱动着隐含的实体级链，进而控制每个观测时间序列的动态。观测结果在实体和系统级的链之间进行反馈，通过依赖于上下文的状态转换来提高灵活性。我们的分层切换循环动力学模型可以通过封闭形式的变分坐标上升更新来学习，其在个体数量上呈线性扩展。

    We seek to model a collection of time series arising from multiple entities interacting over the same time period. Recent work focused on modeling individual time series is inadequate for our intended applications, where collective system-level behavior influences the trajectories of individual entities. To address such problems, we present a new hierarchical switching-state model that can be trained in an unsupervised fashion to simultaneously explain both system-level and individual-level dynamics. We employ a latent system-level discrete state Markov chain that drives latent entity-level chains which in turn govern the dynamics of each observed time series. Feedback from the observations to the chains at both the entity and system levels improves flexibility via context-dependent state transitions. Our hierarchical switching recurrent dynamical models can be learned via closed-form variational coordinate ascent updates to all latent chains that scale linearly in the number of indivi
    
[^3]: 评估模型在交叉子群体间性能的结构回归方法

    A structured regression approach for evaluating model performance across intersectional subgroups. (arXiv:2401.14893v1 [cs.LG])

    [http://arxiv.org/abs/2401.14893](http://arxiv.org/abs/2401.14893)

    这项工作介绍了一种结构回归方法，用于评估模型在不同交叉子群体间的性能。它可以提供可靠的系统性能估计，即使对于很小的子群体。

    

    在人工智能公平性评估中，分解式评估是一项核心任务，目标是衡量人工智能系统在由人口统计学或其他敏感属性组合定义的不同子群体中的性能。标准方法是将评估数据分层到子群体中，并分别计算每个组的性能指标。然而，即使对于中等规模的评估数据集来说，在考虑到交叉子群体时样本数量也会迅速变小，这大大限制了许多分解评估中对交叉群体的考虑程度。在本研究中，我们引入了一种结构回归方法来进行分解评估，我们证明即使对于非常小的子群体，该方法也能产生可靠的系统性能估计。我们还提供了相应的推断策略来构建置信区间，并探索了拟合优度测试如何揭示交叉子群体所经历的与公平相关的伤害的结构。

    Disaggregated evaluation is a central task in AI fairness assessment, with the goal to measure an AI system's performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are considered in many disaggregated evaluations. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We also provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectio
    
[^4]: P3LS: 隐私保护下的偏最小二乘法

    P3LS: Partial Least Squares under Privacy Preservation. (arXiv:2401.14884v1 [stat.ML])

    [http://arxiv.org/abs/2401.14884](http://arxiv.org/abs/2401.14884)

    P3LS是一种隐私保护的偏最小二乘回归技术，通过使用可移动的随机掩码保护每个数据持有者的隐私，实现了跨组织数据集成和过程建模。

    

    现代制造业价值链需要跨公司边界智能协调流程，以最大化利润同时促进社会和环境可持续性。然而，基于数据的价值链决策的集成式系统级方法的实施，目前受到与跨组织数据交换和集成相关的隐私关注的阻碍。我们在这里提出了隐私保护的偏最小二乘（P3LS）回归，一种能够在有隐私保证的情况下实现跨组织数据集成和过程建模的新型联邦学习技术。P3LS涉及一种基于奇异值分解（SVD）的PLS算法，并采用由可信机构生成的可移动的随机掩码来保护每个数据持有者贡献的数据的隐私。我们展示了P3LS在由三个参与方组成的假想价值链上垂直整合过程数据并提高的能力。

    Modern manufacturing value chains require intelligent orchestration of processes across company borders in order to maximize profits while fostering social and environmental sustainability. However, the implementation of integrated, systems-level approaches for data-informed decision-making along value chains is currently hampered by privacy concerns associated with cross-organizational data exchange and integration. We here propose Privacy-Preserving Partial Least Squares (P3LS) regression, a novel federated learning technique that enables cross-organizational data integration and process modeling with privacy guarantees. P3LS involves a singular value decomposition (SVD) based PLS algorithm and employs removable, random masks generated by a trusted authority in order to protect the privacy of the data contributed by each data holder. We demonstrate the capability of P3LS to vertically integrate process data along a hypothetical value chain consisting of three parties and to improve t
    
[^5]: 粒子-MALA和粒子-mGRAD: 面向高维状态空间模型的基于梯度的MCMC方法

    Particle-MALA and Particle-mGRAD: Gradient-based MCMC methods for high-dimensional state-space models. (arXiv:2401.14868v1 [stat.CO])

    [http://arxiv.org/abs/2401.14868](http://arxiv.org/abs/2401.14868)

    粒子-MALA和粒子-mGRAD是基于梯度的MCMC方法，综合了条件顺序Monte Carlo (CSMC)算法的时间可扩展性和MALA或mGRAD的维度可扩展性。

    

    在状态空间模型中，现有的贝叶斯推断方法包括条件顺序Monte Carlo (CSMC)算法和先进的“经典”MCMC算法，如MALA或来自Titsias和Papaspiliopoulos (2018)的mGRAD。前者在每个时间步骤中提出N个粒子来利用模型的“随时间相关性”属性，并且随着时间范围T的增加而可扩展，但如果潜在状态的维度D较大，则会失败。后者利用梯度/先验信息自适应调整局部提议，以在维度D方面有良好的可扩展性，但由于缺乏模型结构的利用而在时间范围T方面显示出亚优的可扩展性。我们介绍了结合了两种方法优点的方法。第一种是粒子-MALA，使用梯度信息在当前状态周围局部扩散N个粒子，从而将MALA扩展到T>1和N>1的提议。第二种是粒子-mGRAD，此外还引入了（条件）Ga

    State-of-the-art methods for Bayesian inference in state-space models are (a) conditional sequential Monte Carlo (CSMC) algorithms; (b) sophisticated 'classical' MCMC algorithms like MALA, or mGRAD from Titsias and Papaspiliopoulos (2018, arXiv:1610.09641v3 [stat.ML]). The former propose $N$ particles at each time step to exploit the model's 'decorrelation-over-time' property and thus scale favourably with the time horizon, $T$ , but break down if the dimension of the latent states, $D$, is large. The latter leverage gradient-/prior-informed local proposals to scale favourably with $D$ but exhibit sub-optimal scalability with $T$ due to a lack of model-structure exploitation. We introduce methods which combine the strengths of both approaches. The first, Particle-MALA, spreads $N$ particles locally around the current state using gradient information, thus extending MALA to $T > 1$ time steps and $N > 1$ proposals. The second, Particle-mGRAD, additionally incorporates (conditionally) Ga
    
[^6]: 一种非参数贝叶斯方法用于在线活动预测

    A Nonparametric Bayes Approach to Online Activity Prediction. (arXiv:2401.14722v1 [stat.ME])

    [http://arxiv.org/abs/2401.14722](http://arxiv.org/abs/2401.14722)

    本研究提出了一种非参数贝叶斯方法，以准确预测在线活动的用户数量和达到所需用户参与门槛所需的时间轨迹。该方法通过捕捉用户参与的潜在异质性，提供了实验者在在线实验中重要的决策支持。

    

    在准确预测特定活动的发生时间内具有重要应用背景。对于运行在线实验（A/B测试）的实验者来说，准确预测未来将接受干预的用户数量是一项重要信息。在这项工作中，我们提出了一种新颖的方法来预测给定时间段内活动用户数量以及达到所需用户参与门槛所需的时间轨迹。我们使用贝叶斯非参数方法来建模用户活动，以捕捉用户参与的潜在异质性。我们推导了在给定时间段内期望的新用户数量的闭式表达式，并提出了一个简单的蒙特卡罗算法来估计达到所需用户数量所需的天数的后验分布；后者对于实验规划非常重要。我们展示了该方法在预测用户活动上的性能。

    Accurately predicting the onset of specific activities within defined timeframes holds significant importance in several applied contexts. In particular, accurate prediction of the number of future users that will be exposed to an intervention is an important piece of information for experimenters running online experiments (A/B tests). In this work, we propose a novel approach to predict the number of users that will be active in a given time period, as well as the temporal trajectory needed to attain a desired user participation threshold. We model user activity using a Bayesian nonparametric approach which allows us to capture the underlying heterogeneity in user engagement. We derive closed-form expressions for the number of new users expected in a given period, and a simple Monte Carlo algorithm targeting the posterior distribution of the number of days needed to attain a desired number of users; the latter is important for experimental planning. We illustrate the performance of o
    
[^7]: 用球面卷积Wasserstein距离验证气候模型

    Validating Climate Models with Spherical Convolutional Wasserstein Distance. (arXiv:2401.14657v1 [physics.ao-ph])

    [http://arxiv.org/abs/2401.14657](http://arxiv.org/abs/2401.14657)

    引入了球面卷积Wasserstein距离来验证气候模型，相比传统方法更全面地衡量气候模型和再分析数据之间的差异，并应用于评估CMIP成员的模型输出。此外，研究发现CMIP第6阶段模型相较于第5阶段有适度改进。

    

    验证全球气候模型对于确保模型输出的准确性和有效性至关重要。我们引入球面卷积Wasserstein距离来更全面地衡量气候模型和再分析数据之间的差异。这个新的相似度测量方法利用卷积投影考虑了空间变异性，并量化了气候变量分布的局部差异。我们将该方法应用于评估耦合模式比较项目（CMIP）成员的历史模型输出，将其与观测数据和再分析数据产品进行比较。此外，我们研究了从CMIP第5阶段到第6阶段的进展，并发现第6阶段模型在生成真实气候学能力方面有适度改进。

    The validation of global climate models is crucial to ensure the accuracy and efficacy of model output. We introduce the spherical convolutional Wasserstein distance to more comprehensively measure differences between climate models and reanalysis data. This new similarity measure accounts for spatial variability using convolutional projections and quantifies local differences in the distribution of climate variables. We apply this method to evaluate the historical model outputs of the Coupled Model Intercomparison Project (CMIP) members by comparing them to observational and reanalysis data products. Additionally, we investigate the progression from CMIP phase 5 to phase 6 and find modest improvements in the phase 6 models regarding their ability to produce realistic climatologies.
    
[^8]: 从分组数据中稳健估计Pareto的尺度参数

    Robust Estimation of Pareto's Scale Parameter from Grouped Data. (arXiv:2401.14593v1 [stat.ME])

    [http://arxiv.org/abs/2401.14593](http://arxiv.org/abs/2401.14593)

    本文介绍了一种新的稳健估计方法（MTuM），用于从分组数据中估计Pareto分布的尾指数。该方法通过应用中心极限定理和模拟研究验证了其推理合理性。

    

    当可获取的完全观测到的从头至尾的损失严重性样本数据集存在时，存在许多稳健估计器作为最大似然估计器（MLE）的替代方案。然而，当处理分组损失严重性数据时，稳健的MLE替代方案的选择变得非常有限，只有少数方法可用，例如最小二乘法、最小Hellinger距离和最优有界影响函数。本文介绍了一种称为截断矩法的新型稳健估计技术，该方法专门用于从分组数据估计Pareto分布的尾指数。通过应用中心极限定理和通过全面的模拟研究验证了MTuM的推理合理性。

    Numerous robust estimators exist as alternatives to the maximum likelihood estimator (MLE) when a completely observed ground-up loss severity sample dataset is available. However, the options for robust alternatives to MLE become significantly limited when dealing with grouped loss severity data, with only a handful of methods like least squares, minimum Hellinger distance, and optimal bounded influence function available. This paper introduces a novel robust estimation technique, the Method of Truncated Moments (MTuM), specifically designed to estimate the tail index of a Pareto distribution from grouped data. Inferential justification of MTuM is established by employing the central limit theorem and validating them through a comprehensive simulation study.
    
[^9]: 利用Ricci流引导的自编码器学习时变动力学

    Ricci flow-guided autoencoders in learning time-dependent dynamics. (arXiv:2401.14591v1 [cs.LG])

    [http://arxiv.org/abs/2401.14591](http://arxiv.org/abs/2401.14591)

    利用Ricci流引导的自编码器方法能够学习非线性动力学，尤其是偏微分方程。该方法通过在训练中学习流形，并使用Ricci流使流形潜空间逐步适应动力学的变化，从而获得更好的表示能力。在实验中，我们展示了该方法在具有周期性和随机性的PDE上的应用，并评估了在分布内和外推场景中的误差。

    

    我们提出了一种基于流形的自编码器方法，用于学习时间上的非线性动力学，尤其是偏微分方程（PDE），其中流形潜空间根据Ricci流发展。这可以通过在物理信息设置中模拟Ricci流来实现，并且可以匹配流形量，以便实现Ricci流。使用我们的方法，流形是作为训练过程的一部分学习的，因此可以识别出理想的几何形状，同时演变也能在静态方法上引起更宽容的潜在表示。我们在一系列数值实验中展示了我们的方法，包括具有周期性和随机性等理想特征的PDE，并在分布内和外推场景中进行误差评估。

    We present a manifold-based autoencoder method for learning nonlinear dynamics in time, notably partial differential equations (PDEs), in which the manifold latent space evolves according to Ricci flow. This can be accomplished by simulating Ricci flow in a physics-informed setting, and manifold quantities can be matched so that Ricci flow is empirically achieved. With our methodology, the manifold is learned as part of the training procedure, so ideal geometries may be discerned, while the evolution simultaneously induces a more accommodating latent representation over static methods. We present our method on a range of numerical experiments consisting of PDEs that encompass desirable characteristics such as periodicity and randomness, remarking error on in-distribution and extrapolation scenarios.
    
[^10]: 理解事后机器学习解释中的差异

    Understanding Disparities in Post Hoc Machine Learning Explanation. (arXiv:2401.14539v1 [cs.LG])

    [http://arxiv.org/abs/2401.14539](http://arxiv.org/abs/2401.14539)

    该研究通过模拟和实验评估了事后机器学习解释中的差异，并发现协变量偏移、概念转变和省略协变量会增加解释差异，对神经网络影响更大。

    

    先前的研究已经指出，现有的事后解释方法在解释准确性上存在差异（涉及“种族”和“性别”等敏感属性），虽然已有大量研究致力于在解释度量水平上减少这些问题，但数据生成过程和黑盒模型与解释差异之间的关系仍然未被广泛探讨。因此，通过模拟和在真实数据集上的实验，我们特别评估了解释差异面临的挑战：数据性质引起的局限样本量、协变量偏移、概念转变、被省略的变量偏差，以及模型性质引起的挑战：敏感属性的包含和适当的函数形式。通过受控模拟分析，我们的研究证明增加协变量偏移、概念转变和省略协变量会增加解释差异，对于神经网络而言，这种效应更加显著。

    Previous work has highlighted that existing post-hoc explanation methods exhibit disparities in explanation fidelity (across 'race' and 'gender' as sensitive attributes), and while a large body of work focuses on mitigating these issues at the explanation metric level, the role of the data generating process and black box model in relation to explanation disparities remains largely unexplored. Accordingly, through both simulations as well as experiments on a real-world dataset, we specifically assess challenges to explanation disparities that originate from properties of the data: limited sample size, covariate shift, concept shift, omitted variable bias, and challenges based on model properties: inclusion of the sensitive attribute and appropriate functional form. Through controlled simulation analyses, our study demonstrates that increased covariate shift, concept shift, and omission of covariates increase explanation disparities, with the effect pronounced higher for neural network 
    
[^11]: 优化港口运营的预测分析

    Predictive Analysis for Optimizing Port Operations. (arXiv:2401.14498v1 [cs.LG])

    [http://arxiv.org/abs/2401.14498](http://arxiv.org/abs/2401.14498)

    本研究开发了一种具有竞争预测和分类能力的港口运营解决方案，用于准确估计船舶在港口的总时间和延迟时间，填补了港口分析模型在这方面的空白，并为海事物流领域提供了有价值的贡献。

    

    海运是远距离和大宗货物运输的重要物流方式。然而，这种运输模式中复杂的规划经常受到不确定性的影响，包括天气条件、货物多样性和港口动态，导致成本增加。因此，准确估计船舶在港口停留的总时间和潜在延迟变得至关重要，以便在港口运营中进行有效的规划和安排。本研究旨在开发具有竞争预测和分类能力的港口运营解决方案，用于估计船舶的总时间和延迟时间。该研究填补了港口分析模型在船舶停留和延迟时间方面的重要空白，为海事物流领域提供了有价值的贡献。所提出的解决方案旨在协助港口环境下的决策制定，并预测服务延迟。通过对巴西港口的案例研究进行验证，同时使用特征分析来理解...

    Maritime transport is a pivotal logistics mode for the long-distance and bulk transportation of goods. However, the intricate planning involved in this mode is often hindered by uncertainties, including weather conditions, cargo diversity, and port dynamics, leading to increased costs. Consequently, accurately estimating vessel total (stay) time at port and potential delays becomes imperative for effective planning and scheduling in port operations. This study aims to develop a port operation solution with competitive prediction and classification capabilities for estimating vessel Total and Delay times. This research addresses a significant gap in port analysis models for vessel Stay and Delay times, offering a valuable contribution to the field of maritime logistics. The proposed solution is designed to assist decision-making in port environments and predict service delays. This is demonstrated through a case study on Brazil ports. Additionally, feature analysis is used to understand
    
[^12]: 预测的四个方面：校准、预测性、随机性和遗憾

    Four Facets of Forecast Felicity: Calibration, Predictiveness, Randomness and Regret. (arXiv:2401.14483v1 [cs.LG])

    [http://arxiv.org/abs/2401.14483](http://arxiv.org/abs/2401.14483)

    本文展示了校准和遗憾在评估预测中的概念等价性，将评估问题构建为一个预测者、一个赌徒和自然之间的博弈，并将预测的评估与结果的随机性联系起来。

    

    机器学习是关于预测的。然而，预测只有经过评估后才具有其有用性。机器学习传统上关注损失类型及其相应的遗憾。目前，机器学习社区重新对校准产生了兴趣。在这项工作中，我们展示了校准和遗憾在评估预测中的概念等价性。我们将评估问题构建为一个预测者、一个赌徒和自然之间的博弈。通过对赌徒和预测者施加直观的限制，校准和遗憾自然地成为了这个框架的一部分。此外，这个博弈将预测的评估与结果的随机性联系起来。相对于预测而言，结果的随机性等同于关于结果的好的预测。我们称这两个方面为校准和遗憾、预测性和随机性，即预测的四个方面。

    Machine learning is about forecasting. Forecasts, however, obtain their usefulness only through their evaluation. Machine learning has traditionally focused on types of losses and their corresponding regret. Currently, the machine learning community regained interest in calibration. In this work, we show the conceptual equivalence of calibration and regret in evaluating forecasts. We frame the evaluation problem as a game between a forecaster, a gambler and nature. Putting intuitive restrictions on gambler and forecaster, calibration and regret naturally fall out of the framework. In addition, this game links evaluation of forecasts to randomness of outcomes. Random outcomes with respect to forecasts are equivalent to good forecasts with respect to outcomes. We call those dual aspects, calibration and regret, predictiveness and randomness, the four facets of forecast felicity.
    
[^13]: 利用专利数据提高抗体人性预测能力

    Improving Antibody Humanness Prediction using Patent Data. (arXiv:2401.14442v1 [q-bio.QM])

    [http://arxiv.org/abs/2401.14442](http://arxiv.org/abs/2401.14442)

    本研究利用专利数据提高了抗体人性预测的能力，通过多阶段、多损失的训练过程以及弱监督对比学习的方法，成功地预测了抗体序列的人性评分。

    

    我们研究了利用专利数据来提高抗体人性预测的潜力，采用了多阶段、多损失的训练过程。抗体人性作为对抗体治疗的免疫反应的代理，是药物发现中的主要原因之一，在临床环境中使用抗体治疗面临着具有挑战性的障碍。我们将初始学习阶段视为一个弱监督对比学习问题，每个抗体序列与可能有多个功能标识符相关联，目标是学习一个编码器，根据其专利属性将它们分组。然后，我们冻结对比编码器的一部分，并继续使用交叉熵损失在专利数据上训练，以预测给定抗体序列的人性评分。我们通过对三个不同的免疫原性数据集进行推理，展示了专利数据和我们的方法的效用。我们的实证结果表明，l

    We investigate the potential of patent data for improving the antibody humanness prediction using a multi-stage, multi-loss training process. Humanness serves as a proxy for the immunogenic response to antibody therapeutics, one of the major causes of attrition in drug discovery and a challenging obstacle for their use in clinical settings. We pose the initial learning stage as a weakly-supervised contrastive-learning problem, where each antibody sequence is associated with possibly multiple identifiers of function and the objective is to learn an encoder that groups them according to their patented properties. We then freeze a part of the contrastive encoder and continue training it on the patent data using the cross-entropy loss to predict the humanness score of a given antibody sequence. We illustrate the utility of the patent data and our approach by performing inference on three different immunogenicity datasets, unseen during training. Our empirical results demonstrate that the l
    
[^14]: [再论] 非线性和非高斯观测模型的贝叶斯滤波的判别式卡尔曼滤波器

    [Re] The Discriminative Kalman Filter for Bayesian Filtering with Nonlinear and Non-Gaussian Observation Models. (arXiv:2401.14429v1 [cs.LG])

    [http://arxiv.org/abs/2401.14429](http://arxiv.org/abs/2401.14429)

    该论文提供了一种针对非线性和非高斯观测模型的贝叶斯滤波的判别式卡尔曼滤波器，并在神经科学背景下证明了其有效性。

    

    卡尔曼滤波器为估计隐藏或潜在变量提供了一种直观且易于理解的方法，并在控制、机器人、信号处理和机器学习等领域应用广泛。其中一种应用是神经脑机接口的神经解码。2020年，Burkhart等人对他们的新版本卡尔曼滤波器进行了深入评估，利用贝叶斯定理改善了对高度非线性或非高斯观测模型的滤波性能。本研究提供了作者MATLAB算法的Python开源替代方案。具体而言，我们重新复现了他们在神经科学背景下最显著的结果，并使用多个随机种子和作者数据集中未使用的试验进一步检验了滤波器的效果。所有实验在一台计算机上离线进行。

    Kalman filters provide a straightforward and interpretable means to estimate hidden or latent variables, and have found numerous applications in control, robotics, signal processing, and machine learning. One such application is neural decoding for neuroprostheses. In 2020, Burkhart et al. thoroughly evaluated their new version of the Kalman filter that leverages Bayes' theorem to improve filter performance for highly non-linear or non-Gaussian observation models. This work provides an open-source Python alternative to the authors' MATLAB algorithm. Specifically, we reproduce their most salient results for neuroscientific contexts and further examine the efficacy of their filter using multiple random seeds and previously unused trials from the authors' dataset. All experiments were performed offline on a single computer.
    
[^15]: 多智能体基于迁移学习的数据驱动空中交通应用

    Multi-Agent Based Transfer Learning for Data-Driven Air Traffic Applications. (arXiv:2401.14421v1 [cs.LG])

    [http://arxiv.org/abs/2401.14421](http://arxiv.org/abs/2401.14421)

    本文提出了一种基于多智能体的迁移学习方法，利用MA-BERT模型和预训练微调框架来解决空中交通管理中的长训练时间和大数据集需求的问题。该方法可以在具有少量数据或无历史数据的情况下实现高性能。

    

    近年来，开发空中交通管理(ATM)的数据驱动模型的研究引起了巨大的兴趣。然而，众所周知，数据驱动模型具有较长的训练时间，并且需要大量的数据集才能达到良好的性能。为了解决这两个问题，本文提出了一种全面考虑ATM系统多智能体特性的Multi-Agent Bidirectional Encoder Representations from Transformers (MA-BERT)模型，并采用预训练和微调迁移学习框架。通过将MA-BERT在一个主要机场的大规模数据集上进行预训练，并在其他机场和特定空中交通应用上进行微调，可以节省大量的总训练时间。此外，对于新采用的程序和建立的机场，没有历史数据可用，本文展示了预训练的MA-BERT可以通过少量数据的定期更新实现高性能。

    Research in developing data-driven models for Air Traffic Management (ATM) has gained a tremendous interest in recent years. However, data-driven models are known to have long training time and require large datasets to achieve good performance. To address the two issues, this paper proposes a Multi-Agent Bidirectional Encoder Representations from Transformers (MA-BERT) model that fully considers the multi-agent characteristic of the ATM system and learns air traffic controllers' decisions, and a pre-training and fine-tuning transfer learning framework. By pre-training the MA-BERT on a large dataset from a major airport and then fine-tuning it to other airports and specific air traffic applications, a large amount of the total training time can be saved. In addition, for newly adopted procedures and constructed airports where no historical data is available, this paper shows that the pre-trained MA-BERT can achieve high performance by updating regularly with little data. The proposed t
    
[^16]: 非交换式共形风险控制

    Non-Exchangeable Conformal Risk Control. (arXiv:2310.01262v1 [cs.LG])

    [http://arxiv.org/abs/2310.01262](http://arxiv.org/abs/2310.01262)

    本文提出了一种非交换式共形风险控制的框架，可以在数据不可交换的情况下控制任何单调损失函数的期望值。

    

    最近，由于其能够为黑匣子神经模型的预测提供形式上保证的不确定性集合或区间，确保包含实际真实值的预定义概率，拆分共形预测引发了极大的兴趣。虽然最初的公式假设数据可交换，但一些扩展处理不可交换的数据，在许多现实世界的场景中经常发生。同时，一些进展已经在共形方法中取得，这些方法对更广泛的目标提供统计保证，例如限制最佳F1分数或以期望最小化误报率。在本文中，我们利用和扩展这两个工作线路，提出了非交换式共形风险控制，可以在数据不可交换的情况下控制任何单调损失函数的期望值。我们的框架灵活，假设很少，并允许根据数据的统计相似性进行加权处理。

    Split conformal prediction has recently sparked great interest due to its ability to provide formally guaranteed uncertainty sets or intervals for predictions made by black-box neural models, ensuring a predefined probability of containing the actual ground truth. While the original formulation assumes data exchangeability, some extensions handle non-exchangeable data, which is often the case in many real-world scenarios. In parallel, some progress has been made in conformal methods that provide statistical guarantees for a broader range of objectives, such as bounding the best F1-score or minimizing the false negative rate in expectation. In this paper, we leverage and extend these two lines of work by proposing non-exchangeable conformal risk control, which allows controlling the expected value of any monotone loss function when the data is not exchangeable. Our framework is flexible, makes very few assumptions, and allows weighting the data based on its statistical similarity with t
    
[^17]: 测量因果控制的因果熵和信息增益

    Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])

    [http://arxiv.org/abs/2309.07703](http://arxiv.org/abs/2309.07703)

    本文提出了一种考虑因果结构的信息论量，用于评估某个特定结果变量的因果重要性，解决了因果可解释性的挑战。

    

    人工智能模型和方法通常缺乏因果可解释性。尽管解释性机器学习（IML）方法取得了进展，但它们经常将重要性赋予那些对结果变量没有因果影响的特征。在模型训练之前或之后，选择因果相关的特征将提供一种解决方案。利用信息论量进行特征选择的方法在识别统计相关特征方面非常成功。然而，它们所基于的信息论量不包含因果关系，因此在这种情况下不适用。为了解决这个挑战，本文提出了能够考虑系统因果结构的信息论量，可以用于评估某个给定结果变量的因果重要性。具体来说，我们引入了因果熵和因果互信息的因果版本。

    Artificial intelligence models and methods commonly lack causal interpretability. Despite the advancements in interpretable machine learning (IML) methods, they frequently assign importance to features which lack causal influence on the outcome variable. Selecting causally relevant features among those identified as relevant by these methods, or even before model training, would offer a solution. Feature selection methods utilizing information theoretical quantities have been successful in identifying statistically relevant features. However, the information theoretical quantities they are based on do not incorporate causality, rendering them unsuitable for such scenarios. To address this challenge, this article proposes information theoretical quantities that incorporate the causal structure of the system, which can be used to evaluate causal importance of features for some given outcome variable. Specifically, we introduce causal versions of entropy and mutual information, termed cau
    
[^18]: 用于计算深度神经网络正则化路径的多目标延续方法

    A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])

    [http://arxiv.org/abs/2308.12044](http://arxiv.org/abs/2308.12044)

    本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。

    

    稀疏性是深度神经网络(DNNs)中非常理想的特征，因为它确保了数值效率，提高了模型的可解释性(由于相关特征的数量较少)和鲁棒性。在基于线性模型的机器学习方法中，众所周知在$\ell^1$范数(即零权重)的最稀疏解和非正则化解之间存在一条连接路径，这条路径被称为正则化路径。最近，通过将经验损失和稀疏性($\ell^1$范数)作为两个冲突的标准，并解决由此产生的多目标优化问题，首次尝试将正则化路径的概念扩展到DNNs。然而，由于$\ell^1$范数的不光滑性和参数数量的高度，从计算的角度来看，这种方法并不是很有效。为了克服这个限制，我们提出了一种算法，可以近似计算整个帕累托曲线

    Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
    
[^19]: 最优低秩矩阵填补：半定松弛和特征向量分离

    Optimal Low-Rank Matrix Completion: Semidefinite Relaxations and Eigenvector Disjunctions. (arXiv:2305.12292v1 [cs.LG])

    [http://arxiv.org/abs/2305.12292](http://arxiv.org/abs/2305.12292)

    该论文通过重新表述低秩矩阵填补问题为投影矩阵的非凸问题，实现了能够确定最优解的分离分支定界方案，并且通过新颖和紧密的凸松弛方法，使得最优性差距相对于现有方法减少了两个数量级。

    

    低秩矩阵填补的目的是计算一个复杂度最小的矩阵，以尽可能准确地恢复给定的一组观测数据，并且具有众多应用，如产品推荐。不幸的是，现有的解决低秩矩阵填补的方法是启发式的，虽然高度可扩展并且通常能够确定高质量的解决方案，但不具备任何最优性保证。我们通过将低秩问题重新表述为投影矩阵的非凸问题，并实现一种分离分支定界方案来重新审视矩阵填补问题，以实现最优性导向。此外，我们通过将低秩矩阵分解为一组秩一矩阵的和，并通过 Shor 松弛来激励每个秩一矩阵中的每个 2*2 小矩阵的行列式为零，从而推导出一种新颖且通常很紧的凸松弛类。在数值实验中，相对于最先进的启发式方法，我们的新凸松弛方法将最优性差距减少了两个数量级。

    Low-rank matrix completion consists of computing a matrix of minimal complexity that recovers a given set of observations as accurately as possible, and has numerous applications such as product recommendation. Unfortunately, existing methods for solving low-rank matrix completion are heuristics that, while highly scalable and often identifying high-quality solutions, do not possess any optimality guarantees. We reexamine matrix completion with an optimality-oriented eye, by reformulating low-rank problems as convex problems over the non-convex set of projection matrices and implementing a disjunctive branch-and-bound scheme that solves them to certifiable optimality. Further, we derive a novel and often tight class of convex relaxations by decomposing a low-rank matrix as a sum of rank-one matrices and incentivizing, via a Shor relaxation, that each two-by-two minor in each rank-one matrix has determinant zero. In numerical experiments, our new convex relaxations decrease the optimali
    
[^20]: 二元积分布的多项式时间和纯差分隐私估计器

    A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v1 [cs.DS])

    [http://arxiv.org/abs/2304.06787](http://arxiv.org/abs/2304.06787)

    本论文提出了第一个多项式时间、纯差分隐私估计器，可以在$\{0,1\}^d$上准确估计二元积分布的均值，达到了最优的样本复杂度。

    

    我们提出了第一个ε-差分隐私、计算有效的算法，可以在总变化距离下准确地估计$\{0,1\}^d$上的乘积分布的均值，同时在多项式对数因子内获得了最优的样本复杂度。之前的工作要么在更弱的隐私概念下有效地解决了这个问题，要么在指数级运行时间内最优地解决了这个问题。

    We present the first $\varepsilon$-differentially private, computationally efficient algorithm that estimates the means of product distributions over $\{0,1\}^d$ accurately in total-variation distance, whilst attaining the optimal sample complexity to within polylogarithmic factors. The prior work had either solved this problem efficiently and optimally under weaker notions of privacy, or had solved it optimally while having exponential running times.
    
[^21]: 单时间尺度演员-评论家法的有限时间分析

    Finite-time analysis of single-timescale actor-critic. (arXiv:2210.09921v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09921](http://arxiv.org/abs/2210.09921)

    这项研究提出了一种在线单时间尺度演员-评论家方法，通过线性函数逼近和马尔可夫样本更新，在连续状态空间中找到了一个$\epsilon$-近似的稳定点，并且在样本复杂度为$\widetilde{\mathcal{O}}(\epsilon^{-2})$的情况下证明了其收敛性。

    

    在许多具有挑战性的应用中，演员-评论家方法取得了显着的成功。然而，在最实际的单时间尺度形式下，其有限时间收敛性仍然不够理解。现有的单时间尺度演员-评论家分析工作仅限于简化的i.i.d.采样或表格设置。我们研究了更实际的在线单时间尺度演员-评论家算法，该算法在连续状态空间中，评论家采用线性函数逼近，并在每个演员步骤中使用单个马尔可夫样本进行更新。先前的分析无法在这种具有挑战性的场景中实现收敛。我们证明，在标准假设下，在线单时间尺度演员-评论家方法能够在样本复杂度为$\widetilde{\mathcal{O}}(\epsilon^{-2})$的情况下找到一个$\epsilon$-近似的稳定点，而在i.i.d.采样下，这个复杂度可以进一步改进为$\mathcal{O}(\epsilon^{-2})$。我们的新框架系统地评估了一个

    Actor-critic methods have achieved significant success in many challenging applications. However, its finite-time convergence is still poorly understood in the most practical single-timescale form. Existing works on analyzing single-timescale actor-critic have been limited to i.i.d. sampling or tabular setting for simplicity. We investigate the more practical online single-timescale actor-critic algorithm on continuous state space, where the critic assumes linear function approximation and updates with a single Markovian sample per actor step. Previous analysis has been unable to establish the convergence for such a challenging scenario. We demonstrate that the online single-timescale actor-critic method provably finds an $\epsilon$-approximate stationary point with $\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity under standard assumptions, which can be further improved to $\mathcal{O}(\epsilon^{-2})$ under the i.i.d. sampling. Our novel framework systematically evaluates an
    
[^22]: 机器学习中的签名方法

    Signature Methods in Machine Learning. (arXiv:2206.14674v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.14674](http://arxiv.org/abs/2206.14674)

    本综述介绍了机器学习中应用的签名方法，通过数学洞察力理解复杂的流式数据之间的交互，并提供了用于分析非规则、非平稳的流式数据的数值方法。

    

    基于签名的技术为理解复杂的流式数据之间的相互作用提供了数学洞察力。这些洞察力可以很自然地转化为理解流式数据的数值方法，也许是因为它们具有数学的精确性，它们在分析非规则、非平稳的流式数据以及数据维度和样本大小都适中的情况下表现出了很有用的性质。对于理解流式多模态数据是指数级的问题：长度为$n$的字母串，来自大小为$d$的字母表，可以是$d^n$种不同的消息。签名消除了由于采样不规则性而产生的指数级的噪声，但仍然存在指数级的信息量。本综述旨在保持在可以直接管理这种指数级缩放的领域内。可扩展性问题是许多问题中的一个重要挑战，但需要另一篇综述文章和进一步的思路。本综述描述了一系列上下文。

    Signature-based techniques give mathematical insight into the interactions between complex streams of evolving data. These insights can be quite naturally translated into numerical approaches to understanding streamed data, and perhaps because of their mathematical precision, have proved useful in analysing streamed data in situations where the data is irregular, and not stationary, and the dimension of the data and the sample sizes are both moderate. Understanding streamed multi-modal data is exponential: a word in $n$ letters from an alphabet of size $d$ can be any one of $d^n$ messages. Signatures remove the exponential amount of noise that arises from sampling irregularity, but an exponential amount of information still remain. This survey aims to stay in the domain where that exponential scaling can be managed directly. Scalability issues are an important challenge in many problems but would require another survey article and further ideas. This survey describes a range of context
    
[^23]: 反射梯度 Langevin 动力学收敛误差分析，用于全局优化非凸约束问题

    Convergence Error Analysis of Reflected Gradient Langevin Dynamics for Globally Optimizing Non-Convex Constrained Problems. (arXiv:2203.10215v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2203.10215](http://arxiv.org/abs/2203.10215)

    本文将梯度 Langevin 动力学和反射梯度 Langevin 动力学扩展到非凸问题上，并通过使用边界反射和概率表示法，在非凸约束问题中提出了更快的收敛速度。

    

    梯度 Langevin 动力学及其各种变体由于在无约束凸框架中收敛于全局最优解而受到越来越多的关注，最近甚至在凸约束非凸问题中也是如此。在本研究中，我们将这些框架扩展到具有全局优化算法的非凸问题上，该算法建立在反射梯度 Langevin 动力学的基础上，并推导出其收敛速度。通过有效地利用边界处的反射和带有纽曼边界条件的泊松方程的概率表示，我们呈现了有希望的收敛速度，特别是对于凸约束非凸问题，比现有方法更快。

    Gradient Langevin dynamics and a variety of its variants have attracted increasing attention owing to their convergence towards the global optimal solution, initially in the unconstrained convex framework while recently even in convex constrained non-convex problems. In the present work, we extend those frameworks to non-convex problems on a non-convex feasible region with a global optimization algorithm built upon reflected gradient Langevin dynamics and derive its convergence rates. By effectively making use of its reflection at the boundary in combination with the probabilistic representation for the Poisson equation with the Neumann boundary condition, we present promising convergence rates, particularly faster than the existing one for convex constrained non-convex problems.
    
[^24]: 稀疏随机超图：非回退谱和社区检测

    Sparse random hypergraphs: Non-backtracking spectra and community detection. (arXiv:2203.07346v4 [math.PR] UPDATED)

    [http://arxiv.org/abs/2203.07346](http://arxiv.org/abs/2203.07346)

    该论文研究了稀疏随机超图中的社区检测问题，证明了基于非回退算子的谱方法能够高概率下达到猜测阈值，并提供了一个高效的维度约减过程。这是第一个能够证明并高效实现HSBM猜测阈值的谱算法。

    

    本文考虑了在一个稀疏的$q$-uniform超图$G$中进行社区检测的问题，假设$G$是根据超图随机块模型(HSBM)生成的。我们证明了基于超图非回退算子的谱方法在高概率下能够达到Angelini等人(2015)猜测的广义Kesten-Stigum检测阈值。我们对稀疏HSBM的非回退算子的谱进行了表征，并利用超图的Ihara-Bass公式提供了一个高效的维度约减过程。因此，对于有$n$个顶点的稀疏HSBM，社区检测可以约化为一个$2n\times 2n$的非正常矩阵的特征向量问题，该矩阵由超图的邻接矩阵和度矩阵构成。据我们所知，这是第一个能够证明并高效实现HSBM猜测阈值的谱算法。

    We consider the community detection problem in a sparse $q$-uniform hypergraph $G$, assuming that $G$ is generated according to the Hypergraph Stochastic Block Model (HSBM). We prove that a spectral method based on the non-backtracking operator for hypergraphs works with high probability down to the generalized Kesten-Stigum detection threshold conjectured by Angelini et al. (2015). We characterize the spectrum of the non-backtracking operator for the sparse HSBM and provide an efficient dimension reduction procedure using the Ihara-Bass formula for hypergraphs. As a result, community detection for the sparse HSBM on $n$ vertices can be reduced to an eigenvector problem of a $2n\times 2n$ non-normal matrix constructed from the adjacency matrix and the degree matrix of the hypergraph. To the best of our knowledge, this is the first provable and efficient spectral algorithm that achieves the conjectured threshold for HSBMs with $r$ blocks generated according to a general symmetric probab
    
[^25]: 基于邻域选择方法的高维函数图模型结构学习

    High-dimensional Functional Graphical Model Structure Learning via Neighborhood Selection Approach. (arXiv:2105.02487v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2105.02487](http://arxiv.org/abs/2105.02487)

    该论文提出了一种基于邻域选择方法的高维函数图模型结构学习方法，通过函数对函数回归估计节点邻域，然后结合这些估计的邻域恢复整个图结构，从而直接估计条件独立结构。

    

    无向图模型广泛用于建模向量值数据的条件独立结构。然而，在许多现代应用中，例如涉及EEG和fMRI数据的应用中，观测更适合被建模为多变量随机函数而不是向量。已经提出了函数图模型来建模这种函数数据的条件独立结构。我们提出了一种邻域选择方法来估计高斯函数图模型的结构，首先通过函数对函数回归估计每个节点的邻域，然后通过组合估计的邻域恢复整个图结构。我们的方法仅需要对随机函数的条件分布进行假设，并直接估计条件独立结构。因此，我们避免了对可能不存在的精度算子进行明确定义的需要，尤其是当函数具有无限维时。

    Undirected graphical models are widely used to model the conditional independence structure of vector-valued data. However, in many modern applications, for example those involving EEG and fMRI data, observations are more appropriately modeled as multivariate random functions rather than vectors. Functional graphical models have been proposed to model the conditional independence structure of such functional data. We propose a neighborhood selection approach to estimate the structure of Gaussian functional graphical models, where we first estimate the neighborhood of each node via a function-on-function regression and subsequently recover the entire graph structure by combining the estimated neighborhoods. Our approach only requires assumptions on the conditional distributions of random functions, and we estimate the conditional independence structure directly. We thus circumvent the need for a well-defined precision operator that may not exist when the functions are infinite dimension
    

