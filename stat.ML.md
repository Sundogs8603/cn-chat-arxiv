# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks.](http://arxiv.org/abs/2305.13271) | MAGDiff是一种新的表示法，可以从神经网络分类器中提取，可以有效地检测协变数据集转移，而不需要训练新模型。这可以通过对比神经网络激活图来计算，并通过两个样本 Kolmogorov-Smirnov 测试进行实证验证。 |
| [^2] | [Bayesian Numerical Integration with Neural Networks.](http://arxiv.org/abs/2305.13248) | 本文提出了一种基于神经网络架构的贝叶斯数值积分方法，称为贝叶斯 Stein 神经网络。该方法可高效地编码积分先验信息并计算积分估计的不确定性。在实际问题中，该方法展现出数量级的加速的优势。 |
| [^3] | [Gibbs free energies via isobaric-isothermal flows.](http://arxiv.org/abs/2305.13233) | 采用机器学习模型利用等压等温流得到吉布斯自由能，并在单原子水的结晶中进行了测试，表现出优秀的性能。 |
| [^4] | [Faster Differentially Private Convex Optimization via Second-Order Methods.](http://arxiv.org/abs/2305.13209) | 本文研究使用二阶信息加速差分隐私凸优化，在强凸损失函数类中提出了一种具有二次收敛速度和最优超额损失的算法。 |
| [^5] | [SignSVRG: fixing SignSGD via variance reduction.](http://arxiv.org/abs/2305.13187) | 本文介绍了一种简单但实用的方法，将方差缩减技术纳入到SignSGD中，并保证了类似完整符号梯度下降的收敛性。 |
| [^6] | [Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained Features Model.](http://arxiv.org/abs/2305.13165) | 本文研究了深度神经坍塌现象（Deep Neural Collapse），证明了在深度无约束特征模型中，唯一的全局最优解表现出了DNC的特征，并且通过选择合适的超参数，仅对模型的最后一层进行训练可以在不损失精度的情况下加快收敛。 |
| [^7] | [Gradient Descent Monotonically Decreases the Sharpness of Gradient Flow Solutions in Scalar Networks and Beyond.](http://arxiv.org/abs/2305.13064) | 对于标量网络和其他模型，研究表明梯度下降会单调递减梯度流解的尖锐度。 |
| [^8] | [A network community detection method with integration of data from multiple layers and node attributes.](http://arxiv.org/abs/2305.13012) | 该论文介绍了一种利用多层数据和节点属性整合的网络社区检测方法，并提出将网络数据表示为数据矩阵的简单方式。该方法可根据分析目标选择数据矩阵，并使用一种压缩数据矩阵的方法将其行分成社区，从而进行强大的分析。 |
| [^9] | [funLOCI: a local clustering algorithm for functional data.](http://arxiv.org/abs/2305.12991) | funLOCI是一种三步分裂式分层聚类算法，可以针对功能数据找出本地聚类，通过借鉴多元和功能聚类的思想，采用加法模型考虑曲线的形状，可使用树状图可视化和指导搜索过程，并实现了额外的步骤将结果数量降至最小。 |
| [^10] | [The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors.](http://arxiv.org/abs/2305.12883) | 该论文研究了基于一般回归误差假设的无噪声回归最小二乘估计值的均方误差，并发现包含大量不重要的参数可以有效地降低估计器的均方误差。 |
| [^11] | [Relabel Minimal Training Subset to Flip a Prediction.](http://arxiv.org/abs/2305.12809) | 本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。 |
| [^12] | [Semi-Supervised Causal Inference: Generalizable and Double Robust Inference for Average Treatment Effects under Selection Bias with Decaying Overlap.](http://arxiv.org/abs/2305.12789) | 本论文提出了一种新的针对高维情况下缺失标签且存在选择偏差的平均处理效应估计方法，它具有良好的一致性和渐近正态性。 |
| [^13] | [Conformal Inference for Invariant Risk Minimization.](http://arxiv.org/abs/2305.12686) | 本文研究了非分布预测区域的构造，以描述不同环境下数据的分布偏移的不确定性估计。该方法利用一种适应特定环境的加权一致性分数构建自适应的一致区间，并证明其条件平均值。 |
| [^14] | [Offline Reinforcement Learning with Additional Covering Distributions.](http://arxiv.org/abs/2305.12679) | 本文提出了一种离线强化学习算法，它在只有部分覆盖数据集和弱可实现函数类的情况下，利用覆盖分布的附加侧信息实现了样本有效离线RL，并展示了覆盖分布在先验知识和所需附加数据量之间进行权衡来获得更好的学习效果。 |
| [^15] | [Limited Resource Allocation in a Non-Markovian World: The Case of Maternal and Child Healthcare.](http://arxiv.org/abs/2305.12640) | 研究中提出了一种新颖的算法TSAB，通过建模参与者的轨迹为时间序列，并结合时间序列预测模型来预测未来状态，以适应非Markovian设置。该算法在提高数据依从性和/或参与度的资源分配方面优于过去的方法。 |
| [^16] | [A parametric distribution for exact post-selection inference with data carving.](http://arxiv.org/abs/2305.12581) | 本文提出了一种基于已知的参数分布用于数据切片的确切后选择推断方法，从而避免了计算昂贵的MCMC方法的使用。 |
| [^17] | [Conditional Generative Modeling is All You Need for Marked Temporal Point Processes.](http://arxiv.org/abs/2305.12569) | 本文提出了一种从标记时间点过程中提取其统计直觉的事件生成模型，通过条件生成器以历史观察作为输入，生成可能发生的高质量随后事件。该模型具有高效、灵活和表示能力等方面的优势。 |
| [^18] | [Two Sides of One Coin: the Limits of Untuned SGD and the Power of Adaptive Methods.](http://arxiv.org/abs/2305.12475) | 本文证明了单调学习率 SGD 的算法依然可以达到渐近最优收敛速度，但是这是以光滑度常数出现灾难性指数级依赖为代价的，因此研究了三种自适应方法来防止这种指数依赖，实现了了准确性和自适应性的平衡。 |
| [^19] | [Quasi-Monte Carlo Graph Random Features.](http://arxiv.org/abs/2305.12470) | 该论文提出了一种名为q-GRFs（拟随机数蒙特卡罗图随机特征）的方法，它通过施加抗生终止的方法诱导算法随机漫步长度之间的负相关性，从而改善了图随机特征的准确性，同时能够适用于任何图形拓扑结构。 |
| [^20] | [Federated Offline Policy Learning with Heterogeneous Observational Data.](http://arxiv.org/abs/2305.12407) | 本文提出了一种基于异构数据源的联邦政策学习算法，该算法基于本地策略聚合的方法，使用双重稳健线下策略评估和学习策略进行训练，可以在不交换原始数据的情况下学习个性化决策政策。我们建立了全局和局部后悔上限的理论模型，并用实验结果支持了理论发现。 |
| [^21] | [When are ensembles really effective?.](http://arxiv.org/abs/2305.12313) | 本文研究证明了在分类任务中，当集成模型的错误率较单个模型更低，且模型间不同意的错误率超过平均错误率，则集成学习能够显著提高性能。 |
| [^22] | [Alignment of Density Maps in Wasserstein Distance.](http://arxiv.org/abs/2305.12310) | 本文提出了一种使用Wasserstein距离对三维物体进行对齐的算法，并通过贝叶斯优化实现计算。在对齐真实蛋白质分子方面，该算法表现出更好的准确性和效率，并阐明了对新距离函数的需求。 |
| [^23] | [Optimal Low-Rank Matrix Completion: Semidefinite Relaxations and Eigenvector Disjunctions.](http://arxiv.org/abs/2305.12292) | 该论文通过重新表述低秩矩阵填补问题为投影矩阵的非凸问题，实现了能够确定最优解的分离分支定界方案，并且通过新颖和紧密的凸松弛方法，使得最优性差距相对于现有方法减少了两个数量级。 |
| [^24] | [Contrastive inverse regression for dimension reduction.](http://arxiv.org/abs/2305.12287) | 本文提出了一种针对病例对照研究数据集的有监督式降维方法CIR，并在保留响应变量的函数关系的同时，直接鼓励在降维空间中将前景组与背景组分离，实验证明其有效性。 |
| [^25] | [Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods.](http://arxiv.org/abs/2305.12283) | 本文提出一种基于非参数方法的无分布模型无偏回归校准方法，具有计算效率和统计一致性，并建立了校准误差的上限和下限的统计保证和优势。 |
| [^26] | [On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training.](http://arxiv.org/abs/2305.12224) | 本文研究了监督预训练数据集中类内多样性和类间多样性之间的权衡对下游任务表现的影响，并理论上证明了下游性能单调地取决于这两种多样性。最佳的类别样本比（#类别 / #每类样本数）与预训练数据集大小无关，可以应用于预测最佳的预训练类别数。 |
| [^27] | [Normalizing flow sampling with Langevin dynamics in the latent space.](http://arxiv.org/abs/2305.12149) | 本文提出了一种在潜在空间中使用 Langevin 动力学的采样方法，以克服归一化流可能面临的复杂分布问题，并能够轻松地融入任何 NF 结构中。 |
| [^28] | [Stability, Generalization and Privacy: Precise Analysis for Random and NTK Features.](http://arxiv.org/abs/2305.12100) | 本论文研究了ERM训练模型对抗强大黑盒攻击的安全问题，并通过两个指标量化模型安全性：单个样本的稳定性和查询与原始数据特征的对齐。在研究中，通过研究RF和NTK回归，证明随着泛化能力的提高，隐私保护可以得到加强。 |
| [^29] | [Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent.](http://arxiv.org/abs/2305.12056) | 本文通过建立学习理论和应用概率之间的联系，提出了一种证明随机优化算法Wasserstein稳定性界限的统一指南，并在随机梯度下降上验证了该方法的有效性，包括强凸损失和带添加噪声的非凸损失。 |
| [^30] | [Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees.](http://arxiv.org/abs/2305.11997) | 本文提出了一种可靠的神经网络反事实解释方法，该方法可以针对自然发生的模型变化提供高概率的鲁棒性。 |
| [^31] | [Sequential Memory with Temporal Predictive Coding.](http://arxiv.org/abs/2305.11982) | 该论文提出了一种基于PC的新型时序记忆模型，称为时间预测编码（tPC），可以通过生物可行的神经实现准确地记忆和检索连续输入。其中tPC可以被看作是一种经典异向性霍普菲尔德网络（AHN），具有更稳定的性能，并且可以编码上下文相关信息，区分在序列中出现的重复元素。 |
| [^32] | [Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization.](http://arxiv.org/abs/2305.11965) | 本文提出了一种具有个性化温度的对比损失用于自监督学习，根据数据分布自动调整温度以使得训练更加有效。 |
| [^33] | [Sequential Best-Arm Identification with Application to Brain-Computer Interface.](http://arxiv.org/abs/2305.11908) | 本论文提出了一种序列最优臂识别方法，应用于脑-机接口中的拼写系统。利用预训练的大型语言模型，可以更快地进行学习并提高信息传输速率。 |
| [^34] | [Discounted Thompson Sampling for Non-Stationary Bandit Problems.](http://arxiv.org/abs/2305.10718) | 该论文提出了一种针对非稳态多臂赌博机问题的折扣汤普森抽样算法（DS-TS），可以解决突然性变化和平滑性变化的问题，并且在两种情况下具有近乎最优的遗憾上限。 |
| [^35] | [Tensor Products and Hyperdimensional Computing.](http://arxiv.org/abs/2305.10572) | 本文探索了张量积在超维计算中的数学关系，将其确定为中心表示，并发现它是最通用、最具表现力和最压缩的表示，同时具有无误差解绑和检测的能力。 |
| [^36] | [Functional Diffusion Maps.](http://arxiv.org/abs/2304.14378) | 本研究关注一种非线性流形学习方法：扩散映射。本文阐述如何将这种方法应用于功能数据，并将其与功能主成分分析进行比较。 |
| [^37] | [Interpretable Neural-Symbolic Concept Reasoning.](http://arxiv.org/abs/2304.14068) | 本文提出了第一个基于概念嵌入的可解释概念模型DCR，能够在多个数据集上实现接近最先进的准确性，相对于最先进的可解释概念模型提高了高达+25％，并产生能够解释其预测的人类可理解规则和真值度，适应性强。 |
| [^38] | [Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance.](http://arxiv.org/abs/2304.10025) | 本文针对治疗不服从性提出了一种半参数框架来评估因果中介效应，提出了一组假设来识别自然中介效应并推导出成倍稳健估计器。 |
| [^39] | [Improved Sample Complexity Bounds for Distributionally Robust Reinforcement Learning.](http://arxiv.org/abs/2303.02783) | 本文改进了分布式鲁棒强化学习的样本复杂度界限，提出了稳健分阶段价值学习（RPVL）算法来解决表格剧情学习环境下的不确定性问题。 |
| [^40] | [Gibbsian polar slice sampling.](http://arxiv.org/abs/2302.03945) | 本文提出了一种基于Gibbs算法的极坐标切片采样方法，该方法通过更新方向和半径分量实现采样过程，且在实验中表现优越。 |
| [^41] | [Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both Worlds in Stochastic and Deterministic Environments.](http://arxiv.org/abs/2301.13446) | 本研究将马尔可夫决策过程的方差相关遗憾界限应用到强化学习中，提出了两个新的环境规范来表征环境的方差属性，并设计出基于模型和无模型的算法，对于随机和确定性环境同时极小极大最优的界限是第一次被证明出来的。 |
| [^42] | [Sampling-based Nystr\"om Approximation and Kernel Quadrature.](http://arxiv.org/abs/2301.09517) | 本文提出了一种基于抽样的Nyström逼近方法用于核积分。同时，引入了一种非i.i.d.地标点的理论保证方法，使得提高了逼近的精度。 |
| [^43] | [Variance reduced Shapley value estimation for trustworthy data valuation.](http://arxiv.org/abs/2210.16835) | 本文提出了一种名为VRDS的分层抽样方法，用于评估数据价值，以缩小排列抽样方法的估计方差，并在不同类型的数据集和数据删除应用程序中得到验证。 |
| [^44] | [FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels.](http://arxiv.org/abs/2210.04635) | 本论文提出了一种使用具有有限支持的一般参数核进行TPP推理的高效解决方案，该方法采用了离散化方法，并通过多项实验证明了该方法的统计和计算效率。 |
| [^45] | [The Curse of Unrolling: Rate of Differentiating Through Optimization.](http://arxiv.org/abs/2209.13271) | 优化问题中的展开求导是机器学习中的一个重要问题，本文对其在梯度下降和 Chebyshev 方法中的二次目标提供了非渐进收敛速率分析，发现我们要确保雅可比矩阵的收敛，就必须面临展开求导的诅咒，即要么选择大的学习率导致快速渐进收敛但算法有较长的初始阶段，要么选择较小的学习率导致即时但较慢的收敛。 |
| [^46] | [Detection of Interacting Variables for Generalized Linear Models via Neural Networks.](http://arxiv.org/abs/2209.08030) | 本文提出了一种使用神经网络和模型特定交互检测方法来自动化寻找GLMs中应添加的交互作用以提高其预测能力的方法。 |
| [^47] | [The Mori-Zwanzig formulation of deep learning.](http://arxiv.org/abs/2209.05544) | 本文提出了基于莫里-茨旺齐格形式主义的深度学习新表述，引入了神经网络记忆的新概念，并通过线性算子方程直接向前和向后传播感兴趣的量。收缩映射理论被用来开发记忆衰减随网络层数增加的充分条件。 |
| [^48] | [Topological Deep Learning: Going Beyond Graph Data.](http://arxiv.org/abs/2206.00606) | 本文提出了一个拓扑深度学习的框架，其中包含组合复合体这一新型拓扑域。组合复合体结合了超图和胞腔复合体的优点，允许构建分层高阶关系。 |
| [^49] | [SepIt: Approaching a Single Channel Speech Separation Bound.](http://arxiv.org/abs/2205.11801) | 该论文提出了一种接近单通道语音分离界限的方法SepIt，在实验中表现优于最先进的神经网络方法，尤其是在5个和10个说话人的情况下仍有提高空间。 |
| [^50] | [Memorization and Optimization in Deep Neural Networks with Minimum Over-parameterization.](http://arxiv.org/abs/2205.10217) | 本文提供了一个最小超参数化的深度神经网络中最小的NTK特征值的下界，具有次线性层宽的深层神经网络是强大的记忆器和优化器，只要参数数量超过样本数量。 |
| [^51] | [Graph Attention Retrospective.](http://arxiv.org/abs/2202.13060) | 图注意力网络是一种能够从邻居节点的特征中聚合信息的模型，通过对上下文随机块模型的节点分类问题进行研究，证明了在“易”区间内，它能够区分跨类和内类边缘并维护重要边缘的权重。 |
| [^52] | [Adaptive and Robust Multi-Task Learning.](http://arxiv.org/abs/2202.05250) | 本文提出一系列自适应方法，能够同时处理多任务学习的相似性和差异性，并具有统计保证和鲁棒性。 |
| [^53] | [Deep Discriminative to Kernel Generative Networks for Calibrated Inference.](http://arxiv.org/abs/2201.13001) | 该论文提出了将判别网络转换为生成网络的方法，用高斯核替换多面体中的仿射函数来生成模型，解决了内部和外部数据校准问题，并在 CIFAR-10，CIFAR-100 和 SVHN 等基准数据集上测试了方法的有效性。 |
| [^54] | [A Robust and Flexible EM Algorithm for Mixtures of Elliptical Distributions with Missing Data.](http://arxiv.org/abs/2201.12020) | 本研究提出了一种鲁棒且灵活的EM算法，用于处理缺失数据的混合椭圆分布，解决了非高斯数据插补的问题。 |
| [^55] | [Barycentric-alignment and reconstruction loss minimization for domain generalization.](http://arxiv.org/abs/2109.01902) | 本论文提出了一个新的理论上界，它不包含双重依赖性的术语，在领域归纳中优化了未见域的风险上界。 |
| [^56] | [Identifiability of interaction kernels in mean-field equations of interacting particles.](http://arxiv.org/abs/2106.05565) | 本研究探索了相互作用微粒平均场方程中相互作用核的可辨识性问题，并确定了二次损失函数仅在特定的函数空间中才具有唯一的最小化器。此外，对于计算实践，研究证明了反问题的病态性质，需要进行正则化处理。 |
| [^57] | [The Theory Behind Overfitting, Cross Validation, Regularization, Bagging, and Boosting: Tutorial.](http://arxiv.org/abs/1905.12787) | 该论文介绍了过拟合、交叉验证、正则化、装袋法和提升法的相关理论，包括定义和具体实现，并给出了AdaBoost的泛化误差上限的具体计算方法。 |
| [^58] | [Eigenvalue and Generalized Eigenvalue Problems: Tutorial.](http://arxiv.org/abs/1903.11240) | 本文是一篇阐述特征值和广义特征值问题的教程。特征值和广义特征值问题可用于各种机器学习算法中，如主成分分析和Fisher判别分析等。 |
| [^59] | [Recovery Bounds on Class-Based Optimal Transport: A Sum-of-Norms Regularization Framework.](http://arxiv.org/abs/1903.03850) | 该论文提出了一个基于范数求和正则化项的凸性最优传输程序，在几何假设条件下可证明恢复基础类结构。该论文还提供了一种加速的近端算法，并提出了一种新的唯一性优化方式。实验表明，新的正则化程序不仅可以更好地保留数据中的类结构，还可以在数据几何形状方面提供额外的鲁棒性。 |

# 详细

[^1]: MAGDiff: 利用深度神经网络激活图检测协变数据集转移

    MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks. (arXiv:2305.13271v1 [stat.ML])

    [http://arxiv.org/abs/2305.13271](http://arxiv.org/abs/2305.13271)

    MAGDiff是一种新的表示法，可以从神经网络分类器中提取，可以有效地检测协变数据集转移，而不需要训练新模型。这可以通过对比神经网络激活图来计算，并通过两个样本 Kolmogorov-Smirnov 测试进行实证验证。

    

    尽管神经网络被广泛应用于各种任务，但像其他机器学习方法一样，它们受到数据转移的影响，在训练数据与实际应用数据之间分布存在差异时，其性能会受到严重影响。本文提出了一种称为 MAGDiff 的新表示方法，可以从任何给定的神经网络分类器中提取出来，并且可以有效地检测协变数据集转移，而不需要训练专门用于此任务的新模型。这些表示形式是通过比较神经网络激活图来计算的，对于属于训练分布和目标分布的样本，提供了强大的数据和任务自适应统计量，用于检测常用的数据集转移的两个样本测试。我们通过测量两个样本 Kolmogorov-Smirnov（KS）测试的统计功率进行了实证验证。

    Despite their successful application to a variety of tasks, neural networks remain limited, like other machine learning methods, by their sensitivity to shifts in the data: their performance can be severely impacted by differences in distribution between the data on which they were trained and that on which they are deployed. In this article, we propose a new family of representations, called MAGDiff, that we extract from any given neural network classifier and that allows for efficient covariate data shift detection without the need to train a new model dedicated to this task. These representations are computed by comparing the activation graphs of the neural network for samples belonging to the training distribution and to the target distribution, and yield powerful data- and task-adapted statistics for the two-sample tests commonly used for data set shift detection. We demonstrate this empirically by measuring the statistical powers of two-sample Kolmogorov-Smirnov (KS) tests on sev
    
[^2]: 基于神经网络的贝叶斯数值积分方法

    Bayesian Numerical Integration with Neural Networks. (arXiv:2305.13248v1 [stat.ML])

    [http://arxiv.org/abs/2305.13248](http://arxiv.org/abs/2305.13248)

    本文提出了一种基于神经网络架构的贝叶斯数值积分方法，称为贝叶斯 Stein 神经网络。该方法可高效地编码积分先验信息并计算积分估计的不确定性。在实际问题中，该方法展现出数量级的加速的优势。

    

    贝叶斯概率数值方法对于数值积分具有显著优势：可以编码积分的先验信息，可以量化积分估计的不确定性。但是，这类方法中最流行的贝叶斯积分算法（Bayesian Quadrature）基于高斯过程模型，因此计算成本很高。为了提高可扩展性，我们提出了一种基于贝叶斯神经网络的替代方法，称为贝叶斯 Stein 神经网络。关键成分是基于 Stein 算子的神经网络结构，以及基于 Laplace 近似的贝叶斯后验的近似。我们展示了这导致了在流行的 Genz 函数基准测试和在贝叶斯动力系统分析以及大规模风力发电预测中规模的数量级加速。

    Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm.
    
[^3]: 通过等压等温流获得吉布斯自由能

    Gibbs free energies via isobaric-isothermal flows. (arXiv:2305.13233v1 [physics.comp-ph])

    [http://arxiv.org/abs/2305.13233](http://arxiv.org/abs/2305.13233)

    采用机器学习模型利用等压等温流得到吉布斯自由能，并在单原子水的结晶中进行了测试，表现出优秀的性能。

    

    我们提出了一种基于归一化流的机器学习模型，该模型经过训练可从等压等温（NPT）集合中进行采样。在我们的方法中，我们采用近似方法来得到完全灵活的三斜晶系统的联合分布和粒子坐标以达到所需的内部压力。我们对单原子水在立方和六角冰相中进行测试，并发现与已建立的基线相比，吉布斯自由能和其他可观测量的结果完全一致。

    We present a machine-learning model based on normalizing flows that is trained to sample from the isobaric-isothermal (NPT) ensemble. In our approach, we approximate the joint distribution of a fully-flexible triclinic simulation box and particle coordinates to achieve a desired internal pressure. We test our model on monatomic water in the cubic and hexagonal ice phases and find excellent agreement of Gibbs free energies and other observables compared with established baselines.
    
[^4]: 通过二阶方法实现更快的差分隐私凸优化

    Faster Differentially Private Convex Optimization via Second-Order Methods. (arXiv:2305.13209v1 [cs.LG])

    [http://arxiv.org/abs/2305.13209](http://arxiv.org/abs/2305.13209)

    本文研究使用二阶信息加速差分隐私凸优化，在强凸损失函数类中提出了一种具有二次收敛速度和最优超额损失的算法。

    

    差分隐私随机梯度下降是差分隐私机器学习的主要方法，在凸和非凸的情况下均可使用。如果没有隐私约束，像牛顿法这样的二阶方法比梯度下降这样的一阶方法更快地收敛。本文研究使用损失函数的二阶信息加速差分隐私凸优化的可能性。我们首先使用Nesterov和Polyak的正则化三次牛顿法开发了一种私有方法，并证明对于强凸损失函数类，我们的算法具有二次收敛速度，并实现了最优的超额损失。然后，我们为无约束逻辑回归问题设计了一个实用的二阶差分隐私算法。我们从理论和实证两方面研究了我们算法的性能，实证结果显示，与其他基线比较，我们的算法始终实现了最佳超额损失，比DP-GD/DP-SGD快10-40倍。

    Differentially private (stochastic) gradient descent is the workhorse of DP private machine learning in both the convex and non-convex settings. Without privacy constraints, second-order methods, like Newton's method, converge faster than first-order methods like gradient descent. In this work, we investigate the prospect of using the second-order information from the loss function to accelerate DP convex optimization. We first develop a private variant of the regularized cubic Newton method of Nesterov and Polyak, and show that for the class of strongly convex loss functions, our algorithm has quadratic convergence and achieves the optimal excess loss. We then design a practical second-order DP algorithm for the unconstrained logistic regression problem. We theoretically and empirically study the performance of our algorithm. Empirical results show our algorithm consistently achieves the best excess loss compared to other baselines and is 10-40x faster than DP-GD/DP-SGD.
    
[^5]: SignSVRG: 通过方差缩减修正SignSGD

    SignSVRG: fixing SignSGD via variance reduction. (arXiv:2305.13187v1 [math.OC])

    [http://arxiv.org/abs/2305.13187](http://arxiv.org/abs/2305.13187)

    本文介绍了一种简单但实用的方法，将方差缩减技术纳入到SignSGD中，并保证了类似完整符号梯度下降的收敛性。

    

    本文考虑了无约束函数的有限和最小化问题。我们提出了一种简单但实用的方法，将方差缩减技术纳入到SignSGD中，并保证了类似完整符号梯度下降的收敛性。该核心思想首先应用于凸和Lipschitz函数和的最小化问题，然后通过方差缩减扩展到平滑情况。我们的分析很基础，比典型的方差缩减方法的证明简单得多。我们表明，对于平滑函数，我们的方法给出了期望梯度范数的$ \mathcal {O}（1 / \ sqrt {T}）$收敛速度，并且对于平滑凸函数的情况，收敛速度为$ \mathcal {O}（1 / T）$，恢复了确定性方法的收敛结果，同时保留了SignSGD的计算优势。

    We consider the problem of unconstrained minimization of finite sums of functions. We propose a simple, yet, practical way to incorporate variance reduction techniques into SignSGD, guaranteeing convergence that is similar to the full sign gradient descent. The core idea is first instantiated on the problem of minimizing sums of convex and Lipschitz functions and is then extended to the smooth case via variance reduction. Our analysis is elementary and much simpler than the typical proof for variance reduction methods. We show that for smooth functions our method gives $\mathcal{O}(1 / \sqrt{T})$ rate for expected norm of the gradient and $\mathcal{O}(1/T)$ rate in the case of smooth convex functions, recovering convergence results of deterministic methods, while preserving computational advantages of SignSGD.
    
[^6]: 深度神经网络的全局最优解可证为深度神经坍塌模型

    Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained Features Model. (arXiv:2305.13165v1 [cs.LG])

    [http://arxiv.org/abs/2305.13165](http://arxiv.org/abs/2305.13165)

    本文研究了深度神经坍塌现象（Deep Neural Collapse），证明了在深度无约束特征模型中，唯一的全局最优解表现出了DNC的特征，并且通过选择合适的超参数，仅对模型的最后一层进行训练可以在不损失精度的情况下加快收敛。

    

    神经坍塌(NC)指的是深度神经网络在梯度下降训练的末期最后一层的惊奇结构。最近有越来越多的实验证据表明NC向神经网络的较早层传播。然而，尽管最后一层中的NC在理论上已经研究得很好，但对于其多层级的对应物-深度神经坍塌(DNC)却知之甚少。特别地，现有的工作基于线性层或仅涉及最后两层，但代价却是一个额外的假设。本文通过将基于无约束特征模型的已建立分析框架推广到多个非线性层级，弥补了这一差距。我们的关键技术贡献在于证明，在深度无约束特征模型中，用于二元分类的唯一全局最优解表现出了DNC的所有典型特征。这解释了现有关于DNC的实验证据。我们的实验也证明，通过选择合适的超参数，仅对模型的最后一层进行训练可以在不损失精度的情况下加快收敛。

    Neural collapse (NC) refers to the surprising structure of the last layer of deep neural networks in the terminal phase of gradient descent training. Recently, an increasing amount of experimental evidence has pointed to the propagation of NC to earlier layers of neural networks. However, while the NC in the last layer is well studied theoretically, much less is known about its multi-layered counterpart - deep neural collapse (DNC). In particular, existing work focuses either on linear layers or only on the last two layers at the price of an extra assumption. Our paper fills this gap by generalizing the established analytical framework for NC - the unconstrained features model - to multiple non-linear layers. Our key technical contribution is to show that, in a deep unconstrained features model, the unique global optimum for binary classification exhibits all the properties typical of DNC. This explains the existing experimental evidence of DNC. We also empirically show that (i) by opt
    
[^7]: 梯度下降单调递减了标量网络和其他模型中的梯度流解的尖锐度。

    Gradient Descent Monotonically Decreases the Sharpness of Gradient Flow Solutions in Scalar Networks and Beyond. (arXiv:2305.13064v1 [cs.LG])

    [http://arxiv.org/abs/2305.13064](http://arxiv.org/abs/2305.13064)

    对于标量网络和其他模型，研究表明梯度下降会单调递减梯度流解的尖锐度。

    

    最近的研究表明，当将梯度下降（GD）应用于神经网络时，损失几乎不会单调递减。相反，损失会在梯度下降收敛到其“稳定边缘”（EoS）时振荡。在这里，我们发现一种在GD训练过程中单调递减的量：梯度流解（GFS）所达到的尖锐度 - 如果从现在开始到收敛，我们使用无穷小的步长进行训练所获得的解决方案。在理论上，我们使用平方损失分析标量神经网络，这可能是EoS现象仍然发生的最简单的情况。在这个模型中，我们证明了GFS尖锐度单调递减。使用这个结果，我们描述了GD在标量网络中可以被证明收敛到EoS的设置。在实验上，我们展示了GD在平方回归模型以及实际神经网络架构中单调递减了GFS的尖锐度。

    Recent research shows that when Gradient Descent (GD) is applied to neural networks, the loss almost never decreases monotonically. Instead, the loss oscillates as gradient descent converges to its ''Edge of Stability'' (EoS). Here, we find a quantity that does decrease monotonically throughout GD training: the sharpness attained by the gradient flow solution (GFS)-the solution that would be obtained if, from now until convergence, we train with an infinitesimal step size. Theoretically, we analyze scalar neural networks with the squared loss, perhaps the simplest setting where the EoS phenomena still occur. In this model, we prove that the GFS sharpness decreases monotonically. Using this result, we characterize settings where GD provably converges to the EoS in scalar networks. Empirically, we show that GD monotonically decreases the GFS sharpness in a squared regression model as well as practical neural network architectures.
    
[^8]: 一种具有多层数据和节点属性整合的网络社区检测方法

    A network community detection method with integration of data from multiple layers and node attributes. (arXiv:2305.13012v1 [physics.soc-ph])

    [http://arxiv.org/abs/2305.13012](http://arxiv.org/abs/2305.13012)

    该论文介绍了一种利用多层数据和节点属性整合的网络社区检测方法，并提出将网络数据表示为数据矩阵的简单方式。该方法可根据分析目标选择数据矩阵，并使用一种压缩数据矩阵的方法将其行分成社区，从而进行强大的分析。

    

    多层网络是当前复杂网络研究的热点。在这样的网络中，可能存在多种类型的链接以及许多节点属性。为了充分利用多层和其他类型的复杂网络应用，将各种数据与拓扑信息相结合，可以进行强大的分析。我们首先提出一种简单的方式，将网络数据表示为数据矩阵，其中行对应节点，列对应数据项。列数可以任意选择，因此可以通过添加列轻松扩展数据矩阵。数据矩阵可以根据分析目标选择，并且在不同情况下可能会有很大不同。接下来，我们使用一种允许数据矩阵最大压缩的方法将数据矩阵的行分成社区。为了压缩数据矩阵，我们建议扩展所谓的非方阵的常规分解方法。我们为几种具体情况说明了我们的方法。

    Multilayer networks are in the focus of the current complex network study. In such networks multiple types of links may exist as well as many attributes for nodes. To fully use multilayer -- and other types of complex networks in applications, the merging of various data with topological information renders a powerful analysis. First, we suggest a simple way of representing network data in a data matrix where rows correspond to the nodes, and columns correspond to the data items. The number of columns is allowed to be arbitrary, so that the data matrix can be easily expanded by adding columns. The data matrix can be chosen according to targets of the analysis, and may vary a lot from case to case. Next, we partition the rows of the data matrix into communities using a method which allows maximal compression of the data matrix. For compressing a data matrix, we suggest to extend so called regular decomposition method for non-square matrices. We illustrate our method for several types of
    
[^9]: funLOCI: 一种针对功能数据的本地聚类算法

    funLOCI: a local clustering algorithm for functional data. (arXiv:2305.12991v1 [stat.ME])

    [http://arxiv.org/abs/2305.12991](http://arxiv.org/abs/2305.12991)

    funLOCI是一种三步分裂式分层聚类算法，可以针对功能数据找出本地聚类，通过借鉴多元和功能聚类的思想，采用加法模型考虑曲线的形状，可使用树状图可视化和指导搜索过程，并实现了额外的步骤将结果数量降至最小。

    

    如今，越来越多的问题涉及到具有一个无限连续维度的数据：功能数据。在本文中，我们介绍了 funLOCI 算法，它允许识别功能本地聚类或功能基因座，即表现出相似行为的函数子集/组在相同区间内的连续子集中。功能本地聚类的定义借鉴了多元和功能聚类以及双聚类的思想，并基于一个加法模型，考虑了曲线的形状。funLOCI 是一个基于分裂式分层聚类的三步算法。使用树状图可以可视化和指导搜索过程以及切割阈值的选择。为了处理大量的本地聚类，实现了额外的步骤以将结果数量降至最小。

    Nowadays, more and more problems are dealing with data with one infinite continuous dimension: functional data. In this paper, we introduce the funLOCI algorithm which allows to identify functional local clusters or functional loci, i.e., subsets/groups of functions exhibiting similar behaviour across the same continuous subset of the domain. The definition of functional local clusters leverages ideas from multivariate and functional clustering and biclustering and it is based on an additive model which takes into account the shape of the curves. funLOCI is a three-step algorithm based on divisive hierarchical clustering. The use of dendrograms allows to visualize and to guide the searching procedure and the cutting thresholds selection. To deal with the large quantity of local clusters, an extra step is implemented to reduce the number of results to the minimum.
    
[^10]: 基于一般回归误差假设来研究无噪声回归最小二乘估计值的均方误差

    The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors. (arXiv:2305.12883v1 [math.ST])

    [http://arxiv.org/abs/2305.12883](http://arxiv.org/abs/2305.12883)

    该论文研究了基于一般回归误差假设的无噪声回归最小二乘估计值的均方误差，并发现包含大量不重要的参数可以有效地降低估计器的均方误差。

    

    近年来，最小$\ell_2$范数（无岭）插值最小二乘估计器的研究方兴未艾。然而，大多数分析都局限于简单的回归误差结构，假设误差是独立同分布的，具有零均值和相同的方差，与特征向量无关。此外，这些理论分析的主要重点是样本外预测风险。本文通过检查无岭插值最小二乘估计器的均方误差，允许更一般的回归误差假设，打破了现有文献的局限性。具体而言，我们研究过度参数化的潜在好处，通过描绘有限样本中的均方误差来表征均方误差。我们的研究结果表明，相对于样本量，包含大量不重要的参数可以有效地降低估计器的均方误差。

    In recent years, there has been a significant growth in research focusing on minimum $\ell_2$ norm (ridgeless) interpolation least squares estimators. However, the majority of these analyses have been limited to a simple regression error structure, assuming independent and identically distributed errors with zero mean and common variance, independent of the feature vectors. Additionally, the main focus of these theoretical analyses has been on the out-of-sample prediction risk. This paper breaks away from the existing literature by examining the mean squared error of the ridgeless interpolation least squares estimator, allowing for more general assumptions about the regression errors. Specifically, we investigate the potential benefits of overparameterization by characterizing the mean squared error in a finite sample. Our findings reveal that including a large number of unimportant parameters relative to the sample size can effectively reduce the mean squared error of the estimator. N
    
[^11]: 通过重新标记最小训练子集来翻转预测

    Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])

    [http://arxiv.org/abs/2305.12809](http://arxiv.org/abs/2305.12809)

    本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。

    

    Yang等人发现，仅删除1%的训练数据就可能导致预测结果翻转。鉴于机器学习模型中存在噪声数据的普遍性，本文提出了一个问题：在模型训练之前通过重新标记一个小的训练数据子集可否导致测试结果翻转？本文利用扩展影响函数提出了一种有效的识别和重新标记这种子集的方法，并证明了其始终能够产生成功的结果。这种机制有多重作用：（1）提供了一种补充方法，可以通过恢复可能错误标记的训练数据来挑战模型预测；（2）评估模型的鲁棒性，因为本文发现子集的大小与训练集中噪声数据的比例之间存在显著关系；（3）提供了洞察训练集偏差的见解。据我们所知，这项工作代表了对识别最小训练子集问题的第一次研究。

    Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
    
[^12]: 半监督因果推断：面向衰减重叠的选择偏差下可泛化的双稳估计平均处理效应

    Semi-Supervised Causal Inference: Generalizable and Double Robust Inference for Average Treatment Effects under Selection Bias with Decaying Overlap. (arXiv:2305.12789v1 [stat.ME])

    [http://arxiv.org/abs/2305.12789](http://arxiv.org/abs/2305.12789)

    本论文提出了一种新的针对高维情况下缺失标签且存在选择偏差的平均处理效应估计方法，它具有良好的一致性和渐近正态性。

    

    平均处理效应（ATE）估计是因果推断文献中的一个重要问题，尤其是在高维混淆变量的情况下受到了极大的关注。本文中，我们考虑了在高维情况下存在可能缺失的标签情况下的ATE估计问题。标记指示符的条件倾向得分允许依赖于协变量，并且随着样本大小的衰减而衰减——从而允许未标记数据大小比标记数据大小增长得更快。这种情况填补了半监督（SS）和缺失数据文献中的重要空白。我们考虑了允许选择偏差的随机缺失（MAR）机制——这通常在标准的SS文献中是禁止的，并且在缺失数据文献中通常需要一个正性条件。我们首先提出了一种针对ATE的一般双稳DR-DMAR（decaying）SS估计器，这种估计器具有良好的一致性和渐近正态性。

    Average treatment effect (ATE) estimation is an essential problem in the causal inference literature, which has received significant recent attention, especially with the presence of high-dimensional confounders. We consider the ATE estimation problem in high dimensions when the observed outcome (or label) itself is possibly missing. The labeling indicator's conditional propensity score is allowed to depend on the covariates, and also decay uniformly with sample size - thus allowing for the unlabeled data size to grow faster than the labeled data size. Such a setting fills in an important gap in both the semi-supervised (SS) and missing data literatures. We consider a missing at random (MAR) mechanism that allows selection bias - this is typically forbidden in the standard SS literature, and without a positivity condition - this is typically required in the missing data literature. We first propose a general doubly robust 'decaying' MAR (DR-DMAR) SS estimator for the ATE, which is cons
    
[^13]: 不变风险最小化的一致推断

    Conformal Inference for Invariant Risk Minimization. (arXiv:2305.12686v1 [stat.ML])

    [http://arxiv.org/abs/2305.12686](http://arxiv.org/abs/2305.12686)

    本文研究了非分布预测区域的构造，以描述不同环境下数据的分布偏移的不确定性估计。该方法利用一种适应特定环境的加权一致性分数构建自适应的一致区间，并证明其条件平均值。

    

    机器学习模型的应用可能会受到分布偏移的严重影响，因为机器学习和统计中对训练和测试样本群体同质性的假设可能在实际情况中并不可行。解决这个问题的一种方式是使用不变学习，例如不变风险最小化（IRM），以获得一种不变表示，有助于在分布偏移情况下的泛化。本文开发了一种方法，用于获得无分布预测区域，以描述数据来自不同环境的分布偏移的不变表示的不确定性估计。我们的方法涉及一种适应特定环境的加权一致性分数，利用加权一致性分数构建自适应一致区间，并在一定条件下证明其条件平均值。为了展示本方法的有效性

    The application of machine learning models can be significantly impeded by the occurrence of distributional shifts, as the assumption of homogeneity between the population of training and testing samples in machine learning and statistics may not be feasible in practical situations. One way to tackle this problem is to use invariant learning, such as invariant risk minimization (IRM), to acquire an invariant representation that aids in generalization with distributional shifts. This paper develops methods for obtaining distribution-free prediction regions to describe uncertainty estimates for invariant representations, accounting for the distribution shifts of data from different environments. Our approach involves a weighted conformity score that adapts to the specific environment in which the test sample is situated. We construct an adaptive conformal interval using the weighted conformity score and prove its conditional average under certain conditions. To demonstrate the effectiven
    
[^14]: 带有附加覆盖分布的离线强化学习

    Offline Reinforcement Learning with Additional Covering Distributions. (arXiv:2305.12679v1 [cs.LG])

    [http://arxiv.org/abs/2305.12679](http://arxiv.org/abs/2305.12679)

    本文提出了一种离线强化学习算法，它在只有部分覆盖数据集和弱可实现函数类的情况下，利用覆盖分布的附加侧信息实现了样本有效离线RL，并展示了覆盖分布在先验知识和所需附加数据量之间进行权衡来获得更好的学习效果。

    

    本文研究了如何使用函数逼近从日志数据集中学习最优策略，即离线强化学习。尽管已经付出了很多努力，在具有理论有限样本保证的现有算法中，通常假设具有探索性数据覆盖或强可实现的函数类，这在现实中很难满足。虽然最近有一些成功解决这些强假设的作品，但它们要么需要只能由一部分MDP满足的间隙假设，要么使用行为正则化，使得学习策略的最优性变得不可行。为了解决这一挑战，我们提供了基于边际重要性抽样(MIS)的简单算法的样本有限保证，证明了在给定覆盖分布的附加侧信息下仅具有部分覆盖数据集和弱可实现函数类的情况下，通用MDP的样本有效离线RL是可能的。此外，我们证明了覆盖分布在先验知识和所需附加数据量之间进行权衡，同时展示了它能够有益于学习的情况。

    We study learning optimal policies from a logged dataset, i.e., offline RL, with function approximation. Despite the efforts devoted, existing algorithms with theoretic finite-sample guarantees typically assume exploratory data coverage or strong realizable function classes, which is hard to be satisfied in reality. While there are recent works that successfully tackle these strong assumptions, they either require the gap assumptions that only could be satisfied by part of MDPs or use the behavior regularization that makes the optimality of learned policy even intractable. To solve this challenge, we provide finite-sample guarantees for a simple algorithm based on marginalized importance sampling (MIS), showing that sample-efficient offline RL for general MDPs is possible with only a partial coverage dataset and weak realizable function classes given additional side information of a covering distribution. Furthermore, we demonstrate that the covering distribution trades off prior knowl
    
[^15]: 非Markovian世界中的有限资源分配：母婴保健的情况

    Limited Resource Allocation in a Non-Markovian World: The Case of Maternal and Child Healthcare. (arXiv:2305.12640v1 [cs.AI])

    [http://arxiv.org/abs/2305.12640](http://arxiv.org/abs/2305.12640)

    研究中提出了一种新颖的算法TSAB，通过建模参与者的轨迹为时间序列，并结合时间序列预测模型来预测未来状态，以适应非Markovian设置。该算法在提高数据依从性和/或参与度的资源分配方面优于过去的方法。

    

    许多医疗保健计划的成功取决于参与者的依从性。我们考虑在资源有限的情况下（例如，从卫生工作者处及时获得支持电话），安排干预措施以增加依从性和/或参与度的问题。过去的研究已经成功地为这个问题开发了几类基于不安定多臂老虎机（RMAB）的解决方案。然而，所有过去的RMAB方法都假设参与者的行为遵循Markov属性。我们展示了来自我们合作NGO ARMMAN的孕妇健康意识计划的真实数据对Markov假设存在显着偏差。此外，我们将RMAB扩展到连续状态空间，这是以前不受重视的领域。为了解决广义的非Markovian RMAB设置，我们（i）将每个参与者轨迹建模为时间序列，（ii）利用时间序列预测模型学习复杂的模式和动态来预测未来状态，（iii）提出Time-series Arm Bandit（TSAB）算法，这是一种新颖的方法，通过捕获过去和未来状态之间的依赖关系来适应非Markovian设置。我们的实验表明，TSAB优于以前的方法，并实现更好的资源分配。

    The success of many healthcare programs depends on participants' adherence. We consider the problem of scheduling interventions in low resource settings (e.g., placing timely support calls from health workers) to increase adherence and/or engagement. Past works have successfully developed several classes of Restless Multi-armed Bandit (RMAB) based solutions for this problem. Nevertheless, all past RMAB approaches assume that the participants' behaviour follows the Markov property. We demonstrate significant deviations from the Markov assumption on real-world data on a maternal health awareness program from our partner NGO, ARMMAN. Moreover, we extend RMABs to continuous state spaces, a previously understudied area. To tackle the generalised non-Markovian RMAB setting we (i) model each participant's trajectory as a time-series, (ii) leverage the power of time-series forecasting models to learn complex patterns and dynamics to predict future states, and (iii) propose the Time-series Arm 
    
[^16]: 带参数分布的数据切片确切后选择推断

    A parametric distribution for exact post-selection inference with data carving. (arXiv:2305.12581v1 [stat.ME])

    [http://arxiv.org/abs/2305.12581](http://arxiv.org/abs/2305.12581)

    本文提出了一种基于已知的参数分布用于数据切片的确切后选择推断方法，从而避免了计算昂贵的MCMC方法的使用。

    

    后选择推断（PoSI）是一种统计技术，用于在假设生成和测试使用相同的数据来源时获取有效的置信区间和p值。 PoSI可用于一系列流行的算法，包括Lasso。 数据切片是PoSI的变体，在推断时间将部分保留数据与假设生成数据结合使用。虽然数据切片具有有吸引力的理论和实证性质，但现有方法依赖于计算昂贵的MCMC方法来执行推断。本文的关键贡献在于展示可基于已知的参数分布构建数据切片过程的枢轴量。具体而言，在高斯响应的一组多面体约束下，数据切片将遵循正常值和截断正常值之和（SNTN），这是截断双变量正态分布的一个变体。这种洞察力的主要影响是使数据切片的有效和确切的后选择推断成为可能，而无需采用计算密集型的MCMC方法。

    Post-selection inference (PoSI) is a statistical technique for obtaining valid confidence intervals and p-values when hypothesis generation and testing use the same source of data. PoSI can be used on a range of popular algorithms including the Lasso. Data carving is a variant of PoSI in which a portion of held out data is combined with the hypothesis generating data at inference time. While data carving has attractive theoretical and empirical properties, existing approaches rely on computationally expensive MCMC methods to carry out inference. This paper's key contribution is to show that pivotal quantities can be constructed for the data carving procedure based on a known parametric distribution. Specifically, when the selection event is characterized by a set of polyhedral constraints on a Gaussian response, data carving will follow the sum of a normal and a truncated normal (SNTN), which is a variant of the truncated bivariate normal distribution. The main impact of this insight i
    
[^17]: 有条件生成模型是标记时间点过程的必备工具。

    Conditional Generative Modeling is All You Need for Marked Temporal Point Processes. (arXiv:2305.12569v1 [stat.ML])

    [http://arxiv.org/abs/2305.12569](http://arxiv.org/abs/2305.12569)

    本文提出了一种从标记时间点过程中提取其统计直觉的事件生成模型，通过条件生成器以历史观察作为输入，生成可能发生的高质量随后事件。该模型具有高效、灵活和表示能力等方面的优势。

    

    近年来，生成建模的进步使得从上下文信息中生成高质量内容成为可能，但一个关键问题仍然存在：如何教模型知道何时生成内容？为了回答这个问题，本研究提出了一种新的事件生成模型，从标记时间点过程中提取其统计直觉，并提供了一个干净、灵活和计算效率高的解决方案，适用于涉及多维标记的各种应用。我们旨在捕捉点过程的分布而不需明确指定条件强度或概率密度。我们使用一个条件生成器，以事件历史为输入并生成在先前观察到的事件下，可能发生的高质量随后事件。所提出的框架提供了一系列利益，包括在学习模型和生成样本方面的异常效率以及相当大的表示能力来捕捉。

    Recent advancements in generative modeling have made it possible to generate high-quality content from context information, but a key question remains: how to teach models to know when to generate content? To answer this question, this study proposes a novel event generative model that draws its statistical intuition from marked temporal point processes, and offers a clean, flexible, and computationally efficient solution for a wide range of applications involving multi-dimensional marks. We aim to capture the distribution of the point process without explicitly specifying the conditional intensity or probability density. Instead, we use a conditional generator that takes the history of events as input and generates the high-quality subsequent event that is likely to occur given the prior observations. The proposed framework offers a host of benefits, including exceptional efficiency in learning the model and generating samples, as well as considerable representational power to capture
    
[^18]: 单调学习率 SGD 的限制和自适应方法的威力

    Two Sides of One Coin: the Limits of Untuned SGD and the Power of Adaptive Methods. (arXiv:2305.12475v1 [math.OC])

    [http://arxiv.org/abs/2305.12475](http://arxiv.org/abs/2305.12475)

    本文证明了单调学习率 SGD 的算法依然可以达到渐近最优收敛速度，但是这是以光滑度常数出现灾难性指数级依赖为代价的，因此研究了三种自适应方法来防止这种指数依赖，实现了了准确性和自适应性的平衡。

    

    随机梯度下降（SGD）算法的经典分析依赖于经过细调的多项式衰减步长，而这需要依赖于问题参数，例如李普希茨平滑常数，而在实践中这通常是未知的。在本文中，我们证明了对于任意的 $\eta > 0$ 的单调学习率 SGD（untuned SGD），其依然能够达到渐近最优收敛速度 $ \tilde{O}(T^{-1/4}) $。然而，这是以光滑度常数出现灾难性指数级依赖为代价的，我们证明了即使在无噪声情况下，这种方案也是不可避免的。接着我们研究了三种自适应方法——归一化的 SGD（NSGD），AMSGrad 和 AdaGrad——揭示了它们在防止如此指数依赖存在时的威力。我们的结果提供了理论上的证明，支持了实践中使用这些方法进行无需更多信息的自适应学习的必要性。

    The classical analysis of Stochastic Gradient Descent (SGD) with polynomially decaying stepsize $\eta_t = \eta/\sqrt{t}$ relies on well-tuned $\eta$ depending on problem parameters such as Lipschitz smoothness constant, which is often unknown in practice. In this work, we prove that SGD with arbitrary $\eta > 0$, referred to as untuned SGD, still attains an order-optimal convergence rate $\widetilde{O}(T^{-1/4})$ in terms of gradient norm for minimizing smooth objectives. Unfortunately, it comes at the expense of a catastrophic exponential dependence on the smoothness constant, which we show is unavoidable for this scheme even in the noiseless setting. We then examine three families of adaptive methods $\unicode{x2013}$ Normalized SGD (NSGD), AMSGrad, and AdaGrad $\unicode{x2013}$ unveiling their power in preventing such exponential dependency in the absence of information about the smoothness parameter and boundedness of stochastic gradients. Our results provide theoretical justificat
    
[^19]: 拟随机数蒙特卡罗图随机特征

    Quasi-Monte Carlo Graph Random Features. (arXiv:2305.12470v1 [stat.ML])

    [http://arxiv.org/abs/2305.12470](http://arxiv.org/abs/2305.12470)

    该论文提出了一种名为q-GRFs（拟随机数蒙特卡罗图随机特征）的方法，它通过施加抗生终止的方法诱导算法随机漫步长度之间的负相关性，从而改善了图随机特征的准确性，同时能够适用于任何图形拓扑结构。

    

    我们提出了一种新的机制来改善最近引入的图随机特征（GRFs）类的准确性。我们的方法通过施加抗生终止 - 一种采样更多样化的随机漫步的过程来诱导算法随机漫步长度之间的负相关性。它具有非常简单的实现。我们对这些拟随机数蒙特卡罗图随机特征（q-GRFs）的性质提供了强有力的理论保证，证明它们在温和条件下产生更低方差的2-正则化拉普拉斯核估计。值得注意的是，我们的结果适用于任何图形拓扑结构。我们展示了各种任务的经验准确度改进，包括新的实用应用程序：图扩散过程的时间有效逼近。据我们所知，q-GRFs是第一个对组合对象上定义的核进行严格研究的拟随机数蒙特卡罗方案，从而引发了关于图形的相关性的新研究。

    We present a novel mechanism to improve the accuracy of the recently-introduced class of graph random features (GRFs). Our method induces negative correlations between the lengths of the algorithm's random walks by imposing antithetic termination: a procedure to sample more diverse random walks which may be of independent interest. It has a trivial drop-in implementation. We derive strong theoretical guarantees on the properties of these quasi-Monte Carlo GRFs (q-GRFs), proving that they yield lower-variance estimators of the 2-regularised Laplacian kernel under mild conditions. Remarkably, our results hold for any graph topology. We demonstrate empirical accuracy improvements on a variety of tasks including a new practical application: time-efficient approximation of the graph diffusion process. To our knowledge, q-GRFs constitute the first rigorously studied quasi-Monte Carlo scheme for kernels defined on combinatorial objects, inviting new research on correlations between graph rand
    
[^20]: 异构观测数据下的联邦弱化政策学习

    Federated Offline Policy Learning with Heterogeneous Observational Data. (arXiv:2305.12407v1 [cs.LG])

    [http://arxiv.org/abs/2305.12407](http://arxiv.org/abs/2305.12407)

    本文提出了一种基于异构数据源的联邦政策学习算法，该算法基于本地策略聚合的方法，使用双重稳健线下策略评估和学习策略进行训练，可以在不交换原始数据的情况下学习个性化决策政策。我们建立了全局和局部后悔上限的理论模型，并用实验结果支持了理论发现。

    

    本文考虑了基于异构数据源的观测数据学习个性化决策政策的问题。此外，我们在联邦设置中研究了这个问题，其中中央服务器旨在在分布在异构源上的数据上学习一个政策，而不交换它们的原始数据。我们提出了一个联邦政策学习算法，它基于使用双重稳健线下策略评估和学习策略训练的本地策略聚合的方法。我们提供了一种新的后悔分析方法来确立对全局后悔概念的有限样本上界，这个全局后悔概念跨越了客户端的分布。此外，我们针对每个单独的客户端建立了相应的局部后悔上界，该上界由相对于所有其他客户端的分布变化特征性地描述。我们用实验结果支持我们的理论发现。我们的分析和实验提供了异构客户端参与联邦学习的价值洞察。

    We consider the problem of learning personalized decision policies on observational data from heterogeneous data sources. Moreover, we examine this problem in the federated setting where a central server aims to learn a policy on the data distributed across the heterogeneous sources without exchanging their raw data. We present a federated policy learning algorithm based on aggregation of local policies trained with doubly robust offline policy evaluation and learning strategies. We provide a novel regret analysis for our approach that establishes a finite-sample upper bound on a notion of global regret across a distribution of clients. In addition, for any individual client, we establish a corresponding local regret upper bound characterized by the presence of distribution shift relative to all other clients. We support our theoretical findings with experimental results. Our analysis and experiments provide insights into the value of heterogeneous client participation in federation fo
    
[^21]: 集成学习何时有效？

    When are ensembles really effective?. (arXiv:2305.12313v1 [stat.ML])

    [http://arxiv.org/abs/2305.12313](http://arxiv.org/abs/2305.12313)

    本文研究证明了在分类任务中，当集成模型的错误率较单个模型更低，且模型间不同意的错误率超过平均错误率，则集成学习能够显著提高性能。

    

    集成学习在统计数据分析中具有悠久的历史，并有许多具有影响力的应用。然而，在许多现代机器学习设置中，集成学习的好处不是普遍且不明显。本文从理论和实证两方面研究了集成学习何时在分类任务中能够显著提高性能的基本问题。

    Ensembling has a long history in statistical data analysis, with many impactful applications. However, in many modern machine learning settings, the benefits of ensembling are less ubiquitous and less obvious. We study, both theoretically and empirically, the fundamental question of when ensembling yields significant performance improvements in classification tasks. Theoretically, we prove new results relating the \emph{ensemble improvement rate} (a measure of how much ensembling decreases the error rate versus a single model, on a relative scale) to the \emph{disagreement-error ratio}. We show that ensembling improves performance significantly whenever the disagreement rate is large relative to the average error rate; and that, conversely, one classifier is often enough whenever the disagreement rate is low relative to the average error rate. On the way to proving these results, we derive, under a mild condition called \emph{competence}, improved upper and lower bounds on the average 
    
[^22]: 使用Wasserstein距离对密度地图进行对齐

    Alignment of Density Maps in Wasserstein Distance. (arXiv:2305.12310v1 [eess.IV])

    [http://arxiv.org/abs/2305.12310](http://arxiv.org/abs/2305.12310)

    本文提出了一种使用Wasserstein距离对三维物体进行对齐的算法，并通过贝叶斯优化实现计算。在对齐真实蛋白质分子方面，该算法表现出更好的准确性和效率，并阐明了对新距离函数的需求。

    

    本文提出一种算法，用于将三维物体表示为密度地图并进行对齐，该算法的动机是在冷冻电子显微镜中的应用。该算法基于在刚性变换后密度地图之间最小化1-Wasserstein距离。引入的损失函数比欧几里得距离场具有更好的特性，并使用贝叶斯优化进行计算。数值实验表明，在真实蛋白质分子的对齐方面，该算法的准确性和效率优于现有算法。在对齐异质对的情况下，我们阐明了新距离函数的潜在需求。

    In this paper we propose an algorithm for aligning three-dimensional objects when represented as density maps, motivated by applications in cryogenic electron microscopy. The algorithm is based on minimizing the 1-Wasserstein distance between the density maps after a rigid transformation. The induced loss function enjoys a more benign landscape than its Euclidean counterpart and Bayesian optimization is employed for computation. Numerical experiments show improved accuracy and efficiency over existing algorithms on the alignment of real protein molecules. In the context of aligning heterogeneous pairs, we illustrate a potential need for new distance functions.
    
[^23]: 最优低秩矩阵填补：半定松弛和特征向量分离

    Optimal Low-Rank Matrix Completion: Semidefinite Relaxations and Eigenvector Disjunctions. (arXiv:2305.12292v1 [cs.LG])

    [http://arxiv.org/abs/2305.12292](http://arxiv.org/abs/2305.12292)

    该论文通过重新表述低秩矩阵填补问题为投影矩阵的非凸问题，实现了能够确定最优解的分离分支定界方案，并且通过新颖和紧密的凸松弛方法，使得最优性差距相对于现有方法减少了两个数量级。

    

    低秩矩阵填补的目的是计算一个复杂度最小的矩阵，以尽可能准确地恢复给定的一组观测数据，并且具有众多应用，如产品推荐。不幸的是，现有的解决低秩矩阵填补的方法是启发式的，虽然高度可扩展并且通常能够确定高质量的解决方案，但不具备任何最优性保证。我们通过将低秩问题重新表述为投影矩阵的非凸问题，并实现一种分离分支定界方案来重新审视矩阵填补问题，以实现最优性导向。此外，我们通过将低秩矩阵分解为一组秩一矩阵的和，并通过 Shor 松弛来激励每个秩一矩阵中的每个 2*2 小矩阵的行列式为零，从而推导出一种新颖且通常很紧的凸松弛类。在数值实验中，相对于最先进的启发式方法，我们的新凸松弛方法将最优性差距减少了两个数量级。

    Low-rank matrix completion consists of computing a matrix of minimal complexity that recovers a given set of observations as accurately as possible, and has numerous applications such as product recommendation. Unfortunately, existing methods for solving low-rank matrix completion are heuristics that, while highly scalable and often identifying high-quality solutions, do not possess any optimality guarantees. We reexamine matrix completion with an optimality-oriented eye, by reformulating low-rank problems as convex problems over the non-convex set of projection matrices and implementing a disjunctive branch-and-bound scheme that solves them to certifiable optimality. Further, we derive a novel and often tight class of convex relaxations by decomposing a low-rank matrix as a sum of rank-one matrices and incentivizing, via a Shor relaxation, that each two-by-two minor in each rank-one matrix has determinant zero. In numerical experiments, our new convex relaxations decrease the optimali
    
[^24]: 对比反向回归的降维方法

    Contrastive inverse regression for dimension reduction. (arXiv:2305.12287v1 [stat.ML])

    [http://arxiv.org/abs/2305.12287](http://arxiv.org/abs/2305.12287)

    本文提出了一种针对病例对照研究数据集的有监督式降维方法CIR，并在保留响应变量的函数关系的同时，直接鼓励在降维空间中将前景组与背景组分离，实验证明其有效性。

    

    监督式降维（SDR）因能在保留与指定响应变量的函数关系的同时减少高维协变量，正成为数据科学日益关注的话题。然而现有的SDR方法并非适用于分析病例对照研究收集的数据集。在这种情况下，目标是学习和利用仅存在于病例组或病例组中富含的低维结构。本文提出了一种名为对比反向回归（CIR）的有监督式降维方法，专为对比情境而设计。CIR在Stiefel流形上引入了优化问题和非稳定目标，直接鼓励在降维空间中将前景组与背景组分离，并在保留响应变量的函数关系的同时进行。我们演示了CIR在模拟和真实数据集上的有效性。

    Supervised dimension reduction (SDR) has been a topic of growing interest in data science, as it enables the reduction of high-dimensional covariates while preserving the functional relation with certain response variables of interest. However, existing SDR methods are not suitable for analyzing datasets collected from case-control studies. In this setting, the goal is to learn and exploit the low-dimensional structure unique to or enriched by the case group, also known as the foreground group. While some unsupervised techniques such as the contrastive latent variable model and its variants have been developed for this purpose, they fail to preserve the functional relationship between the dimension-reduced covariates and the response variable. In this paper, we propose a supervised dimension reduction method called contrastive inverse regression (CIR) specifically designed for the contrastive setting. CIR introduces an optimization problem defined on the Stiefel manifold with a non-sta
    
[^25]: 非参数方法下的无分布模型无偏回归校准

    Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods. (arXiv:2305.12283v1 [cs.LG])

    [http://arxiv.org/abs/2305.12283](http://arxiv.org/abs/2305.12283)

    本文提出一种基于非参数方法的无分布模型无偏回归校准方法，具有计算效率和统计一致性，并建立了校准误差的上限和下限的统计保证和优势。

    

    本文研究回归模型的不确定性量化问题，提出一种基于非参数方法的校准方法，该方法不依赖于底层预测模型，具有计算效率和统计一致性。我们建立了校准误差的上限和下限，并证明了我们提出的方法的统计保证和优势。

    In this paper, we consider the uncertainty quantification problem for regression models. Specifically, we consider an individual calibration objective for characterizing the quantiles of the prediction model. While such an objective is well-motivated from downstream tasks such as newsvendor cost, the existing methods have been largely heuristic and lack of statistical guarantee in terms of individual calibration. We show via simple examples that the existing methods focusing on population-level calibration guarantees such as average calibration or sharpness can lead to harmful and unexpected results. We propose simple nonparametric calibration methods that are agnostic of the underlying prediction model and enjoy both computational efficiency and statistical consistency. Our approach enables a better understanding of the possibility of individual calibration, and we establish matching upper and lower bounds for the calibration error of our proposed methods. Technically, our analysis co
    
[^26]: 监督预训练中类内/类间多样性的权衡

    On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training. (arXiv:2305.12224v1 [cs.LG])

    [http://arxiv.org/abs/2305.12224](http://arxiv.org/abs/2305.12224)

    本文研究了监督预训练数据集中类内多样性和类间多样性之间的权衡对下游任务表现的影响，并理论上证明了下游性能单调地取决于这两种多样性。最佳的类别样本比（#类别 / #每类样本数）与预训练数据集大小无关，可以应用于预测最佳的预训练类别数。

    

    预训练数据集对于构建最先进的机器学习模型至关重要，因此需要对它们对下游任务的影响进行严格研究。在本文中，我们研究了监督预训练数据集中类内多样性（每个类别的样本数）和类间多样性（类别数）之间的权衡对下游表现的影响。实证表明，当预训练数据集大小固定时，最佳的下游表现取决于类内/类间多样性的平衡。为了了解其基本机制，我们理论上证明了下游表现单调地取决于两种多样性。值得注意的是，我们的理论揭示了最佳的类别样本比（#类别 / #每类样本数）不受预训练数据集大小的影响，这启发我们应用预测最佳的预训练类别数。我们通过实验证明了这种应用的有效性，性能提升约为2个百分点。

    Pre-training datasets are critical for building state-of-the-art machine learning models, motivating rigorous study on their impact on downstream tasks. In this work, we study the impact of the trade-off between the intra-class diversity (the number of samples per class) and the inter-class diversity (the number of classes) of a supervised pre-training dataset. Empirically, we found that with the size of the pre-training dataset fixed, the best downstream performance comes with a balance on the intra-/inter-class diversity. To understand the underlying mechanism, we show theoretically that the downstream performance depends monotonically on both types of diversity. Notably, our theory reveals that the optimal class-to-sample ratio (#classes / #samples per class) is invariant to the size of the pre-training dataset, which motivates an application of predicting the optimal number of pre-training classes. We demonstrate the effectiveness of this application by an improvement of around 2 p
    
[^27]: 在潜空间中使用 Langevin 动力学的归一化流采样

    Normalizing flow sampling with Langevin dynamics in the latent space. (arXiv:2305.12149v1 [stat.ML])

    [http://arxiv.org/abs/2305.12149](http://arxiv.org/abs/2305.12149)

    本文提出了一种在潜在空间中使用 Langevin 动力学的采样方法，以克服归一化流可能面临的复杂分布问题，并能够轻松地融入任何 NF 结构中。

    

    归一化流（NF）使用连续生成器将简单的潜在分布（例如高斯分布）映射到与训练数据集相关联的经验目标分布。通过最小化变分目标来训练后，学习到的映射提供了目标分布的近似生成模型。本文提出了一种新的马尔可夫链蒙特卡罗算法，将目标分布在潜域中采样，然后将其传输回目标域，以克服当应对复杂分布时可能出现的问题。该方法依赖于潜空间中的 Metropolis 调整 Langevin 动力学，并且可以轻松地融入任何 NF 结构中。我们展示了我们的方法在玩具和真实数据集上的有效性。

    Normalizing flows (NF) use a continuous generator to map a simple latent (e.g. Gaussian) distribution, towards an empirical target distribution associated with a training data set. Once trained by minimizing a variational objective, the learnt map provides an approximate generative model of the target distribution. Since standard NF implement differentiable maps, they may suffer from pathological behaviors when targeting complex distributions. For instance, such problems may appear for distributions on multi-component topologies or characterized by multiple modes with high probability regions separated by very unlikely areas. A typical symptom is the explosion of the Jacobian norm of the transformation in very low probability areas. This paper proposes to overcome this issue thanks to a new Markov chain Monte Carlo algorithm to sample from the target distribution in the latent domain before transporting it back to the target domain. The approach relies on a Metropolis adjusted Langevin
    
[^28]: 稳定性、泛化性和隐私保护：对于随机特征和NTK特征的精确分析

    Stability, Generalization and Privacy: Precise Analysis for Random and NTK Features. (arXiv:2305.12100v1 [stat.ML])

    [http://arxiv.org/abs/2305.12100](http://arxiv.org/abs/2305.12100)

    本论文研究了ERM训练模型对抗强大黑盒攻击的安全问题，并通过两个指标量化模型安全性：单个样本的稳定性和查询与原始数据特征的对齐。在研究中，通过研究RF和NTK回归，证明随着泛化能力的提高，隐私保护可以得到加强。

    

    深度学习模型容易受到恢复攻击，引起用户隐私保护的担忧。针对经验风险最小化（ERM）等常见算法通常不能直接实施安全保障的问题，本文研究了ERM训练模型对抗特定强大黑盒子攻击的安全问题。我们的分析通过两个看似不同但有联系的指标来量化模型安全性：一是相对于单个训练样本的模型稳定性，另一个是攻击查询和原始数据特征的特征对齐。虽然前者在学习理论中已经得到了很好的阐述，并与经典工作中的泛化误差相关，但在我们的研究中，第二种特性是新颖的。我们的关键技术结果为两种原型设置提供了特征对齐的精确刻画：随机特征（RF）和神经切向核（NTK）回归。这证明，随着泛化能力的提高，隐私保护能够得到加强，同时揭示了其他有趣的性质。

    Deep learning models can be vulnerable to recovery attacks, raising privacy concerns to users, and widespread algorithms such as empirical risk minimization (ERM) often do not directly enforce safety guarantees. In this paper, we study the safety of ERM-trained models against a family of powerful black-box attacks. Our analysis quantifies this safety via two separate terms: (i) the model stability with respect to individual training samples, and (ii) the feature alignment between the attacker query and the original data. While the first term is well established in learning theory and it is connected to the generalization error in classical work, the second one is, to the best of our knowledge, novel. Our key technical result provides a precise characterization of the feature alignment for the two prototypical settings of random features (RF) and neural tangent kernel (NTK) regression. This proves that privacy strengthens with an increase in the generalization capability, unveiling also
    
[^29]: （带噪声的）随机梯度下降的时间均匀Wasserstein稳定性界限

    Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent. (arXiv:2305.12056v1 [stat.ML])

    [http://arxiv.org/abs/2305.12056](http://arxiv.org/abs/2305.12056)

    本文通过建立学习理论和应用概率之间的联系，提出了一种证明随机优化算法Wasserstein稳定性界限的统一指南，并在随机梯度下降上验证了该方法的有效性，包括强凸损失和带添加噪声的非凸损失。

    

    算法稳定性是一个重要的概念，对于推导实践算法的泛化界限已被证明是有用的。过去十年已经见证了不同损失函数所应用的不同算法的稳定性界限的增加。虽然这些界限照亮了优化算法的各种属性，但每个案例的分析通常需要不同的证明技术和显著不同的数学工具。在本研究中，我们在学习理论和应用概率之间建立了新的联系，并介绍了一种证明随机优化算法的Wasserstein稳定性界限的统一指南。我们在随机梯度下降（SGD）上阐述了我们的方法，并获得了强凸损失和带添加噪声的非凸损失的时间均匀稳定性界限（即，界限不随迭代次数增加而增加），在这些情况下，我们恢复了与先前文献相似的结果或将它们扩展到更广泛。

    Algorithmic stability is an important notion that has proven powerful for deriving generalization bounds for practical algorithms. The last decade has witnessed an increasing number of stability bounds for different algorithms applied on different classes of loss functions. While these bounds have illuminated various properties of optimization algorithms, the analysis of each case typically required a different proof technique with significantly different mathematical tools. In this study, we make a novel connection between learning theory and applied probability and introduce a unified guideline for proving Wasserstein stability bounds for stochastic optimization algorithms. We illustrate our approach on stochastic gradient descent (SGD) and we obtain time-uniform stability bounds (i.e., the bound does not increase with the number of iterations) for strongly convex losses and non-convex losses with additive noise, where we recover similar results to the prior art or extend them to mor
    
[^30]: 具有概率保证的神经网络鲁棒的反事实解释

    Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v1 [stat.ML])

    [http://arxiv.org/abs/2305.11997](http://arxiv.org/abs/2305.11997)

    本文提出了一种可靠的神经网络反事实解释方法，该方法可以针对自然发生的模型变化提供高概率的鲁棒性。

    

    针对神经网络发现偏移，通过使用稳定性度量来量化反事实解释对可能的模型变化的鲁棒性。通过在反事实解释优化中引入正则化项来将生成的反事实解释靠近数据流形，从而实现了对自然发生的模型变化的高概率鲁棒性。新的算法在合成和现实世界数据集上进行实验，证明了其有效性。

    There is an emerging interest in generating robust counterfactual explanations that would remain valid if the model is updated or changed even slightly. Towards finding robust counterfactuals, existing literature often assumes that the original model $m$ and the new model $M$ are bounded in the parameter space, i.e., $\|\text{Params}(M){-}\text{Params}(m)\|{<}\Delta$. However, models can often change significantly in the parameter space with little to no change in their predictions or accuracy on the given dataset. In this work, we introduce a mathematical abstraction termed \emph{naturally-occurring} model change, which allows for arbitrary changes in the parameter space such that the change in predictions on points that lie on the data manifold is limited. Next, we propose a measure -- that we call \emph{Stability} -- to quantify the robustness of counterfactuals to potential model changes for differentiable models, e.g., neural networks. Our main contribution is to show that counter
    
[^31]: 带有时间预测编码的时序记忆

    Sequential Memory with Temporal Predictive Coding. (arXiv:2305.11982v1 [q-bio.NC])

    [http://arxiv.org/abs/2305.11982](http://arxiv.org/abs/2305.11982)

    该论文提出了一种基于PC的新型时序记忆模型，称为时间预测编码（tPC），可以通过生物可行的神经实现准确地记忆和检索连续输入。其中tPC可以被看作是一种经典异向性霍普菲尔德网络（AHN），具有更稳定的性能，并且可以编码上下文相关信息，区分在序列中出现的重复元素。

    

    对于生物体存储事件序列的时间顺序至关重要，然而大脑中支配时序记忆的计算机制仍不清楚。本文受到神经科学理论和预测编码（PC）在静态存储任务中的成功启示，提出了一种基于PC的新型时序记忆模型，称为时间预测编码（tPC）。我们展示了我们的tPC模型可以通过生物可行的神经实现准确地记忆和检索连续输入。重要的是，我们的分析研究表明，tPC可以被看作是一种具有隐式统计白化过程的经典异向性霍普菲尔德网络（AHN），这会在结构化输入的时序记忆任务中导致更稳定的性能。此外，我们发现具有多层结构的tPC可以编码上下文相关信息，因此可以区分在序列中出现的重复元素。

    Memorizing the temporal order of event sequences is critical for the survival of biological agents. However, the computational mechanism underlying sequential memory in the brain remains unclear. Inspired by neuroscience theories and recent successes in applying predictive coding (PC) to static memory tasks, in this work we propose a novel PC-based model for sequential memory, called temporal predictive coding (tPC). We show that our tPC models can memorize and retrieve sequential inputs accurately with a biologically plausible neural implementation. Importantly, our analytical study reveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN) with an implicit statistical whitening process, which leads to more stable performance in sequential memory tasks of structured inputs. Moreover, we find that tPC with a multi-layer structure can encode context-dependent information, thus distinguishing between repeating elements appearing in a sequence, a computation attribute
    
[^32]: 不是所有的语义都是平等的：具有自定义温度的对比自监督学习

    Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization. (arXiv:2305.11965v1 [cs.LG])

    [http://arxiv.org/abs/2305.11965](http://arxiv.org/abs/2305.11965)

    本文提出了一种具有个性化温度的对比损失用于自监督学习，根据数据分布自动调整温度以使得训练更加有效。

    

    本文旨在通过原则性和系统性的方式，优化具有个性化温度的对比损失，用于自监督学习。普遍做法是将全局温度参数τ用于所有数据，忽略了“不是所有的语义都是平等的”这个事实，特别是在数据展示长尾分布时，不同的锚点数据可能具有不同数量的类似语义的样本。我们提出了一种基于分布鲁棒性优化（DRO）的新型鲁棒对比损失，为我们提供了有关τ的影响的直觉和自动温度个性化的机制。然后，我们提出了一种有效的随机算法来优化鲁棒性对比损失，具有可证明的收敛保证，而不需要使用大型小批量大小。理论和实验结果表明，我们的算法自动学习每个样本的合适τ。具体来说，具有频繁语义的样本使用较大温度以保持难度。

    In this paper, we aim to optimize a contrastive loss with individualized temperatures in a principled and systematic manner for self-supervised learning. The common practice of using a global temperature parameter $\tau$ ignores the fact that ``not all semantics are created equal", meaning that different anchor data may have different numbers of samples with similar semantics, especially when data exhibits long-tails. First, we propose a new robust contrastive loss inspired by distributionally robust optimization (DRO), providing us an intuition about the effect of $\tau$ and a mechanism for automatic temperature individualization. Then, we propose an efficient stochastic algorithm for optimizing the robust contrastive loss with a provable convergence guarantee without using large mini-batch sizes. Theoretical and experimental results show that our algorithm automatically learns a suitable $\tau$ for each sample. Specifically, samples with frequent semantics use large temperatures to k
    
[^33]: 序列最优臂识别及其在脑-机接口中的应用

    Sequential Best-Arm Identification with Application to Brain-Computer Interface. (arXiv:2305.11908v1 [cs.HC])

    [http://arxiv.org/abs/2305.11908](http://arxiv.org/abs/2305.11908)

    本论文提出了一种序列最优臂识别方法，应用于脑-机接口中的拼写系统。利用预训练的大型语言模型，可以更快地进行学习并提高信息传输速率。

    

    脑-机接口是一种使大脑与外部设备或计算机系统直接通信的技术，它允许个体只使用思维与设备进行交互，并具有在医学、康复和人体增强等领域中广泛应用的潜力。 基于脑电图（EEG）和事件相关电位（ERP）的拼写器系统是一种类型的脑-机接口，它允许用户在不使用物理键盘的情况下拼写单词，而是通过记录和解释在不同的刺激呈现范例下的脑信号。传统的非自适应范例将每个单词选择视为独立的，导致了漫长的学习过程。为了提高采样效率，我们将问题转化为多臂老虎机中一系列最优臂识别任务。利用预训练的大型语言模型（LLM），我们利用从先前任务中学习到的先验知识来通知和促进后续任务。我们提出的方法与现有方法相比具有更快的学习速度和更高的信息传输速率。我们在模拟ERP拼写实验和真实的EEG打字任务中展示了我们方法的有效性。

    A brain-computer interface (BCI) is a technology that enables direct communication between the brain and an external device or computer system. It allows individuals to interact with the device using only their thoughts, and holds immense potential for a wide range of applications in medicine, rehabilitation, and human augmentation. An electroencephalogram (EEG) and event-related potential (ERP)-based speller system is a type of BCI that allows users to spell words without using a physical keyboard, but instead by recording and interpreting brain signals under different stimulus presentation paradigms. Conventional non-adaptive paradigms treat each word selection independently, leading to a lengthy learning process. To improve the sampling efficiency, we cast the problem as a sequence of best-arm identification tasks in multi-armed bandits. Leveraging pre-trained large language models (LLMs), we utilize the prior knowledge learned from previous tasks to inform and facilitate subsequent
    
[^34]: 针对非稳态赌博机问题的折扣汤普森抽样算法

    Discounted Thompson Sampling for Non-Stationary Bandit Problems. (arXiv:2305.10718v1 [cs.LG])

    [http://arxiv.org/abs/2305.10718](http://arxiv.org/abs/2305.10718)

    该论文提出了一种针对非稳态多臂赌博机问题的折扣汤普森抽样算法（DS-TS），可以解决突然性变化和平滑性变化的问题，并且在两种情况下具有近乎最优的遗憾上限。

    

    近年来，非稳态多臂赌博机问题受到了显著关注。NS-MAB通常在两种情况下进行建模：突然性变化和平滑性变化。在本文中，我们提出了带有高斯先验的折扣汤普森采样算法（DS-TS）以解决这两个非稳态设置。我们的算法通过将折扣因子纳入汤普森采样来被动适应变化。DS-TS方法经过实验验证，但缺乏对遗憾上限的分析。在温和的假设下，我们证明了带有高斯先验的DS-TS可以在突然性变化的情况下实现近乎最优的遗憾上限（$\tilde{O} (\sqrt {TB_T})$），在平滑性变化的情况下实现 $\tilde{O}(T^{\beta})$ 的近乎最优遗憾上限，其中 $T$ 是时间步数，$B_T$ 是断点数，$\beta$ 与收益分布的平滑性有关，$\tilde{O}$ 是对数遗憾上限。

    Non-stationary multi-armed bandit (NS-MAB) problems have recently received significant attention. NS-MAB are typically modelled in two scenarios: abruptly changing, where reward distributions remain constant for a certain period and change at unknown time steps, and smoothly changing, where reward distributions evolve smoothly based on unknown dynamics. In this paper, we propose Discounted Thompson Sampling (DS-TS) with Gaussian priors to address both non-stationary settings. Our algorithm passively adapts to changes by incorporating a discounted factor into Thompson Sampling. DS-TS method has been experimentally validated, but analysis of the regret upper bound is currently lacking. Under mild assumptions, we show that DS-TS with Gaussian priors can achieve nearly optimal regret bound on the order of $\tilde{O}(\sqrt{TB_T})$ for abruptly changing and $\tilde{O}(T^{\beta})$ for smoothly changing, where $T$ is the number of time steps, $B_T$ is the number of breakpoints, $\beta$ is asso
    
[^35]: 张量积与超维计算

    Tensor Products and Hyperdimensional Computing. (arXiv:2305.10572v1 [stat.ML])

    [http://arxiv.org/abs/2305.10572](http://arxiv.org/abs/2305.10572)

    本文探索了张量积在超维计算中的数学关系，将其确定为中心表示，并发现它是最通用、最具表现力和最压缩的表示，同时具有无误差解绑和检测的能力。

    

    在之前对图嵌入的分析基础上，我们将一些结果推广和拓展到向量符号结构 (VSA) 和超维计算 (HDC) 的一般设置中。重要的是，我们探索超叠加、正交和张量积之间的数学关系。我们将张量积表示确定为中心表示，并具有一套独特的属性。这包括它是最通用和最具表现力的表示，也是最压缩的表示，具有无误差解绑和检测的能力。

    Following up on a previous analysis of graph embeddings, we generalize and expand some results to the general setting of vector symbolic architectures (VSA) and hyperdimensional computing (HDC). Importantly, we explore the mathematical relationship between superposition, orthogonality, and tensor product. We establish the tensor product representation as the central representation, with a suite of unique properties. These include it being the most general and expressive representation, as well as being the most compressed representation that has errorrless unbinding and detection.
    
[^36]: 功能扩散映射

    Functional Diffusion Maps. (arXiv:2304.14378v1 [cs.LG])

    [http://arxiv.org/abs/2304.14378](http://arxiv.org/abs/2304.14378)

    本研究关注一种非线性流形学习方法：扩散映射。本文阐述如何将这种方法应用于功能数据，并将其与功能主成分分析进行比较。

    

    如今，许多现实世界的数据集可以被视为是功能性的，也就是说生成它们的过程是连续的。这种类型数据的一个基本特性是，理论上它们属于无限维空间。尽管在实践中，我们通常只能得到有限数量的观察结果，它们仍然是高维的，因此降维方法至关重要。在这方面，功能数据分析的主要现有方法是功能主成分分析。尽管如此，这种经典技术假设数据位于一个线性流形中，因此当这个假设不成立时可能会出现问题。本研究聚焦于一种非线性流形学习方法：扩散映射。本文解释了如何将这种多变量方法扩展到功能数据，并将其行为与功能主成分分析在不同的模拟和实际例子中进行了比较。

    Nowadays many real-world datasets can be considered as functional, in the sense that the processes which generate them are continuous. A fundamental property of this type of data is that in theory they belong to an infinite-dimensional space. Although in practice we usually receive finite observations, they are still high-dimensional and hence dimensionality reduction methods are crucial. In this vein, the main state-of-the-art method for functional data analysis is Functional PCA. Nevertheless, this classic technique assumes that the data lie in a linear manifold, and hence it could have problems when this hypothesis is not fulfilled. In this research, attention has been placed on a non-linear manifold learning method: Diffusion Maps. The article explains how to extend this multivariate method to functional data and compares its behavior against Functional PCA over different simulated and real examples.
    
[^37]: 可解释的神经符号概念推理

    Interpretable Neural-Symbolic Concept Reasoning. (arXiv:2304.14068v1 [cs.AI])

    [http://arxiv.org/abs/2304.14068](http://arxiv.org/abs/2304.14068)

    本文提出了第一个基于概念嵌入的可解释概念模型DCR，能够在多个数据集上实现接近最先进的准确性，相对于最先进的可解释概念模型提高了高达+25％，并产生能够解释其预测的人类可理解规则和真值度，适应性强。

    

    深度学习方法具有高度的准确性，但它们不透明的决策过程阻止了它们获得完全的人类信任。概念模型旨在通过学习一组人类可理解的概念来解决这个问题。然而，最先进的概念模型依赖于高维概念嵌入表示，缺乏明确的语义含义，因此质疑其决策过程的可解释性。为了克服这个限制，我们提出了Deep Concept Reasoner(DCR)，这是第一个基于概念嵌入的可解释概念模型。在DCR中，神经网络不直接进行任务预测，而是使用概念嵌入建立语法规则结构。然后DCR在有意义的概念真值度上执行这些规则，以不可微分的方式提供最终的可解释和语义一致的预测。我们的实验表明，DCR：(i)在多个数据集上实现接近最先进的准确性，同时相对于最先进的可解释概念模型提高了高达+25％;(ii)产生能够解释其预测的人类可理解规则和真值度;(iii)很容易适应新领域。

    Deep learning methods are highly accurate, yet their opaque decision process prevents them from earning full human trust. Concept-based models aim to address this issue by learning tasks based on a set of human-understandable concepts. However, state-of-the-art concept-based models rely on high-dimensional concept embedding representations which lack a clear semantic meaning, thus questioning the interpretability of their decision process. To overcome this limitation, we propose the Deep Concept Reasoner (DCR), the first interpretable concept-based model that builds upon concept embeddings. In DCR, neural networks do not make task predictions directly, but they build syntactic rule structures using concept embeddings. DCR then executes these rules on meaningful concept truth degrees to provide a final interpretable and semantically-consistent prediction in a differentiable manner. Our experiments show that DCR: (i) improves up to +25% w.r.t. state-of-the-art interpretable concept-based
    
[^38]: 用于因果中介分析中具有治疗不服从性的识别和倍增稳健估计

    Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance. (arXiv:2304.10025v1 [stat.ME])

    [http://arxiv.org/abs/2304.10025](http://arxiv.org/abs/2304.10025)

    本文针对治疗不服从性提出了一种半参数框架来评估因果中介效应，提出了一组假设来识别自然中介效应并推导出成倍稳健估计器。

    

    在实验和观察研究中，人们通常对了解干预方案如何改善最终结果的潜在机制感兴趣。因果中介分析旨在达到此目的，但主要限于治疗完全服从的情况，只有少数情况需要排除限制。在本文中，我们建立了一个半参数框架，用于在无需排除限制的情况下评估具有治疗不服从性的因果中介效应。我们提出了一组假设来识别整个研究人群的自然中介效应，并进一步针对由潜在服从行为特征化的亚人群中的主要自然中介效应进行识别。我们推导出了主要自然中介效应估计量的有效影响函数，这激励了一组倍增稳健估计器进行推论。这些被识别估计量的半参数效率理论。

    In experimental and observational studies, there is often interest in understanding the potential mechanism by which an intervention program improves the final outcome. Causal mediation analyses have been developed for this purpose but are primarily restricted to the case of perfect treatment compliance, with a few exceptions that require exclusion restriction. In this article, we establish a semiparametric framework for assessing causal mediation in the presence of treatment noncompliance without exclusion restriction. We propose a set of assumptions to identify the natural mediation effects for the entire study population and further, for the principal natural mediation effects within subpopulations characterized by the potential compliance behaviour. We derive the efficient influence functions for the principal natural mediation effect estimands, which motivate a set of multiply robust estimators for inference. The semiparametric efficiency theory for the identified estimands is der
    
[^39]: 分布式鲁棒强化学习的样本复杂性界限的改进

    Improved Sample Complexity Bounds for Distributionally Robust Reinforcement Learning. (arXiv:2303.02783v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02783](http://arxiv.org/abs/2303.02783)

    本文改进了分布式鲁棒强化学习的样本复杂度界限，提出了稳健分阶段价值学习（RPVL）算法来解决表格剧情学习环境下的不确定性问题。

    

    本文考虑了在训练环境与测试环境之间参数不匹配的情况下学习控制策略的问题。我们将其制定为一个分布式鲁棒强化学习(DR-RL)问题，其中目标是学习在不确定集中针对环境最坏的随机模型下最大化价值函数的策略。我们专注于表格剧情学习环境，在不确定集被定义在名义（训练）环境的生成模型周围的情况下，算法可以访问该环境。我们提出了稳健分阶段价值学习(RPVL)算法来解决用四种不同发散度指定的不确定集的问题: 全变分、卡方、Kullback-Leibler和Wasserstein。我们证明了我们的算法达到了 $\tilde{\mathcal{O}}(|\mathcal{S}||\mathcal{A}| H^{5})$ 样本复杂性，这比现有结果平均好了一倍的 $|\mathcal{S}|$

    We consider the problem of learning a control policy that is robust against the parameter mismatches between the training environment and testing environment. We formulate this as a distributionally robust reinforcement learning (DR-RL) problem where the objective is to learn the policy which maximizes the value function against the worst possible stochastic model of the environment in an uncertainty set. We focus on the tabular episodic learning setting where the algorithm has access to a generative model of the nominal (training) environment around which the uncertainty set is defined. We propose the Robust Phased Value Learning (RPVL) algorithm to solve this problem for the uncertainty sets specified by four different divergences: total variation, chi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm achieves $\tilde{\mathcal{O}}(|\mathcal{S}||\mathcal{A}| H^{5})$ sample complexity, which is uniformly better than the existing results by a factor of $|\mathcal{S}|
    
[^40]: Gibbsian极坐标切片采样

    Gibbsian polar slice sampling. (arXiv:2302.03945v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2302.03945](http://arxiv.org/abs/2302.03945)

    本文提出了一种基于Gibbs算法的极坐标切片采样方法，该方法通过更新方向和半径分量实现采样过程，且在实验中表现优越。

    

    极坐标切片采样是一种近似采样分布的马尔科夫链方法，这种方法与维度相关性很好，但实现难度很大，甚至不可能实现。我们在更新链迭代的方向和半径分量时，获得了一系列模拟极坐标切片采样的采样器，同时可以有效地实施。在各种情况下的数值实验表明，我们提出的算法优于最相关的两种方法，即椭圆切片采样和 hit-and-run 均匀切片采样。在目标分布具有适当假设的条件下，我们证明了我们的方法的明确性和收敛性。

    Polar slice sampling (Roberts & Rosenthal, 2002) is a Markov chain approach for approximate sampling of distributions that is difficult, if not impossible, to implement efficiently, but behaves provably well with respect to the dimension. By updating the directional and radial components of chain iterates separately, we obtain a family of samplers that mimic polar slice sampling, and yet can be implemented efficiently. Numerical experiments in a variety of settings indicate that our proposed algorithm outperforms the two most closely related approaches, elliptical slice sampling (Murray et al., 2010) and hit-and-run uniform slice sampling (MacKay, 2003). We prove the well-definedness and convergence of our methods under suitable assumptions on the target distribution.
    
[^41]: 强化学习中的尖锐方差相关界限：随机和确定性环境的最佳结合

    Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both Worlds in Stochastic and Deterministic Environments. (arXiv:2301.13446v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13446](http://arxiv.org/abs/2301.13446)

    本研究将马尔可夫决策过程的方差相关遗憾界限应用到强化学习中，提出了两个新的环境规范来表征环境的方差属性，并设计出基于模型和无模型的算法，对于随机和确定性环境同时极小极大最优的界限是第一次被证明出来的。

    

    本文研究马尔可夫决策过程（MDPs）的方差相关遗憾界限。具有方差相关遗憾保证的算法可以自动利用具有低方差（例如，在确定性MDP上享有常量遗憾）的环境。现有算法要么独立于方差要么次优。我们首先提出两个新的环境规范来表征环境的细粒度方差属性。对于基于模型的方法，我们设计了MVP算法(Zhang等，2021a)的变种，并使用新的分析技术展示了该算法相对于我们提出的规范享有方差相关的界限。特别地，这一界限对于随机和确定性MDP同时是极小极大最优的，这是其种类中的第一个结果。我们进一步通过设计一种参考函数的算法以及一个新的带有上限加倍参考更新进度表的策略启动了关于具有方差相关遗憾界限的无模型算法的研究。最后，我们还提供了一些启示。

    We study variance-dependent regret bounds for Markov decision processes (MDPs). Algorithms with variance-dependent regret guarantees can automatically exploit environments with low variance (e.g., enjoying constant regret on deterministic MDPs). The existing algorithms are either variance-independent or suboptimal. We first propose two new environment norms to characterize the fine-grained variance properties of the environment. For model-based methods, we design a variant of the MVP algorithm (Zhang et al., 2021a) and use new analysis techniques show to this algorithm enjoys variance-dependent bounds with respect to our proposed norms. In particular, this bound is simultaneously minimax optimal for both stochastic and deterministic MDPs, the first result of its kind. We further initiate the study on model-free algorithms with variance-dependent regret bounds by designing a reference-function-based algorithm with a novel capped-doubling reference update schedule. Lastly, we also provid
    
[^42]: 基于抽样的Nyström逼近和核积分。

    Sampling-based Nystr\"om Approximation and Kernel Quadrature. (arXiv:2301.09517v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2301.09517](http://arxiv.org/abs/2301.09517)

    本文提出了一种基于抽样的Nyström逼近方法用于核积分。同时，引入了一种非i.i.d.地标点的理论保证方法，使得提高了逼近的精度。

    

    我们分析与概率测量相关的正定核的Nyström逼近。我们首先证明了传统Nyström逼近在连续区间中使用i.i.d.抽样和奇异值分解的改进误差界，证明技巧借鉴了统计学习理论。我们进一步引入了Nyström逼近中的子空间精细选择，这是适用于非i.i.d.地标点的理论保证。最后，我们讨论了它们在凸核积分中的应用，并给出了新的理论保证以及数值观察。

    We analyze the Nystr\"om approximation of a positive definite kernel associated with a probability measure. We first prove an improved error bound for the conventional Nystr\"om approximation with i.i.d. sampling and singular-value decomposition in the continuous regime; the proof techniques are borrowed from statistical learning theory. We further introduce a refined selection of subspaces in Nystr\"om approximation with theoretical guarantees that is applicable to non-i.i.d. landmark points. Finally, we discuss their application to convex kernel quadrature and give novel theoretical guarantees as well as numerical observations.
    
[^43]: 可信数据价值评估的方差缩小Shapley值估计

    Variance reduced Shapley value estimation for trustworthy data valuation. (arXiv:2210.16835v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.16835](http://arxiv.org/abs/2210.16835)

    本文提出了一种名为VRDS的分层抽样方法，用于评估数据价值，以缩小排列抽样方法的估计方差，并在不同类型的数据集和数据删除应用程序中得到验证。

    

    数据价值评估，特别是在算法预测和决策中量化数据价值，是数据交易场景中的一个基本问题。目前最广泛使用的方法是定义数据Shapley值，然后通过排序抽样算法进行近似计算。为了弥补排列抽样算法的大估计方差，我们提出了一种更稳健的数据估价方法，使用分层抽样，并命名为方差缩小数据Shapley值（VRDS）。我们理论上展示了如何进行分层抽样，每个层抽多少样本，以及VRDS的样本复杂度分析。最后，我们在不同类型的数据集和数据删除应用程序中说明了VRDS的有效性。

    Data valuation, especially quantifying data value in algorithmic prediction and decision-making, is a fundamental problem in data trading scenarios. The most widely used method is to define the data Shapley and approximate it by means of the permutation sampling algorithm. To make up for the large estimation variance of the permutation sampling that hinders the development of the data marketplace, we propose a more robust data valuation method using stratified sampling, named variance reduced data Shapley (VRDS for short). We theoretically show how to stratify, how many samples are taken at each stratum, and the sample complexity analysis of VRDS. Finally, the effectiveness of VRDS is illustrated in different types of datasets and data removal applications.
    
[^44]: FaDIn: 针对具有一般参数核的Hawkes过程的快速离散化推断

    FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels. (arXiv:2210.04635v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.04635](http://arxiv.org/abs/2210.04635)

    本论文提出了一种使用具有有限支持的一般参数核进行TPP推理的高效解决方案，该方法采用了离散化方法，并通过多项实验证明了该方法的统计和计算效率。

    

    时间点过程是建模事件数据的自然工具。在所有的时间点过程模型中，Hawkes过程被证明是最广泛使用的，主要是由于它们对于各种应用的适当建模，特别是在考虑指数或非参数核时。尽管非参数核是一种选择，但这些模型需要大型数据集。而指数核更具数据效率，对于立即触发更多事件的特定应用更有效，但对于需要估计延迟的应用（如神经科学），它们不太适用。本研究旨在提供一种使用具有有限支持的一般参数核进行TPP推理的高效解决方案。所开发的解决方案包括利用事件的离散化的快速$\ell_2$梯度求解器。在理论上支持离散化的使用后，通过多种实验，证明了该新方法的统计和计算效率。

    Temporal point processes (TPP) are a natural tool for modeling event-based data. Among all TPP models, Hawkes processes have proven to be the most widely used, mainly due to their adequate modeling for various applications, particularly when considering exponential or non-parametric kernels. Although non-parametric kernels are an option, such models require large datasets. While exponential kernels are more data efficient and relevant for specific applications where events immediately trigger more events, they are ill-suited for applications where latencies need to be estimated, such as in neuroscience. This work aims to offer an efficient solution to TPP inference using general parametric kernels with finite support. The developed solution consists of a fast $\ell_2$ gradient-based solver leveraging a discretized version of the events. After theoretically supporting the use of discretization, the statistical and computational efficiency of the novel approach is demonstrated through va
    
[^45]: 展开的诅咒：系统优化的不同化速率

    The Curse of Unrolling: Rate of Differentiating Through Optimization. (arXiv:2209.13271v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2209.13271](http://arxiv.org/abs/2209.13271)

    优化问题中的展开求导是机器学习中的一个重要问题，本文对其在梯度下降和 Chebyshev 方法中的二次目标提供了非渐进收敛速率分析，发现我们要确保雅可比矩阵的收敛，就必须面临展开求导的诅咒，即要么选择大的学习率导致快速渐进收敛但算法有较长的初始阶段，要么选择较小的学习率导致即时但较慢的收敛。

    

    计算优化问题解的雅可比矩阵是机器学习中的一个中心问题，在超参数优化、元学习、优化作为一种层以及数据集蒸馏等方面有着广泛应用。展开求导是一种流行的启发式方法，它使用迭代求解器近似求解解，并通过计算路径进行不同化。本文针对梯度下降和Chebyshev方法中二次目标提供了该方法的非渐进收敛速率分析。我们表明，为了确保雅可比矩阵的收敛，我们可以选择1）选择大的学习率，导致快速的渐进收敛，但可能会接受算法具有任意长的初始阶段，或者2）选择较小的学习率，导致即时但较慢的收敛。我们称之为展开的诅咒。最后，我们讨论了与此方法相关的开放问题，例如导出实用的更新规则。

    Computing the Jacobian of the solution of an optimization problem is a central problem in machine learning, with applications in hyperparameter optimization, meta-learning, optimization as a layer, and dataset distillation, to name a few. Unrolled differentiation is a popular heuristic that approximates the solution using an iterative solver and differentiates it through the computational path. This work provides a non-asymptotic convergence-rate analysis of this approach on quadratic objectives for gradient descent and the Chebyshev method. We show that to ensure convergence of the Jacobian, we can either 1) choose a large learning rate leading to a fast asymptotic convergence but accept that the algorithm may have an arbitrarily long burn-in phase or 2) choose a smaller learning rate leading to an immediate but slower convergence. We refer to this phenomenon as the curse of unrolling. Finally, we discuss open problems relative to this approach, such as deriving a practical update rul
    
[^46]: 通过神经网络检测广义线性模型的交互变量

    Detection of Interacting Variables for Generalized Linear Models via Neural Networks. (arXiv:2209.08030v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.08030](http://arxiv.org/abs/2209.08030)

    本文提出了一种使用神经网络和模型特定交互检测方法来自动化寻找GLMs中应添加的交互作用以提高其预测能力的方法。

    

    广义线性模型（GLMs）是保险公司经常使用的建模方法，其质量取决于交互变量的选择。寻找交互作用对于具有许多变量的数据集来说非常耗时，很大程度上依赖于精算师的专业判断，通常依赖于视觉性能指标。因此，本文提出了一种自动化寻找GLMs中应添加的交互作用以提高其预测能力的方法。我们的方法依赖于神经网络和模型特定的交互检测方法，这比传统方法（如Friedman H统计量或SHAP值）要快。在数字研究中，我们提供了我们的方法在人工生成数据以及开源数据上的结果。

    The quality of generalized linear models (GLMs), frequently used by insurance companies, depends on the choice of interacting variables. The search for interactions is time-consuming, especially for data sets with a large number of variables, depends much on expert judgement of actuaries, and often relies on visual performance indicators. Therefore, we present an approach to automating the process of finding interactions that should be added to GLMs to improve their predictive power. Our approach relies on neural networks and a model-specific interaction detection method, which is computationally faster than the traditionally used methods like Friedman H-Statistic or SHAP values. In numerical studies, we provide the results of our approach on artificially generated data as well as open-source data.
    
[^47]: 深度学习的莫里-茨旺齐格表述

    The Mori-Zwanzig formulation of deep learning. (arXiv:2209.05544v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.05544](http://arxiv.org/abs/2209.05544)

    本文提出了基于莫里-茨旺齐格形式主义的深度学习新表述，引入了神经网络记忆的新概念，并通过线性算子方程直接向前和向后传播感兴趣的量。收缩映射理论被用来开发记忆衰减随网络层数增加的充分条件。

    

    本文基于不可逆统计力学的莫里-茨旺齐格（MZ）形式主义，提出了深度学习的新表述。这种新的表述基于深度神经网络和离散动力系统之间的对偶关系，通过线性算子方程直接向前和向后传播感兴趣的量（条件期望和概率密度函数）。这些新方程可以作为开发深度神经网络新的有效参数化的起点，并提供了一种新的通过算子理论方法研究深度学习的框架。所提出的MZ形式主义自然引入了神经网络记忆的新概念，在低维建模和参数化中起着 fundamental 的作用。通过使用收缩映射理论，我们开发出了记忆衰减随网络层数增加的充分条件。

    We develop a new formulation of deep learning based on the Mori-Zwanzig (MZ) formalism of irreversible statistical mechanics. The new formulation is built upon the well-known duality between deep neural networks and discrete dynamical systems, and it allows us to directly propagate quantities of interest (conditional expectations and probability density functions) forward and backward through the network by means of exact linear operator equations. Such new equations can be used as a starting point to develop new effective parameterizations of deep neural networks, and provide a new framework to study deep-learning via operator theoretic methods. The proposed MZ formulation of deep learning naturally introduces a new concept, i.e., the memory of the neural network, which plays a fundamental role in low-dimensional modeling and parameterization. By using the theory of contraction mappings, we develop sufficient conditions for the memory of the neural network to decay with the number of 
    
[^48]: 拓扑深度学习：超越图数据

    Topological Deep Learning: Going Beyond Graph Data. (arXiv:2206.00606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00606](http://arxiv.org/abs/2206.00606)

    本文提出了一个拓扑深度学习的框架，其中包含组合复合体这一新型拓扑域。组合复合体结合了超图和胞腔复合体的优点，允许构建分层高阶关系。

    

    拓扑深度学习是一个快速发展的领域，与开发支持于拓扑域上的深度学习模型有关，例如单纯复合体、胞腔复合体和超图。这些拓扑域在科学计算中广泛应用。在本文中，我们提出了一个建立在更丰富数据结构之上的统一深度学习框架，包括拓扑域。我们首先介绍组合复合体，这是一种新型的拓扑域。组合复合体可以看作是保持某些理想性质的图的推广。类似于超图，组合复合体对关系集合不施加任何约束。此外，组合复合体允许构建分层高阶关系，类似于单纯和胞腔复合体中的关系。因此，组合复合体推广并结合了超图和胞腔复合体的有用特性。

    Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations. In this paper, we present a unifying deep learning framework built upon a richer data structure that includes widely adopted topological domains.  Specifically, we first introduce combinatorial complexes, a novel type of topological domain. Combinatorial complexes can be seen as generalizations of graphs that maintain certain desirable properties. Similar to hypergraphs, combinatorial complexes impose no constraints on the set of relations. In addition, combinatorial complexes permit the construction of hierarchical higher-order relations, analogous to those found in simplicial and cell complexes. Thus, combinatorial complexes generalize and combine useful traits of both hypergraphs and cell complexes, whi
    
[^49]: SepIt: 接近单通道语音分离界限的方法

    SepIt: Approaching a Single Channel Speech Separation Bound. (arXiv:2205.11801v4 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2205.11801](http://arxiv.org/abs/2205.11801)

    该论文提出了一种接近单通道语音分离界限的方法SepIt，在实验中表现优于最先进的神经网络方法，尤其是在5个和10个说话人的情况下仍有提高空间。

    

    我们提出了一种单通道语音分离任务的上界，该上界基于对语音短时段性质的假设。使用该上界，我们能够展示，虽然最近的方法已经取得了在少数几个说话人的情况下显著的进展，但在5个和10个说话人的情况下还有提高的空间。接着，我们引入了深度神经网络SepIt来迭代地改进不同说话人的估计。在测试时，SepIt对于每个测试样本的迭代次数是可变的，基于我们分析中出现的互信息标准。通过广泛的实验，SepIt在2、3、5和10个说话人的情况下胜过了最先进的神经网络方法。

    We present an upper bound for the Single Channel Speech Separation task, which is based on an assumption regarding the nature of short segments of speech. Using the bound, we are able to show that while the recent methods have made significant progress for a few speakers, there is room for improvement for five and ten speakers. We then introduce a Deep neural network, SepIt, that iteratively improves the different speakers' estimation. At test time, SpeIt has a varying number of iterations per test sample, based on a mutual information criterion that arises from our analysis. In an extensive set of experiments, SepIt outperforms the state-of-the-art neural networks for 2, 3, 5, and 10 speakers.
    
[^50]: 带有最小超参数化的深度神经网络中的记忆化与优化

    Memorization and Optimization in Deep Neural Networks with Minimum Over-parameterization. (arXiv:2205.10217v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.10217](http://arxiv.org/abs/2205.10217)

    本文提供了一个最小超参数化的深度神经网络中最小的NTK特征值的下界，具有次线性层宽的深层神经网络是强大的记忆器和优化器，只要参数数量超过样本数量。

    

    神经切向核（NTK）已成为提供深度神经网络记忆化、优化和泛化保证的强大工具。部分学者已研究了至少一层具有$\Omega(N)$个神经元的两层和深层网络的NTK谱，其中$N$是训练样本数量。此外，越来越多的证据表明，具有次线性层宽的深层神经网络是强大的记忆器和优化器，只要参数数量超过样本数量即可。因此，一个自然的开放性问题是在这种具有挑战性的次线性设置下，NTK是否存在良好的条件。在本文中，我们肯定地回答了这个问题。我们的主要技术贡献是提供了一个深度神经网络中最小的NTK特征值的下界，即参数数量大约为$\Omega(N)$，因此神经元数量至少为$\Omega(\sqrt{N})$。为展示我们算法的适用性，我们在多项任务上进行了实证分析。

    The Neural Tangent Kernel (NTK) has emerged as a powerful tool to provide memorization, optimization and generalization guarantees in deep neural networks. A line of work has studied the NTK spectrum for two-layer and deep networks with at least a layer with $\Omega(N)$ neurons, $N$ being the number of training samples. Furthermore, there is increasing evidence suggesting that deep networks with sub-linear layer widths are powerful memorizers and optimizers, as long as the number of parameters exceeds the number of samples. Thus, a natural open question is whether the NTK is well conditioned in such a challenging sub-linear setup. In this paper, we answer this question in the affirmative. Our key technical contribution is a lower bound on the smallest NTK eigenvalue for deep networks with the minimum possible over-parameterization: the number of parameters is roughly $\Omega(N)$ and, hence, the number of neurons is as little as $\Omega(\sqrt{N})$. To showcase the applicability of our N
    
[^51]: 图注意力回顾

    Graph Attention Retrospective. (arXiv:2202.13060v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.13060](http://arxiv.org/abs/2202.13060)

    图注意力网络是一种能够从邻居节点的特征中聚合信息的模型，通过对上下文随机块模型的节点分类问题进行研究，证明了在“易”区间内，它能够区分跨类和内类边缘并维护重要边缘的权重。

    

    基于图的学习是机器学习中快速发展的一个子领域，应用于社交网络、引文网络和生物信息学。其中最流行的模型之一是图注意力网络。它们被引入使节点能够以非统一的方式从邻居节点的特征中聚合信息，与简单的图卷积不同，后者不能区分节点的邻居。本文在理论上研究了图注意网络的行为。我们对上下文随机块模型的节点分类问题证明了图注意机制的多个性能结果。在该模型中，节点特征来自于高斯混合模型，边缘来自于随机块模型。我们证明，在“易”区间内，高斯分布均值之间的距离足够大时，图注意力可以区分跨类和内类边缘。因此，它维护了重要边缘的权重。

    Graph-based learning is a rapidly growing sub-field of machine learning with applications in social networks, citation networks, and bioinformatics. One of the most popular models is graph attention networks. They were introduced to allow a node to aggregate information from features of neighbor nodes in a non-uniform way, in contrast to simple graph convolution which does not distinguish the neighbors of a node. In this paper, we theoretically study the behaviour of graph attention networks. We prove multiple results on the performance of the graph attention mechanism for the problem of node classification for a contextual stochastic block model. Here, the node features are obtained from a mixture of Gaussians and the edges from a stochastic block model. We show that in an "easy" regime, where the distance between the means of the Gaussians is large enough, graph attention is able to distinguish inter-class from intra-class edges. Thus it maintains the weights of important edges and s
    
[^52]: 自适应鲁棒的多任务学习

    Adaptive and Robust Multi-Task Learning. (arXiv:2202.05250v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.05250](http://arxiv.org/abs/2202.05250)

    本文提出一系列自适应方法，能够同时处理多任务学习的相似性和差异性，并具有统计保证和鲁棒性。

    

    本论文研究了解决从不同来源收集的多个数据集并对每个数据集学习一个模型的多任务学习问题。我们提出了一系列自适应方法，自动利用任务之间的相似性，同时处理它们之间的差异。我们证明了这些方法的统计保证，并证明它们对异常任务具有鲁棒性。通过合成和实际数据集的数值实验，证明了我们的新方法的功效。

    We study the multi-task learning problem that aims to simultaneously analyze multiple datasets collected from different sources and learn one model for each of them. We propose a family of adaptive methods that automatically utilize possible similarities among those tasks while carefully handling their differences. We derive sharp statistical guarantees for the methods and prove their robustness against outlier tasks. Numerical experiments on synthetic and real datasets demonstrate the efficacy of our new methods.
    
[^53]: 深度判别到核生成网络的定标推断方法

    Deep Discriminative to Kernel Generative Networks for Calibrated Inference. (arXiv:2201.13001v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.13001](http://arxiv.org/abs/2201.13001)

    该论文提出了将判别网络转换为生成网络的方法，用高斯核替换多面体中的仿射函数来生成模型，解决了内部和外部数据校准问题，并在 CIFAR-10，CIFAR-100 和 SVHN 等基准数据集上测试了方法的有效性。

    

    判别与生成网络在人工智能和自然智能的研究中都有其重要性，我们提出了一种将二者相结合的方法，将深度判别网络转换为核生成网络。我们将深度模型视为广义的划分规则，并使用高斯核替换由训练数据构成的多面体中的仿射函数，来获得生成模型。实验证明了我们方法的有效性。

    The fight between discriminative versus generative goes deep, in both the study of artificial and natural intelligence. In our view, both camps have complementary values. So, we sought to synergistically combine them. Here, we propose a methodology to convert deep discriminative networks to kernel generative networks. We leveraged the fact that deep models, including both random forests and deep networks, learn internal representations which are unions of polytopes with affine activation functions to conceptualize them both as generalized partitioning rules. We replace the affine function in each polytope populated by the training data with Gaussian kernel that results in a generative model. Theoretically, we derive the conditions under which our generative models are a consistent estimator of the corresponding class conditional density. Moreover, our proposed models obtain well calibrated posteriors for in-distribution, and extrapolate beyond the training data to handle out-of-distrib
    
[^54]: 一种鲁棒而灵活的椭圆分布混合缺失数据EM算法

    A Robust and Flexible EM Algorithm for Mixtures of Elliptical Distributions with Missing Data. (arXiv:2201.12020v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2201.12020](http://arxiv.org/abs/2201.12020)

    本研究提出了一种鲁棒且灵活的EM算法，用于处理缺失数据的混合椭圆分布，解决了非高斯数据插补的问题。

    

    本文解决了噪声和非高斯数据缺失数据插补的问题。Gaussian混合模型的期望极大算法已经被证明在一定程度上比基于k近邻或基于多重方程链的插补方法表现更好。但是，Gaussian混合模型对于异构数据是非鲁棒的，当数据受到离群点或遵循非高斯分布的影响时会导致性能估计较差。为了克服这个问题，本文研究了一种新的EM算法，用于椭圆分布的混合物，具有处理潜在缺失数据的特性。本文表明，这个问题可以归结为在通用条件下（即每个样本都是从一个可能不同的椭圆分布混合物中抽取的），估计angular Gaussian分布的混合物。

    This paper tackles the problem of missing data imputation for noisy and non-Gaussian data. A classical imputation method, the Expectation Maximization (EM) algorithm for Gaussian mixture models, has shown interesting properties when compared to other popular approaches such as those based on k-nearest neighbors or on multiple imputations by chained equations. However, Gaussian mixture models are known to be non-robust to heterogeneous data, which can lead to poor estimation performance when the data is contaminated by outliers or follows non-Gaussian distributions. To overcome this issue, a new EM algorithm is investigated for mixtures of elliptical distributions with the property of handling potential missing data. This paper shows that this problem reduces to the estimation of a mixture of Angular Gaussian distributions under generic assumptions (i.e., each sample is drawn from a mixture of elliptical distributions, which is possibly different for one sample to another). In that case
    
[^55]: 多个领域下通用的质心对齐和重构损失最小化领域归纳论文翻译

    Barycentric-alignment and reconstruction loss minimization for domain generalization. (arXiv:2109.01902v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.01902](http://arxiv.org/abs/2109.01902)

    本论文提出了一个新的理论上界，它不包含双重依赖性的术语，在领域归纳中优化了未见域的风险上界。

    

    本文推进了机器学习中领域归纳（DG）理论和实践。我们考虑了典型的DG设置，其中假设由表示映射和标记函数组成。在这个设置中，大多数流行的DG方法旨在通过最小化未见域中的分类风险的已知上界共同学习表示和标记函数。然而，在实践中，基于这个理论上界的方法忽略了一个由于其对表示映射和未知最优标记函数的双重依赖关系而无法直接优化的术语。为了弥合理论与实践之间的差距，我们引入了一个新的上界，它不包含这种双重依赖性的术语，从而产生了一个可以完全优化的未见域风险上界。我们的推导利用了将最优传输度量与信息相连的经典和最近的传输不等式。

    This paper advances the theory and practice of Domain Generalization (DG) in machine learning. We consider the typical DG setting where the hypothesis is composed of a representation mapping followed by a labeling function. Within this setting, the majority of popular DG methods aim to jointly learn the representation and the labeling functions by minimizing a well-known upper bound for the classification risk in the unseen domain. In practice, however, methods based on this theoretical upper bound ignore a term that cannot be directly optimized due to its dual dependence on both the representation mapping and the unknown optimal labeling function in the unseen domain. To bridge this gap between theory and practice, we introduce a new upper bound that is free of terms having such dual dependence, resulting in a fully optimizable risk upper bound for the unseen domain. Our derivation leverages classical and recent transport inequalities that link optimal transport metrics with informati
    
[^56]: 相互作用微粒平均场方程中的相互作用核可辨识性研究

    Identifiability of interaction kernels in mean-field equations of interacting particles. (arXiv:2106.05565v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.05565](http://arxiv.org/abs/2106.05565)

    本研究探索了相互作用微粒平均场方程中相互作用核的可辨识性问题，并确定了二次损失函数仅在特定的函数空间中才具有唯一的最小化器。此外，对于计算实践，研究证明了反问题的病态性质，需要进行正则化处理。

    

    本研究探讨了相互作用微粒或代理人的平均场方程中相互作用核的可辨识性问题，这是各种科学和工程领域日益关注的领域。主要关注点在于确定数据相关函数空间，其中二次损失函数拥有唯一的最小化器。我们考虑了两个数据自适应的$L^2$空间：一个是由数据自适应权重衡量的，另一个使用勒贝格测度。在每个$L^2$空间中，我们表明可辨识性的函数空间是与求积分算子相关的RKHS闭包。与之前的研究相辅相成，本研究完成了具有有限或无限微粒的相互作用微粒系统的可辨识性的全面描述，突显了这两种情况之间的关键差异。此外，可辨识性分析对于计算实践具有重要影响。它表明反问题是病态的，需要正则化处理。

    This study examines the identifiability of interaction kernels in mean-field equations of interacting particles or agents, an area of growing interest across various scientific and engineering fields. The main focus is identifying data-dependent function spaces where a quadratic loss functional possesses a unique minimizer. We consider two data-adaptive $L^2$ spaces: one weighted by a data-adaptive measure and the other using the Lebesgue measure. In each $L^2$ space, we show that the function space of identifiability is the closure of the RKHS associated with the integral operator of inversion.  Alongside prior research, our study completes a full characterization of identifiability in interacting particle systems with either finite or infinite particles, highlighting critical differences between these two settings. Moreover, the identifiability analysis has important implications for computational practice. It shows that the inverse problem is ill-posed, necessitating regularization.
    
[^57]: 过拟合、交叉验证、正则化、装袋法和提升法背后的理论：教程

    The Theory Behind Overfitting, Cross Validation, Regularization, Bagging, and Boosting: Tutorial. (arXiv:1905.12787v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1905.12787](http://arxiv.org/abs/1905.12787)

    该论文介绍了过拟合、交叉验证、正则化、装袋法和提升法的相关理论，包括定义和具体实现，并给出了AdaBoost的泛化误差上限的具体计算方法。

    

    在这篇教程性的论文中，我们首先定义了随机变量和分类/预测模型的均方误差、方差、协方差和偏差。然后，我们利用Stein的无偏风险估计器（SURE）制定了模型的真实和泛化误差，包括训练和验证/测试实例。利用得到的真实和泛化误差，我们定义了过拟合、欠拟合和泛化。我们介绍了交叉验证和两个著名的例子，即K倍交叉验证和留一法交叉验证。我们简要介绍了广义交叉验证，然后转向正则化，在这里我们再次使用SURE。我们对$\ell_2$和$\ell_1$范数正则化进行了研究。然后，我们展示了自举聚合（bagging）如何降低估计方差。我们介绍了提升法，特别是AdaBoost，并解释了它作为一个加性模型和最大间隔模型（即支持向量机（SVM））的原理。给出了AdaBoost的泛化误差上限，包括指数损失和0-1损失。最后，我们总结了教程的主要内容。

    In this tutorial paper, we first define mean squared error, variance, covariance, and bias of both random variables and classification/predictor models. Then, we formulate the true and generalization errors of the model for both training and validation/test instances where we make use of the Stein's Unbiased Risk Estimator (SURE). We define overfitting, underfitting, and generalization using the obtained true and generalization errors. We introduce cross validation and two well-known examples which are $K$-fold and leave-one-out cross validations. We briefly introduce generalized cross validation and then move on to regularization where we use the SURE again. We work on both $\ell_2$ and $\ell_1$ norm regularizations. Then, we show that bootstrap aggregating (bagging) reduces the variance of estimation. Boosting, specifically AdaBoost, is introduced and it is explained as both an additive model and a maximum margin model, i.e., Support Vector Machine (SVM). The upper bound on the gener
    
[^58]: 特征值和广义特征值问题：教程

    Eigenvalue and Generalized Eigenvalue Problems: Tutorial. (arXiv:1903.11240v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1903.11240](http://arxiv.org/abs/1903.11240)

    本文是一篇阐述特征值和广义特征值问题的教程。特征值和广义特征值问题可用于各种机器学习算法中，如主成分分析和Fisher判别分析等。

    

    本文是特征值和广义特征值问题的教程。我们首先介绍了特征值问题、特征值分解（谱分解）和广义特征值问题。然后，我们提到了导致特征值和广义特征值问题的优化问题。我们还提供了机器学习中的例子，包括主成分分析、核监督主成分分析和Fisher判别分析，这些方法都会导致特征值和广义特征值问题。最后，我们介绍了解决特征值和广义特征值问题的方法。

    This paper is a tutorial for eigenvalue and generalized eigenvalue problems. We first introduce eigenvalue problem, eigen-decomposition (spectral decomposition), and generalized eigenvalue problem. Then, we mention the optimization problems which yield to the eigenvalue and generalized eigenvalue problems. We also provide examples from machine learning, including principal component analysis, kernel supervised principal component analysis, and Fisher discriminant analysis, which result in eigenvalue and generalized eigenvalue problems. Finally, we introduce the solutions to both eigenvalue and generalized eigenvalue problems.
    
[^59]: 基于类结构的最优传输恢复界限: 一种范数求和正则化框架

    Recovery Bounds on Class-Based Optimal Transport: A Sum-of-Norms Regularization Framework. (arXiv:1903.03850v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1903.03850](http://arxiv.org/abs/1903.03850)

    该论文提出了一个基于范数求和正则化项的凸性最优传输程序，在几何假设条件下可证明恢复基础类结构。该论文还提供了一种加速的近端算法，并提出了一种新的唯一性优化方式。实验表明，新的正则化程序不仅可以更好地保留数据中的类结构，还可以在数据几何形状方面提供额外的鲁棒性。

    

    我们开展了一个新的理论框架，用于理解尊重类结构的最优传输方案。为此，我们提出了一个带有范数求和正则化项的凸性最优传输程序，该程序在几何假设条件下可证明恢复基础类结构。此外，我们推导出一种加速的近端算法，该算法具有闭式投影和近端操作符方案，从而为计算最优传输计划提供了更可扩展的算法。我们提供了一种新的唯一性优化方式，即使在缺乏强凸性的情况下，也可得到最优解。我们的实验表明，与以前的正则化程序相比，新的正则化程序不仅可以更好地保留数据中的类结构，还可以在数据几何形状方面提供额外的鲁棒性。

    We develop a novel theoretical framework for understating OT schemes respecting a class structure. For this purpose, we propose a convex OT program with a sum-of-norms regularization term, which provably recovers the underlying class structure under geometric assumptions. Furthermore, we derive an accelerated proximal algorithm with a closed-form projection and proximal operator scheme, thereby affording a more scalable algorithm for computing optimal transport plans. We provide a novel argument for the uniqueness of the optimum even in the absence of strong convexity. Our experiments show that the new regularizer not only results in a better preservation of the class structure in the data but also yields additional robustness to the data geometry, compared to previous regularizers.
    

