# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Gaussian Membership Inference Privacy.](http://arxiv.org/abs/2306.07273) | 本文提出了$f$-成员推断隐私($f$-MIP)概念，并分析了似然比成员推断攻击，提出了$\mu$-高斯成员推断隐私($\mu$-GMIP)保证，同时提供了一种分析性的成员推断攻击方法，避免了训练大量影子模型。强调了方差的重要性。 |
| [^2] | [Conditional Matrix Flows for Gaussian Graphical Models.](http://arxiv.org/abs/2306.07255) | 本文为解决高斯图模型中变量的条件独立结构问题，提出了一种针对精度矩阵的$l_p$正则化的方法，并将频率学派和贝叶斯学派的优点融合在变分推理中，并引入了矩阵变量标准化流程来逼近后验。 |
| [^3] | [On the Expected Size of Conformal Prediction Sets.](http://arxiv.org/abs/2306.07254) | 该论文研究了适应性预测集的期望大小问题，提出了一种理论量化方法以及点估计和高概率区间，并在真实数据集上验证了其实用性。 |
| [^4] | [On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling.](http://arxiv.org/abs/2306.07252) | 研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性 |
| [^5] | [Deep Gaussian Mixture Ensembles.](http://arxiv.org/abs/2306.07235) | 本文介绍了一种深度高斯混合集合模型，可逼近复杂概率分布，并能够准确量化先验误差和后验误差，实验结果表明其优于最先进的不确定性量化深度学习模型。 |
| [^6] | [Convergence of mean-field Langevin dynamics: Time and space discretization, stochastic gradient, and variance reduction.](http://arxiv.org/abs/2306.07221) | 该论文研究了均场 Langevin 动力学的收敛性，并通过一个通用框架证明了考虑到有限粒子逼近误差、时间离散化和随机梯度逼近的 MFLD 在时间上一致收敛，为神经网络和 MMD 最小化等广泛学习问题提供了量化收敛速率保证。 |
| [^7] | [Benchmarking Neural Network Training Algorithms.](http://arxiv.org/abs/2306.07179) | 本文解决了神经网络训练算法基准测试中存在的三个挑战，提出了新的基准测试套件，以促进训练算法效率的进一步提高。 |
| [^8] | [General Transformation for Consistent Online Approximation Algorithms.](http://arxiv.org/abs/2306.07163) | 本文提出一个转换框架，可以将离线逼近算法转换为具有低ε-近似遗憾的在线算法，并成功应用于多种问题并实现了多项式时间的近似效果。 |
| [^9] | [Riemannian Laplace approximations for Bayesian neural networks.](http://arxiv.org/abs/2306.07158) | 本论文提出了一种基于黎曼度量的简单参数逼近后验分布方法，实验表明该方法对先验选择不过度敏感，可以较好地改善传统拉普拉斯逼近的表现。 |
| [^10] | [Diverse Projection Ensembles for Distributional Reinforcement Learning.](http://arxiv.org/abs/2306.07124) | 本文研究了分布式强化学习中多样投影集合的理论特性，提出了使用集合差异度量的算法，以促进可靠的不确定性估计。 |
| [^11] | [Analysis of the Relative Entropy Asymmetry in the Regularization of Empirical Risk Minimization.](http://arxiv.org/abs/2306.07123) | 本文分析了相对熵正则化中的不对称性对经验风险最小化的影响，并引入了一种新的Type-II正则化来允许解决方案更广泛。该分析揭示出相对熵将在ERM-RER问题中引入强烈的归纳偏差。 |
| [^12] | [Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast.](http://arxiv.org/abs/2306.07119) | 本文提出了一种基于相似度度量的通用框架，利用k最近邻的方式构建邻域，并通过平均来改进可能简单模型的预测，提高异质性时间序列的预测准确性。 |
| [^13] | [Unveiling the Hessian's Connection to the Decision Boundary.](http://arxiv.org/abs/2306.07104) | Hessian的前几个特征向量描述了神经网络学到的决策边界，异常值数量与决策边界的复杂性成正比，这启发了一种新的泛化度量和边界估计技术。 |
| [^14] | [Latent Dynamical Implicit Diffusion Processes.](http://arxiv.org/abs/2306.07077) | 本文提出了一种新型的潜在变量模型 LDIDPs，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本，相较于最先进的顺序生成模型有更好的性能。 |
| [^15] | [Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals.](http://arxiv.org/abs/2306.07071) | 这篇论文提出了一种名为ω-UCB的新上置信区间抽样策略，使用不对称置信区间以更准确、更紧密地估计奖励成本比，解决了现有预算多臂老虎机问题策略存在的问题，并在合成和真实环境中表现出色。 |
| [^16] | [Prediction Algorithms Achieving Bayesian Decision Theoretical Optimality Based on Decision Trees as Data Observation Processes.](http://arxiv.org/abs/2306.07060) | 本文提出了一种基于决策树作为数据观察过程的贝叶斯决策理论最优预测算法，并通过马尔可夫链模型解决了求解分割轴组合的问题。 |
| [^17] | [A Distribution Optimization Framework for Confidence Bounds of Risk Measures.](http://arxiv.org/abs/2306.07059) | 本文提出了一个分布优化框架，使用两种基于经验分布的估计方案，可以显著提高各种风险度量的置信区间。 |
| [^18] | [Kernel Random Projection Depth for Outlier Detection.](http://arxiv.org/abs/2306.07056) | 本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。 |
| [^19] | [Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained Markov Decision Processes.](http://arxiv.org/abs/2306.07001) | 本文提出了一种创新的模型驱动的双重算法OptAug-CMDP，用于约束马尔可夫决策过程（CMDPs），解决了原先算法中安全性问题的缺陷，证明了其遗憾值优秀。 |
| [^20] | [Can Forward Gradient Match Backpropagation?.](http://arxiv.org/abs/2306.06968) | 本文研究通过从小型局部辅助网络反馈中获得的梯度偏向更有前途的方向，提高了前向梯度算法的性能。 |
| [^21] | [High-precision interpolation of stellar atmospheres with a deep neural network using a 1D convolutional auto encoder for feature extraction.](http://arxiv.org/abs/2306.06938) | 一种高效、准确、适用于恒星模型大气的插值方法，采用深度神经网络和一维卷积自编码器技术，能够提取非线性关系从而实现更加精细的预测。 |
| [^22] | [MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time Series Forecasting.](http://arxiv.org/abs/2306.06895) | 提出了一种名为MPPN的新型深度学习网络，其通过构建上下文感知的多分辨率语义单元和采用多周期模式挖掘来捕获关键模式，然后使用通道自适应模块以考虑多变量对不同模式的感知，用于长期时间序列预测。 |
| [^23] | [Strong consistency and optimality of spectral clustering in symmetric binary non-uniform Hypergraph Stochastic Block Model.](http://arxiv.org/abs/2306.06845) | 论文提出了非均匀超图随机块模型下谱聚类的强一致性信息理论阈值，并且在该阈值以下给出估计标签的期望“不匹配率”上界。并且，单步谱算法可以在超过该阈值时非常高的概率正确地给定每个顶点的标签。 |
| [^24] | [Provably Efficient Bayesian Optimization with Unbiased Gaussian Process Hyperparameter Estimation.](http://arxiv.org/abs/2306.06844) | 针对贝叶斯优化中常见的数据偏差问题，提出了一种新方法，在无需事先知道真实高斯过程超参数的情况下，使用多臂老虎机技术向BO过程中添加随机数据点，采用新的训练损失函数进行超参数估计，以达到次线性收敛到全局最优解的目的。 |
| [^25] | [Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds.](http://arxiv.org/abs/2306.06836) | 本文解决了强化学习中当奖励呈“重尾”分布时的问题，提出了第一种处理这种情况的实例相关算法，并得到了极小最大化的遗憾界。 |
| [^26] | [Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction.](http://arxiv.org/abs/2306.06804) | 本文介绍了为美洲土著语言创建机器翻译系统面临的挑战以及最新的进展和发现。缺乏平行和单语数据是其中的主要难题。 |
| [^27] | [A Penalized Poisson Likelihood Approach to High-Dimensional Semi-Parametric Inference for Doubly-Stochastic Point Processes.](http://arxiv.org/abs/2306.06756) | 本研究提出了一种对于双随机点过程的估计方法，该方法在进行协变量效应估计时非常高效，不需要强烈的限制性假设，且在理论和实践中均表现出了良好的信度保证和效能。 |
| [^28] | [Differentially Private Conditional Independence Testing.](http://arxiv.org/abs/2306.06721) | 本文介绍了两个差分隐私条件独立性检验方法，可适用于Z为连续值的一般情况。 |
| [^29] | [On the Confidence Intervals in Bioequivalence Studies.](http://arxiv.org/abs/2306.06698) | 本文阐明了在生物等效性测试中，用$100(1-2\alpha)\%$置信区间的方法进行检验只有在TOST中两个单侧检验“等尾”时才能得到正确结果，并且提出了一种比标准方法更详细的检验方法。 |
| [^30] | [Efficient Learning of Minimax Risk Classifiers in High Dimensions.](http://arxiv.org/abs/2306.06649) | 提出了一种针对高维数据中的极小化极大风险分类器的有效学习算法，具有特征选择和提供有关分类器性能的最坏情况下的错误概率的优点。 |
| [^31] | [On Kinetic Optimal Probability Paths for Generative Models.](http://arxiv.org/abs/2306.06626) | 本文研究高斯概率路径的动力学最佳成员，发现动能在这样的路径空间上可以通过单一的一维标量函数来整合数据，从而得到了提高研究所需的粒子轨迹简单性的方法。 |
| [^32] | [Variational Imbalanced Regression.](http://arxiv.org/abs/2306.06599) | 本文提出的变分不平衡回归（VIR）模型通过引入Probabilistic Reweighting方法，可以在不平衡回归方面表现良好，并自然产生合理的不确定性估计。 |
| [^33] | [Fast, Distribution-free Predictive Inference for Neural Networks with Coverage Guarantees.](http://arxiv.org/abs/2306.06582) | 该论文提出了一种新颖、计算效率高的预测推断算法，不需要数据做出分布假设。对于交换数据，通过使用$(\epsilon, \delta)$-差分隐私训练一个神经网络并围绕差别私有的神经网络估计进行线性逼近，该方法已被证明具有严格的覆盖保证。 |
| [^34] | [Importance Sparsification for Sinkhorn Algorithm.](http://arxiv.org/abs/2306.06581) | Spar-Sink是一种重要性稀疏化方法，能够有效近似熵正则化最优传输和不平衡最优传输问题，并且在实验中表现优异。 |
| [^35] | [Local-to-global Perspectives on Graph Neural Networks.](http://arxiv.org/abs/2306.06547) | 本文提出了局部到全局的图神经网络模型，包括不变图网络、局部信息传递神经网络和全局图变换器，并研究其收敛性质和在图粗化中的应用。 |
| [^36] | [A Probabilistic Framework for Modular Continual Learning.](http://arxiv.org/abs/2306.06545) | 本文提出了一种名为PICLE的模块化增量学习框架，利用概率模型快速计算每个组合的适应度来加速搜索，是第一个可以实现不同类型的转移的模块化增量学习算法。 |
| [^37] | [Partial Identifiability for Domain Adaptation.](http://arxiv.org/abs/2306.06510) | 本论文提出了一种针对无监督领域自适应的部分可识别性方法，通过依赖跨域因果机制的最小改变属性，在保持特定组分跨域不变的前提下最小化分布转移的不必要影响。 |
| [^38] | [Sufficient Identification Conditions and Semiparametric Estimation under Missing Not at Random Mechanisms.](http://arxiv.org/abs/2306.06443) | 本论文针对缺失非随机数据的问题进行研究，在更加灵活的假设条件下，建立了对完整数据的充分识别条件和半参数估计方法。 |
| [^39] | [Functional Causal Bayesian Optimization.](http://arxiv.org/abs/2306.06409) | 提出功能因果贝叶斯优化（fCBO）方法用于已知因果图中优化目标变量的干预方法。该方法扩展了CBO方法族，使用高斯过程对未知目标进行建模，在再生核希尔伯特空间中定义输入并计算向量值函数之间的距离。演示了在社交网络中的在线广告活动和合成应用中该方法的优点。 |
| [^40] | [Personalized Graph Federated Learning with Differential Privacy.](http://arxiv.org/abs/2306.06399) | 本文提出了一种差分隐私下的个性化图像联邦学习框架，它能够协同学习设备或集群特定的模型，保护每个设备的隐私并提高学习效果。 |
| [^41] | [Any-dimensional equivariant neural networks.](http://arxiv.org/abs/2306.06327) | 该论文提出了一个新的方法，利用代数拓扑中的表示稳定性，可以定义出一个可以以任意维度为输入的等变神经网络。这种方法使用方便，只需指定网络架构和等变性的组，且在任何训练过程中都可以使用。 |
| [^42] | [Differentially private sliced inverse regression in the federated paradigm.](http://arxiv.org/abs/2306.06324) | 本文提出了以联邦学习为基础的差分隐私切片逆回归方法，通过协作估计足够维数的降维子空间以保护敏感数据不被暴露，同时采用多种扰动策略保障差分隐私，还能自然地结合协作变量筛选步骤以有效处理高维数据。 |
| [^43] | [Optimal Heterogeneous Collaborative Linear Regression and Contextual Bandits.](http://arxiv.org/abs/2306.06291) | 本文提出了一种新的估计器MOLAR，它利用协同线性回归和上下文臂问题中的稀疏异质性来提高估计精度，并且相比独立方法具有更好的表现。 |
| [^44] | [Energy-Dissipative Evolutionary Deep Operator Neural Networks.](http://arxiv.org/abs/2306.06281) | 能量耗散进化深度算子神经网络是一种运算学习神经网络，可为一类偏微分方程提供数值解并保留其物理特性，通过支路网络编码不同的输入函数，干线网络评估输出函数，经过训练可生成运算符近似解。 |
| [^45] | [Using Auxiliary Data to Boost Precision in the Analysis of A/B Tests on an Online Educational Platform: New Data and New Results.](http://arxiv.org/abs/2306.06273) | A/B测试的小样本和处理效果过小导致效应估计过于不精密，本研究利用历史用户的丰富日志数据的机器学习模型来提高技术，解决了这个问题，有效提高了A/B测试的能力和统计精度。 |
| [^46] | [Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints.](http://arxiv.org/abs/2306.06265) | 本文研究了强化学习中实现保守探索的问题，提出了名为StepMix的算法，利用现有的安全基线策略平衡开发和探索，同时保证每个回合不违反保守限制，并且能够在不受限制的情况下达到接近最优的后悔量级。 |
| [^47] | [Spectral gap-based deterministic tensor completion.](http://arxiv.org/abs/2306.06262) | 本文界定了Poisson loss和原子范数最小化两种张量补全方法的解的泛化误差，提供了更紧的界限，针对$r$的依赖性从之前的$r^{2(t-1)(t^2-t-1)}$改进为$r^{2(t-1)(3t-5)}$。根据采样稀疏模式的谱间隔控制误差界限，同时证明了原子张量范数的几个新属性，但原子范数最小化存在计算挑战。 |
| [^48] | [Vector Summaries of Persistence Diagrams for Permutation-based Hypothesis Testing.](http://arxiv.org/abs/2306.06257) | 研究了基于排列的假设检验，提出了持久图向量摘要方法。 |
| [^49] | [Feature Programming for Multivariate Time Series Prediction.](http://arxiv.org/abs/2306.06252) | 该论文提出了一种基于特征编程的多元时间序列预测框架，能够生成大量预测特征，同时允许用户以最小的工作量结合他们的归纳偏差。该框架基于细粒度的轨迹增量，引入了新型自旋气体动力学伊辛模型，并提供了一个简约的算子集来总结多元时间序列。 |
| [^50] | [Online Learning with Set-Valued Feedback.](http://arxiv.org/abs/2306.06247) | 本文研究了一种在线多类分类的变体，其中使用集合型反馈。通过引入新的组合维度，该论文表明确定性和随机性的在线可学习性在实现设置下不等价，并将在线多标签排名和在线多标签分类等实际学习设置作为其特定实例。 |
| [^51] | [A Unified Model and Dimension for Interactive Estimation.](http://arxiv.org/abs/2306.06184) | 该论文提出了交互式估计的统一学习框架，引入组合度量差异维度来捕捉模型的可学习性，提出了多项式的遗憾和PAC泛化界限的算法，并统一了统计查询学习和结构化赌博问题。 |
| [^52] | [Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks.](http://arxiv.org/abs/2306.06155) | 本文提出了一种连续时间网络表示学习框架，涵盖核平滑的强度函数估计、最小化强度重构误差的投影学习和归纳构造节点表示。这种表示保留了网络结构和时间一致性。 |
| [^53] | [Forecasting Electric Vehicle Charging Station Occupancy: Smarter Mobility Data Challenge.](http://arxiv.org/abs/2306.06142) | 该论文针对电动汽车充电行为制定更准确的预测模型，利用智慧出行数据挑战开发分层预测方法来预测EV充电站占用率，取得了很好的结果，为电动出行的能源供应商和用户提供了宝贵的参考。 |
| [^54] | [Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning.](http://arxiv.org/abs/2306.04815) | 本文通过研究SGD训练损失中的尖峰现象，提出了“投石机”优化现象，通过增加与真实预测器的平均梯度外积对齐来促进特征学习，并证明较小的批量大小可提高泛化性能。 |
| [^55] | [End-to-End Learning for Stochastic Optimization: A Bayesian Perspective.](http://arxiv.org/abs/2306.04174) | 本文提出了一种基于贝叶斯视角的随机优化端到端学习方法，为经验风险最小化和分布式鲁棒优化问题提供新的端到端学习算法，方式主要是训练决策映射。该方法在合成的newsvendor问题和经济分配问题上均表现出显著的效果，同时也发现决策映射神经网络架构对测试性能的影响很大。 |
| [^56] | [Decentralized SGD and Average-direction SAM are Asymptotically Equivalent.](http://arxiv.org/abs/2306.02913) | 分散SGD和平均方向SAM在渐近意义下是等价的，D-SGD表现出梯度平滑效应和锐度正则化效应，而且可以提高后验评估，并证明了潜在的泛化能力 |
| [^57] | [Diffusion Self-Guidance for Controllable Image Generation.](http://arxiv.org/abs/2306.00986) | 本论文提出了一种扩散自导方法，通过引导扩散模型的内部表示来提供对生成图像的更大控制，可以用于执行具有挑战性的图像操作，同时不需要额外模型或训练。 |
| [^58] | [Stability, Generalization and Privacy: Precise Analysis for Random and NTK Features.](http://arxiv.org/abs/2305.12100) | 本论文研究了ERM训练模型对抗强大黑盒攻击的安全问题，并通过两个指标量化模型安全性：单个样本的稳定性和查询与原始数据特征的对齐。在研究中，通过研究RF和NTK回归，证明随着泛化能力的提高，隐私保护可以得到加强。 |
| [^59] | [Energy-guided Entropic Neural Optimal Transport.](http://arxiv.org/abs/2304.06094) | 本论文提出了一种新的方法，将能量基础模型和熵正则化最优输运结合起来，以解决生成建模问题。我们在2D情景和图像到图像翻译问题中验证了该方法的适用性。 |
| [^60] | [Correcting for Selection Bias and Missing Response in Regression using Privileged Information.](http://arxiv.org/abs/2303.16800) | 该研究提出了一种基于特权信息的重复回归方法，可用于在回归模型中校正选择偏差和缺失响应，这种方法易于实现且表现良好。 |
| [^61] | [Convergence of Momentum-Based Heavy Ball Method with Batch Updating and/or Approximate Gradients.](http://arxiv.org/abs/2303.16241) | 本文研究了含有批量更新和/或近似梯度的动量重球法的收敛性，由于采用了简化的梯度计算方法，大大减少了计算消耗，同时仍能保证收敛性。 |
| [^62] | [Generalized Data Thinning Using Sufficient Statistics.](http://arxiv.org/abs/2303.12931) | 本研究发展了一种基于充分统计量的通用策略，通过松弛求和要求并仅要求函数重构随机变量X，进一步推广了数据稀化方法，扩展了可进行稀化的分布族，并统一了样本分裂和数据稀化。 |
| [^63] | [Finding Competence Regions in Domain Generalization.](http://arxiv.org/abs/2303.09989) | 该论文提出了一个“学习拒绝”框架来解决领域泛化中的默默失败问题。通过预测可信度，该方法在测试分布与训练分布不同的情况下接受超出分布的数据，以识别能力区域。研究发现，通过不同的学习表示衡量无能，增加无能得分会预示着降低准确性。 |
| [^64] | [On the Robustness of Text Vectorizers.](http://arxiv.org/abs/2303.07203) | 本文研究了文本向量化技术中的鲁棒性问题，并证明了流行的嵌入方案具有Hamming距离意义上的鲁棒性。本研究提供了这些方法的定量边界，并展示了其中的常数受文档长度的影响。 |
| [^65] | [DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference.](http://arxiv.org/abs/2303.06171) | 本文提出了一种新的DP-Fast MH算法，用于大规模贝叶斯推断，具有精确、快速和隐私保护的特点。 |
| [^66] | [Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation.](http://arxiv.org/abs/2302.11294) | 提出了一种新的方法扩展了VAE模型容量，采用无限混合的非对称拉普拉斯分布作为解码器，具有分布拟合能力和调整数据隐私级别的优越性。 |
| [^67] | [SGD with AdaGrad Stepsizes: Full Adaptivity with High Probability to Unknown Parameters, Unbounded Gradients and Affine Variance.](http://arxiv.org/abs/2302.08783) | 本文提供了针对 AdaGrad 步幅下的SGD算法的更加全面且无限制性的分析，支持多种模型，可以在高概率下处理未知参数和无界梯度。 |
| [^68] | [Adversarial Rewards in Universal Learning for Contextual Bandits.](http://arxiv.org/abs/2302.07186) | 本文研究了在上下文Bandits中学习的基本极限，给出了关于可学习的上下文过程和通用一致性算法的特性，并讨论了对抗奖励下的乐观通用一致性学习的不可能性。 |
| [^69] | [Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space.](http://arxiv.org/abs/2302.06807) | 本文提出了一种大间隔分类器，它使用浑拟圆决策边界可以优化测地凸优化问题，实验结果表明其竞争性能优越。 |
| [^70] | [Explainable Performance: Measuring the Driving Forces of Predictive Performance.](http://arxiv.org/abs/2212.05866) | XPER方法能衡量输入特征对模型预测性能的具体贡献，并可用于处理异质性问题，构建同质化个体群体，从而提高预测精度。 |
| [^71] | [Reconstructing Training Data from Model Gradient, Provably.](http://arxiv.org/abs/2212.03714) | 通过单个梯度查询可重构训练数据，存在隐私泄露威胁。 |
| [^72] | [Linear Causal Disentanglement via Interventions.](http://arxiv.org/abs/2211.16467) | 本文探讨了线性潜在因果模型中的因果分离问题，指出对于识别性干预数据是必要的，而每个潜在变量的单一干预就足够了。 |
| [^73] | [Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression.](http://arxiv.org/abs/2211.07484) | 该论文研究了一种带有资源线性约束的上下文幸存者问题的变种，提出了一种新的算法，该算法简单、计算效率高，同时能够实现较低的后悔。此外，当某些约束被违反时，算法在统计上是最优的。 |
| [^74] | [MARS: Meta-Learning as Score Matching in the Function Space.](http://arxiv.org/abs/2210.13319) | 本文提出了一种新的元学习方法，通过在函数空间中执行推理，从而避免了指定高维神经网络参数的先验分布族时的限制，可以无缝获取和表示复杂的先验知识。 |
| [^75] | [The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers.](http://arxiv.org/abs/2210.06313) | 本文研究了使用变压器模型的机器学习模型中激活图的稀疏现象，发现在不同层数的变压器配置和其他体系结构中都出现了稀疏现象。 |
| [^76] | [Meta-Learning Priors for Safe Bayesian Optimization.](http://arxiv.org/abs/2210.00762) | 本文提出了一种数据驱动方法，通过元学习先验从离线数据中实现安全的贝叶斯优化，同时开发一种新的框架以数据驱动的方式选择符合安全要求的先验，结果表明，相比于基准方法，元学习先验加快了安全贝叶斯优化的收敛速度并改进了整体性能。 |
| [^77] | [SoccerCPD: Formation and Role Change-Point Detection in Soccer Matches Using Spatiotemporal Tracking Data.](http://arxiv.org/abs/2206.10926) | SoccerCPD是一个新的足球比赛变点检测框架，旨在将足球比赛中的策略意图阵型和角色变化与临时变化区分开来。该框架的两步变点检测在领域专家注释基础上进行验证，结果显示它可以准确检测战术变化并估计每秒的阵型和角色分配。 |
| [^78] | [On the fast convergence of minibatch heavy ball momentum.](http://arxiv.org/abs/2206.07553) | 本文研究了一种随机Kaczmarz算法，使用小批量和重球动量进行加速，在二次优化问题中保持快速收敛率。 |
| [^79] | [Differentiable and Transportable Structure Learning.](http://arxiv.org/abs/2206.06354) | D-Struct是一种可微和可传输的结构学习方法，通过新颖的架构和损失函数使得结构可以在同一领域的不同数据集中传输，比NOTEARS和其他最先进的方法具有更好的性能。 |
| [^80] | [Federated Offline Reinforcement Learning.](http://arxiv.org/abs/2206.05581) | 本文提出了一种联邦离线强化学习算法，可以处理医疗机构间数据共享的隐私限制和异质性问题，同时提供了通信效率和隐私保护性。该算法的样本复杂度证明以及在现实医学数据集上的模拟实验结果表明了其有效性和效率。 |
| [^81] | [Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models.](http://arxiv.org/abs/2206.04615) | 本研究引入了Beyond the Imitation Game基准测试（BIG-bench），该测试集包含了204个各领域的难题，旨在评估当前语言模型的能力并为未来的研究提供信息和准备。 |
| [^82] | [Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression.](http://arxiv.org/abs/2205.14846) | 本文细致研究了点积核岭回归问题，针对 $m\propto d^r$ 高阶标度关系提出了精确的测试误差、偏差和方差公式。 |
| [^83] | [Quadratic models for understanding neural network dynamics.](http://arxiv.org/abs/2205.11787) | 神经二次模型可以展示出神经网络在大学习率情况下的“弹弓阶段”，并且在泛化特性上与神经网络有相似之处，是分析神经网络的有效工具。 |
| [^84] | [Transition to Linearity of General Neural Networks with Directed Acyclic Graph Architecture.](http://arxiv.org/abs/2205.11786) | 本文阐明具有任意有向无环图的神经网络，在宽度无限增大的情况下有线性转化的趋势。结果揭示了转化为线性的数学结构，并推广了一系列关于标准架构神经切向核的线性转化或恒定性的最新研究。 |
| [^85] | [Semantic Information Recovery in Wireless Networks.](http://arxiv.org/abs/2204.13366) | 本文提出了一个基于机器学习的语义通信系统SINFONY，它通过对消息进行数据减少和可靠传输来最好地保留语义，从而实现无线网络中的语义信息恢复。 |
| [^86] | [Risk budget portfolios with convex Non-negative Matrix Factorization.](http://arxiv.org/abs/2204.02757) | 采用凸非负矩阵分解的风险预算组合方法，能够产生可以解释的多头投资组合，具有优异的多样化和风险特征。 |
| [^87] | [Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation.](http://arxiv.org/abs/2203.11740) | 该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。 |
| [^88] | [Universal Regression with Adversarial Responses.](http://arxiv.org/abs/2203.05067) | 本文提出了一种通用回归算法，可针对大类非独立同分布实例序列的对抗性回应，在通用可分离指标空间上实现强一致性的通用一致性学习。 |
| [^89] | [Autoregressive based Drift Detection Method.](http://arxiv.org/abs/2203.04769) | 本研究提出一种基于自回归模型的漂移检测方法，适用于各种机器学习算法，能够在合成数据和现实数据方面表现优于现有方法。 |
| [^90] | [On Testability and Goodness of Fit Tests in Missing Data Models.](http://arxiv.org/abs/2203.00132) | 本文提供了关于缺失数据图模型的可检验性和设计拟合优度测试的新见解。 |
| [^91] | [Accelerating Primal-dual Methods for Regularized Markov Decision Processes.](http://arxiv.org/abs/2202.10506) | 本文介绍了一种新的正-对偶表述方法，结合新的插值度量，可以显著加速收敛。数值结果表明方法在多种设置下性能优越。 |
| [^92] | [Fair Active Learning: Solving the Labeling Problem in Insurance.](http://arxiv.org/abs/2112.09466) | 本文旨在解决保险行业中普遍存在的机器学习模型在数据中发现的偏见和歧视，提出了公平主动学习方法，能够在实现模型预测性能的同时保证数据公平性。 |
| [^93] | [SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking.](http://arxiv.org/abs/2109.10399) | 这个论文介绍了SubseasonalClimateUSA，这是一个用于训练和基准测试美国的亚季节预测模型的数据集。作者使用该数据集对多种模型进行了基准测试。 |
| [^94] | [A data-driven approach to beating SAA out-of-sample.](http://arxiv.org/abs/2105.12342) | 本文提出了一类分布乐观优化（DOO）模型，在外推问题上始终能够超越样本平均逼近（SAA）；然而，乐观解的鲁棒性较差且更容易受到模型错误的影响。 |
| [^95] | [A Doubly Stochastic Simulator with Applications in Arrivals Modeling and Simulation.](http://arxiv.org/abs/2012.13940) | 该论文提出了一种双重随机模拟器，结合了经典的蒙特卡罗模拟器和神经网络模拟器，用于建模、估计和模拟具有一般非平稳和多维随机到达速率的到达过程，并在高速公路交通和航空交通建模和仿真中得到应用。 |
| [^96] | [Learning to Satisfy Unknown Constraints in Iterative MPC.](http://arxiv.org/abs/2006.05054) | 本文提出了一种迭代方法来学习满足未知约束条件的控制设计方法，并通过收集的数据改进了约束条件的估计，使用MPC控制器强健地满足估计的约束条件，同时提供了稳健性和概率保证。 |
| [^97] | [Improving a State-of-the-Art Heuristic for the Minimum Latency Problem with Data Mining.](http://arxiv.org/abs/1908.10705) | 这篇论文通过利用数据挖掘技术，改进了一种基于GRASP的最小延迟问题启发式算法，取得了较好的效果，匹配或优于解的质量，在大大缩短计算时间的同时，还成功地引入了88个新的解成本值。 |

# 详细

[^1]: 高斯成员推断隐私

    Gaussian Membership Inference Privacy. (arXiv:2306.07273v1 [cs.LG])

    [http://arxiv.org/abs/2306.07273](http://arxiv.org/abs/2306.07273)

    本文提出了$f$-成员推断隐私($f$-MIP)概念，并分析了似然比成员推断攻击，提出了$\mu$-高斯成员推断隐私($\mu$-GMIP)保证，同时提供了一种分析性的成员推断攻击方法，避免了训练大量影子模型。强调了方差的重要性。

    

    我们提出了一个新的隐私概念，称为$f$-成员推断隐私($f$-MIP)，它明确考虑了在成员推断攻击威胁模型下现实对手的能力。通过这样做，$f$-MIP提供了可解释的隐私保证和改进的效用(例如更好的分类准确率)。我们对噪声随机梯度下降(SGD)的似然比成员推断攻击进行了新颖的理论分析，得到了一个参数化的$f$-MIP保证族，称为$\mu$-高斯成员推断隐私($\mu$-GMIP)。我们的分析还产生了一种分析性的成员推断攻击，与以前的方法相比具有显著优势。首先，与现有方法不同，我们的攻击不需要训练数百个影子模型来逼近似然比。其次，我们的分析攻击使得$f$-MIP的简单审计成为可能。最后，我们的分析强调了方差的重要性。

    We propose a new privacy notion called $f$-Membership Inference Privacy ($f$-MIP), which explicitly considers the capabilities of realistic adversaries under the membership inference attack threat model. By doing so $f$-MIP offers interpretable privacy guarantees and improved utility (e.g., better classification accuracy). Our novel theoretical analysis of likelihood ratio-based membership inference attacks on noisy stochastic gradient descent (SGD) results in a parametric family of $f$-MIP guarantees that we refer to as $\mu$-Gaussian Membership Inference Privacy ($\mu$-GMIP). Our analysis additionally yields an analytical membership inference attack that offers distinct advantages over previous approaches. First, unlike existing methods, our attack does not require training hundreds of shadow models to approximate the likelihood ratio. Second, our analytical attack enables straightforward auditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the importance of vario
    
[^2]: 针对高斯图模型的条件矩阵流

    Conditional Matrix Flows for Gaussian Graphical Models. (arXiv:2306.07255v1 [cs.LG])

    [http://arxiv.org/abs/2306.07255](http://arxiv.org/abs/2306.07255)

    本文为解决高斯图模型中变量的条件独立结构问题，提出了一种针对精度矩阵的$l_p$正则化的方法，并将频率学派和贝叶斯学派的优点融合在变分推理中，并引入了矩阵变量标准化流程来逼近后验。

    

    在少数观测变量中研究许多变量之间的条件独立结构是一项具有挑战性的任务。高斯图模型通过在$l_p$正则化中鼓励精度矩阵的稀疏性来解决此问题，其中$p \leq1$。然而，由于亚-$l_1$伪范数使目标高度非凸，因此大多数方法依赖于$l_1$范数。在这种情况下，频率学派方法允许优雅地计算作为收缩参数$\lambda$函数的解决方案路径。贝叶斯公式为精度矩阵引入了拉普拉斯先验，但是不同$\lambda$值的后验推断需要多次运行昂贵的吉布斯采样。我们提出了一个非常通用的框架，用于GGM的变分推理，它统一了频率学派和贝叶斯学派的优点。具体而言，我们建议用定义在s空间上的矩阵变量标准化流程来逼近后验。

    Studying conditional independence structure among many variables with few observations is a challenging task. Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through an $l_p$ regularization with $p\leq1$. However, since the objective is highly non-convex for sub-$l_1$ pseudo-norms, most approaches rely on the $l_1$ norm. In this case frequentist approaches allow to elegantly compute the solution path as a function of the shrinkage parameter $\lambda$. Instead of optimizing the penalized likelihood, the Bayesian formulation introduces a Laplace prior on the precision matrix. However, posterior inference for different $\lambda$ values requires repeated runs of expensive Gibbs samplers. We propose a very general framework for variational inference in GGMs that unifies the benefits of frequentist and Bayesian frameworks. Specifically, we propose to approximate the posterior with a matrix-variate Normalizing Flow defined on the space of s
    
[^3]: 关于适应性预测集期望大小的研究

    On the Expected Size of Conformal Prediction Sets. (arXiv:2306.07254v1 [stat.ML])

    [http://arxiv.org/abs/2306.07254](http://arxiv.org/abs/2306.07254)

    该论文研究了适应性预测集的期望大小问题，提出了一种理论量化方法以及点估计和高概率区间，并在真实数据集上验证了其实用性。

    

    虽然适应性预测器在误差频率方面具有严格的统计保证，但其预测集大小对其实际效用至关重要。不幸的是，目前缺乏有限样本分析和预测集大小的保证。为了解决这个问题，我们在分裂适应性预测框架下理论量化预测集的期望大小。因为这种精确的计算通常无法直接计算，我们进一步推导出可轻松计算的点估计和高概率区间，提供了一种描述测试和校准数据不同可能实现的期望预测集大小的实用方法。此外，我们通过对回归和分类问题的真实世界数据集进行实验证实了我们结果的实用性。

    While conformal predictors reap the benefits of rigorous statistical guarantees for their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction set under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high probability intervals that can be easily computed, providing a practical method for characterizing the expected prediction set size across different possible realizations of the test and calibration data. Additionally, we corroborate the efficacy of our results with experiments on real-world datasets, for both regression and classification problems.
    
[^4]: 非均匀抽样下网络数据中符合性预测的有效性研究

    On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])

    [http://arxiv.org/abs/2306.07252](http://arxiv.org/abs/2306.07252)

    研究发现，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则非均匀抽样下网络数据中符合性预测具有有效性，而对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性

    

    我们研究了针对常见非代表性节点采样机制下的网络数据符合性预测的性质。我们将这些采样机制解释为应用于超总体的选择规则，并在适当的选择事件条件下研究符合性预测的有效性。我们证明了，如果选择规则满足置换不变性和超总体具有联合可交换性条件，则采样子阵列在选择事件条件下是可交换的。我们的结果意味着对于与自我网络和雪球抽样相关的某些选择事件，符合性预测具有有限样本有效性。我们还表明，当数据通过图上的随机游走来采样时，加权符合性预测的变体可以对人口独立选择节点的预测集进行渐近有效的预测。

    We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
    
[^5]: 深度高斯混合集合模型

    Deep Gaussian Mixture Ensembles. (arXiv:2306.07235v1 [stat.ML])

    [http://arxiv.org/abs/2306.07235](http://arxiv.org/abs/2306.07235)

    本文介绍了一种深度高斯混合集合模型，可逼近复杂概率分布，并能够准确量化先验误差和后验误差，实验结果表明其优于最先进的不确定性量化深度学习模型。

    

    本文介绍了一种新颖的概率深度学习技术，称为深度高斯混合集合 (DGMEs)，可实现对先验误差和后验误差的准确量化。通过假设数据生成过程符合高斯混合分布，DGMEs 能够逼近复杂的概率分布，例如重尾或多峰分布。我们的贡献包括推导出用于学习模型参数的期望最大化 (EM) 算法，这将得到对标准深度集合的训练数据对数似然的上界。此外，所提出的 EM 训练过程允许学习混合权重，这在集合中通常不会做。我们的实验结果表明，DGMEs 在处理复杂预测密度方面优于最先进的不确定性量化深度学习模型。

    This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, such as heavy-tailed or multimodal distributions. Our contributions include the derivation of an expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the log-likelihood of training data over that of standard deep ensembles. Additionally, the proposed EM training procedure allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive densities.
    
[^6]: 均场 Langevin 动力学的收敛性: 时间和空间离散化，随机梯度和方差减少

    Convergence of mean-field Langevin dynamics: Time and space discretization, stochastic gradient, and variance reduction. (arXiv:2306.07221v1 [cs.LG])

    [http://arxiv.org/abs/2306.07221](http://arxiv.org/abs/2306.07221)

    该论文研究了均场 Langevin 动力学的收敛性，并通过一个通用框架证明了考虑到有限粒子逼近误差、时间离散化和随机梯度逼近的 MFLD 在时间上一致收敛，为神经网络和 MMD 最小化等广泛学习问题提供了量化收敛速率保证。

    

    均场 Langevin 动力学（MFLD）是 Langevin 动力学的非线性推广，它包含一个分布相关的漂移，并通过（带噪）梯度下降从两层神经网络的优化中自然产生。最近的研究表明，MFLD 在测度空间中全局最小化熵正则化的凸泛函。然而，以前的所有分析都假设了无限粒子或连续时间极限，并且无法处理随机梯度更新。我们提供了一个通用框架，证明了考虑到有限粒子逼近误差、时间离散化和随机梯度逼近的 MFLD 在时间上一致收敛。为了展示该框架的广泛适用性，我们建立了量化收敛速率保证，以获得（i）像在均场区域的神经网络和 MMD 最小化这样的广泛学习问题的正则全局最优解，以及（ii）

    The mean-field Langevin dynamics (MFLD) is a nonlinear generalization of the Langevin dynamics that incorporates a distribution-dependent drift, and it naturally arises from the optimization of two-layer neural networks via (noisy) gradient descent. Recent works have shown that MFLD globally minimizes an entropy-regularized convex functional in the space of measures. However, all prior analyses assumed the infinite-particle or continuous-time limit, and cannot handle stochastic gradient updates. We provide an general framework to prove a uniform-in-time propagation of chaos for MFLD that takes into account the errors due to finite-particle approximation, time-discretization, and stochastic gradient approximation. To demonstrate the wide applicability of this framework, we establish quantitative convergence rate guarantees to the regularized global optimal solution under (i) a wide range of learning problems such as neural network in the mean-field regime and MMD minimization, and (ii) 
    
[^7]: 神经网络训练算法基准测试

    Benchmarking Neural Network Training Algorithms. (arXiv:2306.07179v1 [cs.LG])

    [http://arxiv.org/abs/2306.07179](http://arxiv.org/abs/2306.07179)

    本文解决了神经网络训练算法基准测试中存在的三个挑战，提出了新的基准测试套件，以促进训练算法效率的进一步提高。

    

    训练算法是每个深度学习流程的重要组成部分。提高训练算法的效率可以节省时间、计算资源，并带来更好、更准确的模型。然而，我们目前还无法可靠地确定最先进的训练算法。本文通过具体实验，证明了加速训练的真正进展需要解决三个基本挑战：如何确定训练何时结束并精确测量训练时间，如何处理测量对确切工作负载详情的敏感性，并公平比较需要超参数调整的算法。为了增加对训练算法效率的了解，我们提出并设计了一些新的基准测试套件。

    Training algorithms, broadly construed, are an essential part of every deep learning pipeline. Training algorithm improvements that speed up training across a wide variety of workloads (e.g., better update rules, tuning protocols, learning rate schedules, or data selection schemes) could save time, save computational resources, and lead to better, more accurate, models. Unfortunately, as a community, we are currently unable to reliably identify training algorithm improvements, or even determine the state-of-the-art training algorithm. In this work, using concrete experiments, we argue that real progress in speeding up training requires new benchmarks that resolve three basic challenges faced by empirical comparisons of training algorithms: (1) how to decide when training is complete and precisely measure training time, (2) how to handle the sensitivity of measurements to exact workload details, and (3) how to fairly compare algorithms that require hyperparameter tuning. In order to add
    
[^8]: 一般转换构建一致的在线近似算法

    General Transformation for Consistent Online Approximation Algorithms. (arXiv:2306.07163v1 [cs.LG])

    [http://arxiv.org/abs/2306.07163](http://arxiv.org/abs/2306.07163)

    本文提出一个转换框架，可以将离线逼近算法转换为具有低ε-近似遗憾的在线算法，并成功应用于多种问题并实现了多项式时间的近似效果。

    

    我们提出了一个转换框架，可用于从离线逼近算法中开发具有低ε-近似遗憾的在线算法。我们首先给出了一个将具有低平均敏感度的离线逼近算法转换为具有低ε-近似遗憾的在线算法的通用约简定理。然后，我们展示了可以使用coreset构造方法将离线逼近算法转换为低敏感度版本。为了展示我们方法的多样性，我们将其应用于各种问题，包括在线(k，z)-聚类、在线矩阵逼近和在线回归，并成功地为每个问题实现了对数多项式ε-近似遗憾。此外，我们证明，在所有三种情况下，我们的算法也享有低不一致性，这可能是某些在线应用程序所需的。

    We introduce a transformation framework that can be utilized to develop online algorithms with low $\epsilon$-approximate regret in the random-order model from offline approximation algorithms. We first give a general reduction theorem that transforms an offline approximation algorithm with low average sensitivity to an online algorithm with low $\epsilon$-approximate regret. We then demonstrate that offline approximation algorithms can be transformed into a low-sensitivity version using a coreset construction method. To showcase the versatility of our approach, we apply it to various problems, including online $(k,z)$-clustering, online matrix approximation, and online regression, and successfully achieve polylogarithmic $\epsilon$-approximate regret for each problem. Moreover, we show that in all three cases, our algorithm also enjoys low inconsistency, which may be desired in some online applications.
    
[^9]: 基于黎曼流形拉普拉斯逼近的贝叶斯神经网络

    Riemannian Laplace approximations for Bayesian neural networks. (arXiv:2306.07158v1 [stat.ML])

    [http://arxiv.org/abs/2306.07158](http://arxiv.org/abs/2306.07158)

    本论文提出了一种基于黎曼度量的简单参数逼近后验分布方法，实验表明该方法对先验选择不过度敏感，可以较好地改善传统拉普拉斯逼近的表现。

    

    贝叶斯神经网络通常用高斯分布来近似权值后验分布。然而，实际后验分布往往是高度非高斯的，即使是在局部情况下，模型表现也会恶化。在本文章中，我们提出了一种简单的参数逼近后验分布方法，通过用黎曼度量来确定对数后验梯度。我们开发了黎曼拉普拉斯逼近，在这种逼近下，样本会自然地落入负对数后验小的权值区域。我们表明，这些样本可以通过解一组常微分方程来抽取，并且可以通过利用黎曼度量和自动微分的结构来高效地完成。在实证上，我们证明了我们的方法在各种任务上均比传统的拉普拉斯逼近表现更好。我们进一步展示，与传统的拉普拉斯逼近不同的是，我们的方法对先验选择不过度敏感，这缓解了先验选择问题。

    Bayesian neural networks often approximate the weight-posterior with a Gaussian distribution. However, practical posteriors are often, even locally, highly non-Gaussian, and empirical performance deteriorates. We propose a simple parametric approximate posterior that adapts to the shape of the true posterior through a Riemannian metric that is determined by the log-posterior gradient. We develop a Riemannian Laplace approximation where samples naturally fall into weight-regions with low negative log-posterior. We show that these samples can be drawn by solving a system of ordinary differential equations, which can be done efficiently by leveraging the structure of the Riemannian metric and automatic differentiation. Empirically, we demonstrate that our approach consistently improves over the conventional Laplace approximation across tasks. We further show that, unlike the conventional Laplace approximation, our method is not overly sensitive to the choice of prior, which alleviates a p
    
[^10]: 分布式强化学习的多样投影集合

    Diverse Projection Ensembles for Distributional Reinforcement Learning. (arXiv:2306.07124v1 [cs.LG])

    [http://arxiv.org/abs/2306.07124](http://arxiv.org/abs/2306.07124)

    本文研究了分布式强化学习中多样投影集合的理论特性，提出了使用集合差异度量的算法，以促进可靠的不确定性估计。

    

    与传统的强化学习不同，分布式强化学习算法旨在学习回报的分布而不是其期望值。由于回报分布的性质通常是未知的或过于复杂，因此通常采用将未约束的分布投影到可表示的参数分布集合中的方法进行逼近。我们认为，当将这种投影步骤与神经网络和梯度下降相结合时，这种投影步骤会产生强烈的归纳偏见，从而深刻影响学习模型的泛化行为。为了通过多样性促进可靠的不确定性估计，本文研究了分布式集合中多个不同的投影和表示的组合。我们建立了这种投影集合的理论特性，并推导出一种使用集合差异度量的算法。

    In contrast to classical reinforcement learning, distributional reinforcement learning algorithms aim to learn the distribution of returns rather than their expected value. Since the nature of the return distribution is generally unknown a priori or arbitrarily complex, a common approach finds approximations within a set of representable, parametric distributions. Typically, this involves a projection of the unconstrained distribution onto the set of simplified distributions. We argue that this projection step entails a strong inductive bias when coupled with neural networks and gradient descent, thereby profoundly impacting the generalization behavior of learned models. In order to facilitate reliable uncertainty estimation through diversity, this work studies the combination of several different projections and representations in a distributional ensemble. We establish theoretical properties of such projection ensembles and derive an algorithm that uses ensemble disagreement, measure
    
[^11]: 相对熵不对称性在经验风险最小化正则化中的分析

    Analysis of the Relative Entropy Asymmetry in the Regularization of Empirical Risk Minimization. (arXiv:2306.07123v1 [cs.IT])

    [http://arxiv.org/abs/2306.07123](http://arxiv.org/abs/2306.07123)

    本文分析了相对熵正则化中的不对称性对经验风险最小化的影响，并引入了一种新的Type-II正则化来允许解决方案更广泛。该分析揭示出相对熵将在ERM-RER问题中引入强烈的归纳偏差。

    

    本文分析了相对熵不对称性在经验风险最小化相对熵正则化（ERM-RER）问题中的影响。引入了一种新型正则化，称为Type-II正则化，允许ERM-RER问题的解在超出参考度量支持的支持下得到解决。新ERM-RER Type-II问题的解以参考度量与解之间的Radon-Nikodym导数为特征进行分析。解的分析揭示了相对熵在ERM-RER问题中作为正则化器时的以下特性：i）相对熵将Type-II解的支持强制缩小到参考度量的支持范围内，引入了强烈的归纳偏差，主导了训练数据提供的证据; ii）Type-II正则化等效于使用适当的变换进行经典的相对熵正则化。

    The effect of the relative entropy asymmetry is analyzed in the empirical risk minimization with relative entropy regularization (ERM-RER) problem. A novel regularization is introduced, coined Type-II regularization, that allows for solutions to the ERM-RER problem with a support that extends outside the support of the reference measure. The solution to the new ERM-RER Type-II problem is analytically characterized in terms of the Radon-Nikodym derivative of the reference measure with respect to the solution. The analysis of the solution unveils the following properties of relative entropy when it acts as a regularizer in the ERM-RER problem: i) relative entropy forces the support of the Type-II solution to collapse into the support of the reference measure, which introduces a strong inductive bias that dominates the evidence provided by the training data; ii) Type-II regularization is equivalent to classical relative entropy regularization with an appropriate transformation of the empi
    
[^12]: 基于“平均”的异质性时间序列预测方法的改进，以食品需求预测为例

    Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast. (arXiv:2306.07119v1 [stat.ME])

    [http://arxiv.org/abs/2306.07119](http://arxiv.org/abs/2306.07119)

    本文提出了一种基于相似度度量的通用框架，利用k最近邻的方式构建邻域，并通过平均来改进可能简单模型的预测，提高异质性时间序列的预测准确性。

    

    实际应用中的常见预测场景是考虑一组可能异质性的相同领域时间序列。由于每个时间序列的不同特性，如长度等，直接对每个时间序列进行预测是具有挑战性的。本文提出了一种通用框架，利用动态时间规整中的相似度度量找到相似的时间序列，以k最近邻的方式构建邻域，并通过平均来改进可能简单模型的预测。提出了几种执行平均的方法，并理论证明了平均对于预测的有效性。此外，本文还提出了诊断工具，允许深入理解该过程。

    A common forecasting setting in real world applications considers a set of possibly heterogeneous time series of the same domain. Due to different properties of each time series such as length, obtaining forecasts for each individual time series in a straight-forward way is challenging. This paper proposes a general framework utilizing a similarity measure in Dynamic Time Warping to find similar time series to build neighborhoods in a k-Nearest Neighbor fashion, and improve forecasts of possibly simple models by averaging. Several ways of performing the averaging are suggested, and theoretical arguments underline the usefulness of averaging for forecasting. Additionally, diagnostics tools are proposed allowing a deep understanding of the procedure.
    
[^13]: 揭示Hessian与决策边界的联系

    Unveiling the Hessian's Connection to the Decision Boundary. (arXiv:2306.07104v1 [cs.LG])

    [http://arxiv.org/abs/2306.07104](http://arxiv.org/abs/2306.07104)

    Hessian的前几个特征向量描述了神经网络学到的决策边界，异常值数量与决策边界的复杂性成正比，这启发了一种新的泛化度量和边界估计技术。

    

    理解良好泛化最小值的属性是深度学习研究的核心。一方面，神经网络的泛化与决策边界复杂性有关，而在高维输入空间中难以研究。相反，最小值的平坦性已成为泛化的有争议的代理。在这项工作中，我们提供了两种方法之间的缺失链接，并展示了Hessian的前几个特征向量描述了神经网络学到的决策边界。值得注意的是，Hessian谱中的异常值数量与决策边界的复杂性成正比。基于此发现，我们提供了一种研究高维决策边界复杂性的新而简单的方法; 表明该连接自然地启发了一种新的泛化度量; 最后，我们开发了一种新的边界估计技术，该技术与泛化度量结合使用，精确地确定各种模型的边界。

    Understanding the properties of well-generalizing minima is at the heart of deep learning research. On the one hand, the generalization of neural networks has been connected to the decision boundary complexity, which is hard to study in the high-dimensional input space. Conversely, the flatness of a minimum has become a controversial proxy for generalization. In this work, we provide the missing link between the two approaches and show that the Hessian top eigenvectors characterize the decision boundary learned by the neural network. Notably, the number of outliers in the Hessian spectrum is proportional to the complexity of the decision boundary. Based on this finding, we provide a new and straightforward approach to studying the complexity of a high-dimensional decision boundary; show that this connection naturally inspires a new generalization measure; and finally, we develop a novel margin estimation technique which, in combination with the generalization measure, precisely identif
    
[^14]: 潜在动态隐式扩散过程

    Latent Dynamical Implicit Diffusion Processes. (arXiv:2306.07077v1 [cs.LG])

    [http://arxiv.org/abs/2306.07077](http://arxiv.org/abs/2306.07077)

    本文提出了一种新型的潜在变量模型 LDIDPs，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本，相较于最先进的顺序生成模型有更好的性能。

    

    潜在动态模型常被用来学习代表一系列噪声数据样本的潜在动态过程的分布。然而，由于潜在的和观测动态的复杂性和变异性，产生具有高保真度的样本具有挑战性。最近，在基于扩散的生成模型（例如DDPM和NCSN）方面取得的进展，展示了一些有前景的替代方法，适用于从先验分布中生成高质量的序列样本，相较于先进的潜在生成模型（如神经ODE、RNN和正则化流网络）。然而，将它们应用于建模具有潜在动态模型的序列数据尚未被探索。因此，本文提出了一种名为潜在动态隐式扩散过程（LDIDPs）的新型潜在变量模型，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本。我们在合成和模拟神经数据上测试了LDIDPs，并证明它优于最先进的顺序生成模型。

    Latent dynamical models are commonly used to learn the distribution of a latent dynamical process that represents a sequence of noisy data samples. However, producing samples from such models with high fidelity is challenging due to the complexity and variability of latent and observation dynamics. Recent advances in diffusion-based generative models, such as DDPM and NCSN, have shown promising alternatives to state-of-the-art latent generative models, such as Neural ODEs, RNNs, and Normalizing flow networks, for generating high-quality sequential samples from a prior distribution. However, their application in modeling sequential data with latent dynamical models is yet to be explored. Here, we propose a novel latent variable model named latent dynamical implicit diffusion processes (LDIDPs), which utilizes implicit diffusion processes to sample from dynamical latent processes and generate sequential observation samples accordingly. We tested LDIDPs on synthetic and simulated neural d
    
[^15]: 具有不对称置信区间的有限预算多臂老虎机问题

    Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals. (arXiv:2306.07071v1 [cs.LG])

    [http://arxiv.org/abs/2306.07071](http://arxiv.org/abs/2306.07071)

    这篇论文提出了一种名为ω-UCB的新上置信区间抽样策略，使用不对称置信区间以更准确、更紧密地估计奖励成本比，解决了现有预算多臂老虎机问题策略存在的问题，并在合成和真实环境中表现出色。

    

    我们研究了随机预算多臂老虎机（MAB）问题，其中玩家选择具有未知期望奖励和成本的K个臂。目标是在预算约束下最大化总奖励。因此，玩家试图尽可能经常地选择具有最高奖励成本比的臂。当前针对此问题的最先进策略存在一些问题，我们予以说明。为了克服这些问题，我们提出了一种新的上置信区间（UCB）抽样策略，称为ω-UCB，并使用不对称置信区间。这些区间尺度随着样本均值和随机变量边界之间的距离而变化，相对于我们的竞争对手，可以更准确、更紧密地估计奖励成本比。我们证明了我们的方法具有对数后悔，并在合成和真实环境中始终优于现有策略。

    We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a player chooses from $K$ arms with unknown expected rewards and costs. The goal is to maximize the total reward under a budget constraint. A player thus seeks to choose the arm with the highest reward-cost ratio as often as possible. Current state-of-the-art policies for this problem have several issues, which we illustrate. To overcome them, we propose a new upper confidence bound (UCB) sampling policy, $\omega$-UCB, that uses asymmetric confidence intervals. These intervals scale with the distance between the sample mean and the bounds of a random variable, yielding a more accurate and tight estimation of the reward-cost ratio compared to our competitors. We show that our approach has logarithmic regret and consistently outperforms existing policies in synthetic and real settings.
    
[^16]: 基于决策树作为数据观察过程的贝叶斯决策理论最优预测算法

    Prediction Algorithms Achieving Bayesian Decision Theoretical Optimality Based on Decision Trees as Data Observation Processes. (arXiv:2306.07060v1 [cs.LG])

    [http://arxiv.org/abs/2306.07060](http://arxiv.org/abs/2306.07060)

    本文提出了一种基于决策树作为数据观察过程的贝叶斯决策理论最优预测算法，并通过马尔可夫链模型解决了求解分割轴组合的问题。

    

    在决策树领域，大多数先前的研究难以确保预测新数据的统计最优性并且容易出现过拟合，因为决策树通常仅用于表示要从给定数据构建的预测功能。相比之下，包括本文在内的其他一些研究使用树来表示给定数据背后的随机数据观察过程。此外，他们根据贝叶斯决策理论假设树的先验分布，得出了一种具有鲁棒性的统计最优预测方法，可以抵御过拟合。然而，这些研究仍存在一些问题，因为计算这种贝叶斯最优预测需要对特征空间的所有划分模式（由树和一些参数表示）进行总和，这是不可行的。特别是，还存在一种相对于分割轴的组合进行求和的问题，即将特征分配给树的内部节点。我们通过一个马尔可夫链模型来解决这个问题，并基于特征空间的树形分割模式推导出计算贝叶斯最优预测的递归公式。

    In the field of decision trees, most previous studies have difficulty ensuring the statistical optimality of a prediction of new data and suffer from overfitting because trees are usually used only to represent prediction functions to be constructed from given data. In contrast, some studies, including this paper, used the trees to represent stochastic data observation processes behind given data. Moreover, they derived the statistically optimal prediction, which is robust against overfitting, based on the Bayesian decision theory by assuming a prior distribution for the trees. However, these studies still have a problem in computing this Bayes optimal prediction because it involves an infeasible summation for all division patterns of a feature space, which is represented by the trees and some parameters. In particular, an open problem is a summation with respect to combinations of division axes, i.e., the assignment of features to inner nodes of the tree. We solve this by a Markov cha
    
[^17]: 风险度量的置信区间优化框架

    A Distribution Optimization Framework for Confidence Bounds of Risk Measures. (arXiv:2306.07059v1 [cs.LG])

    [http://arxiv.org/abs/2306.07059](http://arxiv.org/abs/2306.07059)

    本文提出了一个分布优化框架，使用两种基于经验分布的估计方案，可以显著提高各种风险度量的置信区间。

    

    我们提出了一个分布优化框架，相比之前的方法，显著提高了各种风险度量的置信区间。我们的框架包括流行的风险度量，例如熵风险度量、条件风险价值（CVaR）、光谱风险度量、失真风险度量、等价确定性和分位数期望效用，这些风险度量在风险敏感决策方面的文献中已经得到了很好的确认。为了实现这一目标，我们引入了两种基于经验分布的集中界限的估计方案，具体使用Wasserstein距离或最高距离。与传统方法从经验风险度量中添加或减去置信半径不同，我们提出的方案评估基于距离的经验分布的特定转换。因此，我们的置信区间相比之前的方法始终产生更紧的结果。我们进一步验证了我们方法的有效性。

    We present a distribution optimization framework that significantly improves confidence bounds for various risk measures compared to previous methods. Our framework encompasses popular risk measures such as the entropic risk measure, conditional value at risk (CVaR), spectral risk measure, distortion risk measure, equivalent certainty, and rank-dependent expected utility, which are well established in risk-sensitive decision-making literature. To achieve this, we introduce two estimation schemes based on concentration bounds derived from the empirical distribution, specifically using either the Wasserstein distance or the supremum distance. Unlike traditional approaches that add or subtract a confidence radius from the empirical risk measures, our proposed schemes evaluate a specific transformation of the empirical distribution based on the distance. Consequently, our confidence bounds consistently yield tighter results compared to previous methods. We further verify the efficacy of th
    
[^18]: 内核随机投影深度用于离群点检测

    Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])

    [http://arxiv.org/abs/2306.07056](http://arxiv.org/abs/2306.07056)

    本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。

    

    本文提出了一种扩展的随机投影深度（RPD）方法，用于处理数据云中的多模式和非凸性。在所提出的方法的框架中，RPD在再现核希尔伯特空间中计算。借助内核主成分分析，我们期望所提出的方法可以处理上述多种模式和非凸性。实验结果表明，所提出的方法优于RPD，并可与基准数据集上现有的检测模型相媲美，关于接收操作特征曲线（ROC）下的曲线下面积（AUC）。

    This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
    
[^19]: 基于Lagrangian方法的约束马尔可夫决策过程中无需取消惩罚的遗憾界限

    Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained Markov Decision Processes. (arXiv:2306.07001v1 [cs.LG])

    [http://arxiv.org/abs/2306.07001](http://arxiv.org/abs/2306.07001)

    本文提出了一种创新的模型驱动的双重算法OptAug-CMDP，用于约束马尔可夫决策过程（CMDPs），解决了原先算法中安全性问题的缺陷，证明了其遗憾值优秀。

    

    约束马尔可夫决策过程（CMDPs）是建模安全强化学习问题的常见方法，其中安全目标由约束函数建模。基于Lagrangian的双重或原始双重算法为CMDPs中的学习提供了高效的方法。但是，当前已知的有限时间段遗憾界限允许“取消错误”，这意味着可以通过另一种场景中的严格约束满足来补偿一个场景中的约束违规行为。本文提出了一种创新的模型驱动的双重算法OptAug-CMDP，该算法受增广拉格朗日方法启发，并可以有效地执行来弥补这种缺陷。我们证明，在$K$个探索CMDP的情况下，我们的算法可以获得$\tilde{O}(\sqrt{K})$的遗憾界限，适用于目标和约束条件。

    Constrained Markov Decision Processes (CMDPs) are one of the common ways to model safe reinforcement learning problems, where the safety objectives are modeled by constraint functions. Lagrangian-based dual or primal-dual algorithms provide efficient methods for learning in CMDPs. For these algorithms, the currently known regret bounds in the finite-horizon setting allow for a \textit{cancellation of errors}; that is, one can compensate for a constraint violation in one episode with a strict constraint satisfaction in another episode. However, in practical applications, we do not consider such a behavior safe.  In this paper, we overcome this weakness by proposing a novel model-based dual algorithm \textsc{OptAug-CMDP} for tabular finite-horizon CMDPs. Our algorithm is motivated by the augmented Lagrangian method and can be performed efficiently. We show that during $K$ episodes of exploring the CMDP, our algorithm obtains a regret of $\tilde{O}(\sqrt{K})$ for both the objective and th
    
[^20]: 前向梯度算法是否能够取代反向传播算法？

    Can Forward Gradient Match Backpropagation?. (arXiv:2306.06968v1 [cs.LG])

    [http://arxiv.org/abs/2306.06968](http://arxiv.org/abs/2306.06968)

    本文研究通过从小型局部辅助网络反馈中获得的梯度偏向更有前途的方向，提高了前向梯度算法的性能。

    

    最近，前向梯度算法——利用正向微分模式中的方向导数的想法——已被证明可用于神经网络训练，同时避免了通常与反向传播梯度计算相关的问题，例如锁定和记忆要求。代价是需要猜测步骤方向，在高维空间中很难。我们提出在更有前途的方向上强烈偏向我们的梯度猜测方向，例如来自小型局部辅助网络的反馈。针对标准的计算机视觉神经网络，我们进行了一项严格的研究，系统地涵盖了各种梯度目标和梯度猜测的组合，包括以前在文献中提出的组合。我们发现，使用从本地损失获得的梯度作为候选方向，比在前向梯度算法中使用随机噪声，具有明显的改进效果。

    Forward Gradients - the idea of using directional derivatives in forward differentiation mode - have recently been shown to be utilizable for neural network training while avoiding problems generally associated with backpropagation gradient computation, such as locking and memorization requirements. The cost is the requirement to guess the step direction, which is hard in high dimensions. While current solutions rely on weighted averages over isotropic guess vector distributions, we propose to strongly bias our gradient guesses in directions that are much more promising, such as feedback obtained from small, local auxiliary networks. For a standard computer vision neural network, we conduct a rigorous study systematically covering a variety of combinations of gradient targets and gradient guesses, including those previously presented in the literature. We find that using gradients obtained from a local loss as a candidate direction drastically improves on random noise in Forward Gradie
    
[^21]: 用一维卷积自编码器进行特征提取，利用深度神经网络实现恒星大气高精度插值

    High-precision interpolation of stellar atmospheres with a deep neural network using a 1D convolutional auto encoder for feature extraction. (arXiv:2306.06938v1 [astro-ph.IM])

    [http://arxiv.org/abs/2306.06938](http://arxiv.org/abs/2306.06938)

    一种高效、准确、适用于恒星模型大气的插值方法，采用深度神经网络和一维卷积自编码器技术，能够提取非线性关系从而实现更加精细的预测。

    

    鉴于恒星大气模型网格的广泛可用性，需要采用超越简单线性插值并捕捉数据的复杂性的准确技术，以通过精确技术恢复中间大气模型。我们的目标是建立一种可靠、精确、轻量级且快速的方法，用于恢复恒星模型大气，也就是质量柱、温度、气体压力和电子密度的分层，给出定义大气特定参数的任何组合：金属丰度、有效温度和表面重力，以及其他关键化学元素的丰度。我们采用了完全连接的深度神经网络，该神经网络使用一维卷积自编码器从ATLAS9和MARCS模型大气中提取非线性关系。这种称为iNNterpol的新方法有效考虑了数据关系中的非线性性，而不是传统方法。

    Given the widespread availability of grids of models for stellar atmospheres, it is necessary to recover intermediate atmospheric models by means of accurate techniques that go beyond simple linear interpolation and capture the intricacies of the data. Our goal is to establish a reliable, precise, lightweight, and fast method for recovering stellar model atmospheres, that is to say the stratification of mass column, temperature, gas pressure, and electronic density with optical depth given any combination of the defining atmospheric specific parameters: metallicity, effective temperature, and surface gravity, as well as the abundances of other key chemical elements. We employed a fully connected deep neural network which in turn uses a 1D convolutional auto-encoder to extract the nonlinearities of a grid using the ATLAS9 and MARCS model atmospheres. This new method we call iNNterpol effectively takes into account the nonlinearities in the relationships of the data as opposed to traditi
    
[^22]: MPPN: 多分辨率周期模式网络用于长期时间序列预测

    MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time Series Forecasting. (arXiv:2306.06895v1 [cs.LG])

    [http://arxiv.org/abs/2306.06895](http://arxiv.org/abs/2306.06895)

    提出了一种名为MPPN的新型深度学习网络，其通过构建上下文感知的多分辨率语义单元和采用多周期模式挖掘来捕获关键模式，然后使用通道自适应模块以考虑多变量对不同模式的感知，用于长期时间序列预测。

    

    长期时间序列预测在各种现实场景中起着重要作用。最近的深度学习方法倾向于通过分解或采样方法捕获时间序列的结构。然而，大多数提取出的模式可能包含难以预测的噪声，并且缺乏良好的可解释性。此外，多变量序列预测方法通常忽略每个变量的个体特征，可能会影响预测精度。为了捕捉时序的内在结构，我们提出了一种名为 Multi-resolution Periodic Pattern Network（MPPN）的新型深度学习网络架构，用于长期时间序列预测。我们首先构建上下文感知的多分辨率语义单元，并采用多周期模式挖掘来捕获时间序列的关键模式。然后，我们提出了一个通道自适应模块，以捕捉多变量对不同模式的感知。

    Long-term time series forecasting plays an important role in various real-world scenarios. Recent deep learning methods for long-term series forecasting tend to capture the intricate patterns of time series by decomposition-based or sampling-based methods. However, most of the extracted patterns may include unpredictable noise and lack good interpretability. Moreover, the multivariate series forecasting methods usually ignore the individual characteristics of each variate, which may affecting the prediction accuracy. To capture the intrinsic patterns of time series, we propose a novel deep learning network architecture, named Multi-resolution Periodic Pattern Network (MPPN), for long-term series forecasting. We first construct context-aware multi-resolution semantic units of time series and employ multi-periodic pattern mining to capture the key patterns of time series. Then, we propose a channel adaptive module to capture the perceptions of multivariate towards different patterns. In 
    
[^23]: 对称二元非均匀超图随机块模型中谱聚类的强一致性与最优性

    Strong consistency and optimality of spectral clustering in symmetric binary non-uniform Hypergraph Stochastic Block Model. (arXiv:2306.06845v1 [math.ST])

    [http://arxiv.org/abs/2306.06845](http://arxiv.org/abs/2306.06845)

    论文提出了非均匀超图随机块模型下谱聚类的强一致性信息理论阈值，并且在该阈值以下给出估计标签的期望“不匹配率”上界。并且，单步谱算法可以在超过该阈值时非常高的概率正确地给定每个顶点的标签。

    

    本论文考虑了在非均匀超图随机块模型下，两个等大小的社区（n/2）中的随机超图上的无监督分类问题，其中每个边只依赖于其顶点的标签，边以一定概率独立出现。在这篇论文中，建立了强一致性的信息理论阈值，在该阈值以下，任何算法都有很高概率会误分类至少两个顶点，而特征向量估计量的期望“不匹配率”上界为$n$的阈值的负指数。另一方面，当超过该阈值时，尽管张量收缩引起了信息损失，但单步谱算法仅在给定收缩的邻接矩阵时，即使SDP在某些情况下失败，也可以非常高的概率正确地给定每个顶点分配标签。此外，强一致性可以通过对所有次优聚合信息实现。

    Consider the unsupervised classification problem in random hypergraphs under the non-uniform \emph{Hypergraph Stochastic Block Model} (HSBM) with two equal-sized communities ($n/2$), where each edge appears independently with some probability depending only on the labels of its vertices. In this paper, an \emph{information-theoretical} threshold for strong consistency is established. Below the threshold, every algorithm would misclassify at least two vertices with high probability, and the expected \emph{mismatch ratio} of the eigenvector estimator is upper bounded by $n$ to the power of minus the threshold. On the other hand, when above the threshold, despite the information loss induced by tensor contraction, one-stage spectral algorithms assign every vertex correctly with high probability when only given the contracted adjacency matrix, even if \emph{semidefinite programming} (SDP) fails in some scenarios. Moreover, strong consistency is achievable by aggregating information from al
    
[^24]: 具有无偏高斯过程超参数估计的可证明高效贝叶斯优化

    Provably Efficient Bayesian Optimization with Unbiased Gaussian Process Hyperparameter Estimation. (arXiv:2306.06844v1 [stat.ML])

    [http://arxiv.org/abs/2306.06844](http://arxiv.org/abs/2306.06844)

    针对贝叶斯优化中常见的数据偏差问题，提出了一种新方法，在无需事先知道真实高斯过程超参数的情况下，使用多臂老虎机技术向BO过程中添加随机数据点，采用新的训练损失函数进行超参数估计，以达到次线性收敛到全局最优解的目的。

    

    基于高斯过程的贝叶斯优化是一种有效优化黑盒函数的方法。该方法的实际性能和理论保证，取决于正确估计高斯过程超参数值。但在实践中，由于常用于贝叶斯优化的数据采样策略可能会引起数据偏差，从而导致超参数估计错误。为了解决这个问题，我们提出了一种新的贝叶斯优化方法，即使在事先不知道真实高斯过程超参数并需要从观察数据中进行估计时，该方法也能够次线性收敛到目标函数的全局最优解。我们的方法使用多臂老虎机技术(EXP3)向BO过程中添加随机数据点，并使用新的训练损失函数用于高斯过程超参数估计过程的训练。

    Gaussian process (GP) based Bayesian optimization (BO) is a powerful method for optimizing black-box functions efficiently. The practical performance and theoretical guarantees associated with this approach depend on having the correct GP hyperparameter values, which are usually unknown in advance and need to be estimated from the observed data. However, in practice, these estimations could be incorrect due to biased data sampling strategies commonly used in BO. This can lead to degraded performance and break the sub-linear global convergence guarantee of BO. To address this issue, we propose a new BO method that can sub-linearly converge to the global optimum of the objective function even when the true GP hyperparameters are unknown in advance and need to be estimated from the observed data. Our method uses a multi-armed bandit technique (EXP3) to add random data points to the BO process, and employs a novel training loss function for the GP hyperparameter estimation process that ens
    
[^25]: 用函数逼近解决强化学习中重尾奖励问题的极小最大化算法和实例相关遗憾度量

    Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds. (arXiv:2306.06836v1 [cs.LG])

    [http://arxiv.org/abs/2306.06836](http://arxiv.org/abs/2306.06836)

    本文解决了强化学习中当奖励呈“重尾”分布时的问题，提出了第一种处理这种情况的实例相关算法，并得到了极小最大化的遗憾界。

    

    虽然有许多工作都专注于为有界奖励的强化学习设计有效算法，但当奖励呈现“重尾”分布时——即存在某个 $\epsilon\in(0,1]$ 使得仅有有限的$(1+\epsilon)$-阶矩——是否存在对大状态-动作空间进行采样或时效性算法仍然是一个未解决的问题。 在本文中，我们解决了具有线性函数逼近的 RL 中的这种奖励机制的挑战。我们首先为重尾线性赌臂设计了一种算法——\textsc{Heavy-OFUL}，其实现了一种实例相关的 $T$-round 遗憾度量，为 $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$，这是这种类型的\emph{第一篇}文章。$\nu_t^{1+\epsilon}$是第 $t$ 轮奖励的 $(1+\epsilon)$-阶中心矩。我们进一步证明了在应用于 st 的最坏情况时，上述界是极小值的最优解。

    While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the \emph{first} of this kind. Here, $d$ is the feature dimension, and $\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in st
    
[^26]: 美洲土著语言的神经机器翻译介绍

    Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction. (arXiv:2306.06804v1 [cs.CL])

    [http://arxiv.org/abs/2306.06804](http://arxiv.org/abs/2306.06804)

    本文介绍了为美洲土著语言创建机器翻译系统面临的挑战以及最新的进展和发现。缺乏平行和单语数据是其中的主要难题。

    

    神经模型已经显著提高了高资源语言之间机器翻译（MT）的最新进展。传统上，这些模型依赖于大量的训练数据，但许多语言对缺乏这些资源。然而，世界上语言的重要部分缺乏这样的数据量，其中美洲的大多数语言也是如此，仅有一定量的平行和单语数据。本文向读者介绍了为这些语言创建MT系统所涉及的基本挑战、概念和技术。最后，我们讨论了最近的进展和发现以及开放的问题，这些发现是NLP社区对这些语言越来越感兴趣的结果。

    Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.
    
[^27]: 一种对于双随机点过程的高维半参数推理的惩罚泊松似然方法。

    A Penalized Poisson Likelihood Approach to High-Dimensional Semi-Parametric Inference for Doubly-Stochastic Point Processes. (arXiv:2306.06756v1 [stat.ME])

    [http://arxiv.org/abs/2306.06756](http://arxiv.org/abs/2306.06756)

    本研究提出了一种对于双随机点过程的估计方法，该方法在进行协变量效应估计时非常高效，不需要强烈的限制性假设，且在理论和实践中均表现出了良好的信度保证和效能。

    

    双随机点过程将空间域内事件的发生建模为在实现随机强度函数的条件下，不均匀泊松过程。它们是捕捉空间异质性和依赖性的灵活工具。然而，双随机空间模型的实现在计算上是有要求的，往往具有有限的理论保证和/或依赖于具有限制性假设。我们提出了一种惩罚回归方法，用于估计双随机点过程中的协变量效应，具有计算效率且不需要基础强度的参数形式或平稳性。我们证实了所提出估计器的一致性和渐近正态性，并开发了一个协方差估计器，导致保守的统计推断程序。模拟研究显示了我们的方法在数据生成机制的限制性较小的情况下的有效性，并且在西雅图犯罪事件的应用中证明了我们的方法在实践中的良好性能。

    Doubly-stochastic point processes model the occurrence of events over a spatial domain as an inhomogeneous Poisson process conditioned on the realization of a random intensity function. They are flexible tools for capturing spatial heterogeneity and dependence. However, implementations of doubly-stochastic spatial models are computationally demanding, often have limited theoretical guarantee, and/or rely on restrictive assumptions. We propose a penalized regression method for estimating covariate effects in doubly-stochastic point processes that is computationally efficient and does not require a parametric form or stationarity of the underlying intensity. We establish the consistency and asymptotic normality of the proposed estimator, and develop a covariance estimator that leads to a conservative statistical inference procedure. A simulation study shows the validity of our approach under less restrictive assumptions on the data generating mechanism, and an application to Seattle crim
    
[^28]: 差分隐私条件独立性检验

    Differentially Private Conditional Independence Testing. (arXiv:2306.06721v1 [stat.ML])

    [http://arxiv.org/abs/2306.06721](http://arxiv.org/abs/2306.06721)

    本文介绍了两个差分隐私条件独立性检验方法，可适用于Z为连续值的一般情况。

    

    条件独立性（CI）检验在统计数据分析中被广泛使用，例如，它们是许多因果图发现算法的构建块。CI测试旨在接受或拒绝$X \perp \!\!\! \perp Y \mid Z$的零假设，其中$X \in \mathbb{R}，Y \in \mathbb{R}，Z \in \mathbb{R}^d$。本文研究了在差分隐私约束下的条件独立性检验。我们设计了基于Shah和Peters（2020）的一般化协方差测量和基于Cand\`es等人的条件随机化检验的两种私人CI测试过程（在模型-X假设下）。我们提供了关于我们测试性能的理论保证，并在实证上验证它们。这些是第一个适用于Z为连续的一般情况的私人CI测试。

    Conditional independence (CI) tests are widely used in statistical data analysis, e.g., they are the building block of many algorithms for causal graph discovery. The goal of a CI test is to accept or reject the null hypothesis that $X \perp \!\!\! \perp Y \mid Z$, where $X \in \mathbb{R}, Y \in \mathbb{R}, Z \in \mathbb{R}^d$. In this work, we investigate conditional independence testing under the constraint of differential privacy. We design two private CI testing procedures: one based on the generalized covariance measure of Shah and Peters (2020) and another based on the conditional randomization test of Cand\`es et al. (2016) (under the model-X assumption). We provide theoretical guarantees on the performance of our tests and validate them empirically. These are the first private CI tests that work for the general case when $Z$ is continuous.
    
[^29]: 关于生物等效性研究中的置信区间

    On the Confidence Intervals in Bioequivalence Studies. (arXiv:2306.06698v1 [stat.ME])

    [http://arxiv.org/abs/2306.06698](http://arxiv.org/abs/2306.06698)

    本文阐明了在生物等效性测试中，用$100(1-2\alpha)\%$置信区间的方法进行检验只有在TOST中两个单侧检验“等尾”时才能得到正确结果，并且提出了一种比标准方法更详细的检验方法。

    

    生物等效性研究是一种比较两种不同药物配方生物等效性的临床试验。在此类研究中，通常会对随机分配给接受两种配方的人体试验对象的药物动力学特征进行比较。根据美国食品和药品管理局（FDA）的指导，对于一个大小为$\alpha$的生物等价性检验，标准做法是构建一个$100(1-2\alpha)\%$置信区间，并验证置信区间是否落在关键区间内。本文阐明了在TOST中两个单侧检验“等尾”时，用$100(1-2\alpha)\%$置信区间的方法进行生物等效性检验只能得到一个大小为$\alpha$的检验。此外，在生物等效性测试环境中，还讨论了一种$100(1-\alpha)\%$置信区间的方法，可以提供比标准方法更详细的推断。

    A bioequivalence study is a type of clinical trial designed to compare the biological equivalence of two different formulations of a drug. Such studies are typically conducted in controlled clinical settings with human subjects, who are randomly assigned to receive two formulations. The two formulations are then compared with respect to their pharmacokinetic profiles, which encompass the absorption, distribution, metabolism, and elimination of the drug. Under the guidance from Food and Drug Administration (FDA), for a size-$\alpha$ bioequivalence test, the standard approach is to construct a $100(1-2\alpha)\%$ confidence interval and verify if the confidence interval falls with the critical region. In this work, we clarify that $100(1-2\alpha)\%$ confidence interval approach for bioequivalence testing yields a size-$\alpha$ test only when the two one-sided tests in TOST are ``equal-tailed''. Furthermore, a $100(1-\alpha)\%$ confidence interval approach is also discussed in the bioequiv
    
[^30]: 高维数据上的极小化极大风险分类器的有效学习

    Efficient Learning of Minimax Risk Classifiers in High Dimensions. (arXiv:2306.06649v1 [stat.ML])

    [http://arxiv.org/abs/2306.06649](http://arxiv.org/abs/2306.06649)

    提出了一种针对高维数据中的极小化极大风险分类器的有效学习算法，具有特征选择和提供有关分类器性能的最坏情况下的错误概率的优点。

    

    高维数据在许多领域非常普遍，比如医疗保健和基因组学，在这种情况下，特征的数量往往会导致学习效率低下。最近，约束生成方法已经使得支持向量机（SVM）的L1正则化的有效学习成为可能。本文利用这些方法获取了一种有效学习算法，用于最近提出的极小化极大风险分类器（MRC）。所提出的迭代算法还提供了一系列最坏情况下的错误概率并执行特征选择。对多个高维度数据集的实验表明，所提出的算法在高维度场景下是有效的。此外，最坏情况下的错误概率提供了关于分类器性能的有用信息，算法选择的特征也与最先进的方法相竞争。

    High-dimensional data is common in multiple areas, such as health care and genomics, where the number of features can be tens of thousands. In such scenarios, the large number of features often leads to inefficient learning. Constraint generation methods have recently enabled efficient learning of L1-regularized support vector machines (SVMs). In this paper, we leverage such methods to obtain an efficient learning algorithm for the recently proposed minimax risk classifiers (MRCs). The proposed iterative algorithm also provides a sequence of worst-case error probabilities and performs feature selection. Experiments on multiple high-dimensional datasets show that the proposed algorithm is efficient in high-dimensional scenarios. In addition, the worst-case error probability provides useful information about the classifier performance, and the features selected by the algorithm are competitive with the state-of-the-art.
    
[^31]: 关于生成模型的动力学最佳概率路径

    On Kinetic Optimal Probability Paths for Generative Models. (arXiv:2306.06626v1 [cs.LG])

    [http://arxiv.org/abs/2306.06626](http://arxiv.org/abs/2306.06626)

    本文研究高斯概率路径的动力学最佳成员，发现动能在这样的路径空间上可以通过单一的一维标量函数来整合数据，从而得到了提高研究所需的粒子轨迹简单性的方法。

    

    最近成功的生成模型通过将神经网络拟合到事先定义的可处理的概率密度路径上来训练。本文研究高斯概率路径空间，包含扩散路径作为一种例子，并在某种意义上寻找一个最优成员。特别是，最小化路径的动能已知可以使粒子的轨迹简单，因此更易于采样，并在未看到数据和样本生成质量方面在经验上得到提高。我们研究动力学最佳高斯路径，并提供以下观察：（i）我们展示了动能在高斯路径空间上采取简化形式，其中仅通过称为“数据分离函数”的单一一维标量函数来纳入数据。（ii）我们用一维ODE描述了KO解。（iii）我们通过逼近表示数据相关的KO路径。

    Recent successful generative models are trained by fitting a neural network to an a-priori defined tractable probability density path taking noise to training examples. In this paper we investigate the space of Gaussian probability paths, which includes diffusion paths as an instance, and look for an optimal member in some useful sense. In particular, minimizing the Kinetic Energy (KE) of a path is known to make particles' trajectories simple, hence easier to sample, and empirically improve performance in terms of likelihood of unseen data and sample generation quality. We investigate Kinetic Optimal (KO) Gaussian paths and offer the following observations: (i) We show the KE takes a simplified form on the space of Gaussian paths, where the data is incorporated only through a single, one dimensional scalar function, called the \emph{data separation function}. (ii) We characterize the KO solutions with a one dimensional ODE. (iii) We approximate data-dependent KO paths by approximating 
    
[^32]: 变分不平衡回归(Variational Imbalanced Regression)

    Variational Imbalanced Regression. (arXiv:2306.06599v1 [cs.LG])

    [http://arxiv.org/abs/2306.06599](http://arxiv.org/abs/2306.06599)

    本文提出的变分不平衡回归（VIR）模型通过引入Probabilistic Reweighting方法，可以在不平衡回归方面表现良好，并自然产生合理的不确定性估计。

    

    当标签分布不平衡时，现有的回归模型往往在准确性和不确定性估计方面表现不佳。本文提出了一种概率深度学习模型——变分不平衡回归（VIR），它不仅在不平衡回归方面表现出色，而且自然地产生合理的不确定性估计。与典型的变分自编码器假设I.I.D.表示（数据点的表示不直接受其他数据点的影响）不同，我们的VIR借用具有类似回归标签的数据来计算潜在表示的变分分布；此外，不同于产生点估计的确定性回归模型， VIR预测整个正态反-伽玛分布并调节相关联的共轭分布，对不平衡数据施加概率重新加权，从而提供更好的不确定性估计。在几个真实世界的数据集上进行了实验。

    Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets sh
    
[^33]: 具有覆盖保证的神经网络无分布预测推断的快速计算方法

    Fast, Distribution-free Predictive Inference for Neural Networks with Coverage Guarantees. (arXiv:2306.06582v1 [stat.ML])

    [http://arxiv.org/abs/2306.06582](http://arxiv.org/abs/2306.06582)

    该论文提出了一种新颖、计算效率高的预测推断算法，不需要数据做出分布假设。对于交换数据，通过使用$(\epsilon, \delta)$-差分隐私训练一个神经网络并围绕差别私有的神经网络估计进行线性逼近，该方法已被证明具有严格的覆盖保证。

    

    该论文提出了一种新颖的、计算效率高的预测推断(PI)算法，它不需要对数据做出分布假设，且比现有的神经网络引导式方法更快地计算。具体来说，如果有$n$个训练样本，引导式方法需要在大小为$n-1$的$n$个子样本上训练一个模型；对于像神经网络这样的大模型，这个过程可能计算上不切实际。相比之下，我们提出的方法在完整数据集上使用$(\epsilon, \delta)$-差分隐私(DP)训练一个神经网络，然后使用线性逼近来高效地近似每个留一出模型，该逼近是围绕差别私有的神经网络估计来进行的。对于交换数据，我们证明了我们的方法具有严格的覆盖保证，这取决于预设的隐私参数和神经网络的稳定性，而不取决于数据分布。模拟和实验数据证明了我们的方法比基于引导式的方法具有更好的计算效率。

    This paper introduces a novel, computationally-efficient algorithm for predictive inference (PI) that requires no distributional assumptions on the data and can be computed faster than existing bootstrap-type methods for neural networks. Specifically, if there are $n$ training samples, bootstrap methods require training a model on each of the $n$ subsamples of size $n-1$; for large models like neural networks, this process can be computationally prohibitive. In contrast, our proposed method trains one neural network on the full dataset with $(\epsilon, \delta)$-differential privacy (DP) and then approximates each leave-one-out model efficiently using a linear approximation around the differentially-private neural network estimate. With exchangeable data, we prove that our approach has a rigorous coverage guarantee that depends on the preset privacy parameters and the stability of the neural network, regardless of the data distribution. Simulations and experiments on real data demonstra
    
[^34]: Sinkhorn算法的重要性稀疏化

    Importance Sparsification for Sinkhorn Algorithm. (arXiv:2306.06581v1 [stat.ML])

    [http://arxiv.org/abs/2306.06581](http://arxiv.org/abs/2306.06581)

    Spar-Sink是一种重要性稀疏化方法，能够有效近似熵正则化最优传输和不平衡最优传输问题，并且在实验中表现优异。

    

    Sinkhorn算法被广泛应用于近似求解最优传输（OT）和不平衡最优传输（UOT）问题。但由于高计算复杂度，其实际应用受到限制。为减轻计算负担，我们提出了一种新的重要性稀疏化方法Spar-Sink，用于高效近似熵正则化OT和UOT解。具体来说，我们的方法利用未知最优传输计划的自然上界确定有效的采样概率，并构建稀疏的核矩阵以加速Sinkhorn迭代，将每次迭代的计算成本从$ O（n ^ 2）$降低到$\widetilde {O（n）}$适用于样本大小为$ n $的情况。理论上，我们证明了对于温和正则性条件下，所提出的OT和UOT问题的估计量是一致的。在各种合成数据上的实验表明，在估计误差方面，Spar-Sink优于主流竞争对手。

    Sinkhorn algorithm has been used pervasively to approximate the solution to optimal transport (OT) and unbalanced optimal transport (UOT) problems. However, its practical application is limited due to the high computational complexity. To alleviate the computational burden, we propose a novel importance sparsification method, called Spar-Sink, to efficiently approximate entropy-regularized OT and UOT solutions. Specifically, our method employs natural upper bounds for unknown optimal transport plans to establish effective sampling probabilities, and constructs a sparse kernel matrix to accelerate Sinkhorn iterations, reducing the computational cost of each iteration from $O(n^2)$ to $\widetilde{O}(n)$ for a sample of size $n$. Theoretically, we show the proposed estimators for the regularized OT and UOT problems are consistent under mild regularity conditions. Experiments on various synthetic data demonstrate Spar-Sink outperforms mainstream competitors in terms of both estimation erro
    
[^35]: 图神经网络的局部到全局视角

    Local-to-global Perspectives on Graph Neural Networks. (arXiv:2306.06547v1 [cs.LG])

    [http://arxiv.org/abs/2306.06547](http://arxiv.org/abs/2306.06547)

    本文提出了局部到全局的图神经网络模型，包括不变图网络、局部信息传递神经网络和全局图变换器，并研究其收敛性质和在图粗化中的应用。

    

    本文提出了一种对于图神经网络（GNN）的局部到全局的视角，其中分为局部信息传递神经网络（MPNN）和全局图变换器。本文提出了三个工作：1）研究一种全局 GNN，不变图网络的收敛性质，2）连接局部 MPNN 和全局图变换器，3）在全局建模中，使用局部 MPNN 进行图粗化，这是一个常见的子程序。

    We present a local-to-global perspective on graph neural networks (GNN), which are categorized as local Message Passing Neural Networks (MPNN) and global Graph Transformer. We present three pieces of work: 1) study the convergence property of a type of global GNN, Invariant Graph Networks, 2) connect the local MPNN and global Graph Transformer, and 3) use local MPNN for graph coarsening, a common subroutine used in global modeling.
    
[^36]: 一种基于概率框架的模块化增量学习方法

    A Probabilistic Framework for Modular Continual Learning. (arXiv:2306.06545v1 [cs.LG])

    [http://arxiv.org/abs/2306.06545](http://arxiv.org/abs/2306.06545)

    本文提出了一种名为PICLE的模块化增量学习框架，利用概率模型快速计算每个组合的适应度来加速搜索，是第一个可以实现不同类型的转移的模块化增量学习算法。

    

    模块化方法是增量学习领域的有前途方向，每个问题使用不同的模块组合且避免遗忘。然而，搜索可能的模块组合是一个挑战，因为评估组合性能需要一轮神经网络训练。为了解决这个问题，我们发展了一种名为PICLE的模块化增量学习框架，通过使用概率模型来快速计算每个组合的适应度来加速搜索。模型结合先前关于良好模块组合的知识与数据集特定信息。它的使用被分为感知和潜在子集等子集的搜索空间加以补充。我们展示了PICLE是第一个可以实现不同类型的转移的模块化增量学习算法，同时还能扩展到大型搜索空间。我们在两个基准套件上对其进行评估，这些套件旨在捕捉增量学习技术的不同要求。

    Modular approaches, which use a different composition of modules for each problem and avoid forgetting by design, have been shown to be a promising direction in continual learning (CL). However, searching through the large, discrete space of possible module compositions is a challenge because evaluating a composition's performance requires a round of neural network training. To address this challenge, we develop a modular CL framework, called PICLE, that accelerates search by using a probabilistic model to cheaply compute the fitness of each composition. The model combines prior knowledge about good module compositions with dataset-specific information. Its use is complemented by splitting up the search space into subsets, such as perceptual and latent subsets. We show that PICLE is the first modular CL algorithm to achieve different types of transfer while scaling to large search spaces. We evaluate it on two benchmark suites designed to capture different desiderata of CL techniques. 
    
[^37]: 针对领域自适应的部分可识别性

    Partial Identifiability for Domain Adaptation. (arXiv:2306.06510v1 [cs.LG])

    [http://arxiv.org/abs/2306.06510](http://arxiv.org/abs/2306.06510)

    本论文提出了一种针对无监督领域自适应的部分可识别性方法，通过依赖跨域因果机制的最小改变属性，在保持特定组分跨域不变的前提下最小化分布转移的不必要影响。

    

    无监督领域适应对于许多没有目标域标签信息的实际应用至关重要。通常情况下，如果没有进一步的假设，特征和标签的联合分布在目标域中是不可识别的。为了解决这个问题，我们依赖跨域因果机制的最小改变属性，以最小化分布转移的不必要影响。为了编码这个属性，我们首先使用一个带有两个分区潜变量子空间的潜变量模型来制定数据生成过程：不变部分的分布在跨域时保持不变，而稀疏的可变部分会在不同的域中发生变化。我们进一步限制了域移位对可变部分的影响。在温和的条件下，我们展示了部分可识别的潜变量，从而证明了目标域中数据和标签的联合分布也是可识别的。

    Unsupervised domain adaptation is critical to many real-world applications where label information is unavailable in the target domain. In general, without further assumptions, the joint distribution of the features and the label is not identifiable in the target domain. To address this issue, we rely on the property of minimal changes of causal mechanisms across domains to minimize unnecessary influences of distribution shifts. To encode this property, we first formulate the data-generating process using a latent variable model with two partitioned latent subspaces: invariant components whose distributions stay the same across domains and sparse changing components that vary across domains. We further constrain the domain shift to have a restrictive influence on the changing components. Under mild conditions, we show that the latent variables are partially identifiable, from which it follows that the joint distribution of data and labels in the target domain is also identifiable. Give
    
[^38]: 缺失非随机机制下的充分识别条件和半参数估计

    Sufficient Identification Conditions and Semiparametric Estimation under Missing Not at Random Mechanisms. (arXiv:2306.06443v1 [stat.ME])

    [http://arxiv.org/abs/2306.06443](http://arxiv.org/abs/2306.06443)

    本论文针对缺失非随机数据的问题进行研究，在更加灵活的假设条件下，建立了对完整数据的充分识别条件和半参数估计方法。

    

    在存在缺失非随机（MNAR）数据的情况下进行有效的统计分析是具有挑战性的，在这种情况下，缺失机制依赖于缺失值本身，即使已知观测数据。在这里，我们考虑一个MNAR模型，它通过两种方式推广了几个先前流行的MNAR模型：首先，在随机独立性假设方面更加灵活，其次，它允许观察样本中的所有变量都具有缺失值。这个MNAR模型对应于在缺失数据的图形模型中考虑的所谓criss-cross结构，它阻止了整个缺失数据模型的非参数识别。尽管如此，完整数据分布的一部分仍然可以被非参数识别。通过利用这个事实，并考虑一个丰富的指数家族分布，我们建立了完整数据的充分识别条件和半参数估计。

    Conducting valid statistical analyses is challenging in the presence of missing-not-at-random (MNAR) data, where the missingness mechanism is dependent on the missing values themselves even conditioned on the observed data. Here, we consider a MNAR model that generalizes several prior popular MNAR models in two ways: first, it is less restrictive in terms of statistical independence assumptions imposed on the underlying joint data distribution, and second, it allows for all variables in the observed sample to have missing values. This MNAR model corresponds to a so-called criss-cross structure considered in the literature on graphical models of missing data that prevents nonparametric identification of the entire missing data model. Nonetheless, part of the complete-data distribution remains nonparametrically identifiable. By exploiting this fact and considering a rich class of exponential family distributions, we establish sufficient conditions for identification of the complete-data 
    
[^39]: 功能因果贝叶斯优化

    Functional Causal Bayesian Optimization. (arXiv:2306.06409v1 [stat.ML])

    [http://arxiv.org/abs/2306.06409](http://arxiv.org/abs/2306.06409)

    提出功能因果贝叶斯优化（fCBO）方法用于已知因果图中优化目标变量的干预方法。该方法扩展了CBO方法族，使用高斯过程对未知目标进行建模，在再生核希尔伯特空间中定义输入并计算向量值函数之间的距离。演示了在社交网络中的在线广告活动和合成应用中该方法的优点。

    

    本文提出了一种名为“功能因果贝叶斯优化”（fCBO）的方法，用于寻找在已知因果图中优化目标变量的干预方法。fCBO扩展了CBO方法族，以实现功能性干预，即将变量设置为其他变量的确定性函数。fCBO使用高斯过程对未知目标进行建模，其输入在再生核希尔伯特空间中定义，从而可以计算向量值函数之间的距离。反过来，这使得可以通过最大化预期改进获取收购收益，同时保持标准BO设置的典型计算可行性，以便顺序选择要探索的函数。我们介绍了图形标准，以确定考虑功能干预是否允许实现更好的目标效果，并确定选择的干预是否也适用于条件目标效果的最优解。我们在社交网络中的在线广告活动和合成应用中展示了该方法的优势。

    We propose functional causal Bayesian optimization (fCBO), a method for finding interventions that optimize a target variable in a known causal graph. fCBO extends the CBO family of methods to enable functional interventions, which set a variable to be a deterministic function of other variables in the graph. fCBO models the unknown objectives with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We introduce graphical criteria that establish when considering functional interventions allows attaining better target effects, and conditions under which selected interventions are also optimal for conditional target effects. We demonstrate the benefits of the method in a synthetic and in a r
    
[^40]: 差分隐私下的个性化图像联邦学习

    Personalized Graph Federated Learning with Differential Privacy. (arXiv:2306.06399v1 [cs.LG])

    [http://arxiv.org/abs/2306.06399](http://arxiv.org/abs/2306.06399)

    本文提出了一种差分隐私下的个性化图像联邦学习框架，它能够协同学习设备或集群特定的模型，保护每个设备的隐私并提高学习效果。

    

    本文提出了一种个性化图像联邦学习框架，其中分布式连接的服务器和它们各自的边缘设备在保持每个单独设备隐私的同时，协同学习设备或集群特定的模型。该方法利用不同模型之间的相似性，为每个设备提供更相关的体验，即使在数据分布不均和数据集不成比例的情况下也能实现。此外，为了确保安全和高效的协作式个性化学习方法，我们研究了一种利用差分隐私的PGFL实现变体，具体而言就是使用了零聚焦差分隐私，其中噪声序列扰动了模型交换。我们的数学分析表明，所提出的具有隐私保护的PGFL算法在线性时间内收敛于每个簇的最优簇特定解。同时，利用簇之间的相似性也能够导致另一种优秀的解决方案。

    This paper presents a personalized graph federated learning (PGFL) framework in which distributedly connected servers and their respective edge devices collaboratively learn device or cluster-specific models while maintaining the privacy of every individual device. The proposed approach exploits similarities among different models to provide a more relevant experience for each device, even in situations with diverse data distributions and disproportionate datasets. Furthermore, to ensure a secure and efficient approach to collaborative personalized learning, we study a variant of the PGFL implementation that utilizes differential privacy, specifically zero-concentrated differential privacy, where a noise sequence perturbs model exchanges. Our mathematical analysis shows that the proposed privacy-preserving PGFL algorithm converges to the optimal cluster-specific solution for each cluster in linear time. It also shows that exploiting similarities among clusters leads to an alternative o
    
[^41]: 任意维度等变神经网络

    Any-dimensional equivariant neural networks. (arXiv:2306.06327v1 [cs.LG])

    [http://arxiv.org/abs/2306.06327](http://arxiv.org/abs/2306.06327)

    该论文提出了一个新的方法，利用代数拓扑中的表示稳定性，可以定义出一个可以以任意维度为输入的等变神经网络。这种方法使用方便，只需指定网络架构和等变性的组，且在任何训练过程中都可以使用。

    

    传统的监督学习旨在通过将函数拟合到一组具有固定维度的输入/输出对来学习未知映射。然后，在相同维度的输入上定义拟合函数。然而，在许多情况下，未知映射以任意维度的输入作为输入；例如，定义在任意大小的图形上的图形参数和定义在任意数量粒子上的物理量。我们利用代数拓扑中的新现象——表示稳定性，来定义等变神经网络，可以使用固定维度的数据进行训练，然后在任意维度上扩展接受输入。我们的方法易于使用，只需要网络架构和等变性的组，并且可以与任何训练过程结合使用。我们提供了我们方法的简单开源实现，并提供了初步的数值实验。

    Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments.
    
[^42]: 以联邦学习范式为基础的差分隐私切片逆回归

    Differentially private sliced inverse regression in the federated paradigm. (arXiv:2306.06324v1 [stat.ME])

    [http://arxiv.org/abs/2306.06324](http://arxiv.org/abs/2306.06324)

    本文提出了以联邦学习为基础的差分隐私切片逆回归方法，通过协作估计足够维数的降维子空间以保护敏感数据不被暴露，同时采用多种扰动策略保障差分隐私，还能自然地结合协作变量筛选步骤以有效处理高维数据。

    

    我们将广受欢迎的切片逆回归扩展到去解决分散式数据、优先保护隐私和通信效率等挑战。我们的方法，被称为联邦切片逆回归（FSIR），便于多个客户端之间协作估计足够维数的降维子空间，只共享本地估计，以保护敏感数据不被暴露。为了防范潜在的攻击，FSIR还采用了多种扰动策略，包括一种新颖的多元高斯机制，以低成本的统计精度保证差分隐私。此外，FSIR自然地结合了协作变量筛选步骤，能够有效地处理高维客户端数据。FSIR的理论性质在低维和高维设置中得到了证实，并得到了广泛的数字实验和实际数据分析的支持。

    We extend the celebrated sliced inverse regression to address the challenges of decentralized data, prioritizing privacy and communication efficiency. Our approach, federated sliced inverse regression (FSIR), facilitates collaborative estimation of the sufficient dimension reduction subspace among multiple clients, solely sharing local estimates to protect sensitive datasets from exposure. To guard against potential adversary attacks, FSIR further employs diverse perturbation strategies, including a novel multivariate Gaussian mechanism that guarantees differential privacy at a low cost of statistical accuracy. Additionally, FSIR naturally incorporates a collaborative variable screening step, enabling effective handling of high-dimensional client data. Theoretical properties of FSIR are established for both low-dimensional and high-dimensional settings, supported by extensive numerical experiments and real data analysis.
    
[^43]: 最优异构协同线性回归和上下文臂研究

    Optimal Heterogeneous Collaborative Linear Regression and Contextual Bandits. (arXiv:2306.06291v1 [stat.ML])

    [http://arxiv.org/abs/2306.06291](http://arxiv.org/abs/2306.06291)

    本文提出了一种新的估计器MOLAR，它利用协同线性回归和上下文臂问题中的稀疏异质性来提高估计精度，并且相比独立方法具有更好的表现。

    

    大型和复杂的数据集往往来自于几个可能是异构的来源。协同学习方法通过利用数据集之间的共性提高效率，同时考虑可能出现的差异。在这里，我们研究协同线性回归和上下文臂问题，其中每个实例的相关参数等于全局参数加上一个稀疏的实例特定术语。我们提出了一种名为MOLAR的新型二阶段估计器，它通过首先构建实例线性回归估计的逐项中位数，然后将实例特定估计值收缩到中位数附近来利用这种结构。与独立最小二乘估计相比，MOLAR提高了估计误差对数据维度的依赖性。然后，我们将MOLAR应用于开发用于稀疏异构协同上下文臂的方法，这些方法相比独立臂模型具有更好的遗憾保证。我们进一步证明了我们的贡献优于先前在文献中报道的算法。

    Large and complex datasets are often collected from several, possibly heterogeneous sources. Collaborative learning methods improve efficiency by leveraging commonalities across datasets while accounting for possible differences among them. Here we study collaborative linear regression and contextual bandits, where each instance's associated parameters are equal to a global parameter plus a sparse instance-specific term. We propose a novel two-stage estimator called MOLAR that leverages this structure by first constructing an entry-wise median of the instances' linear regression estimates, and then shrinking the instance-specific estimates towards the median. MOLAR improves the dependence of the estimation error on the data dimension, compared to independent least squares estimates. We then apply MOLAR to develop methods for sparsely heterogeneous collaborative contextual bandits, which lead to improved regret guarantees compared to independent bandit methods. We further show that our 
    
[^44]: 能量耗散进化深度算子神经网络

    Energy-Dissipative Evolutionary Deep Operator Neural Networks. (arXiv:2306.06281v1 [stat.ML])

    [http://arxiv.org/abs/2306.06281](http://arxiv.org/abs/2306.06281)

    能量耗散进化深度算子神经网络是一种运算学习神经网络，可为一类偏微分方程提供数值解并保留其物理特性，通过支路网络编码不同的输入函数，干线网络评估输出函数，经过训练可生成运算符近似解。

    

    能量耗散进化深度算子神经网络是一种运算学习神经网络，旨在为一类偏微分方程种子提供数值解，而不是单个偏微分方程，例如带有不同参数或不同初始条件的偏微分方程。该网络由两个子网络组成：支路网络和干线网络。对于目标运算符 G，支路网络在相同数量的传感器上编码不同的输入函数 u，而干线网络评估任何位置的输出函数。通过最小化评估的输出 q 和预期输出 G(u)(y) 之间的误差，DeepONet 生成 G 运算符的良好近似。为了保留偏微分方程的重要物理特性，如能量耗散定律，我们采用标量辅助变量法生成最小化问题。它引入了修改后的能量并实现了无条件的能量耗散定律。

    Energy-Dissipative Evolutionary Deep Operator Neural Network is an operator learning neural network. It is designed to seed numerical solutions for a class of partial differential equations instead of a single partial differential equation, such as partial differential equations with different parameters or different initial conditions. The network consists of two sub-networks, the Branch net and the Trunk net. For an objective operator G, the Branch net encodes different input functions u at the same number of sensors, and the Trunk net evaluates the output function at any location. By minimizing the error between the evaluated output q and the expected output G(u)(y), DeepONet generates a good approximation of the operator G. In order to preserve essential physical properties of PDEs, such as the Energy Dissipation Law, we adopt a scalar auxiliary variable approach to generate the minimization problem. It introduces a modified energy and enables unconditional energy dissipation law a
    
[^45]: 利用辅助数据提高在线教育平台A/B测试分析的精度：新数据和新结果

    Using Auxiliary Data to Boost Precision in the Analysis of A/B Tests on an Online Educational Platform: New Data and New Results. (arXiv:2306.06273v1 [stat.ME])

    [http://arxiv.org/abs/2306.06273](http://arxiv.org/abs/2306.06273)

    A/B测试的小样本和处理效果过小导致效应估计过于不精密，本研究利用历史用户的丰富日志数据的机器学习模型来提高技术，解决了这个问题，有效提高了A/B测试的能力和统计精度。

    

    在线学习平台上的随机A/B测试代表着学习科学中一个激动人心的方向。他们几乎没有任何假设，可以在没有混杂偏差的情况下进行因果效应估计和精确的统计推断即使在小样本下。然而，经常由于实验样本和/或处理效果过小，A/B测试缺乏动力，效应估计过于不精密。最近的方法论进展表明，通过将基于设计的因果估计与历史用户的丰富日志数据的机器学习模型相结合，可以实现大幅提高能力和统计精度。即使没有任何其他假设，使用这些技术得出的估计仍然保持不偏，推断仍然精确。本文回顾了这些方法，并将其应用于包括在在线学习平台ASSISTments内进行的250多个随机A/B比较的新数据集。我们使用四个新的深度学习模型比较不同实验的结果。

    Randomized A/B tests within online learning platforms represent an exciting direction in learning sciences. With minimal assumptions, they allow causal effect estimation without confounding bias and exact statistical inference even in small samples. However, often experimental samples and/or treatment effects are small, A/B tests are underpowered, and effect estimates are overly imprecise. Recent methodological advances have shown that power and statistical precision can be substantially boosted by coupling design-based causal estimation to machine-learning models of rich log data from historical users who were not in the experiment. Estimates using these techniques remain unbiased and inference remains exact without any additional assumptions. This paper reviews those methods and applies them to a new dataset including over 250 randomized A/B comparisons conducted within ASSISTments, an online learning platform. We compare results across experiments using four novel deep-learning mode
    
[^46]: 强化学习中基于回合限制的近优保守探索

    Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints. (arXiv:2306.06265v1 [cs.LG])

    [http://arxiv.org/abs/2306.06265](http://arxiv.org/abs/2306.06265)

    本文研究了强化学习中实现保守探索的问题，提出了名为StepMix的算法，利用现有的安全基线策略平衡开发和探索，同时保证每个回合不违反保守限制，并且能够在不受限制的情况下达到接近最优的后悔量级。

    

    本文研究了在强化学习中实现保守探索的问题，其中学习代理的性能在整个学习过程中保证高于某个特定阈值。研究针对有限状态和动作的标签式回合式马尔可夫决策过程（MDP）环境。本文提出了一种名为StepMix的算法，利用现有的安全基线策略在保证每个回合不违反保守限制的前提下，平衡开发和探索。StepMix具有独特的混合策略设计，自适应地、平滑地插值基线策略和乐观策略之间。理论分析表明，StepMix在不受限制的情况下具有接近最优的后悔量级，说明遵守严格的回合限制不会损害学习性能。此外，还提出了基于随机化的EpsMix算法。

    This paper investigates conservative exploration in reinforcement learning where the performance of the learning agent is guaranteed to be above a certain threshold throughout the learning process. It focuses on the tabular episodic Markov Decision Process (MDP) setting that has finite states and actions. With the knowledge of an existing safe baseline policy, an algorithm termed as StepMix is proposed to balance the exploitation and exploration while ensuring that the conservative constraint is never violated in each episode with high probability. StepMix features a unique design of a mixture policy that adaptively and smoothly interpolates between the baseline policy and the optimistic policy. Theoretical analysis shows that StepMix achieves near-optimal regret order as in the constraint-free setting, indicating that obeying the stringent episode-wise conservative constraint does not compromise the learning performance. Besides, a randomization-based EpsMix algorithm is also proposed
    
[^47]: 基于谱间隔的确定性张量补全

    Spectral gap-based deterministic tensor completion. (arXiv:2306.06262v1 [stat.ML])

    [http://arxiv.org/abs/2306.06262](http://arxiv.org/abs/2306.06262)

    本文界定了Poisson loss和原子范数最小化两种张量补全方法的解的泛化误差，提供了更紧的界限，针对$r$的依赖性从之前的$r^{2(t-1)(t^2-t-1)}$改进为$r^{2(t-1)(3t-5)}$。根据采样稀疏模式的谱间隔控制误差界限，同时证明了原子张量范数的几个新属性，但原子范数最小化存在计算挑战。

    

    张量补全是一个核心的机器学习算法，用于推荐系统和其他带有缺失数据的领域。虽然对于矩阵情况已有深入研究，但针对张量问题的理论结果仍然有限，特别是当采样模式是确定性的时候。在本文中，我们对两种张量补全方法的解的泛化误差进行了界定，分别是Poisson loss和原子范数最小化，用目标张量秩作为判断依据，提供了更紧的界限。如果目标张量的阶数为$t$，CP秩为$r$，则我们的界限中针对$r$的依赖性从arXiv:1910.10692的$r^{2(t-1)(t^2-t-1)}$改进为$r^{2(t-1)(3t-5)}$。我们的误差界是由采样稀疏模式的谱间隔决定的。我们还证明了原子张量范数的几个新属性，在随机采样方案下将秩的依赖性从arXiv:1711.04965的$r^{3t-3}$减少到$r^{3t-5}$。然而，原子范数最小化的一个局限性是，虽然在理论上很有趣，但会导致计算上的挑战。

    Tensor completion is a core machine learning algorithm used in recommender systems and other domains with missing data. While the matrix case is well-understood, theoretical results for tensor problems are limited, particularly when the sampling patterns are deterministic. Here we bound the generalization error of the solutions of two tensor completion methods, Poisson loss and atomic norm minimization, providing tighter bounds in terms of the target tensor rank. If the ground-truth tensor is order $t$ with CP-rank $r$, the dependence on $r$ is improved from $r^{2(t-1)(t^2-t-1)}$ in arXiv:1910.10692 to $r^{2(t-1)(3t-5)}$. The error in our bounds is deterministically controlled by the spectral gap of the sampling sparsity pattern. We also prove several new properties for the atomic tensor norm, reducing the rank dependence from $r^{3t-3}$ in arXiv:1711.04965 to $r^{3t-5}$ under random sampling schemes. A limitation is that atomic norm minimization, while theoretically interesting, leads
    
[^48]: 基于排列的假设检验的持久图向量摘要

    Vector Summaries of Persistence Diagrams for Permutation-based Hypothesis Testing. (arXiv:2306.06257v1 [stat.ML])

    [http://arxiv.org/abs/2306.06257](http://arxiv.org/abs/2306.06257)

    研究了基于排列的假设检验，提出了持久图向量摘要方法。

    

    在过去的十年中，拓扑数据分析技术（TDA）已经成为描述数据形状的重要方法。近年来，越来越多的人开始关注开发统计学方法，特别是TDA的假设检验程序。在统计学角度下，持久图是由TDA提供的数据的中心多尺度拓扑描述符，被视为从某个人群或过程中随机抽样的观察值。在这种情况下，最早关于假设检验的工作之一便是专注于两组排列的方法，其中相关的损失函数是通过组内两两瓶颈或Wasserstein距离来定义的(Robinson和Turner，2017)。然而，在持久图数量庞大的情况下，要应用于所考虑问题的排列测试计算成本将变得更高。为了解决这个问题，我们将考虑持久图之间的成对距离。

    Over the past decade, the techniques of topological data analysis (TDA) have grown into prominence to describe the shape of data. In recent years, there has been increasing interest in developing statistical methods and in particular hypothesis testing procedures for TDA. Under the statistical perspective, persistence diagrams -- the central multi-scale topological descriptors of data provided by TDA -- are viewed as random observations sampled from some population or process. In this context, one of the earliest works on hypothesis testing focuses on the two-group permutation-based approach where the associated loss function is defined in terms of within-group pairwise bottleneck or Wasserstein distances between persistence diagrams (Robinson and Turner, 2017). However, in situations where persistence diagrams are large in size and number, the permutation test in question gets computationally more costly to apply. To address this limitation, we instead consider pairwise distances betw
    
[^49]: 基于特征编程的多元时间序列预测

    Feature Programming for Multivariate Time Series Prediction. (arXiv:2306.06252v1 [cs.LG])

    [http://arxiv.org/abs/2306.06252](http://arxiv.org/abs/2306.06252)

    该论文提出了一种基于特征编程的多元时间序列预测框架，能够生成大量预测特征，同时允许用户以最小的工作量结合他们的归纳偏差。该框架基于细粒度的轨迹增量，引入了新型自旋气体动力学伊辛模型，并提供了一个简约的算子集来总结多元时间序列。

    

    我们引入了可编程特征工程的概念，提出了一个特征编程框架，为嘈杂的多元时间序列生成大量预测特征，同时允许用户以最小的工作量结合他们的归纳偏差。我们的框架的关键动机是将任何多元时间序列视为细粒度轨迹增量的累积总和，其中每个增量由一种新型自旋气体动力学伊辛模型控制。这种细粒度的视角激发了发展一个简约的算子集，以抽象的方式总结多元时间序列，为大规模的自动特征工程提供基础。数值上，我们验证了我们的方法在几个合成和真实世界的嘈杂时间序列数据集上的有效性。

    We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets.
    
[^50]: 使用集合型反馈的在线学习

    Online Learning with Set-Valued Feedback. (arXiv:2306.06247v1 [cs.LG])

    [http://arxiv.org/abs/2306.06247](http://arxiv.org/abs/2306.06247)

    本文研究了一种在线多类分类的变体，其中使用集合型反馈。通过引入新的组合维度，该论文表明确定性和随机性的在线可学习性在实现设置下不等价，并将在线多标签排名和在线多标签分类等实际学习设置作为其特定实例。

    

    本文研究了在线多类分类的一种变体，其中学习器预测单个标签，但接收到一个标签的集合作为反馈。在该模型中，如果学习器没有输出包含在反馈集合中的标签，则会受到惩罚。我们表明，与具有单标签反馈的在线多类学习不同，在实现设置中使用集合型反馈时，确定性和随机化的在线可学习性\textit{不等价}。因此，我们提供了两个新的组合维度，分别命名为集合小石和度量破裂维度，严格描述了确定性和随机化的在线可学习性。此外，我们表明度量破裂维度在悟性设置下严格描述在线可学习性。最后，我们证明了在线多标签排名和在线多标签分类等实际学习设置是我们通用在线学习框架的具体实例。

    We study a variant of online multiclass classification where the learner predicts a single label but receives a \textit{set of labels} as feedback. In this model, the learner is penalized for not outputting a label contained in the revealed set. We show that unlike online multiclass learning with single-label feedback, deterministic and randomized online learnability are \textit{not equivalent} even in the realizable setting with set-valued feedback. Accordingly, we give two new combinatorial dimensions, named the Set Littlestone and Measure Shattering dimension, that tightly characterize deterministic and randomized online learnability respectively in the realizable setting. In addition, we show that the Measure Shattering dimension tightly characterizes online learnability in the agnostic setting. Finally, we show that practical learning settings like online multilabel ranking and online multilabel classification are specific instances of our general online learning framework.
    
[^51]: 交互式估计的统一模型和维度

    A Unified Model and Dimension for Interactive Estimation. (arXiv:2306.06184v1 [cs.LG])

    [http://arxiv.org/abs/2306.06184](http://arxiv.org/abs/2306.06184)

    该论文提出了交互式估计的统一学习框架，引入组合度量差异维度来捕捉模型的可学习性，提出了多项式的遗憾和PAC泛化界限的算法，并统一了统计查询学习和结构化赌博问题。

    

    我们研究了一种称为"交互式估计"的抽象学习框架，其目标是根据学习者查询到的样本点与目标之间的"相似性"来估计目标。我们引入了一种称为差异维度的组合度量，它在很大程度上捕捉了我们模型中的可学习性。我们提出了一个简单、通用且广泛适用的算法，对于这个算法，我们获得了在新的维度上多项式的遗憾和PAC泛化界限。我们表明我们的框架包含了并因此统一了两个经典的学习模型：统计查询学习和结构化赌博问题。我们还说明了差异维度如何与这两个框架中的众所周知的参数相关，有时可以获得显著改进的分析。

    We study an abstract framework for interactive learning called interactive estimation in which the goal is to estimate a target from its "similarity'' to points queried by the learner. We introduce a combinatorial measure called dissimilarity dimension which largely captures learnability in our model. We present a simple, general, and broadly-applicable algorithm, for which we obtain both regret and PAC generalization bounds that are polynomial in the new dimension. We show that our framework subsumes and thereby unifies two classic learning models: statistical-query learning and structured bandits. We also delineate how the dissimilarity dimension is related to well-known parameters for both frameworks, in some cases yielding significantly improved analyses.
    
[^52]: 强度轮廓投影：用于动态网络的连续时间表示学习框架。

    Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks. (arXiv:2306.06155v1 [cs.LG])

    [http://arxiv.org/abs/2306.06155](http://arxiv.org/abs/2306.06155)

    本文提出了一种连续时间网络表示学习框架，涵盖核平滑的强度函数估计、最小化强度重构误差的投影学习和归纳构造节点表示。这种表示保留了网络结构和时间一致性。

    

    我们提出了一种名为“强度轮廓投影”的新算法框架，用于学习动态网络节点的连续时间表示，该动态网络由节点集和在连续时间内发生的瞬时交互事件的集合所特征化。我们的框架包括三个阶段：通过核平滑等方法估计节点对之间交互的强度函数；学习一个最小化某种强度重构误差的投影；通过学习的投影归纳构造出不断发展的节点表示。我们展示了我们的表示保留了网络的基本结构，并具有时间一致性，这意味着节点表示可以在不同的时间点上进行有意义的比较。同时，我们也构建了估计理论来阐明平滑作为偏差方差折衷的作用，并展示了如何随着信噪比的增加而减少平滑程度以获得更好的性能。

    We present a new algorithmic framework, Intensity Profile Projection, for learning continuous-time representations of the nodes of a dynamic network, characterised by a node set and a collection of instantaneous interaction events which occur in continuous time. Our framework consists of three stages: estimating the intensity functions underlying the interactions between pairs of nodes, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and inductively constructing evolving node representations via the learned projection. We show that our representations preserve the underlying structure of the network, and are temporally coherent, meaning that node representations can be meaningfully compared at different points in time. We develop estimation theory which elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce smoothing as the signal-to-noise ratio increases on account of the algorithm `borrow
    
[^53]: 预测电动汽车充电站占用率: 智慧出行数据挑战

    Forecasting Electric Vehicle Charging Station Occupancy: Smarter Mobility Data Challenge. (arXiv:2306.06142v1 [cs.DB])

    [http://arxiv.org/abs/2306.06142](http://arxiv.org/abs/2306.06142)

    该论文针对电动汽车充电行为制定更准确的预测模型，利用智慧出行数据挑战开发分层预测方法来预测EV充电站占用率，取得了很好的结果，为电动出行的能源供应商和用户提供了宝贵的参考。

    

    交通业是欧洲温室气体排放的主要贡献者。转向使用低碳能源的电动汽车（EV）可以减少碳排放。然而，为了支持电动出行的发展，我们需要更好地理解电动汽车充电行为和制定更准确的预测模型。为了填补这个空白，智慧出行数据挑战聚焦于开发预测模型以预测EV充电站占用率。这个挑战涉及对2020-2021年7个月内4个地理区域的91个充电站数据集的分析。预测结果在三个不同级别（单个充电站、区域和整体）上进行了评估，以捕捉数据的层次结构。结果凸显出分层预测方法在准确预测EV充电站占用率方面的潜力，为能源供应商和EV用户提供了有价值的见解。这个开放数据集解决了电动出行增长中最关键的问题，结果令人鼓舞。

    The transport sector is a major contributor to greenhouse gas emissions in Europe. Shifting to electric vehicles (EVs) powered by a low-carbon energy mix would reduce carbon emissions. However, to support the development of electric mobility, a better understanding of EV charging behaviours and more accurate forecasting models are needed. To fill that gap, the Smarter Mobility Data Challenge has focused on the development of forecasting models to predict EV charging station occupancy. This challenge involved analysing a dataset of 91 charging stations across four geographical areas over seven months in 2020-2021. The forecasts were evaluated at three levels of aggregation (individual stations, areas and global) to capture the inherent hierarchical structure of the data. The results highlight the potential of hierarchical forecasting approaches to accurately predict EV charging station occupancy, providing valuable insights for energy providers and EV users alike. This open dataset addr
    
[^54]: SGD中的投石机：训练损失中的尖峰及其通过特征学习对泛化的影响

    Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning. (arXiv:2306.04815v1 [cs.LG])

    [http://arxiv.org/abs/2306.04815](http://arxiv.org/abs/2306.04815)

    本文通过研究SGD训练损失中的尖峰现象，提出了“投石机”优化现象，通过增加与真实预测器的平均梯度外积对齐来促进特征学习，并证明较小的批量大小可提高泛化性能。

    

    本文首先解释了神经网络在使用随机梯度下降（SGD）进行训练时为什么经常出现训练损失尖峰的现象。我们提供了证据表明，SGD训练损失中的尖峰是“投石机”，这是一种优化现象，最初在[Lewkowycz等人，2020年]的大学习率GD中观察到。我们通过实验证明这些投石机出现在由正切内核的前几个特征向量所张成的低维子空间中，适用于GD和SGD。其次，我们提出了一个解释，即投石机如何通过增加与真实预测器的平均梯度外积（AGOP）对齐来促进特征学习，从而实现更好的泛化。此外，我们证明，在SGD中，更小的批量大小会导致更多的投石机出现，从而提高AGOP对齐和测试性能。

    In this paper, we first present an explanation regarding the common occurrence of spikes in the training loss when neural networks are trained with stochastic gradient descent (SGD). We provide evidence that the spikes in the training loss of SGD are "catapults", an optimization phenomenon originally observed in GD with large learning rates in [Lewkowycz et al. 2020]. We empirically show that these catapults occur in a low-dimensional subspace spanned by the top eigenvectors of the tangent kernel, for both GD and SGD. Second, we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance.
    
[^55]: 基于贝叶斯视角的随机优化端到端学习方法

    End-to-End Learning for Stochastic Optimization: A Bayesian Perspective. (arXiv:2306.04174v1 [math.OC])

    [http://arxiv.org/abs/2306.04174](http://arxiv.org/abs/2306.04174)

    本文提出了一种基于贝叶斯视角的随机优化端到端学习方法，为经验风险最小化和分布式鲁棒优化问题提供新的端到端学习算法，方式主要是训练决策映射。该方法在合成的newsvendor问题和经济分配问题上均表现出显著的效果，同时也发现决策映射神经网络架构对测试性能的影响很大。

    

    我们提出了一种基于贝叶斯视角的随机优化端到端学习方法，该方法采用了标准端到端学习算法的思想，训练了一个后验贝叶斯行动映射。在此基础上，我们为解决经验风险最小化和分布式鲁棒优化问题提出了新的端到端学习算法。通过合成的newsvendor问题和基于真实数据的经济分配问题的数值结果，我们展示了不同训练方案之间的关键差异以及决策映射神经网络架构对测试性能的影响。

    We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.
    
[^56]: 分散化SGD和平均方向SAM在渐近意义下是等价的

    Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v1 [cs.LG])

    [http://arxiv.org/abs/2306.02913](http://arxiv.org/abs/2306.02913)

    分散SGD和平均方向SAM在渐近意义下是等价的，D-SGD表现出梯度平滑效应和锐度正则化效应，而且可以提高后验评估，并证明了潜在的泛化能力

    

    分散随机梯度下降（D-SGD）允许在没有中央服务器的控制下，大量设备同时进行协作学习。然而，现有理论认为，分散化不可避免地削弱了泛化能力。本文挑战传统信念，提出了完全新的角度来理解分散学习。我们证明了在一般非凸非-$\beta$-平滑设置下，D-SGD隐式地最小化了平均方向锐度感知最小化（SAM）算法的损失函数。这种惊人的渐近等价揭示了内在的正则化-优化权衡以及分散化的三个优点：（1）D-SGD中存在一个自由的不确定性评估机制，可以提高后验估计；（2）D-SGD表现出梯度平滑效应；（3）D-SGD的锐度正则化效应不会随着总批处理大小的增加而减少，这证明了潜在的泛化能力

    Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization b
    
[^57]: 可控图像生成的扩散自导方法

    Diffusion Self-Guidance for Controllable Image Generation. (arXiv:2306.00986v1 [cs.CV])

    [http://arxiv.org/abs/2306.00986](http://arxiv.org/abs/2306.00986)

    本论文提出了一种扩散自导方法，通过引导扩散模型的内部表示来提供对生成图像的更大控制，可以用于执行具有挑战性的图像操作，同时不需要额外模型或训练。

    

    大规模生成模型能够从详细文本描述中生成高质量的图像。然而，图像的许多方面很难或不可能通过文本来传达。我们引入了自导方法，通过引导扩散模型的内部表示来提供对生成图像的更大控制。我们展示了可以从这些表示中提取出对象的形状、位置和外观等属性并用于指导采样。自导类似于分类器引导，但是使用预训练模型本身中存在的信号，不需要额外的模型或训练。我们展示了如何组合一组简单的属性来执行具有挑战性的图像操作，例如修改对象的位置或大小，将一个图像中的对象外观与另一个图像的布局相结合，将多个图像的对象组合成一个，等等。我们还展示了自导可以用于编辑真实图像。

    Large-scale generative models are capable of producing high-quality images from detailed text descriptions. However, many aspects of an image are difficult or impossible to convey through text. We introduce self-guidance, a method that provides greater control over generated images by guiding the internal representations of diffusion models. We demonstrate that properties such as the shape, location, and appearance of objects can be extracted from these representations and used to steer sampling. Self-guidance works similarly to classifier guidance, but uses signals present in the pretrained model itself, requiring no additional models or training. We show how a simple set of properties can be composed to perform challenging image manipulations, such as modifying the position or size of objects, merging the appearance of objects in one image with the layout of another, composing objects from many images into one, and more. We also show that self-guidance can be used to edit real images
    
[^58]: 稳定性、泛化性和隐私保护：对于随机特征和NTK特征的精确分析

    Stability, Generalization and Privacy: Precise Analysis for Random and NTK Features. (arXiv:2305.12100v1 [stat.ML])

    [http://arxiv.org/abs/2305.12100](http://arxiv.org/abs/2305.12100)

    本论文研究了ERM训练模型对抗强大黑盒攻击的安全问题，并通过两个指标量化模型安全性：单个样本的稳定性和查询与原始数据特征的对齐。在研究中，通过研究RF和NTK回归，证明随着泛化能力的提高，隐私保护可以得到加强。

    

    深度学习模型容易受到恢复攻击，引起用户隐私保护的担忧。针对经验风险最小化（ERM）等常见算法通常不能直接实施安全保障的问题，本文研究了ERM训练模型对抗特定强大黑盒子攻击的安全问题。我们的分析通过两个看似不同但有联系的指标来量化模型安全性：一是相对于单个训练样本的模型稳定性，另一个是攻击查询和原始数据特征的特征对齐。虽然前者在学习理论中已经得到了很好的阐述，并与经典工作中的泛化误差相关，但在我们的研究中，第二种特性是新颖的。我们的关键技术结果为两种原型设置提供了特征对齐的精确刻画：随机特征（RF）和神经切向核（NTK）回归。这证明，随着泛化能力的提高，隐私保护能够得到加强，同时揭示了其他有趣的性质。

    Deep learning models can be vulnerable to recovery attacks, raising privacy concerns to users, and widespread algorithms such as empirical risk minimization (ERM) often do not directly enforce safety guarantees. In this paper, we study the safety of ERM-trained models against a family of powerful black-box attacks. Our analysis quantifies this safety via two separate terms: (i) the model stability with respect to individual training samples, and (ii) the feature alignment between the attacker query and the original data. While the first term is well established in learning theory and it is connected to the generalization error in classical work, the second one is, to the best of our knowledge, novel. Our key technical result provides a precise characterization of the feature alignment for the two prototypical settings of random features (RF) and neural tangent kernel (NTK) regression. This proves that privacy strengthens with an increase in the generalization capability, unveiling also
    
[^59]: 能量引导的熵神经最优输运

    Energy-guided Entropic Neural Optimal Transport. (arXiv:2304.06094v1 [cs.LG])

    [http://arxiv.org/abs/2304.06094](http://arxiv.org/abs/2304.06094)

    本论文提出了一种新的方法，将能量基础模型和熵正则化最优输运结合起来，以解决生成建模问题。我们在2D情景和图像到图像翻译问题中验证了该方法的适用性。

    

    能量基础模型（EBMs）在机器学习社区已经有数十年的历史。自两千年代起，一直有很多高效的方法通过能量势（非归一化的似然函数）来解决生成建模问题。相比之下，最优输运（OT）领域，尤其是神经OT求解器，受到的探索要少得多，仅有一些近期的研究（不包括利用OT作为损失函数来解决问题的WGAN方法）。在本研究中，我们弥合了EBMs和熵正则化OT之间的差距，提出了一种新的方法，允许利用前者的最新发展和技术改进来丰富后者。我们在2D情景和标准的图像到图像翻译问题中验证了我们方法的适用性。为简单起见，我们选择了简短和长跑的EBMs。

    Energy-Based Models (EBMs) are known in the Machine Learning community for the decades. Since the seminal works devoted to EBMs dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. We validate the applicability of our method on toy 2D scenarios as well as standard unpaired image-to-image translation problems. For the sake of simplicity, we choose simple short- and long- run EBMs as a 
    
[^60]: 利用特权信息校正回归中的选择偏差和缺失响应

    Correcting for Selection Bias and Missing Response in Regression using Privileged Information. (arXiv:2303.16800v1 [math.ST])

    [http://arxiv.org/abs/2303.16800](http://arxiv.org/abs/2303.16800)

    该研究提出了一种基于特权信息的重复回归方法，可用于在回归模型中校正选择偏差和缺失响应，这种方法易于实现且表现良好。

    

    当进行回归模型估计时，可能会出现一些标签缺失的数据，或者我们的数据可能会受到选择机制的偏差影响。当响应或选择机制是可忽略的（即，在给定特征的情况下，独立于响应变量），可以使用现成的回归方法；在不可忽略的情况下，通常必须进行偏差调整。我们观察到，特权数据（即只在训练期间可用的数据）可能会使不可忽略的选择机制可忽略，并将这种情况称为特权缺失随机（PMAR）。我们提出了一种新的基于插补的回归方法，称为重复回归，适用于PMAR。我们还考虑了一种重要性加权回归方法和两种方法的双重稳健组合。所提出的方法易于使用大多数流行的现成回归算法进行实现。我们通过大量的模拟实验和对Eye State数据集的实证评估来评估所提出的方法的性能。

    When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism. When the response or selection mechanism is ignorable (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the nonignorable case one typically has to adjust for bias. We observe that privileged data (i.e. data that is only available during training) might render a nonignorable selection mechanism ignorable, and we refer to this scenario as Privilegedly Missing at Random (PMAR). We propose a novel imputation-based regression method, named repeated regression, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a 
    
[^61]: 采用批量更新和/或近似梯度的动量重球法的收敛性

    Convergence of Momentum-Based Heavy Ball Method with Batch Updating and/or Approximate Gradients. (arXiv:2303.16241v1 [math.OC])

    [http://arxiv.org/abs/2303.16241](http://arxiv.org/abs/2303.16241)

    本文研究了含有批量更新和/或近似梯度的动量重球法的收敛性，由于采用了简化的梯度计算方法，大大减少了计算消耗，同时仍能保证收敛性。

    

    本文研究了1964年Polyak引入的凸优化和非凸优化中广为人知的“动量重球”法，并在多种情况下确立了其收敛性。当要求解参数的维度非常高时，更新一部分而不是所有参数可以提高优化效率，称之为“批量更新”，若与梯度法配合使用，则理论上只需计算需要更新的参数的梯度，而在实际中，通过反向传播等方法仅计算部分梯度并不能减少计算量。因此，为了在每一步中减少CPU使用量，可以使用一阶微分或近似梯度代替真实梯度。我们的分析表明，在各种假设下，采用近似梯度信息和/或批量更新的动量重球法仍然可以收敛。

    In this paper, we study the well-known "Heavy Ball" method for convex and nonconvex optimization introduced by Polyak in 1964, and establish its convergence under a variety of situations. Traditionally, most algorthms use "full-coordinate update," that is, at each step, very component of the argument is updated. However, when the dimension of the argument is very high, it is more efficient to update some but not all components of the argument at each iteration. We refer to this as "batch updating" in this paper.  When gradient-based algorithms are used together with batch updating, in principle it is sufficient to compute only those components of the gradient for which the argument is to be updated. However, if a method such as back propagation is used to compute these components, computing only some components of gradient does not offer much savings over computing the entire gradient. Therefore, to achieve a noticeable reduction in CPU usage at each step, one can use first-order diffe
    
[^62]: 基于充分统计量的广义数据稀化

    Generalized Data Thinning Using Sufficient Statistics. (arXiv:2303.12931v1 [stat.ME])

    [http://arxiv.org/abs/2303.12931](http://arxiv.org/abs/2303.12931)

    本研究发展了一种基于充分统计量的通用策略，通过松弛求和要求并仅要求函数重构随机变量X，进一步推广了数据稀化方法，扩展了可进行稀化的分布族，并统一了样本分裂和数据稀化。

    

    本文旨在开发一种将随机变量X分解为多个独立随机变量的通用策略，而不会丢失任何有关未知参数的信息。我们通过松弛求和要求并仅要求一些已知的独立随机变量的函数完全重构X来推广了最近一篇论文的过程。该过程的推广有两个目的。首先，它极大地扩展了可进行稀化的分布族。其次，它统一了样本分裂和数据稀化，它们在表面上似乎非常不同，但应用了同样的原理。这个共同的原理是充分性。我们利用这一认识对各种不同的家族进行广义稀疏化操作。

    Our goal is to develop a general strategy to decompose a random variable $X$ into multiple independent random variables, without sacrificing any information about unknown parameters. A recent paper showed that for some well-known natural exponential families, $X$ can be "thinned" into independent random variables $X^{(1)}, \ldots, X^{(K)}$, such that $X = \sum_{k=1}^K X^{(k)}$. In this paper, we generalize their procedure by relaxing this summation requirement and simply asking that some known function of the independent random variables exactly reconstruct $X$. This generalization of the procedure serves two purposes. First, it greatly expands the families of distributions for which thinning can be performed. Second, it unifies sample splitting and data thinning, which on the surface seem to be very different, as applications of the same principle. This shared principle is sufficiency. We use this insight to perform generalized thinning operations for a diverse set of families.
    
[^63]: 在领域泛化中找到能力区域

    Finding Competence Regions in Domain Generalization. (arXiv:2303.09989v1 [cs.LG])

    [http://arxiv.org/abs/2303.09989](http://arxiv.org/abs/2303.09989)

    该论文提出了一个“学习拒绝”框架来解决领域泛化中的默默失败问题。通过预测可信度，该方法在测试分布与训练分布不同的情况下接受超出分布的数据，以识别能力区域。研究发现，通过不同的学习表示衡量无能，增加无能得分会预示着降低准确性。

    

    我们提出了一个“学习拒绝”框架来解决领域泛化中默默失败的问题，即测试分布与训练分布不同的情况。假设有一个温和的分布偏移，我们希望在模型估计的能力预示着可信响应时接受超出分布的数据，而不是直接拒绝超出分布的数据。可信度通过与分类器性能密切相关的代理无能分数进行预测。我们对分类的无能得分进行了全面的实验评估，并强调了拒绝率与准确率之间的权衡。为了与先前的工作进行比较，我们聚焦于标准领域泛化基准，并考虑在闭合和开放世界环境下通过不同的学习表示来衡量无能。我们的结果表明，增加无能分数确实预示着降低准确性，从而导致显着的...

    We propose a "learning to reject" framework to address the problem of silent failures in Domain Generalization (DG), where the test distribution differs from the training distribution. Assuming a mild distribution shift, we wish to accept out-of-distribution (OOD) data whenever a model's estimated competence foresees trustworthy responses, instead of rejecting OOD data outright. Trustworthiness is then predicted via a proxy incompetence score that is tightly linked to the performance of a classifier. We present a comprehensive experimental evaluation of incompetence scores for classification and highlight the resulting trade-offs between rejection rate and accuracy gain. For comparability with prior work, we focus on standard DG benchmarks and consider the effect of measuring incompetence via different learned representations in a closed versus an open world setting. Our results suggest that increasing incompetence scores are indeed predictive of reduced accuracy, leading to significan
    
[^64]: 关于文本向量化技术的鲁棒性研究

    On the Robustness of Text Vectorizers. (arXiv:2303.07203v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.07203](http://arxiv.org/abs/2303.07203)

    本文研究了文本向量化技术中的鲁棒性问题，并证明了流行的嵌入方案具有Hamming距离意义上的鲁棒性。本研究提供了这些方法的定量边界，并展示了其中的常数受文档长度的影响。

    

    机器学习中一个基本问题是模型对输入变化的鲁棒性。在自然语言处理中，模型通常包含第一层嵌入，将词汇序列转换为向量表示。虽然连续输入的稳健性已经被很好地理解，但考虑到离散变化(比如替换句子中的一个词)，情况就不那么明确了。本文正式证明了流行的嵌入方案(如拼接、TF-IDF、段落向量)在Hamming距离意义下表现出鲁棒性，我们为这些方法提供了定量边界，并展示了其中的常数如何受文档长度影响。这些发现通过一系列数值实例加以说明。

    A fundamental issue in machine learning is the robustness of the model with respect to changes in the input. In natural language processing, models typically contain a first embedding layer, transforming a sequence of tokens into vector representations. While the robustness with respect to changes of continuous inputs is well-understood, the situation is less clear when considering discrete changes, for instance replacing a word by another in an input sentence. Our work formally proves that popular embedding schemes, such as concatenation, TF-IDF, and Paragraph Vector (a.k.a. doc2vec), exhibit robustness in the H\"older or Lipschitz sense with respect to the Hamming distance. We provide quantitative bounds for these schemes and demonstrate how the constants involved are affected by the length of the document. These findings are exemplified through a series of numerical examples.
    
[^65]: DP-Fast MH: 大规模贝叶斯推断的私有、快速、准确的Metropolis-Hastings算法

    DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for Large-Scale Bayesian Inference. (arXiv:2303.06171v1 [cs.LG])

    [http://arxiv.org/abs/2303.06171](http://arxiv.org/abs/2303.06171)

    本文提出了一种新的DP-Fast MH算法，用于大规模贝叶斯推断，具有精确、快速和隐私保护的特点。

    This paper proposes a new DP-Fast MH algorithm for large-scale Bayesian inference, which is accurate, fast, and privacy-preserving.

    贝叶斯推断提供了一个从复杂数据中学习和在不确定性下推理的原则性框架。它已经广泛应用于机器学习任务，如医学诊断、药物设计和政策制定。在这些常见应用中，数据可能非常敏感。差分隐私（DP）提供了具有强大最坏情况隐私保证的数据分析工具，并已发展成为隐私保护数据分析的主要方法。在本文中，我们研究了Metropolis-Hastings（MH）算法，这是最基本的MCMC方法之一，用于差分隐私下的大规模贝叶斯推断。虽然大多数现有的私有MCMC算法为了获得隐私而牺牲了准确性和效率，但我们提供了第一个精确且快速的DP MH算法，大多数迭代中仅使用一个小批量的数据。我们进一步揭示了隐私、可扩展性（即批量大小）和效率（即收敛速度）之间的三重权衡，从理论上说明了这一点。

    Bayesian inference provides a principled framework for learning from complex data and reasoning under uncertainty. It has been widely applied in machine learning tasks such as medical diagnosis, drug design, and policymaking. In these common applications, the data can be highly sensitive. Differential privacy (DP) offers data analysis tools with powerful worst-case privacy guarantees and has been developed as the leading approach in privacy-preserving data analysis. In this paper, we study Metropolis-Hastings (MH), one of the most fundamental MCMC methods, for large-scale Bayesian inference under differential privacy. While most existing private MCMC algorithms sacrifice accuracy and efficiency to obtain privacy, we provide the first exact and fast DP MH algorithm, using only a minibatch of data in most iterations. We further reveal, for the first time, a three-way trade-off among privacy, scalability (i.e. the batch size), and efficiency (i.e. the convergence rate), theoretically char
    
[^66]: 变分自编码器的分布式学习：在合成数据生成中的应用

    Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation. (arXiv:2302.11294v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.11294](http://arxiv.org/abs/2302.11294)

    提出了一种新的方法扩展了VAE模型容量，采用无限混合的非对称拉普拉斯分布作为解码器，具有分布拟合能力和调整数据隐私级别的优越性。

    

    尽管变分自编码器（VAE）在计算建模方面很高效，但高斯假设一直被认为是它的主要局限性。在本文中，我们提出了一种新方法，扩展了模型容量（即分布族的表达能力），而不会牺牲VAE框架的计算优势。我们的VAE模型的解码器由无限组合的非对称拉普拉斯分布构成，具有连续变量的分布拟合能力。我们的模型由估计一般分位函数的非参数M-estimator的特殊形式表示，并在理论上建立了所提出模型与分位数估计之间的关系。我们将所提出的模型应用于合成数据生成，特别是在轻松调整数据隐私级别方面，我们的模型展现了其优越性。

    The Gaussianity assumption has been consistently criticized as a main limitation of the Variational Autoencoder (VAE), despite its efficiency in computational modeling. In this paper, we propose a new approach that expands the model capacity (i.e., expressive power of distributional family) without sacrificing the computational advantages of the VAE framework. Our VAE model's decoder is composed of an infinite mixture of asymmetric Laplacian distribution, which possesses general distribution fitting capabilities for continuous variables. Our model is represented by a special form of a nonparametric M-estimator for estimating general quantile functions, and we theoretically establish the relevance between the proposed model and quantile estimation. We apply the proposed model to synthetic data generation, and particularly, our model demonstrates superiority in easily adjusting the level of data privacy.
    
[^67]: AdaGrad 步幅下的随机梯度下降：对未知参数、无界梯度和仿射方差的全适应性高概率研究

    SGD with AdaGrad Stepsizes: Full Adaptivity with High Probability to Unknown Parameters, Unbounded Gradients and Affine Variance. (arXiv:2302.08783v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08783](http://arxiv.org/abs/2302.08783)

    本文提供了针对 AdaGrad 步幅下的SGD算法的更加全面且无限制性的分析，支持多种模型，可以在高概率下处理未知参数和无界梯度。

    

    我们研究了 AdaGrad 步幅下的随机梯度下降：这是一种流行的自适应 (自调节) 的一阶随机优化方法。尽管经过广泛研究，但现有的分析方法存在各种缺陷：它们要么假定对问题参数有一定的了解，要么设定强的全局利普希茨条件，或者不能给出高概率可靠的界限。我们在凸和非凸 (平滑) 情况下，对这种基本方法进行全面无任何限制地分析，另外支持一般的“仿射方差”噪声模型，并在低噪声和高噪声区域中提供锐利的收敛速度。

    We study Stochastic Gradient Descent with AdaGrad stepsizes: a popular adaptive (self-tuning) method for first-order stochastic optimization. Despite being well studied, existing analyses of this method suffer from various shortcomings: they either assume some knowledge of the problem parameters, impose strong global Lipschitz conditions, or fail to give bounds that hold with high probability. We provide a comprehensive analysis of this basic method without any of these limitations, in both the convex and non-convex (smooth) cases, that additionally supports a general ``affine variance'' noise model and provides sharp rates of convergence in both the low-noise and high-noise~regimes.
    
[^68]: 通用学习中对抗奖励在上下文Bandits中的应用

    Adversarial Rewards in Universal Learning for Contextual Bandits. (arXiv:2302.07186v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.07186](http://arxiv.org/abs/2302.07186)

    本文研究了在上下文Bandits中学习的基本极限，给出了关于可学习的上下文过程和通用一致性算法的特性，并讨论了对抗奖励下的乐观通用一致性学习的不可能性。

    

    本文研究了上下文Bandits中学习的基本极限，其中学习者的奖励取决于其行为和已知上下文，这扩展了经典的多臂赌博机，在有附加信息的情况下。我们对能够实现亚线性遗憾的通用一致性算法感兴趣，相对于任何可测定的固定策略，无需任何功能类限制。然而，奖励机制可以随着时间的推移而发生变化，我们展示了在对抗奖励下，上下文Bandits的乐观通用一致性学习是不可能的。

    We study the fundamental limits of learning in contextual bandits, where a learner's rewards depend on their actions and a known context, which extends the canonical multi-armed bandit to the case where side-information is available. We are interested in universally consistent algorithms, which achieve sublinear regret compared to any measurable fixed policy, without any function class restriction. For stationary contextual bandits, when the underlying reward mechanism is time-invariant, Blanchard et. al (2022) characterized learnable context processes for which universal consistency is achievable; and further gave algorithms ensuring universal consistency whenever this is achievable, a property known as optimistic universal consistency. It is well understood, however, that reward mechanisms can evolve over time, possibly adversarially, and depending on the learner's actions. We show that optimistic universal learning for contextual bandits with adversarial rewards is impossible in gen
    
[^69]: 超似曲空间的大间隔分类的浑拟圆决策边界

    Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.06807](http://arxiv.org/abs/2302.06807)

    本文提出了一种大间隔分类器，它使用浑拟圆决策边界可以优化测地凸优化问题，实验结果表明其竞争性能优越。

    

    近年来，用超似曲空间表示层次结构化数据已经越来越流行，同时，文献中也提出了几个针对这些空间中数据分类的算法。这些算法主要使用超平面或测地线作为决策边界，使用大间隔分类器设置，从而导致一个非凸优化问题。在本文中，我们提出了一种基于浑拟圆决策边界的新型大间隔分类器，它可以导致一个测地凸优化问题，可以使用任何黎曼梯度下降技术来优化，保证全局最优解。我们展示了几个实验，展示了我们的分类器相比于 SOTA 的竞争性能。

    Hyperbolic spaces have been quite popular in the recent past for representing hierarchically organized data. Further, several classification algorithms for data in these spaces have been proposed in the literature. These algorithms mainly use either hyperplanes or geodesics for decision boundaries in a large margin classifiers setting leading to a non-convex optimization problem. In this paper, we propose a novel large margin classifier based on horospherical decision boundaries that leads to a geodesically convex optimization problem that can be optimized using any Riemannian gradient descent technique guaranteeing a globally optimal solution. We present several experiments depicting the competitive performance of our classifier in comparison to SOTA.
    
[^70]: 可解释的性能：衡量预测性能的驱动力

    Explainable Performance: Measuring the Driving Forces of Predictive Performance. (arXiv:2212.05866v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.05866](http://arxiv.org/abs/2212.05866)

    XPER方法能衡量输入特征对模型预测性能的具体贡献，并可用于处理异质性问题，构建同质化个体群体，从而提高预测精度。

    

    我们引入了XPER（eXplainable PERformance）方法来衡量输入特征对模型预测性能的具体贡献。我们的方法在理论上基于Shapley值，既不依赖于模型，也不依赖于性能度量。此外，XPER可在模型级别或个体级别实现。我们证明XPER具有标准解释性方法（SHAP）的特殊情况。在贷款违约预测应用中，我们展示了如何利用XPER处理异质性问题，并显著提高样本外性能。为此，我们通过基于个体XPER值对他们进行聚类来构建同质化的个体群体。我们发现估计群体特定的模型比一个模型适用于所有个体具有更高的预测精度。

    We introduce the XPER (eXplainable PERformance) methodology to measure the specific contribution of the input features to the predictive performance of a model. Our methodology is theoretically grounded on Shapley values and is both model-agnostic and performance metric-agnostic. Furthermore, XPER can be implemented either at the model level or at the individual level. We demonstrate that XPER has as a special case the standard explainability method in machine learning (SHAP). In a loan default forecasting application, we show how XPER can be used to deal with heterogeneity issues and significantly boost out-of-sample performance. To do so, we build homogeneous groups of individuals by clustering them based on their individual XPER values. We find that estimating group-specific models yields a much higher predictive accuracy than with a one-fits-all model.
    
[^71]: 从模型梯度重构训练数据，具有可证明性。

    Reconstructing Training Data from Model Gradient, Provably. (arXiv:2212.03714v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03714](http://arxiv.org/abs/2212.03714)

    通过单个梯度查询可重构训练数据，存在隐私泄露威胁。

    

    在隐私方面，理解模型梯度何时以及如何泄露有关训练样本的信息是一个重要问题。在本文中，我们提出了一个令人惊讶的结果：即使没有训练或记忆数据，我们也可以从在随机选择的参数值处进行的单个梯度查询中完全重构训练样本。我们证明了在温和条件下的训练数据的可识别性：使用浅层或深层神经网络和各种激活函数。我们还提出了一种基于张量分解的统计和计算高效算法来重构训练数据。作为揭示敏感训练数据的可证明攻击，我们的发现表明了对隐私的潜在严重威胁，尤其是在联合学习中。

    Understanding when and how much a model gradient leaks information about the training sample is an important question in privacy. In this paper, we present a surprising result: even without training or memorizing the data, we can fully reconstruct the training samples from a single gradient query at a randomly chosen parameter value. We prove the identifiability of the training data under mild conditions: with shallow or deep neural networks and a wide range of activation functions. We also present a statistically and computationally efficient algorithm based on tensor decomposition to reconstruct the training data. As a provable attack that reveals sensitive training data, our findings suggest potential severe threats to privacy, especially in federated learning.
    
[^72]: 线性干预下的因果分离

    Linear Causal Disentanglement via Interventions. (arXiv:2211.16467v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.16467](http://arxiv.org/abs/2211.16467)

    本文探讨了线性潜在因果模型中的因果分离问题，指出对于识别性干预数据是必要的，而每个潜在变量的单一干预就足够了。

    

    因果分离旨在通过一个因果模型来表示涉及的潜在变量。如果潜在模型和从潜在变量到观测变量的转换都是唯一的，则表示是可识别的。本文研究了观测变量是线性潜在因果模型的线性转换。对于识别性，干预数据是必要的：如果一个潜在变量缺少干预，我们将展示存在无法区分的不同模型。反之，我们展示每个潜在变量的单一干预就足够了。我们的证明使用了一个矩阵的RQ分解的推广，取代了通常的正交和上三角条件，而是用基于潜在因果模型确定的行的偏序的类似条件。我们利用一个用于因果分离的方法来证明了我们的理论结果。

    Causal disentanglement seeks a representation of data involving latent variables that relate to one another via a causal model. A representation is identifiable if both the latent model and the transformation from latent to observed variables are unique. In this paper, we study observed variables that are a linear transformation of a linear latent causal model. Data from interventions are necessary for identifiability: if one latent variable is missing an intervention, we show that there exist distinct models that cannot be distinguished. Conversely, we show that a single intervention on each latent variable is sufficient for identifiability. Our proof uses a generalization of the RQ decomposition of a matrix that replaces the usual orthogonal and upper triangular conditions with analogues depending on a partial order on the rows of the matrix, with partial order determined by a latent causal model. We corroborate our theoretical results with a method for causal disentanglement that ac
    
[^73]: 带装载和覆盖约束的上下文幸存者问题：基于回归的模块化Lagrangian方法

    Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression. (arXiv:2211.07484v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.07484](http://arxiv.org/abs/2211.07484)

    该论文研究了一种带有资源线性约束的上下文幸存者问题的变种，提出了一种新的算法，该算法简单、计算效率高，同时能够实现较低的后悔。此外，当某些约束被违反时，算法在统计上是最优的。

    

    我们考虑一种上下文幸存者问题的变种，其中算法在总消费的线性约束下使用多个资源。这个问题推广了带背包的上下文幸存者问题(CBwK)，允许装载和覆盖约束，以及正负资源消耗。我们提出了一种新算法，简单、计算效率高，能够实现退化的后悔。当某些约束被违反时，对于CBwK，它在统计上是最优的。我们的算法基于LagrangianBwK(Immorlica等人，FOCS 2019)，这是一种面向CBwK的Lagrangian技术，以及SquareCB(Foster和Rakhlin，ICML 2020)，这是一种面向上下文幸存者的回归技术。我们的分析利用了两种技术本质上的模块化。

    We consider a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We present a new algorithm that is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for CBwK when an algorithm must stop once some constraint is violated. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019) , a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.
    
[^74]: MARS: 函数空间中基于分数匹配的元学习

    MARS: Meta-Learning as Score Matching in the Function Space. (arXiv:2210.13319v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13319](http://arxiv.org/abs/2210.13319)

    本文提出了一种新的元学习方法，通过在函数空间中执行推理，从而避免了指定高维神经网络参数的先验分布族时的限制，可以无缝获取和表示复杂的先验知识。

    

    元学习旨在从一组相关的数据集中提取有用的归纳偏置。在贝叶斯元学习中，通常通过构建神经网络参数的先验分布来实现这一点。然而，指定一组可行的高维神经网络参数的先验分布族是困难的。因此，现有方法采用元学习限制性的对角高斯先验，严重限制了其表达能力和性能。为了解决这些问题，我们通过函数贝叶斯神经网络推理的视角来看待元学习，将先验视为随机过程，在函数空间中执行推理。具体来说，我们将元训练任务视为从数据生成过程中的样本，并将元学习形式化为经验估计这个随机过程的定律。我们的方法可以通过元学习分数函数，无缝获取和表示复杂的先验知识。

    Meta-learning aims to extract useful inductive biases from a set of related datasets. In Bayesian meta-learning, this is typically achieved by constructing a prior distribution over neural network parameters. However, specifying families of computationally viable prior distributions over the high-dimensional neural network parameters is difficult. As a result, existing approaches resort to meta-learning restrictive diagonal Gaussian priors, severely limiting their expressiveness and performance. To circumvent these issues, we approach meta-learning through the lens of functional Bayesian neural network inference, which views the prior as a stochastic process and performs inference in the function space. Specifically, we view the meta-training tasks as samples from the data-generating process and formalize meta-learning as empirically estimating the law of this stochastic process. Our approach can seamlessly acquire and represent complex prior knowledge by meta-learning the score functi
    
[^75]: 怠惰神经元现象：变压器模型激活稀疏性的出现

    The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers. (arXiv:2210.06313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.06313](http://arxiv.org/abs/2210.06313)

    本文研究了使用变压器模型的机器学习模型中激活图的稀疏现象，发现在不同层数的变压器配置和其他体系结构中都出现了稀疏现象。

    

    本文研究了变压器模型的机器学习模型的激活图稀疏的奇特现象。我们通过中间层多层感知器（MLP）使用ReLU激活函数的输出来表示激活图，稀疏是指平均情况下每个输入到MLP的非零元素非常少（例如，T5-Base为3.0％，ViT-B16为6.3％）。此外，较大的变压器和更宽的MLP隐藏层维度会产生更稀疏的激活图。通过大量实验，我们证明了稀疏的出现是一种普遍现象，它出现在自然语言处理和视觉任务中，出现在训练和评估数据中，在不同层数的变压器配置和其他体系结构中，也包括MLP-混合器和2层MLP。我们还表明，使用具有随机标签或随机输入的训练数据集也会出现稀疏现象。

    This paper studies the curious phenomenon for machine learning models with Transformer architectures that their activation maps are sparse. By activation map we refer to the intermediate output of the multi-layer perceptrons (MLPs) after a ReLU activation function, and by sparse we mean that on average very few entries (e.g., 3.0% for T5-Base and 6.3% for ViT-B16) are nonzero for each input to MLP. Moreover, larger Transformers with more layers and wider MLP hidden dimensions are sparser as measured by the percentage of nonzero entries. Through extensive experiments we demonstrate that the emergence of sparsity is a prevalent phenomenon that occurs for both natural language processing and vision tasks, on both training and evaluation data, for Transformers of various configurations, at layers of all depth levels, as well as for other architectures including MLP-mixers and 2-layer MLPs. We show that sparsity also emerges using training datasets with random labels, or with random inputs,
    
[^76]: 安全贝叶斯优化的元学习先验

    Meta-Learning Priors for Safe Bayesian Optimization. (arXiv:2210.00762v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00762](http://arxiv.org/abs/2210.00762)

    本文提出了一种数据驱动方法，通过元学习先验从离线数据中实现安全的贝叶斯优化，同时开发一种新的框架以数据驱动的方式选择符合安全要求的先验，结果表明，相比于基准方法，元学习先验加快了安全贝叶斯优化的收敛速度并改进了整体性能。

    

    在机器人学中，优化控制器参数并满足安全约束是一个重要的挑战。安全贝叶斯优化通过量化目标和约束中的不确定性来安全地指导探索。然而，在存在未知安全约束的情况下，选择可靠的模型超参数以避免安全违规至关重要，但人工设计适合的概率模型可能很具有挑战性。本文提出了一种数据驱动的方法，通过元学习先验从离线数据中实现安全的贝叶斯优化。我们借助元学习算法 F-PACOH，在数据稀缺性的情况下提供可靠的不确定性量化。同时，在基准函数和高精度运动系统上，我们通过经验不确定度度量和前沿搜索算法开发了一种新的框架，以数据驱动的方式选择符合安全要求的先验。实验结果表明，相比于基准方法，我们的元学习先验加快了安全贝叶斯优化的收敛速度并改进了整体性能。

    In robotics, optimizing controller parameters under safety constraints is an important challenge. Safe Bayesian optimization (BO) quantifies uncertainty in the objective and constraints to safely guide exploration in such settings. Hand-designing a suitable probabilistic model can be challenging, however. In the presence of unknown safety constraints, it is crucial to choose reliable model hyper-parameters to avoid safety violations. Here, we propose a data-driven approach to this problem by meta-learning priors for safe BO from offline data. We build on a meta-learning algorithm, F-PACOH, capable of providing reliable uncertainty quantification in settings of data scarcity. As core contribution, we develop a novel framework for choosing safety-compliant priors in a data-riven manner via empirical uncertainty metrics and a frontier search algorithm. On benchmark functions and a high-precision motion system, we demonstrate that our meta-learned priors accelerate the convergence of safe 
    
[^77]: 基于时空跟踪数据的足球比赛中阵型和角色变化点检测

    SoccerCPD: Formation and Role Change-Point Detection in Soccer Matches Using Spatiotemporal Tracking Data. (arXiv:2206.10926v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2206.10926](http://arxiv.org/abs/2206.10926)

    SoccerCPD是一个新的足球比赛变点检测框架，旨在将足球比赛中的策略意图阵型和角色变化与临时变化区分开来。该框架的两步变点检测在领域专家注释基础上进行验证，结果显示它可以准确检测战术变化并估计每秒的阵型和角色分配。

    

    在诸如足球和篮球等流体团队运动中，分析团队阵容是从领域参与者的角度理解战术最直观的方式之一。然而，现有方法要么假定团队阵型在比赛中始终保持一致，要么按帧分配阵型，这与实际情况不符。为解决这个问题，我们提出了一个名为SoccerCPD的变点检测框架，可将足球比赛中的策略意图阵型和角色变化与临时变化区分开来。我们首先按帧分配球员角色，然后执行两步变点检测：（1）基于角色邻接矩阵序列的阵型变点检测，（2）基于角色排列序列的角色变点检测。使用领域专家注释的基本实况评估SoccerCPD，结果显示我们的方法能够准确检测到战术变化点并估计每秒的阵型和角色分配。

    In fluid team sports such as soccer and basketball, analyzing team formation is one of the most intuitive ways to understand tactics from domain participants' point of view. However, existing approaches either assume that team formation is consistent throughout a match or assign formations frame-by-frame, which disagree with real situations. To tackle this issue, we propose a change-point detection framework named SoccerCPD that distinguishes tactically intended formation and role changes from temporary changes in soccer matches. We first assign roles to players frame-by-frame and perform two-step change-point detections: (1) formation change-point detection based on the sequence of role-adjacency matrices and (2) role change-point detection based on the sequence of role permutations. The evaluation of SoccerCPD using the ground truth annotated by domain experts shows that our method accurately detects the points of tactical changes and estimates the formation and role assignment per s
    
[^78]: 论小批量重球动量法的快速收敛性

    On the fast convergence of minibatch heavy ball momentum. (arXiv:2206.07553v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.07553](http://arxiv.org/abs/2206.07553)

    本文研究了一种随机Kaczmarz算法，使用小批量和重球动量进行加速，在二次优化问题中保持快速收敛率。

    

    简单的随机动量方法被广泛用于机器学习优化中，但由于还没有加速的理论保证，这与它们在实践中的良好性能并不相符。本文旨在通过展示，随机重球动量在二次最优化问题中保持（确定性）重球动量的快速线性率，至少在使用足够大的批量大小进行小批量处理时。我们所研究的算法可以被解释为带小批量处理和重球动量的加速随机Kaczmarz算法。该分析依赖于仔细分解动量转移矩阵，并使用新的独立随机矩阵乘积的谱范围集中界限。我们提供了数值演示，证明了我们的界限相当尖锐。

    Simple stochastic momentum methods are widely used in machine learning optimization, but their good practical performance is at odds with an absence of theoretical guarantees of acceleration in the literature. In this work, we aim to close the gap between theory and practice by showing that stochastic heavy ball momentum retains the fast linear rate of (deterministic) heavy ball momentum on quadratic optimization problems, at least when minibatching with a sufficiently large batch size. The algorithm we study can be interpreted as an accelerated randomized Kaczmarz algorithm with minibatching and heavy ball momentum. The analysis relies on carefully decomposing the momentum transition matrix, and using new spectral norm concentration bounds for products of independent random matrices. We provide numerical illustrations demonstrating that our bounds are reasonably sharp.
    
[^79]: 可微和可传输的结构学习

    Differentiable and Transportable Structure Learning. (arXiv:2206.06354v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.06354](http://arxiv.org/abs/2206.06354)

    D-Struct是一种可微和可传输的结构学习方法，通过新颖的架构和损失函数使得结构可以在同一领域的不同数据集中传输，比NOTEARS和其他最先进的方法具有更好的性能。

    

    有向无环图在它们的结构中编码了关于特定分布的大量信息。然而，推断这些结构所需的计算通常是变量数的超指数，因为推断需要扫描一个组合数量巨大的潜在结构空间。直到最近的进展才使得使用可微度量搜索这个空间成为可能，从而极大地减少了搜索时间。我们介绍了D-Struct，它通过一种新颖的架构和损失函数恢复了发现结构在同一领域中的传输性，同时仍然完全可微。因为D-Struct仍然是可微的，所以我们的方法可以轻松地应用于现有的可微框架中。

    Directed acyclic graphs (DAGs) encode a lot of information about a particular distribution in their structure. However, compute required to infer these structures is typically super-exponential in the number of variables, as inference requires a sweep of a combinatorially large space of potential structures. That is, until recent advances made it possible to search this space using a differentiable metric, drastically reducing search time. While this technique -- named NOTEARS -- is widely considered a seminal work in DAG-discovery, it concedes an important property in favour of differentiability: transportability. To be transportable, the structures discovered on one dataset must apply to another dataset from the same domain. We introduce D-Struct which recovers transportability in the discovered structures through a novel architecture and loss function while remaining fully differentiable. Because D-Struct remains differentiable, our method can be easily adopted in existing different
    
[^80]: 联邦离线强化学习

    Federated Offline Reinforcement Learning. (arXiv:2206.05581v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.05581](http://arxiv.org/abs/2206.05581)

    本文提出了一种联邦离线强化学习算法，可以处理医疗机构间数据共享的隐私限制和异质性问题，同时提供了通信效率和隐私保护性。该算法的样本复杂度证明以及在现实医学数据集上的模拟实验结果表明了其有效性和效率。

    

    基于证据或数据的动态治疗方案对于个性化医疗至关重要，可以受益于离线强化学习（RL）。虽然医疗机构间有大量健康数据可用，但由于隐私限制，它们无法共享。此外，不同站点存在异质性。因此，联邦离线RL算法是必要的且有前途，以解决这些问题。本文提出了一种多站点马尔可夫决策过程模型，允许站点之间的同质性和异质性效应。所提出的模型可以分析站点级特征。我们设计了第一个具有样本复杂度的离线RL联邦策略优化算法。所提出的算法具有通信效率和隐私保护性，仅需要通过交换摘要统计量进行一轮通信交互。我们为所提出的算法提供了理论保证，无需假设站点之间具有相同的转换动态。我们在现实医学数据集上进行了模拟，展示了所提出算法的有效性和效率。

    Evidence-based or data-driven dynamic treatment regimes are essential for personalized medicine, which can benefit from offline reinforcement learning (RL). Although massive healthcare data are available across medical institutions, they are prohibited from sharing due to privacy constraints. Besides, heterogeneity exists in different sites. As a result, federated offline RL algorithms are necessary and promising to deal with the problems. In this paper, we propose a multi-site Markov decision process model which allows both homogeneous and heterogeneous effects across sites. The proposed model makes the analysis of the site-level features possible. We design the first federated policy optimization algorithm for offline RL with sample complexity. The proposed algorithm is communication-efficient and privacy-preserving, which requires only a single round of communication interaction by exchanging summary statistics. We give a theoretical guarantee for the proposed algorithm without the 
    
[^81]: 超越模仿游戏：量化和拓展语言模型的能力

    Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. (arXiv:2206.04615v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.04615](http://arxiv.org/abs/2206.04615)

    本研究引入了Beyond the Imitation Game基准测试（BIG-bench），该测试集包含了204个各领域的难题，旨在评估当前语言模型的能力并为未来的研究提供信息和准备。

    

    随着规模的增大，语言模型展示了数量上的提升和新的定性能力。尽管具有潜在的转变性影响，但这些新的能力目前尚未被充分描述。为了为未来的研究提供信息，为剧变的新型模型能力做准备，并缓解社会有害影响，我们必须了解语言模型的现有和近期能力和限制。为了解决这一挑战，我们引入了Beyond the Imitation Game基准测试（BIG-bench）。BIG-bench目前包括204个任务，由132个机构的450名作者贡献。任务主题多样，涵盖了语言学、儿童发展、数学、常识推理、生物学、物理学、社会偏见、软件开发等等。BIG-bench专注于那些被认为超出了当前语言模型能力的任务。我们评估了OpenAI的GPT模型和谷歌内部的密集转换模型的行为。

    Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transform
    
[^82]: 点积核回归的精确学习曲线和高阶标度极限

    Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression. (arXiv:2205.14846v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14846](http://arxiv.org/abs/2205.14846)

    本文细致研究了点积核岭回归问题，针对 $m\propto d^r$ 高阶标度关系提出了精确的测试误差、偏差和方差公式。

    

    随着现代机器学习模型不断推进计算前沿，开发对不同模型和数据缩放方案下预期性能提高的精确估计变得越来越重要。目前，关于描述预测误差如何随着样本数量而变化的学习曲线的理论理解受限于大样本渐近性 ($m\to\infty$) 或对于某些简单数据分布的高维渐近性，其中样本数量与维数成线性比例 ($m\propto d$)。这两个范畴之间存在很大差距，包括所有高阶标度关系 $m\propto d^r$，这是本文的研究对象。我们专注于点积核岭回归的问题，并提供了在 $m/d\rightarrow2r$ 的 $r$ 阶渐近标度下（其中 $m\to\infty$），对于从球面上均匀抽取的数据，测试误差、偏差和方差的精确公式。

    As modern machine learning models continue to advance the computational frontier, it has become increasingly important to develop precise estimates for expected performance improvements under different model and data scaling regimes. Currently, theoretical understanding of the learning curves that characterize how the prediction error depends on the number of samples is restricted to either large-sample asymptotics ($m\to\infty$) or, for certain simple data distributions, to the high-dimensional asymptotics in which the number of samples scales linearly with the dimension ($m\propto d$). There is a wide gulf between these two regimes, including all higher-order scaling relations $m\propto d^r$, which are the subject of the present paper. We focus on the problem of kernel ridge regression for dot-product kernels and present precise formulas for the test error, bias, and variance, for data drawn uniformly from the sphere in the $r$th-order asymptotic scaling regime $m\to\infty$ with $m/d
    
[^83]: 用于理解神经网络动态的二次模型

    Quadratic models for understanding neural network dynamics. (arXiv:2205.11787v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11787](http://arxiv.org/abs/2205.11787)

    神经二次模型可以展示出神经网络在大学习率情况下的“弹弓阶段”，并且在泛化特性上与神经网络有相似之处，是分析神经网络的有效工具。

    

    当神经网络的宽度增加时，可以用线性模型来逼近神经网络，但宽神经网络的某些特性不能被线性模型捕捉。在这项工作中，我们展示了最近提出的神经二次模型可以展示“弹弓阶段”[Lewkowycz等人，2020]，当使用大学习率训练此类模型时会出现。接着，我们经验证明，神经二次模型的行为与神经网络在泛化特性上有相似之处，尤其是在弹弓阶段范围内。我们的分析进一步表明，二次模型可以成为分析神经网络的有效工具。

    While neural networks can be approximated by linear models as their width increases, certain properties of wide neural networks cannot be captured by linear models. In this work we show that recently proposed Neural Quadratic Models can exhibit the "catapult phase" [Lewkowycz et al. 2020] that arises when training such models with large learning rates. We then empirically show that the behaviour of neural quadratic models parallels that of neural networks in generalization, especially in the catapult phase regime. Our analysis further demonstrates that quadratic models can be an effective tool for analysis of neural networks.
    
[^84]: 具有有向无环图架构的普通神经网络的线性转换

    Transition to Linearity of General Neural Networks with Directed Acyclic Graph Architecture. (arXiv:2205.11786v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11786](http://arxiv.org/abs/2205.11786)

    本文阐明具有任意有向无环图的神经网络，在宽度无限增大的情况下有线性转化的趋势。结果揭示了转化为线性的数学结构，并推广了一系列关于标准架构神经切向核的线性转化或恒定性的最新研究。

    

    本文展示，随着其“宽度”接近无穷大，与任意有向无环图相关的前馈神经网络会发生线性转换。这些普通网络的宽度由其神经元的最小入度（除了输入和第一层之外）来刻画。我们的结果确定了转换到线性所基于的数学结构，并概括了一些旨在表征标准架构下神经切向核的线性转换或恒定性的最近研究工作。

    In this paper we show that feedforward neural networks corresponding to arbitrary directed acyclic graphs undergo transition to linearity as their "width" approaches infinity. The width of these general networks is characterized by the minimum in-degree of their neurons, except for the input and first layers. Our results identify the mathematical structure underlying transition to linearity and generalize a number of recent works aimed at characterizing transition to linearity or constancy of the Neural Tangent Kernel for standard architectures.
    
[^85]: 无线网络中的语义信息恢复

    Semantic Information Recovery in Wireless Networks. (arXiv:2204.13366v4 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2204.13366](http://arxiv.org/abs/2204.13366)

    本文提出了一个基于机器学习的语义通信系统SINFONY，它通过对消息进行数据减少和可靠传输来最好地保留语义，从而实现无线网络中的语义信息恢复。

    

    受机器学习工具在无线通信中的成功启发，1949年Weaver提出的语义通信思想引起了人们的关注。 它打破了Shannon的经典设计范例，旨在传递消息的含义，即语义，而不是其确切版本，从而允许节省信息速率。 在这项工作中，我们将Basu等人的建模语义的基本方法扩展到完整通信马尔可夫链。 因此，我们通过隐含的随机变量来建模语义，并将语义通信任务定义为通过通信信道对消息进行数据减少和可靠传输，从而最好地保留语义。 我们将此任务作为端到端信息瓶颈问题进行建模，允许在保留相关信息的同时进行压缩。 作为解决方案，我们提出了基于ML的语义通信系统SINFONY，并将其用于分布式多点场景：SIN。

    Motivated by the recent success of Machine Learning (ML) tools in wireless communications, the idea of semantic communication by Weaver from 1949 has gained attention. It breaks with Shannon's classic design paradigm by aiming to transmit the meaning of a message, i.e., semantics, rather than its exact version and thus allows for savings in information rate. In this work, we extend the fundamental approach from Basu et al. for modeling semantics to the complete communications Markov chain. Thus, we model semantics by means of hidden random variables and define the semantic communication task as the data-reduced and reliable transmission of messages over a communication channel such that semantics is best preserved. We cast this task as an end-to-end Information Bottleneck problem, allowing for compression while preserving relevant information most. As a solution approach, we propose the ML-based semantic communication system SINFONY and use it for a distributed multipoint scenario: SIN
    
[^86]: 风险预算组合和凸非负矩阵分解

    Risk budget portfolios with convex Non-negative Matrix Factorization. (arXiv:2204.02757v2 [q-fin.PM] UPDATED)

    [http://arxiv.org/abs/2204.02757](http://arxiv.org/abs/2204.02757)

    采用凸非负矩阵分解的风险预算组合方法，能够产生可以解释的多头投资组合，具有优异的多样化和风险特征。

    

    我们提出了一种基于风险因子预算的投资组合分配方法，使用凸非负矩阵分解（NMF）。与经典因子分析、PCA或ICA不同，NMF确保正因子载荷以获得可解释的仅多头头寸组合。由于NMF因子代表不同的风险来源，它们具有准对角线相关矩阵，促进了多样化的投资组合分配。我们在加密货币和传统资产的两个仅多头全球组合的波动率定位背景下评估了我们的方法。我们的方法在多样化方面优于传统的投资组合分配，并呈现出比分层风险平价（HRP）更好的风险特征。我们使用蒙特卡罗模拟评估了我们发现的鲁棒性。

    We propose a portfolio allocation method based on risk factor budgeting using convex Nonnegative Matrix Factorization (NMF). Unlike classical factor analysis, PCA, or ICA, NMF ensures positive factor loadings to obtain interpretable long-only portfolios. As the NMF factors represent separate sources of risk, they have a quasi-diagonal correlation matrix, promoting diversified portfolio allocations. We evaluate our method in the context of volatility targeting on two long-only global portfolios of cryptocurrencies and traditional assets. Our method outperforms classical portfolio allocations regarding diversification and presents a better risk profile than hierarchical risk parity (HRP). We assess the robustness of our findings using Monte Carlo simulation.
    
[^87]: 基于星形细胞对关键期的神经可塑性神经网络，通过现有和记忆性的大脑可塑性和突触形成实现突触竞争和强度平衡。（arXiv: 2203.11740v12 [cs.NE] UPDATED）

    Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2203.11740](http://arxiv.org/abs/2203.11740)

    该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。

    

    除了突触共享连接权重之外，PNN还包括突触有效范围的权重[14-25]。PNN考虑突触强度平衡在突触吞噬的动态和长度常数之和的静态中[14]，并包含了鱼群行为的先导行为。突触形成在实验和模拟中会抑制树突生成[15]。类似于Spring Boot中的强制韧性，反向回路的记忆持久度梯度也存在。相对较好和较差的梯度信息存储在类似于脑褶的记忆痕迹细胞中，在反向回路的突触形成中。争议认为人类海马神经元的再生能力是否持续到老年，并可能在后期迭代中形成新的更长的回路[17,18]。关闭关键期会导致神经紊乱在实验和模拟中[19]。考虑到负面和正面记忆的持久性，有助于更好地激活突触。

    In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
    
[^88]: 具有对抗回应的通用回归算法

    Universal Regression with Adversarial Responses. (arXiv:2203.05067v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.05067](http://arxiv.org/abs/2203.05067)

    本文提出了一种通用回归算法，可针对大类非独立同分布实例序列的对抗性回应，在通用可分离指标空间上实现强一致性的通用一致性学习。

    

    本文提出了在通用可分离指标空间上，对于大类非独立同分布实例序列的对抗回归算法，并给出了关于可学习性的特征说明。我们考虑强一致性的通用一致性学习，无需对值回应进行限制。我们的分析表明：这种目标可在比平稳过程更大的实例序列类中实现，并揭示了值空间之间的根本二分法：是否可以实现有限时间段均值估计。我们进一步提供了乐观的通用性学习规则，即如果它们未能实现通用一致性，则其他任何算法也将失败。对于未界限损失，我们提出了一种温和的可积条件，其下有对抗性回归的算法结论。此外，我们还展示了如何将相同的工具应用于带有对抗性误差的通用预测问题。

    We provide algorithms for regression with adversarial responses under large classes of non-i.i.d. instance sequences, on general separable metric spaces, with provably minimal assumptions. We also give characterizations of learnability in this regression context. We consider universal consistency which asks for strong consistency of a learner without restrictions on the value responses. Our analysis shows that such an objective is achievable for a significantly larger class of instance sequences than stationary processes, and unveils a fundamental dichotomy between value spaces: whether finite-horizon mean estimation is achievable or not. We further provide optimistically universal learning rules, i.e., such that if they fail to achieve universal consistency, any other algorithms will fail as well. For unbounded losses, we propose a mild integrability condition under which there exist algorithms for adversarial regression under large classes of non-i.i.d. instance sequences. In additio
    
[^89]: 基于自回归模型的漂移检测方法

    Autoregressive based Drift Detection Method. (arXiv:2203.04769v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.04769](http://arxiv.org/abs/2203.04769)

    本研究提出一种基于自回归模型的漂移检测方法，适用于各种机器学习算法，能够在合成数据和现实数据方面表现优于现有方法。

    

    在传统的机器学习框架中，模型是在历史数据上进行训练，然后用于预测未来值。假设数据分布在时间上不发生变化（平稳性）。然而，在现实世界的场景中，数据生成过程随时间而变化，模型必须适应新的输入数据。这种现象称为概念漂移，导致预测模型的性能下降。在本研究中，我们提出了一种基于自回归模型的新概念漂移检测方法，称为ADDM。该方法可以与任何机器学习算法集成，从深度神经网络到简单线性回归模型。我们的结果表明，这种新的概念漂移检测方法在合成数据集和现实世界数据集上优于现有的概念漂移检测方法。我们的方法在理论上保证，并在检测各种概念漂移方面具有经验和有效性。

    In the classic machine learning framework, models are trained on historical data and used to predict future values. It is assumed that the data distribution does not change over time (stationarity). However, in real-world scenarios, the data generation process changes over time and the model has to adapt to the new incoming data. This phenomenon is known as concept drift and leads to a decrease in the predictive model's performance. In this study, we propose a new concept drift detection method based on autoregressive models called ADDM. This method can be integrated into any machine learning algorithm from deep neural networks to simple linear regression model. Our results show that this new concept drift detection method outperforms the state-of-the-art drift detection methods, both on synthetic data sets and real-world data sets. Our approach is theoretically guaranteed as well as empirical and effective for the detection of various concept drifts. In addition to the drift detector,
    
[^90]: 论缺失数据模型中的可检验性和拟合优度检验

    On Testability and Goodness of Fit Tests in Missing Data Models. (arXiv:2203.00132v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2203.00132](http://arxiv.org/abs/2203.00132)

    本文提供了关于缺失数据图模型的可检验性和设计拟合优度测试的新见解。

    

    在描述有向无环图可以描述建模假设的缺失数据问题中，已经取得了重要进展。使用这些技术得到的结果的有效性取决于图所编码的假设是否成立，然而，在先前的工作中，对这些假设的验证没有得到足够的关注。本文提供了关于三类缺失数据图模型的可检验性和设计拟合优度测试的新见解。探讨的模型类别包括：可以用于建模具有退出/截尾的纵向研究的序贯缺失随机模型和缺失非随机模型，以及可以应用于横截面研究和调查的非自我截断模型。

    Significant progress has been made in developing identification and estimation techniques for missing data problems where modeling assumptions can be described via a directed acyclic graph. The validity of results using such techniques rely on the assumptions encoded by the graph holding true; however, verification of these assumptions has not received sufficient attention in prior work. In this paper, we provide new insights on the testable implications of three broad classes of missing data graphical models, and design goodness-of-fit tests for them. The classes of models explored are: sequential missing-at-random and missing-not-at-random models which can be used for modeling longitudinal studies with dropout/censoring, and a no self-censoring model which can be applied to cross-sectional studies and surveys.
    
[^91]: 加速正-对偶方法求解正则化马尔可夫决策过程

    Accelerating Primal-dual Methods for Regularized Markov Decision Processes. (arXiv:2202.10506v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2202.10506](http://arxiv.org/abs/2202.10506)

    本文介绍了一种新的正-对偶表述方法，结合新的插值度量，可以显著加速收敛。数值结果表明方法在多种设置下性能优越。

    

    熵正则化马尔可夫决策过程在强化学习中已被广泛应用。本文关注熵正则化问题的正-对偶表述。由于缺乏严格的凸性和凹性，标准的一阶方法收敛缓慢。为解决这个问题，我们首先引入了一个新的二次凸化的正-对偶表述。新表述的自然梯度上升下降具有全局收敛保证和指数收敛速度。我们还提出了一种新的插值度量，可以显著加速收敛。数值结果表明，所提出的方法在多种设置下的性能都很好。

    Entropy regularized Markov decision processes have been widely used in reinforcement learning. This paper is concerned with the primal-dual formulation of the entropy regularized problems. Standard first-order methods suffer from slow convergence due to the lack of strict convexity and concavity. To address this issue, we first introduce a new quadratically convexified primal-dual formulation. The natural gradient ascent descent of the new formulation enjoys global convergence guarantee and exponential convergence rate. We also propose a new interpolating metric that further accelerates the convergence significantly. Numerical results are provided to demonstrate the performance of the proposed methods under multiple settings.
    
[^92]: 公平主动学习：解决保险行业中的标注问题

    Fair Active Learning: Solving the Labeling Problem in Insurance. (arXiv:2112.09466v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.09466](http://arxiv.org/abs/2112.09466)

    本文旨在解决保险行业中普遍存在的机器学习模型在数据中发现的偏见和歧视，提出了公平主动学习方法，能够在实现模型预测性能的同时保证数据公平性。

    

    本文针对在保险行业广泛使用机器学习模型所面临的重大障碍，特别关注促进公平性。最初的挑战在于有效利用未标记的保险数据，通过主动学习技术降低标注的工作量，并强调数据相关性。本文探讨了各种主动学习抽样方法，并评估它们对合成和实际保险数据集的影响。该分析强调了实现公正模型推断的困难，因为机器学习模型可能会复制底层数据中存在的偏见和歧视。为了解决这些相互关联的挑战，本文介绍了一种创新的公平主动学习方法。所提出的方法采样信息量充足且公平的实例，在模型预测性能和公平性之间取得了良好的平衡，这一点在保险数据集上的数值实验中得到了证实。

    This paper addresses significant obstacles that arise from the widespread use of machine learning models in the insurance industry, with a specific focus on promoting fairness. The initial challenge lies in effectively leveraging unlabeled data in insurance while reducing the labeling effort and emphasizing data relevance through active learning techniques. The paper explores various active learning sampling methodologies and evaluates their impact on both synthetic and real insurance datasets. This analysis highlights the difficulty of achieving fair model inferences, as machine learning models may replicate biases and discrimination found in the underlying data. To tackle these interconnected challenges, the paper introduces an innovative fair active learning method. The proposed approach samples informative and fair instances, achieving a good balance between model predictive performance and fairness, as confirmed by numerical experiments on insurance datasets.
    
[^93]: SubseasonalClimateUSA: 用于亚季节预测和基准测试的数据集。

    SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking. (arXiv:2109.10399v3 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2109.10399](http://arxiv.org/abs/2109.10399)

    这个论文介绍了SubseasonalClimateUSA，这是一个用于训练和基准测试美国的亚季节预测模型的数据集。作者使用该数据集对多种模型进行了基准测试。

    

    天气的亚季节预测对资源配置和气候适应至关重要，但对预测社区提出了许多挑战。在这个预测时间范围内，基于物理的动力学模型的技能有限，并且预测目标以一种复杂的方式依赖于本地天气和全球气候变量。最近，机器学习方法显示出推进技术的潜力，但需要复杂的数据整理，将专家知识与多个相关数据来源、文件格式和时间空间分辨率的聚合进行整合。为了简化这个过程并加速未来的发展，我们介绍了SubseasonalClimateUSA，这是一个经过策划的数据集，用于训练和基准测试美国的亚季节预测模型。我们使用这个数据集来对各种不同的亚季节模型进行基准测试，包括操作性动力学模型、古典的气象基线以及十个统计模型。

    Subseasonal forecasting of the weather two to six weeks in advance is critical for resource allocation and climate adaptation but poses many challenges for the forecasting community. At this forecast horizon, physics-based dynamical models have limited skill, and the targets for prediction depend in a complex manner on both local weather and global climate variables. Recently, machine learning methods have shown promise in advancing the state of the art but only at the cost of complex data curation, integrating expert knowledge with aggregation across multiple relevant data sources, file formats, and temporal and spatial resolutions. To streamline this process and accelerate future development, we introduce SubseasonalClimateUSA, a curated dataset for training and benchmarking subseasonal forecasting models in the United States. We use this dataset to benchmark a diverse suite of subseasonal models, including operational dynamical models, classical meteorological baselines, and ten sta
    
[^94]: 基于数据驱动的方法击败SAA（样本平均逼近）的外推问题

    A data-driven approach to beating SAA out-of-sample. (arXiv:2105.12342v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2105.12342](http://arxiv.org/abs/2105.12342)

    本文提出了一类分布乐观优化（DOO）模型，在外推问题上始终能够超越样本平均逼近（SAA）；然而，乐观解的鲁棒性较差且更容易受到模型错误的影响。

    

    虽然分布鲁棒优化（DRO）问题的解有时可能比样本平均逼近（SAA）的预期奖励要高，但并不保证总是这样。本文引入了一类分布乐观优化（DOO）模型，并证明如果我们考虑最优情况（DOO）和最坏情况（DRO）模型，那么总是可以“击败”SAA的外推效果。然而，我们也证明，这是有代价的：乐观解比最坏情况或SAA优化器更敏感于模型错误，因此不太鲁棒，并且在数据有限时很难校准最坏或最优情况模型以超越SAA。

    While solutions of Distributionally Robust Optimization (DRO) problems can sometimes have a higher out-of-sample expected reward than the Sample Average Approximation (SAA), there is no guarantee. In this paper, we introduce a class of Distributionally Optimistic Optimization (DOO) models, and show that it is always possible to ``beat" SAA out-of-sample if we consider not just worst-case (DRO) models but also best-case (DOO) ones. We also show, however, that this comes at a cost: Optimistic solutions are more sensitive to model error than either worst-case or SAA optimizers, and hence are less robust and calibrating the worst- or best-case model to outperform SAA may be difficult when data is limited.
    
[^95]: 一种具有应用于到达模拟和建模的双重随机模拟器

    A Doubly Stochastic Simulator with Applications in Arrivals Modeling and Simulation. (arXiv:2012.13940v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2012.13940](http://arxiv.org/abs/2012.13940)

    该论文提出了一种双重随机模拟器，结合了经典的蒙特卡罗模拟器和神经网络模拟器，用于建模、估计和模拟具有一般非平稳和多维随机到达速率的到达过程，并在高速公路交通和航空交通建模和仿真中得到应用。

    

    我们提出了一种框架，集成了经典的蒙特卡罗模拟器和Wasserstein生成对抗网络，以模拟、估计和模拟具有一般非平稳和多维随机到达速率的广泛到达过程的类别。我们提出了一个双重随机模拟器，它集成了随机生成神经网络和经典的蒙特卡罗泊松模拟器，利用了两者的优势。我们将该框架应用于各种真实世界的应用，包括高速公路交通和航空交通建模和仿真。

    We propose a framework that integrates classical Monte Carlo simulators and Wasserstein generative adversarial networks to model, estimate, and simulate a broad class of arrival processes with general non-stationary and multi-dimensional random arrival rates. Classical Monte Carlo simulators have advantages at capturing the interpretable "physics" of a stochastic object, whereas neural-network-based simulators have advantages at capturing less-interpretable complicated dependence within a high-dimensional distribution. We propose a doubly stochastic simulator that integrates a stochastic generative neural network and a classical Monte Carlo Poisson simulator, to utilize both advantages. Such integration brings challenges to both theoretical reliability and computational tractability for the estimation of the simulator given real data, where the estimation is done through minimizing the Wasserstein distance between the distribution of the simulation output and the distribution of real d
    
[^96]: 迭代MPC中学习满足未知约束条件的方法

    Learning to Satisfy Unknown Constraints in Iterative MPC. (arXiv:2006.05054v3 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2006.05054](http://arxiv.org/abs/2006.05054)

    本文提出了一种迭代方法来学习满足未知约束条件的控制设计方法，并通过收集的数据改进了约束条件的估计，使用MPC控制器强健地满足估计的约束条件，同时提供了稳健性和概率保证。

    

    本文提出了一种针对线性定常系统的控制设计方法，可以迭代学习满足未知多面体状态约束条件。在重复任务的每个迭代中，该方法使用收集的闭环轨迹数据构建未知环境约束条件的估计。在收集到更多数据后，这个估计的约束集合会得到迭代改进。接着，MPC控制器被设计成可以强健地满足这个估计的约束集合。本文详细介绍了所提出方法的细节，并提供了关于约束满足的稳健性和概率保证，这取决于执行任务迭代的次数。我们在详细的数值例子中展示了所提出框架的安全性，并探索了安全性与性能之间的折衷。

    We propose a control design method for linear time-invariant systems that iteratively learns to satisfy unknown polyhedral state constraints. At each iteration of a repetitive task, the method constructs an estimate of the unknown environment constraints using collected closed-loop trajectory data. This estimated constraint set is improved iteratively upon collection of additional data. An MPC controller is then designed to robustly satisfy the estimated constraint set. This paper presents the details of the proposed approach, and provides robust and probabilistic guarantees of constraint satisfaction as a function of the number of executed task iterations. We demonstrate the safety of the proposed framework and explore the safety vs. performance trade-off in a detailed numerical example.
    
[^97]: 运用数据挖掘改进最小延迟问题的启发式算法

    Improving a State-of-the-Art Heuristic for the Minimum Latency Problem with Data Mining. (arXiv:1908.10705v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1908.10705](http://arxiv.org/abs/1908.10705)

    这篇论文通过利用数据挖掘技术，改进了一种基于GRASP的最小延迟问题启发式算法，取得了较好的效果，匹配或优于解的质量，在大大缩短计算时间的同时，还成功地引入了88个新的解成本值。

    

    混合元启发式算法在运筹学中越来越流行。其中一种成功的方法是将贪心随机自适应搜索程序（GRASP）与数据挖掘技术相结合，利用高质量解中发现的频繁模式，在保证搜索范围的同时显著减少计算时间。本文利用数据挖掘技术改进了一个基于GRASP的最小延迟问题启发式算法，适用于两个问题变体。计算实验证明，数据挖掘方法能够在较大数量的实例上匹配或改善解的质量，同时大大减少运行时间。此外，本文还引入了88个新的解成本值。为了支持我们的结果，我们提供了统计显著性检验、挖掘模式的影响、等时间比较和时间到目标曲线的测试。

    Recently, hybrid metaheuristics have become a trend in operations research. A successful example combines the Greedy Randomized Adaptive Search Procedures (GRASP) and data mining techniques, where frequent patterns found in high-quality solutions can lead to an efficient exploration of the search space, along with a significant reduction of computational time. In this work, a GRASP-based state-of-the-art heuristic for the Minimum Latency Problem (MLP) is improved by means of data mining techniques for two MLP variants. Computational experiments showed that the approaches with data mining were able to match or improve the solution quality for a large number of instances, together with a substantial reduction of running time. In addition, 88 new cost values of solutions are introduced into the literature. To support our results, tests of statistical significance, impact of using mined patterns, equal time comparisons and time-to-target plots are provided.
    

