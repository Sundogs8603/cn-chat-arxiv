# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Monotone Tree-Based GAMI Models by Adapting XGBoost.](http://arxiv.org/abs/2309.02426) | 本文提出了一种基于XGBoost算法的单调树形GAMI模型，该模型适用于拟合具有重要交互作用的低阶函数ANOVA模型，并具有直观的解释和可视化能力。 |
| [^2] | [On the Minimax Regret in Online Ranking with Top-k Feedback.](http://arxiv.org/abs/2309.02425) | 本文研究了在线排名中的最小极大后悔问题与Top-k反馈，并通过提供一个全面的极大后悔率刻画，解决了Chaudhuri和Tewari [2017]所提出的问题。 |
| [^3] | [Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test.](http://arxiv.org/abs/2309.02422) | 本文将最大均差相似度应用于神经网络，并提出了一种称为Radon-Kolmogorov-Smirnov（RKS）检验的方法，该方法将样本均值差异最大化的问题推广到多维空间和更高平滑度顺序，同时与神经网络密切相关。 |
| [^4] | [Computing SHAP Efficiently Using Model Structure Information.](http://arxiv.org/abs/2309.02417) | 本论文提出了一种能够高效计算SHAP的方法，对于满足可加性和虚拟假设的SHAP定义，我们开发了不同策略来处理不同模型结构信息的情况。具体而言，对于已知功能分解的情况，我们演示了一种可加性属性和从较低阶功能组件计算SHAP的方法；对于已知模型顺序的情况，我们推导出能够在多项式时间内计算SHAP的公式。这些方法在实验中得到了验证。 |
| [^5] | [Exact Inference for Continuous-Time Gaussian Process Dynamics.](http://arxiv.org/abs/2309.02351) | 本论文提出了一种对连续时间高斯过程动力学进行精确推断的方法，解决了在离散时间下进行预测可能带来的问题，并利用高阶数值积分器进行动力学函数的离散化，避免了传统方法中的近似推断的限制。 |
| [^6] | [PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA LUT-based Inference.](http://arxiv.org/abs/2309.02334) | 提出了一种名为PolyLUT的新方法，用于训练神经网络在FPGA上进行部署。该方法利用多变量多项式作为基本模块，并利用软逻辑将多项式评估隐藏在FPGA的查找表中，从而实现超低延迟推理，并减少了软件逻辑的层数。 |
| [^7] | [Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe Self-Driving in Non-Stationary Environments.](http://arxiv.org/abs/2309.02328) | 这项研究引入了一种名为NUMERLA的算法，利用神经符号元-强化前瞻学习，实现了非稳态环境下的安全自动驾驶，并提出了一种前瞻更新机制来确保安全和效率。 |
| [^8] | [Distributionally Robust Model-based Reinforcement Learning with Large State Spaces.](http://arxiv.org/abs/2309.02236) | 本研究提出了一种用于解决强化学习中复杂动态系统和大状态空间问题的分布鲁棒的基于模型的方法，通过利用高斯过程和最大方差缩减算法进行高效学习，并在不同不确定性集合下展示了统计样本复杂度。 |
| [^9] | [Distributionally Robust Machine Learning with Multi-source Data.](http://arxiv.org/abs/2309.02211) | 本文提出了一种基于多源数据的分布鲁棒机器学习方法，通过引入组分布鲁棒预测模型来提高具有分布偏移的目标人群的预测准确性。 |
| [^10] | [On the Complexity of Differentially Private Best-Arm Identification with Fixed Confidence.](http://arxiv.org/abs/2309.02202) | 本文研究了在ε-全局差分隐私下的固定置信度下的最佳臂识别问题。我们得到了满足ε-全局差分隐私的任何δ-正确的最佳臂识别算法的样本复杂性的下界，并发现了高隐私区域和低隐私区域两种隐私情况。我们提出了一种自适应最佳臂识别算法AdaP-TT，通过动态调整信息论特性时间来平衡隐私和性能。 |
| [^11] | [Sparse Function-space Representation of Neural Networks.](http://arxiv.org/abs/2309.02195) | 本研究提出了一种将神经网络从权重空间转换为函数空间的方法，通过稀疏表示捕捉整个数据集的信息，从而解决了深度神经网络缺乏不确定性估计和融入新数据的问题。 |
| [^12] | [Bias Propagation in Federated Learning.](http://arxiv.org/abs/2309.02160) | 我们的研究揭示了在联邦学习中的偏见传播现象，少数对于较少代表的群体的偏见可以通过网络传播到所有参与者，并且这种偏见程度高于集中式训练。该研究呼吁在联邦学习中审计群体公平性并设计相应的学习算法。 |
| [^13] | [Backward error analysis and the qualitative behaviour of stochastic optimization algorithms: Application to stochastic coordinate descent.](http://arxiv.org/abs/2309.02082) | 该论文提出了一种通过误差分析来探究随机优化算法定性行为的方法，以随机坐标下降为例，研究了修改后微分方程的均方稳定性。 |
| [^14] | [Efficiency is Not Enough: A Critical Perspective of Environmentally Sustainable AI.](http://arxiv.org/abs/2309.02065) | 本论文对环境可持续人工智能提出了批判性视角，认为仅仅提高效率还不足以使机器学习成为一种环境可持续的技术。 |
| [^15] | [Probabilistic Self-supervised Learning via Scoring Rules Minimization.](http://arxiv.org/abs/2309.02048) | 本文提出了一种新颖的概率自监督学习方法ProSMIN，通过评分规则最小化来提升表示质量和缓解崩溃表示。方法通过两个神经网络协同学习多样分布的表示，并提供了对ProSMIN收敛性的理论证明。 |
| [^16] | [Linear Regression using Heterogeneous Data Batches.](http://arxiv.org/abs/2309.01973) | 本论文提出了一种用于线性回归的新颖梯度算法，可以在不同子组的异构数据批次中进行学习，并且不再需要假设输入分布为高斯分布。 |
| [^17] | [QuantEase: Optimization-based Quantization for Language Models -- An Efficient and Intuitive Algorithm.](http://arxiv.org/abs/2309.01885) | QuantEase是一种基于优化的语言模型量化算法，通过逐层量化和基于坐标下降的算法，高质量地解决了复杂的非凸量化问题，并引入了对异常值敏感的变种方法。 |
| [^18] | [Non-asymptotic approximations for Pearson's chi-square statistic and its application to confidence intervals for strictly convex functions of the probability weights of discrete distributions.](http://arxiv.org/abs/2309.01882) | 本文提出了一种非渐近逼近方法，用于计算多项式概率权重的置信区间和累积分布函数比较，并将该方法应用于离散分布的负熵置信区间的计算。 |
| [^19] | [Delegating Data Collection in Decentralized Machine Learning.](http://arxiv.org/abs/2309.01837) | 这项研究在分散机器学习生态系统中研究了委托的数据收集问题，通过设计最优契约解决了模型质量评估的不确定性和对最优性能缺乏预先知识的挑战。 |
| [^20] | [Asymmetric matrix sensing by gradient descent with small random initialization.](http://arxiv.org/abs/2309.01796) | 本论文研究了矩阵感知问题，通过小的随机初始化应用因式梯度下降算法来重建低秩矩阵。特别地，引入了一个连续微分方程，称为“扰动梯度流”，并证明了在扰动被限制在一定范围内时，扰动梯度流能够快速收敛到真实的目标矩阵。 |
| [^21] | [CONFIDERAI: a novel CONFormal Interpretable-by-Design score function forExplainable and Reliable Artificial Intelligence.](http://arxiv.org/abs/2309.01778) | 提出了一种新的可解释机器学习评分函数CONFIDERAI，它将一致性预测与规则模型相结合，利用规则的预测能力和点的几何位置，在特征空间中定义满足一致性保证的区域。 |
| [^22] | [Generalized Information Criteria for Structured Sparse Models.](http://arxiv.org/abs/2309.01764) | 提出了一种新的广义信息准则(GIC)，用于在高维情景下恢复低维模型的结构稀疏模型。该准则考虑了所需恢复的稀疏模式，并提供了非渐进的模型选择界限和一致性条件。 |
| [^23] | [Robust penalized least squares of depth trimmed residuals regression for high-dimensional data.](http://arxiv.org/abs/2309.01666) | 这篇论文介绍了鲁棒罚最小二乘深度修剪残差回归方法，针对高维数据的挑战进行了深入研究，并指出大多数传统方法在处理异常值和污染点时不够稳健。 |
| [^24] | [Locally Stationary Graph Processes.](http://arxiv.org/abs/2309.01657) | 这是一种局部平稳图形过程模型，旨在将局部平稳概念扩展到不规则的图域上。它通过将整个过程表示为一组组成部分过程的组合来表征局部平稳性，以使过程在图上按照每个组成部分的要求变化得更加平滑。 |
| [^25] | [Expectation propagation for the smoothing distribution in dynamic probit.](http://arxiv.org/abs/2309.01641) | 本文提出了一种新的期望传播算法来推理动态probit模型中的平滑分布，通过金融实例表明了其相对于现有算法的准确度提升。 |
| [^26] | [Efficient computation of predictive probabilities in probit models via expectation propagation.](http://arxiv.org/abs/2309.01630) | 该论文通过期望传播方法在贝叶斯probit模型中高效计算预测概率，并展示了与最先进方法相比的改进。 |
| [^27] | [Efficient expectation propagation for posterior approximation in high-dimensional probit models.](http://arxiv.org/abs/2309.01619) | 本文介绍了一种在高维Probit模型中用于后验近似的高效期望传播方法，通过使用扩展多元偏态正态分布的结果，实现了可计算性，并在详细的模拟研究中验证了其有效性。 |
| [^28] | [Les Houches Lectures on Deep Learning at Large & Infinite Width.](http://arxiv.org/abs/2309.01592) | 本论文主要以无穷宽度和大宽度范围内的深度神经网络为研究对象，讨论了这些网络的各种统计和动力学特性，包括随机网络的性质、训练后的网络与线性模型、核函数和高斯过程之间的关系，以及对大但有限宽度网络在初始化和训练后的摄动和非摄动处理。 |
| [^29] | [Accelerating Markov Chain Monte Carlo sampling with diffusion models.](http://arxiv.org/abs/2309.01454) | 本论文提出了一种新的方法，通过将Metropolis-Hastings算法与扩散模型相结合，加速马尔可夫链蒙特卡洛采样，从而有效地探索高维度和/或多模式的后验函数。 |
| [^30] | [Topological Ordering in Differentiable Bayesian Structure Learning with Guaranteed Acyclicity Constraint.](http://arxiv.org/abs/2309.01392) | 本研究提出了一种在贝叶斯结构学习中严格约束图的无环性的替代方法，通过整合拓扑排序知识，能够减少推理复杂性，并确保生成的图的结构是无环的。实证实验表明，该方法胜过相关的贝叶斯基于得分的方法。 |
| [^31] | [Random Projections of Sparse Adjacency Matrices.](http://arxiv.org/abs/2309.01360) | 本研究分析了一种针对邻接矩阵的随机投影方法，发现这种方法在表示稀疏图时具有实用性。通过保留邻接矩阵的功能并具有额外属性，这种方法具有吸引力。研究结果表明，投影大小可以按线性比例缩放，同时保留准确的一阶图信息。 |
| [^32] | [$\mathbb{T}$-Stochastic Graphs.](http://arxiv.org/abs/2309.01301) | 本文研究了社交网络中层次聚类的统计方法，并提出了一种新的概率模型$\mathbb{T}$-随机图，用于解决现有方法中存在的不稳定性问题。 |
| [^33] | [Implicit regularization of deep residual networks towards neural ODEs.](http://arxiv.org/abs/2309.01213) | 本文建立了深度残差网络向神经常微分方程的隐式正则化，通过对用梯度流训练的非线性网络的研究，证明了在网络以神经常微分方程的离散化形式初始化后，这种离散化将在整个训练过程中保持不变，并提供了收敛性的条件。 |
| [^34] | [Tropical Geometric Tools for Machine Learning: the TML package.](http://arxiv.org/abs/2309.01082) | TML软件包是第一个包含一套全面工具和方法的R软件包，用于处理与热带凸性相关的基本计算和可视化，以及使用热带度量进行监督和无监督学习模型的统计推断。 |
| [^35] | [Distribution learning via neural differential equations: a nonparametric statistical perspective.](http://arxiv.org/abs/2309.01043) | 本文提出了一种通过使用神经微分方程进行分布学习的新方法，并建立了相应的非参数统计收敛性分析。 |
| [^36] | [On the training and generalization of deep operator networks.](http://arxiv.org/abs/2309.01020) | 我们提出了一种用于深度运算符网络的新的训练方法，通过将训练任务分解为两个降低复杂性的子任务，并引入正交化过程来提高网络的稳定性和泛化能力。 |
| [^37] | [Bayesian sparsity and class sparsity priors for dictionary learning and coding.](http://arxiv.org/abs/2309.00999) | 本文提出了一种贝叶斯字典学习和编码方法，通过压缩子字典和引入建模误差来改进字典匹配过程，并采用数据驱动的稀疏编码技术识别不相关的子字典。 |
| [^38] | [An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems.](http://arxiv.org/abs/2309.00983) | 我们提出了一种集成评分滤波器（EnSF），在处理高维非线性滤波问题时具有卓越的准确性。EnSF利用评分模型在伪时域中描述滤波密度的演化，并通过评分函数存储信息，相比于使用蒙特卡罗样本的粒子滤波器和集成卡尔曼滤波器具有更好的效果。 |
| [^39] | [Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits.](http://arxiv.org/abs/2309.00814) | 本文提出了一种绕过模拟器的对抗线性情境臂带算法，能够在每轮行动集较小的情况下实现$\widetilde{O}(\sqrt{T})$的遗憾度。这个算法还能够处理损失线性近似以及对抗性损失和随机臂可用性的特殊情况。 |
| [^40] | [Structured Radial Basis Function Network: Modelling Diversity for Multiple Hypotheses Prediction.](http://arxiv.org/abs/2309.00781) | 这篇论文提出了一种结构化径向基函数网络，用于解决多模态回归问题。该网络能够有效地组合多个假设预测器，并通过插值逼近多个假设目标分布，具有较好的性能。 |
| [^41] | [Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models.](http://arxiv.org/abs/2309.00771) | 我们提出了一种通用方法来评估在错误指定模型下基于攻击性损失的鲁棒估计器的性能。我们研究了攻击性过剩风险，并建立了与利普西茨损失函数相关的非渐近上界。在二次损失的非参数回归中，我们展示了攻击性过剩风险界限优于一般损失的结果。 |
| [^42] | [Prediction Error Estimation in Random Forests.](http://arxiv.org/abs/2309.00736) | 本文通过量化评估分类随机森林的误差估计方法，发现随机森林的预测误差估计比平均预测误差更接近真实误差率，并且这一结果适用于不同的误差估计策略。 |
| [^43] | [Local and adaptive mirror descents in extensive-form games.](http://arxiv.org/abs/2309.00656) | 本文研究了在零和不完全信息博弈中学习ε-最优策略的问题。通过提出一种固定采样方法，并使用自适应的在线镜像下降算法进行局部更新，我们取得了收敛速度为$\tilde{\mathcal{O}}(T^{-1/2})$的结果，并在最佳策略下对游戏参数具有近乎最优的依赖关系。 |
| [^44] | [Minimal Assumptions for Optimal Serology Classification: Theory and Implications for Multidimensional Settings and Impure Training Data.](http://arxiv.org/abs/2309.00645) | 本研究提出了一种血清分类的技术，可以在多维和有杂质的训练数据情况下，通过对样本的分类和估计患病率来减少误差。该方法不需要直接访问条件概率密度函数，而是将数据嵌入参数化的曲线空间，并通过最小化经验误差来优化空间。 |
| [^45] | [MKL-$L_{0/1}$-SVM.](http://arxiv.org/abs/2308.12016) | 本文提出了一种多核学习的支持向量机框架(MKL-$L_{0/1}$-SVM)，通过开发快速的ADMM求解器处理非凸非光滑的优化问题，并在实验中展示了与领先方法相当的性能。 |
| [^46] | [On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget.](http://arxiv.org/abs/2308.12000) | 本文研究了在有限预算的随机二臂赌博机中进行最佳臂选择的问题，并证明不存在比等概率采样算法更好的算法。我们引入了一致稳定算法的概念，并证明任何在所有情况下与等概率采样算法表现一样好的算法必须属于这个类别。这一结果解决了之前的两个未解之谜。 |
| [^47] | [Approximately Equivariant Graph Networks.](http://arxiv.org/abs/2308.10436) | 本文关注于图神经网络（GNNs）的主动对称性，通过考虑信号在固定图上的学习设置，提出了一种近似的对称性概念，通过图粗化实现。这篇工作提出了一个偏差-方差公式来衡量近似对称性... |
| [^48] | [Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization.](http://arxiv.org/abs/2307.10053) | 本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。 |
| [^49] | [Deep Network Approximation: Beyond ReLU to Diverse Activation Functions.](http://arxiv.org/abs/2307.06555) | 本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。 |
| [^50] | [Kernel Random Projection Depth for Outlier Detection.](http://arxiv.org/abs/2306.07056) | 本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。 |
| [^51] | [Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation.](http://arxiv.org/abs/2305.17558) | 本论文提出了两种基于虚拟粒子随机逼近的可证速限制变种的SVGD算法，具有可证速的有限粒子收敛率。 |
| [^52] | [On progressive sharpening, flat minima and generalisation.](http://arxiv.org/abs/2305.14683) | 本文提出了一种用损失黑塞矩阵和输入-输出雅克比矩阵联系起来的假设，量化了模型的输入-输出雅克比矩阵近似其在数据分布上的利普西茨范数的程度，并推导出了一个基于经验雅克比矩阵的新的泛化界，给出了关于进化磨锋和平坦极小的泛化性质的新解释。 |
| [^53] | [Stochastic PDE representation of random fields for large-scale Gaussian process regression and statistical finite element analysis.](http://arxiv.org/abs/2305.13879) | 本文针对工程学和机器学习中的贝叶斯建模，使用随机PDE表示来开发一种可扩展的框架，从而可以在几何复杂的域上进行大规模的统计有限元分析和高斯过程回归。 |
| [^54] | [From Random Search to Bandit Learning in Metric Measure Spaces.](http://arxiv.org/abs/2305.11509) | 本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。 |
| [^55] | [Correlation visualization under missing values: a comparison between imputation and direct parameter estimation methods.](http://arxiv.org/abs/2305.06044) | 本文比较了不同的缺失数据处理方法对相关图的影响，建议使用直接参数估计法(DPER)来绘制相关图 |
| [^56] | [Nonlinear Independent Component Analysis for Principled Disentanglement in Unsupervised Deep Learning.](http://arxiv.org/abs/2303.16535) | 本文概括了无监督深度学习中基于独立成分分析方法的最新发展，特别是对于解决非线性情况下唯一性问题提出了可识别的扩展方法。 |
| [^57] | [FAStEN: an efficient adaptive method for feature selection and estimation in high-dimensional functional regressions.](http://arxiv.org/abs/2303.14801) | 提出了一种新的自适应方法FAStEN，用于在高维函数回归问题中执行特征选择和参数估计，通过利用函数主成分和对偶增广Lagrangian问题的稀疏性质，具有显著的计算效率和选择准确性。 |
| [^58] | [Provably Convergent Plug-and-Play Quasi-Newton Methods.](http://arxiv.org/abs/2303.07271) | 本文提出了一种可证明收敛的PnP方法，使用拟牛顿步骤以加速收敛，相对于现有的PnP方法对去噪器或保真度函数施加了较轻的限制。 |
| [^59] | [Performance is not enough: a story of the Rashomon's quartet.](http://arxiv.org/abs/2302.13356) | 本文介绍了Rashomon的四重奏，这是一个合成数据集，其中来自不同类别的四个模型具有几乎相同的预测性能，同时其可视化揭示了极其不同的方法来理解数据中的相关性结构。 |
| [^60] | [Breaking the Lower Bound with (Little) Structure: Acceleration in Non-Convex Stochastic Optimization with Heavy-Tailed Noise.](http://arxiv.org/abs/2302.06763) | 本论文在具有重尾噪声的非凸随机优化问题中，改进了Cutkosky和Mehta的算法，并提供了近乎最优的收敛保证，而无需对随机梯度的矩条件进行额外的假设。 |
| [^61] | [Confidence and Uncertainty Assessment for Distributional Random Forests.](http://arxiv.org/abs/2302.05761) | Distributional Random Forests算法通过对条件分布进行估计，提供了一种量化标准误差和构建置信区间的推理工具，用于估计多变量条件分布和测试不同群体之间的分布差异。 |
| [^62] | [A Reinforcement Learning Framework for Dynamic Mediation Analysis.](http://arxiv.org/abs/2301.13348) | 这项研究提出了一个强化学习框架，首次评估了在无限时间范围内的动态中介效应，并开发了鲁棒和半参数有效的估计方法来推断这些因果效应。 |
| [^63] | [Are you using test log-likelihood correctly?.](http://arxiv.org/abs/2212.00219) | 使用测试对数似然进行比较可能与其他指标相矛盾，并且高测试对数似然不意味着更准确的后验近似。 |
| [^64] | [PAC Verification of Statistical Algorithms.](http://arxiv.org/abs/2211.17096) | 本文介绍了PAC验证的概念，并在三个方面进行了进一步的研究：对于VC维度为$d$的假设类，PAC验证需要$\Omega\left(\sqrt{d}/\varepsilon^2\right)$个i.i.d.样本的下界；提出了一种用于验证实数区间的并集的协议，并与下界对$d$的依赖相匹配；将PAC验证的定义推广到对一般统计算法的验证。 |
| [^65] | [Applications of Machine Learning in Pharmacogenomics: Clustering Plasma Concentration-Time Curves.](http://arxiv.org/abs/2210.13310) | 该论文介绍了应用机器学习对药物动力学曲线进行聚类的方法，发现聚类能够有效地识别相似形状的药物动力学曲线并理解每个聚类中的模式，为药物研发和药物治疗过程提供了新的技术支持。 |
| [^66] | [Outlier Robust and Sparse Estimation of Linear Regression Coefficients.](http://arxiv.org/abs/2208.11592) | 本文介绍了一种异常鲁棒稀疏估计方法，可用于线性回归系数的协方差矩阵已知或未知的情况下，具有较尖锐的误差界，适用于采样自$\mathfrak{L}$-subGaussian分布和重尾分布的协变量向量和噪声。 |
| [^67] | [Treatment Effect Estimation with Observational Network Data using Machine Learning.](http://arxiv.org/abs/2206.14591) | 该论文开发了增广逆概率加权（AIPW）方法，用于使用观测网络数据估计和推断具有溢出效应的治疗的直接效应。方法使用机器学习和样本分割，得到收敛速度较快且服从高斯分布的半参数治疗效果估计器。研究发现，在考虑学生社交网络的情况下，学习时间对考试成绩有影响。 |
| [^68] | [Individual Privacy Accounting for Differentially Private Stochastic Gradient Descent.](http://arxiv.org/abs/2206.02617) | 本文研究了通过差分隐私随机梯度下降训练的模型对个体示例的隐私保证，并发现大多数示例享有较强的隐私保证。此外，我们还发现训练损失和示例的隐私参数存在很强的相关性。最低准确率类别的平均隐私参数比最高准确率类别高44.2%。 |
| [^69] | [Generative Network-Based Reduced-Order Model for Prediction, Data Assimilation and Uncertainty Quantification.](http://arxiv.org/abs/2105.13859) | 该论文提出了一种基于生成网络的降阶模型，用于解决偏微分方程的逆问题。通过使用无条件模拟进行训练，该模型可以有效量化不确定性，并准确匹配测量数据和黄金标准。 |
| [^70] | [A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous Q-Learning and TD-Learning Variants.](http://arxiv.org/abs/2102.01567) | 本文提出了一种统一的框架来研究异步强化学习算法的有限样本收敛保证，并基于Lyapunov分析建立了异步RL算法的均方误差界限。通过对n步TD和TD（λ）的收敛界限的分析，揭示了强化学习中引导技巧效率的理论洞见。 |
| [^71] | [Does the $\ell_1$-norm Learn a Sparse Graph under Laplacian Constrained Graphical Models?.](http://arxiv.org/abs/2006.14925) | 本文研究了在受限Laplacian图模型下学习稀疏图的问题。我们发现经典的$\ell_1$-范数正则化无法有效实现稀疏解，并提出了一种非凸稀疏惩罚的方法来解决这个问题。 |
| [^72] | [Selective machine learning of doubly robust functionals.](http://arxiv.org/abs/1911.02029) | 本文提出了一种选择性机器学习框架，用于在半参数问题中选择可能高维的干扰参数，并对双重鲁棒性函数进行推断。通过引入新的选择标准和伪风险定义，降低了估计所提函数中的偏差，并且具有理想性质。 |

# 详细

[^1]: 基于XGBoost的单调树形GAMI模型

    Monotone Tree-Based GAMI Models by Adapting XGBoost. (arXiv:2309.02426v1 [stat.ML])

    [http://arxiv.org/abs/2309.02426](http://arxiv.org/abs/2309.02426)

    本文提出了一种基于XGBoost算法的单调树形GAMI模型，该模型适用于拟合具有重要交互作用的低阶函数ANOVA模型，并具有直观的解释和可视化能力。

    

    最近的论文采用机器学习结构来拟合低阶函数ANOVA模型，其中包括主效应和二阶交互作用。这些GAMI（GAM + Interaction）模型可以直接解释，因为函数的主效应和交互作用可以轻松绘制和可视化。然而，将单调性要求引入现有的基于提升树的GAMI模型（如EBM和GAMI-Lin-T）并不容易。本文考虑形式为$f(x)=\sum_{j,k}f_{j,k}(x_j, x_k)$的模型，并通过改进XGBoost算法开发了单调树形GAMI模型，称为单调GAMI-Tree。使用XGBoost的选项将单调模型拟合到$f(x)$是直观的。然而，拟合的模型仍然是一个黑盒子。我们采取了不同的方法：i）使用过滤技术确定重要的交互作用，ii）在选择的交互作用上拟合单调XGBoost算法，最后iii）解析和p

    Recent papers have used machine learning architecture to fit low-order functional ANOVA models with main effects and second-order interactions. These GAMI (GAM + Interaction) models are directly interpretable as the functional main effects and interactions can be easily plotted and visualized. Unfortunately, it is not easy to incorporate the monotonicity requirement into the existing GAMI models based on boosted trees, such as EBM (Lou et al. 2013) and GAMI-Lin-T (Hu et al. 2022). This paper considers models of the form $f(x)=\sum_{j,k}f_{j,k}(x_j, x_k)$ and develops monotone tree-based GAMI models, called monotone GAMI-Tree, by adapting the XGBoost algorithm. It is straightforward to fit a monotone model to $f(x)$ using the options in XGBoost. However, the fitted model is still a black box. We take a different approach: i) use a filtering technique to determine the important interactions, ii) fit a monotone XGBoost algorithm with the selected interactions, and finally iii) parse and p
    
[^2]: 在在线排名中的最小极大后悔问题与Top-k反馈

    On the Minimax Regret in Online Ranking with Top-k Feedback. (arXiv:2309.02425v1 [cs.LG])

    [http://arxiv.org/abs/2309.02425](http://arxiv.org/abs/2309.02425)

    本文研究了在线排名中的最小极大后悔问题与Top-k反馈，并通过提供一个全面的极大后悔率刻画，解决了Chaudhuri和Tewari [2017]所提出的问题。

    

    在在线排名中，学习算法按顺序对一组项目进行排名，并以相关性得分的形式接收反馈。由于获得相关性得分通常涉及人工注释，因此考虑仅对排名中的前k个项目限制反馈的部分反馈设置具有极大的兴趣。Chaudhuri和Tewari [2017]开发了一个框架来分析带有Top $k$反馈的在线排名算法。他们工作的关键要素是使用了部分监控技术。在本文中，我们进一步研究了具有Top $k$反馈的在线排名，并解决了Chaudhuri和Tewari [2017]提出的一些开放性问题。我们对所有$k$和以下排名性能度量（Pairwise Loss，Discounted Cumulative Gain和Precision@n）的Top $k$反馈模型进行了最小极大后悔率的完全刻画。此外，我们提供了一种有效的算法，该算法实现了Precision@n的最小极大后悔率。

    In online ranking, a learning algorithm sequentially ranks a set of items and receives feedback on its ranking in the form of relevance scores. Since obtaining relevance scores typically involves human annotation, it is of great interest to consider a partial feedback setting where feedback is restricted to the top-$k$ items in the rankings. Chaudhuri and Tewari [2017] developed a framework to analyze online ranking algorithms with top $k$ feedback. A key element in their work was the use of techniques from partial monitoring. In this paper, we further investigate online ranking with top $k$ feedback and solve some open problems posed by Chaudhuri and Tewari [2017]. We provide a full characterization of minimax regret rates with the top $k$ feedback model for all $k$ and for the following ranking performance measures: Pairwise Loss, Discounted Cumulative Gain, and Precision@n. In addition, we give an efficient algorithm that achieves the minimax regret rate for Precision@n.
    
[^3]: 最大均差相似度遇上神经网络：Radon-Kolmogorov-Smirnov检验

    Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test. (arXiv:2309.02422v1 [stat.ML])

    [http://arxiv.org/abs/2309.02422](http://arxiv.org/abs/2309.02422)

    本文将最大均差相似度应用于神经网络，并提出了一种称为Radon-Kolmogorov-Smirnov（RKS）检验的方法，该方法将样本均值差异最大化的问题推广到多维空间和更高平滑度顺序，同时与神经网络密切相关。

    

    最大均差相似度（MMD）是一类基于最大化两个分布$P$和$Q$之间样本均值差异的非参数双样本检验，其中考虑了所有在某个函数空间$\mathcal{F}$中的数据变换$f$的选择。受到最近将所谓的Radon有界变差函数（RBV）和神经网络联系起来的工作的启发（Parhi和Nowak, 2021, 2023），我们研究了将$\mathcal{F}$取为给定平滑度顺序$k \geq 0$下的RBV空间中的单位球的MMD。这个检验被称为Radon-Kolmogorov-Smirnov（RKS）检验，可以看作是对多维空间和更高平滑度顺序的经典Kolmogorov-Smirnov（KS）检验的一般化。它还与神经网络密切相关：我们证明RKS检验中的证据函数$f$，即达到最大均差的函数，总是一个二次样条函数。

    Maximum mean discrepancy (MMD) refers to a general class of nonparametric two-sample tests that are based on maximizing the mean difference over samples from one distribution $P$ versus another $Q$, over all choices of data transformations $f$ living in some function space $\mathcal{F}$. Inspired by recent work that connects what are known as functions of $\textit{Radon bounded variation}$ (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study the MMD defined by taking $\mathcal{F}$ to be the unit ball in the RBV space of a given smoothness order $k \geq 0$. This test, which we refer to as the $\textit{Radon-Kolmogorov-Smirnov}$ (RKS) test, can be viewed as a generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to multiple dimensions and higher orders of smoothness. It is also intimately connected to neural networks: we prove that the witness in the RKS test -- the function $f$ achieving the maximum mean difference -- is always a ridge spline of degree
    
[^4]: 使用模型结构信息高效计算SHAP

    Computing SHAP Efficiently Using Model Structure Information. (arXiv:2309.02417v1 [stat.ML])

    [http://arxiv.org/abs/2309.02417](http://arxiv.org/abs/2309.02417)

    本论文提出了一种能够高效计算SHAP的方法，对于满足可加性和虚拟假设的SHAP定义，我们开发了不同策略来处理不同模型结构信息的情况。具体而言，对于已知功能分解的情况，我们演示了一种可加性属性和从较低阶功能组件计算SHAP的方法；对于已知模型顺序的情况，我们推导出能够在多项式时间内计算SHAP的公式。这些方法在实验中得到了验证。

    

    SHAP（SHapley加性解释）已成为一种流行的方法，用于将机器学习模型对输入的预测归因于其特征。SHAP的主要挑战之一是计算时间。精确计算Shapley值需要指数时间复杂度。因此，文献中提出了许多近似方法。在本文中，我们提出了能够在多项式时间内或甚至更快地计算出满足可加性和虚拟假设（例如，核心SHAP和基线SHAP）定义的SHAP的方法。我们针对具有不同模型结构信息水平的模型开发了不同的策略：已知功能分解的情况、已知模型顺序（定义为模型中最高交互作用的顺序）的情况，或未知顺序的情况。对于第一种情况，我们演示了可加性属性和从较低阶功能组件计算SHAP的方法。对于第二种情况，我们推导出能够在多项式时间内计算SHAP的公式。两种方法都在实验中得到了验证。

    SHAP (SHapley Additive exPlanations) has become a popular method to attribute the prediction of a machine learning model on an input to its features. One main challenge of SHAP is the computation time. An exact computation of Shapley values requires exponential time complexity. Therefore, many approximation methods are proposed in the literature. In this paper, we propose methods that can compute SHAP exactly in polynomial time or even faster for SHAP definitions that satisfy our additivity and dummy assumptions (eg, kernal SHAP and baseline SHAP). We develop different strategies for models with different levels of model structure information: known functional decomposition, known order of model (defined as highest order of interaction in the model), or unknown order. For the first case, we demonstrate an additive property and a way to compute SHAP from the lower-order functional components. For the second case, we derive formulas that can compute SHAP in polynomial time. Both methods 
    
[^5]: 连续时间高斯过程动力学的精确推断

    Exact Inference for Continuous-Time Gaussian Process Dynamics. (arXiv:2309.02351v1 [cs.LG])

    [http://arxiv.org/abs/2309.02351](http://arxiv.org/abs/2309.02351)

    本论文提出了一种对连续时间高斯过程动力学进行精确推断的方法，解决了在离散时间下进行预测可能带来的问题，并利用高阶数值积分器进行动力学函数的离散化，避免了传统方法中的近似推断的限制。

    

    实际物理系统通常可以通过连续时间动力系统来描述。在实际应用中，真实系统通常是未知的，需要从测量数据中学习。由于数据通常以离散时间收集，例如通过传感器，高斯过程（GP）动力模型学习中的大多数方法都是针对一步预测进行训练的。在一些场景中，这可能会导致问题，例如如果测量结果以不规则的时间步长提供，或者物理系统属性需要保持不变。因此，我们的目标是建立对真实连续时间动力学的GP模型。高阶数值积分器提供了通过任意精度离散化动力学函数来解决这个问题的工具。许多高阶积分器需要在中间时间步骤进行动力学评估，这使得精确的GP推断变得难以处理。在先前的工作中，通常通过使用变分推断来近似GP后验来解决这个问题。然而，精确的GP推断是很困难的。

    Physical systems can often be described via a continuous-time dynamical system. In practice, the true system is often unknown and has to be learned from measurement data. Since data is typically collected in discrete time, e.g. by sensors, most methods in Gaussian process (GP) dynamics model learning are trained on one-step ahead predictions. This can become problematic in several scenarios, e.g. if measurements are provided at irregularly-sampled time steps or physical system properties have to be conserved. Thus, we aim for a GP model of the true continuous-time dynamics. Higher-order numerical integrators provide the necessary tools to address this problem by discretizing the dynamics function with arbitrary accuracy. Many higher-order integrators require dynamics evaluations at intermediate time steps making exact GP inference intractable. In previous work, this problem is often tackled by approximating the GP posterior with variational inference. However, exact GP inference is pre
    
[^6]: PolyLUT: 用于超低延迟FPGA基于查找表推理的分段多项式学习

    PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA LUT-based Inference. (arXiv:2309.02334v1 [cs.LG])

    [http://arxiv.org/abs/2309.02334](http://arxiv.org/abs/2309.02334)

    提出了一种名为PolyLUT的新方法，用于训练神经网络在FPGA上进行部署。该方法利用多变量多项式作为基本模块，并利用软逻辑将多项式评估隐藏在FPGA的查找表中，从而实现超低延迟推理，并减少了软件逻辑的层数。

    

    可编程门阵列（FPGA）被广泛用于实现深度学习推理。标准的深度神经网络推理涉及交错线性映射和非线性激活函数的计算。以往的超低延迟实现工作在FPGA查找表（LUT）中硬编码了线性映射和非线性激活的组合。我们的工作受到这个想法的启发，即FPGA中的LUT可以用来实现比这更多样化的函数。在本文中，我们提出了一种新的方法来训练用于FPGA部署的神经网络，以多变量多项式作为基本模块。我们的方法利用软件逻辑提供的灵活性，将多项式评估隐藏在LUT中且没有任何开销。我们表明，通过使用多项式模块，我们可以实现相同的准确度，而使用的软件逻辑层数要比使用线性函数要少得多，从而带来显著的延迟和面积的减少。

    Field-programmable gate arrays (FPGAs) are widely used to implement deep learning inference. Standard deep neural network inference involves the computation of interleaved linear maps and nonlinear activation functions. Prior work for ultra-low latency implementations has hardcoded the combination of linear maps and nonlinear activations inside FPGA lookup tables (LUTs). Our work is motivated by the idea that the LUTs in an FPGA can be used to implement a much greater variety of functions than this. In this paper, we propose a novel approach to training neural networks for FPGA deployment using multivariate polynomials as the basic building block. Our method takes advantage of the flexibility offered by the soft logic, hiding the polynomial evaluation inside the LUTs with zero overhead. We show that by using polynomial building blocks, we can achieve the same accuracy using considerably fewer layers of soft logic than by using linear functions, leading to significant latency and area i
    
[^7]: 神经符号元-强化前瞻学习在非稳态环境下实现安全自动驾驶

    Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe Self-Driving in Non-Stationary Environments. (arXiv:2309.02328v1 [cs.RO])

    [http://arxiv.org/abs/2309.02328](http://arxiv.org/abs/2309.02328)

    这项研究引入了一种名为NUMERLA的算法，利用神经符号元-强化前瞻学习，实现了非稳态环境下的安全自动驾驶，并提出了一种前瞻更新机制来确保安全和效率。

    

    在学习驱动的人工智能进展领域中，将机器学习（ML）与自动驾驶（SD）技术相结合，是一项令人印象深刻的工程壮举。然而，在真实世界的应用中，超越受控实验室场景的限制，自动驾驶技术的部署承担着关乎生命安全的角色，这就要求研究人员更加关注安全和效率。当自动驾驶模型在实时执行中遇到陌生环境时，焦点不能仅仅集中在提高其预期性能上；同样重要的是确保其执行或实时调整能够保持必要的安全水平。本研究引入了一种用于在线元-强化学习的算法，采用基于“神经符号元-强化前瞻学习”（NUMERLA）的前瞻符号约束。NUMERLA提出了一种前瞻更新机制，可以协调学习和规划，在非稳态环境中实现安全自动驾驶。

    In the area of learning-driven artificial intelligence advancement, the integration of machine learning (ML) into self-driving (SD) technology stands as an impressive engineering feat. Yet, in real-world applications outside the confines of controlled laboratory scenarios, the deployment of self-driving technology assumes a life-critical role, necessitating heightened attention from researchers towards both safety and efficiency. To illustrate, when a self-driving model encounters an unfamiliar environment in real-time execution, the focus must not solely revolve around enhancing its anticipated performance; equal consideration must be given to ensuring its execution or real-time adaptation maintains a requisite level of safety. This study introduces an algorithm for online meta-reinforcement learning, employing lookahead symbolic constraints based on \emph{Neurosymbolic Meta-Reinforcement Lookahead Learning} (NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes th
    
[^8]: 具有大状态空间的分布鲁棒的基于模型的强化学习

    Distributionally Robust Model-based Reinforcement Learning with Large State Spaces. (arXiv:2309.02236v1 [cs.LG])

    [http://arxiv.org/abs/2309.02236](http://arxiv.org/abs/2309.02236)

    本研究提出了一种用于解决强化学习中复杂动态系统和大状态空间问题的分布鲁棒的基于模型的方法，通过利用高斯过程和最大方差缩减算法进行高效学习，并在不同不确定性集合下展示了统计样本复杂度。

    

    强化学习面临着复杂的动态系统和大状态空间的挑战，以及昂贵的数据收集过程以及真实世界动力学与训练环境部署的偏差。为了克服这些问题，我们研究了在广泛使用的Kullback-Leibler、卡方和总变差不确定性集合下具有连续状态空间的分布鲁棒的马尔可夫决策过程。我们提出了一种基于模型的方法，利用高斯过程和最大方差缩减算法来高效学习多输出的名义转移动态，并利用生成模型（即模拟器）的访问权限。我们进一步展示了该方法在不同不确定性集合下的统计样本复杂度。这些复杂度界不依赖于状态数量，并且超越线性动态，确保了我们方法在识别接近最优的分布鲁棒策略方面的有效性。

    Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed met
    
[^9]: 基于多源数据的分布鲁棒机器学习

    Distributionally Robust Machine Learning with Multi-source Data. (arXiv:2309.02211v1 [stat.ML])

    [http://arxiv.org/abs/2309.02211](http://arxiv.org/abs/2309.02211)

    本文提出了一种基于多源数据的分布鲁棒机器学习方法，通过引入组分布鲁棒预测模型来提高具有分布偏移的目标人群的预测准确性。

    

    当目标分布与源数据集不同时，传统的机器学习方法可能导致较差的预测性能。本文利用多个数据源，并引入了一种基于组分布鲁棒预测模型来优化关于目标分布类的可解释方差的对抗性奖励。与传统的经验风险最小化相比，所提出的鲁棒预测模型改善了具有分布偏移的目标人群的预测准确性。我们证明了组分布鲁棒预测模型是源数据集条件结果模型的加权平均。我们利用这一关键鉴别结果来提高任意机器学习算法的鲁棒性，包括随机森林和神经网络等。我们设计了一种新的偏差校正估计器来估计通用机器学习算法的最优聚合权重，并展示了其在c方面的改进。

    Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal aggregation weight for general machine-learning algorithms and demonstrate its improvement in the c
    
[^10]: 关于固定置信度下差分隐私最佳臂识别问题的复杂性

    On the Complexity of Differentially Private Best-Arm Identification with Fixed Confidence. (arXiv:2309.02202v1 [stat.ML])

    [http://arxiv.org/abs/2309.02202](http://arxiv.org/abs/2309.02202)

    本文研究了在ε-全局差分隐私下的固定置信度下的最佳臂识别问题。我们得到了满足ε-全局差分隐私的任何δ-正确的最佳臂识别算法的样本复杂性的下界，并发现了高隐私区域和低隐私区域两种隐私情况。我们提出了一种自适应最佳臂识别算法AdaP-TT，通过动态调整信息论特性时间来平衡隐私和性能。

    

    最佳臂识别问题被逐渐应用于数据敏感的应用，例如设计自适应临床试验、调整超参数和进行用户研究等。基于这些应用引发的数据隐私问题，我们研究了在ε-全局差分隐私下的固定置信度下的最佳臂识别问题。首先，为了衡量隐私开销，我们得到了满足ε-全局差分隐私的任何δ-正确的最佳臂识别算法的样本复杂性的下界。我们的下界表明存在两种隐私区域，取决于隐私预算ε。在高隐私区域（小ε）中，困难程度取决于隐私和一种新颖的信息论数量，称为总变差特征时间的耦合效应。在低隐私区域（大ε）中，样本复杂性下界降低到经典的非隐私下界。其次，我们提出了AdaP-TT，一种ε-全局差分隐私下的自适应最佳臂识别算法，通过考虑信息论特性时间的动态调整来平衡隐私与性能之间的权衡。

    Best Arm Identification (BAI) problems are progressively used for data-sensitive applications, such as designing adaptive clinical trials, tuning hyper-parameters, and conducting user studies to name a few. Motivated by the data privacy concerns invoked by these applications, we study the problem of BAI with fixed confidence under $\epsilon$-global Differential Privacy (DP). First, to quantify the cost of privacy, we derive a lower bound on the sample complexity of any $\delta$-correct BAI algorithm satisfying $\epsilon$-global DP. Our lower bound suggests the existence of two privacy regimes depending on the privacy budget $\epsilon$. In the high-privacy regime (small $\epsilon$), the hardness depends on a coupled effect of privacy and a novel information-theoretic quantity, called the Total Variation Characteristic Time. In the low-privacy regime (large $\epsilon$), the sample complexity lower bound reduces to the classical non-private lower bound. Second, we propose AdaP-TT, an $\ep
    
[^11]: 神经网络的稀疏函数空间表示方法

    Sparse Function-space Representation of Neural Networks. (arXiv:2309.02195v1 [stat.ML])

    [http://arxiv.org/abs/2309.02195](http://arxiv.org/abs/2309.02195)

    本研究提出了一种将神经网络从权重空间转换为函数空间的方法，通过稀疏表示捕捉整个数据集的信息，从而解决了深度神经网络缺乏不确定性估计和融入新数据的问题。

    

    已知深度神经网络（NNs）缺乏不确定性估计，并且难以融入新数据。我们提出了一种方法，通过双重参数化将NNs从权重空间转换为函数空间，以减轻这些问题。重要的是，双重参数化使我们能够制定出捕捉整个数据集信息的稀疏表示。这提供了一种紧凑且原则性的方法来捕捉不确定性，并使我们能够在不重新训练的情况下融入新数据，并保持预测性能。我们通过在UCI基准任务上使用该方法进行证明性演示，来量化监督学习中的不确定性。

    Deep neural networks (NNs) are known to lack uncertainty estimates and struggle to incorporate new data. We present a method that mitigates these issues by converting NNs from weight space to function space, via a dual parameterization. Importantly, the dual parameterization enables us to formulate a sparse representation that captures information from the entire data set. This offers a compact and principled way of capturing uncertainty and enables us to incorporate new data without retraining whilst retaining predictive performance. We provide proof-of-concept demonstrations with the proposed approach for quantifying uncertainty in supervised learning on UCI benchmark tasks.
    
[^12]: 在联邦学习中的偏见传播

    Bias Propagation in Federated Learning. (arXiv:2309.02160v1 [cs.LG])

    [http://arxiv.org/abs/2309.02160](http://arxiv.org/abs/2309.02160)

    我们的研究揭示了在联邦学习中的偏见传播现象，少数对于较少代表的群体的偏见可以通过网络传播到所有参与者，并且这种偏见程度高于集中式训练。该研究呼吁在联邦学习中审计群体公平性并设计相应的学习算法。

    

    我们展示了参与联邦学习可能对群体公平性有害。事实上，少数参与者对于被较少代表的群体（如性别或种族等敏感属性确定的群体）的偏见可以通过网络传播到所有参与者。我们在自然分区的真实数据集上分析和解释了联邦学习中的偏见传播。我们的分析揭示了具有偏见的参与者无意中但秘密地将其偏见编码到少数模型参数中，并且在整个训练过程中，它们稳步增加了全局模型对敏感属性的依赖。重要的是要强调的是，在联邦学习中经历的偏见比参与者在训练在所有数据的联合上的集中式训练中遇到的要高。这表明偏见是由算法造成的。我们的工作呼吁在联邦学习中进行群体公平性审计和设计学习算法。

    We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and explain bias propagation in federated learning on naturally partitioned real-world datasets. Our analysis reveals that biased parties unintentionally yet stealthily encode their bias in a small number of model parameters, and throughout the training, they steadily increase the dependence of the global model on sensitive attributes. What is important to highlight is that the experienced bias in federated learning is higher than what parties would otherwise encounter in centralized training with a model trained on the union of all their data. This indicates that the bias is due to the algorithm. Our work calls for auditing group fairness in federated learning and designing learning algorithms t
    
[^13]: 通过误差分析探究随机优化算法的定性行为：以随机坐标下降为例

    Backward error analysis and the qualitative behaviour of stochastic optimization algorithms: Application to stochastic coordinate descent. (arXiv:2309.02082v1 [math.OC])

    [http://arxiv.org/abs/2309.02082](http://arxiv.org/abs/2309.02082)

    该论文提出了一种通过误差分析来探究随机优化算法定性行为的方法，以随机坐标下降为例，研究了修改后微分方程的均方稳定性。

    

    随机优化方法在解决大规模优化问题时，能够有效地避免计算全部梯度所带来的计算难题。使用数值积分器的改进方程理论，我们提出了一类随机微分方程，更准确地近似了一般随机优化方法的动力学特性，超过了原始的梯度流。分析修改过的随机微分方程可以揭示与优化方法相关的定性见解。在本文中，我们研究了随机坐标下降方法中修改后的微分方程的均方稳定性。

    Stochastic optimization methods have been hugely successful in making large-scale optimization problems feasible when computing the full gradient is computationally prohibitive. Using the theory of modified equations for numerical integrators, we propose a class of stochastic differential equations that approximate the dynamics of general stochastic optimization methods more closely than the original gradient flow. Analyzing a modified stochastic differential equation can reveal qualitative insights about the associated optimization method. Here, we study mean-square stability of the modified equation in the case of stochastic coordinate descent.
    
[^14]: 效率不是唯一标准：对环境可持续人工智能的批判性视角

    Efficiency is Not Enough: A Critical Perspective of Environmentally Sustainable AI. (arXiv:2309.02065v1 [cs.LG])

    [http://arxiv.org/abs/2309.02065](http://arxiv.org/abs/2309.02065)

    本论文对环境可持续人工智能提出了批判性视角，认为仅仅提高效率还不足以使机器学习成为一种环境可持续的技术。

    

    人工智能（AI）目前由深度学习（DL）等机器学习（ML）方法推动，这些方法加速了在许多原本被认为超出AI范围的任务上的进展。这些ML方法通常需要大量计算资源、能源消耗大，并导致大量的碳排放，这是人为气候变化的一个已知驱动因素。此外，ML系统运行的平台与环境影响有关，包括碳排放之外的其他方面。工业界和ML社区广泛推崇的提高ML系统在计算和能源消耗方面的效率来改善环境可持续性的解决方案，我们认为仅仅依靠效率还不足以使ML作为一种环境可持续的技术。我们通过提出三个高层次的差异来阐述考虑众多变量对ML环境可持续性影响时，仅依靠效率是不够的。

    Artificial Intelligence (AI) is currently spearheaded by machine learning (ML) methods such as deep learning (DL) which have accelerated progress on many tasks thought to be out of reach of AI. These ML methods can often be compute hungry, energy intensive, and result in significant carbon emissions, a known driver of anthropogenic climate change. Additionally, the platforms on which ML systems run are associated with environmental impacts including and beyond carbon emissions. The solution lionized by both industry and the ML community to improve the environmental sustainability of ML is to increase the efficiency with which ML systems operate in terms of both compute and energy consumption. In this perspective, we argue that efficiency alone is not enough to make ML as a technology environmentally sustainable. We do so by presenting three high level discrepancies between the effect of efficiency on the environmental sustainability of ML when considering the many variables which it in
    
[^15]: 通过评分规则最小化进行概率自监督学习

    Probabilistic Self-supervised Learning via Scoring Rules Minimization. (arXiv:2309.02048v1 [cs.LG])

    [http://arxiv.org/abs/2309.02048](http://arxiv.org/abs/2309.02048)

    本文提出了一种新颖的概率自监督学习方法ProSMIN，通过评分规则最小化来提升表示质量和缓解崩溃表示。方法通过两个神经网络协同学习多样分布的表示，并提供了对ProSMIN收敛性的理论证明。

    

    在本文中，我们提出了一种新颖的概率自监督学习方法ProSMIN，通过评分规则最小化来提升表示质量和缓解崩溃表示。我们的方法涉及两个神经网络：在线网络和目标网络，它们通过知识蒸馏相互协作学习表示的多样分布。通过将输入样本以两种增强格式呈现，训练在线网络来预测不同增强视图下的目标网络表示的相同样本。通过基于适当的评分规则的新损失函数训练这两个网络。我们对ProSMIN的收敛性提供了理论证明，证明了其修改后的评分规则的严格适用性。这一认识验证了该方法的优化过程并有助于其在提升表示质量方面的稳健性和有效性。

    In this paper, we propose a novel probabilistic self-supervised learning via Scoring Rule Minimization (ProSMIN), which leverages the power of probabilistic models to enhance representation quality and mitigate collapsing representations. Our proposed approach involves two neural networks; the online network and the target network, which collaborate and learn the diverse distribution of representations from each other through knowledge distillation. By presenting the input samples in two augmented formats, the online network is trained to predict the target network representation of the same sample under a different augmented view. The two networks are trained via our new loss function based on proper scoring rules. We provide a theoretical justification for ProSMIN's convergence, demonstrating the strict propriety of its modified scoring rule. This insight validates the method's optimization process and contributes to its robustness and effectiveness in improving representation qualit
    
[^16]: 使用异构数据批次的线性回归

    Linear Regression using Heterogeneous Data Batches. (arXiv:2309.01973v1 [cs.LG])

    [http://arxiv.org/abs/2309.01973](http://arxiv.org/abs/2309.01973)

    本论文提出了一种用于线性回归的新颖梯度算法，可以在不同子组的异构数据批次中进行学习，并且不再需要假设输入分布为高斯分布。

    

    在许多学习应用中，数据是从多个来源收集的，每个来源都提供一批样本，单独的样本是不足以学习其输入-输出关系的。一种常见的方法是假设这些来源属于数个未知的子组，每个子组具有未知的输入分布和输入-输出关系。我们考虑了这种设置最基本和重要的表现之一，即输出是输入的噪声线性组合，并且有 $k$ 个子组，每个子组都有自己的回归向量。之前的研究[1]表明，通过丰富的小批量，可以用少数中等大小的批次来学习回归向量，每个批次有 $\tilde\Omega( k^{3/2})$ 个样本。然而，该论文要求所有 $k$ 个子组的输入分布是各向同性的高斯分布，并表示去除这一假设是一个“有趣且具有挑战性的问题”。我们提出了一种新颖的基于梯度的算法，它可以:

    In many learning applications, data are collected from multiple sources, each providing a \emph{batch} of samples that by itself is insufficient to learn its input-output relationship. A common approach assumes that the sources fall in one of several unknown subgroups, each with an unknown input distribution and input-output relationship. We consider one of this setup's most fundamental and important manifestations where the output is a noisy linear combination of the inputs, and there are $k$ subgroups, each with its own regression vector. Prior work~\cite{kong2020meta} showed that with abundant small-batches, the regression vectors can be learned with only few, $\tilde\Omega( k^{3/2})$, batches of medium-size with $\tilde\Omega(\sqrt k)$ samples each. However, the paper requires that the input distribution for all $k$ subgroups be isotropic Gaussian, and states that removing this assumption is an ``interesting and challenging problem". We propose a novel gradient-based algorithm that
    
[^17]: QuantEase: 基于优化的语言模型量化--一种高效而直观的算法

    QuantEase: Optimization-based Quantization for Language Models -- An Efficient and Intuitive Algorithm. (arXiv:2309.01885v1 [stat.ML])

    [http://arxiv.org/abs/2309.01885](http://arxiv.org/abs/2309.01885)

    QuantEase是一种基于优化的语言模型量化算法，通过逐层量化和基于坐标下降的算法，高质量地解决了复杂的非凸量化问题，并引入了对异常值敏感的变种方法。

    

    随着大型语言模型（LLM）的普及，对于能够实现其高效部署的压缩技术的兴趣日益增加。本研究侧重于LLM的后训练量化（PTQ）。借鉴最近的进展，我们的工作引入了QuantEase，一个逐层量化框架，其中各个层面经过单独的量化。该问题被视为离散结构化的非凸优化问题，促使我们开发了基于坐标下降（CD）技术的算法。这些基于CD的方法为复杂的非凸逐层量化问题提供了高质量的解决方案。值得注意的是，我们的CD方法具有简单的更新步骤，仅依赖于矩阵和向量运算，避免了矩阵求逆或分解的需要。我们还探索了一种对异常值敏感的变种方法，允许保留具有完全精度的重要权重（异常值）。我们的提议达到了最先进的状态。

    With the rising popularity of Large Language Models (LLMs), there has been an increasing interest in compression techniques that enable their efficient deployment. This study focuses on the Post-Training Quantization (PTQ) of LLMs. Drawing from recent advances, our work introduces QuantEase, a layer-wise quantization framework where individual layers undergo separate quantization. The problem is framed as a discrete-structured non-convex optimization, prompting the development of algorithms rooted in Coordinate Descent (CD) techniques. These CD-based methods provide high-quality solutions to the complex non-convex layer-wise quantization problems. Notably, our CD-based approach features straightforward updates, relying solely on matrix and vector operations, circumventing the need for matrix inversion or decomposition. We also explore an outlier-aware variant of our approach, allowing for retaining significant weights (outliers) with complete precision. Our proposal attains state-of-th
    
[^18]: Pearson的卡方统计的非渐近逼近及其在离散分布概率权重的严格凸函数置信区间中的应用

    Non-asymptotic approximations for Pearson's chi-square statistic and its application to confidence intervals for strictly convex functions of the probability weights of discrete distributions. (arXiv:2309.01882v1 [math.ST])

    [http://arxiv.org/abs/2309.01882](http://arxiv.org/abs/2309.01882)

    本文提出了一种非渐近逼近方法，用于计算多项式概率权重的置信区间和累积分布函数比较，并将该方法应用于离散分布的负熵置信区间的计算。

    

    本文针对多项式概率权重提出了一种非渐近局部正态逼近方法。首先，我们使用该方法找到了均匀抖动多项式和具有相同均值和协方差的多元正态分布所引起的度量之间的非渐近总变差界限。根据总变差界限，我们还得到了Pearson的卡方统计量（表示为多项式向量的归一化二次型）和其多元正态分析的累积分布函数的比较以及分位数耦合不等式。我们将我们的结果应用于求解离散分布的负熵的置信区间。我们的方法可以更普遍地应用于求解离散分布权重的严格凸函数的置信区间。

    In this paper, we develop a non-asymptotic local normal approximation for multinomial probabilities. First, we use it to find non-asymptotic total variation bounds between the measures induced by uniformly jittered multinomials and the multivariate normals with the same means and covariances. From the total variation bounds, we also derive a comparison of the cumulative distribution functions and quantile coupling inequalities between Pearson's chi-square statistic (written as the normalized quadratic form of a multinomial vector) and its multivariate normal analogue. We apply our results to find confidence intervals for the negative entropy of discrete distributions. Our method can be applied more generally to find confidence intervals for strictly convex functions of the weights of discrete distributions.
    
[^19]: 委托分散机器学习中的数据收集

    Delegating Data Collection in Decentralized Machine Learning. (arXiv:2309.01837v1 [cs.LG])

    [http://arxiv.org/abs/2309.01837](http://arxiv.org/abs/2309.01837)

    这项研究在分散机器学习生态系统中研究了委托的数据收集问题，通过设计最优契约解决了模型质量评估的不确定性和对最优性能缺乏预先知识的挑战。

    

    受分散机器学习生态系统的出现的启发，我们研究了数据收集的委托问题。以契约理论为出发点，我们设计了解决两个基本机器学习挑战的最优和近似最优契约：模型质量评估的不确定性和对任何模型最优性能的缺乏知识。我们证明，通过简单的线性契约可以解决不确定性问题，即使委托人只有一个小的测试集，也能实现1-1/e的一等效用水平。此外，我们给出了委托人测试集大小的充分条件，可以达到对最优效用的逼近。为了解决对最优性能缺乏预先知识的问题，我们提出了一个凸问题，可以自适应和高效地计算最优契约。

    Motivated by the emergence of decentralized machine learning ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental machine learning challenges: lack of certainty in the assessment of model quality and lack of knowledge regarding the optimal performance of any model. We show that lack of certainty can be dealt with via simple linear contracts that achieve 1-1/e fraction of the first-best utility, even if the principal has a small test set. Furthermore, we give sufficient conditions on the size of the principal's test set that achieves a vanishing additive approximation to the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract.
    
[^20]: 用小的随机初始化梯度下降进行非对称矩阵感知

    Asymmetric matrix sensing by gradient descent with small random initialization. (arXiv:2309.01796v1 [cs.LG])

    [http://arxiv.org/abs/2309.01796](http://arxiv.org/abs/2309.01796)

    本论文研究了矩阵感知问题，通过小的随机初始化应用因式梯度下降算法来重建低秩矩阵。特别地，引入了一个连续微分方程，称为“扰动梯度流”，并证明了在扰动被限制在一定范围内时，扰动梯度流能够快速收敛到真实的目标矩阵。

    

    我们研究了矩阵感知，即从少量线性测量中重建低秩矩阵的问题。它可以被形式化为一个过参数化回归问题，可以通过因式分解的梯度下降解决，当从一个小的随机初始化开始。线性神经网络，特别是通过因式梯度下降进行矩阵感知，作为现代机器学习中非凸问题的典型模型，可以将复杂现象解开并详细研究。许多研究致力于研究非对称矩阵感知的特殊情况，例如非对称矩阵因式分解和对称半正定矩阵感知。我们的关键贡献是引入了一个连续微分方程，我们称之为“扰动梯度流”。我们证明了当扰动被限制在足够范围内时，扰动梯度流能够快速收敛到真实的目标矩阵。梯度下降对矩阵的动态

    We study matrix sensing, which is the problem of reconstructing a low-rank matrix from a few linear measurements. It can be formulated as an overparameterized regression problem, which can be solved by factorized gradient descent when starting from a small random initialization.  Linear neural networks, and in particular matrix sensing by factorized gradient descent, serve as prototypical models of non-convex problems in modern machine learning, where complex phenomena can be disentangled and studied in detail. Much research has been devoted to studying special cases of asymmetric matrix sensing, such as asymmetric matrix factorization and symmetric positive semi-definite matrix sensing.  Our key contribution is introducing a continuous differential equation that we call the $\textit{perturbed gradient flow}$. We prove that the perturbed gradient flow converges quickly to the true target matrix whenever the perturbation is sufficiently bounded. The dynamics of gradient descent for matr
    
[^21]: CONFIDERAI：一种新颖的CONFIRMAL可解释设计评分函数，用于可解释和可靠的人工智能

    CONFIDERAI: a novel CONFormal Interpretable-by-Design score function forExplainable and Reliable Artificial Intelligence. (arXiv:2309.01778v1 [cs.LG])

    [http://arxiv.org/abs/2309.01778](http://arxiv.org/abs/2309.01778)

    提出了一种新的可解释机器学习评分函数CONFIDERAI，它将一致性预测与规则模型相结合，利用规则的预测能力和点的几何位置，在特征空间中定义满足一致性保证的区域。

    

    每天的生活越来越受人工智能的影响，毫无疑问，机器学习算法必须为所有人设计成可靠和值得信赖的。具体来说，如果人工智能系统满足解释性、健壮性、透明性、公平性和隐私性这五个方面，计算机科学家认为它是安全和可信赖的。除了这五个方面，我们提出了第六个基本方面：一致性，即机器学习者对系统行为的概率性保证。在本文中，我们提出了一种方法，通过定义CONFIDERAI，一种基于规则的模型的新评分函数，将一致性预测与可解释的机器学习相结合，利用规则的预测能力和点在规则边界内的几何位置。我们还通过利用控制非一致性的数量的技术来解决在特征空间中定义满足一致性保证的区域的问题。

    Everyday life is increasingly influenced by artificial intelligence, and there is no question that machine learning algorithms must be designed to be reliable and trustworthy for everyone. Specifically, computer scientists consider an artificial intelligence system safe and trustworthy if it fulfills five pillars: explainability, robustness, transparency, fairness, and privacy. In addition to these five, we propose a sixth fundamental aspect: conformity, that is, the probabilistic assurance that the system will behave as the machine learner expects. In this paper, we propose a methodology to link conformal prediction with explainable machine learning by defining CONFIDERAI, a new score function for rule-based models that leverages both rules predictive ability and points geometrical position within rules boundaries. We also address the problem of defining regions in the feature space where conformal guarantees are satisfied by exploiting techniques to control the number of non-conforma
    
[^22]: 结构稀疏模型的广义信息准则

    Generalized Information Criteria for Structured Sparse Models. (arXiv:2309.01764v1 [stat.ME])

    [http://arxiv.org/abs/2309.01764](http://arxiv.org/abs/2309.01764)

    提出了一种新的广义信息准则(GIC)，用于在高维情景下恢复低维模型的结构稀疏模型。该准则考虑了所需恢复的稀疏模式，并提供了非渐进的模型选择界限和一致性条件。

    

    正则化的m-估计器由于能够在高维情景下恢复低维模型而被广泛使用。该研究主要集中在建立奥克尔界限的统一框架和推导支持恢复的条件上。在这个框架下，我们提出了一种新的考虑所需恢复的稀疏模式的广义信息准则(GIC)。我们得到了非渐进的模型选择界限，以及GIC模型选择一致性的充分条件。此外，我们还表明GIC也可以在规则化的$ m $-估计框架中用于选择正则化参数，从而在高维情景中实际使用GIC进行模型选择。我们以广义线性回归和低秩矩阵回归中的分组LASSO为例进行说明。

    Regularized m-estimators are widely used due to their ability of recovering a low-dimensional model in high-dimensional scenarios. Some recent efforts on this subject focused on creating a unified framework for establishing oracle bounds, and deriving conditions for support recovery. Under this same framework, we propose a new Generalized Information Criteria (GIC) that takes into consideration the sparsity pattern one wishes to recover. We obtain non-asymptotic model selection bounds and sufficient conditions for model selection consistency of the GIC. Furthermore, we show that the GIC can also be used for selecting the regularization parameter within a regularized $m$-estimation framework, which allows practical use of the GIC for model selection in high-dimensional scenarios. We provide examples of group LASSO in the context of generalized linear regression and low rank matrix regression.
    
[^23]: 高维数据的鲁棒罚最小二乘深度修剪残差回归

    Robust penalized least squares of depth trimmed residuals regression for high-dimensional data. (arXiv:2309.01666v1 [stat.ML])

    [http://arxiv.org/abs/2309.01666](http://arxiv.org/abs/2309.01666)

    这篇论文介绍了鲁棒罚最小二乘深度修剪残差回归方法，针对高维数据的挑战进行了深入研究，并指出大多数传统方法在处理异常值和污染点时不够稳健。

    

    大数据时代的挑战包括：(i) 维数p往往大于样本量n (ii) 异常值或污染点经常被隐藏起来且更难检测。挑战(i)使得大多数传统方法不适用，因此它吸引了统计学、计算机科学和生物医学界的广泛关注。已经提出了大量惩罚回归方法作为分析高维数据的现代方法。然而，尽管关注了挑战(ii)，但大多数方法在面对单个异常值或污染点时都会崩溃。

    Challenges with data in the big-data era include (i) the dimension $p$ is often larger than the sample size $n$ (ii) outliers or contaminated points are frequently hidden and more difficult to detect. Challenge (i) renders most conventional methods inapplicable. Thus, it attracts tremendous attention from statistics, computer science, and bio-medical communities. Numerous penalized regression methods have been introduced as modern methods for analyzing high-dimensional data. Disproportionate attention has been paid to the challenge (ii) though. Penalized regression methods can do their job very well and are expected to handle the challenge (ii) simultaneously. Most of them, however, can break down by a single outlier (or single adversary contaminated point) as revealed in this article.  The latter systematically examines leading penalized regression methods in the literature in terms of their robustness, provides quantitative assessment, and reveals that most of them can break down by 
    
[^24]: 局部平稳图形过程

    Locally Stationary Graph Processes. (arXiv:2309.01657v1 [stat.ML])

    [http://arxiv.org/abs/2309.01657](http://arxiv.org/abs/2309.01657)

    这是一种局部平稳图形过程模型，旨在将局部平稳概念扩展到不规则的图域上。它通过将整个过程表示为一组组成部分过程的组合来表征局部平稳性，以使过程在图上按照每个组成部分的要求变化得更加平滑。

    

    在不规则的网络拓扑上收集的数据集的分析和推理中，常常会使用平稳图形过程模型。然而，大多数现有方法使用单一的全局有效的平稳过程模型表示图形信号，但在许多实际问题中，过程的特性可能会在图的不同区域发生局部变化。本文提出了一种局部平稳图形过程（LSGP）模型，旨在将经典的局部平稳概念扩展到不规则的图域上。我们通过将整个过程表示为一组组成部分过程的组合来表征局部平稳性，以使过程在图上按照每个组成部分的要求变化得更加平滑。我们提出了一种计算LSGP模型的算法，并研究了用WSS过程对LSGP进行局部近似。在信号内插问题上进行的实验表明

    Stationary graph process models are commonly used in the analysis and inference of data sets collected on irregular network topologies. While most of the existing methods represent graph signals with a single stationary process model that is globally valid on the entire graph, in many practical problems, the characteristics of the process may be subject to local variations in different regions of the graph. In this work, we propose a locally stationary graph process (LSGP) model that aims to extend the classical concept of local stationarity to irregular graph domains. We characterize local stationarity by expressing the overall process as the combination of a set of component processes such that the extent to which the process adheres to each component varies smoothly over the graph. We propose an algorithm for computing LSGP models from realizations of the process, and also study the approximation of LSGPs locally with WSS processes. Experiments on signal interpolation problems show 
    
[^25]: 动态probit模型中平滑分布的期望传播

    Expectation propagation for the smoothing distribution in dynamic probit. (arXiv:2309.01641v1 [stat.CO])

    [http://arxiv.org/abs/2309.01641](http://arxiv.org/abs/2309.01641)

    本文提出了一种新的期望传播算法来推理动态probit模型中的平滑分布，通过金融实例表明了其相对于现有算法的准确度提升。

    

    最近证明了具有高斯状态动力学的动态probit模型的平滑分布属于统一的偏正态家族。尽管在小到中等规模的设置中这是可计算的，但在更高维度上可能变得计算不可行。在这项工作中，我们采用了一种更通用的期望传播算法类别，推导出一种有效的期望传播例程来进行这种分布的推理。我们通过金融实例表明所提出的近似方法相对于现有的近似算法具有准确度的提升。

    The smoothing distribution of dynamic probit models with Gaussian state dynamics was recently proved to belong to the unified skew-normal family. Although this is computationally tractable in small-to-moderate settings, it may become computationally impractical in higher dimensions. In this work, adapting a recent more general class of expectation propagation (EP) algorithms, we derive an efficient EP routine to perform inference for such a distribution. We show that the proposed approximation leads to accuracy gains over available approximate algorithms in a financial illustration.
    
[^26]: 通过期望传播在probit模型中高效计算预测概率

    Efficient computation of predictive probabilities in probit models via expectation propagation. (arXiv:2309.01630v1 [stat.CO])

    [http://arxiv.org/abs/2309.01630](http://arxiv.org/abs/2309.01630)

    该论文通过期望传播方法在贝叶斯probit模型中高效计算预测概率，并展示了与最先进方法相比的改进。

    

    二元回归模型是二分类的流行基于模型的方法。在贝叶斯框架中，后验分布的计算挑战促使了仍在进行的有益研究。在这里，我们关注通过期望传播（EP）在贝叶斯probit模型中计算预测概率。利用最近文献中的更一般结果，我们展示这种预测概率可以得到一个闭式表达式。在模拟研究中展示了与最先进方法相比的改进。

    Binary regression models represent a popular model-based approach for binary classification. In the Bayesian framework, computational challenges in the form of the posterior distribution motivate still-ongoing fruitful research. Here, we focus on the computation of predictive probabilities in Bayesian probit models via expectation propagation (EP). Leveraging more general results in recent literature, we show that such predictive probabilities admit a closed-form expression. Improvements over state-of-the-art approaches are shown in a simulation study.
    
[^27]: 在高维Probit模型中，用于后验近似的高效期望传播

    Efficient expectation propagation for posterior approximation in high-dimensional probit models. (arXiv:2309.01619v1 [stat.CO])

    [http://arxiv.org/abs/2309.01619](http://arxiv.org/abs/2309.01619)

    本文介绍了一种在高维Probit模型中用于后验近似的高效期望传播方法，通过使用扩展多元偏态正态分布的结果，实现了可计算性，并在详细的模拟研究中验证了其有效性。

    

    贝叶斯二元回归是一个繁荣的研究领域，由于当前可用方法在高维设置、大数据集或两者都遇到的计算挑战。在本文中，我们关注于贝叶斯probit回归中后验分布的期望传播（EP）近似，其在多元高斯先验分布下。通过调整Anceschi等人（2023）的更一般的推导，我们展示了如何利用扩展多元偏态正态分布的结果，推导出EP例程的高效实现，其每次迭代的计算成本与协变量的数量成线性比例。这使得EP在挑战性的高维设置中也具有可计算性，正如详细的模拟研究所示。

    Bayesian binary regression is a prosperous area of research due to the computational challenges encountered by currently available methods either for high-dimensional settings or large datasets, or both. In the present work, we focus on the expectation propagation (EP) approximation of the posterior distribution in Bayesian probit regression under a multivariate Gaussian prior distribution. Adapting more general derivations in Anceschi et al. (2023), we show how to leverage results on the extended multivariate skew-normal distribution to derive an efficient implementation of the EP routine having a per-iteration cost that scales linearly in the number of covariates. This makes EP computationally feasible also in challenging high-dimensional settings, as shown in a detailed simulation study.
    
[^28]: 大尺度和无穷宽度下的深度学习勒让演讲

    Les Houches Lectures on Deep Learning at Large & Infinite Width. (arXiv:2309.01592v1 [stat.ML])

    [http://arxiv.org/abs/2309.01592](http://arxiv.org/abs/2309.01592)

    本论文主要以无穷宽度和大宽度范围内的深度神经网络为研究对象，讨论了这些网络的各种统计和动力学特性，包括随机网络的性质、训练后的网络与线性模型、核函数和高斯过程之间的关系，以及对大但有限宽度网络在初始化和训练后的摄动和非摄动处理。

    

    这些演讲是在2022年勒让夏季学校统计物理和机器学习课程上展示的，着重探讨了深度神经网络在无限宽度和大宽度范围内的情况。涵盖的主题包括这些网络的各种统计和动力学特性。特别是，讲师们讨论了随机深度神经网络的特性；训练过的深度神经网络，线性模型，核函数和高斯过程之间的联系，这些联系在无穷宽度的极限下出现；以及在初始化和训练后对大但有限宽度网络的摄动和非摄动处理。

    These lectures, presented at the 2022 Les Houches Summer School on Statistical Physics and Machine Learning, focus on the infinite-width limit and large-width regime of deep neural networks. Topics covered include various statistical and dynamical properties of these networks. In particular, the lecturers discuss properties of random deep neural networks; connections between trained deep neural networks, linear models, kernels, and Gaussian processes that arise in the infinite-width limit; and perturbative and non-perturbative treatments of large but finite-width networks, at initialization and after training.
    
[^29]: 加速马尔可夫链蒙特卡洛采样的扩散模型

    Accelerating Markov Chain Monte Carlo sampling with diffusion models. (arXiv:2309.01454v1 [hep-ph])

    [http://arxiv.org/abs/2309.01454](http://arxiv.org/abs/2309.01454)

    本论文提出了一种新的方法，通过将Metropolis-Hastings算法与扩散模型相结合，加速马尔可夫链蒙特卡洛采样，从而有效地探索高维度和/或多模式的后验函数。

    

    物理模型的全局拟合需要有效的方法来探索高维度和/或多模式的后验函数。我们引入了一种新的方法，通过将Metropolis-Hastings算法与扩散模型相结合，可以绘制全局样本，以近似后验分布。我们简要回顾了图像合成中的扩散模型，然后提供了一种针对低维数据数组的简化扩散模型。然后，我们介绍了我们改进的Metropolis-Hastings算法，它将局部提案与从定期训练的扩散模型中获取的全局提案结合在一起，该模型是在MCMC运行期间产生的样本上进行训练的。我们的方法导致在几个分析函数以及基于部分子分析的物理示例中获得了准确表示贝叶斯后验所需的似然评估数量的显着减少。

    Global fits of physics models require efficient methods for exploring high-dimensional and/or multimodal posterior functions. We introduce a novel method for accelerating Markov Chain Monte Carlo (MCMC) sampling by pairing a Metropolis-Hastings algorithm with a diffusion model that can draw global samples with the aim of approximating the posterior. We briefly review diffusion models in the context of image synthesis before providing a streamlined diffusion model tailored towards low-dimensional data arrays. We then present our adapted Metropolis-Hastings algorithm which combines local proposals with global proposals taken from a diffusion model that is regularly trained on the samples produced during the MCMC run. Our approach leads to a significant reduction in the number of likelihood evaluations required to obtain an accurate representation of the Bayesian posterior across several analytic functions, as well as for a physical example based on a global analysis of parton distributio
    
[^30]: 不同iable的贝叶斯结构学习中的拓扑排序与保证无环性的约束。

    Topological Ordering in Differentiable Bayesian Structure Learning with Guaranteed Acyclicity Constraint. (arXiv:2309.01392v1 [cs.LG])

    [http://arxiv.org/abs/2309.01392](http://arxiv.org/abs/2309.01392)

    本研究提出了一种在贝叶斯结构学习中严格约束图的无环性的替代方法，通过整合拓扑排序知识，能够减少推理复杂性，并确保生成的图的结构是无环的。实证实验表明，该方法胜过相关的贝叶斯基于得分的方法。

    

    基于得分的结构学习方法因其可扩展性而蓬勃发展。连续松弛是这一进展的关键原因。尽管取得了有希望的结果，但大多数方法仍然在通过最小化定义的得分来确保从潜在空间生成的图是无环的方面遇到困难。还存在另一种基于置换的方法，关注的是有向无环图（DAG）中变量的拓扑排序的搜索，以限制图的搜索空间。在本研究中，我们提出了一种利用拓扑排序知识来严格限制图的无环性的替代方法。我们的方法可以减少推理复杂性，同时确保生成的图的结构是无环的。我们对模拟和真实数据进行的实证实验表明，我们的方法可以胜过相关的贝叶斯基于得分的方法。

    Score-based approaches in the structure learning task are thriving because of their scalability. Continuous relaxation has been the key reason for this advancement. Despite achieving promising outcomes, most of these methods are still struggling to ensure that the graphs generated from the latent space are acyclic by minimizing a defined score. There has also been another trend of permutation-based approaches, which concern the search for the topological ordering of the variables in the directed acyclic graph (DAG) in order to limit the search space of the graph. In this study, we propose an alternative approach for strictly constraining the acyclicty of the graphs with an integration of the knowledge from the topological orderings. Our approach can reduce inference complexity while ensuring the structures of the generated graphs to be acyclic. Our empirical experiments with simulated and real-world data show that our approach can outperform related Bayesian score-based approaches.
    
[^31]: 稀疏邻接矩阵的随机投影

    Random Projections of Sparse Adjacency Matrices. (arXiv:2309.01360v1 [cs.DS])

    [http://arxiv.org/abs/2309.01360](http://arxiv.org/abs/2309.01360)

    本研究分析了一种针对邻接矩阵的随机投影方法，发现这种方法在表示稀疏图时具有实用性。通过保留邻接矩阵的功能并具有额外属性，这种方法具有吸引力。研究结果表明，投影大小可以按线性比例缩放，同时保留准确的一阶图信息。

    

    我们分析了一种针对邻接矩阵的随机投影方法，研究其在表示稀疏图中的实用性。我们展示了这些随机投影保留了底层邻接矩阵的功能，同时具有额外的属性，使它们作为动态图表示具有吸引力。特别地，它们可以在相同的空间中表示不同大小和顶点集合的图，从而实现图的聚合和操作的统一。我们还提供了关于保留准确图操作所需的投影大小如何按比例缩放的结果，表明投影大小可以与顶点数量线性缩放，同时准确保留一阶图信息。最后，我们将我们的随机投影表征为保持距离的邻接矩阵映射，类似于传统的Johnson-Lindenstrauss映射。

    We analyze a random projection method for adjacency matrices, studying its utility in representing sparse graphs. We show that these random projections retain the functionality of their underlying adjacency matrices while having extra properties that make them attractive as dynamic graph representations. In particular, they can represent graphs of different sizes and vertex sets in the same space, allowing for the aggregation and manipulation of graphs in a unified manner. We also provide results on how the size of the projections need to scale in order to preserve accurate graph operations, showing that the size of the projections can scale linearly with the number of vertices while accurately retaining first-order graph information. We conclude by characterizing our random projection as a distance-preserving map of adjacency matrices analogous to the usual Johnson-Lindenstrauss map.
    
[^32]: $\mathbb{T}$-随机图

    $\mathbb{T}$-Stochastic Graphs. (arXiv:2309.01301v1 [stat.AP])

    [http://arxiv.org/abs/2309.01301](http://arxiv.org/abs/2309.01301)

    本文研究了社交网络中层次聚类的统计方法，并提出了一种新的概率模型$\mathbb{T}$-随机图，用于解决现有方法中存在的不稳定性问题。

    

    先前的社交网络分析中关于层次聚类的统计方法都构建了一个“超度量”的层次结构。虽然超度量性的假设在系统发生学文献中已经得到了讨论和研究，但在社交网络文献中尚未得到承认。我们展示了网络中的“非超度量结构”引入了现有自上而下恢复算法的显著不稳定性。为了解决这个问题，我们引入了一种不稳定性诊断图并使用它来检查一系列经验网络。这些网络似乎违反了“超度量”假设。我们提出了一种看似简单但又很通用的概率模型类，称为$\mathbb{T}$-随机图，它对潜在层次结构不施加拓扑限制。为了说明这个模型，我们提出了六种替代性的层次网络模型，然后证明了所有六种模型都等价于$\mathbb{T}$-随机图模型。

    Previous statistical approaches to hierarchical clustering for social network analysis all construct an "ultrametric" hierarchy. While the assumption of ultrametricity has been discussed and studied in the phylogenetics literature, it has not yet been acknowledged in the social network literature. We show that "non-ultrametric structure" in the network introduces significant instabilities in the existing top-down recovery algorithms. To address this issue, we introduce an instability diagnostic plot and use it to examine a collection of empirical networks. These networks appear to violate the "ultrametric" assumption. We propose a deceptively simple and yet general class of probabilistic models called $\mathbb{T}$-Stochastic Graphs which impose no topological restrictions on the latent hierarchy. To illustrate this model, we propose six alternative forms of hierarchical network models and then show that all six are equivalent to the $\mathbb{T}$-Stochastic Graph model. These alternativ
    
[^33]: 深度残差网络的隐式正则化与神经常微分方程的关联

    Implicit regularization of deep residual networks towards neural ODEs. (arXiv:2309.01213v1 [stat.ML])

    [http://arxiv.org/abs/2309.01213](http://arxiv.org/abs/2309.01213)

    本文建立了深度残差网络向神经常微分方程的隐式正则化，通过对用梯度流训练的非线性网络的研究，证明了在网络以神经常微分方程的离散化形式初始化后，这种离散化将在整个训练过程中保持不变，并提供了收敛性的条件。

    

    残差神经网络是先进的深度学习模型。它们的连续深度模拟称为神经常微分方程（ODE），也被广泛使用。尽管它们取得了成功，但离散模型与连续模型之间的联系仍缺乏坚实的数学基础。在本文中，我们通过建立一个针对用梯度流训练的非线性网络的深度残差网络向神经常微分方程的隐式正则化来朝着这个方向迈出了一步。我们证明，如果网络的初始化是神经常微分方程的离散化，则这种离散化在整个训练过程中保持不变。我们的结果对于有限的训练时间和训练时间趋于无穷大都成立，只要网络满足Polyak-Lojasiewicz条件。重要的是，这个条件适用于一个残差网络家族，其中残差是两层感知机，在宽度上只是线性超参数化，并且暗示了梯度流的收敛性。

    Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-Lojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to
    
[^34]: 用于机器学习的热带几何工具：TML软件包

    Tropical Geometric Tools for Machine Learning: the TML package. (arXiv:2309.01082v1 [stat.ML])

    [http://arxiv.org/abs/2309.01082](http://arxiv.org/abs/2309.01082)

    TML软件包是第一个包含一套全面工具和方法的R软件包，用于处理与热带凸性相关的基本计算和可视化，以及使用热带度量进行监督和无监督学习模型的统计推断。

    

    在过去的十年中，热带几何学的发展提供了许多直接应用于统计学习问题的工具。TML软件包是第一个包含一套全面的工具和方法的R软件包，用于处理与热带凸性相关的基本计算、热带凸集的可视化，以及使用热带度量和热带投影环上的max-plus代数进行监督和无监督学习模型。主要的，TML软件包使用Hit and Run Markov chain Monte Carlo采样器与热带度量作为统计推断的主要工具。除了基本计算和热带HAR采样器的各种应用之外，我们还关注TML软件包中包含的几种监督和无监督方法，包括热带主成分分析、热带逻辑回归和热带核密度估计。

    In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
    
[^35]: 通过神经微分方程进行分布学习：一种非参数统计角度

    Distribution learning via neural differential equations: a nonparametric statistical perspective. (arXiv:2309.01043v1 [math.ST])

    [http://arxiv.org/abs/2309.01043](http://arxiv.org/abs/2309.01043)

    本文提出了一种通过使用神经微分方程进行分布学习的新方法，并建立了相应的非参数统计收敛性分析。

    

    普通微分方程（ODEs）通过其引导的流映射，为表示复杂概率分布的可逆变换提供了强大的框架。尽管这些模型在机器学习中取得了巨大的成功，特别是对于生成建模和密度估计，但对它们的统计性质知之甚少。本文建立了通过最大似然训练的ODE模型的分布学习的第一个一般非参数统计收敛性分析。我们首先证明了适用于满足一定简单边界约束的任意速度场类$\mathcal{F}$的收敛定理。这个一般结果捕捉了逼近误差（'偏差'）和ODE模型的复杂性（'方差'）之间的平衡。我们证明了通过$\mathcal F$类的$C^1$-度量熵可以量化后者。然后，我们将这个通用框架应用于$C^k$-smoot的情况。

    Ordinary differential equations (ODEs), via their induced flow maps, provide a powerful framework to parameterize invertible transformations for the purpose of representing complex probability distributions. While such models have achieved enormous success in machine learning, particularly for generative modeling and density estimation, little is known about their statistical properties. This work establishes the first general nonparametric statistical convergence analysis for distribution learning via ODE models trained through likelihood maximization. We first prove a convergence theorem applicable to arbitrary velocity field classes $\mathcal{F}$ satisfying certain simple boundary constraints. This general result captures the trade-off between approximation error (`bias') and the complexity of the ODE model (`variance'). We show that the latter can be quantified via the $C^1$-metric entropy of the class $\mathcal F$. We then apply this general framework to the setting of $C^k$-smoot
    
[^36]: 关于深度运算符网络的训练和泛化性

    On the training and generalization of deep operator networks. (arXiv:2309.01020v1 [math.NA])

    [http://arxiv.org/abs/2309.01020](http://arxiv.org/abs/2309.01020)

    我们提出了一种用于深度运算符网络的新的训练方法，通过将训练任务分解为两个降低复杂性的子任务，并引入正交化过程来提高网络的稳定性和泛化能力。

    

    我们提出了一种新的训练方法，用于深度运算符网络（DeepONets），这是一种最流行的用于运算符的神经网络模型。DeepONets由两个子网络构成，分别是分支网络和主干网络。通常情况下，这两个子网络同时进行训练，这相当于在高维空间中解决一个复杂的优化问题。此外，非凸和非线性性质使得训练非常具有挑战性。为了克服这种挑战，我们提出了一种两步训练方法，首先训练主干网络，然后顺序训练分支网络。核心机制受到分而治之的启发，将整个复杂训练任务分解为两个具有降低复杂性的子任务。其中引入了格拉姆-施密特正交化过程，显著提高了稳定性和泛化能力。在理论方面，我们建立了一个关于训练样本数的泛化误差估计。

    We present a novel training method for deep operator networks (DeepONets), one of the most popular neural network models for operators. DeepONets are constructed by two sub-networks, namely the branch and trunk networks. Typically, the two sub-networks are trained simultaneously, which amounts to solving a complex optimization problem in a high dimensional space. In addition, the nonconvex and nonlinear nature makes training very challenging. To tackle such a challenge, we propose a two-step training method that trains the trunk network first and then sequentially trains the branch network. The core mechanism is motivated by the divide-and-conquer paradigm and is the decomposition of the entire complex training task into two subtasks with reduced complexity. Therein the Gram-Schmidt orthonormalization process is introduced which significantly improves stability and generalization ability. On the theoretical side, we establish a generalization error estimate in terms of the number of tr
    
[^37]: 贝叶斯稀疏性和类别稀疏性先验于字典学习和编码

    Bayesian sparsity and class sparsity priors for dictionary learning and coding. (arXiv:2309.00999v1 [stat.ML])

    [http://arxiv.org/abs/2309.00999](http://arxiv.org/abs/2309.00999)

    本文提出了一种贝叶斯字典学习和编码方法，通过压缩子字典和引入建模误差来改进字典匹配过程，并采用数据驱动的稀疏编码技术识别不相关的子字典。

    

    字典学习方法在解决具有挑战性的逆问题中越来越受欢迎。在字典学习方法中，计算正向模型被一个包含可能结果的大型字典替代，问题是识别最能匹配数据的字典条目，类似于传统搜索引擎中的查询匹配。稀疏编码技术用于确保字典匹配只识别出少数字典条目，并且字典压缩方法用于减少匹配问题的复杂性。在本文中，我们提出了一种工作流程来促进字典匹配过程。首先，将完整字典分成单独压缩的子字典。字典压缩引入的误差在贝叶斯框架中被处理为建模误差。此外，我们提出了一种新的基于贝叶斯的数据驱动组稀疏编码方法，以帮助识别不相关的子字典。

    Dictionary learning methods continue to gain popularity for the solution of challenging inverse problems. In the dictionary learning approach, the computational forward model is replaced by a large dictionary of possible outcomes, and the problem is to identify the dictionary entries that best match the data, akin to traditional query matching in search engines. Sparse coding techniques are used to guarantee that the dictionary matching identifies only few of the dictionary entries, and dictionary compression methods are used to reduce the complexity of the matching problem. In this article, we propose a work flow to facilitate the dictionary matching process. First, the full dictionary is divided into subdictionaries that are separately compressed. The error introduced by the dictionary compression is handled in the Bayesian framework as a modeling error. Furthermore, we propose a new Bayesian data-driven group sparsity coding method to help identify subdictionaries that are not relev
    
[^38]: 用于跟踪高维非线性动力系统的集成评分滤波器

    An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems. (arXiv:2309.00983v1 [stat.ML])

    [http://arxiv.org/abs/2309.00983](http://arxiv.org/abs/2309.00983)

    我们提出了一种集成评分滤波器（EnSF），在处理高维非线性滤波问题时具有卓越的准确性。EnSF利用评分模型在伪时域中描述滤波密度的演化，并通过评分函数存储信息，相比于使用蒙特卡罗样本的粒子滤波器和集成卡尔曼滤波器具有更好的效果。

    

    我们提出了一种集成评分滤波器（EnSF）来解决高维非线性滤波问题，并具有卓越的准确性。现有的滤波方法（如粒子滤波器或集成卡尔曼滤波器）在处理高维和高度非线性问题时存在低准确性的主要缺陷。EnSF通过利用基于评分的扩散模型，在伪时域中定义，来描述滤波密度的演化，从而攻克了这一挑战。EnSF在评分函数中存储了递归更新的滤波密度函数的信息，而不是在一组有限的蒙特卡罗样本中存储信息（用于粒子滤波器和集成卡尔曼滤波器）。与训练神经网络来近似评分函数的现有扩散模型不同，我们开发了一种无需训练的评分估计方法，使用基于小批量的蒙特卡罗估计器来直接近似任何伪空间-时间位置处的评分函数，从而提供了足够准确的估计。

    We propose an ensemble score filter (EnSF) for solving high-dimensional nonlinear filtering problems with superior accuracy. A major drawback of existing filtering methods, e.g., particle filters or ensemble Kalman filters, is the low accuracy in handling high-dimensional and highly nonlinear problems. EnSF attacks this challenge by exploiting the score-based diffusion model, defined in a pseudo-temporal domain, to characterizing the evolution of the filtering density. EnSF stores the information of the recursively updated filtering density function in the score function, in stead of storing the information in a set of finite Monte Carlo samples (used in particle filters and ensemble Kalman filters). Unlike existing diffusion models that train neural networks to approximate the score function, we develop a training-free score estimation that uses mini-batch-based Monte Carlo estimator to directly approximate the score function at any pseudo-spatial-temporal location, which provides suf
    
[^39]: 绕过模拟器: 近似最优的对抗线性情境臂带

    Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits. (arXiv:2309.00814v1 [cs.LG])

    [http://arxiv.org/abs/2309.00814](http://arxiv.org/abs/2309.00814)

    本文提出了一种绕过模拟器的对抗线性情境臂带算法，能够在每轮行动集较小的情况下实现$\widetilde{O}(\sqrt{T})$的遗憾度。这个算法还能够处理损失线性近似以及对抗性损失和随机臂可用性的特殊情况。

    

    本文考虑对抗性线性情境臂带问题，其中损失向量完全被对抗地选择，每轮行动集（即情境）从固定分布中抽样。现有针对该问题的方法要么需要访问模拟器生成自由的i.i.d.情境，要么在最优遗憾方面只能达到次优结果，不好于$\widetilde{O}(T^{\frac{5}{6}})$，或者计算效率低下。我们通过不使用模拟器，同时保持在每轮行动集较小的情况下计算效率，大大改善了这些结果，使得遗憾度达到$\widetilde{O}(\sqrt{T})$。对于具有对抗性损失和随机臂可用性的睡眠臂带特例，我们的结果肯定地回答了Saha等人所提出的关于是否存在具有$poly(d)\sqrt{T}$遗憾度的多项式时间算法的开放问题。我们的方法自然地处理了损失近似为线性的情况，同时我们的遗憾度接近最优。

    We consider the adversarial linear contextual bandit problem, where the loss vectors are selected fully adversarially and the per-round action set (i.e. the context) is drawn from a fixed distribution. Existing methods for this problem either require access to a simulator to generate free i.i.d. contexts, achieve a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6}})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-opt
    
[^40]: 结构化径向基函数网络：用于多假设预测的多样性建模

    Structured Radial Basis Function Network: Modelling Diversity for Multiple Hypotheses Prediction. (arXiv:2309.00781v1 [cs.LG])

    [http://arxiv.org/abs/2309.00781](http://arxiv.org/abs/2309.00781)

    这篇论文提出了一种结构化径向基函数网络，用于解决多模态回归问题。该网络能够有效地组合多个假设预测器，并通过插值逼近多个假设目标分布，具有较好的性能。

    

    多模态回归对于预测非平稳过程或具有复杂分布的问题非常重要。可以通过多假设框架来处理，但在学习模型中有效地组合它们是有困难的。本文提出了一种结构化径向基函数网络，作为多假设预测器的集合，用于回归问题。这些预测器是任何类型的回归模型，可以形成以它们在训练过程中的损失为函数的重心维诺图分割。证明了这个结构化模型能够有效地插值这个分割，并且逼近多个假设目标分布，并且等价于插值预测器的元损失，损失是插值误差的零集。该模型在预测器和基函数中心之间具有固定点迭代算法。可以通过截断分割格式来参数化地控制学习中的多样性。

    Multi-modal regression is important in forecasting nonstationary processes or with a complex mixture of distributions. It can be tackled with multiple hypotheses frameworks but with the difficulty of combining them efficiently in a learning model. A Structured Radial Basis Function Network is presented as an ensemble of multiple hypotheses predictors for regression problems. The predictors are regression models of any type that can form centroidal Voronoi tessellations which are a function of their losses during training. It is proved that this structured model can efficiently interpolate this tessellation and approximate the multiple hypotheses target distribution and is equivalent to interpolating the meta-loss of the predictors, the loss being a zero set of the interpolation error. This model has a fixed-point iteration algorithm between the predictors and the centers of the basis functions. Diversity in learning can be controlled parametrically by truncating the tessellation format
    
[^41]: 攻击性过剩风险在错误指定模型下的非渐近界限

    Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models. (arXiv:2309.00771v1 [stat.ML])

    [http://arxiv.org/abs/2309.00771](http://arxiv.org/abs/2309.00771)

    我们提出了一种通用方法来评估在错误指定模型下基于攻击性损失的鲁棒估计器的性能。我们研究了攻击性过剩风险，并建立了与利普西茨损失函数相关的非渐近上界。在二次损失的非参数回归中，我们展示了攻击性过剩风险界限优于一般损失的结果。

    

    我们提出了一种评估基于错误指定模型下的鲁棒估计器性能的通用方法，该方法基于攻击性损失。我们首先展示了在一定的平滑条件下，攻击性风险等同于由分布攻击导致的风险，这确保了攻击性训练过程的良好定义性。为了评估攻击性估计器的泛化性能，我们研究了攻击性过剩风险。我们提出的分析方法包括对泛化误差和逼近误差的调查。然后，我们建立了与利普西茨损失函数相关的攻击性过剩风险的非渐近上界。此外，我们将我们的通用结果应用于分类和回归问题的攻击性训练。对于非参数回归中的二次损失，我们展示了攻击性过剩风险界限可以优于一般损失的结果。

    We propose a general approach to evaluating the performance of robust estimators based on adversarial losses under misspecified models. We first show that adversarial risk is equivalent to the risk induced by a distributional adversarial attack under certain smoothness conditions. This ensures that the adversarial training procedure is well-defined. To evaluate the generalization performance of the adversarial estimator, we study the adversarial excess risk. Our proposed analysis method includes investigations on both generalization error and approximation error. We then establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions. In addition, we apply our general results to adversarial training for classification and regression problems. For the quadratic loss in nonparametric regression, we show that the adversarial excess risk bound can be improved over those for a general loss.
    
[^42]: 随机森林中的预测误差估计

    Prediction Error Estimation in Random Forests. (arXiv:2309.00736v1 [stat.ML])

    [http://arxiv.org/abs/2309.00736](http://arxiv.org/abs/2309.00736)

    本文通过量化评估分类随机森林的误差估计方法，发现随机森林的预测误差估计比平均预测误差更接近真实误差率，并且这一结果适用于不同的误差估计策略。

    

    本文定量评估了分类随机森林的误差估计。在Bates等人（2023年）建立的初步理论框架的基础上，从理论和经验角度探讨了随机森林中常见的各种误差估计方法在真实误差率和期望误差率方面的情况。我们发现，在分类情况下，随机森林的预测误差估计平均更接近真实误差率，而不是平均预测误差。与Bates等人（2023年）对逻辑回归的研究结果相反。我们进一步证明，这个结果适用于交叉验证、自举和数据划分等不同的误差估计策略。

    In this paper, error estimates of classification Random Forests are quantitatively assessed. Based on the initial theoretical framework built by Bates et al. (2023), the true error rate and expected error rate are theoretically and empirically investigated in the context of a variety of error estimation methods common to Random Forests. We show that in the classification case, Random Forests' estimates of prediction error is closer on average to the true error rate instead of the average prediction error. This is opposite the findings of Bates et al. (2023) which were given for logistic regression. We further show that this result holds across different error estimation strategies such as cross-validation, bagging, and data splitting.
    
[^43]: 本文研究在带有轨迹反馈的零和不完全信息博弈中如何学习ε-最优策略。在这种情况下，玩家根据他们在固定数量的回合中观察到的信息依次更新策略。现有的方法由于使用了重要性采样来对动作序列进行估计，导致方差较高。为了减小这种方差，我们考虑使用一种固定采样方法，即玩家在随时间变化的情况下仍然更新策略，但观察到的信息是通过给定的固定采样策略获得的。我们的方法基于一种自适应的在线镜像下降（OMD）算法，该算法将OMD应用于每个信息集，使用逐渐减小的学习率和正则化损失。我们证明了这种方法在高概率下具有收敛速度为$\tilde{\mathcal{O}}(T^{-1/2})$，并在应用最佳策略时对游戏参数具有近乎最优的依赖关系。

    Local and adaptive mirror descents in extensive-form games. (arXiv:2309.00656v1 [cs.GT])

    [http://arxiv.org/abs/2309.00656](http://arxiv.org/abs/2309.00656)

    本文研究了在零和不完全信息博弈中学习ε-最优策略的问题。通过提出一种固定采样方法，并使用自适应的在线镜像下降算法进行局部更新，我们取得了收敛速度为$\tilde{\mathcal{O}}(T^{-1/2})$的结果，并在最佳策略下对游戏参数具有近乎最优的依赖关系。

    

    本文研究在带有轨迹反馈的零和不完全信息博弈中学习ε-最优策略的问题。现有方法由于使用了重要性采样，存在方差较高的问题。为了减小方差，我们提出了一种固定采样方法，使用固定采样策略来观察信息。我们的方法基于自适应的在线镜像下降算法，对每个信息集进行局部更新，并使用逐渐减小的学习率和正则化损失。我们证明了该方法在高概率下具有收敛速度为$\tilde{\mathcal{O}}(T^{-1/2})$，并在最佳策略下对游戏参数具有近乎最优的依赖关系。

    We study how to learn $\epsilon$-optimal strategies in zero-sum imperfect information games (IIG) with trajectory feedback. In this setting, players update their policies sequentially based on their observations over a fixed number of episodes, denoted by $T$. Existing procedures suffer from high variance due to the use of importance sampling over sequences of actions (Steinberger et al., 2020; McAleer et al., 2022). To reduce this variance, we consider a fixed sampling approach, where players still update their policies over time, but with observations obtained through a given fixed sampling policy. Our approach is based on an adaptive Online Mirror Descent (OMD) algorithm that applies OMD locally to each information set, using individually decreasing learning rates and a regularized loss. We show that this approach guarantees a convergence rate of $\tilde{\mathcal{O}}(T^{-1/2})$ with high probability and has a near-optimal dependence on the game parameters when applied with the best 
    
[^44]: 对于多维和杂质训练数据的最优血清分类的最小假设：理论和应用

    Minimal Assumptions for Optimal Serology Classification: Theory and Implications for Multidimensional Settings and Impure Training Data. (arXiv:2309.00645v1 [stat.ML])

    [http://arxiv.org/abs/2309.00645](http://arxiv.org/abs/2309.00645)

    本研究提出了一种血清分类的技术，可以在多维和有杂质的训练数据情况下，通过对样本的分类和估计患病率来减少误差。该方法不需要直接访问条件概率密度函数，而是将数据嵌入参数化的曲线空间，并通过最小化经验误差来优化空间。

    

    在血清学中，减少偏差估计和诊断分类器仍然是一个具有挑战性的任务。理论上，这些问题可以转化为建模测量结果的类别-条件概率密度函数（PDFs），它们控制所有后续分析。然而，即使对于仅具有少数维度（例如目标抗原）的测量输出，这个任务也很快受到维度诅咒的影响。为了解决这个问题，我们提出了一种技术，利用经验训练数据在任意维度上分类样本和估计患病率，而不需要直接访问条件PDFs。我们通过一个引理来解释这个方法，该引理将相对条件概率与最小误差分类边界联系起来。这使我们能够制定一个优化问题：（i）将数据嵌入参数化的曲线空间；（ii）根据样本相对于坐标轴的位置对样本进行分类；（iii）通过最小化经验

    Minimizing error in prevalence estimates and diagnostic classifiers remains a challenging task in serology. In theory, these problems can be reduced to modeling class-conditional probability densities (PDFs) of measurement outcomes, which control all downstream analyses. However, this task quickly succumbs to the curse of dimensionality, even for assay outputs with only a few dimensions (e.g. target antigens). To address this problem, we propose a technique that uses empirical training data to classify samples and estimate prevalence in arbitrary dimension without direct access to the conditional PDFs. We motivate this method via a lemma that relates relative conditional probabilities to minimum-error classification boundaries. This leads us to formulate an optimization problem that: (i) embeds the data in a parameterized, curved space; (ii) classifies samples based on their position relative to a coordinate axis; and (iii) subsequently optimizes the space by minimizing the empirical c
    
[^45]: MKL-$L_{0/1}$-SVM: 一种多核学习的支持向量机框架

    MKL-$L_{0/1}$-SVM. (arXiv:2308.12016v1 [stat.ML])

    [http://arxiv.org/abs/2308.12016](http://arxiv.org/abs/2308.12016)

    本文提出了一种多核学习的支持向量机框架(MKL-$L_{0/1}$-SVM)，通过开发快速的ADMM求解器处理非凸非光滑的优化问题，并在实验中展示了与领先方法相当的性能。

    

    本文提出了一种适用于$(0, 1)$损失函数的支持向量机的多核学习（MKL）框架。首先给出了一阶最优性条件，然后利用它们开发了一个快速的ADMM求解器来处理非凸非光滑的优化问题。详细的合成和真实数据集上的实验表明，我们的MKL-$L_{0/1}$-SVM的性能与一种名为SimpleMKL的领先方法相当。

    This paper presents a Multiple Kernel Learning (abbreviated as MKL) framework for the Support Vector Machine (SVM) with the $(0, 1)$ loss function. Some first-order optimality conditions are given and then exploited to develop a fast ADMM solver to deal with the nonconvex and nonsmooth optimization problem. Extensive numerical experiments on synthetic and real datasets show that the performance of our MKL-$L_{0/1}$-SVM is comparable with the one of the leading approaches called SimpleMKL developed by Rakotomamonjy, Bach, Canu, and Grandvalet [Journal of Machine Learning Research, vol. 9, pp. 2491-2521, 2008].
    
[^46]: 有关在有限预算二臂赌博机中进行最佳臂选择的统一最优算法研究

    On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v1 [stat.ML])

    [http://arxiv.org/abs/2308.12000](http://arxiv.org/abs/2308.12000)

    本文研究了在有限预算的随机二臂赌博机中进行最佳臂选择的问题，并证明不存在比等概率采样算法更好的算法。我们引入了一致稳定算法的概念，并证明任何在所有情况下与等概率采样算法表现一样好的算法必须属于这个类别。这一结果解决了之前的两个未解之谜。

    

    本文研究了在具有伯努利奖励的随机二臂赌博机中，使用有限预算进行最佳臂选择的问题。我们证明令人惊讶的是，不存在一个算法可以在所有情况下与等概率采样算法表现一样好（该算法被称为“均匀采样”算法），并且在至少一个情况下明显优于该算法。简而言之，不存在比均匀采样算法更好的算法。为了证明这一结果，我们引入了“一致”和“稳定”算法的自然类，并且证明了任何算法要在所有情况下与均匀采样算法表现一样好，必须属于这个类别。通过导出满足任何一致且稳定算法的错误率的下界，并证明均匀采样算法与此下界相匹配，我们完成了证明过程。我们的结果解决了\cite{qin2022open}中提出的两个未解之谜。

    We study the problem of best-arm identification with fixed budget in stochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly, there is no algorithm that (i) performs as well as the algorithm sampling each arm equally (this algorithm is referred to as the {\it uniform sampling} algorithm) on all instances, and that (ii) strictly outperforms this algorithm on at least one instance. In short, there is no algorithm better than the uniform sampling algorithm. Towards this result, we introduce the natural class of {\it consistent} and {\it stable} algorithms, and show that any algorithm that performs as well as the uniform sampling algorithm on all instances belongs to this class. The proof is completed by deriving a lower bound on the error rate satisfied by any consistent and stable algorithm, and by showing that the uniform sampling algorithm matches this lower bound. Our results provide a solution to the two open problems presented in \cite{qin2022open}.
    
[^47]: 近似等变图网络

    Approximately Equivariant Graph Networks. (arXiv:2308.10436v1 [stat.ML])

    [http://arxiv.org/abs/2308.10436](http://arxiv.org/abs/2308.10436)

    本文关注于图神经网络（GNNs）的主动对称性，通过考虑信号在固定图上的学习设置，提出了一种近似的对称性概念，通过图粗化实现。这篇工作提出了一个偏差-方差公式来衡量近似对称性...

    

    图神经网络（GNNs）通常被描述为对图中的节点重新排序具有置换等变性。GNNs的这种对称性常被与欧几里得卷积神经网络（CNNs）的平移等变性比较。然而，这两种对称性本质上是不同的：CNNs的平移等变性对应于作用于图像信号的固定域的对称性（有时称为主动对称性），而在GNNs中，任何置换都作用于图信号和图域（有时描述为被动对称性）。在这项工作中，我们聚焦于GNNs的主动对称性，考虑信号在一个固定图上进行学习的情况。在这种情况下，GNNs的自然对称性是图的自同构。由于现实世界中的图往往是非对称的，我们通过形式化图粗化来放松对称性的概念，提出了一个偏差-方差公式来衡量...

    Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that qu
    
[^48]: 非平滑非凸优化中随机次梯度方法的收敛性保证

    Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])

    [http://arxiv.org/abs/2307.10053](http://arxiv.org/abs/2307.10053)

    本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。

    

    本文研究了随机梯度下降（SGD）方法及其变种在训练由非平滑激活函数构建的神经网络中的收敛性质。我们提出了一种新颖的框架，为更新动量项和变量的步长分配了不同的时间尺度。在一些温和的条件下，我们证明了我们提出的框架在单时间尺度和双时间尺度情况下的全局收敛性。我们还证明了我们提出的框架包含了很多已知的SGD类型方法，包括heavy-ball SGD、SignSGD、Lion、normalized SGD和clipped SGD。此外，当目标函数采用有限和形式时，我们基于我们提出的框架证明了这些SGD类型方法的收敛性质。特别地，在温和的假设下，我们证明了这些SGD类型方法在随机选择的步长和初始点上能够找到目标函数的Clarke稳定点。

    In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
    
[^49]: 深度网络逼近：从ReLU到多种激活函数

    Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])

    [http://arxiv.org/abs/2307.06555](http://arxiv.org/abs/2307.06555)

    本文研究了深度神经网络在多种激活函数下的表达能力，证明了可以通过在有界集合上构建一个宽度为6N、深度为2L的varrho激活网络来逼近一个宽度为N、深度为L的ReLU网络，从而将对ReLU网络的逼近结果推广到其他激活函数。

    

    本文探究了深度神经网络在多种激活函数下的表达能力。定义了一个激活函数集合A，包括大多数常用的激活函数，如ReLU、LeakyReLU、ReLU^2、ELU、SELU、Softplus、GELU、SiLU、Swish、Mish、Sigmoid、Tanh、Arctan、Softsign、dSiLU和SRS。我们证明了对于任意激活函数varrho∈A，可以通过一个宽度为6N、深度为2L的varrho激活网络在有界集合上以任意精度逼近一个宽度为N、深度为L的ReLU网络。这一发现使得大部分对于ReLU网络的逼近结果能够推广到其他激活函数，尽管需要稍大的常数代价。

    This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
    
[^50]: 内核随机投影深度用于离群点检测

    Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])

    [http://arxiv.org/abs/2306.07056](http://arxiv.org/abs/2306.07056)

    本文提出了一种内核随机投影深度方法，用于处理数据云中的多模式和非凸性，实验结果表明在基准数据集上表现优异。

    

    本文提出了一种扩展的随机投影深度（RPD）方法，用于处理数据云中的多模式和非凸性。在所提出的方法的框架中，RPD在再现核希尔伯特空间中计算。借助内核主成分分析，我们期望所提出的方法可以处理上述多种模式和非凸性。实验结果表明，所提出的方法优于RPD，并可与基准数据集上现有的检测模型相媲美，关于接收操作特征曲线（ROC）下的曲线下面积（AUC）。

    This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
    
[^51]: 基于虚拟粒子随机逼近的可证速限制变种的SVGD算法。

    Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation. (arXiv:2305.17558v1 [stat.ML])

    [http://arxiv.org/abs/2305.17558](http://arxiv.org/abs/2305.17558)

    本论文提出了两种基于虚拟粒子随机逼近的可证速限制变种的SVGD算法，具有可证速的有限粒子收敛率。

    

    Stein变分梯度下降（SVGD）是一种流行的变分推断算法，它模拟相互作用的粒子系统以近似从目标分布中采样，具有各种领域的令人印象深刻的经验性能。在理论上，它的群体（即，无限粒子）极限动力学已经得到了很好的研究，但是SVGD在有限粒子体制下的行为则不太清楚。在这项工作中，我们设计了两种计算效率高的SVGD变体，即VP-SVGD（从概念上讲很优雅）和GB-SVGD（从经验上看很有效），具有可证速的有限粒子收敛率。我们引入了“虚拟粒子”的概念，并在概率测度空间中开发了人口极限SVGD动力学的新型随机逼近方法，它们可以使用有限数量的粒子精确实现。我们的算法可以看作是SVGD的特定随机批处理逼近，比普通方法更具计算效率。

    Stein Variational Gradient Descent (SVGD) is a popular variational inference algorithm which simulates an interacting particle system to approximately sample from a target distribution, with impressive empirical performance across various domains. Theoretically, its population (i.e, infinite-particle) limit dynamics is well studied but the behavior of SVGD in the finite-particle regime is much less understood. In this work, we design two computationally efficient variants of SVGD, namely VP-SVGD (which is conceptually elegant) and GB-SVGD (which is empirically effective), with provably fast finite-particle convergence rates. We introduce the notion of \emph{virtual particles} and develop novel stochastic approximations of population-limit SVGD dynamics in the space of probability measures, which are exactly implementable using a finite number of particles. Our algorithms can be viewed as specific random-batch approximations of SVGD, which are computationally more efficient than ordinar
    
[^52]: 论进化磨锋、平坦极小和泛化

    On progressive sharpening, flat minima and generalisation. (arXiv:2305.14683v1 [cs.LG])

    [http://arxiv.org/abs/2305.14683](http://arxiv.org/abs/2305.14683)

    本文提出了一种用损失黑塞矩阵和输入-输出雅克比矩阵联系起来的假设，量化了模型的输入-输出雅克比矩阵近似其在数据分布上的利普西茨范数的程度，并推导出了一个基于经验雅克比矩阵的新的泛化界，给出了关于进化磨锋和平坦极小的泛化性质的新解释。

    

    我们提出了一种新的方法来理解深度学习中损失曲率与泛化之间的关系。具体来说，我们利用现有的深度网络损失黑塞矩阵频谱经验分析，提出了一个将损失黑塞矩阵和深度神经网络的输入-输出雅克比矩阵联系起来的假设。然后，我们证明了一系列理论结果，量化了模型的输入-输出雅克比矩阵近似其在数据分布上的利普西茨范数的程度，并推导出了一个基于经验雅克比矩阵的新的泛化界。我们利用我们的假设和理论结果，给出了关于最近观察到的进化磨锋现象以及平坦极小的泛化性质的新描述。实验证据验证了我们的主张。

    We present a new approach to understanding the relationship between loss curvature and generalisation in deep learning. Specifically, we use existing empirical analyses of the spectrum of deep network loss Hessians to ground an ansatz tying together the loss Hessian and the input-output Jacobian of a deep neural network. We then prove a series of theoretical results which quantify the degree to which the input-output Jacobian of a model approximates its Lipschitz norm over a data distribution, and deduce a novel generalisation bound in terms of the empirical Jacobian. We use our ansatz, together with our theoretical results, to give a new account of the recently observed progressive sharpening phenomenon, as well as the generalisation properties of flat minima. Experimental evidence is provided to validate our claims.
    
[^53]: 针对大规模高斯过程回归和统计有限元分析的随机PDE表示随机场

    Stochastic PDE representation of random fields for large-scale Gaussian process regression and statistical finite element analysis. (arXiv:2305.13879v1 [math.NA])

    [http://arxiv.org/abs/2305.13879](http://arxiv.org/abs/2305.13879)

    本文针对工程学和机器学习中的贝叶斯建模，使用随机PDE表示来开发一种可扩展的框架，从而可以在几何复杂的域上进行大规模的统计有限元分析和高斯过程回归。

    

    在工程学和机器学习的贝叶斯建模中，有效表示几何复杂域上的随机场至关重要。当前普遍使用的随机场表示仅限于无界域或在可能的场属性方面过于受限。因此，利用随机PDE与随机场之间的历史联系的新技术对于具有复杂几何形状和存在有限元离散化用于求解物理守恒方程的工程应用尤为吸引人。与随机场的密集协方差矩阵不同，其逆矩阵--精度矩阵通常是稀疏的，并等于类似Helmholtz的随机PDE的刚度矩阵。在本文中，我们使用SPDE表示来开发可扩展的框架，用于在几何复杂域上进行大规模的统计有限元分析（StatFEM）和高斯过程（GP）回归。我们使用SPDE公式

    The efficient representation of random fields on geometrically complex domains is crucial for Bayesian modelling in engineering and machine learning. Today's prevalent random field representations are restricted to unbounded domains or are too restrictive in terms of possible field properties. As a result, new techniques leveraging the historically established link between stochastic PDEs (SPDEs) and random fields are especially appealing for engineering applications with complex geometries which already have a finite element discretisation for solving the physical conservation equations. Unlike the dense covariance matrix of a random field, its inverse, the precision matrix, is usually sparse and equal to the stiffness matrix of a Helmholtz-like SPDE. In this paper, we use the SPDE representation to develop a scalable framework for large-scale statistical finite element analysis (statFEM) and Gaussian process (GP) regression on geometrically complex domains. We use the SPDE formulatio
    
[^54]: 从随机搜索到度量测度空间中的赌博学习

    From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])

    [http://arxiv.org/abs/2305.11509](http://arxiv.org/abs/2305.11509)

    本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。

    

    随机搜索是超参数优化中最常用的方法之一，对于深度学习模型的成功至关重要。尽管其性能令人惊叹，但很少有非启发式的理论用于描述其工作机制。本文给出了关于随机搜索的理论解释。我们引入了“散射维度”的概念，描述了底层函数的状态，并量化了随机搜索的性能。我们表明，当环境没有噪声时，随机搜索的输出以概率收敛到最优值，其速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $，其中$ d_s \ge 0 $是底层函数的散射维度。当观察到的函数值受到有界的独立同分布噪声影响时，随机搜索的输出以概率收敛到最优值，速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $。

    Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
    
[^55]: 缺失值下的相关性可视化：填充法和直接参数估计法的比较

    Correlation visualization under missing values: a comparison between imputation and direct parameter estimation methods. (arXiv:2305.06044v1 [cs.LG])

    [http://arxiv.org/abs/2305.06044](http://arxiv.org/abs/2305.06044)

    本文比较了不同的缺失数据处理方法对相关图的影响，建议使用直接参数估计法(DPER)来绘制相关图

    

    相关矩阵可视化对于理解数据集中变量之间的关系至关重要，但是缺失数据会对相关系数的估计产生显著挑战。本文比较了不同的缺失数据处理方法对相关图的影响，重点关注两种常见的缺失模式：随机和单调。我们旨在为研究人员和实践者提供实用的策略和建议，以创建和分析相关图。我们的实验结果表明，虽然填充法通常用于缺失数据，但使用填充的数据来生成相关矩阵图可能会导致对特征之间关系的误导性推断。我们建议基于其在实验中的表现，使用DPER，一种直接参数估计方法，绘制相关矩阵图。

    Correlation matrix visualization is essential for understanding the relationships between variables in a dataset, but missing data can pose a significant challenge in estimating correlation coefficients. In this paper, we compare the effects of various missing data methods on the correlation plot, focusing on two common missing patterns: random and monotone. We aim to provide practical strategies and recommendations for researchers and practitioners in creating and analyzing the correlation plot. Our experimental results suggest that while imputation is commonly used for missing data, using imputed data for plotting the correlation matrix may lead to a significantly misleading inference of the relation between the features. We recommend using DPER, a direct parameter estimation approach, for plotting the correlation matrix based on its performance in the experiments.
    
[^56]: 无监督深度学习中基于非线性独立成分分析的原则分离问题

    Nonlinear Independent Component Analysis for Principled Disentanglement in Unsupervised Deep Learning. (arXiv:2303.16535v1 [cs.LG])

    [http://arxiv.org/abs/2303.16535](http://arxiv.org/abs/2303.16535)

    本文概括了无监督深度学习中基于独立成分分析方法的最新发展，特别是对于解决非线性情况下唯一性问题提出了可识别的扩展方法。

    

    在无监督深度学习中，如何找到有用的高维数据表示，即所谓的“分离”问题至关重要。大多数方法都是启发式的，缺乏适当的理论基础。在线性表示学习中，独立成分分析（ICA）在许多应用领域取得了成功，并且具有基于良定义的概率模型的原则性。 然而，将ICA扩展到非线性情况已经成为一个棘手的问题，这是由于缺乏可识别性，即表示的唯一性。最近，已经提出了使用时间结构或某些辅助信息的非线性扩展。这些模型实际上是可识别的，因此已经开发出越来越多的算法。特别是一些自监督算法可以显示出估计非线性ICA，即使最初是从启发式角度提出的。本文总结了非线性ICA的最新进展。

    A central problem in unsupervised deep learning is how to find useful representations of high-dimensional data, sometimes called "disentanglement". Most approaches are heuristic and lack a proper theoretical foundation. In linear representation learning, independent component analysis (ICA) has been successful in many applications areas, and it is principled, i.e. based on a well-defined probabilistic model. However, extension of ICA to the nonlinear case has been problematic due to the lack of identifiability, i.e. uniqueness of the representation. Recently, nonlinear extensions that utilize temporal structure or some auxiliary information have been proposed. Such models are in fact identifiable, and consequently, an increasing number of algorithms have been developed. In particular, some self-supervised algorithms can be shown to estimate nonlinear ICA, even though they have initially been proposed from heuristic perspectives. This paper reviews the state-of-the-art of nonlinear ICA 
    
[^57]: 高维函数回归中特征选择和估计的一种高效自适应方法--FAStEN

    FAStEN: an efficient adaptive method for feature selection and estimation in high-dimensional functional regressions. (arXiv:2303.14801v1 [stat.ME])

    [http://arxiv.org/abs/2303.14801](http://arxiv.org/abs/2303.14801)

    提出了一种新的自适应方法FAStEN，用于在高维函数回归问题中执行特征选择和参数估计，通过利用函数主成分和对偶增广Lagrangian问题的稀疏性质，具有显著的计算效率和选择准确性。

    

    函数回归分析是许多当代科学应用的已建立工具。涉及大规模和复杂数据集的回归问题是普遍存在的，特征选择对于避免过度拟合和实现准确预测至关重要。我们提出了一种新的、灵活的、超高效的方法，用于在稀疏高维函数回归问题中执行特征选择，并展示了如何将其扩展到标量对函数框架中。我们的方法将函数数据、优化和机器学习技术相结合，以同时执行特征选择和参数估计。我们利用函数主成分的特性以及对偶增广Lagrangian问题的稀疏性质，显著降低了计算成本，并引入了自适应方案来提高选择准确性。通过广泛的模拟研究，我们将我们的方法与最佳现有竞争对手进行了基准测试，并证明了我们的方法的高效性。

    Functional regression analysis is an established tool for many contemporary scientific applications. Regression problems involving large and complex data sets are ubiquitous, and feature selection is crucial for avoiding overfitting and achieving accurate predictions. We propose a new, flexible, and ultra-efficient approach to perform feature selection in a sparse high dimensional function-on-function regression problem, and we show how to extend it to the scalar-on-function framework. Our method combines functional data, optimization, and machine learning techniques to perform feature selection and parameter estimation simultaneously. We exploit the properties of Functional Principal Components, and the sparsity inherent to the Dual Augmented Lagrangian problem to significantly reduce computational cost, and we introduce an adaptive scheme to improve selection accuracy. Through an extensive simulation study, we benchmark our approach to the best existing competitors and demonstrate a 
    
[^58]: 可证收敛的即插即用拟牛顿方法

    Provably Convergent Plug-and-Play Quasi-Newton Methods. (arXiv:2303.07271v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2303.07271](http://arxiv.org/abs/2303.07271)

    本文提出了一种可证明收敛的PnP方法，使用拟牛顿步骤以加速收敛，相对于现有的PnP方法对去噪器或保真度函数施加了较轻的限制。

    

    即插即用（PnP）方法是一类高效的迭代算法，旨在利用经典优化算法（如ISTA或ADMM），将数据保真度项和深度去噪器相结合。现有的可证明的PnP方法对去噪器或保真度函数施加了严格的限制，如非扩张性或严格凸性。本文提出了一种可证明的PnP方法，该方法基于近端去噪器施加相对较轻的条件，并引入了拟牛顿步骤以大大加速收敛。通过将深度去噪器特别参数化为梯度步骤，我们进一步将拟牛顿PnP算法的固定点表征为可能非凸函数的临界点。

    Plug-and-Play (PnP) methods are a class of efficient iterative methods that aim to combine data fidelity terms and deep denoisers using classical optimization algorithms, such as ISTA or ADMM. Existing provable PnP methods impose heavy restrictions on the denoiser or fidelity function, such as nonexpansiveness or strict convexity. In this work, we propose a provable PnP method that imposes relatively light conditions based on proximal denoisers, and introduce a quasi-Newton step to greatly accelerate convergence. By specially parameterizing the deep denoiser as a gradient step, we further characterize the fixed-points of the quasi-Newton PnP algorithm as critical points of a possibly non-convex function.
    
[^59]: 表现不足以为盈，深究Rashomon的四重奏

    Performance is not enough: a story of the Rashomon's quartet. (arXiv:2302.13356v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.13356](http://arxiv.org/abs/2302.13356)

    本文介绍了Rashomon的四重奏，这是一个合成数据集，其中来自不同类别的四个模型具有几乎相同的预测性能，同时其可视化揭示了极其不同的方法来理解数据中的相关性结构。

    

    预测建模通常被简化为寻找最优模型来优化选定的性能度量。但如果第二优模型能够以完全不同的方式同样描述数据呢？第三个模型呢？最有效的模型会学到完全不同的数据关系吗？受到Anscombe四重奏的启发，本文介绍了Rashomon的四重奏，这是一个合成数据集，其中来自不同类别的四个模型具有几乎相同的预测性能。然而，它们的可视化揭示了极其不同的方法来理解数据中的相关性结构。引入的简单示例旨在进一步促进可视化作为比较预测模型超越性能的必要工具。我们需要开发富有洞察力的技术来解释模型集。

    Predictive modelling is often reduced to finding the best model that optimizes a selected performance measure. But what if the second-best model describes the data equally well but in a completely different way? What about the third? Is it possible that the most effective models learn completely different relationships in the data? Inspired by Anscombe's quartet, this paper introduces Rashomon's quartet, a synthetic dataset for which four models from different classes have practically identical predictive performance. However, their visualization reveals drastically distinct ways of understanding the correlation structure in data. The introduced simple illustrative example aims to further facilitate visualization as a mandatory tool to compare predictive models beyond their performance. We need to develop insightful techniques for the explanatory analysis of model sets.
    
[^60]: 以(小)结构突破下界：具有重尾噪声的非凸随机优化中的加速。(arXiv:2302.06763v2 [cs.LG] 更新)

    Breaking the Lower Bound with (Little) Structure: Acceleration in Non-Convex Stochastic Optimization with Heavy-Tailed Noise. (arXiv:2302.06763v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06763](http://arxiv.org/abs/2302.06763)

    本论文在具有重尾噪声的非凸随机优化问题中，改进了Cutkosky和Mehta的算法，并提供了近乎最优的收敛保证，而无需对随机梯度的矩条件进行额外的假设。

    

    在重尾噪声区域中，我们考虑具有平滑但不一定是凸目标的随机优化问题，其中假设随机梯度的噪声具有有界的$p$阶矩($p\in(1,2]$)。Zhang等人(2020)首次证明了收敛的$\Omega(T^{\frac{1-p}{3p-2}})$下界，并提供了一个简单的剪切算法，以匹配这个最优速率。Cutkosky和Mehta(2021)提出了另一种算法，该算法被证明能够实现近乎最优的高概率收敛保证$O(\log(T/\delta)T^{\frac{1-p}{3p-2}})$，其中$\delta$是失败的概率。然而，这个理想的保证只在附加的假设下成立，即随机梯度本身在$p$阶矩上有界，而即使对于二次目标和中心化的高斯噪声，这个假设也不成立。在这项工作中，我们首先改进了Cutkosky和Mehta(2021)中算法的分析，以获得相同的近乎最优结果。

    We consider the stochastic optimization problem with smooth but not necessarily convex objectives in the heavy-tailed noise regime, where the stochastic gradient's noise is assumed to have bounded $p$th moment ($p\in(1,2]$). Zhang et al. (2020) is the first to prove the $\Omega(T^{\frac{1-p}{3p-2}})$ lower bound for convergence (in expectation) and provides a simple clipping algorithm that matches this optimal rate. Cutkosky and Mehta (2021) proposes another algorithm, which is shown to achieve the nearly optimal high-probability convergence guarantee $O(\log(T/\delta)T^{\frac{1-p}{3p-2}})$, where $\delta$ is the probability of failure. However, this desirable guarantee is only established under the additional assumption that the stochastic gradient itself is bounded in $p$th moment, which fails to hold even for quadratic objectives and centered Gaussian noise.  In this work, we first improve the analysis of the algorithm in Cutkosky and Mehta (2021) to obtain the same nearly optimal h
    
[^61]: Distributional Random Forests 的置信度和不确定性评估

    Confidence and Uncertainty Assessment for Distributional Random Forests. (arXiv:2302.05761v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2302.05761](http://arxiv.org/abs/2302.05761)

    Distributional Random Forests算法通过对条件分布进行估计，提供了一种量化标准误差和构建置信区间的推理工具，用于估计多变量条件分布和测试不同群体之间的分布差异。

    

    Distributional Random Forest (DRF) 是一种最近引入的随机森林算法，用于估计多变量条件分布。由于其通用的估计过程，可以用来估计各种目标，如条件平均处理效应、条件分位数和条件相关性。然而，目前只有关于DRF预测的一致性和收敛速率的结果可用。我们对DRF的渐近分布进行了表征，并开发了其的自助法近似。这使我们能够推导出用于量化标准误差和构建渐进覆盖保证的置信区间的推理工具。在模拟研究中，我们经验证明了该理论对于低维目标的推理和测试两个群体之间的分布差异是有效的。

    The Distributional Random Forest (DRF) is a recently introduced Random Forest algorithm to estimate multivariate conditional distributions. Due to its general estimation procedure, it can be employed to estimate a wide range of targets such as conditional average treatment effects, conditional quantiles, and conditional correlations. However, only results about the consistency and convergence rate of the DRF prediction are available so far. We characterize the asymptotic distribution of DRF and develop a bootstrap approximation of it. This allows us to derive inferential tools for quantifying standard errors and the construction of confidence regions that have asymptotic coverage guarantees. In simulation studies, we empirically validate the developed theory for inference of low-dimensional targets and for testing distributional differences between two populations.
    
[^62]: 一个强化学习框架用于动态中介分析

    A Reinforcement Learning Framework for Dynamic Mediation Analysis. (arXiv:2301.13348v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.13348](http://arxiv.org/abs/2301.13348)

    这项研究提出了一个强化学习框架，首次评估了在无限时间范围内的动态中介效应，并开发了鲁棒和半参数有效的估计方法来推断这些因果效应。

    

    中介分析通过学习介导变量在治疗和结果之间传递的因果效应，在各个科学领域中受到越来越多的关注，以阐明因果关系。大多数现有研究集中在点暴露研究中，其中每个受试者只在一个时间点接受一种治疗。然而，有许多应用（例如移动健康）在这些应用中，治疗是按顺序分配的，动态中介效应是主要关注的对象。通过提出一个强化学习（RL）框架，我们首次评估在无限时间范围内的动态中介效应。我们将平均治疗效应分解为直接效应、中介效应、延迟直接效应和延迟中介效应。在确定每个效应成分后，我们进一步在RL框架下开发鲁棒和半参数有效的估计器来推断这些因果效应。

    Mediation analysis learns the causal effect transmitted via mediator variables between treatments and outcomes and receives increasing attention in various scientific domains to elucidate causal relations. Most existing works focus on point-exposure studies where each subject only receives one treatment at a single time point. However, there are a number of applications (e.g., mobile health) where the treatments are sequentially assigned over time and the dynamic mediation effects are of primary interest. Proposing a reinforcement learning (RL) framework, we are the first to evaluate dynamic mediation effects in settings with infinite horizons. We decompose the average treatment effect into an immediate direct effect, an immediate mediation effect, a delayed direct effect, and a delayed mediation effect. Upon the identification of each effect component, we further develop robust and semi-parametrically efficient estimators under the RL framework to infer these causal effects. The super
    
[^63]: 你是否正确使用了测试对数似然？

    Are you using test log-likelihood correctly?. (arXiv:2212.00219v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.00219](http://arxiv.org/abs/2212.00219)

    使用测试对数似然进行比较可能与其他指标相矛盾，并且高测试对数似然不意味着更准确的后验近似。

    

    测试对数似然常被用来比较不同模型的同一数据，或者比较拟合同一概率模型的不同近似推断算法。我们通过简单的例子展示了如何基于测试对数似然的比较可能与其他目标相矛盾。具体来说，我们的例子表明：（i）达到更高测试对数似然的近似贝叶斯推断算法不必意味着能够产生更准确的后验近似，（ii）基于测试对数似然比较的预测准确性结论可能与基于均方根误差的结论不一致。

    Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.
    
[^64]: 统计算法的PAC验证

    PAC Verification of Statistical Algorithms. (arXiv:2211.17096v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.17096](http://arxiv.org/abs/2211.17096)

    本文介绍了PAC验证的概念，并在三个方面进行了进一步的研究：对于VC维度为$d$的假设类，PAC验证需要$\Omega\left(\sqrt{d}/\varepsilon^2\right)$个i.i.d.样本的下界；提出了一种用于验证实数区间的并集的协议，并与下界对$d$的依赖相匹配；将PAC验证的定义推广到对一般统计算法的验证。

    

    Goldwasser等人（2021）最近提出了PAC验证的设置，其中使用交互式证明来验证假设（机器学习模型），该模型声称满足无知PAC学习目标。本文在多个方面进一步发展了这个概念。首先，我们证明了对于VC维度为$d$的假设类，PAC验证需要$\Omega\left(\sqrt{d}/\varepsilon^2\right)$个i.i.d.样本的下界。其次，我们提出了一个用于PAC验证实数区间的并集的协议，该协议改进了他们提出的协议，并与我们的下界对$d$的依赖相匹配。第三，我们将他们的定义自然推广到了对一般统计算法的验证，这适用于更广泛的领域，超出了无知PAC学习的范畴。通过展示我们提出的定义，我们的最终结果是一种验证具有组合约束的统计查询算法的协议。

    Goldwasser et al. (2021) recently proposed the setting of PAC verification, where a hypothesis (machine learning model) that purportedly satisfies the agnostic PAC learning objective is verified using an interactive proof. In this paper we develop this notion further in a number of ways. First, we prove a lower bound of $\Omega\left(\sqrt{d}/\varepsilon^2\right)$ i.i.d.\ samples for PAC verification of hypothesis classes of VC dimension $d$. Second, we present a protocol for PAC verification of unions of intervals over $\mathbb{R}$ that improves upon their proposed protocol for that task, and matches our lower bound's dependence on $d$. Third, we introduce a natural generalization of their definition to verification of general statistical algorithms, which is applicable to a wider variety of settings beyond agnostic PAC learning. Showcasing our proposed definition, our final result is a protocol for the verification of statistical query algorithms that satisfy a combinatorial constrain
    
[^65]: 机器学习在药物基因组学中的应用：血浆浓度-时间曲线的聚类

    Applications of Machine Learning in Pharmacogenomics: Clustering Plasma Concentration-Time Curves. (arXiv:2210.13310v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2210.13310](http://arxiv.org/abs/2210.13310)

    该论文介绍了应用机器学习对药物动力学曲线进行聚类的方法，发现聚类能够有效地识别相似形状的药物动力学曲线并理解每个聚类中的模式，为药物研发和药物治疗过程提供了新的技术支持。

    

    制药研究人员不断寻求技术改进药物开发过程和患者预后的方法。最近一个受到关注的领域是机器学习在药理学中的潜在应用。本文介绍了如何通过相似性对血浆浓度-时间曲线（药物动力学曲线）进行聚类的发现。具体而言，我们发现聚类对于识别相似形状的药物动力学曲线以及理解每个聚类内的模式非常有效。由于药物动力学曲线是时间序列数据对象，我们的方法利用了与时间序列数据聚类相关的大量研究作为起点。因此，我们检查了许多时间序列数据对象之间的不相似度度量，以找到最适合药物动力学曲线的度量。我们确定欧几里德距离通常是最适合的。

    Pharmaceutical researchers are continually searching for techniques to improve both drug development processes and patient outcomes. An area of recent interest is the potential for machine learning (ML) applications within pharmacology. One such application not yet given close study is the unsupervised clustering of plasma concentration-time curves, hereafter, pharmacokinetic (PK) curves. In this paper, we present our findings on how to cluster PK curves by their similarity. Specifically, we find clustering to be effective at identifying similar-shaped PK curves and informative for understanding patterns within each cluster of PK curves. Because PK curves are time series data objects, our approach utilizes the extensive body of research related to the clustering of time series data as a starting point. As such, we examine many dissimilarity measures between time series data objects to find those most suitable for PK curves. We identify Euclidean distance as generally most appropriate f
    
[^66]: 线性回归系数的异常鲁棒稀疏估计

    Outlier Robust and Sparse Estimation of Linear Regression Coefficients. (arXiv:2208.11592v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2208.11592](http://arxiv.org/abs/2208.11592)

    本文介绍了一种异常鲁棒稀疏估计方法，可用于线性回归系数的协方差矩阵已知或未知的情况下，具有较尖锐的误差界，适用于采样自$\mathfrak{L}$-subGaussian分布和重尾分布的协变量向量和噪声。

    

    我们考虑当协变量向量和噪声分别从$\mathfrak{L}$-subGaussian分布和重尾分布中随机采样时，对线性回归系数进行异常鲁棒稀疏估计。此外，协变量向量和噪声受到对抗性异常值的污染。我们处理两种情况：协变量的协方差矩阵已知或未知。特别地，在已知情况下，我们的估计器可以达到近似信息理论最优的误差界，且我们的误差界比早期处理类似情况的研究更加尖锐。我们的估计器分析在推导尖锐的误差界方面严重依赖于通用链。

    We consider outlier-robust and sparse estimation of linear regression coefficients, when covariate vectors and noises are sampled, respectively, from an $\mathfrak{L}$-subGaussian distribution and a heavy-tailed distribution. Additionally, the covariate vectors and noises are contaminated by adversarial outliers. We deal with two cases: the covariance matrix of the covariates is known or unknown. Particularly, in the known case, our estimator can attain a nearly information theoretical optimal error bound, and our error bound is sharper than those of earlier studies dealing with similar situations. Our estimator analysis relies heavily on generic chaining to derive sharp error bounds.
    
[^67]: 使用机器学习处理观测网络数据的治疗效果估计

    Treatment Effect Estimation with Observational Network Data using Machine Learning. (arXiv:2206.14591v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2206.14591](http://arxiv.org/abs/2206.14591)

    该论文开发了增广逆概率加权（AIPW）方法，用于使用观测网络数据估计和推断具有溢出效应的治疗的直接效应。方法使用机器学习和样本分割，得到收敛速度较快且服从高斯分布的半参数治疗效果估计器。研究发现，在考虑学生社交网络的情况下，学习时间对考试成绩有影响。

    

    因果推断方法通常假设独立单元来进行治疗效果估计。然而，这种假设经常是有问题的，因为单元之间可能会相互作用，导致单元之间的溢出效应。我们开发了增广逆概率加权（AIPW）方法，用于使用具有溢出效应的单个（社交）网络的观测数据对治疗的直接效应进行估计和推断。我们使用基于插件的机器学习和样本分割方法，得到一个半参数的治疗效果估计器，其渐近收敛于参数速率，并且在渐近情况下服从高斯分布。我们将AIPW方法应用于瑞士学生人生研究数据，以研究学习时间对考试成绩的影响，考虑到学生的社交网络。

    Causal inference methods for treatment effect estimation usually assume independent units. However, this assumption is often questionable because units may interact, resulting in spillover effects between units. We develop augmented inverse probability weighting (AIPW) for estimation and inference of the direct effect of the treatment with observational data from a single (social) network with spillover effects. We use plugin machine learning and sample splitting to obtain a semiparametric treatment effect estimator that converges at the parametric rate and asymptotically follows a Gaussian distribution. We apply our AIPW method to the Swiss StudentLife Study data to investigate the effect of hours spent studying on exam performance accounting for the students' social network.
    
[^68]: 个体隐私会计对差分隐私随机梯度下降的影响

    Individual Privacy Accounting for Differentially Private Stochastic Gradient Descent. (arXiv:2206.02617v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02617](http://arxiv.org/abs/2206.02617)

    本文研究了通过差分隐私随机梯度下降训练的模型对个体示例的隐私保证，并发现大多数示例享有较强的隐私保证。此外，我们还发现训练损失和示例的隐私参数存在很强的相关性。最低准确率类别的平均隐私参数比最高准确率类别高44.2%。

    

    差分隐私随机梯度下降是最近私有深度学习的前沿算法。它为数据集中的所有数据点提供了单一的隐私保证。我们提出了针对个例的输出特定$(\varepsilon,\delta)$-DP，以刻画通过DP-SGD训练的模型对个别示例的隐私保证。我们还设计了一种高效算法来研究跨多个数据集的个体隐私。我们发现大多数示例都享有比最坏情况边界更强的隐私保证。我们进一步发现训练损失和示例的隐私参数之间存在很强的相关性。这意味着在模型效用方面受到不足的群体同时经历较弱的隐私保证。例如，在CIFAR-10上，最低测试准确率类别的平均$\varepsilon$比最高准确率类别高44.2%。

    Differentially private stochastic gradient descent (DP-SGD) is the workhorse algorithm for recent advances in private deep learning. It provides a single privacy guarantee to all datapoints in the dataset. We propose output-specific $(\varepsilon,\delta)$-DP to characterize privacy guarantees for individual examples when releasing models trained by DP-SGD. We also design an efficient algorithm to investigate individual privacy across a number of datasets. We find that most examples enjoy stronger privacy guarantees than the worst-case bound. We further discover that the training loss and the privacy parameter of an example are well-correlated. This implies groups that are underserved in terms of model utility simultaneously experience weaker privacy guarantees. For example, on CIFAR-10, the average $\varepsilon$ of the class with the lowest test accuracy is 44.2\% higher than that of the class with the highest accuracy.
    
[^69]: 基于生成网络的降阶模型用于预测、数据同化和不确定性量化

    Generative Network-Based Reduced-Order Model for Prediction, Data Assimilation and Uncertainty Quantification. (arXiv:2105.13859v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.13859](http://arxiv.org/abs/2105.13859)

    该论文提出了一种基于生成网络的降阶模型，用于解决偏微分方程的逆问题。通过使用无条件模拟进行训练，该模型可以有效量化不确定性，并准确匹配测量数据和黄金标准。

    

    我们提出了一种新的方法，该方法将生成网络（GN）整合到降阶模型（ROM）框架中，用于解决偏微分方程（PDE）的逆问题。目标是匹配可用的测量数据，并估计数值物理模拟的状态和参数的相应不确定性。GN仅使用离散化的PDE模型的无条件模拟进行训练。我们将所提出的方法与黄金标准马尔可夫链蒙特卡罗方法进行了比较。我们将所提出的方法应用于流行病学中的时空隔室模型。结果表明，基于GN的降阶模型能够有效量化不确定性，并且仅使用少量无条件模拟的全阶数值PDE模型即可准确匹配测量数据和黄金标准。

    We propose a new method in which a generative network (GN) integrate into a reduced-order model (ROM) framework is used to solve inverse problems for partial differential equations (PDE). The aim is to match available measurements and estimate the corresponding uncertainties associated with the states and parameters of a numerical physical simulation. The GN is trained using only unconditional simulations of the discretized PDE model. We compare the proposed method with the golden standard Markov chain Monte Carlo. We apply the proposed approaches to a spatio-temporal compartmental model in epidemiology. The results show that the proposed GN-based ROM can efficiently quantify uncertainty and accurately match the measurements and the golden standard, using only a few unconditional simulations of the full-order numerical PDE model.
    
[^70]: 一种用于异步Q学习和TD学习变种的有限样本保证的Lyapunov理论

    A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous Q-Learning and TD-Learning Variants. (arXiv:2102.01567v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.01567](http://arxiv.org/abs/2102.01567)

    本文提出了一种统一的框架来研究异步强化学习算法的有限样本收敛保证，并基于Lyapunov分析建立了异步RL算法的均方误差界限。通过对n步TD和TD（λ）的收敛界限的分析，揭示了强化学习中引导技巧效率的理论洞见。

    

    本文通过首先将强化学习算法重新表述为解决固定点方程的"Markovian Stochastic Approximation"(SA)算法，发展了一个统一的框架来研究基于值的异步强化学习算法的有限样本收敛保证。然后，我们使用Lyapunov分析推导出Markovian SA的均方误差界限，基于此结果，我们建立了异步强化学习算法（如Q学习，n步TD，TD（λ）和包括V-trace的离策略TD算法）的有限样本均方收敛界限。作为副产品，通过分析n步TD和TD（λ）的收敛界限，我们提供了关于强化学习中引导技巧效率（即偏差-方差权衡）的理论洞见，这是(Sutton, 1999)中首次提出的一个开放性问题。

    This paper develops an unified framework to study finite-sample convergence guarantees of a large class of value-based asynchronous reinforcement learning (RL) algorithms. We do this by first reformulating the RL algorithms as \textit{Markovian Stochastic Approximation} (SA) algorithms to solve fixed-point equations. We then develop a Lyapunov analysis and derive mean-square error bounds on the convergence of the Markovian SA. Based on this result, we establish finite-sample mean-square convergence bounds for asynchronous RL algorithms such as $Q$-learning, $n$-step TD, TD$(\lambda)$, and off-policy TD algorithms including V-trace. As a by-product, by analyzing the convergence bounds of $n$-step TD and TD$(\lambda)$, we provide theoretical insights into the bias-variance trade-off, i.e., efficiency of bootstrapping in RL. This was first posed as an open problem in (Sutton, 1999).
    
[^71]: $\ell_1$-范数是否能够在受限Laplacian图模型下学习稀疏图形？

    Does the $\ell_1$-norm Learn a Sparse Graph under Laplacian Constrained Graphical Models?. (arXiv:2006.14925v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.14925](http://arxiv.org/abs/2006.14925)

    本文研究了在受限Laplacian图模型下学习稀疏图的问题。我们发现经典的$\ell_1$-范数正则化无法有效实现稀疏解，并提出了一种非凸稀疏惩罚的方法来解决这个问题。

    

    我们考虑在受限Laplacian高斯图模型下学习稀疏图的问题。该问题可以被表示为拉普拉斯约束下的精度矩阵的惩罚最大似然估计。与经典的图形套索问题类似，最近的研究利用了$\ell_1$-范数正则化来促进在拉普拉斯约束精度矩阵估计中的稀疏性。然而，我们发现广泛应用的$\ell_1$-范数在这个问题中无法有效地实现稀疏解。通过经验证据，我们观察到非零图权重的数量随着正则化参数的增加而增加。从理论上来看，我们证明了较大的正则化参数将引发一个意外的完全图，即每对顶点之间都用边连接。为了解决这个问题，我们引入非凸稀疏惩罚，并通过求解一系列加权$\ell_1$-范数得到了一个新的估计器。

    We consider the problem of learning a sparse graph under the Laplacian constrained Gaussian graphical models. This problem can be formulated as a penalized maximum likelihood estimation of the Laplacian constrained precision matrix. Like in the classical graphical lasso problem, recent works made use of the $\ell_1$-norm regularization with the goal of promoting sparsity in Laplacian constrained precision matrix estimation. However, we find that the widely used $\ell_1$-norm is not effective in imposing a sparse solution in this problem. Through empirical evidence, we observe that the number of nonzero graph weights grows with the increase of the regularization parameter. From a theoretical perspective, we prove that a large regularization parameter will surprisingly lead to a complete graph, i.e., every pair of vertices is connected by an edge. To address this issue, we introduce the nonconvex sparsity penalty, and propose a new estimator by solving a sequence of weighted $\ell_1$-nor
    
[^72]: 双重鲁棒性函数的选择性机器学习研究

    Selective machine learning of doubly robust functionals. (arXiv:1911.02029v6 [stat.ME] UPDATED)

    [http://arxiv.org/abs/1911.02029](http://arxiv.org/abs/1911.02029)

    本文提出了一种选择性机器学习框架，用于在半参数问题中选择可能高维的干扰参数，并对双重鲁棒性函数进行推断。通过引入新的选择标准和伪风险定义，降低了估计所提函数中的偏差，并且具有理想性质。

    

    虽然参数和非参数回归或密度估计中的模型选择是一个研究充分的主题，但在半参数问题中选择可能高维的干扰参数则较少研究。本文提出了一种选择性机器学习框架，用于对一个半参数模型上定义的有限维函数进行推断，当后者具有双重鲁棒的估计函数，并有多个候选的机器学习算法可用于估计干扰参数。我们引入了一种新的选择标准，旨在通过一种新颖的伪风险定义来降低估计所提函数中的偏差，该定义受到双重鲁棒性质的启发。直观地说，所提出的标准选择了具有最小伪风险的一对学习器，以使估计的函数对干扰参数的扰动最不敏感。我们为多重交叉验证版本的方法证明了理想性质。

    While model selection is a well-studied topic in parametric and nonparametric regression or density estimation, selection of possibly high-dimensional nuisance parameters in semiparametric problems is far less developed. In this paper, we propose a selective machine learning framework for making inferences about a finite-dimensional functional defined on a semiparametric model, when the latter admits a doubly robust estimating function and several candidate machine learning algorithms are available for estimating the nuisance parameters. We introduce a new selection criterion aimed at bias reduction in estimating the functional of interest based on a novel definition of pseudo-risk inspired by the double robustness property. Intuitively, the proposed criterion selects a pair of learners with the smallest pseudo-risk, so that the estimated functional is least sensitive to perturbations of a nuisance parameter. We establish an oracle property for a multi-fold cross-validation version of 
    

