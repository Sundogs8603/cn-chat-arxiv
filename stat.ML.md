# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach.](http://arxiv.org/abs/2401.13665) | 本研究提出了一种在面板数据中进行因果推断的简单且最佳化的方法，通过简单的矩阵代数和奇异值分解来实现高效计算。通过导出非渐近界限，我们证明了逐项误差与高斯变量的适当缩放具有接近性。同时，我们还开发了一个数据驱动程序，用于构建具有预先指定覆盖保证的逐项置信区间。 |
| [^2] | [Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint.](http://arxiv.org/abs/2401.13624) | 过拟合的深度神经网络在对抗训练中能够泛化，而且可以通过合适的条件获得良好的鲁棒泛化性能。 |
| [^3] | [Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?.](http://arxiv.org/abs/2401.13544) | 本文介绍了一种超越概念瓶颈模型的方法，可以使黑盒模型可干预。通过基于概念的干预来影响模型的输出，并利用这种方法对黑盒模型进行微调。实验证明，微调可以提高干预的效果，并产生更好校准的预测。 |
| [^4] | [Full Bayesian Significance Testing for Neural Networks.](http://arxiv.org/abs/2401.13335) | 该论文提出了一种全贝叶斯神经网络显著性检验方法（nFBST），通过利用贝叶斯神经网络拟合非线性和多维关系，并计算证据值来替代传统方法中的理论推导，该方法能够测试全局、局部和实例级的显著性。 |
| [^5] | [An Explicit Scheme for Pathwise XVA Computations.](http://arxiv.org/abs/2401.13314) | 本论文介绍了一种显式的路径XVA计算方案，使用模拟/回归方法处理交叉估值调整（XVA）方程，并证明了该方案在高维和混合风险XVA用例中的优势。 |
| [^6] | [Quantum natural gradient without monotonicity.](http://arxiv.org/abs/2401.13237) | 本文提出了一种新的量子自然梯度方法，去除了单调性条件，通过提供理论和数值证据来支持该方法的有效性。 |
| [^7] | [On Principled Local Optimization Methods for Federated Learning.](http://arxiv.org/abs/2401.13216) | 本论文提出了关于联邦学习中局部优化方法的研究，主要包括对FedAvg算法的界限探索以及提出了联邦加速随机梯度下降（FedAc）方法。 |
| [^8] | [DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport.](http://arxiv.org/abs/2401.13112) | 本文提出了使用最优传输进行分布式对抗解释的方法DISCOUNT，将对抗解释的概念扩展到整个输入输出分布，并通过统计置信度来支撑这一方法。 |
| [^9] | [Probabilistic Demand Forecasting with Graph Neural Networks.](http://arxiv.org/abs/2401.13096) | 本文提出了一种使用图神经网络进行概率需求预测的方法。该方法在现有的DeepAR模型中集成了GNN编码器，并采用基于文章属性相似性构建图的策略，实验结果表明该方法优于传统方法。 |
| [^10] | [Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?.](http://arxiv.org/abs/2401.13045) | 该论文提出了通过神经信息学和机器学习来评估女性运动员脑震荡的方法。相比传统的临床方法，在女性运动员中诊断脑震荡存在一些局限性，而这些新技术可以通过数据分析找出与性别相关的生物机制，从而填补这一差距。 |
| [^11] | [Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders.](http://arxiv.org/abs/2401.13009) | 对于循环模型中含有隐藏因变量的因果发现，已经出现了能够处理这种情况的多种技术方法。 |
| [^12] | [Improving the Accuracy and Interpretability of Random Forests via Forest Pruning.](http://arxiv.org/abs/2401.05535) | 通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。 |
| [^13] | [Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning.](http://arxiv.org/abs/2311.14828) | 该论文介绍了一种称为深度潜在力模型(DLFM)的通用域模型，使用了基于物理信息核的深度高斯过程，通过过程卷积方法从普通微分方程推导出来。DLFM能够捕捉高度非线性实际多输出时间序列中的动态性，并在基准测试上达到与一系列非物理综合概率模型相当的性能。 |
| [^14] | [Adversarial Imitation Learning from Visual Observations using Latent Information.](http://arxiv.org/abs/2309.17371) | 本文研究了从视觉观察中进行模仿学习的问题，提出了一种名为潜在对抗观察模仿的算法，通过结合离策略对抗学习技术和从观察序列中学习的代理状态的潜在表示来解决这个问题。实验证明，这种算法能与最先进的方法相匹配。 |
| [^15] | [Differentially Private Distributed Estimation and Learning.](http://arxiv.org/abs/2306.15865) | 本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。 |
| [^16] | [Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization.](http://arxiv.org/abs/2302.08298) | 该论文考察了在高维贝叶斯优化中，收购功能最大化器初始化对利用收购功能能力的影响。研究发现随机初始化方法不能充分发挥收购功能的潜力，因此提出了一种更好的初始化方法来利用历史数据。 |
| [^17] | [A mixed-categorical correlation kernel for Gaussian process.](http://arxiv.org/abs/2211.08262) | 提出一种新的混合类别相关核的高斯过程代理，相较于其他现有模型在分析和工程问题上表现更好。 |
| [^18] | [Tournament Leave-pair-out Cross-validation for Receiver Operating Characteristic (ROC) Analysis.](http://arxiv.org/abs/1801.09386) | 提出了一种新方法，称为淘汰对比交叉验证（TLPO），用于解决使用标准交叉验证方法估计接收器工作特性（ROC）曲线下面积（AUC）时的偏差问题，并提供了数据排序功能，为ROC分析提供了可靠的工具。 |

# 详细

[^1]: 《面板数据因果推断的逐项推理方法：一种简单且最佳化的方法》

    Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach. (arXiv:2401.13665v1 [math.ST])

    [http://arxiv.org/abs/2401.13665](http://arxiv.org/abs/2401.13665)

    本研究提出了一种在面板数据中进行因果推断的简单且最佳化的方法，通过简单的矩阵代数和奇异值分解来实现高效计算。通过导出非渐近界限，我们证明了逐项误差与高斯变量的适当缩放具有接近性。同时，我们还开发了一个数据驱动程序，用于构建具有预先指定覆盖保证的逐项置信区间。

    

    在分阶段采用的面板数据中的因果推断中，目标是估计和推导出潜在结果和处理效应的置信区间。我们提出了一种计算效率高的程序，仅涉及简单的矩阵代数和奇异值分解。我们导出了逐项误差的非渐近界限，证明其接近于适当缩放的高斯变量。尽管我们的程序简单，但却是局部最佳化的，因为我们的理论缩放与通过贝叶斯Cram\'{e}r-Rao论证得出的局部实例下界相匹配。利用我们的见解，我们开发了一种数据驱动的程序，用于构建具有预先指定覆盖保证的逐项置信区间。我们的分析基于对矩阵去噪模型应用SVD算法的一般推理工具箱，这可能具有独立的兴趣。

    In causal inference with panel data under staggered adoption, the goal is to estimate and derive confidence intervals for potential outcomes and treatment effects. We propose a computationally efficient procedure, involving only simple matrix algebra and singular value decomposition. We derive non-asymptotic bounds on the entrywise error, establishing its proximity to a suitably scaled Gaussian variable. Despite its simplicity, our procedure turns out to be instance-optimal, in that our theoretical scaling matches a local instance-wise lower bound derived via a Bayesian Cram\'{e}r-Rao argument. Using our insights, we develop a data-driven procedure for constructing entrywise confidence intervals with pre-specified coverage guarantees. Our analysis is based on a general inferential toolbox for the SVD algorithm applied to the matrix denoising model, which might be of independent interest.
    
[^2]: 深度神经网络在对抗训练中的过拟合现象能否泛化？——一个近似视角

    Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint. (arXiv:2401.13624v1 [stat.ML])

    [http://arxiv.org/abs/2401.13624](http://arxiv.org/abs/2401.13624)

    过拟合的深度神经网络在对抗训练中能够泛化，而且可以通过合适的条件获得良好的鲁棒泛化性能。

    

    对抗训练是一种广泛应用的方法，用于提高深度神经网络(DNNs)对对抗扰动的鲁棒性。然而，经验观察表明，在过参数化网络上进行对抗训练往往会遭受"鲁棒性过拟合"：它可以实现几乎零的对抗训练误差，而鲁棒泛化性能并不理想。本文从近似的角度提供了关于在对抗训练中过拟合的DNNs能否泛化的理论理解。具体而言，我们的主要结果总结为三个方面：i) 对于分类问题，我们证明了在过参数化的DNNs上可以构造出无限多个对抗训练分类器，其能够在满足一定条件下（涉及数据质量，良好分离和扰动程度）获得任意小的对抗训练误差（过拟合），同时在鲁棒泛化误差方面表现良好。ii) 线性超过拟合的DNNs也可以实现鲁棒泛化。iii) 我们通过数值实验验证了所提出的理论结果。

    Adversarial training is a widely used method to improve the robustness of deep neural networks (DNNs) over adversarial perturbations. However, it is empirically observed that adversarial training on over-parameterized networks often suffers from the \textit{robust overfitting}: it can achieve almost zero adversarial training error while the robust generalization performance is not promising. In this paper, we provide a theoretical understanding of the question of whether overfitted DNNs in adversarial training can generalize from an approximation viewpoint. Specifically, our main results are summarized into three folds: i) For classification, we prove by construction the existence of infinitely many adversarial training classifiers on over-parameterized DNNs that obtain arbitrarily small adversarial training error (overfitting), whereas achieving good robust generalization error under certain conditions concerning the data quality, well separated, and perturbation level. ii) Linear ove
    
[^3]: 超越概念瓶颈模型：如何使黑盒模型可干预？

    Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?. (arXiv:2401.13544v1 [cs.LG])

    [http://arxiv.org/abs/2401.13544](http://arxiv.org/abs/2401.13544)

    本文介绍了一种超越概念瓶颈模型的方法，可以使黑盒模型可干预。通过基于概念的干预来影响模型的输出，并利用这种方法对黑盒模型进行微调。实验证明，微调可以提高干预的效果，并产生更好校准的预测。

    

    最近，可解释的机器学习重新探索了概念瓶颈模型（CBM），包括从原始特征中逐步预测高级概念和从预测的概念中预测目标变量。这个模型类别的一个引人注目的优势是用户能够对预测的概念值进行干预，从而影响模型的下游输出。在这项工作中，我们介绍了一种方法，在已经训练好但本质上不可解释的神经网络上进行基于概念的干预，给定一个带有注释的验证集。此外，我们将模型的可干预性定义为基于概念干预的有效性的度量，并利用这个定义来对黑盒模型进行微调。实证上，我们探索了合成表格数据和自然图像基准上黑盒分类器的干预性。我们证明，微调提高了干预的效果，并经常产生更好校准的预测。

    Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts. A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output. In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set. Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the 
    
[^4]: 全贝叶斯神经网络显著性检验

    Full Bayesian Significance Testing for Neural Networks. (arXiv:2401.13335v1 [stat.ML])

    [http://arxiv.org/abs/2401.13335](http://arxiv.org/abs/2401.13335)

    该论文提出了一种全贝叶斯神经网络显著性检验方法（nFBST），通过利用贝叶斯神经网络拟合非线性和多维关系，并计算证据值来替代传统方法中的理论推导，该方法能够测试全局、局部和实例级的显著性。

    

    显著性检验旨在确定给定观测结果，关于总体分布的命题是否为真。然而，传统的显著性检验通常需要推导出检验统计量的分布，无法处理复杂的非线性关系。本文提出了一种用于神经网络的全贝叶斯显著性检验方法，称为nFBST，旨在克服传统方法在关系表征方面的局限性。利用贝叶斯神经网络拟合非线性和多维关系，并通过计算证据值而不是进行繁琐的理论推导来避免错误。此外，nFBST还可以测试全局、局部和实例级的显著性，这是之前的检验方法所不关注的。此外，nFBST是一个通用框架，可以根据所选的度量进行扩展，如Grad-nFBST，LRP-nFBST，DeepLIFT-nFBST。

    Significance testing aims to determine whether a proposition about the population distribution is the truth or not given observations. However, traditional significance testing often needs to derive the distribution of the testing statistic, failing to deal with complex nonlinear relationships. In this paper, we propose to conduct Full Bayesian Significance Testing for neural networks, called \textit{n}FBST, to overcome the limitation in relationship characterization of traditional approaches. A Bayesian neural network is utilized to fit the nonlinear and multi-dimensional relationships with small errors and avoid hard theoretical derivation by computing the evidence value. Besides, \textit{n}FBST can test not only global significance but also local and instance-wise significance, which previous testing methods don't focus on. Moreover, \textit{n}FBST is a general framework that can be extended based on the measures selected, such as Grad-\textit{n}FBST, LRP-\textit{n}FBST, DeepLIFT-\t
    
[^5]: 一种用于路径XVA计算的显式方案

    An Explicit Scheme for Pathwise XVA Computations. (arXiv:2401.13314v1 [q-fin.RM])

    [http://arxiv.org/abs/2401.13314](http://arxiv.org/abs/2401.13314)

    本论文介绍了一种显式的路径XVA计算方案，使用模拟/回归方法处理交叉估值调整（XVA）方程，并证明了该方案在高维和混合风险XVA用例中的优势。

    

    针对资本作为贴现保证金的资金来源的真实情况下，交叉估值调整（XVA）方程的动机，我们引入了一种模拟/回归方案用于一类预期BSDE，其中系数涉及解的鞅部分的条件期望缺失率。该方案在时间上是显式的，并使用神经网络最小二乘和分位数回归进行嵌入条件期望和期望缺失率的计算。一种后验蒙特卡罗验证过程允许在每个时间步骤评估方案的回归误差。将该方案与Picard迭代相比较，证明了它在高维和混合市场/违约风险XVA的用例中的优势。

    Motivated by the equations of cross valuation adjustments (XVAs) in the realistic case where capital is deemed fungible as a source of funding for variation margin, we introduce a simulation/regression scheme for a class of anticipated BSDEs, where the coefficient entails a conditional expected shortfall of the martingale part of the solution. The scheme is explicit in time and uses neural network least-squares and quantile regressions for the embedded conditional expectations and expected shortfall computations. An a posteriori Monte Carlo validation procedure allows assessing the regression error of the scheme at each time step. The superiority of this scheme with respect to Picard iterations is illustrated in a high-dimensional and hybrid market/default risks XVA use-case.
    
[^6]: 无单调性的量子自然梯度

    Quantum natural gradient without monotonicity. (arXiv:2401.13237v1 [quant-ph])

    [http://arxiv.org/abs/2401.13237](http://arxiv.org/abs/2401.13237)

    本文提出了一种新的量子自然梯度方法，去除了单调性条件，通过提供理论和数值证据来支持该方法的有效性。

    

    自然梯度是一种信息几何优化方法，在机器学习模型（如神经网络）参数估计中发挥着至关重要的作用。为了将自然梯度应用于量子系统，引入了量子自然梯度（QNG）并在噪声中等规模设备中加以利用。此外，还实施了一种数学上等效的 QNG 方法，称为随机重构方法，以提高量子蒙特卡洛方法的性能。值得注意的是，这些方法基于对数导数（SLD）度量，它是单调度量之一。到目前为止，单调性一直被认为是构建物理几何的指导原则。在本文中，我们提出了一种去除单调性条件的广义QNG。我们首先证明了在传统QNG中，单调性是一个关键条件。随后，我们提供了分析和数值证据。

    Natural gradient (NG) is an information-geometric optimization method that plays a crucial role, especially in the estimation of parameters for machine learning models like neural networks. To apply NG to quantum systems, the quantum natural gradient (QNG) was introduced and utilized for noisy intermediate-scale devices. Additionally, a mathematically equivalent approach to QNG, known as the stochastic reconfiguration method, has been implemented to enhance the performance of quantum Monte Carlo methods. It is worth noting that these methods are based on the symmetric logarithmic derivative (SLD) metric, which is one of the monotone metrics. So far, monotonicity has been believed to be a guiding principle to construct a geometry in physics. In this paper, we propose generalized QNG by removing the condition of monotonicity. Initially, we demonstrate that monotonicity is a crucial condition for conventional QNG to be optimal. Subsequently, we provide analytical and numerical evidence sh
    
[^7]: 关于联邦学习的原则性局部优化方法的研究

    On Principled Local Optimization Methods for Federated Learning. (arXiv:2401.13216v1 [cs.LG])

    [http://arxiv.org/abs/2401.13216](http://arxiv.org/abs/2401.13216)

    本论文提出了关于联邦学习中局部优化方法的研究，主要包括对FedAvg算法的界限探索以及提出了联邦加速随机梯度下降（FedAc）方法。

    

    联邦学习是一种分布式学习范式，通过在设备上协同进行学习，已经成为去中心化人工智能应用的一种有前景的方法。像联邦平均（FedAvg）这样的局部优化方法是联邦学习应用中最突出的方法。尽管这些方法简单且受欢迎，但对局部优化方法的理论理解仍然不够清晰。本论文旨在推进局部方法的理论基础，主要包括以下三个方面。首先，我们为FedAvg建立了严格的界限，这是联邦学习中最流行的算法。我们展示了FedAvg可能受到的一个我们称之为迭代偏见的概念，并且说明了额外的三阶平滑性假设如何减轻这种影响并导致更好的收敛速度。我们从随机微分方程的角度解释了这一现象。其次，我们提出了联邦加速随机梯度下降（FedAc），这是第一个有原则性且速度更快的联邦学习优化方法。

    Federated Learning (FL), a distributed learning paradigm that scales on-device learning collaboratively, has emerged as a promising approach for decentralized AI applications. Local optimization methods such as Federated Averaging (FedAvg) are the most prominent methods for FL applications. Despite their simplicity and popularity, the theoretical understanding of local optimization methods is far from clear. This dissertation aims to advance the theoretical foundation of local methods in the following three directions.  First, we establish sharp bounds for FedAvg, the most popular algorithm in Federated Learning. We demonstrate how FedAvg may suffer from a notion we call iterate bias, and how an additional third-order smoothness assumption may mitigate this effect and lead to better convergence rates. We explain this phenomenon from a Stochastic Differential Equation (SDE) perspective.  Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc), the first principled a
    
[^8]: DISCOUNT: 使用最优传输进行分布式对抗解释

    DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport. (arXiv:2401.13112v1 [cs.AI])

    [http://arxiv.org/abs/2401.13112](http://arxiv.org/abs/2401.13112)

    本文提出了使用最优传输进行分布式对抗解释的方法DISCOUNT，将对抗解释的概念扩展到整个输入输出分布，并通过统计置信度来支撑这一方法。

    

    对抗解释是在黑盒决策模型中提供洞察力和可解释性的事实方法，通过确定导致不同结果的替代输入实例来实现。本文将对抗解释的概念扩展到分布上下文，从个体数据点扩大到整个输入输出分布，命名为分布式对抗解释。在分布式对抗解释中，我们的重点转向分析事实和对抗的分布属性，类似于评估个体实例及其结果决策的经典方法。我们利用最优传输来构建一个机会约束优化问题，旨在导出与事实对应的对抗分布，以统计置信度做支撑。我们提出的优化方法DISCOUNT在输入和输出分布之间平衡这种置信度。

    Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorit
    
[^9]: 使用图神经网络进行概率需求预测

    Probabilistic Demand Forecasting with Graph Neural Networks. (arXiv:2401.13096v1 [cs.LG])

    [http://arxiv.org/abs/2401.13096](http://arxiv.org/abs/2401.13096)

    本文提出了一种使用图神经网络进行概率需求预测的方法。该方法在现有的DeepAR模型中集成了GNN编码器，并采用基于文章属性相似性构建图的策略，实验结果表明该方法优于传统方法。

    

    需求预测是一种重要的商业应用案例，它可以帮助零售商优化库存规划、物流和核心业务决策。需求预测的一个关键挑战是考虑文章之间的关系和互动。大多数现代预测方法提供独立的文章级预测，不考虑相关文章的影响。最近的研究尝试使用图神经网络（GNNs）来解决这个挑战，并取得了有希望的结果。本文在之前的GNNs研究基础上做出了两个贡献。首先，我们将GNN编码器集成到最先进的DeepAR模型中。这个组合模型产生概率预测，这在不确定性下的决策制定中至关重要。其次，我们提出使用文章属性相似性构建图，避免依赖预定义的图结构。对三个实际数据集的实验表明，所提出的方法始终优于现有方法。

    Demand forecasting is a prominent business use case that allows retailers to optimize inventory planning, logistics, and core business decisions. One of the key challenges in demand forecasting is accounting for relationships and interactions between articles. Most modern forecasting approaches provide independent article-level predictions that do not consider the impact of related articles. Recent research has attempted addressing this challenge using Graph Neural Networks (GNNs) and showed promising results. This paper builds on previous research on GNNs and makes two contributions. First, we integrate a GNN encoder into a state-of-the-art DeepAR model. The combined model produces probabilistic forecasts, which are crucial for decision-making under uncertainty. Second, we propose to build graphs using article attribute similarity, which avoids reliance on a pre-defined graph structure. Experiments on three real-world datasets show that the proposed approach consistently outperforms n
    
[^10]: 评估女性运动员脑震荡：神经信息学的作用？

    Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?. (arXiv:2401.13045v1 [stat.ML])

    [http://arxiv.org/abs/2401.13045](http://arxiv.org/abs/2401.13045)

    该论文提出了通过神经信息学和机器学习来评估女性运动员脑震荡的方法。相比传统的临床方法，在女性运动员中诊断脑震荡存在一些局限性，而这些新技术可以通过数据分析找出与性别相关的生物机制，从而填补这一差距。

    

    在过去的十年中，女性运动员脑震荡的复杂性变得明显。传统的临床诊断脑震荡的方法在应用于女性运动员时存在局限性，往往无法捕捉到脑结构和功能的细微变化。先进的神经信息学技术和机器学习模型在这方面已经成为宝贵的资产。虽然这些技术在理解男性运动员的脑震荡方面已经被广泛应用，但在我们对于它们对女性运动员的有效性的理解上仍存在显著差距。通过利用机器学习的强大数据分析能力，研究人员可以将观察到的表型神经影像数据联系到特定于性别的生物机制，揭示女性运动员脑震荡的奥秘。此外，嵌入机器学习的方法还可以在研究中进行交叉验证，进一步检验性别差异。

    Over the past decade, the intricacies of sports-related concussions among female athletes have become readily apparent. Traditional clinical methods for diagnosing concussions suffer limitations when applied to female athletes, often failing to capture subtle changes in brain structure and function. Advanced neuroinformatics techniques and machine learning models have become invaluable assets in this endeavor. While these technologies have been extensively employed in understanding concussion in male athletes, there remains a significant gap in our comprehension of their effectiveness for female athletes. With its remarkable data analysis capacity, machine learning offers a promising avenue to bridge this deficit. By harnessing the power of machine learning, researchers can link observed phenotypic neuroimaging data to sex-specific biological mechanisms, unraveling the mysteries of concussions in female athletes. Furthermore, embedding methods within machine learning enable examining b
    
[^11]: 循环模型中含有隐藏因变量的因果发现方法的比较研究

    Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders. (arXiv:2401.13009v1 [cs.LG])

    [http://arxiv.org/abs/2401.13009](http://arxiv.org/abs/2401.13009)

    对于循环模型中含有隐藏因变量的因果发现，已经出现了能够处理这种情况的多种技术方法。

    

    如今，对因果发现的需求无处不在。理解系统中部分之间的随机依赖性以及实际的因果关系对科学的各个部分都至关重要。因此，寻找可靠的方法来检测因果方向的需求不断增长。在过去的50年里，出现了许多因果发现算法，但大多数仅适用于系统没有反馈环路并且具有因果充分性的假设，即没有未测量的子系统能够影响多个已测量变量。这是不幸的，因为这些限制在实践中往往不能假定。反馈是许多过程的一个重要特性，现实世界的系统很少是完全隔离和完全测量的。幸运的是，在最近几年中，已经发展了几种能够处理循环的、因果不充分的系统的技术。随着多种方法的出现，一种实际的应用方法开始变得可能。

    Nowadays, the need for causal discovery is ubiquitous. A better understanding of not just the stochastic dependencies between parts of a system, but also the actual cause-effect relations, is essential for all parts of science. Thus, the need for reliable methods to detect causal directions is growing constantly. In the last 50 years, many causal discovery algorithms have emerged, but most of them are applicable only under the assumption that the systems have no feedback loops and that they are causally sufficient, i.e. that there are no unmeasured subsystems that can affect multiple measured variables. This is unfortunate since those restrictions can often not be presumed in practice. Feedback is an integral feature of many processes, and real-world systems are rarely completely isolated and fully measured. Fortunately, in recent years, several techniques, that can cope with cyclic, causally insufficient systems, have been developed. And with multiple methods available, a practical ap
    
[^12]: 通过森林修剪提高随机森林的准确性和可解释性

    Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])

    [http://arxiv.org/abs/2401.05535](http://arxiv.org/abs/2401.05535)

    通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。

    

    接近几十年的发展之后，随机森林仍然在各种学习问题中提供最先进的准确性，在这方面超越了决策树甚至神经网络等替代机器学习算法。然而，作为一种集成方法，随机森林在解释性方面往往比决策树表现不佳。在本研究中，我们提出了一种事后方法，旨在兼顾随机森林的准确性和决策树的可解释性。为此，我们提出了两种森林修剪方法，以在给定的随机森林内找到最佳子森林，然后在适用的情况下将选定的树合并为一棵。我们的第一种方法依赖于约束穷举搜索，而第二种方法基于LASSO方法的改进。在合成和真实世界数据集上进行的大量实验证明，在大多数情景下，这两种方法中至少有一种能够显著提高随机森林的准确性和可解释性。

    Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
    
[^13]: 深度潜在力模型：基于ODE的过程卷积用于贝叶斯深度学习

    Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning. (arXiv:2311.14828v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2311.14828](http://arxiv.org/abs/2311.14828)

    该论文介绍了一种称为深度潜在力模型(DLFM)的通用域模型，使用了基于物理信息核的深度高斯过程，通过过程卷积方法从普通微分方程推导出来。DLFM能够捕捉高度非线性实际多输出时间序列中的动态性，并在基准测试上达到与一系列非物理综合概率模型相当的性能。

    

    建模高度非线性动态系统并具有稳健的不确定性量化是一项具有挑战性的任务，通常需要专门设计的方法来解决问题。我们引入了一个通用域模型来解决这个问题，称为深度潜在力模型(DLFM)，它是一个深度高斯过程，每个层次都具有物理信息核，使用过程卷积的普通微分方程推导出。提出了DLFM的两种不同形式，它们利用基于权空间和基于变分感应点的高斯过程近似方法，都适用于双重随机变分推断。我们提供了DLFM捕捉高度非线性实际多输出时间序列数据中存在的动态性的经验证据。此外，我们发现DLFM能够在基准测试上达到与一系列非物理综合概率模型相当的性能。

    Modelling the behaviour of highly nonlinear dynamical systems with robust uncertainty quantification is a challenging task which typically requires approaches specifically designed to address the problem at hand. We introduce a domain-agnostic model to address this issue termed the deep latent force model (DLFM), a deep Gaussian process with physics-informed kernels at each layer, derived from ordinary differential equations using the framework of process convolutions. Two distinct formulations of the DLFM are presented which utilise weight-space and variational inducing points-based Gaussian process approximations, both of which are amenable to doubly stochastic variational inference. We present empirical evidence of the capability of the DLFM to capture the dynamics present in highly nonlinear real-world multi-output time series data. Additionally, we find that the DLFM is capable of achieving comparable performance to a range of non-physics-informed probabilistic models on benchmark
    
[^14]: 利用潜在信息从视觉观察中进行对抗性模仿学习

    Adversarial Imitation Learning from Visual Observations using Latent Information. (arXiv:2309.17371v1 [cs.LG])

    [http://arxiv.org/abs/2309.17371](http://arxiv.org/abs/2309.17371)

    本文研究了从视觉观察中进行模仿学习的问题，提出了一种名为潜在对抗观察模仿的算法，通过结合离策略对抗学习技术和从观察序列中学习的代理状态的潜在表示来解决这个问题。实验证明，这种算法能与最先进的方法相匹配。

    

    我们专注于从视觉观察中进行模仿学习的问题，学习代理只能访问专家的视频作为其唯一的学习源。这个框架的挑战包括缺乏专家的动作和环境的局部可观测性，因为地面真实状态只能从像素中推断出来。为了解决这个问题，我们首先对部分可观测环境中的模仿学习进行了理论分析。我们在专家和代理潜在状态转换分布之间的差异度上建立了学习代理子优度的上界。受到这个分析的启发，我们引入了一种称为潜在对抗观察模仿的算法，它将离策略对抗学习技术与从观察序列中学习的代理状态的潜在表示相结合。在高维连续机器人任务的实验证明，我们的算法与最先进的方法相匹配。

    We focus on the problem of imitation learning from visual observations, where the learning agent has access to videos of experts as its sole learning source. The challenges of this framework include the absence of expert actions and the partial observability of the environment, as the ground-truth states can only be inferred from pixels. To tackle this problem, we first conduct a theoretical analysis of imitation learning in partially observable environments. We establish upper bounds on the suboptimality of the learning agent with respect to the divergence between the expert and the agent latent state-transition distributions. Motivated by this analysis, we introduce an algorithm called Latent Adversarial Imitation from Observations, which combines off-policy adversarial imitation techniques with a learned latent representation of the agent's state from sequences of observations. In experiments on high-dimensional continuous robotic tasks, we show that our algorithm matches state-of-t
    
[^15]: 差分隐私分布式估计和学习

    Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])

    [http://arxiv.org/abs/2306.15865](http://arxiv.org/abs/2306.15865)

    本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。

    

    我们研究了在网络环境中的分布式估计和学习问题，其中代理通过交换信息来估计从其私下观察的样本中未知的统计属性。通过交换私有观测信息，代理可以集体估计未知数量，但他们也面临隐私风险。我们的聚合方案的目标是在时间和网络中高效地组合观测数据，同时满足代理的隐私需求，而不需要任何超越他们本地附近的协调。我们的算法使参与的代理能够从离线或随时间在线获取的私有信号中估计完整的充分统计量，并保护其信号和网络附近的隐私。这是通过线性聚合方案和调整的随机化方案实现的，将噪声添加到交换的估计数据中以满足差分隐私（DP）。

    We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
    
[^16]: 在高维贝叶斯优化中释放收购功能的潜力

    Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization. (arXiv:2302.08298v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08298](http://arxiv.org/abs/2302.08298)

    该论文考察了在高维贝叶斯优化中，收购功能最大化器初始化对利用收购功能能力的影响。研究发现随机初始化方法不能充分发挥收购功能的潜力，因此提出了一种更好的初始化方法来利用历史数据。

    

    贝叶斯优化（BO）被广泛用于优化昂贵的黑盒函数。BO首先构建一个代理模型来表示目标函数并评估其不确定性。然后，它通过最大化基于代理模型的收购函数（AF）来决定采样位置。然而，在处理高维问题时，找到AF的全局最大值变得越来越具有挑战性。在这种情况下，AF最大化器的初始化发挥了关键作用，因为不恰当的设置可能严重影响AF的有效性。本文研究了一个很大程度上未被研究的问题，即AF最大化器初始化对利用AF能力的影响。我们的大规模实证研究表明，广泛使用的随机初始化策略往往无法充分发挥AF的潜力。基于此，我们提出了一种更好的初始化方法，通过使用多个启发式优化器来利用黑盒的历史数据。

    Bayesian optimization (BO) is widely used to optimize expensive-to-evaluate black-box functions.BO first builds a surrogate model to represent the objective function and assesses its uncertainty. It then decides where to sample by maximizing an acquisition function (AF) based on the surrogate model. However, when dealing with high-dimensional problems, finding the global maximum of the AF becomes increasingly challenging. In such cases, the initialization of the AF maximizer plays a pivotal role, as an inadequate setup can severely hinder the effectiveness of the AF.  This paper investigates a largely understudied problem concerning the impact of AF maximizer initialization on exploiting AFs' capability. Our large-scale empirical study shows that the widely used random initialization strategy often fails to harness the potential of an AF. In light of this, we propose a better initialization approach by employing multiple heuristic optimizers to leverage the historical data of black-box
    
[^17]: 一种混合类别相关核的高斯过程

    A mixed-categorical correlation kernel for Gaussian process. (arXiv:2211.08262v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2211.08262](http://arxiv.org/abs/2211.08262)

    提出一种新的混合类别相关核的高斯过程代理，相较于其他现有模型在分析和工程问题上表现更好。

    

    近年来，基于高斯过程代理的混合类别元模型引起了越来越多的关注。在这种情况下，一些现有的方法使用不同的策略，通过使用连续核（例如，连续松弛和Gower距离基于高斯过程）或通过直接估计相关矩阵。在本文中，我们提出了一种基于核的方法，将连续指数核扩展为处理混合类别变量。所提出的核引导到了一个新的高斯代理，它概括了连续松弛和Gower距离基于高斯过程模型。我们在分析和工程问题上证明了，我们的提出的高斯过程模型比其他基于核的现有模型具有更高的可能性和更小的残差误差。我们的方法可使用开源软件SMT。

    Recently, there has been a growing interest for mixed-categorical meta-models based on Gaussian process (GP) surrogates. In this setting, several existing approaches use different strategies either by using continuous kernels (e.g., continuous relaxation and Gower distance based GP) or by using a direct estimation of the correlation matrix. In this paper, we present a kernel-based approach that extends continuous exponential kernels to handle mixed-categorical variables. The proposed kernel leads to a new GP surrogate that generalizes both the continuous relaxation and the Gower distance based GP models. We demonstrate, on both analytical and engineering problems, that our proposed GP model gives a higher likelihood and a smaller residual error than the other kernel-based state-of-the-art models. Our method is available in the open-source software SMT.
    
[^18]: 用于接收器工作特性（ROC）分析的淘汰对比交叉验证(Tournament Leave-pair-out Cross-validation)

    Tournament Leave-pair-out Cross-validation for Receiver Operating Characteristic (ROC) Analysis. (arXiv:1801.09386v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1801.09386](http://arxiv.org/abs/1801.09386)

    提出了一种新方法，称为淘汰对比交叉验证（TLPO），用于解决使用标准交叉验证方法估计接收器工作特性（ROC）曲线下面积（AUC）时的偏差问题，并提供了数据排序功能，为ROC分析提供了可靠的工具。

    

    接收器工作特性（ROC）分析被广泛用于评估诊断系统。最近的研究表明，使用标准交叉验证方法估计ROC曲线下面积（AUC）存在较大偏差。淘汰对比交叉验证（LPO）被证明可以修正这种偏差。然而，虽然LPO可以几乎无偏地估计AUC，但它无法提供绘制和分析ROC曲线所需的数据排序。在本研究中，我们提出了一种新方法，称为淘汰对比交叉验证（TLPO）。该方法通过创建从对比中得出排名的比赛，扩展了LPO的功能，从而为数据提供了排序。TLPO既保留了LPO估计AUC的优势，又可以进行ROC分析。我们使用合成数据和真实世界数据证明了TLPO对于AUC估计与LPO一样可靠，并验证了留一交叉验证在低维数据上的偏差。作为ROC分析的案例研究，我们

    Receiver operating characteristic (ROC) analysis is widely used for evaluating diagnostic systems. Recent studies have shown that estimating an area under ROC curve (AUC) with standard cross-validation methods suffers from a large bias. The leave-pair-out (LPO) cross-validation has been shown to correct this bias. However, while LPO produces an almost unbiased estimate of AUC, it does not provide a ranking of the data needed for plotting and analyzing the ROC curve. In this study, we propose a new method called tournament leave-pair-out (TLPO) cross-validation. This method extends LPO by creating a tournament from pair comparisons to produce a ranking for the data. TLPO preserves the advantage of LPO for estimating AUC, while it also allows performing ROC analyses. We have shown using both synthetic and real world data that TLPO is as reliable as LPO for AUC estimation, and confirmed the bias in leave-one-out cross-validation on low-dimensional data. As a case study on ROC analysis, we
    

