# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Deep reinforcement learning for the dynamic vehicle dispatching problem: An event-based approach.](http://arxiv.org/abs/2307.07508) | 本文介绍了将动态车辆调度问题建模为半马尔可夫决策过程的基于事件的方法，并通过实际场景的数值实验验证了该方法的有效性。 |
| [^2] | [Implicit regularization in AI meets generalized hardness of approximation in optimization -- Sharp results for diagonal linear networks.](http://arxiv.org/abs/2307.07410) | 本论文通过研究对角线性网络（DLNs）的梯度流所施加的隐式正则化，意外地与广义近似难度（GHA）中的相变现象联系起来，并提供了对此的锐利结果。 |
| [^3] | [Performance of $\ell_1$ Regularization for Sparse Convex Optimization.](http://arxiv.org/abs/2307.07405) | 本论文研究了稀疏凸优化中$\ell_1$正则化的性能，给出了Group LASSO的恢复保证，并且发现了Group LASSO选择相同特征集的机制。 |
| [^4] | [How Different Is Stereotypical Bias Across Languages?.](http://arxiv.org/abs/2307.07331) | 本研究拓展了评估预训练语言模型中刻板偏见的研究，通过跨语言分析发现mGPT-2在不同语言中显示出令人惊讶的反刻板行为，并且英语模型表现出最强的偏见，而土耳其语则最不明显。 |
| [^5] | [Adaptive Linear Estimating Equations.](http://arxiv.org/abs/2307.07320) | 本文提出了一种解决自适应线性回归模型中非正态渐近行为的方法，使用自适应线性估计方程构建去偏估计量，并在多臂老虎机的背景下保持了最小二乘估计量的非渐近性能。 |
| [^6] | [On Interpolating Experts and Multi-Armed Bandits.](http://arxiv.org/abs/2307.07264) | 学习专家建议和多臂赌博是两个经典的在线决策问题，我们研究了两者之间的插值问题。我们提出了$\mathbf{m}$-MAB的极小后悔界并设计了$\mathbf{m}$-BAI的最优PAC算法，该算法旨在以尽可能少的轮数确定损失最小的臂。 |
| [^7] | [Benchmarks and Custom Package for Electrical Load Forecasting.](http://arxiv.org/abs/2307.07191) | 本文提供了一个全面的电力负荷预测存档，包括负荷领域特定的特征工程，帮助模型更好地模拟负荷数据，并提供了一种新的损失函数来最小化后续任务的成本。 |
| [^8] | [Rician likelihood loss for quantitative MRI using self-supervised deep learning.](http://arxiv.org/abs/2307.07072) | 本研究提出了一种使用自监督深度学习进行定量MRI的方法，通过引入负对数Rician似然（NLR）损失函数，解决了低信噪比条件下参数估计偏差的问题。 |
| [^9] | [Leveraging Factored Action Spaces for Off-Policy Evaluation.](http://arxiv.org/abs/2307.07014) | 本文研究了如何利用分解的动作空间来减轻涉及大型组合动作空间问题的非策略评估（OPE）的高偏差和高方差问题。通过提出一种基于分解动作空间的新型“分解”重要性抽样（IS）估计器系列，我们证明了分解IS估计器具有比非分解版本更小的方差，同时具有零偏差的性质，并通过模拟实验证实了该理论结果。 |
| [^10] | [Embracing the chaos: analysis and diagnosis of numerical instability in variational flows.](http://arxiv.org/abs/2307.06957) | 本文研究了数值不稳定性对变分流中采样、密度评估和ELBO估计的可靠性的影响。通过理论保证和实验验证，我们发现尽管存在严重的数值不稳定性，变分流产生的结果在应用中常常足够准确。 |
| [^11] | [Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective.](http://arxiv.org/abs/2307.06457) | 该论文研究了组合分布偏移的问题，提出了基于矩阵补全的解决方法。通过在特殊情况下的双线性嵌入，实现对训练中未涵盖的测试分布进行外推。这个设置将缺失非随机数据的矩阵补全问题广义化。 |
| [^12] | [Identifiability Guarantees for Causal Disentanglement from Soft Interventions.](http://arxiv.org/abs/2307.06250) | 本文研究了从软干预中确保因果分解的可识别性。通过开发一种自编码变分贝叶斯算法，我们展示了在给定一般化的忠诚性概念的情况下，即使存在未观测到的因果变量，仍然可以恢复潜在的因果模型，并在无限数据的极限情况下预测未见组合的干预效果。 |
| [^13] | [Seismic Data Interpolation based on Denoising Diffusion Implicit Models with Resampling.](http://arxiv.org/abs/2307.04226) | 本研究提出了一种基于去噪扩散隐式模型和重采样的地震数据插值方法，通过使用多头自注意力和余弦噪声计划，实现了稳定训练生成对抗网络，并提高了已知迹线信息的利用率。 |
| [^14] | [Hypothesis Transfer Learning with Surrogate Classification Losses.](http://arxiv.org/abs/2305.19694) | 本文研究了使用代理分类损失的假设迁移学习的学习理论，通过算法稳定性提供了在温和假设下的学习保证，适用于机器学习算法。 |
| [^15] | [DoCoFL: Downlink Compression for Cross-Device Federated Learning.](http://arxiv.org/abs/2302.00543) | 本研究提出了DoCoFL，一种用于跨设备联合学习的下行压缩框架，能够在降低双向带宽的同时保持竞争力的准确性。 |
| [^16] | [Linear Classification of Neural Manifolds with Correlated Variability.](http://arxiv.org/abs/2211.14961) | 本文研究了神经活动的统计和几何属性与性能的关系，并发现了线性可分性的度量与目标表示之间的相关性之间的关系。研究结果揭示了关于相关性和几何性质之间的二元性在分类问题上的问题，并进一步应用到深度网络数据中。 |
| [^17] | [$\Phi$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation.](http://arxiv.org/abs/2209.15609) | 本文提出了一种物理指导的动态变分自编码器 ($\Phi$-DVAE) 用于将非结构化数据同化到物理模型中，解决了传统方法在未知映射情况下无法实现一致模型与数据综合的问题。 |
| [^18] | [Differentially Private Stochastic Gradient Descent with Low-Noise.](http://arxiv.org/abs/2209.04188) | 本文研究了具有低噪声的差分隐私随机梯度下降法在点问题和成对学习中的性能，并推导出更精确的过剩风险界限。提出的算法基于梯度扰动，具有优化过剩风险率的最佳效果。 |
| [^19] | [Fully probabilistic deep models for forward and inverse problems in parametric PDEs.](http://arxiv.org/abs/2208.04856) | 本论文提出了一种基于深度学习和概率建模的全概率深度模型，用于学习参数化偏微分方程中的前向和反向映射。模型通过最大化观察到的零残差的概率来进行训练，不需要独立的训练数据。 |
| [^20] | [Unpacking the Black Box: Regulating Algorithmic Decisions.](http://arxiv.org/abs/2110.03443) | 本文研究如何在代理使用复杂的“黑盒”预测函数进行决策的情况下，对算法决策进行最优调控。研究发现，限制代理使用透明度足够高的预测函数是低效的，而针对激励偏差源头的目标化工具可以提供次优解决方案，从而改善福利。 |
| [^21] | [On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach.](http://arxiv.org/abs/2010.01079) | 该论文通过使用多臂赌博机模型分析招聘市场中的统计歧视，发现自由放任会导致对少数族裔工人的持续低估问题。研究提出了两种政策解决方案，即混合机制和罗尼法则，表明临时肯定行动可以有效缓解由于数据不足引起的歧视问题。 |
| [^22] | [Alternating the Population and Control Neural Networks to Solve High-Dimensional Stochastic Mean-Field Games.](http://arxiv.org/abs/2002.10113) | 我们提出了一种交替人口和代理控制神经网络（APAC-Net）来解决高维度随机均场博弈（MFG）问题。通过利用变分原始-对偶结构和神经网络参数化价值和密度函数，我们展示了在高维度MFG问题中的潜力。 |
| [^23] | [Signed iterative random forests to identify enhancer-associated transcription factor binding.](http://arxiv.org/abs/1810.07287) | 本文介绍了一种有符号的迭代随机森林（siRF）方法，用于推断Drosophila melanogaster中增强子元素周围的转录因子之间的调控相互作用和功能结合签名。 |

# 详细

[^1]: 深度强化学习用于动态车辆调度问题的基于事件的方法

    Deep reinforcement learning for the dynamic vehicle dispatching problem: An event-based approach. (arXiv:2307.07508v1 [cs.AI])

    [http://arxiv.org/abs/2307.07508](http://arxiv.org/abs/2307.07508)

    本文介绍了将动态车辆调度问题建模为半马尔可夫决策过程的基于事件的方法，并通过实际场景的数值实验验证了该方法的有效性。

    

    动态车辆调度问题涉及决定将哪些车辆分配给随机产生的时间和空间请求。该问题出现在各个领域，如将卡车分配给要运输的货物、应急系统和顺风车服务中。本文将该问题建模为半马尔可夫决策过程，这使我们能够将时间视为连续变量。在此设置中，决策时刻与事件一致，其时间间隔是随机的。我们认为基于事件的方法大大降低了决策空间的组合复杂性，并克服了文献中常提出的离散时间模型的其他局限性。为了测试我们的方法，我们开发了一个新的离散事件模拟器，并使用双深度Q学习训练我们的决策代理。在使用纽约市的数据进行实际场景的数值实验中，我们将通过我们的方法获得的策略与启发式方法进行了比较。

    The dynamic vehicle dispatching problem corresponds to deciding which vehicles to assign to requests that arise stochastically over time and space. It emerges in diverse areas, such as in the assignment of trucks to loads to be transported; in emergency systems; and in ride-hailing services. In this paper, we model the problem as a semi-Markov decision process, which allows us to treat time as continuous. In this setting, decision epochs coincide with discrete events whose time intervals are random. We argue that an event-based approach substantially reduces the combinatorial complexity of the decision space and overcomes other limitations of discrete-time models often proposed in the literature. In order to test our approach, we develop a new discrete-event simulator and use double deep q-learning to train our decision agents. Numerical experiments are carried out in realistic scenarios using data from New York City. We compare the policies obtained through our approach with heuristic
    
[^2]: AI中的隐式正则化与优化中的广义近似难度相遇--对对角线性网络的锐利结果。

    Implicit regularization in AI meets generalized hardness of approximation in optimization -- Sharp results for diagonal linear networks. (arXiv:2307.07410v1 [cs.LG])

    [http://arxiv.org/abs/2307.07410](http://arxiv.org/abs/2307.07410)

    本论文通过研究对角线性网络（DLNs）的梯度流所施加的隐式正则化，意外地与广义近似难度（GHA）中的相变现象联系起来，并提供了对此的锐利结果。

    

    理解神经网络架构和基于梯度的优化方法所施加的隐式正则化是深度学习和人工智能中的一个关键挑战。在这项工作中，我们针对超参数回归设置提供了对于对角线性网络（DLNs）的梯度流所施加的隐式正则化的锐利结果，并意外地将其与广义近似难度（GHA）中的相变现象联系起来。GHA将近似难度的现象从计算机科学推广到连续和鲁棒优化等领域。众所周知，具有微小初始化的DLNs的梯度流的$\ell^1$-范数收敛到基础追踪的目标函数。我们通过展示具有微小初始化的DLNs的梯度流近似于基础追踪优化问题的最小化器（而不仅仅是目标函数），进一步改进了这些结果，并获得了新的锐利收敛结果。

    Understanding the implicit regularization imposed by neural network architectures and gradient based optimization methods is a key challenge in deep learning and AI. In this work we provide sharp results for the implicit regularization imposed by the gradient flow of Diagonal Linear Networks (DLNs) in the over-parameterized regression setting and, potentially surprisingly, link this to the phenomenon of phase transitions in generalized hardness of approximation (GHA). GHA generalizes the phenomenon of hardness of approximation from computer science to, among others, continuous and robust optimization. It is well-known that the $\ell^1$-norm of the gradient flow of DLNs with tiny initialization converges to the objective function of basis pursuit. We improve upon these results by showing that the gradient flow of DLNs with tiny initialization approximates minimizers of the basis pursuit optimization problem (as opposed to just the objective function), and we obtain new and sharp converg
    
[^3]: $\ell_1$正则化在稀疏凸优化中的性能

    Performance of $\ell_1$ Regularization for Sparse Convex Optimization. (arXiv:2307.07405v1 [cs.LG])

    [http://arxiv.org/abs/2307.07405](http://arxiv.org/abs/2307.07405)

    本论文研究了稀疏凸优化中$\ell_1$正则化的性能，给出了Group LASSO的恢复保证，并且发现了Group LASSO选择相同特征集的机制。

    

    虽然LASSO和Group LASSO在实践中被广泛采用, 但是对于除了统计问题以外的其他情况, 这些算法的保证令人震惊地缺乏, 并且在确定性输入的稀疏凸优化背景下通常被认为是一种启发式算法。我们为具有向量值特征的稀疏凸优化的Group LASSO给出了第一个恢复保证。我们证明了，如果在最小化严格凸函数$l$时应用足够大的Group LASSO正则化，那么极小化器是在具有最大梯度的$\ell_2$范数的向量值特征上支持的稀疏向量。因此，重复此过程选择与正交匹配追踪算法相同的特征集，通过弱次模性证明了对于具有受限强凸性和光滑性的任何函数$l$都具有恢复保证。这回答了Tibshirani等人和Yasuda等人的开放问题。我们的结果首次在理论上解释了

    Despite widespread adoption in practice, guarantees for the LASSO and Group LASSO are strikingly lacking in settings beyond statistical problems, and these algorithms are usually considered to be a heuristic in the context of sparse convex optimization on deterministic inputs. We give the first recovery guarantees for the Group LASSO for sparse convex optimization with vector-valued features. We show that if a sufficiently large Group LASSO regularization is applied when minimizing a strictly convex function $l$, then the minimizer is a sparse vector supported on vector-valued features with the largest $\ell_2$ norm of the gradient. Thus, repeating this procedure selects the same set of features as the Orthogonal Matching Pursuit algorithm, which admits recovery guarantees for any function $l$ with restricted strong convexity and smoothness via weak submodularity arguments. This answers open questions of Tibshirani et al. and Yasuda et al. Our result is the first to theoretically expla
    
[^4]: 跨语言的刻板偏见有何不同？

    How Different Is Stereotypical Bias Across Languages?. (arXiv:2307.07331v1 [cs.CL])

    [http://arxiv.org/abs/2307.07331](http://arxiv.org/abs/2307.07331)

    本研究拓展了评估预训练语言模型中刻板偏见的研究，通过跨语言分析发现mGPT-2在不同语言中显示出令人惊讶的反刻板行为，并且英语模型表现出最强的偏见，而土耳其语则最不明显。

    

    最近的研究展示了如何评估预训练的英语语言模型中的刻板偏见。在本研究中，我们通过系统地调查(a)多语言模型和单语模型、(b)不同基础架构下的刻板偏见、(c)多种语言中的偏见，扩展了该研究领域的多个方面。为了实现这一目标，我们利用英语的StereoSet数据集将其半自动翻译成德语、法语、西班牙语和土耳其语。我们发现，在多语言环境下进行这种类型的分析非常重要，因为我们的实验展示了一个更为细致的画面，以及与仅英语分析有显著差异的发现。我们的分析主要得出以下结论：mGPT-2（在某种程度上）在不同语言中显示出令人惊讶的反刻板行为，英语（单语）模型表现出最强的偏见，并且数据集中反映的刻板印象在土耳其语中最不明显。

    Recent studies have demonstrated how to assess the stereotypical bias in pre-trained English language models. In this work, we extend this branch of research in multiple different dimensions by systematically investigating (a) mono- and multilingual models of (b) different underlying architectures with respect to their bias in (c) multiple different languages. To that end, we make use of the English StereoSet data set (Nadeem et al., 2021), which we semi-automatically translate into German, French, Spanish, and Turkish. We find that it is of major importance to conduct this type of analysis in a multilingual setting, as our experiments show a much more nuanced picture as well as notable differences from the English-only analysis. The main takeaways from our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical behavior across languages, English (monolingual) models exhibit the strongest bias, and the stereotypes reflected in the data set are least present in Turkish mod
    
[^5]: 自适应线性估计方程

    Adaptive Linear Estimating Equations. (arXiv:2307.07320v1 [math.ST])

    [http://arxiv.org/abs/2307.07320](http://arxiv.org/abs/2307.07320)

    本文提出了一种解决自适应线性回归模型中非正态渐近行为的方法，使用自适应线性估计方程构建去偏估计量，并在多臂老虎机的背景下保持了最小二乘估计量的非渐近性能。

    

    顺序数据收集已成为增强数据收集过程效率的广泛采用的技术。尽管具有优势，但这种数据收集机制常常给统计推断过程引入复杂性。例如，在自适应线性回归模型中，普通最小二乘（OLS）估计量可能表现出非正态的渐近行为，从而对准确的推断和解释提出挑战。本文提出了一种构建去偏估计量的通用方法，该方法采用自适应线性估计方程的思想，并在理论上保证了渐近正态性，并讨论了实现近似最优渐近方差的问题。我们的估计量的一个显著特点是，在多臂老虎机的背景下，我们的估计量保留了最小二乘估计量的非渐近性能，同时获得了渐近正态性。因此，本工作解决了自适应线性回归模型中非正态渐近行为的问题，并为统计推断提供了可靠的方法。

    Sequential data collection has emerged as a widely adopted technique for enhancing the efficiency of data gathering processes. Despite its advantages, such data collection mechanism often introduces complexities to the statistical inference procedure. For instance, the ordinary least squares (OLS) estimator in an adaptive linear regression model can exhibit non-normal asymptotic behavior, posing challenges for accurate inference and interpretation. In this paper, we propose a general method for constructing debiased estimator which remedies this issue. It makes use of the idea of adaptive linear estimating equations, and we establish theoretical guarantees of asymptotic normality, supplemented by discussions on achieving near-optimal asymptotic variance. A salient feature of our estimator is that in the context of multi-armed bandits, our estimator retains the non-asymptotic performance of the least square estimator while obtaining asymptotic normality property. Consequently, this work
    
[^6]: 关于插值专家和多臂赌博机的研究

    On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])

    [http://arxiv.org/abs/2307.07264](http://arxiv.org/abs/2307.07264)

    学习专家建议和多臂赌博是两个经典的在线决策问题，我们研究了两者之间的插值问题。我们提出了$\mathbf{m}$-MAB的极小后悔界并设计了$\mathbf{m}$-BAI的最优PAC算法，该算法旨在以尽可能少的轮数确定损失最小的臂。

    

    学习专家建议和多臂赌博是两个经典的在线决策问题，它们在每一轮观察信息的方式上有所不同。我们研究了这两者之间的插值问题。对于向量$\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$，$\mathbf{m}$-MAB的一个实例表示将臂分成$K$组，第$i$组包含$m_i$个臂。一旦拉动一个臂，同一组中所有臂的损失都被观察到。我们证明了$\mathbf{m}$-MAB的紧致极小后悔界，并为其纯探索版本$\mathbf{m}$-BAI设计了一个最优的PAC算法，其中目标是用尽可能少的轮数来识别损失最小的臂。我们证明了$\mathbf{m}$-MAB的极小后悔是$\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$，对于一个$(\epsilon,0.05)$-PAC算法的$\mathbf{m}$-BAI，拉动臂的最小次数是$\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$。

    Learning with expert advice and multi-armed bandit are two classic online decision problems which differ on how the information is observed in each round of the game. We study a family of problems interpolating the two. For a vector $\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$, an instance of $\mathbf{m}$-MAB indicates that the arms are partitioned into $K$ groups and the $i$-th group contains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same group are observed. We prove tight minimax regret bounds for $\mathbf{m}$-MAB and design an optimal PAC algorithm for its pure exploration version, $\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with as few rounds as possible. We show that the minimax regret of $\mathbf{m}$-MAB is $\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$ and the minimum number of pulls for an $(\epsilon,0.05)$-PAC algorithm of $\mathbf{m}$-BAI is $\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$. Bot
    
[^7]: 用于电力负荷预测的基准和自定义包

    Benchmarks and Custom Package for Electrical Load Forecasting. (arXiv:2307.07191v1 [cs.LG])

    [http://arxiv.org/abs/2307.07191](http://arxiv.org/abs/2307.07191)

    本文提供了一个全面的电力负荷预测存档，包括负荷领域特定的特征工程，帮助模型更好地模拟负荷数据，并提供了一种新的损失函数来最小化后续任务的成本。

    

    负荷预测在电力行业中具有重要意义，可以为后续任务如电网调度提供参考，从而带来巨大的经济效益。然而，负荷预测与传统的时间序列预测之间存在许多差异。一方面，负荷预测的目标是最小化后续任务（如电网调度）的成本，而不仅仅追求预测准确性。另一方面，负荷受到许多外部因素的影响，如温度或日历变量。此外，预测的规模（如建筑级负荷和聚合级负荷）也会对预测结果产生重大影响。在本文中，我们提供了一个全面的负荷预测存档，其中包括负荷领域特定的特征工程，以帮助预测模型更好地模拟负荷数据。此外，与传统的损失函数仅追求准确性不同，我们还提供了一种方法来...

    Load forecasting is of great significance in the power industry as it can provide a reference for subsequent tasks such as power grid dispatch, thus bringing huge economic benefits. However, there are many differences between load forecasting and traditional time series forecasting. On the one hand, load forecasting aims to minimize the cost of subsequent tasks such as power grid dispatch, rather than simply pursuing prediction accuracy. On the other hand, the load is largely influenced by many external factors, such as temperature or calendar variables. In addition, the scale of predictions (such as building-level loads and aggregated-level loads) can also significantly impact the predicted results. In this paper, we provide a comprehensive load forecasting archive, which includes load domain-specific feature engineering to help forecasting models better model load data. In addition, different from the traditional loss function which only aims for accuracy, we also provide a method to
    
[^8]: 使用自监督深度学习的Rician似然损失进行定量MRI

    Rician likelihood loss for quantitative MRI using self-supervised deep learning. (arXiv:2307.07072v1 [cs.LG])

    [http://arxiv.org/abs/2307.07072](http://arxiv.org/abs/2307.07072)

    本研究提出了一种使用自监督深度学习进行定量MRI的方法，通过引入负对数Rician似然（NLR）损失函数，解决了低信噪比条件下参数估计偏差的问题。

    

    目的：以前使用自监督深度学习进行的定量MRI研究报告在低信噪比条件下存在参数估计偏差的问题。这些系统误差来自于网络训练中选择的均方误差（MSE）损失函数，该函数与Rician分布的MR幅度信号不兼容。为了解决这个问题，我们引入了负对数Rician似然（NLR）损失。方法：我们开发了一个数值稳定且准确的NLR损失的实现，用于估计表观扩散系数（ADC）模型和体素内不相干运动（IVIM）模型的定量参数。通过在一系列信噪比（5-30）下比较偏差、方差和均方根误差来评估参数估计的准确性、精度和总体误差，并与MSE损失进行比较。结果：使用NLR损失训练的网络在SNR降低时显示出比MSE更高的ADC和IVIM扩散系数估计准确性，而精度或总误差几乎没有损失。

    Purpose: Previous quantitative MR imaging studies using self-supervised deep learning have reported biased parameter estimates at low SNR. Such systematic errors arise from the choice of Mean Squared Error (MSE) loss function for network training, which is incompatible with Rician-distributed MR magnitude signals. To address this issue, we introduce the negative log Rician likelihood (NLR) loss. Methods: A numerically stable and accurate implementation of the NLR loss was developed to estimate quantitative parameters of the apparent diffusion coefficient (ADC) model and intra-voxel incoherent motion (IVIM) model. Parameter estimation accuracy, precision and overall error were evaluated in terms of bias, variance and root mean squared error and compared against the MSE loss over a range of SNRs (5 - 30). Results: Networks trained with NLR loss show higher estimation accuracy than MSE for the ADC and IVIM diffusion coefficients as SNR decreases, with minimal loss of precision or total er
    
[^9]: 利用分解的动作空间进行非策略评估

    Leveraging Factored Action Spaces for Off-Policy Evaluation. (arXiv:2307.07014v1 [cs.LG])

    [http://arxiv.org/abs/2307.07014](http://arxiv.org/abs/2307.07014)

    本文研究了如何利用分解的动作空间来减轻涉及大型组合动作空间问题的非策略评估（OPE）的高偏差和高方差问题。通过提出一种基于分解动作空间的新型“分解”重要性抽样（IS）估计器系列，我们证明了分解IS估计器具有比非分解版本更小的方差，同时具有零偏差的性质，并通过模拟实验证实了该理论结果。

    

    非策略评估（OPE）旨在估计根据执行序列收集的数据，遵循反事实的一系列动作的效益。然而，现有的OPE估计器在涉及大型组合动作空间的问题中经常表现出高偏差和高方差。我们研究如何利用分解的动作空间来减轻这个问题，即将每个动作表示为来自较小动作空间的独立子动作的组合。这种方法有助于对动作在其效果上的差异进行更精细的分析。在这项工作中，我们提出了一种基于分解动作空间的新型“分解”重要性抽样（IS）估计器系列。在对底层问题结构进行一定的假设的情况下，我们证明了分解IS估计器的方差比其原始非分解版本小，同时保持零偏差的性质。通过模拟，我们经验证实了我们的理论结果，检验了各种假设的有效性。

    Off-policy evaluation (OPE) aims to estimate the benefit of following a counterfactual sequence of actions, given data collected from executed sequences. However, existing OPE estimators often exhibit high bias and high variance in problems involving large, combinatorial action spaces. We investigate how to mitigate this issue using factored action spaces i.e. expressing each action as a combination of independent sub-actions from smaller action spaces. This approach facilitates a finer-grained analysis of how actions differ in their effects. In this work, we propose a new family of "decomposed" importance sampling (IS) estimators based on factored action spaces. Given certain assumptions on the underlying problem structure, we prove that the decomposed IS estimators have less variance than their original non-decomposed versions, while preserving the property of zero bias. Through simulations, we empirically verify our theoretical results, probing the validity of various assumptions. P
    
[^10]: 拥抱混乱：数值不稳定性在变分流中的分析和诊断

    Embracing the chaos: analysis and diagnosis of numerical instability in variational flows. (arXiv:2307.06957v1 [stat.ML])

    [http://arxiv.org/abs/2307.06957](http://arxiv.org/abs/2307.06957)

    本文研究了数值不稳定性对变分流中采样、密度评估和ELBO估计的可靠性的影响。通过理论保证和实验验证，我们发现尽管存在严重的数值不稳定性，变分流产生的结果在应用中常常足够准确。

    

    本文研究了数值不稳定性对变分流中采样、密度评估和证据下界（ELBO）估计的可靠性的影响。我们首先通过实证验证了常见流可能出现严重的错误累积：数值流映射与精确映射的偏差显著，影响采样；数值逆流映射无法准确恢复初始输入，影响密度和ELBO计算。然而，我们惊讶地发现，尽管存在严重的数值不稳定性，流产生的结果常常足够准确应对应用需求。在这项工作中，我们将变分流视为动力系统，并利用阴影理论通过理论保证对采样、密度评估和ELBO估计的错误来阐明这种行为。最后，我们开发并经验性地测试了一种可以用于验证数值结果的诊断程序。

    In this paper, we investigate the impact of numerical instability on the reliability of sampling, density evaluation, and evidence lower bound (ELBO) estimation in variational flows. We first empirically demonstrate that common flows can exhibit a catastrophic accumulation of error: the numerical flow map deviates significantly from the exact map -- which affects sampling -- and the numerical inverse flow map does not accurately recover the initial input -which affects density and ELBO computations. Surprisingly though, we find that results produced by flows are often accurate enough for applications despite the presence of serious numerical instability. In this work, we treat variational flows as dynamical systems, and leverage shadowing theory to elucidate this behavior via theoretical guarantees on the error of sampling, density evaluation, and ELBO estimation. Finally, we develop and empirically test a diagnostic procedure that can be used to validate results produced by numerica
    
[^11]: 解决组合分布偏移问题：基于矩阵补全的观点

    Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])

    [http://arxiv.org/abs/2307.06457](http://arxiv.org/abs/2307.06457)

    该论文研究了组合分布偏移的问题，提出了基于矩阵补全的解决方法。通过在特殊情况下的双线性嵌入，实现对训练中未涵盖的测试分布进行外推。这个设置将缺失非随机数据的矩阵补全问题广义化。

    

    在分布偏移下获得严格的统计保证仍然是一个开放且活跃的研究领域。我们研究了一种称为组合分布偏移的设置，其中(a)在测试和训练分布下，标签$z$由特征$(x,y)$的对决定，(b)训练分布涵盖了$x$和$y$分别的一定边缘分布，但是(c)测试分布涉及了一个在训练分布中未涵盖的$(x,y)$的产品分布的示例。我们专注于标签由双线性嵌入到Hilbert空间$H$中给出的特殊情况：$\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$，我们的目标是对在训练中未涵盖的测试分布域进行外推，即实现双线性组合外推。我们的设置将缺失非随机数据的矩阵补全的一个特殊情况广义化，对于该情况，所有现有结果都要求....

    Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call combinatorial distribution shift, where (a) under the test- and training-distributions, the labels $z$ are determined by pairs of features $(x,y)$, (b) the training distribution has coverage of certain marginal distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is {not} covered by the training distribution. Focusing on the special case where the labels are given by bilinear embeddings into a Hilbert space $H$: $\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$, we aim to extrapolate to a test distribution domain that is $not$ covered in training, i.e., achieving bilinear combinatorial extrapolation.  Our setting generalizes a special case of matrix completion from missing-not-at-random data, for which all existing results requi
    
[^12]: 从软干预中确保因果分解的可识别性

    Identifiability Guarantees for Causal Disentanglement from Soft Interventions. (arXiv:2307.06250v1 [stat.ML])

    [http://arxiv.org/abs/2307.06250](http://arxiv.org/abs/2307.06250)

    本文研究了从软干预中确保因果分解的可识别性。通过开发一种自编码变分贝叶斯算法，我们展示了在给定一般化的忠诚性概念的情况下，即使存在未观测到的因果变量，仍然可以恢复潜在的因果模型，并在无限数据的极限情况下预测未见组合的干预效果。

    

    因果分解旨在通过潜在变量的相关性揭示数据的表征，其通过因果模型相互关联。如果解释数据的潜在模型是唯一的，那么这种表示是可识别的。本文关注的是当存在不配对的观测和干预数据时的情况，每个干预都会改变一个潜在变量的机制。当因果变量完全观测到时，在诚实性假设下，已经开发出了统计一致的算法来识别因果模型。我们在这里展示，即使存在未观测到的因果变量，在给定一般化的忠诚性概念的情况下仍然可以实现可识别性。我们的结果保证了我们可以恢复潜在的因果模型，预测未见组合的干预效果，在无限数据的极限情况下。我们通过开发一种自编码变分贝叶斯算法和ap来实现我们的因果分解框架。

    Causal disentanglement aims to uncover a representation of data using latent variables that are interrelated through a causal model. Such a representation is identifiable if the latent model that explains the data is unique. In this paper, we focus on the scenario where unpaired observational and interventional data are available, with each intervention changing the mechanism of a latent variable. When the causal variables are fully observed, statistically consistent algorithms have been developed to identify the causal model under faithfulness assumptions. We here show that identifiability can still be achieved with unobserved causal variables, given a generalized notion of faithfulness. Our results guarantee that we can recover the latent causal model up to an equivalence class and predict the effect of unseen combinations of interventions, in the limit of infinite data. We implement our causal disentanglement framework by developing an autoencoding variational Bayes algorithm and ap
    
[^13]: 基于去噪扩散隐式模型和重采样的地震数据插值

    Seismic Data Interpolation based on Denoising Diffusion Implicit Models with Resampling. (arXiv:2307.04226v1 [physics.geo-ph])

    [http://arxiv.org/abs/2307.04226](http://arxiv.org/abs/2307.04226)

    本研究提出了一种基于去噪扩散隐式模型和重采样的地震数据插值方法，通过使用多头自注意力和余弦噪声计划，实现了稳定训练生成对抗网络，并提高了已知迹线信息的利用率。

    

    地震数据空间扩展上缺失剖面导致地震数据不完整是地震采集中普遍存在的问题，由于障碍物和经济限制，这严重影响了地下地质结构的成像质量。最近，基于深度学习的地震插值方法取得了令人期待的进展，但稳定训练生成对抗网络并不容易，如果测试和训练中的缺失模式不匹配，性能退化通常是显著的。在本文中，我们提出了一种新的地震去噪扩散隐式模型和重采样方法。模型训练建立在去噪扩散概率模型的基础上，其中U-Net配备了多头自注意力以匹配每个步骤中的噪声。余弦噪声计划作为全局噪声配置，通过加速过度信息的传递来促进已知迹线信息的高度利用。

    The incompleteness of the seismic data caused by missing traces along the spatial extension is a common issue in seismic acquisition due to the existence of obstacles and economic constraints, which severely impairs the imaging quality of subsurface geological structures. Recently, deep learning-based seismic interpolation methods have attained promising progress, while achieving stable training of generative adversarial networks is not easy, and performance degradation is usually notable if the missing patterns in the testing and training do not match. In this paper, we propose a novel seismic denoising diffusion implicit model with resampling. The model training is established on the denoising diffusion probabilistic model, where U-Net is equipped with the multi-head self-attention to match the noise in each step. The cosine noise schedule, serving as the global noise configuration, promotes the high utilization of known trace information by accelerating the passage of the excessive 
    
[^14]: 利用代理分类损失的假设迁移学习

    Hypothesis Transfer Learning with Surrogate Classification Losses. (arXiv:2305.19694v1 [stat.ML])

    [http://arxiv.org/abs/2305.19694](http://arxiv.org/abs/2305.19694)

    本文研究了使用代理分类损失的假设迁移学习的学习理论，通过算法稳定性提供了在温和假设下的学习保证，适用于机器学习算法。

    

    假设迁移学习（HTL）通过允许先前任务（即源任务）向一个新任务（目标任务）转移学习，而无需访问源数据，与领域自适应相对应。事实上，HTL仅依赖于从源数据学习到的假设，免除了大量数据存储的障碍，并提供了巨大的实际利益。因此，HTL对于依赖于大数据的实际应用非常有利。本文通过算法稳定性研究HTL的学习理论，这是一种用于分析机器学习算法的有吸引力的理论框架，特别是在二分类情况下感兴趣。我们的稳定性分析提供了在温和假设下的学习保证。因此，我们得出了几个比以前更紧密的理论界限，这些界限可以实际应用于机器学习算法。

    Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing for a previous task leverage, named the source, into a new one, the target, without requiring access to the source data. Indeed, HTL relies only on a hypothesis learnt from such source data, relieving the hurdle of expansive data storage and providing great practical benefits. Hence, HTL is highly beneficial for real-world applications relying on big data. The analysis of such a method from a theoretical perspective faces multiple challenges, particularly in classification tasks. This paper deals with this problem by studying the learning theory of HTL through algorithmic stability, an attractive theoretical framework for machine learning algorithms analysis. In particular, we are interested in the statistical behaviour of the regularized empirical risk minimizers in the case of binary classification. Our stability analysis provides learning guarantees under mild assumptions. Consequently, we derive several comp
    
[^15]: DoCoFL：用于跨设备联合学习的下行压缩

    DoCoFL: Downlink Compression for Cross-Device Federated Learning. (arXiv:2302.00543v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00543](http://arxiv.org/abs/2302.00543)

    本研究提出了DoCoFL，一种用于跨设备联合学习的下行压缩框架，能够在降低双向带宽的同时保持竞争力的准确性。

    

    许多压缩技术已被提出用于减少联合学习训练过程中的通信开销。然而，这些技术通常用于压缩模型更新，而模型更新在训练过程中会逐渐减少。因此，这些方法不适用于跨设备的下行（即从服务器到客户端）压缩，在这种场景下，异构客户端在训练期间可能只出现一次，因此必须下载模型参数。因此，我们提出了DoCoFL——一个新的用于跨设备下行压缩的框架。重要的是，DoCoFL可以无缝地与许多上行压缩方案结合使用，使其适用于双向压缩。通过广泛的评估，我们证明DoCoFL在显著降低双向带宽的同时，实现了与没有任何压缩的基准模型相当的准确性。

    Many compression techniques have been proposed to reduce the communication overhead of Federated Learning training procedures. However, these are typically designed for compressing model updates, which are expected to decay throughout training. As a result, such methods are inapplicable to downlink (i.e., from the parameter server to clients) compression in the cross-device setting, where heterogeneous clients $\textit{may appear only once}$ during training and thus must download the model parameters. Accordingly, we propose $\textsf{DoCoFL}$ -- a new framework for downlink compression in the cross-device setting. Importantly, $\textsf{DoCoFL}$ can be seamlessly combined with many uplink compression schemes, rendering it suitable for bi-directional compression. Through extensive evaluation, we show that $\textsf{DoCoFL}$ offers significant bi-directional bandwidth reduction while achieving competitive accuracy to that of a baseline without any compression.
    
[^16]: 神经流形的相关变异的线性分类

    Linear Classification of Neural Manifolds with Correlated Variability. (arXiv:2211.14961v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2211.14961](http://arxiv.org/abs/2211.14961)

    本文研究了神经活动的统计和几何属性与性能的关系，并发现了线性可分性的度量与目标表示之间的相关性之间的关系。研究结果揭示了关于相关性和几何性质之间的二元性在分类问题上的问题，并进一步应用到深度网络数据中。

    

    理解神经活动的统计和几何属性与性能的关系是理论神经科学和深度学习中的一个关键问题。在这里，我们计算目标表示之间的相关性如何影响线性可分性的度量。我们发现，对于球形目标流形，引入质心之间的相关性有效地将球体推向一起，而引入轴之间的相关性有效地缩小了它们的半径，揭示了关于相关性和几何性质之间的二元性在分类问题上的问题。然后，我们将我们的结果应用于准确地估计深度网络数据的能力。

    Understanding how the statistical and geometric properties of neural activity relate to performance is a key problem in theoretical neuroscience and deep learning. Here, we calculate how correlations between object representations affect the capacity, a measure of linear separability. We show that for spherical object manifolds, introducing correlations between centroids effectively pushes the spheres closer together, while introducing correlations between the axes effectively shrinks their radii, revealing a duality between correlations and geometry with respect to the problem of classification. We then apply our results to accurately estimate the capacity of deep network data.
    
[^17]: $\Phi$-DVAE: 物理指导的动态变分自编码器用于非结构化数据同化

    $\Phi$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation. (arXiv:2209.15609v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.15609](http://arxiv.org/abs/2209.15609)

    本文提出了一种物理指导的动态变分自编码器 ($\Phi$-DVAE) 用于将非结构化数据同化到物理模型中，解决了传统方法在未知映射情况下无法实现一致模型与数据综合的问题。

    

    在数据同化中，将非结构化数据纳入物理模型是一个具有挑战性的问题。传统方法通常关注具有明确定义观测算子的情况，其函数形式通常被假定为已知。这阻止了这些方法在从数据空间到模型空间的映射未知的配置中实现一致的模型与数据综合。为了解决这些问题，在本文中我们开发了一种物理指导的动态变分自编码器($\Phi$-DVAE)，将多样化的数据流嵌入到由微分方程描述的时变物理系统中。我们的方法结合了一个标准的、可能是非线性的潜在状态空间模型滤波器和一个变分自编码器，将非结构化数据同化到潜在的动态系统中。在我们的示例系统中，非结构化数据采用视频数据和速度场测量的形式，但该方法的适用性足够通用，可以允许任意未知的观测算子。

    Incorporating unstructured data into physical models is a challenging problem that is emerging in data assimilation. Traditional approaches focus on well-defined observation operators whose functional forms are typically assumed to be known. This prevents these methods from achieving a consistent model-data synthesis in configurations where the mapping from data-space to model-space is unknown. To address these shortcomings, in this paper we develop a physics-informed dynamical variational autoencoder ($\Phi$-DVAE) to embed diverse data streams into time-evolving physical systems described by differential equations. Our approach combines a standard, possibly nonlinear, filter for the latent state-space model and a VAE, to assimilate the unstructured data into the latent dynamical system. Unstructured data, in our example systems, comes in the form of video data and velocity field measurements, however the methodology is suitably generic to allow for arbitrary unknown observation operat
    
[^18]: 具有低噪声的差分隐私随机梯度下降法

    Differentially Private Stochastic Gradient Descent with Low-Noise. (arXiv:2209.04188v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.04188](http://arxiv.org/abs/2209.04188)

    本文研究了具有低噪声的差分隐私随机梯度下降法在点问题和成对学习中的性能，并推导出更精确的过剩风险界限。提出的算法基于梯度扰动，具有优化过剩风险率的最佳效果。

    

    现代机器学习算法旨在从数据中提取细粒度信息，以提供准确的预测，但这往往与保护隐私的目标相冲突。本文探讨了开发保护隐私的机器学习算法在确保良好性能的同时保护隐私的实际和理论重要性。我们在随机凸优化设置中，关注差分隐私随机梯度下降（SGD）算法在隐私性和效用性（通过过剩风险界限衡量）方面的性能。具体而言，我们研究了低噪声设置下的点问题，并得出了差分隐私SGD算法更精确的过剩风险界限。在成对学习设置中，我们提出了一种基于梯度扰动的简单差分隐私SGD算法。此外，我们还提出了所提算法的新型效用界限，证明它即使在非光滑情况下也能达到最优的过剩风险率。

    Modern machine learning algorithms aim to extract fine-grained information from data to provide accurate predictions, which often conflicts with the goal of privacy protection. This paper addresses the practical and theoretical importance of developing privacy-preserving machine learning algorithms that ensure good performance while preserving privacy. In this paper, we focus on the privacy and utility (measured by excess risk bounds) performances of differentially private stochastic gradient descent (SGD) algorithms in the setting of stochastic convex optimization. Specifically, we examine the pointwise problem in the low-noise setting for which we derive sharper excess risk bounds for the differentially private SGD algorithm. In the pairwise learning setting, we propose a simple differentially private SGD algorithm based on gradient perturbation. Furthermore, we develop novel utility bounds for the proposed algorithm, proving that it achieves optimal excess risk rates even for non-sm
    
[^19]: 参数化偏微分方程中前向和反向问题的全概率深度模型

    Fully probabilistic deep models for forward and inverse problems in parametric PDEs. (arXiv:2208.04856v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.04856](http://arxiv.org/abs/2208.04856)

    本论文提出了一种基于深度学习和概率建模的全概率深度模型，用于学习参数化偏微分方程中的前向和反向映射。模型通过最大化观察到的零残差的概率来进行训练，不需要独立的训练数据。

    

    我们引入了一种物理驱动的深度潜变量模型（PDDLVM），用于同时学习参数化偏微分方程（PDEs）的参数到解（前向）和解到参数（反向）映射。我们的方法结合了传统的PDE离散化技术、深度神经网络、概率建模和变分推断，形成了一个完全概率一致的框架。在所假设的概率模型中，前向和反向映射均被近似为由深度神经网络参数化的高斯分布。我们假设PDE残差是一个观测到的随机向量，值为零，因此我们将其建模为一个均值为零、用户指定协方差的随机向量。该模型通过最大化观察到零残差的概率（即证据或边际似然）来进行训练，最大化证据下界（ELBO）。因此，该方法不需要任何独立的训练数据。

    We introduce a physics-driven deep latent variable model (PDDLVM) to learn simultaneously parameter-to-solution (forward) and solution-to-parameter (inverse) maps of parametric partial differential equations (PDEs). Our formulation leverages conventional PDE discretization techniques, deep neural networks, probabilistic modelling, and variational inference to assemble a fully probabilistic coherent framework. In the posited probabilistic model, both the forward and inverse maps are approximated as Gaussian distributions with a mean and covariance parameterized by deep neural networks. The PDE residual is assumed to be an observed random vector of value zero, hence we model it as a random vector with a zero mean and a user-prescribed covariance. The model is trained by maximizing the probability, that is the evidence or marginal likelihood, of observing a residual of zero by maximizing the evidence lower bound (ELBO). Consequently, the proposed methodology does not require any independe
    
[^20]: 揭开黑盒子：调控算法决策

    Unpacking the Black Box: Regulating Algorithmic Decisions. (arXiv:2110.03443v2 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2110.03443](http://arxiv.org/abs/2110.03443)

    本文研究如何在代理使用复杂的“黑盒”预测函数进行决策的情况下，对算法决策进行最优调控。研究发现，限制代理使用透明度足够高的预测函数是低效的，而针对激励偏差源头的目标化工具可以提供次优解决方案，从而改善福利。

    

    我们展示了如何在一个代理使用复杂的“黑盒”预测函数进行决策（如贷款、医疗测试或招聘）且委托人在了解代理的黑盒模型方面有限的情况下，最优地调控预测算法。我们证明，只要诱导不足，且最优预测函数足够复杂，将代理限制在足够透明的预测函数中是低效的。算法审计有助于提高福利，但其收益取决于审计工具的设计。许多解释工具倾向于最小化整体信息损失，但这通常是低效的，因为它们集中于解释预测函数的平均行为。针对性的工具，如针对激励偏差源头（如过多的假阳性或种族差异）的工具，可以提供次优解决方案。我们提供了对我们理论的实证支持。

    We show how to optimally regulate prediction algorithms in a world where an agent uses complex 'black-box' prediction functions to make decisions such as lending, medical testing, or hiring, and where a principal is limited in how much she can learn about the agent's black-box model. We show that limiting agents to prediction functions that are simple enough to be fully transparent is inefficient as long as the misalignment is limited and first-best prediction functions are sufficiently complex. Algorithmic audits can improve welfare, but the gains depend on the design of the audit tools. Tools that focus on minimizing overall information loss, the focus of many explainer tools, will generally be inefficient since they focus on explaining the average behavior of the prediction function. Targeted tools that focus on the source of incentive misalignment, e.g., excess false positives or racial disparities, can provide second-best solutions. We provide empirical support for our theoretical
    
[^21]: 对统计歧视作为社会学习失败的研究：一个多臂赌博机方法

    On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach. (arXiv:2010.01079v6 [econ.TH] UPDATED)

    [http://arxiv.org/abs/2010.01079](http://arxiv.org/abs/2010.01079)

    该论文通过使用多臂赌博机模型分析招聘市场中的统计歧视，发现自由放任会导致对少数族裔工人的持续低估问题。研究提出了两种政策解决方案，即混合机制和罗尼法则，表明临时肯定行动可以有效缓解由于数据不足引起的歧视问题。

    

    我们使用一个多臂赌博机模型来分析招聘市场中的统计歧视。目光短浅的公司面临着具有不同可观察特征的工人。工人的技能和特征之间的关联在先验条件下是未知的，因此公司需要学习。自由放任会导致持久性低估：少数族裔工人很少被雇佣，因此低估往往持续存在。即使人口比例稍微不平衡，也经常导致持久性低估。我们提出了两种政策解决方案：一种新颖的补贴规则（混合机制）和罗尼法则。我们的研究结果表明，临时肯定行动可以有效缓解由于数据不足而导致的歧视问题。

    We analyze statistical discrimination in hiring markets using a multi-armed bandit model. Myopic firms face workers arriving with heterogeneous observable characteristics. The association between the worker's skill and characteristics is unknown ex ante; thus, firms need to learn it. Laissez-faire causes perpetual underestimation: minority workers are rarely hired, and therefore, the underestimation tends to persist. Even a marginal imbalance in the population ratio frequently results in perpetual underestimation. We propose two policy solutions: a novel subsidy rule (the hybrid mechanism) and the Rooney Rule. Our results indicate that temporary affirmative actions effectively alleviate discrimination stemming from insufficient data.
    
[^22]: 将人口和控制神经网络交替应用于解决高维度随机均场博弈问题

    Alternating the Population and Control Neural Networks to Solve High-Dimensional Stochastic Mean-Field Games. (arXiv:2002.10113v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2002.10113](http://arxiv.org/abs/2002.10113)

    我们提出了一种交替人口和代理控制神经网络（APAC-Net）来解决高维度随机均场博弈（MFG）问题。通过利用变分原始-对偶结构和神经网络参数化价值和密度函数，我们展示了在高维度MFG问题中的潜力。

    

    我们提出了一种交替人口和代理控制神经网络（APAC-Net）来解决随机均场博弈（MFG）问题。我们的算法针对高维度的MFG实例，这些实例使用现有解决方法无法解决。我们通过两个步骤实现这一目标。首先，我们利用MFG所展示的变分原始-对偶结构，并将其形式化为凸-凹鞍点问题。其次，我们分别通过两个神经网络对价值和密度函数进行参数化。通过这种方式，解决MFG可以被解释为训练生成对抗网络（GAN）的特例。我们展示了我们的方法在高达100维MFG问题上的潜力。

    We present APAC-Net, an alternating population and agent control neural network for solving stochastic mean field games (MFGs). Our algorithm is geared toward high-dimensional instances of MFGs that are beyond reach with existing solution methods. We achieve this in two steps. First, we take advantage of the underlying variational primal-dual structure that MFGs exhibit and phrase it as a convex-concave saddle point problem. Second, we parameterize the value and density functions by two neural networks, respectively. By phrasing the problem in this manner, solving the MFG can be interpreted as a special case of training a generative adversarial network (GAN). We show the potential of our method on up to 100-dimensional MFG problems.
    
[^23]: 用有符号的迭代随机森林识别增强子相关的转录因子结合

    Signed iterative random forests to identify enhancer-associated transcription factor binding. (arXiv:1810.07287v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1810.07287](http://arxiv.org/abs/1810.07287)

    本文介绍了一种有符号的迭代随机森林（siRF）方法，用于推断Drosophila melanogaster中增强子元素周围的转录因子之间的调控相互作用和功能结合签名。

    

    标准的ChIP-seq峰值调用流程旨在区分各个基因组元素的生化可重复信号和背景噪声。然而，仅凭可重复性并不能暗示功能调控（例如增强子活化、可选剪接）。在这里，我们介绍了一种通用的、可解释的机器学习方法：有符号的迭代随机森林（siRF），我们用它来推断Drosophila melanogaster中增强子元素周围的转录因子之间的调控相互作用和功能结合签名。

    Standard ChIP-seq peak calling pipelines seek to differentiate biochemically reproducible signals of individual genomic elements from background noise. However, reproducibility alone does not imply functional regulation (e.g., enhancer activation, alternative splicing). Here we present a general-purpose, interpretable machine learning method: signed iterative random forests (siRF), which we use to infer regulatory interactions among transcription factors and functional binding signatures surrounding enhancer elements in Drosophila melanogaster.
    

