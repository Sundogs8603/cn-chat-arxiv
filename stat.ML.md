# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Action-State Dependent Dynamic Model Selection.](http://arxiv.org/abs/2307.04754) | 本文提出了一种动态模型选择的方法，该方法能够根据不同的状态选择最优的模型，并通过强化学习算法对动态规划问题进行近似和估计。实验结果表明，在重新平衡成本下切换投资组合模型时，使用宏观经济信息的性能优于事后选择最佳投资组合模型。 |
| [^2] | [Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback.](http://arxiv.org/abs/2307.04749) | 本文提出了一种划分、评估和细化的方法来改善文本到图像对齐。通过分解复杂的提示并使用VQA模型进行测量，最终得到文本到图像的对齐分数。 |
| [^3] | [Episodic Gaussian Process-Based Learning Control with Vanishing Tracking Errors.](http://arxiv.org/abs/2307.04415) | 本研究提出了一种基于时序高斯过程的学习控制方法，通过推导预测误差边界以及一种基于内核的数据密度度量，实现了时变的跟踪精度保证，并展示了跟踪误差的消失。 |
| [^4] | [ARK: Robust Knockoffs Inference with Coupling.](http://arxiv.org/abs/2307.04400) | 本研究探讨了在特征分布被错误估计或估计的情况下，通过耦合模型-X Knockoffs过程与近似Knockoffs过程，实现了在目标水平上的鲁棒的FDR或FWER控制。 |
| [^5] | [Policy Finetuning in Reinforcement Learning via Design of Experiments using Offline Data.](http://arxiv.org/abs/2307.04354) | 本文提出了一种算法，利用离线数据集设计单一的非反应性策略进行探索，并通过理论分析对最终策略的质量进行了量化。 |
| [^6] | [On Sufficient Graphical Models.](http://arxiv.org/abs/2307.04353) | 本研究引入了一种基于非线性充分降维技术的充分图模型，该模型不依赖高维核来描述条件独立性，并且避免了高维核带来的维度灾难。与现有方法相比，在高斯分布或同时高斯分布假设下，我们的方法表现更好。 |
| [^7] | [Seismic Data Interpolation based on Denoising Diffusion Implicit Models with Resampling.](http://arxiv.org/abs/2307.04226) | 本研究提出了一种基于去噪扩散隐式模型和重采样的地震数据插值方法，通过使用多头自注意力和余弦噪声计划，实现了稳定训练生成对抗网络，并提高了已知迹线信息的利用率。 |
| [^8] | [Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory.](http://arxiv.org/abs/2307.04204) | 本文通过实证研究证明了梯度下降轨迹上的稳定边缘现象，并且对于特定的网络结构进行了轨迹对齐分析，建立了渐进尖锐化和稳定边缘现象，扩展了当前文献的研究结果。 |
| [^9] | [On the sample complexity of estimation in logistic regression.](http://arxiv.org/abs/2307.04191) | 本文研究了逻辑回归模型在标准正态协变量下的参数估计样本复杂度，发现样本复杂度曲线在逆温度方面有两个转折点，明确划分了低、中和高温度区域。 |
| [^10] | [A generative flow for conditional sampling via optimal transport.](http://arxiv.org/abs/2307.04102) | 本论文提出了一种通过解决最优输运问题来描述条件分布的非参数生成模型，该模型使用块三角输运映射将参考样本迭代映射到目标样本，从而克服了参数偏差和基于梯度的优化器的限制。 |
| [^11] | [Bidirectional Attention as a Mixture of Continuous Word Experts.](http://arxiv.org/abs/2307.04057) | 双向注意力模型具有混合专家权重，类似于连续词袋模型（CBOW）的统计模型，它在大型语言模型中起到了重要作用。 |
| [^12] | [Manifold Filter-Combine Networks.](http://arxiv.org/abs/2307.04056) | 这篇论文介绍了一类称为流形滤波-组合网络的大型流形神经网络。作者提出了一种基于构建数据驱动图的方法来实现这种网络，并提供了收敛到连续极限的充分条件，其收敛速度不依赖于滤波器数量。 |
| [^13] | [Contextual Dynamic Pricing with Strategic Buyers.](http://arxiv.org/abs/2307.04055) | 本文研究了具有策略性买家的情境动态定价问题，提出了一种策略动态定价策略，将买家的策略行为纳入在线学习中，以最大化卖方的累计收益。 |
| [^14] | [Sup-Norm Convergence of Deep Neural Network Estimator for Nonparametric Regression by Adversarial Training.](http://arxiv.org/abs/2307.04042) | 我们展示了使用对抗训练的深度神经网络估计器在非参数回归中的超范数收敛性。我们发现普通的对抗训练使得神经估计器不一致，但通过所提出的带修正的对抗训练，深度神经网络估计器在超范数意义下达到最优速率。我们的实验证实了这些理论发现。 |
| [^15] | [Fast Empirical Scenarios.](http://arxiv.org/abs/2307.03927) | 该论文提出了两种快速的经验场景提取算法，一种识别之前未观察到的场景并提供场景的协方差矩阵表示，另一种从已实现的世界状态中选择重要的数据点，并与高阶样本矩一致，这些算法计算效率高且适用于一致的基于场景的建模和高维数值积分。 |
| [^16] | [On Regularization and Inference with Label Constraints.](http://arxiv.org/abs/2307.03886) | 本文研究了在机器学习中将先验知识和符号规则以标签约束的形式表达的方法。通过比较正则化和约束推理两种常见的编码标签约束的策略，发现正则化缩小了泛化差距但引入了对次优模型的偏置，而约束推理通过纠正模型的违规行为将违规行为转化为优势。进一步探索了将这两种方法结合使用的可能，并提出了用约束推理来补偿正则化引入的偏置的条件，旨在提高模型复杂性和最优风险。 |
| [^17] | [Optimal Learners for Realizable Regression: PAC Learning and Online Learning.](http://arxiv.org/abs/2307.03848) | 本论文研究了可实现回归问题的PAC学习和在线学习的统计复杂度，并提出了对于可学习性的必要条件和充分条件。 |
| [^18] | [URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates.](http://arxiv.org/abs/2307.03810) | URL基准是一个评估预训练模型可转移性和不确定性估计的方式，研究发现专注于表示本身不确定性或直接估计预测风险的方法效果优于基于概率的方法。 |
| [^19] | [Online Learning and Solving Infinite Games with an ERM Oracle.](http://arxiv.org/abs/2307.01689) | 这项工作提出了一种仅依赖ERM预言机调用的在线学习算法，该算法在可实现情况下具有有限的遗憾，并在不可知情况下具有亚线性增长的遗憾。同时，还提供了类似的结果用于非参数博弈环境中的学习算法，即仅依赖最佳响应预言机的学习算法，并收敛到近似极小-极大均衡点。 |
| [^20] | [Numerical Data Imputation for Multimodal Data Sets: A Probabilistic Nearest-Neighbor Kernel Density Approach.](http://arxiv.org/abs/2306.16906) | 本论文介绍了一种新的数值数据填补方法，通过将最近邻估计和高斯核密度估计结合，能够有效处理多模态数据集中的缺失值，并提供比当前方法更高的概率估计。 |
| [^21] | [Agent market orders representation through a contrastive learning approach.](http://arxiv.org/abs/2306.05987) | 通过对比学习方法，本研究构建了一个自监督学习模型，用于学习代理市场订单的表示。进一步地，我们使用K均值聚类算法对代理订单的学习表示向量进行聚类，以确定每个簇中的不同行为类型。 |
| [^22] | [Decentralized SGD and Average-direction SAM are Asymptotically Equivalent.](http://arxiv.org/abs/2306.02913) | 分散SGD和平均方向SAM在渐近意义下是等价的，D-SGD表现出梯度平滑效应和锐度正则化效应，而且可以提高后验评估，并证明了潜在的泛化能力 |
| [^23] | [Conformal Prediction with Large Language Models for Multi-Choice Question Answering.](http://arxiv.org/abs/2305.18404) | 本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。 |
| [^24] | [SKI to go Faster: Accelerating Toeplitz Neural Networks via Asymmetric Kernels.](http://arxiv.org/abs/2305.09028) | 本论文提出使用非对称核（asymmetric kernels）实现Toeplitz神经网络（TNNs）的加速，通过稀疏加低秩Toeplitz矩阵分解、小型1D卷积和替换相对位置编码器（RPE）多层感知器（MLP）实现O（n）复杂度，针对因果模型，提出了“快速”因果屏蔽来抵消这种方法的限制。 |
| [^25] | [Variational Bayes Made Easy.](http://arxiv.org/abs/2304.14251) | 该论文提出了一个三步骤方法，简化了变分贝叶斯近似推断方法的推导过程。 |
| [^26] | [Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches.](http://arxiv.org/abs/2303.11582) | 本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。 |
| [^27] | [Approximately Stationary Bandits with Knapsacks.](http://arxiv.org/abs/2302.14686) | 带有背包的掠夺者问题在随机和敌对情况下存在巨大的差距，尤其是在敌对情况下，当预算更加紧缺时保证性能变得更差。 |
| [^28] | [Adaptive Sparse Gaussian Process.](http://arxiv.org/abs/2302.10325) | 这篇论文提出了第一个自适应稀疏高斯过程，能够在非平稳环境中进行高效的模型更新，并具有快速的推理收敛性。 |
| [^29] | [Spatially heterogeneous learning by a deep student machine.](http://arxiv.org/abs/2302.07419) | 本论文研究了一种深度学生机器的教师-学生设置，通过学生机器的集合来研究由具有大量可调参数的DNN的监督学习。研究表明DNN的学习在网络空间中相当异质。 |
| [^30] | [Unbinned Profiled Unfolding.](http://arxiv.org/abs/2302.05390) | 本文提出了一种新的基于机器学习的展开方法，可以得到无组合的差分截面并且可以剖析干扰参数。 |
| [^31] | [Generalization Bounds with Data-dependent Fractal Dimensions.](http://arxiv.org/abs/2302.02766) | 这项研究提出了基于数据依赖的分形维度的泛化界限，不需要Lipschitz假设，并能控制泛化误差和互信息项。 |
| [^32] | [Local transfer learning from one data space to another.](http://arxiv.org/abs/2302.00160) |  |
| [^33] | [Learning-Rate-Free Learning by D-Adaptation.](http://arxiv.org/abs/2301.07733) | D-Adaptation是一种可以自动设置学习率的方法，针对最小化凸性Lipschitz函数，用于实现最优收敛速率，而无需超参数，也无需额外对数因子改进，能够在各种机器学习问题中自动匹配手动调整的学习率。 |
| [^34] | [Label Alignment Regularization for Distribution Shift.](http://arxiv.org/abs/2211.14960) | 这篇论文提出了一种用于无监督领域自适应的正则化方法，通过鼓励目标域中的预测与其前几个奇异向量对齐来实现。与传统方法不同的是，这个方法通过正则化分类器与无监督目标数据对齐，而不是正则化表示。通过消除对最优联合风险假设的依赖，该方法展示了很好的效果。 |
| [^35] | [On the Pointwise Behavior of Recursive Partitioning and Its Implications for Heterogeneous Causal Effect Estimation.](http://arxiv.org/abs/2211.10805) | 本文质疑了递归划分在决策树学习中的应用，通过证明它们可能无法实现一致范数的多项式收敛速率。我们提出了随机森林来解决这个问题，将低性能的树转化为几乎最优的过程，但代价是失去了解释性，并引入了两个额外的调整参数。 |
| [^36] | [Preferential Subsampling for Stochastic Gradient Langevin Dynamics.](http://arxiv.org/abs/2210.16189) | 本文提出一种偏好子采样的方法来对随机梯度Langevin动力学进行优化，通过使用非均匀概率分布子采样对具有更大影响的数据点进行加权，同时还通过自适应调整子采样大小来提高梯度估计的准确性。实验证明这种方法可以在减少子采样数的同时保持相同的精度水平。 |
| [^37] | [Conditionally Risk-Averse Contextual Bandits.](http://arxiv.org/abs/2210.13573) | 设计出了第一个具有在线遗憾保证的风险厌恶的上下文赌博算法，并在多个实验场景中展示了其适用性。 |
| [^38] | [Bagging in overparameterized learning: Risk characterization and risk monotonization.](http://arxiv.org/abs/2210.11445) | 本文研究了过度参数化学习中Bagging预测器的风险问题，并提出了通用策略来分析Bagging预测器的风险。通过具体化策略，我们得出了Bagging Ridge和Ridgeless预测器的精确渐近风险，并提供了一种交叉验证过程来选择Bagging的最佳子样本大小，以消除风险的非单调行为。 |
| [^39] | [Compositional Score Modeling for Simulation-based Inference.](http://arxiv.org/abs/2209.14249) | 本研究提出了一种基于条件评分建模的方法，可以有效处理基于多个观测条件下得到的后验分布，同时具有高样本效率和聚合多个观测值的优势。 |
| [^40] | [DynDepNet: Learning Time-Varying Dependency Structures from fMRI Data via Dynamic Graph Structure Learning.](http://arxiv.org/abs/2209.13513) | DynDepNet是一种学习fMRI数据中时变依赖结构的新方法，在性别分类任务中取得了最先进的结果。 |
| [^41] | [The Value of Out-of-Distribution Data.](http://arxiv.org/abs/2208.10967) | 不同分布的数据可以对任务的泛化误差产生非单调的影响，使用少量不同分布的数据进行训练是有价值的。 |
| [^42] | [Survival Kernets: Scalable and Interpretable Deep Kernel Survival Analysis with an Accuracy Guarantee.](http://arxiv.org/abs/2206.10477) | Survival Kernets 是一种可扩展且可解释的深度核生存分析模型，能够在大规模数据集上进行模型解释和理论分析。它利用核函数估计个体的生存分布，通过训练集压缩方案进行数据分簇，因此具有较高的可视化能力和预测准确性保证。该模型在特定情况下的预测生存分布误差界限最优，且在测试时具有可扩展性。 |
| [^43] | [DORA: Exploring outlier representations in Deep Neural Networks.](http://arxiv.org/abs/2206.04530) | 本文提出了一种名为DORA的数据不可知框架，用于分析深度神经网络中的表征空间，并可以识别不符合人类直观认知的表征。 |
| [^44] | [Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting.](http://arxiv.org/abs/2205.14568) | 本研究提出了一种名为Cal-PIT的方法，通过学习一个概率-概率映射，解决了预测分布的诊断和校准问题，来实现有条件校准。 |
| [^45] | [DDAC-SpAM: A Distributed Algorithm for Fitting High-dimensional Sparse Additive Models with Feature Division and Decorrelation.](http://arxiv.org/abs/2205.07932) | DDAC-SpAM是一种在高维稀疏加性模型中利用特征划分和去相关的分布式算法。去相关操作使得每个局部估计器能够恢复每个加性组分的稀疏模式，同时不对变量之间的相关性结构施加严格的约束。该算法在理论和实证分析中证明了其有效性和效率，为拟合稀疏加性模型提供了实际解决方案。 |
| [^46] | [Out-of-distribution generalization for learning quantum dynamics.](http://arxiv.org/abs/2204.10268) | 该论文在量子机器学习中证明了学习未知酉的越域泛化能力，并提出了使用乘积态来学习酉对纠缠态的作用，从而推动了在近期量子硬件上学习量子动力学的前景，并为经典和量子电路的编译提供了新的方法。 |
| [^47] | [A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit.](http://arxiv.org/abs/2202.05767) | 本研究通过关联线性热方程的解，得到了对称双臂伯努利赌博机问题的minmax最优遗憾和伪遗憾的领先项。新的结果改进了先前的研究，并提供了新的非渐近边界。 |
| [^48] | [Consistent Collaborative Filtering via Tensor Decomposition.](http://arxiv.org/abs/2201.11936) | 本文提出了一种通过张量分解来实现一致协同过滤的新模型，它能够扩展传统的用户-物品偏好计算方法，使得在评估物品相对偏好时产生物品之间的交互，具有潜在的非线性态度。 |
| [^49] | [Fast Interpretable Greedy-Tree Sums.](http://arxiv.org/abs/2201.11931) | FIGS是一种快速可解释的贪婪树求和算法，通过将逻辑规则与加法相结合，能够适应加性结构同时保持高度可解释性。在真实数据集上的实验表明，FIGS实现了最先进的预测性能，并在高风险领域如医学中展示了其实用性。 |
| [^50] | [Contextual Combinatorial Multi-output GP Bandits with Group Constraints.](http://arxiv.org/abs/2111.14778) | 这项研究提出了一种应用于联邦多臂赌博问题的新算法，该算法通过选择一组基础臂来最大化超级臂奖励，并同时满足组奖励约束。算法利用两输出高斯过程模型，为每个基础臂的结果提供更大的灵活性。 |
| [^51] | [GFlowNet Foundations.](http://arxiv.org/abs/2111.09266) | GFlowNets是一种生成流网络方法，用于在主动学习环境中采样多样化的候选集。它们具有估计联合概率分布和边际分布的能力，可以表示关于复合对象（如集合和图）的分布。通过单次训练的生成传递，GFlowNets分摊了计算昂贵的MCMC方法的工作。 |
| [^52] | [Sparse MoEs meet Efficient Ensembles.](http://arxiv.org/abs/2110.03360) | 本论文研究了神经网络集成和稀疏专家混合的结合，提出了一种名为E$^3$的高效稀疏MoEs集成方法，在减少计算复杂度的同时取得了在准确性、鲁棒性和不确定性方面的改进。 |
| [^53] | [Low-rank Tensor Estimation via Riemannian Gauss-Newton: Statistical Optimality and Second-Order Convergence.](http://arxiv.org/abs/2104.12031) | 本文提出了一种通过Riemannian Gauss-Newton方法进行低秩张量估计的方法，并证明了其在噪声环境下的局部二次收敛性和统计最优性。 |
| [^54] | [Achieving Efficiency in Black Box Simulation of Distribution Tails with Self-structuring Importance Samplers.](http://arxiv.org/abs/2102.07060) | 本文提出了一种新颖的自结构重要性采样方法，通过复制在较不罕见的样本中观察到的浓度特性，隐式诱导出一种有效的IS分布，从而提高了估计性能度量的分布尾部的效率。 |
| [^55] | [Unsupervised tree boosting for learning probability distributions.](http://arxiv.org/abs/2101.11083) | 本文提出了一种无监督树提升算法，通过拟合叠加树集合来推断独立同分布样本的潜在采样分布，其中关键是引入了新的概率分布上的"加法"概念和与之相对应的"剩余化"操作。这些概念通过一维累积分布函数（CDF）变换和组合自然而然地出现，并扩展到了多元设置中。 |
| [^56] | [Optimal Learning for Structured Bandits.](http://arxiv.org/abs/2007.07302) | 本文研究了结构化多臂赌博机问题，在存在结构信息的情况下，设计了一种能够利用结构信息以最小化后悔的算法。 |
| [^57] | [Testing Robustness Against Unforeseen Adversaries.](http://arxiv.org/abs/1908.08016) | 该论文提出了18种新的对抗攻击，并使用这些攻击创建了一个用于评估对各种未预料到的对手的鲁棒性的新基准。作者还发现了一系列防御策略，可以帮助克服训练期间未考虑到的对手的泛化差距。该研究的结果将为研究现实世界最坏情况下的鲁棒性提供有用工具，促进开发更强大的防御措施。 |

# 详细

[^1]: 动作状态相关的动态模型选择

    Action-State Dependent Dynamic Model Selection. (arXiv:2307.04754v1 [cs.LG])

    [http://arxiv.org/abs/2307.04754](http://arxiv.org/abs/2307.04754)

    本文提出了一种动态模型选择的方法，该方法能够根据不同的状态选择最优的模型，并通过强化学习算法对动态规划问题进行近似和估计。实验结果表明，在重新平衡成本下切换投资组合模型时，使用宏观经济信息的性能优于事后选择最佳投资组合模型。

    

    在世界的某些状态下，多个模型中的一个可能只在其中某些状态下表现最佳。而在模型之间的切换也可能代价高昂。在这种情况下，寻找一种能够动态选择模型的过程需要解决一个复杂的估计问题和动态规划问题。本文使用强化学习算法来从数据中近似和估计这个动态规划问题的最优解。实验结果表明，该算法能够一致地估计出根据一组协变量选择不同模型的最优策略。具体应用方面，例如在重新平衡成本下切换不同投资组合模型，使用宏观经济信息进行决策。通过一组宏观经济变量和价格数据，经验应用于上述投资组合问题表现出比事后选择最佳投资组合模型更优的性能。

    A model among many may only be best under certain states of the world. Switching from a model to another can also be costly. Finding a procedure to dynamically choose a model in these circumstances requires to solve a complex estimation procedure and a dynamic programming problem. A Reinforcement learning algorithm is used to approximate and estimate from the data the optimal solution to this dynamic programming problem. The algorithm is shown to consistently estimate the optimal policy that may choose different models based on a set of covariates. A typical example is the one of switching between different portfolio models under rebalancing costs, using macroeconomic information. Using a set of macroeconomic variables and price data, an empirical application to the aforementioned portfolio problem shows superior performance to choosing the best portfolio model with hindsight.
    
[^2]: 划分、评估和细化：通过迭代VQA反馈评估和改善文本到图像对齐

    Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback. (arXiv:2307.04749v1 [cs.CV])

    [http://arxiv.org/abs/2307.04749](http://arxiv.org/abs/2307.04749)

    本文提出了一种划分、评估和细化的方法来改善文本到图像对齐。通过分解复杂的提示并使用VQA模型进行测量，最终得到文本到图像的对齐分数。

    

    随着潜在扩散模型的最新出现，以文本为条件的图像生成领域取得了前所未有的进展。然而，尽管具有显著性，但是随着文本输入的复杂性增加，最先进的扩散模型仍可能无法生成准确传达给定提示语义的图像。此外，观察到这种不对齐往往被预训练的多模型（如CLIP）未能检测到。为了解决这些问题，在本文中，我们探索了一种简单且有效的分解方法来评估和改善文本到图像对齐。具体而言，我们首先引入了一种分解对齐分数，它将复杂提示分解为一组不相交的断言。然后，使用VQA模型来测量每个断言与生成的图像的对齐情况。最后，将不同断言的对齐分数合并后，得到最终的文本到图像对齐分数。

    The field of text-conditioned image generation has made unparalleled progress with the recent advent of latent diffusion models. While remarkable, as the complexity of given text input increases, the state-of-the-art diffusion models may still fail in generating images which accurately convey the semantics of the given prompt. Furthermore, it has been observed that such misalignments are often left undetected by pretrained multi-modal models such as CLIP. To address these problems, in this paper we explore a simple yet effective decompositional approach towards both evaluation and improvement of text-to-image alignment. In particular, we first introduce a Decompositional-Alignment-Score which given a complex prompt decomposes it into a set of disjoint assertions. The alignment of each assertion with generated images is then measured using a VQA model. Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score. Experimenta
    
[^3]: 基于时序高斯过程的学习控制，实现消失的跟踪误差

    Episodic Gaussian Process-Based Learning Control with Vanishing Tracking Errors. (arXiv:2307.04415v1 [eess.SY])

    [http://arxiv.org/abs/2307.04415](http://arxiv.org/abs/2307.04415)

    本研究提出了一种基于时序高斯过程的学习控制方法，通过推导预测误差边界以及一种基于内核的数据密度度量，实现了时变的跟踪精度保证，并展示了跟踪误差的消失。

    

    随着技术系统的复杂性增加，往往无法获得准确的第一原理模型。通过监督机器学习可以从测量数据中推断模型，高斯过程回归特别适用于此目的，因为它具有高的数据效率和明确的不确定性表示，可以推导出预测误差边界。这些误差边界已被用于展示不同控制方法的跟踪精度保证，但其直接依赖于训练数据通常不明确。我们通过推导基于贝叶斯的高斯过程回归预测误差边界来解决此问题，并展示其随着一种基于内核的数据密度度量的增长而减小。基于预测误差边界，我们证明了学习到的高斯过程模型作为未知非线性的反馈补偿，可以实现时变的跟踪精度保证，并展示了随着时间增加而消失的跟踪误差。

    Due to the increasing complexity of technical systems, accurate first principle models can often not be obtained. Supervised machine learning can mitigate this issue by inferring models from measurement data. Gaussian process regression is particularly well suited for this purpose due to its high data-efficiency and its explicit uncertainty representation, which allows the derivation of prediction error bounds. These error bounds have been exploited to show tracking accuracy guarantees for a variety of control approaches, but their direct dependency on the training data is generally unclear. We address this issue by deriving a Bayesian prediction error bound for GP regression, which we show to decay with the growth of a novel, kernel-based measure of data density. Based on the prediction error bound, we prove time-varying tracking accuracy guarantees for learned GP models used as feedback compensation of unknown nonlinearities, and show to achieve vanishing tracking error with increasi
    
[^4]: ARK: 鲁棒的耦合型Robust Knockoffs推理方法

    ARK: Robust Knockoffs Inference with Coupling. (arXiv:2307.04400v1 [stat.ME])

    [http://arxiv.org/abs/2307.04400](http://arxiv.org/abs/2307.04400)

    本研究探讨了在特征分布被错误估计或估计的情况下，通过耦合模型-X Knockoffs过程与近似Knockoffs过程，实现了在目标水平上的鲁棒的FDR或FWER控制。

    

    本研究通过在特征分布被错误估计或估计的情况下，理论上研究了实际实现的近似Knockoffs算法的特征选择性能，其中我们将该算法称为近似Knockoffs（ARK）过程。我们的理论分析关键技术是将近似Knockoffs过程与模型-X Knockoffs过程耦合，以使这两个过程中的随机变量在实现中接近。我们证明了如果存在这样的耦合模型-X Knockoffs过程，近似Knockoffs过程可以在目标水平上达到渐近的FDR或FWER控制。我们展示了三种具体的构建方法。

    We investigate the robustness of the model-X knockoffs framework with respect to the misspecified or estimated feature distribution. We achieve such a goal by theoretically studying the feature selection performance of a practically implemented knockoffs algorithm, which we name as the approximate knockoffs (ARK) procedure, under the measures of the false discovery rate (FDR) and family wise error rate (FWER). The approximate knockoffs procedure differs from the model-X knockoffs procedure only in that the former uses the misspecified or estimated feature distribution. A key technique in our theoretical analyses is to couple the approximate knockoffs procedure with the model-X knockoffs procedure so that random variables in these two procedures can be close in realizations. We prove that if such coupled model-X knockoffs procedure exists, the approximate knockoffs procedure can achieve the asymptotic FDR or FWER control at the target level. We showcase three specific constructions of s
    
[^5]: 强化学习中利用离线数据通过实验设计进行策略微调

    Policy Finetuning in Reinforcement Learning via Design of Experiments using Offline Data. (arXiv:2307.04354v1 [cs.LG])

    [http://arxiv.org/abs/2307.04354](http://arxiv.org/abs/2307.04354)

    本文提出了一种算法，利用离线数据集设计单一的非反应性策略进行探索，并通过理论分析对最终策略的质量进行了量化。

    

    在强化学习的一些应用中，已经有一份预先收集好的经验数据集，但也可以获取一些额外的在线数据以帮助提高策略的质量。然而，更倾向于使用单一的非反应性探索策略收集额外数据，以避免切换策略带来的工程成本。在本文中，我们提出了一个具有可证明保证的算法，可以利用离线数据集设计一个单一的非反应性策略进行探索。我们对算法进行了理论分析，并将最终策略的质量作为原始数据集的局部覆盖和额外数据收集量的函数进行了度量。

    In some applications of reinforcement learning, a dataset of pre-collected experience is already available but it is also possible to acquire some additional online data to help improve the quality of the policy. However, it may be preferable to gather additional data with a single, non-reactive exploration policy and avoid the engineering costs associated with switching policies.  In this paper we propose an algorithm with provable guarantees that can leverage an offline dataset to design a single non-reactive policy for exploration. We theoretically analyze the algorithm and measure the quality of the final policy as a function of the local coverage of the original dataset and the amount of additional data collected.
    
[^6]: 关于充分图模型的研究

    On Sufficient Graphical Models. (arXiv:2307.04353v1 [stat.ML])

    [http://arxiv.org/abs/2307.04353](http://arxiv.org/abs/2307.04353)

    本研究引入了一种基于非线性充分降维技术的充分图模型，该模型不依赖高维核来描述条件独立性，并且避免了高维核带来的维度灾难。与现有方法相比，在高斯分布或同时高斯分布假设下，我们的方法表现更好。

    

    我们应用最近发展的非线性充分降维技术来评估条件独立性，并引入了一种充分图模型。该图模型是非参数的，因为它不对分布做出假设，如高斯分布或同时高斯分布。然而，与完全非参数的图模型不同，我们的图模型基于给定一组减少维度的充分预测变量的条件独立性。通过这种方式，我们避免了高维核所带来的维度灾难。我们还发展了估计的总体级性质、收敛速度和变量选择一致性。通过模拟比较和对DREAM 4挑战数据集的分析，我们证明了我们的方法在高斯分布或同时高斯分布假设时优于现有方法。

    We introduce a sufficient graphical model by applying the recently developed nonlinear sufficient dimension reduction techniques to the evaluation of conditional independence. The graphical model is nonparametric in nature, as it does not make distributional assumptions such as the Gaussian or copula Gaussian assumptions. However, unlike a fully nonparametric graphical model, which relies on the high-dimensional kernel to characterize conditional independence, our graphical model is based on conditional independence given a set of sufficient predictors with a substantially reduced dimension. In this way we avoid the curse of dimensionality that comes with a high-dimensional kernel. We develop the population-level properties, convergence rate, and variable selection consistency of our estimate. By simulation comparisons and an analysis of the DREAM 4 Challenge data set, we demonstrate that our method outperforms the existing methods when the Gaussian or copula Gaussian assumptions are v
    
[^7]: 基于去噪扩散隐式模型和重采样的地震数据插值

    Seismic Data Interpolation based on Denoising Diffusion Implicit Models with Resampling. (arXiv:2307.04226v1 [physics.geo-ph])

    [http://arxiv.org/abs/2307.04226](http://arxiv.org/abs/2307.04226)

    本研究提出了一种基于去噪扩散隐式模型和重采样的地震数据插值方法，通过使用多头自注意力和余弦噪声计划，实现了稳定训练生成对抗网络，并提高了已知迹线信息的利用率。

    

    地震数据空间扩展上缺失剖面导致地震数据不完整是地震采集中普遍存在的问题，由于障碍物和经济限制，这严重影响了地下地质结构的成像质量。最近，基于深度学习的地震插值方法取得了令人期待的进展，但稳定训练生成对抗网络并不容易，如果测试和训练中的缺失模式不匹配，性能退化通常是显著的。在本文中，我们提出了一种新的地震去噪扩散隐式模型和重采样方法。模型训练建立在去噪扩散概率模型的基础上，其中U-Net配备了多头自注意力以匹配每个步骤中的噪声。余弦噪声计划作为全局噪声配置，通过加速过度信息的传递来促进已知迹线信息的高度利用。

    The incompleteness of the seismic data caused by missing traces along the spatial extension is a common issue in seismic acquisition due to the existence of obstacles and economic constraints, which severely impairs the imaging quality of subsurface geological structures. Recently, deep learning-based seismic interpolation methods have attained promising progress, while achieving stable training of generative adversarial networks is not easy, and performance degradation is usually notable if the missing patterns in the testing and training do not match. In this paper, we propose a novel seismic denoising diffusion implicit model with resampling. The model training is established on the denoising diffusion probabilistic model, where U-Net is equipped with the multi-head self-attention to match the noise in each step. The cosine noise schedule, serving as the global noise configuration, promotes the high utilization of known trace information by accelerating the passage of the excessive 
    
[^8]: 轨迹对齐：通过分叉理论理解稳定边缘现象

    Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory. (arXiv:2307.04204v1 [cs.LG])

    [http://arxiv.org/abs/2307.04204](http://arxiv.org/abs/2307.04204)

    本文通过实证研究证明了梯度下降轨迹上的稳定边缘现象，并且对于特定的网络结构进行了轨迹对齐分析，建立了渐进尖锐化和稳定边缘现象，扩展了当前文献的研究结果。

    

    Cohen等人（2021）通过实证研究梯度下降（GD）轨迹上损失Hessian的最大特征值（即锐度），观察到一种称为稳定边缘（EoS）的现象。锐度在培训的早期阶段增加（称为渐进尖锐化），最终接近阈值$2/\text{(步长)}$附近停滞。本文通过实证研究首先证明了当EoS现象发生时，不同的GD轨迹（经过适当的参数化）在一个特定的分叉图上对齐，而与初始化无关。然后，我们对一个二层全连接线性网络和一个使用单个数据点训练的单神经元非线性网络严格证明了这种轨迹对齐现象。我们的轨迹对齐分析建立了渐进尖锐化和EoS现象，涵盖并扩展了最近文献中的研究结果。

    Cohen et al. (2021) empirically study the evolution of the largest eigenvalue of the loss Hessian, also known as sharpness, along the gradient descent (GD) trajectory and observe a phenomenon called the Edge of Stability (EoS). The sharpness increases at the early phase of training (referred to as progressive sharpening), and eventually saturates close to the threshold of $2 / \text{(step size)}$. In this paper, we start by demonstrating through empirical studies that when the EoS phenomenon occurs, different GD trajectories (after a proper reparameterization) align on a specific bifurcation diagram independent of initialization. We then rigorously prove this trajectory alignment phenomenon for a two-layer fully-connected linear network and a single-neuron nonlinear network trained with a single data point. Our trajectory alignment analysis establishes both progressive sharpening and EoS phenomena, encompassing and extending recent findings in the literature.
    
[^9]: 关于逻辑回归中参数估计的样本复杂度研究

    On the sample complexity of estimation in logistic regression. (arXiv:2307.04191v1 [math.ST])

    [http://arxiv.org/abs/2307.04191](http://arxiv.org/abs/2307.04191)

    本文研究了逻辑回归模型在标准正态协变量下的参数估计样本复杂度，发现样本复杂度曲线在逆温度方面有两个转折点，明确划分了低、中和高温度区域。

    

    逻辑回归模型是噪声二元分类问题中最常见的数据生成模型之一。本文研究了在标准正态协变量下，以$\ell_2$误差为限，估计逻辑回归模型参数的样本复杂度，考虑了维度和逆温度的影响。逆温度控制了数据生成过程中的信噪比。虽然逻辑回归的广义界限和渐近性能已经有了深入研究，但关于参数估计的非渐近样本复杂度在之前的分析中没有讨论其与误差和逆温度的依赖关系。我们展示了样本复杂度曲线在逆温度方面具有两个转折点（或临界点），明确划分了低、中和高温度区域。

    The logistic regression model is one of the most popular data generation model in noisy binary classification problems. In this work, we study the sample complexity of estimating the parameters of the logistic regression model up to a given $\ell_2$ error, in terms of the dimension and the inverse temperature, with standard normal covariates. The inverse temperature controls the signal-to-noise ratio of the data generation process. While both generalization bounds and asymptotic performance of the maximum-likelihood estimator for logistic regression are well-studied, the non-asymptotic sample complexity that shows the dependence on error and the inverse temperature for parameter estimation is absent from previous analyses. We show that the sample complexity curve has two change-points (or critical points) in terms of the inverse temperature, clearly separating the low, moderate, and high temperature regimes.
    
[^10]: 一种通过最优输运进行条件采样的生成流

    A generative flow for conditional sampling via optimal transport. (arXiv:2307.04102v1 [stat.ML])

    [http://arxiv.org/abs/2307.04102](http://arxiv.org/abs/2307.04102)

    本论文提出了一种通过解决最优输运问题来描述条件分布的非参数生成模型，该模型使用块三角输运映射将参考样本迭代映射到目标样本，从而克服了参数偏差和基于梯度的优化器的限制。

    

    条件分布的采样是贝叶斯推断和密度估计的基本任务。生成模型，如归一化流和生成对抗网络，通过学习将简单参考模型（如标准高斯分布）推向目标分布的输运映射，来描述条件分布。虽然这些方法成功地描述了许多非高斯问题，但它们的性能通常受到参数偏差和基于梯度的（对抗性）优化器学习这些转换的可靠性的限制。本文提出了一种非参数生成模型，通过迭代地将参考样本映射到目标样本来描述条件分布。该模型使用块三角输运映射，其组件被证明可以表征目标分布的条件分布。这些映射是通过解决带权 $L^2$ 损失函数的最优输运问题得到的，从而扩展了[Trigila and Tabak, 2016]中的数据驱动方法用于条件采样。

    Sampling conditional distributions is a fundamental task for Bayesian inference and density estimation. Generative models, such as normalizing flows and generative adversarial networks, characterize conditional distributions by learning a transport map that pushes forward a simple reference (e.g., a standard Gaussian) to a target distribution. While these approaches successfully describe many non-Gaussian problems, their performance is often limited by parametric bias and the reliability of gradient-based (adversarial) optimizers to learn these transformations. This work proposes a non-parametric generative model that iteratively maps reference samples to the target. The model uses block-triangular transport maps, whose components are shown to characterize conditionals of the target distribution. These maps arise from solving an optimal transport problem with a weighted $L^2$ cost function, thereby extending the data-driven approach in [Trigila and Tabak, 2016] for conditional sampling
    
[^11]: 双向注意力作为连续词专家的混合物

    Bidirectional Attention as a Mixture of Continuous Word Experts. (arXiv:2307.04057v1 [cs.CL])

    [http://arxiv.org/abs/2307.04057](http://arxiv.org/abs/2307.04057)

    双向注意力模型具有混合专家权重，类似于连续词袋模型（CBOW）的统计模型，它在大型语言模型中起到了重要作用。

    

    双向注意力由位置编码和屏蔽语言模型（MLM）目标组成的自注意力构成，已成为现代大型语言模型（LLMs）的关键组件。尽管它在实践中取得了成功，但很少有研究探讨它的统计基础：双向注意力隐含地拟合了什么统计模型？它与非注意机制的先驱有何不同？本文探讨了这些问题。关键观察是，重新参数化后，拟合单层单头双向注意力等于拟合具有混合专家权重的连续词袋（CBOW）模型。此外，具有多个头和多个层的双向注意力等价于堆叠的MoEs和MoEs的混合。这个统计观点揭示了MoE在双向注意力中的独特用途，这与其在处理异构性方面的实际有效性相一致。

    Bidirectional attention $\unicode{x2013}$ composed of self-attention with positional encodings and the masked language model (MLM) objective $\unicode{x2013}$ has emerged as a key component of modern large language models (LLMs). Despite its empirical success, few studies have examined its statistical underpinnings: What statistical model is bidirectional attention implicitly fitting? What sets it apart from its non-attention predecessors? We explore these questions in this paper. The key observation is that fitting a single-layer single-head bidirectional attention, upon reparameterization, is equivalent to fitting a continuous bag of words (CBOW) model with mixture-of-experts (MoE) weights. Further, bidirectional attention with multiple heads and multiple layers is equivalent to stacked MoEs and a mixture of MoEs, respectively. This statistical viewpoint reveals the distinct use of MoE in bidirectional attention, which aligns with its practical effectiveness in handling heterogeneous
    
[^12]: 流形滤波-组合网络

    Manifold Filter-Combine Networks. (arXiv:2307.04056v1 [stat.ML])

    [http://arxiv.org/abs/2307.04056](http://arxiv.org/abs/2307.04056)

    这篇论文介绍了一类称为流形滤波-组合网络的大型流形神经网络。作者提出了一种基于构建数据驱动图的方法来实现这种网络，并提供了收敛到连续极限的充分条件，其收敛速度不依赖于滤波器数量。

    

    我们介绍了一类大型流形神经网络(MNNs)，我们称之为流形滤波-组合网络。这个类别包括了Wang、Ruiz和Ribeiro之前的研究中考虑的MNNs，流形散射变换(一种基于小波的神经网络模型)，以及其他有趣的之前在文献中未考虑的示例，如Kipf和Welling的图卷积网络的流形等效。然后，我们考虑了一种基于构建数据驱动图的方法，用于在没有对流形有全局知识的情况下实现这样的网络，而只能访问有限数量的样本点。我们提供了网络在样本点数趋于无穷大时能够保证收敛到其连续极限的充分条件。与之前的工作(主要关注特定的MNN结构和图构建)不同，我们的收敛速度并不依赖于使用的滤波器数量。而且，它表现出线性的收敛速度。

    We introduce a large class of manifold neural networks (MNNs) which we call Manifold Filter-Combine Networks. This class includes as special cases, the MNNs considered in previous work by Wang, Ruiz, and Ribeiro, the manifold scattering transform (a wavelet-based model of neural networks), and other interesting examples not previously considered in the literature such as the manifold equivalent of Kipf and Welling's graph convolutional network. We then consider a method, based on building a data-driven graph, for implementing such networks when one does not have global knowledge of the manifold, but merely has access to finitely many sample points. We provide sufficient conditions for the network to provably converge to its continuum limit as the number of sample points tends to infinity. Unlike previous work (which focused on specific MNN architectures and graph constructions), our rate of convergence does not explicitly depend on the number of filters used. Moreover, it exhibits line
    
[^13]: 具有策略性买家的情境动态定价

    Contextual Dynamic Pricing with Strategic Buyers. (arXiv:2307.04055v1 [stat.ML])

    [http://arxiv.org/abs/2307.04055](http://arxiv.org/abs/2307.04055)

    本文研究了具有策略性买家的情境动态定价问题，提出了一种策略动态定价策略，将买家的策略行为纳入在线学习中，以最大化卖方的累计收益。

    

    个性化定价是企业常用的一种针对个体特征制定价格的策略。在这个过程中，买家也可以通过操纵特征数据来获取更低的价格，但这也会导致特定的操作成本。这种策略行为可能会阻碍企业最大化利润。本文研究了具有策略性买家的情境动态定价问题。卖方无法观察到买家的真实特征，而只能观察到买家根据策略行为操纵后的特征。此外，卖方只能观察到买家对产品的估值，而无法直接获取具体数值，只能得到一个二进制的响应，表示是否发生销售。鉴于这些挑战，我们提出了一种策略动态定价策略，将买家的策略行为纳入在线学习中，以最大化卖方的累计收益。首先证明了现有的不考虑策略性的定价策略的存在限制。

    Personalized pricing, which involves tailoring prices based on individual characteristics, is commonly used by firms to implement a consumer-specific pricing policy. In this process, buyers can also strategically manipulate their feature data to obtain a lower price, incurring certain manipulation costs. Such strategic behavior can hinder firms from maximizing their profits. In this paper, we study the contextual dynamic pricing problem with strategic buyers. The seller does not observe the buyer's true feature, but a manipulated feature according to buyers' strategic behavior. In addition, the seller does not observe the buyers' valuation of the product, but only a binary response indicating whether a sale happens or not. Recognizing these challenges, we propose a strategic dynamic pricing policy that incorporates the buyers' strategic behavior into the online learning to maximize the seller's cumulative revenue. We first prove that existing non-strategic pricing policies that neglect
    
[^14]: 使用对抗训练的深度神经网络估计器在非参数回归中的超范数收敛性

    Sup-Norm Convergence of Deep Neural Network Estimator for Nonparametric Regression by Adversarial Training. (arXiv:2307.04042v1 [stat.ML])

    [http://arxiv.org/abs/2307.04042](http://arxiv.org/abs/2307.04042)

    我们展示了使用对抗训练的深度神经网络估计器在非参数回归中的超范数收敛性。我们发现普通的对抗训练使得神经估计器不一致，但通过所提出的带修正的对抗训练，深度神经网络估计器在超范数意义下达到最优速率。我们的实验证实了这些理论发现。

    

    我们展示了使用一种新颖的对抗训练方案的深度神经网络估计器的超范数收敛性。针对非参数回归问题，已经证明使用深度神经网络的估计器在$L2$-范数意义下可以获得更好的性能。相比之下，由于神经网络模型的深度结构，使用最小二乘法的神经估计器很难达到超范数收敛。在本研究中，我们发展了一种对抗训练方案，并研究了深度神经网络估计器的超范数收敛性。首先，我们发现普通的对抗训练使得神经估计器不一致。其次，我们展示了通过所提出的带修正的对抗训练，深度神经网络估计器在超范数意义下达到最优速率。我们将我们的对抗训练扩展到了一般的损失函数和数据生成函数的设置。我们的实验支持了理论发现。

    We show the sup-norm convergence of deep neural network estimators with a novel adversarial training scheme. For the nonparametric regression problem, it has been shown that an estimator using deep neural networks can achieve better performances in the sense of the $L2$-norm. In contrast, it is difficult for the neural estimator with least-squares to achieve the sup-norm convergence, due to the deep structure of neural network models. In this study, we develop an adversarial training scheme and investigate the sup-norm convergence of deep neural network estimators. First, we find that ordinary adversarial training makes neural estimators inconsistent. Second, we show that a deep neural network estimator achieves the optimal rate in the sup-norm sense by the proposed adversarial training with correction. We extend our adversarial training to general setups of a loss function and a data-generating function. Our experiments support the theoretical findings.
    
[^15]: 快速经验场景

    Fast Empirical Scenarios. (arXiv:2307.03927v1 [stat.ML])

    [http://arxiv.org/abs/2307.03927](http://arxiv.org/abs/2307.03927)

    该论文提出了两种快速的经验场景提取算法，一种识别之前未观察到的场景并提供场景的协方差矩阵表示，另一种从已实现的世界状态中选择重要的数据点，并与高阶样本矩一致，这些算法计算效率高且适用于一致的基于场景的建模和高维数值积分。

    

    我们希望从大型和高维面板数据中提取一小部分与样本矩一致的代表性场景。在两种新算法中，第一种算法识别之前未观察到的场景，并提供了一种基于场景的协方差矩阵表示。第二种算法从已实现的世界状态中选择重要的数据点，并与高阶样本矩信息一致。这两种算法计算效率高，并可用于一致的基于场景的建模和高维数值积分。广泛的数值基准测试研究和在投资组合优化中的应用支持所提出的算法。

    We seek to extract a small number of representative scenarios from large and high-dimensional panel data that are consistent with sample moments. Among two novel algorithms, the first identifies scenarios that have not been observed before, and comes with a scenario-based representation of covariance matrices. The second proposal picks important data points from states of the world that have already realized, and are consistent with higher-order sample moment information. Both algorithms are efficient to compute, and lend themselves to consistent scenario-based modeling and high-dimensional numerical integration. Extensive numerical benchmarking studies and an application in portfolio optimization favor the proposed algorithms.
    
[^16]: 关于正则化和标签约束推理的研究

    On Regularization and Inference with Label Constraints. (arXiv:2307.03886v1 [cs.LG])

    [http://arxiv.org/abs/2307.03886](http://arxiv.org/abs/2307.03886)

    本文研究了在机器学习中将先验知识和符号规则以标签约束的形式表达的方法。通过比较正则化和约束推理两种常见的编码标签约束的策略，发现正则化缩小了泛化差距但引入了对次优模型的偏置，而约束推理通过纠正模型的违规行为将违规行为转化为优势。进一步探索了将这两种方法结合使用的可能，并提出了用约束推理来补偿正则化引入的偏置的条件，旨在提高模型复杂性和最优风险。

    

    先验知识和符号规则在机器学习中通常以标签约束的形式表达，特别是在结构预测问题中。本文通过量化其对模型性能的影响，比较了机器学习流程中两种常见的编码标签约束的策略：带约束的正则化和约束推理。对于正则化，我们展示了它通过排除与约束不一致的模型来缩小泛化差距的效果。然而，正则化对小违规的偏好导致了对次优模型的偏置。对于约束推理，我们展示了它通过纠正模型的违规行为来减小总体风险，并将违规行为转化为优势。鉴于这些差异，我们进一步探索了将这两种方法结合使用，并提出了约束推理来补偿正则化引入的偏置的条件，旨在提高模型复杂性和最优风险。

    Prior knowledge and symbolic rules in machine learning are often expressed in the form of label constraints, especially in structured prediction problems. In this work, we compare two common strategies for encoding label constraints in a machine learning pipeline, regularization with constraints and constrained inference, by quantifying their impact on model performance. For regularization, we show that it narrows the generalization gap by precluding models that are inconsistent with the constraints. However, its preference for small violations introduces a bias toward a suboptimal model. For constrained inference, we show that it reduces the population risk by correcting a model's violation, and hence turns the violation into an advantage. Given these differences, we further explore the use of two approaches together and propose conditions for constrained inference to compensate for the bias introduced by regularization, aiming to improve both the model complexity and optimal risk.
    
[^17]: 可实现回归的最优学习算法：PAC学习和在线学习

    Optimal Learners for Realizable Regression: PAC Learning and Online Learning. (arXiv:2307.03848v1 [cs.LG])

    [http://arxiv.org/abs/2307.03848](http://arxiv.org/abs/2307.03848)

    本论文研究了可实现回归问题的PAC学习和在线学习的统计复杂度，并提出了对于可学习性的必要条件和充分条件。

    

    本研究旨在对可实现回归在PAC学习和在线学习的统计复杂度进行刻画。先前的研究已经证明了有限的fat shattering维度对于PAC学习的充分性以及有限的scaled Natarajan维度对于必要性的存在，但自从Simon 1997（SICOMP '97）的工作以来，对于更完整的刻画的进展甚少。为此，我们首先引入了一种最小化实例最优学习算法来对可实现回归进行学习，并提出了一种既定性又定量地刻画了哪些类的实数预测器可以被学习的新颖维度。然后，我们确定了一个与图维度相关的组合维度，该维度刻画了在可实现设置中的ERM可学习性。最后，我们根据与DS维度相关的组合维度建立了学习可行性的必要条件，并猜测它也可能是充分的。

    In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting.  Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in 
    
[^18]: URL：一种可转移不确定性估计的表示学习基准

    URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v1 [cs.LG])

    [http://arxiv.org/abs/2307.03810](http://arxiv.org/abs/2307.03810)

    URL基准是一个评估预训练模型可转移性和不确定性估计的方式，研究发现专注于表示本身不确定性或直接估计预测风险的方法效果优于基于概率的方法。

    

    表示学习显著推动了该领域发展出能够作为从零开始迁移到新数据集时的有价值起点的预训练模型。随着对可靠机器学习和不确定性量化的需求不断增加，需要的预训练模型不仅能提供嵌入向量，还能提供可转移的不确定性估计。为了引导这样的模型的开发，我们提出了URL（Uncertainty-aware Representation Learning）基准。除了表示的可转移性之外，它还使用一种新颖的度量标准来测量不确定性估计的零样本可转移性。我们应用URL来评估11种在ImageNet上进行预训练并转移到8个下游数据集的不确定性量化器。我们发现，着重于表示本身的不确定性或直接估计预测风险的方法优于基于上游类别的概率的方法。然而，实现可转移的不确定性仍然是一个挑战。

    Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction risk directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertaint
    
[^19]: 在线学习和使用ERM预言机解决无穷博弈问题

    Online Learning and Solving Infinite Games with an ERM Oracle. (arXiv:2307.01689v1 [cs.LG])

    [http://arxiv.org/abs/2307.01689](http://arxiv.org/abs/2307.01689)

    这项工作提出了一种仅依赖ERM预言机调用的在线学习算法，该算法在可实现情况下具有有限的遗憾，并在不可知情况下具有亚线性增长的遗憾。同时，还提供了类似的结果用于非参数博弈环境中的学习算法，即仅依赖最佳响应预言机的学习算法，并收敛到近似极小-极大均衡点。

    

    在基于在线学习的情况下，ERM足以达到接近最优泛化误差的目标，但在在线学习环境下并非如此，通常的概念类算法依赖计算效率较低的预言机，如标准最优算法(SOA)。在这项工作中，我们提出了一种仅依赖ERM预言机调用的在线二分类算法，并证明在可实现的情况下具有有限的遗憾(regret)，在不可知的情况下具有亚线性增长的遗憾。我们通过底层概念类的Littlestone和阈值维度来限制遗憾。我们获得了类似的结果用于非参数博弈，其中ERM预言机可以被理解为最佳响应预言机，根据其他玩家的游戏历史找到一个玩家的最佳响应。在这种情况下，我们提供了仅依赖最佳响应预言机的学习算法，并收敛到两人零和博弈的近似极小-极大均衡点。

    While ERM suffices to attain near-optimal generalization error in the stochastic learning setting, this is not known to be the case in the online learning setting, where algorithms for general concept classes rely on computationally inefficient oracles such as the Standard Optimal Algorithm (SOA). In this work, we propose an algorithm for online binary classification setting that relies solely on ERM oracle calls, and show that it has finite regret in the realizable setting and sublinearly growing regret in the agnostic setting. We bound the regret in terms of the Littlestone and threshold dimensions of the underlying concept class.  We obtain similar results for nonparametric games, where the ERM oracle can be interpreted as a best response oracle, finding the best response of a player to a given history of play of the other players. In this setting, we provide learning algorithms that only rely on best response oracles and converge to approximate-minimax equilibria in two-player zero
    
[^20]: 数值数据填补的多模态数据集:一种概率最近邻核密度方法

    Numerical Data Imputation for Multimodal Data Sets: A Probabilistic Nearest-Neighbor Kernel Density Approach. (arXiv:2306.16906v1 [stat.ML])

    [http://arxiv.org/abs/2306.16906](http://arxiv.org/abs/2306.16906)

    本论文介绍了一种新的数值数据填补方法，通过将最近邻估计和高斯核密度估计结合，能够有效处理多模态数据集中的缺失值，并提供比当前方法更高的概率估计。

    

    数值数据填补方法通过估计替换缺失的值以利用不完整的数据集。当前的填补方法试图最小化未观察到的真实值和填补值之间的误差。但是，在多模态或复杂分布存在的情况下，这种策略可能会产生伪像，导致填补效果较差。为了解决这个问题，我们引入了$k$NN$\times$KDE算法: 一种将最近邻估计($k$NN)和使用高斯核进行密度估计(KDE)结合的数据填补方法。我们使用人工和真实数据进行了与之前数据填补方法的比较，涉及了不同的数据缺失情况和不同的数据缺失率，并且展示了我们的方法可以处理复杂的原始数据结构，产生更低的数据填补误差，并提供比当前方法更高的概率估计。我们将代码以开源形式发布给社区：https://github.com/DeltaFloflo/knnxkde

    Numerical data imputation algorithms replace missing values by estimates to leverage incomplete data sets. Current imputation methods seek to minimize the error between the unobserved ground truth and the imputed values. But this strategy can create artifacts leading to poor imputation in the presence of multimodal or complex distributions. To tackle this problem, we introduce the $k$NN$\times$KDE algorithm: a data imputation method combining nearest neighbor estimation ($k$NN) and density estimation with Gaussian kernels (KDE). We compare our method with previous data imputation methods using artificial and real-world data with different data missing scenarios and various data missing rates, and show that our method can cope with complex original data structure, yields lower data imputation errors, and provides probabilistic estimates with higher likelihood than current methods. We release the code in open-source for the community: https://github.com/DeltaFloflo/knnxkde
    
[^21]: 一种基于对比学习方法的代理市场订单表示

    Agent market orders representation through a contrastive learning approach. (arXiv:2306.05987v1 [q-fin.ST])

    [http://arxiv.org/abs/2306.05987](http://arxiv.org/abs/2306.05987)

    通过对比学习方法，本研究构建了一个自监督学习模型，用于学习代理市场订单的表示。进一步地，我们使用K均值聚类算法对代理订单的学习表示向量进行聚类，以确定每个簇中的不同行为类型。

    

    本研究通过访问Euronext的CAC40数据中的标记订单，分析代理在市场中根据其下达的订单的行为。本研究构建了一个自监督学习模型，使用三元组损失来有效地学习代理市场订单的表示。通过获取这个学习表示，各种下游任务变得可行。本研究使用K均值聚类算法对代理订单的学习表示向量进行聚类，以确定每个簇中的不同行为类型。

    Due to the access to the labeled orders on the CAC40 data from Euronext, we are able to analyse agents' behaviours in the market based on their placed orders. In this study, we construct a self-supervised learning model using triplet loss to effectively learn the representation of agent market orders. By acquiring this learned representation, various downstream tasks become feasible. In this work, we utilise the K-means clustering algorithm on the learned representation vectors of agent orders to identify distinct behaviour types within each cluster.
    
[^22]: 分散化SGD和平均方向SAM在渐近意义下是等价的

    Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v1 [cs.LG])

    [http://arxiv.org/abs/2306.02913](http://arxiv.org/abs/2306.02913)

    分散SGD和平均方向SAM在渐近意义下是等价的，D-SGD表现出梯度平滑效应和锐度正则化效应，而且可以提高后验评估，并证明了潜在的泛化能力

    

    分散随机梯度下降（D-SGD）允许在没有中央服务器的控制下，大量设备同时进行协作学习。然而，现有理论认为，分散化不可避免地削弱了泛化能力。本文挑战传统信念，提出了完全新的角度来理解分散学习。我们证明了在一般非凸非-$\beta$-平滑设置下，D-SGD隐式地最小化了平均方向锐度感知最小化（SAM）算法的损失函数。这种惊人的渐近等价揭示了内在的正则化-优化权衡以及分散化的三个优点：（1）D-SGD中存在一个自由的不确定性评估机制，可以提高后验估计；（2）D-SGD表现出梯度平滑效应；（3）D-SGD的锐度正则化效应不会随着总批处理大小的增加而减少，这证明了潜在的泛化能力

    Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization b
    
[^23]: 基于大语言模型的多项选择题答案确认预测研究

    Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v1 [cs.CL])

    [http://arxiv.org/abs/2305.18404](http://arxiv.org/abs/2305.18404)

    本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。

    

    随着大型语言模型的广泛开发，对它们进行健壮的不确定性量化技术将成为它们在高风险场景下安全部署的关键。本研究探讨了如何利用符合性预测技术，在多项选择题回答任务中为语言模型提供不确定性量化。我们发现符合性预测的不确定性估计与预测准确性密切相关。这种观察对于下游应用，如选择性分类和过滤低质量预测，可能会有用。我们还研究了符合性预测对于超出主题的问题的交换性假设，这可能是许多实际应用的更为现实的场景。本研究为在需要可靠保证错误率的安全关键情况下更加值得信赖和可靠地使用大型语言模型做出了贡献。

    As large language models continue to be widely developed, robust uncertainty quantification techniques will become crucial for their safe deployment in high-stakes scenarios. In this work, we explore how conformal prediction can be used to provide uncertainty quantification in language models for the specific task of multiple-choice question-answering. We find that the uncertainty estimates from conformal prediction are tightly correlated with prediction accuracy. This observation can be useful for downstream applications such as selective classification and filtering out low-quality predictions. We also investigate the exchangeability assumption required by conformal prediction to out-of-subject questions, which may be a more realistic scenario for many practical applications. Our work contributes towards more trustworthy and reliable usage of large language models in safety-critical situations, where robust guarantees of error rate are required.
    
[^24]: SKI加速Toeplitz神经网络：通过非对称核实现加速

    SKI to go Faster: Accelerating Toeplitz Neural Networks via Asymmetric Kernels. (arXiv:2305.09028v1 [stat.ML])

    [http://arxiv.org/abs/2305.09028](http://arxiv.org/abs/2305.09028)

    本论文提出使用非对称核（asymmetric kernels）实现Toeplitz神经网络（TNNs）的加速，通过稀疏加低秩Toeplitz矩阵分解、小型1D卷积和替换相对位置编码器（RPE）多层感知器（MLP）实现O（n）复杂度，针对因果模型，提出了“快速”因果屏蔽来抵消这种方法的限制。

    

    Toeplitz神经网络（TNNs）是最近出现并取得令人印象深刻结果的序列模型。它们需要O(n log n)的计算复杂度和O(n)的相对位置编码器（RPE）多层感知器（MLP）和衰减偏差调用。我们的目标是减少它们。我们首先指出，RPE是一个非对称正定核，而Toeplitz矩阵是伪格拉姆矩阵。此外：1）学习的核在主对角线附近显示出刺状行为，而在其他位置则表现出平滑行为；2）RPE MLP较慢。对于双向模型，这促使我们进行稀疏加低秩Toeplitz矩阵分解。对于稀疏组件的操作，我们进行小型1D卷积。对于低秩组件，我们将RPE MLP替换为线性插值，并使用非对称有结构的内核插值（SKI）（Wilson等，2015）以实现O（n）复杂度：我们提供了严格的误差分析。对于因果模型，“快速”因果屏蔽（Katharopoulos等，2020）抵消了SKI的好处。

    Toeplitz Neural Networks (TNNs) (Qin et. al. 2023) are a recent sequence model with impressive results. They require O(n log n) computational complexity and O(n) relative positional encoder (RPE) multi-layer perceptron (MLP) and decay bias calls. We aim to reduce both. We first note that the RPE is a non-SPD (symmetric positive definite) kernel and the Toeplitz matrices are pseudo-Gram matrices. Further 1) the learned kernels display spiky behavior near the main diagonals with otherwise smooth behavior; 2) the RPE MLP is slow. For bidirectional models, this motivates a sparse plus low-rank Toeplitz matrix decomposition. For the sparse component's action, we do a small 1D convolution. For the low rank component, we replace the RPE MLP with linear interpolation and use asymmetric Structured Kernel Interpolation (SKI) (Wilson et. al. 2015) for O(n) complexity: we provide rigorous error analysis. For causal models, "fast" causal masking (Katharopoulos et. al. 2020) negates SKI's benefits. 
    
[^25]: 简化变分贝叶斯方法的推导过程

    Variational Bayes Made Easy. (arXiv:2304.14251v1 [cs.LG])

    [http://arxiv.org/abs/2304.14251](http://arxiv.org/abs/2304.14251)

    该论文提出了一个三步骤方法，简化了变分贝叶斯近似推断方法的推导过程。

    

    变分贝叶斯方法是一种流行的近似推断方法，但其推导过程可能很繁琐。为了简化这个过程，我们给出了一个三步骤的方法，通过显式寻找关于已知分布期望的线性性，来确定后验分布形式。然后我们可以直接通过“读取”这些期望前的项，写出更新。这个方法使得推导更加简单，快速，简短和通用。

    Variational Bayes is a popular method for approximate inference but its derivation can be cumbersome. To simplify the process, we give a 3-step recipe to identify the posterior form by explicitly looking for linearity with respect to expectations of well-known distributions. We can then directly write the update by simply ``reading-off'' the terms in front of those expectations. The recipe makes the derivation easier, faster, shorter, and more general.
    
[^26]: 大规模适应性实验：灵活批处理的贝叶斯算法

    Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])

    [http://arxiv.org/abs/2303.11582](http://arxiv.org/abs/2303.11582)

    本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。

    

    标准的贝叶斯算法假定持续重新分配测量工作，这在实现过程中存在延迟反馈和基础设施/组织难题等挑战。本文针对仅有少数重新分配阶段的实际情况，其中测量结果是以批处理形式测量的，提出了一种新的适应性实验框架，可灵活处理任何批处理大小。我们的主要观察是，在统计推断中普遍使用的正态近似也可以指导可扩展自适应设计。通过推导渐进顺序实验，我们制定了一种动态规划，可以利用平均回报的先验信息。动态规划的状态转移相对于采样分配是可微的，允许使用基于梯度的方法进行规划和策略优化。我们提出了一种简单的迭代规划方法，即残余时限优化，通过优化平衡探索和利用的规划目标来选择采样分配。在合成和真实世界基准测试问题上的实验结果表明，我们的框架实现了最先进的性能，同时具有模块化和易用性。

    Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
    
[^27]: 带有背包的近似稳定掠夺者

    Approximately Stationary Bandits with Knapsacks. (arXiv:2302.14686v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14686](http://arxiv.org/abs/2302.14686)

    带有背包的掠夺者问题在随机和敌对情况下存在巨大的差距，尤其是在敌对情况下，当预算更加紧缺时保证性能变得更差。

    

    带有背包的掠夺者问题（BwK）是在全局预算约束下将掠夺者问题进行泛化的研究，近年来引起了广泛关注。之前的研究关注的是两个极端之一：随机BwK，在每一轮中，奖励和资源的消耗从一个独立同分布的分布中采样；而敌对BwK，则由对手选择这些参数。这两种情况下的可实现保证存在巨大的差距：在随机情况下可以达到无悔学习，而在敌对情况下只能达到基于竞争比的保证，其中竞争比取决于预算或同时取决于时间和资源数量。这种差距之所以如此巨大，在敌对BwK的典型情况下，保证性能变得更差时，预算更加紧缺。虽然已知存在“两全其美”类型的算法（单个算法可以在两个极端情况下提供最佳的可实现保证），它们的界限则会变差。

    Bandits with Knapsacks (BwK), the generalization of the Bandits problem under global budget constraints, has received a lot of attention in recent years. Previous work has focused on one of the two extremes: Stochastic BwK where the rewards and consumptions of the resources of each round are sampled from an i.i.d. distribution, and Adversarial BwK where these parameters are picked by an adversary. Achievable guarantees in the two cases exhibit a massive gap: No-regret learning is achievable in the stochastic case, but in the adversarial case only competitive ratio style guarantees are achievable, where the competitive ratio depends either on the budget or on both the time and the number of resources. What makes this gap so vast is that in Adversarial BwK the guarantees get worse in the typical case when the budget is more binding. While ``best-of-both-worlds'' type algorithms are known (single algorithms that provide the best achievable guarantee in each extreme case), their bounds deg
    
[^28]: 自适应稀疏高斯过程

    Adaptive Sparse Gaussian Process. (arXiv:2302.10325v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10325](http://arxiv.org/abs/2302.10325)

    这篇论文提出了第一个自适应稀疏高斯过程，能够在非平稳环境中进行高效的模型更新，并具有快速的推理收敛性。

    

    自适应学习对于非平稳环境中的学习机器是必要的，因为它需要忘记过去的数据分布。高效的算法需要紧凑的模型更新，以便不随着新数据的到来而增加计算负担，并以最低的计算成本进行在线参数更新。现有的解决方案只是部分满足这些需求。在这里，我们提出了第一个能够解决所有这些问题的自适应稀疏高斯过程（GP）。我们首先通过遗忘因子重新定义了变分稀疏GP算法，使其具有自适应性。接下来，为了使模型推理尽可能简单，我们建议每当出现新样本时同时更新稀疏GP模型的一个单个引导点和其他模型参数。结果，该算法呈现出推理过程的快速收敛性，即使在高度非平稳的环境中也能进行高效的模型更新（只需一次推理迭代）。试验结果表明，该算法在多种数据集上表现出了良好的性能。

    Adaptive learning is necessary for non-stationary environments where the learning machine needs to forget past data distribution. Efficient algorithms require a compact model update to not grow in computational burden with the incoming data and with the lowest possible computational cost for online parameter updating. Existing solutions only partially cover these needs. Here, we propose the first adaptive sparse Gaussian Process (GP) able to address all these issues. We first reformulate a variational sparse GP algorithm to make it adaptive through a forgetting factor. Next, to make the model inference as simple as possible, we propose updating a single inducing point of the sparse GP model together with the remaining model parameters every time a new sample arrives. As a result, the algorithm presents a fast convergence of the inference process, which allows an efficient model update (with a single inference iteration) even in highly non-stationary environments. Experimental results d
    
[^29]: 通过深度学生机器实现空间异质性学习

    Spatially heterogeneous learning by a deep student machine. (arXiv:2302.07419v3 [cond-mat.dis-nn] UPDATED)

    [http://arxiv.org/abs/2302.07419](http://arxiv.org/abs/2302.07419)

    本论文研究了一种深度学生机器的教师-学生设置，通过学生机器的集合来研究由具有大量可调参数的DNN的监督学习。研究表明DNN的学习在网络空间中相当异质。

    

    尽管深度神经网络（DNN）取得了非凡的成功，但由于具有大量可调参数，其仍然是黑匣子。为了研究DNN的隐藏层，本文通过一种统计力学方法称为教师-学生设置，研究了由宽度为N，深度为L，由具有c个输入的感知机组成的DNN的监督学习。我们考虑了一个学生机器的集合，该集合可以精确重现由教师机器提供的M组N维输入/输出关系。我们使用副本方法（H. Yoshino（2020））理论分析了集合，并进行了贪婪的Monte Carlo模拟。对于高维数据$N \gg 1$，理论在'密集极限' $N \gg c \gg 1$ 和 $M \gg 1$ 且固定$\alpha=M/c$时变得精确。理论和模拟都表明，DNN的学习在网络空间中相当异质：机器的配置在靠近输入/输出的层内更加相关。

    Despite the spectacular successes, deep neural networks (DNN) with a huge number of adjustable parameters remain largely black boxes. To shed light on the hidden layers of DNN, we study supervised learning by a DNN of width $N$ and depth $L$ consisting of perceptrons with $c$ inputs by a statistical mechanics approach called the teacher-student setting. We consider an ensemble of student machines that exactly reproduce $M$ sets of $N$ dimensional input/output relations provided by a teacher machine. We analyze the ensemble theoretically using a replica method (H. Yoshino (2020)) and numerically performing greedy Monte Carlo simulations. The replica theory which works on high dimensional data $N \gg 1$ becomes exact in 'dense limit' $N \gg c \gg 1$ and $M \gg 1$ with fixed $\alpha=M/c$. Both the theory and the simulation suggest learning by the DNN is quite heterogeneous in the network space: configurations of the machines are more correlated within the layers closer to the input/output
    
[^30]: 无组合式概貌展开

    Unbinned Profiled Unfolding. (arXiv:2302.05390v3 [hep-ph] UPDATED)

    [http://arxiv.org/abs/2302.05390](http://arxiv.org/abs/2302.05390)

    本文提出了一种新的基于机器学习的展开方法，可以得到无组合的差分截面并且可以剖析干扰参数。

    

    展开是粒子物理实验中的重要过程，它纠正了探测器效应，并提供了可用于提取基本物理参数等一系列后续任务的差分截面测量。传统上，展开是通过将目标相空间离散化为有限数量的区间来进行的，并且在展开变量的数量上存在局限性。最近，已经提出了一些使用机器学习进行无组合展开的方法。然而，这些方法（如大多数展开方法）都不允许同时约束（剖析）干扰参数。我们提出了一种新的基于机器学习的展开方法，可以得到无组合的差分截面并可以剖析干扰参数。机器学习损失函数是基于探测器级别的分区输入的全概率函数。我们首先用简单的高斯示例演示了该方法，然后展示了对模拟数据的影响。

    Unfolding is an important procedure in particle physics experiments which corrects for detector effects and provides differential cross section measurements that can be used for a number of downstream tasks, such as extracting fundamental physics parameters. Traditionally, unfolding is done by discretizing the target phase space into a finite number of bins and is limited in the number of unfolded variables. Recently, there have been a number of proposals to perform unbinned unfolding with machine learning. However, none of these methods (like most unfolding methods) allow for simultaneously constraining (profiling) nuisance parameters. We propose a new machine learning-based unfolding method that results in an unbinned differential cross section and can profile nuisance parameters. The machine learning loss function is the full likelihood function, based on binned inputs at detector-level. We first demonstrate the method with simple Gaussian examples and then show the impact on a simu
    
[^31]: 数据依赖分形维度的泛化界限

    Generalization Bounds with Data-dependent Fractal Dimensions. (arXiv:2302.02766v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.02766](http://arxiv.org/abs/2302.02766)

    这项研究提出了基于数据依赖的分形维度的泛化界限，不需要Lipschitz假设，并能控制泛化误差和互信息项。

    

    在统计学习中，为现代神经网络提供泛化保证是一项关键任务。最近，一些研究尝试使用分形几何的工具来分析这种情况下的泛化误差。尽管这些工作成功地引入了新的数学工具来理解泛化，但它们严重依赖于Lipschitz连续性假设，而这一假设通常不适用于神经网络，并且可能使界限变得无效。在这项工作中，我们解决了这个问题，并且证明了不需要任何Lipschitz假设的基于分形几何的泛化界限。为了实现这个目标，我们在学习理论中基于经典的覆盖论证，并引入了数据依赖的分形维度。尽管引入了大量的技术复杂性，但这个新概念使我们能够控制泛化误差（在固定或随机的假设空间上）以及特定的互信息（MI）项。

    Providing generalization guarantees for modern neural networks has been a crucial task in statistical learning. Recently, several studies have attempted to analyze the generalization error in such settings by using tools from fractal geometry. While these works have successfully introduced new mathematical tools to apprehend generalization, they heavily rely on a Lipschitz continuity assumption, which in general does not hold for neural networks and might make the bounds vacuous. In this work, we address this issue and prove fractal geometry-based generalization bounds without requiring any Lipschitz assumption. To achieve this goal, we build up on a classical covering argument in learning theory and introduce a data-dependent fractal dimension. Despite introducing a significant amount of technical complications, this new notion lets us control the generalization error (over either fixed or random hypothesis spaces) along with certain mutual information (MI) terms. To provide a clearer
    
[^32]: 从一个数据空间到另一个数据空间的本地迁移学习

    Local transfer learning from one data space to another. (arXiv:2302.00160v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00160](http://arxiv.org/abs/2302.00160)

    

    

    流形学习中的一个基本问题是在从支持在高维欧几里得空间中的低维子流形上随机选择的数据上近似一个函数关系。流形本质上由数据集本身定义，并且通常设计为数据在某种意义上在流形上稠密。数据空间的概念是一个抽象的流形，封装了允许进行函数逼近的基本属性。迁移学习（元学习）问题是利用在一个数据集上学习一个函数来学习在另一个数据集上的类似函数。在函数逼近方面，这意味着将一个数据空间上的函数（基本数据空间）提升到另一个数据空间（目标数据空间）。这个观点使我们能够将应用数学中的一些逆问题（如逆Radon变换）与迁移学习联系起来。本文探讨了这种提升问题。

    A fundamental problem in manifold learning is to approximate a functional relationship in a data chosen randomly from a probability distribution supported on a low dimensional sub-manifold of a high dimensional ambient Euclidean space. The manifold is essentially defined by the data set itself and, typically, designed so that the data is dense on the manifold in some sense. The notion of a data space is an abstraction of a manifold encapsulating the essential properties that allow for function approximation. The problem of transfer learning (meta-learning) is to use the learning of a function on one data set to learn a similar function on a new data set. In terms of function approximation, this means lifting a function on one data space (the base data space) to another (the target data space). This viewpoint enables us to connect some inverse problems in applied mathematics (such as inverse Radon transform) with transfer learning. In this paper we examine the question of such lifting w
    
[^33]: 通过D适应实现学习率自由学习

    Learning-Rate-Free Learning by D-Adaptation. (arXiv:2301.07733v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07733](http://arxiv.org/abs/2301.07733)

    D-Adaptation是一种可以自动设置学习率的方法，针对最小化凸性Lipschitz函数，用于实现最优收敛速率，而无需超参数，也无需额外对数因子改进，能够在各种机器学习问题中自动匹配手动调整的学习率。

    

    D适应是一种自动设置学习率的方法，可以渐近地实现最优收敛速率，用于最小化凸性Lipschitz函数，无需回溯或线性搜索，并且每步无需进行额外的函数值或梯度评估。我们的方法是这一类问题的第一个无超参数且收敛速率无需额外对数因子改进的方法。我们针对SGD和Adam变体展示了广泛的实验，其中该方法自动匹配手动调整的学习率，在十多个不同的机器学习问题中应用，包括大规模的视觉和语言问题。开源实现在 \url{https://github.com/facebookresearch/dadaptation}.

    D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems.  An open-source implementation is available at \url{https://github.com/facebookresearch/dadaptation}.
    
[^34]: 分布偏移的标签对齐正则化

    Label Alignment Regularization for Distribution Shift. (arXiv:2211.14960v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14960](http://arxiv.org/abs/2211.14960)

    这篇论文提出了一种用于无监督领域自适应的正则化方法，通过鼓励目标域中的预测与其前几个奇异向量对齐来实现。与传统方法不同的是，这个方法通过正则化分类器与无监督目标数据对齐，而不是正则化表示。通过消除对最优联合风险假设的依赖，该方法展示了很好的效果。

    

    最近的研究强调了监督学习中的标签对齐属性（LAP），即数据集中所有标签的向量大部分在数据矩阵的前几个奇异向量的张成空间内。受到这一观察的启发，我们提出了一种无监督领域自适应的正则化方法，鼓励目标域中的预测与其前几个奇异向量对齐。与传统的领域适应方法专注于正则化表示不同，我们相反，通过在源域和目标域中使用LAP，用正则化分类器与无监督目标数据对齐。理论分析表明，在一定的假设下，我们的解决方案位于目标域数据的前几个右奇异向量的张成空间内，并与最优解对齐。通过消除经典领域适应理论中常见的最优联合风险假设的依赖，我们展示了该方法的有效性。

    Recent work has highlighted the label alignment property (LAP) in supervised learning, where the vector of all labels in the dataset is mostly in the span of the top few singular vectors of the data matrix. Drawing inspiration from this observation, we propose a regularization method for unsupervised domain adaptation that encourages alignment between the predictions in the target domain and its top singular vectors. Unlike conventional domain adaptation approaches that focus on regularizing representations, we instead regularize the classifier to align with the unsupervised target data, guided by the LAP in both the source and target domains. Theoretical analysis demonstrates that, under certain assumptions, our solution resides within the span of the top right singular vectors of the target domain data and aligns with the optimal solution. By removing the reliance on the commonly used optimal joint risk assumption found in classic domain adaptation theory, we showcase the effectivene
    
[^35]: 关于递归划分的逐点行为及其对异质因果效应估计的影响

    On the Pointwise Behavior of Recursive Partitioning and Its Implications for Heterogeneous Causal Effect Estimation. (arXiv:2211.10805v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.10805](http://arxiv.org/abs/2211.10805)

    本文质疑了递归划分在决策树学习中的应用，通过证明它们可能无法实现一致范数的多项式收敛速率。我们提出了随机森林来解决这个问题，将低性能的树转化为几乎最优的过程，但代价是失去了解释性，并引入了两个额外的调整参数。

    

    决策树学习在逐点推断中的应用日益增多。重要的应用包括异质因果治疗效应和动态政策决策，以及条件分位数回归和实验设计，在这些应用中，树的估计和推断是在特定的协变量值上进行的。在本文中，我们对使用决策树（通过自适应递归划分训练）进行此类目的提出了质疑，通过证明它们甚至可以在修剪的情况下无法实现一致范数的多项式收敛速率。相反，收敛速度可能是多项式对数级别的，或者在一些重要的特殊情况下，例如诚实回归树，完全失败。我们表明，随机森林可以解决这个问题，将低性能的树转化为几乎最优的过程，但代价是失去了解释性，并引入了两个额外的调整参数。随机森林的两个标志性特征是子采样和随机特征选择机制。

    Decision tree learning is increasingly being used for pointwise inference. Important applications include causal heterogenous treatment effects and dynamic policy decisions, as well as conditional quantile regression and design of experiments, where tree estimation and inference is conducted at specific values of the covariates. In this paper, we call into question the use of decision trees (trained by adaptive recursive partitioning) for such purposes by demonstrating that they can fail to achieve polynomial rates of convergence in uniform norm, even with pruning. Instead, the convergence may be poly-logarithmic or, in some important special cases, such as honest regression trees, fail completely. We show that random forests can remedy the situation, turning poor performing trees into nearly optimal procedures, at the cost of losing interpretability and introducing two additional tuning parameters. The two hallmarks of random forests, subsampling and the random feature selection mecha
    
[^36]: 偏好子采样对于随机梯度Langevin动力学的研究

    Preferential Subsampling for Stochastic Gradient Langevin Dynamics. (arXiv:2210.16189v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.16189](http://arxiv.org/abs/2210.16189)

    本文提出一种偏好子采样的方法来对随机梯度Langevin动力学进行优化，通过使用非均匀概率分布子采样对具有更大影响的数据点进行加权，同时还通过自适应调整子采样大小来提高梯度估计的准确性。实验证明这种方法可以在减少子采样数的同时保持相同的精度水平。

    

    随机梯度MCMC（SGMCMC）通过使用小型、均匀加权的数据子样本构建对于对数后验梯度的无偏估计，为传统MCMC提供了可扩展的替代方法。虽然计算高效，但由此产生的梯度估计可能具有较高的方差，并且会影响采样器性能。传统上，方差控制问题通过构建更好的随机梯度估计器来解决，通常使用控制变量。我们提议使用离散的非均匀概率分布来偏好地子采样对于对梯度产生更大影响的数据点。此外，我们还提出在算法的每次迭代中自适应地调整子采样大小的方法，以便在难以估计梯度的样本空间中增加子采样大小。我们证明了这种方法可以在大幅减少平均子采样数的同时保持相同的精度水平。

    Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsample of the data. While efficient to compute, the resulting gradient estimator may exhibit a high variance and impact sampler performance. The problem of variance control has been traditionally addressed by constructing a better stochastic gradient estimator, often using control variates. We propose to use a discrete, non-uniform probability distribution to preferentially subsample data points that have a greater impact on the stochastic gradient. In addition, we present a method of adaptively adjusting the subsample size at each iteration of the algorithm, so that we increase the subsample size in areas of the sample space where the gradient is harder to estimate. We demonstrate that such an approach can maintain the same level of accuracy while substantially reducing the average subsample s
    
[^37]: 有条件风险厌恶的上下文赌博问题

    Conditionally Risk-Averse Contextual Bandits. (arXiv:2210.13573v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.13573](http://arxiv.org/abs/2210.13573)

    设计出了第一个具有在线遗憾保证的风险厌恶的上下文赌博算法，并在多个实验场景中展示了其适用性。

    

    在风险厌恶的情况下，具有平均统计保证的上下文赌博问题是不足够的，因为它们可能通过牺牲最坏情况的表现来获得更好的平均性能。设计一个风险厌恶的上下文赌博算法具有挑战性，因为探索是必要的，但风险厌恶对整个奖励分布都很敏感；尽管如此，我们展示了第一个具有在线遗憾保证的风险厌恶的上下文赌博算法。我们在多种场景下进行了实验，这些场景中最坏情况的结果应该被避免，包括动态定价、库存管理和自我调整软件；其中还包括一个生产级的扩展数据处理系统。

    Contextual bandits with average-case statistical guarantees are inadequate in risk-averse situations because they might trade off degraded worst-case behaviour for better average performance. Designing a risk-averse contextual bandit is challenging because exploration is necessary but risk-aversion is sensitive to the entire distribution of rewards; nonetheless we exhibit the first risk-averse contextual bandit algorithm with an online regret guarantee. We conduct experiments from diverse scenarios where worst-case outcomes should be avoided, from dynamic pricing, inventory management, and self-tuning software; including a production exascale data processing system.
    
[^38]: Bagging在过度参数化学习中的风险刻画和风险单调化

    Bagging in overparameterized learning: Risk characterization and risk monotonization. (arXiv:2210.11445v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2210.11445](http://arxiv.org/abs/2210.11445)

    本文研究了过度参数化学习中Bagging预测器的风险问题，并提出了通用策略来分析Bagging预测器的风险。通过具体化策略，我们得出了Bagging Ridge和Ridgeless预测器的精确渐近风险，并提供了一种交叉验证过程来选择Bagging的最佳子样本大小，以消除风险的非单调行为。

    

    Bagging是统计学和机器学习中常用的集成技术，用于提高预测模型的性能。本文研究了在比例渐近情况下，各种变体的Bagging预测器的预测风险，其中特征数与观测数的比值收敛到常数。具体而言，我们提出了一种分析Bagging预测器在平方误差损失下的预测风险的通用策略，利用简单随机抽样的经典结果。通过特殊化该策略，我们推导了具有任意数量的包的Bagging Ridge和Ridgeless预测器在具有任意特征协方差矩阵和信号向量的良好指定线性模型下的精确渐近风险。此外，我们提供了一种通用的交叉验证过程，用于选择Bagging的最佳子样本大小，并讨论其在消除样本大小的风险的非单调行为方面的实用性。

    Bagging is a commonly used ensemble technique in statistics and machine learning to improve the performance of prediction procedures. In this paper, we study the prediction risk of variants of bagged predictors under the proportional asymptotics regime, in which the ratio of the number of features to the number of observations converges to a constant. Specifically, we propose a general strategy to analyze the prediction risk under squared error loss of bagged predictors using classical results on simple random sampling. Specializing the strategy, we derive the exact asymptotic risk of the bagged ridge and ridgeless predictors with an arbitrary number of bags under a well-specified linear model with arbitrary feature covariance matrices and signal vectors. Furthermore, we prescribe a generic cross-validation procedure to select the optimal subsample size for bagging and discuss its utility to eliminate the non-monotonic behavior of the limiting risk in the sample size (i.e., double or m
    
[^39]: 基于组合评分建模的基于模拟推断

    Compositional Score Modeling for Simulation-based Inference. (arXiv:2209.14249v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14249](http://arxiv.org/abs/2209.14249)

    本研究提出了一种基于条件评分建模的方法，可以有效处理基于多个观测条件下得到的后验分布，同时具有高样本效率和聚合多个观测值的优势。

    

    模拟推断的神经后验估计方法在处理基于多个观测条件下得到的后验分布时可能不太适用，因为它们倾向于需要大量的模拟器调用来学习准确的近似。相比之下，神经似然估计方法可以在学习了单独观测值后，处理推断时的多个观测值，但它们依赖于标准的推断方法，如MCMC或变分推断，这些推断方法有一定的性能缺陷。我们引入了一种基于条件评分建模的新方法，它融合了两种方法的优点。我们对由单个观测引起的（扩散的）后验分布建模，然后引入了一种组合学习分数以近似从目标后验分布中采样的方法。我们的方法在样本效率上具有优势，在推断时可以自然地聚合多个观测值，并避免了传统推断方法的缺点。

    Neural Posterior Estimation methods for simulation-based inference can be ill-suited for dealing with posterior distributions obtained by conditioning on multiple observations, as they tend to require a large number of simulator calls to learn accurate approximations. In contrast, Neural Likelihood Estimation methods can handle multiple observations at inference time after learning from individual observations, but they rely on standard inference methods, such as MCMC or variational inference, which come with certain performance drawbacks. We introduce a new method based on conditional score modeling that enjoys the benefits of both approaches. We model the scores of the (diffused) posterior distributions induced by individual observations, and introduce a way of combining the learned scores to approximately sample from the target posterior distribution. Our approach is sample-efficient, can naturally aggregate multiple observations at inference time, and avoids the drawbacks of standa
    
[^40]: DynDepNet:通过动态图结构学习从fMRI数据中学习时变的依赖关系结构

    DynDepNet: Learning Time-Varying Dependency Structures from fMRI Data via Dynamic Graph Structure Learning. (arXiv:2209.13513v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.13513](http://arxiv.org/abs/2209.13513)

    DynDepNet是一种学习fMRI数据中时变依赖结构的新方法，在性别分类任务中取得了最先进的结果。

    

    图神经网络（GNNs）在学习基于功能磁共振成像（fMRI）数据的大脑图表示方面取得了成功。然而，现有的GNN方法假设大脑图在时间上是静态的，并且在模型训练之前已知图邻接矩阵。这些假设与证据相矛盾，即大脑图在时间上是变化的，并且其连接结构取决于功能连接测量的选择。用噪声大脑图错误地表示fMRI数据会对GNN的性能产生不利影响。为了解决这个问题，我们提出了DynDepNet，一种通过下游预测任务所引发的fMRI数据的最优时变依赖结构的学习方法。对于性别分类任务，对真实世界的fMRI数据集进行的实验证明DynDepNet取得了最先进的结果，准确率分别比最佳基准线提高了约8个百分点和6个百分点。

    Graph neural networks (GNNs) have demonstrated success in learning representations of brain graphs derived from functional magnetic resonance imaging (fMRI) data. However, existing GNN methods assume brain graphs are static over time and the graph adjacency matrix is known prior to model training. These assumptions contradict evidence that brain graphs are time-varying with a connectivity structure that depends on the choice of functional connectivity measure. Incorrectly representing fMRI data with noisy brain graphs can adversely affect GNN performance. To address this, we propose DynDepNet, a novel method for learning the optimal time-varying dependency structure of fMRI data induced by downstream prediction tasks. Experiments on real-world fMRI datasets, for the task of sex classification, demonstrate that DynDepNet achieves state-of-the-art results, outperforming the best baseline in terms of accuracy by approximately 8 and 6 percentage points, respectively. Furthermore, analysis 
    
[^41]: 不同分布的数据价值

    The Value of Out-of-Distribution Data. (arXiv:2208.10967v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.10967](http://arxiv.org/abs/2208.10967)

    不同分布的数据可以对任务的泛化误差产生非单调的影响，使用少量不同分布的数据进行训练是有价值的。

    

    我们期望随着类似任务样本的增加，泛化误差会减小；而随着来自不同分布（OOD）任务样本的增加，泛化误差会增大。在这项工作中，我们展示了一个反直觉的现象：任务的泛化误差可以是样本从OOD任务中的数量的非单调函数。随着OOD样本数量的增加，目标任务的泛化误差在超过一个阈值之前会先减小后增大。换句话说，使用少量OOD数据进行训练是有价值的。我们在合成数据集上使用Fisher线性判别和计算机视觉基准数据集（如MNIST、CIFAR-10、CINIC-10、PACS和DomainNet）上的深度网络来展示和分析这一现象。在我们知道哪些样本属于OOD的理想情况下，我们展示了可以利用目标和OOD经验风险的适当加权目标来利用这些非单调趋势。尽管实际应用有限，但这表明如果我们能够检测到OOD样本，这种方法可能是有价值的。

    We expect the generalization error to improve with more samples from a similar task, and to deteriorate with more samples from an out-of-distribution (OOD) task. In this work, we show a counter-intuitive phenomenon: the generalization error of a task can be a non-monotonic function of the number of OOD samples. As the number of OOD samples increases, the generalization error on the target task improves before deteriorating beyond a threshold. In other words, there is value in training on small amounts of OOD data. We use Fisher's Linear Discriminant on synthetic datasets and deep networks on computer vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet to demonstrate and analyze this phenomenon. In the idealistic setting where we know which samples are OOD, we show that these non-monotonic trends can be exploited using an appropriately weighted objective of the target and OOD empirical risk. While its practical utility is limited, this does suggest that if we can det
    
[^42]: Survival Kernets: 可扩展且可解释的深度核生存分析模型，并具有准确性保证

    Survival Kernets: Scalable and Interpretable Deep Kernel Survival Analysis with an Accuracy Guarantee. (arXiv:2206.10477v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10477](http://arxiv.org/abs/2206.10477)

    Survival Kernets 是一种可扩展且可解释的深度核生存分析模型，能够在大规模数据集上进行模型解释和理论分析。它利用核函数估计个体的生存分布，通过训练集压缩方案进行数据分簇，因此具有较高的可视化能力和预测准确性保证。该模型在特定情况下的预测生存分布误差界限最优，且在测试时具有可扩展性。

    

    核生存分析模型通过核函数来估计个体的生存分布，核函数度量任意两个数据点之间的相似性。我们提出了一种新的深度核生存模型——生存kernet，该模型可以适用于大规模数据集，并且易于解释和进行理论分析。具体而言，训练数据根据一种最近发展的用于分类和回归的训练集压缩方案（称为核群）进行分簇。在测试时，每个数据点被表示为这些簇的加权组合，每个簇可以进行可视化展示。对于生存kernet的一个特殊情况，我们建立了一个有限样本误差界限，预测的生存分布在该界限下是最优的（除去一个对数因子）。在测试时具有可扩展性。

    Kernel survival analysis models estimate individual survival distributions with the help of a kernel function, which measures the similarity between any two data points. Such a kernel function can be learned using deep kernel survival models. In this paper, we present a new deep kernel survival model called a survival kernet, which scales to large datasets in a manner that is amenable to model interpretation and also theoretical analysis. Specifically, the training data are partitioned into clusters based on a recently developed training set compression scheme for classification and regression called kernel netting that we extend to the survival analysis setting. At test time, each data point is represented as a weighted combination of these clusters, and each such cluster can be visualized. For a special case of survival kernets, we establish a finite-sample error bound on predicted survival distributions that is, up to a log factor, optimal. Whereas scalability at test time is achiev
    
[^43]: DORA：探索深度神经网络中的异常值表示

    DORA: Exploring outlier representations in Deep Neural Networks. (arXiv:2206.04530v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.04530](http://arxiv.org/abs/2206.04530)

    本文提出了一种名为DORA的数据不可知框架，用于分析深度神经网络中的表征空间，并可以识别不符合人类直观认知的表征。

    

    尽管深度神经网络（DNN）在学习复杂抽象方面非常有效，但它们容易意外地从训练数据中学习到虚假的特征。为了确保模型的透明度，检查学习表示之间的关系至关重要，因为意外的概念往往表现为与所需的任务不符的异常。在这项工作中，我们介绍了DORA（Data-agnOstic Representation Analysis）：用于分析DNN表示空间的第一个数据不可知框架。我们的框架采用了所提出的表示之间的极端激活（EA）距离度量，在不访问任何数据的情况下利用网络内自说明能力。我们定量验证了度量的正确性和与人为定义的语义距离的一致性。EA距离与人类判断之间的一致性使我们能够确定表征，其基本概念被认为是不自然的。

    Although Deep Neural Networks (DNNs) are incredibly effective in learning complex abstractions, they are susceptible to unintentionally learning spurious artifacts from the training data. To ensure model transparency, it is crucial to examine the relationships between learned representations, as unintended concepts often manifest themselves to be anomalous to the desired task. In this work, we introduce DORA (Data-agnOstic Representation Analysis): the first data-agnostic framework for the analysis of the representation space of DNNs. Our framework employs the proposed Extreme-Activation (EA) distance measure between representations that utilizes self-explaining capabilities within the network without accessing any data. We quantitatively validate the metric's correctness and alignment with human-defined semantic distances. The coherence between the EA distance and human judgment enables us to identify representations whose underlying concepts would be considered unnatural by humans by
    
[^44]: 通过概率-概率映射实现有条件校准的预测分布：在银河红移估计和概率预测中的应用

    Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting. (arXiv:2205.14568v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.14568](http://arxiv.org/abs/2205.14568)

    本研究提出了一种名为Cal-PIT的方法，通过学习一个概率-概率映射，解决了预测分布的诊断和校准问题，来实现有条件校准。

    

    不确定性量化对于评估AI算法的预测能力至关重要。过去的研究致力于描述目标变量$y \in \mathbb{R}$在给定复杂输入特征$\mathbf{x} \in \mathcal{X}$的条件下的预测分布$F(y|\mathbf{x})$。然而，现有的预测分布（例如，归一化流和贝叶斯神经网络）往往缺乏条件校准，即给定输入$\mathbf{x}$的事件发生的概率与预测概率显著不同。当前的校准方法不能完全评估和实施有条件校准的预测分布。在这里，我们提出了一种名为Cal-PIT的方法，它通过从校准数据中学习一个概率-概率映射来同时解决预测分布的诊断和校准问题。关键思想是对概率积分变换分数进行$\mathbf{x}$的回归。估计的回归提供了对特征空间中条件覆盖的可解释诊断。

    Uncertainty quantification is crucial for assessing the predictive ability of AI algorithms. Much research has been devoted to describing the predictive distribution (PD) $F(y|\mathbf{x})$ of a target variable $y \in \mathbb{R}$ given complex input features $\mathbf{x} \in \mathcal{X}$. However, off-the-shelf PDs (from, e.g., normalizing flows and Bayesian neural networks) often lack conditional calibration with the probability of occurrence of an event given input $\mathbf{x}$ being significantly different from the predicted probability. Current calibration methods do not fully assess and enforce conditionally calibrated PDs. Here we propose \texttt{Cal-PIT}, a method that addresses both PD diagnostics and recalibration by learning a single probability-probability map from calibration data. The key idea is to regress probability integral transform scores against $\mathbf{x}$. The estimated regression provides interpretable diagnostics of conditional coverage across the feature space. 
    
[^45]: DDAC-SpAM: 一种用特征划分和去相关性的方法拟合高维稀疏加性模型的分布式算法

    DDAC-SpAM: A Distributed Algorithm for Fitting High-dimensional Sparse Additive Models with Feature Division and Decorrelation. (arXiv:2205.07932v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.07932](http://arxiv.org/abs/2205.07932)

    DDAC-SpAM是一种在高维稀疏加性模型中利用特征划分和去相关的分布式算法。去相关操作使得每个局部估计器能够恢复每个加性组分的稀疏模式，同时不对变量之间的相关性结构施加严格的约束。该算法在理论和实证分析中证明了其有效性和效率，为拟合稀疏加性模型提供了实际解决方案。

    

    分布式统计学习已成为大规模数据分析的常用技术。现有的大部分工作都是关注观察值的划分，但我们提出了一种新的算法DDAC-SpAM，在高维稀疏加性模型中对特征进行划分。我们的方法包括三个步骤：划分、去相关和征服。去相关操作使每个局部估计器能够恢复每个加性组分的稀疏模式，而不对变量之间的相关性结构施加严格的约束。通过理论分析和在合成数据和真实数据上的实证结果，证明了该算法的有效性和效率。理论结果包括一致的稀疏模式恢复以及对每个加性函数组成部分的统计推断。我们的方法为拟合稀疏加性模型提供了实际可行的解决方案，在各个领域有着广泛的应用前景。

    Distributed statistical learning has become a popular technique for large-scale data analysis. Most existing work in this area focuses on dividing the observations, but we propose a new algorithm, DDAC-SpAM, which divides the features under a high-dimensional sparse additive model. Our approach involves three steps: divide, decorrelate, and conquer. The decorrelation operation enables each local estimator to recover the sparsity pattern for each additive component without imposing strict constraints on the correlation structure among variables. The effectiveness and efficiency of the proposed algorithm are demonstrated through theoretical analysis and empirical results on both synthetic and real data. The theoretical results include both the consistent sparsity pattern recovery as well as statistical inference for each additive functional component. Our approach provides a practical solution for fitting sparse additive models, with promising applications in a wide range of domains.
    
[^46]: 学习量子动力学的越域泛化

    Out-of-distribution generalization for learning quantum dynamics. (arXiv:2204.10268v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2204.10268](http://arxiv.org/abs/2204.10268)

    该论文在量子机器学习中证明了学习未知酉的越域泛化能力，并提出了使用乘积态来学习酉对纠缠态的作用，从而推动了在近期量子硬件上学习量子动力学的前景，并为经典和量子电路的编译提供了新的方法。

    

    泛化边界是评估量子机器学习（QML）训练数据要求的关键工具。最近的研究已经建立了量子神经网络（QNNs）在域内泛化的保证，其中训练和测试数据来自同一数据分布。然而，目前还没有关于QML中域外泛化的结果，其中我们要求训练出的模型在来自与训练分布不同的数据上表现良好。在这里，我们证明了对学习未知酉的越域泛化的能力。特别地，我们证明了即使仅仅训练到了乘积态，我们也可以学习到酉对纠缠态的作用。由于乘积态只需要使用单比特门就可以制备，这推动了在近期量子硬件上学习量子动力学的前景，并进一步为经典和量子电路的编译提供了新的方法。

    Generalization bounds are a critical tool to assess the training data requirements of Quantum Machine Learning (QML). Recent work has established guarantees for in-distribution generalization of quantum neural networks (QNNs), where training and testing data are drawn from the same data distribution. However, there are currently no results on out-of-distribution generalization in QML, where we require a trained model to perform well even on data drawn from a different distribution to the training distribution. Here, we prove out-of-distribution generalization for the task of learning an unknown unitary. In particular, we show that one can learn the action of a unitary on entangled states having trained only product states. Since product states can be prepared using only single-qubit gates, this advances the prospects of learning quantum dynamics on near term quantum hardware, and further opens up new methods for both the classical and quantum compilation of quantum circuits.
    
[^47]: 基于PDE的对称双臂伯努利赌博机的分析

    A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit. (arXiv:2202.05767v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.05767](http://arxiv.org/abs/2202.05767)

    本研究通过关联线性热方程的解，得到了对称双臂伯努利赌博机问题的minmax最优遗憾和伪遗憾的领先项。新的结果改进了先前的研究，并提供了新的非渐近边界。

    

    本研究探讨了一个版本的双臂伯努利赌博机问题，其中两个臂的平均值之和为1（即对称的双臂伯努利赌博机）。在臂之间的差距趋近于零且预测期数趋近于无穷大的情况下，我们通过将每个解与线性热方程的解关联，得到了该问题的minmax最优遗憾和伪遗憾的领先项。我们的结果改进了先前已知的结果；具体而言，在三种不同的差距缩放模式下，我们明确计算了这些领先项。此外，我们还得到了任何给定时间范围的新的非渐近边界。

    This work addresses a version of the two-armed Bernoulli bandit problem where the sum of the means of the arms is one (the symmetric two-armed Bernoulli bandit). In a regime where the gap between these means goes to zero and the number of prediction periods approaches infinity, we obtain the leading order terms of the minmax optimal regret and pseudoregret for this problem by associating each of them with a solution of a linear heat equation. Our results improve upon the previously known results; specifically, we explicitly compute these leading order terms in three different scaling regimes for the gap. Additionally, we obtain new non-asymptotic bounds for any given time horizon.
    
[^48]: 通过张量分解实现一致的协同过滤

    Consistent Collaborative Filtering via Tensor Decomposition. (arXiv:2201.11936v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2201.11936](http://arxiv.org/abs/2201.11936)

    本文提出了一种通过张量分解来实现一致协同过滤的新模型，它能够扩展传统的用户-物品偏好计算方法，使得在评估物品相对偏好时产生物品之间的交互，具有潜在的非线性态度。

    

    协同过滤是分析用户活动和构建物品推荐系统的事实标准。本文提出了一种基于隐式反馈的协同过滤新模型——切割反对称分解（SAD）。与传统技术不同，SAD通过对用户-物品交互的新颖三维张量视图引入了一个额外的物品的隐含向量。该向量将通过标准点乘计算出的用户-物品偏好扩展到一般内积，从而在评估物品的相对偏好时产生物品之间的交互。当向量折叠为1时，SAD降为最先进的协同过滤模型（SOTA），而本文允许从数据中估计其值。允许新物品向量的值与1不同具有深远的影响。这表明用户可能具有非线性态度。

    Collaborative filtering is the de facto standard for analyzing users' activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlin
    
[^49]: 快速可解释的贪婪树求和

    Fast Interpretable Greedy-Tree Sums. (arXiv:2201.11931v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.11931](http://arxiv.org/abs/2201.11931)

    FIGS是一种快速可解释的贪婪树求和算法，通过将逻辑规则与加法相结合，能够适应加性结构同时保持高度可解释性。在真实数据集上的实验表明，FIGS实现了最先进的预测性能，并在高风险领域如医学中展示了其实用性。

    

    现代机器学习取得了令人印象深刻的预测性能，但通常会牺牲解释性，这在高风险领域如医学中是一个关键考虑因素。在这种情况下，从业者通常使用高度可解释的决策树模型，但这些模型对加性结构存在归纳偏差。为了克服这种偏差，我们提出了快速可解释的贪婪树求和（FIGS），它将CART算法推广到同时增长可变数量的树进行求和。通过将逻辑规则与加法相结合，FIGS能够适应加性结构同时保持高度可解释性。对真实数据集的大量实验表明，FIGS实现了最先进的预测性能。为了展示FIGS在高风险领域的实用性，我们将FIGS改进为学习临床决策工具（CDIs），CDIs是指导临床决策的工具。具体来说，我们引入了FIGS的一个变种，称为G-FIGS，它考虑了加性结构的因素。

    Modern machine learning has achieved impressive prediction performance, but often sacrifices interpretability, a critical consideration in high-stakes domains such as medicine. In such settings, practitioners often use highly interpretable decision tree models, but these suffer from inductive bias against additive structure. To overcome this bias, we propose Fast Interpretable Greedy-Tree Sums (FIGS), which generalizes the CART algorithm to simultaneously grow a flexible number of trees in summation. By combining logical rules with addition, FIGS is able to adapt to additive structure while remaining highly interpretable. Extensive experiments on real-world datasets show that FIGS achieves state-of-the-art prediction performance. To demonstrate the usefulness of FIGS in high-stakes domains, we adapt FIGS to learn clinical decision instruments (CDIs), which are tools for guiding clinical decision-making. Specifically, we introduce a variant of FIGS known as G-FIGS that accounts for the 
    
[^50]: 上下文组合多输出 GP Bandits 带有组约束

    Contextual Combinatorial Multi-output GP Bandits with Group Constraints. (arXiv:2111.14778v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.14778](http://arxiv.org/abs/2111.14778)

    这项研究提出了一种应用于联邦多臂赌博问题的新算法，该算法通过选择一组基础臂来最大化超级臂奖励，并同时满足组奖励约束。算法利用两输出高斯过程模型，为每个基础臂的结果提供更大的灵活性。

    

    在联邦多臂赌博问题中，最大化全局奖励同时满足保护客户的最低隐私要求是主要目标。为了建立这样的问题，我们考虑了一个具有组和变化动作集的组合上下文赌博设定，其中相似的基础臂以组的形式出现，并且必须在每一轮选择一组基础臂（称为超级臂），以最大化超级臂的奖励同时满足来自选择基础臂的组的奖励约束。为了增加灵活性，我们让每个基础臂具有两个结果，被建模为两输出高斯过程（GP）的输出，其中一个结果用于计算超级臂的奖励，另一个用于组的奖励。然后，我们提出了一种新颖的双-UCB GP-bandit 算法，称为阈值组合高斯过程上置信边界（TCGP-UCB），它在最大化累积超级臂奖励和满足组奖励约束之间找到平衡，并且可以调整为偏好一方。

    In federated multi-armed bandit problems, maximizing global reward while satisfying minimum privacy requirements to protect clients is the main goal. To formulate such problems, we consider a combinatorial contextual bandit setting with groups and changing action sets, where similar base arms arrive in groups and a set of base arms, called a super arm, must be chosen in each round to maximize super arm reward while satisfying the constraints of the rewards of groups from which base arms were chosen. To allow for greater flexibility, we let each base arm have two outcomes, modeled as the output of a two-output Gaussian process (GP), where one outcome is used to compute super arm reward and the other for group reward. We then propose a novel double-UCB GP-bandit algorithm, called Thresholded Combinatorial Gaussian Process Upper Confidence Bounds (TCGP-UCB), which balances between maximizing cumulative super arm reward and satisfying group reward constraints and can be tuned to prefer one
    
[^51]: GFlowNet基础

    GFlowNet Foundations. (arXiv:2111.09266v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.09266](http://arxiv.org/abs/2111.09266)

    GFlowNets是一种生成流网络方法，用于在主动学习环境中采样多样化的候选集。它们具有估计联合概率分布和边际分布的能力，可以表示关于复合对象（如集合和图）的分布。通过单次训练的生成传递，GFlowNets分摊了计算昂贵的MCMC方法的工作。

    

    生成流网络（GFlowNets）被引入为在主动学习环境中采样多样化的候选集的方法，其训练目标使其近似按照给定的奖励函数进行采样。本文展示了GFlowNets的一些额外的理论性质。它们可以用于估计联合概率分布和相应的边际分布，其中一些变量未指定，特别是可以表示关于复合对象（如集合和图）的分布。GFlowNets通过单次训练的生成传递来分摊通常由计算昂贵的MCMC方法完成的工作。它们还可以用于估计分区函数和自由能，给定一个子集（子图）的超集（超图）的条件概率，以及给定一个集合（图）的所有超集（超图）的边际分布。我们介绍了一些变体，使得可以估计熵的值。

    Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets. They can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entro
    
[^52]: 稀疏MoEs满足高效的模型集成

    Sparse MoEs meet Efficient Ensembles. (arXiv:2110.03360v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03360](http://arxiv.org/abs/2110.03360)

    本论文研究了神经网络集成和稀疏专家混合的结合，提出了一种名为E$^3$的高效稀疏MoEs集成方法，在减少计算复杂度的同时取得了在准确性、鲁棒性和不确定性方面的改进。

    

    基于子模型的聚合输出的机器学习模型，无论是在激活还是预测水平上，往往相对于单个模型显示出很强的性能。我们研究了两种流行模型的相互作用：神经网络集成和稀疏专家混合（稀疏MoEs）。首先，我们展示了这两种方法具有互补的特点，它们的结合是有益的。这包括对稀疏MoEs在不确定性相关基准测试中的全面评估。然后，我们提出了高效的专家集成（E$^3$），一种可扩展且简单的稀疏MoEs集成方法，它兼具两类模型的优点，同时使用的浮点运算（FLOPs）比深度集成少多达45％。大量实验证明了E$^3$在多个具有挑战性的基于Transformer的视觉基线模型上的准确性、对数似然、少样本学习、鲁棒性和不确定性改进。E$^3$在扩展到具有高达27亿参数的模型时不仅保持其效率，而且还能提供更好的性能。

    Machine learning models based on the aggregated outputs of submodels, either at the activation or prediction levels, often exhibit strong performance compared to individual models. We study the interplay of two popular classes of such models: ensembles of neural networks and sparse mixture of experts (sparse MoEs). First, we show that the two approaches have complementary features whose combination is beneficial. This includes a comprehensive evaluation of sparse MoEs in uncertainty related benchmarks. Then, we present Efficient Ensemble of Experts (E$^3$), a scalable and simple ensemble of sparse MoEs that takes the best of both classes of models, while using up to 45% fewer FLOPs than a deep ensemble. Extensive experiments demonstrate the accuracy, log-likelihood, few-shot learning, robustness, and uncertainty improvements of E$^3$ over several challenging vision Transformer-based baselines. E$^3$ not only preserves its efficiency while scaling to models with up to 2.7B parameters, b
    
[^53]: 通过Riemannian Gauss-Newton进行低秩张量估计：统计最优性和二阶收敛性

    Low-rank Tensor Estimation via Riemannian Gauss-Newton: Statistical Optimality and Second-Order Convergence. (arXiv:2104.12031v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2104.12031](http://arxiv.org/abs/2104.12031)

    本文提出了一种通过Riemannian Gauss-Newton方法进行低秩张量估计的方法，并证明了其在噪声环境下的局部二次收敛性和统计最优性。

    

    本文研究从一系列有噪线性测量中估计低Tucker秩张量的问题。该问题涵盖了许多具体的应用示例，包括张量回归、张量补全和张量PCA / SVD。我们考虑了一种高效的Riemannian Gauss-Newton（RGN）方法来估计低Tucker秩张量。与文献中对RGN的（超）线性收敛保证不同，我们证明了在噪声环境下RGN在低秩张量估计中的第一种局部二次收敛保证，并提供相应的估计误差上界。我们还提供了一个确定性估计误差下界，该下界与上界相匹配，证明了RGN的统计最优性。我们通过两个机器学习应用（张量回归和张量SVD）来说明RGN的优点。最后，我们提供了模拟结果来证实我们的理论发现。

    In this paper, we consider the estimation of a low Tucker rank tensor from a number of noisy linear measurements. The general problem covers many specific examples arising from applications, including tensor regression, tensor completion, and tensor PCA/SVD. We consider an efficient Riemannian Gauss-Newton (RGN) method for low Tucker rank tensor estimation. Different from the generic (super)linear convergence guarantee of RGN in the literature, we prove the first local quadratic convergence guarantee of RGN for low-rank tensor estimation in the noisy setting under some regularity conditions and provide the corresponding estimation error upper bounds. A deterministic estimation error lower bound, which matches the upper bound, is provided that demonstrates the statistical optimality of RGN. The merit of RGN is illustrated through two machine learning applications: tensor regression and tensor SVD. Finally, we provide the simulation results to corroborate our theoretical findings.
    
[^54]: 使用自结构重要性采样实现黑盒模拟分布尾部的效率

    Achieving Efficiency in Black Box Simulation of Distribution Tails with Self-structuring Importance Samplers. (arXiv:2102.07060v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2102.07060](http://arxiv.org/abs/2102.07060)

    本文提出了一种新颖的自结构重要性采样方法，通过复制在较不罕见的样本中观察到的浓度特性，隐式诱导出一种有效的IS分布，从而提高了估计性能度量的分布尾部的效率。

    

    本文提出了一种新颖的重要性采样（IS）方案，用于估计采用丰富工具模拟的性能度量的分布尾部，这些工具包括线性规划、整数线性规划、分段线性/二次目标、使用深度神经网络指定的特征映射等。传统的明确识别有效的测度变化的方法在高度格式化的模型之外受到可行性和可扩展性的限制，因为它们需要与目标和概率分布精心调整。在所提出的方案中，通过一种基本转换克服了这个瓶颈，该转换可以通过复制在较不罕见的样本中观察到的浓度特性来在各种模型中隐式诱导出一个有效的IS分布。这种新颖的方法是通过发展一个大偏差原理来指导的，这种原理揭示了最优IS分布的自相似现象。

    This paper presents a novel Importance Sampling (IS) scheme for estimating distribution tails of performance measures modeled with a rich set of tools such as linear programs, integer linear programs, piecewise linear/quadratic objectives, feature maps specified with deep neural networks, etc. The conventional approach of explicitly identifying efficient changes of measure suffers from feasibility and scalability concerns beyond highly stylized models, due to their need to be tailored intricately to the objective and the underlying probability distribution. This bottleneck is overcome in the proposed scheme with an elementary transformation which is capable of implicitly inducing an effective IS distribution in a variety of models by replicating the concentration properties observed in less rare samples. This novel approach is guided by developing a large deviations principle that brings out the phenomenon of self-similarity of optimal IS distributions. The proposed sampler is the firs
    
[^55]: 无监督树提升学习概率分布

    Unsupervised tree boosting for learning probability distributions. (arXiv:2101.11083v7 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2101.11083](http://arxiv.org/abs/2101.11083)

    本文提出了一种无监督树提升算法，通过拟合叠加树集合来推断独立同分布样本的潜在采样分布，其中关键是引入了新的概率分布上的"加法"概念和与之相对应的"剩余化"操作。这些概念通过一维累积分布函数（CDF）变换和组合自然而然地出现，并扩展到了多元设置中。

    

    我们提出了一种无监督树提升算法，用于根据拟合叠加树集合来推断独立同分布样本的潜在采样分布，其类似于监督树提升。该算法的核心是一种新的概率分布上的"加法"概念，该概念引出了"剩余化"的一致概念，即从观测中减去概率分布，以消除后者的采样分布中的分布结构。我们通过累积分布函数（CDF）变换和组合展示了这些概念在一维分布中的自然出现，由于一维CDF的几个"类似群体"属性。虽然传统的多元CDF不保留这些属性，但新的多元CDF定义可以恢复这些属性，从而使"加法"和"剩余化"的概念也可以在多元设置中得到规范。这样就产生了

    We propose an unsupervised tree boosting algorithm for inferring the underlying sampling distribution of an i.i.d. sample based on fitting additive tree ensembles in a fashion analogous to supervised tree boosting. Integral to the algorithm is a new notion of "addition" on probability distributions that leads to a coherent notion of "residualization", i.e., subtracting a probability distribution from an observation to remove the distributional structure from the sampling distribution of the latter. We show that these notions arise naturally for univariate distributions through cumulative distribution function (CDF) transforms and compositions due to several "group-like" properties of univariate CDFs. While the traditional multivariate CDF does not preserve these properties, a new definition of multivariate CDF can restore these properties, thereby allowing the notions of "addition" and "residualization" to be formulated for multivariate settings as well. This then gives rise to the uns
    
[^56]: 结构化多臂赌博机的最优学习

    Optimal Learning for Structured Bandits. (arXiv:2007.07302v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2007.07302](http://arxiv.org/abs/2007.07302)

    本文研究了结构化多臂赌博机问题，在存在结构信息的情况下，设计了一种能够利用结构信息以最小化后悔的算法。

    

    本文研究了结构化的多臂赌博机问题，即在存在结构信息的不确定性环境下进行在线决策。在这个问题中，决策者需要在观察到不确定的奖励随时间变化时找出最佳行动方针。决策者已经了解到奖励分布属于一个凸紧致集合的某种凸结构信息。在有这种结构信息的情况下，决策者希望通过利用这些信息来最小化后悔（与提前知道最佳行动的基准策略相比的性能差异）。在没有结构信息的情况下，经典的上界置信区间（UCB）和汤姆逊取样算法已被证明具有最小后悔。然而，最近指出，这两种算法都无法利用复杂结构信息。

    We study structured multi-armed bandits, which is the problem of online decision-making under uncertainty in the presence of structural information. In this problem, the decision-maker needs to discover the best course of action despite observing only uncertain rewards over time. The decision-maker is aware of certain convex structural information regarding the reward distributions; that is, the decision-maker knows the reward distributions of the arms belong to a convex compact set. In the presence such structural information, they then would like to minimize their regret by exploiting this information, where the regret is its performance difference against a benchmark policy that knows the best action ahead of time. In the absence of structural information, the classical upper confidence bound (UCB) and Thomson sampling algorithms are well known to suffer minimal regret. As recently pointed out, neither algorithms are, however, capable of exploiting structural information that is com
    
[^57]: 针对未预料到的对手测试鲁棒性

    Testing Robustness Against Unforeseen Adversaries. (arXiv:1908.08016v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1908.08016](http://arxiv.org/abs/1908.08016)

    该论文提出了18种新的对抗攻击，并使用这些攻击创建了一个用于评估对各种未预料到的对手的鲁棒性的新基准。作者还发现了一系列防御策略，可以帮助克服训练期间未考虑到的对手的泛化差距。该研究的结果将为研究现实世界最坏情况下的鲁棒性提供有用工具，促进开发更强大的防御措施。

    

    在考虑现实世界的对抗环境时，防御者在训练期间不太可能对所有可能的对手进行训练，并且对手很可能使用逼真的对抗扭曲，而不限于小的L_p约束扰动。为了缩小研究和现实之间的差距，我们介绍了18种新的对抗攻击，并使用它们创建了ImageNet-UA，这是一个用于评估模型对各种未预料到的对手的鲁棒性的新基准。我们利用这个基准来识别一系列能够帮助克服这种泛化差距的防御策略，发现了可以提高对未预料到的攻击的鲁棒性的技术的丰富空间。我们希望ImageNet-UA的更多样性和逼真性将成为那些研究现实世界最坏情况的鲁棒性的人的有用工具，从而促进开发能够在训练期间看不到的攻击中进行泛化的更强大的防御措施。

    When considering real-world adversarial settings, defenders are unlikely to have access to the full range of deployment-time adversaries during training, and adversaries are likely to use realistic adversarial distortions that will not be limited to small L_p-constrained perturbations. To narrow in on this discrepancy between research and reality we introduce eighteen novel adversarial attacks, which we use to create ImageNet-UA, a new benchmark for evaluating model robustness against a wide range of unforeseen adversaries. We make use of our benchmark to identify a range of defense strategies which can help overcome this generalization gap, finding a rich space of techniques which can improve unforeseen robustness. We hope the greater variety and realism of ImageNet-UA will make it a useful tool for those working on real-world worst-case robustness, enabling development of more robust defenses which can generalize beyond attacks seen during training.
    

