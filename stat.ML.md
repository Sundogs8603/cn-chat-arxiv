# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk.](http://arxiv.org/abs/2304.03247) | 论文提出了一种贝叶斯框架，针对错位处理问题，将其视为治疗切换问题，并通过概率模型解决了复增和末事件偏差的问题。 |
| [^2] | [Pairwise Ranking with Gaussian Kernels.](http://arxiv.org/abs/2304.03185) | 本文提出新的Oracle不等式，在输入域上的一般盒计数维度假设和噪声条件或标准平滑条件下，对于高斯成对排名估计器得出了快速学习率。这表明，输入空间的低固有维度可以帮助避免维度诅咒。 |
| [^3] | [Efficient SAGE Estimation via Causal Structure Learning.](http://arxiv.org/abs/2304.03113) | 提出了一种通过因果结构学习的方法名为d-SAGE，用于加速SAGE逼近算法，显著降低计算开销和提高计算效率，并在理论上展示了$d$-SAGE的逼近误差会收敛于零，实验上体现了高精度。 |
| [^4] | [Static Fuzzy Bag-of-Words: a lightweight sentence embedding algorithm.](http://arxiv.org/abs/2304.03098) | 本文提出了一种静态模糊词袋模型，可提供预定义维度的句子嵌入。该模型在语义文本相似性基准测试中表现出竞争力，并要求低计算资源。 |
| [^5] | [Spectral Gap Regularization of Neural Networks.](http://arxiv.org/abs/2304.03096) | 本文介绍了一种利用谱/图形信息进行神经网络正则化的新方法，即Fiedler正则化。通过使用神经网络底层图的Fiedler值作为正则化工具，我们提供了一种结构加权的 $\text{L}_1$ 惩罚并提供统一泛化误差界限的分析，这使得我们的方法在许多数据集上都取得了良好的性能。 |
| [^6] | [Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series.](http://arxiv.org/abs/2304.03069) | 本文提出了一种适用于非平稳时间序列的自适应学生t分布方法，基于方法的一般自适应矩可以使用廉价的指数移动平均值（EMA）来估计参数。 |
| [^7] | [Sharp Deviations Bounds for Dirichlet Weighted Sums with Application to analysis of Bayesian algorithms.](http://arxiv.org/abs/2304.03056) | 本论文推导了Dirichlet随机变量的加权和的锐性有限差分界，同时应用于贝叶斯bootstrap和多臂赌博机分析，相对于现有的结果具有更好的结果。 |
| [^8] | [Training a Two Layer ReLU Network Analytically.](http://arxiv.org/abs/2304.02972) | 本研究探讨了一种算法，可以使用解析的方法训练双层ReLU网络，相比随机梯度下降和Adam优化器能够找到更深的最小值，在四个真实数据集中获得了显著更小的训练损失值，同时该方法速度更快，调参参数更少。 |
| [^9] | [Adaptable and Interpretable Framework for Novelty Detection in Real-Time IoT Systems.](http://arxiv.org/abs/2304.02947) | 介绍了一种RAID算法，能够在多元动态过程中检测异常行为，具有适应非平稳效应、不需改变现有过程自动化基础设施等特点，可在不同领域高度部署，并通过实际数据案例研究证明其改进的检测准确性。 |
| [^10] | [Classification of Superstatistical Features in High Dimensions.](http://arxiv.org/abs/2304.02912) | 本文利用经验风险最小化的方法，对高维超统计特征下的数据进行分类，并分析了正则化和分布尺度参数对分类的影响。 |
| [^11] | [Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks.](http://arxiv.org/abs/2304.02911) | 本文介绍了一种名为重尾部正则化的技术，在深度神经网络中通过明确提倡更重的重尾谱来提高泛化性能。与标准正则化技术相比，该方法在基准数据集上实现了显着的改进。 |
| [^12] | [Towards Efficient MCMC Sampling in Bayesian Neural Networks by Exploiting Symmetry.](http://arxiv.org/abs/2304.02902) | 本文提出了一种利用对称性在贝叶斯神经网络中实现高效MCMC采样的方法，通过利用神经元可互换性和某些激活函数引起的对称性在参数后验的多模态性中找到平衡。 |
| [^13] | [Variable-Complexity Weighted-Tempered Gibbs Samplers for Bayesian Variable Selection.](http://arxiv.org/abs/2304.02899) | 本文提出了一种变复杂度加权调节 Gibbs 采样器，用于贝叶斯变量选择，可以降低每个MCMC迭代的计算复杂度，并且可以在有限的迭代次数内控制估计器的方差。 |
| [^14] | [A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation.](http://arxiv.org/abs/2304.02858) | 本文研究了集成学习和数据增强方法的应用，针对类别不平衡问题，通过计算评估，找到了最有效的组合。 |
| [^15] | [Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification.](http://arxiv.org/abs/2304.02849) | 该论文介绍了一种新的分类方法，用于提高鲁棒性，减少标签噪声的影响，其基于正态分布，并可通过最小化负对数似然来学习参数。 |
| [^16] | [NTK-SAP: Improving neural network pruning by aligning training dynamics.](http://arxiv.org/abs/2304.02840) | 本文提出了一种新的神经网络剪枝方法：通过对齐训练动态来提高剪枝效果，具体来说就是剪去对NTK频谱影响最小的连接。采用这种方法有助于维持NTK频谱，从而将训练动态和其密集对应物的训练动态对齐。 |
| [^17] | [MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection.](http://arxiv.org/abs/2304.02767) | MethaneMapper是一个可用于光谱域内定位甲烷排放区域的Transformer网络，并在模型尺寸上实现了优化。同时，作者介绍了一个用于研究甲烷检测问题的大规模数据集。 |
| [^18] | [Convergence Rates for Non-Log-Concave Sampling and Log-Partition Estimation.](http://arxiv.org/abs/2303.03237) | 非对数凹势V的高维采样速率可以在一些条件下实现与凸函数相同的收敛速率。 |
| [^19] | [PAD: Towards Principled Adversarial Malware Detection Against Evasion Attacks.](http://arxiv.org/abs/2302.11328) | 该论文提出了一个新的对抗性训练框架，称为合理对抗性恶意软件检测（PAD），它通过可学习的凸度量保护恶意软件检测器免受攻击者的影响，而不是简单的启发式方法。实验结果表明，该方法优于现有技术，提高了恶意软件检测的防御效果。 |
| [^20] | [Learning Lipschitz Functions by GD-trained Shallow Overparameterized ReLU Neural Networks.](http://arxiv.org/abs/2212.13848) | 本论文通过GD训练过程中神经切向核（NTK）近似方法，探究了过度参数化的浅层ReLU神经网络学习Lipschitz函数的能力，提出了一系列能够产生最优速率的实用早停规则。 |
| [^21] | [Online Kernel CUSUM for Change-Point Detection.](http://arxiv.org/abs/2211.15070) | 本研究提出了一种在线变点检测的核CUSUM方法，相比于现有方法更敏感，提供了准确的关键性能指标分析，并建立了最优窗口长度，引入了递归计算程序来确保计算和内存复杂度恒定。 |
| [^22] | [Bayesian Optimization with Conformal Prediction Sets.](http://arxiv.org/abs/2210.12496) | 符合性贝叶斯优化在决策过程中应用符合性预测集，可以纠正由于模型规范不当和协变量转移带来的主观上不可能的结果，并在黑盒优化任务和表格排名任务中表现优异。 |
| [^23] | [Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework.](http://arxiv.org/abs/2210.12048) | 本论文提出了ORCHID框架，将Ollivier-Ricci曲率推广到超图领域，并证明了其具有良好的理论特性。实验结果表明ORCHID曲率对于超图任务有很好的应用性。 |
| [^24] | [Delayed Feedback in Generalised Linear Bandits Revisited.](http://arxiv.org/abs/2207.10786) | 研究了广义线性赌博机中的延迟奖励现象，提出了一种自然的乐观算法，可实现一个独立于时间的惩罚函数，降低了现有工作中随着时间增长而增加的惩罚函数的界限。 |
| [^25] | [Scalable Stochastic Parametric Verification with Stochastic Variational Smoothed Model Checking.](http://arxiv.org/abs/2205.05398) | 本论文提出了一种利用概率机器学习扩展平滑模型检验(smMC)方法的思路，从而使贝叶斯推理的smMC适用于更大的数据集和实际问题。 |
| [^26] | [WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series.](http://arxiv.org/abs/2203.09978) | 该论文提出了一个名为WOODS的时间序列基准测试，致力于解决在离群分布下的泛化过程中面临的挑战，还改进了目前时间序列任务中的离群分布广义性算法，并表明仍有很大的改进空间。 |
| [^27] | [Continual Repeated Annealed Flow Transport Monte Carlo.](http://arxiv.org/abs/2201.13117) | 这篇论文提出了一种结合序列蒙特卡罗采样和标准化流变分推断的连续重复退火流输运蒙特卡罗方法，通过对标准化流的训练，实现不同温度下的传输，并在多个实例中展示了其优于其他方法的表现。 |
| [^28] | [Robust Upper Bounds for Adversarial Training.](http://arxiv.org/abs/2112.09279) | 该论文提出了一种新的对抗性训练方法，通过最小化基于网络的整体展开的对抗损失上界来实现。与传统方法相比，该方法利用了最新的稳健优化领域的工具，可以在保证输出层绑定紧密性的同时，有效地进行训练。 |
| [^29] | [Principal component analysis for Gaussian process posteriors.](http://arxiv.org/abs/2107.07115) | 本文提出了高斯过程后验的主成分分析扩展，解决了如何定义一组具有无限维参数的GP的结构的问题，并且证明了通过元学习提高目标任务性能的有效性。 |
| [^30] | [Sequential Adversarial Anomaly Detection for One-Class Event Data.](http://arxiv.org/abs/1910.09161) | 本文提出了一种对抗顺序检测器，使用带标记的点过程模型捕捉序列事件中的相关性，可以应用于检测异常序列，通过解决最小最大问题，针对最坏情况的生成器，找到最佳检测器。 |

# 详细

[^1]: 一种在不可避免风险存在下进行复发事件因果分析的贝叶斯框架

    A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk. (arXiv:2304.03247v1 [stat.ME])

    [http://arxiv.org/abs/2304.03247](http://arxiv.org/abs/2304.03247)

    论文提出了一种贝叶斯框架，针对错位处理问题，将其视为治疗切换问题，并通过概率模型解决了复增和末事件偏差的问题。

    

    生物医学统计学中对复发事件率的观测研究很常见。通常的目标是在规定的随访时间窗口内，估计在一个明确定义的目标人群中两种治疗方法的事件率差异。使用观测性索赔数据进行估计是具有挑战性的，因为在目标人群的成员资格方面定义时，很少在资格确认时准确分配治疗方式。目前的解决方案通常是错位处理，比如基于后续分配，在资格确认时分配治疗方式，这会将先前的事件率错误地归因于治疗-从而产生不可避免的风险偏差。即使资格和治疗已经对齐，终止事件过程（例如死亡）也经常停止感兴趣的复发事件过程。同样，这两个过程也受到审查的影响，因此在整个随访时间窗口内不能观察到事件。我们的方法将错位处理转化为治疗切换问题：一些患者在整个随访时间窗口内坚持一个特定的治疗策略，另一些患者在这个时间窗口内经历治疗策略的切换。我们提出了一个概率模型，其中包括两个基本元素：通过一个合理的时刻切换模型，正确地建模治疗之间的切换和不可避免风险，通过将非观察事件模型化为复发事件模型，解决了复增和末事件偏差的问题。

    Observational studies of recurrent event rates are common in biomedical statistics. Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window. Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility. Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias. Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest. Both processes are also censored so that events are not observed over the entire followup window. Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on
    
[^2]: 带高斯核的成对排名

    Pairwise Ranking with Gaussian Kernels. (arXiv:2304.03185v1 [stat.ML])

    [http://arxiv.org/abs/2304.03185](http://arxiv.org/abs/2304.03185)

    本文提出新的Oracle不等式，在输入域上的一般盒计数维度假设和噪声条件或标准平滑条件下，对于高斯成对排名估计器得出了快速学习率。这表明，输入空间的低固有维度可以帮助避免维度诅咒。

    

    带高斯核的正则成对排名是前沿的学习算法之一。尽管应用范围广泛，但缺乏严格的理论证明来支持这种排名估计器的性能。本文旨在通过为正则成对排名开发新的 Oracle 不等式来填补这一空白。借助这些 Oracle 不等式，结合输入域上的一般盒计数维度假设和噪声条件或标准平滑条件，我们推导出高斯排名估计器的快速学习率。我们的理论分析改进了现有的估计，并显示输入空间的低固有维度可以帮助速率避免维度诅咒。

    Regularized pairwise ranking with Gaussian kernels is one of the cutting-edge learning algorithms. Despite a wide range of applications, a rigorous theoretical demonstration still lacks to support the performance of such ranking estimators. This work aims to fill this gap by developing novel oracle inequalities for regularized pairwise ranking. With the help of these oracle inequalities, we derive fast learning rates of Gaussian ranking estimators under a general box-counting dimension assumption on the input domain combined with the noise conditions or the standard smoothness condition. Our theoretical analysis improves the existing estimates and shows that a low intrinsic dimension of input space can help the rates circumvent the curse of dimensionality.
    
[^3]: 通过因果结构学习实现高效的SAGE估计

    Efficient SAGE Estimation via Causal Structure Learning. (arXiv:2304.03113v1 [stat.ML])

    [http://arxiv.org/abs/2304.03113](http://arxiv.org/abs/2304.03113)

    提出了一种通过因果结构学习的方法名为d-SAGE，用于加速SAGE逼近算法，显著降低计算开销和提高计算效率，并在理论上展示了$d$-SAGE的逼近误差会收敛于零，实验上体现了高精度。

    

    Shapley Additive Global Importance (SAGE)是一种理论上有吸引力的可解释性方法，它公平地将全局重要性归因于模型的特征。然而，它的精确计算需要计算特征集的指数数量的剩余性能贡献，这在计算上非常昂贵，尤其是因为估计剩余性能贡献需要从条件分布中采样。因此，SAGE逼近算法只考虑了一小部分特征集。我们提出了一种名为$d$-SAGE的方法，它可以加速SAGE逼近。$d$-SAGE是由于观察到特征和模型目标之间的条件独立性 (CI) 意味着零剩余贡献，因此可以跳过它们的计算。为了识别CI，我们利用因果结构学习(CSL)来推断一个图，该图将数据中的(条件)独立性编码为$d$分离。这在计算上更有效，因为我们只需要计算非$d$分离特征集的SAGE值。我们提供了理论保证，说明随着$d$的增加，$d$-SAGE的逼近误差会收敛于零。在实验上，我们证明了$d$-SAGE需要比现有的SAGE逼近算法更少的特征集，同时保持高精度。

    The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model's features. However, its exact calculation requires the computation of the feature's surplus performance contributions over an exponential number of feature sets. This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions. Thus, SAGE approximation algorithms only take a fraction of the feature sets into account. We propose $d$-SAGE, a method that accelerates SAGE approximation. $d$-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped. To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as $d$-separations. This is computationally more ef
    
[^4]: 静态模糊词袋：一种轻量级句子嵌入算法

    Static Fuzzy Bag-of-Words: a lightweight sentence embedding algorithm. (arXiv:2304.03098v1 [cs.CL])

    [http://arxiv.org/abs/2304.03098](http://arxiv.org/abs/2304.03098)

    本文提出了一种静态模糊词袋模型，可提供预定义维度的句子嵌入。该模型在语义文本相似性基准测试中表现出竞争力，并要求低计算资源。

    

    嵌入技术的引入显著推动了自然语言处理领域的发展。许多提出的解决方案都是针对单词级别的编码。然而，在过去的几年中，出现了一些新的机制来处理更高层次的信息处理，例如句子和文档级别。本文专门讨论句子嵌入问题，提出了静态模糊词袋模型。我们的模型是模糊词袋方法的一种改进，针对预定义维度提供句子嵌入。SFBoW在语义文本相似性基准测试中表现竞争力，同时要求低计算资源。

    The introduction of embedding techniques has pushed forward significantly the Natural Language Processing field. Many of the proposed solutions have been presented for word-level encoding; anyhow, in the last years, new mechanism to treat information at an higher level of aggregation, like at sentence- and document-level, have emerged. With this work we address specifically the sentence embeddings problem, presenting the Static Fuzzy Bag-of-Word model. Our model is a refinement of the Fuzzy Bag-of-Words approach, providing sentence embeddings with a predefined dimension. SFBoW provides competitive performances in Semantic Textual Similarity benchmarks, while requiring low computational resources.
    
[^5]: 神经网络的谱间隙正则化

    Spectral Gap Regularization of Neural Networks. (arXiv:2304.03096v1 [stat.ML])

    [http://arxiv.org/abs/2304.03096](http://arxiv.org/abs/2304.03096)

    本文介绍了一种利用谱/图形信息进行神经网络正则化的新方法，即Fiedler正则化。通过使用神经网络底层图的Fiedler值作为正则化工具，我们提供了一种结构加权的 $\text{L}_1$ 惩罚并提供统一泛化误差界限的分析，这使得我们的方法在许多数据集上都取得了良好的性能。

    

    本文引入了Fiedler正则化，这是一种利用谱/图形信息对神经网络进行正则化的新方法。现有的正则化方法常常通过全局/均匀地惩罚权重来实现，忽略了神经网络的连通性结构。我们提出利用神经网络底层图的Fiedler值作为正则化工具。我们通过谱图理论提供了这种方法的理论动机。我们证明了Fiedler值的几个有用属性，使其成为正则化工具。我们提供了一种近似的变分方法，以便在训练期间更快地计算。我们提供了该框架的另一种形式，这是一种结构加权的 $\text{L}_1$ 惩罚，因此将我们的方法与稀疏感应联系起来。我们通过Rademacher复杂性分析提供了Fiedler正则化的统一泛化误差界限。我们对数据集进行了实验比较。

    We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information. Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network. We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization. We provide theoretical motivation for this approach via spectral graph theory. We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool. We provide an approximate, variational approach for faster computation during training. We provide an alternative formulation of this framework in the form of a structurally weighted $\text{L}_1$ penalty, thus linking our approach to sparsity induction. We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis. We performed experiments on datasets that compare F
    
[^6]: 自适应学生t分布与方法矩移动估计器用于非平稳时间序列

    Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series. (arXiv:2304.03069v1 [stat.ME])

    [http://arxiv.org/abs/2304.03069](http://arxiv.org/abs/2304.03069)

    本文提出了一种适用于非平稳时间序列的自适应学生t分布方法，基于方法的一般自适应矩可以使用廉价的指数移动平均值（EMA）来估计参数。

    

    真实的时间序列通常是非平稳的，这带来了模型适应的难题。传统方法如GARCH假定任意类型的依赖性。为了避免这种偏差，我们将着眼于最近提出的不可知的移动估计器哲学：在时间$t$找到优化$F_t=\sum_{\tau<t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$移动对数似然的参数，随时间演化。例如，它允许使用廉价的指数移动平均值（EMA）来估计参数，例如绝对中心矩$E[|x-\mu|^p]$随$p\in\mathbb{R}^+$的变化而演化$m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$。这种基于方法的一般自适应矩的应用将呈现在学生t分布上，尤其是在经济应用中流行，这里应用于DJIA公司的对数收益率。

    The real life time series are usually nonstationary, bringing a difficult question of model adaptation. Classical approaches like GARCH assume arbitrary type of dependence. To prevent such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\sum_{\tau<t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$ moving log-likelihood, evolving in time. It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $E[|x-\mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$ for one or multiple powers $p\in\mathbb{R}^+$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies.
    
[^7]: Dirichlet加权和的锐性偏差界及其在贝叶斯算法分析中的应用

    Sharp Deviations Bounds for Dirichlet Weighted Sums with Application to analysis of Bayesian algorithms. (arXiv:2304.03056v1 [math.PR])

    [http://arxiv.org/abs/2304.03056](http://arxiv.org/abs/2304.03056)

    本论文推导了Dirichlet随机变量的加权和的锐性有限差分界，同时应用于贝叶斯bootstrap和多臂赌博机分析，相对于现有的结果具有更好的结果。

    

    本文推导了Dirichlet随机变量的加权和的锐性有限差分界，这些界基于加权Dirichlet和密度的新的积分表达式，并利用几何和复分析方法得到了与高斯类似的逼近和和分布。我们的结果推广了经典论文Alfers和Dinges（1984）中Beta分布所得到的类似界，同时也可以看作是针对贝叶斯问题中Sanov定理的锐性有限版本，这一点由Ganesh和O'Connell（1999）进行了研究。利用这些结果，我们推导出对Dirichlet过程后验均值的新的偏差界，并通过贝叶斯bootstrap应用。最后，我们应用我们的估计结果到多臂赌博机中的Multinomial Thompson Sampling（TS）算法分析中，明显地改进了现有遗憾的界限而使它们不依赖于问题规模。

    In this work, we derive sharp non-asymptotic deviation bounds for weighted sums of Dirichlet random variables. These bounds are based on a novel integral representation of the density of a weighted Dirichlet sum. This representation allows us to obtain a Gaussian-like approximation for the sum distribution using geometry and complex analysis methods. Our results generalize similar bounds for the Beta distribution obtained in the seminal paper Alfers and Dinges [1984]. Additionally, our results can be considered a sharp non-asymptotic version of the inverse of Sanov's theorem studied by Ganesh and O'Connell [1999] in the Bayesian setting. Based on these results, we derive new deviation bounds for the Dirichlet process posterior means with application to Bayesian bootstrap. Finally, we apply our estimates to the analysis of the Multinomial Thompson Sampling (TS) algorithm in multi-armed bandits and significantly sharpen the existing regret bounds by making them independent of the size of
    
[^8]: 解析训练双层ReLU网络

    Training a Two Layer ReLU Network Analytically. (arXiv:2304.02972v1 [cs.LG])

    [http://arxiv.org/abs/2304.02972](http://arxiv.org/abs/2304.02972)

    本研究探讨了一种算法，可以使用解析的方法训练双层ReLU网络，相比随机梯度下降和Adam优化器能够找到更深的最小值，在四个真实数据集中获得了显著更小的训练损失值，同时该方法速度更快，调参参数更少。

    

    神经网络通常使用各种梯度下降的优化算法进行训练，如随机梯度下降或Adam优化器。最近的理论研究表明，双层ReLU网络的临界点（损失梯度为零的点）不都是局部最小值。然而，在本研究中，我们将探讨一种使用ReLU激活的双层神经网络和平方损失的算法，该算法交替地在一个层的情况下解析地找到损失函数的临界点，同时保持另一个层和神经元激活模式不变。实验表明，这个简单的算法比随机梯度下降或Adam优化器能够找到更深的最小值，在评估的五个真实数据集中有四个获得了显著更小的训练损失值。而且，该方法比梯度下降方法更快，几乎没有调参参数。

    Neural networks are usually trained with different variants of gradient descent based optimization algorithms such as stochastic gradient descent or the Adam optimizer. Recent theoretical work states that the critical points (where the gradient of the loss is zero) of two-layer ReLU networks with the square loss are not all local minima. However, in this work we will explore an algorithm for training two-layer neural networks with ReLU-like activation and the square loss that alternatively finds the critical points of the loss function analytically for one layer while keeping the other layer and the neuron activation pattern fixed. Experiments indicate that this simple algorithm can find deeper optima than Stochastic Gradient Descent or the Adam optimizer, obtaining significantly smaller training loss values on four out of the five real datasets evaluated. Moreover, the method is faster than the gradient descent methods and has virtually no tuning parameters.
    
[^9]: 实时物联网系统中新颖性检测的可适应和可解释框架

    Adaptable and Interpretable Framework for Novelty Detection in Real-Time IoT Systems. (arXiv:2304.02947v1 [cs.LG])

    [http://arxiv.org/abs/2304.02947](http://arxiv.org/abs/2304.02947)

    介绍了一种RAID算法，能够在多元动态过程中检测异常行为，具有适应非平稳效应、不需改变现有过程自动化基础设施等特点，可在不同领域高度部署，并通过实际数据案例研究证明其改进的检测准确性。

    

    本文介绍了一种名为Real-time Adaptive and Interpretable Detection (RAID)算法的新颖方法，它解决了多元动态过程异常检测方法的局限性，这些方法仅限于在模型训练条件范围内检测异常。RAID算法适应了非平稳效应，如数据漂移和变化点，在模型开发期间可能没有进行账务，从而延长了服务寿命。基于联合概率分布的动态模型处理系统中的异常行为检测和基于自适应过程限制的根本原因隔离。RAID算法不需要更改现有的过程自动化基础设施，因此可在不同领域高度部署。两个涉及实际动态系统数据的案例研究证明了RAID算法的好处，包括变更点适应性、根本原因隔离和改进的检测准确性。

    This paper presents the Real-time Adaptive and Interpretable Detection (RAID) algorithm. The novel approach addresses the limitations of state-of-the-art anomaly detection methods for multivariate dynamic processes, which are restricted to detecting anomalies within the scope of the model training conditions. The RAID algorithm adapts to non-stationary effects such as data drift and change points that may not be accounted for during model development, resulting in prolonged service life. A dynamic model based on joint probability distribution handles anomalous behavior detection in a system and the root cause isolation based on adaptive process limits. RAID algorithm does not require changes to existing process automation infrastructures, making it highly deployable across different domains. Two case studies involving real dynamic system data demonstrate the benefits of the RAID algorithm, including change point adaptation, root cause isolation, and improved detection accuracy.
    
[^10]: 高维超统计特征的分类方法

    Classification of Superstatistical Features in High Dimensions. (arXiv:2304.02912v1 [stat.ML])

    [http://arxiv.org/abs/2304.02912](http://arxiv.org/abs/2304.02912)

    本文利用经验风险最小化的方法，对高维超统计特征下的数据进行分类，并分析了正则化和分布尺度参数对分类的影响。

    

    在高维情况下，我们通过经验风险最小化的方法，对具有一般中心点的两个数据云的混合进行了学习，假设具有通用的凸损失和凸正则化。每个数据云是通过从可能是不可数的高斯分布叠加中进行采样来获得的，其方差具有通用的概率密度$\varrho$。我们的分析涵盖了大量的数据分布，包括没有协方差的幂律尾部分布的情况。我们研究了所得估计器的泛化性能，分析了正则化的作用以及分离转换与分布尺度参数的相关性。

    We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation. Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance. We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters.
    
[^11]: 深度神经网络的重尾部正则化

    Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks. (arXiv:2304.02911v1 [stat.ML])

    [http://arxiv.org/abs/2304.02911](http://arxiv.org/abs/2304.02911)

    本文介绍了一种名为重尾部正则化的技术，在深度神经网络中通过明确提倡更重的重尾谱来提高泛化性能。与标准正则化技术相比，该方法在基准数据集上实现了显着的改进。

    

    深度神经网络成功和显著的泛化能力背后的原因仍然是一个巨大的挑战。从随机矩阵理论得到的最新信息，特别是涉及深度神经网络中权重矩阵的谱分析的信息，为解决这个问题提供了有价值的线索。一个关键发现是，神经网络的泛化性能与其权重矩阵的谱的重尾程度相关。为了利用这一发现，我们介绍了一种新的正则化技术，称为重尾部正则化，通过正则化明确提倡权重矩阵中更重的重尾谱。首先，我们采用加权阿尔法和稳定秩作为惩罚项，两者都可微分，从而可以直接计算它们的梯度。为了避免过度正则化，我们介绍了两种惩罚函数的变体。然后，采用贝叶斯统计视角，我们提出了重尾部正则化的概率解释，使我们能够将其效果理解为权重矩阵的先验。在多个基准数据集上的实证评估表明，与标准正则化技术相比，我们的方法明显提高了泛化性能。

    Unraveling the reasons behind the remarkable success and exceptional generalization capabilities of deep neural networks presents a formidable challenge. Recent insights from random matrix theory, specifically those concerning the spectral analysis of weight matrices in deep neural networks, offer valuable clues to address this issue. A key finding indicates that the generalization performance of a neural network is associated with the degree of heavy tails in the spectrum of its weight matrices. To capitalize on this discovery, we introduce a novel regularization technique, termed Heavy-Tailed Regularization, which explicitly promotes a more heavy-tailed spectrum in the weight matrix through regularization. Firstly, we employ the Weighted Alpha and Stable Rank as penalty terms, both of which are differentiable, enabling the direct calculation of their gradients. To circumvent over-regularization, we introduce two variations of the penalty function. Then, adopting a Bayesian statistics
    
[^12]: 利用对称性在贝叶斯神经网络中实现高效MCMC采样

    Towards Efficient MCMC Sampling in Bayesian Neural Networks by Exploiting Symmetry. (arXiv:2304.02902v1 [stat.ML])

    [http://arxiv.org/abs/2304.02902](http://arxiv.org/abs/2304.02902)

    本文提出了一种利用对称性在贝叶斯神经网络中实现高效MCMC采样的方法，通过利用神经元可互换性和某些激活函数引起的对称性在参数后验的多模态性中找到平衡。

    

    由于高维，强多模态参数后验密度景观，深度神经网络的贝叶斯推断是具有挑战性的。马尔可夫链蒙特卡罗方法可以渐进性地恢复真实后验，但因其在大规模现代架构上被认为是代价高昂而难以应用。而局部方法，作为一种流行的替代方案，聚焦于可通过可积函数近似的特定参数区域。虽然这些方法常常能够产生满意的实证结果，但它们未能考虑参数后验的多模态性。本文认为，可以通过利用后验景观中的对称性来缓解精确但代价昂贵和廉价但不精确方法之间的困境。这种对称性由神经元可互换性和某些激活函数引起，在不同的参数值导致相同的功能输出值。我们理论上证明后验预测可以利用对称性被高效地计算和采样。

    Bayesian inference in deep neural networks is challenging due to the high-dimensional, strongly multi-modal parameter posterior density landscape. Markov chain Monte Carlo approaches asymptotically recover the true posterior but are considered prohibitively expensive for large modern architectures. Local methods, which have emerged as a popular alternative, focus on specific parameter regions that can be approximated by functions with tractable integrals. While these often yield satisfactory empirical results, they fail, by definition, to account for the multi-modality of the parameter posterior. In this work, we argue that the dilemma between exact-but-unaffordable and cheap-but-inexact approaches can be mitigated by exploiting symmetries in the posterior landscape. Such symmetries, induced by neuron interchangeability and certain activation functions, manifest in different parameter values leading to the same functional output value. We show theoretically that the posterior predictiv
    
[^13]: 变复杂度加权调节 Gibbs 采样用于贝叶斯变量选择

    Variable-Complexity Weighted-Tempered Gibbs Samplers for Bayesian Variable Selection. (arXiv:2304.02899v1 [stat.ML])

    [http://arxiv.org/abs/2304.02899](http://arxiv.org/abs/2304.02899)

    本文提出了一种变复杂度加权调节 Gibbs 采样器，用于贝叶斯变量选择，可以降低每个MCMC迭代的计算复杂度，并且可以在有限的迭代次数内控制估计器的方差。

    

    最近，Jankowiak引入了子集加权调节 Gibbs 采样器（wTGS），用于在高维应用程序中降低每个MCMC迭代的计算复杂度，其中后验包含概率（PIP）的精确计算并不重要。然而，与该采样器相关的Rao-Backwellized估计器具有高方差，因为信号维度与条件PIP估计数之比很大。在本文中，我们设计了一个新的子集加权调节 Gibbs 采样器（wTGS），其中每个MCMC迭代中可预期的条件PIP计算数量可以远小于信号维度。与子集wTGS和wTGS不同，我们的采样器具有可变的复杂度。我们在有限的迭代次数 $T$ 上提供了与该采样器关联的Rao-Blackwellized估计器的方差上限，并展示了该方差为 $O\big(\big(\frac{P}{S}\big)^2 \frac{\log T}{T}\big)$，其中 $\frac{P}{S}$ 是条件PIP估计数和信号维度之比。

    Subset weighted-Tempered Gibbs Sampler (wTGS) has been recently introduced by Jankowiak to reduce the computation complexity per MCMC iteration in high-dimensional applications where the exact calculation of the posterior inclusion probabilities (PIP) is not essential. However, the Rao-Backwellized estimator associated with this sampler has a high variance as the ratio between the signal dimension and the number of conditional PIP estimations is large. In this paper, we design a new subset weighted-Tempered Gibbs Sampler (wTGS) where the expected number of computations of conditional PIPs per MCMC iteration can be much smaller than the signal dimension. Different from the subset wTGS and wTGS, our sampler has a variable complexity per MCMC iteration. We provide an upper bound on the variance of an associated Rao-Blackwellized estimator for this sampler at a finite number of iterations, $T$, and show that the variance is $O\big(\big(\frac{P}{S}\big)^2 \frac{\log T}{T}\big)$ for a given 
    
[^14]: 面向类别不均问题的集成学习和数据增强模型综述：组合、实现和评估

    A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation. (arXiv:2304.02858v1 [cs.LG])

    [http://arxiv.org/abs/2304.02858](http://arxiv.org/abs/2304.02858)

    本文研究了集成学习和数据增强方法的应用，针对类别不平衡问题，通过计算评估，找到了最有效的组合。

    

    分类问题中的类别不平衡（CI）是指属于一个类的观测值数量低于其他类的数量。集成学习结合数据增强方法已被广泛应用于解决类别不平衡问题。在过去的十年里，一些策略已经被应用于增强集成学习和数据增强方法，同时还开发了一些新方法，如生成对抗网络（GAN）。本文对用于解决基准CI问题的数据增强和集成学习方法进行计算评估。我们提出了一个评估CI问题的10个数据增强方法和10个集成学习方法的通用框架。我们的目标是识别提高分类效果最有效的组合。

    Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classificat
    
[^15]: 分类中异方差标签噪声的逻辑正态似然

    Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification. (arXiv:2304.02849v1 [cs.LG])

    [http://arxiv.org/abs/2304.02849](http://arxiv.org/abs/2304.02849)

    该论文介绍了一种新的分类方法，用于提高鲁棒性，减少标签噪声的影响，其基于正态分布，并可通过最小化负对数似然来学习参数。

    

    在回归中估计异方差标签噪声的一种自然方法是将观测到的（可能带有噪声的）目标建模为一个正态分布的样本，其参数可以通过最小化负对数似然来学习。该损失具有期望的损失衰减特性，因为它可以降低高误差示例的贡献。直观地说，这种行为可以通过减少过拟合来提高对标签噪声的鲁棒性。我们提出了这种简单且概率化方法在分类中的扩展，具有相同的期望损失衰减特性。我们通过测量其对分类中标签噪声的鲁棒性来评估该方法的有效性。我们进行了启发性的实验，探索了该方法的内部工作原理，包括对超参数的敏感性，消融研究等。

    A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more.
    
[^16]: NTK-SAP: 通过对齐训练动态来提高神经网络剪枝

    NTK-SAP: Improving neural network pruning by aligning training dynamics. (arXiv:2304.02840v1 [cs.LG])

    [http://arxiv.org/abs/2304.02840](http://arxiv.org/abs/2304.02840)

    本文提出了一种新的神经网络剪枝方法：通过对齐训练动态来提高剪枝效果，具体来说就是剪去对NTK频谱影响最小的连接。采用这种方法有助于维持NTK频谱，从而将训练动态和其密集对应物的训练动态对齐。

    

    在训练之前剪枝神经网络因其减少训练时间和存储空间的潜力而受到越来越多的关注。其中一种流行的方法是基于某种度量对连接进行剪枝，但是什么度量是最好的选择还不完全清楚。神经切向核（NTK）理论的最新进展表明，足够大的神经网络的训练动态与NTK的频谱密切相关。在此发现的基础上，我们建议剪枝那些对NTK频谱影响最小的连接。这种方法有助于维持NTK频谱，这可能有助于将训练动态与其密集对应物的训练动态对齐。然而，一个可能的问题是给定初始点对应的固定权值NTK可能与训练阶段后的迭代对应的NTK非常不同。我们进一步提议对随机权重的多个实现进行采样以估计NTK频谱。请注意，我们的方法是权重无关的。

    Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK. Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK. This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart. However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase. We further propose to sample multiple realizations of random weights to estimate the NTK spectrum. Note that our approach is weight
    
[^17]: MethaneMapper: 光谱吸收感知高光谱转换器用于甲烷检测。

    MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection. (arXiv:2304.02767v1 [eess.IV])

    [http://arxiv.org/abs/2304.02767](http://arxiv.org/abs/2304.02767)

    MethaneMapper是一个可用于光谱域内定位甲烷排放区域的Transformer网络，并在模型尺寸上实现了优化。同时，作者介绍了一个用于研究甲烷检测问题的大规模数据集。

    

    甲烷(CH4)是全球气候变化的主要贡献者。本文提出了一个全新的端到端的光谱吸收波长感知Transformer网络MethaneMapper，用于检测和定量排放。MethaneMapper引入了两个新模块，帮助在光谱域中定位最相关的甲烷云区域，并用于准确地定位它们。充分的评估表明MethaneMapper在检测方面达到了0.63 mAP，并在模型尺寸上（缩小5倍）与现有技术水平相比实现了优化。此外，我们还介绍了一个大规模的甲烷云分割数据集，包括超过1000张AVIRIS-NG图像以及它们的真实世界地理参考数据。这个数据集将帮助研究人员更好地理解和解决在红外和可见光波长下的甲烷检测问题。

    Methane (CH$_4$) is the chief contributor to global climate change. Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions. Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable. To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions. MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately. Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art. In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1
    
[^18]: 非对数凹采样和对数分区估计的收敛速率

    Convergence Rates for Non-Log-Concave Sampling and Log-Partition Estimation. (arXiv:2303.03237v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.03237](http://arxiv.org/abs/2303.03237)

    非对数凹势V的高维采样速率可以在一些条件下实现与凸函数相同的收敛速率。

    

    从吉布斯分布$p(x)\propto\exp(-V(x)/\epsilon)$中采样并计算其对数分区函数是统计学、机器学习和统计物理中的基本任务。然而，虽然有效的算法已知于凸势函数$V$，但非凸情况下的情况要困难得多，算法必然在最坏情况下受到维度灾难的困扰。最近，已经证明在适当的条件下，高维采样非对数凹势V的速率也可以达到同样快的速度。本文对这些结果进行了回顾，并强调了领域中的一些开放问题。

    Sampling from Gibbs distributions $p(x) \propto \exp(-V(x)/\varepsilon)$ and computing their log-partition function are fundamental tasks in statistics, machine learning, and statistical physics. However, while efficient algorithms are known for convex potentials $V$, the situation is much more difficult in the non-convex case, where algorithms necessarily suffer from the curse of dimensionality in the worst case. For optimization, which can be seen as a low-temperature limit of sampling, it is known that smooth functions $V$ allow faster convergence rates. Specifically, for $m$-times differentiable functions in $d$ dimensions, the optimal rate for algorithms with $n$ function evaluations is known to be $O(n^{-m/d})$, where the constant can potentially depend on $m, d$ and the function to be optimized. Hence, the curse of dimensionality can be alleviated for smooth functions at least in terms of the convergence rate. Recently, it has been shown that similarly fast rates can also be ach
    
[^19]: PAD: 面向对抗逃避攻击的合理恶意软件检测

    PAD: Towards Principled Adversarial Malware Detection Against Evasion Attacks. (arXiv:2302.11328v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.11328](http://arxiv.org/abs/2302.11328)

    该论文提出了一个新的对抗性训练框架，称为合理对抗性恶意软件检测（PAD），它通过可学习的凸度量保护恶意软件检测器免受攻击者的影响，而不是简单的启发式方法。实验结果表明，该方法优于现有技术，提高了恶意软件检测的防御效果。

    

    机器学习技术可以促进恶意软件（简称为恶意软件）的自动检测，但受到逃避攻击的影响。许多研究采用启发式方法来应对这些攻击，缺乏理论保证和有效的防御。在本文中，我们提出了一个新的对抗性训练框架，称为合理对抗性恶意软件检测（PAD），它针对强大的优化方法提供了收敛保证。PAD建立在可学习的凸度量上，量化分布式离散扰动，以保护恶意软件检测器免受攻击者的影响，对于平滑检测器，可以进行理论上的对抗性训练。为了提高防御效果，我们提出了一种新的混合攻击方法来实现PAD，以增强基于深度神经网络的测量和恶意软件检测器。在两个Android恶意软件数据集上的实验结果表明：（i）所提出的方法明显优于现有技术。

    Machine Learning (ML) techniques can facilitate the automation of malicious software (malware for short) detection, but suffer from evasion attacks. Many studies counter such attacks in heuristic manners, lacking theoretical guarantees and defense effectiveness. In this paper, we propose a new adversarial training framework, termed Principled Adversarial Malware Detection (PAD), which offers convergence guarantees for robust optimization methods. PAD lays on a learnable convex measurement that quantifies distribution-wise discrete perturbations to protect malware detectors from adversaries, whereby for smooth detectors, adversarial training can be performed with theoretical treatments. To promote defense effectiveness, we propose a new mixture of attacks to instantiate PAD to enhance deep neural network-based measurements and malware detectors. Experimental results on two Android malware datasets demonstrate: (i) the proposed method significantly outperforms the state-of-the-art defens
    
[^20]: 通过GD训练的过度参数化浅层ReLU神经网络学习Lipschitz函数

    Learning Lipschitz Functions by GD-trained Shallow Overparameterized ReLU Neural Networks. (arXiv:2212.13848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13848](http://arxiv.org/abs/2212.13848)

    本论文通过GD训练过程中神经切向核（NTK）近似方法，探究了过度参数化的浅层ReLU神经网络学习Lipschitz函数的能力，提出了一系列能够产生最优速率的实用早停规则。

    

    本研究探究了过度参数化的浅层ReLU神经网络在通过梯度下降（GD）训练时学习具有加性噪声的Lipschitz、不可微分、有界函数的能力。为避免存在噪声时，神经网络训练到接近0的训练误差时不一致的问题，我们专注于停止较早的GD，从而展示了一致性和最优速率。具体来说，我们从GD训练的有限宽度神经网络的神经切向核（NTK）近似的视角探索了这个问题。我们发现，只要在ReLU激活函数引起的核的希尔伯特空间中，某些早停规则保证能够给出最优的超额风险速率，那么相同的规则就可以被用于实现在Lipschitz函数所考虑的类中通过神经网络学习的极小极值速率。我们讨论了几个无需数据和数据相关的实际吸引力停止准则，这些准则产生了最优速率。

    We explore the ability of overparameterized shallow ReLU neural networks to learn Lipschitz, nondifferentiable, bounded functions with additive noise when trained by Gradient Descent (GD). To avoid the problem that in the presence of noise, neural networks trained to nearly zero training error are inconsistent in this class, we focus on the early-stopped GD which allows us to show consistency and optimal rates. In particular, we explore this problem from the viewpoint of the Neural Tangent Kernel (NTK) approximation of a GD-trained finite-width neural network. We show that whenever some early stopping rule is guaranteed to give an optimal rate (of excess risk) on the Hilbert space of the kernel induced by the ReLU activation function, the same rule can be used to achieve minimax optimal rate for learning on the class of considered Lipschitz functions by neural networks. We discuss several data-free and data-dependent practically appealing stopping rules that yield optimal rates.
    
[^21]: 在线核CUSUM方法进行变点检测

    Online Kernel CUSUM for Change-Point Detection. (arXiv:2211.15070v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2211.15070](http://arxiv.org/abs/2211.15070)

    本研究提出了一种在线变点检测的核CUSUM方法，相比于现有方法更敏感，提供了准确的关键性能指标分析，并建立了最优窗口长度，引入了递归计算程序来确保计算和内存复杂度恒定。

    

    我们提出了一种高效的在线核Cumulative Sum (CUSUM)方法，用于变点检测，利用核统计量集合中的最大值来考虑未知的变点位置。相比于现有方法，如Scan-B统计量，即对应于非参数Shewhart图过程的方法，我们的方法对于小变化具有更高的敏感性。我们提供了两个关键性能指标的准确分析近似值：平均运行长度（ARL）和预期检测延迟（EDD），这使我们能够建立一个与ARL对数同阶的最优窗口长度，以确保相对于具有无限内存的理论模型能够保持最小功率损失。这类似于参数变点检测文献中的窗口限制广义似然比（GLR）过程的经典结果。此外，我们引入了一种递归计算程序，用于检测统计量，以确保计算和内存复杂度恒定。

    We propose an efficient online kernel Cumulative Sum (CUSUM) method for change-point detection that utilizes the maximum over a set of kernel statistics to account for the unknown change-point location. Our approach exhibits increased sensitivity to small changes compared to existing methods, such as the Scan-B statistic, which corresponds to a non-parametric Shewhart chart-type procedure. We provide accurate analytic approximations for two key performance metrics: the Average Run Length (ARL) and Expected Detection Delay (EDD), which enable us to establish an optimal window length on the order of the logarithm of ARL to ensure minimal power loss relative to an oracle procedure with infinite memory. Such a finding parallels the classic result for window-limited Generalized Likelihood Ratio (GLR) procedure in parametric change-point detection literature. Moreover, we introduce a recursive calculation procedure for detection statistics to ensure constant computational and memory complexi
    
[^22]: 带有符合性预测集的贝叶斯优化

    Bayesian Optimization with Conformal Prediction Sets. (arXiv:2210.12496v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12496](http://arxiv.org/abs/2210.12496)

    符合性贝叶斯优化在决策过程中应用符合性预测集，可以纠正由于模型规范不当和协变量转移带来的主观上不可能的结果，并在黑盒优化任务和表格排名任务中表现优异。

    

    贝叶斯优化是面对不确定性时做出决策的普遍方法，应用包括多臂老虎机、主动学习和黑盒优化。贝叶斯优化通过基于贝叶斯模型的后验分布选择具有最大预期效用的决策(即目标函数查询)，该后验分布量化了查询结果的可减少的先验信息不确定性。在实践中，因模型规范不当和协变量转移的原因，主观上不可能的结果可能经常发生。符合性预测是一种不确定性量化方法，即使对于规范不良的模型也具有覆盖保证，并且具有纠正协变量转移的简单机制。我们提出了符合性贝叶斯优化，将查询引导到模型预测具有保证有效性的搜索空间区域，并研究了它在一组黑盒优化任务和表格排名任务中的行为。在许多情况下，我们发现符合性贝叶斯优化优于标准贝叶斯优化方法。

    Bayesian optimization is a coherent, ubiquitous approach to decision-making under uncertainty, with applications including multi-arm bandits, active learning, and black-box optimization. Bayesian optimization selects decisions (i.e. objective function queries) with maximal expected utility with respect to the posterior distribution of a Bayesian model, which quantifies reducible, epistemic uncertainty about query outcomes. In practice, subjectively implausible outcomes can occur regularly for two reasons: 1) model misspecification and 2) covariate shift. Conformal prediction is an uncertainty quantification method with coverage guarantees even for misspecified models and a simple mechanism to correct for covariate shift. We propose conformal Bayesian optimization, which directs queries towards regions of search space where the model predictions have guaranteed validity, and investigate its behavior on a suite of black-box optimization tasks and tabular ranking tasks. In many cases we f
    
[^23]: 超图的Ollivier-Ricci曲率：一个统一的框架

    Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework. (arXiv:2210.12048v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12048](http://arxiv.org/abs/2210.12048)

    本论文提出了ORCHID框架，将Ollivier-Ricci曲率推广到超图领域，并证明了其具有良好的理论特性。实验结果表明ORCHID曲率对于超图任务有很好的应用性。

    

    曲率是一种强大而富有表现力的不变量，连接了几何和拓扑。虽然在流形和图的背景下，曲率的效用已经在理论和实证上得到了证实，但其在新兴的超图领域的推广仍然是一个未被充分探索的问题。在图上，Ollivier-Ricci曲率通过Wasserstein距离度量随机游走之间的不同，从而将几何概念落实到概率论和最优输运的思想中。我们开发了ORCHID，一个将Ollivier-Ricci曲率推广到超图的灵活框架，并证明了所得曲率具有良好的理论属性。通过对来自不同领域的合成和真实超图的广泛实验，我们证明ORCHID曲率既具有可扩展性，也有用于进行各种超图任务的实用性。

    Bridging geometry and topology, curvature is a powerful and expressive invariant. While the utility of curvature has been theoretically and empirically confirmed in the context of manifolds and graphs, its generalization to the emerging domain of hypergraphs has remained largely unexplored. On graphs, the Ollivier-Ricci curvature measures differences between random walks via Wasserstein distances, thus grounding a geometric concept in ideas from probability theory and optimal transport. We develop ORCHID, a flexible framework generalizing Ollivier-Ricci curvature to hypergraphs, and prove that the resulting curvatures have favorable theoretical properties. Through extensive experiments on synthetic and real-world hypergraphs from different domains, we demonstrate that ORCHID curvatures are both scalable and useful to perform a variety of hypergraph tasks in practice.
    
[^24]: 延迟反馈在广义线性赌博机中的研究再访

    Delayed Feedback in Generalised Linear Bandits Revisited. (arXiv:2207.10786v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.10786](http://arxiv.org/abs/2207.10786)

    研究了广义线性赌博机中的延迟奖励现象，提出了一种自然的乐观算法，可实现一个独立于时间的惩罚函数，降低了现有工作中随着时间增长而增加的惩罚函数的界限。

    

    随着许多真实世界的应用中奖励几乎总是被延迟，导致要求即时奖励的模型难以应用。本文将研究在广义线性赌博机中延迟奖励的现象。我们证明了一种自然的乐观算法适应延迟反馈领域能够有一个与时间无关的惩罚函数。这比现有的工作显著的提高了，因为最佳的已知的惩罚函数的界限随着时间的推移而增加。

    The stochastic generalised linear bandit is a well-understood model for sequential decision-making problems, with many algorithms achieving near-optimal regret guarantees under immediate feedback. However, the stringent requirement for immediate rewards is unmet in many real-world applications where the reward is almost always delayed. We study the phenomenon of delayed rewards in generalised linear bandits in a theoretical manner. We show that a natural adaptation of an optimistic algorithm to the delayed feedback achieves a regret bound where the penalty for the delays is independent of the horizon. This result significantly improves upon existing work, where the best known regret bound has the delay penalty increasing with the horizon. We verify our theoretical results through experiments on simulated data.
    
[^25]: 带随机变量的参数化验证-随机变分光滑模型检验的可扩展性研究

    Scalable Stochastic Parametric Verification with Stochastic Variational Smoothed Model Checking. (arXiv:2205.05398v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.05398](http://arxiv.org/abs/2205.05398)

    本论文提出了一种利用概率机器学习扩展平滑模型检验(smMC)方法的思路，从而使贝叶斯推理的smMC适用于更大的数据集和实际问题。

    

    针对随机模型的线性时态性属性的参数化验证可以表示为计算满足一定属性的概率，函数的参数为这个模型的参数。平滑模型检验(smMC)旨在从通过模拟获得的有限的观测值中推断出整个参数空间上的满足函数。由于观测成本高且噪声大，因此smMC被构建为贝叶斯推理问题，使估计值具有额外的不确定性量化。在smMC中，作者使用由期望传播算法推断出的高斯过程(GP)。这种方法提供了准确的重构和统计上合理的不确定性量化。然而，它继承了GP的著名可扩展性问题。因此，本文利用概率机器学习的最新进展，将贝叶斯推理的smMC扩展到更大的数据集，并使其适用于实际问题。

    Parametric verification of linear temporal properties for stochastic models can be expressed as computing the satisfaction probability of a certain property as a function of the parameters of the model. Smoothed model checking (smMC) aims at inferring the satisfaction function over the entire parameter space from a limited set of observations obtained via simulation. As observations are costly and noisy, smMC is framed as a Bayesian inference problem so that the estimates have an additional quantification of the uncertainty. In smMC the authors use Gaussian Processes (GP), inferred by means of the Expectation Propagation algorithm. This approach provides accurate reconstructions with statistically sound quantification of the uncertainty. However, it inherits the well-known scalability issues of GP. In this paper, we exploit recent advances in probabilistic machine learning to push this limitation forward, making Bayesian inference of smMC scalable to larger datasets and enabling its ap
    
[^26]: WOODS: 时间序列领域的离群分布广义性的基准测试

    WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series. (arXiv:2203.09978v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.09978](http://arxiv.org/abs/2203.09978)

    该论文提出了一个名为WOODS的时间序列基准测试，致力于解决在离群分布下的泛化过程中面临的挑战，还改进了目前时间序列任务中的离群分布广义性算法，并表明仍有很大的改进空间。

    

    机器学习模型在分布偏移下往往难以进行很好的泛化。理解和克服这些问题形成了离群分布广义性的研究领域。尽管对于静态计算机视觉任务已经得到广泛研究，但在时间序列任务中，离群分布广义性却鲜有探索。为减少这一差距，我们提出WOODS：八个具有挑战性的开源时间序列基准测试，涵盖了各种数据模态，例如视频、脑记录和传感器信号。我们改进了现有的时间序列任务的离群分布广义性算法，并使用我们的系统框架进行评估。我们的实验显示，对于我们的数据集，经验风险最小化和离群分布广义性算法仍有很大的改进空间，从而凸显了时间序列任务面临的新挑战。代码和文档可在https://woods-benchmarks.github.io获得。

    Machine learning models often fail to generalize well under distributional shifts. Understanding and overcoming these failures have led to a research field of Out-of-Distribution (OOD) generalization. Despite being extensively studied for static computer vision tasks, OOD generalization has been underexplored for time series tasks. To shine light on this gap, we present WOODS: eight challenging open-source time series benchmarks covering a diverse range of data modalities, such as videos, brain recordings, and sensor signals. We revise the existing OOD generalization algorithms for time series tasks and evaluate them using our systematic framework. Our experiments show a large room for improvement for empirical risk minimization and OOD generalization algorithms on our datasets, thus underscoring the new challenges posed by time series tasks. Code and documentation are available at https://woods-benchmarks.github.io .
    
[^27]: 连续重复退火流输运蒙特卡罗

    Continual Repeated Annealed Flow Transport Monte Carlo. (arXiv:2201.13117v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2201.13117](http://arxiv.org/abs/2201.13117)

    这篇论文提出了一种结合序列蒙特卡罗采样和标准化流变分推断的连续重复退火流输运蒙特卡罗方法，通过对标准化流的训练，实现不同温度下的传输，并在多个实例中展示了其优于其他方法的表现。

    

    我们提出连续重复退火流输运蒙特卡罗（CRAFT）方法，将序列蒙特卡罗（SMC）采样器（自身是逐步重要采样的推广）与使用标准化流的变分推断相结合。标准化流直接训练以在每个转换之间传输退火温度，使用KL散度进行优化目标，此优化目标本身使用标准化流/ SMC近似估计。我们在概念上和多个经验实例中展示了CRAFT优于Annealed Flow Transport Monte Carlo（Arbel等人，2021），并在其基础上改进了马尔可夫链蒙特卡罗（MCMC）的随机标准化流（Wu等人，2020）。通过在粒子MCMC中结合CRAFT，我们展示了这样学习的采样器在具有挑战性的晶格场论实例上可以实现令人印象深刻的精确结果。

    We propose Continual Repeated Annealed Flow Transport Monte Carlo (CRAFT), a method that combines a sequential Monte Carlo (SMC) sampler (itself a generalization of Annealed Importance Sampling) with variational inference using normalizing flows. The normalizing flows are directly trained to transport between annealing temperatures using a KL divergence for each transition. This optimization objective is itself estimated using the normalizing flow/SMC approximation. We show conceptually and using multiple empirical examples that CRAFT improves on Annealed Flow Transport Monte Carlo (Arbel et al., 2021), on which it builds and also on Markov chain Monte Carlo (MCMC) based Stochastic Normalizing Flows (Wu et al., 2020). By incorporating CRAFT within particle MCMC, we show that such learnt samplers can achieve impressively accurate results on a challenging lattice field theory example.
    
[^28]: 稳健对抗性训练的强力上界

    Robust Upper Bounds for Adversarial Training. (arXiv:2112.09279v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.09279](http://arxiv.org/abs/2112.09279)

    该论文提出了一种新的对抗性训练方法，通过最小化基于网络的整体展开的对抗损失上界来实现。与传统方法相比，该方法利用了最新的稳健优化领域的工具，可以在保证输出层绑定紧密性的同时，有效地进行训练。

    

    为了提供对抗攻击的安全保证，许多最先进的深度学习对抗性训练方法利用对抗损失的上界。然而，这些方法依赖于凸松弛来传播中间层的下界和上界，这会影响输出层绑定的紧密性。我们引入了一种新的对抗性训练方法，通过最小化基于网络的整体展开的对抗损失上界来实现。该上界利用了稳健优化领域的最新工具，具有闭合形式，并且可以使用反向传播进行有效训练。我们提出了两种新方法来实现这种方法。第一种方法（近似稳健上界或aRUB）使用网络的一阶近似和线性稳健优化的基本工具，获得对抗损失的经验上界，可以轻松实现。

    Many state-of-the-art adversarial training methods for deep learning leverage upper bounds of the adversarial loss to provide security guarantees against adversarial attacks. Yet, these methods rely on convex relaxations to propagate lower and upper bounds for intermediate layers, which affect the tightness of the bound at the output layer. We introduce a new approach to adversarial training by minimizing an upper bound of the adversarial loss that is based on a holistic expansion of the network instead of separate bounds for each layer. This bound is facilitated by state-of-the-art tools from Robust Optimization; it has closed-form and can be effectively trained using backpropagation. We derive two new methods with the proposed approach. The first method (Approximated Robust Upper Bound or aRUB) uses the first order approximation of the network as well as basic tools from Linear Robust Optimization to obtain an empirical upper bound of the adversarial loss that can be easily implement
    
[^29]: 高斯过程后验的主成分分析

    Principal component analysis for Gaussian process posteriors. (arXiv:2107.07115v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2107.07115](http://arxiv.org/abs/2107.07115)

    本文提出了高斯过程后验的主成分分析扩展，解决了如何定义一组具有无限维参数的GP的结构的问题，并且证明了通过元学习提高目标任务性能的有效性。

    

    本文提出了高斯过程后验的主成分分析（GP-PCA）扩展。由于GP-PCA估计了一个低维度的GP后验空间，因此可以用于元学习，这是一种通过估计一组任务的结构来提高目标任务性能的框架。本研究通过考虑具有相同先验的GP后验空间，在信息几何框架下将GP的无限维度问题缩减为有限维度的情况，从而解决了如何定义一组具有无限维参数（如坐标系和发散）的GP的结构的问题。此外，我们提出了一种基于变分推理的GP-PCA近似方法，并通过实验证明了GP-PCA作为元学习的有效性。

    This paper proposes an extension of principal component analysis for Gaussian process (GP) posteriors, denoted by GP-PCA. Since GP-PCA estimates a low-dimensional space of GP posteriors, it can be used for meta-learning, which is a framework for improving the performance of target tasks by estimating a structure of a set of tasks. The issue is how to define a structure of a set of GPs with an infinite-dimensional parameter, such as coordinate system and a divergence. In this study, we reduce the infiniteness of GP to the finite-dimensional case under the information geometrical framework by considering a space of GP posteriors that have the same prior. In addition, we propose an approximation method of GP-PCA based on variational inference and demonstrate the effectiveness of GP-PCA as meta-learning through experiments.
    
[^30]: 用于一类事件数据的顺序对抗异常检测

    Sequential Adversarial Anomaly Detection for One-Class Event Data. (arXiv:1910.09161v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1910.09161](http://arxiv.org/abs/1910.09161)

    本文提出了一种对抗顺序检测器，使用带标记的点过程模型捕捉序列事件中的相关性，可以应用于检测异常序列，通过解决最小最大问题，针对最坏情况的生成器，找到最佳检测器。

    

    本文考虑在单类场景下的顺序异常检测问题，仅在异常序列可用时，提出了一种对抗顺序检测器，通过解决最小最大问题，针对最坏情况的生成器，找到最佳检测器。生成器使用带标记的点过程模型捕捉序列事件中的相关性。检测器顺序评估测试序列的可能性，并将其与学习自最小最大问题的时间变化阈值进行比较。我们在模拟和专有的大规模信用卡欺诈数据集上展示了提出方法的良好性能。该方法通常适用于检测异常序列。

    We consider the sequential anomaly detection problem in the one-class setting when only the anomalous sequences are available and propose an adversarial sequential detector by solving a minimax problem to find an optimal detector against the worst-case sequences from a generator. The generator captures the dependence in sequential events using the marked point process model. The detector sequentially evaluates the likelihood of a test sequence and compares it with a time-varying threshold, also learned from data through the minimax problem. We demonstrate our proposed method's good performance using numerical experiments on simulations and proprietary large-scale credit card fraud datasets. The proposed method can generally apply to detecting anomalous sequences.
    

