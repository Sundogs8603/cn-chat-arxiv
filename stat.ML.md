# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers.](http://arxiv.org/abs/2304.14390) | 本文提出了一种扩展可微分AIS的方法，通过引入类似于顺序蒙特卡洛的重采样步骤来避免粒子滤波中的梯度方差问题。 |
| [^2] | [Functional Diffusion Maps.](http://arxiv.org/abs/2304.14378) | 本研究关注一种非线性流形学习方法：扩散映射。本文阐述如何将这种方法应用于功能数据，并将其与功能主成分分析进行比较。 |
| [^3] | [Variational Bayes Made Easy.](http://arxiv.org/abs/2304.14251) | 该论文提出了一个三步骤方法，简化了变分贝叶斯近似推断方法的推导过程。 |
| [^4] | [On Manifold Learning in Plato's Cave: Remarks on Manifold Learning and Physical Phenomena.](http://arxiv.org/abs/2304.14248) | 本文通过一个警示故事阐释了分析数据时，测量几何和底层现象几何差异带来的问题，以及这种差异在某些情况下如何导致对一个修正过的问题给出错误答案。这些问题适用于降维和无监督学习领域。 |
| [^5] | [LLT: An R package for Linear Law-based Feature Space Transformation.](http://arxiv.org/abs/2304.14211) | LLT是一个R包，用于线性定律特征空间变换，可以帮助对单变量和多变量时间序列进行分类。 |
| [^6] | [An Algorithm for Computing with Brauer's Group Equivariant Neural Network Layers.](http://arxiv.org/abs/2304.14165) | 本文提出一种算法，使用范畴论构造来实现的Brauer群等变神经网络层的乘积，同时采用Kronecker积矩阵，实现了显著的计算成本减少。 |
| [^7] | [Categorification of Group Equivariant Neural Networks.](http://arxiv.org/abs/2304.14144) | 本文利用范畴论构建的算法，成功快速计算了群等变神经网络的线性层函数。这种方法为深度学习的其他领域做出了有益的探索。 |
| [^8] | [The Structurally Complex with Additive Parent Causality (SCARY) Dataset.](http://arxiv.org/abs/2304.14109) | SCARY数据集是一个具有结构复杂性和附加父因果关系的合成数据集，包含40个场景、三个不同的种子、线性和混合因果机制等特点，能够提供更真实的因果关系探索环境。 |
| [^9] | [Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics.](http://arxiv.org/abs/2304.14094) | 本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。 |
| [^10] | [Interpretable Neural-Symbolic Concept Reasoning.](http://arxiv.org/abs/2304.14068) | 本文提出了第一个基于概念嵌入的可解释概念模型DCR，能够在多个数据集上实现接近最先进的准确性，相对于最先进的可解释概念模型提高了高达+25％，并产生能够解释其预测的人类可理解规则和真值度，适应性强。 |
| [^11] | [Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes.](http://arxiv.org/abs/2304.14034) | 本文研究了解耦高斯过程的正交分解问题，提出了一种扩展方法，即引入球形跨域特征，构建更灵活的数据依赖基函数来缓解限制，并展示了其有效性。 |
| [^12] | [Convergence of Adam Under Relaxed Assumptions.](http://arxiv.org/abs/2304.13972) | 本文对Adam算法做了新的假设并进行了证明，证明了在更加现实的条件下，Adam能够以较小的梯度复杂度达到稳定点。 |
| [^13] | [Fairness Uncertainty Quantification: How certain are you that the model is fair?.](http://arxiv.org/abs/2304.13950) | 本篇论文提出了一种针对机器学习模型公平性的不确定性量化方法，针对公平感知模型提供了置信区间（CI）来评估其测试不公平性。 |
| [^14] | [A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion.](http://arxiv.org/abs/2304.13940) | 本文提出了一种基于主导-最小化原则，通过低秩矩阵补全解决1比特矩阵补全问题的新方法，称为MMGN。通过应用高斯-牛顿方法，MMGN具有更快的速度和更准确的结果，同时还不太受到潜在矩阵尖锐度的影响。 |
| [^15] | [Bootstrapped Edge Count Tests for Nonparametric Two-Sample Inference Under Heterogeneity.](http://arxiv.org/abs/2304.13848) | 本文介绍了一种新的非参数检验方法，可以在处理多元和非欧几里得数据时准确地检测到两个样本之间的差异，该方法通过一个包含可能具有不同混合权重但相同组分分布的混合分布假设来处理异质性。 |
| [^16] | [Mixtures of Gaussian process experts based on kernel stick-breaking processes.](http://arxiv.org/abs/2304.13833) | 提出了一种新的基于核棍棒过程的高斯过程专家混合模型，能够维持直观吸引力并提高模型性能，具有实用性。 |
| [^17] | [Adaptation to Misspecified Kernel Regularity in Kernelised Bandits.](http://arxiv.org/abs/2304.13830) | 本文研究了核化赌博问题中对核函数规则性错误的自适应性问题。我们证明了在具有不同规则性的一对RKHS中同时实现最佳累计遗憾是不可能的，并通过现有算法结合极小化非自适应的核赌博机算法，验证了这一下限的紧密性。 |
| [^18] | [Generalized generalized linear models: Convex estimation and online bounds.](http://arxiv.org/abs/2304.13793) | 该论文提出了一种用于估计时间空间数据中依赖关系的广义广义线性模型（GGLM）参数的计算框架，使用单调运算符的变分不等式方法克服了参数估计中的非凸性并为参数恢复提供保证 |
| [^19] | [Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization.](http://arxiv.org/abs/2304.13761) | 通过独热编码和正则化提高梯度提升决策树的鲁棒性，研究表明对带有$L_1$或$L_2$正则化的线性回归形式进行拟合可提高GBDT模型的鲁棒性。 |
| [^20] | [TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation.](http://arxiv.org/abs/2304.13742) | 本文提出了TR0N，将预训练的无条件生成模型转化为高度任意的条件模型。TR0N不需要训练数据或微调，可以在MS-COCO上实现零-shot FID 10.9，并在采样速度上优于竞品，同时保持了多样性和质量。 |
| [^21] | [A mean-field games laboratory for generative modeling.](http://arxiv.org/abs/2304.13534) | 本文提出了使用均场博弈作为实验室对生成模型进行设计和分析的方法，并建立了这种方法与主要流动和扩散型生成模型之间的关联。通过研究每个生成模型与它们相关的 MFG 的最优条件，本文提出了一个基于双人 MFG 的新的生成模型，该模型在提高样本多样性和逼真度的同时改善了解缠结和公平性。 |
| [^22] | [An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response.](http://arxiv.org/abs/2303.17823) | 本文提出了一种基于可解释神经网络的非比例赔率模型 (N$^3$POM) 用于有序回归，可以对连续变量进行预测，同时保留了可解释性，具有灵活性。 |
| [^23] | [Synthetic Data Generator for Adaptive Interventions in Global Health.](http://arxiv.org/abs/2303.01954) | 通过HealthSyn生成基于真实世界的移动健康干预数据，以帮助在全球卫生领域中发展、测试和评估机器学习算法和干预措施。 |
| [^24] | [Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both Worlds in Stochastic and Deterministic Environments.](http://arxiv.org/abs/2301.13446) | 本研究将马尔可夫决策过程的方差相关遗憾界限应用到强化学习中，提出了两个新的环境规范来表征环境的方差属性，并设计出基于模型和无模型的算法，对于随机和确定性环境同时极小极大最优的界限是第一次被证明出来的。 |
| [^25] | [Geometry-Complete Perceptron Networks for 3D Molecular Graphs.](http://arxiv.org/abs/2211.02504) | 本研究引入了一种新的几何完备的图神经网络 GCPNet，用于3D分子图的表示学习，并在多个几何任务上展示了其出色的预测性能。其中最佳表现是在蛋白质-配体结合亲和力预测上得到了比当前最先进方法高出5%以上的相关系数。 |
| [^26] | [Beyond calibration: estimating the grouping loss of modern neural networks.](http://arxiv.org/abs/2210.16315) | 本文提出了一个估计器来近似神经网络的分组损失，并表明现代神经网络在视觉和NLP中展示出显著的分组损失。 |
| [^27] | [Packed-Ensembles for Efficient Uncertainty Estimation.](http://arxiv.org/abs/2210.09184) | Packed-Ensembles是一种能够在标准神经网络内运行的轻量级结构化集合，它通过精心调节编码空间的维度来设计。该方法在不损失效果的情况下提高了训练和推理速度。 |
| [^28] | [Statistical Learning Theory for Control: A Finite Sample Perspective.](http://arxiv.org/abs/2209.05423) | 本文概述了控制领域中最重要的统计学习理论中的最近进展，这些进展主要围绕在线性系统辨识和学习方面，基于现代高维统计学和学习理论的工具，为将机器学习工具融入控制领域的人提供了自包含演示。 |
| [^29] | [DORA: Exploring outlier representations in Deep Neural Networks.](http://arxiv.org/abs/2206.04530) | 本文提出了一种名为DORA的数据不可知框架，用于分析深度神经网络中的表征空间，并可以识别不符合人类直观认知的表征。 |
| [^30] | [Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects.](http://arxiv.org/abs/2205.14714) | 本文探讨了利用元学习器估计多值处理异质效应的问题，发现朴素扩展并不总是可行，提出并讨论了一些表现良好的元学习器。 |
| [^31] | [Dependent Latent Class Models.](http://arxiv.org/abs/2205.08677) | 本文介绍了一种新的贝叶斯模型依赖隐变量类模型（DLCM），相比传统的隐变量类模型（LCMs），DLCMs更适用于具有时间序列、重叠项和结构零等特点的应用。 |
| [^32] | [Spherical Rotation Dimension Reduction with Geometric Loss Functions.](http://arxiv.org/abs/2204.10975) | 该论文提出了一种名为SRCA的非线性降维方法，在处理高维度的低样本大小数据时，通过引入球体或椭球体，保留数据的几何结构，提高近似低维流形的效果。 |
| [^33] | [Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems.](http://arxiv.org/abs/2108.00473) | 本文提出针对非凸-凹极小极大问题的无导数交替投影算法，包括光滑问题的交替随机梯度投影算法（ZO-AGP），以及块状非光滑问题的分块交替随机近端梯度算法（ZO-BAPG）。这些算法具有较少的函数值估计和较高的迭代复杂度。 |
| [^34] | [Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks.](http://arxiv.org/abs/2105.03692) | 本文提出了一种基于不兼容性的聚类机制，该机制可以将数据集划分为由训练过程的目标所定义且具有意义的聚类，并有效减轻后门攻击的影响。 |
| [^35] | [A diffusion approach to Stein's method on Riemannian manifolds.](http://arxiv.org/abs/2003.11497) | 该论文介绍了一种用于Riemann流形上积分度量限制的Stein方法的扩散方法，并通过分析一对具有不同起始点的扩散之间的距离过程，导出了曲率相关的Stein因子。 |

# 详细

[^1]: 可微分顺序蒙特卡洛采样器中的重采样梯度问题

    Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers. (arXiv:2304.14390v1 [stat.ML])

    [http://arxiv.org/abs/2304.14390](http://arxiv.org/abs/2304.14390)

    本文提出了一种扩展可微分AIS的方法，通过引入类似于顺序蒙特卡洛的重采样步骤来避免粒子滤波中的梯度方差问题。

    

    退火重要性采样（AIS）是将粒子沿着一个马尔科夫链从可计算的初始分布移动到不可计算的目标分布。最近提出的可微分AIS（DAIS）允许对AIS的转移核和分布进行高效优化。然而，我们观察到DAIS中存在低有效样本量，表明分布退化。因此，我们借鉴顺序蒙特卡洛方法提出了一个重采样步骤来扩展DAIS。令人惊讶的是，我们在经验上发现，也可以在理论上解释，无需通过重采样步骤进行微分，这避免了粒子滤波中观察到的梯度方差问题。

    Annealed Importance Sampling (AIS) moves particles along a Markov chain from a tractable initial distribution to an intractable target distribution. The recently proposed Differentiable AIS (DAIS) (Geffner and Domke, 2021; Zhang et al., 2021) enables efficient optimization of the transition kernels of AIS and of the distributions. However, we observe a low effective sample size in DAIS, indicating degenerate distributions. We thus propose to extend DAIS by a resampling step inspired by Sequential Monte Carlo. Surprisingly, we find empirically-and can explain theoretically-that it is not necessary to differentiate through the resampling step which avoids gradient variance issues observed in similar approaches for Particle Filters (Maddison et al., 2017; Naesseth et al., 2018; Le et al., 2018).
    
[^2]: 功能扩散映射

    Functional Diffusion Maps. (arXiv:2304.14378v1 [cs.LG])

    [http://arxiv.org/abs/2304.14378](http://arxiv.org/abs/2304.14378)

    本研究关注一种非线性流形学习方法：扩散映射。本文阐述如何将这种方法应用于功能数据，并将其与功能主成分分析进行比较。

    

    如今，许多现实世界的数据集可以被视为是功能性的，也就是说生成它们的过程是连续的。这种类型数据的一个基本特性是，理论上它们属于无限维空间。尽管在实践中，我们通常只能得到有限数量的观察结果，它们仍然是高维的，因此降维方法至关重要。在这方面，功能数据分析的主要现有方法是功能主成分分析。尽管如此，这种经典技术假设数据位于一个线性流形中，因此当这个假设不成立时可能会出现问题。本研究聚焦于一种非线性流形学习方法：扩散映射。本文解释了如何将这种多变量方法扩展到功能数据，并将其行为与功能主成分分析在不同的模拟和实际例子中进行了比较。

    Nowadays many real-world datasets can be considered as functional, in the sense that the processes which generate them are continuous. A fundamental property of this type of data is that in theory they belong to an infinite-dimensional space. Although in practice we usually receive finite observations, they are still high-dimensional and hence dimensionality reduction methods are crucial. In this vein, the main state-of-the-art method for functional data analysis is Functional PCA. Nevertheless, this classic technique assumes that the data lie in a linear manifold, and hence it could have problems when this hypothesis is not fulfilled. In this research, attention has been placed on a non-linear manifold learning method: Diffusion Maps. The article explains how to extend this multivariate method to functional data and compares its behavior against Functional PCA over different simulated and real examples.
    
[^3]: 简化变分贝叶斯方法的推导过程

    Variational Bayes Made Easy. (arXiv:2304.14251v1 [cs.LG])

    [http://arxiv.org/abs/2304.14251](http://arxiv.org/abs/2304.14251)

    该论文提出了一个三步骤方法，简化了变分贝叶斯近似推断方法的推导过程。

    

    变分贝叶斯方法是一种流行的近似推断方法，但其推导过程可能很繁琐。为了简化这个过程，我们给出了一个三步骤的方法，通过显式寻找关于已知分布期望的线性性，来确定后验分布形式。然后我们可以直接通过“读取”这些期望前的项，写出更新。这个方法使得推导更加简单，快速，简短和通用。

    Variational Bayes is a popular method for approximate inference but its derivation can be cumbersome. To simplify the process, we give a 3-step recipe to identify the posterior form by explicitly looking for linearity with respect to expectations of well-known distributions. We can then directly write the update by simply ``reading-off'' the terms in front of those expectations. The recipe makes the derivation easier, faster, shorter, and more general.
    
[^4]: 关于洛克斯洞穴的流形学习：关于流形学习和物理现象的评论（arXiv:2304.14248v1 [stat.ML]）

    On Manifold Learning in Plato's Cave: Remarks on Manifold Learning and Physical Phenomena. (arXiv:2304.14248v1 [stat.ML])

    [http://arxiv.org/abs/2304.14248](http://arxiv.org/abs/2304.14248)

    本文通过一个警示故事阐释了分析数据时，测量几何和底层现象几何差异带来的问题，以及这种差异在某些情况下如何导致对一个修正过的问题给出错误答案。这些问题适用于降维和无监督学习领域。

    

    许多机器学习技术尝试通过测量不需要对物理现象或测量设备进行显式建模的低维流形结构来推断潜在物理现象的低维流形结构，这篇论文提出了关于测量几何和底层现象几何之间差异的警示故事。在普通情况下，这篇论文所展示的度量形变在数学上是直接而不可避免的，并且它只是数个类似效应中的一个。虽然这并不总是出现问题，但我们提供了一个标准且无害数据处理过程的例子，其中这种影响导致对一个看似简单的问题给出了错误的答案。尽管我们关注流形学习，但这些问题广泛适用于降维和无监督学习领域。

    Many techniques in machine learning attempt explicitly or implicitly to infer a low-dimensional manifold structure of an underlying physical phenomenon from measurements without an explicit model of the phenomenon or the measurement apparatus. This paper presents a cautionary tale regarding the discrepancy between the geometry of measurements and the geometry of the underlying phenomenon in a benign setting. The deformation in the metric illustrated in this paper is mathematically straightforward and unavoidable in the general case, and it is only one of several similar effects. While this is not always problematic, we provide an example of an arguably standard and harmless data processing procedure where this effect leads to an incorrect answer to a seemingly simple question. Although we focus on manifold learning, these issues apply broadly to dimensionality reduction and unsupervised learning.
    
[^5]: LLT：线性定律特征空间变换的R包

    LLT: An R package for Linear Law-based Feature Space Transformation. (arXiv:2304.14211v1 [cs.LG])

    [http://arxiv.org/abs/2304.14211](http://arxiv.org/abs/2304.14211)

    LLT是一个R包，用于线性定律特征空间变换，可以帮助对单变量和多变量时间序列进行分类。

    

    线性定律特征空间转换(LLT )算法的目标是帮助对单变量和多变量时间序列进行分类。LLT R包以灵活和用户友好的方式实现了该算法。该包将实例分为训练和测试集，并利用时延嵌入和谱分解技术，识别训练集中每个输入序列(初始特征)的控制模式(称为线性定律)。最后，它应用训练集的线性定律来转换测试集的初始特征。trainTest、trainLaw和testTrans三个单独的函数来执行这些步骤，它们需要预定义的数据结构;然而，为了快速计算，它们只使用内置函数。LLT R包和适当数据结构的示例数据集在GitHub上公开可用。

    The goal of the linear law-based feature space transformation (LLT) algorithm is to assist with the classification of univariate and multivariate time series. The presented R package, called LLT, implements this algorithm in a flexible yet user-friendly way. This package first splits the instances into training and test sets. It then utilizes time-delay embedding and spectral decomposition techniques to identify the governing patterns (called linear laws) of each input sequence (initial feature) within the training set. Finally, it applies the linear laws of the training set to transform the initial features of the test set. These steps are performed by three separate functions called trainTest, trainLaw, and testTrans. Their application requires a predefined data structure; however, for fast calculation, they use only built-in functions. The LLT R package and a sample dataset with the appropriate data structure are publicly available on GitHub.
    
[^6]: 一种计算Brauer群等变神经网络层的算法

    An Algorithm for Computing with Brauer's Group Equivariant Neural Network Layers. (arXiv:2304.14165v1 [cs.LG])

    [http://arxiv.org/abs/2304.14165](http://arxiv.org/abs/2304.14165)

    本文提出一种算法，使用范畴论构造来实现的Brauer群等变神经网络层的乘积，同时采用Kronecker积矩阵，实现了显著的计算成本减少。

    

    在arXiv：2212.08630中，对介于$\mathbb{R}^{n}$的张量幂空间之间的可等变于正交群，$O(n)$，特殊正交群，$SO(n)$，和辛群，$Sp(n)$的线性神经网络层进行了表征。本文提出了一种算法，使用范畴论构造来实现过程，通过利用Kronecker积矩阵来执行乘法，与简单的实现相比，实现了显著的计算成本减少。我们展示了我们的方法扩展到对称组，$S_n$，在此过程中恢复了arXiv：2303.06208的算法。

    The learnable, linear neural network layers between tensor power spaces of $\mathbb{R}^{n}$ that are equivariant to the orthogonal group, $O(n)$, the special orthogonal group, $SO(n)$, and the symplectic group, $Sp(n)$, were characterised in arXiv:2212.08630. We present an algorithm for multiplying a vector by any weight matrix for each of these groups, using category theoretic constructions to implement the procedure. We achieve a significant reduction in computational cost compared with a naive implementation by making use of Kronecker product matrices to perform the multiplication. We show that our approach extends to the symmetric group, $S_n$, recovering the algorithm of arXiv:2303.06208 in the process.
    
[^7]: 分类化群等变神经网络

    Categorification of Group Equivariant Neural Networks. (arXiv:2304.14144v1 [cs.LG])

    [http://arxiv.org/abs/2304.14144](http://arxiv.org/abs/2304.14144)

    本文利用范畴论构建的算法，成功快速计算了群等变神经网络的线性层函数。这种方法为深度学习的其他领域做出了有益的探索。

    

    我们提出了范畴论在深度学习中的一种新应用。我们展示了如何利用范畴论来理解和处理群等变神经网络的线性层函数，其中层是$\mathbb{R}^{n}$的某些张量幂空间，对应于群$S_n$、$O(n)$、$Sp(n)$和$SO(n)$。通过使用范畴论构建，我们建立了比这些神经网络的原始公式更丰富的结构，得出了新的见解。特别是，我们概述了一种算法的开发，该算法可以快速计算通过每个问题中的群等变线性层传递的向量的结果。我们的方法的成功表明，范畴论可以对深度学习的其他领域有益。

    We present a novel application of category theory for deep learning. We show how category theory can be used to understand and work with the linear layer functions of group equivariant neural networks whose layers are some tensor power space of $\mathbb{R}^{n}$ for the groups $S_n$, $O(n)$, $Sp(n)$, and $SO(n)$. By using category theoretic constructions, we build a richer structure that is not seen in the original formulation of these neural networks, leading to new insights. In particular, we outline the development of an algorithm for quickly computing the result of a vector that is passed through an equivariant, linear layer for each group in question. The success of our approach suggests that category theory could be beneficial for other areas of deep learning.
    
[^8]: 结构复杂、具有附加父因果关系的SCARY数据集

    The Structurally Complex with Additive Parent Causality (SCARY) Dataset. (arXiv:2304.14109v1 [stat.ML])

    [http://arxiv.org/abs/2304.14109](http://arxiv.org/abs/2304.14109)

    SCARY数据集是一个具有结构复杂性和附加父因果关系的合成数据集，包含40个场景、三个不同的种子、线性和混合因果机制等特点，能够提供更真实的因果关系探索环境。

    

    因果关系数据集在推动因果学领域方面起着至关重要的作用。然而，现有数据集往往缺乏真实世界问题的复杂性，如选择偏差、不忠实数据和混淆。为了填补这一空白，我们提出了一个新的合成因果数据集，即结构复杂、具有附加父因果关系的SCARY数据集，它包括以下特征。数据集包括40个场景，每个场景生成3个不同的种子，使研究人员能够利用相关数据子集。此外，我们使用两种不同的数据生成机制来生成父节点和子节点之间的因果关系，包括线性和混合因果机制以及多个子类型。我们的数据集生成器受到因果发现工具箱的启发，仅生成加性模型。数据集的Varsortability为0.5。我们的SCARY数据集为研究人员在更现实的场景下探索因果发现提供了一个有价值的资源。

    Causal datasets play a critical role in advancing the field of causality. However, existing datasets often lack the complexity of real-world issues such as selection bias, unfaithful data, and confounding. To address this gap, we propose a new synthetic causal dataset, the Structurally Complex with Additive paRent causalitY (SCARY) dataset, which includes the following features. The dataset comprises 40 scenarios, each generated with three different seeds, allowing researchers to leverage relevant subsets of the dataset. Additionally, we use two different data generation mechanisms for generating the causal relationship between parents and child nodes, including linear and mixed causal mechanisms with multiple sub-types. Our dataset generator is inspired by the Causal Discovery Toolbox and generates only additive models. The dataset has a Varsortability of 0.5. Our SCARY dataset provides a valuable resource for researchers to explore causal discovery under more realistic scenarios. The
    
[^9]: 可解释人工智能的范畴基础：一种统一的结构和语义形式体系。

    Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics. (arXiv:2304.14094v1 [cs.AI])

    [http://arxiv.org/abs/2304.14094](http://arxiv.org/abs/2304.14094)

    本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。

    

    可解释人工智能（XAI）旨在回答与AI模型部署相关的伦理和法律问题。然而，相当数量的领域特定评论强调需要一个数学基础来定义领域中的关键概念，即使“解释”这个术语还缺乏精确定义。这些评论还主张建立一个健全而统一的可解释AI形式体系，以避免出现不良提出问题，帮助研究人员浏览一个快速增长的知识体系。据作者所知，该论文是填补该空白的首次尝试，通过形式化一个可解释AI的统一理论。采用范畴理论的框架，特别是反馈单调范畴，我们首先提供了可解释AI中所有重要术语的形式定义。然后，我们提出了一个遵循提出结构的领域分类法，展示了如何使用引入的理论来对当前研究的所有主要XAI系统类进行分类。

    Explainable AI (XAI) aims to answer ethical and legal questions associated with the deployment of AI models. However, a considerable number of domain-specific reviews highlight the need of a mathematical foundation for the key notions in the field, considering that even the term "explanation" still lacks a precise definition. These reviews also advocate for a sound and unifying formalism for explainable AI, to avoid the emergence of ill-posed questions, and to help researchers navigate a rapidly growing body of knowledge. To the authors knowledge, this paper is the first attempt to fill this gap by formalizing a unifying theory of XAI. Employing the framework of category theory, and feedback monoidal categories in particular, we first provide formal definitions for all essential terms in explainable AI. Then we propose a taxonomy of the field following the proposed structure, showing how the introduced theory can be used to categorize all the main classes of XAI systems currently studi
    
[^10]: 可解释的神经符号概念推理

    Interpretable Neural-Symbolic Concept Reasoning. (arXiv:2304.14068v1 [cs.AI])

    [http://arxiv.org/abs/2304.14068](http://arxiv.org/abs/2304.14068)

    本文提出了第一个基于概念嵌入的可解释概念模型DCR，能够在多个数据集上实现接近最先进的准确性，相对于最先进的可解释概念模型提高了高达+25％，并产生能够解释其预测的人类可理解规则和真值度，适应性强。

    

    深度学习方法具有高度的准确性，但它们不透明的决策过程阻止了它们获得完全的人类信任。概念模型旨在通过学习一组人类可理解的概念来解决这个问题。然而，最先进的概念模型依赖于高维概念嵌入表示，缺乏明确的语义含义，因此质疑其决策过程的可解释性。为了克服这个限制，我们提出了Deep Concept Reasoner(DCR)，这是第一个基于概念嵌入的可解释概念模型。在DCR中，神经网络不直接进行任务预测，而是使用概念嵌入建立语法规则结构。然后DCR在有意义的概念真值度上执行这些规则，以不可微分的方式提供最终的可解释和语义一致的预测。我们的实验表明，DCR：(i)在多个数据集上实现接近最先进的准确性，同时相对于最先进的可解释概念模型提高了高达+25％;(ii)产生能够解释其预测的人类可理解规则和真值度;(iii)很容易适应新领域。

    Deep learning methods are highly accurate, yet their opaque decision process prevents them from earning full human trust. Concept-based models aim to address this issue by learning tasks based on a set of human-understandable concepts. However, state-of-the-art concept-based models rely on high-dimensional concept embedding representations which lack a clear semantic meaning, thus questioning the interpretability of their decision process. To overcome this limitation, we propose the Deep Concept Reasoner (DCR), the first interpretable concept-based model that builds upon concept embeddings. In DCR, neural networks do not make task predictions directly, but they build syntactic rule structures using concept embeddings. DCR then executes these rules on meaningful concept truth degrees to provide a final interpretable and semantically-consistent prediction in a differentiable manner. Our experiments show that DCR: (i) improves up to +25% w.r.t. state-of-the-art interpretable concept-based
    
[^11]: 正交解耦高斯过程的球形感应特征

    Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes. (arXiv:2304.14034v1 [cs.LG])

    [http://arxiv.org/abs/2304.14034](http://arxiv.org/abs/2304.14034)

    本文研究了解耦高斯过程的正交分解问题，提出了一种扩展方法，即引入球形跨域特征，构建更灵活的数据依赖基函数来缓解限制，并展示了其有效性。

    

    尽管高斯过程（GPs）具有许多优点，但它们缺乏学习表征的能力，因此经常与深度神经网络（NNs）进行比较。最近的工作通过在诱导变量与前馈NN的隐藏单元之间建立联系的跨域变分GPs来弥合 GPs和深度NN之间的差距。本文在研究此方法与实际应用中的一些实际问题，并提出一种扩展方法，利用GPs的正交分解来减轻这些限制。具体地，我们引入球形跨域特征，构建更灵活的数据依赖基函数，用于GP逼近的主要和正交分量，结果表明在此框架下加入NN激活特征，不仅可以缓解这些问题，而且比其他策略更具有可扩展性。在多个基准数据集上的实验表明了我们方法的有效性。

    Despite their many desirable properties, Gaussian processes (GPs) are often compared unfavorably to deep neural networks (NNs) for lacking the ability to learn representations. Recent efforts to bridge the gap between GPs and deep NNs have yielded a new class of inter-domain variational GPs in which the inducing variables correspond to hidden units of a feedforward NN. In this work, we examine some practical issues associated with this approach and propose an extension that leverages the orthogonal decomposition of GPs to mitigate these limitations. In particular, we introduce spherical inter-domain features to construct more flexible data-dependent basis functions for both the principal and orthogonal components of the GP approximation and show that incorporating NN activation features under this framework not only alleviates these shortcomings but is more scalable than alternative strategies. Experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.
    
[^12]: 松弛假设下Adam收敛性的证明

    Convergence of Adam Under Relaxed Assumptions. (arXiv:2304.13972v1 [math.OC])

    [http://arxiv.org/abs/2304.13972](http://arxiv.org/abs/2304.13972)

    本文对Adam算法做了新的假设并进行了证明，证明了在更加现实的条件下，Adam能够以较小的梯度复杂度达到稳定点。

    

    本文针对一类广泛的优化目标，对自适应矩估计（Adam）算法的收敛性进行了严格证明。虽然Adam算法在训练深度神经网络中的流行度和效率很高，但其理论性质尚未完全理解，现有的收敛性证明需要过于强的假设，如全局梯度有界，以证明收敛到稳定点。本文证明了在更为现实的条件下，Adam能以$\mathcal{O}(\epsilon^{-4})$梯度复杂度收敛到$\epsilon$-稳定点。我们分析的关键是根据一种广义光滑性假设给出的，沿着优化轨迹的梯度有界的新证明。根据该假设，局部光滑性(即存在时的Hessian norm)受梯度范数的次平方函数限制。此外，我们提出了一种方差约减版本的Adam与加速Gradient。

    In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\epsilon$-stationary points with $\mathcal{O}(\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradien
    
[^13]: 公平性不确定性量化: 您有多大把握模型是公平的?

    Fairness Uncertainty Quantification: How certain are you that the model is fair?. (arXiv:2304.13950v1 [stat.ML])

    [http://arxiv.org/abs/2304.13950](http://arxiv.org/abs/2304.13950)

    本篇论文提出了一种针对机器学习模型公平性的不确定性量化方法，针对公平感知模型提供了置信区间（CI）来评估其测试不公平性。

    

    最近几年，由于机器学习在司法系统等敏感应用中的广泛使用，公平感知机器学习引起了广泛关注。提出了各种启发式和优化框架来强制实现分类中的公平性，其中后一种方法要么提供经验结果，要么为目标函数的精确最小化器提供公平性保证。在现代机器学习中，几乎总是使用随机梯度下降（SGD）类型的算法作为训练算法，这意味着学习的模型以及其公平性属性是随机的。因此，尤其是对于关键应用程序，必须构建置信区间（CI）以评估所学模型的公平性。在这项工作中，我们为测试不公平性提供了置信区间（CI），具体而言，是在考虑到群体公平性的前提下，即差异影响（DI）和不公平影响（DM）感知的线性二元分类模型。

    Fairness-aware machine learning has garnered significant attention in recent years because of extensive use of machine learning in sensitive applications like judiciary systems. Various heuristics, and optimization frameworks have been proposed to enforce fairness in classification \cite{del2020review} where the later approaches either provides empirical results or provides fairness guarantee for the exact minimizer of the objective function \cite{celis2019classification}. In modern machine learning, Stochastic Gradient Descent (SGD) type algorithms are almost always used as training algorithms implying that the learned model, and consequently, its fairness properties are random. Hence, especially for crucial applications, it is imperative to construct Confidence Interval (CI) for the fairness of the learned model. In this work we provide CI for test unfairness when a group-fairness-aware, specifically, Disparate Impact (DI), and Disparate Mistreatment (DM) aware linear binary classifi
    
[^14]: 1比特矩阵补全的主导-最小化高斯牛顿方法

    A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion. (arXiv:2304.13940v1 [stat.ML])

    [http://arxiv.org/abs/2304.13940](http://arxiv.org/abs/2304.13940)

    本文提出了一种基于主导-最小化原则，通过低秩矩阵补全解决1比特矩阵补全问题的新方法，称为MMGN。通过应用高斯-牛顿方法，MMGN具有更快的速度和更准确的结果，同时还不太受到潜在矩阵尖锐度的影响。

    

    在1比特矩阵补全中，旨在从部分二进制观测值中估计潜在的低秩矩阵。我们提出了一种称为MMGN的1比特矩阵补全新方法。我们的方法基于主导-最小化（MM）原则，在我们的设置中产生一系列标准低秩矩阵补全问题。我们通过明确强制假定的低秩结构的分解方法解决这些子问题，然后应用高斯-牛顿方法。我们的数值研究和对实际数据的应用表明，MMGN输出的估计结果与现有方法相比较具有可比性且更准确、速度通常更快，并且对潜在矩阵的尖锐度不太敏感。

    In 1-bit matrix completion, the aim is to estimate an underlying low-rank matrix from a partial set of binary observations. We propose a novel method for 1-bit matrix completion called MMGN. Our method is based on the majorization-minimization (MM) principle, which yields a sequence of standard low-rank matrix completion problems in our setting. We solve each of these sub-problems by a factorization approach that explicitly enforces the assumed low-rank structure and then apply a Gauss-Newton method. Our numerical studies and application to a real-data example illustrate that MMGN outputs comparable if not more accurate estimates, is often significantly faster, and is less sensitive to the spikiness of the underlying matrix than existing methods.
    
[^15]: 针对异质性下的非参数两样本推断的自助边缘计数检验

    Bootstrapped Edge Count Tests for Nonparametric Two-Sample Inference Under Heterogeneity. (arXiv:2304.13848v1 [stat.ME])

    [http://arxiv.org/abs/2304.13848](http://arxiv.org/abs/2304.13848)

    本文介绍了一种新的非参数检验方法，可以在处理多元和非欧几里得数据时准确地检测到两个样本之间的差异，该方法通过一个包含可能具有不同混合权重但相同组分分布的混合分布假设来处理异质性。

    

    非参数两样本检验是推断统计学中的一个经典问题。虽然现代两样本检验，例如边缘计数检验及其变体，可以处理多元和非欧几里得数据，但当下大型数据集由于存在潜在的亚种群而具有异质性。若不对这种异质性进行调节，直接应用这些检验可能会导致错误的统计决策。我们开发了一种新的非参数检验过程，可以在数据生成过程中存在未知异质性的情况下准确检测两个样本之间的差异。我们的框架通过一个包含可能具有不同混合权重但相同组分分布的混合分布假设来处理这种潜在异质性。在这个范围内，我们研究了加权边缘计数检验统计量的渐近行为，并表明它可以被有效地重新校准。

    Nonparametric two-sample testing is a classical problem in inferential statistics. While modern two-sample tests, such as the edge count test and its variants, can handle multivariate and non-Euclidean data, contemporary gargantuan datasets often exhibit heterogeneity due to the presence of latent subpopulations. Direct application of these tests, without regulating for such heterogeneity, may lead to incorrect statistical decisions. We develop a new nonparametric testing procedure that accurately detects differences between the two samples in the presence of unknown heterogeneity in the data generation process. Our framework handles this latent heterogeneity through a composite null that entertains the possibility that the two samples arise from a mixture distribution with identical component distributions but with possibly different mixing weights. In this regime, we study the asymptotic behavior of weighted edge count test statistic and show that it can be effectively re-calibrated 
    
[^16]: 基于核棍棒过程的高斯过程专家混合模型

    Mixtures of Gaussian process experts based on kernel stick-breaking processes. (arXiv:2304.13833v1 [stat.ML])

    [http://arxiv.org/abs/2304.13833](http://arxiv.org/abs/2304.13833)

    提出了一种新的基于核棍棒过程的高斯过程专家混合模型，能够维持直观吸引力并提高模型性能，具有实用性。

    

    高斯过程专家混合模型是一类能同时解决标准高斯过程中存在的两个关键限制：可扩展性和预测性能的模型。使用狄利克雷过程作为门函数的模型能够直观地解释和自动选择混合物中专家的数量。虽然现有模型在感知非平稳性、多模性和异方差性方面表现良好，但其门函数的简单性可能会限制在应用于复杂数据生成过程时的预测性能。我们利用最近在相关狄利克雷过程文献中的进展，提出了一种基于核棍棒过程的新型高斯过程专家混合模型。我们的模型保持直观吸引力，同时提高现有模型的性能。为了使其实用性，我们设计了一个后验计算的切片抽样采样器。

    Mixtures of Gaussian process experts is a class of models that can simultaneously address two of the key limitations inherent in standard Gaussian processes: scalability and predictive performance. In particular, models that use Dirichlet processes as gating functions permit straightforward interpretation and automatic selection of the number of experts in a mixture. While the existing models are intuitive and capable of capturing non-stationarity, multi-modality and heteroskedasticity, the simplicity of their gating functions may limit the predictive performance when applied to complex data-generating processes. Capitalising on the recent advancement in the dependent Dirichlet processes literature, we propose a new mixture model of Gaussian process experts based on kernel stick-breaking processes. Our model maintains the intuitive appeal yet improve the performance of the existing models. To make it practical, we design a sampler for posterior computation based on the slice sampling. 
    
[^17]: 核化赌博机算法中对核函数规律性错误的自适应性研究

    Adaptation to Misspecified Kernel Regularity in Kernelised Bandits. (arXiv:2304.13830v1 [stat.ML])

    [http://arxiv.org/abs/2304.13830](http://arxiv.org/abs/2304.13830)

    本文研究了核化赌博问题中对核函数规则性错误的自适应性问题。我们证明了在具有不同规则性的一对RKHS中同时实现最佳累计遗憾是不可能的，并通过现有算法结合极小化非自适应的核赌博机算法，验证了这一下限的紧密性。

    

    在连续武装赌博问题中，如果底层函数位于再生核希尔伯特空间（RKHS）中，即核赌博问题，一个重要的未解决问题是，如果相关的核函数的规则性是未知的，学习算法可以多么好地适应。在这项工作中，我们研究了平移不变核规则性的自适应性，在赌博设置中，该规则性由核的傅里叶变换的衰减率所描述。我们推导了一个自适应性的下限，证明了在具有不同规则性的一对RKHS中同时实现最佳累计遗憾是不可能的。为了验证这个下限的紧密性，我们展示了一个现有的赌博模型选择算法与极小化非自适应的核赌博机算法相结合，在总步数T的依赖下匹配了下限，除了对数因子。通过填写RKHS之间适应性的遗憾界，我们连接了它们。

    In continuum-armed bandit problems where the underlying function resides in a reproducing kernel Hilbert space (RKHS), namely, the kernelised bandit problems, an important open problem remains of how well learning algorithms can adapt if the regularity of the associated kernel function is unknown. In this work, we study adaptivity to the regularity of translation-invariant kernels, which is characterized by the decay rate of the Fourier transformation of the kernel, in the bandit setting. We derive an adaptivity lower bound, proving that it is impossible to simultaneously achieve optimal cumulative regret in a pair of RKHSs with different regularities. To verify the tightness of this lower bound, we show that an existing bandit model selection algorithm applied with minimax non-adaptive kernelised bandit algorithms matches the lower bound in dependence of $T$, the total number of steps, except for log factors. By filling in the regret bounds for adaptivity between RKHSs, we connect the
    
[^18]: 广义广义线性模型：凸估计和在线界限

    Generalized generalized linear models: Convex estimation and online bounds. (arXiv:2304.13793v1 [stat.ME])

    [http://arxiv.org/abs/2304.13793](http://arxiv.org/abs/2304.13793)

    该论文提出了一种用于估计时间空间数据中依赖关系的广义广义线性模型（GGLM）参数的计算框架，使用单调运算符的变分不等式方法克服了参数估计中的非凸性并为参数恢复提供保证

    

    我们引入了一个新的计算框架，用于估计广义广义线性模型（GGLM）中的参数。这是一类将流行的广义线性模型（GLM）扩展到考虑时空数据中观测之间依赖关系的模型。所提出的方法使用基于单调运算符的变分不等式方法来克服参数估计中的非凸性并为参数恢复提供保证。结果可以应用于GLM和GGLM，重点关注时空模型。我们还使用鞅集中不等式提供了在线实例界限。最后，我们使用数值模拟和野火事件的真实数据示例来展示算法的性能。

    We introduce a new computational framework for estimating parameters in generalized generalized linear models (GGLM), a class of models that extends the popular generalized linear models (GLM) to account for dependencies among observations in spatio-temporal data. The proposed approach uses a monotone operator-based variational inequality method to overcome non-convexity in parameter estimation and provide guarantees for parameter recovery. The results can be applied to GLM and GGLM, focusing on spatio-temporal models. We also present online instance-based bounds using martingale concentrations inequalities. Finally, we demonstrate the performance of the algorithm using numerical simulations and a real data example for wildfire incidents.
    
[^19]: 通过独热编码和正则化提高梯度提升决策树的鲁棒性

    Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization. (arXiv:2304.13761v1 [stat.ML])

    [http://arxiv.org/abs/2304.13761](http://arxiv.org/abs/2304.13761)

    通过独热编码和正则化提高梯度提升决策树的鲁棒性，研究表明对带有$L_1$或$L_2$正则化的线性回归形式进行拟合可提高GBDT模型的鲁棒性。

    

    梯度提升决策树(GBDT)是一种广泛应用的高效机器学习方法，用于表格数据建模。然而，它们复杂的结构可能导致模型对未见数据中的小协变量扰动的鲁棒性较低。本研究应用独热编码将GBDT模型转换为线性框架，通过将每个树叶编码为一个虚拟变量。这允许使用线性回归技术，以及一种新颖的风险分解方法来评估GBDT模型对协变量扰动的鲁棒性。我们建议通过重新拟合其带有$L_1$或$L_2$正则化的线性回归形式，提高GBDT模型的鲁棒性。理论结果表明了正则化对模型性能和鲁棒性的影响。在数值实验中，证明了所提出的正则化方法可以提高独热编码GBDT模型的鲁棒性。

    Gradient-boosted decision trees (GBDT) are widely used and highly effective machine learning approach for tabular data modeling. However, their complex structure may lead to low robustness against small covariate perturbation in unseen data. In this study, we apply one-hot encoding to convert a GBDT model into a linear framework, through encoding of each tree leaf to one dummy variable. This allows for the use of linear regression techniques, plus a novel risk decomposition for assessing the robustness of a GBDT model against covariate perturbations. We propose to enhance the robustness of GBDT models by refitting their linear regression forms with $L_1$ or $L_2$ regularization. Theoretical results are obtained about the effect of regularization on the model performance and robustness. It is demonstrated through numerical experiments that the proposed regularization approach can enhance the robustness of the one-hot-encoded GBDT models.
    
[^20]: TR0N：0-Shot即插即用条件生成的翻译网络

    TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation. (arXiv:2304.13742v1 [cs.LG])

    [http://arxiv.org/abs/2304.13742](http://arxiv.org/abs/2304.13742)

    本文提出了TR0N，将预训练的无条件生成模型转化为高度任意的条件模型。TR0N不需要训练数据或微调，可以在MS-COCO上实现零-shot FID 10.9，并在采样速度上优于竞品，同时保持了多样性和质量。

    

    本文提出了TR0N，一个高度通用的框架，将预训练的无条件生成模型，如GAN和VAE，转换为条件模型。条件可以是高度任意的，并且仅需要预训练的辅助模型。例如，我们展示了如何使用分类器将无条件模型转化为类别条件模型，并利用CLIP将其转化为文本到图像模型。TR0N学习了一种轻量级的随机映射，该映射在条件空间和生成模型的潜在空间之间“翻译”，使得生成的潜在空间对应于满足所需条件的数据样本。然后，通过Langevin动态进一步改进翻译后的潜在样本，使我们能够获得更高质量的数据样本。TR0N不需要训练数据或微调，但可以在MS-COCO上实现零-shot FID 10.9，不仅在这个指标上优于竞品，而且在采样速度上也与其保持了多样性和质量。

    We propose TR0N, a highly general framework to turn pre-trained unconditional generative models, such as GANs and VAEs, into conditional models. The conditioning can be highly arbitrary, and requires only a pre-trained auxiliary model. For example, we show how to turn unconditional models into class-conditional ones with the help of a classifier, and also into text-to-image models by leveraging CLIP. TR0N learns a lightweight stochastic mapping which "translates" between the space of conditions and the latent space of the generative model, in such a way that the generated latent corresponds to a data sample satisfying the desired condition. The translated latent samples are then further improved upon through Langevin dynamics, enabling us to obtain higher-quality data samples. TR0N requires no training data nor fine-tuning, yet can achieve a zero-shot FID of 10.9 on MS-COCO, outperforming competing alternatives not only on this metric, but also in sampling speed -- all while retaining 
    
[^21]: 用均场博弈为生成模型搭建实验室

    A mean-field games laboratory for generative modeling. (arXiv:2304.13534v1 [stat.ML])

    [http://arxiv.org/abs/2304.13534](http://arxiv.org/abs/2304.13534)

    本文提出了使用均场博弈作为实验室对生成模型进行设计和分析的方法，并建立了这种方法与主要流动和扩散型生成模型之间的关联。通过研究每个生成模型与它们相关的 MFG 的最优条件，本文提出了一个基于双人 MFG 的新的生成模型，该模型在提高样本多样性和逼真度的同时改善了解缠结和公平性。

    

    本文展示了均场博弈 (MFGs) 作为一种数学框架用于解释、增强和设计生成模型的多功能性。我们建立了 MFGs 与主要流动和扩散型生成模型之间关联，并通过不同的粒子动力学和代价函数推导了这三个类别的生成模型。此外，我们通过研究它们相关的 MFG 的最优条件——一组耦合的非线性偏微分方程，来研究每个生成模型的数学结构和特性。本文还提出了一个新的基于双人 MFG 的生成模型，其中一个代理合成样本，另一个代理对样本进行识别，理论和实验结果表明，该模型生成的样本多样且逼真，同时与基准模型相比，改善了解缠结和公平性。总之，本文突显了 MFGs 作为设计和分析生成模型的实验室的潜力。

    In this paper, we demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. There is a pervasive sense in the generative modeling community that the various flow and diffusion-based generative models have some foundational common structure and interrelationships. We establish connections between MFGs and major classes of flow and diffusion-based generative models including continuous-time normalizing flows, score-based models, and Wasserstein gradient flows. We derive these three classes of generative models through different choices of particle dynamics and cost functions. Furthermore, we study the mathematical structure and properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled nonlinear partial differential equations (PDEs). The theory of MFGs, therefore, enables the study of generative models through the theory of nonlinear PDEs. Throu
    
[^22]: 一种基于可解释神经网络的连续回应有序回归非比例赔率模型

    An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response. (arXiv:2303.17823v1 [stat.ME])

    [http://arxiv.org/abs/2303.17823](http://arxiv.org/abs/2303.17823)

    本文提出了一种基于可解释神经网络的非比例赔率模型 (N$^3$POM) 用于有序回归，可以对连续变量进行预测，同时保留了可解释性，具有灵活性。

    

    本文提出了一种基于可解释神经网络的非比例赔率模型（N$^3$POM) 用于有序回归，其中反应变量不仅可以取离散值，也可以取连续值，而回归系数根据预测顺序反应也不同。与传统方法直接从离散反应估计线性系数不同，我们训练了一个非线性的神经网络，通过以反应为输入产生线性系数。由于神经网络的优势，N$^3$POM可以在保留传统有序回归的可解释性的同时具有灵活性。我们给出了充分的条件，使得在指定的用户区域内，预测的条件累积概率（CCP）满足局部单调性约束。我们还提供了一种保持单调性的随机（MPS）算法来充分训练神经网络。

    This paper proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression, where the response variable can take not only discrete but also continuous values, and the regression coefficients vary depending on the predicting ordinal response. In contrast to conventional approaches estimating the linear coefficients of regression directly from the discrete response, we train a non-linear neural network that outputs the linear coefficients by taking the response as its input. By virtue of the neural network, N$^3$POM may have flexibility while preserving the interpretability of the conventional ordinal regression. We show a sufficient condition so that the predicted conditional cumulative probability~(CCP) satisfies the monotonicity constraint locally over a user-specified region in the covariate space; we also provide a monotonicity-preserving stochastic (MPS) algorithm for training the neural network adequately.
    
[^23]: 在全球卫生领域中用于自适应干预的合成数据生成器

    Synthetic Data Generator for Adaptive Interventions in Global Health. (arXiv:2303.01954v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.01954](http://arxiv.org/abs/2303.01954)

    通过HealthSyn生成基于真实世界的移动健康干预数据，以帮助在全球卫生领域中发展、测试和评估机器学习算法和干预措施。

    

    人工智能和数字健康有望改变全球卫生状况。然而，在真实的生产环境中进行算法测试和验证的关键是能够访问代表性数据。我们介绍了HealthSyn，一个开源的合成数据生成器，用于测试强化学习算法，以及在移动健康干预中的个性化干预（例如提醒、推荐和激励）。生成器利用马尔可夫过程生成多样化的用户行为，具有个体用户行为模式，可以根据个性化干预而改变。这些行为转化为实际日志，使用ML专用的数据模式，特定于HealthKit与开源SDK中包含的移动健康应用程序功能。这些日志可以提供用户指标。基于真实世界的行为和模拟技术生成的数据，可以以成本效益和保护隐私的方式进行开发、测试和评估，同时评估机器学习算法和干预措施。

    Artificial Intelligence and digital health have the potential to transform global health. However, having access to representative data to test and validate algorithms in realistic production environments is essential. We introduce HealthSyn, an open-source synthetic data generator of user behavior for testing reinforcement learning algorithms in the context of mobile health interventions. The generator utilizes Markov processes to generate diverse user actions, with individual user behavioral patterns that can change in reaction to personalized interventions (i.e., reminders, recommendations, and incentives). These actions are translated into actual logs using an ML-purposed data schema specific to the mobile health application functionality included with HealthKit, and open-source SDK. The logs can be fed to pipelines to obtain user metrics. The generated data, which is based on real-world behaviors and simulation techniques, can be used to develop, test, and evaluate, both ML algori
    
[^24]: 强化学习中的尖锐方差相关界限：随机和确定性环境的最佳结合

    Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both Worlds in Stochastic and Deterministic Environments. (arXiv:2301.13446v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13446](http://arxiv.org/abs/2301.13446)

    本研究将马尔可夫决策过程的方差相关遗憾界限应用到强化学习中，提出了两个新的环境规范来表征环境的方差属性，并设计出基于模型和无模型的算法，对于随机和确定性环境同时极小极大最优的界限是第一次被证明出来的。

    

    本文研究马尔可夫决策过程（MDPs）的方差相关遗憾界限。具有方差相关遗憾保证的算法可以自动利用具有低方差（例如，在确定性MDP上享有常量遗憾）的环境。现有算法要么独立于方差要么次优。我们首先提出两个新的环境规范来表征环境的细粒度方差属性。对于基于模型的方法，我们设计了MVP算法(Zhang等，2021a)的变种，并使用新的分析技术展示了该算法相对于我们提出的规范享有方差相关的界限。特别地，这一界限对于随机和确定性MDP同时是极小极大最优的，这是其种类中的第一个结果。我们进一步通过设计一种参考函数的算法以及一个新的带有上限加倍参考更新进度表的策略启动了关于具有方差相关遗憾界限的无模型算法的研究。最后，我们还提供了一些启示。

    We study variance-dependent regret bounds for Markov decision processes (MDPs). Algorithms with variance-dependent regret guarantees can automatically exploit environments with low variance (e.g., enjoying constant regret on deterministic MDPs). The existing algorithms are either variance-independent or suboptimal. We first propose two new environment norms to characterize the fine-grained variance properties of the environment. For model-based methods, we design a variant of the MVP algorithm (Zhang et al., 2021a) and use new analysis techniques show to this algorithm enjoys variance-dependent bounds with respect to our proposed norms. In particular, this bound is simultaneously minimax optimal for both stochastic and deterministic MDPs, the first result of its kind. We further initiate the study on model-free algorithms with variance-dependent regret bounds by designing a reference-function-based algorithm with a novel capped-doubling reference update schedule. Lastly, we also provid
    
[^25]: 用于三维分子图的几何完备感知器网络

    Geometry-Complete Perceptron Networks for 3D Molecular Graphs. (arXiv:2211.02504v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.02504](http://arxiv.org/abs/2211.02504)

    本研究引入了一种新的几何完备的图神经网络 GCPNet，用于3D分子图的表示学习，并在多个几何任务上展示了其出色的预测性能。其中最佳表现是在蛋白质-配体结合亲和力预测上得到了比当前最先进方法高出5%以上的相关系数。

    

    几何深度学习对于创新和强大的图形神经网络架构的发展产生了重大影响。来自计算机视觉和计算生物学等学科的领域，在这些方法学的推动下取得了显著的收益，从而在科学领域如蛋白质结构预测和设计中实现了突破。在本研究中，我们引入了GCPNet，这是一种新的几何完备、SE(3)-等变的图神经网络，专门用于3D分子图表示学习。四个不同的几何任务的严密实验证明了GCPNet的预测能力，包括：（1）蛋白质-配体结合亲和力的相关系数为0.608，比目前最先进的方法高出5%以上；（2）蛋白质结构排名在目标本地和数据集全局之间具有统计显著的相关性，分别为0.616和0.871；（3）Newtownian多体系统的建模平均成绩达到了

    The field of geometric deep learning has had a profound impact on the development of innovative and powerful graph neural network architectures. Disciplines such as computer vision and computational biology have benefited significantly from such methodological advances, which has led to breakthroughs in scientific domains such as protein structure prediction and design. In this work, we introduce GCPNet, a new geometry-complete, SE(3)-equivariant graph neural network designed for 3D molecular graph representation learning. Rigorous experiments across four distinct geometric tasks demonstrate that GCPNet's predictions (1) for protein-ligand binding affinity achieve a statistically significant correlation of 0.608, more than 5% greater than current state-of-the-art methods; (2) for protein structure ranking achieve statistically significant target-local and dataset-global correlations of 0.616 and 0.871, respectively; (3) for Newtownian many-body systems modeling achieve a task-averaged 
    
[^26]: 超越校准：估计现代神经网络的分组损失

    Beyond calibration: estimating the grouping loss of modern neural networks. (arXiv:2210.16315v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.16315](http://arxiv.org/abs/2210.16315)

    本文提出了一个估计器来近似神经网络的分组损失，并表明现代神经网络在视觉和NLP中展示出显著的分组损失。

    

    确保分类器给出可靠的置信度分数是确保知情决策的关键。为此，最近的研究集中在误校准上，即模型分数的过度或不足置信。然而，校准还不够：即使准确率最高的完美校准分类器也可能具有与真实后验概率相去甚远的置信度分数，这是由于分组损失所造成的，即以相同置信度得分但真实后验概率不同的样本。适当的评分规则理论表明，在给定校准损失的情况下，表征单个错误的缺失部分是分组损失。虽然存在许多校准损失的估计器，但在标准设置中不存在分组损失的估计器。在本文中，我们提出了一个估计器来近似分组损失。我们展示了现代神经网络结构在视觉和NLP中表现出分组损失，特别是在分布偏移设置中，这突显了它的重要性。

    The ability to ensure that a classifier gives reliable confidence scores is essential to ensure informed decision-making. To this end, recent work has focused on miscalibration, i.e., the over or under confidence of model scores. Yet calibration is not enough: even a perfectly calibrated classifier with the best possible accuracy can have confidence scores that are far from the true posterior probabilities. This is due to the grouping loss, created by samples with the same confidence scores but different true posterior probabilities. Proper scoring rule theory shows that given the calibration loss, the missing piece to characterize individual errors is the grouping loss. While there are many estimators of the calibration loss, none exists for the grouping loss in standard settings. Here, we propose an estimator to approximate the grouping loss. We show that modern neural network architectures in vision and NLP exhibit grouping loss, notably in distribution shifts settings, which highli
    
[^27]: 紧凑集成用于高效的不确定性估计

    Packed-Ensembles for Efficient Uncertainty Estimation. (arXiv:2210.09184v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09184](http://arxiv.org/abs/2210.09184)

    Packed-Ensembles是一种能够在标准神经网络内运行的轻量级结构化集合，它通过精心调节编码空间的维度来设计。该方法在不损失效果的情况下提高了训练和推理速度。

    

    深度集成是实现关键指标（如准确性、校准、不确定性估计和超出分布检测）卓越性能的突出方法。但是，现实系统的硬件限制限制了更小的集合和较低容量的网络，严重损害了它们的性能和属性。我们引入了一种称为Packed-Ensembles（PE）的策略，通过精心调节其编码空间的维度来设计和训练轻量级结构化集合。我们利用组卷积将集合并行化为单个共享骨干，并进行前向传递以提高训练和推理速度。PE旨在在标准神经网络的内存限制内运行。

    Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our c
    
[^28]: 控制的统计学习理论：有限样本视角

    Statistical Learning Theory for Control: A Finite Sample Perspective. (arXiv:2209.05423v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2209.05423](http://arxiv.org/abs/2209.05423)

    本文概述了控制领域中最重要的统计学习理论中的最近进展，这些进展主要围绕在线性系统辨识和学习方面，基于现代高维统计学和学习理论的工具，为将机器学习工具融入控制领域的人提供了自包含演示。

    

    本教程综述了最近在统计学习理论中与控制和系统辨识相关的非渐近进展。尽管在所有控制领域都取得了实质性进展，但在线性系统辨识和线性二次调节器学习方面，该理论最为成熟，而这也是本文的重点。从理论角度讲，这些进展的大部分工作都在于借鉴现代高维统计学和学习理论的工具。虽然对于那些有兴趣将机器学习工具融入控制领域的控制理论家来说非常相关，但这些基础材料并不总是易于获取。为了解决这个问题，我们提供了相关素材的自包含演示，概述了所有关键思想和技术机械，为最近的结果打下了基础。我们还提出了一些未解决的问题和未来的方向。

    This tutorial survey provides an overview of recent non-asymptotic advances in statistical learning theory as relevant to control and system identification. While there has been substantial progress across all areas of control, the theory is most well-developed when it comes to linear system identification and learning for the linear quadratic regulator, which are the focus of this manuscript. From a theoretical perspective, much of the labor underlying these advances has been in adapting tools from modern high-dimensional statistics and learning theory. While highly relevant to control theorists interested in integrating tools from machine learning, the foundational material has not always been easily accessible. To remedy this, we provide a self-contained presentation of the relevant material, outlining all the key ideas and the technical machinery that underpin recent results. We also present a number of open problems and future directions.
    
[^29]: DORA：探索深度神经网络中的异常值表示

    DORA: Exploring outlier representations in Deep Neural Networks. (arXiv:2206.04530v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.04530](http://arxiv.org/abs/2206.04530)

    本文提出了一种名为DORA的数据不可知框架，用于分析深度神经网络中的表征空间，并可以识别不符合人类直观认知的表征。

    

    尽管深度神经网络（DNN）在学习复杂抽象方面非常有效，但它们容易意外地从训练数据中学习到虚假的特征。为了确保模型的透明度，检查学习表示之间的关系至关重要，因为意外的概念往往表现为与所需的任务不符的异常。在这项工作中，我们介绍了DORA（Data-agnOstic Representation Analysis）：用于分析DNN表示空间的第一个数据不可知框架。我们的框架采用了所提出的表示之间的极端激活（EA）距离度量，在不访问任何数据的情况下利用网络内自说明能力。我们定量验证了度量的正确性和与人为定义的语义距离的一致性。EA距离与人类判断之间的一致性使我们能够确定表征，其基本概念被认为是不自然的。

    Although Deep Neural Networks (DNNs) are incredibly effective in learning complex abstractions, they are susceptible to unintentionally learning spurious artifacts from the training data. To ensure model transparency, it is crucial to examine the relationships between learned representations, as unintended concepts often manifest themselves to be anomalous to the desired task. In this work, we introduce DORA (Data-agnOstic Representation Analysis): the first data-agnostic framework for the analysis of the representation space of DNNs. Our framework employs the proposed Extreme-Activation (EA) distance measure between representations that utilizes self-explaining capabilities within the network without accessing any data. We quantitatively validate the metric's correctness and alignment with human-defined semantic distances. The coherence between the EA distance and human judgment enables us to identify representations whose underlying concepts would be considered unnatural by humans by
    
[^30]: 元学习器用于多值处理异质作用估计的比较

    Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects. (arXiv:2205.14714v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.14714](http://arxiv.org/abs/2205.14714)

    本文探讨了利用元学习器估计多值处理异质效应的问题，发现朴素扩展并不总是可行，提出并讨论了一些表现良好的元学习器。

    

    在利用观察数据进行因果推断时，条件平均处理效应（CATE）估计是主要挑战之一。除了基于机器学习的模型外，还开发出了称为元学习器的非参数估计器以估计CATE，其主要优点是不局限于特定的监督学习方法。然而，当处理不是二进制的时，一些朴素扩展的限制会出现，这样的任务就变得更加复杂。本文研究了元学习器用于估计多值处理异质效应。我们考虑了不同的元学习器，理论分析了它们的误差上界作为重要参数的函数，例如处理水平的数量，结果显示，朴素扩展并不总是提供满意的结果。我们引入和讨论了一些元学习器，它们在处理数量增多时表现良好。通过模拟研究和一项乙肝治疗研究的真实数据示例，我们证实了元学习器的优缺点。

    Conditional Average Treatment Effects (CATE) estimation is one of the main challenges in causal inference with observational data. In addition to Machine Learning based-models, nonparametric estimators called meta-learners have been developed to estimate the CATE with the main advantage of not restraining the estimation to a specific supervised learning method. This task becomes, however, more complicated when the treatment is not binary as some limitations of the naive extensions emerge. This paper looks into meta-learners for estimating the heterogeneous effects of multi-valued treatments. We consider different meta-learners, and we carry out a theoretical analysis of their error upper bounds as functions of important parameters such as the number of treatment levels, showing that the naive extensions do not always provide satisfactory results. We introduce and discuss meta-learners that perform well as the number of treatments increases. We empirically confirm the strengths and weak
    
[^31]: 依赖隐变量类模型

    Dependent Latent Class Models. (arXiv:2205.08677v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.08677](http://arxiv.org/abs/2205.08677)

    本文介绍了一种新的贝叶斯模型依赖隐变量类模型（DLCM），相比传统的隐变量类模型（LCMs），DLCMs更适用于具有时间序列、重叠项和结构零等特点的应用。

    

    隐变量类模型（LCMs）用于聚类多元分类数据（例如基于调查回答的群组参与者）。传统的LCMs假设一个称为条件独立性的属性。这种假设可能过于严格，导致模型错误规定和过度参数化。为了解决这个问题，我们开发了一种新的贝叶斯模型，称为依赖隐变量类模型（DLCM），它允许条件依赖性。我们验证了DLCMs的可辨识性。我们还展示了DLCMs在模拟和真实应用中的有效性。与传统的LCMs相比，DLCMs在时间序列，重叠项和结构零方面的应用更有效。

    Latent Class Models (LCMs) are used to cluster multivariate categorical data (e.g. group participants based on survey responses). Traditional LCMs assume a property called conditional independence. This assumption can be restrictive, leading to model misspecification and overparameterization. To combat this problem, we developed a novel Bayesian model called a Dependent Latent Class Model (DLCM), which permits conditional dependence. We verify identifiability of DLCMs. We also demonstrate the effectiveness of DLCMs in both simulations and real-world applications. Compared to traditional LCMs, DLCMs are effective in applications with time series, overlapping items, and structural zeroes.
    
[^32]: 带有几何损失函数的球面旋转降维

    Spherical Rotation Dimension Reduction with Geometric Loss Functions. (arXiv:2204.10975v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.10975](http://arxiv.org/abs/2204.10975)

    该论文提出了一种名为SRCA的非线性降维方法，在处理高维度的低样本大小数据时，通过引入球体或椭球体，保留数据的几何结构，提高近似低维流形的效果。

    

    现代数据集通常具有高维性，但数据位于低维流形中，可以揭示对数据分析至关重要的潜在几何结构。这类数据集的典型例子是细胞周期测量值的集合，其中过程的固有循环性可以表示为圆或球。受分析这些类型数据集的需求启发，我们提出了一种非线性降维方法，称为球面旋转成分分析（SRCA），它将几何信息纳入到降维过程中以更好地逼近低维流形。SRCA是一种通用的方法，旨在在高维和小样本大小的情况下工作。通过使用球体或椭球体，SRCA提供了数据的低秩球面表示，并在降维过程中有效地保留了数据集的几何结构。全面的模拟研究以及对人类细胞周期数据的成功应用证明了SRCA的有效性和多功能性。

    Modern datasets often exhibit high dimensionality, yet the data reside in low-dimensional manifolds that can reveal underlying geometric structures critical for data analysis. A prime example of such a dataset is a collection of cell cycle measurements, where the inherently cyclical nature of the process can be represented as a circle or sphere. Motivated by the need to analyze these types of datasets, we propose a nonlinear dimension reduction method, Spherical Rotation Component Analysis (SRCA), that incorporates geometric information to better approximate low-dimensional manifolds. SRCA is a versatile method designed to work in both high-dimensional and small sample size settings. By employing spheres or ellipsoids, SRCA provides a low-rank spherical representation of the data with general theoretic guarantees, effectively retaining the geometric structure of the dataset during dimensionality reduction. A comprehensive simulation study, along with a successful application to human c
    
[^33]: 针对非凸-凹极小极大问题的无导数交替投影算法

    Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems. (arXiv:2108.00473v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2108.00473](http://arxiv.org/abs/2108.00473)

    本文提出针对非凸-凹极小极大问题的无导数交替投影算法，包括光滑问题的交替随机梯度投影算法（ZO-AGP），以及块状非光滑问题的分块交替随机近端梯度算法（ZO-BAPG）。这些算法具有较少的函数值估计和较高的迭代复杂度。

    

    本文研究了非凸-凹极小极大问题的零阶算法，这类问题近年在机器学习、信号处理等领域引起了广泛关注。我们提出了一种零阶交替随机梯度投影（ZO-AGP）算法来解决光滑的非凸-凹极小极大问题，其迭代复杂度为 $\mathcal{O}(\varepsilon^{-4})$，每次迭代的函数值估计次数为 $\mathcal{O}(d_{x}+d_{y})$。此外，我们还提出了一种零阶分块交替随机近端梯度算法（ZO-BAPG）来解决块状非光滑的非凸-凹极小极大优化问题，其迭代复杂度为 $\mathcal{O}(\varepsilon^{-4})$，每次迭代的函数值估计次数为 $\mathcal{O}(K d_{x}+d_{y})$。据我们所知，这是首次提出这些算法。

    In this paper, we study zeroth-order algorithms for nonconvex-concave minimax problems, which have attracted widely attention in machine learning, signal processing and many other fields in recent years. We propose a zeroth-order alternating randomized gradient projection (ZO-AGP) algorithm for smooth nonconvex-concave minimax problems, and its iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$, and the number of function value estimation is bounded by $\mathcal{O}(d_{x}+d_{y})$ per iteration. Moreover, we propose a zeroth-order block alternating randomized proximal gradient algorithm (ZO-BAPG) for solving block-wise nonsmooth nonconvex-concave minimax optimization problems, and the iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$ and the number of function value estimation per iteration is bounded by $\mathcal{O}(K d_{x}+d_{y})$. To the best of our knowledge, this 
    
[^34]: “抵御后门攻击的不兼容聚类机制”

    Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks. (arXiv:2105.03692v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.03692](http://arxiv.org/abs/2105.03692)

    本文提出了一种基于不兼容性的聚类机制，该机制可以将数据集划分为由训练过程的目标所定义且具有意义的聚类，并有效减轻后门攻击的影响。

    

    本文提出一种新型的聚类机制，该机制基于模型训练过程中出现的数据子集不相容性属性。该机制将数据集划分为只能泛化到其自身的子集，即在一个子集上的训练不会改善其他子集的性能。利用数据集与训练过程之间的交互作用，我们的聚类机制将数据集划分为由训练过程的目标所定义且具有意义的聚类。我们将我们的聚类机制应用于防御数据毒化攻击，即攻击者将恶意毒害数据注入训练数据集，以影响训练模型的输出。我们的评估重点关注利用GTSRB和CIFAR-10数据集进行图像分类的深度神经网络中的后门攻击。我们的结果表明：1）这些攻击产生的毒害数据集是有毒害数据和干净数据不相容的；2）我们的聚类机制可以有效减轻后门攻击的影响。

    We propose a novel clustering mechanism based on an incompatibility property between subsets of data that emerges during model training. This mechanism partitions the dataset into subsets that generalize only to themselves, i.e., training on one subset does not improve performance on the other subsets. Leveraging the interaction between the dataset and the training process, our clustering mechanism partitions datasets into clusters that are defined by--and therefore meaningful to--the objective of the training process.  We apply our clustering mechanism to defend against data poisoning attacks, in which the attacker injects malicious poisoned data into the training dataset to affect the trained model's output. Our evaluation focuses on backdoor attacks against deep neural networks trained to perform image classification using the GTSRB and CIFAR-10 datasets. Our results show that (1) these attacks produce poisoned datasets in which the poisoned and clean data are incompatible and (2) o
    
[^35]: Riemann流形上Stein方法的扩散方法

    A diffusion approach to Stein's method on Riemannian manifolds. (arXiv:2003.11497v3 [math.PR] UPDATED)

    [http://arxiv.org/abs/2003.11497](http://arxiv.org/abs/2003.11497)

    该论文介绍了一种用于Riemann流形上积分度量限制的Stein方法的扩散方法，并通过分析一对具有不同起始点的扩散之间的距离过程，导出了曲率相关的Stein因子。

    

    我们详细阐述了一种用于边界概率流形上积分度量限制的Stein方法的方法。我们的方法利用了扩散在$\mathbf M$上生成器与其表征Stein算子之间的关系。我们考虑了一对具有不同起始点的此类扩散，并通过分析它们之间的距离过程，导出了Stein因子，这些因子限制了Stein方程及其导数。Stein因子包含曲率相关的项，并缩减到目前适用于$\mathbb R^m$的因子，并且意味着当$\mathbf M$是平坦流形时，对于$\mathbb R ^m$的限制仍然有效。

    We detail an approach to develop Stein's method for bounding integral metrics on probability measures defined on a Riemannian manifold $\mathbf M$. Our approach exploits the relationship between the generator of a diffusion on $\mathbf M$ with target invariant measure and its characterising Stein operator. We consider a pair of such diffusions with different starting points, and through analysis of the distance process between the pair, derive Stein factors, which bound the solution to the Stein equation and its derivatives. The Stein factors contain curvature-dependent terms and reduce to those currently available for $\mathbb R^m$, and moreover imply that the bounds for $\mathbb R^m$ remain valid when $\mathbf M$ is a flat manifold
    

