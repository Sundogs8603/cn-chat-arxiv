# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation.](http://arxiv.org/abs/2304.13016) | 研究了比例渐近情形下的子采样岭回归集成，证明了最优全岭回归集成的风险与最优岭预测器的风险相匹配，并证明了GCV在估计岭回归集合的预测风险方面的强一致性。 |
| [^2] | [Asymptotic Behaviors and Phase Transitions in Projected Stochastic Approximation: A Jump Diffusion Approach.](http://arxiv.org/abs/2304.12953) | 本文研究了一种无循环投影随机逼近(LPSA)算法，它呈现出一种有趣的渐近偏差-方差权衡，并产生相对于步长的投影概率的相变现象，从而为选择适当的参数提供了见解。 |
| [^3] | [The Score-Difference Flow for Implicit Generative Modeling.](http://arxiv.org/abs/2304.12906) | 本文提出了一种新的评分差异流模型(SD flow)，它可以最优地减少两个分布之间的散度，同时解决Schr​​ödinger桥问题。与去噪扩散模型不同，它没有对先验分布施加任何限制，在一些基准数据集中优于其他方法。 |
| [^4] | [Provable benefits of general coverage conditions in efficient online RL with function approximation.](http://arxiv.org/abs/2304.12886) | 研究者对在线强化学习提出了一种新的一般覆盖条件，并发现更多的覆盖条件，提高了在线强化学习的样本效率和表现，同时阐明良好的覆盖条件仍然有益于获得最优解。 |
| [^5] | [Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the Decoder Network.](http://arxiv.org/abs/2304.12770) | 本文提出了一种基于反Lipschitz约束的解码器网络，可以简单明了地控制广泛的VAE模型的后验坍塌程度，并带有具体的理论保证。 |
| [^6] | [Towards Characterizing the First-order Query Complexity of Learning (Approximate) Nash Equilibria in Zero-sum Matrix Games.](http://arxiv.org/abs/2304.12768) | 本文研究了机器人系统的能量流量和能量特性，摩擦力和被动摆动是其主要影响因素，提出了关键参数和能量特性，有助于进一步研究。 |
| [^7] | [Communication-Constrained Bandits under Additive Gaussian Noise.](http://arxiv.org/abs/2304.12680) | 本文研究了在受限通信和加性高斯噪声下的多臂赌博机问题，提出了一个多阶段赌博算法，并给出了信息理论下限。 |
| [^8] | [Genetically-inspired convective heat transfer enhancement.](http://arxiv.org/abs/2304.12618) | 本文研究了基于遗传算法的对流传热增强方法，通过对自由流相交的六个间隙喷气孔进行控制，优化了成本函数，最终实现了对对流传热速率的提高。 |
| [^9] | [A Bi-fidelity DeepONet Approach for Modeling Uncertain and Degrading Hysteretic Systems.](http://arxiv.org/abs/2304.12609) | 本文介绍了一种用于建模不确定和退化滞后系统的双保真DeepONet方法，在不了解退化效应性质的原始模型数据集的情况下使用低保真度表示，显著提高了退化滞后系统的预测精度。 |
| [^10] | [Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks.](http://arxiv.org/abs/2304.12567) | 本文研究了如何通过增加辅助任务的数量和代理网络的大小，提高表示学习的效果。同时，本文还提出了基于后继度量的新型辅助任务家族 Proto-Value 网络。 |
| [^11] | [A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria for Robust Phase Retrieval.](http://arxiv.org/abs/2304.12522) | 本文提出了一种新的鲁棒相位恢复算法，通过使用自适应停止准则的非精确近端线性算法，该方法在实验中证明比现有方法更高效。 |
| [^12] | [Theory of Posterior Concentration for Generalized Bayesian Additive Regression Trees.](http://arxiv.org/abs/2304.12505) | 本论文提出了一个广义的贝叶斯树及其加性集成的框架，包括大多数BART的变体，并提出响应分布的充分条件，对BART及其变体的实证成功提供了理论支持。 |
| [^13] | [Robust, randomized preconditioning for kernel ridge regression.](http://arxiv.org/abs/2304.12465) | 针对核岭回归问题，本文引入了两种强健的随机预处理技术，分别解决了全数据KRR问题和限制版KRR问题，克服了以往预处理器的故障模式。 |
| [^14] | [Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls.](http://arxiv.org/abs/2304.12420) | 该论文使用了高效的样本集优化和基于代理的方法来设计水下航行器船体，其中代理模型显著提高了计算效率，使优化更加快速准确。 |
| [^15] | [Analyzing categorical time series with the R package ctsfeatures.](http://arxiv.org/abs/2304.12332) | 该软件包提供了一组有用的工具来分析分类时间序列，使得用户可以用图形描述底层时间模式并利用其输出执行传统的机器学习任务包括聚类、分类和异常检测。 |
| [^16] | [Simplifying Momentum-based Riemannian Submanifold Optimization.](http://arxiv.org/abs/2302.09738) | 本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。 |
| [^17] | [Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control.](http://arxiv.org/abs/2302.00839) | 本文提出了一种通用管道（FavMac），可以最大化价值并控制成本。 FavMac可以与几乎任何多标签分类器相结合，并通过在线更新机制处理实际的大规模应用，为成本控制提供无分布理论担保。 |
| [^18] | [Rigid body flows for sampling molecular crystal structures.](http://arxiv.org/abs/2301.11355) | 本文介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计。通过在单位四元数群上定义平滑和表现力强的流以及定义适当的密度，在旋转群上进行训练，我们可以成功地采样分子晶体结构。 |
| [^19] | [Invariant Lipschitz Bandits: A Side Observation Approach.](http://arxiv.org/abs/2212.07524) | 本文研究了不变Lipschitz赌徒设置，并提出了一种名为\texttt{UniformMesh-N}的算法。使用侧面观察的方法，证明了改进的遗憾上界。 |
| [^20] | [On the Ability of Graph Neural Networks to Model Interactions Between Vertices.](http://arxiv.org/abs/2211.16494) | 本文研究了GNN模拟顶点间相互作用的能力，通过一个被称为分离秩的度量标准来量化这种能力，结果表明模拟相互作用的能力主要取决于分区的行走指数，即从分界线开始的行走数量，同时设计了一种名为WISA的边稀疏化算法以提高GNNs的处理效率和表达能力。 |
| [^21] | [MMD-B-Fair: Learning Fair Representations with Statistical Testing.](http://arxiv.org/abs/2211.07907) | 提出了一种基于统计检验的 MMD-B-Fair 方法，用于学习公平的数据表示，并在各种数据集上得到了验证。 |
| [^22] | [Imputation of missing values in multi-view data.](http://arxiv.org/abs/2210.14484) | 本文提出了一种基于StaPLR算法的新的多视角数据插补算法，通过在降维空间中执行插补以解决计算挑战，并在模拟数据集中得到了竞争性结果。 |
| [^23] | [Optimization on Manifolds via Graph Gaussian Processes.](http://arxiv.org/abs/2210.10962) | 本论文结合流形学习和高斯过程，利用流形样本点云定义图高斯过程代理模型，通过选择查询点在流形上优化目标函数，具有良好性能。 |
| [^24] | [Sequential Attention for Feature Selection.](http://arxiv.org/abs/2209.14881) | 在神经网络中，我们提出一种名为序列关注的特征选择算法，它在每个步骤使用注意力权重作为特征重要性的代理，实现了最新的实证结果。 |
| [^25] | [Nonlinear Sufficient Dimension Reduction for Distribution-on-Distribution Regression.](http://arxiv.org/abs/2207.04613) | 本文提出了一种新的非线性降维方法，用于同时处理预测变量和响应变量均为分布数据的情形。该方法使用通用核建立预测变量和响应变量的复现核希尔伯特空间以描述条件独立性，对于单变量分布和多元分布分别采用Wasserstein距离和分片Wasserstein距离构建通用核，经合成数据测试表现优于竞争方法。 |
| [^26] | [Sparse Subspace Clustering in Diverse Multiplex Network Model.](http://arxiv.org/abs/2206.07602) | 本文研究了DIMPLE网络模型中的稀疏子空间聚类，通过识别具有相同社区结构的层组，找到了一种强一致性的结果。 |
| [^27] | [Targeted Adaptive Design.](http://arxiv.org/abs/2205.14208) | TAD是一种新的目标自适应设计算法，可以通过高斯过程代理模型在指定公差中确定产生期望设计特征的最佳控制设置，相比其他自适应设计算法，具有更高的精度和效率。 |
| [^28] | [Maximum Likelihood Estimation in Gaussian Process Regression is Ill-Posed.](http://arxiv.org/abs/2203.09179) | 本文指出了高斯过程回归中，使用最大似然估计器估计长度尺度参数的平稳协方差函数的情况下，在无噪声数据情况下会存在不适定问题。 |
| [^29] | [Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning.](http://arxiv.org/abs/2201.08115) | 本文介绍了一种名为“APEx”的技能发现和转移算法，它以一种原则性和学习的方式利用信息不对称性，实现了最先进的采样效率、任务可转移性和概括能力，同时保留了非分层方法的表达能力和灵活性。 |
| [^30] | [Adaptive Weighted Multi-View Clustering.](http://arxiv.org/abs/2110.13240) | 本文提出了一种加权多视图 NMF算法，旨在学习视图特定权重和观测特定重构权重，以量化每个视图的信息内容，通过分配较小和较大的权重来扩大重要视图的正面影响。 |
| [^31] | [Approximate Regions of Attraction in Learning with Decision-Dependent Distributions.](http://arxiv.org/abs/2107.00055) | 本文分析了在决策相关分布学习中的风险最小化，建立在执行风险最小化的梯度流的扰动轨迹之上，研究了可能存在多个局部最小化器的情况。 |
| [^32] | [Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding Interaction Perspective.](http://arxiv.org/abs/1903.11406) | 本文提出了一种多嵌入交互的角度来分析和比较知识图谱嵌入方法，研究了CP，DistMult和ComplEx等三种流行的方法，揭示了ComplEx性能更好的原因，并为开发新模型提供了见解。 |
| [^33] | [Ensemble Sampling.](http://arxiv.org/abs/1705.07347) | 本文介绍了集成采样，以近似Thompson采样并在复杂模型下保持可行性，将大大扩展Thompson采样的应用范围。 |

# 详细

[^1]: 子采样岭回归集成：等效性和广义交叉验证

    Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation. (arXiv:2304.13016v1 [math.ST])

    [http://arxiv.org/abs/2304.13016](http://arxiv.org/abs/2304.13016)

    研究了比例渐近情形下的子采样岭回归集成，证明了最优全岭回归集成的风险与最优岭预测器的风险相匹配，并证明了GCV在估计岭回归集合的预测风险方面的强一致性。

    

    我们研究了比例渐近情形下的子采样岭回归集成，其中特征大小与样本大小成比例增长，使得它们的比率收敛到一个常数。通过分析岭回归集合的平方预测风险作为显式惩罚$\lambda$和极限子样本方面比$\phi_s$（特征大小与子样本大小的比率）的函数，我们表征了在任何可达风险下的$(\lambda, \phi_s)$-平面上的轮廓。因此，我们证明最优全岭回归集成（适合于所有可能的子样本）的风险与最优岭预测器的风险相匹配。此外，我们证明对于估计岭回归集合的预测风险，基于广义交叉验证（GCV）的子样本大小强一致性。这允许无需样本拆分基于GCV优化全局岭回归集成，并产生一个风险与最优岭回归风险相匹配的预测器。

    We study subsampling-based ridge ensembles in the proportional asymptotics regime, where the feature size grows proportionally with the sample size such that their ratio converges to a constant. By analyzing the squared prediction risk of ridge ensembles as a function of the explicit penalty $\lambda$ and the limiting subsample aspect ratio $\phi_s$ (the ratio of the feature size to the subsample size), we characterize contours in the $(\lambda, \phi_s)$-plane at any achievable risk. As a consequence, we prove that the risk of the optimal full ridgeless ensemble (fitted on all possible subsamples) matches that of the optimal ridge predictor. In addition, we prove strong uniform consistency of generalized cross-validation (GCV) over the subsample sizes for estimating the prediction risk of ridge ensembles. This allows for GCV-based tuning of full ridgeless ensembles without sample splitting and yields a predictor whose risk matches optimal ridge risk.
    
[^2]: 投影随机逼近中的渐近行为和相变：跳跃扩散方法

    Asymptotic Behaviors and Phase Transitions in Projected Stochastic Approximation: A Jump Diffusion Approach. (arXiv:2304.12953v1 [math.OC])

    [http://arxiv.org/abs/2304.12953](http://arxiv.org/abs/2304.12953)

    本文研究了一种无循环投影随机逼近(LPSA)算法，它呈现出一种有趣的渐近偏差-方差权衡，并产生相对于步长的投影概率的相变现象，从而为选择适当的参数提供了见解。

    

    本文考虑线性约束优化问题，并提出了一个无循环投影随机逼近(LPSA)算法。该算法在第n次迭代时以概率$p_n$进行投影，以确保可行性。考虑到概率$p_n$和步长$\eta_n$的具体一类，我们从渐近和连续角度分析了我们的算法。通过使用新颖的跳跃扩散逼近方法，我们证明了连接适当缩放的最后迭代的轨迹弱收敛于特定随机微分方程(SDE)的解。通过分析SDE，我们确定了LPSA在不同的$(p_n, \eta_n)$选择下的渐近行为。我们发现该算法呈现出一种有趣的渐近偏差-方差权衡，并产生相对于$\eta_n$的$p_n$的相变现象。该发现揭示了选择适当的 ${(p_n, \eta_n)}_{n \geq 1}$ 的见解，以最小化概率的满足。

    In this paper we consider linearly constrained optimization problems and propose a loopless projection stochastic approximation (LPSA) algorithm. It performs the projection with probability $p_n$ at the $n$-th iteration to ensure feasibility. Considering a specific family of the probability $p_n$ and step size $\eta_n$, we analyze our algorithm from an asymptotic and continuous perspective. Using a novel jump diffusion approximation, we show that the trajectories connecting those properly rescaled last iterates weakly converge to the solution of specific stochastic differential equations (SDEs). By analyzing SDEs, we identify the asymptotic behaviors of LPSA for different choices of $(p_n, \eta_n)$. We find that the algorithm presents an intriguing asymptotic bias-variance trade-off and yields phase transition phenomenons, according to the relative magnitude of $p_n$ w.r.t. $\eta_n$. This finding provides insights on selecting appropriate ${(p_n, \eta_n)}_{n \geq 1}$ to minimize the pr
    
[^3]: 评分差值流模型用于隐式生成建模

    The Score-Difference Flow for Implicit Generative Modeling. (arXiv:2304.12906v1 [cs.LG])

    [http://arxiv.org/abs/2304.12906](http://arxiv.org/abs/2304.12906)

    本文提出了一种新的评分差异流模型(SD flow)，它可以最优地减少两个分布之间的散度，同时解决Schr​​ödinger桥问题。与去噪扩散模型不同，它没有对先验分布施加任何限制，在一些基准数据集中优于其他方法。

    

    隐式生成建模(IGM)旨在生成符合目标数据分布特征的合成数据样本。最近的研究(例如评分匹配网络、扩散模型)从通过环境空间中的动态扰动或流将合成源数据推向目标分布的角度解决了IGM问题。我们引入了任意目标和源分布之间的评分差异(SD)作为流，它可以最优地减少它们之间的Kullback-Leibler散度，同时解决Schr​​ödinger桥问题。我们将SD流应用于方便的代理分布，当且仅当原始分布对齐时，它们是对齐的。我们在某些条件下展示了这种公式与去噪扩散模型的形式一致性。然而，与扩散模型不同，SD流没有对先验分布施加任何限制。我们还表明，在无限辨别器能力的极限下，生成对抗网络的训练包含SD流。我们的实验表明，SD流在几个基准数据集上优于先前的最新技术。

    Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the characteristics of a target data distribution. Recent work (e.g. score-matching networks, diffusion models) has approached the IGM problem from the perspective of pushing synthetic source data toward the target distribution via dynamical perturbations or flows in the ambient space. We introduce the score difference (SD) between arbitrary target and source distributions as a flow that optimally reduces the Kullback-Leibler divergence between them while also solving the Schr\"odinger bridge problem. We apply the SD flow to convenient proxy distributions, which are aligned if and only if the original distributions are aligned. We demonstrate the formal equivalence of this formulation to denoising diffusion models under certain conditions. However, unlike diffusion models, SD flow places no restrictions on the prior distribution. We also show that the training of generative adversarial networks includ
    
[^4]: 针对函数逼近的在线强化学习的一般覆盖条件的可证明优势

    Provable benefits of general coverage conditions in efficient online RL with function approximation. (arXiv:2304.12886v1 [stat.ML])

    [http://arxiv.org/abs/2304.12886](http://arxiv.org/abs/2304.12886)

    研究者对在线强化学习提出了一种新的一般覆盖条件，并发现更多的覆盖条件，提高了在线强化学习的样本效率和表现，同时阐明良好的覆盖条件仍然有益于获得最优解。

    

    在线强化学习中，与其使用马尔可夫决策过程（MDPs）的标准结构假设，使用某种覆盖条件（源自离线强化学习）足以确保样本有效保证（Xie等人，2023）。本文关注这个新方向，挖掘更多可能和更普遍的覆盖条件，并研究它们在高效在线强化学习中的潜力和用途。我们鉴定了更多概念，包括$L^p$功能集中度、密度比实现性以及部分/全覆盖条件的权衡，这些概念也有益于实现样本有效的在线强化学习，从而实现改进的遗憾边界。此外，如果利用探索性的离线数据，在我们的覆盖条件下，可以为在线强化学习实现统计和计算上高效的保证。此外，即使MDP结构已经给出，例如线性MDP，我们也阐明了良好的覆盖条件仍然有益于获得最优解。

    In online reinforcement learning (RL), instead of employing standard structural assumptions on Markov decision processes (MDPs), using a certain coverage condition (original from offline RL) is enough to ensure sample-efficient guarantees (Xie et al. 2023). In this work, we focus on this new direction by digging more possible and general coverage conditions, and study the potential and the utility of them in efficient online RL. We identify more concepts, including the $L^p$ variant of concentrability, the density ratio realizability, and trade-off on the partial/rest coverage condition, that can be also beneficial to sample-efficient online RL, achieving improved regret bound. Furthermore, if exploratory offline data are used, under our coverage conditions, both statistically and computationally efficient guarantees can be achieved for online RL. Besides, even though the MDP structure is given, e.g., linear MDP, we elucidate that, good coverage conditions are still beneficial to obtai
    
[^5]: 基于反Lipschitz约束的解码器网络控制后验坍塌

    Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the Decoder Network. (arXiv:2304.12770v1 [cs.LG])

    [http://arxiv.org/abs/2304.12770](http://arxiv.org/abs/2304.12770)

    本文提出了一种基于反Lipschitz约束的解码器网络，可以简单明了地控制广泛的VAE模型的后验坍塌程度，并带有具体的理论保证。

    

    变分自编码器（VAE）是深度生成模型中取得巨大成功的一种。然而，在实践中，它们存在一个称为后验坍塌的问题，当编码器与没有考虑输入数据的潜在结构的先验重合或坍塌时就会发生。本文介绍了一种基于反Lipschitz神经网络的解码器，基于这个架构，提供了一种新方法，可以简单明了地控制广泛的VAE模型的后验坍塌程度，并带有具体的理论保证。我们还通过几个数值实验证明了我们方法的有效性。

    Variational autoencoders (VAEs) are one of the deep generative models that have experienced enormous success over the past decades. However, in practice, they suffer from a problem called posterior collapse, which occurs when the encoder coincides, or collapses, with the prior taking no information from the latent structure of the input data into consideration. In this work, we introduce an inverse Lipschitz neural network into the decoder and, based on this architecture, provide a new method that can control in a simple and clear manner the degree of posterior collapse for a wide range of VAE models equipped with a concrete theoretical guarantee. We also illustrate the effectiveness of our method through several numerical experiments.
    
[^6]: 被动摆动摩擦力作用下机器人能量流量的关键参数及其特性

    Towards Characterizing the First-order Query Complexity of Learning (Approximate) Nash Equilibria in Zero-sum Matrix Games. (arXiv:2304.12768v1 [cs.GT])

    [http://arxiv.org/abs/2304.12768](http://arxiv.org/abs/2304.12768)

    本文研究了机器人系统的能量流量和能量特性，摩擦力和被动摆动是其主要影响因素，提出了关键参数和能量特性，有助于进一步研究。

    

    本文旨在研究机器人系统的能量流量和能量特性。我们考虑了机器人传动系统中摩擦力和被动摆动等因素，并提出了一个模型来分析这些因素对能量流量的影响。通过模拟和实验，我们发现能量流量主要受到摩擦力和被动摆动的影响，同时提出了一些关键参数和能量特性以供进一步研究。

    In the first-order query model for zero-sum $K\times K$ matrix games, playersobserve the expected pay-offs for all their possible actions under therandomized action played by their opponent. This is a classical model,which has received renewed interest after the discoveryby Rakhlin and Sridharan that $\epsilon$-approximate Nash equilibria can be computedefficiently from $O(\ln K / \epsilon) $ instead of $O( \ln K / \epsilon^2)$ queries.Surprisingly, the optimal number of such queries, as a function of both$\epsilon$ and $K$, is not known.We make progress on this question on two fronts. First, we fully characterise the query complexity of learning exact equilibria ($\epsilon=0$), by showing that they require a number of queries that is linearin $K$, which means that it is essentially as hard as querying the wholematrix, which can also be done with $K$ queries. Second, for $\epsilon > 0$, the currentquery complexity upper bound stands at $O(\min(\ln(K) / \epsilon , K))$. We argue that, u
    
[^7]: 受限通信加性高斯噪声下的多臂赌博机问题研究

    Communication-Constrained Bandits under Additive Gaussian Noise. (arXiv:2304.12680v1 [cs.LG])

    [http://arxiv.org/abs/2304.12680](http://arxiv.org/abs/2304.12680)

    本文研究了在受限通信和加性高斯噪声下的多臂赌博机问题，提出了一个多阶段赌博算法，并给出了信息理论下限。

    

    本文研究了一个分布式随机多臂赌博机,其中客户端根据相应的拉臂奖励提供受限通信反馈给学习者。在我们的设定下,客户端必须编码奖励，使得编码奖励的二阶矩不超过P，并且这个编码奖励会被方差为$\sigma^2$的加性高斯噪声所污染；学习者只能访问这个被污染的奖励。我们在这个设置中导出了任何方案的最小化后悔的信息论下限$\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$，其中 $ \mathtt{SNR} := \frac{P}{\sigma^2}$，$K$和$T$分别是臂数和时间长度。此外，我们提出了一个多阶段赌博算法$\mathtt{UE\text{-}UCB++}$，它可以将这个下限的值加上一个微小的可加性因子。$\mathtt{UE\text{-}UCB++}$在其初始阶段执行均匀探索，然后在后续阶段使用“上置信界”(UCB)算法。我们还展示了数值结果，表明在实际情况下需要这样的通信有效算法。

    We study a distributed stochastic multi-armed bandit where a client supplies the learner with communication-constrained feedback based on the rewards for the corresponding arm pulls. In our setup, the client must encode the rewards such that the second moment of the encoded rewards is no more than $P$, and this encoded reward is further corrupted by additive Gaussian noise of variance $\sigma^2$; the learner only has access to this corrupted reward. For this setting, we derive an information-theoretic lower bound of $\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$ on the minimax regret of any scheme, where $ \mathtt{SNR} := \frac{P}{\sigma^2}$, and $K$ and $T$ are the number of arms and time horizon, respectively. Furthermore, we propose a multi-phase bandit algorithm, $\mathtt{UE\text{-}UCB++}$, which matches this lower bound to a minor additive factor. $\mathtt{UE\text{-}UCB++}$ performs uniform exploration in its initial phases and then utilizes the {\em upper confidence
    
[^8]: 基于遗传算法的对流传热增强

    Genetically-inspired convective heat transfer enhancement. (arXiv:2304.12618v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2304.12618](http://arxiv.org/abs/2304.12618)

    本文研究了基于遗传算法的对流传热增强方法，通过对自由流相交的六个间隙喷气孔进行控制，优化了成本函数，最终实现了对对流传热速率的提高。

    

    本文在平板上的紊流边界层(TBL)上，采用基于线性遗传算法控制(LGAC)的人工智能方法实现对流传热的增强。该控制方法采用了一组与自由流相交的六个间隙喷气孔。通过对载波频率，占空比和执行器之间的相位差的控制参数定义开环最优周期性激励。根据无扰动TBL和稳态喷流的控制，对控制定律进行了优化。成本函数包括壁面对流传热速率和执行成本。采用红外热成像和粒子图像测速技术评估了控制器的性能。最优控制器产生了略微不对称的流场。LGAC算法收敛于所有执行器的相同频率和占空比。如此频率非常接近于特征频率的倒数。

    The convective heat transfer in a turbulent boundary layer (TBL) on a flat plate is enhanced using an artificial intelligence approach based on linear genetic algorithms control (LGAC). The actuator is a set of six slot jets in crossflow aligned with the freestream. An open-loop optimal periodic forcing is defined by the carrier frequency, the duty cycle and the phase difference between actuators as control parameters. The control laws are optimised with respect to the unperturbed TBL and to the actuation with a steady jet. The cost function includes the wall convective heat transfer rate and the cost of the actuation. The performance of the controller is assessed by infrared thermography and characterised also with particle image velocimetry measurements. The optimal controller yields a slightly asymmetric flow field. The LGAC algorithm converges to the same frequency and duty cycle for all the actuators. It is noted that such frequency is strikingly equal to the inverse of the charac
    
[^9]: 一种用于建模不确定和衰减滞后系统的双保真DeepONet方法

    A Bi-fidelity DeepONet Approach for Modeling Uncertain and Degrading Hysteretic Systems. (arXiv:2304.12609v1 [stat.ML])

    [http://arxiv.org/abs/2304.12609](http://arxiv.org/abs/2304.12609)

    本文介绍了一种用于建模不确定和退化滞后系统的双保真DeepONet方法，在不了解退化效应性质的原始模型数据集的情况下使用低保真度表示，显著提高了退化滞后系统的预测精度。

    

    引入不确定性后，非线性系统如滞后行为的退化通常出现在工程应用中，而建模这种系统变得越来越困难。另一方面，可以很容易地获取不了解退化效应性质的原始模型数据集。本文使用来自原始模型的数据集作为低保真度表示，以训练DeepONet。三个数值实例用于表明所提出的DeepONets的使用，以模拟低保真度模型和真实系统响应之间的偏差，在模型参数存在不确定性时，在退化滞后系统中预测误差显著降低。

    Nonlinear systems, such as with degrading hysteretic behavior, are often encountered in engineering applications. In addition, due to the ubiquitous presence of uncertainty and the modeling of such systems becomes increasingly difficult. On the other hand, datasets from pristine models developed without knowing the nature of the degrading effects can be easily obtained. In this paper, we use datasets from pristine models without considering the degrading effects of hysteretic systems as low-fidelity representations that capture many of the important characteristics of the true system's behavior to train a deep operator network (DeepONet). Three numerical examples are used to show that the proposed use of the DeepONets to model the discrepancies between the low-fidelity model and the true system's response leads to significant improvements in the prediction error in the presence of uncertainty in the model parameters for degrading hysteretic systems.
    
[^10]: Proto-Value Networks: 通过辅助任务进行表示学习的可扩展性研究

    Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks. (arXiv:2304.12567v1 [cs.LG])

    [http://arxiv.org/abs/2304.12567](http://arxiv.org/abs/2304.12567)

    本文研究了如何通过增加辅助任务的数量和代理网络的大小，提高表示学习的效果。同时，本文还提出了基于后继度量的新型辅助任务家族 Proto-Value 网络。

    

    辅助任务可以提高深度强化学习代理学到的表示能力。尽管其效果已经被相当充分地理论分析，但在实践中，它们主要被用作主要学习目标的支持，而不是作为表示学习的一种方法。基于这一观察，本文研究了辅助任务在学习复杂表示方面的有效性，重点关注同时增加任务数量和代理网络的大小的设置。为此，我们提出了一种基于后继度量的新型辅助任务家族。这些任务易于实现，具有吸引人的理论性质。与合适的离线学习规则结合使用，结果是一个表示学习算法，可以被理解为 Proto-Value 网络。

    Auxiliary tasks improve the representations learned by deep reinforcement learning agents. Analytically, their effect is reasonably well understood; in practice, however, their primary use remains in support of a main learning objective, rather than as a method for learning representations. This is perhaps surprising given that many auxiliary tasks are defined procedurally, and hence can be treated as an essentially infinite source of information about the environment. Based on this observation, we study the effectiveness of auxiliary tasks for learning rich representations, focusing on the setting where the number of tasks and the size of the agent's network are simultaneously increased. For this purpose, we derive a new family of auxiliary tasks based on the successor measure. These tasks are easy to implement and have appealing theoretical properties. Combined with a suitable off-policy learning rule, the result is a representation learning algorithm that can be understood as extend
    
[^11]: 一种新的具有自适应停止准则的非精确近端线性算法，用于鲁棒相位恢复问题。

    A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria for Robust Phase Retrieval. (arXiv:2304.12522v1 [math.OC])

    [http://arxiv.org/abs/2304.12522](http://arxiv.org/abs/2304.12522)

    本文提出了一种新的鲁棒相位恢复算法，通过使用自适应停止准则的非精确近端线性算法，该方法在实验中证明比现有方法更高效。

    

    本文考虑了鲁棒相位恢复问题，该问题可视为一个非光滑和非凸优化问题。我们提出了一种新的非精确近端线性算法，其中子问题被不精确求解。我们的贡献是为子问题提出了两种自适应停止准则。我们分析了所提出方法的收敛性能。通过对合成和实际数据集的实验，我们证明了我们的方法比现有方法更高效，例如原始近端线性算法和次梯度方法。

    This paper considers the robust phase retrieval problem, which can be cast as a nonsmooth and nonconvex optimization problem. We propose a new inexact proximal linear algorithm with the subproblem being solved inexactly. Our contributions are two adaptive stopping criteria for the subproblem. The convergence behavior of the proposed methods is analyzed. Through experiments on both synthetic and real datasets, we demonstrate that our methods are much more efficient than existing methods, such as the original proximal linear algorithm and the subgradient method.
    
[^12]: 广义贝叶斯加性回归树的后验集中理论

    Theory of Posterior Concentration for Generalized Bayesian Additive Regression Trees. (arXiv:2304.12505v1 [math.ST])

    [http://arxiv.org/abs/2304.12505](http://arxiv.org/abs/2304.12505)

    本论文提出了一个广义的贝叶斯树及其加性集成的框架，包括大多数BART的变体，并提出响应分布的充分条件，对BART及其变体的实证成功提供了理论支持。

    

    贝叶斯加性回归树（BART）是一种强大的半参数集成学习技术，用于建模非线性回归函数。虽然最初BART仅用于预测连续和二元响应变量，但多年来已经出现了多种扩展，适用于估计更广泛的响应变量（例如分类和计数数据），并且可以应用于很多领域。在本文中，我们描述了一个广义贝叶斯树及其加性集成的框架，其中响应变量来自指数族分布，因此包括BART的大多数变体。 我们推导出响应分布的充分条件，在此条件下，后验以最小化速率集中，最多以对数因子为限。在这方面，我们的结果为BART及其变体的实证成功提供了理论依据。

    Bayesian Additive Regression Trees (BART) are a powerful semiparametric ensemble learning technique for modeling nonlinear regression functions. Although initially BART was proposed for predicting only continuous and binary response variables, over the years multiple extensions have emerged that are suitable for estimating a wider class of response variables (e.g. categorical and count data) in a multitude of application areas. In this paper we describe a Generalized framework for Bayesian trees and their additive ensembles where the response variable comes from an exponential family distribution and hence encompasses a majority of these variants of BART. We derive sufficient conditions on the response distribution, under which the posterior concentrates at a minimax rate, up to a logarithmic factor. In this regard our results provide theoretical justification for the empirical success of BART and its variants.
    
[^13]: 强健的随机预处理方法解决核岭回归问题

    Robust, randomized preconditioning for kernel ridge regression. (arXiv:2304.12465v1 [math.NA])

    [http://arxiv.org/abs/2304.12465](http://arxiv.org/abs/2304.12465)

    针对核岭回归问题，本文引入了两种强健的随机预处理技术，分别解决了全数据KRR问题和限制版KRR问题，克服了以往预处理器的故障模式。

    

    本论文介绍了两种随机预处理技术，用于强健地解决具有中大规模数据点（$10^4 \leq N \leq 10^7$）的核岭回归（KRR）问题。第一种方法，RPCholesky预处理，能够在假设核矩阵特征值有足够快速的多项式衰减的情况下，以$O（N ^ 2）$算法操作准确地解决全数据KRR问题。第二种方法，KRILL预处理，以$O（（N + k ^ 2）k \ logk）$的代价，为KRR问题的限制版本提供准确的解决方案，该版本涉及$k \ll N$选择的数据中心。所提出的方法解决了广泛的KRR问题，克服了以前的KRR预处理器的故障模式，使它们成为实际应用的理想选择。

    This paper introduces two randomized preconditioning techniques for robustly solving kernel ridge regression (KRR) problems with a medium to large number of data points ($10^4 \leq N \leq 10^7$). The first method, RPCholesky preconditioning, is capable of accurately solving the full-data KRR problem in $O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of the kernel matrix eigenvalues. The second method, KRILL preconditioning, offers an accurate solution to a restricted version of the KRR problem involving $k \ll N$ selected data centers at a cost of $O((N + k^2) k \log k)$ operations. The proposed methods solve a broad range of KRR problems and overcome the failure modes of previous KRR preconditioners, making them ideal for practical applications.
    
[^14]: 水下航行器船体的样本高效和基于代理的设计优化

    Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls. (arXiv:2304.12420v1 [cs.LG])

    [http://arxiv.org/abs/2304.12420](http://arxiv.org/abs/2304.12420)

    该论文使用了高效的样本集优化和基于代理的方法来设计水下航行器船体，其中代理模型显著提高了计算效率，使优化更加快速准确。

    

    物理模拟是计算机辅助设计(CAD)优化过程中的一个计算瓶颈。因此，为了使精确(计算昂贵)的模拟可用于设计优化中，需要一个高样本效率的优化框架或快速的数据驱动代理(代理模型)来代替长时间运行的模拟。在这项工作中，我们利用最近优化和人工智能(AI)的进展来解决这两个潜在的解决方案，以设计一个最佳的无人水下航行器(UUV)。我们首先研究并比较了不同优化技术在优化循环中与标准计算流体力学(CFD)求解器相结合时的样本效率和收敛行为。然后，我们开发了一个基于深度神经网络(DNN)的代理模型来逼近否则通过CFD求解器进行计算的阻力。代理模型进而用于样本高效的优化框架中，该框架在不使用代理模型的情况下优于标准优化方法。

    Physics simulations are a computational bottleneck in computer-aided design (CAD) optimization processes. Hence, in order to make accurate (computationally expensive) simulations feasible for use in design optimization, one requires either an optimization framework that is highly sample-efficient or fast data-driven proxies (surrogate models) for long running simulations. In this work, we leverage recent advances in optimization and artificial intelligence (AI) to address both of these potential solutions, in the context of designing an optimal unmanned underwater vehicle (UUV). We first investigate and compare the sample efficiency and convergence behavior of different optimization techniques with a standard computational fluid dynamics (CFD) solver in the optimization loop. We then develop a deep neural network (DNN) based surrogate model to approximate drag forces that would otherwise be computed via direct numerical simulation with the CFD solver. The surrogate model is in turn use
    
[^15]: 使用R软件包ctsfeatures分析分类时间序列

    Analyzing categorical time series with the R package ctsfeatures. (arXiv:2304.12332v1 [stat.ML])

    [http://arxiv.org/abs/2304.12332](http://arxiv.org/abs/2304.12332)

    该软件包提供了一组有用的工具来分析分类时间序列，使得用户可以用图形描述底层时间模式并利用其输出执行传统的机器学习任务包括聚类、分类和异常检测。

    

    时间序列数据如今已无处不在。然而，大部分文献都处理实值时间序列，分类时间序列却受到了较少的关注。近年来，这类数据的数据挖掘技术得到了实质性的发展。 R软件包ctsfeatures为用户提供了一组有用的工具来分析分类时间序列。具体而言，该软件包提供了几个函数，允许提取已知的统计特征并构建描述底层时间模式的图形。某些函数的输出可用于执行传统的机器学习任务，包括聚类、分类和异常检测。该软件包还包括两个在文献中介绍的生物序列数据集，用于聚类目的，以及三个有趣的合成数据库。本文描述了该软件包的主要特征及其使用方法。

    Time series data are ubiquitous nowadays. Whereas most of the literature on the topic deals with real-valued time series, categorical time series have received much less attention. However, the development of data mining techniques for this kind of data has substantially increased in recent years. The R package ctsfeatures offers users a set of useful tools for analyzing categorical time series. In particular, several functions allowing the extraction of well-known statistical features and the construction of illustrative graphs describing underlying temporal patterns are provided in the package. The output of some functions can be employed to perform traditional machine learning tasks including clustering, classification and outlier detection. The package also includes two datasets of biological sequences introduced in the literature for clustering purposes, as well as three interesting synthetic databases. In this work, the main characteristics of the package are described and its us
    
[^16]: 简化基于动量的黎曼子流形优化

    Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09738](http://arxiv.org/abs/2302.09738)

    本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。

    

    带有动量的黎曼子流形优化在计算上是具有挑战性的，因为确保迭代保持在子流形上通常需要解决困难的微分方程。本文针对具有仿射不变度量的对称正定矩阵的子流形优化算法进行了简化。我们提出了黎曼正常坐标的广义版本，可以将问题动态地简化为欧几里得无约束问题。我们使用我们的方法来解释和简化现有的结构化协方差方法，并为深度学习开发了高效的二阶优化器，而无需显式矩阵求逆。

    Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
    
[^17]: 快速在线值最大化预测集和符合规范成本控制。

    Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control. (arXiv:2302.00839v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00839](http://arxiv.org/abs/2302.00839)

    本文提出了一种通用管道（FavMac），可以最大化价值并控制成本。 FavMac可以与几乎任何多标签分类器相结合，并通过在线更新机制处理实际的大规模应用，为成本控制提供无分布理论担保。

    

    许多现实世界的多标签预测问题涉及到必须满足下游使用规定的特定要求的集合值预测。我们关注一个典型的情况，其中这些要求分别编码价值和成本，并相互竞争。我们提出了一种被称为FavMac的通用管道，以在这种情况下最大化价值并控制成本。 FavMac可以与几乎任何多标签分类器相结合，为成本控制提供无分布理论担保。此外，与之前的作品不同，它可以通过精心设计的在线更新机制处理实际的大规模应用，这是值得独立关注的。我们的方法论和理论贡献得到了对多种机器学习分类器和几种数据集的试验支撑。

    Many real-world multi-label prediction problems involve set-valued predictions that must satisfy specific requirements dictated by downstream usage. We focus on a typical scenario where such requirements, separately encoding $\textit{value}$ and $\textit{cost}$, compete with each other. For instance, a hospital might expect a smart diagnosis system to capture as many severe, often co-morbid, diseases as possible (the value), while maintaining strict control over incorrect predictions (the cost). We present a general pipeline, dubbed as FavMac, to maximize the value while controlling the cost in such scenarios. FavMac can be combined with almost any multi-label classifier, affording distribution-free theoretical guarantees on cost control. Moreover, unlike prior works, it can handle real-world large-scale applications via a carefully designed online update mechanism, which is of independent interest. Our methodological and theoretical contributions are supported by experiments on severa
    
[^18]: 用于采样分子晶体结构的刚体流

    Rigid body flows for sampling molecular crystal structures. (arXiv:2301.11355v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11355](http://arxiv.org/abs/2301.11355)

    本文介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计。通过在单位四元数群上定义平滑和表现力强的流以及定义适当的密度，在旋转群上进行训练，我们可以成功地采样分子晶体结构。

    

    正则化流(NF)是一类强大的生成模型，由于其高度灵活和表现力，近年来广受欢迎。在本文中，我们介绍了一种新型的正则化流，专为三维空间中多个物体的位置和方向建模而设计，例如晶体中的分子。我们的方法基于两个关键思想:首先，我们在单位四元数群上定义平滑和表现力强的流，从而可以捕捉刚体的连续旋转运动;其次，我们利用单位四元数的双覆盖特性，在旋转群上定义一个适当的密度。这确保我们的模型可以使用标准的基于似然方法或基于热力学目标密度的变分推断进行训练。我们通过训练两个分子示例的Boltzmann生成器来评估该方法，即四面体系统的多模态密度。

    Normalizing flows (NF) are a class of powerful generative models that have gained popularity in recent years due to their ability to model complex distributions with high flexibility and expressiveness. In this work, we introduce a new type of normalizing flow that is tailored for modeling positions and orientations of multiple objects in three-dimensional space, such as molecules in a crystal. Our approach is based on two key ideas: first, we define smooth and expressive flows on the group of unit quaternions, which allows us to capture the continuous rotational motion of rigid bodies; second, we use the double cover property of unit quaternions to define a proper density on the rotation group. This ensures that our model can be trained using standard likelihood-based methods or variational inference with respect to a thermodynamic target density. We evaluate the method by training Boltzmann generators for two molecular examples, namely the multi-modal density of a tetrahedral system 
    
[^19]: 不变Lipschitz赌徒：一个侧观发现方法

    Invariant Lipschitz Bandits: A Side Observation Approach. (arXiv:2212.07524v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07524](http://arxiv.org/abs/2212.07524)

    本文研究了不变Lipschitz赌徒设置，并提出了一种名为\texttt{UniformMesh-N}的算法。使用侧面观察的方法，证明了改进的遗憾上界。

    

    对称出现在许多优化和决策问题中，并吸引了优化界的相当关注：通过利用这样的对称性，可以显著改进寻找最优解的过程。尽管对称性在（离线）优化中取得成功，但在在线优化设置中，特别是在赌徒文献中，其利用还未得到充分的研究。因此，在本文中，我们研究了不变Lipschitz赌徒设置，这是Lipschitz赌徒的一个子类，在该子类中，奖励函数和臂集在一组变换下保持不变。我们引入了一种名为\texttt{UniformMesh-N}的算法，它自然地将侧面观察使用群轨道整合到\texttt{UniformMesh}算法（\cite{Kleinberg2005_UniformMesh}）中，该算法均匀地分割了臂的集合。通过侧面观察方法，我们证明了改进的遗憾上界，其取决于基数。

    Symmetry arises in many optimization and decision-making problems, and has attracted considerable attention from the optimization community: By utilizing the existence of such symmetries, the process of searching for optimal solutions can be improved significantly. Despite its success in (offline) optimization, the utilization of symmetries has not been well examined within the online optimization settings, especially in the bandit literature. As such, in this paper we study the invariant Lipschitz bandit setting, a subclass of the Lipschitz bandits where the reward function and the set of arms are preserved under a group of transformations. We introduce an algorithm named \texttt{UniformMesh-N}, which naturally integrates side observations using group orbits into the \texttt{UniformMesh} algorithm (\cite{Kleinberg2005_UniformMesh}), which uniformly discretizes the set of arms. Using the side-observation approach, we prove an improved regret upper bound, which depends on the cardinalit
    
[^20]: 关于图神经网络模拟顶点间相互作用的研究

    On the Ability of Graph Neural Networks to Model Interactions Between Vertices. (arXiv:2211.16494v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16494](http://arxiv.org/abs/2211.16494)

    本文研究了GNN模拟顶点间相互作用的能力，通过一个被称为分离秩的度量标准来量化这种能力，结果表明模拟相互作用的能力主要取决于分区的行走指数，即从分界线开始的行走数量，同时设计了一种名为WISA的边稀疏化算法以提高GNNs的处理效率和表达能力。

    

    图神经网络(GNNs)被广泛用于建模由图中顶点表示的实体之间的复杂互动。尽管最近有一些理论分析GNNs表达能力的努力，但对其模拟相互作用的能力缺乏一个正式的描述。本文旨在填补这一空白。通过一个已知的度量标准——分离秩(separation rank)来规范化相互作用的强度，我们量化了某些GNNs模拟给定顶点子集及其补集之间交互的能力，即输入顶点组成的给定分区的两侧之间的互动。我们的结果表明，模拟相互作用的能力主要取决于分区的行走指数(walk index)——一个由分界线开始的行走数量定义的图形特征。常见GNN架构的实验证明了这一发现。作为我们理论的实际应用，我们设计了一种名为Walk Indexed Sparsification Algorithm (WISA)的边稀疏化算法，利用我们的研究结果提高处理大规模图形的GNNs效率同时保持它们的表达能力。

    Graph neural networks (GNNs) are widely used for modeling complex interactions between entities represented as vertices of a graph. Despite recent efforts to theoretically analyze the expressive power of GNNs, a formal characterization of their ability to model interactions is lacking. The current paper aims to address this gap. Formalizing strength of interactions through an established measure known as separation rank, we quantify the ability of certain GNNs to model interaction between a given subset of vertices and its complement, i.e. between the sides of a given partition of input vertices. Our results reveal that the ability to model interaction is primarily determined by the partition's walk index -- a graph-theoretical characteristic defined by the number of walks originating from the boundary of the partition. Experiments with common GNN architectures corroborate this finding. As a practical application of our theory, we design an edge sparsification algorithm named Walk Inde
    
[^21]: 基于统计检验的MMD-B-Fair：学习公平的表示

    MMD-B-Fair: Learning Fair Representations with Statistical Testing. (arXiv:2211.07907v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.07907](http://arxiv.org/abs/2211.07907)

    提出了一种基于统计检验的 MMD-B-Fair 方法，用于学习公平的数据表示，并在各种数据集上得到了验证。

    

    我们提出了一种通过核双样本测试学习数据公平表示的方法MMD-B-Fair。我们找到了数据的神经特征，其中最大平均偏差（MMD）测试无法区分不同敏感组的表示，同时保留有关目标属性的信息。我们的方法利用块测试方案的简单渐近性能够有效地找到公平表示，而不需要使用现有公平表示学习方法中广泛使用的复杂对抗性优化或生成建模方案。我们在各种数据集上评估了我们的方法，显示其能够“隐藏”有关敏感属性的信息，并在下游传输任务中的有效性。

    We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between representations of different sensitive groups, while preserving information about the target attributes. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold's complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to ``hide'' information about sensitive attributes, and its effectiveness in downstream transfer tasks.
    
[^22]: 多视角数据中缺失值的插补问题解决方法

    Imputation of missing values in multi-view data. (arXiv:2210.14484v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.14484](http://arxiv.org/abs/2210.14484)

    本文提出了一种基于StaPLR算法的新的多视角数据插补算法，通过在降维空间中执行插补以解决计算挑战，并在模拟数据集中得到了竞争性结果。

    

    多视角数据是指由多个不同特征集描述的数据。在处理多视角数据时，若出现缺失值，则一个视角中的所有特征极有可能同时缺失，因而导致非常大量的缺失数据问题。本文提出了一种新的多视角学习算法中的插补方法，它基于堆叠惩罚逻辑回归(StaPLR)算法，在降维空间中执行插补，以解决固有的多视角计算挑战。实验结果表明，该方法在模拟数据集上具有竞争性结果，而且具有更低的计算成本，从而可以使用先进的插补算法，例如missForest。

    Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest 
    
[^23]: 基于图高斯过程的流形优化

    Optimization on Manifolds via Graph Gaussian Processes. (arXiv:2210.10962v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.10962](http://arxiv.org/abs/2210.10962)

    本论文结合流形学习和高斯过程，利用流形样本点云定义图高斯过程代理模型，通过选择查询点在流形上优化目标函数，具有良好性能。

    

    本文将流形学习技术与高斯过程上限置信度算法相结合，以优化流形上的目标函数。我们的方法是针对在无法获得完整流形表示且查询目标昂贵的应用场景而设计的。我们依靠流形样本点云来定义用于目标函数的图高斯过程代理模型。使用先前所有查询的后验分布逐步选择查询点。我们在查询次数和点云大小方面建立了遗憾上限。数值实验补充了理论，并说明了我们的方法的性能。

    This paper integrates manifold learning techniques within a \emph{Gaussian process upper confidence bound} algorithm to optimize an objective function on a manifold. Our approach is motivated by applications where a full representation of the manifold is not available and querying the objective is expensive. We rely on a point cloud of manifold samples to define a graph Gaussian process surrogate model for the objective. Query points are sequentially chosen using the posterior distribution of the surrogate model given all previous queries. We establish regret bounds in terms of the number of queries and the size of the point cloud. Several numerical examples complement the theory and illustrate the performance of our method.
    
[^24]: 特征选择的序列关注

    Sequential Attention for Feature Selection. (arXiv:2209.14881v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14881](http://arxiv.org/abs/2209.14881)

    在神经网络中，我们提出一种名为序列关注的特征选择算法，它在每个步骤使用注意力权重作为特征重要性的代理，实现了最新的实证结果。

    

    特征选择是为了选择一个子集用于机器学习模型，而这个子集能最大化模型质量，并且要求在预算范围内。对于神经网络，采用的传统方法包括基于$\ell_1$正则化、注意力和其他技术的方法，通常在一次评估中选择整个特征子集，忽略了在选择期间特征的残留价值，即在选择其他特征后给与特征的边际贡献。我们提出了一种名为序列关注的特征选择算法，它在神经网络中实现了最新的实证结果。该算法基于一遍高效的贪心前向选择实现，并在每个步骤使用注意力权重作为特征重要性的代理。我们通过展示适用于线性回归的理论意义，说明了我们的算法相当于经典的正交匹配追踪（OMP）算法。

    Feature selection is the problem of selecting a subset of features for a machine learning model that maximizes model quality subject to a budget constraint. For neural networks, prior methods, including those based on $\ell_1$ regularization, attention, and other techniques, typically select the entire feature subset in one evaluation round, ignoring the residual value of features during selection, i.e., the marginal contribution of a feature given that other features have already been selected. We propose a feature selection algorithm called Sequential Attention that achieves state-of-the-art empirical results for neural networks. This algorithm is based on an efficient one-pass implementation of greedy forward selection and uses attention weights at each step as a proxy for feature importance. We give theoretical insights into our algorithm for linear regression by showing that an adaptation to this setting is equivalent to the classical Orthogonal Matching Pursuit (OMP) algorithm, a
    
[^25]: 分布回归的非线性充分降维

    Nonlinear Sufficient Dimension Reduction for Distribution-on-Distribution Regression. (arXiv:2207.04613v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2207.04613](http://arxiv.org/abs/2207.04613)

    本文提出了一种新的非线性降维方法，用于同时处理预测变量和响应变量均为分布数据的情形。该方法使用通用核建立预测变量和响应变量的复现核希尔伯特空间以描述条件独立性，对于单变量分布和多元分布分别采用Wasserstein距离和分片Wasserstein距离构建通用核，经合成数据测试表现优于竞争方法。

    

    我们提出了一种新的非线性充分降维方法，用于同时处理预测变量和响应变量均为分布数据的情形，这两种数据都被建模为度量空间中的成员。我们的关键步骤是在度量空间上构建通用核，以建立可以描述决定充分降维的条件独立性的预测变量和响应变量的复现核希尔伯特空间。对于单变量分布，我们使用Wasserstein距离构建通用核，而对于多元分布，我们则采用分片Wasserstein距离。分片Wasserstein距离确保度量空间具有与Wasserstein空间相似的拓扑特性，同时还提供了显著的计算优势。基于合成数据的数值结果表明，我们的方法优于可能的竞争方法。该方法也被应用于多个数据集，包括生育数据和...

    We introduce a new approach to nonlinear sufficient dimension reduction in cases where both the predictor and the response are distributional data, modeled as members of a metric space. Our key step is to build universal kernels (cc-universal) on the metric spaces, which results in reproducing kernel Hilbert spaces for the predictor and response that are rich enough to characterize the conditional independence that determines sufficient dimension reduction. For univariate distributions, we construct the universal kernel using the Wasserstein distance, while for multivariate distributions, we resort to the sliced Wasserstein distance. The sliced Wasserstein distance ensures that the metric space possesses similar topological properties to the Wasserstein space while also offering significant computation benefits. Numerical results based on synthetic data show that our method outperforms possible competing methods. The method is also applied to several data sets, including fertility and 
    
[^26]: 多样多层网络模型中的稀疏子空间聚类

    Sparse Subspace Clustering in Diverse Multiplex Network Model. (arXiv:2206.07602v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.07602](http://arxiv.org/abs/2206.07602)

    本文研究了DIMPLE网络模型中的稀疏子空间聚类，通过识别具有相同社区结构的层组，找到了一种强一致性的结果。

    

    本文考虑了Pensky和Wang（2021）引入的DIverse MultiPLEx（DIMPLE）网络模型，其中网络的所有层都具有相同的节点集合，并配备有随机块模型。此外，所有层都可以分为具有相同社区结构的组，尽管在同一组中的层可能具有不同的块连接概率矩阵。DIMPLE模型概括了许多研究所有层具有相同社区结构的多层网络的论文，以及混合多层随机块模型（MMLSBM），在其中同一组中的层具有相同的块连接概率矩阵。本文使用稀疏子空间聚类（SSC）来识别具有相同社区结构的层组。在温和的条件下，后者导致了强一致性的结果。

    The paper considers the DIverse MultiPLEx (DIMPLE) network model, introduced in Pensky and Wang (2021), where all layers of the network have the same collection of nodes and are equipped with the Stochastic Block Models. In addition, all layers can be partitioned into groups with the same community structures, although the layers in the same group may have different matrices of block connection probabilities. The DIMPLE model generalizes a multitude of papers that study multilayer networks with the same community structures in all layers, as well as the Mixture Multilayer Stochastic Block Model (MMLSBM), where the layers in the same group have identical matrices of block connection probabilities. While Pensky and Wang (2021) applied spectral clustering to the proxy of the adjacency tensor, the present paper uses Sparse Subspace Clustering (SSC) for identifying groups of layers with identical community structures. Under mild conditions, the latter leads to the strongly consistent betwee
    
[^27]: 目标自适应设计

    Targeted Adaptive Design. (arXiv:2205.14208v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14208](http://arxiv.org/abs/2205.14208)

    TAD是一种新的目标自适应设计算法，可以通过高斯过程代理模型在指定公差中确定产生期望设计特征的最佳控制设置，相比其他自适应设计算法，具有更高的精度和效率。

    

    现代先进制造和高级材料设计往往需要在较高维度的过程控制参数空间中搜索最佳结构、性能和性能参数的设置。从前者到后者的映射必须通过嘈杂的实验或昂贵的模拟来确定。我们把这个问题抽象成一个数学框架，其中必须通过昂贵的嘈杂测量来确定从控制空间到设计空间的未知函数，该函数在指定的公差范围内定位产生期望设计特征的最佳控制设置，并量化不确定性。我们描述了目标自适应设计 (TAD)，这是一种有效执行这个采样任务的新算法。TAD 在每个迭代阶段创建一个未知映射的高斯过程代理模型，建议一批新的控制设置进行实验采样，并优化更新的目标设计特征的对数预测似然。

    Modern advanced manufacturing and advanced materials design often require searches of relatively high-dimensional process control parameter spaces for settings that result in optimal structure, property, and performance parameters. The mapping from the former to the latter must be determined from noisy experiments or from expensive simulations. We abstract this problem to a mathematical framework in which an unknown function from a control space to a design space must be ascertained by means of expensive noisy measurements, which locate optimal control settings generating desired design features within specified tolerances, with quantified uncertainty. We describe targeted adaptive design (TAD), a new algorithm that performs this sampling task efficiently. TAD creates a Gaussian process surrogate model of the unknown mapping at each iterative stage, proposing a new batch of control settings to sample experimentally and optimizing the updated log-predictive likelihood of the target desi
    
[^28]: 高斯过程回归中的最大似然估计存在不适定性

    Maximum Likelihood Estimation in Gaussian Process Regression is Ill-Posed. (arXiv:2203.09179v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2203.09179](http://arxiv.org/abs/2203.09179)

    本文指出了高斯过程回归中，使用最大似然估计器估计长度尺度参数的平稳协方差函数的情况下，在无噪声数据情况下会存在不适定问题。

    

    高斯过程回归是机器学习和统计学中无数学术和工业应用的基础，其中最大似然估计通常用于选择适当的协方差核参数。然而，确定最大似然估计为适定问题的情况尚未解决，即，在回归模型的预测对数据的微小扰动不敏感的情况下。本文确定了最大似然估计器无法适定的情况，即在Hellinger距离意义下，预测分布对数据不具有Lipschitz连续性。这些失败情况发生在无噪声数据情况下，对于任何使用最大似然估计估计长度尺度参数的平稳协方差函数的高斯过程。虽然最大似然估计的失败是高斯过程的常识，但这些严格的理论结果似乎是第一次。

    Gaussian process regression underpins countless academic and industrial applications of machine learning and statistics, with maximum likelihood estimation routinely used to select appropriate parameters for the covariance kernel. However, it remains an open problem to establish the circumstances in which maximum likelihood estimation is well-posed, that is, when the predictions of the regression model are insensitive to small perturbations of the data. This article identifies scenarios where the maximum likelihood estimator fails to be well-posed, in that the predictive distributions are not Lipschitz in the data with respect to the Hellinger distance. These failure cases occur in the noiseless data setting, for any Gaussian process with a stationary covariance function whose lengthscale parameter is estimated using maximum likelihood. Although the failure of maximum likelihood estimation is part of Gaussian process folklore, these rigorous theoretical results appear to be the first o
    
[^29]: 先验、层次和信息不对称在强化学习技能转移中的应用

    Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning. (arXiv:2201.08115v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2201.08115](http://arxiv.org/abs/2201.08115)

    本文介绍了一种名为“APEx”的技能发现和转移算法，它以一种原则性和学习的方式利用信息不对称性，实现了最先进的采样效率、任务可转移性和概括能力，同时保留了非分层方法的表达能力和灵活性。

    

    从过去的经验中发现行为，并将其转移到新任务中的能力是智能代理在真实世界中高效采样的标志。为智能强化学习者装备相同的能力可能对它们在机器人技术上的成功部署至关重要。虽然分层和KL-正则化强化学习各自在这方面很有希望，但混合方法可能结合它们各自的优点。这些领域的关键在于利用架构模块之间的信息不对称性来偏执学习的技能。虽然不对称性选择对可转移性有很大影响，但现有方法主要基于直觉，以一个与领域无关的可能次优的方式进行选择。在本文中，我们从理论和经验上展示了序列任务中技能的关键表达能力-可转移性的平衡，由信息不对称性控制。在获得这一洞见后，我们引入了一种名为“APEx”的技能发现和转移算法，它以一种原则性和学习的方式利用信息不对称性。APEx实现了最先进的采样效率、任务可转移性和概括能力，同时保留了非分层方法的表达能力和灵活性。

    The ability to discover behaviours from past experience and transfer them to new tasks is a hallmark of intelligent agents acting sample-efficiently in the real world. Equipping embodied reinforcement learners with the same ability may be crucial for their successful deployment in robotics. While hierarchical and KL-regularized reinforcement learning individually hold promise here, arguably a hybrid approach could combine their respective benefits. Key to these fields is the use of information asymmetry across architectural modules to bias which skills are learnt. While asymmetry choice has a large influence on transferability, existing methods base their choice primarily on intuition in a domain-independent, potentially sub-optimal, manner. In this paper, we theoretically and empirically show the crucial expressivity-transferability trade-off of skills across sequential tasks, controlled by information asymmetry. Given this insight, we introduce Attentive Priors for Expressive and Tra
    
[^30]: 自适应加权多视图聚类

    Adaptive Weighted Multi-View Clustering. (arXiv:2110.13240v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.13240](http://arxiv.org/abs/2110.13240)

    本文提出了一种加权多视图 NMF算法，旨在学习视图特定权重和观测特定重构权重，以量化每个视图的信息内容，通过分配较小和较大的权重来扩大重要视图的正面影响。

    

    学习多视图数据是机器学习研究中一个新兴的问题，非负矩阵分解（NMF）是一种流行的降维方法，用于整合来自多个视图的信息。这些视图通常不仅提供一致性信息，还提供互补信息。然而，大多数多视图NMF算法将每个视图赋予相同的权重，或者通过经验性的线性搜索调整权重，这在没有视图的任何先验知识或计算上是不可行的。在本文中，我们提出了一种加权多视图NMF（WM-NMF）算法。特别地，我们旨在解决关键技术差距，即学习视图特定权重和观测特定重构权重，以量化每个视图的信息内容。引入的加权方案可以通过分配较小和较大的权重来减轻不必要视图的负面影响并扩大重要视图的正面影响。

    Learning multi-view data is an emerging problem in machine learning research, and nonnegative matrix factorization (NMF) is a popular dimensionality-reduction method for integrating information from multiple views. These views often provide not only consensus but also complementary information. However, most multi-view NMF algorithms assign equal weight to each view or tune the weight via line search empirically, which can be infeasible without any prior knowledge of the views or computationally expensive. In this paper, we propose a weighted multi-view NMF (WM-NMF) algorithm. In particular, we aim to address the critical technical gap, which is to learn both view-specific weight and observation-specific reconstruction weight to quantify each view's information content. The introduced weighting scheme can alleviate unnecessary views' adverse effects and enlarge the positive effects of the important views by assigning smaller and larger weights, respectively. Experimental results confir
    
[^31]: 带有决策相关分布的学习中的近似吸引子区域

    Approximate Regions of Attraction in Learning with Decision-Dependent Distributions. (arXiv:2107.00055v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.00055](http://arxiv.org/abs/2107.00055)

    本文分析了在决策相关分布学习中的风险最小化，建立在执行风险最小化的梯度流的扰动轨迹之上，研究了可能存在多个局部最小化器的情况。

    

    随着数据驱动的方法在现实世界中的应用，生成观察数据的过程往往会根据学习者的决策做出反应。例如，数据源可能有一些激励让算法提供特定的标签（如批准银行贷款），并相应地操纵它们的特征。在战略分类和决策相关分布的工作中，通过明确考虑分类器对基础数据分布的影响来表征部署学习算法的闭环行为。最近，在执行预测的研究中，考虑分类器到数据分布的映射的一般属性，而非显式形式来分类闭环行为。基于这个概念，我们将重复的风险最小化分析为执行风险最小化的梯度流的扰动轨迹。我们考虑可能存在多个局部最小化器的场合。

    As data-driven methods are deployed in real-world settings, the processes that generate the observed data will often react to the decisions of the learner. For example, a data source may have some incentive for the algorithm to provide a particular label (e.g. approve a bank loan), and manipulate their features accordingly. Work in strategic classification and decision-dependent distributions seeks to characterize the closed-loop behavior of deploying learning algorithms by explicitly considering the effect of the classifier on the underlying data distribution. More recently, works in performative prediction seek to classify the closed-loop behavior by considering general properties of the mapping from classifier to data distribution, rather than an explicit form. Building on this notion, we analyze repeated risk minimization as the perturbed trajectories of the gradient flows of performative risk minimization. We consider the case where there may be multiple local minimizers of perfor
    
[^32]: 从多嵌入交互的角度分析知识图谱嵌入方法。

    Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding Interaction Perspective. (arXiv:1903.11406v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1903.11406](http://arxiv.org/abs/1903.11406)

    本文提出了一种多嵌入交互的角度来分析和比较知识图谱嵌入方法，研究了CP，DistMult和ComplEx等三种流行的方法，揭示了ComplEx性能更好的原因，并为开发新模型提供了见解。

    

    知识图谱是一种广泛用于表示知识的格式，且在语义搜索引擎、问答系统和推荐系统中有许多应用。然而，实际的知识图谱通常是不完整的，因此提出了基于嵌入向量方法，如CP、DistMult和ComplEx等，以解决此问题。这些方法将实体和关系表示为语义空间中的嵌入向量，并预测它们之间的链接。嵌入向量本身包含丰富的语义信息，可用于其他应用程序，如数据分析。但是，这些模型中的机制和嵌入向量本身变化很大，使其难以理解和比较。因此，我们需要以多嵌入交互的角度来分析和比较知识图谱嵌入方法。具体而言，我们研究了三种流行的方法（CP、DistMult和ComplEx），并研究它们的不同嵌入向量如何相互作用。我们的分析揭示了ComplEx性能更好的原因，并为开发新模型提供了见解。

    Knowledge graph is a popular format for representing knowledge, with many applications to semantic search engines, question-answering systems, and recommender systems. Real-world knowledge graphs are usually incomplete, so knowledge graph embedding methods, such as Canonical decomposition/Parallel factorization (CP), DistMult, and ComplEx, have been proposed to address this issue. These methods represent entities and relations as embedding vectors in semantic space and predict the links between them. The embedding vectors themselves contain rich semantic information and can be used in other applications such as data analysis. However, mechanisms in these models and the embedding vectors themselves vary greatly, making it difficult to understand and compare them. Given this lack of understanding, we risk using them ineffectively or incorrectly, particularly for complicated models, such as CP, with two role-based embedding vectors, or the state-of-the-art ComplEx model, with complex-valu
    
[^33]: 集成采样

    Ensemble Sampling. (arXiv:1705.07347v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1705.07347](http://arxiv.org/abs/1705.07347)

    本文介绍了集成采样，以近似Thompson采样并在复杂模型下保持可行性，将大大扩展Thompson采样的应用范围。

    

    Thompson采样已经成为一种解决多种在线决策问题的有效启发式算法。在其基本形式中，该算法需要计算并从模型的后验分布中采样，仅在简单特殊情况下才可行。本文介绍了集成采样，旨在近似Thompson采样，同时在复杂模型（如神经网络）的面前保持可行性。集成采样大大扩展了适用Thompson采样的应用范围。我们建立了支持该方法的理论基础，并提供了进一步的计算结果来提供更多见解。

    Thompson sampling has emerged as an effective heuristic for a broad range of online decision problems. In its basic form, the algorithm requires computing and sampling from a posterior distribution over models, which is tractable only for simple special cases. This paper develops ensemble sampling, which aims to approximate Thompson sampling while maintaining tractability even in the face of complex models such as neural networks. Ensemble sampling dramatically expands on the range of applications for which Thompson sampling is viable. We establish a theoretical basis that supports the approach and present computational results that offer further insight.
    

