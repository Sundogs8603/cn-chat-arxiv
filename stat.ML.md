# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Low-count Time Series Anomaly Detection.](http://arxiv.org/abs/2308.12925) | 本论文提出了一种解决低计数时间序列异常检测的方法。通过引入新的生成过程来创建包含异常片段的基准数据集，并通过理论和实证分析解释了常用算法在正常和异常片段之间的分布重叠问题。 |
| [^2] | [Prediction without Preclusion: Recourse Verification with Reachable Sets.](http://arxiv.org/abs/2308.12820) | 这项研究引入了一种称为后续验证的正式测试程序，用于检测模型分配固定预测的情况。通过开发可靠的机制，可以确定给定模型是否能为决策对象提供后续措施，从而解决了模型分配固定预测可能带来的问题。该研究还展示了如何在真实世界的数据集中确保后续措施和对抗鲁棒性，并探讨了在贷款数据集中实现后续措施的不可行性。 |
| [^3] | [Single-shot Bayesian approximation for neural networks.](http://arxiv.org/abs/2308.12785) | 这篇论文提出了一种单次MC dropout近似方法，以将神经网络转换为贝叶斯变体的神经网络，该方法具有与普通神经网络相同的计算速度，同时保留了贝叶斯变体神经网络提供的不确定度测量。 |
| [^4] | [On the Consistency of Average Embeddings for Item Recommendation.](http://arxiv.org/abs/2308.12767) | 本文研究了推荐系统中平均嵌入的一致性，并提出了一种衡量方法。实证结果表明，现实世界的平均嵌入在推荐中一致性较低，为进一步改进现实世界嵌入提供了方向。 |
| [^5] | [Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints.](http://arxiv.org/abs/2308.12680) | 这篇论文提出了一种用于解决具有非线性边际反馈和多样性约束的前K个组合多臂赌博机问题的新型主从架构，通过引入六个从模型和教师学习优化以及策略共训练技术，实现了高效的探索和利用之间的决策权衡。 |
| [^6] | [Geodesic Mode Connectivity.](http://arxiv.org/abs/2308.12666) | 本文探讨了测地线模式连通性的现象，并提出了一种算法近似测地线，实现了模式连通性。 |
| [^7] | [Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines.](http://arxiv.org/abs/2308.12635) | 本文介绍了一套工业级匈牙利文本处理模型，利用HuSpaCy框架实现，通过多项改进在资源效率和准确性之间取得了接近最先进的性能。这些模型具备高准确性和吞吐量，并在所有基本文本处理步骤中展示了竞争性能。 |
| [^8] | [A Greedy Approach for Offering to Telecom Subscribers.](http://arxiv.org/abs/2308.12606) | 本论文提出了一个用于解决套餐优化问题的新颖组合算法，该算法针对电信运营商在选择激励套餐和目标用户时面临的困难进行了解决。 |
| [^9] | [Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions.](http://arxiv.org/abs/2308.12562) | 本文提出了一种利用大型语言和多模态模型的变分信息追求(V-IP)框架，通过顺序选择任务相关的可解释查询，实现可解释预测。为了解决数据标注的限制，引入了基础模型(FMs)，使用大型语言模型(LLMs)生成候选可解释概念集，并使用大型多模态模型注释每个数据样本。此方法适用于大规模任务。 |
| [^10] | [Don't blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy.](http://arxiv.org/abs/2308.12553) | 默认-ERM模型通过最大化间隔来优化训练，导致模型更多依赖于捷径而非稳定特征，这对感知任务来说是不合适的。 |
| [^11] | [An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems.](http://arxiv.org/abs/2308.12445) | 本文提出了一种名为 Dr. DRL 的自愈方法，用于解决深度强化学习系统中的一些效率问题，该方法通过在连续学习中引入有意遗忘的机制来应对环境漂移引起的困扰。 |
| [^12] | [Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes.](http://arxiv.org/abs/2308.12304) | 我们研究了量子测量类的可学习性，并建立了必要和充分条件，同时给出了对应的样本复杂性上界。我们发现标准ERM未满足统一收敛性的问题，于是提出了一种新的学习规则——去噪ERM，该规则在POVM和概率观测的概念类别中具有普适性并满足统一收敛性的条件。 |
| [^13] | [A multiobjective continuation method to compute the regularization path of deep neural networks.](http://arxiv.org/abs/2308.12044) | 本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。 |
| [^14] | [On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget.](http://arxiv.org/abs/2308.12000) | 本文研究了在有限预算的随机二臂赌博机中进行最佳臂选择的问题，并证明不存在比等概率采样算法更好的算法。我们引入了一致稳定算法的概念，并证明任何在所有情况下与等概率采样算法表现一样好的算法必须属于这个类别。这一结果解决了之前的两个未解之谜。 |
| [^15] | [A Data-Driven Approach to Morphogenesis under Structural Instability.](http://arxiv.org/abs/2308.11846) | 提出了一种基于数据驱动的方法来理解和预测结构不稳定下的形态发生的时空复杂性，通过机器学习框架研究内外部力驱动下的形态发生，并通过构建数字化图书馆识别异常、预测形态发展，为疾病诊断和抗不稳定设计提供了指导。 |
| [^16] | [Wasserstein Geodesic Generator for Conditional Distributions.](http://arxiv.org/abs/2308.10145) | 通过Wasserstein几何生成器学习条件分布，生成给定特定标签的样本。使用最优输运理论提出的方法能学习观察域的条件分布和它们之间的最优输运映射。在人脸图像数据上的实验验证了该方法的有效性。 |
| [^17] | [Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage.](http://arxiv.org/abs/2308.09113) | 多保真度傅里叶神经算子用于解决大规模地质碳储存问题，通过利用经济性更高的多保真度训练数据集，能够以与高保真度模型相当的准确性进行预测。 |
| [^18] | [Conditional expectation via compact kernels.](http://arxiv.org/abs/2306.10592) | 本文提出了一种基于紧核的算子理论方法来解决条件期望估计问题，在再生核希尔伯特空间中实现，易于实现，且成功应用于实际问题中。 |
| [^19] | [Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach.](http://arxiv.org/abs/2305.17058) | 该论文提出一种精确推理离散统计模型的贝叶斯方法，支持离散采样、连续采样、离散观测、仿射函数、（随机）分支和事件条件。通过概率生成函数实现后验概率、期望、方差和高阶矩的精确计算。该方法性能优于近似蒙特卡洛方法，并避免了近似误差。 |
| [^20] | [Improving multiple-try Metropolis with local balancing.](http://arxiv.org/abs/2211.11613) | 这篇论文提出了一种改进的多次尝试Metropolis算法，通过使用局部平衡策略的权重函数，解决了在高维情况下收敛阶段出现的异常行为问题。 |
| [^21] | [Exact Manifold Gaussian Variational Bayes.](http://arxiv.org/abs/2210.14598) | 我们提出了一种在复杂模型中进行变分推断的优化算法，通过使用自然梯度更新和黎曼流形，我们开发了一种高效的高斯变分推断算法，并验证了其在多个数据集上的性能。 |
| [^22] | [Individual Privacy Accounting with Gaussian Differential Privacy.](http://arxiv.org/abs/2209.15596) | 本论文介绍了用于个体隐私核算的高斯差分隐私方法，通过对自适应组合随机机制进行仔细分析，为高斯机制提供了最优边界。 |
| [^23] | [Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation.](http://arxiv.org/abs/2209.10634) | 这项工作探索了通过内部神经元介导递归通信与直接递归连接相比的计算优势，通过分析连续突触动态和数值模拟，表明具有内部神经元的网络比具有直接递归连接的网络更能抵抗初始化的干扰。 |
| [^24] | [Unifying Gradients to Improve Real-world Robustness for Deep Networks.](http://arxiv.org/abs/2208.06228) | 通过统一不同数据的梯度来防御基于评分的查询攻击（SQAs），这样SQAs只能探测到一个更弱的攻击方向，保护真实世界的深度神经网络。 |
| [^25] | [Demographic Parity Constrained Minimax Optimal Regression under Linear Model.](http://arxiv.org/abs/2206.11546) | 本研究探讨了在线性模型下基于人口平等约束的回归问题的最小最大优化误差，并提出了一个包含更广泛歧视偏差来源的模型。我们发现，在这个模型中，最小最大优化误差与样本大小、维数和人口群组数量存在关系，并且误差会随着模型中偏差的增加而增加。 |
| [^26] | [StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random.](http://arxiv.org/abs/2205.04701) | StableDR是一种稳定的双重稳健学习方法，用于解决推荐系统中数据缺失非随机的问题。通过减少对外推的依赖，StableDR能够同时具有有界的偏差、方差和泛化误差界，在不准确的估计误差和任意小的倾向性下表现出优越性能。 |
| [^27] | [Riemannian Hamiltonian methods for min-max optimization on manifolds.](http://arxiv.org/abs/2204.11418) | 本文研究了流形上的min-max优化问题，并引入了Riemannian Hamiltonian方法作为其代理方法。通过最小化Hamiltonian函数，可以得到所需的min-max鞍点。该方法在geodesic-bilinear优化问题中具有挑战性，但通过解决代理问题可以得到全局最优搜索方向。该方法在多个应用中展示了其有效性。 |
| [^28] | [Near Optimal Adversarial Attack on UCB Bandits.](http://arxiv.org/abs/2008.09312) | 本文提出了一种在对抗攻击下的UCB最优拉臂策略，成本为$\sqrt{\log T}$，并且证明了此攻击策略近乎是最优的。 |

# 详细

[^1]: 低计数时间序列异常检测

    Low-count Time Series Anomaly Detection. (arXiv:2308.12925v1 [cs.LG])

    [http://arxiv.org/abs/2308.12925](http://arxiv.org/abs/2308.12925)

    本论文提出了一种解决低计数时间序列异常检测的方法。通过引入新的生成过程来创建包含异常片段的基准数据集，并通过理论和实证分析解释了常用算法在正常和异常片段之间的分布重叠问题。

    

    低计数时间序列描述稀疏或间断事件，这在捕获和监控不同数据类型的大规模在线平台中很常见。建模低计数时间序列面临几个挑战，特别是低信噪比（当异常签名无法检测时）和非均匀性能（平均度量指标不能代表局部行为）。当前的时间序列异常检测领域缺乏明确的工具和流程来建模和可靠地检测这些情况下的异常。为了解决这个问题，我们引入了一种新的生成过程，用于创建包含有异常片段的低计数时间序列的基准数据集。通过理论和实证分析的混合，我们的工作解释了常用算法在正常和异常片段之间的分布重叠中遇到的困难。为了减轻这个缺点，我们利用我们的发现来展示如何进行异常检测。

    Low-count time series describe sparse or intermittent events, which are prevalent in large-scale online platforms that capture and monitor diverse data types. Several distinct challenges surface when modelling low-count time series, particularly low signal-to-noise ratios (when anomaly signatures are provably undetectable), and non-uniform performance (when average metrics are not representative of local behaviour). The time series anomaly detection community currently lacks explicit tooling and processes to model and reliably detect anomalies in these settings. We address this gap by introducing a novel generative procedure for creating benchmark datasets comprising of low-count time series with anomalous segments. Via a mixture of theoretical and empirical analysis, our work explains how widely-used algorithms struggle with the distribution overlap between normal and anomalous segments. In order to mitigate this shortcoming, we then leverage our findings to demonstrate how anomaly sc
    
[^2]: 不排除预测：基于可达集的后续验证方法

    Prediction without Preclusion: Recourse Verification with Reachable Sets. (arXiv:2308.12820v1 [cs.LG])

    [http://arxiv.org/abs/2308.12820](http://arxiv.org/abs/2308.12820)

    这项研究引入了一种称为后续验证的正式测试程序，用于检测模型分配固定预测的情况。通过开发可靠的机制，可以确定给定模型是否能为决策对象提供后续措施，从而解决了模型分配固定预测可能带来的问题。该研究还展示了如何在真实世界的数据集中确保后续措施和对抗鲁棒性，并探讨了在贷款数据集中实现后续措施的不可行性。

    

    机器学习模型常被用于决定谁有资格得到贷款、面试或公共福利。标准技术用于构建这些模型时，会使用关于人的特征，但忽视他们的可操作性。因此，模型可能会分配固定的预测，这意味着被拒绝贷款、面试或福利的消费者可能永久被排除在获得信贷、就业或援助的机会之外。在这项工作中，我们引入了一种正式的测试程序来检测分配固定预测的模型，我们称之为后续验证。我们开发了一套机制可靠地确定给定模型是否能提供对决策对象的后续手段，这些手段由用户指定的可操作性约束确定。我们演示了我们的工具如何在真实世界的数据集中确保后续措施和对抗鲁棒性，并利用它们研究了在真实世界的贷款数据集中实现后续措施的不可行性。我们的结果凸显了模型如何无意中分配固定预测，从而永久禁止使用者获得相关权益。

    Machine learning models are often used to decide who will receive a loan, a job interview, or a public benefit. Standard techniques to build these models use features about people but overlook their actionability. In turn, models can assign predictions that are fixed, meaning that consumers who are denied loans, interviews, or benefits may be permanently locked out from access to credit, employment, or assistance. In this work, we introduce a formal testing procedure to flag models that assign fixed predictions that we call recourse verification. We develop machinery to reliably determine if a given model can provide recourse to its decision subjects from a set of user-specified actionability constraints. We demonstrate how our tools can ensure recourse and adversarial robustness in real-world datasets and use them to study the infeasibility of recourse in real-world lending datasets. Our results highlight how models can inadvertently assign fixed predictions that permanently bar acces
    
[^3]: 单次贝叶斯近似用于神经网络

    Single-shot Bayesian approximation for neural networks. (arXiv:2308.12785v1 [cs.LG])

    [http://arxiv.org/abs/2308.12785](http://arxiv.org/abs/2308.12785)

    这篇论文提出了一种单次MC dropout近似方法，以将神经网络转换为贝叶斯变体的神经网络，该方法具有与普通神经网络相同的计算速度，同时保留了贝叶斯变体神经网络提供的不确定度测量。

    

    深度神经网络以其高预测性能而闻名。然而，当遇到完全新的情况并且没有指示其不确定性时，神经网络很容易产生不可靠的预测。贝叶斯变体的神经网络（BNNs），如蒙特卡洛（MC）dropout BNNs，在提供不确定度测量的同时提高了预测性能。BNNs唯一的缺点是它们在测试时计算时间较长，因为它们依赖于一种采样方法。在这里，我们提出了一种单次MC dropout近似，它保留了BNNs的优点，同时与神经网络一样快。我们的方法基于矩传播（MP），可以在常用的神经网络层（卷积、最大池化、全连接、softmax和dropout层）中解析地近似MC dropout信号的期望值和方差。MP方法可以在不重新训练的情况下将神经网络转换为BNN，只要NN已经使用标准的dropout进行了训练。我们评估了我们的方法。

    Deep neural networks (NNs) are known for their high-prediction performances. However, NNs are prone to yield unreliable predictions when encountering completely new situations without indicating their uncertainty. Bayesian variants of NNs (BNNs), such as Monte Carlo (MC) dropout BNNs, do provide uncertainty measures and simultaneously increase the prediction performance. The only disadvantage of BNNs is their higher computation time during test time because they rely on a sampling approach. Here we present a single-shot MC dropout approximation that preserves the advantages of BNNs while being as fast as NNs. Our approach is based on moment propagation (MP) and allows to analytically approximate the expected value and the variance of the MC dropout signal for commonly used layers in NNs, i.e. convolution, max pooling, dense, softmax, and dropout layers. The MP approach can convert an NN into a BNN without re-training given the NN has been trained with standard dropout. We evaluate our 
    
[^4]: 关于平均嵌入用于物品推荐的一致性研究

    On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])

    [http://arxiv.org/abs/2308.12767](http://arxiv.org/abs/2308.12767)

    本文研究了推荐系统中平均嵌入的一致性，并提出了一种衡量方法。实证结果表明，现实世界的平均嵌入在推荐中一致性较低，为进一步改进现实世界嵌入提供了方向。

    

    推荐系统中一种流行的做法是将物品嵌入进行平均以在同一嵌入空间中代表用户或更高级的概念。本文研究了这种做法的相关性。为此，我们提出了一种期望精度分数，用于衡量平均嵌入与其构建所使用的物品的一致性。我们随后在具有特定假设的理论环境和来自音乐流媒体服务的真实数据上分析了该分数的数学表达式及其经验表现。我们的结果强调了现实世界的平均值在推荐中的一致性较低，为未来研究更好地将现实世界的嵌入与我们理论环境的假设相一致铺平了道路。

    A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.
    
[^5]: 使用主从深度架构解决具有非线性边际反馈和多样性约束的前K个多臂赌博机问题

    Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints. (arXiv:2308.12680v1 [cs.LG])

    [http://arxiv.org/abs/2308.12680](http://arxiv.org/abs/2308.12680)

    这篇论文提出了一种用于解决具有非线性边际反馈和多样性约束的前K个组合多臂赌博机问题的新型主从架构，通过引入六个从模型和教师学习优化以及策略共训练技术，实现了高效的探索和利用之间的决策权衡。

    

    我们提出了一种新颖的主从架构，用于解决具有非线性边际反馈和多样性约束的前K个组合多臂赌博机问题，据我们所知，这是第一个在赌博反馈下考虑多样性约束的组合臂赌博机设置。具体而言，为了高效地探索组合和受约束的行动空间，我们引入了六个具有显著优点的从模型，以生成平衡奖励和约束以及效率的多样化样本。此外，我们提出了基于教师学习的优化和策略共训练技术，以提升多个从模型的性能。然后，主模型收集从模型提供的精英样本，并通过基于神经上下文UCB网络估计的最佳样本来做出在探索和利用之间权衡的决策。由于从模型的精心设计，共同训练机制成效显著。

    We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback. Specifically, to efficiently explore the combinatorial and constrained action space, we introduce six slave models with distinguished merits to generate diversified samples well balancing rewards and constraints as well as efficiency. Moreover, we propose teacher learning based optimization and the policy co-training technique to boost the performance of the multiple slave models. The master model then collects the elite samples provided by the slave models and selects the best sample estimated by a neural contextual UCB-based network to make a decision with a trade-off between exploration and exploitation. Thanks to the elaborate design of slave models, the co-training mechanism among s
    
[^6]: 测地线模式连通性

    Geodesic Mode Connectivity. (arXiv:2308.12666v1 [cs.LG])

    [http://arxiv.org/abs/2308.12666](http://arxiv.org/abs/2308.12666)

    本文探讨了测地线模式连通性的现象，并提出了一种算法近似测地线，实现了模式连通性。

    

    模式连通性是指训练好的模型之间存在一条低损失路径的现象。我们将这一现象重新解释为信息几何的一部分，其中神经网络被研究为具有曲线几何的参数化分布空间。我们假设这些空间中的最短路径，即测地线，对应于损失景观中的模式连接路径。我们提出了一种近似测地线的算法，并证明其实现了模式连通性。

    Mode connectivity is a phenomenon where trained models are connected by a path of low loss. We reframe this in the context of Information Geometry, where neural networks are studied as spaces of parameterized distributions with curved geometry. We hypothesize that shortest paths in these spaces, known as geodesics, correspond to mode-connecting paths in the loss landscape. We propose an algorithm to approximate geodesics and demonstrate that they achieve mode connectivity.
    
[^7]: 使用HuSpaCy推进匈牙利文本处理：高效准确的自然语言处理管道

    Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines. (arXiv:2308.12635v1 [cs.CL])

    [http://arxiv.org/abs/2308.12635](http://arxiv.org/abs/2308.12635)

    本文介绍了一套工业级匈牙利文本处理模型，利用HuSpaCy框架实现，通过多项改进在资源效率和准确性之间取得了接近最先进的性能。这些模型具备高准确性和吞吐量，并在所有基本文本处理步骤中展示了竞争性能。

    

    本文介绍了一套用于匈牙利文本处理的工业级模型，这些模型在资源效率和准确性之间取得了接近最先进的性能。这些模型是基于spaCy框架实现的，在HuSpaCy工具包的架构上进行了多个改进。与现有的匈牙利语自然语言处理工具相比，我们所有的管道都具备包括标记化、句子边界检测、词性标注、词形特征标注、词形还原、依存句法分析和命名实体识别在内的所有基本文本处理步骤，并且具有高准确性和高吞吐量。我们对提出的改进进行了全面评估，将管道与最先进的工具进行了比较，并在所有文本预处理步骤中展示了新模型的竞争性能。所有实验都可以重现，并且这些管道可以免费使用并采用宽松的许可证。

    This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy. Models have been implemented in the spaCy framework, extending the HuSpaCy toolkit with several improvements to its architecture. Compared to existing NLP tools for Hungarian, all of our pipelines feature all basic text processing steps including tokenization, sentence-boundary detection, part-of-speech tagging, morphological feature tagging, lemmatization, dependency parsing and named entity recognition with high accuracy and throughput. We thoroughly evaluated the proposed enhancements, compared the pipelines with state-of-the-art tools and demonstrated the competitive performance of the new models in all text preprocessing steps. All experiments are reproducible and the pipelines are freely available under a permissive license.
    
[^8]: 一个用于向电信用户提供的贪心方法

    A Greedy Approach for Offering to Telecom Subscribers. (arXiv:2308.12606v1 [stat.ML])

    [http://arxiv.org/abs/2308.12606](http://arxiv.org/abs/2308.12606)

    本论文提出了一个用于解决套餐优化问题的新颖组合算法，该算法针对电信运营商在选择激励套餐和目标用户时面临的困难进行了解决。

    

    客户保留或减少流失是电信运营商面临的一项具有挑战性的任务。其中一个有效的方法是向用户提供一些有吸引力的激励措施或附加服务或金钱，以保持他们的参与并确保他们在运营商的网络中停留更长时间。通常，运营商会分配一定金额的预算来进行推广活动。这项活动的困难之处在于从庞大的订户群体中选择一组客户，并决定应该向个体提供多少金额，以实现运营商的目标。选择订户和选择提供给被选定订户的套餐可能有多个目标（例如，最大化收入，最小化流失数量）。除了金钱利益，套餐还可以包括额外的数据、短信、手机热点共享等等。这个问题被称为套餐优化。在这篇论文中，我们提出了一种新颖的组合算法来解决套餐优化问题。

    Customer retention or churn prevention is a challenging task of a telecom operator. One of the effective approaches is to offer some attractive incentive or additional services or money to the subscribers for keeping them engaged and make sure they stay in the operator's network for longer time. Often, operators allocate certain amount of monetary budget to carry out the offer campaign. The difficult part of this campaign is the selection of a set of customers from a large subscriber-base and deciding the amount that should be offered to an individual so that operator's objective is achieved. There may be multiple objectives (e.g., maximizing revenue, minimizing number of churns) for selection of subscriber and selection of an offer to the selected subscriber. Apart from monetary benefit, offers may include additional data, SMS, hots-spot tethering, and many more. This problem is known as offer optimization. In this paper, we propose a novel combinatorial algorithm for solving offer op
    
[^9]: 利用大型语言和多模态模型进行可解释预测的变分信息追求

    Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions. (arXiv:2308.12562v1 [cs.LG])

    [http://arxiv.org/abs/2308.12562](http://arxiv.org/abs/2308.12562)

    本文提出了一种利用大型语言和多模态模型的变分信息追求(V-IP)框架，通过顺序选择任务相关的可解释查询，实现可解释预测。为了解决数据标注的限制，引入了基础模型(FMs)，使用大型语言模型(LLMs)生成候选可解释概念集，并使用大型多模态模型注释每个数据样本。此方法适用于大规模任务。

    

    变分信息追求(V-IP)是一个通过顺序选择与任务相关、用户定义和可解释的数据查询来设计可解释预测的框架。虽然这使得预测模型具有内置的可解释性，但将V-IP应用于任何任务都需要具有由领域专家进行密集概念标注的数据样本，限制了V-IP在手动数据注释可行的小规模任务中的应用。本文中，我们通过引入基础模型(FMs)来扩展V-IP框架，以解决这个限制。具体而言，我们使用了一个两步流程，首先利用大型语言模型(LLMs)生成足够大的候选任务相关可解释概念集，然后利用大型多模态模型通过与生成的概念集中的每个概念的语义相似性对每个数据样本进行注释。虽然还有其他可解释设计框架，比如Concept Bot，但这些框架不适合处理大规模任务。

    Variational Information Pursuit (V-IP) is a framework for making interpretable predictions by design by sequentially selecting a short chain of task-relevant, user-defined and interpretable queries about the data that are most informative for the task. While this allows for built-in interpretability in predictive models, applying V-IP to any task requires data samples with dense concept-labeling by domain experts, limiting the application of V-IP to small-scale tasks where manual data annotation is feasible. In this work, we extend the V-IP framework with Foundational Models (FMs) to address this limitation. More specifically, we use a two-step process, by first leveraging Large Language Models (LLMs) to generate a sufficiently large candidate set of task-relevant interpretable concepts, then using Large Multimodal Models to annotate each data sample by semantic similarity with each concept in the generated concept set. While other interpretable-by-design frameworks such as Concept Bot
    
[^10]: 不要怪数据集转移！梯度和交叉熵导致了捷径学习

    Don't blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy. (arXiv:2308.12553v1 [cs.LG])

    [http://arxiv.org/abs/2308.12553](http://arxiv.org/abs/2308.12553)

    默认-ERM模型通过最大化间隔来优化训练，导致模型更多依赖于捷径而非稳定特征，这对感知任务来说是不合适的。

    

    常见对于捷径学习的解释认为捷径在训练分布下改善了预测结果，但在测试分布下却没有改善。因此，通过典型的基于梯度的交叉熵优化训练的模型（我们称其为默认-ERM）利用了这个捷径。然而，即使在训练分布中稳定特征决定了标签而捷径并没有提供额外的信息，比如在感知任务中，默认-ERM仍然表现出了捷径学习。为什么这样的解决方案更受青睐，当可以单独使用稳定特征将默认-ERM的损失驱动为零时？通过研究线性感知任务，我们展示了默认-ERM对于最大化间隔的偏好导致了更多依赖于捷径而非稳定特征的模型，即使没有过度参数化。这一发现表明，默认-ERM的隐性归纳偏好即最大间隔对于感知任务是不合适的。相反，我们提出了一种适合感知任务的归纳偏好。

    Common explanations for shortcut learning assume that the shortcut improves prediction under the training distribution but not in the test distribution. Thus, models trained via the typical gradient-based optimization of cross-entropy, which we call default-ERM, utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM still exhibits shortcut learning. Why are such solutions preferred when the loss for default-ERM can be driven to zero using the stable feature alone? By studying a linear perception task, we show that default-ERM's preference for maximizing the margin leads to models that depend more on the shortcut than the stable feature, even without overparameterization. This insight suggests that default-ERM's implicit inductive bias towards max-margin is unsuitable for perception tasks. Instead, we develop an inductive bias toward 
    
[^11]: 一种基于有意遗忘驱动的自愈深度强化学习系统的方法

    An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems. (arXiv:2308.12445v1 [cs.LG])

    [http://arxiv.org/abs/2308.12445](http://arxiv.org/abs/2308.12445)

    本文提出了一种名为 Dr. DRL 的自愈方法，用于解决深度强化学习系统中的一些效率问题，该方法通过在连续学习中引入有意遗忘的机制来应对环境漂移引起的困扰。

    

    深度强化学习 (DRL) 在像 Netflix 和 Facebook 这样的大规模应用中越来越多。和大多数数据驱动系统一样，DRL 系统可能由于环境漂移导致不良行为，而这种漂移经常发生在不断变化的生产环境中。连续学习 (CL) 是自愈方法，用于根据环境条件的变化调整 DRL 代理。然而，大规模的连续变化可能导致生产环境从原始状态偏离。最近的研究表明，这些环境漂移往往导致连续学习进入长时间的自愈周期，甚至无法成功，这是由于灾难性遗忘、温和起始失败和收敛缓慢等效率低下问题引起的。在本文中，我们提出 Dr. DRL，一种对 DRL 系统的有效自愈方法，它将有意遗忘的新颖机制整合到原始的连续学习中以解决其主要问题。Dr. DRL 有意地擦除...

    Deep reinforcement learning (DRL) is increasingly applied in large-scale productions like Netflix and Facebook. As with most data-driven systems, DRL systems can exhibit undesirable behaviors due to environmental drifts, which often occur in constantly-changing production settings. Continual Learning (CL) is the inherent self-healing approach for adapting the DRL agent in response to the environment's conditions shifts. However, successive shifts of considerable magnitude may cause the production environment to drift from its original state. Recent studies have shown that these environmental drifts tend to drive CL into long, or even unsuccessful, healing cycles, which arise from inefficiencies such as catastrophic forgetting, warm-starting failure, and slow convergence. In this paper, we propose Dr. DRL, an effective self-healing approach for DRL systems that integrates a novel mechanism of intentional forgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately erases
    
[^12]: 脂肪碎化、联合可测性和POVM假设类的PAC可学习性

    Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes. (arXiv:2308.12304v1 [stat.ML])

    [http://arxiv.org/abs/2308.12304](http://arxiv.org/abs/2308.12304)

    我们研究了量子测量类的可学习性，并建立了必要和充分条件，同时给出了对应的样本复杂性上界。我们发现标准ERM未满足统一收敛性的问题，于是提出了一种新的学习规则——去噪ERM，该规则在POVM和概率观测的概念类别中具有普适性并满足统一收敛性的条件。

    

    通过建立匹配的必要和充分条件，并给出相应的样本复杂性上界，我们对量子测量类的可学习性进行了刻画，其中学习器仅能接触到已准备好的量子态。我们首先探究了先前作品中关于该设置的结果。我们发现，在一些可学习类别中，先前作品中定义的经验风险与经典理论中的定义相一致，但未能满足统一收敛性质。此外，我们发现，先前作品中对VC维度广义上界的推广常常是无穷的，即使对于有限维的POVM类别也是如此。为了克服标准ERM未能满足统一收敛性的问题，我们提出了一种新的学习规则——去噪ERM。我们证明了对于POVM和概率观测的概念类别，这是一种通用的学习规则，并给出了它满足统一收敛性的条件。

    We characterize learnability for quantum measurement classes by establishing matching necessary and sufficient conditions for their PAC learnability, along with corresponding sample complexity bounds, in the setting where the learner is given access only to prepared quantum states. We first probe the results from previous works on this setting. We show that the empirical risk defined in previous works and matching the definition in the classical theory fails to satisfy the uniform convergence property enjoyed in the classical setting for some learnable classes. Moreover, we show that VC dimension generalization upper bounds in previous work are frequently infinite, even for finite-dimensional POVM classes. To surmount the failure of the standard ERM to satisfy uniform convergence, we define a new learning rule -- denoised ERM. We show this to be a universal learning rule for POVM and probabilistically observed concept classes, and the condition for it to satisfy uniform convergence is 
    
[^13]: 用于计算深度神经网络正则化路径的多目标延续方法

    A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])

    [http://arxiv.org/abs/2308.12044](http://arxiv.org/abs/2308.12044)

    本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。

    

    稀疏性是深度神经网络(DNNs)中非常理想的特征，因为它确保了数值效率，提高了模型的可解释性(由于相关特征的数量较少)和鲁棒性。在基于线性模型的机器学习方法中，众所周知在$\ell^1$范数(即零权重)的最稀疏解和非正则化解之间存在一条连接路径，这条路径被称为正则化路径。最近，通过将经验损失和稀疏性($\ell^1$范数)作为两个冲突的标准，并解决由此产生的多目标优化问题，首次尝试将正则化路径的概念扩展到DNNs。然而，由于$\ell^1$范数的不光滑性和参数数量的高度，从计算的角度来看，这种方法并不是很有效。为了克服这个限制，我们提出了一种算法，可以近似计算整个帕累托曲线

    Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
    
[^14]: 有关在有限预算二臂赌博机中进行最佳臂选择的统一最优算法研究

    On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v1 [stat.ML])

    [http://arxiv.org/abs/2308.12000](http://arxiv.org/abs/2308.12000)

    本文研究了在有限预算的随机二臂赌博机中进行最佳臂选择的问题，并证明不存在比等概率采样算法更好的算法。我们引入了一致稳定算法的概念，并证明任何在所有情况下与等概率采样算法表现一样好的算法必须属于这个类别。这一结果解决了之前的两个未解之谜。

    

    本文研究了在具有伯努利奖励的随机二臂赌博机中，使用有限预算进行最佳臂选择的问题。我们证明令人惊讶的是，不存在一个算法可以在所有情况下与等概率采样算法表现一样好（该算法被称为“均匀采样”算法），并且在至少一个情况下明显优于该算法。简而言之，不存在比均匀采样算法更好的算法。为了证明这一结果，我们引入了“一致”和“稳定”算法的自然类，并且证明了任何算法要在所有情况下与均匀采样算法表现一样好，必须属于这个类别。通过导出满足任何一致且稳定算法的错误率的下界，并证明均匀采样算法与此下界相匹配，我们完成了证明过程。我们的结果解决了\cite{qin2022open}中提出的两个未解之谜。

    We study the problem of best-arm identification with fixed budget in stochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly, there is no algorithm that (i) performs as well as the algorithm sampling each arm equally (this algorithm is referred to as the {\it uniform sampling} algorithm) on all instances, and that (ii) strictly outperforms this algorithm on at least one instance. In short, there is no algorithm better than the uniform sampling algorithm. Towards this result, we introduce the natural class of {\it consistent} and {\it stable} algorithms, and show that any algorithm that performs as well as the uniform sampling algorithm on all instances belongs to this class. The proof is completed by deriving a lower bound on the error rate satisfied by any consistent and stable algorithm, and by showing that the uniform sampling algorithm matches this lower bound. Our results provide a solution to the two open problems presented in \cite{qin2022open}.
    
[^15]: 基于数据驱动的结构不稳定下的形态发生方法

    A Data-Driven Approach to Morphogenesis under Structural Instability. (arXiv:2308.11846v1 [nlin.PS] CROSS LISTED)

    [http://arxiv.org/abs/2308.11846](http://arxiv.org/abs/2308.11846)

    提出了一种基于数据驱动的方法来理解和预测结构不稳定下的形态发生的时空复杂性，通过机器学习框架研究内外部力驱动下的形态发生，并通过构建数字化图书馆识别异常、预测形态发展，为疾病诊断和抗不稳定设计提供了指导。

    

    结构不稳定条件下的形态发生对生命系统和工程结构具有重要意义。本文提出了一种基于数据驱动的方法来理解和预测它们的时空复杂性。基于物理建模的机器学习框架被提出，用于研究内部或外部力驱动下的形态发生。从模拟数据构建了结构模式的数字化图书馆，然后用于识别异常、预测形态发展，并辅助风险评估和预测。通过大脑生长和航空航天结构设计的示例，演示了从全局和局部特征识别关键的分岔特征和预测历史依赖性发展的能力，为疾病诊断/预测和抗不稳定设计提供了指导。

    Morphological development into evolutionary patterns under structural instability is ubiquitous in living systems and often of vital importance for engineering structures. Here we propose a data-driven approach to understand and predict their spatiotemporal complexities. A machine-learning framework is proposed based on the physical modeling of morphogenesis triggered by internal or external forcing. Digital libraries of structural patterns are constructed from the simulation data, which are then used to recognize the abnormalities, predict their development, and assist in risk assessment and prognosis. The capabilities to identify the key bifurcation characteristics and predict the history-dependent development from the global and local features are demonstrated by examples of brain growth and aerospace structural design, which offer guidelines for disease diagnosis/prognosis and instability-tolerant design.
    
[^16]: Wasserstein几何生成器用于条件分布

    Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v1 [stat.ML])

    [http://arxiv.org/abs/2308.10145](http://arxiv.org/abs/2308.10145)

    通过Wasserstein几何生成器学习条件分布，生成给定特定标签的样本。使用最优输运理论提出的方法能学习观察域的条件分布和它们之间的最优输运映射。在人脸图像数据上的实验验证了该方法的有效性。

    

    生成给定特定标签的样本需要估计条件分布。我们推导出条件分布之间Wasserstein距离的可处理的上界，以建立学习条件分布的理论基础。基于这一结果，我们提出了一种新颖的条件生成算法，其中条件分布完全由由统计距离定义的度量空间来表征。我们利用最优输运理论来提出了Wasserstein几何生成器，一种学习Wasserstein几何的新的条件生成器。所提出的方法学习观察域的条件分布和它们之间的最优输运映射。给定两个观察域标签，未观察到的中间域的条件分布位于给定的条件分布之间的Wasserstein几何中。在以光照条件为域标签的人脸图像上的实验证明了所提出方法的有效性。

    Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the \textit{Wasserstein geodesic generator}, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
    
[^17]: 多保真度傅里叶神经算子用于快速建模大规模地质碳储存

    Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v1 [stat.ML])

    [http://arxiv.org/abs/2308.09113](http://arxiv.org/abs/2308.09113)

    多保真度傅里叶神经算子用于解决大规模地质碳储存问题，通过利用经济性更高的多保真度训练数据集，能够以与高保真度模型相当的准确性进行预测。

    

    深度学习的代理模型已广泛应用于地质碳储存（GCS）问题，以加快预测储压和二氧化碳云层移动。然而，由于高计算成本，大规模三维问题的可用训练数据始终有限。因此，我们提出使用多保真度傅里叶神经算子来解决大规模GCS问题，利用更具经济性的多保真度训练数据集。傅里叶神经算子具有良好的网格不变性，简化了不同离散数据集之间的迁移学习过程。我们首先在一个GCS储层模型上进行模型有效性测试，该模型被划分为110,000个网格单元。多保真度模型的预测准确度可与高保真度模型的训练进行比较。

    Deep learning-based surrogate models have been widely applied in geological carbon storage (GCS) problems to accelerate the prediction of reservoir pressure and CO2 plume migration. Large amounts of data from physics-based numerical simulators are required to train a model to accurately predict the complex physical behaviors associated with this process. In practice, the available training data are always limited in large-scale 3D problems due to the high computational cost. Therefore, we propose to use a multi-fidelity Fourier Neural Operator to solve large-scale GCS problems with more affordable multi-fidelity training datasets. The Fourier Neural Operator has a desirable grid-invariant property, which simplifies the transfer learning procedure between datasets with different discretization. We first test the model efficacy on a GCS reservoir model being discretized into 110k grid cells. The multi-fidelity model can predict with accuracy comparable to a high-fidelity model trained wi
    
[^18]: 基于紧核的条件期望估计

    Conditional expectation via compact kernels. (arXiv:2306.10592v1 [stat.ML])

    [http://arxiv.org/abs/2306.10592](http://arxiv.org/abs/2306.10592)

    本文提出了一种基于紧核的算子理论方法来解决条件期望估计问题，在再生核希尔伯特空间中实现，易于实现，且成功应用于实际问题中。

    

    去噪、条件期望和流形学习任务通常可以在寻找两个随机变量积的条件期望的公共环境下表述。本文针对这个更一般的问题，描述了一种算子理论方法来估计条件期望。核积分算子被用作紧致化工具，将估计问题设置为在再生核希尔伯特空间中的线性逆问题。该方程的解被证明对数值逼近是稳定的，从而确保了数据驱动实现的收敛性。总体技术易于实现，还展示了其在一些实际问题中的成功应用。

    The separate tasks of denoising, conditional expectation and manifold learning can often be posed in a common setting of finding the conditional expectations arising from a product of two random variables. This paper focuses on this more general problem and describes an operator theoretic approach to estimating the conditional expectation. Kernel integral operators are used as a compactification tool, to set up the estimation problem as a linear inverse problem in a reproducing kernel Hilbert space. This equation is shown to have solutions that are stable to numerical approximation, thus guaranteeing the convergence of data-driven implementations. The overall technique is easy to implement, and their successful application to some real-world problems are also shown.
    
[^19]: 通过概率生成函数的贝叶斯离散模型精确推理：概率编程方法

    Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach. (arXiv:2305.17058v1 [cs.PL])

    [http://arxiv.org/abs/2305.17058](http://arxiv.org/abs/2305.17058)

    该论文提出一种精确推理离散统计模型的贝叶斯方法，支持离散采样、连续采样、离散观测、仿射函数、（随机）分支和事件条件。通过概率生成函数实现后验概率、期望、方差和高阶矩的精确计算。该方法性能优于近似蒙特卡洛方法，并避免了近似误差。

    

    我们提出了一种离散统计模型的精确贝叶斯推理方法，即使是对于无限支持和连续先验也可以找到准确的解决方案。为了表达这样的模型，我们引入了一种支持离散和连续采样、离散观测、仿射函数、（随机）分支和事件条件的概率编程语言。我们的关键工具是概率生成函数：它们提供了定义程序的分布的紧凑闭合形式表示，从而实现了后验概率、期望、方差和高阶矩的精确计算。我们的推理方法是可证明正确的、完全自动化的，使用自动微分（特别是泰勒多项式），但不需要计算机代数。我们的实验表明，它在一系列真实世界的例子中的性能与近似蒙特卡洛方法竞争，同时避免了近似误差。

    We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to many discrete inference problems, even with infinite support and continuous priors. To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on events. Our key tool is probability generating functions: they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments. Our inference method is provably correct, fully automated and uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra. Our experiments show that its performance on a range of real-world examples is competitive with approximate Monte Carlo methods, while avoiding approximation errors
    
[^20]: 改进多次尝试Metropolis算法，使用局部平衡策略

    Improving multiple-try Metropolis with local balancing. (arXiv:2211.11613v2 [stat.CO] UPDATED)

    [http://arxiv.org/abs/2211.11613](http://arxiv.org/abs/2211.11613)

    这篇论文提出了一种改进的多次尝试Metropolis算法，通过使用局部平衡策略的权重函数，解决了在高维情况下收敛阶段出现的异常行为问题。

    

    多次尝试Metropolis（MTM）是一种流行的Markov链蒙特卡洛方法，具有可并行计算的吸引力特征。在每次迭代中，它会对马尔科夫链的下一个状态进行多个候选样本，并根据权重函数随机选择一个。经过理论和实证分析，我们发现在高维情况下，特别是在收敛阶段，该权重函数会导致异常行为。我们建议使用类似于Zanella（2020）的局部平衡提议分布的权重函数，从而得到不会出现这些异常行为的MTM算法。为了理论分析这些算法，我们研究了可以视为每次迭代采样无限数目候选样本的理想方案的高维性能，以及这些方案与MTM算法之间的差异。

    Multiple-try Metropolis (MTM) is a popular Markov chain Monte Carlo method with the appealing feature of being amenable to parallel computing. At each iteration, it samples several candidates for the next state of the Markov chain and randomly selects one of them based on a weight function. The canonical weight function is proportional to the target density. We show both theoretically and empirically that this weight function induces pathological behaviours in high dimensions, especially during the convergence phase. We propose to instead use weight functions akin to the locally-balanced proposal distributions of Zanella (2020), thus yielding MTM algorithms that do not exhibit those pathological behaviours. To theoretically analyse these algorithms, we study the high-dimensional performance of ideal schemes that can be thought of as MTM algorithms which sample an infinite number of candidates at each iteration, as well as the discrepancy between such schemes and the MTM algorithms whic
    
[^21]: 确切的流形高斯变分贝叶斯

    Exact Manifold Gaussian Variational Bayes. (arXiv:2210.14598v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.14598](http://arxiv.org/abs/2210.14598)

    我们提出了一种在复杂模型中进行变分推断的优化算法，通过使用自然梯度更新和黎曼流形，我们开发了一种高效的高斯变分推断算法，并验证了其在多个数据集上的性能。

    

    我们提出了一种用于复杂模型中变分推断（VI）的优化算法。我们的方法依赖于自然梯度更新，其中变分空间是一个黎曼流形。我们开发了一个高效的高斯变分推断算法，以隐式满足变分协方差矩阵的正定约束。我们的确切流形高斯变分贝叶斯（EMGVB）提供了精确但简单的更新规则，并且易于实现。由于其黑盒性质，EMGVB成为复杂模型中即插即用的解决方案。通过在不同统计、计量和深度学习模型上使用五个数据集，我们对我们的可行性方法进行了实证验证，并与基准方法进行了性能讨论。

    We propose an optimization algorithm for Variational Inference (VI) in complex models. Our approach relies on natural gradient updates where the variational space is a Riemann manifold. We develop an efficient algorithm for Gaussian Variational Inference that implicitly satisfies the positive definite constraint on the variational covariance matrix. Our Exact manifold Gaussian Variational Bayes (EMGVB) provides exact but simple update rules and is straightforward to implement. Due to its black-box nature, EMGVB stands as a ready-to-use solution for VI in complex models. Over five datasets, we empirically validate our feasible approach on different statistical, econometric, and deep learning models, discussing its performance with respect to baseline methods.
    
[^22]: 用高斯机器隐私实现个体隐私核算

    Individual Privacy Accounting with Gaussian Differential Privacy. (arXiv:2209.15596v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2209.15596](http://arxiv.org/abs/2209.15596)

    本论文介绍了用于个体隐私核算的高斯差分隐私方法，通过对自适应组合随机机制进行仔细分析，为高斯机制提供了最优边界。

    

    个体隐私核算能够为参与分析的每个参与者个别地限制差分隐私损失。这通常是有意义的，因为个体隐私损失往往比考虑每次数据访问的最坏情况边界所示的差分隐私边界要小得多。为了以有原则的方式核算个体隐私损失，我们需要一种针对自适应组合随机机制的隐私核算方法，其中在给定的数据访问中所产生的损失允许比最坏情况损失要小。费尔德曼和兹尔尼克（2021）已对Rényi差分隐私（RDP）进行了这种分析，但尚未应用于所谓的最优隐私核算方法。我们通过使用高斯差分隐私进行仔细分析，为此方向迈出了第一步，高斯差分隐私为最多功能的差分隐私机制之一提供了最优边界。这种方法基于...

    Individual privacy accounting enables bounding differential privacy (DP) loss individually for each participant involved in the analysis. This can be informative as often the individual privacy losses are considerably smaller than those indicated by the DP bounds that are based on considering worst-case bounds at each data access. In order to account for the individual privacy losses in a principled manner, we need a privacy accountant for adaptive compositions of randomised mechanisms, where the loss incurred at a given data access is allowed to be smaller than the worst-case loss. This kind of analysis has been carried out for the R\'enyi differential privacy (RDP) by Feldman and Zrnic (2021), however not yet for the so-called optimal privacy accountants. We make first steps in this direction by providing a careful analysis using the Gaussian differential privacy which gives optimal bounds for the Gaussian mechanism, one of the most versatile DP mechanisms. This approach is based on 
    
[^23]: 在统计自适应中，内部神经元加速了递归神经网络的学习动态

    Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation. (arXiv:2209.10634v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2209.10634](http://arxiv.org/abs/2209.10634)

    这项工作探索了通过内部神经元介导递归通信与直接递归连接相比的计算优势，通过分析连续突触动态和数值模拟，表明具有内部神经元的网络比具有直接递归连接的网络更能抵抗初始化的干扰。

    

    大脑中的早期感知系统快速适应波动的输入统计，这需要神经元之间的递归通信。在这项工作中，我们探索了通过内部神经元介导递归通信与直接递归连接相比的计算优势。为此，我们考虑了两种数学可追踪的递归线性神经网络，它们对输入进行统计白化——一种具有直接递归连接，另一种具有介导递归通信的内部神经元。通过分析相应的连续突触动态并对网络进行数值模拟，我们表明具有内部神经元的网络比具有直接递归连接的网络更能抵抗初始化的干扰，即内部神经元网络的突触动态的收敛时间（或者直接递归连接的网络）呈对数尺度。

    Early sensory systems in the brain rapidly adapt to fluctuating input statistics, which requires recurrent communication between neurons. Mechanistically, such recurrent communication is often indirect and mediated by local interneurons. In this work, we explore the computational benefits of mediating recurrent communication via interneurons compared with direct recurrent connections. To this end, we consider two mathematically tractable recurrent linear neural networks that statistically whiten their inputs -- one with direct recurrent connections and the other with interneurons that mediate recurrent communication. By analyzing the corresponding continuous synaptic dynamics and numerically simulating the networks, we show that the network with interneurons is more robust to initialization than the network with direct recurrent connections in the sense that the convergence time for the synaptic dynamics in the network with interneurons (resp. direct recurrent connections) scales logar
    
[^24]: 将梯度统一化以提高深度网络的真实世界鲁棒性

    Unifying Gradients to Improve Real-world Robustness for Deep Networks. (arXiv:2208.06228v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.06228](http://arxiv.org/abs/2208.06228)

    通过统一不同数据的梯度来防御基于评分的查询攻击（SQAs），这样SQAs只能探测到一个更弱的攻击方向，保护真实世界的深度神经网络。

    

    深度神经网络（DNN）的广泛应用对它们的真实世界鲁棒性提出了更多关注，即DNN是否能够抵抗黑盒对抗攻击，其中基于评分的查询攻击（SQAs）最具威胁性，因为它们只能通过访问模型输出有效地攻击受害网络。抵御SQAs需要对输出进行轻微但巧妙的变化，因为用户与SQAs共享相同的输出信息。在本文中，我们提出了一种通过统一不同数据的梯度来进行真实世界防御的方法，使得SQAs只能探测到一个更弱的攻击方向，这个攻击方向对于不同样本是相似的。由于这种统一的攻击扰动被验证为比输入特定的扰动更不具侵略性，UniG通过指示攻击者一个扭曲且信息较少的攻击方向来保护真实世界的DNN。我们通过一个可插拔的Hadamard乘积模块高效实现了UniG。

    The wide application of deep neural networks (DNNs) demands an increasing amount of attention to their real-world robustness, i.e., whether a DNN resists black-box adversarial attacks, among which score-based query attacks (SQAs) are most threatening since they can effectively hurt a victim network with the only access to model outputs. Defending against SQAs requires a slight but artful variation of outputs due to the service purpose for users, who share the same output information with SQAs. In this paper, we propose a real-world defense by Unifying Gradients (UniG) of different data so that SQAs could only probe a much weaker attack direction that is similar for different samples. Since such universal attack perturbations have been validated as less aggressive than the input-specific perturbations, UniG protects real-world DNNs by indicating attackers a twisted and less informative attack direction. We implement UniG efficiently by a Hadamard product module which is plug-and-play. A
    
[^25]: 在线性模型下基于人口平等约束的最小最大优化回归研究

    Demographic Parity Constrained Minimax Optimal Regression under Linear Model. (arXiv:2206.11546v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2206.11546](http://arxiv.org/abs/2206.11546)

    本研究探讨了在线性模型下基于人口平等约束的回归问题的最小最大优化误差，并提出了一个包含更广泛歧视偏差来源的模型。我们发现，在这个模型中，最小最大优化误差与样本大小、维数和人口群组数量存在关系，并且误差会随着模型中偏差的增加而增加。

    

    我们研究了在线性模型下基于人口平等约束的回归问题的最小最大优化误差。相较于Chzhen和Schreuder（2022）提出的模型，我们提出的模型涵盖了更广泛的歧视偏差来源。我们的分析表明，在我们的模型下，人口平等约束回归问题的最小最大优化误差由$\Theta(\frac{dM}{n})$所描述，其中$n$表示样本大小，$d$表示维数，$M$表示由敏感属性引起的人口群组数量。此外，我们证明了误差的最小最大值与模型中较大的偏差呈正相关。

    We explore the minimax optimal error associated with a demographic parity-constrained regression problem within the context of a linear model. Our proposed model encompasses a broader range of discriminatory bias sources compared to the model presented by Chzhen and Schreuder (2022). Our analysis reveals that the minimax optimal error for the demographic parity-constrained regression problem under our model is characterized by $\Theta(\frac{dM}{n})$, where $n$ denotes the sample size, $d$ represents the dimensionality, and $M$ signifies the number of demographic groups arising from sensitive attributes. Moreover, we demonstrate that the minimax error increases in conjunction with a larger bias present in the model.
    
[^26]: StableDR:稳定的双重稳健学习方法用于数据缺失非随机的推荐系统

    StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random. (arXiv:2205.04701v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.04701](http://arxiv.org/abs/2205.04701)

    StableDR是一种稳定的双重稳健学习方法，用于解决推荐系统中数据缺失非随机的问题。通过减少对外推的依赖，StableDR能够同时具有有界的偏差、方差和泛化误差界，在不准确的估计误差和任意小的倾向性下表现出优越性能。

    

    在推荐系统中，用户倾向于选择自己喜欢的物品进行评价，这导致了数据缺失非随机的问题，在对预测模型进行无偏评估和学习时带来了很大挑战。目前，双重稳健（DR）方法已经得到广泛研究，并展示出优越的性能。然而，在本文中，我们展示了DR方法的不稳定性以及对极小的倾向性具有无界偏差、方差和泛化界限的问题。此外，DR更多地依赖外推，这会导致次优的性能。为了解决以上问题，我们提出了一种稳定的双重稳健（StableDR）学习方法，对外推的依赖较弱。理论分析表明，在不准确的估计误差和任意小的倾向性下，StableDR同时具有有界的偏差、方差和泛化误差界。此外，我们还提出了一种针对StableDR的新型学习方法来更新估计值。

    In recommender systems, users always choose the favorite items to rate, which leads to data missing not at random and poses a great challenge for unbiased evaluation and learning of prediction models. Currently, the doubly robust (DR) methods have been widely studied and demonstrate superior performance. However, in this paper, we show that DR methods are unstable and have unbounded bias, variance, and generalization bounds to extremely small propensities. Moreover, the fact that DR relies more on extrapolation will lead to suboptimal performance. To address the above limitations while retaining double robustness, we propose a stabilized doubly robust (StableDR) learning approach with a weaker reliance on extrapolation. Theoretical analysis shows that StableDR has bounded bias, variance, and generalization error bound simultaneously under inaccurate imputed errors and arbitrarily small propensities. In addition, we propose a novel learning approach for StableDR that updates the imputat
    
[^27]: 流形上的Riemannian Hamiltonian方法用于min-max优化问题

    Riemannian Hamiltonian methods for min-max optimization on manifolds. (arXiv:2204.11418v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2204.11418](http://arxiv.org/abs/2204.11418)

    本文研究了流形上的min-max优化问题，并引入了Riemannian Hamiltonian方法作为其代理方法。通过最小化Hamiltonian函数，可以得到所需的min-max鞍点。该方法在geodesic-bilinear优化问题中具有挑战性，但通过解决代理问题可以得到全局最优搜索方向。该方法在多个应用中展示了其有效性。

    

    本文研究了流形上的min-max优化问题。我们引入了一个Riemannian Hamiltonian函数，其最小化作为解决原始min-max问题的代理。在Riemannian Polyak-{\L}ojasiewicz条件下，其最小值对应于所需的min-max鞍点。我们还提供了满足此条件的情况。特别是对于geodesic-bilinear优化，在解决代理问题的情况下，可以得到正确的全局最优搜索方向，而在min-max形式化中变得具有挑战性。为了最小化Hamiltonian函数，我们提出了Riemannian Hamiltonian方法（RHM）并提出了它们的收敛性分析。我们将RHM扩展到包括共识正则化和随机设置。我们通过应用如子空间鲁棒Wasserstein距离、神经网络的鲁棒训练和生成对抗网络等来说明所提出的RHM的有效性。

    In this paper, we study min-max optimization problems on Riemannian manifolds. We introduce a Riemannian Hamiltonian function, minimization of which serves as a proxy for solving the original min-max problems. Under the Riemannian Polyak--{\L}ojasiewicz condition on the Hamiltonian function, its minimizer corresponds to the desired min-max saddle point. We also provide cases where this condition is satisfied. For geodesic-bilinear optimization in particular, solving the proxy problem leads to the correct search direction towards global optimality, which becomes challenging with the min-max formulation. To minimize the Hamiltonian function, we propose Riemannian Hamiltonian methods (RHM) and present their convergence analyses. We extend RHM to include consensus regularization and to the stochastic setting. We illustrate the efficacy of the proposed RHM in applications such as subspace robust Wasserstein distance, robust training of neural networks, and generative adversarial networks.
    
[^28]: UCB Bandits在对抗攻击中的近乎最优攻击策略

    Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2008.09312](http://arxiv.org/abs/2008.09312)

    本文提出了一种在对抗攻击下的UCB最优拉臂策略，成本为$\sqrt{\log T}$，并且证明了此攻击策略近乎是最优的。

    

    本文考虑了一种随机多臂赌博问题，其中奖励受到对抗性破坏。我们提出了一种新颖的攻击策略，通过操作UCB原则来拉动一些非最优目标臂$T-o(T)$次，累积成本的标度为$\sqrt{\log T}$，其中$T$为回合数。我们还证明了累积攻击成本的第一个下界。我们的下界与我们的上界匹配，除了$\log\log T$因子，表明我们的攻击策略近乎是最优的。

    We consider a stochastic multi-arm bandit problem where rewards are subject to adversarial corruption. We propose a novel attack strategy that manipulates a UCB principle into pulling some non-optimal target arm $T - o(T)$ times with a cumulative cost that scales as $\sqrt{\log T}$, where $T$ is the number of rounds. We also prove the first lower bound on the cumulative attack cost. Our lower bound matches our upper bound up to $\log \log T$ factors, showing our attack to be near optimal.
    

