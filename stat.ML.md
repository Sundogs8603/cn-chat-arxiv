# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The ASNR-MICCAI Brain Tumor Segmentation (BraTS) Challenge 2023: Intracranial Meningioma.](http://arxiv.org/abs/2305.07642) | ASNR-MICCAI脑肿瘤分割挑战2023将提供一个适用于自动诊断颅内脑膜瘤的最先进自动化颅内脑膜瘤分割模型的基准。 |
| [^2] | [On the Partial Convexification for Low-Rank Spectral Optimization: Rank Bounds and Algorithms.](http://arxiv.org/abs/2305.07638) | 研究低秩谱最优化问题的部分凸化的实力，提出了派生任何极端点的秩界，并证明了对于不同矩阵空间的域集合的紧致性，同时开发了一个包含矢量凸定价神谕的列生成算法以有效解决此问题。 |
| [^3] | [Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn.](http://arxiv.org/abs/2305.07625) | Meta Omnium提供了一个数据集，包含多个视觉任务，使得学术界可以评估模型对于多项任务的泛化能力。它同时提供了一个一致的框架，来评估元学习者。 |
| [^4] | [Scalable Coupling of Deep Learning with Logical Reasoning.](http://arxiv.org/abs/2305.07617) | 本文介绍了一种可扩展的神经网络模型和损失函数，能够有效学习如何解决NP-hard推理问题，并在离散图模型上进行了实验验证。同时可以提高数据效率和可解释性，并具有对预测的控制能力。 |
| [^5] | [Spider GAN: Leveraging Friendly Neighbors to Accelerate GAN Training.](http://arxiv.org/abs/2305.07613) | 本文提出了一种名为Spider GAN的新方法，通过寻找数据集之间的友好邻居来提高GAN的训练效率，加速收敛，即使是不相关的数据集之间也可以发现对应关系。 |
| [^6] | [Fisher Information Embedding for Node and Graph Learning.](http://arxiv.org/abs/2305.07580) | 本文提出了一种新的基于注意力机制的图节点嵌入框架，可以更好地理解基于注意力机制的GNN。 |
| [^7] | [Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts.](http://arxiv.org/abs/2305.07572) | 本文提出新颖的Voronoi Loss函数来解决高斯门控混合专家模型参数估计的收敛速率问题，并在两种不同的门控网络下提供理论收敛速率的证明。 |
| [^8] | [Expertise-based Weighting for Regression Models with Noisy Labels.](http://arxiv.org/abs/2305.07430) | 本文提出了基于专家评估的加权回归模型，可用于处理具有不同观点的嘈杂标签。该方法包括两个步骤：估计每个专家的专业程度和结合他们的意见，然后将加权平均用于回归建模。本方法在模拟和真实数据上优于现有技术，具有简单、快速和有效的特点。 |
| [^9] | [Distributed Gradient Descent for Functional Learning.](http://arxiv.org/abs/2305.07408) | 该论文提出了一种针对函数数据的分布式梯度下降函数学习算法，在再生核希尔伯特空间框架下通过积分算子方法得到了该算法的理论理解，并取得了不饱和边界的置信度最优学习率。 |
| [^10] | [Locking and Quacking: Stacking Bayesian model predictions by log-pooling and superposition.](http://arxiv.org/abs/2305.07334) | 本文提出了两种新的贝叶斯模型组合工具，可以通过对数池化和超叠加来组合后验密度，避免了标准化常数的负担，并在预测准确性方面优于传统方法。 |
| [^11] | [HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting.](http://arxiv.org/abs/2305.07089) | HINT是一种用于概率预测的新型模型族，能够有效、准确地进行一致性预测，通过引入Bootstrap方法并为网络加入规范化特征提取和输出规范化来保证其性能，在多个数据集上的预测精度比现有技术更高。 |
| [^12] | [Random Smoothing Regularization in Kernel Gradient Descent Learning.](http://arxiv.org/abs/2305.03531) | 本文提出了一种随机平滑正则化的框架，能够自适应地、有效地学习属于经典Sobolev空间范围内的各种真实函数，通过引入噪声避免过拟合，该方法可以在较快的速度下实现最优收敛率。 |
| [^13] | [Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks.](http://arxiv.org/abs/2302.07260) | 本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。 |
| [^14] | [Robust and Scalable Bayesian Online Changepoint Detection.](http://arxiv.org/abs/2302.04759) | 该论文提出了一种在线变点检测方法，具有坚固和可扩展性，通过利用广义贝叶斯视角提供了可证明的坚固性，并通过扩散得分匹配解决了可扩展性问题。所得算法是精确的，更新简单，速度较之前的算法快10倍以上。 |
| [^15] | [Sparse Bayesian Lasso via a Variable-Coefficient $\ell_1$ Penalty.](http://arxiv.org/abs/2211.05089) | 本文提出一种解决高度稀疏性的统计学习算法，即变系数$\ell_1$惩罚的稀疏贝叶斯Lasso，并通过定义可学习的惩罚权重$\lambda_p$及超先验知识来达到目的。 |
| [^16] | [A Nonparametric Approach with Marginals for Modeling Consumer Choice.](http://arxiv.org/abs/2208.06115) | 本文提出了一种基于边缘分布的简单而有效的非参数消费者选择建模方法，在任何选择集合中会把选择概率的集合一致地描述出来。 |
| [^17] | [Hierarchical Bayesian Modelling for Knowledge Transfer Across Engineering Fleets via Multitask Learning.](http://arxiv.org/abs/2204.12404) | 本文提出了一种分层贝叶斯建模方法，利用操作机群中的领域专业知识，在不同的子群之间自动地共享信息。该方法成功地解决了卡车机群的生存分析和风电场的功率预测问题。 |
| [^18] | [Transformers in Time Series: A Survey.](http://arxiv.org/abs/2202.07125) | 本文针对Transformer在时间序列建模中的应用进行了系统回顾，总结了其优点及局限性，从网络结构和应用两个角度审视了其适应和改进。 |
| [^19] | [Parameter identifiability of a deep feedforward ReLU neural network.](http://arxiv.org/abs/2112.12982) | 本文研究了一类深度前馈ReLU神经网络的参数可辨识性，给出了一组刻画条件并证明了在这些条件下，可以唯一确定网络的参数。 |
| [^20] | [Linear Classifiers Under Infinite Imbalance.](http://arxiv.org/abs/2106.05797) | 研究了在无限不平衡情况下的线性分类器，通过权重函数指定的经验损失最小化系数。截距发散但其余系数向量有一个有限的几乎肯定的极限，极限依赖于权重函数的左尾增长速率。极限系数向量反映稳健性或保守性属性，而在亚指数情况下，极限等价于少数类的上采样分布的隐式选择。 |
| [^21] | [Aleatoric uncertainty for Errors-in-Variables models in deep regression.](http://arxiv.org/abs/2105.09095) | 本文提出了一种基于贝叶斯深度回归的方法，利用变量误差模型考虑所使用神经网络的输入所关联的不确定性，并将预测不确定性分解为随机和认识部分。相比于不使用该模型，使用错误变量模型能够提高对已知回归函数的覆盖率，且保持预测性能。 |
| [^22] | [The Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information.](http://arxiv.org/abs/2102.10019) | 本文证明了不确定性对不同人群的影响是不平等的，虽然它会在所有人口群体中产生误差，但误差的类型会有系统性的变化。我们提出了一种名为平权信息的策略，可以消除这种差异并扩大机会的获取，这可以作为平权行动的替代方案。 |

# 详细

[^1]: ASNR-MICCAI脑肿瘤分割挑战2023：颅内脑膜瘤

    The ASNR-MICCAI Brain Tumor Segmentation (BraTS) Challenge 2023: Intracranial Meningioma. (arXiv:2305.07642v1 [cs.CV])

    [http://arxiv.org/abs/2305.07642](http://arxiv.org/abs/2305.07642)

    ASNR-MICCAI脑肿瘤分割挑战2023将提供一个适用于自动诊断颅内脑膜瘤的最先进自动化颅内脑膜瘤分割模型的基准。

    

    脑膜瘤是成人颅内最常见的原发性肿瘤，可能与重大的发病率和死亡率有关。放射科医生、神经外科医生、神经肿瘤学家和放射肿瘤科医生依靠多参数MRI（mpMRI）进行诊断、治疗规划和长期治疗监测；然而，缺乏自动化、客观化和定量化的工具来对mpMRI中的脑膜瘤进行非侵入性评估。BraTS脑膜瘤2023挑战将提供一个社区标准和基于迄今为止最大的专家注释的多标签脑膜瘤mpMRI数据集的最先进自动化颅内脑膜瘤分割模型的基准。挑战参赛者将开发自动化分割模型，预测MRI上的三个不同的脑膜瘤亚区域，包括增强肿瘤、非增强肿瘤核心和周围无增强T2/FLAIR高信号区。模型将使用标准化指标在单独的验证和保留测试数据集上进行评估。

    Meningiomas are the most common primary intracranial tumor in adults and can be associated with significant morbidity and mortality. Radiologists, neurosurgeons, neuro-oncologists, and radiation oncologists rely on multiparametric MRI (mpMRI) for diagnosis, treatment planning, and longitudinal treatment monitoring; yet automated, objective, and quantitative tools for non-invasive assessment of meningiomas on mpMRI are lacking. The BraTS meningioma 2023 challenge will provide a community standard and benchmark for state-of-the-art automated intracranial meningioma segmentation models based on the largest expert annotated multilabel meningioma mpMRI dataset to date. Challenge competitors will develop automated segmentation models to predict three distinct meningioma sub-regions on MRI including enhancing tumor, non-enhancing tumor core, and surrounding nonenhancing T2/FLAIR hyperintensity. Models will be evaluated on separate validation and held-out test datasets using standardized metri
    
[^2]: 关于低秩谱最优化的部分凸化：秩界与算法

    On the Partial Convexification for Low-Rank Spectral Optimization: Rank Bounds and Algorithms. (arXiv:2305.07638v1 [math.OC])

    [http://arxiv.org/abs/2305.07638](http://arxiv.org/abs/2305.07638)

    研究低秩谱最优化问题的部分凸化的实力，提出了派生任何极端点的秩界，并证明了对于不同矩阵空间的域集合的紧致性，同时开发了一个包含矢量凸定价神谕的列生成算法以有效解决此问题。

    

    低秩谱最优化问题（LSOP）的目标是在低秩和谱约束的可行域内，最小化一个线性目标，满足多个双面线性矩阵不等式的交集。虽然解决LSOP在一般情况下是NP难的，但它的部分凸化（即用凸壳代替域集合），称为“LSOP-R”，通常是可处理的并产生高质量的解。这激励我们研究LSOP-R的实力。具体而言，我们为LSOP-R可行集的任何极端点派生秩界，并证明对于不同矩阵空间的域集合，它们的紧致性。所提出的秩界从新的角度恢复了文献中的两个众所周知的结果，并允许我们导出当松弛LSOP-R等价于原始LSOP的充分条件。为了有效地解决LSOP-R，我们开发了一个包含矢量凸定价神谕的列生成算法，配合一个秩降算法，它确保输出一个LSOP-R的准确解。

    A Low-rank Spectral Optimization Problem (LSOP) minimizes a linear objective subject to multiple two-sided linear matrix inequalities intersected with a low-rank and spectral constrained domain set. Although solving LSOP is, in general, NP-hard, its partial convexification (i.e., replacing the domain set by its convex hull) termed "LSOP-R," is often tractable and yields a high-quality solution. This motivates us to study the strength of LSOP-R. Specifically, we derive rank bounds for any extreme point of the feasible set of LSOP-R and prove their tightness for the domain sets with different matrix spaces. The proposed rank bounds recover two well-known results in the literature from a fresh angle and also allow us to derive sufficient conditions under which the relaxation LSOP-R is equivalent to the original LSOP. To effectively solve LSOP-R, we develop a column generation algorithm with a vector-based convex pricing oracle, coupled with a rank-reduction algorithm, which ensures the ou
    
[^3]: Meta Omnium: 一项通用学习-学习基准测试

    Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn. (arXiv:2305.07625v1 [cs.CV])

    [http://arxiv.org/abs/2305.07625](http://arxiv.org/abs/2305.07625)

    Meta Omnium提供了一个数据集，包含多个视觉任务，使得学术界可以评估模型对于多项任务的泛化能力。它同时提供了一个一致的框架，来评估元学习者。

    

    元学习以及其他少样本学习方法已广泛应用于图像识别，同时也越来越应用于其他视觉任务，如姿态估计和密集预测。这自然引出了一个问题：是否存在一种少样本元学习算法，能够泛化到这些多样化的任务类型之间？为了帮助学术界回答这个问题，我们引入了Meta Omnium这个数据集，它涵盖了多个视觉任务，包括识别、关键点定位、语义分割和回归。我们试验了受欢迎的少样本元学习基线，并分析了它们泛化到不同任务类型的能力以及在它们之间传递知识的能力。Meta Omnium使得学术界能够评估模型对于多项任务的泛化能力，这比以前更加广泛，同时它提供了一个在不同视觉应用中以一致的方式评估元学习者的框架。

    Meta-learning and other approaches to few-shot learning are widely studied for image recognition, and are increasingly applied to other vision tasks such as pose estimation and dense prediction. This naturally raises the question of whether there is any few-shot meta-learning algorithm capable of generalizing across these diverse task types? To support the community in answering this question, we introduce Meta Omnium, a dataset-of-datasets spanning multiple vision tasks including recognition, keypoint localization, semantic segmentation and regression. We experiment with popular few-shot meta-learning baselines and analyze their ability to generalize across tasks and to transfer knowledge between them. Meta Omnium enables meta-learning researchers to evaluate model generalization to a much wider array of tasks than previously possible, and provides a single framework for evaluating meta-learners across a wide suite of vision applications in a consistent manner.
    
[^4]: 深度学习与逻辑推理的可扩展耦合

    Scalable Coupling of Deep Learning with Logical Reasoning. (arXiv:2305.07617v1 [cs.AI])

    [http://arxiv.org/abs/2305.07617](http://arxiv.org/abs/2305.07617)

    本文介绍了一种可扩展的神经网络模型和损失函数，能够有效学习如何解决NP-hard推理问题，并在离散图模型上进行了实验验证。同时可以提高数据效率和可解释性，并具有对预测的控制能力。

    

    在将离散推理与神经网络混合的不断探索中，出现了越来越多的对神经结构具备从自然输入中学习如何解决离散推理或优化问题的兴趣。本文提出了一种可扩展的神经结构以及专门用于学习被表示为离散图模型的 NP-hard 推理问题的约束和标准的损失函数。我们的损失函数解决了 Besag 的伪对数似然的主要限制之一，能够学习高能量函数。我们通过实验证明，它能够有效地从自然输入中学习如何解决 NP-hard 推理问题，如符号、视觉或多解数数独问题，以及蛋白质设计问题的能量优化形式，提高了数据效率、可解释性以及对预测的 \textit{a posteriori} 控制。

    In the ongoing quest for hybridizing discrete reasoning with neural nets, there is an increasing interest in neural architectures that can learn how to solve discrete reasoning or optimization problems from natural inputs. In this paper, we introduce a scalable neural architecture and loss function dedicated to learning the constraints and criteria of NP-hard reasoning problems expressed as discrete Graphical Models. Our loss function solves one of the main limitations of Besag's pseudo-loglikelihood, enabling learning of high energies. We empirically show it is able to efficiently learn how to solve NP-hard reasoning problems from natural inputs as the symbolic, visual or many-solutions Sudoku problems as well as the energy optimization formulation of the protein design problem, providing data efficiency, interpretability, and \textit{a posteriori} control over predictions.
    
[^5]: Spider GAN:利用友好邻居加速GAN训练

    Spider GAN: Leveraging Friendly Neighbors to Accelerate GAN Training. (arXiv:2305.07613v1 [cs.CV])

    [http://arxiv.org/abs/2305.07613](http://arxiv.org/abs/2305.07613)

    本文提出了一种名为Spider GAN的新方法，通过寻找数据集之间的友好邻居来提高GAN的训练效率，加速收敛，即使是不相关的数据集之间也可以发现对应关系。

    

    GAN的训练是个有挑战性的任务，本文提出了Spider GAN方法，该方法利用图像结构的特点优化生成器的转换，通过定义一种新的度量方式，即有符号启动距离（SID），使其更高效地寻找友好邻居，结果导致更快的收敛，即使在看似不相关的数据集之间也可以找到对应关系。

    Training Generative adversarial networks (GANs) stably is a challenging task. The generator in GANs transform noise vectors, typically Gaussian distributed, into realistic data such as images. In this paper, we propose a novel approach for training GANs with images as inputs, but without enforcing any pairwise constraints. The intuition is that images are more structured than noise, which the generator can leverage to learn a more robust transformation. The process can be made efficient by identifying closely related datasets, or a ``friendly neighborhood'' of the target distribution, inspiring the moniker, Spider GAN. To define friendly neighborhoods leveraging proximity between datasets, we propose a new measure called the signed inception distance (SID), inspired by the polyharmonic kernel. We show that the Spider GAN formulation results in faster convergence, as the generator can discover correspondence even between seemingly unrelated datasets, for instance, between Tiny-ImageNet 
    
[^6]: 基于Fisher信息嵌入的节点和图学习

    Fisher Information Embedding for Node and Graph Learning. (arXiv:2305.07580v1 [stat.ML])

    [http://arxiv.org/abs/2305.07580](http://arxiv.org/abs/2305.07580)

    本文提出了一种新的基于注意力机制的图节点嵌入框架，可以更好地理解基于注意力机制的GNN。

    

    基于注意力机制的图神经网络（GNN），例如图注意力网络（GAT），已成为处理图结构数据和学习节点嵌入的流行神经网络结构。尽管这些模型在经验上取得了成功，但它们依赖于标注数据，且这些模型的理论属性尚未完全理解。本文提出了一种新颖的基于注意力机制的图节点嵌入框架。我们的框架建立在一种多重集合内节点周围子图的分层核之上（例如，邻域），并且每个核利用平滑统计流形的几何来比较多重集合的成对差异，通过将多重集合“映射”到流形上。通过显式计算高斯混合物流形中的节点嵌入，我们的方法引导出了一种新的关注机制进行邻域聚合。我们提供了有关嵌入的泛化和表达能力的理论见解，为更深入理解基于注意力机制的GNN做出了贡献。

    Attention-based graph neural networks (GNNs), such as graph attention networks (GATs), have become popular neural architectures for processing graph-structured data and learning node embeddings. Despite their empirical success, these models rely on labeled data and the theoretical properties of these models have yet to be fully understood. In this work, we propose a novel attention-based node embedding framework for graphs. Our framework builds upon a hierarchical kernel for multisets of subgraphs around nodes (e.g. neighborhoods) and each kernel leverages the geometry of a smooth statistical manifold to compare pairs of multisets, by "projecting" the multisets onto the manifold. By explicitly computing node embeddings with a manifold of Gaussian mixtures, our method leads to a new attention mechanism for neighborhood aggregation. We provide theoretical insights into genralizability and expressivity of our embeddings, contributing to a deeper understanding of attention-based GNNs. We p
    
[^7]: 高斯门控混合专家模型参数估计的收敛速率研究

    Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts. (arXiv:2305.07572v1 [stat.ML])

    [http://arxiv.org/abs/2305.07572](http://arxiv.org/abs/2305.07572)

    本文提出新颖的Voronoi Loss函数来解决高斯门控混合专家模型参数估计的收敛速率问题，并在两种不同的门控网络下提供理论收敛速率的证明。

    

    混合专家模型因其在集成学习中的应用而被引入神经网络中，近年来成为现代深度神经网络中处理异构数据分析的基本构件。然而，对于高斯门控混合专家模型参数估计的收敛行为的理解还不充分。我们通过设计新颖的Voronoi Loss函数来解决这些问题，并提供了理论收敛速率的证明，揭示了在两种分离的门控网络下最大似然估计器的不同行为。

    Originally introduced as a neural network for ensemble learning, mixture of experts (MoE) has recently become a fundamental building block of highly successful modern deep neural networks for heterogeneous data analysis in several applications, including those in machine learning, statistics, bioinformatics, economics, and medicine. Despite its popularity in practice, a satisfactory level of understanding of the convergence behavior of Gaussian-gated MoE parameter estimation is far from complete. The underlying reason for this challenge is the inclusion of covariates in the Gaussian gating and expert networks, which leads to their intrinsically complex interactions via partial differential equations with respect to their parameters. We address these issues by designing novel Voronoi loss functions to accurately capture heterogeneity in the maximum likelihood estimator (MLE) for resolving parameter estimation in these models. Our results reveal distinct behaviors of the MLE under two se
    
[^8]: 基于专家评估的加权回归模型处理嘈杂标签

    Expertise-based Weighting for Regression Models with Noisy Labels. (arXiv:2305.07430v1 [stat.ML])

    [http://arxiv.org/abs/2305.07430](http://arxiv.org/abs/2305.07430)

    本文提出了基于专家评估的加权回归模型，可用于处理具有不同观点的嘈杂标签。该方法包括两个步骤：估计每个专家的专业程度和结合他们的意见，然后将加权平均用于回归建模。本方法在模拟和真实数据上优于现有技术，具有简单、快速和有效的特点。

    

    回归方法假设训练数据的标签是准确的，然而在某些情况下，获取准确的标签并不可行，因此需要依赖多个具有不同观点的专家。本文提出了一种新的、更灵活的方法来处理嘈杂标签。该方法包括两个步骤：先估计每个专家的专业程度，然后使用学习到的权重结合他们的意见。接着，将加权平均用于回归建模。本文方法经过正式验证，证明在模拟和真实数据上优于现有技术。此外，其灵活性使得可以在两个步骤中利用任何机器学习技术。总之，该方法提供了一种简单、快速和有效的解决方案，用于训练回归模型并处理获取自不同专业来源的嘈杂标签。

    Regression methods assume that accurate labels are available for training. However, in certain scenarios, obtaining accurate labels may not be feasible, and relying on multiple specialists with differing opinions becomes necessary. Existing approaches addressing noisy labels often impose restrictive assumptions on the regression function. In contrast, this paper presents a novel, more flexible approach. Our method consists of two steps: estimating each labeler's expertise and combining their opinions using learned weights. We then regress the weighted average against the input features to build the prediction model. The proposed method is formally justified and empirically demonstrated to outperform existing techniques on simulated and real data. Furthermore, its flexibility enables the utilization of any machine learning technique in both steps. In summary, this method offers a simple, fast, and effective solution for training regression models with noisy labels derived from diverse e
    
[^9]: 面向函数学习的分布式梯度下降算法

    Distributed Gradient Descent for Functional Learning. (arXiv:2305.07408v1 [stat.ML])

    [http://arxiv.org/abs/2305.07408](http://arxiv.org/abs/2305.07408)

    该论文提出了一种针对函数数据的分布式梯度下降函数学习算法，在再生核希尔伯特空间框架下通过积分算子方法得到了该算法的理论理解，并取得了不饱和边界的置信度最优学习率。

    

    近年来，不同类型的分布式学习方案因其在处理大规模数据信息方面的巨大优势而受到越来越多的关注。针对最近从函数数据分析中产生的大数据挑战，我们在再生核希尔伯特空间框架下提出了一种新颖的分布式梯度下降函数学习（DGDFL）算法，用于处理来自众多本地机器（处理器）的函数数据。基于积分算子方法，我们提供了DGDFL算法在文献中的许多方面的第一个理论理解。在理解DGDFL的过程中，首先，我们提出并全面研究了基于数据的渐进式下降函数学习（GDFL）算法与单机模型相关联。在温和的条件下，得到了DGDFL的置信度最优学习率，避免了先前在正则性索引上遭受的饱和边界。

    In recent years, different types of distributed learning schemes have received increasing attention for their strong advantages in handling large-scale data information. In the information era, to face the big data challenges which stem from functional data analysis very recently, we propose a novel distributed gradient descent functional learning (DGDFL) algorithm to tackle functional data across numerous local machines (processors) in the framework of reproducing kernel Hilbert space. Based on integral operator approaches, we provide the first theoretical understanding of the DGDFL algorithm in many different aspects in the literature. On the way of understanding DGDFL, firstly, a data-based gradient descent functional learning (GDFL) algorithm associated with a single-machine model is proposed and comprehensively studied. Under mild conditions, confidence-based optimal learning rates of DGDFL are obtained without the saturation boundary on the regularity index suffered in previous w
    
[^10]: 锁定与叠层：通过对数池化和超叠加堆叠贝叶斯模型预测

    Locking and Quacking: Stacking Bayesian model predictions by log-pooling and superposition. (arXiv:2305.07334v1 [stat.ML])

    [http://arxiv.org/abs/2305.07334](http://arxiv.org/abs/2305.07334)

    本文提出了两种新的贝叶斯模型组合工具，可以通过对数池化和超叠加来组合后验密度，避免了标准化常数的负担，并在预测准确性方面优于传统方法。

    

    将来自不同模型的预测结合起来是贝叶斯推理和机器学习中的一个核心问题。目前，这些预测分布几乎仅使用线性组合进行组合，例如贝叶斯模型平均、贝叶斯堆叠和专家混合。这种线性混合可能对某些应用程序不利，例如多峰性。本文提出了两种新的贝叶斯模型组合工具。这些工具是模型堆叠的推广，但是通过对数线性汇集（锁定）和量子叠加（quacking）来合并后验密度。为了优化模型权重而避免标准化常数的负担，我们研究了组合后验预测的Hyvarinen得分。我们通过一个示例说明了锁定，并将两种方法应用于来自不同连续密度的模拟数据集，将它们与传统的模型组合工具进行比较。结果表明，这两种方法在预测准确性方面优于传统方法，同时具有高效计算的特点。

    Combining predictions from different models is a central problem in Bayesian inference and machine learning more broadly. Currently, these predictive distributions are almost exclusively combined using linear mixtures such as Bayesian model averaging, Bayesian stacking, and mixture of experts. Such linear mixtures impose idiosyncrasies that might be undesirable for some applications, such as multi-modality. While there exist alternative strategies (e.g. geometric bridge or superposition), optimising their parameters usually involves computing an intractable normalising constant repeatedly. We present two novel Bayesian model combination tools. These are generalisations of model stacking, but combine posterior densities by log-linear pooling (locking) and quantum superposition (quacking). To optimise model weights while avoiding the burden of normalising constants, we investigate the Hyvarinen score of the combined posterior predictions. We demonstrate locking with an illustrative examp
    
[^11]: HINT:层次混合网络用于一致概率预测

    HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting. (arXiv:2305.07089v1 [stat.ML])

    [http://arxiv.org/abs/2305.07089](http://arxiv.org/abs/2305.07089)

    HINT是一种用于概率预测的新型模型族，能够有效、准确地进行一致性预测，通过引入Bootstrap方法并为网络加入规范化特征提取和输出规范化来保证其性能，在多个数据集上的预测精度比现有技术更高。

    

    我们提出了一种名为"Hierarchical Mixture Networks"（HINT）的模型族，用于有效而准确的一致性预测。我们通过多元混合并使用复合似然函数进行优化来专门针对该任务进行网络特化，并通过引入Bootstrap方法加以协调。此外，我们在网络中引入了规范化特征提取和输出规范化，以应对时间序列尺度变化。与现有最先进技术相比，我们展示了在五个数据集上的8％ sCRPS增强精度。我们对模型部件进行了消融研究并广泛研究了多元混合的理论性质。 HINT的代码可以在https://github.com/Nixtla/neuralforecast上获得。

    We present the Hierarchical Mixture Networks (HINT), a model family for efficient and accurate coherent forecasting. We specialize the networks on the task via a multivariate mixture optimized with composite likelihood and made coherent via bootstrap reconciliation. Additionally, we robustify the networks to stark time series scale variations, incorporating normalized feature extraction and recomposition of output scales within their architecture. We demonstrate 8% sCRPS improved accuracy across five datasets compared to the existing state-of-the-art. We conduct ablation studies on our model's components and extensively investigate the theoretical properties of the multivariate mixture. HINT's code is available at this https://github.com/Nixtla/neuralforecast.
    
[^12]: 核梯度下降学习中的随机平滑正则化

    Random Smoothing Regularization in Kernel Gradient Descent Learning. (arXiv:2305.03531v1 [stat.ML])

    [http://arxiv.org/abs/2305.03531](http://arxiv.org/abs/2305.03531)

    本文提出了一种随机平滑正则化的框架，能够自适应地、有效地学习属于经典Sobolev空间范围内的各种真实函数，通过引入噪声避免过拟合，该方法可以在较快的速度下实现最优收敛率。

    

    随机平滑数据增强是一种独特的正则化形式，可以通过向输入数据引入噪声来防止过拟合，鼓励模型学习更广泛的特征。尽管在各种应用中都取得了成功，但随机平滑的正则化能力缺乏系统的研究。在本文中，我们旨在通过提出一个随机平滑正则化的框架，能够自适应地、有效地学习属于经典 Sobolev 空间范围内的各种真实函数。具体而言，我们研究了两种基础的函数空间：低固有维度的 Sobolev 空间，其中包括 $D$ 维欧几里德空间或低维子流形作为特例，以及具有张量结构的混合平滑 Sobolev 空间。通过使用随机平滑正则化作为新型卷积平滑核，我们可以在这些情况下实现最优收敛率。

    Random smoothing data augmentation is a unique form of regularization that can prevent overfitting by introducing noise to the input data, encouraging the model to learn more generalized features. Despite its success in various applications, there has been a lack of systematic study on the regularization ability of random smoothing. In this paper, we aim to bridge this gap by presenting a framework for random smoothing regularization that can adaptively and effectively learn a wide range of ground truth functions belonging to the classical Sobolev spaces. Specifically, we investigate two underlying function spaces: the Sobolev space of low intrinsic dimension, which includes the Sobolev space in $D$-dimensional Euclidean space or low-dimensional sub-manifolds as special cases, and the mixed smooth Sobolev space with a tensor structure. By using random smoothing regularization as novel convolution-based smoothing kernels, we can attain optimal convergence rates in these cases using a ke
    
[^13]: 基于随机先验网络的高维输出可扩展贝叶斯优化

    Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07260](http://arxiv.org/abs/2302.07260)

    本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。

    

    科学和工程中的一些基本问题涉及到未知的高维度映射一组可控变量到昂贵实验结果的黑盒函数的全局优化任务。贝叶斯优化（BO）技术已被证明在使用相对较少的目标函数评估时处理全局优化问题时非常有效，但当处理高维输出时，其性能受到影响。为克服维度主要挑战，本文提出了一个基于带随机先验的神经网络的自举集成的BO和序贯决策制定的深度学习框架。使用适当的体系结构选择，我们证明了所提出的框架可以近似设计变量和感兴趣量之间的功能关系，即使在后者取值于高维向量空间或甚至无限维函数空间的情况下。在贝叶斯优化的背景下，该方法允许高效和可扩展的处理高维度黑盒函数的全局优化。

    Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
    
[^14]: 坚固且可扩展的贝叶斯在线变点检测

    Robust and Scalable Bayesian Online Changepoint Detection. (arXiv:2302.04759v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.04759](http://arxiv.org/abs/2302.04759)

    该论文提出了一种在线变点检测方法，具有坚固和可扩展性，通过利用广义贝叶斯视角提供了可证明的坚固性，并通过扩散得分匹配解决了可扩展性问题。所得算法是精确的，更新简单，速度较之前的算法快10倍以上。

    

    本文提出了一种在线、可证明坚固且可扩展的贝叶斯方法用于变点检测。所得算法相对于之前的工作具有重要优势：通过利用广义贝叶斯视角提供了可证明的坚固性，并解决了之前尝试中的可扩展性问题。具体来说，所提出的广义贝叶斯形式主义通过利用扩散得分匹配导致共轭后验的参数可以通过封闭形式获得。所得算法是精确的，可以通过简单的代数更新，并且比其最接近的竞争对手快10倍以上。

    This paper proposes an online, provably robust, and scalable Bayesian approach for changepoint detection. The resulting algorithm has key advantages over previous work: it provides provable robustness by leveraging the generalised Bayesian perspective, and also addresses the scalability issues of previous attempts. Specifically, the proposed generalised Bayesian formalism leads to conjugate posteriors whose parameters are available in closed form by leveraging diffusion score matching. The resulting algorithm is exact, can be updated through simple algebra, and is more than 10 times faster than its closest competitor.
    
[^15]: 变系数$\ell_1$惩罚的稀疏贝叶斯Lasso。

    Sparse Bayesian Lasso via a Variable-Coefficient $\ell_1$ Penalty. (arXiv:2211.05089v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2211.05089](http://arxiv.org/abs/2211.05089)

    本文提出一种解决高度稀疏性的统计学习算法，即变系数$\ell_1$惩罚的稀疏贝叶斯Lasso，并通过定义可学习的惩罚权重$\lambda_p$及超先验知识来达到目的。

    

    现代统计学习算法具有惊人的灵活性，但解释性较差。稀疏性是一种可能的解决方案：通过估计许多参数为0，可以通过使用不光滑的$\ell_1$惩罚来实现这一点。然而，当需要高度稀疏性时，$\ell_1$惩罚会引入显着的偏差。在本文中，我们保留了$\ell_1$惩罚，但定义了可学习的惩罚权重$\lambda_p$并赋予了超先验知识。我们首先研究了这个优化问题，并开发了与$\ell_1$范数相关的近端算子。然后，我们在惩罚似然的背景下研究了这个变系数$\ell_1$惩罚的理论性质。接下来，我们研究了将该惩罚应用于变分贝叶斯的方法，开发了一种模型，称为稀疏贝叶斯Lasso，允许表现出类似于Lasso回归的行为。

    Modern statistical learning algorithms are capable of amazing flexibility, but struggle with interpretability. One possible solution is sparsity: making inference such that many of the parameters are estimated as being identically 0, which may be imposed through the use of nonsmooth penalties such as the $\ell_1$ penalty. However, the $\ell_1$ penalty introduces significant bias when high sparsity is desired. In this article, we retain the $\ell_1$ penalty, but define learnable penalty weights $\lambda_p$ endowed with hyperpriors. We start the article by investigating the optimization problem this poses, developing a proximal operator associated with the $\ell_1$ norm. We then study the theoretical properties of this variable-coefficient $\ell_1$ penalty in the context of penalized likelihood. Next, we investigate application of this penalty to Variational Bayes, developing a model we call the Sparse Bayesian Lasso which allows for behavior qualitatively like Lasso regression to be app
    
[^16]: 基于边缘分布的非参数消费者选择建模方法

    A Nonparametric Approach with Marginals for Modeling Consumer Choice. (arXiv:2208.06115v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.06115](http://arxiv.org/abs/2208.06115)

    本文提出了一种基于边缘分布的简单而有效的非参数消费者选择建模方法，在任何选择集合中会把选择概率的集合一致地描述出来。

    

    鉴于消费者在不同选择集合中作出选择的数据，开发描述和预测消费者选择行为的简洁模型是一个主要挑战。其中一种选择模型是边缘分布模型，该模型仅需要规定随机效用的边缘分布即可解释选项数据。在本文中，我们开发了一种精确的选择概率集合的特征化方法，该集合可以在任何集合中一致地通过边缘分布模型来描述。允许根据其效用的边缘分布将选择集合进行分组，我们展示了(a)验证这个模型与选择概率数据的一致性在多项式时间内是可能的，(b)最接近拟合的方法可以简化为解决混合整数凸规划问题。我们的结果表明，与多项式Logit模型和m相比，边缘分布模型提供了更好的表现能力。

    Given data on choices made by consumers for different assortments, a key challenge is to develop parsimonious models that describe and predict consumer choice behavior. One such choice model is the marginal distribution model which requires only the specification of the marginal distributions of the random utilities of the alternatives to explain choice data. In this paper, we develop an exact characterisation of the set of choice probabilities which are representable by the marginal distribution model consistently across any collection of assortments. Allowing for the possibility of alternatives to be grouped based on the marginal distribution of their utilities, we show (a) verifying consistency of choice probability data with this model is possible in polynomial time and (b) finding the closest fit reduces to solving a mixed integer convex program. Our results show that the marginal distribution model provides much better representational power as compared to multinomial logit and m
    
[^17]: 分层贝叶斯建模在工程机群间多任务学习中的知识转移应用

    Hierarchical Bayesian Modelling for Knowledge Transfer Across Engineering Fleets via Multitask Learning. (arXiv:2204.12404v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.12404](http://arxiv.org/abs/2204.12404)

    本文提出了一种分层贝叶斯建模方法，利用操作机群中的领域专业知识，在不同的子群之间自动地共享信息。该方法成功地解决了卡车机群的生存分析和风电场的功率预测问题。

    

    本论文提出了一种基于群体级别分析的方法来解决工程基础设施预测建模中数据稀疏的问题。利用可解释的分层贝叶斯方法和操作机群数据，自然地将领域专业知识编码（和适当共享）到不同子群之间，分别代表（i）使用类型，（ii）部件或（iii）运行条件。具体而言，通过假设（和先验分布），利用领域专业知识来限制模型，使得方法能够自动在类似资产之间共享信息，以改善卡车机群的生存分析和风电场的功率预测。在每个资产管理示例中，通过合并推理，在机群上学习一组相关函数，以学习群体模型。当子机群在层次结构的不同级别上共享相关信息时，参数估计得到改进。反过来，具有不完整数据的群体自动借用统计强度。

    A population-level analysis is proposed to address data sparsity when building predictive models for engineering infrastructure. Utilising an interpretable hierarchical Bayesian approach and operational fleet data, domain expertise is naturally encoded (and appropriately shared) between different sub-groups, representing (i) use-type, (ii) component, or (iii) operating condition. Specifically, domain expertise is exploited to constrain the model via assumptions (and prior distributions) allowing the methodology to automatically share information between similar assets, improving the survival analysis of a truck fleet and power prediction in a wind farm. In each asset management example, a set of correlated functions is learnt over the fleet, in a combined inference, to learn a population model. Parameter estimation is improved when sub-fleets share correlated information at different levels of the hierarchy. In turn, groups with incomplete data automatically borrow statistical strength
    
[^18]: Transformer在时间序列中的应用概述

    Transformers in Time Series: A Survey. (arXiv:2202.07125v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.07125](http://arxiv.org/abs/2202.07125)

    本文针对Transformer在时间序列建模中的应用进行了系统回顾，总结了其优点及局限性，从网络结构和应用两个角度审视了其适应和改进。

    

    Transformer在自然语言处理和计算机视觉中已经取得了优越的性能，也引起了时间序列社区的极大兴趣。Transformer的多个优势之一是能够捕捉长程依赖和相互作用，特别适合于时间序列建模，极大地推动了时间序列应用的发展。本文系统地回顾了Transformer在时间序列建模中的应用，并强调了其优点及局限性。具体而言，我们从网络结构和应用两个层面审视了Transformer在时间序列上的适应和改进。从网络结构的角度，我们总结了为了适应时间序列分析中的挑战而做出的改变和调整。从应用的角度，我们根据常见任务（包括预测、异常检测和分类）对时间序列Transformer进行了分类。

    Transformers have achieved superior performances in many tasks in natural language processing and computer vision, which also triggered great interest in the time series community. Among multiple advantages of Transformers, the ability to capture long-range dependencies and interactions is especially attractive for time series modeling, leading to exciting progress in various time series applications. In this paper, we systematically review Transformer schemes for time series modeling by highlighting their strengths as well as limitations. In particular, we examine the development of time series Transformers in two perspectives. From the perspective of network structure, we summarize the adaptations and modifications that have been made to Transformers in order to accommodate the challenges in time series analysis. From the perspective of applications, we categorize time series Transformers based on common tasks including forecasting, anomaly detection, and classification. Empirically,
    
[^19]: 深度前馈ReLU神经网络的参数可辨识性

    Parameter identifiability of a deep feedforward ReLU neural network. (arXiv:2112.12982v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2112.12982](http://arxiv.org/abs/2112.12982)

    本文研究了一类深度前馈ReLU神经网络的参数可辨识性，给出了一组刻画条件并证明了在这些条件下，可以唯一确定网络的参数。

    

    在一些情况下，基于神经网络在输入的一个子集上的函数值可以恢复神经网络的参数权重和偏置，这既可以是一个诅咒也可以是一个福音。本文研究了一类深度全连接前馈ReLU神经网络，提出了一组条件来刻画其参数可辨识性的问题，并证明了在这些条件下，可以唯一确定网络的参数-模除置换和正的缩放。

    The possibility for one to recover the parameters-weights and biases-of a neural network thanks to the knowledge of its function on a subset of the input space can be, depending on the situation, a curse or a blessing. On one hand, recovering the parameters allows for better adversarial attacks and could also disclose sensitive information from the dataset used to construct the network. On the other hand, if the parameters of a network can be recovered, it guarantees the user that the features in the latent spaces can be interpreted. It also provides foundations to obtain formal guarantees on the performances of the network. It is therefore important to characterize the networks whose parameters can be identified and those whose parameters cannot. In this article, we provide a set of conditions on a deep fully-connected feedforward ReLU neural network under which the parameters of the network are uniquely identified-modulo permutation and positive rescaling-from the function it impleme
    
[^20]: 无限不平衡下的线性分类器研究

    Linear Classifiers Under Infinite Imbalance. (arXiv:2106.05797v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.05797](http://arxiv.org/abs/2106.05797)

    研究了在无限不平衡情况下的线性分类器，通过权重函数指定的经验损失最小化系数。截距发散但其余系数向量有一个有限的几乎肯定的极限，极限依赖于权重函数的左尾增长速率。极限系数向量反映稳健性或保守性属性，而在亚指数情况下，极限等价于少数类的上采样分布的隐式选择。

    

    本研究探讨了在一个类别的样本数量增长到无穷大而另一个类别的样本数量保持不变的情况下，二元分类中的线性判别函数的行为。分类器的系数通过一个权重函数指定的经验损失最小化。我们展示了，对于广泛的权重函数类，截距发散但其余系数向量在无穷不平衡情况下具有一个有限的几乎肯定的极限，这扩展了之前对逻辑回归的研究。极限依赖于权重函数的左尾增长速率，对此我们区分了两种情况：亚指数和指数。极限系数向量反映了稳健性或保守性属性，因为它们优化了某些最坏情况的替代方法。在亚指数情况下，极限等价于少数类的上采样分布的隐式选择。我们在信用风险设置中应用了这些思想。

    We study the behavior of linear discriminant functions for binary classification in the infinite-imbalance limit, where the sample size of one class grows without bound while the sample size of the other remains fixed. The coefficients of the classifier minimize an empirical loss specified through a weight function. We show that for a broad class of weight functions, the intercept diverges but the rest of the coefficient vector has a finite almost sure limit under infinite imbalance, extending prior work on logistic regression. The limit depends on the left-tail growth rate of the weight function, for which we distinguish two cases: subexponential and exponential. The limiting coefficient vectors reflect robustness or conservatism properties in the sense that they optimize against certain worst-case alternatives. In the subexponential case, the limit is equivalent to an implicit choice of upsampling distribution for the minority class. We apply these ideas in a credit risk setting, wit
    
[^21]: 深度回归中的变量误差模型的随机不确定性

    Aleatoric uncertainty for Errors-in-Variables models in deep regression. (arXiv:2105.09095v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.09095](http://arxiv.org/abs/2105.09095)

    本文提出了一种基于贝叶斯深度回归的方法，利用变量误差模型考虑所使用神经网络的输入所关联的不确定性，并将预测不确定性分解为随机和认识部分。相比于不使用该模型，使用错误变量模型能够提高对已知回归函数的覆盖率，且保持预测性能。

    

    深度学习的贝叶斯处理可以计算与深度神经网络预测相关的不确定性。我们展示了如何在贝叶斯深度回归中使用变量误差的概念，以考虑所使用神经网络的输入所关联的不确定性。所提出的方法利用了一个相关但通常被忽视的不确定性源，并将预测不确定性分解为随机和认识部分，这在统计学角度更完整，而且在很多情况下更一致。我们通过各种模拟和真实的例子讨论了这种方法，并观察到使用变量误差模型会增加不确定性，同时保持不使用变量误差模型的模型的预测性能。对于已知回归函数的例子，我们观察到变量误差模型大大提高了对基础事实的覆盖，表明该方法在回归问题中表现良好。

    A Bayesian treatment of deep learning allows for the computation of uncertainties associated with the predictions of deep neural networks. We show how the concept of Errors-in-Variables can be used in Bayesian deep regression to also account for the uncertainty associated with the input of the employed neural network. The presented approach thereby exploits a relevant, but generally overlooked, source of uncertainty and yields a decomposition of the predictive uncertainty into an aleatoric and epistemic part that is more complete and, in many cases, more consistent from a statistical perspective. We discuss the approach along various simulated and real examples and observe that using an Errors-in-Variables model leads to an increase in the uncertainty while preserving the prediction performance of models without Errors-in-Variables. For examples with known regression function we observe that this ground truth is substantially better covered by the Errors-in-Variables model, indicating 
    
[^22]: 不确定性的不平等影响：平权行动与平权信息

    The Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information. (arXiv:2102.10019v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2102.10019](http://arxiv.org/abs/2102.10019)

    本文证明了不确定性对不同人群的影响是不平等的，虽然它会在所有人口群体中产生误差，但误差的类型会有系统性的变化。我们提出了一种名为平权信息的策略，可以消除这种差异并扩大机会的获取，这可以作为平权行动的替代方案。

    This paper proves that uncertainty has a disparate impact on different demographic groups, with varying types of errors. The proposed strategy, called Affirmative Information, can eliminate this disparity and broaden access to opportunity, serving as an alternative to Affirmative Action.

    像贷款批准、医疗干预和大学录取这样的关键决策是在存在不确定性的情况下进行预测的。在本文中，我们证明了不确定性具有不平等的影响。虽然它会在所有人口群体中产生误差，但误差的类型会有系统性的变化：平均结果较高的群体通常被分配更高的假阳性率，而平均结果较低的群体则被分配更高的假阴性率。我们展示了额外的数据获取可以消除这种差异并扩大机会的获取。我们称之为平权信息的策略可以作为平权行动的替代方案。

    Critical decisions like loan approvals, medical interventions, and college admissions are guided by predictions made in the presence of uncertainty. In this paper, we prove that uncertainty has a disparate impact. While it imparts errors across all demographic groups, the types of errors vary systematically: Groups with higher average outcomes are typically assigned higher false positive rates, while those with lower average outcomes are assigned higher false negative rates. We show that additional data acquisition can eliminate the disparity and broaden access to opportunity. The strategy, which we call Affirmative Information, could stand as an alternative to Affirmative Action.
    

