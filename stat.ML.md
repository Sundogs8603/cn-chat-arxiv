# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning](https://arxiv.org/abs/2402.13221) | 图机器学习领域目前主要集中在预测分子和材料的目标特性，而尚未达到生成能力与其他领域的水平。 |
| [^2] | [Testing Calibration in Subquadratic Time](https://arxiv.org/abs/2402.13187) | 该论文通过属性测试算法方面的研究，提出了一种基于近似线性规划的算法，可以在信息理论上最优地解决校准性测试问题（最多一个常数倍数）。 |
| [^3] | [Order-Optimal Regret in Distributed Kernel Bandits using Uniform Sampling with Shared Randomness](https://arxiv.org/abs/2402.13182) | 提出的算法在分布式核赌博机问题中实现了最优次序遗憾，并且通信成本对于代理数量和时间都是亚线性的。 |
| [^4] | [On Generalization Bounds for Deep Compound Gaussian Neural Networks](https://arxiv.org/abs/2402.13106) | 本文针对受复合高斯先验启发的展开DNN，提出了新颖的泛化误差界限，这些网络在压缩感知和层析成像问题中表现出色。 |
| [^5] | [Mode Estimation with Partial Feedback](https://arxiv.org/abs/2402.13079) | 本文提出了一种在模态估计中利用部分反馈的方法，通过熵编码实现最优信息获取，开发了粗糙的充分统计用于模态识别，并将赌博算法调整为新设置，最终提出了一个高效的问题解决方案 |
| [^6] | [Efficient adjustment for complex covariates: Gaining efficiency with DOPE](https://arxiv.org/abs/2402.12980) | 提出了一种适应任何协变量信息子集的调整的通用框架，并通过理论结果引入了Debiased Outcome-adapted Propensity Estimator（DOPE）以实现有效调整。 |
| [^7] | [A Bound on the Maximal Marginal Degrees of Freedom](https://arxiv.org/abs/2402.12885) | 该论文提出了对于核岭回归的低秩近似和替代方法中，关于低维近似秩的一个下界，从而保证可靠的预测能力，并将有效维度与最大统计杠杆得分联系起来。 |
| [^8] | [Chain of Thought Empowers Transformers to Solve Inherently Serial Problems](https://arxiv.org/abs/2402.12875) | 思维链赋予变压器模型执行固有串行计算的能力，提高了变压器在算术和符号推理任务中的准确性。 |
| [^9] | [Fast Rates in Online Convex Optimization by Exploiting the Curvature of Feasible Sets](https://arxiv.org/abs/2402.12868) | 该论文提出了一种新的分析方法，通过利用可行集的曲率，在在线凸优化中实现了快速收敛速度。 |
| [^10] | [SGD with Clipping is Secretly Estimating the Median Gradient](https://arxiv.org/abs/2402.12828) | 本研究提出了一种基于中值估计的稳健梯度估计方法，针对包括重尾噪声在内的多种应用场景进行了探讨，揭示了不同形式的剪切方法实际上是该方法的特例。 |
| [^11] | [PIP-Net: Pedestrian Intention Prediction in the Wild](https://arxiv.org/abs/2402.12810) | PIP-Net是一个新型框架，通过综合利用动态学数据和场景空间特征，采用循环和时间注意力机制解决方案，成功预测行人通过马路的意图，性能优于现有技术。 |
| [^12] | [Learning Generalization and Regularization of Nonhomogeneous Temporal Poisson Processes](https://arxiv.org/abs/2402.12808) | 将NHPPs的估计问题转化为学习泛化问题，提出了正则化学习NHPPs的框架与两种新的自适应和数据驱动的分箱方法，有效解决了数据量有限时过拟合的问题。 |
| [^13] | [Learning under Singularity: An Information Criterion improving WBIC and sBIC](https://arxiv.org/abs/2402.12762) | LS信息准则旨在增强WBIC和sBIC的功能，有效处理非正则情况，具有稳定性，为奇异情况下的信息准则提供了新的方法 |
| [^14] | [Diffusion Posterior Sampling is Computationally Intractable](https://arxiv.org/abs/2402.12727) | 我们证明了后验抽样在计算上是难以解决的：在加密学中最基本的假设下——单向函数存在的假设下，存在一些实例，对于这些实例，每个算法都需要超多项式时间，即使无条件抽样可以证明是快速的。 |
| [^15] | [Achieving Near-Optimal Regret for Bandit Algorithms with Uniform Last-Iterate Guarantee](https://arxiv.org/abs/2402.12711) | 本文引入了统一最后迭代(ULI)保证这一更强的性能度量，同时证明接近最优的ULI保证直接导致了在各种性能度量上接近最优的累积性能。 |
| [^16] | [Integrating Active Learning in Causal Inference with Interference: A Novel Approach in Online Experiments](https://arxiv.org/abs/2402.12710) | 这项研究通过引入主动学习方法ACI，专注于在网络干扰和非随机处理分配情况下估计直接和溢出处理效应。 |
| [^17] | [Learning on manifolds without manifold learning](https://arxiv.org/abs/2402.12687) | 提出了一种无需流形学习的在流形上学习方法，通过一次性构造获得最佳误差界限。 |
| [^18] | [Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests](https://arxiv.org/abs/2402.12668) | 随机森林相对于装袋法具有减少偏差的能力，在揭示数据模式和高信噪比情况下表现更好的特点，为随机森林在不同信噪比环境下的成功提供了解释和实用见解。 |
| [^19] | [FAST: An Optimization Framework for Fast Additive Segmentation in Transparent ML](https://arxiv.org/abs/2402.12630) | FAST框架通过快速分段形状函数的优化和新的特征选择算法，使得透明的附加模型的拟合速度比现有方法快2个数量级。 |
| [^20] | [Multi-class Temporal Logic Neural Networks](https://arxiv.org/abs/2402.12397) | 提出了一种结合神经网络和信号时间逻辑的方法，用于多类别时间序列数据的分类，关键贡献包括引入边界概念和利用STL属性增强结果的可解释性。 |
| [^21] | [Collaborative Learning with Different Labeling Functions](https://arxiv.org/abs/2402.10445) | 研究了使用不同标注函数的协作学习中，基于经验风险最小化算法在增强假设类上的高效学习方法。 |
| [^22] | [Best Arm Identification for Prompt Learning under a Limited Budget](https://arxiv.org/abs/2402.09723) | 这项工作提出了一种在提示学习中考虑有限预算约束的方法，通过建立提示学习和多臂赌博机中固定预算最佳臂识别之间的联系，提出了一个通用框架TRIPLE，通过利用聚类和嵌入思想实现了两个增强方法。 |
| [^23] | [Fusing Individualized Treatment Rules Using Secondary Outcomes](https://arxiv.org/abs/2402.08828) | 该论文提出了一种新方法，通过融合次要结果来学习个体化治疗规则(ITR)，既最大化主要结果的价值函数，又尽可能接近次要结果的最优规则。 |
| [^24] | [Stein Boltzmann Sampling: A Variational Approach for Global Optimization](https://arxiv.org/abs/2402.04689) | Stein Boltzmann抽样（SBS）是一种全局优化的变分方法，通过从Boltzmann分布中采样，由Stein Variational Gradient Descent算法实现，具有渐近收敛性，并在各种基准函数上比较了几种最先进的全局优化算法，尤其适合作为高效全局优化方法的延续，能够产生更好的解决方案并有效利用预算。 |
| [^25] | [Generalization in Kernel Regression Under Realistic Assumptions](https://arxiv.org/abs/2312.15995) | 本文提供了一个统一的理论，用于对几乎所有常见和现实设置下的核回归的超出风险进行上限约束，并揭示了核分解中存在的自我正则化现象。 |
| [^26] | [Best Arm Identification with Fixed Budget: A Large Deviation Perspective](https://arxiv.org/abs/2312.12137) | 本文通过建立经验比例和经验臂奖励之间的连接，提高了一些现有算法的错误概率上界。 |
| [^27] | [Mean estimation in the add-remove model of differential privacy](https://arxiv.org/abs/2312.06658) | 该论文研究了在差分隐私的添加-删除模型中的一维均值估计问题，并提出了一个新算法，证明其在均方误差中达到最佳常数，该常数与交换模型下的最优算法相同。 |
| [^28] | [Touring sampling with pushforward maps](https://arxiv.org/abs/2311.13845) | 该论文从理论角度对生成建模中的多种采样方法进行了审视和组织，帮助克服采样中的一些挑战，比如推理时间长和生成样本缺乏多样性。 |
| [^29] | [Autoregressive Bandits](https://arxiv.org/abs/2212.06251) | 在自回归过程控制的奖励下，提出了自回归赌博机（ARBs）在线学习设置，并设计了AutoRegressive Upper Confidence Bound (AR-UCB)算法，可以方便计算最优策略并具有次线性遗憾。 |
| [^30] | [Mathematical Framework for Online Social Media Auditing](https://arxiv.org/abs/2209.05550) | 研究提出了一个数学框架，探讨了社交媒体平台上算法过滤的不良影响以及监管复杂性。 |
| [^31] | [Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint.](http://arxiv.org/abs/2312.11456) | 该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。 |
| [^32] | [Add and Thin: Diffusion for Temporal Point Processes.](http://arxiv.org/abs/2311.01139) | 本研究提出了一种基于概率去噪扩散模型的时间点过程模型，相比于现有的方法，该模型在预测方面取得了较好的性能，对具有离散和连续成分的数据具有处理能力。 |
| [^33] | [Conformal Normalization in Recurrent Neural Network of Grid Cells.](http://arxiv.org/abs/2310.19192) | 本文提出了一种循环神经网络中的共形归一化方法，用于处理网格细胞在2D物理空间中的自我位置信息。实验结果表明，该方法能够显著减小位置误差。 |
| [^34] | [Contextual directed acyclic graphs.](http://arxiv.org/abs/2310.15627) | 本论文研究了上下文定向无环图的问题，通过神经网络将上下文特征映射到DAG，利用稀疏的加权邻接矩阵表示图结构，并通过新颖的投影层满足无环性的特点。实验证明该方法能够成功恢复出真实的上下文特定图。 |
| [^35] | [Impact of multi-armed bandit strategies on deep recurrent reinforcement learning.](http://arxiv.org/abs/2310.08331) | 本研究在自动驾驶场景中使用部分可观测系统，通过部署和测试多种技术来平衡探索和利用的权衡，以预测方向盘操作。 |
| [^36] | [SWoTTeD: An Extension of Tensor Decomposition to Temporal Phenotyping.](http://arxiv.org/abs/2310.01201) | SWoTTeD是一种扩展的张量分解方法，用于发现复杂时间模式下的隐藏表征。在实验中，SWoTTeD不仅能与最新的基于张量分解的方法一样准确地重建数据，还能提取出对临床医生有意义的时间表征。 |
| [^37] | [Will More Expressive Graph Neural Networks do Better on Generative Tasks?.](http://arxiv.org/abs/2308.11978) | 本论文调查了更具表现力的图神经网络在分子图生成任务中的表现能力，并通过替换图生成模型的基础GNN来进行实验。研究发现，使用更具表现力的GNN可以改善生成任务的性能。 |
| [^38] | [Kernel Single Proxy Control for Deterministic Confounding.](http://arxiv.org/abs/2308.04585) | 本研究考虑了具有未观测混淆因素的因果效应估计问题，在结果是确定性生成的情况下，提出了一种使用单一代理变量的内核方法，通过两阶段回归和最大矩约束的方法可以一致估计因果效应，并在合成数据集上成功恢复了因果效应。 |
| [^39] | [Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders.](http://arxiv.org/abs/2305.16189) | 该论文提出了一种因子高斯混合变分自动编码器，用于多尺度聚类和源分离，通过利用小波散射协方差来提供随机过程的低维表示，能够区分不同的非高斯随机过程，并在MRO数据集上展现了更好的性能。 |
| [^40] | [Generative Sliced MMD Flows with Riesz Kernels.](http://arxiv.org/abs/2305.11463) | 本文使用Riesz核展示了生成式分割MMD流的高效计算方法，实现了在大规模应用中通过神经网络训练生成模型。 |
| [^41] | [A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization.](http://arxiv.org/abs/2302.08766) | 该论文提出了一种双层经验风险最小化算法，使用的梯度计算次数 $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$，在样本复杂度方面是最优的。 |
| [^42] | [Survival Kernets: Scalable and Interpretable Deep Kernel Survival Analysis with an Accuracy Guarantee.](http://arxiv.org/abs/2206.10477) | Survival Kernets 是一种可扩展且可解释的深度核生存分析模型，能够在大规模数据集上进行模型解释和理论分析。它利用核函数估计个体的生存分布，通过训练集压缩方案进行数据分簇，因此具有较高的可视化能力和预测准确性保证。该模型在特定情况下的预测生存分布误差界限最优，且在测试时具有可扩展性。 |
| [^43] | [Convergence of Batch Asynchronous Stochastic Approximation With Applications to Reinforcement Learning.](http://arxiv.org/abs/2109.03445) | 本文提出了一种批量异步随机逼近算法，它可以在内存需求和时间复杂度之间进行权衡，同时提供了可以使用较弱假设证明收敛的一般方法；在强化学习领域，我们使用此方法证明了SARSA算法的批量异步版本的收敛性。 |
| [^44] | [Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation.](http://arxiv.org/abs/2106.03907) | 本论文提出了一种深度代理因果学习（PCL）方法，用于在存在混淆因素的情况下估计治疗对结果的因果效应。通过构建治疗和代理之间的模型，并利用该模型在给定代理的情况下学习治疗对结果的影响，PCL可以保证恢复真实的因果效应。作者还提出了一种名为深度特征代理变量方法（DFPV）的新方法，用于处理高维和非线性复杂关系的情况，并表明DFPV在合成基准测试中的性能优于最先进的PCL方法。 |

# 详细

[^1]: CHILI: 用于推进图机器学习的化学信息的大型无机纳米材料数据集

    CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning

    [https://arxiv.org/abs/2402.13221](https://arxiv.org/abs/2402.13221)

    图机器学习领域目前主要集中在预测分子和材料的目标特性，而尚未达到生成能力与其他领域的水平。

    

    图机器学习的进展主要受化学应用的驱动，因为图一直是分子最具表现力的表示形式。虽然早期的图机器学习方法主要集中在小有机分子上，但最近，图机器学习的范围已经扩展到包括无机材料。建模无机晶体材料的周期性和对称性带来独特挑战，现有的图机器学习方法无法解决。转向无机纳米材料会增加复杂性，因为每个图中节点数量的范围可能很广（$10$到$10^5$）。现有图机器学习的主要重点是通过图作为输入来预测目标特性，来表征分子和材料。但是，图机器学习最激动人心的应用将在其生成能力方面，目前与图像或文本等其他领域还不在同一水平。

    arXiv:2402.13221v1 Announce Type: new  Abstract: Advances in graph machine learning (ML) have been driven by applications in chemistry as graphs have remained the most expressive representations of molecules. While early graph ML methods focused primarily on small organic molecules, recently, the scope of graph ML has expanded to include inorganic materials. Modelling the periodicity and symmetry of inorganic crystalline materials poses unique challenges, which existing graph ML methods are unable to address. Moving to inorganic nanomaterials increases complexity as the scale of number of nodes within each graph can be broad ($10$ to $10^5$). The bulk of existing graph ML focuses on characterising molecules and materials by predicting target properties with graphs as input. However, the most exciting applications of graph ML will be in their generative capabilities, which is currently not at par with other domains such as images or text.   We invite the graph ML community to address th
    
[^2]: 在次线性时间内测试校准性

    Testing Calibration in Subquadratic Time

    [https://arxiv.org/abs/2402.13187](https://arxiv.org/abs/2402.13187)

    该论文通过属性测试算法方面的研究，提出了一种基于近似线性规划的算法，可以在信息理论上最优地解决校准性测试问题（最多一个常数倍数）。

    

    在最近的机器学习和决策制定文献中，校准性已经成为二元预测模型输出的一个值得期望和广泛研究的统计性质。然而，测量模型校准性的算法方面仍然相对较少被探索。在论文 [BGHN23] 的启发下，该论文提出了一个严格的框架来衡量到校准性的距离，我们通过属性测试的视角引入了校准性研究的算法方面。我们定义了从样本中进行校准性测试的问题，其中从分布 $\mathcal{D}$（预测，二元结果）中给出 $n$ 次抽样，我们的目标是区分 $\mathcal{D}$ 完全校准和 $\mathcal{D}$ 距离校准性为 $\varepsilon$ 的情况。

    arXiv:2402.13187v1 Announce Type: new  Abstract: In the recent literature on machine learning and decision making, calibration has emerged as a desirable and widely-studied statistical property of the outputs of binary prediction models. However, the algorithmic aspects of measuring model calibration have remained relatively less well-explored. Motivated by [BGHN23], which proposed a rigorous framework for measuring distances to calibration, we initiate the algorithmic study of calibration through the lens of property testing. We define the problem of calibration testing from samples where given $n$ draws from a distribution $\mathcal{D}$ on (predictions, binary outcomes), our goal is to distinguish between the case where $\mathcal{D}$ is perfectly calibrated, and the case where $\mathcal{D}$ is $\varepsilon$-far from calibration.   We design an algorithm based on approximate linear programming, which solves calibration testing information-theoretically optimally (up to constant factor
    
[^3]: 使用共享随机性的均匀采样实现分布式核赌博机中的最优次序遗憾

    Order-Optimal Regret in Distributed Kernel Bandits using Uniform Sampling with Shared Randomness

    [https://arxiv.org/abs/2402.13182](https://arxiv.org/abs/2402.13182)

    提出的算法在分布式核赌博机问题中实现了最优次序遗憾，并且通信成本对于代理数量和时间都是亚线性的。

    

    我们考虑分布式核赌博机问题，其中$N$个代理旨在协同最大化存在于再生核希尔伯特空间中的未知奖励函数。每个代理依次查询该函数，以在查询点处获得嘈杂的观测值。代理可以通过中央服务器共享信息，目的是最小化随着时间$T$累积并汇总在代理之间的遗憾。我们开发了第一个算法，该算法实现了在通信成本对$N$和$T$均为亚线性的情况下实现了最优遗憾次序（由集中式学习定义）。所提出算法的关键特点是局部代理的均匀探索和与中央服务器的共享随机性。与GP模型的稀疏逼近一起工作，这两个关键组件使得能够以通信的衰减速率保持中央设置的学习速率。

    arXiv:2402.13182v1 Announce Type: new  Abstract: We consider distributed kernel bandits where $N$ agents aim to collaboratively maximize an unknown reward function that lies in a reproducing kernel Hilbert space. Each agent sequentially queries the function to obtain noisy observations at the query points. Agents can share information through a central server, with the objective of minimizing regret that is accumulating over time $T$ and aggregating over agents. We develop the first algorithm that achieves the optimal regret order (as defined by centralized learning) with a communication cost that is sublinear in both $N$ and $T$. The key features of the proposed algorithm are the uniform exploration at the local agents and shared randomness with the central server. Working together with the sparse approximation of the GP model, these two key components make it possible to preserve the learning rate of the centralized setting at a diminishing rate of communication.
    
[^4]: 关于深度复合高斯神经网络的泛化界限

    On Generalization Bounds for Deep Compound Gaussian Neural Networks

    [https://arxiv.org/abs/2402.13106](https://arxiv.org/abs/2402.13106)

    本文针对受复合高斯先验启发的展开DNN，提出了新颖的泛化误差界限，这些网络在压缩感知和层析成像问题中表现出色。

    

    算法展开或滚动是一种从迭代算法构建深度神经网络（DNN）的技术。展开的DNN在信号估计任务中通常比标准DNN提供更好的可解释性和更优越的经验性能。一个重要的理论问题是最近才引起关注的是为展开的DNN开发泛化误差界限。这些界限提供了理论和实际洞察，说明了DNN在与生成DNN训练数据的概率密度不同但采样自其中的经验数据集上的表现。在本文中，我们为一类受复合高斯先验启发的展开DNN开发了新颖的泛化误差界限。已经显示这些复合高斯网络在压缩感知和层析成像问题中优于比较的标准和展开的深度神经网络。

    arXiv:2402.13106v1 Announce Type: cross  Abstract: Algorithm unfolding or unrolling is the technique of constructing a deep neural network (DNN) from an iterative algorithm. Unrolled DNNs often provide better interpretability and superior empirical performance over standard DNNs in signal estimation tasks. An important theoretical question, which has only recently received attention, is the development of generalization error bounds for unrolled DNNs. These bounds deliver theoretical and practical insights into the performance of a DNN on empirical datasets that are distinct from, but sampled from, the probability density generating the DNN training data. In this paper, we develop novel generalization error bounds for a class of unrolled DNNs that are informed by a compound Gaussian prior. These compound Gaussian networks have been shown to outperform comparative standard and unfolded deep neural networks in compressive sensing and tomographic imaging problems. The generalization error
    
[^5]: 具有部分反馈的模态估计

    Mode Estimation with Partial Feedback

    [https://arxiv.org/abs/2402.13079](https://arxiv.org/abs/2402.13079)

    本文提出了一种在模态估计中利用部分反馈的方法，通过熵编码实现最优信息获取，开发了粗糙的充分统计用于模态识别，并将赌博算法调整为新设置，最终提出了一个高效的问题解决方案

    

    arXiv:2402.13079v1 通告类型: 交叉摘要: 最近人工智能发展中，轻度监督的预训练和在线微调的组合在起着关键作用。这些新的学习流程需要新的理论框架。本文通过一个简单问题，形式化弱监督和主动学习的核心方面：使用部分反馈估计分布的模态。我们展示了如何利用熵编码从部分反馈中实现最优信息获取，为模态识别开发了粗糙的充分统计，并将赌博算法调整为我们的新设置。最后，我们将这些贡献结合起来，提出了一个在统计上和计算上高效的问题解决方案。

    arXiv:2402.13079v1 Announce Type: cross  Abstract: The combination of lightly supervised pre-training and online fine-tuning has played a key role in recent AI developments. These new learning pipelines call for new theoretical frameworks. In this paper, we formalize core aspects of weakly supervised and active learning with a simple problem: the estimation of the mode of a distribution using partial feedback. We show how entropy coding allows for optimal information acquisition from partial feedback, develop coarse sufficient statistics for mode identification, and adapt bandit algorithms to our new setting. Finally, we combine those contributions into a statistically and computationally efficient solution to our problem.
    
[^6]: 复杂协变量的有效调整：利用DOPE提高效率

    Efficient adjustment for complex covariates: Gaining efficiency with DOPE

    [https://arxiv.org/abs/2402.12980](https://arxiv.org/abs/2402.12980)

    提出了一种适应任何协变量信息子集的调整的通用框架，并通过理论结果引入了Debiased Outcome-adapted Propensity Estimator（DOPE）以实现有效调整。

    

    协变量调整是一种用于从观测数据中估计平均处理效应（ATE）的普遍方法。最近的研究结果假设数据生成模型的图结构已知，给出了用于最佳调整的图形标准，从而实现了ATE的有效估计。然而，对于高维和复杂数据，图形方法具有挑战性，并且要指定非欧几里得数据（如文本）的有意义图形模型并不简单。我们提出了一个通用框架，可适应由协变量表达的任何信息子集的调整。我们推广了先前的工作，并利用这些结果识别了用于有效调整的最佳协变量信息。这些信息在给定处理条件下对结果的预测是最小充分的。

    arXiv:2402.12980v1 Announce Type: cross  Abstract: Covariate adjustment is a ubiquitous method used to estimate the average treatment effect (ATE) from observational data. Assuming a known graphical structure of the data generating model, recent results give graphical criteria for optimal adjustment, which enables efficient estimation of the ATE. However, graphical approaches are challenging for high-dimensional and complex data, and it is not straightforward to specify a meaningful graphical model of non-Euclidean data such as texts. We propose an general framework that accommodates adjustment for any subset of information expressed by the covariates. We generalize prior works and leverage these results to identify the optimal covariate information for efficient adjustment. This information is minimally sufficient for prediction of the outcome conditionally on treatment.   Based on our theoretical results, we propose the Debiased Outcome-adapted Propensity Estimator (DOPE) for efficie
    
[^7]: 对最大边际自由度的一个界限

    A Bound on the Maximal Marginal Degrees of Freedom

    [https://arxiv.org/abs/2402.12885](https://arxiv.org/abs/2402.12885)

    该论文提出了对于核岭回归的低秩近似和替代方法中，关于低维近似秩的一个下界，从而保证可靠的预测能力，并将有效维度与最大统计杠杆得分联系起来。

    

    arXiv:2402.12885v1 公告类型: 交叉摘要: 通用核岭回归在内存分配和计算时间上成本高昂。本文研究了核岭回归的低秩近似和替代方法，以应对这些困难。本文的基本贡献在于对低维近似的秩提出了一个下界，要求其保持可靠的预测能力。该界限将有效维度与最大统计杠杆得分联系起来。我们通过涉及核的正则性来表征有效维度及其随正则化参数的增长行为。对于适当选择的核，这种增长被证明是对数渐近的，从而证明了低秩近似作为Nyström方法的合理性。

    arXiv:2402.12885v1 Announce Type: cross  Abstract: Common kernel ridge regression is expensive in memory allocation and computation time. This paper addresses low rank approximations and surrogates for kernel ridge regression, which bridge these difficulties. The fundamental contribution of the paper is a lower bound on the rank of the low dimensional approximation, which is required such that the prediction power remains reliable. The bound relates the effective dimension with the largest statistical leverage score. We characterize the effective dimension and its growth behavior with respect to the regularization parameter by involving the regularity of the kernel. This growth is demonstrated to be asymptotically logarithmic for suitably chosen kernels, justifying low-rank approximations as the Nystr\"om method.
    
[^8]: 思维链激发变压器解决固有串行问题的能力

    Chain of Thought Empowers Transformers to Solve Inherently Serial Problems

    [https://arxiv.org/abs/2402.12875](https://arxiv.org/abs/2402.12875)

    思维链赋予变压器模型执行固有串行计算的能力，提高了变压器在算术和符号推理任务中的准确性。

    

    指导模型生成一系列中间步骤，即思维链（CoT），是提高大型语言模型（LLMs）在算术和符号推理任务上准确性的高效方法。然而，CoT背后的机制仍不清楚。这项工作通过表达性的视角提供了对解码器专用变压器的CoT能力的理论理解。在概念上，CoT赋予模型执行固有串行计算的能力，而这种能力在变压器中缺乏，特别是当深度较低时。先前的作品已经表明，在没有CoT的情况下，具有有限精度$\mathsf{poly}(n)$嵌入尺寸的恒定深度变压器只能在$\mathsf{TC}^0$中解决问题。我们首先展示了具有常数位精度的恒定深度变压器的更紧密的表达性上界，它只能解决$\mathsf{AC}^0$中的问题。

    arXiv:2402.12875v1 Announce Type: new  Abstract: Instructing the model to generate a sequence of intermediate steps, a.k.a., a chain of thought (CoT), is a highly effective method to improve the accuracy of large language models (LLMs) on arithmetics and symbolic reasoning tasks. However, the mechanism behind CoT remains unclear. This work provides a theoretical understanding of the power of CoT for decoder-only transformers through the lens of expressiveness. Conceptually, CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length $n$, previous works have shown that constant-depth transformers with finite precision $\mathsf{poly}(n)$ embedding size can only solve problems in $\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in $\mathsf{AC}^0$, a 
    
[^9]: 通过利用可行集的曲率，在在线凸优化中实现快速收敛速度

    Fast Rates in Online Convex Optimization by Exploiting the Curvature of Feasible Sets

    [https://arxiv.org/abs/2402.12868](https://arxiv.org/abs/2402.12868)

    该论文提出了一种新的分析方法，通过利用可行集的曲率，在在线凸优化中实现了快速收敛速度。

    

    在本文中，我们探讨了在线凸优化（OCO），介绍了一种通过利用可行集的曲率提供快速收敛速度的新分析。我们首先证明，如果最优决策位于可行集的边界上且基础损失函数的梯度非零，则算法在随机环境中可以达到$O(\rho \log T)$的遗憾上界。其中，$\rho > 0$是包含最优决策并围绕可行集的最小球体的半径。

    arXiv:2402.12868v1 Announce Type: new  Abstract: In this paper, we explore online convex optimization (OCO) and introduce a new analysis that provides fast rates by exploiting the curvature of feasible sets. In online linear optimization, it is known that if the average gradient of loss functions is larger than a certain value, the curvature of feasible sets can be exploited by the follow-the-leader (FTL) algorithm to achieve a logarithmic regret. This paper reveals that algorithms adaptive to the curvature of loss functions can also leverage the curvature of feasible sets. We first prove that if an optimal decision is on the boundary of a feasible set and the gradient of an underlying loss function is non-zero, then the algorithm achieves a regret upper bound of $O(\rho \log T)$ in stochastic environments. Here, $\rho > 0$ is the radius of the smallest sphere that includes the optimal decision and encloses the feasible set. Our approach, unlike existing ones, can work directly with co
    
[^10]: SGD梯度剪切方法暗中估计中值梯度

    SGD with Clipping is Secretly Estimating the Median Gradient

    [https://arxiv.org/abs/2402.12828](https://arxiv.org/abs/2402.12828)

    本研究提出了一种基于中值估计的稳健梯度估计方法，针对包括重尾噪声在内的多种应用场景进行了探讨，揭示了不同形式的剪切方法实际上是该方法的特例。

    

    有几种随机优化的应用场景可以受益于对梯度的稳健估计。例如，在具有损坏节点的分布式学习领域、训练数据中存在大的异常值、在隐私约束下学习，甚至由于算法动态本身的重尾噪声。本文研究了基于中值估计的稳健梯度估计的SGD。首先考虑跨样本计算中值梯度，结果表明即使在重尾、状态相关噪声下，该方法也能收敛。然后我们推导了基于随机近端点方法的迭代方法，用于计算几何中值和其推广形式。最后，我们提出了一种算法，用于估计迭代间的中值梯度，并发现几种众所周知的方法 - 特别是不同形式的剪切 - 是这一框架的特例。

    arXiv:2402.12828v1 Announce Type: cross  Abstract: There are several applications of stochastic optimization where one can benefit from a robust estimate of the gradient. For example, domains such as distributed learning with corrupted nodes, the presence of large outliers in the training data, learning under privacy constraints, or even heavy-tailed noise due to the dynamics of the algorithm itself. Here we study SGD with robust gradient estimators based on estimating the median. We first consider computing the median gradient across samples, and show that the resulting method can converge even under heavy-tailed, state-dependent noise. We then derive iterative methods based on the stochastic proximal point method for computing the geometric median and generalizations thereof. Finally we propose an algorithm estimating the median gradient across iterations, and find that several well known methods - in particular different forms of clipping - are particular cases of this framework.
    
[^11]: PIP-Net：城市中行人意图预测

    PIP-Net: Pedestrian Intention Prediction in the Wild

    [https://arxiv.org/abs/2402.12810](https://arxiv.org/abs/2402.12810)

    PIP-Net是一个新型框架，通过综合利用动态学数据和场景空间特征，采用循环和时间注意力机制解决方案，成功预测行人通过马路的意图，性能优于现有技术。

    

    精准的自动驾驶车辆（AVs）对行人意图的预测是当前该领域的一项研究挑战。在本文中，我们介绍了PIP-Net，这是一个新颖的框架，旨在预测AVs在现实世界城市场景中的行人过马路意图。我们提供了两种针对不同摄像头安装和设置设计的PIP-Net变种。利用来自行驶场景的动力学数据和空间特征，所提出的模型采用循环和时间注意力机制的解决方案，性能优于现有技术。为了增强道路用户的视觉表示及其与自车的相关性，我们引入了一个分类深度特征图，结合局部运动流特征，为场景动态提供丰富的洞察。此外，我们探讨了将摄像头的视野从一个扩展到围绕自车的三个摄像头的影响，以提升

    arXiv:2402.12810v1 Announce Type: cross  Abstract: Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the
    
[^12]: 学习非齐次时间泊松过程的泛化和正则化

    Learning Generalization and Regularization of Nonhomogeneous Temporal Poisson Processes

    [https://arxiv.org/abs/2402.12808](https://arxiv.org/abs/2402.12808)

    将NHPPs的估计问题转化为学习泛化问题，提出了正则化学习NHPPs的框架与两种新的自适应和数据驱动的分箱方法，有效解决了数据量有限时过拟合的问题。

    

    泊松过程，尤其是非齐次泊松过程(NHPP)，是一种在许多实际应用中非常重要的计数过程。目前，文献中几乎所有的工作都致力于使用非数据驱动的分箱方法对具有无穷数据的NHPP进行估计。本文将有限和有限数据下的NHPP估计问题公式化为一个学习泛化问题。我们在数学上证明，尽管分箱方法对于估计NHPPs很重要，但在数据量有限时会带来过拟合的风险。我们提出了一个正则化学习NHPPs的框架，其中包括两种新的自适应和数据驱动的分箱方法，帮助消除分箱参数的即兴调整。我们在合成和实际数据集上对我们的方法进行了实验证明了其有效性。

    arXiv:2402.12808v1 Announce Type: new  Abstract: The Poisson process, especially the nonhomogeneous Poisson process (NHPP), is an essentially important counting process with numerous real-world applications. Up to date, almost all works in the literature have been on the estimation of NHPPs with infinite data using non-data driven binning methods. In this paper, we formulate the problem of estimation of NHPPs from finite and limited data as a learning generalization problem. We mathematically show that while binning methods are essential for the estimation of NHPPs, they pose a threat of overfitting when the amount of data is limited. We propose a framework for regularized learning of NHPPs with two new adaptive and data-driven binning methods that help to remove the ad-hoc tuning of binning parameters. Our methods are experimentally tested on synthetic and real-world datasets and the results show their effectiveness.
    
[^13]: 在奇异性下的学习：改进WBIC和sBIC的信息准则

    Learning under Singularity: An Information Criterion improving WBIC and sBIC

    [https://arxiv.org/abs/2402.12762](https://arxiv.org/abs/2402.12762)

    LS信息准则旨在增强WBIC和sBIC的功能，有效处理非正则情况，具有稳定性，为奇异情况下的信息准则提供了新的方法

    

    我们介绍了一种新颖的信息准则（IC），称为在奇异性下的学习（LS），旨在增强广泛适用的贝叶斯信息准则（WBIC）和奇异贝叶斯信息准则（sBIC）的功能。 LS在没有正则性约束的情况下是有效的，并表现出稳定性。Watanabe定义了一个统计模型或学习机器为正则，如果从参数到概率分布的映射是一对一的，并且其Fisher信息矩阵是正定的。相反，不符合这些条件的模型被称为奇异。 在过去的十年中，已经提出了几种奇异情况下的信息准则，包括WBIC和sBIC。 WBIC适用于非正则情况，但在样本量很大且已知学习系数估计冗余时面临挑战。 相反，sBIC在广泛应用方面存在限制，因为它依赖于最大似然估计。

    arXiv:2402.12762v1 Announce Type: cross  Abstract: We introduce a novel Information Criterion (IC), termed Learning under Singularity (LS), designed to enhance the functionality of the Widely Applicable Bayes Information Criterion (WBIC) and the Singular Bayesian Information Criterion (sBIC). LS is effective without regularity constraints and demonstrates stability. Watanabe defined a statistical model or a learning machine as regular if the mapping from a parameter to a probability distribution is one-to-one and its Fisher information matrix is positive definite. In contrast, models not meeting these conditions are termed singular. Over the past decade, several information criteria for singular cases have been proposed, including WBIC and sBIC. WBIC is applicable in non-regular scenarios but faces challenges with large sample sizes and redundant estimation of known learning coefficients. Conversely, sBIC is limited in its broader application due to its dependence on maximum likelihood
    
[^14]: 扩散后验抽样在计算上是难以解决的

    Diffusion Posterior Sampling is Computationally Intractable

    [https://arxiv.org/abs/2402.12727](https://arxiv.org/abs/2402.12727)

    我们证明了后验抽样在计算上是难以解决的：在加密学中最基本的假设下——单向函数存在的假设下，存在一些实例，对于这些实例，每个算法都需要超多项式时间，即使无条件抽样可以证明是快速的。

    

    扩散模型是学习和从分布$p(x)$中抽样的一种非常有效的方法。在后验抽样中，人们还会给出一个测量模型$p(y \mid x)$和一个测量$y$，希望从$p(x \mid y)$中抽样。后验抽样对于诸如修补、超分辨率和MRI重建等任务非常有用，因此一些最近的工作已经给出了启发式近似算法；但没有一个已知能在多项式时间内收敛到正确的分布。

    arXiv:2402.12727v1 Announce Type: cross  Abstract: Diffusion models are a remarkably effective way of learning and sampling from a distribution $p(x)$. In posterior sampling, one is also given a measurement model $p(y \mid x)$ and a measurement $y$, and would like to sample from $p(x \mid y)$. Posterior sampling is useful for tasks such as inpainting, super-resolution, and MRI reconstruction, so a number of recent works have given algorithms to heuristically approximate it; but none are known to converge to the correct distribution in polynomial time.   In this paper we show that posterior sampling is \emph{computationally intractable}: under the most basic assumption in cryptography -- that one-way functions exist -- there are instances for which \emph{every} algorithm takes superpolynomial time, even though \emph{unconditional} sampling is provably fast. We also show that the exponential-time rejection sampling algorithm is essentially optimal under the stronger plausible assumption 
    
[^15]: 具有统一最后迭代保证的赌博算法实现接近最优遗憾

    Achieving Near-Optimal Regret for Bandit Algorithms with Uniform Last-Iterate Guarantee

    [https://arxiv.org/abs/2402.12711](https://arxiv.org/abs/2402.12711)

    本文引入了统一最后迭代(ULI)保证这一更强的性能度量，同时证明接近最优的ULI保证直接导致了在各种性能度量上接近最优的累积性能。

    

    现有的赌博算法性能度量，如遗憾、PAC界限或统一PAC(Dann等人，2017)，通常评估累积性能，同时允许在任意有限时间t内玩弱劣的臂。这种行为在高风险应用中可能造成严重损失。本文介绍了一种更强的性能度量，统一最后迭代(ULI)保证，捕捉赌博算法的累积和瞬时性能。具体来说，ULI表征了瞬时性能，因为它确保所玩弱劣臂的每轮遗憾受到一个函数的限制，该函数随着（大）轮次t单调递减，在有足够样本可用时防止重复访问劣质臂。我们证明，接近最优的ULI保证直接意味着在上述性能度量中实现接近最优的累积性能。为了研究ULI在有限臂集上的可达性

    arXiv:2402.12711v1 Announce Type: new  Abstract: Existing performance measures for bandit algorithms such as regret, PAC bounds, or uniform-PAC (Dann et al., 2017), typically evaluate the cumulative performance, while allowing the play of an arbitrarily bad arm at any finite time t. Such a behavior can be highly detrimental in high-stakes applications. This paper introduces a stronger performance measure, the uniform last-iterate (ULI) guarantee, capturing both cumulative and instantaneous performance of bandit algorithms. Specifically, ULI characterizes the instantaneous performance since it ensures that the per-round regret of the played arm is bounded by a function, monotonically decreasing w.r.t. (large) round t, preventing revisits to bad arms when sufficient samples are available. We demonstrate that a near-optimal ULI guarantee directly implies near-optimal cumulative performance across aforementioned performance measures. To examine the achievability of ULI in the finite arm se
    
[^16]: 在因果推断中整合干预学习：在线实验中一种新颖方法

    Integrating Active Learning in Causal Inference with Interference: A Novel Approach in Online Experiments

    [https://arxiv.org/abs/2402.12710](https://arxiv.org/abs/2402.12710)

    这项研究通过引入主动学习方法ACI，专注于在网络干扰和非随机处理分配情况下估计直接和溢出处理效应。

    

    在因果推断研究领域中，普遍的潜在结果框架，尤其是鲁宾因果模型（RCM），通常忽视个体干扰并假设独立处理效应。然而，这一假设经常与现实世界场景的复杂现实不符，干扰不仅仅是可能性，而且是常见现象。我们的研究旨在通过专注于在两种假设下估计直接和溢出处理效应来解决这一差异：（1）基于网络的干扰，其中连接网络内邻居的处理会影响一个人的结果，以及（2）受混杂因素影响的非随机处理分配。为了提高估计可能复杂效果函数的效率，我们引入了一种新颖的主动学习方法: 交互干预因果推断中的主动学习（ACI）。这种方法利用高斯过程灵活地mo

    arXiv:2402.12710v1 Announce Type: cross  Abstract: In the domain of causal inference research, the prevalent potential outcomes framework, notably the Rubin Causal Model (RCM), often overlooks individual interference and assumes independent treatment effects. This assumption, however, is frequently misaligned with the intricate realities of real-world scenarios, where interference is not merely a possibility but a common occurrence. Our research endeavors to address this discrepancy by focusing on the estimation of direct and spillover treatment effects under two assumptions: (1) network-based interference, where treatments on neighbors within connected networks affect one's outcomes, and (2) non-random treatment assignments influenced by confounders. To improve the efficiency of estimating potentially complex effects functions, we introduce an novel active learning approach: Active Learning in Causal Inference with Interference (ACI). This approach uses Gaussian process to flexibly mo
    
[^17]: 在流形上学习而无需流形学习

    Learning on manifolds without manifold learning

    [https://arxiv.org/abs/2402.12687](https://arxiv.org/abs/2402.12687)

    提出了一种无需流形学习的在流形上学习方法，通过一次性构造获得最佳误差界限。

    

    从未知分布随机抽样的数据进行函数逼近是机器学习中的一个重要问题。与通过最小化损失函数来解决这个问题的盛行范式相反，我们给出了一种直接的一次性构造方法，并在流形假设下给出了最佳误差界限；即假设数据是从高维欧几里得空间的未知子流形中抽样得到的。 Neural Networks 132:253268, 2020 中，我们提出了一个一次性直接方法来实现函数逼近。

    arXiv:2402.12687v1 Announce Type: new  Abstract: Function approximation based on data drawn randomly from an unknown distribution is an important problem in machine learning. In contrast to the prevalent paradigm of solving this problem by minimizing a loss functional, we have given a direct one-shot construction together with optimal error bounds under the manifold assumption; i.e., one assumes that the data is sampled from an unknown sub-manifold of a high dimensional Euclidean space. A great deal of research deals with obtaining information about this manifold, such as the eigendecomposition of the Laplace-Beltrami operator or coordinate charts, and using this information for function approximation. This two step approach implies some extra errors in the approximation stemming from basic quantities of the data in addition to the errors inherent in function approximation. In Neural Networks, 132:253268, 2020, we have proposed a one-shot direct method to achieve function approximation
    
[^18]: 随机化既可以减少偏差又可以减少方差：随机森林的案例研究

    Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests

    [https://arxiv.org/abs/2402.12668](https://arxiv.org/abs/2402.12668)

    随机森林相对于装袋法具有减少偏差的能力，在揭示数据模式和高信噪比情况下表现更好的特点，为随机森林在不同信噪比环境下的成功提供了解释和实用见解。

    

    我们研究了往往被忽视的现象，首次在\cite{breiman2001random}中指出，即随机森林似乎比装袋法减少了偏差。受\cite{mentch2020randomization}一篇有趣的论文的启发，其中作者认为随机森林减少了有效自由度，并且只有在低信噪比（SNR）环境下才能胜过装袋集成，我们探讨了随机森林如何能够揭示被装袋法忽视的数据模式。我们在实证中证明，在存在这种模式的情况下，随机森林不仅可以减小偏差还能减小方差，并且当信噪比高时随机森林的表现愈发好于装袋集成。我们的观察为解释随机森林在各种信噪比情况下的真实世界成功提供了见解，并增进了我们对随机森林与装袋集成在每次分割注入的随机化方面的差异的理解。我们的调查结果还提供了实用见解。

    arXiv:2402.12668v1 Announce Type: cross  Abstract: We study the often overlooked phenomenon, first noted in \cite{breiman2001random}, that random forests appear to reduce bias compared to bagging. Motivated by an interesting paper by \cite{mentch2020randomization}, where the authors argue that random forests reduce effective degrees of freedom and only outperform bagging ensembles in low signal-to-noise ratio (SNR) settings, we explore how random forests can uncover patterns in the data missed by bagging. We empirically demonstrate that in the presence of such patterns, random forests reduce bias along with variance and increasingly outperform bagging ensembles when SNR is high. Our observations offer insights into the real-world success of random forests across a range of SNRs and enhance our understanding of the difference between random forests and bagging ensembles with respect to the randomization injected into each split. Our investigations also yield practical insights into the 
    
[^19]: FAST: 一种用于快速透明机器学习中快速附加分割的优化框架

    FAST: An Optimization Framework for Fast Additive Segmentation in Transparent ML

    [https://arxiv.org/abs/2402.12630](https://arxiv.org/abs/2402.12630)

    FAST框架通过快速分段形状函数的优化和新的特征选择算法，使得透明的附加模型的拟合速度比现有方法快2个数量级。

    

    我们提出了FAST，一种用于快速附加分割的优化框架。FAST为数据集中的每个特征分段常数形状函数，以产生透明的附加模型。该框架利用一种新颖的优化过程适配这些模型，速度比现有最先进的方法，如可解释性增强机器 \citep{nori2019interpretml}，快约2个数量级。我们还在FAST框架中开发了新的特征选择算法，以适配性能良好的简约模型。通过实验证明，FAST提高了附加模型的计算效率和可解释性。

    arXiv:2402.12630v1 Announce Type: cross  Abstract: We present FAST, an optimization framework for fast additive segmentation. FAST segments piecewise constant shape functions for each feature in a dataset to produce transparent additive models. The framework leverages a novel optimization procedure to fit these models $\sim$2 orders of magnitude faster than existing state-of-the-art methods, such as explainable boosting machines \citep{nori2019interpretml}. We also develop new feature selection algorithms in the FAST framework to fit parsimonious models that perform well. Through experiments and case studies, we show that FAST improves the computational efficiency and interpretability of additive models.
    
[^20]: 多类别时间逻辑神经网络

    Multi-class Temporal Logic Neural Networks

    [https://arxiv.org/abs/2402.12397](https://arxiv.org/abs/2402.12397)

    提出了一种结合神经网络和信号时间逻辑的方法，用于多类别时间序列数据的分类，关键贡献包括引入边界概念和利用STL属性增强结果的可解释性。

    

    时间序列数据可以代表无人系统（如无人机和自动驾驶汽车）的行为。在这一领域，二元和多类别分类问题受到了广泛关注。神经网络是一种流行的分类数据的方法；然而，它们缺乏可解释性，这在从中提取有意义的信息方面构成了重要挑战。信号时间逻辑（STL）是一种描述定时行为属性的形式化语言。我们提出了一种将所有这些元素结合在一起的方法：使用表示STL规范的神经网络进行时间序列数据的多类别分类。我们提供了两个关键贡献：1）我们引入了多类别分类的边界概念，2）我们引入了基于STL的属性来增强结果的可解释性。我们在两个数据集上评估了我们的方法，并与最先进的基准进行了比较。

    arXiv:2402.12397v1 Announce Type: cross  Abstract: Time-series data can represent the behaviors of autonomous systems, such as drones and self-driving cars. The problem of binary and multi-class classification has received a lot of attention in this field. Neural networks represent a popular approach to classifying data; However, they lack interpretability, which poses a significant challenge in extracting meaningful information from them. Signal Temporal Logic (STL) is a formalism to describe the properties of timed behaviors. We propose a method that combines all of the above: neural networks that represent STL specifications for multi-class classification of time-series data. We offer two key contributions: 1) We introduce a notion of margin for multi-class classification, and 2) we introduce the use of STL-based attributes for enhancing the interpretability of the results. We evaluate our method on two datasets and compare with state-of-the-art baselines.
    
[^21]: 使用不同标注函数的协作学习

    Collaborative Learning with Different Labeling Functions

    [https://arxiv.org/abs/2402.10445](https://arxiv.org/abs/2402.10445)

    研究了使用不同标注函数的协作学习中，基于经验风险最小化算法在增强假设类上的高效学习方法。

    

    我们研究了一种 Collaborative PAC Learning 的变体，在这种情况下，我们旨在学习每个$n$个数据分布的准确分类器，同时最小化从它们总共抽取的样本数量。与通常的协作学习设置不同，不假设存在一个同时对所有分布准确的单一分类器。我们表明，当数据分布满足较弱的可实现性假设时，仍然可以实现高效的学习。我们给出了一种基于经验风险最小化(ERM)的学习算法，应用于假设类的一个自然增强，分析依赖于对该增强类的VC维的上界。

    arXiv:2402.10445v1 Announce Type: new  Abstract: We study a variant of Collaborative PAC Learning, in which we aim to learn an accurate classifier for each of the $n$ data distributions, while minimizing the number of samples drawn from them in total. Unlike in the usual collaborative learning setup, it is not assumed that there exists a single classifier that is simultaneously accurate for all distributions.   We show that, when the data distributions satisfy a weaker realizability assumption, sample-efficient learning is still feasible. We give a learning algorithm based on Empirical Risk Minimization (ERM) on a natural augmentation of the hypothesis class, and the analysis relies on an upper bound on the VC dimension of this augmented class.   In terms of the computational efficiency, we show that ERM on the augmented hypothesis class is NP-hard, which gives evidence against the existence of computationally efficient learners in general. On the positive side, for two special cases, 
    
[^22]: 有限预算下的迅速学习最佳臂识别

    Best Arm Identification for Prompt Learning under a Limited Budget

    [https://arxiv.org/abs/2402.09723](https://arxiv.org/abs/2402.09723)

    这项工作提出了一种在提示学习中考虑有限预算约束的方法，通过建立提示学习和多臂赌博机中固定预算最佳臂识别之间的联系，提出了一个通用框架TRIPLE，通过利用聚类和嵌入思想实现了两个增强方法。

    

    大型语言模型（LLMs）的显著指令跟随能力引发了对自动学习合适提示的兴趣。然而，虽然提出了许多有效的方法，但在学习过程中产生的成本（例如访问LLM和评估响应）尚未得到考虑。为克服这个限制，本工作在提示学习中明确引入了有限预算约束。为了开发有原则的解决方案，本研究在提示学习和多臂赌博机的固定预算最佳臂识别（BAI-FB）之间建立了一种新的联系。基于这种联系，提出了一个通用框架TRIPLE（用于提示学习的最佳臂识别），以系统地利用BAI-FB在提示学习中的力量。提示学习的独特特点进一步通过利用聚类和嵌入思想提出了TRIPLE的两个基于嵌入的增强方法。

    arXiv:2402.09723v1 Announce Type: cross  Abstract: The remarkable instruction-following capability of large language models (LLMs) has sparked a growing interest in automatically learning suitable prompts. However, while many effective methods have been proposed, the cost incurred during the learning process (e.g., accessing LLM and evaluating the responses) has not been considered. To overcome this limitation, this work explicitly incorporates a finite budget constraint into prompt learning. Towards developing principled solutions, a novel connection is established between prompt learning and fixed-budget best arm identification (BAI-FB) in multi-armed bandits (MAB). Based on this connection, a general framework TRIPLE (besT aRm Identification for Prompt LEarning) is proposed to harness the power of BAI-FB in prompt learning systematically. Unique characteristics of prompt learning further lead to two embedding-based enhancements of TRIPLE by exploiting the ideas of clustering and fun
    
[^23]: 使用次要结果融合个体化治疗规则

    Fusing Individualized Treatment Rules Using Secondary Outcomes

    [https://arxiv.org/abs/2402.08828](https://arxiv.org/abs/2402.08828)

    该论文提出了一种新方法，通过融合次要结果来学习个体化治疗规则(ITR)，既最大化主要结果的价值函数，又尽可能接近次要结果的最优规则。

    

    个体化治疗规则(ITR)是根据患者个体特征变量推荐治疗方案的决策规则。在许多实践中，理想的主要结果的ITR还预计对其他次要结果造成最小的危害。因此，我们的目标是学习一种ITR，它不仅最大化主要结果的价值函数，还尽可能地接近次要结果的最优规则。为了实现这个目标，我们引入了融合惩罚，鼓励基于不同结果的ITR产生类似的推荐。我们提出了两种使用替代损失函数估计ITR的算法。我们证明了主要结果的估计ITR与次要结果的最优ITR之间的一致率收敛比没有考虑次要结果时更快。此外，我们推导出了...

    arXiv:2402.08828v1 Announce Type: cross Abstract: An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the
    
[^24]: Stein Boltzmann抽样：一种全局优化的变分方法

    Stein Boltzmann Sampling: A Variational Approach for Global Optimization

    [https://arxiv.org/abs/2402.04689](https://arxiv.org/abs/2402.04689)

    Stein Boltzmann抽样（SBS）是一种全局优化的变分方法，通过从Boltzmann分布中采样，由Stein Variational Gradient Descent算法实现，具有渐近收敛性，并在各种基准函数上比较了几种最先进的全局优化算法，尤其适合作为高效全局优化方法的延续，能够产生更好的解决方案并有效利用预算。

    

    在本文中，我们介绍了一种新的基于流的方法，用于Lipschitz函数的全局优化，称为Stein Boltzmann抽样（SBS）。我们的方法从Boltzmann分布中采样，该分布在优化函数的最小值集合上渐近均匀。候选解通过Stein Variational Gradient Descent算法进行采样。我们证明了我们方法的渐近收敛性，引入了两种SBS变体，并在各种基准函数上与几种最先进的全局优化算法进行了详细比较。我们方法的设计、理论结果和实验表明，SBS特别适合作为高效全局优化方法的延续，因为它可以在很好地利用预算的同时产生更好的解决方案。

    In this paper, we introduce a new flow-based method for global optimization of Lipschitz functions, called Stein Boltzmann Sampling (SBS). Our method samples from the Boltzmann distribution that becomes asymptotically uniform over the set of the minimizers of the function to be optimized. Candidate solutions are sampled via the \emph{Stein Variational Gradient Descent} algorithm. We prove the asymptotic convergence of our method, introduce two SBS variants, and provide a detailed comparison with several state-of-the-art global optimization algorithms on various benchmark functions. The design of our method, the theoretical results, and our experiments, suggest that SBS is particularly well-suited to be used as a continuation of efficient global optimization methods as it can produce better solutions while making a good use of the budget.
    
[^25]: 在现实假设下的核回归中的泛化

    Generalization in Kernel Regression Under Realistic Assumptions

    [https://arxiv.org/abs/2312.15995](https://arxiv.org/abs/2312.15995)

    本文提供了一个统一的理论，用于对几乎所有常见和现实设置下的核回归的超出风险进行上限约束，并揭示了核分解中存在的自我正则化现象。

    

    现在已经确立的事实是，现代过度参数化模型似乎能够逃避偏差-方差权衡，在过度拟合噪音的情况下泛化良好。许多最近的研究尝试分析这一现象在核回归相对易处理的设置中。然而，正如我们详细讨论的那样，大多数关于这个主题的过去的研究要么做出了不切实际的假设，要么专注于一个狭窄的问题设置。本文旨在提供一个统一的理论来限制几乎所有常见和现实设置下核回归的超出风险。具体来说，我们提供了对于常见核函数以及任意的正则化量、噪声、任意输入维度和任意样本数都成立的严格界限。此外，我们还为核矩阵的特征值提供了相对扰动界限，这可能具有独立的重要性。这些界限揭示了一种自我正则化现象，即核分解的特征值中存在重尾现象。

    arXiv:2312.15995v2 Announce Type: replace-cross  Abstract: It is by now well-established that modern over-parameterized models seem to elude the bias-variance tradeoff and generalize well despite overfitting noise. Many recent works attempt to analyze this phenomenon in the relatively tractable setting of kernel regression. However, as we argue in detail, most past works on this topic either make unrealistic assumptions, or focus on a narrow problem setup. This work aims to provide a unified theory to upper bound the excess risk of kernel regression for nearly all common and realistic settings. Specifically, we provide rigorous bounds that hold for common kernels and for any amount of regularization, noise, any input dimension, and any number of samples. Furthermore, we provide relative perturbation bounds for the eigenvalues of kernel matrices, which may be of independent interest. These reveal a self-regularization phenomenon, whereby a heavy tail in the eigendecomposition of the ker
    
[^26]: 带有固定预算的最佳臂识别：大偏差视角

    Best Arm Identification with Fixed Budget: A Large Deviation Perspective

    [https://arxiv.org/abs/2312.12137](https://arxiv.org/abs/2312.12137)

    本文通过建立经验比例和经验臂奖励之间的连接，提高了一些现有算法的错误概率上界。

    

    我们考虑使用固定抽样预算在随机多臂老虎机(MABs)中识别最佳臂的问题。表征该问题的最小特定实例误差概率构成MABs中一直存在的重要开放问题之一。当使用静态抽样策略选择臂时，错误概率随着样本数呈指数衰减，其速率可以通过大偏差技术明确推导。然而，分析具有自适应抽样策略的算法的性能要困难得多。在本文中，我们建立了通过经验比例满足的大偏差原理(LDP)和通过经验臂奖励满足的LDP之间的连接。这种连接适用于任何自适应算法，并被利用来( i ) 提高某些现有算法的错误概率上界，例如著名的\sr (Successive Re

    arXiv:2312.12137v2 Announce Type: replace  Abstract: We consider the problem of identifying the best arm in stochastic Multi-Armed Bandits (MABs) using a fixed sampling budget. Characterizing the minimal instance-specific error probability for this problem constitutes one of the important remaining open problems in MABs. When arms are selected using a static sampling strategy, the error probability decays exponentially with the number of samples at a rate that can be explicitly derived via Large Deviation techniques. Analyzing the performance of algorithms with adaptive sampling strategies is however much more challenging. In this paper, we establish a connection between the Large Deviation Principle (LDP) satisfied by the empirical proportions of arm draws and that satisfied by the empirical arm rewards. This connection holds for any adaptive algorithm, and is leveraged (i) to improve error probability upper bounds of some existing algorithms, such as the celebrated \sr (Successive Re
    
[^27]: 在差分隐私的添加-删除模型中的均值估计

    Mean estimation in the add-remove model of differential privacy

    [https://arxiv.org/abs/2312.06658](https://arxiv.org/abs/2312.06658)

    该论文研究了在差分隐私的添加-删除模型中的一维均值估计问题，并提出了一个新算法，证明其在均方误差中达到最佳常数，该常数与交换模型下的最优算法相同。

    

    差分隐私通常在两种不同的相邻数据集模型下研究：添加-删除模型和交换模型。虽然交换模型经常在学术文献中用于简化分析，但许多实际应用依赖更保守的添加-删除模型，其中获得紧密结果可能很困难。在这里，我们研究了添加-删除模型下的一维均值估计问题。我们提出了一种新算法，并表明它是最小-最大最优的，在所有$\epsilon$的均方误差的主导项中实现了最佳常数，而且这个常数与交换模型下的最优算法是相同的。这些结果表明，添加-删除模型和交换模型对于均值估计给出了几乎相同的误差，尽管添加-删除模型无法处理数据集的大小作为公共信息。我们还经验性地证明了我们提出的算法

    arXiv:2312.06658v2 Announce Type: replace-cross  Abstract: Differential privacy is often studied under two different models of neighboring datasets: the add-remove model and the swap model. While the swap model is frequently used in the academic literature to simplify analysis, many practical applications rely on the more conservative add-remove model, where obtaining tight results can be difficult. Here, we study the problem of one-dimensional mean estimation under the add-remove model. We propose a new algorithm and show that it is min-max optimal, achieving the best possible constant in the leading term of the mean squared error for all $\epsilon$, and that this constant is the same as the optimal algorithm under the swap model. These results show that the add-remove and swap models give nearly identical errors for mean estimation, even though the add-remove model cannot treat the size of the dataset as public information. We also demonstrate empirically that our proposed algorithm 
    
[^28]: 使用推前映射进行各地采样

    Touring sampling with pushforward maps

    [https://arxiv.org/abs/2311.13845](https://arxiv.org/abs/2311.13845)

    该论文从理论角度对生成建模中的多种采样方法进行了审视和组织，帮助克服采样中的一些挑战，比如推理时间长和生成样本缺乏多样性。

    

    对于一个希望将强大的机器学习方法应用于特定问题的从业者来说，采样方法的数量可能令人生畏。本文从理论角度出发，对在“生成建模”设置中许多采样方法进行了审视和组织，其中希望生成与一些训练样本类似的新数据。通过揭示现有方法之间的联系，可能有助于克服与扩散模型采样相关的一些当前挑战，比如由于扩散模拟而导致的长推理时间，或者生成样本缺乏多样性。

    arXiv:2311.13845v2 Announce Type: replace-cross  Abstract: The number of sampling methods could be daunting for a practitioner looking to cast powerful machine learning methods to their specific problem. This paper takes a theoretical stance to review and organize many sampling approaches in the ``generative modeling'' setting, where one wants to generate new data that are similar to some training examples. By revealing links between existing methods, it might prove useful to overcome some of the current challenges in sampling with diffusion models, such as long inference time due to diffusion simulation, or the lack of diversity in generated samples.
    
[^29]: 自回归赌博机

    Autoregressive Bandits

    [https://arxiv.org/abs/2212.06251](https://arxiv.org/abs/2212.06251)

    在自回归过程控制的奖励下，提出了自回归赌博机（ARBs）在线学习设置，并设计了AutoRegressive Upper Confidence Bound (AR-UCB)算法，可以方便计算最优策略并具有次线性遗憾。

    

    自回归过程在股票市场、销售预测、天气预测、广告和定价等各种实际场景中自然而然地出现。在面对这样的序贯决策问题时，应该正确考虑连续观测之间的时间依赖性，以保证收敛到最优策略。在这项工作中，我们提出了一种新颖的在线学习设置，即自回归赌博机（ARBs），其中观测到的奖励由一个阶数为$k$的自回归过程控制，其参数取决于选择的动作。我们证明，在对奖励过程进行温和假设的情况下，最优策略可以方便地计算出来。然后，我们设计了一种新的乐观遗憾最小化算法，即自回归上置信界（AR-UCB），其遗憾呈现出次线性的阶数$\widetilde{\mathcal{O}} \left( \frac{(k+1)^{3/2}\sqrt{nT}}{(1-\Gamma)^

    arXiv:2212.06251v2 Announce Type: replace  Abstract: Autoregressive processes naturally arise in a large variety of real-world scenarios, including stock markets, sales forecasting, weather prediction, advertising, and pricing. When facing a sequential decision-making problem in such a context, the temporal dependence between consecutive observations should be properly accounted for guaranteeing convergence to the optimal policy. In this work, we propose a novel online learning setting, namely, Autoregressive Bandits (ARBs), in which the observed reward is governed by an autoregressive process of order $k$, whose parameters depend on the chosen action. We show that, under mild assumptions on the reward process, the optimal policy can be conveniently computed. Then, we devise a new optimistic regret minimization algorithm, namely, AutoRegressive Upper Confidence Bound (AR-UCB), that suffers sublinear regret of order $\widetilde{\mathcal{O}} \left( \frac{(k+1)^{3/2}\sqrt{nT}}{(1-\Gamma)^
    
[^30]: 在线社交媒体审计的数学框架

    Mathematical Framework for Online Social Media Auditing

    [https://arxiv.org/abs/2209.05550](https://arxiv.org/abs/2209.05550)

    研究提出了一个数学框架，探讨了社交媒体平台上算法过滤的不良影响以及监管复杂性。

    

    社交媒体平台（SMPs）利用算法过滤（AF）来选择构成用户信息流的内容，旨在最大化奖励。有选择地选择要显示在用户信息流中的内容可能会在一定程度上，无论是较小还是较大，对用户的决策产生影响，与在自然/公平内容选择下会产生的影响相比。正如我们在过去的十年中所见，算法过滤可能导致有害的副作用，从偏见个人决定到塑造整个社会的决定，例如，将用户注意力从是否接种COVID-19疫苗转移或诱使公众选择总统候选人。政府常常试图监管AF的不良影响，但往往因官僚主义、法律事务和财务考虑而变得复杂。另一方面，SMPs寻求监测他们自己的算

    arXiv:2209.05550v2 Announce Type: replace  Abstract: Social media platforms (SMPs) leverage algorithmic filtering (AF) as a means of selecting the content that constitutes a user's feed with the aim of maximizing their rewards. Selectively choosing the contents to be shown on the user's feed may yield a certain extent of influence, either minor or major, on the user's decision-making, compared to what it would have been under a natural/fair content selection. As we have witnessed over the past decade, algorithmic filtering can cause detrimental side effects, ranging from biasing individual decisions to shaping those of society as a whole, for example, diverting users' attention from whether to get the COVID-19 vaccine or inducing the public to choose a presidential candidate. The government's constant attempts to regulate the adverse effects of AF are often complicated, due to bureaucracy, legal affairs, and financial considerations. On the other hand SMPs seek to monitor their own alg
    
[^31]: 人类反馈的迭代偏好学习：在KL约束下将理论与实践联系起来的RLHF

    Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint. (arXiv:2312.11456v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11456](http://arxiv.org/abs/2312.11456)

    该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。

    

    本文研究了生成模型与强化学习从人类反馈中的对齐过程的理论框架。我们考虑了一个标准的数学表达式，即反向KL正则化的上下文多臂赌博机用于RLHF。尽管它被广泛应用于实际应用，但对这个公式的严格理论分析仍然很开放。我们研究了它在离线、在线和混合三种不同场景下的行为，并提出了具有有限样本理论保证的高效算法。朝着实际应用的方向，我们的框架通过对信息理论策略改进预言的稳健近似，自然地产生了几种新颖的RLHF算法。这包括在线场景中的迭代版本的直接偏好优化(DPO)算法，以及离线情景下的多步拒绝抽样策略。我们对大型语言模型的真实对齐实验进行了实证评估。

    This paper studies the theoretical framework of the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees.  Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate t
    
[^32]: 添加和稀疏：一种用于时间点过程的扩散方法

    Add and Thin: Diffusion for Temporal Point Processes. (arXiv:2311.01139v1 [cs.LG])

    [http://arxiv.org/abs/2311.01139](http://arxiv.org/abs/2311.01139)

    本研究提出了一种基于概率去噪扩散模型的时间点过程模型，相比于现有的方法，该模型在预测方面取得了较好的性能，对具有离散和连续成分的数据具有处理能力。

    

    在时间点过程（TPP）框架内，自回归神经网络已成为建模连续时间事件数据的标准。尽管这些模型可以以一步预测的方式精确地捕捉事件序列，但由于其顺序性质引起的误差积累，它们在长期预测应用中具有固有的局限性。为了克服这些限制，我们推导出ADD-THIN，一种面向整个事件序列工作的基于概率去噪扩散模型，它自然地处理具有离散和连续成分的数据。在合成和真实数据集的实验中，我们的模型在密度估计方面与最先进的TPP模型相匹配，并在预测方面表现出色。

    Autoregressive neural networks within the temporal point process (TPP) framework have become the standard for modeling continuous-time event data. Even though these models can expressively capture event sequences in a one-step-ahead fashion, they are inherently limited for long-term forecasting applications due to the accumulation of errors caused by their sequential nature. To overcome these limitations, we derive ADD-THIN, a principled probabilistic denoising diffusion model for TPPs that operates on entire event sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles data with discrete and continuous components. In experiments on synthetic and real-world datasets, our model matches the state-of-the-art TPP models in density estimation and strongly outperforms them in forecasting.
    
[^33]: 网格细胞中的循环神经网络中的共形归一化

    Conformal Normalization in Recurrent Neural Network of Grid Cells. (arXiv:2310.19192v1 [q-bio.NC])

    [http://arxiv.org/abs/2310.19192](http://arxiv.org/abs/2310.19192)

    本文提出了一种循环神经网络中的共形归一化方法，用于处理网格细胞在2D物理空间中的自我位置信息。实验结果表明，该方法能够显著减小位置误差。

    

    哺乳动物大脑中颞叶皮层的网格细胞在2D开放环境中以惊人的六角形发射模式展示出反应图。网格细胞群体的反应在高维神经活动空间中形成一个向量，这个向量表示代理在2D物理空间中的自我位置。当代理移动时，这个向量被一个循环神经网络转换，该网络将代理的速度作为输入。本文中，我们提出了对循环神经网络输入速度进行简单而通用的共形归一化，使得高维神经空间中位置向量的局部位移与2D物理空间中代理的局部位移成比例，无论输入速度的方向如何。我们在最简单的线性和非线性循环网络上进行了数值实验，结果显示共形归一化导致数量级较小的位置误差。

    Grid cells in the entorhinal cortex of the mammalian brain exhibit striking hexagon firing patterns in their response maps as the animal (e.g., a rat) navigates in a 2D open environment. The responses of the population of grid cells collectively form a vector in a high-dimensional neural activity space, and this vector represents the self-position of the agent in the 2D physical space. As the agent moves, the vector is transformed by a recurrent neural network that takes the velocity of the agent as input. In this paper, we propose a simple and general conformal normalization of the input velocity for the recurrent neural network, so that the local displacement of the position vector in the high-dimensional neural space is proportional to the local displacement of the agent in the 2D physical space, regardless of the direction of the input velocity. Our numerical experiments on the minimally simple linear and non-linear recurrent networks show that conformal normalization leads to the 
    
[^34]: 上下文定向无环图

    Contextual directed acyclic graphs. (arXiv:2310.15627v1 [stat.ML])

    [http://arxiv.org/abs/2310.15627](http://arxiv.org/abs/2310.15627)

    本论文研究了上下文定向无环图的问题，通过神经网络将上下文特征映射到DAG，利用稀疏的加权邻接矩阵表示图结构，并通过新颖的投影层满足无环性的特点。实验证明该方法能够成功恢复出真实的上下文特定图。

    

    从观测数据中估计定向无环图（DAG）的结构仍然是机器学习中的一个重大挑战。这个领域的大部分研究集中在为整个人口学习单个DAG上。本文考虑了一个替代性的设置，其中图结构基于可用的“上下文”特征而因人而异。我们通过一个将上下文特征映射到DAG的神经网络来解决这个上下文DAG问题，DAG以加权邻接矩阵表示。神经网络配备了一个新颖的投影层，确保输出矩阵是稀疏的，并满足最近发展的无环性的特点。我们设计了一个可扩展的计算框架来学习上下文DAG，并提供了收敛保证和通过投影层反向传播的分析梯度。我们的实验证明，这种新方法可以恢复出真实的上下文特定图，而现有方法则失败。

    Estimating the structure of directed acyclic graphs (DAGs) from observational data remains a significant challenge in machine learning. Most research in this area concentrates on learning a single DAG for the entire population. This paper considers an alternative setting where the graph structure varies across individuals based on available "contextual" features. We tackle this contextual DAG problem via a neural network that maps the contextual features to a DAG, represented as a weighted adjacency matrix. The neural network is equipped with a novel projection layer that ensures the output matrices are sparse and satisfy a recently developed characterization of acyclicity. We devise a scalable computational framework for learning contextual DAGs and provide a convergence guarantee and an analytical gradient for backpropagating through the projection layer. Our experiments suggest that the new approach can recover the true context-specific graph where existing approaches fail.
    
[^35]: 多臂赌博策略对深度循环强化学习的影响

    Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])

    [http://arxiv.org/abs/2310.08331](http://arxiv.org/abs/2310.08331)

    本研究在自动驾驶场景中使用部分可观测系统，通过部署和测试多种技术来平衡探索和利用的权衡，以预测方向盘操作。

    

    对环境的不完全了解导致智能体在不确定性下做出决策。强化学习中一个重要的困境是，在做出决策时，智能体需要在利用当前环境知识最大化累积奖励和探索行动以提高环境知识的之间进行权衡（探索-利用的平衡）。同时，另一个相关问题是状态的完全可观测性，不是所有应用都能假定。例如，当只将2D图像作为输入用于在3D模拟环境中找到最佳行动时，就存在这个问题。在本研究中，我们通过部署和测试多种技术来解决部分可观测系统中探索和利用的平衡问题，以预测自动驾驶场景中的方向盘操作。

    Incomplete knowledge of the environment leads an agent to make decisions under uncertainty. One of the major dilemmas in Reinforcement Learning (RL) where an autonomous agent has to balance two contrasting needs in making its decisions is: exploiting the current knowledge of the environment to maximize the cumulative reward as well as exploring actions that allow improving the knowledge of the environment, hopefully leading to higher reward values (exploration-exploitation trade-off). Concurrently, another relevant issue regards the full observability of the states, which may not be assumed in all applications. Such as when only 2D images are considered as input in a RL approach used for finding the optimal action within a 3D simulation environment. In this work, we address these issues by deploying and testing several techniques to balance exploration and exploitation trade-off on partially observable systems for predicting steering wheels in autonomous driving scenario. More precisel
    
[^36]: SWoTTeD:张量分解在时间表征中的扩展

    SWoTTeD: An Extension of Tensor Decomposition to Temporal Phenotyping. (arXiv:2310.01201v1 [cs.LG])

    [http://arxiv.org/abs/2310.01201](http://arxiv.org/abs/2310.01201)

    SWoTTeD是一种扩展的张量分解方法，用于发现复杂时间模式下的隐藏表征。在实验中，SWoTTeD不仅能与最新的基于张量分解的方法一样准确地重建数据，还能提取出对临床医生有意义的时间表征。

    

    张量分解最近在机器学习领域对于个体追踪数据的分析，如电子健康记录(EHR)，引起了人们的关注。然而，当数据遵循复杂的时间模式时，这个任务变得更加困难。本文引入了时间表征的概念，即一组随时间变化的特征，并提出了SWoTTeD (Sliding Window for Temporal Tensor Decomposition)方法，一种发现隐藏时间模式的新方法。SWoTTeD集成了多种约束和正则化方法，以增强提取到的表征的可解释性。我们使用合成数据集和真实世界数据集进行验证，并提供了使用巴黎大学医院的数据的原始用例。结果表明，SWoTTeD能够至少与最新的基于张量分解的模型一样准确地重建数据，并提取到对临床医生有意义的时间表征。

    Tensor decomposition has recently been gaining attention in the machine learning community for the analysis of individual traces, such as Electronic Health Records (EHR). However, this task becomes significantly more difficult when the data follows complex temporal patterns. This paper introduces the notion of a temporal phenotype as an arrangement of features over time and it proposes SWoTTeD (Sliding Window for Temporal Tensor Decomposition), a novel method to discover hidden temporal patterns. SWoTTeD integrates several constraints and regularizations to enhance the interpretability of the extracted phenotypes. We validate our proposal using both synthetic and real-world datasets, and we present an original usecase using data from the Greater Paris University Hospital. The results show that SWoTTeD achieves at least as accurate reconstruction as recent state-of-the-art tensor decomposition models, and extracts temporal phenotypes that are meaningful for clinicians.
    
[^37]: 更具表现力的图神经网络在生成任务中是否更好？

    Will More Expressive Graph Neural Networks do Better on Generative Tasks?. (arXiv:2308.11978v1 [cs.LG])

    [http://arxiv.org/abs/2308.11978](http://arxiv.org/abs/2308.11978)

    本论文调查了更具表现力的图神经网络在分子图生成任务中的表现能力，并通过替换图生成模型的基础GNN来进行实验。研究发现，使用更具表现力的GNN可以改善生成任务的性能。

    

    图生成是一个重要的挑战，它涉及根据给定的标签预测一个完整的具有多个节点和边的图。这个任务对许多实际应用非常重要，包括药物和分子设计。近年来，在图生成领域出现了几种成功的方法。然而，这些方法存在两个重大问题：(1) 这些方法中使用的基础图神经网络（GNN）架构往往未经深入探索；(2) 这些方法往往只在有限的指标上进行评估。为填补这个空白，我们通过将图生成模型的基础GNN替换为更具表现力的GNN，研究了GNN在分子图生成任务中的表现能力。具体而言，我们分析了两种不同生成框架（GCPN和GraphAF）中六种GNN在六个不同的分子生成目标上的性能。

    Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZIN
    
[^38]: 决定性混淆下的内核单一代理控制

    Kernel Single Proxy Control for Deterministic Confounding. (arXiv:2308.04585v1 [stat.ML])

    [http://arxiv.org/abs/2308.04585](http://arxiv.org/abs/2308.04585)

    本研究考虑了具有未观测混淆因素的因果效应估计问题，在结果是确定性生成的情况下，提出了一种使用单一代理变量的内核方法，通过两阶段回归和最大矩约束的方法可以一致估计因果效应，并在合成数据集上成功恢复了因果效应。

    

    本文考虑具有未观测混淆因素的因果效应估计问题，其中我们观测到与混淆因素相关的代理变量。尽管代理因果学习（PCL）使用两个代理变量来恢复真实的因果效应，我们证明如果结果是确定性生成的，则使用单个代理变量就足以进行因果估计，并概括了控制结果校准法（COCA）。我们提出了两种基于内核的方法：一种基于两阶段回归方法，另一种基于最大矩约束方法。我们证明了这两种方法都可以一致地估计因果效应，并通过合成数据集的实证实验成功地恢复了因果效应。

    We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
    
[^39]: 火星时间序列分解：一种多尺度嵌套方法中的因子变分自编码器

    Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders. (arXiv:2305.16189v1 [cs.LG])

    [http://arxiv.org/abs/2305.16189](http://arxiv.org/abs/2305.16189)

    该论文提出了一种因子高斯混合变分自动编码器，用于多尺度聚类和源分离，通过利用小波散射协方差来提供随机过程的低维表示，能够区分不同的非高斯随机过程，并在MRO数据集上展现了更好的性能。

    

    无监督的源分离涉及通过混合操作记录的未知源信号的分解，其中对源的先验知识有限，仅可以访问信号混合数据集。这个问题本质上是不适用的，并且进一步受到时间序列数据中源展现出的多种时间尺度的挑战。为了解决这个问题，我们提出了一种无监督的多尺度聚类和源分离框架，通过利用小波散射协方差来提供随机过程的低维表示，能够区分不同的非高斯随机过程。在这个表示空间中，我们开发了一个因子高斯混合变分自动编码器，它被训练用于(1)概率地对不同时间尺度上的源进行聚类和逐层非监督源分离，(2)在每个时间尺度上提取低维表示，(3)学习源信号的因子表示，(4)在表示空间中进行采样，以生成未知源信号。我们在MRO上的三个频道的可见数据集上进行了评估，结果表明所提出的方法比目前最先进的技术具有更好的性能。

    Unsupervised source separation involves unraveling an unknown set of source signals recorded through a mixing operator, with limited prior knowledge about the sources, and only access to a dataset of signal mixtures. This problem is inherently ill-posed and is further challenged by the variety of time-scales exhibited by sources in time series data. Existing methods typically rely on a preselected window size that limits their capacity to handle multi-scale sources. To address this issue, instead of operating in the time domain, we propose an unsupervised multi-scale clustering and source separation framework by leveraging wavelet scattering covariances that provide a low-dimensional representation of stochastic processes, capable of distinguishing between different non-Gaussian stochastic processes. Nested within this representation space, we develop a factorial Gaussian-mixture variational autoencoder that is trained to (1) probabilistically cluster sources at different time-scales a
    
[^40]: 利用Riesz核的生成式分割MMD流

    Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v1 [cs.LG])

    [http://arxiv.org/abs/2305.11463](http://arxiv.org/abs/2305.11463)

    本文使用Riesz核展示了生成式分割MMD流的高效计算方法，实现了在大规模应用中通过神经网络训练生成模型。

    

    在大规模计算中，最大平均差异度(MMD)流的计算成本很高。在本文中，我们展示了使用Riesz核$K(x,y)=-\|x-y\|^r$，$r \in (0,2)$的MMD流具有杰出的性质，可允许其进行高效计算。首先，Riesz核的MMD与其分割版本的MMD重合。因此，可以在一维设置中进行MMD梯度的计算。在此处，对于$r=1$，可以应用简单的排序算法将两个经验度量的复杂度从$O(MN+N^2)$降低到$O((M+N)\log(M+N))$，其中$M$和$N$是支持点。对于实现，我们通过仅使用有限数量的$P$个切片来近似分割MMD的梯度。我们展示了由此产生的误差具有$O(\sqrt{d/P})$的复杂度，其中$d$是数据维度。这些结果使我们能够通过神经网络近似MMD梯度流来训练生成模型，甚至用于大规模应用。

    Maximum mean discrepancy (MMD) flows suffer from high computational costs in large scale computations. In this paper, we show that MMD flows with Riesz kernels $K(x,y) = - \|x-y\|^r$, $r \in (0,2)$ have exceptional properties which allow for their efficient computation. First, the MMD of Riesz kernels coincides with the MMD of their sliced version. As a consequence, the computation of gradients of MMDs can be performed in the one-dimensional setting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce the complexity from $O(MN+N^2)$ to $O((M+N)\log(M+N))$ for two empirical measures with $M$ and $N$ support points. For the implementations we approximate the gradient of the sliced MMD by using only a finite number $P$ of slices. We show that the resulting error has complexity $O(\sqrt{d/P})$, where $d$ is the data dimension. These results enable us to train generative models by approximating MMD gradient flows by neural networks even for large scale applications. We demo
    
[^41]: 一种双层经验风险最小化算法的下界和近似最优算法

    A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.08766](http://arxiv.org/abs/2302.08766)

    该论文提出了一种双层经验风险最小化算法，使用的梯度计算次数 $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$，在样本复杂度方面是最优的。

    

    双层最优化问题越来越多地应用于机器学习中。在许多实际情况下，上层和下层目标对应于经验风险最小化问题，并因此具有总和结构。在这个背景下，我们提出了一个著名的SARAH算法的双层扩展。我们证明了该算法需要$\mathcal {O}((n+m)^{\frac{1}{2}}\varepsilon ^{-1})$次梯度计算才能实现$\varepsilon$稳定性，其中$n+m$是样本总数，这比先前所有的双层算法都要好。此外，我们提供了一个下界，用于得到双层问题的目标函数的近似稳定点所需的oracle调用次数。这个下界正是我们的算法所达到的，因此在样本复杂度方面是最优的。

    Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ gradient computations to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.
    
[^42]: Survival Kernets: 可扩展且可解释的深度核生存分析模型，并具有准确性保证

    Survival Kernets: Scalable and Interpretable Deep Kernel Survival Analysis with an Accuracy Guarantee. (arXiv:2206.10477v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10477](http://arxiv.org/abs/2206.10477)

    Survival Kernets 是一种可扩展且可解释的深度核生存分析模型，能够在大规模数据集上进行模型解释和理论分析。它利用核函数估计个体的生存分布，通过训练集压缩方案进行数据分簇，因此具有较高的可视化能力和预测准确性保证。该模型在特定情况下的预测生存分布误差界限最优，且在测试时具有可扩展性。

    

    核生存分析模型通过核函数来估计个体的生存分布，核函数度量任意两个数据点之间的相似性。我们提出了一种新的深度核生存模型——生存kernet，该模型可以适用于大规模数据集，并且易于解释和进行理论分析。具体而言，训练数据根据一种最近发展的用于分类和回归的训练集压缩方案（称为核群）进行分簇。在测试时，每个数据点被表示为这些簇的加权组合，每个簇可以进行可视化展示。对于生存kernet的一个特殊情况，我们建立了一个有限样本误差界限，预测的生存分布在该界限下是最优的（除去一个对数因子）。在测试时具有可扩展性。

    Kernel survival analysis models estimate individual survival distributions with the help of a kernel function, which measures the similarity between any two data points. Such a kernel function can be learned using deep kernel survival models. In this paper, we present a new deep kernel survival model called a survival kernet, which scales to large datasets in a manner that is amenable to model interpretation and also theoretical analysis. Specifically, the training data are partitioned into clusters based on a recently developed training set compression scheme for classification and regression called kernel netting that we extend to the survival analysis setting. At test time, each data point is represented as a weighted combination of these clusters, and each such cluster can be visualized. For a special case of survival kernets, we establish a finite-sample error bound on predicted survival distributions that is, up to a log factor, optimal. Whereas scalability at test time is achiev
    
[^43]: 批量异步随机逼近的收敛性及在强化学习中的应用

    Convergence of Batch Asynchronous Stochastic Approximation With Applications to Reinforcement Learning. (arXiv:2109.03445v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2109.03445](http://arxiv.org/abs/2109.03445)

    本文提出了一种批量异步随机逼近算法，它可以在内存需求和时间复杂度之间进行权衡，同时提供了可以使用较弱假设证明收敛的一般方法；在强化学习领域，我们使用此方法证明了SARSA算法的批量异步版本的收敛性。

    

    随机逼近（SA）算法是一种广泛使用的概率方法，用于在仅可用函数的有噪测量情况下找到零点或固定点。目前的文献中，区分“同步”更新和“异步”更新，在“同步”更新中，每个猜测的组件都会在每个时间更新，而在“异步”更新中，仅更新一个组件。本文研究了一种中间情况，称为“批量异步随机逼近”（BASA），在这种情况下，每个时间点仅更新“当前估计解”的一些但不是全部的组件。BASA允许用户在内存需求和时间复杂度之间进行权衡。我们开发了一种通用方法，证明此类算法收敛于所研究映射的固定点。这些收敛证明使用比现有结果更弱的假设。具体而言，现有的收敛证明要求步长参数以适当的速率下降。相反，我们仅要求每个组件具有足够的更新频率。我们在强化学习领域展示了我们方法的有用性，证明了广泛使用的SARSA算法的批量异步版本的收敛性。

    The stochastic approximation (SA) algorithm is a widely used probabilistic method for finding a zero or a fixed point of a vector-valued funtion, when only noisy measurements of the function are available. In the literature to date, one makes a distinction between ``synchronous'' updating, whereby every component of the current guess is updated at each time, and ``asynchronous'' updating, whereby only one component is updated. In this paper, we study an intermediate situation that we call ``batch asynchronous stochastic approximation'' (BASA), in which, at each time instant, \textit{some but not all} components of the current estimated solution are updated. BASA allows the user to trade off memory requirements against time complexity. We develop a general methodology for proving that such algorithms converge to the fixed point of the map under study. These convergence proofs make use of weaker hypotheses than existing results. Specifically, existing convergence proofs require that the 
    
[^44]: 深度代理因果学习及其在混淆赌博策略评估中的应用

    Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation. (arXiv:2106.03907v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.03907](http://arxiv.org/abs/2106.03907)

    本论文提出了一种深度代理因果学习（PCL）方法，用于在存在混淆因素的情况下估计治疗对结果的因果效应。通过构建治疗和代理之间的模型，并利用该模型在给定代理的情况下学习治疗对结果的影响，PCL可以保证恢复真实的因果效应。作者还提出了一种名为深度特征代理变量方法（DFPV）的新方法，用于处理高维和非线性复杂关系的情况，并表明DFPV在合成基准测试中的性能优于最先进的PCL方法。

    

    代理因果学习（PCL）是一种在存在未观察到的混淆因素时，利用代理（结构化侧面信息）估计治疗对结果的因果效应的方法。这是通过两阶段回归实现的：在第一阶段，我们建模治疗和代理之间的关系；在第二阶段，我们利用这个模型来学习在给定代理提供的上下文下，治疗对结果的影响。PCL在可识别条件下保证恢复真实的因果效应。我们提出了一种新的PCL方法，深度特征代理变量方法（DFPV），以解决代理、治疗和结果为高维且具有非线性复杂关系的情况，如深度神经网络特征表示。我们表明DFPV在具有挑战性的合成基准测试中优于最近的最先进的PCL方法，包括涉及高维图像数据的设置。此外，我们还展示了PCL的应用...

    Proxy causal learning (PCL) is a method for estimating the causal effect of treatments on outcomes in the presence of unobserved confounding, using proxies (structured side information) for the confounder. This is achieved via two-stage regression: in the first stage, we model relations among the treatment and proxies; in the second stage, we use this model to learn the effect of treatment on the outcome, given the context provided by the proxies. PCL guarantees recovery of the true causal effect, subject to identifiability conditions. We propose a novel method for PCL, the deep feature proxy variable method (DFPV), to address the case where the proxies, treatments, and outcomes are high-dimensional and have nonlinear complex relationships, as represented by deep neural network features. We show that DFPV outperforms recent state-of-the-art PCL methods on challenging synthetic benchmarks, including settings involving high dimensional image data. Furthermore, we show that PCL can be app
    

