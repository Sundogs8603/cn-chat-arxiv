# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Complexity of Sequential Prediction in Dynamical Systems](https://arxiv.org/abs/2402.06614) | 通过学习理论的角度，我们在没有参数假设的情况下，研究了在底层演化函数未知的动力系统中学习预测下一状态的问题，并提出了新的组合度量和维度来量化在可实现和不可知情况下的最佳错误和遗憾界限。 |
| [^2] | [On the Universality of Coupling-based Normalizing Flows](https://arxiv.org/abs/2402.06578) | 我们提出了一个新颖的理论框架，用于理解基于耦合的标准化流的表达能力，并提出了一个新的分布普适性定理来克服以前工作的限制。这些结果支持耦合架构的表达能力，并弥补了实证结果和理论理解之间的差距。 |
| [^3] | [Bandit Convex Optimisation](https://arxiv.org/abs/2402.06535) | 这篇论文介绍了强盗凸优化的基本框架和用于解决这一问题的多种工具。虽然没有太多创新，但通过以新颖的方式应用现有工具，获得了新的算法和改进了一些界限。 |
| [^4] | [Flexible infinite-width graph convolutional networks and the importance of representation learning](https://arxiv.org/abs/2402.06525) | 本文讨论了神经网络高斯过程（NNGP）在理论上的局限，提出图卷积深度内核机（graph convolutional deep kernel machine）来研究图分类任务中的表示学习问题。 |
| [^5] | [Sequential Flow Matching for Generative Modeling](https://arxiv.org/abs/2402.06461) | 本文提出了一种称为SeqRF的新方法，用于通过直线化概率流来减小全局截断误差，并以此加速取样和提高综合质量。 |
| [^6] | [Where is the Truth? The Risk of Getting Confounded in a Continual World](https://arxiv.org/abs/2402.06434) | 这篇论文研究了在一个连续学习环境中遭遇混淆的问题，通过实验证明了传统的连续学习方法无法忽略混淆，需要更强大的方法来处理这个问题。 |
| [^7] | [Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity](https://arxiv.org/abs/2402.06412) | 本文提出了MARINA-P方法，通过引入一系列相关压缩器，优化了服务器到工作节点的通信复杂度。理论分析证明，MARINA-P在算法上优于现有方法，并可以作为支持双向压缩的起点。通过与上行压缩和动量步骤的结合，M3方法实现了双向压缩，并在总通信复杂度上改进。 |
| [^8] | [On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit](https://arxiv.org/abs/2402.06388) | 该论文证明了当学习速率按照逆时间衰减规则时，随机梯度下降（SGD）的收敛速度，并应用于修改的带有L2正则化的策略梯度多臂赌博机（MAB）的收敛性分析。 |
| [^9] | [Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved Decision Trees](https://arxiv.org/abs/2402.06386) | 本研究提出了一种使用提升方法构建多个元树的方法，旨在改进决策树的预测性能。 |
| [^10] | [Optimal estimation of Gaussian (poly)trees](https://arxiv.org/abs/2402.06380) | 该论文开发了最优算法，在学习高斯树和高斯多项式树方面取得了显著成果，并提供了详细的理论保证和实证结果。 |
| [^11] | [Fairness of Exposure in Online Restless Multi-armed Bandits](https://arxiv.org/abs/2402.06348) | 本研究提出了第一个在线的公平RMAB框架，通过将每个臂的拉取与其优势成比例，实现了公平的曝光。算法在单次拉取的公平性遗憾方面取得了次线性的结果$O(\sqrt{T\ln T})$。 |
| [^12] | [How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers](https://arxiv.org/abs/2402.06323) | 在插值神经网络中，均匀随机权重可以产生非均匀偏差，因此通常插值神经网络会与窄教师NN一样很好地泛化。 |
| [^13] | [Particle Denoising Diffusion Sampler](https://arxiv.org/abs/2402.06320) | 本文介绍了一种粒子去噪扩散采样器（PDDS），通过使用原始迭代粒子方案和新颖的得分匹配损失，对非归一化概率密度进行采样和计算规范化常数。与标准的去噪扩散模型不同，PDDS 在温和假设下提供了渐近一致的估计。 |
| [^14] | [Probabilistic Forecasting of Irregular Time Series via Conditional Flows](https://arxiv.org/abs/2402.06293) | 该论文提出了一种使用条件流进行不规则时间序列的概率预测的新模型ProFITi。该模型通过学习条件下未来值的联合分布，对具有缺失值的不规则时间序列进行预测，而不假设底层分布的固定形状。通过引入可逆三角形注意力层和可逆非线性激活函数，该模型取得了良好的实验结果。 |
| [^15] | [Safe Active Learning for Time-Series Modeling with Gaussian Processes](https://arxiv.org/abs/2402.06276) | 本研究提出了一种安全的主动学习方法，用于时间序列建模。通过动态探索输入空间并根据安全要求和过去观察的输入和输出轨迹，我们的方法在现实技术应用中展示了其有效性。 |
| [^16] | [Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models](https://arxiv.org/abs/2402.06223) | 通过潜在部分因果模型，我们展示了多模式对比表示学习在识别潜在耦合变量方面的优秀能力，并揭示了预训练的多模态模型通过线性独立分量分析学习分离表示的潜力。 |
| [^17] | [SMC Is All You Need: Parallel Strong Scaling](https://arxiv.org/abs/2402.06173) | SMC并行扩展方法pSMC具有理论收敛速度，具有有界的时间复杂性和内存要求，适用于贝叶斯推断的问题。 |
| [^18] | [Wasserstein proximal operators describe score-based generative models and resolve memorization](https://arxiv.org/abs/2402.06162) | 该论文研究了基于分数的生成模型的数学结构，通过Wasserstein近端算子和平均场博弈可以描述生成模型的归纳偏差，通过解耦合的偏微分方程可以获得优化条件，提出了一个可解释的基于核的得分函数模型，极大地提高了生成模型的性能。 |
| [^19] | [Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions](https://arxiv.org/abs/2402.06160) | 本文通过混合狄利克雷分布来改进证据深度学习（EDL）方法，解决了现有方法中认知不确定性在无限样本限制下可能不会消失的问题。 |
| [^20] | [POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition](https://arxiv.org/abs/2402.06151) | POTEC提出了一种两阶段策略分解的算法，在大离散动作空间中有效进行离策略学习。该算法利用聚类选择第一阶段策略，并利用回归方法选择每个聚类内的具体动作。 |
| [^21] | [Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams](https://arxiv.org/abs/2402.06122) | 本论文提出了一种名为PEAK的新型非参数顺序复合假设检验方法，适用于多个数据流的均值检验。该方法基于测试即博弈的框架，在任何停止时间上提供了非渐进α水平的检验。PEAK能够有效拒绝在满足非参数假设条件的所有潜在分布中错误的假设，从而实现对多个数据流的联合复合假设检验。与现有方法相比，该方法具有较高的计算效率。 |
| [^22] | [Iterated Denoising Energy Matching for Sampling from Boltzmann Densities](https://arxiv.org/abs/2402.06121) | 提出了一种基于迭代算法的新颖采样方法，通过利用能量函数和梯度进行训练，无需数据样本。该方法能够高效生成统计独立的样本，并且在高维度上具有可扩展性。通过利用扩散的快速模式混合行为，实现了对能量景观的平滑，从而实现了高效的探索和学习。 |
| [^23] | [An operator learning perspective on parameter-to-observable maps](https://arxiv.org/abs/2402.06031) | 本论文从算子学习的视角研究了参数到可观测映射，提出了适应有限维输入和输出的傅里叶神经映射框架，并发展了通用逼近定理来支持该方法。此外，讨论了学习PtO映射的端到端方法和先学习解算子再计算可观测值的效率问题。 |
| [^24] | [Checking the Sufficiently Scattered Condition using a Global Non-Convex Optimization Software](https://arxiv.org/abs/2402.06019) | 本文提出了一种使用全局非凸优化软件Gurobi解决足够分散条件检验问题的方法，在实际场景中可以在合理的时间范围内进行检查。 |
| [^25] | [NPSVC++: Nonparallel Classifiers Encounter Representation Learning](https://arxiv.org/abs/2402.06010) | 本文研究了一种称为非并行支持向量分类器(NPSVCs)的分类器家族，提出了NPSVC++，基于多目标优化。NPSVC++通过表示学习实现了NPSVC及其特征的端到端学习，追求帕累托最优，有效地解决了特征次优和类别依赖的问题，在实验证明了其优越性。 |
| [^26] | [Memory-Efficient Vision Transformers: An Activation-Aware Mixed-Rank Compression Strategy](https://arxiv.org/abs/2402.06004) | 本文提出了一种激活感知的混合秩压缩策略来提高视觉Transformer的内存效率，并通过选择性低秩权重张量近似和层间误差补偿技术来减少参数数量。这种策略避免了浅层局部最小值陷阱，同时取得了优秀的结果。 |
| [^27] | [Bellman Conformal Inference: Calibrating Prediction Intervals For Time Series](https://arxiv.org/abs/2402.05203) | 贝尔曼符合推断（BCI）是一个框架，通过解决一维随机控制问题，利用多步预测来提供校准的时间序列预测区间。BCI在任意分布转换和时间依赖性下实现了长期覆盖，且在波动率预测问题上生成更短的预测区间。 |
| [^28] | [Learning Best-in-Class Policies for the Predict-then-Optimize Framework](https://arxiv.org/abs/2402.03256) | 我们提出了一种新颖的决策感知替代损失函数家族，用于predict-then-optimize框架，并且通过数值证据证实了其在误设置下的优越性。 |
| [^29] | [Fair Coresets via Optimal Transport](https://arxiv.org/abs/2311.05436) | 本研究提出了公平的Wasserstein核心集(FWC)，该方法通过最小化原始数据集与加权合成样本之间的Wasserstein距离，并强制实现人口平等，生成公平的合成代表性样本，可用于下游学习任务。 |
| [^30] | [Robust variance-regularized risk minimization with concomitant scaling](https://arxiv.org/abs/2301.11584) | 本研究提出了一种简单但有效的学习过程，用于最小化潜在存在重尾风险的损失函数，该方法在各种数据集上表现出与使用CVaR或DRO风险等替代标准得到的最佳候选方案相当或更好的性能。 |
| [^31] | [Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier](https://arxiv.org/abs/2212.04382) | 本文研究了在图形输入空间中，分类器边界的结构。通过创建一种新的不确定性度量，称为邻居相似度，我们展示了朴素贝叶斯分类器的边界是巨大且复杂的结构。 |
| [^32] | [Statistical exploration of the Manifold Hypothesis](https://arxiv.org/abs/2208.11665) | 这篇论文通过潜在度量模型从数据中得出了丰富而复杂的流形结构，并提供了解释流形假设的统计解释。该研究为发现和解释高维数据的几何结构以及探索数据生成机制提供了方法。 |
| [^33] | [On Rademacher Complexity-based Generalization Bounds for Deep Learning](https://arxiv.org/abs/2208.04284) | 该论文研究了基于Rademacher复杂度的方法在对卷积神经网络进行少类别图像分类时生成非空泛化界限。其中的关键技术贡献是发展了针对函数空间和具有一般Lipschitz激活函数的CNNs的新的Talagrand压缩引理。 |
| [^34] | [Parameter-free Mirror Descent](https://arxiv.org/abs/2203.00444) | 本论文针对无界域中构建自适应和无参的算法提出了一种修改后的在线镜像下降框架，并以此为基础开发了具有最优动态遗憾界限的无约束在线线性优化算法，并证明了基于Follow-the-Regularized-Leader的策略无法达到类似效果，此外还应用镜像下降框架构建了新的无参隐式更新以及简化和改进的无约束无标度算法。 |
| [^35] | [Fault-Tolerant Neural Networks from Biological Error Correction Codes](https://arxiv.org/abs/2202.12887) | 该论文根据哺乳动物皮质中的模拟纠错码，提出了一种基于生物纠错码的通用容错神经网络，实现了可靠计算；发现了从故障到容错神经计算的相变，为理解嘈杂模拟系统提供了新的途径。 |
| [^36] | [Universal Approximation Power of Deep Residual Neural Networks via Nonlinear Control Theory](https://arxiv.org/abs/2007.06007) | 本文通过非线性控制理论解释了深度残差神经网络的通用逼近能力，并提供了一个充分条件，在激活函数满足二次微分方程的情况下，一个足够深的神经网络能够在紧集合上逼近任意连续函数。 |
| [^37] | [Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data](https://arxiv.org/abs/2006.07841) | 本论文提出了一种同时利用正数据-无标签学习和有条件生成的训练框架，以及额外无标签数据的方法。通过使用一个对噪声标签具有鲁棒性的分类器噪声不变有条件生成对抗网络来提高PU分类器的性能，并利用PU分类器预测的标签和额外数据来帮助生成。实验结果证明了该方法的有效性。 |
| [^38] | [Adaptive Experiment Design with Synthetic Controls.](http://arxiv.org/abs/2401.17205) | 这种方法提出了Syntax，一个具有合成对照组的自适应实验设计，能够在多个亚群体中识别出具有正面治疗效果的亚群体，对于多样化患者反应的临床试验具有样本效率的优势。 |
| [^39] | [FairWASP: Fast and Optimal Fair Wasserstein Pre-processing.](http://arxiv.org/abs/2311.00109) | FairWASP是一种快速和最优的公平Wasserstein预处理方法，通过重新加权数据集来减少分类数据集中的不平等性，同时满足人口平等性准则。这种方法可以用于构建可以输入任何分类方法的数据集。 |
| [^40] | [Revisiting the Learnability of Apple Tasting.](http://arxiv.org/abs/2310.19064) | 该论文重新审视了苹果品尝的可学习性，从组合角度研究了在线可学习性。作者通过引入Effective width参数，紧密量化了在可实现设置中的极小期望错误，并在可实现设置中建立了极小期望错误数量的三分法。 |
| [^41] | [Deep Backtracking Counterfactuals for Causally Compliant Explanations.](http://arxiv.org/abs/2310.07665) | 本研究提供了一种实用方法，用于在深度生成组件的结构因果模型中计算回溯反事实。通过在因果模型的结构化潜在空间中解决优化问题，我们的方法能够生成反事实，并且与其他方法相比具备了多功能、模块化和符合因果关系的特点。 |
| [^42] | [Forecasting of the development of a partially-observed dynamical time series with the aid of time-invariance and linearity.](http://arxiv.org/abs/2306.16593) | 本研究提出了一种自回归松弛时间序列（ARS）模型，通过考虑动态系统的时间不变性和线性性，同时估计演化函数和缺失变量，用于预测动态时间序列中缺失变量的发展。 |
| [^43] | [Probabilistic matching of real and generated data statistics in generative adversarial networks.](http://arxiv.org/abs/2306.10943) | 本文提出一种通过向生成器损失函数中添加KL散度项的方法，来保证生成数据统计分布与真实数据的相应分布重合，并在实验中展示了此方法的优越性能。 |
| [^44] | [Kernel Debiased Plug-in Estimation.](http://arxiv.org/abs/2306.08598) | 本文提出了一种高效、不需要实现影响函数且可计算的去偏插值估计方法。 |
| [^45] | [Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts.](http://arxiv.org/abs/2305.07572) | 本文提出新颖的Voronoi Loss函数来解决高斯门控混合专家模型参数估计的收敛速率问题，并在两种不同的门控网络下提供理论收敛速率的证明。 |
| [^46] | [A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria for Robust Phase Retrieval.](http://arxiv.org/abs/2304.12522) | 本文提出了一种新的鲁棒相位恢复算法，通过使用自适应停止准则的非精确近端线性算法，该方法在实验中证明比现有方法更高效。 |

# 详细

[^1]: 动力系统中顺序预测的复杂性研究

    The Complexity of Sequential Prediction in Dynamical Systems

    [https://arxiv.org/abs/2402.06614](https://arxiv.org/abs/2402.06614)

    通过学习理论的角度，我们在没有参数假设的情况下，研究了在底层演化函数未知的动力系统中学习预测下一状态的问题，并提出了新的组合度量和维度来量化在可实现和不可知情况下的最佳错误和遗憾界限。

    

    我们研究了在底层演化函数未知的情况下学习预测动力系统下一状态的问题。与以前的工作不同，我们对动力系统没有参数假设，并从学习理论的角度研究了该问题。我们定义了新的组合度量和维度，并证明它们量化了在可实现和不可知情况下的最佳错误和遗憾界限。

    We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown. Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective. We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic setting respectively.
    
[^2]: 关于基于耦合的标准化流的普适性

    On the Universality of Coupling-based Normalizing Flows

    [https://arxiv.org/abs/2402.06578](https://arxiv.org/abs/2402.06578)

    我们提出了一个新颖的理论框架，用于理解基于耦合的标准化流的表达能力，并提出了一个新的分布普适性定理来克服以前工作的限制。这些结果支持耦合架构的表达能力，并弥补了实证结果和理论理解之间的差距。

    

    我们提出了一个新颖的理论框架，用于理解基于耦合的标准化流（如RealNVP）的表达能力。尽管耦合流在科学应用中很普遍，但由于其受限的架构，对于耦合流的全面理解仍然困难。现有的定理在实际应用中存在限制，因为它们需要使用任意病态的神经网络。此外，我们还证明了这些结构本质上导致体积保持流，这是一个限制表达能力的基本约束。我们提出了一种新的基于分布的耦合标准化流普适性定理，克服了以前工作的几个限制。我们的结果支持耦合架构具有表达能力的普遍经验，并为选择耦合函数的表达能力提供了细致入微的观点，填补了实证结果和理论理解之间的差距。

    We present a novel theoretical framework for understanding the expressive power of coupling-based normalizing flows such as RealNVP. Despite their prevalence in scientific applications, a comprehensive understanding of coupling flows remains elusive due to their restricted architectures. Existing theorems fall short as they require the use of arbitrarily ill-conditioned neural networks, limiting practical applicability. Additionally, we demonstrate that these constructions inherently lead to volume-preserving flows, a property which we show to be a fundamental constraint for expressivity. We propose a new distributional universality theorem for coupling-based normalizing flows, which overcomes several limitations of prior work. Our results support the general wisdom that the coupling architecture is expressive and provide a nuanced view for choosing the expressivity of coupling functions, bridging a gap between empirical results and theoretical understanding.
    
[^3]: Bandit Convex Optimisation（强盗凸优化）

    Bandit Convex Optimisation

    [https://arxiv.org/abs/2402.06535](https://arxiv.org/abs/2402.06535)

    这篇论文介绍了强盗凸优化的基本框架和用于解决这一问题的多种工具。虽然没有太多创新，但通过以新颖的方式应用现有工具，获得了新的算法和改进了一些界限。

    

    强盗凸优化是研究零阶凸优化的基本框架。本文介绍了用于解决该问题的许多工具，包括切平面方法、内点方法、连续指数权重、梯度下降和在线牛顿步骤。解释了许多假设和设置之间的细微差别。尽管在这里没有太多真正新的东西，但一些现有工具以新颖的方式应用于获得新算法。一些界限稍微改进了一些。

    Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.
    
[^4]: 灵活的无限宽图卷积网络及表示学习的重要性

    Flexible infinite-width graph convolutional networks and the importance of representation learning

    [https://arxiv.org/abs/2402.06525](https://arxiv.org/abs/2402.06525)

    本文讨论了神经网络高斯过程（NNGP）在理论上的局限，提出图卷积深度内核机（graph convolutional deep kernel machine）来研究图分类任务中的表示学习问题。

    

    理解神经网络的一种常见理论方法是进行无限宽度限制，此时输出成为高斯过程（GP）分布。这被称为神经网络高斯过程（NNGP）。然而，NNGP内核是固定的，只能通过少量超参数进行调节，消除了任何表示学习的可能性。这与有限宽度的神经网络形成对比，后者通常被认为能够表现良好，正是因为它们能够学习表示。因此，简化神经网络以使其在理论上可处理的同时，NNGP可能会消除使其工作良好的因素（表示学习）。这激发了我们对一系列图分类任务中表示学习是否必要的理解。我们开发了一个精确的工具来完成这个任务，即图卷积深度内核机（graph convolutional deep kernel machine）。这与NNGP非常相似，因为它是无限宽度限制并使用内核，但它带有一个“旋钮”来控制表示学习的程度。

    A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed. This is known as a neural network Gaussian process (NNGP). However, the NNGP kernel is fixed, and tunable only through a small number of hyperparameters, eliminating any possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well precisely because they are able to learn representations. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of graph classification tasks. We develop a precise tool for this task, the graph convolutional deep kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a `knob' to control the amount 
    
[^5]: 顺序流匹配用于生成建模

    Sequential Flow Matching for Generative Modeling

    [https://arxiv.org/abs/2402.06461](https://arxiv.org/abs/2402.06461)

    本文提出了一种称为SeqRF的新方法，用于通过直线化概率流来减小全局截断误差，并以此加速取样和提高综合质量。

    

    直接引导连续时间生成模型（例如扩散模型或基于流的模型）的概率流是通过数值解算器快速取样的关键。现有方法通过直接生成噪声和数据分布之间的联合分布的概率路径来学习线性路径。ODE模型的仿真速度慢的一个重要原因是ODE轨迹的高曲率导致的ODE求解器的全局截断误差，这会在低NFE范围内放大数值解算器的截断误差。为了解决这个挑战，我们提出了一种称为SeqRF的新方法，它是一种学习技术，用于直线化概率流以减小全局截断误差，从而加速取样并提高综合质量。通过理论和实证研究，我们首先观察到了SeqRF的直线化特性。

    Straightening the probability flow of the continuous-time generative models, such as diffusion models or flow-based models, is the key to fast sampling through the numerical solvers, existing methods learn a linear path by directly generating the probability path the joint distribution between the noise and data distribution. One key reason for the slow sampling speed of the ODE-based solvers that simulate these generative models is the global truncation error of the ODE solver, caused by the high curvature of the ODE trajectory, which explodes the truncation error of the numerical solvers in the low-NFE regime. To address this challenge, We propose a novel method called SeqRF, a learning technique that straightens the probability flow to reduce the global truncation error and hence enable acceleration of sampling and improve the synthesis quality. In both theoretical and empirical studies, we first observe the straightening property of our SeqRF. Through empirical evaluations via SeqR
    
[^6]: 真相在哪里？在连续的世界中遭遇混淆的风险

    Where is the Truth? The Risk of Getting Confounded in a Continual World

    [https://arxiv.org/abs/2402.06434](https://arxiv.org/abs/2402.06434)

    这篇论文研究了在一个连续学习环境中遭遇混淆的问题，通过实验证明了传统的连续学习方法无法忽略混淆，需要更强大的方法来处理这个问题。

    

    如果一个数据集通过一个虚假相关性来解决，而这种相关性无法泛化到新数据，该数据集就是混淆的。我们将展示，在一个连续学习的环境中，混淆因素可能随着任务的变化而变化，导致的挑战远远超过通常考虑的遗忘问题。具体来说，我们从数学上推导了这种混淆因素对一组混淆任务的有效联合解空间的影响。有趣的是，我们的理论预测，在许多这样的连续数据集中，当任务进行联合训练时，虚假相关性很容易被忽略，但是在顺序考虑任务时，避免混淆要困难得多。我们构建了这样一个数据集，并通过实验证明标准的连续学习方法无法忽略混淆，而同时对所有任务进行联合训练则是成功的。我们的连续混淆数据集ConCon基于CLEVR图像，证明了需要更强大的连续学习方法来处理混淆问题。

    A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. We will show that, in a continual learning setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered. In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks. Interestingly, our theory predicts that for many such continual datasets, spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially. We construct such a dataset and demonstrate empirically that standard continual learning methods fail to ignore confounders, while training jointly on all tasks is successful. Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for continual learning methods with more robust b
    
[^7]: 提高非凸分布式优化在函数相似性下的最坏情况双向通信复杂性

    Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity

    [https://arxiv.org/abs/2402.06412](https://arxiv.org/abs/2402.06412)

    本文提出了MARINA-P方法，通过引入一系列相关压缩器，优化了服务器到工作节点的通信复杂度。理论分析证明，MARINA-P在算法上优于现有方法，并可以作为支持双向压缩的起点。通过与上行压缩和动量步骤的结合，M3方法实现了双向压缩，并在总通信复杂度上改进。

    

    服务器和工作节点之间的有效通信在分布式优化中起着关键作用。本文主要关注优化服务器到工作节点的通信，并揭示了当前流行的下行压缩方法中的低效性。首先考虑上行通信成本可忽略的纯粹情况下，我们引入MARINA-P，一种使用一系列相关压缩器的新型下行压缩方法。理论分析证明，使用排列压缩器的MARINA-P可以实现服务器到工作节点的通信复杂度随工作节点数量提高，因此在算法上可证明优于现有算法。我们进一步展示了MARINA-P可以作为支持双向压缩的方法的起点。我们介绍了M3，这是一种将MARINA-P与上行压缩和动量步骤组合的方法，能够实现双向压缩，并在总通信复杂度上证明了改进。

    Effective communication between the server and workers plays a key role in distributed optimization. In this paper, we focus on optimizing the server-to-worker communication, uncovering inefficiencies in prevalent downlink compression approaches. Considering first the pure setup where the uplink communication costs are negligible, we introduce MARINA-P, a novel method for downlink compression, employing a collection of correlated compressors. Theoretical analyses demonstrates that MARINA-P with permutation compressors can achieve a server-to-worker communication complexity improving with the number of workers, thus being provably superior to existing algorithms. We further show that MARINA-P can serve as a starting point for extensions such as methods supporting bidirectional compression. We introduce M3, a method combining MARINA-P with uplink compression and a momentum step, achieving bidirectional compression with provable improvements in total communication complexity as the number
    
[^8]: 关于随机梯度下降（SGD）的收敛速度及其在修改的多臂赌博机上的策略梯度应用

    On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit

    [https://arxiv.org/abs/2402.06388](https://arxiv.org/abs/2402.06388)

    该论文证明了当学习速率按照逆时间衰减规则时，随机梯度下降（SGD）的收敛速度，并应用于修改的带有L2正则化的策略梯度多臂赌博机（MAB）的收敛性分析。

    

    我们提出了一个自包含的证明，证明了当学习速率遵循逆时间衰减规则时，随机梯度下降（SGD）的收敛速度；接下来，我们将这些结果应用于带有L2正则化的修改的策略梯度多臂赌博机（MAB）的收敛性分析。

    We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.
    
[^9]: 基于Boosting的顺序元树集成构建以改进决策树

    Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved Decision Trees

    [https://arxiv.org/abs/2402.06386](https://arxiv.org/abs/2402.06386)

    本研究提出了一种使用提升方法构建多个元树的方法，旨在改进决策树的预测性能。

    

    决策树是机器学习领域中最流行的方法之一。然而，它存在过度加深树形结构导致的过拟合问题。近期有人提出了元树来解决过度加深树形结构导致的过拟合问题。此外，基于贝叶斯决策理论，元树能够保证统计上的最优性。因此，相较于决策树，我们期望元树表现更好。与单个决策树相比，已知由提升算法构造的决策树集成在提高预测性能方面更为有效。因此，我们期望由元树集成来提高预测性能比单个元树更有效，并且以前没有研究使用提升方法构建多个元树。因此，在本研究中，我们提出了使用提升方法构建多个元树的方法。

    A decision tree is one of the most popular approaches in machine learning fields. However, it suffers from the problem of overfitting caused by overly deepened trees. Then, a meta-tree is recently proposed. It solves the problem of overfitting caused by overly deepened trees. Moreover, the meta-tree guarantees statistical optimality based on Bayes decision theory. Therefore, the meta-tree is expected to perform better than the decision tree. In contrast to a single decision tree, it is known that ensembles of decision trees, which are typically constructed boosting algorithms, are more effective in improving predictive performance. Thus, it is expected that ensembles of meta-trees are more effective in improving predictive performance than a single meta-tree, and there are no previous studies that construct multiple meta-trees in boosting. Therefore, in this study, we propose a method to construct multiple meta-trees using a boosting approach. Through experiments with synthetic and ben
    
[^10]: 高斯（多项式）树的最优估计

    Optimal estimation of Gaussian (poly)trees

    [https://arxiv.org/abs/2402.06380](https://arxiv.org/abs/2402.06380)

    该论文开发了最优算法，在学习高斯树和高斯多项式树方面取得了显著成果，并提供了详细的理论保证和实证结果。

    

    我们开发了一种从数据中学习无向高斯树和有向高斯多项式树的最优算法。我们考虑了分布学习（即KL距离）和结构学习（即精确恢复）的两个问题。第一种方法基于Chow-Liu算法，有效地学习最优的树状分布。第二种方法是对用于多项式树的PC算法的修改，它使用偏相关作为条件独立性测试器进行基于约束的结构学习。我们得到了这两种方法的显式有限样本保证，并通过推导匹配的下界证明这两种方法都是最优的。此外，我们进行了数值实验，比较了各种算法的性能，提供了进一步的洞察和经验证据。

    We develop optimal algorithms for learning undirected Gaussian trees and directed Gaussian polytrees from data. We consider both problems of distribution learning (i.e. in KL distance) and structure learning (i.e. exact recovery). The first approach is based on the Chow-Liu algorithm, and learns an optimal tree-structured distribution efficiently. The second approach is a modification of the PC algorithm for polytrees that uses partial correlation as a conditional independence tester for constraint-based structure learning. We derive explicit finite-sample guarantees for both approaches, and show that both approaches are optimal by deriving matching lower bounds. Additionally, we conduct numerical experiments to compare the performance of various algorithms, providing further insights and empirical evidence.
    
[^11]: 在线不平衡多臂赌博机中的曝光公平性

    Fairness of Exposure in Online Restless Multi-armed Bandits

    [https://arxiv.org/abs/2402.06348](https://arxiv.org/abs/2402.06348)

    本研究提出了第一个在线的公平RMAB框架，通过将每个臂的拉取与其优势成比例，实现了公平的曝光。算法在单次拉取的公平性遗憾方面取得了次线性的结果$O(\sqrt{T\ln T})$。

    

    不平衡多臂赌博机（RMAB）推广了多臂赌博机，其中每个臂展示马尔可夫行为，并根据其过渡动态进行转换。针对RMAB的解决方案存在于离线和在线情况下。然而，它们没有考虑臂之间的拉取分布。研究表明，最优策略会导致不公平，其中一些臂不够暴露。现有的RMAB公平性工作主要集中在离线案例中，这降低了它们在环境大部分不知道的现实场景中的应用。在在线场景中，我们提出了第一个公平的RMAB框架，其中每个臂接收的拉取与其优势成比例。我们将臂的优势定义为其稳态奖励分布的函数。我们证明了我们的算法在单次拉取的公平性遗憾方面实现了次线性的结果$O(\sqrt{T\ln T})$，其中$T$是总的尝试次数。经验证明，我们的算法在多次拉取的情况下表现良好。

    Restless multi-armed bandits (RMABs) generalize the multi-armed bandits where each arm exhibits Markovian behavior and transitions according to their transition dynamics. Solutions to RMAB exist for both offline and online cases. However, they do not consider the distribution of pulls among the arms. Studies have shown that optimal policies lead to unfairness, where some arms are not exposed enough. Existing works in fairness in RMABs focus heavily on the offline case, which diminishes their application in real-world scenarios where the environment is largely unknown. In the online scenario, we propose the first fair RMAB framework, where each arm receives pulls in proportion to its merit. We define the merit of an arm as a function of its stationary reward distribution. We prove that our algorithm achieves sublinear fairness regret in the single pull case $O(\sqrt{T\ln T})$, with $T$ being the total number of episodes. Empirically, we show that our algorithm performs well in the multi
    
[^12]: 均匀随机权重如何引起不均匀偏差：典型插值神经网络与窄教师的普遍性

    How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers

    [https://arxiv.org/abs/2402.06323](https://arxiv.org/abs/2402.06323)

    在插值神经网络中，均匀随机权重可以产生非均匀偏差，因此通常插值神经网络会与窄教师NN一样很好地泛化。

    

    背景。一个主要的理论难题是当神经网络被训练到零误差（即插值数据）时，为什么超参数化神经网络（NN）能够很好地泛化。通常，NN是使用随机梯度下降（SGD）或其变种之一训练的。然而，最近的实证研究检验了从看似均匀的参数先验中采样的随机NN对数据的泛化能力：该NN对训练集进行了完美分类。有趣的是，这样的NN样本通常像SGD训练的NN一样泛化良好。贡献。我们证明了如果存在与标签一致的窄“教师NN”，那么这样的随机NN插值器通常能很好地泛化。具体而言，我们证明了在NN参数化中的“平坦”先验通过NN结构中的冗余引入了丰富的NN函数先验。特别是，这会对较简单的函数产生偏向，这些函数需要较少的相关参数。

    Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as SGD-trained NNs.   Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant pa
    
[^13]: 粒子去噪扩散采样器

    Particle Denoising Diffusion Sampler

    [https://arxiv.org/abs/2402.06320](https://arxiv.org/abs/2402.06320)

    本文介绍了一种粒子去噪扩散采样器（PDDS），通过使用原始迭代粒子方案和新颖的得分匹配损失，对非归一化概率密度进行采样和计算规范化常数。与标准的去噪扩散模型不同，PDDS 在温和假设下提供了渐近一致的估计。

    

    去噪扩散模型在生成建模中已经得到广泛应用。其核心思想是通过使用扩散将数据分布转化为高斯分布。然后通过使用得分匹配思想估计这种扩散的时间反演来获得来自数据分布的近似样本。我们在这里采用类似的策略来从非归一化概率密度中采样并计算它们的规范化常数。然而，在这里，时间反演扩散是通过使用基于新颖得分匹配损失的原始迭代粒子方案来模拟的。与标准的去噪扩散模型不同，结果的粒子去噪扩散采样器 (PDDS) 在温和假设下提供了渐近一致的估计。我们在多模态和高维采样任务上演示了 PDDS。

    Denoising diffusion models have become ubiquitous for generative modeling. The core idea is to transport the data distribution to a Gaussian by using a diffusion. Approximate samples from the data distribution are then obtained by estimating the time-reversal of this diffusion using score matching ideas. We follow here a similar strategy to sample from unnormalized probability densities and compute their normalizing constants. However, the time-reversed diffusion is here simulated by using an original iterative particle scheme relying on a novel score matching loss. Contrary to standard denoising diffusion models, the resulting Particle Denoising Diffusion Sampler (PDDS) provides asymptotically consistent estimates under mild assumptions. We demonstrate PDDS on multimodal and high dimensional sampling tasks.
    
[^14]: 通过条件流进行不规则时间序列的概率预测

    Probabilistic Forecasting of Irregular Time Series via Conditional Flows

    [https://arxiv.org/abs/2402.06293](https://arxiv.org/abs/2402.06293)

    该论文提出了一种使用条件流进行不规则时间序列的概率预测的新模型ProFITi。该模型通过学习条件下未来值的联合分布，对具有缺失值的不规则时间序列进行预测，而不假设底层分布的固定形状。通过引入可逆三角形注意力层和可逆非线性激活函数，该模型取得了良好的实验结果。

    

    不规则采样的多变量时间序列具有缺失值的概率预测是许多领域的重要问题，包括医疗保健、天文学和气候学。目前该任务的最先进方法仅估计单个通道和单个时间点上观测值的边际分布，假设了一个固定形状的参数分布。在这项工作中，我们提出了一种新的模型ProFITi，用于使用条件归一化流对具有缺失值的不规则采样时间序列进行概率预测。该模型学习了在过去观测和查询的通道和时间上条件下时间序列未来值的联合分布，而不假设底层分布的固定形状。作为模型组件，我们引入了一种新颖的可逆三角形注意力层和一个可逆的非线性激活函数，能够在整个实数线上进行转换。我们在四个数据集上进行了大量实验，并证明了该模型的提议。

    Probabilistic forecasting of irregularly sampled multivariate time series with missing values is an important problem in many fields, including health care, astronomy, and climate. State-of-the-art methods for the task estimate only marginal distributions of observations in single channels and at single timepoints, assuming a fixed-shape parametric distribution. In this work, we propose a novel model, ProFITi, for probabilistic forecasting of irregularly sampled time series with missing values using conditional normalizing flows. The model learns joint distributions over the future values of the time series conditioned on past observations and queried channels and times, without assuming any fixed shape of the underlying distribution. As model components, we introduce a novel invertible triangular attention layer and an invertible non-linear activation function on and onto the whole real line. We conduct extensive experiments on four datasets and demonstrate that the proposed model pro
    
[^15]: 高斯过程下安全的时间序列建模的主动学习

    Safe Active Learning for Time-Series Modeling with Gaussian Processes

    [https://arxiv.org/abs/2402.06276](https://arxiv.org/abs/2402.06276)

    本研究提出了一种安全的主动学习方法，用于时间序列建模。通过动态探索输入空间并根据安全要求和过去观察的输入和输出轨迹，我们的方法在现实技术应用中展示了其有效性。

    

    学习时间序列模型对于许多应用如模拟和预测都是有用的。在本研究中，我们考虑了在考虑给定的安全性约束条件的情况下主动学习时间序列模型的问题。对于时间序列建模，我们使用了一个具有非线性外部输入结构的高斯过程。所提出的方法通过动态地探索输入空间来生成适用于时间序列模型学习的数据，即输入和输出轨迹。该方法将输入轨迹参数化为连续的轨迹部分，这些部分是根据安全要求和过去的观察逐步确定的。我们对所提出的算法进行分析，并在技术应用上进行了实证评估。结果显示了我们的方法在现实技术使用案例下的有效性。

    Learning time-series models is useful for many applications, such as simulation and forecasting. In this study, we consider the problem of actively learning time-series models while taking given safety constraints into account. For time-series modeling we employ a Gaussian process with a nonlinear exogenous input structure. The proposed approach generates data appropriate for time series model learning, i.e. input and output trajectories, by dynamically exploring the input space. The approach parametrizes the input trajectory as consecutive trajectory sections, which are determined stepwise given safety requirements and past observations. We analyze the proposed algorithm and evaluate it empirically on a technical application. The results show the effectiveness of our approach in a realistic technical use case.
    
[^16]: 通过潜在部分因果模型揭示多模式对比表示学习

    Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models

    [https://arxiv.org/abs/2402.06223](https://arxiv.org/abs/2402.06223)

    通过潜在部分因果模型，我们展示了多模式对比表示学习在识别潜在耦合变量方面的优秀能力，并揭示了预训练的多模态模型通过线性独立分量分析学习分离表示的潜力。

    

    多模式对比表示学习方法在各个领域取得了成功，部分原因是由于它们能够生成复杂现象的有意义的共享表示。为了增强对这些获得的表示的深度分析和理解，我们引入了一种特别针对多模态数据设计的统一因果模型。通过研究这个模型，我们展示了多模式对比表示学习在识别在提出的统一模型中的潜在耦合变量方面的优秀能力，即使在不同假设下导致的线性或置换变换。我们的发现揭示了预训练的多模态模型（如CLIP）通过线性独立分量分析这一令人惊讶的简单而高效的工具学习分离表示的潜力。实验证明了我们发现的鲁棒性，即使在被违反假设的情况下，也验证了所提出方法在学习疾病方面的有效性。

    Multimodal contrastive representation learning methods have proven successful across a range of domains, partly due to their ability to generate meaningful shared representations of complex phenomena. To enhance the depth of analysis and understanding of these acquired representations, we introduce a unified causal model specifically designed for multimodal data. By examining this model, we show that multimodal contrastive representation learning excels at identifying latent coupled variables within the proposed unified model, up to linear or permutation transformations resulting from different assumptions. Our findings illuminate the potential of pre-trained multimodal models, eg, CLIP, in learning disentangled representations through a surprisingly simple yet highly effective tool: linear independent component analysis. Experiments demonstrate the robustness of our findings, even when the assumptions are violated, and validate the effectiveness of the proposed method in learning dise
    
[^17]: SMC就是你需要的：并行强扩展

    SMC Is All You Need: Parallel Strong Scaling

    [https://arxiv.org/abs/2402.06173](https://arxiv.org/abs/2402.06173)

    SMC并行扩展方法pSMC具有理论收敛速度，具有有界的时间复杂性和内存要求，适用于贝叶斯推断的问题。

    

    在贝叶斯推断的一般框架中，目标分布只能按比例常数进行评估。传统的一致Bayesian方法，如序贯蒙特卡洛(SMC)和马尔科夫链蒙特卡洛(MCMC)，具有无界的时间复杂性要求。我们开发了一种完全并行的序贯蒙特卡洛(pSMC)方法，可以证明它具有并行强扩展性，即如果允许异步进程数量增长，时间复杂性(和每个节点的内存)仍然保持有界。更具体地说，pSMC具有MSE$=O(1/NR)$的理论收敛速度，其中$N$表示每个处理器中的通信样本数量，$R$表示处理器数量。特别地，对于适当大的问题相关$N$，当$R\rightarrow \infty$时，该方法以固定有限的时间复杂性Cost$=O(1)$收敛到无穷小精度MSE$=O(\varepsilon^2)$，没有效率泄漏，即计算复杂性Cost$=O(\varepsilon)$。

    In the general framework of Bayesian inference, the target distribution can only be evaluated up-to a constant of proportionality. Classical consistent Bayesian methods such as sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC) have unbounded time complexity requirements. We develop a fully parallel sequential Monte Carlo (pSMC) method which provably delivers parallel strong scaling, i.e. the time complexity (and per-node memory) remains bounded if the number of asynchronous processes is allowed to grow. More precisely, the pSMC has a theoretical convergence rate of MSE$ = O(1/NR)$, where $N$ denotes the number of communicating samples in each processor and $R$ denotes the number of processors. In particular, for suitably-large problem-dependent $N$, as $R \rightarrow \infty$ the method converges to infinitesimal accuracy MSE$=O(\varepsilon^2)$ with a fixed finite time-complexity Cost$=O(1)$ and with no efficiency leakage, i.e. computational complexity Cost$=O(\varepsilon
    
[^18]: Wasserstein近端算子描述基于分数的生成模型并解决记忆问题

    Wasserstein proximal operators describe score-based generative models and resolve memorization

    [https://arxiv.org/abs/2402.06162](https://arxiv.org/abs/2402.06162)

    该论文研究了基于分数的生成模型的数学结构，通过Wasserstein近端算子和平均场博弈可以描述生成模型的归纳偏差，通过解耦合的偏微分方程可以获得优化条件，提出了一个可解释的基于核的得分函数模型，极大地提高了生成模型的性能。

    

    我们关注基于分数的生成模型（SGMs）的基本数学结构。我们首先用Wasserstein近端算子（WPO）来构建SGMs，并证明通过平均场博弈（MFGs），WPO的结构揭示了描述扩散和基于分数模型的归纳偏差的数学结构。特别是，MFGs以一对耦合的偏微分方程的形式给出了最优性条件：一种前向控制的Fokker-Planck（FP）方程和一种向后的Hamilton-Jacobi-Bellman（HJB）方程。通过Cole-Hopf变换并利用交叉熵可以与密度的线性泛函相关联的事实，我们证明了HJB方程是一种无控制的FP方程。其次，利用手头的数学结构，我们提出了一个可解释的基于核的得分函数模型，该模型极大地提高了SGMs在训练样本和训练时间方面的性能。

    We focus on the fundamental mathematical structure of score-based generative models (SGMs). We first formulate SGMs in terms of the Wasserstein proximal operator (WPO) and demonstrate that, via mean-field games (MFGs), the WPO formulation reveals mathematical structure that describes the inductive bias of diffusion and score-based models. In particular, MFGs yield optimality conditions in the form of a pair of coupled partial differential equations: a forward-controlled Fokker-Planck (FP) equation, and a backward Hamilton-Jacobi-Bellman (HJB) equation. Via a Cole-Hopf transformation and taking advantage of the fact that the cross-entropy can be related to a linear functional of the density, we show that the HJB equation is an uncontrolled FP equation. Second, with the mathematical structure at hand, we present an interpretable kernel-based model for the score function which dramatically improves the performance of SGMs in terms of training samples and training time. In addition, the WP
    
[^19]: 通过混合狄利克雷分布改进证据深度学习

    Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions

    [https://arxiv.org/abs/2402.06160](https://arxiv.org/abs/2402.06160)

    本文通过混合狄利克雷分布来改进证据深度学习（EDL）方法，解决了现有方法中认知不确定性在无限样本限制下可能不会消失的问题。

    

    本文探讨了一种现代的预测不确定性估计方法，称为证据深度学习（EDL），其中通过最小化特定的目标函数，训练单个神经网络模型以学习预测分布上的元分布。尽管现有方法在经验性能方面表现强大，但Bengs等人的最近研究发现了现有方法的一个根本缺陷：即使在无限样本限制下，学习到的认知不确定性可能不会消失。通过提供文献中一类广泛使用的目标函数的统一视角，我们得到了这个观察的证实。我们的分析揭示了EDL方法本质上通过最小化分布与与样本大小无关的目标分布之间的特定差异度量来训练元分布，从而产生错误的认知不确定性。基于理论原则，我们提出通过将其建模为狄利克雷分布混合物来学习一致目标分布，从而改进了EDL方法。

    This paper explores a modern predictive uncertainty estimation approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their strong empirical performance, recent studies by Bengs et al. identify a fundamental pitfall of the existing methods: the learned epistemic uncertainty may not vanish even in the infinite-sample limit. We corroborate the observation by providing a unifying view of a class of widely used objectives from the literature. Our analysis reveals that the EDL methods essentially train a meta distribution by minimizing a certain divergence measure between the distribution and a sample-size-independent target distribution, resulting in spurious epistemic uncertainty. Grounded in theoretical principles, we propose learning a consistent target distribution by modeling it with a mixture of Dirichlet distributions and lear
    
[^20]: POTEC:通过两阶段策略分解的大动作空间离策略学习

    POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition

    [https://arxiv.org/abs/2402.06151](https://arxiv.org/abs/2402.06151)

    POTEC提出了一种两阶段策略分解的算法，在大离散动作空间中有效进行离策略学习。该算法利用聚类选择第一阶段策略，并利用回归方法选择每个聚类内的具体动作。

    

    我们研究了在存在大离散动作空间的情境吞噬机制中的离线策略学习(OPL)，现有方法大多依赖于回归模型或重要性加权策略梯度，但由于过高的偏差或方差而失败。为了克服OPL中的这些问题，我们提出了一种新的两阶段算法，称为两阶段策略分解的策略优化(POTEC)。它利用动作空间中的聚类，并分别通过基于策略和回归的方法学习两种不同的策略。特别地，我们推导出一种新颖的低方差梯度估计器，通过基于策略的方法高效地学习第一阶段策略以选择聚类。为了在第一阶段策略采样的聚类中选择特定动作，POTEC在每个聚类中使用来自回归方法的第二阶段策略。我们展示了一种局部正确性条件，该条件仅要求回归模型保持相关性。

    We study off-policy learning (OPL) of contextual bandit policies in large discrete action spaces where existing methods -- most of which rely crucially on reward-regression models or importance-weighted policy gradients -- fail due to excessive bias or variance. To overcome these issues in OPL, we propose a novel two-stage algorithm, called Policy Optimization via Two-Stage Policy Decomposition (POTEC). It leverages clustering in the action space and learns two different policies via policy- and regression-based approaches, respectively. In particular, we derive a novel low-variance gradient estimator that enables to learn a first-stage policy for cluster selection efficiently via a policy-based approach. To select a specific action within the cluster sampled by the first-stage policy, POTEC uses a second-stage policy derived from a regression-based approach within each cluster. We show that a local correctness condition, which only requires that the regression model preserves the rela
    
[^21]: 使用PEAK进行窥探：多个数据流均值的顺序、非参数复合假设检验

    Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams

    [https://arxiv.org/abs/2402.06122](https://arxiv.org/abs/2402.06122)

    本论文提出了一种名为PEAK的新型非参数顺序复合假设检验方法，适用于多个数据流的均值检验。该方法基于测试即博弈的框架，在任何停止时间上提供了非渐进α水平的检验。PEAK能够有效拒绝在满足非参数假设条件的所有潜在分布中错误的假设，从而实现对多个数据流的联合复合假设检验。与现有方法相比，该方法具有较高的计算效率。

    

    我们提出了一种新颖的非参数顺序复合假设检验方法，用于多个数据流的均值。我们的方法名为PEAK（基于期望平均资产的窥探），基于测试即博弈的框架，提供了一个在任何停止时间上的非渐进α水平测试。PEAK在计算上可行，并且能够有效拒绝在满足我们的非参数假设条件的所有潜在分布中错误的假设，从而实现对多个数据流的联合复合假设检验。我们在强化学习中的最佳臂识别和阈值识别任务中对我们的理论结果进行了数值验证，并展示了我们的方法在计算效率上优于现有的测试方法。

    We propose a novel nonparametric sequential test for composite hypotheses for means of multiple data streams. Our proposed method, \emph{peeking with expectation-based averaged capital} (PEAK), builds upon the testing-as-betting framework and provides a non-asymptotic $\alpha$-level test across any stopping time. PEAK is computationally tractable and efficiently rejects hypotheses that are incorrect across all potential distributions that satisfy our nonparametric assumption, enabling joint composite hypothesis testing on multiple streams of data. We numerically validate our theoretical findings under the best arm identification and threshold identification in the bandit setting, illustrating the computational efficiency of our method against state-of-the-art testing methods.
    
[^22]: 通过迭代去噪能量匹配从玻尔兹曼密度中进行采样

    Iterated Denoising Energy Matching for Sampling from Boltzmann Densities

    [https://arxiv.org/abs/2402.06121](https://arxiv.org/abs/2402.06121)

    提出了一种基于迭代算法的新颖采样方法，通过利用能量函数和梯度进行训练，无需数据样本。该方法能够高效生成统计独立的样本，并且在高维度上具有可扩展性。通过利用扩散的快速模式混合行为，实现了对能量景观的平滑，从而实现了高效的探索和学习。

    

    高效地从未标准化的概率分布中生成统计独立的样本，比如多体系统的平衡样本，是科学中的一个基础问题。在本文中，我们提出了迭代去噪能量匹配（iDEM），这是一种迭代算法，它利用了一种新颖的随机得分匹配目标，仅使用能量函数及其梯度 - 而不是数据样本 - 来训练扩散基础的采样器。具体而言，iDEM在以下两个步骤之间交替进行：（I）从扩散基础的采样器中采样高模型密度的区域，和（II）使用这些样本在我们的随机匹配目标中进一步改进采样器。iDEM在高维度上是可扩展的，内部匹配目标是无需模拟的，并且不需要MCMC样本。此外，通过利用扩散的快速模式混合行为，iDEM平滑了能量背景，实现了高效的探索和学习的分摊采样器。我们对一系列任务进行了iDEM的评估...

    Efficiently generating statistically independent samples from an unnormalized probability distribution, such as equilibrium samples of many-body systems, is a foundational problem in science. In this paper, we propose Iterated Denoising Energy Matching (iDEM), an iterative algorithm that uses a novel stochastic score matching objective leveraging solely the energy function and its gradient -- and no data samples -- to train a diffusion-based sampler. Specifically, iDEM alternates between (I) sampling regions of high model density from a diffusion-based sampler and (II) using these samples in our stochastic matching objective to further improve the sampler. iDEM is scalable to high dimensions as the inner matching objective, is simulation-free, and requires no MCMC samples. Moreover, by leveraging the fast mode mixing behavior of diffusion, iDEM smooths out the energy landscape enabling efficient exploration and learning of an amortized sampler. We evaluate iDEM on a suite of tasks rang
    
[^23]: 参数到可观测映射的算子学习视角

    An operator learning perspective on parameter-to-observable maps

    [https://arxiv.org/abs/2402.06031](https://arxiv.org/abs/2402.06031)

    本论文从算子学习的视角研究了参数到可观测映射，提出了适应有限维输入和输出的傅里叶神经映射框架，并发展了通用逼近定理来支持该方法。此外，讨论了学习PtO映射的端到端方法和先学习解算子再计算可观测值的效率问题。

    

    计算高效的参数化物理模型替代品在科学和工程中起着至关重要的作用。算子学习提供了一个数据驱动的替代方案，可以在函数空间中进行映射。然而，通常只有有限维的模型输入参数化或有限维的模型输出可观测数据可用，而不是全场测量数据。本文基于傅里叶神经算子，引入了傅里叶神经映射（Fourier Neural Mappings，FNMs）框架，能够适应这样的有限维输入和输出。本文为该方法发展了通用逼近定理。此外，在许多应用中，底层的参数到可观测（PtO）映射是通过无穷维算子来隐式定义的，例如偏微分方程的解算子。一个自然的问题是，是更有效地学习PtO映射的端到端方法，还是首先学习解算子，然后计算可观测值。

    Computationally efficient surrogates for parametrized physical models play a crucial role in science and engineering. Operator learning provides data-driven surrogates that map between function spaces. However, instead of full-field measurements, often the available data are only finite-dimensional parametrizations of model inputs or finite observables of model outputs. Building off of Fourier Neural Operators, this paper introduces the Fourier Neural Mappings (FNMs) framework that is able to accommodate such finite-dimensional inputs and outputs. The paper develops universal approximation theorems for the method. Moreover, in many applications the underlying parameter-to-observable (PtO) map is defined implicitly through an infinite-dimensional operator, such as the solution operator of a partial differential equation. A natural question is whether it is more data-efficient to learn the PtO map end-to-end or first learn the solution operator and subsequently compute the observable fro
    
[^24]: 使用全局非凸优化软件检验足够分散条件

    Checking the Sufficiently Scattered Condition using a Global Non-Convex Optimization Software

    [https://arxiv.org/abs/2402.06019](https://arxiv.org/abs/2402.06019)

    本文提出了一种使用全局非凸优化软件Gurobi解决足够分散条件检验问题的方法，在实际场景中可以在合理的时间范围内进行检查。

    

    足够分散条件（SSC）是研究各种矩阵分解问题的可辨识性的关键条件，包括非负、最小体积、对称、单纯结构和多面体矩阵分解。足够分散条件可以确保计算得到的矩阵分解是唯一可辨识的，除了平凡的模糊不确定性。然而，一般情况下，这个条件是NP难问题。在本文中，我们展示了在实际场景中，在矩阵的秩不太大时，它可以在合理的时间内进行检查，将问题构建为一个非凸二次优化问题，并在有界集合上求解。我们使用全局非凸优化软件Gurobi，并在合成数据集和实际世界的高光谱图像上展示了该代码的可用性。

    The sufficiently scattered condition (SSC) is a key condition in the study of identifiability of various matrix factorization problems, including nonnegative, minimum-volume, symmetric, simplex-structured, and polytopic matrix factorizations. The SSC allows one to guarantee that the computed matrix factorization is unique/identifiable, up to trivial ambiguities. However, this condition is NP-hard to check in general. In this paper, we show that it can however be checked in a reasonable amount of time in realistic scenarios, when the factorization rank is not too large. This is achieved by formulating the problem as a non-convex quadratic optimization problem over a bounded set. We use the global non-convex optimization software Gurobi, and showcase the usefulness of this code on synthetic data sets and on real-world hyperspectral images.
    
[^25]: NPSVC++: 非并行分类器遇到表示学习

    NPSVC++: Nonparallel Classifiers Encounter Representation Learning

    [https://arxiv.org/abs/2402.06010](https://arxiv.org/abs/2402.06010)

    本文研究了一种称为非并行支持向量分类器(NPSVCs)的分类器家族，提出了NPSVC++，基于多目标优化。NPSVC++通过表示学习实现了NPSVC及其特征的端到端学习，追求帕累托最优，有效地解决了特征次优和类别依赖的问题，在实验证明了其优越性。

    

    本文侧重于一种特定的分类器家族，称为非并行支持向量分类器(NPSVCs)。与典型的分类器不同，NPSVC的训练涉及多目标的最小化，导致特征次优和类别依赖的潜在问题。因此，尚未建立有效的学习方案来通过表示学习，特别是深度学习来改善NPSVC的性能。为了突破这一瓶颈，我们基于多目标优化开发了NPSVC++，实现了NPSVC及其特征的端到端学习。通过追求帕累托最优，NPSVC++在理论上确保了跨类别的特征优化，从而有效地克服了上述两个问题。我们提出了一种基于对偶优化的通用学习过程，并基于此提供了两个可应用的实例，K-NPSVC++和D-NPSVC++。实验证明了它们在现有方法上的优越性，并验证了NPSVC++的有效性。

    This paper focuses on a specific family of classifiers called nonparallel support vector classifiers (NPSVCs). Different from typical classifiers, the training of an NPSVC involves the minimization of multiple objectives, resulting in the potential concerns of feature suboptimality and class dependency. Consequently, no effective learning scheme has been established to improve NPSVCs' performance through representation learning, especially deep learning. To break this bottleneck, we develop NPSVC++ based on multi-objective optimization, enabling the end-to-end learning of NPSVC and its features. By pursuing Pareto optimality, NPSVC++ theoretically ensures feature optimality across classes, hence effectively overcoming the two issues above. A general learning procedure via duality optimization is proposed, based on which we provide two applicable instances, K-NPSVC++ and D-NPSVC++. The experiments show their superiority over the existing methods and verify the efficacy of NPSVC++.
    
[^26]: 内存高效的视觉Transformer：一种激活感知的混合秩压缩策略

    Memory-Efficient Vision Transformers: An Activation-Aware Mixed-Rank Compression Strategy

    [https://arxiv.org/abs/2402.06004](https://arxiv.org/abs/2402.06004)

    本文提出了一种激活感知的混合秩压缩策略来提高视觉Transformer的内存效率，并通过选择性低秩权重张量近似和层间误差补偿技术来减少参数数量。这种策略避免了浅层局部最小值陷阱，同时取得了优秀的结果。

    

    随着视觉Transformer（ViTs）在计算机视觉领域不断刷新最新记录，它们在推理引擎上的实际部署往往受到显著的内存带宽和（芯片内）内存占用的限制。本文通过引入一种激活感知的模型压缩方法来解决这一内存限制问题，该方法使用不同层的选择性低秩权重张量近似来减少ViTs的参数数量。关键思想是将权重张量分解为两个参数高效的张量之和，同时将输入激活与原始权重张量的乘积与输入激活与近似张量之和的乘积之间的误差最小化。通过采用有效的逐层误差补偿技术，利用层输出损失的梯度进一步改进了这种近似。这些技术的组合在避免陷入浅层局部最小值的同时取得了优秀的结果。

    As Vision Transformers (ViTs) increasingly set new benchmarks in computer vision, their practical deployment on inference engines is often hindered by their significant memory bandwidth and (on-chip) memory footprint requirements. This paper addresses this memory limitation by introducing an activation-aware model compression methodology that uses selective low-rank weight tensor approximations of different layers to reduce the parameter count of ViTs. The key idea is to decompose the weight tensors into a sum of two parameter-efficient tensors while minimizing the error between the product of the input activations with the original weight tensor and the product of the input activations with the approximate tensor sum. This approximation is further refined by adopting an efficient layer-wise error compensation technique that uses the gradient of the layer's output loss. The combination of these techniques achieves excellent results while it avoids being trapped in a shallow local minim
    
[^27]: 贝尔曼符合推断：时间序列预测中预测区间的校准

    Bellman Conformal Inference: Calibrating Prediction Intervals For Time Series

    [https://arxiv.org/abs/2402.05203](https://arxiv.org/abs/2402.05203)

    贝尔曼符合推断（BCI）是一个框架，通过解决一维随机控制问题，利用多步预测来提供校准的时间序列预测区间。BCI在任意分布转换和时间依赖性下实现了长期覆盖，且在波动率预测问题上生成更短的预测区间。

    

    我们引入了贝尔曼符合推断（BCI），这是一个围绕任何时间序列预测模型的框架，可以提供校准的预测区间。与现有方法不同，BCI能够利用多步预测，并通过在每个时间步骤上解决一维随机控制问题（SCP）来显式优化平均区间长度。特别地，我们使用动态规划算法来找到SCP的最优策略。我们证明了在任意分布转换和时间依赖性下，BCI能够实现长期覆盖，即使多步预测较差。我们在实证中发现，与现有方法相比，BCI避免了无信息区间（长度无限）的生成，并在波动率预测问题上生成了明显更短的预测区间。

    We introduce Bellman Conformal Inference (BCI), a framework that wraps around any time series forecasting models and provides calibrated prediction intervals. Unlike the existing methods, BCI is able to leverage multi-step ahead forecasts and explicitly optimize the average interval lengths by solving a one-dimensional stochastic control problem (SCP) at each time step. In particular, we use the dynamic programming algorithm to find the optimal policy for the SCP. We prove that BCI achieves long-term coverage under arbitrary distribution shifts and temporal dependence, even with poor multi-step ahead forecasts. We find empirically that BCI avoids uninformative intervals that have infinite lengths and generates substantially shorter prediction intervals on volatility forecasting problems when compared with existing methods.
    
[^28]: 学习Predict-then-Optimize框架中的最优策略

    Learning Best-in-Class Policies for the Predict-then-Optimize Framework

    [https://arxiv.org/abs/2402.03256](https://arxiv.org/abs/2402.03256)

    我们提出了一种新颖的决策感知替代损失函数家族，用于predict-then-optimize框架，并且通过数值证据证实了其在误设置下的优越性。

    

    我们提出了一种新颖的决策感知替代损失函数家族，称为Perturbation Gradient（PG）损失，用于predict-then-optimize框架。这些损失直接近似了下游决策损失，并可以使用现成的基于梯度的方法进行优化。重要的是，与现有的替代损失不同，我们的PG损失的近似误差随着样本数量的增加而消失。这意味着优化我们的替代损失可以在渐近意义下得到最佳策略，即使在误设置下也是如此。这是第一个在误设置下的这样的结果，我们提供了数值证据证实了当基础模型误设置且噪声不是中心对称时，我们的PG损失在实践中显著优于现有的提案。鉴于在实践中误设置很常见--特别是当我们可能更喜欢一个更简单、更可解释的模型时--PG损失提供了一种新颖的、理论上有依据的、可计算的决策感知方法。

    We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. These losses directly approximate the downstream decision loss and can be optimized using off-the-shelf gradient-based methods. Importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. This implies that optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified and the noise is not centrally symmetric. Insofar as misspecification is commonplace in practice -- especially when we might prefer a simpler, more interpretable model -- PG losses offer a novel, theoretically justified, method for computationally tractable decision-aware 
    
[^29]: 通过最优传输实现公平的核心集

    Fair Coresets via Optimal Transport

    [https://arxiv.org/abs/2311.05436](https://arxiv.org/abs/2311.05436)

    本研究提出了公平的Wasserstein核心集(FWC)，该方法通过最小化原始数据集与加权合成样本之间的Wasserstein距离，并强制实现人口平等，生成公平的合成代表性样本，可用于下游学习任务。

    

    数据精炼和核心集已成为生成用于处理大规模数据集的下游学习任务的较小代表性样本集的流行方法。与此同时，机器学习越来越多地应用于社会层面的决策过程，使得模型构建者必须解决存在于数据中的子群体的固有偏见问题。当前方法通过优化相对于原始样本的局部属性来创建公平的合成代表性样本，但其对下游学习过程的影响尚未被探索。在这项工作中，我们提出了公平的Wasserstein核心集（FWC），一种新颖的核心集方法，它生成既具有公平性的合成代表性样本，又具有用于下游学习任务的样本级权重。FWC最小化原始数据集与加权合成样本之间的Wasserstein距离，同时强制实现人口平等。我们展示了FWC的无约束版本等价于通常的最优传输问题，并且通过实验证明了FWC的有效性和公平性。

    Data distillation and coresets have emerged as popular approaches to generate a smaller representative set of samples for downstream learning tasks to handle large-scale datasets. At the same time, machine learning is being increasingly applied to decision-making processes at a societal level, making it imperative for modelers to address inherent biases towards subgroups present in the data. Current approaches create fair synthetic representative samples by optimizing local properties relative to the original samples, but their effect on downstream learning processes has yet to be explored. In this work, we present fair Wasserstein coresets (FWC), a novel coreset approach which generates fair synthetic representative samples along with sample-level weights to be used in downstream learning tasks. FWC minimizes the Wasserstein distance between the original dataset and the weighted synthetic samples while enforcing demographic parity. We show that an unconstrained version of FWC is equiv
    
[^30]: 具有同时调整尺度的健壮方差正则化风险最小化

    Robust variance-regularized risk minimization with concomitant scaling

    [https://arxiv.org/abs/2301.11584](https://arxiv.org/abs/2301.11584)

    本研究提出了一种简单但有效的学习过程，用于最小化潜在存在重尾风险的损失函数，该方法在各种数据集上表现出与使用CVaR或DRO风险等替代标准得到的最佳候选方案相当或更好的性能。

    

    在潜在存在重尾风险的损失函数下，我们考虑了最小化损失均值和标准差之和的任务，而无需精确估计方差。通过修改一种无方差健壮均值估计技术以适应我们的问题设定，我们推导出一个简单的学习过程，可以与标准的基于梯度的求解器轻松结合，用于传统的机器学习工作流程中。经验上，我们验证了我们提出的方法，尽管简单，但在各种数据集上表现出与使用CVaR或DRO风险等替代标准得到的最佳候选方案相当或更好的性能。

    Under losses which are potentially heavy-tailed, we consider the task of minimizing sums of the loss mean and standard deviation, without trying to accurately estimate the variance. By modifying a technique for variance-free robust mean estimation to fit our problem setting, we derive a simple learning procedure which can be easily combined with standard gradient-based solvers to be used in traditional machine learning workflows. Empirically, we verify that our proposed approach, despite its simplicity, performs as well or better than even the best-performing candidates derived from alternative criteria such as CVaR or DRO risks on a variety of datasets.
    
[^31]: 分类器边界的结构：朴素贝叶斯分类器的案例研究

    Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier

    [https://arxiv.org/abs/2212.04382](https://arxiv.org/abs/2212.04382)

    本文研究了在图形输入空间中，分类器边界的结构。通过创建一种新的不确定性度量，称为邻居相似度，我们展示了朴素贝叶斯分类器的边界是巨大且复杂的结构。

    

    无论基于模型、训练数据还是二者组合，分类器将（可能复杂的）输入数据归入相对较少的输出类别之一。本文研究在输入空间为图的情况下，边界的结构——那些被分类为不同类别的邻近点——的特性。我们的科学背景是基于模型的朴素贝叶斯分类器，用于处理由下一代测序仪生成的DNA读数。我们展示了边界既是巨大的，又具有复杂的结构。我们创建了一种新的不确定性度量，称为邻居相似度，它将一个点的结果与其邻居的结果分布进行比较。这个度量不仅追踪了贝叶斯分类器的两个固有不确定性度量，还可以在没有固有不确定性度量的分类器上实现，但需要计算成本。

    Whether based on models, training data or a combination, classifiers place (possibly complex) input data into one of a relatively small number of output categories. In this paper, we study the structure of the boundary--those points for which a neighbor is classified differently--in the context of an input space that is a graph, so that there is a concept of neighboring inputs, The scientific setting is a model-based naive Bayes classifier for DNA reads produced by Next Generation Sequencers. We show that the boundary is both large and complicated in structure. We create a new measure of uncertainty, called Neighbor Similarity, that compares the result for a point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented, at a computational cost, for classifiers without inherent measures of uncertainty.
    
[^32]: 统计对流形假设的探索

    Statistical exploration of the Manifold Hypothesis

    [https://arxiv.org/abs/2208.11665](https://arxiv.org/abs/2208.11665)

    这篇论文通过潜在度量模型从数据中得出了丰富而复杂的流形结构，并提供了解释流形假设的统计解释。该研究为发现和解释高维数据的几何结构以及探索数据生成机制提供了方法。

    

    流形假设是机器学习中广为接受的理论，它认为名义上的高维数据实际上集中在高维空间中的低维流形中。这种现象在许多真实世界的情况中经验性地观察到，在过去几十年中已经导致了多种统计方法的发展，并被认为是现代人工智能技术成功的关键因素。我们表明，通过潜在度量模型这种通用且非常简单的统计模型，可以从数据中生成丰富而有时复杂的流形结构，通过潜变量、相关性和平稳性等基本概念。这为为什么流形假设在这么多情况下似乎成立提供了一个一般的统计解释。在潜在度量模型的基础上，我们提出了发现和解释高维数据几何结构以及探索数据生成机制的程序。

    The Manifold Hypothesis is a widely accepted tenet of Machine Learning which asserts that nominally high-dimensional data are in fact concentrated near a low-dimensional manifold, embedded in high-dimensional space. This phenomenon is observed empirically in many real world situations, has led to development of a wide range of statistical methods in the last few decades, and has been suggested as a key factor in the success of modern AI technologies. We show that rich and sometimes intricate manifold structure in data can emerge from a generic and remarkably simple statistical model -- the Latent Metric Model -- via elementary concepts such as latent variables, correlation and stationarity. This establishes a general statistical explanation for why the Manifold Hypothesis seems to hold in so many situations. Informed by the Latent Metric Model we derive procedures to discover and interpret the geometry of high-dimensional data, and explore hypotheses about the data generating mechanism
    
[^33]: 基于Rademacher复杂度的深度学习一般化界限研究

    On Rademacher Complexity-based Generalization Bounds for Deep Learning

    [https://arxiv.org/abs/2208.04284](https://arxiv.org/abs/2208.04284)

    该论文研究了基于Rademacher复杂度的方法在对卷积神经网络进行少类别图像分类时生成非空泛化界限。其中的关键技术贡献是发展了针对函数空间和具有一般Lipschitz激活函数的CNNs的新的Talagrand压缩引理。

    

    我们展示了基于Rademacher复杂度的方法可以生成对卷积神经网络（CNNs）进行分类少量类别图像非空泛化界限。新的Talagrand压缩引理的发展对于高维映射函数空间和具有一般Lipschitz激活函数的CNNs是一个关键技术贡献。我们的结果表明，Rademacher复杂度不依赖于CNNs的网络长度，特别是对于诸如ReLU，Leaky ReLU，Parametric Rectifier Linear Unit，Sigmoid和Tanh等特定类型的激活函数。

    We show that the Rademacher complexity-based approach can generate non-vacuous generalisation bounds on Convolutional Neural Networks (CNNs) for classifying a small number of classes of images. The development of new Talagrand's contraction lemmas for high-dimensional mappings between function spaces and CNNs for general Lipschitz activation functions is a key technical contribution. Our results show that the Rademacher complexity does not depend on the network length for CNNs with some special types of activation functions such as ReLU, Leaky ReLU, Parametric Rectifier Linear Unit, Sigmoid, and Tanh.
    
[^34]: 无参镜像下降

    Parameter-free Mirror Descent

    [https://arxiv.org/abs/2203.00444](https://arxiv.org/abs/2203.00444)

    本论文针对无界域中构建自适应和无参的算法提出了一种修改后的在线镜像下降框架，并以此为基础开发了具有最优动态遗憾界限的无约束在线线性优化算法，并证明了基于Follow-the-Regularized-Leader的策略无法达到类似效果，此外还应用镜像下降框架构建了新的无参隐式更新以及简化和改进的无约束无标度算法。

    

    我们提出了一种修改后的在线镜像下降框架，适用于在无界域中构建自适应和无参的算法。我们利用这种技术开发了第一个无约束在线线性优化算法，实现了最优的动态遗憾界限，并进一步证明基于Follow-the-Regularized-Leader的自然策略无法达到类似的结果。我们还将我们的镜像下降框架应用于构建无参隐式更新，以及一个简化和改进的无约束无标度算法。

    We develop a modified online mirror descent framework that is suitable for building adaptive and parameter-free algorithms in unbounded domains. We leverage this technique to develop the first unconstrained online linear optimization algorithm achieving an optimal dynamic regret bound, and we further demonstrate that natural strategies based on Follow-the-Regularized-Leader are unable to achieve similar results. We also apply our mirror descent framework to build new parameter-free implicit updates, as well as a simplified and improved unconstrained scale-free algorithm.
    
[^35]: 从生物纠错码到容错神经网络

    Fault-Tolerant Neural Networks from Biological Error Correction Codes

    [https://arxiv.org/abs/2202.12887](https://arxiv.org/abs/2202.12887)

    该论文根据哺乳动物皮质中的模拟纠错码，提出了一种基于生物纠错码的通用容错神经网络，实现了可靠计算；发现了从故障到容错神经计算的相变，为理解嘈杂模拟系统提供了新的途径。

    

    在深度学习中，是否可能实现容错计算一直是一个悬而未决的问题：是否可以仅使用不可靠的神经元实现任意可靠的计算？在哺乳动物皮质的网格细胞中，观察到了模拟纠错码保护状态免受神经射频噪声的现象，但其在信息处理中的作用尚不清楚。在本研究中，我们利用这些生物纠错码，开发了一种通用的容错神经网络，如果每个神经元的故障性都低于一个严格的阈值，则能够实现可靠的计算；令人惊讶的是，我们发现嘈杂的生物神经元低于这个阈值。从故障到容错神经计算的相变的发现，揭示了皮质中可靠计算的机制，为理解与人工智能和神经形态计算有关的嘈杂模拟系统打开了一条道路。

    It has been an open question in deep learning if fault-tolerant computation is possible: can arbitrarily reliable computation be achieved using only unreliable neurons? In the grid cells of the mammalian cortex, analog error correction codes have been observed to protect states against neural spiking noise, but their role in information processing is unclear. Here, we use these biological error correction codes to develop a universal fault-tolerant neural network that achieves reliable computation if the faultiness of each neuron lies below a sharp threshold; remarkably, we find that noisy biological neurons fall below this threshold. The discovery of a phase transition from faulty to fault-tolerant neural computation suggests a mechanism for reliable computation in the cortex and opens a path towards understanding noisy analog systems relevant to artificial intelligence and neuromorphic computing.
    
[^36]: 深度残差神经网络通过非线性控制理论实现通用逼近能力

    Universal Approximation Power of Deep Residual Neural Networks via Nonlinear Control Theory

    [https://arxiv.org/abs/2007.06007](https://arxiv.org/abs/2007.06007)

    本文通过非线性控制理论解释了深度残差神经网络的通用逼近能力，并提供了一个充分条件，在激活函数满足二次微分方程的情况下，一个足够深的神经网络能够在紧集合上逼近任意连续函数。

    

    本文通过几何非线性控制来解释深度残差神经网络的通用逼近能力。受到最近建立残差网络和控制系统之间联系的工作的启发，我们提供了一个一般的充分条件，要求激活函数或其导数之一满足一个二次微分方程，以使残差网络具有通用逼近能力。在实践中使用的许多激活函数满足这个假设，我们证明这个属性足以让一个足够深的具有$n+1$神经元每层的神经网络，在紧集合上相对于最大范数逼近任意连续的从$\mathbb{R}^n$到$\mathbb{R}^n$的函数。我们进一步展示了这个结果适用于非常简单的架构，只需要权重取两个值。第一个关键技术贡献是将通用逼近与残差神经网络的几何非线性控制相联系。

    In this paper, we explain the universal approximation capabilities of deep residual neural networks through geometric nonlinear control. Inspired by recent work establishing links between residual networks and control systems, we provide a general sufficient condition for a residual network to have the power of universal approximation by asking the activation function, or one of its derivatives, to satisfy a quadratic differential equation. Many activation functions used in practice satisfy this assumption, exactly or approximately, and we show this property to be sufficient for an adequately deep neural network with $n+1$ neurons per layer to approximate arbitrarily well, on a compact set and with respect to the supremum norm, any continuous function from $\mathbb{R}^n$ to $\mathbb{R}^n$. We further show this result to hold for very simple architectures for which the weights only need to assume two values. The first key technical contribution consists of relating the universal approxi
    
[^37]: 同时进行正数据-无标签学习和有条件生成，利用额外数据来分类和生成

    Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data

    [https://arxiv.org/abs/2006.07841](https://arxiv.org/abs/2006.07841)

    本论文提出了一种同时利用正数据-无标签学习和有条件生成的训练框架，以及额外无标签数据的方法。通过使用一个对噪声标签具有鲁棒性的分类器噪声不变有条件生成对抗网络来提高PU分类器的性能，并利用PU分类器预测的标签和额外数据来帮助生成。实验结果证明了该方法的有效性。

    

    在许多机器学习问题中，标记类别数据的稀缺性是一个普遍存在的瓶颈。虽然存在丰富的无标签数据并提供潜在的解决方案，但利用它们是非常具有挑战性的。本文通过同时利用正数据-无标签（Positive-Unlabeled，PU）分类和有条件生成，以及额外的无标签数据，解决了这个问题。特别地，我们提出了一个新的训练框架，使得在面对额外数据（尤其是分布外的无标签数据）时，同时进行PU分类和有条件生成成为可能，通过探索它们之间的相互作用：1）通过一个对噪声标签具有鲁棒性的新型分类器噪声不变有条件生成对抗网络（Classifier-Noise-Invariant Conditional GAN，CNI-CGAN）来提高PU分类器的性能，2）利用PU分类器预测的标签和额外数据来帮助生成。从理论上，我们证明了CNI-CGAN的最优条件，并在实验中通过广泛的评估来验证了我们的方法。

    The scarcity of class-labeled data is a ubiquitous bottleneck in many machine learning problems. While abundant unlabeled data typically exist and provide a potential solution, it is highly challenging to exploit them. In this paper, we address this problem by leveraging Positive-Unlabeled~(PU) classification and the conditional generation with extra unlabeled data \emph{simultaneously}. In particular, we present a novel training framework to jointly target both PU classification and conditional generation when exposed to extra data, especially out-of-distribution unlabeled data, by exploring the interplay between them: 1) enhancing the performance of PU classifiers with the assistance of a novel Classifier-Noise-Invariant Conditional GAN~(CNI-CGAN) that is robust to noisy labels, 2) leveraging extra data with predicted labels from a PU classifier to help the generation. Theoretically, we prove the optimal condition of CNI-CGAN, and experimentally, we conducted extensive evaluations on
    
[^38]: 具有合成对照组的自适应实验设计

    Adaptive Experiment Design with Synthetic Controls. (arXiv:2401.17205v1 [stat.ML])

    [http://arxiv.org/abs/2401.17205](http://arxiv.org/abs/2401.17205)

    这种方法提出了Syntax，一个具有合成对照组的自适应实验设计，能够在多个亚群体中识别出具有正面治疗效果的亚群体，对于多样化患者反应的临床试验具有样本效率的优势。

    

    临床试验通常用于了解新治疗对给定患者群体的影响。然而，大规模群体中的患者很少以相同的方式对待相同的治疗做出反应。患者反应的多样性需要进行多个亚群体的效果研究 - 尤其是当治疗对整体群体没有或几乎没有益处，而对特定亚群体可能具有显著的益处时。基于这种需求，我们提出了Syntax，一种探索性试验设计，在众多亚群体中识别具有正面治疗效果的亚群体。Syntax具有样本效率，因为它(i) 自适应招募和分配患者，(ii) 通过合成对照组形成每个亚群体的控制样本，从而估计治疗效果。我们通过实验证实了Syntax的性能，并提供了关于它何时可能优于传统试验设计的见解。

    Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations - especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through e
    
[^39]: FairWASP：快速和最优的公平Wasserstein预处理

    FairWASP: Fast and Optimal Fair Wasserstein Pre-processing. (arXiv:2311.00109v1 [cs.LG])

    [http://arxiv.org/abs/2311.00109](http://arxiv.org/abs/2311.00109)

    FairWASP是一种快速和最优的公平Wasserstein预处理方法，通过重新加权数据集来减少分类数据集中的不平等性，同时满足人口平等性准则。这种方法可以用于构建可以输入任何分类方法的数据集。

    

    近年来，机器学习方法的快速发展旨在减少不同子群体之间模型输出的不平等性。在许多情况下，训练数据可能会被不同用户在多个下游应用中使用，这意味着对训练数据本身进行干预可能是最有效的。在这项工作中，我们提出了一种新的预处理方法FairWASP，旨在减少分类数据集中的不平等性，而不会修改原始数据。FairWASP返回样本级权重，使重新加权的数据集最小化与原始数据集的Wasserstein距离，同时满足（经验版本的）人口平等性，这是一种常用的公平性准则。我们从理论上证明了整数权重的最优性，这意味着我们的方法可以等同地理解为复制或删除样本。因此，FairWASP可用于构建可以输入任何分类方法的数据集，而不仅仅是接受样本权重的方法。

    Recent years have seen a surge of machine learning approaches aimed at reducing disparities in model outputs across different subgroups. In many settings, training data may be used in multiple downstream applications by different users, which means it may be most effective to intervene on the training data itself. In this work, we present FairWASP, a novel pre-processing approach designed to reduce disparities in classification datasets without modifying the original data. FairWASP returns sample-level weights such that the reweighted dataset minimizes the Wasserstein distance to the original dataset while satisfying (an empirical version of) demographic parity, a popular fairness criterion. We show theoretically that integer weights are optimal, which means our method can be equivalently understood as duplicating or eliminating samples. FairWASP can therefore be used to construct datasets which can be fed into any classification method, not just methods which accept sample weights. Ou
    
[^40]: 重新审视苹果品尝的可学习性

    Revisiting the Learnability of Apple Tasting. (arXiv:2310.19064v1 [cs.LG])

    [http://arxiv.org/abs/2310.19064](http://arxiv.org/abs/2310.19064)

    该论文重新审视了苹果品尝的可学习性，从组合角度研究了在线可学习性。作者通过引入Effective width参数，紧密量化了在可实现设置中的极小期望错误，并在可实现设置中建立了极小期望错误数量的三分法。

    

    在在线二元分类中，学习者只有在预测为"1"时观察到真实标签。本文重新研究了这种经典的部分反馈设置，并从组合角度研究了在线可学习性。我们证明了在不可知设置下，Littlestone维度仍然是苹果品尝的紧密定量刻画，解决了\cite{helmbold2000apple}提出的一个悬而未决的问题。此外，我们给出了一个新的组合参数，称为有效宽度，紧密量化了在可实现设置中的极小期望错误。作为推论，我们使用有效宽度在可实现设置中建立了极小期望错误数量的三分法。特别地，我们证明了在可实现设置中，任何学习者在苹果品尝反馈下的期望错误数量只能是$\Theta(1), \Theta(\sqrt{T})$, 或 $\Theta(T)$。

    In online binary classification under \textit{apple tasting} feedback, the learner only observes the true label if it predicts "1". First studied by \cite{helmbold2000apple}, we revisit this classical partial-feedback setting and study online learnability from a combinatorial perspective. We show that the Littlestone dimension continues to prove a tight quantitative characterization of apple tasting in the agnostic setting, closing an open question posed by \cite{helmbold2000apple}. In addition, we give a new combinatorial parameter, called the Effective width, that tightly quantifies the minimax expected mistakes in the realizable setting. As a corollary, we use the Effective width to establish a \textit{trichotomy} of the minimax expected number of mistakes in the realizable setting. In particular, we show that in the realizable setting, the expected number of mistakes for any learner under apple tasting feedback can only be $\Theta(1), \Theta(\sqrt{T})$, or $\Theta(T)$.
    
[^41]: 深度回溯对因果一致解释的反事实推理

    Deep Backtracking Counterfactuals for Causally Compliant Explanations. (arXiv:2310.07665v1 [cs.AI])

    [http://arxiv.org/abs/2310.07665](http://arxiv.org/abs/2310.07665)

    本研究提供了一种实用方法，用于在深度生成组件的结构因果模型中计算回溯反事实。通过在因果模型的结构化潜在空间中解决优化问题，我们的方法能够生成反事实，并且与其他方法相比具备了多功能、模块化和符合因果关系的特点。

    

    反事实推理可以通过回答在改变情况下会观察到什么来提供有价值的见解，条件是根据实际观察。虽然经典的介入式解释已经得到了广泛研究，回溯原则被提出作为一种保持所有因果定律完整性的替代哲学，但其研究较少。在本研究中，我们介绍了在由深度生成组件组成的结构因果模型中计算回溯反事实的实用方法。为此，我们对结构分配施加了条件，通过在因果模型的结构化潜在空间中解决一个可行的约束优化问题来生成反事实。我们的方法还可以与反事实解释领域的方法进行比较。与这些方法相比，我们的方法代表了一种多功能、模块化和遵守因果的替代方案。

    Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. 
    
[^42]: 动态时间序列的发展预测在时间不变性和线性性的帮助下

    Forecasting of the development of a partially-observed dynamical time series with the aid of time-invariance and linearity. (arXiv:2306.16593v1 [stat.ME])

    [http://arxiv.org/abs/2306.16593](http://arxiv.org/abs/2306.16593)

    本研究提出了一种自回归松弛时间序列（ARS）模型，通过考虑动态系统的时间不变性和线性性，同时估计演化函数和缺失变量，用于预测动态时间序列中缺失变量的发展。

    

    动态系统产生一种依赖多元序列，称为动态时间序列，通过演化函数发展而来。由于当前时间点的动态时间序列变量通常依赖于前一个时间点的所有变量，现有研究通过估计演化函数来预测未来时间点的变量。然而，在某些实际情况下，动态时间序列中的一些变量是缺失的。本研究提出了一种自回归松弛时间序列（ARS）模型。ARS模型涉及演化函数和作为松弛时间序列的潜在缺失变量的同时估计，借助于动态系统的时间不变性和线性性。本研究实证了提出的ARS模型的有效性。

    A dynamical system produces a dependent multivariate sequence called dynamical time series, developed with an evolution function. As variables in the dynamical time series at the current time-point usually depend on the whole variables in the previous time-point, existing studies forecast the variables at the future time-point by estimating the evolution function. However, some variables in the dynamical time-series are missing in some practical situations. In this study, we propose an autoregressive with slack time series (ARS) model. ARS model involves the simultaneous estimation of the evolution function and the underlying missing variables as a slack time series, with the aid of the time-invariance and linearity of the dynamical system. This study empirically demonstrates the effectiveness of the proposed ARS model.
    
[^43]: 生成对抗网络中真实数据和生成数据统计的概率匹配

    Probabilistic matching of real and generated data statistics in generative adversarial networks. (arXiv:2306.10943v1 [stat.ML])

    [http://arxiv.org/abs/2306.10943](http://arxiv.org/abs/2306.10943)

    本文提出一种通过向生成器损失函数中添加KL散度项的方法，来保证生成数据统计分布与真实数据的相应分布重合，并在实验中展示了此方法的优越性能。

    

    生成对抗网络是一种强大的生成建模方法。虽然生成样本往往难以区分真实数据，但不能保证它们遵循真实数据分布。本文提出了一种方法，确保某些生成数据统计分布与真实数据的相应分布重合。为此，我们在生成器损失函数中添加了Kullback-Leibler项：KL散度是在每次迭代中从小批量值获得的相应生成分布和由条件能量模型表示的真实分布之间的差异。我们在一个合成数据集和两个实际数据集上评估了该方法，并展示了我们方法的优越性能。

    Generative adversarial networks constitute a powerful approach to generative modeling. While generated samples often are indistinguishable from real data, there is no guarantee that they will follow the true data distribution. In this work, we propose a method to ensure that the distributions of certain generated data statistics coincide with the respective distributions of the real data. In order to achieve this, we add a Kullback-Leibler term to the generator loss function: the KL divergence is taken between the true distributions as represented by a conditional energy-based model, and the corresponding generated distributions obtained from minibatch values at each iteration. We evaluate the method on a synthetic dataset and two real-world datasets and demonstrate improved performance of our method.
    
[^44]: 核去偏插值估计

    Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])

    [http://arxiv.org/abs/2306.08598](http://arxiv.org/abs/2306.08598)

    本文提出了一种高效、不需要实现影响函数且可计算的去偏插值估计方法。

    

    本文考虑在干扰参数存在的情况下估计标量目标参数的问题。采用非参数估计器（例如机器学习（ML）模型）替换未知干扰参数是方便的，但因存在较大偏差而效率低下。为了避免偏差-方差权衡的次优选择，现代方法会进行插值预估的去偏差操作，如有目标最小损失估计（TMLE）和双机器学习（DML）等。现有的去偏方法需要将目标参数的影响函数（IF）作为输入，然而，IF的推导需要专业知识，从而阻碍了这些方法的适应性。我们提出了一种新的去偏插入估计器的方法，它（i）高效、（ii）不需要实现IF、（iii）可计算。

    We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
    
[^45]: 高斯门控混合专家模型参数估计的收敛速率研究

    Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts. (arXiv:2305.07572v1 [stat.ML])

    [http://arxiv.org/abs/2305.07572](http://arxiv.org/abs/2305.07572)

    本文提出新颖的Voronoi Loss函数来解决高斯门控混合专家模型参数估计的收敛速率问题，并在两种不同的门控网络下提供理论收敛速率的证明。

    

    混合专家模型因其在集成学习中的应用而被引入神经网络中，近年来成为现代深度神经网络中处理异构数据分析的基本构件。然而，对于高斯门控混合专家模型参数估计的收敛行为的理解还不充分。我们通过设计新颖的Voronoi Loss函数来解决这些问题，并提供了理论收敛速率的证明，揭示了在两种分离的门控网络下最大似然估计器的不同行为。

    Originally introduced as a neural network for ensemble learning, mixture of experts (MoE) has recently become a fundamental building block of highly successful modern deep neural networks for heterogeneous data analysis in several applications, including those in machine learning, statistics, bioinformatics, economics, and medicine. Despite its popularity in practice, a satisfactory level of understanding of the convergence behavior of Gaussian-gated MoE parameter estimation is far from complete. The underlying reason for this challenge is the inclusion of covariates in the Gaussian gating and expert networks, which leads to their intrinsically complex interactions via partial differential equations with respect to their parameters. We address these issues by designing novel Voronoi loss functions to accurately capture heterogeneity in the maximum likelihood estimator (MLE) for resolving parameter estimation in these models. Our results reveal distinct behaviors of the MLE under two se
    
[^46]: 一种新的具有自适应停止准则的非精确近端线性算法，用于鲁棒相位恢复问题。

    A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria for Robust Phase Retrieval. (arXiv:2304.12522v1 [math.OC])

    [http://arxiv.org/abs/2304.12522](http://arxiv.org/abs/2304.12522)

    本文提出了一种新的鲁棒相位恢复算法，通过使用自适应停止准则的非精确近端线性算法，该方法在实验中证明比现有方法更高效。

    

    本文考虑了鲁棒相位恢复问题，该问题可视为一个非光滑和非凸优化问题。我们提出了一种新的非精确近端线性算法，其中子问题被不精确求解。我们的贡献是为子问题提出了两种自适应停止准则。我们分析了所提出方法的收敛性能。通过对合成和实际数据集的实验，我们证明了我们的方法比现有方法更高效，例如原始近端线性算法和次梯度方法。

    This paper considers the robust phase retrieval problem, which can be cast as a nonsmooth and nonconvex optimization problem. We propose a new inexact proximal linear algorithm with the subproblem being solved inexactly. Our contributions are two adaptive stopping criteria for the subproblem. The convergence behavior of the proposed methods is analyzed. Through experiments on both synthetic and real datasets, we demonstrate that our methods are much more efficient than existing methods, such as the original proximal linear algorithm and the subgradient method.
    

