# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](https://arxiv.org/abs/2404.01245) | 该论文提出了一个通用框架，用于设计大型语言模型水印的统计效率和检测规则，通过关键统计量和秘密密钥控制误报率，同时评估水印检测规则的能力。 |
| [^2] | [Optimal Ridge Regularization for Out-of-Distribution Prediction](https://arxiv.org/abs/2404.01233) | 研究了针对分布外预测的最优岭回归正则化下的行为，并建立了确定最优正则化水平的一般条件，揭示了与分布内设置的鲜明差异。 |
| [^3] | [Novel Node Category Detection Under Subpopulation Shift](https://arxiv.org/abs/2404.01216) | 提出了一种新方法 RECO-SLIP，用于在属性图中检测属于新类别的节点，能够有效解决子群体转移下的节点检测问题，实验证明其性能优越。 |
| [^4] | [Large-Scale Non-convex Stochastic Constrained Distributionally Robust Optimization](https://arxiv.org/abs/2404.01200) | 本文开发了一种用于非凸约束分布鲁棒优化的随机算法，其计算复杂度与整体数据集大小无关，适用于大规模应用。 |
| [^5] | [Nearly-tight Approximation Guarantees for the Improving Multi-Armed Bandits Problem](https://arxiv.org/abs/2404.01198) | 对改进的多臂老虎机问题，我们给出了一个随机在线算法，可以在不了解最优臂最大奖励的情况下，以$O(\sqrt{k} \log k)$的逼近相对于最优。 |
| [^6] | [TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression](https://arxiv.org/abs/2404.01153) | 提出了一种新型融合正则化器的两步法方法，有效处理高维回归中的模型偏移和协变量转移，提高了目标任务的学习性能，具有稳健性并满足最小-最大最优条件。 |
| [^7] | [SoK: A Review of Differentially Private Linear Models For High-Dimensional Data](https://arxiv.org/abs/2404.01141) | 本文对高维数据中差分私有线性模型的优化方法进行全面审查，发现鲁棒和优化的坐标算法效果最好，可为未来研究提供参考。 |
| [^8] | [The Rate-Distortion-Perception Trade-off: The Role of Private Randomness](https://arxiv.org/abs/2404.01111) | 私有随机性在图像压缩中的作用在两种逼真度约束条件下得到阐明，以实现感知质量和失真之间的权衡。 |
| [^9] | [Finite Sample Frequency Domain Identification](https://arxiv.org/abs/2404.01100) | 本研究提出了一种在有限样本情况下进行非参数频域系统识别的方法，通过Empirical Transfer Function Estimate（ETFE）在特定频率处准确估计频率响应，并证明在次高斯彩色噪声和稳定性假设下，ETFE估计值准确可靠。 |
| [^10] | [Inference in Randomized Least Squares and PCA via Normality of Quadratic Forms](https://arxiv.org/abs/2404.00912) | 本文提出了一种通过随机草图或投影来进行统计推断的统一方法，适用于最小二乘和PCA问题，针对广泛范围的草图分布提出了统计推断方法，展示了某些二次形式的渐近正态性。 |
| [^11] | [Learning the mechanisms of network growth](https://arxiv.org/abs/2404.00793) | 我们提出了一种新的模型选择方法，通过在大量合成网络数据上训练分类器，设计出易于计算、解析可处理且具有解释性的动态特征类型，实现了几乎完美的网络分类，超过了目前技术水平。 |
| [^12] | [PyTorch Frame: A Modular Framework for Multi-Modal Tabular Learning](https://arxiv.org/abs/2404.00776) | PyTorch Frame是一个用于处理多模态表格数据的PyTorch框架，通过提供数据结构、模型抽象和外部基础模型整合等功能，实现了模块化的表格模型实现，并成功将这些模型应用于复杂的数据集。 |
| [^13] | [Adversarially-Robust Inference on Trees via Belief Propagation](https://arxiv.org/abs/2404.00768) | 确认了一个民间信念，即恶意对手可以破坏特定叶子节点使得推断变得不可能，但是可以实现对根节点的准确后验推断 |
| [^14] | [C-XGBoost: A tree boosting model for causal effect estimation](https://arxiv.org/abs/2404.00751) | 该论文提出了一种名为C-XGBoost的树提升模型，可用于预测潜在结果，结合了基于树的模型和基于神经网络的因果推断模型的优势，同时继承了XGBoost模型的高效处理缺失值特征的优势。 |
| [^15] | [Two-Stage Nuisance Function Estimation for Causal Mediation Analysis](https://arxiv.org/abs/2404.00735) | 通过两阶段估计策略，该研究提出了一种针对因果中介分析中干扰函数的方法，旨在根据其在偏差结构中的作用来估计干扰函数。 |
| [^16] | [Meta Learning in Bandits within Shared Affine Subspaces](https://arxiv.org/abs/2404.00688) | 通过利用低维仿射子空间集中性，我们提出两种策略解决了在多个环境随机臂上任务中减少预期遗憾的问题。 |
| [^17] | [Convergence of Continuous Normalizing Flows for Learning Probability Distributions](https://arxiv.org/abs/2404.00551) | 本文研究了具有线性插值的CNFs在从有限随机样本中学习概率分布时的理论性质，建立了非渐近误差界，并提供了收敛分析框架。 |
| [^18] | [Minimum-Norm Interpolation Under Covariate Shift](https://arxiv.org/abs/2404.00522) | 本研究首次证明了在转移学习设置下，良性过拟合线性插值器的非渐近超额风险界，并提出了一种新的分类方法。 |
| [^19] | [Transfer Learning with Reconstruction Loss](https://arxiv.org/abs/2404.00505) | 本文通过引入额外的重建阶段和重建损失，提出了一种具有共享模型参数和特征表示的模型训练方法，建立了共同信息的概念，用于解决相关任务。 |
| [^20] | [Convolutional Bayesian Filtering](https://arxiv.org/abs/2404.00481) | 引入不等条件的额外事件，将条件概率转化为特殊积分形式，推广为卷积形式的新滤波框架，称为卷积贝叶斯滤波。 |
| [^21] | [Linguistic Calibration of Language Models](https://arxiv.org/abs/2404.00474) | 该论文提出了一种通过语言模型的文本生成来实现语言校准，可以使用户做出校准概率预测的方法。 |
| [^22] | [Communication Efficient Distributed Training with Distributed Lion](https://arxiv.org/abs/2404.00438) | 分布式狮子是对 Lion 进行了创新性改进，利用符号操作符降低了通信成本，在分布式训练中取得了与标准 Lion 或 AdamW 优化器相当的性能，并显著减少了通信带宽。 |
| [^23] | [Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data](https://arxiv.org/abs/2404.00221) | 学习利用观测数据提出了一种逐步双重强健方法，通过向后归纳解决了最佳动态治疗方案的问题 |
| [^24] | [Partially-Observable Sequential Change-Point Detection for Autocorrelated Data via Upper Confidence Region](https://arxiv.org/abs/2404.00220) | 提出了一种适用于可部分观测多传感器序贯变点检测的自适应上置信区间状态空间模型（AUCRSS），通过自适应采样策略实现高效的变点检测和定位。 |
| [^25] | [Functional-Edged Network Modeling](https://arxiv.org/abs/2404.00218) | 本研究提出了一种功能边缘网络模型，通过将边视为功能数据，并引入额外维度来表示函数，使用Tucker功能分解处理功能邻接张量，进行模型推断以解决不规则观测问题，并通过正则化使基础矩阵对称化，最终展示了模型的理想属性。 |
| [^26] | [Verifying the Selected Completely at Random Assumption in Positive-Unlabeled Learning](https://arxiv.org/abs/2404.00145) | 在正-无监督学习中，研究了验证完全随机选择假设（SCAR）和更为现实的随机选择假设（SAR）对算法复杂性和速度的影响。 |
| [^27] | [Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes](https://arxiv.org/abs/2404.00099) | 在对抗性环境中，本论文提出了一种可修改转移核密度的扰动模型，拓展了传统的边缘敏感性模型，对无限时间RL中策略价值进行了尖锐边界的刻画和估计。 |
| [^28] | [Bayesian Nonparametrics: An Alternative to Deep Learning](https://arxiv.org/abs/2404.00085) | 贝叶斯非参数模型为统计模型选择提供了灵活而强大的框架，揭示了贝叶斯非参数方法的多才多艺和高效性，为在各个学科领域中应对复杂挑战提供了创新解决方案。 |
| [^29] | [Stochastic Optimization with Constraints: A Non-asymptotic Instance-Dependent Analysis](https://arxiv.org/abs/2404.00042) | 该论文研究了具有凸约束的随机凸优化问题，提出了一种非渐近保证的VRPG算法，并展示了其性能受到解以及带凸约束解决的问题的缩放距离控制。 |
| [^30] | [Empowering Credit Scoring Systems with Quantum-Enhanced Machine Learning](https://arxiv.org/abs/2404.00015) | 提出了一种名为Systemic Quantum Score (SQS)的新方法，展示在金融领域生产级应用案例中相比纯经典模型更有优势，能够从较少数据点中提取模式并表现出更好性能。 |
| [^31] | [Kernel Multigrid: Accelerate Back-fitting via Sparse Gaussian Process Regression](https://arxiv.org/abs/2403.13300) | 通过核包技术证明反向拟合的收敛速度，并提出了核多重网格算法，通过稀疏高斯过程回归增强反向拟合，适用于结构化和分散数据的加性GPs。 |
| [^32] | [A Provably Accurate Randomized Sampling Algorithm for Logistic Regression](https://arxiv.org/abs/2402.16326) | 提出了一种逻辑回归问题的简单随机抽样算法，通过随机矩阵乘法实现高质量逼近估计概率和模型整体差异性。 |
| [^33] | [Nesting Particle Filters for Experimental Design in Dynamical Systems](https://arxiv.org/abs/2402.07868) | 本文提出了一种新颖的方法来解决动态系统中的贝叶斯实验设计问题，利用嵌套粒子滤波器和立体蒙特卡洛方法来进行基于梯度的策略优化，相比于其他方法具有更好的性能。 |
| [^34] | [Causal Bayesian Optimization via Exogenous Distribution Learning](https://arxiv.org/abs/2402.02277) | 本文引入了一种新的方法，通过学习外源变量的分布，提高了结构化因果模型的近似精度，并将因果贝叶斯优化扩展到更一般的因果方案。 |
| [^35] | [Handling The Non-Smooth Challenge in Tensor SVD: A Multi-Objective Tensor Recovery Framework](https://arxiv.org/abs/2311.13958) | 提出一种具有可学习张量核范数的新型张量恢复模型，引入交替近端乘子方法（APMM）优化算法，解决处理非光滑变化的张量数据挑战 |
| [^36] | [Riemannian Laplace Approximation with the Fisher Metric](https://arxiv.org/abs/2311.02766) | 黎曼拉普拉斯逼近的新方法利用Fisher度量提供更丰富的逼近族，解决了在无限数据极限下先前方法度量选择不当导致逼近过于狭窄和有偏的问题。 |
| [^37] | [Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities](https://arxiv.org/abs/2302.07615) | 相似性、压缩和局部更新是本文提出的三大技术，用于减少分布式变分不等式问题中通信轮次和成本，实现了前所未有的三重协同作用。 |
| [^38] | [Identifiable Latent Causal Content for Domain Adaptation under Latent Covariate Shift](https://arxiv.org/abs/2208.14161) | 提出了一种新的隐含协变量转移（LCS）范式，增加了领域间的可变性和适应性，并提供了恢复标签变量潜在原因的理论保证。 |
| [^39] | [Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency](https://arxiv.org/abs/2205.13476) | 论文提出了一种名为Embed to Control（ETC）的强化学习算法，通过在两个级别学习表示的方法来解决部分观察马尔可夫决策问题，以实现样本高效利用。 |
| [^40] | [Aligning Logits Generatively for Principled Black-Box Knowledge Distillation](https://arxiv.org/abs/2205.10490) | 本文提出了一个新的黑盒知识蒸馏方法MEKD，通过将教师和学生模型的低维度对数对齐，实现将一个繁琐模型压缩成轻量级模型。 |
| [^41] | [Reinforcement Learning from Partial Observation: Linear Function Approximation with Provable Sample Efficiency](https://arxiv.org/abs/2204.09787) | 该研究提出了一种基于线性函数逼近的部分观测强化学习算法（OP-TENET），在有限的情节数内实现了$\epsilon$-最优策略，样本复杂度与线性结构的本征维度多项式缩放，与观测和状态空间的大小无关。 |
| [^42] | [Detection of Small Holes by the Scale-Invariant Robust Density-Aware Distance (RDAD) Filtration](https://arxiv.org/abs/2204.07821) | 通过引入鲁棒密度感知距离（RDAD）过滤，该方法能够在概率密度函数中准确区分被高密度区域包围的小孔，对噪声和异常值具有鲁棒性。 |
| [^43] | [Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic](https://arxiv.org/abs/2112.13530) | 本文通过均场分析研究了基于特征的神经AC的演化和收敛，提出了一个使用两个学习率更新的AC版本，其中评论家通过大步长进行TD学习更新，演员通过小步长进行PPO更新。 |
| [^44] | [Valid prediction intervals for regression problems](https://arxiv.org/abs/2107.00363) | 本文回顾了回归问题中四类预测区间估计方法，并指出了一些方法在不同数据集上性能波动大的原因。 |
| [^45] | [Variational Transport: A Convergent Particle-BasedAlgorithm for Distributional Optimization](https://arxiv.org/abs/2012.11554) | 提出了一种新的基于粒子的算法，名为变分传输，通过迭代地推动一组粒子，在概率分布流形上近似执行沃瑟斯坦梯度下降。 |
| [^46] | [Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory](https://arxiv.org/abs/2006.04761) | 研究探讨离散时间差分学习和Q学习在深度强化学习中的特征表示演变，证明利用过度参数化的方法可以实现这种演变，并关注特征表示对于算法收敛的重要性。 |
| [^47] | [Provably Efficient Exploration in Policy Optimization](https://arxiv.org/abs/1912.05830) | OPPO是第一个在探索中高效的策略优化算法，在处理具有线性函数近似、未知转移和对抗性奖励的问题中取得了 $\tilde{O}(\sqrt{d^2 H^3 T} )$ 的遗憾。 |
| [^48] | [Quantum Machine Learning: from NISQ to Fault Tolerance.](http://arxiv.org/abs/2401.11351) | 本文提供了对量子机器学习领域的全面回顾，涵盖了在NISQ技术和容错量子计算硬件上使用的技术和算法，并深入讨论了与量子机器学习相关的基本概念和统计学习理论。 |
| [^49] | [Fun with Flags: Robust Principal Directions via Flag Manifolds.](http://arxiv.org/abs/2401.04071) | 本研究提出了一种统一的PCA和其变种框架，该框架基于线性子空间旗帜，并引入了对异常值和数据流形的考虑。通过在旗帜流形上进行优化问题的求解，结合主测地线近似，提出了一系列新的降维算法。 |
| [^50] | [Intrinsic Gaussian Vector Fields on Manifolds.](http://arxiv.org/abs/2310.18824) | 本文提出了一种新型的在流形上处理矢量值信号的高斯过程模型，具有内在定义和考虑空间几何的特点，并为部署在二维球面和超曲面上的Hodge-Mat\'ern高斯向量场提供了计算基元。 |
| [^51] | [Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards.](http://arxiv.org/abs/2310.18715) | 本文提出的ROAM和ROOM算法框架通过将中位数法与离线强化学习策略相结合，提供了对重尾奖励的直接不确定性估计，从而增强了离线强化学习在现实应用中的鲁棒性。 |
| [^52] | [Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity.](http://arxiv.org/abs/2310.17247) | 本文发现神经网络中的grokking现象不仅局限于神经网络，还出现在其他算法和模型中。通过在数据集中添加虚假信息的维度，可以诱发grokking现象。研究表明，grokking现象在解决方案搜索受复杂性和错误指导的任何情况下可能发生。这对理解grokking现象提供了更广泛的理论支持。 |
| [^53] | [Principled Approaches for Learning to Defer with Multiple Experts.](http://arxiv.org/abs/2310.14774) | 我们研究了多个专家学习推迟问题的代理损失和算法，并证明了这些代理损失函数具有强H一致性界限。我们展示了几个实际应用的代理损失函数，并设计了基于最小化这些损失函数的新的学习推迟算法。我们还进行了在SVHN和CIFAR-10数据集上的实验。 |
| [^54] | [Predictor-Rejector Multi-Class Abstention: Theoretical Analysis and Algorithms.](http://arxiv.org/abs/2310.14772) | 我们研究了多类别分类设置中的学习与放弃框架，并提出了一系列新的理论和算法结果，解决了两个现存的开放问题。这些保证为基于最小化放弃损失的新的多类别放弃算法提供了启示。 |
| [^55] | [Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention.](http://arxiv.org/abs/2310.14770) | 本文提出了基于分数的多类放弃的理论基础损失函数和算法，包括引入了新的代理损失函数族群以及证明了这些代理损失的一致性保证。我们通过实验证明了这些算法的实际意义。 |
| [^56] | [Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting.](http://arxiv.org/abs/2310.06081) | 本文研究了一类广泛的马尔可夫链，即Ito链的Ito扩散逼近。与大多数相关论文不同，我们的链具有各向同性和状态相关的噪声，并可以适用于多种应用场景。我们证明了Ito链与对应的随机微分方程之间的W2-距离的上界。这些结果改进了已有的估计方法，并在某些特殊情况下提供了首次的分析。 |
| [^57] | [Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion.](http://arxiv.org/abs/2310.02279) | 提出了一种一致性轨迹模型（CTM），它可以加速扩散模型的采样，同时通过对抗训练和去噪得分匹配损失的组合来提高性能，并实现了最先进的采样质量。 |
| [^58] | [Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs.](http://arxiv.org/abs/2308.16859) | 本文研究了学习动态有向无环图（DDAG）的信息理论最优样本复杂度，提出了一种基于观测时间序列的功率谱密度矩阵的度量和算法来重建DDAG。 |
| [^59] | [PCA, SVD, and Centering of Data.](http://arxiv.org/abs/2307.15213) | 本研究详细研究了PCA方法中数据居中化步骤的影响，分析了带居中化和不带居中化的两个PCA嵌入之间的对齐性，并探讨了其与奇异向量以及均值方向之间的关系。 |
| [^60] | [First Order Methods with Markovian Noise: from Acceleration to Variational Inequalities.](http://arxiv.org/abs/2305.15938) | 本论文研究了涉及马尔科夫噪声的随机优化问题，提出了一种适用于非凸和强凸最小化问题的一阶梯度方法，使用基于多层蒙特卡罗方法的随机批处理方案以获得最优线性关系，并消除了以前研究中的限制条件。在马尔可夫噪声下对变分不等式的扩展是原创性的。 |
| [^61] | [Online Convex Optimization with Unbounded Memory.](http://arxiv.org/abs/2210.09903) | 本论文提出了一种新的在线凸优化框架，可以处理决策历史的长期依赖关系，并介绍了用于量化依赖程度的$p$-有效内存容量的概念。 |
| [^62] | [Estimating large causal polytrees from small samples.](http://arxiv.org/abs/2209.07028) | 本文介绍了一种算法，可以在变量数量远大于样本大小的情况下，准确地估计大规模因果多树结构，而几乎不需要任何分布或建模的假设。 |
| [^63] | [Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes.](http://arxiv.org/abs/2205.13589) | 本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。 |
| [^64] | [Multitask Learning and Bandits via Robust Statistics.](http://arxiv.org/abs/2112.14233) | 本研究探讨了多任务学习以及Bandits方法的健壮统计学实现，提出了一种新颖的两阶段多任务学习估计器，该估计器以一种样本高效的方式利用共享全局参数和稀疏实例特定术语的结构。 |

# 详细

[^1]: 大型语言模型水印的统计框架: 枢轴、检测效率和最优规则

    A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules

    [https://arxiv.org/abs/2404.01245](https://arxiv.org/abs/2404.01245)

    该论文提出了一个通用框架，用于设计大型语言模型水印的统计效率和检测规则，通过关键统计量和秘密密钥控制误报率，同时评估水印检测规则的能力。

    

    自ChatGPT于2022年11月推出以来，将几乎不可察觉的统计信号嵌入到大型语言模型（LLMs）生成的文本中，也被称为水印，已被用作从其人类撰写对应物上可证检测LLM生成文本的原则性方法。 本文介绍了一个通用灵活的框架，用于推理水印的统计效率并设计强大的检测规则。受水印检测的假设检验公式启发，我们的框架首先选择文本的枢轴统计量和由LLM提供给验证器的秘密密钥，以实现控制误报率（将人类撰写的文本错误地检测为LLM生成的错误）。 接下来，该框架允许通过获取渐近错误负率（将LLM生成文本错误地检测为人类撰写的错误）的封闭形式表达式来评估水印检测规则的能力。

    arXiv:2404.01245v1 Announce Type: cross  Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of 
    
[^2]: 针对分布外预测的最优岭回归正则化

    Optimal Ridge Regularization for Out-of-Distribution Prediction

    [https://arxiv.org/abs/2404.01233](https://arxiv.org/abs/2404.01233)

    研究了针对分布外预测的最优岭回归正则化下的行为，并建立了确定最优正则化水平的一般条件，揭示了与分布内设置的鲜明差异。

    

    我们研究了针对分布外预测的最优岭回归正则化和最优岭风险的行为，其中测试分布与训练分布任意偏离。我们建立了确定在协变量和回归偏移下最优正则化水平符号的一般条件。这些条件捕捉了训练数据和测试数据之间协方差和信号结构之间的对齐，并揭示了与在分布内设置相比的鲜明差异。例如，在协变量偏移或回归偏移下，即使训练特征是各向同性的或设计是欠参数化的，负正则化水平也可能是最优的。此外，我们证明了在数据纵横比中，甚至在最优化负正则化水平时，最优调整的风险是单调的，即在分布外设置中也是如此。总的来说，我们的结果对训练数据没有做出任何建模假设。

    arXiv:2404.01233v1 Announce Type: cross  Abstract: We study the behavior of optimal ridge regularization and optimal ridge risk for out-of-distribution prediction, where the test distribution deviates arbitrarily from the train distribution. We establish general conditions that determine the sign of the optimal regularization level under covariate and regression shifts. These conditions capture the alignment between the covariance and signal structures in the train and test data and reveal stark differences compared to the in-distribution setting. For example, a negative regularization level can be optimal under covariate shift or regression shift, even when the training features are isotropic or the design is underparameterized. Furthermore, we prove that the optimally-tuned risk is monotonic in the data aspect ratio, even in the out-of-distribution setting and when optimizing over negative regularization levels. In general, our results do not make any modeling assumptions for the tra
    
[^3]: 在子群体转移下的新颖节点类别检测

    Novel Node Category Detection Under Subpopulation Shift

    [https://arxiv.org/abs/2404.01216](https://arxiv.org/abs/2404.01216)

    提出了一种新方法 RECO-SLIP，用于在属性图中检测属于新类别的节点，能够有效解决子群体转移下的节点检测问题，实验证明其性能优越。

    

    在现实世界的图数据中，分布转移可以通过各种方式表现，例如新类别的出现和现有类别相对比例的变化。在这种分布转移下，检测属于新类别的节点对于安全或洞察发现至关重要。我们引入了一种新方法，称为具有选择性链路预测的召回约束优化（RECO-SLIP），用于在子群体转移下检测属性图中属于新类别的节点。通过将召回约束学习框架与高效样本预测机制相结合，RECO-SLIP解决了抵抗子群体转移和有效利用图结构的双重挑战。我们在多个图数据集上进行了大量实证评估，结果表明RECO-SLIP相对于现有方法具有更优异的性能。

    arXiv:2404.01216v1 Announce Type: new  Abstract: In real-world graph data, distribution shifts can manifest in various ways, such as the emergence of new categories and changes in the relative proportions of existing categories. It is often important to detect nodes of novel categories under such distribution shifts for safety or insight discovery purposes. We introduce a new approach, Recall-Constrained Optimization with Selective Link Prediction (RECO-SLIP), to detect nodes belonging to novel categories in attributed graphs under subpopulation shifts. By integrating a recall-constrained learning framework with a sample-efficient link prediction mechanism, RECO-SLIP addresses the dual challenges of resilience against subpopulation shifts and the effective exploitation of graph structure. Our extensive empirical evaluation across multiple graph datasets demonstrates the superior performance of RECO-SLIP over existing methods.
    
[^4]: 大规模非凸随机约束分布鲁棒优化

    Large-Scale Non-convex Stochastic Constrained Distributionally Robust Optimization

    [https://arxiv.org/abs/2404.01200](https://arxiv.org/abs/2404.01200)

    本文开发了一种用于非凸约束分布鲁棒优化的随机算法，其计算复杂度与整体数据集大小无关，适用于大规模应用。

    

    分布鲁棒优化（DRO）是针对数据分布变化训练健壮模型的强大框架。本文关注具有鲁棒性水平明确特征的约束DRO。现有研究主要集中在具有凸损失函数的约束DRO上，并排除了具有非凸损失函数（如神经网络）的实践和具有挑战性的情况。本文为非凸约束DRO开发了一种随机算法及其性能分析。我们的随机算法在每次迭代的计算复杂度与整体数据集大小独立无关，因此适用于大规模应用。我们侧重于将Cressie-Read家族散度定义的不确定性集成中包含$\chi^2$-散度作为特例。我们证明了我们的算法在计算复杂度为$\mathcal O(\epsilon^{-3k_*-5})$的情况下找到了一个$\epsilon$-稳定点。

    arXiv:2404.01200v1 Announce Type: cross  Abstract: Distributionally robust optimization (DRO) is a powerful framework for training robust models against data distribution shifts. This paper focuses on constrained DRO, which has an explicit characterization of the robustness level. Existing studies on constrained DRO mostly focus on convex loss function, and exclude the practical and challenging case with non-convex loss function, e.g., neural network. This paper develops a stochastic algorithm and its performance analysis for non-convex constrained DRO. The computational complexity of our stochastic algorithm at each iteration is independent of the overall dataset size, and thus is suitable for large-scale applications. We focus on the general Cressie-Read family divergence defined uncertainty set which includes $\chi^2$-divergences as a special case. We prove that our algorithm finds an $\epsilon$-stationary point with a computational complexity of $\mathcal O(\epsilon^{-3k_*-5})$, wh
    
[^5]: 对改进的多臂老虎机问题的近乎最紧密的逼近保证

    Nearly-tight Approximation Guarantees for the Improving Multi-Armed Bandits Problem

    [https://arxiv.org/abs/2404.01198](https://arxiv.org/abs/2404.01198)

    对改进的多臂老虎机问题，我们给出了一个随机在线算法，可以在不了解最优臂最大奖励的情况下，以$O(\sqrt{k} \log k)$的逼近相对于最优。

    

    我们为改进的多臂老虎机问题提供了近乎最紧密的上界和下界。这个问题的一个实例有$k$个臂，每个臂的奖励函数都是一个凹函数，并且是一个与到目前为止拉动该臂的次数成增函数。我们证明了对于任何随机在线算法，都存在一个实例，使其相对于最优奖励必须至少承受一个$\Omega(\sqrt{k})$的近似因子。然后我们提供了一个随机在线算法，如果事先告知最优臂可实现的最大奖励，就可以保证一个$O(\sqrt{k})$的近似因子。我们还展示了如何在额外付出$O(\log k)$的近似因子的代价下，消除这个假设，实现相对于最优的总体$O(\sqrt{k} \log k)$的逼近。

    arXiv:2404.01198v1 Announce Type: new  Abstract: We give nearly-tight upper and lower bounds for the improving multi-armed bandits problem. An instance of this problem has $k$ arms, each of whose reward function is a concave and increasing function of the number of times that arm has been pulled so far. We show that for any randomized online algorithm, there exists an instance on which it must suffer at least an $\Omega(\sqrt{k})$ approximation factor relative to the optimal reward. We then provide a randomized online algorithm that guarantees an $O(\sqrt{k})$ approximation factor, if it is told the maximum reward achievable by the optimal arm in advance. We then show how to remove this assumption at the cost of an extra $O(\log k)$ approximation factor, achieving an overall $O(\sqrt{k} \log k)$ approximation relative to optimal.
    
[^6]: TransFusion：用于高维回归的抗协变量转移学习

    TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression

    [https://arxiv.org/abs/2404.01153](https://arxiv.org/abs/2404.01153)

    提出了一种新型融合正则化器的两步法方法，有效处理高维回归中的模型偏移和协变量转移，提高了目标任务的学习性能，具有稳健性并满足最小-最大最优条件。

    

    传统监督学习与转移学习的主要挑战在于分布偏移，体现为源模型和目标模型之间的偏移以及边际协变量分布之间的偏移。在这项工作中，我们在高维回归设置中处理存在协变量变化的模型变化。具体来说，我们提出了一个两步法方法，使用一种新颖的融合正则化器，有效利用来自源任务的样本来提高在具有有限样本的目标任务上的学习性能。提供了目标模型估计误差的非渐近界限，显示了所提方法对协变量转移的稳健性。我们进一步确定了估计器是最小-最大最优的条件。此外，我们将该方法扩展到分布式设置，允许进行预训练和微调策略，仅需一轮通信即可保留估计

    arXiv:2404.01153v1 Announce Type: cross  Abstract: The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused-regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the esti
    
[^7]: SoK: 高维数据中差分私有线性模型的综述

    SoK: A Review of Differentially Private Linear Models For High-Dimensional Data

    [https://arxiv.org/abs/2404.01141](https://arxiv.org/abs/2404.01141)

    本文对高维数据中差分私有线性模型的优化方法进行全面审查，发现鲁棒和优化的坐标算法效果最好，可为未来研究提供参考。

    

    线性模型在数据科学中随处可见，但在高维度中特别容易出现过拟合和数据记忆。为了保证训练数据的隐私性，可以使用差分隐私。许多论文提出了针对高维度差分私有线性模型的优化技术，但这些方法之间缺乏系统比较。我们通过对私有高维线性模型的优化方法进行全面审查来填补这一空白。对所有方法进行的实证测试表明，鲁棒和优化的坐标算法表现最佳，这可为未来研究提供参考。在线发布了所有方法的实现代码。

    arXiv:2404.01141v1 Announce Type: new  Abstract: Linear models are ubiquitous in data science, but are particularly prone to overfitting and data memorization in high dimensions. To guarantee the privacy of training data, differential privacy can be used. Many papers have proposed optimization techniques for high-dimensional differentially private linear models, but a systematic comparison between these methods does not exist. We close this gap by providing a comprehensive review of optimization methods for private high-dimensional linear models. Empirical tests on all methods demonstrate robust and coordinate-optimized algorithms perform best, which can inform future research. Code for implementing all methods is released online.
    
[^8]: 速率-失真-感知权衡：私有随机性的作用

    The Rate-Distortion-Perception Trade-off: The Role of Private Randomness

    [https://arxiv.org/abs/2404.01111](https://arxiv.org/abs/2404.01111)

    私有随机性在图像压缩中的作用在两种逼真度约束条件下得到阐明，以实现感知质量和失真之间的权衡。

    

    在图像压缩中，随着生成建模的最新进展，揭示了速率和感知质量（逼真度）之间存在一种权衡，其中逼真度通过输出分布与源分布的接近程度来衡量。已经表明，在许多情况下，随机编码可以更好。特别是，共同随机性的作用已被广泛研究。我们阐明了在两种逼真度约束条件下私有随机性在记忆源$X^n=(X_1,...,X_n)$压缩中的作用。接近完美逼真度约束要求输出符号$(Y_1,...,Y_n)$的联合分布与源分布在总变差距离（TVD）上任意接近。每个符号的近乎完美逼真度约束要求输出符号$Y_t$的分布与源分布之间的TVD在任意小，从而实现了一种感知质量和失真之间的权衡。

    arXiv:2404.01111v1 Announce Type: cross  Abstract: In image compression, with recent advances in generative modeling, the existence of a trade-off between the rate and the perceptual quality (realism) has been brought to light, where the realism is measured by the closeness of the output distribution to the source. It has been shown that randomized codes can be strictly better under a number of formulations. In particular, the role of common randomness has been well studied. We elucidate the role of private randomness in the compression of a memoryless source $X^n=(X_1,...,X_n)$ under two kinds of realism constraints. The near-perfect realism constraint requires the joint distribution of output symbols $(Y_1,...,Y_n)$ to be arbitrarily close the distribution of the source in total variation distance (TVD). The per-symbol near-perfect realism constraint requires that the TVD between the distribution of output symbol $Y_t$ and the source distribution be arbitrarily small, uniformly in th
    
[^9]: 有限样本频域识别

    Finite Sample Frequency Domain Identification

    [https://arxiv.org/abs/2404.01100](https://arxiv.org/abs/2404.01100)

    本研究提出了一种在有限样本情况下进行非参数频域系统识别的方法，通过Empirical Transfer Function Estimate（ETFE）在特定频率处准确估计频率响应，并证明在次高斯彩色噪声和稳定性假设下，ETFE估计值准确可靠。

    

    我们从有限样本的角度研究了非参数频域系统识别。我们假设在开环情况下，激励输入是周期性的，并考虑经验传递函数估计（ETFE），其中目标是在给定输入-输出样本的情况下在某些所需（均匀间隔的）频率处估计频率响应。我们表明在次高斯彩色噪声（在时域）和稳定性假设下，ETFE估计值集中在真实值周围。误差率为$\mathcal{O}((d_{\mathrm{u}}+\sqrt{d_{\mathrm{u}}d_{\mathrm{y}}})\sqrt{M/N_{\mathrm{tot}}})$，其中$N_{\mathrm{tot}}$是样本的总数，$M$是所需频率的数量，$d_{\mathrm{u}},\,d_{\mathrm{y}}$分别为输入和输出信号的维数。这个速率对于一般的非理性传递函数仍然有效，并且不需要有限阶的状态空间。

    arXiv:2404.01100v1 Announce Type: cross  Abstract: We study non-parametric frequency-domain system identification from a finite-sample perspective. We assume an open loop scenario where the excitation input is periodic and consider the Empirical Transfer Function Estimate (ETFE), where the goal is to estimate the frequency response at certain desired (evenly-spaced) frequencies, given input-output samples. We show that under sub-Gaussian colored noise (in time-domain) and stability assumptions, the ETFE estimates are concentrated around the true values. The error rate is of the order of $\mathcal{O}((d_{\mathrm{u}}+\sqrt{d_{\mathrm{u}}d_{\mathrm{y}}})\sqrt{M/N_{\mathrm{tot}}})$, where $N_{\mathrm{tot}}$ is the total number of samples, $M$ is the number of desired frequencies, and $d_{\mathrm{u}},\,d_{\mathrm{y}}$ are the dimensions of the input and output signals respectively. This rate remains valid for general irrational transfer functions and does not require a finite order state-sp
    
[^10]: 通过二次形式的正态性进行随机最小二乘和PCA的推论

    Inference in Randomized Least Squares and PCA via Normality of Quadratic Forms

    [https://arxiv.org/abs/2404.00912](https://arxiv.org/abs/2404.00912)

    本文提出了一种通过随机草图或投影来进行统计推断的统一方法，适用于最小二乘和PCA问题，针对广泛范围的草图分布提出了统计推断方法，展示了某些二次形式的渐近正态性。

    

    随机算法可以用来加速大型数据集的分析。本文中，我们针对多元统计分析中两个最基本的问题：最小二乘和主成分分析(PCA)，开发了一种统计推断的统一方法，通过随机草图或投影来进行。该方法适用于固定数据集 -- 即数据条件性 -- 唯一的随机性源于随机算法。我们提出了一种针对广泛范围的草图分布的统计推断方法，例如子采样随机哈达玛变换(SRHT)，稀疏符号嵌入(SSE)和CountSketch，具有独立同分布的条目的草图矩阵以及均匀子采样。据我们所知，目前尚无可比较的方法适用于PCA中的SSE和SRHT。我们的新颖理论方法基于展示某些二次形式的渐近正态性。作为更广泛兴趣的贡献，我们展示了关于二次形式的中心极限定理。

    arXiv:2404.00912v1 Announce Type: cross  Abstract: Randomized algorithms can be used to speed up the analysis of large datasets. In this paper, we develop a unified methodology for statistical inference via randomized sketching or projections in two of the most fundamental problems in multivariate statistical analysis: least squares and PCA. The methodology applies to fixed datasets -- i.e., is data-conditional -- and the only randomness is due to the randomized algorithm. We propose statistical inference methods for a broad range of sketching distributions, such as the subsampled randomized Hadamard transform (SRHT), Sparse Sign Embeddings (SSE) and CountSketch, sketching matrices with i.i.d. entries, and uniform subsampling. To our knowledge, no comparable methods are available for SSE and for SRHT in PCA. Our novel theoretical approach rests on showing the asymptotic normality of certain quadratic forms. As a contribution of broader interest, we show central limit theorems for quadr
    
[^11]: 学习网络增长机制

    Learning the mechanisms of network growth

    [https://arxiv.org/abs/2404.00793](https://arxiv.org/abs/2404.00793)

    我们提出了一种新的模型选择方法，通过在大量合成网络数据上训练分类器，设计出易于计算、解析可处理且具有解释性的动态特征类型，实现了几乎完美的网络分类，超过了目前技术水平。

    

    我们提出了一种面向动态真实网络的新模型选择方法。我们的方法涉及在大量合成网络数据上训练分类器。数据是通过模拟动态网络的九种最先进的随机图模型生成的，选定参数范围以确保网络规模随时间呈指数增长。我们设计了一种概念上新颖的动态特征类型，它计算在特定时间间隔内一组顶点收到的新链接数。所提出的特征易于计算，解析上可处理，并具有解释性。我们的方法实现了对合成网络的几乎完美分类，超过当前技术水平。将我们的分类方法应用于真实世界的引文网络，对文献中声称的具有优先附着、适应性和老化的模型最好地适应真实世界的引文网络的说法具有可靠性，尽管有时，预测可能。

    arXiv:2404.00793v1 Announce Type: cross  Abstract: We propose a novel model-selection method for dynamic real-life networks. Our approach involves training a classifier on a large body of synthetic network data. The data is generated by simulating nine state-of-the-art random graph models for dynamic networks, with parameter range chosen to ensure exponential growth of the network size in time. We design a conceptually novel type of dynamic features that count new links received by a group of vertices in a particular time interval. The proposed features are easy to compute, analytically tractable, and interpretable. Our approach achieves a near-perfect classification of synthetic networks, exceeding the state-of-the-art by a large margin. Applying our classification method to real-world citation networks gives credibility to the claims in the literature that models with preferential attachment, fitness and aging fit real-world citation networks best, although sometimes, the predicted m
    
[^12]: PyTorch Frame: 一个用于多模态表格学习的模块化框架

    PyTorch Frame: A Modular Framework for Multi-Modal Tabular Learning

    [https://arxiv.org/abs/2404.00776](https://arxiv.org/abs/2404.00776)

    PyTorch Frame是一个用于处理多模态表格数据的PyTorch框架，通过提供数据结构、模型抽象和外部基础模型整合等功能，实现了模块化的表格模型实现，并成功将这些模型应用于复杂的数据集。

    

    我们提出了PyTorch Frame，这是一个基于PyTorch的框架，用于处理多模态表格数据的深度学习。PyTorch Frame通过提供基于PyTorch的数据结构来处理复杂的表格数据，引入模型抽象以实现表格模型的模块化实现，并允许整合外部基础模型来处理复杂列（例如，用于文本列的LLMs）。我们通过以模块化方式实现多样的表格模型，成功将这些模型应用于复杂的多模态表格数据，并将我们的框架与PyTorch Geometric集成，PyTorch Geometric是一个用于图神经网络（GNNs）的PyTorch库，以实现对关系数据库的端到端学习。

    arXiv:2404.00776v1 Announce Type: new  Abstract: We present PyTorch Frame, a PyTorch-based framework for deep learning over multi-modal tabular data. PyTorch Frame makes tabular deep learning easy by providing a PyTorch-based data structure to handle complex tabular data, introducing a model abstraction to enable modular implementation of tabular models, and allowing external foundation models to be incorporated to handle complex columns (e.g., LLMs for text columns). We demonstrate the usefulness of PyTorch Frame by implementing diverse tabular models in a modular way, successfully applying these models to complex multi-modal tabular data, and integrating our framework with PyTorch Geometric, a PyTorch library for Graph Neural Networks (GNNs), to perform end-to-end learning over relational databases.
    
[^13]: 通过信念传播在树上实现对抗性稳健推断

    Adversarially-Robust Inference on Trees via Belief Propagation

    [https://arxiv.org/abs/2404.00768](https://arxiv.org/abs/2404.00768)

    确认了一个民间信念，即恶意对手可以破坏特定叶子节点使得推断变得不可能，但是可以实现对根节点的准确后验推断

    

    我们引入并研究了在树形图模型上进行后验推断的问题，存在一个恶意对手可以破坏一些观察节点。在广泛研究的树模型中，当自然信噪比超过1时，根据叶子节点的后验分布与Ber(1/2)有显著差异，并且携带与根符号有关的重要信息。我们确认了一个民间信念，即一个可以破坏自己选择的逆多项式分数叶子节点的恶意对手会让这种推断变得不可能。我们的主要结果是准确地根据叶子节点对根节点进行后验推断。

    arXiv:2404.00768v1 Announce Type: cross  Abstract: We introduce and study the problem of posterior inference on tree-structured graphical models in the presence of a malicious adversary who can corrupt some observed nodes. In the well-studied broadcasting on trees model, corresponding to the ferromagnetic Ising model on a $d$-regular tree with zero external field, when a natural signal-to-noise ratio exceeds one (the celebrated Kesten-Stigum threshold), the posterior distribution of the root given the leaves is bounded away from $\mathrm{Ber}(1/2)$, and carries nontrivial information about the sign of the root. This posterior distribution can be computed exactly via dynamic programming, also known as belief propagation.   We first confirm a folklore belief that a malicious adversary who can corrupt an inverse-polynomial fraction of the leaves of their choosing makes this inference impossible. Our main result is that accurate posterior inference about the root vertex given the leaves is
    
[^14]: C-XGBoost：一种用于因果效应估计的树提升模型

    C-XGBoost: A tree boosting model for causal effect estimation

    [https://arxiv.org/abs/2404.00751](https://arxiv.org/abs/2404.00751)

    该论文提出了一种名为C-XGBoost的树提升模型，可用于预测潜在结果，结合了基于树的模型和基于神经网络的因果推断模型的优势，同时继承了XGBoost模型的高效处理缺失值特征的优势。

    

    因果效应估计旨在估计处理对结果的平均处理效应以及条件平均处理效应，这些知识在许多安全关键领域中至关重要，通常需要从观测数据中提取。在这项工作中，我们提出了一种新的因果推断模型，名为C-XGBoost，用于预测潜在结果。我们的方法动机在于利用基于树的模型处理表格数据的优越性，以及基于神经网络的因果推断模型学习有用于估计处理和非处理案例的结果的表示的显著特性。所提出的模型还继承了XGBoost模型的显著优势，如高效处理具有缺失值特征的特性，需要最少的预处理工作，同时具备正则化技术。

    arXiv:2404.00751v1 Announce Type: cross  Abstract: Causal effect estimation aims at estimating the Average Treatment Effect as well as the Conditional Average Treatment Effect of a treatment to an outcome from the available data. This knowledge is important in many safety-critical domains, where it often needs to be extracted from observational data. In this work, we propose a new causal inference model, named C-XGBoost, for the prediction of potential outcomes. The motivation of our approach is to exploit the superiority of tree-based models for handling tabular data together with the notable property of causal inference neural network-based models to learn representations that are useful for estimating the outcome for both the treatment and non-treatment cases. The proposed model also inherits the considerable advantages of XGBoost model such as efficiently handling features with missing values requiring minimum preprocessing effort, as well as it is equipped with regularization tech
    
[^15]: 因果中介分析的两阶段干扰函数估计

    Two-Stage Nuisance Function Estimation for Causal Mediation Analysis

    [https://arxiv.org/abs/2404.00735](https://arxiv.org/abs/2404.00735)

    通过两阶段估计策略，该研究提出了一种针对因果中介分析中干扰函数的方法，旨在根据其在偏差结构中的作用来估计干扰函数。

    

    在使用基于影响函数的中介功能估计器估计直接和间接因果效应时，了解应该关注治疗、中介和结果的哪些方面是至关重要的。具体而言，将它们视为干扰函数，并试图尽可能准确地拟合这些干扰函数并不一定是最好的方法。在这项工作中，我们提出了一种针对干扰函数的两阶段估计策略，该策略根据干扰函数在影响函数的中介功能估计器的偏差结构中发挥的作用来估计干扰函数。我们对所提出方法进行了稳健性分析，以及参数估计器的一致性和渐近正态性的充分条件。

    arXiv:2404.00735v1 Announce Type: cross  Abstract: When estimating the direct and indirect causal effects using the influence function-based estimator of the mediation functional, it is crucial to understand what aspects of the treatment, the mediator, and the outcome mean mechanisms should be focused on. Specifically, considering them as nuisance functions and attempting to fit these nuisance functions as accurate as possible is not necessarily the best approach to take. In this work, we propose a two-stage estimation strategy for the nuisance functions that estimates the nuisance functions based on the role they play in the structure of the bias of the influence function-based estimator of the mediation functional. We provide robustness analysis of the proposed method, as well as sufficient conditions for consistency and asymptotic normality of the estimator of the parameter of interest.
    
[^16]: 共享仿射子空间中的臂上元学习

    Meta Learning in Bandits within Shared Affine Subspaces

    [https://arxiv.org/abs/2404.00688](https://arxiv.org/abs/2404.00688)

    通过利用低维仿射子空间集中性，我们提出两种策略解决了在多个环境随机臂上任务中减少预期遗憾的问题。

    

    我们研究了通过利用多个环境随机臂上任务在低维仿射子空间周围的集中性，通过在线主成分分析来减少在遇到的臂上任务中的预期遗憾的问题。我们提出并理论分析了两种解决该问题的策略：一种基于面对不确定性时的乐观原则，另一种通过汤普森取样。我们的框架是通用的，并包括先前提出的方法作为特例。此外，实证结果表明我们的方法显著减少了几个臂上任务的遗憾。

    arXiv:2404.00688v1 Announce Type: new  Abstract: We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low-dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the encountered bandits. We propose and theoretically analyze two strategies that solve the problem: One based on the principle of optimism in the face of uncertainty and the other via Thompson sampling. Our framework is generic and includes previously proposed approaches as special cases. Besides, the empirical results show that our methods significantly reduce the regret on several bandit tasks.
    
[^17]: 连续正规化流在学习概率分布中的收敛性

    Convergence of Continuous Normalizing Flows for Learning Probability Distributions

    [https://arxiv.org/abs/2404.00551](https://arxiv.org/abs/2404.00551)

    本文研究了具有线性插值的CNFs在从有限随机样本中学习概率分布时的理论性质，建立了非渐近误差界，并提供了收敛分析框架。

    

    连续正规化流（CNFs）是一种基于常微分方程的学习概率分布的生成方法。这种方法在各种应用中表现出显著的经验成功，包括大规模图像合成、蛋白质结构预测和分子生成。本文研究了具有线性插值的CNFs在从有限随机样本中学习概率分布时的理论性质，使用了流匹配目标函数。我们建立了基于CNFs的分布估计器的非渐近误差界，以Wasserstein-2距离表示。我们分析的关键假设是目标分布满足以下三个条件之一：要么具有有界支持，要么是强对数凹的，要么是有限或无限混合的高斯分布。我们提出了一个包含了误差收敛分析框架

    arXiv:2404.00551v1 Announce Type: cross  Abstract: Continuous normalizing flows (CNFs) are a generative method for learning probability distributions, which is based on ordinary differential equations. This method has shown remarkable empirical success across various applications, including large-scale image synthesis, protein structure prediction, and molecule generation. In this work, we study the theoretical properties of CNFs with linear interpolation in learning probability distributions from a finite random sample, using a flow matching objective function. We establish non-asymptotic error bounds for the distribution estimator based on CNFs, in terms of the Wasserstein-2 distance. The key assumption in our analysis is that the target distribution satisfies one of the following three conditions: it either has a bounded support, is strongly log-concave, or is a finite or infinite mixture of Gaussian distributions. We present a convergence analysis framework that encompasses the err
    
[^18]: 最小范数插值在协变量转移下的应用

    Minimum-Norm Interpolation Under Covariate Shift

    [https://arxiv.org/abs/2404.00522](https://arxiv.org/abs/2404.00522)

    本研究首次证明了在转移学习设置下，良性过拟合线性插值器的非渐近超额风险界，并提出了一种新的分类方法。

    

    转移学习是现实世界机器学习部署的关键组成部分，并在过参数化神经网络的实验研究中得到广泛研究。然而，即使在线性回归的最简单设置中，在对转移学习的理论理解仍存在显著差距。在高维线性回归的分布研究中，已经发现了一种被称为“良性过拟合”现象的现象，即线性插值器会对噪声训练标签过拟合，但仍然能很好地泛化。这种行为发生在源协方差矩阵和输入数据维度上的特定条件下。因此，自然而然地想知道这样的高维线性模型在转移学习下如何行为。我们证明了在转移学习设置中良性过拟合线性插值器的第一个非渐近超额风险界。通过我们的分析，我们提出了一个对转移学习中的\textit {b进行分类}}的方法

    arXiv:2404.00522v1 Announce Type: new  Abstract: Transfer learning is a critical part of real-world machine learning deployments and has been extensively studied in experimental works with overparameterized neural networks. However, even in the simplest setting of linear regression a notable gap still exists in the theoretical understanding of transfer learning. In-distribution research on high-dimensional linear regression has led to the identification of a phenomenon known as \textit{benign overfitting}, in which linear interpolators overfit to noisy training labels and yet still generalize well. This behavior occurs under specific conditions on the source covariance matrix and input data dimension. Therefore, it is natural to wonder how such high-dimensional linear models behave under transfer learning. We prove the first non-asymptotic excess risk bounds for benignly-overfit linear interpolators in the transfer learning setting. From our analysis, we propose a taxonomy of \textit{b
    
[^19]: 具有重建损失的迁移学习

    Transfer Learning with Reconstruction Loss

    [https://arxiv.org/abs/2404.00505](https://arxiv.org/abs/2404.00505)

    本文通过引入额外的重建阶段和重建损失，提出了一种具有共享模型参数和特征表示的模型训练方法，建立了共同信息的概念，用于解决相关任务。

    

    在大多数利用神经网络进行数学优化的应用中，通常为每个特定优化目标训练一个专用模型。然而，在许多场景中，同一组问题输入上经常需要优化几个不同但相关的目标或任务。与为每个问题单独训练不同的神经网络相比，更有效的方法是利用这些目标之间的相关性，使用共享模型参数和特征表示训练多个神经网络模型。为实现这一目标，本文首先建立了共同信息的概念：解决相关任务所需的共享知识，然后提出了一种新颖的模型训练方法，通过在模型中添加一个额外的重建阶段以及相关的新重建损失。该损失用于从选择的隐藏状态开始重新构建共同信息。

    arXiv:2404.00505v1 Announce Type: cross  Abstract: In most applications of utilizing neural networks for mathematical optimization, a dedicated model is trained for each specific optimization objective. However, in many scenarios, several distinct yet correlated objectives or tasks often need to be optimized on the same set of problem inputs. Instead of independently training a different neural network for each problem separately, it would be more efficient to exploit the correlations between these objectives and to train multiple neural network models with shared model parameters and feature representations. To achieve this, this paper first establishes the concept of common information: the shared knowledge required for solving the correlated tasks, then proposes a novel approach for model training by adding into the model an additional reconstruction stage associated with a new reconstruction loss. This loss is for reconstructing the common information starting from a selected hidde
    
[^20]: 卷积贝叶斯滤波

    Convolutional Bayesian Filtering

    [https://arxiv.org/abs/2404.00481](https://arxiv.org/abs/2404.00481)

    引入不等条件的额外事件，将条件概率转化为特殊积分形式，推广为卷积形式的新滤波框架，称为卷积贝叶斯滤波。

    

    贝叶斯滤波是动态系统状态估计的主要框架。标准版本利用全概率规则和贝叶斯定理交替使用，而定义和计算条件概率的方式对状态分布推断至关重要。以前，条件概率被假定为精确已知，代表一个事件发生概率给定第二个事件的度量。本文发现通过添加一个规定不等条件的额外事件，可以将条件概率转化为类似于卷积的特殊积分形式。基于这一转化，我们展示了过渡概率和输出概率均可以推广为卷积形式，从而得到一个更一般的滤波框架，我们称之为卷积贝叶斯滤波。

    arXiv:2404.00481v1 Announce Type: cross  Abstract: Bayesian filtering serves as the mainstream framework of state estimation in dynamic systems. Its standard version utilizes total probability rule and Bayes' law alternatively, where how to define and compute conditional probability is critical to state distribution inference. Previously, the conditional probability is assumed to be exactly known, which represents a measure of the occurrence probability of one event, given the second event. In this paper, we find that by adding an additional event that stipulates an inequality condition, we can transform the conditional probability into a special integration that is analogous to convolution. Based on this transformation, we show that both transition probability and output probability can be generalized to convolutional forms, resulting in a more general filtering framework that we call convolutional Bayesian filtering. This new framework encompasses standard Bayesian filtering as a spe
    
[^21]: 语言模型的语言校准

    Linguistic Calibration of Language Models

    [https://arxiv.org/abs/2404.00474](https://arxiv.org/abs/2404.00474)

    该论文提出了一种通过语言模型的文本生成来实现语言校准，可以使用户做出校准概率预测的方法。

    

    语言模型可能会在自信幻觉时导致用户做出次优化的下游决策。通过语言模型口头传达其主张正确概率可以缓解这个问题，但现有模型无法生成具有校准置信度声明的文本。我们通过决策角度，为长篇生成形式的语言校准形式化定义：如果语言模型的生成使其用户能够做出校准概率预测，则该模型是语言上校准的。这个定义使得一个训练框架成为可能，其中一个监督微调步骤引导一个语言模型发出带有置信度声明的长篇生成，诸如“我估计有30%的机会…”或“我确信…”，然后是一个强化学习步骤，奖励使用户能够对相关问题提供校准答案的生成。我们对Llama 2 7B 进行语言校准，并发现在自动化和人类测试中...

    arXiv:2404.00474v1 Announce Type: cross  Abstract: Language models (LMs) may lead their users to make suboptimal downstream decisions when they confidently hallucinate. This issue can be mitigated by having the LM verbally convey the probability that its claims are correct, but existing models cannot produce text with calibrated confidence statements. Through the lens of decision-making, we formalize linguistic calibration for long-form generations: an LM is linguistically calibrated if its generations enable its users to make calibrated probabilistic predictions. This definition enables a training framework where a supervised finetuning step bootstraps an LM to emit long-form generations with confidence statements such as "I estimate a 30% chance of..." or "I am certain that...", followed by a reinforcement learning step which rewards generations that enable a user to provide calibrated answers to related questions. We linguistically calibrate Llama 2 7B and find in automated and huma
    
[^22]: 使用分布式狮子进行高效通信的分布式训练

    Communication Efficient Distributed Training with Distributed Lion

    [https://arxiv.org/abs/2404.00438](https://arxiv.org/abs/2404.00438)

    分布式狮子是对 Lion 进行了创新性改进，利用符号操作符降低了通信成本，在分布式训练中取得了与标准 Lion 或 AdamW 优化器相当的性能，并显著减少了通信带宽。

    

    Lion优化器在训练大型AI模型方面与AdamW有一定竞争力，具有在内存、计算和样本效率上的优势。本文介绍了分布式狮子，这是狮子在分布式训练环境中的创新性改进。利用狮子中的符号操作符，我们的分布式狮子只需要在工作节点和中心服务器之间传递二进制或低精度向量，显著降低了通信成本。我们的理论分析证实了分布式狮子的收敛性质。实证结果表明，它在多种任务、工作者数量和批量大小上表现稳健，在视觉和语言问题上表现出色。值得注意的是，分布式狮子在聚合梯度上达到了与标准狮子或AdamW优化器相当的性能，但通信带宽显著减少。这个特性对于训练大型模型尤为有利。

    arXiv:2404.00438v1 Announce Type: cross  Abstract: The Lion optimizer has been a promising competitor with the AdamW for training large AI models, with advantages on memory, computation, and sample efficiency. In this paper, we introduce Distributed Lion, an innovative adaptation of Lion for distributed training environments. Leveraging the sign operator in Lion, our Distributed Lion only requires communicating binary or lower-precision vectors between workers to the center server, significantly reducing the communication cost. Our theoretical analysis confirms Distributed Lion's convergence properties. Empirical results demonstrate its robustness across a range of tasks, worker counts, and batch sizes, on both vision and language problems. Notably, Distributed Lion attains comparable performance to standard Lion or AdamW optimizers applied on aggregated gradients, but with significantly reduced communication bandwidth. This feature is particularly advantageous for training large model
    
[^23]: 利用观测数据进行强健学习以获得最佳动态治疗方案

    Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data

    [https://arxiv.org/abs/2404.00221](https://arxiv.org/abs/2404.00221)

    学习利用观测数据提出了一种逐步双重强健方法，通过向后归纳解决了最佳动态治疗方案的问题

    

    许多公共政策和医疗干预涉及其治疗分配中的动态性，治疗通常依据先前治疗的历史和相关特征对每个阶段的效果具有异质性。本文研究了统计学习最佳动态治疗方案(DTR)，根据个体的历史指导每个阶段的最佳治疗分配。我们提出了一种基于观测数据的逐步双重强健方法，在顺序可忽略性假设下学习最佳DTR。该方法通过向后归纳解决了顺序治疗分配问题，在每一步中，我们结合倾向评分和行动值函数(Q函数)的估计量，构建了政策价值的增强反向概率加权估计量。

    arXiv:2404.00221v1 Announce Type: cross  Abstract: Many public policies and medical interventions involve dynamics in their treatment assignments, where treatments are sequentially assigned to the same individuals across multiple stages, and the effect of treatment at each stage is usually heterogeneous with respect to the history of prior treatments and associated characteristics. We study statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's history. We propose a step-wise doubly-robust approach to learn the optimal DTR using observational data under the assumption of sequential ignorability. The approach solves the sequential treatment assignment problem through backward induction, where, at each step, we combine estimators of propensity scores and action-value functions (Q-functions) to construct augmented inverse probability weighting estimators of values of policies 
    
[^24]: 可部分观测序贯自相关数据的变点检测：上置信区间方法

    Partially-Observable Sequential Change-Point Detection for Autocorrelated Data via Upper Confidence Region

    [https://arxiv.org/abs/2404.00220](https://arxiv.org/abs/2404.00220)

    提出了一种适用于可部分观测多传感器序贯变点检测的自适应上置信区间状态空间模型（AUCRSS），通过自适应采样策略实现高效的变点检测和定位。

    

    arXiv:2404.00220v1 公告类型: 交叉摘要: 多变量自相关数据的序贯变点检测是实践中一个非常常见的问题。然而，当感知资源有限时，每次感知时间点只能观测多变量系统的一个子集。这就提出了可部分观测多传感器序贯变点检测的问题。为此，我们提出了一种称为自适应上置信区间状态空间模型(AUCRSS)的检测方案。它通过状态空间模型(SSM)对多变量时间序列进行建模，并利用自适应采样策略进行高效的变点检测和定位。对在线推断SSM的部分可观测卡尔曼滤波算法进行开发，并相应地，基于广义似然比检验的变点检测方案被开发。分析了其检测能力与自适应采样策略的关系。同时，通过将检测能力视为一种再

    arXiv:2404.00220v1 Announce Type: cross  Abstract: Sequential change point detection for multivariate autocorrelated data is a very common problem in practice. However, when the sensing resources are limited, only a subset of variables from the multivariate system can be observed at each sensing time point. This raises the problem of partially observable multi-sensor sequential change point detection. For it, we propose a detection scheme called adaptive upper confidence region with state space model (AUCRSS). It models multivariate time series via a state space model (SSM), and uses an adaptive sampling policy for efficient change point detection and localization. A partially-observable Kalman filter algorithm is developed for online inference of SSM, and accordingly, a change point detection scheme based on a generalized likelihood ratio test is developed. How its detection power relates to the adaptive sampling strategy is analyzed. Meanwhile, by treating the detection power as a re
    
[^25]: 功能边缘网络建模

    Functional-Edged Network Modeling

    [https://arxiv.org/abs/2404.00218](https://arxiv.org/abs/2404.00218)

    本研究提出了一种功能边缘网络模型，通过将边视为功能数据，并引入额外维度来表示函数，使用Tucker功能分解处理功能邻接张量，进行模型推断以解决不规则观测问题，并通过正则化使基础矩阵对称化，最终展示了模型的理想属性。

    

    与现有作品形成对比，现有作品都将节点视为函数，并使用边来表示不同函数之间的关系。我们的目标是网络建模，其中边是功能数据，并将邻接矩阵转换为功能邻接张量，引入一个额外的维度专门用于函数表示。我们使用Tucker功能分解来处理功能邻接张量，为进一步考虑节点之间的社区，对基础矩阵进行正则化使其对称化。此外，为了处理功能边的不规则观测，我们进行模型推断以解决张量完成问题，通过Riemann共轭梯度下降方法进行优化。除此之外，我们还推导出几个定理来展示功能边缘网络模型的理想属性。最后，我们使用模拟数据和真实地铁系统数据评估了我们提出的模型的有效性。

    arXiv:2404.00218v1 Announce Type: cross  Abstract: Contrasts with existing works which all consider nodes as functions and use edges to represent the relationships between different functions. We target at network modeling whose edges are functional data and transform the adjacency matrix into a functional adjacency tensor, introducing an additional dimension dedicated to function representation. Tucker functional decomposition is used for the functional adjacency tensor, and to further consider the community between nodes, we regularize the basis matrices to be symmetrical. Furthermore, to deal with irregular observations of the functional edges, we conduct model inference to solve a tensor completion problem. It is optimized by a Riemann conjugate gradient descent method. Besides these, we also derive several theorems to show the desirable properties of the functional edged network model. Finally, we evaluate the efficacy of our proposed model using simulation data and real metro sys
    
[^26]: 在正-无监督学习中验证完全随机选择假设

    Verifying the Selected Completely at Random Assumption in Positive-Unlabeled Learning

    [https://arxiv.org/abs/2404.00145](https://arxiv.org/abs/2404.00145)

    在正-无监督学习中，研究了验证完全随机选择假设（SCAR）和更为现实的随机选择假设（SAR）对算法复杂性和速度的影响。

    

    正-无监督学习的目标是在包含正例和未标记实例的训练数据基础上训练二元分类器，其中未标记观测可以属于正类或负类。建模正-无监督数据需要关于标签机制的一些假设，描述哪些正例被分配标签。早期研究中考虑的最简单假设是SCAR（完全随机选择假设），其概率分数函数定义为给正例分配标签的概率是常数。另一方面，一个更为现实的假设是SAR（随机选择），它表明概率函数仅依赖于观察到的特征向量。基于SCAR的算法比基于SAR的算法简单得多，并且在计算上更快，后者通常需要挑战性的估计。

    arXiv:2404.00145v1 Announce Type: cross  Abstract: The goal of positive-unlabeled (PU) learning is to train a binary classifier on the basis of training data containing positive and unlabeled instances, where unlabeled observations can belong either to the positive class or to the negative class. Modeling PU data requires certain assumptions on the labeling mechanism that describes which positive observations are assigned a label. The simplest assumption, considered in early works, is SCAR (Selected Completely at Random Assumption), according to which the propensity score function, defined as the probability of assigning a label to a positive observation, is constant. On the other hand, a much more realistic assumption is SAR (Selected at Random), which states that the propensity function solely depends on the observed feature vector. SCAR-based algorithms are much simpler and computationally much faster compared to SAR-based algorithms, which usually require challenging estimation of 
    
[^27]: 在强健马尔可夫决策过程中高效而尖锐的离线策略评估

    Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes

    [https://arxiv.org/abs/2404.00099](https://arxiv.org/abs/2404.00099)

    在对抗性环境中，本论文提出了一种可修改转移核密度的扰动模型，拓展了传统的边缘敏感性模型，对无限时间RL中策略价值进行了尖锐边界的刻画和估计。

    

    我们研究了在马尔可夫决策过程（MDP）中给定来自原始MDP的转移观察时，在最佳和最坏情况下评估策略，无论是在相同策略还是不同策略下。当存在历史和未来环境之间可能发生转变的可能性时，比如由于未测量的混杂、分布转移或对抗性环境。我们提出了一个扰动模型，可以将转移核密度修改至给定乘法因子或其倒数，这将经典的边际敏感性模型（MSM）扩展到无限时间 RL。我们描述了在这个模型下的策略价值的尖锐边界，即在给定来自原始MDP的转移观测时可能的最严格边界，我们研究了从这些转移观察中估计这些边界。我们开发了一个估计器，具有几个吸引人的特性。

    arXiv:2404.00099v1 Announce Type: new  Abstract: We study evaluating a policy under best- and worst-case perturbations to a Markov decision process (MDP), given transition observations from the original MDP, whether under the same or different policy. This is an important problem when there is the possibility of a shift between historical and future environments, due to e.g. unmeasured confounding, distributional shift, or an adversarial environment. We propose a perturbation model that can modify transition kernel densities up to a given multiplicative factor or its reciprocal, which extends the classic marginal sensitivity model (MSM) for single time step decision making to infinite-horizon RL. We characterize the sharp bounds on policy value under this model, that is, the tightest possible bounds given by the transition observations from the original MDP, and we study the estimation of these bounds from such transition observations. We develop an estimator with several appealing gua
    
[^28]: 贝叶斯非参数方法：深度学习的替代选择

    Bayesian Nonparametrics: An Alternative to Deep Learning

    [https://arxiv.org/abs/2404.00085](https://arxiv.org/abs/2404.00085)

    贝叶斯非参数模型为统计模型选择提供了灵活而强大的框架，揭示了贝叶斯非参数方法的多才多艺和高效性，为在各个学科领域中应对复杂挑战提供了创新解决方案。

    

    贝叶斯非参数模型为统计模型选择提供了灵活而强大的框架，能够使模型复杂度适应各种数据集的复杂性。本调查旨在深入探讨贝叶斯非参数方法的重要性，特别是在解决统计学、计算机科学和电气工程等各个领域的复杂挑战方面。通过阐明这些非参数模型的基本特性和理论基础，本调查旨在提供对贝叶斯非参数方法及其在解决复杂问题方面的相关性的全面理解，特别是在多目标跟踪领域。通过这种探索，我们揭示了贝叶斯非参数方法的多才多艺和高效性，为在各个学科领域中应对复杂挑战提供了创新解决方案。

    arXiv:2404.00085v1 Announce Type: new  Abstract: Bayesian nonparametric models offer a flexible and powerful framework for statistical model selection, enabling the adaptation of model complexity to the intricacies of diverse datasets. This survey intends to delve into the significance of Bayesian nonparametrics, particularly in addressing complex challenges across various domains such as statistics, computer science, and electrical engineering. By elucidating the basic properties and theoretical foundations of these nonparametric models, this survey aims to provide a comprehensive understanding of Bayesian nonparametrics and their relevance in addressing complex problems, particularly in the domain of multi-object tracking. Through this exploration, we uncover the versatility and efficacy of Bayesian nonparametric methodologies, paving the way for innovative solutions to intricate challenges across diverse disciplines.
    
[^29]: 具有约束的随机优化：非渐近实例相关分析

    Stochastic Optimization with Constraints: A Non-asymptotic Instance-Dependent Analysis

    [https://arxiv.org/abs/2404.00042](https://arxiv.org/abs/2404.00042)

    该论文研究了具有凸约束的随机凸优化问题，提出了一种非渐近保证的VRPG算法，并展示了其性能受到解以及带凸约束解决的问题的缩放距离控制。

    

    我们考虑了随机凸优化在凸约束下的问题。我们分析了一种适用于这个问题的自然方差减少的近端梯度（VRPG）算法的行为。我们的主要结果是VRPG算法的非渐近保证。与极小值最坏情况保证相反，我们的结果是基于实例的。这意味着我们的保证捕捉了损失函数的复杂性，噪声的变异性和约束集的几何性。我们表明，VRPG算法的非渐近性能受给定问题的解和给定凸约束下解决的特定小扰动问题的解之间的缩放距离（由$\sqrt{N}$缩放）的控制，这里，$N$表示样本数。利用局部极小值下界和扰动问题解之间的一种成熟联系，我们表明当$N \rightarrow +\infty$时，极小值存在并且受指定凸约束的约束。

    arXiv:2404.00042v1 Announce Type: cross  Abstract: We consider the problem of stochastic convex optimization under convex constraints. We analyze the behavior of a natural variance reduced proximal gradient (VRPG) algorithm for this problem. Our main result is a non-asymptotic guarantee for VRPG algorithm. Contrary to minimax worst case guarantees, our result is instance-dependent in nature. This means that our guarantee captures the complexity of the loss function, the variability of the noise, and the geometry of the constraint set. We show that the non-asymptotic performance of the VRPG algorithm is governed by the scaled distance (scaled by $\sqrt{N}$) between the solutions of the given problem and that of a certain small perturbation of the given problem -- both solved under the given convex constraints; here, $N$ denotes the number of samples. Leveraging a well-established connection between local minimax lower bounds and solutions to perturbed problems, we show that as $N \right
    
[^30]: 利用量子增强机器学习赋能信用评分系统

    Empowering Credit Scoring Systems with Quantum-Enhanced Machine Learning

    [https://arxiv.org/abs/2404.00015](https://arxiv.org/abs/2404.00015)

    提出了一种名为Systemic Quantum Score (SQS)的新方法，展示在金融领域生产级应用案例中相比纯经典模型更有优势，能够从较少数据点中提取模式并表现出更好性能。

    

    Quantum Kernels被认为在量子机器学习的早期阶段提供了有用性。然而，在利用庞大数据集时，高度复杂的经典模型很难超越，特别是在理解力方面。尽管如此，一旦数据稀缺且倾斜，经典模型就会遇到困难。量子特征空间被预计在这样具有挑战性的情景中能够找到更好的数据特征和目标类别之间的联系，最重要的是增强了泛化能力。在这项工作中，我们提出了一种名为Systemic Quantum Score (SQS)的新方法，并提供了初步结果，表明在金融行业生产级应用案例中，SQS可能比纯经典模型具有优势。我们的具体研究表明，SQS能够从较少的数据点中提取出模式，并且在数据需求量大的算法（如XGBoost）上表现出更好的性能，带来优势。

    arXiv:2404.00015v1 Announce Type: cross  Abstract: Quantum Kernels are projected to provide early-stage usefulness for quantum machine learning. However, highly sophisticated classical models are hard to surpass without losing interpretability, particularly when vast datasets can be exploited. Nonetheless, classical models struggle once data is scarce and skewed. Quantum feature spaces are projected to find better links between data features and the target class to be predicted even in such challenging scenarios and most importantly, enhanced generalization capabilities. In this work, we propose a novel approach called Systemic Quantum Score (SQS) and provide preliminary results indicating potential advantage over purely classical models in a production grade use case for the Finance sector. SQS shows in our specific study an increased capacity to extract patterns out of fewer data points as well as improved performance over data-hungry algorithms such as XGBoost, providing advantage i
    
[^31]: 核多重网格：通过稀疏高斯过程回归加速反向拟合

    Kernel Multigrid: Accelerate Back-fitting via Sparse Gaussian Process Regression

    [https://arxiv.org/abs/2403.13300](https://arxiv.org/abs/2403.13300)

    通过核包技术证明反向拟合的收敛速度，并提出了核多重网格算法，通过稀疏高斯过程回归增强反向拟合，适用于结构化和分散数据的加性GPs。

    

    添加高斯过程(GPs)是非参数特征选择的流行方法。对于这些模型的常见训练方法是贝叶斯反向拟合。然而，在训练加性GPs时，反向拟合的收敛速度仍然是一个悬而未决的问题。通过利用一种称为核包(KP)的技术，我们证明了反向拟合的收敛速度不会比$(1-\mathcal{O}(\frac{1}{n}))^t$更快，其中$n$和$t$分别表示数据大小和迭代次数。因此，反向拟合需要最少$\mathcal{O}(n\log n)$次迭代才能实现收敛。基于KP，我们进一步提出了一种称为核多重网格(KMG)的算法。该算法通过将稀疏高斯过程回归(GPR)纳入每个反向拟合迭代之后处理残差来增强反向拟合。它适用于具有结构化和分散数据的加性GPs。从理论上讲，我们证明K

    arXiv:2403.13300v1 Announce Type: cross  Abstract: Additive Gaussian Processes (GPs) are popular approaches for nonparametric feature selection. The common training method for these models is Bayesian Back-fitting. However, the convergence rate of Back-fitting in training additive GPs is still an open problem. By utilizing a technique called Kernel Packets (KP), we prove that the convergence rate of Back-fitting is no faster than $(1-\mathcal{O}(\frac{1}{n}))^t$, where $n$ and $t$ denote the data size and the iteration number, respectively. Consequently, Back-fitting requires a minimum of $\mathcal{O}(n\log n)$ iterations to achieve convergence. Based on KPs, we further propose an algorithm called Kernel Multigrid (KMG). This algorithm enhances Back-fitting by incorporating a sparse Gaussian Process Regression (GPR) to process the residuals subsequent to each Back-fitting iteration. It is applicable to additive GPs with both structured and scattered data. Theoretically, we prove that K
    
[^32]: 逻辑回归的可证实准确性随机抽样算法

    A Provably Accurate Randomized Sampling Algorithm for Logistic Regression

    [https://arxiv.org/abs/2402.16326](https://arxiv.org/abs/2402.16326)

    提出了一种逻辑回归问题的简单随机抽样算法，通过随机矩阵乘法实现高质量逼近估计概率和模型整体差异性。

    

    在统计学和机器学习中，逻辑回归是一种广泛应用于二分类任务的监督学习技术。当观测数量远远超过预测变量数量时，我们提出了一种简单的基于随机抽样的逻辑回归问题算法，保证高质量逼近估计概率和模型整体差异性。我们的分析建立在两个简单的结构条件基础上，这两个条件可归结为随机矩阵乘法，是随机化数值线性代数的基本且深入理解的基元。当利用杠杆分数对观测进行抽样时，我们分析了逻辑回归的估计概率属性，并证明准确逼近可以通过远小于总观测数的样本实现。为了进一步验证我们的理论发现，

    arXiv:2402.16326v1 Announce Type: cross  Abstract: In statistics and machine learning, logistic regression is a widely-used supervised learning technique primarily employed for binary classification tasks. When the number of observations greatly exceeds the number of predictor variables, we present a simple, randomized sampling-based algorithm for logistic regression problem that guarantees high-quality approximations to both the estimated probabilities and the overall discrepancy of the model. Our analysis builds upon two simple structural conditions that boil down to randomized matrix multiplication, a fundamental and well-understood primitive of randomized numerical linear algebra. We analyze the properties of estimated probabilities of logistic regression when leverage scores are used to sample observations, and prove that accurate approximations can be achieved with a sample whose size is much smaller than the total number of observations. To further validate our theoretical findi
    
[^33]: 动态系统中的实验设计的嵌套粒子滤波器

    Nesting Particle Filters for Experimental Design in Dynamical Systems

    [https://arxiv.org/abs/2402.07868](https://arxiv.org/abs/2402.07868)

    本文提出了一种新颖的方法来解决动态系统中的贝叶斯实验设计问题，利用嵌套粒子滤波器和立体蒙特卡洛方法来进行基于梯度的策略优化，相比于其他方法具有更好的性能。

    

    本文提出了一种新颖的贝叶斯实验设计方法，用于非交换数据，并将其形式化为风险敏感的策略优化。我们开发了内外SMC^2算法，使用嵌套顺序蒙特卡洛（SMC）估计器来预测期望的信息增益，并将其嵌入到粒子马尔可夫链蒙特卡洛（pMCMC）框架中进行基于梯度的策略优化。与最近依赖于偏估计器来摊销先前学习设计策略的成本的方法相比，我们的方法具有更好的性能。在一组动态系统的数值验证中展示了我们方法的有效性。

    In this paper, we propose a novel approach to Bayesian Experimental Design (BED) for non-exchangeable data that formulates it as risk-sensitive policy optimization. We develop the Inside-Out SMC^2 algorithm that uses a nested sequential Monte Carlo (SMC) estimator of the expected information gain and embeds it into a particle Markov chain Monte Carlo (pMCMC) framework to perform gradient-based policy optimization. This is in contrast to recent approaches that rely on biased estimators of the expected information gain (EIG) to amortize the cost of experiments by learning a design policy in advance. Numerical validation on a set of dynamical systems showcases the efficacy of our method in comparison to other state-of-the-art strategies.
    
[^34]: 因果贝叶斯优化通过外源分布学习

    Causal Bayesian Optimization via Exogenous Distribution Learning

    [https://arxiv.org/abs/2402.02277](https://arxiv.org/abs/2402.02277)

    本文引入了一种新的方法，通过学习外源变量的分布，提高了结构化因果模型的近似精度，并将因果贝叶斯优化扩展到更一般的因果方案。

    

    在结构化因果模型中，将目标变量最大化作为操作目标是一个重要的问题。现有的因果贝叶斯优化（CBO）方法要么依赖于改变因果结构以最大化奖励的硬干预，要么引入动作节点到内生变量中，以调整数据生成机制以实现目标。本文引入了一种新的方法来学习外源变量的分布，这在现有方法中通常被忽略或通过期望进行边缘化。外源分布学习提高了通常通过有限观测数据训练的代理模型中的结构化因果模型的近似精度。此外，学习到的外源分布将现有的CBO扩展到超出加性噪声模型（ANM）的一般因果方案。恢复外源变量使我们能够为噪声或未观测到的隐藏变量使用更灵活的先验。引入了一种新的CBO方法。

    Maximizing a target variable as an operational objective in a structured causal model is an important problem. Existing Causal Bayesian Optimization (CBO) methods either rely on hard interventions that alter the causal structure to maximize the reward; or introduce action nodes to endogenous variables so that the data generation mechanisms are adjusted to achieve the objective. In this paper, a novel method is introduced to learn the distribution of exogenous variables, which is typically ignored or marginalized through expectation by existing methods.   Exogenous distribution learning improves the approximation accuracy of structured causal models in a surrogate model that is usually trained with limited observational data. Moreover, the learned exogenous distribution extends existing CBO to general causal schemes beyond Additive Noise Models (ANM). The recovery of exogenous variables allows us to use a more flexible prior for noise or unobserved hidden variables. A new CBO method is 
    
[^35]: 处理张量奇异值分解中的非光滑挑战：多目标张量恢复框架

    Handling The Non-Smooth Challenge in Tensor SVD: A Multi-Objective Tensor Recovery Framework

    [https://arxiv.org/abs/2311.13958](https://arxiv.org/abs/2311.13958)

    提出一种具有可学习张量核范数的新型张量恢复模型，引入交替近端乘子方法（APMM）优化算法，解决处理非光滑变化的张量数据挑战

    

    最近，许多基于张量奇异值分解（t-SVD）的张量恢复方法在处理视觉数据（如彩色图像和视频）方面表现出潜力。然而，当面对显示出非光滑变化的张量数据时，这些方法通常会遭受严重的性能退化。虽然在现实世界中经常观察到这种情况，但传统的基于t-SVD的方法却忽视了这一点。在这项工作中，我们引入了一种新颖的张量恢复模型，其中包括可学习的张量核范数，以解决这一挑战。我们开发了一种名为交替近端乘子方法（APMM）的新优化算法，以迭代地解决提出的张量补全模型。理论分析证明了所提出的APMM收敛到优化问题的Karush-Kuhn-Tucker（KKT）点。此外，我们基于APMM提出了一个多目标张量恢复框架，以有效探索协

    arXiv:2311.13958v2 Announce Type: replace-cross  Abstract: Recently, numerous tensor singular value decomposition (t-SVD)-based tensor recovery methods have shown promise in processing visual data, such as color images and videos. However, these methods often suffer from severe performance degradation when confronted with tensor data exhibiting non-smooth changes. It has been commonly observed in real-world scenarios but ignored by the traditional t-SVD-based methods. In this work, we introduce a novel tensor recovery model with a learnable tensor nuclear norm to address such a challenge. We develop a new optimization algorithm named the Alternating Proximal Multiplier Method (APMM) to iteratively solve the proposed tensor completion model. Theoretical analysis demonstrates the convergence of the proposed APMM to the Karush-Kuhn-Tucker (KKT) point of the optimization problem. In addition, we propose a multi-objective tensor recovery framework based on APMM to efficiently explore the co
    
[^36]: 具有Fisher度量的黎曼拉普拉斯逼近

    Riemannian Laplace Approximation with the Fisher Metric

    [https://arxiv.org/abs/2311.02766](https://arxiv.org/abs/2311.02766)

    黎曼拉普拉斯逼近的新方法利用Fisher度量提供更丰富的逼近族，解决了在无限数据极限下先前方法度量选择不当导致逼近过于狭窄和有偏的问题。

    

    Laplace方法用高斯分布在其模式处对目标密度进行近似。基于Bernstein-von Mises定理，它在贝叶斯推断中是计算效率高且渐近准确的，但对于复杂的目标和有限数据后验，它往往是一种过于粗糙的近似。最近对Laplace逼近的一般化是根据选择的黎曼几何对高斯近似进行转换，提供了更丰富的近似族，同时保持计算效率。然而，正如本文所示，其性质严重依赖于所选择的度量，实际上，在先前研究中采用的度量导致的逼近即使在无限数据量的极限下也过于狭窄且存在偏差。我们通过进一步发展逼近族，推导出两种在无限数据极限下精确的替代变种，扩展了理论分析。

    arXiv:2311.02766v3 Announce Type: replace  Abstract: Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the
    
[^37]: 相似性、压缩和局部步骤：分布式变分不等式高效通信的三大支柱

    Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities

    [https://arxiv.org/abs/2302.07615](https://arxiv.org/abs/2302.07615)

    相似性、压缩和局部更新是本文提出的三大技术，用于减少分布式变分不等式问题中通信轮次和成本，实现了前所未有的三重协同作用。

    

    变分不等式是一个广泛而灵活的问题类，包括最小化、鞍点和不动点问题作为特例。因此，变分不等式在各种应用中被使用，从均衡搜索到对抗学习都有涉及。随着数据和模型规模的增加，当今的实例需要并行和分布式计算来解决现实世界中的机器学习问题，其中大部分可以表示为变分不等式。同时，大多数分布式方法存在一个重大瓶颈 - 通信成本。减少通信轮次的总数和每轮成本的三种主要技术是本地函数的相似性、传输信息的压缩和局部更新。本文结合了所有这些方法。对于变分不等式和鞍点问题来说，这样的三重协同作用以前并不存在。

    arXiv:2302.07615v2 Announce Type: replace-cross  Abstract: Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck - the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor eve
    
[^38]: 可识别的潜在因果内容用于隐含协变量转移下的领域自适应

    Identifiable Latent Causal Content for Domain Adaptation under Latent Covariate Shift

    [https://arxiv.org/abs/2208.14161](https://arxiv.org/abs/2208.14161)

    提出了一种新的隐含协变量转移（LCS）范式，增加了领域间的可变性和适应性，并提供了恢复标签变量潜在原因的理论保证。

    

    多源领域自适应（MSDA）解决了利用来自多个源域的标记数据和来自目标域的未标记数据来学习针对未标记目标领域的标签预测函数的挑战。我们提出了一种称为潜在协变量转移（LCS）的新范式，它引入了更大的领域间可变性和适应性。值得注意的是，它为恢复标签变量的潜在原因提供了理论保证。

    arXiv:2208.14161v3 Announce Type: replace  Abstract: Multi-source domain adaptation (MSDA) addresses the challenge of learning a label prediction function for an unlabeled target domain by leveraging both the labeled data from multiple source domains and the unlabeled data from the target domain. Conventional MSDA approaches often rely on covariate shift or conditional shift paradigms, which assume a consistent label distribution across domains. However, this assumption proves limiting in practical scenarios where label distributions do vary across domains, diminishing its applicability in real-world settings. For example, animals from different regions exhibit diverse characteristics due to varying diets and genetics.   Motivated by this, we propose a novel paradigm called latent covariate shift (LCS), which introduces significantly greater variability and adaptability across domains. Notably, it provides a theoretical assurance for recovering the latent cause of the label variable, w
    
[^39]: 嵌入控制部分观察系统：具有可证明样本效率的表示学习

    Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency

    [https://arxiv.org/abs/2205.13476](https://arxiv.org/abs/2205.13476)

    论文提出了一种名为Embed to Control（ETC）的强化学习算法，通过在两个级别学习表示的方法来解决部分观察马尔可夫决策问题，以实现样本高效利用。

    

    强化学习在部分观察马尔可夫决策过程（POMDPs）中面临两个挑战。一是通常需要全部历史记录来预测未来，这导致样本复杂度随着时间跨度呈指数级增长。二是观测和状态空间通常是连续的，这导致样本复杂度随外在维数呈指数级增长。为了解决这些挑战，需要通过利用POMDP的结构学习观测和状态历史的最小但足够的表示。为此，我们提出了一种名为Embed to Control (ETC)的强化学习算法，该算法在优化策略的同时学习两个级别的表示。(i)在每一步，ETC学习用低维特征表示状态，这对转移核进行因子分解。(ii)在多个步骤中，ETC学习用低维表示完整历史记录。

    arXiv:2205.13476v2 Announce Type: replace-cross  Abstract: Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but sufficient representation of the observation and state histories by exploiting the structure of the POMDP.   To this end, we propose a reinforcement learning algorithm named Embed to Control (ETC), which learns the representation at two levels while optimizing the policy.~(i) For each step, ETC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, ETC learns to represent the full history with a low-dimensional emb
    
[^40]: 将生成的对数进行准则对齐的黑盒知识蒸馏

    Aligning Logits Generatively for Principled Black-Box Knowledge Distillation

    [https://arxiv.org/abs/2205.10490](https://arxiv.org/abs/2205.10490)

    本文提出了一个新的黑盒知识蒸馏方法MEKD，通过将教师和学生模型的低维度对数对齐，实现将一个繁琐模型压缩成轻量级模型。

    

    黑盒知识蒸馏（B2KD）是一个处理云端到边缘模型压缩的问题，其中数据和模型托管在服务器上且无法看见。B2KD面临的挑战包括互联网交换受限和数据分布在边缘和云端之间的不一致。本文提出了一个包括去隐去和蒸馏两步工作流程，并在理论上提供了一个从对数到单元边界的新优化方向，不同于直接对数对齐。在其指导下，我们提出了一种新方法Mapping-Emulation KD（MEKD），将一个黑盒繁琐模型蒸馏成一个轻量级模型。我们的方法不区分软或硬响应处理，并包括：1）去隐去：通过生成器模拟教师函数的逆映射，和2）蒸馏：通过减小高维图像点之间的距离来对齐教师模型和学生模型的低维度对数。

    arXiv:2205.10490v2 Announce Type: replace-cross  Abstract: Black-Box Knowledge Distillation (B2KD) is a formulated problem for cloud-to-edge model compression with invisible data and models hosted on the server. B2KD faces challenges such as limited Internet exchange and edge-cloud disparity of data distributions. In this paper, we formalize a two-step workflow consisting of deprivatization and distillation, and theoretically provide a new optimization direction from logits to cell boundary different from direct logits alignment. With its guidance, we propose a new method Mapping-Emulation KD (MEKD) that distills a black-box cumbersome model into a lightweight one. Our method does not differentiate between treating soft or hard responses, and consists of: 1) deprivatization: emulating the inverse mapping of the teacher function with a generator, and 2) distillation: aligning low-dimensional logits of the teacher and student models by reducing the distance of high-dimensional image poin
    
[^41]: 基于线性函数逼近的部分观测强化学习及其可证明的样本效率

    Reinforcement Learning from Partial Observation: Linear Function Approximation with Provable Sample Efficiency

    [https://arxiv.org/abs/2204.09787](https://arxiv.org/abs/2204.09787)

    该研究提出了一种基于线性函数逼近的部分观测强化学习算法（OP-TENET），在有限的情节数内实现了$\epsilon$-最优策略，样本复杂度与线性结构的本征维度多项式缩放，与观测和状态空间的大小无关。

    

    我们研究具有无限观测和状态空间的部分观测马尔可夫决策过程（POMDP）的强化学习，在理论上仍然受到较少的研究。为此，我们首次尝试将部分可观测性与具有线性结构的一类POMDP的函数逼近联系起来。具体来说，我们提出了一种强化学习算法（乐观探索通过对抗积分方程或OP-TENET），在$ O（1 / \ epsilon ^ 2）$个情节内实现了$\ epsilon $-最优策略。特别地，样本复杂度在线性结构的本征维度多项式地缩放，并且与观测和状态空间的大小无关。OP-TENET的样本效率由一系列因素实现：（i）具有有限记忆的Bellman算子，以递归方式表示值函数，（ii）识别和估计这样一个算子

    arXiv:2204.09787v3 Announce Type: replace  Abstract: We study reinforcement learning for partially observed Markov decision processes (POMDPs) with infinite observation and state spaces, which remains less investigated theoretically. To this end, we make the first attempt at bridging partial observability and function approximation for a class of POMDPs with a linear structure. In detail, we propose a reinforcement learning algorithm (Optimistic Exploration via Adversarial Integral Equation or OP-TENET) that attains an $\epsilon$-optimal policy within $O(1/\epsilon^2)$ episodes. In particular, the sample complexity scales polynomially in the intrinsic dimension of the linear structure and is independent of the size of the observation and state spaces.   The sample efficiency of OP-TENET is enabled by a sequence of ingredients: (i) a Bellman operator with finite memory, which represents the value function in a recursive manner, (ii) the identification and estimation of such an operator 
    
[^42]: 通过标度不变的鲁棒密度感知距离（RDAD）过滤检测小孔

    Detection of Small Holes by the Scale-Invariant Robust Density-Aware Distance (RDAD) Filtration

    [https://arxiv.org/abs/2204.07821](https://arxiv.org/abs/2204.07821)

    通过引入鲁棒密度感知距离（RDAD）过滤，该方法能够在概率密度函数中准确区分被高密度区域包围的小孔，对噪声和异常值具有鲁棒性。

    

    提出了一种新颖的拓扑数据分析（TDA）方法，用于区分概率密度函数中被高密度区域包围的小孔与噪声。该方法对附加噪声和异常值具有鲁棒性。传统的TDA工具，如基于距离过滤的工具，通常难以区分小特征和噪声，因为两者的持续时间较短。提出了一种名为鲁棒密度感知距离（RDAD）过滤的备用过滤，用于延长高密度区域的小孔的持续时间。这是通过根据Bell等人的观点将距离函数加权密度实现的。引入了距离-测度的概念以增强稳定性和减少噪声。提出过滤的持续时间延长性和鲁棒性得到了严格论证，并提供了数值实验以证明所提过滤的有效性。

    arXiv:2204.07821v3 Announce Type: replace-cross  Abstract: A novel topological-data-analytical (TDA) method is proposed to distinguish, from noise, small holes surrounded by high-density regions of a probability density function. The proposed method is robust against additive noise and outliers. Traditional TDA tools, like those based on the distance filtration, often struggle to distinguish small features from noise, because both have short persistences. An alternative filtration, called the Robust Density-Aware Distance (RDAD) filtration, is proposed to prolong the persistences of small holes of high-density regions. This is achieved by weighting the distance function by the density in the sense of Bell et al. The concept of distance-to-measure is incorporated to enhance stability and mitigate noise. The persistence-prolonging property and robustness of the proposed filtration are rigorously established, and numerical experiments are presented to demonstrate the proposed filtration's
    
[^43]: Wasserstein Flow遇见复制动力学：Actor-Critic中代表学习的均场分析

    Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic

    [https://arxiv.org/abs/2112.13530](https://arxiv.org/abs/2112.13530)

    本文通过均场分析研究了基于特征的神经AC的演化和收敛，提出了一个使用两个学习率更新的AC版本，其中评论家通过大步长进行TD学习更新，演员通过小步长进行PPO更新。

    

    Actor-critic (AC)算法借助神经网络取得了显著的经验成功。然而，目前大部分关于AC算法的理论支持集中在具有线性函数逼近或线性化神经网络的情况下，其中特征表示在整个训练过程中保持不变。这种限制未能捕捉神经AC中代表学习的关键方面，在实际问题中至关重要。本文从均场的角度对基于特征的神经AC的演化和收敛进行了研究。具体地，我们考虑了一个AC的版本，其中演员和评论家由超参数化的两层神经网络表示，并使用两个时间尺度的学习率进行更新。评论家通过较大的步长进行时差（TD）学习更新，而演员通过较小步长进行邻域策略优化（PPO）更新。

    arXiv:2112.13530v2 Announce Type: replace  Abstract: Actor-critic (AC) algorithms, empowered by neural networks, have had significant empirical success in recent years. However, most of the existing theoretical support for AC algorithms focuses on the case of linear function approximations, or linearized neural networks, where the feature representation is fixed throughout training. Such a limitation fails to capture the key aspect of representation learning in neural AC, which is pivotal in practical problems. In this work, we take a mean-field perspective on the evolution and convergence of feature-based neural AC. Specifically, we consider a version of AC where the actor and critic are represented by overparameterized two-layer neural networks and are updated with two-timescale learning rates. The critic is updated by temporal-difference (TD) learning with a larger stepsize while the actor is updated via proximal policy optimization (PPO) with a smaller stepsize. In the continuous-t
    
[^44]: 回归问题的有效预测区间

    Valid prediction intervals for regression problems

    [https://arxiv.org/abs/2107.00363](https://arxiv.org/abs/2107.00363)

    本文回顾了回归问题中四类预测区间估计方法，并指出了一些方法在不同数据集上性能波动大的原因。

    

    在过去几十年中，针对回归设置提出了各种方法来估计预测区间，包括贝叶斯方法、集成方法、直接区间估计方法和符合预测方法。一个重要问题是这些方法的校准：生成的预测区间应该具有预定义的覆盖水平，而不应该过于保守。在这项工作中，我们从概念和实验角度回顾了上述四类方法。来自各个领域的基准数据集的结果突显出在数据集之间的性能有很大波动。这些观察结果可归因于某些类方法固有假设的违背。我们阐述了如何将符合预测用作没有校准步骤会产生差结果的方法的通用校准过程。

    arXiv:2107.00363v4 Announce Type: replace-cross  Abstract: Over the last few decades, various methods have been proposed for estimating prediction intervals in regression settings, including Bayesian methods, ensemble methods, direct interval estimation methods and conformal prediction methods. An important issue is the calibration of these methods: the generated prediction intervals should have a predefined coverage level, without being overly conservative. In this work, we review the above four classes of methods from a conceptual and experimental point of view. Results on benchmark data sets from various domains highlight large fluctuations in performance from one data set to another. These observations can be attributed to the violation of certain assumptions that are inherent to some classes of methods. We illustrate how conformal prediction can be used as a general calibration procedure for methods that deliver poor results without a calibration step.
    
[^45]: 变分传输：一种用于分布优化的收敛粒子算法

    Variational Transport: A Convergent Particle-BasedAlgorithm for Distributional Optimization

    [https://arxiv.org/abs/2012.11554](https://arxiv.org/abs/2012.11554)

    提出了一种新的基于粒子的算法，名为变分传输，通过迭代地推动一组粒子，在概率分布流形上近似执行沃瑟斯坦梯度下降。

    

    我们考虑最小化一个在概率分布族上定义的函数的优化问题，其中假定目标函数具有变分形式。这种分布优化问题在机器学习和统计学中广泛存在，蒙特卡洛抽样、变分推断、策略优化和生成对抗网络是其中的例子。针对这个问题，我们提出了一种新的基于粒子的算法，名为变分传输，通过迭代地推动一组粒子，在概率分布流形上近似执行沃瑟斯坦梯度下降。具体而言，我们证明沿着函数梯度的测地线方向移动，与对概率分布施加一个推前映射等价于通过推动一组粒子来准确近似实施。

    arXiv:2012.11554v2 Announce Type: replace  Abstract: We consider the optimization problem of minimizing a functional defined over a family of probability distributions, where the objective functional is assumed to possess a variational form. Such a distributional optimization problem arises widely in machine learning and statistics, with Monte-Carlo sampling, variational inference, policy optimization, and generative adversarial network as examples. For this problem, we propose a novel particle-based algorithm, dubbed as variational transport, which approximately performs Wasserstein gradient descent over the manifold of probability distributions via iteratively pushing a set of particles. Specifically, we prove that moving along the geodesic in the direction of functional gradient with respect to the second-order Wasserstein distance is equivalent to applying a pushforward mapping to a probability distribution, which can be approximated accurately by pushing a set of particles. Specif
    
[^46]: 离散时间差分和Q学习能学得特征表示吗？一种平均场理论

    Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory

    [https://arxiv.org/abs/2006.04761](https://arxiv.org/abs/2006.04761)

    研究探讨离散时间差分学习和Q学习在深度强化学习中的特征表示演变，证明利用过度参数化的方法可以实现这种演变，并关注特征表示对于算法收敛的重要性。

    

    离散时间差分和Q学习在深度强化学习中发挥关键作用，它们利用神经网络等表达力非线性函数逼近器。它们的实证成功的核心是学得的特征表示，将丰富的观测，如图像和文本，嵌入到编码语义结构的潜在空间中。同时，这种特征表示的演变对离散时间差分学习和Q学习的收敛至关重要。特别地，当函数逼近器在特征表示中是线性的且在整个学习过程中保持不变时，离散时间差分学习会收敛，否则可能发散。我们的目标是回答以下问题：当函数逼近器是神经网络时，相关的特征表示如何演进？如果它收敛，它是否收敛至最优的特征表示？

    arXiv:2006.04761v2 Announce Type: replace  Abstract: Temporal-difference and Q-learning play a key role in deep reinforcement learning, where they are empowered by expressive nonlinear function approximators such as neural networks. At the core of their empirical successes is the learned feature representation, which embeds rich observations, e.g., images and texts, into the latent space that encodes semantic structures. Meanwhile, the evolution of such a feature representation is crucial to the convergence of temporal-difference and Q-learning.   In particular, temporal-difference learning converges when the function approximator is linear in a feature representation, which is fixed throughout learning, and possibly diverges otherwise. We aim to answer the following questions: When the function approximator is a neural network, how does the associated feature representation evolve? If it converges, does it converge to the optimal one?   We prove that, utilizing an overparameterized tw
    
[^47]: 在策略优化中实现可证明高效的探索

    Provably Efficient Exploration in Policy Optimization

    [https://arxiv.org/abs/1912.05830](https://arxiv.org/abs/1912.05830)

    OPPO是第一个在探索中高效的策略优化算法，在处理具有线性函数近似、未知转移和对抗性奖励的问题中取得了 $\tilde{O}(\sqrt{d^2 H^3 T} )$ 的遗憾。

    

    虽然基于策略的强化学习（RL）在实践中取得了巨大成功，但在理论上却远不如基于值函数的RL被理解的充分。具体来说，如何设计一个在探索中综合高效的策略优化算法仍然是模糊的。为弥合这一差距，本文提出了一种Proximal Policy Optimization算法的"乐观变体"（OPPO），其遵循“策略梯度方向”的“乐观版本”。本文证明，对于具有线性函数近似、未知转移和具有完全信息反馈的对抗性奖励的基于情节马尔可夫决策过程问题，OPPO实现了 $\tilde{O}(\sqrt{d^2 H^3 T} )$ 的遗憾。其中，$d$ 是特征维度，$H$ 是情节长度，$T$ 是总步数。就我们所知，OPPO是第一个可证明高效的策略优化算法。

    arXiv:1912.05830v4 Announce Type: replace  Abstract: While policy-based reinforcement learning (RL) achieves tremendous successes in practice, it is significantly less understood in theory, especially compared with value-based RL. In particular, it remains elusive how to design a provably efficient policy optimization algorithm that incorporates exploration. To bridge such a gap, this paper proposes an Optimistic variant of the Proximal Policy Optimization algorithm (OPPO), which follows an ``optimistic version'' of the policy gradient direction. This paper proves that, in the problem of episodic Markov decision process with linear function approximation, unknown transition, and adversarial reward with full-information feedback, OPPO achieves $\tilde{O}(\sqrt{d^2 H^3 T} )$ regret. Here $d$ is the feature dimension, $H$ is the episode horizon, and $T$ is the total number of steps. To the best of our knowledge, OPPO is the first provably efficient policy optimization algorithm that explo
    
[^48]: 量子机器学习：从NISQ到容错。

    Quantum Machine Learning: from NISQ to Fault Tolerance. (arXiv:2401.11351v1 [quant-ph])

    [http://arxiv.org/abs/2401.11351](http://arxiv.org/abs/2401.11351)

    本文提供了对量子机器学习领域的全面回顾，涵盖了在NISQ技术和容错量子计算硬件上使用的技术和算法，并深入讨论了与量子机器学习相关的基本概念和统计学习理论。

    

    量子机器学习是在量子设备上运行机器学习算法的过程，在学术界和商业界引起了广泛关注。本文对量子机器学习领域涌现的各种概念进行了全面而公正的回顾。这包括在噪声中间尺度量子（NISQ）技术中使用的技术，以及与容错量子计算硬件兼容的算法方法。我们的回顾涵盖了与量子机器学习相关的基本概念、算法和统计学习理论。

    Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.
    
[^49]: 旗帜游戏：通过旗帜流形来获得鲁棒的主方向

    Fun with Flags: Robust Principal Directions via Flag Manifolds. (arXiv:2401.04071v1 [cs.CV])

    [http://arxiv.org/abs/2401.04071](http://arxiv.org/abs/2401.04071)

    本研究提出了一种统一的PCA和其变种框架，该框架基于线性子空间旗帜，并引入了对异常值和数据流形的考虑。通过在旗帜流形上进行优化问题的求解，结合主测地线近似，提出了一系列新的降维算法。

    

    主成分分析（PCA）及其对流形和异常数据的扩展，在计算机视觉和机器学习中是不可或缺的。本研究提出了PCA及其变种的统一形式，引入了基于线性子空间旗帜的框架，即逐渐增加维度的嵌套线性子空间的层次结构，不仅允许共同实现，还产生了新的未曾探索的变种。我们从广义化传统的PCA方法开始，这些方法要么最大化方差，要么最小化重构误差。我们扩展这些解释，通过考虑异常值和数据流形，开发出了大量新的降维算法。为了设计一种通用的计算方法，我们将鲁棒和对偶形式的PCA重新构建为在旗帜流形上的优化问题。然后，我们将主测地线近似（切线PCA）整合到这个基于旗帜的框架中，创造出一种新的方法。

    Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, crea
    
[^50]: 球面上的内在高斯向量场

    Intrinsic Gaussian Vector Fields on Manifolds. (arXiv:2310.18824v1 [stat.ML])

    [http://arxiv.org/abs/2310.18824](http://arxiv.org/abs/2310.18824)

    本文提出了一种新型的在流形上处理矢量值信号的高斯过程模型，具有内在定义和考虑空间几何的特点，并为部署在二维球面和超曲面上的Hodge-Mat\'ern高斯向量场提供了计算基元。

    

    从机器人技术到气候科学等各种应用都需要对非欧几里得域（如球面）上的信号进行建模。最近，在流行度量空间上提出了高斯过程模型，尤其是在需要进行不确定性量化的任务中。在流形设置中，与标量值信号相比，矢量值信号可能表现出截然不同的行为，迄今为止的大部分进展都集中在对前者进行建模。然而，对于许多应用，如对未知动力系统的风速或力场进行建模，后者至关重要。本文提出了一种在流形上为矢量值信号提供内在定义并考虑空间几何的新型高斯过程模型。我们提供了部署所得到的Hodge-Mat\'ern高斯向量场在二维球面和超曲面上所需的计算基元。此外，我们还强调了两个推广方向：离散的二维网格和”ide“（暂且译为：想法）。

    Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\'ern Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and "ide
    
[^51]: 具有重尾奖励的强化学习离线策略评估和优化的鲁棒性提升

    Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards. (arXiv:2310.18715v1 [cs.LG])

    [http://arxiv.org/abs/2310.18715](http://arxiv.org/abs/2310.18715)

    本文提出的ROAM和ROOM算法框架通过将中位数法与离线强化学习策略相结合，提供了对重尾奖励的直接不确定性估计，从而增强了离线强化学习在现实应用中的鲁棒性。

    

    本文旨在增强离线强化学习在现实世界应用中普遍存在的重尾奖励情况下的鲁棒性。我们提出了两个算法框架，ROAM和ROOM，用于鲁棒的离线策略评估和离线策略优化。我们的框架的核心是将中位数法与离线强化学习策略相结合，能够对值函数估计器进行直接的不确定性估计。这不仅符合离线策略优化中的保守主义原则，而且灵活处理重尾奖励。理论结果和广泛的实验证明，我们的两个框架在记录的数据集中展示了具有重尾奖励分布时超越现有方法的性能。

    This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions.
    
[^52]: 超越神经网络：模型复杂性的经验探索

    Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity. (arXiv:2310.17247v1 [cs.LG])

    [http://arxiv.org/abs/2310.17247](http://arxiv.org/abs/2310.17247)

    本文发现神经网络中的grokking现象不仅局限于神经网络，还出现在其他算法和模型中。通过在数据集中添加虚假信息的维度，可以诱发grokking现象。研究表明，grokking现象在解决方案搜索受复杂性和错误指导的任何情况下可能发生。这对理解grokking现象提供了更广泛的理论支持。

    

    在某些情况下，神经网络展现出一种称为“grokking”的现象，即它们在验证集上实现完美或接近完美的准确度，而在训练集上则早已达到相同的性能。本文发现，grokking不仅限于神经网络，还出现在其他设置中，例如高斯过程（GP）分类、GP回归和线性回归。我们还发现了一种通过添加包含虚假信息的维度来诱发基于算法的数据集中的grokking现象的机制。非神经结构中的这种现象的存在证明了grokking不局限于SGD或权重范数正则化。相反，grokking可能发生在任何由复杂性和错误指导解决方案搜索的情况中。基于这一洞察和我们在贝叶斯神经网络（BNN）和GP回归模型的训练轨迹中观察到的进一步趋势，我们在grokking的更一般的理论方面取得了进展。

    In some settings neural networks exhibit a phenomenon known as grokking, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression and linear regression. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures provides evidence that grokking is not specific to SGD or weight norm regularisation. Instead, grokking may be possible in any setting where solution search is guided by complexity and error. Based on this insight and further trends we see in the training trajectories of a Bayesian neural network (BNN) and GP regression model, we make progress towards a more general theory of grokking. Spe
    
[^53]: 多个专家学习推迟的原则方法

    Principled Approaches for Learning to Defer with Multiple Experts. (arXiv:2310.14774v1 [cs.LG])

    [http://arxiv.org/abs/2310.14774](http://arxiv.org/abs/2310.14774)

    我们研究了多个专家学习推迟问题的代理损失和算法，并证明了这些代理损失函数具有强H一致性界限。我们展示了几个实际应用的代理损失函数，并设计了基于最小化这些损失函数的新的学习推迟算法。我们还进行了在SVHN和CIFAR-10数据集上的实验。

    

    我们提出了一项关于使用多个专家学习推迟问题的代理损失和算法的研究。我们首先引入了一类专门针对多专家设置的代理损失函数，其中预测和推迟函数同时学习。然后，我们证明了这些代理损失函数受益于强H一致性界限。我们通过几个实际代理损失函数的示例展示了我们分析的应用，并给出了明确的保证。这些损失函数直接导致了基于它们最小化的新的学习推迟算法的设计。虽然本工作的主要重点是理论分析，但我们还报告了在SVHN和CIFAR-10数据集上的多个实验结果。

    We present a study of surrogate losses and algorithms for the general problem of learning to defer with multiple experts. We first introduce a new family of surrogate losses specifically tailored for the multiple-expert setting, where the prediction and deferral functions are learned simultaneously. We then prove that these surrogate losses benefit from strong $H$-consistency bounds. We illustrate the application of our analysis through several examples of practical surrogate losses, for which we give explicit guarantees. These loss functions readily lead to the design of new learning to defer algorithms based on their minimization. While the main focus of this work is a theoretical analysis, we also report the results of several experiments on SVHN and CIFAR-10 datasets.
    
[^54]: 预测-拒绝多类放弃：理论分析和算法

    Predictor-Rejector Multi-Class Abstention: Theoretical Analysis and Algorithms. (arXiv:2310.14772v1 [cs.LG])

    [http://arxiv.org/abs/2310.14772](http://arxiv.org/abs/2310.14772)

    我们研究了多类别分类设置中的学习与放弃框架，并提出了一系列新的理论和算法结果，解决了两个现存的开放问题。这些保证为基于最小化放弃损失的新的多类别放弃算法提供了启示。

    

    我们研究了多类别分类设置中的学习与放弃框架。在这种设置中，学习者可以选择以一定的预定义成本放弃进行预测。我们提出了一系列新的理论和算法结果，解决了预测-拒绝框架下的学习问题。我们引入了几个新的替代损失函数家族，证明了强非渐进和假设集特定的一致性保证，从而积极地解决了两个现存的开放问题。这些保证提供了放弃损失函数的估计误差的上界，与替代损失的误差相关。我们分析了同时学习预测器和拒绝器的单阶段设置，以及在应用中至关重要的两阶段设置，在第一阶段使用标准替代损失函数如交叉熵来学习预测器。这些保证为基于最小化放弃损失的新的多类别放弃算法提供了启示。

    We study the key framework of learning with abstention in the multi-class classification setting. In this setting, the learner can choose to abstain from making a prediction with some pre-defined cost. We present a series of new theoretical and algorithmic results for this learning problem in the predictor-rejector framework. We introduce several new families of surrogate losses for which we prove strong non-asymptotic and hypothesis set-specific consistency guarantees, thereby resolving positively two existing open questions. These guarantees provide upper bounds on the estimation error of the abstention loss function in terms of that of the surrogate loss. We analyze both a single-stage setting where the predictor and rejector are learned simultaneously and a two-stage setting crucial in applications, where the predictor is learned in a first stage using a standard surrogate loss such as cross-entropy. These guarantees suggest new multi-class abstention algorithms based on minimizing
    
[^55]: 基于分数的多类放弃的理论基础损失函数和算法

    Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention. (arXiv:2310.14770v1 [cs.LG])

    [http://arxiv.org/abs/2310.14770](http://arxiv.org/abs/2310.14770)

    本文提出了基于分数的多类放弃的理论基础损失函数和算法，包括引入了新的代理损失函数族群以及证明了这些代理损失的一致性保证。我们通过实验证明了这些算法的实际意义。

    

    学习中的放弃是一种重要的场景，学习者可以选择在某个代价下放弃进行预测。本文在多类别分类的设置下分析了基于分数的学习中的放弃。我们引入了放弃损失函数的新代理损失族群，其中包括单阶段设置中最先进的代理损失以及二阶段设置中的新型损失函数。我们证明了这些代理损失的强非渐近和假设集特定的一致性保证，这些保证上界了放弃损失函数的估计误差，与代理损失的估计误差相关。我们的上界可以帮助比较不同的基于分数的代理损失，指导通过最小化提出的代理损失函数来设计新的放弃算法。我们在CIFAR-10、CIFAR-100和SVHN数据集上对我们的新算法进行了实验评估，展示了我们的新代理损失函数的实际意义。

    Learning with abstention is a key scenario where the learner can abstain from making a prediction at some cost. In this paper, we analyze the score-based formulation of learning with abstention in the multi-class classification setting. We introduce new families of surrogate losses for the abstention loss function, which include the state-of-the-art surrogate losses in the single-stage setting and a novel family of loss functions in the two-stage setting. We prove strong non-asymptotic and hypothesis set-specific consistency guarantees for these surrogate losses, which upper-bound the estimation error of the abstention loss function in terms of the estimation error of the surrogate loss. Our bounds can help compare different score-based surrogates and guide the design of novel abstention algorithms by minimizing the proposed surrogate losses. We experimentally evaluate our new algorithms on CIFAR-10, CIFAR-100, and SVHN datasets and the practical significance of our new surrogate losse
    
[^56]: 用于采样、优化和提升的通用Ito链的Ito扩散逼近

    Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting. (arXiv:2310.06081v1 [math.OC])

    [http://arxiv.org/abs/2310.06081](http://arxiv.org/abs/2310.06081)

    本文研究了一类广泛的马尔可夫链，即Ito链的Ito扩散逼近。与大多数相关论文不同，我们的链具有各向同性和状态相关的噪声，并可以适用于多种应用场景。我们证明了Ito链与对应的随机微分方程之间的W2-距离的上界。这些结果改进了已有的估计方法，并在某些特殊情况下提供了首次的分析。

    

    本文考虑了一类相当一般和广泛的马尔可夫链，即Ito链，其类似于某些随机微分方程的Euler-Maruyama离散化。我们研究的链是一个统一的理论分析框架。与大多数相关论文中的正态和状态独立噪声不同，我们的链具有几乎任意各向同性和状态相关噪声。此外，我们链的漂移和扩散系数可以是精确的，以涵盖诸如随机梯度Langevin动力学、采样、随机梯度下降或随机梯度提升等广泛的应用。我们证明了Ito链与对应的随机微分方程之间的W2-距离的一个上界。这些结果改进或覆盖了大部分已知的估计。此外，对于某些特殊情况，我们的分析是第一个。

    This work considers a rather general and broad class of Markov chains, Ito chains that look like Euler-Maryama discretization of some Stochastic Differential Equation. The chain we study is a unified framework for theoretical analysis. It comes with almost arbitrary isotropic and state-dependent noise instead of normal and state-independent one, as in most related papers. Moreover, our chain's drift and diffusion coefficient can be inexact to cover a wide range of applications such as Stochastic Gradient Langevin Dynamics, sampling, Stochastic Gradient Descent, or Stochastic Gradient Boosting. We prove an upper bound for $W_{2}$-distance between laws of the Ito chain and the corresponding Stochastic Differential Equation. These results improve or cover most of the known estimates. Moreover, for some particular cases, our analysis is the first.
    
[^57]: 一致性轨迹模型：学习扩散的概率流ODE轨迹

    Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion. (arXiv:2310.02279v1 [cs.LG])

    [http://arxiv.org/abs/2310.02279](http://arxiv.org/abs/2310.02279)

    提出了一种一致性轨迹模型（CTM），它可以加速扩散模型的采样，同时通过对抗训练和去噪得分匹配损失的组合来提高性能，并实现了最先进的采样质量。

    

    一致性模型（CM）加速基于得分的扩散模型采样，但以牺牲样本质量为代价，缺乏一种自然的方法来权衡速度和质量。为了解决这个限制，我们提出了一致性轨迹模型（CTM），它是包括CM和基于得分模型在内的泛化模型。CTM训练一个单一的神经网络，可以在单次前向传递中输出得分（即对数密度的梯度），并允许在扩散过程中任意初始和最终时间之间进行不受限制的遍历概率流普通微分方程（ODE）。CTM利用对抗训练和去噪得分匹配损失的有效组合来提高性能，并在CIFAR-10（FID 1.73）和64X64分辨率的ImageNet上实现新的最先进FID。CTM还实现了一系列新的采样方案，包括确定性和随机的ODE解中的长跳跃。

    Consistency Models (CM) (Song et al., 2023) accelerate score-based diffusion model sampling at the cost of sample quality but lack a natural way to trade-off quality for speed. To address this limitation, we propose Consistency Trajectory Model (CTM), a generalization encompassing CM and score-based models as special cases. CTM trains a single neural network that can -- in a single forward pass -- output scores (i.e., gradients of log-density) and enables unrestricted traversal between any initial and final time along the Probability Flow Ordinary Differential Equation (ODE) in a diffusion process. CTM enables the efficient combination of adversarial training and denoising score matching loss to enhance performance and achieves new state-of-the-art FIDs for single-step diffusion model sampling on CIFAR-10 (FID 1.73) and ImageNet at 64X64 resolution (FID 2.06). CTM also enables a new family of sampling schemes, both deterministic and stochastic, involving long jumps along the ODE soluti
    
[^58]: 学习动态有向无环图的信息理论最优样本复杂度

    Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs. (arXiv:2308.16859v1 [stat.ML])

    [http://arxiv.org/abs/2308.16859](http://arxiv.org/abs/2308.16859)

    本文研究了学习动态有向无环图（DDAG）的信息理论最优样本复杂度，提出了一种基于观测时间序列的功率谱密度矩阵的度量和算法来重建DDAG。

    

    本文研究了学习线性动态系统（LDS）在有向无环图（DAG）上的底层相互作用/依赖关系的最优样本复杂度。学习DAG结构的样本复杂度在静态系统中已经得到了很好的研究，其中节点状态的样本是独立同分布的（i.i.d.）。然而，在具有动态系统的DAG中，这样的研究较少。我们将这样的DAG称为\emph{动态}DAG（DDAG）。具体来说，我们考虑了一个DDAG，其中节点动力学由未观测的外生噪声源驱动，这些噪声源在时间上是宽幅平稳的（WSS），但彼此之间是不相关的，并且具有相同的功率谱密度（PSD）。受静态设置的启发，我们提出了一种基于观测时间序列的PSD矩阵的度量和算法来重建DDAG。噪声PSD相等的假设可以放宽，以使其可识别。

    In this article, the optimal sample complexity of learning the underlying interaction/dependencies of a Linear Dynamical System (LDS) over a Directed Acyclic Graph (DAG) is studied. The sample complexity of learning a DAG's structure is well-studied for static systems, where the samples of nodal states are independent and identically distributed (i.i.d.). However, such a study is less explored for DAGs with dynamical systems, where the nodal states are temporally correlated. We call such a DAG underlying an LDS as \emph{dynamical} DAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are driven by unobserved exogenous noise sources that are wide-sense stationary (WSS) in time but are mutually uncorrelated, and have the same {power spectral density (PSD)}. Inspired by the static settings, a metric and an algorithm based on the PSD matrix of the observed time series are proposed to reconstruct the DDAG. The equal noise PSD assumption can be relaxed such that identifiabil
    
[^59]: PCA、SVD和数据居中化

    PCA, SVD, and Centering of Data. (arXiv:2307.15213v1 [stat.ME])

    [http://arxiv.org/abs/2307.15213](http://arxiv.org/abs/2307.15213)

    本研究详细研究了PCA方法中数据居中化步骤的影响，分析了带居中化和不带居中化的两个PCA嵌入之间的对齐性，并探讨了其与奇异向量以及均值方向之间的关系。

    

    本文详细研究了主成分分析（PCA），这是统计学和机器学习中常用的降维方法。奇异值分解（SVD）通常被用作计算PCA的主要方法，这个过程中必不可少地包含了数据居中化的步骤，即从数据集中减去均值位置。在我们的研究中，我们深入探讨了这个关键但常常被忽视或轻视的数据居中化步骤的影响。我们的研究精细地研究了在什么条件下，从带有居中化的SVD和不带居中化的SVD得到的两个PCA嵌入可以看作是对齐的。作为这个探索的一部分，我们分析了第一个奇异向量和均值方向之间的关系，随后将这一观察结果与中心化和非中心化矩阵的两个SVD之间的一致性联系起来。此外，我们还探讨了可能产生的相关影响。

    The research detailed in this paper scrutinizes Principal Component Analysis (PCA), a seminal method employed in statistics and machine learning for the purpose of reducing data dimensionality. Singular Value Decomposition (SVD) is often employed as the primary means for computing PCA, a process that indispensably includes the step of centering - the subtraction of the mean location from the data set. In our study, we delve into a detailed exploration of the influence of this critical yet often ignored or downplayed data centering step. Our research meticulously investigates the conditions under which two PCA embeddings, one derived from SVD with centering and the other without, can be viewed as aligned. As part of this exploration, we analyze the relationship between the first singular vector and the mean direction, subsequently linking this observation to the congruity between two SVDs of centered and uncentered matrices. Furthermore, we explore the potential implications arising fro
    
[^60]: 具有马尔可夫噪声的一阶方法：从加速到变分不等式

    First Order Methods with Markovian Noise: from Acceleration to Variational Inequalities. (arXiv:2305.15938v1 [math.OC])

    [http://arxiv.org/abs/2305.15938](http://arxiv.org/abs/2305.15938)

    本论文研究了涉及马尔科夫噪声的随机优化问题，提出了一种适用于非凸和强凸最小化问题的一阶梯度方法，使用基于多层蒙特卡罗方法的随机批处理方案以获得最优线性关系，并消除了以前研究中的限制条件。在马尔可夫噪声下对变分不等式的扩展是原创性的。

    

    本文研究涉及马尔可夫噪声的随机优化问题。我们提出了一个统一的方法来理论分析一阶梯度方法用于解决随机优化和变分不等式的问题。我们的方法涵盖了非凸和强凸最小化问题的情况。为了实现一个依赖于底层噪声序列混合时间的最优(线性)关系，我们使用基于多层蒙特卡罗方法的随机批处理方案。此外，我们的技术允许我们消除以前关于马尔可夫噪声的研究中的限制条件，例如需要有界域和均匀有界随机梯度。我们在马尔可夫噪声下对变分不等式的扩展是原创性的。此外，我们提供了匹配强凸优化问题的理论最优解的下限。

    This paper delves into stochastic optimization problems that involve Markovian noise. We present a unified approach for the theoretical analysis of first-order gradient methods for stochastic optimization and variational inequalities. Our approach covers scenarios for both non-convex and strongly convex minimization problems. To achieve an optimal (linear) dependence on the mixing time of the underlying noise sequence, we use the randomized batching scheme, which is based on the multilevel Monte Carlo method. Moreover, our technique allows us to eliminate the limiting assumptions of previous research on Markov noise, such as the need for a bounded domain and uniformly bounded stochastic gradients. Our extension to variational inequalities under Markovian noise is original. Additionally, we provide lower bounds that match the oracle complexity of our method in the case of strongly convex optimization problems.
    
[^61]: 具有无限制内存的在线凸优化

    Online Convex Optimization with Unbounded Memory. (arXiv:2210.09903v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09903](http://arxiv.org/abs/2210.09903)

    本论文提出了一种新的在线凸优化框架，可以处理决策历史的长期依赖关系，并介绍了用于量化依赖程度的$p$-有效内存容量的概念。

    

    在线凸优化（OCO）是在线学习中广泛使用的框架。然而，在很多应用中，学习者的损失不仅取决于当前的决策，还取决于直到那个时间点的所有决策历史。本文引入了一种OCO的扩展框架，“具有无限制内存的在线凸优化”，来捕捉对过去决策的长期依赖关系，并介绍了$p$-有效内存容量的概念，$H_p$，它量化了$p$阶影响的最大值。

    Online convex optimization (OCO) is a widely used framework in online learning. In each round, the learner chooses a decision in a convex set and an adversary chooses a convex loss function, and then the learner suffers the loss associated with their current decision. However, in many applications the learner's loss depends not only on the current decision but on the entire history of decisions until that point. The OCO framework and its existing generalizations do not capture this, and they can only be applied to many settings of interest after a long series of approximation arguments. They also leave open the question of whether the dependence on memory is tight because there are no non-trivial lower bounds. In this work we introduce a generalization of the OCO framework, ``Online Convex Optimization with Unbounded Memory'', that captures long-term dependence on past decisions. We introduce the notion of $p$-effective memory capacity, $H_p$, that quantifies the maximum influence of p
    
[^62]: 从小样本中估计大的因果多树

    Estimating large causal polytrees from small samples. (arXiv:2209.07028v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2209.07028](http://arxiv.org/abs/2209.07028)

    本文介绍了一种算法，可以在变量数量远大于样本大小的情况下，准确地估计大规模因果多树结构，而几乎不需要任何分布或建模的假设。

    

    我们考虑从相对较小的独立同分布样本中估计大的因果多树的问题。这是在变量数量与样本大小相比非常大的情况下确定因果结构的问题，例如基因调控网络。我们提出了一种算法，在这种情况下以高准确度恢复树形结构。该算法除了一些温和的非退化条件外，基本不需要分布或建模的假设。

    We consider the problem of estimating a large causal polytree from a relatively small i.i.d. sample. This is motivated by the problem of determining causal structure when the number of variables is very large compared to the sample size, such as in gene regulatory networks. We give an algorithm that recovers the tree with high accuracy in such settings. The algorithm works under essentially no distributional or modeling assumptions other than some mild non-degeneracy conditions.
    
[^63]: 面对混淆因素的悲观情绪：部分可观察马尔可夫决策过程的证明有效离线强化学习

    Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes. (arXiv:2205.13589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13589](http://arxiv.org/abs/2205.13589)

    本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。

    

    本文研究了部分可观测马尔可夫决策过程中的离线强化学习。特别地，我们旨在从由行为策略收集的数据集中学习最优策略，该策略可能取决于潜在状态。这样的数据集在混淆意义上同时影响行动和观测值，这对于现有的离线强化学习算法来说是禁止的。为此，我们提出了通过近端因果推断构建的悲观置信区间耦合序列的代理变量悲观策略优化（P3O）算法，该算法在广义函数逼近的上下文中解决了混淆偏差和最优策略与行为策略之间的分布偏移问题。我们证明，在混淆数据集的部分覆盖假设下，P3O可以实现n^{-1/2}的收敛率。

    We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \underline{P}roxy variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization (\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \texttt{P3O} achieves a $n^{-1/2}$-
    
[^64]: 多任务学习和Bandits通过健壮统计学

    Multitask Learning and Bandits via Robust Statistics. (arXiv:2112.14233v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.14233](http://arxiv.org/abs/2112.14233)

    本研究探讨了多任务学习以及Bandits方法的健壮统计学实现，提出了一种新颖的两阶段多任务学习估计器，该估计器以一种样本高效的方式利用共享全局参数和稀疏实例特定术语的结构。

    

    决策者经常同时面对许多相关但异质的学习问题。在此工作中，我们研究了一种自然的设置，其中每个学习实例中的未知参数可以分解为共享全局参数加上稀疏的实例特定术语。我们提出了一种新颖的两阶段多任务学习估计器，以一种样本高效的方式利用这种结构，使用健壮统计学（在相似实例上学习）和LASSO回归（去偏差结果）的独特组合。我们的估计器提供了改进的样本复杂度界限。

    Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bound
    

