# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Evaluating the Robustness of Test Selection Methods for Deep Neural Networks.](http://arxiv.org/abs/2308.01314) | 本文评估了测试选择方法在深度神经网络测试中的稳定性，通过探讨这些方法的潜在陷阱并进行实证研究，揭示了它们的可靠性问题。 |
| [^2] | [Global Hierarchical Neural Networks using Hierarchical Softmax.](http://arxiv.org/abs/2308.01210) | 本文提出了一种使用层次化softmax的全局层次化神经网络框架，适用于具有层次结构的分类任务，并且在四个文本分类数据集上的实验结果表明，相较于常规softmax和平面分类器，层次化softmax能够取得更好的分类性能。 |
| [^3] | [Adaptive Collaborative Filtering with Personalized Time Decay Functions for Financial Product Recommendation.](http://arxiv.org/abs/2308.01208) | 本研究提出了一种使用个性化时间衰减函数的自适应协同过滤金融产品推荐系统，以解决传统推荐系统在动态环境下提供可靠推荐的挑战。该方法通过建模客户和产品之间的动态协同信号，处理金融数据的非平稳性，为用户提供可靠的推荐。 |
| [^4] | [LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs.](http://arxiv.org/abs/2308.01157) | LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。 |
| [^5] | [Simulation-based inference using surjective sequential neural likelihood estimation.](http://arxiv.org/abs/2308.01054) | 我们提出了一种使用全射序列神经似然估计（SSNL）进行基于仿真的推断的新方法，在模型中无法计算似然函数并且只能使用模拟器生成数据的情况下，SSNL通过拟合降维的全射归一化流模型，并将其作为替代似然函数，解决了先前基于似然方法在高维数据集中遇到的问题，并在各种实验中展示了其优越性能。 |
| [^6] | [Regular Variation in Hilbert Spaces and Principal Component Analysis for Functional Extremes.](http://arxiv.org/abs/2308.01023) | 本文提出了一个在Hilbert空间中处理正则变化和功能极值的概率统计框架，包括对随机变量正则变化的新型表征和功能主成分分析方法。 |
| [^7] | [Certified Multi-Fidelity Zeroth-Order Optimization.](http://arxiv.org/abs/2308.00978) | 本文研究了认证的多流程零阶优化问题，提出了MFDOO算法的认证变体，并证明了其具有近似最优的代价复杂度。同时，还考虑了有噪声评估的特殊情况。 |
| [^8] | [Causal Inference with Differentially Private (Clustered) Outcomes.](http://arxiv.org/abs/2308.00957) | 本文提出了一种新的差分隐私机制"Cluster-DP"，它在保证隐私的同时利用数据的聚类结构，从而实现了更强的隐私保证和较低的方差，可以用于进行因果分析。 |
| [^9] | [The Bayesian Context Trees State Space Model for time series modelling and forecasting.](http://arxiv.org/abs/2308.00913) | 该论文介绍了基于贝叶斯上下文树状态空间模型的时间序列建模和预测方法，通过层级贝叶斯框架将离散状态和实值时间序列模型组合，构建出灵活且可解释的混合模型，并提出了有效的算法来进行贝叶斯推断和预测。 |
| [^10] | [Differentially Private Distributed Estimation and Learning.](http://arxiv.org/abs/2306.15865) | 本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。 |
| [^11] | [Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box.](http://arxiv.org/abs/2304.05527) | 本文提出了“确定性ADVI”（DADVI），它用一种固定的蒙特卡罗近似替换了均值场变分贝叶斯（MFVB）的不可解目标，可以使用现成的二阶优化，适用于更准确的后验线性响应（LR）协方差估计，在某些常见的统计问题类别上效果更好。 |
| [^12] | [Sparse Signal Detection in Heteroscedastic Gaussian Sequence Models: Sharp Minimax Rates.](http://arxiv.org/abs/2211.08580) | 该论文探究了异方差高斯序列模型中的稀疏信号检测问题，提出了一种最小极大分离半径的上下界以及相应的测试，展示了关于稀疏度、距离衡量和异方差性质的新的相变特性。 |
| [^13] | [Instance-Dependent Generalization Bounds via Optimal Transport.](http://arxiv.org/abs/2211.01258) | 该论文提出了一种基于最优传输的实例相关泛化界限的方法，以解释神经网络泛化的关键因素，并且考虑了初始化和随机梯度下降的强归纳偏差。这种方法在模型参数化不可知且训练样本数量远小于参数数量时表现良好，还可以应用于低维流形上的数据和分布转换情况下的泛化问题。 |
| [^14] | [Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS).](http://arxiv.org/abs/2210.08549) | 该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。 |
| [^15] | [FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels.](http://arxiv.org/abs/2210.04635) | 本论文提出了一种使用具有有限支持的一般参数核进行TPP推理的高效解决方案，该方法采用了离散化方法，并通过多项实验证明了该方法的统计和计算效率。 |
| [^16] | [Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation.](http://arxiv.org/abs/2203.11740) | 该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。 |
| [^17] | [Integrated Conditional Estimation-Optimization.](http://arxiv.org/abs/2110.12351) | 该论文提出了一种综合条件估计-优化（ICEO）框架，可以在考虑优化问题结构的同时估计随机参数的条件分布，并提供了一些性能保证。 |
| [^18] | [Semi-nonparametric Latent Class Choice Model with a Flexible Class Membership Component: A Mixture Model Approach.](http://arxiv.org/abs/2007.02739) | 本论文提出了一种新的半非参数潜在类选择模型，采用混合模型的形式来描述潜在类别，并通过比较不同的指标，发现混合模型在选择过程中具有更好的表现。 |

# 详细

[^1]: 评估深度神经网络测试选择方法的稳定性

    Evaluating the Robustness of Test Selection Methods for Deep Neural Networks. (arXiv:2308.01314v1 [cs.LG])

    [http://arxiv.org/abs/2308.01314](http://arxiv.org/abs/2308.01314)

    本文评估了测试选择方法在深度神经网络测试中的稳定性，通过探讨这些方法的潜在陷阱并进行实证研究，揭示了它们的可靠性问题。

    

    由于对收集的原始数据进行标记所需的时间和劳动力，测试基于深度学习的系统是至关重要的，但也具有挑战性。为了减轻标记工作量，已经提出了多种测试选择方法，只需对测试数据的子集进行标记即可满足测试要求。然而，我们观察到，这些报道有希望的结果的方法只在简单情景下进行评估，例如，在原始测试数据上进行测试。这让我们产生了一个问题：它们总是可靠的吗？本文探讨了测试选择方法在测试中失败的时间和程度。具体而言，首先，我们基于其构建方法，确定了来自顶级会议的11种选择方法的潜在陷阱。其次，我们对五个数据集进行了研究，每个数据集有两个模型架构，以从经验上确认这些陷阱的存在。此外，我们还演示了陷阱如何破坏这些方法的可靠性。具体来说，故障检测方法的缺陷。

    Testing deep learning-based systems is crucial but challenging due to the required time and labor for labeling collected raw data. To alleviate the labeling effort, multiple test selection methods have been proposed where only a subset of test data needs to be labeled while satisfying testing requirements. However, we observe that such methods with reported promising results are only evaluated under simple scenarios, e.g., testing on original test data. This brings a question to us: are they always reliable? In this paper, we explore when and to what extent test selection methods fail for testing. Specifically, first, we identify potential pitfalls of 11 selection methods from top-tier venues based on their construction. Second, we conduct a study on five datasets with two model architectures per dataset to empirically confirm the existence of these pitfalls. Furthermore, we demonstrate how pitfalls can break the reliability of these methods. Concretely, methods for fault detection suf
    
[^2]: 使用层次化softmax的全局层次化神经网络

    Global Hierarchical Neural Networks using Hierarchical Softmax. (arXiv:2308.01210v1 [stat.ML])

    [http://arxiv.org/abs/2308.01210](http://arxiv.org/abs/2308.01210)

    本文提出了一种使用层次化softmax的全局层次化神经网络框架，适用于具有层次结构的分类任务，并且在四个文本分类数据集上的实验结果表明，相较于常规softmax和平面分类器，层次化softmax能够取得更好的分类性能。

    

    本文提出了一个框架，在其中使用层次化softmax来创建一个全局层次化分类器。该方法适用于任何具有自然层次结构的分类任务。我们在四个文本分类数据集上展示了实证结果。在所有数据集中，相对于使用平面分类器的常规softmax，层次化softmax在宏F1和宏召回率方面都有所提升。在四个数据集中的三个数据集中，层次化softmax实现了更高的微准确率和宏精确率。

    This paper presents a framework in which hierarchical softmax is used to create a global hierarchical classifier. The approach is applicable for any classification task where there is a natural hierarchy among classes. We show empirical results on four text classification datasets. In all datasets the hierarchical softmax improved on the regular softmax used in a flat classifier in terms of macro-F1 and macro-recall. In three out of four datasets hierarchical softmax achieved a higher micro-accuracy and macro-precision.
    
[^3]: 个性化时间衰减函数的自适应协同过滤金融产品推荐系统

    Adaptive Collaborative Filtering with Personalized Time Decay Functions for Financial Product Recommendation. (arXiv:2308.01208v1 [cs.IR])

    [http://arxiv.org/abs/2308.01208](http://arxiv.org/abs/2308.01208)

    本研究提出了一种使用个性化时间衰减函数的自适应协同过滤金融产品推荐系统，以解决传统推荐系统在动态环境下提供可靠推荐的挑战。该方法通过建模客户和产品之间的动态协同信号，处理金融数据的非平稳性，为用户提供可靠的推荐。

    

    传统的推荐系统通常假设历史数据是不变的，无法考虑用户偏好的动态性，限制了它们在时间敏感环境中提供可靠推荐的能力。这一假设在金融领域尤其有问题，因为金融产品的估值不断变化，导致客户兴趣频繁转移。这些演变的兴趣可以通过过去客户-产品交互中总结出来，其效用随着时间的推移会因客户而异。为了解决这一挑战，我们提出了一种时间相关的协同过滤算法，可以使用个性化衰减函数自适应地折价远离的客户-产品交互。我们的方法旨在处理金融数据的非平稳性，并通过建模客户和产品之间的动态协同信号来产生可靠的推荐。我们使用专有数据集对我们的方法进行评估。

    Classical recommender systems often assume that historical data are stationary and fail to account for the dynamic nature of user preferences, limiting their ability to provide reliable recommendations in time-sensitive settings. This assumption is particularly problematic in finance, where financial products exhibit continuous changes in valuations, leading to frequent shifts in client interests. These evolving interests, summarized in the past client-product interactions, see their utility fade over time with a degree that might differ from one client to another. To address this challenge, we propose a time-dependent collaborative filtering algorithm that can adaptively discount distant client-product interactions using personalized decay functions. Our approach is designed to handle the non-stationarity of financial data and produce reliable recommendations by modeling the dynamic collaborative signals between clients and products. We evaluate our method using a proprietary dataset 
    
[^4]: LLMs理解玻璃盒模型，发现惊喜并提出修复建议。

    LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs. (arXiv:2308.01157v1 [stat.ML])

    [http://arxiv.org/abs/2308.01157](http://arxiv.org/abs/2308.01157)

    LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。

    

    我们展示了大型语言模型(LLMs)在处理可解释模型方面的出色表现，这些模型可以将复杂结果分解为单一变量的图表示组件。通过采用层次推理的方法，LLMs能够在不需要整个模型适应上下文的情况下提供全面的模型级总结。这种方法使LLMs能够应用其广泛的背景知识来自动完成数据科学中的常见任务，如检测与先前知识相矛盾的异常，描述异常的潜在原因，并提出去除异常的修复建议。我们使用医疗保健领域的多个示例来证明LLMs的这些新能力的实用性，特别强调广义可加模型(GAMs)。最后，我们将$\texttt{TalkToEBM}$包作为一个开源的LLM-GAM接口进行介绍。

    We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
    
[^5]: 使用全射序列神经似然估计进行基于仿真的推断

    Simulation-based inference using surjective sequential neural likelihood estimation. (arXiv:2308.01054v1 [stat.ML])

    [http://arxiv.org/abs/2308.01054](http://arxiv.org/abs/2308.01054)

    我们提出了一种使用全射序列神经似然估计（SSNL）进行基于仿真的推断的新方法，在模型中无法计算似然函数并且只能使用模拟器生成数据的情况下，SSNL通过拟合降维的全射归一化流模型，并将其作为替代似然函数，解决了先前基于似然方法在高维数据集中遇到的问题，并在各种实验中展示了其优越性能。

    

    我们提出了全射序列神经似然（SSNL）估计方法，这是一种在模型中无法计算似然函数并且只能使用可以生成合成数据的模拟器时进行基于仿真的推断的新方法。SSNL拟合一个降维的全射归一化流模型，并将其用作替代似然函数，从而可以使用传统的贝叶斯推断方法，包括马尔科夫链蒙特卡罗方法或变分推断。通过将数据嵌入到低维空间中，SSNL解决了先前基于似然方法在应用于高维数据集时遇到的几个问题，例如包含无信息数据维度或位于较低维流形上的数据。我们对SSNL在各种实验中进行了评估，并表明它通常优于在基于仿真推断中使用的现代方法，例如在一项来自天体物理学的具有挑战性的真实世界例子上对磁场模型的建模。

    We present Surjective Sequential Neural Likelihood (SSNL) estimation, a novel method for simulation-based inference in models where the evaluation of the likelihood function is not tractable and only a simulator that can generate synthetic data is available. SSNL fits a dimensionality-reducing surjective normalizing flow model and uses it as a surrogate likelihood function which allows for conventional Bayesian inference using either Markov chain Monte Carlo methods or variational inference. By embedding the data in a low-dimensional space, SSNL solves several issues previous likelihood-based methods had when applied to high-dimensional data sets that, for instance, contain non-informative data dimensions or lie along a lower-dimensional manifold. We evaluate SSNL on a wide variety of experiments and show that it generally outperforms contemporary methods used in simulation-based inference, for instance, on a challenging real-world example from astrophysics which models the magnetic fi
    
[^6]: Hilbert空间中的正则变化与功能极值的主成分分析

    Regular Variation in Hilbert Spaces and Principal Component Analysis for Functional Extremes. (arXiv:2308.01023v1 [math.ST])

    [http://arxiv.org/abs/2308.01023](http://arxiv.org/abs/2308.01023)

    本文提出了一个在Hilbert空间中处理正则变化和功能极值的概率统计框架，包括对随机变量正则变化的新型表征和功能主成分分析方法。

    

    在功能性数据日益丰富的背景下，我们提出了一个用于$L^2[0,1]$中正则变化随机元素$X$的极值的一般概率统计框架。我们将自己置于一个峰值超过阈值的框架中，其中一个功能极值被定义为$L^2$范数$\|X\|$相对较大的观测值$X$。我们的目标是提出一个降维框架，从而为这种极值观测得到有限维度的投影。我们的贡献是双重的。首先，我们研究了随机数量在一般可分离的Hilbert空间中的正则变化概念，对此我们提出了一个仅涉及实值随机变量的随机收敛的新型具体表征。其次，我们提出了一种功能性主成分分析（PCA）的概念，可以考虑功能极值的主要“方向”。我们研究了经验协方差算子的统计性质。

    Motivated by the increasing availability of data of functional nature, we develop a general probabilistic and statistical framework for extremes of regularly varying random elements $X$ in $L^2[0,1]$. We place ourselves in a Peaks-Over-Threshold framework where a functional extreme is defined as an observation $X$ whose $L^2$-norm $\|X\|$ is comparatively large. Our goal is to propose a dimension reduction framework resulting into finite dimensional projections for such extreme observations. Our contribution is double. First, we investigate the notion of Regular Variation for random quantities valued in a general separable Hilbert space, for which we propose a novel concrete characterization involving solely stochastic convergence of real-valued random variables. Second, we propose a notion of functional Principal Component Analysis (PCA) accounting for the principal `directions' of functional extremes. We investigate the statistical properties of the empirical covariance operator of t
    
[^7]: 认证的多流程零阶优化

    Certified Multi-Fidelity Zeroth-Order Optimization. (arXiv:2308.00978v1 [cs.LG])

    [http://arxiv.org/abs/2308.00978](http://arxiv.org/abs/2308.00978)

    本文研究了认证的多流程零阶优化问题，提出了MFDOO算法的认证变体，并证明了其具有近似最优的代价复杂度。同时，还考虑了有噪声评估的特殊情况。

    

    我们考虑多流程零阶优化的问题，在这个问题中，可以在不同的近似水平（代价不同）上评估函数$f$，目标是以尽可能低的代价优化$f$。在本文中，我们研究了\emph{认证}算法，它们额外要求输出一个对优化误差的数据驱动上界。我们首先以算法和评估环境之间的极小极大博弈形式来形式化问题。然后，我们提出了MFDOO算法的认证变体，并推导出其在任意Lipschitz函数$f$上的代价复杂度上界。我们还证明了一个依赖于$f$的下界，表明该算法具有近似最优的代价复杂度。最后，我们通过直接示例解决了有噪声（随机）评估的特殊情况。

    We consider the problem of multi-fidelity zeroth-order optimization, where one can evaluate a function $f$ at various approximation levels (of varying costs), and the goal is to optimize $f$ with the cheapest evaluations possible. In this paper, we study \emph{certified} algorithms, which are additionally required to output a data-driven upper bound on the optimization error. We first formalize the problem in terms of a min-max game between an algorithm and an evaluation environment. We then propose a certified variant of the MFDOO algorithm and derive a bound on its cost complexity for any Lipschitz function $f$. We also prove an $f$-dependent lower bound showing that this algorithm has a near-optimal cost complexity. We close the paper by addressing the special case of noisy (stochastic) evaluations as a direct example.
    
[^8]: 具有差分隐私(分组)结果的因果推断

    Causal Inference with Differentially Private (Clustered) Outcomes. (arXiv:2308.00957v1 [stat.ML])

    [http://arxiv.org/abs/2308.00957](http://arxiv.org/abs/2308.00957)

    本文提出了一种新的差分隐私机制"Cluster-DP"，它在保证隐私的同时利用数据的聚类结构，从而实现了更强的隐私保证和较低的方差，可以用于进行因果分析。

    

    从随机实验中估计因果效应只有在参与者同意透露他们可能敏感的响应时才可行。在确保隐私的许多方法中，标签差分隐私是一种广泛使用的算法隐私保证度量，可以鼓励参与者分享响应而不会面临去匿名化的风险。许多差分隐私机制会向原始数据集中注入噪音来实现这种隐私保证，这会增加大多数统计估计量的方差，使得精确测量因果效应变得困难：从差分隐私数据进行因果分析存在着固有的隐私-方差权衡。为了实现更强隐私保证的较低方差，我们提出了一种新的差分隐私机制"Cluster-DP"，它利用数据的任何给定的聚类结构，同时仍然允许对因果效应进行估计。

    Estimating causal effects from randomized experiments is only feasible if participants agree to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label differential privacy is a widely used measure of an algorithm's privacy guarantee, which might encourage participants to share responses without running the risk of de-anonymization. Many differentially private mechanisms inject noise into the original data-set to achieve this privacy guarantee, which increases the variance of most statistical estimators and makes the precise measurement of causal effects difficult: there exists a fundamental privacy-variance trade-off to performing causal analyses from differentially private data. With the aim of achieving lower variance for stronger privacy guarantees, we suggest a new differential privacy mechanism, "Cluster-DP", which leverages any given cluster structure of the data while still allowing for the estimation of causal effects. We show that, depending 
    
[^9]: 基于贝叶斯上下文树状态空间模型的时间序列建模和预测

    The Bayesian Context Trees State Space Model for time series modelling and forecasting. (arXiv:2308.00913v1 [stat.ME])

    [http://arxiv.org/abs/2308.00913](http://arxiv.org/abs/2308.00913)

    该论文介绍了基于贝叶斯上下文树状态空间模型的时间序列建模和预测方法，通过层级贝叶斯框架将离散状态和实值时间序列模型组合，构建出灵活且可解释的混合模型，并提出了有效的算法来进行贝叶斯推断和预测。

    

    引入了一个层级贝叶斯框架，用于开发用于真实值时间序列的丰富混合模型，以及一系列有效的学习和推断工具。在顶层，通过适当量化最近样本的一些有意义的离散状态来进行鉴定。这些可观察状态的集合被描述为离散的上下文树模型。然后，在底层，将一个不同的、任意的实值时间序列模型（基本模型）与每个状态相关联。这定义了一个非常通用的框架，可以与任何现有模型类一起使用，构建灵活且可解释的混合模型。我们将其称为贝叶斯上下文树状态空间模型，或者BCT-X框架。引入了高效的算法，可以实现有效的、精确的贝叶斯推断；特别是可以确定最大后验概率（MAP）上下文树模型。这些算法可以顺序更新，以便实现有效的推断和预测。

    A hierarchical Bayesian framework is introduced for developing rich mixture models for real-valued time series, along with a collection of effective tools for learning and inference. At the top level, meaningful discrete states are identified as appropriately quantised values of some of the most recent samples. This collection of observable states is described as a discrete context-tree model. Then, at the bottom level, a different, arbitrary model for real-valued time series - a base model - is associated with each state. This defines a very general framework that can be used in conjunction with any existing model class to build flexible and interpretable mixture models. We call this the Bayesian Context Trees State Space Model, or the BCT-X framework. Efficient algorithms are introduced that allow for effective, exact Bayesian inference; in particular, the maximum a posteriori probability (MAP) context-tree model can be identified. These algorithms can be updated sequentially, facili
    
[^10]: 差分隐私分布式估计和学习

    Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])

    [http://arxiv.org/abs/2306.15865](http://arxiv.org/abs/2306.15865)

    本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。

    

    我们研究了在网络环境中的分布式估计和学习问题，其中代理通过交换信息来估计从其私下观察的样本中未知的统计属性。通过交换私有观测信息，代理可以集体估计未知数量，但他们也面临隐私风险。我们的聚合方案的目标是在时间和网络中高效地组合观测数据，同时满足代理的隐私需求，而不需要任何超越他们本地附近的协调。我们的算法使参与的代理能够从离线或随时间在线获取的私有信号中估计完整的充分统计量，并保护其信号和网络附近的隐私。这是通过线性聚合方案和调整的随机化方案实现的，将噪声添加到交换的估计数据中以满足差分隐私（DP）。

    We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
    
[^11]: 一种使用确定性目标的黑匣子变分推断：更快，更精确，更黑。

    Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box. (arXiv:2304.05527v1 [cs.LG])

    [http://arxiv.org/abs/2304.05527](http://arxiv.org/abs/2304.05527)

    本文提出了“确定性ADVI”（DADVI），它用一种固定的蒙特卡罗近似替换了均值场变分贝叶斯（MFVB）的不可解目标，可以使用现成的二阶优化，适用于更准确的后验线性响应（LR）协方差估计，在某些常见的统计问题类别上效果更好。

    

    自动微分变分推断（ADVI）提供了多种现代概率编程语言中快速易用的后验近似方法。然而它的随机优化器缺乏明确的收敛标准，并且需要调整参数。此外，ADVI继承了均值场变分贝叶斯（MFVB）的较差后验不确定性估计。我们引入了“确定性ADVI”（DADVI）来解决这些问题。DADVI用固定的蒙特卡罗近似替换了MFVB的不可解目标，这一技术在随机优化文献中被称为“样本平均近似”（SAA）。通过优化近似但确定的目标，DADVI可以使用现成的二阶优化，而且与标准均值场ADVI不同的是，可以适用于更准确的后验线性响应（LR）协方差估计。与现有的最坏情况理论相反，我们表明，在某些常见的统计问题类别上，DADVI和SAA可以表现得更好。

    Automatic differentiation variational inference (ADVI) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. However, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. Moreover, ADVI inherits the poor posterior uncertainty estimates of mean-field variational Bayes (MFVB). We introduce ``deterministic ADVI'' (DADVI) to address these issues. DADVI replaces the intractable MFVB objective with a fixed Monte Carlo approximation, a technique known in the stochastic optimization literature as the ``sample average approximation'' (SAA). By optimizing an approximate but deterministic objective, DADVI can use off-the-shelf second-order optimization, and, unlike standard mean-field ADVI, is amenable to more accurate posterior linear response (LR) covariance estimates. In contrast to existing worst-case theory, we show that, on certain classes of common statistical problems, DADVI and the SAA can perform 
    
[^12]: 异方差高斯序列模型中的稀疏信号检测: 尖锐的极小极大速率

    Sparse Signal Detection in Heteroscedastic Gaussian Sequence Models: Sharp Minimax Rates. (arXiv:2211.08580v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2211.08580](http://arxiv.org/abs/2211.08580)

    该论文探究了异方差高斯序列模型中的稀疏信号检测问题，提出了一种最小极大分离半径的上下界以及相应的测试，展示了关于稀疏度、距离衡量和异方差性质的新的相变特性。

    

    在一个具有未知均值 $\theta \in \mathbb R^d$ 和已知协方差矩阵 $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$ 的异质高斯序列模型中，我们研究了针对稀疏备选方案的信号检测问题，对于已知的稀疏度 $s$。也就是说，我们确定了有多大的 $\epsilon^*>0$，以便可以区分出零假设 $\theta=0$ 和由 $\mathbb R^d$ 中 $s$-稀疏向量组成的备选解，它们通过 $L^t$ 范数 ($t \in [1,\infty]$) 与 $0$ 分开至少 $\epsilon^*$ 的概率很高。我们找到了极小极大分离半径 $\epsilon^*$ 的极小极大上下界，并证明它们总是匹配的。我们还推导了相应的极小极大测试来实现这些界。我们的结果揭示了关于 $\epsilon^*$ 行为的新的相变特性，这取决于稀疏程度、$L^t$指标和 $\Sigma$ 的异方差特性。在欧几里得（即 $L^2$）分离的情况下，我们的框架允许我们恢复以前的结果，并确定了相应的最优收敛速率。

    Given a heterogeneous Gaussian sequence model with unknown mean $\theta \in \mathbb R^d$ and known covariance matrix $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$, we study the signal detection problem against sparse alternatives, for known sparsity $s$. Namely, we characterize how large $\epsilon^*>0$ should be, in order to distinguish with high probability the null hypothesis $\theta=0$ from the alternative composed of $s$-sparse vectors in $\mathbb R^d$, separated from $0$ in $L^t$ norm ($t \in [1,\infty]$) by at least $\epsilon^*$. We find minimax upper and lower bounds over the minimax separation radius $\epsilon^*$ and prove that they are always matching. We also derive the corresponding minimax tests achieving these bounds. Our results reveal new phase transitions regarding the behavior of $\epsilon^*$ with respect to the level of sparsity, to the $L^t$ metric, and to the heteroscedasticity profile of $\Sigma$. In the case of the Euclidean (i.e. $L^2$) separation,
    
[^13]: 基于最优传输的实例相关泛化界限

    Instance-Dependent Generalization Bounds via Optimal Transport. (arXiv:2211.01258v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.01258](http://arxiv.org/abs/2211.01258)

    该论文提出了一种基于最优传输的实例相关泛化界限的方法，以解释神经网络泛化的关键因素，并且考虑了初始化和随机梯度下降的强归纳偏差。这种方法在模型参数化不可知且训练样本数量远小于参数数量时表现良好，还可以应用于低维流形上的数据和分布转换情况下的泛化问题。

    

    现有的泛化界限无法解释影响现代神经网络泛化的关键因素。由于这些界限通常对所有参数都是一致的，它们容易过度参数化，并且无法考虑到初始化和随机梯度下降的强归纳偏差。作为替代方案，我们提出了一种新颖的最优传输解释泛化问题的方法。这使我们能够获得依赖于数据空间中预测函数的局部利普希茨正则性的实例相关泛化界限。因此，我们的界限对模型的参数化是不可知的，并且在训练样本数量远小于参数数量时表现良好。通过一些小的修改，我们的方法在低维流形上的数据上可以获得加速的速率，并且在分布转换下具有保证。我们通过对神经网络的实证分析来验证我们的泛化界限，结果显示界限值是

    Existing generalization bounds fail to explain crucial factors that drive generalization of modern neural networks. Since such bounds often hold uniformly over all parameters, they suffer from over-parametrization, and fail to account for the strong inductive bias of initialization and stochastic gradient descent. As an alternative, we propose a novel optimal transport interpretation of the generalization problem. This allows us to derive instance-dependent generalization bounds that depend on the local Lipschitz regularity of the earned prediction function in the data space. Therefore, our bounds are agnostic to the parametrization of the model and work well when the number of training samples is much smaller than the number of parameters. With small modifications, our approach yields accelerated rates for data on low-dimensional manifolds, and guarantees under distribution shifts. We empirically analyze our generalization bounds for neural networks, showing that the bound values are 
    
[^14]: 国际空间站自动紧急无尘解决方案: 带有Bi-GRU的(AED-ISS)

    Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2210.08549](http://arxiv.org/abs/2210.08549)

    该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。

    

    随着对PM2.5或PM0.3问题的关注不断增加，颗粒物不仅对环境和人类构成潜在威胁，而且对国际空间站上的仪器也会产生不利影响。本研究团队旨在将各种颗粒物浓度与磁场、湿度、加速度、温度、压力和CO2浓度关联起来。我们的目标是建立一个早期预警系统(EWS)，能够预测颗粒物水平，并为宇航员提供充足的反应时间，以保护他们在某些实验中的仪器，或者提高测量的准确性；此外，所构建的模型还可以进一步发展为与火灾相关的遥感烟雾报警装置的原型。本文中，我们将实现Bi-GRU(双向门控循环单元)算法，收集过去90分钟的数据，并预测超过2.5微米的颗粒物水平。

    With a rising attention for the issue of PM2.5 or PM0.3, particulate matters have become not only a potential threat to both the environment and human, but also a harming existence to instruments onboard International Space Station (ISS). Our team is aiming to relate various concentration of particulate matters to magnetic fields, humidity, acceleration, temperature, pressure and CO2 concentration. Our goal is to establish an early warning system (EWS), which is able to forecast the levels of particulate matters and provides ample reaction time for astronauts to protect their instruments in some experiments or increase the accuracy of the measurements; In addition, the constructed model can be further developed into a prototype of a remote-sensing smoke alarm for applications related to fires. In this article, we will implement the Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for past 90 minutes and predict the levels of particulates which over 2.5 micromete
    
[^15]: FaDIn: 针对具有一般参数核的Hawkes过程的快速离散化推断

    FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels. (arXiv:2210.04635v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.04635](http://arxiv.org/abs/2210.04635)

    本论文提出了一种使用具有有限支持的一般参数核进行TPP推理的高效解决方案，该方法采用了离散化方法，并通过多项实验证明了该方法的统计和计算效率。

    

    时间点过程是建模事件数据的自然工具。在所有的时间点过程模型中，Hawkes过程被证明是最广泛使用的，主要是由于它们对于各种应用的适当建模，特别是在考虑指数或非参数核时。尽管非参数核是一种选择，但这些模型需要大型数据集。而指数核更具数据效率，对于立即触发更多事件的特定应用更有效，但对于需要估计延迟的应用（如神经科学），它们不太适用。本研究旨在提供一种使用具有有限支持的一般参数核进行TPP推理的高效解决方案。所开发的解决方案包括利用事件的离散化的快速$\ell_2$梯度求解器。在理论上支持离散化的使用后，通过多种实验，证明了该新方法的统计和计算效率。

    Temporal point processes (TPP) are a natural tool for modeling event-based data. Among all TPP models, Hawkes processes have proven to be the most widely used, mainly due to their adequate modeling for various applications, particularly when considering exponential or non-parametric kernels. Although non-parametric kernels are an option, such models require large datasets. While exponential kernels are more data efficient and relevant for specific applications where events immediately trigger more events, they are ill-suited for applications where latencies need to be estimated, such as in neuroscience. This work aims to offer an efficient solution to TPP inference using general parametric kernels with finite support. The developed solution consists of a fast $\ell_2$ gradient-based solver leveraging a discretized version of the events. After theoretically supporting the use of discretization, the statistical and computational efficiency of the novel approach is demonstrated through va
    
[^16]: 基于星形细胞对关键期的神经可塑性神经网络，通过现有和记忆性的大脑可塑性和突触形成实现突触竞争和强度平衡。（arXiv: 2203.11740v12 [cs.NE] UPDATED）

    Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2203.11740](http://arxiv.org/abs/2203.11740)

    该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。

    

    除了突触共享连接权重之外，PNN还包括突触有效范围的权重[14-25]。PNN考虑突触强度平衡在突触吞噬的动态和长度常数之和的静态中[14]，并包含了鱼群行为的先导行为。突触形成在实验和模拟中会抑制树突生成[15]。类似于Spring Boot中的强制韧性，反向回路的记忆持久度梯度也存在。相对较好和较差的梯度信息存储在类似于脑褶的记忆痕迹细胞中，在反向回路的突触形成中。争议认为人类海马神经元的再生能力是否持续到老年，并可能在后期迭代中形成新的更长的回路[17,18]。关闭关键期会导致神经紊乱在实验和模拟中[19]。考虑到负面和正面记忆的持久性，有助于更好地激活突触。

    In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
    
[^17]: 综合条件估计-优化

    Integrated Conditional Estimation-Optimization. (arXiv:2110.12351v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2110.12351](http://arxiv.org/abs/2110.12351)

    该论文提出了一种综合条件估计-优化（ICEO）框架，可以在考虑优化问题结构的同时估计随机参数的条件分布，并提供了一些性能保证。

    

    许多实际优化问题涉及具有概率分布的不确定参数，可以使用上下文特征信息进行估计。与先估计不确定参数的分布然后基于估计优化目标的标准方法相反，我们提出了一种综合条件估计-优化（ICEO）框架，该框架在考虑优化问题结构的同时估计随机参数的条件分布。我们直接建模随机参数的条件分布与上下文特征之间的关系，然后用与下游优化问题一致的目标估计概率模型。我们证明了我们的ICEO方法在适度规则条件下是渐进一致的，并进一步提供了一些推广界限形式的有限性能保证。计算上，使用

    Many real-world optimization problems involve uncertain parameters with probability distributions that can be estimated using contextual feature information. In contrast to the standard approach of first estimating the distribution of uncertain parameters and then optimizing the objective based on the estimation, we propose an integrated conditional estimation-optimization (ICEO) framework that estimates the underlying conditional distribution of the random parameter while considering the structure of the optimization problem. We directly model the relationship between the conditional distribution of the random parameter and the contextual features, and then estimate the probabilistic model with an objective that aligns with the downstream optimization problem. We show that our ICEO approach is asymptotically consistent under moderate regularity conditions and further provide finite performance guarantees in the form of generalization bounds. Computationally, performing estimation with
    
[^18]: 半非参数潜在类选择模型与灵活的类成员组件：混合模型方法

    Semi-nonparametric Latent Class Choice Model with a Flexible Class Membership Component: A Mixture Model Approach. (arXiv:2007.02739v1 [econ.EM] CROSS LISTED)

    [http://arxiv.org/abs/2007.02739](http://arxiv.org/abs/2007.02739)

    本论文提出了一种新的半非参数潜在类选择模型，采用混合模型的形式来描述潜在类别，并通过比较不同的指标，发现混合模型在选择过程中具有更好的表现。

    

    本研究提出了一种具有灵活类成员组件的半非参数潜在类选择模型(LCCM)。该模型利用混合模型来描述潜在的类别，作为传统随机效用模型的替代方法，旨在比较这两种方法在预测准确性和选择过程中异质性表示等多个指标上的表现。混合模型是一种基于参数的模型聚类技术，在机器学习、数据挖掘和模式识别等领域广泛应用于聚类和分类问题。我们推导出了一种基于期望最大化(EM)算法的估计方法用于该模型。通过两个不同的出行方式选择行为的案例研究，将该模型与传统离散选择模型进行了比较，分析参数估计的符号、时间价值、统计拟合度量和交叉验证测试等指标。结果表明，混合模型在多个指标上相比传统选择模型具有更好的表现。

    This study presents a semi-nonparametric Latent Class Choice Model (LCCM) with a flexible class membership component. The proposed model formulates the latent classes using mixture models as an alternative approach to the traditional random utility specification with the aim of comparing the two approaches on various measures including prediction accuracy and representation of heterogeneity in the choice process. Mixture models are parametric model-based clustering techniques that have been widely used in areas such as machine learning, data mining and patter recognition for clustering and classification problems. An Expectation-Maximization (EM) algorithm is derived for the estimation of the proposed model. Using two different case studies on travel mode choice behavior, the proposed model is compared to traditional discrete choice models on the basis of parameter estimates' signs, value of time, statistical goodness-of-fit measures, and cross-validation tests. Results show that mixtu
    

