<rss version="2.0"><channel><title>Chat Arxiv cs.NE</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.NE</description><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#33258;&#21160;&#35774;&#35745;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#24418;&#24335;&#21270;&#12289;&#26041;&#27861;&#35770;&#12289;&#25361;&#25112;&#21644;&#30740;&#31350;&#36235;&#21183;&#65292;&#35752;&#35770;&#20102;&#33258;&#21160;&#35774;&#35745;&#30340;&#28508;&#22312;&#26410;&#26469;&#26041;&#21521;&#21644;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.06532</link><description>&lt;p&gt;
&#33258;&#21160;&#35774;&#35745;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Automated Design of Metaheuristic Algorithms. (arXiv:2303.06532v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#33258;&#21160;&#35774;&#35745;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#24418;&#24335;&#21270;&#12289;&#26041;&#27861;&#35770;&#12289;&#25361;&#25112;&#21644;&#30740;&#31350;&#36235;&#21183;&#65292;&#35752;&#35770;&#20102;&#33258;&#21160;&#35774;&#35745;&#30340;&#28508;&#22312;&#26410;&#26469;&#26041;&#21521;&#21644;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a broad picture of the formalization, methodologies, challenges, and research trends of automated design of metaheuristic algorithms, and discusses the potential future directions and open issues in this field.
&lt;/p&gt;
&lt;p&gt;
&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#30001;&#20110;&#20854;&#33021;&#22815;&#29420;&#31435;&#20110;&#38382;&#39064;&#32467;&#26500;&#21644;&#38382;&#39064;&#39046;&#22495;&#36827;&#34892;&#25628;&#32034;&#30340;&#33021;&#21147;&#65292;&#24050;&#32463;&#24341;&#36215;&#20102;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#36890;&#24120;&#65292;&#38656;&#35201;&#20154;&#31867;&#19987;&#23478;&#25163;&#21160;&#35843;&#25972;&#31639;&#27861;&#20197;&#36866;&#24212;&#35299;&#20915;&#30446;&#26631;&#38382;&#39064;&#12290;&#25163;&#21160;&#35843;&#25972;&#36807;&#31243;&#21487;&#33021;&#26159;&#36153;&#21147;&#30340;&#12289;&#23481;&#26131;&#20986;&#38169;&#30340;&#65292;&#24182;&#19988;&#38656;&#35201;&#22823;&#37327;&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;&#36825;&#24341;&#36215;&#20102;&#23545;&#33258;&#21160;&#35774;&#35745;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#36234;&#26469;&#36234;&#22810;&#30340;&#20852;&#36259;&#21644;&#38656;&#27714;&#65292;&#20197;&#20943;&#23569;&#20154;&#31867;&#24178;&#39044;&#12290;&#33258;&#21160;&#35774;&#35745;&#21487;&#20197;&#20351;&#39640;&#24615;&#33021;&#31639;&#27861;&#23545;&#26356;&#24191;&#27867;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#21487;&#29992;&#65307;&#36890;&#36807;&#21033;&#29992;&#35745;&#31639;&#33021;&#21147;&#26469;&#20805;&#20998;&#25506;&#32034;&#28508;&#22312;&#30340;&#35774;&#35745;&#36873;&#25321;&#65292;&#33258;&#21160;&#35774;&#35745;&#21487;&#20197;&#36798;&#21040;&#29978;&#33267;&#36229;&#36807;&#20154;&#31867;&#27700;&#24179;&#30340;&#35774;&#35745;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#29616;&#26377;&#24037;&#20316;&#30340;&#20849;&#21516;&#28857;&#21644;&#24046;&#24322;&#36827;&#34892;&#35843;&#26597;&#65292;&#25552;&#20986;&#20102;&#33258;&#21160;&#35774;&#35745;&#20803;&#21551;&#21457;&#24335;&#31639;&#27861;&#30340;&#24418;&#24335;&#21270;&#12289;&#26041;&#27861;&#35770;&#12289;&#25361;&#25112;&#21644;&#30740;&#31350;&#36235;&#21183;&#30340;&#24191;&#27867;&#27010;&#36848;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#28508;&#22312;&#26410;&#26469;&#26041;&#21521;&#21644;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Metaheuristic algorithms have attracted wide attention from academia and industry due to their capability of conducting search independent of problem structures and problem domains. Often, human experts are requested to manually tailor algorithms to fit for solving a targeted problem. The manual tailoring process may be laborious, error-prone, and require intensive specialized knowledge. This gives rise to increasing interests and demands for automated design of metaheuristic algorithms with less human intervention. The automated design could make high-performance algorithms accessible to a much broader range of researchers and practitioners; and by leveraging computing power to fully explore the potential design choices, automated design could reach or even surpass human-level design. This paper presents a broad picture of the formalization, methodologies, challenges, and research trends of automated design of metaheuristic algorithms, by conducting a survey on the common grounds and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;&#31070;&#32463;&#20803;&#30340;&#21442;&#25968;&#25928;&#29575;&#65292;&#35777;&#26126;&#20102;&#20854;&#21331;&#36234;&#24615;&#33021;&#26159;&#30001;&#20110;&#20869;&#22312;&#34920;&#36798;&#33021;&#21147;&#32780;&#38750;&#21442;&#25968;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2303.06316</link><description>&lt;p&gt;
&#19968;&#20010;&#31070;&#32463;&#20803;&#30340;&#33410;&#30465;&#23601;&#26159;&#19968;&#20010;&#31070;&#32463;&#20803;&#30340;&#25910;&#30410;&#65306;&#20851;&#20110;&#20108;&#27425;&#32593;&#32476;&#21442;&#25968;&#25928;&#29575;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
One Neuron Saved Is One Neuron Earned: On Parametric Efficiency of Quadratic Networks. (arXiv:2303.06316v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06316
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;&#31070;&#32463;&#20803;&#30340;&#21442;&#25968;&#25928;&#29575;&#65292;&#35777;&#26126;&#20102;&#20854;&#21331;&#36234;&#24615;&#33021;&#26159;&#30001;&#20110;&#20869;&#22312;&#34920;&#36798;&#33021;&#21147;&#32780;&#38750;&#21442;&#25968;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the parametric efficiency of quadratic neurons and confirms that their superior performance is due to intrinsic expressive capability rather than increased parameters.
&lt;/p&gt;
&lt;p&gt;
&#21463;&#29983;&#29289;&#31070;&#32463;&#31995;&#32479;&#20013;&#31070;&#32463;&#20803;&#22810;&#26679;&#24615;&#30340;&#21551;&#21457;&#65292;&#22823;&#37327;&#30740;&#31350;&#25552;&#20986;&#20102;&#35774;&#35745;&#26032;&#22411;&#20154;&#24037;&#31070;&#32463;&#20803;&#24182;&#23558;&#31070;&#32463;&#20803;&#22810;&#26679;&#24615;&#24341;&#20837;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#26368;&#36817;&#25552;&#20986;&#30340;&#20108;&#27425;&#31070;&#32463;&#20803;&#65292;&#23558;&#20256;&#32479;&#31070;&#32463;&#20803;&#20013;&#30340;&#20869;&#31215;&#25805;&#20316;&#26367;&#25442;&#20026;&#20108;&#27425;&#25805;&#20316;&#65292;&#22312;&#35768;&#22810;&#37325;&#35201;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#23613;&#31649;&#20108;&#27425;&#31070;&#32463;&#20803;&#30340;&#32467;&#26524;&#24456;&#26377;&#21069;&#36884;&#65292;&#20294;&#20173;&#23384;&#22312;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#65306;&#20108;&#27425;&#32593;&#32476;&#30340;&#21331;&#36234;&#24615;&#33021;&#20165;&#20165;&#26159;&#30001;&#20110;&#21442;&#25968;&#22686;&#21152;&#36824;&#26159;&#30001;&#20110;&#20869;&#22312;&#34920;&#36798;&#33021;&#21147;&#65311;&#22312;&#26410;&#28548;&#28165;&#36825;&#20010;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#65292;&#20108;&#27425;&#32593;&#32476;&#30340;&#24615;&#33021;&#24635;&#26159;&#20196;&#20154;&#24576;&#30097;&#12290;&#27492;&#22806;&#65292;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#23601;&#26159;&#25214;&#21040;&#20108;&#27425;&#32593;&#32476;&#30340;&#26432;&#25163;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20108;&#27425;&#32593;&#32476;&#20855;&#26377;&#21442;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#30830;&#35748;&#20102;&#20108;&#27425;&#32593;&#32476;&#30340;&#21331;&#36234;&#24615;&#33021;&#26159;&#30001;&#20110;&#20854;&#20869;&#22312;&#34920;&#36798;&#33021;&#21147;&#32780;&#38750;&#21442;&#25968;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inspired by neuronal diversity in the biological neural system, a plethora of studies proposed to design novel types of artificial neurons and introduce neuronal diversity into artificial neural networks. Recently proposed quadratic neuron, which replaces the inner-product operation in conventional neurons with a quadratic one, have achieved great success in many essential tasks. Despite the promising results of quadratic neurons, there is still an unresolved issue: \textit{Is the superior performance of quadratic networks simply due to the increased parameters or due to the intrinsic expressive capability?} Without clarifying this issue, the performance of quadratic networks is always suspicious. Additionally, resolving this issue is reduced to finding killer applications of quadratic networks. In this paper, with theoretical and empirical studies, we show that quadratic networks enjoy parametric efficiency, thereby confirming that the superior performance of quadratic networks is due
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24191;&#20041;&#28436;&#21592;-&#35780;&#35770;&#23478;QD-RL&#26694;&#26550;&#65292;&#29992;&#20110;QD-RL&#35774;&#32622;&#20013;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#28145;&#24230;RL&#26041;&#27861;&#12290;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;&#65292;PGA-ME&#65288;SAC&#65289;&#21644;PGA-ME&#65288;DroQ&#65289;&#65292;&#23558;&#28145;&#24230;RL&#30340;&#26368;&#26032;&#36827;&#23637;&#24212;&#29992;&#20110;QD-RL&#35774;&#32622;&#65292;&#24182;&#35299;&#20915;&#20102;&#29616;&#26377;QD-RL&#31639;&#27861;&#26080;&#27861;&#35299;&#20915;&#30340;&#20154;&#24418;&#29615;&#22659;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.06164</link><description>&lt;p&gt;
&#29702;&#35299;&#36136;&#37327;&#22810;&#26679;&#24615;&#21644;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Understanding the Synergies between Quality-Diversity and Deep Reinforcement Learning. (arXiv:2303.06164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24191;&#20041;&#28436;&#21592;-&#35780;&#35770;&#23478;QD-RL&#26694;&#26550;&#65292;&#29992;&#20110;QD-RL&#35774;&#32622;&#20013;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#28145;&#24230;RL&#26041;&#27861;&#12290;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;&#65292;PGA-ME&#65288;SAC&#65289;&#21644;PGA-ME&#65288;DroQ&#65289;&#65292;&#23558;&#28145;&#24230;RL&#30340;&#26368;&#26032;&#36827;&#23637;&#24212;&#29992;&#20110;QD-RL&#35774;&#32622;&#65292;&#24182;&#35299;&#20915;&#20102;&#29616;&#26377;QD-RL&#31639;&#27861;&#26080;&#27861;&#35299;&#20915;&#30340;&#20154;&#24418;&#29615;&#22659;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a Generalized Actor-Critic QD-RL framework for actor-critic deep RL methods in the QD-RL setting. The framework introduces two new algorithms, PGA-ME (SAC) and PGA-ME (DroQ), which apply recent advancements in Deep RL to the QD-RL setting and solve the humanoid environment problem that existing QD-RL algorithms cannot solve.
&lt;/p&gt;
&lt;p&gt;
&#36136;&#37327;&#22810;&#26679;&#24615;&#65288;QD&#65289;&#21644;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;&#24050;&#32463;&#23548;&#33268;&#20102;&#24378;&#22823;&#30340;&#28151;&#21512;QD-RL&#31639;&#27861;&#65292;&#23637;&#31034;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#24182;&#24102;&#26469;&#20102;&#20004;&#20010;&#39046;&#22495;&#30340;&#26368;&#20339;&#23454;&#36341;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20854;&#20182;RL&#31639;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#22312;&#20808;&#21069;&#30340;&#28151;&#21512;&#26041;&#27861;&#20013;&#20165;&#20351;&#29992;&#20102;&#21333;&#20010;&#28145;&#24230;RL&#31639;&#27861;&#65288;TD3&#65289;&#12290;&#27492;&#22806;&#65292;QD&#21644;RL&#20043;&#38388;&#30340;&#20248;&#21270;&#36807;&#31243;&#23384;&#22312;&#26681;&#26412;&#24046;&#24322;&#65292;&#38656;&#35201;&#26356;&#21152;&#21407;&#21017;&#24615;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24191;&#20041;&#28436;&#21592;-&#35780;&#35770;&#23478;QD-RL&#65292;&#36825;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;QD-RL&#35774;&#32622;&#20013;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#28145;&#24230;RL&#26041;&#27861;&#12290;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#26465;&#30740;&#31350;&#28145;&#24230;RL&#22312;QD-RL&#35774;&#32622;&#20013;&#30340;&#35265;&#35299;&#30340;&#36335;&#24452;&#65292;&#36825;&#26159;&#22312;QD-RL&#20013;&#21462;&#24471;&#36827;&#23637;&#30340;&#37325;&#35201;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;&#65292;PGA-ME&#65288;SAC&#65289;&#21644;PGA-ME&#65288;DroQ&#65289;&#65292;&#23558;&#28145;&#24230;RL&#30340;&#26368;&#26032;&#36827;&#23637;&#24212;&#29992;&#20110;QD-RL&#35774;&#32622;&#65292;&#24182;&#35299;&#20915;&#20102;&#29616;&#26377;QD-RL&#31639;&#27861;&#26080;&#27861;&#35299;&#20915;&#30340;&#20154;&#24418;&#29615;&#22659;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The synergies between Quality-Diversity (QD) and Deep Reinforcement Learning (RL) have led to powerful hybrid QD-RL algorithms that have shown tremendous potential, and brings the best of both fields. However, only a single deep RL algorithm (TD3) has been used in prior hybrid methods despite notable progress made by other RL algorithms. Additionally, there are fundamental differences in the optimization procedures between QD and RL which would benefit from a more principled approach. We propose Generalized Actor-Critic QD-RL, a unified modular framework for actor-critic deep RL methods in the QD-RL setting. This framework provides a path to study insights from Deep RL in the QD-RL setting, which is an important and efficient way to make progress in QD-RL. We introduce two new algorithms, PGA-ME (SAC) and PGA-ME (DroQ) which apply recent advancements in Deep RL to the QD-RL setting, and solves the humanoid environment which was not possible using existing QD-RL algorithms. However, we 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#31070;&#32463;&#20803;&#22810;&#26679;&#24615;&#21487;&#20197;&#35299;&#20915;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#36208;&#21521;&#31070;&#32463;&#20154;&#24037;&#26234;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.09245</link><description>&lt;p&gt;
&#36208;&#21521;&#31070;&#32463;&#20154;&#24037;&#26234;&#33021;&#65306;&#23558;&#31070;&#32463;&#20803;&#22810;&#26679;&#24615;&#24341;&#20837;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks. (arXiv:2301.09245v2 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09245
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#31070;&#32463;&#20803;&#22810;&#26679;&#24615;&#21487;&#20197;&#35299;&#20915;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#36208;&#21521;&#31070;&#32463;&#20154;&#24037;&#26234;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Introducing neuronal diversity can solve the fundamental problems of artificial neural networks and lead to NeuroAI.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#25972;&#20010;&#21382;&#21490;&#19978;&#65292;&#20154;&#24037;&#26234;&#33021;&#30340;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65292;&#19968;&#30452;&#23545;&#36234;&#26469;&#36234;&#28145;&#20837;&#30340;&#22823;&#33041;&#29702;&#35299;&#25345;&#24320;&#25918;&#24577;&#24230;&#24182;&#19981;&#26029;&#21463;&#21040;&#21551;&#21457;&#65292;&#20363;&#22914;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;neocognitron&#30340;&#21551;&#21457;&#12290;&#26681;&#25454;&#26032;&#20852;&#39046;&#22495;&#31070;&#32463;&#20154;&#24037;&#26234;&#33021;&#30340;&#21160;&#26426;&#65292;&#22823;&#37327;&#30340;&#31070;&#32463;&#31185;&#23398;&#30693;&#35782;&#21487;&#20197;&#36890;&#36807;&#36171;&#20104;&#32593;&#32476;&#26356;&#24378;&#22823;&#30340;&#33021;&#21147;&#26469;&#20652;&#21270;&#19979;&#19968;&#20195;&#20154;&#24037;&#26234;&#33021;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#30693;&#36947;&#65292;&#20154;&#31867;&#22823;&#33041;&#26377;&#35768;&#22810;&#24418;&#24577;&#21644;&#21151;&#33021;&#19981;&#21516;&#30340;&#31070;&#32463;&#20803;&#65292;&#32780;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20960;&#20046;&#23436;&#20840;&#24314;&#31435;&#22312;&#21333;&#19968;&#31070;&#32463;&#20803;&#31867;&#22411;&#19978;&#12290;&#22312;&#20154;&#31867;&#22823;&#33041;&#20013;&#65292;&#31070;&#32463;&#20803;&#22810;&#26679;&#24615;&#26159;&#21508;&#31181;&#29983;&#29289;&#26234;&#33021;&#34892;&#20026;&#30340;&#19968;&#20010;&#21551;&#21160;&#22240;&#32032;&#12290;&#30001;&#20110;&#20154;&#24037;&#32593;&#32476;&#26159;&#20154;&#31867;&#22823;&#33041;&#30340;&#32553;&#24433;&#65292;&#24341;&#20837;&#31070;&#32463;&#20803;&#22810;&#26679;&#24615;&#24212;&#35813;&#26377;&#21161;&#20110;&#35299;&#20915;&#20154;&#24037;&#32593;&#32476;&#30340;&#35832;&#22914;&#25928;&#29575;&#12289;&#35299;&#37322;&#24615;&#31561;&#22522;&#26412;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpret
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#26694;&#26550;&#65292;&#21487;&#20197;&#20197;&#23481;&#38169;&#30340;&#26041;&#24335;&#23384;&#20648;&#21644;&#26816;&#32034;&#22823;&#37327;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#25512;&#26029;&#32570;&#22833;&#30340;&#27169;&#24577;&#12290;</title><link>http://arxiv.org/abs/2207.04827</link><description>&lt;p&gt;
&#22522;&#20110;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20998;&#31867;&#21644;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Classification and Generation of real-world data with an Associative Memory Model. (arXiv:2207.04827v3 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04827
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#26694;&#26550;&#65292;&#21487;&#20197;&#20197;&#23481;&#38169;&#30340;&#26041;&#24335;&#23384;&#20648;&#21644;&#26816;&#32034;&#22823;&#37327;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#25512;&#26029;&#32570;&#22833;&#30340;&#27169;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a multi-modality framework based on the associative memory model, which can store and retrieve a large amount of real-world data in a fault-tolerant manner, and can be used to infer missing modalities.
&lt;/p&gt;
&lt;p&gt;
&#22238;&#24518;&#36215;&#22810;&#24180;&#26410;&#35265;&#30340;&#26379;&#21451;&#30340;&#38754;&#23380;&#26159;&#19968;&#39033;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#20320;&#20204;&#20598;&#28982;&#30456;&#36935;&#65292;&#20320;&#20204;&#20250;&#36731;&#26131;&#22320;&#35748;&#20986;&#24444;&#27492;&#12290;&#29983;&#29289;&#35760;&#24518;&#37197;&#22791;&#20102;&#19968;&#20010;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#21387;&#32553;&#31639;&#27861;&#65292;&#21487;&#20197;&#23384;&#20648;&#24517;&#35201;&#30340;&#20449;&#24687;&#65292;&#28982;&#21518;&#25512;&#26029;&#32454;&#33410;&#20197;&#21305;&#37197;&#24863;&#30693;&#12290;Willshaw Memory&#26159;&#19968;&#31181;&#29992;&#20110;&#30382;&#23618;&#35745;&#31639;&#30340;&#31616;&#21333;&#25277;&#35937;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#29983;&#29289;&#35760;&#24518;&#30340;&#26426;&#21046;&#12290;&#20351;&#29992;&#25105;&#20204;&#26368;&#36817;&#25552;&#20986;&#30340;&#29992;&#20110;&#35270;&#35273;&#27169;&#24335;&#30340;&#31232;&#30095;&#32534;&#30721;&#35268;&#21017;[34]&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20197;&#23481;&#38169;&#30340;&#26041;&#24335;&#23384;&#20648;&#21644;&#26816;&#32034;&#22823;&#37327;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22810;&#27169;&#24577;&#26694;&#26550;&#25193;&#23637;&#20102;&#22522;&#26412;&#32852;&#24819;&#35760;&#24518;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#35760;&#24518;&#21516;&#26102;&#23384;&#20648;&#27599;&#20010;&#27169;&#24335;&#30340;&#20960;&#31181;&#27169;&#24577;&#65288;&#20363;&#22914;&#65292;&#35270;&#35273;&#25110;&#25991;&#26412;&#65289;&#12290;&#35757;&#32451;&#21518;&#65292;&#24403;&#21482;&#24863;&#30693;&#21040;&#23376;&#38598;&#26102;&#65292;&#35760;&#24518;&#21487;&#20197;&#29992;&#20110;&#25512;&#26029;&#32570;&#22833;&#30340;&#27169;&#24577;&#12290;&#20351;&#29992;&#31616;&#21333;&#30340;&#32534;&#30721;&#22120;-&#35760;&#24518;&#35299;&#30721;&#22120;&#65292;&#25105;&#20204;&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#22810;&#20010;&#27169;&#24577;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Drawing from memory the face of a friend you have not seen in years is a difficult task. However, if you happen to cross paths, you would easily recognize each other. The biological memory is equipped with an impressive compression algorithm that can store the essential, and then infer the details to match perception. The Willshaw Memory is a simple abstract model for cortical computations which implements mechanisms of biological memories. Using our recently proposed sparse coding prescription for visual patterns [34], this model can store and retrieve an impressive amount of real-world data in a fault-tolerant manner. In this paper, we extend the capabilities of the basic Associative Memory Model by using a Multiple-Modality framework. In this setting, the memory stores several modalities (e.g., visual, or textual) of each pattern simultaneously. After training, the memory can be used to infer missing modalities when just a subset is perceived. Using a simple encoder-memory decoder a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#32508;&#36848;&#20102;&#20108;&#36827;&#21046;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;1&#20301;&#28608;&#27963;&#21644;1&#20301;&#21367;&#31215;&#32593;&#32476;&#30340;&#26435;&#37325;&#65292;&#36825;&#20123;&#32593;&#32476;&#21487;&#20197;&#22312;&#24494;&#23567;&#30340;&#21463;&#38480;&#35774;&#22791;&#19978;&#23454;&#29616;&#21644;&#23884;&#20837;&#65292;&#24182;&#33410;&#30465;&#22823;&#37327;&#23384;&#20648;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#33021;&#37327;&#28040;&#32791;&#12290;</title><link>http://arxiv.org/abs/2110.06804</link><description>&lt;p&gt;
&#20108;&#36827;&#21046;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#38754;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A comprehensive review of Binary Neural Network. (arXiv:2110.06804v4 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.06804
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#32508;&#36848;&#20102;&#20108;&#36827;&#21046;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;1&#20301;&#28608;&#27963;&#21644;1&#20301;&#21367;&#31215;&#32593;&#32476;&#30340;&#26435;&#37325;&#65292;&#36825;&#20123;&#32593;&#32476;&#21487;&#20197;&#22312;&#24494;&#23567;&#30340;&#21463;&#38480;&#35774;&#22791;&#19978;&#23454;&#29616;&#21644;&#23884;&#20837;&#65292;&#24182;&#33410;&#30465;&#22823;&#37327;&#23384;&#20648;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#33021;&#37327;&#28040;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article provides a comprehensive overview of recent developments in Binary Neural Networks (BNN), with a focus on 1-bit activations and 1-bit convolution networks. These networks can be implemented and embedded on tiny restricted devices, saving significant storage, computation cost, and energy consumption.
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#26368;&#36817;&#25913;&#21464;&#20102;&#26234;&#33021;&#31995;&#32479;&#30340;&#21457;&#23637;&#65292;&#24182;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#12290;&#23613;&#31649;DL&#20855;&#26377;&#21508;&#31181;&#22909;&#22788;&#21644;&#28508;&#21147;&#65292;&#20294;&#22312;&#19981;&#21516;&#30340;&#35745;&#31639;&#21463;&#38480;&#21644;&#33021;&#37327;&#21463;&#38480;&#35774;&#22791;&#20013;&#38656;&#35201;&#36827;&#34892;DL&#22788;&#29702;&#12290;&#30740;&#31350;&#20108;&#36827;&#21046;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#31561;&#20855;&#26377;&#25913;&#21464;&#28216;&#25103;&#35268;&#21017;&#30340;&#25216;&#26415;&#20197;&#22686;&#21152;&#28145;&#24230;&#23398;&#20064;&#33021;&#21147;&#26159;&#24456;&#33258;&#28982;&#30340;&#12290;&#26368;&#36817;&#22312;BNN&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#30528;&#36827;&#23637;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#22312;&#24494;&#23567;&#30340;&#21463;&#38480;&#35774;&#22791;&#19978;&#23454;&#29616;&#21644;&#23884;&#20837;&#65292;&#24182;&#33410;&#30465;&#22823;&#37327;&#23384;&#20648;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#33021;&#37327;&#28040;&#32791;&#12290;&#28982;&#32780;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;BNN&#34892;&#20026;&#37117;&#20250;&#24102;&#26469;&#39069;&#22806;&#30340;&#20869;&#23384;&#12289;&#35745;&#31639;&#25104;&#26412;&#21644;&#26356;&#39640;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;BNN&#26368;&#36817;&#21457;&#23637;&#30340;&#23436;&#25972;&#27010;&#36848;&#12290;&#26412;&#25991;&#19987;&#38376;&#20851;&#27880;1&#20301;&#28608;&#27963;&#21644;1&#20301;&#21367;&#31215;&#32593;&#32476;&#30340;&#26435;&#37325;&#65292;&#19982;&#20197;&#21069;&#30340;&#35843;&#26597;&#28151;&#21512;&#20351;&#29992;&#20302;&#20301;&#20316;&#21697;&#30456;&#21453;&#12290;&#23427;&#23545;BNN&#30340;&#24320;&#21457;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning (DL) has recently changed the development of intelligent systems and is widely adopted in many real-life applications. Despite their various benefits and potentials, there is a high demand for DL processing in different computationally limited and energy-constrained devices. It is natural to study game-changing technologies such as Binary Neural Networks (BNN) to increase deep learning capabilities. Recently remarkable progress has been made in BNN since they can be implemented and embedded on tiny restricted devices and save a significant amount of storage, computation cost, and energy consumption. However, nearly all BNN acts trade with extra memory, computation cost, and higher performance. This article provides a complete overview of recent developments in BNN. This article focuses exclusively on 1-bit activations and weights 1-bit convolution networks, contrary to previous surveys in which low-bit works are mixed in. It conducted a complete investigation of BNN's dev
&lt;/p&gt;</description></item></channel></rss>