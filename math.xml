<rss version="2.0"><channel><title>Chat Arxiv math</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for math</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2303.06526</link><description>&lt;p&gt;
&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Data Dependent Regret Guarantees Against General Comparators for Full or Bandit Feedback. (arXiv:2303.06526v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06526
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a data-dependent online learning algorithm framework that has data-dependent regret guarantees in both full expert feedback and bandit feedback settings, applicable for a wide variety of problem scenarios.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#23436;&#20840;&#22312;&#32447;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#20855;&#26377;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#19968;&#33324;&#27604;&#36739;&#22120;&#30340;&#39044;&#26399;&#24615;&#33021;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20174;&#36890;&#29992;&#39044;&#27979;&#35282;&#24230;&#24037;&#20316;&#65292;&#20351;&#29992;&#30340;&#24615;&#33021;&#24230;&#37327;&#26159;&#23545;&#20219;&#24847;&#27604;&#36739;&#22120;&#24207;&#21015;&#30340;&#39044;&#26399;&#36951;&#25022;&#65292;&#21363;&#25105;&#20204;&#30340;&#25439;&#22833;&#19982;&#31454;&#20105;&#25439;&#22833;&#24207;&#21015;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#31454;&#20105;&#31867;&#21487;&#20197;&#35774;&#35745;&#20026;&#21253;&#25324;&#22266;&#23450;&#33218;&#36873;&#25321;&#12289;&#20999;&#25442;Bandit&#12289;&#19978;&#19979;&#25991;Bandit&#12289;&#21608;&#26399;Bandit&#25110;&#20219;&#20309;&#20854;&#20182;&#24863;&#20852;&#36259;&#30340;&#31454;&#20105;&#12290;&#31454;&#20105;&#31867;&#20013;&#30340;&#24207;&#21015;&#36890;&#24120;&#30001;&#20855;&#20307;&#24212;&#29992;&#31243;&#24207;&#30830;&#23450;&#65292;&#24182;&#24212;&#30456;&#24212;&#22320;&#35774;&#35745;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26082;&#19981;&#20351;&#29992;&#20063;&#19981;&#38656;&#35201;&#20219;&#20309;&#26377;&#20851;&#25439;&#22833;&#24207;&#21015;&#30340;&#21021;&#27493;&#20449;&#24687;&#65292;&#23436;&#20840;&#22312;&#32447;&#12290;&#20854;
&lt;/p&gt;
&lt;p&gt;
We study the adversarial online learning problem and create a completely online algorithmic framework that has data dependent regret guarantees in both full expert feedback and bandit feedback settings. We study the expected performance of our algorithm against general comparators, which makes it applicable for a wide variety of problem scenarios. Our algorithm works from a universal prediction perspective and the performance measure used is the expected regret against arbitrary comparator sequences, which is the difference between our losses and a competing loss sequence. The competition class can be designed to include fixed arm selections, switching bandits, contextual bandits, periodic bandits or any other competition of interest. The sequences in the competition class are generally determined by the specific application at hand and should be designed accordingly. Our algorithm neither uses nor needs any preliminary information about the loss sequences and is completely online. Its
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#32500;&#35774;&#32622;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#35268;&#27169;&#36739;&#22823;&#26102;&#20173;&#28982;&#21487;&#34892;&#12290;</title><link>http://arxiv.org/abs/2303.06515</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multistage Stochastic Optimization via Kernels. (arXiv:2303.06515v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06515
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#32500;&#35774;&#32622;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#35268;&#27169;&#36739;&#22823;&#26102;&#20173;&#28982;&#21487;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#12289;&#25968;&#25454;&#39537;&#21160;&#12289;&#21487;&#34892;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#20915;&#31574;&#19981;&#24433;&#21709;&#19981;&#30830;&#23450;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558;&#20915;&#31574;&#21464;&#37327;&#34920;&#31034;&#20026;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#20803;&#32032;&#65292;&#24182;&#25191;&#34892;&#20989;&#25968;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#32463;&#39564;&#27491;&#21017;&#21270;&#25439;&#22833;&#12290;&#36890;&#36807;&#32467;&#21512;&#22522;&#20110;&#20989;&#25968;&#23376;&#31354;&#38388;&#25237;&#24433;&#30340;&#31232;&#30095;&#21270;&#25216;&#26415;&#65292;&#25105;&#20204;&#33021;&#22815;&#20811;&#26381;&#26631;&#20934;&#26680;&#26041;&#27861;&#24341;&#20837;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#38543;&#30528;&#25968;&#25454;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20855;&#26377;&#36741;&#21161;&#20449;&#24687;&#30340;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;&#20013;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#12290;&#22312;&#21508;&#31181;&#38543;&#26426;&#24211;&#23384;&#31649;&#29702;&#38382;&#39064;&#30340;&#35745;&#31639;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#32500;&#35774;&#32622;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#35268;&#27169;&#36739;&#22823;&#26102;&#20173;&#28982;&#21487;&#34892;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#35745;&#31639;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#30340;&#26368;&#20248;&#25439;&#22833;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a non-parametric, data-driven, tractable approach for solving multistage stochastic optimization problems in which decisions do not affect the uncertainty. The proposed framework represents the decision variables as elements of a reproducing kernel Hilbert space and performs functional stochastic gradient descent to minimize the empirical regularized loss. By incorporating sparsification techniques based on function subspace projections we are able to overcome the computational complexity that standard kernel methods introduce as the data size increases. We prove that the proposed approach is asymptotically optimal for multistage stochastic optimization with side information. Across various computational experiments on stochastic inventory management problems, {our method performs well in multidimensional settings} and remains tractable when the data size is large. Lastly, by computing lower bounds for the optimal loss of the inventory control problem, we show that the propo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;MIMO-NOMA IoT&#31995;&#32479;&#21151;&#29575;&#20998;&#37197;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;AoI&#21644;&#33021;&#32791;&#12290;</title><link>http://arxiv.org/abs/2303.06411</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;MIMO-NOMA IoT&#31995;&#32479;&#21151;&#29575;&#20998;&#37197;&#65292;&#20197;&#26368;&#23567;&#21270;AoI&#21644;&#33021;&#32791;
&lt;/p&gt;
&lt;p&gt;
Deep Reinforcement Learning Based Power Allocation for Minimizing AoI and Energy Consumption in MIMO-NOMA IoT Systems. (arXiv:2303.06411v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06411
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;MIMO-NOMA IoT&#31995;&#32479;&#21151;&#29575;&#20998;&#37197;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;AoI&#21644;&#33021;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a deep reinforcement learning based power allocation method for MIMO-NOMA IoT systems to minimize AoI and energy consumption.
&lt;/p&gt;
&lt;p&gt;
&#22810;&#36755;&#20837;&#22810;&#36755;&#20986;&#21644;&#38750;&#27491;&#20132;&#22810;&#22336;&#65288;MIMO-NOMA&#65289;&#29289;&#32852;&#32593;&#65288;IoT&#65289;&#31995;&#32479;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20449;&#36947;&#23481;&#37327;&#21644;&#39057;&#35889;&#25928;&#29575;&#65292;&#20197;&#25903;&#25345;&#23454;&#26102;&#24212;&#29992;&#12290;&#26102;&#24310;&#65288;AoI&#65289;&#26159;&#23454;&#26102;&#24212;&#29992;&#30340;&#37325;&#35201;&#25351;&#26631;&#65292;&#20294;&#27809;&#26377;&#25991;&#29486;&#26368;&#23567;&#21270;MIMO-NOMA IoT&#31995;&#32479;&#30340;AoI&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#36827;&#34892;&#36825;&#39033;&#24037;&#20316;&#12290;&#22312;MIMO-NOMA IoT&#31995;&#32479;&#20013;&#65292;&#22522;&#31449;&#65288;BS&#65289;&#30830;&#23450;&#26679;&#26412;&#25910;&#38598;&#35201;&#27714;&#24182;&#20026;&#27599;&#20010;IoT&#35774;&#22791;&#20998;&#37197;&#20256;&#36755;&#21151;&#29575;&#12290;&#27599;&#20010;&#35774;&#22791;&#26681;&#25454;&#26679;&#26412;&#25910;&#38598;&#35201;&#27714;&#30830;&#23450;&#26159;&#21542;&#37319;&#26679;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#20998;&#37197;&#30340;&#21151;&#29575;&#23558;&#37319;&#26679;&#30340;&#25968;&#25454;&#36890;&#36807;MIMO-NOMA&#20449;&#36947;&#20256;&#36755;&#21040;BS&#12290;&#28982;&#21518;&#65292;BS&#37319;&#29992;&#36830;&#32493;&#24178;&#25200;&#28040;&#38500;&#65288;SIC&#65289;&#25216;&#26415;&#35299;&#30721;&#27599;&#20010;&#35774;&#22791;&#20256;&#36755;&#30340;&#25968;&#25454;&#20449;&#21495;&#12290;&#26679;&#26412;&#25910;&#38598;&#35201;&#27714;&#21644;&#21151;&#29575;&#20998;&#37197;&#23558;&#24433;&#21709;&#31995;&#32479;&#30340;AoI&#21644;&#33021;&#32791;&#12290;&#36825;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-input multi-out and non-orthogonal multiple access (MIMO-NOMA) internet-of-things (IoT) systems can improve channel capacity and spectrum efficiency distinctly to support the real-time applications. Age of information (AoI) is an important metric for real-time application, but there is no literature have minimized AoI of the MIMO-NOMA IoT system, which motivates us to conduct this work. In MIMO-NOMA IoT system, the base station (BS) determines the sample collection requirements and allocates the transmission power for each IoT device. Each device determines whether to sample data according to the sample collection requirements and adopts the allocated power to transmit the sampled data to the BS over MIMO-NOMA channel. Afterwards, the BS employs successive interference cancelation (SIC) technique to decode the signal of the data transmitted by each device. The sample collection requirements and power allocation would affect AoI and energy consumption of the system. It is critical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#31070;&#32463;&#27169;&#22411;&#65292;&#29992;&#20110;&#35774;&#35745;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#65288;ISAC&#65289;&#31995;&#32479;&#30340;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#65292;&#20197;&#26368;&#22823;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#30446;&#26631;&#29031;&#26126;&#21151;&#29575;&#65292;&#21516;&#26102;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#26368;&#23567;&#20449;&#24178;&#22122;&#27604;&#65288;SINR&#65289;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23384;&#22312;&#20449;&#36947;&#20272;&#35745;&#35823;&#24046;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20135;&#29983;&#36739;&#23567;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#20449;&#36947;&#26465;&#20214;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.06381</link><description>&lt;p&gt;
&#23398;&#20064;&#39044;&#32534;&#30721;&#29992;&#20110;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning to Precode for Integrated Sensing and Communications Systems. (arXiv:2303.06381v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#31070;&#32463;&#27169;&#22411;&#65292;&#29992;&#20110;&#35774;&#35745;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#65288;ISAC&#65289;&#31995;&#32479;&#30340;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#65292;&#20197;&#26368;&#22823;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#30446;&#26631;&#29031;&#26126;&#21151;&#29575;&#65292;&#21516;&#26102;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#26368;&#23567;&#20449;&#24178;&#22122;&#27604;&#65288;SINR&#65289;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23384;&#22312;&#20449;&#36947;&#20272;&#35745;&#35823;&#24046;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20135;&#29983;&#36739;&#23567;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#20449;&#36947;&#26465;&#20214;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an unsupervised learning neural model to design transmit precoders for integrated sensing and communication (ISAC) systems to maximize the worst-case target illumination power while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for all the users. The proposed method outperforms traditional optimization-based methods in presence of channel estimation errors while incurring lesser computational complexity and generalizing well across different channel conditions that were not shown during training.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#31070;&#32463;&#27169;&#22411;&#65292;&#29992;&#20110;&#35774;&#35745;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#65288;ISAC&#65289;&#31995;&#32479;&#30340;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#65292;&#20197;&#26368;&#22823;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#30446;&#26631;&#29031;&#26126;&#21151;&#29575;&#65292;&#21516;&#26102;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#26368;&#23567;&#20449;&#24178;&#22122;&#27604;&#65288;SINR&#65289;&#12290;&#20174;&#19978;&#34892;&#23548;&#39057;&#21644;&#22238;&#27874;&#20013;&#23398;&#20064;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#30340;&#38382;&#39064;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#20010;&#21442;&#25968;&#21270;&#20989;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26469;&#23398;&#20064;&#36825;&#20010;&#20989;&#25968;&#12290;&#20026;&#20102;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#32435;&#20837;SINR&#21644;&#21151;&#29575;&#32422;&#26463;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#23384;&#22312;&#20449;&#36947;&#20272;&#35745;&#35823;&#24046;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20135;&#29983;&#36739;&#23567;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#20449;&#36947;&#26465;&#20214;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36825;&#20123;&#26465;&#20214;&#22312;&#35757;&#32451;&#26399;&#38388;&#27809;&#26377;&#26174;&#31034;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present an unsupervised learning neural model to design transmit precoders for integrated sensing and communication (ISAC) systems to maximize the worst-case target illumination power while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for all the users. The problem of learning transmit precoders from uplink pilots and echoes can be viewed as a parameterized function estimation problem and we propose to learn this function using a neural network model. To learn the neural network parameters, we develop a novel loss function based on the first-order optimality conditions to incorporate the SINR and power constraints. Through numerical simulations, we demonstrate that the proposed method outperforms traditional optimization-based methods in presence of channel estimation errors while incurring lesser computational complexity and generalizing well across different channel conditions that were not shown during training.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#26041;&#26696;&#65292;&#36890;&#36807;&#20849;&#21516;&#35757;&#32451;&#36866;&#24212;&#29615;&#22659;&#21464;&#21270;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;&#23450;&#20301;&#31934;&#24230;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.06361</link><description>&lt;p&gt;
&#38754;&#21521;&#38750;&#38745;&#24577;&#29615;&#22659;&#30340;&#38544;&#31169;&#20445;&#25252;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#65306;&#32852;&#37030;&#23398;&#20064;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Cooperative Visible Light Positioning for Nonstationary Environment: A Federated Learning Perspective. (arXiv:2303.06361v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#26041;&#26696;&#65292;&#36890;&#36807;&#20849;&#21516;&#35757;&#32451;&#36866;&#24212;&#29615;&#22659;&#21464;&#21270;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;&#23450;&#20301;&#31934;&#24230;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a cooperative visible light positioning scheme based on federated learning, which improves the positioning accuracy and generalization capability in nonstationary environments by jointly training a global model adaptive to environmental changes without sharing private data of users.
&lt;/p&gt;
&lt;p&gt;
&#21487;&#35265;&#20809;&#23450;&#20301;&#65288;VLP&#65289;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#23460;&#20869;&#23450;&#20301;&#25216;&#26415;&#65292;&#24050;&#32463;&#24341;&#36215;&#20102;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#65292;&#30001;&#20110;&#39640;&#24230;&#26102;&#21464;&#30340;&#20449;&#36947;&#65292;VLP&#30340;&#24615;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20102;&#25552;&#39640;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;&#23450;&#20301;&#31934;&#24230;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#21512;&#20316;VLP&#26041;&#26696;&#12290;&#21033;&#29992;FL&#26694;&#26550;&#65292;&#29992;&#25143;&#21487;&#20197;&#20849;&#21516;&#35757;&#32451;&#36866;&#24212;&#29615;&#22659;&#21464;&#21270;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#32780;&#19981;&#20849;&#20139;&#29992;&#25143;&#30340;&#31169;&#26377;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#32593;&#32476;&#65288;CVPosNet&#65289;&#65292;&#20197;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#21644;&#25552;&#39640;&#23450;&#20301;&#31934;&#24230;&#12290;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#20248;&#20110;&#22522;&#20934;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Visible light positioning (VLP) has drawn plenty of attention as a promising indoor positioning technique. However, in nonstationary environments, the performance of VLP is limited because of the highly time-varying channels. To improve the positioning accuracy and generalization capability in nonstationary environments, a cooperative VLP scheme based on federated learning (FL) is proposed in this paper. Exploiting the FL framework, a global model adaptive to environmental changes can be jointly trained by users without sharing private data of users. Moreover, a Cooperative Visible-light Positioning Network (CVPosNet) is proposed to accelerate the convergence rate and improve the positioning accuracy. Simulation results show that the proposed scheme outperforms the benchmark schemes, especially in nonstationary environments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#21306;&#20195;&#25968;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#23618;&#36755;&#20986;&#21644;&#26799;&#24230;&#30340;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2303.06208</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#21306;&#20195;&#25968;&#24555;&#36895;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#23618;
&lt;/p&gt;
&lt;p&gt;
Fast computation of permutation equivariant layers with the partition algebra. (arXiv:2303.06208v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#21306;&#20195;&#25968;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#23618;&#36755;&#20986;&#21644;&#26799;&#24230;&#30340;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new algorithm for computing the output and gradient of permutation equivariant linear layers using the partition algebra, which can be computed in time linear and quadratic in the input size, respectively. The effectiveness of the approach is demonstrated on several benchmark datasets.
&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#23618;&#65292;&#26080;&#35770;&#26159;&#31561;&#21464;&#36824;&#26159;&#19981;&#21464;&#20110;&#20854;&#36755;&#20837;&#30340;&#25490;&#21015;&#65292;&#37117;&#26159;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#26680;&#24515;&#26500;&#24314;&#22359;&#12290;&#20363;&#22914;DeepSets&#30340;&#23618;&#65292;&#20197;&#21450;&#20986;&#29616;&#22312;transformers&#21644;&#19968;&#20123;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27880;&#24847;&#21147;&#22359;&#20013;&#30340;&#32447;&#24615;&#23618;&#12290;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#31354;&#38388;&#21487;&#20197;&#34987;&#35782;&#21035;&#20026;&#26576;&#20010;&#23545;&#31216;&#32676;&#34920;&#31034;&#30340;&#19981;&#21464;&#23376;&#31354;&#38388;&#65292;&#24182;&#19988;&#26368;&#36817;&#30340;&#24037;&#20316;&#36890;&#36807;&#23637;&#31034;&#19968;&#32452;&#22522;&#30784;&#65292;&#20854;&#21521;&#37327;&#26159;&#26631;&#20934;&#22522;&#30784;&#20803;&#32032;&#22312;&#23545;&#31216;&#32676;&#20316;&#29992;&#19979;&#36712;&#36947;&#30340;&#24635;&#21644;&#65292;&#26469;&#21442;&#25968;&#21270;&#36825;&#20010;&#31354;&#38388;&#12290;&#21442;&#25968;&#21270;&#25171;&#24320;&#20102;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#26435;&#37325;&#30340;&#21487;&#33021;&#24615;&#12290;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#31354;&#38388;&#26159;&#20998;&#21306;&#20195;&#25968;&#30340;&#19968;&#33324;&#21270;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#39318;&#27425;&#21457;&#29616;&#30340;&#23545;&#35937;&#65292;&#19982;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#35770;&#26377;&#30528;&#28145;&#21051;&#30340;&#32852;&#31995;&#65292;&#32780;&#19978;&#36848;&#22522;&#30784;&#19982;&#20998;&#21306;&#20195;&#25968;&#30340;&#22522;&#30784;&#23494;&#20999;&#30456;&#20851;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#32852;&#31995;&#65292;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#26102;&#38388;&#20869;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#36755;&#20986;&#65292;&#24182;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#25439;&#22833;&#30456;&#23545;&#20110;&#26435;&#37325;&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#35745;&#31639;&#20998;&#21306;&#20195;&#25968;&#22312;&#21521;&#37327;&#19978;&#20316;&#29992;&#30340;&#26032;&#31639;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#20998;&#21306;&#21367;&#31215;&#8221;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20998;&#21306;&#21367;&#31215;&#21487;&#20197;&#22312;&#36755;&#20837;&#21521;&#37327;&#22823;&#23567;&#30340;&#32447;&#24615;&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#22312;&#36755;&#20837;&#22823;&#23567;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#26102;&#38388;&#20869;&#35745;&#31639;&#32622;&#25442;&#31561;&#21464;&#32447;&#24615;&#23618;&#30340;&#36755;&#20986;&#21644;&#26799;&#24230;&#65292;&#20998;&#21035;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#20998;&#21306;&#21367;&#31215;&#26469;&#35745;&#31639;&#26576;&#20123;&#38750;&#32447;&#24615;&#32622;&#25442;&#31561;&#21464;&#23618;&#30340;&#36755;&#20986;&#21644;&#26799;&#24230;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear neural network layers that are either equivariant or invariant to permutations of their inputs form core building blocks of modern deep learning architectures. Examples include the layers of DeepSets, as well as linear layers occurring in attention blocks of transformers and some graph neural networks. The space of permutation equivariant linear layers can be identified as the invariant subspace of a certain symmetric group representation, and recent work parameterized this space by exhibiting a basis whose vectors are sums over orbits of standard basis elements with respect to the symmetric group action. A parameterization opens up the possibility of learning the weights of permutation equivariant linear layers via gradient descent. The space of permutation equivariant linear layers is a generalization of the partition algebra, an object first discovered in statistical physics with deep connections to the representation theory of the symmetric group, and the basis described abo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.06198</link><description>&lt;p&gt;
&#20811;&#26381;&#24322;&#26041;&#24046;PCA&#20013;&#30149;&#24577;&#38382;&#39064;&#30340;&#32553;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA. (arXiv:2303.06198v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel algorithm, called Deflated-HeteroPCA, that overcomes the curse of ill-conditioning in heteroskedastic PCA while achieving near-optimal and condition-number-free theoretical guarantees.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#20174;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;X*&#30340;&#21015;&#23376;&#31354;&#38388;&#12290;&#24403;&#23384;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#21644;&#19981;&#24179;&#34913;&#30340;&#32500;&#24230;&#65288;&#21363;n2 &gt;&gt; n1&#65289;&#26102;&#65292;&#22914;&#20309;&#22312;&#23481;&#32435;&#26368;&#24191;&#27867;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#30340;&#21516;&#26102;&#33719;&#24471;&#26368;&#20339;&#30340;&#32479;&#35745;&#31934;&#24230;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;HeteroPCA&#25104;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24378;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#36973;&#21463;&#20102;&#8220;&#30149;&#24577;&#38382;&#39064;&#30340;&#35781;&#21650;&#8221;&#65292;&#21363;&#38543;&#30528;X*&#30340;&#26465;&#20214;&#25968;&#22686;&#38271;&#65292;&#20854;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#32780;&#19981;&#24433;&#21709;&#20801;&#35768;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;$\ell_2$&#21644;$\ell_{2,\infty}$&#32479;&#35745;&#31934;&#24230;&#26041;&#38754;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23558;&#35889;&#20998;&#25104;&#20004;&#37096;&#20998;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;K. Pluto&#21644;D. Tasche&#25552;&#20986;&#30340;&#36829;&#32422;&#27010;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#35814;&#32454;&#21015;&#20986;&#20102;&#20551;&#35774;&#21644;&#25512;&#23548;&#65292;&#20026;&#26089;&#26399;&#32844;&#19994;&#20998;&#26512;&#24072;&#25110;&#23398;&#32773;&#25552;&#20379;&#26356;&#22810;&#30340;&#28165;&#26224;&#24230;&#65292;&#29305;&#21035;&#26159;&#20851;&#20110;&#20511;&#27454;&#20154;&#29420;&#31435;&#24615;&#12289;&#26465;&#20214;&#29420;&#31435;&#24615;&#21644;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#22914;&#20108;&#39033;&#24335;&#12289;&#36125;&#22612;&#12289;&#27491;&#24577;&#20998;&#24067;&#31561;&#30340;&#20551;&#35774;&#12290;&#21516;&#26102;&#65292;&#36824;&#23637;&#31034;&#20102;&#36829;&#32422;&#27010;&#29575;&#19982;$\sqrt{\varrho}X-\sqrt{1-\varrho}Y$&#30340;&#32852;&#21512;&#20998;&#24067;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.06148</link><description>&lt;p&gt;
&#20302;&#36829;&#32422;&#32452;&#21512;&#30340;&#36829;&#32422;&#27010;&#29575;&#30340;&#27010;&#29575;&#35770;&#27010;&#36848;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Overview of Probabilities of Default for Low Default Portfolios by K. Pluto and D. Tasche. (arXiv:2303.06148v1 [q-fin.RM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06148
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;K. Pluto&#21644;D. Tasche&#25552;&#20986;&#30340;&#36829;&#32422;&#27010;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#35814;&#32454;&#21015;&#20986;&#20102;&#20551;&#35774;&#21644;&#25512;&#23548;&#65292;&#20026;&#26089;&#26399;&#32844;&#19994;&#20998;&#26512;&#24072;&#25110;&#23398;&#32773;&#25552;&#20379;&#26356;&#22810;&#30340;&#28165;&#26224;&#24230;&#65292;&#29305;&#21035;&#26159;&#20851;&#20110;&#20511;&#27454;&#20154;&#29420;&#31435;&#24615;&#12289;&#26465;&#20214;&#29420;&#31435;&#24615;&#21644;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#22914;&#20108;&#39033;&#24335;&#12289;&#36125;&#22612;&#12289;&#27491;&#24577;&#20998;&#24067;&#31561;&#30340;&#20551;&#35774;&#12290;&#21516;&#26102;&#65292;&#36824;&#23637;&#31034;&#20102;&#36829;&#32422;&#27010;&#29575;&#19982;$\sqrt{\varrho}X-\sqrt{1-\varrho}Y$&#30340;&#32852;&#21512;&#20998;&#24067;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article provides a probabilistic overview of the default probability estimation method proposed by K. Pluto and D. Tasche, including detailed assumptions and derivations. It aims to clarify the assumptions of borrower independence, conditional independence, and interaction between probability distributions such as binomial, beta, and normal for early career analysts or scholars. Additionally, it shows the relationship between the probability of default and the joint distribution of $\sqrt{\varrho}X-\sqrt{1-\varrho}Y$, where $X$ is the standard normal and $Y$ is the beta-normal distribution.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;K. Pluto&#21644;D. Tasche&#25552;&#20986;&#30340;&#36829;&#32422;&#27010;&#29575;&#20272;&#35745;&#26041;&#27861;&#36827;&#34892;&#20102;&#27010;&#29575;&#35770;&#27010;&#36848;&#12290;&#21015;&#20986;&#20102;&#20851;&#20110;&#31995;&#32479;&#22240;&#32032;&#24433;&#21709;&#19979;&#28041;&#21450;&#36829;&#32422;&#27010;&#29575;&#30340;&#19981;&#31561;&#24335;&#30340;&#35814;&#32454;&#20551;&#35774;&#21644;&#25512;&#23548;&#12290;&#20316;&#32773;&#39044;&#35745;&#20026;&#26089;&#26399;&#32844;&#19994;&#20998;&#26512;&#24072;&#25110;&#23398;&#32773;&#25552;&#20379;&#26356;&#22810;&#30340;&#28165;&#26224;&#24230;&#65292;&#29305;&#21035;&#26159;&#20851;&#20110;&#20511;&#27454;&#20154;&#29420;&#31435;&#24615;&#12289;&#26465;&#20214;&#29420;&#31435;&#24615;&#21644;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#22914;&#20108;&#39033;&#24335;&#12289;&#36125;&#22612;&#12289;&#27491;&#24577;&#20998;&#24067;&#31561;&#30340;&#20551;&#35774;&#12290;&#36824;&#23637;&#31034;&#20102;&#36829;&#32422;&#27010;&#29575;&#19982;$\sqrt{\varrho}X-\sqrt{1-\varrho}Y$&#30340;&#32852;&#21512;&#20998;&#24067;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20854;&#20013;$X$&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#65292;$Y$&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#36125;&#22612;-&#27491;&#24577;&#20998;&#24067;&#65292;$X,\,Y$&#26159;&#29420;&#31435;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article gives a probabilistic overview of the widely used method of default probability estimation proposed by K. Pluto and D. Tasche. There are listed detailed assumptions and derivation of the inequality where the probability of default is involved under the influence of systematic factor. The author anticipates adding more clarity, especially for early career analysts or scholars, regarding the assumption of borrowers' independence, conditional independence and interaction between the probability distributions such as binomial, beta, normal and others. There is also shown the relation between the probability of default and the joint distribution of $\sqrt{\varrho}X-\sqrt{1-\varrho}Y$, where $X$, including but not limiting, is the standard normal, $Y$ admits, including but not limiting, the beta-normal distribution and $X,\,Y$ are independent.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22686;&#24378;&#30340;&#22522;&#20110;&#21160;&#37327;&#30340;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#26041;&#27861;&#65288;&#21363;MSGDA&#21644;AdaMSGDA&#65289;&#26469;&#35299;&#20915;&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#20013;AdaMSGDA&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#26469;&#26356;&#26032;&#21464;&#37327;$x$&#21644;$y$&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20840;&#23616;&#21644;&#22352;&#26631;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MSGDA&#21644;AdaMSGDA&#26041;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#31283;&#23450;&#35299;&#26102;&#65292;&#21482;&#38656;&#35201;&#22312;&#27599;&#20010;&#24490;&#29615;&#20013;&#36827;&#34892;&#19968;&#27425;&#37319;&#26679;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#24050;&#30693;&#30340;&#26368;&#20339;&#26679;&#26412;&#65288;&#26799;&#24230;&#65289;&#22797;&#26434;&#24230;$O(\epsilon^{-3})$&#12290;</title><link>http://arxiv.org/abs/2303.03984</link><description>&lt;p&gt;
&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#30340;&#22686;&#24378;&#33258;&#36866;&#24212;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Enhanced Adaptive Gradient Algorithms for Nonconvex-PL Minimax Optimization. (arXiv:2303.03984v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22686;&#24378;&#30340;&#22522;&#20110;&#21160;&#37327;&#30340;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#26041;&#27861;&#65288;&#21363;MSGDA&#21644;AdaMSGDA&#65289;&#26469;&#35299;&#20915;&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#20013;AdaMSGDA&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#26469;&#26356;&#26032;&#21464;&#37327;$x$&#21644;$y$&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20840;&#23616;&#21644;&#22352;&#26631;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MSGDA&#21644;AdaMSGDA&#26041;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#31283;&#23450;&#35299;&#26102;&#65292;&#21482;&#38656;&#35201;&#22312;&#27599;&#20010;&#24490;&#29615;&#20013;&#36827;&#34892;&#19968;&#27425;&#37319;&#26679;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#24050;&#30693;&#30340;&#26368;&#20339;&#26679;&#26412;&#65288;&#26799;&#24230;&#65289;&#22797;&#26434;&#24230;$O(\epsilon^{-3})$&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a class of enhanced momentum-based gradient descent ascent methods (MSGDA and AdaMSGDA) to solve nonconvex-PL minimax problems, where the AdaMSGDA algorithm can use various adaptive learning rates to update variables x and y without relying on any global and coordinate-wise adaptive learning rates. Theoretical analysis shows that MSGDA and AdaMSGDA methods have the best known sample (gradient) complexity of O(&#949;&#8722;3) in finding an &#949;-stationary solution.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#38750;&#20984;&#38750;&#20985;&#30340;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#65288;&#21363;$\min_x\max_y f(x,y)$&#65289;&#65292;&#20854;&#20013;$f(x,y)$&#22312;$x$&#19978;&#21487;&#33021;&#26159;&#38750;&#20984;&#30340;&#65292;&#22312;$y$&#19978;&#26159;&#38750;&#20985;&#30340;&#65292;&#24182;&#28385;&#36275;Polyak-Lojasiewicz&#65288;PL&#65289;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#22686;&#24378;&#30340;&#22522;&#20110;&#21160;&#37327;&#30340;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#26041;&#27861;&#65288;&#21363;MSGDA&#21644;AdaMSGDA&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38543;&#26426;&#38750;&#20984;-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;AdaMSGDA&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#26469;&#26356;&#26032;&#21464;&#37327;$x$&#21644;$y$&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#20840;&#23616;&#21644;&#22352;&#26631;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#25910;&#25947;&#20998;&#26512;&#26694;&#26550;&#26469;&#35299;&#20915;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MSGDA&#21644;AdaMSGDA&#26041;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#31283;&#23450;&#35299;&#65288;&#21363;$\mathbb{E}\|\nabla F(x)\|\leq \epsilon$&#65292;&#20854;&#20013;$F(x)=\max_y f(x,y)$&#65289;&#26102;&#65292;&#21482;&#38656;&#35201;&#22312;&#27599;&#20010;&#24490;&#29615;&#20013;&#36827;&#34892;&#19968;&#27425;&#37319;&#26679;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#24050;&#30693;&#30340;&#26368;&#20339;&#26679;&#26412;&#65288;&#26799;&#24230;&#65289;&#22797;&#26434;&#24230;$O(\epsilon^{-3})$&#12290;
&lt;/p&gt;
&lt;p&gt;
In the paper, we study a class of nonconvex nonconcave minimax optimization problems (i.e., $\min_x\max_y f(x,y)$), where $f(x,y)$ is possible nonconvex in $x$, and it is nonconcave and satisfies the Polyak-Lojasiewicz (PL) condition in $y$. Moreover, we propose a class of enhanced momentum-based gradient descent ascent methods (i.e., MSGDA and AdaMSGDA) to solve these stochastic Nonconvex-PL minimax problems. In particular, our AdaMSGDA algorithm can use various adaptive learning rates in updating the variables $x$ and $y$ without relying on any global and coordinate-wise adaptive learning rates. Theoretically, we present an effective convergence analysis framework for our methods. Specifically, we prove that our MSGDA and AdaMSGDA methods have the best known sample (gradient) complexity of $O(\epsilon^{-3})$ only requiring one sample at each loop in finding an $\epsilon$-stationary solution (i.e., $\mathbb{E}\|\nabla F(x)\|\leq \epsilon$, where $F(x)=\max_y f(x,y)$). This manuscript 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2302.05185</link><description>&lt;p&gt;
&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Penalty-based Bilevel Gradient Descent Method. (arXiv:2302.05185v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a penalty-based bilevel gradient descent algorithm to solve the constrained bilevel problem without lower-level strong convexity, and experiments show its efficiency.
&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#26159;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#38590;&#20197;&#35299;&#20915;&#12290;&#26368;&#36817;&#30340;&#21487;&#25193;&#23637;&#21452;&#23618;&#31639;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#19979;&#23618;&#30446;&#26631;&#20989;&#25968;&#26159;&#24378;&#20984;&#25110;&#26080;&#32422;&#26463;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24809;&#32602;&#26041;&#27861;&#26469;&#35299;&#20915;&#21452;&#23618;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#24809;&#32602;&#37325;&#26500;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#21452;&#23618;&#38382;&#39064;&#30340;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#65288;PBGD&#65289;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#19978;&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#24615;&#12290;&#23454;&#39564;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;PBGD&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization enjoys a wide range of applications in hyper-parameter optimization, meta-learning and reinforcement learning. However, bilevel optimization problems are difficult to solve. Recent progress on scalable bilevel algorithms mainly focuses on bilevel optimization problems where the lower-level objective is either strongly convex or unconstrained. In this work, we tackle the bilevel problem through the lens of the penalty method. We show that under certain conditions, the penalty reformulation recovers the solutions of the original bilevel problem. Further, we propose the penalty-based bilevel gradient descent (PBGD) algorithm and establish its finite-time convergence for the constrained bilevel problem without lower-level strong convexity. Experiments showcase the efficiency of the proposed PBGD algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;Black-Scholes PDE&#30340;&#39640;&#32500;&#26399;&#26435;&#23450;&#20215;&#65292;&#20854;&#22797;&#26434;&#24230;&#34987;&#22810;&#39033;&#24335;&#22320;&#38480;&#21046;&#65292;&#20811;&#26381;&#20102;&#32500;&#24230;&#35781;&#21650;&#12290;</title><link>http://arxiv.org/abs/2301.09241</link><description>&lt;p&gt;
&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#22312;&#37329;&#34701;&#20013;&#39640;&#32500;&#26399;&#26435;&#23450;&#20215;&#20013;&#35299;&#20915;Black-Scholes PDE&#21450;&#20854;&#20811;&#26381;&#32500;&#24230;&#35781;&#21650;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Quantum Monte Carlo algorithm for solving Black-Scholes PDEs for high-dimensional option pricing in finance and its proof of overcoming the curse of dimensionality. (arXiv:2301.09241v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;Black-Scholes PDE&#30340;&#39640;&#32500;&#26399;&#26435;&#23450;&#20215;&#65292;&#20854;&#22797;&#26434;&#24230;&#34987;&#22810;&#39033;&#24335;&#22320;&#38480;&#21046;&#65292;&#20811;&#26381;&#20102;&#32500;&#24230;&#35781;&#21650;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a quantum Monte Carlo algorithm for high-dimensional option pricing by solving high-dimensional Black-Scholes PDEs with correlation, and proves that its computational complexity is polynomially bounded in the space dimension and the reciprocal of the prescribed accuracy, overcoming the curse of dimensionality.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#30456;&#20851;&#24615;&#30340;&#39640;&#32500;Black-Scholes PDE&#30340;&#39640;&#32500;&#26399;&#26435;&#23450;&#20215;&#12290;&#26399;&#26435;&#30340;&#25903;&#20184;&#20989;&#25968;&#20026;&#19968;&#33324;&#24418;&#24335;&#65292;&#21482;&#38656;&#35201;&#36830;&#32493;&#19988;&#20998;&#27573;&#20223;&#23556;&#65288;CPWA&#65289;&#65292;&#28085;&#30422;&#20102;&#37329;&#34701;&#20013;&#20351;&#29992;&#30340;&#22823;&#22810;&#25968;&#30456;&#20851;&#25903;&#20184;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31639;&#27861;&#30340;&#20005;&#26684;&#35823;&#24046;&#20998;&#26512;&#21644;&#22797;&#26434;&#24230;&#20998;&#26512;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22312;PDE&#30340;&#31354;&#38388;&#32500;&#24230;$d$&#21644;&#25152;&#38656;&#31934;&#24230;$\varepsilon$&#30340;&#20498;&#25968;&#20013;&#34987;&#22810;&#39033;&#24335;&#22320;&#38480;&#21046;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#19981;&#20250;&#21463;&#21040;&#32500;&#24230;&#35781;&#21650;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we provide a quantum Monte Carlo algorithm to solve high-dimensional Black-Scholes PDEs with correlation for high-dimensional option pricing. The payoff function of the option is of general form and is only required to be continuous and piece-wise affine (CPWA), which covers most of the relevant payoff functions used in finance. We provide a rigorous error analysis and complexity analysis of our algorithm. In particular, we prove that the computational complexity of our algorithm is bounded polynomially in the space dimension $d$ of the PDE and the reciprocal of the prescribed accuracy $\varepsilon$ and so demonstrate that our quantum Monte Carlo algorithm does not suffer from the curse of dimensionality.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65288;RKBS&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23545;&#20598;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#38797;&#28857;&#38382;&#39064;&#65292;&#21487;&#29992;&#20110;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#30340;&#25972;&#20010;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2211.05020</link><description>&lt;p&gt;
&#36890;&#36807;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#30340;&#31070;&#32463;&#32593;&#32476;&#23545;&#20598;&#24615;
&lt;/p&gt;
&lt;p&gt;
Duality for Neural Networks through Reproducing Kernel Banach Spaces. (arXiv:2211.05020v3 [math.FA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05020
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65288;RKBS&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23545;&#20598;&#24615;&#38382;&#39064;&#65292;&#26500;&#24314;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#38797;&#28857;&#38382;&#39064;&#65292;&#21487;&#29992;&#20110;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#30340;&#25972;&#20010;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new method using Reproducing Kernel Banach spaces (RKBS) to solve the duality problem in neural networks, constructing the saddle point problem for neural networks, which can be used in the whole field of primal-dual optimization.
&lt;/p&gt;
&lt;p&gt;
&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#24050;&#32463;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#21508;&#20010;&#39046;&#22495;&#20013;&#38750;&#24120;&#25104;&#21151;&#30340;&#24037;&#20855;&#12290;&#26368;&#36817;&#65292;Barron&#31354;&#38388;&#24050;&#34987;&#29992;&#20110;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30001;&#20110;&#26435;&#37325;&#30340;&#24378;&#38750;&#32447;&#24615;&#32806;&#21512;&#65292;Barron&#31354;&#38388;&#26080;&#27861;&#29992;RKHS&#30340;&#26415;&#35821;&#29702;&#35299;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#26356;&#19968;&#33324;&#30340;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65288;RKBS&#65289;&#26469;&#35299;&#20915;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;Barron&#31354;&#38388;&#23646;&#20110;&#19968;&#31867;&#31215;&#20998;RKBS&#12290;&#36825;&#20010;&#31867;&#20063;&#21487;&#20197;&#29702;&#35299;&#20026;RKHS&#31354;&#38388;&#30340;&#26080;&#38480;&#24182;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;RKBS&#30340;&#23545;&#20598;&#31354;&#38388;&#65292;&#20877;&#27425;&#26159;&#19968;&#20010;RKBS&#65292;&#20854;&#20013;&#25968;&#25454;&#21644;&#21442;&#25968;&#30340;&#35282;&#33394;&#20114;&#25442;&#65292;&#24418;&#25104;&#19968;&#20010;&#21253;&#25324;&#20877;&#29983;&#26680;&#30340;&#20276;&#38543;RKBS&#23545;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#38797;&#28857;&#38382;&#39064;&#65292;&#21487;&#29992;&#20110;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#30340;&#25972;&#20010;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reproducing Kernel Hilbert spaces (RKHS) have been a very successful tool in various areas of machine learning. Recently, Barron spaces have been used to prove bounds on the generalisation error for neural networks. Unfortunately, Barron spaces cannot be understood in terms of RKHS due to the strong nonlinear coupling of the weights. This can be solved by using the more general Reproducing Kernel Banach spaces (RKBS). We show that these Barron spaces belong to a class of integral RKBS. This class can also be understood as an infinite union of RKHS spaces. Furthermore, we show that the dual space of such RKBSs, is again an RKBS where the roles of the data and parameters are interchanged, forming an adjoint pair of RKBSs including a reproducing kernel. This allows us to construct the saddle point problem for neural networks, which can be used in the whole field of primal-dual optimisation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#21147;&#31995;&#32479;&#29702;&#35770;&#20013;&#30340;&#20960;&#20010;&#24037;&#20855;&#26469;&#35299;&#20915;&#38750;&#20984;&#37319;&#26679;&#20013;&#30340;&#37325;&#35201;&#25361;&#25112;&#12290;&#23545;&#20110;&#19968;&#22823;&#31867;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#23427;&#20204;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#21487;&#20197;&#24402;&#32467;&#20026;&#23545;&#23427;&#20204;&#30340;&#36830;&#32493;&#26102;&#38388;&#23545;&#24212;&#29289;&#30340;&#30740;&#31350;&#65292;&#36825;&#26159;&#26356;&#22909;&#29702;&#35299;&#30340;&#12290;</title><link>http://arxiv.org/abs/2210.13867</link><description>&lt;p&gt;
Langevin-Based Non-Convex Sampling&#30340;&#21160;&#21147;&#23398;&#31995;&#32479;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Dynamical System View of Langevin-Based Non-Convex Sampling. (arXiv:2210.13867v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#21147;&#31995;&#32479;&#29702;&#35770;&#20013;&#30340;&#20960;&#20010;&#24037;&#20855;&#26469;&#35299;&#20915;&#38750;&#20984;&#37319;&#26679;&#20013;&#30340;&#37325;&#35201;&#25361;&#25112;&#12290;&#23545;&#20110;&#19968;&#22823;&#31867;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#23427;&#20204;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#21487;&#20197;&#24402;&#32467;&#20026;&#23545;&#23427;&#20204;&#30340;&#36830;&#32493;&#26102;&#38388;&#23545;&#24212;&#29289;&#30340;&#30740;&#31350;&#65292;&#36825;&#26159;&#26356;&#22909;&#29702;&#35299;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new framework that uses tools from the theory of dynamical systems to address important challenges in non-convex sampling. For a large class of state-of-the-art sampling schemes, their last-iterate convergence in Wasserstein distances can be reduced to the study of their continuous-time counterparts, which is much better understood.
&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;&#37319;&#26679;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#38750;&#20984;&#20248;&#21270;&#20197;&#21450;&#36817;&#20284;&#27010;&#29575;&#25512;&#26029;&#37117;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#29702;&#35770;&#19978;&#20173;&#23384;&#22312;&#35768;&#22810;&#37325;&#35201;&#25361;&#25112;&#65306;&#29616;&#26377;&#30340;&#20445;&#35777;&#36890;&#24120;&#20165;&#36866;&#29992;&#20110;&#24179;&#22343;&#36845;&#20195;&#32780;&#19981;&#26159;&#26356;&#29702;&#24819;&#30340;&#26368;&#21518;&#36845;&#20195;&#65292;&#32570;&#20047;&#25429;&#25417;&#21464;&#37327;&#23610;&#24230;&#65288;&#22914;Wasserstein&#36317;&#31163;&#65289;&#30340;&#25910;&#25947;&#24230;&#37327;&#65292;&#20027;&#35201;&#36866;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#31561;&#22522;&#26412;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#21160;&#21147;&#31995;&#32479;&#29702;&#35770;&#20013;&#30340;&#20960;&#20010;&#24037;&#20855;&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#32467;&#26524;&#26159;&#65292;&#23545;&#20110;&#19968;&#22823;&#31867;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#23427;&#20204;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#21487;&#20197;&#24402;&#32467;&#20026;&#23545;&#23427;&#20204;&#30340;&#36830;&#32493;&#26102;&#38388;&#23545;&#24212;&#29289;&#30340;&#30740;&#31350;&#65292;&#36825;&#26159;&#26356;&#22909;&#29702;&#35299;&#30340;&#12290;&#32467;&#21512;MCMC&#37319;&#26679;&#30340;&#26631;&#20934;&#20551;&#35774;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#31435;&#21363;&#20135;&#29983;&#20102;
&lt;/p&gt;
&lt;p&gt;
Non-convex sampling is a key challenge in machine learning, central to non-convex optimization in deep learning as well as to approximate probabilistic inference. Despite its significance, theoretically there remain many important challenges: Existing guarantees (1) typically only hold for the averaged iterates rather than the more desirable last iterates, (2) lack convergence metrics that capture the scales of the variables such as Wasserstein distances, and (3) mainly apply to elementary schemes such as stochastic gradient Langevin dynamics. In this paper, we develop a new framework that lifts the above issues by harnessing several tools from the theory of dynamical systems. Our key result is that, for a large class of state-of-the-art sampling schemes, their last-iterate convergence in Wasserstein distances can be reduced to the study of their continuous-time counterparts, which is much better understood. Coupled with standard assumptions of MCMC sampling, our theory immediately yie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25299;&#25169;&#32467;&#26500;&#23478;&#26063;EquiTopo&#65292;&#23427;&#20855;&#26377;&#65288;&#20960;&#20046;&#65289;&#24658;&#23450;&#30340;&#24230;&#25968;&#21644;&#19982;&#32593;&#32476;&#22823;&#23567;&#26080;&#20851;&#30340;&#20849;&#35782;&#36895;&#29575;&#65292;&#29992;&#20110;&#34913;&#37327;&#28151;&#21512;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2210.07881</link><description>&lt;p&gt;
&#24102;&#26377;$O(1)$&#20849;&#35782;&#36895;&#29575;&#30340;&#20998;&#25955;&#24335;&#23398;&#20064;&#30340;&#36890;&#20449;&#39640;&#25928;&#25299;&#25169;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Topologies for Decentralized Learning with $O(1)$ Consensus Rate. (arXiv:2210.07881v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25299;&#25169;&#32467;&#26500;&#23478;&#26063;EquiTopo&#65292;&#23427;&#20855;&#26377;&#65288;&#20960;&#20046;&#65289;&#24658;&#23450;&#30340;&#24230;&#25968;&#21644;&#19982;&#32593;&#32476;&#22823;&#23567;&#26080;&#20851;&#30340;&#20849;&#35782;&#36895;&#29575;&#65292;&#29992;&#20110;&#34913;&#37327;&#28151;&#21512;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new family of topologies, EquiTopo, which has an (almost) constant degree and a network-size-independent consensus rate that is used to measure the mixing efficiency.
&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;&#24335;&#20248;&#21270;&#26159;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#26032;&#20852;&#33539;&#20363;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#28857;&#23545;&#28857;&#36890;&#20449;&#23454;&#29616;&#32593;&#32476;&#33539;&#22260;&#20869;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#32780;&#26080;&#38656;&#20013;&#22830;&#26381;&#21153;&#22120;&#12290;&#30001;&#20110;&#36890;&#20449;&#24448;&#24448;&#27604;&#35745;&#31639;&#24930;&#65292;&#22240;&#27492;&#24403;&#27599;&#20010;&#20195;&#29702;&#27599;&#27425;&#36845;&#20195;&#20165;&#19982;&#23569;&#25968;&#30456;&#37051;&#20195;&#29702;&#36890;&#20449;&#26102;&#65292;&#23427;&#20204;&#21487;&#20197;&#27604;&#20351;&#29992;&#26356;&#22810;&#20195;&#29702;&#25110;&#20013;&#22830;&#26381;&#21153;&#22120;&#26356;&#24555;&#22320;&#23436;&#25104;&#36845;&#20195;&#12290;&#28982;&#32780;&#65292;&#21040;&#36798;&#32593;&#32476;&#33539;&#22260;&#20869;&#30340;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#24635;&#36845;&#20195;&#27425;&#25968;&#21463;&#21040;&#20195;&#29702;&#20449;&#24687;&#36890;&#36807;&#36890;&#20449;&#8220;&#28151;&#21512;&#8221;&#30340;&#36895;&#24230;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#27969;&#34892;&#30340;&#36890;&#20449;&#25299;&#25169;&#32467;&#26500;&#35201;&#20040;&#20855;&#26377;&#36739;&#22823;&#30340;&#26368;&#22823;&#24230;&#25968;&#65288;&#20363;&#22914;&#26143;&#24418;&#21644;&#23436;&#20840;&#22270;&#65289;&#65292;&#35201;&#20040;&#22312;&#28151;&#21512;&#20449;&#24687;&#26041;&#38754;&#25928;&#26524;&#19981;&#20339;&#65288;&#20363;&#22914;&#29615;&#21644;&#32593;&#26684;&#65289;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25299;&#25169;&#32467;&#26500;&#23478;&#26063;EquiTopo&#65292;&#23427;&#20855;&#26377;&#65288;&#20960;&#20046;&#65289;&#24658;&#23450;&#30340;&#24230;&#25968;&#21644;&#19982;&#32593;&#32476;&#22823;&#23567;&#26080;&#20851;&#30340;&#20849;&#35782;&#36895;&#29575;&#65292;&#29992;&#20110;&#34913;&#37327;&#28151;&#21512;&#25928;&#29575;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#23478;&#26063;&#20013;&#65292;EquiStatic&#30340;&#24230;&#25968;&#20026;$
&lt;/p&gt;
&lt;p&gt;
Decentralized optimization is an emerging paradigm in distributed learning in which agents achieve network-wide solutions by peer-to-peer communication without the central server. Since communication tends to be slower than computation, when each agent communicates with only a few neighboring agents per iteration, they can complete iterations faster than with more agents or a central server. However, the total number of iterations to reach a network-wide solution is affected by the speed at which the agents' information is ``mixed'' by communication. We found that popular communication topologies either have large maximum degrees (such as stars and complete graphs) or are ineffective at mixing information (such as rings and grids). To address this problem, we propose a new family of topologies, EquiTopo, which has an (almost) constant degree and a network-size-independent consensus rate that is used to measure the mixing efficiency.  In the proposed family, EquiStatic has a degree of $
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24320;&#25918;&#24335;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24615;&#33021;&#24230;&#37327;&#65292;&#21363;&#24320;&#25918;&#24335;FL&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#22312;&#20551;&#35774;&#26412;&#22320;&#23458;&#25143;&#31471;&#20989;&#25968;&#26159;&#24378;&#20984;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#29702;&#35770;&#19978;&#37327;&#21270;&#20102;&#20004;&#31181;FL&#31639;&#27861;&#30340;&#31283;&#23450;&#21322;&#24452;&#12290;</title><link>http://arxiv.org/abs/2209.12307</link><description>&lt;p&gt;
&#24320;&#25918;&#24335;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On the Stability Analysis of Open Federated Learning Systems. (arXiv:2209.12307v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.12307
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24320;&#25918;&#24335;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24615;&#33021;&#24230;&#37327;&#65292;&#21363;&#24320;&#25918;&#24335;FL&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#22312;&#20551;&#35774;&#26412;&#22320;&#23458;&#25143;&#31471;&#20989;&#25968;&#26159;&#24378;&#20984;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#29702;&#35770;&#19978;&#37327;&#21270;&#20102;&#20004;&#31181;FL&#31639;&#27861;&#30340;&#31283;&#23450;&#21322;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the stability issue of open federated learning systems, proposes a new performance metric, namely the stability of open FL systems, and theoretically quantifies the stability radius of two FL algorithms under the assumption that local clients' functions are strongly convex and smooth.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24320;&#25918;&#24335;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#21487;&#33021;&#22312;&#32852;&#37030;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#21644;/&#25110;&#31163;&#24320;&#31995;&#32479;&#12290;&#30001;&#20110;&#23384;&#22312;&#23458;&#25143;&#31471;&#25968;&#37327;&#30340;&#21464;&#21270;&#65292;&#26080;&#27861;&#20445;&#35777;&#22312;&#24320;&#25918;&#31995;&#32479;&#20013;&#25910;&#25947;&#21040;&#22266;&#23450;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#37319;&#29992;&#19968;&#31181;&#26032;&#30340;&#24615;&#33021;&#24230;&#37327;&#65292;&#31216;&#20026;&#24320;&#25918;&#24335;FL&#31995;&#32479;&#30340;&#31283;&#23450;&#24615;&#65292;&#23427;&#37327;&#21270;&#20102;&#22312;&#24320;&#25918;&#31995;&#32479;&#20013;&#23398;&#20064;&#27169;&#22411;&#30340;&#22823;&#23567;&#12290;&#22312;&#20551;&#35774;&#26412;&#22320;&#23458;&#25143;&#31471;&#20989;&#25968;&#26159;&#24378;&#20984;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#37327;&#21270;&#20102;&#20004;&#31181;FL&#31639;&#27861;&#65288;&#21363;&#26412;&#22320;SGD&#21644;&#26412;&#22320;Adam&#65289;&#30340;&#31283;&#23450;&#21322;&#24452;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#36825;&#20010;&#21322;&#24452;&#20381;&#36182;&#20110;&#20960;&#20010;&#20851;&#38190;&#21442;&#25968;&#65292;&#21253;&#25324;&#20989;&#25968;&#26465;&#20214;&#25968;&#20197;&#21450;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#36827;&#19968;&#27493;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the open federated learning (FL) systems, where clients may join and/or leave the system during the FL process. Given the variability of the number of present clients, convergence to a fixed model cannot be guaranteed in open systems. Instead, we resort to a new performance metric that we term the stability of open FL systems, which quantifies the magnitude of the learned model in open systems. Under the assumption that local clients' functions are strongly convex and smooth, we theoretically quantify the radius of stability for two FL algorithms, namely local SGD and local Adam. We observe that this radius relies on several key parameters, including the function condition number as well as the variance of the stochastic gradient. Our theoretical results are further verified by numerical simulations on both synthetic and real-world benchmark data-sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35745;&#31639;&#30446;&#26631;&#20989;&#25968;&#26799;&#24230;&#24456;&#26114;&#36149;&#25110;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#32473;&#23450;&#19968;&#20123;&#36741;&#21161;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#26368;&#23567;&#21270;&#30446;&#26631;&#20989;&#25968;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#29992;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#21463;&#30410;&#20110;&#30446;&#26631;&#21644;&#36741;&#21161;&#20449;&#24687;&#20043;&#38388;&#30340;Hessian&#30456;&#20284;&#24615;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2206.00395</link><description>&lt;p&gt;
&#20855;&#22791;&#36741;&#21161;&#20449;&#24687;&#30340;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Optimization with access to auxiliary information. (arXiv:2206.00395v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35745;&#31639;&#30446;&#26631;&#20989;&#25968;&#26799;&#24230;&#24456;&#26114;&#36149;&#25110;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#32473;&#23450;&#19968;&#20123;&#36741;&#21161;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#26368;&#23567;&#21270;&#30446;&#26631;&#20989;&#25968;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#29992;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#21463;&#30410;&#20110;&#30446;&#26631;&#21644;&#36741;&#21161;&#20449;&#24687;&#20043;&#38388;&#30340;Hessian&#30456;&#20284;&#24615;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the fundamental optimization question of minimizing a target function with expensive or limited gradient computation, given access to some auxiliary side function with cheaper or more available gradients. The authors propose two generic new algorithms and prove that this framework can benefit from the Hessian similarity assumption between the target and side information.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#26412;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#22312;&#35745;&#31639;&#30446;&#26631;&#20989;&#25968;$f(x)$&#30340;&#26799;&#24230;&#24456;&#26114;&#36149;&#25110;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#32473;&#23450;&#19968;&#20123;&#36741;&#21161;&#20989;&#25968;$h(x)$&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#26368;&#23567;&#21270;&#30446;&#26631;&#20989;&#25968;&#12290;&#36825;&#20010;&#20844;&#24335;&#28085;&#30422;&#20102;&#35768;&#22810;&#23454;&#38469;&#30456;&#20851;&#30340;&#35774;&#32622;&#65292;&#22914;i&#65289;&#22312;SGD&#20013;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#65292;ii&#65289;&#36801;&#31227;&#23398;&#20064;&#65292;iii&#65289;&#32852;&#37030;&#23398;&#20064;&#65292;iv&#65289;&#20351;&#29992;&#21387;&#32553;&#27169;&#22411;/&#20002;&#24323;&#31561;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#29992;&#30340;&#26032;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#25152;&#26377;&#36825;&#20123;&#35774;&#32622;&#65292;&#24182;&#35777;&#26126;&#20165;&#20351;&#29992;&#30446;&#26631;&#21644;&#36741;&#21161;&#20449;&#24687;&#20043;&#38388;&#30340;Hessian&#30456;&#20284;&#24615;&#20551;&#35774;&#65292;&#25105;&#20204;&#21487;&#20197;&#20174;&#36825;&#20010;&#26694;&#26550;&#20013;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the fundamental optimization question of minimizing a target function $f(x)$ whose gradients are expensive to compute or have limited availability, given access to some auxiliary side function $h(x)$ whose gradients are cheap or more available. This formulation captures many settings of practical relevance such as i) re-using batches in SGD, ii) transfer learning, iii) federated learning, iv) training with compressed models/dropout, etc. We propose two generic new algorithms which are applicable in all these settings and prove using only an assumption on the Hessian similarity between the target and side information that we can benefit from this framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#26333;&#20809;&#26144;&#23556;&#30340;&#20004;&#20010;&#20316;&#29992;&#20998;&#24320;&#65292;&#20174;&#32780;&#22312;&#26333;&#20809;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#31934;&#30830;&#20272;&#35745;&#26333;&#20809;&#25928;&#24212;&#65292;&#36991;&#20813;&#20102;&#24120;&#24120;&#26159;&#21487;&#30097;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2103.06471</link><description>&lt;p&gt;
&#35823;&#24046;&#26333;&#20809;&#26144;&#23556;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#65306;&#21306;&#20998;&#23450;&#20041;&#21644;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Causal inference with misspecified exposure mappings: separating definitions and assumptions. (arXiv:2103.06471v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.06471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#26333;&#20809;&#26144;&#23556;&#30340;&#20004;&#20010;&#20316;&#29992;&#20998;&#24320;&#65292;&#20174;&#32780;&#22312;&#26333;&#20809;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#31934;&#30830;&#20272;&#35745;&#26333;&#20809;&#25928;&#24212;&#65292;&#36991;&#20813;&#20102;&#24120;&#24120;&#26159;&#21487;&#30097;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new method to separate the two roles of exposure mappings, which allows for precise estimation of exposure effects even when the exposures are misspecified, avoiding often questionable assumptions.
&lt;/p&gt;
&lt;p&gt;
&#24403;&#23454;&#39564;&#21333;&#20301;&#30456;&#20114;&#20316;&#29992;&#26102;&#65292;&#26333;&#20809;&#26144;&#23556;&#26377;&#21161;&#20110;&#30740;&#31350;&#22797;&#26434;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#35201;&#27714;&#23454;&#39564;&#32773;&#22312;&#23450;&#20041;&#24863;&#20852;&#36259;&#30340;&#25928;&#24212;&#21644;&#23545;&#24178;&#25200;&#32467;&#26500;&#26045;&#21152;&#20551;&#35774;&#26102;&#20351;&#29992;&#30456;&#21516;&#30340;&#26333;&#20809;&#26144;&#23556;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20004;&#20010;&#35282;&#33394;&#24456;&#23569;&#37325;&#21512;&#65292;&#23454;&#39564;&#32773;&#34987;&#36843;&#20570;&#20986;&#24120;&#24120;&#26159;&#21487;&#30097;&#30340;&#20551;&#35774;&#65292;&#21363;&#20182;&#20204;&#30340;&#26333;&#20809;&#26144;&#23556;&#26159;&#27491;&#30830;&#30340;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#26333;&#20809;&#26144;&#23556;&#30446;&#21069;&#25152;&#36215;&#30340;&#20004;&#20010;&#20316;&#29992;&#21487;&#20197;&#65292;&#32780;&#19988;&#36890;&#24120;&#24212;&#35813;&#20998;&#24320;&#65292;&#36825;&#26679;&#26333;&#20809;&#23601;&#21487;&#20197;&#29992;&#26469;&#23450;&#20041;&#25928;&#24212;&#65292;&#32780;&#19981;&#24517;&#20551;&#35774;&#23427;&#20204;&#25429;&#25417;&#20102;&#23454;&#39564;&#20013;&#30340;&#23436;&#25972;&#22240;&#26524;&#32467;&#26500;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#26333;&#20809;&#25928;&#24212;&#21487;&#20197;&#22312;&#26333;&#20809;&#34987;&#38169;&#35823;&#25351;&#23450;&#26102;&#31934;&#30830;&#20272;&#35745;&#30340;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#26159;&#21487;&#34892;&#30340;&#12290;&#19968;&#20123;&#37325;&#35201;&#30340;&#38382;&#39064;&#20173;&#28982;&#27809;&#26377;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exposure mappings facilitate investigations of complex causal effects when units interact in experiments. Current methods require experimenters to use the same exposure mappings both to define the effect of interest and to impose assumptions on the interference structure. However, the two roles rarely coincide in practice, and experimenters are forced to make the often questionable assumption that their exposures are correctly specified. This paper argues that the two roles exposure mappings currently serve can, and typically should, be separated, so that exposures are used to define effects without necessarily assuming that they are capturing the complete causal structure in the experiment. The paper shows that this approach is practically viable by providing conditions under which exposure effects can be precisely estimated when the exposures are misspecified. Some important questions remain open.
&lt;/p&gt;</description></item></channel></rss>