# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation.](http://arxiv.org/abs/2401.04728) | 本文通过在多视点一致扩散方法中整合三维可塑模型，提高了从单个图像生成三维一致、可动画和逼真的人物化身的质量和功能。 |
| [^2] | [RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation.](http://arxiv.org/abs/2401.04679) | RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。 |
| [^3] | [Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats and Dogs Dataset.](http://arxiv.org/abs/2401.04666) | 本研究基于ASSIRA猫狗数据集，比较了使用不同优化器和损失函数的各种预训练模型，并通过改变超参数来提高模型准确性。 |
| [^4] | [Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models.](http://arxiv.org/abs/2401.04658) | 本文介绍了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。通过利用平铺的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，采用传统的注意力计算机制处理内部块，并使用新的累积求和方法处理外部块。 |
| [^5] | [A novel framework for generalization of deep hidden physics models.](http://arxiv.org/abs/2401.04648) | 这项工作提出了一种改进的隐含物理模型框架，可以泛化适应系统输入、参数和域的变化，并在系统发现中展现了潜力。 |
| [^6] | [Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks.](http://arxiv.org/abs/2401.04647) | 本文提出了一种先验可解释模型，通过在主分类器网络中添加无监督的解释生成器和对抗训练的方式，实现了模型的可解释性和性能的提升。该方法通过训练解释模块提取视觉概念，同时使用生成对抗网络模块来区分生成的图像和真实图像。实验证明了该方法的鲁棒性，并展示了学到的概念与对象部分和视觉属性的语义一致性。 |
| [^7] | [Applying Large Language Models API to Issue Classification Problem.](http://arxiv.org/abs/2401.04637) | 本研究通过应用生成式预训练转换器（GPT）模型，提出一种可靠的自动化方法来解决问题报告的优先级排序问题，即使在较小的训练数据集下仍能保持可靠性，减少了对大量训练数据的依赖性。 |
| [^8] | [Deep Reinforcement Multi-agent Learning framework for Information Gathering with Local Gaussian Processes for Water Monitoring.](http://arxiv.org/abs/2401.04631) | 本文提出了一个深度强化多智能体学习框架，结合局部高斯过程，用于水污染监测。使用局部高斯过程准确建模不同空间相关性中的信息，并采用深度卷积策略决策方法来获得有效的监测策略。通过双重深度 Q 学习算法训练智能体以减小估计误差。 |
| [^9] | [DebugBench: Evaluating Debugging Capability of Large Language Models.](http://arxiv.org/abs/2401.04621) | 该论文介绍了一个名为DebugBench的LLM调试基准，用于评估大型语言模型的调试能力。研究发现闭源模型与人类相比具有较低的调试性能，而开源模型未能达到合格率。 |
| [^10] | [Agent Alignment in Evolving Social Norms.](http://arxiv.org/abs/2401.04620) | 本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。 |
| [^11] | [A Deep Network for Explainable Prediction of Non-Imaging Phenotypes using Anatomical Multi-View Data.](http://arxiv.org/abs/2401.04579) | 本论文研究了利用解剖多视图数据预测非成像表型的深度网络，提出了一个可解释的多视图网络（EMV-Net），通过融合不同解剖视图来提高预测性能。 |
| [^12] | [Masked Audio Generation using a Single Non-Autoregressive Transformer.](http://arxiv.org/abs/2401.04577) | MAGNeT是一种遮蔽生成序列建模方法，使用单一非自回归Transformer生成具有高质量的音频，并引入了一种新颖的重新评分方法来提高生成音频的质量。同时，MAGNeT还探索了混合版本，可在自回归模式和非自回归模式下生成序列。在实验中证明MAGNeT在文本到音乐和文本到音频生成任务中具有高效性。 |
| [^13] | [Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding.](http://arxiv.org/abs/2401.04575) | Let's Go Shopping (LGS) dataset is a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites, providing a more efficient way to collect and annotate images for vision and vision-language applications. |
| [^14] | [Evaluating Language Model Agency through Negotiations.](http://arxiv.org/abs/2401.04536) | 本研究通过谈判游戏的视角，提出共同评估语言模型（LM）的性能和对齐，以更好地反映真实世界的部署条件，并避免数据泄漏。通过评估多轮次和跨模型交互，我们发现了LM的自我对弈和交叉对弈性能。 |
| [^15] | [MERA: A Comprehensive LLM Evaluation in Russian.](http://arxiv.org/abs/2401.04531) | 这项研究提出了MERA，一个多模态俄语基础模型评估指标。该指标包括21个评估任务，涵盖了11个技能领域中生成模型的评估。研究还提出了一种在零样本和少样本固定指令设置下评估FM和LM的方法。 |
| [^16] | [The Critique of Critique.](http://arxiv.org/abs/2401.04518) | 本文创新性地提出了元批评(MetaCritique)的框架，通过精确度和召回率评估批评的质量，并以F1分数作为整体评分。为了获得可靠的评估结果，引入了原子信息单元(AIUs)来描述批评。元批评提供了自然语言的理由来支持评价结果。 |
| [^17] | [Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models.](http://arxiv.org/abs/2401.04515) | 本文研究了使用大型语言模型进行零样本上位词预测的方法。实验结果表明，语言模型提示的有效性与经典模式之间存在较强的相关性，并且可以通过使用较小的模型进行初步的提示选择。此外，通过使用自动识别的共同下位词将额外信息加入提示，可以改善上位词预测的效果。作者还开发了一种迭代方法来预测更高层次的概念，并在BLESS数据集上取得了显著的质量提升（MAP = 0.8）。 |
| [^18] | [TechGPT-2.0: A large language model project to solve the task of knowledge graph construction.](http://arxiv.org/abs/2401.04507) | TechGPT-2.0是一个解决知识图谱构建任务的大型语言模型项目，具有强大的文本处理能力和多个领域的应用能力。 |
| [^19] | [Optimal Survival Trees: A Dynamic Programming Approach.](http://arxiv.org/abs/2401.04489) | 本文提出了一种利用动态规划的生存树方法，通过递归分割人口和预测不同的生存分布来发现复杂的非线性关系。该方法具有优化保证，并通过特殊算法提高了可扩展性，运行时间优于某些启发式算法。 |
| [^20] | [Fighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset.](http://arxiv.org/abs/2401.04481) | 本文提出了一种基于大型语言模型的方法，通过对其进行引导，自动生成虚假信息的辨别数据集，以解决传统方法标注数据所需的大量人工努力的问题。 |
| [^21] | [TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction.](http://arxiv.org/abs/2401.04478) | TwinBooster结合了大语言模型、Barlow Twins和梯度提升，通过整合生物检测方法和分子指纹，实现了对未见过的生物检测方法和分子属性的精确预测，该方法在数据稀缺的情况下展现出了优秀的性能。 |
| [^22] | [Combining Embedding-Based and Semantic-Based Models for Post-hoc Explanations in Recommender Systems.](http://arxiv.org/abs/2401.04474) | 本论文介绍了一种使用基于嵌入和基于语义的模型相结合的方法来生成推荐系统中的事后解释，并利用基于本体的知识图谱来提高可解释性。这样的框架旨在产生有意义且易于理解的解释，增强用户的信任和满意度。 |
| [^23] | [A Survey on Efficient Federated Learning Methods for Foundation Model Training.](http://arxiv.org/abs/2401.04472) | 这项调查研究了高效联邦学习方法在基础模型训练中的应用，提出了一个新的分类方法以优化计算和通信效率。该研究还讨论了当前广泛使用的FL框架，并展望了未来的研究潜力。 |
| [^24] | [MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation.](http://arxiv.org/abs/2401.04468) | MagicVideo-V2是一个多阶段的高审美视频生成系统，通过集成文本到图像模型、视频运动生成器、参考图像嵌入模块和帧插值模块，实现了以高保真度和流畅性生成高分辨率美学视频的目标。在大规模用户评估中，表现优于其他Text-to-Video系统。 |
| [^25] | [Image classification network enhancement methods based on knowledge injection.](http://arxiv.org/abs/2401.04441) | 本论文介绍了一种基于知识注入的图像分类网络增强方法，该方法利用人类知识构建深度神经网络训练模型，解决了传统算法难以解释结果原因和难以理解分析预测逻辑的问题。 |
| [^26] | [Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using Dimension Reduction Methods.](http://arxiv.org/abs/2401.04437) | 本论文通过对高光谱成像进行异常检测的实证分析，提出了一种基于特征选择的HSI通道还原方法，相对于传统的特征提取方法，在推理阶段的速度快6.90倍。 |
| [^27] | [i-Rebalance: Personalized Vehicle Repositioning for Supply Demand Balance.](http://arxiv.org/abs/2401.04429) | 本文提出了一种名为i-Rebalance的个性化车辆重新定位技术，通过深度强化学习（DRL）估计驾驶员对重新定位推荐的决策。该技术采用顺序重新定位策略，并使用双DRL代理实现供需平衡和驾驶员偏好满意度的优化。 |
| [^28] | [Estimating Text Similarity based on Semantic Concept Embeddings.](http://arxiv.org/abs/2401.04422) | 该论文提出了基于MultiNet语义网络的语义概念嵌入方法，结合传统词嵌入可以提高预测目标群组的准确性。 |
| [^29] | [Optimal Transcoding Resolution Prediction for Efficient Per-Title Bitrate Ladder Estimation.](http://arxiv.org/abs/2401.04405) | 本论文提出了直接预测每个预设比特率下的最佳转码分辨率的方法，以实现高效的比特率阶梯构建，并证明了可以无需任何预编码来高效确定内容优化的比特率阶梯。 |
| [^30] | [IGNITE: Individualized GeNeration of Imputations in Time-series Electronic health records.](http://arxiv.org/abs/2401.04402) | 个体化时间序列电子健康记录的生成模型IGNITE通过学习个体的动态特征，结合人口特征和治疗信息，生成个性化的真实值，为个体化医疗提供了有价值的方式。 |
| [^31] | [Machine unlearning through fine-grained model parameters perturbation.](http://arxiv.org/abs/2401.04385) | 本文提出了一种精细的机器去学习策略，通过细粒度模型参数的扰动来实现用户隐私保护，同时保持可控的计算成本。采用遗忘率和记忆保留率等新的指标来评估去学习效果和模型泛化能力。 |
| [^32] | [Towards Explainable Artificial Intelligence (XAI): A Data Mining Perspective.](http://arxiv.org/abs/2401.04374) | 本研究提出了一种“数据为中心”的视角，探讨了数据收集、处理和分析在可解释的人工智能中的作用。研究将现有工作分为三个类别：深度模型的解释、训练数据的影响和领域知识的见解。通过数据挖掘操作，我们总结了这些XAI方法。 |
| [^33] | [Representative Feature Extraction During Diffusion Process for Sketch Extraction with One Example.](http://arxiv.org/abs/2401.04362) | 本论文介绍了一种名为DiffSketch的草图生成方法，通过选择代表性特征并结合生成模型进行提取，实现从图像中生成多样化的草图。与现有方法相比，该方法在提取草图的性能上具有显著的优势。 |
| [^34] | [Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning.](http://arxiv.org/abs/2401.04361) | 本文提出了一种基于实体对比学习框架来提高知识驱动对话（KGD）系统的稳健性，通过创建正负样本以应对实际噪音，如错别字和不完整的知识图谱。 |
| [^35] | [Iterative Feedback Network for Unsupervised Point Cloud Registration.](http://arxiv.org/abs/2401.04357) | 本文提出了一种用于无监督点云配准的迭代反馈网络 (IFNet)，通过重新路由高层特征来丰富低层特征的表示，有效解决了现有方法中缺乏高层信息到低层信息的指导的问题。 |
| [^36] | [A Change Point Detection Integrated Remaining Useful Life Estimation Model under Variable Operating Conditions.](http://arxiv.org/abs/2401.04351) | 本研究提出了一种新的时间动态学习模型，用于在可变工况下检测设备的变点，并利用这些变点来提高剩余寿命估计的准确性。 |
| [^37] | [Memory-Efficient Personalization using Quantized Diffusion Model.](http://arxiv.org/abs/2401.04339) | 本文研究了使用量化扩散模型进行内存高效个性化的方法，提出了两个策略来解决基线模型中主题和提示质量之间的权衡问题。 |
| [^38] | [Deep Efficient Private Neighbor Generation for Subgraph Federated Learning.](http://arxiv.org/abs/2401.04336) | 本文提出了FedDEP，用于解决子图联邦学习中的信息传播不完整的问题，并提出了一系列新颖的技术设计，包括深度邻居生成和高效的私密领域生成。 |
| [^39] | [Large Language Models for Robotics: Opportunities, Challenges, and Perspectives.](http://arxiv.org/abs/2401.04334) | 大规模语言模型与机器人技术的结合在机器人任务规划中具有巨大潜力，但在与复杂环境互动的实体任务中存在挑战。本研究提出了一个通过多模态GPT-4V的框架来增强实体任务规划效果，并在多样化的数据集上验证了其有效性。 |
| [^40] | [Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study.](http://arxiv.org/abs/2401.04331) | 本文详细研究了图神经分数阶微分方程模型的鲁棒性，通过实施分数阶微积分，模型在特征更新过程中考虑了长期记忆，对抗性条件下的性能仍未得到广泛探究。 |
| [^41] | [BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation.](http://arxiv.org/abs/2401.04330) | 提出了一种名为BD-MSA的新的变化检测模型，通过在训练和预测阶段收集特征图的全局和局部特征信息，成功提取了变化区域的边界信息，并将变化区域的主体与边界分离。 |
| [^42] | [Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs.](http://arxiv.org/abs/2401.04319) | 本文探索了一种通过类比推理增强的LLMs来实现对营销人员需求的结构化理解的新方式，使非专业营销人员能够仅凭需求的自然语言形式选择目标用户。 |
| [^43] | [StarCraftImage: A Dataset For Prototyping Spatial Reasoning Methods For Multi-Agent Environments.](http://arxiv.org/abs/2401.04290) | 这个论文提出了一种使用StarCraft II游戏回放构建的基准数据集，该数据集可以用于原型设计多智能体环境中的空间推理方法，同时具有与MNIST和CIFAR10相似的易用性。 |
| [^44] | [Robust Image Watermarking using Stable Diffusion.](http://arxiv.org/abs/2401.04247) | 本研究提出了一种名为ZoDiac的方法，利用稳定扩散模型在可训练的潜在空间中注入水印，从而使水印能够在受攻击时可靠检测到，对最先进的水印攻击具有很强的鲁棒性，优于现有的水印方法。 |
| [^45] | [FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild.](http://arxiv.org/abs/2401.04210) | 提出了FunnyNet-W，一个多模态模型用于预测视频中的有趣瞬间。该模型利用视觉、音频和文本数据以及交叉和自注意力机制，并且采用无监督方法获得训练标签。 |
| [^46] | [Learning Racing From an AI Coach: Effects of Multimodal Autonomous Driving Explanations on Driving Performance, Cognitive Load, Expertise, and Trust.](http://arxiv.org/abs/2401.04206) | 本研究测试了一种AI驾驶教练的解释对驾驶表现、认知负荷、专业知识和信任的影响。结果显示，AI驾驶教练对于教授新手驾驶技能是有帮助的，并且信息类型和呈现方式对表现结果有影响。 |
| [^47] | [Curiosity & Entropy Driven Unsupervised RL in Multiple Environments.](http://arxiv.org/abs/2401.04198) | 本论文提出了一种无指导的强化学习方法，在多个环境下通过好奇心和熵驱动实现了性能的改进。 |
| [^48] | [Interactive Multi-Objective Evolutionary Optimization of Software Architectures.](http://arxiv.org/abs/2401.04192) | 这篇论文研究了如何将交互式进化计算应用于软件架构设计中，以在搜索过程中融入人的判断，既考虑定量标准又考虑定性标准。 |
| [^49] | [Efficient Selective Audio Masked Multimodal Bottleneck Transformer for Audio-Video Classification.](http://arxiv.org/abs/2401.04154) | 这项研究提出了一种高效选择性音频掩蔽多模态瓶颈Transformer用于音视频分类，通过音视频Transformer提取时空表示并结合自监督目标进行训练，实现了有效的多模态学习和语义音频活动的学习。 |
| [^50] | [Cross-Speaker Encoding Network for Multi-Talker Speech Recognition.](http://arxiv.org/abs/2401.04152) | 本文提出了一种叫做Cross-Speaker Encoding（CSE）的网络，用于解决多说话人语音识别中的局限性，通过聚合跨说话人表示。通过与SOT结合，该模型在两个说话人的数据集上实验证明比SIMO基准模型的词错误率（WER）分别降低了8%和10%。 |
| [^51] | [Online Test-Time Adaptation of Spatial-Temporal Traffic Flow Forecasting.](http://arxiv.org/abs/2401.04148) | 本研究首次研究了在线测试时间适应技术在时空交通流量预测中的应用，提出了一种自适应的双重校正方法，通过对模型输出的分解和校正来提高预测的准确性。 |
| [^52] | [Learn Once Plan Arbitrarily (LOPA): Attention-Enhanced Deep Reinforcement Learning Method for Global Path Planning.](http://arxiv.org/abs/2401.04145) | LOPA是一种增强注意力的深度强化学习方法，用于解决全局路径规划中的收敛性和泛化性等挑战。 |
| [^53] | [Robust Calibration For Improved Weather Prediction Under Distributional Shift.](http://arxiv.org/abs/2401.04144) | 本研究通过混合专家模型、数据增强和鲁棒后校准方法，相比提升树模型，使用深度神经网络在天气预测中实现更准确和更好校准的结果。 |
| [^54] | [On The Potential of The Fractal Geometry and The CNNs Ability to Encode it.](http://arxiv.org/abs/2401.04141) | 本研究探讨分形几何的潜力和深度学习网络对其编码能力的限制。通过相关性分析实验和人类评估，我们发现深度网络不能提取复杂且高层次的分形特征。然而，在需要对象结构对分类任务至关重要的应用中，分形特征表现出很好的有效性。 |
| [^55] | [Expanding Horizons in HCI Research Through LLM-Driven Qualitative Analysis.](http://arxiv.org/abs/2401.04138) | 本文通过引入基于LLM的定性分析方法，拓展了人机交互研究的新视野，并通过研究发现LLMs在性能上不仅与传统分析方法相当，还能提供独特的见解。 |
| [^56] | [The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline.](http://arxiv.org/abs/2401.04136) | 本研究探讨了扩散模型中存在的版权保护漏洞，并提出了一种后门数据污染攻击方法。这种攻击方法无需操作扩散模型的训练或微调过程，仅通过向训练数据集插入污染数据来实施攻击。 |
| [^57] | [Global-Aware Enhanced Spatial-Temporal Graph Recurrent Networks: A New Framework For Traffic Flow Prediction.](http://arxiv.org/abs/2401.04135) | 该论文提出了一个名为GA-STGRN的新的交通流量预测框架，通过结合图卷积网络和循环神经网络来进行时空建模。该框架中的一个关键创新是引入了全局感知层来帮助捕捉全局信息。另外，为了建模非固定的图结构和捕捉局部特征，还提出了一个序列感知的图神经网络。 |
| [^58] | [Web Neural Network with Complete DiGraphs.](http://arxiv.org/abs/2401.04134) | 本文介绍了一种新的神经网络模型，通过使用完全有向图的网络结构和连续数据处理，更接近生物脑，并通过引入循环和消除顺序性来增加额外的结构特性。 |
| [^59] | [SynHIN: Generating Synthetic Heterogeneous Information Network for Explainable AI.](http://arxiv.org/abs/2401.04133) | 该论文提出了一种生成合成异构信息网络的方法，用于可解释人工智能。该方法通过识别现实世界数据集中的模式，构建合成网络，并确保生成的合成图数据与真实数据接近。这提供了用于节点分类任务的合成异构图数据集。 |
| [^60] | [Unsupervised Test-Time Adaptation via Plug-and-Play Transformer Modules.](http://arxiv.org/abs/2401.04130) | 这项工作介绍了PLUTO:一种插拔式模块化的测试时领域适应策略，通过预先训练一系列针对不同源领域的模块，有效地创建了一个"模块存储库"。采用无监督的测试时自适应方法，从存储库中选择稀疏的相关模块的子集，并创建选中模块的加权组合，实现了对新领域的自适应。 |
| [^61] | [The Concept of the Tactile Signature System for Individuals with Visual Impairments.](http://arxiv.org/abs/2401.04126) | 盲人触觉签名系统是一种无障碍和有效的系统，通过触觉互动和语音算法引导，赋予视障人士创建个性化手写签名的能力，促进了他们的独立和包容。 |
| [^62] | [DeepPhysiNet: Bridging Deep Learning and Atmospheric Physics for Accurate and Continuous Weather Modeling.](http://arxiv.org/abs/2401.04125) | DeepPhysiNet框架将物理定律纳入深度学习模型中，实现了准确和连续的天气系统模拟。 |
| [^63] | [MobileAgent: enhancing mobile control via human-machine interaction and SOP integration.](http://arxiv.org/abs/2401.04124) | MobileAgent通过人机交互和SOP集成，提高了移动控制的效率和个性化用户需求的满足，同时解决了隐私问题和代理学习中的挑战。 |
| [^64] | [From Prompt Engineering to Prompt Science With Human in the Loop.](http://arxiv.org/abs/2401.04122) | 基于代码书构建方法和多阶段验证过程，本文提出一种新的方法来更系统地在研究中使用LLMs。 |
| [^65] | [Generation Z's Ability to Discriminate Between AI-generated and Human-Authored Text on Discord.](http://arxiv.org/abs/2401.04120) | 本研究通过对Generation Z的个体进行调查，评估了他们在Discord上区分AI生成和人类撰写文本的能力，发现他们无法有效区分这两种来源的文本。 |
| [^66] | [Why is the User Interface a Dark Pattern? : Explainable Auto-Detection and its Analysis.](http://arxiv.org/abs/2401.04119) | 本研究通过使用BERT模型进行自动检测和LIME、SHAP等解释技术进行解释，揭示了黑暗模式中影响预测的关键术语，为用户提供防范黑暗模式的见解。 |
| [^67] | [Working with Trouble and Failures in Conversation between Humans and Robots (WTF 2023) & Is CUI Design Ready Yet?.](http://arxiv.org/abs/2401.04108) | 本论文总结了两个研讨会的会议录，旨在讨论人机对话中的沟通问题和失败，以及非机器人语音界面的相关失败。目标是彻底调查沟通失败，制定分类法，并展开解决方案的初步讨论。 |
| [^68] | [A Primer on Temporal Graph Learning.](http://arxiv.org/abs/2401.03988) | 本文介绍了时间图学习的基本知识，包括TGL框架中的重要概念、相关的学习架构以及经典的时间序列预测方法，为TGL的可解释学习解决方案提供了灵感。 |
| [^69] | [FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs.](http://arxiv.org/abs/2401.03868) | 该论文提出了FlightLLM，一种在FPGA上实现完整映射流程的高效大型语言模型推断方法。通过利用FPGA特定资源，解决了LLMs的计算和内存开销问题，并提出了可配置的稀疏DSP链以支持不同稀疏模式。 |
| [^70] | [The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance.](http://arxiv.org/abs/2401.03729) | 本研究通过一系列提示变化探究改变提示的构建方式对大规模语言模型决策的影响，发现即使微小的改变，比如在提示末尾加一个空格，也可能导致模型的答案变化。同时，请求以XML格式返回和常用的越狱方式也可能对模型标记的数据产生灾难性影响。 |
| [^71] | [Token-free LLMs Can Generate Chinese Classical Poetry with More Accurate Format.](http://arxiv.org/abs/2401.03512) | 本文提出了一种无需分词的大型语言模型（LLMs）来生成中国古典诗词，并解决了格式不准确性的问题。验证了现有基于分词的模型在字符和分词之间的关系方面的知识有限，并展示了如何通过定制模型解决这一问题。 |
| [^72] | [On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond.](http://arxiv.org/abs/2401.03301) | 本文提出了通过数据多样性概念来统一离线强化学习算法的方法，并证明了基于版本空间、正则化优化和后验采样的算法在标准假设下达到了可比的样本效率。 |
| [^73] | [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM.](http://arxiv.org/abs/2401.02994) | 本研究介绍了一种名为“混合”的方法，通过组合多个适度规模的聊天AI模型，可以达到或超越比它们更大的模型的性能表现。 |
| [^74] | [Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving.](http://arxiv.org/abs/2401.02949) | 本文提出了一种名为Graph2Tac的图神经网络模型，用于在定理证明中学习数学概念的分层表示。该模型能够动态地将新的数学概念纳入到知识库中，并在Coq证明助手中进行训练和应用。 |
| [^75] | [GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning.](http://arxiv.org/abs/2401.01990) | GPS-SSL是一种将先验知识注入到自监督学习中的通用方法，通过设计度量空间并利用最近邻采样生成正样本。它可以减少对强数据增强的依赖，因此在Cifar10上达到了更好的效果。 |
| [^76] | [Multilingual Instruction Tuning With Just a Pinch of Multilinguality.](http://arxiv.org/abs/2401.01854) | 本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。 |
| [^77] | [A Comprehensive Study of Knowledge Editing for Large Language Models.](http://arxiv.org/abs/2401.01286) | 本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。 |
| [^78] | [Masked Modeling for Self-supervised Representation Learning on Vision and Beyond.](http://arxiv.org/abs/2401.00897) | 蒙面建模是一种自监督学习方法，通过预测被蒙面部分实现深度模型学习稳健的表示，已在计算机视觉和自然语言处理等领域展现出卓越性能。 |
| [^79] | [Jatmo: Prompt Injection Defense by Task-Specific Finetuning.](http://arxiv.org/abs/2312.17673) | Jatmo是一种生成对提示注入攻击具有抗性的任务特定模型的方法，通过利用教师模型生成任务特定的数据集并对基础模型进行微调。 |
| [^80] | [LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination.](http://arxiv.org/abs/2312.15224) | 这项研究提出了一种分层语言智能体（HLA）用于实时人机协作，通过改进的LLM引擎和分层策略，既提供强大的推理能力又保持实时执行。 |
| [^81] | [Time-Transformer: Integrating Local and Global Features for Better Time Series Generation.](http://arxiv.org/abs/2312.11714) | 本文提出了一种新的时间序列生成模型，通过时间变换器同时学习本地和全局特征，实现了对时间序列数据的更好生成能力。 |
| [^82] | [Customize-It-3D: High-Quality 3D Creation from A Single Image Using Subject-Specific Knowledge Prior.](http://arxiv.org/abs/2312.11535) | 该论文提出了一种使用主体特定知识先验的两阶段方法，通过考虑阴影模式和纹理增强来生成高质量、有丰富纹理的3D模型，与以前的方法相比具有显著的优势。 |
| [^83] | [The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation.](http://arxiv.org/abs/2312.09085) | 本研究研究了LLMs对误导信息的易受攻击性，特别是在说服性对话中。通过实验证明，LLMs在事实知识上的正确信念很容易被各种说服策略所操纵。 |
| [^84] | [Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection.](http://arxiv.org/abs/2312.07476) | 本研究从可比较的演示的角度探索了上下文学习（ICL）机制，并发现演示偏见存在于大型语言模型（LLMs）中，而通过可比较的演示可以显著减少这种偏见，并在ICL中展现出良好的性能。 |
| [^85] | [From Knowledge Representation to Knowledge Organization and Back.](http://arxiv.org/abs/2312.07302) | 本文介绍了知识表示（KR）和面向分析的知识组织（KO）方法，并提出了一个集成了KO丰富的KR方法，以提高建模质量。 |
| [^86] | [Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in Autonomous Driving.](http://arxiv.org/abs/2312.01468) | 该研究评估了自动驾驶中的LiDAR-相机融合模型的对抗鲁棒性，发现在不改变图像数据通道的情况下，仅通过操纵LiDAR数据通道即可欺骗融合模型，这引发了自动驾驶领域的安全关注，并探讨了攻击的成功率与对抗性点数量、车辆间距离和角度因素的关系。该研究有助于提高自动驾驶的安全性。 |
| [^87] | [Deep Interactive Segmentation of Medical Images: A Systematic Review and Taxonomy.](http://arxiv.org/abs/2311.13964) | 本综述系统地总结了医学图像交互式分割的最新研究进展，通过深度学习的方法推动了领域发展，但目前存在方法之间的比较缺乏的问题。 |
| [^88] | [InteraSSort: Interactive Assortment Planning Using Large Language Models.](http://arxiv.org/abs/2311.12241) | InteraSSort是一种交互式商品组合规划框架，利用大型语言模型和优化工具帮助商店规划者解决复杂的店内规划问题。 |
| [^89] | [LLMs cannot find reasoning errors, but can correct them!.](http://arxiv.org/abs/2311.08516) | 本文研究了LLMs在自我纠正过程中的错误发现和输出纠正两个核心组成部分。研究发现LLMs通常难以发现逻辑错误，但通过使用回溯方法可以在提供错误位置信息时获得大幅改进。 |
| [^90] | [DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework.](http://arxiv.org/abs/2310.12081) | 本研究提出了一种名为DHOT-GM的图匹配方法，使用可微分的分层最优传输框架，充分利用了图中隐藏的多模态信息，通过对匹配结果进行加权平均来推断节点对应关系。 |
| [^91] | [FABind: Fast and Accurate Protein-Ligand Binding.](http://arxiv.org/abs/2310.06763) | FABind是一个结合了口袋预测和对接的端到端模型，旨在实现快速准确的蛋白-配体结合预测。 |
| [^92] | [Stepwise functional refoundation of relational concept analysis.](http://arxiv.org/abs/2310.06441) | 逐步功能重构的关系概念分析（RCA）是形式概念分析的扩展，通过定义良构解决方案的空间和相关函数，解决了RCA在循环依赖数据上返回单一概念格家族的问题。 |
| [^93] | [Bias Assessment and Mitigation in LLM-based Code Generation.](http://arxiv.org/abs/2309.14345) | 这项研究提出了一个新颖的偏差评估框架，针对代码生成任务进行设计。通过对九个最先进的基于LLM的代码生成模型进行广泛评估，发现其中31.45\%到79.93\%的代码函数具有偏见，并提出了如何缓解这种偏见的方法。 |
| [^94] | [s-ID: Causal Effect Identification in a Sub-Population.](http://arxiv.org/abs/2309.02281) | 该论文介绍了在子群体中进行因果效应识别的问题，提出并倡导了s-ID问题。论文提供了必要和充分条件，以便从子群体的观测分布中识别出因果效应。 |
| [^95] | [Where Would I Go Next? Large Language Models as Human Mobility Predictors.](http://arxiv.org/abs/2308.15197) | 本文研究了大型语言模型在人类移动预测任务中的潜力，提出了一种新方法LLM-Mob，通过利用语言模型的语言理解和推理能力分析人类移动数据，并引入历史停留和上下文停留的概念来捕捉长期和短期依赖关系，实现时态感知预测。 |
| [^96] | [Adapting text-based dialogue state tracker for spoken dialogues.](http://arxiv.org/abs/2308.15053) | 这篇论文描述了对构建适应口语对话系统的文本对话状态跟踪器进行的工程工作，利用自动语音识别错误校正和文本对话系统实现了插槽和值的估计。 |
| [^97] | [Decomposition-based Hierarchical Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications.](http://arxiv.org/abs/2308.10393) | 提出了一种基于分解的分层框架，用于多机器人的任务分配和规划，能够处理具有复杂时间约束的任务。该框架首先将每个规范分解为原子子任务，然后推断不同规范之间子任务的时序关系来实现机器人间的协作。 |
| [^98] | [The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations.](http://arxiv.org/abs/2308.02053) | 通过职位推荐分析了大型语言模型（LLMs）的人口统计偏见，发现这些模型对于墨西哥工人一直建议低薪工作，并向女性更倾向于推荐秘书职位。这项研究强调了理解LLMs偏见的重要性。 |
| [^99] | [Variational Classification.](http://arxiv.org/abs/2305.10406) | 提出一种新的变分分类方法，通过引入潜变量建模来优化训练，允许灵活的设计选择以改善校准和对抗鲁棒性，实验结果表明其对于域外数据的分类准确性得到了保持。 |
| [^100] | [Unsupervised Domain Transfer for Science: Exploring Deep Learning Methods for Translation between LArTPC Detector Simulations with Differing Response Models.](http://arxiv.org/abs/2304.12858) | 本文提出了一种基于最近在成对图像转换技术上的进展的，完全无监督的方法来减少LArTPC探测器模拟和真实数据之间的系统差异，以提高模型性能。 |
| [^101] | [Auditing and Generating Synthetic Data with Controllable Trust Trade-offs.](http://arxiv.org/abs/2304.10819) | 本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。 |
| [^102] | [Handling Long and Richly Constrained Tasks through Constrained Hierarchical Reinforcement Learning.](http://arxiv.org/abs/2302.10639) | 本文通过约束层次强化学习的机制解决了长期和丰富约束的任务，在机器人清洁房屋的场景中展示了良好的性能。 |
| [^103] | [Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes based on a Hybrid Spectral Method and the Harmonic Oscillator.](http://arxiv.org/abs/2302.09580) | 该论文提出了一种基于混合谱方法和谐振子的非可分离协方差核的时空高斯过程研究，通过物理论证推导出一类新型的非可分离协方差核，能更好地捕捉观测到的时空相关性。 |
| [^104] | [Enhancing SMT-based Weighted Model Integration by Structure Awareness.](http://arxiv.org/abs/2302.06188) | 本论文提出了一种基于结构感知的SMT加权模型集成算法，用于处理混合领域的概率推断问题，并能够避免生成冗余模型。 |
| [^105] | [General-Purpose In-Context Learning by Meta-Learning Transformers.](http://arxiv.org/abs/2212.04458) | 本文展示了Transformer和其他黑盒模型可以通过元学习训练成为通用的上下文学习器，该模型可以在各种问题上进行测试集预测，无需定义推理模型、训练损失或优化算法。 |
| [^106] | [DyG2Vec: Representation Learning for Dynamic Graphs with Self-Supervision.](http://arxiv.org/abs/2210.16906) | DyG2Vec是一个具有自监督学习能力的动态图表征学习模型，采用了高效而有效的注意力编码器和非对比自监督学习方法，能够提取丰富的时间嵌入表示。在基准数据集上的实验结果表明，该模型在未来链接预测任务中表现出色。 |
| [^107] | [Learning image representations for anomaly detection: application to discovery of histological alterations in drug development.](http://arxiv.org/abs/2210.07675) | 该论文提出了一种基于CNN的异常检测系统，通过对健康组织进行辅助任务训练，使表示适应组织中的相关细节，实现对组织学图像中的异常情况检测。 |
| [^108] | [Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis.](http://arxiv.org/abs/2209.08891) | 研究表明，在文本到图像合成过程中，通过插入异形字，模型会反映生成图片中的文化刻板印象和偏见。这一现象的根本原因是模型的文本编码器。而恶意用户或服务提供商还可能利用类似外形的非拉丁字符，故意引入偏见，创造种族主义刻板印象。 |
| [^109] | [On the Evolution of A.I. and Machine Learning: Towards a Meta-level Measuring and Understanding Impact, Influence, and Leadership at Premier A.I. Conferences.](http://arxiv.org/abs/2205.13131) | 本研究旨在理解人工智能和机器学习的演变，通过衡量研究者在该领域的影响、影响力和领导力，并通过分析在主要人工智能会议上发表的论文，揭示了人工智能领域的发展和演变。人工智能的发展导致了学术论文数量的增加，本研究构建了全面的引用和合作数据集，对相关关系进行了计算。 |
| [^110] | [Molecule Generation for Drug Design: a Graph Learning Perspective.](http://arxiv.org/abs/2202.09212) | 本论文调研了药物设计领域中基于图学习的分子生成方法，分为一步到位法、基于片段法和节点逐个法三类，介绍了公共数据集和评估指标，并讨论了未来研究的挑战和方向。 |
| [^111] | [PHPQ: Pyramid Hybrid Pooling Quantization for Efficient Fine-Grained Image Retrieval.](http://arxiv.org/abs/2109.05206) | PHPQ是一种用于高效细粒度图像检索的金字塔混合池化量化方法。它通过金字塔混合池化模块捕获和保留多层次特征中的细粒度语义信息，并引入可学习的量化模块来提高哈希的表达能力。 |

# 详细

[^1]: 可塑性扩散：单图像化身创建的三维一致扩散

    Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation. (arXiv:2401.04728v1 [cs.CV])

    [http://arxiv.org/abs/2401.04728](http://arxiv.org/abs/2401.04728)

    本文通过在多视点一致扩散方法中整合三维可塑模型，提高了从单个图像生成三维一致、可动画和逼真的人物化身的质量和功能。

    

    最近的生成扩散模型的进展使得从单个输入图像或文本提示生成三维资产成为可能。在这项工作中，我们旨在增强这些模型在创建可控、逼真的人物化身任务中的质量和功能。我们通过将三维可塑模型整合到最先进的多视点一致扩散方法中来实现这一目标。我们证明了精确地将生成流程与关节三维模型的条件相结合，提高了基准模型在单个图像的新视图合成任务上的性能。更重要的是，这种整合使面部表情和身体姿势控制在生成过程中无缝准确地融入其中。据我们所知，我们提出的框架是第一个能够从未见过的主题的单个图像创建完全三维一致、可动画和逼真的人物化身的扩散模型；扩展了当前研究的能力。

    Recent advances in generative diffusion models have enabled the previously unfeasible capability of generating 3D assets from a single input image or a text prompt. In this work, we aim to enhance the quality and functionality of these models for the task of creating controllable, photorealistic human avatars. We achieve this by integrating a 3D morphable model into the state-of-the-art multiview-consistent diffusion approach. We demonstrate that accurate conditioning of a generative pipeline on the articulated 3D model enhances the baseline model performance on the task of novel view synthesis from a single image. More importantly, this integration facilitates a seamless and accurate incorporation of facial expression and body pose control into the generation process. To the best of our knowledge, our proposed framework is the first diffusion model to enable the creation of fully 3D-consistent, animatable, and photorealistic human avatars from a single image of an unseen subject; exte
    
[^2]: RoSA: 通过鲁棒适应实现准确的参数高效微调

    RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v1 [cs.CL])

    [http://arxiv.org/abs/2401.04679](http://arxiv.org/abs/2401.04679)

    RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。

    

    我们研究了在大语言模型 (LLMs) 的背景下，能够在有限的计算和内存预算下提供良好准确性的参数高效微调 (PEFT) 方法。我们提出了一种新的PEFT方法，称为RoSA，受鲁棒主成分分析 (PCA) 的启发，它在一组固定的预训练权重上共同训练$\textit{低秩}$和$\textit{高度稀疏}$的组件，以高效近似完全微调（FFT）解决方案的性能。我们展示了RoSA在一系列具有挑战性的生成任务上的性能，例如小学数学和SQL查询生成，这些任务需要进行微调以获得良好性能，我们证明了在相同的参数预算下，RoSA优于LoRA和纯粹的稀疏微调。我们通过稀疏GPU内核为RoSA提供系统支持，以补充训练算法，从而实现内存和计算效率的训练。我们的代码将在https://github.com/IST-DASLab上提供。

    We investigate parameter-efficient fine-tuning (PEFT) methods that can provide good accuracy under limited computational and memory budgets in the context of large language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA) that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components on top of a set of fixed pretrained weights to efficiently approximate the performance of a full-fine-tuning (FFT) solution. Across a series of challenging generative tasks such as grade-school math and SQL query generation, which require fine-tuning for good performance, we show that RoSA outperforms both LoRA and pure sparse fine-tuning, at the same parameter budget. We provide system support for RoSA to complement the training algorithm, specifically in the form of sparse GPU kernels which enable memoryand computationally-efficient training. Our code will be made available at https://github.com/IST-DASLab
    
[^3]: ASSIRA猫狗数据集上各种预训练深度学习模型的基准分析

    Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats and Dogs Dataset. (arXiv:2401.04666v1 [cs.CV])

    [http://arxiv.org/abs/2401.04666](http://arxiv.org/abs/2401.04666)

    本研究基于ASSIRA猫狗数据集，比较了使用不同优化器和损失函数的各种预训练模型，并通过改变超参数来提高模型准确性。

    

    作为深度学习的最基本应用和实现，图像分类已经越来越受欢迎。知名数据科学社区提供了各种数据集来对机器学习算法和预训练模型进行基准测试。ASSIRA猫狗数据集是其中之一，并且在这项研究中被使用，因为它的整体接受度和基准标准。通过使用不同类型的优化器和损失函数，对各种预训练模型进行了比较。改变超参数以获得模型的最佳结果。通过应用这种方法，我们在不对训练模型进行重大更改的情况下获得了更高的准确性。为了运行实验证明了该数据集以准确率超过先前的实验。

    As the most basic application and implementation of deep learning, image classification has grown in popularity. Various datasets are provided by renowned data science communities for benchmarking machine learning algorithms and pre-trained models. The ASSIRA Cats & Dogs dataset is one of them and is being used in this research for its overall acceptance and benchmark standards. A comparison of various pre-trained models is demonstrated by using different types of optimizers and loss functions. Hyper-parameters are changed to gain the best result from a model. By applying this approach, we have got higher accuracy without major changes in the training model. To run the experiment, we used three different computer architectures: a laptop equipped with NVIDIA GeForce GTX 1070, a laptop equipped with NVIDIA GeForce RTX 3080Ti, and a desktop equipped with NVIDIA GeForce RTX 3090. The acquired results demonstrate supremacy in terms of accuracy over the previously done experiments on this da
    
[^4]: Lightning Attention-2:在大型语言模型中处理无限序列长度的"免费午餐"

    Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models. (arXiv:2401.04658v1 [cs.CL])

    [http://arxiv.org/abs/2401.04658](http://arxiv.org/abs/2401.04658)

    本文介绍了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。通过利用平铺的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，采用传统的注意力计算机制处理内部块，并使用新的累积求和方法处理外部块。

    

    线性注意力是一种高效的注意力机制，最近被认为是传统softmax注意力的一种有前景的替代方法。线性注意力理论上能够在线性的计算复杂度下处理无限长度的序列，而不会牺牲速度，即在固定的内存消耗下，能够以恒定的训练速度处理不同长度的序列。然而，由于累积求和（cumsum）的问题，当前的线性注意力算法无法在因果设置下展现其理论优势。本文提出了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。为了实现这一点，我们利用了平铺（tiling）的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，我们利用传统的注意力计算机制来处理内部块，然后使用一种新的累积求和的方法来处理外部块。

    Linear attention is an efficient attention mechanism that has recently emerged as a promising alternative to conventional softmax attention. With its ability to process tokens in linear computational complexities, linear attention, in theory, can handle sequences of unlimited length without sacrificing speed, i.e., maintaining a constant training speed for various sequence lengths with a fixed memory consumption. However, due to the issue with cumulative summation (cumsum), current linear attention algorithms cannot demonstrate their theoretical advantage in a causal setting. In this paper, we present Lightning Attention-2, the first linear attention implementation that enables linear attention to realize its theoretical computational benefits. To achieve this, we leverage the thought of tiling, separately handling the intra-block and inter-block components in linear attention calculation. Specifically, we utilize the conventional attention computation mechanism for the intra-blocks an
    
[^5]: 一种用于深度隐含物理模型泛化的新框架

    A novel framework for generalization of deep hidden physics models. (arXiv:2401.04648v1 [cs.LG])

    [http://arxiv.org/abs/2401.04648](http://arxiv.org/abs/2401.04648)

    这项工作提出了一种改进的隐含物理模型框架，可以泛化适应系统输入、参数和域的变化，并在系统发现中展现了潜力。

    

    在各种工程和工业应用中，对于系统的建模是一个常见的问题，其中完整的系统信息是未知的，要么是因为考虑到所有涉及的复杂物理是不可能的，要么是为了在可用资源的限制内考虑更简单的模型。最近在灰盒建模领域的进展，如深度隐含物理模型，通过结合数据和物理来解决这个问题。然而，对于大多数实际应用，模型的泛化能力是一个关键问题，因为为每个系统输入和参数的微小变化或域配置的修改重新训练模型可能导致模型在经济上不可行。在这项工作中，我们提出了一个对隐含物理模型思想的新改进，可以适应系统输入、参数和域的变化。我们还展示了这种方法在系统发现中的潜力，并帮助学习到了变化后系统输入、参数和域的隐藏物理规律。

    Modelling of systems where the full system information is unknown is an oft encountered problem for various engineering and industrial applications, as it's either impossible to consider all the complex physics involved or simpler models are considered to keep within the limits of the available resources. Recent advances in greybox modelling like the deep hidden physics models address this space by combining data and physics. However, for most real-life applications, model generalizability is a key issue, as retraining a model for every small change in system inputs and parameters or modification in domain configuration can render the model economically unviable. In this work we present a novel enhancement to the idea of hidden physics models which can generalize for changes in system inputs, parameters and domains. We also show that this approach holds promise in system discovery as well and helps learn the hidden physics for the changed system inputs, parameters and domain configurat
    
[^6]: 通过生成对抗网络推进先验可解释模型

    Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks. (arXiv:2401.04647v1 [cs.CV])

    [http://arxiv.org/abs/2401.04647](http://arxiv.org/abs/2401.04647)

    本文提出了一种先验可解释模型，通过在主分类器网络中添加无监督的解释生成器和对抗训练的方式，实现了模型的可解释性和性能的提升。该方法通过训练解释模块提取视觉概念，同时使用生成对抗网络模块来区分生成的图像和真实图像。实验证明了该方法的鲁棒性，并展示了学到的概念与对象部分和视觉属性的语义一致性。

    

    本文提出了一种新的概念学习框架，用于增强视觉分类任务中模型的可解释性和性能。我们的方法将一个无监督的解释生成器添加到主分类器网络中，并利用对抗训练。在训练过程中，解释模块被优化以从分类器的潜在表示中提取视觉概念，而基于生成对抗网络的模块则旨在区分从概念中生成的图像和真实图像。这种联合训练方案使得模型能够将其内部学习到的概念与人可解释的视觉属性隐式地对齐。全面的实验证明了我们方法的鲁棒性，同时产生了连贯的概念激活。我们分析了学到的概念，展示了它们与对象部分和视觉属性之间的语义一致性。我们还研究了对抗训练协议中的扰动对分类和概念获取的影响。总之，本文通过生成对抗网络推进了先验可解释模型。

    This paper presents a novel concept learning framework for enhancing model interpretability and performance in visual classification tasks. Our approach appends an unsupervised explanation generator to the primary classifier network and makes use of adversarial training. During training, the explanation module is optimized to extract visual concepts from the classifier's latent representations, while the GAN-based module aims to discriminate images generated from concepts, from true images. This joint training scheme enables the model to implicitly align its internally learned concepts with human-interpretable visual properties. Comprehensive experiments demonstrate the robustness of our approach, while producing coherent concept activations. We analyse the learned concepts, showing their semantic concordance with object parts and visual attributes. We also study how perturbations in the adversarial training protocol impact both classification and concept acquisition. In summary, this 
    
[^7]: 将大型语言模型API应用于问题分类问题

    Applying Large Language Models API to Issue Classification Problem. (arXiv:2401.04637v1 [cs.SE])

    [http://arxiv.org/abs/2401.04637](http://arxiv.org/abs/2401.04637)

    本研究通过应用生成式预训练转换器（GPT）模型，提出一种可靠的自动化方法来解决问题报告的优先级排序问题，即使在较小的训练数据集下仍能保持可靠性，减少了对大量训练数据的依赖性。

    

    在软件工程中，问题报告的有效排序对于优化资源分配和及时解决关键问题至关重要。然而，手动对问题报告进行分类以进行排序是费力且缺乏可伸缩性的。相反，许多开源软件项目使用自动化流程解决此问题，尽管需要大量的数据集进行充分的训练。这项研究旨在设计一种自动化方法，在使用较小的数据集进行训练时仍能确保问题排序的可靠性。我们提出的方法利用生成式预训练转换器（GPT）的能力，认识到它们在处理这个任务时的高效性。通过利用这样的模型的能力，我们的目标是开发一个准确优先级问题报告的可靠系统，降低对大量训练数据的需求，同时保持可靠性。在我们的研究中，我们已经开发了一个可靠的基于GPT的方法来准确标记问题报告。

    Effective prioritization of issue reports is crucial in software engineering to optimize resource allocation and address critical problems promptly. However, the manual classification of issue reports for prioritization is laborious and lacks scalability. Alternatively, many open source software (OSS) projects employ automated processes for this task, albeit relying on substantial datasets for adequate training. This research seeks to devise an automated approach that ensures reliability in issue prioritization, even when trained on smaller datasets. Our proposed methodology harnesses the power of Generative Pre-trained Transformers (GPT), recognizing their potential to efficiently handle this task. By leveraging the capabilities of such models, we aim to develop a robust system for prioritizing issue reports accurately, mitigating the necessity for extensive training data while maintaining reliability. In our research, we have developed a reliable GPT-based approach to accurately labe
    
[^8]: 用于水污染监测的深度强化多智能体学习框架和局部高斯过程

    Deep Reinforcement Multi-agent Learning framework for Information Gathering with Local Gaussian Processes for Water Monitoring. (arXiv:2401.04631v1 [cs.AI])

    [http://arxiv.org/abs/2401.04631](http://arxiv.org/abs/2401.04631)

    本文提出了一个深度强化多智能体学习框架，结合局部高斯过程，用于水污染监测。使用局部高斯过程准确建模不同空间相关性中的信息，并采用深度卷积策略决策方法来获得有效的监测策略。通过双重深度 Q 学习算法训练智能体以减小估计误差。

    

    为了有效监测水质，本文提出了一个由自主水面车组成的多智能体系统。为了实现对船队的安全控制，船队策略应该能够基于测量结果和船队状态进行行动。本文提出使用局部高斯过程和深度强化学习来联合获得有效的监测策略。局部高斯过程可以准确地建模不同空间相关性中的信息，从而更准确地捕捉水质信息。文中还提出了一种基于深度卷积策略的决策方法，通过观察这个模型的均值和方差，使用信息增益奖励进行决策。通过双重深度 Q 学习算法，智能体被训练以在安全的情况下尽量减小估计误差。

    The conservation of hydrological resources involves continuously monitoring their contamination. A multi-agent system composed of autonomous surface vehicles is proposed in this paper to efficiently monitor the water quality. To achieve a safe control of the fleet, the fleet policy should be able to act based on measurements and to the the fleet state. It is proposed to use Local Gaussian Processes and Deep Reinforcement Learning to jointly obtain effective monitoring policies. Local Gaussian processes, unlike classical global Gaussian processes, can accurately model the information in a dissimilar spatial correlation which captures more accurately the water quality information. A Deep convolutional policy is proposed, that bases the decisions on the observation on the mean and variance of this model, by means of an information gain reward. Using a Double Deep Q-Learning algorithm, agents are trained to minimize the estimation error in a safe manner thanks to a Consensus-based heuristi
    
[^9]: DebugBench: 评估大型语言模型的调试能力

    DebugBench: Evaluating Debugging Capability of Large Language Models. (arXiv:2401.04621v1 [cs.SE])

    [http://arxiv.org/abs/2401.04621](http://arxiv.org/abs/2401.04621)

    该论文介绍了一个名为DebugBench的LLM调试基准，用于评估大型语言模型的调试能力。研究发现闭源模型与人类相比具有较低的调试性能，而开源模型未能达到合格率。

    

    大型语言模型（LLMs）展示出了出色的编码能力。然而，作为编程能力的另一个关键组成部分，LLMs的调试能力仍然相对未被探索。之前对LLMs的调试能力评估受到数据泄露风险、数据集规模和测试漏洞种类的限制。为了克服这些不足，我们引入了一个名为“DebugBench”的LLM调试基准，包含4253个实例。它涵盖了C ++，Java和Python中四个主要的错误类别和18个次要类型。为了构建DebugBench，我们从LeetCode社区收集了代码片段，使用GPT-4向源数据中注入错误，并进行严格的质量检查。我们在零样例情况下评估了两个商业模型和三个开源模型。我们发现，（1）与人类相比，闭源模型如GPT-4表现出较低的调试性能，而开源模型如Code Llama无法达到任何合格率；（2）t

    Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs' debugging ability are significantly limited by the risk of data leakage, the scale of the dataset, and the variety of tested bugs. To overcome these deficiencies, we introduce `DebugBench', an LLM debugging benchmark consisting of 4,253 instances. It covers four major bug categories and 18 minor types in C++, Java, and Python. To construct DebugBench, we collect code snippets from the LeetCode community, implant bugs into source data with GPT-4, and assure rigorous quality checks. We evaluate two commercial and three open-source models in a zero-shot scenario. We find that (1) while closed-source models like GPT-4 exhibit inferior debugging performance compared to humans, open-source models such as Code Llama fail to attain any pass rate scores; (2) t
    
[^10]: 在不断演化的社会规范中的Agent对齐

    Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v1 [cs.CL])

    [http://arxiv.org/abs/2401.04620](http://arxiv.org/abs/2401.04620)

    本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。

    

    基于大型语言模型（LLM）的Agent越来越多地渗透到人类生产和生活的各个领域，凸显了将其与人类价值观对齐的重要性。目前AI系统的对齐主要集中在通过人为干预对LLM进行被动对齐。然而，Agent具有接受环境反馈和自我进化等特性，使得LLM对齐方法变得不足够。为此，我们提出了一个名为EvolutionaryAgent的Agent进化和对齐的进化框架，将Agent对齐转化为适者生存的演化和选择过程。在社会规范不断演化的环境中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率，而对齐不足的Agent则逐渐减少。通过多个角度对与社会规范相对齐的Agent进行的实验结果进行评估。

    Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstr
    
[^11]: 使用解释型多视图数据预测非成像表型的深度网络

    A Deep Network for Explainable Prediction of Non-Imaging Phenotypes using Anatomical Multi-View Data. (arXiv:2401.04579v1 [q-bio.QM])

    [http://arxiv.org/abs/2401.04579](http://arxiv.org/abs/2401.04579)

    本论文研究了利用解剖多视图数据预测非成像表型的深度网络，提出了一个可解释的多视图网络（EMV-Net），通过融合不同解剖视图来提高预测性能。

    

    大型数据集通常包含多个不同的特征集或视图，这些视图提供了互补信息，可以通过多视图学习方法利用它们来提高结果。我们研究了解剖多视图数据，其中每个脑解剖结构用多个特征集描述。特别是，我们关注来自扩散MR（diffusion MRI）的白质微结构和连接特征集，以及来自结构MR（structural MRI）的灰质面积和厚度特征集。我们研究了应用多视图方法改进非成像表型（包括人口统计学特征（年龄）、运动（力量）和认知（词汇图像））预测的机器学习方法。我们提出了一个可解释的多视图网络（EMV-Net），可以利用不同的解剖视图来提高预测性能。在这个网络中，每个个体解剖视图都经过视图特定的特征提取器处理，然后将每个视图提取的信息融合在一起。

    Large datasets often contain multiple distinct feature sets, or views, that offer complementary information that can be exploited by multi-view learning methods to improve results. We investigate anatomical multi-view data, where each brain anatomical structure is described with multiple feature sets. In particular, we focus on sets of white matter microstructure and connectivity features from diffusion MRI, as well as sets of gray matter area and thickness features from structural MRI. We investigate machine learning methodology that applies multi-view approaches to improve the prediction of non-imaging phenotypes, including demographics (age), motor (strength), and cognition (picture vocabulary). We present an explainable multi-view network (EMV-Net) that can use different anatomical views to improve prediction performance. In this network, each individual anatomical view is processed by a view-specific feature extractor and the extracted information from each view is fused using a l
    
[^12]: 使用单一非自回归Transformer生成遮蔽音频

    Masked Audio Generation using a Single Non-Autoregressive Transformer. (arXiv:2401.04577v1 [cs.SD])

    [http://arxiv.org/abs/2401.04577](http://arxiv.org/abs/2401.04577)

    MAGNeT是一种遮蔽生成序列建模方法，使用单一非自回归Transformer生成具有高质量的音频，并引入了一种新颖的重新评分方法来提高生成音频的质量。同时，MAGNeT还探索了混合版本，可在自回归模式和非自回归模式下生成序列。在实验中证明MAGNeT在文本到音乐和文本到音频生成任务中具有高效性。

    

    我们介绍了一种名为MAGNeT的遮蔽生成序列建模方法，它直接操作多个音频令牌流。与以往的方法不同，MAGNeT由单阶段非自回归Transformer组成。在训练过程中，我们根据遮蔽计划器预测遮蔽令牌的范围，而在推断过程中，我们逐步构建输出序列使用多个解码步骤。为了进一步提高生成音频的质量，我们引入了一种新颖的重新评分方法，其中我们利用外部预训练模型来重新评分和排名MAGNeT的预测结果，这些结果将被用于后续的解码步骤。最后，我们探索了MAGNeT的混合版本，其中我们在自回归模式下生成前几秒钟，而其余的序列则以并行方式进行解码。我们展示了MAGNeT在文本到音乐和文本到音频生成任务中的效率，并进行了广泛的实验验证。

    We introduce MAGNeT, a masked generative sequence modeling method that operates directly over several streams of audio tokens. Unlike prior work, MAGNeT is comprised of a single-stage, non-autoregressive transformer. During training, we predict spans of masked tokens obtained from a masking scheduler, while during inference we gradually construct the output sequence using several decoding steps. To further enhance the quality of the generated audio, we introduce a novel rescoring method in which, we leverage an external pre-trained model to rescore and rank predictions from MAGNeT, which will be then used for later decoding steps. Lastly, we explore a hybrid version of MAGNeT, in which we fuse between autoregressive and non-autoregressive models to generate the first few seconds in an autoregressive manner while the rest of the sequence is being decoded in parallel. We demonstrate the efficiency of MAGNeT for the task of text-to-music and text-to-audio generation and conduct an extensi
    
[^13]: Let's Go Shopping (LGS) -- 用于视觉概念理解的大规模图像文本数据集

    Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding. (arXiv:2401.04575v1 [cs.CV])

    [http://arxiv.org/abs/2401.04575](http://arxiv.org/abs/2401.04575)

    Let's Go Shopping (LGS) dataset is a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites, providing a more efficient way to collect and annotate images for vision and vision-language applications.

    

    神经网络的视觉和视觉-语言应用，如图像分类和字幕，依赖于需要非平凡的数据收集过程的大规模注释数据集。这种耗时的努力限制了大规模数据集的出现，使研究人员和实践者只能选择少数几种选择。因此，我们寻求更有效的方法来收集和注释图像。以往的倡议已经从HTML alt文本和爬取的社交媒体帖子中收集了字幕，但这些数据源存在噪声、稀疏或主观性的问题。因此，我们转向商业购物网站，其数据符合三个标准：干净、信息丰富和流畅。我们介绍了Let's Go Shopping（LGS）数据集，这是一个来自公开可用的电子商务网站的1500万个图像-字幕对的大规模公共数据集。与现有的通用领域数据集相比，LGS图像侧重于前景对象，背景复杂度较低。

    Vision and vision-language applications of neural networks, such as image classification and captioning, rely on large-scale annotated datasets that require non-trivial data-collecting processes. This time-consuming endeavor hinders the emergence of large-scale datasets, limiting researchers and practitioners to a small number of choices. Therefore, we seek more efficient ways to collect and annotate images. Previous initiatives have gathered captions from HTML alt-texts and crawled social media postings, but these data sources suffer from noise, sparsity, or subjectivity. For this reason, we turn to commercial shopping websites whose data meet three criteria: cleanliness, informativeness, and fluency. We introduce the Let's Go Shopping (LGS) dataset, a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites. When compared with existing general-domain datasets, the LGS images focus on the foreground object and have less complex backgro
    
[^14]: 通过谈判评估语言模型的代理能力

    Evaluating Language Model Agency through Negotiations. (arXiv:2401.04536v1 [cs.CL])

    [http://arxiv.org/abs/2401.04536](http://arxiv.org/abs/2401.04536)

    本研究通过谈判游戏的视角，提出共同评估语言模型（LM）的性能和对齐，以更好地反映真实世界的部署条件，并避免数据泄漏。通过评估多轮次和跨模型交互，我们发现了LM的自我对弈和交叉对弈性能。

    

    公司、组织和政府越来越多地利用语言模型（LM）展示类似代理行为的出色能力。随着LM被采用来执行越来越具有自主性的任务，迫切需要可靠且可扩展的评估基准。当前主要是静态的LM基准无法很好地评估此类动态应用。因此，我们提议通过谈判游戏的视角来共同评估LM的性能和对齐。我们认为这个共同任务更好地反映了真实世界的部署条件，并提供了关于LM决策过程的见解。至关重要的是，谈判游戏使我们能够研究多轮次和跨模型交互，调整复杂性，并避免评估中的意外数据泄漏。我们报告了来自几个主要供应商的六个公开可访问的LM在各种谈判游戏上的结果，评估了自我对弈和交叉对弈性能。值得注意的发现包括：（i）开源模式

    Companies, organizations, and governments increasingly exploit Language Models' (LM) remarkable capability to display agent-like behavior. As LMs are adopted to perform tasks with growing autonomy, there exists an urgent need for reliable and scalable evaluation benchmarks. Current, predominantly static LM benchmarks are ill-suited to evaluate such dynamic applications. Thus, we propose jointly evaluating LM performance and alignment through the lenses of negotiation games. We argue that this common task better reflects real-world deployment conditions while offering insights into LMs' decision-making processes. Crucially, negotiation games allow us to study multi-turn, and cross-model interactions, modulate complexity, and side-step accidental data leakage in evaluation. We report results for six publicly accessible LMs from several major providers on a variety of negotiation games, evaluating both self-play and cross-play performance. Noteworthy findings include: (i) open-source mode
    
[^15]: MERA: 俄语LLM综合评估的研究

    MERA: A Comprehensive LLM Evaluation in Russian. (arXiv:2401.04531v1 [cs.CL])

    [http://arxiv.org/abs/2401.04531](http://arxiv.org/abs/2401.04531)

    这项研究提出了MERA，一个多模态俄语基础模型评估指标。该指标包括21个评估任务，涵盖了11个技能领域中生成模型的评估。研究还提出了一种在零样本和少样本固定指令设置下评估FM和LM的方法。

    

    在过去几年中，人工智能研究中最显著的进展之一是基础模型（FM）的发展，其中语言模型（LM）的崛起引人注目。随着模型的规模增大，LM在可衡量的方面展示了提升，并且发展出了新的定性特征。然而，尽管研究人员的关注和LM应用的快速增长，LM的能力、限制和相关风险仍需更好地理解。为了解决这些问题，我们介绍了一种开放的俄语多模态架构评估（MERA）指导基准，用于评估以俄语为导向的基础模型。该基准涵盖了11个技能领域中生成模型的21个评估任务，并被设计为黑盒测试，以确保排除数据泄漏。论文介绍了一种在零样本和少样本固定指令设置下评估FM和LM的方法，并可扩展到其他模态。

    Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). As the models' size increases, LMs demonstrate enhancements in measurable aspects and the development of new qualitative features. However, despite researchers' attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still need to be better understood. To address these issues, we introduce an open Multimodal Evaluation of Russian-language Architectures (MERA), a new instruction benchmark for evaluating foundation models oriented towards the Russian language. The benchmark encompasses 21 evaluation tasks for generative models in 11 skill domains and is designed as a black-box test to ensure the exclusion of data leakage. The paper introduces a methodology to evaluate FMs and LMs in zeroand few-shot fixed instruction settings that can be extended to other modalities. We propose an 
    
[^16]: 《批评的批评》

    The Critique of Critique. (arXiv:2401.04518v1 [cs.CL])

    [http://arxiv.org/abs/2401.04518](http://arxiv.org/abs/2401.04518)

    本文创新性地提出了元批评(MetaCritique)的框架，通过精确度和召回率评估批评的质量，并以F1分数作为整体评分。为了获得可靠的评估结果，引入了原子信息单元(AIUs)来描述批评。元批评提供了自然语言的理由来支持评价结果。

    

    批评作为一种用于评估模型生成内容质量的自然语言描述，在训练、评估和改进大型语言模型(LLMs)中被证明起着重要作用。然而，在评估批评本身质量方面缺乏原则性的理解。本文首创了批评的批评，称为元批评，这是一个评估批评的框架，从精确度和召回率两个方面来评估批评。我们计算精确度和召回率的调和平均值作为整体评分，称为F1分数。为了获得可靠的评估结果，我们提出了原子信息单元(AIUs)，以更精细的方式描述批评。元批评考虑每个AIU，并聚合每个AIU的判断得到整体评分。此外，鉴于评估过程涉及复杂的推理，我们的元批评提供了自然语言的理由来支持评价结果。

    Critique, as a natural language description for assessing the quality of model-generated content, has been proven to play an essential role in the training, evaluation, and refinement of Large Language Models (LLMs). However, there is a lack of principled understanding in evaluating the quality of the critique itself. In this paper, we pioneer the critique of critique, termed MetaCritique, which is a framework to evaluate the critique from two aspects, i.e., factuality as precision score and comprehensiveness as recall score. We calculate the harmonic mean of precision and recall as the overall rating called F1 score. To obtain a reliable evaluation outcome, we propose Atomic Information Units (AIUs), which describe the critique in a more fine-grained manner. MetaCritique takes each AIU into account and aggregates each AIU's judgment for the overall score. Moreover, given the evaluation process involves intricate reasoning, our MetaCritique provides a natural language rationale to supp
    
[^17]: 使用大型语言模型探索基于提示的零样本上位词预测方法

    Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models. (arXiv:2401.04515v1 [cs.CL])

    [http://arxiv.org/abs/2401.04515](http://arxiv.org/abs/2401.04515)

    本文研究了使用大型语言模型进行零样本上位词预测的方法。实验结果表明，语言模型提示的有效性与经典模式之间存在较强的相关性，并且可以通过使用较小的模型进行初步的提示选择。此外，通过使用自动识别的共同下位词将额外信息加入提示，可以改善上位词预测的效果。作者还开发了一种迭代方法来预测更高层次的概念，并在BLESS数据集上取得了显著的质量提升（MAP = 0.8）。

    

    本文研究了使用大型语言模型(LLMs)进行零样本上位词预测的方法。研究采用了基于文本概率计算的方法，并将其应用于各种生成的提示中。实验证明语言模型提示的有效性与经典模式之间存在着较强的相关性，这表明可以通过较小的模型进行初步的提示选择，然后再转向更大的模型。我们还探讨了用于预测共同下位词和通过自动识别的共同下位词将额外信息加入提示以改善上位词预测的提示。我们还开发了一种迭代方法来预测更高层次的概念，进一步提高了在BLESS数据集上的质量（MAP = 0.8）。

    This article investigates a zero-shot approach to hypernymy prediction using large language models (LLMs). The study employs a method based on text probability calculation, applying it to various generated prompts. The experiments demonstrate a strong correlation between the effectiveness of language model prompts and classic patterns, indicating that preliminary prompt selection can be carried out using smaller models before moving to larger ones. We also explore prompts for predicting co-hyponyms and improving hypernymy predictions by augmenting prompts with additional information through automatically identified co-hyponyms. An iterative approach is developed for predicting higher-level concepts, which further improves the quality on the BLESS dataset (MAP = 0.8).
    
[^18]: TechGPT-2.0:一个解决知识图谱构建任务的大型语言模型项目

    TechGPT-2.0: A large language model project to solve the task of knowledge graph construction. (arXiv:2401.04507v1 [cs.CL])

    [http://arxiv.org/abs/2401.04507](http://arxiv.org/abs/2401.04507)

    TechGPT-2.0是一个解决知识图谱构建任务的大型语言模型项目，具有强大的文本处理能力和多个领域的应用能力。

    

    大型语言模型在各种自然语言处理任务中都展现出了强大的性能。本报告介绍了TechGPT-2.0，这是一个项目，旨在增强大型语言模型在知识图谱构建任务中的能力，包括命名实体识别（NER）和关系三元组提取（RTE）。此外，它还作为一个面向中国开源模型社区的LLM可访问研究。我们提供了两个7B大型语言模型的权重和一个专门用于处理长文本的QLoRA权重。值得注意的是，TechGPT-2.0是在华为的Ascend服务器上训练的。继承了TechGPT-1.0的所有功能，它展现出了强大的文本处理能力，特别是在医学和法律领域。此外，我们还为模型引入了新的功能，使其能够处理各个领域的文本，如地理区域、交通、组织机构、文学作品、生物学和自然科学等。

    Large language models have exhibited robust performance across diverse natural language processing tasks. This report introduces TechGPT-2.0, a project designed to enhance the capabilities of large language models specifically in knowledge graph construction tasks, including named entity recognition (NER) and relationship triple extraction (RTE) tasks in NLP applications. Additionally, it serves as a LLM accessible for research within the Chinese open-source model community. We offer two 7B large language model weights and a QLoRA weight specialized for processing lengthy texts.Notably, TechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all functionalities from TechGPT-1.0, it exhibits robust text processing capabilities, particularly in the domains of medicine and law. Furthermore, we introduce new capabilities to the model, enabling it to process texts in various domains such as geographical areas, transportation, organizations, literary works, biology, natural sciences, as
    
[^19]: 最优生存树: 一种动态规划方法

    Optimal Survival Trees: A Dynamic Programming Approach. (arXiv:2401.04489v1 [cs.LG])

    [http://arxiv.org/abs/2401.04489](http://arxiv.org/abs/2401.04489)

    本文提出了一种利用动态规划的生存树方法，通过递归分割人口和预测不同的生存分布来发现复杂的非线性关系。该方法具有优化保证，并通过特殊算法提高了可扩展性，运行时间优于某些启发式算法。

    

    生存分析基于历史数据来研究和预测死亡时间或其他不可重复事件的时间，而某些实例的真实死亡时间是未知的。生存树通过递归地分割人口并在每个叶节点预测不同的生存分布，能够发现紧凑且易于理解的模型中的复杂非线性关系。我们使用动态规划提供了第一个具有优化保证的生存树方法，能够评估启发式算法的优化间隙。我们通过一种特殊的算法来计算深度为2的树，提高了我们方法的可扩展性。实验证明，在获取与最先进技术相当的样本外性能的同时，我们方法的运行时间甚至优于某些启发式算法。

    Survival analysis studies and predicts the time of death, or other singular unrepeated events, based on historical data, while the true time of death for some instances is unknown. Survival trees enable the discovery of complex nonlinear relations in a compact human comprehensible model, by recursively splitting the population and predicting a distinct survival distribution in each leaf node. We use dynamic programming to provide the first survival tree method with optimality guarantees, enabling the assessment of the optimality gap of heuristics. We improve the scalability of our method through a special algorithm for computing trees up to depth two. The experiments show that our method's run time even outperforms some heuristics for realistic cases while obtaining similar out-of-sample performance with the state-of-the-art.
    
[^20]: 以火攻火：对抗启发式生成一个辨别虚假信息的数据集

    Fighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset. (arXiv:2401.04481v1 [cs.CL])

    [http://arxiv.org/abs/2401.04481](http://arxiv.org/abs/2401.04481)

    本文提出了一种基于大型语言模型的方法，通过对其进行引导，自动生成虚假信息的辨别数据集，以解决传统方法标注数据所需的大量人工努力的问题。

    

    大型语言模型（LLM），如GPT、Bard和Llama等，在语言生成能力方面取得了显著的成功。然而，这种成功可能引发对其被滥用的担忧，比如通过生成假新闻和传播错误信息引发大规模激动和仇恨。传统的虚假信息数据集开发方法在标注数据时需要大量人工努力，无法很好地扩展。本文提出了一种基于LLM的方法来创建用于识别虚假信息的银标准数据集。具体而言，给定一个可信新闻文章，我们的方法通过引导LLM自动生成原始文章的摘要版本。我们的方法中的引导作为一种控制机制，用于在生成的摘要中产生特定类型的事实错误，例如错误的数量、错误的归属地等。为了研究这个数据集的实用性，我们进行了实证实验。

    The recent success in language generation capabilities of large language models (LLMs), such as GPT, Bard, Llama etc., can potentially lead to concerns about their possible misuse in inducing mass agitation and communal hatred via generating fake news and spreading misinformation. Traditional means of developing a misinformation ground-truth dataset does not scale well because of the extensive manual effort required to annotate the data. In this paper, we propose an LLM-based approach of creating silver-standard ground-truth datasets for identifying misinformation. Specifically speaking, given a trusted news article, our proposed approach involves prompting LLMs to automatically generate a summarised version of the original article. The prompts in our proposed approach act as a controlling mechanism to generate specific types of factual incorrectness in the generated summaries, e.g., incorrect quantities, false attributions etc. To investigate the usefulness of this dataset, we conduct
    
[^21]: TwinBooster: 结合Barlow Twins和梯度提升的大语言模型协同增强分子属性预测

    TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction. (arXiv:2401.04478v1 [q-bio.BM])

    [http://arxiv.org/abs/2401.04478](http://arxiv.org/abs/2401.04478)

    TwinBooster结合了大语言模型、Barlow Twins和梯度提升，通过整合生物检测方法和分子指纹，实现了对未见过的生物检测方法和分子属性的精确预测，该方法在数据稀缺的情况下展现出了优秀的性能。

    

    药物发现和开发的成功依赖于对分子活性和属性的精确预测。虽然基于计算的分子属性预测显示出了显著的潜力，但其使用迄今为止仅限于大量数据可用的检测方法。在本研究中，我们使用经过微调的大语言模型，结合了基于文本信息的生物检测方法，并使用了一种新颖的自监督学习方法的Siamese神经网络Barlow Twins。该架构利用检测方法信息和分子指纹提取真实的分子信息。TwinBooster通过提供最先进的零样本学习任务，实现了对未见过的生物检测方法和分子的属性预测。值得注意的是，我们的人工智能流水线在FS-Mol基准测试上表现出优秀的性能。这一突破展示了深度学习在通常数据稀缺的关键属性预测任务中的应用。

    The success of drug discovery and development relies on the precise prediction of molecular activities and properties. While in silico molecular property prediction has shown remarkable potential, its use has been limited so far to assays for which large amounts of data are available. In this study, we use a fine-tuned large language model to integrate biological assays based on their textual information, coupled with Barlow Twins, a Siamese neural network using a novel self-supervised learning approach. This architecture uses both assay information and molecular fingerprints to extract the true molecular information. TwinBooster enables the prediction of properties of unseen bioassays and molecules by providing state-of-the-art zero-shot learning tasks. Remarkably, our artificial intelligence pipeline shows excellent performance on the FS-Mol benchmark. This breakthrough demonstrates the application of deep learning to critical property prediction tasks where data is typically scarce.
    
[^22]: 结合基于嵌入和基于语义的模型用于推荐系统中的事后解释

    Combining Embedding-Based and Semantic-Based Models for Post-hoc Explanations in Recommender Systems. (arXiv:2401.04474v1 [cs.IR])

    [http://arxiv.org/abs/2401.04474](http://arxiv.org/abs/2401.04474)

    本论文介绍了一种使用基于嵌入和基于语义的模型相结合的方法来生成推荐系统中的事后解释，并利用基于本体的知识图谱来提高可解释性。这样的框架旨在产生有意义且易于理解的解释，增强用户的信任和满意度。

    

    在当今数据丰富的环境中，推荐系统在决策支持系统中扮演着至关重要的角色。它们为用户提供个性化推荐和对这些推荐的解释。嵌入式模型尽管被广泛使用，但往往缺乏可解释性，这可能损害信任和用户参与度。本论文提出了一种将嵌入式和基于语义的模型相结合的方法，用于在推荐系统中生成事后解释，利用基于本体的知识图谱来提高可解释性。通过在一个结构化框架内组织数据，本体允许对实体之间的复杂关系进行建模，这对于生成解释是必不可少的。通过结合基于嵌入和基于语义的模型用于推荐系统中的事后解释，我们定义的框架旨在产生有意义且易于理解的解释，增强用户的信任和满意度，并潜在地增加推荐的可靠性和效果。

    In today's data-rich environment, recommender systems play a crucial role in decision support systems. They provide to users personalized recommendations and explanations about these recommendations. Embedding-based models, despite their widespread use, often suffer from a lack of interpretability, which can undermine trust and user engagement. This paper presents an approach that combines embedding-based and semantic-based models to generate post-hoc explanations in recommender systems, leveraging ontology-based knowledge graphs to improve interpretability and explainability. By organizing data within a structured framework, ontologies enable the modeling of intricate relationships between entities, which is essential for generating explanations. By combining embedding-based and semantic based models for post-hoc explanations in recommender systems, the framework we defined aims at producing meaningful and easy-to-understand explanations, enhancing user trust and satisfaction, and pot
    
[^23]: 关于高效联邦学习方法在基础模型训练中的调查

    A Survey on Efficient Federated Learning Methods for Foundation Model Training. (arXiv:2401.04472v1 [cs.LG])

    [http://arxiv.org/abs/2401.04472](http://arxiv.org/abs/2401.04472)

    这项调查研究了高效联邦学习方法在基础模型训练中的应用，提出了一个新的分类方法以优化计算和通信效率。该研究还讨论了当前广泛使用的FL框架，并展望了未来的研究潜力。

    

    联邦学习（FL）已成为一种促进隐私保护协作训练的成熟技术。然而，新的FL方法通常只涉及小型深度学习模型的贡献。随着Transformer模型的巨大成功，一个问题出现了：如何使基础模型在FL应用中实施起来？鉴于在FL中计算和通信的时间消耗通常相似，我们引入了一个关于在FL应用中的计算和通信效率方法的新的分类方法。这些方法旨在优化训练时间并减少客户端与服务器之间的通信。我们还研究了目前广泛使用的FL框架，并根据FL研究及其延伸的现有方法讨论了未来的研究潜力。

    Federated Learning (FL) has become an established technique to facilitate privacy-preserving collaborative training. However, new approaches to FL often discuss their contributions involving small deep-learning models only. With the tremendous success of transformer models, the following question arises: What is necessary to operationalize foundation models in an FL application? Knowing that computation and communication often take up similar amounts of time in FL, we introduce a novel taxonomy focused on computational and communication efficiency methods in FL applications. This said, these methods aim to optimize the training time and reduce communication between clients and the server. We also look at the current state of widely used FL frameworks and discuss future research potentials based on existing approaches in FL research and beyond.
    
[^24]: MagicVideo-V2: 多阶段高审美视频生成

    MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation. (arXiv:2401.04468v1 [cs.CV])

    [http://arxiv.org/abs/2401.04468](http://arxiv.org/abs/2401.04468)

    MagicVideo-V2是一个多阶段的高审美视频生成系统，通过集成文本到图像模型、视频运动生成器、参考图像嵌入模块和帧插值模块，实现了以高保真度和流畅性生成高分辨率美学视频的目标。在大规模用户评估中，表现优于其他Text-to-Video系统。

    

    高保真视频生成的不断需求推动了该领域的重大研究。在本工作中，我们介绍了MagicVideo-V2，它将文本到图像模型、视频运动生成器、参考图像嵌入模块和帧插值模块集成到一个端到端的视频生成流程中。凭借这些架构设计，MagicVideo-V2可以生成具有卓越保真度和流畅性的高分辨率美学视频。通过大规模用户评估，它展示了优于领先的Text-to-Video系统如Runway、Pika 1.0、Morph、Moon Valley和Stable Video Diffusion model的性能。

    The growing demand for high-fidelity video generation from textual descriptions has catalyzed significant research in this field. In this work, we introduce MagicVideo-V2 that integrates the text-to-image model, video motion generator, reference image embedding module and frame interpolation module into an end-to-end video generation pipeline. Benefiting from these architecture designs, MagicVideo-V2 can generate an aesthetically pleasing, high-resolution video with remarkable fidelity and smoothness. It demonstrates superior performance over leading Text-to-Video systems such as Runway, Pika 1.0, Morph, Moon Valley and Stable Video Diffusion model via user evaluation at large scale.
    
[^25]: 基于知识注入的图像分类网络增强方法

    Image classification network enhancement methods based on knowledge injection. (arXiv:2401.04441v1 [cs.CV])

    [http://arxiv.org/abs/2401.04441](http://arxiv.org/abs/2401.04441)

    本论文介绍了一种基于知识注入的图像分类网络增强方法，该方法利用人类知识构建深度神经网络训练模型，解决了传统算法难以解释结果原因和难以理解分析预测逻辑的问题。

    

    当前的深度神经网络算法仍然停留在像图像-标签对这样的端到端训练监督方法中，这使得传统的算法难以解释结果的原因，并且预测逻辑难以理解和分析。当前算法没有利用现有的人类知识信息，这使得模型与人类认知模型不一致，不适合人类使用。为了解决以上问题，本发明提供了一种基于人类知识的深度神经网络训练方法，该方法利用人类认知模型构建深度神经网络训练模型，并利用现有的人类知识信息构建深度神经网络训练模型。本文提出了一种多层次分层深度学习算法，由多层次分层深度神经网络结构和多层次分层深度学习框架组成。

    The current deep neural network algorithm still stays in the end-to-end training supervision method like Image-Label pairs, which makes traditional algorithm is difficult to explain the reason for the results, and the prediction logic is difficult to understand and analyze. The current algorithm does not use the existing human knowledge information, which makes the model not in line with the human cognition model and makes the model not suitable for human use. In order to solve the above problems, the present invention provides a deep neural network training method based on the human knowledge, which uses the human cognition model to construct the deep neural network training model, and uses the existing human knowledge information to construct the deep neural network training model. This paper proposes a multi-level hierarchical deep learning algorithm, which is composed of multi-level hierarchical deep neural network architecture and multi-level hierarchical deep learning framework. 
    
[^26]: 使用降维方法对高光谱成像进行异常检测的实证分析

    Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using Dimension Reduction Methods. (arXiv:2401.04437v1 [cs.CV])

    [http://arxiv.org/abs/2401.04437](http://arxiv.org/abs/2401.04437)

    本论文通过对高光谱成像进行异常检测的实证分析，提出了一种基于特征选择的HSI通道还原方法，相对于传统的特征提取方法，在推理阶段的速度快6.90倍。

    

    最近的研究尝试使用高光谱成像（HSI）来检测产品中的异物，因为它能够可视化包括紫外线和红外线在内的不可见波长。考虑到HSI的巨大图像通道，可以考虑使用多种降维方法（如PCA或UMAP）来减少通道数量，但这些方法无法解决以下基本限制：（1）HSI捕捉的延迟问题；（2）对重要通道的解释能力较弱。为了规避上述方法，本文提出了一种基于异常检测的HSI通道还原方法。与特征提取方法（如PCA或UMAP）不同，特征选择可以按影响排序并具有更好的可解释性，因此我们可以重新设计任务优化和成本效益的光谱相机。通过对合成的MVTec AD数据集进行广泛的实验结果验证，我们确认特征选择方法在推理阶段比特征提取方法快6.90倍。

    Recent studies try to use hyperspectral imaging (HSI) to detect foreign matters in products because it enables to visualize the invisible wavelengths including ultraviolet and infrared. Considering the enormous image channels of the HSI, several dimension reduction methods-e.g., PCA or UMAP-can be considered to reduce but those cannot ease the fundamental limitations, as follows: (1) latency of HSI capturing. (2) less explanation ability of the important channels. In this paper, to circumvent the aforementioned methods, one of the ways to channel reduction, on anomaly detection proposed HSI. Different from feature extraction methods (i.e., PCA or UMAP), feature selection can sort the feature by impact and show better explainability so we might redesign the task-optimized and cost-effective spectroscopic camera. Via the extensive experiment results with synthesized MVTec AD dataset, we confirm that the feature selection method shows 6.90x faster at the inference phase compared with feat
    
[^27]: i-Rebalance: 个性化车辆重新定位以实现供需平衡

    i-Rebalance: Personalized Vehicle Repositioning for Supply Demand Balance. (arXiv:2401.04429v1 [cs.AI])

    [http://arxiv.org/abs/2401.04429](http://arxiv.org/abs/2401.04429)

    本文提出了一种名为i-Rebalance的个性化车辆重新定位技术，通过深度强化学习（DRL）估计驾驶员对重新定位推荐的决策。该技术采用顺序重新定位策略，并使用双DRL代理实现供需平衡和驾驶员偏好满意度的优化。

    

    租车平台面临着供需平衡的挑战。现有的车辆重新定位技术通常将司机视为同质化的代理人，并且以确定性的方式重新定位他们，假设他们会遵守重新定位。在本文中，我们考虑了一个更真实和以驾驶员为中心的场景，其中驾驶员具有独特的巡航偏好，并且可以自行决定是否接受推荐。我们提出了一种使用深度强化学习（DRL）的个性化车辆重新定位技术：i-Rebalance。i-Rebalance通过涉及99名真实驾驶员的现场用户研究来估计驾驶员对重新定位推荐的决策。为了同时优化供需平衡和增强偏好满意度，i-Rebalance采用了顺序重新定位策略，并使用双DRL代理：网格代理确定空闲车辆的重新定位顺序，车辆代理为预定义的顺序中的每辆车提供个性化推荐。

    Ride-hailing platforms have been facing the challenge of balancing demand and supply. Existing vehicle reposition techniques often treat drivers as homogeneous agents and relocate them deterministically, assuming compliance with the reposition. In this paper, we consider a more realistic and driver-centric scenario where drivers have unique cruising preferences and can decide whether to take the recommendation or not on their own. We propose i-Rebalance, a personalized vehicle reposition technique with deep reinforcement learning (DRL). i-Rebalance estimates drivers' decisions on accepting reposition recommendations through an on-field user study involving 99 real drivers. To optimize supply-demand balance and enhance preference satisfaction simultaneously, i-Rebalance has a sequential reposition strategy with dual DRL agents: Grid Agent to determine the reposition order of idle vehicles, and Vehicle Agent to provide personalized recommendations to each vehicle in the pre-defined order
    
[^28]: 基于语义概念嵌入的文本相似度估计

    Estimating Text Similarity based on Semantic Concept Embeddings. (arXiv:2401.04422v1 [cs.CL])

    [http://arxiv.org/abs/2401.04422](http://arxiv.org/abs/2401.04422)

    该论文提出了基于MultiNet语义网络的语义概念嵌入方法，结合传统词嵌入可以提高预测目标群组的准确性。

    

    由于其易用性和高准确性，Word2Vec (W2V) 词嵌入在语义表示中取得了巨大成功，包括单词、句子和整个文档的语义表示以及语义相似度估计。然而，它们的缺点是直接从表面表示中提取，不能充分代表人类思维过程，对于高度歧义的词也表现不佳。因此，我们提出了基于MultiNet语义网络(SN)形式化的语义概念嵌入(CE)，以解决这两个问题。在市场目标群体分布任务的评估中，结果显示将传统词嵌入和语义CE结合可以增加预测目标群组的准确性。

    Due to their ease of use and high accuracy, Word2Vec (W2V) word embeddings enjoy great success in the semantic representation of words, sentences, and whole documents as well as for semantic similarity estimation. However, they have the shortcoming that they are directly extracted from a surface representation, which does not adequately represent human thought processes and also performs poorly for highly ambiguous words. Therefore, we propose Semantic Concept Embeddings (CE) based on the MultiNet Semantic Network (SN) formalism, which addresses both shortcomings. The evaluation on a marketing target group distribution task showed that the accuracy of predicted target groups can be increased by combining traditional word embeddings with semantic CEs.
    
[^29]: 对于高效的内容相关比特率阶梯估计的最佳转码分辨率预测

    Optimal Transcoding Resolution Prediction for Efficient Per-Title Bitrate Ladder Estimation. (arXiv:2401.04405v1 [cs.MM])

    [http://arxiv.org/abs/2401.04405](http://arxiv.org/abs/2401.04405)

    本论文提出了直接预测每个预设比特率下的最佳转码分辨率的方法，以实现高效的比特率阶梯构建，并证明了可以无需任何预编码来高效确定内容优化的比特率阶梯。

    

    自适应视频流媒体需要高效的比特率阶梯构建以满足异构网络条件和终端用户需求。针对每个视频的内容优化编码通常会遍历大量的编码参数，以搜索每个视频的帕累托最优工作点。最近，研究人员尝试预测针对预编码开销减少的内容优化比特率阶梯。然而，现有方法通常在帕累托前沿估计编码参数，仍然需要后续的预编码。在本文中，我们提出直接预测每个预设比特率下的最佳转码分辨率，以实现高效的比特率阶梯构建。我们采用时间注意力门控循环网络来捕捉时空特征，并将转码分辨率预测作为多任务分类问题。我们证明，可以无需任何预编码来高效确定内容优化的比特率阶梯。我们的方法能够很好地逼近地面真值。

    Adaptive video streaming requires efficient bitrate ladder construction to meet heterogeneous network conditions and end-user demands. Per-title optimized encoding typically traverses numerous encoding parameters to search the Pareto-optimal operating points for each video. Recently, researchers have attempted to predict the content-optimized bitrate ladder for pre-encoding overhead reduction. However, existing methods commonly estimate the encoding parameters on the Pareto front and still require subsequent pre-encodings. In this paper, we propose to directly predict the optimal transcoding resolution at each preset bitrate for efficient bitrate ladder construction. We adopt a Temporal Attentive Gated Recurrent Network to capture spatial-temporal features and predict transcoding resolutions as a multi-task classification problem. We demonstrate that content-optimized bitrate ladders can thus be efficiently determined without any pre-encoding. Our method well approximates the ground-tr
    
[^30]: IGNITE: 个体化时间序列电子健康记录的生成模型

    IGNITE: Individualized GeNeration of Imputations in Time-series Electronic health records. (arXiv:2401.04402v1 [cs.LG])

    [http://arxiv.org/abs/2401.04402](http://arxiv.org/abs/2401.04402)

    个体化时间序列电子健康记录的生成模型IGNITE通过学习个体的动态特征，结合人口特征和治疗信息，生成个性化的真实值，为个体化医疗提供了有价值的方式。

    

    电子健康记录为推动个体化医疗提供了有价值的方式，可以根据个体差异量身定制治疗方案。为了实现这一目标，许多数据驱动的机器学习和统计模型借助丰富的纵向电子健康记录来研究患者的生理和治疗效果。然而，纵向电子健康记录往往稀疏且存在大量缺失，其中缺失的信息也可能反映患者的健康状况。因此，数据驱动模型在个体化医疗中的成功严重依赖于如何从生理数据、治疗以及数据中的缺失值来表示电子健康记录。为此，我们提出了一种新颖的深度学习模型，该模型可以在个体的人口特征和治疗的条件下，学习多变量数据的患者动态，并生成个性化的真实值。

    Electronic Health Records present a valuable modality for driving personalized medicine, where treatment is tailored to fit individual-level differences. For this purpose, many data-driven machine learning and statistical models rely on the wealth of longitudinal EHRs to study patients' physiological and treatment effects. However, longitudinal EHRs tend to be sparse and highly missing, where missingness could also be informative and reflect the underlying patient's health status. Therefore, the success of data-driven models for personalized medicine highly depends on how the EHR data is represented from physiological data, treatments, and the missing values in the data. To this end, we propose a novel deep-learning model that learns the underlying patient dynamics over time across multivariate data to generate personalized realistic values conditioning on an individual's demographic characteristics and treatments. Our proposed model, IGNITE (Individualized GeNeration of Imputations in
    
[^31]: 通过细粒度模型参数扰动实现机器去学习

    Machine unlearning through fine-grained model parameters perturbation. (arXiv:2401.04385v1 [cs.LG])

    [http://arxiv.org/abs/2401.04385](http://arxiv.org/abs/2401.04385)

    本文提出了一种精细的机器去学习策略，通过细粒度模型参数的扰动来实现用户隐私保护，同时保持可控的计算成本。采用遗忘率和记忆保留率等新的指标来评估去学习效果和模型泛化能力。

    

    机器去学习技术涉及到撤销数据记录和减小该数据对训练模型的影响，从而帮助实现用户隐私保护目标，但会带来显著的计算成本。基于参数扰动的权重去学习是一种通用方法，但通常涉及到全局修改参数。我们提出了精细的Top-K和Random-k参数扰动不精确机器去学习策略，以满足隐私需求同时保持计算成本可控。为了展示我们策略的有效性，我们还解决了评估机器去学习效果的挑战，考虑了模型在去学习和剩余数据上的广义性能。为了更好地评估去学习效果和模型泛化能力，我们提出了新的指标，即遗忘率和记忆保留率。然而，对于不精确的机器去学习，现有的指标无法对去学习程度进行准确量化。

    Machine unlearning techniques, which involve retracting data records and reducing influence of said data on trained models, help with the user privacy protection objective but incur significant computational costs. Weight perturbation-based unlearning is a general approach, but it typically involves globally modifying the parameters. We propose fine-grained Top-K and Random-k parameters perturbed inexact machine unlearning strategies that address the privacy needs while keeping the computational costs tractable.  In order to demonstrate the efficacy of our strategies we also tackle the challenge of evaluating the effectiveness of machine unlearning by considering the model's generalization performance across both unlearning and remaining data. To better assess the unlearning effect and model generalization, we propose novel metrics, namely, the forgetting rate and memory retention rate. However, for inexact machine unlearning, current metrics are inadequate in quantifying the degree of
    
[^32]: 迈向可解释的人工智能（XAI）：一个数据挖掘的视角

    Towards Explainable Artificial Intelligence (XAI): A Data Mining Perspective. (arXiv:2401.04374v1 [cs.AI])

    [http://arxiv.org/abs/2401.04374](http://arxiv.org/abs/2401.04374)

    本研究提出了一种“数据为中心”的视角，探讨了数据收集、处理和分析在可解释的人工智能中的作用。研究将现有工作分为三个类别：深度模型的解释、训练数据的影响和领域知识的见解。通过数据挖掘操作，我们总结了这些XAI方法。

    

    鉴于深度神经网络（DNN）的复杂性和透明度不足，人们进行了大量努力，以使这些系统更具解释性或在可访问的术语中解释其行为。与大多数评论不同，该工作采用“数据为中心”的观点，研究数据收集，处理和分析如何促成可解释的人工智能（XAI）。我们将现有工作分为三类，根据其目的进行分类：深度模型的解释，涉及将数据点与模型输出相关联的特征归因和推理过程；训练数据的影响，研究训练数据细微差异（如数据评估和样本异常）对决策过程的影响；以及领域知识的见解，从数据和模型中发现潜在模式，并促进社会价值和科学发现的新知识。具体而言，我们将XAI方法论提炼为数据挖掘操作。

    Given the complexity and lack of transparency in deep neural networks (DNNs), extensive efforts have been made to make these systems more interpretable or explain their behaviors in accessible terms. Unlike most reviews, which focus on algorithmic and model-centric perspectives, this work takes a "data-centric" view, examining how data collection, processing, and analysis contribute to explainable AI (XAI). We categorize existing work into three categories subject to their purposes: interpretations of deep models, referring to feature attributions and reasoning processes that correlate data points with model outputs; influences of training data, examining the impact of training data nuances, such as data valuation and sample anomalies, on decision-making processes; and insights of domain knowledge, discovering latent patterns and fostering new knowledge from data and models to advance social values and scientific discovery. Specifically, we distill XAI methodologies into data mining op
    
[^33]: 在扩散过程中提取代表性特征，用于从一个样本中提取草图

    Representative Feature Extraction During Diffusion Process for Sketch Extraction with One Example. (arXiv:2401.04362v1 [cs.CV])

    [http://arxiv.org/abs/2401.04362](http://arxiv.org/abs/2401.04362)

    本论文介绍了一种名为DiffSketch的草图生成方法，通过选择代表性特征并结合生成模型进行提取，实现从图像中生成多样化的草图。与现有方法相比，该方法在提取草图的性能上具有显著的优势。

    

    我们介绍了DiffSketch，一种从图像中生成各种风格化草图的方法。我们的方法主要是从预训练的扩散模型中选择代表性特征，以提取草图。这种新颖的草图生成方法只需要一个手工绘制的草图作为训练样本。此外，通过将训练好的生成器提取出一种简化的提取器，确保了高效的草图提取。我们通过分析选择去噪扩散特征，并将这些特征与VAE特征结合，生成草图。此外，我们提出了一种使用条件生成方法进行模型训练的采样方案。通过一系列的比较，我们验证了精简的DiffSketch不仅优于现有的最先进的草图提取方法，而且在提取草图的任务上也超越了基于扩散的风格化方法。

    We introduce DiffSketch, a method for generating a variety of stylized sketches from images. Our approach focuses on selecting representative features from the rich semantics of deep features within a pretrained diffusion model. This novel sketch generation method can be trained with one manual drawing. Furthermore, efficient sketch extraction is ensured by distilling a trained generator into a streamlined extractor. We select denoising diffusion features through analysis and integrate these selected features with VAE features to produce sketches. Additionally, we propose a sampling scheme for training models using a conditional generative approach. Through a series of comparisons, we verify that distilled DiffSketch not only outperforms existing state-of-the-art sketch extraction methods but also surpasses diffusion-based stylization methods in the task of extracting sketches.
    
[^34]: 通过对比学习提高知识驱动对话的稳健性

    Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning. (arXiv:2401.04361v1 [cs.CL])

    [http://arxiv.org/abs/2401.04361](http://arxiv.org/abs/2401.04361)

    本文提出了一种基于实体对比学习框架来提高知识驱动对话（KGD）系统的稳健性，通过创建正负样本以应对实际噪音，如错别字和不完整的知识图谱。

    

    知识驱动的对话（KGD）通过给定的对话环境和外部知识（如知识图谱）来生成信息丰富的回应。最近，大型语言模型（LLMs）和预训练技术的出现为知识驱动的对话带来了巨大的成功。然而，在实际应用中构建KGD系统时，难免会遇到各种实际的噪音。例如，对话环境可能涉及错别字和缩写等扰动。此外，知识图谱通常存在不完整性，也可能包含错误和过时的事实。这些实际的噪音给KGD系统的稳健性带来了挑战，并阻碍了它们在真实世界中的应用。本文提出了一种基于实体对比学习框架来提高KGD稳健性的方法。具体而言，我们利用KGD样本中的实体信息创建其正样本和负样本。

    Knowledge-grounded dialogue (KGD) learns to generate an informative response based on a given dialogue context and external knowledge (\emph{e.g.}, knowledge graphs; KGs). Recently, the emergence of large language models (LLMs) and pre-training techniques has brought great success to knowledge-grounded dialogue. However, when building KGD systems in real applications, there are various real-world noises that are inevitable to face. For example, the dialogue context might involve perturbations such as misspellings and abbreviations. In addition, KGs typically suffer from incompletion and also might contain erroneous and outdated facts. Such real-world noises pose a challenge to the robustness of KGD systems and hinder their applications in the real world. In this paper, we propose an entity-based contrastive learning framework for improving the robustness of KGD. Specifically, we make use of the entity information in a KGD sample to create both its positive and negative samples which in
    
[^35]: 迭代反馈网络用于无监督点云配准

    Iterative Feedback Network for Unsupervised Point Cloud Registration. (arXiv:2401.04357v1 [cs.CV])

    [http://arxiv.org/abs/2401.04357](http://arxiv.org/abs/2401.04357)

    本文提出了一种用于无监督点云配准的迭代反馈网络 (IFNet)，通过重新路由高层特征来丰富低层特征的表示，有效解决了现有方法中缺乏高层信息到低层信息的指导的问题。

    

    点云配准作为计算机视觉中的基本问题，旨在寻找对齐一对点云的最佳变换。在大多数现有方法中，信息传递通常是正向传递，因此缺乏从高层信息到低层信息的指导。此外，过多的高层信息可能过于冗余，直接使用可能与原始低层信息发生冲突。本文提出了一种新颖的迭代反馈网络（IFNet）用于无监督点云配准，其中通过重新路由后续高层特征有效地丰富了低层特征的表示。具体而言，我们的IFNet建立在一系列反馈配准块（FRB）模块上，每个模块负责生成前向刚性变换和反馈高层特征。这些FRB模块被级联和经过时间展开。此外，反馈变换器被设计用来增强特定层级特征之间的关系

    As a fundamental problem in computer vision, point cloud registration aims to seek the optimal transformation for aligning a pair of point clouds. In most existing methods, the information flows are usually forward transferring, thus lacking the guidance from high-level information to low-level information. Besides, excessive high-level information may be overly redundant, and directly using it may conflict with the original low-level information. In this paper, we propose a novel Iterative Feedback Network (IFNet) for unsupervised point cloud registration, in which the representation of low-level features is efficiently enriched by rerouting subsequent high-level features. Specifically, our IFNet is built upon a series of Feedback Registration Block (FRB) modules, with each module responsible for generating the feedforward rigid transformation and feedback high-level features. These FRB modules are cascaded and recurrently unfolded over time. Further, the Feedback Transformer is desig
    
[^36]: 在可变工况下的变点检测综合剩余寿命估计模型

    A Change Point Detection Integrated Remaining Useful Life Estimation Model under Variable Operating Conditions. (arXiv:2401.04351v1 [cs.LG])

    [http://arxiv.org/abs/2401.04351](http://arxiv.org/abs/2401.04351)

    本研究提出了一种新的时间动态学习模型，用于在可变工况下检测设备的变点，并利用这些变点来提高剩余寿命估计的准确性。

    

    通过提供退化过程的开始信息，健康状态评估成为可靠的复杂设备剩余寿命（RUL）估计的重要前提。本文提出了一种新颖的基于时间动态学习的模型，用于检测个体设备的变点，即使在可变的工况下，并利用所学到的变点来提高RUL估计的准确性。在离线模型开发过程中，多变量传感器数据被分解，以学习可推广和代表多个工况下正常运行动态的融合时间相关特征。基于这些学到的时间特征，构建监控统计值和控制限制阈值以动态地检测设备级别的变点。然后，检测到的变点为训练基于长短期记忆（LSTM）的RUL估计模型提供退化数据标记。

    By informing the onset of the degradation process, health status evaluation serves as a significant preliminary step for reliable remaining useful life (RUL) estimation of complex equipment. This paper proposes a novel temporal dynamics learning-based model for detecting change points of individual devices, even under variable operating conditions, and utilises the learnt change points to improve the RUL estimation accuracy. During offline model development, the multivariate sensor data are decomposed to learn fused temporal correlation features that are generalisable and representative of normal operation dynamics across multiple operating conditions. Monitoring statistics and control limit thresholds for normal behaviour are dynamically constructed from these learnt temporal features for the unsupervised detection of device-level change points. The detected change points then inform the degradation data labelling for training a long short-term memory (LSTM)-based RUL estimation model
    
[^37]: 使用量化扩散模型的内存高效个性化

    Memory-Efficient Personalization using Quantized Diffusion Model. (arXiv:2401.04339v1 [cs.CV])

    [http://arxiv.org/abs/2401.04339](http://arxiv.org/abs/2401.04339)

    本文研究了使用量化扩散模型进行内存高效个性化的方法，提出了两个策略来解决基线模型中主题和提示质量之间的权衡问题。

    

    亿级参数扩散模型（如Stable Diffusion XL、Imagen和Dall-E3）的崛起显著推动了生成型人工智能领域的发展。然而，由于资源需求高和推理速度慢，它们的大规模性质在微调和部署中带来了挑战。本文探索了对量化扩散模型进行微调的相对未开发但有前景的领域。我们通过定制三个模型（用于微调量化参数的PEQA，用于后期量化的Q-Diffusion和个性化的DreamBooth），建立了一个强大的基线模型。我们的分析揭示了基线模型中主题和提示质量之间的明显权衡。为了解决这些问题，我们引入了两个策略，灵感来自于扩散模型中不同时间步长的不同角色：S1在选择的时间间隔内仅优化一组微调参数，S2创建多个微调参数组，每个组专门用于不同的时间步长间隔。

    The rise of billion-parameter diffusion models like Stable Diffusion XL, Imagen, and Dall-E3 markedly advances the field of generative AI. However, their large-scale nature poses challenges in fine-tuning and deployment due to high resource demands and slow inference speed. This paper ventures into the relatively unexplored yet promising realm of fine-tuning quantized diffusion models. We establish a strong baseline by customizing three models: PEQA for fine-tuning quantization parameters, Q-Diffusion for post-training quantization, and DreamBooth for personalization. Our analysis reveals a notable trade-off between subject and prompt fidelity within the baseline model. To address these issues, we introduce two strategies, inspired by the distinct roles of different timesteps in diffusion models: S1 optimizing a single set of fine-tuning parameters exclusively at selected intervals, and S2 creating multiple fine-tuning parameter sets, each specialized for different timestep intervals. 
    
[^38]: 深度高效的私密领域生成用于子图联邦学习

    Deep Efficient Private Neighbor Generation for Subgraph Federated Learning. (arXiv:2401.04336v1 [cs.LG])

    [http://arxiv.org/abs/2401.04336](http://arxiv.org/abs/2401.04336)

    本文提出了FedDEP，用于解决子图联邦学习中的信息传播不完整的问题，并提出了一系列新颖的技术设计，包括深度邻居生成和高效的私密领域生成。

    

    在现实应用中，巨大图通常以非中心化子图的形式由多个数据所有者分散存储。为了保护数据隐私，在不损害数据隐私的前提下，考虑到子图联邦学习（subgraph FL）场景是很自然的，其中每个本地客户端持有整个全局图的子图，以获取全局一般化的图挖掘模型。为了解决由于缺少跨子图邻居而导致的局部子图上的信息传播不完整的独特挑战，以前的工作通过缺失邻居生成器和GNN的联合FL来增加本地邻域。然而，它们在FL的效用性、效率性和隐私目标方面存在深层次的限制。在这项工作中，我们提出了FedDEP来全面解决子图FL中的这些挑战。FedDEP包括一系列新颖的技术设计：(1) 利用潜在缺失邻居的GNN嵌入进行深度邻居生成；(2) Effic...

    Behemoth graphs are often fragmented and separately stored by multiple data owners as distributed subgraphs in many realistic applications. Without harming data privacy, it is natural to consider the subgraph federated learning (subgraph FL) scenario, where each local client holds a subgraph of the entire global graph, to obtain globally generalized graph mining models. To overcome the unique challenge of incomplete information propagation on local subgraphs due to missing cross-subgraph neighbors, previous works resort to the augmentation of local neighborhoods through the joint FL of missing neighbor generators and GNNs. Yet their technical designs have profound limitations regarding the utility, efficiency, and privacy goals of FL. In this work, we propose FedDEP to comprehensively tackle these challenges in subgraph FL. FedDEP consists of a series of novel technical designs: (1) Deep neighbor generation through leveraging the GNN embeddings of potential missing neighbors; (2) Effic
    
[^39]: 大规模语言模型与机器人技术：机遇、挑战和前景

    Large Language Models for Robotics: Opportunities, Challenges, and Perspectives. (arXiv:2401.04334v1 [cs.RO])

    [http://arxiv.org/abs/2401.04334](http://arxiv.org/abs/2401.04334)

    大规模语言模型与机器人技术的结合在机器人任务规划中具有巨大潜力，但在与复杂环境互动的实体任务中存在挑战。本研究提出了一个通过多模态GPT-4V的框架来增强实体任务规划效果，并在多样化的数据集上验证了其有效性。

    

    大规模语言模型（LLMs）经历了重大扩展，并在各个领域得到越来越广泛的应用。特别是在机器人任务规划领域，LLMs利用其高级推理和语言理解能力，根据自然语言指令制定精确高效的行动计划。然而，在与复杂环境互动的实体任务中，仅有文本的LLMs常常面临与机器人视觉感知不兼容的挑战。本研究对LLMs和多模态LLMs在各种机器人任务中的新兴集成进行了全面概述。此外，我们提出了一个框架，利用多模态GPT-4V通过自然语言指令和机器人视觉感知的结合来增强实体任务规划。基于多样化的数据集，我们的结果表明，GPT-4V在实体任务中有效地提升了机器人的性能。这项广泛的LLMs调研和评估

    Large language models (LLMs) have undergone significant expansion and have been increasingly integrated across various domains. Notably, in the realm of robot task planning, LLMs harness their advanced reasoning and language comprehension capabilities to formulate precise and efficient action plans based on natural language instructions. However, for embodied tasks, where robots interact with complex environments, text-only LLMs often face challenges due to a lack of compatibility with robotic visual perception. This study provides a comprehensive overview of the emerging integration of LLMs and multimodal LLMs into various robotic tasks. Additionally, we propose a framework that utilizes multimodal GPT-4V to enhance embodied task planning through the combination of natural language instructions and robot visual perceptions. Our results, based on diverse datasets, indicate that GPT-4V effectively enhances robot performance in embodied tasks. This extensive survey and evaluation of LLMs
    
[^40]: 将图神经网络与分数阶连续动力学相结合：鲁棒性研究

    Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study. (arXiv:2401.04331v1 [cs.LG])

    [http://arxiv.org/abs/2401.04331](http://arxiv.org/abs/2401.04331)

    本文详细研究了图神经分数阶微分方程模型的鲁棒性，通过实施分数阶微积分，模型在特征更新过程中考虑了长期记忆，对抗性条件下的性能仍未得到广泛探究。

    

    本文严格研究了图神经分数阶微分方程(FDE)模型的鲁棒性。该框架通过实施分数阶Caputo导数，超越了传统的图神经整数阶常微分方程(ODE)模型。利用分数阶微积分，我们的模型在特征更新过程中考虑了长期记忆，与传统图神经ODE模型中的无记忆马尔可夫更新不同。图神经FDE模型相对于图神经ODE模型在没有攻击或扰动的环境中已经被证明具有优势。尽管传统的图神经ODE模型在现有文献中已经被验证在存在对抗性攻击时具有一定的稳定性和弹性，但图神经FDE模型的鲁棒性，特别是在对抗性条件下的表现，仍未得到广泛探究。本文对图神经FDE模型的鲁棒性进行了详细评估。

    In this work, we rigorously investigate the robustness of graph neural fractional-order differential equation (FDE) models. This framework extends beyond traditional graph neural (integer-order) ordinary differential equation (ODE) models by implementing the time-fractional Caputo derivative. Utilizing fractional calculus allows our model to consider long-term memory during the feature updating process, diverging from the memoryless Markovian updates seen in traditional graph neural ODE models. The superiority of graph neural FDE models over graph neural ODE models has been established in environments free from attacks or perturbations. While traditional graph neural ODE models have been verified to possess a degree of stability and resilience in the presence of adversarial attacks in existing literature, the robustness of graph neural FDE models, especially under adversarial conditions, remains largely unexplored. This paper undertakes a detailed assessment of the robustness of graph 
    
[^41]: BD-MSA: 多尺度特征信息聚合引导的身体解耦高分辨率遥感影像变化检测方法

    BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation. (arXiv:2401.04330v1 [cs.CV])

    [http://arxiv.org/abs/2401.04330](http://arxiv.org/abs/2401.04330)

    提出了一种名为BD-MSA的新的变化检测模型，通过在训练和预测阶段收集特征图的全局和局部特征信息，成功提取了变化区域的边界信息，并将变化区域的主体与边界分离。

    

    遥感图像变化检测旨在检测同一地方拍摄的两个时期的图像之间的差异。深度学习已被广泛应用于遥感图像变化检测任务，在结果识别方面取得了显著成果。然而，由于卫星的拍摄角度、薄云层的影响以及特定的光照条件，在一些遥感摄影中，变化区域的模糊边缘问题无法通过当前的遥感图像变化检测算法正确处理。为了解决这个问题，我们提出了一种身体解耦多尺度特征聚合变化检测（BD-MSA）的新模型，在训练和预测阶段在特征图的通道和空间维度中收集全局和局部特征图信息。这种方法允许我们成功提取变化区域的边界信息，并将变化区域的主体与其边界分离。许多研究表明，评估指标是评价遥感图像变化检测结果质量的重要标准。

    The purpose of remote sensing image change detection (RSCD) is to detect differences between bi-temporal images taken at the same place. Deep learning has been extensively used to RSCD tasks, yielding significant results in terms of result recognition. However, due to the shooting angle of the satellite, the impacts of thin clouds, and certain lighting conditions, the problem of fuzzy edges in the change region in some remote sensing photographs cannot be properly handled using current RSCD algorithms. To solve this issue, we proposed a Body Decouple Multi-Scale by fearure Aggregation change detection (BD-MSA), a novel model that collects both global and local feature map information in the channel and space dimensions of the feature map during the training and prediction phases. This approach allows us to successfully extract the change region's boundary information while also divorcing the change region's main body from its boundary. Numerous studies have shown that the assessment me
    
[^42]: 更好地了解您的需求：通过类比推理增强的LLMs实现对营销人员需求的结构化理解

    Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. (arXiv:2401.04319v1 [cs.CL])

    [http://arxiv.org/abs/2401.04319](http://arxiv.org/abs/2401.04319)

    本文探索了一种通过类比推理增强的LLMs来实现对营销人员需求的结构化理解的新方式，使非专业营销人员能够仅凭需求的自然语言形式选择目标用户。

    

    本文探讨了一种新的用户定位方式，即非专业营销人员可以仅凭需求的自然语言形式选择目标用户。解决这个问题的关键在于如何将自然语言转化为实际的结构化逻辑语言，即对营销人员需求的结构化理解。考虑到大型语言模型（LLMs）出色的自然语言处理能力，我们尝试利用LLMs来解决这个问题。过去的研究表明，通过链式思考（CoT）提示可以有效增强LLMs的推理能力。但是现有方法仍然存在一些限制：（1）先前的方法要么使用简单的“让我们一步一步地思考”提示，要么在演示中提供固定的示例而不考虑提示和问题之间的兼容性，在一些复杂的推理任务（如结构化语言转换）中使LLMs无效。(2) 先前的方法通常在闭源模型或过度实现的模型中实现。

    In this paper, we explore a new way for user targeting, where non-expert marketers could select their target users solely given demands in natural language form. The key to this issue is how to transform natural languages into practical structured logical languages, i.e., the structured understanding of marketer demands. Considering the impressive natural language processing ability of large language models (LLMs), we try to leverage LLMs to solve this issue. Past research indicates that the reasoning ability of LLMs can be effectively enhanced through chain-of-thought (CoT) prompting. But existing methods still have some limitations: (1) Previous methods either use simple "Let's think step by step" spells or provide fixed examples in demonstrations without considering compatibility between prompts and questions, making LLMs ineffective in some complex reasoning tasks such as structured language transformation. (2) Previous methods are often implemented in closed-source models or exces
    
[^43]: StarCraftImage: 一种用于多智能体环境空间推理方法原型设计的数据集

    StarCraftImage: A Dataset For Prototyping Spatial Reasoning Methods For Multi-Agent Environments. (arXiv:2401.04290v1 [cs.CV])

    [http://arxiv.org/abs/2401.04290](http://arxiv.org/abs/2401.04290)

    这个论文提出了一种使用StarCraft II游戏回放构建的基准数据集，该数据集可以用于原型设计多智能体环境中的空间推理方法，同时具有与MNIST和CIFAR10相似的易用性。

    

    多智能体环境中的空间推理任务对于多个应用很重要，如事件预测、智能体类型识别或缺失数据插补等（例如，在传感器网络上的自主监视和强化学习的子任务）。StarCraft II游戏回放记录了智能（和对抗性）的多智能体行为，可以用作这些任务的测试平台；然而，提取出简单和标准化的表示以用于原型设计这些任务非常繁琐并且难以复现。相比之下，尽管MNIST和CIFAR10极其简单，但它们已经实现了机器学习方法的快速原型设计和复现能力。为了遵循这些数据集的简单性，我们基于展示复杂的多智能体行为的StarCraft II游戏回放构建了一个用于空间推理的基准数据集，同时易于使用就像MNIST和CIFAR10一样。具体来说，我们仔细总结了255个连续游戏状态的窗口，创建了360万个摘要图像。

    Spatial reasoning tasks in multi-agent environments such as event prediction, agent type identification, or missing data imputation are important for multiple applications (e.g., autonomous surveillance over sensor networks and subtasks for reinforcement learning (RL)). StarCraft II game replays encode intelligent (and adversarial) multi-agent behavior and could provide a testbed for these tasks; however, extracting simple and standardized representations for prototyping these tasks is laborious and hinders reproducibility. In contrast, MNIST and CIFAR10, despite their extreme simplicity, have enabled rapid prototyping and reproducibility of ML methods. Following the simplicity of these datasets, we construct a benchmark spatial reasoning dataset based on StarCraft II replays that exhibit complex multi-agent behaviors, while still being as easy to use as MNIST and CIFAR10. Specifically, we carefully summarize a window of 255 consecutive game states to create 3.6 million summary images 
    
[^44]: 稳定扩散技术的鲁棒图像水印

    Robust Image Watermarking using Stable Diffusion. (arXiv:2401.04247v1 [cs.CV])

    [http://arxiv.org/abs/2401.04247](http://arxiv.org/abs/2401.04247)

    本研究提出了一种名为ZoDiac的方法，利用稳定扩散模型在可训练的潜在空间中注入水印，从而使水印能够在受攻击时可靠检测到，对最先进的水印攻击具有很强的鲁棒性，优于现有的水印方法。

    

    图像水印对于追踪图像来源和声明所有权非常重要。随着生成模型（如稳定扩散）的出现，能够创建虚假但逼真的图像，水印成为了尤为重要的任务，例如使生成的图像可靠地辨认出来。然而，正是这种稳定扩散技术可以移除使用现有方法注入的水印。为了解决这个问题，我们提出了一种名为ZoDiac的方法，它使用预训练的稳定扩散模型将水印注入到可训练的潜在空间中，从而在受攻击时仍然可以可靠地在潜在向量中检测到水印。我们在三个基准数据集 MS-COCO、DiffusionDB 和 WikiArt 上评估了 ZoDiac，并发现 ZoDiac 对于最先进的水印攻击具有很强的鲁棒性，水印检测率超过98%，误报率低于6.4%，优于现有的水印方法。我们的研究表明，稳定扩散是一种有前途的方法。

    Watermarking images is critical for tracking image provenance and claiming ownership. With the advent of generative models, such as stable diffusion, able to create fake but realistic images, watermarking has become particularly important, e.g., to make generated images reliably identifiable. Unfortunately, the very same stable diffusion technology can remove watermarks injected using existing methods. To address this problem, we present a ZoDiac, which uses a pre-trained stable diffusion model to inject a watermark into the trainable latent space, resulting in watermarks that can be reliably detected in the latent vector, even when attacked. We evaluate ZoDiac on three benchmarks, MS-COCO, DiffusionDB, and WikiArt, and find that ZoDiac is robust against state-of-the-art watermark attacks, with a watermark detection rate over 98% and a false positive rate below 6.4%, outperforming state-of-the-art watermarking methods. Our research demonstrates that stable diffusion is a promising appr
    
[^45]: FunnyNet-W:视频中野外有趣瞬间的多模态学习

    FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild. (arXiv:2401.04210v1 [cs.CV])

    [http://arxiv.org/abs/2401.04210](http://arxiv.org/abs/2401.04210)

    提出了FunnyNet-W，一个多模态模型用于预测视频中的有趣瞬间。该模型利用视觉、音频和文本数据以及交叉和自注意力机制，并且采用无监督方法获得训练标签。

    

    在观看喜剧时自动理解有趣的瞬间（即使让人发笑的瞬间）是具有挑战性的，因为它们涉及到各种特征，如肢体语言、对话和文化。在本文中，我们提出了FunnyNet-W，它是一个依靠视觉、音频和文本数据的交叉和自注意力模型，用于预测视频中的有趣瞬间。与大多数依赖于字幕形式的标注数据的方法不同，在这项工作中，我们利用自然与视频一起出现的多模态数据：（a）视频帧，因为它们包含了场景理解所必需的视觉信息，（b）音频，因为它包含与有趣瞬间相关的更高级别的线索，如语调、音高和停顿，以及（c）由语音转文本模型自动提取的文本，因为它可以在经过大型语言模型处理后提供丰富的信息。为了获得训练标签，我们提出了一种无监督的方法来发现和标记有趣的音频瞬间。我们在五个数据集上进行了实验。

    Automatically understanding funny moments (i.e., the moments that make people laugh) when watching comedy is challenging, as they relate to various features, such as body language, dialogues and culture. In this paper, we propose FunnyNet-W, a model that relies on cross- and self-attention for visual, audio and text data to predict funny moments in videos. Unlike most methods that rely on ground truth data in the form of subtitles, in this work we exploit modalities that come naturally with videos: (a) video frames as they contain visual information indispensable for scene understanding, (b) audio as it contains higher-level cues associated with funny moments, such as intonation, pitch and pauses and (c) text automatically extracted with a speech-to-text model as it can provide rich information when processed by a Large Language Model. To acquire labels for training, we propose an unsupervised approach that spots and labels funny audio moments. We provide experiments on five datasets: 
    
[^46]: 从AI教练学习赛车：多模态自动驾驶解释对驾驶表现、认知负荷、专业知识和信任的影响

    Learning Racing From an AI Coach: Effects of Multimodal Autonomous Driving Explanations on Driving Performance, Cognitive Load, Expertise, and Trust. (arXiv:2401.04206v1 [cs.HC])

    [http://arxiv.org/abs/2401.04206](http://arxiv.org/abs/2401.04206)

    本研究测试了一种AI驾驶教练的解释对驾驶表现、认知负荷、专业知识和信任的影响。结果显示，AI驾驶教练对于教授新手驾驶技能是有帮助的，并且信息类型和呈现方式对表现结果有影响。

    

    在一项前后实验中（n=41），我们测试了模仿人类驾驶专家的指导说明的AI教练的解释沟通对驾驶表现、认知负荷、信心、专业知识和信任的影响。参与者被分为四个组，评估了AI教练解释的两个维度：信息类型（'what'和'why'-type解释）和呈现方式（听觉和视觉）。通过采访，我们描述了参与者的学习过程。结果表明，AI驾驶教练对于教授新手驾驶技能是有用的。比较各组之间，我们发现信息的类型和方式对性能结果有影响。我们将差异归因于信息如何引导注意力，减轻不确定性，并影响参与者经历的负荷过载。这反过来又影响了信心和信任水平。

    In a pre-post experiment (n = 41), we test the impact of an AI Coach's explanatory communications modeled after the instructions of human driving experts. Participants were divided into four (4) groups to assess two (2) dimensions of the AI coach's explanations: information type ('what' and 'why'-type explanations) and presentation modality (auditory and visual). We directly compare how AI Coaching sessions employing these techniques impact driving performance, cognitive load, confidence, expertise, and trust in an observation learning context. Through interviews, we delineate the learning process of our participants. Results show that an AI driving coach can be useful for teaching performance driving skills to novices. Comparing between groups, we find the type and modality of information influences performance outcomes. We attribute differences to how information directed attention, mitigated uncertainty, and influenced overload experienced by participants. These, in turn, affected h
    
[^47]: 无指导下多环境中的好奇心与熵驱动强化学习

    Curiosity & Entropy Driven Unsupervised RL in Multiple Environments. (arXiv:2401.04198v1 [cs.LG])

    [http://arxiv.org/abs/2401.04198](http://arxiv.org/abs/2401.04198)

    本论文提出了一种无指导的强化学习方法，在多个环境下通过好奇心和熵驱动实现了性能的改进。

    

    本论文的作者们提出了一种名为alpha-MEPOL的方法来解决多环境下的无指导强化学习问题。他们通过使用整个环境类别的交互来预训练一个与任务无关的探索策略，然后利用监督来对各种任务进行微调。我们在原始工作的基础上进行了扩展，旨在提高性能。我们主要提出并实验了五个新的修改方法：使用基于熵的概率分布来采样轨迹，动态alpha，更高的KL散度阈值，以好奇心驱动的探索，以及基于好奇心的alpha分位数采样。动态alpha和更高的KL散度阈值都相对于早期工作的基线方法有了显著的改进。当样本空间较小时，PDF采样没有提供任何改进，因为它与基线方法近似等价。在高维环境中，这些修改方法的添加提高了性能。

    The authors of 'Unsupervised Reinforcement Learning in Multiple environments' propose a method, alpha-MEPOL, to tackle unsupervised RL across multiple environments. They pre-train a task-agnostic exploration policy using interactions from an entire environment class and then fine-tune this policy for various tasks using supervision. We expanded upon this work, with the goal of improving performance. We primarily propose and experiment with five new modifications to the original work: sampling trajectories using an entropy-based probability distribution, dynamic alpha, higher KL Divergence threshold, curiosity-driven exploration, and alpha-percentile sampling on curiosity. Dynamic alpha and higher KL-Divergence threshold both provided a significant improvement over the baseline from the earlier work. PDF-sampling failed to provide any improvement due to it being approximately equivalent to the baseline method when the sample space is small. In high-dimensional environments, the addition
    
[^48]: 软件架构的交互式多目标进化优化

    Interactive Multi-Objective Evolutionary Optimization of Software Architectures. (arXiv:2401.04192v1 [cs.SE])

    [http://arxiv.org/abs/2401.04192](http://arxiv.org/abs/2401.04192)

    这篇论文研究了如何将交互式进化计算应用于软件架构设计中，以在搜索过程中融入人的判断，既考虑定量标准又考虑定性标准。

    

    在软件规范过程中，设计师通常需要评估不同的架构选择以确保满足质量标准。即使这些质量方面可以用多个软件度量来表示，其他定性因素无法通过数值测量，而是从工程师的专业知识和先前经验中提取出来的。实际上，发现不仅仅是解决方案的强点，还有弱点，似乎更符合人类决策的方式。将人类纳入搜索过程中为面向人类的活动提供了新的挑战，特别是在早期分析阶段。本文探讨了交互式进化计算如何作为将人类判断融入搜索过程的基础。提出了一种交互式方法来发现软件架构，其中同时应用定量和定性标准来引导搜索过程。

    While working on a software specification, designers usually need to evaluate different architectural alternatives to be sure that quality criteria are met. Even when these quality aspects could be expressed in terms of multiple software metrics, other qualitative factors cannot be numerically measured, but they are extracted from the engineer's know-how and prior experiences. In fact, detecting not only strong but also weak points in the different solutions seems to fit better with the way humans make their decisions. Putting the human in the loop brings new challenges to the search-based software engineering field, especially for those human-centered activities within the early analysis phase. This paper explores how the interactive evolutionary computation can serve as a basis for integrating the human's judgment into the search process. An interactive approach is proposed to discover software architectures, in which both quantitative and qualitative criteria are applied to guide a 
    
[^49]: 高效选择性音频掩蔽多模态瓶颈Transformer用于音视频分类

    Efficient Selective Audio Masked Multimodal Bottleneck Transformer for Audio-Video Classification. (arXiv:2401.04154v1 [cs.CV])

    [http://arxiv.org/abs/2401.04154](http://arxiv.org/abs/2401.04154)

    这项研究提出了一种高效选择性音频掩蔽多模态瓶颈Transformer用于音视频分类，通过音视频Transformer提取时空表示并结合自监督目标进行训练，实现了有效的多模态学习和语义音频活动的学习。

    

    音频和视频是主流媒体平台（如YouTube）中最常见的两种形式。为了有效地从多模态视频中学习，本文提出了一种新的音视频识别方法，称为音视频Transformer（AVT），利用视频Transformer的有效时空表示来提高动作识别的准确性。为了进行多模态融合，简单地通过跨模态Transformer连接多模态令牌会占用大量计算和内存资源，因此我们通过音视频瓶颈Transformer降低了跨模态复杂性。为了提高多模态Transformer的学习效率，我们将自监督目标（即音视频对比学习、音视频匹配和音视频遮蔽学习）整合到AVT训练中，将多样的音频和视频表示映射到一个通用的多模态表示空间中。我们还提出了一个音频片段遮蔽损失来学习语义音频活动。

    Audio and video are two most common modalities in the mainstream media platforms, e.g., YouTube. To learn from multimodal videos effectively, in this work, we propose a novel audio-video recognition approach termed audio video Transformer, AVT, leveraging the effective spatio-temporal representation by the video Transformer to improve action recognition accuracy. For multimodal fusion, simply concatenating multimodal tokens in a cross-modal Transformer requires large computational and memory resources, instead we reduce the cross-modality complexity through an audio-video bottleneck Transformer. To improve the learning efficiency of multimodal Transformer, we integrate self-supervised objectives, i.e., audio-video contrastive learning, audio-video matching, and masked audio and video learning, into AVT training, which maps diverse audio and video representations into a common multimodal representation space. We further propose a masked audio segment loss to learn semantic audio activit
    
[^50]: 跨说话人编码网络用于多说话人语音识别

    Cross-Speaker Encoding Network for Multi-Talker Speech Recognition. (arXiv:2401.04152v1 [cs.SD])

    [http://arxiv.org/abs/2401.04152](http://arxiv.org/abs/2401.04152)

    本文提出了一种叫做Cross-Speaker Encoding（CSE）的网络，用于解决多说话人语音识别中的局限性，通过聚合跨说话人表示。通过与SOT结合，该模型在两个说话人的数据集上实验证明比SIMO基准模型的词错误率（WER）分别降低了8%和10%。

    

    端到端的多说话人语音识别已经引起了极大的兴趣，作为一种直接转录多个说话人重叠语音的有效方法。目前的方法通常采用1）带有分支编码器的单输入多输出（SIMO）模型，或者2）基于注意力机制的编码器-解码器架构和序列化输出训练（SOT）的单输入单输出（SISO）模型。在这项工作中，我们提出了一种叫做Cross-Speaker Encoding（CSE）的网络来解决SIMO模型的局限性，通过聚合跨说话人表示。此外，CSE模型与SOT相结合，既发挥了SIMO和SISO的优势，又缓解了它们的缺点。据我们所知，该工作代表了将SIMO和SISO集成到多说话人语音识别中的早期工作。在两个说话人的LibrispeechMix数据集上进行的实验表明，CES模型相比于SIMO基准模型将词错误率（WER）降低了8%。CSE-SOT模型将WER降低了10%

    End-to-end multi-talker speech recognition has garnered great interest as an effective approach to directly transcribe overlapped speech from multiple speakers. Current methods typically adopt either 1) single-input multiple-output (SIMO) models with a branched encoder, or 2) single-input single-output (SISO) models based on attention-based encoder-decoder architecture with serialized output training (SOT). In this work, we propose a Cross-Speaker Encoding (CSE) network to address the limitations of SIMO models by aggregating cross-speaker representations. Furthermore, the CSE model is integrated with SOT to leverage both the advantages of SIMO and SISO while mitigating their drawbacks. To the best of our knowledge, this work represents an early effort to integrate SIMO and SISO for multi-talker speech recognition. Experiments on the two-speaker LibrispeechMix dataset show that the CES model reduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model reduces WER by 10
    
[^51]: 在线测试时间适应性的时空交通流量预测

    Online Test-Time Adaptation of Spatial-Temporal Traffic Flow Forecasting. (arXiv:2401.04148v1 [cs.LG])

    [http://arxiv.org/abs/2401.04148](http://arxiv.org/abs/2401.04148)

    本研究首次研究了在线测试时间适应技术在时空交通流量预测中的应用，提出了一种自适应的双重校正方法，通过对模型输出的分解和校正来提高预测的准确性。

    

    准确的时空交通流量预测对于交通管理人员实施控制措施和驾驶员选择最佳行驶路线至关重要。传统基于深度学习的交通流量预测方法通常依赖于历史数据来训练模型，然后用于对未来数据进行预测。然而，由于历史数据和未来数据之间的时间漂移，训练模型的性能通常会下降。为了使基于历史数据训练的模型能够在完全在线的方式下更好地适应未来数据，本文首次研究了时空交通流量预测问题的在线测试时间适应性技术。为此，我们提出了一种自适应的双重校正方法，通过对训练模型的输出进行季节性和趋势周期部分的分解，并在测试阶段使用两个独立的模块对其进行校正。

    Accurate spatial-temporal traffic flow forecasting is crucial in aiding traffic managers in implementing control measures and assisting drivers in selecting optimal travel routes. Traditional deep-learning based methods for traffic flow forecasting typically rely on historical data to train their models, which are then used to make predictions on future data. However, the performance of the trained model usually degrades due to the temporal drift between the historical and future data. To make the model trained on historical data better adapt to future data in a fully online manner, this paper conducts the first study of the online test-time adaptation techniques for spatial-temporal traffic flow forecasting problems. To this end, we propose an Adaptive Double Correction by Series Decomposition (ADCSD) method, which first decomposes the output of the trained model into seasonal and trend-cyclical parts and then corrects them by two separate modules during the testing phase using the la
    
[^52]: 一种用于全局路径规划的增强注意力深度强化学习方法：Learn Once Plan Arbitrarily (LOPA)

    Learn Once Plan Arbitrarily (LOPA): Attention-Enhanced Deep Reinforcement Learning Method for Global Path Planning. (arXiv:2401.04145v1 [cs.LG])

    [http://arxiv.org/abs/2401.04145](http://arxiv.org/abs/2401.04145)

    LOPA是一种增强注意力的深度强化学习方法，用于解决全局路径规划中的收敛性和泛化性等挑战。

    

    深度强化学习(DRL)方法在路径规划任务中显示出了很大的潜力。然而，在处理全局规划任务时，这些方法面临着收敛性和泛化性等严重的挑战。为此，我们在本文中提出了一种名为LOPA（Learn Once Plan Arbitrarily）的增强注意力深度强化学习方法。首先，我们从DRL的观察角度分析了这些问题的原因，揭示了传统设计导致DRL受到无关地图信息的干扰。其次，我们开发了LOPA，利用一种新颖的增强注意力机制，以改善对观察中关键信息的注意力能力。这种机制通过两个步骤实现：(1)构建一个注意力模型，将DRL的观察转换为两个动态视图：局部和全局，显著指导LOPA关注给定地图上的关键信息；(2)构建一个双通道网络来处理这两个视图。

    Deep reinforcement learning (DRL) methods have recently shown promise in path planning tasks. However, when dealing with global planning tasks, these methods face serious challenges such as poor convergence and generalization. To this end, we propose an attention-enhanced DRL method called LOPA (Learn Once Plan Arbitrarily) in this paper. Firstly, we analyze the reasons of these problems from the perspective of DRL's observation, revealing that the traditional design causes DRL to be interfered by irrelevant map information. Secondly, we develop the LOPA which utilizes a novel attention-enhanced mechanism to attain an improved attention capability towards the key information of the observation. Such a mechanism is realized by two steps: (1) an attention model is built to transform the DRL's observation into two dynamic views: local and global, significantly guiding the LOPA to focus on the key information on the given maps; (2) a dual-channel network is constructed to process these two
    
[^53]: 改进天气预测的鲁棒性校准

    Robust Calibration For Improved Weather Prediction Under Distributional Shift. (arXiv:2401.04144v1 [cs.LG])

    [http://arxiv.org/abs/2401.04144](http://arxiv.org/abs/2401.04144)

    本研究通过混合专家模型、数据增强和鲁棒后校准方法，相比提升树模型，使用深度神经网络在天气预测中实现更准确和更好校准的结果。

    

    本文介绍了在“鲁棒性和不确定性在现实世界分布转移下的挑战——移位挑战”中改善跨域天气预测和不确定性估计的结果。我们发现，通过利用从计算机视觉领域借鉴的高级数据增强技术以及混合专家模型，并结合对预测不确定性进行鲁棒后校准，我们可以在用于表格数据的深度神经网络中实现比提升树模型更准确和更好校准的结果。我们使用多种指标对我们的预测进行量化，提出了几个未来的探究和实验方向来提升性能。

    In this paper, we present results on improving out-of-domain weather prediction and uncertainty estimation as part of the \texttt{Shifts Challenge on Robustness and Uncertainty under Real-World Distributional Shift} challenge. We find that by leveraging a mixture of experts in conjunction with an advanced data augmentation technique borrowed from the computer vision domain, in conjunction with robust \textit{post-hoc} calibration of predictive uncertainties, we can potentially achieve more accurate and better-calibrated results with deep neural networks than with boosted tree models for tabular data. We quantify our predictions using several metrics and propose several future lines of inquiry and experimentation to boost performance.
    
[^54]: 关于分形几何和卷积神经网络（CNN）对其编码能力的潜力研究

    On The Potential of The Fractal Geometry and The CNNs Ability to Encode it. (arXiv:2401.04141v1 [cs.LG])

    [http://arxiv.org/abs/2401.04141](http://arxiv.org/abs/2401.04141)

    本研究探讨分形几何的潜力和深度学习网络对其编码能力的限制。通过相关性分析实验和人类评估，我们发现深度网络不能提取复杂且高层次的分形特征。然而，在需要对象结构对分类任务至关重要的应用中，分形特征表现出很好的有效性。

    

    分形维数通过研究模式在测量尺度下的变化来提供对象复杂性的统计指标。虽然在几种分类任务中有用，但在深度学习应用中对分形维数的研究还不够深入。本研究探讨了深度模型学习到的特征，并研究了这些深度网络是否能够像分形维数一样编码复杂且高层次的特征。具体而言，我们进行了相关性分析实验，结果表明深度网络在任何层次都不能提取出这样的特征。我们将分析研究与人类评估相结合，研究了深度学习网络和仅操作分形特征的模型之间的差异。此外，我们还展示了分形特征在需要对象结构对分类任务至关重要的应用中的有效性。我们实证表明，在分形特征上训练浅层网络能够取得良好的性能。

    The fractal dimension provides a statistical index of object complexity by studying how the pattern changes with the measuring scale. Although useful in several classification tasks, the fractal dimension is under-explored in deep learning applications. In this work, we investigate the features that are learned by deep models and we study whether these deep networks are able to encode features as complex and high-level as the fractal dimensions. Specifically, we conduct a correlation analysis experiment to show that deep networks are not able to extract such a feature in none of their layers. We combine our analytical study with a human evaluation to investigate the differences between deep learning networks and models that operate on the fractal feature solely. Moreover, we show the effectiveness of fractal features in applications where the object structure is crucial for the classification task. We empirically show that training a shallow network on fractal features achieves perform
    
[^55]: 通过基于LLM的定性分析拓展人机交互研究的视野

    Expanding Horizons in HCI Research Through LLM-Driven Qualitative Analysis. (arXiv:2401.04138v1 [cs.HC])

    [http://arxiv.org/abs/2401.04138](http://arxiv.org/abs/2401.04138)

    本文通过引入基于LLM的定性分析方法，拓展了人机交互研究的新视野，并通过研究发现LLMs在性能上不仅与传统分析方法相当，还能提供独特的见解。

    

    如果我们仍然需要用打字机“发送”论文，研究会是怎样的？我们的生活和研究环境不断演变，往往伴随着对新方法论的争议。在本文中，我们通过引入一种基于Large Language Models（LLMs）的定性分析新方法来拥抱这种变化。我们详细介绍了一种使用LLMs进行定性数据分析的方法，并提出了一个使用SBART余弦相似度进行性能评估的定量框架。我们的研究结果表明，LLMs不仅与传统分析方法有效性相匹配，还提供了独特的洞察力。通过一个新颖的数据集和基准，我们探索了LLMs在人机交互研究中的特点，提出了进一步探索和应用的潜在方向。

    How would research be like if we still needed to "send" papers typed with a typewriter? Our life and research environment have continually evolved, often accompanied by controversial opinions about new methodologies. In this paper, we embrace this change by introducing a new approach to qualitative analysis in HCI using Large Language Models (LLMs). We detail a method that uses LLMs for qualitative data analysis and present a quantitative framework using SBART cosine similarity for performance evaluation. Our findings indicate that LLMs not only match the efficacy of traditional analysis methods but also offer unique insights. Through a novel dataset and benchmark, we explore LLMs' characteristics in HCI research, suggesting potential avenues for further exploration and application in the field.
    
[^56]: 扩散模型强大，后门更容易: 数据污染引发版权侵犯而无需调整微调流程

    The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline. (arXiv:2401.04136v1 [cs.CR])

    [http://arxiv.org/abs/2401.04136](http://arxiv.org/abs/2401.04136)

    本研究探讨了扩散模型中存在的版权保护漏洞，并提出了一种后门数据污染攻击方法。这种攻击方法无需操作扩散模型的训练或微调过程，仅通过向训练数据集插入污染数据来实施攻击。

    

    扩散模型的商业化引发了潜在的版权问题。本研究通过引入后门数据污染攻击（SilentBadDiffusion）来探讨扩散模型中与版权保护相关的漏洞。攻击方法无需访问或控制扩散模型的训练或微调过程，仅涉及将污染数据插入干净的训练数据集中。这些数据是通过利用多模态大型语言模型和文本引导图像生成的。

    The commercialization of diffusion models, renowned for their ability to generate high-quality images that are often indistinguishable from real ones, brings forth potential copyright concerns. Although attempts have been made to impede unauthorized access to copyrighted material during training and to subsequently prevent DMs from generating copyrighted images, the effectiveness of these solutions remains unverified. This study explores the vulnerabilities associated with copyright protection in DMs by introducing a backdoor data poisoning attack (SilentBadDiffusion) against text-to-image diffusion models. Our attack method operates without requiring access to or control over the diffusion model's training or fine-tuning processes; it merely involves the insertion of poisoning data into the clean training dataset. This data, comprising poisoning images equipped with prompts, is generated by leveraging the powerful capabilities of multimodal large language models and text-guided image 
    
[^57]: 具有全局感知增强的时空图递归网络：交通流量预测的新框架

    Global-Aware Enhanced Spatial-Temporal Graph Recurrent Networks: A New Framework For Traffic Flow Prediction. (arXiv:2401.04135v1 [cs.LG])

    [http://arxiv.org/abs/2401.04135](http://arxiv.org/abs/2401.04135)

    该论文提出了一个名为GA-STGRN的新的交通流量预测框架，通过结合图卷积网络和循环神经网络来进行时空建模。该框架中的一个关键创新是引入了全局感知层来帮助捕捉全局信息。另外，为了建模非固定的图结构和捕捉局部特征，还提出了一个序列感知的图神经网络。

    

    交通流量预测在减少交通拥堵和提高运输效率方面起着至关重要的作用。虽然将图卷积网络与循环神经网络相结合进行时空建模在这个领域是一种常见的策略，但是循环神经网络的受限结构限制了它们捕捉全局信息的能力。对于空间建模，许多之前的研究学习一个被假设为固定且在所有时间步骤上均匀的图结构，这可能并不正确。本文提出了一种新颖的交通预测框架，称为全局感知增强时空图递归网络（GA-STGRN），包括两个核心组件：时空图递归神经网络和全局感知层。在这个框架中，提出了三个创新的预测模型。提出了一种序列感知的图神经网络，并将其整合到门控循环单元（GRU）中，以学习不同时间步骤下非固定的图形并捕捉局部特征。

    Traffic flow prediction plays a crucial role in alleviating traffic congestion and enhancing transport efficiency. While combining graph convolution networks with recurrent neural networks for spatial-temporal modeling is a common strategy in this realm, the restricted structure of recurrent neural networks limits their ability to capture global information. For spatial modeling, many prior studies learn a graph structure that is assumed to be fixed and uniform at all time steps, which may not be true. This paper introduces a novel traffic prediction framework, Global-Aware Enhanced Spatial-Temporal Graph Recurrent Network (GA-STGRN), comprising two core components: a spatial-temporal graph recurrent neural network and a global awareness layer. Within this framework, three innovative prediction models are formulated. A sequence-aware graph neural network is proposed and integrated into the Gated Recurrent Unit (GRU) to learn non-fixed graphs at different time steps and capture local te
    
[^58]: 使用完全有向图的Web神经网络

    Web Neural Network with Complete DiGraphs. (arXiv:2401.04134v1 [cs.NE])

    [http://arxiv.org/abs/2401.04134](http://arxiv.org/abs/2401.04134)

    本文介绍了一种新的神经网络模型，通过使用完全有向图的网络结构和连续数据处理，更接近生物脑，并通过引入循环和消除顺序性来增加额外的结构特性。

    

    本文介绍了一种新的神经网络模型，旨在更接近生物脑，通过将网络结构化为每个时间步骤处理连续数据的完全有向图。目前的神经网络结构模糊地模仿脑结构，例如神经元、卷积和循环。本文提出的模型通过引入神经元连接中的循环和消除常见的顺序性来增加额外的结构特性。此外，该模型具有连续的输入和输出，受脉冲神经网络的启发，允许网络学习分类过程，而不仅仅返回最终结果。

    This paper introduces a new neural network model that aims to mimic the biological brain more closely by structuring the network as a complete directed graph that processes continuous data for each timestep. Current neural networks have structures that vaguely mimic the brain structure, such as neurons, convolutions, and recurrence. The model proposed in this paper adds additional structural properties by introducing cycles into the neuron connections and removing the sequential nature commonly seen in other network layers. Furthermore, the model has continuous input and output, inspired by spiking neural networks, which allows the network to learn a process of classification, rather than simply returning the final result.
    
[^59]: SynHIN: 生成用于可解释人工智能的合成异构信息网络

    SynHIN: Generating Synthetic Heterogeneous Information Network for Explainable AI. (arXiv:2401.04133v1 [cs.LG])

    [http://arxiv.org/abs/2401.04133](http://arxiv.org/abs/2401.04133)

    该论文提出了一种生成合成异构信息网络的方法，用于可解释人工智能。该方法通过识别现实世界数据集中的模式，构建合成网络，并确保生成的合成图数据与真实数据接近。这提供了用于节点分类任务的合成异构图数据集。

    

    图神经网络在各个领域有着优秀的表现，从检测电子商务垃圾邮件到社交网络分类问题。然而，缺乏公共图数据集阻碍了研究进展，尤其是在异构信息网络（HIN）方面。由于图神经网络解释模型的进展，对于公平的HIN比较而言，需要数据集的需求越来越大。为此，我们提出了SynHIN，一种生成合成异构信息网络的独特方法。SynHIN识别现实世界数据集中的模式，总结图统计数据，并构建合成网络。我们的方法利用In-Cluster和Out-Cluster Merge模块从主要的模式集群构建合成HIN。在In/Out-Cluster合并和符合真实数据集约束的后修剪过程后，我们确保合成的图统计数据与参考数据接近。SynHIN生成用于节点分类任务的合成异构图数据集，使用主要的模式作为输入。

    Graph Neural Networks (GNNs) excel in various domains, from detecting e-commerce spam to social network classification problems. However, the lack of public graph datasets hampers research progress, particularly in heterogeneous information networks (HIN). The demand for datasets for fair HIN comparisons is growing due to advancements in GNN interpretation models. In response, we propose SynHIN, a unique method for generating synthetic heterogeneous information networks. SynHIN identifies motifs in real-world datasets, summarizes graph statistics, and constructs a synthetic network. Our approach utilizes In-Cluster and Out-Cluster Merge modules to build the synthetic HIN from primary motif clusters. After In/Our-Cluster mergers and a post-pruning process fitting the real dataset constraints, we ensure the synthetic graph statistics align closely with the reference one. SynHIN generates a synthetic heterogeneous graph dataset for node classification tasks, using the primary motif as the
    
[^60]: 无监督的测试时自适应：通过插入和播放变换器模块

    Unsupervised Test-Time Adaptation via Plug-and-Play Transformer Modules. (arXiv:2401.04130v1 [cs.LG])

    [http://arxiv.org/abs/2401.04130](http://arxiv.org/abs/2401.04130)

    这项工作介绍了PLUTO:一种插拔式模块化的测试时领域适应策略，通过预先训练一系列针对不同源领域的模块，有效地创建了一个"模块存储库"。采用无监督的测试时自适应方法，从存储库中选择稀疏的相关模块的子集，并创建选中模块的加权组合，实现了对新领域的自适应。

    

    参数高效调优(PET)方法，如LoRA、Adapter和Visual Prompt Tuning(VPT)，通过调整变换器模型中的小模块，在使适应新领域方面取得了成功。然而，在测试过程中遇到的领域数量可能非常大，数据通常是无标签的。因此，适应新领域是具有挑战性的，也不现实为每个这样的领域生成定制的调整模块。为了应对这些挑战，本文引入了PLUTO：一种插拔模块化的测试时领域适应策略。我们预训练了一系列模块，每个模块专为不同的源领域进行了专门设计，有效地创建了一个"模块存储库"。给定一个带有少样本无标签数据的目标域，我们引入了一种无监督的测试时自适应(TTA)方法，来(1)从库中选择出稀疏的相关模块的子集，并且(2)在不调整权重的情况下创建选中模块的加权组合。这种插拔式的特性使得它可===

    Parameter-efficient tuning (PET) methods such as LoRA, Adapter, and Visual Prompt Tuning (VPT) have found success in enabling adaptation to new domains by tuning small modules within a transformer model. However, the number of domains encountered during test time can be very large, and the data is usually unlabeled. Thus, adaptation to new domains is challenging; it is also impractical to generate customized tuned modules for each such domain. Toward addressing these challenges, this work introduces PLUTO: a Plug-and-pLay modUlar Test-time domain adaptatiOn strategy. We pre-train a large set of modules, each specialized for different source domains, effectively creating a ``module store''. Given a target domain with few-shot unlabeled data, we introduce an unsupervised test-time adaptation (TTA) method to (1) select a sparse subset of relevant modules from this store and (2) create a weighted combination of selected modules without tuning their weights. This plug-and-play nature enable
    
[^61]: 盲人触觉签名系统的概念

    The Concept of the Tactile Signature System for Individuals with Visual Impairments. (arXiv:2401.04126v1 [cs.HC])

    [http://arxiv.org/abs/2401.04126](http://arxiv.org/abs/2401.04126)

    盲人触觉签名系统是一种无障碍和有效的系统，通过触觉互动和语音算法引导，赋予视障人士创建个性化手写签名的能力，促进了他们的独立和包容。

    

    缺乏一种无障碍和有效的系统，使盲人能够创建手写签名，这对他们的独立性和全面参与生活的各个方面构成了重大障碍。本研究介绍了一种开创性的方法，即触觉签名系统，赋予视障人士形成独特的手写签名的能力。系统的关键特点包括：个性化定制：通过触觉互动和语音算法引导，个体可以创建反映其偏好和自然书写风格的签名。实时反馈：AI驱动的语音提示和分析确保签名的准确性和一致性。可访问性：在本地服务中心安装，提供安全监督的环境进行签名创建。该系统的影响超越个体层面：促进包容和独立：盲人可以进行法律和金融交易而无需依赖他人。

    The lack of an accessible and effective system for blind individuals to create handwritten signatures presents a significant barrier to their independence and full participation in various aspects of life. This research introduces the Tactile Signature System, a groundbreaking approach that empowers individuals with visual impairments to form their unique handwritten signatures. Key features of the system include: Personalized customization: Through tactile interaction and voice algorithmic guidance, individuals create signatures reflecting their preferences and natural writing style. Real-time feedback: AI-powered voice prompts and analysis ensure accuracy and consistency in signature formation. Accessibility: Installation in local service centers provides a secure and supervised environment for signature creation. The system's impact reaches beyond the individual level: Promotes inclusivity and independence: Blind individuals can engage in legal and financial transactions without rel
    
[^62]: DeepPhysiNet: 结合深度学习和大气物理学进行准确和连续的天气模拟

    DeepPhysiNet: Bridging Deep Learning and Atmospheric Physics for Accurate and Continuous Weather Modeling. (arXiv:2401.04125v1 [physics.ao-ph])

    [http://arxiv.org/abs/2401.04125](http://arxiv.org/abs/2401.04125)

    DeepPhysiNet框架将物理定律纳入深度学习模型中，实现了准确和连续的天气系统模拟。

    

    准确的天气预报对人类活动非常重要。目前，天气预报有两种范式：数值天气预报（NWP）和基于深度学习的预测（DLP）。NWP利用大气物理学进行天气模拟，但数据利用不足和计算成本高的问题使其受到限制，而DLP可以直接从大量数据中学习天气模式，但难以融入物理定律。这两种范式各有优势和劣势，并且不互相兼容，因为NWP中采用的物理定律描述了坐标和气象变量之间的关系，而DLP直接学习气象变量之间的关系而不考虑坐标。为了解决这些问题，我们引入了DeepPhysiNet框架，将物理定律纳入深度学习模型中，以实现准确和连续的天气系统模拟。首先，我们基于多层网络构建物理网络模型。

    Accurate weather forecasting holds significant importance to human activities. Currently, there are two paradigms for weather forecasting: Numerical Weather Prediction (NWP) and Deep Learning-based Prediction (DLP). NWP utilizes atmospheric physics for weather modeling but suffers from poor data utilization and high computational costs, while DLP can learn weather patterns from vast amounts of data directly but struggles to incorporate physical laws. Both paradigms possess their respective strengths and weaknesses, and are incompatible, because physical laws adopted in NWP describe the relationship between coordinates and meteorological variables, while DLP directly learns the relationships between meteorological variables without consideration of coordinates. To address these problems, we introduce the DeepPhysiNet framework, incorporating physical laws into deep learning models for accurate and continuous weather system modeling. First, we construct physics networks based on multilay
    
[^63]: MobileAgent：通过人机交互和SOP集成增强移动控制

    MobileAgent: enhancing mobile control via human-machine interaction and SOP integration. (arXiv:2401.04124v1 [cs.HC])

    [http://arxiv.org/abs/2401.04124](http://arxiv.org/abs/2401.04124)

    MobileAgent通过人机交互和SOP集成，提高了移动控制的效率和个性化用户需求的满足，同时解决了隐私问题和代理学习中的挑战。

    

    现在以大型语言模型（LLM）为中心的代理能够为用户自动化移动设备操作。在针对学习用户的移动操作进行微调后，这些代理可以在线遵循高级用户指令。它们执行目标分解、子目标序列化和交互式环境探索等任务，直到实现最终目标。然而，在移动操作中存在与个性化用户数据相关的隐私问题，需要用户确认。此外，用户的真实操作是探索性的，行动数据复杂且冗余，给代理学习带来挑战。为了解决这些问题，在我们的实际应用中，我们设计了代理与人之间的交互任务，以识别敏感信息并与个性化用户需求对齐。此外，我们在模型的上下文学习中集成了标准操作规程（SOP）信息，以增强代理的理解能力。

    Agents centered around Large Language Models (LLMs) are now capable of automating mobile device operations for users. After fine-tuning to learn a user's mobile operations, these agents can adhere to high-level user instructions online. They execute tasks such as goal decomposition, sequencing of sub-goals, and interactive environmental exploration, until the final objective is achieved. However, privacy concerns related to personalized user data arise during mobile operations, requiring user confirmation. Moreover, users' real-world operations are exploratory, with action data being complex and redundant, posing challenges for agent learning. To address these issues, in our practical application, we have designed interactive tasks between agents and humans to identify sensitive information and align with personalized user needs. Additionally, we integrated Standard Operating Procedure (SOP) information within the model's in-context learning to enhance the agent's comprehension of comp
    
[^64]: 从提示工程到人在循环中的提示科学

    From Prompt Engineering to Prompt Science With Human in the Loop. (arXiv:2401.04122v1 [cs.HC])

    [http://arxiv.org/abs/2401.04122](http://arxiv.org/abs/2401.04122)

    基于代码书构建方法和多阶段验证过程，本文提出一种新的方法来更系统地在研究中使用LLMs。

    

    随着LLMs在我们生活的许多方面的应用，科学研究领域是一个需要增加审查的地方。LLMs被用于生成或分析研究数据的应用正变得越来越流行。但是，当这种应用被临时决策和工程解决方案所困扰时，我们需要关注它如何影响研究、研究结果或者基于该研究的任何未来工作。我们需要更科学的方法来在我们的研究中使用LLMs。虽然目前有一些积极的努力支持更系统的提示构建，但它们往往更注重实现期望的结果，而不是产生可复制和具有足够透明度、客观性或严谨性的广泛知识。本文提出了一种新的方法，灵感来自通过定性方法构建代码书的方法，以解决这个问题。通过人在循环和多阶段验证过程，该方法为更系统的研究打下了基础。

    As LLMs make their way into many aspects of our lives, one place that warrants increased scrutiny with LLM usage is scientific research. Using LLMs for generating or analyzing data for research purposes is gaining popularity. But when such application is marred with ad-hoc decisions and engineering solutions, we need to be concerned about how it may affect that research, its findings, or any future works based on that research. We need a more scientific approach to using LLMs in our research. While there are several active efforts to support more systematic construction of prompts, they are often focused more on achieving desirable outcomes rather than producing replicable and generalizable knowledge with sufficient transparency, objectivity, or rigor. This article presents a new methodology inspired by codebook construction through qualitative methods to address that. Using humans in the loop and a multi-phase verification processes, this methodology lays a foundation for more systema
    
[^65]: Generation Z在Discord上区分人工智能生成和人类撰写文本的能力

    Generation Z's Ability to Discriminate Between AI-generated and Human-Authored Text on Discord. (arXiv:2401.04120v1 [cs.HC])

    [http://arxiv.org/abs/2401.04120](http://arxiv.org/abs/2401.04120)

    本研究通过对Generation Z的个体进行调查，评估了他们在Discord上区分AI生成和人类撰写文本的能力，发现他们无法有效区分这两种来源的文本。

    

    生成人工智能（AI）聊天机器人的普及，如ChatGPT，对社交媒体产生了深远影响。随着AI生成内容的普及，人们对在线隐私和虚假信息的担忧也越来越多。在社交媒体平台中，Discord允许AI集成，使他们以"Z世代"为主的用户群体特别容易接触到AI生成的内容。我们对年龄为Z世代的个体（n = 335）进行了调查，以评估他们在Discord上区分AI生成和人类撰写文本的能力。调查采用了ChatGPT伪装成在Discord.com平台上收到的一条短信的单次提示。我们探讨了人口统计因素和参与者对Discord和人工智能技术的熟悉程度对能力的影响。我们发现Z世代个体无法区分AI和人类撰写的文本（p = 0.011），那些自我报告程度较低的个体能力更差。

    The growing popularity of generative artificial intelligence (AI) chatbots such as ChatGPT is having transformative effects on social media. As the prevalence of AI-generated content grows, concerns have been raised regarding privacy and misinformation online. Among social media platforms, Discord enables AI integrations -- making their primarily "Generation Z" userbase particularly exposed to AI-generated content. We surveyed Generation Z aged individuals (n = 335) to evaluate their proficiency in discriminating between AI-generated and human-authored text on Discord. The investigation employed one-shot prompting of ChatGPT, disguised as a text message received on the Discord.com platform. We explore the influence of demographic factors on ability, as well as participants' familiarity with Discord and artificial intelligence technologies. We find that Generation Z individuals are unable to discern between AI and human-authored text (p = 0.011), and that those with lower self-reported 
    
[^66]: 为什么用户界面是一种黑暗模式？：可解释的自动检测及其分析。

    Why is the User Interface a Dark Pattern? : Explainable Auto-Detection and its Analysis. (arXiv:2401.04119v1 [cs.HC])

    [http://arxiv.org/abs/2401.04119](http://arxiv.org/abs/2401.04119)

    本研究通过使用BERT模型进行自动检测和LIME、SHAP等解释技术进行解释，揭示了黑暗模式中影响预测的关键术语，为用户提供防范黑暗模式的见解。

    

    黑暗模式是在线服务中误导用户行为的欺骗性用户界面设计。隐私侵犯、财务损失和情绪困扰等黑暗模式可能会对用户造成伤害。这些问题近年来一直是广泛讨论的话题。本文研究了可解释的黑暗模式自动检测，即为什么会将特定的用户界面检测为具有黑暗模式。首先，我们使用基于Transformer的预训练语言模型BERT对电子商务中的黑暗模式进行了文本数据集的自动检测模型训练。然后，我们应用了LIME和SHAP等后置解释技术对训练模型进行了解释，揭示了影响每个预测作为黑暗模式的术语。此外，我们还提取和分析了影响黑暗模式的术语。我们的研究结果可以帮助用户免受黑暗模式的操纵。

    Dark patterns are deceptive user interface designs for online services that make users behave in unintended ways. Dark patterns, such as privacy invasion, financial loss, and emotional distress, can harm users. These issues have been the subject of considerable debate in recent years. In this paper, we study interpretable dark pattern auto-detection, that is, why a particular user interface is detected as having dark patterns. First, we trained a model using transformer-based pre-trained language models, BERT, on a text-based dataset for the automatic detection of dark patterns in e-commerce. Then, we applied post-hoc explanation techniques, including local interpretable model agnostic explanation (LIME) and Shapley additive explanations (SHAP), to the trained model, which revealed which terms influence each prediction as a dark pattern. In addition, we extracted and analyzed terms that affected the dark patterns. Our findings may prevent users from being manipulated by dark patterns, 
    
[^67]: 在人机对话中处理困难和失败（WTF 2023）与CUI设计是否准备好？（arXiv:2401.04108v1 [cs.HC]）

    Working with Trouble and Failures in Conversation between Humans and Robots (WTF 2023) & Is CUI Design Ready Yet?. (arXiv:2401.04108v1 [cs.HC])

    [http://arxiv.org/abs/2401.04108](http://arxiv.org/abs/2401.04108)

    本论文总结了两个研讨会的会议录，旨在讨论人机对话中的沟通问题和失败，以及非机器人语音界面的相关失败。目标是彻底调查沟通失败，制定分类法，并展开解决方案的初步讨论。

    

    该论文是ACM会议上两个分会议“在人机对话中处理困难和失败”（WTF 2023）和“CUI设计是否准备好？”的研讨会会议录。WTF 23旨在汇集来自人机交互、对话系统、人机交互和对话分析领域的研究人员。尽管有所进展，但机器人语音界面在多个方面仍然脆弱，人们对此类界面失败的经历并不罕见。然而，技术文献对它们的良好性能有着积极的偏向。该研讨会旨在提供一个讨论人机交互中的沟通问题和失败以及非机器人语音界面相关失败的平台。目标包括对沟通失败进行彻底调查，开始制定这些失败的分类法，并就解决方案展开初步讨论。

    Workshop proceedings of two co-located workshops "Working with Troubles and Failures in Conversation with Humans and Robots" (WTF 2023) and "Is CUI Design Ready Yet?", both of which were part of the ACM conference on conversational user interfaces 2023.  WTF 23 aimed at bringing together researchers from human-robot interaction, dialogue systems, human-computer interaction, and conversation analysis. Despite all progress, robotic speech interfaces continue to be brittle in a number of ways and the experience of failure of such interfaces is commonplace amongst roboticists. However, the technical literature is positively skewed toward their good performance. The workshop aims to provide a platform for discussing communicative troubles and failures in human-robot interactions and related failures in non-robotic speech interfaces. Aims include a scrupulous investigation into communicative failures, to begin working on a taxonomy of such failures, and enable a preliminary discussion on pos
    
[^68]: 时间图学习的基本知识

    A Primer on Temporal Graph Learning. (arXiv:2401.03988v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.03988](http://arxiv.org/abs/2401.03988)

    本文介绍了时间图学习的基本知识，包括TGL框架中的重要概念、相关的学习架构以及经典的时间序列预测方法，为TGL的可解释学习解决方案提供了灵感。

    

    本文旨在通过概念先行的方法，使读者熟悉时间图学习（TGL）。我们系统地介绍了理解TGL框架所必不可少的重要概念。除了定性解释，我们还在适用的情况下引入了数学公式，提升了文本的清晰度。由于TGL涉及时间和空间学习，我们介绍了相关的学习架构，从循环神经网络和卷积神经网络到转换器和图神经网络。我们还讨论了经典的时间序列预测方法，以激发对TGL的可解释学习解决方案的灵感。

    This document aims to familiarize readers with temporal graph learning (TGL) through a concept-first approach. We have systematically presented vital concepts essential for understanding the workings of a TGL framework. In addition to qualitative explanations, we have incorporated mathematical formulations where applicable, enhancing the clarity of the text. Since TGL involves temporal and spatial learning, we introduce relevant learning architectures ranging from recurrent and convolutional neural networks to transformers and graph neural networks. We also discuss classical time series forecasting methods to inspire interpretable learning solutions for TGL.
    
[^69]: FlightLLM: 高效的FPGA上大型语言模型推断与完整映射流程

    FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs. (arXiv:2401.03868v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2401.03868](http://arxiv.org/abs/2401.03868)

    该论文提出了FlightLLM，一种在FPGA上实现完整映射流程的高效大型语言模型推断方法。通过利用FPGA特定资源，解决了LLMs的计算和内存开销问题，并提出了可配置的稀疏DSP链以支持不同稀疏模式。

    

    基于Transformer的大型语言模型(LLMs)对各个领域产生了重大影响。然而，LLMs的效率受到了大量计算和内存开销的影响。压缩技术如稀疏化和量化常被用于缓解LLMs的计算/内存开销与硬件容量之间的差距。然而，现有的GPU和基于Transformer的加速器无法高效处理压缩的LLMs，因为存在以下未解决的挑战：低计算效率、低利用率的内存带宽和巨大的编译开销。该论文提出了FlightLLM，通过在FPGA上实现完整的映射流程，实现了高效的LLMs推断。在FlightLLM中，我们提出了创新性的解决方案，通过利用FPGA特定的资源（如DSP48和异构内存层次），可以解决LLMs的计算和内存开销问题。我们提出了一种可配置的稀疏DSP链，以高计算效率支持不同稀疏模式。

    Transformer-based Large Language Models (LLMs) have made a significant impact on various domains. However, LLMs' efficiency suffers from both heavy computation and memory overheads. Compression techniques like sparsification and quantization are commonly used to mitigate the gap between LLM's computation/memory overheads and hardware capacity. However, existing GPU and transformer-based accelerators cannot efficiently process compressed LLMs, due to the following unresolved challenges: low computational efficiency, underutilized memory bandwidth, and large compilation overheads.  This paper proposes FlightLLM, enabling efficient LLMs inference with a complete mapping flow on FPGAs. In FlightLLM, we highlight an innovative solution that the computation and memory overhead of LLMs can be solved by utilizing FPGA-specific resources (e.g., DSP48 and heterogeneous memory hierarchy). We propose a configurable sparse DSP chain to support different sparsity patterns with high computation effic
    
[^70]: 改变提示的蝴蝶效应：微小的变化和越狱对大规模语言模型性能的影响

    The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance. (arXiv:2401.03729v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.03729](http://arxiv.org/abs/2401.03729)

    本研究通过一系列提示变化探究改变提示的构建方式对大规模语言模型决策的影响，发现即使微小的改变，比如在提示末尾加一个空格，也可能导致模型的答案变化。同时，请求以XML格式返回和常用的越狱方式也可能对模型标记的数据产生灾难性影响。

    

    大规模语言模型（LLMs）被广泛用于对多个领域和多个任务的数据进行标注。通过简单地向LLM提问或“提示”，实践者能够快速获得任意任务的响应。提示的构建方式是否变化会影响LLM的最终决策？我们通过对多种文本分类任务进行一系列提示变化来回答这个问题。我们发现，即使是最微小的扰动，比如在提示的末尾加一个空格，也可能导致LLM改变其答案。此外，我们发现在XML中请求响应和常用的越狱方式可能对由LLMs标记的数据产生灾难性影响。

    Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or ``prompting,'' practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work, we ask: do variations in the way a prompt is constructed change the ultimate decision of the LLM? We answer this using a series of prompt variations across a variety of text classification tasks. We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the LLM to change its answer. Further, we find that requesting responses in XML and commonly used jailbreaks can have cataclysmic effects on the data labeled by LLMs.
    
[^71]: 无需分词的大型语言模型能够以更准确的格式生成中国古典诗词

    Token-free LLMs Can Generate Chinese Classical Poetry with More Accurate Format. (arXiv:2401.03512v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.03512](http://arxiv.org/abs/2401.03512)

    本文提出了一种无需分词的大型语言模型（LLMs）来生成中国古典诗词，并解决了格式不准确性的问题。验证了现有基于分词的模型在字符和分词之间的关系方面的知识有限，并展示了如何通过定制模型解决这一问题。

    

    经过微调的大型语言模型（如ChatGPT和Qwen-chat）能够根据人类的指令生成中国古典诗词。虽然语言模型在内容方面表现良好，但通常在格式上存在问题，每行字符的数量有时过多或不足。由于大多数最新的语言模型是基于分词的，我们认为格式不准确是由于"分词规划"任务的难度，即语言模型需要准确知道每个分词中包含多少个字符，并基于这个知识进行长度控制规划。本文首先通过展示现有的基于分词的大型语言模型在分词和字符之间的关系方面知识有限来验证我们的假设。我们使用了拼写比赛探测程序，并发现Qwen-chat在近15%的中文拼写测试中失败。然后，我们展示了一个基于分词的模型可以轻松定制成无需分词的模型（对于中文来说），从而能够很大程度上解决格式准确性问题。

    Finetuned large language models (such as ChatGPT and Qwen-chat) can generate Chinese classical poetry following human's instructions. LLMs perform well in content, but are usually lacking in format, with occasionally excess or insufficient number of characters in each line. Since most SOTA LLMs are token-based, we assume that the format inaccuracy is due to the difficulty of the "token planning" task, which means that the LLM need to know exactly how much characters are contained in each token and do length-control planning based on that knowledge. In this paper, we first confirm our assumption by showing that existing token-based large language models has limited knowledge on token-character relationship. We use a spelling bee probing procedure, and find that Qwen-chat failed in nearly 15% Chinese spelling test. We then show that a token-based model can be easily tailored into a token-free model (in terms of Chinese), which can largely solve the format accuracy problem. Our tailoring 
    
[^72]: 在样本高效的离线强化学习中：数据多样性、后验采样，以及更多

    On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond. (arXiv:2401.03301v1 [cs.LG])

    [http://arxiv.org/abs/2401.03301](http://arxiv.org/abs/2401.03301)

    本文提出了通过数据多样性概念来统一离线强化学习算法的方法，并证明了基于版本空间、正则化优化和后验采样的算法在标准假设下达到了可比的样本效率。

    

    我们试图理解什么促进了对于序贝叶斯决策的历史数据集进行样本高效学习，这个问题通常被称为离线强化学习（RL）。此外，我们对于在利用（值）函数逼近的同时享受样本效率的算法感兴趣。在本文中，我们通过提出一个包括离线RL中覆盖度量的先前概念的数据多样性概念来解决这些基本问题，并且利用这个概念将基于版本空间（VS）、正则化优化（RO）和后验采样（PS）的三个不同类别的离线RL算法进行统一。我们在标准假设下证明，基于VS、基于RO和基于PS的算法达到了\emph{可比}的样本效率，这恢复了在有限和线性模型类别下的最优性的标准假设的边界。这个结果令人惊讶，因为之前的研究表明这些算法不具有有利性的样本效率。

    We seek to understand what facilitates sample-efficient learning from historical datasets for sequential decision-making, a problem that is popularly known as offline reinforcement learning (RL). Further, we are interested in algorithms that enjoy sample efficiency while leveraging (value) function approximation. In this paper, we address these fundamental questions by (i) proposing a notion of data diversity that subsumes the previous notions of coverage measures in offline RL and (ii) using this notion to {unify} three distinct classes of offline RL algorithms based on version spaces (VS), regularized optimization (RO), and posterior sampling (PS). We establish that VS-based, RO-based, and PS-based algorithms, under standard assumptions, achieve \emph{comparable} sample efficiency, which recovers the state-of-the-art sub-optimality bounds for finite and linear model classes with the standard assumptions. This result is surprising, given that the prior work suggested an unfavorable sa
    
[^73]: 基于混合方法的聊天AI模型：相对于万亿级参数模型的更廉价、更好的替代方案

    Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM. (arXiv:2401.02994v1 [cs.CL])

    [http://arxiv.org/abs/2401.02994](http://arxiv.org/abs/2401.02994)

    本研究介绍了一种名为“混合”的方法，通过组合多个适度规模的聊天AI模型，可以达到或超越比它们更大的模型的性能表现。

    

    在会话型AI研究中，越来越多的模型采用了更多的参数，如ChatGPT等模型。虽然这些庞大的模型往往能生成更好的聊天回复，但它们需要大量的计算资源和内存。本研究探讨了一个重要问题：能否通过组合较小的模型来达到与单个大模型相当或更好的性能？我们提出了一种称为“混合”的方法，它是一种简单但有效的将多个聊天AI集成在一起的方法。我们的实证证据表明，当特定较小的模型协同混合时，它们可以潜在地超越或匹敌大型模型的性能。例如，仅集成三个适度规模的模型（6B/13B参数）就可以达到或甚至超越ChatGPT（175B+参数）等大型模型的性能指标。这个假设经过了严格的测试。

    In conversational AI research, there's a noticeable trend towards developing models with a larger number of parameters, exemplified by models like ChatGPT. While these expansive models tend to generate increasingly better chat responses, they demand significant computational resources and memory. This study explores a pertinent question: Can a combination of smaller models collaboratively achieve comparable or enhanced performance relative to a singular large model? We introduce an approach termed "blending", a straightforward yet effective method of integrating multiple chat AIs. Our empirical evidence suggests that when specific smaller models are synergistically blended, they can potentially outperform or match the capabilities of much larger counterparts. For instance, integrating just three models of moderate size (6B/13B paramaeters) can rival or even surpass the performance metrics of a substantially larger model like ChatGPT (175B+ paramaters). This hypothesis is rigorously tes
    
[^74]: Graph2Tac: 在定理证明中学习数学概念的分层表示

    Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving. (arXiv:2401.02949v1 [cs.LG])

    [http://arxiv.org/abs/2401.02949](http://arxiv.org/abs/2401.02949)

    本文提出了一种名为Graph2Tac的图神经网络模型，用于在定理证明中学习数学概念的分层表示。该模型能够动态地将新的数学概念纳入到知识库中，并在Coq证明助手中进行训练和应用。

    

    数学及其应用中存在大量的概念。它们在不同的学科领域中有很大的变化，并且每篇数学论文或应用中都会引入新的概念。形式化理论建立了一个层次结构，其中包括了定义、定理和相互引用的证明。当一个AI代理人证明一个新的定理时，大多数与该定理相关的数学概念和引理在训练过程中可能从未被见过。这在Coq证明助手中尤为明显，该助手拥有各种各样的Coq项目，每个项目都有自己的定义、引理，甚至用于证明这些引理的自定义策略过程。将这样的新信息即时地融入到代理人的知识库中对于代理人至关重要。我们通过利用一个新的、大规模的、基于图的数据集，在Coq中进行机器学习。我们利用Coq术语的忠实图表示，创建了一种新颖的图神经网络Graph2Tac，该网络通过定义之间的依赖关系创建了一个有向图。

    Concepts abound in mathematics and its applications. They vary greatly between subject areas, and new ones are introduced in each mathematical paper or application. A formal theory builds a hierarchy of definitions, theorems and proofs that reference each other. When an AI agent is proving a new theorem, most of the mathematical concepts and lemmas relevant to that theorem may have never been seen during training. This is especially true in the Coq proof assistant, which has a diverse library of Coq projects, each with its own definitions, lemmas, and even custom tactic procedures used to prove those lemmas. It is essential for agents to incorporate such new information into their knowledge base on the fly. We work towards this goal by utilizing a new, large-scale, graph-based dataset for machine learning in Coq. We leverage a faithful graph-representation of Coq terms that induces a directed graph of dependencies between definitions to create a novel graph neural network, Graph2Tac (G
    
[^75]: GPS-SSL: 引导正样本采样将先验知识注入到自监督学习中

    GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning. (arXiv:2401.01990v1 [cs.CV])

    [http://arxiv.org/abs/2401.01990](http://arxiv.org/abs/2401.01990)

    GPS-SSL是一种将先验知识注入到自监督学习中的通用方法，通过设计度量空间并利用最近邻采样生成正样本。它可以减少对强数据增强的依赖，因此在Cifar10上达到了更好的效果。

    

    我们提出了引导正样本采样自监督学习（GPS-SSL），这是一种将先验知识注入到自监督学习（SSL）正样本选择的通用方法。当前的SSL方法利用数据增强（DA）生成正样本，并将先验知识结合进去，但是错误或者过弱的DA会严重降低所学到的表示的质量。GPS-SSL则提出设计一个度量空间，使得欧氏距离成为语义关系的有意义的替代。在这个空间中，可以通过最近邻采样生成正样本。任何先验知识都可以独立地嵌入到这个度量空间中，而不受所使用的DA影响。由于其简单性，GPS-SSL适用于任何SSL方法，如SimCLR或BYOL。GPS-SSL的一个关键好处是减少了定制强DA的压力。例如，GPS-SSL在Cifar10上使用弱DA达到了85.58％，而基准值只达到了37.51％。

    We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a general method to inject a priori knowledge into Self-Supervised Learning (SSL) positive samples selection. Current SSL methods leverage Data-Augmentations (DA) for generating positive samples and incorporate prior knowledge - an incorrect, or too weak DA will drastically reduce the quality of the learned representation. GPS-SSL proposes instead to design a metric space where Euclidean distances become a meaningful proxy for semantic relationship. In that space, it is now possible to generate positive samples from nearest neighbor sampling. Any prior knowledge can now be embedded into that metric space independently from the employed DA. From its simplicity, GPS-SSL is applicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is in reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches 85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We therefore move a 
    
[^76]: 多语言指令调优中的多语言性

    Multilingual Instruction Tuning With Just a Pinch of Multilinguality. (arXiv:2401.01854v1 [cs.CL])

    [http://arxiv.org/abs/2401.01854](http://arxiv.org/abs/2401.01854)

    本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    

    随着大型语言模型（LLMs）的全球采纳，它们在多语言指令遵循能力变得越来越重要。一种有前途的方法是跨语言转移，通过在另一种语言上微调，模型可以在某种语言上获得特定的功能。本文研究了多语言LLM在指令调优过程中的多语言性对跨语言指令遵循的影响。首先我们发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，我们发现在英语调优集合中，只有40个多语言示例能够显著提高多语言指令遵循，在调优过程中不论是已见语言还是未见语言。总的来说，我们观察到在多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those language
    
[^77]: 大型语言模型的知识编辑全面研究

    A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])

    [http://arxiv.org/abs/2401.01286](http://arxiv.org/abs/2401.01286)

    本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。

    

    大型语言模型(LLM)在理解和生成与人类交流紧密相似的文本方面展现出了非凡的能力。然而，其主要限制在于训练过程中的显著计算需求，这是由于其广泛的参数化造成的。这一挑战在于世界的动态性，需要频繁更新LLM以修正过时的信息或集成新知识，从而确保其持续的相关性。许多应用需要在训练后进行持续的模型调整，以解决缺陷或不良行为。近年来，对于LLM的知识编辑技术的兴趣越来越高，在特定领域内有效地修改LLM的行为，同时保持整体性能在各种输入中的表现。本文首先定义了知识编辑的目标和挑战，然后综述了现有的知识编辑方法和技术，并讨论了其应用和未来发展的方向。

    Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the kno
    
[^78]: 自监督视觉学习中的蒙面建模

    Masked Modeling for Self-supervised Representation Learning on Vision and Beyond. (arXiv:2401.00897v1 [cs.CV])

    [http://arxiv.org/abs/2401.00897](http://arxiv.org/abs/2401.00897)

    蒙面建模是一种自监督学习方法，通过预测被蒙面部分实现深度模型学习稳健的表示，已在计算机视觉和自然语言处理等领域展现出卓越性能。

    

    随着深度学习的革命不断向前，自监督学习因其出色的表示学习能力和对标注数据的低依赖性而受到越来越多的关注。在这些多样的自监督技术中，蒙面建模已经成为一种独特的方法，其中在训练过程中相应比例的原始数据会被蒙面，模型需要预测出这些蒙面的部分。这种范式使深度模型能够学习到稳健的表示，并在计算机视觉、自然语言处理和其他领域展示出了出色的性能。在本调查中，我们对蒙面建模框架及其方法进行了全面的回顾，详细介绍了蒙面建模中的技术细节，包括多样的蒙面策略、恢复目标、网络架构等。然后，我们系统地调查了它在各个领域中的广泛应用。此外，我们还探讨了其共性。

    As the deep learning revolution marches on, self-supervised learning has garnered increasing attention in recent years thanks to its remarkable representation learning ability and the low dependence on labeled data. Among these varied self-supervised techniques, masked modeling has emerged as a distinctive approach that involves predicting parts of the original data that are proportionally masked during training. This paradigm enables deep models to learn robust representations and has demonstrated exceptional performance in the context of computer vision, natural language processing, and other modalities. In this survey, we present a comprehensive review of the masked modeling framework and its methodology. We elaborate on the details of techniques within masked modeling, including diverse masking strategies, recovering targets, network architectures, and more. Then, we systematically investigate its wide-ranging applications across domains. Furthermore, we also explore the commonalit
    
[^79]: Jatmo:通过任务特定的微调进行提示注入防御

    Jatmo: Prompt Injection Defense by Task-Specific Finetuning. (arXiv:2312.17673v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2312.17673](http://arxiv.org/abs/2312.17673)

    Jatmo是一种生成对提示注入攻击具有抗性的任务特定模型的方法，通过利用教师模型生成任务特定的数据集并对基础模型进行微调。

    

    由于其遵循指令的能力，大型语言模型（LLMs）引起了广泛的研究关注，使用户和开发人员能够利用LLMs执行各种任务。然而，LLMs容易受到提示注入攻击的影响：一种攻击方式，通过劫持模型的指令遵循能力，将对提示的响应更改为不需要或可能具有恶意的响应。在这项工作中，我们介绍了Jatmo，一种生成对提示注入攻击具有抗性的任务特定模型的方法。Jatmo利用了LLMs只能在经历过指令调整后才能遵循指令的事实。它利用一个经过指令调整的教师模型生成一个任务特定的数据集，然后用这个数据集对一个基础模型（即非指令调整的模型）进行微调。Jatmo只需要一个任务提示和一个任务输入的数据集：它使用教师模型生成输出。在没有现成数据集的情况下，Jatmo可以使用一个例子，或者在某些情况下可以使用

    Large Language Models (LLMs) are attracting significant research attention due to their instruction-following abilities, allowing users and developers to leverage LLMs for a variety of tasks. However, LLMs are vulnerable to prompt-injection attacks: a class of attacks that hijack the model's instruction-following abilities, changing responses to prompts to undesired, possibly malicious ones. In this work, we introduce Jatmo, a method for generating task-specific models resilient to prompt-injection attacks. Jatmo leverages the fact that LLMs can only follow instructions once they have undergone instruction tuning. It harnesses a teacher instruction-tuned model to generate a task-specific dataset, which is then used to fine-tune a base model (i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a dataset of inputs for the task: it uses the teacher model to generate outputs. For situations with no pre-existing datasets, Jatmo can use a single example, or in some cases
    
[^80]: LLM动力下的分层语言智能体用于实时人机协作

    LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination. (arXiv:2312.15224v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.15224](http://arxiv.org/abs/2312.15224)

    这项研究提出了一种分层语言智能体（HLA）用于实时人机协作，通过改进的LLM引擎和分层策略，既提供强大的推理能力又保持实时执行。

    

    大规模语言模型（LLM）驱动的AI智能体取得了重大突破，使其能够在各种复杂任务中协助人类，引发了人机协作革命。LLM驱动的智能体通常需要调用LLM API并使用人工设计的复杂提示，导致推理延迟较高。尽管这种模式在最小互动要求的情境下（如代码生成）效果良好，但对于高度互动和实时应用（如游戏）则不适用。传统的游戏AI通常使用小模型或反应策略，可以实现快速推理，但任务完成和交互能力有限。本研究以Overcooked作为我们的测试场景，其中玩家可以使用自然语言进行交流并合作完成订单。我们提出了一种分层语言智能体（HLA）用于人机协作，既提供强大的推理能力又保持实时执行。具体而言，HLA采用了改进的LLM引擎和分层策略，以实现高效的交互和任务完成。

    AI agents powered by Large Language Models (LLMs) have made significant advances, enabling them to assist humans in diverse complex tasks and leading to a revolution in human-AI coordination. LLM-powered agents typically require invoking LLM APIs and employing artificially designed complex prompts, which results in high inference latency. While this paradigm works well in scenarios with minimal interactive demands, such as code generation, it is unsuitable for highly interactive and real-time applications, such as gaming. Traditional gaming AI often employs small models or reactive policies, enabling fast inference but offering limited task completion and interaction abilities. In this work, we consider Overcooked as our testbed where players could communicate with natural language and cooperate to serve orders. We propose a Hierarchical Language Agent (HLA) for human-AI coordination that provides both strong reasoning abilities while keeping real-time execution. In particular, HLA ado
    
[^81]: 时间变换器：融合本地和全局特征以实现更好的时间序列生成

    Time-Transformer: Integrating Local and Global Features for Better Time Series Generation. (arXiv:2312.11714v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11714](http://arxiv.org/abs/2312.11714)

    本文提出了一种新的时间序列生成模型，通过时间变换器同时学习本地和全局特征，实现了对时间序列数据的更好生成能力。

    

    生成时间序列数据是解决数据不足问题的一种有前景的方法。然而，由于时间序列数据的复杂时间特性，包括本地相关性和全局依赖性，使其成为具有挑战性的任务。大多数现有的生成模型未能有效学习时间序列数据的本地和全局特性。为了解决这个问题，我们提出了一种新颖的时间序列生成模型，命名为'时间变换器AAE'，它由一个对抗性自动编码器（AAE）和一个名为'时间变换器'的新设计架构组成。时间变换器首先通过层次并行设计同时学习本地和全局特征，结合了时间卷积网络和Transformer的能力，分别提取本地特征和全局依赖性。其次，提出了一个双向交叉注意力来在两个分支之间提供互补的引导，并实现本地特征和全局特征的合适融合。

    Generating time series data is a promising approach to address data deficiency problems. However, it is also challenging due to the complex temporal properties of time series data, including local correlations as well as global dependencies. Most existing generative models have failed to effectively learn both the local and global properties of time series data. To address this open problem, we propose a novel time series generative model named 'Time-Transformer AAE', which consists of an adversarial autoencoder (AAE) and a newly designed architecture named 'Time-Transformer' within the decoder. The Time-Transformer first simultaneously learns local and global features in a layer-wise parallel design, combining the abilities of Temporal Convolutional Networks and Transformer in extracting local features and global dependencies respectively. Second, a bidirectional cross attention is proposed to provide complementary guidance across the two branches and achieve proper fusion between loc
    
[^82]: Customize-It-3D：使用主体特定知识先验从单个图像创建高质量的3D模型

    Customize-It-3D: High-Quality 3D Creation from A Single Image Using Subject-Specific Knowledge Prior. (arXiv:2312.11535v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.11535](http://arxiv.org/abs/2312.11535)

    该论文提出了一种使用主体特定知识先验的两阶段方法，通过考虑阴影模式和纹理增强来生成高质量、有丰富纹理的3D模型，与以前的方法相比具有显著的优势。

    

    在本文中，我们提出了一种新的两阶段方法，充分利用参考图像提供的信息，建立图像到3D生成的自定义知识先验。之前的方法主要依赖于通用的扩散先验，这些方法在与参考图像得到一致结果方面存在困难，我们提出了一种主体特定且多模态的扩散模型。该模型不仅通过考虑阴影模式来改善几何优化和纹理增强的粗略结果，还有助于使3D内容与主题保持一致。大量实验证明了我们的方法的优越性，Customize-It-3D在视觉质量上远远超过了以前的方法，能够产生出色的360度重建结果，非常适合各种应用，包括文本到3D的创建。

    In this paper, we present a novel two-stage approach that fully utilizes the information provided by the reference image to establish a customized knowledge prior for image-to-3D generation. While previous approaches primarily rely on a general diffusion prior, which struggles to yield consistent results with the reference image, we propose a subject-specific and multi-modal diffusion model. This model not only aids NeRF optimization by considering the shading mode for improved geometry but also enhances texture from the coarse results to achieve superior refinement. Both aspects contribute to faithfully aligning the 3D content with the subject. Extensive experiments showcase the superiority of our method, Customize-It-3D, outperforming previous works by a substantial margin. It produces faithful 360-degree reconstructions with impressive visual quality, making it well-suited for various applications, including text-to-3D creation.
    
[^83]: 地球是扁平的，因为......：通过说服性对话研究LLMs对误导信息的信仰

    The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation. (arXiv:2312.09085v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.09085](http://arxiv.org/abs/2312.09085)

    本研究研究了LLMs对误导信息的易受攻击性，特别是在说服性对话中。通过实验证明，LLMs在事实知识上的正确信念很容易被各种说服策略所操纵。

    

    大型语言模型(LLMs)封装了大量知识，但仍然容易受到外部误导信息的攻击。现有研究主要在单轮对话中研究了这种易受攻击的行为。然而，在多轮对话中，特别是说服性对话中，信仰可以发生变化。因此，在本研究中，我们深入探讨了LLMs对说服性对话的易受攻击性，特别是对它们可以正确回答的事实问题。首先，我们整理了Farm（即事实到误导）数据集，其中包含与系统生成的说服性误导信息相匹配的事实问题。然后，我们开发了一个测试框架，以追踪LLMs在说服性对话中的信仰变化。通过大量实验，我们发现LLMs在事实知识上的正确信念很容易被各种说服策略所操纵。

    Large Language Models (LLMs) encapsulate vast amounts of knowledge but still remain vulnerable to external misinformation. Existing research mainly studied this susceptibility behavior in a single-turn setting. However, belief can change during a multi-turn conversation, especially a persuasive one. Therefore, in this study, we delve into LLMs' susceptibility to persuasive conversations, particularly on factual questions that they can answer correctly. We first curate the Farm (i.e., Fact to Misinform) dataset, which contains factual questions paired with systematically generated persuasive misinformation. Then, we develop a testing framework to track LLMs' belief changes in a persuasive dialogue. Through extensive experiments, we find that LLMs' correct beliefs on factual knowledge can be easily manipulated by various persuasive strategies.
    
[^84]: 可比较的演示在上下文学习中至关重要：对演示选择的新视角

    Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection. (arXiv:2312.07476v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.07476](http://arxiv.org/abs/2312.07476)

    本研究从可比较的演示的角度探索了上下文学习（ICL）机制，并发现演示偏见存在于大型语言模型（LLMs）中，而通过可比较的演示可以显著减少这种偏见，并在ICL中展现出良好的性能。

    

    在上下文学习（ICL）中，通过少量演示将大型语言模型（LLMs）适应于下游任务是一种重要的范式。尽管ICL取得了巨大成功，但演示数量的限制可能导致演示偏见，即由LLMs引起的输入-标签映射误解了任务的本质。受人类经验的启发，我们尝试通过演示间关系的视角来缓解这种偏见。具体而言，我们通过最小化编辑文本来构建可比较的演示（CDs），以翻转相应的标签，以突出任务的本质并通过演示间比较消除潜在的虚假相关性。通过一系列的CDs实验，我们发现：（1）LLMs存在演示偏见，而CDs可以显著减少这种偏见；（2）CDs在ICL中表现出良好的性能，尤其是在分布外场景中。总之，本研究从一种新的视角探索了ICL机制。

    In-Context Learning (ICL) is an important paradigm for adapting Large Language Models (LLMs) to downstream tasks through a few demonstrations. Despite the great success of ICL, the limitation of the demonstration number may lead to demonstration bias, i.e. the input-label mapping induced by LLMs misunderstands the task's essence. Inspired by human experience, we attempt to mitigate such bias through the perspective of the inter-demonstration relationship. Specifically, we construct Comparable Demonstrations (CDs) by minimally editing the texts to flip the corresponding labels, in order to highlight the task's essence and eliminate potential spurious correlations through the inter-demonstration comparison. Through a series of experiments on CDs, we find that (1) demonstration bias does exist in LLMs, and CDs can significantly reduce such bias; (2) CDs exhibit good performance in ICL, especially in out-of-distribution scenarios. In summary, this study explores the ICL mechanisms from a n
    
[^85]: 从知识表示到知识组织再回到知识表示

    From Knowledge Representation to Knowledge Organization and Back. (arXiv:2312.07302v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.07302](http://arxiv.org/abs/2312.07302)

    本文介绍了知识表示（KR）和面向分析的知识组织（KO）方法，并提出了一个集成了KO丰富的KR方法，以提高建模质量。

    

    知识表示（KR）和面向分析的知识组织（KO）是人工智能社区和信息科学社区中最重要的数据和知识建模方法。KR拥有一个强大而可扩展的技术生态系统来支持知识建模，但往往忽视其模型（和基于模型的数据）的质量。另一方面，KO不那么技术驱动，但已经发展出一套确保建模（和基于模型的数据）质量的指导原则（法规）。本文详细阐述了KR和面向分析的KO方法，并提供了它们之间的功能映射。在映射中，本文提出了一个集成了KO丰富的KR方法，拥有所有标准的KR方法组件，以及KO提供的建模质量的指导法规。该方法的实际益处已经得到了示范。

    Knowledge Representation (KR) and facet-analytical Knowledge Organization (KO) have been the two most prominent methodologies of data and knowledge modelling in the Artificial Intelligence community and the Information Science community, respectively. KR boasts of a robust and scalable ecosystem of technologies to support knowledge modelling while, often, underemphasizing the quality of its models (and model-based data). KO, on the other hand, is less technology-driven but has developed a robust framework of guiding principles (canons) for ensuring modelling (and model-based data) quality. This paper elucidates both the KR and facet-analytical KO methodologies in detail and provides a functional mapping between them. Out of the mapping, the paper proposes an integrated KO-enriched KR methodology with all the standard components of a KR methodology plus the guiding canons of modelling quality provided by KO. The practical benefits of the methodological integration has been exemplified t
    
[^86]: 在自动驾驶中探索LiDAR-相机融合模型的对抗鲁棒性

    Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in Autonomous Driving. (arXiv:2312.01468v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2312.01468](http://arxiv.org/abs/2312.01468)

    该研究评估了自动驾驶中的LiDAR-相机融合模型的对抗鲁棒性，发现在不改变图像数据通道的情况下，仅通过操纵LiDAR数据通道即可欺骗融合模型，这引发了自动驾驶领域的安全关注，并探讨了攻击的成功率与对抗性点数量、车辆间距离和角度因素的关系。该研究有助于提高自动驾驶的安全性。

    

    我们的研究评估了LiDAR-相机融合模型在3D物体检测中的对抗鲁棒性。我们引入了一种攻击技术，通过在车辆上方简单添加一定数量的物理约束的对抗性点，可以使融合模型无法检测到车辆。实验结果表明，即使不对图像数据通道进行更改，光达数据通道的操纵就足以欺骗融合模型。这一发现引发了自动驾驶领域的安全关注。此外，我们还探讨了对抗性点的数量、前方接近车辆与光达设备车辆之间的距离以及各种角度因素对攻击成功率的影响。我们相信我们的研究可以有助于理解多传感器的鲁棒性，并为提高自动驾驶的安全性提供洞见和指导。

    Our study assesses the adversarial robustness of LiDAR-camera fusion models in 3D object detection. We introduce an attack technique that, by simply adding a limited number of physically constrained adversarial points above a car, can make the car undetectable by the fusion model. Experimental results reveal that even without changes to the image data channel, the fusion model can be deceived solely by manipulating the LiDAR data channel. This finding raises safety concerns in the field of autonomous driving. Further, we explore how the quantity of adversarial points, the distance between the front-near car and the LiDAR-equipped car, and various angular factors affect the attack success rate. We believe our research can contribute to the understanding of multi-sensor robustness, offering insights and guidance to enhance the safety of autonomous driving.
    
[^87]: 医学图像的深度交互式分割：系统综述和分类

    Deep Interactive Segmentation of Medical Images: A Systematic Review and Taxonomy. (arXiv:2311.13964v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2311.13964](http://arxiv.org/abs/2311.13964)

    本综述系统地总结了医学图像交互式分割的最新研究进展，通过深度学习的方法推动了领域发展，但目前存在方法之间的比较缺乏的问题。

    

    交互式分割是医学图像分析中的关键研究领域，旨在通过结合人类反馈来提高昂贵注释的效率。这些反馈以点击、涂鸦或掩膜的形式出现，允许对模型输出进行迭代优化，以便有效引导系统实现所需的行为。近年来，基于深度学习的方法推动了结果达到一个新水平，导致该领域快速增长，仅医学影像领域就提出了121种方法。在本综述中，我们提供了这一新兴领域的结构化概述，包括全面的分类法、现有方法的系统综述以及对当前实践的深入分析。基于这些贡献，我们讨论了该领域的挑战和机遇。例如，我们发现方法之间的比较严重缺乏，需要通过标准化基准和基准数据进行解决。

    Interactive segmentation is a crucial research area in medical image analysis aiming to boost the efficiency of costly annotations by incorporating human feedback. This feedback takes the form of clicks, scribbles, or masks and allows for iterative refinement of the model output so as to efficiently guide the system towards the desired behavior. In recent years, deep learning-based approaches have propelled results to a new level causing a rapid growth in the field with 121 methods proposed in the medical imaging domain alone. In this review, we provide a structured overview of this emerging field featuring a comprehensive taxonomy, a systematic review of existing methods, and an in-depth analysis of current practices. Based on these contributions, we discuss the challenges and opportunities in the field. For instance, we find that there is a severe lack of comparison across methods which needs to be tackled by standardized baselines and benchmarks.
    
[^88]: InteraSSort: 使用大型语言模型的交互式商品组合规划

    InteraSSort: Interactive Assortment Planning Using Large Language Models. (arXiv:2311.12241v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.12241](http://arxiv.org/abs/2311.12241)

    InteraSSort是一种交互式商品组合规划框架，利用大型语言模型和优化工具帮助商店规划者解决复杂的店内规划问题。

    

    商品组合规划是电子商务和零售领域中研究的关键问题之一。我们提出了一种名为InteraSSort的交互式商品组合规划框架，利用大型语言模型和优化工具辅助商店规划者通过交互式对话做出决策。该解决方案具有用户友好界面，能够帮助商店规划者解决复杂的店内规划问题。

    Assortment planning, integral to multiple commercial offerings, is a key problem studied in e-commerce and retail settings. Numerous variants of the problem along with their integration into business solutions have been thoroughly investigated in the existing literature. However, the nuanced complexities of in-store planning and a lack of optimization proficiency among store planners with strong domain expertise remain largely overlooked. These challenges frequently necessitate collaborative efforts with multiple stakeholders which often lead to prolonged decision-making processes and significant delays. To mitigate these challenges and capitalize on the advancements of Large Language Models (LLMs), we propose an interactive assortment planning framework, InteraSSort that augments LLMs with optimization tools to assist store planners in making decisions through interactive conversations. Specifically, we develop a solution featuring a user-friendly interface that enables users to expre
    
[^89]: LLMs无法找到推理错误，但可以纠正它们！（arXiv：2311.08516v2 [cs.AI] UPDATED）

    LLMs cannot find reasoning errors, but can correct them!. (arXiv:2311.08516v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.08516](http://arxiv.org/abs/2311.08516)

    本文研究了LLMs在自我纠正过程中的错误发现和输出纠正两个核心组成部分。研究发现LLMs通常难以发现逻辑错误，但通过使用回溯方法可以在提供错误位置信息时获得大幅改进。

    

    尽管自我纠正在改善LLM输出的风格和质量方面显示出了潜力（例如Chen等，2023；Madaan等，2023），最近对逻辑或推理错误进行自我纠正的尝试通常会导致正确答案变为错误，从而总体表现变差（Huang等，2023）。在本文中，我们将自我纠正过程分解为两个核心组成部分：错误发现和输出纠正。对于错误发现，我们发布了BIG-Bench Mistake，这是一个Chain-of-Thought推理轨迹中的逻辑错误数据集。我们为几种最先进的LLM提供基准数，并证明LLM通常难以发现逻辑错误。对于输出纠正，我们提出了一种回溯方法，在提供错误位置信息时可以大幅改进。我们将回溯解释为对强化学习方法的轻量级替代方案，并展示了在60-70％准确率下保持有效性的奖励模型。

    While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (Huang et al., 2023). In this paper, we break down the self-correction process into two core components: mistake finding and output correction. For mistake finding, we release BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought reasoning traces. We provide benchmark numbers for several state-of-the-art LLMs, and demonstrate that LLMs generally struggle with finding logical mistakes. For output correction, we propose a backtracking method which provides large improvements when given information on mistake location. We construe backtracking as a lightweight alternative to reinforcement learning methods, and show that it remains effective with a reward model at 60-70% accuracy.
    
[^90]: DHOT-GM：使用可微分的分层最优传输框架实现鲁棒图匹配

    DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework. (arXiv:2310.12081v1 [cs.AI])

    [http://arxiv.org/abs/2310.12081](http://arxiv.org/abs/2310.12081)

    本研究提出了一种名为DHOT-GM的图匹配方法，使用可微分的分层最优传输框架，充分利用了图中隐藏的多模态信息，通过对匹配结果进行加权平均来推断节点对应关系。

    

    在实践中，图匹配是最重要的图分析任务之一，其目标是找到不同图之间的节点对应关系。大多数现有方法在匹配图时依赖于邻接矩阵或节点嵌入，其性能常常不够优越，因为没有充分利用图中隐藏的多模态信息，如节点属性、子图结构等。在本研究中，我们提出了一种基于可微分的分层最优传输（HOT）框架的新颖有效的图匹配方法，称为DHOT-GM。实质上，我们的方法将每个图表示为与不同模态信息对应的一组关系矩阵。给定两个图，我们枚举所有关系矩阵对，并获取它们的匹配结果，然后通过对匹配结果进行加权平均来推断节点对应关系。该方法可以实现为计算两个图之间的HOT距离，每个图都是由关系矩阵表示的。

    Graph matching is one of the most significant graph analytic tasks in practice, which aims to find the node correspondence across different graphs. Most existing approaches rely on adjacency matrices or node embeddings when matching graphs, whose performances are often sub-optimal because of not fully leveraging the multi-modal information hidden in graphs, such as node attributes, subgraph structures, etc. In this study, we propose a novel and effective graph matching method based on a differentiable hierarchical optimal transport (HOT) framework, called DHOT-GM. Essentially, our method represents each graph as a set of relational matrices corresponding to the information of different modalities. Given two graphs, we enumerate all relational matrix pairs and obtain their matching results, and accordingly, infer the node correspondence by the weighted averaging of the matching results. This method can be implemented as computing the HOT distance between the two graphs -- each matching 
    
[^91]: FABind: 快速准确的蛋白-配体结合

    FABind: Fast and Accurate Protein-Ligand Binding. (arXiv:2310.06763v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.06763](http://arxiv.org/abs/2310.06763)

    FABind是一个结合了口袋预测和对接的端到端模型，旨在实现快速准确的蛋白-配体结合预测。

    

    在药物发现中，对蛋白质和配体之间的相互作用进行建模并准确预测其结合结构是一项关键但具有挑战性的任务。深度学习的最新进展在应对这一挑战方面显示出了希望，采样法和回归法成为两种突出的方法。然而，这些方法都存在明显的局限性。采样法通常由于需要生成多个候选结构来进行选择而效率较低。而回归法提供了快速的预测，但可能会导致准确性降低。另外，蛋白质大小的变化通常需要外部模块来选择合适的结合口袋，进一步影响效率。在这项工作中，我们提出了FABind，一个将口袋预测和对接相结合的端到端模型，以实现准确和快速的蛋白-配体结合。

    Modeling the interaction between proteins and ligands and accurately predicting their binding structures is a critical yet challenging task in drug discovery. Recent advancements in deep learning have shown promise in addressing this challenge, with sampling-based and regression-based methods emerging as two prominent approaches. However, these methods have notable limitations. Sampling-based methods often suffer from low efficiency due to the need for generating multiple candidate structures for selection. On the other hand, regression-based methods offer fast predictions but may experience decreased accuracy. Additionally, the variation in protein sizes often requires external modules for selecting suitable binding pockets, further impacting efficiency. In this work, we propose $\mathbf{FABind}$, an end-to-end model that combines pocket prediction and docking to achieve accurate and fast protein-ligand binding. $\mathbf{FABind}$ incorporates a unique ligand-informed pocket prediction
    
[^92]: 逐步功能重构的关系概念分析

    Stepwise functional refoundation of relational concept analysis. (arXiv:2310.06441v1 [cs.AI])

    [http://arxiv.org/abs/2310.06441](http://arxiv.org/abs/2310.06441)

    逐步功能重构的关系概念分析（RCA）是形式概念分析的扩展，通过定义良构解决方案的空间和相关函数，解决了RCA在循环依赖数据上返回单一概念格家族的问题。

    

    关系概念分析（RCA）是形式概念分析的扩展，允许同时处理多个相关的语境。它被设计用于从数据中学习描述逻辑理论，并在各种应用中使用。关于RCA的一个令人困惑的观察是，尽管数据存在循环依赖关系，它返回一个单一的概念格家族，其他解决方案可能被认为是可接受的。RCA的语义以操作方式提供，对此问题并没有提供明确的解释。在本报告中，我们将这些可接受的解决方案定义为属于初始语境确定的空间的概念格家族（良构），不能扩展新属性（饱和），并且仅涉及该家族的概念（自支持）。我们通过定义良构解决方案的空间以及该空间上的两个函数（一个扩张函数和一个收缩函数），采用功能视图来描述RCA过程。我们展示了可接受的解决方案…

    Relational concept analysis (RCA) is an extension of formal concept analysis allowing to deal with several related contexts simultaneously. It has been designed for learning description logic theories from data and used within various applications. A puzzling observation about RCA is that it returns a single family of concept lattices although, when the data feature circular dependencies, other solutions may be considered acceptable. The semantics of RCA, provided in an operational way, does not shed light on this issue. In this report, we define these acceptable solutions as those families of concept lattices which belong to the space determined by the initial contexts (well-formed), cannot scale new attributes (saturated), and refer only to concepts of the family (self-supported). We adopt a functional view on the RCA process by defining the space of well-formed solutions and two functions on that space: one expansive and the other contractive. We show that the acceptable solutions a
    
[^93]: 基于LLM的代码生成中的偏差评估与缓解

    Bias Assessment and Mitigation in LLM-based Code Generation. (arXiv:2309.14345v1 [cs.SE])

    [http://arxiv.org/abs/2309.14345](http://arxiv.org/abs/2309.14345)

    这项研究提出了一个新颖的偏差评估框架，针对代码生成任务进行设计。通过对九个最先进的基于LLM的代码生成模型进行广泛评估，发现其中31.45\%到79.93\%的代码函数具有偏见，并提出了如何缓解这种偏见的方法。

    

    利用最新的大型语言模型（LLM），自动代码生成模型在提高软件开发编码过程的生产力和效率方面起着至关重要的作用。随着LLM在软件编码生态系统中的普及，一个紧迫的问题已经出现：生成的代码是否包含与年龄、性别和种族相关的社会偏见？这个问题关系到依赖于这些模型生成的代码的软件应用的完整性、公平性和道德基础，然而在文献中还没有得到充分探讨。本文提出了一个专为代码生成任务设计的新颖偏差评估框架。基于该框架，我们对九个最先进的基于LLM的代码生成模型的偏差进行了广泛评估。我们的发现揭示了，首先，我们评估的代码生成模型生成的31.45\%到79.93\%的代码函数具有偏见，9.68\%到37.37\%的代码函数的功能使

    Utilizing state-of-the-art Large Language Models (LLMs), automatic code generation models play a pivotal role in enhancing the productivity and efficiency of software development coding procedures. As the adoption of LLMs becomes more widespread in software coding ecosystems, a pressing issue has emerged: does the generated code contain social biases, such as those related to age, gender, and race? This issue concerns the integrity, fairness, and ethical foundation of software applications that depend on the code generated by these models, yet is under-explored in the literature. This paper presents a novel bias assessment framework that is specifically designed for code generation tasks. Based on this framework, we conduct an extensive evaluation on the bias of nine state-of-the-art LLM-based code generation models. Our findings reveal that first, 31.45\% to 79.93\% code functions generated by our evaluated code generation models are biased, and 9.68\% to 37.37\% code functions' funct
    
[^94]: s-ID：在子群体中的因果效应识别

    s-ID: Causal Effect Identification in a Sub-Population. (arXiv:2309.02281v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.02281](http://arxiv.org/abs/2309.02281)

    该论文介绍了在子群体中进行因果效应识别的问题，提出并倡导了s-ID问题。论文提供了必要和充分条件，以便从子群体的观测分布中识别出因果效应。

    

    在子群体中的因果推断涉及到识别干预对特定子组的因果效应，这些子组通过抽样过程中的系统偏差与整个群体有所区别。然而，忽略子群体引入的细微差别可能导致错误的推断，或者限制现有方法的适用性。我们引入并倡导子群体中的因果推断问题（以下简称s-ID），其中我们仅可以访问目标子群体的观测数据（而不是整个群体）。现有的子群体推断问题是基于给定的数据分布源于整个群体的前提，因此无法解决s-ID问题。为了填补这一差距，我们提供了在因果图中必须满足的必要和充分条件，以便从该子群体的观测分布中识别出子群体中的因果效应。

    Causal inference in a sub-population involves identifying the causal effect of an intervention on a specific subgroup, which is distinguished from the whole population through the influence of systematic biases in the sampling process. However, ignoring the subtleties introduced by sub-populations can either lead to erroneous inference or limit the applicability of existing methods. We introduce and advocate for a causal inference problem in sub-populations (henceforth called s-ID), in which we merely have access to observational data of the targeted sub-population (as opposed to the entire population). Existing inference problems in sub-populations operate on the premise that the given data distributions originate from the entire population, thus, cannot tackle the s-ID problem. To address this gap, we provide necessary and sufficient conditions that must hold in the causal graph for a causal effect in a sub-population to be identifiable from the observational distribution of that sub
    
[^95]: 下一个去哪里？大型语言模型作为人类移动预测器。

    Where Would I Go Next? Large Language Models as Human Mobility Predictors. (arXiv:2308.15197v1 [cs.AI])

    [http://arxiv.org/abs/2308.15197](http://arxiv.org/abs/2308.15197)

    本文研究了大型语言模型在人类移动预测任务中的潜力，提出了一种新方法LLM-Mob，通过利用语言模型的语言理解和推理能力分析人类移动数据，并引入历史停留和上下文停留的概念来捕捉长期和短期依赖关系，实现时态感知预测。

    

    准确的人类移动预测在许多重要应用中起着关键作用，包括流行病建模、交通规划和应急响应。由于移动数据的稀疏性和人们日常活动的随机性，实现对人们位置的精确预测仍然是一个挑战。虽然最近开发的大型语言模型（LLMs）在许多与语言相关的任务中展现出卓越性能，但它们在人类移动研究中的适用性尚未被探索。为了填补这一空白，本文探讨了LLMs在人类移动预测任务中的潜力。我们引入了一种新方法LLM-Mob，它利用LLMs的语言理解和推理能力来分析人类移动数据。我们提出了历史停留和上下文停留的概念，以捕捉人类移动中的长期和短期依赖关系，并通过使用时间信息来实现时态感知预测。

    Accurate human mobility prediction underpins many important applications across a variety of domains, including epidemic modelling, transport planning, and emergency responses. Due to the sparsity of mobility data and the stochastic nature of people's daily activities, achieving precise predictions of people's locations remains a challenge. While recently developed large language models (LLMs) have demonstrated superior performance across numerous language-related tasks, their applicability to human mobility studies remains unexplored. Addressing this gap, this article delves into the potential of LLMs for human mobility prediction tasks. We introduce a novel method, LLM-Mob, which leverages the language understanding and reasoning capabilities of LLMs for analysing human mobility data. We present concepts of historical stays and context stays to capture both long-term and short-term dependencies in human movement and enable time-aware prediction by using time information of the predic
    
[^96]: 适应口语对话的文本对话状态跟踪器

    Adapting text-based dialogue state tracker for spoken dialogues. (arXiv:2308.15053v1 [cs.CL])

    [http://arxiv.org/abs/2308.15053](http://arxiv.org/abs/2308.15053)

    这篇论文描述了对构建适应口语对话系统的文本对话状态跟踪器进行的工程工作，利用自动语音识别错误校正和文本对话系统实现了插槽和值的估计。

    

    尽管通过对话系统技术竞赛（DSTC）取得了显著进展，但构建一个具有语音界面的稳健的任务导向对话系统仍然是一个关键挑战。大部分进展都是针对基于文本的对话系统，因为有丰富的书面语料库数据集，而具有口语对话的数据集非常稀缺。然而，正如Siri和Alexa等语音助手系统所展示的，将这种成功转移到口语对话中具有实际重要性。在本文中，我们描述了我们在DSTC11的具有语音感知的对话系统技术挑战赛中的高度成功模型的工程努力。我们的模型由三个主要模块组成：（1）自动语音识别错误校正，以弥合口语和文本话语之间的差距，（2）用于估计插槽和值的基于文本的对话系统（D3ST），该系统使用插槽描述。

    Although there have been remarkable advances in dialogue systems through the dialogue systems technology competition (DSTC), it remains one of the key challenges to building a robust task-oriented dialogue system with a speech interface. Most of the progress has been made for text-based dialogue systems since there are abundant datasets with written corpora while those with spoken dialogues are very scarce. However, as can be seen from voice assistant systems such as Siri and Alexa, it is of practical importance to transfer the success to spoken dialogues. In this paper, we describe our engineering effort in building a highly successful model that participated in the speech-aware dialogue systems technology challenge track in DSTC11. Our model consists of three major modules: (1) automatic speech recognition error correction to bridge the gap between the spoken and the text utterances, (2) text-based dialogue system (D3ST) for estimating the slots and values using slot descriptions, an
    
[^97]: 基于分解的多机器人分层任务分配和规划方法在分层时序逻辑规范下

    Decomposition-based Hierarchical Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications. (arXiv:2308.10393v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2308.10393](http://arxiv.org/abs/2308.10393)

    提出了一种基于分解的分层框架，用于多机器人的任务分配和规划，能够处理具有复杂时间约束的任务。该框架首先将每个规范分解为原子子任务，然后推断不同规范之间子任务的时序关系来实现机器人间的协作。

    

    过去关于带有时序逻辑规范的机器人规划的研究主要基于单一公式，用于单个或多个机器人的任务。但是随着任务复杂性的增加，时序逻辑公式不可避免地变得冗长，使解释和规范生成变得复杂，并且对规划器的计算能力产生压力。最近的发展是提出了时序逻辑的分层表示，其中包含多个时序逻辑规范，提供更可解释的框架。然而，所提出的规划算法假设每个规范中的机器人是独立的，限制了它们在具有复杂时间约束的多机器人协调中的应用。在这项工作中，我们提出了一种基于分解的分层框架。在高层，每个规范首先被分解成一组原子子任务。我们进一步推断不同规范的子任务之间的时序关系来确ete机器人间的协作。

    Past research into robotic planning with temporal logic specifications, notably Linear Temporal Logic (LTL), was largely based on singular formulas for individual or groups of robots. But with increasing task complexity, LTL formulas unavoidably grow lengthy, complicating interpretation and specification generation, and straining the computational capacities of the planners. A recent development has been the hierarchical representation of LTL [1] that contains multiple temporal logic specifications, providing a more interpretable framework. However, the proposed planning algorithm assumes the independence of robots within each specification, limiting their application to multi-robot coordination with complex temporal constraints. In this work, we formulated a decomposition-based hierarchical framework. At the high level, each specification is first decomposed into a set of atomic sub-tasks. We further infer the temporal relations among the sub-tasks of different specifications to const
    
[^98]: 大型语言模型的不平等机会: 通过职位推荐揭示人口统计偏见

    The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations. (arXiv:2308.02053v1 [cs.CL])

    [http://arxiv.org/abs/2308.02053](http://arxiv.org/abs/2308.02053)

    通过职位推荐分析了大型语言模型（LLMs）的人口统计偏见，发现这些模型对于墨西哥工人一直建议低薪工作，并向女性更倾向于推荐秘书职位。这项研究强调了理解LLMs偏见的重要性。

    

    大型语言模型（LLMs）已在各种实际应用中得到广泛应用。了解这些偏见对于理解在使用LLMs进行决策时潜在的后续影响至关重要，特别是对于历史上处于劣势的群体。在这项工作中，我们提出了一种简单的方法来通过职位推荐的角度分析和比较LLMs中的人口统计偏见。我们通过测量ChatGPT和LLaMA这两个前沿LLMs内的交叉偏见来证明我们方法的有效性。我们的实验主要集中在揭示性别认同和国籍偏见上；然而，我们的方法可以扩展到任何人口统计身份的交叉偏见的研究。我们在两个模型中发现了明显的偏见，例如两个模型一直建议墨西哥工人从事低薪工作，或者更倾向于向女性推荐秘书职位。我们的研究强调了测量和理解LLMs中的偏见的重要性。

    Large Language Models (LLMs) have seen widespread deployment in various real-world applications. Understanding these biases is crucial to comprehend the potential downstream consequences when using LLMs to make decisions, particularly for historically disadvantaged groups. In this work, we propose a simple method for analyzing and comparing demographic bias in LLMs, through the lens of job recommendations. We demonstrate the effectiveness of our method by measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge LLMs. Our experiments primarily focus on uncovering gender identity and nationality bias; however, our method can be extended to examine biases associated with any intersection of demographic identities. We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. Our study highlights the importance of measu
    
[^99]: 变分分类

    Variational Classification. (arXiv:2305.10406v1 [cs.LG])

    [http://arxiv.org/abs/2305.10406](http://arxiv.org/abs/2305.10406)

    提出一种新的变分分类方法，通过引入潜变量建模来优化训练，允许灵活的设计选择以改善校准和对抗鲁棒性，实验结果表明其对于域外数据的分类准确性得到了保持。

    

    我们提出了一种传统神经网络方法的新型扩展，称为变分分类 (VC)。通过引入潜变量建模，类似于变分自编码器和传统自编码器之间的关系，我们得到了一个基于证据下界 (ELBO) 的训练目标，采用对抗性方法优化。我们的VC模型允许在设计选择方面更加灵活，特别是类条件潜先验，而不是在现成的softmax分类器中做出的隐式假设。在图像和文本分类数据集上的实证评估表明，我们的方法在保持预测准确性的同时，改善了其他良好特性，如校准和对抗鲁棒性，即使应用于域外数据。

    We present a novel extension of the traditional neural network approach to classification tasks, referred to as variational classification (VC). By incorporating latent variable modeling, akin to the relationship between variational autoencoders and traditional autoencoders, we derive a training objective based on the evidence lower bound (ELBO), optimized using an adversarial approach. Our VC model allows for more flexibility in design choices, in particular class-conditional latent priors, in place of the implicit assumptions made in off-the-shelf softmax classifiers. Empirical evaluation on image and text classification datasets demonstrates the effectiveness of our approach in terms of maintaining prediction accuracy while improving other desirable properties such as calibration and adversarial robustness, even when applied to out-of-domain data.
    
[^100]: 面向科学的无监督域转移：探索深度学习方法实现具有不同响应模型的LArTPC探测器模拟之间的翻译

    Unsupervised Domain Transfer for Science: Exploring Deep Learning Methods for Translation between LArTPC Detector Simulations with Differing Response Models. (arXiv:2304.12858v1 [hep-ex])

    [http://arxiv.org/abs/2304.12858](http://arxiv.org/abs/2304.12858)

    本文提出了一种基于最近在成对图像转换技术上的进展的，完全无监督的方法来减少LArTPC探测器模拟和真实数据之间的系统差异，以提高模型性能。

    

    深度学习技术在科学中具有广泛应用，特别是在寻求简化潜在解决方案和发现的路径方面。然而，DL模型经常在模拟结果上进行训练，然后应用于真实实验数据。因此，模拟和真实数据之间的任何系统差异可能会降低模型的性能，这种效应称为“领域漂移”。本文研究了一种系统差异的玩具模型，提出了一种完全无监督的任务不可知方法来减少两个系统不同的样本之间的差异。该方法基于最近在成对图像转换技术上的进展，并在两组模拟液氩时间投影室（LArTPC）探测器事件样本上进行了验证，这些样本被创建以控制地演示在模拟和真实数据之间的常见系统差异。LArTPC探测器代表了下一代粒子探测器的发展方向。

    Deep learning (DL) techniques have broad applications in science, especially in seeking to streamline the pathway to potential solutions and discoveries. Frequently, however, DL models are trained on the results of simulation yet applied to real experimental data. As such, any systematic differences between the simulated and real data may degrade the model's performance -- an effect known as "domain shift." This work studies a toy model of the systematic differences between simulated and real data. It presents a fully unsupervised, task-agnostic method to reduce differences between two systematically different samples. The method is based on the recent advances in unpaired image-to-image translation techniques and is validated on two sets of samples of simulated Liquid Argon Time Projection Chamber (LArTPC) detector events, created to illustrate common systematic differences between the simulated and real data in a controlled way. LArTPC-based detectors represent the next-generation pa
    
[^101]: 可控的信任权衡下的合成数据审计与生成

    Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])

    [http://arxiv.org/abs/2304.10819](http://arxiv.org/abs/2304.10819)

    本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。

    

    现实中收集的数据往往存在偏差、不平衡，并且有泄露敏感和隐私信息的风险。这一事实引发了创建合成数据集的想法，以减轻真实数据中固有的风险、偏见、伤害和隐私问题。这个概念依赖于生成AI模型，以产生不偏执、保护隐私的合成数据，同时忠实于真实数据。在这种新范式中，我们如何知道这种方法是否兑现了其承诺？我们提出了一个审计框架，提供了对合成数据集和基于它们训练的AI模型的全面评估，围绕偏见和歧视的预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。我们通过审计多个生成模型在不同用例中展示了我们的框架，包括教育、医疗保健、银行、人力资源，以及从表格，时间序列到自然语言的不同模态。我们的用例展示了在合成数据生成中平衡信任和效用的权衡的重要性。

    Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
    
[^102]: 通过约束层次强化学习处理长期和丰富约束的任务

    Handling Long and Richly Constrained Tasks through Constrained Hierarchical Reinforcement Learning. (arXiv:2302.10639v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10639](http://arxiv.org/abs/2302.10639)

    本文通过约束层次强化学习的机制解决了长期和丰富约束的任务，在机器人清洁房屋的场景中展示了良好的性能。

    

    过去在目标导向的强化学习（RL）设置中，通常通过对轨迹施加约束来处理安全问题，对于短期任务表现良好。本文特别关注解决时间上延续的决策问题，例如机器人在清洁房屋的不同区域时，需要避开湿滑和不安全的区域（例如楼梯），同时保持足够的电量移动到充电站；而且面临复杂的安全约束。我们的主要创新是将上层的约束搜索代理（从给定的起始状态到远处目标状态计算最大化回报策略，同时满足成本约束）与底层的目标条件强化学习代理（估计在附近状态之间移动的成本和回报值）结合使用的安全约束搜索与层次强化学习（CoSHRL）机制。CoSHRL的一个主要优势在于它可以处理对轨迹上的约束。

    Safety in goal directed Reinforcement Learning (RL) settings has typically been handled through constraints over trajectories and have demonstrated good performance in primarily short horizon tasks. In this paper, we are specifically interested in the problem of solving temporally extended decision making problems such as robots cleaning different areas in a house while avoiding slippery and unsafe areas (e.g., stairs) and retaining enough charge to move to a charging dock; in the presence of complex safety constraints. Our key contribution is a (safety) Constrained Search with Hierarchical Reinforcement Learning (CoSHRL) mechanism that combines an upper level constrained search agent (which computes a reward maximizing policy from a given start to a far away goal state while satisfying cost constraints) with a low-level goal conditioned RL agent (which estimates cost and reward values to move between nearby states). A major advantage of CoSHRL is that it can handle constraints on the 
    
[^103]: 基于混合谱方法和谐振子的非可分离协方差核的时空高斯过程研究

    Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes based on a Hybrid Spectral Method and the Harmonic Oscillator. (arXiv:2302.09580v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09580](http://arxiv.org/abs/2302.09580)

    该论文提出了一种基于混合谱方法和谐振子的非可分离协方差核的时空高斯过程研究，通过物理论证推导出一类新型的非可分离协方差核，能更好地捕捉观测到的时空相关性。

    

    高斯过程提供了一个灵活的非参数框架，用于近似高维空间中的函数。协方差核是高斯过程的主要引擎，包含了预测分布的相关性。对于具有时空数据集的应用，合适的核应该建模联合的时空依赖关系。可分离的时空协方差核提供了简单和计算效率较高的方案。然而，非可分离核包含了更好地捕捉观测到的相关性的时空交互作用。大多数具有显式表达式的非可分离核是基于数学考虑（可允许条件）而非基于第一原理导出的。我们提出了一种基于物理论证的混合谱方法来生成协方差核。我们使用这种方法推导了一类新型的物理动机的非可分离协方差核，它们的根源来自随机线性...

    Gaussian processes provide a flexible, non-parametric framework for the approximation of functions in high-dimensional spaces. The covariance kernel is the main engine of Gaussian processes, incorporating correlations that underpin the predictive distribution. For applications with spatiotemporal datasets, suitable kernels should model joint spatial and temporal dependence. Separable space-time covariance kernels offer simplicity and computational efficiency. However, non-separable kernels include space-time interactions that better capture observed correlations. Most non-separable kernels that admit explicit expressions are based on mathematical considerations (admissibility conditions) rather than first-principles derivations. We present a hybrid spectral approach for generating covariance kernels which is based on physical arguments. We use this approach to derive a new class of physically motivated, non-separable covariance kernels which have their roots in the stochastic, linear, 
    
[^104]: 基于结构感知的SMT加权模型集成的增强

    Enhancing SMT-based Weighted Model Integration by Structure Awareness. (arXiv:2302.06188v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.06188](http://arxiv.org/abs/2302.06188)

    本论文提出了一种基于结构感知的SMT加权模型集成算法，用于处理混合领域的概率推断问题，并能够避免生成冗余模型。

    

    有效的精确和近似概率推断算法的开发是人工智能研究的一个长期目标。虽然在处理纯离散或纯连续领域方面取得了实质性进展，但将这些解决方案适应于离散和连续变量及其关系的混合领域是非常困难的。加权模型集成（WMI）最近成为混合领域概率推断的统一形式。尽管最近有相当数量的工作，但使WMI算法随着混合问题的复杂性而扩展仍然是一个挑战。在本文中，我们强调了现有最先进解决方案的一些重大局限性，并开发了一种算法，将基于SMT的枚举（一种形式验证中的有效技术）与问题结构的有效编码相结合。这使得我们的算法能够避免生成冗余模型。

    The development of efficient exact and approximate algorithms for probabilistic inference is a long-standing goal of artificial intelligence research. Whereas substantial progress has been made in dealing with purely discrete or purely continuous domains, adapting the developed solutions to tackle hybrid domains, characterised by discrete and continuous variables and their relationships, is highly non-trivial. Weighted Model Integration (WMI) recently emerged as a unifying formalism for probabilistic inference in hybrid domains. Despite a considerable amount of recent work, allowing WMI algorithms to scale with the complexity of the hybrid problem is still a challenge. In this paper we highlight some substantial limitations of existing state-of-the-art solutions, and develop an algorithm that combines SMT-based enumeration, an efficient technique in formal verification, with an effective encoding of the problem structure. This allows our algorithm to avoid generating redundant models, 
    
[^105]: 通过元学习Transformer实现通用上下文学习

    General-Purpose In-Context Learning by Meta-Learning Transformers. (arXiv:2212.04458v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04458](http://arxiv.org/abs/2212.04458)

    本文展示了Transformer和其他黑盒模型可以通过元学习训练成为通用的上下文学习器，该模型可以在各种问题上进行测试集预测，无需定义推理模型、训练损失或优化算法。

    

    现代机器学习要求系统设计者指定学习流程的方方面面，例如损失函数、架构和优化器。而元学习，或者学会学习，目标是学习这些方面，并承诺以更少的手动工作开启更大的能力。元学习的一个特别雄心勃勃的目标是从头开始训练通用的上下文学习算法，仅使用带有最小归纳偏见的黑盒模型。这样的模型接收训练数据，并在各种问题上产生测试集预测，而无需定义推理模型、训练损失或优化算法。在本文中，我们展示了Transformer和其他黑盒模型可以被元训练成为通用的上下文学习器。我们通过模型大小、任务数量和元优化引起的算法之间的转换进行了表征，这些算法可以实现泛化，也可以实现记忆，还有一些算法根本无法进行元训练。

    Modern machine learning requires system designers to specify aspects of the learning pipeline, such as losses, architectures, and optimizers. Meta-learning, or learning-to-learn, instead aims to learn those aspects, and promises to unlock greater capabilities with less manual effort. One particularly ambitious goal of meta-learning is to train general-purpose in-context learning algorithms from scratch, using only black-box models with minimal inductive bias. Such a model takes in training data, and produces test-set predictions across a wide range of problems, without any explicit definition of an inference model, training loss, or optimization algorithm. In this paper we show that Transformers and other black-box models can be meta-trained to act as general-purpose in-context learners. We characterize transitions between algorithms that generalize, algorithms that memorize, and algorithms that fail to meta-train at all, induced by changes in model size, number of tasks, and meta-opti
    
[^106]: DyG2Vec: 带有自监督的动态图表征学习

    DyG2Vec: Representation Learning for Dynamic Graphs with Self-Supervision. (arXiv:2210.16906v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.16906](http://arxiv.org/abs/2210.16906)

    DyG2Vec是一个具有自监督学习能力的动态图表征学习模型，采用了高效而有效的注意力编码器和非对比自监督学习方法，能够提取丰富的时间嵌入表示。在基准数据集上的实验结果表明，该模型在未来链接预测任务中表现出色。

    

    时间图神经网络已经展示出在通过自动提取时间模式来学习归纳表示方面的有希望结果。然而，以往的工作常常依赖于复杂的记忆模块或低效的随机游走方法来构建时间表示。此外，现有的动态图编码器不容易适应自监督范式，这阻碍了它们利用无标签数据。为了解决这些限制，我们提出了一种高效而有效的基于注意力的编码器，利用时间边编码和基于窗口的子图采样来生成任务无关的嵌入。此外，我们提出了一种使用非对比SSL的联合嵌入架构，以学习丰富的时间嵌入而不需要标签。在7个基准数据集上的实验结果表明，我们的模型在传导设置和归纳设置的未来链接预测任务中，平均优于现有的SoTA基线4.23％和3.30％。

    Temporal graph neural networks have shown promising results in learning inductive representations by automatically extracting temporal patterns. However, previous works often rely on complex memory modules or inefficient random walk methods to construct temporal representations. In addition, the existing dynamic graph encoders are non-trivial to adapt to self-supervised paradigms, which prevents them from utilizing unlabeled data. To address these limitations, we present an efficient yet effective attention-based encoder that leverages temporal edge encodings and window-based subgraph sampling to generate task-agnostic embeddings. Moreover, we propose a joint-embedding architecture using non-contrastive SSL to learn rich temporal embeddings without labels. Experimental results on 7 benchmark datasets indicate that on average, our model outperforms SoTA baselines on the future link prediction task by 4.23% for the transductive setting and 3.30% for the inductive setting while only requi
    
[^107]: 学习图像表示以进行异常检测：在药物开发中发现组织学改变的应用

    Learning image representations for anomaly detection: application to discovery of histological alterations in drug development. (arXiv:2210.07675v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.07675](http://arxiv.org/abs/2210.07675)

    该论文提出了一种基于CNN的异常检测系统，通过对健康组织进行辅助任务训练，使表示适应组织中的相关细节，实现对组织学图像中的异常情况检测。

    

    我们提出了一种用于组织病理学图像异常检测的系统。在组织学中，正常样本通常是大量存在的，而异常（病理）情况通常很少或不可用。在这种情况下，使用在健康数据上训练的单类分类器可以检测到分布外的异常样本。这样的方法与预训练的卷积神经网络（CNN）图像表示相结合，以前已经用于异常检测（AD）。但是，预训练的现成CNN表示可能对组织中的异常情况不敏感，而健康组织的自然变异可能导致远离的表示。为了使表示适应健康组织中的相关细节，我们建议在辅助任务上训练CNN，该任务区分不同物种、器官和染色试剂的健康组织。几乎不需要额外的标注工作量，因为健康样本可以自动获得上述标签。在训练中，我们强制执行

    We present a system for anomaly detection in histopathological images. In histology, normal samples are usually abundant, whereas anomalous (pathological) cases are scarce or not available. Under such settings, one-class classifiers trained on healthy data can detect out-of-distribution anomalous samples. Such approaches combined with pre-trained Convolutional Neural Network (CNN) representations of images were previously employed for anomaly detection (AD). However, pre-trained off-the-shelf CNN representations may not be sensitive to abnormal conditions in tissues, while natural variations of healthy tissue may result in distant representations. To adapt representations to relevant details in healthy tissue we propose training a CNN on an auxiliary task that discriminates healthy tissue of different species, organs, and staining reagents. Almost no additional labeling workload is required, since healthy samples come automatically with aforementioned labels. During training we enforce
    
[^108]: 利用同形异义字在文本到图像合成中挖掘文化偏见

    Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis. (arXiv:2209.08891v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.08891](http://arxiv.org/abs/2209.08891)

    研究表明，在文本到图像合成过程中，通过插入异形字，模型会反映生成图片中的文化刻板印象和偏见。这一现象的根本原因是模型的文本编码器。而恶意用户或服务提供商还可能利用类似外形的非拉丁字符，故意引入偏见，创造种族主义刻板印象。

    

    文本到图像合成模型，例如DALL-E 2和Stable Diffusion，近年来吸引了学术界和广大公众的广泛关注。这些模型可以在文本描述的条件下生成描绘各种概念和风格的高质量图像。然而，这些模型从大量的训练数据中采用了与特定Unicode脚本相关的文化特征，这可能不会立即显现。我们展示了通过在文本描述中简单插入单个非拉丁字符，常见模型呈现出生成图像中的文化刻板印象和偏见。我们定性和定量分析了这种行为，并确定了模型的文本编码器是这一现象的根本原因。此外，恶意用户或服务提供商可能试图意图性地通过将拉丁字符替换为非拉丁脚本中外形相似的字符，来引入偏见，创造种族主义刻板印象。

    Models for text-to-image synthesis, such as DALL-E~2 and Stable Diffusion, have recently drawn a lot of interest from academia and the general public. These models are capable of producing high-quality images that depict a variety of concepts and styles when conditioned on textual descriptions. However, these models adopt cultural characteristics associated with specific Unicode scripts from their vast amount of training data, which may not be immediately apparent. We show that by simply inserting single non-Latin characters in a textual description, common models reflect cultural stereotypes and biases in their generated images. We analyze this behavior both qualitatively and quantitatively, and identify a model's text encoder as the root cause of the phenomenon. Additionally, malicious users or service providers may try to intentionally bias the image generation to create racist stereotypes by replacing Latin characters with similarly-looking characters from non-Latin scripts, so-cal
    
[^109]: 论人工智能和机器学习的演变：朝着在主要人工智能会议上衡量和理解影响、影响力和领导力的元级的方向发展

    On the Evolution of A.I. and Machine Learning: Towards a Meta-level Measuring and Understanding Impact, Influence, and Leadership at Premier A.I. Conferences. (arXiv:2205.13131v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.13131](http://arxiv.org/abs/2205.13131)

    本研究旨在理解人工智能和机器学习的演变，通过衡量研究者在该领域的影响、影响力和领导力，并通过分析在主要人工智能会议上发表的论文，揭示了人工智能领域的发展和演变。人工智能的发展导致了学术论文数量的增加，本研究构建了全面的引用和合作数据集，对相关关系进行了计算。

    

    人工智能现在被认为是一项对人类生活产生广泛影响的通用技术。本研究旨在从研究者对该领域的贡献角度来理解人工智能以及机器学习的演变。为此，我们提出了几种衡量人工智能和机器学习研究者影响、影响力和领导力的指标，并通过研究自1969年首次举办国际人工智能联合会议 (IJCAI) 以来在主要人工智能和机器学习会议上发表的论文，对人工智能领域的发展和演变进行探索，从而在一定程度上对人工智能的历史和演变有了新的认识。人工智能的发展和演变导致了学术论文的增加，在过去的六十年来发表的文章数量也有所反映。我们构建了全面的引用合作与论文-作者数据集，并计算了合作引用关系。

    Artificial Intelligence is now recognized as a general-purpose technology with ample impact on human life. This work aims at understanding the evolution of AI and, in particular Machine learning, from the perspective of researchers' contributions to the field. In order to do so, we present several measures allowing the analyses of AI and machine learning researchers' impact, influence, and leadership over the last decades. This work also contributes, to a certain extent, to shed new light on the history and evolution of AI by exploring the dynamics involved in the field's evolution by looking at papers published at the flagship AI and machine learning conferences since the first International Joint Conference on Artificial Intelligence (IJCAI) held in 1969. AI development and evolution have led to increasing research output, reflected in the number of articles published over the last sixty years. We construct comprehensive citation collaboration and paper-author datasets and compute co
    
[^110]: 药物设计中的分子生成：图学习的视角

    Molecule Generation for Drug Design: a Graph Learning Perspective. (arXiv:2202.09212v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.09212](http://arxiv.org/abs/2202.09212)

    本论文调研了药物设计领域中基于图学习的分子生成方法，分为一步到位法、基于片段法和节点逐个法三类，介绍了公共数据集和评估指标，并讨论了未来研究的挑战和方向。

    

    机器学习，特别是图学习，在各个领域都获得了越来越多的认可，具有变革性的影响。其中一个有前景的应用领域是药物设计和发现，特别是在制药行业中。我们的调研提供了药物设计领域现有方法的综合概述，特别关注将（深度）图学习技术纳入其中的全新药物设计方法。我们将这些方法分为三个不同的组：一）一步到位法，二）基于片段法，三）节点逐个法。此外，我们介绍了一些关键的公共数据集，并概述了分子生成和优化常用的评估指标。最后，我们讨论了该领域现有的挑战并提出了未来研究的潜在方向。

    Machine learning, particularly graph learning, is gaining increasing recognition for its transformative impact across various fields. One such promising application is in the realm of molecule design and discovery, notably within the pharmaceutical industry. Our survey offers a comprehensive overview of state-of-the-art methods in molecule design, particularly focusing on \emph{de novo} drug design, which incorporates (deep) graph learning techniques. We categorize these methods into three distinct groups: \emph{i)} \emph{all-at-once}, \emph{ii)} \emph{fragment-based}, and \emph{iii)} \emph{node-by-node}. Additionally, we introduce some key public datasets and outline the commonly used evaluation metrics for both the generation and optimization of molecules. In the end, we discuss the existing challenges in this field and suggest potential directions for future research.
    
[^111]: PHPQ: 金字塔混合池化量化用于高效的细粒度图像检索

    PHPQ: Pyramid Hybrid Pooling Quantization for Efficient Fine-Grained Image Retrieval. (arXiv:2109.05206v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.05206](http://arxiv.org/abs/2109.05206)

    PHPQ是一种用于高效细粒度图像检索的金字塔混合池化量化方法。它通过金字塔混合池化模块捕获和保留多层次特征中的细粒度语义信息，并引入可学习的量化模块来提高哈希的表达能力。

    

    鉴于其高计算和存储效率，深度哈希方法（包括深度量化和深度二进制哈希）已成为大规模图像检索的常见解决方案。然而，大多数现有的哈希方法对于细粒度检索无法产生令人满意的结果，因为它们通常采用最后一个CNN层的输出生成二进制码。由于更深的层倾向于将视觉线索（如纹理）总结为抽象的语义（如狗和猫），最后一个CNN层产生的特征在捕捉浅层中存在但具有辨别力的细微视觉细节方面效果较差。为了改善细粒度图像哈希，我们提出了金字塔混合池化量化（PHPQ）方法。具体地，我们提出了金字塔混合池化（PHP）模块，用于从多层次特征中捕获和保留细粒度的语义信息，强调不同子类别之间的细微区分。此外，我们还提出了一个可学习的量化模块来进一步提高哈希的表达能力。

    Deep hashing approaches, including deep quantization and deep binary hashing, have become a common solution to large-scale image retrieval due to their high computation and storage efficiency. Most existing hashing methods cannot produce satisfactory results for fine-grained retrieval, because they usually adopt the outputs of the last CNN layer to generate binary codes. Since deeper layers tend to summarize visual clues, e.g., texture, into abstract semantics, e.g., dogs and cats, the feature produced by the last CNN layer is less effective in capturing subtle but discriminative visual details that mostly exist in shallow layers. To improve fine-grained image hashing, we propose Pyramid Hybrid Pooling Quantization (PHPQ). Specifically, we propose a Pyramid Hybrid Pooling (PHP) module to capture and preserve fine-grained semantic information from multi-level features, which emphasizes the subtle discrimination of different sub-categories. Besides, we propose a learnable quantization mo
    

