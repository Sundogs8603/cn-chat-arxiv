# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective.](http://arxiv.org/abs/2308.13985) | 本论文重新审视了多任务学习中的标量化方法，并从理论的角度探讨了标量化是否能够充分探索帕累托前沿。结果显示，与最近的研究声称的经验优势相反，标量化本质上无法进行全面探索，特别是对于那些平衡了paren |
| [^2] | [Enhancing Bloodstain Analysis Through AI-Based Segmentation: Leveraging Segment Anything Model for Crime Scene Investigation.](http://arxiv.org/abs/2308.13979) | 本文通过应用预训练的Segment Anything Model和微调的Segment Anything Model在各种图像背景下的血迹图像分割中，证明了其准确性和效率的满意度，微调的模型比预训练模型准确性提升了2.2％，在图像识别速度方面加快了4.70％。 |
| [^3] | [Understanding the Usage of QUBO-based Hamiltonian Function in Combinatorial Optimization over Graphs: A Discussion Using Max Cut (MC) Problem.](http://arxiv.org/abs/2308.13978) | 研究探讨了在图上基于QUBO公式的最大切割问题中，如何使用基于强化学习范式和哈密顿函数来解决组合优化问题。通过使用图神经网络作为信息传递架构，并通过三种不同的公式形式进行实验，发现... |
| [^4] | [Label Denoising through Cross-Model Agreement.](http://arxiv.org/abs/2308.13976) | 本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。 |
| [^5] | [FAM: fast adaptive meta-learning.](http://arxiv.org/abs/2308.13970) | 本论文提出了一个快速自适应联邦元学习（FAM）框架，可以协作学习一个全局模型，并在个别客户端上进行个性化。这解决了数据分布发散和隐私限制的问题，并且适用于需要在不同客户端之间进行个性化的领域转变。 |
| [^6] | [Fixating on Attention: Integrating Human Eye Tracking into Vision Transformers.](http://arxiv.org/abs/2308.13969) | 本研究展示了如何将人眼追踪集成到视觉Transformer模型中，提高在多种驾驶情况和数据集上的准确性。 |
| [^7] | [Improving Knowledge Distillation for BERT Models: Loss Functions, Mapping Methods, and Weight Tuning.](http://arxiv.org/abs/2308.13958) | 本研究旨在改进BERT模型的知识蒸馏方法，通过实验不同的损失函数、映射方法和权重调整，提高知识蒸馏的效率和精度，从而压缩大型Transformer模型，使其在保持准确性的同时更加高效。 |
| [^8] | [Differentiable Weight Masks for Domain Transfer.](http://arxiv.org/abs/2308.13957) | 本论文通过将模块化权重和领域迁移相结合，研究了三种权重掩码方法，并分析它们在保持源任务知识的同时允许高效微调目标任务的能力。 |
| [^9] | [Exploring Large Language Models for Knowledge Graph Completion.](http://arxiv.org/abs/2308.13916) | 本文研究了利用大型语言模型（LLM）进行知识图谱补全的方法，并引入了一种创新的框架（知识图谱LLM），以提高三元组分类和关系预测的性能。 |
| [^10] | [A Wide Evaluation of ChatGPT on Affective Computing Tasks.](http://arxiv.org/abs/2308.13911) | 本论文广泛研究了ChatGPT模型在13个情感计算问题上的能力，并提出了一种能够评估ChatGPT模型在回归问题上的框架。 |
| [^11] | [Exploring Human Crowd Patterns and Categorization in Video Footage for Enhanced Security and Surveillance using Computer Vision and Machine Learning.](http://arxiv.org/abs/2308.13910) | 本文通过使用计算机视觉和机器学习，探索了在视频中追踪人类群体模式和分类的方法，进而增强安全和监视。通过将运动分为不同的弧形、车道、汇聚/分散和随机/阻塞运动，并使用光流技术、CNN模型和机器学习模型，成功地实现了目标，并获得了具有前景的准确性。这些结果可以用于训练异常检测模型、基于运动提供行为洞察，并增强场景理解能力。 |
| [^12] | [Federated Fine-tuning of Billion-Sized Language Models across Mobile Devices.](http://arxiv.org/abs/2308.13894) | 这项工作引入了一种创新的FL协议FwdLLM，旨在提高在移动设备上进行十亿规模语言模型的联邦微调（FedLLM）的效率。FwdLLM通过使用无反向传播（BP）训练方法以及“扰动推断”来提高内存效率和时间效率。 |
| [^13] | [The DiffuseStyleGesture+ entry to the GENEA Challenge 2023.](http://arxiv.org/abs/2308.13879) | DiffuseStyleGesture+是对GENEA挑战的解决方案，利用多模态数据和扩散模型，能够自动生成高质量、逼真的会话手势，并在人类类似性和适应性方面表现出与顶级模型相媲美的性能。 |
| [^14] | [Graph Edit Distance Learning via Different Attention.](http://arxiv.org/abs/2308.13871) | 该论文提出了一种通过不同的关注方式学习图编辑距离的方法，该方法通过图级特征融合模块显著提高了计算的准确性，相对于节点级融合，具有更好的性能和效率。 |
| [^15] | [Effectively Heterogeneous Federated Learning: A Pairing and Split Learning Based Approach.](http://arxiv.org/abs/2308.13849) | 该论文提出了一种有效的异构联邦学习方法，通过配对和分裂学习，解决了异构性带来的训练速度问题，提高了联邦学习的效率。 |
| [^16] | [Deep Learning for Structure-Preserving Universal Stable Koopman-Inspired Embeddings for Nonlinear Canonical Hamiltonian Dynamics.](http://arxiv.org/abs/2308.13835) | 该论文利用深度学习为非线性哈密顿系统发现了保持结构的全局线性化嵌入，通过辛变换获得紧凑辛嵌入，并重点关注其动力学的有界稳定性。 |
| [^17] | [A Survey of Imbalanced Learning on Graphs: Problems, Techniques, and Future Directions.](http://arxiv.org/abs/2308.13821) | 本综述对图上不平衡学习进行了全面的审视，旨在纠正数据分布偏差，以获得更准确和代表性的学习结果。 |
| [^18] | [Packet Header Recognition Utilizing an All-Optical Reservoir Based on Reinforcement-Learning-Optimized Double-Ring Resonator.](http://arxiv.org/abs/2308.13818) | 本文提出了一种基于双环谐振器的全光储备系统，通过使用深度强化学习算法，最大化延迟-带宽积参数，实现了快速、准确的光分组头识别。优化后的级联环可用于实现小尺寸、平顶延迟谱的光计算。 |
| [^19] | [Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models.](http://arxiv.org/abs/2308.13812) | 本文提出了一种新的方法（称为Dysen）来增强面向动态感知的文本到视频扩散，通过提取关键动作、建立动态场景图和丰富细节，以实现高质量的T2V生成。 |
| [^20] | [Reinforcement Learning Based Multi-modal Feature Fusion Network for Novel Class Discovery.](http://arxiv.org/abs/2308.13801) | 本文提出了一种基于强化学习的多模态特征融合网络，用于解决开放集领域中的新类别发现问题。通过模拟人类的认知过程，采用成员-领导者多智能体框架从多模态信息中提取和融合特征，进一步融入自监督学习以增强模型训练，并通过聚类方法来实现对潜在新类别的识别。 |
| [^21] | [Planning with Logical Graph-based Language Model for Instruction Generation.](http://arxiv.org/abs/2308.13782) | 本文提出了一种基于逻辑图的语言模型，Logical-GLM，用于指导语言模型生成具有正确逻辑的文本，并以提高文本生成的有效性和可解释性。实验结果表明，Logical-GLM在使用较少数据和参数的情况下仍然有效和高效。 |
| [^22] | [Unified Single-Stage Transformer Network for Efficient RGB-T Tracking.](http://arxiv.org/abs/2308.13764) | 提出了一种统一单级Transformer RGB-T跟踪网络USTrack，它通过双嵌入层和自注意机制实现模态之间的相互作用和互助指导，从而提高了网络适应目标的能力，并将三阶段融合跟踪范例合并为一个结构，提高了跟踪速度和目标-背景可区分性。 |
| [^23] | [How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context.](http://arxiv.org/abs/2308.13760) | 本文探索了如何将个性化上下文信息与文档对话系统结合，提出了个性化上下文感知的段落检索任务，并引入了一种有效利用上下文信息的新颖方法PCAS。通过实验证明，PCAS不仅在检索最相关的段落方面优于基准系统，而且在确定相关上下文方面也表现出色。这将激发未来研究的兴趣。 |
| [^24] | [SamDSK: Combining Segment Anything Model with Domain-Specific Knowledge for Semi-Supervised Learning in Medical Image Segmentation.](http://arxiv.org/abs/2308.13759) | 这篇论文介绍了一种新方法SamDSK，结合分割任意模型和领域特定知识，在医学图像分割中进行半监督学习。方法包括迭代的两个阶段：分割模型训练和使用训练好的模型和领域特定知识扩展有标签集。通过将分割建议和领域特定知识结合，构建无标签图像的注释。 |
| [^25] | [i-Align: an interpretable knowledge graph alignment model.](http://arxiv.org/abs/2308.13755) | i-Align是一种可解释的知识图对齐模型，可以提供对每个对齐预测的解释，并保持高对齐性能，维护知识图的高质量。 |
| [^26] | [PE-MED: Prompt Enhancement for Interactive Medical Image Segmentation.](http://arxiv.org/abs/2308.13746) | 本文介绍了一个名为PE-MED的新框架，用于提高交互式医学图像分割的成功率。它通过引入自循环策略和提示注意力学习模块来改善用户提供的提示信息的利用，从而防止不利情况的发生，并提高分割结果的准确性。 |
| [^27] | [On Philomatics and Psychomatics for Combining Philosophy and Psychology with Mathematics.](http://arxiv.org/abs/2308.13738) | 本文提出了将哲学、心理学与数学相结合的Philomatics和Psychomatics概念，并解释了四个动机：满足分析哲学的需求、提出哲学科学、用哲学来证明数学算法以及哲学和数学的抽象。并列举了多个示例，包括数学中注意机制和上下文原则、形式理论与全息原理的关系等。本文为将哲学和心理学与数学相结合的研究开辟了研究空间。 |
| [^28] | [A Comprehensive Survey for Evaluation Methodologies of AI-Generated Music.](http://arxiv.org/abs/2308.13736) | 这项研究综合评估了主观、客观和综合方法，用于评估AI生成音乐，突出了每种方法的优势和劣势，为统一音乐评估领域的生成AI提供了有价值的参考。 |
| [^29] | [ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning.](http://arxiv.org/abs/2308.13724) | 提出了ISR-LLM框架，通过迭代自我完善过程改进了LLM-based规划，该框架包括预处理、规划和迭代自我完善三个步骤。通过引入LLM翻译器将自然语言输入转换为PDDL形式，提高了生成的任务计划的可行性和正确性。 |
| [^30] | [WellXplain: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health Analysis.](http://arxiv.org/abs/2308.13710) | 本研究提出了一种通过在Reddit内容中识别健康维度的方法来进行复杂的精神健康分析。他们创建了一个名为WELLXPLAIN的数据集，并制定了一个注释框架。这种方法有助于在社交媒体上识别潜在的精神问题指标。 |
| [^31] | [Linking the Dynamic PicoProbe Analytical Electron-Optical Beam Line / Microscope to Supercomputers.](http://arxiv.org/abs/2308.13701) | 本文提出了将Dynamic PicoProbe的数据传输与Argonne领导计算设施相邻超级计算机相连接的软件架构，该架构支持大规模数据传输和离线数据分析，为科学家提供了查询和重新分析过去实验数据的能力。 |
| [^32] | [On the Depth between Beam Search and Exhaustive Search for Text Generation.](http://arxiv.org/abs/2308.13696) | 本研究探讨了束搜索和穷举搜索之间一系列不同的搜索深度，提出了前瞻束搜索（LBS）算法进行优化。尽管束搜索的搜索误差较高，但在计算成本和性能方面优于穷举搜索。 |
| [^33] | [An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the HYPSO-1 Satellite.](http://arxiv.org/abs/2308.13679) | 这个论文介绍了一个开放的卫星高光谱数据集，包含了来自HYPSO-1卫星的海陆云地面真实数据，并且通过优化深度学习模型，取得了比现有技术更好的性能。 |
| [^34] | [Rethinking Language Models as Symbolic Knowledge Graphs.](http://arxiv.org/abs/2308.13676) | 本研究对不同大小和能力的语言模型进行了全面评估，发现它们能否涵盖知识图谱的复杂拓扑和语义属性，这对于推理过程至关重要。 |
| [^35] | [Generating and Explaining Corner Cases Using Learnt Probabilistic Lane Graphs.](http://arxiv.org/abs/2308.13658) | 本论文提出了使用概率车道图生成和解释角落情况的方法，该方法基于历史交通数据生成新颖而逼真的角落情况，以提高自动驾驶车辆的安全性。 |
| [^36] | [ML-Powered Index Tuning: An Overview of Recent Progress and Open Challenges.](http://arxiv.org/abs/2308.13641) | 本文总结了现代云服务中自动索引调优面临的主要挑战，以及机器学习技术在解决这些挑战方面的最新进展。该研究主要关注工作负载选择、候选索引过滤、加速索引配置搜索、减少查询优化器调用的数量和降低性能回归机会等方面，并提出创新的解决方案。 |
| [^37] | [Adaptive whitening with fast gain modulation and slow synaptic plasticity.](http://arxiv.org/abs/2308.13633) | 本研究提出了一个多时间尺度的自适应白化机制模型，使用快速增益调制和慢速突触可塑性相结合的方式来适应变化的感觉统计信息。 |
| [^38] | [HiFiHR: Enhancing 3D Hand Reconstruction from a Single Image via High-Fidelity Texture.](http://arxiv.org/abs/2308.13628) | HiFiHR是一种通过高保真纹理增强来自单张图像的3D手部重建方法，能够生成逼真且准确的手部网格，并通过各种程度的监督方式改善手部姿态和形状估计。 |
| [^39] | [AI in Thyroid Cancer Diagnosis: Techniques, Trends, and Future Directions.](http://arxiv.org/abs/2308.13592) | 本论文总结了在甲状腺癌诊断中使用人工智能（AI）技术的相关研究。通过提出新的分类方法并比较现有数据集的特征，研究重点在于如何通过AI工具支持甲状腺癌的诊断和治疗。 |
| [^40] | [FrFT based estimation of linear and nonlinear impairments using Vision Transformer.](http://arxiv.org/abs/2308.13575) | 本论文提出了基于FrFT和Transformer的联合估计方法，用于统一表示和识别光纤通信系统中的线性和非线性失真。在数值模拟中验证了该方法的有效性。 |
| [^41] | [Stochastic Configuration Machines for Industrial Artificial Intelligence.](http://arxiv.org/abs/2308.13570) | 本文提出了一种新颖的随机学习器模型，称为随机配置机（SCMs），其基于随机配置网络（SCNs），旨在强调工业人工智能中的有效建模和节约数据大小。SCMs通过压缩模型存储，并保持有利的预测性能，具有在工业应用中很大的潜力。 |
| [^42] | [MLLM-DataEngine: An Iterative Refinement Approach for MLLM.](http://arxiv.org/abs/2308.13566) | 本文提出了一种名为MLLM-DataEngine的迭代改进方法，它通过分析模型弱点，生成适当的增量数据集并迭代地增强模型能力。与以往方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面表现更好。 |
| [^43] | [Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4.](http://arxiv.org/abs/2308.13563) | 三个大型语言模型接口(ChatGPT, BARD和GPT4)在分析事故叙述中的效果进行了比较研究。研究结果表明，它们在提取事故相关信息和回答相关问题方面都具有一定的有效性，但也存在一些限制。 |
| [^44] | [A Systematic Study on Quantifying Bias in GAN-Augmented Data.](http://arxiv.org/abs/2308.13554) | 该研究系统地研究了互动式对抗生成网络（GAN）在数据扩充中引入的偏见，以及用于度量偏见加重程度的度量标准的评估。研究结果表明，虽然有多种度量方法可用，但没有一种单一方法可以可靠地度量不同图像领域中的偏见加重。 |
| [^45] | [Dance with You: The Diversity Controllable Dancer Generation via Diffusion Models.](http://arxiv.org/abs/2308.13551) | 本文介绍了一种名为伙伴舞者生成的多舞者合成任务，旨在通过在保持与主导舞者时间协调的同时确保伙伴舞者的可控多样性。为了实现这一目标，提出了一个名为“与你共舞”的三阶段框架（DanY），它能自动设计伙伴舞者的姿势。 |
| [^46] | [Towards a Holodeck-style Simulation Game.](http://arxiv.org/abs/2308.13548) | Infinitia是一个模拟游戏系统，使用生成图像和语言模型根据玩家的描述塑造游戏场景和NPC，类似于全息舱，同时引入了无限生成的幻想世界、可控的NPC行为、幽默对话、成本和时间效率、玩家合作以及游戏内事件的非确定性元素。 |
| [^47] | [Functional Graph Contrastive Learning of Hyperscanning EEG Reveals Emotional Contagion Evoked by Stereotype-Based Stressors.](http://arxiv.org/abs/2308.13546) | 本研究通过利用超扫描技术，引入功能性图对比学习方法探究基于刻板印象的压力引发的情绪传染。研究结果揭示了情绪传染与认知功能之间的复杂相互作用。 |
| [^48] | [LaGR-SEQ: Language-Guided Reinforcement Learning with Sample-Efficient Querying.](http://arxiv.org/abs/2308.13542) | 这个论文介绍了LaGR（语言引导的强化学习），它利用大型语言模型（LLMs）的预测能力，提出解决部分完成任务的解决方案，以引导强化学习代理的训练。 |
| [^49] | [A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System.](http://arxiv.org/abs/2308.13538) | 本研究介绍了一个用于生成游戏特征建议的系统，通过使用文本提示，提取主题相似的游戏特征并生成新特征。经过用户研究比较，该系统的生成模型在某些游戏中的表现超过了人工建议。该系统是一个与用户在概念层面上进行协作的游戏设计助手工具的一部分。 |
| [^50] | [Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph.](http://arxiv.org/abs/2308.13534) | 本论文提出了一种综述和解决方案架构，用于构建可解释的、隐私感知的对话型AI系统。首先介绍了LLM模型的综合工具LLMXplorer，并阐明了其对社会、伦理和监管等方面的影响。然后提出了将知识图谱的结构动态与LLM的语言能力无缝集成的架构。通过使用真实世界的AI新闻数据进行验证，该架构成功地融合了语言的复杂性与事实的严谨性，并增强了数据安全性。 |
| [^51] | [CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement.](http://arxiv.org/abs/2308.12902) | 本研究提出了一种名为CDAN的卷积稠密注意力引导网络，用于低光图像增强。该网络结合了自编码器架构、卷积和稠密块、注意力机制和跳跃连接，通过专门的后处理阶段进一步改善色彩平衡和对比度。与现有方法相比，在低光图像增强方面取得了显著的进展，展示了在各种具有挑战性的场景中的稳健性。 |
| [^52] | [Large Language Models Vote: Prompting for Rare Disease Identification.](http://arxiv.org/abs/2308.12890) | 本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。 |
| [^53] | [CGMI: Configurable General Multi-Agent Interaction Framework.](http://arxiv.org/abs/2308.12503) | 本研究提出了一个名为CGMI的框架，旨在模拟真实世界场景中的人际交往。该框架采用了树状结构方法来管理智能体的个性，并设计了一个基于ACT*模型的认知架构。通过使用CGMI框架，我们成功模拟了教师和学生之间的课堂互动。 |
| [^54] | [A Probabilistic Fluctuation based Membership Inference Attack for Generative Models.](http://arxiv.org/abs/2308.12143) | 本研究针对生成模型提出了一种概率波动评估成员推断攻击方法(PFAMI)，通过检测概率分布的波动性来推断模型中是否存在某条训练记录的成员身份。 |
| [^55] | [Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments.](http://arxiv.org/abs/2308.12086) | 本文将预训练的大型语言模型（LLMs）应用于网络安全环境，作为攻击代理人进行顺序决策。该设计表明LLMs在高效应对复杂决策方面具有潜力，并且在大多数场景中表现出与经过训练的最先进代理相似或更好的性能。 |
| [^56] | [Pose Modulated Avatars from Video.](http://arxiv.org/abs/2308.11951) | 本文提出了一种基于神经辐射场和稀疏的摄像机组来重建动态人体运动和形状的方法。与现有的角色模型不同，我们的方法在频域中是自适应和显式的，并通过建模身体部位之间的相关性来解决衣物和皮肤的变形建模挑战。实验结果表明，我们的网络在性能上优于现有方法。 |
| [^57] | [Bridging the Gap: Deciphering Tabular Data Using Large Language Model.](http://arxiv.org/abs/2308.11891) | 本研究旨在提升大型语言模型在理解表格数据上的能力，通过设计一个表格序列化模块和纠正机制来实现。实验结果表明，尽管相对于最先进技术仍有差距，但该方法在处理表格数据方面取得了一定的进展。 |
| [^58] | [ProAgent: Building Proactive Cooperative AI with Large Language Models.](http://arxiv.org/abs/2308.11339) | ProAgent是一个利用大型语言模型构建的主动合作的AI框架，能够预测队友的决策并为自己制定增强计划，具有高度的模块化和可解释性。 |
| [^59] | [Enhancing Agent Communication and Learning through Action and Language.](http://arxiv.org/abs/2308.10842) | 通过行动和语言相结合的方式，我们引入了一种新型智能体，其能够同时作为教师和学习者，通过行动演示和语言指令增强了沟通效率，并探索了结合行动和语言沟通模式对学习结果的积极影响。 |
| [^60] | [Large Language Models for Software Engineering: A Systematic Literature Review.](http://arxiv.org/abs/2308.10620) | 通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。 |
| [^61] | [A Study on Robustness and Reliability of Large Language Model Code Generation.](http://arxiv.org/abs/2308.10335) | 本研究针对大型语言模型生成的代码的可靠性和鲁棒性进行了研究，发现在真实的软件开发中可执行的代码并不能保证可靠和鲁棒，滥用API可能导致严重问题。这对初级开发者来说尤其危险，因为他们很难察觉到代码中的API滥用问题。 |
| [^62] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^63] | [An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM.](http://arxiv.org/abs/2308.06828) | 本研究提出了一种集成Electra Transformer、GloVe和LSTM模型的创新问题分类方法，通过在TREC数据集上进行严格测试，证明了融合不同技术可以获得更优越的结果。 |
| [^64] | [CLE Diffusion: Controllable Light Enhancement Diffusion Model.](http://arxiv.org/abs/2308.06725) | CLE扩散是一种可控的光增强扩散模型，通过条件扩散和光照嵌入，让用户可以控制亮度水平，并结合任意分割模型实现用户友好的区域可控性。实验证明CLE Diffusion在各项指标上具有竞争力。 |
| [^65] | [Revealing the Underlying Patterns: Investigating Dataset Similarity, Performance, and Generalization.](http://arxiv.org/abs/2308.03580) | 该研究探索了监督深度学习模型的泛化能力和性能，并提出了一种结合距离度量和模型性能的方法，从候选架构中选择适当的模型/架构。结果显示，通过添加少量未见过的图像，可以改善模型的泛化能力。这种方法可以降低训练和标注成本，并在动态环境中提供模型在未见数据上的性能估计。 |
| [^66] | [External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback.](http://arxiv.org/abs/2307.12057) | 本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。 |
| [^67] | [Of Models and Tin Men -- a behavioural economics study of principal-agent problems in AI alignment using large-language models.](http://arxiv.org/abs/2307.11137) | 本研究基于行为经济学角度，对使用大语言模型进行AI对齐中的委托-代理问题进行研究，发现现实世界中的AI安全问题不仅涉及设计者与代理之间的冲突，还涉及到多个代理之间的信息不对称与效用函数之间的错位。 |
| [^68] | [What's meant by explainable model: A Scoping Review.](http://arxiv.org/abs/2307.09673) | 这项研究通过范围审查方法调查了应用人工智能模型并采用事后解释方法的论文，探讨了可解释模型这一术语的含义。 |
| [^69] | [Handwritten and Printed Text Segmentation: A Signature Case Study.](http://arxiv.org/abs/2307.07887) | 本研究旨在解决手写和打印文本分割的挑战，并提出了一种新的方法来完整地恢复不同类别的文本，特别是在重叠部分提高分割性能。同时，还引入了一个新的数据集SignaTR6K，用于支持该任务。 |
| [^70] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^71] | [On Formal Feature Attribution and Its Approximation.](http://arxiv.org/abs/2307.03380) | 这篇论文研究了解释性人工智能（XAI）中的形式特征归因方法及其近似方法。现有的特征选择和归因方法存在一些问题，而形式化的XAI方法虽然是一个有希望的解决方案，但仍存在一些限制。 |
| [^72] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^73] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^74] | [Emoji Prediction using Transformer Models.](http://arxiv.org/abs/2307.02054) | 使用基于Transformer的方法，在大型语料库上微调BERT模型以预测给定文本的表情符号。实验结果显示，该方法在预测准确率上优于其他最先进的模型，具有潜在的自然语言处理和社交媒体营销应用价值。 |
| [^75] | [Tensorformer: Normalized Matrix Attention Transformer for High-quality Point Cloud Reconstruction.](http://arxiv.org/abs/2306.15989) | Tensorformer是一种归一化矩阵注意力变换器，用于高质量的点云重建。它通过矩阵注意力实现了逐点和逐通道的消息传递，提供了更好的局部几何建模能力，并在两个数据集上取得了最先进的结果。 |
| [^76] | [Decentralized Multi-Agent Reinforcement Learning with Global State Prediction.](http://arxiv.org/abs/2306.12926) | 本文研究了分散式多智能体强化学习中的一个关键挑战：如何在没有全局信息的情况下有效训练机器人。我们提出了一种基于状态预测的方法，在不需要显式通信的情况下使机器人能够协调行动，实现更快更好的学习效果和任务执行性能。 |
| [^77] | [Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset.](http://arxiv.org/abs/2306.11167) | 这项研究探索了大型语言模型（LLMs）对创造性问题解决的能力，并发现大型语言模型容易被误导，出现固定效应和Einstellung范式。 |
| [^78] | [A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises.](http://arxiv.org/abs/2306.04802) | 本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。 |
| [^79] | [The feasibility of artificial consciousness through the lens of neuroscience.](http://arxiv.org/abs/2306.00915) | 从神经科学的角度来看，目前大型语言模型难以具备哺乳动物意识感知相关的丘脑皮层系统的关键特征，缺乏周围世界的具体嵌入式信息，且当前的人工智能无法做到存在的依赖于其行为，这意味着人工意识的可行性存在瓶颈。 |
| [^80] | [Bottom-Up Grounding in the Probabilistic Logic Programming System Fusemate.](http://arxiv.org/abs/2305.18924) | 介绍了自下而上推理的概率逻辑编程系统Fusemate，提出了基于查询引导的相关性测试修剪规则，解决了自下而上推理难以控制ground clauses生成数量的问题，并在包含“时间”的示例中表现出更好的性能。 |
| [^81] | [Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models.](http://arxiv.org/abs/2305.18703) | 本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。 |
| [^82] | [Evaluating Open-QA Evaluation.](http://arxiv.org/abs/2305.12421) | 本研究侧重于评估开放式问答（Open-QA）任务的方法，引入了一个新的任务QA-Eval和数据集EVOUNA，通过人工评估方法来评估AI生成的答案的准确性。我们调查了与人工评估相关的方法，并讨论了当前方法的缺陷和改进方法。我们相信这对于未来的自动评估工具发展和研究具有价值。 |
| [^83] | [A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation.](http://arxiv.org/abs/2305.11391) | 通过验证和验证的视角对大型语言模型的安全性和可信度进行调查，分类它们的已知漏洞，将其分为固有问题、有意攻击和意外错误。同时，考虑四种互补技术以提供LLM及其应用的安全和可信度保障。 |
| [^84] | [Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers.](http://arxiv.org/abs/2305.07011) | 本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。 |
| [^85] | [TinyML Design Contest for Life-Threatening Ventricular Arrhythmia Detection.](http://arxiv.org/abs/2305.05105) | TDC'22是第一届面向ICDs低功耗微控制器的人工智能/机器学习（AI/ML）算法创新竞赛。本次竞赛的挑战是开发一种基于AI/ML的新型实时检测算法，对危及生命的室性心律失常进行检测。 |
| [^86] | [Reinforcement Learning with Delayed, Composite, and Partially Anonymous Reward.](http://arxiv.org/abs/2305.02527) | 本文提出了一种算法用于解决具有延迟、复合和部分匿名奖励反馈的无限时平均奖励马尔可夫决策过程(MDP)，并取得了较好的效果。 |
| [^87] | [Map-based Experience Replay: A Memory-Efficient Solution to Catastrophic Forgetting in Reinforcement Learning.](http://arxiv.org/abs/2305.02054) | 本文提出了一种基于地图的经验回放方法，通过将存储的转换组织成一种简洁的环境模型网络，以在减少内存大小的同时增加每个样本的相关性，从而有效解决强化学习中的遗忘问题。 |
| [^88] | [Exploring the Mutual Influence between Self-Supervised Single-Frame and Multi-Frame Depth Estimation.](http://arxiv.org/abs/2304.12685) | 文章介绍了一种新的自监督训练框架，旨在充分利用单帧深度和多帧深度方法之间的相互影响。通过引入一个像素逐像素自适应深度采样模块，以单帧深度为指导来训练多帧模型，并利用最小重投影为基础的蒸馏方法来优化单帧深度的模型。 |
| [^89] | [Pretrained Language Models as Visual Planners for Human Assistance.](http://arxiv.org/abs/2304.09179) | 本研究提出了视觉辅助计划（VPA）的任务，利用预训练语言模型作为序列模型，在视频行动分割和预测方面优于现有的方法，来实现多模态AI助手指导用户完成复杂多步骤目标的进展。 |
| [^90] | [Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning.](http://arxiv.org/abs/2304.07920) | 本论文提出了一种基于因果决策Transformer和离线强化学习的推荐系统，通过探索用户行为的因果关系，指导代理捕捉动态兴趣，并解决了大规模情境下数据效率低的问题。 |
| [^91] | [PGTask: Introducing the Task of Profile Generation from Dialogues.](http://arxiv.org/abs/2304.06634) | 对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。 |
| [^92] | [ASR: Attention-alike Structural Re-parameterization.](http://arxiv.org/abs/2304.06345) | 该论文提出的ASR技术是一种新颖的深度学习技术，通过等效参数转换实现不同网络体系结构之间的互转。和现有的SRP方法相比，ASR可以成功考虑自注意模块，实现推理期间的性能提升，并在工业和实际应用中具有巨大潜力。 |
| [^93] | [Interaction-Aware Prompting for Zero-Shot Spatio-Temporal Action Detection.](http://arxiv.org/abs/2304.04688) | 提出了一种采用预训练的视觉-语言模型和交互模块进行交互感知提示的零样本时空动作检测方法，优化了视觉-语言特征的对齐，实现了更好的结果。 |
| [^94] | [Retention Is All You Need.](http://arxiv.org/abs/2304.03103) | 本研究提出了HR-DSS方法，使用可解释的AI帮助人力资源部门解释机器学习模型提供的员工流失预测结果，并且提供“What-if-analysis”来观察个体员工可能导致离职的原因。 |
| [^95] | [GINA-3D: Learning to Generate Implicit Neural Assets in the Wild.](http://arxiv.org/abs/2304.02163) | GINA-3D是一种学习从真实场景中生成3D隐式神经资产的生成模型，这对于自主驾驶等机器人学习问题的测试和验证环境是重要的创新。 |
| [^96] | [Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?.](http://arxiv.org/abs/2304.01002) | 这项研究研究了人类合作是否增强了识别LLM生成的深度伪造文本的准确性。结果表明，合作可以潜在地提高两组人对深度伪造文本的检测准确性。 |
| [^97] | [Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning.](http://arxiv.org/abs/2303.12091) | 本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。 |
| [^98] | [GeoMIM: Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding.](http://arxiv.org/abs/2303.11325) | 该论文提出了一种称为GeoMIM的方法，通过基于掩膜图像建模的方式来改进多视角基于相机的三维检测。该方法使用激光雷达模型的知识进行预训练和微调，并利用激光雷达BEV特征作为学习目标。实验结果表明，GeoMIM在多视角三维理解中取得了良好的效果。 |
| [^99] | [Challenges and Practices of Deep Learning Model Reengineering: A Case Study on Computer Vision.](http://arxiv.org/abs/2303.07476) | 本研究对深度学习模型重构进行了实例研究，并发现由于参考模型文档不全、需求变化以及实现和测试成本等原因，该过程具有挑战性，个别工程师可能缺乏软件工程方面的专业知识，但团队必须应用软件工程和深度学习的知识才能成功。 |
| [^100] | [Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning.](http://arxiv.org/abs/2303.00396) | 本文提出了一种通过受限代理学习方法，可以有效地控制深度序数分类中的类布局。 |
| [^101] | [Revolutionizing Genomics with Reinforcement Learning Techniques.](http://arxiv.org/abs/2302.13268) | 强化学习是一种革新的工具，可以在基因组学领域中解决自动数据分析和处理的问题。使用强化学习算法可以降低收集标记训练数据的成本，适用于基因组数据分析和解释。本调查重点关注在基因组研究领域中使用强化学习的应用，包括基因调控网络、基因组组装和序列比对。 |
| [^102] | [Causal Explanations for Stochastic Sequential Multi-Agent Decision-Making.](http://arxiv.org/abs/2302.10809) | CEMA是一个用于多智能体决策因果解释的系统，使用采样反事实世界的方法可以识别和排名决策背后的显著原因。该系统还可以生成基于所选原因的对比解释，并与用户进行交互循环以确保解释的相关性和可读性。 |
| [^103] | [Counterfactual Reasoning for Bias Evaluation and Detection in a Fairness under Unawareness setting.](http://arxiv.org/abs/2302.08204) | 本研究提出了一种方法来揭示即使在丢弃敏感特征的情况下机器学习模型可能仍存在的潜在偏见，并通过利用反事实推理来检测黑盒预测器的偏见。 |
| [^104] | [Scalable Multi-Agent Reinforcement Learning with General Utilities.](http://arxiv.org/abs/2302.07938) | 本论文研究了具有通用效用的可扩展多智能体强化学习，并提出了一种基于分布式策略梯度算法的解决方案，通过利用网络结构的空间相关衰减性质实现了算法的收敛性。 |
| [^105] | [Composing Task Knowledge with Modular Successor Feature Approximators.](http://arxiv.org/abs/2301.12305) | 本研究提出了一种新颖的神经网络架构，"模块化继任特征逼近器"（MSFA），通过让模块发现有用于预测的特征并学习自己的预测表示，实现了更好的泛化能力。 |
| [^106] | [Event knowledge in large language models: the gap between the impossible and the unlikely.](http://arxiv.org/abs/2212.01488) | 大型语言模型拥有丰富的事件知识，几乎总是将可能事件的描述比不可能事件的描述赋予更高的可能性。 |
| [^107] | [Federated Learning for 5G Base Station Traffic Forecasting.](http://arxiv.org/abs/2211.15220) | 本研究探讨了将联邦学习应用于原始基站LTE数据进行5G基站流量预测的效果。 |
| [^108] | [Examining Policy Entropy of Reinforcement Learning Agents for Personalization Tasks.](http://arxiv.org/abs/2211.11869) | 研究了个性化任务中强化学习智能体的策略熵，并发现策略优化智能体在训练过程中往往具有低熵策略，然而Q学习智能体对此影响较小，通常保持高熵策略。 |
| [^109] | [A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning.](http://arxiv.org/abs/2211.11760) | 本文提出了一个低延迟自适应编码脉冲框架用于深度强化学习，在编码器灵活性、延迟和能量效率方面具有优异性能和广泛应用范围。 |
| [^110] | [QuadConv: Quadrature-Based Convolutions with Applications to Non-Uniform PDE Data Compression.](http://arxiv.org/abs/2211.05151) | 本论文提出了一种新的卷积层QuadConv，通过定积分对连续卷积进行近似。该方法适用于非均匀的基于网格的数据，并且在压缩偏微分方程（PDE）模拟数据时表现出与标准离散卷积相当的性能，甚至能够在非均匀数据上保持相同的准确性。QuadConv还优于其他非结构化卷积方法如图卷积。 |
| [^111] | [DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition.](http://arxiv.org/abs/2211.01146) | DynamicISP是一个动态控制图像信号处理器，能够根据前一帧的识别结果自动调整每帧的参数，实现高精度的单类别和多类别物体检测任务，同时计算成本低。 |
| [^112] | [Learning Melanocytic Cell Masks from Adjacent Stained Tissue.](http://arxiv.org/abs/2211.00646) | 本文提出了一种从相邻染色组织学片中训练深度神经网络进行黑色素细胞分割的方法，实现了0.64的平均IOU，尽管存在不完美的标签。 |
| [^113] | [TuneUp: A Simple Improved Training Strategy for Graph Neural Networks.](http://arxiv.org/abs/2210.14843) | TuneUp是一种简单的基于课程的训练策略，用于改进图神经网络在难以预测的尾节点上的泛化性能。 |
| [^114] | [Sufficient Invariant Learning for Distribution Shift.](http://arxiv.org/abs/2210.13533) | 本文研究了分布转移情况下的充分不变学习，观察到之前的工作只学习了部分不变特征，我们提出了学习充分不变特征的重要性，并指出在分布转移时，从训练集中学习的部分不变特征可能不适用于测试集，限制了性能提升。 |
| [^115] | [Benign Autoencoders.](http://arxiv.org/abs/2210.00637) | 本文正式化了用于生成式人工智能中编码器-解码器对的最佳选择问题并提出了良性自编码器（BAE），BAE能够将数据投射到最优的流型上，实现了数据压缩和更加稳定的梯度下降。 |
| [^116] | [Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent.](http://arxiv.org/abs/2209.02552) | 本研究将解释人工智能（XAI）融入到一个对话代理中，设计具有自然语言理解和生成组件的标准模型。通过扩展XAI问题库并提供解释方法，实现了关于机器学习模型的真正自然对话。 |
| [^117] | [TE2Rules: Explaining Tree Ensembles using Rules.](http://arxiv.org/abs/2206.14359) | 本文介绍了一种将二元分类任务中的树集合模型转换为可解释规则列表的方法，该方法可以有效解释模型对于少数类别的预测。实验证明，TE2Rules方法生成的规则列表准确性较高，并且运行时间与其他基线方法相当。 |
| [^118] | [ReCo: A Dataset for Residential Community Layout Planning.](http://arxiv.org/abs/2206.04678) | ReCo是一个用于住宅社区布局规划的数据集，用于解决基于数据驱动的方法在该领域面临的数据不足问题。 |
| [^119] | [Res2NetFuse: A Fusion Method for Infrared and Visible Images.](http://arxiv.org/abs/2112.14540) | 本文提出了一种基于Res2Net的红外和可见光图像融合框架，通过引入新的训练策略和融合策略，实现了最先进的融合性能。 |
| [^120] | [CDistNet: Perceiving Multi-Domain Character Distance for Robust Text Recognition.](http://arxiv.org/abs/2111.11011) | 本文提出了一种名为多域字符距离感知（MDCDP）的新颖模块，用于解决场景文本识别中特征和字符对齐不准确的问题。该模块通过交叉注意机制融合视觉和语义特征，并生成一个内容感知嵌入来感知字符位置。 |
| [^121] | [The Confluence of Networks, Games and Learning.](http://arxiv.org/abs/2105.08158) | 这篇论文讨论了网络、游戏和学习的融合，为理解网络上多智能体决策制定提供了理论基础，并提供了选择性的博弈理论学习算法概述和在现代网络系统中的应用。 |
| [^122] | [Pedestrian Attribute Recognition: A Survey.](http://arxiv.org/abs/1901.07474) | 本文回顾了行人属性识别的现有作品，介绍了行人属性识别的背景、基准、多任务学习和多标签学习的概念，以及流行的网络架构和解决方案。 |
| [^123] | [Generalization in Deep Learning.](http://arxiv.org/abs/1710.05468) | 本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，提出了一些新的开放问题，并讨论了研究结果的局限性。 |

# 详细

[^1]: 重新审视多任务学习中的标量化：一个理论的视角

    Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective. (arXiv:2308.13985v1 [cs.LG])

    [http://arxiv.org/abs/2308.13985](http://arxiv.org/abs/2308.13985)

    本论文重新审视了多任务学习中的标量化方法，并从理论的角度探讨了标量化是否能够充分探索帕累托前沿。结果显示，与最近的研究声称的经验优势相反，标量化本质上无法进行全面探索，特别是对于那些平衡了paren

    

    线性标量化，即通过加权总和来组合所有损失函数，自从多任务学习（MTL）的创立以来一直是文献中的默认选择。近年来，越来越多的人对开发专门的多任务优化器（SMTOs）来处理MTL作为多目标优化问题产生了兴趣。然而，目前还不清楚SMTOs是否比标量化有根本上的优势。实际上，社区中存在对比这两种算法的激烈讨论，主要是从经验角度出发。为了回答上述问题，本文从理论的角度重新审视了标量化。我们专注于线性MTL模型，并研究标量化是否能够充分探索帕累托前沿。我们的研究发现，与那些声称标量化具有经验优势的最近工作相反，标量化本质上无法进行全面探索，特别是对于那些平衡了paren

    Linear scalarization, i.e., combining all loss functions by a weighted sum, has been the default choice in the literature of multi-task learning (MTL) since its inception. In recent years, there is a surge of interest in developing Specialized Multi-Task Optimizers (SMTOs) that treat MTL as a multi-objective optimization problem. However, it remains open whether there is a fundamental advantage of SMTOs over scalarization. In fact, heated debates exist in the community comparing these two types of algorithms, mostly from an empirical perspective. To approach the above question, in this paper, we revisit scalarization from a theoretical perspective. We focus on linear MTL models and study whether scalarization is capable of fully exploring the Pareto front. Our findings reveal that, in contrast to recent works that claimed empirical advantages of scalarization, scalarization is inherently incapable of full exploration, especially for those Pareto optimal solutions that strike the balanc
    
[^2]: 通过基于AI的分割增强血迹分析：利用Segment Anything Model进行现场调查

    Enhancing Bloodstain Analysis Through AI-Based Segmentation: Leveraging Segment Anything Model for Crime Scene Investigation. (arXiv:2308.13979v1 [cs.CV])

    [http://arxiv.org/abs/2308.13979](http://arxiv.org/abs/2308.13979)

    本文通过应用预训练的Segment Anything Model和微调的Segment Anything Model在各种图像背景下的血迹图像分割中，证明了其准确性和效率的满意度，微调的模型比预训练模型准确性提升了2.2％，在图像识别速度方面加快了4.70％。

    

    血迹模式分析通过研究独特的血迹模式为现场调查提供了有价值的信息。传统的图像分析方法对图像背景有严格要求，对于液滴图像分割来说工作量也很大。Segment Anything Model（SAM）是一种近期提出的广泛图像识别方法，尚未充分评估其在血迹图像分割上的准确性和效率。本文探讨了预训练的SAM和微调的SAM在具有不同图像背景的血迹图像分割中的应用。实验结果表明，预训练的SAM和微调的SAM都能够以令人满意的准确性和效率执行血迹图像分割任务，而微调的SAM相对于预训练的SAM在准确性上提升了2.2％，在图像识别速度方面加快了4.70％。

    Bloodstain pattern analysis plays a crucial role in crime scene investigations by providing valuable information through the study of unique blood patterns. Conventional image analysis methods, like Thresholding and Contrast, impose stringent requirements on the image background and is labor-intensive in the context of droplet image segmentation. The Segment Anything Model (SAM), a recently proposed method for extensive image recognition, is yet to be adequately assessed for its accuracy and efficiency on bloodstain image segmentation. This paper explores the application of pre-trained SAM and fine-tuned SAM on bloodstain image segmentation with diverse image backgrounds. Experiment results indicate that both pre-trained and fine-tuned SAM perform the bloodstain image segmentation task with satisfactory accuracy and efficiency, while fine-tuned SAM achieves an overall 2.2\% accuracy improvement than pre-trained SAM and 4.70\% acceleration in terms of speed for image recognition. Analys
    
[^3]: 理解基于QUBO的哈密顿函数在图上的组合优化中的使用：以最大切割问题为例讨论

    Understanding the Usage of QUBO-based Hamiltonian Function in Combinatorial Optimization over Graphs: A Discussion Using Max Cut (MC) Problem. (arXiv:2308.13978v1 [cs.AI])

    [http://arxiv.org/abs/2308.13978](http://arxiv.org/abs/2308.13978)

    研究探讨了在图上基于QUBO公式的最大切割问题中，如何使用基于强化学习范式和哈密顿函数来解决组合优化问题。通过使用图神经网络作为信息传递架构，并通过三种不同的公式形式进行实验，发现...

    

    二次无约束二进制优化（QUBO）是一种广义技术，用于将各种NP困难组合优化问题建模为二进制变量的形式。哈密顿函数经常用于形成QUBO问题，其中它在优化的上下文中被用作目标函数。在本研究中，我们研究了如何使用基于强化学习（RL）范式和哈密顿函数解决QUBO公式中的图上组合优化问题。我们使用图神经网络（GNN）作为信息传递架构在节点之间传递信息。我们主要研究了三种公式，Monty-Carlo Tree Search with GNN-based RL（MCTS-GNN）、DQN with GNN-based RL和带有注意力的通用GNN（GRL）。我们的研究结果表明，...

    Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to model various NP-hard combinatorial optimization problems in the form of binary variables. The Hamiltonian function is often used to formulate QUBO problems where it is used as the objective function in the context of optimization. In this study, we investigate how reinforcement learning-based (RL) paradigms with the presence of the Hamiltonian function can address combinatorial optimization problems over graphs in QUBO formulations. We use Graph Neural Network (GNN) as the message-passing architecture to convey the information among the nodes. We have centered our discussion on QUBO formulated Max-Cut problem but the intuitions can be extended to any QUBO supported canonical NP-Hard combinatorial optimization problems. We mainly investigate three formulations, Monty-Carlo Tree Search with GNN-based RL (MCTS-GNN), DQN with GNN-based RL, and a generic GNN with attention-based RL (GRL). Our findings state that i
    
[^4]: 通过跨模型一致性进行标签去噪

    Label Denoising through Cross-Model Agreement. (arXiv:2308.13976v1 [cs.LG])

    [http://arxiv.org/abs/2308.13976](http://arxiv.org/abs/2308.13976)

    本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。

    

    在现实世界的机器学习应用中，从有噪声的标签学习是非常常见的。记忆这些有噪声的标签可能会影响模型的学习，从而导致次优的性能。在这项工作中，我们提出了一种新颖的框架，用于从有噪声标签中学习鲁棒的机器学习模型。通过实证研究，我们发现不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。受到这一观察的启发，我们提出了使用跨模型一致性进行去噪（DeCA）的方法，该方法旨在最小化由两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。我们将提出的DeCA方法应用于二进制标签情景和多标签情景。对于二进制标签情景，我们选择隐式反馈推荐作为下游任务，并进行了四种最先进方法的实验。

    Learning from corrupted labels is very common in real-world machine-learning applications. Memorizing such noisy labels could affect the learning of the model, leading to sub-optimal performances. In this work, we propose a novel framework to learn robust machine-learning models from noisy labels. Through an empirical study, we find that different models make relatively similar predictions on clean examples, while the predictions on noisy examples vary much more across different models. Motivated by this observation, we propose \em denoising with cross-model agreement \em (DeCA) which aims to minimize the KL-divergence between the true label distributions parameterized by two machine learning models while maximizing the likelihood of data observation. We employ the proposed DeCA on both the binary label scenario and the multiple label scenario. For the binary label scenario, we select implicit feedback recommendation as the downstream task and conduct experiments with four state-of-the
    
[^5]: FAM：快速自适应元学习

    FAM: fast adaptive meta-learning. (arXiv:2308.13970v1 [cs.LG])

    [http://arxiv.org/abs/2308.13970](http://arxiv.org/abs/2308.13970)

    本论文提出了一个快速自适应联邦元学习（FAM）框架，可以协作学习一个全局模型，并在个别客户端上进行个性化。这解决了数据分布发散和隐私限制的问题，并且适用于需要在不同客户端之间进行个性化的领域转变。

    

    在这项工作中，我们提出了一个快速自适应联邦元学习（FAM）框架，用于协作学习一个单一全局模型，然后可以在个别客户端上个性化。联邦学习使多个客户端能够协作训练模型而不共享数据。参与联邦学习的客户端由于数据不足或数据多样性导致学习受到影响。然而，当数据分布发散时，学习会受到困扰。有必要学习一个可以使用客户端特定信息进行自适应的全局模型，并在客户端上创建个性化模型。MRI数据存在这个问题，第一，由于数据采集挑战，在某个地点的本地数据足以训练准确的模型，第二，由于隐私问题有数据共享限制，第三，由于客户端站点之间的领域转变，需要对学习的共享全局模型进行个性化。

    In this work, we propose a fast adaptive federated meta-learning (FAM) framework for collaboratively learning a single global model, which can then be personalized locally on individual clients. Federated learning enables multiple clients to collaborate to train a model without sharing data. Clients with insufficient data or data diversity participate in federated learning to learn a model with superior performance. Nonetheless, learning suffers when data distributions diverge. There is a need to learn a global model that can be adapted using client's specific information to create personalised models on clients is required. MRI data suffers from this problem, wherein, one, due to data acquisition challenges, local data at a site is sufficient for training an accurate model and two, there is a restriction of data sharing due to privacy concerns and three, there is a need for personalization of a learnt shared global model on account of domain shift across client sites. The global model
    
[^6]: 注重注意力：将人眼追踪集成到视觉Transformer模型中

    Fixating on Attention: Integrating Human Eye Tracking into Vision Transformers. (arXiv:2308.13969v1 [cs.CV])

    [http://arxiv.org/abs/2308.13969](http://arxiv.org/abs/2308.13969)

    本研究展示了如何将人眼追踪集成到视觉Transformer模型中，提高在多种驾驶情况和数据集上的准确性。

    

    现代基于Transformer的计算机视觉模型在多种视觉任务上表现出超越人类的能力。然而，一些关键任务，如医学图像解释和自动驾驶，仍然需要依赖人类判断。本研究展示了如何将人类视觉输入，特别是通过眼动仪收集到的注视点，集成到Transformer模型中，以提高在多种驾驶情况和数据集上的准确性。首先，我们在人类实验对象和Vision Transformer模型中观察到，注视区域在左右驾驶决策中的重要性。通过比较人类注视图和ViT注意力权重之间的相似性，我们揭示了单个头部和层之间的重叠动态。通过利用这种重叠动态，我们实现了对模型的修剪而不损失准确性。然后，我们将驾驶场景信息与注视数据相结合，采用“联合空间-注视”（JSF）的注意力设置。最后

    Modern transformer-based models designed for computer vision have outperformed humans across a spectrum of visual tasks. However, critical tasks, such as medical image interpretation or autonomous driving, still require reliance on human judgments. This work demonstrates how human visual input, specifically fixations collected from an eye-tracking device, can be integrated into transformer models to improve accuracy across multiple driving situations and datasets. First, we establish the significance of fixation regions in left-right driving decisions, as observed in both human subjects and a Vision Transformer (ViT). By comparing the similarity between human fixation maps and ViT attention weights, we reveal the dynamics of overlap across individual heads and layers. This overlap is exploited for model pruning without compromising accuracy. Thereafter, we incorporate information from the driving scene with fixation data, employing a "joint space-fixation" (JSF) attention setup. Lastly
    
[^7]: 改进BERT模型的知识蒸馏：损失函数、映射方法和权重调整

    Improving Knowledge Distillation for BERT Models: Loss Functions, Mapping Methods, and Weight Tuning. (arXiv:2308.13958v1 [cs.CL])

    [http://arxiv.org/abs/2308.13958](http://arxiv.org/abs/2308.13958)

    本研究旨在改进BERT模型的知识蒸馏方法，通过实验不同的损失函数、映射方法和权重调整，提高知识蒸馏的效率和精度，从而压缩大型Transformer模型，使其在保持准确性的同时更加高效。

    

    大型基于Transformer的模型，如BERT、GPT和T5在自然语言处理方面取得了重大进展。然而，这些模型计算成本高昂，需要采用模型压缩技术来减小其大小和复杂性，同时保持准确性。本项目研究并应用知识蒸馏用于BERT模型压缩，特别关注TinyBERT学生模型。我们探索了多种技术来改进知识蒸馏，包括实验不同的损失函数、Transformer层映射方法和调整注意力和表示损失的权重，并在GLUE基准测试中评估了我们提出的技术在多个下游任务上的性能。本工作的目标是改进知识蒸馏的效率和效果，从而为各种自然语言处理任务的开发提供更高效和准确的模型。

    The use of large transformer-based models such as BERT, GPT, and T5 has led to significant advancements in natural language processing. However, these models are computationally expensive, necessitating model compression techniques that reduce their size and complexity while maintaining accuracy. This project investigates and applies knowledge distillation for BERT model compression, specifically focusing on the TinyBERT student model. We explore various techniques to improve knowledge distillation, including experimentation with loss functions, transformer layer mapping methods, and tuning the weights of attention and representation loss and evaluate our proposed techniques on a selection of downstream tasks from the GLUE benchmark. The goal of this work is to improve the efficiency and effectiveness of knowledge distillation, enabling the development of more efficient and accurate models for a range of natural language processing tasks.
    
[^8]: 可微分权重掩码用于领域迁移

    Differentiable Weight Masks for Domain Transfer. (arXiv:2308.13957v1 [cs.CV])

    [http://arxiv.org/abs/2308.13957](http://arxiv.org/abs/2308.13957)

    本论文通过将模块化权重和领域迁移相结合，研究了三种权重掩码方法，并分析它们在保持源任务知识的同时允许高效微调目标任务的能力。

    

    深度学习模型在计算机视觉领域的一个主要缺点是它们无法以模块化的方式保留多个信息源。例如，给定一个在源任务上训练过的网络，我们希望在保持其在源任务上的性能的同时，将其重新训练到一个相似但不同的目标任务上。同时，研究人员已经广泛研究了网络权重的模块化，以定位和确定对于触发给定任务的性能的权重集合。一些工作研究了通过学习和分析权重掩码引入的网络权重的模块化。在这项工作中，我们将这些领域结合起来，研究了三种权重掩码方法，并分析它们在缓解源任务的“遗忘”同时允许在目标任务上进行高效微调的能力。我们发现不同的掩码技术在保留源任务知识方面存在权衡。

    One of the major drawbacks of deep learning models for computer vision has been their inability to retain multiple sources of information in a modular fashion. For instance, given a network that has been trained on a source task, we would like to re-train this network on a similar, yet different, target task while maintaining its performance on the source task. Simultaneously, researchers have extensively studied modularization of network weights to localize and identify the set of weights culpable for eliciting the observed performance on a given task. One set of works studies the modularization induced in the weights of a neural network by learning and analysing weight masks. In this work, we combine these fields to study three such weight masking methods and analyse their ability to mitigate "forgetting'' on the source task while also allowing for efficient finetuning on the target task. We find that different masking techniques have trade-offs in retaining knowledge in the source t
    
[^9]: 探索大型语言模型用于知识图谱补全

    Exploring Large Language Models for Knowledge Graph Completion. (arXiv:2308.13916v1 [cs.CL])

    [http://arxiv.org/abs/2308.13916](http://arxiv.org/abs/2308.13916)

    本文研究了利用大型语言模型（LLM）进行知识图谱补全的方法，并引入了一种创新的框架（知识图谱LLM），以提高三元组分类和关系预测的性能。

    

    知识图谱在众多人工智能任务中发挥着重要作用，但经常面临不完整性的问题。在本研究中，我们探索了利用大型语言模型（LLM）进行知识图谱补全的方法。我们将知识图谱中的三元组视为文本序列，并引入了一种创新的框架，称为知识图谱LLM（KG-LLM），来对这些三元组进行建模。我们的技术利用三元组的实体和关系描述作为提示，并利用响应进行预测。对各种基准知识图谱的实验表明，我们的方法在三元组分类和关系预测等任务中达到了最先进的性能。我们还发现，微调相对较小的模型（例如LLaMA-7B，ChatGLM-6B）优于最新的ChatGPT和GPT-4。

    Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4.
    
[^10]: ChatGPT在情感计算任务上的广泛评估

    A Wide Evaluation of ChatGPT on Affective Computing Tasks. (arXiv:2308.13911v1 [cs.AI])

    [http://arxiv.org/abs/2308.13911](http://arxiv.org/abs/2308.13911)

    本论文广泛研究了ChatGPT模型在13个情感计算问题上的能力，并提出了一种能够评估ChatGPT模型在回归问题上的框架。

    

    随着基础模型的崛起，一个新的人工智能范式出现了，即通过使用通用目的的基础模型，通过提示来解决问题，而不是为每个问题训练单独的机器学习模型。这些模型已经显示出解决一些最初未经训练的问题的新性质。对于这类模型的有效性的研究还相当有限。在这项工作中，我们广泛研究了ChatGPT模型（即GPT-4和GPT-3.5）在13个情感计算问题上的能力，包括方面提取、方面极性分类、意见提取、情感分析、情感强度排序、情绪强度排序、自杀倾向检测、毒性检测、福祉评估、参与度测量、人格评估、讽刺检测和主观性检测。我们介绍了一个评估ChatGPT模型在回归问题上的框架，比如强度排序。

    With the rise of foundation models, a new artificial intelligence paradigm has emerged, by simply using general purpose foundation models with prompting to solve problems instead of training a separate machine learning model for each problem. Such models have been shown to have emergent properties of solving problems that they were not initially trained on. The studies for the effectiveness of such models are still quite limited. In this work, we widely study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13 affective computing problems, namely aspect extraction, aspect polarity classification, opinion extraction, sentiment analysis, sentiment intensity ranking, emotions intensity ranking, suicide tendency detection, toxicity detection, well-being assessment, engagement measurement, personality assessment, sarcasm detection, and subjectivity detection. We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking p
    
[^11]: 使用计算机视觉和机器学习，探索视频中人类群体模式和分类，以增强安全和监视

    Exploring Human Crowd Patterns and Categorization in Video Footage for Enhanced Security and Surveillance using Computer Vision and Machine Learning. (arXiv:2308.13910v1 [cs.CV])

    [http://arxiv.org/abs/2308.13910](http://arxiv.org/abs/2308.13910)

    本文通过使用计算机视觉和机器学习，探索了在视频中追踪人类群体模式和分类的方法，进而增强安全和监视。通过将运动分为不同的弧形、车道、汇聚/分散和随机/阻塞运动，并使用光流技术、CNN模型和机器学习模型，成功地实现了目标，并获得了具有前景的准确性。这些结果可以用于训练异常检测模型、基于运动提供行为洞察，并增强场景理解能力。

    

    计算机视觉和机器学习为研究人员、科学家和普通民众带来了革命性的感知变革。这些技术曾被认为是不可企及的，但如今却取得了看似不可能的成就。它们在安全、农业和教育等各个领域的卓越应用证明了它们的影响力。然而，计算机视觉的全部潜力尚未被充分发掘。本文探讨了计算机视觉在安全和监视中的潜力，提出了一种新颖的视频运动追踪方法。通过使用运动信息图像和分块主导运动数据将运动分为弧形、车道、汇聚/分散和随机/阻塞运动，本文考察了不同的光流技术、CNN模型和机器学习模型。通过以很高精度达成目标，本文的结果可以训练异常检测模型，根据运动提供行为洞察，并增强场景理解能力。

    Computer vision and machine learning have brought revolutionary shifts in perception for researchers, scientists, and the general populace. Once thought to be unattainable, these technologies have achieved the seemingly impossible. Their exceptional applications in diverse fields like security, agriculture, and education are a testament to their impact. However, the full potential of computer vision remains untapped. This paper explores computer vision's potential in security and surveillance, presenting a novel approach to track motion in videos. By categorizing motion into Arcs, Lanes, Converging/Diverging, and Random/Block motions using Motion Information Images and Blockwise dominant motion data, the paper examines different optical flow techniques, CNN models, and machine learning models. Successfully achieving its objectives with promising accuracy, the results can train anomaly-detection models, provide behavioral insights based on motion, and enhance scene comprehension.
    
[^12]: 在移动设备上进行十亿规模语言模型的联邦微调

    Federated Fine-tuning of Billion-Sized Language Models across Mobile Devices. (arXiv:2308.13894v1 [cs.AI])

    [http://arxiv.org/abs/2308.13894](http://arxiv.org/abs/2308.13894)

    这项工作引入了一种创新的FL协议FwdLLM，旨在提高在移动设备上进行十亿规模语言模型的联邦微调（FedLLM）的效率。FwdLLM通过使用无反向传播（BP）训练方法以及“扰动推断”来提高内存效率和时间效率。

    

    大规模语言模型（LLM）正在改变移动智能的格局。联邦学习（FL）是一种保护用户数据隐私的方法，通常用于对下游移动任务进行LLM的微调，这被称为FedLLM。尽管最近的研究已经解决了由庞大模型大小引起的网络问题，但它们在与移动设备的整合方面并没有实际缓解诸多挑战，比如显著的内存消耗和缓慢的模型收敛。为了应对这些挑战，本研究引入了一种创新的FL协议FwdLLM，旨在提高FedLLM的效率。FwdLLM的关键思想是采用无反向传播（BP）训练方法，只需要设备执行“扰动推断”。因此，FwdLLM具有更好的内存效率和时间效率（通过移动NPUs和扩大的参与设备数组）。FwdLLM围绕三个关键设计展开：（1）将无反向传播训练与p

    Large Language Models (LLMs) are transforming the landscape of mobile intelligence. Federated Learning (FL), a method to preserve user data privacy, is often employed in fine-tuning LLMs to downstream mobile tasks, an approach known as FedLLM. Though recent efforts have addressed the network issue induced by the vast model size, they have not practically mitigated vital challenges concerning integration with mobile devices, such as significant memory consumption and sluggish model convergence.  In response to these challenges, this work introduces FwdLLM, an innovative FL protocol designed to enhance the FedLLM efficiency. The key idea of FwdLLM to employ backpropagation (BP)-free training methods, requiring devices only to execute ``perturbed inferences''. Consequently, FwdLLM delivers way better memory efficiency and time efficiency (expedited by mobile NPUs and an expanded array of participant devices). FwdLLM centers around three key designs: (1) it combines BP-free training with p
    
[^13]: 《GENEA Challenge 2023》中的DiffuseStyleGesture+入门

    The DiffuseStyleGesture+ entry to the GENEA Challenge 2023. (arXiv:2308.13879v1 [cs.HC])

    [http://arxiv.org/abs/2308.13879](http://arxiv.org/abs/2308.13879)

    DiffuseStyleGesture+是对GENEA挑战的解决方案，利用多模态数据和扩散模型，能够自动生成高质量、逼真的会话手势，并在人类类似性和适应性方面表现出与顶级模型相媲美的性能。

    

    在本文中，我们介绍了DiffuseStyleGesture+，这是我们对于《GENEA Challenge 2023》的解决方案，该挑战旨在促进生成会话手势的现实、自动化系统的开发。参与者将获得一个经过预处理的数据集，并通过众包评分来评估其系统。我们提出的模型DiffuseStyleGesture+利用扩散模型自动生成手势。它结合了多种模态，包括音频、文本、说话者身份和种子手势。这些多样的模态被映射到一个隐藏空间，并通过修改后的扩散模型进行处理，以针对给定的语音输入生成相应的手势。在评估中，DiffuseStyleGesture+展示了与挑战中顶级模型相媲美的性能，表现出与这些模型在人类类似性、适应对话者的合适性和实现达到无显著差异。

    In this paper, we introduce the DiffuseStyleGesture+, our solution for the Generation and Evaluation of Non-verbal Behavior for Embodied Agents (GENEA) Challenge 2023, which aims to foster the development of realistic, automated systems for generating conversational gestures. Participants are provided with a pre-processed dataset and their systems are evaluated through crowdsourced scoring. Our proposed model, DiffuseStyleGesture+, leverages a diffusion model to generate gestures automatically. It incorporates a variety of modalities, including audio, text, speaker ID, and seed gestures. These diverse modalities are mapped to a hidden space and processed by a modified diffusion model to produce the corresponding gesture for a given speech input. Upon evaluation, the DiffuseStyleGesture+ demonstrated performance on par with the top-tier models in the challenge, showing no significant differences with those models in human-likeness, appropriateness for the interlocutor, and achieving com
    
[^14]: 通过不同的关注方式学习图编辑距离

    Graph Edit Distance Learning via Different Attention. (arXiv:2308.13871v1 [cs.AI])

    [http://arxiv.org/abs/2308.13871](http://arxiv.org/abs/2308.13871)

    该论文提出了一种通过不同的关注方式学习图编辑距离的方法，该方法通过图级特征融合模块显著提高了计算的准确性，相对于节点级融合，具有更好的性能和效率。

    

    最近，越来越多的研究集中在使用图神经网络（GNN）来解决图相似性计算问题（GSC），即计算两个图之间的图编辑距离（GED）。这些方法把GSC视为一个可学习的端到端任务，其核心是特征融合模块，用于与两个图的特征交互。现有方法认为，图级嵌入很难捕捉两个图之间局部小结构的差异，因此对节点级嵌入进行细粒度特征融合可以提高准确性，但在训练和推理阶段会导致更大的时间和内存消耗。然而，本文提出了一种新颖的图级特征融合模块Different Attention（DiffAtt），并证明了图级融合嵌入可以显著优于这些复杂的节点级融合嵌入。

    Recently, more and more research has focused on using Graph Neural Networks (GNN) to solve the Graph Similarity Computation problem (GSC), i.e., computing the Graph Edit Distance (GED) between two graphs. These methods treat GSC as an end-to-end learnable task, and the core of their architecture is the feature fusion modules to interact with the features of two graphs. Existing methods consider that graph-level embedding is difficult to capture the differences in local small structures between two graphs, and thus perform fine-grained feature fusion on node-level embedding can improve the accuracy, but leads to greater time and memory consumption in the training and inference phases. However, this paper proposes a novel graph-level fusion module Different Attention (DiffAtt), and demonstrates that graph-level fusion embeddings can substantially outperform these complex node-level fusion embeddings. We posit that the relative difference structure of the two graphs plays an important rol
    
[^15]: 有效的异构联邦学习：基于配对和分裂学习的方法

    Effectively Heterogeneous Federated Learning: A Pairing and Split Learning Based Approach. (arXiv:2308.13849v1 [cs.LG])

    [http://arxiv.org/abs/2308.13849](http://arxiv.org/abs/2308.13849)

    该论文提出了一种有效的异构联邦学习方法，通过配对和分裂学习，解决了异构性带来的训练速度问题，提高了联邦学习的效率。

    

    作为一种有前景的隐私保护机器学习范式，联邦学习在分布式设备协作训练模型时避免了客户端之间的数据传输。然而，由于客户端的异构性，联邦学习存在训练速度的瓶颈问题，导致训练延迟和服务器聚合的延迟。为了解决这个挑战，提出了一种新颖的分裂联邦学习（SFL）框架，它基于计算资源和客户端之间的通信速率将客户端进行配对，并在逻辑层将神经网络模型分成两部分，每个客户端只计算其分配的部分，通过使用分裂学习实现前向推理和后向训练。此外，为了有效解决客户端配对问题，提出了一种启发式贪婪算法，通过重构训练延迟优化来解决该问题。

    As a promising paradigm federated Learning (FL) is widely used in privacy-preserving machine learning, which allows distributed devices to collaboratively train a model while avoiding data transmission among clients. Despite its immense potential, the FL suffers from bottlenecks in training speed due to client heterogeneity, leading to escalated training latency and straggling server aggregation. To deal with this challenge, a novel split federated learning (SFL) framework that pairs clients with different computational resources is proposed, where clients are paired based on computing resources and communication rates among clients, meanwhile the neural network model is split into two parts at the logical level, and each client only computes the part assigned to it by using the SL to achieve forward inference and backward training. Moreover, to effectively deal with the client pairing problem, a heuristic greedy algorithm is proposed by reconstructing the optimization of training late
    
[^16]: 深度学习用于保持结构的非线性标准哈密顿动力学的通用稳定库普曼嵌入

    Deep Learning for Structure-Preserving Universal Stable Koopman-Inspired Embeddings for Nonlinear Canonical Hamiltonian Dynamics. (arXiv:2308.13835v1 [cs.LG])

    [http://arxiv.org/abs/2308.13835](http://arxiv.org/abs/2308.13835)

    该论文利用深度学习为非线性哈密顿系统发现了保持结构的全局线性化嵌入，通过辛变换获得紧凑辛嵌入，并重点关注其动力学的有界稳定性。

    

    发现非线性系统的适当坐标变换可以构建更简单的模型，从而便于复杂非线性系统的预测、控制和优化。为此，库普曼算子理论提供了一种用于非线性系统的全局线性化的框架，从而允许使用线性工具进行设计研究。在这项工作中，我们关注通过辛变换识别标准非线性哈密顿系统的全局线性化嵌入。尽管这个任务通常很具挑战性，我们利用深度学习的能力来发现所需的嵌入。此外，为了克服库普曼算子在具有连续频谱的系统中的缺点，我们应用了抬升原理并学习全局的立方嵌入。此外，我们着重强调了所发现嵌入的动力学的有界稳定性的强制性要求。我们展示了深度学习在获取紧凑辛嵌入中的能力。

    Discovering a suitable coordinate transformation for nonlinear systems enables the construction of simpler models, facilitating prediction, control, and optimization for complex nonlinear systems. To that end, Koopman operator theory offers a framework for global linearization for nonlinear systems, thereby allowing the usage of linear tools for design studies. In this work, we focus on the identification of global linearized embeddings for canonical nonlinear Hamiltonian systems through a symplectic transformation. While this task is often challenging, we leverage the power of deep learning to discover the desired embeddings. Furthermore, to overcome the shortcomings of Koopman operators for systems with continuous spectra, we apply the lifting principle and learn global cubicized embeddings. Additionally, a key emphasis is paid to enforce the bounded stability for the dynamics of the discovered embeddings. We demonstrate the capabilities of deep learning in acquiring compact symplect
    
[^17]: 图上不平衡学习的综述：问题、技术和未来方向

    A Survey of Imbalanced Learning on Graphs: Problems, Techniques, and Future Directions. (arXiv:2308.13821v1 [cs.LG])

    [http://arxiv.org/abs/2308.13821](http://arxiv.org/abs/2308.13821)

    本综述对图上不平衡学习进行了全面的审视，旨在纠正数据分布偏差，以获得更准确和代表性的学习结果。

    

    图表示与世界各种场景中普遍存在的相互连接的结构。有效的图分析技术，如图学习方法，使用户能够从图数据中获得深刻的洞察力，为节点分类和链路预测等各种任务提供支持。然而，这些方法常常面临数据不平衡的问题，即在图数据中某些片段拥有大量数据而其他数据稀缺，从而导致偏倚的学习结果。这就需要出现了图上不平衡学习的新兴领域，旨在纠正这些数据分布偏差，以获得更准确和代表性的学习结果。在本综述中，我们对图上不平衡学习的文献进行了全面的审视。我们首先提供了对该概念和相关术语的明确理解，为读者建立了扎实的基础知识。随后，我们提出了两个全面的分类法：（1）问题分类法（Problem Taxonomy）。

    Graphs represent interconnected structures prevalent in a myriad of real-world scenarios. Effective graph analytics, such as graph learning methods, enables users to gain profound insights from graph data, underpinning various tasks including node classification and link prediction. However, these methods often suffer from data imbalance, a common issue in graph data where certain segments possess abundant data while others are scarce, thereby leading to biased learning outcomes. This necessitates the emerging field of imbalanced learning on graphs, which aims to correct these data distribution skews for more accurate and representative learning outcomes. In this survey, we embark on a comprehensive review of the literature on imbalanced learning on graphs. We begin by providing a definitive understanding of the concept and related terminologies, establishing a strong foundational understanding for readers. Following this, we propose two comprehensive taxonomies: (1) the problem taxono
    
[^18]: 基于强化学习优化的双环谐振器的全光储备的分组头识别

    Packet Header Recognition Utilizing an All-Optical Reservoir Based on Reinforcement-Learning-Optimized Double-Ring Resonator. (arXiv:2308.13818v1 [eess.SP])

    [http://arxiv.org/abs/2308.13818](http://arxiv.org/abs/2308.13818)

    本文提出了一种基于双环谐振器的全光储备系统，通过使用深度强化学习算法，最大化延迟-带宽积参数，实现了快速、准确的光分组头识别。优化后的级联环可用于实现小尺寸、平顶延迟谱的光计算。

    

    光分组头识别是光通信网络中重要的信号处理任务。本文提出了一个全光储备系统，其中集成了双环谐振器作为节点，用于快速准确地识别光分组头。由于节点的延迟-带宽积（DBP）是储备系统中的重要参数，我们采用深度强化学习算法，对不同类型的双环谐振器进行DBP的最大化，该算法具有全参数空间优化和快速收敛速度的优势。有趣的是，级联、并联和嵌入式配置的优化DBP达到了相同的最大值，被认为是全局最大值。最后，使用优化的级联环组成的全光储备系统进行了3位和6位分组头识别任务，该系统具有大大减小的芯片尺寸和所需的“平顶”延迟谱。利用这种光计算方案，字错误率

    Optical packet header recognition is an important signal processing task of optical communication networks. In this work, we propose an all-optical reservoir, consisting of integrated double-ring resonators (DRRs) as nodes, for fast and accurate optical packet header recognition. As the delay-bandwidth product (DBP) of the node is a key figure-of-merit in the reservoir, we adopt a deep reinforcement learning algorithm to maximize the DBPs for various types of DRRs, which has the advantage of full parameter space optimization and fast convergence speed. Intriguingly, the optimized DBPs of the DRRs in cascaded, parallel, and embedded configurations reach the same maximum value, which is believed to be the global maximum. Finally, 3-bit and 6-bit packet header recognition tasks are performed with the all-optical reservoir consisting of the optimized cascaded rings, which have greatly reduced chip size and the desired "flat-top" delay spectra. Using this optical computing scheme, word-erro
    
[^19]: 通过大型语言模型增强面向动态感知的文本到视频扩散

    Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models. (arXiv:2308.13812v1 [cs.AI])

    [http://arxiv.org/abs/2308.13812](http://arxiv.org/abs/2308.13812)

    本文提出了一种新的方法（称为Dysen）来增强面向动态感知的文本到视频扩散，通过提取关键动作、建立动态场景图和丰富细节，以实现高质量的T2V生成。

    

    文本到视频（T2V）合成在社区中引起了越来越多的关注，其中最近出现的扩散模型（DMs）比过去的方法表现更强大。尽管现有的最先进的DMs能够实现高分辨率的视频生成，但它们在复杂的时间动态建模方面存在一些主要限制（例如，动作出现障碍，粗糙的视频运动）。在这项工作中，我们研究了如何加强DMs对视频动态的感知，以实现高质量的T2V生成。受到人类直觉的启发，我们设计了一种创新的动态场景管理器（称为Dysen）模块，其中包括（步骤1）从输入文本中提取具有适当时间顺序安排的关键动作，（步骤2）将动作时间表转化为动态场景图（DSG）表示，以及（步骤3）丰富DSG中的场景并提供充分和合理的细节。

    Text-to-video (T2V) synthesis has gained increasing attention in the community, in which the recently emerged diffusion models (DMs) have promisingly shown stronger performance than the past approaches. While existing state-of-the-art DMs are competent to achieve high-resolution video generation, they may largely suffer from key limitations (e.g., action occurrence disorders, crude video motions) with respect to the intricate temporal dynamics modeling, one of the crux of video synthesis. In this work, we investigate strengthening the awareness of video dynamics for DMs, for high-quality T2V generation. Inspired by human intuition, we design an innovative dynamic scene manager (dubbed as Dysen) module, which includes (step-1) extracting from input text the key actions with proper time-order arrangement, (step-2) transforming the action schedules into the dynamic scene graph (DSG) representations, and (step-3) enriching the scenes in the DSG with sufficient and reasonable details. Takin
    
[^20]: 基于强化学习的多模态特征融合网络用于新类别发现

    Reinforcement Learning Based Multi-modal Feature Fusion Network for Novel Class Discovery. (arXiv:2308.13801v1 [cs.AI])

    [http://arxiv.org/abs/2308.13801](http://arxiv.org/abs/2308.13801)

    本文提出了一种基于强化学习的多模态特征融合网络，用于解决开放集领域中的新类别发现问题。通过模拟人类的认知过程，采用成员-领导者多智能体框架从多模态信息中提取和融合特征，进一步融入自监督学习以增强模型训练，并通过聚类方法来实现对潜在新类别的识别。

    

    随着深度学习技术的发展，监督学习已经取得了超越人类的性能。研究人员为不同的数据模态设计了许多相应的模型，在监督任务中取得了优秀的结果。然而，随着各个领域数据的指数增长，对未标记数据的识别和分类逐渐成为研究热点。在本文中，我们采用了一种基于强化学习的框架，模拟人类的认知过程，有效地解决开放集领域中的新类别发现问题。我们采用了一种成员-领导者多智能体框架，从多模态信息中提取和融合特征，旨在获得对特征空间更全面的理解。此外，这种方法促进了自监督学习的融入，以增强模型训练。我们采用了一种聚类方法，具有不同的约束条件，从严格到松散，从而实现了更好的探索和识别潜在的新类别。

    With the development of deep learning techniques, supervised learning has achieved performances surpassing those of humans. Researchers have designed numerous corresponding models for different data modalities, achieving excellent results in supervised tasks. However, with the exponential increase of data in multiple fields, the recognition and classification of unlabeled data have gradually become a hot topic. In this paper, we employed a Reinforcement Learning framework to simulate the cognitive processes of humans for effectively addressing novel class discovery in the Open-set domain. We deployed a Member-to-Leader Multi-Agent framework to extract and fuse features from multi-modal information, aiming to acquire a more comprehensive understanding of the feature space. Furthermore, this approach facilitated the incorporation of self-supervised learning to enhance model training. We employed a clustering method with varying constraint conditions, ranging from strict to loose, allowin
    
[^21]: 使用基于逻辑图的语言模型进行指令生成的规划

    Planning with Logical Graph-based Language Model for Instruction Generation. (arXiv:2308.13782v1 [cs.CL])

    [http://arxiv.org/abs/2308.13782](http://arxiv.org/abs/2308.13782)

    本文提出了一种基于逻辑图的语言模型，Logical-GLM，用于指导语言模型生成具有正确逻辑的文本，并以提高文本生成的有效性和可解释性。实验结果表明，Logical-GLM在使用较少数据和参数的情况下仍然有效和高效。

    

    尽管大型语言模型在生成自然语言文本方面表现出优越性能，但由于神经模型难以从自由形式的文本中捕捉到隐含的规则，因此很难生成具有正确逻辑的文本。在本文中，我们提出了一种新颖的基于图的语言模型，Logical-GLM，将逻辑注入语言模型以进行更有效的文本生成和可解释性。具体而言，我们首先从自然语言指令中提取信息并构建通常描述领域的逻辑贝叶斯图。接下来，我们生成逻辑骨架以指导语言模型训练，将领域知识注入语言模型。最后，我们交替优化图的搜索策略和语言模型，直至收敛。实验结果表明，Logical-GLM与传统语言模型相比，尽管使用规模较小的训练数据和较少的参数，仍然具有有效和高效的性能。我们的方法可以生成有效的指令。

    Despite the superior performance of large language models to generate natural language texts, it is hard to generate texts with correct logic according to a given task, due to the difficulties for neural models to capture implied rules from free-form texts. In this paper, we propose a novel graph-based language model, Logical-GLM, to infuse logic into language models for more valid text generation and interpretability. Specifically, we first capture information from natural language instructions and construct logical bayes graphs that generally describe domains. Next, we generate logical skeletons to guide language model training, infusing domain knowledge into language models. Finally, we alternately optimize the searching policy of graphs and language models until convergence. The experimental results show that Logical-GLM is both effective and efficient compared with traditional language models, despite using smaller-scale training data and fewer parameters. Our approach can generat
    
[^22]: 高效RGB-T跟踪的统一单级Transformer网络

    Unified Single-Stage Transformer Network for Efficient RGB-T Tracking. (arXiv:2308.13764v1 [cs.CV])

    [http://arxiv.org/abs/2308.13764](http://arxiv.org/abs/2308.13764)

    提出了一种统一单级Transformer RGB-T跟踪网络USTrack，它通过双嵌入层和自注意机制实现模态之间的相互作用和互助指导，从而提高了网络适应目标的能力，并将三阶段融合跟踪范例合并为一个结构，提高了跟踪速度和目标-背景可区分性。

    

    多数现有的RGB-T跟踪网络以分离的方式提取模态特征，缺乏模态之间的相互作用和互助指导。这限制了网络适应目标的多样双模态外观和模态之间的动态关系的能力。另外，这些网络遵循的三阶段融合跟踪范例严重限制了跟踪速度。为了解决这些问题，我们提出了一种统一单级Transformer RGB-T跟踪网络，即USTrack，将上述三个阶段合并为一个具备双嵌入层的单一ViT（视觉Transformer）骨干，并通过自注意机制进行模态的相互作用。通过这种结构，网络可以在模态的相互作用下提取模板和搜索区域的融合特征。同时，对这些特征进行关系建模，高效地获得具有更好的目标-背景可区分性的搜索区域融合特征。

    Most existing RGB-T tracking networks extract modality features in a separate manner, which lacks interaction and mutual guidance between modalities. This limits the network's ability to adapt to the diverse dual-modality appearances of targets and the dynamic relationships between the modalities. Additionally, the three-stage fusion tracking paradigm followed by these networks significantly restricts the tracking speed. To overcome these problems, we propose a unified single-stage Transformer RGB-T tracking network, namely USTrack, which unifies the above three stages into a single ViT (Vision Transformer) backbone with a dual embedding layer through self-attention mechanism. With this structure, the network can extract fusion features of the template and search region under the mutual interaction of modalities. Simultaneously, relation modeling is performed between these features, efficiently obtaining the search region fusion features with better target-background discriminability f
    
[^23]: 如何利用上下文帮助？探索段落和个性化上下文的联合检索

    How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context. (arXiv:2308.13760v1 [cs.AI])

    [http://arxiv.org/abs/2308.13760](http://arxiv.org/abs/2308.13760)

    本文探索了如何将个性化上下文信息与文档对话系统结合，提出了个性化上下文感知的段落检索任务，并引入了一种有效利用上下文信息的新颖方法PCAS。通过实验证明，PCAS不仅在检索最相关的段落方面优于基准系统，而且在确定相关上下文方面也表现出色。这将激发未来研究的兴趣。

    

    将外部个性化上下文信息整合到以文档为基础的对话系统中具有重要的商业价值，但这方面的研究还不够深入。受个性化上下文感知文档对话系统的概念启发，我们引入了上下文感知的段落检索任务，并构建了一个专门为此目的策划的数据集。我们描述了多个基准系统来解决这个任务，并提出了一种新颖的方法，即个性化上下文感知搜索(Personalized Context-Aware Search，PCAS)，它在段落检索过程中有效地利用上下文信息。在多个流行的稠密检索系统上进行的实验评估表明，我们的方法不仅在检索最相关的段落方面优于基准系统，而且在确定所有可用上下文中的相关上下文方面也表现出色。我们预计我们的贡献将成为激励未来研究的催化剂。

    The integration of external personalized context information into document-grounded conversational systems has significant potential business value, but has not been well-studied. Motivated by the concept of personalized context-aware document-grounded conversational systems, we introduce the task of context-aware passage retrieval. We also construct a dataset specifically curated for this purpose. We describe multiple baseline systems to address this task, and propose a novel approach, Personalized Context-Aware Search (PCAS), that effectively harnesses contextual information during passage retrieval. Experimental evaluations conducted on multiple popular dense retrieval systems demonstrate that our proposed approach not only outperforms the baselines in retrieving the most relevant passage but also excels at identifying the pertinent context among all the available contexts. We envision that our contributions will serve as a catalyst for inspiring future research endeavors in this pr
    
[^24]: SamDSK: 结合分割任意模型和领域特定知识进行医学图像分割的半监督学习

    SamDSK: Combining Segment Anything Model with Domain-Specific Knowledge for Semi-Supervised Learning in Medical Image Segmentation. (arXiv:2308.13759v1 [cs.CV])

    [http://arxiv.org/abs/2308.13759](http://arxiv.org/abs/2308.13759)

    这篇论文介绍了一种新方法SamDSK，结合分割任意模型和领域特定知识，在医学图像分割中进行半监督学习。方法包括迭代的两个阶段：分割模型训练和使用训练好的模型和领域特定知识扩展有标签集。通过将分割建议和领域特定知识结合，构建无标签图像的注释。

    

    分割任意模型（SAM）展示了在自然图像中分割各种对象的能力，是各种下游图像分割任务的多功能感知工具。然而，医学图像分割任务通常依赖于领域特定知识（DSK）。在本文中，我们提出了一种将分割基础模型（即SAM）与领域特定知识相结合的新方法，以可靠地利用无标签图像构建医学图像分割模型。我们的新方法是迭代的，包括两个主要阶段：（1）分割模型训练；（2）使用训练好的分割模型、无标签集、SAM和领域特定知识扩展有标签集。这两个阶段重复进行，直到无法再添加样本到有标签集为止。我们开发了一种基于最优匹配的方法，将SAM生成的分割建议与像素级和图像级的DSK相结合，构建无标签图像的注释。

    The Segment Anything Model (SAM) exhibits a capability to segment a wide array of objects in natural images, serving as a versatile perceptual tool for various downstream image segmentation tasks. In contrast, medical image segmentation tasks often rely on domain-specific knowledge (DSK). In this paper, we propose a novel method that combines the segmentation foundation model (i.e., SAM) with domain-specific knowledge for reliable utilization of unlabeled images in building a medical image segmentation model. Our new method is iterative and consists of two main stages: (1) segmentation model training; (2) expanding the labeled set by using the trained segmentation model, an unlabeled set, SAM, and domain-specific knowledge. These two stages are repeated until no more samples are added to the labeled set. A novel optimal-matching-based method is developed for combining the SAM-generated segmentation proposals and pixel-level and image-level DSK for constructing annotations of unlabeled 
    
[^25]: i-Align: 一种可解释的知识图对齐模型

    i-Align: an interpretable knowledge graph alignment model. (arXiv:2308.13755v1 [cs.AI])

    [http://arxiv.org/abs/2308.13755](http://arxiv.org/abs/2308.13755)

    i-Align是一种可解释的知识图对齐模型，可以提供对每个对齐预测的解释，并保持高对齐性能，维护知识图的高质量。

    

    知识图（KG）对于许多下游应用程序来说已经成为必不可少的资源。然而，它们的不完整性可能限制了它们的潜力。因此，需要进行连续维护来减轻这个问题。解决这个问题的策略之一是KG对齐，即通过合并两个或多个KG来形成一个更完整的KG。本文提出了一种可解释的KG对齐模型i-Align。与现有的KG对齐模型不同，i-Align在保持高对齐性能的同时为每个对齐预测提供解释。专家可以使用解释来检查对齐预测的正确性。因此，在维护过程中（例如两个KG的合并过程）可以保持KG的高质量。为此，本文提出了一种新颖的基于Transformer的图编码器（Trans-GE），作为i-Align的关键组成部分，用于聚合实体之间的邻居（结构）信息。Trans-GE使用边缘门控注意力来结合邻接矩阵和…（原文未完）

    Knowledge graphs (KGs) are becoming essential resources for many downstream applications. However, their incompleteness may limit their potential. Thus, continuous curation is needed to mitigate this problem. One of the strategies to address this problem is KG alignment, i.e., forming a more complete KG by merging two or more KGs. This paper proposes i-Align, an interpretable KG alignment model. Unlike the existing KG alignment models, i-Align provides an explanation for each alignment prediction while maintaining high alignment performance. Experts can use the explanation to check the correctness of the alignment prediction. Thus, the high quality of a KG can be maintained during the curation process (e.g., the merging process of two KGs). To this end, a novel Transformer-based Graph Encoder (Trans-GE) is proposed as a key component of i-Align for aggregating information from entities' neighbors (structures). Trans-GE uses Edge-gated Attention that combines the adjacency matrix and th
    
[^26]: PE-MED: 提高交互式医学图像分割的提示增强技术

    PE-MED: Prompt Enhancement for Interactive Medical Image Segmentation. (arXiv:2308.13746v1 [cs.CV])

    [http://arxiv.org/abs/2308.13746](http://arxiv.org/abs/2308.13746)

    本文介绍了一个名为PE-MED的新框架，用于提高交互式医学图像分割的成功率。它通过引入自循环策略和提示注意力学习模块来改善用户提供的提示信息的利用，从而防止不利情况的发生，并提高分割结果的准确性。

    

    交互式医学图像分割是指通过用户与图像之间的交互（例如，点击）准确地分割出感兴趣的目标。近年来，它得到了广泛研究，因为它不太依赖于大量标注的数据，比完全自动化的分割更加灵活。然而，当前的研究还没有充分探索用户提供的提示信息（例如，点），包括在一个交互中挖掘的知识以及多个交互之间的关系。因此，本文介绍了一种装备有提示增强的新型框架，名为PE-MED，用于交互式医学图像分割。首先，我们引入了一种自循环策略，基于第一个提示生成温暖的初始分割结果。它可以防止出现高度不利的情况，比如在第一次交互后遇到空白遮罩作为初始输入。其次，我们提出了一种新颖的提示注意力学习模块（PALM），用于挖掘有用的提示信息。

    Interactive medical image segmentation refers to the accurate segmentation of the target of interest through interaction (e.g., click) between the user and the image. It has been widely studied in recent years as it is less dependent on abundant annotated data and more flexible than fully automated segmentation. However, current studies have not fully explored user-provided prompt information (e.g., points), including the knowledge mined in one interaction, and the relationship between multiple interactions. Thus, in this paper, we introduce a novel framework equipped with prompt enhancement, called PE-MED, for interactive medical image segmentation. First, we introduce a Self-Loop strategy to generate warm initial segmentation results based on the first prompt. It can prevent the highly unfavorable scenarios, such as encountering a blank mask as the initial input after the first interaction. Second, we propose a novel Prompt Attention Learning Module (PALM) to mine useful prompt infor
    
[^27]: 关于将哲学、心理学与数学相结合的Philomatics和Psychomatics研究

    On Philomatics and Psychomatics for Combining Philosophy and Psychology with Mathematics. (arXiv:2308.13738v1 [math.HO])

    [http://arxiv.org/abs/2308.13738](http://arxiv.org/abs/2308.13738)

    本文提出了将哲学、心理学与数学相结合的Philomatics和Psychomatics概念，并解释了四个动机：满足分析哲学的需求、提出哲学科学、用哲学来证明数学算法以及哲学和数学的抽象。并列举了多个示例，包括数学中注意机制和上下文原则、形式理论与全息原理的关系等。本文为将哲学和心理学与数学相结合的研究开辟了研究空间。

    

    我们提出了将哲学、心理学与数学相结合的Philomatics和Psychomatics概念。我们解释了这种结合的四个动机，包括满足分析哲学的需求、提出哲学科学、用哲学来证明数学算法以及哲学和数学的抽象。我们列举了各种Philomatics和Psychomatics的示例，其中一些在更深入地解释。第一个示例是关于数学中注意机制与上下文原则、语义整体主义和使用理论的关系分析。另一个示例是关于哲学中柏拉图的形式理论与弦理论中的全息原理、面向对象编程和机器学习的关系。最后，我们解释了维特根斯坦的家族相似性与数学中的聚类的关系。本文为将哲学和心理学与数学相结合的研究打开了大门。

    We propose the concepts of philomatics and psychomatics as hybrid combinations of philosophy and psychology with mathematics. We explain four motivations for this combination which are fulfilling the desire of analytical philosophy, proposing science of philosophy, justifying mathematical algorithms by philosophy, and abstraction in both philosophy and mathematics. We enumerate various examples for philomatics and psychomatics, some of which are explained in more depth. The first example is the analysis of relation between the context principle, semantic holism, and the usage theory of meaning with the attention mechanism in mathematics. The other example is on the relations of Plato's theory of forms in philosophy with the holographic principle in string theory, object-oriented programming, and machine learning. Finally, the relation between Wittgenstein's family resemblance and clustering in mathematics is explained. This paper opens the door of research for combining philosophy and 
    
[^28]: AI生成音乐评估方法的综合调研

    A Comprehensive Survey for Evaluation Methodologies of AI-Generated Music. (arXiv:2308.13736v1 [cs.SD])

    [http://arxiv.org/abs/2308.13736](http://arxiv.org/abs/2308.13736)

    这项研究综合评估了主观、客观和综合方法，用于评估AI生成音乐，突出了每种方法的优势和劣势，为统一音乐评估领域的生成AI提供了有价值的参考。

    

    近年来，AI生成的音乐取得了显著进展，在多模态和复杂的音乐流派和场景中表现出良好的性能。虽然可以使用客观度量指标评估生成音乐，但它们往往在音乐评估方面缺乏解释性。因此，研究人员常常依赖主观用户研究来评估生成作品的质量，但这种方法需要耗费资源，并且比客观度量指标更难复现。本研究旨在全面评估主观、客观和综合方法，用于评估AI生成音乐，并突出每种方法的优势和劣势。最终，本研究为在音乐评估领域统一生成AI提供了有价值的参考。

    In recent years, AI-generated music has made significant progress, with several models performing well in multimodal and complex musical genres and scenes. While objective metrics can be used to evaluate generative music, they often lack interpretability for musical evaluation. Therefore, researchers often resort to subjective user studies to assess the quality of the generated works, which can be resource-intensive and less reproducible than objective metrics. This study aims to comprehensively evaluate the subjective, objective, and combined methodologies for assessing AI-generated music, highlighting the advantages and disadvantages of each approach. Ultimately, this study provides a valuable reference for unifying generative AI in the field of music evaluation.
    
[^29]: ISR-LLM: 迭代自我完善的大型语言模型用于长时间序列任务规划

    ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning. (arXiv:2308.13724v1 [cs.RO])

    [http://arxiv.org/abs/2308.13724](http://arxiv.org/abs/2308.13724)

    提出了ISR-LLM框架，通过迭代自我完善过程改进了LLM-based规划，该框架包括预处理、规划和迭代自我完善三个步骤。通过引入LLM翻译器将自然语言输入转换为PDDL形式，提高了生成的任务计划的可行性和正确性。

    

    受到自然语言处理领域大型语言模型（LLMs）取得的重大成就的启发，最近的研究开始探索将LLMs应用于机器人领域的复杂长时序列任务规划挑战。LLMs具有优势，可以提升通用性作为任务无关的规划者，并促进人类教师和规划系统之间的灵活互动。然而，LLMs生成的任务计划经常缺乏可行性和正确性。为了解决这个挑战，我们引入了ISR-LLM，一种通过迭代自我完善过程改进基于LLM的规划的新框架。该框架通过三个连续的步骤进行操作：预处理、规划和迭代自我完善。在预处理阶段，使用LLM翻译器将自然语言输入转换为规划域定义语言（PDDL）形式。在规划阶段，LLM规划器制定了任务计划的初步方案。

    Motivated by the substantial achievements observed in Large Language Models (LLMs) in the field of natural language processing, recent research has commenced investigations into the application of LLMs for complex, long-horizon sequential task planning challenges in robotics. LLMs are advantageous in offering the potential to enhance the generalizability as task-agnostic planners and facilitate flexible interaction between human instructors and planning systems. However, task plans generated by LLMs often lack feasibility and correctness. To address this challenge, we introduce ISR-LLM, a novel framework that improves LLM-based planning through an iterative self-refinement process. The framework operates through three sequential steps: preprocessing, planning, and iterative self-refinement. During preprocessing, an LLM translator is employed to convert natural language input into a Planning Domain Definition Language (PDDL) formulation. In the planning phase, an LLM planner formulates 
    
[^30]: WellXplain: Reddit帖子中的健康概念提取和分类，用于精神健康分析

    WellXplain: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health Analysis. (arXiv:2308.13710v1 [cs.CL])

    [http://arxiv.org/abs/2308.13710](http://arxiv.org/abs/2308.13710)

    本研究提出了一种通过在Reddit内容中识别健康维度的方法来进行复杂的精神健康分析。他们创建了一个名为WELLXPLAIN的数据集，并制定了一个注释框架。这种方法有助于在社交媒体上识别潜在的精神问题指标。

    

    在当前的精神健康危机中，从社交媒体内容中识别潜在的精神问题指标的重要性有所增加。忽视精神和社会幸福的多面性可能对一个人的精神状态产生有害影响。在传统的治疗过程中，专业人员需要手动确定潜在精神挑战的起源和结果，这是一个详细而耗时的过程。我们通过将Reddit内容中的健康维度识别为健康概念提取和分类的挑战，引入了一种复杂的精神健康分析方法。我们创建了一个名为WELLXPLAIN的独特数据集，包括3,092个条目，总计72,813个单词。基于哈尔伯特·L·邓恩的著名健康理论，我们的团队制定了一个注释框架和指南。该数据集还包括人工标记的文本片段，清楚解释了健康概念分类决策的原因。

    During the current mental health crisis, the importance of identifying potential indicators of mental issues from social media content has surged. Overlooking the multifaceted nature of mental and social well-being can have detrimental effects on one's mental state. In traditional therapy sessions, professionals manually pinpoint the origins and outcomes of underlying mental challenges, a process both detailed and time-intensive. We introduce an approach to this intricate mental health analysis by framing the identification of wellness dimensions in Reddit content as a wellness concept extraction and categorization challenge. We've curated a unique dataset named WELLXPLAIN, comprising 3,092 entries and totaling 72,813 words. Drawing from Halbert L. Dunn's well-regarded wellness theory, our team formulated an annotation framework along with guidelines. This dataset also includes human-marked textual segments, offering clear reasoning for decisions made in the wellness concept categoriza
    
[^31]: 将动态PicoProbe分析电子光学束线/显微镜与超级计算机相连接

    Linking the Dynamic PicoProbe Analytical Electron-Optical Beam Line / Microscope to Supercomputers. (arXiv:2308.13701v1 [cs.DC])

    [http://arxiv.org/abs/2308.13701](http://arxiv.org/abs/2308.13701)

    本文提出了将Dynamic PicoProbe的数据传输与Argonne领导计算设施相邻超级计算机相连接的软件架构，该架构支持大规模数据传输和离线数据分析，为科学家提供了查询和重新分析过去实验数据的能力。

    

    动态PicoProbe正在Argonne国家实验室进行升级，将能够每天产生高达数百GB的数据。虽然这些数据对基础科学和工业应用都非常重要，但目前在场内的基础设施无法处理这些高容量的数据流。为解决这个问题，我们提供了一个能够支持大规模数据传输到Argonne领导计算设施相邻超级计算机的软件架构。为了准备未来的科学工作流，我们实施了两个示例用例，包括高光谱和时空数据集的（i）离场数据传输，（ii）机器学习/人工智能和传统数据分析方法，以及（iii）实验结果的自动元数据提取和编目。这种基础设施不仅支持预期工作负载，还使领域科学家能够重新查询过去实验的数据。

    The Dynamic PicoProbe at Argonne National Laboratory is undergoing upgrades that will enable it to produce up to 100s of GB of data per day. While this data is highly important for both fundamental science and industrial applications, there is currently limited on-site infrastructure to handle these high-volume data streams. We address this problem by providing a software architecture capable of supporting large-scale data transfers to the neighboring supercomputers at the Argonne Leadership Computing Facility. To prepare for future scientific workflows, we implement two instructive use cases for hyperspectral and spatiotemporal datasets, which include: (i) off-site data transfer, (ii) machine learning/artificial intelligence and traditional data analysis approaches, and (iii) automatic metadata extraction and cataloging of experimental results. This infrastructure supports expected workloads and also provides domain scientists the ability to reinterrogate data from past experiments to
    
[^32]: 关于文本生成中的束搜索和穷举搜索的深度问题研究

    On the Depth between Beam Search and Exhaustive Search for Text Generation. (arXiv:2308.13696v1 [cs.CL])

    [http://arxiv.org/abs/2308.13696](http://arxiv.org/abs/2308.13696)

    本研究探讨了束搜索和穷举搜索之间一系列不同的搜索深度，提出了前瞻束搜索（LBS）算法进行优化。尽管束搜索的搜索误差较高，但在计算成本和性能方面优于穷举搜索。

    

    束搜索和穷举搜索是文本解码算法中深度搜索的两个极端。束搜索在搜索宽度和深度上都有限制，而穷举搜索是全局搜索，没有这些限制。令人惊讶的是，尽管束搜索的搜索误差较高，但它不仅计算成本更低，而且表现更好。许多研究对一系列不同的束宽度进行了调查，并报告称既不太大也不太小的束宽度是理想的。然而，在搜索深度方面，只有束搜索和穷举搜索这两个极端得到了深入研究。在本文中，我们研究了介于两个极端之间的一系列搜索深度，以发现理想的搜索深度。为此，我们引入了前瞻束搜索（LBS），这是一种多步前瞻搜索，通过考虑未来固定步数来优化目标。束搜索和穷举搜索是特殊情况。

    Beam search and exhaustive search are two extreme ends of text decoding algorithms with respect to the search depth. Beam search is limited in both search width and depth, whereas exhaustive search is a global search that has no such limitations. Surprisingly, beam search is not only computationally cheaper but also performs better than exhaustive search despite its higher search error. Plenty of research has investigated a range of beam widths, from small to large, and reported that a beam width that is neither too large nor too small is desirable. However, in terms of search depth, only the two extreme ends, beam search and exhaustive search are studied intensively. In this paper, we examine a range of search depths between the two extremes to discover the desirable search depth. To this end, we introduce Lookahead Beam Search (LBS), a multi-step lookahead search that optimizes the objective considering a fixed number of future steps. Beam search and exhaustive search are special cas
    
[^33]: 一颗开放的卫星高光谱数据集与来自HYPSO-1卫星的海陆云地面真实数据

    An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the HYPSO-1 Satellite. (arXiv:2308.13679v1 [cs.CV])

    [http://arxiv.org/abs/2308.13679](http://arxiv.org/abs/2308.13679)

    这个论文介绍了一个开放的卫星高光谱数据集，包含了来自HYPSO-1卫星的海陆云地面真实数据，并且通过优化深度学习模型，取得了比现有技术更好的性能。

    

    高光谱成像被卫星用于空间遥感，在像HYPSO-1这样的卫星上，面临着少量标注数据集的限制，影响了对需求这些地面真实标注的AI模型的训练。在本研究中，我们介绍了HYPSO-1海陆云标注数据集，这是一个包含200个不同高光谱图像的开放数据集，来自于HYPSO-1任务，可提供未经校准和经过校准的形式，供地球观测的科学研究使用。此外，其中包括来自不同国家的38个图像，在像素级别上包含总计约2500万个为海洋/陆地/云分类标记的光谱特征。为了展示数据集及其标记子集的潜力，我们还优化了一个深度学习模型（1D完全卷积网络），在性能上超过了当前技术水平。完整的数据集，地面真实标注，深度学习模型和软件代码可在网站https://ntnu-sm上免费下载。

    Hyperspectral Imaging, employed in satellites for space remote sensing, like HYPSO-1, faces constraints due to few labeled data sets, affecting the training of AI models demanding these ground-truth annotations. In this work, we introduce The HYPSO-1 Sea-Land-Cloud-Labeled Dataset, an open dataset with 200 diverse hyperspectral images from the HYPSO-1 mission, available in both raw and calibrated forms for scientific research in Earth observation. Moreover, 38 of these images from different countries include ground-truth labels at pixel-level totaling about 25 million spectral signatures labeled for sea/land/cloud categories. To demonstrate the potential of the dataset and its labeled subset, we have additionally optimized a deep learning model (1D Fully Convolutional Network), achieving superior performance to the current state of the art. The complete dataset, ground-truth labels, deep learning model, and software code are openly accessible for download at the website https://ntnu-sm
    
[^34]: 重新思考语言模型作为符号知识图谱

    Rethinking Language Models as Symbolic Knowledge Graphs. (arXiv:2308.13676v1 [cs.CL])

    [http://arxiv.org/abs/2308.13676](http://arxiv.org/abs/2308.13676)

    本研究对不同大小和能力的语言模型进行了全面评估，发现它们能否涵盖知识图谱的复杂拓扑和语义属性，这对于推理过程至关重要。

    

    符号知识图谱在搜索、问答和推荐等以知识为中心的应用中起着关键作用。随着当代基于大量文本数据训练的语言模型（LMs）的重要性日益增加，研究人员广泛探讨了这些模型中的参数化知识是否能够与知识图谱中的知识相匹配。各种方法表明，增加模型大小或训练数据量可以增强其检索符号知识的能力，通常几乎不需要人工监督。尽管取得了这些进展，但我们对于语言模型能否涵盖知识图谱的复杂拓扑和语义属性进行了全面评估，这些属性对于推理过程至关重要。在这项工作中，我们对不同大小和能力的语言模型进行了详尽的评估。我们构建了九个定性基准，涵盖了一系列属性，包括对称性、不对称性、

    Symbolic knowledge graphs (KGs) play a pivotal role in knowledge-centric applications such as search, question answering and recommendation. As contemporary language models (LMs) trained on extensive textual data have gained prominence, researchers have extensively explored whether the parametric knowledge within these models can match up to that present in knowledge graphs. Various methodologies have indicated that enhancing the size of the model or the volume of training data enhances its capacity to retrieve symbolic knowledge, often with minimal or no human supervision. Despite these advancements, there is a void in comprehensively evaluating whether LMs can encompass the intricate topological and semantic attributes of KGs, attributes crucial for reasoning processes. In this work, we provide an exhaustive evaluation of language models of varying sizes and capabilities. We construct nine qualitative benchmarks that encompass a spectrum of attributes including symmetry, asymmetry, h
    
[^35]: 使用学习到的概率车道图来生成和解释角落情况

    Generating and Explaining Corner Cases Using Learnt Probabilistic Lane Graphs. (arXiv:2308.13658v1 [cs.AI])

    [http://arxiv.org/abs/2308.13658](http://arxiv.org/abs/2308.13658)

    本论文提出了使用概率车道图生成和解释角落情况的方法，该方法基于历史交通数据生成新颖而逼真的角落情况，以提高自动驾驶车辆的安全性。

    

    在开放动态环境中验证自动驾驶汽车（AV）的安全性具有挑战性，因为车辆最终会遇到没有代表性训练数据的安全关键情况。通过在基于模拟的场景测试中增加不同的道路和交通条件的覆盖范围，并包括角落情况，可以提高AV的安全性。然而，包含多个代理的角落情况场景的创建是非常困难的。我们的方法可以让工程师基于历史交通数据生成新颖而逼真的角落情况，并解释为什么这些情况是安全关键的。在本文中，我们引入了概率车道图（PLGs）来描述车辆可能行驶的有限一组车道位置和方向。PLGs的结构是直接从时空交通数据中学习得到的。图模型以概率策略的形式表示驾驶员对给定状态的响应行为。

    Validating the safety of Autonomous Vehicles (AVs) operating in open-ended, dynamic environments is challenging as vehicles will eventually encounter safety-critical situations for which there is not representative training data. By increasing the coverage of different road and traffic conditions and by including corner cases in simulation-based scenario testing, the safety of AVs can be improved. However, the creation of corner case scenarios including multiple agents is non-trivial. Our approach allows engineers to generate novel, realistic corner cases based on historic traffic data and to explain why situations were safety-critical. In this paper, we introduce Probabilistic Lane Graphs (PLGs) to describe a finite set of lane positions and directions in which vehicles might travel. The structure of PLGs is learnt directly from spatio-temporal traffic data. The graph model represents the actions of the drivers in response to a given state in the form of a probabilistic policy. We use
    
[^36]: 通过机器学习进行索引调优：最新进展与开放挑战的概述

    ML-Powered Index Tuning: An Overview of Recent Progress and Open Challenges. (arXiv:2308.13641v1 [cs.DB])

    [http://arxiv.org/abs/2308.13641](http://arxiv.org/abs/2308.13641)

    本文总结了现代云服务中自动索引调优面临的主要挑战，以及机器学习技术在解决这些挑战方面的最新进展。该研究主要关注工作负载选择、候选索引过滤、加速索引配置搜索、减少查询优化器调用的数量和降低性能回归机会等方面，并提出创新的解决方案。

    

    现代云服务中工作负载的规模和复杂性使得自动索引调优面临着一个关键挑战——在保持索引调优可扩展性的同时推荐高质量的索引。这一挑战进一步受到自动索引实现在生产环境中引入最小查询性能回归的要求的影响，这构成了实现可扩展性和全自动化的重要障碍。本文关注自动索引调优中的这些挑战，并探讨机器学习技术在缓解这些挑战方面提供的新机遇。具体来说，我们回顾了在工作负载选择、候选索引过滤、加速索引配置搜索、减少查询优化器调用的数量以及降低性能回归机会方面开展的最新工作。我们强调这些工作的关键要点，并强调其创新与贡献。

    The scale and complexity of workloads in modern cloud services have brought into sharper focus a critical challenge in automated index tuning -- the need to recommend high-quality indexes while maintaining index tuning scalability. This challenge is further compounded by the requirement for automated index implementations to introduce minimal query performance regressions in production deployments, representing a significant barrier to achieving scalability and full automation. This paper directs attention to these challenges within automated index tuning and explores ways in which machine learning (ML) techniques provide new opportunities in their mitigation. In particular, we reflect on recent efforts in developing ML techniques for workload selection, candidate index filtering, speeding up index configuration search, reducing the amount of query optimizer calls, and lowering the chances of performance regressions. We highlight the key takeaways from these efforts and underline the g
    
[^37]: 自适应白化：快速增益调制和慢速突触可塑性

    Adaptive whitening with fast gain modulation and slow synaptic plasticity. (arXiv:2308.13633v1 [q-bio.NC])

    [http://arxiv.org/abs/2308.13633](http://arxiv.org/abs/2308.13633)

    本研究提出了一个多时间尺度的自适应白化机制模型，使用快速增益调制和慢速突触可塑性相结合的方式来适应变化的感觉统计信息。

    

    早期感觉区的神经元能够迅速适应变化的感觉统计信息，通过对其个体响应的方差进行归一化以及减少响应之间的相关性。这些转换可以被视为一种自适应的白化过程。现有的自适应白化的机制模型只使用突触可塑性或增益调制作为适应的生物基质，然而，每个模型都有显著的局限性。在这项工作中，我们将这些方法统一起来，提出了一个规范性的多时间尺度机制模型，通过突触可塑性和增益调制的计算角色来自适应地进行白化。增益在快速时间尺度上根据当前的统计情况进行调整，而突触在慢速时间尺度上进行调整，学习输入统计中与情境无关的结构特性。我们的模型来自于一种新颖的多时间尺度

    Neurons in early sensory areas rapidly adapt to changing sensory statistics, both by normalizing the variance of their individual responses and by reducing correlations between their responses. Together, these transformations may be viewed as an adaptive form of statistical whitening. Existing mechanistic models of adaptive whitening exclusively use either synaptic plasticity or gain modulation as the biological substrate for adaptation; however, on their own, each of these models has significant limitations. In this work, we unify these approaches in a normative multi-timescale mechanistic model that adaptively whitens its responses with complementary computational roles for synaptic plasticity and gain modulation. Gains are modified on a fast timescale to adapt to the current statistical context, whereas synapses are modified on a slow timescale to learn structural properties of the input statistics that are invariant across contexts. Our model is derived from a novel multi-timescale
    
[^38]: HiFiHR：通过高保真纹理增强来自单张图像的3D手部重建

    HiFiHR: Enhancing 3D Hand Reconstruction from a Single Image via High-Fidelity Texture. (arXiv:2308.13628v1 [cs.CV])

    [http://arxiv.org/abs/2308.13628](http://arxiv.org/abs/2308.13628)

    HiFiHR是一种通过高保真纹理增强来自单张图像的3D手部重建方法，能够生成逼真且准确的手部网格，并通过各种程度的监督方式改善手部姿态和形状估计。

    

    我们提出了HiFiHR，一种高保真手部重建方法，利用了从单张图像中基于学习的渲染和比较能力，能够生成逼真且准确的3D手部网格，并恢复真实的纹理。我们的方法通过使用预定义纹理资源的参数化手部模型，并在训练过程中在渲染和输入图像之间建立纹理重建一致性来实现卓越的纹理重建效果。此外，我们在一个标注数据集上对网络进行预训练，并使用我们的管道以不同程度的监督方式（自监督、弱监督和全监督）进行实验，讨论了学习到的高保真纹理在改善手部姿态和形状估计中的不同贡献水平。在包括FreiHAND和HO-3D在内的公共基准测试上的实验结果表明，我们的方法在纹理重建质量方面优于现有的手部重建方法。

    We present HiFiHR, a high-fidelity hand reconstruction approach that utilizes render-and-compare in the learning-based framework from a single image, capable of generating visually plausible and accurate 3D hand meshes while recovering realistic textures. Our method achieves superior texture reconstruction by employing a parametric hand model with predefined texture assets, and by establishing a texture reconstruction consistency between the rendered and input images during training. Moreover, based on pretraining the network on an annotated dataset, we apply varying degrees of supervision using our pipeline, i.e., self-supervision, weak supervision, and full supervision, and discuss the various levels of contributions of the learned high-fidelity textures in enhancing hand pose and shape estimation. Experimental results on public benchmarks including FreiHAND and HO-3D demonstrate that our method outperforms the state-of-the-art hand reconstruction methods in texture reconstruction qu
    
[^39]: 甲状腺癌诊断中的人工智能: 技术、趋势和未来方向

    AI in Thyroid Cancer Diagnosis: Techniques, Trends, and Future Directions. (arXiv:2308.13592v1 [eess.IV])

    [http://arxiv.org/abs/2308.13592](http://arxiv.org/abs/2308.13592)

    本论文总结了在甲状腺癌诊断中使用人工智能（AI）技术的相关研究。通过提出新的分类方法并比较现有数据集的特征，研究重点在于如何通过AI工具支持甲状腺癌的诊断和治疗。

    

    在创建智能诊断系统以协助医学专业人员分析和处理治疗无法治愈疾病的大数据方面，引起了越来越多的关注。在这一领域的一个关键挑战是检测甲状腺癌，在使用机器学习（ML）和大数据分析进行甲状腺癌预后评估和确定患者恶性风险方面已经取得了进展。本综述论文总结了与在甲状腺癌诊断中使用人工智能（AI）技术相关的大量文章。相应地，引入了一个新的分类方法，根据所使用的AI算法、框架的目的和计算平台对这些技术进行分类。此外，本研究还根据其特征比较了现有的甲状腺癌数据集。本研究的重点是通过有监督、无监督或混合的AI工具如何支持甲状腺癌的诊断和治疗。

    There has been a growing interest in creating intelligent diagnostic systems to assist medical professionals in analyzing and processing big data for the treatment of incurable diseases. One of the key challenges in this field is detecting thyroid cancer, where advancements have been made using machine learning (ML) and big data analytics to evaluate thyroid cancer prognosis and determine a patient's risk of malignancy. This review paper summarizes a large collection of articles related to artificial intelligence (AI)-based techniques used in the diagnosis of thyroid cancer. Accordingly, a new classification was introduced to classify these techniques based on the AI algorithms used, the purpose of the framework, and the computing platforms used. Additionally, this study compares existing thyroid cancer datasets based on their features. The focus of this study is on how AI-based tools can support the diagnosis and treatment of thyroid cancer, through supervised, unsupervised, or hybrid
    
[^40]: 基于视觉变换器的FrFT算法估计线性和非线性失真

    FrFT based estimation of linear and nonlinear impairments using Vision Transformer. (arXiv:2308.13575v1 [eess.SP])

    [http://arxiv.org/abs/2308.13575](http://arxiv.org/abs/2308.13575)

    本论文提出了基于FrFT和Transformer的联合估计方法，用于统一表示和识别光纤通信系统中的线性和非线性失真。在数值模拟中验证了该方法的有效性。

    

    为了全面评估光纤通信系统的情况，必须实施以下四个关键失真的联合估计：非线性信噪比（SNRNL），光信噪比（OSNR），色散（CD）和差分组延迟（DGD）。然而，由于网络能力的限制和失真统一表示的缺乏，当前研究只能在有限的范围内识别少数失真。为了应对这些挑战，我们采用基于分数傅里叶变换（FrFT）的时频信号处理来实现失真的统一表示，同时采用基于Transformer的神经网络（NN）来突破网络性能的限制。为了验证所提出的估计方法的有效性，我们对5通道偏振分复用四相移键控（PDM-QPSK）长距离光传输进行了数值模拟。

    To comprehensively assess optical fiber communication system conditions, it is essential to implement joint estimation of the following four critical impairments: nonlinear signal-to-noise ratio (SNRNL), optical signal-to-noise ratio (OSNR), chromatic dispersion (CD) and differential group delay (DGD). However, current studies only achieve identifying a limited number of impairments within a narrow range, due to limitations in network capabilities and lack of unified representation of impairments. To address these challenges, we adopt time-frequency signal processing based on fractional Fourier transform (FrFT) to achieve the unified representation of impairments, while employing a Transformer based neural networks (NN) to break through network performance limitations. To verify the effectiveness of the proposed estimation method, the numerical simulation is carried on a 5-channel polarization-division-multiplexed quadrature phase shift keying (PDM-QPSK) long haul optical transmission 
    
[^41]: 工业人工智能中的随机配置机

    Stochastic Configuration Machines for Industrial Artificial Intelligence. (arXiv:2308.13570v1 [cs.LG])

    [http://arxiv.org/abs/2308.13570](http://arxiv.org/abs/2308.13570)

    本文提出了一种新颖的随机学习器模型，称为随机配置机（SCMs），其基于随机配置网络（SCNs），旨在强调工业人工智能中的有效建模和节约数据大小。SCMs通过压缩模型存储，并保持有利的预测性能，具有在工业应用中很大的潜力。

    

    在工业人工智能（IAI）中，需要实时、准确的预测建模，神经网络在其中起到关键作用。工业人工智能中的神经网络需要强大的高性能计算设备来处理大量的浮点数据。本文基于随机配置网络（SCNs），提出了一种新的随机学习器模型，称为随机配置机（SCMs），以强调对于工业应用非常有用和有价值的有效建模和节约数据大小。与具有二值化实现的随机向量功能链接（RVFL）网络相比，SCMs的模型存储可以显著压缩，同时保持有利的预测性能。除了SCM学习器模型的架构和学习算法，作为本文的重要部分，我们还通过分析模型的复杂性提供了SCMs的学习能力的理论基础。实验研究也进行了。

    Real-time predictive modelling with desired accuracy is highly expected in industrial artificial intelligence (IAI), where neural networks play a key role. Neural networks in IAI require powerful, high-performance computing devices to operate a large number of floating point data. Based on stochastic configuration networks (SCNs), this paper proposes a new randomized learner model, termed stochastic configuration machines (SCMs), to stress effective modelling and data size saving that are useful and valuable for industrial applications. Compared to SCNs and random vector functional-link (RVFL) nets with binarized implementation, the model storage of SCMs can be significantly compressed while retaining favourable prediction performance. Besides the architecture of the SCM learner model and its learning algorithm, as an important part of this contribution, we also provide a theoretical basis on the learning capacity of SCMs by analysing the model's complexity. Experimental studies are ca
    
[^42]: MLLM-DataEngine：一种MLLM的迭代改进方法

    MLLM-DataEngine: An Iterative Refinement Approach for MLLM. (arXiv:2308.13566v1 [cs.LG])

    [http://arxiv.org/abs/2308.13566](http://arxiv.org/abs/2308.13566)

    本文提出了一种名为MLLM-DataEngine的迭代改进方法，它通过分析模型弱点，生成适当的增量数据集并迭代地增强模型能力。与以往方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面表现更好。

    

    尽管在指导数据集构建和基准测试方面，多模态大型语言模型（MLLM）取得了很大的进展，但训练和评估的独立性使得当前的MLLM很难在相对较低的人力成本下进一步提高其能力。本文提出了一种新颖的封闭循环系统MLLM-DataEngine，它连接了数据生成、模型训练和评估。在每个循环迭代中，MLLM-DataEngine首先根据评估结果分析模型的弱点，然后生成合适的增量数据集用于下一次训练迭代，并迭代地增强模型的能力。与先前与基准测试分离的数据收集方法相比，MLLM-DataEngine生成的数据在定位、质量和正确性方面都表现得更好。

    Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental datas
    
[^43]: 大型语言模型在分析事故叙述中的应用——ChatGPT、BARD和GPT-4的比较研究

    Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4. (arXiv:2308.13563v1 [cs.CL])

    [http://arxiv.org/abs/2308.13563](http://arxiv.org/abs/2308.13563)

    三个大型语言模型接口(ChatGPT, BARD和GPT4)在分析事故叙述中的效果进行了比较研究。研究结果表明，它们在提取事故相关信息和回答相关问题方面都具有一定的有效性，但也存在一些限制。

    

    在交通安全研究中，使用文本分析从事故叙述中提取信息是一种常见的做法。随着大型语言模型（LLM）的最新进展，了解流行的LLM接口在分类或从事故叙述中提取信息方面的表现将非常有用。为了探索这一问题，我们的研究使用了目前最流行的三个公开可用的LLM接口——ChatGPT、BARD和GPT4。本研究调查了它们在提取信息和回答与事故有关的查询方面的有效性和限制。研究从爱荷华州和堪萨斯州的100个事故叙述中提取信息，并对它们的能力和限制进行了评估，比较了它们对查询的响应。五个与叙述相关的问题被提出：1）谁是责任方？2）碰撞方式是什么？3）事故发生在工作区吗？4）事故涉及行人吗？5）事故中有害事件的顺序是什么？对于第1到第4个问题，三个LLM接口的回答都经过了比较。

    In traffic safety research, extracting information from crash narratives using text analysis is a common practice. With recent advancements of large language models (LLM), it would be useful to know how the popular LLM interfaces perform in classifying or extracting information from crash narratives. To explore this, our study has used the three most popular publicly available LLM interfaces- ChatGPT, BARD and GPT4. This study investigated their usefulness and boundaries in extracting information and answering queries related to accidents from 100 crash narratives from Iowa and Kansas. During the investigation, their capabilities and limitations were assessed and their responses to the queries were compared. Five questions were asked related to the narratives: 1) Who is at-fault? 2) What is the manner of collision? 3) Has the crash occurred in a work-zone? 4) Did the crash involve pedestrians? and 5) What are the sequence of harmful events in the crash? For questions 1 through 4, the o
    
[^44]: 《对GAN增强数据中的偏差进行定量化研究的系统性研究》的翻译

    A Systematic Study on Quantifying Bias in GAN-Augmented Data. (arXiv:2308.13554v1 [cs.LG])

    [http://arxiv.org/abs/2308.13554](http://arxiv.org/abs/2308.13554)

    该研究系统地研究了互动式对抗生成网络（GAN）在数据扩充中引入的偏见，以及用于度量偏见加重程度的度量标准的评估。研究结果表明，虽然有多种度量方法可用，但没有一种单一方法可以可靠地度量不同图像领域中的偏见加重。

    

    生成对抗网络（GANs）最近已成为机器学习实践者使用的流行的数据增强技术。然而，研究表明它们存在所谓的模式崩溃故障模式，使其容易加剧已经偏斜数据集上的偏见，导致生成的数据分布比训练分布更不多样化。为此，我们解决了定量化模式崩溃程度的问题。这项研究是一项系统性的工作，重点评估可能对GAN增强数据中的偏见定量化的最新度量方法。我们发现，虽然有几种方法可用，但没有单一的度量方法可以可靠地定量化不同图像领域的偏见加剧。

    Generative adversarial networks (GANs) have recently become a popular data augmentation technique used by machine learning practitioners. However, they have been shown to suffer from the so-called mode collapse failure mode, which makes them vulnerable to exacerbating biases on already skewed datasets, resulting in the generated data distribution being less diverse than the training distribution. To this end, we address the problem of quantifying the extent to which mode collapse occurs. This study is a systematic effort focused on the evaluation of state-of-the-art metrics that can potentially quantify biases in GAN-augmented data. We show that, while several such methods are available, there is no single metric that quantifies bias exacerbation reliably over the span of different image domains.
    
[^45]: 与你共舞：通过扩散模型实现多样性可控的舞者生成

    Dance with You: The Diversity Controllable Dancer Generation via Diffusion Models. (arXiv:2308.13551v1 [cs.HC])

    [http://arxiv.org/abs/2308.13551](http://arxiv.org/abs/2308.13551)

    本文介绍了一种名为伙伴舞者生成的多舞者合成任务，旨在通过在保持与主导舞者时间协调的同时确保伙伴舞者的可控多样性。为了实现这一目标，提出了一个名为“与你共舞”的三阶段框架（DanY），它能自动设计伙伴舞者的姿势。

    

    最近，虚拟环境中用于人际交互的数字人类引起了广泛关注。本文引入了一项新颖的多舞者合成任务，称为伙伴舞者生成，其涉及合成能够与用户一起跳舞的虚拟人类舞者。该任务旨在控制主导舞者和伙伴舞者之间的姿势多样性。这个任务的核心是确保生成的伙伴舞者具有可控的多样性，同时与主导舞者保持时间上的协调。与以往通过音乐驱动生成舞蹈动作的研究不同，我们的重点是根据预定义的多样性、主导舞者的姿势以及伴奏音乐自动设计伙伴舞者的姿势。为了实现这个目标，我们提出了一个称为“与你共舞”的三阶段框架（DanY）。首先，我们使用三维姿势收集阶段来收集各种基本舞蹈姿势作为参考姿势。

    Recently, digital humans for interpersonal interaction in virtual environments have gained significant attention. In this paper, we introduce a novel multi-dancer synthesis task called partner dancer generation, which involves synthesizing virtual human dancers capable of performing dance with users. The task aims to control the pose diversity between the lead dancer and the partner dancer. The core of this task is to ensure the controllable diversity of the generated partner dancer while maintaining temporal coordination with the lead dancer. This scenario varies from earlier research in generating dance motions driven by music, as our emphasis is on automatically designing partner dancer postures according to pre-defined diversity, the pose of lead dancer, as well as the accompanying tunes. To achieve this objective, we propose a three-stage framework called Dance-with-You (DanY). Initially, we employ a 3D Pose Collection stage to collect a wide range of basic dance poses as referenc
    
[^46]: 朝着全息舱式模拟游戏的方向

    Towards a Holodeck-style Simulation Game. (arXiv:2308.13548v1 [cs.AI])

    [http://arxiv.org/abs/2308.13548](http://arxiv.org/abs/2308.13548)

    Infinitia是一个模拟游戏系统，使用生成图像和语言模型根据玩家的描述塑造游戏场景和NPC，类似于全息舱，同时引入了无限生成的幻想世界、可控的NPC行为、幽默对话、成本和时间效率、玩家合作以及游戏内事件的非确定性元素。

    

    我们引入了Infinitia，一个模拟游戏系统，在游戏时间内使用生成图像和语言模型根据玩家的简短描述重新塑造游戏场景和NPC，类似于虚构的全息舱中创建设置的方式。基于《生成代理》论文的思想，我们的系统引入了游戏性元素，如无限生成的幻想世界，NPC行为的可控性，幽默对话，成本和时间效率，玩家之间的合作以及游戏内事件的非确定性元素。Infinitia使用Unity引擎实现了服务器-客户端架构，方便未来社区开发者加入令人兴奋的功能。此外，它使用了多人框架，允许玩家在模拟中存在并进行交互。模拟将很快在https://infinitia.ai/上提供开放式测试版，并且我们期待与社区共同进步。

    We introduce Infinitia, a simulation game system that uses generative image and language models at play time to reshape all aspects of the setting and NPCs based on a short description from the player, in a way similar to how settings are created on the fictional Holodeck. Building off the ideas of the Generative Agents paper, our system introduces gameplay elements, such as infinite generated fantasy worlds, controllability of NPC behavior, humorous dialogue, cost & time efficiency, collaboration between players and elements of non-determinism among in-game events. Infinitia is implemented in the Unity engine with a server-client architecture, facilitating the addition of exciting features by community developers in the future. Furthermore, it uses a multiplayer framework to allow humans to be present and interact in the simulation. The simulation will be available in open-alpha shortly at https://infinitia.ai/ and we are looking forward to building upon it with the community.
    
[^47]: Hyperscanning EEG的功能性图对比学习揭示了基于刻板印象的压力引发的情绪传染

    Functional Graph Contrastive Learning of Hyperscanning EEG Reveals Emotional Contagion Evoked by Stereotype-Based Stressors. (arXiv:2308.13546v1 [eess.SP])

    [http://arxiv.org/abs/2308.13546](http://arxiv.org/abs/2308.13546)

    本研究通过利用超扫描技术，引入功能性图对比学习方法探究基于刻板印象的压力引发的情绪传染。研究结果揭示了情绪传染与认知功能之间的复杂相互作用。

    

    本研究深入探讨情绪传染的细微差异及其对双人互动中表现的影响。具体而言，研究聚焦于女性对的合作解决问题任务中基于刻板印象的压力背景。通过对情绪传染的研究，旨在揭示其潜在机制和影响。利用基于EEG的超扫描技术，本研究引入了一种名为功能性图对比学习（fGCL）的创新方法，提取主体不变的神经活动模式表示。这些表示进一步应用动态图分类（DGC）模型进行分析，旨在剖析情绪传染的过程。通过对脑部同步和连接性的研究，揭示了情绪传染与认知功能之间的复杂相互作用。结果强调情绪传染在塑造轨迹中的重要作用。

    This study delves into the intricacies of emotional contagion and its impact on performance within dyadic interactions. Specifically, it focuses on the context of stereotype-based stress (SBS) during collaborative problem-solving tasks among female pairs. Through an exploration of emotional contagion, the research seeks to unveil its underlying mechanisms and effects. Leveraging EEG-based hyperscanning technology, the study introduces an innovative approach known as functional Graph Contrastive Learning (fGCL), which extracts subject-invariant representations of neural activity patterns. These representations are further subjected to analysis using the Dynamic Graph Classification (DGC) model, aimed at dissecting the process of emotional contagion. By scrutinizing brain synchronization and connectivity, the study reveals the intricate interplay between emotional contagion and cognitive functioning. The results underscore the substantial role of emotional contagion in shaping the trajec
    
[^48]: LaGR-SEQ: 语言引导的强化学习与高效查询

    LaGR-SEQ: Language-Guided Reinforcement Learning with Sample-Efficient Querying. (arXiv:2308.13542v1 [cs.AI])

    [http://arxiv.org/abs/2308.13542](http://arxiv.org/abs/2308.13542)

    这个论文介绍了LaGR（语言引导的强化学习），它利用大型语言模型（LLMs）的预测能力，提出解决部分完成任务的解决方案，以引导强化学习代理的训练。

    

    最近，大型语言模型（LLMs）展示出了他们通过文本提供上下文感知的印象深刻能力。这种能力可以潜在地用于在序列决策任务中预测可能的解决方案，这些任务与模式完成有关。例如，通过观察部分堆叠的立方体，LLMs可以通过推断观察到的模式（如立方体的大小、颜色或其他属性）来预测剩余立方体应该堆叠的正确顺序。在这项工作中，我们介绍了LaGR（语言引导的强化学习），它利用LLMs的这种预测能力，提出由主强化学习（RL）代理部分完成的任务的解决方案，随后引导后者的训练。然而，由于RL训练通常不具备高效样本利用率，采用这种方法将固有地意味着需要反复查询LLMs来获取解决方案；这个过程可能是昂贵的和不可行的。

    Large language models (LLMs) have recently demonstrated their impressive ability to provide context-aware responses via text. This ability could potentially be used to predict plausible solutions in sequential decision making tasks pertaining to pattern completion. For example, by observing a partial stack of cubes, LLMs can predict the correct sequence in which the remaining cubes should be stacked by extrapolating the observed patterns (e.g., cube sizes, colors or other attributes) in the partial stack. In this work, we introduce LaGR (Language-Guided Reinforcement learning), which uses this predictive ability of LLMs to propose solutions to tasks that have been partially completed by a primary reinforcement learning (RL) agent, in order to subsequently guide the latter's training. However, as RL training is generally not sample-efficient, deploying this approach would inherently imply that the LLM be repeatedly queried for solutions; a process that can be expensive and infeasible. T
    
[^49]: 一个概念游戏特征生成与推荐系统的初步研究

    A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System. (arXiv:2308.13538v1 [cs.IR])

    [http://arxiv.org/abs/2308.13538](http://arxiv.org/abs/2308.13538)

    本研究介绍了一个用于生成游戏特征建议的系统，通过使用文本提示，提取主题相似的游戏特征并生成新特征。经过用户研究比较，该系统的生成模型在某些游戏中的表现超过了人工建议。该系统是一个与用户在概念层面上进行协作的游戏设计助手工具的一部分。

    

    本文介绍了一个基于文本提示生成游戏特征建议的系统。该系统通过使用一个小型的GLoVe模型的词嵌入来提取主题相似的游戏中的特征和实体，并将其通过一个生成模型传递，用于生成用户提示的新特征。我们进行了一项短期用户研究，比较了来自一个经过微调的GPT-2模型、使用ConceptNet的模型以及人工编写的游戏特征生成的特征。虽然人工建议获得了绝大多数的投票，但在某些游戏中，GPT-2模型的表现超过了人工建议。该系统是一个更大的游戏设计助手工具的一部分，能够在概念层面上与用户进行协作。

    This paper introduces a system used to generate game feature suggestions based on a text prompt. Trained on the game descriptions of almost 60k games, it uses the word embeddings of a small GLoVe model to extract features and entities found in thematically similar games which are then passed through a generator model to generate new features for a user's prompt. We perform a short user study comparing the features generated from a fine-tuned GPT-2 model, a model using the ConceptNet, and human-authored game features. Although human suggestions won the overall majority of votes, the GPT-2 model outperformed the human suggestions in certain games. This system is part of a larger game design assistant tool that is able to collaborate with users at a conceptual level.
    
[^50]: 建立对话型AI中的信任：使用LLMs和知识图谱构建可解释的、隐私感知的系统的综述和解决方案架构

    Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph. (arXiv:2308.13534v1 [cs.CL])

    [http://arxiv.org/abs/2308.13534](http://arxiv.org/abs/2308.13534)

    本论文提出了一种综述和解决方案架构，用于构建可解释的、隐私感知的对话型AI系统。首先介绍了LLM模型的综合工具LLMXplorer，并阐明了其对社会、伦理和监管等方面的影响。然后提出了将知识图谱的结构动态与LLM的语言能力无缝集成的架构。通过使用真实世界的AI新闻数据进行验证，该架构成功地融合了语言的复杂性与事实的严谨性，并增强了数据安全性。

    

    对话型AI系统已成为各个领域实现类似于人类交互的关键驱动因素。然而，语言细微差别和事实准确性之间的平衡一直难以把握。在本文中，我们首先介绍了LLMXplorer，这是一个全面的工具，详细审视了150多个大型语言模型（LLMs），阐明了它们从社会、伦理到监管的各种影响，以及它们在各行各业的适用性。在此基础上，我们提出了一种新颖的功能架构，将知识图谱的结构动态与LLMs的语言能力无缝集成。通过使用真实世界的AI新闻数据进行验证，我们的架构巧妙地融合了语言的复杂性与事实的严谨性，并通过基于角色的访问控制进一步加强了数据安全性。本研究为对话型AI发展的变化景观提供了深入见解，强调了高效、透明的系统的必要性。

    Conversational AI systems have emerged as key enablers of human-like interactions across diverse sectors. Nevertheless, the balance between linguistic nuance and factual accuracy has proven elusive. In this paper, we first introduce LLMXplorer, a comprehensive tool that provides an in-depth review of over 150 Large Language Models (LLMs), elucidating their myriad implications ranging from social and ethical to regulatory, as well as their applicability across industries. Building on this foundation, we propose a novel functional architecture that seamlessly integrates the structured dynamics of Knowledge Graphs with the linguistic capabilities of LLMs. Validated using real-world AI news data, our architecture adeptly blends linguistic sophistication with factual rigour and further strengthens data security through Role-Based Access Control. This research provides insights into the evolving landscape of conversational AI, emphasizing the imperative for systems that are efficient, transp
    
[^51]: CDAN: 用于低光图像增强的卷积稠密注意力引导网络

    CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement. (arXiv:2308.12902v1 [cs.CV])

    [http://arxiv.org/abs/2308.12902](http://arxiv.org/abs/2308.12902)

    本研究提出了一种名为CDAN的卷积稠密注意力引导网络，用于低光图像增强。该网络结合了自编码器架构、卷积和稠密块、注意力机制和跳跃连接，通过专门的后处理阶段进一步改善色彩平衡和对比度。与现有方法相比，在低光图像增强方面取得了显著的进展，展示了在各种具有挑战性的场景中的稳健性。

    

    低光图像以不足的照明为特征，面临清晰度减弱、颜色暗淡和细节减少的挑战。低光图像增强是计算机视觉中的一个重要任务，旨在通过改善亮度、对比度和整体感知质量来纠正这些问题，从而促进准确的分析和解释。本文介绍了一种新颖的解决方案：卷积稠密注意力引导网络（CDAN），用于增强低光图像。CDAN将自编码器架构与卷积和稠密块相结合，配合注意力机制和跳跃连接。该架构确保了有效的信息传递和特征学习。此外，专门的后处理阶段可以进一步改善色彩平衡和对比度。与低光图像增强领域的最新成果相比，我们的方法取得了显著的进展，并展示了在各种具有挑战性的场景中的稳健性。

    Low-light images, characterized by inadequate illumination, pose challenges of diminished clarity, muted colors, and reduced details. Low-light image enhancement, an essential task in computer vision, aims to rectify these issues by improving brightness, contrast, and overall perceptual quality, thereby facilitating accurate analysis and interpretation. This paper introduces the Convolutional Dense Attention-guided Network (CDAN), a novel solution for enhancing low-light images. CDAN integrates an autoencoder-based architecture with convolutional and dense blocks, complemented by an attention mechanism and skip connections. This architecture ensures efficient information propagation and feature learning. Furthermore, a dedicated post-processing phase refines color balance and contrast. Our approach demonstrates notable progress compared to state-of-the-art results in low-light image enhancement, showcasing its robustness across a wide range of challenging scenarios. Our model performs 
    
[^52]: 大型语言模型的投票：用于罕见病识别的提示

    Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v1 [cs.CL])

    [http://arxiv.org/abs/2308.12890](http://arxiv.org/abs/2308.12890)

    本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。

    

    生成式大型语言模型(LLMs)的出现强调了准确和高效的提示方法的需求。LLMs经常应用于少样本学习(FSL)的情境中，这里任务只使用很少的训练数据执行。FSL在许多人工智能(AI)子领域中变得流行，包括用于健康的AI。罕见病影响人口的一小部分，在数据可用性受限的情况下 inherently 需要FSL技术，尽管人工数据收集和标注费时费力。在本文中，我们提出了模型投票提示(MVP)，这是一种用于改善FSL环境中LLM查询性能的灵活提示方法。MVP通过提示多个LLMs执行相同的任务，然后对生成的输出进行多数投票来实现。该方法在单次罕见病识别和分类任务中相对于任何单个模型在集成模型中实现了改进的结果。我们还发布了一个新颖的罕见病数据集用于FSL。

    The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FS
    
[^53]: CGMI: 可配置的通用多智能体交互框架。

    CGMI: Configurable General Multi-Agent Interaction Framework. (arXiv:2308.12503v1 [cs.AI])

    [http://arxiv.org/abs/2308.12503](http://arxiv.org/abs/2308.12503)

    本研究提出了一个名为CGMI的框架，旨在模拟真实世界场景中的人际交往。该框架采用了树状结构方法来管理智能体的个性，并设计了一个基于ACT*模型的认知架构。通过使用CGMI框架，我们成功模拟了教师和学生之间的课堂互动。

    

    由于大型语言模型（LLM）的强大能力，基于LLM的智能体已经展现出解决特定领域任务和模仿人类行为的潜力。然而，由于其有限的领域专业知识以及缺乏有效的认知架构，这些智能体生成的内容仍然相对表面。为解决这个问题，我们提出了一个可配置的通用多智能体交互（CGMI）框架，旨在模拟真实世界场景中的人际交往。具体而言，我们提出了一种树状结构的方法论，用于智能体的个性分配、检测和维护。此外，我们设计了一个基于ACT*模型的技能库的认知架构，其中包含记忆、反思和规划模块。我们还整合了通用智能体来增强虚拟环境的真实感。利用CGMI框架，我们模拟了多个教师和学生之间的课堂互动。

    Benefiting from the powerful capabilities of large language models (LLMs), agents based on LLMs have shown the potential to address domain-specific tasks and emulate human behaviors. However, the content generated by these agents remains somewhat superficial, owing to their limited domain expertise and the absence of an effective cognitive architecture. To address this, we present the Configurable General Multi-Agent Interaction (CGMI) framework, designed to replicate human interactions in real-world scenarios. Specifically, we propose a tree-structured methodology for the assignment, detection, and maintenance of agent personality. Additionally, we designed a cognitive architecture equipped with a skill library based on the ACT* model, which contains memory, reflection, and planning modules. We have also integrated general agents to augment the virtual environment's realism. Using the CGMI framework, we simulated numerous classroom interactions between teacher and students. The experi
    
[^54]: 一种基于概率波动的生成模型成员推断攻击方法

    A Probabilistic Fluctuation based Membership Inference Attack for Generative Models. (arXiv:2308.12143v1 [cs.LG])

    [http://arxiv.org/abs/2308.12143](http://arxiv.org/abs/2308.12143)

    本研究针对生成模型提出了一种概率波动评估成员推断攻击方法(PFAMI)，通过检测概率分布的波动性来推断模型中是否存在某条训练记录的成员身份。

    

    成员推断攻击(MIA)通过查询模型来识别机器学习模型的训练集中是否存在某条记录。对经典分类模型的MIA已有很多研究，最近的工作开始探索如何将MIA应用到生成模型上。我们的研究表明，现有的面向生成模型的MIA主要依赖于目标模型的过拟合现象。然而，过拟合可以通过采用各种正则化技术来避免，而现有的MIA在实践中表现不佳。与过拟合不同，记忆对于深度学习模型实现最佳性能是至关重要的，使其成为一种更为普遍的现象。生成模型中的记忆导致生成记录的概率分布呈现出增长的趋势。因此，我们提出了一种基于概率波动的成员推断攻击方法(PFAMI)，它是一种黑盒MIA，通过检测概率波动来推断成员身份。

    Membership Inference Attack (MIA) identifies whether a record exists in a machine learning model's training set by querying the model. MIAs on the classic classification models have been well-studied, and recent works have started to explore how to transplant MIA onto generative models. Our investigation indicates that existing MIAs designed for generative models mainly depend on the overfitting in target models. However, overfitting can be avoided by employing various regularization techniques, whereas existing MIAs demonstrate poor performance in practice. Unlike overfitting, memorization is essential for deep learning models to attain optimal performance, making it a more prevalent phenomenon. Memorization in generative models leads to an increasing trend in the probability distribution of generating records around the member record. Therefore, we propose a Probabilistic Fluctuation Assessing Membership Inference Attack (PFAMI), a black-box MIA that infers memberships by detecting t
    
[^55]: 走出笼子：随机鹦鹉在网络安全环境中的胜利

    Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments. (arXiv:2308.12086v1 [cs.CR])

    [http://arxiv.org/abs/2308.12086](http://arxiv.org/abs/2308.12086)

    本文将预训练的大型语言模型（LLMs）应用于网络安全环境，作为攻击代理人进行顺序决策。该设计表明LLMs在高效应对复杂决策方面具有潜力，并且在大多数场景中表现出与经过训练的最先进代理相似或更好的性能。

    

    大型语言模型（LLMs）在涉及文本生成、摘要和各种自然语言处理任务的不同领域中广受欢迎。尽管存在固有的局限性，基于LLM的设计在规划和导航开放世界场景方面显示出有希望的能力。本文将预训练的LLMs用作网络安全环境中的代理人的新应用，重点关注它们在顺序决策过程中的效用。我们提出了一种方法，利用预训练的LLMs作为两个强化学习环境中的攻击代理。在大多数场景和配置中，我们提出的代理在表现上与经过数千次训练的最先进代理相似或更好。此外，最佳LLM代理在没有任何额外训练过程的情况下表现与环境的人类测试者类似。这种设计突显了LLMs在高效应对复杂决策方面的潜力。

    Large Language Models (LLMs) have gained widespread popularity across diverse domains involving text generation, summarization, and various natural language processing tasks. Despite their inherent limitations, LLM-based designs have shown promising capabilities in planning and navigating open-world scenarios. This paper introduces a novel application of pre-trained LLMs as agents within cybersecurity network environments, focusing on their utility for sequential decision-making processes.  We present an approach wherein pre-trained LLMs are leveraged as attacking agents in two reinforcement learning environments. Our proposed agents demonstrate similar or better performance against state-of-the-art agents trained for thousands of episodes in most scenarios and configurations. In addition, the best LLM agents perform similarly to human testers of the environment without any additional training process. This design highlights the potential of LLMs to efficiently address complex decision
    
[^56]: 从视频中生成姿势调节的虚拟角色

    Pose Modulated Avatars from Video. (arXiv:2308.11951v1 [cs.CV])

    [http://arxiv.org/abs/2308.11951](http://arxiv.org/abs/2308.11951)

    本文提出了一种基于神经辐射场和稀疏的摄像机组来重建动态人体运动和形状的方法。与现有的角色模型不同，我们的方法在频域中是自适应和显式的，并通过建模身体部位之间的相关性来解决衣物和皮肤的变形建模挑战。实验结果表明，我们的网络在性能上优于现有方法。

    

    使用由骨架驱动的神经辐射场（NeRF）和稀疏的摄像机组可以重建动态人体运动和形状。然而，模拟衣物和皮肤的变形与骨架姿势之间的关系仍然是一个挑战。与隐式学习或依赖代理表面的现有角色模型不同，我们的方法源于观察到不同的姿势需要不同的频率分配。忽视这种区别会在平滑区域产生噪点伪影，或使锐利区域的细粒度纹理和形状细节模糊。我们开发了一个在频域中是自适应和显式的双分支神经网络。第一个分支是一个图神经网络，本地建模身体部位之间的相关性，以骨架姿势作为输入。第二个分支将这些相关特征组合到一组全局频率中，然后调节特征编码。我们的实验证明，我们的网络优于现有的状态。

    It is now possible to reconstruct dynamic human motion and shape from a sparse set of cameras using Neural Radiance Fields (NeRF) driven by an underlying skeleton. However, a challenge remains to model the deformation of cloth and skin in relation to skeleton pose. Unlike existing avatar models that are learned implicitly or rely on a proxy surface, our approach is motivated by the observation that different poses necessitate unique frequency assignments. Neglecting this distinction yields noisy artifacts in smooth areas or blurs fine-grained texture and shape details in sharp regions. We develop a two-branch neural network that is adaptive and explicit in the frequency domain. The first branch is a graph neural network that models correlations among body parts locally, taking skeleton pose as input. The second branch combines these correlation features to a set of global frequencies and then modulates the feature encoding. Our experiments demonstrate that our network outperforms state
    
[^57]: 线性语言模型辅助分析表格数据的方法研究

    Bridging the Gap: Deciphering Tabular Data Using Large Language Model. (arXiv:2308.11891v1 [cs.CL])

    [http://arxiv.org/abs/2308.11891](http://arxiv.org/abs/2308.11891)

    本研究旨在提升大型语言模型在理解表格数据上的能力，通过设计一个表格序列化模块和纠正机制来实现。实验结果表明，尽管相对于最先进技术仍有差距，但该方法在处理表格数据方面取得了一定的进展。

    

    在自然语言处理领域，对表格数据的理解一直是学术研究的重点。随着诸如ChatGPT之类的庞大语言模型的出现，研究人员开始探索如何利用这些模型来处理与表格相关的问题。我们的研究旨在探索提升大型语言模型在理解表格结构和内容上的能力，以便更好地回答相关问题。为此，我们设计了一个专门用于将表格序列化的模块，并在模型中引入了一个纠正机制来修正潜在的错误。实验结果显示，尽管我们的方法相对于最先进技术仍有差距。

    In the realm of natural language processing, the understanding of tabular data has perpetually stood as a focal point of scholarly inquiry. The emergence of expansive language models, exemplified by the likes of ChatGPT, has ushered in a wave of endeavors wherein researchers aim to harness these models for tasks related to table-based question answering. Central to our investigative pursuits is the elucidation of methodologies that amplify the aptitude of such large language models in discerning both the structural intricacies and inherent content of tables, ultimately facilitating their capacity to provide informed responses to pertinent queries. To this end, we have architected a distinctive module dedicated to the serialization of tables for seamless integration with expansive language models. Additionally, we've instituted a corrective mechanism within the model to rectify potential inaccuracies. Experimental results indicate that, although our proposed method trails the SOTA by ap
    
[^58]: ProAgent：利用大型语言模型构建主动合作的人工智能

    ProAgent: Building Proactive Cooperative AI with Large Language Models. (arXiv:2308.11339v1 [cs.AI])

    [http://arxiv.org/abs/2308.11339](http://arxiv.org/abs/2308.11339)

    ProAgent是一个利用大型语言模型构建的主动合作的AI框架，能够预测队友的决策并为自己制定增强计划，具有高度的模块化和可解释性。

    

    在AGI研究中，构建具有自适应行为的人工智能以进行人工智能和人类的合作成为一个关键关注点。目前，开发合作代理人的方法主要依赖于基于学习的方法，其中政策泛化严重依赖于与特定队友的过去互动。这些方法限制了代理人在面对新的队友时重新校准策略的能力。我们提出了ProAgent，这是一个新颖的框架，利用大型语言模型（LLMs）来创建一个具有预测队友未来决策能力和为自身制定增强计划能力的主动代理。ProAgent在合作推理方面表现出色，能够动态调整行为以增强与队友的协作努力。此外，ProAgent框架具有高度的模块化和可解释性，便于无缝集成，以应对各种协调场景。

    Building AIs with adaptive behaviors in human-AI cooperation stands as a pivotal focus in AGI research. Current methods for developing cooperative agents predominantly rely on learning-based methods, where policy generalization heavily hinges on past interactions with specific teammates. These approaches constrain the agent's capacity to recalibrate its strategy when confronted with novel teammates. We propose \textbf{ProAgent}, a novel framework that harnesses large language models (LLMs) to fashion a \textit{pro}active \textit{agent} empowered with the ability to anticipate teammates' forthcoming decisions and formulate enhanced plans for itself. ProAgent excels at cooperative reasoning with the capacity to dynamically adapt its behavior to enhance collaborative efforts with teammates. Moreover, the ProAgent framework exhibits a high degree of modularity and interpretability, facilitating seamless integration to address a wide array of coordination scenarios. Experimental evaluations
    
[^59]: 通过行动和语言提升智能体的沟通和学习能力

    Enhancing Agent Communication and Learning through Action and Language. (arXiv:2308.10842v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.10842](http://arxiv.org/abs/2308.10842)

    通过行动和语言相结合的方式，我们引入了一种新型智能体，其能够同时作为教师和学习者，通过行动演示和语言指令增强了沟通效率，并探索了结合行动和语言沟通模式对学习结果的积极影响。

    

    我们引入了一种新型的GC智能体类别，能够同时充当教师和学习者的角色。借助基于行动的演示和基于语言的指令，这些智能体增强了沟通效率。我们研究了在人类沟通和目标实现中的重要元素——教育学和实用主义的融入，提升了智能体的教学和学习能力。此外，我们探讨了结合行动和语言沟通模式对学习结果的影响，强调了多模式方法的优势。

    We introduce a novel category of GC-agents capable of functioning as both teachers and learners. Leveraging action-based demonstrations and language-based instructions, these agents enhance communication efficiency. We investigate the incorporation of pedagogy and pragmatism, essential elements in human communication and goal achievement, enhancing the agents' teaching and learning capabilities. Furthermore, we explore the impact of combining communication modes (action and language) on learning outcomes, highlighting the benefits of a multi-modal approach.
    
[^60]: 大规模语言模型在软件工程中的应用：系统性文献综述

    Large Language Models for Software Engineering: A Systematic Literature Review. (arXiv:2308.10620v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2308.10620](http://arxiv.org/abs/2308.10620)

    通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。

    

    大规模语言模型（LLM）在包括软件工程在内的多个领域产生了显著影响。许多最近的文献探讨了LLM在各种软件工程任务和应用中的应用。然而，对LLM在软件工程中的应用、影响和可能的限制的全面理解仍处于初级阶段。为了弥补这一差距，我们对LLM与软件工程的交叉领域进行了系统性文献综述，特别关注LLM在软件工程中如何被利用来优化过程和结果的理解。我们收集和分析了2017年至2023年的229篇研究论文，以回答四个关键研究问题（RQs）。在RQ1中，我们对在软件工程任务中使用的不同LLM进行分类和比较分析，描绘其独特的特点和用途。在RQ2中，我们分析数据收集、预处理和应用中使用的方法，强调了强大、精心策划的数据集对于成功利用LLM非常重要。

    Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks and applications. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review on the intersection of LLMs and SE, with a particular focus on understanding how LLMs can be exploited in SE to optimize processes and outcomes. We collect and analyze a total of 229 research papers from 2017 to 2023 to answer four key research questions (RQs). In RQ1, we categorize and provide a comparative analysis of different LLMs that have been employed in SE tasks, characterising their distinctive features and uses. In RQ2, we analyse the methods used in data collection, preprocessing, and application highlighting the role of robust, well-curated datasets for successful LLM for S
    
[^61]: 对大型语言模型代码生成的鲁棒性和可靠性的研究

    A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10335](http://arxiv.org/abs/2308.10335)

    本研究针对大型语言模型生成的代码的可靠性和鲁棒性进行了研究，发现在真实的软件开发中可执行的代码并不能保证可靠和鲁棒，滥用API可能导致严重问题。这对初级开发者来说尤其危险，因为他们很难察觉到代码中的API滥用问题。

    

    最近，大型语言模型(LLMs)在理解自然语言和生成编程代码方面显示出了非凡能力。当遇到编码问题时，软件工程师常常会咨询LLMs。尽管已经做出了一些努力来避免语法错误并使代码与预期的语义对齐，但LLMs生成的代码的可靠性和鲁棒性尚未被深入研究。在真实的软件开发环境中，可执行的代码并不等同于可靠和鲁棒的代码。在生成的代码中滥用API可能会导致严重的问题，如资源泄漏、程序崩溃。更糟糕的是，LLM代码生成服务的用户实际上是最容易受到这些看似正确的代码影响的开发者——他们通常是不熟悉LLMs为他们生成代码的API的初级开发者。因此，他们很难察觉到API的滥用。

    Recently, the large language models (LLMs) have shown extraordinary ability in understanding natural language and generating programming code. It has been a common practice of software engineers to consult LLMs when encountering coding questions. Although efforts have been made to avoid syntax errors and align the code with the intended semantics, the reliability and robustness of the code generationfrom LLMs have not yet been thoroughly studied. The executable code is not equivalent to the reliable and robust code, especially in the context of real-world software development. The misuse of APIs in the generated code could lead to severe problem, such as resource leaks, program crashes. To make things worse, the users of LLM code generation services are actually the developers that are most vulnerable to these code that seems right -- They are always novice developers that are not familiar with the APIs that LLMs generate code for them. Therefore, they could hardly tell the misuse in t
    
[^62]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^63]: 问题分类的集成方法：融合Electra Transformer、GloVe和LSTM

    An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM. (arXiv:2308.06828v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.06828](http://arxiv.org/abs/2308.06828)

    本研究提出了一种集成Electra Transformer、GloVe和LSTM模型的创新问题分类方法，通过在TREC数据集上进行严格测试，证明了融合不同技术可以获得更优越的结果。

    

    自然语言处理（NLP）已经成为理解和生成人类语言的关键技术，它在机器翻译、情感分析等任务中扮演着重要角色，尤其是在问题分类方面。作为自然语言处理的子领域，问题分类专注于确定所需信息的类型，这是问题回答系统等下游应用的基本步骤。本研究提出了一种创新的问题分类集成方法，将Electra、GloVe和LSTM模型的优势相结合。该模型在著名的TREC数据集上进行了严格测试，展示了如何整合这些不同技术可以得到更优越的结果。Electra提供了基于transformer的复杂语言理解能力，GloVe提供了全局向量表示以捕捉词级语义，LSTM则贡献了序列学习能力以建模长期依赖关系。

    Natural Language Processing (NLP) has emerged as a crucial technology for understanding and generating human language, playing an essential role in tasks such as machine translation, sentiment analysis, and more pertinently, question classification. As a subfield within NLP, question classification focuses on determining the type of information being sought, a fundamental step for downstream applications like question answering systems. This study presents an innovative ensemble approach for question classification, combining the strengths of Electra, GloVe, and LSTM models. Rigorously tested on the well-regarded TREC dataset, the model demonstrates how the integration of these disparate technologies can lead to superior results. Electra brings in its transformer-based capabilities for complex language understanding, GloVe offers global vector representations for capturing word-level semantics, and LSTM contributes its sequence learning abilities to model long-term dependencies. By fus
    
[^64]: CLE扩散：可控性光增强扩散模型

    CLE Diffusion: Controllable Light Enhancement Diffusion Model. (arXiv:2308.06725v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.06725](http://arxiv.org/abs/2308.06725)

    CLE扩散是一种可控的光增强扩散模型，通过条件扩散和光照嵌入，让用户可以控制亮度水平，并结合任意分割模型实现用户友好的区域可控性。实验证明CLE Diffusion在各项指标上具有竞争力。

    

    随着视觉创作和编辑的快速发展，低光增强变得越来越重要。然而，现有的大多数增强算法都设计为均匀增加图像的亮度到预定义的程度，限制了用户体验。为了解决这个问题，我们提出了一种新颖的扩散框架——可控光增强扩散模型(CLE Diffusion)，以提供丰富的可控性给用户。通过条件扩散模型构建，我们引入了光照嵌入，让用户可以控制所需的亮度水平。此外，我们还结合“任意分割模型”(Segment-Anything Model, SAM)，实现了用户友好的区域可控性，用户可以点击对象来指定他们希望增强的区域。广泛的实验证明，CLE Diffusion在定量指标、定性结果和多样化可控性方面具有竞争力。

    Low light enhancement has gained increasing importance with the rapid development of visual creation and editing. However, most existing enhancement algorithms are designed to homogeneously increase the brightness of images to a pre-defined extent, limiting the user experience. To address this issue, we propose Controllable Light Enhancement Diffusion Model, dubbed CLE Diffusion, a novel diffusion framework to provide users with rich controllability. Built with a conditional diffusion model, we introduce an illumination embedding to let users control their desired brightness level. Additionally, we incorporate the Segment-Anything Model (SAM) to enable user-friendly region controllability, where users can click on objects to specify the regions they wish to enhance. Extensive experiments demonstrate that CLE Diffusion achieves competitive performance regarding quantitative metrics, qualitative results, and versatile controllability. Project page: https://yuyangyin.github.io/CLEDiffusio
    
[^65]: 揭示潜在模式：研究数据集的相似性、性能和泛化能力

    Revealing the Underlying Patterns: Investigating Dataset Similarity, Performance, and Generalization. (arXiv:2308.03580v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.03580](http://arxiv.org/abs/2308.03580)

    该研究探索了监督深度学习模型的泛化能力和性能，并提出了一种结合距离度量和模型性能的方法，从候选架构中选择适当的模型/架构。结果显示，通过添加少量未见过的图像，可以改善模型的泛化能力。这种方法可以降低训练和标注成本，并在动态环境中提供模型在未见数据上的性能估计。

    

    监督深度学习模型需要大量标记数据才能在特定任务上取得可接受的性能。然而，当在未见过的数据上进行测试时，模型可能表现不佳。因此，需要用额外和多样化的标记数据来训练模型以提高泛化能力。本研究旨在理解模型、它们的性能和泛化能力。我们建立了图像-图像、数据集-数据集和图像-数据集距离，以洞察模型的行为。我们提出的距离度量方法结合模型性能可以帮助从候选架构中选择一个合适的模型/架构。我们发现，只需将少量未见过的图像（如1、3或7个）添加到训练集中即可改善这些模型的泛化能力。我们提出的方法可以在动态环境中减少训练和标注成本，并提供模型在未见数据上的性能估计。

    Supervised deep learning models require significant amount of labelled data to achieve an acceptable performance on a specific task. However, when tested on unseen data, the models may not perform well. Therefore, the models need to be trained with additional and varying labelled data to improve the generalization. In this work, our goal is to understand the models, their performance and generalization. We establish image-image, dataset-dataset, and image-dataset distances to gain insights into the model's behavior. Our proposed distance metric when combined with model performance can help in selecting an appropriate model/architecture from a pool of candidate architectures. We have shown that the generalization of these models can be improved by only adding a small number of unseen images (say 1, 3 or 7) into the training set. Our proposed approach reduces training and annotation costs while providing an estimate of model performance on unseen data in dynamic environments.
    
[^66]: 外部推理：朝着多种大型语言模型可互换辅助与人类反馈的方向前进

    External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback. (arXiv:2307.12057v1 [cs.CL])

    [http://arxiv.org/abs/2307.12057](http://arxiv.org/abs/2307.12057)

    本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。

    

    记忆被认为是使海马体和脑神经元内保持视觉和语言信息、随后用于解决通过学习一生中遇到的现实挑战的关键人类能力。通过应用已获得的知识解决复杂的人工智能任务是实现人工通用智能的一大进展。然而，尽管像GPT-3.5和GPT-4这样的大型语言模型在语言理解、生成、交互和推理方面显示了卓越的能力，但由于上下文长度的限制，它们无法处理广泛、不断演变的知识库。本文提出通过从外部存储库中选择性地集成知识来增强LLMs，并介绍了一种外部推理的新方法，例子是ChatPDF。

    Memory is identified as a crucial human faculty that allows for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise through a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4 , which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to
    
[^67]: 模型与锡人之间——使用大语言模型研究AI对齐中的委托-代理问题的行为经济学研究

    Of Models and Tin Men -- a behavioural economics study of principal-agent problems in AI alignment using large-language models. (arXiv:2307.11137v1 [cs.AI])

    [http://arxiv.org/abs/2307.11137](http://arxiv.org/abs/2307.11137)

    本研究基于行为经济学角度，对使用大语言模型进行AI对齐中的委托-代理问题进行研究，发现现实世界中的AI安全问题不仅涉及设计者与代理之间的冲突，还涉及到多个代理之间的信息不对称与效用函数之间的错位。

    

    AI对齐通常被描述为一个设计者与人工智能代理之间的相互作用，设计者试图确保代理的行为与其目的一致，并且风险仅仅是由于设计者意图中的效用函数与代理的内部效用函数之间的意外错位而导致的冲突。然而，随着使用大语言模型（LLM）实例化的代理的出现，这种描述不能捕捉到AI安全的核心方面，因为现实世界中设计者与代理之间并没有一对一的对应关系，而且许多代理，无论是人工智能还是人类，都具有多样的价值观。因此，AI安全具有经济方面的问题，委托-代理问题可能会出现。

    AI Alignment is often presented as an interaction between a single designer and an artificial agent in which the designer attempts to ensure the agent's behavior is consistent with its purpose, and risks arise solely because of conflicts caused by inadvertent misalignment between the utility function intended by the designer and the resulting internal utility function of the agent. With the advent of agents instantiated with large-language models (LLMs), which are typically pre-trained, we argue this does not capture the essential aspects of AI safety because in the real world there is not a one-to-one correspondence between designer and agent, and the many agents, both artificial and human, have heterogeneous values. Therefore, there is an economic aspect to AI safety and the principal-agent problem is likely to arise. In a principal-agent problem conflict arises because of information asymmetry together with inherent misalignment between the utility of the agent and its principal, an
    
[^68]: 什么是可解释模型：一项范围审查

    What's meant by explainable model: A Scoping Review. (arXiv:2307.09673v1 [cs.AI])

    [http://arxiv.org/abs/2307.09673](http://arxiv.org/abs/2307.09673)

    这项研究通过范围审查方法调查了应用人工智能模型并采用事后解释方法的论文，探讨了可解释模型这一术语的含义。

    

    我们经常在描述基于人工智能（AI）的应用的论文标题中看到可解释这个术语。然而，可解释人工智能（XAI）的文献表明，XAI中的解释是特定应用和领域的，因此在用于解释特定应用问题的模型时需要进行评估。此外，文献揭示了事后方法，特别是特征归因方法的性能存在很大差异，暗示它们并不能成为AI可解释性的解决方案。因此，在使用XAI方法时，应在特定应用中评估其信息输出的质量和适用性。基于这些原因，我们使用了范围审查方法来研究应用AI模型和采用事后解释方法的论文，同时将这些模型称为可解释。

    We often see the term explainable in the titles of papers that describe applications based on artificial intelligence (AI). However, the literature in explainable artificial intelligence (XAI) indicates that explanations in XAI are application- and domain-specific, hence requiring evaluation whenever they are employed to explain a model that makes decisions for a specific application problem. Additionally, the literature reveals that the performance of post-hoc methods, particularly feature attribution methods, varies substantially hinting that they do not represent a solution to AI explainability. Therefore, when using XAI methods, the quality and suitability of their information outputs should be evaluated within the specific application. For these reasons, we used a scoping review methodology to investigate papers that apply AI models and adopt methods to generate post-hoc explanations while referring to said models as explainable. This paper investigates whether the term explainabl
    
[^69]: 手写和打印文本分割：一个签名案例研究

    Handwritten and Printed Text Segmentation: A Signature Case Study. (arXiv:2307.07887v1 [cs.CV])

    [http://arxiv.org/abs/2307.07887](http://arxiv.org/abs/2307.07887)

    本研究旨在解决手写和打印文本分割的挑战，并提出了一种新的方法来完整地恢复不同类别的文本，特别是在重叠部分提高分割性能。同时，还引入了一个新的数据集SignaTR6K，用于支持该任务。

    

    在分析扫描文档时，手写文本可能覆盖打印文本。这在文档的光学字符识别（OCR）和数字化过程中造成困难，并且进而影响到下游的自然语言处理（NLP）任务。之前的研究要么仅关注手写文本的二分类，要么进行三类文档的分割，即手写、打印和背景像素的识别。这导致手写和打印重叠的像素只被分配到一个类别中，因此在另一个类别中不被考虑。因此，在这项研究中，我们开发了新的方法来解决手写和打印文本分割的挑战，目标是完整地恢复不同类别的文本，特别是提高重叠部分的分割性能。为了促进这项任务，我们介绍了一个新的数据集SignaTR6K，该数据集收集自真实的法律文件。

    While analyzing scanned documents, handwritten text can overlay printed text. This causes difficulties during the optical character recognition (OCR) and digitization process of documents, and subsequently, hurts downstream NLP tasks. Prior research either focuses only on the binary classification of handwritten text, or performs a three-class segmentation of the document, i.e., recognition of handwritten, printed, and background pixels. This results in the assignment of the handwritten and printed overlapping pixels to only one of the classes, and thus, they are not accounted for in the other class. Thus, in this research, we develop novel approaches for addressing the challenges of handwritten and printed text segmentation with the goal of recovering text in different classes in whole, especially improving the segmentation performance on the overlapping parts. As such, to facilitate with this task, we introduce a new dataset, SignaTR6K, collected from real legal documents, as well as
    
[^70]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^71]: 关于形式特征归因及其近似方法

    On Formal Feature Attribution and Its Approximation. (arXiv:2307.03380v1 [cs.AI])

    [http://arxiv.org/abs/2307.03380](http://arxiv.org/abs/2307.03380)

    这篇论文研究了解释性人工智能（XAI）中的形式特征归因方法及其近似方法。现有的特征选择和归因方法存在一些问题，而形式化的XAI方法虽然是一个有希望的解决方案，但仍存在一些限制。

    

    近年来，人工智能（AI）算法和机器学习（ML）模型得到了广泛应用。尽管取得了巨大成功，但ML模型脆弱性，公平性以及解释性的缺乏等重要问题需要积极发展可解释的人工智能（XAI）和形式化的ML模型验证。XAI的两个主要研究方向包括特征选择方法（例如，Anchors）和特征归因技术（例如，LIME和SHAP）。尽管有希望，但大多数现有的特征选择和归因方法都容易出现一系列关键问题，包括解释不正确和超出分布采样。近期一种形式化的XAI方法（FXAI）虽然作为以上方法的替代品并避免了这些问题，但仍存在一些限制。例如，除了可扩展性限制外，这种形式化方法无法解决特征归因问题。

    Recent years have witnessed the widespread use of artificial intelligence (AI) algorithms and machine learning (ML) models. Despite their tremendous success, a number of vital problems like ML model brittleness, their fairness, and the lack of interpretability warrant the need for the active developments in explainable artificial intelligence (XAI) and formal ML model verification. The two major lines of work in XAI include feature selection methods, e.g. Anchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their promise, most of the existing feature selection and attribution approaches are susceptible to a range of critical issues, including explanation unsoundness and out-of-distribution sampling. A recent formal approach to XAI (FXAI) although serving as an alternative to the above and free of these issues suffers from a few other limitations. For instance and besides the scalability limitation, the formal approach is unable to tackle the feature attribution prob
    
[^72]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^73]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^74]: 使用Transformer模型预测表情符号

    Emoji Prediction using Transformer Models. (arXiv:2307.02054v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02054](http://arxiv.org/abs/2307.02054)

    使用基于Transformer的方法，在大型语料库上微调BERT模型以预测给定文本的表情符号。实验结果显示，该方法在预测准确率上优于其他最先进的模型，具有潜在的自然语言处理和社交媒体营销应用价值。

    

    近年来，社交媒体中使用表情符号的频率大幅增加，使得它们成为了理解在线沟通的重要元素。然而，由于其含糊的特性，预测给定文本中表情符号的含义是一项具有挑战性的任务。在本研究中，我们提出了一种基于Transformer的方法来使用BERT进行表情符号预测，BERT是一种广泛使用的预训练语言模型。我们在一个包含文本和表情符号的大型语料库上对BERT进行微调，以预测给定文本的最合适的表情符号。我们的实验结果表明，我们的方法在预测表情符号方面的准确率超过了75％，优于几种最先进的模型。该研究在自然语言处理、情感分析和社交媒体营销方面具有潜在的应用前景。

    In recent years, the use of emojis in social media has increased dramatically, making them an important element in understanding online communication. However, predicting the meaning of emojis in a given text is a challenging task due to their ambiguous nature. In this study, we propose a transformer-based approach for emoji prediction using BERT, a widely-used pre-trained language model. We fine-tuned BERT on a large corpus of text containing both text and emojis to predict the most appropriate emoji for a given text. Our experimental results demonstrate that our approach outperforms several state-of-the-art models in predicting emojis with an accuracy of over 75 percent. This work has potential applications in natural language processing, sentiment analysis, and social media marketing.
    
[^75]: Tensorformer: 高质量点云重建的归一化矩阵注意力变换器

    Tensorformer: Normalized Matrix Attention Transformer for High-quality Point Cloud Reconstruction. (arXiv:2306.15989v1 [cs.GR])

    [http://arxiv.org/abs/2306.15989](http://arxiv.org/abs/2306.15989)

    Tensorformer是一种归一化矩阵注意力变换器，用于高质量的点云重建。它通过矩阵注意力实现了逐点和逐通道的消息传递，提供了更好的局部几何建模能力，并在两个数据集上取得了最先进的结果。

    

    在计算机图形学界，从原始点云进行表面重建的研究已经进行了几十年，这在现今的建模和渲染应用中需求非常高。传统的解决方案，如Poisson表面重建，需要额外的点法线输入以产生合理的结果。现代基于变换器的方法可以在没有法线的情况下工作，但由于离散点的局部融合编码性能有限，结果较为粗糙。我们引入了一种新颖的归一化矩阵注意力变换器（Tensorformer）来进行高质量的重建。所提出的矩阵注意力允许同时进行逐点和逐通道的消息传递，而之前的向量注意力在不同通道之间丢失了相邻点的信息。它在特征学习中带来更多自由度，从而更好地建模局部几何结构。我们的方法在两个常用数据集ShapeNetCore和ABC上达到了最先进的水平，并且

    Surface reconstruction from raw point clouds has been studied for decades in the computer graphics community, which is highly demanded by modeling and rendering applications nowadays. Classic solutions, such as Poisson surface reconstruction, require point normals as extra input to perform reasonable results. Modern transformer-based methods can work without normals, while the results are less fine-grained due to limited encoding performance in local fusion from discrete points. We introduce a novel normalized matrix attention transformer (Tensorformer) to perform high-quality reconstruction. The proposed matrix attention allows for simultaneous point-wise and channel-wise message passing, while the previous vector attention loses neighbor point information across different channels. It brings more degree of freedom in feature learning and thus facilitates better modeling of local geometries. Our method achieves state-of-the-art on two commonly used datasets, ShapeNetCore and ABC, and 
    
[^76]: 具有全局状态预测的分散式多智能体强化学习

    Decentralized Multi-Agent Reinforcement Learning with Global State Prediction. (arXiv:2306.12926v1 [cs.RO])

    [http://arxiv.org/abs/2306.12926](http://arxiv.org/abs/2306.12926)

    本文研究了分散式多智能体强化学习中的一个关键挑战：如何在没有全局信息的情况下有效训练机器人。我们提出了一种基于状态预测的方法，在不需要显式通信的情况下使机器人能够协调行动，实现更快更好的学习效果和任务执行性能。

    

    深度强化学习（DRL）在控制单个机器人方面取得了显着的成功。然而，将DRL应用于机器人群体存在重大挑战。其中一个关键挑战是非静态性，即当两个或更多机器人同时更新个体或共享政策时，会进入一个相互依存的培训过程，并且不保证收敛。克服非静态性通常涉及使用其他智能体的全局信息来训练机器人，例如其他智能体的状态和/或行动。相比之下，本文探讨了如何消除全局信息的需求。由于缺乏其他信息体的全局知识，我们将问题描述为部分可观察的马尔可夫决策过程。在以集体运输为测试场景的情况下，我们研究了两种多智能体培训方法。在第一种方法中，机器人不交换信息，并且被训练依靠通过推（push）和拉（pull）物体进行隐式通信。在第二种方法中，机器人彼此共享状态预测，使他们能够在没有显式通信的情况下协调行动。我们的实验表明，共享预测可以使智能体更有效地学习，同时在需要更少与环境交互的情况下实现更好的任务执行性能。

    Deep reinforcement learning (DRL) has seen remarkable success in the control of single robots. However, applying DRL to robot swarms presents significant challenges. A critical challenge is non-stationarity, which occurs when two or more robots update individual or shared policies concurrently, thereby engaging in an interdependent training process with no guarantees of convergence. Circumventing non-stationarity typically involves training the robots with global information about other agents' states and/or actions. In contrast, in this paper we explore how to remove the need for global information. We pose our problem as a Partially Observable Markov Decision Process, due to the absence of global knowledge on other agents. Using collective transport as a testbed scenario, we study two approaches to multi-agent training. In the first, the robots exchange no messages, and are trained to rely on implicit communication through push-and-pull on the object to transport. In the second appro
    
[^77]: 大型语言模型被误导：使用Only Connect Wall数据集探索创造性问题解决和Einstellung效应。

    Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11167](http://arxiv.org/abs/2306.11167)

    这项研究探索了大型语言模型（LLMs）对创造性问题解决的能力，并发现大型语言模型容易被误导，出现固定效应和Einstellung范式。

    

    自从人工智能诞生以来，对人类仿真智能的追求一直是人工智能研究的持久话题。最新一代的大型语言模型（LLM）的技术演进和新兴能力将这个主题从学术界带到了文化时代。尽管最近的NLP评估基准任务测试了人类仿真行为的一些方面（例如BIG-bench的“类人行为”任务），但几乎没有一个任务考察创造性问题解决能力。人类的创造性问题解决是认知神经科学中研究较为深入的主题，标准化测试主要使用将线索词之间的（异构）连接能力作为创造性的度量。在这样的任务中，暗示性的误导性刺激-被称为“诱导误解”的干扰因素-通过固定效应和Einstellung范式阻碍了人类的表现。在认知神经科学的研究中，通过事先让参与者接触到有相似拼写的错误因素来实验性地诱导这样的固定。

    The quest for human imitative AI has been an enduring topic in AI research since its inception. The technical evolution and emerging capabilities of the latest cohort of large language models (LLMs) have reinvigorated the subject beyond academia to the cultural zeitgeist. While recent NLP evaluation benchmark tasks test some aspects of human-imitative behaviour (e.g., BIG-bench's 'human-like behavior' tasks), few, if not none, examine creative problem solving abilities. Creative problem solving in humans is a well-studied topic in cognitive neuroscience with standardized tests that predominantly use the ability to associate (heterogeneous) connections among clue words as a metric for creativity. Exposure to misleading stimuli - distractors dubbed red herrings - impede human performance in such tasks via the fixation effect and Einstellung paradigm. In cognitive neuroscience studies, such fixations are experimentally induced by pre-exposing participants to orthographically similar incor
    
[^78]: 医疗知识图谱综述：资源、应用和前景

    A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])

    [http://arxiv.org/abs/2306.04802](http://arxiv.org/abs/2306.04802)

    本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。

    

    医疗知识图谱(HKGs)已成为组织医学知识的有结构且可解释的有为工具，提供了医学概念及其关系的全面视图。然而，数据异质性和覆盖范围有限等挑战仍然存在，强调了在HKG领域需要进一步研究的必要性。本综述是HKG的第一份综合概述。我们总结了HKG构建的流程和关键技术（即从头开始和通过集成），以及常见的利用方法（即基于模型和非基于模型）。为了为研究人员提供有价值的资源，我们根据它们捕获的数据类型和应用领域（该资源存储于https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase）组织了现有的HKG，并提供了相关的统计信息。在应用部分，我们深入探讨了HKG在各种医疗领域的变革性影响。

    Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
    
[^79]: 通过神经科学的视角探究人工意识的可行性

    The feasibility of artificial consciousness through the lens of neuroscience. (arXiv:2306.00915v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2306.00915](http://arxiv.org/abs/2306.00915)

    从神经科学的角度来看，目前大型语言模型难以具备哺乳动物意识感知相关的丘脑皮层系统的关键特征，缺乏周围世界的具体嵌入式信息，且当前的人工智能无法做到存在的依赖于其行为，这意味着人工意识的可行性存在瓶颈。

    

    与大型语言模型的交互引发了这些模型可能具有意识的猜测。从神经科学的角度来看，这种观点很难被证实。首先，大型语言模型的架构缺少哺乳动物意识感知相关的丘脑皮层系统的关键特征。其次，大型语言模型的输入缺乏我们与周围世界的感官接触的具有体验、嵌入式信息的特征。最后，虽然前两个论点在未来的AI系统中可以被克服，但第三个可能更难在不久的将来跨越。换言之，我们认为意识可能取决于是否在“游戏中有皮肤”，即系统的存在是否取决于其行为，而这在当前的人工智能中并不成立。

    Interactions with large language models have led to the suggestion that these models may be conscious. From the perspective of neuroscience, this position is difficult to defend. For one, the architecture of large language models is missing key features of the thalamocortical system that have been linked to conscious awareness in mammals. Secondly, the inputs to large language models lack the embodied, embedded information content characteristic of our sensory contact with the world around us. Finally, while the previous two arguments can be overcome in future AI systems, the third one might be harder to bridge in the near future. Namely, we argue that consciousness might depend on having 'skin in the game', in that the existence of the system depends on its actions, which is not true for present-day artificial intelligence.
    
[^80]: Fusemate概率逻辑编程系统中的自下而上推理

    Bottom-Up Grounding in the Probabilistic Logic Programming System Fusemate. (arXiv:2305.18924v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.18924](http://arxiv.org/abs/2305.18924)

    介绍了自下而上推理的概率逻辑编程系统Fusemate，提出了基于查询引导的相关性测试修剪规则，解决了自下而上推理难以控制ground clauses生成数量的问题，并在包含“时间”的示例中表现出更好的性能。

    

    本文介绍了Fusemate概率逻辑编程系统，该系统的推理引擎包括一个自下而上推理的grounding组件和一个变量消除方法用于概率推理。Fusemate不同于大多数系统，它采用自下而上的方式对程序进行grounding。本文解决了自下而上推理难以控制生成的ground clauses数量的问题，通过交错grounding和一个基于查询引导的相关性测试来修剪与查询不一致的规则。我们详细介绍了我们的方法，并通过包含“时间”的示例（如（隐藏）马尔可夫模型）进行演示。我们的实验证明，在高分支问题上，相比于最先进的概率逻辑编程系统，我们的性能更具竞争力或更好。

    This paper introduces the Fusemate probabilistic logic programming system. Fusemate's inference engine comprises a grounding component and a variable elimination method for probabilistic inference. Fusemate differs from most other systems by grounding the program in a bottom-up way instead of the common top-down way. While bottom-up grounding is attractive for a number of reasons, e.g., for dynamically creating distributions of varying support sizes, it makes it harder to control the amount of ground clauses generated. We address this problem by interleaving grounding with a query-guided relevance test which prunes rules whose bodies are inconsistent with the query. We present our method in detail and demonstrate it with examples that involve "time", such as (hidden) Markov models. Our experiments demonstrate competitive or better performance compared to a state-of-the art probabilistic logic programming system, in particular for high branching problems.
    
[^81]: 超越一个模型适用于所有领域：大型语言模型的领域专门化综述

    Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. (arXiv:2305.18703v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18703](http://arxiv.org/abs/2305.18703)

    本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    

    大型语言模型（LLM）已经大大推动了自然语言处理（NLP）领域的发展，为广泛应用提供了高度实用、任务无关的基础。LLMs 作为通用任务求解器的巨大潜力，促使人们将其用于特定领域，如医疗保健、金融和教育，并将其用作助手甚至替代特定领域的专家和工具。但是，将LLMs直接应用于特定领域中的复杂问题会遇到许多困难，包括领域数据的异质性、领域知识的复杂性、领域目标的独特性以及约束的多样性。为了填补这种差距，最近几年进行了急剧增加的研究和实践致力于大型语言模型的领域专门化，然而这方面的研究尚未被系统地总结。在这篇综述中，我们对LLMs的领域专门化进行了全面概述，包括动机、挑战、方法论和评估指标。此外，我们提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. The great promise of LLMs as general task solvers motivated people to extend their functionality largely beyond just a ``chatbot'', and use it as an assistant or even replacement for domain experts and tools in specific domains such as healthcare, finance, and education. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). To fill such a gap, explosively-increase research, and practices have been conducted in very recent years on the domain specialization of LLMs, which, howe
    
[^82]: 评估开放式问答评估

    Evaluating Open-QA Evaluation. (arXiv:2305.12421v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12421](http://arxiv.org/abs/2305.12421)

    本研究侧重于评估开放式问答（Open-QA）任务的方法，引入了一个新的任务QA-Eval和数据集EVOUNA，通过人工评估方法来评估AI生成的答案的准确性。我们调查了与人工评估相关的方法，并讨论了当前方法的缺陷和改进方法。我们相信这对于未来的自动评估工具发展和研究具有价值。

    

    本研究侧重于对开放式问答（Open-QA）任务的评估，该任务可以直接估计大型语言模型（LLMs）的事实性。目前的自动评估方法已显示出一定的局限性，表明人工评估仍然是最可靠的方法。我们引入了一个新的任务，即评估QA评估（QA-Eval）以及相应的数据集EVOUNA，旨在评估AI生成的答案与Open-QA中的标准答案之间的准确性。我们利用人工标注的结果来评估这些方法的性能。具体而言，本研究调查了那些与人工评估具有高度相关性的方法，认为它们更可靠。我们还讨论了当前方法的缺陷以及改进基于LLM的评估器的方法。我们相信，这个新的QA-Eval任务和相应的数据集EVOUNA将促进更有效的自动评估工具的开发，并对未来的研究具有价值。

    This study focuses on the evaluation of the Open Question Answering (Open-QA) task, which can directly estimate the factuality of large language models (LLMs). Current automatic evaluation methods have shown limitations, indicating that human evaluation still remains the most reliable approach. We introduce a new task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset EVOUNA, designed to assess the accuracy of AI-generated answers in relation to standard answers within Open-QA. Our evaluation of these methods utilizes human-annotated results to measure their performance. Specifically, the work investigates methods that show high correlation with human evaluations, deeming them more reliable. We also discuss the pitfalls of current methods and methods to improve LLM-based evaluators. We believe this new QA-Eval task and corresponding dataset EVOUNA will facilitate the development of more effective automatic evaluation tools and prove valuable for future research in this a
    
[^83]: 通过验证和验证的视角对大型语言模型的安全性和可信度进行调查

    A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation. (arXiv:2305.11391v1 [cs.AI])

    [http://arxiv.org/abs/2305.11391](http://arxiv.org/abs/2305.11391)

    通过验证和验证的视角对大型语言模型的安全性和可信度进行调查，分类它们的已知漏洞，将其分为固有问题、有意攻击和意外错误。同时，考虑四种互补技术以提供LLM及其应用的安全和可信度保障。

    

    大型语言模型（LLM）以其在许多知识领域中为终端用户提供详细和有条理的答案，并能够进行人类级别的对话能力，引发了AI的一波新热潮。为了应对它们在许多工业应用中的快速采用，本次调查关注它们的安全性和可信度。首先，我们回顾LLM的已知漏洞，将它们分类为固有问题、有意攻击和意外错误。然后，我们考虑是否以及如何将已被广泛用于传统软件和深度学习模型（如卷积神经网络）的验证和验证（V＆V）技术，集成并进一步扩展到LLM的整个生命周期中，以提供严格的分析，确保LLM及其应用的安全和可信度。具体而言，我们考虑四种互补技术：虚假性和评估、验证、运行时监视和道德使用。考虑到LLM的快速发展，

    Large Language Models (LLMs) have exploded a new heatwave of AI, for their ability to engage end-users in human-level conversations with detailed and articulate answers across many knowledge domains. In response to their fast adoption in many industrial applications, this survey concerns their safety and trustworthiness. First, we review known vulnerabilities of the LLMs, categorising them into inherent issues, intended attacks, and unintended bugs. Then, we consider if and how the Verification and Validation (V&V) techniques, which have been widely developed for traditional software and deep learning models such as convolutional neural networks, can be integrated and further extended throughout the lifecycle of the LLMs to provide rigorous analysis to the safety and trustworthiness of LLMs and their applications. Specifically, we consider four complementary techniques: falsification and evaluation, verification, runtime monitoring, and ethical use. Considering the fast development of 
    
[^84]: 区域感知预训练：视觉变压器下的开放词汇物体检测

    Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers. (arXiv:2305.07011v1 [cs.CV])

    [http://arxiv.org/abs/2305.07011](http://arxiv.org/abs/2305.07011)

    本文提出了一种基于视觉变压器的对比图像-文本预训练方法，针对开放词汇的物体检测任务，采用区域感知预训练、聚焦损失和新颖物体提案等技术，在LVIS上取得了32.1$AP_r$的最佳效果。

    

    本文提出了区域感知开放词汇视觉变压器（RO-ViT），一种对比图像-文本预训练方法，旨在填补图像级预训练和开放词汇物体检测之间的差距。在预训练阶段，我们建议随机裁剪并调整位置嵌入的区域，而不是使用整个图像位置嵌入。这更好地匹配了检测微调阶段中区域级别上使用位置嵌入的方式。此外，我们用聚焦损失替换了对比学习中常用的softmax交叉熵损失，以更好地学习那些有信息量但难以捕捉的例子。最后，我们利用了最近在新颖物体提案方面的进展，以改进开放词汇检测的微调。我们在LVIS和COCO开放词汇检测基准上评估了完整模型和零-shot转移性能。RO-ViT在LVIS上实现了32.1$AP_r$的最佳效果，超过现有最佳方法5.8个百分点，同时还具有竞争性的零-shot转移检测结果。

    We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of positional embeddings at region-level in the detection finetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to better learn the informative yet difficult examples. Finally, we leverage recent advances in novel object proposals to improve open-vocabulary detection finetuning. We evaluate our full model on the LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 32.1 $AP_r$ on LVIS, surpassing the best existing approach by +5.8 points in addition to competitive zero-shot transfer detec
    
[^85]: 面向危及生命的室性心律失常检测的微小机器学习设计竞赛

    TinyML Design Contest for Life-Threatening Ventricular Arrhythmia Detection. (arXiv:2305.05105v1 [eess.SP])

    [http://arxiv.org/abs/2305.05105](http://arxiv.org/abs/2305.05105)

    TDC'22是第一届面向ICDs低功耗微控制器的人工智能/机器学习（AI/ML）算法创新竞赛。本次竞赛的挑战是开发一种基于AI/ML的新型实时检测算法，对危及生命的室性心律失常进行检测。

    

    第一届ACM/IEEE微小机器学习设计竞赛（TDC）于2022年在第41届计算机辅助设计国际会议（ICCAD）上举行，是一项具有挑战性的多月研发竞赛。TDC'22专注于需要在可植入设备上创新和实现人工智能/机器学习（AI/ML）算法的真实医疗问题。TDC'22的挑战问题是开发一种基于AI/ML的新型实时检测算法，用于心脏除颤器（ICDs）上使用的低功率微控制器对危及生命的室性心律失常进行检测。数据集包含来自90个受试者的8种不同心律类型的超过38,000个5秒心内电图（IEGM）片段。专用硬件平台是STMicroelectronics制造的NUCLEO-L432KC。TDC'22面向全球多人团队，吸引了来自50多个组织的150多支队伍参赛。本文首先介绍这一医疗问题，

    The first ACM/IEEE TinyML Design Contest (TDC) held at the 41st International Conference on Computer-Aided Design (ICCAD) in 2022 is a challenging, multi-month, research and development competition. TDC'22 focuses on real-world medical problems that require the innovation and implementation of artificial intelligence/machine learning (AI/ML) algorithms on implantable devices. The challenge problem of TDC'22 is to develop a novel AI/ML-based real-time detection algorithm for life-threatening ventricular arrhythmia over low-power microcontrollers utilized in Implantable Cardioverter-Defibrillators (ICDs). The dataset contains more than 38,000 5-second intracardiac electrograms (IEGMs) segments over 8 different types of rhythm from 90 subjects. The dedicated hardware platform is NUCLEO-L432KC manufactured by STMicroelectronics. TDC'22, which is open to multi-person teams world-wide, attracted more than 150 teams from over 50 organizations. This paper first presents the medical problem, da
    
[^86]: 《延迟、复合和部分匿名奖励的强化学习》

    Reinforcement Learning with Delayed, Composite, and Partially Anonymous Reward. (arXiv:2305.02527v1 [cs.LG])

    [http://arxiv.org/abs/2305.02527](http://arxiv.org/abs/2305.02527)

    本文提出了一种算法用于解决具有延迟、复合和部分匿名奖励反馈的无限时平均奖励马尔可夫决策过程(MDP)，并取得了较好的效果。

    

    我们研究了具有延迟、复合和部分匿名奖励反馈的无限时平均奖励马尔可夫决策过程(MDP)。奖励的延迟和复杂性意味着在给定状态下采取行动生成的奖励被分解为不同的组成部分，并在延迟的时间实例中被顺序实现。部分匿名属性意味着对于每个状态，学习者只观察到在该状态下采取不同行动产生的过去奖励组成部分的总和，但是在观察实例中实现。我们提出了一种名为$\mathrm{DUCRL2}$的算法，用于获得此设置的近似最优策略，并表明它实现了$\tilde{\mathcal{O}}\left(DS\sqrt{AT} + d (SA)^3\right)$ 的遗憾界，其中$S$和$A$分别是状态和动作空间的大小，$D$是MDP的直径，$d$是一个由最大奖励延迟限制的参数，$T$表示时间的长度。

    We investigate an infinite-horizon average reward Markov Decision Process (MDP) with delayed, composite, and partially anonymous reward feedback. The delay and compositeness of rewards mean that rewards generated as a result of taking an action at a given state are fragmented into different components, and they are sequentially realized at delayed time instances. The partial anonymity attribute implies that a learner, for each state, only observes the aggregate of past reward components generated as a result of different actions taken at that state, but realized at the observation instance. We propose an algorithm named $\mathrm{DUCRL2}$ to obtain a near-optimal policy for this setting and show that it achieves a regret bound of $\tilde{\mathcal{O}}\left(DS\sqrt{AT} + d (SA)^3\right)$ where $S$ and $A$ are the sizes of the state and action spaces, respectively, $D$ is the diameter of the MDP, $d$ is a parameter upper bounded by the maximum reward delay, and $T$ denotes the time horizon
    
[^87]: 基于地图的经验回放：强化学习中遗忘现象的内存节约解决方案

    Map-based Experience Replay: A Memory-Efficient Solution to Catastrophic Forgetting in Reinforcement Learning. (arXiv:2305.02054v1 [cs.LG])

    [http://arxiv.org/abs/2305.02054](http://arxiv.org/abs/2305.02054)

    本文提出了一种基于地图的经验回放方法，通过将存储的转换组织成一种简洁的环境模型网络，以在减少内存大小的同时增加每个样本的相关性，从而有效解决强化学习中的遗忘问题。

    

    深度强化学习代理在训练新数据时常常会遭受灾难性的遗忘，遗忘先前在输入空间中找到的解决方案。回放记忆是解决这个问题的常见方法，它会对旧和新的训练样本进行去关联和混洗。他们天真地按照状态过渡的顺序存储状态转变，而不考虑冗余性。我们介绍了一种基于Grow-When-Required（GWR）自组织网络的新型认知启发式回放内存方法，它类似于一种基于地图的世界认知模型。我们的方法将存储的转换组织成一个简洁的环境模型网络，将相似的样本合并以减少内存大小并增加样本之间的两两距离，从而增加每个样本的相关性。总体而言，我们的论文表明，基于地图的经验回放允许显着减少内存，只会产生轻微的性能下降。

    Deep Reinforcement Learning agents often suffer from catastrophic forgetting, forgetting previously found solutions in parts of the input space when training on new data. Replay Memories are a common solution to the problem, decorrelating and shuffling old and new training samples. They naively store state transitions as they come in, without regard for redundancy. We introduce a novel cognitive-inspired replay memory approach based on the Grow-When-Required (GWR) self-organizing network, which resembles a map-based mental model of the world. Our approach organizes stored transitions into a concise environment-model-like network of state-nodes and transition-edges, merging similar samples to reduce the memory size and increase pair-wise distance among samples, which increases the relevancy of each sample. Overall, our paper shows that map-based experience replay allows for significant memory reduction with only small performance decreases.
    
[^88]: 探索自监督单帧和多帧深度估计之间的相互影响

    Exploring the Mutual Influence between Self-Supervised Single-Frame and Multi-Frame Depth Estimation. (arXiv:2304.12685v1 [cs.CV])

    [http://arxiv.org/abs/2304.12685](http://arxiv.org/abs/2304.12685)

    文章介绍了一种新的自监督训练框架，旨在充分利用单帧深度和多帧深度方法之间的相互影响。通过引入一个像素逐像素自适应深度采样模块，以单帧深度为指导来训练多帧模型，并利用最小重投影为基础的蒸馏方法来优化单帧深度的模型。

    

    尽管自监督单帧和多帧深度估计方法都只需要无标签单目视频进行训练，但它们所利用的信息不同，单帧方法主要依赖于基于外貌的特征，而多帧方法则专注于几何线索。考虑到单帧和多帧方法的互补信息，一些工作尝试利用单帧深度来改进多帧深度。但是，这些方法既不能利用单帧深度和多帧深度之间的差异来改进多帧深度，也不能利用多帧深度来优化单帧深度模型。为了充分利用单帧和多帧方法之间的相互影响，我们提出了一种新的自监督训练框架。具体而言，我们首先引入一个由单帧深度指导的像素逐像素自适应深度采样模块来训练多帧模型。然后，我们利用最小重投影为基础的蒸馏方法来利用多帧深度优化单帧深度的模型。

    Although both self-supervised single-frame and multi-frame depth estimation methods only require unlabeled monocular videos for training, the information they leverage varies because single-frame methods mainly rely on appearance-based features while multi-frame methods focus on geometric cues. Considering the complementary information of single-frame and multi-frame methods, some works attempt to leverage single-frame depth to improve multi-frame depth. However, these methods can neither exploit the difference between single-frame depth and multi-frame depth to improve multi-frame depth nor leverage multi-frame depth to optimize single-frame depth models. To fully utilize the mutual influence between single-frame and multi-frame methods, we propose a novel self-supervised training framework. Specifically, we first introduce a pixel-wise adaptive depth sampling module guided by single-frame depth to train the multi-frame model. Then, we leverage the minimum reprojection based distillat
    
[^89]: 预训练语言模型作为人类辅助视觉计划者

    Pretrained Language Models as Visual Planners for Human Assistance. (arXiv:2304.09179v1 [cs.CV])

    [http://arxiv.org/abs/2304.09179](http://arxiv.org/abs/2304.09179)

    本研究提出了视觉辅助计划（VPA）的任务，利用预训练语言模型作为序列模型，在视频行动分割和预测方面优于现有的方法，来实现多模态AI助手指导用户完成复杂多步骤目标的进展。

    

    为了实现多模态AI助手指导用户完成复杂多步骤目标的进展，本研究提出了视觉辅助计划（VPA）的任务。给定自然语言简要描述的目标，例如“制作书架”，以及用户迄今为止的视频进展，VPA的目标是获得一个计划，即一系列行动，如“砂光书架”、“涂漆书架”等，以实现目标。这需要评估用户在未经修剪的视频中的进展，并与底层目标的要求相关联，即行动的相关性和其中的排序依赖关系。因此，这需要处理长时间的视频历史记录和任意复杂的行动依赖性。为了解决这些问题，我们将VPA分解为视频行动分割和预测。我们将预测步骤公式化为多模态序列建模问题，并提出了基于视觉语言模型的计划者（VLaMP），其中利用预训练的LMs作为序列模型。我们在两个数据集（Epic Kitchen和Charades-Ego）上展示了VLaMP的有效性。我们的实验结果表明，VLaMP在准确性、效率和泛化方面优于现有的方法。

    To make progress towards multi-modal AI assistants which can guide users to achieve complex multi-step goals, we propose the task of Visual Planning for Assistance (VPA). Given a goal briefly described in natural language, e.g., "make a shelf", and a video of the user's progress so far, the aim of VPA is to obtain a plan, i.e., a sequence of actions such as "sand shelf", "paint shelf", etc., to achieve the goal. This requires assessing the user's progress from the untrimmed video, and relating it to the requirements of underlying goal, i.e., relevance of actions and ordering dependencies amongst them. Consequently, this requires handling long video history, and arbitrarily complex action dependencies. To address these challenges, we decompose VPA into video action segmentation and forecasting. We formulate the forecasting step as a multi-modal sequence modeling problem and present Visual Language Model based Planner (VLaMP), which leverages pre-trained LMs as the sequence model. We dem
    
[^90]: 通过离线强化学习实现因果决策Transformer的推荐系统

    Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning. (arXiv:2304.07920v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2304.07920](http://arxiv.org/abs/2304.07920)

    本论文提出了一种基于因果决策Transformer和离线强化学习的推荐系统，通过探索用户行为的因果关系，指导代理捕捉动态兴趣，并解决了大规模情境下数据效率低的问题。

    

    最近，基于强化学习的推荐系统已经变得越来越流行。然而，优化推荐策略的奖励函数的设计往往并不简单。探索用户行为背后的因果关系可以替代奖励函数，指导代理捕捉用户的动态兴趣。此外，由于仿真环境的典型限制（如数据效率），大部分研究无法广泛应用于大规模情境。尽管一些研究尝试将离线数据集转化为仿真器，但数据效率使学习过程变得更加缓慢。由于强化学习的本质是通过相互作用进行学习，它无法在单次交互过程中收集足够的数据进行训练。此外，传统的强化学习算法不像监督学习方法那样具备直接从离线数据集进行学习的牢固能力。

    Reinforcement learning-based recommender systems have recently gained popularity. However, the design of the reward function, on which the agent relies to optimize its recommendation policy, is often not straightforward. Exploring the causality underlying users' behavior can take the place of the reward function in guiding the agent to capture the dynamic interests of users. Moreover, due to the typical limitations of simulation environments (e.g., data inefficiency), most of the work cannot be broadly applied in large-scale situations. Although some works attempt to convert the offline dataset into a simulator, data inefficiency makes the learning process even slower. Because of the nature of reinforcement learning (i.e., learning by interaction), it cannot collect enough data to train during a single interaction. Furthermore, traditional reinforcement learning algorithms do not have a solid capability like supervised learning methods to learn from offline datasets directly. In this p
    
[^91]: PGTask：介绍从对话中生成档案的任务

    PGTask: Introducing the Task of Profile Generation from Dialogues. (arXiv:2304.06634v1 [cs.CL])

    [http://arxiv.org/abs/2304.06634](http://arxiv.org/abs/2304.06634)

    对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。

    

    最近的研究尝试通过将个人资料信息融入模型来个性化对话系统。然而，这种知识信息稀少且难以获取，这使得从对话中提取/生成个人资料信息成为一项基本需求。为了克服这一限制，我们引入了档案生成任务（PGTask）。我们为此问题提供了一个新的数据集，其中包括与相关话语对齐的档案句子，从对话语料库中提取。此外，利用最先进的方法，我们为这个新数据集提供了一个档案生成的基准。我们的实验揭示了档案生成的挑战，并希望这引入了一个新的研究方向。

    Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.
    
[^92]: ASR: 像注意力一样的结构再参数化

    ASR: Attention-alike Structural Re-parameterization. (arXiv:2304.06345v1 [cs.CV])

    [http://arxiv.org/abs/2304.06345](http://arxiv.org/abs/2304.06345)

    该论文提出的ASR技术是一种新颖的深度学习技术，通过等效参数转换实现不同网络体系结构之间的互转。和现有的SRP方法相比，ASR可以成功考虑自注意模块，实现推理期间的性能提升，并在工业和实际应用中具有巨大潜力。

    

    结构再参数化（SRP）技术是一种新颖的深度学习技术，通过等效参数转换实现不同网络体系结构之间的互转。该技术使得在推理过程中通过这些转换减少性能提升的新增代价，例如参数大小和推理时间，因此SRP在工业和实际应用中具有巨大潜力。现有的SRP方法已成功考虑了许多常用的架构，例如归一化、池化方法、多分支卷积等。然而，广泛使用的自注意模块由于在推理期间通常以乘法方式作用于骨干网络并且模块的输出在推理时依赖于输入，所以无法直接实现SRP，而这限制了SRP的应用场景。在本文中，我们从统计角度进行了广泛的实验，并发现...

    The structural re-parameterization (SRP) technique is a novel deep learning technique that achieves interconversion between different network architectures through equivalent parameter transformations. This technique enables the mitigation of the extra costs for performance improvement during training, such as parameter size and inference time, through these transformations during inference, and therefore SRP has great potential for industrial and practical applications. The existing SRP methods have successfully considered many commonly used architectures, such as normalizations, pooling methods, multi-branch convolution. However, the widely used self-attention modules cannot be directly implemented by SRP due to these modules usually act on the backbone network in a multiplicative manner and the modules' output is input-dependent during inference, which limits the application scenarios of SRP. In this paper, we conduct extensive experiments from a statistical perspective and discover
    
[^93]: 交互感知提示的零样本时空动作检测

    Interaction-Aware Prompting for Zero-Shot Spatio-Temporal Action Detection. (arXiv:2304.04688v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.04688](http://arxiv.org/abs/2304.04688)

    提出了一种采用预训练的视觉-语言模型和交互模块进行交互感知提示的零样本时空动作检测方法，优化了视觉-语言特征的对齐，实现了更好的结果。

    

    空间-时间动作检测的目标是确定每个人在视频中动作发生的时间和位置，并对相应的动作类别进行分类。大多数现有方法采用全监督学习，需要大量的训练数据，因此难以实现零样本学习。本文提出利用预训练的视觉-语言模型提取代表性的图像和文本特征，并通过不同的交互模块建模这些特征之间的关系以得到交互特征。此外，利用这个特征提示每个标签以获取更合适的文本特征。最后，我们计算每个标签的交互特征和文本特征之间的相似度，以确定动作类别。在J-HMDB和UCF101-24数据集上的实验表明，所提出的交互模块和提示使视觉-语言特征更加对齐，从而实现了更好的结果。

    The goal of spatial-temporal action detection is to determine the time and place where each person's action occurs in a video and classify the corresponding action category. Most of the existing methods adopt fully-supervised learning, which requires a large amount of training data, making it very difficult to achieve zero-shot learning. In this paper, we propose to utilize a pre-trained visual-language model to extract the representative image and text features, and model the relationship between these features through different interaction modules to obtain the interaction feature. In addition, we use this feature to prompt each label to obtain more appropriate text features. Finally, we calculate the similarity between the interaction feature and the text feature for each label to determine the action category. Our experiments on J-HMDB and UCF101-24 datasets demonstrate that the proposed interaction module and prompting make the visual-language features better aligned, thus achievi
    
[^94]: 留住人才是最重要的，使用可解释的AI来解决员工离职问题

    Retention Is All You Need. (arXiv:2304.03103v1 [cs.AI])

    [http://arxiv.org/abs/2304.03103](http://arxiv.org/abs/2304.03103)

    本研究提出了HR-DSS方法，使用可解释的AI帮助人力资源部门解释机器学习模型提供的员工流失预测结果，并且提供“What-if-analysis”来观察个体员工可能导致离职的原因。

    

    熟练的员工通常被视为组织的最重要支柱。尽管如此，大多数组织都面临着高离职率和流失率。虽然已经开发了几种机器学习模型用于分析离职及其原因，但这些模型的解释仍然不透明。本文提出了HR-DSS方法，即人力资源决策支持系统，使用可解释的AI解决员工流失问题。该系统旨在帮助人力资源部门解释机器学习模型提供的预测结果。在我们的实验中，使用了八种机器学习模型进行预测，并且最佳表现的模型的结果进一步经过了SHAP解释性过程的处理。我们优化了结果的正确性和解释性。此外，我们还使用“What-if-analysis”来观察个体员工可能导致离职的原因。

    Skilled employees are usually seen as the most important pillar of an organization. Despite this, most organizations face high attrition and turnover rates. While several machine learning models have been developed for analyzing attrition and its causal factors, the interpretations of those models remain opaque. In this paper, we propose the HR-DSS approach, which stands for Human Resource Decision Support System, and uses explainable AI for employee attrition problems. The system is designed to assist human resource departments in interpreting the predictions provided by machine learning models. In our experiments, eight machine learning models are employed to provide predictions, and the results achieved by the best-performing model are further processed by the SHAP explainability process. We optimize both the correctness and explanation of the results. Furthermore, using "What-if-analysis", we aim to observe plausible causes for attrition of an individual employee. The results show 
    
[^95]: GINA-3D：在真实场景中学习生成隐式神经资产

    GINA-3D: Learning to Generate Implicit Neural Assets in the Wild. (arXiv:2304.02163v1 [cs.CV])

    [http://arxiv.org/abs/2304.02163](http://arxiv.org/abs/2304.02163)

    GINA-3D是一种学习从真实场景中生成3D隐式神经资产的生成模型，这对于自主驾驶等机器人学习问题的测试和验证环境是重要的创新。

    

    从传感器数据中建模3D世界以进行仿真是开发自动驾驶等机器人学习问题的测试和验证环境的可扩展方法。然而，手动创建或重新创建类似真实世界的环境是困难，昂贵且不可扩展的。最近的生成模型技术，通过仅使用丰富的2D图像来学习3D资产，已经显示出解决这些挑战的有希望的进展 -- 但仍然存在局限性，因为它们利用人类策划的图像数据集或手动创建的合成3D环境的渲染。在本文中，我们介绍GINA-3D，这是一个生成模型，它使用来自相机和LiDAR传感器的真实驾驶数据创建真实3D隐式神经资产，包括各种车辆和行人。与现有的图像数据集相比，真实驾驶环境由于遮挡，光照变化和长尾分布而面临新的挑战。GINA-3D通过解耦从单个视角生成3D达到了解决这些挑战的目的，进而使3D场景的自动化成为可能。

    Modeling the 3D world from sensor data for simulation is a scalable way of developing testing and validation environments for robotic learning problems such as autonomous driving. However, manually creating or re-creating real-world-like environments is difficult, expensive, and not scalable. Recent generative model techniques have shown promising progress to address such challenges by learning 3D assets using only plentiful 2D images -- but still suffer limitations as they leverage either human-curated image datasets or renderings from manually-created synthetic 3D environments. In this paper, we introduce GINA-3D, a generative model that uses real-world driving data from camera and LiDAR sensors to create realistic 3D implicit neural assets of diverse vehicles and pedestrians. Compared to the existing image datasets, the real-world driving setting poses new challenges due to occlusions, lighting-variations and long-tail distributions. GINA-3D tackles these challenges by decoupling re
    
[^96]: 人类合作是否增强了识别LLM生成的深度伪造文本的准确性？

    Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?. (arXiv:2304.01002v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01002](http://arxiv.org/abs/2304.01002)

    这项研究研究了人类合作是否增强了识别LLM生成的深度伪造文本的准确性。结果表明，合作可以潜在地提高两组人对深度伪造文本的检测准确性。

    

    大型语言模型（如GPT-4、LLaMA）的进展改善了大规模生成类似人类写作的连贯句子，从而产生了所谓的深度伪造文本。然而，这一进展引发了安全和隐私的担忧，需要有效解决方案来区分深度伪造文本和人类书写文本。尽管以前的研究探讨了人类检测深度伪造文本的能力，但没有研究“合作”是否能提高深度伪造文本的检测。在本研究中，为了填补对深度伪造文本理解的空白，我们对两组人进行了实验：（1）来自AMT平台的非专家群体和（2）来自Upwork平台的写作专家。结果表明，人类之间的合作可能会提高两组对深度伪造文本的检测准确性，非专家组的检测准确性提高了6.36%，专家组的检测准确性提高了12.76%。

    Advances in Large Language Models (e.g., GPT-4, LLaMA) have improved the generation of coherent sentences resembling human writing on a large scale, resulting in the creation of so-called deepfake texts. However, this progress poses security and privacy concerns, necessitating effective solutions for distinguishing deepfake texts from human-written ones. Although prior works studied humans' ability to detect deepfake texts, none has examined whether "collaboration" among humans improves the detection of deepfake texts. In this study, to address this gap of understanding on deepfake texts, we conducted experiments with two groups: (1) nonexpert individuals from the AMT platform and (2) writing experts from the Upwork platform. The results demonstrate that collaboration among humans can potentially improve the detection of deepfake texts for both groups, increasing detection accuracies by 6.36% for non-experts and 12.76% for experts, respectively, compared to individuals' detection accur
    
[^97]: 适应性负证据深度学习用于开放式半监督学习

    Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning. (arXiv:2303.12091v1 [cs.LG])

    [http://arxiv.org/abs/2303.12091](http://arxiv.org/abs/2303.12091)

    本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。

    

    半监督学习方法假设标记数据、未标记数据和测试数据来自同一分布。开放式半监督学习考虑到一个更实际的情况，即未标记数据和测试数据包含标记数据中未观察到的新类别（异常值）。本文提出了一种新颖的框架——适应性负证据深度学习（ANEDL），以应对二元分类器的不足之处，如缺乏可扩展性和无法区分不同类型的不确定性。具体而言，我们首先介绍证据深度学习（EDL）作为一种异常检测器来量化不同类型的不确定性，并设计不同的不确定性度量方法进行自我训练和推理。此外，我们提出了一种新颖的适应性负优化策略，使EDL更加适合包含内部值和异常值的未标记数据集。通过在基准数据集上的实验验证，我们的ANEDL显著优于现有的开放式半监督学习方法。

    Semi-supervised learning (SSL) methods assume that labeled data, unlabeled data and test data are from the same distribution. Open-set semi-supervised learning (Open-set SSL) considers a more practical scenario, where unlabeled data and test data contain new categories (outliers) not observed in labeled data (inliers). Most previous works focused on outlier detection via binary classifiers, which suffer from insufficient scalability and inability to distinguish different types of uncertainty. In this paper, we propose a novel framework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these limitations. Concretely, we first introduce evidential deep learning (EDL) as an outlier detector to quantify different types of uncertainty, and design different uncertainty metrics for self-training and inference. Furthermore, we propose a novel adaptive negative optimization strategy, making EDL more tailored to the unlabeled dataset containing both inliers and outliers. As demonstrat
    
[^98]: GeoMIM：通过基于掩膜图像建模的三维知识转移实现更好的多视角三维理解

    GeoMIM: Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding. (arXiv:2303.11325v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.11325](http://arxiv.org/abs/2303.11325)

    该论文提出了一种称为GeoMIM的方法，通过基于掩膜图像建模的方式来改进多视角基于相机的三维检测。该方法使用激光雷达模型的知识进行预训练和微调，并利用激光雷达BEV特征作为学习目标。实验结果表明，GeoMIM在多视角三维理解中取得了良好的效果。

    

    在计算机视觉中，多视角基于相机的三维检测是一个具有挑战性的问题。最近的研究利用预训练的激光雷达检测模型将知识转移到基于相机的学生网络中。然而，我们认为激光雷达BEV特征和基于相机的BEV特征之间存在重大的领域差异，因为它们具有不同的特征和来源。在本文中，我们提出了几何增强的掩膜图像建模（GeoMIM），以在预训练-微调范式中通过激光雷达模型的知识来改进基于相机的多视角三维检测。GeoMIM是一个多相机视觉变换器，具有跨视图注意力（CVA）块，使用预训练的BEV模型编码的激光雷达BEV特征作为学习目标。在预训练过程中，GeoMIM的解码器具有一个语义分支，完成密集的透视图特征，并且另一个几何分支重构密集的透视视图深度图。深度分支设计为相机感知。

    Multi-view camera-based 3D detection is a challenging problem in computer vision. Recent works leverage a pretrained LiDAR detection model to transfer knowledge to a camera-based student network. However, we argue that there is a major domain gap between the LiDAR BEV features and the camera-based BEV features, as they have different characteristics and are derived from different sources. In this paper, we propose Geometry Enhanced Masked Image Modeling (GeoMIM) to transfer the knowledge of the LiDAR model in a pretrain-finetune paradigm for improving the multi-view camera-based 3D detection. GeoMIM is a multi-camera vision transformer with Cross-View Attention (CVA) blocks that uses LiDAR BEV features encoded by the pretrained BEV model as learning targets. During pretraining, GeoMIM's decoder has a semantic branch completing dense perspective-view features and the other geometry branch reconstructing dense perspective-view depth maps. The depth branch is designed to be camera-aware b
    
[^99]: 深度学习模型重构的挑战和实践：计算机视觉案例研究

    Challenges and Practices of Deep Learning Model Reengineering: A Case Study on Computer Vision. (arXiv:2303.07476v1 [cs.SE])

    [http://arxiv.org/abs/2303.07476](http://arxiv.org/abs/2303.07476)

    本研究对深度学习模型重构进行了实例研究，并发现由于参考模型文档不全、需求变化以及实现和测试成本等原因，该过程具有挑战性，个别工程师可能缺乏软件工程方面的专业知识，但团队必须应用软件工程和深度学习的知识才能成功。

    

    许多工程组织正在重新实现和扩展研究界的深度神经网络。我们将这个过程描述为深度学习模型重构。深度学习模型重构-重用，再现，调整和增强最先进的深度学习方法-由于参考模型文档不全、需求变化以及实现和测试成本等原因，具有挑战性。此外，个别工程师可能缺乏软件工程方面的专业知识，但团队必须应用软件工程和深度学习的知识才能成功。先前的研究从“产品”视角研究DL系统，无论工程师的目的如何，都会研究项目中的缺陷。我们的研究集中在“过程”视角的重构活动上，专注于参与重构过程的工程师。我们的目标是了解深度学习模型重构的特点和挑战。我们进行了一项案例研究...

    Many engineering organizations are reimplementing and extending deep neural networks from the research community. We describe this process as deep learning model reengineering. Deep learning model reengineering - reusing, reproducing, adapting, and enhancing state-of-the-art deep learning approaches - is challenging for reasons including under-documented reference models, changing requirements, and the cost of implementation and testing. In addition, individual engineers may lack expertise in software engineering, yet teams must apply knowledge of software engineering and deep learning to succeed. Prior work has examined on DL systems from a "product" view, examining defects from projects regardless of the engineers' purpose. Our study is focused on reengineering activities from a "process" view, and focuses on engineers specifically engaged in the reengineering process.  Our goal is to understand the characteristics and challenges of deep learning model reengineering. We conducted a c
    
[^100]: 通过受限代理学习控制深度序数分类中的类布局

    Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning. (arXiv:2303.00396v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.00396](http://arxiv.org/abs/2303.00396)

    本文提出了一种通过受限代理学习方法，可以有效地控制深度序数分类中的类布局。

    

    对于深度序数分类任务，学习特定于序数分类的良好结构化特征空间有助于恰当地捕捉类之间的序数属性。本文提出了一种新颖的受限代理学习方法，该方法可以为每个序数类学习一个代理，然后通过限制这些代理来调整类的全局布局。我们提出了两种策略：硬布局约束和软布局约束。硬布局约束通过直接控制代理的生成来实现，以强制将其放置在严格的线性布局或半圆形布局（即严格序数布局的两种实例）中。软布局约束通过引入正则化项到损失函数中来实现，该项惩罚偏离理想序数布局的情况。在基准数据集上的实验结果证明了所提出的CPL方法在深度序数分类中的有效性。

    For deep ordinal classification, learning a well-structured feature space specific to ordinal classification is helpful to properly capture the ordinal nature among classes. Intuitively, when Euclidean distance metric is used, an ideal ordinal layout in feature space would be that the sample clusters are arranged in class order along a straight line in space. However, enforcing samples to conform to a specific layout in the feature space is a challenging problem. To address this problem, in this paper, we propose a novel Constrained Proxies Learning (CPL) method, which can learn a proxy for each ordinal class and then adjusts the global layout of classes by constraining these proxies. Specifically, we propose two kinds of strategies: hard layout constraint and soft layout constraint. The hard layout constraint is realized by directly controlling the generation of proxies to force them to be placed in a strict linear layout or semicircular layout (i.e., two instantiations of strict ordi
    
[^101]: 使用强化学习技术革新基因组学

    Revolutionizing Genomics with Reinforcement Learning Techniques. (arXiv:2302.13268v2 [q-bio.GN] UPDATED)

    [http://arxiv.org/abs/2302.13268](http://arxiv.org/abs/2302.13268)

    强化学习是一种革新的工具，可以在基因组学领域中解决自动数据分析和处理的问题。使用强化学习算法可以降低收集标记训练数据的成本，适用于基因组数据分析和解释。本调查重点关注在基因组研究领域中使用强化学习的应用，包括基因调控网络、基因组组装和序列比对。

    

    近年来，强化学习（RL）作为一种强大的工具出现在解决各种问题中，包括决策和基因组学。过去二十年的原始基因组数据指数增长已经超出了手动分析的能力，这导致对自动数据分析和处理的兴趣越来越大。RL算法能够在最小的人工监督下从经验中学习，使其非常适合基因组数据分析和解释。使用RL的一个关键好处是降低了收集标记训练数据的成本，这是监督学习所需的。虽然已经有许多研究探讨了机器学习在基因组学中的应用，但本调查仅专注于在各种基因组研究领域（包括基因调控网络，基因组组装和序列比对）中使用RL的情况。我们对现有研究的技术细节进行了全面的概述。

    In recent years, Reinforcement Learning (RL) has emerged as a powerful tool for solving a wide range of problems, including decision-making and genomics. The exponential growth of raw genomic data over the past two decades has exceeded the capacity of manual analysis, leading to a growing interest in automatic data analysis and processing. RL algorithms are capable of learning from experience with minimal human supervision, making them well-suited for genomic data analysis and interpretation. One of the key benefits of using RL is the reduced cost associated with collecting labeled training data, which is required for supervised learning. While there have been numerous studies examining the applications of Machine Learning (ML) in genomics, this survey focuses exclusively on the use of RL in various genomics research fields, including gene regulatory networks (GRNs), genome assembly, and sequence alignment. We present a comprehensive technical overview of existing studies on the applic
    
[^102]: 随机序列多智能体决策的因果解释

    Causal Explanations for Stochastic Sequential Multi-Agent Decision-Making. (arXiv:2302.10809v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10809](http://arxiv.org/abs/2302.10809)

    CEMA是一个用于多智能体决策因果解释的系统，使用采样反事实世界的方法可以识别和排名决策背后的显著原因。该系统还可以生成基于所选原因的对比解释，并与用户进行交互循环以确保解释的相关性和可读性。

    

    我们提出CEMA：用于多智能体决策的因果解释系统；用于在随机序列多智能体环境中生成关于智能体决策的因果解释。CEMA的核心是一种新颖的因果选择方法，不同于之前假设特定因果结构的方法，只需要一个可以预测环境未来状态的概率模型即可应用。我们使用该模型采样反事实世界，以识别和排名决策背后的显著原因。我们还设计了CEMA以满足社会可解释AI的要求。它可以基于所选原因生成对比解释，通过与用户的交互循环来确保对用户的相关性和可读性。我们将CEMA实现在自动驾驶的运动规划中，并在四个不同的模拟场景中进行测试。我们展示CEMA能够正确而且鲁棒地识别决策背后的相关原因，并提供相关解释。

    We present CEMA: Causal Explanations for Multi-Agent decision-making; a system to generate causal explanations for agents' decisions in stochastic sequential multi-agent environments. The core of CEMA is a novel causal selection method which, unlike prior work that assumes a specific causal structure, is applicable whenever a probabilistic model for predicting future states of the environment is available. We sample counterfactual worlds with this model which are used to identify and rank the salient causes behind decisions. We also designed CEMA to meet the requirements of social explainable AI. It can generate contrastive explanations based on selected causes and it works as an interaction loop with users to assure relevance and intelligibility for them. We implement CEMA for motion planning for autonomous driving and test it in four diverse simulated scenarios. We show that CEMA correctly and robustly identifies the relevant causes behind decisions and delivers relevant explanations
    
[^103]: 在无意识公平性设置中，对偏见评估和检测进行反事实推理

    Counterfactual Reasoning for Bias Evaluation and Detection in a Fairness under Unawareness setting. (arXiv:2302.08204v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08204](http://arxiv.org/abs/2302.08204)

    本研究提出了一种方法来揭示即使在丢弃敏感特征的情况下机器学习模型可能仍存在的潜在偏见，并通过利用反事实推理来检测黑盒预测器的偏见。

    

    当前的AI法规要求在算法的决策过程中丢弃敏感特征（如性别、种族、宗教），以防止不公平的结果。然而，即使在训练集中没有敏感特征，算法仍可能持续进行歧视。事实上，在敏感特征被忽略的情况下（无意识公平性），通过非线性关系，可以通过所谓的代理特征推测出这些敏感特征。在这项工作中，我们提出了一种揭示即使在丢弃敏感特征的情况下机器学习模型可能仍存在的潜在偏见的方法。本研究表明，通过利用反事实推理，可以揭示出黑盒预测器是否仍存在偏见。具体而言，当预测器提供负面分类结果时，我们的方法首先为被歧视的用户类别构建反事实示例，以获得正面结果。然后，相同的反事实样本被用于外部分类器（针对敏感特征）进行训练和测试，以评估黑盒预测器的偏见。

    Current AI regulations require discarding sensitive features (e.g., gender, race, religion) in the algorithm's decision-making process to prevent unfair outcomes. However, even without sensitive features in the training set, algorithms can persist in discrimination. Indeed, when sensitive features are omitted (fairness under unawareness), they could be inferred through non-linear relations with the so called proxy features. In this work, we propose a way to reveal the potential hidden bias of a machine learning model that can persist even when sensitive features are discarded. This study shows that it is possible to unveil whether the black-box predictor is still biased by exploiting counterfactual reasoning. In detail, when the predictor provides a negative classification outcome, our approach first builds counterfactual examples for a discriminated user category to obtain a positive outcome. Then, the same counterfactual samples feed an external classifier (that targets a sensitive f
    
[^104]: 具有通用效用的可扩展多智能体强化学习系统

    Scalable Multi-Agent Reinforcement Learning with General Utilities. (arXiv:2302.07938v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07938](http://arxiv.org/abs/2302.07938)

    本论文研究了具有通用效用的可扩展多智能体强化学习，并提出了一种基于分布式策略梯度算法的解决方案，通过利用网络结构的空间相关衰减性质实现了算法的收敛性。

    

    我们研究了具有通用效用的可扩展多智能体强化学习（MARL），其中通用效用被定义为团队长期状态-动作占有率测度的非线性函数。我们的目标是找到一个局部策略，最大化团队局部效用函数的平均值，而不需要完全观测团队中的每个智能体。通过利用网络结构的空间相关衰减性质，我们提出了一种可扩展的分布式策略梯度算法，其中包括三个步骤：（1）阴影奖励估计，（2）截断阴影Q函数估计，以及（3）截断策略梯度估计和策略更新。我们的算法收敛于$\epsilon$-稳定性，高概率下需要$\widetilde{\mathcal{O}}(\epsilon^{-2})$个样本，直到一定程度上的近似误差以指数速度减小到通信半径内。这是关于具有通用效用的多智能体强化学习的文献中的首个结果。

    We study the scalable multi-agent reinforcement learning (MARL) with general utilities, defined as nonlinear functions of the team's long-term state-action occupancy measure. The objective is to find a localized policy that maximizes the average of the team's local utility functions without the full observability of each agent in the team. By exploiting the spatial correlation decay property of the network structure, we propose a scalable distributed policy gradient algorithm with shadow reward and localized policy that consists of three steps: (1) shadow reward estimation, (2) truncated shadow Q-function estimation, and (3) truncated policy gradient estimation and policy update. Our algorithm converges, with high probability, to $\epsilon$-stationarity with $\widetilde{\mathcal{O}}(\epsilon^{-2})$ samples up to some approximation error that decreases exponentially in the communication radius. This is the first result in the literature on multi-agent RL with general utilities that does
    
[^105]: 用模块化的继任特征逼近器组合任务知识

    Composing Task Knowledge with Modular Successor Feature Approximators. (arXiv:2301.12305v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12305](http://arxiv.org/abs/2301.12305)

    本研究提出了一种新颖的神经网络架构，"模块化继任特征逼近器"（MSFA），通过让模块发现有用于预测的特征并学习自己的预测表示，实现了更好的泛化能力。

    

    最近，已经提出了继任特征和广义策略改进（SF&GPI）框架作为学习、组合和转移预测知识和行为的方法。SF&GPI通过让代理学习能够结合GPI进行任务转移的预测表示（SFs）。然而，为了有效，这种方法需要有用于预测的状态特征，而这些状态特征通常是手工设计的。在这项工作中，我们提出了一种新颖的神经网络架构，"模块化继任特征逼近器"（MSFA），其中模块既可以发现有用于预测的特征，也可以学习自己的预测表示。我们展示了MSFA相比基准架构来学习SFs和模块化架构具有更好的泛化能力。

    Recently, the Successor Features and Generalized Policy Improvement (SF&GPI) framework has been proposed as a method for learning, composing, and transferring predictive knowledge and behavior. SF&GPI works by having an agent learn predictive representations (SFs) that can be combined for transfer to new tasks with GPI. However, to be effective this approach requires state features that are useful to predict, and these state-features are typically hand-designed. In this work, we present a novel neural network architecture, "Modular Successor Feature Approximators" (MSFA), where modules both discover what is useful to predict, and learn their own predictive representations. We show that MSFA is able to better generalize compared to baseline architectures for learning SFs and modular architectures
    
[^106]: 大型语言模型中的事件知识：不可能性和不太可能性之间的差距

    Event knowledge in large language models: the gap between the impossible and the unlikely. (arXiv:2212.01488v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01488](http://arxiv.org/abs/2212.01488)

    大型语言模型拥有丰富的事件知识，几乎总是将可能事件的描述比不可能事件的描述赋予更高的可能性。

    

    语言语料库中的词共现模式包含着意想不到的概念知识。通过训练大型语言模型(LLMs)来预测上下文中的词语，这些模型能够利用这些模式，在需要世界知识的各种语义任务上取得令人印象深刻的性能。关于LLMs的语义能力的重要但鲜为研究的问题是它们是否获得了常见事件的一般化知识。在这里，我们测试了五个预训练的LLMs（从2018年的BERT到2023年的MPT）是否比同一事件的不太可能的版本更可能地分配给合理的代理-患者相互作用。使用三个精心策划的最小句对集合（总数n=1,215），我们发现预训练的LLMs拥有相当大的事件知识，表现优于其他分布式语言模型。特别是，它们几乎总是将可能事件与不可能事件相比赋予更高的可能性（教师买了笔记本电脑相对于笔记本电脑买了教师）。

    Word co-occurrence patterns in language corpora contain a surprising amount of conceptual knowledge. Large language models (LLMs), trained to predict words in context, leverage these patterns to achieve impressive performance on diverse semantic tasks requiring world knowledge. An important but understudied question about LLMs' semantic abilities is whether they acquire generalized knowledge of common events. Here, we test whether five pre-trained LLMs (from 2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions of agent-patient interactions than to minimally different implausible versions of the same event. Using three curated sets of minimal sentence pairs (total n=1,215), we found that pre-trained LLMs possess substantial event knowledge, outperforming other distributional language models. In particular, they almost always assign higher likelihood to possible vs. impossible events (The teacher bought the laptop vs. The laptop bought the teacher). However, LLMs
    
[^107]: 面向5G基站流量预测的联邦学习

    Federated Learning for 5G Base Station Traffic Forecasting. (arXiv:2211.15220v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15220](http://arxiv.org/abs/2211.15220)

    本研究探讨了将联邦学习应用于原始基站LTE数据进行5G基站流量预测的效果。

    

    在推动5G移动网络实现智能高效基础设施规划和管理的过程中，细胞流量预测具有重要意义。然而，可用的数据仅限于基站日志信息。因此，需要训练方法来生成高质量的预测结果，可以推广到不同参与方的新观测中。传统方法需要从多个基站收集测量数据，将其传输到中央实体，并使用获取到的数据进行机器学习操作。本地观测结果的传播引发了关于保密性和性能的担忧，这影响了机器学习技术的适用性。尽管已提出各种分布式学习方法来解决这个问题，但它们在流量预测领域的应用仍然很少探索。在这项工作中，我们研究了将联邦学习应用于原始基站LTE数据进行时序流量预测的有效性。

    Cellular traffic prediction is of great importance on the path of enabling 5G mobile networks to perform intelligent and efficient infrastructure planning and management. However, available data are limited to base station logging information. Hence, training methods for generating high-quality predictions that can generalize to new observations across diverse parties are in demand. Traditional approaches require collecting measurements from multiple base stations, transmitting them to a central entity and conducting machine learning operations using the acquire data. The dissemination of local observations raises concerns regarding confidentiality and performance, which impede the applicability of machine learning techniques. Although various distributed learning methods have been proposed to address this issue, their application to traffic prediction remains highly unexplored. In this work, we investigate the efficacy of federated learning applied to raw base station LTE data for tim
    
[^108]: 研究强化学习智能体在个性化任务中的策略熵

    Examining Policy Entropy of Reinforcement Learning Agents for Personalization Tasks. (arXiv:2211.11869v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11869](http://arxiv.org/abs/2211.11869)

    研究了个性化任务中强化学习智能体的策略熵，并发现策略优化智能体在训练过程中往往具有低熵策略，然而Q学习智能体对此影响较小，通常保持高熵策略。

    

    本文着重研究了强化学习系统在个性化环境中的行为，并详细描述了不同学习算法所关联的策略熵的差异。我们证明了在训练过程中，策略优化智能体往往具有低熵策略，实际上导致智能体优先考虑某些动作而避免其他动作。相反地，我们也表明了Q学习智能体对这种行为的影响要小得多，并且通常在训练过程中保持高熵策略，这在实际应用中往往更可取。我们提供了各种数值实验以及理论上的证明，以表明这些熵差异是由所采用的学习类型所导致的。

    This effort is focused on examining the behavior of reinforcement learning systems in personalization environments and detailing the differences in policy entropy associated with the type of learning algorithm utilized. We demonstrate that Policy Optimization agents often possess low-entropy policies during training, which in practice results in agents prioritizing certain actions and avoiding others. Conversely, we also show that Q-Learning agents are far less susceptible to such behavior and generally maintain high-entropy policies throughout training, which is often preferable in real-world applications. We provide a wide range of numerical experiments as well as theoretical justification to show that these differences in entropy are due to the type of learning being employed.
    
[^109]: 一个低延迟自适应编码脉冲框架用于深度强化学习

    A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning. (arXiv:2211.11760v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11760](http://arxiv.org/abs/2211.11760)

    本文提出了一个低延迟自适应编码脉冲框架用于深度强化学习，在编码器灵活性、延迟和能量效率方面具有优异性能和广泛应用范围。

    

    近年来，由于低功耗和事件驱动特性，脉冲神经网络（SNNs）被用于强化学习（RL）。然而，固定编码方法导致的脉冲强化学习（SRL）仍然面临高延迟和较差的灵活性问题。本文中，我们使用可学习的矩阵乘法对脉冲进行编码和解码，提高编码器的灵活性，从而降低延迟。同时，我们使用直接训练方法训练SNNs，并使用两种不同的结构用于在线和离线强化学习算法，使我们的模型拥有更广泛的应用范围。广泛的实验表明，我们的方法在不同的算法和不同的环境中实现了最佳性能，延迟极低（仅为其他SRL方法的0.8%）且具有极高的能量效率（高达DNNs的5倍）。

    In recent years, spiking neural networks (SNNs) have been used in reinforcement learning (RL) due to their low power consumption and event-driven features. However, spiking reinforcement learning (SRL), which suffers from fixed coding methods, still faces the problems of high latency and poor versatility. In this paper, we use learnable matrix multiplication to encode and decode spikes, improving the flexibility of the coders and thus reducing latency. Meanwhile, we train the SNNs using the direct training method and use two different structures for online and offline RL algorithms, which gives our model a wider range of applications. Extensive experiments have revealed that our method achieves optimal performance with ultra-low latency (as low as 0.8% of other SRL methods) and excellent energy efficiency (up to 5X the DNNs) in different algorithms and different environments.
    
[^110]: QuadConv：基于定积分的卷积与非均匀PDE数据压缩的应用

    QuadConv: Quadrature-Based Convolutions with Applications to Non-Uniform PDE Data Compression. (arXiv:2211.05151v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05151](http://arxiv.org/abs/2211.05151)

    本论文提出了一种新的卷积层QuadConv，通过定积分对连续卷积进行近似。该方法适用于非均匀的基于网格的数据，并且在压缩偏微分方程（PDE）模拟数据时表现出与标准离散卷积相当的性能，甚至能够在非均匀数据上保持相同的准确性。QuadConv还优于其他非结构化卷积方法如图卷积。

    

    我们提出了一种新的用于深度学习架构的卷积层，我们将其称为QuadConv——通过定积分对连续卷积进行近似。我们的操作符专门针对非均匀的基于网格的数据进行开发，通过学习一个可以在任意位置进行采样的连续核来实现这一点。此外，我们的操作符的构建还允许高效的实现，我们在文中详细介绍并构造了此实现。作为对我们的操作符的实验验证，我们考虑了从固定网格中压缩偏微分方程（PDE）模拟数据的任务。通过将QuadConv自动编码器（QCAE）与标准卷积自动编码器（CAE）进行比较，我们证明QuadConv能够与标准离散卷积在均匀网格数据上的性能相匹配。此外，我们还展示了QCAE即使在非均匀数据上也能够保持这种准确性。在两种情况下，QuadConv还优于图卷积等其他非结构化卷积方法。

    We present a new convolution layer for deep learning architectures which we call QuadConv -- an approximation to continuous convolution via quadrature. Our operator is developed explicitly for use on non-uniform, mesh-based data, and accomplishes this by learning a continuous kernel that can be sampled at arbitrary locations. Moreover, the construction of our operator admits an efficient implementation which we detail and construct. As an experimental validation of our operator, we consider the task of compressing partial differential equation (PDE) simulation data from fixed meshes. We show that QuadConv can match the performance of standard discrete convolutions on uniform grid data by comparing a QuadConv autoencoder (QCAE) to a standard convolutional autoencoder (CAE). Further, we show that the QCAE can maintain this accuracy even on non-uniform data. In both cases, QuadConv also outperforms alternative unstructured convolution methods such as graph convolution.
    
[^111]: DynamicISP：用于图像识别的动态控制图像信号处理器

    DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition. (arXiv:2211.01146v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.01146](http://arxiv.org/abs/2211.01146)

    DynamicISP是一个动态控制图像信号处理器，能够根据前一帧的识别结果自动调整每帧的参数，实现高精度的单类别和多类别物体检测任务，同时计算成本低。

    

    图像信号处理器（ISPs）在图像识别任务和捕获图像的感知质量中发挥着重要作用。通常情况下，专家们会花费大量精力手动调整ISPs的许多参数，但这些参数是次优的。在文献中，已经积极研究了两种技术：基于机器学习的参数调整技术和基于DNN的ISP技术。前者轻量级但缺乏表现力，后者具有表现力，但在边缘设备上的计算成本太高。为了解决这些问题，我们提出了“DynamicISP”，它由多个传统的ISP函数组成，并根据前一帧的识别结果动态控制每个帧的参数。我们展示了我们的方法成功地控制了多个ISP函数的参数，并在单类别和多类别物体检测任务中以低计算成本实现了最先进的精度。

    Image Signal Processors (ISPs) play important roles in image recognition tasks as well as in the perceptual quality of captured images. In most cases, experts make a lot of effort to manually tune many parameters of ISPs, but the parameters are sub-optimal. In the literature, two types of techniques have been actively studied: a machine learning-based parameter tuning technique and a DNN-based ISP technique. The former is lightweight but lacks expressive power. The latter has expressive power, but the computational cost is too heavy on edge devices. To solve these problems, we propose "DynamicISP," which consists of multiple classical ISP functions and dynamically controls the parameters of each frame according to the recognition result of the previous frame. We show our method successfully controls the parameters of multiple ISP functions and achieves state-of-the-art accuracy with low computational cost in single and multi-category object detection tasks.
    
[^112]: 从相邻的染色组织学片中学习黑色素细胞掩膜

    Learning Melanocytic Cell Masks from Adjacent Stained Tissue. (arXiv:2211.00646v2 [q-bio.QM] UPDATED)

    [http://arxiv.org/abs/2211.00646](http://arxiv.org/abs/2211.00646)

    本文提出了一种从相邻染色组织学片中训练深度神经网络进行黑色素细胞分割的方法，实现了0.64的平均IOU，尽管存在不完美的标签。

    

    黑色素瘤是最具侵袭性的皮肤癌之一，导致大部分皮肤癌死亡。然而，病理学家对黑色素瘤的诊断可靠性较低。由于黑色素瘤是黑色素细胞的肿瘤，需要开发一种与病理学家的差异无关并能自动进行像素级注释的黑色素细胞分割工具。然而，大规模病理学家标注是不现实的。在本文中，我们提出了一种方法，使用邻近组织切片上的偶联免疫组织化学（IHC）染色片，训练深度神经网络进行黑色素细胞分割，虽然很难有完美的标签，但达到了0.64的平均IOU。

    Melanoma is one of the most aggressive forms of skin cancer, causing a large proportion of skin cancer deaths. However, melanoma diagnoses by pathologists shows low interrater reliability. As melanoma is a cancer of the melanocyte, there is a clear need to develop a melanocytic cell segmentation tool that is agnostic to pathologist variability and automates pixel-level annotation. Gigapixel-level pathologist labeling, however, is impractical. Herein, we propose a means to train deep neural networks for melanocytic cell segmentation from hematoxylin and eosin (H&E) stained slides using paired immunohistochemical (IHC) slides of adjacent tissue sections, achieving a mean IOU of 0.64 despite imperfect ground-truth labels.
    
[^113]: TuneUp:一种简单的改进的图神经网络训练策略

    TuneUp: A Simple Improved Training Strategy for Graph Neural Networks. (arXiv:2210.14843v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.14843](http://arxiv.org/abs/2210.14843)

    TuneUp是一种简单的基于课程的训练策略，用于改进图神经网络在难以预测的尾节点上的泛化性能。

    

    尽管图神经网络（GNN）在近期取得了许多进展，但它们的训练策略仍然未被充分探索。传统的训练策略对原始图中的所有节点进行平等学习，这可能是次优的，因为某些节点往往比其他节点更难学习。在这里，我们提出了TuneUp，一种简单的基于课程的训练策略，用于提高GNN的预测性能。TuneUp将GNN分为两个阶段进行训练。在第一阶段，TuneUp应用传统的训练方法，获得一个强大的基础GNN。基础GNN在头节点（具有大度数的节点）上表现良好，但在尾节点（具有小度数的节点）上表现较差。因此，TuneUp的第二阶段侧重于通过进一步训练基础GNN以在难以预测的尾节点上提高预测能力。我们在理论上分析了TuneUp，并证明它能够改善尾节点的泛化性能。TuneUp实现简单，适用于广泛的范围。

    Despite recent advances in Graph Neural Networks (GNNs), their training strategies remain largely under-explored. The conventional training strategy learns over all nodes in the original graph(s) equally, which can be sub-optimal as certain nodes are often more difficult to learn than others. Here we present TuneUp, a simple curriculum-based training strategy for improving the predictive performance of GNNs. TuneUp trains a GNN in two stages. In the first stage, TuneUp applies conventional training to obtain a strong base GNN. The base GNN tends to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). Therefore, the second stage of TuneUp focuses on improving prediction on the difficult tail nodes by further training the base GNN on synthetically generated tail node data. We theoretically analyze TuneUp and show it provably improves generalization performance on tail nodes. TuneUp is simple to implement and applicable to a broad ran
    
[^114]: 分布转移的充分不变学习

    Sufficient Invariant Learning for Distribution Shift. (arXiv:2210.13533v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13533](http://arxiv.org/abs/2210.13533)

    本文研究了分布转移情况下的充分不变学习，观察到之前的工作只学习了部分不变特征，我们提出了学习充分不变特征的重要性，并指出在分布转移时，从训练集中学习的部分不变特征可能不适用于测试集，限制了性能提升。

    

    机器学习算法在各种应用中展现出了卓越的性能。然而，在训练集和测试集的分布不同的情况下，保证性能仍然具有挑战性。为了改善分布转移情况下的性能，已经提出了一些方法，通过学习跨组或领域的不变特征来提高性能。然而，我们观察到之前的工作只部分地学习了不变特征。虽然先前的工作侧重于有限的不变特征，但我们首次提出了充分不变特征的重要性。由于只有训练集是经验性的，从训练集中学习得到的部分不变特征可能不存在于分布转移时的测试集中。因此，分布转移情况下的性能提高可能受到限制。本文认为从训练集中学习充分的不变特征对于分布转移情况至关重要。

    Machine learning algorithms have shown remarkable performance in diverse applications. However, it is still challenging to guarantee performance in distribution shifts when distributions of training and test datasets are different. There have been several approaches to improve the performance in distribution shift cases by learning invariant features across groups or domains. However, we observe that the previous works only learn invariant features partially. While the prior works focus on the limited invariant features, we first raise the importance of the sufficient invariant features. Since only training sets are given empirically, the learned partial invariant features from training sets might not be present in the test sets under distribution shift. Therefore, the performance improvement on distribution shifts might be limited. In this paper, we argue that learning sufficient invariant features from the training set is crucial for the distribution shift case. Concretely, we newly 
    
[^115]: 良性自编码器

    Benign Autoencoders. (arXiv:2210.00637v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00637](http://arxiv.org/abs/2210.00637)

    本文正式化了用于生成式人工智能中编码器-解码器对的最佳选择问题并提出了良性自编码器（BAE），BAE能够将数据投射到最优的流型上，实现了数据压缩和更加稳定的梯度下降。

    

    最近，生成式人工智能取得了很多进展，其中常采用编码器-解码器架构来实现数据的高效表示。本论文正式化了寻找最佳编码器-解码器对的数学问题并表征其解决方案，我们将其命名为“良性自编码器”（BAE）。我们证明BAE将数据投射到一个流型上，其维数为生成问题的最佳可压缩维度。我们强调BAE与人工智能中几个最近发展的方向之间的惊人联系，如有条件的GAN，上下文编码器，稳定扩散，堆叠自编码器和生成模型的学习能力。我们展示了BAE如何找到最优的低维潜在表示，从而在分布转移下提高鉴别器的性能。通过压缩“恶性”数据维度，BAE导致梯度更加平滑和稳定。

    Recent progress in Generative Artificial Intelligence (AI) relies on efficient data representations, often featuring encoder-decoder architectures. We formalize the mathematical problem of finding the optimal encoder-decoder pair and characterize its solution, which we name the "benign autoencoder" (BAE). We prove that BAE projects data onto a manifold whose dimension is the optimal compressibility dimension of the generative problem. We highlight surprising connections between BAE and several recent developments in AI, such as conditional GANs, context encoders, stable diffusion, stacked autoencoders, and the learning capabilities of generative models. As an illustration, we show how BAE can find optimal, low-dimensional latent representations that improve the performance of a discriminator under a distribution shift. By compressing "malignant" data dimensions, BAE leads to smoother and more stable gradients.
    
[^116]: 自然对话中解释机器学习模型：走向对话式XAI代理

    Explaining Machine Learning Models in Natural Conversations: Towards a Conversational XAI Agent. (arXiv:2209.02552v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02552](http://arxiv.org/abs/2209.02552)

    本研究将解释人工智能（XAI）融入到一个对话代理中，设计具有自然语言理解和生成组件的标准模型。通过扩展XAI问题库并提供解释方法，实现了关于机器学习模型的真正自然对话。

    

    可解释人工智能（XAI）的目标是设计方法来揭示黑盒模型（如深度神经网络）的推理过程，以便向人类解释。社会科学研究指出，这样的解释应该是对话式的，类似于人与人之间的解释。在这项工作中，我们展示了如何将XAI融入到一个对话代理中，使用了一个包括自然语言理解和生成组件的标准设计。我们根据质控的释义重述扩展了一个XAI问题库，以理解用户的信息需求。我们进一步系统地调查了适合提供答案信息的解释方法的文献，并提出了一个全面的建议列表。我们的工作是实现关于机器学习模型的真正自然对话的第一步，与一个解释代理有关的全面的XAI问题列表和相应的解释方法。

    The goal of Explainable AI (XAI) is to design methods to provide insights into the reasoning process of black-box models, such as deep neural networks, in order to explain them to humans. Social science research states that such explanations should be conversational, similar to human-to-human explanations. In this work, we show how to incorporate XAI in a conversational agent, using a standard design for the agent comprising natural language understanding and generation components. We build upon an XAI question bank which we extend by quality-controlled paraphrases to understand the user's information needs. We further systematically survey the literature for suitable explanation methods that provide the information to answer those questions, and present a comprehensive list of suggestions. Our work is the first step towards truly natural conversations about machine learning models with an explanation agent. The comprehensive list of XAI questions and the corresponding explanation meth
    
[^117]: TE2Rules: 使用规则解释树集合模型

    TE2Rules: Explaining Tree Ensembles using Rules. (arXiv:2206.14359v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14359](http://arxiv.org/abs/2206.14359)

    本文介绍了一种将二元分类任务中的树集合模型转换为可解释规则列表的方法，该方法可以有效解释模型对于少数类别的预测。实验证明，TE2Rules方法生成的规则列表准确性较高，并且运行时间与其他基线方法相当。

    

    树集合（如梯度提升树）通常相比单棵决策树具有更高的预测性能，然而，树集合模型通常缺乏透明度和可解释性，因为人类难以理解它们的决策逻辑。本文提出一种新颖的方法，将用于二元分类任务的树集合模型转换为接近树集合的可解释规则列表，并且有效地解释模型对于模型预测的少数类别。在基准数据集上的实验表明，TE2Rules生成的规则列表相对于现有方法具有更高的准确性，TE2Rules的运行时间与其他类似基线方法相当，TE2Rules算法的运行时间可以以稍微降低的准确性为代价进行权衡。

    Tree Ensemble (TE) models (like Gradient Boosted Trees) often provide higher prediction performance compared to single decision trees. However, TE models generally lack transparency and interpretability, as humans have difficulty understanding their decision logic. This paper presents a novel approach to convert a TE trained for a binary classification task, to a rule list (RL) that closely approximates the TE and is interpretable for a human. This RL can effectively explain the model even on the minority class predicted by the model. Experiments on benchmark datasets demonstrate that, (i) predictions from the RL generated by TE2Rules have higher fidelity (with respect to the original TE) compared to state-of-the-art methods, (ii) the run-time of TE2Rules is comparable to that of some other similar baselines and (iii) the run-time of TE2Rules algorithm can be traded off at the cost of a slightly lower fidelity.
    
[^118]: ReCo: 一种用于住宅社区布局规划的数据集

    ReCo: A Dataset for Residential Community Layout Planning. (arXiv:2206.04678v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.04678](http://arxiv.org/abs/2206.04678)

    ReCo是一个用于住宅社区布局规划的数据集，用于解决基于数据驱动的方法在该领域面临的数据不足问题。

    

    布局规划在建筑和城市设计领域中非常重要。在承载城市功能的各种基本单位中，住宅社区对支持人类生活起着至关重要的作用。因此，住宅社区的布局规划一直受到关注，并自深度学习问世以来，尤其引起了人们的关注，因为深度学习有助于自动布局生成和空间模式识别。然而，研究领域普遍面临住宅社区布局基准或高质量数据集的不足，这阻碍了基于数据驱动的住宅社区布局规划方法的进一步探索。数据集的缺乏主要是由于大规模实际住宅数据采集和长期专家筛选的困难。为了解决这些问题，并推进智慧城市发展中各种智能空间设计和分析应用的基准数据集，我们提出了一个名为ReCo的数据集。

    Layout planning is centrally important in the field of architecture and urban design. Among the various basic units carrying urban functions, residential community plays a vital part for supporting human life. Therefore, the layout planning of residential community has always been of concern, and has attracted particular attention since the advent of deep learning that facilitates the automated layout generation and spatial pattern recognition. However, the research circles generally suffer from the insufficiency of residential community layout benchmark or high-quality datasets, which hampers the future exploration of data-driven methods for residential community layout planning. The lack of datasets is largely due to the difficulties of large-scale real-world residential data acquisition and long-term expert screening. In order to address the issues and advance a benchmark dataset for various intelligent spatial design and analysis applications in the development of smart city, we in
    
[^119]: Res2NetFuse：一种适用于红外和可见光图像的融合方法

    Res2NetFuse: A Fusion Method for Infrared and Visible Images. (arXiv:2112.14540v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.14540](http://arxiv.org/abs/2112.14540)

    本文提出了一种基于Res2Net的红外和可见光图像融合框架，通过引入新的训练策略和融合策略，实现了最先进的融合性能。

    

    本文提出了一种基于Res2Net的红外和可见光图像融合框架。提出的融合模型包括编码器、融合层和解码器三个部分。利用基于Res2Net的编码器提取源图像的多尺度特征，引入一种新的训练策略，仅使用单个图像进行训练。然后，基于注意力模型开发了一种新的融合策略。最后，通过解码器重构融合图像。本文还对所提出的方法进行了详细分析。实验证明，该方法在客观和主观评估中都实现了最先进的融合性能，与现有方法进行了比较。

    This paper presents a novel Res2Net-based fusion framework for infrared and visible images. The proposed fusion model has three parts: an encoder, a fusion layer and a decoder, respectively. The Res2Net-based encoder is used to extract multi-scale features of source images, the paper introducing a new training strategy for training a Res2Net-based encoder that uses only a single image. Then, a new fusion strategy is developed based on the attention model. Finally, the fused image is reconstructed by the decoder. The proposed approach is also analyzed in detail. Experiments show that our method achieves state-of-the-art fusion performance in objective and subjective assessment by comparing with the existing methods.
    
[^120]: CDistNet：感知多域字符距离的鲁棒文本识别

    CDistNet: Perceiving Multi-Domain Character Distance for Robust Text Recognition. (arXiv:2111.11011v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2111.11011](http://arxiv.org/abs/2111.11011)

    本文提出了一种名为多域字符距离感知（MDCDP）的新颖模块，用于解决场景文本识别中特征和字符对齐不准确的问题。该模块通过交叉注意机制融合视觉和语义特征，并生成一个内容感知嵌入来感知字符位置。

    

    基于Transformer的编码-解码框架在场景文本识别中越来越流行，主要是因为它能够自然地整合来自视觉和语义领域的识别线索。然而，最近的研究表明这两种线索并不总是很好地注册，因此在困难文本（例如，具有罕见形状的文本）中，特征和字符可能不对齐。因此，引入了字符位置等约束来缓解这个问题。尽管在一定程度上取得了成功，但视觉和语义仍然是分别建模的，它们之间只是松散关联。在本文中，我们提出了一个新颖的模块，称为多域字符距离感知（MDCDP），用于建立一个视觉上和语义上相关的位置嵌入。MDCDP使用位置嵌入通过交叉注意机制查询视觉和语义特征。这两种线索被融合到位置分支中，生成一个能够很好地感知字符的内容感知嵌入。

    The Transformer-based encoder-decoder framework is becoming popular in scene text recognition, largely because it naturally integrates recognition clues from both visual and semantic domains. However, recent studies show that the two kinds of clues are not always well registered and therefore, feature and character might be misaligned in difficult text (e.g., with a rare shape). As a result, constraints such as character position are introduced to alleviate this problem. Despite certain success, visual and semantic are still separately modeled and they are merely loosely associated. In this paper, we propose a novel module called Multi-Domain Character Distance Perception (MDCDP) to establish a visually and semantically related position embedding. MDCDP uses the position embedding to query both visual and semantic features following the cross-attention mechanism. The two kinds of clues are fused into the position branch, generating a content-aware embedding that well perceives characte
    
[^121]: 网络、游戏和学习的融合

    The Confluence of Networks, Games and Learning. (arXiv:2105.08158v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2105.08158](http://arxiv.org/abs/2105.08158)

    这篇论文讨论了网络、游戏和学习的融合，为理解网络上多智能体决策制定提供了理论基础，并提供了选择性的博弈理论学习算法概述和在现代网络系统中的应用。

    

    近年来，现代网络应用的技术和服务取得了显著进展，包括智能电网管理、无线通信、网络安全以及多智能体自主系统。考虑到网络实体的异构性，新兴网络应用需要博弈理论模型和基于学习的方法，以创建对动态或对抗环境中的不确定性和干扰作出响应的分布式网络智能。本文阐述了网络、游戏和学习的融合，为理解网络上多智能体决策制定奠定了理论基础。我们在随机逼近理论的框架内提供了博弈理论学习算法的选择性概述，并介绍了在现代网络系统的一些代表性场景中的应用，例如下一代无线通信网络、智能电网。

    Recent years have witnessed significant advances in technologies and services in modern network applications, including smart grid management, wireless communication, cybersecurity as well as multi-agent autonomous systems. Considering the heterogeneous nature of networked entities, emerging network applications call for game-theoretic models and learning-based approaches in order to create distributed network intelligence that responds to uncertainties and disruptions in a dynamic or an adversarial environment. This paper articulates the confluence of networks, games and learning, which establishes a theoretical underpinning for understanding multi-agent decision-making over networks. We provide an selective overview of game-theoretic learning algorithms within the framework of stochastic approximation theory, and associated applications in some representative contexts of modern network systems, such as the next generation wireless communication networks, the smart grid and distribute
    
[^122]: 行人属性识别: 一项调查

    Pedestrian Attribute Recognition: A Survey. (arXiv:1901.07474v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/1901.07474](http://arxiv.org/abs/1901.07474)

    本文回顾了行人属性识别的现有作品，介绍了行人属性识别的背景、基准、多任务学习和多标签学习的概念，以及流行的网络架构和解决方案。

    

    由于在视频监控中起着重要作用，识别行人属性是计算机视觉领域的一项重要任务。许多算法已被提出来处理这个任务。本文的目标是回顾使用传统方法或基于深度学习网络的现有作品。首先，我们介绍行人属性识别的背景，包括行人属性的基本概念和相应的挑战。其次，我们介绍现有的基准，包括流行的数据集和评估标准。第三，我们分析了多任务学习和多标签学习的概念，并解释了这两种学习算法与行人属性识别之间的关系。我们还回顾了在深度学习社区中广泛应用的一些流行网络架构。第四，我们分析了此任务的流行解决方案，如属性组和基于部分的方法等。

    Recognizing pedestrian attributes is an important task in the computer vision community due to it plays an important role in video surveillance. Many algorithms have been proposed to handle this task. The goal of this paper is to review existing works using traditional methods or based on deep learning networks. Firstly, we introduce the background of pedestrian attribute recognition (PAR, for short), including the fundamental concepts of pedestrian attributes and corresponding challenges. Secondly, we introduce existing benchmarks, including popular datasets and evaluation criteria. Thirdly, we analyze the concept of multi-task learning and multi-label learning and also explain the relations between these two learning algorithms and pedestrian attribute recognition. We also review some popular network architectures which have been widely applied in the deep learning community. Fourthly, we analyze popular solutions for this task, such as attributes group, part-based, etc. Fifthly, we 
    
[^123]: 深度学习的泛化问题

    Generalization in Deep Learning. (arXiv:1710.05468v8 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1710.05468](http://arxiv.org/abs/1710.05468)

    本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，提出了一些新的开放问题，并讨论了研究结果的局限性。

    

    本文从理论上解释了为什么以及如何深度学习能够在容量大、复杂性高、可能存在算法不稳定性、非鲁棒性和尖锐极小值的情况下实现良好的泛化，回应了文献中的一个开放问题。我们还讨论了提供深度学习非虚空泛化保证的方法。基于理论观察，我们提出了一些新的开放问题，并讨论了我们研究结果的局限性。

    This paper provides theoretical insights into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, responding to an open question in the literature. We also discuss approaches to provide non-vacuous generalization guarantees for deep learning. Based on theoretical observations, we propose new open problems and discuss the limitations of our results.
    

