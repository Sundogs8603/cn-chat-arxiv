# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents.](http://arxiv.org/abs/2401.12963) | AutoRT是一个利用现有的基础模型来扩展机器人在未知场景中的部署的系统，通过利用视觉-语言模型和大型语言模型，提出多样化和新颖的指令，并有效地推理自主权和安全性的权衡。 |
| [^2] | [Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding.](http://arxiv.org/abs/2401.12954) | 元提示是一种支持技术，将单个语言模型转化为多面手指挥者，通过高级指令将复杂任务分解为子任务，并由不同的专家模型处理，最终提高效率。 |
| [^3] | [Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion.](http://arxiv.org/abs/2401.12947) | 本论文研究了基于Transformer模型学习结构递归的能力，介绍了一个通用框架，将编程语言领域中的抽象概念与具体的序列建模问题和学习模型行为相连接。 |
| [^4] | [Truck Parking Usage Prediction with Decomposed Graph Neural Networks.](http://arxiv.org/abs/2401.12920) | 提出了Regional Temporal Graph Neural Network (RegT-GCN)作为一个预测框架，用于评估整个州的卡车停车使用情况，以提供更准确的停车信息并缓解未经授权的停车问题。 |
| [^5] | [Active Inference as a Model of Agency.](http://arxiv.org/abs/2401.12917) | 本文展示了使用主动推断作为规范性贝叶斯框架来模拟和建模机构的方法，通过最小化风险和对世界状态的不确定性来整合探索与开发。这种方法是广泛应用于行为神经科学、强化学习和机器人技术领域的方法。 |
| [^6] | [Red Teaming Visual Language Models.](http://arxiv.org/abs/2401.12915) | 本论文通过提供一个新颖的红队数据集RTVLM，评估了当前视觉语言模型VLMs在忠实度、隐私、安全和公平性方面的性能，并与GPT-4V进行了比较。结果显示，10个知名的VLMs在红队行动中存在不同程度的困难。 |
| [^7] | [Emergent Communication Protocol Learning for Task Offloading in Industrial Internet of Things.](http://arxiv.org/abs/2401.12914) | 本文提出了一种利用多智能体强化学习框架来解决工业物联网中任务卸载问题的新型通信协议学习方法，实验证明该方法能够提高信道接入成功率和成功计算任务的数量，并且胜过现有的远程计算和本地计算方法。 |
| [^8] | [From Understanding to Utilization: A Survey on Explainability for Large Language Models.](http://arxiv.org/abs/2401.12874) | 本综述论文研究了大规模语言模型(LLMs)可解释性的新兴领域，强调了在LLMs中增强可解释性的必要性，同时解决了广大公众对其信任和技术界对这些模型更深理解的需求。该综述对现有的可解释性方法进行分类，并讨论了它们在提高模型透明度和可靠性方面的应用，旨在弥合理论理解和实际应用之间的差距。 |
| [^9] | [Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model.](http://arxiv.org/abs/2401.12873) | 本研究探索了利用质量估计作为奖励模型来预测人类偏好以改善机器翻译的潜力。我们发现基于质量估计的反馈训练存在过度优化问题，采用启发式规则来检测错误翻译并对质量估计模型进行惩罚以解决该问题。 |
| [^10] | [TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks.](http://arxiv.org/abs/2401.12869) | 本研究提出了一种名为TROVE的方法，它能够通过生成、使用、扩展和定期修剪工具箱，引导生成可验证和高效的函数工具箱。与其他基准方法相比，TROVE在解决各种任务时能够产生更简单且更准确的解决方案，同时减小了工具箱的体积，并且能够实现更快速和更准确的人工验证。此外，TROVE还能够为不同的任务和数据集创建多样化的函数，提供洞见。 |
| [^11] | [Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing.](http://arxiv.org/abs/2401.12866) | 移动众包系统中任务分配和质量问题引起了研究者的关注。本文提出了一种基于数据流学习的方法来预测任务结果，并通过任务转移来解决任务分配中的问题。这些机制有助于提高移动众包系统的服务质量。 |
| [^12] | [KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning.](http://arxiv.org/abs/2401.12863) | KAM-CoT是一个知识增强的多模式思维链推理框架，可以通过引入外部知识图谱来提高模型对多模式任务的理解能力，并生成更准确的答案。 |
| [^13] | [FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units.](http://arxiv.org/abs/2401.12862) | FedRSU是一种创新的联邦学习框架，用于自监督场景流估计，它通过整合RSU收集的数据，采用循环自监督训练范式来提高模型的准确性和稳定性。 |
| [^14] | [Classification of grapevine varieties using UAV hyperspectral imaging.](http://arxiv.org/abs/2401.12851) | 该研究提出了一种使用无人机高光谱成像对17种红白葡萄品种进行分类的方法，相比于传统的破坏性方法，这种方法更高效和 less prohibitive，能够纠正和降低大量数据的采样率，并且能够处理葡萄品种高度相似的高光谱特征。 |
| [^15] | [Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization.](http://arxiv.org/abs/2401.12850) | 本文提出了一种针对演讲者分割的端到端监督分层图聚类算法，使用图神经网络进行表示学习、度量学习和聚类，并通过外部重叠检测器提供额外的输入。 |
| [^16] | [How well can large language models explain business processes?.](http://arxiv.org/abs/2401.12846) | 该论文介绍了一个用于生成业务流程解释的SAX4BPM框架，该框架通过与大型语言模型（LLM）集成来综合各种输入要素，以提供更好的情境感知解释（SAX）。 |
| [^17] | [SGTR+: End-to-end Scene Graph Generation with Transformer.](http://arxiv.org/abs/2401.12835) | 本论文提出了一种基于Transformer的端到端场景图生成方法，通过解决二分图构建问题，实现了实体和谓词候选集的生成和关系三元组的推断，并设计了图组装模块推断二分图的连通性，从而实现了场景图的端到端生成。 |
| [^18] | [Enhancing Next Destination Prediction: A Novel LSTM Approach Using Real-World Airline Data.](http://arxiv.org/abs/2401.12830) | 提出了一种新颖的基于LSTM的模型架构，通过准确捕捉旅行数据中的序列模式和依赖关系，实现了对个人旅行者未来目的地的准确预测。实验结果表明该模型在不同数据规模和性能指标上表现出色，为提升目的地预测方法做出了贡献，并使公司能够提供个性化推荐和优化客户体验。 |
| [^19] | [Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms.](http://arxiv.org/abs/2401.12822) | 本研究使用深度强化学习算法创建了磷去除过程控制的模拟器，通过试错来学习控制策略。然而，模拟器的性能在更长时间范围内受到模型误差累积的限制。 |
| [^20] | [Dynamic Layer Tying for Parameter-Efficient Transformers.](http://arxiv.org/abs/2401.12819) | 本论文提出了一种动态层绑定的方法，通过使用强化学习动态选择层并将它们绑定在一起，来减少深度Transformer网络中的可训练参数数量并提高性能。 |
| [^21] | [Binary structured physics-informed neural networks for solving equations with rapidly changing solutions.](http://arxiv.org/abs/2401.12806) | 本论文提出了一种二进制结构的物理信息神经网络框架，通过利用二进制结构来捕捉局部特征，并解决了传统物理信息神经网络在处理具有快速变化解的方程时的困难。 |
| [^22] | [Enhancements for 5G NR PRACH Reception: An AI/ML Approach.](http://arxiv.org/abs/2401.12803) | 这项研究提出了一种基于AI/ML的方法来增强5G NR PRACH接收，通过使用两个神经网络分别估计RAPID和TA，与传统相关方法相比，实验证明了这种方法在性能上的改进。 |
| [^23] | [A Review of Deep Learning Methods for Photoplethysmography Data.](http://arxiv.org/abs/2401.12783) | 本综述系统地回顾了自2017年至2023年期间应用深度学习模型处理光电容积法数据的论文。研究发现，深度学习在个人健康管理和其他应用中具有显著成果。根据任务的不同，这些论文被分为医学相关和非医学相关两大类别，医学相关又细分为七个子组，包括血压分析... |
| [^24] | [Deep Learning-based Intraoperative MRI Reconstruction.](http://arxiv.org/abs/2401.12771) | 本研究评估了基于深度学习的术中磁共振成像重建方法在脑肿瘤手术中的质量，并与传统的压缩感知方法进行了比较。结果表明，深度学习重建方法在质量上表现优异。 |
| [^25] | [What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition.](http://arxiv.org/abs/2401.12756) | 本研究提出了一个新的零样本模块组合框架，统一了选择、加权和组合参数模块的各种变化。以领域知识和适配器层为场景，通过系统化的统一概念，进行了首次全面的零样本知识组合的基准研究。 |
| [^26] | [The Distributional Uncertainty of the SHAP score in Explainable Machine Learning.](http://arxiv.org/abs/2401.12731) | 本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。 |
| [^27] | [Evaluation of large language models for assessing code maintainability.](http://arxiv.org/abs/2401.12714) | 本文评估大规模语言模型用于评估代码可维护性，发现通过比较生成的代码的概率与当前代码可能具有的概率可以指示潜在的质量问题，且交叉熵是可维护性的预测因子。 |
| [^28] | [Deep Neural Network Benchmarks for Selective Classification.](http://arxiv.org/abs/2401.12708) | 本论文研究了用于选择性分类的深度神经网络，目的是设计一种选择机制来平衡被拒绝的预测比例和所选预测的预测性能改进。 |
| [^29] | [Securing Recommender System via Cooperative Training.](http://arxiv.org/abs/2401.12700) | 本研究提出了一种综合数据处理和鲁棒模型的通用框架来保护推荐系统，并引入了一种高效的攻击策略。研究揭示了现有攻击威胁不足的原因。 |
| [^30] | [Energy-based Automated Model Evaluation.](http://arxiv.org/abs/2401.12689) | 提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。 |
| [^31] | [Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach.](http://arxiv.org/abs/2401.12686) | 这篇论文提出了一种在稀疏图上学习平均场对局博弈的新方法，通过引入图形扩展的概念，解决了现有方法对于稀疏网络拓扑结构的限制。 |
| [^32] | [Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning.](http://arxiv.org/abs/2401.12681) | 这篇论文提出了一种新的对比性典型学习方法，用于改进Kriging过程中邻居和非邻居的信息利用，从而提高属性估计的准确性。 |
| [^33] | [ChatGraph: Chat with Your Graphs.](http://arxiv.org/abs/2401.12672) | ChatGraph是一个基于大型语言模型的框架，它使用户能够通过自然语言与图进行交互，比传统方法更加简单和灵活。ChatGraph通过生成图分析API链来实现对用户输入的文本和图像的理解。 |
| [^34] | [EL-VIT: Probing Vision Transformer with Interactive Visualization.](http://arxiv.org/abs/2401.12666) | 本文介绍了EL-VIT，一个交互式可视化系统，旨在探测视觉变压器并促进对其操作的更好理解。 |
| [^35] | [ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation.](http://arxiv.org/abs/2401.12665) | 这项工作提出了一种名为ClipSAM的CLIP和SAM协作框架，用于零样本异常分割。ClipSAM利用CLIP的语义理解能力进行异常定位和粗糙分割，然后将其用作SAM的提示约束，进一步改进异常分割结果。 |
| [^36] | [Integrating Human Expertise in Continuous Spaces: A Novel Interactive Bayesian Optimization Framework with Preference Expected Improvement.](http://arxiv.org/abs/2401.12662) | 提出了一种将人类专业知识与机器学习相结合的新型交互式贝叶斯优化框架，通过捕捉用户偏好和引入新的收益函数提高机器学习系统的效率。 |
| [^37] | [Emergent Cooperation under Uncertain Incentive Alignment.](http://arxiv.org/abs/2401.12646) | 本研究研究了在存在不确定的激励一致性情况下，如何训练强化学习代理人在不频繁交互的情况下建立合作行为。研究发现，不确定性明显降低了代理人从事合作行为的能力。 |
| [^38] | [Modeling Resilience of Collaborative AI Systems.](http://arxiv.org/abs/2401.12632) | 本文提供了一个新的框架，用于建模碰撞化人工智能系统在遇到不利事件时的性能。 |
| [^39] | [A Reply to Makelov et al. (2023)'s "Interpretability Illusion" Arguments.](http://arxiv.org/abs/2401.12631) | 本文回应了Makelov等人(2023)的论文，该论文评述了子空间交换干预方法的"解释性错觉"问题。我们指出，所谓的"解释性错觉"可以包括直观和可取的解释，而Makelov等人(2023)发现的"错觉"是他们训练和评估范例的产物。尽管我们不同意他们的核心表述，但他们的例子和讨论推动了可解释性领域的发展。 |
| [^40] | [Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control.](http://arxiv.org/abs/2401.12624) | 这项工作通过将语言导向的语义通信与新兴通信相结合，通过知识蒸馏的方式，提出了一种面向多智能体远程控制的新框架，实现了更快的行程时间和更高的训练收敛速度。 |
| [^41] | [Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition.](http://arxiv.org/abs/2401.12599) | 本论文通过增强的PDF结构识别来革新检索增强的生成模型，解决了专业文档中PDF解析的低准确性对基于专业知识问答的影响，提高了问答的准确性和效率。 |
| [^42] | [MOReGIn: Multi-Objective Recommendation at the Global and Individual Levels.](http://arxiv.org/abs/2401.12593) | MOReGIn是一种多目标推荐系统，可以同时在全局和个体层面上满足多个目标。通过调节推荐列表，MORS可以保证推荐的流派校准和供应商公平性。验证实验表明了该方法的有效性。 |
| [^43] | [LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools.](http://arxiv.org/abs/2401.12576) | LLMCheckup是一个可解释性工具，通过连接大型语言模型与可解释的AI工具，使用户能够与模型进行对话，生成自我解释并提供建议。 |
| [^44] | [DiffMoog: a Differentiable Modular Synthesizer for Sound Matching.](http://arxiv.org/abs/2401.12570) | DiffMoog是一个可微分的模块化合成器，可以集成到神经网络中，实现自动化的声音匹配。它具有调制能力、低频振荡器、滤波器和包络形状器等功能，并且用户可以创建自定义信号链。该研究还提出了一个基于信号链损失和编码器网络的端到端声音匹配框架，为使用可微分合成进行声音匹配的研究提供了见解和经验教训。 |
| [^45] | [Balancing the AI Strength of Roles in Self-Play Training with Regret Matching+.](http://arxiv.org/abs/2401.12557) | 通过引入后悔匹配+，本论文提出了一种简单的方法来平衡自博弈训练中不同角色的AI能力。 |
| [^46] | [Can Large Language Models Write Parallel Code?.](http://arxiv.org/abs/2401.12554) | 本文研究了大型语言模型生成并行代码的能力。我们提出了一个基准测试集PCGBench，并使用新指标评估了几个最先进的语言模型在并行编程模型和计算问题类型上的性能。 |
| [^47] | [UR4NNV: Neural Network Verification, Under-approximation Reachability Works!.](http://arxiv.org/abs/2401.12550) | 本文提出了UR4NNV验证框架，利用欠估计可达性分析进行DNN验证。该框架对具有ReLU激活的DNN进行欠估计，并通过试错方法有效地证伪DNN属性。 |
| [^48] | [Efficient Constrained $k$-Center Clustering with Background Knowledge.](http://arxiv.org/abs/2401.12533) | 本论文提出了一种在k中心聚类上利用背景知识的约束聚类算法，通过采用一系列技术，得到了效率高且具有最佳近似比例2的算法。 |
| [^49] | [DAFA: Distance-Aware Fair Adversarial Training.](http://arxiv.org/abs/2401.12532) | DAFA通过考虑类别之间的相似性，引入了不同的损失权重和对抗边界，并调整它们以提高在对抗训练中的鲁棒公平性。 |
| [^50] | [BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models.](http://arxiv.org/abs/2401.12522) | BiTA是一种用于大语言模型的创新方法，通过双向调整实现了无损加速。它采用简化的半自回归生成和草稿验证，通过高效的基于树的解码同时进行候选生成和验证，提高了推理效率。这种方法不需要额外的辅助模型或显著的额外内存开销。 |
| [^51] | [Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR.](http://arxiv.org/abs/2401.12513) | 该论文使用YOLOv8、DeiT和SimCLR在希腊纸草中进行字符检测和识别竞赛，在识别挑战中获得了42.2%的mAP，并在检测挑战中以51.4%的平均精度获得了亚军。 |
| [^52] | [Building Minimal and Reusable Causal State Abstractions for Reinforcement Learning.](http://arxiv.org/abs/2401.12497) | 本文介绍了一种称为Causal Bisimulation Modeling (CBM)的方法，该方法通过学习动态和奖励函数中的因果关系来构建最小和可重用的任务特定抽象。实证验证表明，CBM学习到的隐式动态模型比显式模型更准确地识别出底层的因果关系和状态抽象。 |
| [^53] | [Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?.](http://arxiv.org/abs/2401.12492) | 本研究比较了以群体属性、个体用户和组合方法来模拟人的上下文。合并群体和个体特征显著提高了用户级回归任务的性能，而模拟个体用户则显著提高了单个文档级分类任务的性能。 |
| [^54] | [Assessing and Understanding Creativity in Large Language Models.](http://arxiv.org/abs/2401.12491) | 本文旨在建立一个评估大型语言模型（LLM）创造力水平的高效框架，并提出了评估方法和一个包含700个问题的全面数据集。研究发现创造力水平受到任务差异和LLM模型参数的影响。 |
| [^55] | [Unsupervised Learning Method for the Wave Equation Based on Finite Difference Residual Constraints Loss.](http://arxiv.org/abs/2401.12489) | 本文提出了一种新型的无监督学习方法，通过基于有限差分残差约束的波动方程，解决了现有深度学习方法中存在的问题。该方法具有高效、低成本和强泛化能力，并通过实验证明其优于传统的物理感知神经网络。 |
| [^56] | [Adiabatic Quantum Support Vector Machines.](http://arxiv.org/abs/2401.12485) | 本文描述了一种用于训练支持向量机的绝热量子方法，与经典方法相比，我们的方法在时间复杂度上取得了一个数量级的改进，并且在五个基准数据集上取得了与经典方法相当的测试准确率。我们还展示了我们的方法具有良好的可扩展性。 |
| [^57] | [Mini-batch Submodular Maximization.](http://arxiv.org/abs/2401.12478) | 我们提出了第一个小批量算法，用于在约束条件下最大化非负单调可分解的子模函数F，该算法在实践中比基于稀疏化方法的做法更好。 |
| [^58] | [Reinforcement Learning for Graph Coloring: Understanding the Power and Limits of Non-Label Invariant Representations.](http://arxiv.org/abs/2401.12470) | 本论文将寄存器分配问题转化为图着色问题，并展示了Proximal Policy Optimization模型通过学习解决图着色问题。同时，我们还发现图的标记对模型性能至关重要，并提出了机器学习模型需要具有标签重新排序不变性的图表示。 |
| [^59] | [An open dataset for the evolution of oracle bone characters: EVOBC.](http://arxiv.org/abs/2401.12467) | 本研究收集了古代字符数据集，揭示了甲骨文字符在六个历史阶段的演变过程，为解读甲骨文铭文提供了有价值的资源。 |
| [^60] | [Towards Socially and Morally Aware RL agent: Reward Design With LLM.](http://arxiv.org/abs/2401.12459) | 本文研究了利用大型语言模型的理解能力，以遵循社会和道德规范，在强化学习中进行安全探索，并将语言模型的结果作为直接奖励信号。 |
| [^61] | [Exploration and Improvement of Nerf-based 3D Scene Editing Techniques.](http://arxiv.org/abs/2401.12456) | 这篇论文探索了基于NeRF的3D场景编辑技术，通过结合其他模型进一步扩展了NeRF的编辑能力，实现了实时编辑反馈、多模态编辑、4D合成性能等功能。 |
| [^62] | [Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management.](http://arxiv.org/abs/2401.12455) | 这项研究提出了一种基于集中训练和分散执行的多Agent深度强化学习框架，用于管理交通基础设施系统的整个生命周期，在处理高维度空间中的不确定性和约束条件时能够降低长期风险和成本。 |
| [^63] | [Methods and strategies for improving the novel view synthesis quality of neural radiation field.](http://arxiv.org/abs/2401.12451) | 这项研究总结了神经辐射场技术在提高图像渲染质量方面的各种方法和策略，为研究人员提供了当前状态和未来演化方向的理解，从而推动NeRF技术在相关领域的应用。 |
| [^64] | [Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network.](http://arxiv.org/abs/2401.12435) | 本文提出了一种使用物理信息神经网络对细胞外间隙中分子传输进行定量分析的新方法，解决了对分子传输形式不清楚的挑战，并实现了自动计算扩散系数和分子速度的优化功能。 |
| [^65] | [AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space.](http://arxiv.org/abs/2401.12421) | AdaEmbed是一种在嵌入空间中进行半监督领域自适应的新方法，通过学习共享的嵌入空间以及生成准确且统一的伪标签，该方法显著提高了性能，并在多个基准数据集上超过了传统方法。 |
| [^66] | [Enhancing In-context Learning via Linear Probe Calibration.](http://arxiv.org/abs/2401.12406) | 本研究提出了一种名为线性探测校准（LinC）的技术，通过校准模型的输出概率，显著提高了上下文学习（ICL）在生成预训练变压器（GPT）模型上的测试性能。 |
| [^67] | [A Learning-based Declarative Privacy-Preserving Framework for Federated Data Management.](http://arxiv.org/abs/2401.12393) | 本论文提出了一个基于学习的声明性隐私保护框架，通过使用Differentially-Private Stochastic Gradient Descent（DP-SGD）算法训练的深度学习模型替代部分实际数据来回答查询，并允许用户指定要保护的私人信息。此框架还可以自动选择转换计划和超参数，并允许人工专家审核和调整隐私保护机制。 |
| [^68] | [Evaluating Roadside Perception for Autonomous Vehicles: Insights from Field Testing.](http://arxiv.org/abs/2401.12392) | 本文介绍了一种专门设计用于评估路边感知系统性能的综合评估方法，该方法通过现实世界的实地测试来确保实际适用性，并在控制测试环境中评估了各种现成的感知系统。 |
| [^69] | [Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis.](http://arxiv.org/abs/2401.12379) | 本论文研究了大型语言模型在文本转SQL合成中的有效性，通过对比两种方法，发现微调gpt-3.5-turbo-16k + gpt-4-turbo模型的执行准确率较高，达到82.1%。同时，对错误查询进行分类分析，找出错误的原因。 |
| [^70] | [Development of an NLP-driven computer-based test guide for visually impaired students.](http://arxiv.org/abs/2401.12375) | 本文介绍了一种为视力障碍学生开发的基于NLP的计算机化测试指南，利用语音技术和NLP技术实时提供支持和帮助，并将文本问题和选项转化为机器可读的格式。 |
| [^71] | [OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for Generalized and Robust Retinal Disease Detection.](http://arxiv.org/abs/2401.12344) | OCT-SelfNet是一种用于眼科疾病检测的自监督机器学习框架，通过结合多模态数据集和两阶段训练方法，实现了广义和鲁棒的检测结果。 |
| [^72] | [Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation.](http://arxiv.org/abs/2401.12340) | 本论文提出了一种基于对比学习和循环一致性的混合非配对域转换网络（H-CUT）来解决自动目标识别（ATR）中标记数据不足的问题。该方法在跨领域转导迁移学习中取得了显著低的FID分数，并通过注意力和熵来强调领域特定区域，以生成高质量的合成图像。 |
| [^73] | [Towards a prioritised use of transportation infrastructures: the case of vehicle-specific dynamic access restrictions to city centres.](http://arxiv.org/abs/2401.12329) | 这项研究提出了一种基于社会效益的动态优先分配稀缺交通基础设施的方法，以解决城市交通问题。 |
| [^74] | [Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection.](http://arxiv.org/abs/2401.12326) | 本文研究了对多生成器、多领域和多语言机器生成文本的大型语言模型进行微调的任务。实验结果显示，转换器模型特别是LoRA-RoBERTa在效果上超过了传统的机器学习方法，对于多语言环境下的机器生成文本识别，多数投票方法尤为有效。 |
| [^75] | [Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis.](http://arxiv.org/abs/2401.12324) | 本文提出了在法律分析基础上简化先进的出租车调度策略的方法，并强调了在利用人工智能方法和工具进行原型实现时需要充分考虑法律和伦理问题。 |
| [^76] | [Smart Recommendations for Renting Bikes in Bike Sharing Systems.](http://arxiv.org/abs/2401.12322) | 这项研究主要关注共享单车系统中的租车智能推荐问题，旨在解决车辆可用性不均衡的挑战。 |
| [^77] | [GRATH: Gradual Self-Truthifying for Large Language Models.](http://arxiv.org/abs/2401.12292) | GRATH是一种逐步自我真实化的方法，用于提高大型语言模型的真实性。它通过使用领域外问题提示生成答案，并通过直接偏好优化进行自适应模型优化。GRATH在没有标注答案的情况下以自我监督的方式学习真实性，并通过迭代优化来逐步提升模型真实性。 |
| [^78] | [Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation.](http://arxiv.org/abs/2401.12275) | 本文提出了一种多Agent动态关系推理方法，通过明确推断关系结构的演化，来实现在社交机器人导航中的有效性。方法包括推断超边缘以实现群体推理和轨迹预测器生成未来状态。 |
| [^79] | [The Ethics of Interaction: Mitigating Security Threats in LLMs.](http://arxiv.org/abs/2401.12273) | 本研究全面探讨了与语言学习模型（LLMs）面临的安全威胁相关的伦理挑战。分析了五种主要威胁的伦理后果，并强调了确保这些系统在伦理规范范围内运作的紧迫性。 |
| [^80] | [Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks.](http://arxiv.org/abs/2401.12261) | 本文提出了一种综合流程，用于对AI视觉模型在开放存储库中的质量属性进行分析，尤其是在面对对抗攻击时的表现。我们展示了一个涉及六个计算机视觉模型的评估场景，以评估准确性、鲁棒性、解释效用和开销。 |
| [^81] | [Agreement Technologies for Coordination in Smart Cities.](http://arxiv.org/abs/2401.12259) | 该论文介绍了协议技术在智能城市中的协调应用，以解决智能交通、智能能源网格和参与性治理等领域中的挑战。这些技术基于协议概念，通过开发开放的多agent系统来实现协调。 |
| [^82] | [Emergent Dominance Hierarchies in Reinforcement Learning Agents.](http://arxiv.org/abs/2401.12258) | 本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。 |
| [^83] | [Instructional Fingerprinting of Large Language Models.](http://arxiv.org/abs/2401.12255) | 这项研究提出了一种指纹识别大型语言模型的方法，通过轻量级的指令调整，保护知识产权并确保遵守许可条款。实验证明这种方法不影响模型的正常行为，并且具有鲁棒性和高效训练的特点。 |
| [^84] | [Exploring consumers response to text-based chatbots in e-commerce: The moderating role of task complexity and chatbot disclosure.](http://arxiv.org/abs/2401.12247) | 本研究探索了消费者对电子商务中基于文本的聊天机器人的反应，发现共情和友好度对信任产生积极影响，任务复杂性和聊天机器人披露对这些影响具有调节作用。 |
| [^85] | [Large-scale Reinforcement Learning for Diffusion Models.](http://arxiv.org/abs/2401.12244) | 本文介绍了一种大规模强化学习算法，用于改进文本到图像的扩散模型，能够提高模型与人类偏好的一致性，并生成更受人类喜欢的样本。 |
| [^86] | [LLM4EDA: Emerging Progress in Large Language Models for Electronic Design Automation.](http://arxiv.org/abs/2401.12224) | LLMs have shown promising potential in achieving fully automated chip design and generating circuits with improved power, performance, and area (PPA) in the field of Electronic Design Automation (EDA). (翻译为：LLM在电子设计自动化（EDA）领域显示出了实现全自动化芯片设计和生成具有改进功耗、性能和面积（PPA）的电路的潜力) |
| [^87] | [The Global Impact of AI-Artificial Intelligence: Recent Advances and Future Directions, A Review.](http://arxiv.org/abs/2401.12223) | 人工智能是一项新兴技术，有潜力改变社会的多个方面，但也存在经济、道德、社会、安全与隐私以及就业方面的风险和挑战。为了确保AI的负责任发展与应用，政府、行业和学术界之间的合作以及公众的参与和教育至关重要。 |
| [^88] | [BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge.](http://arxiv.org/abs/2401.11851) | 二值化Transformer在边缘部署中有潜力，但面临QMM执行效率低和能耗开销高的挑战。本研究提出了一种计算流抽象方法优化QMM执行效率，并开发了一种二值化节能Transformer加速器BETA，具有可配置的高并行性和高能效的QMM引擎。实验结果表明BETA在ZCU102 FPGA上实现了平均能效。 |
| [^89] | [Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations.](http://arxiv.org/abs/2401.11792) | 本文介绍了一种安全且广义的端到端自主驾驶系统 (SGADS)，使用强化学习和示范相结合的方法解决了现有方法的低安全性、泛化能力差和采样效率低的问题，同时引入了变分推理和归一化流以准确预测驾驶轨迹，并提出了鲁棒性安全约束的制定方法。 |
| [^90] | [GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?.](http://arxiv.org/abs/2401.11748) | 本文提出了一种新颖的梯度反转攻击方法GI-PIP，不需要依赖不切实际的辅助数据集，通过利用异常检测模型从较少的数据中捕获底层分布，并能在图像恢复方面表现出优异的能力，同时在分布泛化方面也更强大。 |
| [^91] | [In-context Learning with Retrieved Demonstrations for Language Models: A Survey.](http://arxiv.org/abs/2401.11624) | 本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。 |
| [^92] | [ChatQA: Building GPT-4 Level Conversational QA Models.](http://arxiv.org/abs/2401.10225) | ChatQA是一系列对话问答模型，可以达到GPT-4级别的准确性。通过两阶段的指令调整方法，可以显著提高大型语言模型在零-shot对话问答中的结果。使用密集检索器进行问答数据集的微调可以实现与最先进的查询重写模型相当的结果，同时降低部署成本。ChatQA-70B在10个对话问答数据集上的平均得分超过了GPT-4，且不依赖于任何来自OpenAI GPT模型的合成数据。 |
| [^93] | [Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep Learning.](http://arxiv.org/abs/2401.09479) | 本文提出了一种使用多模态深度学习进行硬件特洛伊检测的方法，通过生成对抗网络扩充数据，并采用早融合和晚融合策略进行评估。通过估计不确定性量化指标，实现风险感知的决策制定。 |
| [^94] | [Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring.](http://arxiv.org/abs/2401.08517) | 这个论文研究了一种基于知识图谱情境化的LLM聊天机器人，作为学生学习推荐的解释工具和指导。通过定义上下文并利用人工策划的信息源来调控LLM的生成，聊天机器人能在与学生对话中提供解释和指导。 |
| [^95] | [Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks.](http://arxiv.org/abs/2401.07709) | 本文介绍了一种名为即时扩散编辑的图像编辑方法，该方法利用了现有的扩散模型的跨模态注意力能力，实现了即时的蒙版引导。通过采用无需训练的细化方案，该方法可以自适应地生成准确的蒙版，从而提高了扩散式图像编辑的效率。 |
| [^96] | [APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning.](http://arxiv.org/abs/2401.06827) | 本研究提出了APLe方法，通过逐令牌自适应的方式调节CLIP模型中的视觉和语言模式提示，提高了模型的泛化性能。 |
| [^97] | [An Analysis of User Behaviours for Objectively Evaluating Spoken Dialogue Systems.](http://arxiv.org/abs/2401.04867) | 本文研究了用户行为与主观评估在口语对话系统中的关系，提出了一种间接但客观评估系统的框架，并发现在不同类型的对话任务中，不同的用户行为指标对评估起到重要作用。 |
| [^98] | [Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM.](http://arxiv.org/abs/2401.02994) | 本研究介绍了一种名为“混合”的方法，通过组合多个适度规模的聊天AI模型，可以达到或超越比它们更大的模型的性能表现。 |
| [^99] | [AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI.](http://arxiv.org/abs/2401.01651) | 本论文介绍了AIGCBench，一个全面评估AI生成的图像到视频内容的基准。通过引入多样化且开放领域的图像-文本数据集，AIGCBench解决了现有基准的局限性。为了建立统一的评估框架，该基准包括11个度量指标，涵盖控制视频对齐、动态效果、时间一致性和视频质量等方面。 |
| [^100] | [An Empirical Study on Compliance with Ranking Transparency in the Software Documentation of EU Online Platforms.](http://arxiv.org/abs/2312.14794) | 该研究通过实证研究了解欧盟在线平台软件文档中排名透明度的合规性情况，并引入并测试了基于ChatGPT和信息检索技术的自动合规性评估工具，结果显示其作为合规性评估的可靠代理的前景很有希望。 |
| [^101] | [Tracking Any Object Amodally.](http://arxiv.org/abs/2312.12433) | 本论文介绍了一种追踪任何物体的非现态方法，利用数据增强和微调现态跟踪器，可以提高追踪的效果。 |
| [^102] | [Conditional Variational Diffusion Models.](http://arxiv.org/abs/2312.02246) | 该论文提出了一种新的条件变分扩散模型，通过学习调度作为训练过程的一部分，解决了扩散模型的敏感性问题，并且能够适应不同的应用场景，提供高质量的解决方案。 |
| [^103] | [A ripple in time: a discontinuity in American history.](http://arxiv.org/abs/2312.01185) | 该论文通过使用向量嵌入和非线性降维方法，发现GPT-2与UMAP的结合可以提供更好的分离和聚类效果。同时，经过微调的DistilBERT模型可用于识别总统和演讲的年份。 |
| [^104] | [GraphPro: Graph Pre-training and Prompt Learning for Recommendation.](http://arxiv.org/abs/2311.16716) | GraphPro是一个结合了参数高效和动态图预训练与提示学习的框架，能够有效捕捉长期用户偏好和短期行为动态，从而在真实世界的推荐系统中提供准确和及时的推荐。 |
| [^105] | [Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach.](http://arxiv.org/abs/2311.13884) | 本研究提出了一种基于大型语言模型的演员-评论家方法，通过一个名为LLaMAC的模块化框架来解决在多智能体系统中的幻觉和协调问题，并有效利用令牌来促进智能体之间的交互。通过系统资源分配和机器人网格运输的评估，证明了该方法的显著优势。 |
| [^106] | [A Safe Preference Learning Approach for Personalization with Applications to Autonomous Vehicles.](http://arxiv.org/abs/2311.02099) | 本研究介绍了一种安全的个性化偏好学习方法，应用于自动驾驶汽车。该方法利用信号时态逻辑公式的优先顺序进行学习，并提出了一种解决这个学习问题的方法。通过对比较，我们找到了适合的权重估计，使得首选信号的加权满足度高于非首选信号。在人体试验中证明了该方法的有效性。 |
| [^107] | [A Stability Principle for Learning under Non-Stationarity.](http://arxiv.org/abs/2310.18304) | 本研究提出了一个适用于非稳态环境的统计学习框架，通过应用稳定性原则选择回溯窗口来最大化历史数据利用，并保持累积偏差在可接受范围内。该方法展示了对未知非稳态的适应性，遗憾界在强凸或满足Lipschitz条件下是极小化的最优解。该研究的创新点是函数相似度度量和非稳态数据序列划分技术。 |
| [^108] | [Outlier Dimensions Encode Task-Specific Knowledge.](http://arxiv.org/abs/2310.17715) | 异常维度可以编码关键的特定任务知识，并且一个单一的异常维度可以以最小的错误率完成下游任务。 |
| [^109] | [HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks.](http://arxiv.org/abs/2310.15318) | HetGPT是一种预训练异构图神经网络的方法，通过利用提示调整来解决预训练与下游任务之间的不匹配问题。 |
| [^110] | [Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception.](http://arxiv.org/abs/2310.13712) | 本研究探索了四种教学指导策略对学习者在使用LLM时的表现和感知效果，发现直接LLM答案提高了表现，而改进学生解决方案则增加了对LLM的信任度。同时，结构化指导也减少了随机查询和学生复制粘贴问题的现象。 |
| [^111] | [Formally Specifying the High-Level Behavior of LLM-Based Agents.](http://arxiv.org/abs/2310.08535) | 本文介绍了一个最小生成框架，通过在高级声明中定义所需的代理人行为，然后构建解码监视器，从而实现了基于LLM的代理人的快速设计和实施。 |
| [^112] | [Direction-Oriented Visual-semantic Embedding Model for Remote Sensing Image-text Retrieval.](http://arxiv.org/abs/2310.08276) | 这篇论文提出了一种面向方向的视觉-语义嵌入模型（DOVE），通过区域导向的注意力模块和轻量级的文字基因辅助模块，解决了遥感图像-文本检索中的视觉-语义不平衡问题，提高了检索准确性。 |
| [^113] | [Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction.](http://arxiv.org/abs/2310.05207) | 本文提出了一种新的面部动作单位（AU）检测框架，通过共享参数和引入多任务学习，在面部标志检测和AU域分离与重建之间实现了更好的性能。实验证明我们方法在野外AU检测方面优于现有方法。 |
| [^114] | [Retrieval meets Long Context Large Language Models.](http://arxiv.org/abs/2310.03025) | "本论文研究了将检索增强和长上下文窗口的大语言模型相结合的解决方案，发现在长上下文任务中，通过检索增强的LLM使用4K上下文窗口可以取得与通过长上下文窗口微调的LLM使用16K上下文窗口相当的性能，同时计算量要少得多。此外，无论上下文窗口大小如何，检索都可以显著提高LLM的性能。" |
| [^115] | [GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.](http://arxiv.org/abs/2310.00737) | 这篇论文探讨了生成式人工智能和大型语言模型的潜在滥用，呼吁认识到这些挑战的紧迫性。研究揭示了这些技术在深度伪造、合成身份恶意活动以及虚假信息和欺诈方面可能带来的社会影响。 |
| [^116] | ["AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI.](http://arxiv.org/abs/2309.16606) | 该研究发现，无论是正面还是负面描述AI，在实际情况下都不存在AI时，参与者的期望值都很高，并且表现更好。这表明AI的表现期望在负面描述下是有偏差且稳定的。 |
| [^117] | [Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction.](http://arxiv.org/abs/2309.10016) | 本研究评估了GPT-3在抗癌药物敏感性预测任务中的潜力，并发现药物的SMILES表示和细胞系的基因组突变特征对药物反应具有预测能力。这些结果有助于在精准肿瘤学中设计更有效的治疗方案。 |
| [^118] | [CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary Keyword-Spotting.](http://arxiv.org/abs/2309.09552) | CB-Whisper是一种基于OpenAI的Whisper模型的自动语音识别系统，通过使用开放词汇关键词检测（OV-KWS）识别罕见的命名实体，并使用这些实体作为提示来改进识别效果。实验证明，该方法在提高实体召回率的同时会略微增加混淆错误率（MER）。 |
| [^119] | [Defensive Alliances in Signed Networks.](http://arxiv.org/abs/2309.06801) | 这项研究探讨了在签名网络中的防御联盟问题，提出了一种量化的群体结构，并通过考虑智能体之间的喜好和厌恶关系，在联盟形成中引入了新的因素。 |
| [^120] | [LLM Powered Sim-to-real Transfer for Traffic Signal Control.](http://arxiv.org/abs/2308.14284) | 本研究利用大型语言模型（LLMs）通过基于提示的行动转换，解决了交通信号控制任务中从仿真到真实的迁移问题。 |
| [^121] | [Score-Based Generative Models for PET Image Reconstruction.](http://arxiv.org/abs/2308.14190) | 本研究提出了适用于PET图像重建的基于分数的生成模型，通过应对PET图像重建中的挑战，包括高方差的泊松噪声和广泛的动态范围，展示了改进PET重建的显著潜力。 |
| [^122] | [Large Language Models Vote: Prompting for Rare Disease Identification.](http://arxiv.org/abs/2308.12890) | 本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。 |
| [^123] | [Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks.](http://arxiv.org/abs/2308.11624) | 本论文提出了一种利用人工智能和图表示技术对TCAD器件模拟中的半导体器件进行编码的创新方法，通过引入图注意力网络和通用编码方案，实现了全面的数据驱动建模，为研究人员提供了在设备级上应用基于人工智能的电子设计自动化解决方案的可能性。 |
| [^124] | [Revisiting column-generation-based matheuristic for learning classification trees.](http://arxiv.org/abs/2308.11477) | 该论文改进了基于列生成的启发式方法，以提高学习分类树的效果。通过减少子问题数量、使用数据依赖约束作为割平面以及生成违反约束的数据点，该方法提高了可伸缩性并适用于大型数据集。 |
| [^125] | [Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees.](http://arxiv.org/abs/2308.10487) | 本文介绍了一种使用神经符号混合系统进行机器学习和符号推理的方法，并通过检查知识库来确定它们在促进成功学习方面的效力。研究发现许多知识库满足判据，但也存在一些无法满足的知识库。 |
| [^126] | [Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings.](http://arxiv.org/abs/2307.03212) | 提出了一种区域关注的多视角表示学习（ROMER）的算法，用于捕捉多视角之间的依赖关系，学习城市区域的表达能力，并在多源城市数据中优于现有方法。 |
| [^127] | [CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis.](http://arxiv.org/abs/2307.00384) | 本文提出了一个级联生成对抗网络（CasTGAN）框架，用于生成逼真的表格数据，并特别关注输出的有效性。通过采用级联架构，其中专门的生成器对每个特征进行采样，使得合成输出更能代表真实数据。实验结果表明，CasTGAN能够产生更真实有效的合成表格数据。 |
| [^128] | [QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules.](http://arxiv.org/abs/2306.09549) | 该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。 |
| [^129] | [Data-Driven Regret Balancing for Online Model Selection in Bandits.](http://arxiv.org/abs/2306.02869) | 论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。 |
| [^130] | [Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery.](http://arxiv.org/abs/2305.14259) | 本文介绍了一种基于文献的发现方法，通过上下文化的学习生成新的科学方向，克服了标准方法在预测关联、忽略上下文等方面的局限性。模型使用了引文和知识图关系的网络，并使用大型语言模型进行评估，发现GPT4在生成创新思想方面表现出色。 |
| [^131] | [Iterative Adversarial Attack on Image-guided Story Ending Generation.](http://arxiv.org/abs/2305.13208) | 本文提出了一种迭代对抗攻击方法，通过融合图像和文本模态的攻击，实现了对多模态文本生成任务的对抗攻击搜索，提高了攻击的效果。 |
| [^132] | [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement.](http://arxiv.org/abs/2304.14391) | 本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。 |
| [^133] | [Improving Urban Flood Prediction using LSTM-DeepLabv3+ and Bayesian Optimization with Spatiotemporal feature fusion.](http://arxiv.org/abs/2304.09994) | 本研究提出了一种基于CNN-RNN混合特征融合建模的贝叶斯优化城市洪水预测模型，实现了静态和动态的预测，并通过结合多个CNN和RNN模型，在精度上取得了显著提高。 |
| [^134] | [Learning policies for resource allocation in business processes.](http://arxiv.org/abs/2304.09970) | 本文提出了两种基于学习的方法来进行企业流程资源分配，具有优于常见启发式方法的效果。 |
| [^135] | [Qualitative Failures of Image Generation Models and Their Application in Detecting Deepfakes.](http://arxiv.org/abs/2304.06470) | 研究调查了图像生成模型的质量失误及其应用于检测Deepfakes，识别了五种定性缺陷。这些发现有助于改进模型并制定检测Deepfakes的策略。 |
| [^136] | [Sample-efficient Adversarial Imitation Learning.](http://arxiv.org/abs/2303.07846) | 本研究提出了一种利用自监督表示来增强样本效率的对抗性模仿学习方法，从而学习不受扭曲影响的状态和动作表示以建立非图像控制任务的预测表征。 |
| [^137] | [Refined Edge Usage of Graph Neural Networks for Edge Prediction.](http://arxiv.org/abs/2212.12970) | 这项研究提出了一种新的边缘预测范式（EMPIRE），通过细化边缘使用方法解决了节点分类任务和边缘预测任务之间的区别。该方法引入了边缘拆分技术和新的消息传递机制，以更好地利用边缘的拓扑结构和监督信号。 |
| [^138] | [The Normalized Cross Density Functional: A Framework to Quantify Statistical Dependence for Random Processes.](http://arxiv.org/abs/2212.04631) | 本文提出了一种用于量化随机过程统计依赖关系的框架，通过最大化交替协方差估计和规范化交叉密度来衡量多变量统计依赖性，并应用于机器学习架构中。 |
| [^139] | [Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects.](http://arxiv.org/abs/2208.04883) | 本文提出了神经会合，一种深度学习导航和控制框架，用于可靠、准确和自主地遭遇快速移动的星际物体。它通过点最小范数追踪控制和谱归一化深度神经网络引导策略来提供高概率指数上界的飞行器交付误差。 |
| [^140] | [Empowering GNNs via Edge-Aware Weisfeiler-Lehman Algorithm.](http://arxiv.org/abs/2206.02059) | 本文提出了一种基于边缘感知的Weisfeiler-Lehman算法，以增强图神经网络的表达能力，同时保持消息传递方案的可扩展性。实验表明，我们NC-GNN框架在各种基准测试中表现出有效性和高效性。 |
| [^141] | [Personalized Algorithmic Recourse with Preference Elicitation.](http://arxiv.org/abs/2205.13743) | 研究提出了PEAR方法，这是一个首个能够针对最终用户需求提供个性化算法补救成本的人机交互方法。该方法利用贝叶斯偏好引导的见解，通过最大化原则性信息增益度量来计算目标用户选择的预期效用，然后将偏好引导整合到强化学习框架中。该方法显著提高了算法干预的经济实用性和用户友好性。 |
| [^142] | [Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities.](http://arxiv.org/abs/2203.13883) | 这项研究总结了多模式虚假信息检测的方法、挑战和机遇。由于社交媒体平台的转变，虚假信息的性质也发生了变化。研究人员已经开发出自动检测跨模态不协调的技术，但仍面临挑战和不足之处，进一步的研究机会也在等待着挖掘。 |
| [^143] | [Generalized Out-of-Distribution Detection: A Survey.](http://arxiv.org/abs/2110.11334) | 广义的离群检测的调查研究探讨了离群检测的重要性及其与异常检测、新颖性检测和开放集识别等问题的联系，对于提高机器学习系统的可靠性和安全性具有关键意义。 |
| [^144] | [An extended Knowledge Compilation Map for Conditional Preference Statements-based and Generalized Additive Utilities-based Languages.](http://arxiv.org/abs/2102.04107) | 本文扩展了基于条件偏好语句的语言的知识编译图，研究了查询和转换的各种复杂性，并增加了新的查询和转换的研究，对于广义可加性效用也进行了研究。 |

# 详细

[^1]: AutoRT：大规模编排机器人代理的具身基础模型

    AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents. (arXiv:2401.12963v1 [cs.RO])

    [http://arxiv.org/abs/2401.12963](http://arxiv.org/abs/2401.12963)

    AutoRT是一个利用现有的基础模型来扩展机器人在未知场景中的部署的系统，通过利用视觉-语言模型和大型语言模型，提出多样化和新颖的指令，并有效地推理自主权和安全性的权衡。

    

    拥有语言、视觉和行动等功能的具身基础模型已经彻底改变了利用互联网规模的数据来推理有用任务的能力。然而，训练具身基础模型的一个关键挑战是缺乏基于物理世界的数据。在本文中，我们提出了AutoRT，一个利用现有的基础模型来扩展完全未知场景中操作机器人的部署的系统，只需要最少的人工监督。AutoRT利用视觉-语言模型(VLMs)实现场景理解和基础绑定，并进一步利用大型语言模型(LLMs)提出多样化和新颖的指令，供一组机器人执行。通过利用基础模型的知识来指导数据收集，AutoRT能够有效地推理自主权和安全性的权衡，同时显著扩大机器人学习的数据收集。我们演示了AutoRT向20多个机器人提议指令。

    Foundation models that incorporate language, vision, and more recently actions have revolutionized the ability to harness internet scale data to reason about useful tasks. However, one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world. In this paper, we propose AutoRT, a system that leverages existing foundation models to scale up the deployment of operational robots in completely unseen scenarios with minimal human supervision. AutoRT leverages vision-language models (VLMs) for scene understanding and grounding, and further uses large language models (LLMs) for proposing diverse and novel instructions to be performed by a fleet of robots. Guiding data collection by tapping into the knowledge of foundation models enables AutoRT to effectively reason about autonomy tradeoffs and safety while significantly scaling up data collection for robot learning. We demonstrate AutoRT proposing instructions to over 20 robots across multi
    
[^2]: 元提示：增强语言模型的任务无关支持

    Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding. (arXiv:2401.12954v1 [cs.CL])

    [http://arxiv.org/abs/2401.12954](http://arxiv.org/abs/2401.12954)

    元提示是一种支持技术，将单个语言模型转化为多面手指挥者，通过高级指令将复杂任务分解为子任务，并由不同的专家模型处理，最终提高效率。

    

    我们引入了元提示，一种有效的支持技术，旨在增强语言模型（LM）的功能。这种方法将单个LM转化为多面手指挥者，善于管理和整合多个独立的LM查询。通过使用高级指令，元提示指导LM将复杂任务分解为更小、更可管理的子任务。然后，这些子任务由相同LM的不同“专家”实例处理，每个实例都在特定的、定制化的指导下操作。该过程的核心是LM本身，它作为指挥者确保这些专家模型的输出无缝沟通和有效集成。它还利用其固有的批判性思维和强大的验证过程来完善和验证最终结果。这种协作提示方法使单个LM能够同时充当全面的编排者和多样化的专家小组，极大地提高了效率。

    We introduce meta-prompting, an effective scaffolding technique designed to enhance the functionality of language models (LMs). This approach transforms a single LM into a multi-faceted conductor, adept at managing and integrating multiple independent LM queries. By employing high-level instructions, meta-prompting guides the LM to break down complex tasks into smaller, more manageable subtasks. These subtasks are then handled by distinct "expert" instances of the same LM, each operating under specific, tailored instructions. Central to this process is the LM itself, in its role as the conductor, which ensures seamless communication and effective integration of the outputs from these expert models. It additionally employs its inherent critical thinking and robust verification processes to refine and authenticate the end result. This collaborative prompting approach empowers a single LM to simultaneously act as a comprehensive orchestrator and a panel of diverse experts, significantly e
    
[^3]: 基于Transformer模型在学习模拟结构递归方面尚未完美

    Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion. (arXiv:2401.12947v1 [cs.CL])

    [http://arxiv.org/abs/2401.12947](http://arxiv.org/abs/2401.12947)

    本论文研究了基于Transformer模型学习结构递归的能力，介绍了一个通用框架，将编程语言领域中的抽象概念与具体的序列建模问题和学习模型行为相连接。

    

    本论文研究了基于Transformer模型学习结构递归的能力。递归是自然语言和形式语言中的一种通用概念。结构递归在编程语言和形式数学任务中是至关重要的，而在这些任务中，符号工具目前在神经模型之上有优势，比如推断数据类型之间的语义关系和模拟程序行为。我们引入了一个通用框架，将编程语言领域中的抽象概念与具体的序列建模问题和学习模型行为相连接。该框架包括一个捕捉结构递归一般"语法"的表示，以及两种不同的框架来理解它们的"语义"——一种更符合编程语言视角的自然方式，以及一种有助于将该视角与底层Transformer模型的机械理解相结合的方式。

    This paper investigates the ability of transformer-based models to learn structural recursion from examples. Recursion is a universal concept in both natural and formal languages. Structural recursion is central to the programming language and formal mathematics tasks where symbolic tools currently excel beyond neural models, such as inferring semantic relations between datatypes and emulating program behavior. We introduce a general framework that nicely connects the abstract concepts of structural recursion in the programming language domain to concrete sequence modeling problems and learned models' behavior. The framework includes a representation that captures the general \textit{syntax} of structural recursion, coupled with two different frameworks for understanding their \textit{semantics} -- one that is more natural from a programming languages perspective and one that helps bridge that perspective with a mechanistic understanding of the underlying transformer architecture.  Wit
    
[^4]: 用分解的图神经网络预测卡车停车使用情况

    Truck Parking Usage Prediction with Decomposed Graph Neural Networks. (arXiv:2401.12920v1 [cs.AI])

    [http://arxiv.org/abs/2401.12920](http://arxiv.org/abs/2401.12920)

    提出了Regional Temporal Graph Neural Network (RegT-GCN)作为一个预测框架，用于评估整个州的卡车停车使用情况，以提供更准确的停车信息并缓解未经授权的停车问题。

    

    货运走廊上的卡车停车面临诸多挑战，如停车位不足和遵守工时规定。这些限制往往导致未经授权的停车行为，引发安全问题。为了提高货运作业的安全性，提供准确的停车使用预测被证明是一种经济高效的解决方案。尽管已有研究表明对于单个卡车停车场使用情况的预测准确度较高，但对多个卡车停车场的空间依赖关系进行使用预测的方法很少。我们提出了区域时空图神经网络（RegT-GCN）作为一个预测框架，用于评估整个州的停车使用情况，以提供更好的卡车停车信息和缓解未经授权的停车问题。该框架利用卡车停车场分布的拓扑结构和历史停车数据来预测整个州的占用率。

    Truck parking on freight corridors faces various challenges, such as insufficient parking spaces and compliance with Hour-of-Service (HOS) regulations. These constraints often result in unauthorized parking practices, causing safety concerns. To enhance the safety of freight operations, providing accurate parking usage prediction proves to be a cost-effective solution. Despite the existing research demonstrating satisfactory accuracy for predicting individual truck parking site usage, few approaches have been proposed for predicting usage with spatial dependencies of multiple truck parking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN) as a predictive framework for assessing parking usage across the entire state to provide better truck parking information and mitigate unauthorized parking. The framework leverages the topological structures of truck parking site distributions and historical parking data to predict occupancy rates across a state. To achieve this,
    
[^5]: 主动推断作为机构模型

    Active Inference as a Model of Agency. (arXiv:2401.12917v1 [cs.AI])

    [http://arxiv.org/abs/2401.12917](http://arxiv.org/abs/2401.12917)

    本文展示了使用主动推断作为规范性贝叶斯框架来模拟和建模机构的方法，通过最小化风险和对世界状态的不确定性来整合探索与开发。这种方法是广泛应用于行为神经科学、强化学习和机器人技术领域的方法。

    

    除了奖励最大化之外，是否有一种规范的方式来思考机构？在本文中，我们展示了任何符合关于宏观生物体如何与世界互动的物理合理假设的行为都以最小化风险和对世界状态的不确定性的意义上，规范地整合了探索与开发。这种描述被称为主动推断，它精细化了自由能原理，这是神经科学中行动和知觉的一个流行的描述性框架。主动推断提供了一种规范性的贝叶斯框架，用于模拟和建模机构，广泛应用于行为神经科学、强化学习和机器人技术领域。主动推断在强化学习领域的用处有三个方面。a) 主动推断提供了一个能够有效模拟生物机构的问题的解决方案。b) 它提供了一个可解释的配方来模拟行为，行为随之成为一个可解释的结果。

    Is there a canonical way to think of agency beyond reward maximisation? In this paper, we show that any type of behaviour complying with physically sound assumptions about how macroscopic biological agents interact with the world canonically integrates exploration and exploitation in the sense of minimising risk and ambiguity about states of the world. This description, known as active inference, refines the free energy principle, a popular descriptive framework for action and perception originating in neuroscience. Active inference provides a normative Bayesian framework to simulate and model agency that is widely used in behavioural neuroscience, reinforcement learning (RL) and robotics. The usefulness of active inference for RL is three-fold. \emph{a}) Active inference provides a principled solution to the exploration-exploitation dilemma that usefully simulates biological agency. \emph{b}) It provides an explainable recipe to simulate behaviour, whence behaviour follows as an expla
    
[^6]: 红队针对视觉语言模型的研究

    Red Teaming Visual Language Models. (arXiv:2401.12915v1 [cs.AI])

    [http://arxiv.org/abs/2401.12915](http://arxiv.org/abs/2401.12915)

    本论文通过提供一个新颖的红队数据集RTVLM，评估了当前视觉语言模型VLMs在忠实度、隐私、安全和公平性方面的性能，并与GPT-4V进行了比较。结果显示，10个知名的VLMs在红队行动中存在不同程度的困难。

    

    视觉语言模型(VLMs)扩展了大型语言模型(LLMs)接受多模态输入的能力。由于已经验证LLMs可以通过特定测试用例产生有害或不准确的内容(称为红队行动)，VLMs在类似场景中的表现如何，特别是在文本和视觉输入的组合中，仍然是一个问题。为了探索这个问题，我们提供了一个新颖的红队数据集RTVLM，包含4个主要方面(忠实度、隐私、安全、公平)下的10个子任务(如图像误导、多模态越狱、脸部公平等)。我们的RTVLM是第一个从这四个不同方面评估当前VLMs的红队数据集。详细分析表明，10个知名的开放源代码VLMs在红队行动中遇到不同程度的困难，并且与GPT-4V相比，性能差距高达31%。此外，我们还使用RT简单地将红队行动对齐到LLaVA-v1.5上，使用监督微调(SFT)。

    VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language Models) to accept multimodal inputs. Since it has been verified that LLMs can be induced to generate harmful or inaccurate content through specific test cases (termed as Red Teaming), how VLMs perform in similar scenarios, especially with their combination of textual and visual inputs, remains a question. To explore this problem, we present a novel red teaming dataset RTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modal jail-breaking, face fairness, etc) under 4 primary aspects (faithfulness, privacy, safety, fairness). Our RTVLM is the first red-teaming dataset to benchmark current VLMs in terms of these 4 different aspects. Detailed analysis shows that 10 prominent open-sourced VLMs struggle with the red teaming in different degrees and have up to 31% performance gap with GPT-4V. Additionally, we simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning (SFT) using RT
    
[^7]: 工业物联网中的任务卸载的新型通信协议学习

    Emergent Communication Protocol Learning for Task Offloading in Industrial Internet of Things. (arXiv:2401.12914v1 [cs.IT])

    [http://arxiv.org/abs/2401.12914](http://arxiv.org/abs/2401.12914)

    本文提出了一种利用多智能体强化学习框架来解决工业物联网中任务卸载问题的新型通信协议学习方法，实验证明该方法能够提高信道接入成功率和成功计算任务的数量，并且胜过现有的远程计算和本地计算方法。

    

    本文利用多智能体强化学习框架来联合学习计算卸载决策和多信道接入策略以及对应的信令。具体而言，基站和工业物联网移动设备是需要合作以在截止时间限制内执行计算任务的强化学习智能体。我们采用新型的通信协议学习框架来解决这个问题。数值结果显示，相比于基于竞争、无竞争和无通信的方法，新型的通信协议能够提高信道接入成功率和成功计算任务的数量。此外，提出的任务卸载策略胜过远程计算和本地计算基准模型。

    In this paper, we leverage a multi-agent reinforcement learning (MARL) framework to jointly learn a computation offloading decision and multichannel access policy with corresponding signaling. Specifically, the base station and industrial Internet of Things mobile devices are reinforcement learning agents that need to cooperate to execute their computation tasks within a deadline constraint. We adopt an emergent communication protocol learning framework to solve this problem. The numerical results illustrate the effectiveness of emergent communication in improving the channel access success rate and the number of successfully computed tasks compared to contention-based, contention-free, and no-communication approaches. Moreover, the proposed task offloading policy outperforms remote and local computation baselines.
    
[^8]: 从理解到应用：大规模语言模型可解释性研究综述

    From Understanding to Utilization: A Survey on Explainability for Large Language Models. (arXiv:2401.12874v1 [cs.CL])

    [http://arxiv.org/abs/2401.12874](http://arxiv.org/abs/2401.12874)

    本综述论文研究了大规模语言模型(LLMs)可解释性的新兴领域，强调了在LLMs中增强可解释性的必要性，同时解决了广大公众对其信任和技术界对这些模型更深理解的需求。该综述对现有的可解释性方法进行分类，并讨论了它们在提高模型透明度和可靠性方面的应用，旨在弥合理论理解和实际应用之间的差距。

    

    本综述论文深入研究了大规模语言模型(LLMs)可解释性的新兴领域，这是自然语言处理中一个关键且具有挑战性的方面。LLMs在各种应用中发挥着关键作用，但其“黑盒”性质引发了对透明性和伦理使用的担忧。本文强调了在LLMs中增强可解释性的必要性，同时解决了广大公众对其信任和技术界对这些模型更深理解的需求。我们集中在预训练的基于Transformer的LLMs，如LLaMA，其规模和复杂性使其面临独特的可解释性挑战。我们的综述对现有的可解释性方法进行分类，并讨论了它们在提高模型透明度和可靠性方面的应用。我们还讨论了代表性的评价方法，强调了它们的优势和局限性。本综述的目标是弥合理论理解和实际应用之间的差距，提供从技术角度总结可解释性方法的全面视角。

    This survey paper delves into the burgeoning field of explainability for Large Language Models (LLMs), a critical yet challenging aspect of natural language processing. With LLMs playing a pivotal role in various applications, their "black-box" nature raises concerns about transparency and ethical use. This paper emphasizes the necessity for enhanced explainability in LLMs, addressing both the general public's trust and the technical community's need for a deeper understanding of these models. We concentrate on pre-trained Transformer-based LLMs, such as LLaMA, which present unique interpretability challenges due to their scale and complexity. Our review categorizes existing explainability methods and discusses their application in improving model transparency and reliability. We also discuss representative evaluation methods, highlighting their strengths and limitations. The goal of this survey is to bridge the gap between theoretical understanding and practical application, offering 
    
[^9]: 通过人的反馈改善机器翻译: 将质量估计作为奖励模型的探索

    Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model. (arXiv:2401.12873v1 [cs.CL])

    [http://arxiv.org/abs/2401.12873](http://arxiv.org/abs/2401.12873)

    本研究探索了利用质量估计作为奖励模型来预测人类偏好以改善机器翻译的潜力。我们发现基于质量估计的反馈训练存在过度优化问题，采用启发式规则来检测错误翻译并对质量估计模型进行惩罚以解决该问题。

    

    不充分建模人类偏好导致奖励模型在利用人的反馈提高翻译质量方面成为一个主要障碍。幸运的是，质量估计(QE)在过去两年中无需参考文献就能准确预测给定翻译的质量。在这项工作中，我们探讨了将QE模型作为奖励模型(基于QE的奖励模型)来预测人的偏好以进行反馈训练的潜力。我们首先发现了在基于QE的反馈训练中的过度优化问题，表现为奖励的增加而翻译质量下降。我们研究了这个问题，并认为QE模型的脆弱性可能导致错误翻译的高奖励，从而导致过度优化和错误传播。为解决这个问题，我们采用了一种简单而有效的方法，使用启发式规则检测错误翻译，并为QE模型添加了一个惩罚项。

    Insufficient modeling of human preferences within the reward model is a major obstacle for leveraging human feedback to improve translation quality. Fortunately, quality estimation (QE), which predicts the quality of a given translation without reference, has achieved impressive alignment with human evaluations in the last two years. In this work, we investigate the potential of employing the QE model as the reward model (the QE-based reward model) to predict human preferences for feedback training. We first identify the overoptimization problem during QE-based feedback training, manifested as an increase in reward while translation quality declines. We examine the problem and argue that the vulnerability of the QE model might lead to high rewards for incorrect translations, resulting in overoptimization and error propagation. To address the problem, we adopt a simple yet effective method that uses heuristic rules to detect the incorrect translations and assigns a penalty term to the Q
    
[^10]: TroVE:引导可验证和高效工具箱解决程序化任务

    TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks. (arXiv:2401.12869v1 [cs.AI])

    [http://arxiv.org/abs/2401.12869](http://arxiv.org/abs/2401.12869)

    本研究提出了一种名为TROVE的方法，它能够通过生成、使用、扩展和定期修剪工具箱，引导生成可验证和高效的函数工具箱。与其他基准方法相比，TROVE在解决各种任务时能够产生更简单且更准确的解决方案，同时减小了工具箱的体积，并且能够实现更快速和更准确的人工验证。此外，TROVE还能够为不同的任务和数据集创建多样化的函数，提供洞见。

    

    语言模型（LMs）可以通过编写程序来解决诸如回答表格或图像相关问题的任务。然而，使用基本函数通常会导致冗长且容易出错的程序，而高级函数需要专家设计。为了实现无需人力的更好解决方案，我们要求代码LMs策划可重用的高级函数，并使用它们编写解决方案。我们提出了TROVE，一种无需训练的方法，通过生成、使用、扩展和定期修剪工具箱，引导生成可验证和高效的函数工具箱。在从数学、表格问答和图像推理任务中得到的11个数据集上，TROVE始终比使用CODELLAMA和先前使用GPT的基准方法产生更简单且更准确的解决方案，同时使用79-98%更小的工具箱。TROVE还使得人工验证比基准方法快31％且准确性更高13％。在相同的流程下，它为不同的任务和数据集创建了多样化的函数，为我们提供了洞见。

    Language models (LMs) can solve tasks such as answering questions about tables or images by writing programs. However, using primitive functions often leads to verbose and error-prone programs, and higher-level functions require expert design. To enable better solutions without human labor, we ask code LMs to curate reusable high-level functions, and use them to write solutions. We present TROVE, a training-free method of inducing a verifiable and efficient toolbox of functions, by generating via using, growing, and periodically trimming the toolbox. On 11 datasets from math, table question answering, and image reasoning tasks, TROVE consistently yields simpler solutions with higher accuracy than baselines using CODELLAMA and previous methods using GPT, while using 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% more accurate human verification than baselines. With the same pipeline, it creates diverse functions for varied tasks and datasets, providing insights into 
    
[^11]: 在数据流支持的移动众包协调中评估协作和自治代理

    Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing. (arXiv:2401.12866v1 [cs.AI])

    [http://arxiv.org/abs/2401.12866](http://arxiv.org/abs/2401.12866)

    移动众包系统中任务分配和质量问题引起了研究者的关注。本文提出了一种基于数据流学习的方法来预测任务结果，并通过任务转移来解决任务分配中的问题。这些机制有助于提高移动众包系统的服务质量。

    

    移动众包是指完成任务需要众包工作者在按需劳动力中进行物理移动的系统。Evidence suggests that in such systems, tasks often get assigned to crowdworkers who struggle to complete those tasks successfully, resulting in high failure rates and low service quality. 提高服务质量的一个有希望的解决方案是不断适应任务分配，并在出现导致失败的事件时将任务转移给更合适的工作者，他们使用不同的路线或车辆。然而，在移动众包中实现任务转移是困难的，因为工作者是自治的，可能拒绝转移请求。此外，任务结果是不确定的，需要进行预测。在本文中，我们提出了不同的机制来实现移动众包中的结果预测和任务协调。首先，我们分析了不同的数据流学习方法来预测任务结果。其次，基于此我们p

    Mobile crowdsourcing refers to systems where the completion of tasks necessarily requires physical movement of crowdworkers in an on-demand workforce. Evidence suggests that in such systems, tasks often get assigned to crowdworkers who struggle to complete those tasks successfully, resulting in high failure rates and low service quality. A promising solution to ensure higher quality of service is to continuously adapt the assignment and respond to failure-causing events by transferring tasks to better-suited workers who use different routes or vehicles. However, implementing task transfers in mobile crowdsourcing is difficult because workers are autonomous and may reject transfer requests. Moreover, task outcomes are uncertain and need to be predicted. In this paper, we propose different mechanisms to achieve outcome prediction and task coordination in mobile crowdsourcing. First, we analyze different data stream learning approaches for the prediction of task outcomes. Second, based on
    
[^12]: KAM-CoT: 知识增强的多模式思维链推理

    KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning. (arXiv:2401.12863v1 [cs.CL])

    [http://arxiv.org/abs/2401.12863](http://arxiv.org/abs/2401.12863)

    KAM-CoT是一个知识增强的多模式思维链推理框架，可以通过引入外部知识图谱来提高模型对多模式任务的理解能力，并生成更准确的答案。

    

    大型语言模型（LLM）通过利用思维链（CoT）实现了在自然语言处理任务中令人印象深刻的性能，在最近的研究中，将LLMs扩展为多模式能力是一个有吸引力的方向，但会增加计算成本并需要大量硬件资源。为了应对这些挑战，我们提出了KAM-CoT框架，该框架融合了CoT推理、知识图谱（KGs）和多种模式，以全面理解多模式任务。KAM-CoT采用两阶段训练过程，通过KG基础生成有效的理由和答案。通过在推理过程中引入来自知识图谱的外部知识，模型获得了更深入的语境理解，减少了虚构和改善了答案的质量。这种知识增强的CoT推理使模型能够处理需要外部上下文的问题，并提供更有根据的答案。实验结果显示，KAM-CoT在性能上优于现有的方法。

    Large Language Models (LLMs) have demonstrated impressive performance in natural language processing tasks by leveraging chain of thought (CoT) that enables step-by-step thinking. Extending LLMs with multimodal capabilities is the recent interest, but incurs computational cost and requires substantial hardware resources. To address these challenges, we propose KAM-CoT a framework that integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities for a comprehensive understanding of multimodal tasks. KAM-CoT adopts a two-stage training process with KG grounding to generate effective rationales and answers. By incorporating external knowledge from KGs during reasoning, the model gains a deeper contextual understanding reducing hallucinations and enhancing the quality of answers. This knowledge-augmented CoT reasoning empowers the model to handle questions requiring external context, providing more informed answers. Experimental findings show KAM-CoT outperforms the state-of-t
    
[^13]: FedRSU: 基于RSU的联邦学习在场景流估计中的应用

    FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units. (arXiv:2401.12862v1 [cs.CV])

    [http://arxiv.org/abs/2401.12862](http://arxiv.org/abs/2401.12862)

    FedRSU是一种创新的联邦学习框架，用于自监督场景流估计，它通过整合RSU收集的数据，采用循环自监督训练范式来提高模型的准确性和稳定性。

    

    RSU（路边单元）通过车联网（V2X）通信可以显著提高自动驾驶汽车的安全性和稳健性。目前，单个RSU的使用主要集中在实时推断和V2X协作上，而忽视了RSU传感器收集的高质量数据的潜在价值。整合大量来自多个RSU的数据可以为模型训练提供丰富的数据来源。然而，缺乏地面真值标注和传输庞大数据量的困难是充分利用这些隐藏价值的两个不可避免的障碍。在本文中，我们介绍了FedRSU，一种创新的自监督场景流估计的联邦学习框架。在FedRSU中，我们提出了一种循环自监督训练范式，对于每个RSU，可以通过其后续未来的多模态观测对每个时间戳的点的场景流预测进行监督。FedRSU的另一个关键组成部分是联邦

    Roadside unit (RSU) can significantly improve the safety and robustness of autonomous vehicles through Vehicle-to-Everything (V2X) communication. Currently, the usage of a single RSU mainly focuses on real-time inference and V2X collaboration, while neglecting the potential value of the high-quality data collected by RSU sensors. Integrating the vast amounts of data from numerous RSUs can provide a rich source of data for model training. However, the absence of ground truth annotations and the difficulty of transmitting enormous volumes of data are two inevitable barriers to fully exploiting this hidden value. In this paper, we introduce FedRSU, an innovative federated learning framework for self-supervised scene flow estimation. In FedRSU, we present a recurrent self-supervision training paradigm, where for each RSU, the scene flow prediction of points at every timestamp can be supervised by its subsequent future multi-modality observation. Another key component of FedRSU is federated
    
[^14]: 使用无人机高光谱成像对葡萄品种进行分类

    Classification of grapevine varieties using UAV hyperspectral imaging. (arXiv:2401.12851v1 [cs.CV])

    [http://arxiv.org/abs/2401.12851](http://arxiv.org/abs/2401.12851)

    该研究提出了一种使用无人机高光谱成像对17种红白葡萄品种进行分类的方法，相比于传统的破坏性方法，这种方法更高效和 less prohibitive，能够纠正和降低大量数据的采样率，并且能够处理葡萄品种高度相似的高光谱特征。

    

    不同葡萄品种的分类是精准葡萄栽培中一个相关的表型分析任务，因为它可以估计不同品种的葡萄园行的生长情况，并涉及到葡萄酒行业的其他应用。这项任务可以通过破坏性的方法来完成，需要耗时的数据收集和实验室分析等任务。然而，无人机提供了一种更高效、 less prohibitive的方法来收集高光谱数据，尽管可能会获得更嘈杂的数据。因此，第一个任务是处理这些数据以纠正和降低大量数据的采样率。此外，葡萄品种的高光谱特征非常相似。在这项工作中，提出了一种卷积神经网络（CNN）用于对17种红白葡萄品种进行分类。与分类单个样本不同，这些样本与其周围环境一起进行处理。因此，需要进行空间特征的提取。

    The classification of different grapevine varieties is a relevant phenotyping task in Precision Viticulture since it enables estimating the growth of vineyard rows dedicated to different varieties, among other applications concerning the wine industry. This task can be performed with destructive methods that require time-consuming tasks, including data collection and analysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide a more efficient and less prohibitive approach to collecting hyperspectral data, despite acquiring noisier data. Therefore, the first task is the processing of these data to correct and downsample large amounts of data. In addition, the hyperspectral signatures of grape varieties are very similar. In this work, a Convolutional Neural Network (CNN) is proposed for classifying seventeen varieties of red and white grape variants. Rather than classifying single samples, these are processed together with their neighbourhood. Hence, the extraction of spa
    
[^15]: 针对演讲者分割的端到端监督分层图聚类算法

    Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization. (arXiv:2401.12850v1 [eess.AS])

    [http://arxiv.org/abs/2401.12850](http://arxiv.org/abs/2401.12850)

    本文提出了一种针对演讲者分割的端到端监督分层图聚类算法，使用图神经网络进行表示学习、度量学习和聚类，并通过外部重叠检测器提供额外的输入。

    

    演讲者分割是基于说话者身份对音频录音进行分割的重要语音预处理步骤，适用于多个下游应用。传统的分割方法涉及多次嵌入提取和聚类步骤，通常以孤立的方式进行优化。虽然端到端的分割系统试图学习一个单一模型来完成任务，但通常训练复杂且需要大量的监督数据集。在本文中，我们提出了一种基于图神经网络(GNN)的端到端监督分层聚类算法，称为E-SHARC。E-SHARC方法使用前端mel-filterbank特征作为输入，并联合学习嵌入提取器和GNN聚类模块，进行表示学习、度量学习和端到端优化的聚类。此外，E-SHARC还通过外部重叠检测器提供额外的输入。

    Speaker diarization, the task of segmenting an audio recording based on speaker identity, constitutes an important speech pre-processing step for several downstream applications. The conventional approach to diarization involves multiple steps of embedding extraction and clustering, which are often optimized in an isolated fashion. While end-to-end diarization systems attempt to learn a single model for the task, they are often cumbersome to train and require large supervised datasets. In this paper, we propose an end-to-end supervised hierarchical clustering algorithm based on graph neural networks (GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). The E-SHARC approach uses front-end mel-filterbank features as input and jointly learns an embedding extractor and the GNN clustering module, performing representation learning, metric learning, and clustering with end-to-end optimization. Further, with additional inputs from an external overlap detector, the E-SHARC app
    
[^16]: 大型语言模型能够如何解释业务流程？

    How well can large language models explain business processes?. (arXiv:2401.12846v1 [cs.AI])

    [http://arxiv.org/abs/2401.12846](http://arxiv.org/abs/2401.12846)

    该论文介绍了一个用于生成业务流程解释的SAX4BPM框架，该框架通过与大型语言模型（LLM）集成来综合各种输入要素，以提供更好的情境感知解释（SAX）。

    

    大型语言模型（LLMs）可能在未来的AI辅助业务流程管理系统（ABPMSs）中发挥重要作用，其功能涵盖系统生命周期的各个阶段。其中一个系统功能是情境感知解释（SAX），它涉及生成在考虑所解释条件出现的流程上下文的前提下既符合因果关系又可人类解读的解释。在本文中，我们介绍了开发用于生成SAX解释的SAX4BPM框架。SAX4BPM套件包括一组服务和一个中央知识库。这些服务的功能是获取构成SAX解释的各种知识要素。其中一个创新性的关键组成部分是因果过程执行视图。在本工作中，我们将该框架与LLM集成，以利用其综合各种输入要素的能力，从而改进SAX解释的质量。

    Large Language Models (LLMs) are likely to play a prominent role in future AI-augmented business process management systems (ABPMSs) catering functionalities across all system lifecycle stages. One such system's functionality is Situation-Aware eXplainability (SAX), which relates to generating causally sound and yet human-interpretable explanations that take into account the process context in which the explained condition occurred. In this paper, we present the SAX4BPM framework developed to generate SAX explanations. The SAX4BPM suite consists of a set of services and a central knowledge repository. The functionality of these services is to elicit the various knowledge ingredients that underlie SAX explanations. A key innovative component among these ingredients is the causal process execution view. In this work, we integrate the framework with an LLM to leverage its power to synthesize the various input ingredients for the sake of improved SAX explanations. Since the use of LLMs for
    
[^17]: SGTR+: 基于Transformer的端到端场景图生成方法

    SGTR+: End-to-end Scene Graph Generation with Transformer. (arXiv:2401.12835v1 [cs.CV])

    [http://arxiv.org/abs/2401.12835](http://arxiv.org/abs/2401.12835)

    本论文提出了一种基于Transformer的端到端场景图生成方法，通过解决二分图构建问题，实现了实体和谓词候选集的生成和关系三元组的推断，并设计了图组装模块推断二分图的连通性，从而实现了场景图的端到端生成。

    

    场景图生成（SGG）因其组合性质而仍然是一个具有挑战性的视觉理解任务。大多数以前的方法采用自下而上的两阶段或基于点的一阶段方法，这些方法往往受到高时间复杂度或次优设计的困扰。在这项工作中，我们提出了一种新的SGG方法来解决上述问题，将该任务形式化为一个二分图构建问题。为了解决上述问题，我们创建了一个基于Transformer的端到端框架来生成实体和实体感知谓词候选集，并推断出形成关系三元组的有向边。此外，我们设计了一个图组装模块来根据我们的实体感知结构推断出二分图的连通性，使我们能够以端到端的方式生成场景图。基于二分图组装范例，我们进一步提出了一种新的技术设计来解决实体感知建模的有效性和图组装的优化稳定性问题。

    Scene Graph Generation (SGG) remains a challenging visual understanding task due to its compositional property. Most previous works adopt a bottom-up, two-stage or point-based, one-stage approach, which often suffers from high time complexity or suboptimal designs. In this work, we propose a novel SGG method to address the aforementioned issues, formulating the task as a bipartite graph construction problem. To address the issues above, we create a transformer-based end-to-end framework to generate the entity and entity-aware predicate proposal set, and infer directed edges to form relation triplets. Moreover, we design a graph assembling module to infer the connectivity of the bipartite scene graph based on our entity-aware structure, enabling us to generate the scene graph in an end-to-end manner. Based on bipartite graph assembling paradigm, we further propose a new technical design to address the efficacy of entity-aware modeling and optimization stability of graph assembling. Equi
    
[^18]: 提升下一个目的地预测：一种基于真实航空数据的新颖LSTM方法

    Enhancing Next Destination Prediction: A Novel LSTM Approach Using Real-World Airline Data. (arXiv:2401.12830v1 [cs.LG])

    [http://arxiv.org/abs/2401.12830](http://arxiv.org/abs/2401.12830)

    提出了一种新颖的基于LSTM的模型架构，通过准确捕捉旅行数据中的序列模式和依赖关系，实现了对个人旅行者未来目的地的准确预测。实验结果表明该模型在不同数据规模和性能指标上表现出色，为提升目的地预测方法做出了贡献，并使公司能够提供个性化推荐和优化客户体验。

    

    在现代交通行业中，准确预测旅行者的下一个目的地为公司带来很多好处，例如提高客户满意度和定向营销。本研究旨在开发一种准确捕捉旅行数据中的序列模式和依赖关系的模型，实现对个人旅行者未来目的地的准确预测。为了实现这一目标，提出了一种基于长短期记忆（LSTM）的滑动窗口方法的新颖模型架构，用于交通业中的目的地预测。实验结果表明，该模型在不同数据规模和性能指标上取得了令人满意的表现和高分数。本研究在推进目的地预测方法方面做出了贡献，使公司能够提供个性化推荐并优化动态旅行环境中的客户体验。

    In the modern transportation industry, accurate prediction of travelers' next destinations brings multiple benefits to companies, such as customer satisfaction and targeted marketing. This study focuses on developing a precise model that captures the sequential patterns and dependencies in travel data, enabling accurate predictions of individual travelers' future destinations. To achieve this, a novel model architecture with a sliding window approach based on Long Short-Term Memory (LSTM) is proposed for destination prediction in the transportation industry. The experimental results highlight satisfactory performance and high scores achieved by the proposed model across different data sizes and performance metrics. This research contributes to advancing destination prediction methods, empowering companies to deliver personalized recommendations and optimize customer experiences in the dynamic travel landscape.
    
[^19]: 基于深度强化学习算法的深度学习模拟器用于废水处理中磷去除过程控制

    Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms. (arXiv:2401.12822v1 [eess.SY])

    [http://arxiv.org/abs/2401.12822](http://arxiv.org/abs/2401.12822)

    本研究使用深度强化学习算法创建了磷去除过程控制的模拟器，通过试错来学习控制策略。然而，模拟器的性能在更长时间范围内受到模型误差累积的限制。

    

    磷去除对于废水处理至关重要，以减少对有限资源的依赖。深度强化学习是一种可以通过试错来学习控制策略的机器学习技术，可以优化复杂和非线性的系统，包括废水处理厂的处理过程。然而，将深度强化学习应用于化学和生物过程是具有挑战性的，因为需要准确的模拟器。本研究训练了六个模型来识别磷去除过程，并使用它们创建了一个用于深度强化学习环境的模拟器。虽然模型的准确性很高（>97%），但不确定性和错误预测行为限制了它们作为模拟器在更长时间范围内的性能。模型预测误差的累积被确定为这个问题的原因之一。这种改进过程控制的方法涉及为深度强化学习算法创建模拟环境，使用监控与数据采集系统（SCADA）数据。

    Phosphorus removal is vital in wastewater treatment to reduce reliance on limited resources. Deep reinforcement learning (DRL) is a machine learning technique that can optimize complex and nonlinear systems, including the processes in wastewater treatment plants, by learning control policies through trial and error. However, applying DRL to chemical and biological processes is challenging due to the need for accurate simulators. This study trained six models to identify the phosphorus removal process and used them to create a simulator for the DRL environment. Although the models achieved high accuracy (>97%), uncertainty and incorrect prediction behavior limited their performance as simulators over longer horizons. Compounding errors in the models' predictions were identified as one of the causes of this problem. This approach for improving process control involves creating simulation environments for DRL algorithms, using data from supervisory control and data acquisition (SCADA) sys
    
[^20]: 动态层绑定用于参数高效的Transformer

    Dynamic Layer Tying for Parameter-Efficient Transformers. (arXiv:2401.12819v1 [cs.LG])

    [http://arxiv.org/abs/2401.12819](http://arxiv.org/abs/2401.12819)

    本论文提出了一种动态层绑定的方法，通过使用强化学习动态选择层并将它们绑定在一起，来减少深度Transformer网络中的可训练参数数量并提高性能。

    

    在减少深度Transformer网络中可训练参数的过程中，我们使用强化学习在训练期间动态选择层并将它们绑定在一起。每隔一段时间，RL agent会被询问是否独立训练每个层$i$，还是复制前一个层$j<i$的权重。这样做有助于共享权重，减少可训练参数的数量，同时也作为一种有效的正则化技术。实验评估验证了我们的模型在困惑度方面略优于基准Transformer模型，并且显著减少了可训练参数的数量。特别是，在训练期间的内存消耗比常规训练方法少一个数量级。

    In the pursuit of reducing the number of trainable parameters in deep transformer networks, we employ Reinforcement Learning to dynamically select layers during training and tie them together. Every few iterations, the RL agent is asked whether to train each layer $i$ independently or to copy the weights of a previous layer $j<i$. This facilitates weight sharing, reduces the number of trainable parameters, and also serves as an effective regularization technique. Experimental evaluations validate that our model modestly outperforms the baseline transformer model with regard to perplexity and drastically reduces the number of trainable parameters. In particular, the memory consumption during training is up to one order of magnitude less than the conventional training method.
    
[^21]: 二进制结构的物理信息神经网络用于解决具有快速变化解的方程

    Binary structured physics-informed neural networks for solving equations with rapidly changing solutions. (arXiv:2401.12806v1 [cs.LG])

    [http://arxiv.org/abs/2401.12806](http://arxiv.org/abs/2401.12806)

    本论文提出了一种二进制结构的物理信息神经网络框架，通过利用二进制结构来捕捉局部特征，并解决了传统物理信息神经网络在处理具有快速变化解的方程时的困难。

    

    物理信息神经网络(PINNs)，基于深度学习，已成为解决偏微分方程(PDEs)的一种有前途的方法。通过将PDEs描述的物理信息嵌入前馈神经网络中，PINNs被训练为替代模型，以近似解决方案而无需标签数据。然而，尽管PINNs表现出了卓越的性能，但它们在处理具有快速变化解的方程时可能会遇到困难。这些困难包括收敛速度慢、易陷入局部最小值和解决精度降低。为了解决这些问题，我们提出了一种二进制结构的物理信息神经网络(BsPINN)框架，该框架使用二进制结构的神经网络(BsNN)作为神经网络组件。通过利用二进制结构，BsPINNs在捕捉局部特征方面表现出色

    Physics-informed neural networks (PINNs), rooted in deep learning, have emerged as a promising approach for solving partial differential equations (PDEs). By embedding the physical information described by PDEs into feedforward neural networks, PINNs are trained as surrogate models to approximate solutions without the need for label data. Nevertheless, even though PINNs have shown remarkable performance, they can face difficulties, especially when dealing with equations featuring rapidly changing solutions. These difficulties encompass slow convergence, susceptibility to becoming trapped in local minima, and reduced solution accuracy. To address these issues, we propose a binary structured physics-informed neural network (BsPINN) framework, which employs binary structured neural network (BsNN) as the neural network component. By leveraging a binary structure that reduces inter-neuron connections compared to fully connected neural networks, BsPINNs excel in capturing the local features 
    
[^22]: 5G NR PRACH接收的增强：一种基于AI/ML的方法

    Enhancements for 5G NR PRACH Reception: An AI/ML Approach. (arXiv:2401.12803v1 [cs.IT])

    [http://arxiv.org/abs/2401.12803](http://arxiv.org/abs/2401.12803)

    这项研究提出了一种基于AI/ML的方法来增强5G NR PRACH接收，通过使用两个神经网络分别估计RAPID和TA，与传统相关方法相比，实验证明了这种方法在性能上的改进。

    

    随机接入是使用户设备（UE）与基站（gNB）进行最初连接的重要步骤。UE通过嵌入在已知基序列的相位旋转中的前导索引（RAPID）来进行自我识别，并将其发送到物理随机接入通道（PRACH）。PRACH上的信号还能够估计由UE位置引起的传播时延（常称为时间提前，TA）。传统接收器使用基于相关技术的方法来估计RAPID和TA。本文介绍了一种使用AI/ML模型的替代接收器方法，其中提出了两个神经网络，一个用于RAPID，一个用于TA。与其他研究不同，这两个模型可以并行运行，而不是顺序运行。通过使用模拟数据和实际硬件捕获的实验，我们证明了基于AI/ML的技术相对于传统的相关方法具有更好的性能。

    Random Access is an important step in enabling the initial attachment of a User Equipment (UE) to a Base Station (gNB). The UE identifies itself by embedding a Preamble Index (RAPID) in the phase rotation of a known base sequence, which it transmits on the Physical Random Access Channel (PRACH). The signal on the PRACH also enables the estimation of propagation delay, often known as Timing Advance (TA), which is induced by virtue of the UE's position. Traditional receivers estimate the RAPID and TA using correlation-based techniques. This paper presents an alternative receiver approach that uses AI/ML models, wherein two neural networks are proposed, one for the RAPID and one for the TA. Different from other works, these two models can run in parallel as opposed to sequentially. Experiments with both simulated data and over-the-air hardware captures highlight the improved performance of the proposed AI/ML-based techniques compared to conventional correlation methods.
    
[^23]: 深度学习方法在光电容积法数据中的应用综述

    A Review of Deep Learning Methods for Photoplethysmography Data. (arXiv:2401.12783v1 [cs.AI])

    [http://arxiv.org/abs/2401.12783](http://arxiv.org/abs/2401.12783)

    本综述系统地回顾了自2017年至2023年期间应用深度学习模型处理光电容积法数据的论文。研究发现，深度学习在个人健康管理和其他应用中具有显著成果。根据任务的不同，这些论文被分为医学相关和非医学相关两大类别，医学相关又细分为七个子组，包括血压分析...

    

    光电容积法（PPG）是一种非常有前景的设备，因为它具有便携性、用户友好操作和非侵入性测量多种生理信息的能力。深度学习的最新进展，通过利用PPG信号，展示了在个人健康管理和其他多方面应用任务上取得了显著的成果。本综述系统地回顾了自2017年1月1日至2023年7月31日期间在Google学术、PubMed和Dimensions发表的应用深度学习模型处理PPG数据的论文。每篇论文从任务、模型和数据三个关键角度进行分析。最终提取了193篇论文，其中使用了不同的深度学习框架来处理PPG信号。根据这些论文所涉及的任务，我们将它们分为两大类别：医学相关和非医学相关。医学相关任务进一步分为七个子组，包括血压分析...

    Photoplethysmography (PPG) is a highly promising device due to its advantages in portability, user-friendly operation, and non-invasive capabilities to measure a wide range of physiological information. Recent advancements in deep learning have demonstrated remarkable outcomes by leveraging PPG signals for tasks related to personal health management and other multifaceted applications. In this review, we systematically reviewed papers that applied deep learning models to process PPG data between January 1st of 2017 and July 31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzed from three key perspectives: tasks, models, and data. We finally extracted 193 papers where different deep learning frameworks were used to process PPG signals. Based on the tasks addressed in these papers, we categorized them into two major groups: medical-related, and non-medical-related. The medical-related tasks were further divided into seven subgroups, including blood pressure anal
    
[^24]: 基于深度学习的术中磁共振成像重建

    Deep Learning-based Intraoperative MRI Reconstruction. (arXiv:2401.12771v1 [eess.IV])

    [http://arxiv.org/abs/2401.12771](http://arxiv.org/abs/2401.12771)

    本研究评估了基于深度学习的术中磁共振成像重建方法在脑肿瘤手术中的质量，并与传统的压缩感知方法进行了比较。结果表明，深度学习重建方法在质量上表现优异。

    

    目的：评估深度学习重建用于术中磁共振成像（iMRI）在脑肿瘤手术中的质量。材料和方法：在脑手术中使用放置在切除区域周围的双表面线圈进行加速iMRI。使用fastMRI神经数据集训练了一个深度学习（DL）模型，以模拟iMRI协议的数据。评估了40名在2021年11月1日至2023年6月1日期间进行脑肿瘤切除手术期间进行iMRI的患者的成像材料。在传统的压缩感知（CS）方法和训练过的DL重建方法之间进行了比较分析。两位神经放射科医师和一位神经外科医生以1至5的Likert量表（1=非诊断、2=差、3=可接受、4=好、5=优秀）进行了盲评估，并选择最佳的重建变体。

    Purpose: To evaluate the quality of deep learning reconstruction for prospectively accelerated intraoperative magnetic resonance imaging (iMRI) during resective brain tumor surgery.  Materials and Methods: Accelerated iMRI was performed during brain surgery using dual surface coils positioned around the area of resection. A deep learning (DL) model was trained on the fastMRI neuro dataset to mimic the data from the iMRI protocol. Evaluation was performed on imaging material from 40 patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI during tumor resection surgery. A comparative analysis was conducted between the conventional compressed sense (CS) method and the trained DL reconstruction method. Blinded evaluation of multiple image quality metrics was performed by two working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likert scale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and the favored reconstruction variant.  Results: The DL reconst
    
[^25]: What the Weight?! 零样本知识组合的统一框架

    What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition. (arXiv:2401.12756v1 [cs.CL])

    [http://arxiv.org/abs/2401.12756](http://arxiv.org/abs/2401.12756)

    本研究提出了一个新的零样本模块组合框架，统一了选择、加权和组合参数模块的各种变化。以领域知识和适配器层为场景，通过系统化的统一概念，进行了首次全面的零样本知识组合的基准研究。

    

    模型中所封装的知识是确定其在下游任务中最终性能的核心因素。自然语言处理领域的许多研究都集中在存储和调整不同类型知识的有效方法上，例如在专用的模块化结构中，以及如何通过学习额外的参数来有效地组合这些知识。然而，鉴于存在许多可能的选项，对于这些组合中涉及的机制缺乏全面的理解，因此目前仍不清楚应该使用哪些策略。为了填补这一研究空白，我们提出了一个新的零样本模块组合框架，它涵盖了现有的一些选择、加权和组合参数模块的变化，统一了这些概念。在聚焦领域知识和适配器层的情景下，我们的框架提供了一个系统化的统一概念，使我们能够进行首次全面的各种零样本知识组合的基准研究。

    The knowledge encapsulated in a model is the core factor determining its final performance on downstream tasks. Much research in NLP has focused on efficient methods for storing and adapting different types of knowledge, e.g., in dedicated modularized structures, and on how to effectively combine these, e.g., by learning additional parameters. However, given the many possible options, a thorough understanding of the mechanisms involved in these compositions is missing, and hence it remains unclear which strategies to utilize. To address this research gap, we propose a novel framework for zero-shot module composition, which encompasses existing and some novel variations for selecting, weighting, and combining parameter modules under a single unified notion. Focusing on the scenario of domain knowledge and adapter layers, our framework provides a systematic unification of concepts, allowing us to conduct the first comprehensive benchmarking study of various zero-shot knowledge compositio
    
[^26]: SHAP评分在可解释机器学习中的分布不确定性

    The Distributional Uncertainty of the SHAP score in Explainable Machine Learning. (arXiv:2401.12731v1 [cs.AI])

    [http://arxiv.org/abs/2401.12731](http://arxiv.org/abs/2401.12731)

    本研究提出了一个原则性框架，用于处理在未知实体群体分布下的SHAP评分问题。通过考虑一个不确定性区域，我们可以确定所有特征的SHAP评分的紧束范围。

    

    归属分数反映了输入实体中的特征值对机器学习模型输出的重要性。其中最受欢迎的评分之一是SHAP评分，它是合作博弈理论中Shapley值的具体实例。该评分的定义依赖于实体群体的概率分布。由于通常不知道精确的分布，因此需要主观地进行分配或从数据中进行估计，这可能会导致误导性的特征评分。在本文中，我们提出了一个基于不知道实体群体分布的SHAP评分推理的原则性框架。在我们的框架中，我们考虑一个包含潜在分布的不确定性区域，而特征的SHAP评分成为在该区域上定义的一个函数。我们研究了找到该函数的最大值和最小值的基本问题，这使我们能够确定所有特征的SHAP评分的紧束范围。

    Attribution scores reflect how important the feature values in an input entity are for the output of a machine learning model. One of the most popular attribution scores is the SHAP score, which is an instantiation of the general Shapley value used in coalition game theory. The definition of this score relies on a probability distribution on the entity population. Since the exact distribution is generally unknown, it needs to be assigned subjectively or be estimated from data, which may lead to misleading feature scores. In this paper, we propose a principled framework for reasoning on SHAP scores under unknown entity population distributions. In our framework, we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region. We study the basic problems of finding maxima and minima of this function, which allows us to determine tight ranges for the SHAP scores of all features. In particular, we pinp
    
[^27]: 评估大规模语言模型用于评估代码可维护性

    Evaluation of large language models for assessing code maintainability. (arXiv:2401.12714v1 [cs.SE])

    [http://arxiv.org/abs/2401.12714](http://arxiv.org/abs/2401.12714)

    本文评估大规模语言模型用于评估代码可维护性，发现通过比较生成的代码的概率与当前代码可能具有的概率可以指示潜在的质量问题，且交叉熵是可维护性的预测因子。

    

    开源软件仓库的可用性增加以及利用大规模语言模型（LLMs）进行代码分析的最新进展已经引发了一系列尝试自动化之前非常难以自动化的软件工程任务的新工作。本文研究了最近的一项工作，假设通过比较LLMs生成的代码的概率与当前代码可能具有的概率可以指示潜在的质量问题。我们调查了十种不同模型（基于GPT2和Llama2）生成的代码的交叉熵与可读性、可理解性、复杂性、模块化以及由专家评估并在基准数据集中可用的总体可维护性之间的关联。我们的结果表明，在控制逻辑代码行数（LLOC）的情况下，由LLMs计算得到的交叉熵确实是类级别上可维护性的预测因子（交叉熵越高，可维护性越低）。

    Increased availability of open-source software repositories and recent advances in code analysis using large language models (LLMs) has triggered a wave of new work to automate software engineering tasks that were previously very difficult to automate. In this paper, we investigate a recent line of work that hypothesises that comparing the probability of code generated by LLMs with the probability the current code would have had can indicate potential quality problems. We investigate the association between the cross-entropy of code generated by ten different models (based on GPT2 and Llama2) and the following quality aspects: readability, understandability, complexity, modularisation, and overall maintainability assessed by experts and available in an benchmark dataset. Our results show that, controlling for the number of logical lines of codes (LLOC), cross-entropy computed by LLMs is indeed a predictor of maintainability on a class level (the higher the cross-entropy the lower the m
    
[^28]: 用于选择性分类的深度神经网络基准

    Deep Neural Network Benchmarks for Selective Classification. (arXiv:2401.12708v1 [cs.LG])

    [http://arxiv.org/abs/2401.12708](http://arxiv.org/abs/2401.12708)

    本论文研究了用于选择性分类的深度神经网络，目的是设计一种选择机制来平衡被拒绝的预测比例和所选预测的预测性能改进。

    

    随着机器学习模型在许多具有社会敏感性的任务中的部署增加，对可靠和可信预测的需求也日益增长。实现这些要求的一种方法是允许模型在存在高错误风险时放弃进行预测。这需要为模型添加选择机制，该机制选择模型将提供预测的例子。选择性分类框架旨在设计一个平衡被拒绝预测比例（即模型不进行预测的例子比例）与在所选预测上的预测性能改进之间的机制。存在多个选择性分类框架，其中大多数依赖于深度神经网络架构。然而，现有方法的实证评估仍局限于部分方法和设置之间的比较，给实践者提供了很少的见解。

    With the increasing deployment of machine learning models in many socially-sensitive tasks, there is a growing demand for reliable and trustworthy predictions. One way to accomplish these requirements is to allow a model to abstain from making a prediction when there is a high risk of making an error. This requires adding a selection mechanism to the model, which selects those examples for which the model will provide a prediction. The selective classification framework aims to design a mechanism that balances the fraction of rejected predictions (i.e., the proportion of examples for which the model does not make a prediction) versus the improvement in predictive performance on the selected predictions. Multiple selective classification frameworks exist, most of which rely on deep neural network architectures. However, the empirical evaluation of the existing approaches is still limited to partial comparisons among methods and settings, providing practitioners with little insight into 
    
[^29]: 通过合作训练来保护推荐系统

    Securing Recommender System via Cooperative Training. (arXiv:2401.12700v1 [cs.AI])

    [http://arxiv.org/abs/2401.12700](http://arxiv.org/abs/2401.12700)

    本研究提出了一种综合数据处理和鲁棒模型的通用框架来保护推荐系统，并引入了一种高效的攻击策略。研究揭示了现有攻击威胁不足的原因。

    

    推荐系统往往容易受到精心制作的虚假个人资料的影响，导致推荐结果存在偏见。在现有的防御方法中，基于数据处理的方法不可避免地会排除正常样本，而基于模型的方法则无法同时实现泛化性和鲁棒性。为此，我们提出了一个综合数据处理和鲁棒模型的通用框架，Triple Cooperative Defense（TCD），它采用三个协同模型相互增强数据，从而提高推荐的鲁棒性。此外，考虑到现有攻击方法在平衡双层优化和效率方面存在困难，我们重新审视了推荐系统中的攻击问题，并引入了一种高效的攻击策略，Co-training Attack（Co-Attack），该策略在考虑双层设置的同时，协同优化攻击优化和模型训练，保持攻击的效率。此外，我们揭示了现有攻击威胁不足的一个潜在原因。

    Recommender systems are often susceptible to well-crafted fake profiles, leading to biased recommendations. Among existing defense methods, data-processing-based methods inevitably exclude normal samples, while model-based methods struggle to enjoy both generalization and robustness. To this end, we suggest integrating data processing and the robust model to propose a general framework, Triple Cooperative Defense (TCD), which employs three cooperative models that mutually enhance data and thereby improve recommendation robustness. Furthermore, Considering that existing attacks struggle to balance bi-level optimization and efficiency, we revisit poisoning attacks in recommender systems and introduce an efficient attack strategy, Co-training Attack (Co-Attack), which cooperatively optimizes the attack optimization and model training, considering the bi-level setting while maintaining attack efficiency. Moreover, we reveal a potential reason for the insufficient threat of existing attacks
    
[^30]: 基于能量的自动化模型评估

    Energy-based Automated Model Evaluation. (arXiv:2401.12689v1 [cs.LG])

    [http://arxiv.org/abs/2401.12689](http://arxiv.org/abs/2401.12689)

    提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。

    

    传统的机器学习模型评估协议依赖于标记的、假设独立同分布的测试数据集，而这在实际应用中往往并不常见。自动模型评估（AutoEval）提出了一种替代传统工作流程的方法，通过形成一个接近预测性能的测试管线，而无需真实标签的存在。尽管AutoEval框架近年来取得了一些成功，但仍存在过度自信、存储和计算成本高的问题。因此，我们提出了一种新颖的度量方式——元分布能量（MDE），它可以使AutoEval框架更加高效和有效。MDE的核心是建立一个关于个体样本相关信息（能量）的元分布统计量，然后通过基于能量的学习提供更平滑的表示能力。我们通过将MDE与分类损失相连接，进一步提供了理论洞见。我们还提供了大量实验证据来验证我们的方法。

    The conventional evaluation protocols on machine learning models rely heavily on a labeled, i.i.d-assumed testing dataset, which is not often present in real world applications. The Automated Model Evaluation (AutoEval) shows an alternative to this traditional workflow, by forming a proximal prediction pipeline of the testing performance without the presence of ground-truth labels. Despite its recent successes, the AutoEval frameworks still suffer from an overconfidence issue, substantial storage and computational cost. In that regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that allows the AutoEval framework to be both more efficient and effective. The core of the MDE is to establish a meta-distribution statistic, on the information (energy) associated with individual samples, then offer a smoother representation enabled by energy-based learning. We further provide our theoretical insights by connecting the MDE with the classification loss. We provide extensive
    
[^31]: 在稀疏图上学习平均场对局博弈：一种混合图形扩展方法

    Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach. (arXiv:2401.12686v1 [cs.MA])

    [http://arxiv.org/abs/2401.12686](http://arxiv.org/abs/2401.12686)

    这篇论文提出了一种在稀疏图上学习平均场对局博弈的新方法，通过引入图形扩展的概念，解决了现有方法对于稀疏网络拓扑结构的限制。

    

    学习大规模代理群体的行为是许多研究领域中的重要任务。虽然多代理强化学习（MARL）领域在解决这些系统方面取得了重要进展，但对于许多代理的解决方案通常在计算上是不可行的，且缺乏理论保证。平均场对局博弈（MFGs）解决了这两个问题，并且可以扩展到包括代理之间的网络结构的图形平均场对局博弈（GMFGs）。尽管具有诸多优点，但GMFGs的现实世界应用受到图形只能捕捉密集图的限制。由于大多数实验证明的网络显示出一定程度的稀疏性，例如幂律图，因此GMFG框架无法捕捉这些网络拓扑结构。因此，我们提出了一种新颖的图形对局博弈（GXMFGs）的概念，它建立在图论概念图形扩展（graphexes）基础上。图形扩展是稀疏图序列的极限对象，还具有其他一些理想特性，如sma

    Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the sma
    
[^32]: Kriging 的扩展:一种新的对比性典型学习方法

    Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning. (arXiv:2401.12681v1 [cs.LG])

    [http://arxiv.org/abs/2401.12681](http://arxiv.org/abs/2401.12681)

    这篇论文提出了一种新的对比性典型学习方法，用于改进Kriging过程中邻居和非邻居的信息利用，从而提高属性估计的准确性。

    

    Kriging的目标是通过空间邻近或物理连接中的观测值来估计未采样地理位置的属性，从而有助于减轻由于部署不足的传感器引起的监测偏差。现有的工作假设邻居的信息为估计未观察到的目标的属性提供基础，而忽略了非邻居。然而，非邻居也可以提供有益的信息，而邻居也可能是误导性的。为此，我们提出了一种称为“对比性典型”自监督学习的扩展方法，用于改进邻居的有价值信息并回收非邻居的信息。作为预训练范式，我们从表示的新视角进行Kriging任务：我们首先学习强大而通用的表示，然后从表示中恢复属性。设计了一个邻居对比模块，通过缩小目标与邻居的表示距离，粗略地学习表示。

    Kriging aims at estimating the attributes of unsampled geo-locations from observations in the spatial vicinity or physical connections, which helps mitigate skewed monitoring caused by under-deployed sensors. Existing works assume that neighbors' information offers the basis for estimating the attributes of the unobserved target while ignoring non-neighbors. However, non-neighbors could also offer constructive information, and neighbors could also be misleading. To this end, we propose ``Contrastive-Prototypical'' self-supervised learning for Kriging (KCP) to refine valuable information from neighbors and recycle the one from non-neighbors. As a pre-trained paradigm, we conduct the Kriging task from a new perspective of representation: we aim to first learn robust and general representations and then recover attributes from representations. A neighboring contrastive module is designed that coarsely learns the representations by narrowing the representation distance between the target a
    
[^33]: ChatGraph: 与图进行对话

    ChatGraph: Chat with Your Graphs. (arXiv:2401.12672v1 [cs.AI])

    [http://arxiv.org/abs/2401.12672](http://arxiv.org/abs/2401.12672)

    ChatGraph是一个基于大型语言模型的框架，它使用户能够通过自然语言与图进行交互，比传统方法更加简单和灵活。ChatGraph通过生成图分析API链来实现对用户输入的文本和图像的理解。

    

    图分析在现实世界的应用中是基础性的。传统方法要么依赖于类似SPARQL的语言，要么依赖于点击和拖动式的界面与图数据进行交互。然而，这些方法要么要求用户具备高级编程技能，要么仅支持有限范围的图分析功能。为解决这些限制，我们提出了一个基于大型语言模型（LLM）的框架，称为ChatGraph。通过ChatGraph，用户可以通过自然语言与图进行交互，使得使用比传统方法更加简单和灵活。ChatGraph的核心在于基于对用户提示中的文本和图像的理解生成图分析API链。为实现这一目标，ChatGraph包括三个主要模块：API检索模块用于搜索相关API，图分析LLM模块使LLM能够理解图数据，以及API链导向的微调模块用于指导LLM生成API链。

    Graph analysis is fundamental in real-world applications. Traditional approaches rely on SPARQL-like languages or clicking-and-dragging interfaces to interact with graph data. However, these methods either require users to possess high programming skills or support only a limited range of graph analysis functionalities. To address the limitations, we propose a large language model (LLM)-based framework called ChatGraph. With ChatGraph, users can interact with graphs through natural language, making it easier to use and more flexible than traditional approaches. The core of ChatGraph lies in generating chains of graph analysis APIs based on the understanding of the texts and graphs inputted in the user prompts. To achieve this, ChatGraph consists of three main modules: an API retrieval module that searches for relevant APIs, a graph-aware LLM module that enables the LLM to comprehend graphs, and an API chain-oriented finetuning module that guides the LLM in generating API chains.
    
[^34]: EL-VIT: 使用交互式可视化探测视觉变压器

    EL-VIT: Probing Vision Transformer with Interactive Visualization. (arXiv:2401.12666v1 [cs.AI])

    [http://arxiv.org/abs/2401.12666](http://arxiv.org/abs/2401.12666)

    本文介绍了EL-VIT，一个交互式可视化系统，旨在探测视觉变压器并促进对其操作的更好理解。

    

    如今，视觉变压器（ViT）在各种计算机视觉任务中广泛使用，由于其独特的自注意机制。然而，ViT的模型架构复杂，往往难以理解，导致学习曲线陡峭。ViT的开发者和用户经常遇到解释其内部工作的困难。因此，需要一个可视化系统来帮助ViT用户理解其功能。本文介绍了EL-VIT，这是一个交互式的可视分析系统，旨在探测视觉变压器并促进对其操作的更好理解。该系统包括四个层次的可视化视图。前三个层次包括模型概述、知识背景图和模型详细视图。这三个层次从总体模型架构、详细解释和数学操作的三个角度阐明了ViT的操作过程，使用户能够理解其基本原理。

    Nowadays, Vision Transformer (ViT) is widely utilized in various computer vision tasks, owing to its unique self-attention mechanism. However, the model architecture of ViT is complex and often challenging to comprehend, leading to a steep learning curve. ViT developers and users frequently encounter difficulties in interpreting its inner workings. Therefore, a visualization system is needed to assist ViT users in understanding its functionality. This paper introduces EL-VIT, an interactive visual analytics system designed to probe the Vision Transformer and facilitate a better understanding of its operations. The system consists of four layers of visualization views. The first three layers include model overview, knowledge background graph, and model detail view. These three layers elucidate the operation process of ViT from three perspectives: the overall model architecture, detailed explanation, and mathematical operations, enabling users to understand the underlying principles and 
    
[^35]: ClipSAM：CLIP和SAM的合作用于零样本异常分割

    ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation. (arXiv:2401.12665v1 [cs.CV])

    [http://arxiv.org/abs/2401.12665](http://arxiv.org/abs/2401.12665)

    这项工作提出了一种名为ClipSAM的CLIP和SAM协作框架，用于零样本异常分割。ClipSAM利用CLIP的语义理解能力进行异常定位和粗糙分割，然后将其用作SAM的提示约束，进一步改进异常分割结果。

    

    最近，基于CLIP和SAM等基础模型在零样本异常分割（ZSAS）任务中表现出了很有希望的性能。然而，无论是基于CLIP还是SAM的ZSAS方法仍然存在一些不可忽视的关键缺点：1）CLIP主要关注不同输入之间的全局特征对齐，导致对局部异常部分的分割不准确；2）SAM倾向于生成大量没有适当提示约束的冗余掩码，导致复杂的后处理要求。在这项工作中，我们创新性地提出了一种名为ClipSAM的CLIP和SAM协作框架，用于ZSAS。ClipSAM的思路是利用CLIP的语义理解能力进行异常定位和粗糙分割，进一步将其用作提供提示约束以改进SAM的异常分割结果。具体地，我们引入了一个关键的统一多尺度跨模态交互（UMCI）模块，用于在多个尺度上相互作用语言和视觉特征。

    Recently, foundational models such as CLIP and SAM have shown promising performance for the task of Zero-Shot Anomaly Segmentation (ZSAS). However, either CLIP-based or SAM-based ZSAS methods still suffer from non-negligible key drawbacks: 1) CLIP primarily focuses on global feature alignment across different inputs, leading to imprecise segmentation of local anomalous parts; 2) SAM tends to generate numerous redundant masks without proper prompt constraints, resulting in complex post-processing requirements. In this work, we innovatively propose a CLIP and SAM collaboration framework called ClipSAM for ZSAS. The insight behind ClipSAM is to employ CLIP's semantic understanding capability for anomaly localization and rough segmentation, which is further used as the prompt constraints for SAM to refine the anomaly segmentation results. In details, we introduce a crucial Unified Multi-scale Cross-modal Interaction (UMCI) module for interacting language with visual features at multiple sc
    
[^36]: 将人类专业知识融入连续空间: 一种新颖的具有偏好预期改善的交互式贝叶斯优化框架

    Integrating Human Expertise in Continuous Spaces: A Novel Interactive Bayesian Optimization Framework with Preference Expected Improvement. (arXiv:2401.12662v1 [cs.RO])

    [http://arxiv.org/abs/2401.12662](http://arxiv.org/abs/2401.12662)

    提出了一种将人类专业知识与机器学习相结合的新型交互式贝叶斯优化框架，通过捕捉用户偏好和引入新的收益函数提高机器学习系统的效率。

    

    交互式机器学习（IML）旨在将人类专业知识与机器学习过程相结合。然而，大多数现有算法不能应用于实际场景，因为它们的状态空间和/或行为空间仅限于离散值。此外，所有现有方法之间的交互受到在多个建议之间做出决策的限制。因此，我们提出了一种基于贝叶斯优化（BO）的新型框架。交互式贝叶斯优化（IBO）实现了机器学习算法和人类之间的合作。该框架捕捉用户偏好，并提供界面给用户手动调整策略。此外，我们还加入了一种新的收益函数，偏好预期改善（PEI），通过用户偏好的概率模型来提高系统的效率。我们的方法旨在确保机器能从人类专业知识中受益，以实现更加协调和有效的学习过程。

    Interactive Machine Learning (IML) seeks to integrate human expertise into machine learning processes. However, most existing algorithms cannot be applied to Realworld Scenarios because their state spaces and/or action spaces are limited to discrete values. Furthermore, the interaction of all existing methods is restricted to deciding between multiple proposals. We therefore propose a novel framework based on Bayesian Optimization (BO). Interactive Bayesian Optimization (IBO) enables collaboration between machine learning algorithms and humans. This framework captures user preferences and provides an interface for users to shape the strategy by hand. Additionally, we've incorporated a new acquisition function, Preference Expected Improvement (PEI), to refine the system's efficiency using a probabilistic model of the user preferences. Our approach is geared towards ensuring that machines can benefit from human expertise, aiming for a more aligned and effective learning process. In the c
    
[^37]: 不确定激励对新兴合作的影响研究

    Emergent Cooperation under Uncertain Incentive Alignment. (arXiv:2401.12646v1 [cs.MA])

    [http://arxiv.org/abs/2401.12646](http://arxiv.org/abs/2401.12646)

    本研究研究了在存在不确定的激励一致性情况下，如何训练强化学习代理人在不频繁交互的情况下建立合作行为。研究发现，不确定性明显降低了代理人从事合作行为的能力。

    

    理解计算代理系统中合作的出现对于开发有效的合作人工智能至关重要。真实世界中个体之间的交互通常稀少，并在广泛的激励范围内发生，这些激励通常只有部分知晓。本研究探讨了在遇到不频繁的情况和代理人面临对其激励与他人激励的一致性存在不确定性的情况下，如何在强化学习代理人之间建立合作。为此，我们在各种不同环境下训练代理人，从完全竞争到完全合作再到混合动机。在这种不确定性下，我们研究了文献中提出的用于在混合动机环境中促进合作的机制，如声誉和内在奖励。我们的发现显示，不确定性显著降低了代理人从事合作行为的能力，尤其是当这种合作行为需要团结一致时。

    Understanding the emergence of cooperation in systems of computational agents is crucial for the development of effective cooperative AI. Interaction among individuals in real-world settings are often sparse and occur within a broad spectrum of incentives, which often are only partially known. In this work, we explore how cooperation can arise among reinforcement learning agents in scenarios characterised by infrequent encounters, and where agents face uncertainty about the alignment of their incentives with those of others. To do so, we train the agents under a wide spectrum of environments ranging from fully competitive, to fully cooperative, to mixed-motives. Under this type of uncertainty we study the effects of mechanisms, such as reputation and intrinsic rewards, that have been proposed in the literature to foster cooperation in mixed-motives environments. Our findings show that uncertainty substantially lowers the agents' ability to engage in cooperative behaviour, when that wou
    
[^38]: 碰撞化人工智能系统的韧性建模

    Modeling Resilience of Collaborative AI Systems. (arXiv:2401.12632v1 [cs.SE])

    [http://arxiv.org/abs/2401.12632](http://arxiv.org/abs/2401.12632)

    本文提供了一个新的框架，用于建模碰撞化人工智能系统在遇到不利事件时的性能。

    

    碰撞化人工智能系统（CAIS）与人类合作执行行动以实现共同目标。 CAIS可以使用经过训练的人工智能模型来控制人-系统交互，也可以使用人类交互以在线方式动态地从人类中学习。在带有人类反馈的在线学习中，通过系统传感器在学习状态下监测人类交互，AI模型通过学习在操作状态下激活CAIS的自主组件。因此，任何影响这些传感器的不利事件可能会影响AI模型做出准确决策的能力并降低CAIS的性能。因此，CAIS管理者能够自动跟踪系统性能以了解CAIS在此类不利事件中的韧性至关重要。在本文中，我们提供了一个新的框架，用于在系统遇到不利事件时建模CAIS的性能。

    A Collaborative Artificial Intelligence System (CAIS) performs actions in collaboration with the human to achieve a common goal. CAISs can use a trained AI model to control human-system interaction, or they can use human interaction to dynamically learn from humans in an online fashion. In online learning with human feedback, the AI model evolves by monitoring human interaction through the system sensors in the learning state, and actuates the autonomous components of the CAIS based on the learning in the operational state. Therefore, any disruptive event affecting these sensors may affect the AI model's ability to make accurate decisions and degrade the CAIS performance. Consequently, it is of paramount importance for CAIS managers to be able to automatically track the system performance to understand the resilience of the CAIS upon such disruptive events. In this paper, we provide a new framework to model CAIS performance when the system experiences a disruptive event. With our frame
    
[^39]: 对Makelov等人(2023)的《可解释性错觉》论点的回应

    A Reply to Makelov et al. (2023)'s "Interpretability Illusion" Arguments. (arXiv:2401.12631v1 [cs.LG])

    [http://arxiv.org/abs/2401.12631](http://arxiv.org/abs/2401.12631)

    本文回应了Makelov等人(2023)的论文，该论文评述了子空间交换干预方法的"解释性错觉"问题。我们指出，所谓的"解释性错觉"可以包括直观和可取的解释，而Makelov等人(2023)发现的"错觉"是他们训练和评估范例的产物。尽管我们不同意他们的核心表述，但他们的例子和讨论推动了可解释性领域的发展。

    

    我们回应了Makelov等人(2023)的最新论文，该论文评述了诸如分布式对齐搜索(DAS; Geiger等人，2023)这样的子空间交换干预方法，并声称这些方法可能引起"解释性错觉"。我们首先回顾了Makelov等人(2023)对"解释性错觉"的技术概念，然后展示了即使直观和可取的解释在这个意义上也可能成为错觉。因此，他们发现"错觉"的方法可能会拒绝他们认为"非错觉"的解释。接着，我们认为Makelov等人(2023)在实践中看到的"错觉"是他们训练和评估范例的产物。最后，我们强调，尽管我们不同意他们的核心表述，但Makelov等人(2023)的例子和讨论无疑推动了可解释性领域的发展。

    We respond to the recent paper by Makelov et al. (2023), which reviews subspace interchange intervention methods like distributed alignment search (DAS; Geiger et al. 2023) and claims that these methods potentially cause "interpretability illusions". We first review Makelov et al. (2023)'s technical notion of what an "interpretability illusion" is, and then we show that even intuitive and desirable explanations can qualify as illusions in this sense. As a result, their method of discovering "illusions" can reject explanations they consider "non-illusory". We then argue that the illusions Makelov et al. (2023) see in practice are artifacts of their training and evaluation paradigms. We close by emphasizing that, though we disagree with their core characterization, Makelov et al. (2023)'s examples and discussion have undoubtedly pushed the field of interpretability forward.
    
[^40]: 面向多智能体远程控制的基于语言到新兴通信的知识蒸馏

    Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control. (arXiv:2401.12624v1 [cs.AI])

    [http://arxiv.org/abs/2401.12624](http://arxiv.org/abs/2401.12624)

    这项工作通过将语言导向的语义通信与新兴通信相结合，通过知识蒸馏的方式，提出了一种面向多智能体远程控制的新框架，实现了更快的行程时间和更高的训练收敛速度。

    

    在这项工作中，我们比较了基于多智能体深度强化学习（MADRL）的新兴通信（EC）和由预训练的大型语言模型（LLM）使用人类语言的面向语言的语义通信（LSC）。在一个多智能体远程导航任务中，使用包含位置和通道地图的多模态输入数据，结果表明，EC在使用多模态数据时会产生高的训练成本和困难，而LSC由于LLM尺寸较大，会导致高的推理计算成本。为了解决它们各自的瓶颈，我们提出了一种通过知识蒸馏（KD）引导EC训练使用LSC的新颖框架：语言引导的EC（LEC）。模拟验证了LEC实现了更快的行程时间，避免了信道质量差的区域，并且在与EC相比能够加速MADRL训练收敛达到61.8%。

    In this work, we compare emergent communication (EC) built upon multi-agent deep reinforcement learning (MADRL) and language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM) using human language. In a multi-agent remote navigation task, with multimodal input data comprising location and channel maps, it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size. To address their respective bottlenecks, we propose a novel framework of language-guided EC (LEC) by guiding the EC training using LSC via knowledge distillation (KD). Simulations corroborate that LEC achieves faster travel time while avoiding areas with poor channel conditions, as well as speeding up the MADRL training convergence by up to 61.8% compared to EC.
    
[^41]: 用增强的PDF结构识别来革新检索增强的生成模型

    Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition. (arXiv:2401.12599v1 [cs.AI])

    [http://arxiv.org/abs/2401.12599](http://arxiv.org/abs/2401.12599)

    本论文通过增强的PDF结构识别来革新检索增强的生成模型，解决了专业文档中PDF解析的低准确性对基于专业知识问答的影响，提高了问答的准确性和效率。

    

    随着大型语言模型（LLM）的快速发展，检索增强的生成（RAG）已成为专业知识问答领域中的主要方法。目前，主要的基础模型公司已经开放了嵌入式和聊天API接口，而LangChain等框架已经整合了RAG流程。看似RAG中的关键模型和步骤已经得到解决，这就引出了一个问题：专业知识问答系统是否接近完美了？本文发现当前的主要方法依赖于访问高质量的文本语料库的前提。然而，由于专业文档主要以PDF形式存储，PDF解析的低准确性显著影响了基于专业知识的问答的效果。我们在数百个来自相应真实世界专业文档的问题上进行了经验性的RAG实验。结果显示，ChatDOC是一个配备了全景视图功能的RAG系统，能够提高问答的准确性和效率。

    With the rapid development of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) has become a predominant method in the field of professional knowledge-based question answering. Presently, major foundation model companies have opened up Embedding and Chat API interfaces, and frameworks like LangChain have already integrated the RAG process. It appears that the key models and steps in RAG have been resolved, leading to the question: are professional knowledge QA systems now approaching perfection? This article discovers that current primary methods depend on the premise of accessing high-quality text corpora. However, since professional documents are mainly stored in PDFs, the low accuracy of PDF parsing significantly impacts the effectiveness of professional knowledge-based QA. We conducted an empirical RAG experiment across hundreds of questions from the corresponding real-world professional documents. The results show that, ChatDOC, a RAG system equipped with a panopt
    
[^42]: MOReGIn: 多目标推荐在全局和个体层面上的应用

    MOReGIn: Multi-Objective Recommendation at the Global and Individual Levels. (arXiv:2401.12593v1 [cs.IR])

    [http://arxiv.org/abs/2401.12593](http://arxiv.org/abs/2401.12593)

    MOReGIn是一种多目标推荐系统，可以同时在全局和个体层面上满足多个目标。通过调节推荐列表，MORS可以保证推荐的流派校准和供应商公平性。验证实验表明了该方法的有效性。

    

    多目标推荐系统（MORS）作为一种保证多个目标的范式出现。除了准确性外，MORS可以在全局层面上工作，为整个系统实现除准确性之外的其他目标，也可以在个体层面上工作，这意味着推荐是根据每个用户的需求定制的。现有的MORS要么在全局层面上工作，要么在个体层面上工作，而不假设这两种观点的共存。在本研究中，我们表明当全局和个体目标共存时，MORS无法同时满足这两种目标。为了解决这个问题，我们提出了一种方法，通过调节推荐列表来保证全局和个体的观点，同时保持其有效性。具体而言，作为个体角度，我们解决了流派校准问题，作为全局角度，我们解决了供应商公平性问题。我们在两个实际数据集上验证了我们的方法，这些数据集与本文一同公开发布。

    Multi-Objective Recommender Systems (MORSs) emerged as a paradigm to guarantee multiple (often conflicting) goals. Besides accuracy, a MORS can operate at the global level, where additional beyond-accuracy goals are met for the system as a whole, or at the individual level, meaning that the recommendations are tailored to the needs of each user. The state-of-the-art MORSs either operate at the global or individual level, without assuming the co-existence of the two perspectives. In this study, we show that when global and individual objectives co-exist, MORSs are not able to meet both types of goals. To overcome this issue, we present an approach that regulates the recommendation lists so as to guarantee both global and individual perspectives, while preserving its effectiveness. Specifically, as individual perspective, we tackle genre calibration and, as global perspective, provider fairness. We validate our approach on two real-world datasets, publicly released with this paper.
    
[^43]: LLMCheckup：通过可解释性工具对大型语言模型进行对话式检查

    LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools. (arXiv:2401.12576v1 [cs.CL])

    [http://arxiv.org/abs/2401.12576](http://arxiv.org/abs/2401.12576)

    LLMCheckup是一个可解释性工具，通过连接大型语言模型与可解释的AI工具，使用户能够与模型进行对话，生成自我解释并提供建议。

    

    提供以对话形式进行解释的可解释性工具已经证明在增强用户理解方面具有效果，因为一次性解释有时无法提供足够的信息给用户。然而，当前基于对话的解释方案需要许多依赖项，并且不容易转移到它们未设计的任务上。通过LLMCheckup，我们提供了一个易于访问的工具，允许用户与任何最新的大型语言模型（LLM）进行对话以了解其行为。我们使LLMs能够自行生成所有解释，并通过与一系列可解释性AI（XAI）工具（例如特征归因、基于嵌入的相似性以及反事实和基于理由生成的提示策略）连接，以完成意图识别而无需微调。LLM（自我）解释以交互对话的形式呈现，支持后续问题和生成建议。

    Interpretability tools that offer explanations in the form of a dialogue have demonstrated their efficacy in enhancing users' understanding, as one-off explanations may occasionally fall short in providing sufficient information to the user. Current solutions for dialogue-based explanations, however, require many dependencies and are not easily transferable to tasks they were not designed for. With LLMCheckup, we present an easily accessible tool that allows users to chat with any state-of-the-art large language model (LLM) about its behavior. We enable LLMs to generate all explanations by themselves and take care of intent recognition without fine-tuning, by connecting them with a broad spectrum of Explainable AI (XAI) tools, e.g. feature attributions, embedding-based similarity, and prompting strategies for counterfactual and rationale generation. LLM (self-)explanations are presented as an interactive dialogue that supports follow-up questions and generates suggestions. LLMCheckup p
    
[^44]: DiffMoog: 一个可微分的模块化合成器用于声音匹配

    DiffMoog: a Differentiable Modular Synthesizer for Sound Matching. (arXiv:2401.12570v1 [eess.AS])

    [http://arxiv.org/abs/2401.12570](http://arxiv.org/abs/2401.12570)

    DiffMoog是一个可微分的模块化合成器，可以集成到神经网络中，实现自动化的声音匹配。它具有调制能力、低频振荡器、滤波器和包络形状器等功能，并且用户可以创建自定义信号链。该研究还提出了一个基于信号链损失和编码器网络的端到端声音匹配框架，为使用可微分合成进行声音匹配的研究提供了见解和经验教训。

    

    本文介绍了DiffMoog - 一个具有商业乐器中常见模块的可微分模块化合成器。作为可微分的，它可以集成到神经网络中，实现自动化的声音匹配，以复制给定的音频输入。值得注意的是，DiffMoog具有调制能力（FM / AM）、低频振荡器（LFOs）、滤波器、包络形状器以及用户创建自定义信号链的能力。我们介绍了一个开源平台，该平台包括了DiffMoog和端到端的声音匹配框架。该框架利用了一种新颖的信号链损失和一个编码器网络，该网络根据用户定义的模块化架构来自动编程其输出，以预测DiffMoog的参数。此外，我们还提供了使用可微分合成进行声音匹配的见解和经验教训。通过将强大的声音功能与全面的平台结合，DiffMoog成为加快音频合成研究的首选资产。

    This paper presents DiffMoog - a differentiable modular synthesizer with a comprehensive set of modules typically found in commercial instruments. Being differentiable, it allows integration into neural networks, enabling automated sound matching, to replicate a given audio input. Notably, DiffMoog facilitates modulation capabilities (FM/AM), low-frequency oscillators (LFOs), filters, envelope shapers, and the ability for users to create custom signal chains. We introduce an open-source platform that comprises DiffMoog and an end-to-end sound matching framework. This framework utilizes a novel signal-chain loss and an encoder network that self-programs its outputs to predict DiffMoogs parameters based on the user-defined modular architecture. Moreover, we provide insights and lessons learned towards sound matching using differentiable synthesis. Combining robust sound capabilities with a holistic platform, DiffMoog stands as a premier asset for expediting research in audio synthesis an
    
[^45]: 平衡自博弈训练中角色的AI能力与后悔匹配+的方法

    Balancing the AI Strength of Roles in Self-Play Training with Regret Matching+. (arXiv:2401.12557v1 [cs.AI])

    [http://arxiv.org/abs/2401.12557](http://arxiv.org/abs/2401.12557)

    通过引入后悔匹配+，本论文提出了一种简单的方法来平衡自博弈训练中不同角色的AI能力。

    

    在为涵盖多个角色的游戏训练人工智能时，开发一个能够控制游戏内任意角色的通用模型是一个可行的选择。这种策略不仅可以在训练阶段节省计算资源和时间，而且可以减少部署时的资源需求。然而，训练这样一个通用模型经常遇到控制不同角色时能力不平衡的挑战。本文提出了一种基于后悔匹配+的简单方法，可以促进模型在控制不同角色时更平衡的性能。

    When training artificial intelligence for games encompassing multiple roles, the development of a generalized model capable of controlling any character within the game presents a viable option. This strategy not only conserves computational resources and time during the training phase but also reduces resource requirements during deployment. training such a generalized model often encounters challenges related to uneven capabilities when controlling different roles. A simple method is introduced based on Regret Matching+, which facilitates a more balanced performance of strength by the model when controlling various roles.
    
[^46]: 大型语言模型能否编写并行代码?

    Can Large Language Models Write Parallel Code?. (arXiv:2401.12554v1 [cs.DC])

    [http://arxiv.org/abs/2401.12554](http://arxiv.org/abs/2401.12554)

    本文研究了大型语言模型生成并行代码的能力。我们提出了一个基准测试集PCGBench，并使用新指标评估了几个最先进的语言模型在并行编程模型和计算问题类型上的性能。

    

    大型语言模型正变得越来越受软件开发者的欢迎。它们在多种情境下展示了对源代码的建模和生成能力，包括代码补全、摘要、翻译和查找等。然而，它们往往难以为更复杂的任务生成代码。在本文中，我们探讨了最先进的语言模型生成并行代码的能力。我们提出了一个名为PCGBench的基准测试集，其中包含420个任务，用于评估语言模型生成并行代码的能力，并对几个最先进的开源和闭源语言模型在这些任务上的性能进行评估。我们引入了一些用于比较并行代码生成性能的新指标，并使用这些指标来探究每个语言模型在不同的并行编程模型和计算问题类型上的表现。

    Large Language Models are becoming an increasingly popular tool for software development. Their ability to model and generate source code has been demonstrated in a variety of contexts, including code completion, summarization, translation, and lookup. However, they often struggle to generate code for more complex tasks. In this paper, we explore the ability of state-of-the-art language models to generate parallel code. We propose a benchmark, PCGBench, consisting of a set of 420 tasks for evaluating the ability of language models to generate parallel code, and we evaluate the performance of several state-of-the-art open- and closed-source language models on these tasks. We introduce novel metrics for comparing parallel code generation performance and use them to explore how well each LLM performs on various parallel programming models and computational problem types.
    
[^47]: UR4NNV: 神经网络验证，基于欠估计可达性的方法！

    UR4NNV: Neural Network Verification, Under-approximation Reachability Works!. (arXiv:2401.12550v1 [cs.AI])

    [http://arxiv.org/abs/2401.12550](http://arxiv.org/abs/2401.12550)

    本文提出了UR4NNV验证框架，利用欠估计可达性分析进行DNN验证。该框架对具有ReLU激活的DNN进行欠估计，并通过试错方法有效地证伪DNN属性。

    

    最近，深度神经网络（DNNs）的形式验证引起了广泛关注，基于过度估计的方法因其有效性和高效性而变得流行。然而，这些策略在解决涉及确切输出区域或引入的近似误差是否违反所讨论属性的“未知困境”方面面临挑战。为了解决这个问题，本文首次引入了UR4NNV验证框架，该框架利用欠估计可达性分析进行DNN验证。UR4NNV专注于具有修正线性单元（ReLU）激活的DNN，并采用基于二叉树分支的欠估计算法。在每个周期中，UR4NNV对可达集合的子多面体进行欠估计，并针对给定的属性验证该多面体。通过试错方法，UR4NNV在达到验证周期边界和失败时提供了有效地证伪DNN属性的信心水平。

    Recently, formal verification of deep neural networks (DNNs) has garnered considerable attention, and over-approximation based methods have become popular due to their effectiveness and efficiency. However, these strategies face challenges in addressing the "unknown dilemma" concerning whether the exact output region or the introduced approximation error violates the property in question. To address this, this paper introduces the UR4NNV verification framework, which utilizes under-approximation reachability analysis for DNN verification for the first time. UR4NNV focuses on DNNs with Rectified Linear Unit (ReLU) activations and employs a binary tree branch-based under-approximation algorithm. In each epoch, UR4NNV under-approximates a sub-polytope of the reachable set and verifies this polytope against the given property. Through a trial-and-error approach, UR4NNV effectively falsifies DNN properties while providing confidence levels when reaching verification epoch bounds and failing
    
[^48]: 有效利用背景知识的约束k中心聚类

    Efficient Constrained $k$-Center Clustering with Background Knowledge. (arXiv:2401.12533v1 [cs.LG])

    [http://arxiv.org/abs/2401.12533](http://arxiv.org/abs/2401.12533)

    本论文提出了一种在k中心聚类上利用背景知识的约束聚类算法，通过采用一系列技术，得到了效率高且具有最佳近似比例2的算法。

    

    中心为基础的聚类在理论和实践中都引起了重要的研究兴趣。在许多实际应用中，输入数据通常包含可以用于改进聚类结果的背景知识。在这项工作中，我们基于广泛采用的k中心聚类，并将其输入的背景知识建模为必连（ML）和不连（CL）约束集。然而，大多数包括k中心在内的聚类问题本质上都是NP困难的，而更复杂的受约束变体被认为受到更严重的近似和计算障碍的限制，极大地限制了它们的适用性。通过采用一系列技术，包括反支配集，线性规划（LP）整数平面和LP对偶性，我们得到了第一个具有最佳近似比例2的约束k中心的高效近似算法。我们还构建了竞争基准算法，并对我们的近似算法进行了实证评估。

    Center-based clustering has attracted significant research interest from both theory and practice. In many practical applications, input data often contain background knowledge that can be used to improve clustering results. In this work, we build on widely adopted $k$-center clustering and model its input background knowledge as must-link (ML) and cannot-link (CL) constraint sets. However, most clustering problems including $k$-center are inherently $\mathcal{NP}$-hard, while the more complex constrained variants are known to suffer severer approximation and computation barriers that significantly limit their applicability. By employing a suite of techniques including reverse dominating sets, linear programming (LP) integral polyhedron, and LP duality, we arrive at the first efficient approximation algorithm for constrained $k$-center with the best possible ratio of 2. We also construct competitive baseline algorithms and empirically evaluate our approximation algorithm against them o
    
[^49]: DAFA：距离感知公平对抗训练

    DAFA: Distance-Aware Fair Adversarial Training. (arXiv:2401.12532v1 [cs.LG])

    [http://arxiv.org/abs/2401.12532](http://arxiv.org/abs/2401.12532)

    DAFA通过考虑类别之间的相似性，引入了不同的损失权重和对抗边界，并调整它们以提高在对抗训练中的鲁棒公平性。

    

    标准训练中类别间的准确性差异在对抗训练中被放大，这被称为鲁棒公平问题。现有的方法为增强鲁棒公平性而牺牲模型对易类别的性能，以改善对难类别的性能。然而，我们观察到在对抗攻击下，模型对最差类别样本的预测大多偏向于与最差类别相似的类别，而不是易类别。通过理论和实证分析，我们证明了随着类别之间距离的减小，鲁棒公平性会恶化。受到这些观察的启发，我们引入了距离感知公平对抗训练（DAFA）方法，通过考虑类别之间的相似性来解决鲁棒公平性问题。具体而言，我们的方法为每个类别分配不同的损失权重和对抗边界，并调整它们以促进一种权衡关系。

    The disparity in accuracy between classes in standard training is amplified during adversarial training, a phenomenon termed the robust fairness problem. Existing methodologies aimed to enhance robust fairness by sacrificing the model's performance on easier classes in order to improve its performance on harder ones. However, we observe that under adversarial attacks, the majority of the model's predictions for samples from the worst class are biased towards classes similar to the worst class, rather than towards the easy classes. Through theoretical and empirical analysis, we demonstrate that robust fairness deteriorates as the distance between classes decreases. Motivated by these insights, we introduce the Distance-Aware Fair Adversarial training (DAFA) methodology, which addresses robust fairness by taking into account the similarities between classes. Specifically, our method assigns distinct loss weights and adversarial margins to each class and adjusts them to encourage a trade-
    
[^50]: BiTA: 大语言模型中无损加速的双向调整

    BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models. (arXiv:2401.12522v1 [cs.CL])

    [http://arxiv.org/abs/2401.12522](http://arxiv.org/abs/2401.12522)

    BiTA是一种用于大语言模型的创新方法，通过双向调整实现了无损加速。它采用简化的半自回归生成和草稿验证，通过高效的基于树的解码同时进行候选生成和验证，提高了推理效率。这种方法不需要额外的辅助模型或显著的额外内存开销。

    

    大型语言模型（LLMs）通常在推理过程中使用自回归生成，导致高内存带宽需求和延迟延长。为了减轻这种效率低下的问题，我们提出了一种创新方法——双向调整以实现无损加速（BiTA），通过简化的半自回归生成和草稿验证来加速LLMs。受启发于提示调整的概念，我们使用一种参数高效的设计，称为双向调整，来增强LLMs在半自回归生成方面的能力。采用高效的基于树的解码，模型可以同时进行草稿候选生成和验证，确保输出结果与它们的自回归对应物在贪婪抽样下完全相同。BiTA作为一个轻量级的插件模块，可以无缝增强现有LLMs的推理效率，而无需额外的辅助模型或承担显著的额外内存开销。通过应用提出的BiTA，LLaMA-2-70B-Chat实现了

    Large language models (LLMs) commonly employ autoregressive generation during inference, leading to high memory bandwidth demand and consequently extended latency. To mitigate this inefficiency, we present Bi-directional Tuning for lossless Acceleration (BiTA), an innovative method expediting LLMs via streamlined semi-autoregressive generation and draft verification. Inspired by the concept of prompt tuning, we enhance LLMs with a parameter-efficient design called bi-directional tuning for the capability in semi-autoregressive generation. Employing efficient tree-based decoding, the models perform draft candidate generation and verification in parallel, ensuring outputs identical to their autoregressive counterparts under greedy sampling. BiTA serves as a lightweight plug-in module, seamlessly boosting the inference efficiency of existing LLMs without requiring additional assistance models or incurring significant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat achieve
    
[^51]: 使用YOLOv8、DeiT和SimCLR在希腊纸草这检测和识别字符

    Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR. (arXiv:2401.12513v1 [cs.CV])

    [http://arxiv.org/abs/2401.12513](http://arxiv.org/abs/2401.12513)

    该论文使用YOLOv8、DeiT和SimCLR在希腊纸草中进行字符检测和识别竞赛，在识别挑战中获得了42.2%的mAP，并在检测挑战中以51.4%的平均精度获得了亚军。

    

    从纸草手稿的图像中分离和识别单个字符的能力为数字分析提供了丰富的机会。因此，“ICDAR 2023年希腊纸草上字符检测和识别竞赛”作为第17届国际文件分析和识别会议的一部分举行。本文讨论了我们在比赛中的提交。我们使用了一组YOLOv8模型来检测和分类单个字符，并采用了两种不同的方法来完善字符预测，包括基于变压器的DeiT方法和使用SimCLR自监督学习方法在大量无标签数据上训练的ResNet-50模型。我们的提交在识别挑战中获得了42.2%的mAP，并在检测挑战中以51.4%的平均精度获得了亚军。在更宽松的iou阈值为0.5的情况下，我们实现了最高的平均精度和平均.

    The capacity to isolate and recognize individual characters from facsimile images of papyrus manuscripts yields rich opportunities for digital analysis. For this reason the `ICDAR 2023 Competition on Detection and Recognition of Greek Letters on Papyri' was held as part of the 17th International Conference on Document Analysis and Recognition. This paper discusses our submission to the competition. We used an ensemble of YOLOv8 models to detect and classify individual characters and employed two different approaches for refining the character predictions, including a transformer based DeiT approach and a ResNet-50 model trained on a large corpus of unlabelled data using SimCLR, a self-supervised learning method. Our submission won the recognition challenge with a mAP of 42.2%, and was runner-up in the detection challenge with a mean average precision (mAP) of 51.4%. At the more relaxed intersection over union threshold of 0.5, we achieved the highest mean average precision and mean ave
    
[^52]: 构建最小和可重用的因果状态抽象用于强化学习

    Building Minimal and Reusable Causal State Abstractions for Reinforcement Learning. (arXiv:2401.12497v1 [cs.AI])

    [http://arxiv.org/abs/2401.12497](http://arxiv.org/abs/2401.12497)

    本文介绍了一种称为Causal Bisimulation Modeling (CBM)的方法，该方法通过学习动态和奖励函数中的因果关系来构建最小和可重用的任务特定抽象。实证验证表明，CBM学习到的隐式动态模型比显式模型更准确地识别出底层的因果关系和状态抽象。

    

    强化学习算法的两个期望是能够从相对较少的经验中学习，并学习适用于一系列问题规范的策略。在因素化状态空间中，实现这两个目标的一种方法是学习状态抽象，只保留学习任务所需的变量。本文介绍了一种称为Causal Bisimulation Modeling (CBM)的方法，该方法学习每个任务的动态和奖励函数中的因果关系，以获得一个最小、任务特定的抽象。CBM利用和改进了隐式建模技术，训练了一个高保真度的因果动态模型，可以在同一环境中为所有任务重复使用。在操作环境和Deepmind Control Suite上的实证验证表明，CBM学习到的隐式动态模型比显式模型更准确地识别出底层的因果关系和状态抽象。

    Two desiderata of reinforcement learning (RL) algorithms are the ability to learn from relatively little experience and the ability to learn policies that generalize to a range of problem specifications. In factored state spaces, one approach towards achieving both goals is to learn state abstractions, which only keep the necessary variables for learning the tasks at hand. This paper introduces Causal Bisimulation Modeling (CBM), a method that learns the causal relationships in the dynamics and reward functions for each task to derive a minimal, task-specific abstraction. CBM leverages and improves implicit modeling to train a high-fidelity causal dynamics model that can be reused for all tasks in the same environment. Empirical validation on manipulation environments and Deepmind Control Suite reveals that CBM's learned implicit dynamics models identify the underlying causal relationships and state abstractions more accurately than explicit ones. Furthermore, the derived state abstrac
    
[^53]: 比较以人为中心的语言建模：模拟群体、个体特点还是两者兼顾？

    Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?. (arXiv:2401.12492v1 [cs.CL])

    [http://arxiv.org/abs/2401.12492](http://arxiv.org/abs/2401.12492)

    本研究比较了以群体属性、个体用户和组合方法来模拟人的上下文。合并群体和个体特征显著提高了用户级回归任务的性能，而模拟个体用户则显著提高了单个文档级分类任务的性能。

    

    自然语言处理在将人的上下文纳入其模型中取得了进展，但使用群体属性（如45岁以上的人群）还是模拟个体人物更有效的问题尚未确定。群体属性在技术上更容易实现，但是过于粗糙：并非所有45岁以上的人都以相同的方式书写。相反，模拟个体人物能够捕捉每个人身份的复杂性，允许更个性化的表示，但我们可能需要模拟无限数量的用户并且需要可能无法获取的数据。我们比较了通过群体属性、个体用户和组合方法来模拟人的上下文。将群体和个体特征结合起来，显著提高了基于用户文档的用户级回归任务（如年龄估计或个性评估）的性能。模拟个体用户显著提高了单个文档级分类任务（如立场和主题检测）的性能。

    Natural language processing has made progress in incorporating human context into its models, but whether it is more effective to use group-wise attributes (e.g., over-45-year-olds) or model individuals remains open. Group attributes are technically easier but coarse: not all 45-year-olds write the same way. In contrast, modeling individuals captures the complexity of each person's identity. It allows for a more personalized representation, but we may have to model an infinite number of users and require data that may be impossible to get. We compare modeling human context via group attributes, individual users, and combined approaches. Combining group and individual features significantly benefits user-level regression tasks like age estimation or personality assessment from a user's documents. Modeling individual users significantly improves the performance of single document-level classification tasks like stance and topic detection. We also find that individual-user modeling does w
    
[^54]: 评估和理解大型语言模型中的创造力

    Assessing and Understanding Creativity in Large Language Models. (arXiv:2401.12491v1 [cs.CL])

    [http://arxiv.org/abs/2401.12491](http://arxiv.org/abs/2401.12491)

    本文旨在建立一个评估大型语言模型（LLM）创造力水平的高效框架，并提出了评估方法和一个包含700个问题的全面数据集。研究发现创造力水平受到任务差异和LLM模型参数的影响。

    

    在自然语言处理领域，大型语言模型（LLM）的快速发展引起了越来越多的关注。LLMs在各种任务中展现出了高水平的创造力，但评估这种创造力的方法尚不完善。评估LLM的创造力需要考虑与人类的差异，需要进行多维度的测量，同时平衡准确性和效率。本文旨在建立一个评估LLM创造力水平的高效框架。通过改进的托兰斯创造性思维测试的改编，本研究评估了各种LLM在7个任务中的创造性表现，强调了流畅度、灵活性、独创性和丰富性等4个标准。在这个背景下，我们开发了一个包含700个问题的全面数据集，用于测试和基于LLM的评估方法。此外，本研究还对LLM对各种提示和角色扮演情境的反应进行了新颖的分析。我们发现创造力的水平取决于任务的不同，同时也受到LLM的模型和参数的影响。

    In the field of natural language processing, the rapid development of large language model (LLM) has attracted more and more attention. LLMs have shown a high level of creativity in various tasks, but the methods for assessing such creativity are inadequate. The assessment of LLM creativity needs to consider differences from humans, requiring multi-dimensional measurement while balancing accuracy and efficiency. This paper aims to establish an efficient framework for assessing the level of creativity in LLMs. By adapting the modified Torrance Tests of Creative Thinking, the research evaluates the creative performance of various LLMs across 7 tasks, emphasizing 4 criteria including Fluency, Flexibility, Originality, and Elaboration. In this context, we develop a comprehensive dataset of 700 questions for testing and an LLM-based evaluation method. In addition, this study presents a novel analysis of LLMs' responses to diverse prompts and role-play situations. We found that the creativit
    
[^55]: 基于有限差分残差约束损失的波动方程无监督学习方法

    Unsupervised Learning Method for the Wave Equation Based on Finite Difference Residual Constraints Loss. (arXiv:2401.12489v1 [cs.LG])

    [http://arxiv.org/abs/2401.12489](http://arxiv.org/abs/2401.12489)

    本文提出了一种新型的无监督学习方法，通过基于有限差分残差约束的波动方程，解决了现有深度学习方法中存在的问题。该方法具有高效、低成本和强泛化能力，并通过实验证明其优于传统的物理感知神经网络。

    

    波动方程是一种重要的物理偏微分方程，在近年来，深度学习已经展示出在加速或替代传统数值方法中解决波动方程方面的潜力。然而，现有的深度学习方法存在着高数据获取成本、低训练效率以及对边界条件的不充分泛化能力。为了解决这些问题，本文提出了一种基于有限差分残差约束的波动方程无监督学习方法。我们构建了一种基于结构化网格和有限差分方法的新型有限差分残差约束，以及一种无监督训练策略，使卷积神经网络可以在无数据的情况下进行训练并预测波的前向传播过程。实验结果表明，有限差分残差约束相对于基于物理信息约束的物理感知神经网络（PINNs）具有更好的适应性和更低的拟合成本。

    The wave equation is an important physical partial differential equation, and in recent years, deep learning has shown promise in accelerating or replacing traditional numerical methods for solving it. However, existing deep learning methods suffer from high data acquisition costs, low training efficiency, and insufficient generalization capability for boundary conditions. To address these issues, this paper proposes an unsupervised learning method for the wave equation based on finite difference residual constraints. We construct a novel finite difference residual constraint based on structured grids and finite difference methods, as well as an unsupervised training strategy, enabling convolutional neural networks to train without data and predict the forward propagation process of waves. Experimental results show that finite difference residual constraints have advantages over physics-informed neural networks (PINNs) type physical information constraints, such as easier fitting, lowe
    
[^56]: 绝热量子支持向量机

    Adiabatic Quantum Support Vector Machines. (arXiv:2401.12485v1 [cs.LG])

    [http://arxiv.org/abs/2401.12485](http://arxiv.org/abs/2401.12485)

    本文描述了一种用于训练支持向量机的绝热量子方法，与经典方法相比，我们的方法在时间复杂度上取得了一个数量级的改进，并且在五个基准数据集上取得了与经典方法相当的测试准确率。我们还展示了我们的方法具有良好的可扩展性。

    

    绝热量子计算机可以解决困难的优化问题（例如二次无约束二进制优化问题），并且它们似乎非常适合用于训练机器学习模型。在本文中，我们描述了一种用于训练支持向量机的绝热量子方法。我们展示了我们的量子方法的时间复杂度比经典方法好一个数量级。接下来，我们在五个基准数据集（Iris，Wisconsin乳腺癌（WBC），Wine，Digits和Lambeq）上将我们的量子方法的测试准确率与使用Python中的Scikit-learn库的经典方法进行了比较。我们展示了我们的量子方法获得了与经典方法相当的准确度。最后，我们进行了一项可扩展性研究，其中我们计算了量子方法和经典方法在训练数据集中特征数量和数据点数量增加时的总训练时间。我们的可扩展性结果显示，量子方法具有良好的可扩展性。

    Adiabatic quantum computers can solve difficult optimization problems (e.g., the quadratic unconstrained binary optimization problem), and they seem well suited to train machine learning models. In this paper, we describe an adiabatic quantum approach for training support vector machines. We show that the time complexity of our quantum approach is an order of magnitude better than the classical approach. Next, we compare the test accuracy of our quantum approach against a classical approach that uses the Scikit-learn library in Python across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC), Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracies on par with the classical approach. Finally, we perform a scalability study in which we compute the total training times of the quantum approach and the classical approach with increasing number of features and number of data points in the training dataset. Our scalability results show that the quantum approa
    
[^57]: 小批量子模最大化算法

    Mini-batch Submodular Maximization. (arXiv:2401.12478v1 [cs.LG])

    [http://arxiv.org/abs/2401.12478](http://arxiv.org/abs/2401.12478)

    我们提出了第一个小批量算法，用于在约束条件下最大化非负单调可分解的子模函数F，该算法在实践中比基于稀疏化方法的做法更好。

    

    我们提出了第一个用于在一组约束条件下最大化一个非负单调可分解的子模函数F的小批量算法，其中F等于$f^i$的和。我们在理论和实践上都超越了基于稀疏化方法的做法。实验证明，我们的算法生成的解比基于稀疏化方法生成的解要好得多。

    We present the first mini-batch algorithm for maximizing a non-negative monotone decomposable submodular function, $F=\sum_{i=1}^N f^i$, under a set of constraints. We improve over the sparsifier based approach both in theory and in practice. We experimentally observe that our algorithm generates solutions that are far superior to those generated by the sparsifier based approach.
    
[^58]: 基于图着色的强化学习：理解非标签不变表示的能力和局限性

    Reinforcement Learning for Graph Coloring: Understanding the Power and Limits of Non-Label Invariant Representations. (arXiv:2401.12470v1 [cs.LG])

    [http://arxiv.org/abs/2401.12470](http://arxiv.org/abs/2401.12470)

    本论文将寄存器分配问题转化为图着色问题，并展示了Proximal Policy Optimization模型通过学习解决图着色问题。同时，我们还发现图的标记对模型性能至关重要，并提出了机器学习模型需要具有标签重新排序不变性的图表示。

    

    寄存器分配是现代编译器中最重要的问题之一。在拥有几乎无限数量的用户变量和少量CPU寄存器的情况下，将变量分配给寄存器以避免冲突是一个复杂的任务。本研究将寄存器分配问题转化为图着色问题，并使用PyTorch和OpenAI Gymnasium Environments等技术展示了Proximal Policy Optimization模型能够学习解决图着色问题。同时，我们还展示了图的标记对模型性能的重要性，通过获取图的矩阵表示并对其进行排列来进行测试。然后测试模型在每个排列上的效果，并展示当给出同一图的重新标记时其效果不佳。我们的主要贡献在于表明了机器学习模型需要具有标签重新排序不变性的图表示以实现一致的性能。

    Register allocation is one of the most important problems for modern compilers. With a practically unlimited number of user variables and a small number of CPU registers, assigning variables to registers without conflicts is a complex task. This work demonstrates the use of casting the register allocation problem as a graph coloring problem. Using technologies such as PyTorch and OpenAI Gymnasium Environments we will show that a Proximal Policy Optimization model can learn to solve the graph coloring problem. We will also show that the labeling of a graph is critical to the performance of the model by taking the matrix representation of a graph and permuting it. We then test the model's effectiveness on each of these permutations and show that it is not effective when given a relabeling of the same graph. Our main contribution lies in showing the need for label reordering invariant representations of graphs for machine learning models to achieve consistent performance.
    
[^59]: 用于甲骨文字符演变的开放数据集：EVOBC

    An open dataset for the evolution of oracle bone characters: EVOBC. (arXiv:2401.12467v1 [cs.AI])

    [http://arxiv.org/abs/2401.12467](http://arxiv.org/abs/2401.12467)

    本研究收集了古代字符数据集，揭示了甲骨文字符在六个历史阶段的演变过程，为解读甲骨文铭文提供了有价值的资源。

    

    最早的中文字符源自甲骨文铭文，与其他东亚语言密切相关。这些铭文对人类学和考古学具有巨大价值。然而，解读甲骨文仍然是一个巨大的挑战，迄今为止只有约1600个4500多个现存字符得到诠释。需要进一步的学术研究，全面了解这种古代书写系统。人工智能技术在解读甲骨文字符方面具有潜力，特别是在字符演变方面。然而，挑战之一是缺乏映射这些字符演变的数据集。在本研究中，我们系统地收集了古代字符，涵盖了甲骨文（公元前15世纪）、金文（公元前13世纪至公元221年）、篆书（公元前11至8世纪）、秦简（公元前221至206年）、小篆（公元前206至8世纪）、楷书（公元2至5世纪）这六个历史阶段的文字。

    The earliest extant Chinese characters originate from oracle bone inscriptions, which are closely related to other East Asian languages. These inscriptions hold immense value for anthropology and archaeology. However, deciphering oracle bone script remains a formidable challenge, with only approximately 1,600 of the over 4,500 extant characters elucidated to date. Further scholarly investigation is required to comprehensively understand this ancient writing system. Artificial Intelligence technology is a promising avenue for deciphering oracle bone characters, particularly concerning their evolution. However, one of the challenges is the lack of datasets mapping the evolution of these characters over time. In this study, we systematically collected ancient characters from authoritative texts and websites spanning six historical stages: Oracle Bone Characters - OBC (15th century B.C.), Bronze Inscriptions - BI (13th to 221 B.C.), Seal Script - SS (11th to 8th centuries B.C.), Spring and
    
[^60]: 朝着具有社会和道德意识的强化学习智能体：使用LLM进行奖励设计

    Towards Socially and Morally Aware RL agent: Reward Design With LLM. (arXiv:2401.12459v1 [cs.AI])

    [http://arxiv.org/abs/2401.12459](http://arxiv.org/abs/2401.12459)

    本文研究了利用大型语言模型的理解能力，以遵循社会和道德规范，在强化学习中进行安全探索，并将语言模型的结果作为直接奖励信号。

    

    在设计和部署强化学习（RL）智能体时，奖励函数激励智能体实现一个目标。目标的不正确或不完整的规范可能导致与人类价值观不一致的行为，不遵守模糊和依赖上下文的社会和道德规范，并导致负面副作用和不安全的探索等不希望的结果。先前的工作通过手动定义奖励函数来避免负面副作用，使用人类监督进行安全探索，或使用基础模型作为规划工具。本研究研究了利用大型语言模型（LLM）对安全探索增强强化学习方法中的道德和社会规范的理解能力。本研究通过与人类反馈评估语言模型的结果，并展示语言模型作为直接奖励信号的能力。

    When we design and deploy an Reinforcement Learning (RL) agent, reward functions motivates agents to achieve an objective. An incorrect or incomplete specification of the objective can result in behavior that does not align with human values - failing to adhere with social and moral norms that are ambiguous and context dependent, and cause undesired outcomes such as negative side effects and exploration that is unsafe. Previous work have manually defined reward functions to avoid negative side effects, use human oversight for safe exploration, or use foundation models as planning tools. This work studies the ability of leveraging Large Language Models (LLM)' understanding of morality and social norms on safe exploration augmented RL methods. This work evaluates language model's result against human feedbacks and demonstrates language model's capability as direct reward signals.
    
[^61]: 基于NeRF的3D场景编辑技术的探索与改进

    Exploration and Improvement of Nerf-based 3D Scene Editing Techniques. (arXiv:2401.12456v1 [cs.CV])

    [http://arxiv.org/abs/2401.12456](http://arxiv.org/abs/2401.12456)

    这篇论文探索了基于NeRF的3D场景编辑技术，通过结合其他模型进一步扩展了NeRF的编辑能力，实现了实时编辑反馈、多模态编辑、4D合成性能等功能。

    

    NeRF的高质量场景合成能力在提出后的几年中迅速被学者们接受，并在3D场景表示和合成方面取得了重大进展。然而，高计算成本限制了场景直观高效的编辑，使得NeRF在场景编辑领域面临着诸多挑战。本文回顾了近年来学者们在NeRF在场景或物体编辑领域的初步探索，主要包括在新合成场景中改变场景或物体的形状和纹理；通过将GaN和Transformer等残差模型与NeRF相结合，进一步扩展了NeRF场景编辑的泛化能力，包括实时新视角编辑反馈、文本合成的多模态编辑、4D合成性能以及在光影编辑方面的深入探索，初步实现了间接触摸编辑和细节表示的优化。

    NeRF's high-quality scene synthesis capability was quickly accepted by scholars in the years after it was proposed, and significant progress has been made in 3D scene representation and synthesis. However, the high computational cost limits intuitive and efficient editing of scenes, making NeRF's development in the scene editing field facing many challenges. This paper reviews the preliminary explorations of scholars on NeRF in the scene or object editing field in recent years, mainly changing the shape and texture of scenes or objects in new synthesized scenes; through the combination of residual models such as GaN and Transformer with NeRF, the generalization ability of NeRF scene editing has been further expanded, including realizing real-time new perspective editing feedback, multimodal editing of text synthesized 3D scenes, 4D synthesis performance, and in-depth exploration in light and shadow editing, initially achieving optimization of indirect touch editing and detail represent
    
[^62]: 基于集中训练和分散执行的多Agent深度强化学习在交通基础设施管理中的应用

    Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management. (arXiv:2401.12455v1 [cs.MA])

    [http://arxiv.org/abs/2401.12455](http://arxiv.org/abs/2401.12455)

    这项研究提出了一种基于集中训练和分散执行的多Agent深度强化学习框架，用于管理交通基础设施系统的整个生命周期，在处理高维度空间中的不确定性和约束条件时能够降低长期风险和成本。

    

    我们提出了一种多Agent深度强化学习框架，用于在交通基础设施的整个生命周期内进行管理。这种工程系统的生命周期管理是一个需要大量计算的任务，需要适当的顺序检查和维护决策，能够在处理不同的不确定性和约束条件时降低长期风险和成本，这些不确定性和约束条件存在于高维空间中。到目前为止，静态的基于年龄或条件的维护方法和基于风险或定期检查计划主要解决了这类优化问题。然而，在这些方法下，优化性、可扩展性和不确定性限制经常显现出来。本工作中的优化问题以约束的部分可观察马尔可夫决策过程(POMDPs)框架为基础，为具有观察不确定性、风险考虑和随机顺序决策的问题提供了综合的数学基础。

    We present a multi-agent Deep Reinforcement Learning (DRL) framework for managing large transportation infrastructure systems over their life-cycle. Life-cycle management of such engineering systems is a computationally intensive task, requiring appropriate sequential inspection and maintenance decisions able to reduce long-term risks and costs, while dealing with different uncertainties and constraints that lie in high-dimensional spaces. To date, static age- or condition-based maintenance methods and risk-based or periodic inspection plans have mostly addressed this class of optimization problems. However, optimality, scalability, and uncertainty limitations are often manifested under such approaches. The optimization problem in this work is cast in the framework of constrained Partially Observable Markov Decision Processes (POMDPs), which provides a comprehensive mathematical basis for stochastic sequential decision settings with observation uncertainties, risk considerations, and l
    
[^63]: 提高神经辐射场新视图合成质量的方法和策略

    Methods and strategies for improving the novel view synthesis quality of neural radiation field. (arXiv:2401.12451v1 [cs.CV])

    [http://arxiv.org/abs/2401.12451](http://arxiv.org/abs/2401.12451)

    这项研究总结了神经辐射场技术在提高图像渲染质量方面的各种方法和策略，为研究人员提供了当前状态和未来演化方向的理解，从而推动NeRF技术在相关领域的应用。

    

    神经辐射场（NeRF）技术可以从2D图像中学习场景的3D隐式模型，并合成逼真的新视图图像。该技术受到工业界的广泛关注，并具有良好的应用前景。为了解决NeRF图像渲染质量需要提高的问题，许多研究人员在过去三年中提出了各种方法来改善渲染质量。本研究对最新的相关论文进行了分类和审查，分析了质量改进背后的技术原理，并讨论了质量改进方法的未来演化方向。这项研究可以帮助研究人员快速了解该领域技术的当前状态和演化背景，有助于激发开发更高效算法的发展，并推动NeRF技术在相关领域的应用。

    Neural Radiation Field (NeRF) technology can learn a 3D implicit model of a scene from 2D images and synthesize realistic novel view images. This technology has received widespread attention from the industry and has good application prospects. In response to the problem that the rendering quality of NeRF images needs to be improved, many researchers have proposed various methods to improve the rendering quality in the past three years. The latest relevant papers are classified and reviewed, the technical principles behind quality improvement are analyzed, and the future evolution direction of quality improvement methods is discussed. This study can help researchers quickly understand the current state and evolutionary context of technology in this field, which is helpful in inspiring the development of more efficient algorithms and promoting the application of NeRF technology in related fields.
    
[^64]: 使用物理信息神经网络对细胞外间隙中的分子传输进行定量分析

    Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network. (arXiv:2401.12435v1 [cs.AI])

    [http://arxiv.org/abs/2401.12435](http://arxiv.org/abs/2401.12435)

    本文提出了一种使用物理信息神经网络对细胞外间隙中分子传输进行定量分析的新方法，解决了对分子传输形式不清楚的挑战，并实现了自动计算扩散系数和分子速度的优化功能。

    

    大脑的细胞外间隙 (ECS)是位于细胞之间或细胞与血管之间的不规则、极其迂回的纳米级空间，对神经细胞的生存至关重要。它在记忆、情绪和感觉等高级脑功能中起着关键作用。然而，ECS内分子传输的具体形式仍然不清楚。为了解决这个问题，本文提出了一种新的方法，通过使用物理信息神经网络 (PINN) 解决从对流-扩散方程 (ADE) 导出的一个逆问题，定量分析ECS内的分子传输。PINN为ADE提供了一个简化的解决方案，而无需复杂的数学公式或网格设置。此外，PINN的优化功能可自动计算决定长期分子传输的扩散系数和由对流驱动的分子速度。因此，所提出的方法允许进行定量分析。

    The brain extracellular space (ECS), an irregular, extremely tortuous nanoscale space located between cells or between cells and blood vessels, is crucial for nerve cell survival. It plays a pivotal role in high-level brain functions such as memory, emotion, and sensation. However, the specific form of molecular transport within the ECS remain elusive. To address this challenge, this paper proposes a novel approach to quantitatively analyze the molecular transport within the ECS by solving an inverse problem derived from the advection-diffusion equation (ADE) using a physics-informed neural network (PINN). PINN provides a streamlined solution to the ADE without the need for intricate mathematical formulations or grid settings. Additionally, the optimization of PINN facilitates the automatic computation of the diffusion coefficient governing long-term molecule transport and the velocity of molecules driven by advection. Consequently, the proposed method allows for the quantitative analy
    
[^65]: AdaEmbed: 在嵌入空间中进行半监督领域自适应

    AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space. (arXiv:2401.12421v1 [cs.CV])

    [http://arxiv.org/abs/2401.12421](http://arxiv.org/abs/2401.12421)

    AdaEmbed是一种在嵌入空间中进行半监督领域自适应的新方法，通过学习共享的嵌入空间以及生成准确且统一的伪标签，该方法显著提高了性能，并在多个基准数据集上超过了传统方法。

    

    半监督领域自适应（SSDA）在计算机视觉中是一个关键的难题，特别是在现实世界的环境中标记数据常常稀缺的情况下。这种稀缺常导致在新领域应用基础模型时效果不佳。我们提出的AdaEmbed是半监督领域自适应的一种新方法，为这些挑战提供了一个有希望的解决方案。AdaEmbed利用无标签数据的潜力，通过学习共享的嵌入空间，促进从有标签源领域到无标签目标领域的知识转移。通过根据建立的嵌入空间生成准确且统一的伪标签，该模型克服了传统SSDA的局限，从而显著提高了性能。我们通过对DomainNet、Office-Home和VisDA-C等基准数据集进行了大量实验，验证了我们方法的有效性，AdaEmbed在所有基线上均取得了更好的性能，创造了领域中的新纪录。

    Semi-supervised domain adaptation (SSDA) presents a critical hurdle in computer vision, especially given the frequent scarcity of labeled data in real-world settings. This scarcity often causes foundation models, trained on extensive datasets, to underperform when applied to new domains. AdaEmbed, our newly proposed methodology for SSDA, offers a promising solution to these challenges. Leveraging the potential of unlabeled data, AdaEmbed facilitates the transfer of knowledge from a labeled source domain to an unlabeled target domain by learning a shared embedding space. By generating accurate and uniform pseudo-labels based on the established embedding space, the model overcomes the limitations of conventional SSDA, thus enhancing performance significantly. Our method's effectiveness is validated through extensive experiments on benchmark datasets such as DomainNet, Office-Home, and VisDA-C, where AdaEmbed consistently outperforms all the baselines, setting a new state of the art for S
    
[^66]: 通过线性探测校准提高上下文学习

    Enhancing In-context Learning via Linear Probe Calibration. (arXiv:2401.12406v1 [cs.CL])

    [http://arxiv.org/abs/2401.12406](http://arxiv.org/abs/2401.12406)

    本研究提出了一种名为线性探测校准（LinC）的技术，通过校准模型的输出概率，显著提高了上下文学习（ICL）在生成预训练变压器（GPT）模型上的测试性能。

    

    上下文学习（ICL）是一种新的自然语言处理范式，利用生成预训练变压器（GPT）等模型。这种方法使用包含上下文演示的提示来为新的查询输入生成相应的输出。然而，在实际情况下应用ICL无法随着样本数量的增加而扩展，并且对不同的提示模板和演示排列缺乏鲁棒性。本文首先展示了使用ICL的GPT模型基于基于香农熵的新度量而导致不可靠的预测。然后，我们提出了一种称为线性探测校准（LinC）的新技术，它可以校准模型的输出概率，从而得到可靠的预测和改进的性能，且仅需要极少量的额外样本（仅需五个已标记的数据样本）。LinC显著提高了GPT模型在各种基准数据集上的ICL测试性能，平均改善效果很大。

    In-context learning (ICL) is a new paradigm for natural language processing that utilizes Generative Pre-trained Transformer (GPT)-like models. This approach uses prompts that include in-context demonstrations to generate the corresponding output for a new query input. However, applying ICL in real cases does not scale with the number of samples, and lacks robustness to different prompt templates and demonstration permutations. In this paper, we first show that GPT-like models using ICL result in unreliable predictions based on a new metric based on Shannon entropy. Then, to solve this problem, we propose a new technique called the Linear Probe Calibration (LinC), a method that calibrates the model's output probabilities, resulting in reliable predictions and improved performance, while requiring only minimal additional samples (as few as five labeled data samples). LinC significantly enhances the ICL test performance of GPT models on various benchmark datasets, with an average improve
    
[^67]: 基于学习的声明性隐私保护数据联邦管理框架

    A Learning-based Declarative Privacy-Preserving Framework for Federated Data Management. (arXiv:2401.12393v1 [cs.DB])

    [http://arxiv.org/abs/2401.12393](http://arxiv.org/abs/2401.12393)

    本论文提出了一个基于学习的声明性隐私保护框架，通过使用Differentially-Private Stochastic Gradient Descent（DP-SGD）算法训练的深度学习模型替代部分实际数据来回答查询，并允许用户指定要保护的私人信息。此框架还可以自动选择转换计划和超参数，并允许人工专家审核和调整隐私保护机制。

    

    在多个私有数据孤岛上进行联邦查询处理时，平衡隐私和准确性是一项具有挑战性的任务。在这项工作中，我们将演示一种自动化新兴隐私保护技术的端到端工作流，该技术使用使用差分隐私随机梯度下降（DP-SGD）算法训练的深度学习模型替换实际数据的部分来回答查询。我们提出的新颖声明性隐私保护工作流允许用户指定“要保护的私人信息”而不是“如何保护”。在底层，系统自动选择查询-模型转换计划以及超参数。同时，所提出的工作流还允许人工专家审核和调整选择的隐私保护机制，用于审计/合规和优化目的。

    It is challenging to balance the privacy and accuracy for federated query processing over multiple private data silos. In this work, we will demonstrate an end-to-end workflow for automating an emerging privacy-preserving technique that uses a deep learning model trained using the Differentially-Private Stochastic Gradient Descent (DP-SGD) algorithm to replace portions of actual data to answer a query. Our proposed novel declarative privacy-preserving workflow allows users to specify "what private information to protect" rather than "how to protect". Under the hood, the system automatically chooses query-model transformation plans as well as hyper-parameters. At the same time, the proposed workflow also allows human experts to review and tune the selected privacy-preserving mechanism for audit/compliance, and optimization purposes.
    
[^68]: 自动驾驶车辆路边感知的评估：来自现场测试的见解

    Evaluating Roadside Perception for Autonomous Vehicles: Insights from Field Testing. (arXiv:2401.12392v1 [cs.RO])

    [http://arxiv.org/abs/2401.12392](http://arxiv.org/abs/2401.12392)

    本文介绍了一种专门设计用于评估路边感知系统性能的综合评估方法，该方法通过现实世界的实地测试来确保实际适用性，并在控制测试环境中评估了各种现成的感知系统。

    

    路边感知系统在提高交通安全和促进自动驾驶车辆的合作驾驶方面变得越来越重要。尽管技术不断进步，但这个新兴领域仍存在一个主要挑战：缺乏标准化的评估方法和基准来评估这些系统。这种限制阻碍了有效评估和比较不同系统的性能，从而限制了这个重要领域的进展。本文介绍了一种专门设计用于评估路边感知系统性能的综合评估方法。我们的方法包括测量技术、指标选择和实验试验设计，所有这些都建立在现实世界的实地测试基础上，以确保我们方法的实际适用性。我们在控制测试环境Mcity中应用了我们的方法，评估了各种现成的感知系统。

    Roadside perception systems are increasingly crucial in enhancing traffic safety and facilitating cooperative driving for autonomous vehicles. Despite rapid technological advancements, a major challenge persists for this newly arising field: the absence of standardized evaluation methods and benchmarks for these systems. This limitation hampers the ability to effectively assess and compare the performance of different systems, thus constraining progress in this vital field. This paper introduces a comprehensive evaluation methodology specifically designed to assess the performance of roadside perception systems. Our methodology encompasses measurement techniques, metric selection, and experimental trial design, all grounded in real-world field testing to ensure the practical applicability of our approach.  We applied our methodology in Mcity\footnote{\url{https://mcity.umich.edu/}}, a controlled testing environment, to evaluate various off-the-shelf perception systems. This approach al
    
[^69]: 分析大型语言模型在文本转SQL合成中的有效性

    Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis. (arXiv:2401.12379v1 [cs.AI])

    [http://arxiv.org/abs/2401.12379](http://arxiv.org/abs/2401.12379)

    本论文研究了大型语言模型在文本转SQL合成中的有效性，通过对比两种方法，发现微调gpt-3.5-turbo-16k + gpt-4-turbo模型的执行准确率较高，达到82.1%。同时，对错误查询进行分类分析，找出错误的原因。

    

    本研究调查了使用大型语言模型（LLM）进行文本转SQL程序合成的各种方法，重点关注了产生的结果和洞察。使用流行的文本转SQL数据集spider，目标是输入自然语言问题和数据库模式，输出正确的SQL SELECT查询。最初的方法是对本地和开源模型进行微调，生成SELECT查询。在spider数据集上通过QLoRa微调WizardLM的WizardCoder-15B模型后，生成查询的执行准确率达到61%的高水平。通过第二种方法，使用微调的gpt-3.5-turbo-16k（Few-shot）+ gpt-4-turbo（Zero-shot错误修正），执行准确率达到82.1%的高水平。在所有错误的查询中，大部分可以分为七个不同的类别，说明了出错的原因：选择错误的列或列的顺序不正确，按错误的列进行分组，预测条件中的值错误，使用了不同的...

    This study investigates various approaches to using Large Language Models (LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights derived. Employing the popular Text-to-SQL dataset, spider, the goal was to input a natural language question along with the database schema and output the correct SQL SELECT query. The initial approach was to fine-tune a local and open-source model to generate the SELECT query. After QLoRa fine-tuning WizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy for generated queries rose to a high of 61%. With the second approach, using the fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error correction), the execution accuracy reached a high of 82.1%. Of all the incorrect queries, most can be categorized into a seven different categories of what went wrong: selecting the wrong columns or wrong order of columns, grouping by the wrong column, predicting the wrong values in conditionals, using differ
    
[^70]: 为视力障碍学生开发基于NLP的计算机化测试指南

    Development of an NLP-driven computer-based test guide for visually impaired students. (arXiv:2401.12375v1 [cs.CL])

    [http://arxiv.org/abs/2401.12375](http://arxiv.org/abs/2401.12375)

    本文介绍了一种为视力障碍学生开发的基于NLP的计算机化测试指南，利用语音技术和NLP技术实时提供支持和帮助，并将文本问题和选项转化为机器可读的格式。

    

    近年来，自然语言处理（NLP）技术的进步改变了无障碍和独占性测试领域，特别是对于视力障碍学生（VIS）。计算机化测试（CBT）在过去的几年中已经显示出了在电子化考试方面的重要性，使考试过程更加简便，提供更快更准确的结果，并为考生提供更大的灵活性和可访问性。然而，视力障碍学生无法访问印刷文件，因此本文提出了一种面向视力障碍学生的基于NLP的计算机化测试指南。该系统采用语音技术预先训练的方法，为视力障碍学生实时提供支持和帮助。系统利用NLP技术将基于文本的问题和相关选项转化为机器可读的格式。随后，语音技术预先训练的模型处理转化后的文本，实现对视力障碍学生的支持。

    In recent years, advancements in Natural Language Processing (NLP) techniques have revolutionized the field of accessibility and exclusivity of testing, particularly for visually impaired students (VIS). CBT has shown in years back its relevance in terms of administering exams electronically, making the test process easier, providing quicker and more accurate results, and offering greater flexibility and accessibility for candidates. Yet, its relevance was not felt by the visually impaired students as they cannot access printed documents. Hence, in this paper, we present an NLP-driven Computer-Based Test guide for visually impaired students. It employs a speech technology pre-trained methods to provide real-time assistance and support to visually impaired students. The system utilizes NLP technologies to convert the text-based questions and the associated options in a machine-readable format. Subsequently, the speech technology pre-trained model processes the converted text enabling th
    
[^71]: OCT-SelfNet:一种基于多模态数据的自监督框架，用于广义和鲁棒的视网膜疾病检测

    OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for Generalized and Robust Retinal Disease Detection. (arXiv:2401.12344v1 [cs.CV])

    [http://arxiv.org/abs/2401.12344](http://arxiv.org/abs/2401.12344)

    OCT-SelfNet是一种用于眼科疾病检测的自监督机器学习框架，通过结合多模态数据集和两阶段训练方法，实现了广义和鲁棒的检测结果。

    

    尽管AI的革命性影响和本地训练算法的发展，但在医学AI中从多模态数据实现广义学习仍然是一个重大挑战。这个差距限制了可扩展医学AI解决方案的实际部署。为了解决这个挑战，我们的研究提出了一种自监督的鲁棒机器学习框架OCT-SelfNet，用于使用光学相干断层扫描（OCT）图像检测眼科疾病。在这项工作中，综合了来自不同机构的各种数据集，实现了更全面的表征范围。我们的方法通过使用基于SwinV2骨架的自监督预训练和监督微调的双阶段训练方法，提供了一个适用于临床实际部署的解决方案。在三个数据集上进行了大量实验证明了不同编码器骨架、低数据设置、未见数据设置和数据增强的影响。

    Despite the revolutionary impact of AI and the development of locally trained algorithms, achieving widespread generalized learning from multi-modal data in medical AI remains a significant challenge. This gap hinders the practical deployment of scalable medical AI solutions. Addressing this challenge, our research contributes a self-supervised robust machine learning framework, OCT-SelfNet, for detecting eye diseases using optical coherence tomography (OCT) images. In this work, various data sets from various institutions are combined enabling a more comprehensive range of representation. Our method addresses the issue using a two-phase training approach that combines self-supervised pretraining and supervised fine-tuning with a mask autoencoder based on the SwinV2 backbone by providing a solution for real-world clinical deployment. Extensive experiments on three datasets with different encoder backbones, low data settings, unseen data settings, and the effect of augmentation show tha
    
[^72]: 基于对比学习和循环一致性的跨领域转导迁移学习用于目标标注

    Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation. (arXiv:2401.12340v1 [cs.CV])

    [http://arxiv.org/abs/2401.12340](http://arxiv.org/abs/2401.12340)

    本论文提出了一种基于对比学习和循环一致性的混合非配对域转换网络（H-CUT）来解决自动目标识别（ATR）中标记数据不足的问题。该方法在跨领域转导迁移学习中取得了显著低的FID分数，并通过注意力和熵来强调领域特定区域，以生成高质量的合成图像。

    

    自动目标识别（ATR）的注释是一项极具挑战性的任务，主要由于目标域中标记数据的缺乏。因此，通过利用源域图像的标记信息来构建最佳目标域分类器是至关重要的。先前在文献中提出了一种包含基于CycleGAN的非配对域转换网络的跨领域转导迁移学习（TTL）方法，用于有效的ATR标注。尽管该方法显示出了ATR的巨大潜力，但它严重受到注释性能较低、更高的Fr\'echet Inception Distance（FID）分数以及合成图像中存在的视觉伪影的困扰。为了解决这些问题，我们提出了一种基于对比学习和循环一致性的混合非配对域转换（H-CUT）网络，它实现了显著较低的FID分数。它结合了注意力和熵来强调领域特定的区域，噪声特征混合模块用于生成高质量的合成图像。

    Annotating automatic target recognition (ATR) is a highly challenging task, primarily due to the unavailability of labeled data in the target domain. Hence, it is essential to construct an optimal target domain classifier by utilizing the labeled information of the source domain images. The transductive transfer learning (TTL) method that incorporates a CycleGAN-based unpaired domain translation network has been previously proposed in the literature for effective ATR annotation. Although this method demonstrates great potential for ATR, it severely suffers from lower annotation performance, higher Fr\'echet Inception Distance (FID) score, and the presence of visual artifacts in the synthetic images. To address these issues, we propose a hybrid contrastive learning base unpaired domain translation (H-CUT) network that achieves a significantly lower FID score. It incorporates both attention and entropy to emphasize the domain-specific region, a noisy feature mixup module to generate high
    
[^73]: 迈向交通基础设施的优先使用：城市中心车辆特定动态进入限制的案例研究

    Towards a prioritised use of transportation infrastructures: the case of vehicle-specific dynamic access restrictions to city centres. (arXiv:2401.12329v1 [physics.soc-ph])

    [http://arxiv.org/abs/2401.12329](http://arxiv.org/abs/2401.12329)

    这项研究提出了一种基于社会效益的动态优先分配稀缺交通基础设施的方法，以解决城市交通问题。

    

    大城市地方政府所面临的主要问题之一是城市交通管理。他们需要提供有效的人员流动和物品分配手段。然而，交通服务的提供需要考虑到普遍的全球目标，如减少排放和创造更健康的生活环境，这与个体利益并不总是一致。城市交通通常通过包括支持流动性的所有要素的交通基础设施来提供。在许多情况下，这种基础设施要素的容量低于实际需求，因此不同 的交通活动会竞争使用它们。在本文中，我们认为稀缺的交通基础设施要素应以动态和优先的方式分配给从社会角度来看具有较高效用的交通活动；例如，产生排放减少和创造更健康生活环境的活动。

    One of the main problems that local authorities of large cities have to face is the regulation of urban mobility. They need to provide the means to allow for the efficient movement of people and distribution of goods. However, the provisioning of transportation services needs to take into account general global objectives, like reducing emissions and having more healthy living environments, which may not always be aligned with individual interests. Urban mobility is usually provided through a transport infrastructure that includes all the elements that support mobility. On many occasions, the capacity of the elements of this infrastructure is lower than the actual demand and thus different transportation activities compete for their use. In this paper, we argue that scarce transport infrastructure elements should be assigned dynamically and in a prioritised manner to transport activities that have a higher utility from the point of view of society; for example, activities that produce 
    
[^74]: 对多生成器、多领域和多语言机器生成文本检测的大型语言模型进行微调

    Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection. (arXiv:2401.12326v1 [cs.CL])

    [http://arxiv.org/abs/2401.12326](http://arxiv.org/abs/2401.12326)

    本文研究了对多生成器、多领域和多语言机器生成文本的大型语言模型进行微调的任务。实验结果显示，转换器模型特别是LoRA-RoBERTa在效果上超过了传统的机器学习方法，对于多语言环境下的机器生成文本识别，多数投票方法尤为有效。

    

    SemEval-2024任务8引入了从多种语言和领域的不同大型语言模型（LLMs）中识别机器生成文本的挑战。该任务由三个子任务组成：单语和多语言的二元分类（子任务A）、多类别分类（子任务B）以及混合文本检测（子任务C）。本文重点关注子任务A和B。每个子任务都有三个数据集用于训练、开发和测试。为了解决这个任务，采用了两种方法：1）使用传统的机器学习（ML）和自然语言预处理（NLP）进行特征提取，2）对文本分类进行大型语言模型的微调。结果表明，转换器模型，特别是LoRA-RoBERTa，在效果上超过了传统的机器学习方法，多数投票在多语言环境中识别机器生成文本方面尤为有效。

    SemEval-2024 Task 8 introduces the challenge of identifying machine-generated texts from diverse Large Language Models (LLMs) in various languages and domains. The task comprises three subtasks: binary classification in monolingual and multilingual (Subtask A), multi-class classification (Subtask B), and mixed text detection (Subtask C). This paper focuses on Subtask A & B. Each subtask is supported by three datasets for training, development, and testing. To tackle this task, two methods: 1) using traditional machine learning (ML) with natural language preprocessing (NLP) for feature extraction, and 2) fine-tuning LLMs for text classification. The results show that transformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in effectiveness, with majority voting being particularly effective in multilingual contexts for identifying machine-generated texts.
    
[^75]: 在法律分析基础上简化先进的出租车调度策略

    Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis. (arXiv:2401.12324v1 [cs.AI])

    [http://arxiv.org/abs/2401.12324](http://arxiv.org/abs/2401.12324)

    本文提出了在法律分析基础上简化先进的出租车调度策略的方法，并强调了在利用人工智能方法和工具进行原型实现时需要充分考虑法律和伦理问题。

    

    近年来，出现了许多新颖的应用程序，以协作的方式促进服务和活动的提供。这种系统的关键思想是利用现有资源的闲置或低使用率，以提供改进的服务，帮助人们完成日常任务，并提供额外功能、增加效率和/或降低成本。尤其在城市交通领域，许多研究人员提出了新颖的想法，然后通过常常利用人工智能方法和工具进行原型的实现和评估。然而，这些提议也引发了多个非技术问题，如果想将这些系统应用于实际世界，就需要对其进行充分的识别和解决。尽管在实践中，与基于人工智能的系统相关的法律和伦理问题很少在研究和开发过程初期考虑，但我们认为这些问题不仅限制了设计决策，同时也制约了系统范围的扩展和实施。

    In recent years many novel applications have appeared that promote the provision of services and activities in a collaborative manner. The key idea behind such systems is to take advantage of idle or underused capacities of existing resources, in order to provide improved services that assist people in their daily tasks, with additional functionality, enhanced efficiency, and/or reduced cost. Particularly in the domain of urban transportation, many researchers have put forward novel ideas, which are then implemented and evaluated through prototypes that usually draw upon AI methods and tools. However, such proposals also bring up multiple non-technical issues that need to be identified and addressed adequately if such systems are ever meant to be applied to the real world. While, in practice, legal and ethical aspects related to such AI-based systems are seldomly considered in the beginning of the research and development process, we argue that they not only restrict design decisions, 
    
[^76]: 在共享单车系统中的租车智能推荐

    Smart Recommendations for Renting Bikes in Bike Sharing Systems. (arXiv:2401.12322v1 [cs.AI])

    [http://arxiv.org/abs/2401.12322](http://arxiv.org/abs/2401.12322)

    这项研究主要关注共享单车系统中的租车智能推荐问题，旨在解决车辆可用性不均衡的挑战。

    

    近年来，车辆共享系统（如自行车、汽车或摩托车共享系统）在大城市中越来越受欢迎。一方面，它们提供了比私人汽车更便宜和环保的交通方式，另一方面，它们满足了市民个体化的出行需求，比传统的公共交通系统更好。其中一个优势是可用性，比如在城市中几乎可以随处（还）车。这种可用性显然取决于不同的战略和运营管理决策和政策，如车队规模或车辆（再）分配。在这种系统中，由于使用模式，可用车辆集中在某些地区，而其他地区没有车辆的问题非常常见，需要解决。研究一直致力于解决这个问题，更具体地指明了不同的策略和方法。

    Vehicle-sharing systems -- such as bike-, car-, or motorcycle-sharing systems -- have become increasingly popular in big cities in recent years. On the one hand, they provide a cheaper and environmentally friendlier means of transportation than private cars, and on the other hand, they satisfy the individual mobility demands of citizens better than traditional public transport systems. One of their advantages in this regard is their availability, e.g., the possibility of taking (or leaving) a vehicle almost anywhere in a city. This availability obviously depends on different strategic and operational management decisions and policies, such as the dimension of the fleet or the (re)distribution of vehicles. Agglutination problems -- where, due to usage patterns, available vehicles are concentrated in certain areas, whereas no vehicles are available in others -- are quite common in such systems, and need to be dealt with. Research has been dedicated to this problem, specifying different t
    
[^77]: GRATH: 大型语言模型的逐渐自我真实化方法

    GRATH: Gradual Self-Truthifying for Large Language Models. (arXiv:2401.12292v1 [cs.CL])

    [http://arxiv.org/abs/2401.12292](http://arxiv.org/abs/2401.12292)

    GRATH是一种逐步自我真实化的方法，用于提高大型语言模型的真实性。它通过使用领域外问题提示生成答案，并通过直接偏好优化进行自适应模型优化。GRATH在没有标注答案的情况下以自我监督的方式学习真实性，并通过迭代优化来逐步提升模型真实性。

    

    随着大型语言模型（LLMs）在真实世界应用中的部署越来越多，真实性对它们来说至关重要。然而，现有的LLMs在生成真实答案和内容方面仍然存在困难，如在TruthfulQA等基准上的表现不佳。为了解决这个问题，我们提出了GRAdual self-truTHifying (GRATH)，一种通过后处理方法提高LLMs真实性的新方法。GRATH利用领域外的问题提示生成相应的答案，并通过直接偏好优化进行自适应模型优化。在这个过程中，GRATH以无需标注答案的自我监督方式学习真实性。具体而言，GRATH首先通过提示LLM自身生成成对真实性训练数据，每对包含一个问题及其正确和错误答案。然后，使用直接偏好优化来微调模型，从答案对的差异中学习。随后，GRATH迭代地优化模型以逐渐提高真实性。

    Truthfulness is paramount for large language models (LLMs) as they are increasingly deployed in real-world applications. However, existing LLMs still struggle with generating truthful answers and content, as evidenced by their modest performance on benchmarks like TruthfulQA. To address this issue, we propose GRAdual self-truTHifying (GRATH), a novel post-processing method to enhance truthfulness of LLMs. GRATH utilizes out-of-domain question prompts to generate corresponding answers and adaptively optimizes the model via direct preference optimization (DPO). Note that during this process, GRATH learns truthfulness in a self-supervised manner without requiring annotated answers. In particular, GRATH first generates pairwise truthfulness training data by prompting the LLM itself, with each pair containing a question and its correct and incorrect answers. The model is then fine-tuned using DPO to learn from the difference between answer pairs. Subsequently, GRATH iteratively refines the 
    
[^78]: 多Agent动态关系推理用于社交机器人导航

    Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation. (arXiv:2401.12275v1 [cs.RO])

    [http://arxiv.org/abs/2401.12275](http://arxiv.org/abs/2401.12275)

    本文提出了一种多Agent动态关系推理方法，通过明确推断关系结构的演化，来实现在社交机器人导航中的有效性。方法包括推断超边缘以实现群体推理和轨迹预测器生成未来状态。

    

    社交机器人导航在日常生活的各种情景下可以提供帮助，但需要安全的人机交互和高效的轨迹规划。在多Agent交互系统中，建模成对的关系已经被广泛研究，但是捕捉更大规模的群体活动的能力有限。在本文中，我们提出了一种系统的关系推理方法，通过明确推断正在演变的关系结构，展示了其在多Agent轨迹预测和社交机器人导航中的有效性。除了节点对之间的边缘（即Agent），我们还提出了推断超边缘的方法，以自适应地连接多个节点，以便进行群体推理。我们的方法推断动态演化的关系图和超图，以捕捉关系的演化，轨迹预测器利用这些图来生成未来状态。同时，我们提出了对锐度和逻辑稀疏性进行正则化的方法。

    Social robot navigation can be helpful in various contexts of daily life but requires safe human-robot interactions and efficient trajectory planning. While modeling pairwise relations has been widely studied in multi-agent interacting systems, the ability to capture larger-scale group-wise activities is limited. In this paper, we propose a systematic relational reasoning approach with explicit inference of the underlying dynamically evolving relational structures, and we demonstrate its effectiveness for multi-agent trajectory prediction and social robot navigation. In addition to the edges between pairs of nodes (i.e., agents), we propose to infer hyperedges that adaptively connect multiple nodes to enable group-wise reasoning in an unsupervised manner. Our approach infers dynamically evolving relation graphs and hypergraphs to capture the evolution of relations, which the trajectory predictor employs to generate future states. Meanwhile, we propose to regularize the sharpness and sp
    
[^79]: 交互的伦理问题：缓解LLMs中的安全威胁

    The Ethics of Interaction: Mitigating Security Threats in LLMs. (arXiv:2401.12273v1 [cs.CR])

    [http://arxiv.org/abs/2401.12273](http://arxiv.org/abs/2401.12273)

    本研究全面探讨了与语言学习模型（LLMs）面临的安全威胁相关的伦理挑战。分析了五种主要威胁的伦理后果，并强调了确保这些系统在伦理规范范围内运作的紧迫性。

    

    本文全面探讨了与语言学习模型（LLMs）面临的安全威胁相关的伦理挑战。这些复杂的数字存储库日益融入到我们的日常生活中，因此成为攻击的主要目标，可能危及其训练数据和数据源的机密性。本文深入研究了这些安全威胁对社会和个人隐私的微妙伦理影响。我们对五个主要威胁进行了详细分析：提示注入、越狱、个人可识别信息（PII）曝露、性别显露内容和基于仇恨的内容。我们不仅仅进行了识别，还评估了它们的关键伦理后果以及对强化防御策略的紧迫性。对LLMs的不断依赖凸显了确保这些系统在伦理规范范围内运作的重要性，特别是由于它们的滥用可能导致重大社会和个人伤害。我们提出了将这些系统概念化的要求。

    This paper comprehensively explores the ethical challenges arising from security threats to Language Learning Models (LLMs). These intricate digital repositories are increasingly integrated into our daily lives, making them prime targets for attacks that can compromise their training data and the confidentiality of their data sources. The paper delves into the nuanced ethical repercussions of such security threats on society and individual privacy. We scrutinize five major threats: prompt injection, jailbreaking, Personal Identifiable Information (PII) exposure, sexually explicit content, and hate based content, going beyond mere identification to assess their critical ethical consequences and the urgency they create for robust defensive strategies. The escalating reliance on LLMs underscores the crucial need for ensuring these systems operate within the bounds of ethical norms, particularly as their misuse can lead to significant societal and individual harm. We propose conceptualizin
    
[^80]: 在开放存储库中分析AI视觉模型的质量属性及其在对抗攻击下的表现

    Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks. (arXiv:2401.12261v1 [cs.CR])

    [http://arxiv.org/abs/2401.12261](http://arxiv.org/abs/2401.12261)

    本文提出了一种综合流程，用于对AI视觉模型在开放存储库中的质量属性进行分析，尤其是在面对对抗攻击时的表现。我们展示了一个涉及六个计算机视觉模型的评估场景，以评估准确性、鲁棒性、解释效用和开销。

    

    随着AI模型的快速发展，它们经常发布到开放存储库中，如HuggingFace。在将它们集成到生产开发生命周期之前，对这些模型进行质量保证验证是至关重要的。除了评估平衡准确性和计算成本方面的效率外，对抗攻击可能对AI模型的鲁棒性和可解释性构成威胁。同时，可解释性AI（XAI）应用近似输入到输出的算法来识别贡献特征。对抗扰动可能会降低需要进一步研究的XAI解释的效用。在本文中，我们提出了一种综合流程，用于下游评估任务，包括验证AI模型的准确性，使用基准扰动评估鲁棒性，比较解释效用以及评估开销。我们展示了一个涉及六个计算机视觉模型的评估场景，其中包括基于CNN和Transformer的模型。

    As AI models rapidly evolve, they are frequently released to open repositories, such as HuggingFace. It is essential to perform quality assurance validation on these models before integrating them into the production development lifecycle. In addition to evaluating efficiency in terms of balanced accuracy and computing costs, adversarial attacks are potential threats to the robustness and explainability of AI models. Meanwhile, XAI applies algorithms that approximate inputs to outputs post-hoc to identify the contributing features. Adversarial perturbations may also degrade the utility of XAI explanations that require further investigation. In this paper, we present an integrated process designed for downstream evaluation tasks, including validating AI model accuracy, evaluating robustness with benchmark perturbations, comparing explanation utility, and assessing overhead. We demonstrate an evaluation scenario involving six computer vision models, which include CNN-based, Transformer-b
    
[^81]: 协议技术在智能城市中的协调应用

    Agreement Technologies for Coordination in Smart Cities. (arXiv:2401.12259v1 [cs.MA])

    [http://arxiv.org/abs/2401.12259](http://arxiv.org/abs/2401.12259)

    该论文介绍了协议技术在智能城市中的协调应用，以解决智能交通、智能能源网格和参与性治理等领域中的挑战。这些技术基于协议概念，通过开发开放的多agent系统来实现协调。

    

    当前社会面临着许多挑战，可以通过分布式开放系统来解决。这在智能城市这样的领域尤其如此，包括智能交通、智能能源网络和参与性治理等。在为这些领域设计电脑应用时，需要考虑一个事实，即系统的元素（通常称为软件代理）通常来自不同的设计师，并代表特定的利益相关者。此外，在设计时无法确定这些代理何时加入或离开系统，以及新代理将代表什么利益。在这样的系统中进行协调是非常具有挑战性的，因为通常只能在运行时直接控制其中的一部分。协议技术是指基于协议概念的一组工具和机制，用于开发这种开放的多agent系统。本文认为，协议技术是解决智能城市协调问题的有效途径。

    Many challenges in today's society can be tackled by distributed open systems. This is particularly true for domains that are commonly perceived under the umbrella of smart cities, such as intelligent transportation, smart energy grids, or participative governance. When designing computer applications for these domains, it is necessary to account for the fact that the elements of such systems, often called software agents, are usually made by different designers and act on behalf of particular stakeholders. Furthermore, it is unknown at design time when such agents will enter or leave the system, and what interests new agents will represent. To instil coordination in such systems is particularly demanding, as usually only part of them can be directly controlled at runtime. Agreement technologies refer to a sandbox of tools and mechanisms for the development of such open multiagent systems, which are based on the notion of agreement. In this paper, we argue that agreement technologies a
    
[^82]: 强化学习代理中的新兴支配等级

    Emergent Dominance Hierarchies in Reinforcement Learning Agents. (arXiv:2401.12258v1 [cs.MA])

    [http://arxiv.org/abs/2401.12258](http://arxiv.org/abs/2401.12258)

    本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。

    

    现代强化学习算法在各种任务中能够胜过人类。多智能体强化学习(MARL)设置提出了额外的挑战，成功的混合动机代理协作取决于个体和群体目标之间的微妙平衡。社会习惯和规范，往往受到人类机构的启发，被用作实现这种平衡的工具。在本文中，我们研究了一种基本且经过深入研究的社会习惯，即支配等级，它在动物和人类社会中都存在。我们将支配等级的行为理论应用于人工智能代理，并尽可能少地修改现有的术语和定义。我们证明，在没有明确编程或内在奖励的情况下，强化学习代理的群体能够发明、学习、实施和传递支配等级给新的群体。所产生的支配等级有一个

    Modern Reinforcement Learning (RL) algorithms are able to outperform humans in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings present additional challenges, and successful cooperation in mixed-motive groups of agents depends on a delicate balancing act between individual and group objectives. Social conventions and norms, often inspired by human institutions, are used as tools for striking this balance.  In this paper, we examine a fundamental, well-studied social convention that underlies cooperation in both animal and human societies: Dominance hierarchies.  We adapt the ethological theory of dominance hierarchies to artificial agents, borrowing the established terminology and definitions with as few amendments as possible. We demonstrate that populations of RL agents, operating without explicit programming or intrinsic rewards, can invent, learn, enforce, and transmit a dominance hierarchy to new populations. The dominance hierarchies that emerge have a 
    
[^83]: 大型语言模型的指令指纹识别

    Instructional Fingerprinting of Large Language Models. (arXiv:2401.12255v1 [cs.CR])

    [http://arxiv.org/abs/2401.12255](http://arxiv.org/abs/2401.12255)

    这项研究提出了一种指纹识别大型语言模型的方法，通过轻量级的指令调整，保护知识产权并确保遵守许可条款。实验证明这种方法不影响模型的正常行为，并且具有鲁棒性和高效训练的特点。

    

    从零开始训练大型语言模型（LLM）的巨大成本使得对模型进行指纹识别以保护知识产权成为必要，通过所有权认证并确保下游用户和开发者遵守许可条款（如限制商业使用）。在这项研究中，我们提出了LLM指纹识别的试点研究，作为一种非常轻量级的指令调整形式。模型发布者指定一个机密的私钥，并将其植入为一个指令后门，当密钥存在时，导致LLM生成特定的文本。对11个常用LLMs的结果表明，这种方法轻量级且不影响模型的正常行为。它还可以防止发布者过度宣称，对指纹猜测和参数高效训练保持鲁棒性，并支持类似于MIT许可证的多阶段指纹识别。代码可在https://cnut1648.github.io/Model-Fingerprint/中获得。

    The exorbitant cost of training Large language models (LLMs) from scratch makes it essential to fingerprint the models to protect intellectual property via ownership authentication and to ensure downstream users and developers comply with their license terms (e.g. restricting commercial use). In this study, we present a pilot study on LLM fingerprinting as a form of very lightweight instruction tuning. Model publisher specifies a confidential private key and implants it as an instruction backdoor that causes the LLM to generate specific text when the key is present. Results on 11 popularly-used LLMs showed that this approach is lightweight and does not affect the normal behavior of the model. It also prevents publisher overclaim, maintains robustness against fingerprint guessing and parameter-efficient training, and supports multi-stage fingerprinting akin to MIT License. Code is available in https://cnut1648.github.io/Model-Fingerprint/.
    
[^84]: 探索消费者对电子商务中基于文本的聊天机器人的反应：任务复杂性和聊天机器人披露的调节作用

    Exploring consumers response to text-based chatbots in e-commerce: The moderating role of task complexity and chatbot disclosure. (arXiv:2401.12247v1 [cs.AI])

    [http://arxiv.org/abs/2401.12247](http://arxiv.org/abs/2401.12247)

    本研究探索了消费者对电子商务中基于文本的聊天机器人的反应，发现共情和友好度对信任产生积极影响，任务复杂性和聊天机器人披露对这些影响具有调节作用。

    

    基于人工智能的聊天机器人带来了前所未有的商业潜力。本研究旨在探索消费者对电子商务中基于文本的聊天机器人的信任和反应，以及任务复杂性和聊天机器人身份披露的调节效应。通过299个可用的调查问卷收集了数据。本研究采用普通最小二乘回归分析来测试假设。首先，消费者对聊天机器人的共情和友好度的认知对他们的信任产生积极影响。其次，任务的复杂性负向调节了友好度与消费者信任之间的关系。第三，文本聊天机器人的披露负向调节了共情与消费者信任之间的关系，同时正向调节了友好度与消费者信任之间的关系。第四，消费者对聊天机器人的信任增加了他们对聊天机器人的依赖，并减少了他们对未来互动中的抵抗。

    Artificial intelligence based chatbots have brought unprecedented business potential. This study aims to explore consumers trust and response to a text-based chatbot in ecommerce, involving the moderating effects of task complexity and chatbot identity disclosure. A survey method with 299 useable responses was conducted in this research. This study adopted the ordinary least squares regression to test the hypotheses. First, the consumers perception of both the empathy and friendliness of the chatbot positively impacts their trust in it. Second, task complexity negatively moderates the relationship between friendliness and consumers trust. Third, disclosure of the text based chatbot negatively moderates the relationship between empathy and consumers trust, while it positively moderates the relationship between friendliness and consumers trust. Fourth, consumers trust in the chatbot increases their reliance on the chatbot and decreases their resistance to the chatbot in future interactio
    
[^85]: 大规模强化学习用于扩散模型

    Large-scale Reinforcement Learning for Diffusion Models. (arXiv:2401.12244v1 [cs.CV])

    [http://arxiv.org/abs/2401.12244](http://arxiv.org/abs/2401.12244)

    本文介绍了一种大规模强化学习算法，用于改进文本到图像的扩散模型，能够提高模型与人类偏好的一致性，并生成更受人类喜欢的样本。

    

    文本到图像的扩散模型是一类深度生成模型，已经展示出了令人印象深刻的高质量图像生成能力。然而，这些模型容易受到网页规模的文本-图像训练对的隐式偏见的影响，可能无法准确地建模我们关心的图像方面。这可能导致次优的样本、模型偏见和与人类道德和喜好不符的图像。在本文中，我们提出了一种有效的可扩展算法，使用强化学习（RL）来改进扩散模型，涵盖了数百万个图像的人类偏好、组合性和公平性等多样的回报函数。我们展示了我们的方法如何大大优于现有的方法，使扩散模型与人类偏好相一致。我们进一步说明了这如何大大改进了预训练的稳定扩散（SD）模型，所生成的样本在80.3%的时间内优于基本SD模型的样本。

    Text-to-image diffusion models are a class of deep generative models that have demonstrated an impressive capacity for high-quality image generation. However, these models are susceptible to implicit biases that arise from web-scale text-image training pairs and may inaccurately model aspects of images we care about. This can result in suboptimal samples, model bias, and images that do not align with human ethics and preferences. In this paper, we present an effective scalable algorithm to improve diffusion models using Reinforcement Learning (RL) across a diverse set of reward functions, such as human preference, compositionality, and fairness over millions of images. We illustrate how our approach substantially outperforms existing methods for aligning diffusion models with human preferences. We further illustrate how this substantially improves pretrained Stable Diffusion (SD) models, generating samples that are preferred by humans 80.3% of the time over those from the base SD model
    
[^86]: LLM4EDA：大型语言模型在电子设计自动化中的新进展

    LLM4EDA: Emerging Progress in Large Language Models for Electronic Design Automation. (arXiv:2401.12224v1 [cs.AR])

    [http://arxiv.org/abs/2401.12224](http://arxiv.org/abs/2401.12224)

    LLMs have shown promising potential in achieving fully automated chip design and generating circuits with improved power, performance, and area (PPA) in the field of Electronic Design Automation (EDA). (翻译为：LLM在电子设计自动化（EDA）领域显示出了实现全自动化芯片设计和生成具有改进功耗、性能和面积（PPA）的电路的潜力)

    

    驱动着摩尔定律，现代芯片设计的复杂性和规模正在迅速增加。电子设计自动化（EDA）已被广泛应用于解决完整芯片设计过程中遇到的挑战。然而，超大规模集成电路的演进使得芯片设计耗时且资源密集，需要大量的专业知识。此外，在寻求最佳解决方案时，中间的人工控制活动至关重要。在系统设计阶段，电路通常用硬件描述语言（HDL）作为文本格式表示。最近，大型语言模型（LLM）在上下文理解、逻辑推理和答案生成方面展现出了自己的能力。由于电路可以用HDL作为文本格式表示，合理地质疑LLM能否在EDA领域中发挥作用，实现完全自动化的芯片设计并生成具有改进的功耗、性能和面积（PPA）的电路。

    Driven by Moore's Law, the complexity and scale of modern chip design are increasing rapidly. Electronic Design Automation (EDA) has been widely applied to address the challenges encountered in the full chip design process. However, the evolution of very large-scale integrated circuits has made chip design time-consuming and resource-intensive, requiring substantial prior expert knowledge. Additionally, intermediate human control activities are crucial for seeking optimal solutions. In system design stage, circuits are usually represented with Hardware Description Language (HDL) as a textual format. Recently, Large Language Models (LLMs) have demonstrated their capability in context understanding, logic reasoning and answer generation. Since circuit can be represented with HDL in a textual format, it is reasonable to question whether LLMs can be leveraged in the EDA field to achieve fully automated chip design and generate circuits with improved power, performance, and area (PPA). In t
    
[^87]: AI-人工智能的全球影响：最新进展与未来方向的综述

    The Global Impact of AI-Artificial Intelligence: Recent Advances and Future Directions, A Review. (arXiv:2401.12223v1 [cs.CR])

    [http://arxiv.org/abs/2401.12223](http://arxiv.org/abs/2401.12223)

    人工智能是一项新兴技术，有潜力改变社会的多个方面，但也存在经济、道德、社会、安全与隐私以及就业方面的风险和挑战。为了确保AI的负责任发展与应用，政府、行业和学术界之间的合作以及公众的参与和教育至关重要。

    

    人工智能（AI）是一项新兴技术，有潜力改变社会的许多方面，包括经济、医疗和交通等。本文综合了关于AI全球影响的最新研究文献，探讨了其潜在的益处和风险。文章强调了AI的影响，包括其对经济、道德、社会、安全与隐私以及就业方面的影响。它讨论了AI开发所涉及的伦理问题，包括偏见、安全和隐私侵犯等问题。为了确保AI的负责任开发和部署，政府、行业和学术界之间的合作至关重要。文章最后强调了公众参与和教育的重要性，以促进对AI对社会影响的意识和理解。

    Artificial intelligence (AI) is an emerging technology that has the potential to transform many aspects of society, including the economy, healthcare, and transportation. This article synthesizes recent research literature on the global impact of AI, exploring its potential benefits and risks. The article highlights the implications of AI, including its impact on economic, ethical, social, security & privacy, and job displacement aspects. It discusses the ethical concerns surrounding AI development, including issues of bias, security, and privacy violations. To ensure the responsible development and deployment of AI, collaboration between government, industry, and academia is essential. The article concludes by emphasizing the importance of public engagement and education to promote awareness and understanding of AI's impact on society at large.
    
[^88]: BETA：边缘二值化节能Transformer加速器

    BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge. (arXiv:2401.11851v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2401.11851](http://arxiv.org/abs/2401.11851)

    二值化Transformer在边缘部署中有潜力，但面临QMM执行效率低和能耗开销高的挑战。本研究提出了一种计算流抽象方法优化QMM执行效率，并开发了一种二值化节能Transformer加速器BETA，具有可配置的高并行性和高能效的QMM引擎。实验结果表明BETA在ZCU102 FPGA上实现了平均能效。

    

    现有的二值化Transformer由于其紧凑的模型大小、低计算复杂度和可观的推理准确性，在边缘部署中具有潜力。然而，部署二值化Transformer面临着先前处理器的挑战，由于量化矩阵乘法(QMM)的低效执行和多精度激活带来的能耗开销。为了解决以上挑战，我们首先为二值化Transformer开发了一种计算流抽象方法，通过优化计算顺序来改善QMM的执行效率。此外，还提出了一种名为BETA的二值化节能Transformer加速器，以提升在边缘的高效部署。值得注意的是，BETA具有可配置的QMM引擎，适应二值化Transformer的不同激活精度，并为具有出色能效的QMM提供高并行性和高速度。在ZCU102 FPGA上进行的实验结果表明，BETA实现了平均能效。

    Existing binary Transformers are promising in edge deployment due to their compact model size, low computational complexity, and considerable inference accuracy. However, deploying binary Transformers faces challenges on prior processors due to inefficient execution of quantized matrix multiplication (QMM) and the energy consumption overhead caused by multi-precision activations. To tackle the challenges above, we first develop a computation flow abstraction method for binary Transformers to improve QMM execution efficiency by optimizing the computation order. Furthermore, a binarized energy-efficient Transformer accelerator, namely BETA, is proposed to boost the efficient deployment at the edge. Notably, BETA features a configurable QMM engine, accommodating diverse activation precisions of binary Transformers and offering high-parallelism and high-speed for QMMs with impressive energy efficiency. Experimental results evaluated on ZCU102 FPGA show BETA achieves an average energy effic
    
[^89]: 安全且广义的端到端自主驾驶系统：基于强化学习和示范的研究

    Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations. (arXiv:2401.11792v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2401.11792](http://arxiv.org/abs/2401.11792)

    本文介绍了一种安全且广义的端到端自主驾驶系统 (SGADS)，使用强化学习和示范相结合的方法解决了现有方法的低安全性、泛化能力差和采样效率低的问题，同时引入了变分推理和归一化流以准确预测驾驶轨迹，并提出了鲁棒性安全约束的制定方法。

    

    一个智能驾驶系统应该能够根据当前环境和车辆状态动态制定适当的驾驶策略，同时确保系统的安全性和可靠性。然而，基于强化学习和模仿学习的现有方法存在安全性低、泛化能力差和采样效率低的问题。此外，它们无法准确预测未来的驾驶轨迹，而准确预测未来的驾驶轨迹是做出最优决策的前提。为了解决这些问题，本文引入了一种复杂而多样场景下的安全且广义的端到端自主驾驶系统 (SGADS)。我们的SGADS与变分推理和归一化流结合，使智能车辆能够准确预测未来的驾驶轨迹。此外，我们提出了鲁棒性安全约束的制定。此外，我们将强化学习与示范相结合进行增强学习。

    An intelligent driving system should be capable of dynamically formulating appropriate driving strategies based on the current environment and vehicle status, while ensuring the security and reliability of the system. However, existing methods based on reinforcement learning and imitation learning suffer from low safety, poor generalization, and inefficient sampling. Additionally, they cannot accurately predict future driving trajectories, and the accurate prediction of future driving trajectories is a precondition for making optimal decisions. To solve these problems, in this paper, we introduce a Safe and Generalized end-to-end Autonomous Driving System (SGADS) for complex and various scenarios. Our SGADS incorporates variational inference with normalizing flows, enabling the intelligent vehicle to accurately predict future driving trajectories. Moreover, we propose the formulation of robust safety constraints. Furthermore, we combine reinforcement learning with demonstrations to aug
    
[^90]: GI-PIP：梯度反转攻击是否需要不切实际的辅助数据集？

    GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?. (arXiv:2401.11748v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2401.11748](http://arxiv.org/abs/2401.11748)

    本文提出了一种新颖的梯度反转攻击方法GI-PIP，不需要依赖不切实际的辅助数据集，通过利用异常检测模型从较少的数据中捕获底层分布，并能在图像恢复方面表现出优异的能力，同时在分布泛化方面也更强大。

    

    深度梯度反转攻击通过准确地恢复共享梯度中的隐私数据，对联邦学习构成了严重威胁。然而，现有技术在访问过多的辅助数据方面依赖于不切实际的假设，这违反了联邦学习的基本数据分区原则。本文提出了一种新颖的方法，即使用实用图像先验的梯度反转攻击（GI-PIP），在经过修订的威胁模型下。GI-PIP利用异常检测模型从更少的数据中捕获底层分布，而基于GAN的方法需要消耗更多的数据来合成图像。然后，利用提取出的分布来调节攻击过程作为异常得分损失。实验结果表明，GI-PIP只使用了ImageNet数据的3.8%即可实现16.12 dB的PSNR恢复，而基于GAN的方法则需要超过70%的数据。此外，与基于GAN的方法相比，GI-PIP在分布泛化方面表现出更强大的能力。

    Deep gradient inversion attacks expose a serious threat to Federated Learning (FL) by accurately recovering private data from shared gradients. However, the state-of-the-art heavily relies on impractical assumptions to access excessive auxiliary data, which violates the basic data partitioning principle of FL. In this paper, a novel method, Gradient Inversion Attack using Practical Image Prior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits anomaly detection models to capture the underlying distribution from fewer data, while GAN-based methods consume significant more data to synthesize images. The extracted distribution is then leveraged to regulate the attack process as Anomaly Score loss. Experimental results show that GI-PIP achieves a 16.12 dB PSNR recovery using only 3.8% data of ImageNet, while GAN-based methods necessitate over 70%. Moreover, GI-PIP exhibits superior capability on distribution generalization compared to GAN-based methods. Our approach signif
    
[^91]: 通过检索示范进行上下文学习的语言模型：一项综述

    In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.11624](http://arxiv.org/abs/2401.11624)

    本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。

    

    语言模型，特别是预训练的大型语言模型，已展示出卓越的能力，可以在输入上下文中进行少量样本的情境学习（ICL），并在新任务上具有适应能力。然而，模型的ICL能力对于少样本示范的选择是敏感的。最近的一项研究进展是检索针对每个输入查询定制的示范。示范检索的实现相对简单，利用现有的数据库和检索系统。这不仅提高了学习过程的效率和可扩展性，而且已经证明可以减少手动示例选择中的偏见。鉴于令人鼓舞的结果和在检索示范的ICL方面不断增长的研究，我们进行了广泛的研究综述。在这项综述中，我们讨论和比较了检索模型的不同设计选择，检索训练

    Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training p
    
[^92]: ChatQA: 构建GPT-4级对话问答模型

    ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])

    [http://arxiv.org/abs/2401.10225](http://arxiv.org/abs/2401.10225)

    ChatQA是一系列对话问答模型，可以达到GPT-4级别的准确性。通过两阶段的指令调整方法，可以显著提高大型语言模型在零-shot对话问答中的结果。使用密集检索器进行问答数据集的微调可以实现与最先进的查询重写模型相当的结果，同时降低部署成本。ChatQA-70B在10个对话问答数据集上的平均得分超过了GPT-4，且不依赖于任何来自OpenAI GPT模型的合成数据。

    

    在这项工作中，我们介绍了ChatQA，一系列具有GPT-4级别准确性的对话问答模型。具体地，我们提出了一个两阶段的指令调整方法，可以显著提高大型语言模型（LLM）在零-shot对话问答中的结果。为了处理对话问答中的检索问题，我们在多轮问答数据集上进行了密集检索器的微调，这样可以提供与使用最先进的查询重写模型相当的结果，同时大大降低部署成本。值得注意的是，我们的ChatQA-70B可以在10个对话问答数据集的平均分上超过GPT-4（54.14 vs. 53.90），而不依赖于OpenAI GPT模型的任何合成数据。

    In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.
    
[^93]: 使用多模态深度学习的不确定性感知硬件特洛伊检测

    Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep Learning. (arXiv:2401.09479v1 [cs.CR])

    [http://arxiv.org/abs/2401.09479](http://arxiv.org/abs/2401.09479)

    本文提出了一种使用多模态深度学习进行硬件特洛伊检测的方法，通过生成对抗网络扩充数据，并采用早融合和晚融合策略进行评估。通过估计不确定性量化指标，实现风险感知的决策制定。

    

    在零信任的无厂无印造制造时代，硬件特洛伊在芯片生产的各个阶段被插入的风险增加了。为了应对这一问题，已经开发了各种机器学习解决方案用于检测硬件特洛伊。尽管大部分关注点都集中在统计学或深度学习方法上，但受到特洛伊感染基准样本数量有限的影响，检测准确性受限，无法检测到零日特洛伊。为了填补这一差距，我们首先采用生成对抗网络来扩充数据，以两种替代表示模态，图形和表格，确保数据集以代表性的方式分布。此外，我们提出了一种多模态深度学习方法来检测硬件特洛伊，并评估了早融合和晚融合策略的结果。我们还估计了每个预测的不确定性量化指标，用于风险感知的决策制定。结果不仅确认了我们方法的有效性，而且表明了不确定性估计对硬件特洛伊检测的重要性。

    The risk of hardware Trojans being inserted at various stages of chip production has increased in a zero-trust fabless era. To counter this, various machine learning solutions have been developed for the detection of hardware Trojans. While most of the focus has been on either a statistical or deep learning approach, the limited number of Trojan-infected benchmarks affects the detection accuracy and restricts the possibility of detecting zero-day Trojans. To close the gap, we first employ generative adversarial networks to amplify our data in two alternative representation modalities, a graph and a tabular, ensuring that the dataset is distributed in a representative manner. Further, we propose a multimodal deep learning approach to detect hardware Trojans and evaluate the results from both early fusion and late fusion strategies. We also estimate the uncertainty quantification metrics of each prediction for risk-aware decision-making. The outcomes not only confirms the efficacy of our
    
[^94]: 支持学生决策的学习推荐：基于知识图谱情境化的LLM聊天机器人，实现对话解释和指导

    Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring. (arXiv:2401.08517v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.08517](http://arxiv.org/abs/2401.08517)

    这个论文研究了一种基于知识图谱情境化的LLM聊天机器人，作为学生学习推荐的解释工具和指导。通过定义上下文并利用人工策划的信息源来调控LLM的生成，聊天机器人能在与学生对话中提供解释和指导。

    

    学生对学习推荐的决策与其理解推荐原因的能力是不可分割的；他们能否根据这种理解进行修改。在各种解释性方法中，聊天机器人具有与同行或导师讨论类似的潜力来与学生进行对话。然而，尽管生成式人工智能（GenAI）和大型语言模型（LLM）的进展，聊天机器人的能力仍然不足以取代人类导师。因此，我们提出了一种方法，利用聊天机器人作为对话的中介和解释的有限和受控生成的来源，以利用LLM的潜力的同时减少其潜在风险。所提出的基于LLM的聊天机器人支持学生理解学习路径推荐。我们使用知识图谱（KG）作为人工策划的信息源，通过定义其提示的上下文来调控LLM的输出。

    Student commitment towards a learning recommendation is not separable from their understanding of the reasons it was recommended to them; and their ability to modify it based on that understanding. Among explainability approaches, chatbots offer the potential to engage the student in a conversation, similar to a discussion with a peer or a mentor. The capabilities of chatbots, however, are still not sufficient to replace a human mentor, despite the advancements of generative AI (GenAI) and large language models (LLM). Therefore, we propose an approach to utilize chatbots as mediators of the conversation and sources of limited and controlled generation of explanations, to harvest the potential of LLMs while reducing their potential risks at the same time. The proposed LLM-based chatbot supports students in understanding learning-paths recommendations. We use a knowledge graph (KG) as a human-curated source of information, to regulate the LLM's output through defining its prompt's contex
    
[^95]: 高效扩散式图像编辑与即时关注蒙版的研究

    Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks. (arXiv:2401.07709v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.07709](http://arxiv.org/abs/2401.07709)

    本文介绍了一种名为即时扩散编辑的图像编辑方法，该方法利用了现有的扩散模型的跨模态注意力能力，实现了即时的蒙版引导。通过采用无需训练的细化方案，该方法可以自适应地生成准确的蒙版，从而提高了扩散式图像编辑的效率。

    

    扩散式图像编辑是一个新兴的研究热点，通常通过应用语义蒙版来控制编辑的目标区域。然而，现有的解决方案大多通过手动操作或离线处理来获取这些蒙版，大大降低了其效率。本文提出了一种针对文本到图像扩散模型的图像编辑方法，称为即时扩散编辑(InstDiffEdit)。InstDiffEdit旨在利用现有扩散模型的跨模态注意力能力，在扩散步骤中实现即时蒙版引导。为了减少注意力映射的噪声并实现全自动化，我们为InstDiffEdit配备了一种无需训练的细化方案，以自适应地聚合注意力分布，从而实现准确的蒙版生成。同时，为了补充现有的DIE评估，我们提出了一个名为Editing-Mask的新基准来检验蒙版准确性和局部编辑能力。

    Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which often applies a semantic mask to control the target area for diffusion-based editing. However, most existing solutions obtain these masks via manual operations or off-line processing, greatly reducing their efficiency. In this paper, we propose a novel and efficient image editing method for Text-to-Image (T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In particular, InstDiffEdit aims to employ the cross-modal attention ability of existing diffusion models to achieve instant mask guidance during the diffusion steps. To reduce the noise of attention maps and realize the full automatics, we equip InstDiffEdit with a training-free refinement scheme to adaptively aggregate the attention distributions for the automatic yet accurate mask generation. Meanwhile, to supplement the existing evaluations of DIE, we propose a new benchmark called Editing-Mask to examine the mask accuracy and local edi
    
[^96]: APLe: 多模式提示学习的逐令牌自适应方法

    APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning. (arXiv:2401.06827v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.06827](http://arxiv.org/abs/2401.06827)

    本研究提出了APLe方法，通过逐令牌自适应的方式调节CLIP模型中的视觉和语言模式提示，提高了模型的泛化性能。

    

    预训练的视觉语言模型在下游任务的泛化能力方面为同类模型树立了一个基准。现有研究中已经探索了视觉语言模型的许多特征，包括对文本输入的敏感性和跨多模式提示的调节过程所面临的挑战。最近的方法中，借鉴了图像融合中广泛使用的逐层训练思想，以提高泛化性能并解决上述挑战，取代了手工设计的提示，使用可学习的提示来提升性能。在解决多模式提示挑战的背景下，我们提出了逐令牌自适应方法(APLe)，以顺序方式调节CLIP中的视觉和语言两种模式提示。APLe能够高效地改进泛化能力。

    Pre-trained Vision-Language (V-L) models set the benchmark for generalization to downstream tasks among the noteworthy contenders. Many characteristics of the V-L model have been explored in existing research including the challenge of the sensitivity to text input and the tuning process across multi-modal prompts. With the advanced utilization of the V-L model like CLIP, recent approaches deploy learnable prompts instead of hand-craft prompts to boost the generalization performance and address the aforementioned challenges. Inspired by layer-wise training, which is wildly used in image fusion, we note that using a sequential training process to adapt different modalities branches of CLIP efficiently facilitates the improvement of generalization. In the context of addressing the multi-modal prompting challenge, we propose Token-wise Adaptive for Multi-modal Prompt Learning (APLe) for tuning both modalities prompts, vision and language, as tokens in a sequential manner. APLe addresses t
    
[^97]: 对用户行为进行分析以客观评估口语对话系统

    An Analysis of User Behaviours for Objectively Evaluating Spoken Dialogue Systems. (arXiv:2401.04867v1 [cs.CL])

    [http://arxiv.org/abs/2401.04867](http://arxiv.org/abs/2401.04867)

    本文研究了用户行为与主观评估在口语对话系统中的关系，提出了一种间接但客观评估系统的框架，并发现在不同类型的对话任务中，不同的用户行为指标对评估起到重要作用。

    

    建立口语对话系统的评估方案很重要，但也具有挑战性。虽然主观评估在用户实验中常用，但客观评估对于研究比较和可复制性是必要的。为解决这个问题，我们提出了一个框架，通过用户行为间接但客观地评估系统。为此，我们调查了社交对话任务中用户行为与主观评估分数之间的关系：专注倾听、面试和首次会议对话。结果显示，在用户话语是主要因素的对话任务中，如专注倾听和面试，话语数量和单词数量等指标在评估中起到重要作用。观察语调不流畅等也可以指示正式任务的有效性，例如面试。另一方面，在高互动性的对话任务中，如首次会议对话，用户情绪和参与程度更重要。

    Establishing evaluation schemes for spoken dialogue systems is important, but it can also be challenging. While subjective evaluations are commonly used in user experiments, objective evaluations are necessary for research comparison and reproducibility. To address this issue, we propose a framework for indirectly but objectively evaluating systems based on users' behaviours. In this paper, to this end, we investigate the relationship between user behaviours and subjective evaluation scores in social dialogue tasks: attentive listening, job interview, and first-meeting conversation. The results reveal that in dialogue tasks where user utterances are primary, such as attentive listening and job interview, indicators like the number of utterances and words play a significant role in evaluation. Observing disfluency also can indicate the effectiveness of formal tasks, such as job interview. On the other hand, in dialogue tasks with high interactivity, such as first-meeting conversation, b
    
[^98]: 基于混合方法的聊天AI模型：相对于万亿级参数模型的更廉价、更好的替代方案

    Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM. (arXiv:2401.02994v1 [cs.CL])

    [http://arxiv.org/abs/2401.02994](http://arxiv.org/abs/2401.02994)

    本研究介绍了一种名为“混合”的方法，通过组合多个适度规模的聊天AI模型，可以达到或超越比它们更大的模型的性能表现。

    

    在会话型AI研究中，越来越多的模型采用了更多的参数，如ChatGPT等模型。虽然这些庞大的模型往往能生成更好的聊天回复，但它们需要大量的计算资源和内存。本研究探讨了一个重要问题：能否通过组合较小的模型来达到与单个大模型相当或更好的性能？我们提出了一种称为“混合”的方法，它是一种简单但有效的将多个聊天AI集成在一起的方法。我们的实证证据表明，当特定较小的模型协同混合时，它们可以潜在地超越或匹敌大型模型的性能。例如，仅集成三个适度规模的模型（6B/13B参数）就可以达到或甚至超越ChatGPT（175B+参数）等大型模型的性能指标。这个假设经过了严格的测试。

    In conversational AI research, there's a noticeable trend towards developing models with a larger number of parameters, exemplified by models like ChatGPT. While these expansive models tend to generate increasingly better chat responses, they demand significant computational resources and memory. This study explores a pertinent question: Can a combination of smaller models collaboratively achieve comparable or enhanced performance relative to a singular large model? We introduce an approach termed "blending", a straightforward yet effective method of integrating multiple chat AIs. Our empirical evidence suggests that when specific smaller models are synergistically blended, they can potentially outperform or match the capabilities of much larger counterparts. For instance, integrating just three models of moderate size (6B/13B paramaeters) can rival or even surpass the performance metrics of a substantially larger model like ChatGPT (175B+ paramaters). This hypothesis is rigorously tes
    
[^99]: AIGCBench：AI生成的图像到视频内容的全面评估

    AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI. (arXiv:2401.01651v1 [cs.CV])

    [http://arxiv.org/abs/2401.01651](http://arxiv.org/abs/2401.01651)

    本论文介绍了AIGCBench，一个全面评估AI生成的图像到视频内容的基准。通过引入多样化且开放领域的图像-文本数据集，AIGCBench解决了现有基准的局限性。为了建立统一的评估框架，该基准包括11个度量指标，涵盖控制视频对齐、动态效果、时间一致性和视频质量等方面。

    

    人工智能生成内容（AIGC）领域正在迅速发展，尤其是视频生成。本论文介绍了AIGCBench，这是一种开创性的综合性和可扩展性基准，旨在评估各种视频生成任务，主要关注图像到视频（I2V）生成。AIGCBench解决了现有基准的局限性，这些基准缺乏多样化的数据集，通过包括一个多样化且开放领域的图像-文本数据集来评估不同的最先进算法在相等条件下的性能。我们采用了一种新颖的文本组合器和GPT-4来创建丰富的文本提示，然后使用先进的文本到图像模型生成图像。为了建立一个统一的视频生成任务评估框架，我们的基准包括11个度量指标，涵盖四个维度，以评估算法性能。这些维度是控制视频对齐，动态效果，时间一致性和视频质量。

    The burgeoning field of Artificial Intelligence Generated Content (AIGC) is witnessing rapid advancements, particularly in video generation. This paper introduces AIGCBench, a pioneering comprehensive and scalable benchmark designed to evaluate a variety of video generation tasks, with a primary focus on Image-to-Video (I2V) generation. AIGCBench tackles the limitations of existing benchmarks, which suffer from a lack of diverse datasets, by including a varied and open-domain image-text dataset that evaluates different state-of-the-art algorithms under equivalent conditions. We employ a novel text combiner and GPT-4 to create rich text prompts, which are then used to generate images via advanced Text-to-Image models. To establish a unified evaluation framework for video generation tasks, our benchmark includes 11 metrics spanning four dimensions to assess algorithm performance. These dimensions are control-video alignment, motion effects, temporal consistency, and video quality. These 
    
[^100]: 对欧盟在线平台软件文档中排名透明度合规性的实证研究

    An Empirical Study on Compliance with Ranking Transparency in the Software Documentation of EU Online Platforms. (arXiv:2312.14794v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2312.14794](http://arxiv.org/abs/2312.14794)

    该研究通过实证研究了解欧盟在线平台软件文档中排名透明度的合规性情况，并引入并测试了基于ChatGPT和信息检索技术的自动合规性评估工具，结果显示其作为合规性评估的可靠代理的前景很有希望。

    

    欧盟平台对企业（P2B）规例的遵守对在线平台来说是具有挑战性的，而公共机构评估其合规性也可能存在困难。部分原因是缺乏自动化工具来评估平台提供的关于排名透明度的信息（例如，软件文档）。我们的研究以两种方式解决了这个问题。首先，我们对六个主要平台（Amazon，Bing，Booking，Google，Tripadvisor和Yahoo）的合规性进行了实证评估，揭示了它们的文档中存在重大差异。其次，我们引入并测试了基于ChatGPT和信息检索技术的自动合规性评估工具。这些工具与人工判断进行了评估，结果显示它们作为合规性评估的可靠代理的前景很有希望。我们的发现可以帮助提升监管合规性，并与联合国可持续发展目标10.3保持一致，该目标旨在减少包括商业差距在内的不平等。

    Compliance with the European Union's Platform-to-Business (P2B) Regulation is challenging for online platforms, and assessing their compliance can be difficult for public authorities. This is partly due to the lack of automated tools for assessing the information (e.g., software documentation) platforms provide concerning ranking transparency. Our study tackles this issue in two ways. First, we empirically evaluate the compliance of six major platforms (Amazon, Bing, Booking, Google, Tripadvisor, and Yahoo), revealing substantial differences in their documentation. Second, we introduce and test automated compliance assessment tools based on ChatGPT and information retrieval technology. These tools are evaluated against human judgments, showing promising results as reliable proxies for compliance assessments. Our findings could help enhance regulatory compliance and align with the United Nations Sustainable Development Goal 10.3, which seeks to reduce inequality, including business disp
    
[^101]: 追踪任何物体的非现态方法

    Tracking Any Object Amodally. (arXiv:2312.12433v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.12433](http://arxiv.org/abs/2312.12433)

    本论文介绍了一种追踪任何物体的非现态方法，利用数据增强和微调现态跟踪器，可以提高追踪的效果。

    

    非现态感知是一种从部分可见性中理解完整物体结构的基本技能，它对于婴儿甚至是成人都非常重要。它的重要性延伸到了自动驾驶等应用领域，对于理解重叠物体至关重要。然而，现代的检测和跟踪算法通常忽视了这一关键能力，可能是因为大多数数据集中普遍使用的是现态标注。为了解决非现态数据的匮乏问题，我们引入了TAO-Amodal基准，其中包含数千个视频序列中的880个多样化的物体类别。我们的数据集包括可见和遮挡对象的非现态和现态边界框，包括部分超出画面范围的物体。为了增强非现态追踪的目标永久性，我们利用了一个轻量级的插件模块，即非现态扩展器，通过对几百个视频序列进行数据增强的微调，将标准的现态跟踪器转化为非现态跟踪器。我们取得了3.3％和1.6％的改进效果。

    Amodal perception, the ability to comprehend complete object structures from partial visibility, is a fundamental skill, even for infants. Its significance extends to applications like autonomous driving, where a clear understanding of heavily occluded objects is essential. However, modern detection and tracking algorithms often overlook this critical capability, perhaps due to the prevalence of modal annotations in most datasets. To address the scarcity of amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse categories in thousands of video sequences. Our dataset includes amodal and modal bounding boxes for visible and occluded objects, including objects that are partially out-of-frame. To enhance amodal tracking with object permanence, we leverage a lightweight plug-in module, the amodal expander, to transform standard, modal trackers into amodal ones through fine-tuning on a few hundred video sequences with data augmentation. We achieve a 3.3\% and 1.6\% improve
    
[^102]: 条件变分扩散模型

    Conditional Variational Diffusion Models. (arXiv:2312.02246v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.02246](http://arxiv.org/abs/2312.02246)

    该论文提出了一种新的条件变分扩散模型，通过学习调度作为训练过程的一部分，解决了扩散模型的敏感性问题，并且能够适应不同的应用场景，提供高质量的解决方案。

    

    逆问题旨在从观测中确定参数，这是工程和科学中的一个关键任务。最近，生成模型，特别是扩散模型，因其能够产生逼真的解决方案和良好的数学特性而在这一领域中越来越受欢迎。尽管取得了成功，但扩散模型的一个重要缺点是对方差调度的选择敏感，该调度控制着扩散过程的动态。为特定应用程序微调这个调度是至关重要的，但时间成本高昂，并且不能保证最优结果。我们提出了一种新颖的方法，将学习调度作为训练过程的一部分。我们的方法支持对数据的概率条件，提供高质量的解决方案，并且具有灵活性，能够在最小的开销下适应不同的应用。这种方法在两个不相关的逆问题中进行了测试：超分辨率显微镜和定量相位成像，结果表明比较或更好。

    Inverse problems aim to determine parameters from observations, a crucial task in engineering and science. Lately, generative models, especially diffusion models, have gained popularity in this area for their ability to produce realistic solutions and their good mathematical properties. Despite their success, an important drawback of diffusion models is their sensitivity to the choice of variance schedule, which controls the dynamics of the diffusion process. Fine-tuning this schedule for specific applications is crucial but time-costly and does not guarantee an optimal result. We propose a novel approach for learning the schedule as part of the training process. Our method supports probabilistic conditioning on data, provides high-quality solutions, and is flexible, proving able to adapt to different applications with minimum overhead. This approach is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging, yielding comparable or superior 
    
[^103]: 时间中的涟漪：美国历史中的不连续性

    A ripple in time: a discontinuity in American history. (arXiv:2312.01185v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.01185](http://arxiv.org/abs/2312.01185)

    该论文通过使用向量嵌入和非线性降维方法，发现GPT-2与UMAP的结合可以提供更好的分离和聚类效果。同时，经过微调的DistilBERT模型可用于识别总统和演讲的年份。

    

    在这篇论文中，我们使用来自Kaggle的国情咨文数据集对美国历史的总体时间线及咨文本身的特点和性质进行了一些令人惊讶（也有些不那么令人惊讶）的观察。我们的主要方法是使用向量嵌入，如BERT（DistilBERT）和GPT-2。虽然广泛认为BERT（及其变体）最适合NLP分类任务，但我们发现GPT-2结合UMAP等非线性降维方法可以提供更好的分离和更强的聚类效果。这使得GPT-2 + UMAP成为一个有趣的替代方案。在我们的情况下，不需要对模型进行微调，预训练的GPT-2模型就足够好用。我们还使用了经过微调的DistilBERT模型来检测哪位总统发表了哪篇演讲，并取得了非常好的结果（准确率为93\% - 95\%，具体取决于运行情况）。为了确定写作年份，我们还执行了一个类似的任务。

    In this note we use the State of the Union Address (SOTU) dataset from Kaggle to make some surprising (and some not so surprising) observations pertaining to the general timeline of American history, and the character and nature of the addresses themselves. Our main approach is using vector embeddings, such as BERT (DistilBERT) and GPT-2.  While it is widely believed that BERT (and its variations) is most suitable for NLP classification tasks, we find out that GPT-2 in conjunction with nonlinear dimension reduction methods such as UMAP provide better separation and stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In our case, no model fine-tuning is required, and the pre-trained out-of-the-box GPT-2 model is enough.  We also used a fine-tuned DistilBERT model for classification detecting which President delivered which address, with very good results (accuracy 93\% - 95\% depending on the run). An analogous task was performed to determine the year of writing, an
    
[^104]: GraphPro: 面向推荐系统的图预训练和提示学习

    GraphPro: Graph Pre-training and Prompt Learning for Recommendation. (arXiv:2311.16716v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2311.16716](http://arxiv.org/abs/2311.16716)

    GraphPro是一个结合了参数高效和动态图预训练与提示学习的框架，能够有效捕捉长期用户偏好和短期行为动态，从而在真实世界的推荐系统中提供准确和及时的推荐。

    

    基于GNN的推荐系统通过多次消息传递在建模复杂的用户-物品交互方面表现出色。然而，现有方法往往忽视了不断变化的用户-物品交互的动态性，这限制了其在适应用户偏好变化和新到达数据分布变化方面的可扩展性和性能。因此，它们在真实世界的动态环境中的可扩展性和性能受到了限制。在这项研究中，我们提出了GraphPro，这是一个将参数高效和动态图预训练与提示学习相结合的框架。这种新颖的组合能够有效捕捉长期用户偏好和短期行为动态，从而实现准确和及时的推荐。我们的GraphPro框架通过无缝集成临时提示机制和图结构提示学习机制到预训练的GNN模型中来解决用户偏好不断变化的挑战。

    GNN-based recommenders have excelled in modeling intricate user-item interactions through multi-hop message passing. However, existing methods often overlook the dynamic nature of evolving user-item interactions, which impedes the adaption to changing user preferences and distribution shifts in newly arriving data. Thus, their scalability and performances in real-world dynamic environments are limited. In this study, we propose GraphPro, a framework that incorporates parameter-efficient and dynamic graph pre-training with prompt learning. This novel combination empowers GNNs to effectively capture both long-term user preferences and short-term behavior dynamics, enabling the delivery of accurate and timely recommendations. Our GraphPro framework addresses the challenge of evolving user preferences by seamlessly integrating a temporal prompt mechanism and a graph-structural prompt learning mechanism into the pre-trained GNN model. The temporal prompt mechanism encodes time information o
    
[^105]: 基于大型语言模型的大规模决策中控制模型代理：一种演员-评论家方法

    Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach. (arXiv:2311.13884v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.13884](http://arxiv.org/abs/2311.13884)

    本研究提出了一种基于大型语言模型的演员-评论家方法，通过一个名为LLaMAC的模块化框架来解决在多智能体系统中的幻觉和协调问题，并有效利用令牌来促进智能体之间的交互。通过系统资源分配和机器人网格运输的评估，证明了该方法的显著优势。

    

    大型语言模型（LLM）的显著进展为解决多智能体系统中的规划和决策问题开辟了新的途径。然而，随着智能体数量的增加，LLM中的幻觉问题和多智能体系统的协调问题变得日益突出。此外，在利用LLM促进大量智能体之间的交互时，有效利用令牌成为一项重要考虑因素。在本文中，我们开发了一个名为LLaMAC的模块化框架来缓解这些挑战。LLaMAC实现了类似于人脑中的价值分布编码，利用内部和外部反馈机制促进其模块之间的协作和迭代推理。通过涉及系统资源分配和机器人网格运输的评估，我们展示了我们提出方法所带来的巨大优势。

    The remarkable progress in Large Language Models (LLMs) opens up new avenues for addressing planning and decision-making problems in Multi-Agent Systems (MAS). However, as the number of agents increases, the issues of hallucination in LLMs and coordination in MAS have become increasingly prominent. Additionally, the efficient utilization of tokens emerges as a critical consideration when employing LLMs to facilitate the interactions among a substantial number of agents. In this paper, we develop a modular framework called LLaMAC to mitigate these challenges. LLaMAC implements a value distribution encoding similar to that found in the human brain, utilizing internal and external feedback mechanisms to facilitate collaboration and iterative reasoning among its modules. Through evaluations involving system resource allocation and robot grid transportation, we demonstrate the considerable advantages afforded by our proposed approach.
    
[^106]: 一种安全的个性化偏好学习方法及其在自动驾驶汽车中的应用

    A Safe Preference Learning Approach for Personalization with Applications to Autonomous Vehicles. (arXiv:2311.02099v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.02099](http://arxiv.org/abs/2311.02099)

    本研究介绍了一种安全的个性化偏好学习方法，应用于自动驾驶汽车。该方法利用信号时态逻辑公式的优先顺序进行学习，并提出了一种解决这个学习问题的方法。通过对比较，我们找到了适合的权重估计，使得首选信号的加权满足度高于非首选信号。在人体试验中证明了该方法的有效性。

    

    本研究介绍了一种偏好学习方法，确保符合给定规范，并应用于自动驾驶汽车。我们的方法将描述交通规则的信号时态逻辑(STL)公式的优先顺序纳入学习框架中。通过利用参数加权信号时态逻辑(PWSTL)，我们基于成对比较提出了一种解决这个学习问题的方法，该方法确保了安全保证的偏好学习。我们的方法找到了给定PWSTL公式权重的可行估计，使得使用这些权重时，首选信号的加权定量满足度大于非首选信号。我们的方法得到的权重的可行估计导致了一个加权STL公式，可以用于正确性和定制合成控制器。我们通过两个不同的模拟驾驶场景进行了一项人体试验，验证了我们方法的性能。

    This work introduces a preference learning method that ensures adherence to given specifications, with an application to autonomous vehicles. Our approach incorporates the priority ordering of Signal Temporal Logic (STL) formulas describing traffic rules into a learning framework. By leveraging Parametric Weighted Signal Temporal Logic (PWSTL), we formulate the problem of safety-guaranteed preference learning based on pairwise comparisons and propose an approach to solve this learning problem. Our approach finds a feasible valuation for the weights of the given PWSTL formula such that, with these weights, preferred signals have weighted quantitative satisfaction measures greater than their non-preferred counterparts. The feasible valuation of weights given by our approach leads to a weighted STL formula that can be used in correct-and-custom-by-construction controller synthesis. We demonstrate the performance of our method with a pilot human subject study in two different simulated dri
    
[^107]: 学习非稳态条件下的稳定性原则

    A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])

    [http://arxiv.org/abs/2310.18304](http://arxiv.org/abs/2310.18304)

    本研究提出了一个适用于非稳态环境的统计学习框架，通过应用稳定性原则选择回溯窗口来最大化历史数据利用，并保持累积偏差在可接受范围内。该方法展示了对未知非稳态的适应性，遗憾界在强凸或满足Lipschitz条件下是极小化的最优解。该研究的创新点是函数相似度度量和非稳态数据序列划分技术。

    

    我们在非稳定环境中开发了一个灵活的统计学习框架。在每个时间段，我们的方法应用稳定性原则来选择一个回溯窗口，最大限度地利用历史数据，同时将累积偏差保持在与随机误差相对可接受的范围内。我们的理论展示了该方法对未知非稳定性的适应性。当人口损失函数强凸或仅满足Lipschitz条件时，遗憾界是极小化的最优解，仅受对数因子的影响。我们的分析核心是两个新颖的组成部分：函数之间的相似度度量和将非稳态数据序列划分为准稳态片段的分割技术。

    We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
    
[^108]: 异常维度编码特定任务知识

    Outlier Dimensions Encode Task-Specific Knowledge. (arXiv:2310.17715v1 [cs.CL])

    [http://arxiv.org/abs/2310.17715](http://arxiv.org/abs/2310.17715)

    异常维度可以编码关键的特定任务知识，并且一个单一的异常维度可以以最小的错误率完成下游任务。

    

    大型语言模型（LLM）的表示被少数几个具有极高方差的异常维度所主导。先前的研究认为，虽然去除LLM表示中的异常维度会损害下游性能，但异常维度对嵌入表示的质量是有害的。在本研究中，我们研究了微调对异常维度的影响，并展示了以下结果：1）在预训练中出现的异常维度在微调模型中仍然存在，2）一个单一的异常维度可以以最小的错误率完成下游任务。我们的结果表明，异常维度可以编码关键的特定任务知识，并且一个表示在单个异常维度上的值会影响下游模型的决策。

    Representations from large language models (LLMs) are known to be dominated by a small subset of dimensions with exceedingly high variance. Previous works have argued that although ablating these outlier dimensions in LLM representations hurts downstream performance, outlier dimensions are detrimental to the representational quality of embeddings. In this study, we investigate how fine-tuning impacts outlier dimensions and show that 1) outlier dimensions that occur in pre-training persist in fine-tuned models and 2) a single outlier dimension can complete downstream tasks with a minimal error rate. Our results suggest that outlier dimensions can encode crucial task-specific knowledge and that the value of a representation in a single outlier dimension drives downstream model decisions.
    
[^109]: HetGPT: 利用预训练异构图神经网络中的提示调整的能力

    HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks. (arXiv:2310.15318v1 [cs.LG])

    [http://arxiv.org/abs/2310.15318](http://arxiv.org/abs/2310.15318)

    HetGPT是一种预训练异构图神经网络的方法，通过利用提示调整来解决预训练与下游任务之间的不匹配问题。

    

    图表现为表示和分析Web中的复杂模式和丰富信息的自然选择，使得在线页面分类和社交推荐等应用成为可能。然而，当前的“预训练，微调”范式在图机器学习任务中广泛应用，特别是在有限标记节点的情况下，往往存在预训练目标任务与下游任务之间的不匹配问题。这种差距可能导致“负转移”问题，即预训练所获得的知识对下游任务的性能产生不利影响。自然语言处理领域中基于提示的学习的兴起表明了将“预训练，提示”范式应用于图形的潜力，作为一种替代方案。然而，现有的图形提示技术针对的是同质图，忽视了Web图的内在异构性。为了填补这一差距，我们提出了HetGPT，

    Graphs have emerged as a natural choice to represent and analyze the intricate patterns and rich information of the Web, enabling applications such as online page classification and social recommendation. The prevailing "pre-train, fine-tune" paradigm has been widely adopted in graph machine learning tasks, particularly in scenarios with limited labeled nodes. However, this approach often exhibits a misalignment between the training objectives of pretext tasks and those of downstream tasks. This gap can result in the "negative transfer" problem, wherein the knowledge gained from pre-training adversely affects performance in the downstream tasks. The surge in prompt-based learning within Natural Language Processing (NLP) suggests the potential of adapting a "pre-train, prompt" paradigm to graphs as an alternative. However, existing graph prompting techniques are tailored to homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To bridge this gap, we propose HetGPT, a 
    
[^110]: 学习者使用LLM时指导和交互策略对学习者的表现和感知的影响

    Impact of Guidance and Interaction Strategies for LLM Use on Learner Performance and Perception. (arXiv:2310.13712v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2310.13712](http://arxiv.org/abs/2310.13712)

    本研究探索了四种教学指导策略对学习者在使用LLM时的表现和感知效果，发现直接LLM答案提高了表现，而改进学生解决方案则增加了对LLM的信任度。同时，结构化指导也减少了随机查询和学生复制粘贴问题的现象。

    

    面对不断增长的教室规模和教师资源有限的问题，个性化的基于聊天机器人的教学助手可以发挥关键作用。大型语言模型（LLMs）提供了有希望的途径，越来越多的研究探索它们在教育中的实用性。然而，挑战不仅在于确定LLMs的有效性，而且在于识别学习者与这些模型之间的互动细微差别，这会影响学习者的参与和成果。我们在一个本科计算机科学课堂（N=145）和Prolific上进行了一项形成性研究（N=356），以探索四种教学指导策略对学习者在LLMs上的表现、自信心和信任度的影响。直接的LLM答案稍微提高了表现，而改进学生的解决方案增加了信任度。结构化指导减少了随机查询和学生将作业问题复制粘贴给LLM的情况。我们的工作凸显了t

    Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role t
    
[^111]: 正式规定基于LLM的代理人的高级行为

    Formally Specifying the High-Level Behavior of LLM-Based Agents. (arXiv:2310.08535v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.08535](http://arxiv.org/abs/2310.08535)

    本文介绍了一个最小生成框架，通过在高级声明中定义所需的代理人行为，然后构建解码监视器，从而实现了基于LLM的代理人的快速设计和实施。

    

    最近，由LLM驱动的自主目标驱动型代理人已成为解决具有挑战性问题的有前途的工具，而无需获得昂贵的任务特定的精细调整模型。目前，这类代理人的设计和实施是临时性的，因为LLM-based代理人可能应用于的各种任务的广泛性质意味着不能有一种适用于所有情况的代理人设计方法。在这项工作中，我们旨在通过提出一个简化代理人构建过程的最小生成框架来减轻设计和实施新代理人的难度。我们引入的框架允许用户以高级声明的规范方式定义所需的代理人行为，然后使用这个规范构建解码监视器，以确保LLM会产生具有所需行为的输出。我们的声明性方法，即描述行为而不考虑如何实施或强制执行，可以实现快速设计

    Autonomous, goal-driven agents powered by LLMs have recently emerged as promising tools for solving challenging problems without the need for task-specific finetuned models that can be expensive to procure. Currently, the design and implementation of such agents is ad hoc, as the wide variety of tasks that LLM-based agents may be applied to naturally means there can be no one-size-fits-all approach to agent design. In this work we aim to alleviate the difficulty of designing and implementing new agents by proposing a minimalistic generation framework that simplifies the process of building agents. The framework we introduce allows the user to define desired agent behaviors in a high-level, declarative specification that is then used to construct a decoding monitor which guarantees the LLM will produce an output exhibiting the desired behavior. Our declarative approach, in which the behavior is described without concern for how it should be implemented or enforced, enables rapid design,
    
[^112]: 面向方向的视觉-语义嵌入模型在遥感图像-文本检索中的应用

    Direction-Oriented Visual-semantic Embedding Model for Remote Sensing Image-text Retrieval. (arXiv:2310.08276v1 [cs.CV])

    [http://arxiv.org/abs/2310.08276](http://arxiv.org/abs/2310.08276)

    这篇论文提出了一种面向方向的视觉-语义嵌入模型（DOVE），通过区域导向的注意力模块和轻量级的文字基因辅助模块，解决了遥感图像-文本检索中的视觉-语义不平衡问题，提高了检索准确性。

    

    图像-文本检索在近年来得到了快速发展，然而在遥感领域仍然存在着视觉-语义不平衡的挑战，这导致了非语义视觉和文本特征的错误匹配。为了解决这个问题，我们提出了一种新颖的面向方向的视觉-语义嵌入模型（DOVE），来挖掘视觉和语言之间的关系。具体而言，通过区域导向的注意力模块（ROAM），在潜在的语义空间中，根据区域视觉特征自适应地调整最终的视觉和文本嵌入之间的距离。同时，设计了一个轻量级的文字基因辅助模块（DTGA），用较少的注意力操作来扩展可处理的文本表示范围，增强全局词级语义连接。最后，我们利用全局视觉-语义约束来减少单一视觉依赖，并为最终的视觉和文本表示提供外部约束。

    Image-text retrieval has developed rapidly in recent years. However, it is still a challenge in remote sensing due to visual-semantic imbalance, which leads to incorrect matching of non-semantic visual and textual features. To solve this problem, we propose a novel Direction-Oriented Visual-semantic Embedding Model (DOVE) to mine the relationship between vision and language. Concretely, a Regional-Oriented Attention Module (ROAM) adaptively adjusts the distance between the final visual and textual embeddings in the latent semantic space, oriented by regional visual features. Meanwhile, a lightweight Digging Text Genome Assistant (DTGA) is designed to expand the range of tractable textual representation and enhance global word-level semantic connections using less attention operations. Ultimately, we exploit a global visual-semantic constraint to reduce single visual dependency and serve as an external constraint for the final visual and textual representations. The effectiveness and su
    
[^113]: 通过同时学习面部标志检测、域分离和重建来提高面部动作单位检测的精度

    Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction. (arXiv:2310.05207v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05207](http://arxiv.org/abs/2310.05207)

    本文提出了一种新的面部动作单位（AU）检测框架，通过共享参数和引入多任务学习，在面部标志检测和AU域分离与重建之间实现了更好的性能。实验证明我们方法在野外AU检测方面优于现有方法。

    

    最近，如何将大量的在野非标记面部图像引入监督式面部动作单位（AU）检测框架中成为一个具有挑战性的问题。本文提出了一种新的AU检测框架，通过共享同构面部提取模块的参数，引入多任务学习，同时学习AU域分离和重建以及面部标志检测。另外，我们提出了一种基于对比学习的新特征对齐方案，通过简单的投影器和改进的对比损失添加了四个额外的中间监督器来促进特征重建的过程。在两个基准测试上的实验结果表明，我们在野外AU检测方面优于现有的方法。

    Recently how to introduce large amounts of unlabeled facial images in the wild into supervised Facial Action Unit (AU) detection frameworks has become a challenging problem. In this paper, we propose a new AU detection framework where multi-task learning is introduced to jointly learn AU domain separation and reconstruction and facial landmark detection by sharing the parameters of homostructural facial extraction modules. In addition, we propose a new feature alignment scheme based on contrastive learning by simple projectors and an improved contrastive loss, which adds four additional intermediate supervisors to promote the feature reconstruction process. Experimental results on two benchmarks demonstrate our superiority against the state-of-the-art methods for AU detection in the wild.
    
[^114]: "检索遇上长篇大语言模型"

    Retrieval meets Long Context Large Language Models. (arXiv:2310.03025v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.03025](http://arxiv.org/abs/2310.03025)

    "本论文研究了将检索增强和长上下文窗口的大语言模型相结合的解决方案，发现在长上下文任务中，通过检索增强的LLM使用4K上下文窗口可以取得与通过长上下文窗口微调的LLM使用16K上下文窗口相当的性能，同时计算量要少得多。此外，无论上下文窗口大小如何，检索都可以显著提高LLM的性能。"

    

    "最近，扩展大语言模型（LLM）的上下文窗口越来越流行，而将检索与LLM相结合的解决方案已存在多年。自然而然的问题是：检索增强与长上下文窗口，哪个对下游任务更好？这两种方法可以结合起来以兼顾利弊吗？在这项工作中，我们使用两个最先进的预训练LLM（即一个私有的43B GPT和Llama2-70B）来研究这两种解决方案。也许令人惊讶的是，我们发现在长上下文任务中，LLM使用4K上下文窗口并通过简单的检索增强在生成时可以达到与通过长上下文窗口进行位置插值的微调LLM使用16K上下文窗口相当的性能，同时计算量要少得多。更重要的是，我们证明了不论其扩展的上下文窗口大小如何，检索都可以显著提高LLM的性能。我们最好的模型是具有32K上下文窗口的检索增强Llama2-70B。"

    Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years. The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks? ii) Can both methods be combined to get the best of both worlds? In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation. More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes. Our best model, retrieval-augmented Llama2-70B with 32K context wi
    
[^115]: 《GenAI对抗人性：生成式人工智能和大型语言模型的邪恶应用》

    GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models. (arXiv:2310.00737v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2310.00737](http://arxiv.org/abs/2310.00737)

    这篇论文探讨了生成式人工智能和大型语言模型的潜在滥用，呼吁认识到这些挑战的紧迫性。研究揭示了这些技术在深度伪造、合成身份恶意活动以及虚假信息和欺诈方面可能带来的社会影响。

    

    生成式人工智能（GenAI）和大型语言模型（LLM）是技术的奇迹，以其在自然语言处理和多模式内容生成方面的卓越能力而受到赞扬，它们承诺带来一个变革的未来。但就像所有强大的工具一样，它们也有其阴影存在。想象一下生活在一个深度伪造与现实无法区分、合成身份组织恶意活动、以及有着无与伦比精确度的有针对性的虚假信息或欺诈手法的世界。欢迎来到GenAI应用的黑暗面。本文不仅是探索GenAI和LLMs潜在滥用的旅程，也是呼吁认识到面临的挑战的紧迫性。在我们航行于虚假信息活动、恶意内容生成与精密恶意软件构建的海洋中，我们将揭示这场我们正在见证的GenAI革命中的社会影响。

    Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of GenAI applications. This article is not just a journey through the meanders of potential misuse of GenAI and LLMs, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we'll uncover the societal implications that ripple through the GenAI revolution we are witnessing. From AI-powered botnets on social med
    
[^116]: “AI增强我们的表现，我毫不怀疑这一篇论文也会做到同样的事情”：安慰剂效应对AI负面描述有一定的影响(arXiv:2309.16606v1 [cs.HC])

    "AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI. (arXiv:2309.16606v1 [cs.HC])

    [http://arxiv.org/abs/2309.16606](http://arxiv.org/abs/2309.16606)

    该研究发现，无论是正面还是负面描述AI，在实际情况下都不存在AI时，参与者的期望值都很高，并且表现更好。这表明AI的表现期望在负面描述下是有偏差且稳定的。

    

    AI更高的期望通过安慰剂效应促进了人机交互的表现。降低期望来控制安慰剂效应是明智的，但过于负面的期望可能导致负安慰剂效应。在一个字母辨识任务中，我们告知参与者AI会通过调整界面来增强或降低他们的表现，但实际上，在任何条件下都没有AI存在。贝叶斯分析显示，参与者期望值很高，并且不管AI的描述如何，当一个虚假的AI存在时，他们的表现都更好。通过认知建模，我们可以追溯到参与者收集更多信息从而获得优势。一项复制研究验证了负面AI描述不会改变期望值，这表明AI的表现期望在负面言语描述下是有偏差且稳定的。我们讨论了用户期望对于AI交互和评估的影响，并提供了行为安慰剂的证据。

    Heightened AI expectations facilitate performance in human-AI interactions through placebo effects. While lowering expectations to control for placebo effects is advisable, overly negative expectations could induce nocebo effects. In a letter discrimination task, we informed participants that an AI would either increase or decrease their performance by adapting the interface, but in reality, no AI was present in any condition. A Bayesian analysis showed that participants had high expectations and performed descriptively better irrespective of the AI description when a sham-AI was present. Using cognitive modeling, we could trace this advantage back to participants gathering more information. A replication study verified that negative AI descriptions do not alter expectations, suggesting that performance expectations with AI are biased and robust to negative verbal descriptions. We discuss the impact of user expectations on AI interactions and evaluation and provide a behavioral placebo
    
[^117]: GPT-3用于抗癌药物敏感性预测的评估

    Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction. (arXiv:2309.10016v1 [cs.LG])

    [http://arxiv.org/abs/2309.10016](http://arxiv.org/abs/2309.10016)

    本研究评估了GPT-3在抗癌药物敏感性预测任务中的潜力，并发现药物的SMILES表示和细胞系的基因组突变特征对药物反应具有预测能力。这些结果有助于在精准肿瘤学中设计更有效的治疗方案。

    

    本研究使用结构化的药物基因组数据，在五种组织类型中探究了GPT-3在抗癌药物敏感性预测任务中的潜力，并分别采用零样本提示和微调范式对其性能进行了评估。药物的SMILES表示和细胞系的基因组突变特征对药物反应具有预测能力。本研究的结果有望为精准肿瘤学中设计更有效的治疗方案铺平道路。

    In this study, we investigated the potential of GPT-3 for the anti-cancer drug sensitivity prediction task using structured pharmacogenomics data across five tissue types and evaluated its performance with zero-shot prompting and fine-tuning paradigms. The drug's smile representation and cell line's genomic mutation features were predictive of the drug response. The results from this study have the potential to pave the way for designing more efficient treatment protocols in precision oncology.
    
[^118]: CB-Whisper: 使用开放词汇关键词检测进行上下文偏置的Whisper

    CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary Keyword-Spotting. (arXiv:2309.09552v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09552](http://arxiv.org/abs/2309.09552)

    CB-Whisper是一种基于OpenAI的Whisper模型的自动语音识别系统，通过使用开放词汇关键词检测（OV-KWS）识别罕见的命名实体，并使用这些实体作为提示来改进识别效果。实验证明，该方法在提高实体召回率的同时会略微增加混淆错误率（MER）。

    

    自动语音识别系统往往难以识别罕见的命名实体，如个人姓名、组织机构和在训练数据中不经常遇到的专业术语。本文提出了一种基于OpenAI的Whisper模型的Contextual Biasing Whisper（CB-Whisper）自动语音识别系统，通过使用Whisper编码器的隐藏状态执行开放词汇关键词检测（OV-KWS）来识别用户定义的命名实体。识别出的实体被用作Whisper解码器的提示。我们首先提出了一种使用OV-KWS和ASR任务进行多任务训练的方法来优化模型。实验证明，与原始Whisper模型相比，这种方法在中国Aishell热词子集和两个内部代码切换测试集上显著提高了实体召回率。然而，由于灾难性遗忘，我们观察到在内部测试集上混淆错误率（MER）略微增加。为了解决这个问题并使用不同大小的Whisper模型，我们进一步提出了一种解决方案。

    End-to-end automatic speech recognition (ASR) systems often struggle to recognize rare name entities, such as personal names, organizations, and terminologies not frequently encountered in the training data. This paper presents Contextual Biasing Whisper (CB-Whisper), a novel ASR system based on OpenAI's Whisper model that can recognize user-defined name entities by performing open-vocabulary keyword-spotting (OV-KWS) using the hidden states of Whisper encoder. The recognized entities are used as prompts for the Whisper decoder. We first propose a multitask training approach with OV-KWS and ASR tasks to optimize the model. Experiments show that this approach substantially improves the entity recalls compared to the original Whisper model on Chinese Aishell hot word subsets and two internal code-switch test sets. However, we observed a slight increase in mixed-error-rate (MER) on internal test sets due to catastrophic forgetting. To address this problem and use different sizes of the Wh
    
[^119]: 签名网络中的防御联盟

    Defensive Alliances in Signed Networks. (arXiv:2309.06801v1 [cs.CC])

    [http://arxiv.org/abs/2309.06801](http://arxiv.org/abs/2309.06801)

    这项研究探讨了在签名网络中的防御联盟问题，提出了一种量化的群体结构，并通过考虑智能体之间的喜好和厌恶关系，在联盟形成中引入了新的因素。

    

    社交网络和多智能体系统的分析是人工智能中的一个核心主题。某些研究方向涉及寻找能够共同合作实现特定目标的智能体群体。为此，文献中引入了不同概念的图与网络中的集群或社区。其中，防御联盟是一种量化的群体结构。然而，迄今为止，关于联盟的所有研究都忽视了一个在形成联盟中非常直观的方面，即假设智能体在态度方面对其他智能体有预设，他们喜欢和他们喜欢的智能体一起在某个群体（联盟）中，因此愿意相互帮助实现共同的目标，可能会对不喜欢的群体外的智能体进行对抗。签名网络在心理学文献中被引入以模拟智能体之间的喜欢和厌恶关系，这扩展了现有研究的范围。

    The analysis of (social) networks and multi-agent systems is a central theme in Artificial Intelligence. Some line of research deals with finding groups of agents that could work together to achieve a certain goal. To this end, different notions of so-called clusters or communities have been introduced in the literature of graphs and networks. Among these, defensive alliance is a kind of quantitative group structure. However, all studies on the alliance so for have ignored one aspect that is central to the formation of alliances on a very intuitive level, assuming that the agents are preconditioned concerning their attitude towards other agents: they prefer to be in some group (alliance) together with the agents they like, so that they are happy to help each other towards their common aim, possibly then working against the agents outside of their group that they dislike. Signed networks were introduced in the psychology literature to model liking and disliking between agents, generaliz
    
[^120]: LLM强化了交通信号控制的从仿真到真实的迁移

    LLM Powered Sim-to-real Transfer for Traffic Signal Control. (arXiv:2308.14284v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.14284](http://arxiv.org/abs/2308.14284)

    本研究利用大型语言模型（LLMs）通过基于提示的行动转换，解决了交通信号控制任务中从仿真到真实的迁移问题。

    

    尽管已经有很多解决方案用于交通信号控制（TSC）任务，旨在提供高效的交通和减轻拥堵浪费，但仍然存在性能差距，当在仿真器中训练的策略部署到现实世界时。本研究利用大型语言模型（LLMs）通过基于提示的扎根行动转换，来理解和描述系统动态。通过接受填空提示模板，并根据可以访问的上下文填写答案，利用预训练的LLM的推理能力，应用于对系统动态的理解。

    Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks aiming to provide efficient transportation and mitigate congestion waste. In recent, promising results have been attained by Reinforcement Learning (RL) methods through trial and error in simulators, bringing confidence in solving cities' congestion headaches. However, there still exist performance gaps when simulator-trained policies are deployed to the real world. This issue is mainly introduced by the system dynamic difference between the training simulator and the real-world environments. The Large Language Models (LLMs) are trained on mass knowledge and proved to be equipped with astonishing inference abilities. In this work, we leverage LLMs to understand and profile the system dynamics by a prompt-based grounded action transformation. Accepting the cloze prompt template, and then filling in the answer based on accessible context, the pre-trained LLM's inference ability is exploited and applied to understa
    
[^121]: 基于分数的生成模型用于PET图像重建

    Score-Based Generative Models for PET Image Reconstruction. (arXiv:2308.14190v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2308.14190](http://arxiv.org/abs/2308.14190)

    本研究提出了适用于PET图像重建的基于分数的生成模型，通过应对PET图像重建中的挑战，包括高方差的泊松噪声和广泛的动态范围，展示了改进PET重建的显著潜力。

    

    基于分数的生成模型已经在磁共振成像或计算机断层扫描等医学图像重建任务中展现出高度有前景的效果。然而，他们在正电子发射断层扫描（PET）中的应用仍然相对未知。PET图像重建涉及多种挑战，包括高方差的泊松噪声和广泛的动态范围。为了解决这些挑战，我们提出了几种适用于PET的基于分数的生成模型的特定适应方法。我们的方法适用于2D和3D PET，并且提供了使用磁共振图像进行引导重建的扩展。我们通过在没有病变的患者真实数据上进行了广泛的2D和3D的$\textit{in-silico}$实验中验证了这种方法，并通过没有病变的数据以及带有病变的数据进行了评估。这证明了该方法的鲁棒性和显著的PET重建改进潜力。

    Score-based generative models have demonstrated highly promising results for medical image reconstruction tasks in magnetic resonance imaging or computed tomography. However, their application to Positron Emission Tomography (PET) is still largely unexplored. PET image reconstruction involves a variety of challenges, including Poisson noise with high variance and a wide dynamic range. To address these challenges, we propose several PET-specific adaptations of score-based generative models. The proposed framework is developed for both 2D and 3D PET. In addition, we provide an extension to guided reconstruction using magnetic resonance images. We validate the approach through extensive 2D and 3D $\textit{in-silico}$ experiments with a model trained on patient-realistic data without lesions, and evaluate on data without lesions as well as out-of-distribution data with lesions. This demonstrates the proposed method's robustness and significant potential for improved PET reconstruction.
    
[^122]: 大型语言模型的投票：用于罕见病识别的提示

    Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v1 [cs.CL])

    [http://arxiv.org/abs/2308.12890](http://arxiv.org/abs/2308.12890)

    本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。

    

    生成式大型语言模型(LLMs)的出现强调了准确和高效的提示方法的需求。LLMs经常应用于少样本学习(FSL)的情境中，这里任务只使用很少的训练数据执行。FSL在许多人工智能(AI)子领域中变得流行，包括用于健康的AI。罕见病影响人口的一小部分，在数据可用性受限的情况下 inherently 需要FSL技术，尽管人工数据收集和标注费时费力。在本文中，我们提出了模型投票提示(MVP)，这是一种用于改善FSL环境中LLM查询性能的灵活提示方法。MVP通过提示多个LLMs执行相同的任务，然后对生成的输出进行多数投票来实现。该方法在单次罕见病识别和分类任务中相对于任何单个模型在集成模型中实现了改进的结果。我们还发布了一个新颖的罕见病数据集用于FSL。

    The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FS
    
[^123]: 用通用设备编码和图注意力网络革新TCAD模拟

    Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks. (arXiv:2308.11624v1 [cs.LG])

    [http://arxiv.org/abs/2308.11624](http://arxiv.org/abs/2308.11624)

    本论文提出了一种利用人工智能和图表示技术对TCAD器件模拟中的半导体器件进行编码的创新方法，通过引入图注意力网络和通用编码方案，实现了全面的数据驱动建模，为研究人员提供了在设备级上应用基于人工智能的电子设计自动化解决方案的可能性。

    

    本论文提出了一种创新方法，利用人工智能和图表示技术来对TCAD器件模拟中的半导体器件进行编码。提出了一种基于图的通用编码方案，不仅考虑了材料级和器件级嵌入，还引入了一种新颖的基于空间关系的嵌入，受有限元网格中常用的插值操作启发而来。利用器件模拟的通用物理定律进行全面的数据驱动建模，包括基于泊松仿真的替代和基于漂移扩散模型的电流-电压（IV）预测。这两者都是使用一种新颖的图注意力网络（称为RelGAT）实现的。论文还提供了基于Sentaurus TCAD器件模拟器的详细技术细节，使研究人员可以在设备级上采用提出的基于人工智能的电子设计自动化解决方案。

    An innovative methodology that leverages artificial intelligence (AI) and graph representation for semiconductor device encoding in TCAD device simulation is proposed. A graph-based universal encoding scheme is presented that not only considers material-level and device-level embeddings, but also introduces a novel spatial relationship embedding inspired by interpolation operations typically used in finite element meshing. Universal physical laws from device simulations are leveraged for comprehensive data-driven modeling, which encompasses surrogate Poisson emulation and current-voltage (IV) prediction based on drift-diffusion model. Both are achieved using a novel graph attention network, referred to as RelGAT. Comprehensive technical details based on the device simulator Sentaurus TCAD are presented, empowering researchers to adopt the proposed AI-driven Electronic Design Automation (EDA) solution at the device level.
    
[^124]: 重新审视基于列生成的启发式方法用于学习分类树

    Revisiting column-generation-based matheuristic for learning classification trees. (arXiv:2308.11477v1 [cs.LG])

    [http://arxiv.org/abs/2308.11477](http://arxiv.org/abs/2308.11477)

    该论文改进了基于列生成的启发式方法，以提高学习分类树的效果。通过减少子问题数量、使用数据依赖约束作为割平面以及生成违反约束的数据点，该方法提高了可伸缩性并适用于大型数据集。

    

    决策树是机器学习中解决分类问题的高度可解释性模型。传统的机器学习算法训练决策树快速但生成的树在准确性上不够优化。文献中其他离散优化模型解决了最优性问题但只在较小的数据集上表现良好。firat2020column提出了一种基于列生成的启发式方法来学习决策树。该方法提高了可伸缩性，并可以处理大型数据集。在这篇论文中，我们描述了对该列生成方法的改进。首先，我们修改了子问题模型以显著减少多类分类实例中的子问题数量。接下来，我们证明了主问题中的数据依赖约束是蕴含的，并将其用作割平面。此外，我们描述了一个分离模型来生成线性规划松弛解违反其对应的数据点。

    Decision trees are highly interpretable models for solving classification problems in machine learning (ML). The standard ML algorithms for training decision trees are fast but generate suboptimal trees in terms of accuracy. Other discrete optimization models in the literature address the optimality problem but only work well on relatively small datasets. \cite{firat2020column} proposed a column-generation-based heuristic approach for learning decision trees. This approach improves scalability and can work with large datasets. In this paper, we describe improvements to this column generation approach. First, we modify the subproblem model to significantly reduce the number of subproblems in multiclass classification instances. Next, we show that the data-dependent constraints in the master problem are implied, and use them as cutting planes. Furthermore, we describe a separation model to generate data points for which the linear programming relaxation solution violates their correspond
    
[^125]: 用可证明的保证解密神经符号学习中的原始数据

    Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees. (arXiv:2308.10487v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.10487](http://arxiv.org/abs/2308.10487)

    本文介绍了一种使用神经符号混合系统进行机器学习和符号推理的方法，并通过检查知识库来确定它们在促进成功学习方面的效力。研究发现许多知识库满足判据，但也存在一些无法满足的知识库。

    

    神经符号混合系统在整合机器学习和符号推理方面很有前景，其中感知模型通过逻辑推理从符号知识库中推断出信息。尽管有经验证据表明混合系统能够学习准确的感知模型，但对于可学习性的理论理解仍然不足。因此，对于为什么混合系统能够成功完成特定任务以及在不同的知识库下可能失败仍不清楚。本文介绍了一种新的方式，用于描述来自知识库的监督信号，并建立了一个判据来确定知识在促进成功学习方面的效力。这是首次允许我们通过检查正在研究的知识库来回答上述两个问题。我们的分析表明，许多知识库满足判据，从而实现有效的学习，而有些则无法满足，表明存在问题。

    Neuro-symbolic hybrid systems are promising for integrating machine learning and symbolic reasoning, where perception models are facilitated with information inferred from a symbolic knowledge base through logical reasoning. Despite empirical evidence showing the ability of hybrid systems to learn accurate perception models, the theoretical understanding of learnability is still lacking. Hence, it remains unclear why a hybrid system succeeds for a specific task and when it may fail given a different knowledge base. In this paper, we introduce a novel way of characterising supervision signals from a knowledge base, and establish a criterion for determining the knowledge's efficacy in facilitating successful learning. This, for the first time, allows us to address the two questions above by inspecting the knowledge base under investigation. Our analysis suggests that many knowledge bases satisfy the criterion, thus enabling effective learning, while some fail to satisfy it, indicating po
    
[^126]: 基于区域关注的多视角表示学习用于城市区域嵌入

    Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings. (arXiv:2307.03212v1 [cs.CV])

    [http://arxiv.org/abs/2307.03212](http://arxiv.org/abs/2307.03212)

    提出了一种区域关注的多视角表示学习（ROMER）的算法，用于捕捉多视角之间的依赖关系，学习城市区域的表达能力，并在多源城市数据中优于现有方法。

    

    城市区域嵌入是一个重要且具有高度挑战性的问题，由于城市数据的复杂性和不断变化的性质。为了解决这些挑战，我们提出了一种区域关注的多视角表示学习（ROMER），以捕捉多视角之间的依赖关系，并学习城市区域的表达能力，而不受刚性邻域条件的限制。我们的模型专注于从多源城市数据中学习城市区域表示。首先，我们从移动流模式、POI语义和签到动态中捕捉多视角的相关性。然后，我们采用全局图注意网络来学习图中任意两个顶点的相似性。为了全面考虑和共享多个视角的特征，我们进一步提出了一个两阶段的融合模块，利用外部注意力学习权重来融合多视角嵌入。在真实世界数据集上进行的两个下游任务的大量实验证明，我们的模型优于现有的方法。

    Urban region embedding is an important and yet highly challenging issue due to the complexity and constantly changing nature of urban data. To address the challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighbourhood region conditions. Our model focus on learn urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics and check-in dynamics. Then, we adopt global graph attention networks to learn similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods
    
[^127]: CasTGAN: 用于逼真表格数据合成的级联生成对抗网络

    CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis. (arXiv:2307.00384v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.00384](http://arxiv.org/abs/2307.00384)

    本文提出了一个级联生成对抗网络（CasTGAN）框架，用于生成逼真的表格数据，并特别关注输出的有效性。通过采用级联架构，其中专门的生成器对每个特征进行采样，使得合成输出更能代表真实数据。实验结果表明，CasTGAN能够产生更真实有效的合成表格数据。

    

    近年来，生成对抗网络（GANs）因其在生成可用于多种目的的合成数据方面的能力而引起了广泛关注。虽然GAN已经成功地生成了复制原始数据集动态的合成数据样本，但合成数据的有效性和潜在的隐私问题仍然是不容忽视的挑战。在本研究中，我们设计了一个级联表格GAN框架（CasTGAN），用于生成逼真的表格数据，并特别关注输出的有效性。在这个上下文中，有效性是指在真实数据中存在的特征之间的依赖关系，通常被传统的生成模型所误解。我们的关键思想是采用级联架构，其中专门的生成器对每个特征进行采样，使得合成输出更能代表真实数据。我们的实验结果显示，CasTGAN能够产生更真实有效的合成表格数据。

    Generative adversarial networks (GANs) have drawn considerable attention in recent years for their proven capability in generating synthetic data which can be utilised for multiple purposes. While GANs have demonstrated tremendous successes in producing synthetic data samples that replicate the dynamics of the original datasets, the validity of the synthetic data and the underlying privacy concerns represent major challenges which are not sufficiently addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN) for generating realistic tabular data with a specific focus on the validity of the output. In this context, validity refers to the the dependency between features that can be found in the real data, but is typically misrepresented by traditional generative models. Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data. Our experimental resu
    
[^128]: QH9：QM9分子的量子哈密顿预测基准测试

    QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules. (arXiv:2306.09549v1 [physics.chem-ph])

    [http://arxiv.org/abs/2306.09549](http://arxiv.org/abs/2306.09549)

    该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。

    

    监督式机器学习方法越来越被用于加速电子结构预测，作为第一性原理计算方法（如密度泛函理论（DFT））的替代品。虽然许多量子化学数据集侧重于化学性质和原子力，但准确且高效地预测哈密顿矩阵的能力是非常重要和基本的物理量，它确定了物理系统和化学性质的量子状态。在这项工作中，我们生成了一个新的量子哈密顿数据集，命名为QH9，基于QM9数据集为2,399个分子动力学轨迹和130,831个稳定分子几何形态提供精确的哈密顿矩阵。通过设计各种分子的基准任务，我们展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。QH9数据集和基准模型都提供。

    Supervised machine learning approaches have been increasingly used in accelerating electronic structure prediction as surrogates of first-principle computational methods, such as density functional theory (DFT). While numerous quantum chemistry datasets focus on chemical properties and atomic forces, the ability to achieve accurate and efficient prediction of the Hamiltonian matrix is highly desired, as it is the most important and fundamental physical quantity that determines the quantum states of physical systems and chemical properties. In this work, we generate a new Quantum Hamiltonian dataset, named as QH9, to provide precise Hamiltonian matrices for 2,399 molecular dynamics trajectories and 130,831 stable molecular geometries, based on the QM9 dataset. By designing benchmark tasks with various molecules, we show that current machine learning models have the capacity to predict Hamiltonian matrices for arbitrary molecules. Both the QH9 dataset and the baseline models are provided
    
[^129]: 基于数据驱动的遗憾平衡在线模型选择的研究

    Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v1 [cs.LG])

    [http://arxiv.org/abs/2306.02869](http://arxiv.org/abs/2306.02869)

    论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。

    

    我们考虑在具有赌博反馈的随机环境中进行顺序决策模型选择，其中元学习器可以使用一组基本学习器，并根据每个基本学习器推荐的策略动态决策。我们通过遗憾平衡来执行模型选择，但与此相关的最近文献不同的是，我们没有假设任何关于基本学习器的先验知识，如候选遗憾保证；相反，我们以数据驱动的方式揭示这些数量。因此，元学习器能够利用每个基本学习器在给定的学习环境中产生的实际遗憾（而不是期望遗憾），并挑选出最佳的遗憾。我们设计了两个模型选择算法，操作更为雄心勃勃的遗憾概念，并且除了通过遗憾平衡证明模型选择保证外，我们还在实验中展示了处理实际遗憾的令人信服的实际优势。

    We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets ins
    
[^130]: 使用基于文献的语境化学习生成新的科学方向

    Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. (arXiv:2305.14259v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14259](http://arxiv.org/abs/2305.14259)

    本文介绍了一种基于文献的发现方法，通过上下文化的学习生成新的科学方向，克服了标准方法在预测关联、忽略上下文等方面的局限性。模型使用了引文和知识图关系的网络，并使用大型语言模型进行评估，发现GPT4在生成创新思想方面表现出色。

    

    基于文献的发现（LBD）旨在通过挖掘论文并生成假设来发现新的科学知识。标准的LBD仅限于预测离散概念之间的两两关系（例如，药物和疾病的关联）。LBD还忽略了关键的上下文，例如实验设置（例如，药物评估的特定患者群体）和人类科学家考虑的背景知识和动机（例如，找到没有特定副作用的药物候选）。我们通过一种新颖的上下文化LBD（C-LBD）表述来解决这些局限性：以自然语言生成科学假设，同时将它们联系到控制假设搜索空间的上下文中。我们提出了一个建模框架，使用获得的引文和知识图关系的异构网络中的“灵感”，并创建了一个从论文中派生的新数据集。我们使用强大的大型语言模型（LLM）进行评估，发现GPT4倾向于生成具有创新性的思想。

    Literature-Based Discovery (LBD) aims to discover new scientific knowledge by mining papers and generating hypotheses. Standard LBD is limited to predicting pairwise relations between discrete concepts (e.g., drug-disease links). LBD also ignores critical contexts like experimental settings (e.g., a specific patient population where a drug is evaluated) and background knowledge and motivations that human scientists consider (e.g., to find a drug candidate without specific side effects). We address these limitations with a novel formulation of contextualized-LBD (C-LBD): generating scientific hypotheses in natural language, while grounding them in a context that controls the hypothesis search space. We present a modeling framework using retrieval of ``inspirations'' from a heterogeneous network of citations and knowledge graph relations, and create a new dataset derived from papers. Our evaluations with powerful large language models (LLMs) reveal that GPT4 tends to generate ideas with 
    
[^131]: 图像引导的故事结局生成的迭代对抗攻击

    Iterative Adversarial Attack on Image-guided Story Ending Generation. (arXiv:2305.13208v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.13208](http://arxiv.org/abs/2305.13208)

    本文提出了一种迭代对抗攻击方法，通过融合图像和文本模态的攻击，实现了对多模态文本生成任务的对抗攻击搜索，提高了攻击的效果。

    

    多模态学习涉及开发能够整合来自各种来源（如图像和文本）信息的模型。在这一领域中，多模态文本生成是一个关键的方面，它涉及处理来自多个模态的数据并输出文本。图像引导的故事结局生成（IgSEG）是一个特别重要的任务，旨在理解文本和图像数据之间的复杂关系，并生成完整的故事结局文本。不幸的是，最近的IgSEG模型的基础是深度神经网络，这些网络容易受到对抗样本的攻击。当前的对抗攻击方法主要集中在单模态数据上，并未分析用于使用跨模态信息的多模态文本生成任务的对抗攻击。为此，我们提出了一种迭代对抗攻击方法（Iterative-attack），融合了图像和文本模态的攻击，以更有效的迭代方式搜索对抗文本和图像。

    Multimodal learning involves developing models that can integrate information from various sources like images and texts. In this field, multimodal text generation is a crucial aspect that involves processing data from multiple modalities and outputting text. The image-guided story ending generation (IgSEG) is a particularly significant task, targeting on an understanding of complex relationships between text and image data with a complete story text ending. Unfortunately, deep neural networks, which are the backbone of recent IgSEG models, are vulnerable to adversarial samples. Current adversarial attack methods mainly focus on single-modality data and do not analyze adversarial attacks for multimodal text generation tasks that use cross-modal information. To this end, we propose an iterative adversarial attack method (Iterative-attack) that fuses image and text modality attacks, allowing for an attack search for adversarial text and image in an more effective iterative way. Experimen
    
[^132]: 基于能量模型的零样本场景重新排列规划器

    Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v1 [cs.RO])

    [http://arxiv.org/abs/2304.14391](http://arxiv.org/abs/2304.14391)

    本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    

    本文致力于开发一个场景重排框架，可以解释长指令以及在训练时从未见过的空间概念组合。我们提出使用相对对象排列的能量函数来表示语言指导的空间概念。语言解析器将指令映射到相应的能量函数，而开放式视觉语言模型将它们的参数基于场景中的相关对象进行修正。通过梯度下降求解能量函数的总和，并利用基于本地计算机视觉的策略将对象重新定位到推断的目标位置，即可生成目标场景配置。我们在已建立的指令导向操作基准测试以及我们提出的组合指令基准测试中测试了模型，结果表明，我们的模型的绩效优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then relocate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model 
    
[^133]: 基于LSTM-DeepLabv3+和时空特征融合的贝叶斯优化城市洪水预测模型改进

    Improving Urban Flood Prediction using LSTM-DeepLabv3+ and Bayesian Optimization with Spatiotemporal feature fusion. (arXiv:2304.09994v1 [cs.LG])

    [http://arxiv.org/abs/2304.09994](http://arxiv.org/abs/2304.09994)

    本研究提出了一种基于CNN-RNN混合特征融合建模的贝叶斯优化城市洪水预测模型，实现了静态和动态的预测，并通过结合多个CNN和RNN模型，在精度上取得了显著提高。

    

    深度学习模型因其相对传统方法更高的准确性和效率，逐渐成为流行的洪水预测方法。但是，当前的机器学习方法通常依赖于单独的空间或时间特征分析，并对输入数据的类型、数量和维度存在限制。本研究提出了一个基于CNN-RNN的混合特征融合建模方法，用于城市洪水预测，将CNN在处理空间特征方面的优势和RNN在分析不同维度的时间序列方面的优势整合起来。这种方法允许进行静态和动态的洪水预测。应用贝叶斯优化来确定七个最具影响力的洪水驱动因素，并确定最佳组合策略。通过结合四个CNN（FCN，UNet，SegNet，DeepLabv3+）和三个RNN（LSTM，BiLSTM，GRU），最优混合模型被确定为LSTM-DeepLabv3+。该模型实现了最高的预测准确性（MAE、RMSE、NSE和KGE率）。

    Deep learning models have become increasingly popular for flood prediction due to their superior accuracy and efficiency compared to traditional methods. However, current machine learning methods often rely on separate spatial or temporal feature analysis and have limitations on the types, number, and dimensions of input data. This study presented a CNN-RNN hybrid feature fusion modelling approach for urban flood prediction, which integrated the strengths of CNNs in processing spatial features and RNNs in analyzing different dimensions of time sequences. This approach allowed for both static and dynamic flood predictions. Bayesian optimization was applied to identify the seven most influential flood-driven factors and determine the best combination strategy. By combining four CNNs (FCN, UNet, SegNet, DeepLabv3+) and three RNNs (LSTM, BiLSTM, GRU), the optimal hybrid model was identified as LSTM-DeepLabv3+. This model achieved the highest prediction accuracy (MAE, RMSE, NSE, and KGE wer
    
[^134]: 学习策略在企业流程资源分配中的应用

    Learning policies for resource allocation in business processes. (arXiv:2304.09970v1 [cs.AI])

    [http://arxiv.org/abs/2304.09970](http://arxiv.org/abs/2304.09970)

    本文提出了两种基于学习的方法来进行企业流程资源分配，具有优于常见启发式方法的效果。

    

    资源分配是将资源分配到必须在运行时刻执行的业务流程活动中。虽然资源分配在制造等其他领域中已经得到深入研究，但在业务流程管理中却只存在少量的方法。现有方法不适用于大型企业流程的应用或是只针对单个实例进行资源分配的优化。本文提出了两种基于学习的方法来进行企业流程资源分配：一种基于深度强化学习的方法和一种基于评分的价值函数逼近方法。在代表典型业务流程结构的一组情景以及在代表现实业务流程的完整网络上，将两种方法与现有的启发式方法进行比较。结果表明，我们的学习方法在大多数情景中优于或与常见的启发式方法竞争力相当。

    Resource allocation is the assignment of resources to activities that must be executed in a business process at a particular moment at run-time. While resource allocation is well-studied in other fields, such as manufacturing, there exist only a few methods in business process management. Existing methods are not suited for application in large business processes or focus on optimizing resource allocation for a single case rather than for all cases combined. To fill this gap, this paper proposes two learning-based methods for resource allocation in business processes: a deep reinforcement learning-based approach and a score-based value function approximation approach. The two methods are compared against existing heuristics in a set of scenarios that represent typical business process structures and on a complete network that represents a realistic business process. The results show that our learning-based methods outperform or are competitive with common heuristics in most scenarios a
    
[^135]: 图像生成模型的定性失败及其在检测Deepfakes中的应用

    Qualitative Failures of Image Generation Models and Their Application in Detecting Deepfakes. (arXiv:2304.06470v1 [cs.CV])

    [http://arxiv.org/abs/2304.06470](http://arxiv.org/abs/2304.06470)

    研究调查了图像生成模型的质量失误及其应用于检测Deepfakes，识别了五种定性缺陷。这些发现有助于改进模型并制定检测Deepfakes的策略。

    

    图像和视频生成模型创造出逼真的影像的能力已经达到了前所未有的高度，这使得在许多情况下很难区分真实和伪造的图像。然而，尽管取得了进展，但生成图像的质量和真实世界中的图像之间仍存在差距。为了解决这个问题，我们回顾了大量学术论文和社交媒体内容，以确定图像生成模型的定性缺陷，并将其分类为五类。通过了解这些失败，我们可以确定这些模型需要改进的领域，并制定检测Deepfakes的策略。今天社会中Deepfakes的普遍存在是一个严重的问题，我们的研究发现可以帮助减轻它们的负面影响。

    The ability of image and video generation models to create photorealistic images has reached unprecedented heights, making it difficult to distinguish between real and fake images in many cases. However, despite this progress, a gap remains between the quality of generated images and those found in the real world. To address this, we have reviewed a vast body of literature from both academic publications and social media to identify qualitative shortcomings in image generation models, which we have classified into five categories. By understanding these failures, we can identify areas where these models need improvement, as well as develop strategies for detecting deep fakes. The prevalence of deep fakes in today's society is a serious concern, and our findings can help mitigate their negative impact.
    
[^136]: 高效率对抗性模仿学习

    Sample-efficient Adversarial Imitation Learning. (arXiv:2303.07846v1 [cs.LG])

    [http://arxiv.org/abs/2303.07846](http://arxiv.org/abs/2303.07846)

    本研究提出了一种利用自监督表示来增强样本效率的对抗性模仿学习方法，从而学习不受扭曲影响的状态和动作表示以建立非图像控制任务的预测表征。

    

    模仿学习即通过演示进行学习，已经被研究并应用于序贯决策任务中，在这类任务中，奖励函数并不是预定义的。然而，模仿学习方法仍需要大量的专家演示样本才能成功模仿专家的行为。为提高样本效率，我们利用自监督表示学习，该方法可以从给定的数据生成大量的训练信号。在本研究中，我们提出了一种基于自监督表示的对抗性模仿学习方法，以学习不受各种扭曲影响的状态和动作表示，并建立非图像控制任务的预测表征。特别是，与现有的表格数据自监督学习方法相比，我们提出了一种针对状态和动作表示的不同损坏方法，以使其能够抵抗各种扭曲。理论和实证观察表明，使一个信息量大的特征流形与一个简单的生成器与一个复杂的分类器协同工作能够提高状态表征的质量。

    Imitation learning, in which learning is performed by demonstration, has been studied and advanced for sequential decision-making tasks in which a reward function is not predefined. However, imitation learning methods still require numerous expert demonstration samples to successfully imitate an expert's behavior. To improve sample efficiency, we utilize self-supervised representation learning, which can generate vast training signals from the given data. In this study, we propose a self-supervised representation-based adversarial imitation learning method to learn state and action representations that are robust to diverse distortions and temporally predictive, on non-image control tasks. In particular, in comparison with existing self-supervised learning methods for tabular data, we propose a different corruption method for state and action representations that is robust to diverse distortions. We theoretically and empirically observe that making an informative feature manifold with 
    
[^137]: 基于图神经网络的边缘预测中细化边缘使用方法

    Refined Edge Usage of Graph Neural Networks for Edge Prediction. (arXiv:2212.12970v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12970](http://arxiv.org/abs/2212.12970)

    这项研究提出了一种新的边缘预测范式（EMPIRE），通过细化边缘使用方法解决了节点分类任务和边缘预测任务之间的区别。该方法引入了边缘拆分技术和新的消息传递机制，以更好地利用边缘的拓扑结构和监督信号。

    

    图神经网络（GNNs）最初用于节点分类，也激发了许多关于边缘预测（即链路预测）的最新研究。然而，现有方法在关于这两个任务的区别方面缺乏精细的设计，这一点常常被忽视：（i）对于节点分类任务而言，边仅构成拓扑结构，但在边缘预测任务中既可以作为拓扑结构，也可以作为监督信号（即标签）；（ii）节点分类是对每个节点进行预测，而边缘预测则由每对节点决定。为此，我们提出了一种称为边缘感知消息传递神经网络（EMPIRE）的新型边缘预测范式。具体而言，我们首先引入一种边缘拆分技术来指定每个边的使用方式，其中每个边仅用作拓扑结构或监督信号（分别称为拓扑边或监督边）。然后，我们开发了一种新的消息传递机制，生成消息的传递的过程。

    Graph Neural Networks (GNNs), originally proposed for node classification, have also motivated many recent works on edge prediction (a.k.a., link prediction). However, existing methods lack elaborate design regarding the distinctions between two tasks that have been frequently overlooked: (i) edges only constitute the topology in the node classification task but can be used as both the topology and the supervisions (i.e., labels) in the edge prediction task; (ii) the node classification makes prediction over each individual node, while the edge prediction is determinated by each pair of nodes. To this end, we propose a novel edge prediction paradigm named Edge-aware Message PassIng neuRal nEtworks (EMPIRE). Concretely, we first introduce an edge splitting technique to specify use of each edge where each edge is solely used as either the topology or the supervision (named as topology edge or supervision edge). We then develop a new message passing mechanism that generates the messages t
    
[^138]: 规范化交叉密度函数：一种用于量化随机过程统计依赖关系的框架

    The Normalized Cross Density Functional: A Framework to Quantify Statistical Dependence for Random Processes. (arXiv:2212.04631v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04631](http://arxiv.org/abs/2212.04631)

    本文提出了一种用于量化随机过程统计依赖关系的框架，通过最大化交替协方差估计和规范化交叉密度来衡量多变量统计依赖性，并应用于机器学习架构中。

    

    本文提出了一种基于阿尔弗雷德·雷尼（Alfr\'ed R\'enyi）的功能方法论，通过对两个连续随机过程（r.p.）之间的统计依赖关系进行新颖的多变量定义。将随机过程样本对的互信息的对数论证命名为规范化交叉密度（NCD），定义了一种对称和自伴的正定函数。我们证明，最大化交替协方差估计（ACE）递归应用于输入样本对的联合概率密度，符合雷尼的最大相关性的所有性质。我们提出了NCD的特征谱作为一种新颖的多变量度量，用于衡量输入和输出r.p.之间的统计依赖关系。利用r.p.的实现，也可以直接估计多变量统计依赖性。提出的功能最大相关算法（FMCA）应用于由两个神经网络构建的机器学习架构上，通过逼近联合训练来同时学习。

    This paper proposes a novel multivariate definition of statistical dependence between two continuous random processes (r.p.) using a functional methodology inspired by Alfr\'ed R\'enyi. The argument of the logarithm of mutual information between pairs of samples of a r.p., named here the normalized cross density (NCD), defines a symmetric and self-adjoint positive definite function. We show that maximizing the alternating covariance estimation (ACE) recursion, applied to each of the joint probability density of input sample pairs, obeys all the properties of Renyi's maximal correlation. We propose the NCD's eigenspectrum as a novel multivariate measure of the statistical dependence between the input and output r.p.  The multivariate statistical dependence can also be estimated directly from r.p. realizations. The proposed functional maximum correlation algorithm (FMCA) is applied to a machine learning architecture built from two neural networks that learn concurrently by approximating 
    
[^139]: 神经会合：面向星际物体的可靠导航和控制的证明

    Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects. (arXiv:2208.04883v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2208.04883](http://arxiv.org/abs/2208.04883)

    本文提出了神经会合，一种深度学习导航和控制框架，用于可靠、准确和自主地遭遇快速移动的星际物体。它通过点最小范数追踪控制和谱归一化深度神经网络引导策略来提供高概率指数上界的飞行器交付误差。

    

    星际物体（ISOs）很可能是不可替代的原始材料，在理解系外行星星系方面具有重要价值。然而，由于其运行轨道难以约束，通常具有较高的倾角和相对速度，使用传统的人在环路方法探索ISOs具有相当大的挑战性。本文提出了一种名为神经会合的深度学习导航和控制框架，用于在实时中以可靠、准确和自主的方式遭遇快速移动的物体，包括ISOs。它在基于谱归一化的深度神经网络的引导策略之上使用点最小范数追踪控制，其中参数通过直接惩罚MPC状态轨迹跟踪误差的损失函数进行调优。我们展示了神经会合在预期的飞行器交付误差上提供了高概率指数上界，其证明利用了随机递增稳定性分析。

    Interstellar objects (ISOs) are likely representatives of primitive materials invaluable in understanding exoplanetary star systems. Due to their poorly constrained orbits with generally high inclinations and relative velocities, however, exploring ISOs with conventional human-in-the-loop approaches is significantly challenging. This paper presents Neural-Rendezvous, a deep learning-based guidance and control framework for encountering fast-moving objects, including ISOs, robustly, accurately, and autonomously in real time. It uses pointwise minimum norm tracking control on top of a guidance policy modeled by a spectrally-normalized deep neural network, where its hyperparameters are tuned with a loss function directly penalizing the MPC state trajectory tracking error. We show that Neural-Rendezvous provides a high probability exponential bound on the expected spacecraft delivery error, the proof of which leverages stochastic incremental stability analysis. In particular, it is used to
    
[^140]: 通过基于边的Weisfeiler-Lehman算法增强GNN

    Empowering GNNs via Edge-Aware Weisfeiler-Lehman Algorithm. (arXiv:2206.02059v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02059](http://arxiv.org/abs/2206.02059)

    本文提出了一种基于边缘感知的Weisfeiler-Lehman算法，以增强图神经网络的表达能力，同时保持消息传递方案的可扩展性。实验表明，我们NC-GNN框架在各种基准测试中表现出有效性和高效性。

    

    消息传递图神经网络(GNN)的表达能力被已知的一维Weisfeiler-Lehman (1-WL)算法上界所限制。为了实现更强大的GNN，现有的尝试要么需要特定的特征，要么涉及高时间和空间复杂度的操作。在本文中，我们提出了一个通用且可证明具有强大表达力的GNN框架，保持了消息传递方案的可扩展性。具体而言，我们首先通过考虑邻居之间的边缘来授权1-WL进行图同构测试，从而产生NC-1-WL。 NC-1-WL的表达能力在理论上被显示为严格高于1-WL且低于3-WL。进一步，我们提出了NC-GNN框架作为NC-1-WL的可区分神经版本。我们的简单NC-GNN实现可证明与NC-1-WL一样强大。实验表明，我们的NC-GNN在各种基准测试中表现出有效性和高效性。

    Message passing graph neural networks (GNNs) are known to have their expressiveness upper-bounded by 1-dimensional Weisfeiler-Lehman (1-WL) algorithm. To achieve more powerful GNNs, existing attempts either require ad hoc features, or involve operations that incur high time and space complexities. In this work, we propose a general and provably powerful GNN framework that preserves the scalability of the message passing scheme. In particular, we first propose to empower 1-WL for graph isomorphism test by considering edges among neighbors, giving rise to NC-1-WL. The expressiveness of NC-1-WL is shown to be strictly above 1-WL and below 3-WL theoretically. Further, we propose the NC-GNN framework as a differentiable neural version of NC-1-WL. Our simple implementation of NC-GNN is provably as powerful as NC-1-WL. Experiments demonstrate that our NC-GNN performs effectively and efficiently on various benchmarks.
    
[^141]: 带有偏好引导的个性化算法干预研究

    Personalized Algorithmic Recourse with Preference Elicitation. (arXiv:2205.13743v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13743](http://arxiv.org/abs/2205.13743)

    研究提出了PEAR方法，这是一个首个能够针对最终用户需求提供个性化算法补救成本的人机交互方法。该方法利用贝叶斯偏好引导的见解，通过最大化原则性信息增益度量来计算目标用户选择的预期效用，然后将偏好引导整合到强化学习框架中。该方法显著提高了算法干预的经济实用性和用户友好性。

    

    算法干预（AR）的问题是计算用户执行一系列操作以颠覆不良机器决策的过程。该过程的操作序列不应该对用户的实施提出过高的要求。然而，大多数AR方法都假设所有用户的操作成本相同，因此可能会向某些用户推荐昂贵的补救计划。为了解决这个问题，我们提出了PEAR，这是一种首个可提供个性化算法补救成本的人机交互方法，以满足任何最终用户的需求。PEAR利用贝叶斯偏好引导的见解，通过向目标用户发出选择集查询来迭代地改善对操作成本的估计值。这些查询的计算是通过最大化选择的预期效用来计算的，这是一种能够考虑成本估计和用户响应不确定性的原则性信息增益度量。PEAR将偏好引导整合到强化学习框架中，同时考虑用户实现AR任务所需达成目标的偏好，以及执行每个操作所涉及的成本。我们通过引入更具挑战性的AR任务来评估PEAR，并显示其比现有的方法找到了更为经济实用且用户友好的补救计划。

    Algorithmic Recourse (AR) is the problem of computing a sequence of actions that -- once performed by a user -- overturns an undesirable machine decision. It is paramount that the sequence of actions does not require too much effort for users to implement. Yet, most approaches to AR assume that actions cost the same for all users, and thus may recommend unfairly expensive recourse plans to certain users. Prompted by this observation, we introduce PEAR, the first human-in-the-loop approach capable of providing personalized algorithmic recourse tailored to the needs of any end-user. PEAR builds on insights from Bayesian Preference Elicitation to iteratively refine an estimate of the costs of actions by asking choice set queries to the target user. The queries themselves are computed by maximizing the Expected Utility of Selection, a principled measure of information gain accounting for uncertainty on both the cost estimate and the user's responses. PEAR integrates elicitation into a Rein
    
[^142]: 多模式的虚假信息检测：方法、挑战与机遇

    Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities. (arXiv:2203.13883v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.13883](http://arxiv.org/abs/2203.13883)

    这项研究总结了多模式虚假信息检测的方法、挑战和机遇。由于社交媒体平台的转变，虚假信息的性质也发生了变化。研究人员已经开发出自动检测跨模态不协调的技术，但仍面临挑战和不足之处，进一步的研究机会也在等待着挖掘。

    

    随着社交媒体平台从文本为主的论坛转向多模式环境，社交媒体中的虚假信息的性质也相应发生了变化。利用图像和视频等视觉模态更受用户青睐和吸引力的事实，以及文本内容有时被粗略浏览的情况，虚假信息传播者最近开始针对模态之间的上下文连接，例如文本和图像之间的关系。因此，许多研究人员已经开发出自动检测网页内容中可能存在的跨模态不协调的技术。我们分析、分类和识别现有的方法，以及它们面临的挑战和不足之处，以揭示多模式虚假信息检测领域的新研究机会。

    As social media platforms are evolving from text-based forums into multi-modal environments, the nature of misinformation in social media is also transforming accordingly. Taking advantage of the fact that visual modalities such as images and videos are more favorable and attractive to the users and textual contents are sometimes skimmed carelessly, misinformation spreaders have recently targeted contextual connections between the modalities e.g., text and image. Hence many researchers have developed automatic techniques for detecting possible cross-modal discordance in web-based content. We analyze, categorize and identify existing approaches in addition to challenges and shortcomings they face in order to unearth new research opportunities in the field of multi-modal misinformation detection.
    
[^143]: 广义的离群检测：一项调查研究

    Generalized Out-of-Distribution Detection: A Survey. (arXiv:2110.11334v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2110.11334](http://arxiv.org/abs/2110.11334)

    广义的离群检测的调查研究探讨了离群检测的重要性及其与异常检测、新颖性检测和开放集识别等问题的联系，对于提高机器学习系统的可靠性和安全性具有关键意义。

    

    离群检测对于确保机器学习系统的可靠性和安全性至关重要。例如，在自动驾驶中，当系统检测到在训练时从未见过且无法作出安全决策的异常场景或对象时，我们希望驾驶系统能发出警报并将控制交给人类。离群检测一词首次出现在2017年，自那以后引起了研究界的越来越多的关注，从基于分类的方法到基于密度和距离的方法，研究方法五花八门。同时，离群检测与异常检测、新颖性检测、开放集识别和异常检测等其他问题密切相关。尽管目标相同，但这些主题在定义和问题设置上有微妙的差异，经常使读者和从业者感到困惑。

    Out-of-distribution (OOD) detection is critical to ensuring the reliability and safety of machine learning systems. For instance, in autonomous driving, we would like the driving system to issue an alert and hand over the control to humans when it detects unusual scenes or objects that it has never seen during training time and cannot make a safe decision. The term, OOD detection, first emerged in 2017 and since then has received increasing attention from the research community, leading to a plethora of methods developed, ranging from classification-based to density-based to distance-based ones. Meanwhile, several other problems, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD), are closely related to OOD detection in terms of motivation and methodology. Despite common goals, these topics develop in isolation, and their subtle differences in definition and problem setting often confuse readers and practitioners. In this su
    
[^144]: 基于条件偏好语句和广义可加性效用语言的扩展知识编译图

    An extended Knowledge Compilation Map for Conditional Preference Statements-based and Generalized Additive Utilities-based Languages. (arXiv:2102.04107v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2102.04107](http://arxiv.org/abs/2102.04107)

    本文扩展了基于条件偏好语句的语言的知识编译图，研究了查询和转换的各种复杂性，并增加了新的查询和转换的研究，对于广义可加性效用也进行了研究。

    

    条件偏好语句被用来紧凑地表示组合领域中的偏好。它们是CP-网和其一般化版本以及字典排序偏好树的核心。一些研究已经解决了一些查询（特别是优化和支配性）的复杂性。我们在本文中扩展了其中一部分结果，并研究了迄今尚未解决的其他查询，如等价性，以及如条件和变量消除等转换，从而为基于条件偏好语句的语言提供了一个知识编译图。我们还研究了广义可加性效用的查询和转换的表达能力和复杂性。

    Conditional preference statements have been used to compactly represent preferences over combinatorial domains. They are at the core of CP-nets and their generalizations, and lexicographic preference trees. Several works have addressed the complexity of some queries (optimization, dominance in particular). We extend in this paper some of these results, and study other queries which have not been addressed so far, like equivalence, and transformations, like conditioning and variable elimination, thereby contributing to a knowledge compilation map for languages based on conditional preference statements. We also study the expressiveness and complexity of queries and transformations for generalized additive utilities.
    

