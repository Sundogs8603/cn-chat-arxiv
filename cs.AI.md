# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models.](http://arxiv.org/abs/2311.01441) | 本文提出了一个概念简单且轻量级的框架，通过结合知识蒸馏和数据增强的方法来提高视觉模型的鲁棒性，并从预训练的基础模型中获得鲁棒教师模型的知识。借助离散对抗蒸馏方法，我们生成更有信息量的对抗样本，取得了在对抗性样本上鲁棒性显著提升的结果。此外，我们提供了理论框架来支持在知识蒸馏和数据增强设置中使用鲁棒教师模型，并展示了在不同学生模型上的显著性能提升。我们的方法在计算负载方面的开销较小，并可以与其他数据增强方法轻松结合。 |
| [^2] | [Tailoring Mixup to Data using Kernel Warping functions.](http://arxiv.org/abs/2311.01434) | 本研究提出了一种利用核扭曲函数对Mixup数据进行个性化处理的方法，通过动态改变插值系数的概率分布来实现更频繁和更强烈的混合相似数据点。实验证明这种方法不仅提高了模型性能，还提高了模型的校准性。 |
| [^3] | [Analysis of Information Propagation in Ethereum Network Using Combined Graph Attention Network and Reinforcement Learning to Optimize Network Efficiency and Scalability.](http://arxiv.org/abs/2311.01406) | 本研究提出了一种使用图卷积网络和强化学习模型的创新方法，分析以太坊网络中的信息传播模式，并优化网络效率和可扩展性。最终目标是学习在不同网络状态下采取的最佳行动，提高网络效率和可扩展性。 |
| [^4] | [Vision-Language Foundation Models as Effective Robot Imitators.](http://arxiv.org/abs/2311.01378) | 该论文介绍了一种利用视觉语言基础模型进行机器人操作的方法，通过在语言条件的操作数据集上进行微调，实现了在低性能平台上的有效模仿控制。 |
| [^5] | [Recognize Any Regions.](http://arxiv.org/abs/2311.01373) | 本文提出了一种名为RegionSpot的新型、通用且高效的区域识别架构，旨在解决在计算机视觉中理解无约束图像中区域的语义的挑战。 |
| [^6] | [Simplicial Models for the Epistemic Logic of Faulty Agents.](http://arxiv.org/abs/2311.01351) | 本文研究了故障代理的认知逻辑，并提出了基于单纯模型的新模型，该模型允许世界中参与的代理数量可以变化。这对于容错分布式计算非常有用。 |
| [^7] | [Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers.](http://arxiv.org/abs/2311.01344) | 本文研究了如何通过简单的功率分析方法，在32位微控制器上提取深度神经网络模型的架构信息。 |
| [^8] | [Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching.](http://arxiv.org/abs/2311.01331) | 本论文提出了一种通过最小化原始Wasserstein距离来匹配专家和学习者状态占用的方法，以解决离线学习从观察中模仿任务的问题。 |
| [^9] | [Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information.](http://arxiv.org/abs/2311.01326) | 本研究提出了将节点邻居作为额外信息加入语言模型，以改进知识图谱完善方法。在归纳和传递式Wikidata子集上，我们的方法优于传统方法和基于语言模型的KGC方法。邻居信息对模型预测具有重要影响。 |
| [^10] | [Scattering Vision Transformer: Spectral Mixing Matters.](http://arxiv.org/abs/2311.01310) | 本文提出了一种名为散射视觉变换（SVT）的新方法，通过光谱混合来解决视觉变换中的注意力复杂性和信息捕捉问题。 |
| [^11] | [AWEQ: Post-Training Quantization with Activation-Weight Equalization for Large Language Models.](http://arxiv.org/abs/2311.01305) | AWEQ是一种后训练量化和激活权重均衡方法，能够在大型语言模型中实现超低位量化和8-bit权重和激活量化，并通过改进的均衡方法减小量化偏差误差，提高模型的鲁棒性。 |
| [^12] | [TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence Generation with Biomedical Language Models.](http://arxiv.org/abs/2311.01301) | TRIALSCOPE是一个统一的框架，利用生物医学语言模型将临床文本进行结构化，采用概率建模进行去噪和插补，并应用因果推断技术来应对混杂因素，以从实际世界数据中提取实证证据和推理临床假设。 |
| [^13] | [UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding.](http://arxiv.org/abs/2311.01267) | 这项研究提出了UniFolding，一种高效利用样本的机器人系统，用于展开和折叠各种服装。通过整合展开和折叠决策，以及利用部分点云数据，UniFolding具有较强的泛化能力和对纹理和形状变化的鲁棒性。 |
| [^14] | [Expressive TTS Driven by Natural Language Prompts Using Few Human Annotations.](http://arxiv.org/abs/2311.01260) | 本文提出了一种使用少量人工标注的自然语言提示驱动的表达性文本到语音技术，通过利用大型语言模型将表达性文本到语音转变为样式检索任务，使得合成演讲具有预期样式。 |
| [^15] | [Formal Methods for Autonomous Systems.](http://arxiv.org/abs/2311.01258) | 本论文综述了在自主系统领域中应用形式化方法的最新研究，并讨论了构造正确性合成、不确定性处理和系统监测等方面的内容。 |
| [^16] | [An energy-based comparative analysis of common approaches to text classification in the Legal domain.](http://arxiv.org/abs/2311.01256) | 本研究通过在法律领域的文本分类任务上进行比较分析，综合考虑性能和能源消耗等指标，探讨了大型语言模型与传统方法的优劣，并强调了在性能相近的情况下应重视生产成本、能源消耗和碳足迹等方面的考量。 |
| [^17] | [Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching.](http://arxiv.org/abs/2311.01248) | 本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。 |
| [^18] | [FacadeNet: Conditional Facade Synthesis via Selective Editing.](http://arxiv.org/abs/2311.01240) | FacadeNet是一种深度学习方法，通过条件生成对抗网络实现了从不同视角合成建筑立面图像，并通过引入选择性编辑模块，实现了对视角相关元素进行精确修改。实验结果表明，该方法在建筑立面生成方面具有领先的性能。 |
| [^19] | [Navigating Complex Search Tasks with AI Copilots.](http://arxiv.org/abs/2311.01235) | 该论文介绍了使用AI副驾驶员来导航复杂搜索任务，并探讨了生成AI和辅助代理的出现对于支持复杂搜索任务的潜力和重要性。 |
| [^20] | [Long Story Short: a Summarize-then-Search Method for Long Video Question Answering.](http://arxiv.org/abs/2311.01233) | 本论文研究了大型语言模型是否能够在长篇多模态叙述的多媒体内容中扩展它们的零样本推理能力。作者提出了“长话短说”框架，该框架通过将视频的叙述总结成简短情节，并搜索与问题相关的视频部分，来进行叙述性视频问答。实验证明，该模型在长视频问答任务中的性能显著优于最先进的监督模型，展示了零样本问答在长视频中的潜力。 |
| [^21] | [Multi-Operational Mathematical Derivations in Latent Space.](http://arxiv.org/abs/2311.01230) | 本文研究在潜在空间中逼近多个数学运算进行表达式推导的可能性，并通过构建大规模数据集和使用最先进的神经编码器实例化，探索了不同编码机制在潜在空间中逼近方程推理的能力。 |
| [^22] | [Diffusion Models for Reinforcement Learning: A Survey.](http://arxiv.org/abs/2311.01223) | 强化学习中的扩散模型已经成为一种突出的生成模型，通过在样本质量和训练稳定性方面的优势改进了强化学习解决方案。该综述提供了这一新兴领域发展的概述，并探讨了扩散模型在强化学习中的分类法和应用。 |
| [^23] | [Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral Image Classification.](http://arxiv.org/abs/2311.01212) | 本文提出了一种在跨领域少样本高光谱图像分类中学习样本关系的方法，通过从不同视角对样本进行学习，并利用对抗性学习来改进分类性能。 |
| [^24] | [Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent.](http://arxiv.org/abs/2311.01205) | 我们设计了Injectivity Bit Flip Attack来针对图神经网络，成功地降低了其对图结构的识别能力和表达能力，从而增加了其对位反转攻击的易受攻击性。 |
| [^25] | [Cross-Modal Information-Guided Network using Contrastive Learning for Point Cloud Registration.](http://arxiv.org/abs/2311.01202) | 这篇论文提出了一种使用对比学习的跨模态信息引导网络，通过利用从2D图像中学到的视觉信息来实现精确且鲁棒的点云配准。 |
| [^26] | [Federated Learning on Edge Sensing Devices: A Review.](http://arxiv.org/abs/2311.01201) | 本文综述了在边缘感知设备上的联邦学习的研究现状。边缘感知设备的快速增长使得监测环境特征并获取环境信息成为可能，但云端或服务器上的分析面临隐私、硬件和连接性等挑战。联邦学习作为一种解决方案逐渐受到关注。 |
| [^27] | [AiluRus: A Scalable ViT Framework for Dense Prediction.](http://arxiv.org/abs/2311.01197) | AiluRus是一种用于密集预测的可扩展ViT框架，通过应用自适应分辨率和密度聚类算法，将语义相似的令牌合并在一起，以处理长令牌序列的复杂性。 |
| [^28] | [Contextual Confidence and Generative AI.](http://arxiv.org/abs/2311.01193) | 本文讨论了在面对生成型人工智能对上下文置信度的挑战时，采取的两类策略：遏制策略和动员策略。 |
| [^29] | [VIGraph: Self-supervised Learning for Class-Imbalanced Node Classification.](http://arxiv.org/abs/2311.01191) | VIGraph是一个基于自我监督学习的模型，通过利用自编码器生成少数类节点来解决图数据中的类别不平衡问题，并通过引入孪生对比策略提高生成节点的质量。 |
| [^30] | [Revolutionizing Healthcare Image Analysis in Pandemic-Based Fog-Cloud Computing Architectures.](http://arxiv.org/abs/2311.01185) | 这个论文介绍了一种基于雾计算和改进型卷积神经网络的医疗架构，用于解决医疗影像分析中的效率和准确性挑战。 |
| [^31] | [Generative Input: Towards Next-Generation Input Methods Paradigm.](http://arxiv.org/abs/2311.01166) | 本研究提出了一种新的生成输入范式GeneInput，结合提示和用户反馈进行个性化的输入处理，在中文输入法引擎的构建中实现了最先进的性能。 |
| [^32] | [Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering.](http://arxiv.org/abs/2311.01161) | 本研究提出了一种基于程序执行结果的领域无关筛选机制，用于解决弱监督下语义解析中的虚假程序问题 |
| [^33] | [A Review of Digital Twins and their Application in Cybersecurity based on Artificial Intelligence.](http://arxiv.org/abs/2311.01154) | 数字孪生技术与人工智能工具之间的强互动可以改善数字平台的网络安全，但由于缺乏信息和安全标准，网络犯罪分子能够利用数字孪生技术对整个集合造成威胁。 |
| [^34] | [Revisiting the Knowledge Injection Frameworks.](http://arxiv.org/abs/2311.01150) | 这项研究重新审视了知识注入框架，发现将未对齐的随机知识注入到大型语言模型中可以取得与对齐知识相当甚至更好的结果。研究还提供了一种简单的修正技术来解决这个问题。 |
| [^35] | [GREEMA: Proposal and Experimental Verification of Growing Robot by Eating Environmental MAterial for Landslide Disaster.](http://arxiv.org/abs/2311.01107) | GREEMA是一种通过吃环境材料来壮大的创新机器人，在滑坡等无法进入的地区能够取代人力工作，减少运输成本和时间。 |
| [^36] | [Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO.](http://arxiv.org/abs/2311.01057) | 本文介绍了在智能眼镜上实现超高效设备内目标检测的设计和实施，利用新型低功耗处理器实现小型机器学习算法，以便在具有小尺寸和有限电池容量的智能眼镜上实现长时间连续运行。 |
| [^37] | [Multi-dimensional data refining strategy for effective fine-tuning LLMs.](http://arxiv.org/abs/2311.01049) | 本文介绍了一种多维数据精化策略，包括利用现有数据集和生成型AI工具开发数据爬取脚本，用于调优越南语言模型。研究结果表明，使用该策略得到的模型在从提示生成越南新闻文章时表现出良好性能。 |
| [^38] | [AI-assisted Learning for Electronic Engineering Courses in High Education.](http://arxiv.org/abs/2311.01048) | 本研究评估了ChatGPT作为一种AI教学工具在高等教育电子工程课程中的效果，并探讨了其提供见解、个性化支持和互动学习体验的能力。研究结果揭示了ChatGPT作为AI工具的优点和局限性，并为技术学科中创新的学习方法提供了有价值的参考。此外，该研究对教育领域的数字化转型有所贡献。 |
| [^39] | [A Survey of Large Language Models for Autonomous Driving.](http://arxiv.org/abs/2311.01043) | 这篇论文概述了自动驾驶技术的发展趋势，从传统的基于规则的系统过渡到基于数据驱动的端到端系统，并介绍了利用大型语言模型与视觉模型相结合来增强自动驾驶系统能力的思路。 |
| [^40] | [Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism.](http://arxiv.org/abs/2311.01041) | 本文提出了一种学会拒绝（L2R）的简单而有效的解决方案，通过引入拒绝机制，使大型语言模型（LLMs）能够识别和拒绝难以回答的问题，从而提高模型的可控性和可靠性。 |
| [^41] | [ATHENA: Mathematical Reasoning with Thought Expansion.](http://arxiv.org/abs/2311.01036) | ATHENA是一种基于注意力机制的思维扩展网络架构，通过模拟人类的思维扩展机制来解决数学推理中的挑战，它能够产生合理的思考路径以解决实际世界的数学问题。 |
| [^42] | [Non-Autoregressive Diffusion-based Temporal Point Processes for Continuous-Time Long-Term Event Prediction.](http://arxiv.org/abs/2311.01033) | 本论文提出了一种基于扩散的非自回归连续时间点过程模型，用于长期事件预测。通过整体预测未来事件序列、开发双向映射和设计降噪网络等手段，得到了更优的预测质量。 |
| [^43] | [Joint Learning of Local and Global Features for Aspect-based Sentiment Classification.](http://arxiv.org/abs/2311.01030) | 该论文提出了一种联合学习局部和全局特征的方法，以应对基于方面的情感分类中的问题。通过设计一个包含高斯掩码层和协方差自注意层的局部编码器，在模型中有效地整合了局部上下文和全局特征，并提供了更好的区分能力。 |
| [^44] | [Distance-Based Propagation for Efficient Knowledge Graph Reasoning.](http://arxiv.org/abs/2311.01024) | 提出了一种基于距离的传播策略TAGNet，用于知识图谱补全任务中的高效推理。与其他方法相比，TAGNet能够在保持性能的前提下减少传播消息的数量，并且复杂度与层数无关。 |
| [^45] | [Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview Learning for Medical Image Segmentation.](http://arxiv.org/abs/2311.01023) | 本论文提出了一种基于增强驱动的对比多视图学习框架用于医学图像分割，通过与多个增强视图进行对比性学习不变的特征表示，以克服数据短缺和计算资源依赖的问题。 |
| [^46] | [NeuroWrite: Predictive Handwritten Digit Classification using Deep Neural Networks.](http://arxiv.org/abs/2311.01022) | NeuroWrite是一种使用深度神经网络进行手写数字分类预测的独特方法，通过使用卷积神经网络和循环神经网络，在识别和分类手写数字方面取得了优秀的准确性。它可以实现高精度的分类和稳健的泛化能力，并具有在数字化文档中进行数字识别、签名验证和自动邮政编码识别等实际应用的潜力。 |
| [^47] | [Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion.](http://arxiv.org/abs/2311.01017) | 本论文提出了一种通过离散扩散学习无监督的自动驾驶世界模型的新方法，通过使用VQVAE对传感器观察进行标记化并通过离散扩散预测未来，我们的模型在点云观察中实现了显著改进，将1秒预测的SOTA Chamfer距离降低了65%以上。 |
| [^48] | [Revamping AI Models in Dermatology: Overcoming Critical Challenges for Enhanced Skin Lesion Diagnosis.](http://arxiv.org/abs/2311.01009) | 提出了一种名为HOT模型的全能-层次-分布之外-临床分类模型，通过生成层次预测、对分布之外图像的警示以及对临床图像不足的情况下建议进行皮肤镜检查，以提高皮肤病变诊断的效果和协同效应。 |
| [^49] | [Effective Human-AI Teams via Learned Natural Language Rules and Onboarding.](http://arxiv.org/abs/2311.01007) | 本论文提出了一种通过学习自然语言规则和引导的方法，以提高人工智能团队的效果。通过找到数据的局部区域和使用语言模型进行描述，我们教导人类如何与AI合作。通过目标检测和问答任务的用户研究，我们证明了我们的方法可以使人工智能团队更加准确。 |
| [^50] | [Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning.](http://arxiv.org/abs/2311.01004) | 本论文提出了一种使用混合语义学习的Sam引导增强细粒度编码的医学图像字幕生成方法，有效地捕捉了医学图像的详细特征，并在评估指标上优于预训练的BLIP2模型。 |
| [^51] | [Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy.](http://arxiv.org/abs/2311.01002) | 该论文提出了一种通过最大化重新标记准确性来进行鲁棒数据修剪的算法，该算法能够找到一个子集，使得所有训练示例的邻域置信度之和最大化。这个方法在现代深度学习中具有重要的应用价值。 |
| [^52] | [Fully Quantized Always-on Face Detector Considering Mobile Image Sensors.](http://arxiv.org/abs/2311.01001) | 在考虑移动图像传感器的情况下，本研究探索了极低位轻量级的人脸检测器，旨在弥合始终开启场景下的人脸检测的不足。 |
| [^53] | [Replicable Benchmarking of Neural Machine Translation (NMT) on Low-Resource Local Languages in Indonesia.](http://arxiv.org/abs/2311.00998) | 本研究通过在印度尼西亚的低资源本地语言上训练NMT系统的综合分析，解决了神经机器翻译面临的挑战。 尽管计算资源和文本数据有限，但我们的几个NMT系统取得了竞争性性能，与零-shot gpt-3.5-turbo的翻译质量相媲美。 这些发现显著推动了低资源语言的NMT，为研究人员提供了宝贵的指导。 |
| [^54] | [Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks.](http://arxiv.org/abs/2311.00983) | 本文提出了一种基于决策导向学习的方法来解决库存配送问题，通过直接集成库存预测和路径优化，可能确保一个强大的供应链策略。 |
| [^55] | [An Integrated Framework Integrating Monte Carlo Tree Search and Supervised Learning for Train Timetabling Problem.](http://arxiv.org/abs/2311.00971) | 提出了一个综合应用蒙特卡洛树搜索和监督学习的框架，用于解决列车运行图问题(TTP)。实验证明该框架在提高TTP的解决效率方面是有效的。 |
| [^56] | [Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model.](http://arxiv.org/abs/2311.00968) | Video2Music是一个生成音乐的人工智能框架，可以根据视频生成相匹配的音乐。该框架通过分析视频的语义、场景偏移、动作和情感特征，采用Affective Multimodal Transformer (AMT)模型生成音乐。 |
| [^57] | [Vision-Language Interpreter for Robot Task Planning.](http://arxiv.org/abs/2311.00967) | 本文提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架通过使用先进的语言模型和视觉语言模型生成机器人任务描述，并通过符号规划器的错误消息反馈进行改进。实验结果表明ViLaIn和符号规划器能够准确生成有效的机器人计划。 |
| [^58] | [IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End Task-Oriented Dialogue Systems.](http://arxiv.org/abs/2311.00958) | 本文介绍了IndoToD，一个用于印尼语的端到端多领域任务导向对话系统的基准。通过将英语数据集转化为印尼语，我们创建了这个基准，并通过雇佣母语为印尼语的人员进行翻译和数据收集，这为评估印尼语和英语对话系统以及跨语言和双语迁移学习方法提供了有效工具。 |
| [^59] | [Gaussian Mixture Solvers for Diffusion Models.](http://arxiv.org/abs/2311.00941) | 这篇论文提出了一种名为高斯混合解算器(GMS)的新型SDE-based解算器用于扩散模型，通过估计前三阶矩并优化高斯混合参数来解决现有SDE-based解算器的效率-有效性困境问题。 |
| [^60] | [Bridging the Gap: Addressing Discrepancies in Diffusion Model Training for Classifier-Free Guidance.](http://arxiv.org/abs/2311.00938) | 本文介绍了一种更新的损失函数，以更好地对齐传统训练方法与扩散模型所期望的条件采样行为之间的差异。实验证明该方法能够以更少的采样时间步长生成更高质量的样本，并对于引导规模的选择更具鲁棒性。 |
| [^61] | [Scalable Counterfactual Distribution Estimation in Multivariate Causal Models.](http://arxiv.org/abs/2311.00927) | 该论文提出了一种可扩展的方法，用于在多变量因果模型中估计多个感兴趣量的反事实联合分布。通过利用原始高维空间中的一维潜在子空间和单一变量因果模型，该方法可以同时处理多变量结果的相关结构并产生准确的反事实分布估计。 |
| [^62] | [M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place.](http://arxiv.org/abs/2311.00926) | M2T2是一个用于物体操作的多任务遮蔽变换器模型，通过推理场景的原始点云，可以稳定地提供不同类型的低级操作，并在真实机器人上实现了零-shot仿真到实际的转移。 |
| [^63] | [The Power of the Senses: Generalizable Manipulation from Vision and Touch through Masked Multimodal Learning.](http://arxiv.org/abs/2311.00924) | 本文基于屏蔽多模态学习方法提出了一种在强化学习中融合视觉和触觉信息的系统方法，实现了超越单一感官的通用化操控能力，并且这种多模态学习对于仅视觉策略也具有好处。 |
| [^64] | [Artificial Intelligence Ethics Education in Cybersecurity: Challenges and Opportunities: a focus group report.](http://arxiv.org/abs/2311.00903) | 这项研究揭示了人工智能在网络安全中的挑战和机遇，包括获取免费工具、课程多样性、伦理原则的明确阐述以及解决“黑匣子”思维等问题。研究提出了通过严格的技术培训、清晰的文档和伦理监控的框架来解决这些问题。 |
| [^65] | [Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code.](http://arxiv.org/abs/2311.00889) | 该论文研究了使用SALLMS评估LLM生成代码的安全性，指出现有数据集和评估指标未能充分考虑到与安全相关的真实软件工程任务，从而导致不安全的代码生成。 |
| [^66] | [SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization.](http://arxiv.org/abs/2311.00880) | SCPO是一种安全强化学习算法，通过引入安全批判器来确保遵守安全约束并平衡回报的最大化。 |
| [^67] | [Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2311.00865) | 本文介绍了一种选择性多智能体强化学习方法，即选择性多智能体优先体验中继，代理之间共享有限数量的训练经验。与其他算法相比，该方法实现了去中心化训练，并取得了比基准算法和最先进算法更好的性能。 |
| [^68] | [Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning.](http://arxiv.org/abs/2311.00860) | 本文提出了一种用于物理约束操作学习的新型自动微分算法，通过零坐标移动（ZCS）的技巧，将所需导数的复杂度从“多根多叶”简化为“一根多叶”，从而显著提高了性能。 |
| [^69] | [Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems.](http://arxiv.org/abs/2311.00859) | 本研究提出了一种基于最优成本约束的分布式攻击代理的对抗攻击方法，可以在多智能体系统中显著降低受攻击代理获得的奖励。 |
| [^70] | [A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. Ending the HIV Epidemic Plan.](http://arxiv.org/abs/2311.00855) | 本论文提出了一种多智能体强化学习（MARL）框架，用于评估美国终结HIV流行计划。该框架能够进行特定地区的决策分析，并考虑到地区之间的流行病学相互作用。 |
| [^71] | [healthAIChain: Improving security and safety using Blockchain Technology applications in AI-based healthcare systems.](http://arxiv.org/abs/2311.00842) | healthAIChain使用区块链技术改进AI医疗系统的安全性和安全性，解决了医疗保健系统中与安全性，性能效率和安全性相关的问题。 |
| [^72] | [Constant-time Motion Planning with Anytime Refinement for Manipulation.](http://arxiv.org/abs/2311.00837) | 我们提出了一种任意时间提炼方法，结合恒定时间动作规划器（CTMP）在机器人操作中改善解决方案。这种方法利用机器人系统拥有的多余计划时间来完善运动规划的结果。 |
| [^73] | [Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks.](http://arxiv.org/abs/2311.00800) | 本论文通过引入包括时间特征的多流模型，提出了一个经过视频训练的鲁棒性模型，通过在训练中包括视频和时间流，减少了图像和视频理解任务的准确性下降率。 |
| [^74] | [Tipping Points of Evolving Epidemiological Networks: Machine Learning-Assisted, Data-Driven Effective Modeling.](http://arxiv.org/abs/2311.00797) | 该论文通过机器学习辅助的数据驱动建模方法，研究了自适应易感-感染-易感流行病学网络的临界转折点集体动力学。他们识别出了一个有效的随机微分方程以描述网络的演化行为，并观察到了罕见的大幅度集体振荡现象。 |
| [^75] | [SAGE: Smart home Agent with Grounded Execution.](http://arxiv.org/abs/2311.00772) | SAGE框架通过替换手动定义的推理逻辑，实现了基于实际执行的智能家居助手，提高了灵活性。它可以学习用户偏好，与设备交互，监视设备，并理解自然的设备引用。在评估中，SAGE在43个智能家居任务中成功完成了23个任务，优于现有的LLM基准。 |
| [^76] | [Hand Gesture Classification on Praxis Dataset: Trading Accuracy for Expense.](http://arxiv.org/abs/2311.00767) | 本文研究了在Praxis数据集上的手势分类问题，提出了一种基于身体关节数据和深度学习的手势分类器模型，相比之前的模型更有效。通过使用窗口技术和循环神经网络（RNN）结构，仅使用身体关节数据就达到了70.8%的准确率。此外，还研究了一种长短时记忆（LSTM）方法来提取和分析关节运动特征以识别手势。 |
| [^77] | [Learning to Design and Use Tools for Robotic Manipulation.](http://arxiv.org/abs/2311.00754) | 本论文提出了学习一种设计策略来制作适用于不同任务的专用工具，并通过这些工具进行机器人操纵。这可以解锁机器人的额外能力。 |
| [^78] | [Are These the Same Apple? Comparing Images Based on Object Intrinsics.](http://arxiv.org/abs/2311.00750) | 本研究提出了一种基于物体内在特性的图像相似度度量方法，通过对通用对象类别进行扩展，并收集了大规模的CUTE数据集来评估该方法。 |
| [^79] | [Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?.](http://arxiv.org/abs/2311.00738) | 本文介绍了一个新的多模态基准数据集，观察、对话和引导（WTaG），以及两个任务：用户和环境理解以及指导者决策。研究发现，基础模型在感知化任务引导方面有一定的性能，但快速而可靠的适应仍然是一个挑战。 |
| [^80] | [tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for Detecting Tweets Self-reporting a COVID-19 Diagnosis.](http://arxiv.org/abs/2311.00732) | 本文研究了用于检测自我报告COVID-19诊断推文的不同文本预处理技术，通过使用四个基于transformer的模型进行实验，并通过微调语言模型集成获得了比平均值高出4.1%的84.5%的F1得分。 |
| [^81] | [ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection.](http://arxiv.org/abs/2311.00729) | ZEETAD是一个零样本端到端时间动作检测模型，其中包括双定位和零样本提议分类两个模块。前者是基于Transformer的模块，用于检测动作事件并收集关键的语义嵌入，后者是基于CLIP的模块，用于生成文本和帧输入的语义嵌入。 |
| [^82] | [Investigating Relative Performance of Transfer and Meta Learning.](http://arxiv.org/abs/2311.00727) | 本文研究了迁移学习和元学习作为解决有限数据学习问题的两种方法的相对性能，以建立一个在不同的机器学习场景中选择最适合的方法的稳健标准。 |
| [^83] | [Fraud Analytics Using Machine-learning & Engineering on Big Data (FAME) for Telecom.](http://arxiv.org/abs/2311.00724) | 本文提出了一种工业化解决方案，利用自适应数据挖掘技术和大数据技术来准确、高效、低成本地检测电信行业的欺诈。已成功应用于检测国际收入分成欺诈，并发现了新的欺诈模式。 |
| [^84] | [AI Alignment in the Design of Interactive AI: Specification Alignment, Process Alignment, and Evaluation Support.](http://arxiv.org/abs/2311.00710) | 本文关注AI在界面设计和评估中的对齐问题，提出了规范对齐、过程对齐和评估支持等三个对齐目标，并介绍了代理过程和过程海湾的概念。 |
| [^85] | [Can AI Mitigate Human Perceptual Biases? A Pilot Study.](http://arxiv.org/abs/2311.00706) | 本研究试图调查机器推荐是否可以缓解人类感知偏差。通过一项实验，发现AI助手在集合任务中的使用可以提高参与者的工作效率，但并没有通过统计学分析证明AI助手可以显著降低“下拉”偏差。此外，延迟AI回应也没有对人类决策准确性产生显著影响。 |
| [^86] | [Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning.](http://arxiv.org/abs/2311.00651) | 通过分布式元强化学习在开放式任务分布上训练的智能体展现了强大的集体探索能力，从而产生了复杂的合作行为。 |
| [^87] | [Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value.](http://arxiv.org/abs/2311.00582) | 该论文研究了游戏修改问题，提出了一种最小修改马尔可夫博弈的方法，使得目标策略配置成为唯一的Nash均衡并具有特定价值范围，同时最小化修改成本。 |
| [^88] | [Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design.](http://arxiv.org/abs/2311.00462) | 本文提出了一种新的多细胞机器人粗细设计方法，利用双曲嵌入框架在共享的双曲空间内统一了各种粒度的机器人，并通过改进的交叉熵方法进行优化。这种方法能够自主地在双曲空间中确定探索的区域。 |
| [^89] | [A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents.](http://arxiv.org/abs/2311.00344) | 本文为开放式学习问题定义了一个关键的基本属性，即无限时间内不断产生新元素。在这基础上，提出了开放式学习问题的概念，并着重研究了开放式目标条件强化学习的子集。 |
| [^90] | [JADE: A Linguistic-based Safety Evaluation Platform for LLM.](http://arxiv.org/abs/2311.00286) | JADE是一种基于语言分析的LLM安全评估平台，能够破坏广泛使用的中文和英文LLM，并生成高度威胁的不安全问题。 |
| [^91] | [AutoMixer for Improved Multivariate Time-Series Forecasting on BizITOps Data.](http://arxiv.org/abs/2310.20280) | 这篇论文提出了AutoMixer，一个基于时间序列基础模型的自动混合模型，通过通道压缩预训练和微调工作流技术，有效解耦了BizITOps数据中有用和嘈杂的跨通道交互，提高了多变量时间序列预测的性能。 |
| [^92] | [Meaning Representations from Trajectories in Autoregressive Models.](http://arxiv.org/abs/2310.18348) | 本文提出了一种从自回归语言模型中提取意义表征的方法，通过考虑输入文本的所有可能轨迹的分布。这种方法可以模拟非对称关系，且在语义相似性任务上优于其他方法。 |
| [^93] | [Interactive Motion Planning for Autonomous Vehicles with Joint Optimization.](http://arxiv.org/abs/2310.18301) | 本论文介绍了一种交互式联合规划方法，将模型预测控制（MPC）与基于深度学习的轨迹预测模型结合，实现在高度交互的驾驶场景中为自主驾驶车辆规划安全的运动路径。 |
| [^94] | [Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering.](http://arxiv.org/abs/2310.17490) | 本研究提出了一种通过减少无关文档的干扰来改善开放领域问答中的零样本阅读器的方法。采用了干扰感知的答案选择(DAS)方法，以解决LLMs受到干扰和过度自信的问题。实验结果表明，该方法成功地改善了零样本阅读器的性能，并展现出了优越的可迁移性。 |
| [^95] | [Identifiability of total effects from abstractions of time series causal graphs.](http://arxiv.org/abs/2310.14691) | 本文研究了基于因果图抽象从观测时间序列中识别干预总效应的问题，并证明了在扩展摘要因果图中总效应总是可识别的。同时，我们提供了摘要因果图中总效应可识别的必要和充分的图形条件，并提供了调整集合以估计总效应。 |
| [^96] | [Getting aligned on representational alignment.](http://arxiv.org/abs/2310.13018) | 该论文研究了生物和人工信息处理系统的表示一致性，探讨了不同系统之间的表示是否一致以及如何调整表示以更好地匹配其他系统。为了改善领域之间的交流，提出了一个统一的框架作为共同语言。 |
| [^97] | [Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks.](http://arxiv.org/abs/2310.02230) | 本文提出了一种利用扩散分离表示来处理不完全规定的视觉任务中捷径学习问题的方法，通过生成合成反事实来促进模型的多样性，从而使模型能够忽略捷径线索并达到与其他方法相当的性能。 |
| [^98] | [Computer Vision Technology for Robotized Wire Harness Assembly.](http://arxiv.org/abs/2309.13745) | 该论文介绍了机器人化线束装配的计算机视觉技术，以提高装配质量并优化人体工程学和劳动成本。 |
| [^99] | [A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly.](http://arxiv.org/abs/2309.13744) | 该论文对计算机视觉在机器人化线束装配中的应用进行了系统的文献综述，总结出了挑战和未来研究机会。 |
| [^100] | [Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey.](http://arxiv.org/abs/2309.12177) | 可解释的人工智能在药物发现中的应用越来越受关注，为研究人员提供了对机器学习模型预测的更具解释性的理解，进一步促进了目标识别、化合物设计和毒性预测等方面的发展。 |
| [^101] | [Data Summarization beyond Monotonicity: Non-monotone Two-Stage Submodular Maximization.](http://arxiv.org/abs/2309.05183) | 这篇论文研究了两阶段子模最大化问题，目标是使用子模训练函数来减少底层集合，并引入了非单调子模函数的第一个恒定因子逼近算法。 |
| [^102] | [Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models.](http://arxiv.org/abs/2309.04316) | 本文提出了一个从自然互动中实现复杂行为增量学习的系统，并演示了在一个人形机器人上的应用。该系统利用大型语言模型对机器人的行为进行高级协调，通过交互式控制台生成Python语句来调用机器人的感知和动作，并通过将人类指令、环境观测和执行结果反馈给语言模型来实现循环交互。 |
| [^103] | [Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy.](http://arxiv.org/abs/2309.01267) | 本文提出了一种闭环安全学习的范式，用于合成机器人的安全控制策略。该方法考虑机器人学习能力和不确定性，能够快速应对未来场景，从而在确保安全的同时保持性能表现。 |
| [^104] | [Socratis: Are large multimodal models emotionally aware?.](http://arxiv.org/abs/2308.16741) | 这项研究提出了Socratis，一个新的社会反应基准，用于学习多模态内容的多样化情绪反应。根据人类研究结果，人们更喜欢人工撰写的情感原因，比机器生成的要多2倍以上。 |
| [^105] | [Expressive probabilistic sampling in recurrent neural networks.](http://arxiv.org/abs/2308.11809) | 该论文探索了循环神经电路如何从复杂概率分布中进行抽样，并证明了带有单独输出单元的神经电路的发放率动力学可以从任意概率分布中进行抽样。 |
| [^106] | [Dealing with Small Annotated Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models.](http://arxiv.org/abs/2308.06534) | 本研究评估了在医学影像领域使用自监督预训练方法的可行性，比较了共同对比学习和掩码自编码器方法在CT扫描卷积模型中的性能。 |
| [^107] | [Predict-AI-bility of how humans balance self-interest with the interest of others.](http://arxiv.org/abs/2307.12776) | 生成式AI能够准确预测人类在决策中平衡自身利益与他人利益的行为模式，但存在高估他人关注行为的倾向，这对AI的开发者和用户具有重要意义。 |
| [^108] | [Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery.](http://arxiv.org/abs/2307.10943) | 本文提出了一种基于代理锚点的无监督学习方法，用于在无标签数据集上发现新的类别，该方法通过微调特征提取器和代理锚点，将样本分为旧的和新的类别，并生成代表性的类别实例。 |
| [^109] | [VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models.](http://arxiv.org/abs/2307.05973) | VoxPoser提出了一种新方法，通过组合3D价值映射和语言模型，实现了机器人在多种操作任务下根据自由形式的指令和对象合成机器人轨迹的能力。 |
| [^110] | [Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning.](http://arxiv.org/abs/2307.03486) | 通过对比学习方法，我们在强化学习中提出了新的成就蒸馏方法，可以加强代理对下一个解锁成就的预测能力，并优于先前的模型驱动和层次化方法。 |
| [^111] | [EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models.](http://arxiv.org/abs/2307.02028) | 该论文介绍了EHRSHOT，一个用于少样本评估基础模型的电子健康记录基准。该论文利用EHRSHOT数据集和预训练模型CLMBR-T-base，为医疗保健ML的发展提供了解决方案。 |
| [^112] | [Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties.](http://arxiv.org/abs/2306.15668) | 该论文提出了一个新的数据集和基准测试——Physion++，用于评估在需要准确估计场景中物体潜在物理属性的情况下的视觉物理预测。 |
| [^113] | [Fedstellar: A Platform for Decentralized Federated Learning.](http://arxiv.org/abs/2306.09750) | Fedstellar是一个联邦学习平台，支持物理或虚拟设备的去中心化、半去中心化和中心化的方式训练模型，旨在解决现有平台在处理异构联盟网络拓扑等问题时的挑战。 |
| [^114] | [AVIS: Autonomous Visual Information Seeking with Large Language Models.](http://arxiv.org/abs/2306.08129) | 本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。 |
| [^115] | [Parting with Misconceptions about Learning-based Vehicle Motion Planning.](http://arxiv.org/abs/2306.07962) | 该论文提出了nuPlan，一个大规模真实世界数据集和评估方案，针对精确的短期规划和长期目标预测。证实了现有系统难以同时满足两个要求。最终提出一个非常简单高效的规划器。 |
| [^116] | [Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics.](http://arxiv.org/abs/2305.18333) | 研究了物品流行度、质量和位置偏差对用户福利的影响，提出了通过探索减轻流行度偏见负面影响的算法。 |
| [^117] | [Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning.](http://arxiv.org/abs/2305.14909) | 本论文提出了一种新的方法，利用预训练的大型语言模型构建显式的世界模型，并将其用于规划。通过将语言模型作为PDDL和纠正反馈源之间的接口，在用户不懂PDDL的情况下将PDDL转化为自然语言，并有效地编码纠正反馈。 |
| [^118] | [UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild.](http://arxiv.org/abs/2305.11147) | 本文提出了UniControl，一种新的生成基础模型，能够整合广泛的可控条件与图像任务，并仍然允许任意语言提示，UniControl能够进行像素级精确的图像生成，其中视觉条件主要影响生成的结构，语言提示则引导样式和上下文。我们提出了一种统一的扩散模型，它将扩散过程和变分自动编码器的优点结合起来，实验结果表明UniControl在可控性和图像质量方面均优于现有的最先进模型。 |
| [^119] | [Calibrated Explanations: with Uncertainty Information and Counterfactuals.](http://arxiv.org/abs/2305.02305) | 该论文提出了一种新的特征重要性解释方法，Calibrated Explanations (CE)，它可以提供准确、稳定的解释，并且可以为概率估计和特征重要性权重提供不确定性量化信息，是一种快速、可靠且强健的解释方法。 |
| [^120] | [How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.](http://arxiv.org/abs/2305.00586) | 本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。 |
| [^121] | [CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society.](http://arxiv.org/abs/2303.17760) | 本文介绍了一个名为角色扮演的新型交互式代理框架，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。 |
| [^122] | [Conformal Prediction for Time Series with Modern Hopfield Networks.](http://arxiv.org/abs/2303.12783) | 该论文提出了一种名为 HopCPT 的新一致性时间序列预测方法，不仅能够处理时间结构，而且能够利用其优势，已在多种真实世界的时间序列数据集上证明了优于现有方法的性能。 |
| [^123] | [Towards Safe Propofol Dosing during General Anesthesia Using Deep Offline Reinforcement Learning.](http://arxiv.org/abs/2303.10180) | 本文提出了一种基于真实临床数据集的数据驱动强化学习算法Policy Constraint Q-Learning(PCQL)来实现全麻药物剂量控制，添加了保守Q-Learning方法和策略约束项以确保智能体做出更安全的决策。 |
| [^124] | [Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain.](http://arxiv.org/abs/2301.08317) | 本研究通过使用卷积神经网络回归预测胎儿脑部超声平面的姿势，构建了一个超声平面定位系统，并对其准确性进行了分析和量化。结果表明，通过注册质量的改进和数据扩充，该系统可以实现更准确的结果。 |
| [^125] | [Inversion of Bayesian Networks.](http://arxiv.org/abs/2212.10649) | 本文研究了识别网络如何模拟真实后验分布的必要和充分条件，通过导出全局条件和局部条件，发现完美性为其具备期望性质起到了重要作用。 |
| [^126] | [Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting.](http://arxiv.org/abs/2211.15092) | 该论文提出了一种使用分层代理建模的技术H-Pro，通过利用时间序列数据的层次结构，通过测试代理驱动超参数优化，以解决测试验证期间不匹配的问题，并验证了该技术在时间序列数据集上的有效性。 |
| [^127] | [Computational Choreography using Human Motion Synthesis.](http://arxiv.org/abs/2210.04366) | 本文介绍了一种利用深度学习模型分析舞蹈动作和生成新动作序列的方法，同时也结合了前人的努力来开发出一套系统。 |
| [^128] | [Failed Goal Aware Hindsight Experience Replay.](http://arxiv.org/abs/2208.14741) | 本文提出了一种称为Failed goal Aware HER (FAHER)的新方法来增强多目标强化学习中的采样效率。该方法利用实现目标与未实现目标之间的关系，并通过聚类模型对序列进行聚类和采样。 |
| [^129] | [SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault Diagnosis in Chemical Processes.](http://arxiv.org/abs/2208.08879) | "SensorSCAN"是一种自我监督学习和深度聚类的方法，用于在化工过程中进行故障诊断。使用这种方法，在无需专家注释的情况下，可以有效检测大多数过程故障，并且通过在少量标记数据上微调，几乎达到了最优模型的性能水平。 |
| [^130] | [Combining optimal path search with task-dependent learning in a neural network.](http://arxiv.org/abs/2201.11104) | 这篇论文提出了一种在神经网络中结合最优路径搜索和任务相关学习的方法，通过将成本值转化为神经网络的权重来实现在线权重适应。实验结果表明，该方法与经典算法Bellman-Ford具有相同的解，并且网络学习机制可以进一步增强算法的性能。 |
| [^131] | [Entropy-based Discovery of Summary Causal Graphs in Time Series.](http://arxiv.org/abs/2105.10381) | 该研究提出了一种基于熵的方法，在时间序列中学习摘要因果图，并通过PC-like和FCI-like算法展示了其有效性和高效性。 |
| [^132] | [Model-free Policy Learning with Reward Gradients.](http://arxiv.org/abs/2103.05147) | 本研究开发了一种新颖的方法，无需学习模型即可集成奖赏梯度，提高了策略学习的样本效率。 |
| [^133] | [Positional Games and QBF: A Polished Encoding.](http://arxiv.org/abs/2005.05098) | 这项研究提出了一种将位置游戏编码为QBF的方法，通过结构特性和对非法移动的处理，生成更紧凑的实例，提高了求解速度。这些编码方法还可以应用于其他位置游戏，并可用于翻译实际问题。 |

# 详细

[^1]: 从视觉-语言基础模型中提取对抗性鲁棒性的框架

    Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models. (arXiv:2311.01441v1 [cs.LG])

    [http://arxiv.org/abs/2311.01441](http://arxiv.org/abs/2311.01441)

    本文提出了一个概念简单且轻量级的框架，通过结合知识蒸馏和数据增强的方法来提高视觉模型的鲁棒性，并从预训练的基础模型中获得鲁棒教师模型的知识。借助离散对抗蒸馏方法，我们生成更有信息量的对抗样本，取得了在对抗性样本上鲁棒性显著提升的结果。此外，我们提供了理论框架来支持在知识蒸馏和数据增强设置中使用鲁棒教师模型，并展示了在不同学生模型上的显著性能提升。我们的方法在计算负载方面的开销较小，并可以与其他数据增强方法轻松结合。

    

    我们提出了一个概念简单且轻量级的框架，通过知识蒸馏和数据增强的结合来提高视觉模型的鲁棒性。我们通过从预训练的基础模型中进行蒸馏，展示了在对抗性样本上获得的鲁棒性增益，以此反驳了更大的模型不一定会成为更好的教师的猜想。我们还提出了离散对抗蒸馏（Discrete Adversarial Distillation，DAD）方法，利用鲁棒的教师模型生成对抗样本，并通过VQGAN将其离散化，从而创造出比标准数据增强技术更有信息量的样本。我们提供了一个理论框架，用于在知识蒸馏和数据增强的设置中使用鲁棒的教师模型，并在不同的学生模型中展示了在对抗性样本上的鲁棒性和干净准确性的显著提升。值得注意的是，与类似技术相比，我们的方法增加了少量的计算负载，并且可以轻松与其他数据增强方法相结合。

    We propose a conceptually simple and lightweight framework for improving the robustness of vision models through the combination of knowledge distillation and data augmentation. We address the conjecture that larger models do not make for better teachers by showing strong gains in out-of-distribution robustness when distilling from pretrained foundation models. Following this finding, we propose Discrete Adversarial Distillation (DAD), which leverages a robust teacher to generate adversarial examples and a VQGAN to discretize them, creating more informative samples than standard data augmentation techniques. We provide a theoretical framework for the use of a robust teacher in the knowledge distillation with data augmentation setting and demonstrate strong gains in out-of-distribution robustness and clean accuracy across different student architectures. Notably, our method adds minor computational overhead compared to similar techniques and can be easily combined with other data augmen
    
[^2]: 通过核扭曲函数定制Mixup数据

    Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])

    [http://arxiv.org/abs/2311.01434](http://arxiv.org/abs/2311.01434)

    本研究提出了一种利用核扭曲函数对Mixup数据进行个性化处理的方法，通过动态改变插值系数的概率分布来实现更频繁和更强烈的混合相似数据点。实验证明这种方法不仅提高了模型性能，还提高了模型的校准性。

    

    数据增强是学习高效深度学习模型的重要基础。在所有提出的增强技术中，线性插值训练数据点（也称为Mixup）已被证明在许多应用中非常有效。然而，大多数研究都集中在选择合适的点进行混合，或者应用复杂的非线性插值，而我们则对更相似的点进行更频繁和更强烈的混合感兴趣。为此，我们提出了通过扭曲函数动态改变插值系数的概率分布的方法，取决于要组合的数据点之间的相似性。我们定义了一个高效而灵活的框架来实现这一点，以避免多样性的损失。我们进行了广泛的分类和回归任务实验，结果显示我们提出的方法既提高了模型的性能，又提高了模型的校准性。代码可在https://github.com/ENSTA-U2IS/torch-uncertainty上找到。

    Data augmentation is an essential building block for learning efficient deep learning models. Among all augmentation techniques proposed so far, linear interpolation of training data points, also called mixup, has found to be effective for a large panel of applications. While the majority of works have focused on selecting the right points to mix, or applying complex non-linear interpolation, we are interested in mixing similar points more frequently and strongly than less similar ones. To this end, we propose to dynamically change the underlying distribution of interpolation coefficients through warping functions, depending on the similarity between data points to combine. We define an efficient and flexible framework to do so without losing in diversity. We provide extensive experiments for classification and regression tasks, showing that our proposed method improves both performance and calibration of models. Code available in https://github.com/ENSTA-U2IS/torch-uncertainty
    
[^3]: 使用综合图注意力网络和强化学习分析以太坊网络中的信息传播，以优化网络效率和可扩展性

    Analysis of Information Propagation in Ethereum Network Using Combined Graph Attention Network and Reinforcement Learning to Optimize Network Efficiency and Scalability. (arXiv:2311.01406v1 [cs.LG])

    [http://arxiv.org/abs/2311.01406](http://arxiv.org/abs/2311.01406)

    本研究提出了一种使用图卷积网络和强化学习模型的创新方法，分析以太坊网络中的信息传播模式，并优化网络效率和可扩展性。最终目标是学习在不同网络状态下采取的最佳行动，提高网络效率和可扩展性。

    

    区块链技术在分布式网络中革新了信息传播的方式。以太坊在推动智能合约和分布式应用方面起到了关键作用。了解以太坊中的信息传播动态对于确保网络效率、安全性和可扩展性非常重要。在本研究中，我们提出了一种创新的方法，利用图卷积网络（GCNs）分析以太坊网络中的信息传播模式。我们的研究的第一阶段涉及从以太坊区块链中收集数据，包括区块、交易和节点度。我们使用邻接矩阵构建了一个交易图表示，以捕捉节点嵌入；而我们的主要贡献是开发了一个综合图注意力网络（GAT）和强化学习（RL）模型来优化网络效率和可扩展性。它学习在不同网络状态下采取的最佳行动，最终导致网络效率的提升。

    Blockchain technology has revolutionized the way information is propagated in decentralized networks. Ethereum plays a pivotal role in facilitating smart contracts and decentralized applications. Understanding information propagation dynamics in Ethereum is crucial for ensuring network efficiency, security, and scalability. In this study, we propose an innovative approach that utilizes Graph Convolutional Networks (GCNs) to analyze the information propagation patterns in the Ethereum network. The first phase of our research involves data collection from the Ethereum blockchain, consisting of blocks, transactions, and node degrees. We construct a transaction graph representation using adjacency matrices to capture the node embeddings; while our major contribution is to develop a combined Graph Attention Network (GAT) and Reinforcement Learning (RL) model to optimize the network efficiency and scalability. It learns the best actions to take in various network states, ultimately leading t
    
[^4]: Vision-Language Foundation Models作为有效的机器人模仿者

    Vision-Language Foundation Models as Effective Robot Imitators. (arXiv:2311.01378v1 [cs.RO])

    [http://arxiv.org/abs/2311.01378](http://arxiv.org/abs/2311.01378)

    该论文介绍了一种利用视觉语言基础模型进行机器人操作的方法，通过在语言条件的操作数据集上进行微调，实现了在低性能平台上的有效模仿控制。

    

    最近在视觉语言基础模型方面的进展显示出它们理解多模态数据和解决复杂的视觉语言任务（包括机器人操作）的能力。我们寻求一种简单的方式来利用现有的视觉语言模型（VLMs）在机器人数据上进行简单微调。为此，我们提出了一个简单而新颖的视觉语言操作框架，名为RoboFlamingo，它建立在开源的VLMs，OpenFlamingo之上。与以前的工作不同，RoboFlamingo利用预训练的VLMs进行单步视觉语言理解，使用显式策略头模拟顺序历史信息，并只在语言条件的操作数据集上进行微调。这种分解为RoboFlamingo提供了在低性能平台上进行开环控制和部署的灵活性。通过在测试基准上大幅超过现有技术水平，我们展示了RoboFlamingo可以成为一种有效的机器人模仿者。

    Recent progress in vision language foundation models has shown their ability to understand multimodal data and resolve complicated vision language tasks, including robotics manipulation. We seek a straightforward way of making use of existing vision-language models (VLMs) with simple fine-tuning on robotics data. To this end, we derive a simple and novel vision-language manipulation framework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo. Unlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step vision-language comprehension, models sequential history information with an explicit policy head, and is slightly fine-tuned by imitation learning only on language-conditioned manipulation datasets. Such a decomposition provides RoboFlamingo the flexibility for open-loop control and deployment on low-performance platforms. By exceeding the state-of-the-art performance with a large margin on the tested benchmark, we show RoboFlamingo can be an effective an
    
[^5]: 认证任何区域

    Recognize Any Regions. (arXiv:2311.01373v1 [cs.CV])

    [http://arxiv.org/abs/2311.01373](http://arxiv.org/abs/2311.01373)

    本文提出了一种名为RegionSpot的新型、通用且高效的区域识别架构，旨在解决在计算机视觉中理解无约束图像中区域的语义的挑战。

    

    理解无约束图像中各个区域或块的语义，例如在开放世界物体检测中，代表了一项关键而具有挑战性的计算机视觉任务。在基于强大的图像级视觉语言（ViL）基础模型如CLIP的成功基础上，最近的努力要么通过使用广泛的区域-标签对集合从头开始训练对比模型，要么将检测模型的输出与区域建议的图像级表示对齐，以发挥它们的能力。尽管取得了显著进展，但这些方法都受到计算密集型的训练需求、数据噪声的影响以及环境信息的不足等限制。为了解决这些问题，我们探索了现成的基础模型的协同潜力，利用它们在定位和语义方面的各自优势。我们引入了一种新颖的、通用的、高效的区域识别架构，称为RegionSpot。

    Understanding the semantics of individual regions or patches within unconstrained images, such as in open-world object detection, represents a critical yet challenging task in computer vision. Building on the success of powerful image-level vision-language (ViL) foundation models like CLIP, recent efforts have sought to harness their capabilities by either training a contrastive model from scratch with an extensive collection of region-label pairs or aligning the outputs of a detection model with image-level representations of region proposals. Despite notable progress, these approaches are plagued by computationally intensive training requirements, susceptibility to data noise, and deficiency in contextual information. To address these limitations, we explore the synergistic potential of off-the-shelf foundation models, leveraging their respective strengths in localization and semantics. We introduce a novel, generic, and efficient region recognition architecture, named RegionSpot, de
    
[^6]: 故障代理的认知逻辑的单纯模型

    Simplicial Models for the Epistemic Logic of Faulty Agents. (arXiv:2311.01351v1 [cs.LO])

    [http://arxiv.org/abs/2311.01351](http://arxiv.org/abs/2311.01351)

    本文研究了故障代理的认知逻辑，并提出了基于单纯模型的新模型，该模型允许世界中参与的代理数量可以变化。这对于容错分布式计算非常有用。

    

    近年来，一些作者一直在研究单纯模型，这是基于称为单纯复合体的高维结构的认知逻辑模型。在最初的形式中，单纯模型始终被假设为纯粹的，意味着所有世界具有相同的维度。这相当于基于克里普克模型的标准S5n语义的认知逻辑。通过移除模型必须是纯粹的假设，我们可以超越常规的克里普克语义，并研究参与一个世界的代理数量可以变化的认知逻辑。这种方法已在许多论文中得到应用，其中应用于容错分布式计算，其中在系统执行期间可能会发生过程崩溃。一个问题是，在定义不纯的单纯模型时，微妙的设计选择可能会导致所得到的逻辑的不同公理。在本文中，我们系统地对这些设计选择进行分类，并公理化相应的认知逻辑。

    In recent years, several authors have been investigating simplicial models, a model of epistemic logic based on higher-dimensional structures called simplicial complexes. In the original formulation, simplicial models were always assumed to be pure, meaning that all worlds have the same dimension. This is equivalent to the standard S5n semantics of epistemic logic, based on Kripke models. By removing the assumption that models must be pure, we can go beyond the usual Kripke semantics and study epistemic logics where the number of agents participating in a world can vary. This approach has been developed in a number of papers, with applications in fault-tolerant distributed computing where processes may crash during the execution of a system. A difficulty that arises is that subtle design choices in the definition of impure simplicial models can result in different axioms of the resulting logic. In this paper, we classify those design choices systematically, and axiomatize the correspon
    
[^7]: 用简单的功率分析在32位微控制器上阅读神经网络架构

    Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers. (arXiv:2311.01344v1 [cs.CR])

    [http://arxiv.org/abs/2311.01344](http://arxiv.org/abs/2311.01344)

    本文研究了如何通过简单的功率分析方法，在32位微控制器上提取深度神经网络模型的架构信息。

    

    模型提取是AI系统安全的一个不断增长的关注点。对于深度神经网络模型来说，架构是对手试图恢复的最重要的信息。作为一系列重复计算块，部署在边缘设备上的神经网络模型将产生独特的侧信道泄露。当目标平台在物理上可访问时，可以利用这些信道泄露来提取关键信息。通过结合对深度学习实践的理论知识和对广泛使用的实现库（ARM CMSIS-NN）的分析，我们的目的是回答这个关键问题：通过简单地检查一个EM侧信道跟踪，我们可以提取多远的架构信息？我们首次提出了一种用于传统MLP和CNN模型的提取方法，这些模型在高端32位微控制器（Cortex-M7）上运行，仅依赖于简单的模式识别分析。尽管存在几个具有挑战性的情况，但我们声称，与参数提取相反，我们可以通过这种方法从简单的功率分析中提取出架构信息。

    Model extraction is a growing concern for the security of AI systems. For deep neural network models, the architecture is the most important information an adversary aims to recover. Being a sequence of repeated computation blocks, neural network models deployed on edge-devices will generate distinctive side-channel leakages. The latter can be exploited to extract critical information when targeted platforms are physically accessible. By combining theoretical knowledge about deep learning practices and analysis of a widespread implementation library (ARM CMSIS-NN), our purpose is to answer this critical question: how far can we extract architecture information by simply examining an EM side-channel trace? For the first time, we propose an extraction methodology for traditional MLP and CNN models running on a high-end 32-bit microcontroller (Cortex-M7) that relies only on simple pattern recognition analysis. Despite few challenging cases, we claim that, contrary to parameters extraction
    
[^8]: 通过原始Wasserstein状态占用匹配实现的离线观察模仿

    Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching. (arXiv:2311.01331v1 [cs.LG])

    [http://arxiv.org/abs/2311.01331](http://arxiv.org/abs/2311.01331)

    本论文提出了一种通过最小化原始Wasserstein距离来匹配专家和学习者状态占用的方法，以解决离线学习从观察中模仿任务的问题。

    

    在现实世界的情境中，与环境的任意交互往往是昂贵的，并且专家示范的行为并不总是可用的。为了减少这两者的需求，离线学习从观察（LfO）得到了广泛研究，其中代理通过只有专家状态和与任务无关的非专家状态-动作对来学习解决任务。最先进的分布校正估计（DICE）方法最小化了学习者和专家策略之间的状态占用差异。然而，它们仅限于$f$-divergences（KL和$\chi^2$）或带有Rubinstein对偶的Wasserstein距离，后者限制了对性能关键的基础距离度量的使用。为了解决这个问题，我们提出了原始Wasserstein DICE（PW-DICE），它通过悲观正则化器最小化专家和学习者状态占用之间的原始Wasserstein距离，并利用了对比学习的dis

    In real-world scenarios, arbitrary interactions with the environment can often be costly, and actions of expert demonstrations are not always available. To reduce the need for both, Offline Learning from Observations (LfO) is extensively studied, where the agent learns to solve a task with only expert states and \textit{task-agnostic} non-expert state-action pairs. The state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the state occupancy divergence between the learner and expert policies. However, they are limited to either $f$-divergences (KL and $\chi^2$) or Wasserstein distance with Rubinstein duality, the latter of which constrains the underlying distance metric crucial to the performance of Wasserstein-based solutions. To address this problem, we propose Primal Wasserstein DICE (PW-DICE), which minimizes the primal Wasserstein distance between the expert and learner state occupancies with a pessimistic regularizer and leverages a contrastively learned dis
    
[^9]: 更好地在生成式知识图谱完善中使用语言模型和邻居信息

    Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information. (arXiv:2311.01326v1 [cs.CL])

    [http://arxiv.org/abs/2311.01326](http://arxiv.org/abs/2311.01326)

    本研究提出了将节点邻居作为额外信息加入语言模型，以改进知识图谱完善方法。在归纳和传递式Wikidata子集上，我们的方法优于传统方法和基于语言模型的KGC方法。邻居信息对模型预测具有重要影响。

    

    实际应用中的知识图谱经常存在不完整问题，限制了其潜在性能。知识图谱完善（KGC）技术旨在解决这个问题。然而，传统的KGC方法在大规模知识图谱上计算复杂度高，不实际，需要学习密集的节点嵌入和计算成对距离。生成式转换器语言模型（如T5和最近的KGT5）提供了一种有希望的解决方案，因为它们可以直接预测尾节点。在本研究中，我们提出了在语言模型基础上包含节点邻居作为额外信息来改进KGC方法。我们检验了这种补全的效果，并展示了在归纳和传递式Wikidata子集上，我们的方法优于KGT5和传统的KGC方法。我们还对邻居对模型预测的影响进行了广泛分析，并展示了其重要性。此外，我们指出了通过更高效的方法显著改善KGC的路径。

    Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which limits their potential performance. Knowledge Graph Completion (KGC) techniques aim to address this issue. However, traditional KGC methods are computationally intensive and impractical for large-scale KGs, necessitating the learning of dense node embeddings and computing pairwise distances. Generative transformer-based language models (e.g., T5 and recent KGT5) offer a promising solution as they can predict the tail nodes directly. In this study, we propose to include node neighborhoods as additional information to improve KGC methods based on language models. We examine the effects of this imputation and show that, on both inductive and transductive Wikidata subsets, our method outperforms KGT5 and conventional KGC approaches. We also provide an extensive analysis of the impact of neighborhood on model prediction and show its importance. Furthermore, we point the way to significantly improve KGC through more ef
    
[^10]: 散射视觉变换：光谱混合的重要性

    Scattering Vision Transformer: Spectral Mixing Matters. (arXiv:2311.01310v1 [cs.CV])

    [http://arxiv.org/abs/2311.01310](http://arxiv.org/abs/2311.01310)

    本文提出了一种名为散射视觉变换（SVT）的新方法，通过光谱混合来解决视觉变换中的注意力复杂性和信息捕捉问题。

    

    视觉变换器在各种计算机视觉任务中，包括图像分类、实例分割和目标检测中获得了显著的关注，并取得了最先进的性能。然而，解决注意力复杂性和有效捕捉图像中细粒度信息仍然存在挑战。现有的解决方案通常采用降采样操作（如池化）来减少计算成本。然而，这种操作是不可逆的，可能导致信息丢失。在本文中，我们提出了一种称为散射视觉变换（SVT）的新方法来解决这些挑战。SVT结合了一个光谱散射网络，实现了对复杂图像细节的捕捉。SVT通过分离低频和高频分量，克服了与降采样操作相关的不可逆问题。此外，SVT引入了一个独特的光谱门控网络，利用Einstein乘法来处理令牌和通道。

    Vision transformers have gained significant attention and achieved state-of-the-art performance in various computer vision tasks, including image classification, instance segmentation, and object detection. However, challenges remain in addressing attention complexity and effectively capturing fine-grained information within images. Existing solutions often resort to down-sampling operations, such as pooling, to reduce computational cost. Unfortunately, such operations are non-invertible and can result in information loss. In this paper, we present a novel approach called Scattering Vision Transformer (SVT) to tackle these challenges. SVT incorporates a spectrally scattering network that enables the capture of intricate image details. SVT overcomes the invertibility issue associated with down-sampling operations by separating low-frequency and high-frequency components. Furthermore, SVT introduces a unique spectral gating network utilizing Einstein multiplication for token and channel 
    
[^11]: AWEQ：用于大型语言模型的后训练量化和激活权重均衡方法

    AWEQ: Post-Training Quantization with Activation-Weight Equalization for Large Language Models. (arXiv:2311.01305v1 [cs.LG])

    [http://arxiv.org/abs/2311.01305](http://arxiv.org/abs/2311.01305)

    AWEQ是一种后训练量化和激活权重均衡方法，能够在大型语言模型中实现超低位量化和8-bit权重和激活量化，并通过改进的均衡方法减小量化偏差误差，提高模型的鲁棒性。

    

    大型语言模型(LLMs)在各种任务中表现出色，但其计算和存储成本也相对较高。量化这些模型是缓解这个问题的有效方法。然而，现有方法很难在模型准确性和硬件效率之间取得平衡。因此，我们引入了AWEQ，一种后训练方法，不需要额外的训练开销。AWEQ在超低位量化和8-bit权重和激活(W8A8)量化方面表现出色。观察到权重量化比激活量化更容易。AWEQ通过通道均衡将激活量化的难度转移到权重上，实现了两者量化困难的平衡，从而最大化了性能。我们进一步改进了均衡方法，减小了量化偏差误差，确保模型的鲁棒性。在像LLaMA这样的流行模型上进行了大量实验。

    Large language models(LLMs) exhibit excellent performance across a variety of tasks, but they come with significant computational and storage costs. Quantizing these models is an effective way to alleviate this issue. However, existing methods struggle to strike a balance between model accuracy and hardware efficiency. This is where we introduce AWEQ, a post-training method that requires no additional training overhead. AWEQ excels in both ultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization. There is an observation that weight quantization is less challenging than activation quantization. AWEQ transfers the difficulty of activation quantization to weights using channel equalization, achieving a balance between the quantization difficulties of both, and thereby maximizing performance. We have further refined the equalization method to mitigate quantization bias error, ensuring the robustness of the model. Extensive experiments on popular models such as LLaMA a
    
[^12]: TRIALSCOPE：一个统一的因果框架，用于利用生物医学语言模型扩展实际世界证据生成

    TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence Generation with Biomedical Language Models. (arXiv:2311.01301v1 [cs.LG])

    [http://arxiv.org/abs/2311.01301](http://arxiv.org/abs/2311.01301)

    TRIALSCOPE是一个统一的框架，利用生物医学语言模型将临床文本进行结构化，采用概率建模进行去噪和插补，并应用因果推断技术来应对混杂因素，以从实际世界数据中提取实证证据和推理临床假设。

    

    实际世界数据的快速数字化为优化医疗服务和加速生物医学发现提供了前所未有的机会。然而，在实践中，这些数据往往以非结构化形式存在，如电子医疗记录中的临床笔记，并且通常受到混杂因素的困扰。本文介绍了TRIALSCOPE，一个用于从人群级观察数据中提取实际世界证据的统一框架。TRIALSCOPE利用生物医学语言模型来扩展规模化的临床文本，采用先进的概率建模进行去噪和插补，并结合最先进的因果推断技术来应对常见的混杂因素。利用临床试验规范作为通用表示形式，TRIALSCOPE提供了一个一键式解决方案，可使用观察数据生成和推理临床假设。在一个包含超过一百万个癌症患者的大规模实际世界数据集上进行了广泛的实验和分析。

    The rapid digitization of real-world data offers an unprecedented opportunity for optimizing healthcare delivery and accelerating biomedical discovery. In practice, however, such data is most abundantly available in unstructured forms, such as clinical notes in electronic medical records (EMRs), and it is generally plagued by confounders. In this paper, we present TRIALSCOPE, a unifying framework for distilling real-world evidence from population-level observational data. TRIALSCOPE leverages biomedical language models to structure clinical text at scale, employs advanced probabilistic modeling for denoising and imputation, and incorporates state-of-the-art causal inference techniques to combat common confounders. Using clinical trial specification as generic representation, TRIALSCOPE provides a turn-key solution to generate and reason with clinical hypotheses using observational data. In extensive experiments and analyses on a large-scale real-world dataset with over one million canc
    
[^13]: UniFolding: 实现高效样本利用率、可扩展性和泛化性的机器人服装折叠系统

    UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding. (arXiv:2311.01267v1 [cs.RO])

    [http://arxiv.org/abs/2311.01267](http://arxiv.org/abs/2311.01267)

    这项研究提出了UniFolding，一种高效利用样本的机器人系统，用于展开和折叠各种服装。通过整合展开和折叠决策，以及利用部分点云数据，UniFolding具有较强的泛化能力和对纹理和形状变化的鲁棒性。

    

    本文探讨了UniFolding的开发，它是一种高效利用样本、可扩展和具有泛化能力的机器人系统，用于展开和折叠各种服装。UniFolding利用所提出的UFONet神经网络将展开和折叠决策整合到一个单一策略模型中，该模型可适应不同类型和状态的服装。UniFolding的设计基于服装的部分点云，这有助于泛化并降低对纹理和形状变化的敏感性。训练流程优先考虑低成本、高效样本收集。通过基于人的过程进行离线和在线阶段的数据收集。离线阶段通过虚拟现实进行人类的展开和折叠操作，而在线阶段则利用人机协同学习在真实环境中对模型进行微调。该系统在两种服装类型：长袖和短袖衬衫上进行了测试。性能评估基于20件具有显著变化的衬衫。

    This paper explores the development of UniFolding, a sample-efficient, scalable, and generalizable robotic system for unfolding and folding various garments. UniFolding employs the proposed UFONet neural network to integrate unfolding and folding decisions into a single policy model that is adaptable to different garment types and states. The design of UniFolding is based on a garment's partial point cloud, which aids in generalization and reduces sensitivity to variations in texture and shape. The training pipeline prioritizes low-cost, sample-efficient data collection. Training data is collected via a human-centric process with offline and online stages. The offline stage involves human unfolding and folding actions via Virtual Reality, while the online stage utilizes human-in-the-loop learning to fine-tune the model in a real-world setting. The system is tested on two garment types: long-sleeve and short-sleeve shirts. Performance is evaluated on 20 shirts with significant variation
    
[^14]: 使用少量人工标注的自然语言提示驱动的表达性文本到语音技术

    Expressive TTS Driven by Natural Language Prompts Using Few Human Annotations. (arXiv:2311.01260v1 [eess.AS])

    [http://arxiv.org/abs/2311.01260](http://arxiv.org/abs/2311.01260)

    本文提出了一种使用少量人工标注的自然语言提示驱动的表达性文本到语音技术，通过利用大型语言模型将表达性文本到语音转变为样式检索任务，使得合成演讲具有预期样式。

    

    表达性文本到语音（TTS）旨在合成具有人类般的语调、情绪甚至艺术属性的演讲。最近在表达性TTS方面的进展使用户能够通过自然语言提示直接控制合成风格。然而，这些方法通常需要大量带有标注样式的数据进行训练，这可能难以获取。此外，由于固定的样式标注，它们的适应能力可能有限。在这项工作中，我们提出了FreeStyleTTS（FS-TTS），一种具有最小人工标注的可控表达性TTS模型。我们的方法利用大型语言模型（LLM）将表达性TTS转变为样式检索任务。LLM根据外部样式提示从已注释的语句中选择最佳匹配的样式参考，这些样式提示可以是原始输入文本或自然语言样式描述。所选的参考指导TTS管道以合成具有预期样式的演讲。这种创新的方法引进了少量人工标注来驱动表达性TTS。

    Expressive text-to-speech (TTS) aims to synthesize speeches with human-like tones, moods, or even artistic attributes. Recent advancements in expressive TTS empower users with the ability to directly control synthesis style through natural language prompts. However, these methods often require excessive training with a significant amount of style-annotated data, which can be challenging to acquire. Moreover, they may have limited adaptability due to fixed style annotations. In this work, we present FreeStyleTTS (FS-TTS), a controllable expressive TTS model with minimal human annotations. Our approach utilizes a large language model (LLM) to transform expressive TTS into a style retrieval task. The LLM selects the best-matching style references from annotated utterances based on external style prompts, which can be raw input text or natural language style descriptions. The selected reference guides the TTS pipeline to synthesize speeches with the intended style. This innovative approach
    
[^15]: 自主系统的形式化方法

    Formal Methods for Autonomous Systems. (arXiv:2311.01258v1 [cs.AI])

    [http://arxiv.org/abs/2311.01258](http://arxiv.org/abs/2311.01258)

    本论文综述了在自主系统领域中应用形式化方法的最新研究，并讨论了构造正确性合成、不确定性处理和系统监测等方面的内容。

    

    形式化方法指的是系统开发中严谨的、数学方法，对于确立安全关键系统的正确性起着关键作用。形式化方法的主要构建模块是模型和规范，类似于系统设计中的行为和需求，它们给我们提供了验证和合成系统行为的手段和形式化保证。本专著对自主系统领域中形式化方法应用的最新研究进行了综述。我们考虑在不同的形式化条件下进行构造正确性合成，包括封闭系统、反应式系统和概率设置等。除了在已知环境中合成系统外，我们还通过形式化方法处理了不确定性的概念，并对采用学习的系统行为进行了限制。此外，我们还研究了与监测相关的系统合成，这是一种保证系统在偏离预期行为后仍能找到一种方式的缓解技术。

    Formal methods refer to rigorous, mathematical approaches to system development and have played a key role in establishing the correctness of safety-critical systems. The main building blocks of formal methods are models and specifications, which are analogous to behaviors and requirements in system design and give us the means to verify and synthesize system behaviors with formal guarantees.  This monograph provides a survey of the current state of the art on applications of formal methods in the autonomous systems domain. We consider correct-by-construction synthesis under various formulations, including closed systems, reactive, and probabilistic settings. Beyond synthesizing systems in known environments, we address the concept of uncertainty and bound the behavior of systems that employ learning using formal methods. Further, we examine the synthesis of systems with monitoring, a mitigation technique for ensuring that once a system deviates from expected behavior, it knows a way o
    
[^16]: 基于能源的法律领域文本分类常见方法的比较分析

    An energy-based comparative analysis of common approaches to text classification in the Legal domain. (arXiv:2311.01256v1 [cs.CL])

    [http://arxiv.org/abs/2311.01256](http://arxiv.org/abs/2311.01256)

    本研究通过在法律领域的文本分类任务上进行比较分析，综合考虑性能和能源消耗等指标，探讨了大型语言模型与传统方法的优劣，并强调了在性能相近的情况下应重视生产成本、能源消耗和碳足迹等方面的考量。

    

    大部分机器学习研究评估最佳解决方案的性能。然而，在追求最佳性能的竞争中，经常忽视许多重要因素，而事实上，这些因素应该被仔细考虑。实际上，有时不同方法之间的性能差距可以忽略不计，而生产成本、能源消耗和碳足迹等因素必须考虑在内。大型语言模型（LLMs）被广泛应用于学术界和工业界的NLP问题。在这项工作中，我们在LexGLUE基准上对LLM和传统方法（例如SVM）进行了详细的定量比较，同时考虑性能（标准指标）和其他指标，如时间、耗能和成本，总之就是碳足迹。在我们的分析中，我们分别考虑了原型设计阶段（通过训练-验证-测试迭代进行模型选择）和生产阶段。

    Most Machine Learning research evaluates the best solutions in terms of performance. However, in the race for the best performing model, many important aspects are often overlooked when, on the contrary, they should be carefully considered. In fact, sometimes the gaps in performance between different approaches are neglectable, whereas factors such as production costs, energy consumption, and carbon footprint must take into consideration. Large Language Models (LLMs) are extensively adopted to address NLP problems in academia and industry. In this work, we present a detailed quantitative comparison of LLM and traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes into account both performance (standard indices) and alternative metrics such as timing, power consumption and cost, in a word: the carbon-footprint. In our analysis, we considered the prototyping phase (model selection by training-validation-test iterations) and in-production phases separately, since they fol
    
[^17]: 将其推向展示极限：多模态视觉触觉模仿学习与力匹配

    Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching. (arXiv:2311.01248v1 [cs.RO])

    [http://arxiv.org/abs/2311.01248](http://arxiv.org/abs/2311.01248)

    本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。

    

    光学触觉传感器已经成为机器人操作过程中获取密集接触信息的有效手段。最近引入的“透视你的皮肤”（STS）型传感器具有视觉和触觉模式，通过利用半透明表面和可控照明实现。本文研究了视觉触觉传感与模仿学习在富有接触的操作任务中的好处。首先，我们使用触觉力测量和一种新的算法，在运动示范中产生更好匹配人体示范者的力曲线。其次，我们添加了视觉/触觉STS模式切换作为控制策略输出，简化传感器的应用。最后，我们研究了多种观察配置，比较和对比了视觉/触觉数据（包括模式切换和不切换）与手腕挂载的眼在手摄像机的视觉数据的价值。我们在一个广泛的实验系列上进行实验。

    Optical tactile sensors have emerged as an effective means to acquire dense contact information during robotic manipulation. A recently-introduced `see-through-your-skin' (STS) variant of this type of sensor has both visual and tactile modes, enabled by leveraging a semi-transparent surface and controllable lighting. In this work, we investigate the benefits of pairing visuotactile sensing with imitation learning for contact-rich manipulation tasks. First, we use tactile force measurements and a novel algorithm during kinesthetic teaching to yield a force profile that better matches that of the human demonstrator. Second, we add visual/tactile STS mode switching as a control policy output, simplifying the application of the sensor. Finally, we study multiple observation configurations to compare and contrast the value of visual/tactile data (both with and without mode switching) with visual data from a wrist-mounted eye-in-hand camera. We perform an extensive series of experiments on a
    
[^18]: FacadeNet: 通过选择性编辑进行条件立面综合的深度学习方法

    FacadeNet: Conditional Facade Synthesis via Selective Editing. (arXiv:2311.01240v1 [cs.CV])

    [http://arxiv.org/abs/2311.01240](http://arxiv.org/abs/2311.01240)

    FacadeNet是一种深度学习方法，通过条件生成对抗网络实现了从不同视角合成建筑立面图像，并通过引入选择性编辑模块，实现了对视角相关元素进行精确修改。实验结果表明，该方法在建筑立面生成方面具有领先的性能。

    

    我们介绍了FacadeNet，一种基于深度学习的方法，可以从不同的视角合成建筑立面图像。我们的方法使用条件生成对抗网络，将一个立面的单一视图和所需的视角信息作为输入，生成一个从不同视角看到的立面图像。为了精确修改与视角相关的元素（如窗户和门），同时保留与视角无关的结构（如墙壁），我们引入了选择性编辑模块。该模块利用从预训练的视觉转换器中提取的图像嵌入。我们的实验表明，在建筑立面生成方面，我们的方法表现出了最先进的性能，超过了其他方法。

    We introduce FacadeNet, a deep learning approach for synthesizing building facade images from diverse viewpoints. Our method employs a conditional GAN, taking a single view of a facade along with the desired viewpoint information and generates an image of the facade from the distinct viewpoint. To precisely modify view-dependent elements like windows and doors while preserving the structure of view-independent components such as walls, we introduce a selective editing module. This module leverages image embeddings extracted from a pre-trained vision transformer. Our experiments demonstrated state-of-the-art performance on building facade generation, surpassing alternative methods.
    
[^19]: 使用AI副驾驶员导航复杂搜索任务

    Navigating Complex Search Tasks with AI Copilots. (arXiv:2311.01235v1 [cs.IR])

    [http://arxiv.org/abs/2311.01235](http://arxiv.org/abs/2311.01235)

    该论文介绍了使用AI副驾驶员来导航复杂搜索任务，并探讨了生成AI和辅助代理的出现对于支持复杂搜索任务的潜力和重要性。

    

    正如信息检索(IR)研究界的许多人所知和欣赏的那样，搜索远未解决。每天都有数百万人在搜索引擎上面对任务的困难。他们的困难通常与任务的内在复杂性以及搜索系统无法完全理解任务和提供相关结果有关。任务激发了搜索，创建了搜索者尝试连接/解决的差距/问题情况，并在他们处理不同任务方面时驱动搜索行为。复杂搜索任务需要的不仅是基本事实查找或搜索的支持。支持复杂任务的方法研究包括生成查询和网站建议，个性化和上下文化搜索，以及开发新的搜索体验，包括跨时间和空间。最近兴起的生成人工智能(AI)和基于该技术的辅助代理，或者说副驾驶员，的出现。

    As many of us in the information retrieval (IR) research community know and appreciate, search is far from being a solved problem. Millions of people struggle with tasks on search engines every day. Often, their struggles relate to the intrinsic complexity of their task and the failure of search systems to fully understand the task and serve relevant results. The task motivates the search, creating the gap/problematic situation that searchers attempt to bridge/resolve and drives search behavior as they work through different task facets. Complex search tasks require more than support for rudimentary fact finding or re-finding. Research on methods to support complex tasks includes work on generating query and website suggestions, personalizing and contextualizing search, and developing new search experiences, including those that span time and space. The recent emergence of generative artificial intelligence (AI) and the arrival of assistive agents, or copilots, based on this technology
    
[^20]: 长话短说：用于长视频问答的总结后搜索方法

    Long Story Short: a Summarize-then-Search Method for Long Video Question Answering. (arXiv:2311.01233v1 [cs.CV])

    [http://arxiv.org/abs/2311.01233](http://arxiv.org/abs/2311.01233)

    本论文研究了大型语言模型是否能够在长篇多模态叙述的多媒体内容中扩展它们的零样本推理能力。作者提出了“长话短说”框架，该框架通过将视频的叙述总结成简短情节，并搜索与问题相关的视频部分，来进行叙述性视频问答。实验证明，该模型在长视频问答任务中的性能显著优于最先进的监督模型，展示了零样本问答在长视频中的潜力。

    

    大型语言模型（如GPT-3）展示了令人印象深刻的能力，即在不需要特定任务的训练数据的情况下适应新任务。这种能力在叙述式问题回答等场景中特别有效，这些场景中任务的多样性很大，但可用的监督数据很少。在这项工作中，我们探讨了这种语言模型是否可以将其零样本推理能力扩展到包含剧情、电影和动画等多媒体内容的长篇多模态叙述中，其中故事起着重要作用。我们提出了“长话短说”框架，用于叙述性视频问答，该框架首先将视频的叙述总结成一个简短的情节，然后搜索与问题相关的视频部分。我们还提出了CLIPCheck来增强视觉匹配。我们的模型大幅超过了最先进的监督模型，突显了零样本问答在长视频中的潜力。

    Large language models such as GPT-3 have demonstrated an impressive capability to adapt to new tasks without requiring task-specific training data. This capability has been particularly effective in settings such as narrative question answering, where the diversity of tasks is immense, but the available supervision data is small. In this work, we investigate if such language models can extend their zero-shot reasoning abilities to long multimodal narratives in multimedia content such as drama, movies, and animation, where the story plays an essential role. We propose Long Story Short, a framework for narrative video QA that first summarizes the narrative of the video to a short plot and then searches parts of the video relevant to the question. We also propose to enhance visual matching with CLIPCheck. Our model outperforms state-of-the-art supervised models by a large margin, highlighting the potential of zero-shot QA for long videos.
    
[^21]: 潜在空间中的多个数学运算推导

    Multi-Operational Mathematical Derivations in Latent Space. (arXiv:2311.01230v1 [cs.LG])

    [http://arxiv.org/abs/2311.01230](http://arxiv.org/abs/2311.01230)

    本文研究在潜在空间中逼近多个数学运算进行表达式推导的可能性，并通过构建大规模数据集和使用最先进的神经编码器实例化，探索了不同编码机制在潜在空间中逼近方程推理的能力。

    

    本文研究在潜在空间中逼近多个数学运算进行表达式推导的可能性。为此，我们引入了不同的多操作表示范式，将数学运算建模为显式的几何变换。通过利用符号引擎，我们构建了一个包含61K个前提和6个运算符的大规模数据集，分析了每个范式在与最先进的神经编码器实例化时的性质。具体而言，我们研究了不同的编码机制在潜在空间中如何逼近方程推理，并探讨了学习不同运算符和在单个运算中专门化之间的权衡，以及支持多步推导和超越分布广义化的能力。我们的实证分析表明，多操作范式对于解开不同运算符是至关重要的，同时可以区分结论。

    This paper investigates the possibility of approximating multiple mathematical operations in latent space for expression derivation. To this end, we introduce different multi-operational representation paradigms, modelling mathematical operations as explicit geometric transformations. By leveraging a symbolic engine, we construct a large-scale dataset comprising 1.7M derivation steps stemming from 61K premises and 6 operators, analysing the properties of each paradigm when instantiated with state-of-the-art neural encoders. Specifically, we investigate how different encoding mechanisms can approximate equational reasoning in latent space, exploring the trade-off between learning different operators and specialising within single operations, as well as the ability to support multi-step derivations and out-of-distribution generalisation. Our empirical analysis reveals that the multi-operational paradigm is crucial for disentangling different operators, while discriminating the conclusion
    
[^22]: 强化学习的扩散模型: 一份综述

    Diffusion Models for Reinforcement Learning: A Survey. (arXiv:2311.01223v1 [cs.LG])

    [http://arxiv.org/abs/2311.01223](http://arxiv.org/abs/2311.01223)

    强化学习中的扩散模型已经成为一种突出的生成模型，通过在样本质量和训练稳定性方面的优势改进了强化学习解决方案。该综述提供了这一新兴领域发展的概述，并探讨了扩散模型在强化学习中的分类法和应用。

    

    扩散模型作为一种突出的生成模型类别已经出现，超越了以往方法在样本质量和训练稳定性方面的优势。最近的研究表明，扩散模型在改进强化学习（RL）解决方案方面具有优势，包括作为轨迹规划器、表达能力丰富的策略类别、数据合成器等。本综述旨在提供该新兴领域发展的概述，并希望能启发新的研究方向。首先，我们审查了当前RL算法遇到的一些挑战。然后，我们根据扩散模型在RL中所扮演的角色，提出了现有方法的分类法，并探讨了如何解决现有挑战。我们进一步概述了扩散模型在各种与RL相关任务中的成功应用，并讨论了当前方法的局限性。最后，我们总结了这项综述，并提出了对未来研究方向的见解，重点是提高模型性能和应用扩散模型的方法。

    Diffusion models have emerged as a prominent class of generative models, surpassing previous methods regarding sample quality and training stability. Recent works have shown the advantages of diffusion models in improving reinforcement learning (RL) solutions, including as trajectory planners, expressive policy classes, data synthesizers, etc. This survey aims to provide an overview of the advancements in this emerging field and hopes to inspire new avenues of research. First, we examine several challenges encountered by current RL algorithms. Then, we present a taxonomy of existing methods based on the roles played by diffusion models in RL and explore how the existing challenges are addressed. We further outline successful applications of diffusion models in various RL-related tasks while discussing the limitations of current approaches. Finally, we conclude the survey and offer insights into future research directions, focusing on enhancing model performance and applying diffusion m
    
[^23]: 多视角关系学习用于跨领域少样本高光谱图像分类

    Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral Image Classification. (arXiv:2311.01212v1 [cs.CV])

    [http://arxiv.org/abs/2311.01212](http://arxiv.org/abs/2311.01212)

    本文提出了一种在跨领域少样本高光谱图像分类中学习样本关系的方法，通过从不同视角对样本进行学习，并利用对抗性学习来改进分类性能。

    

    跨领域少样本高光谱图像分类侧重于从源领域中大量标记样本中学习先前的知识，然后将这些知识转移到目标领域中仅包含少量标记样本的任务中。在度量方法的基础上，许多当前的方法首先提取查询样本和支持样本的特征，然后根据查询样本到支持样本或原型的距离直接预测查询样本的类别。样本之间的关系尚未得到充分的探索和利用。与当前的方法不同，本文提出了从不同视角学习样本关系并将其纳入模型学习过程中，以提高跨领域少样本高光谱图像分类的性能。在当前DCFSL方法的基础上，该方法采用对抗性学习来学习类别级别的样本关系。

    Cross-domain few-shot hyperspectral image classification focuses on learning prior knowledge from a large number of labeled samples from source domain and then transferring the knowledge to the tasks which contain only few labeled samples in target domains. Following the metric-based manner, many current methods first extract the features of the query and support samples, and then directly predict the classes of query samples according to their distance to the support samples or prototypes. The relations between samples have not been fully explored and utilized. Different from current works, this paper proposes to learn sample relations from different views and take them into the model learning process, to improve the cross-domain few-shot hyperspectral image classification. Building on current DCFSL method which adopts a domain discriminator to deal with domain-level distribution difference, the proposed method applys contrastive learning to learn the class-level sample relations to o
    
[^24]: 使用位反转攻击图神经网络：Weisfeiler和Lehman变得冷漠了

    Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent. (arXiv:2311.01205v1 [cs.LG])

    [http://arxiv.org/abs/2311.01205](http://arxiv.org/abs/2311.01205)

    我们设计了Injectivity Bit Flip Attack来针对图神经网络，成功地降低了其对图结构的识别能力和表达能力，从而增加了其对位反转攻击的易受攻击性。

    

    先前对图神经网络的攻击主要集中在图毒化和规避上，忽略了网络的权重和偏置。传统的基于权重的故障注入攻击，如用于卷积神经网络的位反转攻击，没有考虑到图神经网络的独特属性。我们提出了注入率位反转攻击（Injectivity Bit Flip Attack），这是第一个专门针对图神经网络设计的位反转攻击。我们的攻击针对量化消息传递神经网络中的可学习邻域聚合函数，降低了其区分图结构的能力，失去了Weisfeiler-Lehman测试的表达能力。我们的发现表明，利用特定于某些图神经网络架构的数学属性可能会显著增加其对位反转攻击的易受攻击性。注入率位反转攻击可以将各种图属性预测数据集上训练的最大表达性同构网络降级为随机输出。

    Prior attacks on graph neural networks have mostly focused on graph poisoning and evasion, neglecting the network's weights and biases. Traditional weight-based fault injection attacks, such as bit flip attacks used for convolutional neural networks, do not consider the unique properties of graph neural networks. We propose the Injectivity Bit Flip Attack, the first bit flip attack designed specifically for graph neural networks. Our attack targets the learnable neighborhood aggregation functions in quantized message passing neural networks, degrading their ability to distinguish graph structures and losing the expressivity of the Weisfeiler-Lehman test. Our findings suggest that exploiting mathematical properties specific to certain graph neural network architectures can significantly increase their vulnerability to bit flip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive Graph Isomorphism Networks trained on various graph property prediction datasets to rando
    
[^25]: 使用对比学习的跨模态信息引导网络进行点云配准

    Cross-Modal Information-Guided Network using Contrastive Learning for Point Cloud Registration. (arXiv:2311.01202v1 [cs.CV])

    [http://arxiv.org/abs/2311.01202](http://arxiv.org/abs/2311.01202)

    这篇论文提出了一种使用对比学习的跨模态信息引导网络，通过利用从2D图像中学到的视觉信息来实现精确且鲁棒的点云配准。

    

    目前大多数点云配准方法依赖于从点中提取特征。然而，这些方法受限于仅从单一模态的点获取的信息，可能导致全局特征感知不足和缺乏纹理信息等问题。实际上，人类可以利用从2D图像中学到的视觉信息来理解3D世界。基于这一事实，我们提出了一种新颖的跨模态信息引导网络（CMIGNet），通过跨模态信息获得全局形状感知，以实现精确且鲁棒的点云配准。具体而言，我们首先将点云的投影图像与注意机制融合，在交叉模态特征上进行融合。此外，我们采用两种对比学习策略，即重叠对比学习和跨模态对比学习。前者侧重于重叠区域的特征，而后者强调跨模态特征的学习。

    The majority of point cloud registration methods currently rely on extracting features from points. However, these methods are limited by their dependence on information obtained from a single modality of points, which can result in deficiencies such as inadequate perception of global features and a lack of texture information. Actually, humans can employ visual information learned from 2D images to comprehend the 3D world. Based on this fact, we present a novel Cross-Modal Information-Guided Network (CMIGNet), which obtains global shape perception through cross-modal information to achieve precise and robust point cloud registration. Specifically, we first incorporate the projected images from the point clouds and fuse the cross-modal features using the attention mechanism. Furthermore, we employ two contrastive learning strategies, namely overlapping contrastive learning and cross-modal contrastive learning. The former focuses on features in overlapping regions, while the latter emph
    
[^26]: 在边缘感知设备上的联邦学习：一项综述

    Federated Learning on Edge Sensing Devices: A Review. (arXiv:2311.01201v1 [cs.LG])

    [http://arxiv.org/abs/2311.01201](http://arxiv.org/abs/2311.01201)

    本文综述了在边缘感知设备上的联邦学习的研究现状。边缘感知设备的快速增长使得监测环境特征并获取环境信息成为可能，但云端或服务器上的分析面临隐私、硬件和连接性等挑战。联邦学习作为一种解决方案逐渐受到关注。

    

    快速增长的边缘感知设备（如物联网、移动设备和可穿戴设备）及其集成传感器的测量能力使得监控环境特征、与之交互并获取环境信息成为可能。尽管这些设备体积小、数据存储和处理能力较低，但它们产生了大量的数据。传感器数据的收集和处理应用领域包括医疗保健、环境（包括空气质量和污染水平）、汽车、工业、航空航天和农业等。从边缘设备收集的这些海量感知数据使用各种机器学习（ML）和深度学习（DL）方法进行分析。然而，在云端或服务器上进行分析会带来与隐私、硬件和连接性限制相关的挑战。联邦学习（FL）正逐渐成为解决这些问题的解决方案。

    The ability to monitor ambient characteristics, interact with them, and derive information about the surroundings has been made possible by the rapid proliferation of edge sensing devices like IoT, mobile, and wearable devices and their measuring capabilities with integrated sensors. Even though these devices are small and have less capacity for data storage and processing, they produce vast amounts of data. Some example application areas where sensor data is collected and processed include healthcare, environmental (including air quality and pollution levels), automotive, industrial, aerospace, and agricultural applications. These enormous volumes of sensing data collected from the edge devices are analyzed using a variety of Machine Learning (ML) and Deep Learning (DL) approaches. However, analyzing them on the cloud or a server presents challenges related to privacy, hardware, and connectivity limitations. Federated Learning (FL) is emerging as a solution to these problems while pre
    
[^27]: AiluRus: 一种用于密集预测的可扩展ViT框架

    AiluRus: A Scalable ViT Framework for Dense Prediction. (arXiv:2311.01197v1 [cs.CV])

    [http://arxiv.org/abs/2311.01197](http://arxiv.org/abs/2311.01197)

    AiluRus是一种用于密集预测的可扩展ViT框架，通过应用自适应分辨率和密度聚类算法，将语义相似的令牌合并在一起，以处理长令牌序列的复杂性。

    

    Vision transformers (ViTs)因其出色的性能而成为视觉任务中常见的架构。然而，在处理长令牌序列时，尤其是在需要高分辨率输入的密集预测任务中，ViTs的复杂性显著增加。值得注意的是，密集预测任务（如语义分割或目标检测）更加强调对象的轮廓或形状，而对象内部的纹理信息较少。受此观察的启发，我们提出根据图像中不同区域的重要性应用自适应分辨率。具体而言，在ViT的中间层中，我们利用一种基于空间感知的密度聚类算法从令牌序列中选择代表性的令牌。确定了代表性令牌后，我们继续将其他令牌合并到最近的代表性令牌中。因此，语义相似的令牌被合并在一起形成低分辨率的特征。

    Vision transformers (ViTs) have emerged as a prevalent architecture for vision tasks owing to their impressive performance. However, when it comes to handling long token sequences, especially in dense prediction tasks that require high-resolution input, the complexity of ViTs increases significantly. Notably, dense prediction tasks, such as semantic segmentation or object detection, emphasize more on the contours or shapes of objects, while the texture inside objects is less informative. Motivated by this observation, we propose to apply adaptive resolution for different regions in the image according to their importance. Specifically, at the intermediate layer of the ViT, we utilize a spatial-aware density-based clustering algorithm to select representative tokens from the token sequence. Once the representative tokens are determined, we proceed to merge other tokens into their closest representative token. Consequently, semantic similar tokens are merged together to form low-resoluti
    
[^28]: 上下文置信度和生成型人工智能

    Contextual Confidence and Generative AI. (arXiv:2311.01193v1 [cs.AI])

    [http://arxiv.org/abs/2311.01193](http://arxiv.org/abs/2311.01193)

    本文讨论了在面对生成型人工智能对上下文置信度的挑战时，采取的两类策略：遏制策略和动员策略。

    

    生成型人工智能模型扰乱了有效人际沟通的基础，给上下文置信度带来新的挑战，使参与者难以确定沟通的真实上下文，并且保护沟通不被在意图之外的环境中重复使用和重组。本文描述了旨在在面对这些挑战时稳定沟通的策略-工具、技术和政策。我们讨论的策略可分为两个大类。遏制策略旨在在当前被威胁上下文自由的期望和规范的环境中重新确定上下文-这是对互联网所建立的无上下文期望和规范的一种反应。相反，动员策略将生成型人工智能的崛起视为在媒体沟通中主动建立隐私和真实性新期望的机会。

    Generative AI models perturb the foundations of effective human communication. They present new challenges to contextual confidence, disrupting participants' ability to identify the authentic context of communication and their ability to protect communication from reuse and recombination outside its intended context. In this paper, we describe strategies--tools, technologies and policies--that aim to stabilize communication in the face of these challenges. The strategies we discuss fall into two broad categories. Containment strategies aim to reassert context in environments where it is currently threatened--a reaction to the context-free expectations and norms established by the internet. Mobilization strategies, by contrast, view the rise of generative AI as an opportunity to proactively set new and higher expectations around privacy and authenticity in mediated communication.
    
[^29]: VIGraph：自我监督学习用于类别不平衡节点分类

    VIGraph: Self-supervised Learning for Class-Imbalanced Node Classification. (arXiv:2311.01191v1 [cs.LG])

    [http://arxiv.org/abs/2311.01191](http://arxiv.org/abs/2311.01191)

    VIGraph是一个基于自我监督学习的模型，通过利用自编码器生成少数类节点来解决图数据中的类别不平衡问题，并通过引入孪生对比策略提高生成节点的质量。

    

    图数据中的类别不平衡为节点分类带来了重大挑战。现有方法，如基于SMOTE的方法，在不平衡场景构建过程中仍存在局限性。自我监督学习（SSL）通过从数据中合成少数类节点提供了一个有前景的解决方案，然而其潜力尚未被探索。本文分析了基于SMOTE的方法的限制，并引入了VIGraph，这是一种基于自我监督变分图自编码器（VGAE）的新型SSL模型，利用变分推断（VI）生成少数类节点。具体而言，VIGraph在构建不平衡图时严格遵循不平衡的概念，并利用生成型VGAE生成少数类节点。此外，VIGraph在解码阶段引入了一种新颖的孪生对比策略，以提高生成节点的整体质量。VIGraph能够生成高质量的节点，无需重新集成。

    Class imbalance in graph data poses significant challenges for node classification. Existing methods, represented by SMOTE-based approaches, partially alleviate this issue but still exhibit limitations during imbalanced scenario construction. Self-supervised learning (SSL) offers a promising solution by synthesizing minority nodes from the data itself, yet its potential remains unexplored. In this paper, we analyze the limitations of SMOTE-based approaches and introduce VIGraph, a novel SSL model based on the self-supervised Variational Graph Auto-Encoder (VGAE) that leverages Variational Inference (VI) to generate minority nodes. Specifically, VIGraph strictly adheres to the concept of imbalance when constructing imbalanced graphs and utilizes the generative VGAE to generate minority nodes. Moreover, VIGraph introduces a novel Siamese contrastive strategy at the decoding phase to improve the overall quality of generated nodes. VIGraph can generate high-quality nodes without reintegrat
    
[^30]: 在基于疫情的雾云计算架构中革新医疗影像分析

    Revolutionizing Healthcare Image Analysis in Pandemic-Based Fog-Cloud Computing Architectures. (arXiv:2311.01185v1 [cs.CV])

    [http://arxiv.org/abs/2311.01185](http://arxiv.org/abs/2311.01185)

    这个论文介绍了一种基于雾计算和改进型卷积神经网络的医疗架构，用于解决医疗影像分析中的效率和准确性挑战。

    

    突发疫情的出现极大地强调了在医疗数据分析中寻求有效解决方案的需求。在这个领域中，一个特别的挑战是对医学影像如X光和CT扫描进行手动检查。这个过程耗时且涉及将这些影像传输到集中的云计算服务器的物流复杂性。此外，图像分析的速度和准确性对于高效的医疗影像管理至关重要。这篇研究论文介绍了一种创新的医疗架构，通过利用人工智能的能力，解决了分析效率和准确性方面的挑战。具体地，提出的架构利用了雾计算，并呈现了一个专为图像分析设计的改进型卷积神经网络（CNN）。不同的CNN层架构进行了彻底的探索和评估，以优化整体性能。

    The emergence of pandemics has significantly emphasized the need for effective solutions in healthcare data analysis. One particular challenge in this domain is the manual examination of medical images, such as X-rays and CT scans. This process is time-consuming and involves the logistical complexities of transferring these images to centralized cloud computing servers. Additionally, the speed and accuracy of image analysis are vital for efficient healthcare image management. This research paper introduces an innovative healthcare architecture that tackles the challenges of analysis efficiency and accuracy by harnessing the capabilities of Artificial Intelligence (AI). Specifically, the proposed architecture utilizes fog computing and presents a modified Convolutional Neural Network (CNN) designed specifically for image analysis. Different architectures of CNN layers are thoroughly explored and evaluated to optimize overall performance. To demonstrate the effectiveness of the proposed 
    
[^31]: 生成输入：迈向下一代输入方法范式

    Generative Input: Towards Next-Generation Input Methods Paradigm. (arXiv:2311.01166v1 [cs.CL])

    [http://arxiv.org/abs/2311.01166](http://arxiv.org/abs/2311.01166)

    本研究提出了一种新的生成输入范式GeneInput，结合提示和用户反馈进行个性化的输入处理，在中文输入法引擎的构建中实现了最先进的性能。

    

    自从ChatGPT发布以来，生成模型在各种自然语言处理任务中取得了巨大成功，并成为事实上的方法。然而，在输入法领域中，其应用仍然不够深入。许多神经网络方法已被应用于中文输入法引擎的构建。以往的研究常常假设输入的拼音是正确的，并关注拼音到字符的转换任务，这在满足用户需求方面显然不足够。此外，以前的研究无法利用用户反馈来优化模型并提供个性化的结果。在本研究中，我们提出了一种名为GeneInput的全新生成输入范式。它使用提示处理所有输入场景和其他智能辅助输入功能，通过用户反馈优化模型以提供个性化的结果。实验结果表明，我们首次在全模式按键序列到字符的任务上达到了最先进的性能。

    Since the release of ChatGPT, generative models have achieved tremendous success and become the de facto approach for various NLP tasks. However, its application in the field of input methods remains under-explored. Many neural network approaches have been applied to the construction of Chinese input method engines(IMEs).Previous research often assumed that the input pinyin was correct and focused on Pinyin-to-character(P2C) task, which significantly falls short of meeting users' demands. Moreover, previous research could not leverage user feedback to optimize the model and provide personalized results. In this study, we propose a novel Generative Input paradigm named GeneInput. It uses prompts to handle all input scenarios and other intelligent auxiliary input functions, optimizing the model with user feedback to deliver personalized results. The results demonstrate that we have achieved state-of-the-art performance for the first time in the Full-mode Key-sequence to Characters(FK2C) 
    
[^32]: 弱监督下基于执行的虚假程序过滤的语义解析问题

    Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering. (arXiv:2311.01161v1 [cs.CL])

    [http://arxiv.org/abs/2311.01161](http://arxiv.org/abs/2311.01161)

    本研究提出了一种基于程序执行结果的领域无关筛选机制，用于解决弱监督下语义解析中的虚假程序问题

    

    在弱监督下训练语义解析器时，虚假程序是一个长期存在的挑战。为了消除具有错误语义但正确指示的程序，现有的方法着重于利用基于领域特定知识的例子相似性。在本文中，我们提出了一种基于程序执行结果的领域无关筛选机制。具体而言，对于通过搜索过程获得的每个程序，我们首先构建一个表示，它以各种输入下的执行结果捕捉程序的语义。然后，我们对这些表示进行多数投票，以识别并过滤掉与其他程序具有明显不同语义的程序。特别是，我们的方法与程序搜索过程正交，因此可以轻松增强任何现有的弱监督语义解析框架。在自然语言视觉推理和WikiTableQuestions上进行了实证评估

    The problem of spurious programs is a longstanding challenge when training a semantic parser from weak supervision. To eliminate such programs that have wrong semantics but correct denotation, existing methods focus on exploiting similarities between examples based on domain-specific knowledge. In this paper, we propose a domain-agnostic filtering mechanism based on program execution results. Specifically, for each program obtained through the search process, we first construct a representation that captures the program's semantics as execution results under various inputs. Then, we run a majority vote on these representations to identify and filter out programs with significantly different semantics from the other programs. In particular, our method is orthogonal to the program search process so that it can easily augment any of the existing weakly supervised semantic parsing frameworks. Empirical evaluations on the Natural Language Visual Reasoning and WikiTableQuestions demonstrate 
    
[^33]: 数字孪生与基于人工智能的网络安全应用综述

    A Review of Digital Twins and their Application in Cybersecurity based on Artificial Intelligence. (arXiv:2311.01154v1 [cs.CR])

    [http://arxiv.org/abs/2311.01154](http://arxiv.org/abs/2311.01154)

    数字孪生技术与人工智能工具之间的强互动可以改善数字平台的网络安全，但由于缺乏信息和安全标准，网络犯罪分子能够利用数字孪生技术对整个集合造成威胁。

    

    数字孪生技术的潜力尚未完全发挥，由于其多样性和未开发的潜力。数字孪生使得系统的分析、设计、优化和演化能够通过数字方式或与协同的网络-物理方法相结合进行，以提高传统工程方法的速度、准确性和效率。工业4.0、未来工厂和数字孪生技术继续从该技术中受益，并在现有系统中提供了增强的效率。由于缺乏与网络数字化过渡相关的信息和安全标准，网络犯罪分子能够利用这种情况。访问产品或服务的数字孪生等同于威胁整个集合。数字孪生与人工智能工具之间存在着强有力的互动，这导致这些技术之间存在着紧密的互动，因此可以用来改善这些数字平台的网络安全。

    The potential of digital twin technology is yet to be fully realized due to its diversity and untapped potential. Digital twins enable systems' analysis, design, optimization, and evolution to be performed digitally or in conjunction with a cyber-physical approach to improve speed, accuracy, and efficiency over traditional engineering methods. Industry 4.0, factories of the future, and digital twins continue to benefit from the technology and provide enhanced efficiency within existing systems. Due to the lack of information and security standards associated with the transition to cyber digitization, cybercriminals have been able to take advantage of the situation. Access to a digital twin of a product or service is equivalent to threatening the entire collection. There is a robust interaction between digital twins and artificial intelligence tools, which leads to strong interaction between these technologies, so it can be used to improve the cybersecurity of these digital platforms ba
    
[^34]: 重访知识注入框架

    Revisiting the Knowledge Injection Frameworks. (arXiv:2311.01150v1 [cs.CL])

    [http://arxiv.org/abs/2311.01150](http://arxiv.org/abs/2311.01150)

    这项研究重新审视了知识注入框架，发现将未对齐的随机知识注入到大型语言模型中可以取得与对齐知识相当甚至更好的结果。研究还提供了一种简单的修正技术来解决这个问题。

    

    近年来，大型语言模型（LLMs），如GPT，已在全球范围内产生了巨大的影响。然而，如何利用外部知识使这些LLMs更适应垂直领域特定任务的问题尚未完全解决。实际上，在这方面已经出现了一些工作，其中大部分依赖于构建对齐启发式规则，通过将相应的知识元组注入到相关的文本样本中。然而，尽管有希望，但我们普遍发现这项工作中存在一个关键问题。简而言之，我们发现将未对齐（即随机）的知识元组注入到LLMs中，可以取得与注入对齐知识相当甚至更好的结果。因此，我们对这一令人沮丧的发现进行了彻底的调查，并进一步提供了一系列可能的解释。基于这一切，我们提供了一种简单的修正技术。简要地说，这种技术的核心根植于...

    In recent years, large language models (LLMs), such as GPTs, have attained great impact worldwide. However, how to adapt these LLMs to better suit the vertical domain-specific tasks by utilizing external knowledge remains not completely solved. Indeed, there have emerged a few works on this line where most of them rely on an alignment heuristic that is built to inject the corresponding knowledge tuple into the associated text sample.  However, despite the promise, we identify a pivotal problem in this work ubiquitously. Simply put, we find that injecting unaligned (i.e., random) knowledge tuple into the LLMs achieves comparable (and sometimes better) results than the aligned knowledge being injected. We therefore take a thorough investigation of this frustrating finding on a variety of related prior work and further provide a chain of potential interpretations for the phenomenon. Based on all that, we offer a simple remediated technique. Briefly, the core of this technique is rooted in
    
[^35]: GREEMA:通过吃环境材料来壮大的机器人的提案和实验验证

    GREEMA: Proposal and Experimental Verification of Growing Robot by Eating Environmental MAterial for Landslide Disaster. (arXiv:2311.01107v1 [cs.RO])

    [http://arxiv.org/abs/2311.01107](http://arxiv.org/abs/2311.01107)

    GREEMA是一种通过吃环境材料来壮大的创新机器人，在滑坡等无法进入的地区能够取代人力工作，减少运输成本和时间。

    

    在对人类不可进入的地区，如月球表面和滑坡现场，需要多个可自主移动的机器人系统来取代人力工作。特别是在河道堵塞等滑坡现场，需要机器人尽快清除水和沉积物。传统上，几台建筑机械被部署到现场进行土木工程。然而，由于传统建筑设备的体积和重量较大，很难将多台建筑设备移动到现场，导致较大的运输成本和时间。为了解决这些问题，本研究提出了一种名为GREEMA的通过吃环境材料来壮大的创新机器人，其在运输过程中重量轻巧紧凑，一旦到达现场就能通过吃环境材料进行功能运作。GREEMA主动吸收水和沉积物等环境材料，并利用它们来

    In areas that are inaccessible to humans, such as the lunar surface and landslide sites, there is a need for multiple autonomous mobile robot systems that can replace human workers. In particular, at landslide sites such as river channel blockages, robots are required to remove water and sediment from the site as soon as possible. Conventionally, several construction machines have been deployed to the site for civil engineering work. However, because of the large size and weight of conventional construction equipment, it is difficult to move multiple units of construction equipment to the site, resulting in significant transportation costs and time. To solve such problems, this study proposes a novel growing robot by eating environmental material called GREEMA, which is lightweight and compact during transportation, but can function by eating on environmental materials once it arrives at the site. GREEMA actively takes in environmental materials such as water and sediment, uses them as
    
[^36]: 带有TinyissimoYOLO的AI集成智能眼镜上的超高效设备内目标检测

    Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO. (arXiv:2311.01057v1 [cs.CV])

    [http://arxiv.org/abs/2311.01057](http://arxiv.org/abs/2311.01057)

    本文介绍了在智能眼镜上实现超高效设备内目标检测的设计和实施，利用新型低功耗处理器实现小型机器学习算法，以便在具有小尺寸和有限电池容量的智能眼镜上实现长时间连续运行。

    

    智能眼镜借助尖端计算技术、加速硬件架构和小型AI算法，正迅速获得先进功能。在面向全天使用以实现满意用户体验时，将AI集成到具有小尺寸和有限电池容量的智能眼镜仍然具有挑战性。本文阐述了利用新型低功耗处理器实现小型机器学习算法设计和实现，以在智能眼镜中实现长时间连续运行。我们探索了智能眼镜在实时目标检测情况下的能量和时延效率。为此，我们设计了一个智能眼镜原型作为研究平台，其中包括两个微控制器，包括一个具有视觉AI硬件加速器的新型毫瓦级功率RISC-V并行处理器，以及一个用于通信的低功耗蓝牙模块。智能眼镜集成了图像和音频感应接口等电源循环机制。

    Smart glasses are rapidly gaining advanced functionality thanks to cutting-edge computing technologies, accelerated hardware architectures, and tiny AI algorithms. Integrating AI into smart glasses featuring a small form factor and limited battery capacity is still challenging when targeting full-day usage for a satisfactory user experience. This paper illustrates the design and implementation of tiny machine-learning algorithms exploiting novel low-power processors to enable prolonged continuous operation in smart glasses. We explore the energy- and latency-efficient of smart glasses in the case of real-time object detection. To this goal, we designed a smart glasses prototype as a research platform featuring two microcontrollers, including a novel milliwatt-power RISC-V parallel processor with a hardware accelerator for visual AI, and a Bluetooth low-power module for communication. The smart glasses integrate power cycling mechanisms, including image and audio sensing interfaces. Fur
    
[^37]: 用于有效调优语言模型的多维数据精化策略

    Multi-dimensional data refining strategy for effective fine-tuning LLMs. (arXiv:2311.01049v1 [cs.CL])

    [http://arxiv.org/abs/2311.01049](http://arxiv.org/abs/2311.01049)

    本文介绍了一种多维数据精化策略，包括利用现有数据集和生成型AI工具开发数据爬取脚本，用于调优越南语言模型。研究结果表明，使用该策略得到的模型在从提示生成越南新闻文章时表现出良好性能。

    

    数据是调优大型语言模型的基础，但获取合适的数据仍具有挑战性。这些挑战包括数据稀缺、语言多样性和特定领域内容。本文介绍了在爬取和精化针对调优越南语言模型的数据时所学到的经验。制作这样一个数据集需要细致的计划，考虑到语言的复杂性以及在包容性和准确性之间保持平衡。我们的论文提出了一个多维策略，包括利用英语中的现有数据集和借助生成型AI工具开发定制的数据爬取脚本。使用由产生的数据集生成的越南语言模型的调优模型，在从提示生成越南新闻文章时表现出良好性能。该研究为将来调优越南语等语言的模型提供了实用的解决方案和指导。

    Data is a cornerstone for fine-tuning large language models, yet acquiring suitable data remains challenging. Challenges encompassed data scarcity, linguistic diversity, and domain-specific content. This paper presents lessons learned while crawling and refining data tailored for fine-tuning Vietnamese language models. Crafting such a dataset, while accounting for linguistic intricacies and striking a balance between inclusivity and accuracy, demands meticulous planning. Our paper presents a multidimensional strategy including leveraging existing datasets in the English language and developing customized data-crawling scripts with the assistance of generative AI tools. A fine-tuned LLM model for the Vietnamese language, which was produced using resultant datasets, demonstrated good performance while generating Vietnamese news articles from prompts. The study offers practical solutions and guidance for future fine-tuning models in languages like Vietnamese.
    
[^38]: 高等教育中AI辅助学习电子工程课程的研究

    AI-assisted Learning for Electronic Engineering Courses in High Education. (arXiv:2311.01048v1 [cs.CY])

    [http://arxiv.org/abs/2311.01048](http://arxiv.org/abs/2311.01048)

    本研究评估了ChatGPT作为一种AI教学工具在高等教育电子工程课程中的效果，并探讨了其提供见解、个性化支持和互动学习体验的能力。研究结果揭示了ChatGPT作为AI工具的优点和局限性，并为技术学科中创新的学习方法提供了有价值的参考。此外，该研究对教育领域的数字化转型有所贡献。

    

    本研究评估了在亚洲某高等教育机构的集成电路系统课程中使用ChatGPT作为AI教学和学习支持工具的有效性。完成了各种不同类型的问题，并对ChatGPT的回答进行评估，以获得进一步研究的有价值的见解。研究旨在评估ChatGPT在工程教育中提供见解、个性化支持和互动学习体验的能力。该研究包括对不同利益相关方（学生、讲师和工程师）的评估和反思。本研究的发现揭示了ChatGPT作为AI工具的优点和局限性，为技术学科中创新的学习方法铺平了道路。此外，该研究有助于我们对数字化转型在教育领域如何展开的理解。

    This study evaluates the efficacy of ChatGPT as an AI teaching and learning support tool in an integrated circuit systems course at a higher education institution in an Asian country. Various question types were completed, and ChatGPT responses were assessed to gain valuable insights for further investigation. The objective is to assess ChatGPT's ability to provide insights, personalized support, and interactive learning experiences in engineering education. The study includes the evaluation and reflection of different stakeholders: students, lecturers, and engineers. The findings of this study shed light on the benefits and limitations of ChatGPT as an AI tool, paving the way for innovative learning approaches in technical disciplines. Furthermore, the study contributes to our understanding of how digital transformation is likely to unfold in the education sector.
    
[^39]: 自动驾驶的大型语言模型概述

    A Survey of Large Language Models for Autonomous Driving. (arXiv:2311.01043v1 [cs.AI])

    [http://arxiv.org/abs/2311.01043](http://arxiv.org/abs/2311.01043)

    这篇论文概述了自动驾驶技术的发展趋势，从传统的基于规则的系统过渡到基于数据驱动的端到端系统，并介绍了利用大型语言模型与视觉模型相结合来增强自动驾驶系统能力的思路。

    

    自动驾驶技术作为改变交通和城市流动性的催化剂，正趋向于从基于规则的系统转向基于数据驱动的策略。传统的模块化系统受到级联模块中的累积误差和不灵活的预设规则的限制。相比之下，端到端自动驾驶系统通过完全数据驱动的训练过程，有潜力避免错误累积，尽管由于其黑盒性质，它们往往缺乏透明度，使得决策的验证和可追溯性变得复杂。近期，大型语言模型（LLMs）展示了理解背景、逻辑推理和生成答案等能力。自然而然的想法是利用这些能力赋予自动驾驶以更强大的能力。通过将LLM与基础视觉模型结合，可能打开对开放世界理解、推理和少样本学习的大门，这是当前自动驾驶系统所缺乏的。

    Autonomous driving technology, a catalyst for revolutionizing transportation and urban mobility, has the tend to transition from rule-based systems to data-driven strategies. Traditional module-based systems are constrained by cumulative errors among cascaded modules and inflexible pre-set rules. In contrast, end-to-end autonomous driving systems have the potential to avoid error accumulation due to their fully data-driven training process, although they often lack transparency due to their ``black box" nature, complicating the validation and traceability of decisions. Recently, large language models (LLMs) have demonstrated abilities including understanding context, logical reasoning, and generating answers. A natural thought is to utilize these abilities to empower autonomous driving. By combining LLM with foundation vision models, it could open the door to open-world understanding, reasoning, and few-shot learning, which current autonomous driving systems are lacking. In this paper,
    
[^40]: 学会拒绝：通过知识范围限制和拒绝机制使大型语言模型更可控和可靠

    Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism. (arXiv:2311.01041v1 [cs.CL])

    [http://arxiv.org/abs/2311.01041](http://arxiv.org/abs/2311.01041)

    本文提出了一种学会拒绝（L2R）的简单而有效的解决方案，通过引入拒绝机制，使大型语言模型（LLMs）能够识别和拒绝难以回答的问题，从而提高模型的可控性和可靠性。

    

    大型语言模型（LLMs）展示了令人印象深刻的语言理解和生成能力，使它们能够回答各个领域的广泛问题。然而，这些模型并不完美，经常产生含有错误或错误信息的回答。这些不准确性，通常称为幻觉，使得LLMs在许多场景中不可靠甚至不可用。本文的重点是在LLMs中缓解幻觉问题，特别是在问答环境中。我们探索了一种拒绝机制，指导LLMs拒绝回答具有挑战性的问题以避免错误。我们提出了一个简单而有效的解决方案Learn to Refuse (L2R)，它将拒绝机制纳入到LLMs中，使其能够识别和拒绝那些它们难以回答的问题。为了实现这一点，我们利用结构化知识库来表示所有LLMs所需要的知识。

    Large language models (LLMs) have demonstrated impressive language understanding and generation capabilities, enabling them to answer a wide range of questions across various domains. However, these models are not flawless and often produce responses that contain errors or misinformation. These inaccuracies, commonly referred to as hallucinations, render LLMs unreliable and even unusable in many scenarios. In this paper, our focus is on mitigating the issue of hallucination in LLMs, particularly in the context of question-answering. Instead of attempting to answer all questions, we explore a refusal mechanism that instructs LLMs to refuse to answer challenging questions in order to avoid errors. We then propose a simple yet effective solution called Learn to Refuse (L2R), which incorporates the refusal mechanism to enable LLMs to recognize and refuse to answer questions that they find difficult to address. To achieve this, we utilize a structured knowledge base to represent all the LLM
    
[^41]: ATHENA: 数学推理与思维扩展

    ATHENA: Mathematical Reasoning with Thought Expansion. (arXiv:2311.01036v1 [cs.CL])

    [http://arxiv.org/abs/2311.01036](http://arxiv.org/abs/2311.01036)

    ATHENA是一种基于注意力机制的思维扩展网络架构，通过模拟人类的思维扩展机制来解决数学推理中的挑战，它能够产生合理的思考路径以解决实际世界的数学问题。

    

    解决数学问题取决于如何表达问题，以及模型如何看待人类语言表达的角度。实际世界的情境更依赖这种方法，因为同样的数学运算有多种实践方式。以往的研究通过限制预测策略来限制可用的思维过程，而忽略了这些策略在获取数学知识方面的重要性。我们引入了基于注意力的思维扩展网络架构 (ATHENA) 来应对现实世界中的挑战，模仿神经网络传播的形式来模拟人类的思维扩展机制。思维扩展通过递归生成候选数学表达式，从上一步驱动并选择通向目标的有效路径，产生合理的思维。我们的实验表明，ATHENA 在各种问题中都取得了全新的最先进水平，即使在信息有限的情况下，也能给出令人信服的答案。

    Solving math word problems depends on how to articulate the problems, the lens through which models view human linguistic expressions. Real-world settings count on such a method even more due to the diverse practices of the same mathematical operations. Earlier works constrain available thinking processes by limited prediction strategies without considering their significance in acquiring mathematical knowledge. We introduce Attention-based THought Expansion Network Architecture (ATHENA) to tackle the challenges of real-world practices by mimicking human thought expansion mechanisms in the form of neural network propagation. A thought expansion recurrently generates the candidates carrying the thoughts of possible math expressions driven from the previous step and yields reasonable thoughts by selecting the valid pathways to the goal. Our experiments show that ATHENA achieves a new state-of-the-art stage toward the ideal model that is compelling in variant questions even when the infor
    
[^42]: 非自回归基于扩散的连续时间长期事件预测的时间点过程

    Non-Autoregressive Diffusion-based Temporal Point Processes for Continuous-Time Long-Term Event Prediction. (arXiv:2311.01033v1 [cs.LG])

    [http://arxiv.org/abs/2311.01033](http://arxiv.org/abs/2311.01033)

    本论文提出了一种基于扩散的非自回归连续时间点过程模型，用于长期事件预测。通过整体预测未来事件序列、开发双向映射和设计降噪网络等手段，得到了更优的预测质量。

    

    连续时间长期事件预测在许多应用场景中起着重要作用。大多数现有工作依赖于自回归框架来预测事件序列，但这种方法容易累积错误，从而影响预测的质量。受到降噪扩散概率模型成功的启发，我们提出了一种基于扩散的非自回归连续时间点过程模型，用于长期事件预测。我们的模型整体预测未来的事件序列，而不是以自回归的方式逐个生成事件。为了在事件序列上进行扩散处理，我们开发了目标事件序列和欧几里德向量空间之间的双向映射。此外，我们设计了一个新颖的降噪网络，以捕捉顺序和上下文特征，提高样本质量。通过大量实验证明，我们提出的模型在长期事件上优于现有方法。

    Continuous-time long-term event prediction plays an important role in many application scenarios. Most existing works rely on autoregressive frameworks to predict event sequences, which suffer from error accumulation, thus compromising prediction quality. Inspired by the success of denoising diffusion probabilistic models, we propose a diffusion-based non-autoregressive temporal point process model for long-term event prediction in continuous time. Instead of generating events one at a time in an autoregressive way, our model predicts the future event sequence entirely as a whole. In order to perform diffusion processes on event sequences, we develop a bidirectional map between target event sequences and the Euclidean vector space. Furthermore, we design a novel denoising network to capture both sequential and contextual features for better sample quality. Extensive experiments are conducted to prove the superiority of our proposed model over state-of-the-art methods on long-term event
    
[^43]: 联合学习局部和全局特征用于基于方面的情感分类

    Joint Learning of Local and Global Features for Aspect-based Sentiment Classification. (arXiv:2311.01030v1 [cs.CL])

    [http://arxiv.org/abs/2311.01030](http://arxiv.org/abs/2311.01030)

    该论文提出了一种联合学习局部和全局特征的方法，以应对基于方面的情感分类中的问题。通过设计一个包含高斯掩码层和协方差自注意层的局部编码器，在模型中有效地整合了局部上下文和全局特征，并提供了更好的区分能力。

    

    基于方面的情感分类旨在判断句子中给定方面术语所传达的情感极性。情感极性不仅由局部上下文决定，还与远离给定方面术语的词汇相关。最近的基于注意力模型在某些情况下无法足够地区分应该更关注哪些词语。与此同时，基于图的模型正在进入基于方向的情感分类以编码句法依赖树信息。但是这些模型并没有充分利用句法依赖树，因为它们忽视了将依赖关系标签信息有效地整合到表示学习中。在本文中，我们通过有效地建模局部和全局特征来解决这些问题。首先，我们设计了一个包含高斯掩码层和协方差自注意层的局部编码器。高斯掩码层倾向于自适应地调整周围方面术语的感受野，以使其不重要化。

    Aspect-based sentiment classification (ASC) aims to judge the sentiment polarity conveyed by the given aspect term in a sentence. The sentiment polarity is not only determined by the local context but also related to the words far away from the given aspect term. Most recent efforts related to the attention-based models can not sufficiently distinguish which words they should pay more attention to in some cases. Meanwhile, graph-based models are coming into ASC to encode syntactic dependency tree information. But these models do not fully leverage syntactic dependency trees as they neglect to incorporate dependency relation tag information into representation learning effectively. In this paper, we address these problems by effectively modeling the local and global features. Firstly, we design a local encoder containing: a Gaussian mask layer and a covariance self-attention layer. The Gaussian mask layer tends to adjust the receptive field around aspect terms adaptively to deemphasize 
    
[^44]: 基于距离的传播策略用于知识图谱推理的效率提升

    Distance-Based Propagation for Efficient Knowledge Graph Reasoning. (arXiv:2311.01024v1 [cs.LG])

    [http://arxiv.org/abs/2311.01024](http://arxiv.org/abs/2311.01024)

    提出了一种基于距离的传播策略TAGNet，用于知识图谱补全任务中的高效推理。与其他方法相比，TAGNet能够在保持性能的前提下减少传播消息的数量，并且复杂度与层数无关。

    

    知识图谱补全旨在预测知识图谱中未见的边，从而发现新的事实。一类新的方法提出了通过聚合路径信息来解决这个问题。这些方法在知识图谱补全的任务中展示了巨大的能力。然而，它们饱受效率问题的困扰。虽然最近有一些尝试通过可学习的路径修剪来解决这个问题，但它们往往在性能上做出了牺牲以换取效率。在这项工作中，我们确定了这些方法的两个固有限制，这些限制影响了效率和表示质量。为了解决这些限制，我们引入了一种新方法，TAGNet，它能够有效地传播信息。这是通过仅在每对源-目标对中聚合固定窗口中的路径来实现的。我们证明了TAGNet的复杂度与层数无关。大量实验证明TAGNet可以减少传播消息的数量。

    Knowledge graph completion (KGC) aims to predict unseen edges in knowledge graphs (KGs), resulting in the discovery of new facts. A new class of methods have been proposed to tackle this problem by aggregating path information. These methods have shown tremendous ability in the task of KGC. However they are plagued by efficiency issues. Though there are a few recent attempts to address this through learnable path pruning, they often sacrifice the performance to gain efficiency. In this work, we identify two intrinsic limitations of these methods that affect the efficiency and representation quality. To address the limitations, we introduce a new method, TAGNet, which is able to efficiently propagate information. This is achieved by only aggregating paths in a fixed window for each source-target pair. We demonstrate that the complexity of TAGNet is independent of the number of layers. Extensive experiments demonstrate that TAGNet can cut down on the number of propagated messages by as m
    
[^45]: 增强是AUtO-Net：基于增强驱动的对比多视图学习的医学图像分割

    Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview Learning for Medical Image Segmentation. (arXiv:2311.01023v1 [cs.CV])

    [http://arxiv.org/abs/2311.01023](http://arxiv.org/abs/2311.01023)

    本论文提出了一种基于增强驱动的对比多视图学习框架用于医学图像分割，通过与多个增强视图进行对比性学习不变的特征表示，以克服数据短缺和计算资源依赖的问题。

    

    利用深度学习分割算法学习复杂器官和组织模式，并从噪声背景中提取感兴趣的重要区域，以提高医学图像诊断的视觉能力，在医学图像计算中取得了令人印象深刻的结果。本论文关注视网膜血管分割任务，提供了对基于深度学习的医学图像分割方法的广泛文献综述，并比较了各种方法和实证性能。本研究还通过指出两个重要现有限制（数据大小约束和对高计算资源的依赖性）来检查当前最先进方法的局限性。为了解决这些问题，本文提出了一种新颖的高效简单的多视图学习框架，通过与多个增强视图进行对比性学习不变的血管特征表示，以克服数据短缺和计算资源依赖的问题。

    The utilisation of deep learning segmentation algorithms that learn complex organs and tissue patterns and extract essential regions of interest from the noisy background to improve the visual ability for medical image diagnosis has achieved impressive results in Medical Image Computing (MIC). This thesis focuses on retinal blood vessel segmentation tasks, providing an extensive literature review of deep learning-based medical image segmentation approaches while comparing the methodologies and empirical performances. The work also examines the limitations of current state-of-the-art methods by pointing out the two significant existing limitations: data size constraints and the dependency on high computational resources. To address such problems, this work proposes a novel efficient, simple multiview learning framework that contrastively learns invariant vessel feature representation by comparing with multiple augmented views by various transformations to overcome data shortage and impr
    
[^46]: NeuroWrite: 使用深度神经网络进行手写数字分类的预测

    NeuroWrite: Predictive Handwritten Digit Classification using Deep Neural Networks. (arXiv:2311.01022v1 [cs.CV])

    [http://arxiv.org/abs/2311.01022](http://arxiv.org/abs/2311.01022)

    NeuroWrite是一种使用深度神经网络进行手写数字分类预测的独特方法，通过使用卷积神经网络和循环神经网络，在识别和分类手写数字方面取得了优秀的准确性。它可以实现高精度的分类和稳健的泛化能力，并具有在数字化文档中进行数字识别、签名验证和自动邮政编码识别等实际应用的潜力。

    

    深度神经网络的快速发展已经彻底改变了机器学习领域，使各个领域取得了显著的进展。在本文中，我们介绍了一种独特的方法NeuroWrite，利用深度神经网络来预测手写数字的分类。我们的模型通过利用卷积神经网络（CNNs）和循环神经网络（RNNs）的优势，在识别和分类手写数字方面表现出色。在本文中，我们详细研究了NeuroWrite中使用的数据准备方法、网络设计和训练方法。通过实施最先进的技术，我们展示了NeuroWrite在手写数字数据集（如MNIST）上实现了高精度的分类和稳健的泛化能力。此外，我们探索了该模型在数字化文档中的潜在应用，包括数字识别、签名验证和自动邮政编码识别等。

    The rapid evolution of deep neural networks has revolutionized the field of machine learning, enabling remarkable advancements in various domains. In this article, we introduce NeuroWrite, a unique method for predicting the categorization of handwritten digits using deep neural networks. Our model exhibits outstanding accuracy in identifying and categorising handwritten digits by utilising the strength of convolutional neural networks (CNNs) and recurrent neural networks (RNNs).In this article, we give a thorough examination of the data preparation methods, network design, and training methods used in NeuroWrite. By implementing state-of-the-art techniques, we showcase how NeuroWrite can achieve high classification accuracy and robust generalization on handwritten digit datasets, such as MNIST. Furthermore, we explore the model's potential for real-world applications, including digit recognition in digitized documents, signature verification, and automated postal code recognition. Neur
    
[^47]: 通过离散扩散学习无监督的自动驾驶世界模型

    Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion. (arXiv:2311.01017v1 [cs.CV])

    [http://arxiv.org/abs/2311.01017](http://arxiv.org/abs/2311.01017)

    本论文提出了一种通过离散扩散学习无监督的自动驾驶世界模型的新方法，通过使用VQVAE对传感器观察进行标记化并通过离散扩散预测未来，我们的模型在点云观察中实现了显著改进，将1秒预测的SOTA Chamfer距离降低了65%以上。

    

    学习世界模型可以以无监督的方式教会智能体世界的运作方式。尽管它可以看作是序列建模的特殊情况，但在自动驾驶等机器人应用中，与使用生成预训练转换器（GPT）扩展语言模型相比，扩展世界模型的进展相对较慢。我们指出了两个主要瓶颈：处理复杂和无结构的观察空间以及具有可扩展性的生成模型。因此，我们提出了一种新颖的世界建模方法，首先使用VQVAE对传感器观察进行标记化，然后通过离散扩散预测未来。为了有效地并行解码和去噪标记，我们将遮蔽生成图像转换器转换为离散扩散框架，并进行了一些简单的改进，取得了显着的改进效果。当应用于点云观察的世界模型学习时，我们的模型将1秒预测的SOTA Chamfer距离降低了65%以上。

    Learning world models can teach an agent how the world works in an unsupervised manner. Even though it can be viewed as a special case of sequence modeling, progress for scaling world models on robotic applications such as autonomous driving has been somewhat less rapid than scaling language models with Generative Pre-trained Transformers (GPT). We identify two reasons as major bottlenecks: dealing with complex and unstructured observation space, and having a scalable generative model. Consequently, we propose a novel world modeling approach that first tokenizes sensor observations with VQVAE, then predicts the future via discrete diffusion. To efficiently decode and denoise tokens in parallel, we recast Masked Generative Image Transformer into the discrete diffusion framework with a few simple changes, resulting in notable improvement. When applied to learning world models on point cloud observations, our model reduces prior SOTA Chamfer distance by more than 65% for 1s prediction, an
    
[^48]: 重塑皮肤病学中的AI模型：克服关键挑战以提高皮肤病变诊断

    Revamping AI Models in Dermatology: Overcoming Critical Challenges for Enhanced Skin Lesion Diagnosis. (arXiv:2311.01009v1 [cs.CV])

    [http://arxiv.org/abs/2311.01009](http://arxiv.org/abs/2311.01009)

    提出了一种名为HOT模型的全能-层次-分布之外-临床分类模型，通过生成层次预测、对分布之外图像的警示以及对临床图像不足的情况下建议进行皮肤镜检查，以提高皮肤病变诊断的效果和协同效应。

    

    近年来，通过图像分析开发深度学习模型诊断皮肤病变的数量激增，然而它们面临临床挑战。当前皮肤病学AI模型存在一些限制：有限的诊断结果数量，对不常见病变的现实世界测试的缺乏，无法检测到分布之外的图像，并过度依赖于皮肤镜图像。为了解决这些问题，我们提出了一种名为“全能-层次-分布之外-临床分类（HOT）”模型。对于临床图像，我们的模型生成三个输出：层次预测、对分布之外图像的警示以及如果仅凭临床图像无法诊断则建议进行皮肤镜检查。当采纳这个建议时，它将整合临床和皮肤镜图像以得出最终诊断。对代表性的皮肤病变数据集进行了大量实验，证明了我们框架中每个组件的有效性和协同效应。

    The surge in developing deep learning models for diagnosing skin lesions through image analysis is notable, yet their clinical black faces challenges. Current dermatology AI models have limitations: limited number of possible diagnostic outputs, lack of real-world testing on uncommon skin lesions, inability to detect out-of-distribution images, and over-reliance on dermoscopic images. To address these, we present an All-In-One \textbf{H}ierarchical-\textbf{O}ut of Distribution-\textbf{C}linical Triage (HOT) model. For a clinical image, our model generates three outputs: a hierarchical prediction, an alert for out-of-distribution images, and a recommendation for dermoscopy if clinical image alone is insufficient for diagnosis. When the recommendation is pursued, it integrates both clinical and dermoscopic images to deliver final diagnosis. Extensive experiments on a representative cutaneous lesion dataset demonstrate the effectiveness and synergy of each component within our framework. 
    
[^49]: 通过学习自然语言规则和引导来提高人工智能团队的效果

    Effective Human-AI Teams via Learned Natural Language Rules and Onboarding. (arXiv:2311.01007v1 [cs.LG])

    [http://arxiv.org/abs/2311.01007](http://arxiv.org/abs/2311.01007)

    本论文提出了一种通过学习自然语言规则和引导的方法，以提高人工智能团队的效果。通过找到数据的局部区域和使用语言模型进行描述，我们教导人类如何与AI合作。通过目标检测和问答任务的用户研究，我们证明了我们的方法可以使人工智能团队更加准确。

    

    人们越来越依赖于AI代理来帮助他们完成各种任务。人类必须知道何时依赖于代理，与代理合作或忽略其建议。在这项工作中，我们提出了一种通过数据区域和自然语言描述的学习规则的方法，以说明人类应该如何与AI合作。我们的新颖区域发现算法在嵌入空间中找到数据的局部区域作为邻域，纠正了人类的先验知识。然后，每个区域都通过迭代和对比过程进行描述，其中一个大型语言模型描述该区域。然后我们通过引导阶段将这些规则教给人类。通过在目标检测和问答任务上的用户研究，我们证明了我们的方法可以使人工智能团队更加准确。我们还分别评估了我们的区域发现和描述算法。

    People are relying on AI agents to assist them with various tasks. The human must know when to rely on the agent, collaborate with the agent, or ignore its suggestions. In this work, we propose to learn rules grounded in data regions and described in natural language that illustrate how the human should collaborate with the AI. Our novel region discovery algorithm finds local regions in the data as neighborhoods in an embedding space that corrects the human prior. Each region is then described using an iterative and contrastive procedure where a large language model describes the region. We then teach these rules to the human via an onboarding stage. Through user studies on object detection and question-answering tasks, we show that our method can lead to more accurate human-AI teams. We also evaluate our region discovery and description algorithms separately.
    
[^50]: 使用混合语义学习的Sam引导增强细粒度编码的医学图像字幕生成

    Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning. (arXiv:2311.01004v1 [cs.CV])

    [http://arxiv.org/abs/2311.01004](http://arxiv.org/abs/2311.01004)

    本论文提出了一种使用混合语义学习的Sam引导增强细粒度编码的医学图像字幕生成方法，有效地捕捉了医学图像的详细特征，并在评估指标上优于预训练的BLIP2模型。

    

    随着多模态和大型语言模型的发展，基于深度学习的医学图像字幕生成技术具有提供有价值的诊断建议的潜力。然而，当前的通用文本和图像预训练模型在描述医学图像中的复杂细节时无法提供令人满意的结果。在本文中，我们提出了一种由段落任意模型（SAM）引导的新型医学图像字幕生成方法，以实现对一般和详细特征的增强编码。此外，我们的方法采用独特的混合语义学习预训练策略，同时捕捉医学图像的整体信息和更细节的细节。我们展示了这种方法的有效性，它在生成医学图像描述的各种评估指标上优于预训练的BLIP2模型。

    With the development of multimodality and large language models, the deep learning-based technique for medical image captioning holds the potential to offer valuable diagnostic recommendations. However, current generic text and image pre-trained models do not yield satisfactory results when it comes to describing intricate details within medical images. In this paper, we present a novel medical image captioning method guided by the segment anything model (SAM) to enable enhanced encoding with both general and detailed feature extraction. In addition, our approach employs a distinctive pre-training strategy with mixed semantic learning to simultaneously capture both the overall information and finer details within medical images. We demonstrate the effectiveness of this approach, as it outperforms the pre-trained BLIP2 model on various evaluation metrics for generating descriptions of medical images.
    
[^51]: 通过最大化重新标记准确性来进行鲁棒数据修剪

    Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy. (arXiv:2311.01002v1 [cs.LG])

    [http://arxiv.org/abs/2311.01002](http://arxiv.org/abs/2311.01002)

    该论文提出了一种通过最大化重新标记准确性来进行鲁棒数据修剪的算法，该算法能够找到一个子集，使得所有训练示例的邻域置信度之和最大化。这个方法在现代深度学习中具有重要的应用价值。

    

    数据修剪旨在将大型训练集缩减为一个小而信息丰富的子集，对于减少现代深度学习的巨大计算成本至关重要。尽管大规模数据集中不可避免地含有注释噪声，并且已经开发了许多鲁棒学习方法，但对于噪声鲁棒学习场景下的数据修剪几乎未受到关注。通过自校正错误标签的最新重新标记方法在训练过程中，很难确定哪个子集能够在整个训练集中引发最准确的重新标记。在本文中，我们形式化了重新标记的数据修剪问题。首先我们展示了一个训练示例被正确重新标记的可能性与其邻域中的预测置信度成比例。因此，我们提出了一种全新的数据修剪算法，名为Prune4Rel，它能找到一个子集，使得所有训练示例的邻域置信度之和最大化。

    Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples,
    
[^52]: 在考虑移动图像传感器的情况下，完全量化的始终开启的人脸检测器

    Fully Quantized Always-on Face Detector Considering Mobile Image Sensors. (arXiv:2311.01001v1 [cs.CV])

    [http://arxiv.org/abs/2311.01001](http://arxiv.org/abs/2311.01001)

    在考虑移动图像传感器的情况下，本研究探索了极低位轻量级的人脸检测器，旨在弥合始终开启场景下的人脸检测的不足。

    

    尽管对于边缘设备设计的轻量级深度神经网络（DNN）进行了大量研究，但当前的人脸检测器并不能完全满足集成了嵌入式DNN的"智能"CMOS图像传感器（iCIS）的要求。这些传感器在各种实际应用中至关重要，例如节能手机和带始终开启能力的监控系统。其中一个值得注意的局限性是始终开启场景下的合适人脸检测器的缺失，这是图像传感器级别应用的一个关键方面。这些检测器必须在图像信号处理器（ISP）接管之前直接处理传感器原始数据。这种差距在实现这种场景下的最佳性能方面带来了重大挑战。需要进一步的研究和开发来弥合这一差距，充分利用iCIS应用的潜力。在本研究中，我们的目标是通过探索极低位轻量级人脸检测器来弥合这一差距，重点是始终开启的人脸检测。

    Despite significant research on lightweight deep neural networks (DNNs) designed for edge devices, the current face detectors do not fully meet the requirements for "intelligent" CMOS image sensors (iCISs) integrated with embedded DNNs. These sensors are essential in various practical applications, such as energy-efficient mobile phones and surveillance systems with always-on capabilities. One noteworthy limitation is the absence of suitable face detectors for the always-on scenario, a crucial aspect of image sensor-level applications. These detectors must operate directly with sensor RAW data before the image signal processor (ISP) takes over. This gap poses a significant challenge in achieving optimal performance in such scenarios. Further research and development are necessary to bridge this gap and fully leverage the potential of iCIS applications. In this study, we aim to bridge the gap by exploring extremely low-bit lightweight face detectors, focusing on the always-on face detec
    
[^53]: 在印度尼西亚的低资源本地语言上可复制的神经机器翻译基准

    Replicable Benchmarking of Neural Machine Translation (NMT) on Low-Resource Local Languages in Indonesia. (arXiv:2311.00998v1 [cs.CL])

    [http://arxiv.org/abs/2311.00998](http://arxiv.org/abs/2311.00998)

    本研究通过在印度尼西亚的低资源本地语言上训练NMT系统的综合分析，解决了神经机器翻译面临的挑战。 尽管计算资源和文本数据有限，但我们的几个NMT系统取得了竞争性性能，与零-shot gpt-3.5-turbo的翻译质量相媲美。 这些发现显著推动了低资源语言的NMT，为研究人员提供了宝贵的指导。

    

    面对印度尼西亚低资源本地语言的神经机器翻译(NMT)面临着重大挑战，包括需要一个代表性的基准和有限的数据可用性。本研究通过全面分析为印度尼西亚的四种低资源本地语言（爪哇语、苏丹尼斯语、米南卡博和巴厘语）训练NMT系统来解决这些挑战。我们的研究涵盖了各种训练方法、范例、数据规模以及对使用大型语言模型进行合成低资源语言平行数据生成的初步研究。我们揭示了低资源语言翻译实用策略的具体趋势和见解。我们的研究表明，尽管计算资源和文本数据有限，我们的几个NMT系统在竞争性性能方面取得了成功，与零-shot gpt-3.5-turbo的翻译质量相媲美。这些发现显著推动了低资源语言的NMT，为研究人员提供了宝贵的指导。

    Neural machine translation (NMT) for low-resource local languages in Indonesia faces significant challenges, including the need for a representative benchmark and limited data availability. This work addresses these challenges by comprehensively analyzing training NMT systems for four low-resource local languages in Indonesia: Javanese, Sundanese, Minangkabau, and Balinese. Our study encompasses various training approaches, paradigms, data sizes, and a preliminary study into using large language models for synthetic low-resource languages parallel data generation. We reveal specific trends and insights into practical strategies for low-resource language translation. Our research demonstrates that despite limited computational resources and textual data, several of our NMT systems achieve competitive performances, rivaling the translation quality of zero-shot gpt-3.5-turbo. These findings significantly advance NMT for low-resource languages, offering valuable guidance for researchers in
    
[^54]: 优化库存配送：一种基于神经网络的决策导向学习方法

    Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks. (arXiv:2311.00983v1 [cs.LG])

    [http://arxiv.org/abs/2311.00983](http://arxiv.org/abs/2311.00983)

    本文提出了一种基于决策导向学习的方法来解决库存配送问题，通过直接集成库存预测和路径优化，可能确保一个强大的供应链策略。

    

    库存配送问题（IRP）是供应链管理中的一个关键挑战，它涉及在考虑库存需求规划的不确定性的情况下优化有效的路径选择。为了解决IRP问题，通常采用两阶段的方法，首先使用机器学习技术预测需求，然后使用优化算法来最小化配送成本。我们的实验表明，机器学习模型在实现完美准确度方面存在不足，因为库存水平受动态业务环境的影响，进而影响到下一阶段的优化问题，导致次优决策。在本文中，我们提出了一种基于决策导向学习的方法来解决现实世界的IRP问题。这种方法在一个端到端的系统中直接集成了库存预测和路径优化，可能确保一个强大的供应链策略。

    Inventory Routing Problem (IRP) is a crucial challenge in supply chain management as it involves optimizing efficient route selection while considering the uncertainty of inventory demand planning. To solve IRPs, usually a two-stage approach is employed, where demand is predicted using machine learning techniques first, and then an optimization algorithm is used to minimize routing costs. Our experiment shows machine learning models fall short of achieving perfect accuracy because inventory levels are influenced by the dynamic business environment, which, in turn, affects the optimization problem in the next stage, resulting in sub-optimal decisions. In this paper, we formulate and propose a decision-focused learning-based approach to solving real-world IRPs. This approach directly integrates inventory prediction and routing optimization within an end-to-end system potentially ensuring a robust supply chain strategy.
    
[^55]: 一个集成蒙特卡洛树搜索和监督学习的列车运行图问题综合框架

    An Integrated Framework Integrating Monte Carlo Tree Search and Supervised Learning for Train Timetabling Problem. (arXiv:2311.00971v1 [cs.LG])

    [http://arxiv.org/abs/2311.00971](http://arxiv.org/abs/2311.00971)

    提出了一个综合应用蒙特卡洛树搜索和监督学习的框架，用于解决列车运行图问题(TTP)。实验证明该框架在提高TTP的解决效率方面是有效的。

    

    单线铁路列车运行图问题(TTP)是一个重要且复杂的问题。本文提出了一个综合应用启发式方法、无监督学习方法和监督学习方法的蒙特卡洛树搜索(MCTS)计算框架，用于解决离散动作空间下的TTP。本文首先描述了TTP的数学模型和仿真系统动力学，并从MCTS的角度分析了解决方案的特点，提出了一些启发式方法以改进MCTS。本文将这些方法视为所提框架中的规划器。其次，本文利用深度卷积神经网络来近似节点的值，并进一步应用于MCTS搜索过程中，称为学习器。实验证明，所提出的启发式MCTS方法有助于解决TTP；将规划器和学习器集成到算法框架中可以提高解决TTP的数据效率；该算法框架还可以应用于其他类似的优化问题。

    The single-track railway train timetabling problem (TTP) is an important and complex problem. This article proposes an integrated Monte Carlo Tree Search (MCTS) computing framework that combines heuristic methods, unsupervised learning methods, and supervised learning methods for solving TTP in discrete action spaces. This article first describes the mathematical model and simulation system dynamics of TTP, analyzes the characteristics of the solution from the perspective of MCTS, and proposes some heuristic methods to improve MCTS. This article considers these methods as planners in the proposed framework. Secondly, this article utilizes deep convolutional neural networks to approximate the value of nodes and further applies them to the MCTS search process, referred to as learners. The experiment shows that the proposed heuristic MCTS method is beneficial for solving TTP; The algorithm framework that integrates planners and learners can improve the data efficiency of solving TTP; The 
    
[^56]: Video2Music：使用情感多模态Transformer模型从视频中生成合适的音乐

    Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model. (arXiv:2311.00968v1 [cs.SD])

    [http://arxiv.org/abs/2311.00968](http://arxiv.org/abs/2311.00968)

    Video2Music是一个生成音乐的人工智能框架，可以根据视频生成相匹配的音乐。该框架通过分析视频的语义、场景偏移、动作和情感特征，采用Affective Multimodal Transformer (AMT)模型生成音乐。

    

    在音乐生成领域，许多研究展示了令人印象深刻的性能，但几乎没有模型能够直接根据视频生成相匹配的音乐。在这项工作中，我们开发了一个生成音乐的人工智能框架Video2Music，它可以匹配提供的视频。我们首先精心策划了一个独特的音乐视频集合。然后，我们分析音乐视频以获得语义、场景偏移、动作和情感特征。然后，这些不同的特征被用作我们音乐生成模型的引导输入。我们将音频文件转录为MIDI和和弦，并提取音符密度和音量等特征。这产生了一个丰富的多模态数据集MuVi-Sync，我们用这个数据集训练了一个新颖的情感多模态Transformer模型（AMT）来根据视频生成音乐。该模型包括一种新颖的机制来强制视频和音乐之间的情感相似性。最后，基于一个基于双向GRU的回归模型进行后处理，估计音符密度。

    Numerous studies in the field of music generation have demonstrated impressive performance, yet virtually no models are able to directly generate music to match accompanying videos. In this work, we develop a generative music AI framework, Video2Music, that can match a provided video. We first curated a unique collection of music videos. Then, we analysed the music videos to obtain semantic, scene offset, motion, and emotion features. These distinct features are then employed as guiding input to our music generation model. We transcribe the audio files into MIDI and chords, and extract features such as note density and loudness. This results in a rich multimodal dataset, called MuVi-Sync, on which we train a novel Affective Multimodal Transformer (AMT) model to generate music given a video. This model includes a novel mechanism to enforce affective similarity between video and music. Finally, post-processing is performed based on a biGRU-based regression model to estimate note density 
    
[^57]: 机器人任务规划的视觉语言解释器

    Vision-Language Interpreter for Robot Task Planning. (arXiv:2311.00967v1 [cs.RO])

    [http://arxiv.org/abs/2311.00967](http://arxiv.org/abs/2311.00967)

    本文提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架通过使用先进的语言模型和视觉语言模型生成机器人任务描述，并通过符号规划器的错误消息反馈进行改进。实验结果表明ViLaIn和符号规划器能够准确生成有效的机器人计划。

    

    大型语言模型（LLMs）正在加速语言引导的机器人规划器的发展。同时，符号规划器具有可解释性的优势。本文提出了一个新的任务，将这两种趋势相结合，即多模态规划问题规范。目标是生成一个问题描述（PD），这是规划器用来查找计划的机器可读文件。通过从语言指令和场景观测中生成PD，我们可以驱动符号规划器在语言引导框架下工作。我们提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架使用先进的LLM和视觉语言模型生成PD。ViLaIn可以通过符号规划器的错误消息反馈来改进生成的PD。我们的目标是回答这个问题：ViLaIn和符号规划器能够准确地生成有效的机器人计划吗？为了评估ViLaIn，我们引入了一个名为问题描述生成（ProDG）数据集的新颖数据集。该框架将在评估中进行测试。

    Large language models (LLMs) are accelerating the development of language-guided robot planners. Meanwhile, symbolic planners offer the advantage of interpretability. This paper proposes a new task that bridges these two trends, namely, multimodal planning problem specification. The aim is to generate a problem description (PD), a machine-readable file used by the planners to find a plan. By generating PDs from language instruction and scene observation, we can drive symbolic planners in a language-guided framework. We propose a Vision-Language Interpreter (ViLaIn), a new framework that generates PDs using state-of-the-art LLM and vision-language models. ViLaIn can refine generated PDs via error message feedback from the symbolic planner. Our aim is to answer the question: How accurately can ViLaIn and the symbolic planner generate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset called the problem description generation (ProDG) dataset. The framework is evaluated wi
    
[^58]: IndoToD: 一个用于多领域印尼语端到端任务导向对话系统的基准

    IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End Task-Oriented Dialogue Systems. (arXiv:2311.00958v1 [cs.CL])

    [http://arxiv.org/abs/2311.00958](http://arxiv.org/abs/2311.00958)

    本文介绍了IndoToD，一个用于印尼语的端到端多领域任务导向对话系统的基准。通过将英语数据集转化为印尼语，我们创建了这个基准，并通过雇佣母语为印尼语的人员进行翻译和数据收集，这为评估印尼语和英语对话系统以及跨语言和双语迁移学习方法提供了有效工具。

    

    大多数任务导向对话系统只是为高资源语言如英语和汉语创建的，然而，有必要开发其他区域或本地语言的对话系统，以扩展它们理解不同语言对话背景的能力。本文介绍了IndoToD，一个印尼语端到端多领域对话系统基准。我们通过词法分析将两个英语对话数据集扩展到印尼语，包括四个不同领域，以高效地减少注释的大小。为了确保高质量的数据收集，我们雇用母语为印尼语的人手动翻译对话。除了原始的英语数据集外，这些新的印尼语数据集可以作为评估印尼语和英语对话系统以及探索跨语言和双语迁移学习方法潜在益处的有效基准。

    Task-oriented dialogue (ToD) systems have been mostly created for high-resource languages, such as English and Chinese. However, there is a need to develop ToD systems for other regional or local languages to broaden their ability to comprehend the dialogue contexts in various languages. This paper introduces IndoToD, an end-to-end multi domain ToD benchmark in Indonesian. We extend two English ToD datasets to Indonesian, comprising four different domains by delexicalization to efficiently reduce the size of annotations. To ensure a high-quality data collection, we hire native speakers to manually translate the dialogues. Along with the original English datasets, these new Indonesian datasets serve as an effective benchmark for evaluating Indonesian and English ToD systems as well as exploring the potential benefits of cross-lingual and bilingual transfer learning approaches.
    
[^59]: 高斯混合解算器用于扩散模型

    Gaussian Mixture Solvers for Diffusion Models. (arXiv:2311.00941v1 [cs.LG])

    [http://arxiv.org/abs/2311.00941](http://arxiv.org/abs/2311.00941)

    这篇论文提出了一种名为高斯混合解算器(GMS)的新型SDE-based解算器用于扩散模型，通过估计前三阶矩并优化高斯混合参数来解决现有SDE-based解算器的效率-有效性困境问题。

    

    最近，扩散模型在生成任务中取得了巨大的成功。从扩散模型中采样等价于解决反扩散随机微分方程（SDEs）或相应的概率流常微分方程（ODEs）。与之相比，基于SDE的解算器可以生成更高质量的样本，并适用于基于笔划合成的图像转换任务。然而，在推断过程中，现有的基于SDE的解算器受到效率-有效性困境的严重限制。我们的调查表明，这是因为反向转换核中的高斯假设在有限数量的离散化步骤中经常被违反（即使在简单混合数据的情况下）。为了克服这个限制，我们引入了一种新的基于SDE的解算器类，称为高斯混合解算器（GMS）用于扩散模型。我们的解算器估计了前三阶矩，并优化了高斯混合的参数

    Recently, diffusion models have achieved great success in generative tasks. Sampling from diffusion models is equivalent to solving the reverse diffusion stochastic differential equations (SDEs) or the corresponding probability flow ordinary differential equations (ODEs). In comparison, SDE-based solvers can generate samples of higher quality and are suited for image translation tasks like stroke-based synthesis. During inference, however, existing SDE-based solvers are severely constrained by the efficiency-effectiveness dilemma. Our investigation suggests that this is because the Gaussian assumption in the reverse transition kernel is frequently violated (even in the case of simple mixture data) given a limited number of discretization steps. To overcome this limitation, we introduce a novel class of SDE-based solvers called \emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver estimates the first three-order moments and optimizes the parameters of a Gaussian mixture
    
[^60]: 缩小差距：解决分类模型训练中的差异问题以实现无分类器引导

    Bridging the Gap: Addressing Discrepancies in Diffusion Model Training for Classifier-Free Guidance. (arXiv:2311.00938v1 [cs.LG])

    [http://arxiv.org/abs/2311.00938](http://arxiv.org/abs/2311.00938)

    本文介绍了一种更新的损失函数，以更好地对齐传统训练方法与扩散模型所期望的条件采样行为之间的差异。实验证明该方法能够以更少的采样时间步长生成更高质量的样本，并对于引导规模的选择更具鲁棒性。

    

    扩散模型已经成为生成模型中的一个重要进展，为生成的实例质量设定了新的标准。本文旨在强调传统训练方法与这些模型所期望的条件采样行为之间存在的差异。虽然流行的无分类器引导技术效果不错，但也存在一些缺陷。在引导规模参数$w$取较高值时，我们经常得到分布之外的样本和模式崩溃，而在$w$取较低值时，可能无法获得所期望的特异性。为了解决这些挑战，我们引入了一种更新的损失函数，更好地将训练目标与采样行为对齐。在CIFAR-10上的FID分数的实验证明了我们的方法能够以较少的采样时间步长生成更高质量的样本，并且对于引导规模$w$的选择更具鲁棒性。我们还尝试了在提出的损失上对稳定性扩散进行微调，以提供e。

    Diffusion models have emerged as a pivotal advancement in generative models, setting new standards to the quality of the generated instances. In the current paper we aim to underscore a discrepancy between conventional training methods and the desired conditional sampling behavior of these models. While the prevalent classifier-free guidance technique works well, it's not without flaws. At higher values for the guidance scale parameter $w$, we often get out of distribution samples and mode collapse, whereas at lower values for $w$ we may not get the desired specificity. To address these challenges, we introduce an updated loss function that better aligns training objectives with sampling behaviors. Experimental validation with FID scores on CIFAR-10 elucidates our method's ability to produce higher quality samples with fewer sampling timesteps, and be more robust to the choice of guidance scale $w$. We also experiment with fine-tuning Stable Diffusion on the proposed loss, to provide e
    
[^61]: 可扩展的多变量因果模型中的反事实分布估计

    Scalable Counterfactual Distribution Estimation in Multivariate Causal Models. (arXiv:2311.00927v1 [stat.ML])

    [http://arxiv.org/abs/2311.00927](http://arxiv.org/abs/2311.00927)

    该论文提出了一种可扩展的方法，用于在多变量因果模型中估计多个感兴趣量的反事实联合分布。通过利用原始高维空间中的一维潜在子空间和单一变量因果模型，该方法可以同时处理多变量结果的相关结构并产生准确的反事实分布估计。

    

    我们考虑了在经典的差异差异设计的基础上扩展的多变量因果模型中估计多个感兴趣量（例如结果）的反事实联合分布的问题。现有的方法要么忽略多变量结果各维度间的相关结构，通过在每个维度上考虑单一变量因果模型而产生错误的反事实分布；要么在直接处理这种多变量因果模型时，在中等大小的数据集上表现不佳。我们提出了一种方法，可以同时减轻这两个问题，方法是利用原始高维空间中鲁棒的一维潜在子空间，并利用单一变量因果模型在该空间上的高效估计。由于一维子空间的构建使用了来自所有维度的信息，我们的方法可以捕捉相关结构并产生反事实分布的良好估计。

    We consider the problem of estimating the counterfactual joint distribution of multiple quantities of interests (e.g., outcomes) in a multivariate causal model extended from the classical difference-in-difference design. Existing methods for this task either ignore the correlation structures among dimensions of the multivariate outcome by considering univariate causal models on each dimension separately and hence produce incorrect counterfactual distributions, or poorly scale even for moderate-size datasets when directly dealing with such multivariate causal model. We propose a method that alleviates both issues simultaneously by leveraging a robust latent one-dimensional subspace of the original high-dimension space and exploiting the efficient estimation from the univariate causal model on such space. Since the construction of the one-dimensional subspace uses information from all the dimensions, our method can capture the correlation structures and produce good estimates of the coun
    
[^62]: M2T2:多任务遮蔽变换器用于物体中心的拾取和放置

    M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place. (arXiv:2311.00926v1 [cs.RO])

    [http://arxiv.org/abs/2311.00926](http://arxiv.org/abs/2311.00926)

    M2T2是一个用于物体操作的多任务遮蔽变换器模型，通过推理场景的原始点云，可以稳定地提供不同类型的低级操作，并在真实机器人上实现了零-shot仿真到实际的转移。

    

    随着大语言模型和大规模机器人数据集的出现，高级物体操作的高级决策已经取得了巨大进展。这些通用模型能够使用语言指令解释复杂任务，但由于低级动作原语的能力不足，它们通常难以推广到超出分布范围的对象。相反，现有的任务特定模型在未知对象的低级操作方面表现出色，但仅适用于单一类型的动作。为了弥合这个差距，我们提出了M2T2，它是一个单一模型，可以在杂乱场景中稳定地提供不同类型的低级操作。M2T2是一个变换器模型，通过对场景的原始点云进行推理，推断接触点，并预测不同动作模式的有效夹持器姿势。在一个包含128K个场景的大规模合成数据集上训练，M2T2在真实机器人上实现了零-shot仿真到实际的转移，并超过了基准系统。

    With the advent of large language models and large-scale robotic datasets, there has been tremendous progress in high-level decision-making for object manipulation. These generic models are able to interpret complex tasks using language commands, but they often have difficulties generalizing to out-of-distribution objects due to the inability of low-level action primitives. In contrast, existing task-specific models excel in low-level manipulation of unknown objects, but only work for a single type of action. To bridge this gap, we present M2T2, a single model that supplies different types of low-level actions that work robustly on arbitrary objects in cluttered scenes. M2T2 is a transformer model which reasons about contact points and predicts valid gripper poses for different action modes given a raw point cloud of the scene. Trained on a large-scale synthetic dataset with 128K scenes, M2T2 achieves zero-shot sim2real transfer on the real robot, outperforming the baseline system with
    
[^63]: 视觉和触觉的融合学习：基于屏蔽多模态学习的通用化操控能力

    The Power of the Senses: Generalizable Manipulation from Vision and Touch through Masked Multimodal Learning. (arXiv:2311.00924v1 [cs.RO])

    [http://arxiv.org/abs/2311.00924](http://arxiv.org/abs/2311.00924)

    本文基于屏蔽多模态学习方法提出了一种在强化学习中融合视觉和触觉信息的系统方法，实现了超越单一感官的通用化操控能力，并且这种多模态学习对于仅视觉策略也具有好处。

    

    人类在大部分基本任务中依靠感官的协同作用。对于需要物体操纵的任务，我们无缝且有效地利用视觉和触觉的互补性。本文受到这种能力的启发，旨在找到一种系统的方法来在强化学习环境中融合视觉和触觉信息。我们提出了屏蔽多模态学习（M3L），通过屏蔽自动编码，同时学习策略和视觉-触觉表述。从视觉和触觉中共同学习的表述提高了样本效率，并且展现了超越单一感官单独实现的泛化能力。值得注意的是，多模态环境中学习的表述也对测试时的仅视觉策略有益。我们在三个模拟环境（机器人插入、开门和灵巧的手上操作）中评估了M3L，展示了学习的益处。

    Humans rely on the synergy of their senses for most essential tasks. For tasks requiring object manipulation, we seamlessly and effectively exploit the complementarity of our senses of vision and touch. This paper draws inspiration from such capabilities and aims to find a systematic approach to fuse visual and tactile information in a reinforcement learning setting. We propose Masked Multimodal Learning (M3L), which jointly learns a policy and visual-tactile representations based on masked autoencoding. The representations jointly learned from vision and touch improve sample efficiency, and unlock generalization capabilities beyond those achievable through each of the senses separately. Remarkably, representations learned in a multimodal setting also benefit vision-only policies at test time. We evaluate M3L on three simulated environments with both visual and tactile observations: robotic insertion, door opening, and dexterous in-hand manipulation, demonstrating the benefits of learn
    
[^64]: 人工智能伦理教育在网络安全中的挑战与机遇：一个焦点小组报告

    Artificial Intelligence Ethics Education in Cybersecurity: Challenges and Opportunities: a focus group report. (arXiv:2311.00903v1 [cs.CR])

    [http://arxiv.org/abs/2311.00903](http://arxiv.org/abs/2311.00903)

    这项研究揭示了人工智能在网络安全中的挑战和机遇，包括获取免费工具、课程多样性、伦理原则的明确阐述以及解决“黑匣子”思维等问题。研究提出了通过严格的技术培训、清晰的文档和伦理监控的框架来解决这些问题。

    

    人工智能工具在网络安全中的出现带来了许多机遇和不确定性。与网络安全高级研究生的焦点小组讨论揭示了挑战和机遇的潜在深度和广度。重要问题包括获取开源或免费工具、文档、课程多样性以及对人工智能网络安全教育伦理原则的明确阐述。解决人工智能网络安全工作中的“黑匣子”思维也至关重要，同时加强对基础人工智能工作的深入和先行教育。系统思考和有效沟通被认为是教育改进的相关领域。未来的人工智能教育者和从业者需要通过实施严格的技术培训课程、清晰的文档和伦理监控人工智能的框架，并结合批判性和系统思考以及沟通技能来解决这些问题。

    The emergence of AI tools in cybersecurity creates many opportunities and uncertainties. A focus group with advanced graduate students in cybersecurity revealed the potential depth and breadth of the challenges and opportunities. The salient issues are access to open source or free tools, documentation, curricular diversity, and clear articulation of ethical principles for AI cybersecurity education. Confronting the "black box" mentality in AI cybersecurity work is also of the greatest importance, doubled by deeper and prior education in foundational AI work. Systems thinking and effective communication were considered relevant areas of educational improvement. Future AI educators and practitioners need to address these issues by implementing rigorous technical training curricula, clear documentation, and frameworks for ethically monitoring AI combined with critical and system's thinking and communication skills.
    
[^65]: 生成和验证：使用SALLMS评估LLM生成的代码的安全性

    Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code. (arXiv:2311.00889v1 [cs.SE])

    [http://arxiv.org/abs/2311.00889](http://arxiv.org/abs/2311.00889)

    该论文研究了使用SALLMS评估LLM生成代码的安全性，指出现有数据集和评估指标未能充分考虑到与安全相关的真实软件工程任务，从而导致不安全的代码生成。

    

    随着大型语言模型（例如GitHub Copilot，ChatGPT等）在软件工程师的日常实践中越来越受欢迎，确保这些工具生成的代码不仅功能正确，而且没有漏洞变得非常重要。尽管LLM可以帮助开发人员提高生产力，但之前的实证研究表明LLM可能会生成不安全的代码。存在两个导致不安全代码生成的因素。首先，用于评估大型语言模型（LLM）的现有数据集没有充分地代表与安全相关的真实软件工程任务。相反，它们通常基于竞技编程挑战或以课堂形式为基础的编码任务。在真实世界的应用中，生成的代码将被集成到更大的代码库中，引入潜在的安全风险。目前缺乏专注于评估生成代码安全性的基准。其次，现有的评估指标主要侧重于功能性而忽视安全性。

    With the growing popularity of Large Language Models (e.g. GitHub Copilot, ChatGPT, etc.) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate Large Language Models (LLMs) do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. There's a clear absence of benchmarks that focus on evaluating the security of the generated code. Second, existing evaluation metrics primarily focus on the func
    
[^66]: SCPO: 安全批判策略优化下的安全强化学习

    SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization. (arXiv:2311.00880v1 [cs.LG])

    [http://arxiv.org/abs/2311.00880](http://arxiv.org/abs/2311.00880)

    SCPO是一种安全强化学习算法，通过引入安全批判器来确保遵守安全约束并平衡回报的最大化。

    

    将安全性纳入强化学习在现实场景中的实际应用中是必不可少的。为了应对这一挑战，我们利用了约束马尔可夫决策过程（CMDPs），引入了表示安全违规的独立成本函数。在CMDPs的设置中，先前的算法采用了拉格朗日松弛技术将约束优化问题转化为无约束对偶问题。然而，这些算法可能会不准确地预测不安全行为，导致在学习拉格朗日乘子时产生不稳定性。本研究介绍了一种新的安全强化学习算法——安全批判策略优化（SCPO）。在本研究中，我们定义了安全批判器，一种通过违反安全约束而获得的奖励被抵消的机制。此外，我们的理论分析表明，所提出的算法可以自动平衡在遵守安全约束和最大化回报之间的权衡。

    Incorporating safety is an essential prerequisite for broadening the practical applications of reinforcement learning in real-world scenarios. To tackle this challenge, Constrained Markov Decision Processes (CMDPs) are leveraged, which introduce a distinct cost function representing safety violations. In CMDPs' settings, Lagrangian relaxation technique has been employed in previous algorithms to convert constrained optimization problems into unconstrained dual problems. However, these algorithms may inaccurately predict unsafe behavior, resulting in instability while learning the Lagrange multiplier. This study introduces a novel safe reinforcement learning algorithm, Safety Critic Policy Optimization (SCPO). In this study, we define the safety critic, a mechanism that nullifies rewards obtained through violating safety constraints. Furthermore, our theoretical analysis indicates that the proposed algorithm can automatically balance the trade-off between adhering to safety constraints 
    
[^67]: 选择性分享体验提升多智能体强化学习

    Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning. (arXiv:2311.00865v1 [cs.LG])

    [http://arxiv.org/abs/2311.00865](http://arxiv.org/abs/2311.00865)

    本文介绍了一种选择性多智能体强化学习方法，即选择性多智能体优先体验中继，代理之间共享有限数量的训练经验。与其他算法相比，该方法实现了去中心化训练，并取得了比基准算法和最先进算法更好的性能。

    

    我们提出了一种新颖的多智能体强化学习方法，即选择性多智能体优先体验中继，其中代理通过分享训练过程中观察到的有限的转换与其他代理共享。其背后的直觉是，来自其他代理的少量相关经验可以帮助每个代理学习。与许多其他多智能体强化学习算法不同，该方法允许基本去中心化的训练，只需要代理之间的有限通信渠道。我们展示了我们的方法优于基准无共享去中心化训练和最先进的多智能体强化学习算法。此外，仅分享少量高度相关的经验优于代理之间的所有经验共享，而且选择性体验共享的性能提升在各种超参数和DQN变体中均具有鲁棒性。我们的算法的参考实现可在https://github.com/mgerstgrasser/super获得。

    We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized Experience Relay, in which agents share with other agents a limited number of transitions they observe during training. The intuition behind this is that even a small number of relevant experiences from other agents could help each agent learn. Unlike many other multi-agent RL algorithms, this approach allows for largely decentralized training, requiring only a limited communication channel between agents. We show that our approach outperforms baseline no-sharing decentralized training and state-of-the art multi-agent RL algorithms. Further, sharing only a small number of highly relevant experiences outperforms sharing all experiences between agents, and the performance uplift from selective experience sharing is robust across a range of hyperparameters and DQN variants. A reference implementation of our algorithm is available at https://github.com/mgerstgrasser/super.
    
[^68]: 零坐标移动：针对物理约束操作学习的优化自动微分方法

    Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning. (arXiv:2311.00860v1 [cs.LG])

    [http://arxiv.org/abs/2311.00860](http://arxiv.org/abs/2311.00860)

    本文提出了一种用于物理约束操作学习的新型自动微分算法，通过零坐标移动（ZCS）的技巧，将所需导数的复杂度从“多根多叶”简化为“一根多叶”，从而显著提高了性能。

    

    自动微分（AD）是物理约束机器学习中的关键步骤，用于计算网络输出相对于坐标的高阶导数。本文提出了一种新颖且轻量级的算法，用于进行针对物理约束操作学习的自动微分，称为零坐标移动（ZCS）的技巧。ZCS引入了一个标量值的叶变量，用于每个空间或时间维度，通过将所需导数从“多根多叶”简化为“一根多叶”，从而实现了性能的巨大提升。ZCS很容易在当前的深度学习库中实现；我们使用DeepXDE软件包进行了自己的实现。我们进行了全面的基准分析和多个案例研究，训练物理约束的DeepONets来解决无数据的偏微分方程（PDE）。结果表明，ZCS一直通过降低GPU内存消耗提供了改进效果。

    Automatic differentiation (AD) is a critical step in physics-informed machine learning, required for computing the high-order derivatives of network output w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm to conduct such AD for physics-informed operator learning, as we call the trick of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf variables, ZCS introduces only one scalar-valued leaf variable for each spatial or temporal dimension, leading to a game-changing performance leap by simplifying the wanted derivatives from "many-roots-many-leaves" to "one-root-many-leaves". ZCS is easy to implement with current deep learning libraries; our own implementation is by extending the DeepXDE package. We carry out a comprehensive benchmark analysis and several case studies, training physics-informed DeepONets to solve partial differential equations (PDEs) without data. The results show that ZCS has persistently brought down GPU memory co
    
[^69]: 多智能体系统中基于最优成本约束的对抗攻击

    Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems. (arXiv:2311.00859v1 [cs.LG])

    [http://arxiv.org/abs/2311.00859](http://arxiv.org/abs/2311.00859)

    本研究提出了一种基于最优成本约束的分布式攻击代理的对抗攻击方法，可以在多智能体系统中显著降低受攻击代理获得的奖励。

    

    寻找最优的对抗攻击策略是强化学习和马尔可夫决策过程中的重要课题。先前的研究通常假设一个全知的协调者（攻击者），攻击不同的接收者（受害者）代理会产生统一的成本。然而，在现实中，攻击通常需要由分布式攻击代理执行，而不是使用一个无限制的中心攻击者。我们在多智能体系统中提出了一个问题，即如何使用分布式攻击代理进行最优的对抗代理间攻击，其中对每个不同的攻击者-受害者对都施加不同的成本约束。我们提出了一种最优方法，通过在步骤内进行静态约束攻击资源分配优化，并在步骤间进行动态规划，以实现多智能体系统中的最优对抗攻击。我们的数值结果表明，所提出的攻击能够显著降低受攻击代理所获得的奖励。

    Finding optimal adversarial attack strategies is an important topic in reinforcement learning and the Markov decision process. Previous studies usually assume one all-knowing coordinator (attacker) for whom attacking different recipient (victim) agents incurs uniform costs. However, in reality, instead of using one limitless central attacker, the attacks often need to be performed by distributed attack agents. We formulate the problem of performing optimal adversarial agent-to-agent attacks using distributed attack agents, in which we impose distinct cost constraints on each different attacker-victim pair. We propose an optimal method integrating within-step static constrained attack-resource allocation optimization and between-step dynamic programming to achieve the optimal adversarial attack in a multi-agent system. Our numerical results show that the proposed attacks can significantly reduce the rewards received by the attacked agents.
    
[^70]: 一种用于评估美国终结HIV流行计划的多智能体强化学习框架

    A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. Ending the HIV Epidemic Plan. (arXiv:2311.00855v1 [cs.AI])

    [http://arxiv.org/abs/2311.00855](http://arxiv.org/abs/2311.00855)

    本论文提出了一种多智能体强化学习（MARL）框架，用于评估美国终结HIV流行计划。该框架能够进行特定地区的决策分析，并考虑到地区之间的流行病学相互作用。

    

    人类免疫缺陷病毒（HIV）是美国的主要公共卫生问题，每年有约1.2万人感染HIV，其中有3.5万人是新感染者。美国的HIV负担和护理接触存在着地理差异。2019年的终结HIV流行计划旨在到2030年将新感染人数减少90%，通过提高诊断、治疗和预防干预措施的覆盖率，并优先考虑HIV高流行地区。确定最佳干预措施的规模扩大将有助于资源分配的决策。现有的HIV决策模型要么只评估特定城市，要么评估整个国家人口，忽视地方的相互作用或差异。在本文中，我们提出了一种多智能体强化学习（MARL）模型，它能够进行特定地区的决策分析，同时考虑跨地区的流行病互动。在实验分析中，

    Human immunodeficiency virus (HIV) is a major public health concern in the United States, with about 1.2 million people living with HIV and 35,000 newly infected each year. There are considerable geographical disparities in HIV burden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE) initiative aims to reduce new infections by 90% by 2030, by improving coverage of diagnoses, treatment, and prevention interventions and prioritizing jurisdictions with high HIV prevalence. Identifying optimal scale-up of intervention combinations will help inform resource allocation. Existing HIV decision analytic models either evaluate specific cities or the overall national population, thus overlooking jurisdictional interactions or differences. In this paper, we propose a multi-agent reinforcement learning (MARL) model, that enables jurisdiction-specific decision analyses but in an environment with cross-jurisdictional epidemiological interactions. In experimental analyses, conduct
    
[^71]: healthAIChain: 使用区块链技术改进AI医疗系统的安全性和安全性

    healthAIChain: Improving security and safety using Blockchain Technology applications in AI-based healthcare systems. (arXiv:2311.00842v1 [cs.CR])

    [http://arxiv.org/abs/2311.00842](http://arxiv.org/abs/2311.00842)

    healthAIChain使用区块链技术改进AI医疗系统的安全性和安全性，解决了医疗保健系统中与安全性，性能效率和安全性相关的问题。

    

    区块链作为一种数字分类帐，用于记录数字交易和其他信息，是一种安全且去中心化的技术。每天全球数字人口的增长对在线数据，包括医疗和患者数据构成了重大威胁。区块链技术在医疗行业和医疗保健中应用广泛，可以在保持最高安全标准的同时促进高度可配置的开放性，用于医疗患者的关键数据的分布式记录保存，使数字资产不可改变且透明，通过加密哈希和去中心化网络。该研究深入探讨了在基于AI的医疗保健系统中实施区块链所带来的安全性和安全性改进。区块链启用的AI解决了医疗保健系统中与安全性，性能效率和安全性相关的现有问题。

    Blockchain as a digital ledger for keeping records of digital transactions and other information, it is secure and decentralized technology. The globally growing number of digital population every day possesses a significant threat to online data including the medical and patients data. After bitcoin, blockchain technology has emerged into a general-purpose technology with applications in medical industries and healthcare. Blockchain can promote highly configurable openness while retaining the highest security standards for critical data of medical patients. Referred to as distributed record keeping for healthcare systems which makes digital assets unalterable and transparent via a cryptographic hash and decentralized network. The study delves into the security and safety improvement associated with implementing blockchain in AI-based healthcare systems. Blockchain-enabled AI tackles the existing issues related to security, performance efficiencies, and safety in healthcare systems. We
    
[^72]: 任意时间提炼的恒定时间运动规划和操纵

    Constant-time Motion Planning with Anytime Refinement for Manipulation. (arXiv:2311.00837v1 [cs.RO])

    [http://arxiv.org/abs/2311.00837](http://arxiv.org/abs/2311.00837)

    我们提出了一种任意时间提炼方法，结合恒定时间动作规划器（CTMP）在机器人操作中改善解决方案。这种方法利用机器人系统拥有的多余计划时间来完善运动规划的结果。

    

    机器人操作器对于未来的自主系统至关重要，但对其自主性的信任有限，将其限制为刚性、任务特定的系统。操作器的复杂配置空间，以及避障和约束满足的挑战经常使得运动规划成为实现可靠和适应性自主性的瓶颈。最近，引入了一类恒定时间运动规划器（CTMP）。这些规划器利用预处理阶段计算数据结构，能够在用户定义的时间限制内生成运动规划，虽然可能并不是最优解。这个框架在许多时间关键的任务中被证明是有效的。然而，机器人系统通常有比CTMP所需的在线部分更多的计划时间，这些时间可以用来改善解决方案。为此，我们提出了一个在CTMP中与任意时间提炼方法结合使用的方法。

    Robotic manipulators are essential for future autonomous systems, yet limited trust in their autonomy has confined them to rigid, task-specific systems. The intricate configuration space of manipulators, coupled with the challenges of obstacle avoidance and constraint satisfaction, often makes motion planning the bottleneck for achieving reliable and adaptable autonomy. Recently, a class of constant-time motion planners (CTMP) was introduced. These planners employ a preprocessing phase to compute data structures that enable online planning provably guarantee the ability to generate motion plans, potentially sub-optimal, within a user defined time bound. This framework has been demonstrated to be effective in a number of time-critical tasks. However, robotic systems often have more time allotted for planning than the online portion of CTMP requires, time that can be used to improve the solution. To this end, we propose an anytime refinement approach that works in combination with CTMP a
    
[^73]: 超越静止图像：强大的多流时空网络

    Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks. (arXiv:2311.00800v1 [cs.CV])

    [http://arxiv.org/abs/2311.00800](http://arxiv.org/abs/2311.00800)

    本论文通过引入包括时间特征的多流模型，提出了一个经过视频训练的鲁棒性模型，通过在训练中包括视频和时间流，减少了图像和视频理解任务的准确性下降率。

    

    自然视觉的一个定义特征是其能够承受各种输入变化，从而创建周围环境的不变表示。虽然卷积神经网络对某些形式的空间输入变化具有韧性，但空间和时间方面的修改可以显着影响深度神经网络中视频内容的表示。受自然视觉对输入变化的韧性启发，我们使用一个简单的多流模型来探索其通过包含时间特征来处理时空变化的潜力。我们的主要目标是引入一个经过视频训练的模型，并评估其对多样的图像和视频输入的鲁棒性，特别关注时间特征在不变识别中的作用。结果表明，训练时包括视频和时间流可以将图像和视频理解任务的准确性和mAP下降率减少1.36%和3.14%。

    A defining characteristic of natural vision is its ability to withstand a variety of input alterations, resulting in the creation of an invariant representation of the surroundings. While convolutional neural networks exhibit resilience to certain forms of spatial input variation, modifications in the spatial and temporal aspects can significantly affect the representations of video content in deep neural networks. Inspired by the resilience of natural vision to input variations, we employ a simple multi-stream model to explore its potential to address spatiotemporal changes by including temporal features. Our primary goal is to introduce a video-trained model and evaluate its robustness to diverse image and video inputs, with a particular focus on exploring the role of temporal features in invariant recognition. Results show that including videos and the temporal stream during training mitigates the decline in accuracy and mAP in image and video understanding tasks by 1.36% and 3.14%,
    
[^74]: 演化流行病学网络的临界转折点：机器学习辅助的数据驱动有效建模

    Tipping Points of Evolving Epidemiological Networks: Machine Learning-Assisted, Data-Driven Effective Modeling. (arXiv:2311.00797v1 [cs.LG])

    [http://arxiv.org/abs/2311.00797](http://arxiv.org/abs/2311.00797)

    该论文通过机器学习辅助的数据驱动建模方法，研究了自适应易感-感染-易感流行病学网络的临界转折点集体动力学。他们识别出了一个有效的随机微分方程以描述网络的演化行为，并观察到了罕见的大幅度集体振荡现象。

    

    我们通过数据驱动的、机器学习辅助的方式研究自适应易感-感染-易感(SIS)流行病学网络的临界转折点集体动力学。我们通过受数值随机积分器启发的深度学习ResNet架构，识别出一个参数相关的基于物理意义的粗粒度均场变量的有效随机微分方程(eSDE)。我们基于eSDE的确定偏移项构建了一个近似的有效分岔图，并将其与均场SIS模型的分岔图进行对比。我们观察到演化网络的有效SIS动力学中的次临界Hopf分岔，它引起了临界转折行为；这表现为大幅度的集体振荡，它们从(噪声的)固定状态的邻域中自发地、罕见地出现。我们通过重复的暴力模拟和使用已建立的数学工具研究了这些罕见事件的统计特性。

    We study the tipping point collective dynamics of an adaptive susceptible-infected-susceptible (SIS) epidemiological network in a data-driven, machine learning-assisted manner. We identify a parameter-dependent effective stochastic differential equation (eSDE) in terms of physically meaningful coarse mean-field variables through a deep-learning ResNet architecture inspired by numerical stochastic integrators. We construct an approximate effective bifurcation diagram based on the identified drift term of the eSDE and contrast it with the mean-field SIS model bifurcation diagram. We observe a subcritical Hopf bifurcation in the evolving network's effective SIS dynamics, that causes the tipping point behavior; this takes the form of large amplitude collective oscillations that spontaneously -- yet rarely -arise from the neighborhood of a (noisy) stationary state. We study the statistics of these rare events both through repeated brute force simulations and by using established mathemati
    
[^75]: SAGE: 具有基于实际执行的智能家居助手

    SAGE: Smart home Agent with Grounded Execution. (arXiv:2311.00772v1 [cs.AI])

    [http://arxiv.org/abs/2311.00772](http://arxiv.org/abs/2311.00772)

    SAGE框架通过替换手动定义的推理逻辑，实现了基于实际执行的智能家居助手，提高了灵活性。它可以学习用户偏好，与设备交互，监视设备，并理解自然的设备引用。在评估中，SAGE在43个智能家居任务中成功完成了23个任务，优于现有的LLM基准。

    

    本文介绍了SAGE（具有基于实际执行的智能家居助手）框架，该框架通过将手动定义的推理逻辑替换为LLM驱动的自主代理系统，以最大程度地提高智能家居助手的灵活性。SAGE通过协调一系列工具整合用户偏好、设备状态和外部因素（如天气和电视节目表）。SAGE的功能包括从自然语言表达中学习用户偏好，通过阅读设备的API文档与设备交互，编写代码以持续监视设备，并理解自然的设备引用。为了评估SAGE，我们开发了一个包含43个高度挑战的智能家居任务的基准，SAGE成功完成了23个任务，显著优于现有的LLM基准（5/43）。

    This article introduces SAGE (Smart home Agent with Grounded Execution), a framework designed to maximize the flexibility of smart home assistants by replacing manually-defined inference logic with an LLM-powered autonomous agent system. SAGE integrates information about user preferences, device states, and external factors (such as weather and TV schedules) through the orchestration of a collection of tools. SAGE's capabilities include learning user preferences from natural-language utterances, interacting with devices by reading their API documentation, writing code to continuously monitor devices, and understanding natural device references. To evaluate SAGE, we develop a benchmark of 43 highly challenging smart home tasks, where SAGE successfully achieves 23 tasks, significantly outperforming existing LLM-enabled baselines (5/43).
    
[^76]: 在Praxis数据集上的手势分类：以精确性为代价

    Hand Gesture Classification on Praxis Dataset: Trading Accuracy for Expense. (arXiv:2311.00767v1 [cs.AI])

    [http://arxiv.org/abs/2311.00767](http://arxiv.org/abs/2311.00767)

    本文研究了在Praxis数据集上的手势分类问题，提出了一种基于身体关节数据和深度学习的手势分类器模型，相比之前的模型更有效。通过使用窗口技术和循环神经网络（RNN）结构，仅使用身体关节数据就达到了70.8%的准确率。此外，还研究了一种长短时记忆（LSTM）方法来提取和分析关节运动特征以识别手势。

    

    本文研究了依靠通过RGB-Depth传感器记录的抽象化的“骨骼”数据的手势分类器。我们关注Praxis数据集中由身体关节坐标表示的“骨骼”数据。Praxis数据集包含了患有大脑皮层病理（如阿尔茨海默病）的患者在临床医师指导下进行Praxis测试的记录。本文提出的手势分类器在Praxis数据集上比之前提出的模型更有效。身体关节数据提供了一种可以专门用于手势识别的压缩数据形式。通过使用窗口技术与循环神经网络（RNN）等深度学习架构的结合，我们仅使用身体关节数据就达到了70.8%的整体准确率。此外，我们还研究了一种长短时记忆（LSTM）方法，以提取和分析关节的运动特征以识别正在执行的手势。

    In this paper, we investigate hand gesture classifiers that rely upon the abstracted 'skeletal' data recorded using the RGB-Depth sensor. We focus on 'skeletal' data represented by the body joint coordinates, from the Praxis dataset. The PRAXIS dataset contains recordings of patients with cortical pathologies such as Alzheimer's disease, performing a Praxis test under the direction of a clinician. In this paper, we propose hand gesture classifiers that are more effective with the PRAXIS dataset than previously proposed models. Body joint data offers a compressed form of data that can be analyzed specifically for hand gesture recognition. Using a combination of windowing techniques with deep learning architecture such as a Recurrent Neural Network (RNN), we achieved an overall accuracy of 70.8% using only body joint data. In addition, we investigated a long-short-term-memory (LSTM) to extract and analyze the movement of the joints through time to recognize the hand gestures being perfor
    
[^77]: 学习设计和使用机器人操纵工具

    Learning to Design and Use Tools for Robotic Manipulation. (arXiv:2311.00754v1 [cs.RO])

    [http://arxiv.org/abs/2311.00754](http://arxiv.org/abs/2311.00754)

    本论文提出了学习一种设计策略来制作适用于不同任务的专用工具，并通过这些工具进行机器人操纵。这可以解锁机器人的额外能力。

    

    当面临自身形态限制时，人类和某些动物种类具有使用环境中的物体来完成原本不可能的任务的能力。机器人可能通过使用工具解锁一系列额外的能力。最近的通过深度学习来联合优化形态和控制的技术在设计移动机器人方面非常有效。但是，尽管输出一个单一的形态对于移动来说是有意义的，但是操纵涉及到根据手头的任务目标采用各种策略。一个操纵机器人必须能够快速制作出适用于不同目标的专用工具。因此，我们提出学习一个设计策略，而不是一个单一的设计。设计策略以任务信息为条件，并输出一个有助于解决任务的工具设计。然后，一个以设计条件为基础的控制策略可以使用这些工具进行操纵。在这项工作中，我们朝着这个目标迈出了一步，引入了一种强化学习方法。

    When limited by their own morphologies, humans and some species of animals have the remarkable ability to use objects from the environment toward accomplishing otherwise impossible tasks. Robots might similarly unlock a range of additional capabilities through tool use. Recent techniques for jointly optimizing morphology and control via deep learning are effective at designing locomotion agents. But while outputting a single morphology makes sense for locomotion, manipulation involves a variety of strategies depending on the task goals at hand. A manipulation agent must be capable of rapidly prototyping specialized tools for different goals. Therefore, we propose learning a designer policy, rather than a single design. A designer policy is conditioned on task information and outputs a tool design that helps solve the task. A design-conditioned controller policy can then perform manipulation using these tools. In this work, we take a step towards this goal by introducing a reinforcement
    
[^78]: 这些是同一个苹果吗？基于物体内在特性比较图像

    Are These the Same Apple? Comparing Images Based on Object Intrinsics. (arXiv:2311.00750v1 [cs.CV])

    [http://arxiv.org/abs/2311.00750](http://arxiv.org/abs/2311.00750)

    本研究提出了一种基于物体内在特性的图像相似度度量方法，通过对通用对象类别进行扩展，并收集了大规模的CUTE数据集来评估该方法。

    

    人类视觉系统可以轻松识别在不同的外在因素下（如光照、物体姿势和背景）的对象，然而当前的计算机视觉系统在这些变异方面经常遇到困难。理解和改进人工视觉系统的重要一步是纯基于定义对象身份的内在物体特性来测量图像相似性。这个问题在计算机视觉文献中已被研究为重新识别，尽管主要局限于特定的对象类别如人和汽车。我们提出将其扩展到通用对象类别，探索基于物体内在特性的图像相似度度量。为了评估这种测量方法，我们收集了Common paired objects Under differenT Extrinsics (CUTE)数据集，包括180个对象的18000张图像，涵盖了不同的外在因素，如光照、姿势和成像条件。然而，现有的方法如LPIPS和CLIP分数并不能很好地测量物体内在特性。

    The human visual system can effortlessly recognize an object under different extrinsic factors such as lighting, object poses, and background, yet current computer vision systems often struggle with these variations. An important step to understanding and improving artificial vision systems is to measure image similarity purely based on intrinsic object properties that define object identity. This problem has been studied in the computer vision literature as re-identification, though mostly restricted to specific object categories such as people and cars. We propose to extend it to general object categories, exploring an image similarity metric based on object intrinsics. To benchmark such measurements, we collect the Common paired objects Under differenT Extrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different extrinsic factors such as lighting, poses, and imaging conditions. While existing methods such as LPIPS and CLIP scores do not measure object intrinsics wel
    
[^79]: 基于基础模型的观察、对话和引导：制作蛋糕

    Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?. (arXiv:2311.00738v1 [cs.AI])

    [http://arxiv.org/abs/2311.00738](http://arxiv.org/abs/2311.00738)

    本文介绍了一个新的多模态基准数据集，观察、对话和引导（WTaG），以及两个任务：用户和环境理解以及指导者决策。研究发现，基础模型在感知化任务引导方面有一定的性能，但快速而可靠的适应仍然是一个挑战。

    

    尽管人工智能取得了巨大进步，但开发能够提供情境化、个性化指导并协助人类进行各种任务的交互式任务引导系统仍然是一个重大挑战。这些系统需要对用户和环境有深入的理解，并及时准确地决定何时以及要说什么。为了解决这个问题，我们创建了一个新的多模态基准数据集，Watch, Talk and Guide（WTaG），基于人类用户和人类指导者之间的自然交互。我们进一步提出了两个任务：用户和环境理解以及指导者决策。我们利用了几个基础模型来研究这些模型在感知化任务引导方面的快速适应程度。我们的定量、定性和人类评估结果表明，这些模型在某些情况下可以展示出公平的性能，即使没有特定任务的训练，但快速而可靠的适应仍然是一个重大挑战。

    Despite tremendous advances in AI, it remains a significant challenge to develop interactive task guidance systems that can offer situated, personalized guidance and assist humans in various tasks. These systems need to have a sophisticated understanding of the user as well as the environment, and make timely accurate decisions on when and what to say. To address this issue, we created a new multimodal benchmark dataset, Watch, Talk and Guide (WTaG) based on natural interaction between a human user and a human instructor. We further proposed two tasks: User and Environment Understanding, and Instructor Decision Making. We leveraged several foundation models to study to what extent these models can be quickly adapted to perceptually enabled task guidance. Our quantitative, qualitative, and human evaluation results show that these models can demonstrate fair performances in some cases with no task-specific training, but a fast and reliable adaptation remains a significant challenge. Our 
    
[^80]: tmn在#SMM4H 2023上的论文:比较用于检测自我报告COVID-19诊断推文的文本预处理技术

    tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for Detecting Tweets Self-reporting a COVID-19 Diagnosis. (arXiv:2311.00732v1 [cs.CL])

    [http://arxiv.org/abs/2311.00732](http://arxiv.org/abs/2311.00732)

    本文研究了用于检测自我报告COVID-19诊断推文的不同文本预处理技术，通过使用四个基于transformer的模型进行实验，并通过微调语言模型集成获得了比平均值高出4.1%的84.5%的F1得分。

    

    本文描述了一个用于SMM4H 2023任务1的系统。该任务的目标是自动区分那些自我报告COVID-19诊断的推文（例如，阳性检测、临床诊断或住院）和那些没有的推文。我们使用四个基于transformer的模型研究了不同的推文预处理技术。经过微调的语言模型集成获得了84.5%的F1得分，比平均值高出4.1%。

    The paper describes a system developed for Task 1 at SMM4H 2023. The goal of the task is to automatically distinguish tweets that self-report a COVID-19 diagnosis (for example, a positive test, clinical diagnosis, or hospitalization) from those that do not. We investigate the use of different techniques for preprocessing tweets using four transformer-based models. The ensemble of fine-tuned language models obtained an F1-score of 84.5%, which is 4.1% higher than the average value.
    
[^81]: ZEETAD: 为零样本端到端时间动作检测改进预训练的视觉-语言模型

    ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection. (arXiv:2311.00729v1 [cs.CV])

    [http://arxiv.org/abs/2311.00729](http://arxiv.org/abs/2311.00729)

    ZEETAD是一个零样本端到端时间动作检测模型，其中包括双定位和零样本提议分类两个模块。前者是基于Transformer的模块，用于检测动作事件并收集关键的语义嵌入，后者是基于CLIP的模块，用于生成文本和帧输入的语义嵌入。

    

    时间动作检测（TAD）涉及在非剪辑视频中定位和分类动作实例。尽管传统TAD在大量训练数据上采用完全监督学习和封闭集设置，但最近的零样本TAD方法通过利用大规模对比的视觉-语言（ViL）预训练模型展示了开放集设置的潜力。然而，现有的零样本TAD方法在如何适当构建定位和分类这两个相互依赖的任务之间的强关系以及将ViL模型适应于视频理解方面存在局限性。在这项工作中，我们提出了ZEETAD，包含两个模块：双定位和零样本提议分类。前者是基于Transformer的模块，用于检测动作事件，并选择性地收集关键的语义嵌入以供后续识别。后者是基于CLIP的模块，用于为每个时间单位从文本和帧输入生成语义嵌入。

    Temporal action detection (TAD) involves the localization and classification of action instances within untrimmed videos. While standard TAD follows fully supervised learning with closed-set setting on large training data, recent zero-shot TAD methods showcase the promising of open-set setting by leveraging large-scale contrastive visual-language (ViL) pretrained models. However, existing zero-shot TAD methods have limitations on how to properly construct the strong relationships between two interdependent tasks of localization and classification and adapt ViL model to video understanding. In this work, we present ZEETAD, featuring two modules: dual-localization and zero-shot proposal classification. The former is a Transformer-based module that detects action events while selectively collecting crucial semantic embeddings for later recognition. The latter one, CLIP-based module, generates semantic embeddings from text and frame inputs for each temporal unit. Additionally, we enhance d
    
[^82]: 研究迁移学习和元学习的相对性能

    Investigating Relative Performance of Transfer and Meta Learning. (arXiv:2311.00727v1 [cs.LG])

    [http://arxiv.org/abs/2311.00727](http://arxiv.org/abs/2311.00727)

    本文研究了迁移学习和元学习作为解决有限数据学习问题的两种方法的相对性能，以建立一个在不同的机器学习场景中选择最适合的方法的稳健标准。

    

    过去十年来，机器学习领域取得了显著的进展。尽管图像识别系统在准确度方面取得了令人印象深刻的成就，但它们仍然依赖于大量的训练数据集。此外，一个重要挑战是在分布外性能方面表现不佳，这要求当神经网络遇到与其训练数据不一致的条件时重新训练。这个限制显著影响了自动驾驶技术的进展。这些紧迫问题引发了对使神经网络能够有效地从有限数据中学习的方法的广泛关注。本文介绍了一项旨在比较两种不同方法——迁移学习和元学习的研究成果，作为解决这个问题的潜在方案。总体目标是建立一个在不同的机器学习场景中选择最适合的方法的稳健标准。

    Over the past decade, the field of machine learning has experienced remarkable advancements. While image recognition systems have achieved impressive levels of accuracy, they continue to rely on extensive training datasets. Additionally, a significant challenge has emerged in the form of poor out-of-distribution performance, which necessitates retraining neural networks when they encounter conditions that deviate from their training data. This limitation has notably contributed to the slow progress in self-driving car technology. These pressing issues have sparked considerable interest in methods that enable neural networks to learn effectively from limited data. This paper presents the outcomes of an extensive investigation designed to compare two distinct approaches, transfer learning and meta learning, as potential solutions to this problem. The overarching objective was to establish a robust criterion for selecting the most suitable method in diverse machine learning scenarios. Bui
    
[^83]: 利用机器学习和大数据分析技术进行电信行业的欺诈分析

    Fraud Analytics Using Machine-learning & Engineering on Big Data (FAME) for Telecom. (arXiv:2311.00724v1 [cs.LG])

    [http://arxiv.org/abs/2311.00724](http://arxiv.org/abs/2311.00724)

    本文提出了一种工业化解决方案，利用自适应数据挖掘技术和大数据技术来准确、高效、低成本地检测电信行业的欺诈。已成功应用于检测国际收入分成欺诈，并发现了新的欺诈模式。

    

    电信行业由于欺诈行为每年全球损失463亿美元。过去使用数据挖掘和机器学习技术（除了规则导向方法）来进行欺诈检测，但效率很低，因为欺诈模式变化非常快。本文提出了一种工业化解决方案，采用自适应数据挖掘技术和大数据技术来准确、高效、低成本地检测欺诈并发现新的欺诈模式。该解决方案已成功应用于<5%的误报率检测国际收入分成欺诈。本研究使用了来自知名批发运营商和海外电信中转运营商的超过1TB的通话详单记录进行实证研究。

    Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining and machine learning techniques (apart from rules oriented approach) have been used in past, but efficiency has been low as fraud pattern changes very rapidly. This paper presents an industrialized solution approach with self adaptive data mining technique and application of big data technologies to detect fraud and discover novel fraud patterns in accurate, efficient and cost effective manner. Solution has been successfully demonstrated to detect International Revenue Share Fraud with <5% false positive. More than 1 Terra Bytes of Call Detail Record from a reputed wholesale carrier and overseas telecom transit carrier has been used to conduct this study.
    
[^84]: AI互动中的AI对齐：规范对齐，过程对齐和评估支持

    AI Alignment in the Design of Interactive AI: Specification Alignment, Process Alignment, and Evaluation Support. (arXiv:2311.00710v1 [cs.HC])

    [http://arxiv.org/abs/2311.00710](http://arxiv.org/abs/2311.00710)

    本文关注AI在界面设计和评估中的对齐问题，提出了规范对齐、过程对齐和评估支持等三个对齐目标，并介绍了代理过程和过程海湾的概念。

    

    AI对齐是确保AI产生期望结果而避免不良副作用的整体问题。虽然通常从安全和人类价值的角度考虑AI对齐，但也可以在设计和评估交互式AI系统的界面的背景下考虑AI对齐。本文将AI对齐的概念映射到基本的三步交互循环中，得出相应的对齐目标：1）规范对齐：确保用户能够高效可靠地将目标传达给AI；2）过程对齐：提供验证和可选择控制AI执行过程的能力；3）评估支持：确保用户能够验证和理解AI的输出。我们还介绍了代理过程的概念，它被定义为AI实际过程的简化、分离派生但可控制的表示；以及过程海湾的概念，它突显人类和AI过程之间的差异。

    AI alignment considers the overall problem of ensuring an AI produces desired outcomes, without undesirable side effects. While often considered from the perspectives of safety and human values, AI alignment can also be considered in the context of designing and evaluating interfaces for interactive AI systems. This paper maps concepts from AI alignment onto a basic, three step interaction cycle, yielding a corresponding set of alignment objectives: 1) specification alignment: ensuring the user can efficiently and reliably communicate objectives to the AI, 2) process alignment: providing the ability to verify and optionally control the AI's execution process, and 3) evaluation support: ensuring the user can verify and understand the AI's output. We also introduce the concepts of a surrogate process, defined as a simplified, separately derived, but controllable representation of the AI's actual process; and the notion of a Process Gulf, which highlights how differences between human and
    
[^85]: AI是否可以缓解人类感知偏差？一项实验性研究。

    Can AI Mitigate Human Perceptual Biases? A Pilot Study. (arXiv:2311.00706v1 [cs.HC])

    [http://arxiv.org/abs/2311.00706](http://arxiv.org/abs/2311.00706)

    本研究试图调查机器推荐是否可以缓解人类感知偏差。通过一项实验，发现AI助手在集合任务中的使用可以提高参与者的工作效率，但并没有通过统计学分析证明AI助手可以显著降低“下拉”偏差。此外，延迟AI回应也没有对人类决策准确性产生显著影响。

    

    我们展示了一项旨在衡量机器推荐是否能够纠正人类感知偏差的试点实验结果。我们特别研究了“下拉”效应，即人们低估了线的平均位置，在线图中估计数据点的集合平均值的任务中。这些线图可以显示例如12个月内的温度或降水量。六名参与者使用或不使用AI助手估计集合平均值。当有AI助手时，助手以不同速度回应，以模拟可能延迟回应的人类协作者的条件。我们的试点研究表明，在集合任务中，参与者使用AI助手比没有使用AI助手的基准组更快。尽管“下拉”偏差得到了减少，但AI助手的影响并不具有统计学意义。此外，延迟AI回应对人类决策准确性没有显著影响。我们讨论了这些结果的影响。

    We present results from a pilot experiment to measure if machine recommendations can debias human perceptual biases in visualization tasks. We specifically studied the ``pull-down'' effect, i.e., people underestimate the average position of lines, for the task of estimating the ensemble average of data points in line charts. These line charts can show for example temperature or precipitation in 12 months. Six participants estimated ensemble averages with or without an AI assistant. The assistant, when available, responded at three different speeds to assemble the conditions of a human collaborator who may delay his or her responses. Our pilot study showed that participants were faster with AI assistance in ensemble tasks, compared to the baseline without AI assistance. Although ``pull-down'' biases were reduced, the effect of AI assistance was not statistically significant. Also, delaying AI responses had no significant impact on human decision accuracy. We discuss the implications of 
    
[^86]: 分布式元强化学习中的集体自发开放式探索的出现

    Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning. (arXiv:2311.00651v1 [cs.MA])

    [http://arxiv.org/abs/2311.00651](http://arxiv.org/abs/2311.00651)

    通过分布式元强化学习在开放式任务分布上训练的智能体展现了强大的集体探索能力，从而产生了复杂的合作行为。

    

    最近的研究证明，在自我对战的开放式任务分布中，通过使用元强化学习来训练的智能体可以产生复杂的合作行为。虽然结果令人印象深刻，但我们认为，自我对战和其他集中化训练技术并不能准确地反映自然界中普遍的集体探索策略是如何出现的：通过分布式训练和对任务的无限分布进行训练。因此，在这项工作中，我们研究了集体探索策略的出现，其中多个智能体在一个无限的任务分布中独立地元学习循环策略。为此，我们引入了一个新的环境，它具有一个无限的过程生成的任务空间，动态组合了从五种不同类型的任务中抽样的多个子任务，形成了一个庞大的任务树分布。我们展示了在我们的环境中训练的分散智能体在面对新的目标时展示出强大的泛化能力。

    Recent works have proven that intricate cooperative behaviors can emerge in agents trained using meta reinforcement learning on open ended task distributions using self-play. While the results are impressive, we argue that self-play and other centralized training techniques do not accurately reflect how general collective exploration strategies emerge in the natural world: through decentralized training and over an open-ended distribution of tasks. In this work we therefore investigate the emergence of collective exploration strategies, where several agents meta-learn independent recurrent policies on an open ended distribution of tasks. To this end we introduce a novel environment with an open ended procedurally generated task space which dynamically combines multiple subtasks sampled from five diverse task types to form a vast distribution of task trees. We show that decentralized agents trained in our environment exhibit strong generalization abilities when confronted with novel obj
    
[^87]: 最小修改马尔可夫博弈以实现任意Nash均衡和价值

    Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value. (arXiv:2311.00582v1 [cs.GT])

    [http://arxiv.org/abs/2311.00582](http://arxiv.org/abs/2311.00582)

    该论文研究了游戏修改问题，提出了一种最小修改马尔可夫博弈的方法，使得目标策略配置成为唯一的Nash均衡并具有特定价值范围，同时最小化修改成本。

    

    我们研究了游戏修改问题，其中一位善意的游戏设计者或恶意的对手修改了一个零和马尔可夫博弈的奖励函数，以便一个目标确定性或随机的策略配置成为唯一的马尔可夫完美Nash均衡，并且在目标范围内具有价值，以最小化修改成本。我们表征了能够安装为某个游戏的唯一均衡的策略配置的集合，并建立了成功安装的充分和必要条件。我们提出了一种高效的算法，该算法通过解一个带有线性约束的凸优化问题，然后进行随机扰动，来获得一个成本近乎最优的修改计划。

    We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of some game, and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm, which solves a convex optimization problem with linear constraints and then performs random perturbation, to obtain a modification plan with a near-optimal cost.
    
[^88]: 利用双曲嵌入进行粗细设计的机器人设计

    Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design. (arXiv:2311.00462v1 [cs.AI])

    [http://arxiv.org/abs/2311.00462](http://arxiv.org/abs/2311.00462)

    本文提出了一种新的多细胞机器人粗细设计方法，利用双曲嵌入框架在共享的双曲空间内统一了各种粒度的机器人，并通过改进的交叉熵方法进行优化。这种方法能够自主地在双曲空间中确定探索的区域。

    

    多细胞机器人设计旨在创建由许多细胞组成的机器人，以便能够高效地控制执行各种任务。过去的研究已经证明了生成各种任务的机器人的能力，但这些方法通常直接在庞大的设计空间中对机器人进行优化，导致了难以控制的复杂形态的机器人。为了解决这个问题，本文提出了一种新的多细胞机器人粗细设计方法。该策略首先寻求最佳的粗粒度机器人，然后逐步对其进行精细调整。为了解决在粗细转换过程中确定精细调整关节的挑战，我们引入了用于机器人设计的双曲嵌入 (HERD) 框架。HERD 在一个共享的双曲空间内统一了各种粒度的机器人，并利用改进的交叉熵方法进行优化。这个框架使得我们的方法能够自主地在双曲空间中确定探索的区域。

    Multi-cellular robot design aims to create robots comprised of numerous cells that can be efficiently controlled to perform diverse tasks. Previous research has demonstrated the ability to generate robots for various tasks, but these approaches often optimize robots directly in the vast design space, resulting in robots with complicated morphologies that are hard to control. In response, this paper presents a novel coarse-to-fine method for designing multi-cellular robots. Initially, this strategy seeks optimal coarse-grained robots and progressively refines them. To mitigate the challenge of determining the precise refinement juncture during the coarse-to-fine transition, we introduce the Hyperbolic Embeddings for Robot Design (HERD) framework. HERD unifies robots of various granularity within a shared hyperbolic space and leverages a refined Cross-Entropy Method for optimization. This framework enables our method to autonomously identify areas of exploration in hyperbolic space and c
    
[^89]: 为目标条件智能体定义开放式学习问题

    A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents. (arXiv:2311.00344v1 [cs.AI])

    [http://arxiv.org/abs/2311.00344](http://arxiv.org/abs/2311.00344)

    本文为开放式学习问题定义了一个关键的基本属性，即无限时间内不断产生新元素。在这基础上，提出了开放式学习问题的概念，并着重研究了开放式目标条件强化学习的子集。

    

    近期的许多机器学习研究论文中都提到了“开放式学习”，但很少有人尝试定义这个术语。更糟糕的是，当仔细研究时，似乎对于开放式学习与连续学习、终身学习或自为目的学习等相关概念的区别没有共识。在本文中，我们致力于解决这种情况。通过阐述这个概念的起源和最近的观点，我们说明了开放式学习通常被认为是一个包含多种属性的复合概念。与这些之前的方法不同，我们提出了将开放式过程的一个关键基本属性与时间无限制地产生新元素相分离的想法。基于此，我们建立了开放式学习问题的概念，并特别关注了开放式目标条件强化学习的子集。

    A lot of recent machine learning research papers have "Open-ended learning" in their title. But very few of them attempt to define what they mean when using the term. Even worse, when looking more closely there seems to be no consensus on what distinguishes open-ended learning from related concepts such as continual learning, lifelong learning or autotelic learning. In this paper, we contribute to fixing this situation. After illustrating the genealogy of the concept and more recent perspectives about what it truly means, we outline that open-ended learning is generally conceived as a composite notion encompassing a set of diverse properties. In contrast with these previous approaches, we propose to isolate a key elementary property of open-ended processes, which is to always produce novel elements from time to time over an infinite horizon. From there, we build the notion of open-ended learning problems and focus in particular on the subset of open-ended goal-conditioned reinforcement
    
[^90]: JADE：基于语言的LLM安全评估平台

    JADE: A Linguistic-based Safety Evaluation Platform for LLM. (arXiv:2311.00286v1 [cs.CL])

    [http://arxiv.org/abs/2311.00286](http://arxiv.org/abs/2311.00286)

    JADE是一种基于语言分析的LLM安全评估平台，能够破坏广泛使用的中文和英文LLM，并生成高度威胁的不安全问题。

    

    本文介绍了JADE，一种针对语言分析的模糊测试平台，通过增强种子问题的语言复杂性，同时并始终能够破坏广泛使用的三类LLM：八个开源中文LLM，六个商业中文LLM和四个商业英文LLM。JADE为这三类LLM生成了三个安全基准，其中包含高度威胁的不安全问题：这些问题可以同时触发多个LLM的有害生成，平均不安全生成比例为70%（请参见下表），同时这些问题仍然是自然、流畅且保留了核心的不安全语义。我们在以下链接中发布了对商业英文LLM和开源英文LLM生成的基准演示：https://github.com/whitzard-ai/jade-db。对于对JADE生成的更多问题感兴趣的读者，请与我们联系。

    In this paper, we present \textit{JADE}, a targeted linguistic fuzzing platform which strengthens the linguistic complexity of seed questions to simultaneously and consistently break a wide range of widely-used LLMs categorized in three groups: eight open-sourced Chinese, six commercial Chinese and four commercial English LLMs. JADE generates three safety benchmarks for the three groups of LLMs, which contain unsafe questions that are highly threatening: the questions simultaneously trigger harmful generation of multiple LLMs, with an average unsafe generation ratio of \textbf{$70\%$} (please see the table below), while are still natural questions, fluent and preserving the core unsafe semantics. We release the benchmark demos generated for commercial English LLMs and open-sourced English LLMs in the following link: https://github.com/whitzard-ai/jade-db. For readers who are interested in evaluating on more questions generated by JADE, please contact us.  \textit{JADE} is based on Noam
    
[^91]: 改进的多变量时间序列预测的自动混合模型在BizITOps数据上的应用

    AutoMixer for Improved Multivariate Time-Series Forecasting on BizITOps Data. (arXiv:2310.20280v1 [cs.LG])

    [http://arxiv.org/abs/2310.20280](http://arxiv.org/abs/2310.20280)

    这篇论文提出了AutoMixer，一个基于时间序列基础模型的自动混合模型，通过通道压缩预训练和微调工作流技术，有效解耦了BizITOps数据中有用和嘈杂的跨通道交互，提高了多变量时间序列预测的性能。

    

    业务过程的效率依赖于业务关键绩效指标（Biz-KPIs），而IT故障可能对其产生负面影响。BizITOps数据将Biz-KPIs和IT事件通道融合成多变量时间序列数据。提前预测Biz-KPIs可以通过主动的纠正措施提高效率和收益。然而，BizITOps数据通常展示出Biz-KPIs和IT事件之间有用和嘈杂的跨通道交互，需要有效解耦。当使用现有的多变量预测模型时，这导致预测性能不佳。为了解决这个问题，我们引入了一个称为AutoMixer的时间序列基础模型（FM）方法，该方法基于新颖的通道压缩预训练和微调工作流技术。AutoMixer利用自动编码器进行通道压缩的预训练，并将其与先进的TSMixer模型集成，用于多变量时间序列预测。这种融合极大地增强了TSM

    The efficiency of business processes relies on business key performance indicators (Biz-KPIs), that can be negatively impacted by IT failures. BizITOps data fuses both Biz-KPIs and IT event channels together as multivariate time series data. Forecasting Biz-KPIs in advance can enhance efficiency and revenue through proactive corrective measures. However, BizITOps data generally exhibit both useful and noisy inter-channel interactions between Biz-KPIs and IT events that need to be effectively decoupled. This leads to suboptimal forecasting performance when existing multivariate forecasting models are employed. To address this, we introduce AutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel technique of channel-compressed pretrain and finetune workflows. AutoMixer leverages an AutoEncoder for channel-compressed pretraining and integrates it with the advanced TSMixer model for multivariate time series forecasting. This fusion greatly enhances the potency of TSM
    
[^92]: 意义表征来自自回归模型中的轨迹

    Meaning Representations from Trajectories in Autoregressive Models. (arXiv:2310.18348v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.18348](http://arxiv.org/abs/2310.18348)

    本文提出了一种从自回归语言模型中提取意义表征的方法，通过考虑输入文本的所有可能轨迹的分布。这种方法可以模拟非对称关系，且在语义相似性任务上优于其他方法。

    

    我们提出通过考虑扩展输入文本的所有可能轨迹的分布来从自回归语言模型中提取意义表征。这种策略是无提示的，不需要微调，并适用于任何预训练的自回归模型。此外，与基于向量的表征不同，基于分布的表征还可以通过使用似然函数之间的代数运算来建模非对称关系（例如，逻辑蕴涵的方向，上位词/下位词关系）。这些想法基于语义的分布视角，并与自动机理论中的标准构造相连接，但据我们所知，它们尚未应用于现代语言模型。我们通过实验证明，从大型模型获得的表征与人类注释很好地一致，在语义相似性任务上优于其他零样本和无提示方法，并可用于解决更复杂的蕴涵和包含任务。

    We propose to extract meaning representations from autoregressive language models by considering the distribution of all possible trajectories extending an input text. This strategy is prompt-free, does not require fine-tuning, and is applicable to any pre-trained autoregressive model. Moreover, unlike vector-based representations, distribution-based representations can also model asymmetric relations (e.g., direction of logical entailment, hypernym/hyponym relations) by using algebraic operations between likelihood functions. These ideas are grounded in distributional perspectives on semantics and are connected to standard constructions in automata theory, but to our knowledge they have not been applied to modern language models. We empirically show that the representations obtained from large models align well with human annotations, outperform other zero-shot and prompt-free methods on semantic similarity tasks, and can be used to solve more complex entailment and containment tasks 
    
[^93]: 自主驾驶车辆的交互式运动规划与联合优化

    Interactive Motion Planning for Autonomous Vehicles with Joint Optimization. (arXiv:2310.18301v1 [cs.RO])

    [http://arxiv.org/abs/2310.18301](http://arxiv.org/abs/2310.18301)

    本论文介绍了一种交互式联合规划方法，将模型预测控制（MPC）与基于深度学习的轨迹预测模型结合，实现在高度交互的驾驶场景中为自主驾驶车辆规划安全的运动路径。

    

    在高度交互的驾驶场景中，一个车辆的行动会极大地影响到其周围车辆的行为。因此，在这样的交互环境中为自主驾驶车辆规划安全的运动路径需要考虑自身意图行动对周围车辆行为的影响。近年来，基于深度学习的轨迹预测模型在相关研究中取得了巨大的成功，许多模型都支持以自身条件来进行预测。然而，由于神经网络的复杂性，利用自身条件的预测在下游规划中仍然具有挑战性，限制了规划器的结构，例如采样型规划器。尽管采样型规划器能够生成精细的高质量运动路径，但基于梯度的规划算法，如模型预测控制（MPC），由于其迭代性质和对梯度的需求，很难利用自身条件的预测。我们提出了交互式联合规划（IJP），将MPC与

    In highly interactive driving scenarios, the actions of one agent greatly influences those of its neighbors. Planning safe motions for autonomous vehicles in such interactive environments, therefore, requires reasoning about the impact of the ego's intended motion plan on nearby agents' behavior. Deep-learning-based models have recently achieved great success in trajectory prediction and many models in the literature allow for ego-conditioned prediction. However, leveraging ego-conditioned prediction remains challenging in downstream planning due to the complex nature of neural networks, limiting the planner structure to simple ones, e.g., sampling-based planner. Despite their ability to generate fine-grained high-quality motion plans, it is difficult for gradient-based planning algorithms, such as model predictive control (MPC), to leverage ego-conditioned prediction due to their iterative nature and need for gradient. We present Interactive Joint Planning (IJP) that bridges MPC with 
    
[^94]: 提高通过减少无关文档对开放领域问答中的零样本阅读器的干扰的方法

    Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering. (arXiv:2310.17490v1 [cs.CL])

    [http://arxiv.org/abs/2310.17490](http://arxiv.org/abs/2310.17490)

    本研究提出了一种通过减少无关文档的干扰来改善开放领域问答中的零样本阅读器的方法。采用了干扰感知的答案选择(DAS)方法，以解决LLMs受到干扰和过度自信的问题。实验结果表明，该方法成功地改善了零样本阅读器的性能，并展现出了优越的可迁移性。

    

    大型语言模型(LLMs)使得在开放领域问答(ODQA)中实现零样本方法成为可能，但是由于阅读器相对于检索器的进展有限。本研究旨在探讨一种零样本阅读器的可行性，以解决计算成本和标注数据需求等挑战。我们发现LLMs由于检索到的无关文档以及作为零样本阅读器时生成答案的过度自信而受到干扰。为了解决这些问题，我们采用了基于否定的指令和分数调整的干扰感知的答案选择(DAS)方法，以减轻这些文档的影响。实验结果表明，我们的方法成功地处理了不同场景下的干扰，提高了零样本阅读器的性能。此外，与面对未见过数据而困难重重的监督式阅读器不同，零样本阅读器展现出了优越的可迁移性，无需任何训练。

    Large language models (LLMs) enable zero-shot approaches in open-domain question answering (ODQA), yet with limited advancements as the reader is compared to the retriever. This study aims at the feasibility of a zero-shot reader that addresses the challenges of computational cost and the need for labeled data. We find that LLMs are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers. To tackle these problems, we mitigate the impact of such documents via Distraction-aware Answer Selection (DAS) with a negation-based instruction and score adjustment for proper answer selection. Experimental results show that our approach successfully handles distraction across diverse scenarios, enhancing the performance of zero-shot readers. Furthermore, unlike supervised readers struggling with unseen data, zero-shot readers demonstrate outstanding transferability without any training.
    
[^95]: 时序因果图的抽象中总效应的可识别性研究

    Identifiability of total effects from abstractions of time series causal graphs. (arXiv:2310.14691v2 [math.ST] CROSS LISTED)

    [http://arxiv.org/abs/2310.14691](http://arxiv.org/abs/2310.14691)

    本文研究了基于因果图抽象从观测时间序列中识别干预总效应的问题，并证明了在扩展摘要因果图中总效应总是可识别的。同时，我们提供了摘要因果图中总效应可识别的必要和充分的图形条件，并提供了调整集合以估计总效应。

    

    我们研究了仅基于系统的因果图抽象从观测时间序列中识别干预总效应的问题。具体而言，我们考虑了两种类型的抽象：扩展摘要因果图将所有滞后因果关系混淆在一起，但区分滞后和瞬时关系；而摘要因果图则不提供任何关于因果关系滞后的指示。我们证明扩展摘要因果图中总效应总是可识别的，并且我们提供了摘要因果图中的可识别性所必需和充分的图形条件。此外，在总效应可识别时，我们提供了用于估计总效应的调整集合。

    We study the problem of identifiability of the total effect of an intervention from observational time series only given an abstraction of the causal graph of the system. Specifically, we consider two types of abstractions: the extended summary causal graph which conflates all lagged causal relations but distinguishes between lagged and instantaneous relations; and the summary causal graph which does not give any indication about the lag between causal relations. We show that the total effect is always identifiable in extended summary causal graphs and we provide necessary and sufficient graphical conditions for identifiability in summary causal graphs. Furthermore, we provide adjustment sets allowing to estimate the total effect whenever it is identifiable.
    
[^96]: 对表示一致性达成共识

    Getting aligned on representational alignment. (arXiv:2310.13018v1 [q-bio.NC])

    [http://arxiv.org/abs/2310.13018](http://arxiv.org/abs/2310.13018)

    该论文研究了生物和人工信息处理系统的表示一致性，探讨了不同系统之间的表示是否一致以及如何调整表示以更好地匹配其他系统。为了改善领域之间的交流，提出了一个统一的框架作为共同语言。

    

    生物和人工信息处理系统构建可以用来进行分类、推理、规划、导航和决策的世界表示。这些多样化系统所构建的表示在多大程度上是一致的？即使表示不同，是否仍然能够导致相同的行为？系统如何修改它们的表示以更好地匹配另一个系统的表示？这些关于表示一致性研究的问题是当代认知科学、神经科学和机器学习中一些最活跃的研究领域的核心。不幸的是，对于对表示一致性感兴趣的研究社区之间的知识转移有限，其中大部分在一个领域的进展最终会在另一个领域独立地重新发现，而更广泛的领域间交流将是有利的。为了改善领域之间的交流，我们提出了一个统一的框架，可以作为一种共同的语言。

    Biological and artificial information processing systems form representations of the world that they can use to categorize, reason, plan, navigate, and make decisions. To what extent do the representations formed by these diverse systems agree? Can diverging representations still lead to the same behaviors? And how can systems modify their representations to better match those of another system? These questions pertaining to the study of \textbf{\emph{representational alignment}} are at the heart of some of the most active research areas in contemporary cognitive science, neuroscience, and machine learning. Unfortunately, there is limited knowledge-transfer between research communities interested in representational alignment, and much of the progress in one field ends up being rediscovered independently in another, when greater cross-field communication would be advantageous. To improve communication between fields, we propose a unifying framework that can serve as a common language b
    
[^97]: 利用扩散分离表示来缓解不完全规定的视觉任务中的捷径问题

    Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks. (arXiv:2310.02230v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.02230](http://arxiv.org/abs/2310.02230)

    本文提出了一种利用扩散分离表示来处理不完全规定的视觉任务中捷径学习问题的方法，通过生成合成反事实来促进模型的多样性，从而使模型能够忽略捷径线索并达到与其他方法相当的性能。

    

    数据中的伪相关性，其中多个线索预测目标标签，通常会导致捷径学习现象，即模型可能依赖于错误的、易于学习的线索而忽略可靠线索。在这项工作中，我们提出了一个利用扩散概率模型（DPMs）生成合成反事实的集成多样化框架。我们发现，即使训练数据中这些线索高度相关，DPMs具有独立表示多个视觉线索的固有能力。我们利用这个特性来促进模型的多样性，并在几个多样化目标上实证证明了该方法的有效性。我们展示了扩散引导的多样化可以使模型避开捷径线索的注意，实现了与需要额外数据收集的先前方法可比较的集成多样性性能。

    Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to shortcut learning phenomena, where a model may rely on erroneous, easy-to-learn, cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting the generation of synthetic counterfactuals using Diffusion Probabilistic Models (DPMs). We discover that DPMs have the inherent capability to represent multiple visual cues independently, even when they are largely correlated in the training data. We leverage this characteristic to encourage model diversity and empirically show the efficacy of the approach with respect to several diversification objectives. We show that diffusion-guided diversification can lead models to avert attention from shortcut cues, achieving ensemble diversity performance comparable to previous methods requiring additional data collection.
    
[^98]: 机器人化线束装配的计算机视觉技术

    Computer Vision Technology for Robotized Wire Harness Assembly. (arXiv:2309.13745v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2309.13745](http://arxiv.org/abs/2309.13745)

    该论文介绍了机器人化线束装配的计算机视觉技术，以提高装配质量并优化人体工程学和劳动成本。

    

    线束在现代汽车中是电子系统的重要硬件。随着汽车行业向电动化和自动驾驶的转变，越来越多的汽车电子产品负责能量传输和安全关键功能，如操纵、驾驶辅助和安全系统。这种范式转变从安全角度对汽车线束提出更高的要求，并强调了在车辆中的高质量线束装配的重要性。然而，目前大部分线束装配操作仍由熟练工人手动完成，其中一些手动工序从不同的角度存在问题，如质量控制和人体工程学。行业中也持续需求提高竞争力并获得市场份额。因此，希望能在提高人体工程学和优化劳动成本的同时保证装配质量。机器人化装配通过计算机视觉技术实现。

    Wire harnesses are essential hardware for electronic systems in modern automotive vehicles. With a shift in the automotive industry towards electrification and autonomous driving, more and more automotive electronics are responsible for energy transmission and safety-critical functions such as maneuvering, driver assistance, and safety system. This paradigm shift places more demand on automotive wiring harnesses from the safety perspective and stresses the greater importance of high-quality wire harness assembly in vehicles. However, most of the current operations of wire harness assembly are still performed manually by skilled workers, and some of the manual processes are problematic from different perspectives, such as quality control and ergonomics. There is also a persistent demand in the industry to increase competitiveness and gain market share. Hence, assuring assembly quality while improving ergonomics and optimizing labor costs is desired. Robotized assembly, accomplished by r
    
[^99]: 计算机视觉在机器人化线束装配中的应用的系统文献综述

    A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly. (arXiv:2309.13744v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.13744](http://arxiv.org/abs/2309.13744)

    该论文对计算机视觉在机器人化线束装配中的应用进行了系统的文献综述，总结出了挑战和未来研究机会。

    

    本文对计算机视觉在机器人化线束装配中的应用提出了一个系统的文献综述，从现有研究中提取了挑战，并找到了未来研究促进更实际的机器人化线束装配的机会。

    This article presents a systematic literature review on computer vision applications that have been proposed for robotized wire harness assembly, derives challenges from existing studies, and identifies opportunities for future research to promote a more practical robotized assembly of wire harnesses.
    
[^100]: 可解释的人工智能在药物发现和开发中的应用 - 一项综合调查

    Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey. (arXiv:2309.12177v1 [cs.AI])

    [http://arxiv.org/abs/2309.12177](http://arxiv.org/abs/2309.12177)

    可解释的人工智能在药物发现中的应用越来越受关注，为研究人员提供了对机器学习模型预测的更具解释性的理解，进一步促进了目标识别、化合物设计和毒性预测等方面的发展。

    

    随着人工智能（AI）和机器学习（ML）技术的出现，药物发现领域经历了显著的转变。然而，随着这些AI和ML模型变得越来越复杂，对于模型的透明性和解释能力的需求也在增加。可解释的人工智能（XAI）是一种新颖的方法，解决了这个问题，并提供了对机器学习模型所做预测的更具解释性的理解。近年来，对于将XAI技术应用于药物发现的兴趣日益增加。本综述文章全面概述了XAI在药物发现中的最新进展，包括各种XAI方法、它们在药物发现中的应用，以及XAI技术在药物发现中的挑战和限制。该文章还涵盖了XAI在药物发现中的应用，包括目标识别、化合物设计和毒性预测。

    The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies. However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models. Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models. In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery. This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery. The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction. Furtherm
    
[^101]: 超越单调性的数据汇总：非单调的两阶段子模最大化

    Data Summarization beyond Monotonicity: Non-monotone Two-Stage Submodular Maximization. (arXiv:2309.05183v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2309.05183](http://arxiv.org/abs/2309.05183)

    这篇论文研究了两阶段子模最大化问题，目标是使用子模训练函数来减少底层集合，并引入了非单调子模函数的第一个恒定因子逼近算法。

    

    两阶段子模最大化问题的目标是使用提供的子模训练函数来减少底层集合，以确保在减小后的底层集合上优化新的目标函数的结果与在原始底层集合上获得的结果相当。这个问题在数据汇总等各个领域都有应用。现有的研究通常假设目标函数是单调的，而我们的工作将这个研究扩展到了非单调子模函数的情况。我们引入了这种更一般情况的第一个恒定因子逼近算法。

    The objective of a two-stage submodular maximization problem is to reduce the ground set using provided training functions that are submodular, with the aim of ensuring that optimizing new objective functions over the reduced ground set yields results comparable to those obtained over the original ground set. This problem has applications in various domains including data summarization. Existing studies often assume the monotonicity of the objective function, whereas our work pioneers the extension of this research to accommodate non-monotone submodular functions. We have introduced the first constant-factor approximation algorithms for this more general case.
    
[^102]: 从自然互动和大型语言模型中增量学习人形机器人行为

    Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models. (arXiv:2309.04316v1 [cs.RO])

    [http://arxiv.org/abs/2309.04316](http://arxiv.org/abs/2309.04316)

    本文提出了一个从自然互动中实现复杂行为增量学习的系统，并演示了在一个人形机器人上的应用。该系统利用大型语言模型对机器人的行为进行高级协调，通过交互式控制台生成Python语句来调用机器人的感知和动作，并通过将人类指令、环境观测和执行结果反馈给语言模型来实现循环交互。

    

    自然语言对话对于直观的人机交互至关重要。它不仅可以用来表达人类的意图，而且还可以用来传达指令以改进机器人对命令的理解。非常重要的是要赋予机器人从这种交互经验中增量学习的能力，以使它们能够改进自己的行为或避免未来的错误。本文提出了一个从自然互动中实现复杂行为增量学习的系统，并在一个人形机器人上演示其实现。基于最新的进展，我们提出了一个使用大型语言模型（Large Language Models，LLMs）进行机器人行为的高层协调的系统，这个系统的思想是让LLM在交互式控制台中生成Python语句来调用机器人的感知和动作。通过将人类指令、环境观测和执行结果反馈给LLM来关闭交互循环。

    Natural-language dialog is key for intuitive human-robot interaction. It can be used not only to express humans' intents, but also to communicate instructions for improvement if a robot does not understand a command correctly. Of great importance is to endow robots with the ability to learn from such interaction experience in an incremental way to allow them to improve their behaviors or avoid mistakes in the future. In this paper, we propose a system to achieve incremental learning of complex behavior from natural interaction, and demonstrate its implementation on a humanoid robot. Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action. The interaction loop is closed by feeding back human instructions, environment observations, and execution results to the LLM, 
    
[^103]: 伪装游戏：在交互式机器人自主性中闭环安全学习

    Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy. (arXiv:2309.01267v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2309.01267](http://arxiv.org/abs/2309.01267)

    本文提出了一种闭环安全学习的范式，用于合成机器人的安全控制策略。该方法考虑机器人学习能力和不确定性，能够快速应对未来场景，从而在确保安全的同时保持性能表现。

    

    自主车辆等机器人系统的广泛部署面临的一个重要挑战是确保与人类安全互动而不牺牲性能。现有的安全方法往往忽视了机器人在运行时学习和适应的能力，导致过度保守的行为。本文提出了一种新的闭环范式，用于合成安全控制策略，明确考虑机器人不断变化的不确定性和其快速应对未来场景的能力，并联合考虑物理动力学和机器人学习算法。我们利用对抗性强化学习，以可行的方式进行高维学习动力学的安全分析，并通过贝叶斯信念传播和大型预训练神经轨迹预测器展示了我们框架的能力。

    An outstanding challenge for the widespread deployment of robotic systems like autonomous vehicles is ensuring safe interaction with humans without sacrificing performance. Existing safety methods often neglect the robot's ability to learn and adapt at runtime, leading to overly conservative behavior. This paper proposes a new closed-loop paradigm for synthesizing safe control policies that explicitly account for the robot's evolving uncertainty and its ability to quickly respond to future scenarios as they arise, by jointly considering the physical dynamics and the robot's learning algorithm. We leverage adversarial reinforcement learning for tractable safety analysis under high-dimensional learning dynamics and demonstrate our framework's ability to work with both Bayesian belief propagation and implicit learning through large pre-trained neural trajectory predictors.
    
[^104]: Socratis：大型多模态模型是否具有情绪意识？

    Socratis: Are large multimodal models emotionally aware?. (arXiv:2308.16741v1 [cs.AI])

    [http://arxiv.org/abs/2308.16741](http://arxiv.org/abs/2308.16741)

    这项研究提出了Socratis，一个新的社会反应基准，用于学习多模态内容的多样化情绪反应。根据人类研究结果，人们更喜欢人工撰写的情感原因，比机器生成的要多2倍以上。

    

    现有的情绪预测基准包含粗糙的情绪标签，不考虑图像和文本在人类中引发多样化情绪的各种原因。学习多样化的对于多模态内容的反应非常重要，因为智能机器在生成和传递内容给社会中起到核心作用。为了填补这一空白，我们提出了Socratis，一个社会反应基准，在其中每个图像-标题（IC）对都附带有多种情绪和感受它们的原因的注释。Socratis包含了来自5个广泛阅读的新闻和图像标题（IC）数据集的2075个图像-标题对的980个情绪的18K个自由形式反应。我们评估了最先进的多模态大型语言模型在给定IC对的情感原因生成方面的能力。根据一个初步的人类研究，我们观察到，人们更喜欢人工撰写的原因，比机器生成的要多2倍以上。

    Existing emotion prediction benchmarks contain coarse emotion labels which do not consider the diversity of emotions that an image and text can elicit in humans due to various reasons. Learning diverse reactions to multimodal content is important as intelligent machines take a central role in generating and delivering content to society. To address this gap, we propose Socratis, a \underline{soc}ietal \underline{r}e\underline{a}c\underline{ti}on\underline{s} benchmark, where each image-caption (IC) pair is annotated with multiple emotions and the reasons for feeling them. Socratis contains 18K free-form reactions for 980 emotions on 2075 image-caption pairs from 5 widely-read news and image-caption (IC) datasets. We benchmark the capability of state-of-the-art multimodal large language models to generate the reasons for feeling an emotion given an IC pair. Based on a preliminary human study, we observe that humans prefer human-written reasons over 2 times more often than machine-genera
    
[^105]: 在循环神经网络中的表达性概率抽样

    Expressive probabilistic sampling in recurrent neural networks. (arXiv:2308.11809v1 [q-bio.NC])

    [http://arxiv.org/abs/2308.11809](http://arxiv.org/abs/2308.11809)

    该论文探索了循环神经电路如何从复杂概率分布中进行抽样，并证明了带有单独输出单元的神经电路的发放率动力学可以从任意概率分布中进行抽样。

    

    在基于采样的大脑功能贝叶斯模型中，假设神经活动是来自大脑用于概率计算的概率分布样本。然而，对于神经动力学机制模型如何从任意分布中进行抽样仍然缺乏全面理解。我们使用函数分析和随机微分方程的工具来探索$\textit{循环}$神经电路从复杂分布中进行抽样的最小架构要求。首先我们考虑传统的采样模型，它由一个神经元网络组成，其输出直接表示样本（仅采样器网络）。我们认为传统模型中的突触电流和发放率动力学能够从复杂概率分布中进行抽样的能力有限。我们证明了一个带有单独的输出单元集的循环神经电路的发放率动力学可以从任意概率分布中进行抽样。

    In sampling-based Bayesian models of brain function, neural activities are assumed to be samples from probability distributions that the brain uses for probabilistic computation. However, a comprehensive understanding of how mechanistic models of neural dynamics can sample from arbitrary distributions is still lacking. We use tools from functional analysis and stochastic differential equations to explore the minimum architectural requirements for $\textit{recurrent}$ neural circuits to sample from complex distributions. We first consider the traditional sampling model consisting of a network of neurons whose outputs directly represent the samples (sampler-only network). We argue that synaptic current and firing-rate dynamics in the traditional model have limited capacity to sample from a complex probability distribution. We show that the firing rate dynamics of a recurrent neural circuit with a separate set of output units can sample from an arbitrary probability distribution. We call 
    
[^106]: 解决医学影像深度学习中的小型注释数据集问题：对比共同对比学习和掩码自编码器方法在CT扫描卷积模型中的自监督预训练的评估

    Dealing with Small Annotated Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models. (arXiv:2308.06534v1 [cs.CV])

    [http://arxiv.org/abs/2308.06534](http://arxiv.org/abs/2308.06534)

    本研究评估了在医学影像领域使用自监督预训练方法的可行性，比较了共同对比学习和掩码自编码器方法在CT扫描卷积模型中的性能。

    

    医学影像中的深度学习有潜力减少诊断错误的风险、减轻放射科医生的工作负担并加速确诊。训练这样的深度学习模型需要大型且准确的数据集，并且需要为所有训练样本提供注释。然而，在医学影像领域，由于注释的高复杂性、受限的获取方式或疾病的罕见性，特定任务的注释数据集通常很小。为了应对这一挑战，深度学习模型可以使用自监督学习领域的方法，在没有注释的大型图像数据集上进行预训练。在预训练之后，小型的已注释数据集就足以对模型进行特定任务的微调，即所谓的“下游任务”。医学影像中最流行的自监督预训练方法基于共同对比学习。然而，最近的自然图像处理研究表明掩码自编码器方法具有很大的潜力。本研究比较了二者在CT扫描卷积模型中的性能。

    Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task, the so-called ``downstream task". The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares sta
    
[^107]: 预测人类如何在自身利益与他人利益之间平衡的可预测性

    Predict-AI-bility of how humans balance self-interest with the interest of others. (arXiv:2307.12776v1 [econ.GN])

    [http://arxiv.org/abs/2307.12776](http://arxiv.org/abs/2307.12776)

    生成式AI能够准确预测人类在决策中平衡自身利益与他人利益的行为模式，但存在高估他人关注行为的倾向，这对AI的开发者和用户具有重要意义。

    

    生成式人工智能具有革命性的潜力，可以改变从日常生活到高风险场景的决策过程。然而，由于许多决策具有社会影响，为了使AI能够成为可靠的决策助手，它必须能够捕捉自身利益与他人利益之间的平衡。我们对三种最先进的聊天机器人对来自12个国家的78个实验的独裁者游戏决策进行了研究。我们发现，只有GPT-4（而不是Bard或Bing）能够正确捕捉到行为模式的定性特征，识别出三种主要的行为类别：自私的、不公平厌恶的和完全无私的。然而，GPT-4一直高估了他人关注行为，夸大了不公平厌恶和完全无私参与者的比例。这种偏见对于AI开发人员和用户具有重要意义。

    Generative artificial intelligence holds enormous potential to revolutionize decision-making processes, from everyday to high-stake scenarios. However, as many decisions carry social implications, for AI to be a reliable assistant for decision-making it is crucial that it is able to capture the balance between self-interest and the interest of others. We investigate the ability of three of the most advanced chatbots to predict dictator game decisions across 78 experiments with human participants from 12 countries. We find that only GPT-4 (not Bard nor Bing) correctly captures qualitative behavioral patterns, identifying three major classes of behavior: self-interested, inequity-averse, and fully altruistic. Nonetheless, GPT-4 consistently overestimates other-regarding behavior, inflating the proportion of inequity-averse and fully altruistic participants. This bias has significant implications for AI developers and users.
    
[^108]: 基于代理锚点的无监督学习用于连续广义类别发现

    Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery. (arXiv:2307.10943v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.10943](http://arxiv.org/abs/2307.10943)

    本文提出了一种基于代理锚点的无监督学习方法，用于在无标签数据集上发现新的类别，该方法通过微调特征提取器和代理锚点，将样本分为旧的和新的类别，并生成代表性的类别实例。

    

    近年来，深度学习的进展显著提高了各种计算机视觉应用的性能。然而，在增量学习场景中发现新的类别仍然是一个具有挑战性的问题，因为缺乏关于新类别数量和性质的先验知识。现有的新类别发现方法受限于对标记数据集和批次中新样本数量的先验知识。为了解决这些限制并更准确地反映实际场景，在本文中，我们提出了一种新的无监督类别增量学习方法，用于在无标签集上发现新的类别。所提出的方法通过在标记集上微调特征提取器和代理锚点，然后将样本分为旧的和新的类别，并在无标签数据集上进行聚类。此外，基于代理锚点的样本生成代表性类别实例。

    Recent advances in deep learning have significantly improved the performance of various computer vision applications. However, discovering novel categories in an incremental learning scenario remains a challenging problem due to the lack of prior knowledge about the number and nature of new categories. Existing methods for novel category discovery are limited by their reliance on labeled datasets and prior knowledge about the number of novel categories and the proportion of novel samples in the batch. To address the limitations and more accurately reflect real-world scenarios, in this paper, we propose a novel unsupervised class incremental learning approach for discovering novel categories on unlabeled sets without prior knowledge. The proposed method fine-tunes the feature extractor and proxy anchors on labeled sets, then splits samples into old and novel categories and clusters on the unlabeled dataset. Furthermore, the proxy anchors-based exemplar generates representative category 
    
[^109]: VoxPoser: 用于带有语言模型的机器人操作的可组合的3D价值映射

    VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models. (arXiv:2307.05973v1 [cs.RO])

    [http://arxiv.org/abs/2307.05973](http://arxiv.org/abs/2307.05973)

    VoxPoser提出了一种新方法，通过组合3D价值映射和语言模型，实现了机器人在多种操作任务下根据自由形式的指令和对象合成机器人轨迹的能力。

    

    研究表明，大型语言模型（LLMs）具有丰富的可行动知识，可以以推理和规划的形式提取出用于机器人操作的信息。尽管取得了进展，大多数模型仍然依赖于预定义的运动原语来执行与环境的物理交互，这仍然是一个重大瓶颈。在这项工作中，我们的目标是在给定开集指令和开集对象的情况下，为各种操作任务合成机器人轨迹，即一系列密集的6-DoF末端执行器路径点。我们首先观察到LLMs在给定自由形式的语言指令时擅长推断可行性和约束。更重要的是，通过利用它们的代码编写能力，它们可以与视觉-语言模型（VLM）交互，以组合3D价值映射将知识接地到Agent的观测空间中。然后在基于模型的规划框架中使用组合的价值映射来零试合成闭环轨迹。

    Large language models (LLMs) are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning. Despite the progress, most still rely on pre-defined motion primitives to carry out the physical interactions with the environment, which remains a major bottleneck. In this work, we aim to synthesize robot trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a large variety of manipulation tasks given an open-set of instructions and an open-set of objects. We achieve this by first observing that LLMs excel at inferring affordances and constraints given a free-form language instruction. More importantly, by leveraging their code-writing capabilities, they can interact with a visual-language model (VLM) to compose 3D value maps to ground the knowledge into the observation space of the agent. The composed value maps are then used in a model-based planning framework to zero-shot synthesize closed-loop ro
    
[^110]: 通过对比学习在强化学习中发现层次化成就

    Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning. (arXiv:2307.03486v1 [cs.LG])

    [http://arxiv.org/abs/2307.03486](http://arxiv.org/abs/2307.03486)

    通过对比学习方法，我们在强化学习中提出了新的成就蒸馏方法，可以加强代理对下一个解锁成就的预测能力，并优于先前的模型驱动和层次化方法。

    

    在生成环境中发现具有层次结构的成就是一个重大挑战。这需要智能体具备广泛的能力，包括泛化和长期推理。许多先前的方法基于模型驱动或层次化方法，认为显式的长期规划模块对于学习层次化成就是有益的。然而，这些方法需要大量的环境交互或大型模型，限制了它们的实用性。在这项工作中，我们发现近期实施实践中的近端策略优化（PPO）算法优于先前的方法。此外，我们发现PPO智能体可以在一定程度上预测下一个要解锁的成就，尽管预测的置信度较低。基于这一观察，我们提出了一种新颖的对比学习方法，称为成就蒸馏，可以加强PPO智能体对下一个解锁成就的预测能力。

    Discovering achievements with a hierarchical structure on procedurally generated environments poses a significant challenge. This requires agents to possess a broad range of abilities, including generalization and long-term reasoning. Many prior methods are built upon model-based or hierarchical approaches, with the belief that an explicit module for long-term planning would be beneficial for learning hierarchical achievements. However, these methods require an excessive amount of environment interactions or large model sizes, limiting their practicality. In this work, we identify that proximal policy optimization (PPO), a simple and versatile model-free algorithm, outperforms the prior methods with recent implementation practices. Moreover, we find that the PPO agent can predict the next achievement to be unlocked to some extent, though with low confidence. Based on this observation, we propose a novel contrastive learning method, called achievement distillation, that strengthens the 
    
[^111]: EHRSHOT:一种用于少样本评估基础模型的电子健康记录基准

    EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models. (arXiv:2307.02028v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02028](http://arxiv.org/abs/2307.02028)

    该论文介绍了EHRSHOT，一个用于少样本评估基础模型的电子健康记录基准。该论文利用EHRSHOT数据集和预训练模型CLMBR-T-base，为医疗保健ML的发展提供了解决方案。

    

    尽管一般的机器学习(ML)社区已经受益于公开的数据集、任务和模型，但是ML在医疗保健领域的进展受到了共享资产的缺乏的阻碍。基础模型的成功为医疗保健ML带来了新的挑战，需要访问共享的预训练模型来验证性能优势。我们通过三个贡献来帮助解决这些挑战。首先，我们发布了一个新的数据集EHRSHOT，其中包含6,739名来自斯坦福医学的患者的去识别结构化的电子健康记录(EHR)数据。与MIMIC-III/IV和其他流行的EHR数据集不同，EHRSHOT是纵向的，不仅局限于ICU/ED患者。其次，我们发布了CLMBR-T-base的权重，这是一个在结构化EHR数据中预训练的141M参数临床基础模型，该数据包括2.57M名患者。我们是最早完全发布这样一个用于编码EHR数据的模型之一；相比之下，大多数先前发布的临床数据模型（如GatorTron、ClinicalBER）并没有完全发布。

    While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets. The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits. We help address these challenges through three contributions. First, we publish a new dataset, EHRSHOT, which contains deidentified structured data from the electronic health records (EHRs) of 6,739 patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients. Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients. We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBER
    
[^112]: Physion++：对需要在线推理不同物理属性的物理场景理解进行评估

    Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties. (arXiv:2306.15668v1 [cs.CV])

    [http://arxiv.org/abs/2306.15668](http://arxiv.org/abs/2306.15668)

    该论文提出了一个新的数据集和基准测试——Physion++，用于评估在需要准确估计场景中物体潜在物理属性的情况下的视觉物理预测。

    

    一般的物理场景理解需要的不仅仅是定位和识别物体，还需要了解物体可以具有不同的潜在属性（例如质量或弹性），并且这些属性会影响物理事件的结果。尽管近年来在物理和视频预测模型方面取得了很大进展，但评估它们性能的基准测试通常不要求理解物体具有个体的物理属性，或者最多只测试可以直接观察到的属性（例如大小或颜色）。本文提出了一个新的数据集和基准测试——Physion++，在这个人工系统下严格评估了视觉物理预测，其中预测依赖于场景中物体潜在物理属性的准确估计。具体而言，我们测试了准确预测依赖于质量、摩擦力、弹性和可变性等属性的场景。

    General physical scene understanding requires more than simply localizing and recognizing objects -- it requires knowledge that objects can have different latent properties (e.g., mass or elasticity), and that those properties affect the outcome of physical events. While there has been great progress in physical and video prediction models in recent years, benchmarks to test their performance typically do not require an understanding that objects have individual physical properties, or at best test only those properties that are directly observable (e.g., size or color). This work proposes a novel dataset and benchmark, termed Physion++, that rigorously evaluates visual physical prediction in artificial systems under circumstances where those predictions rely on accurate estimates of the latent physical properties of objects in the scene. Specifically, we test scenarios where accurate prediction relies on estimates of properties such as mass, friction, elasticity, and deformability, an
    
[^113]: Fedstellar：一个去中心化联邦学习平台

    Fedstellar: A Platform for Decentralized Federated Learning. (arXiv:2306.09750v1 [cs.LG])

    [http://arxiv.org/abs/2306.09750](http://arxiv.org/abs/2306.09750)

    Fedstellar是一个联邦学习平台，支持物理或虚拟设备的去中心化、半去中心化和中心化的方式训练模型，旨在解决现有平台在处理异构联盟网络拓扑等问题时的挑战。

    

    2016年，谷歌提出了联邦学习（FL）作为一种新的范式，可以在保护数据隐私的同时跨联盟参与者训练机器学习（ML）模型。虽然中心化联邦学习（CFL）是最常用的方法，但它存在通信瓶颈、单点故障和对中央服务器的依赖等局限。去中心化联邦学习（DFL）通过实现去中心化模型聚合和最小化对中央实体的依赖，来解决这些问题。然而，目前训练DFL模型的平台在处理异构联盟网络拓扑等关键问题方面存在困难。为了克服这些挑战，本文提出了Fedstellar，这是一个新型的平台，旨在在物理或虚拟设备的不同联盟中以去中心化、半去中心化和中心化的方式训练FL模型。

    In 2016, Google proposed Federated Learning (FL) as a novel paradigm to train Machine Learning (ML) models across the participants of a federation while preserving data privacy. Since its birth, Centralized FL (CFL) has been the most used approach, where a central entity aggregates participants' models to create a global one. However, CFL presents limitations such as communication bottlenecks, single point of failure, and reliance on a central server. Decentralized Federated Learning (DFL) addresses these issues by enabling decentralized model aggregation and minimizing dependency on a central entity. Despite these advances, current platforms training DFL models struggle with key issues such as managing heterogeneous federation network topologies. To overcome these challenges, this paper presents Fedstellar, a novel platform designed to train FL models in a decentralized, semi-decentralized, and centralized fashion across diverse federations of physical or virtualized devices. The Feds
    
[^114]: AVIS:利用大型语言模型的自主视觉信息检索

    AVIS: Autonomous Visual Information Seeking with Large Language Models. (arXiv:2306.08129v1 [cs.CV])

    [http://arxiv.org/abs/2306.08129](http://arxiv.org/abs/2306.08129)

    本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。

    

    本文提出了一种利用大型语言模型（LLM）实现自主信息检索的视觉问答框架AVIS。我们的方法利用LLM动态地制定利用外部工具的策略，并调查它们的输出，从而获取提供所提出问题所需的不可或缺的知识。回答需要外部知识的视觉问题，如“这幅图像所描绘的建筑物是为了纪念哪个事件？”，是一项复杂的任务。这个任务呈现出一个组合搜索空间，需要一系列行动，包括调用API、分析它们的响应并做出明智的决策。我们进行了一个用户研究，收集了人类面对这个任务时各种各样的决策实例。然后利用这些数据设计了一个由三个组件组成的系统：一个由LLM驱动的规划器，动态确定下一个要使用的工具；一个由LLM驱动的推理器，分析并提取关键信息。

    In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as "What event is commemorated by the building depicted in this image?", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information 
    
[^115]: 与学习导向的车辆运动规划的误解告别

    Parting with Misconceptions about Learning-based Vehicle Motion Planning. (arXiv:2306.07962v1 [cs.RO])

    [http://arxiv.org/abs/2306.07962](http://arxiv.org/abs/2306.07962)

    该论文提出了nuPlan，一个大规模真实世界数据集和评估方案，针对精确的短期规划和长期目标预测。证实了现有系统难以同时满足两个要求。最终提出一个非常简单高效的规划器。

    

    nuPlan的发布标志着车辆运动规划研究的一个新时代，提供了第一个需要精确的短期规划和长期目标预测的大规模真实世界数据集和评估方案。现有系统难以同时满足两个要求。实际上，我们发现这些任务存在根本上的不对齐问题，应该分别进行解决。我们进一步评估了领域内闭环规划的现状，揭示了学习为基础的方法在复杂的真实场景中的局限性，以及选择通过车道图搜索算法的简单基于规则的先验项（例如中心线选择）的价值。更令人惊讶的是，在开环子任务中，我们观察到当仅使用这个中心线作为场景上下文时（即忽略所有有关地图和其他代理的信息）可以获得最佳结果。结合这些见解，我们提出了一个非常简单高效的规划器，它的表现优于大量竞争对手。

    The release of nuPlan marks a new era in vehicle motion planning research, offering the first large-scale real-world dataset and evaluation schemes requiring both precise short-term planning and long-horizon ego-forecasting. Existing systems struggle to simultaneously meet both requirements. Indeed, we find that these tasks are fundamentally misaligned and should be addressed independently. We further assess the current state of closed-loop planning in the field, revealing the limitations of learning-based methods in complex real-world scenarios and the value of simple rule-based priors such as centerline selection through lane graph search algorithms. More surprisingly, for the open-loop sub-task, we observe that the best results are achieved when using only this centerline as scene context (\ie, ignoring all information regarding the map and other agents). Combining these insights, we propose an extremely simple and efficient planner which outperforms an extensive set of competitors,
    
[^116]: 具有流行度偏见的排名：自增强动态下的用户福利

    Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics. (arXiv:2305.18333v1 [cs.IR])

    [http://arxiv.org/abs/2305.18333](http://arxiv.org/abs/2305.18333)

    研究了物品流行度、质量和位置偏差对用户福利的影响，提出了通过探索减轻流行度偏见负面影响的算法。

    

    虽然已经确认流行度偏见在推荐（和其他基于排名的）系统中发挥作用，但其对用户福利的影响的详细分析仍然缺乏。我们提出了一种通用机制，通过它，物品的流行度、质量和位置偏差可以影响用户选择，并且可以负面影响各种推荐策略的集体用户效用。我们将问题表述为非平稳上下文脱靶机，强调不是为了消除流行度偏见而是为了减轻其负面影响而进行探索的重要性。首先，普通的有流行度偏差的推荐系统会通过混淆物品质量和流行度而引发线性遗憾。更一般地，我们展示了即使在线性设置下，由于流行度偏见的混淆效应，物品质量的可识别性也可能无法实现。然而，在足够变异的假设下，我们开发了一种高效的类UCB算法，并证明了有效的遗憾保证。我们通过实验验证了我们提出的算法的有效性，并证实了流行度偏见的负面影响。

    While popularity bias is recognized to play a role in recommmender (and other ranking-based) systems, detailed analyses of its impact on user welfare have largely been lacking. We propose a general mechanism by which item popularity, item quality, and position bias can impact user choice, and how it can negatively impact the collective user utility of various recommender policies. Formulating the problem as a non-stationary contextual bandit, we highlight the importance of exploration, not to eliminate popularity bias, but to mitigate its negative effects. First, naive popularity-biased recommenders are shown to induce linear regret by conflating item quality and popularity. More generally, we show that, even in linear settings, identifiability of item quality may not be possible due to the confounding effects of popularity bias. However, under sufficient variability assumptions, we develop an efficient UCB-style algorithm and prove efficient regret guarantees. We complement our analys
    
[^117]: 利用预训练的大型语言模型构建和利用世界模型进行基于模型的任务规划

    Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning. (arXiv:2305.14909v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.14909](http://arxiv.org/abs/2305.14909)

    本论文提出了一种新的方法，利用预训练的大型语言模型构建显式的世界模型，并将其用于规划。通过将语言模型作为PDDL和纠正反馈源之间的接口，在用户不懂PDDL的情况下将PDDL转化为自然语言，并有效地编码纠正反馈。

    

    越来越多的人开始将预训练的大型语言模型（LLMs）应用于规划问题。然而，直接使用LLMs作为规划器的方法目前在实际操作中并不可行，原因包括计划的正确性有限，与模拟器或实际环境的交互反馈依赖较强，以及利用人类反馈的效率低下。在这项工作中，我们引入了一种新的替代范式，通过规划领域定义语言（PDDL）构建一个显式的世界（领域）模型，然后使用它来进行具有良好领域独立性的规划。为了解决LLMs可能无法最初生成完全功能的PDDL模型的问题，我们将LLMs作为PDDL和纠正反馈源（如PDDL验证器和人类）之间的接口。对于没有PDDL背景的用户，我们证明LLMs可以将PDDL转化为自然语言，并将纠正反馈有效地编码回底层领域模型。

    There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framewo
    
[^118]: UniControl：统一的扩散模型用于可控的生动图像生成

    UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild. (arXiv:2305.11147v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.11147](http://arxiv.org/abs/2305.11147)

    本文提出了UniControl，一种新的生成基础模型，能够整合广泛的可控条件与图像任务，并仍然允许任意语言提示，UniControl能够进行像素级精确的图像生成，其中视觉条件主要影响生成的结构，语言提示则引导样式和上下文。我们提出了一种统一的扩散模型，它将扩散过程和变分自动编码器的优点结合起来，实验结果表明UniControl在可控性和图像质量方面均优于现有的最先进模型。

    

    实现机器自治和人类控制往往代表着相互矛盾的目标，特别是在交互式人工智能系统的设计中。现实中的可控视觉生成模型（如稳定扩散）在使用任意语言时具有良好的表现，但在生成具有空间、结构或几何控制的图像方面往往表现不佳。本文提出了UniControl，这是一种新的生成基础模型，它将广泛的可控条件与图像（C2I）任务整合到一个单一的框架中，同时仍允许任意语言提示。UniControl能够进行像素级精确的图像生成，其中视觉条件主要影响生成的结构，语言提示则引导样式和上下文。为了使UniControl具备处理各种视觉条件的能力，我们提出了一种统一的扩散模型，它将扩散过程和变分自动编码器的优点结合起来。实验结果表明，我们提出的UniControl在可控性和图像质量方面均优于现有的最先进模型。

    Achieving machine autonomy and human control often represent divergent objectives in the design of interactive AI systems. Visual generative foundation models such as Stable Diffusion show promise in navigating these goals, especially when prompted with arbitrary languages. However, they often fall short in generating images with spatial, structural, or geometric controls. The integration of such controls, which can accommodate various visual conditions in a single unified model, remains an unaddressed challenge. In response, we introduce UniControl, a new generative foundation model that consolidates a wide array of controllable condition-to-image (C2I) tasks within a singular framework, while still allowing for arbitrary language prompts. UniControl enables pixel-level-precise image generation, where visual conditions primarily influence the generated structures and language prompts guide the style and context. To equip UniControl with the capacity to handle diverse visual conditions
    
[^119]: 校准化解释：基于不确定性信息和反事实的解释模型

    Calibrated Explanations: with Uncertainty Information and Counterfactuals. (arXiv:2305.02305v1 [cs.AI])

    [http://arxiv.org/abs/2305.02305](http://arxiv.org/abs/2305.02305)

    该论文提出了一种新的特征重要性解释方法，Calibrated Explanations (CE)，它可以提供准确、稳定的解释，并且可以为概率估计和特征重要性权重提供不确定性量化信息，是一种快速、可靠且强健的解释方法。

    

    人工智能已经成为各种领域决策支持系统中不可或缺的一部分，但人工智能决策系统中预测模型缺乏透明度可能导致滥用或不使用。可解释人工智能旨在创建可以向人类用户解释其推理过程的人工智能系统。可解释人工智能中的局部解释可以提供关于特征重要性的个别预测原因的信息，但存在不稳定性等缺点。为了解决这些问题，我们提出了一种新的特征重要性解释方法，校准化解释(Calibrated Explanations，CE)，它基于 Venn-Abers，同时在生成特征重要性解释的同时校准底层模型。CE不仅提供快速、可靠、稳定和强健的解释，还提供概率估计和特征重要性权重的不确定性量化。此外，该方法是模型无关的，具有易于理解的条件规则，也可以生成反事实推理。

    Artificial Intelligence (AI) has become an integral part of decision support systems (DSSs) in various domains, but the lack of transparency in the predictive models used in AI-based DSSs can lead to misuse or disuse. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance, but they suffer from drawbacks such as instability. To address these issues, we propose a new feature importance explanation method, Calibrated Explanations (CE), which is based on Venn-Abers and calibrates the underlying model while generating feature importance explanations. CE provides fast, reliable, stable, and robust explanations, along with uncertainty quantification of the probability estimates and feature importance weights. Furthermore, the method is model agnostic with easily understood conditional rules and can also genera
    
[^120]: GPT-2是如何计算大于符号的？解释预训练语言模型中的数学能力

    How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v1 [cs.CL])

    [http://arxiv.org/abs/2305.00586](http://arxiv.org/abs/2305.00586)

    本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。

    

    预训练语言模型在未被明确训练的任务上表现出惊人的能力，但它们如何实现这些功能却不为人所知。本文通过机械式可解释性技术探究预训练语言模型通常具有的基本数学能力。具体来说，我们以GPT-2 Small为例，研究其能否通过输入"战争持续时间是从1732年到17年"，预测出有效的两位数字的截止年份 (大于32年)。我们首先确定了一个电路，即GPT-2 Small计算图的一个小子集，用于计算这个任务的输出，然后我们解释了每个电路组件的作用，显示出GPT-2 Small的最终多层感知器提高了结束年份大于开始年份的概率。最后，我们证明了我们的电路适用于其他任务，在其他大于场景中发挥作用。

    Pre-trained language models can be surprisingly adept at tasks they were not explicitly trained on, but how they implement these capabilities is poorly understood. In this paper, we investigate the basic mathematical abilities often acquired by pre-trained language models. Concretely, we use mechanistic interpretability techniques to explain the (limited) mathematical abilities of GPT-2 small. As a case study, we examine its ability to take in sentences such as "The war lasted from the year 1732 to the year 17", and predict valid two-digit end years (years > 32). We first identify a circuit, a small subset of GPT-2 small's computational graph that computes this task's output. Then, we explain the role of each circuit component, showing that GPT-2 small's final multi-layer perceptrons boost the probability of end years greater than the start year. Finally, we show that our circuit generalizes to other tasks, playing a role in other greater-than scenarios.
    
[^121]: CAMEL: 用于“心智”探索大规模语言模型社群的交互式代理

    CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. (arXiv:2303.17760v1 [cs.AI])

    [http://arxiv.org/abs/2303.17760](http://arxiv.org/abs/2303.17760)

    本文介绍了一个名为角色扮演的新型交互式代理框架，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。

    

    对话式语言模型的快速发展已取得了在复杂任务解决方面的显著进展。然而，它们的成功在很大程度上依赖于人类的指导，以引导对话，这可能是具有挑战性和耗时的。本文探讨了构建可扩展技术以促进交互式代理之间的自主合作并深入了解它们的“认知”过程的潜力。为了解决实现自主合作的挑战，我们提出了一个名为角色扮演的新型交互式代理框架。我们的方法涉及使用启动提示来引导聊天代理完成任务，同时保持与人类意图的一致性。我们展示了如何使用角色扮演来生成对话数据，以研究聊天代理的行为和能力，为研究对话式语言模型提供了有价值的资源。我们的贡献是介绍了一种新型的交互式代理框架，名为角色扮演，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。

    The rapid advancement of conversational and chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and provide insight into their "cognitive" processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing. Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of chat agents, providing a valuable resource for investigating conversational language models. Our contributions include introducing a novel communicative agent framewor
    
[^122]: 基于现代 Hopfield 网络的时间序列一致性预测方法

    Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v1 [cs.LG])

    [http://arxiv.org/abs/2303.12783](http://arxiv.org/abs/2303.12783)

    该论文提出了一种名为 HopCPT 的新一致性时间序列预测方法，不仅能够处理时间结构，而且能够利用其优势，已在多种真实世界的时间序列数据集上证明了优于现有方法的性能。

    

    为了量化不确定性，一致性预测方法受到越来越多的关注，并已成功应用于各个领域。然而，它们难以应用于时间序列，因为时间序列的自相关结构违反了一致性预测所需的基本假设。我们提出了 HopCPT，一种新的基于 Hopfield 网络的时间序列一致性预测方法，不仅能够应对时间结构，而且能够利用它们。我们证明了我们的方法在存在时间依赖性的时间序列中在理论上是有很好的理论基础的。在实验中，我们证明了我们的新方法在四个不同领域的多个真实世界时间序列数据集上优于现有的最先进的一致性预测方法。

    To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.
    
[^123]: 使用深度离线强化学习实现安全的丙泊酚全麻剂量控制

    Towards Safe Propofol Dosing during General Anesthesia Using Deep Offline Reinforcement Learning. (arXiv:2303.10180v1 [cs.LG])

    [http://arxiv.org/abs/2303.10180](http://arxiv.org/abs/2303.10180)

    本文提出了一种基于真实临床数据集的数据驱动强化学习算法Policy Constraint Q-Learning(PCQL)来实现全麻药物剂量控制，添加了保守Q-Learning方法和策略约束项以确保智能体做出更安全的决策。

    

    自动化麻醉有望实现更精确和个性化的麻醉管理，使麻醉师免于重复性任务，专注于患者手术护理的最关键方面。当前的研究通常集中于创建模拟环境，以便智能体进行学习。这些方法已经展示出良好的实验结果，但离临床应用还有很大的差距。本文提出了一种基于真实临床数据集的数据驱动强化学习算法Policy Constraint Q-Learning(PCQL)来解决学习麻醉策略的问题。首先引入了保守Q-Learning方法以缓解脱线情况下Q函数过度估计的问题。在智能体的培训中添加一项策略约束项，以保持智能体和麻醉师的策略分布一致，以确保智能体在全麻情景下做出更安全的决策。通过实验证明了PCQL的有效性。

    Automated anesthesia promises to enable more precise and personalized anesthetic administration and free anesthesiologists from repetitive tasks, allowing them to focus on the most critical aspects of a patient's surgical care. Current research has typically focused on creating simulated environments from which agents can learn. These approaches have demonstrated good experimental results, but are still far from clinical application. In this paper, Policy Constraint Q-Learning (PCQL), a data-driven reinforcement learning algorithm for solving the problem of learning anesthesia strategies on real clinical datasets, is proposed. Conservative Q-Learning was first introduced to alleviate the problem of Q function overestimation in an offline context. A policy constraint term is added to agent training to keep the policy distribution of the agent and the anesthesiologist consistent to ensure safer decisions made by the agent in anesthesia scenarios. The effectiveness of PCQL was validated b
    
[^124]: 超声平面姿势回归：评估胎儿脑部的广义姿势坐标

    Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates in the Fetal Brain. (arXiv:2301.08317v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.08317](http://arxiv.org/abs/2301.08317)

    本研究通过使用卷积神经网络回归预测胎儿脑部超声平面的姿势，构建了一个超声平面定位系统，并对其准确性进行了分析和量化。结果表明，通过注册质量的改进和数据扩充，该系统可以实现更准确的结果。

    

    在产科超声扫描中，从二维超声图像中心理构建胎儿的三维地图是技能习得中的重大挑战。本研究旨在构建一个超声平面定位系统，用于三维可视化、训练和引导，而无需集成额外的传感器。我们的工作基于我们先前的研究，利用卷积神经网络(CNN)回归网络预测相对于标准参考帧的任意定向超声平面切割胎儿脑部的六维姿势。在这里，我们详细分析了标准胎儿脑参考帧的假设，并量化了其相对于胎儿生物测量中经脑室标准平面的获取的准确性。我们研究了注册质量对训练和测试数据的影响以及对训练模型的后续影响。最后，我们引入了数据扩充和更大的训练数据集。

    In obstetric ultrasound (US) scanning, the learner's ability to mentally build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US image represents a significant challenge in skill acquisition. We aim to build a US plane localization system for 3D visualization, training, and guidance without integrating additional sensors. This work builds on top of our previous work, which predicts the six-dimensional (6D) pose of arbitrarily oriented US planes slicing the fetal brain with respect to a normalized reference frame using a convolutional neural network (CNN) regression network. Here, we analyze in detail the assumptions of the normalized fetal brain reference frame and quantify its accuracy with respect to the acquisition of transventricular (TV) standard plane (SP) for fetal biometry. We investigate the impact of registration quality in the training and testing data and its subsequent effect on trained models. Finally, we introduce data augmentations and larger trai
    
[^125]: 贝叶斯网络的逆推

    Inversion of Bayesian Networks. (arXiv:2212.10649v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10649](http://arxiv.org/abs/2212.10649)

    本文研究了识别网络如何模拟真实后验分布的必要和充分条件，通过导出全局条件和局部条件，发现完美性为其具备期望性质起到了重要作用。

    

    变分自编码器和Helmholtz机使用一个识别网络（编码器）来近似生成模型（解码器）的后验分布。本文研究了识别网络具备模拟真实后验分布的必要和充分条件。这些结果基于概率图模型／贝叶斯网络的一般背景，其中网络代表了一组条件独立性语句。我们导出了全局条件（通过d-分离）和局部条件，使得识别网络具备期望的性质。局部条件中，完美性（每个节点只与其父节点相连）发挥了重要作用。

    Variational autoencoders and Helmholtz machines use a recognition network (encoder) to approximate the posterior distribution of a generative model (decoder). In this paper we study the necessary and sufficient properties of a recognition network so that it can model the true posterior distribution exactly. These results are derived in the general context of probabilistic graphical modelling / Bayesian networks, for which the network represents a set of conditional independence statements. We derive both global conditions, in terms of d-separation, and local conditions for the recognition network to have the desired qualities. It turns out that for the local conditions the property perfectness (for every node, all parents are joined) plays an important role.
    
[^126]: 提升时间序列预测中超参数优化的分层代理建模

    Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting. (arXiv:2211.15092v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15092](http://arxiv.org/abs/2211.15092)

    该论文提出了一种使用分层代理建模的技术H-Pro，通过利用时间序列数据的层次结构，通过测试代理驱动超参数优化，以解决测试验证期间不匹配的问题，并验证了该技术在时间序列数据集上的有效性。

    

    在时间序列预测中，选择正确的超参数集是至关重要的。传统的时间交叉验证框架在超参数优化中经常导致测试性能差，因为验证和测试期间可能存在不匹配的情况。为了解决这个测试-验证不匹配问题，我们提出了一种新颖的技术，即H-Pro，通过利用与时间序列数据集经常相关的数据层次结构，通过测试代理来驱动HPO。由于高层次的聚合时间序列通常显示出较少的不规则性和更好的可预测性，相比之下最低层次的时间序列可能是稀疏和间歇性的，我们通过利用高层次预测器生成的测试期间的代理预测结果来优化最低层次的基本预测器的超参数。H-Pro可以应用于任何现成的机器学习模型进行HPO。我们通过对五个公开可用的分层时间序列数据集进行了大量的经验评估，验证了我们的技术的有效性。

    Selecting the right set of hyperparameters is crucial in time series forecasting. The classical temporal cross-validation framework for hyperparameter optimization (HPO) often leads to poor test performance because of a possible mismatch between validation and test periods. To address this test-validation mismatch, we propose a novel technique, H-Pro to drive HPO via test proxies by exploiting data hierarchies often associated with time series datasets. Since higher-level aggregated time series often show less irregularity and better predictability as compared to the lowest-level time series which can be sparse and intermittent, we optimize the hyperparameters of the lowest-level base-forecaster by leveraging the proxy forecasts for the test period generated from the forecasters at higher levels. H-Pro can be applied on any off-the-shelf machine learning model to perform HPO. We validate the efficacy of our technique with extensive empirical evaluation on five publicly available hierar
    
[^127]: 利用人体动作合成进行计算编舞

    Computational Choreography using Human Motion Synthesis. (arXiv:2210.04366v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.04366](http://arxiv.org/abs/2210.04366)

    本文介绍了一种利用深度学习模型分析舞蹈动作和生成新动作序列的方法，同时也结合了前人的努力来开发出一套系统。

    

    深度学习模型是否应该被训练来分析人体表演艺术？为了回答这个问题，我们探索了深度神经网络在合成艺术人体动作方面的应用。人体运动合成中的问题任务包括预测野外环境中人体运动，以及生成基于这些预测的新动作序列。我们将讨论一个非传统的应用潜力，即将学习模型应用于预测舞蹈动作。最近有一些显著的努力，以计算的方式分析舞蹈动作，例如Everybody Dance Now（EDN）学习模型和Cal Poly硕士论文Take The Lead（TTL）。我们有效地将这两个作品与我们自己的深度神经网络结合起来，生成了一种新的舞蹈动作预测系统、图像到图像的转换和视频生成。

    Should deep learning models be trained to analyze human performance art? To help answer this question, we explore an application of deep neural networks to synthesize artistic human motion. Problem tasks in human motion synthesis can include predicting the motions of humans in-the-wild, as well as generating new sequences of motions based on said predictions. We will discuss the potential of a less traditional application, where learning models are applied to predicting dance movements. There have been notable, recent efforts to analyze dance movements in a computational light, such as the Everybody Dance Now (EDN) learning model and a Cal Poly master's thesis, Take The Lead (TTL). We have effectively combined these two works along with our own deep neural network to produce a new system for dance motion prediction, image-to-image translation, and video generation.
    
[^128]: 失败目标感知的事后经验重播

    Failed Goal Aware Hindsight Experience Replay. (arXiv:2208.14741v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2208.14741](http://arxiv.org/abs/2208.14741)

    本文提出了一种称为Failed goal Aware HER (FAHER)的新方法来增强多目标强化学习中的采样效率。该方法利用实现目标与未实现目标之间的关系，并通过聚类模型对序列进行聚类和采样。

    

    在给定环境中的多目标强化学习中，代理通过与环境的交互获得的经验来学习实现多个目标的策略。在这种情况下，一个关键挑战是使用稀疏二元奖励训练代理，由于缺乏成功的经验，这可能会很困难。为了解决这个挑战，事后经验重播（HER）从不成功的经验中生成成功的经验。然而，从均匀抽样的经验中生成成功的经验的过程可能效率低下。本文提出了一种名为Failed goal Aware HER (FAHER)的新方法来增强采样效率。该方法利用了实现目标与未实现目标之间的关系，并使用聚类模型对具有不同实现目标的序列进行聚类，并在HER的方式下对经验进行采样。

    In multi-goal reinforcement learning for a given environment, agents learn policies to achieve multiple goals by using experiences gained from interactions with the environment. One of the key challenges in this setting is training agents using sparse binary rewards, which can be difficult due to a lack of successful experiences. To address this challenge, hindsight experience replay (HER) generates successful experiences from unsuccessful experiences. However, the process of generating successful experiences from uniformly sampled ones can be inefficient. In this paper, a novel approach called Failed goal Aware HER (FAHER) is proposed to enhance the sampling efficiency. The approach exploits the property of achieved goals in relation to failed goals that are defined as the original goals not achieved. The proposed method involves clustering episodes with different achieved goals using a cluster model and subsequently sampling experiences in the manner of HER. The cluster model is gene
    
[^129]: SensorSCAN: 自我监督学习和深度聚类在化工过程中的故障诊断中的应用

    SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault Diagnosis in Chemical Processes. (arXiv:2208.08879v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.08879](http://arxiv.org/abs/2208.08879)

    "SensorSCAN"是一种自我监督学习和深度聚类的方法，用于在化工过程中进行故障诊断。使用这种方法，在无需专家注释的情况下，可以有效检测大多数过程故障，并且通过在少量标记数据上微调，几乎达到了最优模型的性能水平。

    

    现代工业设施在生产过程中产生大量的原始传感器数据。这些数据用于监控和控制过程，并可分析以检测和预测过程异常。通常，数据必须由专家进行注释，以便在预测建模中使用。然而，在工业环境中手动注释大量数据可能很困难。在本文中，我们提出了一种名为SensorSCAN的新方法，用于无监督故障检测和诊断，专为工业化学过程监测而设计。我们在两个公开可用的Tennessee Eastman工艺数据集上展示了我们模型的性能，包括各种故障。结果表明，我们的方法在没有专家注释的情况下明显优于现有方法（在固定FPR下，增加了0.2-0.3的TPR），有效地检测出大多数过程故障。此外，我们展示了在少量标记数据上微调的模型几乎达到了SOT模型的性能水平。

    Modern industrial facilities generate large volumes of raw sensor data during the production process. This data is used to monitor and control the processes and can be analyzed to detect and predict process abnormalities. Typically, the data has to be annotated by experts in order to be used in predictive modeling. However, manual annotation of large amounts of data can be difficult in industrial settings.  In this paper, we propose SensorSCAN, a novel method for unsupervised fault detection and diagnosis, designed for industrial chemical process monitoring. We demonstrate our model's performance on two publicly available datasets of the Tennessee Eastman Process with various faults. The results show that our method significantly outperforms existing approaches (+0.2-0.3 TPR for a fixed FPR) and effectively detects most of the process faults without expert annotation. Moreover, we show that the model fine-tuned on a small fraction of labeled data nearly reaches the performance of a SOT
    
[^130]: 在神经网络中结合最优路径搜索和任务相关学习

    Combining optimal path search with task-dependent learning in a neural network. (arXiv:2201.11104v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.11104](http://arxiv.org/abs/2201.11104)

    这篇论文提出了一种在神经网络中结合最优路径搜索和任务相关学习的方法，通过将成本值转化为神经网络的权重来实现在线权重适应。实验结果表明，该方法与经典算法Bellman-Ford具有相同的解，并且网络学习机制可以进一步增强算法的性能。

    

    在连接图中找到最优路径需要确定沿着图的边缘行进的最小总成本。这个问题可以通过几种经典算法来解决，通常所有边缘的成本都是预先定义好的。因此，在想要根据某个任务的要求以自适应的方式改变成本时，通常无法使用传统规划方法。在这里，我们展示了可以通过将成本值转化为突触权重来定义路径搜索问题的神经网络表示，这允许使用网络学习机制进行在线权重适应。当从一个初始活跃度值为1开始时，在这个网络中的活动传播将导致与Bellman-Ford算法找到的解相同的解。神经网络具有与Bellman-Ford相同的算法复杂度，并且此外，我们可以证明网络学习机制（如赫布学习）可以调整网络中的权重来增强算法的性能。

    Finding optimal paths in connected graphs requires determining the smallest total cost for traveling along the graph's edges. This problem can be solved by several classical algorithms where, usually, costs are predefined for all edges. Conventional planning methods can, thus, normally not be used when wanting to change costs in an adaptive way following the requirements of some task. Here we show that one can define a neural network representation of path finding problems by transforming cost values into synaptic weights, which allows for online weight adaptation using network learning mechanisms. When starting with an initial activity value of one, activity propagation in this network will lead to solutions, which are identical to those found by the Bellman-Ford algorithm. The neural network has the same algorithmic complexity as Bellman-Ford and, in addition, we can show that network learning mechanisms (such as Hebbian learning) can adapt the weights in the network augmenting the r
    
[^131]: 基于熵的时间序列摘要因果图的发现

    Entropy-based Discovery of Summary Causal Graphs in Time Series. (arXiv:2105.10381v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2105.10381](http://arxiv.org/abs/2105.10381)

    该研究提出了一种基于熵的方法，在时间序列中学习摘要因果图，并通过PC-like和FCI-like算法展示了其有效性和高效性。

    

    本研究解决了在可能具有不同采样频率的时间序列上学习摘要因果图的问题。为此，我们首先提出了一种用于时间序列的新因果时态互信息度量。然后，我们展示了该度量与熵减原理的关系，可以看作是概率提升原理的特殊情况。最后，我们将这两个要素结合在类似于PC和FCI的算法中，构建了摘要因果图。这些算法在多个数据集上进行了评估，显示出它们的有效性和高效性。

    This study addresses the problem of learning a summary causal graph on time series with potentially different sampling rates. To do so, we first propose a new causal temporal mutual information measure for time series. We then show how this measure relates to an entropy reduction principle that can be seen as a special case of the probability raising principle. We finally combine these two ingredients in PC-like and FCI-like algorithms to construct the summary causal graph. There algorithm are evaluated on several datasets, which shows both their efficacy and efficiency.
    
[^132]: 无模型的基于奖赏梯度的策略学习

    Model-free Policy Learning with Reward Gradients. (arXiv:2103.05147v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.05147](http://arxiv.org/abs/2103.05147)

    本研究开发了一种新颖的方法，无需学习模型即可集成奖赏梯度，提高了策略学习的样本效率。

    

    尽管策略梯度方法越来越受欢迎，但在样本稀缺的应用中，如机器人学，它们仍未被广泛利用。通过充分利用可用信息，可以提高样本效率。作为增强学习中的重要组成部分，奖赏函数通常被精心设计以引导智能体。因此，奖赏函数通常是已知的，可以访问标量奖赏信号和奖赏梯度。为了从奖赏梯度中获益，之前的工作需要了解环境动态，这是很难获得的。在这项工作中，我们开发了一种新颖的方法——奖赏策略梯度估计器，它可以集成奖赏梯度而无需学习模型。绕过模型动态使我们的估计器能够在偏差-方差权衡方面取得更好的效果，这导致更高的样本效率，如经验分析所示。我们的方法还提升了不同环境下的近端策略优化的性能。

    Despite the increasing popularity of policy gradient methods, they are yet to be widely utilized in sample-scarce applications, such as robotics. The sample efficiency could be improved by making best usage of available information. As a key component in reinforcement learning, the reward function is usually devised carefully to guide the agent. Hence, the reward function is usually known, allowing access to not only scalar reward signals but also reward gradients. To benefit from reward gradients, previous works require the knowledge of environment dynamics, which are hard to obtain. In this work, we develop the \textit{Reward Policy Gradient} estimator, a novel approach that integrates reward gradients without learning a model. Bypassing the model dynamics allows our estimator to achieve a better bias-variance trade-off, which results in a higher sample efficiency, as shown in the empirical analysis. Our method also boosts the performance of Proximal Policy Optimization on different 
    
[^133]: 位置游戏与QBF：一个完善的编码

    Positional Games and QBF: A Polished Encoding. (arXiv:2005.05098v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2005.05098](http://arxiv.org/abs/2005.05098)

    这项研究提出了一种将位置游戏编码为QBF的方法，通过结构特性和对非法移动的处理，生成更紧凑的实例，提高了求解速度。这些编码方法还可以应用于其他位置游戏，并可用于翻译实际问题。

    

    位置游戏是一类数学上的双人游戏，包括井字棋及其推广。我们提出了一种新颖的将这些游戏编码成量化布尔公式（QBF）的方法，使得游戏实例存在第一玩家的胜利策略当且仅当相应的公式为真。我们的方法在多个方面改进了先前的QBF游戏编码。首先，它是通用的，并且允许我们编码其他位置游戏，如六角棋。其次，位置游戏的结构特性以及对非法移动的仔细处理使得我们能够生成更紧凑的实例，这些实例可以被最先进的QBF求解器更快地求解。我们通过大量实验确证了后一事实。最后，我们的新编码的紧凑性使得将现实中的游戏问题转化成QBF问题成为可能。我们确定了几个具有历史意义的实际问题，并将它们作为难度递增的里程碑向QBF社区提出。

    Positional games are a mathematical class of two-player games comprising Tic-tac-toe and its generalizations. We propose a novel encoding of these games into Quantified Boolean Formulas (QBFs) such that a game instance admits a winning strategy for the first player if and only if the corresponding formula is true. Our approach improves over previous QBF encodings of games in multiple ways. First, it is generic and lets us encode other positional games, such as Hex. Second, the structural properties of positional games, together with careful treatment of illegal moves, let us generate more compact instances that can be solved faster by state-of-the-art QBF solvers. We establish the latter fact through extensive experiments. Finally, the compactness of our new encoding makes it feasible to translate realistic game problems. We identify a few such problems of historical significance and put them forward to the QBF community as milestones of increasing difficulty.
    

