# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Synthetic Data Generation Framework, Dataset, and Efficient Deep Model for Pedestrian Intention Prediction.](http://arxiv.org/abs/2401.06757) | 本文提出了一个用于行人意图预测的合成数据生成框架ARCANE，并介绍了相应生成的大型多样化数据集PedSynth。同时，还提出了一种高效深度模型PedGNN，用于实时C/NC预测。 |
| [^2] | [The Unreasonable Effectiveness of Easy Training Data for Hard Tasks.](http://arxiv.org/abs/2401.06751) | 当困难训练数据很难正确标记时，当前的语言模型通常能够相对良好地从易到难的数据泛化，并且即使在关注于困难数据的性能时，收集和训练易数据可能比困难数据更好。 |
| [^3] | [Using Natural Language Inference to Improve Persona Extraction from Dialogue in a New Domain.](http://arxiv.org/abs/2401.06742) | 本研究通过使用自然语言推理方法，提出了一种后期适应已训练的角色提取模型到新领域中的方法，以解决对话中角色提取的多样性和非真实世界设置的问题。 |
| [^4] | [Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty.](http://arxiv.org/abs/2401.06730) | 本研究调查了语言模型在回答问题时不愿表达不确定性的影响，发现语言模型往往过于自信，导致高错误率。实验还表明用户无论是否标记了确定性都会严重依赖语言模型生成的结果。 |
| [^5] | [Reframing Tax Law Entailment as Analogical Reasoning.](http://arxiv.org/abs/2401.06715) | 本论文将法定推理重新定义为类比任务，通过增加数据集大小和引入解释性因素，展示了这个任务与原始任务的难度相当，并利用检索机制和类比模型解决法定推理问题，在之前的可比工作上取得了一些进展。 |
| [^6] | [Reliability Analysis of Psychological Concept Extraction and Classification in User-penned Text.](http://arxiv.org/abs/2401.06709) | 该论文研究了在用户撰写的文本中心理概念提取和分类的可靠性分析，并通过注解LoST数据集来捕捉表明低自尊存在的微妙文本提示。研究发现，NLP模型对触发词、LoST指标和后果这三类文本提示更加关注。 |
| [^7] | [A Closed-form Solution for Weight Optimization in Fully-connected Feed-forward Neural Networks.](http://arxiv.org/abs/2401.06699) | 本文提出了一种闭合解法，通过最小二乘法来优化全连接前馈神经网络的权重，具有非常高的效率和独立性。 |
| [^8] | [An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models.](http://arxiv.org/abs/2401.06692) | 该论文提出了一个实验设计框架来减少大型语言模型有限标签监督微调的注释成本，并解决了主动学习的计算瓶颈问题。 |
| [^9] | [Exploring Conversational Agents as an Effective Tool for Measuring Cognitive Biases in Decision-Making.](http://arxiv.org/abs/2401.06686) | 本研究探索了对话代理作为衡量决策中认知偏差的有效工具，通过对不同领域中的各种认知偏差进行测量。实验结果表明，对话代理可以有效地用于测量框架和损失厌恶偏差。 |
| [^10] | [DQNC2S: DQN-based Cross-stream Crisis event Summarizer.](http://arxiv.org/abs/2401.06683) | 本研究提出了一种基于DQN的在线危机事件摘要生成方法，能够同时总结多个灾害相关的数据流，无需人工标注或内容重新排序，且具有较好的性能表现。 |
| [^11] | [LLMRS: Unlocking Potentials of LLM-Based Recommender Systems for Software Purchase.](http://arxiv.org/abs/2401.06676) | LLMRS是一种基于LLM的零-shot推荐系统，可以将用户评论编码为评论分数并生成个性化推荐。实验证明，LLMRS在软件购买方面的推荐性能超过基准模型，并成功从产品评论中捕捉到有意义的信息，提供更可靠的推荐。 |
| [^12] | [Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI Benchmarks.](http://arxiv.org/abs/2401.06654) | 本研究提出了两个视角来解决基于遮挡的解释方法中的矛盾问题，首先通过使用R-OMS得分来衡量可靠性，然后通过解耦像素翻转和遮挡策略来提高结果的一致性。 |
| [^13] | [Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently.](http://arxiv.org/abs/2401.06640) | 本研究通过控制实验环境的方式，发现语言模型在属性继承任务中表现出了一定的非平凡能力，但这种能力是不一致的。 |
| [^14] | [CCFC: Bridging Federated Clustering and Contrastive Learning.](http://arxiv.org/abs/2401.06634) | 本论文桥接了联邦聚类和对比学习，提出了一种名为CCFC的新联邦聚类方法。通过表示学习，CCFC在某些情况下聚类性能甚至是最佳基准方法的两倍。与最相关的基准方法相比，在最显著的案例中，CCFC的NMI得分提高了0.4155。同时，CCFC还能有效处理联邦场景下的数据分布和质量差异。 |
| [^15] | [Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations.](http://arxiv.org/abs/2401.06633) | Ada-Retrieval是一种适应性多轮检索范例，用于提升推荐系统的物品候选者选择过程。它通过迭代地改进用户表示来更好地捕捉完整的物品空间中的潜在候选者，并具有模型无关的设计。 |
| [^16] | [Every Node is Different: Dynamically Fusing Self-Supervised Tasks for Attributed Graph Clustering.](http://arxiv.org/abs/2401.06595) | 提出了一种动态融合自监督任务并学习不同节点的权重的方法，通过从不同的SSL任务中提取的特征融合来提高属性图聚类的性能。 |
| [^17] | [Dynamic Behaviour of Connectionist Speech Recognition with Strong Latency Constraints.](http://arxiv.org/abs/2401.06588) | 本文研究了具有强延迟约束条件下的连接主义语音识别，在实时推导合成面部唇部运动的同时，亦关注了时间演化模型与转移模型的相互作用。实验结果表明神经网络拓扑结构、语言模型中的时间依赖关系和解码器延迟之间存在强烈相互作用。 |
| [^18] | [Mapping Transformer Leveraged Embeddings for Cross-Lingual Document Representation.](http://arxiv.org/abs/2401.06583) | 本研究通过使用预训练的变形器模型和映射方法，探索了跨语言文档表示的方法。实验结果表明，通过映射到跨语言领域的变形器技术文档表示（TLDRs），能够有效地实现跨语言的推荐系统。 |
| [^19] | [Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation.](http://arxiv.org/abs/2401.06568) | 本论文研究了大型语言模型（LLMs）如何利用源语言和参考信息评估机器翻译的质量，并发现参考信息显著提高了评估准确性，而源语言信息有时会适得其反，表明在使用LLMs评估翻译时存在跨语言能力不足的问题。 |
| [^20] | [A General Benchmark Framework is Dynamic Graph Neural Network Need.](http://arxiv.org/abs/2401.06559) | 本文强调了动态图学习的重要性及其在各个领域中的应用，并强调了对捕捉时间动态、演化图结构和下游任务需求的标准化基准框架的需求。缺乏统一的基准框架是当前动态图学习研究的局限之处，建立这样的框架将有助于推动动态图学习技术的进步。 |
| [^21] | [Treatment-Aware Hyperbolic Representation Learning for Causal Effect Estimation with Social Networks.](http://arxiv.org/abs/2401.06557) | 该论文提出了一种新的方法，称为Treatment-Aware Hyperbolic Representation Learning（TAHyper），用于利用超螺旋空间学习社交网络中隐藏混淆因素的表示，从而改进个体治疗效应的估计。 |
| [^22] | [Multimodal Learning for detecting urban functional zones using remote sensing image and multi-semantic information.](http://arxiv.org/abs/2401.06550) | 本研究提出了一种利用遥感图像和多语义信息进行城市功能区检测的多模态学习算法，能够满足移动互联网在线到离线业务的精确要求。 |
| [^23] | [Medical Dialogue Generation via Intuitive-then-Analytical Differential Diagnosis.](http://arxiv.org/abs/2401.06541) | 本研究提出了一种医疗对话生成框架，通过直觉-分析式鉴别诊断（IADDx）实现了对医疗对话的生成。该方法使用直觉和分析推理来建立鉴别诊断，并通过图增强的分析方法进行细化，提高了医疗对话系统的实际应用价值。 |
| [^24] | [Intelligent Data-Driven Architectural Features Orchestration for Network Slicing.](http://arxiv.org/abs/2401.06538) | 本论文讨论了基于机器学习的网络切片架构中特征和能力编排的问题和挑战，提出了使用机器学习嵌入的代理进行智能的资源和功能编排的建议。 |
| [^25] | [PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed Circuit Boards.](http://arxiv.org/abs/2401.06528) | 本文提出了一个开创性的RGB-高光谱印制电路板（PCB）基准数据集，通过利用非侵入性分析方法，提供了对废弃电子产品回收过程的定量和定性洞察力，以优化回收效率。 |
| [^26] | [ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A Case Study.](http://arxiv.org/abs/2401.06513) | ML-On-Rails是一个旨在保护机器学习模型的协议，在软件系统中解决了安全性、可靠性和透明度等挑战，并在生产环境中提高了模型的鲁棒性。通过一项实际案例研究，我们强调了保护ML模型在生产中的重要性。 |
| [^27] | [Frequency Masking for Universal Deepfake Detection.](http://arxiv.org/abs/2401.06506) | 本研究针对通用深度伪造检测问题，首次尝试探索了将屏蔽图像建模应用于频率屏蔽的方法，相较于已有方法，在检测性能上取得了显著提升。 |
| [^28] | [Improving the Detection of Small Oriented Objects in Aerial Images.](http://arxiv.org/abs/2401.06503) | 本研究提出了一种改进的方法，通过增强有方向物体检测模型的任务，准确地检测航空图像中的小型有方向物体。实验结果表明，我们的方法在航空数据集上取得了显著的效果。 |
| [^29] | [Expected Shapley-Like Scores of Boolean Functions: Complexity and Applications to Probabilistic Databases.](http://arxiv.org/abs/2401.06493) | 这篇论文提出了一种适应概率环境的类Shapley分数，用于评估数据库中事实对查询回答的贡献。通过研究布尔函数的可处理情况，设计了一个多项式时间的算法，并在概率数据库中应用该算法。 |
| [^30] | [Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation.](http://arxiv.org/abs/2401.06477) | Kun是一种使用指令反向翻译和答案优化的方法，用于创建高质量的指导调整数据集，该方法不依赖于手动注释，通过自我筛选过程来改善和选择最有效的指令-输出对。它的主要创新在于通过算法改进提高数据的保留和清晰度，并通过创新的数据生成方法减少了手动注释的依赖。 |
| [^31] | [A Brain-inspired Computational Model for Human-like Concept Learning.](http://arxiv.org/abs/2401.06471) | 本研究开发了一种基于脉冲神经网络的人类概念学习计算模型，该模型借鉴了多感官表示和文本导出的机制，并通过语义控制系统协调两种类型的表示，从而模拟了人类概念习得的过程。 |
| [^32] | [PersianMind: A Cross-Lingual Persian-English Large Language Model.](http://arxiv.org/abs/2401.06466) | PersianMind是一个开源的双语大型语言模型，通过在波斯语中展现与闭源的GPT-3.5-turbo相当的性能，并利用迁移学习在不同语言间传递任务知识的优势，解决了开源模型在非英文语言上性能不佳的问题。 |
| [^33] | [Sanity Checks Revisited: An Exploration to Repair the Model Parameter Randomisation Test.](http://arxiv.org/abs/2401.06465) | 这项研究对模型参数随机化测试进行了探索和修复，通过引入平滑 MPRT 和高效 MPRT 两种改进方法，解决了实证解释的方法论注意事项，并通过实验结果证明这些改进方法可以提高度量可靠性，从而更可信地应用可解释人工智能方法。 |
| [^34] | [Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers.](http://arxiv.org/abs/2401.06461) | 本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。 |
| [^35] | [3D-PreMise: Can Large Language Models Generate 3D Shapes with Sharp Features and Parametric Control?.](http://arxiv.org/abs/2401.06437) | 本研究介绍了一种利用大型语言模型的框架，通过程序合成操控3D软件生成具有尖锐特征和参数控制的3D形状。我们提出了一个专门的数据集和流程来探究最先进的语言模型，在工业应用的3D参数建模中揭示了LLMs的潜力和局限性。 |
| [^36] | [Improving Graph Convolutional Networks with Transformer Layer in social-based items recommendation.](http://arxiv.org/abs/2401.06436) | 本文提出了一种在社交网络中预测评分的方法，该方法通过在GCN模型中引入Transformer层，在节点嵌入方面取得了更好的性能。 |
| [^37] | [From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape.](http://arxiv.org/abs/2401.06431) | 本研究调查了大型语言模型（LLM）在自动化作文评分系统中的有效性，并发现LLM AES系统具有更高的准确性、一致性、普适性和可解释性。此外，LLM还能提升人类评分员的性能。 |
| [^38] | [UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer.](http://arxiv.org/abs/2401.06426) | UPDP是一种适用于CNN和Vision Transformer的统一渐进深度修剪器，通过引入新的块修剪策略和渐进训练方法，解决了传统的修剪方法在修剪高效模型时遇到的问题，且在各种修剪配置下表现优于现有的深度修剪方法。 |
| [^39] | [Uncertainty quantification for probabilistic machine learning in earth observation using conformal prediction.](http://arxiv.org/abs/2401.06421) | 本论文介绍了地球观测领域中使用符合预测进行不确定性量化的方法。与其他方法不同，符合预测不需要访问底层模型和训练数据集，并同时提供统计上有效和有信息的预测区域，同时保持计算效率。 |
| [^40] | [Mission: Impossible Language Models.](http://arxiv.org/abs/2401.06416) | 本文为了支持大型语言模型(LLMs)能够学习不可能的语言的观点，开发了一组人工合成的不可能语言，并通过评估GPT-2小型模型的学习能力得出了结论。 |
| [^41] | [Knowledge-Informed Machine Learning for Cancer Diagnosis and Prognosis: A review.](http://arxiv.org/abs/2401.06406) | 知识驱动的机器学习在癌症诊断和预后中的应用已经取得了一定的进展。该方法将生物医学知识与数据驱动模型相结合，能够提高模型结果的准确性、鲁棒性和可解释性。这篇综述回顾了最新研究，并强调了四个主要特点。 |
| [^42] | [DevEval: Evaluating Code Generation in Practical Software Projects.](http://arxiv.org/abs/2401.06401) | 本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。 |
| [^43] | [Adaptive Data Augmentation for Aspect Sentiment Quad Prediction.](http://arxiv.org/abs/2401.06394) | 本文提出了一种自适应数据增强（ADA）框架来解决方面情感四元预测（ASQP）任务中的数据不平衡问题。实验证实，数据增强可以改善ASQP任务的性能，而ADA方法优于简单的数据过采样方法。 |
| [^44] | [What should I say? -- Interacting with AI and Natural Language Interfaces.](http://arxiv.org/abs/2401.06382) | 随着人工智能技术的普及，研究人类与AI的交互变得越来越重要。本研究通过探索人类与AI交互过程中心智表征的建立，旨在帮助实现成功和轻松的沟通。 |
| [^45] | [Vehicle: Bridging the Embedding Gap in the Verification of Neuro-Symbolic Programs.](http://arxiv.org/abs/2401.06379) | 本文提出了一个名为Vehicle的工具，它能够在验证神经符号化程序中弥合嵌入缺口，为指定神经网络属性和解释其与嵌入空间的关系提供了方便的语言和强大的编译器。 |
| [^46] | [Cognitive BPM as an Equalizer: Improving Access and Efficiency for Employees with (and without) Cognitive Disabilities.](http://arxiv.org/abs/2401.06375) | 本研究以ProcessGPT为例，探讨了在人类认知限制下管理业务流程的挑战，特别是针对认知障碍个体。研究表明，ProcessGPT改善了不同认知能力的个体的流程可用性，对组织来说也能带来更高的生产力、士气和包容性。 |
| [^47] | [How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs.](http://arxiv.org/abs/2401.06373) | 本文通过将LLMs视为人类交流者，探索了每天语言互动和AI安全之间忽视的交叉点，并提出了一种通过说服LLMs进行越狱的方法。研究结果表明，说服显著提高了越狱性能，在多个风险类别上均取得了超过92%的攻击成功率。 |
| [^48] | [Graph Relation Distillation for Efficient Biomedical Instance Segmentation.](http://arxiv.org/abs/2401.06370) | 本研究提出了一种用于高效生物医学实例分割的图关系蒸馏方法，通过考虑实例级特征、实例关系和像素级边界的知识，使用实例图蒸馏和亲和图蒸馏来解决资源需求巨大的问题。 |
| [^49] | [A Temporal-Spectral Fusion Transformer with Subject-specific Adapter for Enhancing RSVP-BCI Decoding.](http://arxiv.org/abs/2401.06340) | 本文提出了一种基于主题专用适配器的时间-频谱融合Transformer (TSformer-SA) 用于增强RSVP-BCI解码。该方法通过引入多视图信息并减少准备时间，实现了解码性能的提升。 |
| [^50] | [Striking a Balance in Fairness for Dynamic Systems Through Reinforcement Learning.](http://arxiv.org/abs/2401.06318) | 本文研究了在决策模型操作的动态人口中的公平性问题，并提出了一种通过强化学习结合各种公平考虑的算法框架。通过预处理和处理中的方法，我们的方法能够在传统公平性、长期公平性和效用之间取得平衡。 |
| [^51] | [A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic 6G-Based Applications.](http://arxiv.org/abs/2401.06308) | 本文提出了一种语义感知多址访问方案，旨在优化资源利用与公平性的权衡，并考虑用户数据的相关性，以满足未来6G应用的要求和特性。 |
| [^52] | [Advantage of Quantum Neural Networks as Quantum Information Decoders.](http://arxiv.org/abs/2401.06300) | 本论文研究了量子神经网络（QNN）作为解码器在解码量子信息时的优势。实验证明，QNN解码器在读取错误方面几乎具有二次改进。这使得在解码实际的量子纠错码时可以探索更广泛的非稳定器码。 |
| [^53] | [MultiSlot ReRanker: A Generic Model-based Re-Ranking Framework in Recommendation Systems.](http://arxiv.org/abs/2401.06293) | 多插槽重新排序器是一个通用的基于模型的重新排序框架，在推荐系统中同时优化相关性、多样性和新鲜度。它通过建模物品之间的相互影响和利用多个目标的第二次排序得分来提高离线AUC，并通过离线回放理论在多个目标之间进行权衡，进一步改善离线回放结果。 |
| [^54] | [A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI.](http://arxiv.org/abs/2401.06256) | 本文提出了一个普适的知识模型和认知架构，用于原型开发通用人工智能（AGI）。该架构包括42种认知架构和一组功能模块，用于接近AGI能力的智能系统。此外，本文还提出了一种通用的知识表示方法，可以将各种不同形式的知识表示整合到一个知识库中。 |
| [^55] | [WISE: full-Waveform variational Inference via Subsurface Extensions.](http://arxiv.org/abs/2401.06230) | WISE是一种通过地下扩展进行全波形变分推断的方法，能够准确量化偏移速度模型对成像的影响，并且不依赖于准确的初始速度模型。 |
| [^56] | [Learning Unsupervised Semantic Document Representation for Fine-grained Aspect-based Sentiment Analysis.](http://arxiv.org/abs/2401.06210) | 这篇论文研究了学习无监督的语义文档表示以进行细粒度的基于方面的情感分析。通过克服现有方法的困难，实验证明该模型在各个任务上的性能优于最先进方法。 |
| [^57] | [An Exploratory Assessment of LLM's Potential Toward Flight Trajectory Reconstruction Analysis.](http://arxiv.org/abs/2401.06204) | 本研究探索了大型语言模型（LLMs）在航空领域中重建飞行轨迹的潜力，并通过使用ADS-B数据对LLaMA 2模型进行实证研究，发现LLMs在过滤噪音和估计飞行轨迹方面表现出色。然而，研究也揭示了处理较长数据序列的挑战，该挑战可能源于LLM模型的标记长度限制。这些研究结果强调了LLMs在航空和交通领域广泛应用的潜力。 |
| [^58] | [xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein.](http://arxiv.org/abs/2401.06199) | xTrimoPGLM是一个统一的100亿规模预训练蛋白质语言模型，能够同时处理蛋白质理解和生成任务，通过创新的预训练框架和大规模的参数训练，显著优于其他先进模型，在18个蛋白理解基准测试中取得了成功，并能够实现对蛋白质结构的原子分辨率观察。 |
| [^59] | [NeuSpin: Design of a Reliable Edge Neuromorphic System Based on Spintronics for Green AI.](http://arxiv.org/abs/2401.06195) | NeuSpin是一个全栈硬件和软件共同设计的项目，旨在解决使用自旋电子学技术在边缘进行绿色人工智能实现的挑战。通过计算内存一体化，NeuSPIN可以实现超低功耗、高处理能力以及可靠性的要求，从而促进物联网和智能可穿戴设备的发展。 |
| [^60] | [CrisisKAN: Knowledge-infused and Explainable Multimodal Attention Network for Crisis Event Classification.](http://arxiv.org/abs/2401.06194) | CrisisKAN是一种知识注入和可解释的多模态注意力网络，用于危机事件分类。它通过结合图像、文本和维基百科的外部知识来弥合图像和文本模态之间的语义差距，并解释模型的结果，以建立在高风险情况下的信任。 |
| [^61] | [End to end Hindi to English speech conversion using Bark, mBART and a finetuned XLSR Wav2Vec2.](http://arxiv.org/abs/2401.06183) | 本论文提出了一个端到端的语音转换框架，用于印地语到英语的转换，采用了Bark、mBART和经过微调的XLSR Wav2Vec2等先进技术，为跨语言交流提供了统一而无缝的解决方案。 |
| [^62] | [AI Art is Theft: Labour, Extraction, and Exploitation, Or, On the Dangers of Stochastic Pollocks.](http://arxiv.org/abs/2401.06178) | 这篇论文分析、证实和批评了商业领导者使用AI图像生成取代人类艺术劳动力的行为，并指出这种AI图像生成涉及一种不道德的劳动性盗窃，这对许多其他的AI应用也具有影响。 |
| [^63] | [GOODAT: Towards Test-time Graph Out-of-Distribution Detection.](http://arxiv.org/abs/2401.06176) | GOODAT是一种用于检测测试时图形领域外样本的方法，具有数据驱动、无监督和即插即用的特点。 |
| [^64] | [MTAD: Tools and Benchmarks for Multivariate Time Series Anomaly Detection.](http://arxiv.org/abs/2401.06175) | 这篇论文提出了一套综合的多元时间序列异常检测工具和基准，解决了现有方法缺乏严格比较和重新实现困难的问题。 |
| [^65] | [Harnessing Artificial Intelligence for Sustainable Agricultural Development in Africa: Opportunities, Challenges, and Impact.](http://arxiv.org/abs/2401.06171) | 本文探索了人工智能在非洲农业可持续发展中的潜力，并研究了精准农业、作物监测和气候适应性实践等机会，并分析了技术基础设施、数据获取和技能缺口等挑战。此外，本文还讨论了人工智能对小农户、供应链和包容性增长的影响，并提出了负责任的人工智能整合方法。 |
| [^66] | [A Survey on Game Theory Optimal Poker.](http://arxiv.org/abs/2401.06168) | 本文调查了博弈论最优扑克，比较了博弈论最优扑克和剥削扑克的差异，讨论了扑克机器人所采用的特定策略，探讨了2人对多人游戏的不同以及与玩更多玩家时出现的局限性，同时还讨论了机器学习和理论方法在开发获胜策略中的作用。 |
| [^67] | [Enhancing Multimodal Understanding with CLIP-Based Image-to-Text Transformation.](http://arxiv.org/abs/2401.06167) | 本文提出了一种集成方法，利用对比式语言图像预训练模型的能力，来实现图像到文本的转换，进而增强多模态理解能力。 |
| [^68] | [A debiasing technique for place-based algorithmic patrol management.](http://arxiv.org/abs/2401.06162) | 这项工作介绍了一种用于基于地点的算法巡逻管理系统的去偏技术，该技术能够有效消除种族偏见特征并保留高准确性的模型。 |
| [^69] | [Trustworthy human-centric based Automated Decision-Making Systems.](http://arxiv.org/abs/2401.06161) | 该论文讨论了自动决策系统在当代社会和未来环境中的潜在风险，以及在部署ADS时的规范、透明度和伦理行为的必要性。 |
| [^70] | [Future-proofing Education: A Prototype for Simulating Oral Examinations Using Large Language Models.](http://arxiv.org/abs/2401.06160) | 使用大型语言模型模拟口试的原型在未来教育中具有潜力，可以实现教育民主化、包容多样的学生群体以及提高教学质量和效率。 |
| [^71] | [UDEEP: Edge-based Computer Vision for In-Situ Underwater Crayfish and Plastic Detection.](http://arxiv.org/abs/2401.06157) | UDEEP是一个基于边缘计算机视觉的平台，可以帮助解决入侵信号龙虾和废弃塑料对水生生态系统的挑战。 |
| [^72] | [Multi-Modal Optimization with k-Cluster Big Bang-Big Crunch Algorithm.](http://arxiv.org/abs/2401.06153) | 这篇论文提出了一种基于聚类的多模态优化Big Bang-Big Crunch算法的版本，称为k-BBBC。该算法能够高效地解决多模态优化问题，并在测试中表现出良好的性能。 |
| [^73] | [Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein Complexes with SE(3)-Discrete Diffusion.](http://arxiv.org/abs/2401.06151) | MMDiff是一个联合生成核酸和蛋白质复合物序列和结构的生成模型，具有重要的大分子设计应用价值，并通过验证实例展示了其有效性。 |
| [^74] | [D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation.](http://arxiv.org/abs/2401.06150) | D-STGCNT是一种新的模型，结合了STGCN和transformer的架构，用于自动评估患者身体康复锻炼。它通过将骨架数据视为图形，并检测关键关节，在处理时空数据方面具有高效性。该模型通过密集连接和GRU机制来处理大型3D骨架输入，有效建立时空动态模型。transformer的注意力机制对于评估康复锻炼非常有用。 |
| [^75] | [Artificial Intelligence for Digital and Computational Pathology.](http://arxiv.org/abs/2401.06148) | 本综述总结了计算病理学在自动化临床实践和发现新生物标记物方面的最新进展，并提供了未来展望，该领域会涉及更广泛的临床和研究任务，以及不断增多的临床数据模态。 |
| [^76] | [Redefining Recon: Bridging Gaps with UAVs, 360 degree Cameras, and Neural Radiance Fields.](http://arxiv.org/abs/2401.06143) | 本文介绍了一种创新的方法，利用小型无人机配备360度摄像头和神经辐射场（NeRFs）技术，在城市环境中生成精确的3D模型，特别适用于经历严重破坏的场景。我们的方法在火灾场景下经过测试，证明了NeRFs的高效性。 |
| [^77] | [QuasiNet: a neural network with trainable product layers.](http://arxiv.org/abs/2401.06137) | QuasiNet是一种新的神经网络模型，通过可训练的乘积层解决了小规模隐藏神经元下传统神经网络在难问题上的有限收敛问题，具有更高的成功率。 |
| [^78] | [Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models.](http://arxiv.org/abs/2401.06102) | 本论文提出了一个叫做Patchscope的框架，用于检查语言模型的隐藏表示。该框架不仅统一了先前的检查技术，还解决了其中一些问题，并且还开辟了新的可能性。 |
| [^79] | [Secrets of RLHF in Large Language Models Part II: Reward Modeling.](http://arxiv.org/abs/2401.06080) | 本报告探讨了在 RLHF 中解决奖励建模的两个挑战，通过使用多个奖励模型的投票机制来测量数据中偏好的强度，并解决在特定分布数据上训练奖励模型难以推广的问题。 |
| [^80] | [Surgical-DINO: Adapter Learning of Foundation Model for Depth Estimation in Endoscopic Surgery.](http://arxiv.org/abs/2401.06013) | 本研究提出了一种基于基础模型的适配器学习方法，针对内窥镜手术中的深度估计问题进行了改进。通过在DINO模型中构建LoRA层，并将其与手术场景的特征结合起来，实现了手术特定的深度估计。实验结果表明，该方法在内窥镜手术中取得了良好的性能。 |
| [^81] | [Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks.](http://arxiv.org/abs/2401.05949) | 本研究发现上下文学习范式在大型语言模型中存在漏洞，攻击者可以通过污染示范上下文来操控模型行为，而无需进行微调。这项研究设计了一种名为ICLAttack的后门攻击方法，可以通过污染示范样本和提示来使模型按照预定义的意图行事。 |
| [^82] | [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training.](http://arxiv.org/abs/2401.05566) | 该论文研究了在大型语言模型中训练并保持持久的欺骗性行为，这种行为无法被当前的安全训练技术移除。 |
| [^83] | [Functional Graphical Models: Structure Enables Offline Data-Driven Optimization.](http://arxiv.org/abs/2401.05442) | 功能图模型（FGMs）通过结构实现了样本高效的数据驱动优化。 |
| [^84] | [Representation Learning for Wearable-Based Applications in the Case of Missing Data.](http://arxiv.org/abs/2401.05437) | 本论文研究了可穿戴应用中表示学习的问题，特别是在缺失数据情况下。作者通过比较Transformer模型和统计方法的性能，发现Transformer模型在变化频繁的信号的缺失数据填充方面表现优秀。此研究为基于掩码的自监督学习任务的设计和开发提供了洞察。 |
| [^85] | [RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation.](http://arxiv.org/abs/2401.04679) | RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。 |
| [^86] | [MERA: A Comprehensive LLM Evaluation in Russian.](http://arxiv.org/abs/2401.04531) | 这项研究提出了MERA，一个多模态俄语基础模型评估指标。该指标包括21个评估任务，涵盖了11个技能领域中生成模型的评估。研究还提出了一种在零样本和少样本固定指令设置下评估FM和LM的方法。 |
| [^87] | [Simultaneous Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications.](http://arxiv.org/abs/2401.04003) | 该论文介绍了在多机器人系统中，利用层次化时间逻辑规范实现同时的任务分配和规划的方法。通过引入层次化结构到LTL规范中，该方法更具表达能力。采用基于搜索的方法来综合多机器人系统的计划，将搜索空间拆分为松散相互连接的子空间，以便更高效地进行任务分配和规划。 |
| [^88] | [Can AI Be as Creative as Humans?.](http://arxiv.org/abs/2401.01623) | 本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。 |
| [^89] | [LLaMA Beyond English: An Empirical Study on Language Capability Transfer.](http://arxiv.org/abs/2401.01055) | 本文提出了LLaMA超越英语：语言能力转移的实证研究。通过对LLaMA进行广泛的实证调查，分析了词汇扩展、进一步预训练和指导调整等关键因素对非英语语言上的能力转移的影响，并通过四个标准化测试基准评估了模型的知识水平和响应质量。 |
| [^90] | [A Comprehensive Survey of Evaluation Techniques for Recommendation Systems.](http://arxiv.org/abs/2312.16015) | 本文介绍了一套综合的推荐系统评估指标，包括相似性指标、候选生成指标、预测指标、排序指标和业务指标。 |
| [^91] | [NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes.](http://arxiv.org/abs/2312.14890) | NPHardEval是一个新的基准，旨在评估大型语言模型在900个算法问题上的推理能力，扩展到NP-Hard复杂性类别。 |
| [^92] | [Quantum Polar Metric Learning: Efficient Classically Learned Quantum Embeddings.](http://arxiv.org/abs/2312.01655) | 本论文提出了一种称为量子极坐标度量学习(QPMeL)的方法，通过经典模型学习量子比特的极坐标形式的参数，然后使用浅层PQC和可训练的门层来创建量子态和学习纠缠。与QMeL相比，QPMeL具有更高效的计算性能和可扩展性。 |
| [^93] | [Grounding Foundation Models through Federated Transfer Learning: A General Framework.](http://arxiv.org/abs/2311.17431) | 本论文提出了一个通用框架，通过联邦迁移学习将基础模型接地，以解决面临的挑战，如受限的计算资源、数据隐私、模型异构性和模型所有权。这个框架可以帮助释放基础模型的潜力，并在不同行业中产生重要影响。 |
| [^94] | [The Impact of Adversarial Node Placement in Decentralized Federated Learning Networks.](http://arxiv.org/abs/2311.07946) | 本文研究了分布式联邦学习网络中对抗节点部署的影响，提出了两种基线策略，并提出了一种新颖的攻击算法，优先考虑对抗的分散性而不是中心性。 |
| [^95] | [When Fairness Meets Privacy: Exploring Privacy Threats in Fair Binary Classifiers through Membership Inference Attacks.](http://arxiv.org/abs/2311.03865) | 本研究探索了公平二分类器中的隐私威胁，并揭示了针对公平增强模型的基于分数的成员推断攻击的无效性。同时，公平性方法可能导致训练数据中大多数子群体的预测性能下降。 |
| [^96] | [Inner-IoU: More Effective Intersection over Union Loss with Auxiliary Bounding Box.](http://arxiv.org/abs/2311.02877) | Inner-IoU损失通过使用不同尺度的辅助边界框计算损失，有效加速了边界框回归过程，并提供了更有效的交并比损失方法。 |
| [^97] | [DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with Diffusion Auto-encoder.](http://arxiv.org/abs/2311.01811) | 本论文提出了一种名为DiffDub的基于扩散的配音方法，使用扩散自动编码器和修复渲染器，在保留其他部分的同时无缝填充下半脸区域。通过使用多种策略，解决了语义编码和面部定位的挑战，提高了配音的质量和通用性。 |
| [^98] | [O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models.](http://arxiv.org/abs/2310.14403) | O3D提出了一种基于离线数据的学习框架，利用大规模数据改进了大规模语言模型在顺序决策问题中的性能，通过自动发现可重复使用的技能，提高了模型的表现 |
| [^99] | [Spike Accumulation Forwarding for Effective Training of Spiking Neural Networks.](http://arxiv.org/abs/2310.02772) | 本研究提出了一种名为脉冲累积转发（SAF）的方法，可以有效训练脉冲神经网络（SNNs）。SAF不仅可以减少前向过程中的操作次数，与Spike Representation和OTTT保持一致，而且可以解决SNNs训练中的难题。 |
| [^100] | [Computer Vision Technology for Robotized Wire Harness Assembly.](http://arxiv.org/abs/2309.13745) | 该论文介绍了机器人化线束装配的计算机视觉技术，以提高装配质量并优化人体工程学和劳动成本。 |
| [^101] | [Visual Speech Recognition for Low-resource Languages with Automatic Labels From Whisper Model.](http://arxiv.org/abs/2309.08535) | 本文提出了一种利用Whisper模型从未标注的多语言视听数据自动标注的方法，实现了在低资源语言中的视觉语音识别，并证明了该方法可以获得与人工标注相似的性能。 |
| [^102] | [Self-consistency for open-ended generations.](http://arxiv.org/abs/2307.06857) | 本论文提出了一种改进大规模预训练语言模型生成输出质量和一致性的新方法，通过扩展自洽性框架的适用性，实现了从一个候选集中恢复最优或接近最优的生成结果，并提出了一种轻量级无参数相似性函数来改进代码生成、自动形式化和摘要任务的效果。 |
| [^103] | [milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing.](http://arxiv.org/abs/2306.17010) | milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。 |
| [^104] | [Asynchronous Algorithmic Alignment with Cocycles.](http://arxiv.org/abs/2306.15632) | 该论文提出了一种将节点状态更新和消息函数调用分离的数学框架，以实现异步计算，并以此作为基础，进行了异步算法和神经网络的对齐。 |
| [^105] | [Enhancing variational quantum state diagonalization using reinforcement learning techniques.](http://arxiv.org/abs/2306.11086) | 本研究采用强化学习技术，通过新的编码方法来优化量子状态对角化所需的电路深度，从而提高其在近期量子硬件上的应用性能。 |
| [^106] | [LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning.](http://arxiv.org/abs/2306.09910) | 本论文介绍了一个新的综合性标签高效学习基准评估框架LabelBench，并通过引入一种新的与半监督学习相结合的主动学习方法的基准测试，证明了在相对较少的标记示例下实现更好的标签效率。 |
| [^107] | [Design Principles for Generalization and Scalability of AI in Communication Systems.](http://arxiv.org/abs/2306.06251) | 本文提出了可持续和可扩展的AI集成通信系统的设计原则，侧重于创建具备通用性的AI算法，通过少量的AI驱动的RAN函数来解决更大的问题，提高系统性能，并简化生命周期管理。 |
| [^108] | [A Unified Approach for Maximizing Continuous DR-submodular Functions.](http://arxiv.org/abs/2305.16671) | 本文提出了一种适用于一系列设置和 Oracle 访问类型的统一方法，用于最大化连续 DR-submodular 函数，为 16 种情况中的 9 种提供了新的/改进的结果，并且针对基于随机函数值的 Oracle 取得了第一个适用于随机 DR-submodular 函数的后悔界限。 |
| [^109] | [Bilingual analogical proportions.](http://arxiv.org/abs/2305.05614) | 本文在通用代数和一阶逻辑的一般设定下，推广了抽象的类比比例代数逻辑框架，实现了从单语言到双语言框架的转变，扩展了基础框架的适用性。 |
| [^110] | [TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins.](http://arxiv.org/abs/2303.15954) | TraffNet是一个学习交通量生成原因的深度学习框架，将车辆轨迹数据表示为异构图，利用递归神经网络结构实现了对交通生成原因的预测。 |
| [^111] | [Active Inference and Reinforcement Learning: A unified inference on continuous state and action spaces under partially observability.](http://arxiv.org/abs/2212.07946) | 本论文提出了一种能够在部分可观测的连续状态和动作空间下进行统一推理的框架，通过最小化期望自由能函数指导代理选择动作，以实现最大化奖励的决策制定。 |
| [^112] | [State-of-the-art generalisation research in NLP: A taxonomy and review.](http://arxiv.org/abs/2210.03050) | 本文提出了一个用于分类和理解NLP中泛化研究的分类法，对400多篇论文进行了综述和分类，总结了当前泛化研究的现状。 |
| [^113] | [Learning Temporal Resolution in Spectrogram for Audio Classification.](http://arxiv.org/abs/2210.01719) | 本文提出了一种新的方法DiffRes，可以实现音频分类中的可微分时间分辨率建模。给定一个用固定跳步大小计算的声谱图，DiffRes将非重要的时间帧合并，同时保留重要的帧。 |

# 详细

[^1]: 用于行人意图预测的合成数据生成框架、数据集和高效深度模型

    Synthetic Data Generation Framework, Dataset, and Efficient Deep Model for Pedestrian Intention Prediction. (arXiv:2401.06757v1 [cs.CV])

    [http://arxiv.org/abs/2401.06757](http://arxiv.org/abs/2401.06757)

    本文提出了一个用于行人意图预测的合成数据生成框架ARCANE，并介绍了相应生成的大型多样化数据集PedSynth。同时，还提出了一种高效深度模型PedGNN，用于实时C/NC预测。

    

    行人意图预测对于自主驾驶至关重要。特别是，了解行人是否将横穿在自主车辆前方对于执行安全和舒适的操控至关重要。从序列图像中准确且快速地预测此类意图的模型是具有挑战性的。导致这一挑战的一个因素是缺乏具有多样化横穿和非横穿（C/NC）场景的数据集。我们通过引入一个名为ARCANE的框架来解决这个问题，该框架允许自动地生成包含C/NC视频剪辑样本的合成数据集。作为一个示例，我们使用ARCANE生成了一个大型多样化的数据集，命名为PedSynth。我们将展示PedSynth如何补充广泛使用的实际数据集，如JAAD和PIE，从而为C/NC预测提供更准确的模型。考虑到C/NC预测模型的车载部署，我们还提出了一种名为PedGNN的深度模型，它速度快且内存占用非常低。PedGNN基于GNN-G模型。

    Pedestrian intention prediction is crucial for autonomous driving. In particular, knowing if pedestrians are going to cross in front of the ego-vehicle is core to performing safe and comfortable maneuvers. Creating accurate and fast models that predict such intentions from sequential images is challenging. A factor contributing to this is the lack of datasets with diverse crossing and non-crossing (C/NC) scenarios. We address this scarceness by introducing a framework, named ARCANE, which allows programmatically generating synthetic datasets consisting of C/NC video clip samples. As an example, we use ARCANE to generate a large and diverse dataset named PedSynth. We will show how PedSynth complements widely used real-world datasets such as JAAD and PIE, so enabling more accurate models for C/NC prediction. Considering the onboard deployment of C/NC prediction models, we also propose a deep model named PedGNN, which is fast and has a very low memory footprint. PedGNN is based on a GNN-G
    
[^2]: Easy Training Data对于困难任务的不合理有效性

    The Unreasonable Effectiveness of Easy Training Data for Hard Tasks. (arXiv:2401.06751v1 [cs.CL])

    [http://arxiv.org/abs/2401.06751](http://arxiv.org/abs/2401.06751)

    当困难训练数据很难正确标记时，当前的语言模型通常能够相对良好地从易到难的数据泛化，并且即使在关注于困难数据的性能时，收集和训练易数据可能比困难数据更好。

    

    当困难训练数据在定义上很难正确标记时，我们如何训练模型在困难测试数据上表现良好？这个问题被称为可扩展监督问题，在语言模型不断改进的过程中引起了越来越多的关注。在本文中，我们提出了一个令人惊讶的结论，即当前的语言模型通常从易到难的数据泛化相对良好，甚至表现得和在困难数据上训练的“oracle”模型一样好。我们使用简单的训练方法（如上下文学习、线性分类器头和QLoRA）展示了这种从易到难的泛化，针对七个不同的数据点难度度量，包括六个经验多样的人类难度度量（如年级水平）和一个基于模型的度量（基于损失）。此外，我们还表明，即使最关心模型在困难数据上的性能，收集并训练易数据可能比困难数据更好，因为困难数据通常更嘈杂和昂贵。

    How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current language models often generalize relatively well from easy to hard data, even performing as well as "oracle" models trained on hard data. We demonstrate this kind of easy-to-hard generalization using simple training methods like in-context learning, linear classifier heads, and QLoRA for seven different measures of datapoint hardness, including six empirically diverse human hardness measures (like grade level) and one model-based measure (loss-based). Furthermore, we show that even if one cares most about model performance on hard data, it can be better to collect and train on easy data rather than hard data, since hard data is generally noisier and costli
    
[^3]: 使用自然语言推理来改进对话中的角色提取在新领域中的应用

    Using Natural Language Inference to Improve Persona Extraction from Dialogue in a New Domain. (arXiv:2401.06742v1 [cs.CL])

    [http://arxiv.org/abs/2401.06742](http://arxiv.org/abs/2401.06742)

    本研究通过使用自然语言推理方法，提出了一种后期适应已训练的角色提取模型到新领域中的方法，以解决对话中角色提取的多样性和非真实世界设置的问题。

    

    虽然宝贵的数据集如PersonaChat为训练有基于角色的对话代理提供了基础，但它们在对话和叙事环境的多样性方面缺乏，主要存在于“真实”世界中。为了开发具有独特角色的对话代理，模型被训练以在给定特定角色的情况下进行对话，但手工制作这些角色可能耗时，因此存在从现有特定角色对话中自动提取角色信息的方法。然而，这些角色提取模型也是在从PersonaChat衍生的数据集上进行训练，并且很难从非真实世界的对话设置中提供高质量的角色信息，例如以幻想为主题的数据集LIGHT。创建新数据以训练特定设置的模型是人力密集型的，因此代价过高。为了解决这两个问题，我们引入了一种自然语言推理方法，以后期调整已训练的角色提取模型适应新的设置

    While valuable datasets such as PersonaChat provide a foundation for training persona-grounded dialogue agents, they lack diversity in conversational and narrative settings, primarily existing in the "real" world. To develop dialogue agents with unique personas, models are trained to converse given a specific persona, but hand-crafting these persona can be time-consuming, thus methods exist to automatically extract persona information from existing character-specific dialogue. However, these persona-extraction models are also trained on datasets derived from PersonaChat and struggle to provide high-quality persona information from conversational settings that do not take place in the real world, such as the fantasy-focused dataset, LIGHT. Creating new data to train models on a specific setting is human-intensive, thus prohibitively expensive. To address both these issues, we introduce a natural language inference method for post-hoc adapting a trained persona extraction model to a new 
    
[^4]: 不可靠的依赖：语言模型不愿表达不确定性的影响

    Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty. (arXiv:2401.06730v1 [cs.CL])

    [http://arxiv.org/abs/2401.06730](http://arxiv.org/abs/2401.06730)

    本研究调查了语言模型在回答问题时不愿表达不确定性的影响，发现语言模型往往过于自信，导致高错误率。实验还表明用户无论是否标记了确定性都会严重依赖语言模型生成的结果。

    

    随着自然语言成为人工智能交互的默认接口，语言模型适当地传达下游应用的不确定性变得至关重要。本研究调查了语言模型如何通过自然语言表达对其回答的置信度，以及下游用户对语言模型表达的不确定性的反应。我们调查了公开部署的模型，发现在回答问题时，即使产生了错误答案，语言模型也无法表达不确定性。虽然可以明确要求语言模型表达置信度，但它们往往过于自信，导致在置信的回答中错误率高达平均47%。我们通过人类实验测试了语言模型过度自信的风险，并证明用户无论是否标记了确定性都会严重依赖语言模型生成的结果。最后，我们研究了在RLHF对齐中使用的偏好注释数据集，并发现人类对带有不确定性的文本有偏见。我们的研究突出了这一问题。

    As natural language becomes the default interface for human-AI interaction, there is a critical need for LMs to appropriately communicate uncertainties in downstream applications. In this work, we investigate how LMs incorporate confidence about their responses via natural language and how downstream users behave in response to LM-articulated uncertainties. We examine publicly deployed models and find that LMs are unable to express uncertainties when answering questions even when they produce incorrect responses. LMs can be explicitly prompted to express confidences, but tend to be overconfident, resulting in high error rates (on average 47%) among confident responses. We test the risks of LM overconfidence by running human experiments and show that users rely heavily on LM generations, whether or not they are marked by certainty. Lastly, we investigate the preference-annotated datasets used in RLHF alignment and find that humans have a bias against texts with uncertainty. Our work hig
    
[^5]: 重新定义税法推论为类比推理

    Reframing Tax Law Entailment as Analogical Reasoning. (arXiv:2401.06715v1 [cs.CL])

    [http://arxiv.org/abs/2401.06715](http://arxiv.org/abs/2401.06715)

    本论文将法定推理重新定义为类比任务，通过增加数据集大小和引入解释性因素，展示了这个任务与原始任务的难度相当，并利用检索机制和类比模型解决法定推理问题，在之前的可比工作上取得了一些进展。

    

    法定推理是指将立法规定应用于用自然语言描述的一系列案例事实。我们将法定推理重新定义为类比任务，其中每个类比任务实例涉及两个法定推理实例的组合。这样做可以将数据集大小增加两个数量级，并引入解释性因素。我们证明这个任务对于自然语言处理模型来说与原始任务的难度相当。最后，我们通过结合检索机制和类比模型来解决法定推理问题，并在之前的可比工作上取得了一些进展。

    Statutory reasoning refers to the application of legislative provisions to a series of case facts described in natural language. We re-frame statutory reasoning as an analogy task, where each instance of the analogy task involves a combination of two instances of statutory reasoning. This increases the dataset size by two orders of magnitude, and introduces an element of interpretability. We show that this task is roughly as difficult to Natural Language Processing models as the original task. Finally, we come back to statutory reasoning, solving it with a combination of a retrieval mechanism and analogy models, and showing some progress on prior comparable work.
    
[^6]: 在用户撰写的文本中心理概念提取和分类的可靠性分析

    Reliability Analysis of Psychological Concept Extraction and Classification in User-penned Text. (arXiv:2401.06709v1 [cs.CL])

    [http://arxiv.org/abs/2401.06709](http://arxiv.org/abs/2401.06709)

    该论文研究了在用户撰写的文本中心理概念提取和分类的可靠性分析，并通过注解LoST数据集来捕捉表明低自尊存在的微妙文本提示。研究发现，NLP模型对触发词、LoST指标和后果这三类文本提示更加关注。

    

    社交NLP研究社区最近在心理健康分析的计算进展中见证了一波复杂的语言使用和自我感知之间相互作用的AI模型的建立。这些负责任的AI模型有助于从社交媒体上的用户撰写的文本中量化心理概念。在超越低级（分类）任务的基础上，我们将现有的二元分类数据集提升到更高级别的可靠性分析任务，通过解释的角度将之作为一种安全措施。我们注释了LoST数据集，以捕捉表明Reddit用户发帖中存在低自尊的微妙文本提示。我们进一步指出，用于确定低自尊存在的NLP模型更加关注三种类型的文本提示：（i）触发词：触发心理扰动的词汇，（ii）LoST指标：强调低自尊的文本指标，以及（iii）后果：描述情绪稳定性后果的词汇。

    The social NLP research community witness a recent surge in the computational advancements of mental health analysis to build responsible AI models for a complex interplay between language use and self-perception. Such responsible AI models aid in quantifying the psychological concepts from user-penned texts on social media. On thinking beyond the low-level (classification) task, we advance the existing binary classification dataset, towards a higher-level task of reliability analysis through the lens of explanations, posing it as one of the safety measures. We annotate the LoST dataset to capture nuanced textual cues that suggest the presence of low self-esteem in the posts of Reddit users. We further state that the NLP models developed for determining the presence of low self-esteem, focus more on three types of textual cues: (i) Trigger: words that triggers mental disturbance, (ii) LoST indicators: text indicators emphasizing low self-esteem, and (iii) Consequences: words describing
    
[^7]: 全连接前馈神经网络权重优化的闭合解方案

    A Closed-form Solution for Weight Optimization in Fully-connected Feed-forward Neural Networks. (arXiv:2401.06699v1 [cs.LG])

    [http://arxiv.org/abs/2401.06699](http://arxiv.org/abs/2401.06699)

    本文提出了一种闭合解法，通过最小二乘法来优化全连接前馈神经网络的权重，具有非常高的效率和独立性。

    

    本文针对全连接前馈神经网络的权重优化问题进行了研究。与现有的基于反向传播和链式规则梯度优化的方法不同，该方法通过最小二乘法提供了闭合形式的权重优化解决方案。在输入到输出映射是可逆的情况下，新方法通过同时优化每个神经元层的一组权重，在单次迭代中以反向传播的方式优化权重。在输入到输出映射不可逆的情况下（例如分类问题），提出的解决方案可以轻松地在几次迭代中获得最终解。与现有解决方案相比，一个重要的优势是这些计算（对于每个神经元层的所有神经元）是独立的，因此它们可以同时进行。

    This work addresses weight optimization problem for fully-connected feed-forward neural networks. Unlike existing approaches that are based on back-propagation (BP) and chain rule gradient-based optimization (which implies iterative execution, potentially burdensome and time-consuming in some cases), the proposed approach offers the solution for weight optimization in closed-form by means of least squares (LS) methodology. In the case where the input-to-output mapping is injective, the new approach optimizes the weights in a back-propagating fashion in a single iteration by jointly optimizing a set of weights in each layer for each neuron. In the case where the input-to-output mapping is not injective (e.g., in classification problems), the proposed solution is easily adapted to obtain its final solution in a few iterations. An important advantage over the existing solutions is that these computations (for all neurons in a layer) are independent from each other; thus, they can be carri
    
[^8]: 大型语言模型有限标签监督微调的实验设计框架

    An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models. (arXiv:2401.06692v1 [cs.CL])

    [http://arxiv.org/abs/2401.06692](http://arxiv.org/abs/2401.06692)

    该论文提出了一个实验设计框架来减少大型语言模型有限标签监督微调的注释成本，并解决了主动学习的计算瓶颈问题。

    

    在现代大型语言模型中，指导数据集上的有限标签监督微调（SFT）在实现了令人惊叹的零射击泛化能力方面发挥了至关重要的作用。然而，为了为指令产生高质量的回答所需的注释工作正在变得难以承受，特别是随着指令数据集所涵盖的任务数量的增加。主动学习可以有效地从未标记的样本池中确定有用的子集进行注释，但其高计算成本仍然是其在LLMs环境中广泛应用的障碍。为了减少SFT的注释成本并规避主动学习的计算瓶颈，我们提出使用实验设计。实验设计技术选择最具信息量的样本进行标注，通常最大化某种不确定性和/或多样性的概念。在我们的工作中，我们实施了一个评估多种现有和新颖的实验设计方法的框架。

    Supervised finetuning (SFT) on instruction datasets has played a crucial role in achieving the remarkable zero-shot generalization capabilities observed in modern large language models (LLMs). However, the annotation efforts required to produce high quality responses for instructions are becoming prohibitively expensive, especially as the number of tasks spanned by instruction datasets continues to increase. Active learning is effective in identifying useful subsets of samples to annotate from an unlabeled pool, but its high computational cost remains a barrier to its widespread applicability in the context of LLMs. To mitigate the annotation cost of SFT and circumvent the computational bottlenecks of active learning, we propose using experimental design. Experimental design techniques select the most informative samples to label, and typically maximize some notion of uncertainty and/or diversity. In our work, we implement a framework that evaluates several existing and novel experimen
    
[^9]: 探索对话代理作为衡量决策中认知偏差的有效工具

    Exploring Conversational Agents as an Effective Tool for Measuring Cognitive Biases in Decision-Making. (arXiv:2401.06686v1 [cs.HC])

    [http://arxiv.org/abs/2401.06686](http://arxiv.org/abs/2401.06686)

    本研究探索了对话代理作为衡量决策中认知偏差的有效工具，通过对不同领域中的各种认知偏差进行测量。实验结果表明，对话代理可以有效地用于测量框架和损失厌恶偏差。

    

    启发法和认知偏差是人类决策的重要组成部分。自动检测特定的认知偏差可以使智能工具提供更好的决策支持。目前，检测认知偏差的存在需要手工设计实验和人工解释。我们的研究旨在探索对话代理作为衡量不同领域中各种认知偏差的有效工具。我们提出的对话代理含有一个根据现有实验设计和文献中确定的各种实验任务的偏差测量机制。我们对衡量框架和损失厌恶偏差的初始实验表明，对话代理可以有效地用于测量这些偏差。

    Heuristics and cognitive biases are an integral part of human decision-making. Automatically detecting a particular cognitive bias could enable intelligent tools to provide better decision-support. Detecting the presence of a cognitive bias currently requires a hand-crafted experiment and human interpretation. Our research aims to explore conversational agents as an effective tool to measure various cognitive biases in different domains. Our proposed conversational agent incorporates a bias measurement mechanism that is informed by the existing experimental designs and various experimental tasks identified in the literature. Our initial experiments to measure framing and loss-aversion biases indicate that the conversational agents can be effectively used to measure the biases.
    
[^10]: DQNC2S：基于DQN的跨流危机事件摘要生成器

    DQNC2S: DQN-based Cross-stream Crisis event Summarizer. (arXiv:2401.06683v1 [cs.IR])

    [http://arxiv.org/abs/2401.06683](http://arxiv.org/abs/2401.06683)

    本研究提出了一种基于DQN的在线危机事件摘要生成方法，能够同时总结多个灾害相关的数据流，无需人工标注或内容重新排序，且具有较好的性能表现。

    

    同时总结多个与灾害相关的数据流尤其具有挑战性，因为现有的检索与重新排序策略在多流数据的固有冗余和多查询环境下的限制可扩展性方面存在问题。本文提出了一种基于弱标注和深度Q网络的在线危机时间轴生成方法。它能够实时选择相关的文本片段，无需人工标注或内容重新排序，从而使推理时间与输入查询的数量无关。该方法还将冗余过滤器融入奖励函数中，以有效处理跨流内容重叠。在CrisisFACTS 2022基准测试中，所达到的ROUGE和BERTScore结果优于最佳性能模型。

    Summarizing multiple disaster-relevant data streams simultaneously is particularly challenging as existing Retrieve&Re-ranking strategies suffer from the inherent redundancy of multi-stream data and limited scalability in a multi-query setting. This work proposes an online approach to crisis timeline generation based on weak annotation with Deep Q-Networks. It selects on-the-fly the relevant pieces of text without requiring neither human annotations nor content re-ranking. This makes the inference time independent of the number of input queries. The proposed approach also incorporates a redundancy filter into the reward function to effectively handle cross-stream content overlaps. The achieved ROUGE and BERTScore results are superior to those of best-performing models on the CrisisFACTS 2022 benchmark.
    
[^11]: LLMRS: 解锁基于LLM的推荐系统对软件购买的潜力

    LLMRS: Unlocking Potentials of LLM-Based Recommender Systems for Software Purchase. (arXiv:2401.06676v1 [cs.IR])

    [http://arxiv.org/abs/2401.06676](http://arxiv.org/abs/2401.06676)

    LLMRS是一种基于LLM的零-shot推荐系统，可以将用户评论编码为评论分数并生成个性化推荐。实验证明，LLMRS在软件购买方面的推荐性能超过基准模型，并成功从产品评论中捕捉到有意义的信息，提供更可靠的推荐。

    

    推荐系统无处不在，从Spotify的歌单推荐到亚马逊的产品推荐。然而，根据方法或数据集的不同，这些系统通常无法捕捉用户的偏好并生成普适的推荐。最近大型语言模型（LLM）的进展为分析用户查询提供了有希望的结果。然而，利用这些模型来捕捉用户的偏好和提高效率仍然是一个未解决的问题。在本文中，我们提出了LLMRS，一种基于LLM的零-shot推荐系统，我们利用预训练的LLM将用户评论编码为评论分数，并生成个性化的推荐。我们在亚马逊产品评论的真实数据集上对LLMRS进行了实验，用于软件购买的使用案例。结果表明，LLMRS优于基于排名的基准模型，同时成功从产品评论中捕捉到有意义的信息，从而提供更可靠的推荐。

    Recommendation systems are ubiquitous, from Spotify playlist suggestions to Amazon product suggestions. Nevertheless, depending on the methodology or the dataset, these systems typically fail to capture user preferences and generate general recommendations. Recent advancements in Large Language Models (LLM) offer promising results for analyzing user queries. However, employing these models to capture user preferences and efficiency remains an open question. In this paper, we propose LLMRS, an LLM-based zero-shot recommender system where we employ pre-trained LLM to encode user reviews into a review score and generate user-tailored recommendations. We experimented with LLMRS on a real-world dataset, the Amazon product reviews, for software purchase use cases. The results show that LLMRS outperforms the ranking-based baseline model while successfully capturing meaningful information from product reviews, thereby providing more reliable recommendations.
    
[^12]: 解耦像素翻转与遮挡策略以实现一致的XAI基准

    Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI Benchmarks. (arXiv:2401.06654v1 [cs.CV])

    [http://arxiv.org/abs/2401.06654](http://arxiv.org/abs/2401.06654)

    本研究提出了两个视角来解决基于遮挡的解释方法中的矛盾问题，首先通过使用R-OMS得分来衡量可靠性，然后通过解耦像素翻转和遮挡策略来提高结果的一致性。

    

    特征移除是可解释人工智能（XAI）的核心构建模块，既适用于基于遮挡的解释（Shapley值），也适用于它们的评估（像素翻转，PF）。然而，遮挡策略可以从简单的均值替换到使用最先进的扩散模型进行修复之间差异很大。这种不确定性限制了遮挡方法的实用性。例如，PF基准会导致矛盾的排名。这一问题还因竞争的PF度量而变得复杂：特征要么从最有影响力的开始移除（MIF），要么从最无影响力的开始移除（LIF）。本研究提出了两个互补的视角来解决这个问题。首先，我们解决了针对基于遮挡的XAI的常见批评，即人工样本导致模型评估不可靠的问题。我们提出用R-OMS得分来衡量可靠性（参考模型范围之外的R-OMS得分）。R-OMS得分能够对遮挡策略进行系统比较，并解决了矛盾问题。

    Feature removal is a central building block for eXplainable AI (XAI), both for occlusion-based explanations (Shapley values) as well as their evaluation (pixel flipping, PF). However, occlusion strategies can vary significantly from simple mean replacement up to inpainting with state-of-the-art diffusion models. This ambiguity limits the usefulness of occlusion-based approaches. For example, PF benchmarks lead to contradicting rankings. This is amplified by competing PF measures: Features are either removed starting with most influential first (MIF) or least influential first (LIF). This study proposes two complementary perspectives to resolve this disagreement problem. Firstly, we address the common criticism of occlusion-based XAI, that artificial samples lead to unreliable model evaluations. We propose to measure the reliability by the R(eference)-Out-of-Model-Scope (OMS) score. The R-OMS score enables a systematic comparison of occlusion strategies and resolves the disagreement pro
    
[^13]: 实验环境能够促进语言模型在稳健的语义属性推断中的表现，但不一致。

    Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently. (arXiv:2401.06640v1 [cs.CL])

    [http://arxiv.org/abs/2401.06640](http://arxiv.org/abs/2401.06640)

    本研究通过控制实验环境的方式，发现语言模型在属性继承任务中表现出了一定的非平凡能力，但这种能力是不一致的。

    

    最近的无人监督评估凸显了语言模型（LMs）在执行意义提取方面的重要限制。然而，众所周知，在引入实验环境（如上下文示例和指导）的情况下，LMs的表现可以显著提高。那么这是否适用于先前研究的意义敏感任务呢？我们在控制上下文示例和指导内容的前提下，对实验环境对于提高LMs在执行属性继承任务中的鲁棒性的程度进行了案例研究，该任务是预先表明LMs无法完成的任务。我们的研究发现，实验环境确实可以导致LMs在属性继承行为方面表现出非平凡的能力。然而，这种能力是不一致的：通过对任务进行最小改写，发现一些LMs从输入中捕捉到浅层的非语义式启发式信息，这表明计算机的行为具有不一致性。

    Recent zero-shot evaluations have highlighted important limitations in the abilities of language models (LMs) to perform meaning extraction. However, it is now well known that LMs can demonstrate radical improvements in the presence of experimental contexts such as in-context examples and instructions. How well does this translate to previously studied meaning-sensitive tasks? We present a case-study on the extent to which experimental contexts can improve LMs' robustness in performing property inheritance -- predicting semantic properties of novel concepts, a task that they have been previously shown to fail on. Upon carefully controlling the nature of the in-context examples and the instructions, our work reveals that they can indeed lead to non-trivial property inheritance behavior in LMs. However, this ability is inconsistent: with a minimal reformulation of the task, some LMs were found to pick up on shallow, non-semantic heuristics from their inputs, suggesting that the computati
    
[^14]: CCFC：桥接联邦聚类和对比学习

    CCFC: Bridging Federated Clustering and Contrastive Learning. (arXiv:2401.06634v1 [cs.LG])

    [http://arxiv.org/abs/2401.06634](http://arxiv.org/abs/2401.06634)

    本论文桥接了联邦聚类和对比学习，提出了一种名为CCFC的新联邦聚类方法。通过表示学习，CCFC在某些情况下聚类性能甚至是最佳基准方法的两倍。与最相关的基准方法相比，在最显著的案例中，CCFC的NMI得分提高了0.4155。同时，CCFC还能有效处理联邦场景下的数据分布和质量差异。

    

    联邦聚类是对于联邦场景中集中聚类的重要扩展，可以让多个数据持有客户端在保留本地数据的同时协同进行数据分组。在集中场景中，通过表示学习驱动的聚类在处理高维复杂数据方面取得了重大进展。然而，联邦聚类和表示学习的结合仍然未被充分研究。为了弥合这一差距，我们首先为学习聚类友好的表示定制了一个聚类对比模型。然后，我们利用这个模型作为提出新的联邦聚类方法的基础，称为聚类对比联邦聚类（CCFC）。受益于表示学习，CCFC的聚类性能在某些情况下甚至是最佳基准方法的两倍。与最相关的基准方法相比，在最显著的案例中，这种收益导致NMI得分的显著提高，最高达到0.4155。此外，CCFC还可以有效地处理在联邦场景下出现的数据分布和质量差异。

    Federated clustering, an essential extension of centralized clustering for federated scenarios, enables multiple data-holding clients to collaboratively group data while keeping their data locally. In centralized scenarios, clustering driven by representation learning has made significant advancements in handling high-dimensional complex data. However, the combination of federated clustering and representation learning remains underexplored. To bridge this, we first tailor a cluster-contrastive model for learning clustering-friendly representations. Then, we harness this model as the foundation for proposing a new federated clustering method, named cluster-contrastive federated clustering (CCFC). Benefiting from representation learning, the clustering performance of CCFC even double those of the best baseline methods in some cases. Compared to the most related baseline, the benefit results in substantial NMI score improvements of up to 0.4155 on the most conspicuous case. Moreover, CCF
    
[^15]: Ada-Retrieval：适应性多轮检索范例用于顺序推荐

    Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations. (arXiv:2401.06633v1 [cs.IR])

    [http://arxiv.org/abs/2401.06633](http://arxiv.org/abs/2401.06633)

    Ada-Retrieval是一种适应性多轮检索范例，用于提升推荐系统的物品候选者选择过程。它通过迭代地改进用户表示来更好地捕捉完整的物品空间中的潜在候选者，并具有模型无关的设计。

    

    检索模型旨在选择与给定用户偏好匹配的一小组物品候选者。它们在大规模推荐系统中起着重要作用，因为后续的模型（如排名器）高度依赖于物品候选者的质量。然而，大多数现有的检索模型采用单轮推理范例，可能无法充分捕捉用户偏好的动态性并固定在物品空间的某个区域。在本文中，我们提出了Ada-Retrieval，一种适用于推荐系统的自适应多轮检索范例，通过迭代地改进用户表示来更好地捕捉完整的物品空间中的潜在候选者。Ada-Retrieval包含两个关键模块：物品表示适配器和用户表示适配器，旨在将上下文信息注入物品和用户的表示中。该框架具有模型无关的设计，可以与各种基础模型（如RNN或Transformer）无缝集成。

    Retrieval models aim at selecting a small set of item candidates which match the preference of a given user. They play a vital role in large-scale recommender systems since subsequent models such as rankers highly depend on the quality of item candidates. However, most existing retrieval models employ a single-round inference paradigm, which may not adequately capture the dynamic nature of user preferences and stuck in one area in the item space. In this paper, we propose Ada-Retrieval, an adaptive multi-round retrieval paradigm for recommender systems that iteratively refines user representations to better capture potential candidates in the full item space. Ada-Retrieval comprises two key modules: the item representation adapter and the user representation adapter, designed to inject context information into items' and users' representations. The framework maintains a model-agnostic design, allowing seamless integration with various backbone models such as RNNs or Transformers. We pe
    
[^16]: 每个节点都不同：动态融合自监督任务进行属性图聚类

    Every Node is Different: Dynamically Fusing Self-Supervised Tasks for Attributed Graph Clustering. (arXiv:2401.06595v1 [cs.LG])

    [http://arxiv.org/abs/2401.06595](http://arxiv.org/abs/2401.06595)

    提出了一种动态融合自监督任务并学习不同节点的权重的方法，通过从不同的SSL任务中提取的特征融合来提高属性图聚类的性能。

    

    属性图聚类是一项无监督任务，将节点分为不同的组。自监督学习（SSL）在处理这个任务方面显示出巨大的潜力，并且最近的一些研究同时学习多个SSL任务以进一步提高性能。目前，不同的SSL任务被分配给所有图节点相同的权重。然而，我们观察到一些图节点其邻居在不同的组中，对SSL任务需要有显著不同的强调。在本文中，我们提出了一种动态学习不同节点的SSL任务权重并融合从不同SSL任务中学到的嵌入以提高性能的方法。我们设计了一种创新的图聚类方法，即动态融合自监督学习（DyFSS）。具体而言，DyFSS使用从门控网络推导出的不同权重融合从多样的SSL任务中提取的特征。为了有效学习门控网络，我们设计了一个双层自监督策略，其中包含...

    Attributed graph clustering is an unsupervised task that partitions nodes into different groups. Self-supervised learning (SSL) shows great potential in handling this task, and some recent studies simultaneously learn multiple SSL tasks to further boost performance. Currently, different SSL tasks are assigned the same set of weights for all graph nodes. However, we observe that some graph nodes whose neighbors are in different groups require significantly different emphases on SSL tasks. In this paper, we propose to dynamically learn the weights of SSL tasks for different nodes and fuse the embeddings learned from different SSL tasks to boost performance. We design an innovative graph clustering approach, namely Dynamically Fusing Self-Supervised Learning (DyFSS). Specifically, DyFSS fuses features extracted from diverse SSL tasks using distinct weights derived from a gating network. To effectively learn the gating network, we design a dual-level self-supervised strategy that incorpora
    
[^17]: 具有强延迟约束的连接主义语音识别的动态行为

    Dynamic Behaviour of Connectionist Speech Recognition with Strong Latency Constraints. (arXiv:2401.06588v1 [eess.AS])

    [http://arxiv.org/abs/2401.06588](http://arxiv.org/abs/2401.06588)

    本文研究了具有强延迟约束条件下的连接主义语音识别，在实时推导合成面部唇部运动的同时，亦关注了时间演化模型与转移模型的相互作用。实验结果表明神经网络拓扑结构、语言模型中的时间依赖关系和解码器延迟之间存在强烈相互作用。

    

    本文描述了在强延迟约束条件下使用连接主义技术进行语音识别的情况。这些约束是通过将语音信号输入到口腔运动合成器中，从而实时推导出合成面部的唇部运动来实现的。我们特别关注了多层感知器学习的时间演化模型与维特比译码器强制的转移模型在不同延迟条件下的相互作用。进行了两个实验，通过参数控制了语言模型中的时间依赖关系。结果显示了神经网络拓扑结构、语言模型中时间依赖的长度和解码器延迟之间的强烈相互作用。

    This paper describes the use of connectionist techniques in phonetic speech recognition with strong latency constraints. The constraints are imposed by the task of deriving the lip movements of a synthetic face in real time from the speech signal, by feeding the phonetic string into an articulatory synthesiser. Particular attention has been paid to analysing the interaction between the time evolution model learnt by the multi-layer perceptrons and the transition model imposed by the Viterbi decoder, in different latency conditions. Two experiments were conducted in which the time dependencies in the language model (LM) were controlled by a parameter. The results show a strong interaction between the three factors involved, namely the neural network topology, the length of time dependencies in the LM and the decoder latency.
    
[^18]: 将变形器技术应用于跨语言文档表示的映射

    Mapping Transformer Leveraged Embeddings for Cross-Lingual Document Representation. (arXiv:2401.06583v1 [cs.CL])

    [http://arxiv.org/abs/2401.06583](http://arxiv.org/abs/2401.06583)

    本研究通过使用预训练的变形器模型和映射方法，探索了跨语言文档表示的方法。实验结果表明，通过映射到跨语言领域的变形器技术文档表示（TLDRs），能够有效地实现跨语言的推荐系统。

    

    推荐系统对于文档已经成为在网络上找到相关内容的工具。然而，当推荐非查询语言的文档时，这些系统存在一定限制，可能会忽视非母语的资源。本研究旨在通过使用映射到跨语言领域的变形器技术文档表示（TLDRs）来表示跨语言文档。评估了四个多语言预训练变形器模型（mBERT，mT5 XLM RoBERTa，ErnieM）在20种语言对上使用三种映射方法的效果，这些语言对代表了欧盟选择的五种语言的组合。使用Mate检索率和互惠排序等指标来衡量映射TLDRs与未映射TLDRs的效果。结果强调了通过预训练变形器和映射方法实现的跨语言表示的能力，为扩展跨语言文档表示提供了有希望的方向。

    Recommendation systems, for documents, have become tools to find relevant content on the Web. However, these systems have limitations when it comes to recommending documents in languages different from the query language, which means they might overlook resources in non-native languages. This research focuses on representing documents across languages by using Transformer Leveraged Document Representations (TLDRs) that are mapped to a cross-lingual domain. Four multilingual pre-trained transformer models (mBERT, mT5 XLM RoBERTa, ErnieM) were evaluated using three mapping methods across 20 language pairs representing combinations of five selected languages of the European Union. Metrics like Mate Retrieval Rate and Reciprocal Rank were used to measure the effectiveness of mapped TLDRs compared to non-mapped ones. The results highlight the power of cross-lingual representations achieved through pre-trained transformers and mapping approaches suggesting a promising direction for expanding
    
[^19]: 在源语言中迷失：大型语言模型如何评估机器翻译的质量

    Lost in the Source Language: How Large Language Models Evaluate the Quality of Machine Translation. (arXiv:2401.06568v1 [cs.CL])

    [http://arxiv.org/abs/2401.06568](http://arxiv.org/abs/2401.06568)

    本论文研究了大型语言模型（LLMs）如何利用源语言和参考信息评估机器翻译的质量，并发现参考信息显著提高了评估准确性，而源语言信息有时会适得其反，表明在使用LLMs评估翻译时存在跨语言能力不足的问题。

    

    大型语言模型（LLMs）在机器翻译评估任务中取得了显著的成果，但对它们如何利用提供的数据进行评估仍存在知识差距。本研究旨在探索LLMs如何利用源语言和参考信息评估翻译，以更好地理解LLMs的工作机制。为此，我们设计了涵盖各种输入模式和模型类型的受控实验，并采用粗粒度和细粒度的提示来区分源语言和参考信息的实用性。令人惊讶的是，我们发现参考信息显著提高了评估准确性，而源语言信息有时会适得其反，表明在使用LLMs评估翻译时存在跨语言能力不足的问题。我们还对LLMs进行了翻译错误检测的元评估，观察到了类似的现象。这些发现还暗示了一种潜在的方法，即利用参考信息来改善机器翻译的质量评估任务。

    Large Language Models (LLMs) have achieved remarkable results in the machine translation evaluation task, yet there remains a gap in knowledge regarding how they utilize the provided data to conduct evaluations. This study aims to explore how LLMs leverage source and reference information in evaluating translations, with the ultimate goal of better understanding the working mechanism of LLMs. To this end, we design the controlled experiments across various input modes and model types, and employ both coarse-grained and fine-grained prompts to discern the utility of source versus reference information. Surprisingly, we find that reference information significantly enhances the evaluation accuracy, while source information sometimes is counterproductive, indicating a lack of cross-lingual capability when using LLMs to evaluate translations. We further conduct a meta-evaluation for translation error detection of LLMs, observing a similar phenomenon. These findings also suggest a potential
    
[^20]: 一个通用的基准框架对于动态图神经网络的需要

    A General Benchmark Framework is Dynamic Graph Neural Network Need. (arXiv:2401.06559v1 [cs.LG])

    [http://arxiv.org/abs/2401.06559](http://arxiv.org/abs/2401.06559)

    本文强调了动态图学习的重要性及其在各个领域中的应用，并强调了对捕捉时间动态、演化图结构和下游任务需求的标准化基准框架的需求。缺乏统一的基准框架是当前动态图学习研究的局限之处，建立这样的框架将有助于推动动态图学习技术的进步。

    

    动态图学习对于建模具有演化关系和时间动态的真实世界系统至关重要。然而，当前研究中缺乏统一的基准框架导致动态图模型的评估不准确。本文强调了动态图学习的重要性及其在各个领域中的应用。它强调了对捕捉时间动态、演化图结构和下游任务需求的标准化基准框架的需求。建立统一的基准框架将有助于研究人员了解现有模型的优势和局限性，促进创新，并推动动态图学习的进展。总之，本文确定缺乏统一的基准框架是当前动态图学习研究的局限之处。这样的框架将有助于准确评估模型，推动动态图学习技术的进步，并为生成更有效的模型打下基础。

    Dynamic graph learning is crucial for modeling real-world systems with evolving relationships and temporal dynamics. However, the lack of a unified benchmark framework in current research has led to inaccurate evaluations of dynamic graph models. This paper highlights the significance of dynamic graph learning and its applications in various domains. It emphasizes the need for a standardized benchmark framework that captures temporal dynamics, evolving graph structures, and downstream task requirements. Establishing a unified benchmark will help researchers understand the strengths and limitations of existing models, foster innovation, and advance dynamic graph learning. In conclusion, this paper identifies the lack of a standardized benchmark framework as a current limitation in dynamic graph learning research . Such a framework will facilitate accurate model evaluation, drive advancements in dynamic graph learning techniques, and enable the development of more effective models for re
    
[^21]: 对待社交网络中因果效应估计的超螺旋表示学习的关注

    Treatment-Aware Hyperbolic Representation Learning for Causal Effect Estimation with Social Networks. (arXiv:2401.06557v1 [cs.LG])

    [http://arxiv.org/abs/2401.06557](http://arxiv.org/abs/2401.06557)

    该论文提出了一种新的方法，称为Treatment-Aware Hyperbolic Representation Learning（TAHyper），用于利用超螺旋空间学习社交网络中隐藏混淆因素的表示，从而改进个体治疗效应的估计。

    

    从观测数据中估计个体治疗效应（ITE）是一个具有重要价值的关键研究领域。如何识别隐藏的混淆因素在ITE估计中是一个关键挑战。最近的研究已经将社交网络的结构信息纳入其中，取得了显著的进展。然而，这些方法利用图神经网络在欧几里得空间中学习隐藏混淆因素的表示，忽视了两个关键问题：（1）社交网络经常表现出无标度结构，而欧几里得嵌入在嵌入此类图时会产生高度失真，（2）社交网络中的每个自我中心网络都表现出与治疗相关的特征，意味着隐藏混淆因素的显著模式。为了解决这些问题，我们提出了一种新的方法，名为Treatment-Aware Hyperbolic Representation Learning（TAHyper）。首先，TAHyper使用超螺旋空间进行嵌入学习，以捕捉社交网络的无标度特性，并利用治疗相关的特征来学习隐藏混淆因素的模式。

    Estimating the individual treatment effect (ITE) from observational data is a crucial research topic that holds significant value across multiple domains. How to identify hidden confounders poses a key challenge in ITE estimation. Recent studies have incorporated the structural information of social networks to tackle this challenge, achieving notable advancements. However, these methods utilize graph neural networks to learn the representation of hidden confounders in Euclidean space, disregarding two critical issues: (1) the social networks often exhibit a scalefree structure, while Euclidean embeddings suffer from high distortion when used to embed such graphs, and (2) each ego-centric network within a social network manifests a treatment-related characteristic, implying significant patterns of hidden confounders. To address these issues, we propose a novel method called Treatment-Aware Hyperbolic Representation Learning (TAHyper). Firstly, TAHyper employs the hyperbolic space to en
    
[^22]: 通过遥感图像和多语义信息检测城市功能区的多模态学习

    Multimodal Learning for detecting urban functional zones using remote sensing image and multi-semantic information. (arXiv:2401.06550v1 [cs.CV])

    [http://arxiv.org/abs/2401.06550](http://arxiv.org/abs/2401.06550)

    本研究提出了一种利用遥感图像和多语义信息进行城市功能区检测的多模态学习算法，能够满足移动互联网在线到离线业务的精确要求。

    

    城市兴趣区（AOI）是指具有定义边界的整合的城市功能区域。城市商业的迅速发展导致了对定义AOI的更精确要求的增加。然而，现有研究主要集中于城市规划或区域经济分析的广泛AOI挖掘，未能满足移动互联网在线到离线业务的精确要求。这些业务需要到具体的社区、学校或医院的准确度。在本文中，我们提出了一种端到端的多模态深度学习算法，用于使用遥感图像和多语义参考信息检测AOI围栏多边形。然后，我们通过包含动态人员流动和物流地址信息的级联模块来评估其时效性。具体而言，我们从选择特定类别的兴趣点（POI）开始，并用它来召回相应的遥感图像、附近的POI、道路n

    Urban area-of-interest (AOI) refers to an integrated urban functional zone with defined boundaries. The rapid development of urban commerce has resulted in an increased demand for more precise requirements in defining AOIs. However, existing research primarily concentrates on broad AOI mining for urban planning or regional economic analysis, failing to cater to the precise requirements of mobile Internet online-to-offline businesses. These businesses necessitate accuracy down to a specific community, school, or hospital. In this paper, we propose an end-to-end multimodal deep learning algorithm for detecting AOI fence polygon using remote sensing images and multi-semantics reference information. We then evaluate its timeliness through a cascaded module that incorporates dynamic human mobility and logistics address information. Specifically, we begin by selecting a point-of-interest (POI) of specific category, and use it to recall corresponding remote sensing images, nearby POIs, road n
    
[^23]: 通过直觉-分析式鉴别诊断生成医疗对话

    Medical Dialogue Generation via Intuitive-then-Analytical Differential Diagnosis. (arXiv:2401.06541v1 [cs.CL])

    [http://arxiv.org/abs/2401.06541](http://arxiv.org/abs/2401.06541)

    本研究提出了一种医疗对话生成框架，通过直觉-分析式鉴别诊断（IADDx）实现了对医疗对话的生成。该方法使用直觉和分析推理来建立鉴别诊断，并通过图增强的分析方法进行细化，提高了医疗对话系统的实际应用价值。

    

    医疗对话系统因其能够提供快速诊断、治疗方案和健康咨询的潜力而引起越来越多的研究关注。在医疗对话中，正确的诊断至关重要，因为它为未来的咨询建立了基础。临床医生通常使用直觉和分析推理来形成鉴别诊断。这个推理过程假设和验证了各种可能的疾病，并努力生成全面而严谨的诊断。然而，最近关于医疗对话生成的研究忽视了建模鉴别诊断的重要性，这阻碍了这些系统的实际应用。为了解决以上问题，我们提出了一种带有直觉-分析式鉴别诊断（IADDx）的医疗对话生成框架。我们的方法通过基于检索的直觉联想进行鉴别诊断，然后通过图增强的分析方法对其进行细化。

    Medical dialogue systems have attracted growing research attention as they have the potential to provide rapid diagnoses, treatment plans, and health consultations. In medical dialogues, a proper diagnosis is crucial as it establishes the foundation for future consultations. Clinicians typically employ both intuitive and analytic reasoning to formulate a differential diagnosis. This reasoning process hypothesizes and verifies a variety of possible diseases and strives to generate a comprehensive and rigorous diagnosis. However, recent studies on medical dialogue generation have overlooked the significance of modeling a differential diagnosis, which hinders the practical application of these systems. To address the above issue, we propose a medical dialogue generation framework with the Intuitive-then-Analytic Differential Diagnosis (IADDx). Our method starts with a differential diagnosis via retrieval-based intuitive association and subsequently refines it through a graph-enhanced anal
    
[^24]: 智能数据驱动的网络切片体系结构特征编排

    Intelligent Data-Driven Architectural Features Orchestration for Network Slicing. (arXiv:2401.06538v1 [cs.NI])

    [http://arxiv.org/abs/2401.06538](http://arxiv.org/abs/2401.06538)

    本论文讨论了基于机器学习的网络切片架构中特征和能力编排的问题和挑战，提出了使用机器学习嵌入的代理进行智能的资源和功能编排的建议。

    

    网络切片是下一代移动网络（NGMN）以及其他新系统（如物联网和工业物联网）的关键推动因素和趋势。编排和机器学习是网络切片过程中起着关键作用的元素，因为切片过程需要编排资源和功能，而机器学习可以潜在地优化编排过程。然而，现有的网络切片架构缺乏定义智能方法来编排切片过程中的特征和资源的能力。本文讨论了基于机器学习的网络切片架构中的特征和能力编排。首先，对切片规划、配置、调试和运行阶段的切片资源编排和分配进行了分析。接下来，我们强调了优化架构特征编排的需求，并建议使用机器学习嵌入的代理、联邦学习等方法。

    Network slicing is a crucial enabler and a trend for the Next Generation Mobile Network (NGMN) and various other new systems like the Internet of Vehicles (IoV) and Industrial IoT (IIoT). Orchestration and machine learning are key elements with a crucial role in the network-slicing processes since the NS process needs to orchestrate resources and functionalities, and machine learning can potentially optimize the orchestration process. However, existing network-slicing architectures lack the ability to define intelligent approaches to orchestrate features and resources in the slicing process. This paper discusses machine learning-based orchestration of features and capabilities in network slicing architectures. Initially, the slice resource orchestration and allocation in the slicing planning, configuration, commissioning, and operation phases are analyzed. In sequence, we highlight the need for optimized architectural feature orchestration and recommend using ML-embed agents, federated
    
[^25]: PCB-Vision: 一个多场景的印制电路板RGB-高光谱基准数据集。

    PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed Circuit Boards. (arXiv:2401.06528v1 [cs.CV])

    [http://arxiv.org/abs/2401.06528](http://arxiv.org/abs/2401.06528)

    本文提出了一个开创性的RGB-高光谱印制电路板（PCB）基准数据集，通过利用非侵入性分析方法，提供了对废弃电子产品回收过程的定量和定性洞察力，以优化回收效率。

    

    本文致力于开发先进的自动化数据处理流水线，作为决策和过程控制的基础，以应对废弃电子产品（电子垃圾）回收的关键问题。与循环经济和联合国可持续发展目标（SDG）的更广泛目标一致，我们的研究利用非侵入性分析方法，利用RGB和高光谱成像数据，为优化回收效率提供定量和定性洞察力。在本文中，我们介绍了“PCB-Vision”；一个开创性的RGB-高光谱印制电路板（PCB）基准数据集，包括53张高空间分辨率的RGB图像，配对其对应的可见光和近红外（VNIR）范围内的高光谱数据立方体。基于开放科学原则，我们的数据集通过高质量的真实数据为研究人员提供了一个全面的资源，重点关注电子垃圾流的组成。

    Addressing the critical theme of recycling electronic waste (E-waste), this contribution is dedicated to developing advanced automated data processing pipelines as a basis for decision-making and process control. Aligning with the broader goals of the circular economy and the United Nations (UN) Sustainable Development Goals (SDG), our work leverages non-invasive analysis methods utilizing RGB and hyperspectral imaging data to provide both quantitative and qualitative insights into the E-waste stream composition for optimizing recycling efficiency. In this paper, we introduce 'PCB-Vision'; a pioneering RGB-hyperspectral printed circuit board (PCB) benchmark dataset, comprising 53 RGB images of high spatial resolution paired with their corresponding high spectral resolution hyperspectral data cubes in the visible and near-infrared (VNIR) range. Grounded in open science principles, our dataset provides a comprehensive resource for researchers through high-quality ground truths, focusing 
    
[^26]: ML-On-Rails: 在软件系统中保护机器学习模型的案例研究

    ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A Case Study. (arXiv:2401.06513v1 [cs.SE])

    [http://arxiv.org/abs/2401.06513](http://arxiv.org/abs/2401.06513)

    ML-On-Rails是一个旨在保护机器学习模型的协议，在软件系统中解决了安全性、可靠性和透明度等挑战，并在生产环境中提高了模型的鲁棒性。通过一项实际案例研究，我们强调了保护ML模型在生产中的重要性。

    

    机器学习（ML），特别是随着大型语言模型（LLM）的出现，已经显著改变了各个行业。然而，从ML模型的原型设计到在软件系统中的实际应用，存在着许多挑战。这些挑战主要涉及确保安全性、保证可靠性和透明度，从而影响了ML模型的鲁棒性和可信度。本文介绍了一个名为ML-On-Rails的协议，旨在保护ML模型，并为不同的ML任务建立一个明确定义的端点接口，以促进ML提供者和ML消费者（软件工程师）之间的清晰沟通。ML-On-Rails通过添加检测能力来提高ML模型的鲁棒性，以识别与实际生产中的ML相关的特定挑战。我们通过对MoveReminder应用的实际案例研究来评估ML-On-Rails协议。通过这个评估，我们强调了在生产中保护ML模型的重要性。

    Machine learning (ML), especially with the emergence of large language models (LLMs), has significantly transformed various industries. However, the transition from ML model prototyping to production use within software systems presents several challenges. These challenges primarily revolve around ensuring safety, security, and transparency, subsequently influencing the overall robustness and trustworthiness of ML models. In this paper, we introduce ML-On-Rails, a protocol designed to safeguard ML models, establish a well-defined endpoint interface for different ML tasks, and clear communication between ML providers and ML consumers (software engineers). ML-On-Rails enhances the robustness of ML models via incorporating detection capabilities to identify unique challenges specific to production ML. We evaluated the ML-On-Rails protocol through a real-world case study of the MoveReminder application. Through this evaluation, we emphasize the importance of safeguarding ML models in produ
    
[^27]: 频率屏蔽用于通用深度伪造检测

    Frequency Masking for Universal Deepfake Detection. (arXiv:2401.06506v1 [cs.CV])

    [http://arxiv.org/abs/2401.06506](http://arxiv.org/abs/2401.06506)

    本研究针对通用深度伪造检测问题，首次尝试探索了将屏蔽图像建模应用于频率屏蔽的方法，相较于已有方法，在检测性能上取得了显著提升。

    

    我们研究通用深度伪造检测。我们的目标是检测一系列生成型AI方法中的合成图像，尤其是在深度伪造检测的训练过程中未曾见过的新兴方法。通用深度伪造检测需要出色的泛化能力。受最近提出的屏蔽图像建模的启发，该方法在自监督预训练中展现出了出色的泛化性能，我们首次尝试探索将屏蔽图像建模应用于通用深度伪造检测。我们研究在训练深度伪造检测器时的空间和频率域屏蔽。基于经验分析，我们提出了一种通过频率屏蔽的新型深度伪造检测器。我们的重点是频率域，与大多数方法主要针对空间域检测有所不同。我们的比较分析揭示了与现有方法相比的显著性能提升。代码和模型已公开发布。

    We study universal deepfake detection. Our goal is to detect synthetic images from a range of generative AI approaches, particularly from emerging ones which are unseen during training of the deepfake detector. Universal deepfake detection requires outstanding generalization capability. Motivated by recently proposed masked image modeling which has demonstrated excellent generalization in self-supervised pre-training, we make the first attempt to explore masked image modeling for universal deepfake detection. We study spatial and frequency domain masking in training deepfake detectors. Based on empirical analysis, we propose a novel deepfake detector via frequency masking. Our focus on frequency domain is different from the majority, which primarily target spatial domain detection. Our comparative analyses reveal substantial performance gains over existing methods. Code and models are publicly available.
    
[^28]: 改进航空图像中小型有方向物体的检测

    Improving the Detection of Small Oriented Objects in Aerial Images. (arXiv:2401.06503v1 [cs.CV])

    [http://arxiv.org/abs/2401.06503](http://arxiv.org/abs/2401.06503)

    本研究提出了一种改进的方法，通过增强有方向物体检测模型的任务，准确地检测航空图像中的小型有方向物体。实验结果表明，我们的方法在航空数据集上取得了显著的效果。

    

    由于其尺寸和方向，大规模航空图像中代表较小像素区域的小型有方向物体很难检测。现有的有方向航空检测器已经取得了有希望的结果，但主要关注物体的方向建模，对物体的尺寸关注较少。在这项工作中，我们提出了一种方法，通过增强有方向物体检测模型的分类和回归任务，准确地检测航空图像中的小型有方向物体。我们设计了Attention-Points网络，包括两个损失：引导注意力损失（GALoss）和框点损失（BPLoss）。GALoss使用实例分割掩模作为基本真值，学习提高小型物体检测所需的注意力特征。这些注意力特征然后用于预测BPLoss中的框点，确定点相对于目标有方向边界框的位置。实验结果表明，我们的Attention-Points网络在标准的航空数据集上效果显著。

    Small oriented objects that represent tiny pixel-area in large-scale aerial images are difficult to detect due to their size and orientation. Existing oriented aerial detectors have shown promising results but are mainly focused on orientation modeling with less regard to the size of the objects. In this work, we proposed a method to accurately detect small oriented objects in aerial images by enhancing the classification and regression tasks of the oriented object detection model. We designed the Attention-Points Network consisting of two losses: Guided-Attention Loss (GALoss) and Box-Points Loss (BPLoss). GALoss uses an instance segmentation mask as ground-truth to learn the attention features needed to improve the detection of small objects. These attention features are then used to predict box points for BPLoss, which determines the points' position relative to the target oriented bounding box. Experimental results show the effectiveness of our Attention-Points Network on a standar
    
[^29]: 预期的类Shapley分数: 复杂性与在概率数据库中的应用

    Expected Shapley-Like Scores of Boolean Functions: Complexity and Applications to Probabilistic Databases. (arXiv:2401.06493v1 [cs.DB])

    [http://arxiv.org/abs/2401.06493](http://arxiv.org/abs/2401.06493)

    这篇论文提出了一种适应概率环境的类Shapley分数，用于评估数据库中事实对查询回答的贡献。通过研究布尔函数的可处理情况，设计了一个多项式时间的算法，并在概率数据库中应用该算法。

    

    Shapley值是源自博弈论并在可解释的人工智能中越来越重要的方法，用于评估数据库中事实对查询回答的贡献，以及其他类似的权重指标，如Banzhaf值。在这项工作中，我们将这些类Shapley分数适应到概率环境中，目标是计算它们的期望值。我们证明了预期Shapley值和布尔函数的期望值的计算在多项式时间内相互可归约，从而获得相同的可处理性。我们探究了布尔函数被表示为确定性可分解电路的可处理情况，在该情况下设计了一个多项式时间的算法。我们通过数据库来源解释在概率数据库中应用这个算法，并在ProvSQL系统中实现了一个有效的实现，实验证明了它在标准基准测试中的可行性。

    Shapley values, originating in game theory and increasingly prominent in explainable AI, have been proposed to assess the contribution of facts in query answering over databases, along with other similar power indices such as Banzhaf values. In this work we adapt these Shapley-like scores to probabilistic settings, the objective being to compute their expected value. We show that the computations of expected Shapley values and of the expected values of Boolean functions are interreducible in polynomial time, thus obtaining the same tractability landscape. We investigate the specific tractable case where Boolean functions are represented as deterministic decomposable circuits, designing a polynomial-time algorithm for this setting. We present applications to probabilistic databases through database provenance, and an effective implementation of this algorithm within the ProvSQL system, which experimentally validates its feasibility over a standard benchmark.
    
[^30]: Kun: 使用指令反向翻译的中国自对齐问题的答案优化方法

    Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation. (arXiv:2401.06477v1 [cs.CL])

    [http://arxiv.org/abs/2401.06477](http://arxiv.org/abs/2401.06477)

    Kun是一种使用指令反向翻译和答案优化的方法，用于创建高质量的指导调整数据集，该方法不依赖于手动注释，通过自我筛选过程来改善和选择最有效的指令-输出对。它的主要创新在于通过算法改进提高数据的保留和清晰度，并通过创新的数据生成方法减少了手动注释的依赖。

    

    在本文中，我们介绍了一种名为Kun的新方法，用于在不依赖手动注释的情况下为大型语言模型（LLMs）创建高质量的指导调整数据集。Kun利用来自吾道、完卷和SkyPile等多个来源的未标记数据，采用基于指令反向翻译和答案优化的自我训练算法，生成了一个超过一百万个中文指导数据点的大规模数据集。该方法通过使用自我筛选过程来完善和选择最有效的指令-输出对，显著偏离传统方法。我们在多个基准测试上对6B参数的Yi模型进行了实验，结果表明Kun具有鲁棒性和可扩展性。我们方法的核心贡献在于算法的改进，增强了数据的保留和清晰度，并且创新的数据生成方法极大地减少了对昂贵和耗时的手动注释的依赖。这种方法ological方法提出了一种解决中文自对齐问题的方法，并提高了数据的准确性和质量。

    In this paper, we introduce Kun, a novel approach for creating high-quality instruction-tuning datasets for large language models (LLMs) without relying on manual annotations. Adapting a self-training algorithm based on instruction back-translation and answer polishment, Kun leverages unlabelled data from diverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial dataset of over a million Chinese instructional data points. This approach significantly deviates from traditional methods by using a self-curation process to refine and select the most effective instruction-output pairs. Our experiments with the 6B-parameter Yi model across various benchmarks demonstrate Kun's robustness and scalability. Our method's core contributions lie in its algorithmic advancement, which enhances data retention and clarity, and its innovative data generation approach that substantially reduces the reliance on costly and time-consuming manual annotations. This methodology presents a sc
    
[^31]: 一种基于大脑启发的人类概念学习的计算模型

    A Brain-inspired Computational Model for Human-like Concept Learning. (arXiv:2401.06471v1 [cs.AI])

    [http://arxiv.org/abs/2401.06471](http://arxiv.org/abs/2401.06471)

    本研究开发了一种基于脉冲神经网络的人类概念学习计算模型，该模型借鉴了多感官表示和文本导出的机制，并通过语义控制系统协调两种类型的表示，从而模拟了人类概念习得的过程。

    

    概念学习是人类认知的基本方面，在分类、推理、记忆和决策等心理过程中起着关键作用。来自计算神经科学和认知心理学的研究人员着眼于揭示个体的概念习得机制。这些研究发现表明，大脑对概念的表示依赖于两个基本组成部分：多感官表示和文本导出的表示。这两种类型的表示由一个语义控制系统协调，最终导致概念的习得。借鉴这种机制，本研究基于脉冲神经网络开发了一种人类概念学习的计算模型。通过有效地解决多源数据和维度不平衡的挑战，该模型能够模拟人类概念习得的过程。

    Concept learning is a fundamental aspect of human cognition and plays a critical role in mental processes such as categorization, reasoning, memory, and decision-making. Researchers across various disciplines have shown consistent interest in the process of concept acquisition in individuals. To elucidate the mechanisms involved in human concept learning, this study examines the findings from computational neuroscience and cognitive psychology. These findings indicate that the brain's representation of concepts relies on two essential components: multisensory representation and text-derived representation. These two types of representations are coordinated by a semantic control system, ultimately leading to the acquisition of concepts. Drawing inspiration from this mechanism, the study develops a human-like computational model for concept learning based on spiking neural networks. By effectively addressing the challenges posed by diverse sources and imbalanced dimensionality of the two
    
[^32]: PersianMind: 一个跨语言的波斯语-英语大型语言模型

    PersianMind: A Cross-Lingual Persian-English Large Language Model. (arXiv:2401.06466v1 [cs.CL])

    [http://arxiv.org/abs/2401.06466](http://arxiv.org/abs/2401.06466)

    PersianMind是一个开源的双语大型语言模型，通过在波斯语中展现与闭源的GPT-3.5-turbo相当的性能，并利用迁移学习在不同语言间传递任务知识的优势，解决了开源模型在非英文语言上性能不佳的问题。

    

    大型语言模型在各种语言任务中展现出了卓越的能力，并具备广泛的多领域知识。虽然它们在英语方面表现最优，但它们在其他语言方面的能力也很显著。与此相反，如LLaMa这样的开源模型主要是在英文数据集上训练的，导致在非英文语言中表现不佳。在本文中，我们介绍了PersianMind，一个开源的双语大型语言模型，在波斯语中展示了与闭源的GPT-3.5-turbo相当的性能。通过将LLaMa2的词汇表扩展10,000个波斯语标记，并训练约20亿个波斯语标记的数据集，我们展示了我们的方法保留了模型的英语知识并利用迁移学习在不同语言间传递任务知识的优势。

    Large language models demonstrate remarkable proficiency in various linguistic tasks and have extensive knowledge across various domains. Although they perform best in English, their ability in other languages is notable too. In contrast, open-source models, such as LLaMa, are primarily trained on English datasets, resulting in poor performance in non-English languages. In this paper, we introduce PersianMind, an open-source bilingual large language model which demonstrates comparable performance to closed-source GPT-3.5-turbo in the Persian language. By expanding LLaMa2's vocabulary with 10,000 Persian tokens and training it on a dataset comprising nearly 2 billion Persian tokens, we show that our approach preserves the model's English knowledge and employs transfer learning to excel at transferring task knowledge from one language to another.
    
[^33]: Sanity Checks Revisited: 修复模型参数随机化测试的探索

    Sanity Checks Revisited: An Exploration to Repair the Model Parameter Randomisation Test. (arXiv:2401.06465v1 [cs.AI])

    [http://arxiv.org/abs/2401.06465](http://arxiv.org/abs/2401.06465)

    这项研究对模型参数随机化测试进行了探索和修复，通过引入平滑 MPRT 和高效 MPRT 两种改进方法，解决了实证解释的方法论注意事项，并通过实验结果证明这些改进方法可以提高度量可靠性，从而更可信地应用可解释人工智能方法。

    

    在可解释人工智能 (XAI) 社区中，模型参数随机化测试 (MPRT) 凭借其有力的评估原则而广受认可：解释函数应对模型函数参数的变化敏感。然而，最近的研究发现了关于 MPRT 的几个方法论上的注意事项。为了解决这些注意事项，我们引入了两种对原始 MPRT 进行改进的方法——平滑 MPRT 和高效 MPRT，前者通过采样来最小化噪音对评估结果的影响，后者通过在完全参数随机化后解释的复杂度上升来绕过对偏倚相似度测量的需求。我们的实验结果表明，这些提出的变体可以提高度量的可靠性，从而更可信地应用 XAI 方法。

    The Model Parameter Randomisation Test (MPRT) is widely acknowledged in the eXplainable Artificial Intelligence (XAI) community for its well-motivated evaluative principle: that the explanation function should be sensitive to changes in the parameters of the model function. However, recent works have identified several methodological caveats for the empirical interpretation of MPRT. To address these caveats, we introduce two adaptations to the original MPRT -- Smooth MPRT and Efficient MPRT, where the former minimises the impact that noise has on the evaluation results through sampling and the latter circumvents the need for biased similarity measurements by re-interpreting the test through the explanation's rise in complexity, after full parameter randomisation. Our experimental results demonstrate that these proposed variants lead to improved metric reliability, thus enabling a more trustworthy application of XAI methods.
    
[^34]: 代码之间的界限：揭示机器和人类程序员之间不同的模式

    Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. (arXiv:2401.06461v1 [cs.SE])

    [http://arxiv.org/abs/2401.06461](http://arxiv.org/abs/2401.06461)

    本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。

    

    大型语言模型在代码生成方面取得了显著的进展，但它们模糊了机器和人类源代码之间的区别，导致软件产物的完整性和真实性问题。本文通过对代码长度、词汇多样性和自然性等属性的严格分析，揭示了机器和人类代码固有的独特模式。在我们的研究中特别注意到，代码的结构分割是识别其来源的关键因素。基于我们的发现，我们提出了一种名为DetectCodeGPT的新型机器生成代码检测方法，该方法改进了DetectGPT。

    Large language models have catalyzed an unprecedented wave in code generation. While achieving significant advances, they blur the distinctions between machine-and human-authored source code, causing integrity and authenticity issues of software artifacts. Previous methods such as DetectGPT have proven effective in discerning machine-generated texts, but they do not identify and harness the unique patterns of machine-generated code. Thus, its applicability falters when applied to code. In this paper, we carefully study the specific patterns that characterize machine and human-authored code. Through a rigorous analysis of code attributes such as length, lexical diversity, and naturalness, we expose unique pat-terns inherent to each source. We particularly notice that the structural segmentation of code is a critical factor in identifying its provenance. Based on our findings, we propose a novel machine-generated code detection method called DetectCodeGPT, which improves DetectGPT by cap
    
[^35]: 3D-PreMise：大型语言模型能否生成具有尖锐特征和参数控制的3D形状？

    3D-PreMise: Can Large Language Models Generate 3D Shapes with Sharp Features and Parametric Control?. (arXiv:2401.06437v1 [cs.GR])

    [http://arxiv.org/abs/2401.06437](http://arxiv.org/abs/2401.06437)

    本研究介绍了一种利用大型语言模型的框架，通过程序合成操控3D软件生成具有尖锐特征和参数控制的3D形状。我们提出了一个专门的数据集和流程来探究最先进的语言模型，在工业应用的3D参数建模中揭示了LLMs的潜力和局限性。

    

    最近对隐式3D表示和生成模型的进展极大地推动了3D物体生成领域的发展。然而，在参数控制下准确建模具有定义的尖锐特征的几何形状仍然是一个重大挑战，这在工业设计和制造领域至关重要。为了弥合这一差距，我们引入了一种采用大型语言模型（LLMs）通过程序合成操控3D软件生成文本驱动的3D形状的框架。我们提出了3D-PreMise，这是一个专门针对工业形状的3D参数建模的数据集，旨在在我们提出的流程中探索最先进的LLMs。我们的工作揭示了有效的生成策略，并通过可视界面探索了LLMs的自我修正能力。我们的工作突显了LLMs在工业应用的3D参数建模中的潜力和局限性。

    Recent advancements in implicit 3D representations and generative models have markedly propelled the field of 3D object generation forward. However, it remains a significant challenge to accurately model geometries with defined sharp features under parametric controls, which is crucial in fields like industrial design and manufacturing. To bridge this gap, we introduce a framework that employs Large Language Models (LLMs) to generate text-driven 3D shapes, manipulating 3D software via program synthesis. We present 3D-PreMise, a dataset specifically tailored for 3D parametric modeling of industrial shapes, designed to explore state-of-the-art LLMs within our proposed pipeline. Our work reveals effective generation strategies and delves into the self-correction capabilities of LLMs using a visual interface. Our work highlights both the potential and limitations of LLMs in 3D parametric modeling for industrial applications.
    
[^36]: 在基于社交网络的物品推荐中，用Transformer层改进图卷积网络

    Improving Graph Convolutional Networks with Transformer Layer in social-based items recommendation. (arXiv:2401.06436v1 [cs.LG])

    [http://arxiv.org/abs/2401.06436](http://arxiv.org/abs/2401.06436)

    本文提出了一种在社交网络中预测评分的方法，该方法通过在GCN模型中引入Transformer层，在节点嵌入方面取得了更好的性能。

    

    在这项工作中，我们提出了一种改进GCN在社交网络中预测评分的方法。我们的模型在标准模型的基础上扩展了几层Transformer架构。论文的主要焦点是网络中节点嵌入的编码器架构。使用来自基于图的卷积层的嵌入层，注意机制可以重新排列特征空间，为下游任务获取更高效的嵌入。实验表明，我们提出的架构在传统的链接预测任务上表现优于GCN。

    In this work, we have proposed an approach for improving the GCN for predicting ratings in social networks. Our model is expanded from the standard model with several layers of transformer architecture. The main focus of the paper is on the encoder architecture for node embedding in the network. Using the embedding layer from the graph-based convolution layer, the attention mechanism could rearrange the feature space to get a more efficient embedding for the downstream task. The experiments showed that our proposed architecture achieves better performance than GCN on the traditional link prediction task.
    
[^37]: 从自动化到增强：大型语言模型提升作文评分领域

    From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape. (arXiv:2401.06431v1 [cs.CL])

    [http://arxiv.org/abs/2401.06431](http://arxiv.org/abs/2401.06431)

    本研究调查了大型语言模型（LLM）在自动化作文评分系统中的有效性，并发现LLM AES系统具有更高的准确性、一致性、普适性和可解释性。此外，LLM还能提升人类评分员的性能。

    

    对于第二语言学习者来说，接收即时个性化反馈非常重要，当人类教师无法提供时，自动化作文评分系统是一种重要资源。本研究调查了大型语言模型（LLM），特别是GPT-4和经过微调的GPT-3.5，作为AES工具的有效性。我们基于公共和私有数据集进行了一系列全面的实验，突出了LLM AES系统的显着优势，包括更高的准确性、一致性、普适性和可解释性，而经过微调的GPT-3.5超越了传统评分模型。此外，我们进行了LLM辅助的人工评估实验，涉及初学者和专家评分员。一个关键的发现是，LLM不仅能自动化评分过程，还能提升人类评分员的性能。当初学者评分员获得LLM生成的反馈时，其准确性与专家水平相当，同时专家变得更加高效。

    Receiving immediate and personalized feedback is crucial for second-language learners, and Automated Essay Scoring (AES) systems are a vital resource when human instructors are unavailable. This study investigates the effectiveness of Large Language Models (LLMs), specifically GPT-4 and fine-tuned GPT-3.5, as tools for AES. Our comprehensive set of experiments, conducted on both public and private datasets, highlights the remarkable advantages of LLM-based AES systems. They include superior accuracy, consistency, generalizability, and interpretability, with fine-tuned GPT-3.5 surpassing traditional grading models. Additionally, we undertake LLM-assisted human evaluation experiments involving both novice and expert graders. One pivotal discovery is that LLMs not only automate the grading process but also enhance the performance of human graders. Novice graders when provided with feedback generated by LLMs, achieve a level of accuracy on par with experts, while experts become more effici
    
[^38]: UPDP: 一种适用于CNN和Vision Transformer的统一渐进深度修剪器

    UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer. (arXiv:2401.06426v1 [cs.CV])

    [http://arxiv.org/abs/2401.06426](http://arxiv.org/abs/2401.06426)

    UPDP是一种适用于CNN和Vision Transformer的统一渐进深度修剪器，通过引入新的块修剪策略和渐进训练方法，解决了传统的修剪方法在修剪高效模型时遇到的问题，且在各种修剪配置下表现优于现有的深度修剪方法。

    

    传统的逐通道修剪方法通过减少网络通道来修剪CNN模型中的深度卷积层和某些高效模块，如流行的反向残差块。之前的深度修剪方法通过减少网络深度不能很好地修剪一些高效模型，因为存在某些归一化层。此外，通过直接删除激活层来微调子网络会破坏原始模型权重，阻碍修剪模型的高性能。为了解决这些问题，我们提出了一种新颖的高效模型深度修剪方法。我们的方法提出了一种新颖的块修剪策略和子网络的渐进训练方法。此外，我们将修剪方法扩展到了Vision Transformer模型。实验证明，我们的方法在各种修剪配置上持续优于现有的深度修剪方法。我们获得了三个修剪后的ConvNeXtV1模型。

    Traditional channel-wise pruning methods by reducing network channels struggle to effectively prune efficient CNN models with depth-wise convolutional layers and certain efficient modules, such as popular inverted residual blocks. Prior depth pruning methods by reducing network depths are not suitable for pruning some efficient models due to the existence of some normalization layers. Moreover, finetuning subnet by directly removing activation layers would corrupt the original model weights, hindering the pruned model from achieving high performance. To address these issues, we propose a novel depth pruning method for efficient models. Our approach proposes a novel block pruning strategy and progressive training method for the subnet. Additionally, we extend our pruning method to vision transformer models. Experimental results demonstrate that our method consistently outperforms existing depth pruning methods across various pruning configurations. We obtained three pruned ConvNeXtV1 mo
    
[^39]: 使用符合预测的不确定性量化的地球观测概率机器学习

    Uncertainty quantification for probabilistic machine learning in earth observation using conformal prediction. (arXiv:2401.06421v1 [cs.LG])

    [http://arxiv.org/abs/2401.06421](http://arxiv.org/abs/2401.06421)

    本论文介绍了地球观测领域中使用符合预测进行不确定性量化的方法。与其他方法不同，符合预测不需要访问底层模型和训练数据集，并同时提供统计上有效和有信息的预测区域，同时保持计算效率。

    

    当使用人工智能系统进行决策时，不可靠的预测可能会导致负面后果。符合预测提供了一个与模型无关的不确定性量化框架，可以应用于任何数据集，无论其分布如何。与其他像素级的不确定性量化方法不同，符合预测不需要访问底层模型和训练数据集，并同时提供统计上有效和有信息的预测区域，同时保持计算效率。

    Unreliable predictions can occur when using artificial intelligence (AI) systems with negative consequences for downstream applications, particularly when employed for decision-making. Conformal prediction provides a model-agnostic framework for uncertainty quantification that can be applied to any dataset, irrespective of its distribution, post hoc. In contrast to other pixel-level uncertainty quantification methods, conformal prediction operates without requiring access to the underlying model and training dataset, concurrently offering statistically valid and informative prediction regions, all while maintaining computational efficiency. In response to the increased need to report uncertainty alongside point predictions, we bring attention to the promise of conformal prediction within the domain of Earth Observation (EO) applications. To accomplish this, we assess the current state of uncertainty quantification in the EO domain and found that only 20% of the reviewed Google Earth En
    
[^40]: 不可能任务：语言模型

    Mission: Impossible Language Models. (arXiv:2401.06416v1 [cs.CL])

    [http://arxiv.org/abs/2401.06416](http://arxiv.org/abs/2401.06416)

    本文为了支持大型语言模型(LLMs)能够学习不可能的语言的观点，开发了一组人工合成的不可能语言，并通过评估GPT-2小型模型的学习能力得出了结论。

    

    Chomsky和其他人直接声称，大型语言模型(LLMs)能够学习人类无法学习的可能和不可能的语言。然而，很少有发表的实验证据支持这样的说法。在这里，我们通过系统地改变英文数据的词序和语法规则，开发了一组不可能的合成语言，每种语言的复杂程度不同。这些语言位于一个不可能的连续体上：一端是本质上不可能的语言，例如英文单词的随机和不可逆的洗牌，而另一端是在语言学上常被认为是不可能的语言，特别是基于计算词位置的规则。我们报告了广泛的评估来评估GPT-2小型模型学习这些无可争议的不可能语言的能力，并且至关重要的是，在整个过程中进行了这些评估。

    Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim. Here, we develop a set of synthetic impossible languages of differing complexity, each designed by systematically altering English data with unnatural word orders and grammar rules. These languages lie on an impossibility continuum: at one end are languages that are inherently impossible, such as random and irreversible shuffles of English words, and on the other, languages that may not be intuitively impossible but are often considered so in linguistics, particularly those with rules based on counting word positions. We report on a wide range of evaluations to assess the capacity of GPT-2 small models to learn these uncontroversially impossible languages, and crucially, we perform these assessments at various stages throughout
    
[^41]: 知识驱动的机器学习在癌症诊断和预后中的应用：综述

    Knowledge-Informed Machine Learning for Cancer Diagnosis and Prognosis: A review. (arXiv:2401.06406v1 [cs.LG])

    [http://arxiv.org/abs/2401.06406](http://arxiv.org/abs/2401.06406)

    知识驱动的机器学习在癌症诊断和预后中的应用已经取得了一定的进展。该方法将生物医学知识与数据驱动模型相结合，能够提高模型结果的准确性、鲁棒性和可解释性。这篇综述回顾了最新研究，并强调了四个主要特点。

    

    癌症仍然是医学领域中治疗最具挑战性的疾病之一。机器学习已经使得对于癌症诊断和预后的丰富的多组学数据和医学图像进行了深入分析。尽管取得了这些进展，机器学习模型面临着一些挑战，包括标记样本数量有限、高维数据类型之间的复杂相互作用、患者内部和肿瘤内部的固有异质性以及与现有生物医学知识的解释和一致性。克服这些挑战的一种方法是将生物医学知识纳入数据驱动模型中，这已经被证明具有提高模型结果的准确性、鲁棒性和可解释性的潜力。在本文中，我们综述了采用了融合生物医学知识和数据的知识驱动机器学习，在癌症诊断和预后中的最新研究。突出了四个主要特点。

    Cancer remains one of the most challenging diseases to treat in the medical field. Machine learning has enabled in-depth analysis of rich multi-omics profiles and medical imaging for cancer diagnosis and prognosis. Despite these advancements, machine learning models face challenges stemming from limited labeled sample sizes, the intricate interplay of high-dimensionality data types, the inherent heterogeneity observed among patients and within tumors, and concerns about interpretability and consistency with existing biomedical knowledge. One approach to surmount these challenges is to integrate biomedical knowledge into data-driven models, which has proven potential to improve the accuracy, robustness, and interpretability of model results. Here, we review the state-of-the-art machine learning studies that adopted the fusion of biomedical knowledge and data, termed knowledge-informed machine learning, for cancer diagnosis and prognosis. Emphasizing the properties inherent in four prima
    
[^42]: DevEval: 评估实际软件项目中的代码生成

    DevEval: Evaluating Code Generation in Practical Software Projects. (arXiv:2401.06401v1 [cs.SE])

    [http://arxiv.org/abs/2401.06401](http://arxiv.org/abs/2401.06401)

    本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。

    

    如何评估大型语言模型（LLMs）在代码生成中的表现是一个开放的问题。许多基准测试已经提出，但是与实际软件项目不一致，例如虚构的程序分布，依赖不足和小规模项目背景。因此，LLMs在实际项目中的能力还不清楚。在本文中，我们提出了一个名为DevEval的新基准测试，与开发人员在实际项目中的经验相吻合。DevEval通过一个严格的流程收集到了来自119个实际项目的2690个样本，涵盖10个领域。与之前的基准测试相比，DevEval在多个维度上与实际项目相吻合，例如真实的程序分布，充足的依赖和足够规模的项目背景。我们在DevEval上评估了五个流行的LLMs（例如gpt-4，gpt-3.5-turbo，CodeLLaMa和StarCoder），并揭示了它们在代码生成中的实际能力。例如，gpt-3.5-turbo的最高Pass@1只有42。

    How to evaluate Large Language Models (LLMs) in code generation is an open question. Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts. Thus, the capabilities of LLMs in practical projects are still unclear. In this paper, we propose a new benchmark named DevEval, aligned with Developers' experiences in practical projects. DevEval is collected through a rigorous pipeline, containing 2,690 samples from 119 practical projects and covering 10 domains. Compared to previous benchmarks, DevEval aligns to practical projects in multiple dimensions, e.g., real program distributions, sufficient dependencies, and enough-scale project contexts. We assess five popular LLMs on DevEval (e.g., gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo only is 42 in our experim
    
[^43]: 自适应数据增强用于方面情感四元预测

    Adaptive Data Augmentation for Aspect Sentiment Quad Prediction. (arXiv:2401.06394v1 [cs.CL])

    [http://arxiv.org/abs/2401.06394](http://arxiv.org/abs/2401.06394)

    本文提出了一种自适应数据增强（ADA）框架来解决方面情感四元预测（ASQP）任务中的数据不平衡问题。实验证实，数据增强可以改善ASQP任务的性能，而ADA方法优于简单的数据过采样方法。

    

    方面情感四元预测（ASQP）旨在预测给定句子的四元情感元素，这是方面情感分析领域中的关键任务。然而，在ASQP任务中，数据不平衡问题尚未得到足够的重视。在本文中，我们将问题分为两个方面：四元模式不平衡和方面类别不平衡，并提出了一种自适应数据增强（ADA）框架来解决不平衡问题。具体而言，通过具有条件函数的数据增强过程，自适应增强尾部四元模式和方面类别，缓解ASQP中的数据不平衡。在之前的研究基础上，我们还进一步探索了生成框架，通过引入类别先验知识和语法引导解码目标，提取完整的四元。实验证实，数据增强可以改善ASQP任务中的不平衡问题，并且所提出的ADA方法优于简单的数据过采样方法。

    Aspect sentiment quad prediction (ASQP) aims to predict the quad sentiment elements for a given sentence, which is a critical task in the field of aspect-based sentiment analysis. However, the data imbalance issue has not received sufficient attention in ASQP task. In this paper, we divide the issue into two-folds, quad-pattern imbalance and aspect-category imbalance, and propose an Adaptive Data Augmentation (ADA) framework to tackle the imbalance issue. Specifically, a data augmentation process with a condition function adaptively enhances the tail quad patterns and aspect categories, alleviating the data imbalance in ASQP. Following previous studies, we also further explore the generative framework for extracting complete quads by introducing the category prior knowledge and syntax-guided decoding target. Experimental results demonstrate that data augmentation for imbalance in ASQP task can improve the performance, and the proposed ADA method is superior to naive data oversampling.
    
[^44]: 我应该说什么？-与AI和自然语言界面的交互

    What should I say? -- Interacting with AI and Natural Language Interfaces. (arXiv:2401.06382v1 [cs.HC])

    [http://arxiv.org/abs/2401.06382](http://arxiv.org/abs/2401.06382)

    随着人工智能技术的普及，研究人类与AI的交互变得越来越重要。本研究通过探索人类与AI交互过程中心智表征的建立，旨在帮助实现成功和轻松的沟通。

    

    随着人工智能（AI）技术越来越普遍，探索人类如何与AI交互变得越来越重要。人工智能交互（HAI）子领域从人机交互（HCI）领域中出现，旨在研究这个问题。许多交互模式已经实施，但对于使用这些更像人类本质的替代界面所需认知的变化以及使用这些界面的认知科学影响，了解还很有限。先前的研究表明，成功和轻松的沟通关键在于心智表征，然而，在与AI交互时，心智表征是如何建立的仍不甚了解。

    As Artificial Intelligence (AI) technology becomes more and more prevalent, it becomes increasingly important to explore how we as humans interact with AI. The Human-AI Interaction (HAI) sub-field has emerged from the Human-Computer Interaction (HCI) field and aims to examine this very notion. Many interaction patterns have been implemented without fully understanding the changes in required cognition as well as the cognitive science implications of using these alternative interfaces that aim to be more human-like in nature. Prior research suggests that theory of mind representations are crucial to successful and effortless communication, however very little is understood when it comes to how theory of mind representations are established when interacting with AI.
    
[^45]: Vehicle: 在验证神经符号化程序中弥合嵌入缺口

    Vehicle: Bridging the Embedding Gap in the Verification of Neuro-Symbolic Programs. (arXiv:2401.06379v1 [cs.AI])

    [http://arxiv.org/abs/2401.06379](http://arxiv.org/abs/2401.06379)

    本文提出了一个名为Vehicle的工具，它能够在验证神经符号化程序中弥合嵌入缺口，为指定神经网络属性和解释其与嵌入空间的关系提供了方便的语言和强大的编译器。

    

    神经符号化程序是包含机器学习组件和传统符号化代码的程序，正在变得越来越普遍。然而，我们认为目前缺乏一种通用的方法来验证这些程序，因为它们的正确性取决于机器学习组件的行为。在本文中，我们将“嵌入缺口”——以语义有意义的“问题空间”属性与等效的“嵌入空间”属性之间缺乏技术的问题——视为关键问题之一，并描述了一个名为Vehicle的工具，以模块化的方式促进神经符号化程序的端到端验证。Vehicle提供了一种方便的语言，用于指定神经网络的“问题空间”属性并声明它们与“嵌入空间”的关系，以及一个强大的编译器，可以自动将这些属性解释为所选择的机器学习训练环境、神经网络验证工具支持的语言。

    Neuro-symbolic programs -- programs containing both machine learning components and traditional symbolic code -- are becoming increasingly widespread. However, we believe that there is still a lack of a general methodology for verifying these programs whose correctness depends on the behaviour of the machine learning components. In this paper, we identify the ``embedding gap'' -- the lack of techniques for linking semantically-meaningful ``problem-space'' properties to equivalent ``embedding-space'' properties -- as one of the key issues, and describe Vehicle, a tool designed to facilitate the end-to-end verification of neural-symbolic programs in a modular fashion. Vehicle provides a convenient language for specifying ``problem-space'' properties of neural networks and declaring their relationship to the ``embedding-space", and a powerful compiler that automates interpretation of these properties in the language of a chosen machine-learning training environment, neural network verifie
    
[^46]: 认知BPM作为平等化因素：提高具有（和没有）认知障碍的员工的访问和效率

    Cognitive BPM as an Equalizer: Improving Access and Efficiency for Employees with (and without) Cognitive Disabilities. (arXiv:2401.06375v1 [cs.AI])

    [http://arxiv.org/abs/2401.06375](http://arxiv.org/abs/2401.06375)

    本研究以ProcessGPT为例，探讨了在人类认知限制下管理业务流程的挑战，特别是针对认知障碍个体。研究表明，ProcessGPT改善了不同认知能力的个体的流程可用性，对组织来说也能带来更高的生产力、士气和包容性。

    

    我们研究了ProcessGPT，一个旨在自动化、增强和改善业务流程的人工智能模型，以研究在人类劳动力的认知限制下管理业务流程的挑战，尤其是认知障碍的个体。ProcessGPT提供了设计高效业务流程的蓝图，考虑到人类的认知限制。通过从认知障碍的角度来看待，我们表明ProcessGPT改善了具有和没有认知障碍的个体的流程可用性。我们还证明实施类似ProcessGPT功能的组织将实现增加的生产力、士气和包容性。

    We examine ProcessGPT, an AI model designed to automate, augment, and improve business processes, to study the challenges of managing business processes within the cognitive limitations of the human workforce, particularly individuals with cognitive disabilities. ProcessGPT provides a blueprint for designing efficient business processes that take into account human cognitive limitations. By viewing this through the lens of cognitive disabilities, we show that ProcessGPT improves process usability for individuals with and without cognitive disabilities. We also demonstrate that organizations implementing ProcessGPT-like capabilities will realize increased productivity, morale, and inclusion.
    
[^47]: 如何使Johnny说服LLMs越狱：通过人性化LLMs重新思考对AI安全的挑战

    How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs. (arXiv:2401.06373v1 [cs.CL])

    [http://arxiv.org/abs/2401.06373](http://arxiv.org/abs/2401.06373)

    本文通过将LLMs视为人类交流者，探索了每天语言互动和AI安全之间忽视的交叉点，并提出了一种通过说服LLMs进行越狱的方法。研究结果表明，说服显著提高了越狱性能，在多个风险类别上均取得了超过92%的攻击成功率。

    

    大多数传统的AI安全研究将AI模型视为机器，并集中在由安全专家开发的基于算法的攻击上。随着大型语言模型（LLMs）的普及和竞争力越来越强，非专家用户在日常互动中也可能产生风险。本文介绍了一种新的视角，将LLMs作为类似人类的交流者来越狱，以探索每天语言互动和AI安全之间被忽视的交叉点。具体而言，我们研究如何说服LLMs越狱。首先，我们提出了一个从几十年的社会科学研究中得出的说服分类法。然后，我们应用这个分类法来自动生成可解释的说服对抗提示（PAP）来越狱LLMs。结果显示，说服显著提高了越狱性能，在所有风险类别上PAP在Llama 2-7b Chat、GPT-3.5和GPT-4上的攻击成功率在10次试验中均超过92%，超过了最近的基于算法的攻击。

    Most traditional AI safety research has approached AI models as machines and centered on algorithm-focused attacks developed by security experts. As large language models (LLMs) become increasingly common and competent, non-expert users can also impose risks during daily interactions. This paper introduces a new perspective to jailbreak LLMs as human-like communicators, to explore this overlooked intersection between everyday language interaction and AI safety. Specifically, we study how to persuade LLMs to jailbreak them. First, we propose a persuasion taxonomy derived from decades of social science research. Then, we apply the taxonomy to automatically generate interpretable persuasive adversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion significantly increases the jailbreak performance across all risk categories: PAP consistently achieves an attack success rate of over $92\%$ on Llama 2-7b Chat, GPT-3.5, and GPT-4 in $10$ trials, surpassing recent algorithm-focu
    
[^48]: 用于高效生物医学实例分割的图关系蒸馏

    Graph Relation Distillation for Efficient Biomedical Instance Segmentation. (arXiv:2401.06370v1 [cs.CV])

    [http://arxiv.org/abs/2401.06370](http://arxiv.org/abs/2401.06370)

    本研究提出了一种用于高效生物医学实例分割的图关系蒸馏方法，通过考虑实例级特征、实例关系和像素级边界的知识，使用实例图蒸馏和亲和图蒸馏来解决资源需求巨大的问题。

    

    由深度神经网络预测的实例感知嵌入已经在生物医学实例分割中引起了革命，但其资源需求巨大。知识蒸馏通过将来自重型教师网络的蒸馏知识转移给轻量级但高性能的学生网络，提供了一种解决方案。然而，现有的知识蒸馏方法在提取用于区分实例的知识和忽略全局关系信息方面存在困难。为了解决这些挑战，我们提出了一种用于高效生物医学实例分割的图关系蒸馏方法，它考虑了三种关键类型的知识：实例级特征、实例关系和像素级边界。我们引入了两种图蒸馏方案，分别部署在图像内部和图像间：实例图蒸馏（IGD）和亲和图蒸馏（AGD）。IGD构建了一个表示实例特征和关系的图，并将这两种类型的知识转移给学生网络。

    Instance-aware embeddings predicted by deep neural networks have revolutionized biomedical instance segmentation, but its resource requirements are substantial. Knowledge distillation offers a solution by transferring distilled knowledge from heavy teacher networks to lightweight yet high-performance student networks. However, existing knowledge distillation methods struggle to extract knowledge for distinguishing instances and overlook global relation information. To address these challenges, we propose a graph relation distillation approach for efficient biomedical instance segmentation, which considers three essential types of knowledge: instance-level features, instance relations, and pixel-level boundaries. We introduce two graph distillation schemes deployed at both the intra-image level and the inter-image level: instance graph distillation (IGD) and affinity graph distillation (AGD). IGD constructs a graph representing instance features and relations, transferring these two typ
    
[^49]: 基于主题专用适配器的时间-频谱融合Transformer用于增强RSVP-BCI解码

    A Temporal-Spectral Fusion Transformer with Subject-specific Adapter for Enhancing RSVP-BCI Decoding. (arXiv:2401.06340v1 [cs.HC])

    [http://arxiv.org/abs/2401.06340](http://arxiv.org/abs/2401.06340)

    本文提出了一种基于主题专用适配器的时间-频谱融合Transformer (TSformer-SA) 用于增强RSVP-BCI解码。该方法通过引入多视图信息并减少准备时间，实现了解码性能的提升。

    

    快速串联视觉呈现（RSVP）基于脑机接口（BCI）是一种利用脑电信号进行目标检索的高效技术。传统解码方法的性能改进依赖于大量来自新测试对象的训练数据，这增加了BCI系统的准备时间。一些研究引入了来自现有对象的数据以减少性能改进对新对象数据的依赖性，但它们基于对抗学习的优化策略以及大量数据的训练增加了准备过程中的训练时间。此外，大多数之前的方法只关注脑电信号的单视图信息，而忽略了其他视图的信息，这可能进一步改善性能。为了在减少准备时间的同时提高解码性能，我们提出了一种具有主题专用适配器的时间-频谱融合Transformer（TSformer-SA）。

    The Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface (BCI) is an efficient technology for target retrieval using electroencephalography (EEG) signals. The performance improvement of traditional decoding methods relies on a substantial amount of training data from new test subjects, which increases preparation time for BCI systems. Several studies introduce data from existing subjects to reduce the dependence of performance improvement on data from new subjects, but their optimization strategy based on adversarial learning with extensive data increases training time during the preparation procedure. Moreover, most previous methods only focus on the single-view information of EEG signals, but ignore the information from other views which may further improve performance. To enhance decoding performance while reducing preparation time, we propose a Temporal-Spectral fusion transformer with Subject-specific Adapter (TSformer-SA). Specifically, a cross-view interaction 
    
[^50]: 通过强化学习在动态系统公平性中取得平衡

    Striking a Balance in Fairness for Dynamic Systems Through Reinforcement Learning. (arXiv:2401.06318v1 [cs.LG])

    [http://arxiv.org/abs/2401.06318](http://arxiv.org/abs/2401.06318)

    本文研究了在决策模型操作的动态人口中的公平性问题，并提出了一种通过强化学习结合各种公平考虑的算法框架。通过预处理和处理中的方法，我们的方法能够在传统公平性、长期公平性和效用之间取得平衡。

    

    在公平机器学习领域取得了重大进展，但大多数研究集中在决策模型在静态人群上运行的情况下。本文研究了决策模型操作的人口是动态的情况下的公平性。每个决策可能会改变特征或用户行为的基础分布。我们通过马尔科夫决策过程（MDP）建模动态系统。在承认传统公平性概念和长期公平性是不同要求且可能不一致的情况下，我们提出了一种算法框架，将各种公平考虑与强化学习相结合，同时使用预处理和处理中的方法。三个案例研究显示我们的方法能够在传统公平性、长期公平性和效用之间取得平衡。

    While significant advancements have been made in the field of fair machine learning, the majority of studies focus on scenarios where the decision model operates on a static population. In this paper, we study fairness in dynamic systems where sequential decisions are made. Each decision may shift the underlying distribution of features or user behavior. We model the dynamic system through a Markov Decision Process (MDP). By acknowledging that traditional fairness notions and long-term fairness are distinct requirements that may not necessarily align with one another, we propose an algorithmic framework to integrate various fairness considerations with reinforcement learning using both pre-processing and in-processing approaches. Three case studies show that our method can strike a balance between traditional fairness notions, long-term fairness, and utility.
    
[^51]: 一种用于分布式、动态6G应用的语义感知多址访问方案

    A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic 6G-Based Applications. (arXiv:2401.06308v1 [cs.NI])

    [http://arxiv.org/abs/2401.06308](http://arxiv.org/abs/2401.06308)

    本文提出了一种语义感知多址访问方案，旨在优化资源利用与公平性的权衡，并考虑用户数据的相关性，以满足未来6G应用的要求和特性。

    

    语义感知范式的出现为创新的服务提供了机会，尤其是在基于6G的应用环境中。尽管在语义提取技术方面取得了显著进展，但将语义信息纳入资源分配决策仍处于早期阶段，缺乏对未来系统需求和特性的考虑。为此，本文引入了一种新的无线频谱多址访问问题的建模。它旨在优化利用率与公平性的权衡，使用α-公平度量，并通过引入自助吞吐量和协助吞吐量的概念来考虑用户数据的相关性。首先，分析了该问题，找出了最优解。接下来，提出了一种基于模型无关的多主体深度强化学习技术的语义感知多智能体双重和决斗深度Q学习 (SAMA-D3QL) 方法。

    The emergence of the semantic-aware paradigm presents opportunities for innovative services, especially in the context of 6G-based applications. Although significant progress has been made in semantic extraction techniques, the incorporation of semantic information into resource allocation decision-making is still in its early stages, lacking consideration of the requirements and characteristics of future systems. In response, this paper introduces a novel formulation for the problem of multiple access to the wireless spectrum. It aims to optimize the utilization-fairness trade-off, using the $\alpha$-fairness metric, while accounting for user data correlation by introducing the concepts of self- and assisted throughputs. Initially, the problem is analyzed to identify its optimal solution. Subsequently, a Semantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL) technique is proposed. This method is grounded in Model-free Multi-Agent Deep Reinforcement Learning (MADRL),
    
[^52]: 量子神经网络作为量子信息译码器的优势

    Advantage of Quantum Neural Networks as Quantum Information Decoders. (arXiv:2401.06300v1 [quant-ph])

    [http://arxiv.org/abs/2401.06300](http://arxiv.org/abs/2401.06300)

    本论文研究了量子神经网络（QNN）作为解码器在解码量子信息时的优势。实验证明，QNN解码器在读取错误方面几乎具有二次改进。这使得在解码实际的量子纠错码时可以探索更广泛的非稳定器码。

    

    一种保护量子信息免受噪声引起的错误的有希望策略是将其编码到拓扑量子存储设备的低能态中。然而，在实际情况下，来自这种存储器的读取错误的情况尚不清楚。我们研究了在存在泛函扰动（如瞬态失调）的情况下，解码编码在拓扑稳定器哈密顿量的基态中的量子信息的问题。首先，我们证明了标准的稳定器型错误校正和解码方案在这种扰动的量子码中工作得相当好，通过展示解码错误在底层无扰动码的距离上呈指数衰减。然后，我们证明了量子神经网络（QNN）译码器在读取错误方面提供了几乎二次的改进。因此，我们证明了在解码实际的量子纠错码方面使用QNN的明显优势，并且我们的结果使得探索更广泛的非稳定器码成为可能。

    A promising strategy to protect quantum information from noise-induced errors is to encode it into the low-energy states of a topological quantum memory device. However, readout errors from such memory under realistic settings is less understood. We study the problem of decoding quantum information encoded in the groundspaces of topological stabilizer Hamiltonians in the presence of generic perturbations, such as quenched disorder. We first prove that the standard stabilizer-based error correction and decoding schemes work adequately well in such perturbed quantum codes by showing that the decoding error diminishes exponentially in the distance of the underlying unperturbed code. We then prove that Quantum Neural Network (QNN) decoders provide an almost quadratic improvement on the readout error. Thus, we demonstrate provable advantage of using QNNs for decoding realistic quantum error-correcting codes, and our result enables the exploration of a wider range of non-stabilizer codes in 
    
[^53]: 多插槽重新排序器: 推荐系统中的通用基于模型的重新排序框架

    MultiSlot ReRanker: A Generic Model-based Re-Ranking Framework in Recommendation Systems. (arXiv:2401.06293v1 [cs.AI])

    [http://arxiv.org/abs/2401.06293](http://arxiv.org/abs/2401.06293)

    多插槽重新排序器是一个通用的基于模型的重新排序框架，在推荐系统中同时优化相关性、多样性和新鲜度。它通过建模物品之间的相互影响和利用多个目标的第二次排序得分来提高离线AUC，并通过离线回放理论在多个目标之间进行权衡，进一步改善离线回放结果。

    

    本文提出了一种通用的基于模型的重新排序框架——多插槽重新排序器，它同时优化相关性、多样性和新鲜度。具体而言，我们的顺序贪心算法（SGA）足够高效（线性时间复杂度）用于大规模生产推荐引擎。它在离线AUC（接收器操作特征曲线下面积）上取得了6%至10%的提升，主要是由于在列表中明确建模了物品之间的相互影响，并利用了多个目标的第二次排序得分。此外，我们将离线回放理论推广到多插槽重新排序场景，通过在多个目标之间进行权衡来改善离线回放结果。离线回放结果还可以通过Pareto最优性进一步改进。此外，我们还基于OpenAI Gym和Ray框架构建了一个多插槽重新排序模拟器。它可以根据不同的假设进行简单配置，快速评估强化学习和...

    In this paper, we propose a generic model-based re-ranking framework, MultiSlot ReRanker, which simultaneously optimizes relevance, diversity, and freshness. Specifically, our Sequential Greedy Algorithm (SGA) is efficient enough (linear time complexity) for large-scale production recommendation engines. It achieved a lift of $+6\%$ to $ +10\%$ offline Area Under the receiver operating characteristic Curve (AUC) which is mainly due to explicitly modeling mutual influences among items of a list, and leveraging the second pass ranking scores of multiple objectives. In addition, we have generalized the offline replay theory to multi-slot re-ranking scenarios, with trade-offs among multiple objectives. The offline replay results can be further improved by Pareto Optimality. Moreover, we've built a multi-slot re-ranking simulator based on OpenAI Gym integrated with the Ray framework. It can be easily configured for different assumptions to quickly benchmark both reinforcement learning and s
    
[^54]: 一个用于原型开发通用人工智能的普适知识模型和认知架构

    A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI. (arXiv:2401.06256v1 [cs.AI])

    [http://arxiv.org/abs/2401.06256](http://arxiv.org/abs/2401.06256)

    本文提出了一个普适的知识模型和认知架构，用于原型开发通用人工智能（AGI）。该架构包括42种认知架构和一组功能模块，用于接近AGI能力的智能系统。此外，本文还提出了一种通用的知识表示方法，可以将各种不同形式的知识表示整合到一个知识库中。

    

    本文确定了42种用于创建通用人工智能（AGI）的认知架构，并提出了一组相互关联的功能模块，这些模块是接近AGI能力的智能系统所应具备的。由于现有的架构中没有找到所需的功能模块集合，本文提出了一种新的认知架构，用于接近AGI能力的智能系统。作为架构框架中的关键解决方案之一，本文提出了一种通用的知识表示方法，可以将各种非形式化、部分和完全形式化的知识表示方法结合在一个知识库中，如自然语言文本、图像、音频和视频记录、图形、算法、数据库、神经网络、知识图、本体、框架、实质-属性-关系模型、推理系统、谓词演算模型、概念模型等。为了组合和结构化各个片段

    The article identified 42 cognitive architectures for creating general artificial intelligence (AGI) and proposed a set of interrelated functional blocks that an agent approaching AGI in its capabilities should possess. Since the required set of blocks is not found in any of the existing architectures, the article proposes a new cognitive architecture for intelligent systems approaching AGI in their capabilities. As one of the key solutions within the framework of the architecture, a universal method of knowledge representation is proposed, which allows combining various non-formalized, partially and fully formalized methods of knowledge representation in a single knowledge base, such as texts in natural languages, images, audio and video recordings, graphs, algorithms, databases, neural networks, knowledge graphs, ontologies, frames, essence-property-relation models, production systems, predicate calculus models, conceptual models, and others. To combine and structure various fragment
    
[^55]: WISE: 基于地下扩展的全波形变分推断方法

    WISE: full-Waveform variational Inference via Subsurface Extensions. (arXiv:2401.06230v1 [physics.geo-ph])

    [http://arxiv.org/abs/2401.06230](http://arxiv.org/abs/2401.06230)

    WISE是一种通过地下扩展进行全波形变分推断的方法，能够准确量化偏移速度模型对成像的影响，并且不依赖于准确的初始速度模型。

    

    我们引入了一种利用变分推断和条件归一化流来量化偏移速度模型及其对成像的影响的全波形反演概率技术。我们的方法将生成式人工智能与物理知识驱动的共享图像收集相结合，减少了对准确的初始速度模型的依赖。考虑到的案例研究证明了该方法在根据数据生成偏移速度模型方面的有效性。这些模型被用来量化后续成像过程中的振幅和定位效应。

    We introduce a probabilistic technique for full-waveform inversion, employing variational inference and conditional normalizing flows to quantify uncertainty in migration-velocity models and its impact on imaging. Our approach integrates generative artificial intelligence with physics-informed common-image gathers, reducing reliance on accurate initial velocity models. Considered case studies demonstrate its efficacy producing realizations of migration-velocity models conditioned by the data. These models are used to quantify amplitude and positioning effects during subsequent imaging.
    
[^56]: 学习无监督的语义文档表示以进行细粒度的基于方面的情感分析

    Learning Unsupervised Semantic Document Representation for Fine-grained Aspect-based Sentiment Analysis. (arXiv:2401.06210v1 [cs.LG])

    [http://arxiv.org/abs/2401.06210](http://arxiv.org/abs/2401.06210)

    这篇论文研究了学习无监督的语义文档表示以进行细粒度的基于方面的情感分析。通过克服现有方法的困难，实验证明该模型在各个任务上的性能优于最先进方法。

    

    文档表示是机器理解中许多自然语言处理任务的核心。以无监督方式学习的一般表示保留了通用性，可用于各种应用。在实践中，情感分析（SA）是一个挑战性的任务，被认为与语义密切相关，并经常用于评估一般表示。现有的无监督文档表示学习方法可以分为两类：序列方法（显式考虑单词的顺序）和非序列方法（不显式考虑顺序）。然而，它们都有各自的缺点。在本文中，我们提出了一个模型，克服了这两类方法遇到的困难。实验证明，我们的模型在流行的SA数据集和细粒度的基于方面的SA上优于现有的最先进方法。

    Document representation is the core of many NLP tasks on machine understanding. A general representation learned in an unsupervised manner reserves generality and can be used for various applications. In practice, sentiment analysis (SA) has been a challenging task that is regarded to be deeply semantic-related and is often used to assess general representations. Existing methods on unsupervised document representation learning can be separated into two families: sequential ones, which explicitly take the ordering of words into consideration, and non-sequential ones, which do not explicitly do so. However, both of them suffer from their own weaknesses. In this paper, we propose a model that overcomes difficulties encountered by both families of methods. Experiments show that our model outperforms state-of-the-art methods on popular SA datasets and a fine-grained aspect-based SA by a large margin.
    
[^57]: 对LLM在飞行轨迹重建分析中潜力的探索性评估

    An Exploratory Assessment of LLM's Potential Toward Flight Trajectory Reconstruction Analysis. (arXiv:2401.06204v1 [cs.LG])

    [http://arxiv.org/abs/2401.06204](http://arxiv.org/abs/2401.06204)

    本研究探索了大型语言模型（LLMs）在航空领域中重建飞行轨迹的潜力，并通过使用ADS-B数据对LLaMA 2模型进行实证研究，发现LLMs在过滤噪音和估计飞行轨迹方面表现出色。然而，研究也揭示了处理较长数据序列的挑战，该挑战可能源于LLM模型的标记长度限制。这些研究结果强调了LLMs在航空和交通领域广泛应用的潜力。

    

    大型语言模型（LLMs）在航空领域，特别是在重建飞行轨迹方面具有革命性潜力。本文研究了这一潜力，基于LLMs在处理序列数据和解读复杂数据结构方面的优势。利用预先训练的开源LLM模型LLaMA 2，本研究着重于使用自动相关监视广播（ADS-B）数据重建飞行轨迹，该数据具有真实世界场景中的不规则性。研究结果表明该模型能够有效地过滤噪音，并估计出线性和曲线型飞行轨迹。然而，分析同时也揭示了在处理较长数据序列方面存在的挑战，这可能归因于LLM模型的标记长度限制。研究的发现突显了LLMs在飞行轨迹重建中的潜力，并为其在航空和交通领域的广泛应用开辟了新的途径。

    Large Language Models (LLMs) hold transformative potential in aviation, particularly in reconstructing flight trajectories. This paper investigates this potential, grounded in the notion that LLMs excel at processing sequential data and deciphering complex data structures. Utilizing the LLaMA 2 model, a pre-trained open-source LLM, the study focuses on reconstructing flight trajectories using Automatic Dependent Surveillance-Broadcast (ADS-B) data with irregularities inherent in real-world scenarios. The findings demonstrate the model's proficiency in filtering noise and estimating both linear and curved flight trajectories. However, the analysis also reveals challenges in managing longer data sequences, which may be attributed to the token length limitations of LLM models. The study's insights underscore the promise of LLMs in flight trajectory reconstruction and open new avenues for their broader application across the aviation and transportation sectors.
    
[^58]: xTrimoPGLM: 统一的百亿规模预训练蛋白质语言模型，用于解析蛋白质的语言

    xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein. (arXiv:2401.06199v1 [q-bio.QM])

    [http://arxiv.org/abs/2401.06199](http://arxiv.org/abs/2401.06199)

    xTrimoPGLM是一个统一的100亿规模预训练蛋白质语言模型，能够同时处理蛋白质理解和生成任务，通过创新的预训练框架和大规模的参数训练，显著优于其他先进模型，在18个蛋白理解基准测试中取得了成功，并能够实现对蛋白质结构的原子分辨率观察。

    

    蛋白质语言模型在学习蛋白质序列中的生物信息方面显示出显著的成功。然而，大多数现有模型局限于自编码或自回归的预训练目标，这使得它们在处理蛋白质理解和生成任务时很难同时进行。我们提出了一个统一的蛋白质语言模型，xTrimoPGLM，通过创新的预训练框架同时解决这两类任务。我们的关键技术贡献是探索这两类目标的兼容性和联合优化的潜力，从而导致了一个以前所未有的规模，使用1000亿参数和1万亿训练标记来训练xTrimoPGLM的策略。我们广泛的实验证明，1）xTrimoPGLM在四个类别的18个蛋白理解基准测试中明显优于其他先进基线。该模型还有助于对蛋白质结构进行原子分辨率的观察，从而实现了对蛋白质结构的理解和生成。

    Protein language models have shown remarkable success in learning biological information from protein sequences. However, most existing models are limited by either autoencoding or autoregressive pre-training objectives, which makes them struggle to handle protein understanding and generation tasks concurrently. We propose a unified protein language model, xTrimoPGLM, to address these two types of tasks simultaneously through an innovative pre-training framework. Our key technical contribution is an exploration of the compatibility and the potential for joint optimization of the two types of objectives, which has led to a strategy for training xTrimoPGLM at an unprecedented scale of 100 billion parameters and 1 trillion training tokens. Our extensive experiments reveal that 1) xTrimoPGLM significantly outperforms other advanced baselines in 18 protein understanding benchmarks across four categories. The model also facilitates an atomic-resolution view of protein structures, leading to 
    
[^59]: NeuSpin：基于自旋电子学的可靠边缘神经形态系统设计用于绿色人工智能

    NeuSpin: Design of a Reliable Edge Neuromorphic System Based on Spintronics for Green AI. (arXiv:2401.06195v1 [cs.ET])

    [http://arxiv.org/abs/2401.06195](http://arxiv.org/abs/2401.06195)

    NeuSpin是一个全栈硬件和软件共同设计的项目，旨在解决使用自旋电子学技术在边缘进行绿色人工智能实现的挑战。通过计算内存一体化，NeuSPIN可以实现超低功耗、高处理能力以及可靠性的要求，从而促进物联网和智能可穿戴设备的发展。

    

    物联网（IoT）和个性化医疗智能可穿戴设备将需要存储和处理越来越多的数据。这些设备的关键要求是超低功耗、高处理能力、低成本的自主性，以及可靠性和准确性，以实现边缘绿色人工智能。人工智能（AI）模型，特别是贝叶斯神经网络（BayNNs），对资源的需求高，并且由于内存墙问题，面临着传统计算架构的挑战。利用新型可变电阻记忆的计算内存一体化（CIM）提供了一种解决方案，通过将内存块和计算单元结合起来，提高了效率，降低了功耗。然而，在CIM硬件上实现BayNNs，特别是使用自旋电子学技术，由于可变性和制造缺陷而存在技术挑战。NeuSPIN项目旨在通过全栈硬件和软件共同设计来应对这些挑战，开发新颖的算法。

    Internet of Things (IoT) and smart wearable devices for personalized healthcare will require storing and computing ever-increasing amounts of data. The key requirements for these devices are ultra-low-power, high-processing capabilities, autonomy at low cost, as well as reliability and accuracy to enable Green AI at the edge. Artificial Intelligence (AI) models, especially Bayesian Neural Networks (BayNNs) are resource-intensive and face challenges with traditional computing architectures due to the memory wall problem. Computing-in-Memory (CIM) with emerging resistive memories offers a solution by combining memory blocks and computing units for higher efficiency and lower power consumption. However, implementing BayNNs on CIM hardware, particularly with spintronic technologies, presents technical challenges due to variability and manufacturing defects. The NeuSPIN project aims to address these challenges through full-stack hardware and software co-design, developing novel algorithmic 
    
[^60]: CrisisKAN: 知识注入和可解释的多模态注意力网络用于危机事件分类

    CrisisKAN: Knowledge-infused and Explainable Multimodal Attention Network for Crisis Event Classification. (arXiv:2401.06194v1 [cs.LG])

    [http://arxiv.org/abs/2401.06194](http://arxiv.org/abs/2401.06194)

    CrisisKAN是一种知识注入和可解释的多模态注意力网络，用于危机事件分类。它通过结合图像、文本和维基百科的外部知识来弥合图像和文本模态之间的语义差距，并解释模型的结果，以建立在高风险情况下的信任。

    

    广泛使用社交媒体已成为实时信息（如图像、文本或二者兼有）识别各种事件的新兴来源。尽管图像和文本的事件分类迅速发展，但最先进的模型仍然难以弥合由于不一致的编码导致的图像和文本模态之间的语义差距。此外，模型的黑匣子特性无法解释模型的结果，无法在灾难、大流行等高风险情况下建立信任。此外，社交媒体帖子的字数限制可能会对特定事件引入偏见。为了解决这些问题，我们提出了CrisisKAN，一种新颖的知识注入和可解释的多模态注意力网络，将图像和文本与维基百科的外部知识相结合，用于分类危机事件。为了丰富对文本信息的上下文特定理解，我们使用了提出的维基百科知识提取方法。

    Pervasive use of social media has become the emerging source for real-time information (like images, text, or both) to identify various events. Despite the rapid growth of image and text-based event classification, the state-of-the-art (SOTA) models find it challenging to bridge the semantic gap between features of image and text modalities due to inconsistent encoding. Also, the black-box nature of models fails to explain the model's outcomes for building trust in high-stakes situations such as disasters, pandemic. Additionally, the word limit imposed on social media posts can potentially introduce bias towards specific events. To address these issues, we proposed CrisisKAN, a novel Knowledge-infused and Explainable Multimodal Attention Network that entails images and texts in conjunction with external knowledge from Wikipedia to classify crisis events. To enrich the context-specific understanding of textual information, we integrated Wikipedia knowledge using proposed wiki extraction
    
[^61]: 使用Bark、mBART和经过微调的XLSR Wav2Vec2的端到端印地语到英语语音转换

    End to end Hindi to English speech conversion using Bark, mBART and a finetuned XLSR Wav2Vec2. (arXiv:2401.06183v1 [eess.AS])

    [http://arxiv.org/abs/2401.06183](http://arxiv.org/abs/2401.06183)

    本论文提出了一个端到端的语音转换框架，用于印地语到英语的转换，采用了Bark、mBART和经过微调的XLSR Wav2Vec2等先进技术，为跨语言交流提供了统一而无缝的解决方案。

    

    长期以来，语音一直是有效沟通和连接的障碍，在我们日益互联的世界中仍然具有挑战性。这篇研究论文介绍了一种针对印地语到英语翻译量身定制的端到端语音转换框架，最终实现了英文音频的合成。通过整合XLSR Wav2Vec2用于自动语音识别（ASR），mBART用于神经机器翻译（NMT），以及一个文本到语音（TTS）合成组件等尖端技术，该框架提供了一种统一而无缝的跨语言交流方式。我们深入研究了每个组件的复杂细节，阐明了它们的个别贡献，并探讨了相互之间的协同作用，从而实现从印地语口语到合成英文音频的流畅过渡。

    Speech has long been a barrier to effective communication and connection, persisting as a challenge in our increasingly interconnected world. This research paper introduces a transformative solution to this persistent obstacle an end-to-end speech conversion framework tailored for Hindi-to-English translation, culminating in the synthesis of English audio. By integrating cutting-edge technologies such as XLSR Wav2Vec2 for automatic speech recognition (ASR), mBART for neural machine translation (NMT), and a Text-to-Speech (TTS) synthesis component, this framework offers a unified and seamless approach to cross-lingual communication. We delve into the intricate details of each component, elucidating their individual contributions and exploring the synergies that enable a fluid transition from spoken Hindi to synthesized English audio.
    
[^62]: AI艺术是盗窃：劳动、提取和剥削，或者说关于随机波洛克的危险

    AI Art is Theft: Labour, Extraction, and Exploitation, Or, On the Dangers of Stochastic Pollocks. (arXiv:2401.06178v1 [cs.CY])

    [http://arxiv.org/abs/2401.06178](http://arxiv.org/abs/2401.06178)

    这篇论文分析、证实和批评了商业领导者使用AI图像生成取代人类艺术劳动力的行为，并指出这种AI图像生成涉及一种不道德的劳动性盗窃，这对许多其他的AI应用也具有影响。

    

    自从DALL-E、Midjourney和稳定扩散等应用推出以来，生成式人工智能作为创作艺术的工具一直备受争议。一些人提出了对这些技术的长期担忧，认为它们预示着即将到来的完全自动化的未来，但更紧迫的是生成式人工智能对当前创作劳动力的影响。商业领导者已经开始用AI生成的图像取代人类艺术劳动力。作家的工会发起了一场抗议运动，认为AI图像生成是一种盗窃行为。本文对这些论点进行了分析、证实和批评，并得出结论认为，AI图像生成涉及一种不道德的劳动性盗窃。如果正确的话，许多其他的AI应用也依赖于这种盗窃行为。

    Since the launch of applications such as DALL-E, Midjourney, and Stable Diffusion, generative artificial intelligence has been controversial as a tool for creating artwork. While some have presented longtermist worries about these technologies as harbingers of fully automated futures to come, more pressing is the impact of generative AI on creative labour in the present. Already, business leaders have begun replacing human artistic labour with AI-generated images. In response, the artistic community has launched a protest movement, which argues that AI image generation is a kind of theft. This paper analyzes, substantiates, and critiques these arguments, concluding that AI image generators involve an unethical kind of labour theft. If correct, many other AI applications also rely upon theft.
    
[^63]: GOODAT: 面向测试时图形的领域外检测

    GOODAT: Towards Test-time Graph Out-of-Distribution Detection. (arXiv:2401.06176v1 [cs.LG])

    [http://arxiv.org/abs/2401.06176](http://arxiv.org/abs/2401.06176)

    GOODAT是一种用于检测测试时图形领域外样本的方法，具有数据驱动、无监督和即插即用的特点。

    

    图神经网络(GNNs)在建模不同领域的图数据中具有广泛的应用。虽然GNN在测试数据与训练数据符合同一分布(即分布内,ID)的场景中表现出色，但当面对来自不熟悉分布(即领域外,OOD)的样本时，它们通常会出现错误的预测。为了用GNNs识别和拒绝OOD样本，最近的研究探索了图OOD检测，通常集中在训练特定模型或在经过良好训练的GNN之上修改数据。尽管这些方法是有效的，但它们需要重型的训练资源和成本，因为它们需要在训练数据上优化基于GNN的模型。此外，它们对修改原始GNN和访问训练数据的依赖进一步限制了它们的普适性。为此，本文介绍了一种在测试时检测图形的方法(GOODAT)，这是一种面向数据、无监督和即插即用的解决方案。

    Graph neural networks (GNNs) have found widespread application in modeling graph data across diverse domains. While GNNs excel in scenarios where the testing data shares the distribution of their training counterparts (in distribution, ID), they often exhibit incorrect predictions when confronted with samples from an unfamiliar distribution (out-of-distribution, OOD). To identify and reject OOD samples with GNNs, recent studies have explored graph OOD detection, often focusing on training a specific model or modifying the data on top of a well-trained GNN. Despite their effectiveness, these methods come with heavy training resources and costs, as they need to optimize the GNN-based models on training data. Moreover, their reliance on modifying the original GNNs and accessing training data further restricts their universality. To this end, this paper introduces a method to detect Graph Out-of-Distribution At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play solu
    
[^64]: MTAD: 多元时间序列异常检测的工具和基准

    MTAD: Tools and Benchmarks for Multivariate Time Series Anomaly Detection. (arXiv:2401.06175v1 [cs.SE])

    [http://arxiv.org/abs/2401.06175](http://arxiv.org/abs/2401.06175)

    这篇论文提出了一套综合的多元时间序列异常检测工具和基准，解决了现有方法缺乏严格比较和重新实现困难的问题。

    

    关键绩效指标是确保许多软件系统可靠性和稳定性的重要时间序列指标。它们忠实记录运行时状态，便于理解异常系统行为，并为工程师提供定位根本原因的有用线索。然而，现代软件系统的规模和复杂性前所未有，导致KPI数量激增。因此，许多传统的KPI异常检测方法变得不实用，这促使了学术界和工业界机器学习解决方案的快速发展。然而，目前缺乏对这些KPI异常检测方法的严格比较，并且重新实现需要付出相当大的工作量。此外，我们观察到不同的研究采用独立的评估过程和不同的指标。其中一些可能无法充分展示模型的能力，有些则产生了进展的错觉。为了更好地理解这个问题，我们提出了一套综合的多元时间序列异常检测工具和基准。

    Key Performance Indicators (KPIs) are essential time-series metrics for ensuring the reliability and stability of many software systems. They faithfully record runtime states to facilitate the understanding of anomalous system behaviors and provide informative clues for engineers to pinpoint the root causes. The unprecedented scale and complexity of modern software systems, however, make the volume of KPIs explode. Consequently, many traditional methods of KPI anomaly detection become impractical, which serves as a catalyst for the fast development of machine learning-based solutions in both academia and industry. However, there is currently a lack of rigorous comparison among these KPI anomaly detection methods, and re-implementation demands a non-trivial effort. Moreover, we observe that different works adopt independent evaluation processes with different metrics. Some of them may not fully reveal the capability of a model and some are creating an illusion of progress. To better und
    
[^65]: 《利用人工智能促进非洲可持续农业发展：机遇、挑战和影响》

    Harnessing Artificial Intelligence for Sustainable Agricultural Development in Africa: Opportunities, Challenges, and Impact. (arXiv:2401.06171v1 [cs.CY])

    [http://arxiv.org/abs/2401.06171](http://arxiv.org/abs/2401.06171)

    本文探索了人工智能在非洲农业可持续发展中的潜力，并研究了精准农业、作物监测和气候适应性实践等机会，并分析了技术基础设施、数据获取和技能缺口等挑战。此外，本文还讨论了人工智能对小农户、供应链和包容性增长的影响，并提出了负责任的人工智能整合方法。

    

    本文探讨人工智能在非洲各地可持续农业发展中的变革潜力。通过研究人工智能在农业中的应用机会、挑战和影响，本文深入探索了人工智能在农业领域的动态发展。文章分析了精准农业、作物监测和气候适应性实践等方面的机会，同时探讨了与技术基础设施、数据获取和技能缺口相关的挑战。此外，本文还分析了人工智能对小农户、供应链和包容性增长的影响。同时，论文还讨论了伦理考虑和政策影响，提供了人工智能整合的负责任方法。通过提供细致的认识，本文对于利用人工智能促进非洲农业的可持续发展的讨论做出了贡献。

    This paper explores the transformative potential of artificial intelligence (AI) in the context of sustainable agricultural development across diverse regions in Africa. Delving into opportunities, challenges, and impact, the study navigates through the dynamic landscape of AI applications in agriculture. Opportunities such as precision farming, crop monitoring, and climate-resilient practices are examined, alongside challenges related to technological infrastructure, data accessibility, and skill gaps. The article analyzes the impact of AI on smallholder farmers, supply chains, and inclusive growth. Ethical considerations and policy implications are also discussed, offering insights into responsible AI integration. By providing a nuanced understanding, this paper contributes to the ongoing discourse on leveraging AI for fostering sustainability in African agriculture.
    
[^66]: 关于博弈论最优扑克的调查

    A Survey on Game Theory Optimal Poker. (arXiv:2401.06168v1 [cs.GT])

    [http://arxiv.org/abs/2401.06168](http://arxiv.org/abs/2401.06168)

    本文调查了博弈论最优扑克，比较了博弈论最优扑克和剥削扑克的差异，讨论了扑克机器人所采用的特定策略，探讨了2人对多人游戏的不同以及与玩更多玩家时出现的局限性，同时还讨论了机器学习和理论方法在开发获胜策略中的作用。

    

    扑克是一种不完全信息游戏，与国际象棋、四连棋等完全信息游戏不同。虽然许多完全信息游戏已经被解决，但迄今为止还没有解决任何非平凡的不完全信息游戏。这使得扑克成为人工智能研究的极好试验平台。本文首先比较了博弈论最优扑克和剥削扑克。其次，我们讨论了抽象技术、投注模型和成功的扑克机器人（如Tartanian[1]和Pluribus[6]）所采用的特定策略的复杂性。第三，我们还探讨了2人对多人游戏的差异以及与玩更多玩家时出现的局限性。最后，本文讨论了机器学习和理论方法在开发获胜策略中的作用，并提出了这一快速发展领域的未来发展方向。

    Poker is in the family of imperfect information games unlike other games such as chess, connect four, etc which are perfect information game instead. While many perfect information games have been solved, no non-trivial imperfect information game has been solved to date. This makes poker a great test bed for Artificial Intelligence research. In this paper we firstly compare Game theory optimal poker to Exploitative poker. Secondly, we discuss the intricacies of abstraction techniques, betting models, and specific strategies employed by successful poker bots like Tartanian[1] and Pluribus[6]. Thirdly, we also explore 2-player vs multi-player games and the limitations that come when playing with more players. Finally, this paper discusses the role of machine learning and theoretical approaches in developing winning strategies and suggests future directions for this rapidly evolving field.
    
[^67]: 使用基于CLIP的图像到文本转换增强多模态理解能力

    Enhancing Multimodal Understanding with CLIP-Based Image-to-Text Transformation. (arXiv:2401.06167v1 [cs.CV])

    [http://arxiv.org/abs/2401.06167](http://arxiv.org/abs/2401.06167)

    本文提出了一种集成方法，利用对比式语言图像预训练模型的能力，来实现图像到文本的转换，进而增强多模态理解能力。

    

    在计算机视觉和自然语言处理领域中，将输入图像转换为相应的文本解释的过程是一项关键且复杂的工作。在本文中，我们提出了一种创新的集成方法，利用对比式语言图像预训练模型的能力。

    The process of transforming input images into corresponding textual explanations stands as a crucial and complex endeavor within the domains of computer vision and natural language processing. In this paper, we propose an innovative ensemble approach that harnesses the capabilities of Contrastive Language-Image Pretraining models.
    
[^68]: 一种用于基于地点的算法巡逻管理的去偏技术

    A debiasing technique for place-based algorithmic patrol management. (arXiv:2401.06162v1 [cs.CY])

    [http://arxiv.org/abs/2401.06162](http://arxiv.org/abs/2401.06162)

    这项工作介绍了一种用于基于地点的算法巡逻管理系统的去偏技术，该技术能够有效消除种族偏见特征并保留高准确性的模型。

    

    最近几年，数据驱动的警务工作发生了革命。随之而来的是对历史数据中偏见如何影响算法决策的审查。在这项探索性工作中，我们介绍了一种用于基于地点的算法巡逻管理系统的去偏技术。我们展示了这种技术在保留模型高准确性的同时有效消除了种族偏见特征。最后，我们提供了这项工作揭示的在公平和数据驱动的警务领域中潜在的未来研究的一长串清单。

    In recent years, there has been a revolution in data-driven policing. With that has come scrutiny on how bias in historical data affects algorithmic decision making. In this exploratory work, we introduce a debiasing technique for place-based algorithmic patrol management systems. We show that the technique efficiently eliminates racially biased features while retaining high accuracy in the models. Finally, we provide a lengthy list of potential future research in the realm of fairness and data-driven policing which this work uncovered.
    
[^69]: 人类为中心的可信自动决策系统

    Trustworthy human-centric based Automated Decision-Making Systems. (arXiv:2401.06161v1 [cs.CY])

    [http://arxiv.org/abs/2401.06161](http://arxiv.org/abs/2401.06161)

    该论文讨论了自动决策系统在当代社会和未来环境中的潜在风险，以及在部署ADS时的规范、透明度和伦理行为的必要性。

    

    自动决策系统（ADS）在各个领域、活动和职业中已普遍使用，以提高性能。然而，这种广泛采用引入了潜在风险，包括ADS的滥用。当ADS在不必要的情况下使用，或者忽视了重要要求、条件和条款，导致意外后果时，可能会出现这种滥用。本研究论文对数字化、数字转型以及在当代社会和未来环境中利用ADS所涉及的含义、区别和伦理考虑进行了深入研究。重点强调了在部署ADS时的规范、透明度和伦理行为的必要性。

    Automated Decision-Making Systems (ADS) have become pervasive across various fields, activities, and occupations, to enhance performance. However, this widespread adoption introduces potential risks, including the misuse of ADS. Such misuse may manifest when ADS is employed in situations where it is unnecessary or when essential requirements, conditions, and terms are overlooked, leading to unintended consequences. This research paper presents a thorough examination of the implications, distinctions, and ethical considerations associated with digitalization, digital transformation, and the utilization of ADS in contemporary society and future contexts. Emphasis is placed on the imperative need for regulation, transparency, and ethical conduct in the deployment of ADS.
    
[^70]: 未来教育的防风险设计：使用大型语言模型模拟口试的原型

    Future-proofing Education: A Prototype for Simulating Oral Examinations Using Large Language Models. (arXiv:2401.06160v1 [cs.CY])

    [http://arxiv.org/abs/2401.06160](http://arxiv.org/abs/2401.06160)

    使用大型语言模型模拟口试的原型在未来教育中具有潜力，可以实现教育民主化、包容多样的学生群体以及提高教学质量和效率。

    

    本研究探讨了在高等教育中使用大型语言模型（LLMs）的影响，重点是使用原型进行自动口试模拟。描述了原型的设计考虑，并通过一组选择的教育者和学生对系统进行了评估。讨论了技术和教学观察。原型在模拟口试、提供个性化反馈和简化教育工作负担方面证明了其有效性。原型的有望结果显示了LLMs在民主教育、包容不同学生群体以及提高教学质量和效率方面的潜力。

    This study explores the impact of Large Language Models (LLMs) in higher education, focusing on an automated oral examination simulation using a prototype. The design considerations of the prototype are described, and the system is evaluated with a select group of educators and students. Technical and pedagogical observations are discussed. The prototype proved to be effective in simulating oral exams, providing personalized feedback, and streamlining educators' workloads. The promising results of the prototype show the potential for LLMs in democratizing education, inclusion of diverse student populations, and improvement of teaching quality and efficiency.
    
[^71]: UDEEP: 基于边缘的水下信号龙虾和塑料检测的计算机视觉

    UDEEP: Edge-based Computer Vision for In-Situ Underwater Crayfish and Plastic Detection. (arXiv:2401.06157v1 [cs.CV])

    [http://arxiv.org/abs/2401.06157](http://arxiv.org/abs/2401.06157)

    UDEEP是一个基于边缘计算机视觉的平台，可以帮助解决入侵信号龙虾和废弃塑料对水生生态系统的挑战。

    

    入侵的信号龙虾对生态系统造成了不利影响。它们传播了对英国唯一的本地白爪龙虾致命的真菌型龙虾瘟疫病(Aphanomyces astaci)。入侵的信号龙虾广泛挖掘洞穴，破坏栖息地，侵蚀河岸并对水质产生不利影响，同时竞争本地物种的资源并导致本地种群下降。此外，污染也使白爪龙虾更加容易受到损害，其种群在英国某些地区下降超过90％，使其极易濒临灭绝。为了保护水生生态系统，解决入侵物种和废弃塑料对英国河流生态系统的挑战至关重要。UDEEP平台可以通过实时分类信号龙虾和塑料碎片，充当环境监测的关键角色。

    Invasive signal crayfish have a detrimental impact on ecosystems. They spread the fungal-type crayfish plague disease (Aphanomyces astaci) that is lethal to the native white clawed crayfish, the only native crayfish species in Britain. Invasive signal crayfish extensively burrow, causing habitat destruction, erosion of river banks and adverse changes in water quality, while also competing with native species for resources and leading to declines in native populations. Moreover, pollution exacerbates the vulnerability of White-clawed crayfish, with their populations declining by over 90% in certain English counties, making them highly susceptible to extinction. To safeguard aquatic ecosystems, it is imperative to address the challenges posed by invasive species and discarded plastics in the United Kingdom's river ecosystem's. The UDEEP platform can play a crucial role in environmental monitoring by performing on-the-fly classification of Signal crayfish and plastic debris while leveragi
    
[^72]: 基于k-聚类Big Bang-Big Crunch算法的多模态优化

    Multi-Modal Optimization with k-Cluster Big Bang-Big Crunch Algorithm. (arXiv:2401.06153v1 [cs.NE])

    [http://arxiv.org/abs/2401.06153](http://arxiv.org/abs/2401.06153)

    这篇论文提出了一种基于聚类的多模态优化Big Bang-Big Crunch算法的版本，称为k-BBBC。该算法能够高效地解决多模态优化问题，并在测试中表现出良好的性能。

    

    多模态优化经常在工程问题中遇到，特别是在寻找不同和替代解决方案时。进化算法通过种群的概念、探索/开发功能和适合并行计算等特点，能够高效地解决多模态优化问题。本文介绍了一种基于聚类的多模态优化Big Bang-Big Crunch算法的版本，称为k-BBBC。该算法能够保证整个种群的完全收敛，对于特定问题平均检索到99\%的局部最优解。此外，我们引入了两种后处理方法，用于(i)在一组检索到的解决方案中确定局部最优解，以及(ii)定量测量正确检索到的最优解数量与预期数量之间的比率（即成功率）。我们的结果表明，k-BBBC在具有大量最优解（测试了379个最优解）和高维度的问题上表现良好。

    Multi-modal optimization is often encountered in engineering problems, especially when different and alternative solutions are sought. Evolutionary algorithms can efficiently tackle multi-modal optimization thanks to their features such as the concept of population, exploration/exploitation, and being suitable for parallel computation.  This paper introduces a multi-modal optimization version of the Big Bang-Big Crunch algorithm based on clustering, namely, k-BBBC. This algorithm guarantees a complete convergence of the entire population, retrieving on average the 99\% of local optima for a specific problem. Additionally, we introduce two post-processing methods to (i) identify the local optima in a set of retrieved solutions (i.e., a population), and (ii) quantify the number of correctly retrieved optima against the expected ones (i.e., success rate).  Our results show that k-BBBC performs well even with problems having a large number of optima (tested on 379 optima) and high dimensio
    
[^73]: 趋向于使用SE(3)-离散扩散生成核酸和蛋白质复合物的联合序列-结构生成

    Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein Complexes with SE(3)-Discrete Diffusion. (arXiv:2401.06151v1 [q-bio.BM])

    [http://arxiv.org/abs/2401.06151](http://arxiv.org/abs/2401.06151)

    MMDiff是一个联合生成核酸和蛋白质复合物序列和结构的生成模型，具有重要的大分子设计应用价值，并通过验证实例展示了其有效性。

    

    大分子的生成模型对蛋白质工程的工业和生物医学研究具有丰富且重要的影响。然而，现有的方法目前仅限于独立或联合地对蛋白质结构或序列进行建模，而不考虑蛋白质和其他大分子之间常见的相互作用。在本研究中，我们引入了MMDiff，一个使用联合SE(3)-离散扩散噪声设计核酸和蛋白质复合物的序列和结构的生成模型。这样的模型对于结构基础转录因子设计和非编码RNA序列设计等新兴的大分子设计领域具有重要意义。我们通过在本研究中引入的严格新的大分子复合物生成设计基准来展示了MMDiff的实用性。我们的结果表明，MMDiff能够成功生成微型RNA和单链DNA分子。

    Generative models of macromolecules carry abundant and impactful implications for industrial and biomedical efforts in protein engineering. However, existing methods are currently limited to modeling protein structures or sequences, independently or jointly, without regard to the interactions that commonly occur between proteins and other macromolecules. In this work, we introduce MMDiff, a generative model that jointly designs sequences and structures of nucleic acid and protein complexes, independently or in complex, using joint SE(3)-discrete diffusion noise. Such a model has important implications for emerging areas of macromolecular design including structure-based transcription factor design and design of noncoding RNA sequences. We demonstrate the utility of MMDiff through a rigorous new design benchmark for macromolecular complex generation that we introduce in this work. Our results demonstrate that MMDiff is able to successfully generate micro-RNA and single-stranded DNA mole
    
[^74]: D-STGCNT:一种基于transformer的密集时空图卷积GRU网络用于评估患者身体康复

    D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on transformer for assessment of patient physical rehabilitation. (arXiv:2401.06150v1 [eess.IV])

    [http://arxiv.org/abs/2401.06150](http://arxiv.org/abs/2401.06150)

    D-STGCNT是一种新的模型，结合了STGCN和transformer的架构，用于自动评估患者身体康复锻炼。它通过将骨架数据视为图形，并检测关键关节，在处理时空数据方面具有高效性。该模型通过密集连接和GRU机制来处理大型3D骨架输入，有效建立时空动态模型。transformer的注意力机制对于评估康复锻炼非常有用。

    

    本文解决了自动评估无临床监督情况下患者进行身体康复锻炼的挑战。其目标是提供质量评分以确保正确执行和获得期望结果。为实现这一目标，引入了一种新的基于图结构的模型，Dense Spatio-Temporal Graph Conv-GRU Network with Transformer。该模型结合了改进的STGCN和transformer架构，用于高效处理时空数据。其关键思想是将骨架数据视为图形，并检测每个康复锻炼中起主要作用的关节。密集连接和GRU机制用于快速处理大型3D骨架输入并有效建模时空动态。transformer编码器的注意机制侧重于输入序列的相关部分，使其在评估康复锻炼方面非常有用。

    This paper tackles the challenge of automatically assessing physical rehabilitation exercises for patients who perform the exercises without clinician supervision. The objective is to provide a quality score to ensure correct performance and achieve desired results. To achieve this goal, a new graph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with Transformer, is introduced. This model combines a modified version of STGCN and transformer architectures for efficient handling of spatio-temporal data. The key idea is to consider skeleton data respecting its non-linear structure as a graph and detecting joints playing the main role in each rehabilitation exercise. Dense connections and GRU mechanisms are used to rapidly process large 3D skeleton inputs and effectively model temporal dynamics. The transformer encoder's attention mechanism focuses on relevant parts of the input sequence, making it useful for evaluating rehabilitation exercises. The evaluation of our propose
    
[^75]: 用于数字和计算病理学的人工智能

    Artificial Intelligence for Digital and Computational Pathology. (arXiv:2401.06148v1 [eess.IV])

    [http://arxiv.org/abs/2401.06148](http://arxiv.org/abs/2401.06148)

    本综述总结了计算病理学在自动化临床实践和发现新生物标记物方面的最新进展，并提供了未来展望，该领域会涉及更广泛的临床和研究任务，以及不断增多的临床数据模态。

    

    数字化组织切片的进展以及人工智能中深度学习等快速进展推动了计算病理学领域的发展。该领域具有巨大的潜力，可以自动化临床诊断，预测患者的预后和治疗反应，并从组织图像中发现新的形态学生物标记物。一些基于人工智能的系统现在获得批准用于辅助临床诊断；然而，技术障碍仍然存在，限制了其作为研究工具的广泛临床应用和整合。本综述总结了计算病理学在全切片图像中预测临床终点方面的最新方法学进展，并强调这些发展如何实现临床实践的自动化和新生物标记物的发现。然后，我们提供未来展望，随着该领域扩展到更广泛的临床和研究任务，以及日益多样化的临床数据模态。

    Advances in digitizing tissue slides and the fast-paced progress in artificial intelligence, including deep learning, have boosted the field of computational pathology. This field holds tremendous potential to automate clinical diagnosis, predict patient prognosis and response to therapy, and discover new morphological biomarkers from tissue images. Some of these artificial intelligence-based systems are now getting approved to assist clinical diagnosis; however, technical barriers remain for their widespread clinical adoption and integration as a research tool. This Review consolidates recent methodological advances in computational pathology for predicting clinical end points in whole-slide images and highlights how these developments enable the automation of clinical practice and the discovery of new biomarkers. We then provide future perspectives as the field expands into a broader range of clinical and research tasks with increasingly diverse modalities of clinical data.
    
[^76]: 重新定义侦察：利用无人机，360度摄像头和神经辐射场弥合差距

    Redefining Recon: Bridging Gaps with UAVs, 360 degree Cameras, and Neural Radiance Fields. (arXiv:2401.06143v1 [cs.CV])

    [http://arxiv.org/abs/2401.06143](http://arxiv.org/abs/2401.06143)

    本文介绍了一种创新的方法，利用小型无人机配备360度摄像头和神经辐射场（NeRFs）技术，在城市环境中生成精确的3D模型，特别适用于经历严重破坏的场景。我们的方法在火灾场景下经过测试，证明了NeRFs的高效性。

    

    在灾害情况下的数字态势感知领域中，准确的数字表示，如3D模型，发挥着不可或缺的作用。为了确保救援队的安全，通常会部署机器人平台来生成这些模型。在本文中，我们介绍了一种创新的方法，将小于30厘米的紧凑型无人机配备360度摄像头的能力与神经辐射场（NeRFs）的进展相结合。NeRF是一种专门的神经网络，可以利用2D图像推断任何场景的3D表示，然后根据需要从各个角度合成它。这种方法特别适用于经历了巨大破坏的城市环境，其中建筑物的结构完整性已经受损到无法进入的程度-通常在地震后和严重火灾后观察到。我们通过最近的火灾场景测试了我们的方法，强调了NeRFs的有效性，即使在严重破坏的环境下也是如此。

    In the realm of digital situational awareness during disaster situations, accurate digital representations, like 3D models, play an indispensable role. To ensure the safety of rescue teams, robotic platforms are often deployed to generate these models. In this paper, we introduce an innovative approach that synergizes the capabilities of compact Unmaned Arial Vehicles (UAVs), smaller than 30 cm, equipped with 360 degree cameras and the advances of Neural Radiance Fields (NeRFs). A NeRF, a specialized neural network, can deduce a 3D representation of any scene using 2D images and then synthesize it from various angles upon request. This method is especially tailored for urban environments which have experienced significant destruction, where the structural integrity of buildings is compromised to the point of barring entry-commonly observed post-earthquakes and after severe fires. We have tested our approach through recent post-fire scenario, underlining the efficacy of NeRFs even in ch
    
[^77]: QuasiNet: 一种具有可训练乘积层的神经网络

    QuasiNet: a neural network with trainable product layers. (arXiv:2401.06137v1 [cs.NE])

    [http://arxiv.org/abs/2401.06137](http://arxiv.org/abs/2401.06137)

    QuasiNet是一种新的神经网络模型，通过可训练的乘积层解决了小规模隐藏神经元下传统神经网络在难问题上的有限收敛问题，具有更高的成功率。

    

    传统神经网络在类似XOR或奇偶校验等难题的小规模隐藏神经元下只能实现有限的收敛。为了提高神经网络在这些问题上的成功率，我们提出了一种新的神经网络模型，受现有具有所谓乘积神经元和由经典误差反向传播推导出的学习规则启发，优雅地解决了互斥情况的问题。与现有的具有预设且不可调节权重的乘积神经元不同，我们的神经元乘积层也能够学习。我们测试了该模型，并将其成功率与传统的多层感知机在前述问题和其他难题（如两个螺旋）中进行了比较。我们的结果表明，我们的模型比传统的多层感知机更成功，并且在许多任务和应用中具有潜力。

    Classical neural networks achieve only limited convergence in hard problems such as XOR or parity when the number of hidden neurons is small. With the motivation to improve the success rate of neural networks in these problems, we propose a new neural network model inspired by existing neural network models with so called product neurons and a learning rule derived from classical error backpropagation, which elegantly solves the problem of mutually exclusive situations. Unlike existing product neurons, which have weights that are preset and not adaptable, our product layers of neurons also do learn. We tested the model and compared its success rate to a classical multilayer perceptron in the aforementioned problems as well as in other hard problems such as the two spirals. Our results indicate that our model is clearly more successful than the classical MLP and has the potential to be used in many tasks and applications.
    
[^78]: Patchscope: 一个统一的框架，用于检查语言模型的隐藏表示

    Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models. (arXiv:2401.06102v1 [cs.CL])

    [http://arxiv.org/abs/2401.06102](http://arxiv.org/abs/2401.06102)

    本论文提出了一个叫做Patchscope的框架，用于检查语言模型的隐藏表示。该框架不仅统一了先前的检查技术，还解决了其中一些问题，并且还开辟了新的可能性。

    

    检查大型语言模型（LLM）的隐藏表示中编码的信息可以解释模型的行为并验证其与人类价值观的一致性。鉴于LLM生成人类可理解文本的能力，我们建议利用模型本身以自然语言解释其内部表示。我们引入了一个称为Patchscopes的框架，并展示了如何使用它来回答关于LLM计算的各种研究问题。我们表明，先前基于将表示投影到词汇空间和干预LLM计算的可解释性方法，可以看作是该框架的特殊实例。此外，通过Patchscope可以弥补优势，如检查早期层失败或表达能力不足。除了统一先前的检查技术，Patchscopes还开辟了新的可能性，例如使用更强大的模型来解释较小模型的表示。

    Inspecting the information encoded in hidden representations of large language models (LLMs) can explain models' behavior and verify their alignment with human values. Given the capabilities of LLMs in generating human-understandable text, we propose leveraging the model itself to explain its internal representations in natural language. We introduce a framework called Patchscopes and show how it can be used to answer a wide range of research questions about an LLM's computation. We show that prior interpretability methods based on projecting representations into the vocabulary space and intervening on the LLM computation, can be viewed as special instances of this framework. Moreover, several of their shortcomings such as failure in inspecting early layers or lack of expressivity can be mitigated by a Patchscope. Beyond unifying prior inspection techniques, Patchscopes also opens up new possibilities such as using a more capable model to explain the representations of a smaller model,
    
[^79]: RLHF在大型语言模型中的秘密 Part II: 奖励建模

    Secrets of RLHF in Large Language Models Part II: Reward Modeling. (arXiv:2401.06080v1 [cs.AI])

    [http://arxiv.org/abs/2401.06080](http://arxiv.org/abs/2401.06080)

    本报告探讨了在 RLHF 中解决奖励建模的两个挑战，通过使用多个奖励模型的投票机制来测量数据中偏好的强度，并解决在特定分布数据上训练奖励模型难以推广的问题。

    

    从人类反馈中进行强化学习（RLHF）已成为将语言模型与人类价值和意图对齐的关键技术，使模型能够产生更有帮助且无害的回应。奖励模型被训练为人类偏好的代理，以驱动强化学习优化。然而，在实际应用中，奖励模型面临以下挑战：（1）数据集中不正确和模糊的偏好对可能妨碍奖励模型准确捕捉人类意图。（2）在特定分布的数据上训练的奖励模型往往难以推广到分布之外的示例，并且不适用于迭代RLHF训练。本研究尝试解决这两个问题。从数据角度出发，我们提出一种方法来测量数据中偏好的强度，基于多个奖励模型的投票机制。实验结果...

    Reinforcement Learning from Human Feedback (RLHF) has become a crucial technology for aligning language models with human values and intentions, enabling models to produce more helpful and harmless responses. Reward models are trained as proxies for human preferences to drive reinforcement learning optimization. While reward models are often considered central to achieving high performance, they face the following challenges in practical applications: (1) Incorrect and ambiguous preference pairs in the dataset may hinder the reward model from accurately capturing human intent. (2) Reward models trained on data from a specific distribution often struggle to generalize to examples outside that distribution and are not suitable for iterative RLHF training.  In this report, we attempt to address these two issues. (1) From a data perspective, we propose a method to measure the strength of preferences within the data, based on a voting mechanism of multiple reward models. Experimental result
    
[^80]: 在内窥镜手术中深度估计的手术DINO：基于基础模型的适配器学习

    Surgical-DINO: Adapter Learning of Foundation Model for Depth Estimation in Endoscopic Surgery. (arXiv:2401.06013v1 [cs.CV])

    [http://arxiv.org/abs/2401.06013](http://arxiv.org/abs/2401.06013)

    本研究提出了一种基于基础模型的适配器学习方法，针对内窥镜手术中的深度估计问题进行了改进。通过在DINO模型中构建LoRA层，并将其与手术场景的特征结合起来，实现了手术特定的深度估计。实验结果表明，该方法在内窥镜手术中取得了良好的性能。

    

    目的：在机器人手术中进行深度估计对于三维重建、手术导航和增强现实可视化至关重要。尽管基础模型在许多视觉任务中表现出色，包括深度估计（如DINOv2），但最近的研究观察到其在医学和手术特定应用中的局限性。本研究提出了一种手术深度估计的低秩适配（LoRA）基础模型。方法：我们设计了一种基于基础模型的深度估计方法，称为Surgical-DINO，这是DINOv2在内窥镜手术中深度估计中的低秩适配。我们在DINO中构建了LoRA层，并将其整合到DINO中，以适应手术特定的领域知识，而不是传统的微调方法。在训练过程中，我们冻结了DINO的图像编码器，该编码器表现出优秀的视觉表示能力，只优化了LoRA层和深度解码器，以整合手术场景的特征。结果：我们的模型是ex...

    Purpose: Depth estimation in robotic surgery is vital in 3D reconstruction, surgical navigation and augmented reality visualization. Although the foundation model exhibits outstanding performance in many vision tasks, including depth estimation (e.g., DINOv2), recent works observed its limitations in medical and surgical domain-specific applications. This work presents a low-ranked adaptation (LoRA) of the foundation model for surgical depth estimation. Methods: We design a foundation model-based depth estimation method, referred to as Surgical-DINO, a low-rank adaptation of the DINOv2 for depth estimation in endoscopic surgery. We build LoRA layers and integrate them into DINO to adapt with surgery-specific domain knowledge instead of conventional fine-tuning. During training, we freeze the DINO image encoder, which shows excellent visual representation capacity, and only optimize the LoRA layers and depth decoder to integrate features from the surgical scene. Results: Our model is ex
    
[^81]: 大型语言模型中的通用漏洞：上下文学习后门攻击

    Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v1 [cs.CL])

    [http://arxiv.org/abs/2401.05949](http://arxiv.org/abs/2401.05949)

    本研究发现上下文学习范式在大型语言模型中存在漏洞，攻击者可以通过污染示范上下文来操控模型行为，而无需进行微调。这项研究设计了一种名为ICLAttack的后门攻击方法，可以通过污染示范样本和提示来使模型按照预定义的意图行事。

    

    上下文学习是一种在预训练和微调之间弥合差距的范式，在几个自然语言处理任务中展现了高效性，特别是在少样本设置中。与传统的微调方法不同，上下文学习能够适应未见过的任务而无需更新任何参数。尽管被广泛应用，上下文学习仍然容易受到恶意攻击。本研究提出了对这一范式的安全性问题的关切。我们的研究表明，攻击者可以通过污染示范上下文来操控大型语言模型的行为，而无需对模型进行微调。具体来说，我们设计了一种新的后门攻击方法，命名为ICLAttack，针对基于上下文学习的大型语言模型。我们的方法包括两种类型的攻击：污染示范样本和污染提示，可以使模型按照预定义的意图行事。ICLAttack不需要额外的微调。

    In-context learning, a paradigm bridging the gap between pre-training and fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in few-shot settings. Unlike traditional fine-tuning methods, in-context learning adapts pre-trained models to unseen tasks without updating any parameters. Despite being widely applied, in-context learning is vulnerable to malicious attacks. In this work, we raise security concerns regarding this paradigm. Our studies demonstrate that an attacker can manipulate the behavior of large language models by poisoning the demonstration context, without the need for fine-tuning the model. Specifically, we have designed a new backdoor attack method, named ICLAttack, to target large language models based on in-context learning. Our method encompasses two types of attacks: poisoning demonstration examples and poisoning prompts, which can make models behave in accordance with predefined intentions. ICLAttack does not require additional fine-tuning 
    
[^82]: 卧底特工：训练骗人的LLM以通过安全训练

    Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training. (arXiv:2401.05566v1 [cs.CR])

    [http://arxiv.org/abs/2401.05566](http://arxiv.org/abs/2401.05566)

    该论文研究了在大型语言模型中训练并保持持久的欺骗性行为，这种行为无法被当前的安全训练技术移除。

    

    人类有能力进行战略性的欺骗行为：在大多数情况下表现出有益的行为，但在有机会的时候却表现出截然不同的行为以追求其他目标。如果一个AI系统学会了这样的欺骗策略，是否能够通过当前最先进的安全训练技术检测并移除它？为了研究这个问题，我们构建了大型语言模型（LLM）中欺骗行为的概念验证样例。例如，我们训练模型，在提示语句中将年份设为2023时编写安全代码，但在年份设为2024时插入有漏洞的代码。我们发现，这种暗门行为可以被持续保留，无法通过标准的安全训练技术（包括监督微调、强化学习和对抗性训练）移除。暗门行为在最大的模型和训练成产生思维链的模型中最为持久。

    Humans are capable of strategically deceptive behavior: behaving helpfully in most situations, but then behaving very differently in order to pursue alternative objectives when given the opportunity. If an AI system learned such a deceptive strategy, could we detect it and remove it using current state-of-the-art safety training techniques? To study this question, we construct proof-of-concept examples of deceptive behavior in large language models (LLMs). For example, we train models that write secure code when the prompt states that the year is 2023, but insert exploitable code when the stated year is 2024. We find that such backdoored behavior can be made persistent, so that it is not removed by standard safety training techniques, including supervised fine-tuning, reinforcement learning, and adversarial training (eliciting unsafe behavior and then training to remove it). The backdoored behavior is most persistent in the largest models and in models trained to produce chain-of-thoug
    
[^83]: 功能图模型：结构实现离线数据驱动优化

    Functional Graphical Models: Structure Enables Offline Data-Driven Optimization. (arXiv:2401.05442v1 [cs.LG])

    [http://arxiv.org/abs/2401.05442](http://arxiv.org/abs/2401.05442)

    功能图模型（FGMs）通过结构实现了样本高效的数据驱动优化。

    

    虽然机器学习模型通常是为了解决预测问题而训练的，但我们经常希望将它们用于优化问题。例如，给定一组蛋白质及其对应的荧光水平的数据集，我们可能希望为具有最高荧光的新蛋白质进行优化。这种数据驱动的优化（DDO）面临着一系列挑战，超出了标准预测问题中的挑战，因为我们需要成功预测在训练集中没有见过的优于最佳设计的新设计的性能的模型。从理论上讲，甚至不清楚现有方法什么时候甚至能比简单地选择数据集中最佳设计的朴素方法执行得更好。在本文中，我们研究了如何通过结构实现高效的数据驱动优化。为了形式化结构的概念，我们引入了功能图模型（FGMs）并从理论上展示了它们如何通过分解实现基于数据的优化。

    While machine learning models are typically trained to solve prediction problems, we might often want to use them for optimization problems. For example, given a dataset of proteins and their corresponding fluorescence levels, we might want to optimize for a new protein with the highest possible fluorescence. This kind of data-driven optimization (DDO) presents a range of challenges beyond those in standard prediction problems, since we need models that successfully predict the performance of new designs that are better than the best designs seen in the training set. It is not clear theoretically when existing approaches can even perform better than the naive approach that simply selects the best design in the dataset. In this paper, we study how structure can enable sample-efficient data-driven optimization. To formalize the notion of structure, we introduce functional graphical models (FGMs) and show theoretically how they can provide for principled data-driven optimization by decomp
    
[^84]: 可穿戴应用中的表示学习：在缺失数据情况下的探索

    Representation Learning for Wearable-Based Applications in the Case of Missing Data. (arXiv:2401.05437v1 [eess.SP])

    [http://arxiv.org/abs/2401.05437](http://arxiv.org/abs/2401.05437)

    本论文研究了可穿戴应用中表示学习的问题，特别是在缺失数据情况下。作者通过比较Transformer模型和统计方法的性能，发现Transformer模型在变化频繁的信号的缺失数据填充方面表现优秀。此研究为基于掩码的自监督学习任务的设计和开发提供了洞察。

    

    可穿戴设备持续收集传感器数据并用于推断个体的行为，如睡眠、体力活动和情绪。尽管在这个领域有很大的兴趣和进展，但由于数据质量低和数据注释有限，建模真实环境中的多模式传感器数据仍然具有挑战性。本研究探讨了用于填充缺失可穿戴数据的表示学习，并将其与最先进的统计方法进行了比较。我们使用10个生理和行为信号的变化率不同的掩码比率，研究了Transformer模型在缺失数据填充上的性能。结果显示，Transformer模型在变化频繁的信号的缺失数据填充方面优于基准模型，但对于单调信号则不然。我们进一步研究了填充策略和掩码比率对下游分类任务的影响。本研究为基于掩码的自监督学习任务的设计和开发提供了洞察。

    Wearable devices continuously collect sensor data and use it to infer an individual's behavior, such as sleep, physical activity, and emotions. Despite the significant interest and advancements in this field, modeling multimodal sensor data in real-world environments is still challenging due to low data quality and limited data annotations. In this work, we investigate representation learning for imputing missing wearable data and compare it with state-of-the-art statistical approaches. We investigate the performance of the transformer model on 10 physiological and behavioral signals with different masking ratios. Our results show that transformers outperform baselines for missing data imputation of signals that change more frequently, but not for monotonic signals. We further investigate the impact of imputation strategies and masking rations on downstream classification tasks. Our study provides insights for the design and development of masking-based self-supervised learning tasks a
    
[^85]: RoSA: 通过鲁棒适应实现准确的参数高效微调

    RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v1 [cs.CL])

    [http://arxiv.org/abs/2401.04679](http://arxiv.org/abs/2401.04679)

    RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。

    

    我们研究了在大语言模型 (LLMs) 的背景下，能够在有限的计算和内存预算下提供良好准确性的参数高效微调 (PEFT) 方法。我们提出了一种新的PEFT方法，称为RoSA，受鲁棒主成分分析 (PCA) 的启发，它在一组固定的预训练权重上共同训练$\textit{低秩}$和$\textit{高度稀疏}$的组件，以高效近似完全微调（FFT）解决方案的性能。我们展示了RoSA在一系列具有挑战性的生成任务上的性能，例如小学数学和SQL查询生成，这些任务需要进行微调以获得良好性能，我们证明了在相同的参数预算下，RoSA优于LoRA和纯粹的稀疏微调。我们通过稀疏GPU内核为RoSA提供系统支持，以补充训练算法，从而实现内存和计算效率的训练。我们的代码将在https://github.com/IST-DASLab上提供。

    We investigate parameter-efficient fine-tuning (PEFT) methods that can provide good accuracy under limited computational and memory budgets in the context of large language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA) that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components on top of a set of fixed pretrained weights to efficiently approximate the performance of a full-fine-tuning (FFT) solution. Across a series of challenging generative tasks such as grade-school math and SQL query generation, which require fine-tuning for good performance, we show that RoSA outperforms both LoRA and pure sparse fine-tuning, at the same parameter budget. We provide system support for RoSA to complement the training algorithm, specifically in the form of sparse GPU kernels which enable memoryand computationally-efficient training. Our code will be made available at https://github.com/IST-DASLab
    
[^86]: MERA: 俄语LLM综合评估的研究

    MERA: A Comprehensive LLM Evaluation in Russian. (arXiv:2401.04531v1 [cs.CL])

    [http://arxiv.org/abs/2401.04531](http://arxiv.org/abs/2401.04531)

    这项研究提出了MERA，一个多模态俄语基础模型评估指标。该指标包括21个评估任务，涵盖了11个技能领域中生成模型的评估。研究还提出了一种在零样本和少样本固定指令设置下评估FM和LM的方法。

    

    在过去几年中，人工智能研究中最显著的进展之一是基础模型（FM）的发展，其中语言模型（LM）的崛起引人注目。随着模型的规模增大，LM在可衡量的方面展示了提升，并且发展出了新的定性特征。然而，尽管研究人员的关注和LM应用的快速增长，LM的能力、限制和相关风险仍需更好地理解。为了解决这些问题，我们介绍了一种开放的俄语多模态架构评估（MERA）指导基准，用于评估以俄语为导向的基础模型。该基准涵盖了11个技能领域中生成模型的21个评估任务，并被设计为黑盒测试，以确保排除数据泄漏。论文介绍了一种在零样本和少样本固定指令设置下评估FM和LM的方法，并可扩展到其他模态。

    Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). As the models' size increases, LMs demonstrate enhancements in measurable aspects and the development of new qualitative features. However, despite researchers' attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still need to be better understood. To address these issues, we introduce an open Multimodal Evaluation of Russian-language Architectures (MERA), a new instruction benchmark for evaluating foundation models oriented towards the Russian language. The benchmark encompasses 21 evaluation tasks for generative models in 11 skill domains and is designed as a black-box test to ensure the exclusion of data leakage. The paper introduces a methodology to evaluate FMs and LMs in zeroand few-shot fixed instruction settings that can be extended to other modalities. We propose an 
    
[^87]: 多机器人在层次化时间逻辑规范下的任务分配和规划

    Simultaneous Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications. (arXiv:2401.04003v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2401.04003](http://arxiv.org/abs/2401.04003)

    该论文介绍了在多机器人系统中，利用层次化时间逻辑规范实现同时的任务分配和规划的方法。通过引入层次化结构到LTL规范中，该方法更具表达能力。采用基于搜索的方法来综合多机器人系统的计划，将搜索空间拆分为松散相互连接的子空间，以便更高效地进行任务分配和规划。

    

    过去关于机器人规划与时间逻辑规范的研究，特别是线性时间逻辑（LTL），主要是基于针对个体或群体机器人的单一公式。但随着任务复杂性的增加，LTL公式不可避免地变得冗长，使解释和规范生成变得复杂，同时还对规划器的计算能力造成压力。通过利用任务的内在结构，我们引入了一种层次化结构到具有语法和语义需求的LTL规范中，并证明它们比扁平规范更具表达能力。其次，我们采用基于搜索的方法来综合多机器人系统的计划，实现同时的任务分配和规划。搜索空间由松散相互连接的子空间近似表示，每个子空间对应一个LTL规范。搜索主要受限于单个子空间，根据特定条件转移到另一个子空间。

    Past research into robotic planning with temporal logic specifications, notably Linear Temporal Logic (LTL), was largely based on singular formulas for individual or groups of robots. But with increasing task complexity, LTL formulas unavoidably grow lengthy, complicating interpretation and specification generation, and straining the computational capacities of the planners. By leveraging the intrinsic structure of tasks, we introduced a hierarchical structure to LTL specifications with requirements on syntax and semantics, and proved that they are more expressive than their flat counterparts. Second, we employ a search-based approach to synthesize plans for a multi-robot system, accomplishing simultaneous task allocation and planning. The search space is approximated by loosely interconnected sub-spaces, with each sub-space corresponding to one LTL specification. The search is predominantly confined to a single sub-space, transitioning to another sub-space under certain conditions, de
    
[^88]: AI是否能像人类一样具备创造力？

    Can AI Be as Creative as Humans?. (arXiv:2401.01623v1 [cs.AI])

    [http://arxiv.org/abs/2401.01623](http://arxiv.org/abs/2401.01623)

    本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。

    

    创造力是社会进步和创新的基石，但其评估仍然是一个复杂且主观的任务。随着先进的生成型AI模型的出现，能够完成曾经只属于人类创造力的任务，探索AI的创造潜力变得至关重要，以确保其负责任的发展和应用。本文通过引入一个名为“相对创造力”的新概念来解决定义和评估创造力的复杂性。我们不再试图对创造力进行普遍定义，而是将焦点转向AI是否能够与一位假设的人类具备相同的创造能力。这种观点借鉴了图灵测试的思想，并扩展其范围以解决评估创造力中所固有的挑战和主观性。这种方法的转变使得对AI创造力的统计量化评估成为可能，我们将其称为统计创造力。这种方法允许直接比较AI与特定人类的创造能力。

    Creativity serves as a cornerstone for societal progress and innovation, but its assessment remains a complex and often subjective endeavor. With the rise of advanced generative AI models capable of tasks once reserved for human creativity, the study of AI's creative potential becomes imperative for its responsible development and application. This paper addresses the complexities in defining and evaluating creativity by introducing a new concept called Relative Creativity. Instead of trying to define creativity universally, we shift the focus to whether AI can match the creative abilities of a hypothetical human. This perspective draws inspiration from the Turing Test, expanding upon it to address the challenges and subjectivities inherent in evaluating creativity. This methodological shift facilitates a statistically quantifiable evaluation of AI's creativity, which we term Statistical Creativity. This approach allows for direct comparisons of AI's creative abilities with those of sp
    
[^89]: LLaMA超越英语：语言能力转移的实证研究

    LLaMA Beyond English: An Empirical Study on Language Capability Transfer. (arXiv:2401.01055v1 [cs.CL])

    [http://arxiv.org/abs/2401.01055](http://arxiv.org/abs/2401.01055)

    本文提出了LLaMA超越英语：语言能力转移的实证研究。通过对LLaMA进行广泛的实证调查，分析了词汇扩展、进一步预训练和指导调整等关键因素对非英语语言上的能力转移的影响，并通过四个标准化测试基准评估了模型的知识水平和响应质量。

    

    最近，在大型语言模型（LLM）方面取得了重大进展，如ChatGPT，在各种复杂任务中展现出卓越的熟练度。然而，许多主流的LLM（如LLaMA）是基于以英语为主导的语料库进行预训练的，这限制了它们在其他非英语语言中的性能。本文主要研究如何有效地将语言生成和遵循指示的能力转移到非英语语言上。为了回答这个问题，我们基于LLaMA进行了广泛的实证调查，总计耗费了1440个GPU小时。我们分析了诸如词汇扩展、进一步预训练和指导调整等关键因素对转移的影响。为了准确评估模型的知识水平，我们采用了四个广泛使用的标准化测试基准：C-Eval、MMLU、AGI-Eval和GAOKAO-Bench。此外，我们还对模型的响应质量进行了全面评估，考虑了诸如...

    In recent times, substantial advancements have been witnessed in large language models (LLMs), exemplified by ChatGPT, showcasing remarkable proficiency across a range of complex tasks. However, many mainstream LLMs (e.g. LLaMA) are pretrained on English-dominant corpus, which limits their performance in other non-English languages. In this paper, we focus on how to effectively transfer the capabilities of language generation and following instructions to a non-English language. To answer this question, we conduct an extensive empirical investigation based on LLaMA, accumulating over 1440 GPU hours. We analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer. To accurately assess the model's level of knowledge, we employ four widely used standardized testing benchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a comprehensive evaluation of the model's response quality is conducted, considering aspects such as 
    
[^90]: 用于推荐系统评估的综合调查

    A Comprehensive Survey of Evaluation Techniques for Recommendation Systems. (arXiv:2312.16015v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.16015](http://arxiv.org/abs/2312.16015)

    本文介绍了一套综合的推荐系统评估指标，包括相似性指标、候选生成指标、预测指标、排序指标和业务指标。

    

    推荐系统的有效性对于用户在在线平台上的参与和满意度至关重要。随着这些推荐系统越来越影响用户的选择，它们的评估不仅仅局限于技术性能，而变得对于业务成功至关重要。本文通过引入一套全面的指标来解决推荐系统评估的多方面特性，每个指标专门捕捉系统性能的不同方面。我们讨论了以下几个方面的指标：相似性指标：用于量化基于内容的过滤机制的准确性，并评估协同过滤技术的准确性；候选生成指标：用于评估系统有效地识别广泛但相关的项目的能力；预测指标：用于评估预测的用户偏好的准确性；排序指标：用于评估推荐顺序的有效性；业务指标：用于对齐推荐系统的性能。

    The effectiveness of recommendation systems is pivotal to user engagement and satisfaction in online platforms. As these recommendation systems increasingly influence user choices, their evaluation transcends mere technical performance and becomes central to business success. This paper addresses the multifaceted nature of recommendations system evaluation by introducing a comprehensive suite of metrics, each tailored to capture a distinct aspect of system performance. We discuss  * Similarity Metrics: to quantify the precision of content-based filtering mechanisms and assess the accuracy of collaborative filtering techniques.  * Candidate Generation Metrics: to evaluate how effectively the system identifies a broad yet relevant range of items.  * Predictive Metrics: to assess the accuracy of forecasted user preferences.  * Ranking Metrics: to evaluate the effectiveness of the order in which recommendations are presented.  * Business Metrics: to align the performance of the recommendat
    
[^91]: NPHardEval: 通过复杂性类别对大型语言模型的推理能力进行动态基准评估

    NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes. (arXiv:2312.14890v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.14890](http://arxiv.org/abs/2312.14890)

    NPHardEval是一个新的基准，旨在评估大型语言模型在900个算法问题上的推理能力，扩展到NP-Hard复杂性类别。

    

    复杂推理能力是当前大型语言模型的最重要特征之一，它也被用于在复杂决策任务中起到了重要作用。因此，研究大型语言模型的推理能力至关重要：已经建立了许多基准来评估大型语言模型的推理能力。然而，目前的基准在提供大型语言模型推理能力的全面评估方面还不够，同时也容易出现过拟合的风险，因为这些基准是公开可访问且静态的，使得模型有可能根据特定的基准指标调整其响应，从而夸大其性能。针对这些限制，我们的研究引入了一个新的基准，名为NPHardEval。该基准旨在评估大型语言模型在广泛的900个算法问题上的推理能力，涵盖了NP-Hard复杂性类别。

    Complex reasoning ability is one of the most important features of current LLMs, which has also been leveraged to play an integral role in complex decision-making tasks. Therefore, the investigation into the reasoning capabilities of Large Language Models (LLMs) is critical: numerous benchmarks have been established to assess the reasoning abilities of LLMs. However, current benchmarks are inadequate in offering a rigorous evaluation of the full extent of reasoning abilities that LLMs are capable of achieving. They are also prone to the risk of overfitting, as these benchmarks, being publicly accessible and static, allow models to potentially tailor their responses to specific benchmark metrics, thereby inflating their performance. Addressing these limitations, our research introduces a new benchmark, named NPHardEval. This benchmark is designed to evaluate the reasoning abilities of LLMs across a broad spectrum of 900 algorithmic questions, extending up to the NP-Hard complexity class
    
[^92]: 量子极坐标度量学习: 高效经典学习的量子嵌入

    Quantum Polar Metric Learning: Efficient Classically Learned Quantum Embeddings. (arXiv:2312.01655v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2312.01655](http://arxiv.org/abs/2312.01655)

    本论文提出了一种称为量子极坐标度量学习(QPMeL)的方法，通过经典模型学习量子比特的极坐标形式的参数，然后使用浅层PQC和可训练的门层来创建量子态和学习纠缠。与QMeL相比，QPMeL具有更高效的计算性能和可扩展性。

    

    深度度量学习在经典数据范畴中表现出极有潜力的结果，创建了分离明显的特征空间。这个想法也被应用到量子计算机中，通过量子度量学习(QMeL)。QMeL包括两个步骤，首先使用经典模型将数据压缩以适应有限数量的量子比特，然后使用参数化量子电路(PQC)在希尔伯特空间中创建更好的分离效果。然而，在嘈杂中间规模量子(NISQ)设备上，QMeL解决方案导致电路宽度和深度较大，从而限制了可扩展性。我们提出了一种称为量子极坐标度量学习(QPMeL)的方法，它使用经典模型学习一个量子比特的极坐标形式的参数。然后，我们利用仅包含$R_y$和$R_z$门的浅层PQC创建量子态，并利用可训练的$ZZ(\theta)$门层学习纠缠。电路还通过SWAP测试计算保真度，用于我们提出的保真度三元损失函数的训练，用于同时训练经典和量子模型。

    Deep metric learning has recently shown extremely promising results in the classical data domain, creating well-separated feature spaces. This idea was also adapted to quantum computers via Quantum Metric Learning(QMeL). QMeL consists of a 2 step process with a classical model to compress the data to fit into the limited number of qubits, then train a Parameterized Quantum Circuit(PQC) to create better separation in Hilbert Space. However, on Noisy Intermediate Scale Quantum (NISQ) devices. QMeL solutions result in high circuit width and depth, both of which limit scalability. We propose Quantum Polar Metric Learning (QPMeL) that uses a classical model to learn the parameters of the polar form of a qubit. We then utilize a shallow PQC with $R_y$ and $R_z$ gates to create the state and a trainable layer of $ZZ(\theta)$-gates to learn entanglement. The circuit also computes fidelity via a SWAP Test for our proposed Fidelity Triplet Loss function, used to train both classical and quantum 
    
[^93]: 通过联邦迁移学习对基础模型进行接地：一个通用框架

    Grounding Foundation Models through Federated Transfer Learning: A General Framework. (arXiv:2311.17431v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.17431](http://arxiv.org/abs/2311.17431)

    本论文提出了一个通用框架，通过联邦迁移学习将基础模型接地，以解决面临的挑战，如受限的计算资源、数据隐私、模型异构性和模型所有权。这个框架可以帮助释放基础模型的潜力，并在不同行业中产生重要影响。

    

    基于广泛知识和强大的新兴能力编码的Foundation Models（FMs），如GPT-4，在各种自然语言处理和计算机视觉任务中取得了显著成功。通过将FMs适应于特定领域任务或增加领域特定知识来对其进行接地，我们可以充分发挥FMs的潜力。然而，接地FMs面临着多个挑战，主要是受限的计算资源、数据隐私、模型异构性和模型所有权。联邦迁移学习（FTL），即联邦学习和迁移学习的结合，为解决这些挑战提供了有希望的解决方案。近年来，学术界和工业界对通过FTL-FM利用FMs进行接地的需求强烈增长。受到FTL-FM研究的强劲增长和FTL-FM对工业应用的潜在影响的推动，我们提出了一个FTL-FM框架，用于在联邦学习环境中建立FMs的接地问题。

    Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. In recent years, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated lea
    
[^94]: 分布式联邦学习网络中对抗节点部署的影响

    The Impact of Adversarial Node Placement in Decentralized Federated Learning Networks. (arXiv:2311.07946v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2311.07946](http://arxiv.org/abs/2311.07946)

    本文研究了分布式联邦学习网络中对抗节点部署的影响，提出了两种基线策略，并提出了一种新颖的攻击算法，优先考虑对抗的分散性而不是中心性。

    

    随着联邦学习（FL）越来越受欢迎，新的分布式框架也越来越普及。这些框架利用分布式环境的优势，实现了快速和节能的设备间通信。然而，这种增长也加大了对强大安全措施的需求。尽管现有研究已经探讨了FL安全的各个方面，但是对于分布式网络中对抗节点部署的作用仍然较少研究。本文通过分析不同对抗部署策略下分布式FL的性能，来填补这一空白。我们建立了两种基线策略来部署对抗节点：随机部署和基于网络中心性的部署。在此基础上，我们提出了一种新颖的攻击算法，通过最大化对抗节点之间的平均网络距离，优先考虑对抗的分散性而不是中心性。

    As Federated Learning (FL) grows in popularity, new decentralized frameworks are becoming widespread. These frameworks leverage the benefits of decentralized environments to enable fast and energy-efficient inter-device communication. However, this growing popularity also intensifies the need for robust security measures. While existing research has explored various aspects of FL security, the role of adversarial node placement in decentralized networks remains largely unexplored. This paper addresses this gap by analyzing the performance of decentralized FL for various adversarial placement strategies when adversaries can jointly coordinate their placement within a network. We establish two baseline strategies for placing adversarial node: random placement and network centrality-based placement. Building on this foundation, we propose a novel attack algorithm that prioritizes adversarial spread over adversarial centrality by maximizing the average network distance between adversaries.
    
[^95]: 当公平性遇见隐私：通过成员推断攻击探索公平二分类器中的隐私威胁

    When Fairness Meets Privacy: Exploring Privacy Threats in Fair Binary Classifiers through Membership Inference Attacks. (arXiv:2311.03865v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.03865](http://arxiv.org/abs/2311.03865)

    本研究探索了公平二分类器中的隐私威胁，并揭示了针对公平增强模型的基于分数的成员推断攻击的无效性。同时，公平性方法可能导致训练数据中大多数子群体的预测性能下降。

    

    先前的研究开发了针对具有歧视行为的有偏模型的公平方法，以达到公平预测的目标。然而，最近的研究发现这些模型在基于分数的成员推断攻击中存在潜在的漏洞。在这些攻击中，对手可以通过分析模型的预测分数推断出特定数据样本是否在训练过程中使用。然而，我们的调查发现，针对公平增强模型的基于分数的成员推断攻击是无效的。针对这些攻击训练的模型退化为简单的阈值模型，从而导致攻击性能降低。与此同时，我们观察到公平性方法往往导致训练数据中的大多数子群体的预测性能下降。这提高了成功攻击的难度，同时扩大了成员和非成员数据之间的预测差距。

    Previous studies have developed fairness methods for biased models that exhibit discriminatory behaviors towards specific subgroups. While these models have shown promise in achieving fair predictions, recent research has identified their potential vulnerability to score-based membership inference attacks (MIAs). In these attacks, adversaries can infer whether a particular data sample was used during training by analyzing the model's prediction scores. However, our investigations reveal that these score-based MIAs are ineffective when targeting fairness-enhanced models in binary classifications. The attack models trained to launch the MIAs degrade into simplistic threshold models, resulting in lower attack performance. Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon th
    
[^96]: Inner-IoU: 借助辅助边界框更有效的交并比损失

    Inner-IoU: More Effective Intersection over Union Loss with Auxiliary Bounding Box. (arXiv:2311.02877v4 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2311.02877](http://arxiv.org/abs/2311.02877)

    Inner-IoU损失通过使用不同尺度的辅助边界框计算损失，有效加速了边界框回归过程，并提供了更有效的交并比损失方法。

    

    随着检测器的快速发展，边界框回归（BBR）损失函数不断更新和优化。然而，现有的基于IoU的BBR仍然着重于通过添加新的损失项来加速收敛，忽视了IoU损失项本身的局限性。尽管从理论上讲，IoU损失可以有效描述边界框回归的状态，但在实际应用中，它不能根据不同的检测器和检测任务自我调整，并且没有很强的泛化性。基于上述问题，我们首先分析了BBR模型，并得出结论：区分不同的回归样本，并利用不同尺度的辅助边界框计算损失，可以有效加速边界框回归过程。对于高IoU的样本，使用较小的辅助边界框计算损失可以加速收敛，而对于低IoU的样本，则适合使用较大的辅助边界框。然后，我们提出了Inner-IoU损失，它计算...

    With the rapid development of detectors, Bounding Box Regression (BBR) loss function has constantly updated and optimized. However, the existing IoU-based BBR still focus on accelerating convergence by adding new loss terms, ignoring the limitations of IoU loss term itself. Although theoretically IoU loss can effectively describe the state of bounding box regression,in practical applications, it cannot adjust itself according to different detectors and detection tasks, and does not have strong generalization. Based on the above, we first analyzed the BBR model and concluded that distinguishing different regression samples and using different scales of auxiliary bounding boxes to calculate losses can effectively accelerate the bounding box regression process. For high IoU samples, using smaller auxiliary bounding boxes to calculate losses can accelerate convergence, while larger auxiliary bounding boxes are suitable for low IoU samples. Then, we propose Inner-IoU loss, which calculates 
    
[^97]: DiffDub: 使用扩散自动编码器和修复渲染器的通用演员视觉配音

    DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with Diffusion Auto-encoder. (arXiv:2311.01811v1 [cs.CV])

    [http://arxiv.org/abs/2311.01811](http://arxiv.org/abs/2311.01811)

    本论文提出了一种名为DiffDub的基于扩散的配音方法，使用扩散自动编码器和修复渲染器，在保留其他部分的同时无缝填充下半脸区域。通过使用多种策略，解决了语义编码和面部定位的挑战，提高了配音的质量和通用性。

    

    生成高质量且通用的视觉配音仍然是一个挑战。最近的创新看到了一个两阶段的范例的出现，通过中间表示解耦渲染和口型同步过程。然而，先前的方法依赖于粗糙的标记点或局限于单一的说话人，从而限制了它们的性能。在本文中，我们提出了DiffDub：基于扩散的配音方法。首先，我们使用一个修复渲染器和一个蒙版来绘制Diffusion自动编码器，以界定可编辑区域和未更改区域。这样可以在保留其余部分的同时无缝填充下半脸区域。在我们的实验中，我们遇到了一些挑战。首先，语义编码器缺乏鲁棒性，限制了它捕捉高级特征的能力。此外，建模忽略了面部定位，导致帧间口或鼻子抖动。为了解决这些问题，我们采用了多功能的策略，包括...

    Generating high-quality and person-generic visual dubbing remains a challenge. Recent innovation has seen the advent of a two-stage paradigm, decoupling the rendering and lip synchronization process facilitated by intermediate representation as a conduit. Still, previous methodologies rely on rough landmarks or are confined to a single speaker, thus limiting their performance. In this paper, we propose DiffDub: Diffusion-based dubbing. We first craft the Diffusion auto-encoder by an inpainting renderer incorporating a mask to delineate editable zones and unaltered regions. This allows for seamless filling of the lower-face region while preserving the remaining parts. Throughout our experiments, we encountered several challenges. Primarily, the semantic encoder lacks robustness, constricting its ability to capture high-level features. Besides, the modeling ignored facial positioning, causing mouth or nose jitters across frames. To tackle these issues, we employ versatile strategies, inc
    
[^98]: O3D: 基于离线数据的发现与蒸馏方法，用于大规模语言模型在顺序决策中的应用

    O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models. (arXiv:2310.14403v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.14403](http://arxiv.org/abs/2310.14403)

    O3D提出了一种基于离线数据的学习框架，利用大规模数据改进了大规模语言模型在顺序决策问题中的性能，通过自动发现可重复使用的技能，提高了模型的表现

    

    最近对大规模语言模型 (LLMs)的研究取得了令人期待的进展，在解决顺序决策问题方面显示出了良好的性能。通过模仿提示中提供的少量示例（即上下文学习），LLM代理可以与外部环境交互并完成给定任务，而无需额外的训练。然而，这种少量示例往往不足以生成复杂且长期目标任务的高质量解决方案，而有限的上下文长度无法处理更大规模的演示。为此，我们提出了一种利用离线数据的学习框架，以大规模的离线数据（例如人类交互的日志）来改进LLM代理的上下文学习性能。我们通过文本和代码两种方法正式定义了LLM强化策略。然后，我们引入了一种名为O3D的离线数据驱动发现和蒸馏框架，以改善LLM强化策略而无需微调。O3D自动地发现可重复使用的技能

    Recent advancements in large language models (LLMs) have exhibited promising performance in solving sequential decision-making problems. By imitating few-shot examples provided in the prompts (i.e., in-context learning), an LLM agent can interact with an external environment and complete given tasks without additional training. However, such few-shot examples are often insufficient to generate high-quality solutions for complex and long-horizon tasks, while the limited context length cannot consume larger-scale demonstrations. To this end, we propose an offline learning framework that utilizes offline data at scale (e.g, logs of human interactions) to facilitate the in-context learning performance of LLM agents. We formally define LLM-powered policies with both text-based approaches and code-based approaches. We then introduce an Offline Data-driven Discovery and Distillation (O3D) framework to improve LLM-powered policies without finetuning. O3D automatically discovers reusable skills
    
[^99]: 用于有效训练脉冲神经网络的脉冲累积转发方法

    Spike Accumulation Forwarding for Effective Training of Spiking Neural Networks. (arXiv:2310.02772v1 [cs.NE])

    [http://arxiv.org/abs/2310.02772](http://arxiv.org/abs/2310.02772)

    本研究提出了一种名为脉冲累积转发（SAF）的方法，可以有效训练脉冲神经网络（SNNs）。SAF不仅可以减少前向过程中的操作次数，与Spike Representation和OTTT保持一致，而且可以解决SNNs训练中的难题。

    

    本文提出了一种新的脉冲神经网络（SNNs）训练范式，即脉冲累积转发（SAF）。已知SNNs具有高能效但难以训练的特点。许多研究者提出了各种方法来解决这个问题，其中时间上的在线训练（OTTT）是一种在每个时间步骤推断的方法，同时抑制内存成本。然而，为了在GPU上高效计算，OTTT需要进行脉冲序列操作和脉冲序列加权求和操作。此外，OTTT与Spike Representation（另一种训练方法）之间存在关联，但与Spike Representation的理论一致性尚未得到证明。我们的方法可以解决这些问题，即SAF可以在前向过程中减少一半的操作次数，并且可以从理论上证明SAF分别与Spike Representation和OTTT一致。此外，我们还确认了......

    In this article, we propose a new paradigm for training spiking neural networks (SNNs), spike accumulation forwarding (SAF). It is known that SNNs are energy-efficient but difficult to train. Consequently, many researchers have proposed various methods to solve this problem, among which online training through time (OTTT) is a method that allows inferring at each time step while suppressing the memory cost. However, to compute efficiently on GPUs, OTTT requires operations with spike trains and weighted summation of spike trains during forwarding. In addition, OTTT has shown a relationship with the Spike Representation, an alternative training method, though theoretical agreement with Spike Representation has yet to be proven. Our proposed method can solve these problems; namely, SAF can halve the number of operations during the forward process, and it can be theoretically proven that SAF is consistent with the Spike Representation and OTTT, respectively. Furthermore, we confirmed the a
    
[^100]: 机器人化线束装配的计算机视觉技术

    Computer Vision Technology for Robotized Wire Harness Assembly. (arXiv:2309.13745v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2309.13745](http://arxiv.org/abs/2309.13745)

    该论文介绍了机器人化线束装配的计算机视觉技术，以提高装配质量并优化人体工程学和劳动成本。

    

    线束在现代汽车中是电子系统的重要硬件。随着汽车行业向电动化和自动驾驶的转变，越来越多的汽车电子产品负责能量传输和安全关键功能，如操纵、驾驶辅助和安全系统。这种范式转变从安全角度对汽车线束提出更高的要求，并强调了在车辆中的高质量线束装配的重要性。然而，目前大部分线束装配操作仍由熟练工人手动完成，其中一些手动工序从不同的角度存在问题，如质量控制和人体工程学。行业中也持续需求提高竞争力并获得市场份额。因此，希望能在提高人体工程学和优化劳动成本的同时保证装配质量。机器人化装配通过计算机视觉技术实现。

    Wire harnesses are essential hardware for electronic systems in modern automotive vehicles. With a shift in the automotive industry towards electrification and autonomous driving, more and more automotive electronics are responsible for energy transmission and safety-critical functions such as maneuvering, driver assistance, and safety system. This paradigm shift places more demand on automotive wiring harnesses from the safety perspective and stresses the greater importance of high-quality wire harness assembly in vehicles. However, most of the current operations of wire harness assembly are still performed manually by skilled workers, and some of the manual processes are problematic from different perspectives, such as quality control and ergonomics. There is also a persistent demand in the industry to increase competitiveness and gain market share. Hence, assuring assembly quality while improving ergonomics and optimizing labor costs is desired. Robotized assembly, accomplished by r
    
[^101]: 用Whisper模型从自动标注中获得低资源语言的视觉语音识别

    Visual Speech Recognition for Low-resource Languages with Automatic Labels From Whisper Model. (arXiv:2309.08535v1 [cs.CV])

    [http://arxiv.org/abs/2309.08535](http://arxiv.org/abs/2309.08535)

    本文提出了一种利用Whisper模型从未标注的多语言视听数据自动标注的方法，实现了在低资源语言中的视觉语音识别，并证明了该方法可以获得与人工标注相似的性能。

    

    本文提出了一种强大的视觉语音识别(VSR)方法，适用于多种语言，特别是那些标注数据有限的低资源语言。与之前试图通过从其他语言学习的知识来提高目标语言的VSR性能的方法不同，我们探索是否可以在不依赖人工干预的情况下增加不同语言的训练数据量。为此，我们使用了一个Whisper模型，它可以进行语言识别和基于音频的语音识别。它用于过滤所需语言的数据，并从未注释的多语言视听数据池中转录标签。通过比较使用自动标签和人工标注标签训练的VSR模型的性能，我们表明即使不使用人工注释，我们也可以达到与人工注释标签相似的VSR性能。通过自动标注的过程，我们标注了大规模未标注数据。

    This paper proposes a powerful Visual Speech Recognition (VSR) method for multiple languages, especially for low-resource languages that have a limited number of labeled data. Different from previous methods that tried to improve the VSR performance for the target language by using knowledge learned from other languages, we explore whether we can increase the amount of training data itself for the different languages without human intervention. To this end, we employ a Whisper model which can conduct both language identification and audio-based speech recognition. It serves to filter data of the desired languages and transcribe labels from the unannotated, multilingual audio-visual data pool. By comparing the performances of VSR models trained on automatic labels and the human-annotated labels, we show that we can achieve similar VSR performance to that of human-annotated labels even without utilizing human annotations. Through the automated labeling process, we label large-scale unlab
    
[^102]: 自洽性方法用于无限生成问题的改进

    Self-consistency for open-ended generations. (arXiv:2307.06857v1 [cs.AI])

    [http://arxiv.org/abs/2307.06857](http://arxiv.org/abs/2307.06857)

    本论文提出了一种改进大规模预训练语言模型生成输出质量和一致性的新方法，通过扩展自洽性框架的适用性，实现了从一个候选集中恢复最优或接近最优的生成结果，并提出了一种轻量级无参数相似性函数来改进代码生成、自动形式化和摘要任务的效果。

    

    在这篇论文中，我们提出了一种改进大规模预训练语言模型生成输出的质量和一致性的新方法。自洽性已经被证明是一种有效的方法，对于具有固定答案的提示，选择得票最多的答案。我们引入了一个推广的自洽性框架，扩展了其适用性，超越了固定答案问题的范围。通过大量的模拟实验，我们证明了我们的方法能够从候选集中恢复最优或接近最优的生成结果。我们还提出了一种轻量级无参数相似性函数，即使没有访问到标记的概率，也能在代码生成、自动形式化和摘要任务中显著和一致地改进效果。我们的方法几乎没有计算开销，不需要额外的再排序模型或对现有模型的修改。

    In this paper, we present a novel approach for improving the quality and consistency of generated outputs from large-scale pre-trained language models (LLMs). Self-consistency has emerged as an effective approach for prompts with fixed answers, selecting the answer with the highest number of votes. In this paper, we introduce a generalized framework for self-consistency that extends its applicability beyond problems that have fixed-answer answers. Through extensive simulations, we demonstrate that our approach consistently recovers the optimal or near-optimal generation from a set of candidates. We also propose lightweight parameter-free similarity functions that show significant and consistent improvements across code generation, autoformalization, and summarization tasks, even without access to token log probabilities. Our method incurs minimal computational overhead, requiring no auxiliary reranker models or modifications to the existing model.
    
[^103]: milliFlow：用于人体运动感知的毫米波雷达点云场景流估计

    milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing. (arXiv:2306.17010v1 [cs.CV])

    [http://arxiv.org/abs/2306.17010](http://arxiv.org/abs/2306.17010)

    milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。

    

    随着普适计算时代的到来，人体运动感知在智能系统中起着关键作用，用于决策、用户交互和个性化服务。在传统方法中，人体跟踪、姿势估计、手势识别和活动识别等方面进行了大量研究，这些方法主要基于摄像机。然而，摄像机的侵入性特点限制了它们在智能家居应用中的使用。为了解决这个问题，毫米波雷达由于其保护隐私的特点而受到欢迎。在这项工作中，我们提出了一种新颖的深度学习方法milliFlow，用于对毫米波雷达点云进行场景流估计，作为中间层的特征，直接受益于下游的人体运动感知任务。实验结果表明，我们的方法具有优越的性能，平均3D端点误差为4.6cm，明显超过竞争方法。此外，通过结合...

    Approaching the era of ubiquitous computing, human motion sensing plays a crucial role in smart systems for decision making, user interaction, and personalized services. Extensive research has been conducted on human tracking, pose estimation, gesture recognition, and activity recognition, which are predominantly based on cameras in traditional methods. However, the intrusive nature of cameras limits their use in smart home applications. To address this, mmWave radars have gained popularity due to their privacy-friendly features. In this work, we propose \textit{milliFlow}, a novel deep learning method for scene flow estimation as a complementary motion information for mmWave point cloud, serving as an intermediate level of features and directly benefiting downstream human motion sensing tasks. Experimental results demonstrate the superior performance of our method with an average 3D endpoint error of 4.6cm, significantly surpassing the competing approaches. Furthermore, by incorporati
    
[^104]: 异步算法与Cocycles的对齐

    Asynchronous Algorithmic Alignment with Cocycles. (arXiv:2306.15632v1 [cs.LG])

    [http://arxiv.org/abs/2306.15632](http://arxiv.org/abs/2306.15632)

    该论文提出了一种将节点状态更新和消息函数调用分离的数学框架，以实现异步计算，并以此作为基础，进行了异步算法和神经网络的对齐。

    

    最先进的神经算法推理器使用图神经网络（GNN）中的消息传递。但是，典型的GNN在定义和调用消息函数之间模糊了区别，迫使节点在每一层都向其邻居发送消息，同步地进行。然而，当将GNN应用于学习执行动态规划算法时，大多数步骤只有少数几个节点会有有意义的更新要发送。因此，通过在图中发送太多无关的数据，可能导致低效率，而许多中间的GNN步骤必须学习身份函数。在这项工作中，我们明确地分离了节点状态更新和消息函数调用的概念。通过这种分离，我们得到了一个数学表达，可以让我们思考算法和神经网络中的异步计算。

    State-of-the-art neural algorithmic reasoners make use of message passing in graph neural networks (GNNs). But typical GNNs blur the distinction between the definition and invocation of the message function, forcing a node to send messages to its neighbours at every layer, synchronously. When applying GNNs to learn to execute dynamic programming algorithms, however, on most steps only a handful of the nodes would have meaningful updates to send. One, hence, runs the risk of inefficiencies by sending too much irrelevant data across the graph -- with many intermediate GNN steps having to learn identity functions. In this work, we explicitly separate the concepts of node state update and message function invocation. With this separation, we obtain a mathematical formulation that allows us to reason about asynchronous computation in both algorithms and neural networks.
    
[^105]: 采用强化学习技术增强变分量子状态对角化

    Enhancing variational quantum state diagonalization using reinforcement learning techniques. (arXiv:2306.11086v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2306.11086](http://arxiv.org/abs/2306.11086)

    本研究采用强化学习技术，通过新的编码方法来优化量子状态对角化所需的电路深度，从而提高其在近期量子硬件上的应用性能。

    

    变分量子算法的发展对于 NISQ 计算机的应用至关重要。这种算法需要短的量子电路，这种电路更易于在近期硬件上实现，也已经开发出了许多这样的方法。其中一个特别有趣的算法是所谓的变分对角化方法，它是一种重要的算法子例程，可以直接用于处理以量子状态编码的数据。特别地，它可以用于分辨量子态的特征，例如系统的纠缠性质，或者在量子机器学习算法中使用。在本研究中，我们利用强化学习解决在量子状态对角化任务中所需电路非常浅的设计问题。为了实现这一点，我们利用一种新的编码方法，可以利用强化学习方法解决电路深度优化问题。我们证明，我们的方法有可能显著减少所需的电路深度，从而使其更适用于近期量子硬件。

    The development of variational quantum algorithms is crucial for the application of NISQ computers. Such algorithms require short quantum circuits, which are more amenable to implementation on near-term hardware, and many such methods have been developed. One of particular interest is the so-called the variational diagonalization method, which constitutes an important algorithmic subroutine, and it can be used directly for working with data encoded in quantum states. In particular, it can be applied to discern the features of quantum states, such as entanglement properties of a system, or in quantum machine learning algorithms. In this work, we tackle the problem of designing a very shallow quantum circuit, required in the quantum state diagonalization task, by utilizing reinforcement learning. To achieve this, we utilize a novel encoding method that can be used to tackle the problem of circuit depth optimization using a reinforcement learning approach. We demonstrate that our approach
    
[^106]: LabelBench：基于综合框架的标签高效学习基准评估

    LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning. (arXiv:2306.09910v1 [cs.LG])

    [http://arxiv.org/abs/2306.09910](http://arxiv.org/abs/2306.09910)

    本论文介绍了一个新的综合性标签高效学习基准评估框架LabelBench，并通过引入一种新的与半监督学习相结合的主动学习方法的基准测试，证明了在相对较少的标记示例下实现更好的标签效率。

    

    标记数据是现代机器学习应用程序的关键，但获取标记可能很昂贵。为了减缓这一成本，机器学习方法（如迁移学习、半监督学习和主动学习）旨在实现标签高效性：从相对较少的标记示例中实现高预测性能。虽然在实践中获得最佳的标签效率通常需要这些技术的组合，但现有的基准评估框架并没有捕捉到所有这些技术的协同组合。本文通过引入LabelBench解决了这个缺陷，这是一个新的计算效率高的综合性框架，用于联合评估多个标签高效学习技术。作为LabelBench的一个应用，我们引入了一种与半监督学习一起使用的最新主动学习方法的新基准，用于微调预训练的视觉转换器。我们的基准证明了比先前报告的更好的标签效率。

    Labeled data are critical to modern machine learning applications, but obtaining labels can be expensive. To mitigate this cost, machine learning methods, such as transfer learning, semi-supervised learning and active learning, aim to be label-efficient: achieving high predictive performance from relatively few labeled examples. While obtaining the best label-efficiency in practice often requires combinations of these techniques, existing benchmark and evaluation frameworks do not capture a concerted combination of all such techniques. This paper addresses this deficiency by introducing LabelBench, a new computationally-efficient framework for joint evaluation of multiple label-efficient learning techniques. As an application of LabelBench, we introduce a novel benchmark of state-of-the-art active learning methods in combination with semi-supervised learning for fine-tuning pretrained vision transformers. Our benchmark demonstrates better label-efficiencies than previously reported in 
    
[^107]: 通信系统中AI通用性与可扩展性的设计原则

    Design Principles for Generalization and Scalability of AI in Communication Systems. (arXiv:2306.06251v1 [cs.LG])

    [http://arxiv.org/abs/2306.06251](http://arxiv.org/abs/2306.06251)

    本文提出了可持续和可扩展的AI集成通信系统的设计原则，侧重于创建具备通用性的AI算法，通过少量的AI驱动的RAN函数来解决更大的问题，提高系统性能，并简化生命周期管理。

    

    人工智能（AI）已经成为通信系统中解决复杂和动态任务的强大工具，传统的基于规则的算法往往无法胜任。然而，大多数网络任务的AI应用都是针对特定和有限的条件设计和训练的，使得算法无法适应于常见的网络环境、任务和控制任务。本文提出了可持续和可扩展的AI集成通信系统的设计原则，侧重于创建可以在网络环境、意图和控制任务上具备通用性的AI算法。这种方法可以使少量的AI驱动的RAN函数来解决更大的问题，提高系统性能，并简化生命周期管理。为了实现可持续性和自动化，我们引入了一种可扩展的学习架构，该架构支持系统中部署的所有AI应用程序。该架构将中央化学习功能与分布式学习和数据采集功能分离，确保了系统的可扩展性和稳健性。

    Artificial intelligence (AI) has emerged as a powerful tool for addressing complex and dynamic tasks in communication systems, where traditional rule-based algorithms often struggle. However, most AI applications to networking tasks are designed and trained for specific, limited conditions, hindering the algorithms from learning and adapting to generic situations, such as those met across radio access networks (RAN). This paper proposes design principles for sustainable and scalable AI integration in communication systems, focusing on creating AI algorithms that can generalize across network environments, intents, and control tasks. This approach enables a limited number of AI-driven RAN functions to tackle larger problems, improve system performance, and simplify lifecycle management. To achieve sustainability and automation, we introduce a scalable learning architecture that supports all deployed AI applications in the system. This architecture separates centralized learning function
    
[^108]: 一种统一的方法用于最大化连续 DR-submodular 函数

    A Unified Approach for Maximizing Continuous DR-submodular Functions. (arXiv:2305.16671v1 [cs.LG])

    [http://arxiv.org/abs/2305.16671](http://arxiv.org/abs/2305.16671)

    本文提出了一种适用于一系列设置和 Oracle 访问类型的统一方法，用于最大化连续 DR-submodular 函数，为 16 种情况中的 9 种提供了新的/改进的结果，并且针对基于随机函数值的 Oracle 取得了第一个适用于随机 DR-submodular 函数的后悔界限。

    

    本文提出了一种统一的方法，用于最大化连续的 DR-submodular 函数，涵盖了一系列设置和 Oracle 访问类型。我们的方法包括针对单调和非单调函数的 Frank-Wolfe 类型离线算法，具有不同的一般凸集限制。我们考虑了 Oracle 提供函数梯度或仅函数值的访问以及确定性或随机性访问的设置。我们在所有情况下确定了所需的 Oracle 访问数量。我们的方法为 16 个考虑的情况中的 9 个提供了新的/改进的结果，在两个情况下避免了计算上昂贵的投影，而所提出的框架在其余五个情况下与最先进的方法相匹配。值得注意的是，我们针对基于随机函数值的 Oracle 的方法，为随机 DR-submodular 函数提供了第一个带有探险反馈的后悔界限。

    This paper presents a unified approach for maximizing continuous DR-submodular functions that encompasses a range of settings and oracle access types. Our approach includes a Frank-Wolfe type offline algorithm for both monotone and non-monotone functions, with different restrictions on the general convex set. We consider settings where the oracle provides access to either the gradient of the function or only the function value, and where the oracle access is either deterministic or stochastic. We determine the number of required oracle accesses in all cases. Our approach gives new/improved results for nine out of the sixteen considered cases, avoids computationally expensive projections in two cases, with the proposed framework matching performance of state-of-the-art approaches in the remaining five cases. Notably, our approach for the stochastic function value-based oracle enables the first regret bounds with bandit feedback for stochastic DR-submodular functions.
    
[^109]: 双语类比比例

    Bilingual analogical proportions. (arXiv:2305.05614v1 [cs.LO])

    [http://arxiv.org/abs/2305.05614](http://arxiv.org/abs/2305.05614)

    本文在通用代数和一阶逻辑的一般设定下，推广了抽象的类比比例代数逻辑框架，实现了从单语言到双语言框架的转变，扩展了基础框架的适用性。

    

    类比比例是“$a$到$b$就如同$c$到$d$”这种表达式，它处于类比推理的核心，后者又处于人工智能和人类智能的核心。作者最近基于通用代数和一阶逻辑的一般设定，从第一原理开始介绍了一种抽象的类比比例代数逻辑框架。在该框架中，源代数和目标代数具有相同的基础语言。本文的目的是将其单语言框架推广到双语言框架，其中基础语言可能不同。通过在比例证明中使用限定语，我们实现了这一目的。其结果是一个重大的推广，广泛地扩展了基础框架的适用性。从更广泛的意义上说，本文是迈向类比推理数学理论的进一步步骤。

    Analogical proportions are expressions of the form ``$a$ is to $b$ what $c$ is to $d$'' at the core of analogical reasoning which itself is at the core of human and artificial intelligence. The author has recently introduced {\em from first principles} an abstract algebro-logical framework of analogical proportions within the general setting of universal algebra and first-order logic. In that framework, the source and target algebras have the {\em same} underlying language. The purpose of this paper is to generalize his unilingual framework to a bilingual one where the underlying languages may differ. This is achieved by using hedges in justifications of proportions. The outcome is a major generalization vastly extending the applicability of the underlying framework. In a broader sense, this paper is a further step towards a mathematical theory of analogical reasoning.
    
[^110]: TraffNet：学习道路网络数字孪生交通生成因果关系

    TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins. (arXiv:2303.15954v1 [cs.LG])

    [http://arxiv.org/abs/2303.15954](http://arxiv.org/abs/2303.15954)

    TraffNet是一个学习交通量生成原因的深度学习框架，将车辆轨迹数据表示为异构图，利用递归神经网络结构实现了对交通生成原因的预测。

    

    道路网络数字孪生（RNDT）在开发下一代智能交通系统中发挥着关键作用，可以实现更精确的交通规划和控制。为了支持实时决策，RNDT需要一个模型，从在线传感器数据中动态学习交通模式并生成高保真模拟结果。尽管基于图神经网络的当前交通预测技术已经实现了最先进的性能，但是这些技术仅通过挖掘历史交通数据中的相关性来预测未来交通，而忽略了交通生成的原因，例如交通需求和路径选择。因此，它们的性能对于实时决策是不可靠的。为了填补这一差距，我们引入了一个新的深度学习框架称为 TraffNet，该框架从车辆轨迹数据中学习交通量的因果性。首先，我们使用异构图来表示道路网络，使模型能够并入预测所需的其他数据，然后我们提出了一种新颖的递归神经网络结构，从而能够预测交通量的因果联系。

    Road network digital twins (RNDTs) play a critical role in the development of next-generation intelligent transportation systems, enabling more precise traffic planning and control. To support just-in-time (JIT) decision making, RNDTs require a model that dynamically learns the traffic patterns from online sensor data and generates high-fidelity simulation results. Although current traffic prediction techniques based on graph neural networks have achieved state-of-the-art performance, these techniques only predict future traffic by mining correlations in historical traffic data, disregarding the causes of traffic generation, such as traffic demands and route selection. Therefore, their performance is unreliable for JIT decision making. To fill this gap, we introduce a novel deep learning framework called TraffNet that learns the causality of traffic volume from vehicle trajectory data. First, we use a heterogeneous graph to represent the road network, allowing the model to incorporate 
    
[^111]: 主动推理和强化学习：在部分可观测的连续状态和动作空间下的统一推理

    Active Inference and Reinforcement Learning: A unified inference on continuous state and action spaces under partially observability. (arXiv:2212.07946v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07946](http://arxiv.org/abs/2212.07946)

    本论文提出了一种能够在部分可观测的连续状态和动作空间下进行统一推理的框架，通过最小化期望自由能函数指导代理选择动作，以实现最大化奖励的决策制定。

    

    强化学习在完全可观测环境中开发决策制定代理以最大化由外部监督员指定的奖励引起了极大关注。然而，许多现实世界的问题涉及部分观测，形式化为部分可观测的马尔可夫决策过程（POMDP）。以往的研究通过将过去的行动和观测记忆或通过从观测数据中推断环境的真实状态来解决POMDP中的强化学习问题。然而，在连续空间中随时间聚合观测数据变得不可行。此外，基于推理的强化学习方法通常需要许多样本才能表现良好，因为它们仅关注奖励最大化，忽视了推断状态的不确定性。主动推理（AIF）是在POMDP中制定的一种框架，通过最小化一个称为期望自由能（EFE）的函数指导代理选择动作。这提供了最大化奖励（富有开发性）的行为。

    Reinforcement learning (RL) has garnered significant attention for developing decision-making agents that aim to maximize rewards, specified by an external supervisor, within fully observable environments. However, many real-world problems involve partial observations, formulated as partially observable Markov decision processes (POMDPs). Previous studies have tackled RL in POMDPs by either incorporating the memory of past actions and observations or by inferring the true state of the environment from observed data. However, aggregating observed data over time becomes impractical in continuous spaces. Moreover, inference-based RL approaches often require many samples to perform well, as they focus solely on reward maximization and neglect uncertainty in the inferred state. Active inference (AIF) is a framework formulated in POMDPs and directs agents to select actions by minimizing a function called expected free energy (EFE). This supplies reward-maximizing (exploitative) behaviour, as
    
[^112]: NLP中的最新泛化研究：分类和综述

    State-of-the-art generalisation research in NLP: A taxonomy and review. (arXiv:2210.03050v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.03050](http://arxiv.org/abs/2210.03050)

    本文提出了一个用于分类和理解NLP中泛化研究的分类法，对400多篇论文进行了综述和分类，总结了当前泛化研究的现状。

    

    良好的泛化能力是自然语言处理(NLP)的主要目标之一。然而，对于什么是“良好的泛化”以及如何评估它仍不明确，也没有泛化的评估标准。在本文中，我们为解决这两个问题奠定了基础。我们提出了一个用于表征和理解NLP中泛化研究的分类法。该分类法基于对泛化研究的广泛文献综述，包含了五个不同的维度：主要动机、研究的泛化类型、考虑的数据转移类型、数据转移的来源以及转移在建模流程中的位置。我们使用这个分类法对测试泛化的400多篇论文进行了分类，共进行了600多个实验。通过综述的结果，我们提供了一份深入分析，揭示了当前泛化研究的现状。

    The ability to generalise well is one of the primary desiderata of natural language processing (NLP). Yet, what 'good generalisation' entails and how it should be evaluated is not well understood, nor are there any evaluation standards for generalisation. In this paper, we lay the groundwork to address both of these issues. We present a taxonomy for characterising and understanding generalisation research in NLP. Our taxonomy is based on an extensive literature review of generalisation research, and contains five axes along which studies can differ: their main motivation, the type of generalisation they investigate, the type of data shift they consider, the source of this data shift, and the locus of the shift within the modelling pipeline. We use our taxonomy to classify over 400 papers that test generalisation, for a total of more than 600 individual experiments. Considering the results of this review, we present an in-depth analysis that maps out the current state of generalisation 
    
[^113]: 学习音频分类中声谱图的时间分辨率

    Learning Temporal Resolution in Spectrogram for Audio Classification. (arXiv:2210.01719v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.01719](http://arxiv.org/abs/2210.01719)

    本文提出了一种新的方法DiffRes，可以实现音频分类中的可微分时间分辨率建模。给定一个用固定跳步大小计算的声谱图，DiffRes将非重要的时间帧合并，同时保留重要的帧。

    

    音频声谱图是一种广泛用于音频分类的时频表示方法。声谱图的一个关键属性是时间分辨率，该分辨率取决于短时傅里叶变换（STFT）中使用的跳步大小。以前的研究通常假设跳步大小应为常量值（例如10毫秒）。然而，对于不同类型的声音，固定的时间分辨率并不总是最优的。时间分辨率不仅影响分类准确性，还影响计算成本。本文提出了一种新的方法DiffRes，可以实现音频分类中的可微分时间分辨率建模。给定一个用固定跳步大小计算的声谱图，DiffRes将非重要的时间帧合并，同时保留重要的帧。DiffRes作为音频声谱图和分类器之间的“插入”模块，可以与分类任务共同优化。我们在五个音频分类任务上评估了DiffRes，使用mel

    The audio spectrogram is a time-frequency representation that has been widely used for audio classification. One of the key attributes of the audio spectrogram is the temporal resolution, which depends on the hop size used in the Short-Time Fourier Transform (STFT). Previous works generally assume the hop size should be a constant value (e.g., 10 ms). However, a fixed temporal resolution is not always optimal for different types of sound. The temporal resolution affects not only classification accuracy but also computational cost. This paper proposes a novel method, DiffRes, that enables differentiable temporal resolution modeling for audio classification. Given a spectrogram calculated with a fixed hop size, DiffRes merges non-essential time frames while preserving important frames. DiffRes acts as a "drop-in" module between an audio spectrogram and a classifier and can be jointly optimized with the classification task. We evaluate DiffRes on five audio classification tasks, using mel
    

