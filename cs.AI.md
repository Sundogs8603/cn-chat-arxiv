# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Understanding Post-hoc Explainers: The Case of Anchors.](http://arxiv.org/abs/2303.08806) | 本文对Anchors进行了理论分析，这是一种基于规则的可解释性方法，用于解释文本分类器的决策。 |
| [^2] | [Building an Effective Email Spam Classification Model with spaCy.](http://arxiv.org/abs/2303.08792) | 本文介绍了使用spaCy和机器学习算法来检测Gmail中的垃圾邮件，结果显示多层感知器算法在垃圾邮件检测中的准确率达到96％。 |
| [^3] | [PLEX: Making the Most of the Available Data for Robotic Manipulation Pretraining.](http://arxiv.org/abs/2303.08789) | PLEX提出了一种新的机器人操纵预训练方法，利用任务不可知的视觉运动轨迹和大量的任务条件下的物体操作视频，在学习通用的操纵例程的同时，通过视频演示学习如何在这个特征空间中规划各种任务。 |
| [^4] | [Fully neuromorphic vision and control for autonomous drone flight.](http://arxiv.org/abs/2303.08778) | 本文介绍了第一个全神经形态视觉到控制的流程，使无人机具备了执行自主基于视觉的飞行所需的能力，为机器人感知和行动提供了低延迟和能量有效的解决方案。 |
| [^5] | [GPT-4 Technical Report.](http://arxiv.org/abs/2303.08774) | GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。 |
| [^6] | [Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion.](http://arxiv.org/abs/2303.08767) | 本论文提出了一种简单但高效的个性化方法——使用高度个性化文本嵌入来进行图像操作，可以运用于图像的背景、纹理和动作的编辑，不需要多个参考图像或复杂训练，能实现复杂语义图像编辑。 |
| [^7] | [Cascaded Zoom-in Detector for High Resolution Aerial Images.](http://arxiv.org/abs/2303.08747) | 本研究提出了一种基于级联放大的高分辨率航空图像检测器，使用密度裁剪来增强小物体检测，且易于集成到任何检测器中。 |
| [^8] | [DACOS-A Manually Annotated Dataset of Code Smells.](http://arxiv.org/abs/2303.08729) | DACOS是一个手动注释的包含三种不同粒度的代码异味（多面抽象、复杂方法和长参数列表）的数据集，用于作为机器学习检测代码异味的训练和基准测试。 |
| [^9] | [Artificial Influence: An Analysis Of AI-Driven Persuasion.](http://arxiv.org/abs/2303.08721) | 本文探讨了AI驱动的说服未来的不确定性，包括移动说服力平衡的方式、定制化的说服、虚假信息的带动以及改变人类自身言论的方式。我们警告存在负面影响，并呼吁加强对其开发和使用的监管。 |
| [^10] | [Bi-directional Distribution Alignment for Transductive Zero-Shot Learning.](http://arxiv.org/abs/2303.08698) | 本文提出了一种 Bi-VAEGAN 模型，通过双向分布对齐、L_2 范数特征归一化和更复杂的先验估计方法，大大改善了跨域零样本学习中的分布偏移问题。 |
| [^11] | [Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization.](http://arxiv.org/abs/2303.08697) | Mirror 是一个由大型语言模型支持的平台，它提供了一个直观的自然语言接口，可以将问题转化为 SQL，并自动生成可执行的 SQL 命令。用户可以预览和编辑 SQL 以保证查询的准确性，还可以获得数据摘要和可视化。它适用于各种程度的数据分析人员和非技术专业人员。 |
| [^12] | [Panoptic One-Click Segmentation: Applied to Agricultural Data.](http://arxiv.org/abs/2303.08689) | 本研究提出了一种全景式一键分割方法，允许从点击输入中以高效准确的方式产生伪标签，用于训练实例分割模型，从而大大减少了标记工作和成本。 |
| [^13] | [Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video.](http://arxiv.org/abs/2303.08670) | 本论文提出了基于人脸视频的强制对齐技术，补充了使用音频强制对齐技术存在的缺陷，但由于视觉语音识别技术性能较低且文本到视频的翻译不可靠，开发可靠的视觉强制对齐技术具有挑战性。 |
| [^14] | [Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer.](http://arxiv.org/abs/2303.08622) | 本文提出了一种适用于文本引导图像风格迁移中的零样本对比损失方法，可以在不需要额外训练的情况下生成具有相同语义内容的图像。 |
| [^15] | [Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model.](http://arxiv.org/abs/2303.08613) | 本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。 |
| [^16] | [On the Calibration and Uncertainty with P\'{o}lya-Gamma Augmentation for Dialog Retrieval Models.](http://arxiv.org/abs/2303.08606) | 本文提出了一种PG-DRR框架，通过加入高斯过程层来提高对话响应检索模型的校准性和不确定性估计，可以在保持性能不变的情况下实现最低的校准误差。 |
| [^17] | [Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval.](http://arxiv.org/abs/2303.08599) | 本文提出了一个高斯过程下的不确定性校准框架GPF-BERT用于基于BERT的对话搜索，实现了高质量的神经排名器，相较于基本校准方法具有更低的经验校准误差和更高的检索性能，在时间上具有8倍的加速效果。 |
| [^18] | [Sensitivity-Aware Visual Parameter-Efficient Tuning.](http://arxiv.org/abs/2303.08566) | 本文提出了敏感度感知的视觉参数低效调整（SPT）方案，可以自适应地将可训练参数分配到任务特定的重要位置，以提高表示能力，适应预训练视觉模型到下游任务。 |
| [^19] | [Cognitive Semantic Communication Systems Driven by Knowledge Graph: Principle, Implementation, and Performance Evaluation.](http://arxiv.org/abs/2303.08546) | 本文提出了两种认知语义通信框架，利用知识图谱提出了一个可解释的语义信息检测算法和一种有效的语义纠错算法，并对预训练模型进行微调。性能评估结果表明，所提出的系统优于现有语义通信框架。 |
| [^20] | [Bayesian Learning for the Robust Verification of Autonomous Robots.](http://arxiv.org/abs/2303.08476) | 本文提出了一种新框架，利用贝叶斯学习方法对验证机器人系统的先验知识和观测数据进行处理，以计算其期望的事件发生率范围，进而进行强健验证。该框架所用方法可处理常规事件和罕见情况，能处理真实系统内在的不确定性。 |
| [^21] | [Who's in Charge? Roles and Responsibilities of Decision-Making Components in Conversational Robots.](http://arxiv.org/abs/2303.08470) | 讨论模块化与端到端架构的优缺点，认为模块化架构在与人类用户协作执行复杂任务的对话机器人中是首选。 |
| [^22] | [The Benefits of Mixup for Feature Learning.](http://arxiv.org/abs/2303.08433) | 本论文介绍了数据增强方法Mixup对于特征学习的益处。混合训练可以有效地从混合数据中学习罕见特征，相比之下，标准训练可能会漏掉这些罕见特征。 |
| [^23] | [Implicit Ray-Transformers for Multi-view Remote Sensing Image Segmentation.](http://arxiv.org/abs/2303.08401) | 本文提出了一种基于Implicit Ray-Transformers的多视角遥感图像分割方法，借助神经场和Ray Transformer，有效处理稀疏标注情况下的遥感场景，实现准确且视角一致的语义分割。 |
| [^24] | [A Triplet-loss Dilated Residual Network for High-Resolution Representation Learning in Image Retrieval.](http://arxiv.org/abs/2303.08398) | 本文介绍了一种可训练参数较少、使用扩张残差神经网络和三元组损失的图像检索系统，可以在不增加模型复杂度的情况下提高图像检索准确性。 |
| [^25] | [Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle Consistency Losses.](http://arxiv.org/abs/2303.08364) | 本文提出了一种非监督的深度学习方法，通过机械和循环一致性损失来跟踪细胞轮廓上的所有点，不仅在精度和鲁棒性方面优于现有方法，而且还首次考虑了点对应，具有应用于活细胞成像的潜力。 |
| [^26] | [Sharing Low Rank Conformer Weights for Tiny Always-On Ambient Speech Recognition Models.](http://arxiv.org/abs/2303.08343) | 本论文提出了一种基于低秩张量分享的模型方法，将大型语音识别模型缩小至5M参数，同时实现了在低内存神经处理器边缘设备上的始终处于运行状态的语音识别。 |
| [^27] | [FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization.](http://arxiv.org/abs/2303.08335) | FactReranker是一种新颖的辅助评估器，可以在保持摘要与放射学发现实况一致性的基础上，通过事实引导来有效地选择最佳的摘要。 |
| [^28] | [Optimization Design for Federated Learning in Heterogeneous 6G Networks.](http://arxiv.org/abs/2303.08322) | 联邦学习是实现6G网络人工智能普及的关键技术，但在6G网络中，存在一些系统和统计异构性挑战。本研究研究了能够有效解决这些异构性问题的优化方法。 |
| [^29] | [A Comprehensive Study on Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2303.08302) | 本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。 |
| [^30] | [Learning From High-Dimensional Cyber-Physical Data Streams for Diagnosing Faults in Smart Grids.](http://arxiv.org/abs/2303.08300) | 本文采用特征工程相结合的方法解决了网络物理电力系统数据质量、计算成本和冗余测量数据的问题，提高了故障诊断系统的性能。 |
| [^31] | [Machine Learning Approaches in Agile Manufacturing with Recycled Materials for Sustainability.](http://arxiv.org/abs/2303.08291) | 本文提出将回收再利用材料用于敏捷制造，应用机器学习模型进行预测分析，以决策支持实现环境可持续性。 |
| [^32] | [Improving Adversarial Robustness with Hypersphere Embedding and Angular-based Regularizations.](http://arxiv.org/abs/2303.08289) | 本文提出了一种新的对抗训练方法，角度-AT，结合超球嵌入和基于角度的正则化技术以提高深度神经网络的对抗鲁棒性能。 |
| [^33] | [Linking Alternative Fuel Vehicles Adoption with Socioeconomic Status and Air Quality Index.](http://arxiv.org/abs/2303.08286) | 该研究借助机器学习技术，探究替代燃料汽车的普及，同时将其与消费者的社会经济地位和空气质量指数进行关联，从而制定合适的政策。 |
| [^34] | [Robot Navigation in Risky, Crowded Environments: Understanding Human Preferences.](http://arxiv.org/abs/2303.08284) | 本文研究了在风险与拥挤环境下的机器人导航，通过探索人们在COVID-19疫情购物场景中的路径选择偏好，并评估三种流行的风险模型(CPT，CVaR和ER)，以更好地设计机器人导航可解释人工智能(XAI)。 |
| [^35] | [Act-Then-Measure: Reinforcement Learning for Partially Observable Environments with Active Measuring.](http://arxiv.org/abs/2303.08271) | 本论文研究了对于代理有直接控制何时以及如何收集信息的能力的马尔可夫决策过程。我们引入了行动后测量 (ATM) 策略，并开发了一个基于 ATM 启发式方法的强化学习算法，展示了其在多个部分可观察环境上优于先前的方法的卓越性能。 |
| [^36] | [Neuro-symbolic Commonsense Social Reasoning.](http://arxiv.org/abs/2303.08264) | 本文介绍了一种神经符号方法，将自然语言中的社交规则转换为一阶逻辑，并使用神经符号定理证明器进行推理。该方法展现了有希望的结果，可以用来进行对社交常识问题的明确推理。 |
| [^37] | [Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures.](http://arxiv.org/abs/2303.08259) | 本文使用Transformer预训练深度学习架构开发了NLP系统，可在临床笔记中提取药物及其上下文信息，并在药物信息提取任务中取得最先进的性能。 |
| [^38] | [NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions.](http://arxiv.org/abs/2303.08233) | NL4Opt比赛旨在研究如何从自然语言描述中提取出优化问题的含义和表述，并通过自然语言与非专业人士进行交互。竞赛分为两个子任务：(1) 识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。 |
| [^39] | [DeepAxe: A Framework for Exploration of Approximation and Reliability Trade-offs in DNN Accelerators.](http://arxiv.org/abs/2303.08226) | DeepAxe是一个用于在DNN加速器的设计空间中考虑近似和可靠性权衡的框架，逼近可靠性关键的DNN，并提供一组Pareto最优的DNN实现设计空间。 |
| [^40] | [Graph Transformer GANs for Graph-Constrained House Generation.](http://arxiv.org/abs/2303.08225) | 本文提出了一种基于图变换器生成对抗网络的方法，通过连接节点和非连接节点的全局关系以及基于房屋布局拓扑的本地顶点交互，实现了图约束房屋的端到端生成。 |
| [^41] | [Few-Shot Classification of Autism Spectrum Disorder using Site-Agnostic Meta-Learning and Brain MRI.](http://arxiv.org/abs/2303.08224) | 本文研究了针对自闭症谱系障碍的场地不可知元学习模型在少样本情况下的表现，使用在多个站点的MRI数据训练出的模型，实现对病人和正常人的快速识别分类。 |
| [^42] | [Efficiently Training Vision Transformers on Structural MRI Scans for Alzheimer's Disease Detection.](http://arxiv.org/abs/2303.08216) | 本文尝试使用Vision Transformers对基于MRI扫描的性别和AD分类任务进行了测试，其中两种ViT架构变体分别实现了0.987的性别分类AUC和0.892的AD分类AUC。该方法可为大规模神经影像学识别提供高效解决方案。 |
| [^43] | [Is forgetting less a good inductive bias for forward transfer?.](http://arxiv.org/abs/2303.08207) | 本文提出对于持续学习任务来说，遗忘不是一种良好的归纳偏差。之前的研究没有考虑到前向迁移的量度方式，本文提出了一种新的量度方式，发现较不遗忘的模型具有更好的性能。 |
| [^44] | [The Elements of Visual Art Recommendation: Learning Latent Semantic Representations of Paintings.](http://arxiv.org/abs/2303.08182) | 本文研究了如何高效地捕捉视觉艺术的元素，提出了结合文本和视觉特征学习技术的推荐系统，用于个性化艺术品推荐，结果显示两者的结合可以捕捉最合适的隐藏语义关系。 |
| [^45] | [MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain.](http://arxiv.org/abs/2303.08179) | 本文介绍了medBERT.de，这是一个用于德语医学领域的BERT模型，通过在大规模语料库上的训练，在八个不同的医学基准测试中取得最新的最先进的表现。该模型对长文本特别有用，而数据去重和有效的分词则只对模型性能产生了较小的影响。 |
| [^46] | [The Equitable AI Research Roundtable (EARR): Towards Community-Based Decision Making in Responsible AI Development.](http://arxiv.org/abs/2303.08177) | 本文介绍了平等AI研究圆桌会议（EARR），EARR为AI技术的道德和社会伤害提供关键研究视角和反馈，并提出了三个原则：扩大AI开发的专业知识范围，促进知识好奇心和责任，以及创造相互学习的空间。 |
| [^47] | [Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images.](http://arxiv.org/abs/2303.07274) | WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。 |
| [^48] | [Interpretable Outlier Summarization.](http://arxiv.org/abs/2303.06261) | STAIR提出了一种可解释的异常值汇总方法，通过学习一组紧凑的人类可理解规则，以汇总和解释异常检测结果，具有强大的可解释性，以准确地总结检测结果。 |
| [^49] | [Vector Quantized Time Series Generation with a Bidirectional Prior Model.](http://arxiv.org/abs/2303.04743) | 本文提出了一种新的时间序列生成方法，使用向量量化技术和双向变压器模型来生成质量更好、模块化变化更快的合成信号。 |
| [^50] | [Constrained Bayesian Optimization for Automatic Underwater Vehicle Hull Design.](http://arxiv.org/abs/2302.14732) | 本文研究了自主水下载体的优化设计问题，通过集成FreeCAD和OpenFoam等工具进行自动化设计评估，并采用贝叶斯优化算法解决了优化中样本效率的问题。 |
| [^51] | [Which One Are You Referring To? Multimodal Object Identification in Situated Dialogue.](http://arxiv.org/abs/2302.14680) | 本文探索了三种多模态对象识别方法并在SIMMC 2.1数据集上进行了评估。最佳方法是基于场景对话的对齐，相比基准测试提高了约20%的F1分数。 |
| [^52] | [Estimation of continuous environments by robot swarms: Correlated networks and decision-making.](http://arxiv.org/abs/2302.13629) | 本论文研究了机器人群体对连续环境的估计任务，并提出了一种控制算法。其独特之处在于动态网络拓扑和决策制定之间存在因果循环，影响着精度和收敛时间。 |
| [^53] | [Recent Advancements in Deep Learning Applications and Methods for Autonomous Navigation -- A Comprehensive Review.](http://arxiv.org/abs/2302.11089) | 本综述论文介绍了自主导航领域中最新的深度学习应用和方法，包括障碍检测、场景感知、路径规划和控制。突出了深度学习在工程数据科学中的快速发展，以及创新导航方法的开发和跨学科研究的重要性和挑战。 |
| [^54] | [DrasCLR: A Self-supervised Framework of Learning Disease-related and Anatomy-specific Representation for 3D Medical Images.](http://arxiv.org/abs/2302.10390) | DrasCLR是一个自监督框架，通过提出两种领域特定的对比学习策略来学习疾病相关和解剖特异性表示，特别是解决了区分疾病模式和解剖特征的挑战。 |
| [^55] | [Search for universal minimum drag resistance underwater vehicle hull using CFD.](http://arxiv.org/abs/2302.09441) | 本文利用CFD模拟和优化算法，研究最小化阻力的水下航行器设计方案。初步结果表明，不存在可以适应所有运行和环境条件的通用设计，但在高速和高湍流条件下找到了接近最佳设计的方案。 |
| [^56] | [SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning.](http://arxiv.org/abs/2301.10921) | 本文提出了SoftMatch，通过在训练中保持高数量和高质量的伪标签来克服半监督学习中数量-质量权衡问题，有效地利用未标注的数据。 在实验中，SoftMatch在图像、文本和影片等多个基准测试中都显示了实质性的改进。 |
| [^57] | [Generative Logic with Time: Beyond Logical Consistency and Statistical Possibility.](http://arxiv.org/abs/2301.08509) | 本文提出了一种将数据和逻辑结合起来进行推理的理论，解决了符号知识的概率推理问题，并在定位问题中展示出机器人可以完全数据驱动地解决这一问题。 |
| [^58] | [Age of Information in Deep Learning-Driven Task-Oriented Communications.](http://arxiv.org/abs/2301.04298) | 本文研究了在任务导向通信中通过编码器-解码器对来执行任务的信息时代问题，通过信道利用率的增加可以提高准确性，但需要更长的服务时间，引入任务信息的最大时代（PAoTI）来对准确性和延迟进行权衡。 |
| [^59] | [Fairness Guaranteed and Auction-based x-haul and Cloud Resource Allocation in Multi-tenant O-RANs.](http://arxiv.org/abs/2301.00597) | 本文提出基于竞拍的资源分配机制，在多租户O-RAN生态系统中最小化不同MNO租户类型的OPEX，同时保证公平。 |
| [^60] | [Policy Adaptation from Foundation Model Feedback.](http://arxiv.org/abs/2212.07398) | 本文提出了基于基础模型反馈的策略适应（PAFF）方法，通过让策略使用随机生成的指令进行演示，并利用预训练的基础模型提供反馈来重新标记演示，自动提供新的演示-指令数据对进行策略微调，以实现机器人操作的泛化。实验结果表明，PAFF优于现有最先进的方法。 |
| [^61] | [Heterogeneous Graph Learning for Multi-modal Medical Data Analysis.](http://arxiv.org/abs/2211.15158) | 该论文提出了一种名为HetMed的异构图学习框架，用于融合多模态医学数据，以提高临床决策的准确性。 |
| [^62] | [Generalized Category Discovery with Decoupled Prototypical Network.](http://arxiv.org/abs/2211.15115) | 本文提出了一种解耦原型网络（DPN）模型，通过二分图匹配问题分离已知和新类别来有效地实现不同的训练目标，并将标记和未标记数据中的已知类别对齐，以显式转移类别特定的知识和捕获高级语义信息。 |
| [^63] | [VGFlow: Visibility guided Flow Network for Human Reposing.](http://arxiv.org/abs/2211.08540) | 提出了一种基于可见性引导流模块的流网络模型VGFlow，可以分离出目标的可见和不可见部分以实现纹理保留和风格操作，同时采用了多路径结构以在不同级别的细节上操作。在生成逼真人体姿势方面表现出有效性。 |
| [^64] | [Biologically-Inspired Continual Learning of Human Motion Sequences.](http://arxiv.org/abs/2211.05231) | 本文提出了一个受生物启示的条件时间变分自动编码器(BI-CTVAE)模型，通过持续学习生成(CL2Gen)场景，可以对不同类别的运动序列进行生成，并在一组任务上得到较高的生成准确性和分类准确性。 |
| [^65] | [Formalizing Statistical Causality via Modal Logic.](http://arxiv.org/abs/2210.16751) | 提出了一种基于模态逻辑的形式语言，用于描述和解释统计因果关系，并且能够指定和解释统计因果推断的正确性。 |
| [^66] | [Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion.](http://arxiv.org/abs/2210.08471) | 本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。 |
| [^67] | [MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting.](http://arxiv.org/abs/2210.07179) | MAPL使用对齐的图像-文本数据学习单模态模型表示空间之间的轻量级映射，从而实现了面向视觉-语言少样本任务的基于参数效率的适应，并在测试中显示出优越的性能表现。 |
| [^68] | [Perplexity from PLM Is Unreliable for Evaluating Text Quality.](http://arxiv.org/abs/2210.05892) | 该研究发现，使用困惑度指标评估生成文本质量是不可靠的，由于短文本 PPL 值高于长文本，重复文本段落和标点符号也可以损坏指标表现。 使用语言模型评估文本质量应谨慎。 |
| [^69] | [Learning Minimally-Violating Continuous Control for Infeasible Linear Temporal Logic Specifications.](http://arxiv.org/abs/2210.01162) | 本文提出了一个模型自由框架，使用深度强化学习来实现复杂高级任务的目标驱动导航。通过将先前的多目标DRL问题转化为一个单一目标问题，并使用基于采样的路径规划算法来指导DRL智能体，该方法可以满足不可行的线性时态逻辑任务并尽可能减少违规。 |
| [^70] | [From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds.](http://arxiv.org/abs/2209.13974) | 本论文证明了NSGA-II算法在适当的人口规模下，在解决$OneMinMax$问题时需要$\Omega(Nn\log n)$次函数评估，并在解决跳跃大小为$k$的$OneJumpZeroJump$问题时需要$\Omega(Nn^k)$次评估。这些下限也表明，即使使用更大的人口大小，NSGA-II也不能在并行运行时间方面受益。 |
| [^71] | [How GPT-3 responds to different publics on climate change and Black Lives Matter: A critical appraisal of equity in conversational AI.](http://arxiv.org/abs/2209.13627) | 本论文提出了一个分析框架，以检查人工智能和人类对话中公平性的含义。作者使用这个框架进行了审计研究，发现 GPT-3 在回应气候变化和BBL运动的提示时存在不公平的行为，强化了刻板印象，边缘化了某些特定的群体。该研究表明有必要解决这些偏见，以防止AI-powered服务中进一步巩固权力结构。 |
| [^72] | [Generalization in Neural Networks: A Broad Survey.](http://arxiv.org/abs/2209.01610) | 这篇论文总结了神经网络模型中不同抽象层次上的泛化问题及其方法，其中样本泛化已经取得了进展，但未来需要重点关注减少过拟合；分布泛化与领域泛化有相似之处，领域泛化方法可以应用于困难的样本或分布泛化。 |
| [^73] | [Runtime Analysis for the NSGA-II: Provable Speed-Ups From Crossover.](http://arxiv.org/abs/2208.08759) | 本文证明NSGA-II优化OneJumpZeroJump基准函数时，交叉操作可以带来可证明的加速效果；同样，交叉操作对于单目标优化中的$(\mu+1)$遗传算法也有更显著的加速效果。 |
| [^74] | [Quantifying the Effect of Feedback Frequency in Interactive Reinforcement Learning for Robotic Tasks.](http://arxiv.org/abs/2207.09845) | 本文对交互式强化学习中反馈频率对机器人任务的影响进行了定量化研究，结果表明没有单一的理想反馈频率存在，应该根据具体的任务和机器人复杂性进行调整。 |
| [^75] | [Betty: An Automatic Differentiation Library for Multilevel Optimization.](http://arxiv.org/abs/2207.02849) | 本文介绍了一个名为Betty的自动微分库，可用于大规模的梯度优化问题，有效地减少了计算复杂度并提高了可扩展性，在广泛的多层次优化任务中表现出良好性能。 |
| [^76] | [NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds.](http://arxiv.org/abs/2206.11736) | NovelCraft数据集提供了开放世界中新颖性检测与发现任务的挑战。在复杂的场景中插入新颖物体的检测需要更好的基准，并发现了控制假阳性时更简单的方法可能比复杂的方法更出色。 |
| [^77] | [Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity.](http://arxiv.org/abs/2204.06242) | 提出了一种新的基于修改过的马蹄蚌先验的多视角潜变量模型MuVI，用于建模结构稀疏性。它能够纳入有限且噪声的领域知识，以内在可解释的方式分析多视角数据，优于现有结构稀疏性建模方法。 |
| [^78] | [Visuo-Haptic Object Perception for Robots: An Overview.](http://arxiv.org/abs/2203.11544) | 本文总结了机器人视觉触觉物体感知的现状以及挑战。人类多模态物体感知的生物学基础和最新的机器人感知技术和数据采集策略被概述，同时重点介绍了多模态机器学习的主要挑战，并提出了一些未来的研究方向。 |
| [^79] | [A Large and Diverse Arabic Corpus for Language Modeling.](http://arxiv.org/abs/2201.09227) | 该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。 |
| [^80] | [Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting.](http://arxiv.org/abs/2110.03135) | 该论文发现了对抗训练中存在的标签噪声，并解释了其对鲁棒过度拟合的普遍存在以及扰动半径和数据质量的依赖性。通过该论文提出的方法，可以自动校准标签以应对标签噪声和鲁棒过度拟合。 |
| [^81] | [The Ecosystem Path to General AI.](http://arxiv.org/abs/2108.07578) | 这篇论文介绍了一个基于Unity游戏引擎的开源生态系统模拟器Ecotwin，其中动物认知的建模通过整合三个独立的网络实现，模拟自然现象在模型中出现而无需硬编码。 |
| [^82] | [Bounded rationality for relaxing best response and mutual consistency: The Quantal Hierarchy model of decision-making.](http://arxiv.org/abs/2106.15844) | 本研究提出了Quantal Hierarchy模型，放宽了互相一致性和最优反应的限制，使得可以近似级别K，QRE或Nash均衡行为。这种模型基于变分自由能原理的递归形式，将更高阶推理表示为演化形式博弈树中的（伪）序列决策制定。 |
| [^83] | [Label prompt for multi-label text classification.](http://arxiv.org/abs/2106.10076) | 本文提出了一种 Label Mask 多标签文本分类模型（LM-MTC），利用预训练语言模型的能力来捕捉标签之间的隐含关系，并通过基于标签的遮盖语言模型（MLM）进一步提高模型的泛化能力。 |
| [^84] | [Planning and Learning Using Adaptive Entropy Tree Search.](http://arxiv.org/abs/2102.06808) | 本论文提出了一种全新的算法ANTS，它将规划和学习结合在最大熵范式中，并通过在Atari基准测试上的实验证明其明显优于当前最先进的AlphaZero系统的规划组件PUCT，具有较强的稳健性，可推动基于树的规划方法的实际应用。 |
| [^85] | [To Be Announced.](http://arxiv.org/abs/2004.05802) | 该论文综述了动态认知逻辑中的信息变化量化模态，包括公理化、表述方式、可决定性和复杂性评估，并提出了未解决的问题和研究方向。 |

# 详细

[^1]: 理解事后解释器：以Anchors为例

    Understanding Post-hoc Explainers: The Case of Anchors. (arXiv:2303.08806v1 [stat.ML])

    [http://arxiv.org/abs/2303.08806](http://arxiv.org/abs/2303.08806)

    本文对Anchors进行了理论分析，这是一种基于规则的可解释性方法，用于解释文本分类器的决策。

    

    在许多情况下，机器学习模型可解释性是一项高度要求但难以实现的任务。为了解释这些模型的个体预测，已经提出了本地模型无关方法。然而，产生解释的过程对于用户来说可能与要解释的预测一样神秘。此外，可解释性方法经常缺乏理论保证，并且它们在简单模型上的行为通常是未知的。本文对Anchors（Ribeiro等人，2018）进行理论分析：一种流行的基于规则的可解释性方法，它强调一小组单词以解释文本分类器的决策。

    In many scenarios, the interpretability of machine learning models is a highly required but difficult task. To explain the individual predictions of such models, local model-agnostic approaches have been proposed. However, the process generating the explanations can be, for a user, as mysterious as the prediction to be explained. Furthermore, interpretability methods frequently lack theoretical guarantees, and their behavior on simple models is frequently unknown. While it is difficult, if not impossible, to ensure that an explainer behaves as expected on a cutting-edge model, we can at least ensure that everything works on simple, already interpretable models. In this paper, we present a theoretical analysis of Anchors (Ribeiro et al., 2018): a popular rule-based interpretability method that highlights a small set of words to explain a text classifier's decision. After formalizing its algorithm and providing useful insights, we demonstrate mathematically that Anchors produces meaningf
    
[^2]: 使用spaCy构建有效的电子邮件垃圾邮件分类模型

    Building an Effective Email Spam Classification Model with spaCy. (arXiv:2303.08792v1 [cs.AI])

    [http://arxiv.org/abs/2303.08792](http://arxiv.org/abs/2303.08792)

    本文介绍了使用spaCy和机器学习算法来检测Gmail中的垃圾邮件，结果显示多层感知器算法在垃圾邮件检测中的准确率达到96％。

    

    如今，人们使用Gmail、Outlook、AOL Mail等电子邮件服务快速相互沟通，发送信息和官方信函。垃圾邮件是这种通信的主要挑战，通常是由僵尸网络发送的，旨在向不同的人群广告、损害和窃取信息。每天收到大量不想要的垃圾邮件会填满收件箱文件夹。因此，垃圾邮件检测是一项基本的挑战，目前已经有许多工作使用聚类和文本分类方法来检测垃圾邮件。本文作者使用了spaCy自然语言处理库和Python编程语言中的3种机器学习（ML）算法朴素贝叶斯（NB）、决策树C45和多层感知器（MLP）来检测从Gmail服务收集的垃圾邮件。观察结果显示，多层感知器（MLP）算法在垃圾邮件检测中的准确率为96％。

    Today, people use email services such as Gmail, Outlook, AOL Mail, etc. to communicate with each other as quickly as possible to send information and official letters. Spam or junk mail is a major challenge to this type of communication, usually sent by botnets with the aim of advertising, harming and stealing information in bulk to different people. Receiving unwanted spam emails on a daily basis fills up the inbox folder. Therefore, spam detection is a fundamental challenge, so far many works have been done to detect spam using clustering and text categorisation methods. In this article, the author has used the spaCy natural language processing library and 3 machine learning (ML) algorithms Naive Bayes (NB), Decision Tree C45 and Multilayer Perceptron (MLP) in the Python programming language to detect spam emails collected from the Gmail service. Observations show the accuracy rate (96%) of the Multilayer Perceptron (MLP) algorithm in spam detection.
    
[^3]: PLEX：利用可用数据进行机器人操纵预训练的最大化

    PLEX: Making the Most of the Available Data for Robotic Manipulation Pretraining. (arXiv:2303.08789v1 [cs.RO])

    [http://arxiv.org/abs/2303.08789](http://arxiv.org/abs/2303.08789)

    PLEX提出了一种新的机器人操纵预训练方法，利用任务不可知的视觉运动轨迹和大量的任务条件下的物体操作视频，在学习通用的操纵例程的同时，通过视频演示学习如何在这个特征空间中规划各种任务。

    

    丰富的表征是实现机器人操纵的关键，但现有的模型架构需要大量数据来学习。不幸的是，理想的机器人操纵训练数据，即各种已注释任务的专家视觉-动作演示，是稀缺的。在本文中，我们提出了一种基于变压器的架构PLEX，它是从任务不可知视觉运动轨迹中学习的，伴随着大量的任务条件下的物体操作视频——这是一种数量可观的与机器人相关的数据。PLEX背后的关键见解是，在观察和行动方面的轨迹下，有助于诱导潜在的特征空间，并训练机器人执行与任务不相关的操作例程，而多样化的仅为视频演示仅可以有效地教会机器人如何在这个特征空间中规划各种任务。与大多数机器人操纵预培训作品不同，PLEX学习了一种可推广的感觉运动多任务策略。

    A rich representation is key to general robotic manipulation, but existing model architectures require a lot of data to learn it. Unfortunately, ideal robotic manipulation training data, which comes in the form of expert visuomotor demonstrations for a variety of annotated tasks, is scarce. In this work we propose PLEX, a transformer-based architecture that learns from task-agnostic visuomotor trajectories accompanied by a much larger amount of task-conditioned object manipulation videos -- a type of robotics-relevant data available in quantity. The key insight behind PLEX is that the trajectories with observations and actions help induce a latent feature space and train a robot to execute task-agnostic manipulation routines, while a diverse set of video-only demonstrations can efficiently teach the robot how to plan in this feature space for a wide variety of tasks. In contrast to most works on robotic manipulation pretraining, PLEX learns a generalizable sensorimotor multi-task polic
    
[^4]: 全神经形态视觉和控制的自主飞行执照。

    Fully neuromorphic vision and control for autonomous drone flight. (arXiv:2303.08778v1 [cs.RO])

    [http://arxiv.org/abs/2303.08778](http://arxiv.org/abs/2303.08778)

    本文介绍了第一个全神经形态视觉到控制的流程，使无人机具备了执行自主基于视觉的飞行所需的能力，为机器人感知和行动提供了低延迟和能量有效的解决方案。

    

    生物感知和处理是异步和稀疏的，导致低延迟和能量有效的感知和行动。在机器人学中，使用面向事件的神经形态硬件和尖峰神经网络承诺具有类似的特征。然而，由于当前嵌入式神经形态处理器中受限的网络规模以及训练尖峰神经网络的困难，机器人实现仅限于具有低维感官输入和运动执行的基本任务。在这里，我们提出了第一个全神经形态视觉到控制的流程，以控制自由飞行的无人机。具体而言，我们训练了一个尖峰神经网络，该神经网络接受高维原始事件相机数据并输出执行自主基于视觉的飞行所需的低级控制动作。网络的视觉部分由五层和 28.8k 神经元组成，将传入的原始事件映射到自我运动估计上，并使用真实环境的自我监督学习进行训练。

    Biological sensing and processing is asynchronous and sparse, leading to low-latency and energy-efficient perception and action. In robotics, neuromorphic hardware for event-based vision and spiking neural networks promises to exhibit similar characteristics. However, robotic implementations have been limited to basic tasks with low-dimensional sensory inputs and motor actions due to the restricted network size in current embedded neuromorphic processors and the difficulties of training spiking neural networks. Here, we present the first fully neuromorphic vision-to-control pipeline for controlling a freely flying drone. Specifically, we train a spiking neural network that accepts high-dimensional raw event-based camera data and outputs low-level control actions for performing autonomous vision-based flight. The vision part of the network, consisting of five layers and 28.8k neurons, maps incoming raw events to ego-motion estimates and is trained with self-supervised learning on real e
    
[^5]: GPT-4技术报告

    GPT-4 Technical Report. (arXiv:2303.08774v1 [cs.CL])

    [http://arxiv.org/abs/2303.08774](http://arxiv.org/abs/2303.08774)

    GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。

    

    我们报告了GPT-4的开发，它是一个可以接受图像和文本输入并产生文本输出的大规模多模态模型。虽然在许多现实场景中不如人类，但GPT-4在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试，成绩排名在前10％左右。GPT-4是一个基于Transformer的模型，预训练用于预测文档中的下一个标记。后训练对齐过程提高了事实性和符合期望行为的性能指标。项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。这使我们能够准确预测GPT-4的某些性能方面，而这些性能是基于使用不超过GPT-4计算能力的1/1,000的模型训练的。

    We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.
    
[^6]: 基于稳定扩散的高度个性化文本嵌入图像操作

    Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion. (arXiv:2303.08767v1 [cs.CV])

    [http://arxiv.org/abs/2303.08767](http://arxiv.org/abs/2303.08767)

    本论文提出了一种简单但高效的个性化方法——使用高度个性化文本嵌入来进行图像操作，可以运用于图像的背景、纹理和动作的编辑，不需要多个参考图像或复杂训练，能实现复杂语义图像编辑。

    

    稳定扩散模型已经展现出在图像生成和操作方面的卓越性能，但内部随机性带来的挑战在于如何保留和操作图像内容和身份。虽然之前的方法如“梦境相机”和“文本反转”提出了使用模型或潜在表示个性化来保持内容，但它们对多个参考图像和复杂训练的依赖限制了它们的实用性。本文提出了一种简单而又非常有效的个性化方法，使用高度个性化（HiPer）文本嵌入通过分解CLIP嵌入空间实现个性化和内容操作。我们的方法不需要模型微调或识别符，但仍可以仅通过单个图像和目标文本来实现背景、纹理和动作的操作。通过对多样化的目标文本的实验，我们证明了我们的方法在各种任务中都能产生高度个性化和复杂的语义图像编辑。

    Diffusion models have shown superior performance in image generation and manipulation, but the inherent stochasticity presents challenges in preserving and manipulating image content and identity. While previous approaches like DreamBooth and Textual Inversion have proposed model or latent representation personalization to maintain the content, their reliance on multiple reference images and complex training limits their practicality. In this paper, we present a simple yet highly effective approach to personalization using highly personalized (HiPer) text embedding by decomposing the CLIP embedding space for personalization and content manipulation. Our method does not require model fine-tuning or identifiers, yet still enables manipulation of background, texture, and motion with just a single image and target text. Through experiments on diverse target texts, we demonstrate that our approach produces highly personalized and complex semantic image edits across a wide range of tasks. We
    
[^7]: 基于级联放大的高分辨率航空图像检测器

    Cascaded Zoom-in Detector for High Resolution Aerial Images. (arXiv:2303.08747v1 [cs.CV])

    [http://arxiv.org/abs/2303.08747](http://arxiv.org/abs/2303.08747)

    本研究提出了一种基于级联放大的高分辨率航空图像检测器，使用密度裁剪来增强小物体检测，且易于集成到任何检测器中。

    

    在航空图像中检测物体是具有挑战性的，因为它们通常由分布不均匀的拥挤小物体组成，分辨率也很高。密度裁剪是改善小物体检测的广泛方法，其中提取并处理高分辨率下的拥挤小物体区域。然而，这通常通过添加其他可学习组件来完成，从而使训练和推理过程复杂化，这不符合标准检测流程。在本文中，我们提出了一种有效的级联放大检测器（CZ检测器），它重新定位检测器本身以进行密度引导式训练和推理。在训练期间，定位密度裁剪，标记为新类别，并用于增强训练数据集。在推理期间，密度裁剪与基类别对象一起首先被检测，然后输入进行第二阶段的推理。这种方法可以轻松地集成到任何检测器中，并且不会对标准检测流程造成重大变化。

    Detecting objects in aerial images is challenging because they are typically composed of crowded small objects distributed non-uniformly over high-resolution images. Density cropping is a widely used method to improve this small object detection where the crowded small object regions are extracted and processed in high resolution. However, this is typically accomplished by adding other learnable components, thus complicating the training and inference over a standard detection process. In this paper, we propose an efficient Cascaded Zoom-in (CZ) detector that re-purposes the detector itself for density-guided training and inference. During training, density crops are located, labeled as a new class, and employed to augment the training dataset. During inference, the density crops are first detected along with the base class objects, and then input for a second stage of inference. This approach is easily integrated into any detector, and creates no significant change in the standard det
    
[^8]: DACOS-一个手动注释的代码异味数据集

    DACOS-A Manually Annotated Dataset of Code Smells. (arXiv:2303.08729v1 [cs.SE])

    [http://arxiv.org/abs/2303.08729](http://arxiv.org/abs/2303.08729)

    DACOS是一个手动注释的包含三种不同粒度的代码异味（多面抽象、复杂方法和长参数列表）的数据集，用于作为机器学习检测代码异味的训练和基准测试。

    

    研究人员应用机器学习技术来检测代码异味，以抵消许多代码异味的主观性。这种方法需要一个大型、手动注释的数据集进行训练和基准测试。现有文献提供了一些数据集，但它们规模较小，更重要的是，它们没有关注主观代码片段。本文介绍了DACOS，一个手动注释的数据集，包含10,267个对5,192个代码片段的注释。该数据集针对不同粒度的三种代码异味：多面抽象、复杂方法和长参数列表。数据集分为两个阶段创建。第一阶段通过确定用于检测气味的度量标准的阈值来帮助我们识别可能具有主观性的代码片段。第二阶段收集可能具有主观性的代码片段的注释。我们还提供了一个扩展数据集DACOSX，它使用阈值包含明确的良性代码片段和明确的有异味的代码片段。

    Researchers apply machine-learning techniques for code smell detection to counter the subjectivity of many code smells. Such approaches need a large, manually annotated dataset for training and benchmarking. Existing literature offers a few datasets; however, they are small in size and, more importantly, do not focus on the subjective code snippets. In this paper, we present DACOS, a manually annotated dataset containing 10,267 annotations for 5,192 code snippets. The dataset targets three kinds of code smells at different granularity: multifaceted abstraction, complex method, and long parameter list. The dataset is created in two phases. The first phase helps us identify the code snippets that are potentially subjective by determining the thresholds of metrics used to detect a smell. The second phase collects annotations for potentially subjective snippets. We also offer an extended dataset DACOSX that includes definitely benign and definitely smelly snippets by using the thresholds i
    
[^9]: 人工影响: AI驱动的说服分析

    Artificial Influence: An Analysis Of AI-Driven Persuasion. (arXiv:2303.08721v1 [cs.CY])

    [http://arxiv.org/abs/2303.08721](http://arxiv.org/abs/2303.08721)

    本文探讨了AI驱动的说服未来的不确定性，包括移动说服力平衡的方式、定制化的说服、虚假信息的带动以及改变人类自身言论的方式。我们警告存在负面影响，并呼吁加强对其开发和使用的监管。

    

    说服是人类的重要特征之一，是商业、政治等事业的核心。人工智能（AI）的进步已经产生了能够说服人类购买产品、观看视频、点击搜索结果等的AI系统。即使没有明确设计为说服的系统，在实践中也可能会这样做。未来，越来越具有人形特征的AI系统可能会与用户形成持续的关系，提高它们的说服力。本文探讨了具有不确定性的AI系统的说服能力未来。我们考虑到AI如何在移动说服力平衡的基础上，实现定制化的说服，为虚假信息带来动力以及改变人类塑造自身言论的方式。我们考虑AI驱动的说服方式可能与人类驱动的方式有所不同。我们警告说，普遍存在高度说服力的AI系统可能对人类的自主权和福祉产生负面影响，并呼吁加强关于其开发和使用的对话和监管。

    Persuasion is a key aspect of what it means to be human, and is central to business, politics, and other endeavors. Advancements in artificial intelligence (AI) have produced AI systems that are capable of persuading humans to buy products, watch videos, click on search results, and more. Even systems that are not explicitly designed to persuade may do so in practice. In the future, increasingly anthropomorphic AI systems may form ongoing relationships with users, increasing their persuasive power. This paper investigates the uncertain future of persuasive AI systems. We examine ways that AI could qualitatively alter our relationship to and views regarding persuasion by shifting the balance of persuasive power, allowing personalized persuasion to be deployed at scale, powering misinformation campaigns, and changing the way humans can shape their own discourse. We consider ways AI-driven persuasion could differ from human-driven persuasion. We warn that ubiquitous highlypersuasive AI sy
    
[^10]: 面向跨域零样本学习的双向分布对齐方法

    Bi-directional Distribution Alignment for Transductive Zero-Shot Learning. (arXiv:2303.08698v1 [cs.CV])

    [http://arxiv.org/abs/2303.08698](http://arxiv.org/abs/2303.08698)

    本文提出了一种 Bi-VAEGAN 模型，通过双向分布对齐、L_2 范数特征归一化和更复杂的先验估计方法，大大改善了跨域零样本学习中的分布偏移问题。

    

    零样本学习存在领域转移问题，即未见类别的真实和学习数据分布不匹配。尽管转导式零样本学习可以使用未见类别的无标签样本，但分布偏移仍然很高。本文提出了一种新颖的 TZSL 模型（命名为 Bi-VAEGAN），通过加强视觉空间和辅助空间之间的分布对齐，大大改善了这种偏移。模型设计的关键提议包括（1）双向分布对齐，（2）基于 L_2 范数的简单而有效的特征归一化方法，（3）更复杂的未见类别先验估计方法。在使用四个数据集进行基准评估时，Bi-VAEGAN 在标准和广义 TZSL 设置下均取得了新的最先进结果。代码可在 https://github.com/Zhicaiwww/Bi-VAEGAN 找到。

    It is well-known that zero-shot learning (ZSL) can suffer severely from the problem of domain shift, where the true and learned data distributions for the unseen classes do not match. Although transductive ZSL (TZSL) attempts to improve this by allowing the use of unlabelled examples from the unseen classes, there is still a high level of distribution shift. We propose a novel TZSL model (named as Bi-VAEGAN), which largely improves the shift by a strengthened distribution alignment between the visual and auxiliary spaces. The key proposal of the model design includes (1) a bi-directional distribution alignment, (2) a simple but effective L_2-norm based feature normalization approach, and (3) a more sophisticated unseen class prior estimation approach. In benchmark evaluation using four datasets, Bi-VAEGAN achieves the new state of the arts under both the standard and generalized TZSL settings. Code could be found at https://github.com/Zhicaiwww/Bi-VAEGAN
    
[^11]: Mirror: 自然语言接口用于数据查询、摘要和可视化

    Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization. (arXiv:2303.08697v1 [cs.DB])

    [http://arxiv.org/abs/2303.08697](http://arxiv.org/abs/2303.08697)

    Mirror 是一个由大型语言模型支持的平台，它提供了一个直观的自然语言接口，可以将问题转化为 SQL，并自动生成可执行的 SQL 命令。用户可以预览和编辑 SQL 以保证查询的准确性，还可以获得数据摘要和可视化。它适用于各种程度的数据分析人员和非技术专业人员。

    

    我们提出了 Mirror，这是一个由大型语言模型推动的数据探索和分析开源平台。Mirror 提供了一个直观的自然语言接口，用于查询数据库，并自动生成可执行的 SQL 命令来检索相关数据并用自然语言进行摘要。此外，用户可以预览和手动编辑生成的 SQL 命令，以确保查询的准确性。Mirror 还生成可视化图表，以便了解数据情况。设计时考虑到灵活性和人的输入，因此 Mirror 适合于经验丰富的数据分析师和非技术专业人员从数据中获取见解。

    We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data.
    
[^12]: 全景式一键分割：应用于农业数据

    Panoptic One-Click Segmentation: Applied to Agricultural Data. (arXiv:2303.08689v1 [cs.CV])

    [http://arxiv.org/abs/2303.08689](http://arxiv.org/abs/2303.08689)

    本研究提出了一种全景式一键分割方法，允许从点击输入中以高效准确的方式产生伪标签，用于训练实例分割模型，从而大大减少了标记工作和成本。

    

    在杂草控制方面，精准农业可以帮助大大减少除草剂的使用，从而产生经济和生态效益。其中一个关键因素是能够从图像数据中定位和分割所有植物。现代实例分割技术可以实现这一点，但是训练这样的系统需要大量手工标记的数据，这是昂贵且费力的。弱监督训练可以大大减少标记工作和成本。我们提出了全景式一键分割，这是一种高效准确的离线工具，可以从点击输入中产生伪标签，从而减少标记工作量。与传统方法独立迭代所有N个对象相比，我们的方法联合估计了N个对象场景中每个像素的位置，从而大大减少了训练时间。只使用10％的数据来训练我们的全景式一键分割方法，即可获得68.1％和68.8％的平均目标交集联合（IoU）。

    In weed control, precision agriculture can help to greatly reduce the use of herbicides, resulting in both economical and ecological benefits. A key element is the ability to locate and segment all the plants from image data. Modern instance segmentation techniques can achieve this, however, training such systems requires large amounts of hand-labelled data which is expensive and laborious to obtain. Weakly supervised training can help to greatly reduce labelling efforts and costs. We propose panoptic one-click segmentation, an efficient and accurate offline tool to produce pseudo-labels from click inputs which reduces labelling effort. Our approach jointly estimates the pixel-wise location of all N objects in the scene, compared to traditional approaches which iterate independently through all N objects; this greatly reduces training time. Using just 10% of the data to train our panoptic one-click segmentation approach yields 68.1% and 68.8% mean object intersection over union (IoU) o
    
[^13]: 深度视觉强制对齐: 学习将音频文字对齐到人脸视频中

    Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video. (arXiv:2303.08670v1 [cs.CV])

    [http://arxiv.org/abs/2303.08670](http://arxiv.org/abs/2303.08670)

    本论文提出了基于人脸视频的强制对齐技术，补充了使用音频强制对齐技术存在的缺陷，但由于视觉语音识别技术性能较低且文本到视频的翻译不可靠，开发可靠的视觉强制对齐技术具有挑战性。

    

    强制对齐是指将给定的音频文字转录与相应的语音进行时序对齐的技术。然而，随着强制对齐技术使用语音音频进行开发，当输入的语音音频受到噪声污染或无法访问时，它们可能会在对齐方面失败。我们关注的是语音可以从另一个组件中推断出，即语音视频(即，说话人的面部视频)。由于当音频信号处于不良状态时，可以使用视觉信息来补充音频强制对齐技术的缺点，因此我们尝试开发一种新型的基于视频的强制对齐方法。然而，与音频强制对齐不同，开发可靠的视觉强制对齐技术具有挑战性，原因在于: 1)视觉语音识别(VSR)与基于音频的自动语音识别(ASR)相比性能较低, 2)从文本到视频的翻译不可靠。

    Forced alignment refers to a technology that time-aligns a given transcription with a corresponding speech. However, as the forced alignment technologies have developed using speech audio, they might fail in alignment when the input speech audio is noise-corrupted or is not accessible. We focus on that there is another component that the speech can be inferred from, the speech video (i.e., talking face video). Since the drawbacks of audio-based forced alignment can be complemented using the visual information when the audio signal is under poor condition, we try to develop a novel video-based forced alignment method. However, different from audio forced alignment, it is challenging to develop a reliable visual forced alignment technology for the following two reasons: 1) Visual Speech Recognition (VSR) has a much lower performance compared to audio-based Automatic Speech Recognition (ASR), and 2) the translation from text to video is not reliable, so the method typically used for build
    
[^14]: 零样本对比损失用于文本引导扩散图像风格迁移

    Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer. (arXiv:2303.08622v1 [cs.CV])

    [http://arxiv.org/abs/2303.08622](http://arxiv.org/abs/2303.08622)

    本文提出了一种适用于文本引导图像风格迁移中的零样本对比损失方法，可以在不需要额外训练的情况下生成具有相同语义内容的图像。

    

    扩散模型在文本引导图像风格迁移中表现出极大的潜力，但由于其随机性而存在风格转换和内容保护之间的权衡。现有方法需要计算密集的扩散模型微调或附加神经网络。为了解决这个问题，我们在扩散模型中提出了一种零样本对比损失，它不需要额外的微调或辅助网络。通过利用预训练的扩散模型中生成样本和原始图像嵌入之间的图块对比损失，我们的方法可以以零样本的方式生成具有与源图像相同语义内容的图像。我们的方法在保留内容且不需要额外训练的同时，在图像风格迁移、图像到图像的转换和操作中均优于现有方法。我们的实验结果证实了我们提出的方法的有效性。

    Diffusion models have shown great promise in text-guided image style transfer, but there is a trade-off between style transformation and content preservation due to their stochastic nature. Existing methods require computationally expensive fine-tuning of diffusion models or additional neural network. To address this, here we propose a zero-shot contrastive loss for diffusion models that doesn't require additional fine-tuning or auxiliary networks. By leveraging patch-wise contrastive loss between generated samples and original image embeddings in the pre-trained diffusion model, our method can generate images with the same semantic content as the source image in a zero-shot manner. Our approach outperforms existing methods while preserving content and requiring no additional training, not only for image style transfer but also for image-to-image translation and manipulation. Our experimental results validate the effectiveness of our proposed method.
    
[^15]: 学习奖励信息获取：正确计分规则遇到委托代理模型

    Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model. (arXiv:2303.08613v1 [cs.LG])

    [http://arxiv.org/abs/2303.08613](http://arxiv.org/abs/2303.08613)

    本文设计了一种样本高效算法，将 UCB 算法（Auer等人，2002）应用于委托代理模型的在线设置，该算法能够通过与策略代理多次互动来设计最优的计分规则，并实现良好的效果。

    

    本文研究委托代理模型中的激励信息获取问题。此问题被建模为委托方和代理方之间的 Stackelberg 博弈，其中委托人宣布了一条得分规则来指定付款，然后代理方选择最大化其自身利润和报告信息的努力水平。我们从委托方的角度研究这个问题的在线设置，即通过与策略代理多次交互来设计最优计分规则。我们设计了一种可证明的样本高效算法，将 UCB 算法 (Auer et al., 2002) 量身定制到我们的模型中，其在 T 次迭代后实现了次线性 $T^{2/3}$-遗憾。我们的算法具有对委托方最优利润进行精细估计的过程以及保守纠正方案，以确保代理方的行动得到有效激励。此外，我们的遗憾界的一个关键特征是它是渐进最小可实现的。

    We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a sublinear $T^{2/3}$-regret after $T$ iterations. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is i
    
[^16]: 论文标题：Polya-Gamma增强对于对话检索模型的校准和不确定性研究

    On the Calibration and Uncertainty with P\'{o}lya-Gamma Augmentation for Dialog Retrieval Models. (arXiv:2303.08606v1 [cs.CL])

    [http://arxiv.org/abs/2303.08606](http://arxiv.org/abs/2303.08606)

    本文提出了一种PG-DRR框架，通过加入高斯过程层来提高对话响应检索模型的校准性和不确定性估计，可以在保持性能不变的情况下实现最低的校准误差。

    

    深度神经检索模型已经充分展示了它们的能力，但估计它们预测的可靠性仍然具有挑战性。大多数对话响应检索模型为每个响应输出一个相关问题的单个得分。然而，深度神经网络的坏校准会导致各种不确定性单个得分，从而不可靠的预测总是误导用户决策。为了研究这些问题，我们提出了一种高效的校准和不确定性估计框架PG-DRR，用于对话响应检索模型，它将一个高斯过程层添加到一个确定性深度神经网络中，并通过Polya-Gamma增强恢复共轭以便得到易处理的后验推断。最后，PG-DRR在域内数据集和分布偏移任务中实现了最低的实证校准误差（ECE），同时保持$R_{10}@1$和MAP性能。

    Deep neural retrieval models have amply demonstrated their power but estimating the reliability of their predictions remains challenging. Most dialog response retrieval models output a single score for a response on how relevant it is to a given question. However, the bad calibration of deep neural network results in various uncertainty for the single score such that the unreliable predictions always misinform user decisions. To investigate these issues, we present an efficient calibration and uncertainty estimation framework PG-DRR for dialog response retrieval models which adds a Gaussian Process layer to a deterministic deep neural network and recovers conjugacy for tractable posterior inference by P\'{o}lya-Gamma augmentation. Finally, PG-DRR achieves the lowest empirical calibration error (ECE) in the in-domain datasets and the distributional shift task while keeping $R_{10}@1$ and MAP performance.
    
[^17]: 高斯过程的高效不确定性估计用于可靠对话响应检索

    Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval. (arXiv:2303.08599v1 [cs.CL])

    [http://arxiv.org/abs/2303.08599](http://arxiv.org/abs/2303.08599)

    本文提出了一个高斯过程下的不确定性校准框架GPF-BERT用于基于BERT的对话搜索，实现了高质量的神经排名器，相较于基本校准方法具有更低的经验校准误差和更高的检索性能，在时间上具有8倍的加速效果。

    

    检索式对话系统中的深度神经网络表现出卓越的性能，但它们被证明是不良校准的。虽然像蒙特卡罗Dropout和Ensemble这样的基本校准方法可以很好地校准，但这些方法在训练或推理阶段需要耗费大量时间。为了应对这些挑战，我们提出了一种高效的不确定性校准框架GPF-BERT，用于基于BERT的会话搜索，它采用高斯过程层和焦点损失在BERT架构的顶部，以实现高质量的神经排名器。大量实验用于验证我们的方法的有效性。与基本校准方法相比，GPF-BERT在三个领域内数据集和分布偏移任务中实现了最低的经验校准误差（ECE），同时在大多数情况下产生了最高的$R_{10}@1$和MAP性能。在时间消耗方面，我们的GPF-BERT具有8倍的加速效果。

    Deep neural networks have achieved remarkable performance in retrieval-based dialogue systems, but they are shown to be ill calibrated. Though basic calibration methods like Monte Carlo Dropout and Ensemble can calibrate well, these methods are time-consuming in the training or inference stages. To tackle these challenges, we propose an efficient uncertainty calibration framework GPF-BERT for BERT-based conversational search, which employs a Gaussian Process layer and the focal loss on top of the BERT architecture to achieve a high-quality neural ranker. Extensive experiments are conducted to verify the effectiveness of our method. In comparison with basic calibration methods, GPF-BERT achieves the lowest empirical calibration error (ECE) in three in-domain datasets and the distributional shift tasks, while yielding the highest $R_{10}@1$ and MAP performance on most cases. In terms of time consumption, our GPF-BERT has an 8$\times$ speedup.
    
[^18]: 敏感度感知的视觉参数低效调整

    Sensitivity-Aware Visual Parameter-Efficient Tuning. (arXiv:2303.08566v1 [cs.CV])

    [http://arxiv.org/abs/2303.08566](http://arxiv.org/abs/2303.08566)

    本文提出了敏感度感知的视觉参数低效调整（SPT）方案，可以自适应地将可训练参数分配到任务特定的重要位置，以提高表示能力，适应预训练视觉模型到下游任务。

    

    视觉参数低效调整（VPET）已成为自适应预训练视觉模型到下游任务的强劲替代方法。现有VPET方法根据人工启发式方法将可训练参数引入不同任务的相同位置，忽略领域差异。本文提出了一种新颖的敏感度感知的视觉参数低效调整（SPT）方案，以自适应的方式分配可训练参数到任务特定的重要位置，给定所需的可调参数预算。本文首先依据数据的相关性快速识别特定任务所需调整的敏感参数，然后提升表示能力，增大重要的权重矩阵数量。

    Visual Parameter-Efficient Tuning (VPET) has become a powerful alternative for full fine-tuning so as to adapt pre-trained vision models to downstream tasks, which only tunes a small number of parameters while freezing the vast majority ones to ease storage burden and optimization difficulty. However, existing VPET methods introduce trainable parameters to the same positions across different tasks depending solely on human heuristics and neglect the domain gaps. To this end, we study where to introduce and how to allocate trainable parameters by proposing a novel Sensitivity-aware visual Parameter-efficient Tuning (SPT) scheme, which adaptively allocates trainable parameters to task-specific important positions given a desired tunable parameter budget. Specifically, our SPT first quickly identifies the sensitive parameters that require tuning for a given task in a data-dependent way. Next, our SPT further boosts the representational capability for the weight matrices whose number of se
    
[^19]: 知识图谱驱动的认知语义通信系统：原理、实现和性能评估

    Cognitive Semantic Communication Systems Driven by Knowledge Graph: Principle, Implementation, and Performance Evaluation. (arXiv:2303.08546v1 [cs.AI])

    [http://arxiv.org/abs/2303.08546](http://arxiv.org/abs/2303.08546)

    本文提出了两种认知语义通信框架，利用知识图谱提出了一个可解释的语义信息检测算法和一种有效的语义纠错算法，并对预训练模型进行微调。性能评估结果表明，所提出的系统优于现有语义通信框架。

    

    语义通信被视为突破香农极限的一种有前途的技术。然而，语义推断和语义纠错研究不足。此外，现有语义通信框架的纠错方法不可解释和不灵活，限制了其性能。本文利用知识图谱开发了认知语义通信系统，针对单用户和多用户情景提出了两种认知语义通信框架。此外，提出了一种简单、通用、可解释的语义信息检测算法。进一步地，从知识图谱中挖掘推理规则，提出了一种有效的语义纠错算法。最后，通过对预训练模型进行微调，恢复语义信息。对于多用户认知语义通信系统，提出了基于用户社交属性的信息恢复算法。性能评估结果表明，所提出的认知语义通信系统优于现有语义通信框架。

    Semantic communication is envisioned as a promising technique to break through the Shannon limit. However, semantic inference and semantic error correction have not been well studied. Moreover, error correction methods of existing semantic communication frameworks are inexplicable and inflexible, which limits the achievable performance. In this paper, to tackle this issue, a knowledge graph is exploited to develop semantic communication systems. Two cognitive semantic communication frameworks are proposed for the single-user and multiple-user communication scenarios. Moreover, a simple, general, and interpretable semantic alignment algorithm for semantic information detection is proposed. Furthermore, an effective semantic correction algorithm is proposed by mining the inference rule from the knowledge graph. Additionally, the pre-trained model is fine-tuned to recover semantic information. For the multi-user cognitive semantic communication system, a message recovery algorithm is prop
    
[^20]: 自主机器人强健验证的贝叶斯学习方法

    Bayesian Learning for the Robust Verification of Autonomous Robots. (arXiv:2303.08476v1 [cs.RO])

    [http://arxiv.org/abs/2303.08476](http://arxiv.org/abs/2303.08476)

    本文提出了一种新框架，利用贝叶斯学习方法对验证机器人系统的先验知识和观测数据进行处理，以计算其期望的事件发生率范围，进而进行强健验证。该框架所用方法可处理常规事件和罕见情况，能处理真实系统内在的不确定性。

    

    本文开发了一种新颖的贝叶斯学习框架，能够在不确定环境中运行验证自主机器人进行关键任务。该框架利用验证机器人系统的先验知识和观测数据，学习其事件发生率的预期值的范围。该框架支持在系统操作期间常规观察到的事件以及那些罕见或是灾难性故障等回报巨大的事件。此外，我们利用学习到的事件发生率范围组装区间连续时间马尔可夫模型，并应用定量验证方法来计算关键系统属性的预期变化区间。这些区间反映了许多真实世界系统的内在不确定性，能够在参数不确定性下强健验证其定量属性。本文将所提出的框架应用于水下自主机器人任务验证的案例研究中。

    We develop a novel Bayesian learning framework that enables the runtime verification of autonomous robots performing critical missions in uncertain environments. Our framework exploits prior knowledge and observations of the verified robotic system to learn expected ranges of values for the occurrence rates of its events. We support both events observed regularly during system operation, and singular events such as catastrophic failures or the completion of difficult one-off tasks. Furthermore, we use the learnt event-rate ranges to assemble interval continuous-time Markov models, and we apply quantitative verification to these models to compute expected intervals of variation for key system properties. These intervals reflect the uncertainty intrinsic to many real-world systems, enabling the robust verification of their quantitative properties under parametric uncertainty. We apply the proposed framework to the case study of verification of an autonomous robotic mission for underwater
    
[^21]: 谁在掌控？对话机器人决策组件的角色与责任

    Who's in Charge? Roles and Responsibilities of Decision-Making Components in Conversational Robots. (arXiv:2303.08470v1 [cs.AI])

    [http://arxiv.org/abs/2303.08470](http://arxiv.org/abs/2303.08470)

    讨论模块化与端到端架构的优缺点，认为模块化架构在与人类用户协作执行复杂任务的对话机器人中是首选。

    

    对话机器人的软件架构通常由多个模块组成，每个模块都设计用于特定的处理任务或功能。其中一些模块是为了决策机器人在当前背景下执行的下一个动作而开发的。这些动作可能涉及到物理移动，如向前驱动或抓取物体，但也可能对应于交流行为，如向人类用户问问题。在本文中，我们反思人-机器人交互平台中这些决策模块的组织。我们讨论了模块化和端到端架构的相对优缺点，并认为，尽管端到端方法越来越受欢迎，但在开发旨在与人类用户协作执行复杂任务的对话机器人时，模块化架构仍然是首选。我们还展示了大多数实际人-机器人交互架构往往是以机器人为中心的。

    Software architectures for conversational robots typically consist of multiple modules, each designed for a particular processing task or functionality. Some of these modules are developed for the purpose of making decisions about the next action that the robot ought to perform in the current context. Those actions may relate to physical movements, such as driving forward or grasping an object, but may also correspond to communicative acts, such as asking a question to the human user. In this position paper, we reflect on the organization of those decision modules in human-robot interaction platforms. We discuss the relative benefits and limitations of modular vs. end-to-end architectures, and argue that, despite the increasing popularity of end-to-end approaches, modular architectures remain preferable when developing conversational robots designed to execute complex tasks in collaboration with human users. We also show that most practical HRI architectures tend to be either robot-cen
    
[^22]: 混合数据增强方法Mixup对于特征学习的益处

    The Benefits of Mixup for Feature Learning. (arXiv:2303.08433v1 [cs.LG])

    [http://arxiv.org/abs/2303.08433](http://arxiv.org/abs/2303.08433)

    本论文介绍了数据增强方法Mixup对于特征学习的益处。混合训练可以有效地从混合数据中学习罕见特征，相比之下，标准训练可能会漏掉这些罕见特征。

    

    Mixup是一种简单的数据增强方法，通过线性插值随机混合两个数据点，已广泛应用于各种深度学习应用中，以获得更好的泛化效果。然而，其有效性的理论基础尚未完全被理解。本文旨在寻求对Mixup益处的基本理解。首先，我们展示Mixup在特征和标签使用不同的线性插值参数时仍可实现类似于标准Mixup的性能。这表明，Zhang等人（2018）提出的直观线性解释可能并不能完全解释Mixup的成功。然后，我们从特征学习的角度对Mixup进行理论研究。我们考虑一个特征噪声数据模型，并展示Mixup训练可以有效地从其与常见特征（出现在大部分数据中）混合中学习罕见特征（出现在少部分数据中）。相比之下，标准训练可能会漏掉这些罕见特征。

    Mixup, a simple data augmentation method that randomly mixes two data points via linear interpolation, has been extensively applied in various deep learning applications to gain better generalization. However, the theoretical underpinnings of its efficacy are not yet fully understood. In this paper, we aim to seek a fundamental understanding of the benefits of Mixup. We first show that Mixup using different linear interpolation parameters for features and labels can still achieve similar performance to the standard Mixup. This indicates that the intuitive linearity explanation in Zhang et al., (2018) may not fully explain the success of Mixup. Then we perform a theoretical study of Mixup from the feature learning perspective. We consider a feature-noise data model and show that Mixup training can effectively learn the rare features (appearing in a small fraction of data) from its mixture with the common features (appearing in a large fraction of data). In contrast, standard training ca
    
[^23]: 基于Implicit Ray-Transformers的多视角遥感图像分割

    Implicit Ray-Transformers for Multi-view Remote Sensing Image Segmentation. (arXiv:2303.08401v1 [cs.CV])

    [http://arxiv.org/abs/2303.08401](http://arxiv.org/abs/2303.08401)

    本文提出了一种基于Implicit Ray-Transformers的多视角遥感图像分割方法，借助神经场和Ray Transformer，有效处理稀疏标注情况下的遥感场景，实现准确且视角一致的语义分割。

    

    目前大多数基于CNN的遥感图像语义分割方法通常依赖于大量标记的训练数据，但这种范式因未考虑场景中的3D信息，而在仅有少量标记视图的情况下难以应对遥感多视角场景的分割问题。为此，本文基于Implicit Neural Representation（INR）提出了“Implicit Ray-Transformer（IRT）”，用于处理仅有稀疏标注（如100个图像中的4-6个标签）的遥感场景语义分割。我们探索了一种将多视图3D结构先验引入任务以获得准确且视角一致的语义分割的新方法。所提出的方法包括两个阶段的学习过程。在第一阶段，我们优化神经场以编码基于多视图图像的遥感场景的颜色和3D结构。在第二阶段，我们设计了一个Ray Transformer来利用神经场3D特征与2D纹理特征之间的关系，以学习更好的语义分割。

    The mainstream CNN-based remote sensing (RS) image semantic segmentation approaches typically rely on massive labeled training data. Such a paradigm struggles with the problem of RS multi-view scene segmentation with limited labeled views due to the lack of considering 3D information within the scene. In this paper, we propose ''Implicit Ray-Transformer (IRT)'' based on Implicit Neural Representation (INR), for RS scene semantic segmentation with sparse labels (such as 4-6 labels per 100 images). We explore a new way of introducing multi-view 3D structure priors to the task for accurate and view-consistent semantic segmentation. The proposed method includes a two-stage learning process. In the first stage, we optimize a neural field to encode the color and 3D structure of the remote sensing scene based on multi-view images. In the second stage, we design a Ray Transformer to leverage the relations between the neural field 3D features and 2D texture features for learning better semantic
    
[^24]: 一种三元组损失扩张残差网络用于高分辨率图像检索中的表示学习

    A Triplet-loss Dilated Residual Network for High-Resolution Representation Learning in Image Retrieval. (arXiv:2303.08398v1 [cs.CV])

    [http://arxiv.org/abs/2303.08398](http://arxiv.org/abs/2303.08398)

    本文介绍了一种可训练参数较少、使用扩张残差神经网络和三元组损失的图像检索系统，可以在不增加模型复杂度的情况下提高图像检索准确性。

    

    基于内容的图像检索是从广泛的图像库中基于视觉内容（如颜色，形状或空间关系和纹理）检索图像子集的过程。在某些应用中，如本地化，图像检索被用作初始步骤。在这种情况下，检索到的前几个图像的准确性显着影响总体系统准确性。本文介绍了一种简单而有效的图像检索系统，其可训练参数较少，可以在检索到的前几个图像中提供可接受的准确性。所提出的方法利用了一种带有三元组损失的扩张残差卷积神经网络。实验表明，该模型可以通过扩大感受野从而提取更丰富的信息（即高分辨率表示），从而提高图像检索准确性，而无需增加模型的深度或复杂度。为增强提取表示的鲁棒性，本研究获得了候选图像的多个Crop。

    Content-based image retrieval is the process of retrieving a subset of images from an extensive image gallery based on visual contents, such as color, shape or spatial relations, and texture. In some applications, such as localization, image retrieval is employed as the initial step. In such cases, the accuracy of the top-retrieved images significantly affects the overall system accuracy. The current paper introduces a simple yet efficient image retrieval system with a fewer trainable parameters, which offers acceptable accuracy in top-retrieved images. The proposed method benefits from a dilated residual convolutional neural network with triplet loss. Experimental evaluations show that this model can extract richer information (i.e., high-resolution representations) by enlarging the receptive field, thus improving image retrieval accuracy without increasing the depth or complexity of the model. To enhance the extracted representations' robustness, the current research obtains candidat
    
[^25]: 通过机械和循环一致性损失的非监督细胞轮廓跟踪

    Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle Consistency Losses. (arXiv:2303.08364v1 [cs.CV])

    [http://arxiv.org/abs/2303.08364](http://arxiv.org/abs/2303.08364)

    本文提出了一种非监督的深度学习方法，通过机械和循环一致性损失来跟踪细胞轮廓上的所有点，不仅在精度和鲁棒性方面优于现有方法，而且还首次考虑了点对应，具有应用于活细胞成像的潜力。

    

    分析细胞形态的动态变化对于理解活细胞（包括干细胞和转移性癌症细胞）的各种功能和特性至关重要。为此，我们需要在每个活细胞视频帧上跟踪细胞轮廓上的所有点。轮廓上的局部形状和纹理不明显，其运动复杂，常常伴随局部轮廓特征的扩张和收缩。目前光流或深度点集跟踪的先前工作由于细胞的流动性而不适用，以前的深度轮廓跟踪也没有考虑点对应。我们提出了第一种基于深度学习的细胞（或更一般的粘弹性材料）轮廓跟踪，通过融合两个轮廓之间的密集表示和交叉关注实现点对应。由于手动标记轮廓上的密集跟踪点是不现实的，因此采用了机械和循环一致性损失的非监督学习方法。所提出的方法在合成和实验数据集上进行评估，并在精度和鲁棒性方面优于现有方法，展示了其在活细胞成像应用中的潜力。

    Analyzing the dynamic changes of cellular morphology is important for understanding the various functions and characteristics of live cells, including stem cells and metastatic cancer cells. To this end, we need to track all points on the highly deformable cellular contour in every frame of live cell video. Local shapes and textures on the contour are not evident, and their motions are complex, often with expansion and contraction of local contour features. The prior arts for optical flow or deep point set tracking are unsuited due to the fluidity of cells, and previous deep contour tracking does not consider point correspondence. We propose the first deep learning-based tracking of cellular (or more generally viscoelastic materials) contours with point correspondence by fusing dense representation between two contours with cross attention. Since it is impractical to manually label dense tracking points on the contour, unsupervised learning comprised of the mechanical and cyclical cons
    
[^26]: 基于低秩张量分享的Tiny Ambient Speech Recognition模型

    Sharing Low Rank Conformer Weights for Tiny Always-On Ambient Speech Recognition Models. (arXiv:2303.08343v1 [eess.AS])

    [http://arxiv.org/abs/2303.08343](http://arxiv.org/abs/2303.08343)

    本论文提出了一种基于低秩张量分享的模型方法，将大型语音识别模型缩小至5M参数，同时实现了在低内存神经处理器边缘设备上的始终处于运行状态的语音识别。

    

    机器学习技术的持续改进为使用更大的模型和更大的训练数据集提供了令人兴奋的新机会。但是，在仅有低内存的智能手机、可穿戴设备和其他嵌入式环境等低功耗设备上提供这些新功能的需求与日俱增。为此，我们考虑了一些方法来减小基于Conformer的语音识别模型的模型大小，这些模型通常需要大于100M个参数的模型，将其缩小到仅$5$M个参数，同时最小化对模型质量的影响。这样的模型使我们能够在具有低内存神经处理器的边缘设备上实现始终处于运行状态的语音识别。我们提出在模型架构中的不同层次上重复使用模型权重: (i) 重复整个Conformer块层，(ii) 在层之间共享特定的Conformer模块，(iii) 在Conformer模块中共享子部件，(iv) 在低秩张量分解后共享分解的子部件权重。

    Continued improvements in machine learning techniques offer exciting new opportunities through the use of larger models and larger training datasets. However, there is a growing need to offer these new capabilities on-board low-powered devices such as smartphones, wearables and other embedded environments where only low memory is available. Towards this, we consider methods to reduce the model size of Conformer-based speech recognition models which typically require models with greater than 100M parameters down to just $5$M parameters while minimizing impact on model quality. Such a model allows us to achieve always-on ambient speech recognition on edge devices with low-memory neural processors. We propose model weight reuse at different levels within our model architecture: (i) repeating full conformer block layers, (ii) sharing specific conformer modules across layers, (iii) sharing sub-components per conformer module, and (iv) sharing decomposed sub-component weights after low-rank 
    
[^27]: FactReranker：基于事实引导的辅助评估器用于忠实的放射学报告摘要。

    FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization. (arXiv:2303.08335v1 [cs.CL])

    [http://arxiv.org/abs/2303.08335](http://arxiv.org/abs/2303.08335)

    FactReranker是一种新颖的辅助评估器，可以在保持摘要与放射学发现实况一致性的基础上，通过事实引导来有效地选择最佳的摘要。

    

    自动放射学报告摘要是一项至关重要的临床任务，其主要挑战在于保持所产生的摘要和地面实况放射学发现之间的实际准确性。现有研究采用强化学习来直接优化正确认知度量指标，如CheXBert或RadGraph分数。然而，它们使用贪婪搜索或束搜索的解码方法，在选择最佳候选项时没有考虑事实的一致性，从而导致实际一致性的改善受限。为了解决这个问题，我们提出了一种新颖的第二阶段摘要方法FactReranker，它是第一次尝试基于它们估计的实际一致性得分来学习从所有候选项中选择最佳摘要。我们建议基于RadGraph模式提取输入医疗报告、其黄金摘要和候选摘要的医疗事实，并设计基于事实引导的重新排序器，以有效地结合提取的医疗事实来选择最佳摘要。我们分解了事实-

    Automatic radiology report summarization is a crucial clinical task, whose key challenge is to maintain factual accuracy between produced summaries and ground truth radiology findings. Existing research adopts reinforcement learning to directly optimize factual consistency metrics such as CheXBert or RadGraph score. However, their decoding method using greedy search or beam search considers no factual consistency when picking the optimal candidate, leading to limited factual consistency improvement. To address it, we propose a novel second-stage summarizing approach FactReranker, the first attempt that learns to choose the best summary from all candidates based on their estimated factual consistency score. We propose to extract medical facts of the input medical report, its gold summary, and candidate summaries based on the RadGraph schema and design the fact-guided reranker to efficiently incorporate the extracted medical facts for selecting the optimal summary. We decompose the fact-
    
[^28]: 异构6G网络中联邦学习的优化设计

    Optimization Design for Federated Learning in Heterogeneous 6G Networks. (arXiv:2303.08322v1 [cs.LG])

    [http://arxiv.org/abs/2303.08322](http://arxiv.org/abs/2303.08322)

    联邦学习是实现6G网络人工智能普及的关键技术，但在6G网络中，存在一些系统和统计异构性挑战。本研究研究了能够有效解决这些异构性问题的优化方法。

    

    随着5G网络的快速发展，亿万智能物联网设备和庞大的数据在网络边缘生成。尽管仍处于早期阶段，但预计正在发展中的6G网络将采用先进的人工智能技术来收集、传输和学习这些宝贵的数据，以实现创新应用和智能服务。然而，传统的机器学习方法需要将训练数据集中到数据中心或云中，引发了严重的用户隐私问题。作为一种新兴的分布式人工智能范例，具有隐私保护性质的联邦学习被视为实现6G网络普遍应用人工智能的关键技术。然而，在6G网络中有效、高效地实现联邦学习仍存在一些系统和统计异构性挑战。本文探讨了能够有效解决这些异构性问题的优化方法。

    With the rapid advancement of 5G networks, billions of smart Internet of Things (IoT) devices along with an enormous amount of data are generated at the network edge. While still at an early age, it is expected that the evolving 6G network will adopt advanced artificial intelligence (AI) technologies to collect, transmit, and learn this valuable data for innovative applications and intelligent services. However, traditional machine learning (ML) approaches require centralizing the training data in the data center or cloud, raising serious user-privacy concerns. Federated learning, as an emerging distributed AI paradigm with privacy-preserving nature, is anticipated to be a key enabler for achieving ubiquitous AI in 6G networks. However, there are several system and statistical heterogeneity challenges for effective and efficient FL implementation in 6G networks. In this article, we investigate the optimization approaches that can effectively address the challenging heterogeneity issues
    
[^29]: 基于后训练量化的大型语言模型综合研究

    A Comprehensive Study on Post-Training Quantization for Large Language Models. (arXiv:2303.08302v1 [cs.LG])

    [http://arxiv.org/abs/2303.08302](http://arxiv.org/abs/2303.08302)

    本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。

    

    后训练量化是一种减少大型语言模型内存消耗和/或计算成本的权衡方法。然而，关于不同量化方案、不同模型族、不同后训练量化方法、不同量化位精度等的影响的全面研究仍缺失。本文通过数万个零-shot实验对这些组件进行了广泛的研究。我们的研究结果表明：(1)细粒度量化和后训练量化方法(而不是朴素的最近舍入量化)是实现良好精度的必要条件；(2) 用粗粒度量化的更高位数（如5位）比用非常细粒度的更低位数（如4位）（其有效位数与5位相似）更强大。我们还提出了如何为不同大小的\llms利用量化的建议，并留下未来机会和系统工作的建议。

    Post-training quantization (\ptq) had been recently shown as a compromising method to reduce the memory consumption and/or compute cost for large language models. However, a comprehensive study about the effect of different quantization schemes, different model families, different \ptq methods, different quantization bit precision, etc, is still missing. In this work, we provide an extensive study on those components over tens of thousands of zero-shot experiments. Our results show that (1) Fine-grained quantization and \ptq methods (instead of naive round-to-nearest quantization) are necessary to achieve good accuracy and (2) Higher bits (e.g., 5 bits) with coarse-grained quantization is more powerful than lower bits (e.g., 4 bits) with very fine-grained quantization (whose effective bits is similar to 5-bits). We also present recommendations about how to utilize quantization for \llms with different sizes, and leave suggestions of future opportunities and system work that are not res
    
[^30]: 学习高维网络物理数据流用于智能电网的故障诊断

    Learning From High-Dimensional Cyber-Physical Data Streams for Diagnosing Faults in Smart Grids. (arXiv:2303.08300v1 [cs.LG])

    [http://arxiv.org/abs/2303.08300](http://arxiv.org/abs/2303.08300)

    本文采用特征工程相结合的方法解决了网络物理电力系统数据质量、计算成本和冗余测量数据的问题，提高了故障诊断系统的性能。

    

    故障诊断系统的性能受网络物理电力系统数据质量的影响。这些系统产生大量数据，使系统承受过多的计算成本。另一个问题是记录测量中存在噪声，这可以防止构建精确的决策模型。此外，诊断模型通常配备了一组冗余测量数据，可能偏离正常和故障分布的学习。本文介绍了特征工程对于缓解网络物理系统中上述挑战的影响。特征选择和降维方法与决策模型相结合，模拟了对118个总线电力系统中的数据驱动故障诊断。因此，开展了比较研究，比较了两个领域中的几种先进技术。同时比较了降维和特征选择方法。最后，进行了实验验证。

    The performance of fault diagnosis systems is highly affected by data quality in cyber-physical power systems. These systems generate massive amounts of data that overburden the system with excessive computational costs. Another issue is the presence of noise in recorded measurements, which prevents building a precise decision model. Furthermore, the diagnostic model is often provided with a mixture of redundant measurements that may deviate it from learning normal and fault distributions. This paper presents the effect of feature engineering on mitigating the aforementioned challenges in cyber-physical systems. Feature selection and dimensionality reduction methods are combined with decision models to simulate data-driven fault diagnosis in a 118-bus power system. A comparative study is enabled accordingly to compare several advanced techniques in both domains. Dimensionality reduction and feature selection methods are compared both jointly and separately. Finally, experiments are con
    
[^31]: 在回收材料可持续化的敏捷制造中应用机器学习方法(arXiv:2303.08291v1 [cs.AI])

    Machine Learning Approaches in Agile Manufacturing with Recycled Materials for Sustainability. (arXiv:2303.08291v1 [cs.AI])

    [http://arxiv.org/abs/2303.08291](http://arxiv.org/abs/2303.08291)

    本文提出将回收再利用材料用于敏捷制造，应用机器学习模型进行预测分析，以决策支持实现环境可持续性。

    

    在材料科学和制造业中开发可持续的、环保的过程非常重要。人工智能在决策支持方面可以起到重要的作用，这一点已经在我们之前的研究中得以证明，通过我们提出的基于机器学习的方法开发的工具，可以用于计算估计和专家系统。本研究通过决策支持实现在材料科学中的环境可持续性，应用回收和再生材料进行敏捷制造，这是一种安全、负责任的将特定废弃物转变成增值产品的方式。我们建议使用数据驱动的AI方法，通过应用机器学习模型进行预测分析，以指导制造中的决策支持，包括利用人工神经网络研究影响材料热处理及其性能的参数，以及通过先进技术（如卷积神经网络）进行深度学习，来探索粒度大小对性能的影响。

    It is important to develop sustainable processes in materials science and manufacturing that are environmentally friendly. AI can play a significant role in decision support here as evident from our earlier research leading to tools developed using our proposed machine learning based approaches. Such tools served the purpose of computational estimation and expert systems. This research addresses environmental sustainability in materials science via decision support in agile manufacturing using recycled and reclaimed materials. It is a safe and responsible way to turn a specific waste stream to value-added products. We propose to use data-driven methods in AI by applying machine learning models for predictive analysis to guide decision support in manufacturing. This includes harnessing artificial neural networks to study parameters affecting heat treatment of materials and impacts on their properties; deep learning via advances such as convolutional neural networks to explore grain size
    
[^32]: 通过超球嵌入和基于角度的正则化提高对抗鲁棒性

    Improving Adversarial Robustness with Hypersphere Embedding and Angular-based Regularizations. (arXiv:2303.08289v1 [cs.LG])

    [http://arxiv.org/abs/2303.08289](http://arxiv.org/abs/2303.08289)

    本文提出了一种新的对抗训练方法，角度-AT，结合超球嵌入和基于角度的正则化技术以提高深度神经网络的对抗鲁棒性能。

    

    对抗训练（AT）方法已被证明对深度神经网络的对抗攻击具有一定效果。已经提出了许多AT的变体来改善其性能。 Pang等人最近表明，将超球嵌入（HE）纳入现有的AT过程中可以提高对抗性。我们观察到现有的AT过程并不是为HE框架设计的，因此未能充分学习HE框架中的角度判别信息。在本文中，我们提出将HE与利用HE框架中的丰富角度信息的正则化项目相结合，将其集成到AT中。具体而言，我们提出的方法称为角度AT，将正则化项目添加到AT中，并通过角度特征明确强制权重特征紧凑性和类间分隔。实验结果表明，角度AT进一步提高了对抗鲁棒性。

    Adversarial training (AT) methods have been found to be effective against adversarial attacks on deep neural networks. Many variants of AT have been proposed to improve its performance. Pang et al. [1] have recently shown that incorporating hypersphere embedding (HE) into the existing AT procedures enhances robustness. We observe that the existing AT procedures are not designed for the HE framework, and thus fail to adequately learn the angular discriminative information available in the HE framework. In this paper, we propose integrating HE into AT with regularization terms that exploit the rich angular information available in the HE framework. Specifically, our method, termed angular-AT, adds regularization terms to AT that explicitly enforce weight-feature compactness and inter-class separation; all expressed in terms of angular features. Experimental results show that angular-AT further improves adversarial robustness.
    
[^33]: 将替代燃料汽车的采用与社会经济地位和空气质量指数联系起来

    Linking Alternative Fuel Vehicles Adoption with Socioeconomic Status and Air Quality Index. (arXiv:2303.08286v1 [cs.AI])

    [http://arxiv.org/abs/2303.08286](http://arxiv.org/abs/2303.08286)

    该研究借助机器学习技术，探究替代燃料汽车的普及，同时将其与消费者的社会经济地位和空气质量指数进行关联，从而制定合适的政策。

    

    这是一项研究，研究替代燃料汽车的潜在广泛使用，将它们与相应消费者的社会经济地位以及对 resulting 空气质量指数的影响联系起来。该领域的研究旨在利用机器学习技术，以促进适当的政策，推广替代燃料汽车的普及，例如电动汽车，要公正对待不同的人群。该模型使用 Pearson 相关系数对社会经济数据、空气质量指数和替代燃料汽车的数据关系进行建模。基于社会经济因素，使用线性回归对空气质量指数进行预测建模，以根据替代燃料汽车的采用情况进行调整。这项工作证明了人工智能的社会价值。

    This is a study on the potential widespread usage of alternative fuel vehicles, linking them with the socio-economic status of the respective consumers as well as the impact on the resulting air quality index. Research in this area aims to leverage machine learning techniques in order to promote appropriate policies for the proliferation of alternative fuel vehicles such as electric vehicles with due justice to different population groups. Pearson correlation coefficient is deployed in the modeling the relationships between socio-economic data, air quality index and data on alternative fuel vehicles. Linear regression is used to conduct predictive modeling on air quality index as per the adoption of alternative fuel vehicles, based on socio-economic factors. This work exemplifies artificial intelligence for social good.
    
[^34]: 在风险与拥挤环境中的机器人导航：理解人类偏好

    Robot Navigation in Risky, Crowded Environments: Understanding Human Preferences. (arXiv:2303.08284v1 [cs.RO])

    [http://arxiv.org/abs/2303.08284](http://arxiv.org/abs/2303.08284)

    本文研究了在风险与拥挤环境下的机器人导航，通过探索人们在COVID-19疫情购物场景中的路径选择偏好，并评估三种流行的风险模型(CPT，CVaR和ER)，以更好地设计机器人导航可解释人工智能(XAI)。

    

    风险与拥挤环境(RCE)包含虚拟的风险和不确定性来源，而这些风险被不同的人感知为不同的行为，因此，在RCE中部署的机器人需要具备多样化的感知和规划能力，以解读其他人类的行为并在这些环境中做出相应的行动。为了了解这个问题域，我们进行了一个研究，探讨了在RCE中人类的路径选择，以便更好地设计机器人导航可解释人工智能(XAI)。我们创建了一个新的COVID-19大流行购物场景，其中包含时间风险权衡，获取了用户的路径偏好。我们发现参与者展示了各种路径首选项：从冒险与紧急到安全与放松。为了对用户的决策进行建模，我们评估了三种流行的风险模型(累积前景理论(CPT),条件价值风险(CVaR)和期望风险(ER))。我们发现，CPT比CVaR和ER更准确地捕捉到了人们的决策行为。

    Risky and crowded environments (RCE) contain abstract sources of risk and uncertainty, which are perceived differently by humans, leading to a variety of behaviors. Thus, robots deployed in RCEs, need to exhibit diverse perception and planning capabilities in order to interpret other human agents' behavior and act accordingly in such environments. To understand this problem domain, we conducted a study to explore human path choices in RCEs, enabling better robotic navigational explainable AI (XAI) designs. We created a novel COVID-19 pandemic grocery shopping scenario which had time-risk tradeoffs, and acquired users' path preferences. We found that participants showcase a variety of path preferences: from risky and urgent to safe and relaxed. To model users' decision making, we evaluated three popular risk models (Cumulative Prospect Theory (CPT), Conditional Value at Risk (CVAR), and Expected Risk (ER). We found that CPT captured people's decision making more accurately than CVaR and
    
[^35]: Act-Then-Measure: 带主动测量的部分可观察环境中的强化学习

    Act-Then-Measure: Reinforcement Learning for Partially Observable Environments with Active Measuring. (arXiv:2303.08271v1 [cs.AI])

    [http://arxiv.org/abs/2303.08271](http://arxiv.org/abs/2303.08271)

    本论文研究了对于代理有直接控制何时以及如何收集信息的能力的马尔可夫决策过程。我们引入了行动后测量 (ATM) 策略，并开发了一个基于 ATM 启发式方法的强化学习算法，展示了其在多个部分可观察环境上优于先前的方法的卓越性能。

    

    本研究研究了马尔可夫决策过程 (MDPs)，其中代理有直接控制何时以及如何收集信息的能力，如 action-contingent noiselessly observable MDPs (ACNO-MPDs) 所形式化。在这些模型中，动作由两个组成部分组成：影响环境的控制动作和影响代理可以观察到什么的测量动作。为了解决 ACNO-MDPs，我们引入了行动后测量 (ATM) 策略，它假设在选择控制动作时可以忽略未来状态的不确定性。我们展示了遵循此策略可能导致较短的策略计算时间，并证明了该启发式方法引起的性能丧失的界限。为了确定是否采取测量行动，我们引入了测量价值的概念。我们基于 ATM 启发式方法开发了一个强化学习算法，使用针对部分可观察域的 Dyna-Q 变体，并展示了它在多个部分可观察环境上优于先前的方法的卓越性能。

    We study Markov decision processes (MDPs), where agents have direct control over when and how they gather information, as formalized by action-contingent noiselessly observable MDPs (ACNO-MPDs). In these models, actions consist of two components: a control action that affects the environment, and a measurement action that affects what the agent can observe. To solve ACNO-MDPs, we introduce the act-then-measure (ATM) heuristic, which assumes that we can ignore future state uncertainty when choosing control actions. We show how following this heuristic may lead to shorter policy computation times and prove a bound on the performance loss incurred by the heuristic. To decide whether or not to take a measurement action, we introduce the concept of measuring value. We develop a reinforcement learning algorithm based on the ATM heuristic, using a Dyna-Q variant adapted for partially observable domains, and showcase its superior performance compared to prior methods on a number of partially-o
    
[^36]: 神经符号常识社会推理

    Neuro-symbolic Commonsense Social Reasoning. (arXiv:2303.08264v1 [cs.AI])

    [http://arxiv.org/abs/2303.08264](http://arxiv.org/abs/2303.08264)

    本文介绍了一种神经符号方法，将自然语言中的社交规则转换为一阶逻辑，并使用神经符号定理证明器进行推理。该方法展现了有希望的结果，可以用来进行对社交常识问题的明确推理。

    

    社会规范是所有人类社交互动的基础，但将其形式化并进行推理仍然是人工智能系统面临的主要挑战。本文提出了一个新颖的系统，从Social Chemistry 101数据集中以自然语言的形式获取社交规则，并将它们转换为一阶逻辑，使用神经符号定理证明器进行推理。我们通过几个步骤实现了这一目标。首先，将社交规则转换为抽象意义表示(AMR)，即一句话中概念的图形表示，并与RoBERTa嵌入对齐。然后，通过一种新颖的算法生成AMR的备用简化版本，重新组合和合并嵌入以增强对文本不同措辞和不正确的AMR解析的鲁棒性。然后将AMR转换为一阶逻辑，并使用神经符号定理证明器进行查询。本文旨在开发和评估一种神经符号方法，对自然语言中的常识规则进行明确的推理。我们的方法弥合了符号和神经方法在人工智能领域的差距，在一组社交常识问题上展现了有希望的结果。

    Social norms underlie all human social interactions, yet formalizing and reasoning with them remains a major challenge for AI systems. We present a novel system for taking social rules of thumb (ROTs) in natural language from the Social Chemistry 101 dataset and converting them to first-order logic where reasoning is performed using a neuro-symbolic theorem prover. We accomplish this in several steps. First, ROTs are converted into Abstract Meaning Representation (AMR), which is a graphical representation of the concepts in a sentence, and align the AMR with RoBERTa embeddings. We then generate alternate simplified versions of the AMR via a novel algorithm, recombining and merging embeddings for added robustness against different wordings of text, and incorrect AMR parses. The AMR is then converted into first-order logic, and is queried with a neuro-symbolic theorem prover. The goal of this paper is to develop and evaluate a neuro-symbolic method which performs explicit reasoning about
    
[^37]: 基于Transformer的深度学习体系结构在语境化药物信息提取中的应用

    Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures. (arXiv:2303.08259v1 [cs.CL])

    [http://arxiv.org/abs/2303.08259](http://arxiv.org/abs/2303.08259)

    本文使用Transformer预训练深度学习架构开发了NLP系统，可在临床笔记中提取药物及其上下文信息，并在药物信息提取任务中取得最先进的性能。

    

    目的：开发自然语言处理(NLP)系统，提取药物及有助于理解药物变化的上下文信息。方法：开发了三个NLP系统，包括药物提及提取、事件分类(指药物变化的讨论或未讨论)、以及分类药物变化上下文到5个与药物变化相关的正交维度。我们探索了6个最先进的预训练变压器模型，包括GatorTron，它是一个大型语言模型，预训练使用超过90亿个单词的文本(包括来自佛罗里达大学健康中心识别的2.9亿多个临床笔记中的超过80亿个单词)。我们使用2022 n2c2的注释数据和评估脚本来评估我们的NLP系统。结果：我们的GatorTron模型在药物提取、事件分类和上下文分类方面分别取得了最佳的 F1 分数，分别为 0.9828（排名第3）、0.9379（排名第1）、0.8375（排名第1），超过其他5个预训练模型。我们最佳的NLP系统在18个参赛团队中排名第二，获得了总体F1得分0.8774 。结论：基于Transformer的深度学习体系结构，如GatorTron，可以有效地从临床笔记中提取药物和上下文信息，并在药物信息提取任务中取得最先进的性能。

    Objective: To develop a natural language processing (NLP) system to extract medications and contextual information that help understand drug changes. This project is part of the 2022 n2c2 challenge.  Materials and methods: We developed NLP systems for medication mention extraction, event classification (indicating medication changes discussed or not), and context classification to classify medication changes context into 5 orthogonal dimensions related to drug changes. We explored 6 state-of-the-art pretrained transformer models for the three subtasks, including GatorTron, a large language model pretrained using >90 billion words of text (including >80 billion words from >290 million clinical notes identified at the University of Florida Health). We evaluated our NLP systems using annotated data and evaluation scripts provided by the 2022 n2c2 organizers.  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for medication extraction (ranked 3rd), 0.9379 for event classif
    
[^38]: NL4Opt 比赛：基于自然语言描述构建优化问题

    NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions. (arXiv:2303.08233v1 [cs.CL])

    [http://arxiv.org/abs/2303.08233](http://arxiv.org/abs/2303.08233)

    NL4Opt比赛旨在研究如何从自然语言描述中提取出优化问题的含义和表述，并通过自然语言与非专业人士进行交互。竞赛分为两个子任务：(1) 识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。

    

    自然语言优化（NL4Opt）竞赛旨在研究如何根据优化问题的文本描述提取其含义和表述的方法。具体而言，该竞赛的目标是通过使用自然语言中介来使非专业人士能够接口使用优化求解器，以增加其可访问性和可用性。我们将这一挑战性目标分为两个子任务：(1)识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。第一个任务旨在通过检测和标记优化问题的实体来减少歧义。第二个任务创建了一个线性规划(LP)问题的中间表示，该中间表示被转换为商用求解器可用的格式。在本报告中，我们介绍了LP单词问题数据集和NL4Opt比赛的共享任务，并总结了竞赛条目的结果。

    The Natural Language for Optimization (NL4Opt) Competition was created to investigate methods of extracting the meaning and formulation of an optimization problem based on its text description. Specifically, the goal of the competition is to increase the accessibility and usability of optimization solvers by allowing non-experts to interface with them using natural language. We separate this challenging goal into two sub-tasks: (1) recognize and label the semantic entities that correspond to the components of the optimization problem; (2) generate a meaning representation (i.e., a logical form) of the problem from its detected problem entities. The first task aims to reduce ambiguity by detecting and tagging the entities of the optimization problems. The second task creates an intermediate representation of the linear programming (LP) problem that is converted into a format that can be used by commercial solvers. In this report, we present the LP word problem dataset and shared tasks f
    
[^39]: DeepAxe: 一种用于探索DNN加速器的近似和可靠性权衡的框架

    DeepAxe: A Framework for Exploration of Approximation and Reliability Trade-offs in DNN Accelerators. (arXiv:2303.08226v1 [cs.LG])

    [http://arxiv.org/abs/2303.08226](http://arxiv.org/abs/2303.08226)

    DeepAxe是一个用于在DNN加速器的设计空间中考虑近似和可靠性权衡的框架，逼近可靠性关键的DNN，并提供一组Pareto最优的DNN实现设计空间。

    

    随着Deep Neural Networks（DNNs）在广泛的安全关键型应用中的作用正在扩大，新兴的DNN经历了计算能力方面的巨大增长。这增加了提高DNN加速器可靠性的必要性，同时降低硬件平台上的计算负担，即降低能耗和执行时间，提高DNN加速器的效率。因此，硬件性能（即区域、功率和延迟）与DNN加速器实现的可靠性之间的权衡变得至关重要，需要工具进行分析。在本文中，我们提出了一个框架DeepAxe，用于在考虑应用功能近似对准确度、可靠性和硬件性能的三方影响的情况下，对基于FPGA的DNN实现进行设计空间探索。该框架使得对于关键可靠性的DNN进行有选择的逼近，提供了一组Pareto最优的DNN实现设计空间。

    While the role of Deep Neural Networks (DNNs) in a wide range of safety-critical applications is expanding, emerging DNNs experience massive growth in terms of computation power. It raises the necessity of improving the reliability of DNN accelerators yet reducing the computational burden on the hardware platforms, i.e. reducing the energy consumption and execution time as well as increasing the efficiency of DNN accelerators. Therefore, the trade-off between hardware performance, i.e. area, power and delay, and the reliability of the DNN accelerator implementation becomes critical and requires tools for analysis. In this paper, we propose a framework DeepAxe for design space exploration for FPGA-based implementation of DNNs by considering the trilateral impact of applying functional approximation on accuracy, reliability and hardware performance. The framework enables selective approximation of reliability-critical DNNs, providing a set of Pareto-optimal DNN implementation design spac
    
[^40]: 基于图变换器的 GANs 用于图约束房屋生成

    Graph Transformer GANs for Graph-Constrained House Generation. (arXiv:2303.08225v1 [cs.CV])

    [http://arxiv.org/abs/2303.08225](http://arxiv.org/abs/2303.08225)

    本文提出了一种基于图变换器生成对抗网络的方法，通过连接节点和非连接节点的全局关系以及基于房屋布局拓扑的本地顶点交互，实现了图约束房屋的端到端生成。

    

    本文提出了一种新颖的图变换器生成对抗网络 (GTGAN)，以学习端到端的有效图节点关系，以解决具有挑战性的图约束房屋生成任务。所提出的基于图变换器的生成器，包括一种新颖的图变换器编码器，它结合了 Transformer 中的图卷积和自注意力机制，以对连接和非连接图节点间的本地和全局交互进行建模。具体而言，所提出的连接节点注意力 (CNA) 和非连接节点注意力 (NNA) 旨在捕捉输入图中连接节点和非连接节点之间的全局关系。所提出的图建模块 (GMB) 旨在利用基于房屋布局拓扑的本地顶点交互。此外，我们提出了一种基于节点分类的新型鉴别器，以保留不同房屋组件的高层语义和判别性节点特征。最后，我们提出一种新的基于图的循环一致性损失，通过循环生成和重构来增强 GTGAN 的学习。

    We present a novel graph Transformer generative adversarial network (GTGAN) to learn effective graph node relations in an end-to-end fashion for the challenging graph-constrained house generation task. The proposed graph-Transformer-based generator includes a novel graph Transformer encoder that combines graph convolutions and self-attentions in a Transformer to model both local and global interactions across connected and non-connected graph nodes. Specifically, the proposed connected node attention (CNA) and non-connected node attention (NNA) aim to capture the global relations across connected nodes and non-connected nodes in the input graph, respectively. The proposed graph modeling block (GMB) aims to exploit local vertex interactions based on a house layout topology. Moreover, we propose a new node classification-based discriminator to preserve the high-level semantic and discriminative node features for different house components. Finally, we propose a novel graph-based cycle-co
    
[^41]: 使用场地不可知元学习和脑部MRI进行自闭症谱系障碍的少样本分类

    Few-Shot Classification of Autism Spectrum Disorder using Site-Agnostic Meta-Learning and Brain MRI. (arXiv:2303.08224v1 [eess.IV])

    [http://arxiv.org/abs/2303.08224](http://arxiv.org/abs/2303.08224)

    本文研究了针对自闭症谱系障碍的场地不可知元学习模型在少样本情况下的表现，使用在多个站点的MRI数据训练出的模型，实现对病人和正常人的快速识别分类。

    

    对于医学影像中的机器学习应用，由于训练数据可用性有限，设计针对细微病情（如自闭症谱系障碍）的放射学分类器受到阻碍。迁移学习是解决低训练数据问题的一种方法。本文探讨在具有多个站点的先前数据的情况下使用元学习的使用，即我们称之为场地不可知元学习的方法，用于非常低数据制度的情况。受到元学习在优化模型跨多个任务方面的有效性的启发，我们提出了一个框架，使其适应于不同站点之间的学习。我们在来自38个影像站点的2,201个T1加权（T1-w）MRI扫描中测试了我们的元学习模型，这些数据是作为自闭症脑部影像数据交换（ABIDE）的一部分收集的（年龄：5.2-64.0岁）。该方法被训练为查找一个良好的初始状态，以便快速适应新的未见数据。

    For machine learning applications in medical imaging, the availability of training data is often limited, which hampers the design of radiological classifiers for subtle conditions such as autism spectrum disorder (ASD). Transfer learning is one method to counter this problem of low training data regimes. Here we explore the use of meta-learning for very low data regimes in the context of having prior data from multiple sites - an approach we term site-agnostic meta-learning. Inspired by the effectiveness of meta-learning for optimizing a model across multiple tasks, here we propose a framework to adapt it to learn across multiple sites. We tested our meta-learning model for classifying ASD versus typically developing controls in 2,201 T1-weighted (T1-w) MRI scans collected from 38 imaging sites as part of Autism Brain Imaging Data Exchange (ABIDE) [age: 5.2-64.0 years]. The method was trained to find a good initialization state for our model that can quickly adapt to data from new uns
    
[^42]: 用于阿尔茨海默病检测的结构性MRI扫描的Vision Transformers高效训练

    Efficiently Training Vision Transformers on Structural MRI Scans for Alzheimer's Disease Detection. (arXiv:2303.08216v1 [eess.IV])

    [http://arxiv.org/abs/2303.08216](http://arxiv.org/abs/2303.08216)

    本文尝试使用Vision Transformers对基于MRI扫描的性别和AD分类任务进行了测试，其中两种ViT架构变体分别实现了0.987的性别分类AUC和0.892的AD分类AUC。该方法可为大规模神经影像学识别提供高效解决方案。

    

    大规模人群神经影像学对于识别促进或抵抗脑疾病的因素以及协助诊断、亚型分类和预后都具有价值。本文尝试使用Vision Transformers(ViT)对基于难度调整的一系列神经影像学任务进行了测试，包括性别和阿尔茨海默病(AD)基于3D大脑MRI的分类。在实验中，两种ViT架构变体分别实现了0.987的性别分类AUC和0.892的AD分类AUC。我们独立评估了模型在两个基准AD数据集上的性能，并获得了5%和9-10%的性能提升。

    Neuroimaging of large populations is valuable to identify factors that promote or resist brain disease, and to assist diagnosis, subtyping, and prognosis. Data-driven models such as convolutional neural networks (CNNs) have increasingly been applied to brain images to perform diagnostic and prognostic tasks by learning robust features. Vision transformers (ViT) - a new class of deep learning architectures - have emerged in recent years as an alternative to CNNs for several computer vision applications. Here we tested variants of the ViT architecture for a range of desired neuroimaging downstream tasks based on difficulty, in this case for sex and Alzheimer's disease (AD) classification based on 3D brain MRI. In our experiments, two vision transformer architecture variants achieved an AUC of 0.987 for sex and 0.892 for AD classification, respectively. We independently evaluated our models on data from two benchmark AD datasets. We achieved a performance boost of 5% and 9-10% upon fine-t
    
[^43]: 遗忘是否是前向迁移的良好归纳偏差？

    Is forgetting less a good inductive bias for forward transfer?. (arXiv:2303.08207v1 [cs.LG])

    [http://arxiv.org/abs/2303.08207](http://arxiv.org/abs/2303.08207)

    本文提出对于持续学习任务来说，遗忘不是一种良好的归纳偏差。之前的研究没有考虑到前向迁移的量度方式，本文提出了一种新的量度方式，发现较不遗忘的模型具有更好的性能。

    

    持续学习的主要动机之一是，该问题设置允许模型从过去的任务中积累知识以更有效地学习新任务。然而，最近的研究表明，持续学习算法所优化的关键指标，即减少灾难性遗忘，并不与前向知识迁移相关。我们认为之前的研究结论是由于他们衡量前向迁移的方式所致。我们认为，衡量一个任务的前向迁移不应受到为保留先前任务知识而对持续学习器施加的限制的影响。相反，前向迁移应该通过持续学习产生的一组表示来评估给定一个新任务有多容易学习。在这种前向迁移概念下，我们评估了不同的持续学习算法在各种图像分类基准测试中的表现。我们的结果表明，较不遗忘的模型具有更好的性能，特别是当训练数据数量少时。

    One of the main motivations of studying continual learning is that the problem setting allows a model to accrue knowledge from past tasks to learn new tasks more efficiently. However, recent studies suggest that the key metric that continual learning algorithms optimize, reduction in catastrophic forgetting, does not correlate well with the forward transfer of knowledge. We believe that the conclusion previous works reached is due to the way they measure forward transfer. We argue that the measure of forward transfer to a task should not be affected by the restrictions placed on the continual learner in order to preserve knowledge of previous tasks. Instead, forward transfer should be measured by how easy it is to learn a new task given a set of representations produced by continual learning on previous tasks. Under this notion of forward transfer, we evaluate different continual learning algorithms on a variety of image classification benchmarks. Our results indicate that less forgetf
    
[^44]: 视觉艺术推荐的要素：学习画作的潜在语义表征

    The Elements of Visual Art Recommendation: Learning Latent Semantic Representations of Paintings. (arXiv:2303.08182v1 [cs.IR])

    [http://arxiv.org/abs/2303.08182](http://arxiv.org/abs/2303.08182)

    本文研究了如何高效地捕捉视觉艺术的元素，提出了结合文本和视觉特征学习技术的推荐系统，用于个性化艺术品推荐，结果显示两者的结合可以捕捉最合适的隐藏语义关系。

    

    艺术品推荐具有挑战性，因为它需要理解用户如何与高度主观的内容互动，艺术品中嵌入的概念的复杂性，以及它们可能引起用户的情感和认知反应。本文重点研究如何高效地捕捉视觉艺术的元素（即潜在语义关系），以进行个性化推荐。我们提出并研究了基于文本和视觉特征学习技术以及它们的组合的推荐系统。我们对推荐质量进行了小规模和大规模的用户中心评估。我们的结果表明，文本特征比视觉特征表现更好，而两者的结合可以捕捉艺术品推荐最合适的隐藏语义关系。最终，本文有助于理解如何提供适合用户兴趣和感知的内容。

    Artwork recommendation is challenging because it requires understanding how users interact with highly subjective content, the complexity of the concepts embedded within the artwork, and the emotional and cognitive reflections they may trigger in users. In this paper, we focus on efficiently capturing the elements (i.e., latent semantic relationships) of visual art for personalized recommendation. We propose and study recommender systems based on textual and visual feature learning techniques, as well as their combinations. We then perform a small-scale and a large-scale user-centric evaluation of the quality of the recommendations. Our results indicate that textual features compare favourably with visual ones, whereas a fusion of both captures the most suitable hidden semantic relationships for artwork recommendation. Ultimately, this paper contributes to our understanding of how to deliver content that suitably matches the user's interests and how they are perceived.
    
[^45]: MEDBERT.de：一个基于德语的、针对医学领域专门设计的全面BERT模型

    MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain. (arXiv:2303.08179v1 [cs.CL])

    [http://arxiv.org/abs/2303.08179](http://arxiv.org/abs/2303.08179)

    本文介绍了medBERT.de，这是一个用于德语医学领域的BERT模型，通过在大规模语料库上的训练，在八个不同的医学基准测试中取得最新的最先进的表现。该模型对长文本特别有用，而数据去重和有效的分词则只对模型性能产生了较小的影响。

    

    本文介绍了medBERT.de，这是一个针对德语医学领域专门设计的预训练BERT模型。该模型已经在470万份德语医学文档的大型语料库上进行了训练，并在八个不同的医学基准测试中取得了新的最先进的效果，涉及各种学科和医学文献类型。除了评估该模型的整体性能外，本文还对其能力进行了更深入的分析。我们研究了数据去重对模型性能的影响，以及使用更有效的分词方法的潜在好处。我们的结果表明，像medBERT.de这样的领域专用模型特别适用于较长的文本，并且数据去重不一定会导致性能改善。此外，我们发现有效的分词只在提高模型性能方面发挥了较小的作用，并且大多数改进源于模型的预训练。

    This paper presents medBERT.de, a pre-trained German BERT model specifically designed for the German medical domain. The model has been trained on a large corpus of 4.7 Million German medical documents and has been shown to achieve new state-of-the-art performance on eight different medical benchmarks covering a wide range of disciplines and medical document types. In addition to evaluating the overall performance of the model, this paper also conducts a more in-depth analysis of its capabilities. We investigate the impact of data deduplication on the model's performance, as well as the potential benefits of using more efficient tokenization methods. Our results indicate that domain-specific models such as medBERT.de are particularly useful for longer texts, and that deduplication of training data does not necessarily lead to improved performance. Furthermore, we found that efficient tokenization plays only a minor role in improving model performance, and attribute most of the improved
    
[^46]: 平等AI研究圆桌会议（EARR）：朝向社区决策的AI负责任开发

    The Equitable AI Research Roundtable (EARR): Towards Community-Based Decision Making in Responsible AI Development. (arXiv:2303.08177v1 [cs.AI])

    [http://arxiv.org/abs/2303.08177](http://arxiv.org/abs/2303.08177)

    本文介绍了平等AI研究圆桌会议（EARR），EARR为AI技术的道德和社会伤害提供关键研究视角和反馈，并提出了三个原则：扩大AI开发的专业知识范围，促进知识好奇心和责任，以及创造相互学习的空间。

    

    本文报道了我们对平等AI研究圆桌会议（EARR）的初步评估 —— 一个由法律、教育、社区参与、社会正义和技术专家组成的联盟。EARR是由大型科技公司、非营利组织、NGO研究机构和大学合作创建的，旨在提供关于技术新兴的道德和社会伤害的关键研究视角和反馈。通过半结构化的研讨会和在大型科技公司中的讨论，EARR提供了关于如何将公平和脆弱性与AI技术相关联的关键观点和反馈。我们概述了EARR迄今为止操作的三个原则，这些原则与FAccT社区的关注特别相关：如何扩大AI开发中的专业知识范围，如何促进知识好奇心和责任，以及如何创造相互学习的空间。本文既是分析又是翻译。

    This paper reports on our initial evaluation of The Equitable AI Research Roundtable -- a coalition of experts in law, education, community engagement, social justice, and technology. EARR was created in collaboration among a large tech firm, nonprofits, NGO research institutions, and universities to provide critical research based perspectives and feedback on technology's emergent ethical and social harms. Through semi-structured workshops and discussions within the large tech firm, EARR has provided critical perspectives and feedback on how to conceptualize equity and vulnerability as they relate to AI technology. We outline three principles in practice of how EARR has operated thus far that are especially relevant to the concerns of the FAccT community: how EARR expands the scope of expertise in AI development, how it fosters opportunities for epistemic curiosity and responsibility, and that it creates a space for mutual learning. This paper serves as both an analysis and translatio
    
[^47]: 打破常识：WHOOPS！一个基于合成和组合图像的视觉与语言基准测试

    Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images. (arXiv:2303.07274v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07274](http://arxiv.org/abs/2303.07274)

    WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。

    

    奇怪、异常和神秘的图像会引起观察者的好奇心，因为它们挑战了常识。我们提出WHOOPS！一个新的视觉常识数据集和基准测试。该数据集由设计师使用Midjourney等公共可用图像生成工具制作，并包含若干个任务。除了图像字幕、跨模态匹配和视觉问答之外，我们还引入了一个困难的解释生成任务，其中模型必须识别并解释给定图像的异常之处。

    Weird, unusual, and uncanny images pique the curiosity of observers because they challenge commonsense. For example, an image released during the 2022 world cup depicts the famous soccer stars Lionel Messi and Cristiano Ronaldo playing chess, which playfully violates our expectation that their competition should occur on the football field. Humans can easily recognize and interpret these unconventional images, but can AI models do the same? We introduce WHOOPS!, a new dataset and benchmark for visual commonsense. The dataset is comprised of purposefully commonsense-defying images created by designers using publicly-available image generation tools like Midjourney. We consider several tasks posed over the dataset. In addition to image captioning, cross-modal matching, and visual question answering, we introduce a difficult explanation generation task, where models must identify and explain why a given image is unusual. Our results show that state-of-the-art models such as GPT3 and BLIP2
    
[^48]: 可解释的异常值汇总

    Interpretable Outlier Summarization. (arXiv:2303.06261v1 [cs.LG])

    [http://arxiv.org/abs/2303.06261](http://arxiv.org/abs/2303.06261)

    STAIR提出了一种可解释的异常值汇总方法，通过学习一组紧凑的人类可理解规则，以汇总和解释异常检测结果，具有强大的可解释性，以准确地总结检测结果。

    STAIR proposes an interpretable outlier summarization method by learning a compact set of human understandable rules to summarize and explain the anomaly detection results, which has strong interpretability to accurately summarize the detection results.

    异常值检测在实际应用中是至关重要的，以防止金融欺诈、防御网络入侵或检测即将发生的设备故障。为了减少人力评估异常值检测结果的工作量，并有效地将异常值转化为可操作的见解，用户通常希望系统自动产生可解释的异常值检测结果的子组的汇总。然而，到目前为止，没有这样的系统存在。为了填补这一空白，我们提出了STAIR，它学习了一组紧凑的人类可理解规则，以汇总和解释异常检测结果。STAIR不使用经典的决策树算法来产生这些规则，而是提出了一个新的优化目标，以产生少量规则，具有最小的复杂性，因此具有强大的可解释性，以准确地总结检测结果。STAIR的学习算法通过迭代分割大规则来产生规则集，并在每个i中最大化这个目标，是最优的。

    Outlier detection is critical in real applications to prevent financial fraud, defend network intrusions, or detecting imminent device failures. To reduce the human effort in evaluating outlier detection results and effectively turn the outliers into actionable insights, the users often expect a system to automatically produce interpretable summarizations of subgroups of outlier detection results. Unfortunately, to date no such systems exist. To fill this gap, we propose STAIR which learns a compact set of human understandable rules to summarize and explain the anomaly detection results. Rather than use the classical decision tree algorithms to produce these rules, STAIR proposes a new optimization objective to produce a small number of rules with least complexity, hence strong interpretability, to accurately summarize the detection results. The learning algorithm of STAIR produces a rule set by iteratively splitting the large rules and is optimal in maximizing this objective in each i
    
[^49]: 带有双向先验模型的向量量化时间序列生成

    Vector Quantized Time Series Generation with a Bidirectional Prior Model. (arXiv:2303.04743v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04743](http://arxiv.org/abs/2303.04743)

    本文提出了一种新的时间序列生成方法，使用向量量化技术和双向变压器模型来生成质量更好、模块化变化更快的合成信号。

    

    时间序列生成研究主要集中在使用生成对抗网络（GAN）与递归神经网络（RNN）变体相结合。然而，训练 GAN 的基本限制和挑战仍然存在。此外，RNN族通常在远程时间步之间的时间一致性方面存在困难。受到图像生成领域成功的启发，我们提出 TimeVQVAE，这是我们所知道的第一个使用向量量化（VQ）技术解决 TSG 问题的工作。此外，离散潜在空间的先验使用双向变压器模型进行学习，可以更好地捕捉全局时间一致性。我们还提出在时间 - 频率域中进行 VQ 建模，分为低频（LF）和高频（HF）。这使我们能够保留时间序列的重要特征，并生成质量更好、模块性变化更快的新合成信号。

    Time series generation (TSG) studies have mainly focused on the use of Generative Adversarial Networks (GANs) combined with recurrent neural network (RNN) variants. However, the fundamental limitations and challenges of training GANs still remain. In addition, the RNN-family typically has difficulties with temporal consistency between distant timesteps. Motivated by the successes in the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our knowledge, that uses vector quantization (VQ) techniques to address the TSG problem. Moreover, the priors of the discrete latent spaces are learned with bidirectional transformer models that can better capture global temporal consistency. We also propose VQ modeling in a time-frequency domain, separated into low-frequency (LF) and high-frequency (HF). This allows us to retain important characteristics of the time series and, in turn, generate new synthetic signals that are of better quality, with sharper changes in modularity, t
    
[^50]: 自主水下车体设计的约束贝叶斯优化

    Constrained Bayesian Optimization for Automatic Underwater Vehicle Hull Design. (arXiv:2302.14732v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.14732](http://arxiv.org/abs/2302.14732)

    本文研究了自主水下载体的优化设计问题，通过集成FreeCAD和OpenFoam等工具进行自动化设计评估，并采用贝叶斯优化算法解决了优化中样本效率的问题。

    

    自主水下车体设计优化是一个复杂的工程过程，旨在满足给定要求生成具有优化特性的UUV载体。首先，它涉及集成相关的复杂工程仿真工具。其次，它需要将样本有效的优化框架与集成工具链相结合。为此，我们将称为FreeCAD的CAD工具与CFD工具openFoam集成，以进行自动化设计评估。我们选择了贝叶斯优化（BO）进行优化，这是一种为优化耗时昂贵的工程模拟而开发的众所周知的技术，在多种问题中已证明具有非常高的样本效率，包括超参数调整和实验设计。在优化过程中，我们可以将不可行设计作为约束集成到优化过程中。通过将领域专用工具链与基于AI的优化相结合，我们执行了自动设计优化。

    Automatic underwater vehicle hull Design optimization is a complex engineering process for generating a UUV hull with optimized properties on a given requirement. First, it involves the integration of involved computationally complex engineering simulation tools. Second, it needs integration of a sample efficient optimization framework with the integrated toolchain. To this end, we integrated the CAD tool called FreeCAD with CFD tool openFoam for automatic design evaluation. For optimization, we chose Bayesian optimization (BO), which is a well-known technique developed for optimizing time-consuming expensive engineering simulations and has proven to be very sample efficient in a variety of problems, including hyper-parameter tuning and experimental design. During the optimization process, we can handle infeasible design as constraints integrated into the optimization process. By integrating domain-specific toolchain with AI-based optimization, we executed the automatic design optimiza
    
[^51]: 你是指哪一个？基于情境对话的多模态对象识别

    Which One Are You Referring To? Multimodal Object Identification in Situated Dialogue. (arXiv:2302.14680v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14680](http://arxiv.org/abs/2302.14680)

    本文探索了三种多模态对象识别方法并在SIMMC 2.1数据集上进行了评估。最佳方法是基于场景对话的对齐，相比基准测试提高了约20%的F1分数。

    

    多模态对话系统的需求在各个领域都有不断上升，这强调了从对话和情境背景中理解多模态信息的重要性。我们探索了三种方法来解决这个问题，并在最大的情境对话数据集SIMMC 2.1上对它们进行了评估。我们最好的方法是基于场景对话的对齐，相比SIMMC 2.1的基准测试，它提高了约20%的F1分数。我们提供了分析和讨论我们方法的局限性和未来工作的潜在方向。我们的代码公开在https://github.com/holylovenia/multimodal-object-identification中。

    The demand for multimodal dialogue systems has been rising in various domains, emphasizing the importance of interpreting multimodal inputs from conversational and situational contexts. We explore three methods to tackle this problem and evaluate them on the largest situated dialogue dataset, SIMMC 2.1. Our best method, scene-dialogue alignment, improves the performance by ~20% F1-score compared to the SIMMC 2.1 baselines. We provide analysis and discussion regarding the limitation of our methods and the potential directions for future works. Our code is publicly available at https://github.com/holylovenia/multimodal-object-identification.
    
[^52]: 机器人群体对连续环境的估计：相关网络和决策制定

    Estimation of continuous environments by robot swarms: Correlated networks and decision-making. (arXiv:2302.13629v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.13629](http://arxiv.org/abs/2302.13629)

    本论文研究了机器人群体对连续环境的估计任务，并提出了一种控制算法。其独特之处在于动态网络拓扑和决策制定之间存在因果循环，影响着精度和收敛时间。

    

    集体决策是建立在群体层面上的大规模多机器人系统的关键能力。群体机器人集体决策的大部分文献都集中在从有限数量的选项中进行的离散决策上。在这里，我们将一个分散式机器人系统的任务分配为探索无界环境，找出可测环境特征的平均值并汇总至那个值被测量的区域（例如，等高线）。该任务的独特性在于机器人的动态网络拓扑和它们的决策制定之间存在因果循环。例如，网络的平均节点度数影响收敛时间，而当前已认同的平均值影响群体的汇聚位置，因此，也影响网络结构以及精度误差。我们提出了一种控制算法，并在不同环境中进行了实际机器人群体实验来研究它。

    Collective decision-making is an essential capability of large-scale multi-robot systems to establish autonomy on the swarm level. A large portion of literature on collective decision-making in swarm robotics focuses on discrete decisions selecting from a limited number of options. Here we assign a decentralized robot system with the task of exploring an unbounded environment, finding consensus on the mean of a measurable environmental feature, and aggregating at areas where that value is measured (e.g., a contour line). A unique quality of this task is a causal loop between the robots' dynamic network topology and their decision-making. For example, the network's mean node degree influences time to convergence while the currently agreed-on mean value influences the swarm's aggregation location, hence, also the network structure as well as the precision error. We propose a control algorithm and study it in real-world robot swarm experiments in different environments. We show that our a
    
[^53]: 深度学习在自主导航中的应用与方法的最新进展--综述

    Recent Advancements in Deep Learning Applications and Methods for Autonomous Navigation -- A Comprehensive Review. (arXiv:2302.11089v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.11089](http://arxiv.org/abs/2302.11089)

    本综述论文介绍了自主导航领域中最新的深度学习应用和方法，包括障碍检测、场景感知、路径规划和控制。突出了深度学习在工程数据科学中的快速发展，以及创新导航方法的开发和跨学科研究的重要性和挑战。

    

    本综述论文全面介绍了在自主导航背景下使用的端到端深度学习框架，包括障碍物检测、场景感知、路径规划和控制。该论文旨在通过分析最近的研究成果并评估深度学习方法的实施和测试来弥合自主导航和深度学习之间的鸿沟。重点强调了导航对于移动机器人、自主车辆和无人机的重要性，同时也认识到由于环境复杂性、不确定性、障碍物、动态环境以及规划多个智能体的路径的需要而带来的挑战。本综述突出深度学习在工程数据科学中的快速发展以及其创新导航方法的发展，讨论了与本领域相关的近期跨学科研究，并对深度学习的局限性、挑战和潜在增长领域提出了简要展望。

    This review paper presents a comprehensive overview of end-to-end deep learning frameworks used in the context of autonomous navigation, including obstacle detection, scene perception, path planning, and control. The paper aims to bridge the gap between autonomous navigation and deep learning by analyzing recent research studies and evaluating the implementation and testing of deep learning methods. It emphasizes the importance of navigation for mobile robots, autonomous vehicles, and unmanned aerial vehicles, while also acknowledging the challenges due to environmental complexity, uncertainty, obstacles, dynamic environments, and the need to plan paths for multiple agents. The review highlights the rapid growth of deep learning in engineering data science and its development of innovative navigation methods. It discusses recent interdisciplinary work related to this field and provides a brief perspective on the limitations, challenges, and potential areas of growth for deep learning m
    
[^54]: DrasCLR: 一个用于学习疾病相关和解剖特异性表示的自监督框架，适用于三维医学图像

    DrasCLR: A Self-supervised Framework of Learning Disease-related and Anatomy-specific Representation for 3D Medical Images. (arXiv:2302.10390v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.10390](http://arxiv.org/abs/2302.10390)

    DrasCLR是一个自监督框架，通过提出两种领域特定的对比学习策略来学习疾病相关和解剖特异性表示，特别是解决了区分疾病模式和解剖特征的挑战。

    

    由于大规模带注释的体积医学图像的获取成本高昂，因此自监督学习（SSL）为许多下游任务提供了一种有前途的预训练和特征提取解决方案，因为它仅使用未标记数据。最近，基于实例区分的SSL方法在医学成像领域变得流行。然而，SSL预训练编码器可能使用许多图像线索来区分一个实例，而这些线索不一定与疾病相关。此外，病理模式常常很微妙和异质，需要所需方法能够表示对不同身体部位中的异常变化敏感的解剖特异性特征。本文提出了一个名为DrasCLR的新的SSL框架，用于三维医学成像，以克服这些挑战。我们提出了两种领域特定的对比学习策略：一种旨在捕捉局部解剖区域内微妙疾病模式，另一种旨在识别具有不同挑战性的解剖区域间的疾病相关特征。

    Large-scale volumetric medical images with annotation are rare, costly, and time prohibitive to acquire. Self-supervised learning (SSL) offers a promising pre-training and feature extraction solution for many downstream tasks, as it only uses unlabeled data. Recently, SSL methods based on instance discrimination have gained popularity in the medical imaging domain. However, SSL pre-trained encoders may use many clues in the image to discriminate an instance that are not necessarily disease-related. Moreover, pathological patterns are often subtle and heterogeneous, requiring the ability of the desired method to represent anatomy-specific features that are sensitive to abnormal changes in different body parts. In this work, we present a novel SSL framework, named DrasCLR, for 3D medical imaging to overcome these challenges. We propose two domain-specific contrastive learning strategies: one aims to capture subtle disease patterns inside a local anatomical region, and the other aims to r
    
[^55]: 应用CFD寻找水下航行器的最小阻力设计

    Search for universal minimum drag resistance underwater vehicle hull using CFD. (arXiv:2302.09441v2 [cs.CE] UPDATED)

    [http://arxiv.org/abs/2302.09441](http://arxiv.org/abs/2302.09441)

    本文利用CFD模拟和优化算法，研究最小化阻力的水下航行器设计方案。初步结果表明，不存在可以适应所有运行和环境条件的通用设计，但在高速和高湍流条件下找到了接近最佳设计的方案。

    

    在自主水下航行器（AUV）设计中，船身阻力是确定车辆功率需求和航程的重要因素，进而影响设计中电池大小、重量和体积要求。本文利用基于人工智能的优化算法和计算流体动力学（CFD）模拟，研究最小化阻力的最佳船体设计。通过在不同的运行速度和湍流强度下运行基于CFD的优化，我们希望研究/搜索可在所有操作条件（操作速度）和环境条件（湍流强度）下提供最小阻力/接近最佳设计的通用设计的可能性。初步结果表明，在低速和低湍流条件下找到的最佳设计在高速和高湍流条件下表现非常差。然而，在高速和高湍流条件下最佳的设计表现接近优秀。

    In Autonomous Underwater Vehicles (AUVs) design, hull resistance is an important factor in determining the power requirements and range of vehicle and consequently affect battery size, weight, and volume requirement of the design. In this paper, we leverage on AI-based optimization algorithm along with Computational Fluid Dynamics (CFD) simulation to study the optimal hull design that minimizing the resistance. By running the CFD-based optimization at different operating velocities and turbulence intensity, we want to study/search the possibility of a universal design that will provide least resistance/near-optimal design across all operating conditions (operating velocity) and environmental conditions (turbulence intensity). Early result demonstrated that the optimal design found at low velocity and low turbulence condition performs very poor at high velocity and high turbulence conditions. However, a design that is optimal at high velocity and high turbulence conditions performs near
    
[^56]: SoftMatch：解决半监督学习中的数量-质量权衡问题

    SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning. (arXiv:2301.10921v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10921](http://arxiv.org/abs/2301.10921)

    本文提出了SoftMatch，通过在训练中保持高数量和高质量的伪标签来克服半监督学习中数量-质量权衡问题，有效地利用未标注的数据。 在实验中，SoftMatch在图像、文本和影片等多个基准测试中都显示了实质性的改进。

    

    半监督学习的关键挑战是如何有效利用有限的标注数据和大量的未标注数据提高模型的泛化性能。本文首先通过统一的样本加权公式重新审视了流行的伪标签方法，并演示了伪标签阈值法固有的数量-质量权衡问题，可能会阻碍学习。为此，我们提出了SoftMatch，通过在训练期间保持伪标签的高数量和高质量来克服这种权衡，有效地利用未标注的数据。我们推导出一个截断的高斯函数来根据样本的置信度对样本进行加权，这可以看作是置信度阈值的软版本。我们进一步通过提出统一的对齐方法来增强对弱学习类的利用。在实验中，SoftMatch在包括图像、文本和影片等各种基准测试中显示出了实质性的改进。

    The critical challenge of Semi-Supervised Learning (SSL) is how to effectively leverage the limited labeled data and massive unlabeled data to improve the model's generalization performance. In this paper, we first revisit the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrate the inherent quantity-quality trade-off problem of pseudo-labeling with thresholding, which may prohibit learning. To this end, we propose SoftMatch to overcome the trade-off by maintaining both high quantity and high quality of pseudo-labels during training, effectively exploiting the unlabeled data. We derive a truncated Gaussian function to weight samples based on their confidence, which can be viewed as a soft version of the confidence threshold. We further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. In experiments, SoftMatch shows substantial improvements across a wide variety of benchmarks, including image, text, and im
    
[^57]: 带有时间的生成逻辑：超越逻辑一致性和统计可能性

    Generative Logic with Time: Beyond Logical Consistency and Statistical Possibility. (arXiv:2301.08509v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.08509](http://arxiv.org/abs/2301.08509)

    本文提出了一种将数据和逻辑结合起来进行推理的理论，解决了符号知识的概率推理问题，并在定位问题中展示出机器人可以完全数据驱动地解决这一问题。

    

    本文提出了一种简单的推理理论，可以从数据中完全逻辑推理符号知识。我们采用贝叶斯方法来建模数据如何引起符号知识。符号知识的概率推理被建模为正向和反向过程，分别对应形式逻辑的解释和逆解释。该理论应用于定位问题，展示了一个具有损坏或噪声传感器的机器人可以以完全数据驱动的方式有效地解决该问题。

    This paper gives a simple theory of inference to logically reason symbolic knowledge fully from data over time. We take a Bayesian approach to model how data causes symbolic knowledge. Probabilistic reasoning with symbolic knowledge is modelled as a process of going the causality forwards and backwards. The forward and backward processes correspond to an interpretation and inverse interpretation of formal logic, respectively. The theory is applied to a localisation problem to show a robot with broken or noisy sensors can efficiently solve the problem in a fully data-driven fashion.
    
[^58]: 深度学习驱动的任务导向通信中的信息时代

    Age of Information in Deep Learning-Driven Task-Oriented Communications. (arXiv:2301.04298v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2301.04298](http://arxiv.org/abs/2301.04298)

    本文研究了在任务导向通信中通过编码器-解码器对来执行任务的信息时代问题，通过信道利用率的增加可以提高准确性，但需要更长的服务时间，引入任务信息的最大时代（PAoTI）来对准确性和延迟进行权衡。

    

    本文研究了任务导向通信中的信息时代概念，旨在利用发射机处的数据在接收器处执行任务。发射机和接收机之间的操作被建模为一个联合训练的编码器-解码器对，并考虑了信道效应。编码器将数据样本转换为小维度的特征向量，并使用少量的信道用于传输，从而减少了传输次数和延迟。解码器不再重构输入样本，而是对接收到的信号执行任务，例如分类。通过在MNIST和CIFAR-10图像数据集上应用不同的编码器-解码器深度神经网络，显示分类器的准确性随着信道利用率的增加而提高，但需要更长的服务时间。引入任务信息的最大时代（PAoTI）来分析准确性和延迟权衡的时机，当信息年龄增长时，除非接收到的信号被正确分类。通过结合通道和源的影响对PAoTI进行了分析，结果表明PAoTI与通道的影响趋势一致，但概述误差可能增加。

    This paper studies the notion of age in task-oriented communications that aims to execute a task at a receiver utilizing the data at its transmitter. The transmitter-receiver operations are modeled as an encoder-decoder pair that is jointly trained while considering channel effects. The encoder converts data samples into feature vectors of small dimension and transmits them with a small number of channel uses thereby reducing the number of transmissions and latency. Instead of reconstructing input samples, the decoder performs a task, e.g., classification, on the received signals. Applying different deep neural networks of encoder-decoder pairs on MNIST and CIFAR-10 image datasets, the classifier accuracy is shown to increase with the number of channel uses at the expense of longer service time. The peak age of task information (PAoTI) is introduced to analyze this accuracy-latency tradeoff when the age grows unless a received signal is classified correctly. By incorporating channel an
    
[^59]: 保证公平的基于竞拍的x-haul和云资源分配方案在多租户O-RAN中的应用

    Fairness Guaranteed and Auction-based x-haul and Cloud Resource Allocation in Multi-tenant O-RANs. (arXiv:2301.00597v3 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2301.00597](http://arxiv.org/abs/2301.00597)

    本文提出基于竞拍的资源分配机制，在多租户O-RAN生态系统中最小化不同MNO租户类型的OPEX，同时保证公平。

    

    开放式无线接入网络（O-RAN）采用云化和网络功能虚拟化，通过分离的无线电单元（RUs）、分布式单元（DUs）和集中式单元（CUs）进行基带功能处理。这使得云RAN愿景成为现实，多个移动网络运营商（MNOs）可以安装专有或开放式的RUs，但是通过开放的x-haul接口从公共可用的开放云中租用按需的DU-CU计算资源。本文提出并比较了最小最大公平和Vickrey-Clarke-Groves（VCG）基于竞拍的x-haul和DU-CU资源分配机制的性能，以创建一个适用于小、中、大MNOs可持续发展的多租户O-RAN生态系统。最小最大公平方法通过按其需求比例进行成本分摊，最小化RUs的最大OPEX，而基于VCG拍卖的方法则可最小化利用的所有资源的总OPEX，并从RUs中提取真实需求。我们注释了评估结果的公平指数，以确保在不同的MNO租户类型之间实现公平。

    The open-radio access network (O-RAN) embraces cloudification and network function virtualization for base-band function processing by dis-aggregated radio units (RUs), distributed units (DUs), and centralized units (CUs). These enable the cloud-RAN vision in full, where multiple mobile network operators (MNOs) can install their proprietary or open RUs, but lease on-demand computational resources for DU-CU functions from commonly available open-clouds via open x-haul interfaces. In this paper, we propose and compare the performances of min-max fairness and Vickrey-Clarke-Groves (VCG) auction-based x-haul and DU-CU resource allocation mechanisms to create a multi-tenant O-RAN ecosystem that is sustainable for small, medium, and large MNOs. The min-max fair approach minimizes the maximum OPEX of RUs through cost-sharing proportional to their demands, whereas the VCG auction-based approach minimizes the total OPEX for all resources utilized while extracting truthful demands from RUs. We c
    
[^60]: 基于基础模型反馈的策略适应

    Policy Adaptation from Foundation Model Feedback. (arXiv:2212.07398v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07398](http://arxiv.org/abs/2212.07398)

    本文提出了基于基础模型反馈的策略适应（PAFF）方法，通过让策略使用随机生成的指令进行演示，并利用预训练的基础模型提供反馈来重新标记演示，自动提供新的演示-指令数据对进行策略微调，以实现机器人操作的泛化。实验结果表明，PAFF优于现有最先进的方法。

    

    最近在视觉-语言基础模型方面的进展为构建通用机器人带来了显著进步。通过使用预训练模型将场景和指令编码为决策输入，指令条件化策略可以在不同的对象和任务之间进行泛化。尽管这是令人鼓舞的，但策略在遇到未见过的任务或环境时仍然失败。在本工作中，我们提出了一种基于基础模型反馈的策略适应（PAFF）。当将训练好的策略部署到新任务或新环境时，我们首先让策略使用随机生成的指令进行演示。虽然执行可能出现错误，但我们可以利用预训练的基础模型提供反馈来重新标记演示。这自动为策略微调提供了新的演示-指令数据对。我们在机器人操作设置中进行了各种实验的评估，重点是在未见过的对象、任务和未观察到的环境中的泛化。我们的实验结果表明，PAFF在最终任务成功率和训练效率方面优于现有最先进的方法。

    Recent progress on vision-language foundation models have brought significant advancement to building general-purpose robots. By using the pre-trained models to encode the scene and instructions as inputs for decision making, the instruction-conditioned policy can generalize across different objects and tasks. While this is encouraging, the policy still fails in most cases given an unseen task or environment. In this work, we propose Policy Adaptation from Foundation model Feedback (PAFF). When deploying the trained policy to a new task or a new environment, we first let the policy play with randomly generated instructions to record the demonstrations. While the execution could be wrong, we can use the pre-trained foundation models to provide feedback to relabel the demonstrations. This automatically provides new pairs of demonstration-instruction data for policy fine-tuning. We evaluate our method on a broad range of experiments with the focus on generalization on unseen objects, unse
    
[^61]: 多模态医学数据分析的异构图学习

    Heterogeneous Graph Learning for Multi-modal Medical Data Analysis. (arXiv:2211.15158v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.15158](http://arxiv.org/abs/2211.15158)

    该论文提出了一种名为HetMed的异构图学习框架，用于融合多模态医学数据，以提高临床决策的准确性。

    

    病人的常规临床访问不仅会产生图像数据，还会包含有关病人的临床信息等非图像数据，即医学数据的多模态性质。这样的异构模态提供了不同和互补的病人视角，当它们被正确地组合时，可以导致更准确的临床决策。然而，尽管其重要性，如何将多模态医学数据有效地融合到统一框架中却受到了相对较少的关注。本文提出了一种名为HetMed（多模态医学数据分析的异构图学习）的有效图形框架，用于融合多模态医学数据。具体而言，我们构建一个包括多种病人非图像特征的多重网络，以系统化方式捕获病人之间的复杂关系，从而导致更准确的临床决策。大量实验结果表明，与最先进的方法相比，我们的方法具有更优越性。

    Routine clinical visits of a patient produce not only image data, but also non-image data containing clinical information regarding the patient, i.e., medical data is multi-modal in nature. Such heterogeneous modalities offer different and complementary perspectives on the same patient, resulting in more accurate clinical decisions when they are properly combined. However, despite its significance, how to effectively fuse the multi-modal medical data into a unified framework has received relatively little attention. In this paper, we propose an effective graph-based framework called HetMed (Heterogeneous Graph Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal medical data. Specifically, we construct a multiplex network that incorporates multiple types of non-image features of patients to capture the complex relationship between patients in a systematic way, which leads to more accurate clinical decisions. Extensive experiments on various real-world datasets dem
    
[^62]: 基于解耦原型网络的广义类别发现

    Generalized Category Discovery with Decoupled Prototypical Network. (arXiv:2211.15115v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15115](http://arxiv.org/abs/2211.15115)

    本文提出了一种解耦原型网络（DPN）模型，通过二分图匹配问题分离已知和新类别来有效地实现不同的训练目标，并将标记和未标记数据中的已知类别对齐，以显式转移类别特定的知识和捕获高级语义信息。

    

    广义类别发现（GCD）的目标是从一组无标签数据中识别已知和新的类别，基于另一个仅带有已知类别的数据集。目前的方法忽略已知和新类别之间的差异，在耦合的方式下学习它们，这可能会损害模型的泛化和区分能力。此外，耦合训练方法阻止这些模型显式地从标记数据向未标记数据转移类别特定的知识，这可能会丢失高级语义信息并影响模型性能。为了减轻上述限制，我们提出了一种新颖的模型，称为解耦原型网络（DPN）。通过为类别原型制定一个二分图匹配问题，DPN不仅可以解耦已知和新的类别以有效地实现不同的训练目标，而且还可以将标记和未标记数据中的已知类别对齐，以显式地转移类别特定的知识并捕获高水平的语义信息。

    Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high
    
[^63]: VGFlow: 针对人体重定位的可见性引导流网络

    VGFlow: Visibility guided Flow Network for Human Reposing. (arXiv:2211.08540v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.08540](http://arxiv.org/abs/2211.08540)

    提出了一种基于可见性引导流模块的流网络模型VGFlow，可以分离出目标的可见和不可见部分以实现纹理保留和风格操作，同时采用了多路径结构以在不同级别的细节上操作。在生成逼真人体姿势方面表现出有效性。

    

    人体重定位的任务涉及生成一个站立在任意构想姿势下的真实人物图像。生成感知准确图像存在多个困难，现有方法在保留纹理、维持图案一致性、考虑服装边界、处理遮挡、调整皮肤生成等方面存在局限性。这些困难还因可能的人体姿势方向空间巨大且多变、服装物品的本质高度非刚性、身体形状的多样性大大不同于人口中的多样性而进一步恶化。为了缓解这些困难并合成感知准确的图像，我们提出了VGFlow。我们的模型使用可见性引导流模块将流分离为目标的可见和不可见部分，以实现同时纹理保留和风格操作。此外，为了解决不同的身体形状和避免网络伪影，我们还采用了一个多路径结构，包括全局结构路径和多个局部细节路径，可以在不同级别的细节上进行操作。实验结果显示了所提出方法在生成具有精细细节和准确纹理的逼真人体姿势方面的有效性。

    The task of human reposing involves generating a realistic image of a person standing in an arbitrary conceivable pose. There are multiple difficulties in generating perceptually accurate images, and existing methods suffer from limitations in preserving texture, maintaining pattern coherence, respecting cloth boundaries, handling occlusions, manipulating skin generation, etc. These difficulties are further exacerbated by the fact that the possible space of pose orientation for humans is large and variable, the nature of clothing items is highly non-rigid, and the diversity in body shape differs largely among the population. To alleviate these difficulties and synthesize perceptually accurate images, we propose VGFlow. Our model uses a visibility-guided flow module to disentangle the flow into visible and invisible parts of the target for simultaneous texture preservation and style manipulation. Furthermore, to tackle distinct body shapes and avoid network artifacts, we also incorporat
    
[^64]: 受生物启示的人类运动序列的持续学习模型

    Biologically-Inspired Continual Learning of Human Motion Sequences. (arXiv:2211.05231v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05231](http://arxiv.org/abs/2211.05231)

    本文提出了一个受生物启示的条件时间变分自动编码器(BI-CTVAE)模型，通过持续学习生成(CL2Gen)场景，可以对不同类别的运动序列进行生成，并在一组任务上得到较高的生成准确性和分类准确性。

    

    本文提出了一种持续学习模型，专注于涉及时间序列——具体而言，是人的运动。该模型改进了最近提出的类似于大脑的重放模型(BI-R)，它建立了一个受生物启示的条件时间变分自动编码器(BI-CTVAE)，其实例化了一个高斯函数混合体来表示类别。我们研究了一种新颖的持续学习生成(CL2Gen)场景，其中模型生成不同类别的运动序列。模型的生成准确性在一组任务上进行了测试。在按顺序学习所有动作类别之后，BI-CTVAE在一个人类运动数据集上的最终分类准确性达到了78％，比不使用重放高63％，比最先进的离线训练GRU模型低5.4％。

    This work proposes a model for continual learning on tasks involving temporal sequences, specifically, human motions. It improves on a recently proposed brain-inspired replay model (BI-R) by building a biologically-inspired conditional temporal variational autoencoder (BI-CTVAE), which instantiates a latent mixture-of-Gaussians for class representation. We investigate a novel continual-learning-to-generate (CL2Gen) scenario where the model generates motion sequences of different classes. The generative accuracy of the model is tested over a set of tasks. The final classification accuracy of BI-CTVAE on a human motion dataset after sequentially learning all action classes is 78%, which is 63% higher than using no-replay, and only 5.4% lower than a state-of-the-art offline trained GRU model.
    
[^65]: 基于模态逻辑的统计因果关系形式化

    Formalizing Statistical Causality via Modal Logic. (arXiv:2210.16751v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.16751](http://arxiv.org/abs/2210.16751)

    提出了一种基于模态逻辑的形式语言，用于描述和解释统计因果关系，并且能够指定和解释统计因果推断的正确性。

    

    我们提出了一种描述和解释统计因果关系的形式语言。具体来说，我们定义了统计因果语言（StaCL），用于表达随机变量上的因果效应并指定因果推断的要求。StaCL通过干预的模态运算符，在不同可能的世界的概率分布之间表达因果属性，在Kripke模型中解释。我们使用StaCL公式正式化概率分布、干预和因果谓词的公理。这些公理足够表达Pearl的do-calculus规则。最后，我们通过示例证明了StaCL可以用于指定和解释统计因果推断的正确性。

    We propose a formal language for describing and explaining statistical causality. Concretely, we define Statistical Causality Language (StaCL) for expressing causal effects on random variables and specifying the requirements for causal inference. StaCL incorporates modal operators for interventions to express causal properties between probability distributions in different possible worlds in a Kripke model. We formalize axioms for probability distributions, interventions, and causal predicates using StaCL formulas. These axioms are expressive enough to derive the rules of Pearl's do-calculus. Finally, we demonstrate by examples that StaCL can be used to specify and explain the correctness of statistical causal inference.
    
[^66]: 通过结构增强的预训练模型和自适应融合提高语义匹配

    Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion. (arXiv:2210.08471v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08471](http://arxiv.org/abs/2210.08471)

    本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。

    

    基于Transformer的预训练模型，如BERT，在语义句子匹配方面取得了很大的进展。同时，依赖性先验知识在多个NLP任务中也显示出普遍的益处。然而，如何将依赖性先验结构有效地集成到预训练模型中，以更好地模拟复杂的语义匹配关系，仍未确定。在本文中，我们提出了一种名为DAFA的依赖增强自适应融合注意力模型，这将依赖结构明确地引入预训练模型，并将其自适应地融合到语义信息中。具体地，DAFA首先提出了一个结构敏感范式来构建一个依赖矩阵，以校准注意力权重。它采用自适应融合模块来集成获取的依赖信息和原始语义信号。此外，DAFA重构了注意力计算流程，并提供了更好的可解释性。

    Transformer-based pre-trained models like BERT have achieved great progress on Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also shown general benefits in multiple NLP tasks. However, how to efficiently integrate dependency prior structure into pre-trained models to better model complex semantic matching relations is still unsettled. In this paper, we propose the \textbf{D}ependency-Enhanced \textbf{A}daptive \textbf{F}usion \textbf{A}ttention (\textbf{DAFA}), which explicitly introduces dependency structure into pre-trained models and adaptively fuses it with semantic information. Specifically, \textbf{\emph{(i)}} DAFA first proposes a structure-sensitive paradigm to construct a dependency matrix for calibrating attention weights. It adopts an adaptive fusion module to integrate the obtained dependency information and the original semantic signals. Moreover, DAFA reconstructs the attention calculation flow and provides better interpretability. By applying it o
    
[^67]: MAPL: 基于参数效率的单模态预训练模型在视觉-语言少样本任务中的适应

    MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting. (arXiv:2210.07179v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.07179](http://arxiv.org/abs/2210.07179)

    MAPL使用对齐的图像-文本数据学习单模态模型表示空间之间的轻量级映射，从而实现了面向视觉-语言少样本任务的基于参数效率的适应，并在测试中显示出优越的性能表现。

    

    在单模态视觉和语言任务中，大型预训练模型已经被证明是出色的零样本和（基于提示的）少样本学习器。我们提出了MAPL，一种简单且参数效率高的方法，它重用冻结的单模态预训练模型，并利用它们在多模态视觉-语言（VL）场景中的强大泛化能力。MAPL使用对齐的图像-文本数据学习了单模态模型表示空间之间的轻量级映射，并且可以从仅有少量上下文示例就推广到看不见的VL任务。MAPL的可训练参数数量很少，使得它在低数据和域内学习方面非常有效。此外，MAPL的模块化使得可以轻松扩展到其他预训练模型。在几个视觉问答和图像标题生成基准测试上的大量实验证明，MAPL相对于类似方法在训练少得多的参数时实现了优越或有竞争力的性能。MAPL可以在几小时内使用适度的计算资源进行训练。

    Large pre-trained models have proved to be remarkable zero- and (prompt-based) few-shot learners in unimodal vision and language tasks. We propose MAPL, a simple and parameter-efficient method that reuses frozen pre-trained unimodal models and leverages their strong generalization capabilities in multimodal vision-language (VL) settings. MAPL learns a lightweight mapping between the representation spaces of unimodal models using aligned image-text data, and can generalize to unseen VL tasks from just a few in-context examples. The small number of trainable parameters makes MAPL effective at low-data and in-domain learning. Moreover, MAPL's modularity enables easy extension to other pre-trained models. Extensive experiments on several visual question answering and image captioning benchmarks show that MAPL achieves superior or competitive performance compared to similar methods while training orders of magnitude fewer parameters. MAPL can be trained in just a few hours using modest comp
    
[^68]: PLM 困惑度不可靠，用于评估文本质量

    Perplexity from PLM Is Unreliable for Evaluating Text Quality. (arXiv:2210.05892v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05892](http://arxiv.org/abs/2210.05892)

    该研究发现，使用困惑度指标评估生成文本质量是不可靠的，由于短文本 PPL 值高于长文本，重复文本段落和标点符号也可以损坏指标表现。 使用语言模型评估文本质量应谨慎。

    

    最近，很多研究都使用困惑度（PPL）来评估生成文本的质量。他们认为，如果 PPL 的值越小，被评估文本的质量（即流畅性）就越好。然而，我们发现 PPL 双重错误，不能公正地评估生成文本的质量，原因包括：（i）短文本的 PPL 值大于长文本，这与常识相悖，（ii）重复文本段落状态下可以损坏 PPL，（iii）标点符号可以严重影响 PPL 的表现。实验表明，PPL 不能可靠地评估给定文本的质量。最后，我们讨论了使用语言模型评估文本质量的关键问题。

    Recently, amounts of works utilize perplexity~(PPL) to evaluate the quality of the generated text. They suppose that if the value of PPL is smaller, the quality(i.e. fluency) of the text to be evaluated is better. However, we find that the PPL referee is unqualified and it cannot evaluate the generated text fairly for the following reasons: (i) The PPL of short text is larger than long text, which goes against common sense, (ii) The repeated text span could damage the performance of PPL, and (iii) The punctuation marks could affect the performance of PPL heavily. Experiments show that the PPL is unreliable for evaluating the quality of given text. Last, we discuss the key problems with evaluating text quality using language models.
    
[^69]: 学习最小违反连续控制以实现不可行线性时态逻辑规范

    Learning Minimally-Violating Continuous Control for Infeasible Linear Temporal Logic Specifications. (arXiv:2210.01162v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.01162](http://arxiv.org/abs/2210.01162)

    本文提出了一个模型自由框架，使用深度强化学习来实现复杂高级任务的目标驱动导航。通过将先前的多目标DRL问题转化为一个单一目标问题，并使用基于采样的路径规划算法来指导DRL智能体，该方法可以满足不可行的线性时态逻辑任务并尽可能减少违规。

    

    本文研究了连续时间控制综合，以实现线性时态逻辑(LTL)表达的复杂高级任务的目标驱动导航。我们提出了一个模型自由框架，使用深度强化学习(DRL)，其中底层动态系统未知（透明盒子）。与先前的工作不同，本文考虑了给定的LTL规范可能是不可行的情况，因此无法全局完成。我们不修改给定的LTL公式，而是提供了一个通用的DRL方法，以最小违规满足它。为了做到这一点，我们将先前的多目标DRL问题转化为一个单一目标问题，该问题要求同时实现自动机满足和最小违规代价。通过使用基于采样的路径规划算法来指导可能不可行的LTL任务的DRL智能体，所提出的方法减轻了DRL的近视倾向，这在学习可以具有长或无限持续时间的一般LTL任务时经常是一个问题。

    This paper explores continuous-time control synthesis for target-driven navigation to satisfy complex high-level tasks expressed as linear temporal logic (LTL). We propose a model-free framework using deep reinforcement learning (DRL) where the underlying dynamic system is unknown (an opaque box). Unlike prior work, this paper considers scenarios where the given LTL specification might be infeasible and therefore cannot be accomplished globally. Instead of modifying the given LTL formula, we provide a general DRL-based approach to satisfy it with minimal violation. To do this, we transform a previously multi-objective DRL problem, which requires simultaneous automata satisfaction and minimum violation cost, into a single objective. By guiding the DRL agent with a sampling-based path planning algorithm for the potentially infeasible LTL task, the proposed approach mitigates the myopic tendencies of DRL, which are often an issue when learning general LTL tasks that can have long or infin
    
[^70]: 从理解NSGA-II的人口动态到首次证明的下限

    From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds. (arXiv:2209.13974v2 [cs.NE] CROSS LISTED)

    [http://arxiv.org/abs/2209.13974](http://arxiv.org/abs/2209.13974)

    本论文证明了NSGA-II算法在适当的人口规模下，在解决$OneMinMax$问题时需要$\Omega(Nn\log n)$次函数评估，并在解决跳跃大小为$k$的$OneJumpZeroJump$问题时需要$\Omega(Nn^k)$次评估。这些下限也表明，即使使用更大的人口大小，NSGA-II也不能在并行运行时间方面受益。

    

    由于NSGA-II的更为复杂的人口动态，目前该算法的所有运行时保证都没有附带任何非平凡下限。通过对NSGA-II的人口动态进行第一次数学理解，即通过估计具有特定目标值的个体的期望数量，我们证明了NSGA-II需要适当的人口规模才能在$OneMinMax$问题中找到Pareto前沿，并在跳跃大小为$k$时需要$\Omega(Nn^k)$次评估来解决$OneJumpZeroJump$问题。这些下限是渐进紧密的（即与之前显示的上限匹配），并且表明在并行运行时间（迭代次数）方面，即使使用更大的人口大小，NSGA-II也不会从中获益。对于$OneJumpZeroJump$问题，当使用相同的排序来计算两个目标的拥挤距离贡献时，我们甚至获得了一个紧密的运行时估计。

    Due to the more complicated population dynamics of the NSGA-II, none of the existing runtime guarantees for this algorithm is accompanied by a non-trivial lower bound. Via a first mathematical understanding of the population dynamics of the NSGA-II, that is, by estimating the expected number of individuals having a certain objective value, we prove that the NSGA-II with suitable population size needs $\Omega(Nn\log n)$ function evaluations to find the Pareto front of the OneMinMax problem and $\Omega(Nn^k)$ evaluations on the OneJumpZeroJump problem with jump size $k$. These bounds are asymptotically tight (that is, they match previously shown upper bounds) and show that the NSGA-II here does not even in terms of the parallel runtime (number of iterations) profit from larger population sizes. For the OneJumpZeroJump problem and when the same sorting is used for the computation of the crowding distance contributions of the two objectives, we even obtain a runtime estimate that is tight 
    
[^71]: GPT-3 如何处理气候变化和“黑人的命也是命”等不同公众的话题：关于对话式 AI 公平性的批判性评估

    How GPT-3 responds to different publics on climate change and Black Lives Matter: A critical appraisal of equity in conversational AI. (arXiv:2209.13627v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.13627](http://arxiv.org/abs/2209.13627)

    本论文提出了一个分析框架，以检查人工智能和人类对话中公平性的含义。作者使用这个框架进行了审计研究，发现 GPT-3 在回应气候变化和BBL运动的提示时存在不公平的行为，强化了刻板印象，边缘化了某些特定的群体。该研究表明有必要解决这些偏见，以防止AI-powered服务中进一步巩固权力结构。

    

    自回归语言模型越来越普遍，这种模型利用深度学习生成接近人类的文本。这些模型驱动着智能健康、金融和自主驾驶等领域的流行虚拟助手。虽然这些大型语言模型的参数正在改进，但人们仍然担心这些模型可能不同程度地为社会中的所有子群体提供服务。尽管跨学科的 AI 公平讨论越来越多，但缺乏系统性的指标来评估对话系统中公平的含义，以及如何让不同的人群参与评估循环。本文基于民主决策理论和科学技术研究，提出了一个分析框架来揭示人工智能和人类对话中公平性的含义。使用这一框架，我们进行了审计研究，以检查 GPT-3 如何响应关键的科学和社会话题：气候变化和“黑人的命也是命”运动。我们的语料库包括 480 次提示，其中系统地变化发言人的性别、种族和地理位置。我们的发现表明，当回应气候变化和 BLM 的提示时，GPT-3 有时会强化刻板印象，边缘化某些群体，如土著民族。我们认为必须解决这些偏见，以防止权力结构在 AI 动力服务中进一步巩固。

    Autoregressive language models, which use deep learning to produce human-like texts, have become increasingly widespread. Such models are powering popular virtual assistants in areas like smart health, finance, and autonomous driving. While the parameters of these large language models are improving, concerns persist that these models might not work equally for all subgroups in society. Despite growing discussions of AI fairness across disciplines, there lacks systemic metrics to assess what equity means in dialogue systems and how to engage different populations in the assessment loop. Grounded in theories of deliberative democracy and science and technology studies, this paper proposes an analytical framework for unpacking the meaning of equity in human-AI dialogues. Using this framework, we conducted an auditing study to examine how GPT-3 responded to different sub-populations on crucial science and social topics: climate change and the Black Lives Matter (BLM) movement. Our corpus 
    
[^72]: 神经网络中的泛化：综述与分析

    Generalization in Neural Networks: A Broad Survey. (arXiv:2209.01610v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.01610](http://arxiv.org/abs/2209.01610)

    这篇论文总结了神经网络模型中不同抽象层次上的泛化问题及其方法，其中样本泛化已经取得了进展，但未来需要重点关注减少过拟合；分布泛化与领域泛化有相似之处，领域泛化方法可以应用于困难的样本或分布泛化。

    

    本文综述了神经网络模型中不同抽象层次的概念、建模方法和最近的研究成果，包括样本、分布、领域、任务、模态和范围上的泛化。在样本泛化方面的研究结果显示，在ImageNet数据集的情况下，几乎所有的最新改进都减小了训练误差，而过拟合保持不变；随着几乎所有的训练误差被消除，未来的进展将需要集中关注减少过拟合。从统计学的角度来看，(2)分布泛化可以被看作是样本权重或输入输出关系的变化；因此，在领域泛化成功的技术有可能应用于困难的样本或分布泛化。本文总结了转移学习方法(3)领域泛化的应用，以及最近的进展和丰富的应用领域。

    This paper reviews concepts, modeling approaches, and recent findings along a spectrum of different levels of abstraction of neural network models including generalization across (1) Samples, (2) Distributions, (3) Domains, (4) Tasks, (5) Modalities, and (6) Scopes. Results on (1) sample generalization show that, in the case of ImageNet, nearly all the recent improvements reduced training error while overfitting stayed flat; with nearly all the training error eliminated, future progress will require a focus on reducing overfitting. Perspectives from statistics highlight how (2) distribution generalization can be viewed alternately as a change in sample weights or a change in the input-output relationship; thus, techniques that have been successful in domain generalization have the potential to be applied to difficult forms of sample or distribution generalization. Transfer learning approaches to (3) domain generalization are summarized, as are recent advances and the wealth of domain a
    
[^73]: NSGA-II的运行时分析：交叉操作带来可证明的加速

    Runtime Analysis for the NSGA-II: Provable Speed-Ups From Crossover. (arXiv:2208.08759v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2208.08759](http://arxiv.org/abs/2208.08759)

    本文证明NSGA-II优化OneJumpZeroJump基准函数时，交叉操作可以带来可证明的加速效果；同样，交叉操作对于单目标优化中的$(\mu+1)$遗传算法也有更显著的加速效果。

    

    最近，对于NSGA-II，最常用的多目标演化算法进行了第一次数学运行时分析。本研究证明，当使用交叉时，NSGA-II在优化OneJumpZeroJump基准函数时会呈现出渐近更快的速度。与Dang、Opris、Salehi和Sudholt的一项独立并行工作一起，这是第一次证明交叉操作对NSGA-II有这样的优势。我们的论证可以被转移到单目标优化中。而且，他们证明交叉操作可以比以前更加显著地加速$(\mu+1)$遗传算法。我们的实验证实了交叉的附加价值，并表明观察到的优势甚至比我们的证明所能保证的更大。

    Very recently, the first mathematical runtime analyses for the NSGA-II, the most common multi-objective evolutionary algorithm, have been conducted. Continuing this research direction, we prove that the NSGA-II optimizes the OneJumpZeroJump benchmark asymptotically faster when crossover is employed. Together with a parallel independent work by Dang, Opris, Salehi, and Sudholt, this is the first time such an advantage of crossover is proven for the NSGA-II. Our arguments can be transferred to single-objective optimization. They then prove that crossover can speed up the $(\mu+1)$ genetic algorithm in a different way and more pronounced than known before. Our experiments confirm the added value of crossover and show that the observed advantages are even larger than what our proofs can guarantee.
    
[^74]: 交互式强化学习中反馈频率对机器人任务的影响的定量化研究

    Quantifying the Effect of Feedback Frequency in Interactive Reinforcement Learning for Robotic Tasks. (arXiv:2207.09845v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2207.09845](http://arxiv.org/abs/2207.09845)

    本文对交互式强化学习中反馈频率对机器人任务的影响进行了定量化研究，结果表明没有单一的理想反馈频率存在，应该根据具体的任务和机器人复杂性进行调整。

    

    强化学习（RL）在机器人控制中被广泛采用。尽管有许多成功案例，但一个重要的持久性问题是数据效率非常低。交互反馈是一种解决方案，已被证明可以大大加速RL。因此，有大量不同的策略，然而这些策略主要是在离散的网格世界和小规模的最优控制场景中测试的。在文献中，对于哪种反馈频率最优或在什么时候反馈最有益并没有共识。为了解决这些差异，我们在具有连续状态和动作空间的机器人任务中分离并量化了反馈频率的影响。实验涵盖了不同复杂度的机械臂的逆运动学学习。我们展示了表面上矛盾的现象在不同的复杂度水平上出现。此外，我们的结果表明，没有单一的理想反馈频率存在。反馈频率应该根据具体的任务和机器人复杂性进行调整。

    Reinforcement learning (RL) has become widely adopted in robot control. Despite many successes, one major persisting problem can be very low data efficiency. One solution is interactive feedback, which has been shown to speed up RL considerably. As a result, there is an abundance of different strategies, which are, however, primarily tested on discrete grid-world and small scale optimal control scenarios. In the literature, there is no consensus about which feedback frequency is optimal or at which time the feedback is most beneficial. To resolve these discrepancies we isolate and quantify the effect of feedback frequency in robotic tasks with continuous state and action spaces. The experiments encompass inverse kinematics learning for robotic manipulator arms of different complexity. We show that seemingly contradictory reported phenomena occur at different complexity levels. Furthermore, our results suggest that no single ideal feedback frequency exists. Rather that feedback frequenc
    
[^75]: Betty: 一个用于多层次优化的自动微分库

    Betty: An Automatic Differentiation Library for Multilevel Optimization. (arXiv:2207.02849v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.02849](http://arxiv.org/abs/2207.02849)

    本文介绍了一个名为Betty的自动微分库，可用于大规模的梯度优化问题，有效地减少了计算复杂度并提高了可扩展性，在广泛的多层次优化任务中表现出良好性能。

    

    基于梯度的多层次优化(MLO)已成为研究众多问题的框架，包括超参数优化、元学习、神经架构搜索和强化学习等。然而，MLO中的梯度，是通过链式法则组成最佳响应Jacobi矩阵而获得的，具有计算和内存密集等不利因素。本文介绍了一个面向大规模MLO的软件库Betty，从而初步为解决这一问题迈出了一步。在其核心，我们设计了一个新的MLO数据流图，使我们能够(1)为MLO开发高效的自动微分，将计算复杂度从O(d^3)降至O(d^2)，(2)融入系统支持，例如混合精度和数据并行训练，以实现可伸缩性，(3)便于实现任意复杂度的MLO程序，同时允许多样化的算法和系统设计选择的模块化接口。我们通过实验证明，Betty在广泛的MLO任务中都实现了很好的性能，例如超参数优化、元学习和神经架构搜索。

    Gradient-based multilevel optimization (MLO) has gained attention as a framework for studying numerous problems, ranging from hyperparameter optimization and meta-learning to neural architecture search and reinforcement learning. However, gradients in MLO, which are obtained by composing best-response Jacobians via the chain rule, are notoriously difficult to implement and memory/compute intensive. We take an initial step towards closing this gap by introducing Betty, a software library for large-scale MLO. At its core, we devise a novel dataflow graph for MLO, which allows us to (1) develop efficient automatic differentiation for MLO that reduces the computational complexity from O(d^3) to O(d^2), (2) incorporate systems support such as mixed-precision and data-parallel training for scalability, and (3) facilitate implementation of MLO programs of arbitrary complexity while allowing a modular interface for diverse algorithmic and systems design choices. We empirically demonstrate that
    
[^76]: NovelCraft：开放世界中的新颖性检测和发现数据集

    NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds. (arXiv:2206.11736v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.11736](http://arxiv.org/abs/2206.11736)

    NovelCraft数据集提供了开放世界中新颖性检测与发现任务的挑战。在复杂的场景中插入新颖物体的检测需要更好的基准，并发现了控制假阳性时更简单的方法可能比复杂的方法更出色。

    

    为了让人工智能代理在不断变化的环境中成功执行任务，必须能够检测和适应新颖性。然而，视觉新颖性检测研究通常只评估旨在进行对象分类的重复利用数据集（如CIFAR-10），其中图像聚焦于一个明显、居中的对象。需要新的基准来代表在开放世界中导航复杂场景的挑战。我们的新NovelCraft数据集包含完成修改后的Minecraft环境中的跳跳球装配任务的代理所看到的图像和符号世界状态的多模式情节数据。在某些情节中，我们在复杂的3D场景中插入新颖物体，这些物体可能影响游戏玩法并出现在各种大小和位置中。我们的视觉新颖性检测基准发现，控制假阳性时，最好的面积下曲线度量的方法可能会被更简单的替代方法超过。

    In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects within the complex 3D scene that may impact gameplay and appear in a variety of sizes and positions. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. 
    
[^77]: 多视角潜变量模型中的领域知识编码:带结构稀疏贝叶斯方法

    Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity. (arXiv:2204.06242v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.06242](http://arxiv.org/abs/2204.06242)

    提出了一种新的基于修改过的马蹄蚌先验的多视角潜变量模型MuVI，用于建模结构稀疏性。它能够纳入有限且噪声的领域知识，以内在可解释的方式分析多视角数据，优于现有结构稀疏性建模方法。

    

    许多现实世界的系统不仅有来自单个数据源的数据，还有来自多个数据视角的数据。例如，在基因组医学中，患者可以通过来自不同分子层面的数据进行描述。利用具有结构稀疏性的潜变量模型是揭示数据视角内和跨视角变化的常用工具。然而，它们的可解释性较差，需要专家直接检查和解释每个要素。在这里，我们提出了MuVI，一种基于修改过的马蹄蚌先验的新型多视角潜变量模型，用于建模结构稀疏性。这有助于对有限的和噪声领域知识进行纳入，从而以内在可解释的方式分析多视角数据。我们证明了我们的模型在重建误差和精确度/召回方面优于现有的结构稀疏性建模方法，并且可以稳健地整合噪声领域专业知识。

    Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, patients can be characterized by data from different molecular layers. Latent variable models with structured sparsity are a commonly used tool for disentangling variation within and across data views. However, their interpretability is cumbersome since it requires a direct inspection and interpretation of each factor from domain experts. Here, we propose MuVI, a novel multi-view latent variable model based on a modified horseshoe prior for modeling structured sparsity. This facilitates the incorporation of limited and noisy domain knowledge, thereby allowing for an analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) outperforms state-of-the-art approaches for modeling structured sparsity in terms of the reconstruction error and the precision/recall, (ii) robustly integrates noisy domain expertise in t
    
[^78]: 机器人的视觉触觉物体感知：概述

    Visuo-Haptic Object Perception for Robots: An Overview. (arXiv:2203.11544v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2203.11544](http://arxiv.org/abs/2203.11544)

    本文总结了机器人视觉触觉物体感知的现状以及挑战。人类多模态物体感知的生物学基础和最新的机器人感知技术和数据采集策略被概述，同时重点介绍了多模态机器学习的主要挑战，并提出了一些未来的研究方向。

    

    人类的物体感知能力令人印象深刻，而在开发拥有类似熟练技能的自主机器人解决方案方面，这一点变得更加明显。虽然人工视觉和触觉技术已经取得了显著进展，但这两种传感模式在机器人应用中的有效整合仍有待改善，存在着几个挑战。本文受到人类如何通过视觉和触觉知觉来感知物体属性和推动手动任务执行的启发，总结了机器人的视觉触觉物体感知的现状。首先，概述了人类多模态物体感知的生物学基础。接下来，讨论了机器人的感知技术和数据采集策略的最新进展。然后，介绍了主要的计算技术，重点介绍了多模态机器学习的主要挑战，并提出了一些未来的研究方向。

    The object perception capabilities of humans are impressive, and this becomes even more evident when trying to develop solutions with a similar proficiency in autonomous robots. While there have been notable advancements in the technologies for artificial vision and touch, the effective integration of these two sensory modalities in robotic applications still needs to be improved, and several open challenges exist. Taking inspiration from how humans combine visual and haptic perception to perceive object properties and drive the execution of manual tasks, this article summarises the current state of the art of visuo-haptic object perception in robots. Firstly, the biological basis of human multimodal object perception is outlined. Then, the latest advances in sensing technologies and data collection strategies for robots are discussed. Next, an overview of the main computational techniques is presented, highlighting the main challenges of multimodal machine learning and presenting a fe
    
[^79]: 一个大规模多元化的阿拉伯语语料库用于语言建模

    A Large and Diverse Arabic Corpus for Language Modeling. (arXiv:2201.09227v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.09227](http://arxiv.org/abs/2201.09227)

    该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。

    

    语言模型（LM）引入了自然语言处理（NLP）建模的重大范式转变，其中大型预先训练的LM已经成为大多数NLP任务不可分割的组成部分。LM足够智能，可以在没有任何监督的情况下找到语言的有用和相关表示。这些模型被用于对常规NLP任务进行微调，相对于传统方法，具有显着更高的准确性。相反，这些模型的训练需要一个大规模的语料库，这个语料库可以很好地代表阿拉伯语。由于英语语料库可获得大量资源，因此英语LM通常比其他语言LM表现更好。本文详细描述了一个大型阿拉伯语语料库的设计和开发。它由超过500GB的已加工的阿拉伯文本组成，旨在提高大规模语言模型的跨领域知识和下游推理能力。此外，该语料库还用于训练大型阿拉伯语LM。

    Language models (LMs) have introduced a major paradigm shift in Natural Language Processing (NLP) modeling where large pre-trained LMs became integral to most of the NLP tasks. The LMs are intelligent enough to find useful and relevant representations of the language without any supervision. Perhaps, these models are used to fine-tune typical NLP tasks with significantly high accuracy as compared to the traditional approaches. Conversely, the training of these models requires a massively large corpus that is a good representation of the language. English LMs generally perform better than their other language counterparts, due to the availability of massive English corpora. This work elaborates on the design and development of a large Arabic corpus. It consists of over 500 GB of Arabic cleaned text targeted at improving cross-domain knowledge and downstream generalization capability of large-scale language models. Moreover, the corpus is utilized in the training of a large Arabic LM. In
    
[^80]: 对抗训练中的标签噪声：研究鲁棒过度拟合的新视角

    Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting. (arXiv:2110.03135v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03135](http://arxiv.org/abs/2110.03135)

    该论文发现了对抗训练中存在的标签噪声，并解释了其对鲁棒过度拟合的普遍存在以及扰动半径和数据质量的依赖性。通过该论文提出的方法，可以自动校准标签以应对标签噪声和鲁棒过度拟合。

    

    我们展示了在对抗训练中存在标签噪声。这种标签噪声是由于对抗样本的真实标签分布与从干净样本继承的标签之间的不匹配造成的 - 真实标签分布被对抗扰动扭曲，但从干净样本继承标签的常见做法却忽略了这一点。认识到标签噪声有助于洞察对抗训练中鲁棒过度拟合的普遍存在，并解释了其对扰动半径和数据质量的奇特依赖性。此外，我们的标签噪声视角与我们对对抗训练中纪元双下降现象的观察相吻合。在我们的分析指导下，我们提出了一种方法来自动校准标签以应对标签噪声和鲁棒过度拟合。我们的方法在各种模型和数据集上实现了一致的性能提升，而不引入新的超参数或额外的调整。

    We show that label noise exists in adversarial training. Such label noise is due to the mismatch between the true label distribution of adversarial examples and the label inherited from clean examples - the true label distribution is distorted by the adversarial perturbation, but is neglected by the common practice that inherits labels from clean examples. Recognizing label noise sheds insights on the prevalence of robust overfitting in adversarial training, and explains its intriguing dependence on perturbation radius and data quality. Also, our label noise perspective aligns well with our observations of the epoch-wise double descent in adversarial training. Guided by our analyses, we proposed a method to automatically calibrate the label to address the label noise and robust overfitting. Our method achieves consistent performance improvements across various models and datasets without introducing new hyper-parameters or additional tuning.
    
[^81]: 通往通用人工智能的生态系统之路

    The Ecosystem Path to General AI. (arXiv:2108.07578v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2108.07578](http://arxiv.org/abs/2108.07578)

    这篇论文介绍了一个基于Unity游戏引擎的开源生态系统模拟器Ecotwin，其中动物认知的建模通过整合三个独立的网络实现，模拟自然现象在模型中出现而无需硬编码。

    

    首先讨论了生态系统模拟器与通用人工智能之间的联系。随后我们介绍了基于Unity游戏引擎的开源生态系统模拟器Ecotwin，它可以运行包含无生命物体如山脉和湖泊以及包括动物和植物的生态系统。动物认知的建模是通过整合三个独立的网络来实现的：（i）硬连通的反射网络；（ii）幸福网络，用于将传感数据，如氧气、水、能量和气味，映射到一个标量幸福值；（iii）选择行动的策略网络。策略网络是通过强化学习（RL）进行训练的，其中奖励信号被定义为从一个时间步到下一个时间步的幸福差。所有的生物能够进行有性或无性繁殖，并且如果它们耗尽了关键资源，它们就会死亡。我们报告了使用Ecotwin进行的三个研究的结果，其中自然现象在模型中出现而无需硬编码。

    We start by discussing the link between ecosystem simulators and general AI. Then we present the open-source ecosystem simulator Ecotwin, which is based on the game engine Unity and operates on ecosystems containing inanimate objects like mountains and lakes, as well as organisms such as animals and plants. Animal cognition is modeled by integrating three separate networks: (i) a reflex network for hard-wired reflexes; (ii) a happiness network that maps sensory data such as oxygen, water, energy, and smells, to a scalar happiness value; and (iii) a policy network for selecting actions. The policy network is trained with reinforcement learning (RL), where the reward signal is defined as the happiness difference from one time step to the next. All organisms are capable of either sexual or asexual reproduction, and they die if they run out of critical resources. We report results from three studies with Ecotwin, in which natural phenomena emerge in the models without being hardwired. Firs
    
[^82]: 有界理性下的量级序列模型：放宽最优反应和互相一致性的限制

    Bounded rationality for relaxing best response and mutual consistency: The Quantal Hierarchy model of decision-making. (arXiv:2106.15844v5 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2106.15844](http://arxiv.org/abs/2106.15844)

    本研究提出了Quantal Hierarchy模型，放宽了互相一致性和最优反应的限制，使得可以近似级别K，QRE或Nash均衡行为。这种模型基于变分自由能原理的递归形式，将更高阶推理表示为演化形式博弈树中的（伪）序列决策制定。

    

    尽管博弈论对决策制定具有转型性的作用，但在某些情况下，所假设的条件可能过于严格。在本研究中，我们调查了理性的一些潜在假设，如互相一致性和最优反应，并考虑使用级别K推理和量化反馈平衡（QRE）的概念放宽这些假设的方法。具体而言，我们提出了一个名为Quantal Hierarchy模型的信息论双参数模型，可以放宽互相一致性和最优反应的限制，同时在极限情况下近似级别K，QRE或典型的Nash均衡行为。该模型基于变分自由能原理的递归形式，将更高阶推理表示为演化形式博弈树中的（伪）序列决策制定。这种表示方法使我们能够以类似于顺序博弈的方式处理同时博弈，其中推理资源在游戏中逐渐耗尽。

    While game theory has been transformative for decision-making, the assumptions made can be overly restrictive in certain instances. In this work, we investigate some of the underlying assumptions of rationality, such as mutual consistency and best response, and consider ways to relax these assumptions using concepts from level-$k$ reasoning and quantal response equilibrium (QRE) respectively. Specifically, we propose an information-theoretic two-parameter model called the Quantal Hierarchy model, which can relax both mutual consistency and best response while still approximating level-$k$, QRE, or typical Nash equilibrium behaviour in the limiting cases. The model is based on a recursive form of the variational free energy principle, representing higher-order reasoning as (pseudo) sequential decision-making in extensive-form game tree. This representation enables us to treat simultaneous games in a similar manner to sequential games, where reasoning resources deplete throughout the gam
    
[^83]: 多标签文本分类的标签提示方法

    Label prompt for multi-label text classification. (arXiv:2106.10076v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.10076](http://arxiv.org/abs/2106.10076)

    本文提出了一种 Label Mask 多标签文本分类模型（LM-MTC），利用预训练语言模型的能力来捕捉标签之间的隐含关系，并通过基于标签的遮盖语言模型（MLM）进一步提高模型的泛化能力。

    

    在多标签文本分类中，一个关键问题是如何利用标签之间的关联。但是，在一个复杂和未知的标签空间中直接建模标签之间的关联是非常具有挑战性的。在本文中，我们提出了一种 Label Mask 多标签文本分类模型（LM-MTC），它受到语言模型的填空问题思想的启发。LM-MTC 能够通过预训练语言模型的强大能力捕捉标签之间的隐含关系。在此基础上，我们为每个潜在标签分配一个不同的标记，并以一定概率随机遮盖该标记，建立了基于标签的遮掩语言模型（MLM）。我们同时训练 MTC 和 MLM，进一步提高了模型的泛化能力。多个数据集上的大量实验证明了我们方法的有效性。

    One of the key problems in multi-label text classification is how to take advantage of the correlation among labels. However, it is very challenging to directly model the correlations among labels in a complex and unknown label space. In this paper, we propose a Label Mask multi-label text classification model (LM-MTC), which is inspired by the idea of cloze questions of language model. LM-MTC is able to capture implicit relationships among labels through the powerful ability of pre-train language models. On the basis, we assign a different token to each potential label, and randomly mask the token with a certain probability to build a label based Masked Language Model (MLM). We train the MTC and MLM together, further improving the generalization ability of the model. A large number of experiments on multiple datasets demonstrate the effectiveness of our method.
    
[^84]: 自适应熵树搜索的规划与学习

    Planning and Learning Using Adaptive Entropy Tree Search. (arXiv:2102.06808v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2102.06808](http://arxiv.org/abs/2102.06808)

    本论文提出了一种全新的算法ANTS，它将规划和学习结合在最大熵范式中，并通过在Atari基准测试上的实验证明其明显优于当前最先进的AlphaZero系统的规划组件PUCT，具有较强的稳健性，可推动基于树的规划方法的实际应用。

    

    最近的人工智能突破表明，将基于树的规划与深度学习相结合可以实现更高的性能。本论文提出了一种称作自适应熵树搜索（ANTS）的全新算法，将规划和学习结合在最大熵范式中。通过在Atari基准测试上进行全面的实验，我们证明ANTS明显优于目前最先进的AlphaZero系统的规划组件PUCT。ANTS建立在最大熵规划方法的基础之上，然而我们发现这种方法在与学习相结合时表现不佳，ANTS解决了这个问题并达到了与目前最先进算法相当的性能水平。此外，我们还发现ANTS在不同的超参数选择下表现出更强的稳健性。我们相信，ANTS的高性能和稳健性将使基于树的规划方法更加适用于实际应用。

    Recent breakthroughs in Artificial Intelligence have shown that the combination of tree-based planning with deep learning can lead to superior performance. We present Adaptive Entropy Tree Search (ANTS) - a novel algorithm combining planning and learning in the maximum entropy paradigm. Through a comprehensive suite of experiments on the Atari benchmark we show that ANTS significantly outperforms PUCT, the planning component of the state-of-the-art AlphaZero system. ANTS builds upon recent work on maximum entropy planning methods - which however, as we show, fail in combination with learning. ANTS resolves this issue to reach state-of-the-art performance. We further find that ANTS exhibits superior robustness to different hyperparameter choices, compared to the previous algorithms. We believe that the high performance and robustness of ANTS can bring tree search planning one step closer to wide practical adoption.
    
[^85]: 动态认知逻辑中的信息变化量化模态：概述与评估

    To Be Announced. (arXiv:2004.05802v4 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2004.05802](http://arxiv.org/abs/2004.05802)

    该论文综述了动态认知逻辑中的信息变化量化模态，包括公理化、表述方式、可决定性和复杂性评估，并提出了未解决的问题和研究方向。

    

    在这篇论文中，我们回顾了具有信息变化量化模态的动态认知逻辑，并介绍了其完整的公理化。我们关注了涉及知识和量词交互作用的公理，在表述方式、可决定性、模型检查和可满足性的复杂性，以及应用方面进行了评估。我们重点关注开放的问题和研究新方向。

    In this survey we review dynamic epistemic logics with modalities for quantification over information change. Of such logics we present complete axiomatizations, focussing on axioms involving the interaction between knowledge and such quantifiers, we report on their relative expressivity, on decidability and on the complexity of model checking and satisfiability, and on applications. We focus on open problems and new directions for research.
    

