# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [INSIGHT: End-to-End Neuro-Symbolic Visual Reinforcement Learning with Language Explanations](https://arxiv.org/abs/2403.12451) | 本文提出了一种可以同时学习结构化状态和符号策略的框架，通过将视觉基础模型提炼成可扩展的感知模块来克服效率瓶颈，并利用大的语言模型生成简洁易读的语言解释。 |
| [^2] | [Learning Macroeconomic Policies based on Microfoundations: A Stackelberg Mean Field Game Approach](https://arxiv.org/abs/2403.12093) | 本研究提出了基于Stackelberg Mean Field Game的方法，可以有效地学习宏观经济政策，并在模型预训练和无模型Stackelberg均场强化学习算法的基础上取得了实验结果表明其优越性。 |
| [^3] | [QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction](https://arxiv.org/abs/2403.11886) | QueryAgent提出了一种基于环境反馈的自我校正方法ERASER，在语义解析中表现出显著的性能提升和高效性 |
| [^4] | [Demystifying Deep Reinforcement Learning-Based Autonomous Vehicle Decision-Making](https://arxiv.org/abs/2403.11432) | 本研究致力于研究基于注意力的DRL框架的可解释性，在自主车辆决策中，通过在开源AV仿真环境中添加多头注意力框架，提高了模型的解释性。 |
| [^5] | [ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image](https://arxiv.org/abs/2403.09871) | ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。 |
| [^6] | [KEBench: A Benchmark on Knowledge Editing for Large Vision-Language Models](https://arxiv.org/abs/2403.07350) | KEBench提出了一个新的基准测试，采用不同的数据收集方法和新增加的度量标准（可移植性），以全面评估大型视觉-语言模型知识编辑的质量。 |
| [^7] | [Towards Safe and Aligned Large Language Models for Medicine](https://arxiv.org/abs/2403.03744) | 对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。 |
| [^8] | [Speech emotion recognition from voice messages recorded in the wild](https://arxiv.org/abs/2403.02167) | 使用Emotional Voice Messages数据库，结合eGeMAPS特征和Transformer模型，实现了在野外录制的语音消息中的语音情感识别，取得了较高的准确度，并比基准模型提高了10%。 |
| [^9] | [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](https://arxiv.org/abs/2403.01924) | 本文介绍了MedGENIE，这是医学领域多项选择问题回答的第一个生成后阅读框架。 |
| [^10] | [CLLMs: Consistency Large Language Models](https://arxiv.org/abs/2403.00835) | 提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。 |
| [^11] | [Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages](https://arxiv.org/abs/2402.17496) | 该研究介绍了Emotional Voice Messages (EMOVOME)数据库，其中包含来自100名西班牙说话者的999条自发语音消息，通过专家和非专家的标记实现了在valence和arousal维度上的情感识别，并尝试使用语音和文本转录实现情感识别模型。 |
| [^12] | [The European Commitment to Human-Centered Technology: The Integral Role of HCI in the EU AI Act's Success](https://arxiv.org/abs/2402.14728) | 欧盟AI法案强调透明性、可解释性和人类理解能力，提出了人本AI系统的民主呼吁，同时制定了人本创新的跨学科研究议程，以避免重复GDPR的错误并避免实施混乱。 |
| [^13] | [FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models](https://arxiv.org/abs/2402.10986) | FinTral是一类基于Mistral-7b模型的GPT-4级别多模态金融大型语言模型，通过领域特定的预训练和检索方法优化，在AI驱动金融技术中取得显著进展。 |
| [^14] | [MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music](https://arxiv.org/abs/2402.09871) | MuChin是一个用于评估多模态语言模型在音乐理解和描述方面性能的中文口语描述基准。 |
| [^15] | [Transfer learning with generative models for object detection on limited datasets](https://arxiv.org/abs/2402.06784) | 本论文提出了一个适用于通用情景的基于生成模型的迁移学习框架，用于解决有限数据集上的目标检测任务。 |
| [^16] | [CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion](https://arxiv.org/abs/2402.05889) | 该论文提出了一种名为CREMA的高效且模块化的模态融合框架，用于将任意新的模态注入视频推理。通过利用预训练模型增强多种信息模态，并引入查询转换器和融合模块，实现了灵活且有效的多模态组合推理。 |
| [^17] | [LESS: Selecting Influential Data for Targeted Instruction Tuning](https://arxiv.org/abs/2402.04333) | LESS是一种优化感知且实际高效的算法，用于在大型语言模型中选择具有影响力的数据以开发特定能力，它采用低秩梯度相似性搜索方法进行指令数据选择。 |
| [^18] | [Flora: Low-Rank Adapters Are Secretly Gradient Compressors](https://arxiv.org/abs/2402.03293) | 本文研究了低秩适配器的动力学，并提出了一种基于随机投影的方法Flora，通过重新采样投影矩阵实现高秩更新，同时减少优化状态的空间复杂度。 |
| [^19] | [ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models](https://arxiv.org/abs/2401.17230) | ESPnet-SPK是一个全流程说话人嵌入工具包，具备可复现的配方、自监督的前端和现成模型，能够轻松构建模型并与其他领域进行集成。其通过优化的架构设计和多样的自监督学习特征，实现了在多个任务中的出色性能。 |
| [^20] | [Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey](https://arxiv.org/abs/2401.11963) | 通过整合进化算法与强化学习，进化强化学习（ERL）展现出卓越的性能提升，本综述呈现了ERL领域的各个研究分支，突出了EA辅助RL的优化、RL辅助EA的优化以及EA和RL的协同优化这三个主要研究方向。 |
| [^21] | [Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models](https://arxiv.org/abs/2311.17095) | 提出了一种简单但高效的无需训练的技术，用于开放词汇语义分割，通过使用VLM和显著性丢弃来解决过度分割和欠分割的问题 |
| [^22] | [Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning](https://arxiv.org/abs/2311.08894) | 提出了一种新的KBQA架构FuSIC-KBQA，通过多个源训练的召回器执行KB检索，在LLM的重新排序后以此作为LLM少样本上下文学习的输入来生成逻辑形式，并利用执行引导反馈进一步优化。 |
| [^23] | [Exploring semantic information in disease: Simple Data Augmentation Techniques for Chinese Disease Normalization](https://arxiv.org/abs/2306.01931) | 提出了一组定制的数据增强技术，旨在利用疾病名称中的语义信息，增强模型对疾病名称的语义细微差别和分类结构的理解 |
| [^24] | [Whole Page Unbiased Learning to Rank](https://arxiv.org/abs/2210.10718) | 本论文提出整页无偏学习排序（WP-ULTR）方法处理整页 SERP 特征引发的偏差，该方法面临适合的用户行为模型的挑战和复杂的模型训练难题。 |
| [^25] | [Unlearning Reveals the Influential Training Data of Language Models.](http://arxiv.org/abs/2401.15241) | 本文提出了一种简单而有效的方法UnTrac，通过反学习训练数据集来估计语言模型的影响。实验结果表明，UnTrac能够准确评估预训练数据集对生成有害内容的影响，并且无需额外的资源。 |
| [^26] | [Learning Racing From an AI Coach: Effects of Multimodal Autonomous Driving Explanations on Driving Performance, Cognitive Load, Expertise, and Trust.](http://arxiv.org/abs/2401.04206) | 本研究测试了一种AI驾驶教练的解释对驾驶表现、认知负荷、专业知识和信任的影响。结果显示，AI驾驶教练对于教授新手驾驶技能是有帮助的，并且信息类型和呈现方式对表现结果有影响。 |
| [^27] | [Human as AI Mentor: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving.](http://arxiv.org/abs/2401.03160) | 本文提出了一种增强的人机协作强化学习方法，通过将人类智能注入到AI中实现混合交通编队中的安全高效自动驾驶。该方法将人类专家作为导师，允许代理在不确定环境中进行探索，同时在危险情况下接管控制以避免事故，并指导代理减小交通流干扰，优化交通流效果。 |
| [^28] | [INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing.](http://arxiv.org/abs/2311.09868) | INTERVENOR模型通过模拟人类修复代码的行为，使用交互式修复链条来引导大型语言模型的编码能力，取得了显著的性能提升。 |
| [^29] | [Recognize Any Regions.](http://arxiv.org/abs/2311.01373) | 本文提出了一种名为RegionSpot的新型、通用且高效的区域识别架构，旨在解决在计算机视觉中理解无约束图像中区域的语义的挑战。 |
| [^30] | [DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection.](http://arxiv.org/abs/2310.16776) | 这项研究介绍了一种名为DEFT的数据高效微调框架，通过无监督核心集选择来最小化微调大规模语言模型所需的数据量。研究结果表明，DEFT模型在准确性上与现有模型相当，并且仅使用了70%的数据量。 |
| [^31] | [Concise and Organized Perception Facilitates Large Language Models for Deductive Reasoning.](http://arxiv.org/abs/2310.03309) | 利用大型语言模型进行演绎推理是一个具有挑战性的问题。这篇论文提出了一个简明有序的方法，将任务分解为子任务并且人类化地组织思维，以提高演绎推理的效果。 |
| [^32] | [Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models.](http://arxiv.org/abs/2310.02409) | Nugget 2D是一种用于仅解码器语言模型的动态上下文压缩方法，可以在保留任务能力的同时大幅减少解码过程所需的时间和空间开销。 |
| [^33] | [Tell Me a Story! Narrative-Driven XAI with Large Language Models.](http://arxiv.org/abs/2309.17057) | 这项研究提出了基于大型语言模型的XAIstories框架，通过叙事方式解释AI预测，其中SHAPstories基于SHAP解释解释预测得分，CFstories基于CF解释解释决策。研究结果表明，超过90%的普通读者认可SHAPstories生成的叙事的说服力，92%的数据科学家认为SHAPstories能够提高非专业人士的易用性和信心。 |
| [^34] | [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes.](http://arxiv.org/abs/2309.00237) | 使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。 |
| [^35] | [Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment.](http://arxiv.org/abs/2305.13669) | 本文提出了MixAlign框架，通过与用户和知识库交互，实现自动的问题-知识对齐，从而解决了语言模型因无法正确理解问题和知识而导致的幻觉问题。 |
| [^36] | [Artificial Intelligence and Dual Contract.](http://arxiv.org/abs/2303.12350) | 本文通过实验研究了人工智能算法在双重合同问题中能够自主设计激励相容的合同，无需外部引导或通信，并且不同AI算法支持的委托人可以采用混合和零和博弈行为，更具智能的委托人往往会变得合作。 |
| [^37] | [Robust Knowledge Transfer in Tiered Reinforcement Learning.](http://arxiv.org/abs/2302.05534) | 本文研究了层级增强学习中的知识传输，提出了一种新颖的在线学习算法，在没有先验知识的任务相似性的情况下实现强大的知识传输。 |

# 详细

[^1]: INSIGHT: 带有语言解释的端到端神经符号视觉强化学习

    INSIGHT: End-to-End Neuro-Symbolic Visual Reinforcement Learning with Language Explanations

    [https://arxiv.org/abs/2403.12451](https://arxiv.org/abs/2403.12451)

    本文提出了一种可以同时学习结构化状态和符号策略的框架，通过将视觉基础模型提炼成可扩展的感知模块来克服效率瓶颈，并利用大的语言模型生成简洁易读的语言解释。

    

    神经符号强化学习（NS-RL）已成为可解释决策制定的有希望的范式，其特点是符号策略的可解释性。对于具有视觉观测的任务，NS-RL涉及对状态进行结构化表示，但由于缺乏效率，先前的算法无法利用奖励信号来细化结构化状态。可访问性也是一个问题，因为需要广泛的领域知识来解释当前的符号策略。在本文中，我们提出了一个能够同时学习结构化状态和符号策略的框架，其关键思想是通过将视觉基础模型提炼成可扩展的感知模块，克服效率瓶颈。此外，我们设计了一个流水线，利用大的语言模型为政策和决策生成简洁易读的语言解释。在九个Atari任务的实验中，我们的方法表现出...

    arXiv:2403.12451v1 Announce Type: new  Abstract: Neuro-symbolic reinforcement learning (NS-RL) has emerged as a promising paradigm for explainable decision-making, characterized by the interpretability of symbolic policies. For tasks with visual observations, NS-RL entails structured representations for states, but previous algorithms are unable to refine the structured states with reward signals due to a lack of efficiency. Accessibility is also an issue, as extensive domain knowledge is required to interpret current symbolic policies. In this paper, we present a framework that is capable of learning structured states and symbolic policies simultaneously, whose key idea is to overcome the efficiency bottleneck by distilling vision foundation models into a scalable perception module. Moreover, we design a pipeline that uses large language models to generate concise and readable language explanations for policies and decisions. In experiments on nine Atari tasks, our approach demonstrat
    
[^2]: 基于微观基础的宏观经济政策学习：一种斯塔克尔贝格均场博弈方法

    Learning Macroeconomic Policies based on Microfoundations: A Stackelberg Mean Field Game Approach

    [https://arxiv.org/abs/2403.12093](https://arxiv.org/abs/2403.12093)

    本研究提出了基于Stackelberg Mean Field Game的方法，可以有效地学习宏观经济政策，并在模型预训练和无模型Stackelberg均场强化学习算法的基础上取得了实验结果表明其优越性。

    

    有效的宏观经济政策在促进经济增长和社会稳定方面起着至关重要的作用。本文基于Stackelberg Mean Field Game（SMFG）模型，将最优宏观经济政策问题建模，其中政府作为政策制定的领导者，大规模家庭动态响应为追随者。这种建模方法捕捉了政府和大规模家庭之间的非对称动态博弈，并可以解释地评估基于微观基础的宏观经济政策效果，这是现有方法难以实现的。我们还提出了一种解决SMFG的方法，将真实数据进行预训练，并结合一种无模型的Stackelberg均场强化学习（SMFRL）算法，该算法可以独立于先前的环境知识和转变运行。我们的实验结果展示了SMFG方法在经济政策方面优于其他方法的优越性。

    arXiv:2403.12093v1 Announce Type: cross  Abstract: Effective macroeconomic policies play a crucial role in promoting economic growth and social stability. This paper models the optimal macroeconomic policy problem based on the \textit{Stackelberg Mean Field Game} (SMFG), where the government acts as the leader in policy-making, and large-scale households dynamically respond as followers. This modeling method captures the asymmetric dynamic game between the government and large-scale households, and interpretably evaluates the effects of macroeconomic policies based on microfoundations, which is difficult for existing methods to achieve. We also propose a solution for SMFGs, incorporating pre-training on real data and a model-free \textit{Stackelberg mean-field reinforcement learning }(SMFRL) algorithm, which operates independently of prior environmental knowledge and transitions. Our experimental results showcase the superiority of the SMFG method over other economic policies in terms 
    
[^3]: QueryAgent：一种具有环境反馈的可靠高效推理框架及自我校正

    QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction

    [https://arxiv.org/abs/2403.11886](https://arxiv.org/abs/2403.11886)

    QueryAgent提出了一种基于环境反馈的自我校正方法ERASER，在语义解析中表现出显著的性能提升和高效性

    

    使用大型语言模型（LLMs）进行语义解析取得了显著成功，但在遇到幻觉时现有方法可靠性和效率方面存在不足。本文提出了一个名为QueryAgent的框架，通过逐步解决问题并进行逐步自我校正来解决这些挑战。我们引入了一种基于环境反馈的自我校正方法ERASER。与传统方法不同，ERASER利用中间步骤中的丰富环境反馈，在必要时仅进行选择性和差异化的自我校正。实验结果表明，QueryAgent在GrailQA和GraphQ上仅使用一个例子就比所有先前的少样本方法取得了7.0和15.0的F1值提升。此外，我们的方法在效率方面表现出优势，包括运行时间、查询开销和API调用成本。通过利用ERASER，

    arXiv:2403.11886v1 Announce Type: cross  Abstract: Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find existing methods fall short in terms of reliability and efficiency when hallucinations are encountered. In this paper, we address these challenges with a framework called QueryAgent, which solves a question step-by-step and performs step-wise self-correction. We introduce an environmental feedback-based self-correction method called ERASER. Unlike traditional approaches, ERASER leverages rich environmental feedback in the intermediate steps to perform selective and differentiated self-correction only when necessary. Experimental results demonstrate that QueryAgent notably outperforms all previous few-shot methods using only one example on GrailQA and GraphQ by 7.0 and 15.0 F1. Moreover, our approach exhibits superiority in terms of efficiency, including runtime, query overhead, and API invocation costs. By leveraging ERASER, we
    
[^4]: 深度强化学习驱动的自主车辆决策的揭秘

    Demystifying Deep Reinforcement Learning-Based Autonomous Vehicle Decision-Making

    [https://arxiv.org/abs/2403.11432](https://arxiv.org/abs/2403.11432)

    本研究致力于研究基于注意力的DRL框架的可解释性，在自主车辆决策中，通过在开源AV仿真环境中添加多头注意力框架，提高了模型的解释性。

    

    随着强化学习领域中通用函数逼近器的出现，利用深度强化学习（DRL）的实际应用数量激增。自动驾驶任务中的决策制定已成为其中一项主要应用，将传感器数据或高阶运动学变量作为输入，并提供离散选择或连续控制输出。然而，模型的黑盒特性限制了DRL在自主车辆中的实际部署。因此，在这项研究工作中，我们关注基于注意力的DRL框架的可解释性。我们在开源AV仿真环境中使用了基于连续近端策略优化的DRL算法作为基线模型，并添加了一个多头注意力框架。我们提供了一些分析技术来讨论训练模型的可解释性。

    arXiv:2403.11432v1 Announce Type: cross  Abstract: With the advent of universal function approximators in the domain of reinforcement learning, the number of practical applications leveraging deep reinforcement learning (DRL) has exploded. Decision-making in automated driving tasks has emerged as a chief application among them, taking the sensor data or the higher-order kinematic variables as the input and providing a discrete choice or continuous control output. However, the black-box nature of the models presents an overwhelming limitation that restricts the real-world deployment of DRL in autonomous vehicles (AVs). Therefore, in this research work, we focus on the interpretability of an attention-based DRL framework. We use a continuous proximal policy optimization-based DRL algorithm as the baseline model and add a multi-head attention framework in an open-source AV simulation environment. We provide some analytical techniques for discussing the interpretability of the trained mode
    
[^5]: ThermoHands：一种用于从主观视角热图中估计3D手部姿势的基准

    ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image

    [https://arxiv.org/abs/2403.09871](https://arxiv.org/abs/2403.09871)

    ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。

    

    在这项工作中，我们提出了ThermoHands，这是一个针对基于热图的主观视角3D手部姿势估计的新基准，旨在克服诸如光照变化和遮挡（例如手部穿戴物）等挑战。该基准包括来自28名主体进行手-物体和手-虚拟交互的多样数据集，经过自动化过程准确标注了3D手部姿势。我们引入了一个定制的基线方法TheFormer，利用双transformer模块在热图中实现有效的主观视角3D手部姿势估计。我们的实验结果突显了TheFormer的领先性能，并确认了热成像在实现恶劣条件下稳健的3D手部姿势估计方面的有效性。

    arXiv:2403.09871v1 Announce Type: cross  Abstract: In this work, we present ThermoHands, a new benchmark for thermal image-based egocentric 3D hand pose estimation, aimed at overcoming challenges like varying lighting and obstructions (e.g., handwear). The benchmark includes a diverse dataset from 28 subjects performing hand-object and hand-virtual interactions, accurately annotated with 3D hand poses through an automated process. We introduce a bespoken baseline method, TheFormer, utilizing dual transformer modules for effective egocentric 3D hand pose estimation in thermal imagery. Our experimental results highlight TheFormer's leading performance and affirm thermal imaging's effectiveness in enabling robust 3D hand pose estimation in adverse conditions.
    
[^6]: KEBench: 用于大型视觉-语言模型知识编辑的基准测试

    KEBench: A Benchmark on Knowledge Editing for Large Vision-Language Models

    [https://arxiv.org/abs/2403.07350](https://arxiv.org/abs/2403.07350)

    KEBench提出了一个新的基准测试，采用不同的数据收集方法和新增加的度量标准（可移植性），以全面评估大型视觉-语言模型知识编辑的质量。

    

    arXiv:2403.07350v1 公告类型: 跨领域 摘要: 目前，针对大型视觉-语言模型(LVLMs)的知识编辑研究很少。编辑LVLMs面临着有效整合多种模态（图像和文本）的挑战，同时确保修改连贯且与上下文相关。现有基准测试具有三个度量标准（可靠性、局部性和一般性）用于衡量LVLMs的知识编辑。然而，该基准测试在评估中使用的生成图像质量不足，并且无法评估模型是否有效地利用与相关内容相关的编辑知识。我们采用不同的数据收集方法构建了一个新的基准测试$\textbf{KEBench}$，并扩展了新度量标准(可移植性)以进行全面评估。借助多模态知识图，我们的图像数据呈现出明确的给实体方向性。这种方向性可以进一步用于提取与实体相关的知识和进行编辑。

    arXiv:2403.07350v1 Announce Type: cross  Abstract: Currently, little research has been done on knowledge editing for Large Vision-Language Models (LVLMs). Editing LVLMs faces the challenge of effectively integrating diverse modalities (image and text) while ensuring coherent and contextually relevant modifications. An existing benchmark has three metrics (Reliability, Locality and Generality) to measure knowledge editing for LVLMs. However, the benchmark falls short in the quality of generated images used in evaluation and cannot assess whether models effectively utilize edited knowledge in relation to the associated content. We adopt different data collection methods to construct a new benchmark, $\textbf{KEBench}$, and extend new metric (Portability) for a comprehensive evaluation. Leveraging a multimodal knowledge graph, our image data exhibits clear directionality towards entities. This directional aspect can be further utilized to extract entity-related knowledge and form editing 
    
[^7]: 为医药领域打造安全和对齐的大型语言模型

    Towards Safe and Aligned Large Language Models for Medicine

    [https://arxiv.org/abs/2403.03744](https://arxiv.org/abs/2403.03744)

    对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。

    

    大型语言模型（LLMs）的能力正在以惊人的速度进步，即使是它们的开发者也对它们的潜力和风险的深度感到困惑。尽管已经采取了初步步骤评估通用知识LLMs的安全性和对齐性，揭示了一些弱点，但据我们所知，尽管在个人健康和安全、公共健康和安全以及人权方面存在风险，医学LLMs的安全性和对齐性尚未得到评估。为此，我们进行了对医学LLMs的首次安全评估。具体而言，我们提出了医学人工智能系统的医学安全性和对齐性的定义，开发了一个有害医学问题的数据集来评估LLM的医学安全性和对齐性，评估了医学LLMs的通用安全性和对齐性，展示了微调作为一种有效的缓解策略，并讨论了更广泛的、大规模的方法。

    arXiv:2403.03744v1 Announce Type: new  Abstract: The capabilities of large language models (LLMs) have been progressing at a breathtaking speed, leaving even their own developers grappling with the depth of their potential and risks. While initial steps have been taken to evaluate the safety and alignment of general-knowledge LLMs, exposing some weaknesses, to our knowledge, the safety and alignment of medical LLMs has not been evaluated despite their risks for personal health and safety, public health and safety, and human rights. To this end, we carry out the first safety evaluation for medical LLMs. Specifically, we set forth a definition of medical safety and alignment for medical artificial intelligence systems, develop a dataset of harmful medical questions to evaluate the medical safety and alignment of an LLM, evaluate both general and medical safety and alignment of medical LLMs, demonstrate fine-tuning as an effective mitigation strategy, and discuss broader, large-scale appr
    
[^8]: 从野外录制的语音消息中识别语音情感

    Speech emotion recognition from voice messages recorded in the wild

    [https://arxiv.org/abs/2403.02167](https://arxiv.org/abs/2403.02167)

    使用Emotional Voice Messages数据库，结合eGeMAPS特征和Transformer模型，实现了在野外录制的语音消息中的语音情感识别，取得了较高的准确度，并比基准模型提高了10%。

    

    用于语音情感识别（SER）的情感数据集通常包含表演或引发的语音，限制了它们在现实场景中的适用性。在这项工作中，我们使用了Emotional Voice Messages（EMOVOME）数据库，其中包括来自100名西班牙语使用者在消息应用中的自发语音消息，由专家和非专家标注者以连续和离散的情感进行标记。我们使用了eGeMAPS特征、基于Transformer的模型以及它们的组合来创建讲话者无关的SER模型。我们将结果与参考数据库进行了比较，并分析了标注者和性别公平性的影响。预训练的Unispeech-L模型及其与eGeMAPS的组合取得了最佳结果，在3类valence和arousal预测中分别获得了61.64%和55.57%的Unweighted Accuracy（UA），比基线模型提高了10%。对于情感类别，获得了42.58%的UA。EMOVOME表现不佳。

    arXiv:2403.02167v1 Announce Type: cross  Abstract: Emotion datasets used for Speech Emotion Recognition (SER) often contain acted or elicited speech, limiting their applicability in real-world scenarios. In this work, we used the Emotional Voice Messages (EMOVOME) database, including spontaneous voice messages from conversations of 100 Spanish speakers on a messaging app, labeled in continuous and discrete emotions by expert and non-expert annotators. We created speaker-independent SER models using the eGeMAPS features, transformer-based models and their combination. We compared the results with reference databases and analyzed the influence of annotators and gender fairness. The pre-trained Unispeech-L model and its combination with eGeMAPS achieved the highest results, with 61.64% and 55.57% Unweighted Accuracy (UA) for 3-class valence and arousal prediction respectively, a 10% improvement over baseline models. For the emotion categories, 42.58% UA was obtained. EMOVOME performed low
    
[^9]: 生成还是检索？关于人工环境在医学开放域问答效果的研究

    To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering

    [https://arxiv.org/abs/2403.01924](https://arxiv.org/abs/2403.01924)

    本文介绍了MedGENIE，这是医学领域多项选择问题回答的第一个生成后阅读框架。

    

    医学领域的开放域问答需要大量专业知识的支持。近期的努力致力于将知识与模型参数分离，对抗架构规模化，并允许在常见的低资源硬件上进行训练。检索然后阅读的范式已变得普遍，模型预测依赖于来自外部知识库（如PubMed、教科书和UMLS）的相关知识片段。另一条尚未得到充分探索但由于领域特定大型语言模型的出现变得可能的路径是通过提示构建人工环境。因此，“生成还是检索”成为了现代版的哈姆雷特困境。本文提出了MedGENIE，这是医学领域多项选择问答的生成然后阅读框架。我们在MedQA-USMLE、MedMCQA和MMLU上进行了广泛实验，从实践的角度出发，假设最大

    arXiv:2403.01924v1 Announce Type: cross  Abstract: Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible by the advent of domain-specific large language models, entails constructing artificial contexts through prompting. As a result, "to generate or to retrieve" is the modern equivalent of Hamlet's dilemma. This paper presents MedGENIE, the first generate-then-read framework for multiple-choice question answering in medicine. We conduct extensive experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical perspective by assuming a maxim
    
[^10]: CLLMs: 一致性大型语言模型

    CLLMs: Consistency Large Language Models

    [https://arxiv.org/abs/2403.00835](https://arxiv.org/abs/2403.00835)

    提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。

    

    并行解码方法，如雅可比解码，显示出有望实现更高效的LLM推断，因为它打破了LLM解码过程的顺序性，并将其转换为可并行化计算。然而，在实践中，与传统的自回归（AR）解码相比，雅可比解码很少能在单个固定点迭代步骤中准确预测多个标记，因此在速度上取得的提升相对较小。为了解决这个问题，我们开发了一种新方法，旨在实现从任何状态快速收敛到雅各比轨迹上的固定点。通过精细调整目标LLM，以便在任何输入状态下一致地预测固定点。大量实验证明了我们方法的有效性，在领域特定和开放域基准测试中显示出生成速度提高了2.4倍到3.4倍，同时保持了生成质量。

    arXiv:2403.00835v1 Announce Type: cross  Abstract: Parallel decoding methods such as Jacobi decoding show promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point on a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\times$ to 3.4$\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.
    
[^11]: Emotional Voice Messages (EMOVOME)数据库：自发情感语音消息中的情感识别

    Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages

    [https://arxiv.org/abs/2402.17496](https://arxiv.org/abs/2402.17496)

    该研究介绍了Emotional Voice Messages (EMOVOME)数据库，其中包含来自100名西班牙说话者的999条自发语音消息，通过专家和非专家的标记实现了在valence和arousal维度上的情感识别，并尝试使用语音和文本转录实现情感识别模型。

    

    Emotional Voice Messages (EMOVOME)是一个自发语音数据集，包含来自100名西班牙说话者、男女性平衡的999条真实会话中的音频消息，这些消息通过一个消息应用程序产生，在参与者被招募之前在野外环境中制作，避免了由于实验室环境而产生的任何意识偏见。音频按照三个非专家和两个专家的认可在valence和arousal维度上进行了标记，然后将它们结合以获得每个维度的最终标签。专家还提供了对应于七种情感类别的额外标签。为了为将来使用EMOVOME进行调查设定基准，我们使用了语音和音频转录来实现情感识别模型。对于语音部分，我们使用了标准的eGeMAPS特征集和支持向量机，分别获得了49.27%和44.71%的valence和arousal未加权准确度。对于文本部分，我们对一个多语言BERT模型进行了微调，并实现了61%的情感识别准确度。

    arXiv:2402.17496v1 Announce Type: cross  Abstract: Emotional Voice Messages (EMOVOME) is a spontaneous speech dataset containing 999 audio messages from real conversations on a messaging app from 100 Spanish speakers, gender balanced. Voice messages were produced in-the-wild conditions before participants were recruited, avoiding any conscious bias due to laboratory environment. Audios were labeled in valence and arousal dimensions by three non-experts and two experts, which were then combined to obtain a final label per dimension. The experts also provided an extra label corresponding to seven emotion categories. To set a baseline for future investigations using EMOVOME, we implemented emotion recognition models using both speech and audio transcriptions. For speech, we used the standard eGeMAPS feature set and support vector machines, obtaining 49.27% and 44.71% unweighted accuracy for valence and arousal respectively. For text, we fine-tuned a multilingual BERT model and achieved 61
    
[^12]: 欧洲对人本科技的承诺：HCI在欧盟AI法案成功中的重要作用

    The European Commitment to Human-Centered Technology: The Integral Role of HCI in the EU AI Act's Success

    [https://arxiv.org/abs/2402.14728](https://arxiv.org/abs/2402.14728)

    欧盟AI法案强调透明性、可解释性和人类理解能力，提出了人本AI系统的民主呼吁，同时制定了人本创新的跨学科研究议程，以避免重复GDPR的错误并避免实施混乱。

    

    AI的发展将深刻重塑未来。欧盟认识到这一即将到来的重要性，已经通过了AI法案，对基于AI的系统的市场准入进行监管。该法案的一个显著特征是通过专注于透明性、可解释性以及人类理解和控制AI系统的能力，维护民主和人道主义价值观。因此，欧盟AI法案不仅仅规定了AI系统的技术要求。欧盟发出了一个民主号召，要求人本AI系统，进而制定了人本创新的跨学科研究议程，促进AI发展中的人本创新。如果没有强大的方法来评估AI系统及其对个人和社会的影响，欧盟AI法案可能会导致重复欧盟《一般数据保护条例》的错误，导致仓促、混乱、临时和模糊的实施，带来更多的困惑而不是指导。

    arXiv:2402.14728v1 Announce Type: cross  Abstract: The evolution of AI is set to profoundly reshape the future. The European Union, recognizing this impending prominence, has enacted the AI Act, regulating market access for AI-based systems. A salient feature of the Act is to guard democratic and humanistic values by focusing regulation on transparency, explainability, and the human ability to understand and control AI systems. Hereby, the EU AI Act does not merely specify technological requirements for AI systems. The EU issues a democratic call for human-centered AI systems and, in turn, an interdisciplinary research agenda for human-centered innovation in AI development. Without robust methods to assess AI systems and their effect on individuals and society, the EU AI Act may lead to repeating the mistakes of the General Data Protection Regulation of the EU and to rushed, chaotic, ad-hoc, and ambiguous implementation, causing more confusion than lending guidance. Moreover, determine
    
[^13]: FinTral：一类GPT-4级别的多模态金融大型语言模型

    FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models

    [https://arxiv.org/abs/2402.10986](https://arxiv.org/abs/2402.10986)

    FinTral是一类基于Mistral-7b模型的GPT-4级别多模态金融大型语言模型，通过领域特定的预训练和检索方法优化，在AI驱动金融技术中取得显著进展。

    

    我们引入FinTral，这是一组基于Mistral-7b模型构建的一流多模态大型语言模型（LLMs），专门为金融分析定制。FinTral整合了文本、数字、表格和图像数据。我们通过利用为本研究策划的大量文本和视觉数据集，通过领域特定的预训练、指导微调和RLAIF训练增强了FinTral。我们还介绍了一个包含九个任务和25个数据集进行评估的广泛基准测试，其中包括金融领域的幻觉。我们的FinTral模型，通过采用先进的工具和检索方法进行直接偏好优化训练，命名为FinTral-DPO-T&R，展现了出色的零-shot性能。它在所有任务中均优于ChatGPT-3.5，并在九项任务中的五项中超越GPT-4，标志着人工智能驱动的金融技术的重要进步。我们还展示了FinTral具有潜力

    arXiv:2402.10986v1 Announce Type: cross  Abstract: We introduce FinTral, a suite of state-of-the-art multimodal large language models (LLMs) built upon the Mistral-7b model and tailored for financial analysis. FinTral integrates textual, numerical, tabular, and image data. We enhance FinTral with domain-specific pretraining, instruction fine-tuning, and RLAIF training by exploiting a large collection of textual and visual datasets we curate for this work. We also introduce an extensive benchmark featuring nine tasks and 25 datasets for evaluation, including hallucinations in the financial domain. Our FinTral model trained with direct preference optimization employing advanced Tools and Retrieval methods, dubbed FinTral-DPO-T&R, demonstrates an exceptional zero-shot performance. It outperforms ChatGPT-3.5 in all tasks and surpasses GPT-4 in five out of nine tasks, marking a significant advancement in AI-driven financial technology. We also demonstrate that FinTral has the potential to e
    
[^14]: MuChin：用于评估音乐领域中语言模型的中文口语描述基准

    MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music

    [https://arxiv.org/abs/2402.09871](https://arxiv.org/abs/2402.09871)

    MuChin是一个用于评估多模态语言模型在音乐理解和描述方面性能的中文口语描述基准。

    

    快速发展的多模态大型语言模型（LLMs）迫切需要新的基准来统一评估它们在理解和以文字描述音乐方面的性能。然而，由于音乐信息检索（MIR）算法与人类理解之间的语义差距，专业人士和公众之间的差异，以及注释的低精度，现有的音乐描述数据集无法作为基准。为此，我们提出了MuChin，这是第一个用中文口语描述的开源音乐描述基准，旨在评估多模态LLMs在理解和描述音乐方面的性能。我们建立了采虫音乐注释平台（CaiMAP），采用创新的多人、多阶段保证方法，并招募了业余爱好者和专业人士，以确保注释的精度和与流行语义的对齐。利用这种方法，我们构建了一个数据集。

    arXiv:2402.09871v1 Announce Type: cross  Abstract: The rapidly evolving multimodal Large Language Models (LLMs) urgently require new benchmarks to uniformly evaluate their performance on understanding and textually describing music. However, due to semantic gaps between Music Information Retrieval (MIR) algorithms and human understanding, discrepancies between professionals and the public, and low precision of annotations, existing music description datasets cannot serve as benchmarks. To this end, we present MuChin, the first open-source music description benchmark in Chinese colloquial language, designed to evaluate the performance of multimodal LLMs in understanding and describing music. We established the Caichong Music Annotation Platform (CaiMAP) that employs an innovative multi-person, multi-stage assurance method, and recruited both amateurs and professionals to ensure the precision of annotations and alignment with popular semantics. Utilizing this method, we built a dataset w
    
[^15]: 有限数据集上基于生成模型的迁移学习用于目标检测

    Transfer learning with generative models for object detection on limited datasets

    [https://arxiv.org/abs/2402.06784](https://arxiv.org/abs/2402.06784)

    本论文提出了一个适用于通用情景的基于生成模型的迁移学习框架，用于解决有限数据集上的目标检测任务。

    

    在某些领域中，数据的可用性是有限的，尤其是对于目标检测任务，需要正确标记每个目标周围的边界框。一个显著的例子是在海洋生物学领域，需要开发自动检测海洋物种用于环境监测的方法。为了解决数据限制问题，目前最先进的机器学习策略采用了两种主要方法。第一种方法是在现有数据集上预训练模型，然后推广到具体的领域。第二种策略是使用copy-paste技术或ad-hoc模拟器等方法创建特定于目标领域的合成数据集。第一种方法往往面临重大的领域转移问题，而第二种方法需要针对特定任务设计定制解决方案。为了应对这些挑战，我们提出了一个在通用情景下有效的迁移学习框架。

    The availability of data is limited in some fields, especially for object detection tasks, where it is necessary to have correctly labeled bounding boxes around each object. A notable example of such data scarcity is found in the domain of marine biology, where it is useful to develop methods to automatically detect submarine species for environmental monitoring. To address this data limitation, the state-of-the-art machine learning strategies employ two main approaches. The first involves pretraining models on existing datasets before generalizing to the specific domain of interest. The second strategy is to create synthetic datasets specifically tailored to the target domain using methods like copy-paste techniques or ad-hoc simulators. The first strategy often faces a significant domain shift, while the second demands custom solutions crafted for the specific task. In response to these challenges, here we propose a transfer learning framework that is valid for a generic scenario. In
    
[^16]: CREMA: 通过有效的模块化适应和融合进行多模态组合视频推理

    CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion

    [https://arxiv.org/abs/2402.05889](https://arxiv.org/abs/2402.05889)

    该论文提出了一种名为CREMA的高效且模块化的模态融合框架，用于将任意新的模态注入视频推理。通过利用预训练模型增强多种信息模态，并引入查询转换器和融合模块，实现了灵活且有效的多模态组合推理。

    

    尽管在多模态组合推理方法方面取得了令人瞩目的进展，但由于处理固定模态输入并更新许多模型参数，仍然存在灵活性和效率方面的限制。本文解决了这些关键挑战，提出了CREMA，一种用于将任何新的模态注入视频推理的高效且模块化的模态融合框架。我们首先利用现有的预训练模型从给定的视频中增强多种信息模态（如光流、3D点云、音频），而无需额外的人工注释。接下来，我们引入了一个查询转换器，该转换器与每个可以访问的模态相关联，并具有多个参数高效的模块。它将多种模态特征投影到LLM令牌嵌入空间，使模型能够整合不同的数据类型以进行响应生成。此外，我们提出了一个融合模块，用于压缩多模态查询，在LLM中保持计算效率的同时进行融合组合。

    Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters. This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning. We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models. Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality. It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation. Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additio
    
[^17]: LESS：用于目标指导调整的选择有影响力的数据

    LESS: Selecting Influential Data for Targeted Instruction Tuning

    [https://arxiv.org/abs/2402.04333](https://arxiv.org/abs/2402.04333)

    LESS是一种优化感知且实际高效的算法，用于在大型语言模型中选择具有影响力的数据以开发特定能力，它采用低秩梯度相似性搜索方法进行指令数据选择。

    

    指令调整已经在大型语言模型中释放出强大的能力，有效地使用组合数据集来开发通用聊天机器人。然而，实际应用往往需要一套专门的技能（例如推理）。挑战在于从这些广泛的数据集中识别出最相关的数据，以有效开发特定的能力，我们将这种情况称为目标指导调整。我们提出了LESS，一种优化感知且实际高效的算法，以有效估计数据影响并执行适用于指令数据选择的低秩梯度相似性搜索。关键在于LESS将现有的影响公式调整为与Adam优化器和可变长度指令数据一起工作。LESS首先构建了一个具有低维梯度特征的高度可重用和可传递的梯度数据存储库，然后根据它们与具有特定能力的少样本示例的相似度选择示例。实验证明，t

    Instruction tuning has unlocked powerful capabilities in large language models (LLMs), effectively using combined datasets to develop generalpurpose chatbots. However, real-world applications often require a specialized suite of skills (e.g., reasoning). The challenge lies in identifying the most relevant data from these extensive datasets to effectively develop specific capabilities, a setting we frame as targeted instruction tuning. We propose LESS, an optimizer-aware and practically efficient algorithm to effectively estimate data influences and perform Low-rank gradiEnt Similarity Search for instruction data selection. Crucially, LESS adapts existing influence formulations to work with the Adam optimizer and variable-length instruction data. LESS first constructs a highly reusable and transferable gradient datastore with low-dimensional gradient features and then selects examples based on their similarity to few-shot examples embodying a specific capability. Experiments show that t
    
[^18]: Flora: 低秩适配器是悄悄的梯度压缩器

    Flora: Low-Rank Adapters Are Secretly Gradient Compressors

    [https://arxiv.org/abs/2402.03293](https://arxiv.org/abs/2402.03293)

    本文研究了低秩适配器的动力学，并提出了一种基于随机投影的方法Flora，通过重新采样投影矩阵实现高秩更新，同时减少优化状态的空间复杂度。

    

    尽管大型神经网络展示了完成不同任务的显着能力，但它们需要过多的内存使用来存储训练的优化状态。为了缓解这个问题，提出低秩适配（LoRA）来通过训练更少的参数来减少优化状态。然而，LoRA将整体权重更新矩阵限制为低秩，限制了模型的性能。在这项工作中，我们研究了LoRA的动力学，并确定它可以近似为随机投影。基于这一观察，我们提出了Flora，它能够通过重新采样投影矩阵实现高秩更新，同时享受优化状态的次线性空间复杂度。我们在不同任务和模型架构上进行实验证实了我们方法的有效性。

    Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training. To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters. However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance. In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection. Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states. We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach.
    
[^19]: ESPnet-SPK:具备可复现的配方，自监督的前端和现成模型的全流程说话人嵌入工具包

    ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible recipes, self-supervised front-ends, and off-the-shelf models

    [https://arxiv.org/abs/2401.17230](https://arxiv.org/abs/2401.17230)

    ESPnet-SPK是一个全流程说话人嵌入工具包，具备可复现的配方、自监督的前端和现成模型，能够轻松构建模型并与其他领域进行集成。其通过优化的架构设计和多样的自监督学习特征，实现了在多个任务中的出色性能。

    

    本文介绍了ESPnet-SPK，一个专为训练说话人嵌入提取器设计的工具包。我们提供了一个开源平台，供说话人识别社区的研究人员轻松构建模型。我们提供了多个模型，从x-vector到最近的SKA-TDNN。通过模块化的架构设计，可以轻松开发变体。我们还希望将开发的模型与其他领域进行连接，从而使广泛的研究社区能够轻松地整合最先进的嵌入提取器。预训练的嵌入提取器可以以现成的方式访问，并通过展示其与两个任务的集成来展示工具包的多功能性。另一个目标是与多样的自监督学习特征集成。我们发布了一个可复现的配方，使用WavLM-Large和ECAPA-TDNN在Vox1-O评估协议上实现了0.39%的等误差率。

    This paper introduces ESPnet-SPK, a toolkit designed with several objectives for training speaker embedding extractors. First, we provide an open-source platform for researchers in the speaker recognition community to effortlessly build models. We provide several models, ranging from x-vector to recent SKA-TDNN. Through the modularized architecture design, variants can be developed easily. We also aspire to bridge developed models with other domains, facilitating the broad research community to effortlessly incorporate state-of-the-art embedding extractors. Pre-trained embedding extractors can be accessed in an off-the-shelf manner and we demonstrate the toolkit's versatility by showcasing its integration with two tasks. Another goal is to integrate with diverse self-supervised learning features. We release a reproducible recipe that achieves an equal error rate of 0.39% on the Vox1-O evaluation protocol using WavLM-Large with ECAPA-TDNN.
    
[^20]: 跨越进化算法和强化学习：一项全面调查

    Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey

    [https://arxiv.org/abs/2401.11963](https://arxiv.org/abs/2401.11963)

    通过整合进化算法与强化学习，进化强化学习（ERL）展现出卓越的性能提升，本综述呈现了ERL领域的各个研究分支，突出了EA辅助RL的优化、RL辅助EA的优化以及EA和RL的协同优化这三个主要研究方向。

    

    进化强化学习（ERL）将进化算法（EAs）和强化学习（RL）相结合进行优化，表现出卓越的性能提升。通过融合两种方法的优势，ERL已经成为一个有前景的研究方向。本调查综述了ERL中不同研究分支的全面概述。具体而言，我们系统总结了相关算法的最新进展，并确定了三个主要研究方向：EA辅助RL的优化，RL辅助EA的优化，以及EA和RL的协同优化。随后，我们深入分析了每个研究方向，组织了多个研究分支。我们阐明了每个分支致力于解决的问题，以及EA和RL的整合如何应对这些挑战。最后，我们讨论了潜在的挑战和未来的研究方向。

    arXiv:2401.11963v2 Announce Type: replace-cross  Abstract: Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary Algorithms (EAs) and Reinforcement Learning (RL) for optimization, has demonstrated remarkable performance advancements. By fusing the strengths of both approaches, ERL has emerged as a promising research direction. This survey offers a comprehensive overview of the diverse research branches in ERL. Specifically, we systematically summarize recent advancements in relevant algorithms and identify three primary research directions: EA-assisted optimization of RL, RL-assisted optimization of EA, and synergistic optimization of EA and RL. Following that, we conduct an in-depth analysis of each research direction, organizing multiple research branches. We elucidate the problems that each branch aims to tackle and how the integration of EA and RL addresses these challenges. In conclusion, we discuss potential challenges and prospective future research directions
    
[^21]: 从现成的视觉语言模型中实现的紧急开放词汇语义分割

    Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models

    [https://arxiv.org/abs/2311.17095](https://arxiv.org/abs/2311.17095)

    提出了一种简单但高效的无需训练的技术，用于开放词汇语义分割，通过使用VLM和显著性丢弃来解决过度分割和欠分割的问题

    

    从图像-文本对中，大规模视觉语言模型（VLMs）学习隐式将图像区域与词汇关联起来，这对于诸如视觉问答等任务非常有效。然而，利用学习到的关联进行开放词汇语义分割仍然具有挑战性。在本文中，我们提出了一种简单但极其有效的无需训练的技术，Plug-and-Play Open-Vocabulary Semantic Segmentation (PnP-OVSS)。PnP-OVSS利用具有直接文本到图像交叉注意力和图像-文本匹配损失的VLM。为了在过度分割和欠分割之间取得平衡，我们引入了显著性丢弃（Salience Dropout）；通过迭代丢弃模型最关注的补丁，我们能够更好地解决整个分割掩模的范围。

    arXiv:2311.17095v2 Announce Type: replace-cross  Abstract: From image-text pairs, large-scale vision-language models (VLMs) learn to implicitly associate image regions with words, which prove effective for tasks like visual question answering. However, leveraging the learned association for open-vocabulary semantic segmentation remains a challenge. In this paper, we propose a simple, yet extremely effective, training-free technique, Plug-and-Play Open-Vocabulary Semantic Segmentation (PnP-OVSS) for this task. PnP-OVSS leverages a VLM with direct text-to-image cross-attention and an image-text matching loss. To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the model is most attentive to, we are able to better resolve the entire extent of the segmentation mask. \shortname{} does not require any neural network training and performs hyperparameter tuning without the need for any segmentation annotations, even f
    
[^22]: 少样本迁移学习用于知识库问答：融合监督模型和上下文学习

    Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning

    [https://arxiv.org/abs/2311.08894](https://arxiv.org/abs/2311.08894)

    提出了一种新的KBQA架构FuSIC-KBQA，通过多个源训练的召回器执行KB检索，在LLM的重新排序后以此作为LLM少样本上下文学习的输入来生成逻辑形式，并利用执行引导反馈进一步优化。

    

    现有的知识库问答（KBQA）架构需要大量注释数据，这使得它们在部署时成本高且耗时。我们提出少样本迁移学习用于KBQA的问题，目标域仅提供少量标记示例，但在源域中有大量标记训练数据集可用。我们提出了一种名为FuSIC-KBQA的新型KBQA架构，它使用多个经过源培训的召回器执行KB检索，使用LLM重新排序，将此作为LLM少样本上下文学习的输入以生成逻辑形式，进一步使用执行引导反馈进行细化。在四对不同复杂度的源-目标KBQA对上的实验表明，FuSIC-KBQA明显优于为此设置调整的SoTA KBQA模型。在领域内设置的额外实验表明，当训练数据有限时，FuSIC-KBQA也优于SoTA KBQA模型。

    arXiv:2311.08894v2 Announce Type: replace-cross  Abstract: Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which make them costly and time-consuming to deploy. We introduce the problem of few-shot transfer learning for KBQA, where the target domain offers only a few labeled examples, but a large labeled training dataset is available in a source domain. We propose a novel KBQA architecture called FuSIC-KBQA that performs KB-retrieval using multiple source-trained retrievers, re-ranks using an LLM and uses this as input for LLM few-shot in-context learning to generate logical forms, which are further refined using execution-guided feedback. Experiments over four source-target KBQA pairs of varying complexity show that FuSIC-KBQA significantly outperforms adaptations of SoTA KBQA models for this setting. Additional experiments in the in-domain setting show that FuSIC-KBQA also outperforms SoTA KBQA models when training data is limited.
    
[^23]: 探索疾病中的语义信息：用于中文疾病规范化的简单数据增强技术

    Exploring semantic information in disease: Simple Data Augmentation Techniques for Chinese Disease Normalization

    [https://arxiv.org/abs/2306.01931](https://arxiv.org/abs/2306.01931)

    提出了一组定制的数据增强技术，旨在利用疾病名称中的语义信息，增强模型对疾病名称的语义细微差别和分类结构的理解

    

    疾病名称规范化是医学领域中的重要任务。它将以各种格式编写的疾病名称分类为标准化名称，作为智能医疗系统中各种与疾病相关功能的基本组件。然而，现有疾病名称规范化系统面临的最大障碍是训练数据严重不足。虽然数据增强是解决数据稀缺性的有效方法，但我们的研究发现，传统的数据增强技术通常会阻碍任务性能，主要是由于疾病名称的多轴和多粒度性质。因此，我们介绍了一组定制的数据增强技术，旨在利用疾病名称中固有的语义信息。这些技术旨在增强模型对疾病名称的语义复杂性和分类结构的理解。

    arXiv:2306.01931v2 Announce Type: replace  Abstract: Disease name normalization is an important task in the medical domain. It classifies disease names written in various formats into standardized names, serving as a fundamental component in smart healthcare systems for various disease-related functions. Nevertheless, the most significant obstacle to existing disease name normalization systems is the severe shortage of training data. While data augmentation is a powerful approach for addressing data scarcity, our findings reveal that conventional data augmentation techniques often impede task performance, primarily due to the multi-axis and multi-granularity nature of disease names. Consequently, we introduce a set of customized data augmentation techniques designed to leverage the semantic information inherent in disease names. These techniques aim to enhance the model's understanding of the semantic intricacies and classification structure of disease names. Through extensive experime
    
[^24]: 整页无偏学习排序

    Whole Page Unbiased Learning to Rank

    [https://arxiv.org/abs/2210.10718](https://arxiv.org/abs/2210.10718)

    本论文提出整页无偏学习排序（WP-ULTR）方法处理整页 SERP 特征引发的偏差，该方法面临适合的用户行为模型的挑战和复杂的模型训练难题。

    

    信息检索系统中页面呈现的偏见，尤其是点击行为方面的偏差，是一个众所周知的挑战，阻碍了使用隐式用户反馈来改进排序模型的性能。因此，提出了无偏学习排序(ULTR)算法，通过偏差点击数据来学习一个无偏的排序模型。然而，大多数现有算法特别设计用于减轻与位置相关的偏差，例如信任偏差，并未考虑到搜索结果页面呈现(SERP)中其他特征引发的偏差，例如由多媒体引发的吸引偏差。不幸的是，这些偏差在工业系统中广泛存在，可能导致不令人满意的搜索体验。因此，我们引入了一个新的问题，即整页无偏学习排序(WP-ULTR)，旨在同时处理整页SERP特征引发的偏差。这带来了巨大的挑战：(1) 很难找到适合的用户行为模型 (用户行为假设)；(2) 复杂的模型训练问题。

    The page presentation biases in the information retrieval system, especially on the click behavior, is a well-known challenge that hinders improving ranking models' performance with implicit user feedback. Unbiased Learning to Rank~(ULTR) algorithms are then proposed to learn an unbiased ranking model with biased click data. However, most existing algorithms are specifically designed to mitigate position-related bias, e.g., trust bias, without considering biases induced by other features in search result page presentation(SERP), e.g. attractive bias induced by the multimedia. Unfortunately, those biases widely exist in industrial systems and may lead to an unsatisfactory search experience. Therefore, we introduce a new problem, i.e., whole-page Unbiased Learning to Rank(WP-ULTR), aiming to handle biases induced by whole-page SERP features simultaneously. It presents tremendous challenges: (1) a suitable user behavior model (user behavior hypothesis) can be hard to find; and (2) complex
    
[^25]: 反学习揭示了语言模型的影响训练数据

    Unlearning Reveals the Influential Training Data of Language Models. (arXiv:2401.15241v1 [cs.CL])

    [http://arxiv.org/abs/2401.15241](http://arxiv.org/abs/2401.15241)

    本文提出了一种简单而有效的方法UnTrac，通过反学习训练数据集来估计语言模型的影响。实验结果表明，UnTrac能够准确评估预训练数据集对生成有害内容的影响，并且无需额外的资源。

    

    为了提高语言模型的性能，同时减少生成有害内容的风险，识别哪些训练数据集影响模型的输出至关重要。理想情况下，我们可以通过从训练中移除每个数据集来衡量其影响;然而，多次重新训练模型是非常昂贵的。本文提出了UnTrac，通过从训练模型中取消学习来估计训练数据集的影响。UnTrac非常简单; 通过梯度上升来取消学习每个训练数据集，并评估在取消学习后模型的预测发生了多大变化。我们经验性地研究了我们的方法是否能评估预训练数据集对生成有毒、有偏见和不真实内容的影响。实验结果表明，我们的方法比现有方法更准确地估计了它们的影响，同时不需要过多的内存空间或多个模型检查点。

    In order to enhance the performance of language models while mitigating the risks of generating harmful content, it is crucial to identify which training dataset affects the model's outputs. Ideally, we can measure the influence of each dataset by removing it from training; however, it is prohibitively expensive to retrain a model multiple times. This paper presents UnTrac, which estimates the influence of a training dataset by unlearning it from the trained model. UnTrac is extremely simple; each training dataset is unlearned by gradient ascent, and we evaluate how much the model's predictions change after unlearning. We empirically examine if our methods can assess the influence of pretraining datasets on generating toxic, biased, and untruthful content. Experimental results demonstrate that our method estimates their influence much more accurately than existing methods while requiring neither excessive memory space nor multiple model checkpoints.
    
[^26]: 从AI教练学习赛车：多模态自动驾驶解释对驾驶表现、认知负荷、专业知识和信任的影响

    Learning Racing From an AI Coach: Effects of Multimodal Autonomous Driving Explanations on Driving Performance, Cognitive Load, Expertise, and Trust. (arXiv:2401.04206v1 [cs.HC])

    [http://arxiv.org/abs/2401.04206](http://arxiv.org/abs/2401.04206)

    本研究测试了一种AI驾驶教练的解释对驾驶表现、认知负荷、专业知识和信任的影响。结果显示，AI驾驶教练对于教授新手驾驶技能是有帮助的，并且信息类型和呈现方式对表现结果有影响。

    

    在一项前后实验中（n=41），我们测试了模仿人类驾驶专家的指导说明的AI教练的解释沟通对驾驶表现、认知负荷、信心、专业知识和信任的影响。参与者被分为四个组，评估了AI教练解释的两个维度：信息类型（'what'和'why'-type解释）和呈现方式（听觉和视觉）。通过采访，我们描述了参与者的学习过程。结果表明，AI驾驶教练对于教授新手驾驶技能是有用的。比较各组之间，我们发现信息的类型和方式对性能结果有影响。我们将差异归因于信息如何引导注意力，减轻不确定性，并影响参与者经历的负荷过载。这反过来又影响了信心和信任水平。

    In a pre-post experiment (n = 41), we test the impact of an AI Coach's explanatory communications modeled after the instructions of human driving experts. Participants were divided into four (4) groups to assess two (2) dimensions of the AI coach's explanations: information type ('what' and 'why'-type explanations) and presentation modality (auditory and visual). We directly compare how AI Coaching sessions employing these techniques impact driving performance, cognitive load, confidence, expertise, and trust in an observation learning context. Through interviews, we delineate the learning process of our participants. Results show that an AI driving coach can be useful for teaching performance driving skills to novices. Comparing between groups, we find the type and modality of information influences performance outcomes. We attribute differences to how information directed attention, mitigated uncertainty, and influenced overload experienced by participants. These, in turn, affected h
    
[^27]: 人作为AI导师：增强人机协作强化学习以实现安全高效的自动驾驶

    Human as AI Mentor: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving. (arXiv:2401.03160v1 [cs.LG])

    [http://arxiv.org/abs/2401.03160](http://arxiv.org/abs/2401.03160)

    本文提出了一种增强的人机协作强化学习方法，通过将人类智能注入到AI中实现混合交通编队中的安全高效自动驾驶。该方法将人类专家作为导师，允许代理在不确定环境中进行探索，同时在危险情况下接管控制以避免事故，并指导代理减小交通流干扰，优化交通流效果。

    

    尽管自动驾驶车辆（AVs）取得了重大进展，但确保AVs的安全性和交通流效率的驾驶策略的发展尚未得到充分探索。在本文中，我们提出了一种增强的人机协作强化学习方法，称为基于人作为AI导师的深度强化学习（HAIM-DRL）框架，以在混合交通编队中实现安全高效的自动驾驶。从人类学习过程中汲取灵感，我们首先引入了一种创新的学习范式，有效地将人类智能注入到AI中，称为人作为AI导师（HAIM）。在这个范式中，人类专家作为导师为AI代理提供帮助。在允许代理在不确定环境中进行充分探索的同时，人类专家可以在危险情况下接管控制，并展示正确的行动以避免潜在事故。另一方面，可以指导代理减小交通流干扰，从而优化交通流效果。

    Despite significant progress in autonomous vehicles (AVs), the development of driving policies that ensure both the safety of AVs and traffic flow efficiency has not yet been fully explored. In this paper, we propose an enhanced human-in-the-loop reinforcement learning method, termed the Human as AI mentor-based deep reinforcement learning (HAIM-DRL) framework, which facilitates safe and efficient autonomous driving in mixed traffic platoon. Drawing inspiration from the human learning process, we first introduce an innovative learning paradigm that effectively injects human intelligence into AI, termed Human as AI mentor (HAIM). In this paradigm, the human expert serves as a mentor to the AI agent. While allowing the agent to sufficiently explore uncertain environments, the human expert can take control in dangerous situations and demonstrate correct actions to avoid potential accidents. On the other hand, the agent could be guided to minimize traffic flow disturbance, thereby optimizi
    
[^28]: INTERVENOR: 使用交互式修复链条来引导大型语言模型的编码能力

    INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing. (arXiv:2311.09868v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2311.09868](http://arxiv.org/abs/2311.09868)

    INTERVENOR模型通过模拟人类修复代码的行为，使用交互式修复链条来引导大型语言模型的编码能力，取得了显著的性能提升。

    

    本文提出了一种名为INTERVENOR的交互式修复链条（INTERactiVE chaiN Of Repairing），模拟了人类修复代码的行为（迭代判断、重新思考和修复），并促进了大型语言模型（LLMs）的编码能力。具体而言，INTERVENOR采用了两个基于LLM的代理，即Code Learner和Code Teacher，它们在代码修复中扮演不同的角色，并通过互动来修复生成的代码。Code Learner根据Code Teacher的指导生成和修复代码，而Code Teacher根据编译器的反馈重新思考代码错误，并迭代生成修复链条（CoR）以引导Code Learner的代码修复过程。实验证明，INTERVENOR优于最先进的方法，在代码生成和代码转换任务上相对于GPT-3.5模型分别取得了约13%和4.5%的提升。进一步分析表明，CoR能够揭示bug的原因。

    This paper proposes INTERactiVE chaiN Of Repairing (INTERVENOR), which mimics human code repairing behavior (iteratively judging, rethinking, and repairing) and prompts the coding ability of regard Large Language Models (LLMs). Specifically, INTERVENOR employs two LLM based agents, Code Learner and Code Teacher, to play different roles in code repairing and work interactively to repair the generated codes. The Code Learner is asked to generate and repair code according to the instructions from the Code Teacher. The Code Teacher rethinks the code errors according to the corresponding feedback from compilers and iteratively generates the chain-of-repairing (CoR) to guide the code repairing process for Code Learner. Our experiments show that INTERVENOR outperforms the state-of-the-art methods and achieves about 13% and 4.5% improvements over the GPT-3.5 model in code generation and code translation tasks, respectively. Our further analyses show that CoR can illuminate the bug reasons and 
    
[^29]: 认证任何区域

    Recognize Any Regions. (arXiv:2311.01373v1 [cs.CV])

    [http://arxiv.org/abs/2311.01373](http://arxiv.org/abs/2311.01373)

    本文提出了一种名为RegionSpot的新型、通用且高效的区域识别架构，旨在解决在计算机视觉中理解无约束图像中区域的语义的挑战。

    

    理解无约束图像中各个区域或块的语义，例如在开放世界物体检测中，代表了一项关键而具有挑战性的计算机视觉任务。在基于强大的图像级视觉语言（ViL）基础模型如CLIP的成功基础上，最近的努力要么通过使用广泛的区域-标签对集合从头开始训练对比模型，要么将检测模型的输出与区域建议的图像级表示对齐，以发挥它们的能力。尽管取得了显著进展，但这些方法都受到计算密集型的训练需求、数据噪声的影响以及环境信息的不足等限制。为了解决这些问题，我们探索了现成的基础模型的协同潜力，利用它们在定位和语义方面的各自优势。我们引入了一种新颖的、通用的、高效的区域识别架构，称为RegionSpot。

    Understanding the semantics of individual regions or patches within unconstrained images, such as in open-world object detection, represents a critical yet challenging task in computer vision. Building on the success of powerful image-level vision-language (ViL) foundation models like CLIP, recent efforts have sought to harness their capabilities by either training a contrastive model from scratch with an extensive collection of region-label pairs or aligning the outputs of a detection model with image-level representations of region proposals. Despite notable progress, these approaches are plagued by computationally intensive training requirements, susceptibility to data noise, and deficiency in contextual information. To address these limitations, we explore the synergistic potential of off-the-shelf foundation models, leveraging their respective strengths in localization and semantics. We introduce a novel, generic, and efficient region recognition architecture, named RegionSpot, de
    
[^30]: DEFT：通过无监督核心集选择实现大规模语言模型数据高效微调

    DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection. (arXiv:2310.16776v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.16776](http://arxiv.org/abs/2310.16776)

    这项研究介绍了一种名为DEFT的数据高效微调框架，通过无监督核心集选择来最小化微调大规模语言模型所需的数据量。研究结果表明，DEFT模型在准确性上与现有模型相当，并且仅使用了70%的数据量。

    

    最近的进展使得许多预训练语言模型（PLMs）可以使用；然而，一个仍然存在的问题是微调PLMs以用于下游任务究竟需要多少数据？在这项工作中，我们介绍了DEFT，一种数据高效的微调框架，它利用无监督的核心集选择来最小化微调PLMs所需的数据量。我们在文本编辑LM的背景下展示了DEFT框架的有效性，并与最先进的文本编辑模型CoEDIT进行了比较。我们的定量和定性结果表明，DEFT模型在准确性上与CoEDIT一样，而使用的数据量要少约70%。

    Recent advances have led to the availability of many pre-trained language models (PLMs); however, a question that remains is how much data is truly needed to fine-tune PLMs for downstream tasks? In this work, we introduce DEFT, a data-efficient fine-tuning framework that leverages unsupervised core-set selection to minimize the amount of data needed to fine-tune PLMs for downstream tasks. We demonstrate the efficacy of our DEFT framework in the context of text-editing LMs, and compare to the state-of-the art text-editing model, CoEDIT. Our quantitative and qualitative results demonstrate that DEFT models are just as accurate as CoEDIT while being finetuned on ~70% less data.
    
[^31]: 简明有序的感知有助于大型语言模型进行演绎推理

    Concise and Organized Perception Facilitates Large Language Models for Deductive Reasoning. (arXiv:2310.03309v1 [cs.CL])

    [http://arxiv.org/abs/2310.03309](http://arxiv.org/abs/2310.03309)

    利用大型语言模型进行演绎推理是一个具有挑战性的问题。这篇论文提出了一个简明有序的方法，将任务分解为子任务并且人类化地组织思维，以提高演绎推理的效果。

    

    利用大型语言模型（LLMs）解决演绎推理问题已经引起了越来越多的关注。在复杂的演绎问题中仍然很难取得令人满意的结果，这类问题具有大量前提（即事实或规则），其中涉及实体之间错综复杂的关系，需要进行多跳推理。一种直观的解决方案是将原始任务分解为较小的子任务，然后以前向（例如选择-推理）或反向（例如LAMBADA）方式将多个因果推理步骤连接在一起。然而，这些技术不可避免地需要大量的总体阶段，导致计算开销大，并且有更高的可能性产生误导性的步骤。除了逐阶段分解之外，我们还从人类问题解决的另一个方面获得了启发。人类倾向于提炼出最相关的信息并有序地组织思维（例如创建思维导图），这有助于他们对问题进行有效的推理。

    Exploiting large language models (LLMs) to tackle deductive reasoning has garnered growing attention. It still remains highly challenging to achieve satisfactory results in complex deductive problems, characterized by plenty of premises (i.e., facts or rules) entailing intricate relationships among entities and requiring multi-hop reasoning. One intuitive solution is to decompose the original task into smaller sub-tasks, and then chain the multiple casual reasoning steps together in a forward (e.g., Selection-Inference) or backward (e.g., LAMBADA) direction. However, these techniques inevitably necessitate a large number of overall stages, leading to computationally expensive operations and a higher possibility of making misleading steps. In addition to stage-by-stage decomposition, we draw inspiration from another aspect of human problem-solving. Humans tend to distill the most relevant information and organize their thoughts systematically (e.g., creating mind maps), which assists th
    
[^32]: Nugget 2D：用于仅解码器语言模型的动态上下文压缩的扩展

    Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models. (arXiv:2310.02409v1 [cs.CL])

    [http://arxiv.org/abs/2310.02409](http://arxiv.org/abs/2310.02409)

    Nugget 2D是一种用于仅解码器语言模型的动态上下文压缩方法，可以在保留任务能力的同时大幅减少解码过程所需的时间和空间开销。

    

    标准的基于Transformer的语言模型在长上下文中缩放效果不佳。我们提出了一种基于动态上下文压缩的解决方案，该方案将Qin＆Van Durme（2023年）的Nugget方法从BERT类框架扩展到仅解码器的语言模型。我们的方法将历史建模为压缩的“nuggets”，这些“nuggets”经过训练可以进行重建，它可以使用诸如LLaMA之类的现成模型进行初始化。我们通过语言建模、问答和摘要的实验证明，Nugget2D在这些任务中保留了能力，同时在解码过程中大幅减少了时间和空间开销。例如，在自动编码实验中，Nugget2D可以以20倍的压缩比收缩上下文，重建时的BLEU得分为98％，实现了近乎无损编码。

    Standard Transformer-based language models (LMs) scale poorly to long contexts. We propose a solution based on dynamic contextual compression, which extends the Nugget approach of Qin & Van Durme (2023) from BERT-like frameworks to decoder-only LMs. Our method models history as compressed "nuggets" which are trained to allow for reconstruction, and it can be initialized with off-the-shelf models such as LLaMA. We demonstrate through experiments in language modeling, question answering, and summarization that Nugget2D retains capabilities in these tasks, while drastically reducing the overhead during decoding in terms of time and space. For example, in the experiments of autoencoding, Nugget2D can shrink context at a 20x compression ratio with a BLEU score of 98% for reconstruction, achieving nearly lossless encoding.
    
[^33]: 讲给我听！基于大型语言模型的叙事驱动可解释人工智能

    Tell Me a Story! Narrative-Driven XAI with Large Language Models. (arXiv:2309.17057v1 [cs.AI])

    [http://arxiv.org/abs/2309.17057](http://arxiv.org/abs/2309.17057)

    这项研究提出了基于大型语言模型的XAIstories框架，通过叙事方式解释AI预测，其中SHAPstories基于SHAP解释解释预测得分，CFstories基于CF解释解释决策。研究结果表明，超过90%的普通读者认可SHAPstories生成的叙事的说服力，92%的数据科学家认为SHAPstories能够提高非专业人士的易用性和信心。

    

    在当今重要领域中，黑盒机器学习模型的盛行加大了对可解释人工智能（XAI）的需求。广泛使用的SHAP值虽然量化了特征重要性，但往往过于复杂，缺乏人性化的解释。此外，反事实（CF）解释展示了“如果”但没有解释“为什么”。为了弥合这一差距，我们引入了XAIstories。利用大型语言模型，XAIstories提供了叙事来阐明AI预测：基于SHAP解释的SHAPstories解释预测得分，而基于CF解释的CFstories解释决策。我们的结果令人震惊：超过90%的调查普通读者认为SHAPstories生成的叙事是有说服力的。数据科学家主要认为SHAPstories在向普通读者传达解释方面具有价值，92%的数据科学家表示这将有助于非专业人士的易用性和信心。

    In today's critical domains, the predominance of black-box machine learning models amplifies the demand for Explainable AI (XAI). The widely used SHAP values, while quantifying feature importance, are often too intricate and lack human-friendly explanations. Furthermore, counterfactual (CF) explanations present `what ifs' but leave users grappling with the 'why'. To bridge this gap, we introduce XAIstories. Leveraging Large Language Models, XAIstories provide narratives that shed light on AI predictions: SHAPstories do so based on SHAP explanations to explain a prediction score, while CFstories do so for CF explanations to explain a decision. Our results are striking: over 90% of the surveyed general audience finds the narrative generated by SHAPstories convincing. Data scientists primarily see the value of SHAPstories in communicating explanations to a general audience, with 92% of data scientists indicating that it will contribute to the ease and confidence of nonspecialists in under
    
[^34]: 基于合成临床记录的公开可共享的临床大语言模型

    Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes. (arXiv:2309.00237v1 [cs.CL])

    [http://arxiv.org/abs/2309.00237](http://arxiv.org/abs/2309.00237)

    使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。

    

    基于合成的临床案例报告，我们首先创建了大规模的合成临床记录，以解决临床记录的有限可及性和可用性的问题。然后，我们使用这些合成记录来训练我们的专门的临床大语言模型Asclepius。虽然Asclepius是在合成数据上训练的，但我们通过使用真实临床记录对其进行评估，以评估其在现实应用中的潜在性能。我们将Asclepius与包括GPT-3.5-turbo和其他开源替代方案在内的几种其他大语言模型进行了基准测试。为了进一步验证我们使用合成记录的方法，我们还将Asclepius与其在真实临床记录上训练的变体进行了比较。我们的发现有力地证明，合成临床记录在构建临床大语言模型时可以作为可行的替代品。

    The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructi
    
[^35]: 通过交互式问题-知识对齐解决语言模型幻觉问题

    Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment. (arXiv:2305.13669v1 [cs.CL])

    [http://arxiv.org/abs/2305.13669](http://arxiv.org/abs/2305.13669)

    本文提出了MixAlign框架，通过与用户和知识库交互，实现自动的问题-知识对齐，从而解决了语言模型因无法正确理解问题和知识而导致的幻觉问题。

    

    尽管语言模型近期进展显著，但仍面临幻觉问题，可能会生成误导性和不支持的回答。一种缓解幻觉问题的常见方法是从知识库中检索和整合支持证据。然而，用户的问题通常与存储的知识不太对齐，因为他们在提问前不知道可用的信息。这种不对齐可能限制语言模型定位和利用知识的能力，可能迫使其通过忽略或覆盖检索到的证据而产生幻觉。为了解决这个问题，我们介绍了 MixAlign，一个框架，它与用户和知识库交互以获得并整合关于用户问题与存储信息相关性的澄清信息。 MixAlign 采用语言模型实现自动问题-知识对齐，并在需要时通过人工用户澄清进一步增强这种对齐。

    Despite the remarkable recent advances in language models, they still struggle with the hallucination problem and can generate misleading and unsupported responses. A common approach to mitigate the hallucination issue is retrieving and incorporating supporting evidence from a knowledge base. However, user questions usually do not align well with the stored knowledge, as they are unaware of the information available before asking questions. This misalignment can limit the language model's ability to locate and utilize the knowledge, potentially forcing it to hallucinate by ignoring or overriding the retrieved evidence. To address this issue, we introduce MixAlign, a framework that interacts with both the user and the knowledge base to obtain and integrate clarifications on how the user question relates to the stored information. MixAlign employs a language model to achieve automatic question-knowledge alignment and, if necessary, further enhances this alignment through human user clari
    
[^36]: 人工智能与双重合同

    Artificial Intelligence and Dual Contract. (arXiv:2303.12350v1 [cs.AI])

    [http://arxiv.org/abs/2303.12350](http://arxiv.org/abs/2303.12350)

    本文通过实验研究了人工智能算法在双重合同问题中能够自主设计激励相容的合同，无需外部引导或通信，并且不同AI算法支持的委托人可以采用混合和零和博弈行为，更具智能的委托人往往会变得合作。

    

    随着人工智能算法的快速进步，人们希望算法很快就能在各个领域取代人类决策者，例如合同设计。我们通过实验研究了由人工智能（多智能体Q学习）驱动的算法在双重委托-代理问题的经典“双重合同”模型中的行为。我们发现，这些AI算法可以自主学习设计合适的激励相容合同，而无需外部引导或者它们之间的通信。我们强调，由不同AI算法支持的委托人可以采用混合和零和博弈行为。我们还发现，更具智能的委托人往往会变得合作，而智能较低的委托人则会出现内生性近视并倾向于竞争。在最优合同下，代理的较低合同激励由委托人之间的勾结策略维持。

    With the dramatic progress of artificial intelligence algorithms in recent times, it is hoped that algorithms will soon supplant human decision-makers in various fields, such as contract design. We analyze the possible consequences by experimentally studying the behavior of algorithms powered by Artificial Intelligence (Multi-agent Q-learning) in a workhorse \emph{dual contract} model for dual-principal-agent problems. We find that the AI algorithms autonomously learn to design incentive-compatible contracts without external guidance or communication among themselves. We emphasize that the principal, powered by distinct AI algorithms, can play mixed-sum behavior such as collusion and competition. We find that the more intelligent principals tend to become cooperative, and the less intelligent principals are endogenizing myopia and tend to become competitive. Under the optimal contract, the lower contract incentive to the agent is sustained by collusive strategies between the principals
    
[^37]: 强大的层级增强学习中的知识传输

    Robust Knowledge Transfer in Tiered Reinforcement Learning. (arXiv:2302.05534v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05534](http://arxiv.org/abs/2302.05534)

    本文研究了层级增强学习中的知识传输，提出了一种新颖的在线学习算法，在没有先验知识的任务相似性的情况下实现强大的知识传输。

    

    本文研究了层级增强学习设置，这是一个并行传输学习框架，在这个框架中，目标是将知识从低层（源）任务传输到高层（目标）任务，以减少后者的探索风险，同时并行解决这两个任务。与先前的工作不同，我们不假设低层和高层任务共享相同的动态或奖励函数，并且专注于在没有先验知识的任务相似性的情况下实现强大的知识传输。我们确定了一个称为“最优值支配”的自然而必要的条件，适用于我们的目标。在这个条件下，我们提出了一种新颖的在线学习算法，使得对于高层任务，在部分状态上可以实现恒定的遗憾，这取决于任务相似性，并在两个任务不相似时保持接近最优遗憾；而对于低层任务，它可以在不做出牺牲的情况下保持接近最优。此外，我们进一步研究了具有多个低层任务的情况。

    In this paper, we study the Tiered Reinforcement Learning setting, a parallel transfer learning framework, where the goal is to transfer knowledge from the low-tier (source) task to the high-tier (target) task to reduce the exploration risk of the latter while solving the two tasks in parallel. Unlike previous work, we do not assume the low-tier and high-tier tasks share the same dynamics or reward functions, and focus on robust knowledge transfer without prior knowledge on the task similarity. We identify a natural and necessary condition called the ``Optimal Value Dominance'' for our objective. Under this condition, we propose novel online learning algorithms such that, for the high-tier task, it can achieve constant regret on partial states depending on the task similarity and retain near-optimal regret when the two tasks are dissimilar, while for the low-tier task, it can keep near-optimal without making sacrifice. Moreover, we further study the setting with multiple low-tier tasks
    

