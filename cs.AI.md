# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and AI Storytelling.](http://arxiv.org/abs/2310.12902) | 本研究提出了一种框架，通过比较人类众包叙事和AI叙事，探究了文化产物和社会偏见在故事中的表现。实验结果显示，GPT-3.5和GPT-4生成的叙事更具进展性，并且普罗米修斯神话在人类和大型语言模型的想象中起到了重要作用。 |
| [^2] | [Personalized human mobility prediction for HuMob challenge.](http://arxiv.org/abs/2310.12900) | 该论文介绍了一种个性化的人类移动预测方法，基于个体数据而不是整体数据进行预测，并成功运用于HuMob Challenge竞赛中。采用了特征设计和机器学习模型SVR，通过离线评估和特征选择和参数调整，使预测准确性得到验证。 |
| [^3] | [TwinPot: Digital Twin-assisted Honeypot for Cyber-Secure Smart Seaports.](http://arxiv.org/abs/2310.12880) | 该论文介绍了一种数字孪生辅助的蜜罐，用于保护智能海港的网络安全。传统安全解决方案对于保护物联网和物理网络系统是有限的，而蜜罐则可以提供有关攻击者行为的宝贵信息。数字孪生技术可以增强虚拟蜜罐的逼真性，吸引更多的攻击者。 |
| [^4] | [Predicting Ovarian Cancer Treatment Response in Histopathology using Hierarchical Vision Transformers and Multiple Instance Learning.](http://arxiv.org/abs/2310.12866) | 该研究使用Hierarchical Vision Transformers和多实例学习来预测卵巢癌的治疗反应，为卵巢癌患者选择治疗方案提供了有效的自动预测方法。 |
| [^5] | [Physical Information Neural Networks for Solving High-index Differential-algebraic Equation Systems Based on Radau Methods.](http://arxiv.org/abs/2310.12846) | 本文提出了一个将Radau数值方法和神经网络结构相结合的物理信息神经网络框架，能够直接求解高阶微分代数方程系统，并采用领域分解策略提高求解能力。 |
| [^6] | [AgentTuning: Enabling Generalized Agent Abilities for LLMs.](http://arxiv.org/abs/2310.12823) | 本论文提出了AgentTuning，一种简单而通用的方法，可提升LLMs的代理能力，同时保持其通用能力。通过构建AgentInstruct数据集，并采用一种混合训练方法，作者成功地实现了提高LLMs代理能力的目标。 |
| [^7] | [Hybrid Search for Efficient Planning with Completeness Guarantees.](http://arxiv.org/abs/2310.12819) | 本论文提出了一种混合搜索方法，用于在离散动作空间中进行高效规划，并保证了完整性。通过在高级搜索中添加低级动作，该方法既具有高级搜索的实际效率，又具有低级搜索的完整性。 |
| [^8] | [Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models.](http://arxiv.org/abs/2310.12818) | 本论文提出了一种提升参数共享预训练语言模型推理效率的简单技术，并介绍了一种简单的预训练方法来实现完全或部分共享的模型，实验结果证明了这些方法在各种模型上的有效性，为更有效地利用参数提供了新的见解。 |
| [^9] | [2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision.](http://arxiv.org/abs/2310.12817) | 本文提出了一种基于场景级监督的2D-3D交错Transformer模型，用于弱监督点云分割。该模型通过两个编码器计算2D和3D数据的自注意特征，并通过交替切换查询和键值对的角色，实现了2D和3D特征的融合。 |
| [^10] | [Prompt Injection Attacks and Defenses in LLM-Integrated Applications.](http://arxiv.org/abs/2310.12815) | 本文提出了一个通用框架来形式化提示注入攻击，并系统化防御这种类型的攻击。 |
| [^11] | [Model Merging by Uncertainty-Based Gradient Matching.](http://arxiv.org/abs/2310.12808) | 本论文通过不确定性梯度匹配的方法，提出了一种新的模型合并方案，该方案能够减少梯度不匹配，从而提高了模型合并的性能并对超参数更具鲁棒性。 |
| [^12] | [An effective theory of collective deep learning.](http://arxiv.org/abs/2310.12802) | 通过竞争局部学习和单元之间的扩散耦合，我们引入了一个简化模型，预测了集体学习中的无序-有序-无序相变，并验证了这个理论。 |
| [^13] | [Exploring Graph Neural Networks for Indian Legal Judgment Prediction.](http://arxiv.org/abs/2310.12800) | 本研究探索了使用图神经网络来解决印度法律判决预测问题，通过识别司法案件的图结构并进行节点分类，以实现自动化推测案件结果。研究考虑了模型特征、公平性和链接预测任务。 |
| [^14] | [Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning.](http://arxiv.org/abs/2310.12774) | 本文提出了一种名为ClaPS的简单黑盒搜索方法，通过聚类和修剪搜索空间中最有影响力的提示令牌，解决了现代黑盒方法中的效率问题。 |
| [^15] | [Safe RLHF: Safe Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2310.12773) | 我们提出了一种名为安全RLHF的算法，用于在大型语言模型的训练过程中平衡性能和安全性。它通过解耦人类偏好，并训练分别的奖励和成本模型，成功解决了有益和无害目标之间的固有张力，并通过动态调整平衡来优化算法性能。 |
| [^16] | [SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications.](http://arxiv.org/abs/2310.12768) | 本文提出了一种新颖的技术，语义干扰消除（SemantIC），用于提高6G无线通信网络的信息质量。通过在接收器上使用语义自动编码器，SemantIC能够迭代消除信号中的噪声和语义干扰。仿真结果表明，SemantIC能够在不增加额外信道资源成本的情况下改进性能。 |
| [^17] | [Neurosymbolic Grounding for Compositional World Models.](http://arxiv.org/abs/2310.12690) | 本论文介绍了一种名为Cosmos的框架，用于对象为中心的世界建模，通过使用神经符号化基础和视觉-语言基础模型，实现了在未见过的输入场景上的高性能组合泛化能力。 |
| [^18] | [Compression of Recurrent Neural Networks using Matrix Factorization.](http://arxiv.org/abs/2310.12688) | 本论文提出了一种称为Rank-Tuning的训练后秩选择方法，可以在循环神经网络中高效压缩模型，并在几乎没有性能降低的情况下实现高压缩率。 |
| [^19] | [PSYCHIC: A Neuro-Symbolic Framework for Knowledge Graph Question-Answering Grounding.](http://arxiv.org/abs/2310.12638) | 本论文提出了PSYCHIC，一个基于神经符号框架的知识图谱问答模型，在国际语义网会议的学术问答挑战中取得了较高的分数。 |
| [^20] | [Towards a Deep Learning-based Online Quality Prediction System for Welding Processes.](http://arxiv.org/abs/2310.12632) | 该论文提出了一个基于深度学习的气体金属电弧焊接预测质量系统的概念，通过收集和管理多传感器数据以及实时处理和特征工程的方式，可以识别关系并预测焊接质量。 |
| [^21] | [Heart Disease Detection using Vision-Based Transformer Models from ECG Images.](http://arxiv.org/abs/2310.12630) | 本研究提出使用基于ECG图像的视觉转换模型进行心脏疾病检测。心脏疾病是一种常见的医疗条件，早期准确检测对临床实践至关重要。近年来，结合先进技术和计算方法的发展，对心脏疾病检测进行了显著的进展。 |
| [^22] | [Cross-attention Spatio-temporal Context Transformer for Semantic Segmentation of Historical Maps.](http://arxiv.org/abs/2310.12616) | 这篇论文提出了一种基于U-Net的网络，通过使用跨关注的变换器（U-SpaTem）融合时空特征，解决了历史地图语义分割中的数据相关不确定性问题。 |
| [^23] | [Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model.](http://arxiv.org/abs/2310.12611) | 本研究通过三种方法识别英文语言模型中负责性别偏见的Transformer组件，然后使用这些组件进行参数高效的偏见缓解微调，取得了成功的性别偏见缓解效果并减少了对一般语言建模的损害。 |
| [^24] | [Denoising Heat-inspired Diffusion with Insulators for Collision Free Motion Planning.](http://arxiv.org/abs/2310.12609) | 本文提出了一种使用绝缘体改善热力扩散进行无碰撞运动规划的去噪方法。该方法通过单一的视觉输入，在推理时能够同时生成可达目标并规划避开障碍物的运动路径，具有稳健性和多模态适应性。 |
| [^25] | [Time-Aware Representation Learning for Time-Sensitive Question Answering.](http://arxiv.org/abs/2310.12585) | 该论文提出了一种时态感知的问题回答框架，通过引入时间上下文的区间抽取任务和相应的数据生成框架来训练模型，提高了QA模型的时间感知能力，在TimeQA数据集中的F1分数上超过了基准模型达8.5。 |
| [^26] | [Pretraining Language Models with Text-Attributed Heterogeneous Graphs.](http://arxiv.org/abs/2310.12580) | 本文提出了一个新的语言模型预训练框架，能够明确考虑到文本属性异构图中的拓扑和异构信息。通过优化语言模型和辅助的异构图神经网络，预测了文本属性异构图中的节点。同时，还设计了一个文本丰富性加权的节点抽样策略，以更好地利用文本信息。 |
| [^27] | [Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark.](http://arxiv.org/abs/2310.12567) | 本文介绍了一个名为Safety-Gymnasium的环境套件，其中包括单个和多个Agent场景中的安全关键任务，并提供了一个包含16种最先进的SafeRL算法的算法库。这个基准旨在促进对安全性能的评估和比较，推动强化学习在安全性能上的发展。 |
| [^28] | [DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text.](http://arxiv.org/abs/2310.12557) | DepWiGNN是一种用于多跳空间推理的深度图神经网络。它通过设计新颖的节点记忆方案，并在图的深度维度上聚合信息，从而能够收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，DepWiGNN在两个挑战数据集上比传统GNN方法具有更高的准确性。 |
| [^29] | [Large Language Model for Multi-objective Evolutionary Optimization.](http://arxiv.org/abs/2310.12541) | 本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。 |
| [^30] | [Testing the Consistency of Performance Scores Reported for Binary Classification Problems.](http://arxiv.org/abs/2310.12527) | 这篇论文介绍了一种测试报告的二分类问题性能分数和实验设置一致性的数值方法，该方法不依赖于统计推断。 |
| [^31] | [Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks.](http://arxiv.org/abs/2310.12516) | 本文提出了一种通过可迁移的对抗攻击在大型语言模型中自动生成评估数据的方法，并使用ChatGPT和Natural Questions（NQ）数据集进行了验证。 |
| [^32] | [SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation.](http://arxiv.org/abs/2310.12508) | 这篇论文提出了一种名为SalUn的机器遗忘方法，通过引入"权重显著性"的概念，将关注点从整个模型引导到具体的模型权重上，提高了遗忘的效果和效率。这是第一个能够有效消除遗忘数据、类别或概念影响的有原则的机器遗忘方法。 |
| [^33] | [Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models.](http://arxiv.org/abs/2310.12481) | 本文研究了大型语言模型中的文化主导问题，发现由于在模型训练中主要使用英语数据，当用户使用非英语语言提问时，模型往往提供与预期文化不相关的不恰当答案。我们提出了通过多样化数据预训练和文化感知提示两种方法来解决这个问题。 |
| [^34] | [GRAPE-S: Near Real-Time Coalition Formation for Multiple Service Collectives.](http://arxiv.org/abs/2310.12480) | GRAPE-S是一个基于hedonic游戏的联盟形成算法，能在需要分组成百上千台机器人的大规模集群中以近实时的方式生成解决方案。 |
| [^35] | [An Exploration of In-Context Learning for Speech Language Model.](http://arxiv.org/abs/2310.12477) | 本研究是首次探索了在语音处理中利用上下文学习（ICL）的可能性，通过在输入中呈现LM话语-标签示范，语音LM可以在没有文本监督的情况下实现少样本学习，并通过验证了在语音分类任务上进行ICL的可行性。 |
| [^36] | [Affective Conversational Agents: Understanding Expectations and Personal Influences.](http://arxiv.org/abs/2310.12459) | 该研究调查了745名受访者，研究了情感对话代理的期望和偏好，并发现在人与人的互动、情感支持和创造性任务的场景中，情感能力得到了重视，并受到情绪重新评估和个性特质等因素的影响。 |
| [^37] | [Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models.](http://arxiv.org/abs/2310.12454) | 本研究重新思考了构建用于理解预训练语言模型机制的有效度量方法。通过设计一系列度量方法，并使用树拓扑探针模型对BERT-large进行了实证研究。 |
| [^38] | [MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features.](http://arxiv.org/abs/2310.12451) | MTS-LOF是一种利用对比学习和遮挡自编码器方法的医学时间序列表示学习框架，能够为医疗应用提供更复杂、更丰富的上下文表示，并通过多遮挡策略实现了遮挡不变特征的学习。 |
| [^39] | [Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher.](http://arxiv.org/abs/2310.12443) | 该论文提出了一种新颖的生成检索框架，旨在将LLM转变为一个相关、负责任且可信赖的搜索器。该框架包括生成器、验证器和优化器三个核心模块，分别用于生成可信赖的在线来源、验证来源可靠性和优化不可信赖的来源。通过广泛的实验证明了该方法相对于其他方法在相关性、负责任性和可信度方面的优势。 |
| [^40] | [PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models.](http://arxiv.org/abs/2310.12439) | PoisonPrompt是一种新的后门攻击方法，能够成功地破坏基于提示的大型语言模型，该攻击方法的有效性、保真度和鲁棒性经过了广泛实验验证，强调了基于提示的语言模型面临的安全威胁和进一步研究的必要性。 |
| [^41] | [Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach.](http://arxiv.org/abs/2310.12428) | 这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。 |
| [^42] | [MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models.](http://arxiv.org/abs/2310.12426) | 本研究提出了一种多方面反馈的迭代优化框架，该框架包括冻结的语言模型和外部工具模块，每个模块都专注于特定的错误类型。实验证明该方法改善了大型语言模型在推理任务中的性能，相对提升了多达20%。 |
| [^43] | [Automated Repair of Declarative Software Specifications in the Era of Large Language Models.](http://arxiv.org/abs/2310.12425) | 大语言模型时代下，自动修复声明式软件规范的有效技术需求愈发突出。该研究评估了利用ChatGPT修复Alloy声明式语言规范的效果，并探索了大型语言模型在此自动修复过程中的机会。 |
| [^44] | [Provable Guarantees for Neural Networks via Gradient Feature Learning.](http://arxiv.org/abs/2310.12408) | 本研究提出了一个针对梯度特征学习的统一分析框架，证明了双层神经网络在训练过程中的可靠性，并在多个典型问题上展示了其有效性和有趣的学习现象。 |
| [^45] | [Classification-Aided Robust Multiple Target Tracking Using Neural Enhanced Message Passing.](http://arxiv.org/abs/2310.12407) | 本文提出了一种利用神经增强的方法进行分类辅助的鲁棒多目标跟踪，在强杂波环境中利用雷达传感器的测量信息来增强杂波剔除和数据关联，从而提高目标跟踪的鲁棒性。 |
| [^46] | [GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems.](http://arxiv.org/abs/2310.12397) | 本文研究了在推理问题中使用迭代提示的有效性，以解决图着色问题。通过实证研究发现，GPT-4的迭代自我批评和外部正确推理器验证对最终结果有实际影响。 |
| [^47] | [Learning to Solve Climate Sensor Placement Problems with a Transformer.](http://arxiv.org/abs/2310.12387) | 本文介绍了一种使用深度强化学习方法学习改进传感器布放策略的新方法，通过与其他方法的对比实验证明了该方法在产生高质量解决方案方面的有效性和优越性。 |
| [^48] | [Online Learning and Planning in Cognitive Hierarchies.](http://arxiv.org/abs/2310.12386) | 本研究扩展了一个形式化框架，用于模拟机器人系统的复杂集成推理行为，并实现了在线学习与规划。新的框架还允许更灵活地建模不同推理组件之间的交互。 |
| [^49] | [Solving Hard Analogy Questions with Relation Embedding Chains.](http://arxiv.org/abs/2310.12379) | 本文提出了一种解决困难的类比问题的方法，通过将关系建模为路径并关联其边缘与关系嵌入，以获得合适的中间词和有信息量的关系嵌入，从而结合了知识图谱和关系嵌入的优势。 |
| [^50] | [ClusT3: Information Invariant Test-Time Training.](http://arxiv.org/abs/2310.12345) | ClusT3是一种新颖的无监督测试时间训练方法，通过最大化多尺度特征图和离散潜在表示之间的互信息来增强深度学习模型的鲁棒性。实验结果表明，在不同的测试时间自适应基准上具有竞争性的分类性能。 |
| [^51] | [Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs' Non-linear Thinking.](http://arxiv.org/abs/2310.12342) | 本文提出了一种名为推断性排除提示（IEP）的新框架，通过结合排除和推理的原则，引导LLM进行非线性思考。IEP通过规划和自然语言推理，可以模拟复杂的人类思维过程，比其他方法具有更广泛的视角。 |
| [^52] | [Opportunities for Adaptive Experiments to Enable Continuous Improvement that Trades-off Instructor and Researcher Incentives.](http://arxiv.org/abs/2310.12324) | 适应性实验为持续课程改进提供了机会，通过动态部署最有效的条件以满足学生需求。 |
| [^53] | [The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis.](http://arxiv.org/abs/2310.12318) | 这项研究通过调查189篇论文，批判性地研究了情感分析在社会技术系统中的应用，揭示了对情感的不同概念化，并提出了一个伦理表格来解决情感分析中的公平利用问题。 |
| [^54] | [A Unifying Framework for Learning Argumentation Semantics.](http://arxiv.org/abs/2310.12309) | 本文提出了一种统一的框架来学习论证语义，通过使用可解释的方法，优于现有的论证求解器，并在形式论证和人机对话领域开辟了新的研究方向。 |
| [^55] | [Preference Optimization for Molecular Language Models.](http://arxiv.org/abs/2310.12304) | 本研究调查了使用直接偏好优化进行微调的方法，以更好地与化学家的偏好对齐生成的分子。这种方法简单、高效，且非常有效。 |
| [^56] | [Document-Level Language Models for Machine Translation.](http://arxiv.org/abs/2310.12303) | 这项工作提出了一种利用文档级别语言模型构建上下文感知的翻译系统的方法。通过结合任何现有的句级别翻译模型与文档级别语言模型，并借鉴模型组合的最新进展，尤其是权重技术的提出，可以显著提高文档级别指标并降低计算开销。 |
| [^57] | [Jorge: Approximate Preconditioning for GPU-efficient Second-order Optimization.](http://arxiv.org/abs/2310.12298) | 本文介绍了Jorge，一种GPU高效的二阶优化算法，通过近似预处理方法替代矩阵求逆计算来提高计算效率，同时兼具二阶方法的收敛性能。实验证明了Jorge的有效性。 |
| [^58] | [Fact-based Agent modeling for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2310.12290) | 提出了一种基于事实的智能体建模方法，用于解决在非稳态环境中对其他智能体的信念、行为和意图进行建模的问题，并在未知场景中实现智能体建模。 |
| [^59] | [Enhancing the Performance of Automated Grade Prediction in MOOC using Graph Representation Learning.](http://arxiv.org/abs/2310.12281) | 本研究通过图表示学习构建了一个独特的知识图谱，以提高MOOC中自动化成绩预测的性能。 |
| [^60] | [An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning.](http://arxiv.org/abs/2310.12274) | 提出了一种多概念提示学习（MCPL）框架，通过同时学习多个新的“词”来解决在单个场景中识别和整合多个对象级概念的挑战。针对词概念相关性准确性问题，提出了注意力掩码、提示对比损失和绑定形容词等三种正则化技术。通过图像生成进行了评估，结果表明该框架能够生成更多样化和合成的图像。 |
| [^61] | [A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm.](http://arxiv.org/abs/2310.12244) | 这篇论文提出了一种统一的带有记忆的领域增量学习方法（UDIL），通过统一不同的现有方法并使用自适应系数，实现了更紧的泛化误差界限，并在实验证明在合成数据和真实数据集上优于最先进的方法。 |
| [^62] | [Few-Shot In-Context Imitation Learning via Implicit Graph Alignment.](http://arxiv.org/abs/2310.12238) | 本文提出了一种少样本背景下的模仿学习方法，通过将模仿学习视为物体的图表示之间的条件对齐问题，实现了在没有先验知识或进一步训练的情况下，机器人可以在新的物体集上执行任务。 |
| [^63] | [An Eager Satisfiability Modulo Theories Solver for Algebraic Datatypes.](http://arxiv.org/abs/2310.12234) | 该论文提出了一种针对代数数据类型的热切满足模理论求解器。通过将ADT查询简化为非解释函数 (UF)，然后使用现有求解器，该方法在声音性和完备性上都得到了证明，并且在性能上优于现有方法。 |
| [^64] | [Stranger Danger! Cross-Community Interactions with Fringe Users Increase the Growth of Fringe Communities on Reddit.](http://arxiv.org/abs/2310.12186) | 边缘互动是推动Reddit上边缘社区增长的机制之一，收到边缘互动的用户比没有收到互动的用户更有可能加入边缘社区。 |
| [^65] | [Architectural Implications of GNN Aggregation Programming Abstractions.](http://arxiv.org/abs/2310.12184) | 本文通过对现有GNN聚合编程抽象进行分类，并在最先进的GNN库上进行特征研究和性能比较，提供了未来GNN加速的见解。 |
| [^66] | [An Optimistic-Robust Approach for Dynamic Positioning of Omnichannel Inventories.](http://arxiv.org/abs/2310.12183) | 这篇论文介绍了一种乐观-鲁棒的全渠道库存动态定位方法，通过兼顾库存弹性和改善平均性能，来平衡店铺失去销售和跨渠道电子商务履约成本的权衡。 |
| [^67] | [RK-core: An Established Methodology for Exploring the Hierarchical Structure within Datasets.](http://arxiv.org/abs/2310.12168) | RK-core方法探索数据集中的层次结构，通过分析样本的核心值，发现核心值高的样本在性能上具有更大的贡献。 |
| [^68] | [AI Potentiality and Awareness: A Position Paper from the Perspective of Human-AI Teaming in Cybersecurity.](http://arxiv.org/abs/2310.12162) | 这篇立场文件通过探讨人工智能在网络安全中的潜力，强调了人工智能与人类专家的协作的重要性。人工智能系统可以通过模式识别和预测建模主动发现漏洞并检测异常情况，而人类专家可以补充和辅助AI的输出结果，提高整体的网络安全防护能力。 |
| [^69] | [Improving Generalization of Alignment with Human Preferences through Group Invariant Learning.](http://arxiv.org/abs/2310.11971) | 该论文提出了一种通过强化学习实现在不同数据组或领域中学习一致策略的方法，该方法可以提高AI助手对不同领域的泛化能力，并更好地与人类偏好对齐。 |
| [^70] | [Auction-Based Scheduling.](http://arxiv.org/abs/2310.11798) | 该论文提出了一种基于拍卖的调度框架，用于解决多目标决策问题。该框架的创新之处在于将每个目标的实现分配给单独的策略，并且可以独立创建、修改和替换这些策略。使用拍卖机制来解决冲突和组合策略，确保长期的调度公平性。 |
| [^71] | [Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT.](http://arxiv.org/abs/2310.11709) | 本文介绍了用于时间图的“实时图实验室”的概念，该实验室可以从NFT的区块链中提取开放、动态和实时的交易图，为了弥补对新兴NFT生态系统的特性了解的缺口，我们使用NFT交易网络实例化了一个实时图并进行了调查 |
| [^72] | [Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning.](http://arxiv.org/abs/2310.11670) | 基于原型的超适配器（PHA）框架用于样本高效多任务调整，通过引入实例密集的检索器和样本高效的原型超网络生成条件模块，在多任务学习和少样本迁移学习中取得了可比性能的提升，甚至在数据量较小时也能超过其他强基线方法的性能。 |
| [^73] | [WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks.](http://arxiv.org/abs/2310.11595) | 本文提出了一种名为WaveAttack的新型基于频率的背门攻击方法，通过离散小波变换获取图像的高频特征来生成背门触发器，并引入了一种不对称的频率混淆方法来改善触发器的影响力，有效提高了背门攻击的成功率并且不易被检测到。 |
| [^74] | [When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting.](http://arxiv.org/abs/2310.11569) | 提出了一个新的概率分层时间序列预测模型，该模型能够有效建模和预测具有层次化关系的多变量时间序列。相较于现有方法，该模型不仅考虑点预测，还能提供经过良好校准的概率预测分布，并且在建模过程中考虑了预测分布的相关性。 |
| [^75] | [Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction.](http://arxiv.org/abs/2310.11466) | 本文研究了蛋白质基于结构的性质预测中使用预测结构时性能下降的原因，并将其归因为结构嵌入偏差。 |
| [^76] | [HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning.](http://arxiv.org/abs/2310.11102) | HGCVAE是一种将生成式学习和对比学习整合为一体的异构图学习方法，通过利用生成式的自监督学习能力来解决异构图学习的挑战。 |
| [^77] | [BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys.](http://arxiv.org/abs/2310.10765) | 提出了一种新颖的方法BiomedJourney，通过指导学习多模态患者旅程，进行反事实生物医学图像生成。使用GPT-4处理图像报告生成疾病进展的自然语言描述，并训练潜在扩散模型。 |
| [^78] | [ACES: generating diverse programming puzzles with autotelic language models and semantic descriptors.](http://arxiv.org/abs/2310.10692) | ACES是一种使用自我目标语言模型和语义描述符生成多样化的编程难题的方法，能够优化有趣的多样性和少样本生成。 |
| [^79] | [In-Context Pretraining: Language Modeling Beyond Document Boundaries.](http://arxiv.org/abs/2310.10638) | 本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。 |
| [^80] | [Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories.](http://arxiv.org/abs/2310.10541) | 本论文提出了一种高效的数据集精炼方法，通过与平滑高质量的专家轨迹对齐，实现对大规模数据集的替代，并提出了剪辑损失和梯度惩罚的集成来调节学生和专家之间的互动。 |
| [^81] | [Microscaling Data Formats for Deep Learning.](http://arxiv.org/abs/2310.10537) | 本文评估了Microscaling（MX）数据格式在降低深度学习应用的计算和存储成本方面的可行性。实证结果显示MX数据格式可以作为基线FP32的替代，同时保持低用户摩擦，并且成功在超过两打基准测试中以小于8位的数据格式进行了训练。 |
| [^82] | [A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks.](http://arxiv.org/abs/2310.09430) | 通过对大型语言模型在非分布式逻辑推理任务上进行系统评估，我们发现这些模型在处理我们新构建的数据集时都存在困难，尽管它们在其他自然语言处理任务上表现良好。这表明这些模型在逻辑推理方面的泛化和鲁棒性仍需要进一步研究。 |
| [^83] | [Ranking LLM-Generated Loop Invariants for Program Verification.](http://arxiv.org/abs/2310.09342) | 本研究提出了一种针对LLM生成结果进行重新排名的方法，可以显著提高正确不变量的排名，从而减少程序验证的调用次数。 |
| [^84] | [Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation.](http://arxiv.org/abs/2310.08395) | 本文提出了一种使用思路链（CoT）对大型语言模型进行少样本知识库问题生成的方法，该方法将问题生成任务形式化为推理问题，并通过检索支持性逻辑形式和编写提示来实现生成过程。 |
| [^85] | [Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer.](http://arxiv.org/abs/2310.07587) | 本文提出了一种名为Fed-GraB的方法，该方法通过自适应梯度平衡器来解决联邦式长尾学习的问题。该方法能够在隐私约束下刻画全局长尾分布，并通过调整本地学习策略来解决头部-尾部不平衡的问题。 |
| [^86] | [ChatGPT for Computational Topology.](http://arxiv.org/abs/2310.07570) | 该论文介绍了如何利用ChatGPT桥接理论拓扑概念和计算拓扑实现之间的差距，展示了在没有编码技能的情况下，通过ChatGPT的帮助，纯粹的理论家如何将数学公式和概念转化为功能性的计算拓扑代码。 |
| [^87] | [ROMO: Retrieval-enhanced Offline Model-based Optimization.](http://arxiv.org/abs/2310.07560) | ROMO是一种检索增强的离线模型优化方法，通过在离线数据集中优化平庸设计，并保持给定的约束来解决约束MBO问题。 |
| [^88] | [KwaiYiiMath: Technical Report.](http://arxiv.org/abs/2310.07488) | KwaiYiiMath是一个用于增强数学推理能力的大型语言模型，通过应用监督微调和人类反馈强化学习，在英语和中文数学任务上取得了最先进的性能，并且能够正确解决生成的问题过程。 |
| [^89] | [Jaeger: A Concatenation-Based Multi-Transformer VQA Model.](http://arxiv.org/abs/2310.07091) | Jaeger是一种基于连接的多变换器VQA模型，利用RoBERTa large和GPT2-xl作为特征提取器，通过并行考虑多源信息来增强模型表征能力。 |
| [^90] | [CAW-coref: Conjunction-Aware Word-level Coreference Resolution.](http://arxiv.org/abs/2310.06165) | 本文介绍了一种关联词感知的词级共指消解模型（CAW-coref），在处理并列提及的情况下表现出了较高的性能，有效地缩小了与昂贵的最先进方法的差距。 |
| [^91] | [Solving Multi-Configuration Problems: A Performance Analysis with Choco Solver.](http://arxiv.org/abs/2310.02658) | 本文介绍了使用Choco Solver进行多配置问题求解的应用案例，以及对约束求解器性能分析的研究，从而揭示了相关性能问题。 |
| [^92] | [zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning.](http://arxiv.org/abs/2310.02554) | zkFL是一种基于零知识证明的联邦学习梯度聚合方法，通过提供每轮的证明来解决协调者恶意行为的问题。 |
| [^93] | [SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training.](http://arxiv.org/abs/2310.02227) | SNIP引入了一种统一的预训练框架，通过联合对比学习加强了符号和数值领域之间的相似性，并提供了跨领域的表示洞察力。 |
| [^94] | [OceanGPT: A Large Language Model for Ocean Science Tasks.](http://arxiv.org/abs/2310.02031) | OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。 |
| [^95] | [Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation.](http://arxiv.org/abs/2310.01680) | 本论文提出了一种关键点增强的自监督学习方法，通过在医学图像分割中引入长程空间自注意力，同时运用全局和局部自监督预训练，以提高CNN模型在低注释情况下的性能。 |
| [^96] | [Meta Semantic Template for Evaluation of Large Language Models.](http://arxiv.org/abs/2310.01448) | 提出了一种通过创建元语义模板来评估大型语言模型（LLM）对语义理解能力的方法，该方法利用现有数据集生成新的超出分布（OOD）评估集。 |
| [^97] | [Measuring Value Understanding in Language Models through Discriminator-Critique Gap.](http://arxiv.org/abs/2310.00378) | 通过鉴别-批判差距测量LLMs对人类价值的理解，我们提出了价值理解测量（VUM）框架，并使用GPT-4开发了一个包含一千个对话的数据集。我们的评估结果显示，尺度定律对LLMs的“知道什么”有较大影响，而对“知道为什么”影响较小。 |
| [^98] | [AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling.](http://arxiv.org/abs/2309.13218) | 这篇论文提出了一个AI-企业优化的协同辅助系统，通过采用大型语言模型和微调预训练模型的方法，实现了减少人类专业知识需求的目标。 |
| [^99] | [AnglE-Optimized Text Embeddings.](http://arxiv.org/abs/2309.12871) | 本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。 |
| [^100] | [Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models.](http://arxiv.org/abs/2309.10444) | 本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。 |
| [^101] | [Generative modeling, design and analysis of spider silk protein sequences for enhanced mechanical properties.](http://arxiv.org/abs/2309.10170) | 提出了一种生成式语言模型，用于设计具有复杂目标机械性能组合的新型蜘蛛丝蛋白序列。通过BLAST搜索、性能评估、分子结构比较和序列基序分析等方式对模型性能进行了评估。 |
| [^102] | [DeepVol: A Deep Transfer Learning Approach for Universal Asset Volatility Modeling.](http://arxiv.org/abs/2309.02072) | DeepVol是一种用于通用资产波动性建模的深度迁移学习方法，通过一个通用模型有效地捕捉和建模所有金融资产的波动性动态，可能改变对波动性的理解和预测方式。 |
| [^103] | [Topic-Level Bayesian Surprise and Serendipity for Recommender Systems.](http://arxiv.org/abs/2308.06368) | 本文通过引入基于主题的贝叶斯惊喜概念，提出了一种用于推荐系统的意外性模型，以解决过滤泡问题，通过识别相似用户和测量用户对物品的意外性来推荐具有高潜力的意外性物品。 |
| [^104] | [Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation.](http://arxiv.org/abs/2307.09688) | Amazon-M2是一个多语言多区域购物会话数据集，可以增强个性化推荐和理解用户偏好能力。 |
| [^105] | [Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation.](http://arxiv.org/abs/2307.06125) | 这项工作提出了一个层次化的强化学习方法，用于解决在未知环境中需要同时进行操控和导航的交互式多目标搜索任务。实验证明，该方法可以在新环境中进行零样本迁移，并对未见过的子任务具有鲁棒性。 |
| [^106] | [URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates.](http://arxiv.org/abs/2307.03810) | URL基准是一个评估预训练模型可转移性和不确定性估计的方式，研究发现专注于表示本身不确定性或直接估计预测风险的方法效果优于基于概率的方法。 |
| [^107] | [Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data.](http://arxiv.org/abs/2307.03512) | 本文研究了利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割。实验结果表明，传输学习的应用可以提高性能，为未来工作提供基准。 |
| [^108] | [MeLM, a generative pretrained language modeling framework that solves forward and inverse mechanics problems.](http://arxiv.org/abs/2306.17525) | MeLM是一个灵活的多模式力学语言模型，利用自回归注意力机制解决正向和逆向力学问题，表现出色。 |
| [^109] | [Learning-to-Rank Meets Language: Boosting Language-Driven Ordering Alignment for Ordinal Classification.](http://arxiv.org/abs/2306.13856) | 本文提出了一种利用语言驱动的高效序数分类方法，即L2RCLIP，它通过视觉-语言对齐任务充分利用语言中的序数先验，利用补充提示调整技术RankFormer增强原始排序提示的排序关系，并使用跨模态排序约束损失(CMOCL)进一步将语言先验融入模型中。在多个标准数据集中，L2RCLIP都比现有最先进方法具有更好的性能表现。 |
| [^110] | [Provably Powerful Graph Neural Networks for Directed Multigraphs.](http://arxiv.org/abs/2306.11586) | 本文分析了一组简单的改进方法，将标准的消息传递图神经网络（GNN）转化为可证明强大的有向多图神经网络，能够检测任何有向子图模式。实验结果展示了这些改进方法在合成子图检测任务和金融犯罪分析任务上的出色性能。 |
| [^111] | [Evaluating Superhuman Models with Consistency Checks.](http://arxiv.org/abs/2306.09983) | 本文提出了一个用一致性检查评估超人模型的框架，可以发现决策制定中的逻辑不一致性，即使对于超人模型的决策正确性可能是不可能评估的情况。 |
| [^112] | [ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations.](http://arxiv.org/abs/2306.08141) | 为研究人工智能与人类交互，研究者创建了ArtWhisperer数据集，这是一个在线游戏，人们通过反复尝试不同的提示词，来生成和目标图像类似的图像，并记录了50,000多个交互记录。在初步分析中，研究者发现人们提交了各种各样的提示词，并能够发现生成各种文本描述的图像。 |
| [^113] | [Language-Guided Traffic Simulation via Scene-Level Diffusion.](http://arxiv.org/abs/2306.06344) | 该论文提出了一种可以受到语言指导的场景级条件扩散模型，该模型能够生成真实且可控的交通，并通过大型语言模型将用户的查询转化为损失函数，指导模型生成符合查询条件的仿真交通。 |
| [^114] | [On the Design Fundamentals of Diffusion Models: A Survey.](http://arxiv.org/abs/2306.04542) | 本文综述了扩散模型的设计基础，即其三个关键组件：正向过程、逆向过程和采样过程，为未来的研究提供了有益的细粒度透视。 |
| [^115] | [Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing Semantics with MASCHInE.](http://arxiv.org/abs/2306.03659) | 本论文提出了一种通过 MASCHInE 捕捉语义学习知识图嵌入的方法，通过设计生成原型图并利用其语义，进而训练出更好地捕捉语义的 KGEs。 |
| [^116] | [Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning.](http://arxiv.org/abs/2306.00477) | 本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。 |
| [^117] | [NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models.](http://arxiv.org/abs/2305.16986) | NavGPT是基于LLM的导航智能体，可以在视觉语言导航（VLN）中，通过对文本描述进行推理，执行零-shot连续动作预测。该模型具有高级规划能力，可以将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。NavGPT展示了通用体现智能体发展的美好前景。 |
| [^118] | [Voyager: An Open-Ended Embodied Agent with Large Language Models.](http://arxiv.org/abs/2305.16291) | Voyager是一个在Minecraft中使用大型语言模型进行开放式探索和学习的代理，它通过自动课程设置、可执行代码技能库和迭代提示机制不断提升自己的能力，并展现出强大的终身学习能力和在玩Minecraft方面的出色表现。 |
| [^119] | [Connecting Multi-modal Contrastive Representations.](http://arxiv.org/abs/2305.14381) | 本文提出了一种无需配对数据学习MCR的方法，叫做C-MCR，并且在新空间中使用重叠模态B的数据来对齐两个MCR。通过这个方法，非重叠模态对（A，C）也可以使用连接。 |
| [^120] | [Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs.](http://arxiv.org/abs/2305.12818) | 基于无注释平行语料库，我们提出一种基于词义共存模式的多语言图方法，用于低资源语言的跨语言迁移学习。通过建立高质量的多语言嵌入，我们实现了高召回率的词义共存识别。 |
| [^121] | [Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning.](http://arxiv.org/abs/2305.12295) | 本文介绍了一种名为Logic-LM的新框架，它将大型语言模型与符号求解器结合起来，以提升在复杂逻辑问题上的推理能力。通过将自然语言问题转化为符号表达，并利用确定性符号求解器进行推理，我们的方法能够有效地改进准确逻辑推理。实验证明，Logic-LM在多个逻辑推理数据集上取得了显著的性能提升，并且相比使用标准提示或思维链提示，效果分别提高了39.2%和18.4%。这表明将大型语言模型与符号逻辑相结合是实现准确逻辑推理的一个有前途的方法。 |
| [^122] | [Automatic Prompt Optimization with "Gradient Descent" and Beam Search.](http://arxiv.org/abs/2305.03495) | 在基于大型语言模型的自然语言处理中，使用梯度下降和 beam search 的自动提示优化方法可以自动改进提示，提高性能。 |
| [^123] | [PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques.](http://arxiv.org/abs/2304.12410) | 本文提出了PEFT-Ref参考架构，标准化了不同PEFT技术共享的方面，隔离了差异到特定位置和交互中，模块化的视图有助于比较不同技术及其效率和任务性能，并有助于更好地理解PEFT的基本原理。 |
| [^124] | [An Introduction to Transformers.](http://arxiv.org/abs/2304.10557) | Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。 |
| [^125] | [A Scalable Test Problem Generator for Sequential Transfer Optimization.](http://arxiv.org/abs/2304.08503) | STO中已有的测试问题设计不完善，难以代表真实问题多样化关系，限制了算法的表现。本文介绍了一种可扩展的序列转移优化问题生成器。 |
| [^126] | [On Existential First Order Queries Inference on Knowledge Graphs.](http://arxiv.org/abs/2304.07063) | 本文阐述了关于知识图谱中存在性一阶查询推理的新方法，提出了一个新数据集，并开发了一种来自模糊逻辑理论的新搜索算法，该算法能够解决新公式，并在现有公式中超过以前的方法。 |
| [^127] | [IC3: Image Captioning by Committee Consensus.](http://arxiv.org/abs/2302.01328) | "IC3: Image Captioning by Committee Consensus"引入了一种通过委员会共识生成图像字幕的方法，能够从多个注释者的视角捕捉高层细节，优于单个人生成的参考字幕，并在视觉描述方面取得了显著改进。 |
| [^128] | [A Retrieve-and-Read Framework for Knowledge Graph Link Prediction.](http://arxiv.org/abs/2212.09724) | 这项研究提出了一种检索和阅读框架来解决现有知识图谱链接预测系统的局限性。通过首先检索相关子图上下文，然后使用高容量阅读器联合推理上下文和查询，该框架能够提供更有用的信息和更强大的表达能力。 |
| [^129] | [Large Language Models are reasoners with Self-Verification.](http://arxiv.org/abs/2212.09561) | 本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。 |
| [^130] | [Multi-person 3D pose estimation from unlabelled data.](http://arxiv.org/abs/2212.08731) | 本文提出了一种基于图神经网络和多层感知器的模型，通过深度学习在多视图系统中进行多人三维姿势估计，实现了对人物的唯一标识和克服噪声和潜在遮挡的挑战。此方法不需要大型数据集的3D标注。 |
| [^131] | [Learning threshold neurons via the "edge of stability".](http://arxiv.org/abs/2212.07469) | 该论文通过对简化的两层神经网络模型的梯度下降进行详细分析，揭示了大学习率下非凸训练动态的稳定边缘现象，并发现了神经网络无法学习阈值样式神经元的临界步长。 |
| [^132] | [Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction.](http://arxiv.org/abs/2211.08238) | 本文提出了一种利用对比学习和数字证据的方法改进混淆的法律判决预测。通过提出一种监督对比学习方法和利用数字证据预测处罚期限，成功地解决了区分分类错误和利用数字的问题。 |
| [^133] | [Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook.](http://arxiv.org/abs/2210.13623) | 这篇综述调查了强化学习和赌博机在语音和自然语言处理中的最新进展，讨论了如何有效利用它们解决相关问题，构建适应性、交互性和可扩展性的模型。 |
| [^134] | [Optimality Guarantees for Particle Belief Approximation of POMDPs.](http://arxiv.org/abs/2210.05015) | 该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。 |
| [^135] | [Unraveling the Connections between Privacy and Certified Robustness in Federated Learning Against Poisoning Attacks.](http://arxiv.org/abs/2209.04030) | 该论文研究了联邦学习中隐私和认证稳定性之间的联系，并探讨了如何利用差分隐私提供认证稳定性以及如何改进隐私以提高稳定性认证。 |
| [^136] | [Can Brain Signals Reveal Inner Alignment with Human Languages?.](http://arxiv.org/abs/2208.06348) | 本研究探索了脑信号和人类语言之间的关系，并介绍了一种名为MTAM的方法，该方法在情感分析和关系检测等下游应用中取得了新的最先进结果。 |
| [^137] | [Learning to translate by learning to communicate.](http://arxiv.org/abs/2207.07025) | 本研究提出了一种利用紧急通信（EC）和预先训练的多语言模型的技术，通过基于视觉任务激励模型来改进资源匮乏语言的非监督NMT系统。实验证明，在四种语言中，其中包括了资源匮乏的尼泊尔语，我们的方法优于仅使用回译的基准模型。 |
| [^138] | [PROFHIT: Probabilistic Robust Forecasting for Hierarchical Time-series.](http://arxiv.org/abs/2206.07940) | PROFHIT是一个概率鲁棒的分层时间序列预测模型，能够提供整个层次结构的预测分布，并引入一种新颖的分布一致性正则化方法。 |
| [^139] | [Category-Agnostic 6D Pose Estimation with Conditional Neural Processes.](http://arxiv.org/abs/2206.07162) | 该论文提出了一种无关类别的6D姿态估计方法，通过神经过程元学习来捕捉对象的纹理和几何形状，并使用几何感知解码器考虑对象的几何约束进行关键点预测。 |
| [^140] | [Example-based Hypernetworks for Out-of-Distribution Generalization.](http://arxiv.org/abs/2203.14276) | 本文提出了一个基于示例的超网络框架，利用多个源领域的标记数据来进行领域外泛化。该框架通过生成输入示例的唯一签名，并将其嵌入源领域的语义空间中，并利用超网络生成任务分类器的权重。实验结果表明，该方法在29个适应场景中表现优于现有算法，且在输入示例的表示上具有丰富性。同时，与少样本GPT-3进行了比较，证明了其有效性。 |
| [^141] | [Deep Discriminative to Kernel Generative Networks for Calibrated Inference.](http://arxiv.org/abs/2201.13001) | 该论文提出了将判别网络转换为生成网络的方法，用高斯核替换多面体中的仿射函数来生成模型，解决了内部和外部数据校准问题，并在 CIFAR-10，CIFAR-100 和 SVHN 等基准数据集上测试了方法的有效性。 |
| [^142] | [Trilevel and Multilevel Optimization using Monotone Operator Theory.](http://arxiv.org/abs/2105.09407) | 该论文提出了一个基于不动点理论的自然一阶算法，用于解决通用的多层优化问题，并分析了其在不同参数区间下的收敛性和收敛速度。 |

# 详细

[^1]: 实验叙事：人类众包叙事和AI叙事的比较

    Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and AI Storytelling. (arXiv:2310.12902v1 [cs.CL])

    [http://arxiv.org/abs/2310.12902](http://arxiv.org/abs/2310.12902)

    本研究提出了一种框架，通过比较人类众包叙事和AI叙事，探究了文化产物和社会偏见在故事中的表现。实验结果显示，GPT-3.5和GPT-4生成的叙事更具进展性，并且普罗米修斯神话在人类和大型语言模型的想象中起到了重要作用。

    

    本论文提出了一个框架，结合行为和计算实验，利用虚构的提示作为一种新的工具，研究人类和生成式AI叙事中的文化产物和社会偏见。本研究分析了2019年6月由众包工作者创作的250个故事和2023年3月由GPT-3.5和GPT-4生成的80个故事，将叙事学和推理统计学方法相结合。众包工作者和大型语言模型都回答了关于与人工智能人类相恋的主题的相同提示。提出的实验范式使人类和LLM生成的叙事可以直接进行比较。对于提到普罗米修斯主题的回应证实了普罗米修斯神话在人类和大型语言模型的集体想象中的普遍存在。所有提供的叙事都表现出科学或技术的追求。分析表明，GPT-3.5和尤其是GPT-4生成的叙事更具进展性。

    The paper proposes a framework that combines behavioral and computational experiments employing fictional prompts as a novel tool for investigating cultural artifacts and social biases in storytelling both by humans and generative AI. The study analyzes 250 stories authored by crowdworkers in June 2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging methods from narratology and inferential statistics. Both crowdworkers and large language models responded to identical prompts about creating and falling in love with an artificial human. The proposed experimental paradigm allows a direct comparison between human and LLM-generated storytelling. Responses to the Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth in the collective imaginary of both humans and large language models. All solicited narratives present a scientific or technological pursuit. The analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more more progre
    
[^2]: 个性化的人类移动预测方法及其贡献

    Personalized human mobility prediction for HuMob challenge. (arXiv:2310.12900v1 [cs.LG])

    [http://arxiv.org/abs/2310.12900](http://arxiv.org/abs/2310.12900)

    该论文介绍了一种个性化的人类移动预测方法，基于个体数据而不是整体数据进行预测，并成功运用于HuMob Challenge竞赛中。采用了特征设计和机器学习模型SVR，通过离线评估和特征选择和参数调整，使预测准确性得到验证。

    

    我们介绍了用于创建提交给HuMob Challenge的数据的方法，这是一个用于人类移动预测的数据分析竞赛。我们采用了一个个性化模型基于个体的数据来预测其运动轨迹，而不是基于整体运动的预测，基于人类运动对于每个人而言是独特的假设。我们设计了特征，如日期和时间，活动时间，周几，一天中的时间和POI（兴趣点）访问频率等。作为额外的特征，我们通过聚类来融合具有相似行为模式的其他个体的运动。我们采用的机器学习模型是支持向量回归（SVR）。我们通过离线评估进行准确性检验，并进行特征选择和参数调整。尽管总体数据集包含10万名用户的轨迹，但我们的方法只使用了2万名目标用户的数据，并不需要使用其他8万名用户的数据。

    We explain the methodology used to create the data submitted to HuMob Challenge, a data analysis competition for human mobility prediction. We adopted a personalized model to predict the individual's movement trajectory from their data, instead of predicting from the overall movement, based on the hypothesis that human movement is unique to each person. We devised the features such as the date and time, activity time, days of the week, time of day, and frequency of visits to POI (Point of Interest). As additional features, we incorporated the movement of other individuals with similar behavior patterns through the employment of clustering. The machine learning model we adopted was the Support Vector Regression (SVR). We performed accuracy through offline assessment and carried out feature selection and parameter tuning. Although overall dataset provided consists of 100,000 users trajectory, our method use only 20,000 target users data, and do not need to use other 80,000 data. Despite 
    
[^3]: TwinPot: 数字孪生辅助的蜜罐用于网络安全的智能海港

    TwinPot: Digital Twin-assisted Honeypot for Cyber-Secure Smart Seaports. (arXiv:2310.12880v1 [cs.CR])

    [http://arxiv.org/abs/2310.12880](http://arxiv.org/abs/2310.12880)

    该论文介绍了一种数字孪生辅助的蜜罐，用于保护智能海港的网络安全。传统安全解决方案对于保护物联网和物理网络系统是有限的，而蜜罐则可以提供有关攻击者行为的宝贵信息。数字孪生技术可以增强虚拟蜜罐的逼真性，吸引更多的攻击者。

    

    最近十年，随着效率需求的上升和货物量的不断增加，下一代港口的概念变得更加明显。在这个智能基础设施和设施的新时代，很明显网络安全已经成为海港和海事当局近期最关注的问题，并且是大多数港口议程上的首要关注点。传统的安全解决方案可以应用于保护物联网和物理网络系统免受有害实体的侵害。然而，如果这些解决方案更透明地运行，安全研究人员只能观察、检查和了解攻击者的行为。因此，蜜罐是潜在的解决方案，因为它们提供有关攻击者的宝贵信息。蜜罐可以是虚拟的或物理的。虚拟蜜罐必须更加逼真以吸引攻击者，因此需要更好的高度逼真性。为此，可以采用数字孪生技术(DT)。

    The idea of next-generation ports has become more apparent in the last ten years in response to the challenge posed by the rising demand for efficiency and the ever-increasing volume of goods. In this new era of intelligent infrastructure and facilities, it is evident that cyber-security has recently received the most significant attention from the seaport and maritime authorities, and it is a primary concern on the agenda of most ports. Traditional security solutions can be applied to safeguard IoT and Cyber-Physical Systems (CPS) from harmful entities. Nevertheless, security researchers can only watch, examine, and learn about the behaviors of attackers if these solutions operate more transparently. Herein, honeypots are potential solutions since they offer valuable information about the attackers. It can be virtual or physical. Virtual honeypots must be more realistic to entice attackers, necessitating better high-fidelity. To this end, Digital Twin (DT) technology can be employed t
    
[^4]: 使用层次视觉Transformer和多实例学习预测组织病理学中卵巢癌的治疗反应

    Predicting Ovarian Cancer Treatment Response in Histopathology using Hierarchical Vision Transformers and Multiple Instance Learning. (arXiv:2310.12866v1 [eess.IV])

    [http://arxiv.org/abs/2310.12866](http://arxiv.org/abs/2310.12866)

    该研究使用Hierarchical Vision Transformers和多实例学习来预测卵巢癌的治疗反应，为卵巢癌患者选择治疗方案提供了有效的自动预测方法。

    

    对于许多患者来说，目前的卵巢癌治疗效果有限。对于某些治疗方法，无法预测患者的反应，这可能会使他们暴露于治疗的不良效果而没有任何治疗效果。作为卵巢癌中使用组织病理学图像自动预测治疗效果（ATEC23）挑战的一部分，我们评估了深度学习在预测包括抗血管生成药物贝伐单抗在内的治疗方案能否在至少6个月内促使缓解或预防疾病进展的有效性。我们的方法使用预训练的Hierarchical Image Pyramid Transformer（HIPT）提取区域级特征，并使用基于注意力的多实例学习（ABMIL）模型来聚合特征和分类整个幻灯片。最优的HIPT-ABMIL模型在内部平衡准确度方面为60.2%+-2.9%，并且...

    For many patients, current ovarian cancer treatments offer limited clinical benefit. For some therapies, it is not possible to predict patients' responses, potentially exposing them to the adverse effects of treatment without any therapeutic benefit. As part of the automated prediction of treatment effectiveness in ovarian cancer using histopathological images (ATEC23) challenge, we evaluated the effectiveness of deep learning to predict whether a course of treatment including the antiangiogenic drug bevacizumab could contribute to remission or prevent disease progression for at least 6 months in a set of 282 histopathology whole slide images (WSIs) from 78 ovarian cancer patients. Our approach used a pretrained Hierarchical Image Pyramid Transformer (HIPT) to extract region-level features and an attention-based multiple instance learning (ABMIL) model to aggregate features and classify whole slides. The optimal HIPT-ABMIL model had an internal balanced accuracy of 60.2% +- 2.9% and an
    
[^5]: 基于Radau方法的物理信息神经网络求解高阶微分代数方程系统

    Physical Information Neural Networks for Solving High-index Differential-algebraic Equation Systems Based on Radau Methods. (arXiv:2310.12846v1 [math.NA])

    [http://arxiv.org/abs/2310.12846](http://arxiv.org/abs/2310.12846)

    本文提出了一个将Radau数值方法和神经网络结构相结合的物理信息神经网络框架，能够直接求解高阶微分代数方程系统，并采用领域分解策略提高求解能力。

    

    已知微分代数方程(DAEs)能够描述动态变化和基础约束，已经广泛应用于流体力学、多体动力学、机械系统和控制理论等工程领域。在这些领域的实际物理建模中，系统通常会产生高阶DAEs。传统的隐式数值方法在求解高阶系统时通常会导致数值精度下降。最近，物理信息神经网络(PINN)在解决DAE系统方面引起了关注。然而，它面临着如不能直接求解高阶系统、预测精度较低和泛化能力较弱等挑战。本文提出了一个将Radau IIA数值方法与注意力机制相结合的神经网络结构的PINN计算框架，以直接求解高阶DAEs。此外，我们还采用了领域分解策略以增强其求解能力。

    As is well known, differential algebraic equations (DAEs), which are able to describe dynamic changes and underlying constraints, have been widely applied in engineering fields such as fluid dynamics, multi-body dynamics, mechanical systems and control theory. In practical physical modeling within these domains, the systems often generate high-index DAEs. Classical implicit numerical methods typically result in varying order reduction of numerical accuracy when solving high-index systems.~Recently, the physics-informed neural network (PINN) has gained attention for solving DAE systems. However, it faces challenges like the inability to directly solve high-index systems, lower predictive accuracy, and weaker generalization capabilities. In this paper, we propose a PINN computational framework, combined Radau IIA numerical method with a neural network structure via the attention mechanisms, to directly solve high-index DAEs. Furthermore, we employ a domain decomposition strategy to enhan
    
[^6]: AgentTuning: 为LLMs实现通用代理能力

    AgentTuning: Enabling Generalized Agent Abilities for LLMs. (arXiv:2310.12823v1 [cs.CL])

    [http://arxiv.org/abs/2310.12823](http://arxiv.org/abs/2310.12823)

    本论文提出了AgentTuning，一种简单而通用的方法，可提升LLMs的代理能力，同时保持其通用能力。通过构建AgentInstruct数据集，并采用一种混合训练方法，作者成功地实现了提高LLMs代理能力的目标。

    

    开放的大型语言模型（LLMs）在各种任务中具有出色的性能，极大地推动了LLMs的发展。然而，当它们作为代理在现实世界中应对复杂任务时，它们远不及ChatGPT和GPT-4等商业模型。这些代理任务将LLMs作为负责规划、记忆和工具利用的中央控制器，需要细粒度的提示方法和强大的LLMs才能达到令人满意的性能。虽然已经提出了许多提示方法来完成特定的代理任务，但缺乏研究专注于提高LLMs自身的代理能力而不损害其通用能力。在这项工作中，我们提出了AgentTuning，一种简单而通用的方法，可以提升LLMs的代理能力，同时保持其通用的LLM能力。我们构建了AgentInstruct，一个轻量级的指令调整数据集，其中包含高质量的交互轨迹。

    Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities. In this work, we present AgentTuning, a simple and general method to enhance the agent abilities of LLMs while maintaining their general LLM capabilities. We construct AgentInstruct, a lightweight instruction-tuning dataset containing high-quality interaction trajectories. We employ a hy
    
[^7]: 带有完整性保证的高效规划的混合搜索

    Hybrid Search for Efficient Planning with Completeness Guarantees. (arXiv:2310.12819v1 [cs.AI])

    [http://arxiv.org/abs/2310.12819](http://arxiv.org/abs/2310.12819)

    本论文提出了一种混合搜索方法，用于在离散动作空间中进行高效规划，并保证了完整性。通过在高级搜索中添加低级动作，该方法既具有高级搜索的实际效率，又具有低级搜索的完整性。

    

    在计算机科学中，解决复杂的规划问题一直是一个长期存在的挑战。基于学习的子目标搜索方法在处理这些问题上显示出了很大的潜力，但它们经常缺乏完整性保证，这意味着它们可能无法找到解决方案，即使存在一个解决方案。在本文中，我们提出了一种有效的方法来增强子目标搜索方法，以实现在离散动作空间中的完整性。具体地，我们通过在高级搜索中添加低级动作来执行多层次（混合）搜索，我们称之为完整的子目标搜索。这个解决方案实现了高级搜索的实际效率和低级搜索的完整性的最佳结合。我们将所提出的搜索方法应用于最近提出的子目标搜索算法，并评估使用离线数据训练的算法在复杂的规划问题上的表现。我们证明我们的完整子目标搜索不仅保证了完整性，还可以改进性能。

    Solving complex planning problems has been a long-standing challenge in computer science. Learning-based subgoal search methods have shown promise in tackling these problems, but they often suffer from a lack of completeness guarantees, meaning that they may fail to find a solution even if one exists. In this paper, we propose an efficient approach to augment a subgoal search method to achieve completeness in discrete action spaces. Specifically, we augment the high-level search with low-level actions to execute a multi-level (hybrid) search, which we call complete subgoal search. This solution achieves the best of both worlds: the practical efficiency of high-level search and the completeness of low-level search. We apply the proposed search method to a recently proposed subgoal search algorithm and evaluate the algorithm trained on offline data on complex planning problems. We demonstrate that our complete subgoal search not only guarantees completeness but can even improve performan
    
[^8]: 提升推理效率：释放参数共享的预训练语言模型的能力

    Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models. (arXiv:2310.12818v1 [cs.CL])

    [http://arxiv.org/abs/2310.12818](http://arxiv.org/abs/2310.12818)

    本论文提出了一种提升参数共享预训练语言模型推理效率的简单技术，并介绍了一种简单的预训练方法来实现完全或部分共享的模型，实验结果证明了这些方法在各种模型上的有效性，为更有效地利用参数提供了新的见解。

    

    参数共享的预训练语言模型（PLMs）已经成为在资源有限环境中的成功方法，能够在不显著降低性能的情况下实现模型存储和内存成本的大幅降低。然而，需要注意的是，参数共享不能减轻推理过程中的计算负担，这使得在具有严格时延要求或计算资源受限的情况下，其实用性受到限制。基于神经常微分方程（ODEs），我们引入了一种简单的技术来提高参数共享的PLMs的推理效率。此外，我们提出了一种简单的预训练技术，可以实现完全或部分共享的模型，从而实现更大的推理加速。实验结果表明，我们的方法对于自回归和自编码PLMs都具有很好的效果，为更有效地利用参数提供了新的见解。

    Parameter-shared pre-trained language models (PLMs) have emerged as a successful approach in resource-constrained environments, enabling substantial reductions in model storage and memory costs without significant performance compromise. However, it is important to note that parameter sharing does not alleviate computational burdens associated with inference, thus impeding its practicality in situations characterized by limited stringent latency requirements or computational resources. Building upon neural ordinary differential equations (ODEs), we introduce a straightforward technique to enhance the inference efficiency of parameter-shared PLMs. Additionally, we propose a simple pre-training technique that leads to fully or partially shared models capable of achieving even greater inference acceleration. The experimental results demonstrate the effectiveness of our methods on both autoregressive and autoencoding PLMs, providing novel insights into more efficient utilization of paramet
    
[^9]: 基于场景级监督的点云分割的2D-3D交错Transformer模型

    2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision. (arXiv:2310.12817v1 [cs.CV])

    [http://arxiv.org/abs/2310.12817](http://arxiv.org/abs/2310.12817)

    本文提出了一种基于场景级监督的2D-3D交错Transformer模型，用于弱监督点云分割。该模型通过两个编码器计算2D和3D数据的自注意特征，并通过交替切换查询和键值对的角色，实现了2D和3D特征的融合。

    

    本文提出了一种多模态交错Transformer模型（MIT），用于考虑2D和3D数据进行弱监督点云分割。研究表明，2D和3D特征在点云分割中互补。然而，现有方法需要额外的2D注释来实现2D-3D信息融合。鉴于点云的高注释成本，基于弱监督学习的有效2D和3D特征融合需求非常迫切。为此，我们提出了一个具有两个编码器和一个解码器的Transformer模型，仅使用场景级类标签进行弱监督点云分割。具体而言，两个编码器分别计算3D点云和2D多视图图像的自注意特征。解码器实现交错的2D-3D交叉注意力，并进行隐式2D和3D特征融合。我们在解码器层中交替切换查询和键值对的角色。实验证明，2D和3D特征是互补的。

    We present a Multimodal Interlaced Transformer (MIT) that jointly considers 2D and 3D data for weakly supervised point cloud segmentation. Research studies have shown that 2D and 3D features are complementary for point cloud segmentation. However, existing methods require extra 2D annotations to achieve 2D-3D information fusion. Considering the high annotation cost of point clouds, effective 2D and 3D feature fusion based on weakly supervised learning is in great demand. To this end, we propose a transformer model with two encoders and one decoder for weakly supervised point cloud segmentation using only scene-level class tags. Specifically, the two encoders compute the self-attended features for 3D point clouds and 2D multi-view images, respectively. The decoder implements interlaced 2D-3D cross-attention and carries out implicit 2D and 3D feature fusion. We alternately switch the roles of queries and key-value pairs in the decoder layers. It turns out that the 2D and 3D features are 
    
[^10]: LLM-集成应用中的提示注入攻击和防御

    Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])

    [http://arxiv.org/abs/2310.12815](http://arxiv.org/abs/2310.12815)

    本文提出了一个通用框架来形式化提示注入攻击，并系统化防御这种类型的攻击。

    

    大型语言模型（LLMs）越来越多地用作各种称为LLM-集成应用的实际应用程序的后端。最近的多项研究表明，LLM-集成应用容易受到提示注入攻击的威胁，攻击者可以将恶意指令/数据注入这些应用程序的输入中，以达到攻击者的预期结果。然而，现有的研究仅限于案例研究，缺乏对提示注入攻击及其防御的系统理解。本论文旨在填补这一空白。我们提出了一个通用框架来形式化提示注入攻击，并将研究论文和博客文章中讨论的现有攻击视为我们框架的特例。我们的框架使我们能够通过组合现有攻击设计新的攻击方式。此外，我们还提出了一个系统化提示注入攻击防御的框架。利用我们的框架，我们可以预防和缓解这种类型的攻击。

    Large Language Models (LLMs) are increasingly deployed as the backend for a variety of real-world applications called LLM-Integrated Applications. Multiple recent works showed that LLM-Integrated Applications are vulnerable to prompt injection attacks, in which an attacker injects malicious instruction/data into the input of those applications such that they produce results as the attacker desires. However, existing works are limited to case studies. As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses. We aim to bridge the gap in this work. In particular, we propose a general framework to formalize prompt injection attacks. Existing attacks, which are discussed in research papers and blog posts, are special cases in our framework. Our framework enables us to design a new attack by combining existing attacks. Moreover, we also propose a framework to systematize defenses against prompt injection attacks. Using our frameworks, we con
    
[^11]: 基于不确定性梯度匹配的模型合并

    Model Merging by Uncertainty-Based Gradient Matching. (arXiv:2310.12808v1 [cs.LG])

    [http://arxiv.org/abs/2310.12808](http://arxiv.org/abs/2310.12808)

    本论文通过不确定性梯度匹配的方法，提出了一种新的模型合并方案，该方案能够减少梯度不匹配，从而提高了模型合并的性能并对超参数更具鲁棒性。

    

    在不同数据集上训练的模型可以通过参数的加权平均来合并，但为什么会起作用，什么情况下会失败？在这里，我们将加权平均的不准确性与梯度不匹配联系起来，并提出了一种新的基于不确定性的方案，通过减少不匹配来提高性能。这种联系还揭示了其他方案（如平均值、任务算术和Fisher加权平均）中的隐含假设。我们的新方法在大型语言模型和视觉转换器方面都在性能和超参数鲁棒性方面得到了一致的改进。

    Models trained on different datasets can be merged by a weighted-averaging of their parameters, but why does it work and when can it fail? Here, we connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a new uncertainty-based scheme to improve the performance by reducing the mismatch. The connection also reveals implicit assumptions in other schemes such as averaging, task arithmetic, and Fisher-weighted averaging. Our new method gives consistent improvements for large language models and vision transformers, both in terms of performance and robustness to hyperparameters.
    
[^12]: 一种集体深度学习的有效理论

    An effective theory of collective deep learning. (arXiv:2310.12802v1 [physics.soc-ph])

    [http://arxiv.org/abs/2310.12802](http://arxiv.org/abs/2310.12802)

    通过竞争局部学习和单元之间的扩散耦合，我们引入了一个简化模型，预测了集体学习中的无序-有序-无序相变，并验证了这个理论。

    

    揭示耦合的人工神经网络系统中集体学习的出现是对物理学、机器学习、神经科学和社会学的广泛影响的一项努力。我们引入了一个简化模型，通过考虑各个神经网络单元参数的局部学习动态和单元之间的扩散耦合之间的竞争，将几个最近的分散算法进行了压缩。我们通过一个与具有淬灭随机性的Ginzburg-Landau模型类似的线性网络的有效理论，推导出了我们模型的粗粒化行为。这个框架预测了参数解的（深度依赖的）无序-有序-无序相变，揭示了集体学习相的开始，以及深度引起的临界点延迟和微观学习路径的鲁棒形状。我们在现实中验证了我们的理论。

    Unraveling the emergence of collective learning in systems of coupled artificial neural networks is an endeavor with broader implications for physics, machine learning, neuroscience and society. Here we introduce a minimal model that condenses several recent decentralized algorithms by considering a competition between two terms: the local learning dynamics in the parameters of each neural network unit, and a diffusive coupling among units that tends to homogenize the parameters of the ensemble. We derive the coarse-grained behavior of our model via an effective theory for linear networks that we show is analogous to a deformed Ginzburg-Landau model with quenched disorder. This framework predicts (depth-dependent) disorder-order-disorder phase transitions in the parameters' solutions that reveal the onset of a collective learning phase, along with a depth-induced delay of the critical point and a robust shape of the microscopic learning path. We validate our theory in realistic ensembl
    
[^13]: 探索图神经网络在印度法律判决预测中的应用

    Exploring Graph Neural Networks for Indian Legal Judgment Prediction. (arXiv:2310.12800v1 [cs.LG])

    [http://arxiv.org/abs/2310.12800](http://arxiv.org/abs/2310.12800)

    本研究探索了使用图神经网络来解决印度法律判决预测问题，通过识别司法案件的图结构并进行节点分类，以实现自动化推测案件结果。研究考虑了模型特征、公平性和链接预测任务。

    

    不平衡的法官与案件比例对司法系统产生了繁重的影响，表现为大量积压的未决案件以及持续涌入的新案件。为了解决这个问题并加快司法程序，提出了利用事实证据和过去案件的先例来推测案件结果的自动化系统的建议变得重要。本研究论文侧重于开发基于图神经网络的模型来解决法律判决预测（LJP）问题，识别司法案件的内在图结构，并将其转化为二进制节点分类问题。我们探索了各种嵌入作为模型特征，同时添加和修剪了时间节点和司法行为节点以评估模型的性能。本研究还考虑了这些预测的公平性的伦理维度，考虑了性别和姓名的偏见。还进行了链接预测任务以评估模型对未来案件的熟练程度。

    The burdensome impact of a skewed judges-to-cases ratio on the judicial system manifests in an overwhelming backlog of pending cases alongside an ongoing influx of new ones. To tackle this issue and expedite the judicial process, the proposition of an automated system capable of suggesting case outcomes based on factual evidence and precedent from past cases gains significance. This research paper centres on developing a graph neural network-based model to address the Legal Judgment Prediction (LJP) problem, recognizing the intrinsic graph structure of judicial cases and making it a binary node classification problem. We explored various embeddings as model features, while nodes such as time nodes and judicial acts were added and pruned to evaluate the model's performance. The study is done while considering the ethical dimension of fairness in these predictions, considering gender and name biases. A link prediction task is also conducted to assess the model's proficiency in anticipati
    
[^14]: 存活最有影响力的提示：通过聚类和修剪实现高效的黑盒提示搜索

    Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning. (arXiv:2310.12774v1 [cs.CL])

    [http://arxiv.org/abs/2310.12774](http://arxiv.org/abs/2310.12774)

    本文提出了一种名为ClaPS的简单黑盒搜索方法，通过聚类和修剪搜索空间中最有影响力的提示令牌，解决了现代黑盒方法中的效率问题。

    

    基于提示的学习已经成为大型预训练语言模型（LLM）的有效范例，使得少样本甚至零样本学习成为可能。最近，黑盒提示搜索因其梯度-free优化的独特特性而受到越来越多的关注，被证明在模型即服务的使用中特别有用和强大。然而，组合优化的离散本质和复杂性阻碍了现代黑盒方法的效率。尽管在搜索算法上进行了广泛研究，但搜索空间设计和优化的关键方面却被大部分忽视了。在本文中，我们首先通过提示LLM进行敏感性分析，揭示只有少量的令牌对LLM预测产生了不成比例的影响。利用这一洞见，我们提出了一种名为Clustering and Pruning for Efficient Black-box Prompt Search（ClaPS）的简单黑盒搜索方法，该方法首先对搜索空间进行聚类和修剪，只关注最具影响力的提示令牌。

    Prompt-based learning has been an effective paradigm for large pretrained language models (LLM), enabling few-shot or even zero-shot learning. Black-box prompt search has received growing interest recently for its distinctive properties of gradient-free optimization, proven particularly useful and powerful for model-as-a-service usage. However, the discrete nature and the complexity of combinatorial optimization hinder the efficiency of modern black-box approaches. Despite extensive research on search algorithms, the crucial aspect of search space design and optimization has been largely overlooked. In this paper, we first conduct a sensitivity analysis by prompting LLM, revealing that only a small number of tokens exert a disproportionate amount of influence on LLM predictions. Leveraging this insight, we propose the Clustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple black-box search method that first clusters and prunes the search space to focus exclusivel
    
[^15]: 安全RLHF：从人类反馈中进行安全强化学习

    Safe RLHF: Safe Reinforcement Learning from Human Feedback. (arXiv:2310.12773v1 [cs.AI])

    [http://arxiv.org/abs/2310.12773](http://arxiv.org/abs/2310.12773)

    我们提出了一种名为安全RLHF的算法，用于在大型语言模型的训练过程中平衡性能和安全性。它通过解耦人类偏好，并训练分别的奖励和成本模型，成功解决了有益和无害目标之间的固有张力，并通过动态调整平衡来优化算法性能。

    

    随着大型语言模型（LLM）的发展，平衡AI系统的性能和安全性变得更加关键。然而，LLM训练过程中的有益和无害目标之间的固有张力在很大程度上增加了挑战。为了解决这个问题，我们提出了安全RLHF：一种用于人类价值对齐的新颖算法。安全RLHF明确解耦了关于有益性和无害性的人类偏好，有效避免了众包工作者对张力的困惑，并允许我们训练分别的奖励和成本模型。我们将LLM的安全问题形式化为一个优化任务，即在满足指定成本约束的同时最大化奖励函数。通过利用Lagrangian方法解决这个约束问题，安全RLHF在精调过程中动态调整两个目标之间的平衡。通过三轮使用安全RLHF进行精调，我们得到了一个安全且具有优良性能的AI系统。

    With the development of large language models (LLMs), striking a balance between the performance and safety of AI systems has never been more critical. However, the inherent tension between the objectives of helpfulness and harmlessness presents a significant challenge during LLM training. To address this issue, we propose Safe Reinforcement Learning from Human Feedback (Safe RLHF), a novel algorithm for human value alignment. Safe RLHF explicitly decouples human preferences regarding helpfulness and harmlessness, effectively avoiding the crowdworkers' confusion about the tension and allowing us to train separate reward and cost models. We formalize the safety concern of LLMs as an optimization task of maximizing the reward function while satisfying specified cost constraints. Leveraging the Lagrangian method to solve this constrained problem, Safe RLHF dynamically adjusts the balance between the two objectives during fine-tuning. Through a three-round fine-tuning using Safe RLHF, we d
    
[^16]: SemantIC: 语义干扰消除在6G无线通信中的应用

    SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications. (arXiv:2310.12768v1 [eess.SP])

    [http://arxiv.org/abs/2310.12768](http://arxiv.org/abs/2310.12768)

    本文提出了一种新颖的技术，语义干扰消除（SemantIC），用于提高6G无线通信网络的信息质量。通过在接收器上使用语义自动编码器，SemantIC能够迭代消除信号中的噪声和语义干扰。仿真结果表明，SemantIC能够在不增加额外信道资源成本的情况下改进性能。

    

    本文提出了一种新颖的抗干扰技术，即语义干扰消除（SemantIC），用于提高第六代（6G）无线网络中的信息质量。SemantIC只需要接收器将信道解码器与语义自动编码器连接起来。这构建了一个迭代循环，交替消除信号域和语义域中的噪声。从网络信息论的角度来看，语义自动编码器的神经网络通过训练存储了辅助信息，并在迭代解码中提供辅助信息，作为Wyner-Ziv定理的一种实现。仿真结果验证了SemantIC在不增加额外信道资源成本的情况下改进了性能。

    This letter proposes a novel anti-interference technique, semantic interference cancellation (SemantIC), for enhancing information quality towards the sixth-generation (6G) wireless networks. SemantIC only requires the receiver to concatenate the channel decoder with a semantic auto-encoder. This constructs a turbo loop which iteratively and alternately eliminates noise in the signal domain and the semantic domain. From the viewpoint of network information theory, the neural network of the semantic auto-encoder stores side information by training, and provides side information in iterative decoding, as an implementation of the Wyner-Ziv theorem. Simulation results verify the performance improvement by SemantIC without extra channel resource cost.
    
[^17]: 神经符号化基础上的组合式世界建模

    Neurosymbolic Grounding for Compositional World Models. (arXiv:2310.12690v1 [cs.LG])

    [http://arxiv.org/abs/2310.12690](http://arxiv.org/abs/2310.12690)

    本论文介绍了一种名为Cosmos的框架，用于对象为中心的世界建模，通过使用神经符号化基础和视觉-语言基础模型，实现了在未见过的输入场景上的高性能组合泛化能力。

    

    我们引入了Cosmos，一个针对组合泛化（CG）设计的以对象为中心的世界建模框架，即在通过已知的视觉“原子”组合获得的未见过的输入场景上具有高性能。Cosmos的核心洞察力是使用一种新颖的神经符号化基础。具体来说，该框架引入了两个新工具：（i）神经符号化场景编码，使用神经编码器计算每个场景中的实体的实向量表示，并使用描述实体属性的可组合符号向量，以及（ii）神经符号化注意机制，将这些实体与学习到的交互规则绑定起来。Cosmos是端到端可微分的；此外，与传统的神经符号化方法需要手动将表示映射为符号不同，它使用视觉-语言基础模型计算实体的符号属性。通过对已建立的blocks场景进行两种不同形式的CG评估，我们验证了Cosmos的有效性。

    We introduce Cosmos, a framework for object-centric world modeling that is designed for compositional generalization (CG), i.e., high performance on unseen input scenes obtained through the composition of known visual "atoms." The central insight behind Cosmos is the use of a novel form of neurosymbolic grounding. Specifically, the framework introduces two new tools: (i) neurosymbolic scene encodings, which represent each entity in a scene using a real vector computed using a neural encoder, as well as a vector of composable symbols describing attributes of the entity, and (ii) a neurosymbolic attention mechanism that binds these entities to learned rules of interaction. Cosmos is end-to-end differentiable; also, unlike traditional neurosymbolic methods that require representations to be manually mapped to symbols, it computes an entity's symbolic attributes using vision-language foundation models. Through an evaluation that considers two different forms of CG on an established blocks-
    
[^18]: 使用矩阵因式分解压缩循环神经网络

    Compression of Recurrent Neural Networks using Matrix Factorization. (arXiv:2310.12688v1 [cs.LG])

    [http://arxiv.org/abs/2310.12688](http://arxiv.org/abs/2310.12688)

    本论文提出了一种称为Rank-Tuning的训练后秩选择方法，可以在循环神经网络中高效压缩模型，并在几乎没有性能降低的情况下实现高压缩率。

    

    在实时或嵌入式应用中部署模型时，压缩神经网络是一个关键步骤。使用低秩近似对模型的矩阵进行分解是一种有前途的压缩方法。虽然在训练之前可以设置秩，但这种方法既不灵活也不最优。在这项工作中，我们提出了一种名为Rank-Tuning的训练后秩选择方法，可以为每个矩阵选择不同的秩。结合训练适应性的使用，我们的方法在几乎没有性能降低或者有很少性能降低的情况下实现了高压缩率。我们在信号处理任务上的数值实验结果显示，我们可以将循环神经网络压缩至最多14倍，且相对性能降低最多为1.4%。

    Compressing neural networks is a key step when deploying models for real-time or embedded applications. Factorizing the model's matrices using low-rank approximations is a promising method for achieving compression. While it is possible to set the rank before training, this approach is neither flexible nor optimal. In this work, we propose a post-training rank-selection method called Rank-Tuning that selects a different rank for each matrix. Used in combination with training adaptations, our method achieves high compression rates with no or little performance degradation. Our numerical experiments on signal processing tasks show that we can compress recurrent neural networks up to 14x with at most 1.4% relative performance reduction.
    
[^19]: PSYCHIC: 一个用于知识图谱问答基础的神经符号框架

    PSYCHIC: A Neuro-Symbolic Framework for Knowledge Graph Question-Answering Grounding. (arXiv:2310.12638v1 [cs.AI])

    [http://arxiv.org/abs/2310.12638](http://arxiv.org/abs/2310.12638)

    本论文提出了PSYCHIC，一个基于神经符号框架的知识图谱问答模型，在国际语义网会议的学术问答挑战中取得了较高的分数。

    

    学术问答在链接数据上的问题（Scholarly QALD）是国际语义网会议（ISWC）2023挑战中的两个子任务，我们通过提出一个基于PSYCHIC的神经符号（NS）框架，来回答与知识图谱（KG）相关的问答（KGQA over DBLP）任务。我们的系统在回答问题方面达到了00.18%的F1得分，并在实体链接（EL）方面以71.00%的得分获得第三名。

    The Scholarly Question Answering over Linked Data (Scholarly QALD) at The International Semantic Web Conference (ISWC) 2023 challenge presents two sub-tasks to tackle question answering (QA) over knowledge graphs (KGs). We answer the KGQA over DBLP (DBLP-QUAD) task by proposing a neuro-symbolic (NS) framework based on PSYCHIC, an extractive QA model capable of identifying the query and entities related to a KG question. Our system achieved a F1 score of 00.18% on question answering and came in third place for entity linking (EL) with a score of 71.00%.
    
[^20]: 面向焊接过程的基于深度学习的在线质量预测系统

    Towards a Deep Learning-based Online Quality Prediction System for Welding Processes. (arXiv:2310.12632v1 [cs.LG])

    [http://arxiv.org/abs/2310.12632](http://arxiv.org/abs/2310.12632)

    该论文提出了一个基于深度学习的气体金属电弧焊接预测质量系统的概念，通过收集和管理多传感器数据以及实时处理和特征工程的方式，可以识别关系并预测焊接质量。

    

    制造过程的数字化为机器学习辅助的质量保证提供了有前景的应用。一个广泛应用的制造过程，可以从数据驱动的解决方案中受益匪浅，是气体金属电弧焊接（GMAW）。焊接过程以材料性质、工艺条件和焊接质量之间复杂的因果关系为特征。在频繁更改工艺参数的非实验室环境中，通过破坏性测试准确确定焊缝质量是经济上不可行的。深度学习提供了从工艺观察中识别关系并预测焊接质量的潜力。本文提出了一个基于深度学习的气体金属电弧焊接预测质量系统的概念。核心概念包括由四个主要阶段组成的管线：多传感器数据（如电流和电压）的收集和管理、时间序列的实时处理和特征工程

    The digitization of manufacturing processes enables promising applications for machine learning-assisted quality assurance. A widely used manufacturing process that can strongly benefit from data-driven solutions is \ac{GMAW}. The welding process is characterized by complex cause-effect relationships between material properties, process conditions and weld quality. In non-laboratory environments with frequently changing process parameters, accurate determination of weld quality by destructive testing is economically unfeasible. Deep learning offers the potential to identify the relationships in available process data and predict the weld quality from process observations. In this paper, we present a concept for a deep learning based predictive quality system in \ac{GMAW}. At its core, the concept involves a pipeline consisting of four major phases: collection and management of multi-sensor data (e.g. current and voltage), real-time processing and feature engineering of the time series 
    
[^21]: 使用基于ECG图像的视觉转换模型进行心脏疾病检测

    Heart Disease Detection using Vision-Based Transformer Models from ECG Images. (arXiv:2310.12630v1 [cs.CV])

    [http://arxiv.org/abs/2310.12630](http://arxiv.org/abs/2310.12630)

    本研究提出使用基于ECG图像的视觉转换模型进行心脏疾病检测。心脏疾病是一种常见的医疗条件，早期准确检测对临床实践至关重要。近年来，结合先进技术和计算方法的发展，对心脏疾病检测进行了显著的进展。

    

    心脏疾病，也称为心血管疾病，是一种常见而严重的医疗条件，其特征是心脏和血管的损伤，导致各种并发症，如冠状动脉疾病，心力衰竭和心肌梗死。在临床实践中，及时准确地检测心脏疾病至关重要。早期识别患病风险的个体能够采取积极的干预措施、预防措施和个性化治疗策略，以减轻疾病的进展并降低不良结果。近年来，心脏疾病检测领域在技术和计算方法的集成方面取得了显著的进展。这些包括机器学习算法、数据挖掘技术和预测建模框架，利用大量的临床和生理数据来提高诊断准确性和风险分层。在这项工作中，我们提出使用基于ECG图像的视觉转换模型进行心脏疾病检测。

    Heart disease, also known as cardiovascular disease, is a prevalent and critical medical condition characterized by the impairment of the heart and blood vessels, leading to various complications such as coronary artery disease, heart failure, and myocardial infarction. The timely and accurate detection of heart disease is of paramount importance in clinical practice. Early identification of individuals at risk enables proactive interventions, preventive measures, and personalized treatment strategies to mitigate the progression of the disease and reduce adverse outcomes. In recent years, the field of heart disease detection has witnessed notable advancements due to the integration of sophisticated technologies and computational approaches. These include machine learning algorithms, data mining techniques, and predictive modeling frameworks that leverage vast amounts of clinical and physiological data to improve diagnostic accuracy and risk stratification. In this work, we propose to d
    
[^22]: 跨关注时空上下文变换器用于历史地图的语义分割

    Cross-attention Spatio-temporal Context Transformer for Semantic Segmentation of Historical Maps. (arXiv:2310.12616v1 [cs.CV])

    [http://arxiv.org/abs/2310.12616](http://arxiv.org/abs/2310.12616)

    这篇论文提出了一种基于U-Net的网络，通过使用跨关注的变换器（U-SpaTem）融合时空特征，解决了历史地图语义分割中的数据相关不确定性问题。

    

    在现代地球观测技术诞生之前，历史地图提供了有关地球表面的有用时空信息。为了从地图中提取信息，近年来广受欢迎的神经网络已经取代了手工制作的地图处理方法和繁琐的手工劳动。然而，由于原始地图表面的绘制/扫描/褪色缺陷以及将地图裁剪成小块考虑训练过程的内存限制时所产生的不充分上下文，导致了数据相关的不确定性，挑战模型进行正确预测。由于即使收集更多的训练数据，数据相关的不确定性也不能降低，因此我们认为互补的时空上下文可能会有所帮助。为了实现这一点，我们提出了一个基于U-Net的网络，它使用跨关注的变换器（U-SpaTem）融合时空特征，以在更大的空间范围和时间序列中汇集信息。

    Historical maps provide useful spatio-temporal information on the Earth's surface before modern earth observation techniques came into being. To extract information from maps, neural networks, which gain wide popularity in recent years, have replaced hand-crafted map processing methods and tedious manual labor. However, aleatoric uncertainty, known as data-dependent uncertainty, inherent in the drawing/scanning/fading defects of the original map sheets and inadequate contexts when cropping maps into small tiles considering the memory limits of the training process, challenges the model to make correct predictions. As aleatoric uncertainty cannot be reduced even with more training data collected, we argue that complementary spatio-temporal contexts can be helpful. To achieve this, we propose a U-Net-based network that fuses spatio-temporal features with cross-attention transformers (U-SpaTem), aggregating information at a larger spatial range as well as through a temporal sequence of im
    
[^23]: 识别和调整英文语言模型中负责性别偏见的Transformer组件

    Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model. (arXiv:2310.12611v1 [cs.CL])

    [http://arxiv.org/abs/2310.12611](http://arxiv.org/abs/2310.12611)

    本研究通过三种方法识别英文语言模型中负责性别偏见的Transformer组件，然后使用这些组件进行参数高效的偏见缓解微调，取得了成功的性别偏见缓解效果并减少了对一般语言建模的损害。

    

    语言模型（LMs）展现和放大了许多种不希望从训练数据中学到的偏见，包括性别偏见。然而，我们缺乏有效和高效地改变这种行为而不损害一般语言建模性能的工具。在本文中，我们研究了三种方法来识别LM组件与特定输出之间的因果关系：因果中介分析、自动电路发现和我们的新颖高效的方法DiffMask+，基于差异掩模。我们将这些方法应用于GPT-2 small和性别偏见问题，并使用发现的组件集进行参数高效的偏见缓解微调。我们的结果表明，尽管这些方法的计算要求存在巨大差异，但识别出的组件在很大程度上重叠，并且成功减轻了性别偏见，相比于完整模型微调对一般语言建模的损害较小。然而，我们的工作也强调了一些困难。

    Language models (LMs) exhibit and amplify many types of undesirable biases learned from the training data, including gender bias. However, we lack tools for effectively and efficiently changing this behavior without hurting general language modeling performance. In this paper, we study three methods for identifying causal relations between LM components and particular output: causal mediation analysis, automated circuit discovery and our novel, efficient method called DiffMask+ based on differential masking. We apply the methods to GPT-2 small and the problem of gender bias, and use the discovered sets of components to perform parameter-efficient fine-tuning for bias mitigation. Our results show significant overlap in the identified components (despite huge differences in the computational requirements of the methods) as well as success in mitigating gender bias, with less damage to general language modeling compared to full model fine-tuning. However, our work also underscores the dif
    
[^24]: 使用绝缘体改善热力扩散进行无碰撞运动规划的去噪方法

    Denoising Heat-inspired Diffusion with Insulators for Collision Free Motion Planning. (arXiv:2310.12609v1 [cs.RO])

    [http://arxiv.org/abs/2310.12609](http://arxiv.org/abs/2310.12609)

    本文提出了一种使用绝缘体改善热力扩散进行无碰撞运动规划的去噪方法。该方法通过单一的视觉输入，在推理时能够同时生成可达目标并规划避开障碍物的运动路径，具有稳健性和多模态适应性。

    

    由于其灵活性和多模态性，扩散模型在机器人领域中已经成为一种强大的工具。尽管其中一些方法有效地解决了复杂问题，但它们往往严重依赖于推理时的障碍物检测并需要额外的设备。为了应对这些挑战，我们提出了一种方法，该方法在推理时能够从单一的视觉输入中同时生成可达目标并规划避开障碍物的运动路径。我们的方法的核心是对训练过程中新颖的碰撞避免扩散核进行使用。通过与行为克隆和经典扩散模型进行评估，我们的框架证明了其稳健性。特别是在多模态环境中，它能够导航到目标并避开被障碍物阻挡的不可达目标，同时确保避免碰撞。

    Diffusion models have risen as a powerful tool in robotics due to their flexibility and multi-modality. While some of these methods effectively address complex problems, they often depend heavily on inference-time obstacle detection and require additional equipment. Addressing these challenges, we present a method that, during inference time, simultaneously generates only reachable goals and plans motions that avoid obstacles, all from a single visual input. Central to our approach is the novel use of a collision-avoiding diffusion kernel for training. Through evaluations against behavior-cloning and classical diffusion models, our framework has proven its robustness. It is particularly effective in multi-modal environments, navigating toward goals and avoiding unreachable ones blocked by obstacles, while ensuring collision avoidance.
    
[^25]: 时态敏感问题回答的时态感知表示学习

    Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])

    [http://arxiv.org/abs/2310.12585](http://arxiv.org/abs/2310.12585)

    该论文提出了一种时态感知的问题回答框架，通过引入时间上下文的区间抽取任务和相应的数据生成框架来训练模型，提高了QA模型的时间感知能力，在TimeQA数据集中的F1分数上超过了基准模型达8.5。

    

    时间是现实世界中问题回答的关键因素之一，然而语言模型很难理解时间限定词如“之后”和“之前”与数字之间的关系，因为现有的问题回答数据集中没有足够的时间表达。为了解决这个问题，我们提出了一种时间上下文感知的问题回答框架。我们提出了一种基于时间上下文的区间抽取任务，并构建了一个依赖于时间上下文的数据生成框架用于模型训练。此外，我们提出了一个评估QA模型的时间感知度的度量方法。区间抽取任务包括一个问题和四个句子候选项，根据时间和上下文分类为正确或错误。模型被训练为从在时间和上下文上都正确的句子中提取答案区间。通过使用TCQA训练的模型在TimeQA数据集上的F1分数上优于基准模型达8.5。我们的数据集和代码可在以下链接中获得。

    Time is one of the crucial factors in real-world question answering (QA) problems. However, language models have difficulty understanding the relationships between time specifiers, such as 'after' and 'before', and numbers, since existing QA datasets do not include sufficient time expressions. To address this issue, we propose a Time-Context aware Question Answering (TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE) task, and build a time-context dependent data generation framework for model training. Moreover, we present a metric to evaluate the time awareness of the QA model using TCSE. The TCSE task consists of a question and four sentence candidates classified as correct or incorrect based on time and context. The model is trained to extract the answer span from the sentence that is both correct in time and context. The model trained with TCQA outperforms baseline models up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code are available at
    
[^26]: 使用文本属性异构图进行语言模型的预训练

    Pretraining Language Models with Text-Attributed Heterogeneous Graphs. (arXiv:2310.12580v1 [cs.CL])

    [http://arxiv.org/abs/2310.12580](http://arxiv.org/abs/2310.12580)

    本文提出了一个新的语言模型预训练框架，能够明确考虑到文本属性异构图中的拓扑和异构信息。通过优化语言模型和辅助的异构图神经网络，预测了文本属性异构图中的节点。同时，还设计了一个文本丰富性加权的节点抽样策略，以更好地利用文本信息。

    

    在许多实际场景中（如学术网络、社交平台），不同类型的实体不仅与文本相关，还通过各种关系相连，这可以被抽象为文本属性异构图（Text-Attributed Heterogeneous Graphs，TAHGs）。

    In many real-world scenarios (e.g., academic networks, social platforms), different types of entities are not only associated with texts but also connected by various relationships, which can be abstracted as Text-Attributed Heterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models (LMs) primarily focus on separately learning the textual information of each entity and overlook the crucial aspect of capturing topological connections among entities in TAHGs. In this paper, we present a new pretraining framework for LMs that explicitly considers the topological and heterogeneous information in TAHGs. Firstly, we define a context graph as neighborhoods of a target node within specific orders and propose a topology-aware pretraining task to predict nodes involved in the context graph by jointly optimizing an LM and an auxiliary heterogeneous graph neural network. Secondly, based on the observation that some nodes are text-rich while others have little text, we devise a tex
    
[^27]: Safety-Gymnasion：一个统一的安全强化学习基准

    Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark. (arXiv:2310.12567v1 [cs.AI])

    [http://arxiv.org/abs/2310.12567](http://arxiv.org/abs/2310.12567)

    本文介绍了一个名为Safety-Gymnasium的环境套件，其中包括单个和多个Agent场景中的安全关键任务，并提供了一个包含16种最先进的SafeRL算法的算法库。这个基准旨在促进对安全性能的评估和比较，推动强化学习在安全性能上的发展。

    

    人工智能系统拥有推动社会进步的巨大潜力。然而，它们的部署经常面临严重的安全问题。安全强化学习(SafeRL)作为一种解决方案出现，可以在同时遵守多个约束的情况下优化策略，从而解决集成强化学习在安全关键场景中的挑战。本文介绍了一个名为Safety-Gymnasium的环境套件，包括单个和多个Agent场景中的安全关键任务，并接受向量和仅视觉输入。此外，我们提供了一个名为Safe Policy Optimization（SafePO）的算法库，包含16种最先进的SafeRL算法。这个综合性库可以作为研究社区的验证工具。通过引入这个基准，我们旨在促进对安全性能的评估和比较，从而推动强化学习在安全性能上的发展。

    Artificial intelligence (AI) systems possess significant potential to drive societal progress. However, their deployment often faces obstacles due to substantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a solution to optimize policies while simultaneously adhering to multiple constraints, thereby addressing the challenge of integrating reinforcement learning in safety-critical scenarios. In this paper, we present an environment suite called Safety-Gymnasium, which encompasses safety-critical tasks in both single and multi-agent scenarios, accepting vector and vision-only input. Additionally, we offer a library of algorithms named Safe Policy Optimization (SafePO), comprising 16 state-of-the-art SafeRL algorithms. This comprehensive library can serve as a validation tool for the research community. By introducing this benchmark, we aim to facilitate the evaluation and comparison of safety performance, thus fostering the development of reinforcement learning for s
    
[^28]: DepWiGNN：一种用于多跳空间推理的深度图神经网络

    DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text. (arXiv:2310.12557v1 [cs.CL])

    [http://arxiv.org/abs/2310.12557](http://arxiv.org/abs/2310.12557)

    DepWiGNN是一种用于多跳空间推理的深度图神经网络。它通过设计新颖的节点记忆方案，并在图的深度维度上聚合信息，从而能够收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，DepWiGNN在两个挑战数据集上比传统GNN方法具有更高的准确性。

    

    文本中的空间推理在各种实际应用中起着至关重要的作用。现有的空间推理方法通常从纯文本中推断空间关系，忽视了自然语言与符号结构之间的差距。图神经网络（GNN）在引导和聚合符号结构方面表现出了卓越的能力。然而，传统的GNN在处理多跳空间推理时面临着挑战，由于过度平滑的问题，即随着图层数量的增加，性能显著下降。为了应对这些挑战，我们提出了一种新颖的Depth-Wise Graph Neural Network（DepWiGNN）。具体地，我们设计了一种新颖的节点记忆方案，并在图的深度维度上聚合信息，而不是在广度维度上，这样可以收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，在两个挑战数据集上，DepWiGNN可以以比传统GNN方法更高的准确性进行多跳空间推理。

    Spatial reasoning in text plays a crucial role in various real-world applications. Existing approaches for spatial reasoning typically infer spatial relations from pure text, which overlook the gap between natural language and symbolic structures. Graph neural networks (GNNs) have showcased exceptional proficiency in inducing and aggregating symbolic structures. However, classical GNNs face challenges in handling multi-hop spatial reasoning due to the over-smoothing issue, \textit{i.e.}, the performance decreases substantially as the number of graph layers increases. To cope with these challenges, we propose a novel \textbf{Dep}th-\textbf{Wi}se \textbf{G}raph \textbf{N}eural \textbf{N}etwork (\textbf{DepWiGNN}). Specifically, we design a novel node memory scheme and aggregate the information over the depth dimension instead of the breadth dimension of the graph, which empowers the ability to collect long dependencies without stacking multiple layers. Experimental results on two challen
    
[^29]: 大型语言模型用于多目标进化优化

    Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v1 [cs.NE])

    [http://arxiv.org/abs/2310.12541](http://arxiv.org/abs/2310.12541)

    本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。

    

    多目标进化算法（MOEAs）是解决多目标优化问题（MOPs）的主要方法。在过去几十年中，提出了许多MOEAs，其操作符需要通过领域知识进行精心设计。最近，一些尝试将MOEAs中手动设计的操作符替换为基于学习的操作符（如神经网络模型）已经取得了一些进展。然而，设计和训练这样的模型仍然需要大量的工作，并且学习到的操作符可能不能很好地推广到解决新问题。为了解决上述挑战，本文研究了一种利用强大的大型语言模型（LLM）来设计MOEA操作符的新方法。通过适当的提示工程，我们成功地让一个通用的LLM以零-shot的方式作为分解型MOEA（MOEA/D）的黑盒搜索操作符。此外，通过从LLM行为中学习，我们进一步设计了一个显性的白盒操作符，并提出了...

    Multiobjective evolutionary algorithms (MOEAs) are major methods for solving multiobjective optimization problems (MOPs). Many MOEAs have been proposed in the past decades, of which the operators need carefully handcrafted design with domain knowledge. Recently, some attempts have been made to replace the manually designed operators in MOEAs with learning-based operators (e.g., neural network models). However, much effort is still required for designing and training such models, and the learned operators might not generalize well to solve new problems. To tackle the above challenges, this work investigates a novel approach that leverages the powerful large language model (LLM) to design MOEA operators. With proper prompt engineering, we successfully let a general LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a zero-shot manner. In addition, by learning from the LLM behavior, we further design an explicit white-box operator with randomness and propose
    
[^30]: 测试报告的二分类问题性能分数的一致性

    Testing the Consistency of Performance Scores Reported for Binary Classification Problems. (arXiv:2310.12527v1 [cs.LG])

    [http://arxiv.org/abs/2310.12527](http://arxiv.org/abs/2310.12527)

    这篇论文介绍了一种测试报告的二分类问题性能分数和实验设置一致性的数值方法，该方法不依赖于统计推断。

    

    二分类是机器学习中的一个基本任务，应用范围涵盖各个科学领域。科学家在进行基础研究或优化实际应用时，通常会根据准确率、敏感度和特异度等性能指标评估和排名分类技术。然而，报告的性能得分并不总是可靠的研究排名依据。这可能归因于未公开或非常规的交叉验证实践、排版错误和其他因素。在给定的实验设置中，具有特定数量的阳性和阴性测试项，大多数性能得分可以假设的特定、相互相关的值。在本文中，我们引入了数值技术来评估报告的性能得分的一致性和假设的实验设置。重要的是，所提出的方法不依赖于统计推断，而是使用数值方法来识别不一致的情况。

    Binary classification is a fundamental task in machine learning, with applications spanning various scientific domains. Whether scientists are conducting fundamental research or refining practical applications, they typically assess and rank classification techniques based on performance metrics such as accuracy, sensitivity, and specificity. However, reported performance scores may not always serve as a reliable basis for research ranking. This can be attributed to undisclosed or unconventional practices related to cross-validation, typographical errors, and other factors. In a given experimental setup, with a specific number of positive and negative test items, most performance scores can assume specific, interrelated values. In this paper, we introduce numerical techniques to assess the consistency of reported performance scores and the assumed experimental setup. Importantly, the proposed approach does not rely on statistical inference but uses numerical methods to identify inconsi
    
[^31]: 通过可迁移的对抗攻击实现对齐大型语言模型的自动幻觉评估

    Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks. (arXiv:2310.12516v1 [cs.CL])

    [http://arxiv.org/abs/2310.12516](http://arxiv.org/abs/2310.12516)

    本文提出了一种通过可迁移的对抗攻击在大型语言模型中自动生成评估数据的方法，并使用ChatGPT和Natural Questions（NQ）数据集进行了验证。

    

    尽管在使用指令调整和检索增强技术防止大型语言模型（LLM）的幻觉方面取得了显著进展，但衡量LLM的可靠性仍然具有挑战性，因为人工评估数据对于许多任务和领域来说并不可用且可能存在数据泄漏。受到对抗机器学习的启发，本文旨在开发一种通过适当修改LLM在其中表现忠实的现有数据来自动生成评估数据的方法。具体而言，本文提出了一种基于LLM的框架AutoDebug，使用提示链接来生成以问答示例形式的可迁移对抗攻击。我们希望了解这些示例在多大程度上触发了LLM的幻觉行为。我们使用ChatGPT实现了AutoDebug，并对一个热门的开放领域问答数据集Natural Questions（NQ）的两个变体进行了评估。

    Although remarkable progress has been achieved in preventing large language model (LLM) hallucinations using instruction tuning and retrieval augmentation, it remains challenging to measure the reliability of LLMs using human-crafted evaluation data which is not available for many tasks and domains and could suffer from data leakage. Inspired by adversarial machine learning, this paper aims to develop a method of automatically generating evaluation data by appropriately modifying existing data on which LLMs behave faithfully. Specifically, this paper presents AutoDebug, an LLM-based framework to use prompting chaining to generate transferable adversarial attacks in the form of question-answering examples. We seek to understand the extent to which these examples trigger the hallucination behaviors of LLMs.  We implement AutoDebug using ChatGPT and evaluate the resulting two variants of a popular open-domain question-answering dataset, Natural Questions (NQ), on a collection of open-sour
    
[^32]: SalUn：通过基于梯度的权重显著性增强机器遗忘在图像分类和生成中的效果

    SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation. (arXiv:2310.12508v1 [cs.LG])

    [http://arxiv.org/abs/2310.12508](http://arxiv.org/abs/2310.12508)

    这篇论文提出了一种名为SalUn的机器遗忘方法，通过引入"权重显著性"的概念，将关注点从整个模型引导到具体的模型权重上，提高了遗忘的效果和效率。这是第一个能够有效消除遗忘数据、类别或概念影响的有原则的机器遗忘方法。

    

    随着数据法规的不断发展，机器遗忘（MU）已成为增强当前AI模型的信任和安全性的重要工具。然而，现有的MU方法通常在遗忘精度、稳定性和跨领域适用性方面存在局限。为了解决这些挑战，我们引入了MU中的“权重显著性”概念，借鉴了模型解释中的输入显著性。这一创新将MU的关注点从整个模型引导到了具体的模型权重上，提高了其效果和效率。我们称之为显著性遗忘（SalUn）的方法将其与“精确”遗忘（在删除遗忘数据集后从头开始重新训练模型）的性能差距缩小。据我们所知，SalUn是第一个能够在图像分类和生成中有效消除遗忘数据、类别或概念影响的有原则的MU方法。例如，SalUn可在图片分类和生成任务中擦除遗忘数据、类别或概念。

    With evolving data regulations, machine unlearning (MU) has become an important tool for fostering trust and safety in today's AI models. However, existing MU methods focusing on data and/or weight perspectives often grapple with limitations in unlearning accuracy, stability, and cross-domain applicability. To address these challenges, we introduce the concept of 'weight saliency' in MU, drawing parallels with input saliency in model explanation. This innovation directs MU's attention toward specific model weights rather than the entire model, improving effectiveness and efficiency. The resultant method that we call saliency unlearning (SalUn) narrows the performance gap with 'exact' unlearning (model retraining from scratch after removing the forgetting dataset). To the best of our knowledge, SalUn is the first principled MU approach adaptable enough to effectively erase the influence of forgetting data, classes, or concepts in both image classification and generation. For example, Sa
    
[^33]: 并非所有国家都庆祝感恩节：关于大型语言模型中的文化主导问题

    Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models. (arXiv:2310.12481v1 [cs.CL])

    [http://arxiv.org/abs/2310.12481](http://arxiv.org/abs/2310.12481)

    本文研究了大型语言模型中的文化主导问题，发现由于在模型训练中主要使用英语数据，当用户使用非英语语言提问时，模型往往提供与预期文化不相关的不恰当答案。我们提出了通过多样化数据预训练和文化感知提示两种方法来解决这个问题。

    

    本文针对大型语言模型（LLM）中存在的文化主导问题进行了研究，该问题源于在模型训练中主要使用英语数据（例如ChatGPT）。当用户使用非英语语言提问时，LLMs往往会提供与预期文化不相关的不恰当的英语文化相关答案。为了系统评估文化主导问题，我们构建了一个包含具体文化对象（如假日和歌曲）和抽象文化对象（如价值观和观点）的基准测试集。实证结果表明，代表性的GPT模型存在文化主导问题，其中GPT-4受到最严重影响，而text-davinci-003在这个问题上受影响最小。我们的研究强调了在开发和部署过程中对文化主导问题进行批判性审视和伦理考虑的需要。我们展示了两种直接的方法：模型开发中的多样化数据预训练和部署中的文化感知提示，可以显著缓解文化主导问题。

    In this paper, we identify a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g. ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark that consists of both concrete (e.g. holidays and songs) and abstract (e.g. values and opinions) cultural objects. Empirical results show that the representative GPT models suffer from the culture dominance problem, where GPT-4 is the most affected while text-davinci-003 suffers the least from this problem. Our study emphasizes the need for critical examination of cultural dominance and ethical consideration in their development and deployment. We show two straightforward methods in model development (i.e. pretraining on more diverse data) and deployment (e.g. culture-aware prompting) can signifi
    
[^34]: GRAPE-S: 多个服务集群的近实时联盟形成

    GRAPE-S: Near Real-Time Coalition Formation for Multiple Service Collectives. (arXiv:2310.12480v1 [cs.MA])

    [http://arxiv.org/abs/2310.12480](http://arxiv.org/abs/2310.12480)

    GRAPE-S是一个基于hedonic游戏的联盟形成算法，能在需要分组成百上千台机器人的大规模集群中以近实时的方式生成解决方案。

    

    军事和灾难响应应用的机器人集群需要联盟形成算法将机器人分组为适当的任务团队。集群的任务通常涵盖需要多个高级机器人行为或服务的任务，联盟形成必须予以考虑。高度动态和非结构化的应用领域还要求联盟形成算法能够在几百台机器人的大规模集群中以近乎最优解（即> 95％效用）的方式以近实时（即<5分钟）生成解决方案。没有以前的联盟形成算法满足这些要求。初始评估发现传统的基于拍卖的算法运行时间太长，尽管集中式模拟器中采用的是不太可能在实际部署中发生的理想条件（即机器人之间的同步和完美的即时通信）。 hedonic游戏算法GRAPE可以在近实时中生成解决方案。

    Robotic collectives for military and disaster response applications require coalition formation algorithms to partition robots into appropriate task teams. Collectives' missions will often incorporate tasks that require multiple high-level robot behaviors or services, which coalition formation must accommodate. The highly dynamic and unstructured application domains also necessitate that coalition formation algorithms produce near optimal solutions (i.e., >95% utility) in near real-time (i.e., <5 minutes) with very large collectives (i.e., hundreds of robots). No previous coalition formation algorithm satisfies these requirements. An initial evaluation found that traditional auction-based algorithms' runtimes are too long, even though the centralized simulator incorporated ideal conditions unlikely to occur in real-world deployments (i.e., synchronization across robots and perfect, instantaneous communication). The hedonic game-based GRAPE algorithm can produce solutions in near real-t
    
[^35]: 对语音语言模型的上下文学习进行探索

    An Exploration of In-Context Learning for Speech Language Model. (arXiv:2310.12477v1 [eess.AS])

    [http://arxiv.org/abs/2310.12477](http://arxiv.org/abs/2310.12477)

    本研究是首次探索了在语音处理中利用上下文学习（ICL）的可能性，通过在输入中呈现LM话语-标签示范，语音LM可以在没有文本监督的情况下实现少样本学习，并通过验证了在语音分类任务上进行ICL的可行性。

    

    自从GPT-3在自然语言处理（NLP）领域的发展以来，上下文学习（ICL）在利用大型语言模型（LLMs）方面发挥了重要作用。通过在输入中呈现LM话语-标签示范，LM可以在不依赖梯度下降或要求显式修改参数的情况下实现少样本学习。这使得LM能以黑盒的方式学习和调整。尽管ICL在NLP领域取得了成功，但在语音处理领域，很少有人研究ICL的可能性。本研究首次在没有文本监督的情况下提出了对语音LM的ICL的探索。我们首先证明了当前的语音LM没有ICL的能力。通过提出的热身训练，语音LM因此可以在未知任务上执行ICL。在这项研究中，我们验证了对语音LM在语音分类任务上进行ICL的可行性。

    Ever since the development of GPT-3 in the natural language processing (NLP) field, in-context learning (ICL) has played an important role in utilizing large language models (LLMs). By presenting the LM utterance-label demonstrations at the input, the LM can accomplish few-shot learning without relying on gradient descent or requiring explicit modification of its parameters. This enables the LM to learn and adapt in a black-box manner. Despite the success of ICL in NLP, little work is exploring the possibility of ICL in speech processing. This study proposes the first exploration of ICL with a speech LM without text supervision. We first show that the current speech LM does not have the ICL capability. With the proposed warmup training, the speech LM can, therefore, perform ICL on unseen tasks. In this work, we verify the feasibility of ICL for speech LM on speech classification tasks.
    
[^36]: 情感对话代理: 理解期望和个人影响

    Affective Conversational Agents: Understanding Expectations and Personal Influences. (arXiv:2310.12459v1 [cs.HC])

    [http://arxiv.org/abs/2310.12459](http://arxiv.org/abs/2310.12459)

    该研究调查了745名受访者，研究了情感对话代理的期望和偏好，并发现在人与人的互动、情感支持和创造性任务的场景中，情感能力得到了重视，并受到情绪重新评估和个性特质等因素的影响。

    

    AI对话代理的兴起扩展了在各个领域增强人类能力的机会。随着这些代理的普及，研究不同情感能力对其性能和用户体验的影响变得至关重要。在这项研究中，我们调查了745名受访者，以了解各种应用中对情感技能的期望和偏好。具体而言，我们评估了AI代理在32个不同场景中感知、回应和模拟情绪的偏好。我们的结果表明，人与人的互动、情感支持和创造性任务的场景更受欢迎，受到情绪重新评估和个性特质等因素的影响。总体而言，AI代理所需的情感技能在很大程度上取决于应用的上下文和性质，强调了在情感AI对话代理的设计中需要适应性和上下文感知。

    The rise of AI conversational agents has broadened opportunities to enhance human capabilities across various domains. As these agents become more prevalent, it is crucial to investigate the impact of different affective abilities on their performance and user experience. In this study, we surveyed 745 respondents to understand the expectations and preferences regarding affective skills in various applications. Specifically, we assessed preferences concerning AI agents that can perceive, respond to, and simulate emotions across 32 distinct scenarios. Our results indicate a preference for scenarios that involve human interaction, emotional support, and creative tasks, with influences from factors such as emotional reappraisal and personality traits. Overall, the desired affective skills in AI agents depend largely on the application's context and nature, emphasizing the need for adaptability and context-awareness in the design of affective AI conversational agents.
    
[^37]: 重新思考构建用于理解预训练语言模型机制的有效度量方法

    Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models. (arXiv:2310.12454v1 [cs.CL])

    [http://arxiv.org/abs/2310.12454](http://arxiv.org/abs/2310.12454)

    本研究重新思考了构建用于理解预训练语言模型机制的有效度量方法。通过设计一系列度量方法，并使用树拓扑探针模型对BERT-large进行了实证研究。

    

    预训练语言模型被期望能够有效地将输入文本映射到一组向量，同时保留文本内在的关系。因此，设计一个白盒模型来计算反映这些向量内部关系存在的度量成为分析预训练语言模型后续可解释性的常见方法。然而，在源模型缺乏内在可解释性时，在白盒模型中实现可解释性并保证度量计算的严谨性变得具有挑战性。因此，本文讨论了在这种权衡中寻找平衡的方法，并提出了一种新颖的方法来构建理解预训练语言模型机制的度量方法。我们特别设计了一系列沿这一研究方向的度量方法，并使用这些方法中的树拓扑探针模型对BERT-large进行了测量。

    Pretrained language models are expected to effectively map input text to a set of vectors while preserving the inherent relationships within the text. Consequently, designing a white-box model to compute metrics that reflect the presence of specific internal relations in these vectors has become a common approach for post-hoc interpretability analysis of pretrained language models. However, achieving interpretability in white-box models and ensuring the rigor of metric computation becomes challenging when the source model lacks inherent interpretability. Therefore, in this paper, we discuss striking a balance in this trade-off and propose a novel line to constructing metrics for understanding the mechanisms of pretrained language models. We have specifically designed a family of metrics along this line of investigation, and the model used to compute these metrics is referred to as the tree topological probe. We conducted measurements on BERT-large by using these metrics. Based on the e
    
[^38]: MTS-LOF: 利用遮挡不变特征进行医学时间序列的表示学习

    MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features. (arXiv:2310.12451v1 [cs.LG])

    [http://arxiv.org/abs/2310.12451](http://arxiv.org/abs/2310.12451)

    MTS-LOF是一种利用对比学习和遮挡自编码器方法的医学时间序列表示学习框架，能够为医疗应用提供更复杂、更丰富的上下文表示，并通过多遮挡策略实现了遮挡不变特征的学习。

    

    医学时间序列数据在医疗保健中不可或缺，为疾病诊断、治疗计划和患者管理提供了重要的洞察力。先进的传感器技术带来的数据复杂性的指数增长，使数据标注面临挑战。自监督学习（SSL）已经成为解决这些挑战的一种变革性方法，消除了对广泛人工标注的需求。在本研究中，我们介绍了一种新的医学时间序列表示学习框架，称为MTS-LOF。MTS-LOF利用对比学习和遮挡自编码器（MAE）方法的优势，提供了一种针对医学时间序列数据的独特的表示学习方法。通过结合这些技术，MTS-LOF通过提供更复杂、更丰富的上下文表示，增强了医疗应用的潜力。此外，MTS-LOF采用多遮挡策略，促进了遮挡不变特征的学习。

    Medical time series data are indispensable in healthcare, providing critical insights for disease diagnosis, treatment planning, and patient management. The exponential growth in data complexity, driven by advanced sensor technologies, has presented challenges related to data labeling. Self-supervised learning (SSL) has emerged as a transformative approach to address these challenges, eliminating the need for extensive human annotation. In this study, we introduce a novel framework for Medical Time Series Representation Learning, known as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and Masked Autoencoder (MAE) methods, offering a unique approach to representation learning for medical time series data. By combining these techniques, MTS-LOF enhances the potential of healthcare applications by providing more sophisticated, context-rich representations. Additionally, MTS-LOF employs a multi-masking strategy to facilitate occlusion-invariant feature learning. This appr
    
[^39]: 了解何处前往：使LLM成为一个相关、负责任且可信赖的搜索器。

    Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher. (arXiv:2310.12443v1 [cs.IR])

    [http://arxiv.org/abs/2310.12443](http://arxiv.org/abs/2310.12443)

    该论文提出了一种新颖的生成检索框架，旨在将LLM转变为一个相关、负责任且可信赖的搜索器。该框架包括生成器、验证器和优化器三个核心模块，分别用于生成可信赖的在线来源、验证来源可靠性和优化不可信赖的来源。通过广泛的实验证明了该方法相对于其他方法在相关性、负责任性和可信度方面的优势。

    

    大型语言模型（LLMs）的出现已经显示出它在提高搜索相关性和提供直接答案方面的潜力。然而，由于传统信息检索算法的局限性和LLM的错觉问题，验证生成结果的可靠性和贡献来源的可信度是一个挑战。为了创建LLM时代的“PageRank”，我们致力于将LLM转变为一个相关、负责任且可信赖的搜索器。我们提出了一个新颖的生成检索框架，利用LLM的知识建立查询和在线来源之间的直接链接。该框架包括三个核心模块：生成器、验证器和优化器，分别专注于生成可信赖的在线来源、验证来源的可靠性和优化不可信赖的来源。广泛的实验证明了我们方法在相关性、负责任性和可信度方面相对于各种SOTA方法的优势。

    The advent of Large Language Models (LLMs) has shown the potential to improve relevance and provide direct answers in web searches. However, challenges arise in validating the reliability of generated results and the credibility of contributing sources, due to the limitations of traditional information retrieval algorithms and the LLM hallucination problem. Aiming to create a "PageRank" for the LLM era, we strive to transform LLM into a relevant, responsible, and trustworthy searcher. We propose a novel generative retrieval framework leveraging the knowledge of LLMs to foster a direct link between queries and online sources. This framework consists of three core modules: Generator, Validator, and Optimizer, each focusing on generating trustworthy online sources, verifying source reliability, and refining unreliable sources, respectively. Extensive experiments and evaluations highlight our method's superior relevance, responsibility, and trustfulness against various SOTA methods.
    
[^40]: PoisonPrompt: 基于提示的大型语言模型的后门攻击

    PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models. (arXiv:2310.12439v1 [cs.CL])

    [http://arxiv.org/abs/2310.12439](http://arxiv.org/abs/2310.12439)

    PoisonPrompt是一种新的后门攻击方法，能够成功地破坏基于提示的大型语言模型，该攻击方法的有效性、保真度和鲁棒性经过了广泛实验验证，强调了基于提示的语言模型面临的安全威胁和进一步研究的必要性。

    

    最近，提示显著改善了预训练大型语言模型（LLM）在各种下游任务上的性能，使得它们在各种LLM应用场景中变得越来越不可或缺。然而，对于基于提示的LLM而言，后门漏洞——一种可以恶意更改受害模型正常预测的严重安全威胁——尚未得到充分的探索。本文提出了一种新颖的后门攻击POISONPROMPT，能够成功地破坏硬件和软件基于提示的LLM。我们通过对三种流行的提示方法、六个数据集和三种广泛使用的LLM进行广泛实验来评估POISONPROMPT的有效性、保真度和鲁棒性。我们的研究结果强调了基于提示的LLM受到后门攻击的潜在安全威胁，并强调了在这个领域需要进一步研究的必要性。

    Prompts have significantly improved the performance of pretrained Large Language Models (LLMs) on various downstream tasks recently, making them increasingly indispensable for a diverse range of LLM application scenarios. However, the backdoor vulnerability, a serious security threat that can maliciously alter the victim model's normal predictions, has not been sufficiently explored for prompt-based LLMs. In this paper, we present POISONPROMPT, a novel backdoor attack capable of successfully compromising both hard and soft prompt-based LLMs. We evaluate the effectiveness, fidelity, and robustness of POISONPROMPT through extensive experiments on three popular prompt methods, using six datasets and three widely used LLMs. Our findings highlight the potential security threats posed by backdoor attacks on prompt-based LLMs and emphasize the need for further research in this area.
    
[^41]: 实现随机森林的局部可解释性增强：基于邻近性的方法

    Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])

    [http://arxiv.org/abs/2310.12428](http://arxiv.org/abs/2310.12428)

    这项研究提出了一种利用随机森林模型的特征空间中的邻近性来解释模型预测的方法，为模型预测提供了局部的解释性，与现有方法相辅相成。通过实验证明了这种方法在债券定价模型中的有效性。

    

    我们提出一种新的方法来解释随机森林（RF）模型的样本外性能，利用了任何RF都可以被表述为自适应加权K最近邻（KNN）模型的事实。具体而言，我们利用RF在特征空间中学到的点之间的邻近性，将随机森林的预测重写为训练数据点目标标签的加权平均值。这种线性性质有助于在训练集观测中为任何模型预测生成属性，从而为RF预测提供了局部的解释性，补充了SHAP等已有方法，这些方法则为特征空间维度上的模型预测生成属性。我们在训练于美国公司债券交易数据的债券定价模型中演示了这种方法，并将其与各种现有的模型解释方法进行了比较。

    We initiate a novel approach to explain the out of sample performance of random forest (RF) models by exploiting the fact that any RF can be formulated as an adaptive weighted K nearest-neighbors model. Specifically, we use the proximity between points in the feature space learned by the RF to re-write random forest predictions exactly as a weighted average of the target labels of training data points. This linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established methods like SHAP, which instead generates attributions for a model prediction across dimensions of the feature space. We demonstrate this approach in the context of a bond pricing model trained on US corporate bond trades, and compare our approach to various existing approaches to model explainability.
    
[^42]: MAF: 多方面反馈以改善大型语言模型的推理能力

    MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models. (arXiv:2310.12426v1 [cs.CL])

    [http://arxiv.org/abs/2310.12426](http://arxiv.org/abs/2310.12426)

    本研究提出了一种多方面反馈的迭代优化框架，该框架包括冻结的语言模型和外部工具模块，每个模块都专注于特定的错误类型。实验证明该方法改善了大型语言模型在推理任务中的性能，相对提升了多达20%。

    

    语言模型在各种自然语言任务中展现出了令人印象深刻的性能。然而，在涉及自然语言推理的情况下，语言模型仍然面临诸如幻觉，生成错误的中间推理步骤和数学错误等挑战。最近的研究集中在通过反馈自我改进来增强语言模型。然而，现有的方法仅依赖于单一的通用反馈来源，无法解决语言模型生成的推理链中的多样错误类型。在这项工作中，我们提出了多方面反馈，这是一个集成了多个反馈模块的迭代优化框架，其中包括冻结的语言模型和外部工具，每个模块都专注于特定的错误类别。我们的实验证明了我们的方法在解决语言模型生成的推理链中的几个错误方面的有效性，从而改善了语言模型在几个推理任务中的整体性能。我们看到了在数学推理任务中相对提升了多达20%。

    Language Models (LMs) have shown impressive performance in various natural language tasks. However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors. Recent research has focused on enhancing LMs through self-improvement using feedback. Nevertheless, existing approaches relying on a single generic feedback source fail to address the diverse error types found in LM-generated reasoning chains. In this work, we propose Multi-Aspect Feedback, an iterative refinement framework that integrates multiple feedback modules, including frozen LMs and external tools, each focusing on a specific error category. Our experimental results demonstrate the efficacy of our approach to addressing several errors in the LM-generated reasoning chain and thus improving the overall performance of an LM in several reasoning tasks. We see a relative improvement of up to 20% in Mathematical
    
[^43]: 大语言模型时代下的声明式软件规范自动修复

    Automated Repair of Declarative Software Specifications in the Era of Large Language Models. (arXiv:2310.12425v1 [cs.SE])

    [http://arxiv.org/abs/2310.12425](http://arxiv.org/abs/2310.12425)

    大语言模型时代下，自动修复声明式软件规范的有效技术需求愈发突出。该研究评估了利用ChatGPT修复Alloy声明式语言规范的效果，并探索了大型语言模型在此自动修复过程中的机会。

    

    声明式软件规范语言的广泛采用以及其在调试方面的困难性，凸显了对适用于此类语言的有效自动化修复技术的需求。研究人员最近探索了各种方法来自动修复声明式软件规范，如基于模板的修复、反馈驱动的迭代修复和有界穷举方法。大型语言模型的最新发展为自动修复声明式规范提供了新机会。在这项研究中，我们评估了利用OpenAI的ChatGPT修复用Alloy声明式语言编写的软件规范的效果。与命令式语言不同，Alloy中的规范不会被执行，而是被转换为逻辑公式，并使用后端约束求解器进行评估，以识别规范实例和断言的反例。我们的评估重点是ChatGPT在改进声明式规范修复能力方面的能力。

    The growing adoption of declarative software specification languages, coupled with their inherent difficulty in debugging, has underscored the need for effective and automated repair techniques applicable to such languages. Researchers have recently explored various methods to automatically repair declarative software specifications, such as template-based repair, feedback-driven iterative repair, and bounded exhaustive approaches. The latest developments in large language models provide new opportunities for the automatic repair of declarative specifications. In this study, we assess the effectiveness of utilizing OpenAI's ChatGPT to repair software specifications written in the Alloy declarative language. Unlike imperative languages, specifications in Alloy are not executed but rather translated into logical formulas and evaluated using backend constraint solvers to identify specification instances and counterexamples to assertions. Our evaluation focuses on ChatGPT's ability to impr
    
[^44]: 通过梯度特征学习证明神经网络的可靠性

    Provable Guarantees for Neural Networks via Gradient Feature Learning. (arXiv:2310.12408v1 [cs.LG])

    [http://arxiv.org/abs/2310.12408](http://arxiv.org/abs/2310.12408)

    本研究提出了一个针对梯度特征学习的统一分析框架，证明了双层神经网络在训练过程中的可靠性，并在多个典型问题上展示了其有效性和有趣的学习现象。

    

    神经网络在实践中取得了显著的表现，但目前的理论分析不足以理解其成功，例如神经切线核方法无法捕捉到其关键的特征学习能力，而最近对特征学习的分析通常是问题特定的。本研究提出了一个统一的分析框架，针对由梯度下降训练的双层网络。该框架以梯度特征学习原理为核心，并通过在几个典型问题中的应用来证明其有效性，例如高斯混合和奇偶函数。该框架还揭示了有趣的网络学习现象，如超越核的特征学习和彩票票据假设。

    Neural networks have achieved remarkable empirical performance, while the current theoretical analysis is not adequate for understanding their success, e.g., the Neural Tangent Kernel approach fails to capture their key feature learning ability, while recent analyses on feature learning are typically problem-specific. This work proposes a unified analysis framework for two-layer networks trained by gradient descent. The framework is centered around the principle of feature learning from gradients, and its effectiveness is demonstrated by applications in several prototypical problems, such as mixtures of Gaussians and parity functions. The framework also sheds light on interesting network learning phenomena such as feature learning beyond kernels and the lottery ticket hypothesis.
    
[^45]: 利用神经增强的消息传递实现分类辅助的鲁棒多目标跟踪

    Classification-Aided Robust Multiple Target Tracking Using Neural Enhanced Message Passing. (arXiv:2310.12407v1 [cs.LG])

    [http://arxiv.org/abs/2310.12407](http://arxiv.org/abs/2310.12407)

    本文提出了一种利用神经增强的方法进行分类辅助的鲁棒多目标跟踪，在强杂波环境中利用雷达传感器的测量信息来增强杂波剔除和数据关联，从而提高目标跟踪的鲁棒性。

    

    本文解决了在强杂波环境中利用雷达传感器测量对未知数量目标的跟踪挑战。通过利用距离-多普勒谱信息，我们识别出测量类别，这可以作为额外信息增强杂波剔除和数据关联，从而增强目标跟踪的鲁棒性。我们首先引入了一种新颖的神经增强的消息传递方法，其中通过统一的消息传递获得的信念被输入到神经网络中作为额外信息。然后利用输出的信念来优化原始信念。接着，我们提出了一种分类辅助的鲁棒多目标跟踪算法，利用神经增强的消息传递技术。该算法由三个模块组成：消息传递模块，神经网络模块和Dempster-Shafer模块。消息传递模块用于通过因子图表示统计模型，并推断目标运动状态。

    We address the challenge of tracking an unknown number of targets in strong clutter environments using measurements from a radar sensor. Leveraging the range-Doppler spectra information, we identify the measurement classes, which serve as additional information to enhance clutter rejection and data association, thus bolstering the robustness of target tracking. We first introduce a novel neural enhanced message passing approach, where the beliefs obtained by the unified message passing are fed into the neural network as additional information. The output beliefs are then utilized to refine the original beliefs. Then, we propose a classification-aided robust multiple target tracking algorithm, employing the neural enhanced message passing technique. This algorithm is comprised of three modules: a message-passing module, a neural network module, and a Dempster-Shafer module. The message-passing module is used to represent the statistical model by the factor graph and infers target kinema
    
[^46]: GPT-4并不知道它错了：对迭代提示在推理问题中的分析

    GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems. (arXiv:2310.12397v1 [cs.AI])

    [http://arxiv.org/abs/2310.12397](http://arxiv.org/abs/2310.12397)

    本文研究了在推理问题中使用迭代提示的有效性，以解决图着色问题。通过实证研究发现，GPT-4的迭代自我批评和外部正确推理器验证对最终结果有实际影响。

    

    关于大型语言模型（LLM）的推理能力存在许多意见分歧。尽管最初对于推理能够随着规模自动产生的乐观主义被一系列反例所抑制，但人们普遍相信它们具有迭代自我批评能力。本文系统地调查了在图着色的上下文中对LLM的迭代提示的有效性，这是一个与命题可满足性以及实践问题（如调度和分配）相关的经典NP完全推理问题。我们通过对GPT4在解决图着色实例或验证候选着色的正确性中的表现进行了有原则的实证研究。在迭代模式下，我们尝试了模型批评自己的答案以及外部的正确推理器验证提出的解决方案。在两种情况下，我们分析了批评的内容是否实际影响了最终结果。

    There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples, a wide spread belief in their iterative self-critique capabilities persists. In this paper, we set out to systematically investigate the effectiveness of iterative prompting of LLMs in the context of Graph Coloring, a canonical NP-complete reasoning problem that is related to propositional satisfiability as well as practical problems like scheduling and allocation. We present a principled empirical study of the performance of GPT4 in solving graph coloring instances or verifying the correctness of candidate colorings. In iterative modes, we experiment with the model critiquing its own answers and an external correct reasoner verifying proposed solutions. In both cases, we analyze whether the content of the criticisms actually affects bottom line
    
[^47]: 使用Transformer学习解决气候传感器布放问题

    Learning to Solve Climate Sensor Placement Problems with a Transformer. (arXiv:2310.12387v1 [cs.LG])

    [http://arxiv.org/abs/2310.12387](http://arxiv.org/abs/2310.12387)

    本文介绍了一种使用深度强化学习方法学习改进传感器布放策略的新方法，通过与其他方法的对比实验证明了该方法在产生高质量解决方案方面的有效性和优越性。

    

    由于其NP难性质，环境监测和灾害管理中的传感器布放优化是一个具有挑战性的问题。传统的传感器布放方法包括精确、近似或启发式方法，其中启发式方法是最常用的。然而，启发式方法受到专家直觉和经验的限制。深度学习（DL）已经成为自动生成启发式算法的一种有前景的方法。本文介绍了一种新颖的传感器布放方法，重点是使用深度强化学习（RL）方法学习改进的启发式算法。我们的方法利用了一个强化学习公式来学习改进的启发式算法，通过演员-评论家算法训练策略网络。我们通过进行全面的实验将我们的方法与几种最先进的方法进行比较，证明了我们提出的方法在产生高质量解决方案方面的有效性和优越性。我们的工作提出了一种有前景的方法，用于解决气候传感器布放问题。

    The optimal placement of sensors for environmental monitoring and disaster management is a challenging problem due to its NP-hard nature. Traditional methods for sensor placement involve exact, approximation, or heuristic approaches, with the latter being the most widely used. However, heuristic methods are limited by expert intuition and experience. Deep learning (DL) has emerged as a promising approach for generating heuristic algorithms automatically. In this paper, we introduce a novel sensor placement approach focused on learning improvement heuristics using deep reinforcement learning (RL) methods. Our approach leverages an RL formulation for learning improvement heuristics, driven by an actor-critic algorithm for training the policy network. We compare our method with several state-of-the-art approaches by conducting comprehensive experiments, demonstrating the effectiveness and superiority of our proposed approach in producing high-quality solutions. Our work presents a promisi
    
[^48]: 在认知层次中的在线学习与规划

    Online Learning and Planning in Cognitive Hierarchies. (arXiv:2310.12386v1 [cs.AI])

    [http://arxiv.org/abs/2310.12386](http://arxiv.org/abs/2310.12386)

    本研究扩展了一个形式化框架，用于模拟机器人系统的复杂集成推理行为，并实现了在线学习与规划。新的框架还允许更灵活地建模不同推理组件之间的交互。

    

    复杂的机器人行为通常需要整合多种机器人和人工智能技术和组件。在保证全局性质和行为的同时，将这些不同的组件整合成一个连贯的系统是认知机器人学面临的重大挑战。使用形式化框架来建模组件之间的交互可以是应对这一挑战的重要步骤。在本文中，我们扩展了一个已有的形式化框架[Clark et al., 2016]，以模拟机器人系统的复杂集成推理行为；从符号规划到在线学习策略和转换系统。此外，新的框架允许更灵活地建模不同推理组件之间的交互。

    Complex robot behaviour typically requires the integration of multiple robotic and Artificial Intelligence (AI) techniques and components. Integrating such disparate components into a coherent system, while also ensuring global properties and behaviours, is a significant challenge for cognitive robotics. Using a formal framework to model the interactions between components can be an important step in dealing with this challenge. In this paper we extend an existing formal framework [Clark et al., 2016] to model complex integrated reasoning behaviours of robotic systems; from symbolic planning through to online learning of policies and transition systems. Furthermore the new framework allows for a more flexible modelling of the interactions between different reasoning components.
    
[^49]: 用关系嵌入链解决困难的类比问题

    Solving Hard Analogy Questions with Relation Embedding Chains. (arXiv:2310.12379v1 [cs.CL])

    [http://arxiv.org/abs/2310.12379](http://arxiv.org/abs/2310.12379)

    本文提出了一种解决困难的类比问题的方法，通过将关系建模为路径并关联其边缘与关系嵌入，以获得合适的中间词和有信息量的关系嵌入，从而结合了知识图谱和关系嵌入的优势。

    

    在词汇语义学中，建模概念之间的关系是一个核心主题。一个常见策略是依赖于知识图谱（KGs）如ConceptNet，并将两个概念之间的关系建模为一组路径。然而，KGs仅限于固定的关系类型，不完整并且通常嘈杂。另一个策略是从微调的语言模型中提炼关系嵌入。然而，对于只间接相关的词来说，这种方法不太适用，并且不容易将结构化领域知识整合进来。在本文中，我们旨在结合两者的优点。我们将关系建模为路径，但将其边缘与关系嵌入相关联。首先，通过识别合适的中间词语来获取路径，然后选择那些可以获得有信息量的关系嵌入的词语。我们经验证明，我们提出的表示方法对于解决困难的类比问题是有用的。

    Modelling how concepts are related is a central topic in Lexical Semantics. A common strategy is to rely on knowledge graphs (KGs) such as ConceptNet, and to model the relation between two concepts as a set of paths. However, KGs are limited to a fixed set of relation types, and they are incomplete and often noisy. Another strategy is to distill relation embeddings from a fine-tuned language model. However, this is less suitable for words that are only indirectly related and it does not readily allow us to incorporate structured domain knowledge. In this paper, we aim to combine the best of both worlds. We model relations as paths but associate their edges with relation embeddings. The paths are obtained by first identifying suitable intermediate words and then selecting those words for which informative relation embeddings can be obtained. We empirically show that our proposed representations are useful for solving hard analogy questions.
    
[^50]: ClusT3:信息不变的测试时间训练

    ClusT3: Information Invariant Test-Time Training. (arXiv:2310.12345v1 [cs.CV])

    [http://arxiv.org/abs/2310.12345](http://arxiv.org/abs/2310.12345)

    ClusT3是一种新颖的无监督测试时间训练方法，通过最大化多尺度特征图和离散潜在表示之间的互信息来增强深度学习模型的鲁棒性。实验结果表明，在不同的测试时间自适应基准上具有竞争性的分类性能。

    

    深度学习模型在各种视觉任务中展现出了显著的性能。然而，它们在测试时间经常受到域偏移的影响。为了减轻这些漏洞，已经开发了测试时间训练（TTT）方法，其中在训练时同时解决了一个次要任务和主任务，并在测试时作为自监督的代理任务使用。在本研究中，我们提出了一种基于多尺度特征图和离散潜在表示之间的互信息最大化的新颖无监督TTT技术，该技术可以作为辅助聚类任务集成到标准训练中。实验结果表明，在不同的常见测试时间自适应基准上具有竞争性的分类性能。

    Deep Learning models have shown remarkable performance in a broad range of vision tasks. However, they are often vulnerable against domain shifts at test-time. Test-time training (TTT) methods have been developed in an attempt to mitigate these vulnerabilities, where a secondary task is solved at training time simultaneously with the main task, to be later used as an self-supervised proxy task at test-time. In this work, we propose a novel unsupervised TTT technique based on the maximization of Mutual Information between multi-scale feature maps and a discrete latent representation, which can be integrated to the standard training as an auxiliary clustering task. Experimental results demonstrate competitive classification performance on different popular test-time adaptation benchmarks.
    
[^51]: 通过推理与规划消除推理：一种引导LLMs非线性思维的新框架

    Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs' Non-linear Thinking. (arXiv:2310.12342v1 [cs.CL])

    [http://arxiv.org/abs/2310.12342](http://arxiv.org/abs/2310.12342)

    本文提出了一种名为推断性排除提示（IEP）的新框架，通过结合排除和推理的原则，引导LLM进行非线性思考。IEP通过规划和自然语言推理，可以模拟复杂的人类思维过程，比其他方法具有更广泛的视角。

    

    Thought Chain（CoT）提示及其变体通过模拟人类线性认知和逻辑，探索为大型语言模型（LLM）装备高级推理能力。然而，人类思维复杂且混合线性和非线性思维。在这项工作中，我们提出了一种新的提示方式，称为推断性排除提示（IEP），它结合了排除和推理的原则，以引导LLM进行非线性思考。IEP指导LLM进行规划，并利用自然语言推理（NLI）推断每个可能解与上下文、常识或事实的推理关系，从而通过回溯推理获得更广泛的视角。相比其他基于CoT的方法，IEP的前向规划和后向排除过程更好地模拟了复杂的人类思维过程，后者仅反映线性认知过程。我们进行了一系列的实证研究，并验证了IEP的优势。

    Chain-of-Thought(CoT) prompting and its variants explore equipping large language models (LLMs) with high-level reasoning abilities by emulating human-like linear cognition and logic. However, the human mind is complicated and mixed with both linear and nonlinear thinking. In this work, we propose \textbf{I}nferential \textbf{E}xclusion \textbf{P}rompting (IEP), a novel prompting that combines the principles of elimination and inference in order to guide LLMs to think non-linearly. IEP guides LLMs to plan and then utilize Natural Language Inference (NLI) to deduce each possible solution's entailment relation with context, commonsense, or facts, therefore yielding a broader perspective by thinking back for inferring. This forward planning and backward eliminating process allows IEP to better simulate the complex human thinking processes compared to other CoT-based methods, which only reflect linear cognitive processes. We conducted a series of empirical studies and have corroborated tha
    
[^52]: 通过平衡教师和研究者的激励，探索适应性实验促进持续改进的机会

    Opportunities for Adaptive Experiments to Enable Continuous Improvement that Trades-off Instructor and Researcher Incentives. (arXiv:2310.12324v1 [cs.HC])

    [http://arxiv.org/abs/2310.12324](http://arxiv.org/abs/2310.12324)

    适应性实验为持续课程改进提供了机会，通过动态部署最有效的条件以满足学生需求。

    

    随机实验比较不同教学策略的机会可以为教师的决策提供有用的经验证据。然而，传统实验缺乏清晰简明的使用数据快速增加实验学生获得最佳条件机会的途径。受领先科技公司在产品开发中使用机器学习和实验的启示，我们探讨了如何利用适应性实验来持续改进课程。在适应性实验中，不同的条件将被应用于学生身上，数据将被分析并用于改变未来学生的学习体验。可以使用机器学习算法来识别哪些行动可以更有希望改善学生的体验或结果。然后，该算法可以动态地将最有效的条件应用于未来的学生，从而更好地满足学生的需求。我们通过实例说明了这种方法的应用。

    Randomized experimental comparisons of alternative pedagogical strategies could provide useful empirical evidence in instructors' decision-making. However, traditional experiments do not have a clear and simple pathway to using data rapidly to try to increase the chances that students in an experiment get the best conditions. Drawing inspiration from the use of machine learning and experimentation in product development at leading technology companies, we explore how adaptive experimentation might help in continuous course improvement. In adaptive experiments, as different arms/conditions are deployed to students, data is analyzed and used to change the experience for future students. This can be done using machine learning algorithms to identify which actions are more promising for improving student experience or outcomes. This algorithm can then dynamically deploy the most effective conditions to future students, resulting in better support for students' needs. We illustrate the appr
    
[^53]: The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis.

    The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis. (arXiv:2310.12318v1 [cs.CL])

    [http://arxiv.org/abs/2310.12318](http://arxiv.org/abs/2310.12318)

    这项研究通过调查189篇论文，批判性地研究了情感分析在社会技术系统中的应用，揭示了对情感的不同概念化，并提出了一个伦理表格来解决情感分析中的公平利用问题。

    

    我们通过批判性地研究189篇同行评审的论文，对情感分析（SA）的应用、模型和数据集进行了调查，以探究情感分析的社会技术方面。我们的研究来源于对情感分析在不同社会技术系统中成为重要组成部分的认识，并对社会学和技术文献中的情感概念进行了深入研究。我们的研究揭示了金融、政府和医疗等领域对情感的不同概念化。我们的研究还发现在情感的定义和框架方面存在明确不足，可能导致挑战和偏见。为解决这个问题，我们提出了一个涵盖关键问题的伦理表格，以指导从业者确保情感分析的公平利用。我们的研究强调了采用跨学科方法来定义情感分析的重要性，并提供了一个实用的解决方案来实施情感分析。

    We conduct an inquiry into the sociotechnical aspects of sentiment analysis (SA) by critically examining 189 peer-reviewed papers on their applications, models, and datasets. Our investigation stems from the recognition that SA has become an integral component of diverse sociotechnical systems, exerting influence on both social and technical users. By delving into sociological and technological literature on sentiment, we unveil distinct conceptualizations of this term in domains such as finance, government, and medicine. Our study exposes a lack of explicit definitions and frameworks for characterizing sentiment, resulting in potential challenges and biases. To tackle this issue, we propose an ethics sheet encompassing critical inquiries to guide practitioners in ensuring equitable utilization of SA. Our findings underscore the significance of adopting an interdisciplinary approach to defining sentiment in SA and offer a pragmatic solution for its implementation.
    
[^54]: 一种统一的学习论证语义的框架

    A Unifying Framework for Learning Argumentation Semantics. (arXiv:2310.12309v1 [cs.AI])

    [http://arxiv.org/abs/2310.12309](http://arxiv.org/abs/2310.12309)

    本文提出了一种统一的框架来学习论证语义，通过使用可解释的方法，优于现有的论证求解器，并在形式论证和人机对话领域开辟了新的研究方向。

    

    论证是人工智能领域的一个非常活跃的研究领域，涉及到在人与人或人与人工智能代理之间的对话中所使用的论证的表示和评估。正式论证系统的可接受性语义定义了论证的接受或拒绝的标准。已经开发了一些称为论证求解器的软件系统，用于使用这些标准计算被接受/被拒绝的论证。其中一些系统通过使用不可解释的方法来学习识别接受的论证。在本文中，我们提出了一种新颖的框架，该框架采用归纳逻辑编程方法以可解释的方式来学习多个抽象和结构化论证框架的可接受性语义。通过实证评估，我们展示了我们的框架优于现有的论证求解器，从而开辟了形式论证和人机对话领域的新的未来研究方向。

    Argumentation is a very active research field of Artificial Intelligence concerned with the representation and evaluation of arguments used in dialogues between humans and/or artificial agents. Acceptability semantics of formal argumentation systems define the criteria for the acceptance or rejection of arguments. Several software systems, known as argumentation solvers, have been developed to compute the accepted/rejected arguments using such criteria. These include systems that learn to identify the accepted arguments using non-interpretable methods. In this paper we present a novel framework, which uses an Inductive Logic Programming approach to learn the acceptability semantics for several abstract and structured argumentation frameworks in an interpretable way. Through an empirical evaluation we show that our framework outperforms existing argumentation solvers, thus opening up new future research directions in the area of formal argumentation and human-machine dialogues.
    
[^55]: 分子语言模型的偏好优化

    Preference Optimization for Molecular Language Models. (arXiv:2310.12304v1 [stat.ML])

    [http://arxiv.org/abs/2310.12304](http://arxiv.org/abs/2310.12304)

    本研究调查了使用直接偏好优化进行微调的方法，以更好地与化学家的偏好对齐生成的分子。这种方法简单、高效，且非常有效。

    

    分子语言建模是一种生成新颖化学结构的有效方法。然而，这些模型不会\emph{先验地}编码化学家可能期望的某些偏好。本研究调查了使用直接偏好优化进行微调的方法，以更好地与化学家的偏好对齐生成的分子。我们的发现表明，这种方法简单、高效，且非常有效。

    Molecular language modeling is an effective approach to generating novel chemical structures. However, these models do not \emph{a priori} encode certain preferences a chemist may desire. We investigate the use of fine-tuning using Direct Preference Optimization to better align generated molecules with chemist preferences. Our findings suggest that this approach is simple, efficient, and highly effective.
    
[^56]: 文档级语言模型用于机器翻译

    Document-Level Language Models for Machine Translation. (arXiv:2310.12303v1 [cs.CL])

    [http://arxiv.org/abs/2310.12303](http://arxiv.org/abs/2310.12303)

    这项工作提出了一种利用文档级别语言模型构建上下文感知的翻译系统的方法。通过结合任何现有的句级别翻译模型与文档级别语言模型，并借鉴模型组合的最新进展，尤其是权重技术的提出，可以显著提高文档级别指标并降低计算开销。

    

    尽管已知存在局限性，但大多数机器翻译系统仍然在句级别上运行。其中一个原因是，大多数平行训练数据只有句级别的对齐，没有文档级别的元信息。在这项工作中，我们利用文档级别的单语数据构建上下文感知的翻译系统。我们通过将任何现有的句级别翻译模型与文档级别语言模型相结合来实现这一目标。我们通过利用模型组合的最新进展来改进现有方法。此外，我们提出了能够使系统组合更灵活、显著降低计算开销的权重技术。通过对四个不同的翻译任务进行全面评估，我们证明了我们的扩展显著提高了文档级别指标，并且在计算效率上也更优。然而，我们还发现在大多数情况下，反向翻译的结果更好，

    Despite the known limitations, most machine translation systems today still operate on the sentence-level. One reason for this is, that most parallel training data is only sentence-level aligned, without document-level meta information available. In this work, we set out to build context-aware translation systems utilizing document-level monolingual data instead. This can be achieved by combining any existing sentence-level translation model with a document-level language model. We improve existing approaches by leveraging recent advancements in model combination. Additionally, we propose novel weighting techniques that make the system combination more flexible and significantly reduce computational overhead. In a comprehensive evaluation on four diverse translation tasks, we show that our extensions improve document-targeted scores substantially and are also computationally more efficient. However, we also find that in most scenarios, back-translation gives even better results, at the
    
[^57]: Jorge: GPU高效的二阶优化的近似预处理方法

    Jorge: Approximate Preconditioning for GPU-efficient Second-order Optimization. (arXiv:2310.12298v1 [cs.LG])

    [http://arxiv.org/abs/2310.12298](http://arxiv.org/abs/2310.12298)

    本文介绍了Jorge，一种GPU高效的二阶优化算法，通过近似预处理方法替代矩阵求逆计算来提高计算效率，同时兼具二阶方法的收敛性能。实验证明了Jorge的有效性。

    

    尽管与一阶优化器相比，二阶优化器具有更好的收敛性能，但由于计算成本较大，深度学习中的二阶优化器一直不太受欢迎。这种优化器中的主要效率瓶颈是预处理步骤中的矩阵求逆计算，在GPU上计算昂贵。在本文中，我们引入了Jorge，一种二阶优化器，它兼具二阶方法的快速收敛特性和一阶方法的高计算效率。我们通过完全消除矩阵求逆计算的方法来解决计算瓶颈，用近似的预处理器计算替代。这使得Jorge在墙钟时间上在GPU上非常高效。此外，我们描述了一种直接从调整良好的SGD基准中确定Jorge超参数的方法，从而显著减少了调参工作。我们的实证评估证明了Jorge的效果。

    Despite their better convergence properties compared to first-order optimizers, second-order optimizers for deep learning have been less popular due to their significant computational costs. The primary efficiency bottleneck in such optimizers is matrix inverse calculations in the preconditioning step, which are expensive to compute on GPUs. In this paper, we introduce Jorge, a second-order optimizer that promises the best of both worlds -- rapid convergence benefits of second-order methods, and high computational efficiency typical of first-order methods. We address the primary computational bottleneck of computing matrix inverses by completely eliminating them using an approximation of the preconditioner computation. This makes Jorge extremely efficient on GPUs in terms of wall-clock time. Further, we describe an approach to determine Jorge's hyperparameters directly from a well-tuned SGD baseline, thereby significantly minimizing tuning efforts. Our empirical evaluations demonstrate
    
[^58]: 基于事实的多智能体强化学习中的智能体建模

    Fact-based Agent modeling for Multi-Agent Reinforcement Learning. (arXiv:2310.12290v1 [cs.AI])

    [http://arxiv.org/abs/2310.12290](http://arxiv.org/abs/2310.12290)

    提出了一种基于事实的智能体建模方法，用于解决在非稳态环境中对其他智能体的信念、行为和意图进行建模的问题，并在未知场景中实现智能体建模。

    

    在多智能体系统中，智能体需要在环境中与其他智能体进行互动和合作。智能体建模对于促进智能体间的互动和实现自适应合作策略至关重要。然而，在非稳态环境中，智能体同时学习所有智能体策略的情况下，智能体对其他智能体的信念、行为和意图进行建模是具有挑战性的。此外，现有的方法通过行为克隆实现智能体建模，假设在执行或训练期间可以访问其他智能体的本地信息。然而，在未知的场景中，如竞争团队、不可靠的通信和出于隐私考虑的联邦学习等未知代理特征的情况下，这种假设是不可行的。为了消除这种假设并在未知场景中实现智能体建模，提出了基于事实的智能体建模（FAM）方法，其中基于事实的信念推理（FBI）网络在部分可观察的环境中对其他智能体进行建模。

    In multi-agent systems, agents need to interact and collaborate with other agents in environments. Agent modeling is crucial to facilitate agent interactions and make adaptive cooperation strategies. However, it is challenging for agents to model the beliefs, behaviors, and intentions of other agents in non-stationary environment where all agent policies are learned simultaneously. In addition, the existing methods realize agent modeling through behavior cloning which assume that the local information of other agents can be accessed during execution or training. However, this assumption is infeasible in unknown scenarios characterized by unknown agents, such as competition teams, unreliable communication and federated learning due to privacy concerns. To eliminate this assumption and achieve agent modeling in unknown scenarios, Fact-based Agent modeling (FAM) method is proposed in which fact-based belief inference (FBI) network models other agents in partially observable environment on
    
[^59]: 使用图表示学习提高 MOOC 自动化成绩预测的性能

    Enhancing the Performance of Automated Grade Prediction in MOOC using Graph Representation Learning. (arXiv:2310.12281v1 [cs.LG])

    [http://arxiv.org/abs/2310.12281](http://arxiv.org/abs/2310.12281)

    本研究通过图表示学习构建了一个独特的知识图谱，以提高MOOC中自动化成绩预测的性能。

    

    近年来，大规模在线开放课程（MOOCs）作为一种快速增长的在线学习现象获得了显著的关注。与传统的教室不同，MOOCs提供了一个独特的机会，以满足来自不同背景和地理位置的各种受众。著名大学和专门提供MOOCs的供应商，如Coursera，在各种主题上提供MOOC课程。由于高入学率和教师与学习者之间的有限直接互动，自动评估任务如成绩和早期退学预测变得必要。然而，当前自动评估方法忽视了下游任务中涉及不同实体之间的结构链接，例如学生和课程。我们的假设是，通过交互图表现的这些结构关系包含可以提高所需任务性能的宝贵信息。为了验证这一点，我们为一个大规模MOOC构建了一个独特的知识图谱。

    In recent years, Massive Open Online Courses (MOOCs) have gained significant traction as a rapidly growing phenomenon in online learning. Unlike traditional classrooms, MOOCs offer a unique opportunity to cater to a diverse audience from different backgrounds and geographical locations. Renowned universities and MOOC-specific providers, such as Coursera, offer MOOC courses on various subjects. Automated assessment tasks like grade and early dropout predictions are necessary due to the high enrollment and limited direct interaction between teachers and learners. However, current automated assessment approaches overlook the structural links between different entities involved in the downstream tasks, such as the students and courses. Our hypothesis suggests that these structural relationships, manifested through an interaction graph, contain valuable information that can enhance the performance of the task at hand. To validate this, we construct a unique knowledge graph for a large MOOC 
    
[^60]: 一图抵千言：使用多概念提示学习来学习对象级概念

    An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning. (arXiv:2310.12274v1 [cs.CV])

    [http://arxiv.org/abs/2310.12274](http://arxiv.org/abs/2310.12274)

    提出了一种多概念提示学习（MCPL）框架，通过同时学习多个新的“词”来解决在单个场景中识别和整合多个对象级概念的挑战。针对词概念相关性准确性问题，提出了注意力掩码、提示对比损失和绑定形容词等三种正则化技术。通过图像生成进行了评估，结果表明该框架能够生成更多样化和合成的图像。

    

    文字反转是一种提示学习方法，它学习一种新的“单词”的嵌入表示图像风格和外观，使其能够整合到自然语言句子中生成新的合成图像。然而，即使对于可获得个别概念的嵌入，识别和整合一个场景中的多个对象级概念仍然面临着显著的挑战，这也得到了我们的实证测试的进一步证实。为了解决这个挑战，我们引入了一个多概念提示学习（MCPL）的框架，可以从一个句子-图像对中同时学习多个新的“词”。为了增强词概念相关性的准确性，我们提出了三种正则化技术：注意力掩码（AttnMask）将学习集中在相关区域；提示对比损失（PromptCL）将不同概念的嵌入分离开来；以及绑定形容词（Bind adj.）将新的“词”与已知词相关联。我们通过图像生成进行评估

    Textural Inversion, a prompt learning method, learns a singular embedding for a new "word" to represent image style and appearance, allowing it to be integrated into natural language sentences to generate novel synthesised images. However, identifying and integrating multiple object-level concepts within one scene poses significant challenges even when embeddings for individual concepts are attainable. This is further confirmed by our empirical tests. To address this challenge, we introduce a framework for Multi-Concept Prompt Learning (MCPL), where multiple new "words" are simultaneously learned from a single sentence-image pair. To enhance the accuracy of word-concept correlation, we propose three regularisation techniques: Attention Masking (AttnMask) to concentrate learning on relevant areas; Prompts Contrastive Loss (PromptCL) to separate the embeddings of different concepts; and Bind adjective (Bind adj.) to associate new "words" with known words. We evaluate via image generation
    
[^61]: 一种统一的带有记忆的领域增量学习方法: 理论和算法

    A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm. (arXiv:2310.12244v1 [cs.LG])

    [http://arxiv.org/abs/2310.12244](http://arxiv.org/abs/2310.12244)

    这篇论文提出了一种统一的带有记忆的领域增量学习方法（UDIL），通过统一不同的现有方法并使用自适应系数，实现了更紧的泛化误差界限，并在实验证明在合成数据和真实数据集上优于最先进的方法。

    

    领域增量学习旨在适应一系列领域，仅能访问先前领域的一小部分数据（即记忆）。针对这个问题已经提出了各种方法，但它们之间的关系以及从实践者角度何时选择其中一种方法仍然不清楚。为此，我们提出了一种统一的框架，称为统一领域增量学习（UDIL），用于带有记忆的领域增量学习。我们的UDIL将各种现有方法统一起来，我们的理论分析表明，与这些方法相比，UDIL始终实现更紧的泛化误差界限。关键观点是不同的现有方法对应于我们的边界具有不同的固定系数；基于这种统一的洞察力，我们的UDIL允许在训练过程中使用自适应系数，从而始终实现最紧的界限。实证结果表明，我们的UDIL在合成数据和真实数据集上均优于最先进的领域增量学习方法。

    Domain incremental learning aims to adapt to a sequence of domains with access to only a small subset of data (i.e., memory) from previous domains. Various methods have been proposed for this problem, but it is still unclear how they are related and when practitioners should choose one method over another. In response, we propose a unified framework, dubbed Unified Domain Incremental Learning (UDIL), for domain incremental learning with memory. Our UDIL **unifies** various existing methods, and our theoretical analysis shows that UDIL always achieves a tighter generalization error bound compared to these methods. The key insight is that different existing methods correspond to our bound with different **fixed** coefficients; based on insights from this unification, our UDIL allows **adaptive** coefficients during training, thereby always achieving the tightest bound. Empirical results show that our UDIL outperforms the state-of-the-art domain incremental learning methods on both synthe
    
[^62]: 通过隐式图对齐进行少样本背景下的模仿学习

    Few-Shot In-Context Imitation Learning via Implicit Graph Alignment. (arXiv:2310.12238v1 [cs.RO])

    [http://arxiv.org/abs/2310.12238](http://arxiv.org/abs/2310.12238)

    本文提出了一种少样本背景下的模仿学习方法，通过将模仿学习视为物体的图表示之间的条件对齐问题，实现了在没有先验知识或进一步训练的情况下，机器人可以在新的物体集上执行任务。

    

    考虑以下问题：给定在几个不同物体上进行的任务的少量演示，机器人如何学会在新的、之前未见过的物体上执行相同的任务？这是具有挑战性的，因为类别内多样的物体使得推断新物体与演示中的物体之间的任务相关关系变得困难。我们通过将模仿学习视为物体的图表示之间的条件对齐问题来解决这个问题。因此，我们展示了这种条件允许背景下的学习，在演示之后，机器人可以立即在一组新物体上执行任务，而无需关于物体类别的任何先验知识或任何进一步的训练。在实验中，我们探索和验证了我们的设计选择，并证明了我们的方法在几个真实世界的日常任务的少样本学习中非常有效，同时优于基线方法。可以在我们的项目网页上观看视频。

    Consider the following problem: given a few demonstrations of a task across a few different objects, how can a robot learn to perform that same task on new, previously unseen objects? This is challenging because the large variety of objects within a class makes it difficult to infer the task-relevant relationship between the new objects and the objects in the demonstrations. We address this by formulating imitation learning as a conditional alignment problem between graph representations of objects. Consequently, we show that this conditioning allows for in-context learning, where a robot can perform a task on a set of new objects immediately after the demonstrations, without any prior knowledge about the object class or any further training. In our experiments, we explore and validate our design choices, and we show that our method is highly effective for few-shot learning of several real-world, everyday tasks, whilst outperforming baselines. Videos are available on our project webpag
    
[^63]: 一种针对代数数据类型的热切满足模理论求解器

    An Eager Satisfiability Modulo Theories Solver for Algebraic Datatypes. (arXiv:2310.12234v1 [cs.LO])

    [http://arxiv.org/abs/2310.12234](http://arxiv.org/abs/2310.12234)

    该论文提出了一种针对代数数据类型的热切满足模理论求解器。通过将ADT查询简化为非解释函数 (UF)，然后使用现有求解器，该方法在声音性和完备性上都得到了证明，并且在性能上优于现有方法。

    

    代数数据类型 (ADTs) 是功能性编程语言中经典的构造，用于捕捉枚举类型、列表和树等数据结构。近年来，对ADTs的兴趣逐渐增加。例如，流行的编程语言，如Python，已经为ADTs添加了支持。可以使用满足模理论 (SMT) 求解来自动进行关于ADTs的推理，SMT是布尔可满足性问题在一阶结构上的约束扩展。然而，支持ADTs的SMT求解器无法扩展，因为现有方法都采用了同样\emph{懒惰}的方法。在本文中，我们提出了一种完全不同的SMT求解器，即\emph{热切}方法。具体而言，我们的求解器将ADT查询简化为更简单的逻辑理论，如非解释函数 (UF)，然后在简化后的查询上使用现有求解器。我们证明了我们方法的声音性和完备性，并证明其性能优于现有方法。

    Algebraic data types (ADTs) are a construct classically found in functional programming languages that capture data structures like enumerated types, lists, and trees. In recent years, interest in ADTs has increased. For example, popular programming languages, like Python, have added support for ADTs. Automated reasoning about ADTs can be done using satisfiability modulo theories (SMT) solving, an extension of the Boolean satisfiability problem with constraints over first-order structures. Unfortunately, SMT solvers that support ADTs do not scale as state-of-the-art approaches all use variations of the same \emph{lazy} approach. In this paper, we present an SMT solver that takes a fundamentally different approach, an \emph{eager} approach. Specifically, our solver reduces ADT queries to a simpler logical theory, uninterpreted functions (UF), and then uses an existing solver on the reduced query. We prove the soundness and completeness of our approach and demonstrate that it outperforms
    
[^64]: 陌生人危险！与边缘用户的跨社区互动增加了Reddit上边缘社区的增长。

    Stranger Danger! Cross-Community Interactions with Fringe Users Increase the Growth of Fringe Communities on Reddit. (arXiv:2310.12186v1 [cs.SI])

    [http://arxiv.org/abs/2310.12186](http://arxiv.org/abs/2310.12186)

    边缘互动是推动Reddit上边缘社区增长的机制之一，收到边缘互动的用户比没有收到互动的用户更有可能加入边缘社区。

    

    在主流平台上，推广阴谋论和极端意识形态的边缘社区蓬勃发展，这引发了人们对其增长机制的疑问。我们假设并研究了可能的机制：新成员可能通过边缘互动招募：成员与非成员之间的评论交流。我们应用基于文本的因果推断技术研究了边缘互动对Reddit上三个知名边缘社区（r/Incel，r/GenderCritical和r/The_Donald）增长的影响。我们的研究结果表明，边缘互动吸引了新的社区成员。收到这些互动的用户比没有收到互动的相似匹配用户更有可能加入边缘社区，增加了4.2个百分点。这种影响受到以下因素的影响：1）互动发生的社区特性（例如，左倾和右倾社区）和2）互动中使用的语言。

    Fringe communities promoting conspiracy theories and extremist ideologies have thrived on mainstream platforms, raising questions about the mechanisms driving their growth. Here, we hypothesize and study a possible mechanism: new members may be recruited through fringe-interactions: the exchange of comments between members and non-members of fringe communities. We apply text-based causal inference techniques to study the impact of fringe-interactions on the growth of three prominent fringe communities on Reddit: r/Incel, r/GenderCritical, and r/The_Donald. Our results indicate that fringe-interactions attract new members to fringe communities. Users who receive these interactions are up to 4.2 percentage points (pp) more likely to join fringe communities than similar, matched users who do not.  This effect is influenced by 1) the characteristics of communities where the interaction happens (e.g., left vs. right-leaning communities) and 2) the language used in the interactions. Interact
    
[^65]: GNN聚合编程抽象的架构影响

    Architectural Implications of GNN Aggregation Programming Abstractions. (arXiv:2310.12184v1 [cs.LG])

    [http://arxiv.org/abs/2310.12184](http://arxiv.org/abs/2310.12184)

    本文通过对现有GNN聚合编程抽象进行分类，并在最先进的GNN库上进行特征研究和性能比较，提供了未来GNN加速的见解。

    

    图神经网络（GNN）由于从图数据中提取有用表示的强大能力而受到广泛关注。随着对高效GNN计算的需求增加，为优化GNN聚合而设计的各种编程抽象应运而生，以促进加速。然而，对现有抽象没有全面的评估和分析，因此对哪种方法更好没有明确的共识。在这封信中，我们通过数据组织和传播方法的维度对现有的GNN聚合编程抽象进行分类。通过在最先进的GNN库上构建这些抽象，我们进行了彻底和详细的特征研究，以比较它们的性能和效率，并根据我们的分析提供了一些关于未来GNN加速的见解。

    Graph neural networks (GNNs) have gained significant popularity due to the powerful capability to extract useful representations from graph data. As the need for efficient GNN computation intensifies, a variety of programming abstractions designed for optimizing GNN Aggregation have emerged to facilitate acceleration. However, there is no comprehensive evaluation and analysis upon existing abstractions, thus no clear consensus on which approach is better. In this letter, we classify existing programming abstractions for GNN Aggregation by the dimension of data organization and propagation method. By constructing these abstractions on a state-of-the-art GNN library, we perform a thorough and detailed characterization study to compare their performance and efficiency, and provide several insights on future GNN acceleration based on our analysis.
    
[^66]: 一种乐观-鲁棒的全渠道库存动态定位方法

    An Optimistic-Robust Approach for Dynamic Positioning of Omnichannel Inventories. (arXiv:2310.12183v1 [math.OC])

    [http://arxiv.org/abs/2310.12183](http://arxiv.org/abs/2310.12183)

    这篇论文介绍了一种乐观-鲁棒的全渠道库存动态定位方法，通过兼顾库存弹性和改善平均性能，来平衡店铺失去销售和跨渠道电子商务履约成本的权衡。

    

    我们介绍了一种新的数据驱动和免分布乐观-鲁棒双模式库存优化策略，以有效分配销售链上的库存，以满足时变的、不确定的全渠道需求。传统的鲁棒优化方法更加注重最坏情况下的对抗性需求，而双模式策略不仅考虑了保持像鲁棒优化一样的弹性，还通过克服内生奇异值的存在而获得了改善平均情况下性能的回报。这种双模式策略在平衡店铺失去销售和跨渠道电子商务履约成本的权衡方面特别有价值，这也是我们库存优化模型的核心所在。由于渠道的异质行为，这些因素是非对称的，前者在失销售成本方面存在偏差，而后者则依赖于网络效应。

    We introduce a new class of data-driven and distribution-free optimistic-robust bimodal inventory optimization (BIO) strategy to effectively allocate inventory across a retail chain to meet time-varying, uncertain omnichannel demand. While prior Robust optimization (RO) methods emphasize the downside, i.e., worst-case adversarial demand, BIO also considers the upside to remain resilient like RO while also reaping the rewards of improved average-case performance by overcoming the presence of endogenous outliers. This bimodal strategy is particularly valuable for balancing the tradeoff between lost sales at the store and the costs of cross-channel e-commerce fulfillment, which is at the core of our inventory optimization model. These factors are asymmetric due to the heterogenous behavior of the channels, with a bias towards the former in terms of lost-sales cost and a dependence on network effects for the latter. We provide structural insights about the BIO solution and how it can be tu
    
[^67]: RK-core: 一种可用于探索数据集中层次结构的已建立方法

    RK-core: An Established Methodology for Exploring the Hierarchical Structure within Datasets. (arXiv:2310.12168v1 [cs.LG])

    [http://arxiv.org/abs/2310.12168](http://arxiv.org/abs/2310.12168)

    RK-core方法探索数据集中的层次结构，通过分析样本的核心值，发现核心值高的样本在性能上具有更大的贡献。

    

    最近，机器学习领域已经从以模型为中心转向以数据为中心。对各种学习任务的进展是由于更广泛的数据集的积累所推动的，随之而来的是在这些数据集上训练更大模型的可能性。然而，这些数据集仍然相对未被充分探索。为此，我们引入了一种开创性的方法，称为RK-core，以帮助更深入地了解数据集内复杂的层次结构。在多个基准数据集上，我们发现具有较低核心值的样本在其相应类别中的代表性较低，相反，具有较高核心值的样本表现出更大的代表性。相应地，具有较高核心值的样本相对于具有较低核心值的样本对性能贡献更大。基于此，我们进一步利用RK-core分析具有不同coreness值的样本的层次结构。

    Recently, the field of machine learning has undergone a transition from model-centric to data-centric. The advancements in diverse learning tasks have been propelled by the accumulation of more extensive datasets, subsequently facilitating the training of larger models on these datasets. However, these datasets remain relatively under-explored. To this end, we introduce a pioneering approach known as RK-core, to empower gaining a deeper understanding of the intricate hierarchical structure within datasets. Across several benchmark datasets, we find that samples with low coreness values appear less representative of their respective categories, and conversely, those with high coreness values exhibit greater representativeness. Correspondingly, samples with high coreness values make a more substantial contribution to the performance in comparison to those with low coreness values. Building upon this, we further employ RK-core to analyze the hierarchical structure of samples with differen
    
[^68]: AI潜力与认知：人工智能与网络安全中的人机协作的立场文件

    AI Potentiality and Awareness: A Position Paper from the Perspective of Human-AI Teaming in Cybersecurity. (arXiv:2310.12162v1 [cs.CR])

    [http://arxiv.org/abs/2310.12162](http://arxiv.org/abs/2310.12162)

    这篇立场文件通过探讨人工智能在网络安全中的潜力，强调了人工智能与人类专家的协作的重要性。人工智能系统可以通过模式识别和预测建模主动发现漏洞并检测异常情况，而人类专家可以补充和辅助AI的输出结果，提高整体的网络安全防护能力。

    

    本立场文件在网络安全环境下探讨了人工智能的潜力，并特别强调了与意识相关的可能风险因素，这可以通过将人类专家纳入“人工智能-人类”协作中进行管理。随着人工智能技术的发展，它们将为攻击识别、事件响应和恢复提供无与伦比的机会。然而，成功将人工智能部署到网络安全措施中需要深入了解其能力、挑战以及与之相关的风险因素的道德和法律影响，以应对实际应用领域中的问题。为此，我们强调了一种平衡的方法，将人工智能的计算能力与人类专业知识结合起来。人工智能系统可以通过模式识别和预测建模主动发现漏洞并检测异常情况，极大提高识别速度和准确性。人类专家可以解释AI的输出结果，并提供领域专业知识的补充和辅助，从而增强整体的网络安全防护能力。

    This position paper explores the broad landscape of AI potentiality in the context of cybersecurity, with a particular emphasis on its possible risk factors with awareness, which can be managed by incorporating human experts in the loop, i.e., "Human-AI" teaming. As artificial intelligence (AI) technologies advance, they will provide unparalleled opportunities for attack identification, incident response, and recovery. However, the successful deployment of AI into cybersecurity measures necessitates an in-depth understanding of its capabilities, challenges, and ethical and legal implications to handle associated risk factors in real-world application areas. Towards this, we emphasize the importance of a balanced approach that incorporates AI's computational power with human expertise. AI systems may proactively discover vulnerabilities and detect anomalies through pattern recognition, and predictive modeling, significantly enhancing speed and accuracy. Human experts can explain AI-gene
    
[^69]: 通过群体不变性学习提高与人类偏好的对齐的泛化能力

    Improving Generalization of Alignment with Human Preferences through Group Invariant Learning. (arXiv:2310.11971v1 [cs.LG])

    [http://arxiv.org/abs/2310.11971](http://arxiv.org/abs/2310.11971)

    该论文提出了一种通过强化学习实现在不同数据组或领域中学习一致策略的方法，该方法可以提高AI助手对不同领域的泛化能力，并更好地与人类偏好对齐。

    

    基于语言模型(LLMs)的AI助手的成功在于强化学习从人类反馈中, 使生成的回答更加与人类偏好一致. 作为通用AI助手, 人们越来越期望它们在不同领域中表现一致. 然而, 先前的工作表明,强化学习(RL)经常利用捷径以获得较高的奖励, 忽略了具有挑战性的样本. 这种对快速奖励收益的关注不仅削弱了训练的稳定性, 也削弱了模型对新的未见数据的泛化能力. 在这项工作中, 我们提出了一种新颖的方法, 可以通过RL在不同数据组或领域中学习一致的策略. 鉴于获得群体标注的挑战, 我们的方法会自动将数据分类到不同的组中, 有意地最大化性能差异. 然后, 我们优化策略以在具有挑战性的组中表现良好. 最后, 利用已建立的

    The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences. As universal AI assistants, there's a growing expectation for them to perform consistently across various domains. However, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples. This focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data. In this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains. Given the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance. Then, we optimize the policy to perform well on challenging groups. Lastly, leveraging the estab
    
[^70]: 基于拍卖的调度

    Auction-Based Scheduling. (arXiv:2310.11798v1 [cs.AI])

    [http://arxiv.org/abs/2310.11798](http://arxiv.org/abs/2310.11798)

    该论文提出了一种基于拍卖的调度框架，用于解决多目标决策问题。该框架的创新之处在于将每个目标的实现分配给单独的策略，并且可以独立创建、修改和替换这些策略。使用拍卖机制来解决冲突和组合策略，确保长期的调度公平性。

    

    许多顺序决策任务需要满足多个部分矛盾的目标。现有方法是整体化的，即通过一个函数来选择一系列动作来满足所有目标。我们提出了基于拍卖的调度，这是一个模块化的多目标决策框架。每个目标都使用单独的策略来实现，这些策略可以独立创建、修改和替换。可以理解的是，具有冲突目标的不同策略可能在给定时间选择冲突的动作。为了解决冲突和组合策略，我们采用了一种新颖的基于拍卖的机制。我们给每个策略分配一个有限的预算，在每一步，策略同时从可用的预算中出价来获取调度和选择动作的特权。策略使用其出价来表达调度的紧迫性，有限的预算确保了长期的调度公平性。

    Many sequential decision-making tasks require satisfaction of multiple, partially contradictory objectives. Existing approaches are monolithic, namely all objectives are fulfilled using a single policy, which is a function that selects a sequence of actions. We present auction-based scheduling, a modular framework for multi-objective decision-making problems. Each objective is fulfilled using a separate policy, and the policies can be independently created, modified, and replaced. Understandably, different policies with conflicting goals may choose conflicting actions at a given time. In order to resolve conflicts, and compose policies, we employ a novel auction-based mechanism. We allocate a bounded budget to each policy, and at each step, the policies simultaneously bid from their available budgets for the privilege of being scheduled and choosing an action. Policies express their scheduling urgency using their bids and the bounded budgets ensure long-run scheduling fairness. We lay 
    
[^71]: Live Graph Lab:朝向具有NFT的开放、动态和实时交易图

    Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT. (arXiv:2310.11709v1 [cs.AI])

    [http://arxiv.org/abs/2310.11709](http://arxiv.org/abs/2310.11709)

    本文介绍了用于时间图的“实时图实验室”的概念，该实验室可以从NFT的区块链中提取开放、动态和实时的交易图，为了弥补对新兴NFT生态系统的特性了解的缺口，我们使用NFT交易网络实例化了一个实时图并进行了调查

    

    进行了大量研究来调查大规模时间图的特性。尽管这些图在现实场景中普遍存在，但由于隐私问题和技术限制，我们通常无法获取整个实时图。在本文中，我们介绍了用于时间图的“实时图实验室”概念，该实验室可以从区块链中提取开放、动态和实时的交易图。其中，非同质化代币（NFT）在过去几年中成为区块链中最重要的部分之一。这个分散化生态系统具有超过400亿美元的市值，产生了大量的匿名和实时交易活动，自然形成了一个复杂的交易网络。然而，从时间图分析的角度对这个新兴的NFT生态系统的特性了解有限。为了弥补这一差距，我们使用NFT交易网络实例化了一个实时图并进行了调查。

    Numerous studies have been conducted to investigate the properties of large-scale temporal graphs. Despite the ubiquity of these graphs in real-world scenarios, it's usually impractical for us to obtain the whole real-time graphs due to privacy concerns and technical limitations. In this paper, we introduce the concept of {\it Live Graph Lab} for temporal graphs, which enables open, dynamic and real transaction graphs from blockchains. Among them, Non-fungible tokens (NFTs) have become one of the most prominent parts of blockchain over the past several years. With more than \$40 billion market capitalization, this decentralized ecosystem produces massive, anonymous and real transaction activities, which naturally forms a complicated transaction network. However, there is limited understanding about the characteristics of this emerging NFT ecosystem from a temporal graph analysis perspective. To mitigate this gap, we instantiate a live graph with NFT transaction network and investigate 
    
[^72]: 基于原型的超适配器用于样本高效多任务调整

    Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning. (arXiv:2310.11670v1 [cs.CL])

    [http://arxiv.org/abs/2310.11670](http://arxiv.org/abs/2310.11670)

    基于原型的超适配器（PHA）框架用于样本高效多任务调整，通过引入实例密集的检索器和样本高效的原型超网络生成条件模块，在多任务学习和少样本迁移学习中取得了可比性能的提升，甚至在数据量较小时也能超过其他强基线方法的性能。

    

    参数高效微调（PEFT）已经证明在适应预训练语言模型到下游任务时有效，同时只更新了少量参数。尽管取得了成功，大多数现有方法独立地适应每个任务，没有考虑任务之间的知识传输，并且受限于低数据情景。为了克服这个问题，我们提出了一种基于原型的超适配器（PHA）框架，该框架建立在适配器调整和超网络基础上。它引入了一个实例密集的检索器和一个样本高效的原型超网络来生成条件模块。这导致与现有PEFT方法在多任务学习和少样本迁移学习上相当的性能改进。更重要的是，当可用数据量变小时，我们的方法比其他强基线方法有很大的优势。基于我们在各种数据集上的广泛实证实验，我们证明了PHA在权衡方面取得了更好的结果。

    Parameter-efficient fine-tuning (PEFT) has shown its effectiveness in adapting the pre-trained language models to downstream tasks while only updating a small number of parameters. Despite the success, most existing methods independently adapt to each task without considering knowledge transfer between tasks and are limited to low-data regimes. To overcome this issue, we propose Prototype-based HyperAdapter (PHA), a novel framework built on the adapter-tuning and hypernetwork. It introduces an instance-dense retriever and a prototypical hypernetwork to generate the conditional modules in a sample-efficient manner. This leads to comparable performance improvements against existing PEFT methods on multi-task learning and few-shot transfer learning. More importantly, when the available data size gets smaller, our method outperforms other strong baselines by a large margin. Based on our extensive empirical experiments across various datasets, we demonstrate that PHA strikes a better trade-
    
[^73]: WaveAttack：基于不对称频率混淆的基于背门的深度神经网络攻击

    WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks. (arXiv:2310.11595v1 [cs.CV])

    [http://arxiv.org/abs/2310.11595](http://arxiv.org/abs/2310.11595)

    本文提出了一种名为WaveAttack的新型基于频率的背门攻击方法，通过离散小波变换获取图像的高频特征来生成背门触发器，并引入了一种不对称的频率混淆方法来改善触发器的影响力，有效提高了背门攻击的成功率并且不易被检测到。

    

    由于人工智能（AI）技术的普及，许多对手设计了背门攻击，通过操纵训练样本和训练过程，误导深度神经网络的预测。虽然背门攻击在各种实际场景中都很有效，但它们仍然存在被现有的背门检测算法轻易检测到的问题，主要表现为毒化样本的低保真性和隐藏空间中的非可忽略转换。为了克服这个弱点，本文提出了一种新颖的基于频率的背门攻击方法，称为WaveAttack，它通过离散小波变换（DWT）获取图像的高频特征来生成背门触发器。此外，我们引入了一种不对称的频率混淆方法，可以在训练和推断阶段添加自适应残差，以提高触发器的影响力，并进一步增强WaveAttack的有效性。综合实验结果表明，WaveAttack不仅提高了背门攻击的成功率并且不易被检测到。

    Due to the popularity of Artificial Intelligence (AI) technology, numerous backdoor attacks are designed by adversaries to mislead deep neural network predictions by manipulating training samples and training processes. Although backdoor attacks are effective in various real scenarios, they still suffer from the problems of both low fidelity of poisoned samples and non-negligible transfer in latent space, which make them easily detectable by existing backdoor detection algorithms. To overcome the weakness, this paper proposes a novel frequency-based backdoor attack method named WaveAttack, which obtains image high-frequency features through Discrete Wavelet Transform (DWT) to generate backdoor triggers. Furthermore, we introduce an asymmetric frequency obfuscation method, which can add an adaptive residual in the training and inference stage to improve the impact of triggers and further enhance the effectiveness of WaveAttack. Comprehensive experimental results show that WaveAttack not
    
[^74]: 当刚性成为问题：软一致性正则化用于概率分层时间序列预测

    When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2310.11569v1 [cs.LG])

    [http://arxiv.org/abs/2310.11569](http://arxiv.org/abs/2310.11569)

    提出了一个新的概率分层时间序列预测模型，该模型能够有效建模和预测具有层次化关系的多变量时间序列。相较于现有方法，该模型不仅考虑点预测，还能提供经过良好校准的概率预测分布，并且在建模过程中考虑了预测分布的相关性。

    

    概率分层时间序列预测是时间序列预测的重要变体，其目标是对具有层次化关系的多变量时间序列进行建模和预测。大多数方法关注点预测，并未提供经过良好校准的概率预测分布。最近的概率预测方法也在点预测和分布样本中施加层次关系，但未考虑预测分布的相关性。以往的研究也默认数据集总是与给定的层次关系保持一致，并未适应显示出偏离此假设的真实世界数据集。我们填补了这两个空白，并提出了PROFHiT模型，它是一个完全概率的分层预测模型，同时对整个层次的预测分布进行建模。PROFHiT使用灵活的概率贝叶斯方法，并引入了一种新颖的分布一致性正则化方法。

    Probabilistic hierarchical time-series forecasting is an important variant of time-series forecasting, where the goal is to model and forecast multivariate time-series that have underlying hierarchical relations. Most methods focus on point predictions and do not provide well-calibrated probabilistic forecasts distributions. Recent state-of-art probabilistic forecasting methods also impose hierarchical relations on point predictions and samples of distribution which does not account for coherency of forecast distributions. Previous works also silently assume that datasets are always consistent with given hierarchical relations and do not adapt to real-world datasets that show deviation from this assumption. We close both these gap and propose PROFHiT, which is a fully probabilistic hierarchical forecasting model that jointly models forecast distribution of entire hierarchy. PROFHiT uses a flexible probabilistic Bayesian approach and introduces a novel Distributional Coherency regulariz
    
[^75]: 蛋白质三维图结构学习用于稳健的基于结构的蛋白质性质预测

    Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction. (arXiv:2310.11466v1 [cs.LG])

    [http://arxiv.org/abs/2310.11466](http://arxiv.org/abs/2310.11466)

    本文研究了蛋白质基于结构的性质预测中使用预测结构时性能下降的原因，并将其归因为结构嵌入偏差。

    

    蛋白质基于结构的性质预测已经成为各种生物学任务（如蛋白质功能预测和亚细胞定位估计）的一种有希望的方法。现有方法高度依赖实验蛋白质结构数据，在这些数据不可用的情况下失败。利用人工智能工具（如AlphaFold2）预测的蛋白质结构作为替代方案。然而，我们观察到目前的做法，即在推理过程中仅使用准确预测的结构，会导致预测准确性明显下降。虽然类似现象已经在一般领域（如计算机视觉）中进行了广泛研究作为模型的稳健性，但它们对蛋白质性质预测的影响尚未被探索。在本文中，我们首先从结构表示学习的角度研究了在利用预测的结构时性能下降的原因，将其归因为结构嵌入偏差。为了研究这个问题

    Protein structure-based property prediction has emerged as a promising approach for various biological tasks, such as protein function prediction and sub-cellular location estimation. The existing methods highly rely on experimental protein structure data and fail in scenarios where these data are unavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were utilized as alternatives. However, we observed that current practices, which simply employ accurately predicted structures during inference, suffer from notable degradation in prediction accuracy. While similar phenomena have been extensively studied in general fields (e.g., Computer Vision) as model robustness, their impact on protein property prediction remains unexplored. In this paper, we first investigate the reason behind the performance decrease when utilizing predicted structures, attributing it to the structure embedding bias from the perspective of structure representation learning. To study this problem
    
[^76]: HGCVAE: 将生成式学习和对比学习整合为一体的异构图学习方法

    HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning. (arXiv:2310.11102v1 [cs.LG])

    [http://arxiv.org/abs/2310.11102](http://arxiv.org/abs/2310.11102)

    HGCVAE是一种将生成式学习和对比学习整合为一体的异构图学习方法，通过利用生成式的自监督学习能力来解决异构图学习的挑战。

    

    生成式自监督学习（SSL）在图学习中展示了巨大的潜力和越来越多的关注。本研究旨在探索生成式SSL在异构图学习（HGL）中的问题。以往关于异构图的SSL方法主要依赖对比学习，需要设计复杂的视图来捕捉异质性。然而，现有的生成式SSL方法并未充分利用生成模型的能力来解决HGL的挑战。在本文中，我们提出了HGCVAE，一种新颖的对比变分图自编码器，使HGL摆脱了复杂异质性的负担。HGCVAE不再专注于复杂的异质性，而是充分利用了生成式SSL的潜力。HGCVAE创新地将对比学习与生成式SSL相结合，引入了几个关键创新。首先，我们采用渐进机制生成高质量的hard样本，

    Generative self-supervised learning (SSL) has exhibited significant potential and garnered increasing interest in graph learning. In this study, we aim to explore the problem of generative SSL in the context of heterogeneous graph learning (HGL). The previous SSL approaches for heterogeneous graphs have primarily relied on contrastive learning, necessitating the design of complex views to capture heterogeneity. However, existing generative SSL methods have not fully leveraged the capabilities of generative models to address the challenges of HGL. In this paper, we present HGCVAE, a novel contrastive variational graph auto-encoder that liberates HGL from the burden of intricate heterogeneity capturing. Instead of focusing on complicated heterogeneity, HGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively consolidates contrastive learning with generative SSL, introducing several key innovations. Firstly, we employ a progressive mechanism to generate high-quality hard
    
[^77]: BiomedJourney: 指导学习多模态患者旅程中的反事实生物医学图像生成

    BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys. (arXiv:2310.10765v1 [cs.CV])

    [http://arxiv.org/abs/2310.10765](http://arxiv.org/abs/2310.10765)

    提出了一种新颖的方法BiomedJourney，通过指导学习多模态患者旅程，进行反事实生物医学图像生成。使用GPT-4处理图像报告生成疾病进展的自然语言描述，并训练潜在扩散模型。

    

    随着自然语言指令图像编辑的指导学习取得了快速进展，如InstructPix2Pix，生物医学领域可以将这些方法应用于反事实图像生成，从而帮助区分因果结构和伪相关，并促进疾病进展建模的稳健图像解释。然而，通用的图像编辑模型并不适用于生物医学领域，反事实生物医学图像生成的研究还远未深入。在本文中，我们提出了一种新颖的方法BiomedJourney，通过指导学习多模态患者旅程，进行反事实生物医学图像生成。给定一个拍摄于不同时间点的两个生物医学图像的患者，我们使用GPT-4处理相应的图像报告，并生成疾病进展的自然语言描述。然后，使用生成的三元组（先前图像、进展描述、新图像）来训练一个潜在扩散模型。

    Rapid progress has been made in instruction-learning for image editing with natural-language instruction, as exemplified by InstructPix2Pix. In biomedicine, such methods can be applied to counterfactual image generation, which helps differentiate causal structure from spurious correlation and facilitate robust image interpretation for disease progression modeling. However, generic image-editing models are ill-suited for the biomedical domain, and counterfactual biomedical image generation is largely underexplored. In this paper, we present BiomedJourney, a novel method for counterfactual biomedical image generation by instruction-learning from multimodal patient journeys. Given a patient with two biomedical images taken at different time points, we use GPT-4 to process the corresponding imaging reports and generate a natural language description of disease progression. The resulting triples (prior image, progression description, new image) are then used to train a latent diffusion mode
    
[^78]: ACES: 使用自我目标语言模型和语义描述符生成多样的编程难题

    ACES: generating diverse programming puzzles with autotelic language models and semantic descriptors. (arXiv:2310.10692v1 [cs.LG])

    [http://arxiv.org/abs/2310.10692](http://arxiv.org/abs/2310.10692)

    ACES是一种使用自我目标语言模型和语义描述符生成多样化的编程难题的方法，能够优化有趣的多样性和少样本生成。

    

    寻找和选择新颖有趣的问题是好奇心、科学和创新的核心。在Python编程难题的无限空间中，我们研究了自动问题生成。现有的生成模型通常旨在建模参考分布，没有明确的多样性优化。其他方法在有限的手工编码表示空间或不可解释的学习嵌入空间中明确优化多样性，这些嵌入空间可能与人类对有趣变化的感知不符。通过ACES（自我目标代码探索与语义描述符），我们引入了一种新的自我目标生成方法，利用大型语言模型（LLM）生成语义描述符，直接优化有趣的多样性，以及少样本生成。每个难题都标记有10个维度，每个维度捕捉了解决它所需的编程技能。ACES生成并追求新颖可行的目标。

    Finding and selecting new and interesting problems to solve is at the heart of curiosity, science and innovation. We here study automated problem generation in the context of the open-ended space of python programming puzzles. Existing generative models often aim at modeling a reference distribution without any explicit diversity optimization. Other methods explicitly optimizing for diversity do so either in limited hand-coded representation spaces or in uninterpretable learned embedding spaces that may not align with human perceptions of interesting variations. With ACES (Autotelic Code Exploration via Semantic descriptors), we introduce a new autotelic generation method that leverages semantic descriptors produced by a large language model (LLM) to directly optimize for interesting diversity, as well as few-shot-based generation. Each puzzle is labeled along 10 dimensions, each capturing a programming skill required to solve it. ACES generates and pursues novel and feasible goals to 
    
[^79]: 超越文档边界的上下文预训练：语言模型

    In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10638](http://arxiv.org/abs/2310.10638)

    本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。

    

    目前，大型语言模型（LMs）通过预测给定文档前缀的标记来进行训练，从而能够直接进行长篇生成和提示式任务，这可以简化为文档完成。现有的预训练管道通过连接随机组合的短文档来训练LMs，以创建输入上下文，但前一个文档对于预测下一个文档没有提供任何信号。我们提出了一种新方法——上下文预训练，即在相关文档序列上预先训练语言模型，从而明确鼓励它们跨越文档边界进行阅读和推理。我们可以通过改变文档顺序，使每个上下文包含相关的文档，并直接应用现有的预训练管道来进行上下文预训练。然而，这个文档排序问题很具有挑战性。有数十亿个文档，我们希望在每个文档中最大化上下文相似性而不重复任何数据。

    Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do
    
[^80]: 通过与平滑高质量专家轨迹对齐实现高效数据集精炼

    Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories. (arXiv:2310.10541v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2310.10541](http://arxiv.org/abs/2310.10541)

    本论文提出了一种高效的数据集精炼方法，通过与平滑高质量的专家轨迹对齐，实现对大规模数据集的替代，并提出了剪辑损失和梯度惩罚的集成来调节学生和专家之间的互动。

    

    训练一大型的先进机器学习模型通常需要使用大规模数据集，这使得训练和参数调整过程变得昂贵且耗时。一些研究人员选择将真实世界数据集中的信息精炼为小型合成数据集，同时保持其训练性能，从而提出了一种称为数据集精炼（DD）的数据高效方法。尽管该领域近年来取得了进展，但现有方法仍然表现不佳，不能有效替代大规模数据集。在本文中，与仅关注改进学生成绩的先前方法不同，我们首次认识到专家和学生之间的重要相互作用。我们认为在后续数据集精炼中，采用更强大的专家轨迹时，专家的平滑性具有重要影响。基于此，我们引入了剪辑损失和梯度惩罚的集成，以调节学生和专家之间的互动。

    Training a large and state-of-the-art machine learning model typically necessitates the use of large-scale datasets, which, in turn, makes the training and parameter-tuning process expensive and time-consuming. Some researchers opt to distil information from real-world datasets into tiny and compact synthetic datasets while maintaining their ability to train a well-performing model, hence proposing a data-efficient method known as Dataset Distillation (DD). Despite recent progress in this field, existing methods still underperform and cannot effectively replace large datasets. In this paper, unlike previous methods that focus solely on improving the efficacy of student distillation, we are the first to recognize the important interplay between expert and student. We argue the significant impact of expert smoothness when employing more potent expert trajectories in subsequent dataset distillation. Based on this, we introduce the integration of clipping loss and gradient penalty to regul
    
[^81]: 深度学习的微扩展数据格式

    Microscaling Data Formats for Deep Learning. (arXiv:2310.10537v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.10537](http://arxiv.org/abs/2310.10537)

    本文评估了Microscaling（MX）数据格式在降低深度学习应用的计算和存储成本方面的可行性。实证结果显示MX数据格式可以作为基线FP32的替代，同时保持低用户摩擦，并且成功在超过两打基准测试中以小于8位的数据格式进行了训练。

    

    窄位宽数据格式对于降低现代深度学习应用的计算和存储成本至关重要。本文评估了将每个块的缩放因子与窄浮点和整数类型相结合的微扩展（MX）数据格式，以满足硬件效率、模型准确性和用户摩擦之间的竞争需求。对于AI推理和训练，MX数据格式在超过两打基准测试中的实证结果证明了其作为基线FP32的可行性，并且使用时用户摩擦小。我们还展示了在最小的准确性损失和无需修改训练配方的情况下，首次训练生成式语言模型在小于8位的权重、激活和渐变上。

    Narrow bit-width data formats are key to reducing the computational and storage costs of modern deep learning applications. This paper evaluates Microscaling (MX) data formats that combine a per-block scaling factor with narrow floating-point and integer types for individual elements. MX formats balance the competing needs of hardware efficiency, model accuracy, and user friction. Empirical results on over two dozen benchmarks demonstrate practicality of MX data formats as a drop-in replacement for baseline FP32 for AI inference and training with low user friction. We also show the first instance of training generative language models at sub-8-bit weights, activations, and gradients with minimal accuracy loss and no modifications to the training recipe.
    
[^82]: 对大型语言模型在非分布式逻辑推理任务上的系统评估

    A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v1 [cs.CL])

    [http://arxiv.org/abs/2310.09430](http://arxiv.org/abs/2310.09430)

    通过对大型语言模型在非分布式逻辑推理任务上进行系统评估，我们发现这些模型在处理我们新构建的数据集时都存在困难，尽管它们在其他自然语言处理任务上表现良好。这表明这些模型在逻辑推理方面的泛化和鲁棒性仍需要进一步研究。

    

    大型语言模型（LLMs），如GPT-3.5和GPT-4，已经将人工系统在各种自然语言处理任务上的性能提升到接近人类水平。然而，它们在逻辑推理方面的泛化和鲁棒性仍未得到充分评估。为了探索这种能力，我们提出了三个新的逻辑推理数据集，分别名为"ReClor-plus"、"LogiQA-plus"和"LogiQAv2-plus"，每个数据集都包含三个子集：第一个是选项随机打乱，第二个是将正确选项替换为"没有其他选项是正确的"，第三个是前两个子集的组合。我们在这些数据集上进行了实验，使用了鉴别和生成型的LLMs，并表明这些简单的技巧极大地阻碍了语言模型的性能。尽管在原始的公开可用数据集上表现出优秀的性能，但我们发现所有模型都很难回答我们新构建的数据集。我们展示了通过扰动引入任务变化可以提高模型的性能。

    Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly advanced the performance of artificial systems on various natural language processing tasks to human-like levels. However, their generalisation and robustness to perform logical reasoning remain under-evaluated. To probe this ability, we propose three new logical reasoning datasets named "ReClor-plus", "LogiQA-plus" and "LogiQAv2-plus", each featuring three subsets: the first with randomly shuffled options, the second with the correct choices replaced by "none of the other options are correct", and a combination of the previous two subsets. We carry out experiments on these datasets with both discriminative and generative LLMs and show that these simple tricks greatly hinder the performance of the language models. Despite their superior performance on the original publicly available datasets, we find that all models struggle to answer our newly constructed datasets. We show that introducing task variations by perturb
    
[^83]: 为程序验证对LLM生成的循环不变式进行排名

    Ranking LLM-Generated Loop Invariants for Program Verification. (arXiv:2310.09342v1 [cs.PL])

    [http://arxiv.org/abs/2310.09342](http://arxiv.org/abs/2310.09342)

    本研究提出了一种针对LLM生成结果进行重新排名的方法，可以显著提高正确不变量的排名，从而减少程序验证的调用次数。

    

    合成归纳循环不变量是自动化程序验证的基础。我们观察到，大型语言模型（如gpt-3.5或gpt-4）能够在0-shot环境下为一类程序合成循环不变量，但需要多个样本才能生成正确的不变量。这可能导致大量调用程序验证器来建立不变性。为了解决这个问题，我们提出了一种对LLM生成结果进行重新排名的方法。我们设计了一个排名器，可以根据问题定义区分正确的归纳不变量和错误的尝试。该排名器经过对比排名优化。实验结果表明，这种重新排名机制显著提高了正确不变量在生成的候选项中的排名，从而大幅减少了对验证器的调用次数。

    Synthesizing inductive loop invariants is fundamental to automating program verification. In this work, we observe that Large Language Models (such as gpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of programs in a 0-shot setting, yet require several samples to generate the correct invariants. This can lead to a large number of calls to a program verifier to establish an invariant. To address this issue, we propose a {\it re-ranking} approach for the generated results of LLMs. We have designed a ranker that can distinguish between correct inductive invariants and incorrect attempts based on the problem definition. The ranker is optimized as a contrastive ranker. Experimental results demonstrate that this re-ranking mechanism significantly improves the ranking of correct invariants among the generated candidates, leading to a notable reduction in the number of calls to a verifier.
    
[^84]: 使用思路链进行大型语言模型的少样本知识库问题生成

    Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation. (arXiv:2310.08395v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08395](http://arxiv.org/abs/2310.08395)

    本文提出了一种使用思路链（CoT）对大型语言模型进行少样本知识库问题生成的方法，该方法将问题生成任务形式化为推理问题，并通过检索支持性逻辑形式和编写提示来实现生成过程。

    

    知识库问答生成（KBQG）的任务是将逻辑形式转化为自然语言问题。由于大规模问题注释的昂贵成本，在低资源场景下急需开发KBQG方法。然而，当前方法在少样本问题生成中过于依赖注释数据的微调，这对于少样本问题生成并不合适。大型语言模型（LLM）的出现展示了它们在少样本任务中的印象力泛化能力。受到思路链（CoT）提示的启发，这是一种用于推理的上下文学习策略，我们将KBQG任务形式化为推理问题，其中一个完整问题的生成被分为一系列的子问题生成。我们提出的提示方法KQG-CoT首先从未标记数据池中检索支持性的逻辑形式，考虑逻辑形式的特征。然后，我们编写一个提示来明确推理链的生成过程。

    The task of Question Generation over Knowledge Bases (KBQG) aims to convert a logical form into a natural language question. For the sake of expensive cost of large-scale question annotation, the methods of KBQG under low-resource scenarios urgently need to be developed. However, current methods heavily rely on annotated data for fine-tuning, which is not well-suited for few-shot question generation. The emergence of Large Language Models (LLMs) has shown their impressive generalization ability in few-shot tasks. Inspired by Chain-of-Thought (CoT) prompting, which is an in-context learning strategy for reasoning, we formulate KBQG task as a reasoning problem, where the generation of a complete question is splitted into a series of sub-question generation. Our proposed prompting method KQG-CoT first retrieves supportive logical forms from the unlabeled data pool taking account of the characteristics of the logical form. Then, we write a prompt to explicit the reasoning chain of generati
    
[^85]: Fed-GraB：具有自适应梯度平衡器的联邦式长尾学习

    Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer. (arXiv:2310.07587v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.07587](http://arxiv.org/abs/2310.07587)

    本文提出了一种名为Fed-GraB的方法，该方法通过自适应梯度平衡器来解决联邦式长尾学习的问题。该方法能够在隐私约束下刻画全局长尾分布，并通过调整本地学习策略来解决头部-尾部不平衡的问题。

    

    数据隐私和长尾分布在许多现实任务中是常态而非例外。本文研究了一种联邦式长尾学习（Fed-LT）任务，在该任务中，每个客户端持有一个本地异构数据集；如果可以全局聚合数据集，则它们共同展现出长尾分布。在这样的设置下，现有的联邦优化和/或集中式长尾学习方法很难应用，因为存在以下挑战：（a）在隐私约束下刻画全局长尾分布，以及（b）调整本地学习策略以应对头部-尾部不平衡。为此，我们提出了一种方法称为$\texttt{Fed-GraB}$，它包括一个自适应梯度平衡器（SGB）模块，该模块以闭环方式根据全局长尾分布的反馈对客户端的梯度进行重新加权，评估方法为直接先验分析器（DPA）模块。使用$\texttt{Fed-GraB}$，客户端可以有效缓解数据分布的不均衡问题。

    Data privacy and long-tailed distribution are the norms rather than the exception in many real-world tasks. This paper investigates a federated long-tailed learning (Fed-LT) task in which each client holds a locally heterogeneous dataset; if the datasets can be globally aggregated, they jointly exhibit a long-tailed distribution. Under such a setting, existing federated optimization and/or centralized long-tailed learning methods hardly apply due to challenges in (a) characterizing the global long-tailed distribution under privacy constraints and (b) adjusting the local learning strategy to cope with the head-tail imbalance. In response, we propose a method termed $\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB) module that re-weights clients' gradients in a closed-loop manner, based on the feedback of global long-tailed distribution evaluated by a Direct Prior Analyzer (DPA) module. Using $\texttt{Fed-GraB}$, clients can effectively alleviate the distribution
    
[^86]: ChatGPT用于计算拓扑学

    ChatGPT for Computational Topology. (arXiv:2310.07570v2 [math.AT] UPDATED)

    [http://arxiv.org/abs/2310.07570](http://arxiv.org/abs/2310.07570)

    该论文介绍了如何利用ChatGPT桥接理论拓扑概念和计算拓扑实现之间的差距，展示了在没有编码技能的情况下，通过ChatGPT的帮助，纯粹的理论家如何将数学公式和概念转化为功能性的计算拓扑代码。

    

    ChatGPT是人工智能领域的一个重要里程碑，广泛应用于不同领域。然而，在数学环境中，它往往受到概念错误的限制。同时，拓扑数据分析是一个相对较新的学科，在近年来引起了广泛关注。然而，计算算法和编码技能在理论家中的理解还有限，这阻碍了拓扑学的进展。这项工作旨在通过利用ChatGPT来弥合理论拓扑概念与计算拓扑实现之间的差距。我们展示了如何在没有计算经验和编码技能的情况下，纯粹的理论家如何借助ChatGPT将数学公式和概念有效地转化为功能性的计算拓扑代码。我们的策略概述了一个有效的过程。

    ChatGPT represents a significant milestone in the field of artificial intelligence (AI), finding widespread applications across diverse domains. However, its effectiveness in mathematical contexts has been somewhat constrained by its susceptibility to conceptual errors. Concurrently, topological data analysis (TDA), a relatively new discipline, has garnered substantial interest in recent years. Nonetheless, the advancement of TDA is impeded by the limited understanding of computational algorithms and coding proficiency among theoreticians. This work endeavors to bridge the gap between theoretical topological concepts and their practical implementation in computational topology through the utilization of ChatGPT. We showcase how a pure theoretician, devoid of computational experience and coding skills, can effectively transform mathematical formulations and concepts into functional code for computational topology with the assistance of ChatGPT. Our strategy outlines a productive process
    
[^87]: ROMO: 检索增强的离线模型优化

    ROMO: Retrieval-enhanced Offline Model-based Optimization. (arXiv:2310.07560v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.07560](http://arxiv.org/abs/2310.07560)

    ROMO是一种检索增强的离线模型优化方法，通过在离线数据集中优化平庸设计，并保持给定的约束来解决约束MBO问题。

    

    数据驱动的黑盒模型优化（MBO）问题在许多实际应用场景中出现，其目标是基于静态离线数据集，寻找使黑盒目标函数最大化的整个空间上的设计。在这项工作中，我们考虑了一种更一般但具有挑战性的MBO设置，称为约束MBO（CoMBO），其中只有部分设计空间可以优化，而其余部分受环境约束。CoMBO带来的新挑战是大多数满足约束条件的观察设计在评估中是平庸的。因此，我们的重点是在离线数据集中优化这些平庸的设计，同时保持给定的约束，而不是在传统的MBO设置中进一步增强最佳观察设计。我们提出了检索增强的离线模型优化（ROMO），一种新的可导性前向方法，它检索离线数据集并聚合相关样本以提供可靠的预测，然后将其应用于CoMBO。

    Data-driven black-box model-based optimization (MBO) problems arise in a great number of practical application scenarios, where the goal is to find a design over the whole space maximizing a black-box target function based on a static offline dataset. In this work, we consider a more general but challenging MBO setting, named constrained MBO (CoMBO), where only part of the design space can be optimized while the rest is constrained by the environment. A new challenge arising from CoMBO is that most observed designs that satisfy the constraints are mediocre in evaluation. Therefore, we focus on optimizing these mediocre designs in the offline dataset while maintaining the given constraints rather than further boosting the best observed design in the traditional MBO setting. We propose retrieval-enhanced offline model-based optimization (ROMO), a new derivable forward approach that retrieves the offline dataset and aggregates relevant samples to provide a trusted prediction, and use it f
    
[^88]: KwaiYiiMath: 技术报告

    KwaiYiiMath: Technical Report. (arXiv:2310.07488v1 [cs.CL])

    [http://arxiv.org/abs/2310.07488](http://arxiv.org/abs/2310.07488)

    KwaiYiiMath是一个用于增强数学推理能力的大型语言模型，通过应用监督微调和人类反馈强化学习，在英语和中文数学任务上取得了最先进的性能，并且能够正确解决生成的问题过程。

    

    近年来，大型语言模型（LLMs）在处理各种自然语言处理（NLP）下游任务方面展示出了显著的能力，甚至可以处理需要多步推理的数学任务。在本报告中，我们介绍了KwaiYiiMath，通过应用监督微调（SFT）和人类反馈强化学习（RLHF），增强了KwaiYiiBase1的数学推理能力，包括英语和中文的数学任务。同时，我们还构建了一个小规模的中小学数学测试集（命名为KMath），包含188个例子，用来评估模型生成的问题解决过程的正确性。实证研究表明，与类似规模的模型相比，KwaiYiiMath在GSM8k、CMath和KMath上均能取得最先进的性能（SOTA）。

    Recent advancements in large language models (LLMs) have demonstrated remarkable abilities in handling a variety of natural language processing (NLP) downstream tasks, even on mathematical tasks requiring multi-step reasoning. In this report, we introduce the KwaiYiiMath which enhances the mathematical reasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT) and Reinforced Learning from Human Feedback (RLHF), including on both English and Chinese mathematical tasks. Meanwhile, we also constructed a small-scale Chinese primary school mathematics test set (named KMath), consisting of 188 examples to evaluate the correctness of the problem-solving process generated by the models. Empirical studies demonstrate that KwaiYiiMath can achieve state-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with the similar size models, respectively.
    
[^89]: Jaeger:一种基于连接的多变换器VQA模型

    Jaeger: A Concatenation-Based Multi-Transformer VQA Model. (arXiv:2310.07091v1 [cs.CL])

    [http://arxiv.org/abs/2310.07091](http://arxiv.org/abs/2310.07091)

    Jaeger是一种基于连接的多变换器VQA模型，利用RoBERTa large和GPT2-xl作为特征提取器，通过并行考虑多源信息来增强模型表征能力。

    

    基于文档的视觉问答在语言意义消歧和细粒度多模态检索之间提出了一个具有挑战性的任务。虽然由于大规模语言和开放世界先验模型的利用，文档问答取得了鼓舞人心的进展，但仍存在一些挑战，包括响应时间延长、推断持续时间延长和匹配不准确。为了克服这些挑战，我们提出了一种基于连接的多变换器VQA模型Jaegar。为了提取问题特征，我们利用了RoBERTa large和GPT2-xl等预训练模型的强大能力作为特征提取器。随后，我们将两种模型的输出进行连接操作。这个操作使得模型可以同时考虑来自不同来源的信息，增强了其表征能力。通过利用预训练模型进行特征提取，我们的方法有可能增强性能。

    Document-based Visual Question Answering poses a challenging task between linguistic sense disambiguation and fine-grained multimodal retrieval. Although there has been encouraging progress in document-based question answering due to the utilization of large language and open-world prior models\cite{1}, several challenges persist, including prolonged response times, extended inference durations, and imprecision in matching. In order to overcome these challenges, we propose Jaegar, a concatenation-based multi-transformer VQA model. To derive question features, we leverage the exceptional capabilities of RoBERTa large\cite{2} and GPT2-xl\cite{3} as feature extractors. Subsequently, we subject the outputs from both models to a concatenation process. This operation allows the model to consider information from diverse sources concurrently, strengthening its representational capability. By leveraging pre-trained models for feature extraction, our approach has the potential to amplify the pe
    
[^90]: CAW-coref: 关联词感知的词级共指消解

    CAW-coref: Conjunction-Aware Word-level Coreference Resolution. (arXiv:2310.06165v1 [cs.CL])

    [http://arxiv.org/abs/2310.06165](http://arxiv.org/abs/2310.06165)

    本文介绍了一种关联词感知的词级共指消解模型（CAW-coref），在处理并列提及的情况下表现出了较高的性能，有效地缩小了与昂贵的最先进方法的差距。

    

    当前最先进的共指消解系统每篇文章需要多次调用语言模型，因此对于许多应用场景来说（例如使用大规模语料库进行信息提取），代价太高。而词级共指系统 (WL-coref) 在效率上更加高效，实现了这些最先进系统 96.6% 的性能。本文发现了 WL-coref 的一个常见但重要的失败案例：处理“Tom 和 Mary”之类的并列提及。我们提供了一个简单但有效的解决方案，在 OntoNotes 测试集上将性能提高了 0.9% F1，将高效的词级共指消解与昂贵的最先进方法的差距缩小了34.6%。我们的关联词感知的词级共指模型（CAW-coref）和代码可在 https://github.com/KarelDO/wl-coref 获取。

    State-of-the-art coreference resolutions systems depend on multiple LLM calls per document and are thus prohibitively expensive for many use cases (e.g., information extraction with large corpora). The leading word-level coreference system (WL-coref) attains 96.6% of these SOTA systems' performance while being much more efficient. In this work, we identify a routine yet important failure case of WL-coref: dealing with conjoined mentions such as 'Tom and Mary'. We offer a simple yet effective solution that improves the performance on the OntoNotes test set by 0.9% F1, shrinking the gap between efficient word-level coreference resolution and expensive SOTA approaches by 34.6%. Our Conjunction-Aware Word-level coreference model (CAW-coref) and code is available at https://github.com/KarelDO/wl-coref.
    
[^91]: 解决多配置问题：使用Choco Solver的性能分析

    Solving Multi-Configuration Problems: A Performance Analysis with Choco Solver. (arXiv:2310.02658v1 [cs.AI])

    [http://arxiv.org/abs/2310.02658](http://arxiv.org/abs/2310.02658)

    本文介绍了使用Choco Solver进行多配置问题求解的应用案例，以及对约束求解器性能分析的研究，从而揭示了相关性能问题。

    

    在许多场景中，配置器支持配置满足单个用户偏好的解决方案。多配置的概念基于配置一组配置的想法。这种功能在配置个性化考试，配置项目团队和为旅游团队的每个成员配置不同的旅行（例如，在访问特定城市时）等场景中非常重要。在本文中，我们示例了多配置应用于生成个性化考试。我们还提供了一个约束求解器的性能分析，帮助我们对相应的性能问题有一些了解。

    In many scenarios, configurators support the configuration of a solution that satisfies the preferences of a single user. The concept of \emph{multi-configuration} is based on the idea of configuring a set of configurations. Such a functionality is relevant in scenarios such as the configuration of personalized exams, the configuration of project teams, and the configuration of different trips for individual members of a tourist group (e.g., when visiting a specific city). In this paper, we exemplify the application of multi-configuration for generating individualized exams. We also provide a constraint solver performance analysis which helps to gain some insights into corresponding performance issues.
    
[^92]: zkFL: 基于零知识证明的联邦学习梯度聚合

    zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning. (arXiv:2310.02554v1 [cs.AI])

    [http://arxiv.org/abs/2310.02554](http://arxiv.org/abs/2310.02554)

    zkFL是一种基于零知识证明的联邦学习梯度聚合方法，通过提供每轮的证明来解决协调者恶意行为的问题。

    

    联邦学习是一种机器学习范式，使多个分散的客户端在中央协调者的组织下共同训练一个模型。传统的联邦学习解决方案依赖于对中央协调者的信任，它以公平诚实的方式形成客户端的群体。然而，在现实中，恶意的协调者可能会放弃并替换客户端的训练模型，或者发动虚假客户端的肆意攻击。这种恶意行为让协调者在联邦学习环境中拥有更多控制客户端和决定最终训练结果的权力。本文介绍了zkFL，它利用零知识证明(ZKPs)来解决训练模型聚合过程中的恶意协调者问题。为了保证正确的聚合结果，协调者需要每轮提供一个证明。这个证明可以向客户端证明协调者忠实执行预期行为。为了进一步保护客户端隐私和数据安全，我们还引入了差分隐私机制，并对zkFL进行了实验评估。

    Federated Learning (FL) is a machine learning paradigm, which enables multiple and decentralized clients to collaboratively train a model under the orchestration of a central aggregator. Traditional FL solutions rely on the trust assumption of the centralized aggregator, which forms cohorts of clients in a fair and honest manner. However, a malicious aggregator, in reality, could abandon and replace the client's training models, or launch Sybil attacks to insert fake clients. Such malicious behaviors give the aggregator more power to control clients in the FL setting and determine the final training results. In this work, we introduce zkFL, which leverages zero-knowledge proofs (ZKPs) to tackle the issue of a malicious aggregator during the training model aggregation process. To guarantee the correct aggregation results, the aggregator needs to provide a proof per round. The proof can demonstrate to the clients that the aggregator executes the intended behavior faithfully. To further r
    
[^93]: SNIP: 用统一的预训练框架连接数学符号和数值领域

    SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training. (arXiv:2310.02227v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.02227](http://arxiv.org/abs/2310.02227)

    SNIP引入了一种统一的预训练框架，通过联合对比学习加强了符号和数值领域之间的相似性，并提供了跨领域的表示洞察力。

    

    在一个无法缺少符号数学方程来建模复杂自然现象的时代，科学探究往往涉及到收集观察数据并将其转化为数学表达式。最近，深度学习已经成为从数据中提取洞察力的强大工具。然而，现有模型通常特化于数值领域或符号领域，并且通常在为特定任务量身定制的监督式训练中进行训练。这种方法忽视了符号方程和其数值对应物之间可能产生的重大好处。为了弥合这种差距，我们引入了SNIP，一种符号-数值集成预训练的方法，它通过在符号和数值领域之间进行联合对比学习，增强了它们在预训练嵌入中的相互相似性。通过进行潜空间分析，我们观察到SNIP提供了跨领域的表示洞察力，揭示了符号和数值之间的关联关系。

    In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions. Recently, deep learning has emerged as a powerful tool for extracting insights from data. However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks. This approach neglects the substantial benefits that could arise from a task-agnostic unified understanding between symbolic equations and their numeric counterparts. To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training, which employs joint contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the pre-trained embeddings. By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic 
    
[^94]: OceanGPT：用于海洋科学任务的大型语言模型

    OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v1 [cs.CL])

    [http://arxiv.org/abs/2310.02031](http://arxiv.org/abs/2310.02031)

    OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。

    

    海洋科学是探索充满生命和生物多样性的海洋的科学，考虑到海洋覆盖了地球表面的70％以上，这一领域具有重要意义。最近，大型语言模型（LLM）的进展改变了科学的范式。尽管在其他领域取得了成功，但现有的LLM通常无法满足海洋学家等领域专家的需求，同时对LLM在海洋科学中的潜力尚未得到充分探索。这其中的根本原因可能是海洋数据的庞大而复杂的性质，以及对更高的粒度和丰富的知识的需求。为了解决这些问题，我们推出了首个海洋领域的LLM——OceanGPT，该模型擅长各种海洋科学任务。我们提出了一个新颖的框架DoInstruct，用于自动获取大量的海洋领域指导数据，它基于多智能体的协作生成指导。

    Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench,
    
[^95]: 通过关键点增强的自监督学习在有限注释情况下的医学图像分割

    Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation. (arXiv:2310.01680v1 [cs.CV])

    [http://arxiv.org/abs/2310.01680](http://arxiv.org/abs/2310.01680)

    本论文提出了一种关键点增强的自监督学习方法，通过在医学图像分割中引入长程空间自注意力，同时运用全局和局部自监督预训练，以提高CNN模型在低注释情况下的性能。

    

    通过自监督训练CNN模型（如UNet）已成为在低注释环境下促进医学图像分割的强大方法。最近的对比学习方法鼓励相同图像经历不同变换时的类似全局表示，或在本质上相关的不同图像/补丁特征之间实施不变性。然而，通过CNN提取的全局和局部特征在捕捉生物解剖学中至关重要的长程空间依赖性方面存在局限性。为此，我们提出了一个关键点增强的融合层，可以提取既保留短程又保留长程自注意力的表示。特别地，我们通过增加一个额外的输入，在多个尺度上增强CNN特征图，该输入学习了局部关键点特征之间的长程空间自注意力。此外，我们还引入了全局和局部自监督预训练框架。在全局尺度上，我们获得了全局的表示。

    Pretraining CNN models (i.e., UNet) through self-supervision has become a powerful approach to facilitate medical image segmentation under low annotation regimes. Recent contrastive learning methods encourage similar global representations when the same image undergoes different transformations, or enforce invariance across different image/patch features that are intrinsically correlated. However, CNN-extracted global and local features are limited in capturing long-range spatial dependencies that are essential in biological anatomy. To this end, we present a keypoint-augmented fusion layer that extracts representations preserving both short- and long-range self-attention. In particular, we augment the CNN feature map at multiple scales by incorporating an additional input that learns long-range spatial self-attention among localized keypoint features. Further, we introduce both global and local self-supervised pretraining for the framework. At the global scale, we obtain global repres
    
[^96]: 大型语言模型评估的元语义模板

    Meta Semantic Template for Evaluation of Large Language Models. (arXiv:2310.01448v1 [cs.CL])

    [http://arxiv.org/abs/2310.01448](http://arxiv.org/abs/2310.01448)

    提出了一种通过创建元语义模板来评估大型语言模型（LLM）对语义理解能力的方法，该方法利用现有数据集生成新的超出分布（OOD）评估集。

    

    大型语言模型（LLM）是否真正理解语言的语义，还是仅仅记住训练数据？最近对LLM潜在数据污染的担忧引起了社区对LLM评估研究的关注。在本文中，我们提出了MSTemp，一种通过创建元语义模板来评估LLM对语义理解能力的方法。MSTemp的核心不是直接在现有基准数据集上进行评估，而是使用现有数据集作为种子生成新的超出分布（OOD）评估集。具体而言，对于给定的句子，MSTemp利用另一个语言模型生成新样本，同时保留其语义。这些新样本被称为原句子的语义模板。然后，MSTemp通过句子解析和随机替换词语来生成评估样本。MSTemp具有高度灵活、动态和成本效益性。我们的初步实验表明，MSTemp-

    Do large language models (LLMs) genuinely understand the semantics of the language, or just memorize the training data? The recent concern on potential data contamination of LLMs has raised awareness of the community to conduct research on LLMs evaluation. In this paper, we propose MSTemp, an approach that creates meta semantic templates to evaluate the semantic understanding ability of LLMs. The core of MSTemp is not to perform evaluation directly on existing benchmark datasets, but to generate new out-of-distribution (OOD) evaluation sets using existing datasets as seeds. Specifically, for a given sentence, MSTemp leverages another language model to generate new samples while preserving its semantics. The new samples are called semantic templates to the original sentence. Then, MSTemp generates evaluation samples via sentence parsing and random word replacement on the semantic templates. MSTemp is highly flexible, dynamic, and cost-effective. Our initial experiments show that MSTemp-
    
[^97]: 通过鉴别-批判差距测量语言模型对价值的理解

    Measuring Value Understanding in Language Models through Discriminator-Critique Gap. (arXiv:2310.00378v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00378](http://arxiv.org/abs/2310.00378)

    通过鉴别-批判差距测量LLMs对人类价值的理解，我们提出了价值理解测量（VUM）框架，并使用GPT-4开发了一个包含一千个对话的数据集。我们的评估结果显示，尺度定律对LLMs的“知道什么”有较大影响，而对“知道为什么”影响较小。

    

    最近大型语言模型（LLMs）的进展引发了对它们与人类价值观之间潜在不一致性的担忧。然而，由于它们的复杂和适应性，评估它们对这些价值观的理解是复杂的。我们认为真正理解LLMs中的价值观需要考虑到“知道什么”和“知道为什么”两个方面。为此，我们提出了价值理解测量（VUM）框架，通过量化鉴别-批判差距来定量评估“知道什么”和“知道为什么”。利用施瓦茨价值观调查，我们确定了评估价值观的标准，并使用GPT-4开发了一个包含一千个对话的数据集。我们的评估考察了LLMs的输出与基准答案之间的价值观一致性，以及LLMs的回答与GPT-4的注释在价值认知原因上的一致性。我们评估了五个代表性LLMs，并提供了强有力的证据表明，尺度定律对“知道什么”的影响较大，但对“知道为什么”的影响较小。

    Recent advancements in Large Language Models (LLMs) have heightened concerns about their potential misalignment with human values. However, evaluating their grasp of these values is complex due to their intricate and adaptable nature. We argue that truly understanding values in LLMs requires considering both "know what" and "know why". To this end, we present the Value Understanding Measurement (VUM) framework that quantitatively assess both "know what" and "know why" by measuring the discriminator-critique gap related to human values. Using the Schwartz Value Survey, we specify our evaluation values and develop a thousand-level dialogue dataset with GPT-4. Our assessment looks at both the value alignment of LLM's outputs compared to baseline answers and how LLM responses align with reasons for value recognition versus GPT-4's annotations. We evaluate five representative LLMs and provide strong evidence that the scaling law significantly impacts "know what" but not much on "know why", 
    
[^98]: AI-企业优化的协同辅助：一个框架和在生产调度中的案例研究。

    AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling. (arXiv:2309.13218v1 [cs.AI])

    [http://arxiv.org/abs/2309.13218](http://arxiv.org/abs/2309.13218)

    这篇论文提出了一个AI-企业优化的协同辅助系统，通过采用大型语言模型和微调预训练模型的方法，实现了减少人类专业知识需求的目标。

    

    企业优化是寻找和实施高效和具有成本效益的运营方式，以为企业带来竞争优势的过程。综合问题表述是企业优化的一个重要组成部分，它围绕着人类专业知识展开，因此很有可能成为瓶颈。随着大型语言模型（LLMs）的最新进展，通过人工智能（AI）可以潜在地减少问题表述中所需的人类专业知识。然而，开发用于问题表述的LLM具有挑战性，由于训练数据要求、令牌限制以及LLM中缺乏适当的性能度量。为了减少大量训练数据的需求，最近人们开始关注对预训练的LLM进行微调以适应下游任务，而不是从头开始训练一个特定任务的LLM。在本文中，我们采用了这种方法，提出了一个AI-企业优化的协同辅助系统。

    Business optimisation is the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation which is centred around human expertise, thus with a high potential of becoming a bottleneck. With the recent advancements in Large Language Models (LLMs), human expertise needed in problem formulation can potentially be minimized using Artificial Intelligence (AI). However, developing a LLM for problem formulation is challenging, due to training data requirements, token limitations, and the lack of appropriate performance metrics in LLMs. To minimize the requirement of large training data, considerable attention has recently been directed towards fine-tuning pre-trained LLMs for downstream tasks, rather than training a LLM from scratch for a specific task. In this paper, we adopt this approach and propose an AI-Copilot for business optimisation by 
    
[^99]: 角度优化的文本嵌入

    AnglE-Optimized Text Embeddings. (arXiv:2309.12871v1 [cs.CL])

    [http://arxiv.org/abs/2309.12871](http://arxiv.org/abs/2309.12871)

    本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。

    

    高质量的文本嵌入对于提升语义文本相似度（STS）任务至关重要，而这些任务又是大型语言模型（LLM）应用中的关键组成部分。然而，现有的文本嵌入模型面临的一个普遍挑战是渐变消失问题，主要是由于它们在优化目标中依赖余弦函数，而余弦函数具有饱和区域。为了解决这个问题，本文提出了一种称为AnglE的新型角度优化文本嵌入模型。AnglE的核心思想是在一个复杂空间中引入角度优化。这种新颖的方法有效地缓解了余弦函数饱和区域产生的不利影响，从而可以阻碍梯度并阻碍优化过程。为了建立全面的STS评估，我们在现有的短文本STS数据集和从GitHub Issues中新收集的长文本STS数据集上进行了实验。此外，我们还研究了具有有限标签数据的特定领域STS场景，并探讨了AnglE的工作原理。

    High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works w
    
[^100]: 利用大型语言模型探索自我强化以改进学生生成的多项选择题解释

    Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v1 [cs.AI])

    [http://arxiv.org/abs/2309.10444](http://arxiv.org/abs/2309.10444)

    本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。

    

    学生资源共享涉及学生生成和分享学习资源。在学生生成多项选择题时，创建解释是一个关键步骤，因为它有助于对相关概念的深入理解。然而，学生往往由于主题理解有限和仅仅重申问题、干扰因素和正确答案的倾向而难以编写有效的解释。为了帮助支撑这个任务，在这项工作中，我们提出了一个自我强化的大型语言模型框架，旨在自动生成和评估解释。该框架由三个模块组成，生成与学生对齐的解释，评估这些解释以确保其质量，并迭代增强解释。如果一个解释的评估分数低于定义的阈值，框架会迭代地优化和重新评估解释。重要的是，我们的框架模拟了一个学生学习的过程。

    Learnersourcing involves students generating and sharing learning resources with their peers. When learnersourcing multiple-choice questions, creating explanations for the generated questions is a crucial step as it facilitates a deeper understanding of the related concepts. However, it is often difficult for students to craft effective explanations due to limited subject understanding and a tendency to merely restate the question stem, distractors, and correct answer. To help scaffold this task, in this work we propose a self-reinforcement large-language-model framework, with the goal of generating and evaluating explanations automatically. Comprising three modules, the framework generates student-aligned explanations, evaluates these explanations to ensure their quality and iteratively enhances the explanations. If an explanation's evaluation score falls below a defined threshold, the framework iteratively refines and reassesses the explanation. Importantly, our framework emulates th
    
[^101]: 生成建模，设计和分析蜘蛛丝蛋白序列以提高机械性能

    Generative modeling, design and analysis of spider silk protein sequences for enhanced mechanical properties. (arXiv:2309.10170v1 [cond-mat.mtrl-sci] CROSS LISTED)

    [http://arxiv.org/abs/2309.10170](http://arxiv.org/abs/2309.10170)

    提出了一种生成式语言模型，用于设计具有复杂目标机械性能组合的新型蜘蛛丝蛋白序列。通过BLAST搜索、性能评估、分子结构比较和序列基序分析等方式对模型性能进行了评估。

    

    蜘蛛丝是一种拥有出色的机械性能（如强度，延展性和轻量化）的材料。然而，到目前为止，仅有有限的模型可用于完全探索序列-性能关系以进行分析和设计。在这里，我们提出了一种定制的生成式语言模型，用于设计新的蜘蛛丝蛋白序列以满足复杂的目标机械性能组合。该模型在大量蛋白序列的预训练基础上进行微调，针对约1,000个主要泡腺丝蛋白（MaSp）序列进行了正向和逆向生成策略的端到端设计。通过以下评估性能：（1）通过BLAST搜索对生成的蜘蛛丝蛋白序列进行新颖性分析和蛋白类型分类，（2）对比类似序列的性能评估和比较，（3）分子结构比较，以及（4）详细的序列基序分析。

    Spider silks are remarkable materials characterized by superb mechanical properties such as strength, extensibility and lightweightedness. Yet, to date, limited models are available to fully explore sequence-property relationships for analysis and design. Here we propose a custom generative large-language model to enable design of novel spider silk protein sequences to meet complex combinations of target mechanical properties. The model, pretrained on a large set of protein sequences, is fine-tuned on ~1,000 major ampullate spidroin (MaSp) sequences for which associated fiber-level mechanical properties exist, to yield an end-to-end forward and inverse generative strategy. Performance is assessed through: (1), a novelty analysis and protein type classification for generated spidroin sequences through BLAST searches, (2) property evaluation and comparison with similar sequences, (3) comparison of molecular structures, as well as, and (4) a detailed sequence motif analyses. We generate s
    
[^102]: DeepVol：一种用于通用资产波动性建模的深度迁移学习方法

    DeepVol: A Deep Transfer Learning Approach for Universal Asset Volatility Modeling. (arXiv:2309.02072v1 [econ.EM])

    [http://arxiv.org/abs/2309.02072](http://arxiv.org/abs/2309.02072)

    DeepVol是一种用于通用资产波动性建模的深度迁移学习方法，通过一个通用模型有效地捕捉和建模所有金融资产的波动性动态，可能改变对波动性的理解和预测方式。

    

    本文介绍了一种新的深度学习波动性模型DeepVol，它在模型的广泛性方面优于传统的计量经济模型。DeepVol利用迁移学习的能力，通过一个通用模型有效地捕捉和建模所有金融资产的波动性动态，包括以前未见过的资产。这与计量经济学文献中的主流做法形成鲜明对比，后者需要为不同数据集训练单独的模型。引入DeepVol为金融行业的波动性建模和预测开辟了新的途径，可能会改变对波动性的理解和预测方式。

    This paper introduces DeepVol, a promising new deep learning volatility model that outperforms traditional econometric models in terms of model generality. DeepVol leverages the power of transfer learning to effectively capture and model the volatility dynamics of all financial assets, including previously unseen ones, using a single universal model. This contrasts to the prevailing practice in econometrics literature, which necessitates training separate models for individual datasets. The introduction of DeepVol opens up new avenues for volatility modeling and forecasting in the finance industry, potentially transforming the way volatility is understood and predicted.
    
[^103]: 基于主题的贝叶斯惊喜和意外性用于推荐系统

    Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v1 [cs.IR])

    [http://arxiv.org/abs/2308.06368](http://arxiv.org/abs/2308.06368)

    本文通过引入基于主题的贝叶斯惊喜概念，提出了一种用于推荐系统的意外性模型，以解决过滤泡问题，通过识别相似用户和测量用户对物品的意外性来推荐具有高潜力的意外性物品。

    

    推荐系统优化其推荐仅适合用户对已消费物品的评级历史，这可能导致过滤泡，用户无法从新颖、未见过的类别中体验物品。我们提出了一种基于内容的意外性形式，以贝叶斯惊喜为基础，用于测量用户消费并评级后物品的意外性。结合识别相似用户的协同过滤组件，可以推荐具有高潜力意外性的物品。为了便于评估主题级别的惊喜和意外性模型，我们介绍了一个从Goodreads中提取的图书阅读历史数据集，包含超过26千个用户和近130万本书，并对其中的449篇书进行了手动注释。

    A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 
    
[^104]: Amazon-M2: 一个用于推荐和文本生成的多语言多区域购物会话数据集

    Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation. (arXiv:2307.09688v1 [cs.IR])

    [http://arxiv.org/abs/2307.09688](http://arxiv.org/abs/2307.09688)

    Amazon-M2是一个多语言多区域购物会话数据集，可以增强个性化推荐和理解用户偏好能力。

    

    对于电子商务来说，建模客户购物意图是一个重要的任务，因为它直接影响用户体验和参与度。因此，准确理解客户的偏好对于提供个性化推荐至关重要。基于会话的推荐技术利用客户会话数据来预测他们的下一次互动，已经越来越受到欢迎。然而，现有的会话数据集在项目属性、用户多样性和数据集规模方面存在局限性。因此，它们不能全面地捕捉用户行为和偏好的谱系。为了弥补这一差距，我们提出了Amazon Multilingual Multi-locale Shopping Session Dataset，即Amazon-M2。它是第一个由来自六个不同区域的数百万用户会话组成的多语言数据集，其中产品的主要语言是英语、德语、日语、法语、意大利语和西班牙语。值得注意的是，这个数据集可以帮助我们增强个性化和理解用户偏好能力。

    Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, w
    
[^105]: 学习层次交互式多目标搜索以进行移动操作

    Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation. (arXiv:2307.06125v1 [cs.RO])

    [http://arxiv.org/abs/2307.06125](http://arxiv.org/abs/2307.06125)

    这项工作提出了一个层次化的强化学习方法，用于解决在未知环境中需要同时进行操控和导航的交互式多目标搜索任务。实验证明，该方法可以在新环境中进行零样本迁移，并对未见过的子任务具有鲁棒性。

    

    现有的目标搜索方法使得机器人可以在自由路径上进行搜索，然而，在非结构化的以人为中心的环境中操作的机器人经常需要操控环境以满足他们的需求。在这项工作中，我们引入了一种新的交互式多目标搜索任务，机器人需要打开门以浏览房间，并在橱柜和抽屉内搜索目标物品。这些新挑战需要在未知环境中结合操控和导航技能。我们提出了HIMOS，一种层次强化学习方法，学习组合探索、导航和操控技能。为了实现这一点，我们设计了一个围绕语义地图记忆的抽象高级动作空间，并利用探索过的环境作为实例导航点。我们在仿真和真实世界中进行了大量实验，证明HIMOS可以零样本方式有效地迁移到新的环境中，并且对于未见过的子任务具有鲁棒性。

    Existing object-search approaches enable robots to search through free pathways, however, robots operating in unstructured human-centered environments frequently also have to manipulate the environment to their needs. In this work, we introduce a novel interactive multi-object search task in which a robot has to open doors to navigate rooms and search inside cabinets and drawers to find target objects. These new challenges require combining manipulation and navigation skills in unexplored environments. We present HIMOS, a hierarchical reinforcement learning approach that learns to compose exploration, navigation, and manipulation skills. To achieve this, we design an abstract high-level action space around a semantic map memory and leverage the explored environment as instance navigation points. We perform extensive experiments in simulation and the real-world that demonstrate that HIMOS effectively transfers to new environments in a zero-shot manner. It shows robustness to unseen subp
    
[^106]: URL：一种可转移不确定性估计的表示学习基准

    URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v1 [cs.LG])

    [http://arxiv.org/abs/2307.03810](http://arxiv.org/abs/2307.03810)

    URL基准是一个评估预训练模型可转移性和不确定性估计的方式，研究发现专注于表示本身不确定性或直接估计预测风险的方法效果优于基于概率的方法。

    

    表示学习显著推动了该领域发展出能够作为从零开始迁移到新数据集时的有价值起点的预训练模型。随着对可靠机器学习和不确定性量化的需求不断增加，需要的预训练模型不仅能提供嵌入向量，还能提供可转移的不确定性估计。为了引导这样的模型的开发，我们提出了URL（Uncertainty-aware Representation Learning）基准。除了表示的可转移性之外，它还使用一种新颖的度量标准来测量不确定性估计的零样本可转移性。我们应用URL来评估11种在ImageNet上进行预训练并转移到8个下游数据集的不确定性量化器。我们发现，着重于表示本身的不确定性或直接估计预测风险的方法优于基于上游类别的概率的方法。然而，实现可转移的不确定性仍然是一个挑战。

    Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction risk directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertaint
    
[^107]: 利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割研究

    Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data. (arXiv:2307.03512v1 [cs.CV])

    [http://arxiv.org/abs/2307.03512](http://arxiv.org/abs/2307.03512)

    本文研究了利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割。实验结果表明，传输学习的应用可以提高性能，为未来工作提供基准。

    

    当将深度学习应用于考古研究中的遥感数据时，一个显著的障碍是适用于模型训练的合适数据集的有限可用性。传输学习的应用经常被用来减轻这个缺点。然而，仍有必要探索在不同考古数据集上应用传输学习的有效性。本文比较了使用两个语义分割深度神经网络在两个LiDAR数据集上的各种传输学习配置的性能。实验结果表明，基于传输学习的方法在考古学中可以提高性能，尽管尚未观察到系统性的改进。我们提供了关于此类技术有效性的具体见解，可作为未来工作的基准。

    When applying deep learning to remote sensing data in archaeological research, a notable obstacle is the limited availability of suitable datasets for training models. The application of transfer learning is frequently employed to mitigate this drawback. However, there is still a need to explore its effectiveness when applied across different archaeological datasets. This paper compares the performance of various transfer learning configurations using two semantic segmentation deep neural networks on two LiDAR datasets. The experimental results indicate that transfer learning-based approaches in archaeology can lead to performance improvements, although a systematic enhancement has not yet been observed. We provide specific insights about the validity of such techniques that can serve as a baseline for future works.
    
[^108]: MeLM：一个解决正向和逆向力学问题的生成式预训练语言建模框架

    MeLM, a generative pretrained language modeling framework that solves forward and inverse mechanics problems. (arXiv:2306.17525v1 [cond-mat.mtrl-sci] CROSS LISTED)

    [http://arxiv.org/abs/2306.17525](http://arxiv.org/abs/2306.17525)

    MeLM是一个灵活的多模式力学语言模型，利用自回归注意力机制解决正向和逆向力学问题，表现出色。

    

    我们报道了一个灵活的多模式力学语言模型MeLM，应用于解决各种非线性的正向和逆向问题，可以处理一组指令、数字和微结构数据。该框架应用于各个示例，包括仿生分层蜂窝设计、碳纳米管力学和蛋白质展开。尽管模型具有灵活性，能够轻松地融入不同材料、尺度和力学特征，但它在不同的正向和逆向任务中表现出色。基于自回归注意力模型，MeLM有效地表示了一个由数亿个神经元组成的庞大多粒子系统，通过形成图形的自注意机制发现相互作用势能，然后利用在训练数据中发现的协同效应来识别出现结构之间的关系。我们展示了该模型可以解决复杂的退化力学设计问题。

    We report a flexible multi-modal mechanics language model, MeLM, applied to solve various nonlinear forward and inverse problems, that can deal with a set of instructions, numbers and microstructure data. The framework is applied to various examples including bio-inspired hierarchical honeycomb design, carbon nanotube mechanics, and protein unfolding. In spite of the flexible nature of the model-which allows us to easily incorporate diverse materials, scales, and mechanical features-it performs well across disparate forward and inverse tasks. Based on an autoregressive attention-model, MeLM effectively represents a large multi-particle system consisting of hundreds of millions of neurons, where the interaction potentials are discovered through graph-forming self-attention mechanisms that are then used to identify relationships from emergent structures, while taking advantage of synergies discovered in the training data. We show that the model can solve complex degenerate mechanics desi
    
[^109]: 学习排序遇见语言：增强基于语言驱动的排序对齐以支持序数分类

    Learning-to-Rank Meets Language: Boosting Language-Driven Ordering Alignment for Ordinal Classification. (arXiv:2306.13856v1 [cs.CV])

    [http://arxiv.org/abs/2306.13856](http://arxiv.org/abs/2306.13856)

    本文提出了一种利用语言驱动的高效序数分类方法，即L2RCLIP，它通过视觉-语言对齐任务充分利用语言中的序数先验，利用补充提示调整技术RankFormer增强原始排序提示的排序关系，并使用跨模态排序约束损失(CMOCL)进一步将语言先验融入模型中。在多个标准数据集中，L2RCLIP都比现有最先进方法具有更好的性能表现。

    

    我们提出了一种新颖的基于语言驱动的排序对准方法，用于序数分类。在序数分类中，标签包含额外的排序关系，如果仅依赖于训练数据，很容易出现过拟合现象。最近预训练的视觉-语言模型的发展启发我们通过将原始任务转化为视觉-语言对齐任务来利用人类语言中丰富的序数先验。因此，我们提出了L2RCLIP，它从两个方面充分利用了语言先验：首先，我们引入了一种补充提示调整技术RankFormer，旨在增强原始排序提示的排序关系。它在单词嵌入空间中使用标记级别的注意力和残差风格提示混合。其次，为了进一步融入语言先验，我们重新考虑了香草交叉熵损失的近似绑定优化，并在跨模态嵌入空间内进行了重构。因此，我们提出了一种跨模态排序约束损失（CMOCL），用于规范从语言中导出的序数约束。实验结果表明，我们提出的方法在多个流行的序数分类基准数据集上均显著优于现有最先进方法。

    We present a novel language-driven ordering alignment method for ordinal classification. The labels in ordinal classification contain additional ordering relations, making them prone to overfitting when relying solely on training data. Recent developments in pre-trained vision-language models inspire us to leverage the rich ordinal priors in human language by converting the original task into a vision-language alignment task. Consequently, we propose L2RCLIP, which fully utilizes the language priors from two perspectives. First, we introduce a complementary prompt tuning technique called RankFormer, designed to enhance the ordering relation of original rank prompts. It employs token-level attention with residual-style prompt blending in the word embedding space. Second, to further incorporate language priors, we revisit the approximate bound optimization of vanilla cross-entropy loss and restructure it within the cross-modal embedding space. Consequently, we propose a cross-modal ordin
    
[^110]: 可证明强大的有向多图神经网络

    Provably Powerful Graph Neural Networks for Directed Multigraphs. (arXiv:2306.11586v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11586](http://arxiv.org/abs/2306.11586)

    本文分析了一组简单的改进方法，将标准的消息传递图神经网络（GNN）转化为可证明强大的有向多图神经网络，能够检测任何有向子图模式。实验结果展示了这些改进方法在合成子图检测任务和金融犯罪分析任务上的出色性能。

    

    本文分析了一组简单的改进方法，将标准的消息传递图神经网络（GNN）转化为可证明强大的有向多图神经网络。改进方法包括多图端口编号、个体ID和反向消息传递。我们证明这些方法的组合在理论上能够检测任何有向子图模式。为了验证我们提出的改进方法在实践中的有效性，我们在合成子图检测任务上进行了实验，结果表明其具有出色的性能，几乎可以得到完美的结果。此外，我们将提出的改进方法应用于两个金融犯罪分析任务。我们观察到在检测洗钱交易方面有显著的改善，将标准的消息传递GNN的少数类F1分数提高了高达30%，并且与基于树和GNN的基准相媲美或超越。在一个实际的网络钓鱼检测数据集上也观察到了类似令人印象深刻的结果，提升了三个标准方法的性能。

    This paper analyses a set of simple adaptations that transform standard message-passing Graph Neural Networks (GNN) into provably powerful directed multigraph neural networks. The adaptations include multigraph port numbering, ego IDs, and reverse message passing. We prove that the combination of these theoretically enables the detection of any directed subgraph pattern. To validate the effectiveness of our proposed adaptations in practice, we conduct experiments on synthetic subgraph detection tasks, which demonstrate outstanding performance with almost perfect results. Moreover, we apply our proposed adaptations to two financial crime analysis tasks. We observe dramatic improvements in detecting money laundering transactions, improving the minority-class F1 score of a standard message-passing GNN by up to 30%, and closely matching or outperforming tree-based and GNN baselines. Similarly impressive results are observed on a real-world phishing detection dataset, boosting three standar
    
[^111]: 用一致性检查评估超人模型

    Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v1 [cs.LG])

    [http://arxiv.org/abs/2306.09983](http://arxiv.org/abs/2306.09983)

    本文提出了一个用一致性检查评估超人模型的框架，可以发现决策制定中的逻辑不一致性，即使对于超人模型的决策正确性可能是不可能评估的情况。

    

    如果机器学习模型在各种推理或决策任务上实现了超人能力，那么我们该如何评估这些模型，考虑到人类代理会产生偏差? 在本文中，我们提出了一个用一致性检查评估超人模型的框架。我们的前提是，虽然评估超人决策的正确性可能是不可能的，但是如果模型的决策未能满足某些逻辑上、可解释的规则，我们仍然可以发现错误。我们将我们的框架实现在三个任务上，这些任务的决策正确性由于超人模型能力或其他缺乏基本事实而难以评估：评估国际象棋局面、预测未来事件和作出法律判断。我们表明，无论模型在这些任务上的表现如何(可能是超人的)，我们都能发现决策制定中的逻辑不一致性。例如：国际象棋引擎给出对局中棋子相对估值的不同排列。

    If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model's decisions fail to satisfy certain logical, human-interpretable rules. We instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model's (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to 
    
[^112]: ArtWhisperer：一个用于描述艺术创作中人工智能与人类交互的数据集

    ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations. (arXiv:2306.08141v1 [cs.AI])

    [http://arxiv.org/abs/2306.08141](http://arxiv.org/abs/2306.08141)

    为研究人工智能与人类交互，研究者创建了ArtWhisperer数据集，这是一个在线游戏，人们通过反复尝试不同的提示词，来生成和目标图像类似的图像，并记录了50,000多个交互记录。在初步分析中，研究者发现人们提交了各种各样的提示词，并能够发现生成各种文本描述的图像。

    

    随着生成型人工智能越来越普及，研究人类用户如何与这些模型交互变得越来越重要。在这项工作中，我们研究了人们如何使用文本到图像的模型生成所需的目标图像。为了研究这种交互，我们创建了ArtWhisperer，这是一个在线游戏，用户会得到一个目标图像，并需要反复尝试不同的提示词，以便生成类似目标图像的图像。通过这个游戏，我们记录了50,000多个人工智能-人类交互的记录；每个交互都对应着用户创建的一个提示词和相应生成的图像。大多数记录都是重复的交互，用户通过反复尝试找到最佳的提示词以生成目标图像，这使得这个数据集成为研究人工智能与人类协作的独特连续数据集。在对这个数据集的初步分析中，我们发现了一些提示词交互和用户策略的特征。人们提交了各种各样的提示词，并能够发现生成各种文本描述的图像。

    As generative AI becomes more prevalent, it is important to study how human users interact with such models. In this work, we investigate how people use text-to-image models to generate desired target images. To study this interaction, we created ArtWhisperer, an online game where users are given a target image and are tasked with iteratively finding a prompt that creates a similar-looking image as the target. Through this game, we recorded over 50,000 human-AI interactions; each interaction corresponds to one text prompt created by a user and the corresponding generated image. The majority of these are repeated interactions where a user iterates to find the best prompt for their target image, making this a unique sequential dataset for studying human-AI collaborations. In an initial analysis of this dataset, we identify several characteristics of prompt interactions and user strategies. People submit diverse prompts and are able to discover a variety of text descriptions that generate
    
[^113]: 语言指导下的场景级交通仿真模拟

    Language-Guided Traffic Simulation via Scene-Level Diffusion. (arXiv:2306.06344v1 [cs.RO])

    [http://arxiv.org/abs/2306.06344](http://arxiv.org/abs/2306.06344)

    该论文提出了一种可以受到语言指导的场景级条件扩散模型，该模型能够生成真实且可控的交通，并通过大型语言模型将用户的查询转化为损失函数，指导模型生成符合查询条件的仿真交通。

    

    实现真实和可控的交通仿真是加速自主驾驶汽车（AV）发展的核心能力。然而，目前用于控制基于学习的交通模型的方法需要大量领域专业知识，对于从业者来说很难使用。为了解决这个问题，我们提出了CTG++，一种可以受到语言指导的场景级条件扩散模型。为了达到这个目的，我们需要解决两个问题：需要一个真实和可控的交通模型骨干结构，并且要有一种有效的方法来使用语言与交通模型进行交互。为了解决这些问题，我们首先提出了一个带有时空转换器骨干结构的场景级扩散模型，它生成了真实和可控的交通。然后，我们利用大型语言模型（LLM）将用户的查询转换为损失函数，指导扩散模型朝着查询合规的生成方向前进。通过全面的评估，我们展示了该模型的有效性。

    Realistic and controllable traffic simulation is a core capability that is necessary to accelerate autonomous vehicle (AV) development. However, current approaches for controlling learning-based traffic models require significant domain expertise and are difficult for practitioners to use. To remedy this, we present CTG++, a scene-level conditional diffusion model that can be guided by language instructions. Developing this requires tackling two challenges: the need for a realistic and controllable traffic model backbone, and an effective method to interface with a traffic model using language. To address these challenges, we first propose a scene-level diffusion model equipped with a spatio-temporal transformer backbone, which generates realistic and controllable traffic. We then harness a large language model (LLM) to convert a user's query into a loss function, guiding the diffusion model towards query-compliant generation. Through comprehensive evaluation, we demonstrate the effect
    
[^114]: 关于扩散模型的设计基础：综述

    On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v1 [cs.LG])

    [http://arxiv.org/abs/2306.04542](http://arxiv.org/abs/2306.04542)

    本文综述了扩散模型的设计基础，即其三个关键组件：正向过程、逆向过程和采样过程，为未来的研究提供了有益的细粒度透视。

    

    扩散模型是一种生成模型，通过逐渐添加和删除噪声来学习训练数据的潜在分布以生成数据。扩散模型的组成部分已经受到了广泛的关注，许多设计选择被提出。现有的评论主要关注高层次的解决方案，对组件的设计基础覆盖较少。本研究旨在通过提供一个全面而连贯的综述，针对扩散模型的组件设计选择进行分析。具体来说，我们将这个综述按照三个关键组件进行组织，即正向过程、逆向过程和采样过程。这使得我们可以提供扩散模型的细粒度透视，有助于未来研究分析个体组件、设计选择的适用性以及扩散模型的实现。

    Diffusion models are generative models, which gradually add and remove noise to learn the underlying distribution of training data for data generation. The components of diffusion models have gained significant attention with many design choices proposed. Existing reviews have primarily focused on higher-level solutions, thereby covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review on component-wise design choices in diffusion models. Specifically, we organize this review according to their three key components, namely the forward process, the reverse process, and the sampling procedure. This allows us to provide a fine-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the applicability of design choices, and the implementation of diffusion models.
    
[^115]: Schema First！通过MASCHInE捕捉语义学习通用知识图嵌入

    Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing Semantics with MASCHInE. (arXiv:2306.03659v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.03659](http://arxiv.org/abs/2306.03659)

    本论文提出了一种通过 MASCHInE 捕捉语义学习知识图嵌入的方法，通过设计生成原型图并利用其语义，进而训练出更好地捕捉语义的 KGEs。

    

    近年来，知识图嵌入模型（KGEMs）受到了广泛关注，这些模型学习了知识图中实体和关系的向量表示，即知识图嵌入（KGEs）。学习多功能的KGEs非常有意义，因为这使得它们在广泛的任务上有用。然而，KGEMs通常是针对特定任务进行训练的，这使得它们的嵌入是任务相关的。与此同时，关于KGEMs实际上是否创建了底层实体和关系的语义表示（例如，将相似的实体放在一起，将不相似的实体放在一起）的普遍假设受到了质疑。在这项工作中，我们设计了启发式方法来生成原型图-一个小型、修改过的KG版本，利用了RDF/S信息。所学习的基于原型图的嵌入旨在封装KG的语义，并可以在学习KGEs时加以利用，从而更好地捕捉语义。对各种评估基准进行了大量实验证明了这一点。

    Knowledge graph embedding models (KGEMs) have gained considerable traction in recent years. These models learn a vector representation of knowledge graph entities and relations, a.k.a. knowledge graph embeddings (KGEs). Learning versatile KGEs is desirable as it makes them useful for a broad range of tasks. However, KGEMs are usually trained for a specific task, which makes their embeddings task-dependent. In parallel, the widespread assumption that KGEMs actually create a semantic representation of the underlying entities and relations (e.g., project similar entities closer than dissimilar ones) has been challenged. In this work, we design heuristics for generating protographs -small, modified versions of a KG that leverage RDF/S information. The learnt protograph-based embeddings are meant to encapsulate the semantics of a KG, and can be leveraged in learning KGEs that, in turn, also better capture semantics. Extensive experiments on various evaluation benchmarks demonstrate the so
    
[^116]: 使预训练模型具有可逆性：从参数到内存高效的微调

    Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v1 [cs.CL])

    [http://arxiv.org/abs/2306.00477](http://arxiv.org/abs/2306.00477)

    本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。

    

    预训练语言模型（PLM）的参数高效微调已经成为一种非常成功的方法，只需训练少量参数而不会降低性能，并随着PLM越来越大而成为事实上的学习范式。然而，现有的PEFT方法不具备内存效率，因为它们仍需要存储大部分中间激活值以便计算梯度，类似于微调。一个减少激活内存的有效方法是应用可逆模型，这样中间激活值就无需缓存，可以重新计算。然而，将PLM修改为它的可逆变体并进行PEFT并不是一件容易的事，因为可逆模型具有与当前发布的PLM不同的体系结构。本文首先调查现有PEFT方法成功的关键因素，认识到在初始化PEFT时保留PLM的起点是至关重要的。

    Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs) has emerged as a highly successful approach, with training only a small number of parameters without sacrificing performance and becoming the de-facto learning paradigm with the increasing size of PLMs. However, existing PEFT methods are not memory-efficient, because they still require caching most of the intermediate activations for the gradient calculation, akin to fine-tuning. One effective way to reduce the activation memory is to apply a reversible model, so the intermediate activations are not necessary to be cached and can be recomputed. Nevertheless, modifying a PLM to its reversible variant with PEFT is not straightforward, since the reversible model has a distinct architecture from the currently released PLMs. In this paper, we first investigate what is a key factor for the success of existing PEFT methods, and realize that it's essential to preserve the PLM's starting point when initializing a PEFT 
    
[^117]: NavGPT: 带有大型语言模型的视觉语言导航中的显式推理

    NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. (arXiv:2305.16986v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.16986](http://arxiv.org/abs/2305.16986)

    NavGPT是基于LLM的导航智能体，可以在视觉语言导航（VLN）中，通过对文本描述进行推理，执行零-shot连续动作预测。该模型具有高级规划能力，可以将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。NavGPT展示了通用体现智能体发展的美好前景。

    

    大型语言模型（LLM）例如ChatGPT和GPT-4以前所未有的规模进行训练，从模型的扩展中展现出显著的推理能力。这种趋势强调了使用无限语言数据训练LLM的潜力，推动了通用体现智能体的发展。本文介绍了NavGPT，这是一个纯粹基于LLM的指令跟随导航智能体，通过为视觉语言导航（VLN）执行零-shot的连续动作预测，揭示了对于在复杂的现实场景下GPT模型的推理能力。在每一步中，NavGPT将视觉观察、导航历史和未来可探索方向的文本描述作为输入，推理出智能体的当前状态，并决定如何接近目标。通过全面的实验，我们证明了NavGPT可以明确地执行导航的高级规划，包括将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。我们的结果表明，LLM可能成为复杂顺序决策任务中的传统流程的强有力替代品，展示了通用体现智能体发展的美好前景。

    Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goal, integrating commonsense k
    
[^118]: Voyager:一个具有大型语言模型的开放式机器体代理

    Voyager: An Open-Ended Embodied Agent with Large Language Models. (arXiv:2305.16291v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.16291](http://arxiv.org/abs/2305.16291)

    Voyager是一个在Minecraft中使用大型语言模型进行开放式探索和学习的代理，它通过自动课程设置、可执行代码技能库和迭代提示机制不断提升自己的能力，并展现出强大的终身学习能力和在玩Minecraft方面的出色表现。

    

    我们介绍了Voyager，这是一个在Minecraft中持续探索世界、获得多种技能和进行新的发现而无需人类干预的第一个LLM驱动的全能代理。Voyager包括三个关键组件：1)最大化探索的自动课程设置，2)用于存储和检索复杂行为的不断增长的可执行代码技能库，和3)一种通过环境反馈、执行错误和自我验证进行程序改进的新的迭代提示机制。Voyager通过黑盒查询与GPT-4互动，避免了模型参数微调的需要。Voyager开发的技能具有时间延长性、可解释性和组合性，这加快了代理的能力增长并减轻了灾难性遗忘。从经验上看，Voyager表现出强大的上下文型终身学习能力，并在玩Minecraft方面展现了异常的熟练程度。

    We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique it
    
[^119]: 连接多模态对比表示

    Connecting Multi-modal Contrastive Representations. (arXiv:2305.14381v1 [cs.LG])

    [http://arxiv.org/abs/2305.14381](http://arxiv.org/abs/2305.14381)

    本文提出了一种无需配对数据学习MCR的方法，叫做C-MCR，并且在新空间中使用重叠模态B的数据来对齐两个MCR。通过这个方法，非重叠模态对（A，C）也可以使用连接。

    

    多模态对比表示（MCR）学习旨在将不同的模态编码到一个语义对齐的共享空间中。该范例在各种模式下的大量下游任务中表现出了显著的泛化能力。然而，对大规模高质量数据对的依赖限制了其在更多模态上的进一步发展。本文提出了一种新的无需配对数据学习MCR的训练高效方法，称为连接多模态对比表示（C-MCR）。具体而言，在（A，B）和（B，C）模态对上预训练两个现有的MCR之后，我们将它们投影到一个新的空间，并使用重叠模态B的数据来在新空间中对齐两个MCR。同时，由于模态对（A，B）和（B，C）在每个MCR内已经对齐，因此通过重叠模态学习到的连接也可以转移到非重叠模态对（A，C）。为了发挥C-MCR的潜力，我们进一步引入了一个语义增强的int

    Multi-modal Contrastive Representation (MCR) learning aims to encode different modalities into a semantically aligned shared space. This paradigm shows remarkable generalization ability on numerous downstream tasks across various modalities. However, the reliance on massive high-quality data pairs limits its further development on more modalities. This paper proposes a novel training-efficient method for learning MCR without paired data called Connecting Multi-modal Contrastive Representations (C-MCR). Specifically, given two existing MCRs pre-trained on (A, B) and (B, C) modality pairs, we project them to a new space and use the data from the overlapping modality B to aligning the two MCRs in the new space. Meanwhile, since the modality pairs (A, B) and (B, C) are already aligned within each MCR, the connection learned by overlapping modality can also be transferred to non-overlapping modality pair (A, C). To unleash the potential of C-MCR, we further introduce a semantic-enhanced int
    
[^120]: 基于多语言词义关系图的低资源语言跨语言迁移学习

    Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs. (arXiv:2305.12818v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12818](http://arxiv.org/abs/2305.12818)

    基于无注释平行语料库，我们提出一种基于词义共存模式的多语言图方法，用于低资源语言的跨语言迁移学习。通过建立高质量的多语言嵌入，我们实现了高召回率的词义共存识别。

    

    在比较语言学中，词义共存指的是一个词汇形式传达两个或更多不同的意义的现象。现有的关于词义共存模式的工作基于注释的词汇表，限制了在自然语言处理中的可扩展性和实用性。相比之下，我们从未注释的平行语料库中直接识别了超过2,000个概念在1,335种语言中的词义共存模式。然后，我们提出了简单而有效的方法来建立基于词义共存模式的多语言图：ColexNet和ColexNet+。ColexNet的节点是概念，边是词义共存关系。在ColexNet+中，概念节点通过中间节点进行附加连接，每个中间节点代表1,334种语言中的一个ngram。我们使用ColexNet+训练高质量的多语言嵌入，称之为$\overrightarrow{\mbox{ColexNet+}}$，非常适合迁移学习。在实验中，我们首先展示了ColexNet在跨语言词义共存数据集CLICS上的高召回率。然后我们对建议的方法进行了评估...

    In comparative linguistics, colexification refers to the phenomenon of a lexical form conveying two or more distinct meanings. Existing work on colexification patterns relies on annotated word lists, limiting scalability and usefulness in NLP. In contrast, we identify colexification patterns of more than 2,000 concepts across 1,335 languages directly from an unannotated parallel corpus. We then propose simple and effective methods to build multilingual graphs from the colexification patterns: ColexNet and ColexNet+. ColexNet's nodes are concepts and its edges are colexifications. In ColexNet+, concept nodes are additionally linked through intermediate nodes, each representing an ngram in one of 1,334 languages. We use ColexNet+ to train $\overrightarrow{\mbox{ColexNet+}}$, high-quality multilingual embeddings that are well-suited for transfer learning. In our experiments, we first show that ColexNet achieves high recall on CLICS, a dataset of crosslingual colexifications. We then evalu
    
[^121]: Logic-LM：通过符号求解器增强大型语言模型在准确逻辑推理方面的能力

    Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. (arXiv:2305.12295v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12295](http://arxiv.org/abs/2305.12295)

    本文介绍了一种名为Logic-LM的新框架，它将大型语言模型与符号求解器结合起来，以提升在复杂逻辑问题上的推理能力。通过将自然语言问题转化为符号表达，并利用确定性符号求解器进行推理，我们的方法能够有效地改进准确逻辑推理。实验证明，Logic-LM在多个逻辑推理数据集上取得了显著的性能提升，并且相比使用标准提示或思维链提示，效果分别提高了39.2%和18.4%。这表明将大型语言模型与符号逻辑相结合是实现准确逻辑推理的一个有前途的方法。

    

    大型语言模型(LLMs)已经展示了人类一样的推理能力，但仍然在复杂的逻辑问题上遇到困难。本文提出了一种新颖的框架，Logic-LM，将LLMs与符号求解器集成，以改进逻辑问题的解决能力。我们的方法首先利用LLMs将自然语言问题转化为符号化表述。然后，确定性符号求解器对问题进行推理。我们还引入了自我完善模块，利用符号求解器的错误信息修正符号化表示。通过在五个逻辑推理数据集ProofWriter、PrOntoQA、FOLIO、LogicalDeduction和AR-LSAT上的实验证明了Logic-LM的有效性。平均而言，Logic-LM相比仅使用LLMs的标准提示可以显著提高39.2%的性能，相比使用LLMs的思维链提示可以提高18.4%的性能。我们的研究结果表明，通过将LLMs与符号逻辑相结合，Logic-LM为准确的逻辑推理提供了一个有前途的途径。

    Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver's error messages to revise symbolic formalizations. We demonstrate Logic-LM's effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2% over using LLM alone with standard prompting and 18.4% over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical r
    
[^122]: 基于“梯度下降”与 beam search 的自动提示优化

    Automatic Prompt Optimization with "Gradient Descent" and Beam Search. (arXiv:2305.03495v1 [cs.CL])

    [http://arxiv.org/abs/2305.03495](http://arxiv.org/abs/2305.03495)

    在基于大型语言模型的自然语言处理中，使用梯度下降和 beam search 的自动提示优化方法可以自动改进提示，提高性能。

    

    大型语言模型（LLM）在通用智能方面展现了出色性能，但其能力仍高度依赖于手写的提示，需要大量的试错尝试。我们提出了一个简单而非参数化的解决方案——自动提示优化（APO），其灵感来自于使用数值梯度下降自动改进提示。

    Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of data to form natural language ``gradients'' that criticize the current prompt. The gradients are then ``propagated'' into the prompt by editing the prompt in the opposite semantic direction of the gradient. These gradient descent steps are guided by a beam search and bandit selection procedure which significantly improves algorithmic efficiency. Preliminary results across three benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest that Automatic Prompt Optimization can outperform prior prompt editing 
    
[^123]: PEFT-Ref: 一种模块化的参考架构和类型，用于参数效率微调技术

    PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v1 [cs.CL])

    [http://arxiv.org/abs/2304.12410](http://arxiv.org/abs/2304.12410)

    本文提出了PEFT-Ref参考架构，标准化了不同PEFT技术共享的方面，隔离了差异到特定位置和交互中，模块化的视图有助于比较不同技术及其效率和任务性能，并有助于更好地理解PEFT的基本原理。

    

    最近的参数效率微调(PEFT)技术旨在改善完全微调大型预训练语言模型(PLM)的高昂成本。随着不同的PEFT技术不断出现，对它们进行比较变得越来越困难，特别是在以下方面：(i)它们添加到PLM的结构和功能，(ii)不同类型和程度的效率改进，(iii)在不同的下游任务中的性能，以及(iv)结构和功能差异如何与效率和任务性能相关联。为了促进这样的比较，本文提出了一个参考框架，标准化了不同PEFT技术共享的方面，同时将差异隔离到与标准组件的特定位置和交互中。通过这个标准化和隔离差异的过程，出现了PEFT技术的模块化视图，不仅支持直接比较不同技术及其效率和任务性能，而且还有助于更好地理解PEFT的基本原理。所提出的参考架构称为PEFT-Ref，包括七个核心模块，每个模块都处理PEFT的特定方面，并可用作开发新PEFT技术和比较现有技术的指南。

    Recent parameter-efficient finetuning (PEFT) techniques aim to improve over the considerable cost of fully finetuning large pretrained language models (PLM). As different PEFT techniques proliferate, it is becoming difficult to compare them, in particular in terms of (i) the structure and functionality they add to the PLM, (ii) the different types and degrees of efficiency improvements achieved, (iii) performance at different downstream tasks, and (iv) how differences in structure and functionality relate to efficiency and task performance. To facilitate such comparisons, this paper presents a reference framework which standardises aspects shared by different PEFT techniques, while isolating differences to specific locations and interactions with the standard components. Through this process of standardising and isolating differences, a modular view of PEFT techniques emerges, supporting not only direct comparison of different techniques and their efficiency and task performance, but a
    
[^124]: Transformer介绍

    An Introduction to Transformers. (arXiv:2304.10557v1 [cs.LG])

    [http://arxiv.org/abs/2304.10557](http://arxiv.org/abs/2304.10557)

    Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。

    

    Transformer是一种可以学习序列或数据集表示的神经网络组件。Transformer在自然语言处理、计算机视觉和时空建模方面取得了重大进展。虽然有很多Transformer的介绍，但大多数都缺少对其架构的精确数学描述，其设计选择的直觉也常常缺失。此外，随着研究路径的曲折，Transformer部件的解释可能是异质的。在这篇论文中，我们旨在提供一个数学精确、直观、简洁的Transformer架构描述。

    The transformer is a neural network component that can be used to learn useful representations of sequences or sets of datapoints. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture.
    
[^125]: 一种可扩展的序列转移优化问题生成器

    A Scalable Test Problem Generator for Sequential Transfer Optimization. (arXiv:2304.08503v1 [cs.NE])

    [http://arxiv.org/abs/2304.08503](http://arxiv.org/abs/2304.08503)

    STO中已有的测试问题设计不完善，难以代表真实问题多样化关系，限制了算法的表现。本文介绍了一种可扩展的序列转移优化问题生成器。

    

    近年来，序列转移优化(STO)受到越来越多的研究关注，旨在利用储存在数据库中以前求解的优化任务的知识来提高优化性能。然而，尽管算法设计已有重大进展，但STO中的测试问题设计并不完善。它们往往是由其他基准函数随机组合而成，这些基准函数具有相同的最佳值，或者生成自表现出有限变化的实际问题。这些问题中源任务和目标任务的最优解之间的关系是手动配置的，因此单调，限制了它们表征真实问题多样化关系的能力。因此，许多算法在这些问题上取得的有前途的结果具有高度的偏见，并且难以推广到其他问题。鉴于此，我们首先引入了一些表征STO问题的基本概念。

    Sequential transfer optimization (STO), which aims to improve optimization performance by exploiting knowledge captured from previously-solved optimization tasks stored in a database, has been gaining increasing research attention in recent years. However, despite significant advancements in algorithm design, the test problems in STO are not well designed. Oftentimes, they are either randomly assembled by other benchmark functions that have identical optima or are generated from practical problems that exhibit limited variations. The relationships between the optimal solutions of source and target tasks in these problems are manually configured and thus monotonous, limiting their ability to represent the diverse relationships of real-world problems. Consequently, the promising results achieved by many algorithms on these problems are highly biased and difficult to be generalized to other problems. In light of this, we first introduce a few rudimentary concepts for characterizing STO pr
    
[^126]: 关于知识图谱中存在性一阶查询推理的研究

    On Existential First Order Queries Inference on Knowledge Graphs. (arXiv:2304.07063v1 [cs.AI])

    [http://arxiv.org/abs/2304.07063](http://arxiv.org/abs/2304.07063)

    本文阐述了关于知识图谱中存在性一阶查询推理的新方法，提出了一个新数据集，并开发了一种来自模糊逻辑理论的新搜索算法，该算法能够解决新公式，并在现有公式中超过以前的方法。

    

    知识图谱推理是一项具有挑战性的任务，因为它利用观察到的信息来预测缺失的信息。特别地，回答一阶逻辑公式是特别感兴趣的，因为它具有清晰的语法和语义。最近，提出了查询嵌入方法，该方法学习了一组实体的嵌入，并将逻辑运算视为集合运算。尽管有很多研究遵循相同的方法，但它缺乏从逻辑角度进行系统检查的方法。在本文中，我们描述了先前研究调查的查询范围，并准确地确定了它与整个存在性公式家族之间的差距。此外，我们还开发了一个包含十个新公式的新数据集，并讨论了同时出现的新挑战。最后，我们提出了一种来自模糊逻辑理论的新搜索算法，该算法能够解决新公式，并在现有公式中超过以前的方法。

    Reasoning on knowledge graphs is a challenging task because it utilizes observed information to predict the missing one. Specifically, answering first-order logic formulas is of particular interest because of its clear syntax and semantics. Recently, the query embedding method has been proposed which learns the embedding of a set of entities and treats logic operations as set operations. Though there has been much research following the same methodology, it lacks a systematic inspection from the standpoint of logic. In this paper, we characterize the scope of queries investigated previously and precisely identify the gap between it and the whole family of existential formulas. Moreover, we develop a new dataset containing ten new formulas and discuss the new challenges coming simultaneously. Finally, we propose a new search algorithm from fuzzy logic theory which is capable of solving new formulas and outperforming the previous methods in existing formulas.
    
[^127]: IC3：通过委员会共识进行图像字幕生成

    IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.01328](http://arxiv.org/abs/2302.01328)

    "IC3: Image Captioning by Committee Consensus"引入了一种通过委员会共识生成图像字幕的方法，能够从多个注释者的视角捕捉高层细节，优于单个人生成的参考字幕，并在视觉描述方面取得了显著改进。

    

    如果你请一个人描述一幅图像，他们可能会用一千种不同的方式来描述。传统上，图像字幕生成模型被训练成生成一个“最佳”（与参考最相似）的图像字幕。然而，这样做会鼓励生成“信息贫乏”的字幕，并且只关注可能细节的一个子集，而忽略了场景中其他可能有用的信息。在这项工作中，我们引入了一种简单而新颖的方法："通过委员会共识进行图像字幕生成"（IC3），旨在生成一个能够从多个注释者的视角捕捉到高层细节的单个字幕。人类评价IC3生成的字幕至少与基准SOTA模型一样有帮助的情况占了三分之二以上，并且IC3可以将SOTA自动召回系统的性能提升高达84%，胜过单个人生成的参考字幕，并显示出在视觉描述方面相比于SOTA方法的显著改进。代码可通过https://davidmchan获取。

    If you ask a human to describe an image, they might do so in a thousand different ways. Traditionally, image captioning models are trained to generate a single "best" (most like a reference) image caption. Unfortunately, doing so encourages captions that are "informationally impoverished," and focus on only a subset of the possible details, while ignoring other potentially useful information in the scene. In this work, we introduce a simple, yet novel, method: "Image Captioning by Committee Consensus" (IC3), designed to generate a single caption that captures high-level details from several annotator viewpoints. Humans rate captions produced by IC3 at least as helpful as baseline SOTA models more than two thirds of the time, and IC3 can improve the performance of SOTA automated recall systems by up to 84%, outperforming single human-generated reference captions, and indicating significant improvements over SOTA approaches for visual description. Code is available at https://davidmchan.
    
[^128]: 一种用于知识图谱链接预测的检索和阅读框架

    A Retrieve-and-Read Framework for Knowledge Graph Link Prediction. (arXiv:2212.09724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09724](http://arxiv.org/abs/2212.09724)

    这项研究提出了一种检索和阅读框架来解决现有知识图谱链接预测系统的局限性。通过首先检索相关子图上下文，然后使用高容量阅读器联合推理上下文和查询，该框架能够提供更有用的信息和更强大的表达能力。

    

    知识图谱链接预测旨在根据知识图谱中的现有事实推断出新的事实。最近的研究表明，通过图神经网络（GNNs）使用节点的图邻域提供了比仅使用查询信息更有用的信息。传统的KG链接预测的GNNs遵循整个KG上的标准消息传递范式，这导致了冗余计算、节点表示的过度平滑以及限制了它们的表达能力。在大规模上，从整个KG中聚合有用的信息进行推理变得计算上昂贵。为了解决现有KG链接预测框架的局限性，我们提出了一种新颖的检索和阅读框架，该框架首先检索与查询相关的子图上下文，然后通过高容量阅读器联合推理上下文和查询。作为我们新框架的实例化的一部分，我们提出了一种基于Transformer的GNN作为r的新方法。

    Knowledge graph (KG) link prediction aims to infer new facts based on existing facts in the KG. Recent studies have shown that using the graph neighborhood of a node via graph neural networks (GNNs) provides more useful information compared to just using the query information. Conventional GNNs for KG link prediction follow the standard message-passing paradigm on the entire KG, which leads to superfluous computation, over-smoothing of node representations, and also limits their expressive power. On a large scale, it becomes computationally expensive to aggregate useful information from the entire KG for inference. To address the limitations of existing KG link prediction frameworks, we propose a novel retrieve-and-read framework, which first retrieves a relevant subgraph context for the query and then jointly reasons over the context and the query with a high-capacity reader. As part of our exemplar instantiation for the new framework, we propose a novel Transformer-based GNN as the r
    
[^129]: 大型语言模型是带有自我验证的推理器

    Large Language Models are reasoners with Self-Verification. (arXiv:2212.09561v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.09561](http://arxiv.org/abs/2212.09561)

    本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。

    

    当大型语言模型（LLM）通过思维链（CoT）进行复杂推理时，它非常敏感于个别错误。为了解决这个问题，我们必须训练验证器。我们提出一种称为自我验证的新方法，该方法使用CoT的结论作为条件来构建一个新样本，并要求LLM重新预测被掩盖的原始条件。我们基于准确性计算可解释的验证分数。该方法可以在使用少量样本学习时提高多个算术和逻辑推理数据集的准确性。我们已经证明LLM可以对其自己的结论进行可解释的自我验证并实现竞争性的推理性能。全面的实验表明，我们的方法可以帮助多种带有自我验证功能的大型语言模型避免混淆。

    When a large language model (LLM) performs complex reasoning by chain of thought (CoT), it can be highly sensitive to individual mistakes. We have had to train verifiers to address this issue. As we all know, after human inferring a conclusion, they often check it by re-verifying it, which can avoid some mistakes. We propose a new method called self-verification that uses the conclusion of the CoT as a condition to build a new sample and asks the LLM to re-predict the original conditions which be masked. We calculate an explainable verification score based on the accuracy. This method can improve the accuracy of multiple arithmetics and logical reasoning datasets when using few-shot learning. we have demonstrated that LLMs can conduct explainable self-verification of their own conclusions and achieve competitive reasoning performance. Extensive experimentals have demonstrated that our method can help multiple large language models with self-verification can avoid interference from inco
    
[^130]: 从无标注数据中进行多人三维姿势估计

    Multi-person 3D pose estimation from unlabelled data. (arXiv:2212.08731v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.08731](http://arxiv.org/abs/2212.08731)

    本文提出了一种基于图神经网络和多层感知器的模型，通过深度学习在多视图系统中进行多人三维姿势估计，实现了对人物的唯一标识和克服噪声和潜在遮挡的挑战。此方法不需要大型数据集的3D标注。

    

    多人三维姿势估计具有广泛的应用，但在多视图系统中，由于相机提供的2D信息，需要首先在不同视图中唯一标识每个人物。此外，从多视图2D信息中估计每个人物的三维姿势需要克服噪声和潜在遮挡等挑战。本文通过深度学习解决了这两个挑战，提出了一个基于图神经网络的模型，能够预测场景中人物的跨视图对应关系，并使用多层感知器从2D点生成每个人物的三维姿势。这两个模型在自监督的方式下训练，避免了需要包含3D标注的大型数据集。

    Its numerous applications make multi-human 3D pose estimation a remarkably impactful area of research. Nevertheless, assuming a multiple-view system composed of several regular RGB cameras, 3D multi-pose estimation presents several challenges. First of all, each person must be uniquely identified in the different views to separate the 2D information provided by the cameras. Secondly, the 3D pose estimation process from the multi-view 2D information of each person must be robust against noise and potential occlusions in the scenario. In this work, we address these two challenges with the help of deep learning. Specifically, we present a model based on Graph Neural Networks capable of predicting the cross-view correspondence of the people in the scenario along with a Multilayer Perceptron that takes the 2D points to yield the 3D poses of each person. These two models are trained in a self-supervised manner, thus avoiding the need for large datasets with 3D annotations.
    
[^131]: 通过"稳定边缘"学习阈值神经元

    Learning threshold neurons via the "edge of stability". (arXiv:2212.07469v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.07469](http://arxiv.org/abs/2212.07469)

    该论文通过对简化的两层神经网络模型的梯度下降进行详细分析，揭示了大学习率下非凸训练动态的稳定边缘现象，并发现了神经网络无法学习阈值样式神经元的临界步长。

    

    现有的神经网络训练分析通常基于极小学习率的不现实假设。与实际智慧和经验研究相反，例如J. Cohen等人的工作（ICLR 2021），展示了惊人的新现象（"稳定边缘"或"不稳定收敛"），以及大学习率体制下的潜在泛化效果。然而，尽管最近有大量关于这个主题的研究，但后一种效应仍然理解有限。本文通过对简化的两层神经网络模型的梯度下降进行详细分析，迈出了理解大学习率下真正非凸训练动态的一步。对于这些模型，我们证明了稳定边缘现象，并发现了一个尖锐的阶跃转变，当步长小于此值时，神经网络无法学习到"阈值样式"神经元（即具有非零第一层偏置的神经元）。

    Existing analyses of neural network training often operate under the unrealistic assumption of an extremely small learning rate. This lies in stark contrast to practical wisdom and empirical studies, such as the work of J. Cohen et al. (ICLR 2021), which exhibit startling new phenomena (the "edge of stability" or "unstable convergence") and potential benefits for generalization in the large learning rate regime. Despite a flurry of recent works on this topic, however, the latter effect is still poorly understood. In this paper, we take a step towards understanding genuinely non-convex training dynamics with large learning rates by performing a detailed analysis of gradient descent for simplified models of two-layer neural networks. For these models, we provably establish the edge of stability phenomenon and discover a sharp phase transition for the step size below which the neural network fails to learn "threshold-like" neurons (i.e., neurons with a non-zero first-layer bias). This elu
    
[^132]: 利用对比学习和数字证据改进混淆的法律判决预测

    Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction. (arXiv:2211.08238v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08238](http://arxiv.org/abs/2211.08238)

    本文提出了一种利用对比学习和数字证据的方法改进混淆的法律判决预测。通过提出一种监督对比学习方法和利用数字证据预测处罚期限，成功地解决了区分分类错误和利用数字的问题。

    

    鉴于一个法律案例的事实描述文本，法律判决预测（LJP）旨在预测案例的罪名、法律条款和处罚期限。LJP的一个核心问题是如何区分混淆的法律案例，其中只存在微妙的文本差异。以往的研究在使用标准的交叉熵分类损失无法区分不同的分类错误，并忽略了事实描述中的数字，用于预测处罚期限。为了解决这些问题，本文首先提出了一种基于moco的监督对比学习，以学习可区分的表示，并探索构建正例对的最佳策略，从而同时有利于LJP的三个子任务。其次，为了利用法律案例中的数字来预测某些案例的处罚期限，我们进一步增强了由预训练数值模型编码的提取的犯罪金额对事实描述的表示。对公开数据集进行了大量实验。

    Given the fact description text of a legal case, legal judgment prediction (LJP) aims to predict the case's charge, law article and penalty term. A core problem of LJP is how to distinguish confusing legal cases, where only subtle text differences exist. Previous studies fail to distinguish different classification errors with a standard cross-entropy classification loss, and ignore the numbers in the fact description for predicting the term of penalty. To tackle these issues, in this work, first, we propose a moco-based supervised contrastive learning to learn distinguishable representations, and explore the best strategy to construct positive example pairs to benefit all three subtasks of LJP simultaneously. Second, in order to exploit the numbers in legal cases for predicting the penalty terms of certain cases, we further enhance the representation of the fact description with extracted crime amounts which are encoded by a pre-trained numeracy model. Extensive experiments on public 
    
[^133]: 强化学习和赌博机在语音和自然语言处理中的应用: 教程，回顾和展望

    Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook. (arXiv:2210.13623v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.13623](http://arxiv.org/abs/2210.13623)

    这篇综述调查了强化学习和赌博机在语音和自然语言处理中的最新进展，讨论了如何有效利用它们解决相关问题，构建适应性、交互性和可扩展性的模型。

    

    最近几年，强化学习和赌博机已经在包括医疗保健，金融，推荐系统，机器人以及语音和自然语言处理等广泛的实际应用中发生了转变。虽然大部分强化学习算法在语音和语言处理领域的应用主要集中于利用其灵活的优化属性提高深度神经网络的训练，但仍有许多研究空间可以利用强化学习的好处，比如基于奖励驱动的适应性、状态表示、时间结构和通用性。在本文中，我们提出了强化学习和赌博机的最新进展综述，并讨论了如何有效地利用它们来解决语音和自然语言处理问题，构建适应性、交互性和可扩展性的模型。

    In recent years, reinforcement learning and bandits have transformed a wide range of real-world applications including healthcare, finance, recommendation systems, robotics, and last but not least, the speech and natural language processing. While most speech and language applications of reinforcement learning algorithms are centered around improving the training of deep neural networks with its flexible optimization properties, there are still many grounds to explore to utilize the benefits of reinforcement learning, such as its reward-driven adaptability, state representations, temporal structures and generalizability. In this survey, we present an overview of recent advancements of reinforcement learning and bandits, and discuss how they can be effectively employed to solve speech and natural language processing problems with models that are adaptive, interactive and scalable.
    
[^134]: 粒子信念近似POMDP的最优性保证

    Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.05015](http://arxiv.org/abs/2210.05015)

    该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。

    

    部分可观察马尔可夫决策过程(POMDP)提供了现实决策和控制问题的灵活表示。然而，POMDP的求解非常困难，特别是当状态和观测空间是连续或混合的时候，这在物理系统中经常发生。尽管最近使用观测似然权重策划的在线采样POMDP算法表现出了实用的有效性，但先前并没有提出一般理论来刻画这些算法使用的粒子滤波技术的逼近误差。我们的主要贡献是限定任何POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差。这种PB-MDP和POMDP之间的基础桥梁使得我们能够通过解决相应的粒子信念MDP将任何采样MDP算法适应到POMDP中，从而将MDP算法的收敛保证扩展到POMDP中。在实践中，这可以提高在解决具有大的或连续状态空间的POMDP时的性能和鲁棒性。

    Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, thi
    
[^135]: 揭示隐私与认证稳定性之间在联邦学习中对抗毒化攻击中的联系

    Unraveling the Connections between Privacy and Certified Robustness in Federated Learning Against Poisoning Attacks. (arXiv:2209.04030v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2209.04030](http://arxiv.org/abs/2209.04030)

    该论文研究了联邦学习中隐私和认证稳定性之间的联系，并探讨了如何利用差分隐私提供认证稳定性以及如何改进隐私以提高稳定性认证。

    

    联邦学习（FL）提供了一种有效的范式，可以利用分布式用户的数据共同训练全局模型。由于本地训练数据来自不可信任的不同用户，一些研究表明FL容易受到毒化攻击。与此同时，为了保护本地用户的隐私，FL通常采用差分隐私的方式进行训练（DPFL）。因此，在本文中，我们提出以下问题：差分隐私和联邦学习中的认证稳定性之间存在何种联系？我们能否利用DPFL的隐私属性为FL提供认证稳定性？我们如何进一步改进FL的隐私以提高这种稳定性认证？我们首先研究FL的用户级和实例级隐私，并提供正式的隐私分析以实现提高实例级隐私。然后，我们提供了两个稳定性认证指标：认证预测和认证攻击无效性，用于用户和实例级DPFL的认证。

    Federated learning (FL) provides an efficient paradigm to jointly train a global model leveraging data from distributed users. As local training data comes from different users who may not be trustworthy, several studies have shown that FL is vulnerable to poisoning attacks. Meanwhile, to protect the privacy of local users, FL is usually trained in a differentially private way (DPFL). Thus, in this paper, we ask: What are the underlying connections between differential privacy and certified robustness in FL against poisoning attacks? Can we leverage the innate privacy property of DPFL to provide certified robustness for FL? Can we further improve the privacy of FL to improve such robustness certification? We first investigate both user-level and instance-level privacy of FL and provide formal privacy analysis to achieve improved instance-level privacy. We then provide two robustness certification criteria: certified prediction and certified attack inefficacy for DPFL on both user and i
    
[^136]: 能否通过脑信号揭示人类语言的内部一致性？

    Can Brain Signals Reveal Inner Alignment with Human Languages?. (arXiv:2208.06348v4 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2208.06348](http://arxiv.org/abs/2208.06348)

    本研究探索了脑信号和人类语言之间的关系，并介绍了一种名为MTAM的方法，该方法在情感分析和关系检测等下游应用中取得了新的最先进结果。

    

    脑信号（如脑电图）和人类语言在许多下游任务中被广泛研究，但二者之间的联系尚未得到很好的探索。本研究探讨了脑电图和语言之间的关系和依赖性。在表示层面上，我们引入了一种名为MTAM（Multimodal Transformer Alignment Model）的方法，用于观察这两种模态之间的协调表示。我们使用了多种关系对齐技术，如典型相关分析和Wasserstein距离，作为损失函数来转换特征。在情感分析和关系检测等下游应用中，我们在ZuCo和K-EmoCon两个数据集上实现了新的最先进结果。我们的方法在情感分析方面使K-EmoCon数据集的F1分数提高了1.7％，ZuCo数据集提高了9.3％，在关系检测方面ZuCo数据集提高了7.4％。此外，我们提供了国际上最大的人类类比推理数据集的编码方案。

    Brain Signals, such as Electroencephalography (EEG), and human languages have been widely explored independently for many downstream tasks, however, the connection between them has not been well explored. In this study, we explore the relationship and dependency between EEG and language. To study at the representation level, we introduced \textbf{MTAM}, a \textbf{M}ultimodal \textbf{T}ransformer \textbf{A}lignment \textbf{M}odel, to observe coordinated representations between the two modalities. We used various relationship alignment-seeking techniques, such as Canonical Correlation Analysis and Wasserstein Distance, as loss functions to transfigure features. On downstream applications, sentiment analysis and relation detection, we achieved new state-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method achieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets for sentiment analysis, and 7.4% on ZuCo for relation detection. In addition, we provide inter
    
[^137]: 学习通过学习交流来进行翻译

    Learning to translate by learning to communicate. (arXiv:2207.07025v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.07025](http://arxiv.org/abs/2207.07025)

    本研究提出了一种利用紧急通信（EC）和预先训练的多语言模型的技术，通过基于视觉任务激励模型来改进资源匮乏语言的非监督NMT系统。实验证明，在四种语言中，其中包括了资源匮乏的尼泊尔语，我们的方法优于仅使用回译的基准模型。

    

    我们提出并测试了一种技术，利用紧急通信（EC）和预先训练的多语言模型，改进了现代非监督NMT系统，特别是对于资源匮乏的语言。已有观点认为，当前在NLP领域主导地位的文本预训练模型无法产生稳健的自然语言理解系统，并突出了对基于目标、目标导向和交互式语言学习的需求。在我们的方法中，我们将多语言模型（mBART，Liu等，2020）嵌入到一个EC图像参考游戏中，模型被激励使用多语言生成来完成一个基于视觉的任务。我们的假设是，这将使多种语言对齐到一个共享的任务空间。我们提出了两种EC微调的变体（Steinert-Threlkeld等人，2022），其中一种在包括资源匮乏的尼泊尔语在内的四种语言中都优于仅使用回译的基准模型。

    We formulate and test a technique to use Emergent Communication (EC) with a pre-trained multilingual model to improve on modern Unsupervised NMT systems, especially for low-resource languages. It has been argued that the current dominant paradigm in NLP of pre-training on text-only corpora will not yield robust natural language understanding systems, and the need for grounded, goal-oriented, and interactive language learning has been high lighted. In our approach, we embed a multilingual model (mBART, Liu et al., 2020) into an EC image-reference game, in which the model is incentivized to use multilingual generations to accomplish a vision-grounded task. The hypothesis is that this will align multiple languages to a shared task space. We present two variants of EC Fine-Tuning (Steinert-Threlkeld et al., 2022), one of which outperforms a backtranslation-only baseline in all four languages investigated, including the low-resource language Nepali.
    
[^138]: PROFHIT: 面向分层时间序列的概率鲁棒预测

    PROFHIT: Probabilistic Robust Forecasting for Hierarchical Time-series. (arXiv:2206.07940v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.07940](http://arxiv.org/abs/2206.07940)

    PROFHIT是一个概率鲁棒的分层时间序列预测模型，能够提供整个层次结构的预测分布，并引入一种新颖的分布一致性正则化方法。

    

    概率性分层时间序列预测是时间序列预测的重要变种，其目标是建模和预测具有分层关系的多变量时间序列。大多数方法关注点预测，并没有提供良好校准的概率预测分布。最近的概率预测方法在点预测和分布样本上也引入了分层关系，但没有考虑预测分布的一致性。之前的工作也默默地假设数据集总是与给定的分层关系一致，并且不适应显示与此假设偏离的真实世界数据集。我们填补了这两个差距，并提出了PROFHIT，这是一个完全概率性的分层预测模型，能够同时建模整个层次结构的预测分布。PROFHIT采用灵活的概率贝叶斯方法，并引入一种新颖的分布一致性正则化方法。

    Probabilistic hierarchical time-series forecasting is an important variant of time-series forecasting, where the goal is to model and forecast multivariate time-series that have underlying hierarchical relations. Most methods focus on point predictions and do not provide well-calibrated probabilistic forecasts distributions. Recent state-of-art probabilistic forecasting methods also impose hierarchical relations on point predictions and samples of distribution which does not account for coherency of forecast distributions. Previous works also silently assume that datasets are always consistent with given hierarchical relations and do not adapt to real-world datasets that show deviation from this assumption. We close both these gaps and propose PROFHIT, which is a fully probabilistic hierarchical forecasting model that jointly models forecast distribution of entire hierarchy. PROFHIT uses a flexible probabilistic Bayesian approach and introduces a novel Distributional Coherency regulari
    
[^139]: 无关类别的有条件神经过程的6D姿态估计

    Category-Agnostic 6D Pose Estimation with Conditional Neural Processes. (arXiv:2206.07162v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.07162](http://arxiv.org/abs/2206.07162)

    该论文提出了一种无关类别的6D姿态估计方法，通过神经过程元学习来捕捉对象的纹理和几何形状，并使用几何感知解码器考虑对象的几何约束进行关键点预测。

    

    我们提出了一种新颖的元学习方法，用于未知物体的6D姿态估计。与“实例级”和“类别级”姿态估计方法相比，我们的算法以无关类别的方式学习对象表示，使其具有强大的跨对象类别的泛化能力。具体地，我们采用基于神经过程的元学习方法，通过很少的RGB-D图像和真实关键点来训练编码器捕捉对象的纹理和几何形状，并得到一个潜在表示。然后，潜在表示被同时元训练的解码器用于预测新图像中物体的6D姿态。此外，我们提出了一种针对关键点预测的新颖几何感知解码器，使用图神经网络（GNN）明确考虑到每个对象的几何约束。为了评估我们的算法，在linemod数据集和我们的新的完全注释数据集上进行了大量实验。

    We present a novel meta-learning approach for 6D pose estimation on unknown objects. In contrast to ``instance-level" and ``category-level" pose estimation methods, our algorithm learns object representation in a category-agnostic way, which endows it with strong generalization capabilities across object categories. Specifically, we employ a neural process-based meta-learning approach to train an encoder to capture texture and geometry of an object in a latent representation, based on very few RGB-D images and ground-truth keypoints. The latent representation is then used by a simultaneously meta-trained decoder to predict the 6D pose of the object in new images. Furthermore, we propose a novel geometry-aware decoder for the keypoint prediction using a Graph Neural Network (GNN), which explicitly takes geometric constraints specific to each object into consideration. To evaluate our algorithm, extensive experiments are conducted on the \linemod dataset, and on our new fully-annotated s
    
[^140]: 基于示例的超网络用于领域外泛化

    Example-based Hypernetworks for Out-of-Distribution Generalization. (arXiv:2203.14276v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.14276](http://arxiv.org/abs/2203.14276)

    本文提出了一个基于示例的超网络框架，利用多个源领域的标记数据来进行领域外泛化。该框架通过生成输入示例的唯一签名，并将其嵌入源领域的语义空间中，并利用超网络生成任务分类器的权重。实验结果表明，该方法在29个适应场景中表现优于现有算法，且在输入示例的表示上具有丰富性。同时，与少样本GPT-3进行了比较，证明了其有效性。

    

    随着自然语言处理(NLP)算法不断突破新的里程碑，领域外泛化仍然是一个重大挑战。本文解决了对于陌生领域的多源适应问题：我们利用来自多个源领域的标记数据，在训练中泛化到未知目标领域。我们的创新性框架采用基于示例的超网络适应：一个T5编码-解码器首先从输入示例中生成一个唯一的签名，并将其嵌入到源领域的语义空间中。然后，这个签名被一个超网络利用来生成任务分类器的权重。我们在29种适应场景中评估了我们的方法，涉及情感分类和自然语言推理两个任务，在这些场景中，我们的方法超过了已有算法。在高级版本中，签名还丰富了输入示例的表示。我们还将我们的微调架构与少样本GPT-3进行了比较，证明了其有效性。

    As Natural Language Processing (NLP) algorithms continually achieve new milestones, out-of-distribution generalization remains a significant challenge. This paper addresses the issue of multi-source adaptation for unfamiliar domains: We leverage labeled data from multiple source domains to generalize to unknown target domains at training. Our innovative framework employs example-based Hypernetwork adaptation: a T5 encoder-decoder initially generates a unique signature from an input example, embedding it within the source domains' semantic space. This signature is subsequently utilized by a Hypernetwork to generate the task classifier's weights. We evaluated our method across two tasks - sentiment classification and natural language inference - in 29 adaptation scenarios, where it outpaced established algorithms. In an advanced version, the signature also enriches the input example's representation. We also compare our finetuned architecture to few-shot GPT-3, demonstrating its effectiv
    
[^141]: 深度判别到核生成网络的定标推断方法

    Deep Discriminative to Kernel Generative Networks for Calibrated Inference. (arXiv:2201.13001v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.13001](http://arxiv.org/abs/2201.13001)

    该论文提出了将判别网络转换为生成网络的方法，用高斯核替换多面体中的仿射函数来生成模型，解决了内部和外部数据校准问题，并在 CIFAR-10，CIFAR-100 和 SVHN 等基准数据集上测试了方法的有效性。

    

    判别与生成网络在人工智能和自然智能的研究中都有其重要性，我们提出了一种将二者相结合的方法，将深度判别网络转换为核生成网络。我们将深度模型视为广义的划分规则，并使用高斯核替换由训练数据构成的多面体中的仿射函数，来获得生成模型。实验证明了我们方法的有效性。

    The fight between discriminative versus generative goes deep, in both the study of artificial and natural intelligence. In our view, both camps have complementary values. So, we sought to synergistically combine them. Here, we propose a methodology to convert deep discriminative networks to kernel generative networks. We leveraged the fact that deep models, including both random forests and deep networks, learn internal representations which are unions of polytopes with affine activation functions to conceptualize them both as generalized partitioning rules. We replace the affine function in each polytope populated by the training data with Gaussian kernel that results in a generative model. Theoretically, we derive the conditions under which our generative models are a consistent estimator of the corresponding class conditional density. Moreover, our proposed models obtain well calibrated posteriors for in-distribution, and extrapolate beyond the training data to handle out-of-distrib
    
[^142]: 使用单调算子理论进行三层和多层优化

    Trilevel and Multilevel Optimization using Monotone Operator Theory. (arXiv:2105.09407v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2105.09407](http://arxiv.org/abs/2105.09407)

    该论文提出了一个基于不动点理论的自然一阶算法，用于解决通用的多层优化问题，并分析了其在不同参数区间下的收敛性和收敛速度。

    

    我们考虑一类相当通用的多层优化问题，其中一个凸目标函数需要在满足嵌套凸优化问题的最优性约束下进行最小化。作为特例，我们考虑了一个三层优化问题，其中两个较低层的目标包括平滑项和非平滑项的求和。基于不动点理论和相关论证，我们提出了一种自然的一阶算法，并分析了在几个参数区间下的收敛性和收敛速度。

    We consider rather a general class of multi-level optimization problems, where a convex objective function is to be minimized subject to constraints of optimality of nested convex optimization problems. As a special case, we consider a trilevel optimization problem, where the objective of the two lower layers consists of a sum of a smooth and a non-smooth term.~Based on fixed-point theory and related arguments, we present a natural first-order algorithm and analyze its convergence and rates of convergence in several regimes of parameters.
    

